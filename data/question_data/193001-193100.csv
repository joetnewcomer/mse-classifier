,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Derivative of sign function with two variables in the argument,Derivative of sign function with two variables in the argument,,"It is known that the derivative of the sign function $\mathbf{sgn}$ , defined as $$ \mathrm{sgn}(x) = \frac{x}{|x|} $$ is given as $$ \frac{\mathrm d}{\mathrm dx}\mathrm{sgn}(x) = 2\delta (x) $$ where $\delta(x)$ represents the Dirac delta function. Suppose now I have a sign function with 2 variables $x$ , $y$ in its argument. Namely: $\mathrm{sgn}(x-y)$ . How can I compute $$ \frac{\mathrm d}{\mathrm dy}\mathrm{sgn}(x-y)\qquad? $$","It is known that the derivative of the sign function , defined as is given as where represents the Dirac delta function. Suppose now I have a sign function with 2 variables , in its argument. Namely: . How can I compute","\mathbf{sgn} 
\mathrm{sgn}(x) = \frac{x}{|x|}
 
\frac{\mathrm d}{\mathrm dx}\mathrm{sgn}(x) = 2\delta (x)
 \delta(x) x y \mathrm{sgn}(x-y) 
\frac{\mathrm d}{\mathrm dy}\mathrm{sgn}(x-y)\qquad?
","['derivatives', 'absolute-value', 'dirac-delta']"
1,Spivak: How do we know $\arctan{x}$ and $\log{(1+x)}$ for all $x$ if we know these functions for $|x|<1$?,Spivak: How do we know  and  for all  if we know these functions for ?,\arctan{x} \log{(1+x)} x |x|<1,"In Ch. 20 of Spivak's Calculus , he shows that the remainder terms for $\arctan$ and $\log{(1+x)}$ become large with the order of the Taylor polynomial used to approximate these functions. Thus these approximations are of no use whatsoever in computing $\arctan{x}$ and $\log{(1+x)}$ . This is no tragedy, because the values of these functions can be found for any $x$ once they are known for all $x$ with $|x|<1$ . How do we find the values of these functions for any $x$ if we know the functions for $|x|<1$ ?","In Ch. 20 of Spivak's Calculus , he shows that the remainder terms for and become large with the order of the Taylor polynomial used to approximate these functions. Thus these approximations are of no use whatsoever in computing and . This is no tragedy, because the values of these functions can be found for any once they are known for all with . How do we find the values of these functions for any if we know the functions for ?",\arctan \log{(1+x)} \arctan{x} \log{(1+x)} x x |x|<1 x |x|<1,"['calculus', 'integration', 'derivatives', 'polynomials', 'taylor-expansion']"
2,Solving $ A\frac{\partial z}{\partial x} + B \frac{\partial^2 z}{ \partial x \partial y} + C \frac{\partial^3 z}{\partial x \partial^2 y} = 0 $? [closed],Solving ? [closed], A\frac{\partial z}{\partial x} + B \frac{\partial^2 z}{ \partial x \partial y} + C \frac{\partial^3 z}{\partial x \partial^2 y} = 0 ,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Non-mathematician here trying to find a hopefully analytic solution or any constructive directions  for solving differential equations of this particular form: Take a function $z(x,y)$ , is there any solution structure for $ A\frac{\partial z}{\partial x} + B \frac{\partial^2 z}{ \partial x \partial y} + C \frac{\partial^3 z}{\partial x \partial^2 y} = 0 $ ? $A,B,C \in \Bbb{R} $ Thanks","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Non-mathematician here trying to find a hopefully analytic solution or any constructive directions  for solving differential equations of this particular form: Take a function , is there any solution structure for ? Thanks","z(x,y)  A\frac{\partial z}{\partial x} + B \frac{\partial^2 z}{ \partial x \partial y} + C \frac{\partial^3 z}{\partial x \partial^2 y} = 0  A,B,C \in \Bbb{R} ","['derivatives', 'partial-differential-equations']"
3,Let $f:\mathbb{R \rightarrow R}$ satisfies $f(x)+f(y)= f \biggl(\frac{x+y}{1-xy}\biggl)$ and $f'(0)=5$. Then find $f(x)$,Let  satisfies  and . Then find,f:\mathbb{R \rightarrow R} f(x)+f(y)= f \biggl(\frac{x+y}{1-xy}\biggl) f'(0)=5 f(x),Let $f:\mathbb{R \rightarrow R}$ satisfies $f(x)+f(y)= f \biggl(\frac{x+y}{1-xy}\biggl)$ and $f'(0)=5$ . Then find $f(x)$ Teacher's Method: He differentiated the whole function with respect to $x$ as follow $f^{\prime}(x)+f^{\prime}(y) \cdot \frac{dy}{dx}=f^{\prime}(\frac {x+y}{1-xy}) \cdot \biggl(\frac{\big(1-xy\big)\big(1+\frac{dy}{dx}\big)+\big(x+y\big)\big(x\frac{dy}{dx}+y\big)}{\big(1-xy\bigl)^2}\biggl)$ And he put $\frac{dy}{dx}=0$ stating that $x$ and $y$ are independent and finally he obtained the result $f(x)=5\tan^{-1}(x)$ My Doubt: why $x$ and $y$ are independent? finally we are obtaining the result $y=5\tan^{-1}(x)$ $\;$ then how can they be independent? My second Doubt: why above method is not working for $f(x+y)=f(x)+f(y)$ I know what is the other method to solve this Question but my doubt is as mentioned above.,Let satisfies and . Then find Teacher's Method: He differentiated the whole function with respect to as follow And he put stating that and are independent and finally he obtained the result My Doubt: why and are independent? finally we are obtaining the result then how can they be independent? My second Doubt: why above method is not working for I know what is the other method to solve this Question but my doubt is as mentioned above.,f:\mathbb{R \rightarrow R} f(x)+f(y)= f \biggl(\frac{x+y}{1-xy}\biggl) f'(0)=5 f(x) x f^{\prime}(x)+f^{\prime}(y) \cdot \frac{dy}{dx}=f^{\prime}(\frac {x+y}{1-xy}) \cdot \biggl(\frac{\big(1-xy\big)\big(1+\frac{dy}{dx}\big)+\big(x+y\big)\big(x\frac{dy}{dx}+y\big)}{\big(1-xy\bigl)^2}\biggl) \frac{dy}{dx}=0 x y f(x)=5\tan^{-1}(x) x y y=5\tan^{-1}(x) \; f(x+y)=f(x)+f(y),"['calculus', 'integration', 'derivatives', 'partial-derivative', 'inverse-function']"
4,Why is it necessary to take the 2nd derivative to determine concavity?,Why is it necessary to take the 2nd derivative to determine concavity?,,"I'm having trouble understanding why you need the second derivative to determine concavity. For example, if I have the equation: $y = -4x^2 + 24x + 42$ $y' = -8x +24$ I know from the first derivative alone that the slope is -8 from what you learn from $y=mx+b$ . So what's the point in taking the second derivative? Isn't taking the slope of the slope (second derivative) redundant at this point? For context: I have read / listened to explanations online. And I understand the explanations about getting the first derivative for the slope. But then the explanation says something along the lines of, ""So it follows that the second derivative will give us what we need for concavity. If the slope is greater than 0,...If the slope is less than 0,..."" But if the first derivative is a tangent line (straight line) then what are we taking the slope for again? I thought taking the derivative could be used for straight lines, but was specifically useful for non-linear graphs. Otherwise, if it's linear, we could just use $y=mx+b$ to determine the slope. Or am I oversimplified this? And the real point is that if you have higher order equations, you can differentiate until you have no variables and that gives you the slope? Note: I did see this question, but I'm still confused. Concavity & Second Derivative","I'm having trouble understanding why you need the second derivative to determine concavity. For example, if I have the equation: I know from the first derivative alone that the slope is -8 from what you learn from . So what's the point in taking the second derivative? Isn't taking the slope of the slope (second derivative) redundant at this point? For context: I have read / listened to explanations online. And I understand the explanations about getting the first derivative for the slope. But then the explanation says something along the lines of, ""So it follows that the second derivative will give us what we need for concavity. If the slope is greater than 0,...If the slope is less than 0,..."" But if the first derivative is a tangent line (straight line) then what are we taking the slope for again? I thought taking the derivative could be used for straight lines, but was specifically useful for non-linear graphs. Otherwise, if it's linear, we could just use to determine the slope. Or am I oversimplified this? And the real point is that if you have higher order equations, you can differentiate until you have no variables and that gives you the slope? Note: I did see this question, but I'm still confused. Concavity & Second Derivative",y = -4x^2 + 24x + 42 y' = -8x +24 y=mx+b y=mx+b,"['calculus', 'derivatives']"
5,Calculating $f(x)$,Calculating,f(x),"Let $f(x)$ be a non-constant polynomial satisfying the relation $$f(x)f(y)=f(x)+f(y)+f(xy)-2; \forall x,y \in \Bbb R;\\ f(0)\ne1, f(4)=65,$$ By plugging $x=y=1$ , we get two values of $f(1)=1,2$ . But now which is the correct value? Similar when we do it for $x=0$ , $f(0)=1,2$ and following the question $f(0)=2$ . But as it is a non-constant polynomial $f(1)=1$ , is this argument correct? We can easily calculate all the values of $f(x)$ as we did for $x=0,1$ . We can also plug $y=\frac{1}{x}$ but now how should we calculate $f(x)$ . Because we have two values each for $f(1),f(2),f(3)....$ so on. But which is the correct one and what's the reason?","Let be a non-constant polynomial satisfying the relation By plugging , we get two values of . But now which is the correct value? Similar when we do it for , and following the question . But as it is a non-constant polynomial , is this argument correct? We can easily calculate all the values of as we did for . We can also plug but now how should we calculate . Because we have two values each for so on. But which is the correct one and what's the reason?","f(x) f(x)f(y)=f(x)+f(y)+f(xy)-2; \forall x,y \in \Bbb R;\\ f(0)\ne1, f(4)=65, x=y=1 f(1)=1,2 x=0 f(0)=1,2 f(0)=2 f(1)=1 f(x) x=0,1 y=\frac{1}{x} f(x) f(1),f(2),f(3)....","['derivatives', 'polynomials', 'functional-equations']"
6,"Suppose that $f \in \mathcal{C}^{1}([a, b])$. Prove that $|f(x)| \leqslant \frac{1}{2}|f(a)+f(b)|+\int_{a}^{b}\left|f^{\prime}\right|$",Suppose that . Prove that,"f \in \mathcal{C}^{1}([a, b]) |f(x)| \leqslant \frac{1}{2}|f(a)+f(b)|+\int_{a}^{b}\left|f^{\prime}\right|","I've tried to prove it through the following way but failed. There is a gap that I can't get through. $$ |f(x)| = \left|\int^b_x f'-f(b)\right| = \left| \int^x_a f'+f(a)\right|, $$ So $$ 2|f(x)|=\left|\int^b_x f'-f(b)\right| + \left|\int^x_a f'+f(a)\right| $$ Thus $$ 2|f(x)|  = \left|\int^b_x f'-f(b)\right| + \left|\int^x_a f'+f(a) \right|  \le \left| \int^b_x f'\right| + |f(b)| + \left|\int^x_a f'\right|+|f(a)| $$ Since we have $$ \left| \int^b_x f' \right| \le \int^b_x |f'| \quad \text{ and } \quad \left| \int^x_a f' \right| \le \int^x_a |f'| $$ Thus $$ \left|\int^b_x f'\right| + \left| \int^x_a f' \right|  \le \int^b_x |f'| + \int^x_a |f'|  =   \int^b_a |f'| $$ But the problem is that I can't have $|f(b)|+|f(a)|\le|f(a)+f(b)|$ So I think I probably went in a wrong way.",I've tried to prove it through the following way but failed. There is a gap that I can't get through. So Thus Since we have Thus But the problem is that I can't have So I think I probably went in a wrong way.,"
|f(x)| = \left|\int^b_x f'-f(b)\right| = \left| \int^x_a f'+f(a)\right|,
 
2|f(x)|=\left|\int^b_x f'-f(b)\right| + \left|\int^x_a f'+f(a)\right|
 
2|f(x)|
 = \left|\int^b_x f'-f(b)\right| + \left|\int^x_a f'+f(a) \right|
 \le \left| \int^b_x f'\right| + |f(b)| + \left|\int^x_a f'\right|+|f(a)|
 
\left| \int^b_x f' \right| \le \int^b_x |f'|
\quad \text{ and } \quad
\left| \int^x_a f' \right| \le \int^x_a |f'|
 
\left|\int^b_x f'\right| + \left| \int^x_a f' \right|
 \le \int^b_x |f'| + \int^x_a |f'|
 =   \int^b_a |f'|
 |f(b)|+|f(a)|\le|f(a)+f(b)|","['real-analysis', 'integration', 'derivatives', 'inequality', 'sobolev-spaces']"
7,Find the general solution to the differential equation $\frac{dy}{dx} = \frac{2\sqrt{1+e^y}}{ \sec(x)} \cdot e^{\sin(x)-y}$,Find the general solution to the differential equation,\frac{dy}{dx} = \frac{2\sqrt{1+e^y}}{ \sec(x)} \cdot e^{\sin(x)-y},"This is for Calculus 2. Finding the General solution for: $$\frac{dy}{dx} = \frac{2\sqrt{1+e^y}}{ \sec(x)} \cdot e^{\sin(x)-y}$$ Hello everyone, I am not quite sure how to start solving this equation. If someone could help me set up the equation by having the y-values on the the left. That is all I need. Thank you!","This is for Calculus 2. Finding the General solution for: Hello everyone, I am not quite sure how to start solving this equation. If someone could help me set up the equation by having the y-values on the the left. That is all I need. Thank you!",\frac{dy}{dx} = \frac{2\sqrt{1+e^y}}{ \sec(x)} \cdot e^{\sin(x)-y},"['calculus', 'derivatives', 'differential']"
8,Prove that $x/(1 + \frac{2}{\pi} \cdot x) < \arctan(x)$ $\forall x > 0$,Prove that,x/(1 + \frac{2}{\pi} \cdot x) < \arctan(x) \forall x > 0,"The first thing that I tried to do is to differentiate both functions and try to see if there establishes inequality that we want (considering that they are equal when $x = 0$ ). This attempt failed because firstly it really is true but after that we get opposing inequality. Also, I have noticed that $\lim \frac{x}{1 + x \cdot \frac{2}{\pi}} = \lim \arctan(x) = \frac{\pi}{2}$ as $x \rightarrow + \infty$ but it didn't lead me to solution. I also tried to apply Taylor's formula but it didn't help much either. So, what are available ways to solve this problem?","The first thing that I tried to do is to differentiate both functions and try to see if there establishes inequality that we want (considering that they are equal when ). This attempt failed because firstly it really is true but after that we get opposing inequality. Also, I have noticed that as but it didn't lead me to solution. I also tried to apply Taylor's formula but it didn't help much either. So, what are available ways to solve this problem?",x = 0 \lim \frac{x}{1 + x \cdot \frac{2}{\pi}} = \lim \arctan(x) = \frac{\pi}{2} x \rightarrow + \infty,"['calculus', 'derivatives', 'inequality']"
9,How to differentiate $ABA^T$ with respect to $A$?,How to differentiate  with respect to ?,ABA^T A,"I don't see how to differentiate $ABA^T$ with respect to $A$ where $A$ and $B$ are $n\times n$ matrices. I know it's going to be a rank-4 tensor, but what exactly will it be? The inspiration for this comes from having to find the derivative of the covariance matrix $\operatorname{Cov}(TX)$ with respect to $T$ . So I'll tell you all what I've done so far and maybe you can help. I was working with the squared Bures distance $d_H^2(Cov(TX),\Sigma_v) = tr(Cov(TX) + \Sigma_v - 2(Cov(TX))^{1/2}\Sigma_v Cov(TX)^{1/2})^{1/2})$ . First I computed the derivative of $d_H^2(A,B)$ for positive matrices $A$ and $B$ , which turned out to be $tr(I-A_{\#}B^{-1})$ . Here we define $A_{\#}B=(AB^{-1})^{1/2}B.$ So now I was using the chain rule to compute the derivative of $d_H^2(Cov(TX),\Sigma_v)$ . But in order to do that, I need to differentiate $Cov(TX)$ w.r.t. $T$ . That's where I'm stuck. ========= Ultimately, I'm looking to find the gradient with respect to $T$ of $$ \lambda \left\|TX-X\right\|^2 + \left\|T\right\|_{HS} + d_H^2(Cov(TX),\Sigma_v). $$ and calculate its roots. Assuming I didn't make any mistakes, the derivatives of the first two terms are $2(TX-X)X^T$ and $T/\left\|T\right\|_{HS}$ respectively -- feel free to correct me if I'm wrong here. So the last term is what's causing problems for me when I differentiate.","I don't see how to differentiate with respect to where and are matrices. I know it's going to be a rank-4 tensor, but what exactly will it be? The inspiration for this comes from having to find the derivative of the covariance matrix with respect to . So I'll tell you all what I've done so far and maybe you can help. I was working with the squared Bures distance . First I computed the derivative of for positive matrices and , which turned out to be . Here we define So now I was using the chain rule to compute the derivative of . But in order to do that, I need to differentiate w.r.t. . That's where I'm stuck. ========= Ultimately, I'm looking to find the gradient with respect to of and calculate its roots. Assuming I didn't make any mistakes, the derivatives of the first two terms are and respectively -- feel free to correct me if I'm wrong here. So the last term is what's causing problems for me when I differentiate.","ABA^T A A B n\times n \operatorname{Cov}(TX) T d_H^2(Cov(TX),\Sigma_v) = tr(Cov(TX) + \Sigma_v - 2(Cov(TX))^{1/2}\Sigma_v Cov(TX)^{1/2})^{1/2}) d_H^2(A,B) A B tr(I-A_{\#}B^{-1}) A_{\#}B=(AB^{-1})^{1/2}B. d_H^2(Cov(TX),\Sigma_v) Cov(TX) T T 
\lambda \left\|TX-X\right\|^2 + \left\|T\right\|_{HS} + d_H^2(Cov(TX),\Sigma_v).
 2(TX-X)X^T T/\left\|T\right\|_{HS}","['matrices', 'derivatives', 'matrix-calculus', 'tensors']"
10,What is the derivative of $\mathbf{a}^T\mathbf{X}^2\mathbf{b}$ wrt the matrix $\mathbf{X}$?,What is the derivative of  wrt the matrix ?,\mathbf{a}^T\mathbf{X}^2\mathbf{b} \mathbf{X},"Given vectors $\mathbf{a}$ and $\mathbf{b}$ , I am looking for the derivative of the following scalar function $$y(\mathbf{X}) = \mathbf{a}^T\mathbf{X}^2\mathbf{b}$$ with respect to matrix $\mathbf{X}$ . I couldn't find a direct answer from Wikipedia .","Given vectors and , I am looking for the derivative of the following scalar function with respect to matrix . I couldn't find a direct answer from Wikipedia .",\mathbf{a} \mathbf{b} y(\mathbf{X}) = \mathbf{a}^T\mathbf{X}^2\mathbf{b} \mathbf{X},"['matrices', 'derivatives', 'matrix-calculus']"
11,How to differentiate using properties of logarithms,How to differentiate using properties of logarithms,,"How would I differentiate the function $\ln\dfrac{x-1}{x^3}$ by applying the properties of logarithms? I've already differentiated using chain rule and got $-\dfrac{2x-3}{(x-1)x}$ . However, I'm not sure how to do so with the properties of logarithms.","How would I differentiate the function by applying the properties of logarithms? I've already differentiated using chain rule and got . However, I'm not sure how to do so with the properties of logarithms.",\ln\dfrac{x-1}{x^3} -\dfrac{2x-3}{(x-1)x},"['calculus', 'derivatives']"
12,Integrate $\int \frac{dx}{\sqrt{x^2-9}}$ by trig substitution [duplicate],Integrate  by trig substitution [duplicate],\int \frac{dx}{\sqrt{x^2-9}},"This question already has answers here : Integral of $\int \frac{dx}{\sqrt{x^2 -9}}$ (2 answers) Closed 5 years ago . $$ \begin{align} x = 3\sec\theta, dx &= 3\sec\theta\tan\theta d\theta\\\\ \int \frac{dx}{\sqrt{x^2-9}} &= \int \frac{3\sec\theta\tan\theta d\theta}{\sqrt{(3\sec\theta)^2 - 3^2}} \\\\ & = \int \frac{3\sec\theta\tan\theta d\theta}{\sqrt{3^2(\sec^2\theta -1)}} \\\\ &= \int \frac{3\sec\theta\tan\theta d\theta}{\sqrt{3^2\tan^2\theta}} = \int \sec\theta\\\\ &= \ln|\sec\theta + \tan\theta| + C = \ln| \frac{x}{3} + \frac{\sqrt{x^2-9}}{3}| \end{align} $$ However, wolphram alpha says the answer is $\ln |x+ \sqrt{x^2-9}$ I am wondering how did it get rid of the 3 in the denominator? This is pretty much how I got my answer: $$ x = 3\sec\theta \\ \frac{x}{3} = \sec\theta \\ \frac{\sqrt{x^2-9}}{3} = \tan\theta $$","This question already has answers here : Integral of $\int \frac{dx}{\sqrt{x^2 -9}}$ (2 answers) Closed 5 years ago . However, wolphram alpha says the answer is I am wondering how did it get rid of the 3 in the denominator? This is pretty much how I got my answer:","
\begin{align}
x = 3\sec\theta, dx &= 3\sec\theta\tan\theta d\theta\\\\
\int \frac{dx}{\sqrt{x^2-9}} &= \int \frac{3\sec\theta\tan\theta d\theta}{\sqrt{(3\sec\theta)^2 - 3^2}} \\\\
& = \int \frac{3\sec\theta\tan\theta d\theta}{\sqrt{3^2(\sec^2\theta -1)}} \\\\
&= \int \frac{3\sec\theta\tan\theta d\theta}{\sqrt{3^2\tan^2\theta}} = \int \sec\theta\\\\
&= \ln|\sec\theta + \tan\theta| + C = \ln| \frac{x}{3} + \frac{\sqrt{x^2-9}}{3}|
\end{align}
 \ln |x+ \sqrt{x^2-9} 
x = 3\sec\theta \\
\frac{x}{3} = \sec\theta \\
\frac{\sqrt{x^2-9}}{3} = \tan\theta
","['calculus', 'integration', 'derivatives', 'trigonometry']"
13,Integrate $\int \frac{dx}{(x^2-1)^{\frac{3}{2}}}$ via trig substitution,Integrate  via trig substitution,\int \frac{dx}{(x^2-1)^{\frac{3}{2}}},"$x = a\sec\theta, dx = \sec\theta \tan\theta$ $\int \frac{dx}{(x^2-1)^{\frac{3}{2}}}$ = $ \int \frac{dx}{(\tan^2\theta)^{\frac{3}{2}}}$ = $ \int \frac{dx}{\tan^{\frac{7}{2}}\theta}$ = $\int \frac{\sec\theta \tan\theta}{\tan\theta ^{\frac{7}{2}}}$ = $\int \tan^{\frac{-5}{2}}\theta \sec\theta$ Here is where I get stuck...I tried converting $\tan\theta$ and $\sec\theta$ in terms of $\cos\theta$ and $\sin\theta$ , but that didn't seem to get me anywhere...What is my next move from here? Did I even start this problem correctly? I can't tell :( Update with more work after initial answers: $\int \frac{\cos\theta}{\sin^2\theta}$ $u = \sin\theta, du = \cos\theta d\theta$ I found $\sin^{-1}\theta = \frac{\sqrt{x^2-1}}{x}$ $= \int \frac{du}{u^2} = \frac{1}{ \frac{1}{3}u^3} =  \frac{1}{3\sin^3\theta} = 3 \bigg( \frac{x}{\sqrt{x^2-1}} \bigg)^3$","= = = = Here is where I get stuck...I tried converting and in terms of and , but that didn't seem to get me anywhere...What is my next move from here? Did I even start this problem correctly? I can't tell :( Update with more work after initial answers: I found","x = a\sec\theta, dx = \sec\theta \tan\theta \int \frac{dx}{(x^2-1)^{\frac{3}{2}}}  \int \frac{dx}{(\tan^2\theta)^{\frac{3}{2}}}  \int \frac{dx}{\tan^{\frac{7}{2}}\theta} \int \frac{\sec\theta \tan\theta}{\tan\theta ^{\frac{7}{2}}} \int \tan^{\frac{-5}{2}}\theta \sec\theta \tan\theta \sec\theta \cos\theta \sin\theta \int \frac{\cos\theta}{\sin^2\theta} u = \sin\theta, du = \cos\theta d\theta \sin^{-1}\theta = \frac{\sqrt{x^2-1}}{x} = \int \frac{du}{u^2} = \frac{1}{ \frac{1}{3}u^3} = 
\frac{1}{3\sin^3\theta}
= 3 \bigg( \frac{x}{\sqrt{x^2-1}} \bigg)^3","['integration', 'derivatives', 'trigonometry']"
14,Maclaurin Series from sin(x) to cos(x) using derivative,Maclaurin Series from sin(x) to cos(x) using derivative,,"I understand how to find the MacLaurin series for $\sin(x)$ . $$\sum_{n=1}^\infty \frac{x^{2n-1}\cdot\!(-1)^{n-1}}{(2n-1)!}$$ Now I am trying to find the MacLaurin series for $\cos(x)$ by taking the derivative of the above sum with respect to $x$ . Using power rule, I got the following series: $$\cos(x) = \sum_{n=1}^\infty \frac{x^{2n-2}\cdot\!\mathrm{(-1)}^{n-1}}{(2n-2)!}$$ However, the MacLaurin series is: $$\cos(x) = \sum_{n=0}^\infty \frac{x^{2n}\cdot\!\mathrm{(-1)}^{n}}{(2n)!}$$ How are these two $\cos(x)$ MacLaurin series equal? What makes the second one more correct than the series I got by taking the derivative of the $\sin(x)$ series. A sort of related question: if you choose to start at $n=1$ vs $n=0$ , how would you change the terms of the $\sin(x)$ Maclaurin series?","I understand how to find the MacLaurin series for . Now I am trying to find the MacLaurin series for by taking the derivative of the above sum with respect to . Using power rule, I got the following series: However, the MacLaurin series is: How are these two MacLaurin series equal? What makes the second one more correct than the series I got by taking the derivative of the series. A sort of related question: if you choose to start at vs , how would you change the terms of the Maclaurin series?",\sin(x) \sum_{n=1}^\infty \frac{x^{2n-1}\cdot\!(-1)^{n-1}}{(2n-1)!} \cos(x) x \cos(x) = \sum_{n=1}^\infty \frac{x^{2n-2}\cdot\!\mathrm{(-1)}^{n-1}}{(2n-2)!} \cos(x) = \sum_{n=0}^\infty \frac{x^{2n}\cdot\!\mathrm{(-1)}^{n}}{(2n)!} \cos(x) \sin(x) n=1 n=0 \sin(x),"['derivatives', 'power-series', 'taylor-expansion']"
15,Can $f^{(\infty)}(a)=0$ for almost all $a$?,Can  for almost all ?,f^{(\infty)}(a)=0 a,"My question is: Does there exist an infinitely differentiable function $f$ such that $$\lim_{n\to\infty} f^{(n)}(a)=0\qquad{\text{for almost all } a\in[0,\infty)}$$ ? ( $f$ cannot be a constant function or a polynomial.) If we restrict us to $C^{\omega}$ (i.e. assuming $f$ is holomorphic), it is likely that the answer is no, since $$f^{(n)}(a)=\frac{n!}{2\pi i}\oint_{\gamma}\frac{f(z)}{(z-a)^{n+1}}dz$$ the integrand only decays exponentially in $n$ while there is a $n!$ factor there. However, I am not quite sure if the above argument is correct. For smooth functions, I have no ideas. Any help will be appreciated. Thanks in advance.","My question is: Does there exist an infinitely differentiable function such that ? ( cannot be a constant function or a polynomial.) If we restrict us to (i.e. assuming is holomorphic), it is likely that the answer is no, since the integrand only decays exponentially in while there is a factor there. However, I am not quite sure if the above argument is correct. For smooth functions, I have no ideas. Any help will be appreciated. Thanks in advance.","f \lim_{n\to\infty} f^{(n)}(a)=0\qquad{\text{for almost all } a\in[0,\infty)} f C^{\omega} f f^{(n)}(a)=\frac{n!}{2\pi i}\oint_{\gamma}\frac{f(z)}{(z-a)^{n+1}}dz n n!","['real-analysis', 'complex-analysis', 'derivatives']"
16,On differentiating $F(x)=\ln(2x)$,On differentiating,F(x)=\ln(2x),"If we differentiate $F(x)=\ln(2x)$ we will get $F'(x) =\dfrac2{2x}$ after the shortcut $F'(x)=\dfrac1x$ , right? Now if we integrate $F'(x)$ we will get $F(x)=\ln(x)$ but also $F(x)=\ln(2x)$ . This means $\ln(2x)=\ln(x)$ . What happened?","If we differentiate we will get after the shortcut , right? Now if we integrate we will get but also . This means . What happened?",F(x)=\ln(2x) F'(x) =\dfrac2{2x} F'(x)=\dfrac1x F'(x) F(x)=\ln(x) F(x)=\ln(2x) \ln(2x)=\ln(x),"['calculus', 'derivatives']"
17,"The absolute value function $|\cdot|$ is elementary, but not differentiable?","The absolute value function  is elementary, but not differentiable?",|\cdot|,"As usual, define the absolute value function $|\cdot|:\mathbb R \rightarrow \mathbb R$ by $$|x| = \left\{ \begin{array}{ll}       x & \text{for } x \geq 0,\\       -x & \text{for } x < 0.\\ \end{array} \right.$$ Observe that the absolute value function can also defined by: $$|x| = \sqrt {x^2}.$$ And so by ProofWiki's definition of elementary functions , the absolute value function is the composition of two elementary functions and is itself elementary. According to Wikipedia , the set of elementary functions ""is also closed under differentiation"". I believe this implies the claim that every elementary function is differentiable. But I know that the absolute value function isn't. What is the flaw/error in the above argument? Addendum: I also found in Edwards and Larson ( Calculus , 2018 ) the claim that ""you can differentiate any elementary function"".","As usual, define the absolute value function by Observe that the absolute value function can also defined by: And so by ProofWiki's definition of elementary functions , the absolute value function is the composition of two elementary functions and is itself elementary. According to Wikipedia , the set of elementary functions ""is also closed under differentiation"". I believe this implies the claim that every elementary function is differentiable. But I know that the absolute value function isn't. What is the flaw/error in the above argument? Addendum: I also found in Edwards and Larson ( Calculus , 2018 ) the claim that ""you can differentiate any elementary function"".","|\cdot|:\mathbb R \rightarrow \mathbb R |x| = \left\{
\begin{array}{ll}
      x & \text{for } x \geq 0,\\
      -x & \text{for } x < 0.\\
\end{array} \right. |x| = \sqrt {x^2}.",['derivatives']
18,Basic proof that $\frac{d}{dx}(\sin(nx))=n\cos(nx)$,Basic proof that,\frac{d}{dx}(\sin(nx))=n\cos(nx),"Could someone provide a basic proof that $\frac{d}{dx}(\sin(nx))=n\cos(nx)$ ? I'm using $n$ to be broad, and so this can be searched easier, though if it's easier to provide an example, then replace $n$ with $3$ . My teacher has just taught us the Chain Rule, and he showed us an example like this: $$f(x)=(\sin(3x))^3$$ $$f'(x)=3(\sin(3x))^2(\cos(3x))(3)$$ $$f'(x)=9\sin^2(3x)\cos(3x)$$ I understand that the derivative of $\sin(x)$ is $\cos(x)$ and I understand that the derivative of $3x$ is $3$ , but I just don't see how this makes sense, because it feels like you're taking the derivative of $\sin(3x)$ which as far as I can tell should be $\cos(3x)$ , so where did the 3 come from? I was told that the 3 was taken as the derivative of the 3x inside the $\cos$ ... but why? Isn't the $\cos(3x)$ already differentiated? My teacher made a few different attempts to explain this to me, and I just don't get it, this is why I've asked for a proof. Now, I ask for a basic proof, because I don't want one of these super textbook like answers. Feel free to cut corners like not always putting $f(x)$ in front of each line or something like that, I just want to wrap my head around this concept! Oh and, I've already graphed $\sin(3x)$ and $3\cos(3x)$ , which so far is the only way I was able to actually see that, that is indeed the derivative.","Could someone provide a basic proof that ? I'm using to be broad, and so this can be searched easier, though if it's easier to provide an example, then replace with . My teacher has just taught us the Chain Rule, and he showed us an example like this: I understand that the derivative of is and I understand that the derivative of is , but I just don't see how this makes sense, because it feels like you're taking the derivative of which as far as I can tell should be , so where did the 3 come from? I was told that the 3 was taken as the derivative of the 3x inside the ... but why? Isn't the already differentiated? My teacher made a few different attempts to explain this to me, and I just don't get it, this is why I've asked for a proof. Now, I ask for a basic proof, because I don't want one of these super textbook like answers. Feel free to cut corners like not always putting in front of each line or something like that, I just want to wrap my head around this concept! Oh and, I've already graphed and , which so far is the only way I was able to actually see that, that is indeed the derivative.",\frac{d}{dx}(\sin(nx))=n\cos(nx) n n 3 f(x)=(\sin(3x))^3 f'(x)=3(\sin(3x))^2(\cos(3x))(3) f'(x)=9\sin^2(3x)\cos(3x) \sin(x) \cos(x) 3x 3 \sin(3x) \cos(3x) \cos \cos(3x) f(x) \sin(3x) 3\cos(3x),"['calculus', 'trigonometry', 'derivatives', 'chain-rule']"
19,How do I evaluate the following derivative?,How do I evaluate the following derivative?,,"How can I evaluate the derivative $$\left. \frac{d}{dx} \left( x \, \ln(x^5) \right)\right|_{x=1} \, ?$$ I have this math problem, and the biggest thing I do not understand, is which derivative rule do I need to apply, and what does the vertical bar mean in this problem? Solution $$\left. \frac{d}{dx} \left( x \, \ln(x^5) \right)\right|_{x=1} = 5.$$","How can I evaluate the derivative I have this math problem, and the biggest thing I do not understand, is which derivative rule do I need to apply, and what does the vertical bar mean in this problem? Solution","\left. \frac{d}{dx} \left( x \, \ln(x^5) \right)\right|_{x=1} \, ? \left. \frac{d}{dx} \left( x \, \ln(x^5) \right)\right|_{x=1} = 5.","['calculus', 'derivatives']"
20,Reconcile the chain rule with a derivative formula,Reconcile the chain rule with a derivative formula,,"I know the chain rule is like this:  $f(g(x)) = f'(g(x))g'(x)$. However, I encountered a derivative with which I cannot reconcile the statement above. Let $F$ be a function of $x$ and $z$, and $z$ is a function of $x$. Then by the chain rule: $$\frac{dF}{dx} = \frac{\partial{F}}{\partial{x}} + \frac{\partial{F}}{\partial{z}}\frac{\partial{z}}{\partial{x}}$$ I'm not sure how the equation is derived. The second part of the left hand side $\frac{\partial{F}}{\partial{z}}\frac{\partial{z}}{\partial{x}}$ looks similar to the chain rule. I'm not sure where $\frac{\partial{F}}{\partial{x}}$ came from.","I know the chain rule is like this:  $f(g(x)) = f'(g(x))g'(x)$. However, I encountered a derivative with which I cannot reconcile the statement above. Let $F$ be a function of $x$ and $z$, and $z$ is a function of $x$. Then by the chain rule: $$\frac{dF}{dx} = \frac{\partial{F}}{\partial{x}} + \frac{\partial{F}}{\partial{z}}\frac{\partial{z}}{\partial{x}}$$ I'm not sure how the equation is derived. The second part of the left hand side $\frac{\partial{F}}{\partial{z}}\frac{\partial{z}}{\partial{x}}$ looks similar to the chain rule. I'm not sure where $\frac{\partial{F}}{\partial{x}}$ came from.",,"['derivatives', 'partial-derivative', 'chain-rule']"
21,If $ f(x)= \int_0^x x^2\sin(t^2)dt$ then $f'(x)= ?$,If  then, f(x)= \int_0^x x^2\sin(t^2)dt f'(x)= ?,"Since the integral doesn't depend on $x$, I take $x^2$ out of the integral and take the derivative of a constant times a function. The final result is $x^2\sin(x^2)$. I saw one suggested answer which gives a different answer: $x^2\sin(x^2)+2xf(x)$, which is the derivative using the product rule. Which one is correct? Please explain, thanks.","Since the integral doesn't depend on $x$, I take $x^2$ out of the integral and take the derivative of a constant times a function. The final result is $x^2\sin(x^2)$. I saw one suggested answer which gives a different answer: $x^2\sin(x^2)+2xf(x)$, which is the derivative using the product rule. Which one is correct? Please explain, thanks.",,['calculus']
22,"Taking the derivative of $x^4\sin(x)\cos(x)$, which step is wrong?","Taking the derivative of , which step is wrong?",x^4\sin(x)\cos(x),"I'm trying to take the derivative of $x^4\sin(x)\cos(x)$ and I keep getting the wrong answer. My steps: $$\frac {d}{dx}[x^4\sin(x)\cos(x)]$$ Apply product rule: $$\frac {d}{dx}[x^4](\sin(x)\cos(x)+x^4\frac {d}{dx}[\sin(x)\cos(x)]$$ Simplify first part: $$4x^3\sin(x)\cos(x)+x^4\frac {d}{dx}[\sin(x)\cos(x)]$$ Apply product rule to second part: $$\cos(x)\cos(x)+(-\sin(x))$$ Add them all together: $$4x^3\sin(x)\cos(x)+x^4\cos^2(x)-\sin(x)$$ So something is wrong as the correct answer is $$-x^4\sin^2(x)+x^4\cos^2(x)+4x^3\cos(x)\sin(x)$$ Got the biggest headache from this one, would really appreciate help! Thanks!","I'm trying to take the derivative of $x^4\sin(x)\cos(x)$ and I keep getting the wrong answer. My steps: $$\frac {d}{dx}[x^4\sin(x)\cos(x)]$$ Apply product rule: $$\frac {d}{dx}[x^4](\sin(x)\cos(x)+x^4\frac {d}{dx}[\sin(x)\cos(x)]$$ Simplify first part: $$4x^3\sin(x)\cos(x)+x^4\frac {d}{dx}[\sin(x)\cos(x)]$$ Apply product rule to second part: $$\cos(x)\cos(x)+(-\sin(x))$$ Add them all together: $$4x^3\sin(x)\cos(x)+x^4\cos^2(x)-\sin(x)$$ So something is wrong as the correct answer is $$-x^4\sin^2(x)+x^4\cos^2(x)+4x^3\cos(x)\sin(x)$$ Got the biggest headache from this one, would really appreciate help! Thanks!",,"['calculus', 'derivatives']"
23,Derivative of $(Ax) \otimes y$ with respect to $x$,Derivative of  with respect to,(Ax) \otimes y x,"Suppose $A$ is an $ n \times n$ matrix and suppose that $x,\, k$ are  $n \times 1$ vectors. Also suppose that $k$ is a constant vector. let $$ y : = \left( Ax \right) \otimes k $$ Note that by $\otimes$ in this context we mean the outer product of two vectors given as $v\otimes u = vu^\top$. I would like to find $\frac{\partial y}{\partial x}$. By this symbol I mean to find the derivative of each entry of $y$ with respect to each entry of $x$. I know that, $$ \mathrm{d}(x \otimes y) = (\mathrm{d}x)\otimes y + x \otimes (\mathrm{d}y) $$ Therefore (at least formally) we would have \begin{align} \frac{\partial y}{\partial x} = A \otimes k \label{A} \end{align} But then what I don't understand is (if the way I have found the derivative is correct) what is meant by $A \otimes k$?. Does it mean the Kronecker product of $A$ and $k$ in the usual sense? Can someone please clarify?. Better yet, how does one find this derivative? EDIT $Ax k^\top$ is an $n \times n$ matrix.","Suppose $A$ is an $ n \times n$ matrix and suppose that $x,\, k$ are  $n \times 1$ vectors. Also suppose that $k$ is a constant vector. let $$ y : = \left( Ax \right) \otimes k $$ Note that by $\otimes$ in this context we mean the outer product of two vectors given as $v\otimes u = vu^\top$. I would like to find $\frac{\partial y}{\partial x}$. By this symbol I mean to find the derivative of each entry of $y$ with respect to each entry of $x$. I know that, $$ \mathrm{d}(x \otimes y) = (\mathrm{d}x)\otimes y + x \otimes (\mathrm{d}y) $$ Therefore (at least formally) we would have \begin{align} \frac{\partial y}{\partial x} = A \otimes k \label{A} \end{align} But then what I don't understand is (if the way I have found the derivative is correct) what is meant by $A \otimes k$?. Does it mean the Kronecker product of $A$ and $k$ in the usual sense? Can someone please clarify?. Better yet, how does one find this derivative? EDIT $Ax k^\top$ is an $n \times n$ matrix.",,"['matrices', 'derivatives', 'kronecker-product']"
24,Why is $\frac{dx}{dy} \neq \frac{1}{\frac{dy}{dx}}$?,Why is ?,\frac{dx}{dy} \neq \frac{1}{\frac{dy}{dx}},"Suppose I have a function $y=\sqrt{x}$. Then $\frac{dy}{dx}=\frac{\sqrt{x}}{2}$. Now if I rewrite the function in terms of y then it becomes $x=y^2$ and $\frac{dx}{dy}=2y$. Clearly $\frac{dx}{dy} \neq \frac{1}{\frac{dy}{dx}}$, but why is that the case? I'm confused because we have frequently used $\frac{dx}{dy}= \frac{1}{\frac{dy}{dx}}$ in rate of change questions, and I've never been taught that that's not the case.","Suppose I have a function $y=\sqrt{x}$. Then $\frac{dy}{dx}=\frac{\sqrt{x}}{2}$. Now if I rewrite the function in terms of y then it becomes $x=y^2$ and $\frac{dx}{dy}=2y$. Clearly $\frac{dx}{dy} \neq \frac{1}{\frac{dy}{dx}}$, but why is that the case? I'm confused because we have frequently used $\frac{dx}{dy}= \frac{1}{\frac{dy}{dx}}$ in rate of change questions, and I've never been taught that that's not the case.",,"['calculus', 'derivatives']"
25,Why isn't the arc length of $\cos x$ equal to $\pm \sin x$?,Why isn't the arc length of  equal to ?,\cos x \pm \sin x,"The arc length of some function $f(x)$ is given by $$L=\int{\sqrt{1+f'\left(x\right)^2}}dx$$ Plugging $\cos x$ in for $f$ and using basic algebra, this simplifies as follows $$L=\int{\sqrt{1+\cos'\left(x\right)^2}}dx$$ $$L=\int{\sqrt{1-\sin\left(x\right)^2}}dx$$ $$L=\int{\sqrt{\cos\left(x\right)^2}}dx$$ $$L=\int{\pm\cos\left(x\right)}dx$$ $$L=\pm\sin x$$ Obviously this is wrong. The real answer involves elliptic integrals, but my question is, why does this approach give such an incorrect result? What am I overlooking?","The arc length of some function $f(x)$ is given by $$L=\int{\sqrt{1+f'\left(x\right)^2}}dx$$ Plugging $\cos x$ in for $f$ and using basic algebra, this simplifies as follows $$L=\int{\sqrt{1+\cos'\left(x\right)^2}}dx$$ $$L=\int{\sqrt{1-\sin\left(x\right)^2}}dx$$ $$L=\int{\sqrt{\cos\left(x\right)^2}}dx$$ $$L=\int{\pm\cos\left(x\right)}dx$$ $$L=\pm\sin x$$ Obviously this is wrong. The real answer involves elliptic integrals, but my question is, why does this approach give such an incorrect result? What am I overlooking?",,"['calculus', 'integration', 'trigonometry', 'derivatives', 'arc-length']"
26,Monotonicity of $f(x) =\sin(\ln(x))-\cos(\ln(x))$,Monotonicity of,f(x) =\sin(\ln(x))-\cos(\ln(x)),Find the interval in which $f(x) =\sin(\ln(x))-\cos(\ln(x))$ is increasing.  After differentiating we get $$f'(x) = \frac{\cos\left(\ln(x)\right)}{x} +\frac{\sin\left(\ln(x)\right)}{x}$$ Now how do we analyze this expression?,Find the interval in which $f(x) =\sin(\ln(x))-\cos(\ln(x))$ is increasing.  After differentiating we get $$f'(x) = \frac{\cos\left(\ln(x)\right)}{x} +\frac{\sin\left(\ln(x)\right)}{x}$$ Now how do we analyze this expression?,,['derivatives']
27,Evaluate $\lim_{ x\to \infty} \left( \tan^{-1}\left(\frac{1+x}{4+x}\right)-\frac{\pi}{4}\right)x$,Evaluate,\lim_{ x\to \infty} \left( \tan^{-1}\left(\frac{1+x}{4+x}\right)-\frac{\pi}{4}\right)x,Evaluate    $$\lim_{ x\to \infty} \left(  \tan^{-1}\left(\frac{1+x}{4+x}\right)-\frac{\pi}{4}\right)x$$ I assumed $x=\frac{1}{y}$ we get $$L=\lim_{y \to 0}\frac{\left(  \tan^{-1}\left(\frac{1+y}{1+4y}\right)-\frac{\pi}{4}\right)}{y}$$ using L'Hopital's rule we get $$L=\lim_{y \to 0} \frac{1}{1+\left(\frac{1+y}{1+4y}\right)^2} \times \frac{-3}{(1+4y)^2}$$ $$L=\lim_{y \to 0}\frac{-3}{(1+y)^2+(1+4y)^2}=\frac{-3}{2}$$ is this possible to do without Lhopita's rule,Evaluate    $$\lim_{ x\to \infty} \left(  \tan^{-1}\left(\frac{1+x}{4+x}\right)-\frac{\pi}{4}\right)x$$ I assumed $x=\frac{1}{y}$ we get $$L=\lim_{y \to 0}\frac{\left(  \tan^{-1}\left(\frac{1+y}{1+4y}\right)-\frac{\pi}{4}\right)}{y}$$ using L'Hopital's rule we get $$L=\lim_{y \to 0} \frac{1}{1+\left(\frac{1+y}{1+4y}\right)^2} \times \frac{-3}{(1+4y)^2}$$ $$L=\lim_{y \to 0}\frac{-3}{(1+y)^2+(1+4y)^2}=\frac{-3}{2}$$ is this possible to do without Lhopita's rule,,"['calculus', 'algebra-precalculus', 'limits', 'derivatives', 'limits-without-lhopital']"
28,MCQ The nth derivative of $f(x)=\frac{1+x}{1-x}$,MCQ The nth derivative of,f(x)=\frac{1+x}{1-x},Let $f(x)=\dfrac{1+x}{1-x}$ The nth derivative of f is equal to: $\dfrac{2n}{(1-x)^{n+1}} $ $\dfrac{2(n!)}{(1-x)^{2n}} $ $\dfrac{2(n!)}{(1-x)^{n+1}} $ by Leibniz formula $$ {\displaystyle \left( \dfrac{1+x}{1-x}\right)^{(n)}=\sum _{k=0}^{n}{\binom {n}{k}}\ (1+x)^{(k)}\ \left(\dfrac{1}{1-x}\right)^{(n-k)}}$$ using the hint $\dfrac{1+x}{1-x}=\dfrac{2-(1-x)}{1-x}=\dfrac2{1-x}-1$ and $\left(\dfrac{1}{x}\right)^{n}=\dfrac{(-1)^{n}n!}{x^{n+1}}$ so $${\displaystyle \left( \dfrac{1+x}{1-x} \right)^{(n)} = \left( \dfrac{2}{1-x}-1 \right)^{(n)}=2\dfrac{ (-1)^{n}n! }{ (1-x)^{n+1} }   }  $$ but this result isn't apear in any proposed answers what about the method of Lord Shark the Unknown tell me please this way holds for any mqc question contain find the n th derivative so it's suffice to check each answer in y case i will start with first let $f_n(x)=\dfrac{2n}{(1-x)^{n+1}}$ then $f_{n+1}(x)=\dfrac{2(n+1)}{(1-x)^{n+2}}$ do i have $f'_{n}=f_{n+1}$  let calculate $$ f'_n=\dfrac{-2n(n+1)}{(1-x)^{n+2}}\neq f_{n+1}$$ let $f_n(x)=\dfrac{2(n!)}{(1-x)^{2n}}$ then $f_{n+1}(x)=\dfrac{2((n+1)!)}{(1-x)^{2(n+1)}}$ do i have $f'_{n}=f_{n+1}$  let calculate $$ f'_n=\dfrac{-2(n!)(2n)}{(1-x)^{4n}}\neq f_{n+1}$$ let $f_n(x)=\dfrac{2(n!)}{(1-x)^{n+1}}$ then $f_{n+1}(x)=\dfrac{2((n+1)!)}{(1-x)^{n+2}}$ do i have $f'_{n}=f_{n+1}$  let calculate $$ f'_n=\dfrac{2(n!)(n+1)}{((1-x)^{n+1})^{2}}=\dfrac{2((n+1)!)}{(1-x)^{2n+2}}\neq f_{n+1}$$,Let $f(x)=\dfrac{1+x}{1-x}$ The nth derivative of f is equal to: $\dfrac{2n}{(1-x)^{n+1}} $ $\dfrac{2(n!)}{(1-x)^{2n}} $ $\dfrac{2(n!)}{(1-x)^{n+1}} $ by Leibniz formula $$ {\displaystyle \left( \dfrac{1+x}{1-x}\right)^{(n)}=\sum _{k=0}^{n}{\binom {n}{k}}\ (1+x)^{(k)}\ \left(\dfrac{1}{1-x}\right)^{(n-k)}}$$ using the hint $\dfrac{1+x}{1-x}=\dfrac{2-(1-x)}{1-x}=\dfrac2{1-x}-1$ and $\left(\dfrac{1}{x}\right)^{n}=\dfrac{(-1)^{n}n!}{x^{n+1}}$ so $${\displaystyle \left( \dfrac{1+x}{1-x} \right)^{(n)} = \left( \dfrac{2}{1-x}-1 \right)^{(n)}=2\dfrac{ (-1)^{n}n! }{ (1-x)^{n+1} }   }  $$ but this result isn't apear in any proposed answers what about the method of Lord Shark the Unknown tell me please this way holds for any mqc question contain find the n th derivative so it's suffice to check each answer in y case i will start with first let $f_n(x)=\dfrac{2n}{(1-x)^{n+1}}$ then $f_{n+1}(x)=\dfrac{2(n+1)}{(1-x)^{n+2}}$ do i have $f'_{n}=f_{n+1}$  let calculate $$ f'_n=\dfrac{-2n(n+1)}{(1-x)^{n+2}}\neq f_{n+1}$$ let $f_n(x)=\dfrac{2(n!)}{(1-x)^{2n}}$ then $f_{n+1}(x)=\dfrac{2((n+1)!)}{(1-x)^{2(n+1)}}$ do i have $f'_{n}=f_{n+1}$  let calculate $$ f'_n=\dfrac{-2(n!)(2n)}{(1-x)^{4n}}\neq f_{n+1}$$ let $f_n(x)=\dfrac{2(n!)}{(1-x)^{n+1}}$ then $f_{n+1}(x)=\dfrac{2((n+1)!)}{(1-x)^{n+2}}$ do i have $f'_{n}=f_{n+1}$  let calculate $$ f'_n=\dfrac{2(n!)(n+1)}{((1-x)^{n+1})^{2}}=\dfrac{2((n+1)!)}{(1-x)^{2n+2}}\neq f_{n+1}$$,,['derivatives']
29,"Proof that, for finite $a$, $\lim_{x\to a^-} f(x) = -\infty$ implies $\lim_{x\to a^-} f'(x) = -\infty$","Proof that, for finite ,  implies",a \lim_{x\to a^-} f(x) = -\infty \lim_{x\to a^-} f'(x) = -\infty,"So this is just a conjecture. It might be true as is, but it also might need some further conditions, as a clever manipulation of $\sin(1/x)$ or something could break it (I haven't found a counterexample, I guess that too is a conjecture). Intuitively, it makes sense: if a graph goes downward in a sort of vertical asymptote, then the line tangent to the graph will get closer and closer to vertical in the negative direction (that was less than eloquent, but I hope it was clear). I don't know how to prove the implication. There is very little to work with. I have tried manipulating $\lim_{x\to a^-} f'(x)$ using the limit definition of a derivative, but that gets us nowhere.","So this is just a conjecture. It might be true as is, but it also might need some further conditions, as a clever manipulation of $\sin(1/x)$ or something could break it (I haven't found a counterexample, I guess that too is a conjecture). Intuitively, it makes sense: if a graph goes downward in a sort of vertical asymptote, then the line tangent to the graph will get closer and closer to vertical in the negative direction (that was less than eloquent, but I hope it was clear). I don't know how to prove the implication. There is very little to work with. I have tried manipulating $\lim_{x\to a^-} f'(x)$ using the limit definition of a derivative, but that gets us nowhere.",,"['calculus', 'real-analysis', 'limits', 'derivatives']"
30,Confusing differentials problem - Electrical resistance $ R = \frac{k}{r^2} $ with $ dr = 5\% $,Confusing differentials problem - Electrical resistance  with, R = \frac{k}{r^2}   dr = 5\% ,"I am struggling with a confusing differentials' problem. It seems like there is a key piece of information missing: The problem: The electrical resistance $ R $ of a copper wire is given by $  R = \frac{k}{r^2} $ where $ k $ is a constant and $ r $ is the radius of the wire. Suppose that the radius has an error of $  \pm 5\% $, find the $\%$ error of $ R $. My solution: \begin{align*} R &= \frac{k}{r^2}\\ \frac{dR}{dr} &= k \cdot (-2) \cdot r^{-3} \quad \therefore \quad dR = \frac{-2k \cdot 0.05}{r^3} = \frac{-0.1k}{r^3}\\ \end{align*} So the percentage error is given by \begin{align*} E_\% = \frac{\frac{-0.1k}{r^3}}{\frac{k}{r^2}} = - \frac{0.1}{r} \end{align*} My question: Am I missing something? Should I have arrived in a real value (not a function of $ r $ )? Is there information missing on the problem? Thank you.","I am struggling with a confusing differentials' problem. It seems like there is a key piece of information missing: The problem: The electrical resistance $ R $ of a copper wire is given by $  R = \frac{k}{r^2} $ where $ k $ is a constant and $ r $ is the radius of the wire. Suppose that the radius has an error of $  \pm 5\% $, find the $\%$ error of $ R $. My solution: \begin{align*} R &= \frac{k}{r^2}\\ \frac{dR}{dr} &= k \cdot (-2) \cdot r^{-3} \quad \therefore \quad dR = \frac{-2k \cdot 0.05}{r^3} = \frac{-0.1k}{r^3}\\ \end{align*} So the percentage error is given by \begin{align*} E_\% = \frac{\frac{-0.1k}{r^3}}{\frac{k}{r^2}} = - \frac{0.1}{r} \end{align*} My question: Am I missing something? Should I have arrived in a real value (not a function of $ r $ )? Is there information missing on the problem? Thank you.",,"['calculus', 'derivatives', 'physics']"
31,Taylor series expansion of $\frac{(1- \cos x)}{x^2} $,Taylor series expansion of,\frac{(1- \cos x)}{x^2} ,"According to my calculations, the Taylor series expansion for $1- \cos x$ around $x=\pi$ is  $$2 - \frac{(x-\pi)^2}{2} + \frac{(x-\pi)^4}{24} - \frac{(x-\pi)^6}{720} + \frac{(x-\pi)^8}{40320} -\dotsb $$ In solving the Taylor series expansion of $\frac{(1- \cos x)}{x^2}$ around $x= \pi$, would it be the same if I'll just multiply $\frac{1}{x^2}$ to the series written above? If that's not possible, how can I solve the series expansion of the quotient of two functions without doing ridiculously long sessions of product rule differentiation?","According to my calculations, the Taylor series expansion for $1- \cos x$ around $x=\pi$ is  $$2 - \frac{(x-\pi)^2}{2} + \frac{(x-\pi)^4}{24} - \frac{(x-\pi)^6}{720} + \frac{(x-\pi)^8}{40320} -\dotsb $$ In solving the Taylor series expansion of $\frac{(1- \cos x)}{x^2}$ around $x= \pi$, would it be the same if I'll just multiply $\frac{1}{x^2}$ to the series written above? If that's not possible, how can I solve the series expansion of the quotient of two functions without doing ridiculously long sessions of product rule differentiation?",,"['calculus', 'derivatives', 'taylor-expansion']"
32,Find stationary point of $y = \frac {e^{2x}} {4 + e^{3x}}$,Find stationary point of,y = \frac {e^{2x}} {4 + e^{3x}},"The curve with equation $y = \frac {e^{2x}} {4 + e^{3x}}$ has one stationary point. Find the exact values of the coordinates of this point. I got to the point where this is my $\frac {dy} {dx}$:$$\frac{ (4 + e^{3x}) (2e{^{2x}})-e^{2x}(3e^{3x})}{(4+e^{3x})^2} = 0$$ Is this correct to find the stationary points, if it is, how do I get $x $ from this equation?","The curve with equation $y = \frac {e^{2x}} {4 + e^{3x}}$ has one stationary point. Find the exact values of the coordinates of this point. I got to the point where this is my $\frac {dy} {dx}$:$$\frac{ (4 + e^{3x}) (2e{^{2x}})-e^{2x}(3e^{3x})}{(4+e^{3x})^2} = 0$$ Is this correct to find the stationary points, if it is, how do I get $x $ from this equation?",,['derivatives']
33,Why Rolle's theorem gives me wrong answer?,Why Rolle's theorem gives me wrong answer?,,"Find number of zeroes of $f(x) = 1 - x^{-2}$. I assume that this function has two or more zeroes in the domain $ \mathbb{R} - \{0\}$. Since $f^\prime (x) = \large{2\over x^3}$, therefore we can say      $f^\prime(x) \ne 0$ for all $x \in   \mathbb{R} - \{0\}$. Therefore by Rolle's theorem we can say that our assumption is wrong (because if it was correct then for any two zeroes $a,b\in\mathbb{R} - \{0\}$, $f^\prime(c) = 0$ where $c \in [a, b]$)  and  $f(x)$ has one zero at most in $\mathbb{R} - \{0\}$. What we deduced is incorrect given the fact that $f(\pm 1) = 0$ and $\{\pm 1\} \in \mathbb{R} - \{0\}$. Here I followed a similar proof . What is the error in my proof ?","Find number of zeroes of $f(x) = 1 - x^{-2}$. I assume that this function has two or more zeroes in the domain $ \mathbb{R} - \{0\}$. Since $f^\prime (x) = \large{2\over x^3}$, therefore we can say      $f^\prime(x) \ne 0$ for all $x \in   \mathbb{R} - \{0\}$. Therefore by Rolle's theorem we can say that our assumption is wrong (because if it was correct then for any two zeroes $a,b\in\mathbb{R} - \{0\}$, $f^\prime(c) = 0$ where $c \in [a, b]$)  and  $f(x)$ has one zero at most in $\mathbb{R} - \{0\}$. What we deduced is incorrect given the fact that $f(\pm 1) = 0$ and $\{\pm 1\} \in \mathbb{R} - \{0\}$. Here I followed a similar proof . What is the error in my proof ?",,"['calculus', 'real-analysis']"
34,Prove that $f(x)=-\exp(-g(x))$ is convex if $g(x)$ is convex...,Prove that  is convex if  is convex...,f(x)=-\exp(-g(x)) g(x),"Show that the following function $f:\Re^{n}\rightarrow \Re$ is convex. \begin{equation} f(x)=-\exp(-g(x)) \end{equation} where $g:\Re^{n}\rightarrow \Re$ is a twice differentiable function with convex domain and satisfies \begin{eqnarray*} \left( \begin{array}{cc} \nabla^{2} g & \nabla g  \\ \nabla^{T} g & 1 \\ \end{array} \right)\geq 0 \;(semidefinite\; positive\; matrix) \end{eqnarray*} for $x\in Dom$ $g$.\ My idea to prove that is to show that the Hessian of $f$ is a semidefinite positive matrix. So, I computed the Hessian of $f$ \begin{eqnarray*} \nabla^{2}f(x)&=&-\exp(-g(x))\left( \begin{array}{cccc} g_{x_{1}}^{2}-g_{x_{1}x_{1}} & g_{x_{2}}g_{x_{1}}-g_{x_{2}x_{1}} & \ldots & g_{x_{n}}g_{x_{1}}-g_{x_{n}x_{1}}  \\ g_{x_{2}}g_{x_{1}}-g_{x_{2}x_{1}} & g_{x_{2}}^{2}-g_{x_{2}x_{2}} & \ldots & g_{x_{n}}g_{x_{2}}-g_{x_{n}x_{2}}  \\ \vdots & \vdots & \ddots & \vdots \\ g_{x_{n}}g_{x_{1}}-g_{x_{n}x_{1}} & g_{x_{2}}g_{x_{n}}-g_{x_{2}x_{n}} & \ldots & g_{x_{n}}^{2}-g_{x_{n}x_{n}} \end{array} \right)\\ &=&\exp(-g(x))\left( \nabla^{2}g-\nabla g \nabla^{T}g\right) . \end{eqnarray*} Until now I havent been able to use the hipotesis to prove what I want, just that $\nabla^{2}g$ is a semidefinite positive matrix. Also, I know that $\nabla g \nabla^{T}g$ is a semidefinite positive matrix (but I dont know if this result is useful). Thanks for the help.","Show that the following function $f:\Re^{n}\rightarrow \Re$ is convex. \begin{equation} f(x)=-\exp(-g(x)) \end{equation} where $g:\Re^{n}\rightarrow \Re$ is a twice differentiable function with convex domain and satisfies \begin{eqnarray*} \left( \begin{array}{cc} \nabla^{2} g & \nabla g  \\ \nabla^{T} g & 1 \\ \end{array} \right)\geq 0 \;(semidefinite\; positive\; matrix) \end{eqnarray*} for $x\in Dom$ $g$.\ My idea to prove that is to show that the Hessian of $f$ is a semidefinite positive matrix. So, I computed the Hessian of $f$ \begin{eqnarray*} \nabla^{2}f(x)&=&-\exp(-g(x))\left( \begin{array}{cccc} g_{x_{1}}^{2}-g_{x_{1}x_{1}} & g_{x_{2}}g_{x_{1}}-g_{x_{2}x_{1}} & \ldots & g_{x_{n}}g_{x_{1}}-g_{x_{n}x_{1}}  \\ g_{x_{2}}g_{x_{1}}-g_{x_{2}x_{1}} & g_{x_{2}}^{2}-g_{x_{2}x_{2}} & \ldots & g_{x_{n}}g_{x_{2}}-g_{x_{n}x_{2}}  \\ \vdots & \vdots & \ddots & \vdots \\ g_{x_{n}}g_{x_{1}}-g_{x_{n}x_{1}} & g_{x_{2}}g_{x_{n}}-g_{x_{2}x_{n}} & \ldots & g_{x_{n}}^{2}-g_{x_{n}x_{n}} \end{array} \right)\\ &=&\exp(-g(x))\left( \nabla^{2}g-\nabla g \nabla^{T}g\right) . \end{eqnarray*} Until now I havent been able to use the hipotesis to prove what I want, just that $\nabla^{2}g$ is a semidefinite positive matrix. Also, I know that $\nabla g \nabla^{T}g$ is a semidefinite positive matrix (but I dont know if this result is useful). Thanks for the help.",,"['calculus', 'derivatives', 'convex-analysis', 'convex-optimization', 'positive-semidefinite']"
35,"If $f:\mathbb{R}\to\mathbb{R}$ is continuous, differentiable at $0$, with $f(0)=1$, $f'(0)=1$, and $f(s+t)=f(s)f(t)$, how to show that $f(x)=e^x$?","If  is continuous, differentiable at , with , , and , how to show that ?",f:\mathbb{R}\to\mathbb{R} 0 f(0)=1 f'(0)=1 f(s+t)=f(s)f(t) f(x)=e^x,"Hi guys I wondered whether you could help me to prove the following, This is part of a longer exam question which I'm revising now. Also could you recommend any good books with proofs relating to calculus please. Suppose $f:\mathbb R \to \mathbb R$ is a continuous function such that: $f$ is differentiable at $0$ with $f(0) = 1$ and $f'(0)=1$ $f(s+t) = f(s)f(t) $ for all $s, t\in \mathbb R$ Prove that $f(x)>0$ for all $x\in \mathbb R$. Prove that $f$ is differentiable on $\mathbb R$ with $f'(x)=f(x)$ for $x\in \mathbb R$. Deduce that $f(x)e^{-x}$ is constant, and hence $f(x)=e^x$ Thank-you :)","Hi guys I wondered whether you could help me to prove the following, This is part of a longer exam question which I'm revising now. Also could you recommend any good books with proofs relating to calculus please. Suppose $f:\mathbb R \to \mathbb R$ is a continuous function such that: $f$ is differentiable at $0$ with $f(0) = 1$ and $f'(0)=1$ $f(s+t) = f(s)f(t) $ for all $s, t\in \mathbb R$ Prove that $f(x)>0$ for all $x\in \mathbb R$. Prove that $f$ is differentiable on $\mathbb R$ with $f'(x)=f(x)$ for $x\in \mathbb R$. Deduce that $f(x)e^{-x}$ is constant, and hence $f(x)=e^x$ Thank-you :)",,"['calculus', 'real-analysis', 'derivatives']"
36,"Show that, if $f ' (x) = 1$ then $f(x) = x + C$","Show that, if  then",f ' (x) = 1 f(x) = x + C,"Let $f : [a, b] \to \mathbb{R}$ be a continuous function that is differentiable on $(a, b)$ . Show that, if $f'(x) = 1$ for all $x \in (a, b)$ , then there exists a constant $C \in \mathbb{R}$ such that $f(x) = x + C$ for all $x ∈ (a, b)$ . Initially I was going to let $f(x)=y$ then integrate it like a differential equation but my teacher said that wasn't allowed. Could I prove that the differential of $f(x)= x + C$ is equal to 1 ? Any help would be very much appreciated.","Let be a continuous function that is differentiable on . Show that, if for all , then there exists a constant such that for all . Initially I was going to let then integrate it like a differential equation but my teacher said that wasn't allowed. Could I prove that the differential of is equal to 1 ? Any help would be very much appreciated.","f : [a, b] \to \mathbb{R} (a, b) f'(x) = 1 x \in (a, b) C \in \mathbb{R} f(x) = x + C x ∈ (a, b) f(x)=y f(x)= x + C","['calculus', 'derivatives', 'proof-writing']"
37,"Tangent Line, and Derivative","Tangent Line, and Derivative",,"I was given the function $f(x)=k\sqrt{x}$ , and a line $y=x+4$ .  I need to find a value for k such that the line is tangent to the graph.  I have attempted the problem by taking the derivative of the given function. Derivative $$f'(x)=\frac{k}{2\sqrt{x}}$$ Since the slope of the tangent line is $1$ , I set the derivative equal to $1$ and get: $$1=\frac{k}{2\sqrt{x}}$$ and then I get: $$2\sqrt{x}=k$$ I feel like I am on the right track, but I am clueless on how to find an x to ensure I find the right k.  What other process would be necessary to find k, assuming I am on the right track?","I was given the function , and a line .  I need to find a value for k such that the line is tangent to the graph.  I have attempted the problem by taking the derivative of the given function. Derivative Since the slope of the tangent line is , I set the derivative equal to and get: and then I get: I feel like I am on the right track, but I am clueless on how to find an x to ensure I find the right k.  What other process would be necessary to find k, assuming I am on the right track?",f(x)=k\sqrt{x} y=x+4 f'(x)=\frac{k}{2\sqrt{x}} 1 1 1=\frac{k}{2\sqrt{x}} 2\sqrt{x}=k,"['calculus', 'derivatives']"
38,"Dual number $(a+b\varepsilon)$ raised to a dual power, e.g. $(a+b\varepsilon)^{(c+d\varepsilon)}$","Dual number  raised to a dual power, e.g.",(a+b\varepsilon) (a+b\varepsilon)^{(c+d\varepsilon)},"I'm working on some code which utilizes Newton's method, and I would like to take advantage of dual numbers to simplify taking the derivative. I've worked out a class definition Dual which works great for polynomials, pow (where either base or exponent is real) exp , and log . However, I am a bit stymied at raising a dual number to the power of another dual number, e.g. $(a+b\varepsilon)^{(c+d\varepsilon)}$ I used the general form derived from the Taylor series $f(a+b\varepsilon) = f(a) + bf'(a)\varepsilon$ to derive the rules for $x^n$ and $n^x$ where $n$ is real and $x$ is dual. For those, I got: $x^n = a^n + bna^{n-1}$ , where $ x = a+b\varepsilon$ $n^y = n^c + d\ln(n)n^{c}$ , where $  y = c+d\varepsilon$ Substituting and simplifying, I end up with: $x^y = a^c + (d\ln(a)a^c + bca^{c-1})\varepsilon$ This seems to work right in my code, but I do not know if this is actually correct. The implementations of exp and pow work properly with this more general code, and $\varepsilon^\varepsilon = 1 + NaN\varepsilon$, which is a good-ish sign (if I got something well-formed, that would be more troubling). Is this formula valid?","I'm working on some code which utilizes Newton's method, and I would like to take advantage of dual numbers to simplify taking the derivative. I've worked out a class definition Dual which works great for polynomials, pow (where either base or exponent is real) exp , and log . However, I am a bit stymied at raising a dual number to the power of another dual number, e.g. $(a+b\varepsilon)^{(c+d\varepsilon)}$ I used the general form derived from the Taylor series $f(a+b\varepsilon) = f(a) + bf'(a)\varepsilon$ to derive the rules for $x^n$ and $n^x$ where $n$ is real and $x$ is dual. For those, I got: $x^n = a^n + bna^{n-1}$ , where $ x = a+b\varepsilon$ $n^y = n^c + d\ln(n)n^{c}$ , where $  y = c+d\varepsilon$ Substituting and simplifying, I end up with: $x^y = a^c + (d\ln(a)a^c + bca^{c-1})\varepsilon$ This seems to work right in my code, but I do not know if this is actually correct. The implementations of exp and pow work properly with this more general code, and $\varepsilon^\varepsilon = 1 + NaN\varepsilon$, which is a good-ish sign (if I got something well-formed, that would be more troubling). Is this formula valid?",,"['derivatives', 'nilpotence', 'hypercomplex-numbers']"
39,Antiderrivative of ${d^2 y \over dx^2} = 1-x^2$,Antiderrivative of,{d^2 y \over dx^2} = 1-x^2,"At any point $(x,y)$ on a curve, ${d^2 y \over dx^2} = 1-x^2$, and an equation of the tangent line to the curve at the point $(1,1)$ is $y=2-x$. Find an equation of the curve. This is what I've done $${d^2 y \over dx^2} = 1-x^2 \\ \int dy' = \int (1-x^2)dx \\y' = x- {x^3 \over 3} +C \\ {dy\over dx}=x- {x^3 \over 3} +C \\\int dy =\int (x- {x^3 \over 3} +C)dx \\y= {x^2 \over 2}-{1\over 3} \cdot {x^4 \over 4}+c_1x + c_2 \\ y= {x^2 \over 2}-{x^4 \over 12}+c_1x +c_2$$ Do I now substitute (1,1) in this? I don't this is right. Someone help me. Thank you!","At any point $(x,y)$ on a curve, ${d^2 y \over dx^2} = 1-x^2$, and an equation of the tangent line to the curve at the point $(1,1)$ is $y=2-x$. Find an equation of the curve. This is what I've done $${d^2 y \over dx^2} = 1-x^2 \\ \int dy' = \int (1-x^2)dx \\y' = x- {x^3 \over 3} +C \\ {dy\over dx}=x- {x^3 \over 3} +C \\\int dy =\int (x- {x^3 \over 3} +C)dx \\y= {x^2 \over 2}-{1\over 3} \cdot {x^4 \over 4}+c_1x + c_2 \\ y= {x^2 \over 2}-{x^4 \over 12}+c_1x +c_2$$ Do I now substitute (1,1) in this? I don't this is right. Someone help me. Thank you!",,"['calculus', 'integration', 'derivatives', 'proof-verification']"
40,Applying the chain rule to compute $\frac{d}{dx}(\cos^6 x)$,Applying the chain rule to compute,\frac{d}{dx}(\cos^6 x),"$$\frac{d}{dx}(\cos^6x)$$ Using the chain rule $ M'(N(x)).N'(x)$, I'm deconstructing the $\cos$ function $$\begin{align*} &M= \cos^6 \\ &N= x\end{align*}$$ End result should be $$-6\sin^5x \cdot 1$$ or $$-6\sin^5x$$ Yet my book said the end result is $$-6\sin x \cos^ 5 x$$ Why?","$$\frac{d}{dx}(\cos^6x)$$ Using the chain rule $ M'(N(x)).N'(x)$, I'm deconstructing the $\cos$ function $$\begin{align*} &M= \cos^6 \\ &N= x\end{align*}$$ End result should be $$-6\sin^5x \cdot 1$$ or $$-6\sin^5x$$ Yet my book said the end result is $$-6\sin x \cos^ 5 x$$ Why?",,"['calculus', 'derivatives']"
41,If $g(x) = f(-x)$ then $g'(x) = -f'(-x)$,If  then,g(x) = f(-x) g'(x) = -f'(-x),"I am doing two exercises using Derivatives. Prove that if $f$ is even , then $f'(x) = -f(-x)$ Prove that if $f$ is odd, then $f'(x) = f'(-x)$. Now, I found the answer for the exercises, but there is a statement : if $g(x) = f(-x)$ then $g'(x) = -f'(-x)$. How can I prove that statement using the Derrivate's Definition. I tried it, but everytime I get $g'(x) = -f'(x)$ instead of $g'(x) = -f'(-x)$. Thanks","I am doing two exercises using Derivatives. Prove that if $f$ is even , then $f'(x) = -f(-x)$ Prove that if $f$ is odd, then $f'(x) = f'(-x)$. Now, I found the answer for the exercises, but there is a statement : if $g(x) = f(-x)$ then $g'(x) = -f'(-x)$. How can I prove that statement using the Derrivate's Definition. I tried it, but everytime I get $g'(x) = -f'(x)$ instead of $g'(x) = -f'(-x)$. Thanks",,"['calculus', 'derivatives']"
42,$f\to L$ and $f''$ bounded implies $f'\to 0$,and  bounded implies,f\to L f'' f'\to 0,"Let $f$ be a $C^\infty(\mathbb R,\mathbb R)$ function. I'm reading a proof where the author bluntly states the following: Since $\lim_{x\to \infty}f(x)=L$ and $f''$ is bounded, $\lim_{x\to \infty}f'(x)=0$ Since no proof is given, I'm assuming this is something basic, but I haven't found a proof. Consider two reals $x$ and $x_0$. From $\displaystyle f(x)=f(x_0)+f'(x_0)(x-x_0)+\int_{x_0}^x (x-t)f''(t) dt$ I derive $$|f'(x_0)|\leq \left|\frac{f(x)-f(x_0)}{x-x_0}\right|+ \sup \left|f''\right|\frac{|x-x_0|}2$$ If I let $x\to \infty$, the RHS goes to $\infty$ and the proof is ruined... If I choose $x$ close to $x_0$, the inequality looks like $$\sup \left|f''\right|\frac{|x-x_0|}2\geq 0$$ Not good...","Let $f$ be a $C^\infty(\mathbb R,\mathbb R)$ function. I'm reading a proof where the author bluntly states the following: Since $\lim_{x\to \infty}f(x)=L$ and $f''$ is bounded, $\lim_{x\to \infty}f'(x)=0$ Since no proof is given, I'm assuming this is something basic, but I haven't found a proof. Consider two reals $x$ and $x_0$. From $\displaystyle f(x)=f(x_0)+f'(x_0)(x-x_0)+\int_{x_0}^x (x-t)f''(t) dt$ I derive $$|f'(x_0)|\leq \left|\frac{f(x)-f(x_0)}{x-x_0}\right|+ \sup \left|f''\right|\frac{|x-x_0|}2$$ If I let $x\to \infty$, the RHS goes to $\infty$ and the proof is ruined... If I choose $x$ close to $x_0$, the inequality looks like $$\sup \left|f''\right|\frac{|x-x_0|}2\geq 0$$ Not good...",,"['real-analysis', 'derivatives']"
43,$xf'(x) = αf(x)$. How to prove that $f(x) = cx^\alpha$?,. How to prove that ?,xf'(x) = αf(x) f(x) = cx^\alpha,"Let $f$ be a differentiable function such that $xf'(x) = \alpha f(x)$ for all $x > 0$. How do I show that $f(x) = cx^\alpha$ for some constant $c$? I have $f'(x) = \alpha f(x)/x$ , and I can see that $\alpha$ is the original power and $x$ is the denominator to make the power $(\alpha-1)$, as usual in differentiation, but I don't know how to show this mathematically.","Let $f$ be a differentiable function such that $xf'(x) = \alpha f(x)$ for all $x > 0$. How do I show that $f(x) = cx^\alpha$ for some constant $c$? I have $f'(x) = \alpha f(x)/x$ , and I can see that $\alpha$ is the original power and $x$ is the denominator to make the power $(\alpha-1)$, as usual in differentiation, but I don't know how to show this mathematically.",,"['derivatives', 'proof-verification', 'proof-writing', 'proof-explanation']"
44,"Show there exists $\xi \in [a,b]$ such that $g(\xi)\int_a^\xi f(x)\text{d}x=f(\xi)\int_\xi^b g(x)\text{d}x$",Show there exists  such that,"\xi \in [a,b] g(\xi)\int_a^\xi f(x)\text{d}x=f(\xi)\int_\xi^b g(x)\text{d}x","Assume $f(x),g(x)$ is continuous on $[a,b]$. show that there exists $\xi \in [a,b]$, such that $$g(\xi)\int_a^\xi f(x)\text{d}x=f(\xi)\int_\xi^b g(x)\text{d}x$$ I tried to use intermediate value theorem to $F(t) = g(t)\int_a^t f(x)\text{d}x-f(t)\int_t^b g(x)\text{d}x$. but I failed to find two opposite values.","Assume $f(x),g(x)$ is continuous on $[a,b]$. show that there exists $\xi \in [a,b]$, such that $$g(\xi)\int_a^\xi f(x)\text{d}x=f(\xi)\int_\xi^b g(x)\text{d}x$$ I tried to use intermediate value theorem to $F(t) = g(t)\int_a^t f(x)\text{d}x-f(t)\int_t^b g(x)\text{d}x$. but I failed to find two opposite values.",,"['calculus', 'real-analysis', 'derivatives', 'definite-integrals']"
45,How do you find the equation of a tangent line to an equation: $\sin$ in it?,How do you find the equation of a tangent line to an equation:  in it?,\sin,"This is the question I need to answer, but I don't know how to. Find an equation of the tangent line to $y=10\sin(x)$ at $x=\pi$.","This is the question I need to answer, but I don't know how to. Find an equation of the tangent line to $y=10\sin(x)$ at $x=\pi$.",,"['calculus', 'derivatives']"
46,How to find the nth derivative for $\cos^3(x)$?,How to find the nth derivative for ?,\cos^3(x),"Could you please explain it so that I can find nth derivatives for other terms such as $\sin^3(x)$, $x^2e^{5x}$. Or also $x^2\sin(5x)$? Thanks in advance. I understand Leibniz's theorem but I am not being able to find the nth derivative for non standard functions. If there are any sites that you could refer to me or any excerpt from any textbook or sites that'd be great.","Could you please explain it so that I can find nth derivatives for other terms such as $\sin^3(x)$, $x^2e^{5x}$. Or also $x^2\sin(5x)$? Thanks in advance. I understand Leibniz's theorem but I am not being able to find the nth derivative for non standard functions. If there are any sites that you could refer to me or any excerpt from any textbook or sites that'd be great.",,"['calculus', 'trigonometry', 'derivatives']"
47,Calculating the $n^\text{th}$ derivative,Calculating the  derivative,n^\text{th},How do we calculate the $n^{\text{th}}$ derivative for $$ \frac{x^3}{(x-a)(x-b)(x-c)}? $$ How can I obtain the partial fraction for the given term?,How do we calculate the $n^{\text{th}}$ derivative for $$ \frac{x^3}{(x-a)(x-b)(x-c)}? $$ How can I obtain the partial fraction for the given term?,,"['calculus', 'derivatives', 'partial-fractions']"
48,Derivative of integral in interval,Derivative of integral in interval,,"Let $$F(x)=\int_{2}^{x^3}\frac{dt}{\ln t}$$ and $x$ is in $(2,3)$. Find $F'(x)$. Can somebody give me idea how to do this? Thank you","Let $$F(x)=\int_{2}^{x^3}\frac{dt}{\ln t}$$ and $x$ is in $(2,3)$. Find $F'(x)$. Can somebody give me idea how to do this? Thank you",,"['calculus', 'derivatives']"
49,Proving $\sin^2(x) + \cos^2(x) =1$ using calculus,Proving  using calculus,\sin^2(x) + \cos^2(x) =1,"Ok so the book in which I found this doesn't say mention the trigonometric functions by name but the question is: Let $s(x)$ and $c(x)$ be functions satisfying $s'(x)=c(x)$ and $c'(x)= -s(x)$ for all $x$. If $s(0)=0$ and $c(0)=1$, prove that $s^2(x) + c^2(x) =1$. I tried using integrals and derivatives but could only show that the derivative of  $s'(x)+c'(x)$ is $s(x) + c(x)$ but I think that was completely wrong way to think about it. I didn't read too well up on the mean value theorem and Rolle's theorem and perhaps the proof uses those theorems. Anyway could any one show me proof of this? Thanks.","Ok so the book in which I found this doesn't say mention the trigonometric functions by name but the question is: Let $s(x)$ and $c(x)$ be functions satisfying $s'(x)=c(x)$ and $c'(x)= -s(x)$ for all $x$. If $s(0)=0$ and $c(0)=1$, prove that $s^2(x) + c^2(x) =1$. I tried using integrals and derivatives but could only show that the derivative of  $s'(x)+c'(x)$ is $s(x) + c(x)$ but I think that was completely wrong way to think about it. I didn't read too well up on the mean value theorem and Rolle's theorem and perhaps the proof uses those theorems. Anyway could any one show me proof of this? Thanks.",,"['calculus', 'integration', 'derivatives', 'proof-verification']"
50,Tangent line parallel to another line,Tangent line parallel to another line,,At what point of the parabola $y=x^2-3x-5$ is the tangent line parallel to $3x-y=2$? Find its equation. I don't know what the slope of the tangent line will be. Is it the negative reciprocal?,At what point of the parabola $y=x^2-3x-5$ is the tangent line parallel to $3x-y=2$? Find its equation. I don't know what the slope of the tangent line will be. Is it the negative reciprocal?,,"['calculus', 'derivatives']"
51,Find a function $f(x)$ in an integral,Find a function  in an integral,f(x),"(Related question here ). Is there a way to calculate the function $f(x)$ in this integral in terms of $x$ without using $a,b,c$: $$\int_{a}^{b} f(x)dx=c$$ Two examples $\rightarrow$ how do find these functions $f(x)$: 1) How do find that $f(x)$ can be $x^2$?:$$\int_{0}^{1}f(x)dx=\frac{1}{3}\Longleftrightarrow f(x)=x^2$$ 2) How do find that $f(x)$ can be $\frac{x^4(1-x)^4}{1+x^2}$?:$$\int_{0}^{1}f(x)dx=\frac{22}{7}-\pi\Longleftrightarrow f(x)=\frac{x^4(1-x)^4}{1+x^2}$$","(Related question here ). Is there a way to calculate the function $f(x)$ in this integral in terms of $x$ without using $a,b,c$: $$\int_{a}^{b} f(x)dx=c$$ Two examples $\rightarrow$ how do find these functions $f(x)$: 1) How do find that $f(x)$ can be $x^2$?:$$\int_{0}^{1}f(x)dx=\frac{1}{3}\Longleftrightarrow f(x)=x^2$$ 2) How do find that $f(x)$ can be $\frac{x^4(1-x)^4}{1+x^2}$?:$$\int_{0}^{1}f(x)dx=\frac{22}{7}-\pi\Longleftrightarrow f(x)=\frac{x^4(1-x)^4}{1+x^2}$$",,"['calculus', 'real-analysis', 'integration', 'derivatives', 'pi']"
52,Differentiating the exponent power series,Differentiating the exponent power series,,"We know that $$ e^x = \sum\limits_{n=0}^{\infty}\frac{x^n}{n!} $$ We know that the series is uniformly convergent everywhere, and therefore we can differentiate term by term, i.e $$ \left(\sum\limits_{n=0}^{\infty}\frac{x^n}{n!}\right)' = \sum\limits_{n=0}^{\infty}\frac{nx^{n-1}}{n!} $$ But the above is equal to $e^x$. What will happen if I do this $n$ times? $$ (e^x)^{(n)} = \sum\limits_{n=0}^{\infty}1 $$ What is wrong here?","We know that $$ e^x = \sum\limits_{n=0}^{\infty}\frac{x^n}{n!} $$ We know that the series is uniformly convergent everywhere, and therefore we can differentiate term by term, i.e $$ \left(\sum\limits_{n=0}^{\infty}\frac{x^n}{n!}\right)' = \sum\limits_{n=0}^{\infty}\frac{nx^{n-1}}{n!} $$ But the above is equal to $e^x$. What will happen if I do this $n$ times? $$ (e^x)^{(n)} = \sum\limits_{n=0}^{\infty}1 $$ What is wrong here?",,"['calculus', 'derivatives', 'power-series']"
53,derivative integral $\int_0^{x^2} \sin(t^2)dt$,derivative integral,\int_0^{x^2} \sin(t^2)dt,I want to know how I derivative this integral: $$\int_0^{x^2} \sin(t^2)dt$$ what are the steps to derivative  it?,I want to know how I derivative this integral: $$\int_0^{x^2} \sin(t^2)dt$$ what are the steps to derivative  it?,,"['calculus', 'integration', 'derivatives']"
54,"for each $x>1 , \frac{x-1}{x}\ < \ln x < x-1$",for each,"x>1 , \frac{x-1}{x}\ < \ln x < x-1","I tried to prove this with differentiation: when $x >$ 1, all 3 functions are positive and when $x = 1$, all 3 reaches zero. And the derivatives are varying like $$\frac{\mathrm{d}(\frac{x-1}{x})}{\mathrm{d}x}\ < \frac{\mathrm{d}(\ln x)}{\mathrm{d}x}\ < \frac{\mathrm{d}(x-1)}{\mathrm{d}x}$$ Are they enough to say that above inequality is true?","I tried to prove this with differentiation: when $x >$ 1, all 3 functions are positive and when $x = 1$, all 3 reaches zero. And the derivatives are varying like $$\frac{\mathrm{d}(\frac{x-1}{x})}{\mathrm{d}x}\ < \frac{\mathrm{d}(\ln x)}{\mathrm{d}x}\ < \frac{\mathrm{d}(x-1)}{\mathrm{d}x}$$ Are they enough to say that above inequality is true?",,"['derivatives', 'implicit-differentiation']"
55,Solve for $\frac{dy}{dx}$?,Solve for ?,\frac{dy}{dx},"Q: Given $3^{x+y} = x^3 + 3y$, find $\frac{dy}{dx}$. I am convinced that, since it is not possible to algebraically solve for $y(x)$, one can't find $\frac{dy}{dx}$. Am I correct? Thanks!","Q: Given $3^{x+y} = x^3 + 3y$, find $\frac{dy}{dx}$. I am convinced that, since it is not possible to algebraically solve for $y(x)$, one can't find $\frac{dy}{dx}$. Am I correct? Thanks!",,"['calculus', 'derivatives', 'implicit-differentiation']"
56,How to determine $\lim_{h \to 0}\frac{g(h+1)-g(1)}{h}$,How to determine,\lim_{h \to 0}\frac{g(h+1)-g(1)}{h},It is given that $g(x) = x^{20}$ Determine $$\lim_{h \to 0} \frac{g(h+1)-g(1)}{h}$$ Can someone give me a hint please? I worked it out to be so far as: $$\lim_{h \to 0} \frac{(1+h)^{20}-1}{h}$$ The exponent of power $20$ is quite problematic. Any hints? Note : I have to do it using first principles.,It is given that $g(x) = x^{20}$ Determine $$\lim_{h \to 0} \frac{g(h+1)-g(1)}{h}$$ Can someone give me a hint please? I worked it out to be so far as: $$\lim_{h \to 0} \frac{(1+h)^{20}-1}{h}$$ The exponent of power $20$ is quite problematic. Any hints? Note : I have to do it using first principles.,,"['calculus', 'derivatives']"
57,How to differentiate $x^2-|x^3|$?,How to differentiate ?,x^2-|x^3|,How to differentiate $x^2-|x^3|$? I tried breaking it into a piecewise function but I've been told this is not necessary. How can I approach this in another way?,How to differentiate $x^2-|x^3|$? I tried breaking it into a piecewise function but I've been told this is not necessary. How can I approach this in another way?,,['derivatives']
58,Derivative with summation operator,Derivative with summation operator,,How do you take the derivative when there is a summation operator in this step.. $$\frac{d}{dt} \left[1-\sum_{n=0}^{k-1} \frac{(\lambda t)^n e^{-\lambda t}}{n!} \right] =  \lambda e^{-\lambda t} \left(\sum_0^{k-1}\frac{(\lambda t)^n}{n!} - \lambda \sum_{n=0}^{k-2} \frac{(\lambda t)^n}{n!}\right)$$,How do you take the derivative when there is a summation operator in this step.. $$\frac{d}{dt} \left[1-\sum_{n=0}^{k-1} \frac{(\lambda t)^n e^{-\lambda t}}{n!} \right] =  \lambda e^{-\lambda t} \left(\sum_0^{k-1}\frac{(\lambda t)^n}{n!} - \lambda \sum_{n=0}^{k-2} \frac{(\lambda t)^n}{n!}\right)$$,,['derivatives']
59,Fundamental Theorem of Calculus Proof,Fundamental Theorem of Calculus Proof,,"Find $f'$ where is $f$ is defined on $[0, 1]$ as indicated: $$f(x) = \int_x^{\sqrt{x}} \frac 1{1+t^3}dt$$ I know that the fundamental theorem is going to be used in this proof, but I'm not really sure where to begin. So any help would be greatly appreciated. Thank you!","Find $f'$ where is $f$ is defined on $[0, 1]$ as indicated: $$f(x) = \int_x^{\sqrt{x}} \frac 1{1+t^3}dt$$ I know that the fundamental theorem is going to be used in this proof, but I'm not really sure where to begin. So any help would be greatly appreciated. Thank you!",,"['real-analysis', 'integration', 'analysis', 'derivatives']"
60,Let $z = x^a y^b \ln(xy)$. Find $x \frac {dz} {dx} - y \frac {dz} {dy}$ in terms of $z$,Let . Find  in terms of,z = x^a y^b \ln(xy) x \frac {dz} {dx} - y \frac {dz} {dy} z,"I'm baffled by this question. I assume I'm meant to use the product rule to work out $\frac{dz}{dx}$ and $\frac{dz}{dy}$? But when I'm doing that I'm getting crazy answers that I know are wrong: $$\frac{dz}{dx} = b y^{b-1} x^a\ln(xy)+\frac{1}{xy}xx^ay^b$$ $$\frac{dz}{dy} = b y^{2b-2}yx^ay\ln(xy)+y^{2b}x^a$$ I'm not sure why, or where I'm going wrong, but I know that this is wrong. Please help. Thanks! Note, the d's are 'curly' d's for the partial derivative but I wasnt sure how to type them in","I'm baffled by this question. I assume I'm meant to use the product rule to work out $\frac{dz}{dx}$ and $\frac{dz}{dy}$? But when I'm doing that I'm getting crazy answers that I know are wrong: $$\frac{dz}{dx} = b y^{b-1} x^a\ln(xy)+\frac{1}{xy}xx^ay^b$$ $$\frac{dz}{dy} = b y^{2b-2}yx^ay\ln(xy)+y^{2b}x^a$$ I'm not sure why, or where I'm going wrong, but I know that this is wrong. Please help. Thanks! Note, the d's are 'curly' d's for the partial derivative but I wasnt sure how to type them in",,"['calculus', 'derivatives']"
61,differentiability of $\tan^{-1}(\frac{1}{|x|})$,differentiability of,\tan^{-1}(\frac{1}{|x|}),"How to justify, the following function is differentiable at origin or not? $f(x) = \tan^{-1}\frac{1}{|x|}$ if $x \ne 0$, $f(x) = \frac{\pi}{2}$ if $x = 0$. Even though mod x is not behaves well at the origin, since we are composing the mod x with the nice function $\tan^{-1}(x)$, I am guessing that above defined $f$ is differentiable at 0. But how to show that rigorously? I think my guess is correct. Thanks in Advance.","How to justify, the following function is differentiable at origin or not? $f(x) = \tan^{-1}\frac{1}{|x|}$ if $x \ne 0$, $f(x) = \frac{\pi}{2}$ if $x = 0$. Even though mod x is not behaves well at the origin, since we are composing the mod x with the nice function $\tan^{-1}(x)$, I am guessing that above defined $f$ is differentiable at 0. But how to show that rigorously? I think my guess is correct. Thanks in Advance.",,['derivatives']
62,"If $f$ is continuous on $[0,\infty)$ and differentiable on $(0,\infty)$ and if $lim_{x\to\infty}f'(x)=0$ Then $f$ uniformly continuous on $[0,\infty)$",If  is continuous on  and differentiable on  and if  Then  uniformly continuous on,"f [0,\infty) (0,\infty) lim_{x\to\infty}f'(x)=0 f [0,\infty)","I got this problem: Let $f$ be a continuous function on $[0,\infty)$ and differentiable function on $(0,\infty)$ such that $\lim_{x\to\infty}f'(x)=0$. (1) Prove that for each $0<\epsilon$ there exist $0<M$ such that if $x$ and $y$ are numbers that satisfy the inequality $M<y<x<y+1$, Then $|f(x)-f(y)|<\epsilon$. (2) Prove that $f$ is uniformly continuous on $[0,\infty)$ using (1). I managed to prove (1) (by using the mean value theorem for derivatives), But when I tried to prove (2) I got stuck. Any help on how to prove (2) by using (1) will be appreciated.","I got this problem: Let $f$ be a continuous function on $[0,\infty)$ and differentiable function on $(0,\infty)$ such that $\lim_{x\to\infty}f'(x)=0$. (1) Prove that for each $0<\epsilon$ there exist $0<M$ such that if $x$ and $y$ are numbers that satisfy the inequality $M<y<x<y+1$, Then $|f(x)-f(y)|<\epsilon$. (2) Prove that $f$ is uniformly continuous on $[0,\infty)$ using (1). I managed to prove (1) (by using the mean value theorem for derivatives), But when I tried to prove (2) I got stuck. Any help on how to prove (2) by using (1) will be appreciated.",,"['calculus', 'real-analysis', 'derivatives', 'continuity', 'uniform-continuity']"
63,Taylor Theorem inequality,Taylor Theorem inequality,,"Prove that for all $f\in C^2([0,1])$ with $f(0)=f(1)=0$ and $|f''(x)| \le 1$ $$|f(x)| \le \frac{1}{2}x(1-x)$$  $\forall  x \in [0,1]$.","Prove that for all $f\in C^2([0,1])$ with $f(0)=f(1)=0$ and $|f''(x)| \le 1$ $$|f(x)| \le \frac{1}{2}x(1-x)$$  $\forall  x \in [0,1]$.",,"['calculus', 'derivatives', 'taylor-expansion']"
64,Find the derivative of $\int_x^{x^2} e^{-t^2}dt $,Find the derivative of,\int_x^{x^2} e^{-t^2}dt ,"Hey guys this was given to me as an exercise question and its really confusing. I'm not really sure where to start with this one, and I am assuming that the derivative isn't just $e^{-t^2}  dt$. Anyways, any help is appreciated, thank you!. Find the derivative of $$\int \limits_x^{x^2} e^{-t^2}dt $$","Hey guys this was given to me as an exercise question and its really confusing. I'm not really sure where to start with this one, and I am assuming that the derivative isn't just $e^{-t^2}  dt$. Anyways, any help is appreciated, thank you!. Find the derivative of $$\int \limits_x^{x^2} e^{-t^2}dt $$",,"['calculus', 'real-analysis', 'integration', 'derivatives', 'definite-integrals']"
65,Why are derivatives lines?,Why are derivatives lines?,,"If you look at a function ""infinitely close"", the difference between two points is a line: __    __/  __/ Where each ""__"" is a point, and  ""/"" is the value of a derivative (assume the two ""/""s have different slopes). I have this intuition because a function can be approximated by a line at an infinitely close distance (i.e. ""Linear Approximations"") If you use the above graph of the function to graph the derivative, the derivative looks like this: _  _| So at an infinitely close distance the derivative looks like the second graph above. But now if you look at the derivative at an infinitely close distance, it looks the the first graph.  So how can the derivative look two different ways at an infinitely close distance? It looks like the first graph when you look at it directly at an infinitely close distance, but the second graph if you look at its antiderivative at an infinitely close distance and use that to plot it. I know this obviously isn't rigourous but what part of my intuition is wrong?","If you look at a function ""infinitely close"", the difference between two points is a line: __    __/  __/ Where each ""__"" is a point, and  ""/"" is the value of a derivative (assume the two ""/""s have different slopes). I have this intuition because a function can be approximated by a line at an infinitely close distance (i.e. ""Linear Approximations"") If you use the above graph of the function to graph the derivative, the derivative looks like this: _  _| So at an infinitely close distance the derivative looks like the second graph above. But now if you look at the derivative at an infinitely close distance, it looks the the first graph.  So how can the derivative look two different ways at an infinitely close distance? It looks like the first graph when you look at it directly at an infinitely close distance, but the second graph if you look at its antiderivative at an infinitely close distance and use that to plot it. I know this obviously isn't rigourous but what part of my intuition is wrong?",,"['calculus', 'integration', 'derivatives', 'intuition']"
66,The derivative of $\tanh x$,The derivative of,\tanh x,"I'm trying to calculate the derivative of $\displaystyle\tanh h = \frac{e^h-e^{-h}}{e^h+e^{-h}}$. Could someone verify if I got it right or not, if I forgot something etc. Here goes my try: $$\frac{d}{dh}\left( \frac{e^h - e^{-h}}{e^h + e^{-h}}\right) = \frac{d}{dh}\left( (e^h - e^{-h})\cdot(e^h + e^{-h})^{-1}\right) $$ $$= \frac{d}{dh}\left( e^h -e^{-h}\right)\cdot(e^h + e^{-h})^{-1} + (e^h -e^{-h})\cdot\frac{d}{dh}\left( (e^h + e^{-h})^{-1}\right) $$$$ = (e^h + e^{-h})\cdot(e^h + e^{-h})^{-1} - (e^h-e^{-h})\cdot\frac{e^h-e^{-h}}{(e^h+e^{-h})^2} $$$$= 1-\frac{(e^h-e^{-h})^2}{(e^h+e^{-h})^2} = 1-\frac{(e^{2h}-2 + e^{-2h})}{e^{2h} + 2+e^{-2h}} =  1+\frac{-e^{2h}+2 - e^{-2h}}{e^{2h} + 2+e^{-2h}}$$ Thnx for any help! :)","I'm trying to calculate the derivative of $\displaystyle\tanh h = \frac{e^h-e^{-h}}{e^h+e^{-h}}$. Could someone verify if I got it right or not, if I forgot something etc. Here goes my try: $$\frac{d}{dh}\left( \frac{e^h - e^{-h}}{e^h + e^{-h}}\right) = \frac{d}{dh}\left( (e^h - e^{-h})\cdot(e^h + e^{-h})^{-1}\right) $$ $$= \frac{d}{dh}\left( e^h -e^{-h}\right)\cdot(e^h + e^{-h})^{-1} + (e^h -e^{-h})\cdot\frac{d}{dh}\left( (e^h + e^{-h})^{-1}\right) $$$$ = (e^h + e^{-h})\cdot(e^h + e^{-h})^{-1} - (e^h-e^{-h})\cdot\frac{e^h-e^{-h}}{(e^h+e^{-h})^2} $$$$= 1-\frac{(e^h-e^{-h})^2}{(e^h+e^{-h})^2} = 1-\frac{(e^{2h}-2 + e^{-2h})}{e^{2h} + 2+e^{-2h}} =  1+\frac{-e^{2h}+2 - e^{-2h}}{e^{2h} + 2+e^{-2h}}$$ Thnx for any help! :)",,"['calculus', 'derivatives', 'hyperbolic-functions']"
67,$n$th derivative of $x^3(x-2x^{1/2})^2$,th derivative of,n x^3(x-2x^{1/2})^2,I don't know how to find the n th derivative of this equation because there are negative integer so I don't how to use factorial on it. I Try(?): $\left(f(x)g(x)\right)^{(n)}=\sum_{k=0}^n\binom nk f^{(k)}(x)\cdot g^{(n-k)}(x)$ Let $f(x) = x^4\ and \ g(x) = (\sqrt(x)-2)^2 )$ $( x^4(\sqrt(x)-2)^2)^{(n)}=\sum_{k=0}^n\frac{n!}{k!(n-k)!}\frac{4!}{(4-n)!}x^{(4-n)}\cdot \frac{(\sqrt(x)-2)^2\cdot2!}{(x-n+k)!}$ Is this?,I don't know how to find the n th derivative of this equation because there are negative integer so I don't how to use factorial on it. I Try(?): $\left(f(x)g(x)\right)^{(n)}=\sum_{k=0}^n\binom nk f^{(k)}(x)\cdot g^{(n-k)}(x)$ Let $f(x) = x^4\ and \ g(x) = (\sqrt(x)-2)^2 )$ $( x^4(\sqrt(x)-2)^2)^{(n)}=\sum_{k=0}^n\frac{n!}{k!(n-k)!}\frac{4!}{(4-n)!}x^{(4-n)}\cdot \frac{(\sqrt(x)-2)^2\cdot2!}{(x-n+k)!}$ Is this?,,"['calculus', 'derivatives']"
68,Second derivative criteria for maxima and minima.,Second derivative criteria for maxima and minima.,,Why is $\frac{d^2y}{dx^2} > 0$ for a minimum point and $\frac{d^2y}{dx^2} <0$ for a maximum? Also why does the second derivative not provide a reliable nature of the point of inflection? Sorry I searched around and couldn't find any results.,Why is for a minimum point and for a maximum? Also why does the second derivative not provide a reliable nature of the point of inflection? Sorry I searched around and couldn't find any results.,\frac{d^2y}{dx^2} > 0 \frac{d^2y}{dx^2} <0,"['real-analysis', 'calculus', 'derivatives', 'maxima-minima']"
69,Find the point on the graph of $y=e^{2x}$ at which the tangent line passes through the origin,Find the point on the graph of  at which the tangent line passes through the origin,y=e^{2x},"Find the point on the graph of $y=e^{2x}$ at which the tangent line passes through the origin. Completely lost on this question, the wording is confusing here.","Find the point on the graph of $y=e^{2x}$ at which the tangent line passes through the origin. Completely lost on this question, the wording is confusing here.",,"['calculus', 'derivatives', 'exponential-function']"
70,Using the alternative formula to find the derivative of a function?,Using the alternative formula to find the derivative of a function?,,"I'm attempting to find the derivative of the function: $$f(x) = 4x^2+3x+5$$ Using the alternative formula: $$\frac{f(z)-f(x)}{z-x}$$ Here are my steps so far: $$\frac{4z^2+3z+5-(4x^2+3x+5)}{z-x}$$ $$\frac{4(z^2-x^2)+3(z-x)}{z-x}$$ I have no idea where to go from this point. I've tried several different things to come up with the correct answer - which I know is $8x+3$. Can someone please guide me through this problem? I'm completely stuck. Also, sorry about the formatting. I'm using this editor http://www.codecogs.com/latex/eqneditor.php?lang=en-en and don't have it completely figured out yet.","I'm attempting to find the derivative of the function: $$f(x) = 4x^2+3x+5$$ Using the alternative formula: $$\frac{f(z)-f(x)}{z-x}$$ Here are my steps so far: $$\frac{4z^2+3z+5-(4x^2+3x+5)}{z-x}$$ $$\frac{4(z^2-x^2)+3(z-x)}{z-x}$$ I have no idea where to go from this point. I've tried several different things to come up with the correct answer - which I know is $8x+3$. Can someone please guide me through this problem? I'm completely stuck. Also, sorry about the formatting. I'm using this editor http://www.codecogs.com/latex/eqneditor.php?lang=en-en and don't have it completely figured out yet.",,"['calculus', 'derivatives']"
71,"If $f$ has graph satisfying $|y|=|x^2-x^3|$, at how many points must it be differentiable?","If  has graph satisfying , at how many points must it be differentiable?",f |y|=|x^2-x^3|,"I'm trying to do problem 2 here . Let $f(x)$ be a function defined for all real $x$ such that the coordinates of each point of its graph satisfy $|y|=|x^2-x^3|$ . The total number of points at which $f(x)$ must be differentiable is (A) none (B) $1$ (C) $2$ (D) $3$ (E) infinite The correct answer is B, but I'm completely stumped as to why that is. Is there an explanation for this answer?","I'm trying to do problem 2 here . Let be a function defined for all real such that the coordinates of each point of its graph satisfy . The total number of points at which must be differentiable is (A) none (B) (C) (D) (E) infinite The correct answer is B, but I'm completely stumped as to why that is. Is there an explanation for this answer?",f(x) x |y|=|x^2-x^3| f(x) 1 2 3,"['calculus', 'derivatives']"
72,Computing the derivative from the definition,Computing the derivative from the definition,,"Using the limit definition of the derivative which I know is: $$f'(x)=\lim_{h\to0}\left(\frac{f(x+h)-f(x)}{h}\right)$$ I am trying to solve this problem  $$f(x)= \frac{x}{x+2}   $$ How do I go about properly solving this, I seemed to get $$\frac{x}{x+2}\   $$   as my answer again? What are the steps I should follow? I am trying to find the derivative of $f(x)= \frac{x}{x+2}$ using the definition of the derivative.","Using the limit definition of the derivative which I know is: $$f'(x)=\lim_{h\to0}\left(\frac{f(x+h)-f(x)}{h}\right)$$ I am trying to solve this problem  $$f(x)= \frac{x}{x+2}   $$ How do I go about properly solving this, I seemed to get $$\frac{x}{x+2}\   $$   as my answer again? What are the steps I should follow? I am trying to find the derivative of $f(x)= \frac{x}{x+2}$ using the definition of the derivative.",,"['calculus', 'derivatives']"
73,Why is this limit said to equal some value rather than approach that value?,Why is this limit said to equal some value rather than approach that value?,,"I have rewritten this entire question, since what I've learned since asking it requires me to restate it.  I want to get rid of the obfuscating revisions. Let's say that f is a continuous function. $f(x)$ approaches L as x approaches a. So $\lim\limits_{x \to a}f(x) = L$ When it's said that the gradient of a tangent line to a curve at some particular point has some particular value, this is the same as saying f(a)=L.  But without explicitly evaluating at that point, you can't say as much.  All you can say is what happens as you approach that value.  In other words, you can only say what value $f(x)$ approaches as $x$ approaches $a$, you can't say what $f(a)$ is. Is that true? Some textbooks will just say that the value of $f(a)=L$.  Sal Khan's explanation does this.  He says, about the function as it approaches the limit, ""this is the gradient of the tangent.""  I'm saying that it should be said that, ""the derivative approaches the gradient of the tangent to the curve.""  I think ""approaches"" and ""is"" are very different. If there is a way to prove that the $f(a)=L$ then I'd like to see it.  I don't know how to do this yet.","I have rewritten this entire question, since what I've learned since asking it requires me to restate it.  I want to get rid of the obfuscating revisions. Let's say that f is a continuous function. $f(x)$ approaches L as x approaches a. So $\lim\limits_{x \to a}f(x) = L$ When it's said that the gradient of a tangent line to a curve at some particular point has some particular value, this is the same as saying f(a)=L.  But without explicitly evaluating at that point, you can't say as much.  All you can say is what happens as you approach that value.  In other words, you can only say what value $f(x)$ approaches as $x$ approaches $a$, you can't say what $f(a)$ is. Is that true? Some textbooks will just say that the value of $f(a)=L$.  Sal Khan's explanation does this.  He says, about the function as it approaches the limit, ""this is the gradient of the tangent.""  I'm saying that it should be said that, ""the derivative approaches the gradient of the tangent to the curve.""  I think ""approaches"" and ""is"" are very different. If there is a way to prove that the $f(a)=L$ then I'd like to see it.  I don't know how to do this yet.",,"['calculus', 'limits', 'derivatives']"
74,Evaluate: $\int_{-2}^{2} \frac{x^2}{1+5^{x}} dx$,Evaluate:,\int_{-2}^{2} \frac{x^2}{1+5^{x}} dx,"Evaluate: $$\int_{-2}^{2} \frac{x^2}{1+5^{x}} dx$$ After checking f(-x) for odd/even function and not getting suitable results. Let $$1+5^x=t$$ $$dx=\frac{dt}{log(5)(t-1)}$$ $$x^2=\frac{(t-1)^2}{(log(5))^2}$$ Limits changed from $[-2,2]$ to $[\frac{26}{25},26]$ $$\int_{\frac{26}{25}}^{26} \frac{(t-1)^2}{[(log(5))^2(t)(log(5)(t-1)]} dt$$ $$\frac{1}{(log(5))^3}\int_{\frac{26}{25}}^{26} \frac{t-1}{t} dt$$ This gave me some abomination that wasn't the answer I required which is 8/3. I now also know the intended solution as mentioned below: Let $$I=\int_{-2}^{2} \frac{x^2}{1+5^{x}} dx$$ Using Identity of f(a+b-x) from definite integrals: $$I=\int_{-2}^{2} \frac{(2-2-x)^2}{1+5^{(2-2-x)}} dx$$ $$I=\int_{-2}^{2} \frac{x^2}{1+5^{(-x)}} dx$$ $$I=\int_{-2}^{2} \frac{(5^x)x^2}{1+5^{x}} dx$$ $$2I=\int_{-2}^{2} \frac{x^2}{1+5^{x}}+\frac{(5^x)x^2}{1+5^{x}} dx$$ $$2I=\int_{-2}^{2} x^2 dx$$ $$I=\frac{1}{6}.[2^3-(-2^3)]=\frac{8}{3}$$ So why didn't my first approach work?",Evaluate: After checking f(-x) for odd/even function and not getting suitable results. Let Limits changed from to This gave me some abomination that wasn't the answer I required which is 8/3. I now also know the intended solution as mentioned below: Let Using Identity of f(a+b-x) from definite integrals: So why didn't my first approach work?,"\int_{-2}^{2} \frac{x^2}{1+5^{x}} dx 1+5^x=t dx=\frac{dt}{log(5)(t-1)} x^2=\frac{(t-1)^2}{(log(5))^2} [-2,2] [\frac{26}{25},26] \int_{\frac{26}{25}}^{26} \frac{(t-1)^2}{[(log(5))^2(t)(log(5)(t-1)]} dt \frac{1}{(log(5))^3}\int_{\frac{26}{25}}^{26} \frac{t-1}{t} dt I=\int_{-2}^{2} \frac{x^2}{1+5^{x}} dx I=\int_{-2}^{2} \frac{(2-2-x)^2}{1+5^{(2-2-x)}} dx I=\int_{-2}^{2} \frac{x^2}{1+5^{(-x)}} dx I=\int_{-2}^{2} \frac{(5^x)x^2}{1+5^{x}} dx 2I=\int_{-2}^{2} \frac{x^2}{1+5^{x}}+\frac{(5^x)x^2}{1+5^{x}} dx 2I=\int_{-2}^{2} x^2 dx I=\frac{1}{6}.[2^3-(-2^3)]=\frac{8}{3}","['calculus', 'integration', 'derivatives', 'definite-integrals', 'logarithms']"
75,What is this step?,What is this step?,,"Hello, I’m a first year engineering student and today our prof showed us this proof of the derivative of polynomials. However, I don’t understand how the second term is equal to the third term (the prof said we should know this from school so he did not explain). Could someone please explain to me about what happened there? I really can’t figure it out and don’t know how to search for it in the internet. Thanks in advance.","Hello, I’m a first year engineering student and today our prof showed us this proof of the derivative of polynomials. However, I don’t understand how the second term is equal to the third term (the prof said we should know this from school so he did not explain). Could someone please explain to me about what happened there? I really can’t figure it out and don’t know how to search for it in the internet. Thanks in advance.",,"['analysis', 'derivatives', 'proof-explanation']"
76,"Let $f:[0,1] \to \mathbb R$ differentiable s.t $f(0)=0$. $\forall x \in [0,1]$: $|f^{'}(x)| \le |f(x)|$. Prove $f(x) =0$, $\forall x \in [0,1]$.","Let  differentiable s.t . : . Prove , .","f:[0,1] \to \mathbb R f(0)=0 \forall x \in [0,1] |f^{'}(x)| \le |f(x)| f(x) =0 \forall x \in [0,1]","Let $f:[0,1] \to \mathbb R$ differentiable s.t $f(0)=0$ . $\forall x \in [0,1]$ : $|f^{'}(x)| \le |f(x)|$ . Prove $f(x) =0$ , $\forall x \in [0,1]$ . I've tried proving this with Mean Value Theorem but I think one of my implementations isn't good enough. I'd love some help! First of all we have $f(x)$ is differentiable $\implies$ $f(x)$ is continuous in $[0,1]$ . From MVT we have: exists some $c_1 \in (0,1)$ s.t $|f(1)| = {f(1)-f(0) \over 1-0} = f^{'}(c_1)$ . From the datum we can deduce: $0 \le f(1) = |f^{'}(c_1)| \le |f(c_1)|$ . Now take some $b \in (0,1)$ . Let us examine the interval $[0,b]$ . From MVT we have some $c_2 \in (0,b)$ s.t: $|f(b)| \lt {f(b) \over b} = {f(b)-f(0) \over b-0} = f^{'}(c_2) \implies 0 \le f(b) \lt |f^{'}(c_2)| \le |f(c_2)|$ . This is the tricky part: Since we took some random $b \in (0,1)$ we have $\forall x \in (0,1]$ we have $0 \le |f(x)| \le f(0) = 0$ thus implementing $f(x) = 0, \forall x \in [0,1]$ as needed. I understand the last conclusion is based on a limit type of argument which I have not provided.","Let differentiable s.t . : . Prove , . I've tried proving this with Mean Value Theorem but I think one of my implementations isn't good enough. I'd love some help! First of all we have is differentiable is continuous in . From MVT we have: exists some s.t . From the datum we can deduce: . Now take some . Let us examine the interval . From MVT we have some s.t: . This is the tricky part: Since we took some random we have we have thus implementing as needed. I understand the last conclusion is based on a limit type of argument which I have not provided.","f:[0,1] \to \mathbb R f(0)=0 \forall x \in [0,1] |f^{'}(x)| \le |f(x)| f(x) =0 \forall x \in [0,1] f(x) \implies f(x) [0,1] c_1 \in (0,1) |f(1)| = {f(1)-f(0) \over 1-0} = f^{'}(c_1) 0 \le f(1) = |f^{'}(c_1)| \le |f(c_1)| b \in (0,1) [0,b] c_2 \in (0,b) |f(b)| \lt {f(b) \over b} = {f(b)-f(0) \over b-0} = f^{'}(c_2) \implies 0 \le f(b) \lt |f^{'}(c_2)| \le |f(c_2)| b \in (0,1) \forall x \in (0,1] 0 \le |f(x)| \le f(0) = 0 f(x) = 0, \forall x \in [0,1]","['calculus', 'derivatives', 'continuity', 'mean-value-theorem']"
77,Why is the derivative of $e^{-x^2}$ equal to $-2xe^{-x^2}$?,Why is the derivative of  equal to ?,e^{-x^2} -2xe^{-x^2},"I was messing around with the derivatives and integrals of $e^{-x^{2}}$ on Desmos, and had mistakenly been integrating the function $\displaystyle{\displaylines{\int_{0}^{x} e^{-x^{2}}dt}}$ which coincidentally is equal to $\displaystyle{\displaylines{-\frac{1}{2}\frac{dx}{dt}e^{-x^{2}}}}$ , but after realizing that this wasn't the actual integral, I tried to see how I could modify the actual integral $\displaystyle{\displaylines{\int_{0}^{x}e^{-t^{2}}dt}}$ to result in this same curve as I mistakenly achieved earlier which I found with the below equation $$ \displaystyle{\displaylines{-2e^{-x^{2}}\left(\lim_{n \rightarrow \infty} \int_{0}^{x} e^{-\frac{t^{2}}{n}}dt\right) = \frac{dx}{dt}e^{-x^{2}}}} $$ Which it turns out that the limit $\displaystyle{\displaylines{\lim_{n \rightarrow \infty} \int_{0}^{x} e^{-\frac{t^{2}}{n}}dt}}$ approaches the line $\displaystyle{\displaylines{y=x}}$ , so the equation simplifies to: $$ \displaystyle{\displaylines{-2xe^{-x^{2}} = \frac{dx}{dt}e^{-x^{2}}}} $$ What I'm wondering is why multiplying $\displaystyle{\displaylines{e^{-x^{2}}}}$ by $\displaystyle{\displaylines{-2x}}$ would equal the derivative of the original function. I'd wager a guess that the answer might have to do with the property of $\displaystyle{\displaylines{e^{x}}}$ being its own derivative, but I have no clue where the $\displaystyle{\displaylines{-2}}$ comes from. Does anybody know why this might be? Thanks!","I was messing around with the derivatives and integrals of on Desmos, and had mistakenly been integrating the function which coincidentally is equal to , but after realizing that this wasn't the actual integral, I tried to see how I could modify the actual integral to result in this same curve as I mistakenly achieved earlier which I found with the below equation Which it turns out that the limit approaches the line , so the equation simplifies to: What I'm wondering is why multiplying by would equal the derivative of the original function. I'd wager a guess that the answer might have to do with the property of being its own derivative, but I have no clue where the comes from. Does anybody know why this might be? Thanks!","e^{-x^{2}} \displaystyle{\displaylines{\int_{0}^{x} e^{-x^{2}}dt}} \displaystyle{\displaylines{-\frac{1}{2}\frac{dx}{dt}e^{-x^{2}}}} \displaystyle{\displaylines{\int_{0}^{x}e^{-t^{2}}dt}} 
\displaystyle{\displaylines{-2e^{-x^{2}}\left(\lim_{n \rightarrow \infty} \int_{0}^{x} e^{-\frac{t^{2}}{n}}dt\right) = \frac{dx}{dt}e^{-x^{2}}}}
 \displaystyle{\displaylines{\lim_{n \rightarrow \infty} \int_{0}^{x} e^{-\frac{t^{2}}{n}}dt}} \displaystyle{\displaylines{y=x}} 
\displaystyle{\displaylines{-2xe^{-x^{2}} = \frac{dx}{dt}e^{-x^{2}}}}
 \displaystyle{\displaylines{e^{-x^{2}}}} \displaystyle{\displaylines{-2x}} \displaystyle{\displaylines{e^{x}}} \displaystyle{\displaylines{-2}}","['integration', 'derivatives']"
78,Proof that $\frac{d}{dx} \tan^{-1} x = \frac{1}{1+x^2}$using implicit differentiation,Proof that using implicit differentiation,\frac{d}{dx} \tan^{-1} x = \frac{1}{1+x^2},"Proof that $\frac{d}{dx} \tan^{-1} x = \frac{1}{1+x^2}$ using implicit differentiation My workings: $y=\tan^{-1} x$ , $x= \tan y$ $\frac{d}{dx} (x) = \frac{d}{dx} \tan y$ $1 = \sec^2 y \frac{dy}{dx}$ $\frac{dy}{dx} = \frac{1}{\sec^2 y} = \cos^2 y$ How do I carry on from here?","Proof that using implicit differentiation My workings: , How do I carry on from here?",\frac{d}{dx} \tan^{-1} x = \frac{1}{1+x^2} y=\tan^{-1} x x= \tan y \frac{d}{dx} (x) = \frac{d}{dx} \tan y 1 = \sec^2 y \frac{dy}{dx} \frac{dy}{dx} = \frac{1}{\sec^2 y} = \cos^2 y,['derivatives']
79,Is there any method to compute $\frac{d^{n}}{d x^{n}}\left(\cos ^{k} x\right)$ other than complex numbers?,Is there any method to compute  other than complex numbers?,\frac{d^{n}}{d x^{n}}\left(\cos ^{k} x\right),"In this couple of days, I need to know the high derivatives of $cos^kx$ whose power $k$ make the differentiation much harder.  Then I attempt to use the identity $$ \cos x=\frac{1}{2}\left(e^{x i}+e^{-x i}\right), $$ to expand it with Binomial expansion $$ \begin{aligned} \cos ^{k} x &=\frac{1}{2 ^k} \sum_{j=0}^{k}\binom{k}{j}e^{x(k-j) i} e^{-x i j}  =\frac{1}{2^{k}} \sum_{j=0}^{k}\binom{k}{j} e^{x(k-2 j) i} \end{aligned} $$ Differentiating it by $n$ times yields $$ \begin{aligned} \frac{d^{n}}{d x^{n}}\left(\cos ^{k} x\right) &=\frac{1}{2^k} \sum_{j=0}^{k}\binom{k}{j}[(k-2 j) i]^{n} e^{x(k-2 j) i} \\ &=\frac{i^{n}}{2 ^k} \sum_{j=0}^{k}\binom{k}{j}(k-2 j)^{n} e^{x(k-2 j) i} \\ &=\frac{i^{n}}{2^{k}} \sum_{j=0}^{k}\binom{k}{j}(k-2 j)^{n}[\cos ((k-2 j) x)+i \sin ((k-2 j) x)] \end{aligned} $$ If $x$ is real , then comparing the imaginary and real parts on both sides yields \begin{equation} \displaystyle \frac{d^{n}}{d x^{n}}\left(\cos ^{k} x\right)=\left\{\begin{array}{ll} \displaystyle \frac{(-1)^{\frac{n}{2}}}{2^{k-1}} \sum_{j=0}^{\left\lfloor\frac{k}{2}\right\rfloor}\binom{k}{j}(k-2 j)^{n}\cos((k-2j)x) \quad \textrm{ if n is even.}\\\displaystyle  \frac{(-1)^{\frac{n+1}{2}}}{2^{k-1}} \sum_{j=0}^{\left\lfloor\frac{k}{2}\right\rfloor}\binom{k}{j}(k-2 j)^{n} \sin((k-2j)x)  \quad \textrm{ if n is odd.} \end{array}\right. \end{equation} For examples, When $n$ is even, $$ \left.\frac{d^{n}}{d x^{n}}\left(\cos ^{k} x\right)\right|_{x=0}=\frac{(-1)^{\frac{n}{2}}}{2^{k-1}} \sum_{j=0}^{\left\lfloor\frac{k}{2}\right\rfloor}\binom{k}{j}(k-2 j)^{n} $$ In particular, $$ \begin{aligned} \left.\frac{d^{6}}{d x^{6}}\left(\cos ^{5} x\right)\right|_{x=0}&=\frac{(-1)^{3}}{2^{4}} \sum_{j=0}^{2}\binom{5}{j}(5-2 j)^{6} \\ &=\frac{1}{16}\left[5^{6}+5 \cdot 3^{6}+10 \cdot 1^{6}\right] \\ &=1205 \end{aligned} $$ When $n$ is odd, $$ \left.\frac{d^{n}}{d x^{n}}\left(\cos ^{k} x\right)\right|_{x=0}=0; $$ $$\left.\frac{d^{n}}{d x^{n}}\left(\cos ^{k} x\right) \right|_{x=\frac{\pi}{4} }=  \frac{(-1)^{\frac{n+1}{2}}}{2^{k-1}} \sum_{j=0}^{\left\lfloor\frac{k}{2}\right\rfloor}\binom{k}{j}(k-2 j)^{n} \sin \frac{(k-2 j) \pi}{4} $$ Can we find its closed form without using the complex numbers?","In this couple of days, I need to know the high derivatives of whose power make the differentiation much harder.  Then I attempt to use the identity to expand it with Binomial expansion Differentiating it by times yields If is real , then comparing the imaginary and real parts on both sides yields For examples, When is even, In particular, When is odd, Can we find its closed form without using the complex numbers?","cos^kx k 
\cos x=\frac{1}{2}\left(e^{x i}+e^{-x i}\right),
 
\begin{aligned}
\cos ^{k} x &=\frac{1}{2 ^k} \sum_{j=0}^{k}\binom{k}{j}e^{x(k-j) i} e^{-x i j} 
=\frac{1}{2^{k}} \sum_{j=0}^{k}\binom{k}{j} e^{x(k-2 j) i}
\end{aligned}
 n 
\begin{aligned}
\frac{d^{n}}{d x^{n}}\left(\cos ^{k} x\right) &=\frac{1}{2^k} \sum_{j=0}^{k}\binom{k}{j}[(k-2 j) i]^{n} e^{x(k-2 j) i} \\
&=\frac{i^{n}}{2 ^k} \sum_{j=0}^{k}\binom{k}{j}(k-2 j)^{n} e^{x(k-2 j) i} \\
&=\frac{i^{n}}{2^{k}} \sum_{j=0}^{k}\binom{k}{j}(k-2 j)^{n}[\cos ((k-2 j) x)+i \sin ((k-2 j) x)]
\end{aligned}
 x \begin{equation}
\displaystyle \frac{d^{n}}{d x^{n}}\left(\cos ^{k} x\right)=\left\{\begin{array}{ll}
\displaystyle \frac{(-1)^{\frac{n}{2}}}{2^{k-1}} \sum_{j=0}^{\left\lfloor\frac{k}{2}\right\rfloor}\binom{k}{j}(k-2 j)^{n}\cos((k-2j)x) \quad \textrm{ if n is even.}\\\displaystyle 
\frac{(-1)^{\frac{n+1}{2}}}{2^{k-1}} \sum_{j=0}^{\left\lfloor\frac{k}{2}\right\rfloor}\binom{k}{j}(k-2 j)^{n} \sin((k-2j)x)  \quad \textrm{ if n is odd.}
\end{array}\right.
\end{equation} n 
\left.\frac{d^{n}}{d x^{n}}\left(\cos ^{k} x\right)\right|_{x=0}=\frac{(-1)^{\frac{n}{2}}}{2^{k-1}} \sum_{j=0}^{\left\lfloor\frac{k}{2}\right\rfloor}\binom{k}{j}(k-2 j)^{n}
 
\begin{aligned}
\left.\frac{d^{6}}{d x^{6}}\left(\cos ^{5} x\right)\right|_{x=0}&=\frac{(-1)^{3}}{2^{4}} \sum_{j=0}^{2}\binom{5}{j}(5-2 j)^{6} \\
&=\frac{1}{16}\left[5^{6}+5 \cdot 3^{6}+10 \cdot 1^{6}\right] \\
&=1205
\end{aligned}
 n 
\left.\frac{d^{n}}{d x^{n}}\left(\cos ^{k} x\right)\right|_{x=0}=0;
 \left.\frac{d^{n}}{d x^{n}}\left(\cos ^{k} x\right) \right|_{x=\frac{\pi}{4} }= 
\frac{(-1)^{\frac{n+1}{2}}}{2^{k-1}} \sum_{j=0}^{\left\lfloor\frac{k}{2}\right\rfloor}\binom{k}{j}(k-2 j)^{n} \sin \frac{(k-2 j) \pi}{4} ","['calculus', 'derivatives', 'complex-numbers', 'binomial-theorem']"
80,"Partial derivative, show that problem. L.H.S to R.H.S","Partial derivative, show that problem. L.H.S to R.H.S",,"This is a question from Advanced Calculus by David Wider. If $u=f(x,y),x=r\cos(\theta)$ and $y=r\sin(\theta)$ show that $$\frac{\partial u}{\partial x}^2+ \frac{\partial u}{\partial y}^2 = \frac{\partial u}{\partial r}^2 + \frac{\partial  u}{\partial \theta}^2\frac{1}{r^2}$$ So far I have said the following \begin{align}&\frac{\partial u}{\partial x}=\frac{\partial u}{\partial r}\frac{\partial r}{\partial x}= \frac{\partial u}{\partial r}\frac{1}{(\frac{\partial x}{\partial r})}=\frac{\partial u}{\partial r}\frac{1}{\cos\theta} \\ \Rightarrow  &\frac{\partial u}{\partial x}^2=\frac{\partial u}{\partial r}^2\frac{1}{\cos^2\theta}\text{, and } \frac{\partial u}{\partial y}=\frac{\partial u}{\partial \theta}\frac{\partial \theta}{\partial y}=\frac{\partial u}{\partial \theta}\frac{1}{(\frac{\partial y}{\partial \theta})}=\frac{\partial u}{\partial \theta}\frac{1}{-r\cos\theta} \\  \Rightarrow &\frac{\partial u}{\partial y}^2=\frac{\partial u}{\partial \theta}^2\frac{1}{r^2\cos^2\theta}  \\ &\text{ taking the sum ( the L. H .S) we get the following }\\ &\frac{\partial u}{\partial r}^2\frac{1}{\cos^2\theta}+\frac{\partial u}{\partial \theta}^2\frac{1}{r^2\cos^2\theta}=\frac{1}{\cos^2 \theta}(\frac{\partial u}{\partial r}^2+ \frac{\partial  u}{\partial \theta}^2\frac{1}{r^2}) \end{align} given my certainty about the fact that $\frac{1}{\cos^2 \theta}$ not equalling 1 can say I have made a mistake could someone please point it out or provide a complete solution that would be apricated. I suspect my mistake might be around my inversion of the partial derivatives but i am not sure.",This is a question from Advanced Calculus by David Wider. If and show that So far I have said the following given my certainty about the fact that not equalling 1 can say I have made a mistake could someone please point it out or provide a complete solution that would be apricated. I suspect my mistake might be around my inversion of the partial derivatives but i am not sure.,"u=f(x,y),x=r\cos(\theta) y=r\sin(\theta) \frac{\partial u}{\partial x}^2+ \frac{\partial u}{\partial y}^2 = \frac{\partial u}{\partial r}^2 + \frac{\partial
 u}{\partial \theta}^2\frac{1}{r^2} \begin{align}&\frac{\partial u}{\partial x}=\frac{\partial u}{\partial r}\frac{\partial r}{\partial x}=
\frac{\partial u}{\partial r}\frac{1}{(\frac{\partial x}{\partial r})}=\frac{\partial u}{\partial r}\frac{1}{\cos\theta} \\
\Rightarrow 
&\frac{\partial u}{\partial x}^2=\frac{\partial u}{\partial r}^2\frac{1}{\cos^2\theta}\text{, and } \frac{\partial u}{\partial y}=\frac{\partial u}{\partial \theta}\frac{\partial \theta}{\partial y}=\frac{\partial u}{\partial \theta}\frac{1}{(\frac{\partial y}{\partial \theta})}=\frac{\partial u}{\partial \theta}\frac{1}{-r\cos\theta} \\
 \Rightarrow
&\frac{\partial u}{\partial y}^2=\frac{\partial u}{\partial \theta}^2\frac{1}{r^2\cos^2\theta}  \\
&\text{ taking the sum ( the L. H .S) we get the following }\\
&\frac{\partial u}{\partial r}^2\frac{1}{\cos^2\theta}+\frac{\partial u}{\partial \theta}^2\frac{1}{r^2\cos^2\theta}=\frac{1}{\cos^2 \theta}(\frac{\partial u}{\partial r}^2+ \frac{\partial
 u}{\partial \theta}^2\frac{1}{r^2})
\end{align} \frac{1}{\cos^2 \theta}","['derivatives', 'partial-differential-equations', 'partial-derivative']"
81,"$\frac{dy}{dx}=\frac{y}{x}$ for a homogeneous equation in $x,y$?",for a homogeneous equation in ?,"\frac{dy}{dx}=\frac{y}{x} x,y","A problem book I use mentions the following: ...since the curve $32x^3y^2=(x+y)^5$ is homogeneous, $\frac{dy}{dx}=\frac{y}{x}$ I have indeed verified the derivative. Is this a known theorem? I generalized it to $$cx^ay^b=(x+y)^{a+b},$$ but does there exist a more generalized form?","A problem book I use mentions the following: ...since the curve is homogeneous, I have indeed verified the derivative. Is this a known theorem? I generalized it to but does there exist a more generalized form?","32x^3y^2=(x+y)^5 \frac{dy}{dx}=\frac{y}{x} cx^ay^b=(x+y)^{a+b},","['derivatives', 'curves']"
82,How is manipulation of derivatives possible?,How is manipulation of derivatives possible?,,"In parametric differentiation, finding the second derivative can be given by: $\frac{d^2y}{dx^2} = \frac{d}{dx}(\frac{dy}{dx}) = \frac{d}{dx}(\frac{dy}{dt}*\frac{dt}{dx})$ Now if I am differentiating two functions multiplied together, I would use the product rule right? $\frac{d}{dx}(\frac{dy}{dt}*\frac{dt}{dx})$ = $\frac{dt}{dx}*\frac{d}{dx}(\frac{dy}{dt})$ + $\frac{dy}{dt}* \frac{d}{dx}(\frac{dt}{dx})$ But that is a wrong manipulation, rather this is what is given in my textbook: Manipulating derivatives is hard, at some points, they act like fractions, while at others they do not. How do I know for sure that what I am doing is correct?","In parametric differentiation, finding the second derivative can be given by: Now if I am differentiating two functions multiplied together, I would use the product rule right? = + But that is a wrong manipulation, rather this is what is given in my textbook: Manipulating derivatives is hard, at some points, they act like fractions, while at others they do not. How do I know for sure that what I am doing is correct?",\frac{d^2y}{dx^2} = \frac{d}{dx}(\frac{dy}{dx}) = \frac{d}{dx}(\frac{dy}{dt}*\frac{dt}{dx}) \frac{d}{dx}(\frac{dy}{dt}*\frac{dt}{dx}) \frac{dt}{dx}*\frac{d}{dx}(\frac{dy}{dt}) \frac{dy}{dt}* \frac{d}{dx}(\frac{dt}{dx}),"['calculus', 'derivatives']"
83,Lang's proof that there exists $x>0$ such that $\cos x=0$,Lang's proof that there exists  such that,x>0 \cos x=0,"In Undergraduate Analysis on p. 90, Lang assumes the existence of two functions $f$ (sine) and $g$ (cosine) satisfying the conditions $f(0)=0$ , $g(0)=1$ , $f'=g$ and $g'=-f$ . He then goes on to show that there exists $x>0$ such that $\cos x=0$ . With your help, I would like to make some of the steps in his proof more explicit. Suppose that no such number exists. Since $\cos$ is continuous, we conclude that $\cos x$ cannot be negative for any value $x>0$ (by intermediate value theorem). Hence $\sin$ is strictly increasing for all $x>0$ , and $\cos x$ is strictly decreasing for all $x>0$ ... It's clear why $\sin$ is strictly increasing on the interval $(0,\infty)$ . Why is $\cos$ strictly decreasing on the interval $(0,\infty)$ ? This would require $\sin x>0$ for all $x\in(0,\infty)$ . But how can I show this? ... Let $a>0$ . Then $0<\cos 2a=\cos^2a-\sin^2a<\cos^2a$ . By induction, we see that $\cos(2^n a)<(\cos a)^{2^n}$ for all positive integers $n$ . Hence $\cos(2^na)$ approaches $0$ as $n$ becomes large, because $0<\cos a<1$ . Since $\cos$ is strictly decreasing for $x>0$ , it follows that $\cos x$ approaches $0$ as $x$ becomes large, and hence $\sin x$ approaches $1$ . In particular, there exists a number $b>0$ such that $$\cos b<\frac{1}{4}\text{ and }\sin b>\frac{1}{2}.$$ If $\lim_{n\rightarrow\infty}\cos(2^na)=0$ for all $a>0$ , how can I conclude that $\lim_{x\rightarrow\infty}\cos x=0$ ? Let $\epsilon>0$ . Then I would have to show that there exists $s\in\mathbb{R}$ such that $$(\forall x)(x\in(s,\infty)\implies|\cos x|<\epsilon).$$ It's not immediately clear how to find such an $s$ . I would have to use the fact that $\lim_{n\rightarrow\infty}\cos(2^na)=0$ for all $a>0$ , but I don't know how.","In Undergraduate Analysis on p. 90, Lang assumes the existence of two functions (sine) and (cosine) satisfying the conditions , , and . He then goes on to show that there exists such that . With your help, I would like to make some of the steps in his proof more explicit. Suppose that no such number exists. Since is continuous, we conclude that cannot be negative for any value (by intermediate value theorem). Hence is strictly increasing for all , and is strictly decreasing for all ... It's clear why is strictly increasing on the interval . Why is strictly decreasing on the interval ? This would require for all . But how can I show this? ... Let . Then . By induction, we see that for all positive integers . Hence approaches as becomes large, because . Since is strictly decreasing for , it follows that approaches as becomes large, and hence approaches . In particular, there exists a number such that If for all , how can I conclude that ? Let . Then I would have to show that there exists such that It's not immediately clear how to find such an . I would have to use the fact that for all , but I don't know how.","f g f(0)=0 g(0)=1 f'=g g'=-f x>0 \cos x=0 \cos \cos x x>0 \sin x>0 \cos x x>0 \sin (0,\infty) \cos (0,\infty) \sin x>0 x\in(0,\infty) a>0 0<\cos 2a=\cos^2a-\sin^2a<\cos^2a \cos(2^n a)<(\cos a)^{2^n} n \cos(2^na) 0 n 0<\cos a<1 \cos x>0 \cos x 0 x \sin x 1 b>0 \cos b<\frac{1}{4}\text{ and }\sin b>\frac{1}{2}. \lim_{n\rightarrow\infty}\cos(2^na)=0 a>0 \lim_{x\rightarrow\infty}\cos x=0 \epsilon>0 s\in\mathbb{R} (\forall x)(x\in(s,\infty)\implies|\cos x|<\epsilon). s \lim_{n\rightarrow\infty}\cos(2^na)=0 a>0","['real-analysis', 'derivatives', 'trigonometry', 'continuity', 'proof-explanation']"
84,Why the partial derivative for these two similar cases are done differently?,Why the partial derivative for these two similar cases are done differently?,,I was watching patrickJMT's derivates of logarithmic functions video and I got stuck understanding why these derivates are treated differently: $f(x) = \ln(g(x))$ derivative is $f'(x) = \frac{1 }{ g(x)} * g'(x)$ while the function $f(x) = log_a g(x)$ has the derivative $f'(x) = \frac{1 }{ g(x) \ln(a)}$ . Why do we not include the derivative of $g(x)$ as well to the case of log function? Reference,I was watching patrickJMT's derivates of logarithmic functions video and I got stuck understanding why these derivates are treated differently: derivative is while the function has the derivative . Why do we not include the derivative of as well to the case of log function? Reference,f(x) = \ln(g(x)) f'(x) = \frac{1 }{ g(x)} * g'(x) f(x) = log_a g(x) f'(x) = \frac{1 }{ g(x) \ln(a)} g(x),"['derivatives', 'logarithms']"
85,Correct notation for (partial) derivative evaluated in a given point,Correct notation for (partial) derivative evaluated in a given point,,"Consider a function $f : \mathbb{R}^N \to \mathbb{R}.$ In general, we write the function in the from $f({\bf x})$ , where ${\bf x} = [x_1, x_2, \ldots, x_N]^\top \in \mathbb{R}^N$ . Consider the partial derivative with respect to the $i$ -th component of ${\bf x}.$ I would write: $$\frac{\partial f}{\partial x_i} ~\text{or} ~ \frac{\partial f({\bf x})}{\partial x_i}.$$ What is the correct way to represent this derivative when evaluated in the point ${\bf y} \in \mathbb{R}^N$ ? I don't feel so comfortable writing: $$\frac{\partial f({\bf y})}{\partial x_i},$$ since the reader may miss the relationships between $x_i$ and the argument of the function. Is $$\left.\frac{\partial f({\bf x})}{\partial x_i}\right|_{{\bf x} = {\bf y}},$$ a more correct way to write the partial derivative evaluated in ${\bf y}$ ?","Consider a function In general, we write the function in the from , where . Consider the partial derivative with respect to the -th component of I would write: What is the correct way to represent this derivative when evaluated in the point ? I don't feel so comfortable writing: since the reader may miss the relationships between and the argument of the function. Is a more correct way to write the partial derivative evaluated in ?","f : \mathbb{R}^N \to \mathbb{R}. f({\bf x}) {\bf x} = [x_1, x_2, \ldots, x_N]^\top \in \mathbb{R}^N i {\bf x}. \frac{\partial f}{\partial x_i} ~\text{or} ~ \frac{\partial f({\bf x})}{\partial x_i}. {\bf y} \in \mathbb{R}^N \frac{\partial f({\bf y})}{\partial x_i}, x_i \left.\frac{\partial f({\bf x})}{\partial x_i}\right|_{{\bf x} = {\bf y}}, {\bf y}","['derivatives', 'notation', 'soft-question', 'partial-derivative']"
86,"Solving for the derivative of absolute value, gone wrong","Solving for the derivative of absolute value, gone wrong",,"The absolute value $|x|$ can be represented as $\sqrt{x^{2}}$ , as per this question . Let $f(x) = |x| = \sqrt{x^{2}}$ . Solving for $f'(x)$ , let $u = x^{2}$ . Then, \begin{align*}\frac{df}{dx} &= \frac{df}{du}\cdot\frac{du}{dx} \\ &= \frac{d}{du}(\sqrt{u})\cdot\frac{d}{dx}(x^{2}) \\ &=\frac{1}{2\sqrt{u}}\cdot2x \\ &= \frac{x}{\sqrt{x^{2}}} \\ &= \frac{x}{|x|}\end{align*} We can also see that $\sqrt{x^{2}} = \left(\sqrt{x}\right)^{2}$ . Then, let $u = \sqrt{x}$ . Solving for $f'(x)$ , \begin{align*}\frac{df}{dx} &= \frac{df}{du}\cdot\frac{du}{dx} \\ &= \frac{d}{du}(u^{2})\cdot\frac{d}{dx}(\sqrt{x}) \\ &= 2u\cdot \frac{1}{2\sqrt{x}} \\ &= \frac{\sqrt{x}}{\sqrt{x}} \\ &= 1\end{align*} I think the problem here is by letting $u = \sqrt{x}$ . What seems to be the problem?","The absolute value can be represented as , as per this question . Let . Solving for , let . Then, We can also see that . Then, let . Solving for , I think the problem here is by letting . What seems to be the problem?",|x| \sqrt{x^{2}} f(x) = |x| = \sqrt{x^{2}} f'(x) u = x^{2} \begin{align*}\frac{df}{dx} &= \frac{df}{du}\cdot\frac{du}{dx} \\ &= \frac{d}{du}(\sqrt{u})\cdot\frac{d}{dx}(x^{2}) \\ &=\frac{1}{2\sqrt{u}}\cdot2x \\ &= \frac{x}{\sqrt{x^{2}}} \\ &= \frac{x}{|x|}\end{align*} \sqrt{x^{2}} = \left(\sqrt{x}\right)^{2} u = \sqrt{x} f'(x) \begin{align*}\frac{df}{dx} &= \frac{df}{du}\cdot\frac{du}{dx} \\ &= \frac{d}{du}(u^{2})\cdot\frac{d}{dx}(\sqrt{x}) \\ &= 2u\cdot \frac{1}{2\sqrt{x}} \\ &= \frac{\sqrt{x}}{\sqrt{x}} \\ &= 1\end{align*} u = \sqrt{x},"['calculus', 'derivatives', 'absolute-value']"
87,Cannot understand calculations (Taylor's Theorem),Cannot understand calculations (Taylor's Theorem),,"I have been studying Taylor's Theorem in Bartle's book. However, I cannot understand some simple (?) calculations, and this is really bothering me. Theorem (as stated in the book): Let $n \in \mathbb{N},$ let $I:=[a, b],$ and let $f: I \rightarrow \mathbb{R}$ be such that $f$ and its derivatives $f^{\prime}, f^{\prime \prime}, \ldots, f^{(n)}$ are continuous on $I$ , and that $f^{(n+1)}$ exists on $(a, b)$ . If $x_{0} \in I,$ then for any $x$ in $I$ there exists a point $c$ between $x$ and $x_{0}$ such that: $$ f(x)=f\left(x_{0}\right)+f^{\prime}\left(x_{0}\right)\left(x-x_{0}\right)+\frac{f^{\prime \prime}\left(x_{0}\right)}{2 !}\left(x-x_{0}\right)^{2} $$ $$ +\cdots+\frac{f^{(n)}\left(x_{0}\right)}{n !}\left(x-x_{0}\right)^{n}+\frac{f^{(n+1)}(c)}{(n+1) !}\left(x-x_{0}\right)^{n+1} $$ Proof: Let $x_{0}$ and $x$ be given, and let $J$ denote the closed interval with endpoints $x_{0}$ and $x$ . We define the function $F$ on $J$ by: $$ F(t):=f(x)-f(t)-(x-t) f^{\prime}(t)-\cdots-\frac{(x-t)^{n}}{n !} f^{(n)}(t) $$ for $t \in J$ . Then an easy calculation shows that we have: $$ F^{\prime}(t)=-\frac{(x-t)^{n}}{n !} f^{(n+1)}(t) $$ The proof continues here, but the rest is fine, I get it. What I cannot understand is the following: Then an easy calculation shows that we have: $$ F^{\prime}(t)=-\frac{(x-t)^{n}}{n !} f^{(n+1)}(t) $$ There are a lot of terms that just seem to have vanished from the expression regarding $F(t)$ , and I just don't know how that happened. Furthermore, the last term $$ F^{\prime}(t)=-\frac{(x-t)^{n}}{n !} f^{(n+1)}(t) $$ does not make sense to me. What I got from the derivative of the last term $-\frac{(x-t)^{n}}{n !} f^{(n)}(t)$ was: $$ \left((x-t)^{n} \cdot f^{(n)}(t)\right)^{\prime}=n(x-t)^{n-1} \cdot(-1) \cdot f^{(n)}(t)-(x-t)^{n} \cdot f^{(n+1)}(t) $$ Now, dividing by $n!$ what I get is: $$ \frac{-n(x-t)^{n-1} \cdot f^{(n)}(t)}{n \cdot(n-1) !}-\frac{(x-t)^{n} \cdot f^{(n+1)}(t)}{n !} $$ which does not even resemble the last term regarding the $F(t)$ expression. Can someone help?","I have been studying Taylor's Theorem in Bartle's book. However, I cannot understand some simple (?) calculations, and this is really bothering me. Theorem (as stated in the book): Let let and let be such that and its derivatives are continuous on , and that exists on . If then for any in there exists a point between and such that: Proof: Let and be given, and let denote the closed interval with endpoints and . We define the function on by: for . Then an easy calculation shows that we have: The proof continues here, but the rest is fine, I get it. What I cannot understand is the following: Then an easy calculation shows that we have: There are a lot of terms that just seem to have vanished from the expression regarding , and I just don't know how that happened. Furthermore, the last term does not make sense to me. What I got from the derivative of the last term was: Now, dividing by what I get is: which does not even resemble the last term regarding the expression. Can someone help?","n \in \mathbb{N}, I:=[a, b], f: I \rightarrow \mathbb{R} f f^{\prime}, f^{\prime \prime}, \ldots, f^{(n)} I f^{(n+1)} (a, b) x_{0} \in I, x I c x x_{0} 
f(x)=f\left(x_{0}\right)+f^{\prime}\left(x_{0}\right)\left(x-x_{0}\right)+\frac{f^{\prime \prime}\left(x_{0}\right)}{2 !}\left(x-x_{0}\right)^{2}
 
+\cdots+\frac{f^{(n)}\left(x_{0}\right)}{n !}\left(x-x_{0}\right)^{n}+\frac{f^{(n+1)}(c)}{(n+1) !}\left(x-x_{0}\right)^{n+1}
 x_{0} x J x_{0} x F J 
F(t):=f(x)-f(t)-(x-t) f^{\prime}(t)-\cdots-\frac{(x-t)^{n}}{n !} f^{(n)}(t)
 t \in J 
F^{\prime}(t)=-\frac{(x-t)^{n}}{n !} f^{(n+1)}(t)
 
F^{\prime}(t)=-\frac{(x-t)^{n}}{n !} f^{(n+1)}(t)
 F(t) 
F^{\prime}(t)=-\frac{(x-t)^{n}}{n !} f^{(n+1)}(t)
 -\frac{(x-t)^{n}}{n !} f^{(n)}(t) 
\left((x-t)^{n} \cdot f^{(n)}(t)\right)^{\prime}=n(x-t)^{n-1} \cdot(-1) \cdot f^{(n)}(t)-(x-t)^{n} \cdot f^{(n+1)}(t)
 n! 
\frac{-n(x-t)^{n-1} \cdot f^{(n)}(t)}{n \cdot(n-1) !}-\frac{(x-t)^{n} \cdot f^{(n+1)}(t)}{n !}
 F(t)","['real-analysis', 'calculus', 'derivatives', 'continuity', 'taylor-expansion']"
88,Smallest possible area for triangle,Smallest possible area for triangle,,"I'm solving the following question: The two legs of a right triangle lie along the positive x and y axes. The hypotenuse is tangent to the ellipse $2x^2 + y^2 = 1$ . What is the smallest possible area for such a triangle ? This is my attempt at solving the problem: Let $a$ be the length of the x axis and $b$ be the length in it's y axis if the triangle. So it's area is $1/2 a.b$ Let's find the tangent of the ellipse: $2x^2 + y^2 = 1$ $4x + 2y \dfrac{dy}{dx} = 0$ $\dfrac{dy}{dx} = \dfrac{-2x}{y}$ Since the two points on the triangle are $(0,b)$ and $(a,0)$ , we can find the slope of the line: $m = \dfrac{b-0}{0-a} = \dfrac{-a}{b}$ So the equation of hypotonuse is $y = \dfrac{-a}{b}x + c$ Since $(0,b)$ is one of the point in the line, we can substitute it in the above line to find that $b = c$ . Solving it with the other co-ordinate, we can find the following fact $b = a$ . So now area is $1/2 a.b = 1/2 a^2$ Now I used the first derivative test to find that the function attains it's local minima at $0$ . So the smallest possible area for such a triangle is zero. I have missed lots of steps in my above solution for brevity, but I can expand if needed. My question: is zero the right answer ?  Unfortunately, the book I'm using doesn't provide the answer to this question.","I'm solving the following question: The two legs of a right triangle lie along the positive x and y axes. The hypotenuse is tangent to the ellipse . What is the smallest possible area for such a triangle ? This is my attempt at solving the problem: Let be the length of the x axis and be the length in it's y axis if the triangle. So it's area is Let's find the tangent of the ellipse: Since the two points on the triangle are and , we can find the slope of the line: So the equation of hypotonuse is Since is one of the point in the line, we can substitute it in the above line to find that . Solving it with the other co-ordinate, we can find the following fact . So now area is Now I used the first derivative test to find that the function attains it's local minima at . So the smallest possible area for such a triangle is zero. I have missed lots of steps in my above solution for brevity, but I can expand if needed. My question: is zero the right answer ?  Unfortunately, the book I'm using doesn't provide the answer to this question.","2x^2 + y^2 = 1 a b 1/2 a.b 2x^2 + y^2 = 1 4x + 2y \dfrac{dy}{dx} = 0 \dfrac{dy}{dx} = \dfrac{-2x}{y} (0,b) (a,0) m = \dfrac{b-0}{0-a} = \dfrac{-a}{b} y = \dfrac{-a}{b}x + c (0,b) b = c b = a 1/2 a.b = 1/2 a^2 0","['calculus', 'derivatives', 'optimization']"
89,Can a function be differentiable at a jump discontinuity?,Can a function be differentiable at a jump discontinuity?,,"I learnt in spivak's calculus that if a function is differentiable at a point then it is continuous at that point however I am confused about this function for example $$ f(x)=\begin{cases} -2x & x<4, \\ 8 & x=4.  \end{cases} $$ Is this function differentiable at $x=4$ since this point is an isolated point of the functions range the function is continuous at that point. However why can we not calculate the derivative at $x=4$ the right hand limit need not exsist as the function is not even defined for values of x greater than 4 so why is the derivative not defined ?",I learnt in spivak's calculus that if a function is differentiable at a point then it is continuous at that point however I am confused about this function for example Is this function differentiable at since this point is an isolated point of the functions range the function is continuous at that point. However why can we not calculate the derivative at the right hand limit need not exsist as the function is not even defined for values of x greater than 4 so why is the derivative not defined ?,"
f(x)=\begin{cases}
-2x & x<4, \\
8 & x=4. 
\end{cases}
 x=4 x=4","['calculus', 'limits', 'derivatives', 'self-learning']"
90,Show a function such that $f'(c)\neq \dfrac{f(b)-f(a)}{b-a}$ for any $a<b$,Show a function such that  for any,f'(c)\neq \dfrac{f(b)-f(a)}{b-a} a<b,"Could you help me with the following please: Give an example of a differentiable function $f:\mathbb{R} \rightarrow \mathbb{R}$ that has a point $c$ such that $f'(c)$ is not equal to the difference quotient $\dfrac{f(b)-f(a)}{b-a}$ for any $a<b$ . Why does this not contradict the mean value theorem? In a graphical way what can be seen is that this occurs when the second derivative of $ f $ is 0, but trying to find this function, I have considered a polynomial with this property, but I cannot see that it fulfills this characteristic. One attempt has been to consider the $ f(x)=x^3+3x+2 $ , but it failed to conclude that this is an example of what the exercise asks of us. And well, I think this does not contradict the MVT for the domain of said function.","Could you help me with the following please: Give an example of a differentiable function that has a point such that is not equal to the difference quotient for any . Why does this not contradict the mean value theorem? In a graphical way what can be seen is that this occurs when the second derivative of is 0, but trying to find this function, I have considered a polynomial with this property, but I cannot see that it fulfills this characteristic. One attempt has been to consider the , but it failed to conclude that this is an example of what the exercise asks of us. And well, I think this does not contradict the MVT for the domain of said function.",f:\mathbb{R} \rightarrow \mathbb{R} c f'(c) \dfrac{f(b)-f(a)}{b-a} a<b  f   f(x)=x^3+3x+2 ,"['real-analysis', 'derivatives']"
91,How to find first derivative of function $y=x \ln(x)$ by limit definition using this formula $y'=\lim_{h\to 0}\frac{f(x+h)-f(x)}h$?,How to find first derivative of function  by limit definition using this formula ?,y=x \ln(x) y'=\lim_{h\to 0}\frac{f(x+h)-f(x)}h,"How to find first derivative of function $y=x \ln(x)$ by limit definition, that is using this formula $$y'=\lim_{h\to 0}\frac{f(x+h)-f(x)}h$$ not product rule or L'Hopital rule are allowed. Thank you in advance :)","How to find first derivative of function by limit definition, that is using this formula not product rule or L'Hopital rule are allowed. Thank you in advance :)",y=x \ln(x) y'=\lim_{h\to 0}\frac{f(x+h)-f(x)}h,"['calculus', 'limits', 'derivatives', 'trigonometry', 'limits-without-lhopital']"
92,"Maximum of $f(x)=\frac{2x\sqrt{(x+1)}}{(9x^2+3)^{\frac{1}{4}}}+\frac{(1-2x)\sqrt{2-2x}}{(9(1-2x)^2+3)^{\frac{1}{4}}}$ on the interval $[0,1/2]$",Maximum of  on the interval,"f(x)=\frac{2x\sqrt{(x+1)}}{(9x^2+3)^{\frac{1}{4}}}+\frac{(1-2x)\sqrt{2-2x}}{(9(1-2x)^2+3)^{\frac{1}{4}}} [0,1/2]","I would like to find the maxima of the following function in one variable : $$f(x)=\frac{2x\sqrt{(x+1)}}{(9x^2+3)^{\frac{1}{4}}}+\frac{(1-2x)\sqrt{2-2x}}{(9(1-2x)^2+3)^{\frac{1}{4}}}$$ on the interval $[0,1/2]$ . I have already checked that it must occur at $1/3$ , but could someone give me a proper method of proving it (ideally without using computation engines ?). The problem here is obviously that the derivative of this function is not nice-looking at all and i do not wish to ""play"" with it. Thanks in advance !","I would like to find the maxima of the following function in one variable : on the interval . I have already checked that it must occur at , but could someone give me a proper method of proving it (ideally without using computation engines ?). The problem here is obviously that the derivative of this function is not nice-looking at all and i do not wish to ""play"" with it. Thanks in advance !","f(x)=\frac{2x\sqrt{(x+1)}}{(9x^2+3)^{\frac{1}{4}}}+\frac{(1-2x)\sqrt{2-2x}}{(9(1-2x)^2+3)^{\frac{1}{4}}} [0,1/2] 1/3","['calculus', 'derivatives', 'optimization', 'maxima-minima', 'cauchy-schwarz-inequality']"
93,"If $\forall n \in \mathbb Z_{\ge0} \ $ and $\forall x \in \mathbb R$, we know that $\big|f^{(n)}(x)\big|\le \big|p(x)\big|$, then $f=0$.","If  and , we know that , then .",\forall n \in \mathbb Z_{\ge0} \  \forall x \in \mathbb R \big|f^{(n)}(x)\big|\le \big|p(x)\big| f=0,"If $p(x)$ is an odd degree polynomial such as $\forall   n \in \mathbb Z_{\geq 0}$ and $\forall x \in \mathbb R$ we know that $$\big|f^{(n)}(x)\big|\le \big|p(x)\big|\,.$$ I need to show that $\forall x \in \mathbb R \ $ $f(x)=0$ . My thoughts till now: I tried to use Taylor polynomial but it didn't help. and I really need help. Thanks in advance.",If is an odd degree polynomial such as and we know that I need to show that . My thoughts till now: I tried to use Taylor polynomial but it didn't help. and I really need help. Thanks in advance.,"p(x) \forall   n \in \mathbb Z_{\geq 0} \forall x \in \mathbb R \big|f^{(n)}(x)\big|\le \big|p(x)\big|\,. \forall x \in \mathbb R \  f(x)=0","['calculus', 'derivatives', 'polynomials', 'taylor-expansion']"
94,"Is it a necessary condition for an even function to have a local extremum (for $f(x)=k,$ derivative${}=0$) at $x=0$",Is it a necessary condition for an even function to have a local extremum (for  derivative) at,"f(x)=k, {}=0 x=0","Let $f(x)$ be an even function ( $f(-x)=f(x)$ ) if $f(x)$ is continuous and differentiable at $x = 0$ will it be necessary for it to have a local extremum? Or more generally, have it's derivative $=0$ at $x=0$ ? I thought this as: $$f(x+h)-f(x)=f(x-h)-f(x) \\ \text{(for $x=0 , h>0$)}$$ so the derivative should also be zero. Am I correct or is there a counter example?","Let be an even function ( ) if is continuous and differentiable at will it be necessary for it to have a local extremum? Or more generally, have it's derivative at ? I thought this as: so the derivative should also be zero. Am I correct or is there a counter example?","f(x) f(-x)=f(x) f(x) x = 0 =0 x=0 f(x+h)-f(x)=f(x-h)-f(x) \\ \text{(for x=0 , h>0)}","['calculus', 'derivatives']"
95,Inequality proof. Bounded second derivative.,Inequality proof. Bounded second derivative.,,Given $|f’’(x)| < c$ for all Real values of $x$ and a $c > 0$ . Prove the following inequality: $$| f(x+1) + f(x-1) - 2f(x)| < 2c $$ So I’m relatively sure it has something to do with the second difference formula. But I’m not entirely sure how to make sense of it. Difference formula: $$ f’’(x) =  ( f(x + h) + f( x- h ) - 2f(x))/h.  (h -> 0)$$,Given for all Real values of and a . Prove the following inequality: So I’m relatively sure it has something to do with the second difference formula. But I’m not entirely sure how to make sense of it. Difference formula:,|f’’(x)| < c x c > 0 | f(x+1) + f(x-1) - 2f(x)| < 2c   f’’(x) =  ( f(x + h) + f( x- h ) - 2f(x))/h.  (h -> 0),"['real-analysis', 'calculus', 'derivatives', 'inequality']"
96,Can't get the right result for a derivative of a trigonometric function,Can't get the right result for a derivative of a trigonometric function,,"so I need to find the derivative of the following expression: $$y=(-\csc x)(-\sin x)$$ This is what I have done so far by applying the product rule: $$y'=\csc x\cot x(-\sin x) + (-\csc x)(-\cos x)=-\sin x\csc x\cot x + \csc x\cos x$$ $$y'=\csc x(-\sin x\cot x + \cos x)$$ Unfortunately, my textbook displays the result as: $$y'=\cos x\cot^2x$$ Am I doing something wrong, or both results are equivalent? If they are equivalent, can someone show me step by step how to get to the textbook's result? Thank you so much in advance!","so I need to find the derivative of the following expression: This is what I have done so far by applying the product rule: Unfortunately, my textbook displays the result as: Am I doing something wrong, or both results are equivalent? If they are equivalent, can someone show me step by step how to get to the textbook's result? Thank you so much in advance!",y=(-\csc x)(-\sin x) y'=\csc x\cot x(-\sin x) + (-\csc x)(-\cos x)=-\sin x\csc x\cot x + \csc x\cos x y'=\csc x(-\sin x\cot x + \cos x) y'=\cos x\cot^2x,"['real-analysis', 'calculus', 'analysis', 'derivatives', 'trigonometry']"
97,Where does the $dy$ go in the process of integration?,Where does the  go in the process of integration?,dy,"I'm currently looking at integration (calculus 1). For example $y = \int 3x dx$ I don't understand how we ended up with just "" $y$ "" on the left hand side. For example $dy/dx = 3x$ , then $dy = 3x dx$ so $\int dy = \int 3x dx$ which is not the same. Is $\int dy$ somehow the same as $y$ ? I get confused as some use $dx$ as just notation while others actually use it as a term that can be moved around.","I'm currently looking at integration (calculus 1). For example I don't understand how we ended up with just "" "" on the left hand side. For example , then so which is not the same. Is somehow the same as ? I get confused as some use as just notation while others actually use it as a term that can be moved around.",y = \int 3x dx y dy/dx = 3x dy = 3x dx \int dy = \int 3x dx \int dy y dx,"['calculus', 'integration', 'derivatives']"
98,"Find absolute extrema of $f(x)=\begin{cases}x^2-1,&x<1,\\\ln(x),&x\geq1\end{cases}$",Find absolute extrema of,"f(x)=\begin{cases}x^2-1,&x<1,\\\ln(x),&x\geq1\end{cases}","Find absolute extrema of $$f(x)=\begin{cases}x^2-1,&x<1,\\\ln(x),&x\geq1.\end{cases}$$ I could find the critical points by setting $f'(x)=0$ : $$f'(x)=\begin{cases}2x,&x<1,\\\dfrac{1}{x},&x\geq1\end{cases}=0\implies2x=0\implies x=0,$$ and $$f''(x)=\begin{cases}2,&x<1,\\-\dfrac{1}{x^2},&x\geq1\end{cases}\implies f''(0)=2>0,$$ therefore $x=0$ is a relative minimum of $f$ , which has value $f(0)=-1$ : How can we prove that it is also an absolute minimum? I tried the following: It is not hard to see that $x^2-1\geq-1$ for $x<1$ , and $\ln(x)\geq0$ for $x\geq1$ . Combining these, $x=-1$ is the first of the upper bounds of $f$ , so $x=-1$ is an absolute minimum. Is it correct? If not, how would you prove it? Thanks!!","Find absolute extrema of I could find the critical points by setting : and therefore is a relative minimum of , which has value : How can we prove that it is also an absolute minimum? I tried the following: It is not hard to see that for , and for . Combining these, is the first of the upper bounds of , so is an absolute minimum. Is it correct? If not, how would you prove it? Thanks!!","f(x)=\begin{cases}x^2-1,&x<1,\\\ln(x),&x\geq1.\end{cases} f'(x)=0 f'(x)=\begin{cases}2x,&x<1,\\\dfrac{1}{x},&x\geq1\end{cases}=0\implies2x=0\implies x=0, f''(x)=\begin{cases}2,&x<1,\\-\dfrac{1}{x^2},&x\geq1\end{cases}\implies f''(0)=2>0, x=0 f f(0)=-1 x^2-1\geq-1 x<1 \ln(x)\geq0 x\geq1 x=-1 f x=-1","['calculus', 'proof-verification', 'derivatives']"
99,Explain why $\frac{d}{dx} \frac{x}{x+1}= \frac{d}{dx}\frac{-1}{x+1}$ and what does the Mean Value Theorem have to do with it?,Explain why  and what does the Mean Value Theorem have to do with it?,\frac{d}{dx} \frac{x}{x+1}= \frac{d}{dx}\frac{-1}{x+1},"My Calculus 1 professor gave us this problem to help us prepare for the final exam. I can show $\frac{d}{dx} \frac{x}{x+1}= \frac{d}{dx}\frac{-1}{x+1}$ and explain why $\frac{d}{dx} \frac{x}{x+1}= \frac{d}{dx}\frac{-1}{x+1}$ is the case, but I have no idea what it has to do with the Mean Value Theorem. Could someone please help me understand what the Mean Value Theorem has to do with this? Mean Value Theorem: If $f(x)$ is defined and continuous on the interval $[a, b]$ and differentiable on $(a,b)$ then there is at least one number $c$ such that $$f'(c)=\frac{f(b)-f(a)}{b-a}$$ Problem Text: Show that $\frac{d}{dx} \frac{x}{x+1}= \frac{d}{dx}\frac{-1}{x+1}$ even though $\frac{x}{x+1} \neq \frac{-1}{x+1}$ . Why is this true and what does the Mean Value Theorem have to do with it?","My Calculus 1 professor gave us this problem to help us prepare for the final exam. I can show and explain why is the case, but I have no idea what it has to do with the Mean Value Theorem. Could someone please help me understand what the Mean Value Theorem has to do with this? Mean Value Theorem: If is defined and continuous on the interval and differentiable on then there is at least one number such that Problem Text: Show that even though . Why is this true and what does the Mean Value Theorem have to do with it?","\frac{d}{dx} \frac{x}{x+1}= \frac{d}{dx}\frac{-1}{x+1} \frac{d}{dx} \frac{x}{x+1}= \frac{d}{dx}\frac{-1}{x+1} f(x) [a, b] (a,b) c f'(c)=\frac{f(b)-f(a)}{b-a} \frac{d}{dx} \frac{x}{x+1}= \frac{d}{dx}\frac{-1}{x+1} \frac{x}{x+1} \neq \frac{-1}{x+1}","['calculus', 'derivatives']"
