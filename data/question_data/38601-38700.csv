,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Finite abelian group generated by elements of maximal order,Finite abelian group generated by elements of maximal order,,"I'm trying to prove that a finite abelian group $G$ is generated by elements of maximal order. I can sort of see why that happens in a vague instinctive kind of way but no real hard logic. So far, I have tried to use this lemma: Let $G$ be a finite abelian group and a be an element of maximal order in $G$. Then any element $b$ is such that $|b|$ divides $|a|$. Then each cyclic group generated by the maximal order element contains exactly 1 element of each possible order for an element in the group. I have tried expanding from this idea in a few directions but I don't think it's the correct way to go since it's not going anywhere. Any help appreciated. Thanks guys.","I'm trying to prove that a finite abelian group $G$ is generated by elements of maximal order. I can sort of see why that happens in a vague instinctive kind of way but no real hard logic. So far, I have tried to use this lemma: Let $G$ be a finite abelian group and a be an element of maximal order in $G$. Then any element $b$ is such that $|b|$ divides $|a|$. Then each cyclic group generated by the maximal order element contains exactly 1 element of each possible order for an element in the group. I have tried expanding from this idea in a few directions but I don't think it's the correct way to go since it's not going anywhere. Any help appreciated. Thanks guys.",,"['abstract-algebra', 'group-theory']"
1,Show $\mathbb{Z}[\sqrt{6}]$ is a Euclidean domain,Show  is a Euclidean domain,\mathbb{Z}[\sqrt{6}],"I'm attempting to modify the proof the $\mathbb{Z}[\sqrt{2}]$ is a Euclidean domain to prove a similar result for $\mathbb{Z}[\sqrt{6}]$. The idea is to prove that $\mathbb{Q}[\sqrt{6}]$ is Euclidean which will then give the result for  $\mathbb{Z}[\sqrt{6}]$. According to Dummit and Foote's Abstract Algebra this should have norm $d(a+b\sqrt{6})=|a^2-6b^2|$. The result for $\mathbb{Z}[\sqrt{2}]$ relies on the fact that for any element $x$ in $\mathbb{Q}[\sqrt{2}]$ there is an element $x'$ in $\mathbb{Z}[\sqrt{2}]$ with $d(x-x')<1$, which is then used to show that for $x=qy+r$ we have $$ d(r)=d(x-qy)=d\left(y\left(\frac{x}{y}-q\right)\right)=d(y)d\left(\frac{x}{y}-q\right)<d(y) $$ But in this case, I'm having a hard time showing that we can find an element with $d(x-x')<1$ for $x\in\mathbb{Q}[\sqrt{6}], x'\in\mathbb{Z}[\sqrt{6}]$. Consider $x=a+b\sqrt{6}\in\mathbb{Q}[\sqrt{6}]$. The furthest this element can be away from any $x'=a'+b'\sqrt{6}\in\mathbb{Z}[\sqrt{6}]$ is when $|a-a'|=\frac{1}{2}=|b-b'| \Rightarrow$ $$ d(x-x')=\left|\left(\frac{1}{2}\right)^2-6\left(\frac{1}{2}\right)^2\right|=\frac{5}{4}>1 $$ What can I do to get around this issue?","I'm attempting to modify the proof the $\mathbb{Z}[\sqrt{2}]$ is a Euclidean domain to prove a similar result for $\mathbb{Z}[\sqrt{6}]$. The idea is to prove that $\mathbb{Q}[\sqrt{6}]$ is Euclidean which will then give the result for  $\mathbb{Z}[\sqrt{6}]$. According to Dummit and Foote's Abstract Algebra this should have norm $d(a+b\sqrt{6})=|a^2-6b^2|$. The result for $\mathbb{Z}[\sqrt{2}]$ relies on the fact that for any element $x$ in $\mathbb{Q}[\sqrt{2}]$ there is an element $x'$ in $\mathbb{Z}[\sqrt{2}]$ with $d(x-x')<1$, which is then used to show that for $x=qy+r$ we have $$ d(r)=d(x-qy)=d\left(y\left(\frac{x}{y}-q\right)\right)=d(y)d\left(\frac{x}{y}-q\right)<d(y) $$ But in this case, I'm having a hard time showing that we can find an element with $d(x-x')<1$ for $x\in\mathbb{Q}[\sqrt{6}], x'\in\mathbb{Z}[\sqrt{6}]$. Consider $x=a+b\sqrt{6}\in\mathbb{Q}[\sqrt{6}]$. The furthest this element can be away from any $x'=a'+b'\sqrt{6}\in\mathbb{Z}[\sqrt{6}]$ is when $|a-a'|=\frac{1}{2}=|b-b'| \Rightarrow$ $$ d(x-x')=\left|\left(\frac{1}{2}\right)^2-6\left(\frac{1}{2}\right)^2\right|=\frac{5}{4}>1 $$ What can I do to get around this issue?",,"['abstract-algebra', 'commutative-algebra']"
2,the image of $1$ by a homomorphism between unitary rings,the image of  by a homomorphism between unitary rings,1,"let $R$ and $S$ be unitary rings and $\phi:R\rightarrow S$ a ring homomorphism. is the following correct: $\phi(1_R)=\phi(1_R\cdot1_R)=\phi(1_R)\cdot\phi(1_R)$ so $\phi(1_R)(1_S-\phi(1_R))=0_S$ and so $\phi(1_R)$ could be anything in $S$ when $S$ is a general ring, i mean we can not conclude what values $\phi(1_R)$ could take in $S$ . But when $S$ is an integral domain then we can say that we have $\phi(1_R)=0_S$ or $1_S-\phi(1_R)=0_S$ i.e, $\phi(1_R)=1_S$. Moreover when $\phi$ is a monomorphism then since only $0_R$ maps to $0_S$ then necessarily   $\phi(1_R)=1_S$.","let $R$ and $S$ be unitary rings and $\phi:R\rightarrow S$ a ring homomorphism. is the following correct: $\phi(1_R)=\phi(1_R\cdot1_R)=\phi(1_R)\cdot\phi(1_R)$ so $\phi(1_R)(1_S-\phi(1_R))=0_S$ and so $\phi(1_R)$ could be anything in $S$ when $S$ is a general ring, i mean we can not conclude what values $\phi(1_R)$ could take in $S$ . But when $S$ is an integral domain then we can say that we have $\phi(1_R)=0_S$ or $1_S-\phi(1_R)=0_S$ i.e, $\phi(1_R)=1_S$. Moreover when $\phi$ is a monomorphism then since only $0_R$ maps to $0_S$ then necessarily   $\phi(1_R)=1_S$.",,"['ring-theory', 'abstract-algebra']"
3,Finding the norm in the cyclotomic field $\mathbb{Q}(e^{2\pi i / 5})$,Finding the norm in the cyclotomic field,\mathbb{Q}(e^{2\pi i / 5}),"I'm doing one of the exercises of Stewart and Tall's book on Algebraic Number Theory. The problem concerns finding an expression for the norm in the cyclotomic field $K = \mathbb{Q}(e^{2\pi i / 5})$. The exact problem is the following: If $\zeta = e^{2 \pi i / 5}$, $K = \mathbb{Q}(e^{2\pi i / 5})$, prove that the norm of $\alpha \in \mathbb{Z}[\zeta]$ is of the form $\frac{1}{4}(A^2 -5B^2)$ where $A, B \in \mathbb{Z}$. ( Hint: In calculating $\textbf{N}(\alpha)$, first calculate $\sigma_1 (\alpha) \sigma_4 (\alpha)$ where $\sigma_i (\zeta) := \zeta^{i}$. Show that this is of the form $q + r\theta + s\phi$ where $q, r, s \in \mathbb{Z}$, $\theta = \zeta + \zeta^{4}$ and $\phi = \zeta^{2} + \zeta^{3}$. In the same way establish $\sigma_2 (\alpha) \sigma_3 (\alpha) = q + s\theta + r\phi$  ) Using Exercise $3$ prove that $\mathbb{Z}[\zeta]$ has an infinite number of units. Now, I've already done what the hint says and arrived at the following. If we let $\alpha = a +b\zeta^{} + c\zeta^{2} + d\zeta^{3} \in \mathbb{Z}[\zeta]$ then after simplifying I get $$\textbf{N}(\alpha) = \sigma_1 (\alpha) \sigma_4 (\alpha) \sigma_2(\alpha) \sigma_3(\alpha) = ( q + r\theta + s\phi ) ( q + s\theta + r\phi )$$ $$ = q^2 + (qr + qs)(\theta + \phi) + rs(\theta^2 + \phi^2) + (r^2 + s^2)\theta \phi$$ and then it is not that hard to see that $\theta + \phi = -1$, $\theta^2 + \phi^2 = 3$ and $\theta \phi = -1$ so that in the end one obtains $$\textbf{N}(\alpha) = q^2 - (qr + qs) + 3rs - (r^2 + s^2)$$ where $q = a^2 + b^2 + c^2 + d^2$, $r = ab + bc + cd$ and $s = ac + ad + bd$. Now, here I got stuck because I just can't take the last expression for the norm into the form that the exercise wants. The purpose is to get that nice form for the norm to find units by solving the diophantine equation $\textbf{N}(\alpha) = \pm 1$, which is what the Exercise $3$ mentioned in the statatement of the problem is about. I already know how to prove the existence of infinitely many units in $\mathbb{Z}[\zeta]$ (without using Dirichlet's Unit Theorem of course), but the exercise also demands a proof that the norm is equal to $\frac{1}{4}(A^2 -5B^2)$. I even asked my professor about this and we were not able to get the desired form for the norm. So my question is if anybody knows how to prove that the norm has that form, and if so, how can I show that? Or if it could be that maybe the hint given in the exercise is not that helpful? Thanks a lot in advance for any help with this. EDIT After looking at Derek Jennings' answer below, to get from the expression I had for the norm to the one in Derek's answer is just a matter of taking out a common factor of $1/4$ in the expression and then completing the square, $$\textbf{N}(\alpha) = q^2 - (qr + qs) + 3rs - (r^2 + s^2) = q^2 - q(r+s) + rs - (r-s)^2$$ $$ = \frac{1}{4}( 4q^2 - 4q(r+s) + 4rs - 4(r-s)^2  ) $$ $$=  \frac{1}{4} ( 4q^2 - 4q(r+s) +\overbrace{(r+s)^2} - \overbrace{(r+s)^2} + 4rs - 4(r-s)^2  )$$ $$ = \frac{1}{4} ( (2q -(r+s))^2 -(r-s)^2 - 4(r-s)^2 )$$ $$ = \frac{1}{4}( (2q - r - s)^2 - 5(r-s)^2 ) = \frac{1}{4}(A^2 - 5B^2),$$ as desired. Of course it is easier if you already know what to get at =)","I'm doing one of the exercises of Stewart and Tall's book on Algebraic Number Theory. The problem concerns finding an expression for the norm in the cyclotomic field $K = \mathbb{Q}(e^{2\pi i / 5})$. The exact problem is the following: If $\zeta = e^{2 \pi i / 5}$, $K = \mathbb{Q}(e^{2\pi i / 5})$, prove that the norm of $\alpha \in \mathbb{Z}[\zeta]$ is of the form $\frac{1}{4}(A^2 -5B^2)$ where $A, B \in \mathbb{Z}$. ( Hint: In calculating $\textbf{N}(\alpha)$, first calculate $\sigma_1 (\alpha) \sigma_4 (\alpha)$ where $\sigma_i (\zeta) := \zeta^{i}$. Show that this is of the form $q + r\theta + s\phi$ where $q, r, s \in \mathbb{Z}$, $\theta = \zeta + \zeta^{4}$ and $\phi = \zeta^{2} + \zeta^{3}$. In the same way establish $\sigma_2 (\alpha) \sigma_3 (\alpha) = q + s\theta + r\phi$  ) Using Exercise $3$ prove that $\mathbb{Z}[\zeta]$ has an infinite number of units. Now, I've already done what the hint says and arrived at the following. If we let $\alpha = a +b\zeta^{} + c\zeta^{2} + d\zeta^{3} \in \mathbb{Z}[\zeta]$ then after simplifying I get $$\textbf{N}(\alpha) = \sigma_1 (\alpha) \sigma_4 (\alpha) \sigma_2(\alpha) \sigma_3(\alpha) = ( q + r\theta + s\phi ) ( q + s\theta + r\phi )$$ $$ = q^2 + (qr + qs)(\theta + \phi) + rs(\theta^2 + \phi^2) + (r^2 + s^2)\theta \phi$$ and then it is not that hard to see that $\theta + \phi = -1$, $\theta^2 + \phi^2 = 3$ and $\theta \phi = -1$ so that in the end one obtains $$\textbf{N}(\alpha) = q^2 - (qr + qs) + 3rs - (r^2 + s^2)$$ where $q = a^2 + b^2 + c^2 + d^2$, $r = ab + bc + cd$ and $s = ac + ad + bd$. Now, here I got stuck because I just can't take the last expression for the norm into the form that the exercise wants. The purpose is to get that nice form for the norm to find units by solving the diophantine equation $\textbf{N}(\alpha) = \pm 1$, which is what the Exercise $3$ mentioned in the statatement of the problem is about. I already know how to prove the existence of infinitely many units in $\mathbb{Z}[\zeta]$ (without using Dirichlet's Unit Theorem of course), but the exercise also demands a proof that the norm is equal to $\frac{1}{4}(A^2 -5B^2)$. I even asked my professor about this and we were not able to get the desired form for the norm. So my question is if anybody knows how to prove that the norm has that form, and if so, how can I show that? Or if it could be that maybe the hint given in the exercise is not that helpful? Thanks a lot in advance for any help with this. EDIT After looking at Derek Jennings' answer below, to get from the expression I had for the norm to the one in Derek's answer is just a matter of taking out a common factor of $1/4$ in the expression and then completing the square, $$\textbf{N}(\alpha) = q^2 - (qr + qs) + 3rs - (r^2 + s^2) = q^2 - q(r+s) + rs - (r-s)^2$$ $$ = \frac{1}{4}( 4q^2 - 4q(r+s) + 4rs - 4(r-s)^2  ) $$ $$=  \frac{1}{4} ( 4q^2 - 4q(r+s) +\overbrace{(r+s)^2} - \overbrace{(r+s)^2} + 4rs - 4(r-s)^2  )$$ $$ = \frac{1}{4} ( (2q -(r+s))^2 -(r-s)^2 - 4(r-s)^2 )$$ $$ = \frac{1}{4}( (2q - r - s)^2 - 5(r-s)^2 ) = \frac{1}{4}(A^2 - 5B^2),$$ as desired. Of course it is easier if you already know what to get at =)",,"['abstract-algebra', 'algebraic-number-theory']"
4,On which structures does the free group 'naturally' act?,On which structures does the free group 'naturally' act?,,"One of the best ways to get a handle on a group is to recognize it as isomorphic to a set of symmetries of some structure. The dihedral group of order $2n$ is easily recognized as the set of symmetries of a regular $n$-gon, the symmetric group as the permutations of a set, the Klein-four group as the symmetries of the 'cross'---one pair of opposing prongs are longer than the other pair. The previous descriptions are also in a sense 'exhaustive': every 'sensible' symmetry you could conceive of those structures is represented by some element of the group. An example where the group is not exhaustive over its structure is $C_n$ over the regular $n$-gon (reflection is missing), or $A_n$ over the set of $n$ elements. I wish to know of a structure that a free group---specifically $F_2$---naturally acts on which it is also in a sense 'exhaustive'. I'm aware of $F_2$'s Cayley graph, but I want other examples. EDIT The question may have been a bit unfair and imprecise, but I can't help that it is really. One of the reasons it may be unfair is that 'exhaustive' is a bit subjective. For example, I myself cannot point out a structure that $C_n$ naturally acts on that $D_{2n}$ could not be conceived of as acting on also; however, both of these groups also sit in $S_n$ in a more-or-less canonical fashion. But there are structures, such as polygons, that we think of as $D_{2n}$ acting on naturally rather than $S_n$. I'm trying to find structures such that when we think of their 'natural' set of symmetries, the group of these symmetries would be isomorphic to a free group. I want a couple of examples, as I'm slightly disappointed in having only the Cayley graph or finite tuples of words as a reference. Other groups have many examples of acting on a structure. For example the Klein four group could also be realized as the symmetries of a proper rectangle, $A_4$ can be realized as the rigid motions of the tetrahedron rather than the even permutations of a 4-element set. I also don't want these examples to be 'cheap'. What I mean by this is that the action is not arrived at by quotienting by a normal subgroup to get an action that is more properly realized by another group.","One of the best ways to get a handle on a group is to recognize it as isomorphic to a set of symmetries of some structure. The dihedral group of order $2n$ is easily recognized as the set of symmetries of a regular $n$-gon, the symmetric group as the permutations of a set, the Klein-four group as the symmetries of the 'cross'---one pair of opposing prongs are longer than the other pair. The previous descriptions are also in a sense 'exhaustive': every 'sensible' symmetry you could conceive of those structures is represented by some element of the group. An example where the group is not exhaustive over its structure is $C_n$ over the regular $n$-gon (reflection is missing), or $A_n$ over the set of $n$ elements. I wish to know of a structure that a free group---specifically $F_2$---naturally acts on which it is also in a sense 'exhaustive'. I'm aware of $F_2$'s Cayley graph, but I want other examples. EDIT The question may have been a bit unfair and imprecise, but I can't help that it is really. One of the reasons it may be unfair is that 'exhaustive' is a bit subjective. For example, I myself cannot point out a structure that $C_n$ naturally acts on that $D_{2n}$ could not be conceived of as acting on also; however, both of these groups also sit in $S_n$ in a more-or-less canonical fashion. But there are structures, such as polygons, that we think of as $D_{2n}$ acting on naturally rather than $S_n$. I'm trying to find structures such that when we think of their 'natural' set of symmetries, the group of these symmetries would be isomorphic to a free group. I want a couple of examples, as I'm slightly disappointed in having only the Cayley graph or finite tuples of words as a reference. Other groups have many examples of acting on a structure. For example the Klein four group could also be realized as the symmetries of a proper rectangle, $A_4$ can be realized as the rigid motions of the tetrahedron rather than the even permutations of a 4-element set. I also don't want these examples to be 'cheap'. What I mean by this is that the action is not arrived at by quotienting by a normal subgroup to get an action that is more properly realized by another group.",,"['abstract-algebra', 'group-theory']"
5,Prove that there isn't a polynomial with $\text {f(x)}^{13} = {(x-1)}^{143}+(x+1)^{2002}$,Prove that there isn't a polynomial with,\text {f(x)}^{13} = {(x-1)}^{143}+(x+1)^{2002},Prove that there isn't a polynomial with  $\text {f(x)}^{13} = {(x-1)}^{143}+(x+1)^{2002}$ We can easily find out that  $\text {deg}(f) = 154$ Then?,Prove that there isn't a polynomial with  $\text {f(x)}^{13} = {(x-1)}^{143}+(x+1)^{2002}$ We can easily find out that  $\text {deg}(f) = 154$ Then?,,"['abstract-algebra', 'polynomials']"
6,Generalization of index 2 subgroups are normal,Generalization of index 2 subgroups are normal,,"Let $G$ be a finite group and $H$ a subgroup of index $p$, where $p$ is a prime. If $\operatorname{gcd}(|H|, p-1)=1$, then $H$ must be normal. Does somebody have a quick proof of this?","Let $G$ be a finite group and $H$ a subgroup of index $p$, where $p$ is a prime. If $\operatorname{gcd}(|H|, p-1)=1$, then $H$ must be normal. Does somebody have a quick proof of this?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'symmetric-groups']"
7,Given a commutative ring $R$ and an epimorphism of free modules $R^m \to R^n$ is then $m \geq n$?,Given a commutative ring  and an epimorphism of free modules  is then ?,R R^m \to R^n m \geq n,"If $\varphi:R^{m}\to R^{n}$ is an epimorphism of free modules over a nontrivial commutative ring, does it follow that $m \geq n$ ? This is obviously true for vector spaces over a field, but how would one show this over just a commutative ring? -----Edit Is there any way to use the following? If $\varphi : M \to M'$ is an epimorphism of left $S$ -modules and $N$ is any right $S$ -module then $id_N \otimes \varphi $ is an epimorphism.","If is an epimorphism of free modules over a nontrivial commutative ring, does it follow that ? This is obviously true for vector spaces over a field, but how would one show this over just a commutative ring? -----Edit Is there any way to use the following? If is an epimorphism of left -modules and is any right -module then is an epimorphism.",\varphi:R^{m}\to R^{n} m \geq n \varphi : M \to M' S N S id_N \otimes \varphi ,"['abstract-algebra', 'commutative-algebra', 'ring-theory', 'modules', 'tensor-products']"
8,My proof: Frobenius Map generates $\mbox{Gal}(\mathbb F_{p^n}/\mathbb F_p)$,My proof: Frobenius Map generates,\mbox{Gal}(\mathbb F_{p^n}/\mathbb F_p),"I would like to ask, whether anyone can confirm or correct the following version of the proof that the Frobenius map generates the Galois Group of a finite field. Proof First note that $\newcommand{\Fpn}{\mathbb F_{p^n}}\newcommand{\Fp}{\mathbb F_p}\newcommand{\GalFpn}{\mbox{Gal}(\Fpn/\Fp)}\#\GalFpn=[\Fpn:\Fp]=n$. I want to show that the Frobenius map $\newcommand{\Fr}{\mbox{Fr}}\Fr:\Fpn\rightarrow\Fpn$ given by $\alpha\mapsto\alpha^p$ generates the Galois Group of the extension $\Fpn\supset\Fp$. To see this I will show the following two statements. $\Fr$ is an element of $\GalFpn$ $\Fr$ has order $n$ Statement 1 Since the group $\Fp^*$ has $p-1$ elements is follows that $a\in\Fp$ satisfies $a^{p-1}=1$ so that $\Fr(a)=a^p=a$. This shows that $\Fr$ fixes $\Fp$. Now note that $\Fr$ is injective since $\alpha^p=0$ if and only if $\alpha=0$ (there are no zero divisors in a field). Since we have a finite field $\Fpn$ an injective map is also surjective. This shows that $\Fr$ is bijective so $\Fr$ is contained in $\GalFpn$. Statement 2 Next we must establish that $\Fr$ has order $n$. Consider the multiplicative group $\Fpn^*$. This is a cyclic group with $p^n-1$ elements, so we have an $\alpha\in\Fpn$ of order $p^n-1$. Thus $$ \alpha^p,\alpha^{p^2},...,\alpha^{p^n} $$ will be $n$ distinct elements which is really just to say that $$ \Fr(\alpha),\Fr^2(\alpha),...,\Fr^n(\alpha) $$ are $n$ distinct elements. This shows that $\Fr$ has order $n$ so that it generates $\GalFpn$.","I would like to ask, whether anyone can confirm or correct the following version of the proof that the Frobenius map generates the Galois Group of a finite field. Proof First note that $\newcommand{\Fpn}{\mathbb F_{p^n}}\newcommand{\Fp}{\mathbb F_p}\newcommand{\GalFpn}{\mbox{Gal}(\Fpn/\Fp)}\#\GalFpn=[\Fpn:\Fp]=n$. I want to show that the Frobenius map $\newcommand{\Fr}{\mbox{Fr}}\Fr:\Fpn\rightarrow\Fpn$ given by $\alpha\mapsto\alpha^p$ generates the Galois Group of the extension $\Fpn\supset\Fp$. To see this I will show the following two statements. $\Fr$ is an element of $\GalFpn$ $\Fr$ has order $n$ Statement 1 Since the group $\Fp^*$ has $p-1$ elements is follows that $a\in\Fp$ satisfies $a^{p-1}=1$ so that $\Fr(a)=a^p=a$. This shows that $\Fr$ fixes $\Fp$. Now note that $\Fr$ is injective since $\alpha^p=0$ if and only if $\alpha=0$ (there are no zero divisors in a field). Since we have a finite field $\Fpn$ an injective map is also surjective. This shows that $\Fr$ is bijective so $\Fr$ is contained in $\GalFpn$. Statement 2 Next we must establish that $\Fr$ has order $n$. Consider the multiplicative group $\Fpn^*$. This is a cyclic group with $p^n-1$ elements, so we have an $\alpha\in\Fpn$ of order $p^n-1$. Thus $$ \alpha^p,\alpha^{p^2},...,\alpha^{p^n} $$ will be $n$ distinct elements which is really just to say that $$ \Fr(\alpha),\Fr^2(\alpha),...,\Fr^n(\alpha) $$ are $n$ distinct elements. This shows that $\Fr$ has order $n$ so that it generates $\GalFpn$.",,"['abstract-algebra', 'galois-theory', 'proof-verification', 'finite-fields']"
9,Center of Direct Product is the Direct Product of Centers,Center of Direct Product is the Direct Product of Centers,,"The exercise for which I am seeking feedback wants me to prove that the center of a direct product is the direct product of the centers. That is, $$Z(G_1 \times \cdots \times G_n)=Z(G_1) \times \cdots \times Z(G_n).$$ Attempt at Solution: We proceed by induction on $n$ . First, we prove our desired for $n=2$ ; this will establish our basis step. Let $(g_{1},g_{2}) \in Z(G_{1} \times G_{2})$ . Then $(g_{1},g_{2})(x_{1},x_{2})=(x_{1},x_{2})(g_{1},g_{2})$ for all $(x_{1},x_{2}) \in G_{1} \times G_{2}.$ This implies $g_{1}x_{1}=x_{1}g_{1}$ and $g_{2}x_{2}=x_{2}g_{2}$ for all $x_{1} \in G_{1}$ and for all $x_{2} \in G_{2}$ . Hence, $g_{1} \in Z(G_{1})$ and $g_{2} \in Z(G_{2})$ . To prove the reverse inclusion, this time let $(g_{1},g_{2}) \in Z(G_{1}) \times Z(G_{2})$ Then, $g_{1}x_{1}=x_{1}g_{1}$ and $g_{2}x_{2}=x_{2}g_{2}$ for all $x_{1} \in G_{1}$ and for all $x_{2} \in G_{2}$ ; it, of course, follows that $(g_{1},g_{2})(x_{1},x_{2})=(x_{1},x_{2})(g_{1},g_{2})$ for all $(x_{1},x_{2}) \in G_{1} \times G_{2}.$ Indeed, $(g_{1},g_{2}) \in Z(G_{1} \times G_{2})$ For our induction step, assume that desired result holds for some $n$ ; that is, assume $$Z(G_1 \times \cdots \times G_n)=Z(G_1) \times \cdots \times Z(G_n).$$ We show $$Z(G_1 \times \cdots \times G_n \times G_{n+1})=Z(G_1) \times \cdots \times Z(G_n) \times Z(G_{n+1}).$$ By our basis step, $$Z(G_1 \times \cdots \times G_n \times G_{n+1})=Z(G_1 \times \cdots \times G_n) \times Z(G_{n+1}).$$ Then, using our induction hypothesis, we obtain $$Z(G_1 \times \cdots \times G_n) \times Z(G_{n+1})=Z(G_1) \times \cdots \times Z(G_n) \times Z(G_{n+1}).$$ Hence, our induction step has been established. Finally, by the principle of mathematical induction, we conclude $$Z(G_1 \times \cdots \times G_n)=Z(G_1) \times \cdots \times Z(G_n),$$ for any finite collection of groups $G_{1}, \ldots , G_{n}.$ $\blacksquare$ Question: This may be a stupid question; but, I'll ask anyway! Would it be wrong if I completed the proof by letting $(g_{1},\ldots , g_{n}) \in Z(G_1 \times \cdots \times G_n)$ and showing $(g_{1},\ldots , g_{n}) \in Z(G_1) \times \cdots \times Z(G_n)$ ? (Then, of course, proceed by proving the reverse inclusion.) Thank you!","The exercise for which I am seeking feedback wants me to prove that the center of a direct product is the direct product of the centers. That is, Attempt at Solution: We proceed by induction on . First, we prove our desired for ; this will establish our basis step. Let . Then for all This implies and for all and for all . Hence, and . To prove the reverse inclusion, this time let Then, and for all and for all ; it, of course, follows that for all Indeed, For our induction step, assume that desired result holds for some ; that is, assume We show By our basis step, Then, using our induction hypothesis, we obtain Hence, our induction step has been established. Finally, by the principle of mathematical induction, we conclude for any finite collection of groups Question: This may be a stupid question; but, I'll ask anyway! Would it be wrong if I completed the proof by letting and showing ? (Then, of course, proceed by proving the reverse inclusion.) Thank you!","Z(G_1 \times \cdots \times G_n)=Z(G_1) \times \cdots \times Z(G_n). n n=2 (g_{1},g_{2}) \in Z(G_{1} \times G_{2}) (g_{1},g_{2})(x_{1},x_{2})=(x_{1},x_{2})(g_{1},g_{2}) (x_{1},x_{2}) \in G_{1} \times G_{2}. g_{1}x_{1}=x_{1}g_{1} g_{2}x_{2}=x_{2}g_{2} x_{1} \in G_{1} x_{2} \in G_{2} g_{1} \in Z(G_{1}) g_{2} \in Z(G_{2}) (g_{1},g_{2}) \in Z(G_{1}) \times Z(G_{2}) g_{1}x_{1}=x_{1}g_{1} g_{2}x_{2}=x_{2}g_{2} x_{1} \in G_{1} x_{2} \in G_{2} (g_{1},g_{2})(x_{1},x_{2})=(x_{1},x_{2})(g_{1},g_{2}) (x_{1},x_{2}) \in G_{1} \times G_{2}. (g_{1},g_{2}) \in Z(G_{1} \times G_{2}) n Z(G_1 \times \cdots \times G_n)=Z(G_1) \times \cdots \times Z(G_n). Z(G_1 \times \cdots \times G_n \times G_{n+1})=Z(G_1) \times \cdots \times Z(G_n) \times Z(G_{n+1}). Z(G_1 \times \cdots \times G_n \times G_{n+1})=Z(G_1 \times \cdots \times G_n) \times Z(G_{n+1}). Z(G_1 \times \cdots \times G_n) \times Z(G_{n+1})=Z(G_1) \times \cdots \times Z(G_n) \times Z(G_{n+1}). Z(G_1 \times \cdots \times G_n)=Z(G_1) \times \cdots \times Z(G_n), G_{1}, \ldots , G_{n}. \blacksquare (g_{1},\ldots , g_{n}) \in Z(G_1 \times \cdots \times G_n) (g_{1},\ldots , g_{n}) \in Z(G_1) \times \cdots \times Z(G_n)","['abstract-algebra', 'group-theory', 'solution-verification', 'direct-product']"
10,Countable number of subgroups $\implies $ countable group,Countable number of subgroups  countable group,\implies ,I know that if a group $G$ has a finite number of subgroups then the group $G$ is finite. But if a group $G$ has countable number of subgroups then is the group countable?,I know that if a group $G$ has a finite number of subgroups then the group $G$ is finite. But if a group $G$ has countable number of subgroups then is the group countable?,,"['abstract-algebra', 'group-theory', 'set-theory', 'infinite-groups']"
11,Is factoring polynomials easier than factoring integers? [duplicate],Is factoring polynomials easier than factoring integers? [duplicate],,"This question already has answers here : Is factoring polynomials as hard as factoring integers? (3 answers) Closed 10 years ago . I was reading the book Algebra: Chapter 0 , by Paolo Aluffi, and came across the following assertion, in page 290, Exercise 5.9: It is in fact much harder to factor integers than integers polynomials. What I want to know is: What exactly is the meaning of easier . Why is that so? Because it seems quite unintuitive for me that finding a factorization of a high degree polynomial (with a lot of big integer coefficients) should be easier than factoring the degree of polynomial itself.","This question already has answers here : Is factoring polynomials as hard as factoring integers? (3 answers) Closed 10 years ago . I was reading the book Algebra: Chapter 0 , by Paolo Aluffi, and came across the following assertion, in page 290, Exercise 5.9: It is in fact much harder to factor integers than integers polynomials. What I want to know is: What exactly is the meaning of easier . Why is that so? Because it seems quite unintuitive for me that finding a factorization of a high degree polynomial (with a lot of big integer coefficients) should be easier than factoring the degree of polynomial itself.",,"['abstract-algebra', 'polynomials', 'factoring']"
12,Is there a group homomorphism $\Bbb{C}^*\to\Bbb{R}^*$ with a countable kernel?,Is there a group homomorphism  with a countable kernel?,\Bbb{C}^*\to\Bbb{R}^*,"Consider a group homomorphism $f:\Bbb{C}^*\to\Bbb{R}^*$. In a recent question we easily established that $\ker(f)$ is necessarily infinite. The homomorphisms that can be easily described are of the form $$ f(z)=|z|^a $$ for some real constant $a$. All those homomorphisms contain the unit circle in their kernel. This raises the suspicion: Is $\ker (f)$ necessarily uncountable? Not all the homomorphisms are of the above form. The group of positive real numbers is divisible , i.e. all the positive real numbers have positive roots of a given integer order. This implies that in the category of Abelian groups the group $\Bbb{R}_{>0}$ is an injective object (Zorn's lemma is needed to prove this). This implies the existence of other homomorphisms as follows. Let $\omega\in\Bbb{C}$ be a number such that i) $|\omega|=1$, and ii) $\omega^n\neq1$ for all $n\in\Bbb{Z}$, IOW $\omega=e^{2\pi i r}$ for some irrational real number $r$. Let us select $a\in\Bbb{R}_{>0}$, $a\neq1$. Consider the subgroup $H=\langle \omega\rangle\times\Bbb{R}_{>0}\le\Bbb{C}^*$. The rule $$ f_a(\omega^nx)=a^nx, $$ for all $x\in\Bbb{R}_{>0}$, then defines a homomorphism $f_a:H\to\Bbb{R}_{>0}$. By injectivity of the target group we can extend this to a homomorphism $f'_a$ from all of $\Bbb{C}^*$ to $\Bbb{R}_{>0}$ such that $f'_a(\omega)=a\neq1$. But does that really help answer the question? Neither $\Bbb{C}^*$ nor $\Bbb{R}^*$ is finitely generated, so we don't know whether they can be written as a direct product of a torsion group and a free abelian group, or do we?","Consider a group homomorphism $f:\Bbb{C}^*\to\Bbb{R}^*$. In a recent question we easily established that $\ker(f)$ is necessarily infinite. The homomorphisms that can be easily described are of the form $$ f(z)=|z|^a $$ for some real constant $a$. All those homomorphisms contain the unit circle in their kernel. This raises the suspicion: Is $\ker (f)$ necessarily uncountable? Not all the homomorphisms are of the above form. The group of positive real numbers is divisible , i.e. all the positive real numbers have positive roots of a given integer order. This implies that in the category of Abelian groups the group $\Bbb{R}_{>0}$ is an injective object (Zorn's lemma is needed to prove this). This implies the existence of other homomorphisms as follows. Let $\omega\in\Bbb{C}$ be a number such that i) $|\omega|=1$, and ii) $\omega^n\neq1$ for all $n\in\Bbb{Z}$, IOW $\omega=e^{2\pi i r}$ for some irrational real number $r$. Let us select $a\in\Bbb{R}_{>0}$, $a\neq1$. Consider the subgroup $H=\langle \omega\rangle\times\Bbb{R}_{>0}\le\Bbb{C}^*$. The rule $$ f_a(\omega^nx)=a^nx, $$ for all $x\in\Bbb{R}_{>0}$, then defines a homomorphism $f_a:H\to\Bbb{R}_{>0}$. By injectivity of the target group we can extend this to a homomorphism $f'_a$ from all of $\Bbb{C}^*$ to $\Bbb{R}_{>0}$ such that $f'_a(\omega)=a\neq1$. But does that really help answer the question? Neither $\Bbb{C}^*$ nor $\Bbb{R}^*$ is finitely generated, so we don't know whether they can be written as a direct product of a torsion group and a free abelian group, or do we?",,"['abstract-algebra', 'group-theory']"
13,How to prove that the cross product doesn't satisfy any kind of generalized associativity?,How to prove that the cross product doesn't satisfy any kind of generalized associativity?,,"It's well known that the cross product in $\mathbb{R}^3$ doesn't obey the associative law of $$ A \times (B \times C) = (A \times B) \times C $$ We can define a ""Generalized Associative Law"" as an expression involving equation two sets of $N$ same ordered symbols turned into a binary expression tree via non-redundant parenthesis. An example in 4 symbols of such a generalized associativity could be: $$ A \times (B \times (C \times D)) = (A \times B) \times (C \times D) $$ After performing a computerized search I was surprised to find that there is NO generalized associative law for the cross product at least up to 15 symbols. For the interested reader the number of such parenthesized expressions on $N$ symbols grows according to the Catalan Numbers While I can try optimizing my code and increasing its performance to check against more symbols I naturally have to ask: If the cross product doesn't have ANY generalized associative law. How would we even go about proving it?","It's well known that the cross product in doesn't obey the associative law of We can define a ""Generalized Associative Law"" as an expression involving equation two sets of same ordered symbols turned into a binary expression tree via non-redundant parenthesis. An example in 4 symbols of such a generalized associativity could be: After performing a computerized search I was surprised to find that there is NO generalized associative law for the cross product at least up to 15 symbols. For the interested reader the number of such parenthesized expressions on symbols grows according to the Catalan Numbers While I can try optimizing my code and increasing its performance to check against more symbols I naturally have to ask: If the cross product doesn't have ANY generalized associative law. How would we even go about proving it?",\mathbb{R}^3  A \times (B \times C) = (A \times B) \times C  N  A \times (B \times (C \times D)) = (A \times B) \times (C \times D)  N,"['abstract-algebra', 'combinatorics', 'cross-product', 'associativity']"
14,Abstract Algebra book with exercise solutions recommendations.,Abstract Algebra book with exercise solutions recommendations.,,I am new to studying abstract algebra (and math in general). I've been reading Gilligan and Pinter's books. I am trying to improve my understanding by doing exercises. However none of the books I am reading seem to come with exercise solutions. Is there an abstract algebra book with lots of exercise with solutions? I am confused as to why none of the math books come with complete exercise solutions. How do people verify that their answers are right.,I am new to studying abstract algebra (and math in general). I've been reading Gilligan and Pinter's books. I am trying to improve my understanding by doing exercises. However none of the books I am reading seem to come with exercise solutions. Is there an abstract algebra book with lots of exercise with solutions? I am confused as to why none of the math books come with complete exercise solutions. How do people verify that their answers are right.,,"['abstract-algebra', 'reference-request', 'soft-question', 'book-recommendation']"
15,Primes of ramification index 1 with inseparable residue field extension,Primes of ramification index 1 with inseparable residue field extension,,"I've been reading through Neukirch's Algebraic Number Theory , and I'm a little puzzled about a possibility with ramification of primes. As usual, let $\mathcal{O}_K$ be a Dedekind domain with field of fractions $K$, let $L/K$ be a finite algebraic extension, and let $\mathcal{O}_L$ be the algebraic closure of $\mathcal{O}_K$ in $L$. Let $\mathfrak{p}$ be a prime of $\mathcal{O}_K$, and let $\mathfrak{p} = \prod_{i=1}^{r} \mathfrak{P}_i^{e_i}$ be its prime factorization in $\mathcal{O}_L$. Neukirch defines $\mathfrak{P}_i$ to be unramified over $\mathcal{O}_K$ provided that $e_i = 1$ and the residue field $\mathcal{O}_L/\mathfrak{P}_i$ is separable over $\mathcal{O}_K/\mathfrak{p}$. It's the latter condition that has me wondering: What if $e_i = 1$, but the residue field extension is inseparable (perhaps even purely inseparable)? In other words, can a prime be ramified despite having ramification index 1? The definition suggests it can, but no examples readily come to mind, probably because most of the examples I've worked with are perfect fields. Also, is there some good geometric way of thinking about what it means for a point to be ramified with ramification index 1? I usually think of ramification points as ""points with multiplicity"" or something along those lines, but that doesn't make sense if $e_i = 1$. Is there an example — ideally, a reasonably natural one — that illustrates this phenomenon?","I've been reading through Neukirch's Algebraic Number Theory , and I'm a little puzzled about a possibility with ramification of primes. As usual, let $\mathcal{O}_K$ be a Dedekind domain with field of fractions $K$, let $L/K$ be a finite algebraic extension, and let $\mathcal{O}_L$ be the algebraic closure of $\mathcal{O}_K$ in $L$. Let $\mathfrak{p}$ be a prime of $\mathcal{O}_K$, and let $\mathfrak{p} = \prod_{i=1}^{r} \mathfrak{P}_i^{e_i}$ be its prime factorization in $\mathcal{O}_L$. Neukirch defines $\mathfrak{P}_i$ to be unramified over $\mathcal{O}_K$ provided that $e_i = 1$ and the residue field $\mathcal{O}_L/\mathfrak{P}_i$ is separable over $\mathcal{O}_K/\mathfrak{p}$. It's the latter condition that has me wondering: What if $e_i = 1$, but the residue field extension is inseparable (perhaps even purely inseparable)? In other words, can a prime be ramified despite having ramification index 1? The definition suggests it can, but no examples readily come to mind, probably because most of the examples I've worked with are perfect fields. Also, is there some good geometric way of thinking about what it means for a point to be ramified with ramification index 1? I usually think of ramification points as ""points with multiplicity"" or something along those lines, but that doesn't make sense if $e_i = 1$. Is there an example — ideally, a reasonably natural one — that illustrates this phenomenon?",,"['abstract-algebra', 'algebraic-number-theory', 'arithmetic-geometry']"
16,A conjecture concerning primes and algebra,A conjecture concerning primes and algebra,,"A monoid morphism $\psi:\mathbb Z_+\!\!\rightarrow\mathbb Z_+$ is defined by an arbitrary function $f:\mathbb Z_+\!\!\rightarrow\mathbb Z_+$ and defines a group homomorphism $\varphi:\mathbb Q_+\!\!\rightarrow\mathbb Q_+$: $\psi(a\cdot b)=\psi(a)\cdot\psi(b)\Rightarrow\psi(\prod p_i^{n_i})=\prod\psi(p_i)^{n_i}$, so any function $i\mapsto \psi(p_i)$ defines $\psi$. Further, since  $\varphi(\frac{1}{n})=\frac{1}{\varphi(n)}$ a function $f$ uniquely defines the group homomorphism $\varphi$. For fun I intend to study the group homomorphism generated by the identity function  $i\mapsto\omega(p_i)=i$. Then $\omega:\mathbb Z_+\!\!\rightarrow\mathbb Z_+$ seems to be an algebraic analogue to the analytic approach with $\pi(N)$ since also $\omega$ is a left inverse to the prime number function $p_n$. In the diagram $\omega$ is the blue curve and $\pi$ the red and one can see (especially if the picture is loaded and viewed in a larger scale) that $\omega(1)>\pi(1),\; \omega(35)>\pi(35)$ and $\omega(49)>\pi(49)$. Of course $\omega$ and $\pi$ coincide for all primes, but also for other values as $91,\;95$ and $133$. However, I have tested all values less than $2^{16}$ and $\omega(N)\leq\pi(N)$ for $N>49$ in this interval. I have no idea how to prove the conjecture (if possible) but I will try to construct a program that (in principle) can test any interval of integers. Edit: I realize now that it is virtually impossible to make such a program, but with help of arrays of primes my program have tested all values $< 1\,000\,000$ and the only numbers for which $\omega(N)\geq\pi(N)$ (italic numbers stands for '$>$') are: $\mathit{1},\,9,\,15,\,21,\,25,\,\mathit{35},\,39,\,\mathit{49},\,57,\,65,\,91,\,95,\,133$. Conjecture: For $N=\prod p_k^{n_k}>49$ it holds that $\prod k^{n_k}\leq\pi(N)$. Thoughtful: from an analytic point of view $\omega$ seems to be very irregular, but algebraically it is an almost canonical morphism.","A monoid morphism $\psi:\mathbb Z_+\!\!\rightarrow\mathbb Z_+$ is defined by an arbitrary function $f:\mathbb Z_+\!\!\rightarrow\mathbb Z_+$ and defines a group homomorphism $\varphi:\mathbb Q_+\!\!\rightarrow\mathbb Q_+$: $\psi(a\cdot b)=\psi(a)\cdot\psi(b)\Rightarrow\psi(\prod p_i^{n_i})=\prod\psi(p_i)^{n_i}$, so any function $i\mapsto \psi(p_i)$ defines $\psi$. Further, since  $\varphi(\frac{1}{n})=\frac{1}{\varphi(n)}$ a function $f$ uniquely defines the group homomorphism $\varphi$. For fun I intend to study the group homomorphism generated by the identity function  $i\mapsto\omega(p_i)=i$. Then $\omega:\mathbb Z_+\!\!\rightarrow\mathbb Z_+$ seems to be an algebraic analogue to the analytic approach with $\pi(N)$ since also $\omega$ is a left inverse to the prime number function $p_n$. In the diagram $\omega$ is the blue curve and $\pi$ the red and one can see (especially if the picture is loaded and viewed in a larger scale) that $\omega(1)>\pi(1),\; \omega(35)>\pi(35)$ and $\omega(49)>\pi(49)$. Of course $\omega$ and $\pi$ coincide for all primes, but also for other values as $91,\;95$ and $133$. However, I have tested all values less than $2^{16}$ and $\omega(N)\leq\pi(N)$ for $N>49$ in this interval. I have no idea how to prove the conjecture (if possible) but I will try to construct a program that (in principle) can test any interval of integers. Edit: I realize now that it is virtually impossible to make such a program, but with help of arrays of primes my program have tested all values $< 1\,000\,000$ and the only numbers for which $\omega(N)\geq\pi(N)$ (italic numbers stands for '$>$') are: $\mathit{1},\,9,\,15,\,21,\,25,\,\mathit{35},\,39,\,\mathit{49},\,57,\,65,\,91,\,95,\,133$. Conjecture: For $N=\prod p_k^{n_k}>49$ it holds that $\prod k^{n_k}\leq\pi(N)$. Thoughtful: from an analytic point of view $\omega$ seems to be very irregular, but algebraically it is an almost canonical morphism.",,"['abstract-algebra', 'inequality', 'prime-numbers', 'conjectures']"
17,An example of a commutative ring in which every primary ideal is prime,An example of a commutative ring in which every primary ideal is prime,,"It is clear that every prime ideal in a commutative ring is primary. The converse is false; for example, in the ring $\mathbb{Z}$ the ideal $(p^2)$ is an example of a primary ideal that is not prime (where $p$ is a prime number). So my question is when does the converse hold: 1) Is there any characterization of commutative rings in which every   primary ideal is prime? One class of rings satisfying the above condition are absolutely flat rings. In fact, it is known that in every absolutely flat ring every primary ideal is maximal (see, for example, exercise 3 in page 55 of ""Introduction to Commutative Algebra"" by Atiyah & Macdonald). Here is my second question, that is more specific: 2) What would be an example of an ring in which every primary ideal is   prime, but not every primary ideal is maximal? An answer for question 1) would probably solve 2) easily. Thanks!","It is clear that every prime ideal in a commutative ring is primary. The converse is false; for example, in the ring $\mathbb{Z}$ the ideal $(p^2)$ is an example of a primary ideal that is not prime (where $p$ is a prime number). So my question is when does the converse hold: 1) Is there any characterization of commutative rings in which every   primary ideal is prime? One class of rings satisfying the above condition are absolutely flat rings. In fact, it is known that in every absolutely flat ring every primary ideal is maximal (see, for example, exercise 3 in page 55 of ""Introduction to Commutative Algebra"" by Atiyah & Macdonald). Here is my second question, that is more specific: 2) What would be an example of an ring in which every primary ideal is   prime, but not every primary ideal is maximal? An answer for question 1) would probably solve 2) easily. Thanks!",,"['abstract-algebra', 'commutative-algebra', 'ring-theory']"
18,Literature on group theory of Rubik's Cube,Literature on group theory of Rubik's Cube,,"While searching for literature on the group theory of Rubik's Cube, I mostly find introductions to group theory motivated by applications to Rubik's cube. I.e. the focus lies on elementary group theory while the cube is just superficially treated. Is there also literature for people already familiar with group theory, who wants to study the cube in detail? Thanks in advance!","While searching for literature on the group theory of Rubik's Cube, I mostly find introductions to group theory motivated by applications to Rubik's cube. I.e. the focus lies on elementary group theory while the cube is just superficially treated. Is there also literature for people already familiar with group theory, who wants to study the cube in detail? Thanks in advance!",,"['abstract-algebra', 'group-theory', 'finite-groups', 'permutations', 'rubiks-cube']"
19,What is symmetric about the symmetric group? [duplicate],What is symmetric about the symmetric group? [duplicate],,"This question already has answers here : What kind of ""symmetry"" is the symmetric group about? (7 answers) Closed 11 years ago . In my abstract algebra reader many times they use the word ""symmetry"".  But I just found out that I'm not quite sure what they mean with it. Let $X=\{1,...,n\}$. The set $S_n$ of bijections $X\to X$ under   composition with identity $X\to X :x\mapsto x$  is called the   symmetric group on $n$ symbols. If I think about symmetry I think about figures, as something I can visualize. However I'm not sure if or how I should visualize the symmetric group of $n$ symbols as something symmetric. Edit: Thanks for all the answers! They all contributed to be finally satisfied with calling $S_n$ symmetric :) Edit2: This helped me a lot as well: http://en.wikipedia.org/wiki/Frucht%27s_theorem Frucht's theorem says that every finite group is the symmetry group of   some graph. So every finite abstract group is actually the symmetries   of some explicit object.","This question already has answers here : What kind of ""symmetry"" is the symmetric group about? (7 answers) Closed 11 years ago . In my abstract algebra reader many times they use the word ""symmetry"".  But I just found out that I'm not quite sure what they mean with it. Let $X=\{1,...,n\}$. The set $S_n$ of bijections $X\to X$ under   composition with identity $X\to X :x\mapsto x$  is called the   symmetric group on $n$ symbols. If I think about symmetry I think about figures, as something I can visualize. However I'm not sure if or how I should visualize the symmetric group of $n$ symbols as something symmetric. Edit: Thanks for all the answers! They all contributed to be finally satisfied with calling $S_n$ symmetric :) Edit2: This helped me a lot as well: http://en.wikipedia.org/wiki/Frucht%27s_theorem Frucht's theorem says that every finite group is the symmetry group of   some graph. So every finite abstract group is actually the symmetries   of some explicit object.",,"['abstract-algebra', 'group-theory', 'symmetric-groups']"
20,Intersection of Cyclotomic Fields,Intersection of Cyclotomic Fields,,"How would I prove that $\mathbb{Q}_m \cap \mathbb{Q}_n = \mathbb{Q}_{(m, n)}$ (here $\mathbb{Q}_n$ denotes the $n$ th cyclotomic field)? I already know of a solution involving the fact that given two normal extension fields $M, L$ of some field $K$ contained in some common extension, then $\text{Gal}(ML/L) \cong \text{Gal}(M/M \cap L)$ , but does there exist a solution that doesn't require such a theorem?","How would I prove that (here denotes the th cyclotomic field)? I already know of a solution involving the fact that given two normal extension fields of some field contained in some common extension, then , but does there exist a solution that doesn't require such a theorem?","\mathbb{Q}_m \cap \mathbb{Q}_n = \mathbb{Q}_{(m, n)} \mathbb{Q}_n n M, L K \text{Gal}(ML/L) \cong \text{Gal}(M/M \cap L)","['abstract-algebra', 'field-theory', 'galois-theory']"
21,"Why is $O_K\otimes \mathbb{Z}_p\cong \oplus_{\mathfrak{p}|p}O_{K,\mathfrak{p}}$?",Why is ?,"O_K\otimes \mathbb{Z}_p\cong \oplus_{\mathfrak{p}|p}O_{K,\mathfrak{p}}","In my old number theory notebook this is stated as a fact. However, I ran into problems when I tried to prove it. First let me state the (supposed) theorem accurately: Theorem (?) Let $K$ be a number field with ring of integers $O_K$. Let $p$ be a prime of $\mathbb{Z}$. Then $O_K\otimes \mathbb{Z}_p\cong \oplus_{\mathfrak{p}|p}O_{K,\mathfrak{p}}$, where $\mathfrak{p}$ runs over those primes of $O_K$ that lie over $p$, and where $O_{K,\mathfrak{p}}$ is the formal local ring of $O_K$ at $\mathfrak{p}$ (i.e., $\varprojlim O_K/\mathfrak{p}^n$). Attempt The way I was thinking of proving this is through the Chinese Remainder Theorem. The following is true for every natural number $n$: $$O_K\otimes \mathbb{Z}/p^n\mathbb{Z}\cong O_K/p^nO_K\cong O_K/\mathfrak{p}_1^{ne_1}\cdots \mathfrak{p}_m^{ne_m}\cong O_K/\mathfrak{p}_1^{ne_1}\oplus...\oplus O_K/\mathfrak{p}_m^{ne_m}.$$ where $pO_K=\mathfrak{p}_1^{e_1}\cdots \mathfrak{p}_m^{e_m}$. The next natural step is to take inverse limits of both sides with respect to n. As inverse limits commute with direct sums (as both are limits), $\varprojlim O_K/\mathfrak{p}_1^{ne_1}\oplus...\oplus O_K/\mathfrak{p}_m^{ne_m}\cong O_{K,\mathfrak{p}_1}\oplus...\oplus O_{K,\mathfrak{p}_m}$. This is where the wheels come off the argument: inverse limits don't generally commute with tensor products. This is because inverse limits are categorical limits, whereas tensor products are categorical colimits (indeed they are the coproduct of the category of $\mathbb{Z}$-algebras). So there is no reason, a priori, that $\varprojlim O_K\otimes \mathbb{Z}/p^n\mathbb{Z}$ would be isomorphic to $O_K\otimes \mathbb{Z}_p$. So this leads me to the Question Why is the theorem true? (if it even is.)","In my old number theory notebook this is stated as a fact. However, I ran into problems when I tried to prove it. First let me state the (supposed) theorem accurately: Theorem (?) Let $K$ be a number field with ring of integers $O_K$. Let $p$ be a prime of $\mathbb{Z}$. Then $O_K\otimes \mathbb{Z}_p\cong \oplus_{\mathfrak{p}|p}O_{K,\mathfrak{p}}$, where $\mathfrak{p}$ runs over those primes of $O_K$ that lie over $p$, and where $O_{K,\mathfrak{p}}$ is the formal local ring of $O_K$ at $\mathfrak{p}$ (i.e., $\varprojlim O_K/\mathfrak{p}^n$). Attempt The way I was thinking of proving this is through the Chinese Remainder Theorem. The following is true for every natural number $n$: $$O_K\otimes \mathbb{Z}/p^n\mathbb{Z}\cong O_K/p^nO_K\cong O_K/\mathfrak{p}_1^{ne_1}\cdots \mathfrak{p}_m^{ne_m}\cong O_K/\mathfrak{p}_1^{ne_1}\oplus...\oplus O_K/\mathfrak{p}_m^{ne_m}.$$ where $pO_K=\mathfrak{p}_1^{e_1}\cdots \mathfrak{p}_m^{e_m}$. The next natural step is to take inverse limits of both sides with respect to n. As inverse limits commute with direct sums (as both are limits), $\varprojlim O_K/\mathfrak{p}_1^{ne_1}\oplus...\oplus O_K/\mathfrak{p}_m^{ne_m}\cong O_{K,\mathfrak{p}_1}\oplus...\oplus O_{K,\mathfrak{p}_m}$. This is where the wheels come off the argument: inverse limits don't generally commute with tensor products. This is because inverse limits are categorical limits, whereas tensor products are categorical colimits (indeed they are the coproduct of the category of $\mathbb{Z}$-algebras). So there is no reason, a priori, that $\varprojlim O_K\otimes \mathbb{Z}/p^n\mathbb{Z}$ would be isomorphic to $O_K\otimes \mathbb{Z}_p$. So this leads me to the Question Why is the theorem true? (if it even is.)",,"['abstract-algebra', 'number-theory', 'commutative-algebra', 'p-adic-number-theory']"
22,"Basis for $\Bbb Z[x_1,\dots,x_n]$ over $\Bbb Z[e_1,\dots,e_n]$",Basis for  over,"\Bbb Z[x_1,\dots,x_n] \Bbb Z[e_1,\dots,e_n]","I'm reading the introductory bits in Procesi's Lie Groups , and on p. 22 we have (paraphrasing) Theorem 2. $\mathcal{B}=\{x_1^{\large h_1}\cdots x_n^{\large h_n}: 0\le h_k\le n-k\}$ is a basis for the ring $\Bbb Z[x_1,\dots,x_n]$ considered over $\Bbb Z[e_1,\dots,e_n]$ , where $e_i$ are the elementary symmetric polynomials in the $x_i$ . I haven't been able to see why this is true. The previous theorem was the fundamental theorem of symmetric polynomials, which was proven inductively with a recursive algorithm: If $x_n\mid f$ then $x_1\cdots x_n\mid f$ , and dividing out we are left with a symmetric polynomial of smaller degree than before. Otherwise, write $f(x_1,\dots,x_{n-1},0)$ as a polynomial $p$ in the elementary symmetric polynomials $\hat{e}_i$ of the first $n-1$ variables, $p(\hat{e}_1,\dots,\hat{e}_{n-1})$ . Now the polynomial $$f(x_1,\dots,x_n)-p(e_1,\dots,e_{n-1})$$ is symmetric in all of $x_1,\dots,x_n$ and evaluates to $0$ at $x_n=0$ , i.e., is divisible by $x_n$ . Induct. Is there a straightforward adaptation of this with which we can argue for theorem 2? Or is there perhaps another way to see that it must be true? I feel I am missing something simple here.","I'm reading the introductory bits in Procesi's Lie Groups , and on p. 22 we have (paraphrasing) Theorem 2. is a basis for the ring considered over , where are the elementary symmetric polynomials in the . I haven't been able to see why this is true. The previous theorem was the fundamental theorem of symmetric polynomials, which was proven inductively with a recursive algorithm: If then , and dividing out we are left with a symmetric polynomial of smaller degree than before. Otherwise, write as a polynomial in the elementary symmetric polynomials of the first variables, . Now the polynomial is symmetric in all of and evaluates to at , i.e., is divisible by . Induct. Is there a straightforward adaptation of this with which we can argue for theorem 2? Or is there perhaps another way to see that it must be true? I feel I am missing something simple here.","\mathcal{B}=\{x_1^{\large h_1}\cdots x_n^{\large h_n}: 0\le h_k\le n-k\} \Bbb Z[x_1,\dots,x_n] \Bbb Z[e_1,\dots,e_n] e_i x_i x_n\mid f x_1\cdots x_n\mid f f(x_1,\dots,x_{n-1},0) p \hat{e}_i n-1 p(\hat{e}_1,\dots,\hat{e}_{n-1}) f(x_1,\dots,x_n)-p(e_1,\dots,e_{n-1}) x_1,\dots,x_n 0 x_n=0 x_n","['abstract-algebra', 'polynomials', 'symmetric-polynomials', 'invariant-theory']"
23,$\mathrm{Aut}(\mathrm{Aut}(G))\cong\mathrm{Aut}(G)$ for $G$ a non-abelian simple group,for  a non-abelian simple group,\mathrm{Aut}(\mathrm{Aut}(G))\cong\mathrm{Aut}(G) G,"For the last couple of days I've been doing a lot of group theory problems, but I found the following particularly difficult, and quite interesting. My level is up to an introductionary course in group theory excluding Sylow Theory. I've made a big edit to include all the work done this far and exclude non-relevant parts. Let $G$ be a non-abelian group such that all normal subgroups are trivial (i.e. the only normal subgroups are $\{e\}$ and $G$ itself). Prove the following. a. $G\cong\mathrm{Inn}(G)$ b. If $\psi\in\mathrm{Aut}(G)$ and $\forall\varphi\in\mathrm{Inn}(G), \ \psi\circ\varphi=\varphi\circ\psi$ , then $\psi=\mathrm{id}_G$ . c. If $N\lhd\mathrm{Aut}(G)$ such that $N\cap\mathrm{Inn}(G)=\{\mathrm{id}_G\}$ , then $N=\{\mathrm{id}_G\}$ . d. $\mathrm{Inn}(G)\ char \ \mathrm{Aut}(G)$ e. $\mathrm{Aut}(\mathrm{Aut}(G))=\mathrm{Inn}(\mathrm{Aut}(G))\cong\mathrm{Aut}(G)$ a. Since $Z(G)\lhd G $ , either $Z(G)=\{e\}$ or $Z(G)=G$ . In the latter case $G$ is abelian, which is not the case, thus $Z(G)=\{e\}$ , and it follows that $\mathrm{Inn}(G)\cong G/Z(G)\cong G$ . b. Elaborating on the comments by Max and Servaes, we see that the given identity yields $\psi(g)\psi(a)\psi(g^{-1})=g\psi(a)g^{-1}$ and from there $g^{-1}\psi(g)\psi(a)=\psi(a)g^{-1}\psi(g)$ . Since $\psi\in\mathrm{Aut}(G)$ , $\psi$ is bijective (thus surjective), and thus $\forall g\in G \ g^{-1}\psi(g)\in Z(G)=\{e\}$ , thus $g=\psi(g)$ for all $g\in G$ , so $\psi=\mathrm{id}_G$ c. Suppose $N\lhd\mathrm{Aut}(G)$ such that $N\cap\mathrm{Inn}(G)=\{\mathrm{id}_G\}$ . Since $\mathrm{Inn}(G)\lhd\mathrm{Aut}(G)$ and the intersection between both normal subgroups is trivial, $\forall\varphi\in\mathrm{Inn}(G)\ \forall \psi\in N, \ \ \psi\circ\varphi=\varphi\circ\psi$ , thus by applying part b conclude that $\psi=\mathrm{id_G}$ if $\psi\in N$ , thus $N=\{\mathrm{id}_G\}$ indeed. d. Is worked out by Servaes. e. The last part that remains. Some conjectured that part e) might contain a typo, but I don't think so. I managed to proof the following: we know from part b) that if $\psi\in\mathrm{Aut}(G)$ commutes with all $\chi\in\mathrm{Aut}(G)$ , then certainly $\psi$ commutes with all $\varphi\in\mathrm{Inn}(G)\subset\mathrm{Aut}(G)$ . So $Z(\mathrm{Aut}(G))=\{\mathrm{id}_G\}$ , and thus $\mathrm{Inn}(\mathrm{Aut}(G))\cong\mathrm{Aut}(G)/Z(\mathrm{Aut}(G))\cong\mathrm{Aut}(G)$ . The only thing that remains to be proven is that $\mathrm{Aut}(\mathrm{Aut}(G))=\mathrm{Inn}(\mathrm{Aut}(G))$ , for a simple non-abelian group the automorphism group is complete. According to Wikipedia , this should be true, but I've no idea how to prove this, but I guess it might follow quite easily. I would appreciate it a lot if someone could write a proof for this very last part.","For the last couple of days I've been doing a lot of group theory problems, but I found the following particularly difficult, and quite interesting. My level is up to an introductionary course in group theory excluding Sylow Theory. I've made a big edit to include all the work done this far and exclude non-relevant parts. Let be a non-abelian group such that all normal subgroups are trivial (i.e. the only normal subgroups are and itself). Prove the following. a. b. If and , then . c. If such that , then . d. e. a. Since , either or . In the latter case is abelian, which is not the case, thus , and it follows that . b. Elaborating on the comments by Max and Servaes, we see that the given identity yields and from there . Since , is bijective (thus surjective), and thus , thus for all , so c. Suppose such that . Since and the intersection between both normal subgroups is trivial, , thus by applying part b conclude that if , thus indeed. d. Is worked out by Servaes. e. The last part that remains. Some conjectured that part e) might contain a typo, but I don't think so. I managed to proof the following: we know from part b) that if commutes with all , then certainly commutes with all . So , and thus . The only thing that remains to be proven is that , for a simple non-abelian group the automorphism group is complete. According to Wikipedia , this should be true, but I've no idea how to prove this, but I guess it might follow quite easily. I would appreciate it a lot if someone could write a proof for this very last part.","G \{e\} G G\cong\mathrm{Inn}(G) \psi\in\mathrm{Aut}(G) \forall\varphi\in\mathrm{Inn}(G), \ \psi\circ\varphi=\varphi\circ\psi \psi=\mathrm{id}_G N\lhd\mathrm{Aut}(G) N\cap\mathrm{Inn}(G)=\{\mathrm{id}_G\} N=\{\mathrm{id}_G\} \mathrm{Inn}(G)\ char \ \mathrm{Aut}(G) \mathrm{Aut}(\mathrm{Aut}(G))=\mathrm{Inn}(\mathrm{Aut}(G))\cong\mathrm{Aut}(G) Z(G)\lhd G  Z(G)=\{e\} Z(G)=G G Z(G)=\{e\} \mathrm{Inn}(G)\cong G/Z(G)\cong G \psi(g)\psi(a)\psi(g^{-1})=g\psi(a)g^{-1} g^{-1}\psi(g)\psi(a)=\psi(a)g^{-1}\psi(g) \psi\in\mathrm{Aut}(G) \psi \forall g\in G \ g^{-1}\psi(g)\in Z(G)=\{e\} g=\psi(g) g\in G \psi=\mathrm{id}_G N\lhd\mathrm{Aut}(G) N\cap\mathrm{Inn}(G)=\{\mathrm{id}_G\} \mathrm{Inn}(G)\lhd\mathrm{Aut}(G) \forall\varphi\in\mathrm{Inn}(G)\ \forall \psi\in N, \ \ \psi\circ\varphi=\varphi\circ\psi \psi=\mathrm{id_G} \psi\in N N=\{\mathrm{id}_G\} \psi\in\mathrm{Aut}(G) \chi\in\mathrm{Aut}(G) \psi \varphi\in\mathrm{Inn}(G)\subset\mathrm{Aut}(G) Z(\mathrm{Aut}(G))=\{\mathrm{id}_G\} \mathrm{Inn}(\mathrm{Aut}(G))\cong\mathrm{Aut}(G)/Z(\mathrm{Aut}(G))\cong\mathrm{Aut}(G) \mathrm{Aut}(\mathrm{Aut}(G))=\mathrm{Inn}(\mathrm{Aut}(G))","['abstract-algebra', 'group-theory', 'automorphism-group']"
24,Preimage of a maximal ideal.,Preimage of a maximal ideal.,,"My textbook says that if $f: R \rightarrow S$ is a ring homomorphism, where $R$ and S are commutative; then if $P$ is a maximal ideal of $S$ , it might not necessarily be a maximal ideal of $R$ . A counterexample is if we choose $R = \Bbb{Z}$ , $S = \Bbb{Q}$ , and let $f$ be the inclusion map. However, when I try to ""prove"" that the preimage must also be maximal, my proof makes sense to me. I know that I must be doing something wrong in the proof, but I couldn't really see it. ""Proof"" Define $g: S \rightarrow S/P$ with kernel $P$ . Let $h = g \circ f: R \rightarrow S/P$ . Since $h$ is a ring homomorphism, the kernel is an ideal of $R$ . Also, from the first isomorphism theorem, we know that $R/\ker(h) \cong S/P$ . Since $P$ is a maximal ideal of $S$ , we know that $S/P$ is a field. Since $R/\ker(h)$ is isomorphic to $S/P$ , it must also be a field, which implies that the kernel of $R$ (which is the preimage of $P$ ) is a maximal ideal of $R$ . Can anybody tell me where I went wrong in this proof? Thank you in advance","My textbook says that if is a ring homomorphism, where and S are commutative; then if is a maximal ideal of , it might not necessarily be a maximal ideal of . A counterexample is if we choose , , and let be the inclusion map. However, when I try to ""prove"" that the preimage must also be maximal, my proof makes sense to me. I know that I must be doing something wrong in the proof, but I couldn't really see it. ""Proof"" Define with kernel . Let . Since is a ring homomorphism, the kernel is an ideal of . Also, from the first isomorphism theorem, we know that . Since is a maximal ideal of , we know that is a field. Since is isomorphic to , it must also be a field, which implies that the kernel of (which is the preimage of ) is a maximal ideal of . Can anybody tell me where I went wrong in this proof? Thank you in advance",f: R \rightarrow S R P S R R = \Bbb{Z} S = \Bbb{Q} f g: S \rightarrow S/P P h = g \circ f: R \rightarrow S/P h R R/\ker(h) \cong S/P P S S/P R/\ker(h) S/P R P R,['abstract-algebra']
25,Is computing distance a lesser capability than computing square roots?,Is computing distance a lesser capability than computing square roots?,,"Let $F$ be a field.  Consider the following three abilities: (SQRT) Given $a\in F$, find $x\in F$ such that $a = x^2$ (when such $x$ exists). (NORM) Given $a,b\in F$, find $x\in F$ such that $a^2+b^2 = x^2$ (when such $x$ exists). (BISQ) Given $a\in F$, find $x,y\in F$ such that $a = x^2+y^2$ (when such $x,y$ exist). Abilities NORM and BISQ together yield ability SQRT.  Ability SQRT (plus the ability to perform field operations) yields ability NORM.  If $F=\mathbb{R}$, then ability SQRT also yields ability BISQ (since in $\mathbb{R}$ the numbers expressible as a sum of squares are exactly the numbers expressible as squares, namely the nonnegative numbers, so we can compute $x$ using SQRT and take $y=0$), and so for $\mathbb{R}$ ability SQRT is equivalent to the combination of abilities NORM and BISQ.  [This paragraph was revised after an error was pointed out by joriki.] My question: Is NORM a strictly lesser capability than SQRT (in $\mathbb{R}$ or in any other field)? I don't state the question formally because I don't know the right formalization.  Any reasonable interpretation of the question is legit. My observations so far: In a field of characteristic 2, ability NORM is trivial (take $x=a+b$).  It seems like SQRT should be a nontrivial ability, but I don't see how to prove that, for example, in the field of power series over $\mathbb{Z}/2\mathbb{Z}$, the square root operation cannot be performed using the field operations alone. I had hoped to construct a field $F$ containing $\mathbb{Q}$ and closed under the operation of NORM, but not closed under SQRT (maybe using some trick related to the characterization of the integers which are representable as the sum of two squares).  This would show that, in that field, NORM is a strictly lesser capability than SQRT in a very strong sense.  But because every positive integer is the sum of four squares, any such field contains the square roots of all positive integers (if $n = a^2+b^2+c^2+d^2$ then $\sqrt n = \sqrt{(\sqrt{a^2+b^2})^2 + (\sqrt{c^2+d^2})^2}$), hence the square roots of all positive rationals ($\sqrt{p/q} = \sqrt{pq}/q$), so it doesn't seem very hopeful. (The origin of the question is that a computer programmer I know was wondering whether there was a way to perform NORM without having to invoke the computationally expensive SQRT operation.  I doubt that this question has a positive practical answer, but the theoretical aspect struck my curiosity.)","Let $F$ be a field.  Consider the following three abilities: (SQRT) Given $a\in F$, find $x\in F$ such that $a = x^2$ (when such $x$ exists). (NORM) Given $a,b\in F$, find $x\in F$ such that $a^2+b^2 = x^2$ (when such $x$ exists). (BISQ) Given $a\in F$, find $x,y\in F$ such that $a = x^2+y^2$ (when such $x,y$ exist). Abilities NORM and BISQ together yield ability SQRT.  Ability SQRT (plus the ability to perform field operations) yields ability NORM.  If $F=\mathbb{R}$, then ability SQRT also yields ability BISQ (since in $\mathbb{R}$ the numbers expressible as a sum of squares are exactly the numbers expressible as squares, namely the nonnegative numbers, so we can compute $x$ using SQRT and take $y=0$), and so for $\mathbb{R}$ ability SQRT is equivalent to the combination of abilities NORM and BISQ.  [This paragraph was revised after an error was pointed out by joriki.] My question: Is NORM a strictly lesser capability than SQRT (in $\mathbb{R}$ or in any other field)? I don't state the question formally because I don't know the right formalization.  Any reasonable interpretation of the question is legit. My observations so far: In a field of characteristic 2, ability NORM is trivial (take $x=a+b$).  It seems like SQRT should be a nontrivial ability, but I don't see how to prove that, for example, in the field of power series over $\mathbb{Z}/2\mathbb{Z}$, the square root operation cannot be performed using the field operations alone. I had hoped to construct a field $F$ containing $\mathbb{Q}$ and closed under the operation of NORM, but not closed under SQRT (maybe using some trick related to the characterization of the integers which are representable as the sum of two squares).  This would show that, in that field, NORM is a strictly lesser capability than SQRT in a very strong sense.  But because every positive integer is the sum of four squares, any such field contains the square roots of all positive integers (if $n = a^2+b^2+c^2+d^2$ then $\sqrt n = \sqrt{(\sqrt{a^2+b^2})^2 + (\sqrt{c^2+d^2})^2}$), hence the square roots of all positive rationals ($\sqrt{p/q} = \sqrt{pq}/q$), so it doesn't seem very hopeful. (The origin of the question is that a computer programmer I know was wondering whether there was a way to perform NORM without having to invoke the computationally expensive SQRT operation.  I doubt that this question has a positive practical answer, but the theoretical aspect struck my curiosity.)",,['abstract-algebra']
26,Why are Dedekind-finite rings called so?,Why are Dedekind-finite rings called so?,,"A Dedekind-finite ring is a ring in which $ab=1$ implies $ba=1$. It seems natural to look for a connection to Dedekind-finite sets, however for such a set any injective endomorphism is surjective, while for a Dedekind-finite ring it goes vice versa, namely, any surjective endomorphism is injective (In other words, such a ring is Hopfian). So, what is the motivation behind this name (for rings)? Thanks.","A Dedekind-finite ring is a ring in which $ab=1$ implies $ba=1$. It seems natural to look for a connection to Dedekind-finite sets, however for such a set any injective endomorphism is surjective, while for a Dedekind-finite ring it goes vice versa, namely, any surjective endomorphism is injective (In other words, such a ring is Hopfian). So, what is the motivation behind this name (for rings)? Thanks.",,"['abstract-algebra', 'ring-theory', 'noncommutative-algebra']"
27,Coloring the faces of a hypercube,Coloring the faces of a hypercube,,"I will restate the 3-D version of the problem. In how many ways can you color a regular cube with 2 colors up to a rotational isometry. The answer is of course a special case of Burnsides Lemma which can be used to show that the number of distinct face permutations is $\frac{1}{24}(N^6 + 3N^4 + 12N^3 + 8N^2)$ where $N$ is the number of colors used, $2$ in this case, which gives us an answer of $10$ distinct permutations. My question is how can you expand this to a tesseract, and then more generally, to any hypercube. The rotational isometries of a cube are somewhat simple to comprehend, but the rotational isometries o hypercube are difficult to grasp (even after an hour of playing with the 4d rubiks cube app) My initial thought was to consider the expansion of a tesseract as 8 interconnected cubelets. For the two color case each one of these cubelets has 10 distinct states. Which gives us $10^8$ non-distinct permutations of the hypercube. Or more generally, this reduces to how many distinct ways one can color a 8 faced 3-dimensional figure using 10 colors. So the complicated question of 4-dimensional isometries reduces to 3 dimensional rotational isometries of a octahedron. But I'm a physicist so what the hell do I know :D","I will restate the 3-D version of the problem. In how many ways can you color a regular cube with 2 colors up to a rotational isometry. The answer is of course a special case of Burnsides Lemma which can be used to show that the number of distinct face permutations is $\frac{1}{24}(N^6 + 3N^4 + 12N^3 + 8N^2)$ where $N$ is the number of colors used, $2$ in this case, which gives us an answer of $10$ distinct permutations. My question is how can you expand this to a tesseract, and then more generally, to any hypercube. The rotational isometries of a cube are somewhat simple to comprehend, but the rotational isometries o hypercube are difficult to grasp (even after an hour of playing with the 4d rubiks cube app) My initial thought was to consider the expansion of a tesseract as 8 interconnected cubelets. For the two color case each one of these cubelets has 10 distinct states. Which gives us $10^8$ non-distinct permutations of the hypercube. Or more generally, this reduces to how many distinct ways one can color a 8 faced 3-dimensional figure using 10 colors. So the complicated question of 4-dimensional isometries reduces to 3 dimensional rotational isometries of a octahedron. But I'm a physicist so what the hell do I know :D",,"['geometry', 'combinatorics', 'abstract-algebra', 'group-theory']"
28,"Doubt regarding proof that $\mathbb{Z}, \mathbb{Z}[x]$ are unique factorization domains",Doubt regarding proof that  are unique factorization domains,"\mathbb{Z}, \mathbb{Z}[x]","The usual proof for unique factorization in $\mathbb{Z}$ proceeds via the concept of GCD (greatest common divisor) of two integers leading to the fundamental property of primes in $\mathbb{Z}$ : Theorem : If $p$ is prime and $a, b \in \mathbb{Z}$ such that $p\mid ab$ then either $p\mid a$ or $p\mid b$ . And this is the result which guarantees uniqueness of factorization. Note that the same procedure does not apply in $\mathbb{Z}[x]$ as we don't have a concept of GCD here. Thus for example we can't say that $2, x$ have GCD $1$ because we can't find polynomials $p(x), q(x) \in \mathbb{Z}[x]$ such that $$1 = 2p(x) + xq(x)$$ (contradiction arises when we put $x = 0$ in above equation). The problem is eliminated by considering polynomials in $\mathbb{Q}[x]$ and then we have the GCD available here so that $\mathbb{Q}[x]$ is a unique factorization domain. Next we use the fact that $\mathbb{Z}[x]\subset\mathbb{Q}[x]$ to factorize elements of $\mathbb{Z}[x]$ as product of polynomials in $\mathbb{Q}[x]$ and then use Gauss lemma to prove that the factorization can also be done using polynomials in $\mathbb{Z}[x]$ only. Thus it appears that existence of GCD is not necessary to guarantee existence of unique factorization. Does that mean we can prove unique factorization in $\mathbb{Z}$ via some other means rather than the approach I outlined in the beginning? Also I would like to know if the property of prime numbers (mentioned in theorem at the beginning) is always a consequence of the existence of GCD in a more generally setting of integral domains? Update : From the comments and in particular the wiki link given by Hand Lundmark it is clear that the ideas of the usual ring of integers have been generalized in many ways to give rise to the famous chain of class inclusions (see wiki link on GCD Domains ) and this question is perhaps a very naive attempt to understand that all (or some of) those inclusions are proper . Further Update : I was a bit hesitant about asking question related to a seemingly trivial matter (namely unique factorization in integers and polynomials with integer coefficients), but the way it has been received here is so much more than what I expected. MSE never ceases to amaze me (and perhaps other users too)! Thanks to all those who answered/commented/chatted. I have now got a lot of food for thought (and study).","The usual proof for unique factorization in proceeds via the concept of GCD (greatest common divisor) of two integers leading to the fundamental property of primes in : Theorem : If is prime and such that then either or . And this is the result which guarantees uniqueness of factorization. Note that the same procedure does not apply in as we don't have a concept of GCD here. Thus for example we can't say that have GCD because we can't find polynomials such that (contradiction arises when we put in above equation). The problem is eliminated by considering polynomials in and then we have the GCD available here so that is a unique factorization domain. Next we use the fact that to factorize elements of as product of polynomials in and then use Gauss lemma to prove that the factorization can also be done using polynomials in only. Thus it appears that existence of GCD is not necessary to guarantee existence of unique factorization. Does that mean we can prove unique factorization in via some other means rather than the approach I outlined in the beginning? Also I would like to know if the property of prime numbers (mentioned in theorem at the beginning) is always a consequence of the existence of GCD in a more generally setting of integral domains? Update : From the comments and in particular the wiki link given by Hand Lundmark it is clear that the ideas of the usual ring of integers have been generalized in many ways to give rise to the famous chain of class inclusions (see wiki link on GCD Domains ) and this question is perhaps a very naive attempt to understand that all (or some of) those inclusions are proper . Further Update : I was a bit hesitant about asking question related to a seemingly trivial matter (namely unique factorization in integers and polynomials with integer coefficients), but the way it has been received here is so much more than what I expected. MSE never ceases to amaze me (and perhaps other users too)! Thanks to all those who answered/commented/chatted. I have now got a lot of food for thought (and study).","\mathbb{Z} \mathbb{Z} p a, b \in \mathbb{Z} p\mid ab p\mid a p\mid b \mathbb{Z}[x] 2, x 1 p(x), q(x) \in \mathbb{Z}[x] 1 = 2p(x) + xq(x) x = 0 \mathbb{Q}[x] \mathbb{Q}[x] \mathbb{Z}[x]\subset\mathbb{Q}[x] \mathbb{Z}[x] \mathbb{Q}[x] \mathbb{Z}[x] \mathbb{Z}","['abstract-algebra', 'ring-theory', 'unique-factorization-domains']"
29,For which $d \in \mathbb{Z}$ is $\mathbb{Z}[\sqrt{d}]$ a unique factorization domain?,For which  is  a unique factorization domain?,d \in \mathbb{Z} \mathbb{Z}[\sqrt{d}],"Is there a general criterion which tells me whether $\mathbb{Z}[\sqrt{d}]$, $d \in \mathbb{Z}$ is a unique factorization domain? $\mathbb{Z}[\sqrt{-5}]$ is a frequent example for non-unique factorization domains because 6 has two different factorizations. $\mathbb{Z}[\sqrt{-1}]$ on the other hand is a Euclidean domain. But I'm not even sure about simple examples like $\mathbb{Z}[\sqrt{2}]$.","Is there a general criterion which tells me whether $\mathbb{Z}[\sqrt{d}]$, $d \in \mathbb{Z}$ is a unique factorization domain? $\mathbb{Z}[\sqrt{-5}]$ is a frequent example for non-unique factorization domains because 6 has two different factorizations. $\mathbb{Z}[\sqrt{-1}]$ on the other hand is a Euclidean domain. But I'm not even sure about simple examples like $\mathbb{Z}[\sqrt{2}]$.",,"['abstract-algebra', 'ring-theory', 'unique-factorization-domains']"
30,What is the overall idea of Galois theory?,What is the overall idea of Galois theory?,,"I am a third year undergraduate, doing a course on Field and Galois theory. Now, while I seem to understand most of the concepts locally, I do not seem to get the 'Whole picture' of what is happening in Galois theory , and things seem to be a bit disconnected. I would be grateful if some could help me get an overall picture of the subject. The whole, I believe, is greater than the sum of its parts. I am familiar with the concepts of field theory, such as extensions, separability, splitting fields, finite fields and all the other basic concepts you would expect to know to study Galois theory, and also have a fair understanding of the main concepts of Galois theory. I just dont get the whole picture. Thanks.","I am a third year undergraduate, doing a course on Field and Galois theory. Now, while I seem to understand most of the concepts locally, I do not seem to get the 'Whole picture' of what is happening in Galois theory , and things seem to be a bit disconnected. I would be grateful if some could help me get an overall picture of the subject. The whole, I believe, is greater than the sum of its parts. I am familiar with the concepts of field theory, such as extensions, separability, splitting fields, finite fields and all the other basic concepts you would expect to know to study Galois theory, and also have a fair understanding of the main concepts of Galois theory. I just dont get the whole picture. Thanks.",,"['abstract-algebra', 'soft-question', 'field-theory', 'galois-theory', 'big-picture']"
31,"Making sense out of ""field"", ""algebra"", ""ring"" and ""semi-ring"" in names of set systems","Making sense out of ""field"", ""algebra"", ""ring"" and ""semi-ring"" in names of set systems",,"There are some set systems with algebraic titles, such as ""field"", ""algebra"", ""ring"" and ""semi-ring"" (and possibly other titles), in their names. Examples are a sigma field (aka sigma algebra, delta algebra), a delta ring of sets, a sigma ring of sets, a field (aka algebra) of sets, a ring of sets in order theory sense, a ring of sets in measure theory sense, a semi-ring of sets, a semi-algebra of sets, among others (I don't know yet but you are welcome to add more). They seem to suggest some algebraic structures, but it is not the actual algebraic structure at least in one case "" a field of sets is not an ""field"" in the sense of abstract algebra, but a Boolean algebra "" (I am not very sure about other cases). I was wondering if there are some definitions for ""field"", ""algebra"", ""ring"" and ""semi-ring"" appearing in names of set systems? If not, what are the reasons to name such a set system with one of these titles, instead of randomly pick one? Why are there some set systems without these algebraic titles in them, such as topology, convexity structure, $\lambda$ system, monotone class, $\pi$ system closure system? For example, there is only one set operation finite intersection in defining a $\pi$ system, and only arbitrary intersection in a closure system. So in the spirit of ""field"" and ""ring"" for two set operations, shall a $\pi$ system and a closure system be called ""group""? Thanks and regards!","There are some set systems with algebraic titles, such as ""field"", ""algebra"", ""ring"" and ""semi-ring"" (and possibly other titles), in their names. Examples are a sigma field (aka sigma algebra, delta algebra), a delta ring of sets, a sigma ring of sets, a field (aka algebra) of sets, a ring of sets in order theory sense, a ring of sets in measure theory sense, a semi-ring of sets, a semi-algebra of sets, among others (I don't know yet but you are welcome to add more). They seem to suggest some algebraic structures, but it is not the actual algebraic structure at least in one case "" a field of sets is not an ""field"" in the sense of abstract algebra, but a Boolean algebra "" (I am not very sure about other cases). I was wondering if there are some definitions for ""field"", ""algebra"", ""ring"" and ""semi-ring"" appearing in names of set systems? If not, what are the reasons to name such a set system with one of these titles, instead of randomly pick one? Why are there some set systems without these algebraic titles in them, such as topology, convexity structure, $\lambda$ system, monotone class, $\pi$ system closure system? For example, there is only one set operation finite intersection in defining a $\pi$ system, and only arbitrary intersection in a closure system. So in the spirit of ""field"" and ""ring"" for two set operations, shall a $\pi$ system and a closure system be called ""group""? Thanks and regards!",,"['abstract-algebra', 'general-topology', 'measure-theory', 'elementary-set-theory', 'convex-analysis']"
32,$|G| + \frac{|G|}{\left|\langle a\rangle\right|} + \frac{|G|}{\left|\langle b\rangle\right|} + \frac{|G|}{\left|\langle ab\rangle\right|}$,,|G| + \frac{|G|}{\left|\langle a\rangle\right|} + \frac{|G|}{\left|\langle b\rangle\right|} + \frac{|G|}{\left|\langle ab\rangle\right|},"Show that for every finite group $G$ and for every elements $a, b \in G$ the following expression $$ |G| + \frac{|G|}{\left|\langle a\rangle\right|} + \frac{|G|}{\left|\langle b\rangle\right|} + \frac{|G|}{\left|\langle ab\rangle\right|} $$ is even.","Show that for every finite group $G$ and for every elements $a, b \in G$ the following expression $$ |G| + \frac{|G|}{\left|\langle a\rangle\right|} + \frac{|G|}{\left|\langle b\rangle\right|} + \frac{|G|}{\left|\langle ab\rangle\right|} $$ is even.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
33,Writing a group element as $ghg^{-1} h^{-1}$ and as $g^2 h^2$,Writing a group element as  and as,ghg^{-1} h^{-1} g^2 h^2,"I recently read the elegant paper Generalized Frobenius Schur Numbers , by Bump and Ginzburg, which I learned about here . The results in this paper imply the following: Let $G$ be a finite group where every element is conjugate to its inverse. Then, for any $x \in G$, the number of ways to write $x$ as $ghg^{-1} h^{-1}$ is equal to the number of ways to write $x$ as $g^2 h^2$. I'll give the proof below, using character theory. I tried to find an elementary proof and failed. Can you do it? $\def\CC{\mathbb{C}}$We need to prove the equality $\sum_{g, h \in G} g^2 h^2 = \sum_{g, h \in G} g h g^{-1} h^{-1}$ in $\CC[G]$. Since we have $\CC[G] \cong \bigoplus_V \mathrm{End}(V)$, where the sum is over irreps of $V$, it is enough to show that both group elements act the same way on each $V$. As I computed in this answer , $\sum_{g, h \in G} ghg^{-1} h^{-1}$ acts on an irrep $V$ by $\left( \frac{|G|}{\dim V} \right)^2$. Now consider $\sum_{g \in G} g^2$ acting on an irrep $V$. Since $\sum_{g \in G} g^2$ is central in $\CC[G]$, it must act by a scalar, and computing traces we find that this scalar is $\frac{1}{\dim V} \sum_{g \in G} \chi_V(g^2)$. The quantity $\frac{1}{|G|} \sum_{g \in G} \chi_V(g)^2$ is known as the Frobenius-Schur indicator and is $\pm 1$ for a group where every element is conjugate to its inverse. So $\sum_{g \in G} g^2$ acts on $V$ by $\pm \frac{|G|}{dim V}$ and $\left( \sum_{g \in G} g^2 \right)^2$ acts on $V$ by $\left( \frac{|G|}{\dim V} \right)^2$. We have shown that $\sum_{g, h \in G} ghg^{-1} h^{-1}$ and $\left( \sum_{g \in G} g^2 \right)^2 = \sum_{g,h \in G} g^2 h^2$ act on every irrep by the same scalar, so they are equal in the group algebra. QED. The same argument shows that, in any finite group, the number of ways to write $x$ as $f^2 g^2 h^2$ is the same as the number of ways to write $x$ as $f^2 g h g^{-1} h^{-1}$, using that the Frob. Schur indicator is always $-1$, $0$ or $1$ and thus obeys $\epsilon^3 = \epsilon$. In case anyone finds that easier to think about...","I recently read the elegant paper Generalized Frobenius Schur Numbers , by Bump and Ginzburg, which I learned about here . The results in this paper imply the following: Let $G$ be a finite group where every element is conjugate to its inverse. Then, for any $x \in G$, the number of ways to write $x$ as $ghg^{-1} h^{-1}$ is equal to the number of ways to write $x$ as $g^2 h^2$. I'll give the proof below, using character theory. I tried to find an elementary proof and failed. Can you do it? $\def\CC{\mathbb{C}}$We need to prove the equality $\sum_{g, h \in G} g^2 h^2 = \sum_{g, h \in G} g h g^{-1} h^{-1}$ in $\CC[G]$. Since we have $\CC[G] \cong \bigoplus_V \mathrm{End}(V)$, where the sum is over irreps of $V$, it is enough to show that both group elements act the same way on each $V$. As I computed in this answer , $\sum_{g, h \in G} ghg^{-1} h^{-1}$ acts on an irrep $V$ by $\left( \frac{|G|}{\dim V} \right)^2$. Now consider $\sum_{g \in G} g^2$ acting on an irrep $V$. Since $\sum_{g \in G} g^2$ is central in $\CC[G]$, it must act by a scalar, and computing traces we find that this scalar is $\frac{1}{\dim V} \sum_{g \in G} \chi_V(g^2)$. The quantity $\frac{1}{|G|} \sum_{g \in G} \chi_V(g)^2$ is known as the Frobenius-Schur indicator and is $\pm 1$ for a group where every element is conjugate to its inverse. So $\sum_{g \in G} g^2$ acts on $V$ by $\pm \frac{|G|}{dim V}$ and $\left( \sum_{g \in G} g^2 \right)^2$ acts on $V$ by $\left( \frac{|G|}{\dim V} \right)^2$. We have shown that $\sum_{g, h \in G} ghg^{-1} h^{-1}$ and $\left( \sum_{g \in G} g^2 \right)^2 = \sum_{g,h \in G} g^2 h^2$ act on every irrep by the same scalar, so they are equal in the group algebra. QED. The same argument shows that, in any finite group, the number of ways to write $x$ as $f^2 g^2 h^2$ is the same as the number of ways to write $x$ as $f^2 g h g^{-1} h^{-1}$, using that the Frob. Schur indicator is always $-1$, $0$ or $1$ and thus obeys $\epsilon^3 = \epsilon$. In case anyone finds that easier to think about...",,"['abstract-algebra', 'group-theory', 'finite-groups', 'representation-theory', 'alternative-proof']"
34,Proof a Rng cannot have exactly five non-zero divisors.,Proof a Rng cannot have exactly five non-zero divisors.,,"Let $R$ be a Rng (a ring which does not necessarily have a $1$). We call an element $a$ regular if $xa=0$ implies $x=0$ and $ax=0$ implies $x=0$. Prove $R$ cannot have exactly five regular elements. This problem is from the Galois-Noether competition. This is the progress so far. regular elements are closed under multiplication, their multiplications are cancellative. Therefore we can conceive the set $M$ of regular elements, if it had order $5$ then it would be a finite cancellative semigroup, hence a group. Since $5$ is prime it would have to be a cyclic group. Therefore $M$, with multiplication, would be isomorphic to $\mathbb Z_5$. I don't now if this is useful, but this is what I've found, I also have to thank Anon from chat for his help.","Let $R$ be a Rng (a ring which does not necessarily have a $1$). We call an element $a$ regular if $xa=0$ implies $x=0$ and $ax=0$ implies $x=0$. Prove $R$ cannot have exactly five regular elements. This problem is from the Galois-Noether competition. This is the progress so far. regular elements are closed under multiplication, their multiplications are cancellative. Therefore we can conceive the set $M$ of regular elements, if it had order $5$ then it would be a finite cancellative semigroup, hence a group. Since $5$ is prime it would have to be a cyclic group. Therefore $M$, with multiplication, would be isomorphic to $\mathbb Z_5$. I don't now if this is useful, but this is what I've found, I also have to thank Anon from chat for his help.",,"['abstract-algebra', 'ring-theory', 'contest-math']"
35,Which field is it?,Which field is it?,,"Consider the ring $R=\mathbb{Z}^\mathbb{N}$ of integer sequences with the usual componentwise operations and let $I$ be the ideal of sequences that are eventually zero.  Questions: Is there a unique maximal ideal $\mathfrak m \supseteq I$ of $R$ ? Is $R/\mathfrak m$ isomorphic to a well-known field (like $\mathbb{R}, \mathbb{Q}_p$,...) where $\mathfrak m\supseteq I$ is any maximal ideal ?","Consider the ring $R=\mathbb{Z}^\mathbb{N}$ of integer sequences with the usual componentwise operations and let $I$ be the ideal of sequences that are eventually zero.  Questions: Is there a unique maximal ideal $\mathfrak m \supseteq I$ of $R$ ? Is $R/\mathfrak m$ isomorphic to a well-known field (like $\mathbb{R}, \mathbb{Q}_p$,...) where $\mathfrak m\supseteq I$ is any maximal ideal ?",,['abstract-algebra']
36,"Example of unital non-commutative ring with $(ab)^2=(ba)^2$ for all $a,b$",Example of unital non-commutative ring with  for all,"(ab)^2=(ba)^2 a,b","I'm trying to exhibit a unital, non-commutative ring $R$ such that $(ab)^2=(ba)^2$ for all $a,b\in R$. This is an exercise out of Herstein's Topics in Algebra . In the previous exercise , I showed that if $R$ was unital, had the same property regarding squares, but also had the property that $2a=0$ implied $a=0$ for any $a\in R$, then $R$ was commutative. Therefore I've tried several things with the quaternions, the $2\times 2$ matrices, the $3\times 3$ matrices, and even block matrices, all over $\mathbb{Z}/2\mathbb{Z}$ and $\mathbb{Z}/4\mathbb{Z}$. I can't seem to come up with anything, though, and I'd appreciate a hint.","I'm trying to exhibit a unital, non-commutative ring $R$ such that $(ab)^2=(ba)^2$ for all $a,b\in R$. This is an exercise out of Herstein's Topics in Algebra . In the previous exercise , I showed that if $R$ was unital, had the same property regarding squares, but also had the property that $2a=0$ implied $a=0$ for any $a\in R$, then $R$ was commutative. Therefore I've tried several things with the quaternions, the $2\times 2$ matrices, the $3\times 3$ matrices, and even block matrices, all over $\mathbb{Z}/2\mathbb{Z}$ and $\mathbb{Z}/4\mathbb{Z}$. I can't seem to come up with anything, though, and I'd appreciate a hint.",,"['abstract-algebra', 'ring-theory', 'noncommutative-algebra']"
37,Radical/Prime/Maximal ideals under quotient maps,Radical/Prime/Maximal ideals under quotient maps,,"Let $I$ be an ideal of a ring (commutative with unity) $R$ and let $q:R\to R/I$ be the quotient map. Then there is a well known correspondence between ideals of $R$ containing $I$ and ideals of $R/I.$ Let $J$ be an ideal of $R$ containing $I$ and let $J'$ be the corresponding ideal in the quotient ring. I had to show that $J$ is radical/prime/maximal iff $J'$ is radical/prime/maximal. Showing $J$ is radical/prime/maximal if $J'$ is was simple enough by direct element manipulation arguments. For the other direction, I did it by using $J'=J/I,$ the fact that ideals are radical/prime/maximal iff their quotient rings are reduced/domains/fields and the second isomorphism theorem. However, I tried unsuccessfully to find a ""direct"" proof that perhaps manipulates elements of the ring in a similar way to the other direction. Is there a more direct proof? I'm wondering this especially for the radical ideals, because this is Exercise 1.22 (page 7) in Fulton's Algebraic Curves and he has never even mentioned reduced rings or nilradicals yet, and doesn't expect you to know it already because he introduced what radical ideals were.","Let $I$ be an ideal of a ring (commutative with unity) $R$ and let $q:R\to R/I$ be the quotient map. Then there is a well known correspondence between ideals of $R$ containing $I$ and ideals of $R/I.$ Let $J$ be an ideal of $R$ containing $I$ and let $J'$ be the corresponding ideal in the quotient ring. I had to show that $J$ is radical/prime/maximal iff $J'$ is radical/prime/maximal. Showing $J$ is radical/prime/maximal if $J'$ is was simple enough by direct element manipulation arguments. For the other direction, I did it by using $J'=J/I,$ the fact that ideals are radical/prime/maximal iff their quotient rings are reduced/domains/fields and the second isomorphism theorem. However, I tried unsuccessfully to find a ""direct"" proof that perhaps manipulates elements of the ring in a similar way to the other direction. Is there a more direct proof? I'm wondering this especially for the radical ideals, because this is Exercise 1.22 (page 7) in Fulton's Algebraic Curves and he has never even mentioned reduced rings or nilradicals yet, and doesn't expect you to know it already because he introduced what radical ideals were.",,"['abstract-algebra', 'commutative-algebra', 'ring-theory', 'ideals']"
38,Zero divisors in polynomial rings [duplicate],Zero divisors in polynomial rings [duplicate],,"This question already has answers here : Zero divisor in $R[x]$ (5 answers) Closed 8 years ago . The following is an exercise in Hungerford (Ch. III, ex. 5.6). Let $R$ be a commutative ring with identity. If $f=a_nx^n+\dots+a_0$ is a zero divisor   in $R[x]$, then there exists a nonzero $b$ in $R$ such that $ba_n=ba_{n-1}=\dots=ba_0=0$. I can see for example that $\{g\in R[x]\mid fg=0\}$ is a nonzero ideal, so it contains a nonzero element of smallest degree.  But how to show that such an element is actually a constant?","This question already has answers here : Zero divisor in $R[x]$ (5 answers) Closed 8 years ago . The following is an exercise in Hungerford (Ch. III, ex. 5.6). Let $R$ be a commutative ring with identity. If $f=a_nx^n+\dots+a_0$ is a zero divisor   in $R[x]$, then there exists a nonzero $b$ in $R$ such that $ba_n=ba_{n-1}=\dots=ba_0=0$. I can see for example that $\{g\in R[x]\mid fg=0\}$ is a nonzero ideal, so it contains a nonzero element of smallest degree.  But how to show that such an element is actually a constant?",,"['abstract-algebra', 'polynomials']"
39,"What is the ""higher cohomology"" version of the Eudoxus reals?","What is the ""higher cohomology"" version of the Eudoxus reals?",,"The ""Eudoxus reals"" are one way to construct $\mathbb{R}$ directly from the integers. A full account is given by Arthan ; here is the short version: A function $f: \mathbb{Z} \to \mathbb{Z}$ is an ""almost homomorphism"" if the function $d_f: \mathbb{Z} \times \mathbb{Z} \to \mathbb{Z}$ defined by $d_f(a,b) = f(a+b) - f(a) - f(b)$ has finite/bounded image. The set of almost homomorphisms forms a group under pointwise addition, and the quotient of this group by the subgroup of functions $f$ with bounded image is isomorphic to the real numbers. This same construction can be applied to functions $f: G \to H$ where $G$ and $H$ are abelian groups. If they are both finitely generated, then Arthan shows that the resulting group is isomorphic to $\operatorname{Hom}_{\text{Ab}}(G, H) \otimes \mathbb{R}$ . (*) There is a ""higher cohomology"" version of this construction. For example, say that a function $f: \mathbb{Z} \times \mathbb{Z} \to \mathbb{Z}$ is an ""almost 2-cocycle"" if the function $d_f: \mathbb{Z}^3 \to \mathbb{Z}$ defined by $d_f(a,b,c) = f(b,c) - f(a+b,c) + f(a,b+c) - f(a,b)$ has finite image. These form a group under addition. The subgroup of ""almost 2-coboundaries"" is the subgroup generated by the true 2-coboundaries (functions of the form $f(a,b) = g(a+b) - g(a) - g(b)$ for some function $g: \mathbb{Z} \to \mathbb{Z}$ ) and by the functions which have finite image. My question is: What is the quotient of the group of almost 2-cocyles by the subgroup of almost 2-coboundaries? (Call this quotient $H^2_{\text{almost}}(\mathbb{Z}, \mathbb{Z})$ .) More generally, what do we get if we repeat this construction for arbitrary abelian groups $G, H$ and consider almost $n$ -cocycles and almost $n$ -coboundaries? In light of (*), I would expect the answer to be some kind of higher Ext group tensored with $\mathbb{R}$ . In particular, since $H^2(\mathbb{Z}, \mathbb{Z}) = 0$ , I would expect that $H^2_{\text{almost}}(\mathbb{Z}, \mathbb{Z}) = 0$ as well. Therefore, a more specific question is: Is the implication $H^2(\mathbb{Z}, \mathbb{Z}) = 0 \Rightarrow H^2_{\text{almost}}(\mathbb{Z}, \mathbb{Z}) = 0$ true, and if so, is there a concrete way to see it?","The ""Eudoxus reals"" are one way to construct directly from the integers. A full account is given by Arthan ; here is the short version: A function is an ""almost homomorphism"" if the function defined by has finite/bounded image. The set of almost homomorphisms forms a group under pointwise addition, and the quotient of this group by the subgroup of functions with bounded image is isomorphic to the real numbers. This same construction can be applied to functions where and are abelian groups. If they are both finitely generated, then Arthan shows that the resulting group is isomorphic to . (*) There is a ""higher cohomology"" version of this construction. For example, say that a function is an ""almost 2-cocycle"" if the function defined by has finite image. These form a group under addition. The subgroup of ""almost 2-coboundaries"" is the subgroup generated by the true 2-coboundaries (functions of the form for some function ) and by the functions which have finite image. My question is: What is the quotient of the group of almost 2-cocyles by the subgroup of almost 2-coboundaries? (Call this quotient .) More generally, what do we get if we repeat this construction for arbitrary abelian groups and consider almost -cocycles and almost -coboundaries? In light of (*), I would expect the answer to be some kind of higher Ext group tensored with . In particular, since , I would expect that as well. Therefore, a more specific question is: Is the implication true, and if so, is there a concrete way to see it?","\mathbb{R} f: \mathbb{Z} \to \mathbb{Z} d_f: \mathbb{Z} \times \mathbb{Z} \to \mathbb{Z} d_f(a,b) = f(a+b) - f(a) - f(b) f f: G \to H G H \operatorname{Hom}_{\text{Ab}}(G, H) \otimes \mathbb{R} f: \mathbb{Z} \times \mathbb{Z} \to \mathbb{Z} d_f: \mathbb{Z}^3 \to \mathbb{Z} d_f(a,b,c) = f(b,c) - f(a+b,c) + f(a,b+c) - f(a,b) f(a,b) = g(a+b) - g(a) - g(b) g: \mathbb{Z} \to \mathbb{Z} H^2_{\text{almost}}(\mathbb{Z}, \mathbb{Z}) G, H n n \mathbb{R} H^2(\mathbb{Z}, \mathbb{Z}) = 0 H^2_{\text{almost}}(\mathbb{Z}, \mathbb{Z}) = 0 H^2(\mathbb{Z}, \mathbb{Z}) = 0 \Rightarrow H^2_{\text{almost}}(\mathbb{Z}, \mathbb{Z}) = 0","['abstract-algebra', 'homology-cohomology', 'homological-algebra', 'real-numbers', 'group-cohomology']"
40,$\mathbb{Q}(i)$ has no unramified extensions,has no unramified extensions,\mathbb{Q}(i),"It is a classical result that every extension of $\mathbb{Q}$ is ramified. Put differently: there are no unramified extensions of $\mathbb{Q}$ . The classical proof follows from the following two statements: (a) The only number field having discriminant $1$ is $\mathbb{Q}$ itself. (b) A prime number $p$ ramifies in a number field $K$ if and only if it is a divisor of the discriminant $\Delta_K$ . Is it possible to argue for something similar for $\mathbb{Q}(i)$ ? The goal of my question is to construct an example of a Hilbert Class Field without appealing (yet) to Artin Reciprocity. Using Artin Reciprocity, one has that $Gal(L/\mathbb{Q}) \cong Cl(\mathbb{Q})$ , where $L$ is the Hilbert Class Field of $K=\mathbb{Q}$ . Now, because $\mathbb{Z}$ is a PID, the class group becomes trivial, and we have that $L=\mathbb{Q}$ . Since $L$ is by definition the maximal unramified abelian extension of $K=\mathbb{Q}$ , this implies that there are no unramified extensions of $\mathbb{Q}$ . Repeating the argument (and observing that $\mathbb{Z}[i]$ is a PID), one deduces that the Hilbert Class Field of $K=\mathbb{Q}(i)$ is $L=\mathbb{Q}(i)$ . But this just means that $\mathbb{Q}(i)$ has no unramified extensions. However, I would like to have a proof from scratch which argues that $\mathbb{Q}(i)$ has no unramified extensions. EDIT: My question seems related to this MO post but I am having trouble following the argument there.","It is a classical result that every extension of is ramified. Put differently: there are no unramified extensions of . The classical proof follows from the following two statements: (a) The only number field having discriminant is itself. (b) A prime number ramifies in a number field if and only if it is a divisor of the discriminant . Is it possible to argue for something similar for ? The goal of my question is to construct an example of a Hilbert Class Field without appealing (yet) to Artin Reciprocity. Using Artin Reciprocity, one has that , where is the Hilbert Class Field of . Now, because is a PID, the class group becomes trivial, and we have that . Since is by definition the maximal unramified abelian extension of , this implies that there are no unramified extensions of . Repeating the argument (and observing that is a PID), one deduces that the Hilbert Class Field of is . But this just means that has no unramified extensions. However, I would like to have a proof from scratch which argues that has no unramified extensions. EDIT: My question seems related to this MO post but I am having trouble following the argument there.",\mathbb{Q} \mathbb{Q} 1 \mathbb{Q} p K \Delta_K \mathbb{Q}(i) Gal(L/\mathbb{Q}) \cong Cl(\mathbb{Q}) L K=\mathbb{Q} \mathbb{Z} L=\mathbb{Q} L K=\mathbb{Q} \mathbb{Q} \mathbb{Z}[i] K=\mathbb{Q}(i) L=\mathbb{Q}(i) \mathbb{Q}(i) \mathbb{Q}(i),"['abstract-algebra', 'algebraic-number-theory', 'class-field-theory']"
41,What are the commutative quasigroups satisfying $a/b=b/a$?,What are the commutative quasigroups satisfying ?,a/b=b/a,"There's a harder question lurking behind this question that was just asked. The context is quasigroup theory. A commutative quasigroup can be defined as a set $Q$ together with commutative binary operation $*$ such that for all $a,b \in Q$, there is a unique ""solution"" $s \in Q$ solving $s*a=b$. We write $b/a$ for the unique such $s$. The linked question (essentially) asks if there exists a commutative quasigroup satisfying the identity $a/b=b/a$. (Yes, for example $\mathbb{Z}/2\mathbb{Z}$ has this property with respect to addition.) What I'd like to know is, can we usefully characterize all commutative quasigroups satisfying this identity, including the non-associative ones? Ideas, anyone?","There's a harder question lurking behind this question that was just asked. The context is quasigroup theory. A commutative quasigroup can be defined as a set $Q$ together with commutative binary operation $*$ such that for all $a,b \in Q$, there is a unique ""solution"" $s \in Q$ solving $s*a=b$. We write $b/a$ for the unique such $s$. The linked question (essentially) asks if there exists a commutative quasigroup satisfying the identity $a/b=b/a$. (Yes, for example $\mathbb{Z}/2\mathbb{Z}$ has this property with respect to addition.) What I'd like to know is, can we usefully characterize all commutative quasigroups satisfying this identity, including the non-associative ones? Ideas, anyone?",,"['abstract-algebra', 'quasigroups']"
42,Necessary and sufficient conditions for a polynomial in $\mathbb{Z}[t]$ to have an $n$th root in $\mathbb{Z}[[t]]$,Necessary and sufficient conditions for a polynomial in  to have an th root in,\mathbb{Z}[t] n \mathbb{Z}[[t]],"Let $p(t) = \sum p_k t^k$ be a polynomial in $\mathbb{Z}[t]$, with $p_0=1$.  Is there a necessary and sufficient condition (congruence or other) on the coefficients $p_k$ such that $p(t)$ admits a square root in $\mathbb{Z}[[t]]$? More generally, is there a necessary and sufficient condition for $p(t)$ to have an $n$-th root in $\mathbb{Z}[[t]]$? Based on the fact that $(1+n^2z)^{1/n} \in \mathbb{Z}[[z]]$ for any $n \in \mathbb{Z}^+$, we obtain a sufficient condition, namely that $n^2 \mid p_k$ for all $k>0$.  This is, however, very weak. Edit: Clarified notation as per one of the comments.  Also, a recent paper `On the Integrality of $n$th Roots of Generating Functions' by Heninger, Rains, and Sloane provides a criterion that may be of some use: ""Let $\mu_n = n \prod_{q \mid n} q$ where $q$ ranges over the primes dividing $n$.  Then $f= \sum u_n t^n \in \mathbb{Z}[[t]]$ admits an $n$th root in $\mathbb{Z}[[t]]$ if and only if $f \mod \mu_n$ does as well."" As such, we can hope to get lucky and have some reduction that is obviously an $n$th power (for example, if $f \mod \mu_n$ is the power of some polynomial , instead of just a power series.  Note of course that this does not resolve our original question. Edit II: This question has been untouched for a long while, but perhaps this will help another as a reference.  For completeness, I'd like to add that the condition that $p$ reduce modulo $\mu_n$ to the $n$th power of a polynomial in $\mathbb{Z}[t]$ is actually both sufficient and necessary for $p$ to admit an $n$th root in $\mathbb{Z}[[t]]$ (given, of course, that $p(0)=1$).  The proof relies on the following combinatorial lemma, that $$\mu_n \mid (\mu_n/n)^k \binom{n}{k}$$ for $k=1,\ldots, n$.  One may then show that our $n$th roots of $p(t)$, say $\sum a_n t^n \in \mathbb{Z}[[t]]$, reduce to polynomials $\mod \mu_n/n$, by showing that $n a_n$ is eventually divisible by $(\mu_n/n)^k \binom{n}{k}$ for some $k$, through a symmetry/combinatorial argument.","Let $p(t) = \sum p_k t^k$ be a polynomial in $\mathbb{Z}[t]$, with $p_0=1$.  Is there a necessary and sufficient condition (congruence or other) on the coefficients $p_k$ such that $p(t)$ admits a square root in $\mathbb{Z}[[t]]$? More generally, is there a necessary and sufficient condition for $p(t)$ to have an $n$-th root in $\mathbb{Z}[[t]]$? Based on the fact that $(1+n^2z)^{1/n} \in \mathbb{Z}[[z]]$ for any $n \in \mathbb{Z}^+$, we obtain a sufficient condition, namely that $n^2 \mid p_k$ for all $k>0$.  This is, however, very weak. Edit: Clarified notation as per one of the comments.  Also, a recent paper `On the Integrality of $n$th Roots of Generating Functions' by Heninger, Rains, and Sloane provides a criterion that may be of some use: ""Let $\mu_n = n \prod_{q \mid n} q$ where $q$ ranges over the primes dividing $n$.  Then $f= \sum u_n t^n \in \mathbb{Z}[[t]]$ admits an $n$th root in $\mathbb{Z}[[t]]$ if and only if $f \mod \mu_n$ does as well."" As such, we can hope to get lucky and have some reduction that is obviously an $n$th power (for example, if $f \mod \mu_n$ is the power of some polynomial , instead of just a power series.  Note of course that this does not resolve our original question. Edit II: This question has been untouched for a long while, but perhaps this will help another as a reference.  For completeness, I'd like to add that the condition that $p$ reduce modulo $\mu_n$ to the $n$th power of a polynomial in $\mathbb{Z}[t]$ is actually both sufficient and necessary for $p$ to admit an $n$th root in $\mathbb{Z}[[t]]$ (given, of course, that $p(0)=1$).  The proof relies on the following combinatorial lemma, that $$\mu_n \mid (\mu_n/n)^k \binom{n}{k}$$ for $k=1,\ldots, n$.  One may then show that our $n$th roots of $p(t)$, say $\sum a_n t^n \in \mathbb{Z}[[t]]$, reduce to polynomials $\mod \mu_n/n$, by showing that $n a_n$ is eventually divisible by $(\mu_n/n)^k \binom{n}{k}$ for some $k$, through a symmetry/combinatorial argument.",,"['abstract-algebra', 'power-series']"
43,Is there some sort of classification of all minimal non-cyclic groups?,Is there some sort of classification of all minimal non-cyclic groups?,,"Does there exist some sort of classification of all minimal non-cyclic groups (non-cyclic groups, such that all their proper subgroups are cyclic) I know the following classes of such groups: 1) $C_p × C_p$ , where $p$ is a prime 2) $Q_8$ 3) $\langle a,b | a^p = b^{q^m} = 1, b^{−1}ab = a^{r}\rangle$ , where $p$ and $q$ are distinct primes and $r ≡ 1 \pmod q$ , $r^q ≡1 \pmod p$ . (These three classes completely cover the case, when our group is finite: Classification of finite minimal non-cyclic group ) 4) $C_{p^{\infty}}$ , where $p$ is a prime 5) $(\{ \frac{n}{p^m}| m, n \in \mathbb{Z} \}, +)$ , where $p$ is a prime (These two classes completely cover the case, when our group is infinite abelian: Does there exist an infinite non-abelian group such that all of its proper subgroups become cyclic? ) 6)Infinite non-abelian groups, such that all their nontrivial proper subgroups are isomorphic to $C_{p}$ for a fixed prime $p$ (Tarski monster groups) 7)Infinite non-abelian groups, such that all their nontrivial proper subgroups are isomorphic to $C_{\infty}$ ( Does there exist an infinite non-abelian group, such that all its nontrivial proper subgroups are isomorphic to $C_\infty$? ). However, I do not know, whether there exists anything, that does not fall into these classes. I only know, that if such groups exist, they have to be infinite non-abelian.","Does there exist some sort of classification of all minimal non-cyclic groups (non-cyclic groups, such that all their proper subgroups are cyclic) I know the following classes of such groups: 1) , where is a prime 2) 3) , where and are distinct primes and , . (These three classes completely cover the case, when our group is finite: Classification of finite minimal non-cyclic group ) 4) , where is a prime 5) , where is a prime (These two classes completely cover the case, when our group is infinite abelian: Does there exist an infinite non-abelian group such that all of its proper subgroups become cyclic? ) 6)Infinite non-abelian groups, such that all their nontrivial proper subgroups are isomorphic to for a fixed prime (Tarski monster groups) 7)Infinite non-abelian groups, such that all their nontrivial proper subgroups are isomorphic to ( Does there exist an infinite non-abelian group, such that all its nontrivial proper subgroups are isomorphic to $C_\infty$? ). However, I do not know, whether there exists anything, that does not fall into these classes. I only know, that if such groups exist, they have to be infinite non-abelian.","C_p × C_p p Q_8 \langle a,b | a^p = b^{q^m} = 1, b^{−1}ab = a^{r}\rangle p q r ≡ 1 \pmod q r^q ≡1 \pmod p C_{p^{\infty}} p (\{ \frac{n}{p^m}| m, n \in \mathbb{Z} \}, +) p C_{p} p C_{\infty}","['abstract-algebra', 'group-theory', 'cyclic-groups', 'infinite-groups']"
44,Can any commutative ring of characteristic $p\in\mathbb P$ be written as the form $R/(p)$ with $R$ being a ring of characteristic $0$?,Can any commutative ring of characteristic  be written as the form  with  being a ring of characteristic ?,p\in\mathbb P R/(p) R 0,"Let $S$ be a commutative ring with identity with $\operatorname{char}S=p$, where $p$ is a prime number. I wonder if we can always find a ring $R$ such that $\operatorname{char}R=0$ and $R/(p)\cong S$. I think above question is equivalent to if for every $\mathbb Z_{p}$-polynomial algebra $A$ and ideal $I$ of $A$ containing $p$, there exists an ideal $J$ not containing nonzero constants such that $I=(p)+J$. But I'm not sure if the latter simplifies the former. Moreover, it'll be more preferable if such a $R$ admits a canonical projection $\varphi:R\twoheadrightarrow S$ in the sense that every ring homomorphism from a ring of characteristic $0$ to $S$ can be factored through $\varphi$.","Let $S$ be a commutative ring with identity with $\operatorname{char}S=p$, where $p$ is a prime number. I wonder if we can always find a ring $R$ such that $\operatorname{char}R=0$ and $R/(p)\cong S$. I think above question is equivalent to if for every $\mathbb Z_{p}$-polynomial algebra $A$ and ideal $I$ of $A$ containing $p$, there exists an ideal $J$ not containing nonzero constants such that $I=(p)+J$. But I'm not sure if the latter simplifies the former. Moreover, it'll be more preferable if such a $R$ admits a canonical projection $\varphi:R\twoheadrightarrow S$ in the sense that every ring homomorphism from a ring of characteristic $0$ to $S$ can be factored through $\varphi$.",,"['abstract-algebra', 'ring-theory', 'commutative-algebra']"
45,"What properties do the rings of infinite, upper-triangular matrices have?","What properties do the rings of infinite, upper-triangular matrices have?",,"I'm very familiar with the ring of $n\times n$ matrices over a field , the ring of $n\times n$ upper triangular matrices over a field , and the ring of infinite column-finite matrices over a field . But until now, I haven't asked myself about infinite upper triangular matrix rings over a field (sides indexed by some infinite set $I$ which has a linear order.) ""Upper triangular"" means, of course, that the $i,j$ entries are zero if $i >j$. Let's call the ring $R$, and assume $I=\Bbb N$ for simplicity. This ring can be realized as a subring of the linear transformations of a countable dimensional vector space in the following way: select a chain of subspaces $V_i$ of dimension $i$ for each natural number $i$, with $V_i\subseteq V_{i+1}$ for all $i$. The set of transformations which map $V_i$ into $V_i$ for all $i$ is represented by the ring we are speaking of. What can be said about $R$'s ring-theoretic properties? It seems to satisfy quite few positively. Structurally: It is clearly a subring of the ring of column-finite matrices indexed with $I$. it seems the Jacobson radical $J(R)$ is still the strictly upper triangular matrices. The Jacobson radical isn't nilpotent anymore when $I$ is infinite (it is not even nil). I have read that the elements with no zeros on the diagonal are invertible. (Perhaps these are all the units?) It looks like the powers of $J(R)$ form an infinitely long filtration of ideals with intersection $\{0\}$. Some observations on properties: It's certainly not Artinian or Noetherian on either side. It isn't even semiprime: $e_{12}Re_{12}=0$ for the matrix units $e_{ij}$. Unlike the ring of column-finite matrices, the ring of upper triangular matrices is Dedekind finite since it has a commutative quotient ring (namely $R/J(R)$.) To give a few concrete questions: is it hereditary, semihereditary or coherent on either side? is it stably finite? What do its socles look like? What do its left/right singular ideals look like? I can split the question into two halves, perhaps, if the need arises.","I'm very familiar with the ring of $n\times n$ matrices over a field , the ring of $n\times n$ upper triangular matrices over a field , and the ring of infinite column-finite matrices over a field . But until now, I haven't asked myself about infinite upper triangular matrix rings over a field (sides indexed by some infinite set $I$ which has a linear order.) ""Upper triangular"" means, of course, that the $i,j$ entries are zero if $i >j$. Let's call the ring $R$, and assume $I=\Bbb N$ for simplicity. This ring can be realized as a subring of the linear transformations of a countable dimensional vector space in the following way: select a chain of subspaces $V_i$ of dimension $i$ for each natural number $i$, with $V_i\subseteq V_{i+1}$ for all $i$. The set of transformations which map $V_i$ into $V_i$ for all $i$ is represented by the ring we are speaking of. What can be said about $R$'s ring-theoretic properties? It seems to satisfy quite few positively. Structurally: It is clearly a subring of the ring of column-finite matrices indexed with $I$. it seems the Jacobson radical $J(R)$ is still the strictly upper triangular matrices. The Jacobson radical isn't nilpotent anymore when $I$ is infinite (it is not even nil). I have read that the elements with no zeros on the diagonal are invertible. (Perhaps these are all the units?) It looks like the powers of $J(R)$ form an infinitely long filtration of ideals with intersection $\{0\}$. Some observations on properties: It's certainly not Artinian or Noetherian on either side. It isn't even semiprime: $e_{12}Re_{12}=0$ for the matrix units $e_{ij}$. Unlike the ring of column-finite matrices, the ring of upper triangular matrices is Dedekind finite since it has a commutative quotient ring (namely $R/J(R)$.) To give a few concrete questions: is it hereditary, semihereditary or coherent on either side? is it stably finite? What do its socles look like? What do its left/right singular ideals look like? I can split the question into two halves, perhaps, if the need arises.",,"['abstract-algebra', 'ring-theory', 'noncommutative-algebra', 'infinite-matrices']"
46,"Induced representation, Ind(Res(U))","Induced representation, Ind(Res(U))",,"I am reading a book of Fulton and Harris ""Representation theory, a first course"". Now it's all about representation theory of finite groups, and there is one exercise, which I can't solve: If $U$ is a representation of $G$ and $W$ a representation of $H$ (here $H$ is a subgroup of $G$ ; further induced and restricted representations are all with respect to $H$ ), show that $U \otimes \operatorname{Ind} W = \operatorname{Ind}(\operatorname{Res}U \otimes W)$ . In particular, $\operatorname{Ind}(\operatorname{Res}U) = U \otimes P$ , where $P$ is the permutation representation of $G$ on $G/H$ . Actually, it's seems that it only requires to use definitions, but I stuck with it! The thing I don't really understand is : as I see, restriction doesn't serve the whole information about the original representation, but the formula says other things. If it's possible, give a detailed explanation, please. Thank you very much. P.S. Sorry for duplicating this question. There were 2 aswers given before: 1 and 2 . but the first was really hard to comprehend, and there was no full answer in the second. (The hint was to use Frobenius reciprocity, but the thing is in the book Frobenius reciprocity goes only after this exercise and I am not capable to go on until I completely understand this problem)","I am reading a book of Fulton and Harris ""Representation theory, a first course"". Now it's all about representation theory of finite groups, and there is one exercise, which I can't solve: If is a representation of and a representation of (here is a subgroup of ; further induced and restricted representations are all with respect to ), show that . In particular, , where is the permutation representation of on . Actually, it's seems that it only requires to use definitions, but I stuck with it! The thing I don't really understand is : as I see, restriction doesn't serve the whole information about the original representation, but the formula says other things. If it's possible, give a detailed explanation, please. Thank you very much. P.S. Sorry for duplicating this question. There were 2 aswers given before: 1 and 2 . but the first was really hard to comprehend, and there was no full answer in the second. (The hint was to use Frobenius reciprocity, but the thing is in the book Frobenius reciprocity goes only after this exercise and I am not capable to go on until I completely understand this problem)",U G W H H G H U \otimes \operatorname{Ind} W = \operatorname{Ind}(\operatorname{Res}U \otimes W) \operatorname{Ind}(\operatorname{Res}U) = U \otimes P P G G/H,"['abstract-algebra', 'group-theory', 'finite-groups', 'representation-theory']"
47,Is $\bigl(X(X-a)(X-b)\bigr)^{2^n} +1$ an irreducible polynomial over $\mathbb{Q}[X]$?,Is  an irreducible polynomial over ?,\bigl(X(X-a)(X-b)\bigr)^{2^n} +1 \mathbb{Q}[X],"Let $a, b \in \mathbb{Q}$, with $a\neq b$ and $ab\neq 0$, and $n$ a positive integer. Is the polynomial $\bigl(X(X-a)(X-b)\bigr)^{2^n} +1$ irreducible over $\mathbb{Q}[X]$? I know that $\bigl(X(X-a)\bigr)^{2^n} +1$ is irreducible over $\mathbb{Q}[X]$, but I have a hard time generalizing my proof with three factors. PS: This is not homework (and may even be open).","Let $a, b \in \mathbb{Q}$, with $a\neq b$ and $ab\neq 0$, and $n$ a positive integer. Is the polynomial $\bigl(X(X-a)(X-b)\bigr)^{2^n} +1$ irreducible over $\mathbb{Q}[X]$? I know that $\bigl(X(X-a)\bigr)^{2^n} +1$ is irreducible over $\mathbb{Q}[X]$, but I have a hard time generalizing my proof with three factors. PS: This is not homework (and may even be open).",,"['abstract-algebra', 'polynomials', 'irreducible-polynomials', 'cyclotomic-polynomials']"
48,"Abusing mathematical notation, are these examples of abuse?","Abusing mathematical notation, are these examples of abuse?",,"I have often seen notation like this: Let $f:\mathbb{R}^2 \to \mathbb{R}$ be defined by $$f(x,y)=x^2+83xy+y^7$$ How does this make any sense? If the domain is $\mathbb{R}^2$ then $f$ should be mapping individual tuples. Therefore I expect a proper representation of the above function would be: $$f(t)=\pi_1(t)^2+83\pi_1(t)\pi_2(t)+\pi_2(t)^7$$ Isn't this more accurate? If the domain is $\mathbb{R}\times \mathbb{R}=\mathbb{R}^2$ and $\mathbb{R}\times \mathbb{R}=\{(x,y):(x\in \mathbb{R})\land (y\in \mathbb{R})\}$ then every element in the domain is a two-tuple $(x,y)$ not some irregular expression composed of two variables seperated by a comma like ""$x,y$"" right? Also when speaking of algebraic structures why do people constantly interchange the carrier set with the algebraic structure itself. For example you might see someone write this: Given any field $\mathbb{F}$ take those elements in our field $a\in \mathbb{F}$ that satisfy the equation $a^8=a$. How does this make any sense? If $\mathbb{F}$ is a field then it is a tuple equipped with two binary operations and corresponding identity elements all of which satisfy a variety of axioms. Thus we should have for some set $S$ that $\mathbb{F}=(S,+,\times,0,1)$ so they would be writing $a\in (S,+,\times,0,1)$ which is gibberish, they should write $a\in S$. Again I see the field $\mathbb{F}$ and its underlying set $S$ are being interchanged, I see this across almost all areas of abstract algebra with monoids, groups, rings etc.","I have often seen notation like this: Let $f:\mathbb{R}^2 \to \mathbb{R}$ be defined by $$f(x,y)=x^2+83xy+y^7$$ How does this make any sense? If the domain is $\mathbb{R}^2$ then $f$ should be mapping individual tuples. Therefore I expect a proper representation of the above function would be: $$f(t)=\pi_1(t)^2+83\pi_1(t)\pi_2(t)+\pi_2(t)^7$$ Isn't this more accurate? If the domain is $\mathbb{R}\times \mathbb{R}=\mathbb{R}^2$ and $\mathbb{R}\times \mathbb{R}=\{(x,y):(x\in \mathbb{R})\land (y\in \mathbb{R})\}$ then every element in the domain is a two-tuple $(x,y)$ not some irregular expression composed of two variables seperated by a comma like ""$x,y$"" right? Also when speaking of algebraic structures why do people constantly interchange the carrier set with the algebraic structure itself. For example you might see someone write this: Given any field $\mathbb{F}$ take those elements in our field $a\in \mathbb{F}$ that satisfy the equation $a^8=a$. How does this make any sense? If $\mathbb{F}$ is a field then it is a tuple equipped with two binary operations and corresponding identity elements all of which satisfy a variety of axioms. Thus we should have for some set $S$ that $\mathbb{F}=(S,+,\times,0,1)$ so they would be writing $a\in (S,+,\times,0,1)$ which is gibberish, they should write $a\in S$. Again I see the field $\mathbb{F}$ and its underlying set $S$ are being interchanged, I see this across almost all areas of abstract algebra with monoids, groups, rings etc.",,"['abstract-algebra', 'group-theory', 'functions', 'notation', 'definition']"
49,"If $x^m=e$ has at most $m$ solutions for any $m\in \mathbb{N}$, then $G$ is cyclic","If  has at most  solutions for any , then  is cyclic",x^m=e m m\in \mathbb{N} G,"Fraleigh(7th ed) Sec10, Ex47. Let $G$ be a finite group. Show that if for each positive integer $m$ the number of solutions $x$ of the equation $x^m=e$ in $G$ is at most $m$, then $G$ is cyclic. I tried it a few hours but I couldn't solve it. So I read the solution. But I narrowly understood the solution, and it's still unclear to me. How can I solve it?","Fraleigh(7th ed) Sec10, Ex47. Let $G$ be a finite group. Show that if for each positive integer $m$ the number of solutions $x$ of the equation $x^m=e$ in $G$ is at most $m$, then $G$ is cyclic. I tried it a few hours but I couldn't solve it. So I read the solution. But I narrowly understood the solution, and it's still unclear to me. How can I solve it?",,"['abstract-algebra', 'group-theory', 'finite-groups']"
50,Does an isomorphism of groups that can be written as a direct product induce isomorphisms on the factors?,Does an isomorphism of groups that can be written as a direct product induce isomorphisms on the factors?,,"An answer to question Isomorphism of Direct Product of Groups says if you have two  (or more) group isomorphisms $ \phi_1:A_1 \rightarrow X_1 $ and $ \phi_2:A_2 \rightarrow X_2 $ then it follows that $ A_1 \times A_2 \cong X_1 \times X_2 $ under the isomorphism $\phi(a_1,a_2)=(\phi_1(a_1),\phi_2 (a_2) )$ I am interested in whether the converse of this statement is true. If $\phi: A_1 \times A_2 \rightarrow X_1 \times X_2 $ is an isomorphism, is it true that $A_1 \cong  X_1 $ under an isomorphism  $ \phi_1 $ and $ A_2 \cong X_2 $ under an isomorphism $\phi_2$ such that $ \phi(a_1,a_2)= (\phi_1 (a_1), \phi (a_2)) $?","An answer to question Isomorphism of Direct Product of Groups says if you have two  (or more) group isomorphisms $ \phi_1:A_1 \rightarrow X_1 $ and $ \phi_2:A_2 \rightarrow X_2 $ then it follows that $ A_1 \times A_2 \cong X_1 \times X_2 $ under the isomorphism $\phi(a_1,a_2)=(\phi_1(a_1),\phi_2 (a_2) )$ I am interested in whether the converse of this statement is true. If $\phi: A_1 \times A_2 \rightarrow X_1 \times X_2 $ is an isomorphism, is it true that $A_1 \cong  X_1 $ under an isomorphism  $ \phi_1 $ and $ A_2 \cong X_2 $ under an isomorphism $\phi_2$ such that $ \phi(a_1,a_2)= (\phi_1 (a_1), \phi (a_2)) $?",,"['abstract-algebra', 'group-theory', 'group-isomorphism']"
51,Advice on finding counterexamples,Advice on finding counterexamples,,"I am reaching out for specific advice on how one should go about finding counterexamples. It seems almost every time I've ever attempted a ""find a counterexample"" problem, I have to cheat by asking a friend, or I have to use a computer. That being said, I've encountered another problem which I can look up the solution to, and probably understand why it is a counter example after it is given to me, but I am helpless when it comes to actually finding it. That being said, I am asking if someone could post a counterexample to the following problem and explain to me their thought process. This would help me so much. Problem: Give an example of two subgroups $H$ and $K$ of a group $G$ whose union $H\cup K$ is not a subgroup of $G$. How far I've gotten: I know that a nonempty subset $H$ of a finite group $G$ is a subgroup if and only if $a,b\in H$ implies $ab\in H$. Using this we can know that  If $a,b\in H\cup K$, but $ab\not \in H\cup K$, then $H$ is not a subgroup of $G$. So I know what a counterexample should look like if I see one, but how do I find it? Thanks so much.","I am reaching out for specific advice on how one should go about finding counterexamples. It seems almost every time I've ever attempted a ""find a counterexample"" problem, I have to cheat by asking a friend, or I have to use a computer. That being said, I've encountered another problem which I can look up the solution to, and probably understand why it is a counter example after it is given to me, but I am helpless when it comes to actually finding it. That being said, I am asking if someone could post a counterexample to the following problem and explain to me their thought process. This would help me so much. Problem: Give an example of two subgroups $H$ and $K$ of a group $G$ whose union $H\cup K$ is not a subgroup of $G$. How far I've gotten: I know that a nonempty subset $H$ of a finite group $G$ is a subgroup if and only if $a,b\in H$ implies $ab\in H$. Using this we can know that  If $a,b\in H\cup K$, but $ab\not \in H\cup K$, then $H$ is not a subgroup of $G$. So I know what a counterexample should look like if I see one, but how do I find it? Thanks so much.",,"['abstract-algebra', 'examples-counterexamples']"
52,When does the product of two polynomials = $x^{k}$?,When does the product of two polynomials = ?,x^{k},"Suppose $f$ and $g$ are are two polynomials with complex coefficents (i.e $f,g \in \mathbb{C}[x]$). Let $m$ be the order of $f$ and let $n$ be the order of $g$. Are there some general conditions where $fg= \alpha x^{n+m}$ for some non-zero $\alpha \in \mathbb{C}$","Suppose $f$ and $g$ are are two polynomials with complex coefficents (i.e $f,g \in \mathbb{C}[x]$). Let $m$ be the order of $f$ and let $n$ be the order of $g$. Are there some general conditions where $fg= \alpha x^{n+m}$ for some non-zero $\alpha \in \mathbb{C}$",,"['abstract-algebra', 'polynomials']"
53,Is there an example of an ordered ring that is not isomorphic to any subring of the real numbers?,Is there an example of an ordered ring that is not isomorphic to any subring of the real numbers?,,"Somebody told me it's possible to show the existence of rings non-isomorphic to any subring of the real numbers using model theory, but they couldn't get an example.","Somebody told me it's possible to show the existence of rings non-isomorphic to any subring of the real numbers using model theory, but they couldn't get an example.",,"['abstract-algebra', 'ring-theory', 'order-theory']"
54,Why isn't $D_\infty$ the set of symmetries of a circle?,Why isn't  the set of symmetries of a circle?,D_\infty,"According to Wikipedia, ""the infinite dihedral group Dih∞ is an infinite group with properties analogous to those of the finite dihedral groups."" However, it doesn't appear that this has anything to do with the symmetries of the circle, which surprised me, because that seems like the most natural generalization of the finite-order dihedral groups, which are sets of symmetries of regular polygons. Put another way, since regular polygons ""approach"" becoming a circle as the number of vertices, $n\to\infty$, it seems like $D_\infty$ should be the symmetries of the circle. So what kinds of symmetries does $D_\infty$ represent, and why was this group chosen for extension of the finite dihedral groups over the symmetries of the circle? (Or are they related in some way I'm just not grasping?)","According to Wikipedia, ""the infinite dihedral group Dih∞ is an infinite group with properties analogous to those of the finite dihedral groups."" However, it doesn't appear that this has anything to do with the symmetries of the circle, which surprised me, because that seems like the most natural generalization of the finite-order dihedral groups, which are sets of symmetries of regular polygons. Put another way, since regular polygons ""approach"" becoming a circle as the number of vertices, $n\to\infty$, it seems like $D_\infty$ should be the symmetries of the circle. So what kinds of symmetries does $D_\infty$ represent, and why was this group chosen for extension of the finite dihedral groups over the symmetries of the circle? (Or are they related in some way I'm just not grasping?)",,"['abstract-algebra', 'group-theory']"
55,Ring of trigonometric functions with real coefficients,Ring of trigonometric functions with real coefficients,,"Let $R$ be the ring of functions that are polynomials in $\cos t$ and $\sin t$ with real coefficients. Prove that $R$ is isomorphic to $\mathbb R[x,y]/(x^2+y^2-1)$. Prove that $R$ is not a unique factorization domain. Prove that $S=\mathbb C[x,y]/(x^2+y^2-1)$ is a principal ideal domain and hence a unique factorization domain. Determine the units of the rings $S$ and $R$. (Hint: Show that $S$ is isomorphic to the Laurent polynomial ring $\mathbb C[u,u^{-1}]$.)","Let $R$ be the ring of functions that are polynomials in $\cos t$ and $\sin t$ with real coefficients. Prove that $R$ is isomorphic to $\mathbb R[x,y]/(x^2+y^2-1)$. Prove that $R$ is not a unique factorization domain. Prove that $S=\mathbb C[x,y]/(x^2+y^2-1)$ is a principal ideal domain and hence a unique factorization domain. Determine the units of the rings $S$ and $R$. (Hint: Show that $S$ is isomorphic to the Laurent polynomial ring $\mathbb C[u,u^{-1}]$.)",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'principal-ideal-domains', 'unique-factorization-domains']"
56,Counterexample for the normalizer being a normal subgroup,Counterexample for the normalizer being a normal subgroup,,"Let $G$ be a group, and $H$ a subgroup. $H$'s normalizer is defined: $N(H):=\{g\in G| gHg^{-1}=H \}$. Prove $N(H)$ is a normal subgroup of G, or give counterexample. Intuitively it seems to me that this claim is wrong, however, I'm having trouble with finding a counterexample. Thans in advance for any assistance!","Let $G$ be a group, and $H$ a subgroup. $H$'s normalizer is defined: $N(H):=\{g\in G| gHg^{-1}=H \}$. Prove $N(H)$ is a normal subgroup of G, or give counterexample. Intuitively it seems to me that this claim is wrong, however, I'm having trouble with finding a counterexample. Thans in advance for any assistance!",,"['abstract-algebra', 'group-theory', 'examples-counterexamples', 'normal-subgroups']"
57,Right invertible and left zero divisor in matrix rings over a commutative ring,Right invertible and left zero divisor in matrix rings over a commutative ring,,"If a ring $R$ is commutative, I don't understand why if $A, B \in R^{n \times n}$, $AB=1$ means that $BA=1$, i.e., $R^{n \times n}$ is Dedekind finite. Arguing with determinant seems to be wrong, although $\det(AB)=\det(BA ) =1$ but it necessarily doesn't mean that $BA =1$. And is every left zero divisor also a right divisor ?","If a ring $R$ is commutative, I don't understand why if $A, B \in R^{n \times n}$, $AB=1$ means that $BA=1$, i.e., $R^{n \times n}$ is Dedekind finite. Arguing with determinant seems to be wrong, although $\det(AB)=\det(BA ) =1$ but it necessarily doesn't mean that $BA =1$. And is every left zero divisor also a right divisor ?",,"['abstract-algebra', 'matrices']"
58,Show that $x^4-10x^2+1$ is irreducible over $\mathbb{Q}$,Show that  is irreducible over,x^4-10x^2+1 \mathbb{Q},"How do I show that $x^4-10x^2+1$ is irreducible over $\mathbb{Q}$? Someone says I should use the rational root test, but I don't exactly know how that applies. Thanks for any input.","How do I show that $x^4-10x^2+1$ is irreducible over $\mathbb{Q}$? Someone says I should use the rational root test, but I don't exactly know how that applies. Thanks for any input.",,"['abstract-algebra', 'polynomials', 'irreducible-polynomials']"
59,Do binary operations need to be surjective functions?,Do binary operations need to be surjective functions?,,"Let $\star$ be a binary operation on the set $S=[0,1]$ defined to be $$\star : [0,1] \times [0,1] \to [0,1] $$ $$\text{where } a \star b = \text{min}\left(\frac12 a , \frac12 b\right) $$ From observation we can see that the set $S$ is closed under $\star$ and that each ordered pair $(a,b)$ is mapped to only one element in $S$. For example, $1 \star 0.3 = 0.15$ But we also don't have every element in the codomain being hit. There doesn't exist any $(a,b) \in S^2$ such that $a \star b = 0.75$, for example. Does this cause a problem at all? Is $\star$ still considered a binary operation on $S$? In class we were told all binary operations were surjective, but the textbook for the class states no such thing. And if it is not a problem, I am wondering if there are any more complicated or ""elegant"" examples. I am interested to see them if they are. Thanks for any clarification on my confusion.","Let $\star$ be a binary operation on the set $S=[0,1]$ defined to be $$\star : [0,1] \times [0,1] \to [0,1] $$ $$\text{where } a \star b = \text{min}\left(\frac12 a , \frac12 b\right) $$ From observation we can see that the set $S$ is closed under $\star$ and that each ordered pair $(a,b)$ is mapped to only one element in $S$. For example, $1 \star 0.3 = 0.15$ But we also don't have every element in the codomain being hit. There doesn't exist any $(a,b) \in S^2$ such that $a \star b = 0.75$, for example. Does this cause a problem at all? Is $\star$ still considered a binary operation on $S$? In class we were told all binary operations were surjective, but the textbook for the class states no such thing. And if it is not a problem, I am wondering if there are any more complicated or ""elegant"" examples. I am interested to see them if they are. Thanks for any clarification on my confusion.",,"['abstract-algebra', 'binary-operations']"
60,Hom-tensor adjunctions,Hom-tensor adjunctions,,"Let $A$ be a ring (which might or might not be commutative), and let $M,N$ and $K$ be three bi-modules over $A$. There are two hom-tensor adjunctions. One says that $Hom_A(M\otimes_A N, K) \cong Hom_A(M,Hom_A(N,K))$. The other says that $Hom_A(M\otimes_A N, K) \cong Hom_A(N,Hom_A(M,K))$. Are these isomorphisms of bimodules? If so, does this mean that the two bimodules $Hom_A(N,Hom_A(M,K))$ and $Hom_A(M,Hom_A(N,K))$ are isomorphic?","Let $A$ be a ring (which might or might not be commutative), and let $M,N$ and $K$ be three bi-modules over $A$. There are two hom-tensor adjunctions. One says that $Hom_A(M\otimes_A N, K) \cong Hom_A(M,Hom_A(N,K))$. The other says that $Hom_A(M\otimes_A N, K) \cong Hom_A(N,Hom_A(M,K))$. Are these isomorphisms of bimodules? If so, does this mean that the two bimodules $Hom_A(N,Hom_A(M,K))$ and $Hom_A(M,Hom_A(N,K))$ are isomorphic?",,"['abstract-algebra', 'tensor-products', 'noncommutative-algebra']"
61,Motivation for definition of free group?,Motivation for definition of free group?,,"Let $S$ be a set and $F_S$ be the equivalence classes of all words that can be built from members of $S$ . Then $F_S$ is called the free group over $S$ . I don't understand the motivation for this definition. Since each word $w$ in $F_S$ is a finite product of elements of $S$ , it uniquely identifies to an element $s\in S$ , so if $S$ were a group then clearly $S$ and $F_S$ would be isomorphic. What makes the free group an interesting object? I assume it is the case when $S$ is not a group, but instead some arbitrary set closed under some binary operation. I suppose the most general type of set we could define a free group over would be a magma , then? What group axiom should we leave out to construct an interesting (nontrivial) example of a free group? I suppose it would be associativity, but I am not sure.","Let be a set and be the equivalence classes of all words that can be built from members of . Then is called the free group over . I don't understand the motivation for this definition. Since each word in is a finite product of elements of , it uniquely identifies to an element , so if were a group then clearly and would be isomorphic. What makes the free group an interesting object? I assume it is the case when is not a group, but instead some arbitrary set closed under some binary operation. I suppose the most general type of set we could define a free group over would be a magma , then? What group axiom should we leave out to construct an interesting (nontrivial) example of a free group? I suppose it would be associativity, but I am not sure.",S F_S S F_S S w F_S S s\in S S S F_S S,"['abstract-algebra', 'group-theory', 'definition', 'free-groups', 'motivation']"
62,Number of prime ideals of a ring,Number of prime ideals of a ring,,"Could anyone tell me how to find the number of distinct prime ideals of the ring $$\mathbb{Q}[x]/\langle x^m-1\rangle,$$ where $m$ is a positive integer say $4$, or $5$? What result/results I need to apply to solve this problem? Thank you for your help.","Could anyone tell me how to find the number of distinct prime ideals of the ring $$\mathbb{Q}[x]/\langle x^m-1\rangle,$$ where $m$ is a positive integer say $4$, or $5$? What result/results I need to apply to solve this problem? Thank you for your help.",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'ideals', 'maximal-and-prime-ideals']"
63,Unique factorization domain that is not a Principal ideal domain,Unique factorization domain that is not a Principal ideal domain,,"Let $c$ be an integer, not necessarily positive and not a square. Let $R=\mathbb{Z}[\sqrt{c}]$  denote the set of numbers of the form $$a+b\sqrt{c}, a,b \in \mathbb{Z}.$$  Then $R$ is a subring of $\mathbb{C}$ under the usual addition and multiplication. My question is: if $R$ is a UFD (unique factorization domain), does it follow that it is also a PID (principal ideal domain)?","Let $c$ be an integer, not necessarily positive and not a square. Let $R=\mathbb{Z}[\sqrt{c}]$  denote the set of numbers of the form $$a+b\sqrt{c}, a,b \in \mathbb{Z}.$$  Then $R$ is a subring of $\mathbb{C}$ under the usual addition and multiplication. My question is: if $R$ is a UFD (unique factorization domain), does it follow that it is also a PID (principal ideal domain)?",,"['abstract-algebra', 'ring-theory']"
64,"How to test if a polynomial is cyclotomic, i.e. divides $x^k - 1$ for some $k$?","How to test if a polynomial is cyclotomic, i.e. divides  for some ?",x^k - 1 k,"Given a monic polynomial $f\in\mathbb{Z}[x]$ , how can I determine whether there is $k\in\mathbb{Z}^+$ such that $f\mid x^k-1$ ? For example, $x^2-x+1$ divides $x^6-1$ , but $x^2-x-1$ does not divide any such $x^k-1$ (unless I miss my mark!). I would also be interested in finding how to answer this for other parameterized families of polynomials, or working over $\mathbb{Q}[x]$ - I expect the former to be hard and the latter easy.","Given a monic polynomial , how can I determine whether there is such that ? For example, divides , but does not divide any such (unless I miss my mark!). I would also be interested in finding how to answer this for other parameterized families of polynomials, or working over - I expect the former to be hard and the latter easy.",f\in\mathbb{Z}[x] k\in\mathbb{Z}^+ f\mid x^k-1 x^2-x+1 x^6-1 x^2-x-1 x^k-1 \mathbb{Q}[x],"['abstract-algebra', 'polynomials']"
65,"Find all subrings of $\mathbb{Z}^2\,$(congruences as subalgebras of the square $\Bbb Z^2)$",Find all subrings of (congruences as subalgebras of the square,"\mathbb{Z}^2\, \Bbb Z^2)",This may be a simple question: Find all subrings of $\mathbb{Z}^2$.,This may be a simple question: Find all subrings of $\mathbb{Z}^2$.,,"['abstract-algebra', 'ring-theory']"
66,"Is 'Algebraic Number Theory' the study of the theory of algebraic numbers, or is it the study of the theory of numbers from an algebraic viewpoint?","Is 'Algebraic Number Theory' the study of the theory of algebraic numbers, or is it the study of the theory of numbers from an algebraic viewpoint?",,Asked differently: Is Algebraic Number Theory the study of the theory of algebraic numbers? Or is it Number Theory from an algebraic viewpoint? Or is it both? I know I can just find a wiki article but I figure answers from the MSE community would be more intuitive and instructive.,Asked differently: Is Algebraic Number Theory the study of the theory of algebraic numbers? Or is it Number Theory from an algebraic viewpoint? Or is it both? I know I can just find a wiki article but I figure answers from the MSE community would be more intuitive and instructive.,,"['abstract-algebra', 'number-theory', 'soft-question', 'algebraic-number-theory', 'self-learning']"
67,What is the relation between normal extension and separable extension?,What is the relation between normal extension and separable extension?,,"What is the relation between normal extension and separable extension? Let F be the algebraic extension of K, if F is a separable extension of K,if and only if F is a normal extension of K? is this correct?","What is the relation between normal extension and separable extension? Let F be the algebraic extension of K, if F is a separable extension of K,if and only if F is a normal extension of K? is this correct?",,['abstract-algebra']
68,Why does the smallest ring have two elements at least?,Why does the smallest ring have two elements at least?,,"I found it written in my lecturer's notes that the smallest ring will have $2$ elements, while the smallest group will have $1$ element. I'm not completely sure why this is true. My understanding of a ring $R$ is that it is an algebraic structure (which ensures closure) has two binary operations $+$ and $*$. $(R,+)$ forms an Abelian group. $(R,*)$ forms a semigroup (ensures associativity). From the definition alone, I'm not able to see why a ring should at the minimum have two elements. Can't it just have the identity element $e$ and nothing else? Edit: According to the comments, this seems to be just a matter of convention as usually the identity elements for $(R,+)$ and $(R,*)$ are considered to be different. In that case, could someone explain in which cases such a convention is useful?","I found it written in my lecturer's notes that the smallest ring will have $2$ elements, while the smallest group will have $1$ element. I'm not completely sure why this is true. My understanding of a ring $R$ is that it is an algebraic structure (which ensures closure) has two binary operations $+$ and $*$. $(R,+)$ forms an Abelian group. $(R,*)$ forms a semigroup (ensures associativity). From the definition alone, I'm not able to see why a ring should at the minimum have two elements. Can't it just have the identity element $e$ and nothing else? Edit: According to the comments, this seems to be just a matter of convention as usually the identity elements for $(R,+)$ and $(R,*)$ are considered to be different. In that case, could someone explain in which cases such a convention is useful?",,['abstract-algebra']
69,"Proof of $\gcd(a,b)=ax+by\ $ [Bezout's identity]",Proof of  [Bezout's identity],"\gcd(a,b)=ax+by\ ","Here is my proof of $\gcd(a,b)=ax+by$ for $a, b, x, y \in \mathbb{Z}$. Am I doing something wrong? Are there easier proofs? $a,b \in \mathbb{Z}, g=\gcd(a,b)$ and suppose $g \neq ax + by$. Let $c$ be a common divisor of $a$ and $b$. Then $$\forall x', y' \in \mathbb{Z}: c | ax' + by'\Longrightarrow\exists q_1, q_2 \in \mathbb{Z}\,\,\, s.t.\,\,\, c q_1 = ax' + by'\,\,,\,\,cq_2 = g$$ So $$gcd(a, b)=g=c q_2 = c q_1 \frac{q_2}{q_1} = \left(\frac{q_2}{q_1}x'\right)a + \left(\frac{q_2}{q_1}y'\right)b$$ So if we have $q_1|q_2$ then we found $\gcd(a,b)=ax'+by'$ for all $x', y' \in \mathbb{Z}$. Now $$\frac{q_1}{q_2}=\frac{c q_1}{c q_2} = \frac{ax'+by'}{g}$$ but $g|a$ and $g|b$ so $\exists q_3 \in \mathbb{Z}: \frac{q_1}{q_2}=q_3 \Rightarrow q_1=q_2 q_3 \Rightarrow q_1 | q_2\,$ . QED.","Here is my proof of $\gcd(a,b)=ax+by$ for $a, b, x, y \in \mathbb{Z}$. Am I doing something wrong? Are there easier proofs? $a,b \in \mathbb{Z}, g=\gcd(a,b)$ and suppose $g \neq ax + by$. Let $c$ be a common divisor of $a$ and $b$. Then $$\forall x', y' \in \mathbb{Z}: c | ax' + by'\Longrightarrow\exists q_1, q_2 \in \mathbb{Z}\,\,\, s.t.\,\,\, c q_1 = ax' + by'\,\,,\,\,cq_2 = g$$ So $$gcd(a, b)=g=c q_2 = c q_1 \frac{q_2}{q_1} = \left(\frac{q_2}{q_1}x'\right)a + \left(\frac{q_2}{q_1}y'\right)b$$ So if we have $q_1|q_2$ then we found $\gcd(a,b)=ax'+by'$ for all $x', y' \in \mathbb{Z}$. Now $$\frac{q_1}{q_2}=\frac{c q_1}{c q_2} = \frac{ax'+by'}{g}$$ but $g|a$ and $g|b$ so $\exists q_3 \in \mathbb{Z}: \frac{q_1}{q_2}=q_3 \Rightarrow q_1=q_2 q_3 \Rightarrow q_1 | q_2\,$ . QED.",,"['abstract-algebra', 'elementary-number-theory', 'proof-writing', 'divisibility', 'gcd-and-lcm']"
70,An ideal whose radical is maximal is primary,An ideal whose radical is maximal is primary,,"I've got to prove that an ideal $Q$ whose radical is a maximal ideal is a primary ideal. That is, I want to prove that if $xy\in Q$, then $x\in Q$ or $y^n\in Q$ for some $n>0$. I've been trying for a while and I'm not sure where to begin. All I've got is that if $\text{Rad}(Q)$ is maximal and by definition it's the intersection of all prime ideals $P_i$ containing $Q$, then it must be equal to each of these $P_i$. So there is only 1 prime ideal containing $Q$, namely $\text{Rad}(Q)$. Could anyone point me in the right direction? Thanks for any replies.","I've got to prove that an ideal $Q$ whose radical is a maximal ideal is a primary ideal. That is, I want to prove that if $xy\in Q$, then $x\in Q$ or $y^n\in Q$ for some $n>0$. I've been trying for a while and I'm not sure where to begin. All I've got is that if $\text{Rad}(Q)$ is maximal and by definition it's the intersection of all prime ideals $P_i$ containing $Q$, then it must be equal to each of these $P_i$. So there is only 1 prime ideal containing $Q$, namely $\text{Rad}(Q)$. Could anyone point me in the right direction? Thanks for any replies.",,"['abstract-algebra', 'commutative-algebra', 'ideals']"
71,An 'obvious' property of algebraic integers?,An 'obvious' property of algebraic integers?,,"I am looking at the book A Brief Guide to Algebraic Number Theory by H. P. F. Swinnerton-Dyer. I like the section on page 1 'the ring of integers' as it gives a motivation for choosing which elements we would like to regard as integers and how we get the definition in terms of monic polynomials. He lists the 'obvious' properties which one would want the integers ${\frak{o}}_k$ of an algebraic number field $k$ to have. Property number 3 is: ${\bf{3.}} \ {\frak{o}}_{k} \otimes_{\mathbb{Z}} \mathbb{Q}= k $. I have not come across this tensor product notation before, but I have a feeling this statement is related to the requirement that the field $k$ should be the field of fractions of ${\frak{o}}_k$. Is this the case, and if so how can the statement 3 be 'translated' into this requirement? Is it really as obvious as he claims? Why do you think he has chosen to state it in this way? A link to the book.","I am looking at the book A Brief Guide to Algebraic Number Theory by H. P. F. Swinnerton-Dyer. I like the section on page 1 'the ring of integers' as it gives a motivation for choosing which elements we would like to regard as integers and how we get the definition in terms of monic polynomials. He lists the 'obvious' properties which one would want the integers ${\frak{o}}_k$ of an algebraic number field $k$ to have. Property number 3 is: ${\bf{3.}} \ {\frak{o}}_{k} \otimes_{\mathbb{Z}} \mathbb{Q}= k $. I have not come across this tensor product notation before, but I have a feeling this statement is related to the requirement that the field $k$ should be the field of fractions of ${\frak{o}}_k$. Is this the case, and if so how can the statement 3 be 'translated' into this requirement? Is it really as obvious as he claims? Why do you think he has chosen to state it in this way? A link to the book.",,"['abstract-algebra', 'number-theory', 'algebraic-number-theory', 'tensor-products']"
72,"If $R$ is an integral domain, then $R[[x]]$ is an integral domain","If  is an integral domain, then  is an integral domain",R R[[x]],"While solving another problem (specifically Exercise 7.2 in Atiyah & Macdonald's Introduction to  Commutative Algebra ), I got stuck in the following step: If $R$ is an integral domain, how I can prove that $R[[x]]$ is an   integral domain? Here $R[[x]]$ is the set of all formal series in $x$ with coefficients in $R$. So typical element of $R[[x]]$ would have the form $a_0+a_1x+a_2x^2+\cdots$ where $a_i\in R$. So I need to prove that if $$ (a_0+a_1x+a_2x^2+\cdots)(b_0+b_1x+b_2x^2+\cdots)=0 $$ then $a_i=0$ and $b_i=0$ for all $i\ge 0$. Now, I am not particularly fond of opening up those brackets :( Is there any slick way of proving this?","While solving another problem (specifically Exercise 7.2 in Atiyah & Macdonald's Introduction to  Commutative Algebra ), I got stuck in the following step: If $R$ is an integral domain, how I can prove that $R[[x]]$ is an   integral domain? Here $R[[x]]$ is the set of all formal series in $x$ with coefficients in $R$. So typical element of $R[[x]]$ would have the form $a_0+a_1x+a_2x^2+\cdots$ where $a_i\in R$. So I need to prove that if $$ (a_0+a_1x+a_2x^2+\cdots)(b_0+b_1x+b_2x^2+\cdots)=0 $$ then $a_i=0$ and $b_i=0$ for all $i\ge 0$. Now, I am not particularly fond of opening up those brackets :( Is there any slick way of proving this?",,"['abstract-algebra', 'commutative-algebra']"
73,Irreducible polynomial modulo every prime?,Irreducible polynomial modulo every prime?,,"There exist irreducible polynomials in $\mathbb{Z}[x]$ (e.g. $x^4-10x^2+1$) which are reducible modulo every prime $p$. (A proof can be found in J.S. Milne's Fields and Galois Theory , page 13.) This kind of polynomial is so ""bad"". I want to know if there exists some non-trivial ""good"" polynomials. State precisely: Does there exist a polynomial $f(x)\in \mathbb{Z}[x]$ with degree $>1$ such that $f(x)$ is irreducible in $\mathbb{F}_p[x]$ for any prime number $p$?","There exist irreducible polynomials in $\mathbb{Z}[x]$ (e.g. $x^4-10x^2+1$) which are reducible modulo every prime $p$. (A proof can be found in J.S. Milne's Fields and Galois Theory , page 13.) This kind of polynomial is so ""bad"". I want to know if there exists some non-trivial ""good"" polynomials. State precisely: Does there exist a polynomial $f(x)\in \mathbb{Z}[x]$ with degree $>1$ such that $f(x)$ is irreducible in $\mathbb{F}_p[x]$ for any prime number $p$?",,"['abstract-algebra', 'polynomials', 'irreducible-polynomials']"
74,Prove that the order of an element in $S_n$ equals the least common multiple of the lengths of the cycles in its cycle decomposition.,Prove that the order of an element in  equals the least common multiple of the lengths of the cycles in its cycle decomposition.,S_n,Prove that the order of an element in $S_n$ equals the least common multiple of the lengths of the cycles in its cycle decomposition. Proof: Let $\sigma \in S_n$ . Then $\sigma = (a_1a_2...a_{m_1})(a_{m_1+1}a_{m_1+2}...a_{m_2})....(a_{m_{k-1}+1}a_{m_{k-1}+2}...a_{m_{k}})$ represents the cycle decomposition of $\sigma$ . Suppose $|\sigma| = n$ is the order of an element in $S_n$ . So $\sigma^n = 1$ . Can someone please help  me?  I don't know how if I am doing this fine. And I am stuck. Thank you for any help.,Prove that the order of an element in equals the least common multiple of the lengths of the cycles in its cycle decomposition. Proof: Let . Then represents the cycle decomposition of . Suppose is the order of an element in . So . Can someone please help  me?  I don't know how if I am doing this fine. And I am stuck. Thank you for any help.,S_n \sigma \in S_n \sigma = (a_1a_2...a_{m_1})(a_{m_1+1}a_{m_1+2}...a_{m_2})....(a_{m_{k-1}+1}a_{m_{k-1}+2}...a_{m_{k}}) \sigma |\sigma| = n S_n \sigma^n = 1,"['abstract-algebra', 'group-theory', 'permutations', 'symmetric-groups']"
75,"If $M$ is an artinian module and $f : M\to M$ is an injective homomorphism, then $f$ is surjective.","If  is an artinian module and  is an injective homomorphism, then  is surjective.",M f : M\to M f,"If $M$ is an artinian module and $f: M\to M$ is an injective homomorphism, then $f$ is surjective. I somehow found out that if we consider the module $\mathbb Z_{p^{\infty}}$ denoting the submodule of the $\mathbb{Z}$-module $\mathbb{Q/Z}$ consisting of elements which are annihilated by some power of $p$, then it is artinian, but if we have the homomorphism $f(\frac{1}{p^{k}})=\frac{1}{p^{k+1}}$, then we get a $\mathbb{Z}$-module homomorphism, but this map is not surjective, because $\frac{1}{p}$ has no preimage. I would be very grateful if someone can tell me what is wrong with this counterexample? And how to prove the proposition above if it is correct? Thanks.","If $M$ is an artinian module and $f: M\to M$ is an injective homomorphism, then $f$ is surjective. I somehow found out that if we consider the module $\mathbb Z_{p^{\infty}}$ denoting the submodule of the $\mathbb{Z}$-module $\mathbb{Q/Z}$ consisting of elements which are annihilated by some power of $p$, then it is artinian, but if we have the homomorphism $f(\frac{1}{p^{k}})=\frac{1}{p^{k+1}}$, then we get a $\mathbb{Z}$-module homomorphism, but this map is not surjective, because $\frac{1}{p}$ has no preimage. I would be very grateful if someone can tell me what is wrong with this counterexample? And how to prove the proposition above if it is correct? Thanks.",,"['abstract-algebra', 'modules']"
76,Injectivity of Homomorphism in Localization,Injectivity of Homomorphism in Localization,,"Let $\alpha:A\to B$ be a ring homomorphism, $Q\subset B$ a prime ideal, $P=\alpha^{-1}(Q)\subset A$ a prime ideal. Consider the natural map $\alpha_Q:A_P\to B_Q$ defined by $\alpha_Q(a/b)=\alpha(a)/\alpha(b)$. Suppose that $\alpha$ is injective. Then is $\alpha_Q$ always injective? I think so, but I'm clearly being too dense to prove it! My argument goes as follows. Let $\alpha(a)/\alpha(b)=0$. Then $\exists c \in B\setminus Q$ s.t. $c\alpha(a)=0$. If $B$ is a domain we are done. If not we must exhibit some $d\in A\setminus P$ s.t. $da=0$. Obviously this is true if $c =\alpha(d)$. But I don't see how I have any information to prove this! Am I wrong and this is actually false? If so could someone show me the trivial counterexample I must be missing? Many thanks!","Let $\alpha:A\to B$ be a ring homomorphism, $Q\subset B$ a prime ideal, $P=\alpha^{-1}(Q)\subset A$ a prime ideal. Consider the natural map $\alpha_Q:A_P\to B_Q$ defined by $\alpha_Q(a/b)=\alpha(a)/\alpha(b)$. Suppose that $\alpha$ is injective. Then is $\alpha_Q$ always injective? I think so, but I'm clearly being too dense to prove it! My argument goes as follows. Let $\alpha(a)/\alpha(b)=0$. Then $\exists c \in B\setminus Q$ s.t. $c\alpha(a)=0$. If $B$ is a domain we are done. If not we must exhibit some $d\in A\setminus P$ s.t. $da=0$. Obviously this is true if $c =\alpha(d)$. But I don't see how I have any information to prove this! Am I wrong and this is actually false? If so could someone show me the trivial counterexample I must be missing? Many thanks!",,"['abstract-algebra', 'algebraic-geometry', 'ring-theory', 'commutative-algebra', 'examples-counterexamples']"
77,Tensor product and compositum of fields,Tensor product and compositum of fields,,"Let $E/k$ , $F/k$ be two arbitrary field extensions of $k$ . My question is: Is there a field extension $M/k$ s.t. $E/k$ , $F/k$ are subextensions of $M/k$ ? Alternatively, can we talk about compositum fields without assuming a larger field? If the answer to the above question is yes, can we construct such a $M/k$ explicitly (by tensor product, direct product, localization, quotient etc.)? Is the $k-$ algebra $E\otimes_k F $ never the zero ring?","Let , be two arbitrary field extensions of . My question is: Is there a field extension s.t. , are subextensions of ? Alternatively, can we talk about compositum fields without assuming a larger field? If the answer to the above question is yes, can we construct such a explicitly (by tensor product, direct product, localization, quotient etc.)? Is the algebra never the zero ring?",E/k F/k k M/k E/k F/k M/k M/k k- E\otimes_k F ,"['abstract-algebra', 'field-theory']"
78,Does every commutative ring have $2^n$ idempotents?,Does every commutative ring have  idempotents?,2^n,"I've spent a lot of time looking for examples, and I can't find any commutative rings which have a finite number of idempotents other than a power of $2$ . Intuitively, adjoining an extra idempotent $a$ always seems to double the number, as for every other idempotent $b$ , $ab$ is a new idempotent. But there doesn't seem to be any way to turn this into a proof. I'm not sure whether it's even true. I have managed to prove the characteristic $2$ case, as there the idempotents form a subring, and hence $\mathbb{Z}_2$ -Algebra. But this doesn't seem to be any help for the other cases. I'm sorry I can't show more of an attempt, but this really has me stumped. So are there commutative rings with a finite number of idempotents which don't have $2^n$ idempotents for some $n$ ? I also don't know of any rings that have $k \ne 2^n$ idempotents in the noncommutative case, but I haven't investigated that much.","I've spent a lot of time looking for examples, and I can't find any commutative rings which have a finite number of idempotents other than a power of . Intuitively, adjoining an extra idempotent always seems to double the number, as for every other idempotent , is a new idempotent. But there doesn't seem to be any way to turn this into a proof. I'm not sure whether it's even true. I have managed to prove the characteristic case, as there the idempotents form a subring, and hence -Algebra. But this doesn't seem to be any help for the other cases. I'm sorry I can't show more of an attempt, but this really has me stumped. So are there commutative rings with a finite number of idempotents which don't have idempotents for some ? I also don't know of any rings that have idempotents in the noncommutative case, but I haven't investigated that much.",2 a b ab 2 \mathbb{Z}_2 2^n n k \ne 2^n,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'idempotents']"
79,Error in proof: $\mathbb{C} \cong \mathbb{C} \times \mathbb{C}$??,Error in proof: ??,\mathbb{C} \cong \mathbb{C} \times \mathbb{C},"I've unintentionally ""proved"" the following: $$\mathbb{C} \cong \mathbb{C} \times \mathbb{C}$$ Can you help me tracing the error I made resulting to this non-proof? Here it is. First of all, I recall an algebraic theorem about the complex plane: $\mathbb{C} \cong  \mathbb{R}[X]/(X^2+1)$ . The rest of the non-proof is about the apparent isomorphism $\mathbb{C} \times \mathbb{C} \cong  \mathbb{R}[X]/(X^2+1)$ . The ring $R[X]$ is a commutative ring containing a unit, so we can write the ideal $(X^2+1)$ as a product of ideals $(X-i)(X+i)$ . These ideals are indivisable: $(X+i)(X-i) \ni \frac{1}{2}(X+i)-\frac{1}{2}(X-i)=i$ , so every polynomial $q = i^3q \cdot i$ is contained in the sum of ideals. Now we can use the generalisation of the Chinese remainder theorem:  For a commutative ring R with unity, and indivisible ideals $I,J$ applies $R/IJ \cong R/I \times R/J$ . Now we have $\mathbb{R}[X]/(X^2+1) \cong \mathbb{R}[X]/(X+i) \times \mathbb{R}[X]/(X-i)$ . I recall that for every homomorphism of rings $f: R \rightarrow S$ the isomorphism $R/\ker(f) \cong f(R)$ holds. Consider the mapping $s_r \ : \ R[X] \rightarrow S \ : \ \sum a_i X^i \mapsto \sum a_i r^i$ . This substitution map is an homomorphism. A special case is the homomorphism $s_i \ : \ \mathbb{R}[X] \rightarrow \mathbb{C} \ : \ \sum a_i X^i \mapsto \sum a_i r^i$ that substitutes $i$ in $X$ . Its kernel is exactly the ideal $(X-i)$ . The image clairy contains $\{ a + bi: a,b \in \mathbb{R} \} = \mathbb{C}$ , and the image is contained in $\mathbb{C}$ as well. So we obtain $\mathbb{C} \cong \mathbb{R}[X]/(X+i)$ . The same trick with the substitution $s_{-i}$ shows that $\mathbb{C} \cong \mathbb{R}[X]/(X-i)$ . This results into $\mathbb{C} \cong \mathbb{C} \times \mathbb{C}$ . Here ends the ""proof."" I feel a little bad about using $s_i$ , because $i \notin \mathbb{R}$ , but I remember that a similar mapping had to be used to proof that $\mathbb{C} \cong  \mathbb{R}[X]/(X^2+1)$ . I'd be thankful if you help me to sift this through and find the error(s).","I've unintentionally ""proved"" the following: Can you help me tracing the error I made resulting to this non-proof? Here it is. First of all, I recall an algebraic theorem about the complex plane: . The rest of the non-proof is about the apparent isomorphism . The ring is a commutative ring containing a unit, so we can write the ideal as a product of ideals . These ideals are indivisable: , so every polynomial is contained in the sum of ideals. Now we can use the generalisation of the Chinese remainder theorem:  For a commutative ring R with unity, and indivisible ideals applies . Now we have . I recall that for every homomorphism of rings the isomorphism holds. Consider the mapping . This substitution map is an homomorphism. A special case is the homomorphism that substitutes in . Its kernel is exactly the ideal . The image clairy contains , and the image is contained in as well. So we obtain . The same trick with the substitution shows that . This results into . Here ends the ""proof."" I feel a little bad about using , because , but I remember that a similar mapping had to be used to proof that . I'd be thankful if you help me to sift this through and find the error(s).","\mathbb{C} \cong \mathbb{C} \times \mathbb{C} \mathbb{C} \cong  \mathbb{R}[X]/(X^2+1) \mathbb{C} \times \mathbb{C} \cong  \mathbb{R}[X]/(X^2+1) R[X] (X^2+1) (X-i)(X+i) (X+i)(X-i) \ni \frac{1}{2}(X+i)-\frac{1}{2}(X-i)=i q = i^3q \cdot i I,J R/IJ \cong R/I \times R/J \mathbb{R}[X]/(X^2+1) \cong \mathbb{R}[X]/(X+i) \times \mathbb{R}[X]/(X-i) f: R \rightarrow S R/\ker(f) \cong f(R) s_r \ : \ R[X] \rightarrow S \ : \ \sum a_i X^i \mapsto \sum a_i r^i s_i \ : \ \mathbb{R}[X] \rightarrow \mathbb{C} \ : \ \sum a_i X^i \mapsto \sum a_i r^i i X (X-i) \{ a + bi: a,b \in \mathbb{R} \} = \mathbb{C} \mathbb{C} \mathbb{C} \cong \mathbb{R}[X]/(X+i) s_{-i} \mathbb{C} \cong \mathbb{R}[X]/(X-i) \mathbb{C} \cong \mathbb{C} \times \mathbb{C} s_i i \notin \mathbb{R} \mathbb{C} \cong  \mathbb{R}[X]/(X^2+1)","['abstract-algebra', 'ring-theory', 'fake-proofs']"
80,"Should every group be a monoid, or should no group be a monoid?","Should every group be a monoid, or should no group be a monoid?",,"Question: What is more convenient/useful? Writing mathematics as if every group is a monoid, or as if these two classes are disjoint? Additional discussion. Define a monoid as follows. Defn 1 . A monoid is a triple $(X,*,e)$ such that $*$ is an associative binary operation on $X$, and $e \in X$, and $e$ has the property that for all $x \in X$ it holds that $x * e = e * x = x$. From here, there's at least two ways of defining a group. Defn 2. A group is a monoid $(X,*,e)$ such that for all $x \in X$ there exists $y \in X$ such that $x*y=e$. Defn 2'. A group is a quadruple $(X,*,e,i)$ such that $(X,*,e)$ is a monoid, and $i$ is a function $X \rightarrow X$, and for all $x \in X$ it holds that $x * i(x) = e$. Now I understand that minimalism favors Defn 2, while practitioners of universal algebra favor Defn 3. However, this is not my question. My question is not : which is preferable, Defn 2 or Defn 2'? Rather, my question is : which is preferable, definitions like Defn 2 such that every group is a monoid, or definitions like Defn 2' such that no group is monoid? So just to clarify, I want to know: what is more convenient/useful? Writing mathematics as if every group is a monoid, or as if these two classes are disjoint?","Question: What is more convenient/useful? Writing mathematics as if every group is a monoid, or as if these two classes are disjoint? Additional discussion. Define a monoid as follows. Defn 1 . A monoid is a triple $(X,*,e)$ such that $*$ is an associative binary operation on $X$, and $e \in X$, and $e$ has the property that for all $x \in X$ it holds that $x * e = e * x = x$. From here, there's at least two ways of defining a group. Defn 2. A group is a monoid $(X,*,e)$ such that for all $x \in X$ there exists $y \in X$ such that $x*y=e$. Defn 2'. A group is a quadruple $(X,*,e,i)$ such that $(X,*,e)$ is a monoid, and $i$ is a function $X \rightarrow X$, and for all $x \in X$ it holds that $x * i(x) = e$. Now I understand that minimalism favors Defn 2, while practitioners of universal algebra favor Defn 3. However, this is not my question. My question is not : which is preferable, Defn 2 or Defn 2'? Rather, my question is : which is preferable, definitions like Defn 2 such that every group is a monoid, or definitions like Defn 2' such that no group is monoid? So just to clarify, I want to know: what is more convenient/useful? Writing mathematics as if every group is a monoid, or as if these two classes are disjoint?",,"['abstract-algebra', 'soft-question', 'terminology']"
81,"Are the groups $(\mathbb{C},+)$ and $(\mathbb{R},+)$ isomorphic?",Are the groups  and  isomorphic?,"(\mathbb{C},+) (\mathbb{R},+)","Are the groups $(\mathbb{C},+)$ and $(\mathbb{R},+)$ isomorphic? And how could I prove this ? What about $\mathbb{Q}$ and $\mathbb{Q}[i]$ ?",Are the groups and isomorphic? And how could I prove this ? What about and ?,"(\mathbb{C},+) (\mathbb{R},+) \mathbb{Q} \mathbb{Q}[i]","['abstract-algebra', 'group-theory']"
82,A fraction field is not finitely generated over its subdomain,A fraction field is not finitely generated over its subdomain,,"I'm looking for proofs of the following fact. Suppose that $R$ is a domain which is not a field with fraction field $K$. Then $K$ is not finitely generated as $R$-module. I know this fact is true, at least, when $R$ is Noetherian and I guess it is true in general. I know two proofs, one when $R$ is Noetherian and one (very indirect) when $R$ is Noetherian local. Do you know any direct proof for any arbitrary domain $R$? Thanks!","I'm looking for proofs of the following fact. Suppose that $R$ is a domain which is not a field with fraction field $K$. Then $K$ is not finitely generated as $R$-module. I know this fact is true, at least, when $R$ is Noetherian and I guess it is true in general. I know two proofs, one when $R$ is Noetherian and one (very indirect) when $R$ is Noetherian local. Do you know any direct proof for any arbitrary domain $R$? Thanks!",,"['abstract-algebra', 'commutative-algebra', 'integral-domain', 'finitely-generated']"
83,Roots of an irreducible polynomial in a finite field,Roots of an irreducible polynomial in a finite field,,"Given a irreducible polynomial $f \in K[x]$ where $|K|=q$ is a finite field and $\deg(f)=n$. If $\alpha$ is a root of $f$ why are $\alpha, \alpha^q, \dots, \alpha^{q^{n-1}}$ the only possible candidates for the roots of $f$?","Given a irreducible polynomial $f \in K[x]$ where $|K|=q$ is a finite field and $\deg(f)=n$. If $\alpha$ is a root of $f$ why are $\alpha, \alpha^q, \dots, \alpha^{q^{n-1}}$ the only possible candidates for the roots of $f$?",,"['abstract-algebra', 'finite-fields']"
84,Is the Ratio of Associative Binary Operations to All Binary Operations on a Set of $n$ Elements Generally Small?,Is the Ratio of Associative Binary Operations to All Binary Operations on a Set of  Elements Generally Small?,n,"I started thinking about the number of associative (binary) operations on a set with $n$ elements today.  Looking online I found this paper which indicates only $113$ of the possible $19,683$ operations on a three-element set satisfy association.  So, $50\%$ of binary operations on a two-element set satisfy association, and less than $0.6\%$ of all binary operations on a three element set satisfy association.  For an $n$-element set, where $n$ denotes a natural number, is the ratio $R_{n}=A_{n}/B_{n}$, of the number of associative binary operations $A_{n}$ to the number of all binary operations $B_{n}$, in general small?  I don't mean the following questions as equivalent, but since they seem more concretely answerable in principle, does $$ \lim_{n \to +\infty} \frac{A_{n}}{B_{n}} = 0 ? $$ Also, is $F : n \to R_{n}$ a monotonically decreasing function? Some Background of the Question: In his Linear Algebra Problem Book 1995 on p. 6 Paul Halmos writes ""The commonly accepted attitudes toward the commutative law and the associative law are different.  Many real life operations fail to commute; the mathematical community has learned to live with that fact and even to enjoy it.  Violations of the associative law, on the other hand, are usually considered by specialists only.""  For all I know, Halmos might only have written that to motivate the study of Linear Algebra and doesn't quite literally mean what he appears to say.  But, if he means what he appears to say, and if $F : n \to R_{n}$ is monotonically decreasing, or $R_{n}$ is generally small, I think there's something amiss with what Halmos says, since non-associative operations seem so common that one may as well enjoy them.","I started thinking about the number of associative (binary) operations on a set with $n$ elements today.  Looking online I found this paper which indicates only $113$ of the possible $19,683$ operations on a three-element set satisfy association.  So, $50\%$ of binary operations on a two-element set satisfy association, and less than $0.6\%$ of all binary operations on a three element set satisfy association.  For an $n$-element set, where $n$ denotes a natural number, is the ratio $R_{n}=A_{n}/B_{n}$, of the number of associative binary operations $A_{n}$ to the number of all binary operations $B_{n}$, in general small?  I don't mean the following questions as equivalent, but since they seem more concretely answerable in principle, does $$ \lim_{n \to +\infty} \frac{A_{n}}{B_{n}} = 0 ? $$ Also, is $F : n \to R_{n}$ a monotonically decreasing function? Some Background of the Question: In his Linear Algebra Problem Book 1995 on p. 6 Paul Halmos writes ""The commonly accepted attitudes toward the commutative law and the associative law are different.  Many real life operations fail to commute; the mathematical community has learned to live with that fact and even to enjoy it.  Violations of the associative law, on the other hand, are usually considered by specialists only.""  For all I know, Halmos might only have written that to motivate the study of Linear Algebra and doesn't quite literally mean what he appears to say.  But, if he means what he appears to say, and if $F : n \to R_{n}$ is monotonically decreasing, or $R_{n}$ is generally small, I think there's something amiss with what Halmos says, since non-associative operations seem so common that one may as well enjoy them.",,"['combinatorics', 'abstract-algebra', 'analysis']"
85,Classifying Unital Commutative Rings of Order $p^2$,Classifying Unital Commutative Rings of Order,p^2,"I'm trying to classify unital commutative rings of order $p^2$, where $p$ is a prime. At first, I happened to neglect the 'unital' and 'commutative' requirements, and after an arduous route I managed to show that there are $11$ such rings up to isomorphism. Some are non-commutative and non-unital, and the journey to that result is a bit ugly for a class on commutative algebra. This should be easier if we only consider unital rings of order $p^2$. (It's easy to show that if it's unital, then it's commutative in this case). But so far, I haven't found a solution that doesn't use the fact that I found representations for the $11$ rings. I am certain that a much less technical and messy method to find unital commutative rings of order $p^2$ is possible. For reference on the context, this question comes amidst a review of the Chinese Remainder Theorem, the Structure Theorem on Modules over a PID, tensor products, and algebras. I heavily suspect that if I were more fluent in applying the CRT, I would be able to get there. Do you have any ideas? By the way, I believe there are $4$. They should look like $\mathbb{F}_{p^2}, \mathbb{Z}_{p^2}, \mathbb{Z}_p [x]/(x^2),$ and (I don't know a convenient name for the fourth, but e.g., the Klein 4-group with standard ring structure on top, which I'm inclined to designate $\mathbb{Z}_{p \times p}$). In a more convenient designation, 1 is built on the additive group $C_{p^2}$ and 3 are built on $C_p \times C_p$. I would be content if I could enumerate how many rings are on each additive group, up to homomorphism, instead of actually classifying them.","I'm trying to classify unital commutative rings of order $p^2$, where $p$ is a prime. At first, I happened to neglect the 'unital' and 'commutative' requirements, and after an arduous route I managed to show that there are $11$ such rings up to isomorphism. Some are non-commutative and non-unital, and the journey to that result is a bit ugly for a class on commutative algebra. This should be easier if we only consider unital rings of order $p^2$. (It's easy to show that if it's unital, then it's commutative in this case). But so far, I haven't found a solution that doesn't use the fact that I found representations for the $11$ rings. I am certain that a much less technical and messy method to find unital commutative rings of order $p^2$ is possible. For reference on the context, this question comes amidst a review of the Chinese Remainder Theorem, the Structure Theorem on Modules over a PID, tensor products, and algebras. I heavily suspect that if I were more fluent in applying the CRT, I would be able to get there. Do you have any ideas? By the way, I believe there are $4$. They should look like $\mathbb{F}_{p^2}, \mathbb{Z}_{p^2}, \mathbb{Z}_p [x]/(x^2),$ and (I don't know a convenient name for the fourth, but e.g., the Klein 4-group with standard ring structure on top, which I'm inclined to designate $\mathbb{Z}_{p \times p}$). In a more convenient designation, 1 is built on the additive group $C_{p^2}$ and 3 are built on $C_p \times C_p$. I would be content if I could enumerate how many rings are on each additive group, up to homomorphism, instead of actually classifying them.",,"['abstract-algebra', 'ring-theory']"
86,A question regarding the definition of Galois group,A question regarding the definition of Galois group,,"In my book, Galois group is defined to mean the set of automorphisms on $E/F$ that ""leave alone"" the elements in $F$. On Wikipedia it says: ""If $E/F$ is a Galois extension, then $Aut(E/F)$ is called the Galois group of (the extension) $E$ over $F$, $\dots$"" And Wikipedia's definition of Galois: ""An algebraic field extension $E/F$ is Galois if it is normal and separable. Equivalently, the extension $E/F$ is Galois if and only if it is algebraic, and the field fixed by the automorphism group $Aut(E/F)$ is precisely the base field $F$."" So in one case, Wikipedia, the extension is restricted to be algebraic. So the set of automorphisms on $\mathbb{Q}(\pi) / \mathbb{Q}$ is not a Galois group. My question: How is it possible to have two different definitions of what a Galois group is? Do these not conflict? Or what am I missing here? Many thanks for your help. Edit: I'm using J. Gallian, Contemporary Abstract Algebra and Allan Clark, Elements of Abstract Algebra. Both use the same terminology, not the same as Wikipedia.","In my book, Galois group is defined to mean the set of automorphisms on $E/F$ that ""leave alone"" the elements in $F$. On Wikipedia it says: ""If $E/F$ is a Galois extension, then $Aut(E/F)$ is called the Galois group of (the extension) $E$ over $F$, $\dots$"" And Wikipedia's definition of Galois: ""An algebraic field extension $E/F$ is Galois if it is normal and separable. Equivalently, the extension $E/F$ is Galois if and only if it is algebraic, and the field fixed by the automorphism group $Aut(E/F)$ is precisely the base field $F$."" So in one case, Wikipedia, the extension is restricted to be algebraic. So the set of automorphisms on $\mathbb{Q}(\pi) / \mathbb{Q}$ is not a Galois group. My question: How is it possible to have two different definitions of what a Galois group is? Do these not conflict? Or what am I missing here? Many thanks for your help. Edit: I'm using J. Gallian, Contemporary Abstract Algebra and Allan Clark, Elements of Abstract Algebra. Both use the same terminology, not the same as Wikipedia.",,"['abstract-algebra', 'group-theory', 'field-theory', 'galois-theory']"
87,Are integers mod n a unique factorization domain?,Are integers mod n a unique factorization domain?,,"I am trying to learn abstract algebra from scratch, jolly stuff, but in the process of doing so this puzzles me: Having a ring of integers mod $n$, where $n=pq$ is composite, as I understand we have that  $\mathbb{Z}/n\mathbb{Z}$ is a Principal Ideal Domain (PID) (by this question ). Therefore by the pretty chain of inclusions located here , it is also a unique factorization domain. And this is where I am lost, as I keep thinking of for example $\mathbb{Z}/8\mathbb{Z}$ where I can have $4\equiv 2\cdot2 \equiv 2\cdot2\cdot5 \bmod 8$. Also, $p\cdot q \equiv 0 \bmod n$ which gives two non-zero divisors of zero. In my world, this means that $\mathbb{Z}/8\mathbb{Z}$ is not a UFD and not even integral domain. I feel like I am missing something very simple yet crucial :-).","I am trying to learn abstract algebra from scratch, jolly stuff, but in the process of doing so this puzzles me: Having a ring of integers mod $n$, where $n=pq$ is composite, as I understand we have that  $\mathbb{Z}/n\mathbb{Z}$ is a Principal Ideal Domain (PID) (by this question ). Therefore by the pretty chain of inclusions located here , it is also a unique factorization domain. And this is where I am lost, as I keep thinking of for example $\mathbb{Z}/8\mathbb{Z}$ where I can have $4\equiv 2\cdot2 \equiv 2\cdot2\cdot5 \bmod 8$. Also, $p\cdot q \equiv 0 \bmod n$ which gives two non-zero divisors of zero. In my world, this means that $\mathbb{Z}/8\mathbb{Z}$ is not a UFD and not even integral domain. I feel like I am missing something very simple yet crucial :-).",,"['abstract-algebra', 'ring-theory', 'modular-arithmetic']"
88,What are the irreducible representations of the cyclic group $C_n$ over a real vector space $V$?,What are the irreducible representations of the cyclic group  over a real vector space ?,C_n V,It suffices just to consider a linear transformation $f$ such that $f^n=id$ and require $V$ to have no proper subspace invariant under $f$. But I still don't have a picture of what's going on.,It suffices just to consider a linear transformation $f$ such that $f^n=id$ and require $V$ to have no proper subspace invariant under $f$. But I still don't have a picture of what's going on.,,"['abstract-algebra', 'representation-theory']"
89,Axiomatic approach to polynomials?,Axiomatic approach to polynomials?,,"I only know the ""constructive"" definition of $\mathbb K [x]$, via the space of finite sequences in $\mathbb K$. It essentially tells a polynomial is its coefficients. Is there a way to define polynomials ""axiomatically""? I just don't know a more suitable word, what I mean is like real numbers can be defined as complete ordered field, in opposition for example to repeating decimals. If there is no such definition then why? Why it is needed to tell what is a polynomial as itself, instead of telling what can be done with it? Maybe there are axiomatic definitions for some specific kinds of polynomials?","I only know the ""constructive"" definition of $\mathbb K [x]$, via the space of finite sequences in $\mathbb K$. It essentially tells a polynomial is its coefficients. Is there a way to define polynomials ""axiomatically""? I just don't know a more suitable word, what I mean is like real numbers can be defined as complete ordered field, in opposition for example to repeating decimals. If there is no such definition then why? Why it is needed to tell what is a polynomial as itself, instead of telling what can be done with it? Maybe there are axiomatic definitions for some specific kinds of polynomials?",,"['abstract-algebra', 'polynomials', 'axioms']"
90,Left inverse implies right inverse in a finite ring,Left inverse implies right inverse in a finite ring,,"Let $R$ be a finite ring with identity $1$ , and assume $\exists x,y\in R$ such that $ xy=1$ . How can I show it implies $yx=1$ ?","Let be a finite ring with identity , and assume such that . How can I show it implies ?","R 1 \exists x,y\in R  xy=1 yx=1","['abstract-algebra', 'ring-theory', 'finite-rings']"
91,Finding groups $G$ such that $G \cong \mathscr{S}(G)$,Finding groups  such that,G G \cong \mathscr{S}(G),"Let $G$ be a group and let $\mathscr{S}(G)$ denote the group of Inner-Automorphisms of $G$. The only isomorphism theorem I know, that connects a group to its inner-automorphism is:  $$G/Z(G) \cong \mathscr{S}(G)$$ where $Z(G)$ is the center of the group. Now, if $Z(G) =\{e\}$ then one can see that $G \cong \mathscr{S}(G)$. What about the converse? That is if $G \cong \mathscr{S}(G)$ does it imply that $Z(G)=\{e\}$? In other word's I need to know whether there are groups with non-trivial center which are isomorphic to their group of Inner-Automorphisms . Are there any type of classification for such type of groups?","Let $G$ be a group and let $\mathscr{S}(G)$ denote the group of Inner-Automorphisms of $G$. The only isomorphism theorem I know, that connects a group to its inner-automorphism is:  $$G/Z(G) \cong \mathscr{S}(G)$$ where $Z(G)$ is the center of the group. Now, if $Z(G) =\{e\}$ then one can see that $G \cong \mathscr{S}(G)$. What about the converse? That is if $G \cong \mathscr{S}(G)$ does it imply that $Z(G)=\{e\}$? In other word's I need to know whether there are groups with non-trivial center which are isomorphic to their group of Inner-Automorphisms . Are there any type of classification for such type of groups?",,['abstract-algebra']
92,Why should we expect Maschke's theorem to be true?,Why should we expect Maschke's theorem to be true?,,"Maschke's theorem tells us that any representation of a finite group $G$ can be decomposed into a direct sum of irreducible representations. The proof does make intuitive sense to me ( Intuition behind Maschke's theorem ), but my question is really about why we should expect it to be true in the first place. Sure, we can do some explicit examples (perhaps a most obvious starting point is the standard permutation representation of $S_n$ , which has an obvious invariant subspace $\{(x,x,\ldots, x) \in \mathbb C^n: x\in \mathbb C\}$ , and almost as obvious complement subspace $\{(x_1,\ldots, x_n) \in \mathbb C^n: \sum x_i = 0\}$ ), and perhaps one has already seen the result for abelian groups over $\mathbb C$ in the guise of linear algebra: Matrices commute if and only if they share a common basis of eigenvectors? . However I wonder if there is any other point of view that makes Maschke's theorem feel ""inevitable""...since right now, it just seems absurdly powerful/magical.","Maschke's theorem tells us that any representation of a finite group can be decomposed into a direct sum of irreducible representations. The proof does make intuitive sense to me ( Intuition behind Maschke's theorem ), but my question is really about why we should expect it to be true in the first place. Sure, we can do some explicit examples (perhaps a most obvious starting point is the standard permutation representation of , which has an obvious invariant subspace , and almost as obvious complement subspace ), and perhaps one has already seen the result for abelian groups over in the guise of linear algebra: Matrices commute if and only if they share a common basis of eigenvectors? . However I wonder if there is any other point of view that makes Maschke's theorem feel ""inevitable""...since right now, it just seems absurdly powerful/magical.","G S_n \{(x,x,\ldots, x) \in \mathbb C^n: x\in \mathbb C\} \{(x_1,\ldots, x_n) \in \mathbb C^n: \sum x_i = 0\} \mathbb C","['abstract-algebra', 'group-theory', 'representation-theory']"
93,Logic for decomposing a permutation into different products composed of transpositions,Logic for decomposing a permutation into different products composed of transpositions,,"I know that any permutation cycle can be decomposed into transpositions as follows: $(a_1,a_2...,a_n) = (a_1,a_{n-1})...(a_1,a_2)$ But in my book there is an example of the following form $(1,2,3,4,5) = (5,4)(5,2)(2,1)(2,5)(2,3)(1,3)$ I verified that it holds true. But I cant seem to figure out how the author came up with that. Also, What is the generic algorithm to produce all decompositions of permutation in terms of transpositions.","I know that any permutation cycle can be decomposed into transpositions as follows: $(a_1,a_2...,a_n) = (a_1,a_{n-1})...(a_1,a_2)$ But in my book there is an example of the following form $(1,2,3,4,5) = (5,4)(5,2)(2,1)(2,5)(2,3)(1,3)$ I verified that it holds true. But I cant seem to figure out how the author came up with that. Also, What is the generic algorithm to produce all decompositions of permutation in terms of transpositions.",,"['abstract-algebra', 'group-theory', 'symmetric-groups', 'permutations']"
94,Help with proof that $\mathbb Z[i]/\langle 1 - i \rangle$ is a field.,Help with proof that  is a field.,\mathbb Z[i]/\langle 1 - i \rangle,"I have been having a lot of trouble teaching myself rings, so much so that even ""simple"" proofs are really difficult for me. I think I am finally starting to get it, but just to be sure could some one please check this proof that $\mathbb Z[i]/\langle 1 - i \rangle$ is a field. Thank you. Proof: Notice that $$\langle 1 - i \rangle\\  \Rightarrow 1 = i\\  \Rightarrow 2 = 0.$$ Thus all elements of the form $a+ bi + \langle 1 - i \rangle$ can be rewritten as $a+ b + \langle 1 - i \rangle$. But since $2=0$ this implies that the elements that are left can be written as $1 + \langle 1 - i \rangle$ or $0 + \langle 1 - i \rangle$. Thus  $$ \mathbb Z[i]/ \langle 1 - i \rangle = \{ 0+ \langle 1 - i \rangle , 1 + \langle 1 - i \rangle\}. $$ This is obviously a commutative ring with unity and no zero-divisors, thus it is a finite integral domain, and hence is a field. $\square$","I have been having a lot of trouble teaching myself rings, so much so that even ""simple"" proofs are really difficult for me. I think I am finally starting to get it, but just to be sure could some one please check this proof that $\mathbb Z[i]/\langle 1 - i \rangle$ is a field. Thank you. Proof: Notice that $$\langle 1 - i \rangle\\  \Rightarrow 1 = i\\  \Rightarrow 2 = 0.$$ Thus all elements of the form $a+ bi + \langle 1 - i \rangle$ can be rewritten as $a+ b + \langle 1 - i \rangle$. But since $2=0$ this implies that the elements that are left can be written as $1 + \langle 1 - i \rangle$ or $0 + \langle 1 - i \rangle$. Thus  $$ \mathbb Z[i]/ \langle 1 - i \rangle = \{ 0+ \langle 1 - i \rangle , 1 + \langle 1 - i \rangle\}. $$ This is obviously a commutative ring with unity and no zero-divisors, thus it is a finite integral domain, and hence is a field. $\square$",,"['abstract-algebra', 'ring-theory', 'field-theory', 'self-learning', 'ideals']"
95,Prove that the fields $\mathbb Z_{11}[x]/\langle x^2+1\rangle$ and $\mathbb Z_{11}[x]/\langle x^2+x+4 \rangle$ are isomorphic,Prove that the fields  and  are isomorphic,\mathbb Z_{11}[x]/\langle x^2+1\rangle \mathbb Z_{11}[x]/\langle x^2+x+4 \rangle,"I have been stuck in this problem for some time now. Prove that $x^2+2$ and $x^2+x+4$ are irreducible over $\mathbb{Z}_{11}$. Also, prove further $\mathbb Z_{11}[x]/\langle x^2+1\rangle$   and $\mathbb Z_{11}[x]/\langle x^2+x+4\rangle$ are isomorphic, each   having $121$ elements. The first part is easy to prove since there is no element of $\mathbb Z_{11}$ that satisfies either of the polynomials given in the question. However, proving that  $\mathbb Z_{11}[x]/\langle x^2+1\rangle$ and $\mathbb Z_{11}[x]/\langle x^2+x+4\rangle$ are isomorphic has been a challenge for me. How do I proceed? Moreover, how do I show that the the fields $\mathbb {Z}_{11}[x]/\langle x^2+1\rangle$ and $\mathbb {Z}_{11}[x]/\langle x^2+x+4\rangle$ each have $121$ elements?","I have been stuck in this problem for some time now. Prove that $x^2+2$ and $x^2+x+4$ are irreducible over $\mathbb{Z}_{11}$. Also, prove further $\mathbb Z_{11}[x]/\langle x^2+1\rangle$   and $\mathbb Z_{11}[x]/\langle x^2+x+4\rangle$ are isomorphic, each   having $121$ elements. The first part is easy to prove since there is no element of $\mathbb Z_{11}$ that satisfies either of the polynomials given in the question. However, proving that  $\mathbb Z_{11}[x]/\langle x^2+1\rangle$ and $\mathbb Z_{11}[x]/\langle x^2+x+4\rangle$ are isomorphic has been a challenge for me. How do I proceed? Moreover, how do I show that the the fields $\mathbb {Z}_{11}[x]/\langle x^2+1\rangle$ and $\mathbb {Z}_{11}[x]/\langle x^2+x+4\rangle$ each have $121$ elements?",,['abstract-algebra']
96,Why polynomial division algorithm works for $x-a$ or any monic polynomial?,Why polynomial division algorithm works for  or any monic polynomial?,x-a,"In Theorem 5.2.3 in these notes, it is said that Since $x − a$ has leading coefficient $1$ , which is a unit, we may use the Division Algorithm... Why is this true? I thought that the Division Algorithm is only guaranteed to work in Euclidean domains not any integral domain.","In Theorem 5.2.3 in these notes, it is said that Since has leading coefficient , which is a unit, we may use the Division Algorithm... Why is this true? I thought that the Division Algorithm is only guaranteed to work in Euclidean domains not any integral domain.",x − a 1,"['abstract-algebra', 'polynomials', 'ring-theory', 'divisibility']"
97,Why are projective objects important?,Why are projective objects important?,,"I belive we study them because in important categories they are close to free objects and even a retract of a free object in some algebraic instances (for example, direct summands in Mod_R, and precisely the free objects in Gps). Am I right? Are there other reasons?","I belive we study them because in important categories they are close to free objects and even a retract of a free object in some algebraic instances (for example, direct summands in Mod_R, and precisely the free objects in Gps). Am I right? Are there other reasons?",,"['abstract-algebra', 'group-theory', 'category-theory', 'homological-algebra']"
98,Is there a good example of a subgroup of an infinitely generated abelian group that is not isomorphic to a quotient of that group?,Is there a good example of a subgroup of an infinitely generated abelian group that is not isomorphic to a quotient of that group?,,"Whilst I understand the classification of the finitely generated abelian groups, this had me wondering whether there is a subgroup $H$ of a general (necessarily infinitely generated) abelian group $G$ such that $H$ is not isomorphic to any quotient $G/N$ of $G$.","Whilst I understand the classification of the finitely generated abelian groups, this had me wondering whether there is a subgroup $H$ of a general (necessarily infinitely generated) abelian group $G$ such that $H$ is not isomorphic to any quotient $G/N$ of $G$.",,"['abstract-algebra', 'group-theory', 'abelian-groups', 'infinite-groups']"
99,Why tensor product of two sheaves of modules is a sheaf of modules?,Why tensor product of two sheaves of modules is a sheaf of modules?,,"Let $(X, \mathcal O_X)$ be  a ringed topological space. Consider two $\mathcal O_X$ modules, $\mathcal F$ and $\mathcal G$. First we define the tensor product presheaf $\mathcal F \otimes_{p,\mathcal O_X} \mathcal G$, which assigns every open set $U$ in $X$ the $\mathcal O_X(U)$-module $\mathcal F(U) \otimes_{\mathcal O_X(U)} \mathcal G(U)$. Now, $\mathcal F \otimes_{p,\mathcal O_X} \mathcal G$ is a presheaf of abelian groups . We take the the sheafication of the $\mathcal F \otimes_{p,\mathcal O_X} \mathcal G$ to obtain a sheaf of abelian groups , $\mathcal F \otimes_{\mathcal O_X} \mathcal G$. My question is for any open set $U$ in $X$ what is the $\mathcal O_X(U)$-module on   $(\mathcal F \otimes_{\mathcal O_X} \mathcal G)(U)$?","Let $(X, \mathcal O_X)$ be  a ringed topological space. Consider two $\mathcal O_X$ modules, $\mathcal F$ and $\mathcal G$. First we define the tensor product presheaf $\mathcal F \otimes_{p,\mathcal O_X} \mathcal G$, which assigns every open set $U$ in $X$ the $\mathcal O_X(U)$-module $\mathcal F(U) \otimes_{\mathcal O_X(U)} \mathcal G(U)$. Now, $\mathcal F \otimes_{p,\mathcal O_X} \mathcal G$ is a presheaf of abelian groups . We take the the sheafication of the $\mathcal F \otimes_{p,\mathcal O_X} \mathcal G$ to obtain a sheaf of abelian groups , $\mathcal F \otimes_{\mathcal O_X} \mathcal G$. My question is for any open set $U$ in $X$ what is the $\mathcal O_X(U)$-module on   $(\mathcal F \otimes_{\mathcal O_X} \mathcal G)(U)$?",,"['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'sheaf-theory']"
