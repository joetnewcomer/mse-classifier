,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Find all polynomials $P(x) \in \mathbb{Z}[x]$ such that if $P(s)$ and $P(t)$ are both integers, then $P(s+t)$ is also an integer","Find all polynomials  such that if  and  are both integers, then  is also an integer",P(x) \in \mathbb{Z}[x] P(s) P(t) P(s+t),"Find all polynomials $P(x)$ with integer coefficients such that for all real numbers $s$ and $t$ , if $P(s)$ and $P(t)$ are both integers, then $P(s+t)$ is also an integer. This is a problem inspired by problem $5$ of APMO $2018$ . Without loss of generality, we may assume $$P(x) = \displaystyle \sum_{i=0}^n a_i x^i, \, a_n>0.$$ This is because if $P(x)$ is a solution, then so is $-P(x)$ . However, I can't even guess what kind of polynomials could be other than integer constant.","Find all polynomials with integer coefficients such that for all real numbers and , if and are both integers, then is also an integer. This is a problem inspired by problem of APMO . Without loss of generality, we may assume This is because if is a solution, then so is . However, I can't even guess what kind of polynomials could be other than integer constant.","P(x) s t P(s) P(t) P(s+t) 5 2018 P(x) = \displaystyle \sum_{i=0}^n a_i x^i, \, a_n>0. P(x) -P(x)","['functions', 'polynomials', 'contest-math']"
1,Continuous function in compact sets - Real analysis,Continuous function in compact sets - Real analysis,,"I have the following proposition. $\textbf{Proposition:}$ If $f:X\times K\longrightarrow\mathbb{R}^n$ is a continuous function, $K$ is a compact set in $\mathbb{R}^n$ and $X\subseteq\mathbb{R}^n$ . Fixed $x_0\in X$ , prove that for every $\varepsilon>0$ exist $\delta>0$ such that if $\|x-x_0\|<\delta$ then $\|f(x,\alpha)-f(x_0,\alpha)\|<\varepsilon$ for every $\alpha\in K$ . $\textbf{Proof Sketch:}$ Fix $x_0\in X\subseteq\mathbb{R}^n$ . Consider the set $A=\{x_0\}\times K\subseteq\mathbb{R}^{2n}$ ; then $A$ is compact in $X\times K\subseteq\mathbb{R}^{2n}$ with the usual metric since $\{x_0\}$ is a finite set and therefore compact and $K$ is also compact in $\mathbb{R}^n$ by hypothesis and Cartesian product of compact sets is compact. Consider the open balls in $\mathbb{R}^{2n}$ centred in $(x_0,\alpha)\in A$ and radius 1, lets say for simplicity $$A(\alpha)=B_{\mathbb{R}^{2n}}((x_0,\alpha),1)=\{y\in\mathbb{R}^{2n}\ :\ \|y-(x_0,\alpha)\|<1\}.$$ Then, we have an open cover for $A:$ $$A\subseteq\bigcup_{\alpha\in K}A(\alpha).$$ Since $A$ is compact there exist $\alpha_1,\alpha_2,\cdots,\alpha_m\in K$ such that $$A\subseteq\bigcup_{i=1}^{m}A(\alpha_i).$$ Applying $f$ to both sides, by property of the direct image then $$f(A)\subseteq f\left(\bigcup_{i=1}^{m}A(\alpha_i)\right)=\bigcup_{i=1}^{m}f(A(\alpha_i)).$$ Since $f$ is continuous then $f(A)$ is compact in $\mathbb{R}^n$ , and by definition $$f(A)=\{f(x_0,\alpha)\in\mathbb{R}^n\ :\ \alpha\in K\}$$ $$f(A(\alpha_i))=\{f(x,\alpha)\in\mathbb{R}^n\ :\ \|(x,\alpha)-(x_0,\alpha_i)\|<1\}$$ for each $i=1,2,\cdots,m$ . Let $\varepsilon>0$ be arbitrary, consider the open balls in $\mathbb{R}^{n}$ centred in $f(x_0,k)$ and radius $\varepsilon$ for every $k\in K$ and define for simplicity $$B(k,\varepsilon)=B_{\mathbb{R}^n}(f(x_0,k),\varepsilon)=\{z\in\mathbb{R}^n\ :\ \|z-f(x_0,k)\|<\varepsilon\}.$$ Then, for every $\varepsilon>0$ we have an open cover for $f(A)$ $$f(A)\subseteq\bigcup_{k\in K}B(k,\varepsilon).$$ Since $f(A)$ is compact there exist $k_1,k_2,\cdots,k_{m'}\in K$ such that $$f(A)\subseteq\bigcup_{j=1}^{m'}B(k_j,\varepsilon).$$ Recall that $f$ is continuous and so there is $\delta_j>0$ such that $f(B'_j)\subseteq B(k_j,\varepsilon)$ where $B'_j$ is the open ball in $\mathbb{R}^{2n}$ centred in $(x_0,k_j)$ with radius $\delta_j$ for each $j=1,2,\cdots,m'$ . That is to say, $$B'_j=B_{\mathbb{R}^{2n}}((x_0,k_j),\delta_j)=\{y\in\mathbb{R}^{2n}\ :\ \|y-(x_0,k_j)\|<\delta_j\}$$ $$f(B'_j)=\{f(x,\alpha)\in\mathbb{R}^{n}\ :\ \|(x,\alpha)-(x_0,k_j)\|<\delta_j\}$$ Then, doing the joint of sets $$\bigcup_{j=1}^{m'}f(B'_j)\subseteq\bigcup_{j=1}^{m'}B(k_j,\varepsilon)$$ $\textbf{Â¡Stack!:}$ This where I get stuck; I've been thinking for a long time without resolution how to relate each $\alpha_i$ with each $k_j$ so that considering something like $\delta=\min\{1,\delta_1,\delta_2,\cdots,\delta_{m'}\}$ and assuming $\|x-x_0\|<\delta$ then I can get the desired result. I also think that this ""proof"" can be simpler without having to consider so many sets, however it's the path that comes to my mind. I have an introductory knowledge in real analysis so I look for any help you can give me. Edit Inspired by the contribution made by Mikhail Katz: $\textbf{Proof Sketch 2:}$ Fix $x_0\in X\subseteq\mathbb{R}^n$ . Consider the closed ball in $\mathbb{R}^n$ centred in $x_0$ with radius 1: $$B=B[x_0,1]=\{x\in\mathbb{R}^n:\|x-x_0\|\leq1\}$$ Every closed ball in $\mathbb{R}^n$ is compact so $B$ is compact and so closed and bounded in $\mathbb{R}^n$ . Consider the adherence (closure) of $X$ , this is $\overline{X}$ . Define $L=\overline{X}\cap B=\{x\in \overline{X}:\|x-x_0\|\leq1\}$ . Since $L\subseteq B$ then $L$ is bounded. Since $\overline{X}$ and $B$ are closed and intersection of closed sets is always closed then $L$ is closed. So, by Heine-Borel's Theorem $L$ is compact in $\mathbb{R}^n$ . Define $S=X\cap B=\{x\in X:\|x-x_0\|\leq1\}\subseteq X$ . Therefore $S\subseteq L$ and $\overline{S}=L$ ; so $S$ is dense in $L$ . By hypothesis $f$ is continuous in $X\times K$ ; particularly $f$ is continuous in $S\times K$ . Since $S$ is dense in $L$ then $S\times K$ is dense in $L\times K$ . Therefore exist a continuous extension of $f$ from $S\times K$ to $L\times K$ , say $g$ . The set $L\times K$ is a Cartesian product of compact sets in $\mathbb{R}^n$ so it's compact in $\mathbb{R}^{2n}$ . Since $g$ is continuous in $L\times K$ then $g$ is uniformly continuous. For every $\varepsilon>0$ there is $\delta>0$ such that if $\|(x_1,\alpha_1)-(x_2,\alpha_2)\|<\delta$ then $\|g(x_1,\alpha_1)-g(x_2,\alpha_2)\|<\varepsilon$ for all $(x_1,\alpha_1),(x_2,\alpha_2)\in L\times K$ . In particular, for $x_1=x\in S$ , $x_2=x_0\in S$ and $\alpha_1=\alpha_2=\alpha\in K$ . Suppose: $$\|(x,\alpha)-(x_0,\alpha)\|=\|(x-x_0,\bar{0})\|=\|x-x_0\|<\delta$$ Since $g$ is an extension of $f$ and $x,x_0\in S$ then: $$\|g(x,\alpha)-g(x_0,\alpha)\|=\|f(x,\alpha)-f(x_0,\alpha)\|<\varepsilon$$ for all $\alpha\in K$ . $\textbf{Observation:}$ To guarantee the existence of $g$ it's sufficient that the set $S\times X$ be closed. If not, the statement may not be true. I don't know if this condition is satisfied or not in this context because $X$ is given as a nonempty set of $\mathbb{R}^n$ and nothing more about itself. For example, if we had in the hypotheses that $X\subseteq\mathbb{R}^n$ is closed then $X=\overline{X}$ and so $L=S$ ; the proof is complete and would be even simpler.","I have the following proposition. If is a continuous function, is a compact set in and . Fixed , prove that for every exist such that if then for every . Fix . Consider the set ; then is compact in with the usual metric since is a finite set and therefore compact and is also compact in by hypothesis and Cartesian product of compact sets is compact. Consider the open balls in centred in and radius 1, lets say for simplicity Then, we have an open cover for Since is compact there exist such that Applying to both sides, by property of the direct image then Since is continuous then is compact in , and by definition for each . Let be arbitrary, consider the open balls in centred in and radius for every and define for simplicity Then, for every we have an open cover for Since is compact there exist such that Recall that is continuous and so there is such that where is the open ball in centred in with radius for each . That is to say, Then, doing the joint of sets This where I get stuck; I've been thinking for a long time without resolution how to relate each with each so that considering something like and assuming then I can get the desired result. I also think that this ""proof"" can be simpler without having to consider so many sets, however it's the path that comes to my mind. I have an introductory knowledge in real analysis so I look for any help you can give me. Edit Inspired by the contribution made by Mikhail Katz: Fix . Consider the closed ball in centred in with radius 1: Every closed ball in is compact so is compact and so closed and bounded in . Consider the adherence (closure) of , this is . Define . Since then is bounded. Since and are closed and intersection of closed sets is always closed then is closed. So, by Heine-Borel's Theorem is compact in . Define . Therefore and ; so is dense in . By hypothesis is continuous in ; particularly is continuous in . Since is dense in then is dense in . Therefore exist a continuous extension of from to , say . The set is a Cartesian product of compact sets in so it's compact in . Since is continuous in then is uniformly continuous. For every there is such that if then for all . In particular, for , and . Suppose: Since is an extension of and then: for all . To guarantee the existence of it's sufficient that the set be closed. If not, the statement may not be true. I don't know if this condition is satisfied or not in this context because is given as a nonempty set of and nothing more about itself. For example, if we had in the hypotheses that is closed then and so ; the proof is complete and would be even simpler.","\textbf{Proposition:} f:X\times K\longrightarrow\mathbb{R}^n K \mathbb{R}^n X\subseteq\mathbb{R}^n x_0\in X \varepsilon>0 \delta>0 \|x-x_0\|<\delta \|f(x,\alpha)-f(x_0,\alpha)\|<\varepsilon \alpha\in K \textbf{Proof Sketch:} x_0\in X\subseteq\mathbb{R}^n A=\{x_0\}\times K\subseteq\mathbb{R}^{2n} A X\times K\subseteq\mathbb{R}^{2n} \{x_0\} K \mathbb{R}^n \mathbb{R}^{2n} (x_0,\alpha)\in A A(\alpha)=B_{\mathbb{R}^{2n}}((x_0,\alpha),1)=\{y\in\mathbb{R}^{2n}\ :\ \|y-(x_0,\alpha)\|<1\}. A: A\subseteq\bigcup_{\alpha\in K}A(\alpha). A \alpha_1,\alpha_2,\cdots,\alpha_m\in K A\subseteq\bigcup_{i=1}^{m}A(\alpha_i). f f(A)\subseteq f\left(\bigcup_{i=1}^{m}A(\alpha_i)\right)=\bigcup_{i=1}^{m}f(A(\alpha_i)). f f(A) \mathbb{R}^n f(A)=\{f(x_0,\alpha)\in\mathbb{R}^n\ :\ \alpha\in K\} f(A(\alpha_i))=\{f(x,\alpha)\in\mathbb{R}^n\ :\ \|(x,\alpha)-(x_0,\alpha_i)\|<1\} i=1,2,\cdots,m \varepsilon>0 \mathbb{R}^{n} f(x_0,k) \varepsilon k\in K B(k,\varepsilon)=B_{\mathbb{R}^n}(f(x_0,k),\varepsilon)=\{z\in\mathbb{R}^n\ :\ \|z-f(x_0,k)\|<\varepsilon\}. \varepsilon>0 f(A) f(A)\subseteq\bigcup_{k\in K}B(k,\varepsilon). f(A) k_1,k_2,\cdots,k_{m'}\in K f(A)\subseteq\bigcup_{j=1}^{m'}B(k_j,\varepsilon). f \delta_j>0 f(B'_j)\subseteq B(k_j,\varepsilon) B'_j \mathbb{R}^{2n} (x_0,k_j) \delta_j j=1,2,\cdots,m' B'_j=B_{\mathbb{R}^{2n}}((x_0,k_j),\delta_j)=\{y\in\mathbb{R}^{2n}\ :\ \|y-(x_0,k_j)\|<\delta_j\} f(B'_j)=\{f(x,\alpha)\in\mathbb{R}^{n}\ :\ \|(x,\alpha)-(x_0,k_j)\|<\delta_j\} \bigcup_{j=1}^{m'}f(B'_j)\subseteq\bigcup_{j=1}^{m'}B(k_j,\varepsilon) \textbf{Â¡Stack!:} \alpha_i k_j \delta=\min\{1,\delta_1,\delta_2,\cdots,\delta_{m'}\} \|x-x_0\|<\delta \textbf{Proof Sketch 2:} x_0\in X\subseteq\mathbb{R}^n \mathbb{R}^n x_0 B=B[x_0,1]=\{x\in\mathbb{R}^n:\|x-x_0\|\leq1\} \mathbb{R}^n B \mathbb{R}^n X \overline{X} L=\overline{X}\cap B=\{x\in \overline{X}:\|x-x_0\|\leq1\} L\subseteq B L \overline{X} B L L \mathbb{R}^n S=X\cap B=\{x\in X:\|x-x_0\|\leq1\}\subseteq X S\subseteq L \overline{S}=L S L f X\times K f S\times K S L S\times K L\times K f S\times K L\times K g L\times K \mathbb{R}^n \mathbb{R}^{2n} g L\times K g \varepsilon>0 \delta>0 \|(x_1,\alpha_1)-(x_2,\alpha_2)\|<\delta \|g(x_1,\alpha_1)-g(x_2,\alpha_2)\|<\varepsilon (x_1,\alpha_1),(x_2,\alpha_2)\in L\times K x_1=x\in S x_2=x_0\in S \alpha_1=\alpha_2=\alpha\in K \|(x,\alpha)-(x_0,\alpha)\|=\|(x-x_0,\bar{0})\|=\|x-x_0\|<\delta g f x,x_0\in S \|g(x,\alpha)-g(x_0,\alpha)\|=\|f(x,\alpha)-f(x_0,\alpha)\|<\varepsilon \alpha\in K \textbf{Observation:} g S\times X X \mathbb{R}^n X\subseteq\mathbb{R}^n X=\overline{X} L=S","['real-analysis', 'functions', 'continuity', 'compactness']"
2,Newtons method for finding reciprocal,Newtons method for finding reciprocal,,Define a function 1 which is $f_1(x)=a-1/x$ and function  2 which is $f_2(x)=1-ax $ If I set both to zero I am looking for when $x=1/a$ as the root using Newtons method. When I do this I get two different answers however and they should surely both be the same. for 1 I get $$x(n+1)=x(n)+x(n) (1-ax(n) )$$ and for 2 I get $$x(n+1)=x(n)+(1/a)(1-ax(n))$$ difference being the $1/a$ term.,Define a function 1 which is $f_1(x)=a-1/x$ and function  2 which is $f_2(x)=1-ax $ If I set both to zero I am looking for when $x=1/a$ as the root using Newtons method. When I do this I get two different answers however and they should surely both be the same. for 1 I get $$x(n+1)=x(n)+x(n) (1-ax(n) )$$ and for 2 I get $$x(n+1)=x(n)+(1/a)(1-ax(n))$$ difference being the $1/a$ term.,,"['functions', 'derivatives', 'numerical-methods', 'newton-raphson', 'linearization']"
3,Proof of Discontinuity Criterion for functions,Proof of Discontinuity Criterion for functions,,"I would really appreciate a proof for the Discontinuity Criterion Theorem for functions. It is stated as such... Let $A$ be a subset of $\mathbb{R}$, let $f: A \to \mathbb{R}$ and let $c \in A$. Then $f$ is discontinuous at $c$ iff there exists a sequence $x_n \in\mathbb{R}$ such that $x_n$ converges to $c$ but the sequence $f(x_n)$ does not converge to $f(c)$. Thank you!","I would really appreciate a proof for the Discontinuity Criterion Theorem for functions. It is stated as such... Let $A$ be a subset of $\mathbb{R}$, let $f: A \to \mathbb{R}$ and let $c \in A$. Then $f$ is discontinuous at $c$ iff there exists a sequence $x_n \in\mathbb{R}$ such that $x_n$ converges to $c$ but the sequence $f(x_n)$ does not converge to $f(c)$. Thank you!",,"['real-analysis', 'functions', 'continuity']"
4,"Intuitive definition of injective, surjective and bijective","Intuitive definition of injective, surjective and bijective",,"I tried to find a more intuitive way of explaining to myself how injective and surjective functions work. Does the following make sense? I'm assuming you have a function defined in the form $f(x)=y$. Injective functions, for every unique $y$-value, have at most one corresponding $x$. Surjective functions, for every unique $y$-value, have at least one corresponding $x$. Bijective functions are both injective and surjective, so for every unique $y$-value, they have exactly one corresponding $x$.","I tried to find a more intuitive way of explaining to myself how injective and surjective functions work. Does the following make sense? I'm assuming you have a function defined in the form $f(x)=y$. Injective functions, for every unique $y$-value, have at most one corresponding $x$. Surjective functions, for every unique $y$-value, have at least one corresponding $x$. Bijective functions are both injective and surjective, so for every unique $y$-value, they have exactly one corresponding $x$.",,['functions']
5,$f\circ f\circ f(x)=x^9$ then $f$ is increasing,then  is increasing,f\circ f\circ f(x)=x^9 f,"The full statement is: If $f:\Bbb R \to \Bbb R$ is a continuous function and $f\circ f\circ f(x)=x^9$ then $f$ is increasing. $(1)$ I was thinking about suppose that $f$ is decreasing (or constant) and then it is easy to get a contradiction. After that I would like to state that "" If $f:\Bbb R \to \Bbb R$ is continous and not increasing then there is an interval where $f$ is decreasing or constant. "" and then I can use $(1)$ and get the result. But I still can't prove if the statement is true. Any hint or any other solution?","The full statement is: If $f:\Bbb R \to \Bbb R$ is a continuous function and $f\circ f\circ f(x)=x^9$ then $f$ is increasing. $(1)$ I was thinking about suppose that $f$ is decreasing (or constant) and then it is easy to get a contradiction. After that I would like to state that "" If $f:\Bbb R \to \Bbb R$ is continous and not increasing then there is an interval where $f$ is decreasing or constant. "" and then I can use $(1)$ and get the result. But I still can't prove if the statement is true. Any hint or any other solution?",,"['real-analysis', 'functions', 'continuity']"
6,Find all function $ f:\Bbb R\to\Bbb R$ such that $ f(x+y)f(x-y)=(f(x)+f(y))^2-4x^2f(y)$.,Find all function  such that ., f:\Bbb R\to\Bbb R  f(x+y)f(x-y)=(f(x)+f(y))^2-4x^2f(y),"While doing some INMO questions, one entry went this way: Find all function $ f:\Bbb R\to\Bbb R$ such that $f(x+y)f(x-y)=(f(x)+f(y))^2-4x^2f(y)$. I made an approach similar to this : On Putting $x=0, y=0$ we get $$f(0+0)f(0-0)=(f(0)+f(0))^2-4\times0^2f(0)$$  $$f(0)^2=(2\times f(0))^2$$Which gives us $f(0)=0$. Then, on putting $x=1, y=1$,  $$f(1+1)f(1-1)=(f(1)+f(1))^2-4\times1^2f(1)$$  $$f(2)f(0)=(2\times f(1))^2+-4\times f(1)$$ $$4\times f(1)=4\times f(1)^2$$ Which gives us $f(1)=0 $  or $f(1)=1$. From here, I can't go further. I think that method I m working on is quite right and will take me to the right answer. But the problem is that I can't find that right answer. I shall be thankful if you can provide me a hint or a complete solution. Thanks. SIDE NOTE: I am using this method for a while (I got this one from then answer of a post). Now I m thinking to switch, If you know some other method to solve such functional equations, please try to give your answer by that method.","While doing some INMO questions, one entry went this way: Find all function $ f:\Bbb R\to\Bbb R$ such that $f(x+y)f(x-y)=(f(x)+f(y))^2-4x^2f(y)$. I made an approach similar to this : On Putting $x=0, y=0$ we get $$f(0+0)f(0-0)=(f(0)+f(0))^2-4\times0^2f(0)$$  $$f(0)^2=(2\times f(0))^2$$Which gives us $f(0)=0$. Then, on putting $x=1, y=1$,  $$f(1+1)f(1-1)=(f(1)+f(1))^2-4\times1^2f(1)$$  $$f(2)f(0)=(2\times f(1))^2+-4\times f(1)$$ $$4\times f(1)=4\times f(1)^2$$ Which gives us $f(1)=0 $  or $f(1)=1$. From here, I can't go further. I think that method I m working on is quite right and will take me to the right answer. But the problem is that I can't find that right answer. I shall be thankful if you can provide me a hint or a complete solution. Thanks. SIDE NOTE: I am using this method for a while (I got this one from then answer of a post). Now I m thinking to switch, If you know some other method to solve such functional equations, please try to give your answer by that method.",,"['functions', 'contest-math', 'functional-equations']"
7,Proving an unspecified function is invertible,Proving an unspecified function is invertible,,"Given $g: \mathbb{R} \rightarrow \mathbb{R}$ is a differentiable function with bounded derivative i.e. satisfying $|g'(x)|\leq K>0 ,  \forall x \in \mathbb{R}$, I am trying to show that for some constant $\epsilon>0$ small enough, the function $f: \mathbb{R} \rightarrow \mathbb{R}$ defined by $f(x):=x+\epsilon g(x)$ is invertible. My idea is to show that $f$ is bijective.  It occurred to me that  $f$ is injective since its derivative can be made to be strictly positive so that it is strictly increasing if $\epsilon<1/K \implies f'=1+\epsilon g'>1+\epsilon(-K)>1-1>0$.  However, how can I prove $f$ is surjective?","Given $g: \mathbb{R} \rightarrow \mathbb{R}$ is a differentiable function with bounded derivative i.e. satisfying $|g'(x)|\leq K>0 ,  \forall x \in \mathbb{R}$, I am trying to show that for some constant $\epsilon>0$ small enough, the function $f: \mathbb{R} \rightarrow \mathbb{R}$ defined by $f(x):=x+\epsilon g(x)$ is invertible. My idea is to show that $f$ is bijective.  It occurred to me that  $f$ is injective since its derivative can be made to be strictly positive so that it is strictly increasing if $\epsilon<1/K \implies f'=1+\epsilon g'>1+\epsilon(-K)>1-1>0$.  However, how can I prove $f$ is surjective?",,['functions']
8,Book recommendation for studying functional equations,Book recommendation for studying functional equations,,"I am a student who is just starting high school and am very interested in taking part in the IMO (International Mathematical Olympiad). I am currently reading about inequalities. Having studied many of the classical inequalities, I have found that a good knowledge of functions and functional equations would be very beneficial. However, the books I have looked up seem very complicated and I have not found any book offering a friendly introduction into the subject for beginners. None of what I have looked up also relate to olympiad problems. Can anyone please recommend me a book that could help me get acquainted with the topic. Thanks.","I am a student who is just starting high school and am very interested in taking part in the IMO (International Mathematical Olympiad). I am currently reading about inequalities. Having studied many of the classical inequalities, I have found that a good knowledge of functions and functional equations would be very beneficial. However, the books I have looked up seem very complicated and I have not found any book offering a friendly introduction into the subject for beginners. None of what I have looked up also relate to olympiad problems. Can anyone please recommend me a book that could help me get acquainted with the topic. Thanks.",,"['functions', 'inequality', 'soft-question', 'contest-math', 'book-recommendation']"
9,Conjecture function $g(x)$ is even function?,Conjecture function  is even function?,g(x),"Let $f,g:R\to R\setminus\{0\}$ and $\forall x,y\in R$,such $$\color{crimson}{f(x-y)=f(x)g(y)-f(y)g(x)}$$ I have  prove  the function $\color{crimson}f$ odd function. because let $y=0$ we have $$f(x)=f(x)g(0)-f(0)g(x)\tag{1}$$ Let $x=0,y=x$ we have $$f(-x)=f(0)g(x)-f(x)g(0)\tag{2}$$ by $(1),(2)$ ,then $$f(x)=-f(-x)$$ Conjectureï¼ $\color{crimson}{g(x)}$ is even function For this function $g(x)$ is even problem ,I don't have any idea to prove it.But I think is right,because $$\color{blue}{\sin{(x-y)}=\sin{x}\cos{y}-\sin{y}\cos{x}}$$ $$\color{crimson}{\sinh{(x-y)}=\sinh{x}\cosh{y}-\sinh{y}\cosh{x}}$$","Let $f,g:R\to R\setminus\{0\}$ and $\forall x,y\in R$,such $$\color{crimson}{f(x-y)=f(x)g(y)-f(y)g(x)}$$ I have  prove  the function $\color{crimson}f$ odd function. because let $y=0$ we have $$f(x)=f(x)g(0)-f(0)g(x)\tag{1}$$ Let $x=0,y=x$ we have $$f(-x)=f(0)g(x)-f(x)g(0)\tag{2}$$ by $(1),(2)$ ,then $$f(x)=-f(-x)$$ Conjectureï¼ $\color{crimson}{g(x)}$ is even function For this function $g(x)$ is even problem ,I don't have any idea to prove it.But I think is right,because $$\color{blue}{\sin{(x-y)}=\sin{x}\cos{y}-\sin{y}\cos{x}}$$ $$\color{crimson}{\sinh{(x-y)}=\sinh{x}\cosh{y}-\sinh{y}\cosh{x}}$$",,['functions']
10,Solve this problem on functions,Solve this problem on functions,,"Let $f$ be a bijection from the set of non-negative integers to itself. Show that there exist integers $a$,$b$,$c$ such that $a < b < c$ and $f(a)+f(c)=2f(b)$. I don't know how to approach this problem. I think I'll have to show some kind of contradiction. But, I haven't managed to do anything fruitful yet. Any help would be appreciated.","Let $f$ be a bijection from the set of non-negative integers to itself. Show that there exist integers $a$,$b$,$c$ such that $a < b < c$ and $f(a)+f(c)=2f(b)$. I don't know how to approach this problem. I think I'll have to show some kind of contradiction. But, I haven't managed to do anything fruitful yet. Any help would be appreciated.",,"['elementary-number-theory', 'functions', 'arithmetic-progressions']"
11,"What is the range of $f :R â R$, and $f(x) = x^2 + 6x â 8$","What is the range of , and",f :R â R f(x) = x^2 + 6x â 8,"I have this discrete math question I have done completing the square but not sure how to continue. May I get some guide? Thanks! What is the range of $f :R â R$, and $f(x) = x^2 + 6x â 8$ $f(x)=x^2+6x-8$ $f(x)=(x^2+6x+9)-8-9$ $f(x)=(x+3)^2-17$","I have this discrete math question I have done completing the square but not sure how to continue. May I get some guide? Thanks! What is the range of $f :R â R$, and $f(x) = x^2 + 6x â 8$ $f(x)=x^2+6x-8$ $f(x)=(x^2+6x+9)-8-9$ $f(x)=(x+3)^2-17$",,"['calculus', 'functions', 'discrete-mathematics', 'quadratics']"
12,Example of real analytic function,Example of real analytic function,,"We were taught real analytic functions in class today. I am playing around trying to construct examples. I see exponential, sine, cosine and logarithmic functions (for $x > 0$). One function I am having trouble with is $f(x) = \frac{1}{1 + e^x}$. In spirit, this function is like $e^{-x}$, so I want to say it is real analytic, but not totally sure. Any help, please?","We were taught real analytic functions in class today. I am playing around trying to construct examples. I see exponential, sine, cosine and logarithmic functions (for $x > 0$). One function I am having trouble with is $f(x) = \frac{1}{1 + e^x}$. In spirit, this function is like $e^{-x}$, so I want to say it is real analytic, but not totally sure. Any help, please?",,"['real-analysis', 'functions', 'analyticity']"
13,Are custom named functions acceptable notation?,Are custom named functions acceptable notation?,,"A custom name being, for example, my function name (MFN): $MFN(x) := ax + b$ As contrasted with: $\delta(x) := ax + b$ Questions: Is it permissible to name the function $MFN$ above? Or is this restricted to very well known functions, such as $sgn(x)$? Can you refer me to a source for the use of word abbreviations as names of functions? Is lower-case preferred to upper-case? What circumstances dictate upper-case function names (or letters)?","A custom name being, for example, my function name (MFN): $MFN(x) := ax + b$ As contrasted with: $\delta(x) := ax + b$ Questions: Is it permissible to name the function $MFN$ above? Or is this restricted to very well known functions, such as $sgn(x)$? Can you refer me to a source for the use of word abbreviations as names of functions? Is lower-case preferred to upper-case? What circumstances dictate upper-case function names (or letters)?",,"['functions', 'notation']"
14,Isn't this a non-surjective epimorphism on the category of sets?,Isn't this a non-surjective epimorphism on the category of sets?,,"I am trying to prove that a morphism in the category of sets is epic iff it is a surjective function. Recall that for objects $A,B,C$, $f \in \hom(A,B)$ is epic when $g_1 \circ f = g_2 \circ f \Rightarrow g_1 = g_2, \forall g_1, g_2 \in \hom(B,C)$. Consider $A= \{0\}, B= \{1,2\}, C=\{3\}$. Since there is only one element in $\hom(B,C)$, $g_1 \circ f = g_2 \circ f \Rightarrow g_1 = g_2, \forall g_1, g_2 \in \hom(B,C)$ is trivially satisfied $\forall f \in \hom(A,B)$ In particular, $f : A \rightarrow B $ $f(0) \mapsto 1$ is an epimorphism, but $f$ is non-surjective. Am I missing something about how categories are defined? Or is it simply false that the original implication is two-sided?","I am trying to prove that a morphism in the category of sets is epic iff it is a surjective function. Recall that for objects $A,B,C$, $f \in \hom(A,B)$ is epic when $g_1 \circ f = g_2 \circ f \Rightarrow g_1 = g_2, \forall g_1, g_2 \in \hom(B,C)$. Consider $A= \{0\}, B= \{1,2\}, C=\{3\}$. Since there is only one element in $\hom(B,C)$, $g_1 \circ f = g_2 \circ f \Rightarrow g_1 = g_2, \forall g_1, g_2 \in \hom(B,C)$ is trivially satisfied $\forall f \in \hom(A,B)$ In particular, $f : A \rightarrow B $ $f(0) \mapsto 1$ is an epimorphism, but $f$ is non-surjective. Am I missing something about how categories are defined? Or is it simply false that the original implication is two-sided?",,"['functions', 'category-theory']"
15,Maximum value of function given minimum value,Maximum value of function given minimum value,,"Suppose there is a function $f(x)=\frac{x^2-2x+b}{x^2+2x+b}$ (the problem doesn't specify, but I am assuming $b$ is a real) that has a minimum value of $\frac{1}{2}$. What is the maximum value of $f(x)$? My first instinct was to divide out everything, getting that $f(x)=1-\frac{4x}{x^2+2x+b}$. From there, I'm not sure what to do. I am looking for a solution that does not involve calculus.","Suppose there is a function $f(x)=\frac{x^2-2x+b}{x^2+2x+b}$ (the problem doesn't specify, but I am assuming $b$ is a real) that has a minimum value of $\frac{1}{2}$. What is the maximum value of $f(x)$? My first instinct was to divide out everything, getting that $f(x)=1-\frac{4x}{x^2+2x+b}$. From there, I'm not sure what to do. I am looking for a solution that does not involve calculus.",,['functions']
16,Opposite of a function being bijective?,Opposite of a function being bijective?,,A function is bijective if it is both surjective and injective . Is there a term for when a function is both not surjective and not injective ?,A function is bijective if it is both surjective and injective . Is there a term for when a function is both not surjective and not injective ?,,"['functions', 'elementary-set-theory', 'terminology']"
17,Function with $f(a)-f(b)$ dividing $a^3-b^3$,Function with  dividing,f(a)-f(b) a^3-b^3,"What are all functions $f:\mathbb{Z}\rightarrow\mathbb{Z}$ such that $f(a)-f(b)$ divides $a^3-b^3$ for all $a,b\in\mathbb{Z}$ such that $f(a)\neq f(b)$? The constant functions satisfy vacuously, and both $f(x)=x+c$ and $f(x)=-x+c$ works for any $c\in\mathbb{Z}$. Same with $f(x)=x^3+c$ and $f(x)=-x^3+c$. Are there other such functions? Edit : As Meelo pointed out, any function with range spanning only two consecutive integers works, since $\pm1$ divides everything.","What are all functions $f:\mathbb{Z}\rightarrow\mathbb{Z}$ such that $f(a)-f(b)$ divides $a^3-b^3$ for all $a,b\in\mathbb{Z}$ such that $f(a)\neq f(b)$? The constant functions satisfy vacuously, and both $f(x)=x+c$ and $f(x)=-x+c$ works for any $c\in\mathbb{Z}$. Same with $f(x)=x^3+c$ and $f(x)=-x^3+c$. Are there other such functions? Edit : As Meelo pointed out, any function with range spanning only two consecutive integers works, since $\pm1$ divides everything.",,"['elementary-number-theory', 'functions', 'divisibility']"
18,Making a piecewise function continuous and differentiable at point,Making a piecewise function continuous and differentiable at point,,"Problem: Let $f(x) = \left\{   \begin{array}{lr}     \frac{\arctan(x)}{(1+x)^2} & : x \geq 0\\     Ae^x + B & : x < 0   \end{array} \right. $ Find $A$ and $B$ such that the function is continuous and differentiable at $x=0$. My attempt: To ensure continuity at $x = 0$ I figured $A = B = 0$ would be the only option. But this, of course, seems very wrong, and in any case, it wouldn't cause differentiability at $x=0$. As far as I could tell, the derivative of $\frac{\arctan(x)}{(1+x)^2}$ at $x=0$ would be $1$. While the second piece's derivative evaluates trivially to $0$.","Problem: Let $f(x) = \left\{   \begin{array}{lr}     \frac{\arctan(x)}{(1+x)^2} & : x \geq 0\\     Ae^x + B & : x < 0   \end{array} \right. $ Find $A$ and $B$ such that the function is continuous and differentiable at $x=0$. My attempt: To ensure continuity at $x = 0$ I figured $A = B = 0$ would be the only option. But this, of course, seems very wrong, and in any case, it wouldn't cause differentiability at $x=0$. As far as I could tell, the derivative of $\frac{\arctan(x)}{(1+x)^2}$ at $x=0$ would be $1$. While the second piece's derivative evaluates trivially to $0$.",,"['calculus', 'functions', 'derivatives']"
19,How to create a function based on the characteristics?,How to create a function based on the characteristics?,,"I wonder how to create a function based on the characteristics. suppose I have function $f$ and $g$ like this: $f(x,g(x,y,z)) = y$ $\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,,$     $g(x,f(x,z),a) = z$ With $x,y,z,a$ are the parameters. Are there ""algorithm"" to ""generate"" arbitrary function which appropriate to that functions ( f and g )?$\,\,\,$ or I should use brute forces / try and error to do that? what mathematics branch to study that?","I wonder how to create a function based on the characteristics. suppose I have function $f$ and $g$ like this: $f(x,g(x,y,z)) = y$ $\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,,$     $g(x,f(x,z),a) = z$ With $x,y,z,a$ are the parameters. Are there ""algorithm"" to ""generate"" arbitrary function which appropriate to that functions ( f and g )?$\,\,\,$ or I should use brute forces / try and error to do that? what mathematics branch to study that?",,['functions']
20,What is a transformation?,What is a transformation?,,"I am not a native English speaker and I have been pointed out that the word ""transformation"" as a synonym of ""function"" is grammatically incorrect. However, I even found a wikipedia and a mathworld entries where they use ""transformation"" as a synonym of function: http://en.wikipedia.org/wiki/Transformation_(function) http://mathworld.wolfram.com/Transformation.html Which one is correct?","I am not a native English speaker and I have been pointed out that the word ""transformation"" as a synonym of ""function"" is grammatically incorrect. However, I even found a wikipedia and a mathworld entries where they use ""transformation"" as a synonym of function: http://en.wikipedia.org/wiki/Transformation_(function) http://mathworld.wolfram.com/Transformation.html Which one is correct?",,"['functions', 'definition', 'transformation']"
21,Non-monotonic functions on ordered sets,Non-monotonic functions on ordered sets,,"I'm trying to prove that if $~~(A,<_A)~~$ and $~~(B,<_B)~~$ are linearly ordered sets and $~~f: A \rightarrow B~~$ is non-monotonic function than there exist points $~~a,b,c\in A~~$ such that $~~ a <_A b <_A c~~$ and ($f(b)<_B\min\{f(a),f(c)\}~~$ or $~~\max\{f(a),f(c)\}<_Bf(b)$) But unfortunately nothing better than brute-force enumeration of possibilities comes to my mind. So i'll be grateful for any tips or solutions for this question. Thanks in advance.","I'm trying to prove that if $~~(A,<_A)~~$ and $~~(B,<_B)~~$ are linearly ordered sets and $~~f: A \rightarrow B~~$ is non-monotonic function than there exist points $~~a,b,c\in A~~$ such that $~~ a <_A b <_A c~~$ and ($f(b)<_B\min\{f(a),f(c)\}~~$ or $~~\max\{f(a),f(c)\}<_Bf(b)$) But unfortunately nothing better than brute-force enumeration of possibilities comes to my mind. So i'll be grateful for any tips or solutions for this question. Thanks in advance.",,"['functions', 'order-theory']"
22,"There cannot exist a rational function $f: \mathbb{R} \to \mathbb{R}$ injective, not surjective","There cannot exist a rational function  injective, not surjective",f: \mathbb{R} \to \mathbb{R},"I was looking for a rational function $f: \mathbb{R} \to \mathbb{R}$ that looks like $\arctan$, in that it is injective not surjective well-defined on all $x\in \mathbb{R}$ (no vertical asymptotes) I believe I have proven that one can't exist. My thinking is this: it can't be a polynomial, because an odd-degree polynomial is surjective and an even degree polynomial is not injective. Therefore it must have a nontrivial denominator. The denominator can't be an odd degree polynomial, or else it has a zero somewhere. If the numerator is a polynomial of degree greater than the denominator $N>D$, then we get surjectivity (if $N-D$ is odd), or we lose injectivity (if $N-D$ is even). If $N\leq D$, then we lose injectivity, since the function will approach the same limit as $x \to \pm \infty$ (I claim that together with continuity, this implies that we lose injectivity). Do you agree? Is there a general result about such functions?","I was looking for a rational function $f: \mathbb{R} \to \mathbb{R}$ that looks like $\arctan$, in that it is injective not surjective well-defined on all $x\in \mathbb{R}$ (no vertical asymptotes) I believe I have proven that one can't exist. My thinking is this: it can't be a polynomial, because an odd-degree polynomial is surjective and an even degree polynomial is not injective. Therefore it must have a nontrivial denominator. The denominator can't be an odd degree polynomial, or else it has a zero somewhere. If the numerator is a polynomial of degree greater than the denominator $N>D$, then we get surjectivity (if $N-D$ is odd), or we lose injectivity (if $N-D$ is even). If $N\leq D$, then we lose injectivity, since the function will approach the same limit as $x \to \pm \infty$ (I claim that together with continuity, this implies that we lose injectivity). Do you agree? Is there a general result about such functions?",,"['calculus', 'functions', 'polynomials', 'rational-functions']"
23,Solving the functional equation $(x+1)f\left(\frac{y}{f(x)}\right)=f(x+y)$,Solving the functional equation,(x+1)f\left(\frac{y}{f(x)}\right)=f(x+y),"Solve functional equation: Find all strictly monotone functions $f:(0,+\infty)\to(0,+\infty)$ such that $$(x+1)f\left(\frac{y}{f(x)}\right)=f(x+y),\forall x,y>0\text.$$",Solve functional equation: Find all strictly monotone functions such that,"f:(0,+\infty)\to(0,+\infty) (x+1)f\left(\frac{y}{f(x)}\right)=f(x+y),\forall x,y>0\text.","['functions', 'functional-equations']"
24,Is this a field of study?,Is this a field of study?,,"Is there a name for an equation that takes the following form? $$F(f(x),f^{-1}(x),x)=0$$ A nice example being $$f(x)-f^{-1}(x)=0$$ because the solutions of this equation are their own inverses. WolframAlpha solved this problem, though I had to type the equation as $f(f(x))=x$. Is there any nice method for solving such equations? How do you think WolframAlpha does it? For instance, what if I wanted to solve $$f(x)={f^{-1}(x)}^2+x$$ Which could also be written as $$f(\sqrt{f(x)-x})-x=0$$","Is there a name for an equation that takes the following form? $$F(f(x),f^{-1}(x),x)=0$$ A nice example being $$f(x)-f^{-1}(x)=0$$ because the solutions of this equation are their own inverses. WolframAlpha solved this problem, though I had to type the equation as $f(f(x))=x$. Is there any nice method for solving such equations? How do you think WolframAlpha does it? For instance, what if I wanted to solve $$f(x)={f^{-1}(x)}^2+x$$ Which could also be written as $$f(\sqrt{f(x)-x})-x=0$$",,"['functions', 'soft-question', 'inverse', 'functional-equations']"
25,function inequality $f(x+y)+y \leq f(f(f(x)))$,function inequality,f(x+y)+y \leq f(f(f(x))),$f(x+y)+y \leq f(f(f(x)))$ find all possible solution for $ f: \mathbb {R} \rightarrow \mathbb {R}$,$f(x+y)+y \leq f(f(f(x)))$ find all possible solution for $ f: \mathbb {R} \rightarrow \mathbb {R}$,,"['functions', 'inequality']"
26,Proving if function is one to one,Proving if function is one to one,,"This is not a homework, I'm just doing some revision and I saw this exercise: Consider the function $f :$ $NÃ N$ $\rightarrow$ $NÃ N$ given by: $f(m, n) = (3m+n, n^2)$ (a) Is $f$ one-to-one? (b) Is $f$ onto? What should I do in this case $(3m+n, n^2)$ ? I usually assume $f(m)=f(n)$ and so on but here it's different.","This is not a homework, I'm just doing some revision and I saw this exercise: Consider the function given by: (a) Is one-to-one? (b) Is onto? What should I do in this case ? I usually assume and so on but here it's different.","f : NÃ N \rightarrow NÃ N f(m, n) = (3m+n, n^2) f f (3m+n, n^2) f(m)=f(n)",['functions']
27,How to tell if a function is onto or one-to-one,How to tell if a function is onto or one-to-one,,"I'm practicing what we learned in lecture today and unfortunately I have little to no understanding about the material. I only know the difference of these functions only when a diagram is present (and I can't always have that, so I need to learn how to figure it out without one) So I've provided an example from my textbook (not assigned work) Question: Determine whether each of these functions from $\mathbb{Z}$ to $\mathbb{Z}$ is one-to-one $a$) $f(n)=n-1$ (ANS: onto) $b$) $f(n)=n^2+1$ (ANS: one-to-one) I know the answers only since I looked in the back, but have no idea why. Can someone please explain? I will be using the answers as a base to complete the rest of the questions for study.","I'm practicing what we learned in lecture today and unfortunately I have little to no understanding about the material. I only know the difference of these functions only when a diagram is present (and I can't always have that, so I need to learn how to figure it out without one) So I've provided an example from my textbook (not assigned work) Question: Determine whether each of these functions from $\mathbb{Z}$ to $\mathbb{Z}$ is one-to-one $a$) $f(n)=n-1$ (ANS: onto) $b$) $f(n)=n^2+1$ (ANS: one-to-one) I know the answers only since I looked in the back, but have no idea why. Can someone please explain? I will be using the answers as a base to complete the rest of the questions for study.",,"['functions', 'discrete-mathematics']"
28,Find lower bound of function,Find lower bound of function,,"Can someone help me finding a lower bound to the function $$f(x)=\frac{x-1}{e^{-1}-xe^{-x^2}},$$ where $x\in[1,+\infty[$? Taking the derivative and then solve $f'(x)=0$ isn't analytically possible. Then I tried the second best thing, find a lower bound but I don't really know how to start, so any help would be most welcome.","Can someone help me finding a lower bound to the function $$f(x)=\frac{x-1}{e^{-1}-xe^{-x^2}},$$ where $x\in[1,+\infty[$? Taking the derivative and then solve $f'(x)=0$ isn't analytically possible. Then I tried the second best thing, find a lower bound but I don't really know how to start, so any help would be most welcome.",,"['calculus', 'functions', 'optimization']"
29,Surjections and equivalence relations,Surjections and equivalence relations,,"(a)  Let $f: A \to B$ be a surjective function.  We define $a_1 \sim a_2$ if $f(a_1)=f(a_2)$.  Prove that $\sim$ is an equivalence relation. Reflexivity: This comes for free.  If $a_1 \sim a_1$, then $f(a_1)=f(a_1)$. Symmetry: Suppose $a \sim b$.  Then $f(a)=f(b)$.  But that is the same as saying $f(b)=f(a)$.  Thus $b \sim a$. Transitivity: Suppose $a \sim b$ and $b \sim c$. Then $f(a)=f(b)$ and $f(b)=f(c)$.  Then $f(a)=f(c)$.  Thus $a \sim c$. (b)  Suppose $A$ is a set and $\sim$ is an equivalence relation on $A$.  Find a set $B$ and a function $f\colon A \to B$ such that $f(a_1)=f(a_2)$ exactly when $a_1\sim a_2$. This one I'm not sure how to even start.  It does seem like I am trying to prove the converse to part (a), but I am not sure.","(a)  Let $f: A \to B$ be a surjective function.  We define $a_1 \sim a_2$ if $f(a_1)=f(a_2)$.  Prove that $\sim$ is an equivalence relation. Reflexivity: This comes for free.  If $a_1 \sim a_1$, then $f(a_1)=f(a_1)$. Symmetry: Suppose $a \sim b$.  Then $f(a)=f(b)$.  But that is the same as saying $f(b)=f(a)$.  Thus $b \sim a$. Transitivity: Suppose $a \sim b$ and $b \sim c$. Then $f(a)=f(b)$ and $f(b)=f(c)$.  Then $f(a)=f(c)$.  Thus $a \sim c$. (b)  Suppose $A$ is a set and $\sim$ is an equivalence relation on $A$.  Find a set $B$ and a function $f\colon A \to B$ such that $f(a_1)=f(a_2)$ exactly when $a_1\sim a_2$. This one I'm not sure how to even start.  It does seem like I am trying to prove the converse to part (a), but I am not sure.",,"['abstract-algebra', 'elementary-set-theory', 'functions', 'equivalence-relations']"
30,Definition of correspondence,Definition of correspondence,,"A one-to-one correspondence is an alternative name for a bijection between two sets, but to what does the term 'correspondence' alone refer? As far as I can see, it seems to be another term for 'relation', but I think there must be a difference.","A one-to-one correspondence is an alternative name for a bijection between two sets, but to what does the term 'correspondence' alone refer? As far as I can see, it seems to be another term for 'relation', but I think there must be a difference.",,"['functions', 'terminology', 'definition', 'relations']"
31,Bijection for algebraic numbers,Bijection for algebraic numbers,,"Is there a bijective function $f(n)$, where $n \in \mathbb{N}$, which enumerates all algebraic numbers? Is it possible to define such function?","Is there a bijective function $f(n)$, where $n \in \mathbb{N}$, which enumerates all algebraic numbers? Is it possible to define such function?",,"['elementary-set-theory', 'functions', 'cardinals']"
32,What is the difference between a function and a map? [duplicate],What is the difference between a function and a map? [duplicate],,This question already has answers here : Closed 11 years ago . Possible Duplicate: Is there any difference between mapping and function? I am an aspiring mathematician who just started out. What is the difference between a function and a map? Or are these notions equivalent?,This question already has answers here : Closed 11 years ago . Possible Duplicate: Is there any difference between mapping and function? I am an aspiring mathematician who just started out. What is the difference between a function and a map? Or are these notions equivalent?,,"['functions', 'terminology', 'definition']"
33,"Finding a function that fits the ""lowest points"" of another one","Finding a function that fits the ""lowest points"" of another one",,"I came up with this problem, which I cannot solve myself. Consider the function: $\displaystyle f(x) = x^{\ln(|\pi \cos x ^ 2| + |\pi \tan x ^ 2|)}$, which has singularities at $\sqrt{\pi}\sqrt{n + \dfrac{1}{2}}$, with $n \in \mathbb{Z}$. Looking at its graph: we can see it is globally increasing: I was wondering if there exists a function $g(x)$, such that $f(x) - g(x) \ge 0, \forall x \in \mathbb{R^{+}}$ and that best fits the ""lowest points"" of $f(x)$. Sorry for the inaccurate terminology but I really don't know how to express this concept mathematically. Here is, for example, $g(x) = x ^ {1.14}$ (in red): Actually $g(x)$ is not correct because for small values of $x$ it is greater than $f(x)$. Is it possible to find such a $g(x)$, given that the ""nearest"" is $g(x)$ to $f(x)$'s ""lowest points"" the better it is? Again, sorry for my terminology, I hope you could point me in the right direction. Thanks,","I came up with this problem, which I cannot solve myself. Consider the function: $\displaystyle f(x) = x^{\ln(|\pi \cos x ^ 2| + |\pi \tan x ^ 2|)}$, which has singularities at $\sqrt{\pi}\sqrt{n + \dfrac{1}{2}}$, with $n \in \mathbb{Z}$. Looking at its graph: we can see it is globally increasing: I was wondering if there exists a function $g(x)$, such that $f(x) - g(x) \ge 0, \forall x \in \mathbb{R^{+}}$ and that best fits the ""lowest points"" of $f(x)$. Sorry for the inaccurate terminology but I really don't know how to express this concept mathematically. Here is, for example, $g(x) = x ^ {1.14}$ (in red): Actually $g(x)$ is not correct because for small values of $x$ it is greater than $f(x)$. Is it possible to find such a $g(x)$, given that the ""nearest"" is $g(x)$ to $f(x)$'s ""lowest points"" the better it is? Again, sorry for my terminology, I hope you could point me in the right direction. Thanks,",,"['functions', 'graphing-functions']"
34,Constructing a function from a function of its inverse,Constructing a function from a function of its inverse,,"Let $f$ be a continuous strictly-increasing function that maps $\mathbb{R}_+$ to $\mathbb{R}_+$ . Define a function $g$ on $\mathbb{R}_+$ as follows: $$g(x) := f^{-1}(f(x)+1).$$ For example, if $f(x) = x^2$ , then $g(x) = \sqrt{x^2+1}$ . In words, $g(x)$ describes to what value you should increase $x$ , so that $f(x)$ increases by $1$ . The function $g$ clearly satisfies two properties: $g(x)>x$ for all $x$ ; $g(x)$ is strictly increasing. QUESTION: Given a function $g$ that satisfies these two properties, does there always exist a corresponding function $f$ ? If not, what other conditions are required?","Let be a continuous strictly-increasing function that maps to . Define a function on as follows: For example, if , then . In words, describes to what value you should increase , so that increases by . The function clearly satisfies two properties: for all ; is strictly increasing. QUESTION: Given a function that satisfies these two properties, does there always exist a corresponding function ? If not, what other conditions are required?",f \mathbb{R}_+ \mathbb{R}_+ g \mathbb{R}_+ g(x) := f^{-1}(f(x)+1). f(x) = x^2 g(x) = \sqrt{x^2+1} g(x) x f(x) 1 g g(x)>x x g(x) g f,"['functions', 'inverse-function']"
35,"Interpretation of ""Noise"" in Function Optimization","Interpretation of ""Noise"" in Function Optimization",,"I am trying to better understand the meaning of ""noise"" with regards to function optimization - specifically, why ""Noisy"" functions are more difficult to optimize compared to ""Non-Noisy"" functions. Up until now, I always thought of ""noise"" from a signal processing standpoint: for example - how to remove and filter out the noise component from some signal: I also generally think of this in the context of Time Series Analysis, where a time series is separated into non-random components (e.g. seasonal) and random components (e.g. noise): In both of these above cases, ""Noise"" is viewed as something with inherent ""negative connotations"", as something undesirable which is either hindering or further complicating the end goal of (usually) a forecasting or engineering project. However, I am interested in ""noise"" from more of a Machine Learning and Optimization perspective. For instance, (I am not sure if this is correct) I have heard that since the ""loss functions"" of Machine Learning algorithms are always modelling a random variable - thus, any ""loss function"" of a Machine Learning algorithm is always considered to be a ""noisy function"": My Question: Why are ""Noisy"" Functions difficult to optimize compared to ""Non-Noisy"" Functions? I can understand that ""Noisy"" Functions contain ""random noise"" (as the name implies) which alters their ""fidelity"" with regards to the concept they are attempting to represent (i.e. an additional source of ""difficulty"" when attempting to use them for some applied purpose) - but are ""Noisy"" Functions inherent more ""computationally expensive"" to evaluate (e.g. their derivatives) compared to ""Non-Noisy"" and ""Lesser-Noisy"" Functions of similar complexity? How exactly does the ""Noisiness"" of a function contribute to its computational complexity (to the extent that gradient-free methods are often used on ""Noisy"" Functions in order to reduce their ""computational costs"")? I have heard the following argument being made on an informal level : Given that ""Noisy"" Functions are often more ""computationally expensive"" to optimize, and that no major theoretical results have been established on the convergence properties of gradient-based optimization algorithms on ""Noisy"" Functions - using gradient-free optimization algorithms (e.g. evolutionary algorithms, genetic algorithm, metaheuristics) might have certain advantages in optimizing such ""Noisy"" Functions. Have any significant theoretical results been established regarding the convergence properties of common optimization algorithms (e.g. gradient descent, stochastic gradient descent) on ""Noisy"" Functions? Thanks! References: http://pages.cs.wisc.edu/~ferris/talks/Informs-washington.pdf https://noisyopt.readthedocs.io/en/latest/ https://hal.archives-ouvertes.fr/hal-01306636v2/document","I am trying to better understand the meaning of ""noise"" with regards to function optimization - specifically, why ""Noisy"" functions are more difficult to optimize compared to ""Non-Noisy"" functions. Up until now, I always thought of ""noise"" from a signal processing standpoint: for example - how to remove and filter out the noise component from some signal: I also generally think of this in the context of Time Series Analysis, where a time series is separated into non-random components (e.g. seasonal) and random components (e.g. noise): In both of these above cases, ""Noise"" is viewed as something with inherent ""negative connotations"", as something undesirable which is either hindering or further complicating the end goal of (usually) a forecasting or engineering project. However, I am interested in ""noise"" from more of a Machine Learning and Optimization perspective. For instance, (I am not sure if this is correct) I have heard that since the ""loss functions"" of Machine Learning algorithms are always modelling a random variable - thus, any ""loss function"" of a Machine Learning algorithm is always considered to be a ""noisy function"": My Question: Why are ""Noisy"" Functions difficult to optimize compared to ""Non-Noisy"" Functions? I can understand that ""Noisy"" Functions contain ""random noise"" (as the name implies) which alters their ""fidelity"" with regards to the concept they are attempting to represent (i.e. an additional source of ""difficulty"" when attempting to use them for some applied purpose) - but are ""Noisy"" Functions inherent more ""computationally expensive"" to evaluate (e.g. their derivatives) compared to ""Non-Noisy"" and ""Lesser-Noisy"" Functions of similar complexity? How exactly does the ""Noisiness"" of a function contribute to its computational complexity (to the extent that gradient-free methods are often used on ""Noisy"" Functions in order to reduce their ""computational costs"")? I have heard the following argument being made on an informal level : Given that ""Noisy"" Functions are often more ""computationally expensive"" to optimize, and that no major theoretical results have been established on the convergence properties of gradient-based optimization algorithms on ""Noisy"" Functions - using gradient-free optimization algorithms (e.g. evolutionary algorithms, genetic algorithm, metaheuristics) might have certain advantages in optimizing such ""Noisy"" Functions. Have any significant theoretical results been established regarding the convergence properties of common optimization algorithms (e.g. gradient descent, stochastic gradient descent) on ""Noisy"" Functions? Thanks! References: http://pages.cs.wisc.edu/~ferris/talks/Informs-washington.pdf https://noisyopt.readthedocs.io/en/latest/ https://hal.archives-ouvertes.fr/hal-01306636v2/document",,"['functions', 'convergence-divergence', 'optimization', 'machine-learning', 'noise']"
36,What is the range of $f(x) = \sec ^{-1}(x) + \tan^{-1} (x)$ .,What is the range of  .,f(x) = \sec ^{-1}(x) + \tan^{-1} (x),"To find the range of this function $$f(x) = \sec ^{-1}(x) + \tan^{-1} (x)$$ I solved it like, Range ( $\sec ^{-1}(x)$ ) = $[0,Ï] $ ~ $ $ {Ï/2} and, Range ( $\tan^{-1} (x)$ ) = $(-Ï/2 , Ï/2)$ So the resultant Range will be the intersection of the two individual ranges. So I got my answer as $[0, Ï/2)$ , but the textbook answer is $(0,Ï)$ . Hence my question is what is happening here and where am I wrong. Please help me to get the fundamentals used here.","To find the range of this function I solved it like, Range ( ) = ~ {Ï/2} and, Range ( ) = So the resultant Range will be the intersection of the two individual ranges. So I got my answer as , but the textbook answer is . Hence my question is what is happening here and where am I wrong. Please help me to get the fundamentals used here.","f(x) = \sec ^{-1}(x) + \tan^{-1} (x) \sec ^{-1}(x) [0,Ï]    \tan^{-1} (x) (-Ï/2 , Ï/2) [0, Ï/2) (0,Ï)",['functions']
37,"Is there a name for $(x, f(x))$?",Is there a name for ?,"(x, f(x))","Given a function $f$ , and an $x$ from its domain, is there a name for the pair $(x, f(x))$ ? Is there a defined terminology for one (any) such pair? I think the set of all $(x, f(x))$ is called the graph of the function, but I am asking is there's a name for one (or any) point of the graph.","Given a function , and an from its domain, is there a name for the pair ? Is there a defined terminology for one (any) such pair? I think the set of all is called the graph of the function, but I am asking is there's a name for one (or any) point of the graph.","f x (x, f(x)) (x, f(x))","['functions', 'terminology']"
38,Can you define $f(x)$ such that $2^{x}<f(f(f(x)))<2^{2^x}$?,Can you define  such that ?,f(x) 2^{x}<f(f(f(x)))<2^{2^x},"Can you define a real-valued function $f$ using standard arthimetical operations such that $2^{x} < f(f(f(x))) < 2^{2^x}$ for sufficiently large $x\in \mathbb{R}$ ? I know that the rule $f(f(x))=2^{x}$ can't be established with standard arthimetical operations, but is it possible to find a function using standard arthimetical operations such that $2^{x}<f(f(f(x)))<2^{2^x}$ for sufficiently large $x\in \mathbb{R}$ ?","Can you define a real-valued function using standard arthimetical operations such that for sufficiently large ? I know that the rule can't be established with standard arthimetical operations, but is it possible to find a function using standard arthimetical operations such that for sufficiently large ?",f 2^{x} < f(f(f(x))) < 2^{2^x} x\in \mathbb{R} f(f(x))=2^{x} 2^{x}<f(f(f(x)))<2^{2^x} x\in \mathbb{R},"['functions', 'exponentiation', 'problem-solving']"
39,What's the name of a function with a variable in the base and exponent?,What's the name of a function with a variable in the base and exponent?,,"For example, $k^x$ , where $k$ is a constant, is an exponential function. It is differentiated quite easily. $x^x$ is also an exponential function. It takes much more effort to differentiate it. Is there a specific name for the latter type of function?","For example, , where is a constant, is an exponential function. It is differentiated quite easily. is also an exponential function. It takes much more effort to differentiate it. Is there a specific name for the latter type of function?",k^x k x^x,"['functions', 'terminology']"
40,The digit at position $n$ of the number $x$ in base $m$,The digit at position  of the number  in base,n x m,"As a solution to this question , we can define a function $f_b(x, n)$ which finds the digit in the $n$ th position of $x$ in base $b$ . $$ f_b(x, n) = \left\lfloor \frac{x}{b^n} \right\rfloor \bmod b $$ It even works for decimals, for example: e = 2 . 7  1  8  2  8  1  8 2 8 ...     0  -1 -2 -3 -4 -5 -6 -7 -8 -9 th position $$ f_{10}(e, -8) = 2 \quad \checkmark $$ However, when using a non-integer base, all the digits are fractional. $$ f_\pi(e, [0,-1,-2,\dots]) = [2, 1.717, 0.867, 2.319, \dots] $$ For reference, Wolfram Alpha states that $e$ in base $\pi$ is actually 2.2021201002111... Additionally, for negative bases, all the digits of $f$ are negative. Wolfram Alpha states that $e$ in base $-10$ is 3.3223222325590... Furthermore, the function also screws up if $x_b$ is negative. So I am also looking for a function to have a way of differentiating positive and negative numbers (especially important in negative bases, since for example, 21 in decimal would be -39 in negadecimal). My question is if there is a function which does this but is also valid even for non-integer and negative bases. I'm sure there would be, but I don't know what we need to modify such that this would happen. In other words, is there a function such that $$ f_b\left(\sum_{k=-\infty}^\infty a_k b^k, n \right) = a_n \qquad b\in\mathbb{R} $$ ? I have since then found a recursive method for non-integer but not negative bases : Start by calculating $A=\lfloor\log_b n\rfloor$ , then $$ U_1 = f_b(n, A) = \left\lfloor\frac{n}{b^A}\right\rfloor $$ $$ U_2 = f_b(n, A-1) = \left\lfloor\frac{n-U_1b^A}{b^{A-1}}\right\rfloor $$ $$ U_3 = f_b(n, A-2) = \left\lfloor\frac{n-U_1b^A-U_2b^{A-1}}{b^{A-2}}\right\rfloor $$ etc. The simple problem with this one is when it deals with a negative base, it returns negative digits.","As a solution to this question , we can define a function which finds the digit in the th position of in base . It even works for decimals, for example: e = 2 . 7  1  8  2  8  1  8 2 8 ...     0  -1 -2 -3 -4 -5 -6 -7 -8 -9 th position However, when using a non-integer base, all the digits are fractional. For reference, Wolfram Alpha states that in base is actually 2.2021201002111... Additionally, for negative bases, all the digits of are negative. Wolfram Alpha states that in base is 3.3223222325590... Furthermore, the function also screws up if is negative. So I am also looking for a function to have a way of differentiating positive and negative numbers (especially important in negative bases, since for example, 21 in decimal would be -39 in negadecimal). My question is if there is a function which does this but is also valid even for non-integer and negative bases. I'm sure there would be, but I don't know what we need to modify such that this would happen. In other words, is there a function such that ? I have since then found a recursive method for non-integer but not negative bases : Start by calculating , then etc. The simple problem with this one is when it deals with a negative base, it returns negative digits.","f_b(x, n) n x b 
f_b(x, n) = \left\lfloor \frac{x}{b^n} \right\rfloor \bmod b
 
f_{10}(e, -8) = 2 \quad \checkmark
 
f_\pi(e, [0,-1,-2,\dots]) = [2, 1.717, 0.867, 2.319, \dots]
 e \pi f e -10 x_b 
f_b\left(\sum_{k=-\infty}^\infty a_k b^k, n \right) = a_n \qquad b\in\mathbb{R}
 A=\lfloor\log_b n\rfloor  U_1 = f_b(n, A) = \left\lfloor\frac{n}{b^A}\right\rfloor   U_2 = f_b(n, A-1) = \left\lfloor\frac{n-U_1b^A}{b^{A-1}}\right\rfloor   U_3 = f_b(n, A-2) = \left\lfloor\frac{n-U_1b^A-U_2b^{A-1}}{b^{A-2}}\right\rfloor ","['functions', 'number-systems']"
41,$f(A\cap B) = f(A)\cap f(B)$ if $f$ is surjective,if  is surjective,f(A\cap B) = f(A)\cap f(B) f,"If $f$ is injective, then the statement $f(A\cap B) = f(A)\cap f(B)$ holds, but what if $f$ is surjective (and not injective)? Is the statement true as well? I think that it is not true, but I am not sure whether my counterexample works: Assume $f: X\rightarrow Y$ , where $X=[-2,2]$ and $Y=[0,4]$ and $f(x) = x^2$ . Then $f$ is surjective. Now define $A=[-2,0]$ and $B=[0,2]$ , then $f(A\cap B) = f(0) = 0$ , whereas $f(A)\cap f(B) = [0,4]$ . Is this correct or is $f$ not surjective for the defined $A$ and $B$ ?","If is injective, then the statement holds, but what if is surjective (and not injective)? Is the statement true as well? I think that it is not true, but I am not sure whether my counterexample works: Assume , where and and . Then is surjective. Now define and , then , whereas . Is this correct or is not surjective for the defined and ?","f f(A\cap B) = f(A)\cap f(B) f f: X\rightarrow Y X=[-2,2] Y=[0,4] f(x) = x^2 f A=[-2,0] B=[0,2] f(A\cap B) = f(0) = 0 f(A)\cap f(B) = [0,4] f A B",['functions']
42,Given certain conditions show $f'''(x)\ge3$,Given certain conditions show,f'''(x)\ge3,"Suppose $f$ is a real valued continuous function defined on $[-2,2]$ and is the times differentiable in $(-2,2)$. If $f(2)=-f(-2)=4$ and $f'(0)=0$ then show there exists $x\in(-2,2)$ such that $f'''(x)\ge3$. I have tried using MVT to no avail. Tried to back calculate assuming $f'''(x)\ge3$ and then integrating. Couldn't do it.","Suppose $f$ is a real valued continuous function defined on $[-2,2]$ and is the times differentiable in $(-2,2)$. If $f(2)=-f(-2)=4$ and $f'(0)=0$ then show there exists $x\in(-2,2)$ such that $f'''(x)\ge3$. I have tried using MVT to no avail. Tried to back calculate assuming $f'''(x)\ge3$ and then integrating. Couldn't do it.",,"['real-analysis', 'functions']"
43,does my proof on inverse functions make sense?,does my proof on inverse functions make sense?,,"I am proving this question: let $g : N \rightarrow M$ and $ A \subseteq M$. Prove that if $f$ is surjective then $g(g^{-1}(A)) = A$ For the proof this is what I have said: (forwards)Let $y \in g(g^{-1}(A)) $, also lets say that $\exists x \in g^{-1}(A)$. Then by subjectivity $g(x) = y$. Then $g(x)=y \in A$. Wich leads to the conclution that $ g(g^{-1}(A)) \subseteq A$ (reverse) let  $y \in A$, also lets say that $\exists x \in N$, such that $g(x)=y\in A$.  This leads to $x \in g^{-1}(A)$ which is equivelent to $y = g(x) \in g(g^{-1}(A))$. This leads to the conclution that $A \subseteq g(g^{-1}(A))$ Hence   $g(g^{-1}(A)) = A$. Thanks for the help, any improvements welcome","I am proving this question: let $g : N \rightarrow M$ and $ A \subseteq M$. Prove that if $f$ is surjective then $g(g^{-1}(A)) = A$ For the proof this is what I have said: (forwards)Let $y \in g(g^{-1}(A)) $, also lets say that $\exists x \in g^{-1}(A)$. Then by subjectivity $g(x) = y$. Then $g(x)=y \in A$. Wich leads to the conclution that $ g(g^{-1}(A)) \subseteq A$ (reverse) let  $y \in A$, also lets say that $\exists x \in N$, such that $g(x)=y\in A$.  This leads to $x \in g^{-1}(A)$ which is equivelent to $y = g(x) \in g(g^{-1}(A))$. This leads to the conclution that $A \subseteq g(g^{-1}(A))$ Hence   $g(g^{-1}(A)) = A$. Thanks for the help, any improvements welcome",,"['real-analysis', 'functions', 'proof-verification', 'proof-writing']"
44,Showing $f(z) \le 2 \sqrt{ \varepsilon} f(y)$ if $z < \varepsilon y$ for given $f$,Showing  if  for given,f(z) \le 2 \sqrt{ \varepsilon} f(y) z < \varepsilon y f,Is is possible to show $f(z) \le 2 \sqrt{ \varepsilon} f(y)$ if $z < \varepsilon y$ for $f(x) = \sqrt{|x|\log \frac{1}{|x|}}$? I would like to use this inequality in a proof but I don't know wether it is true and how I can show it. Any hints would be great!,Is is possible to show $f(z) \le 2 \sqrt{ \varepsilon} f(y)$ if $z < \varepsilon y$ for $f(x) = \sqrt{|x|\log \frac{1}{|x|}}$? I would like to use this inequality in a proof but I don't know wether it is true and how I can show it. Any hints would be great!,,"['functions', 'inequality', 'estimation']"
45,"If there is a need to distinguish between 'image' and 'codomain', why not do this on the input side of a function?","If there is a need to distinguish between 'image' and 'codomain', why not do this on the input side of a function?",,"I see lots of reasons provided for distinguishing between codomain and image.  But it seems to me I can take all those reasons and make them into reasons for making a similar distinction on the input side (e.g. to discriminate between a 'domain of discourse' and 'domain of definition'). For example, here are some quotes from a discussion on the need to distinguish between 'image' and 'codomain' Why is it important to have a discrepancy between image and codomain? : for many functions it's not particularly important what its image is, while at the same time it would be tricky to figure this out. The codomain however is easy, it describes the type of value one can get. Is it a real number, a complex number, a fraction? For some functions, the same is true for the input side. That is, when dealing with a function I want to describe the type of input values (real numbers, or complex numbers, or?) that I would like that function to deal with, but the function may be a really hairy function for which its actual domain is tricky (if not impossible, if I define some function over Turing-machines and have their halting behavior be an essential aspect as to whether the output value is defined) to figure out. Codomain and Image of a function are two completely different concepts. The codomain of a function often has a structure, like being a topological space or something like this. It will be very inconvenient to put all that structure in the image, which is only a set, and often not such a nice one. Again, I think the same could be said on the input side ... for some functions it will be very inconvenient to describe its domain, as it's not a nice one, and as it's just a set, rather than a structure. I would like two similar concepts on the input side as well. You cannot speak about surjectivity (that is, whether it is onto) otherwise. If we would define the codomain of every function to be its image, then every function would be surjective. I can likewise say: ""You cannot speak of totality if you don't distinguish between 'domain of discourse' and 'domain of definition'. If we would define the 'domain of discourse' to be its 'domain of definition', then every function would be total."" What is a function? Informally, it is a process, or an assignment, from an input set to an output set. It is not just the process or assignment that forms a function, but specifying the input and output is part of what it is. Right ... so that would suggest we define a 'domain of discourse' before we figure out for which values the function is actually defined. I need to define a co-domain before the image makes sense. Same for the input: if you give me something like $f(x) = 1/x$, I would first need to know the domain of discourse (real numbers? Complex numbers?) before I can figure out its actual domain of definition. Finally, if it is so important for functions to have a codomain in addition to an image, why is it that when I take the inverse of a function (assuming it has one), its codomain will always be the same as its image, namely the domain of the original function? It seems to me that if you do make a distinction between 'domain of discourse' and 'domain of definition', then right there you have your 'codomain' and 'image' of the inverse that actually can be different and serve their respective purposes for the inverse. So, my question is this:  why then don't we typically make a similar discrepancy on the input as we do on the output? (and yes, I believe some mathematical texts do make this distinction, but my question is why don't we typically make this distinction?)  Why don't we have two terms on the input side that are the conceptual counterparts of 'co-domain' vs 'image' on the output side?  Is this mere historical 'accident' and mostly a matter of 'well, we've always done things this way', or are there actual good practical reasons for this?","I see lots of reasons provided for distinguishing between codomain and image.  But it seems to me I can take all those reasons and make them into reasons for making a similar distinction on the input side (e.g. to discriminate between a 'domain of discourse' and 'domain of definition'). For example, here are some quotes from a discussion on the need to distinguish between 'image' and 'codomain' Why is it important to have a discrepancy between image and codomain? : for many functions it's not particularly important what its image is, while at the same time it would be tricky to figure this out. The codomain however is easy, it describes the type of value one can get. Is it a real number, a complex number, a fraction? For some functions, the same is true for the input side. That is, when dealing with a function I want to describe the type of input values (real numbers, or complex numbers, or?) that I would like that function to deal with, but the function may be a really hairy function for which its actual domain is tricky (if not impossible, if I define some function over Turing-machines and have their halting behavior be an essential aspect as to whether the output value is defined) to figure out. Codomain and Image of a function are two completely different concepts. The codomain of a function often has a structure, like being a topological space or something like this. It will be very inconvenient to put all that structure in the image, which is only a set, and often not such a nice one. Again, I think the same could be said on the input side ... for some functions it will be very inconvenient to describe its domain, as it's not a nice one, and as it's just a set, rather than a structure. I would like two similar concepts on the input side as well. You cannot speak about surjectivity (that is, whether it is onto) otherwise. If we would define the codomain of every function to be its image, then every function would be surjective. I can likewise say: ""You cannot speak of totality if you don't distinguish between 'domain of discourse' and 'domain of definition'. If we would define the 'domain of discourse' to be its 'domain of definition', then every function would be total."" What is a function? Informally, it is a process, or an assignment, from an input set to an output set. It is not just the process or assignment that forms a function, but specifying the input and output is part of what it is. Right ... so that would suggest we define a 'domain of discourse' before we figure out for which values the function is actually defined. I need to define a co-domain before the image makes sense. Same for the input: if you give me something like $f(x) = 1/x$, I would first need to know the domain of discourse (real numbers? Complex numbers?) before I can figure out its actual domain of definition. Finally, if it is so important for functions to have a codomain in addition to an image, why is it that when I take the inverse of a function (assuming it has one), its codomain will always be the same as its image, namely the domain of the original function? It seems to me that if you do make a distinction between 'domain of discourse' and 'domain of definition', then right there you have your 'codomain' and 'image' of the inverse that actually can be different and serve their respective purposes for the inverse. So, my question is this:  why then don't we typically make a similar discrepancy on the input as we do on the output? (and yes, I believe some mathematical texts do make this distinction, but my question is why don't we typically make this distinction?)  Why don't we have two terms on the input side that are the conceptual counterparts of 'co-domain' vs 'image' on the output side?  Is this mere historical 'accident' and mostly a matter of 'well, we've always done things this way', or are there actual good practical reasons for this?",,"['functions', 'definition', 'math-history']"
46,Fractal fundamentals,Fractal fundamentals,,"I am a programmer by trade, and am very interested in fractals. To be very basic about the concept, one might say a 'circle of circles' is a fractal. Where each circle is made up of circles, and those circles are made of smaller circles and so on. This idea is similar to a Sierpinski triangle, which I interpret basically a triangle of triangles. To test my understanding, I decided to draw out this notion of a 'circle of circles'. Realize, I did this by hand with MS paint, copy and paste. I really should have just written out a simple program using some derivative of pi to get a perfect, mathematical display. In any case, this image is just to illustrate the concept. It's obviously not perfect, my question is: Is the notion of a 'circle of circles', 'triangle of triangles', or 'function of functions' truly the definition of a fractal? And, consequently, is the application of this notion, in this image, a fractal? (I realize it isn't because the alignment is incorrect.) Note: The coloring was just so I could see the pattern easier, lets assume there is no color. Though if the color had been also repeating, would this still prove true? I included another, expanding on the use of color:","I am a programmer by trade, and am very interested in fractals. To be very basic about the concept, one might say a 'circle of circles' is a fractal. Where each circle is made up of circles, and those circles are made of smaller circles and so on. This idea is similar to a Sierpinski triangle, which I interpret basically a triangle of triangles. To test my understanding, I decided to draw out this notion of a 'circle of circles'. Realize, I did this by hand with MS paint, copy and paste. I really should have just written out a simple program using some derivative of pi to get a perfect, mathematical display. In any case, this image is just to illustrate the concept. It's obviously not perfect, my question is: Is the notion of a 'circle of circles', 'triangle of triangles', or 'function of functions' truly the definition of a fractal? And, consequently, is the application of this notion, in this image, a fractal? (I realize it isn't because the alignment is incorrect.) Note: The coloring was just so I could see the pattern easier, lets assume there is no color. Though if the color had been also repeating, would this still prove true? I included another, expanding on the use of color:",,"['functions', 'recursion', 'fractals', 'cantor-set']"
47,Envelope of two sine waves interfering,Envelope of two sine waves interfering,,"I have two waves interfering with different amplitudes, frequencies and phases. $$ x(t) = X_1 \sin(\omega_1 t+\varphi_1) + X_2 \sin(\omega_2 t+\varphi_2) $$ I am able to convert this wave into the form $$ x(t) = A \cos(\delta t) \cos(\sigma t) + B \cos(\delta t) \sin(\sigma t) + C \sin(\delta t)\cos(\sigma t) + D \sin(\delta t)\sin(\sigma t) $$ with parameters $$ \begin{aligned}  \delta & = \frac{\omega_1-\omega_2}{2} &\sigma & = \frac{\omega_1+\omega_2}{2} \\ A & = X_1 \sin(\varphi_1)+X_2 \sin(\varphi_2) & B & =X_1 \cos(\varphi_1)+X_2 \cos(\varphi_2) \\ C & = X_1 \cos(\varphi_1)-X_2 \cos(\varphi_2) & D & = X_2 \sin(\varphi_2)-X_1 \sin(\varphi_1) \end{aligned} $$ What I am looking for is an expression of the envelope shape (see below) in terms of A,B,C,D,Ï,Î´ . Edit 1 The example above is from $$ x(t)=0.8 \sin(20 t+(-1)) + 0.2 \sin(21 t+0) $$ It seems like an approximation by I have a Wolfram Plot which indicates that the envelope is $$e(t) = X_1+X_2 \cos((\omega_1-\omega_2) t+(\varphi_1-\varphi_2))$$ I am curious if there is an analytical way to prove that this is good approximation.","I have two waves interfering with different amplitudes, frequencies and phases. $$ x(t) = X_1 \sin(\omega_1 t+\varphi_1) + X_2 \sin(\omega_2 t+\varphi_2) $$ I am able to convert this wave into the form $$ x(t) = A \cos(\delta t) \cos(\sigma t) + B \cos(\delta t) \sin(\sigma t) + C \sin(\delta t)\cos(\sigma t) + D \sin(\delta t)\sin(\sigma t) $$ with parameters $$ \begin{aligned}  \delta & = \frac{\omega_1-\omega_2}{2} &\sigma & = \frac{\omega_1+\omega_2}{2} \\ A & = X_1 \sin(\varphi_1)+X_2 \sin(\varphi_2) & B & =X_1 \cos(\varphi_1)+X_2 \cos(\varphi_2) \\ C & = X_1 \cos(\varphi_1)-X_2 \cos(\varphi_2) & D & = X_2 \sin(\varphi_2)-X_1 \sin(\varphi_1) \end{aligned} $$ What I am looking for is an expression of the envelope shape (see below) in terms of A,B,C,D,Ï,Î´ . Edit 1 The example above is from $$ x(t)=0.8 \sin(20 t+(-1)) + 0.2 \sin(21 t+0) $$ It seems like an approximation by I have a Wolfram Plot which indicates that the envelope is $$e(t) = X_1+X_2 \cos((\omega_1-\omega_2) t+(\varphi_1-\varphi_2))$$ I am curious if there is an analytical way to prove that this is good approximation.",,"['functions', 'trigonometry']"
48,Find Functions That Can Be Inverted from Their Sums,Find Functions That Can Be Inverted from Their Sums,,"I have the following situation:$$ 	f_1(x_1) + f_1(x_2) + f_1(x_3) + \cdots + f_1(x_n) = c_1\\ 	f_2(x_1) + f_2(x_2) + f_2(x_3) + \cdots + f_2(x_n) = c_2\\ 	\vdots\\ 	f_n(x_1) + f_n(x_2) + f_n(x_3) + \cdots + f_n(x_n) = c_n $$These formulae are evaluated at a particular vector $\vec{x}$, producing a vector $\vec{c}$ of constants.  Now, given this vector $\vec{c}$, I want to reconstruct the original $\vec{x}$. What $f_i$ s should I choose that will let me do this? There are two constraints: $f_i$ is bounded on $(0,1)$ and $\left[f_i(x_j)=0\right] \rightarrow \left[x_j \in \{0,1\}\right]$ (and $f_i(x_j)$ is $0$ in at least one point). There are, however, some simplifying assumptions.  Each $x_i \in [0,1]$ and $\left[x_i=x_j\right] \rightarrow \left[\left[i=j\right] \vee \left[f_k(x_i)=f_k(x_j)=0\right]\right]$.  Furthermore, the order of the components of $\vec{x}$ is irrelevant (that is, reconstructing any permutation of $\vec{x}$ is fine). A closed-form solution is ideal, but a numerical solution scaling gracefully with $n$ is acceptable too.  Partial solutions for $n \geq 4$ will be accepted if there is no general approach. I have tried a number of things, but my best attempt so far is the rather basic:$$ 	f_i(x_j) := x_j^{i} $$So that we have:$$ 	f_1(x_j) := x_j^1\\ 	f_2(x_j) := x_j^2\\ 	\vdots\\ 	f_n(x_j) := x_j^n $$Viewed this way, each equation represents an $n$-dimensional superquadric .  For $n=2$, a closed form exists (intersection of line with circle quadrant).  For $n=3$, I used multidimensional Newton iteration .  However, for $n=4$, the solver fails to converge (or at least has numerical issues). The question again: What is a good choice of $f_i$ such that I can reconstruct $\vec{x}$ given $\vec{c}$?","I have the following situation:$$ 	f_1(x_1) + f_1(x_2) + f_1(x_3) + \cdots + f_1(x_n) = c_1\\ 	f_2(x_1) + f_2(x_2) + f_2(x_3) + \cdots + f_2(x_n) = c_2\\ 	\vdots\\ 	f_n(x_1) + f_n(x_2) + f_n(x_3) + \cdots + f_n(x_n) = c_n $$These formulae are evaluated at a particular vector $\vec{x}$, producing a vector $\vec{c}$ of constants.  Now, given this vector $\vec{c}$, I want to reconstruct the original $\vec{x}$. What $f_i$ s should I choose that will let me do this? There are two constraints: $f_i$ is bounded on $(0,1)$ and $\left[f_i(x_j)=0\right] \rightarrow \left[x_j \in \{0,1\}\right]$ (and $f_i(x_j)$ is $0$ in at least one point). There are, however, some simplifying assumptions.  Each $x_i \in [0,1]$ and $\left[x_i=x_j\right] \rightarrow \left[\left[i=j\right] \vee \left[f_k(x_i)=f_k(x_j)=0\right]\right]$.  Furthermore, the order of the components of $\vec{x}$ is irrelevant (that is, reconstructing any permutation of $\vec{x}$ is fine). A closed-form solution is ideal, but a numerical solution scaling gracefully with $n$ is acceptable too.  Partial solutions for $n \geq 4$ will be accepted if there is no general approach. I have tried a number of things, but my best attempt so far is the rather basic:$$ 	f_i(x_j) := x_j^{i} $$So that we have:$$ 	f_1(x_j) := x_j^1\\ 	f_2(x_j) := x_j^2\\ 	\vdots\\ 	f_n(x_j) := x_j^n $$Viewed this way, each equation represents an $n$-dimensional superquadric .  For $n=2$, a closed form exists (intersection of line with circle quadrant).  For $n=3$, I used multidimensional Newton iteration .  However, for $n=4$, the solver fails to converge (or at least has numerical issues). The question again: What is a good choice of $f_i$ such that I can reconstruct $\vec{x}$ given $\vec{c}$?",,"['functions', 'summation', 'inverse']"
49,Graphing a Piecewise Function,Graphing a Piecewise Function,,I graphed this function below. I want to make sure I am graphing piecewise functions such as this one correctly.,I graphed this function below. I want to make sure I am graphing piecewise functions such as this one correctly.,,"['functions', 'graphing-functions', 'piecewise-continuity']"
50,Multitangent to a polynomial function,Multitangent to a polynomial function,,"I'm trying to build some exercises on tangents of functions for beginner students in mathematical analysis. In particular I would like to suggest the study of polynomial functions  $ y = p (x) $ of which is possible to determine the graph with elementary methods and also determine (if it exists) the  $n$-tangent, i.e. a straight line $ y = mx + q $ (with $ m \ne 0$  to avoid trivial solutions) which has $ n $ distinct points of tangency with the graph and no other intersection points with it, so that the system $$ \begin{cases} y=p(x)\\ y=mx+q \end{cases} $$  has $n$ double solutions. For bi-tangents I find, for example, functions of the form: $$ y= a(x^4-3k^2x^2+2k^3x) $$ that have as bi-tangents the straight lines  $$ y=2ak^3x-\dfrac{9}{4}ak^3 $$ or: $$ y=a\left( \dfrac{1}{4}x^4 -\dfrac{3k}{2}x^3+\dfrac{9k^2}{4}x^2-k^3x\right) $$ with bi-tangents  $y=ak^3x$. I cannot, however, find an example with a $ 3 $ -tangent, i.e. a polynomial of sixth degree $ y = p (x) $ such that $ p (x) $ and $ p '(x) $ are decomposable (more or less easily) in factors of degree  $n \le 2$, and that at the same time has a $3$-tangent such that hits points of tangency can be determined without using  the general formula to solve a cubic equation. Someone knows any function of this type, or may suggest an efficient way to find it? In other words: find a function: $$ y=a_6x^6+a_5x^5+a_4x^4+a_3x^3+a_2x^2+a_1x+a_0 $$ such that $ y $ and $y'$ are factorizable with factors of degree $n \le 2$ and there exist $m,q \in \mathbb{R}$ (or better $\in \mathbb{Q}$) such that $$ a_6x^6+a_5x^5+a_4x^4+a_3x^3+a_2x^2+(a_1-m)x+a_0-q  =a_6\left( x^3+Bx^2+Cx+D\right)^2 $$  and the latter $3^{rd}$ degree polynomial is also factorizable. Added after the Answer. The answer of Michael Burr don't fit the request  that $f(x)$ and $fâ²(x)$ has roots that we can find solving equations of degree $\le 2$. Here I sum up and a bit generalize the problem: Let $f(x) \in \mathbb{R}[x]$ be a polynomial of degree $2n > 4$ and $f'(x) $ its derivative. I want determine the coefficients of $f(x)$ in such a way that: all the real roots of $f(x)$ and $f'(x)$ can be found solving equations of degree $\le 2$, and there are $m,q \in \mathbb{R}$ such that the polynomial $g(x)=f(x)+mx+q$ has $n$ double roots. Or proof that such a polynomial can not exists.","I'm trying to build some exercises on tangents of functions for beginner students in mathematical analysis. In particular I would like to suggest the study of polynomial functions  $ y = p (x) $ of which is possible to determine the graph with elementary methods and also determine (if it exists) the  $n$-tangent, i.e. a straight line $ y = mx + q $ (with $ m \ne 0$  to avoid trivial solutions) which has $ n $ distinct points of tangency with the graph and no other intersection points with it, so that the system $$ \begin{cases} y=p(x)\\ y=mx+q \end{cases} $$  has $n$ double solutions. For bi-tangents I find, for example, functions of the form: $$ y= a(x^4-3k^2x^2+2k^3x) $$ that have as bi-tangents the straight lines  $$ y=2ak^3x-\dfrac{9}{4}ak^3 $$ or: $$ y=a\left( \dfrac{1}{4}x^4 -\dfrac{3k}{2}x^3+\dfrac{9k^2}{4}x^2-k^3x\right) $$ with bi-tangents  $y=ak^3x$. I cannot, however, find an example with a $ 3 $ -tangent, i.e. a polynomial of sixth degree $ y = p (x) $ such that $ p (x) $ and $ p '(x) $ are decomposable (more or less easily) in factors of degree  $n \le 2$, and that at the same time has a $3$-tangent such that hits points of tangency can be determined without using  the general formula to solve a cubic equation. Someone knows any function of this type, or may suggest an efficient way to find it? In other words: find a function: $$ y=a_6x^6+a_5x^5+a_4x^4+a_3x^3+a_2x^2+a_1x+a_0 $$ such that $ y $ and $y'$ are factorizable with factors of degree $n \le 2$ and there exist $m,q \in \mathbb{R}$ (or better $\in \mathbb{Q}$) such that $$ a_6x^6+a_5x^5+a_4x^4+a_3x^3+a_2x^2+(a_1-m)x+a_0-q  =a_6\left( x^3+Bx^2+Cx+D\right)^2 $$  and the latter $3^{rd}$ degree polynomial is also factorizable. Added after the Answer. The answer of Michael Burr don't fit the request  that $f(x)$ and $fâ²(x)$ has roots that we can find solving equations of degree $\le 2$. Here I sum up and a bit generalize the problem: Let $f(x) \in \mathbb{R}[x]$ be a polynomial of degree $2n > 4$ and $f'(x) $ its derivative. I want determine the coefficients of $f(x)$ in such a way that: all the real roots of $f(x)$ and $f'(x)$ can be found solving equations of degree $\le 2$, and there are $m,q \in \mathbb{R}$ such that the polynomial $g(x)=f(x)+mx+q$ has $n$ double roots. Or proof that such a polynomial can not exists.",,"['real-analysis', 'functions', 'derivatives', 'polynomials']"
51,Why can't we generalize straight line equations for all curves?,Why can't we generalize straight line equations for all curves?,,"Apologies, but I'm confused. Let $y = f(x)$ be curve such that at a point $(a,b)$ lying on it, the slope of the tangent kissing that point is $f'(x)$ Now, the equation of the tangent passing through $(a,b)$ is found using the point-slope equation: $$y - b = f'(x)(x-a)$$ But this would be the same equation I would get if I were asked to substitute the point and slope to find the equation of the curve. Now, I know that the point slope form is for straight lines but I think this should be extendable to any curve because all curves just have variable slopes. Maybe this is stupid and may not work. Could someone tell me why this is so? Here's a demonstration of the point slope not yielding back the curve: $$y=2(xâ5)^2 +5 \stackrel{\frac{\mathrm d}{\mathrm dx}\text{ing}}{\implies} y' = 4(x-5)$$ It can clearly be seen that the point $(5,5)$ satisfies the given curve. So, using point-slope: $$ y - 5 = y'(x - 5) \implies y = 4(xâ5)^2 +5$$ From this example it is observed that using that the straight line equation does not yield back the curve. My only conclusion is that this is the equation of the tangent passing through $(5,5)$ Please correct where my thinking has gone wrong.","Apologies, but I'm confused. Let $y = f(x)$ be curve such that at a point $(a,b)$ lying on it, the slope of the tangent kissing that point is $f'(x)$ Now, the equation of the tangent passing through $(a,b)$ is found using the point-slope equation: $$y - b = f'(x)(x-a)$$ But this would be the same equation I would get if I were asked to substitute the point and slope to find the equation of the curve. Now, I know that the point slope form is for straight lines but I think this should be extendable to any curve because all curves just have variable slopes. Maybe this is stupid and may not work. Could someone tell me why this is so? Here's a demonstration of the point slope not yielding back the curve: $$y=2(xâ5)^2 +5 \stackrel{\frac{\mathrm d}{\mathrm dx}\text{ing}}{\implies} y' = 4(x-5)$$ It can clearly be seen that the point $(5,5)$ satisfies the given curve. So, using point-slope: $$ y - 5 = y'(x - 5) \implies y = 4(xâ5)^2 +5$$ From this example it is observed that using that the straight line equation does not yield back the curve. My only conclusion is that this is the equation of the tangent passing through $(5,5)$ Please correct where my thinking has gone wrong.",,"['calculus', 'functions']"
52,What is the order of operations in trig functions? [duplicate],What is the order of operations in trig functions? [duplicate],,"This question already has answers here : What are the meanings of $\operatorname{trig}(x)^n$ and $\operatorname{trig}^n(x)$? (4 answers) Closed last year . Is $\sin(x)^2$ the same as $\sin^2(x)$ or $\sin(x^2)$? I thought it would mean the former interpretation, $\sin^2(x)$, rather than the latter, but my teacher and I had a long argument on this and in the end I found that Casio calculators have a space between before the parenthesis, so it would look like $\sin\text{ }(x)^2$ and what the calculator would do is calculate $x^2$, and then take the $\sin$ of that whereas on Texas calculators, there is no space, so it would look like $\sin(x)^2$ and it will calculate $\sin$ of $x$ first, and then take the result and square it.","This question already has answers here : What are the meanings of $\operatorname{trig}(x)^n$ and $\operatorname{trig}^n(x)$? (4 answers) Closed last year . Is $\sin(x)^2$ the same as $\sin^2(x)$ or $\sin(x^2)$? I thought it would mean the former interpretation, $\sin^2(x)$, rather than the latter, but my teacher and I had a long argument on this and in the end I found that Casio calculators have a space between before the parenthesis, so it would look like $\sin\text{ }(x)^2$ and what the calculator would do is calculate $x^2$, and then take the $\sin$ of that whereas on Texas calculators, there is no space, so it would look like $\sin(x)^2$ and it will calculate $\sin$ of $x$ first, and then take the result and square it.",,"['functions', 'trigonometry']"
53,"Inverse of $f(x)=x^n+x$ on $[0,\infty)$",Inverse of  on,"f(x)=x^n+x [0,\infty)","Fix integer $n > 1$. The function $f_n(x) = x^n + x$ is monotone increasing on $[0,\infty)$, and so has an inverse $f_n^{-1}(x)$ that is also monotone increasing on $[0,\infty)$. I'm interested in properties of $f_n^{-1}(x)$ (in particular, in its Taylor series). I'm sure that it's a well-studied function (or rather, family of functions), but I can't find any literature on it, mostly because I don't know what keywords to use. Does anyone know a name for this function?","Fix integer $n > 1$. The function $f_n(x) = x^n + x$ is monotone increasing on $[0,\infty)$, and so has an inverse $f_n^{-1}(x)$ that is also monotone increasing on $[0,\infty)$. I'm interested in properties of $f_n^{-1}(x)$ (in particular, in its Taylor series). I'm sure that it's a well-studied function (or rather, family of functions), but I can't find any literature on it, mostly because I don't know what keywords to use. Does anyone know a name for this function?",,"['real-analysis', 'functions']"
54,How is called the class of functions whose inverse function is a polynomial?,How is called the class of functions whose inverse function is a polynomial?,,How is called the class of functions whose inverse function is a polynomial? Is there any study of such functions?,How is called the class of functions whose inverse function is a polynomial? Is there any study of such functions?,,"['functions', 'polynomials']"
55,"For bijection $f:A \rightarrow B$, prove that $f^{-1} \circ f = {\text {id}}_{A}$","For bijection , prove that",f:A \rightarrow B f^{-1} \circ f = {\text {id}}_{A},"I have to prove that for a bijection $f:A \rightarrow B$, $f^{-1} \circ  f = {\text {id}}_{A}$, where ${\text {id}_A}$ is the identity function of $A$, and we define $f^{-1}: B \rightarrow A$ by $f^{-1}(b) = a$ if $f(a)=b$. This definition is given by the homework prompt, so I think it's safe to assume it. Here is my work: For $a \in A$ and $b \in B$, we have defined that if $f(a)=b$, then $f^{-1}(b)=a$, so $f^{-1}(f(a))=a$, so $f^{-1} \circ f:A\rightarrow A$. We know ${\text{id}}_A:A\rightarrow A$ is the bijective function s.t. $\forall a \in A,  {\text{id}}(a)=a$. As the domains of the functions are equal and $\forall a \in A, (f^{-1}\circ f)(a) = {\text {id}}_{A}(a)$, the two functions are equal. Can someone please confirm whether it is sufficiently rigorous, or if not, suggest any improvements?","I have to prove that for a bijection $f:A \rightarrow B$, $f^{-1} \circ  f = {\text {id}}_{A}$, where ${\text {id}_A}$ is the identity function of $A$, and we define $f^{-1}: B \rightarrow A$ by $f^{-1}(b) = a$ if $f(a)=b$. This definition is given by the homework prompt, so I think it's safe to assume it. Here is my work: For $a \in A$ and $b \in B$, we have defined that if $f(a)=b$, then $f^{-1}(b)=a$, so $f^{-1}(f(a))=a$, so $f^{-1} \circ f:A\rightarrow A$. We know ${\text{id}}_A:A\rightarrow A$ is the bijective function s.t. $\forall a \in A,  {\text{id}}(a)=a$. As the domains of the functions are equal and $\forall a \in A, (f^{-1}\circ f)(a) = {\text {id}}_{A}(a)$, the two functions are equal. Can someone please confirm whether it is sufficiently rigorous, or if not, suggest any improvements?",,"['elementary-set-theory', 'functions', 'proof-writing', 'proof-verification']"
56,"Sets, functions and relations problem","Sets, functions and relations problem",,"Yes this is a homework problem but I have attempted to solve it and my work is below, also this is my first question here so I'm sorry for any mistakes: Question: Context: Let $A$ and $B$ be subsets of $\Bbb{Z}$, and let $F = \{f : A\to B\}$. Define a relation $R$ on $F$ by: for any $f,g\in F$, $fRg$ if and only if $f - g$ is a constant function; that is, there is a constant $c$ so that $f(x) - g(x) = c$ for all $x\in A$. Assume that $A=\{1,2,3\}$ and $B=\{1,2,\ldots,n\}$ where $n \geq 2$ is a fixed integer Actual question: Prove that for all $g,h \in F$ so that $gRh$, if there exists $a,b \in A$ so that $g(a) = 1$ and $h(b) = 1$ then $g = h$. Attempted solution: By definition $g(x) - h(x) = c$, from which we can write that $g(a) - h(a) = c$ and $g(b) - h(b) = c$. Now if we plug in the initial values: $1 - h(a) = c$ and $g(b) - 1 = c$. Next I equated them: $1 - h(a) = g(b) - 1$. And this is where I'm stuck, I know that in order for that to be true: $c = 0$, but I know that starting a proof with what I want to prove is incorrect so I can't use that in my reasoning. And where I am right now seems a bit useless for me... I'm not asking for answers, any insight will be helpful, thank you! Thanks! (And sorry if I made it complicated :-/","Yes this is a homework problem but I have attempted to solve it and my work is below, also this is my first question here so I'm sorry for any mistakes: Question: Context: Let $A$ and $B$ be subsets of $\Bbb{Z}$, and let $F = \{f : A\to B\}$. Define a relation $R$ on $F$ by: for any $f,g\in F$, $fRg$ if and only if $f - g$ is a constant function; that is, there is a constant $c$ so that $f(x) - g(x) = c$ for all $x\in A$. Assume that $A=\{1,2,3\}$ and $B=\{1,2,\ldots,n\}$ where $n \geq 2$ is a fixed integer Actual question: Prove that for all $g,h \in F$ so that $gRh$, if there exists $a,b \in A$ so that $g(a) = 1$ and $h(b) = 1$ then $g = h$. Attempted solution: By definition $g(x) - h(x) = c$, from which we can write that $g(a) - h(a) = c$ and $g(b) - h(b) = c$. Now if we plug in the initial values: $1 - h(a) = c$ and $g(b) - 1 = c$. Next I equated them: $1 - h(a) = g(b) - 1$. And this is where I'm stuck, I know that in order for that to be true: $c = 0$, but I know that starting a proof with what I want to prove is incorrect so I can't use that in my reasoning. And where I am right now seems a bit useless for me... I'm not asking for answers, any insight will be helpful, thank you! Thanks! (And sorry if I made it complicated :-/",,"['functions', 'relations', 'equivalence-relations']"
57,What is this function called (looks like a variant of the exponential function),What is this function called (looks like a variant of the exponential function),,"We set (as usual) $\displaystyle{x \choose k} := \frac{x \cdot (x-1) \cdots (x-k+1)}{k!}$ for $x\in \mathbb{C}$. Now we can define a function $\displaystyle f(x) := \sum\limits_{k=0}^\infty {x \choose k}$. Does anybody know how this function is called (I need its name, so that I can get more information about it)? I believe, it should be well-known, but I don't know its name. Note that if we defined $\displaystyle{x \choose k} := \frac{x^k}{k!}$ instead, we would simply get the $\exp$ function - so my function is probably be related to it.","We set (as usual) $\displaystyle{x \choose k} := \frac{x \cdot (x-1) \cdots (x-k+1)}{k!}$ for $x\in \mathbb{C}$. Now we can define a function $\displaystyle f(x) := \sum\limits_{k=0}^\infty {x \choose k}$. Does anybody know how this function is called (I need its name, so that I can get more information about it)? I believe, it should be well-known, but I don't know its name. Note that if we defined $\displaystyle{x \choose k} := \frac{x^k}{k!}$ instead, we would simply get the $\exp$ function - so my function is probably be related to it.",,['functions']
58,Does this property of a function $f : 2^A \rightarrow A$ have a name?,Does this property of a function  have a name?,f : 2^A \rightarrow A,"I've got this property: For all $S\in 2^A$ and all partitions $P$ of $S$ , $f(S) = f\left(\left\{f(M)\mid M \in P\right\}\right)$ , i.e. $f$ maps a set of values to a single value and gives the same result whether we map the set ""at once"" or whether we map subsets first and then map the set of the results. Examples for $f$ would be sums of finite sets of numbers, or the least upper bound of subsets of a complete lattice. So, if $A = \mathbb{N}\cup\left\{\infty\right\}$ and $f(S) = \sum_{s \in S} s$ , the property is fulfilled, as, for example $f(\{1,2,3\}) = f(\{f(\{1,2\}),f(\{3\})\}) = 3+3 = 6$ Is that a well-known property? If so, what's it called so I can read up more on it?","I've got this property: For all and all partitions of , , i.e. maps a set of values to a single value and gives the same result whether we map the set ""at once"" or whether we map subsets first and then map the set of the results. Examples for would be sums of finite sets of numbers, or the least upper bound of subsets of a complete lattice. So, if and , the property is fulfilled, as, for example Is that a well-known property? If so, what's it called so I can read up more on it?","S\in 2^A P S f(S) = f\left(\left\{f(M)\mid M \in P\right\}\right) f f A = \mathbb{N}\cup\left\{\infty\right\} f(S) = \sum_{s \in S} s f(\{1,2,3\}) = f(\{f(\{1,2\}),f(\{3\})\}) = 3+3 = 6","['functions', 'elementary-set-theory']"
59,Does the functional equation $f(x)-f\left(x-\frac{x^2}3\right)=\frac{x}{3-x}-\log\left(\frac3{3-x}\right)$ define an analytic function?,Does the functional equation  define an analytic function?,f(x)-f\left(x-\frac{x^2}3\right)=\frac{x}{3-x}-\log\left(\frac3{3-x}\right),"When trying to solve functional equation $$f(x)-f\left(x-\frac{x^2}3\right)=\frac{x}{3-x}-\log\left(\frac3{3-x}\right)\,,$$ by assuming that $\displaystyle f(x)=\sum_{k=1}^{\infty}a_k x^k$ , we could get equations: $$\sum_{s=1}^{\lfloor\frac k2\rfloor}{k-s \choose s}(-1)^{s-1}3^{k-s} a_{k-s}=\frac{k-1}{k}\,,$$ so that we could get $$\begin{matrix} f(t)&=\frac t6+\frac{t^2}{27}+\frac{13t^3}{972}+\frac{113t^4}{19440}+\frac{1187t^5}{437400}\\&+\frac{877t^6}{688905}+\frac{14569t^7}{25719120}+\frac{176017t^8}{793618560}+\frac{1745717t^9}{26784626400}\\&+\frac{88217t^{10}}{15345358875}-\frac{147635381t^{11}}{19445638766400}-\frac{3238110769t^{12}}{827323540243200}\\&+\frac{63045343657t^{13}}{37643221081065600}+\frac{24855467017t^{14}}{7125970336860375}+O(t^{15})\end{matrix}$$ I have thought that the coefficients of the expansion above is bounded so that $f(t)$ is an analytic function. But after computing more terms, we could find the absolute value of coefficients increase rapidly after around $50$ terms, such as term $51$ to $60$ is around: $$[78.513621003297250420074188707102682220, 202.58713829274578879553773336619242812, -449.99520262010819218204869756666128052, -1873.4863539770463771221218334858172231, 2366.9955239364074357260471634171465472, 17249.065560767631956266214434624779288, -8940.7592181048466843451670448875449069, -160960.78661872319570785726231645359908, -24829.450164495412949086768442609647625, 1533556.2377505922967945825482291368540]$$ So it seems the expansion above only provides an approximation of $f(x)$ like Stirling's approximation. So, my question is: Does the expansion above really defines an analytic function? Or does it really accurately defines a function? Let $v(x)=\frac{3x^2}{3x-1}, v_1(x)=v(x), v_{k+1}(x)=v(v_k(x))$ We could prove that $c(x)=\lim_{n\to\infty}\left(3v_n(x)-n-\log(n)\right)$ exists for all x large enough. It is easy to show that $c(v(x))=c(x)+1$ . So $c'(v(x))v'(x)=c'(x)$ and $c'(v_{n+1}(x))v'(v_n(x))=c'(v_n(x))$ so that $c'(x)=c'(v_{n+1}(x))\prod_{k=0}^{n}v'(v_k(x))$ Since $v_n(x)=\frac n3+\frac{\log(n)}3 +\frac{c(x)}3 +o(1)$ and $v'(x)=1+O(\frac1{x^2})$ , we could get $\lim_{n\to\infty}c'(v_{n+1}(x))=1$ and $c'(x)=\prod_{k=0}^{\infty}v'(v_k(x))$ uniformly converges and it likely converged to an analytic function. Finally we could prove that $c(x)=3x-\log(x)+f(\frac1x)$ so that f(x) should be analytic function too.","When trying to solve functional equation by assuming that , we could get equations: so that we could get I have thought that the coefficients of the expansion above is bounded so that is an analytic function. But after computing more terms, we could find the absolute value of coefficients increase rapidly after around terms, such as term to is around: So it seems the expansion above only provides an approximation of like Stirling's approximation. So, my question is: Does the expansion above really defines an analytic function? Or does it really accurately defines a function? Let We could prove that exists for all x large enough. It is easy to show that . So and so that Since and , we could get and uniformly converges and it likely converged to an analytic function. Finally we could prove that so that f(x) should be analytic function too.","f(x)-f\left(x-\frac{x^2}3\right)=\frac{x}{3-x}-\log\left(\frac3{3-x}\right)\,, \displaystyle f(x)=\sum_{k=1}^{\infty}a_k x^k \sum_{s=1}^{\lfloor\frac k2\rfloor}{k-s \choose s}(-1)^{s-1}3^{k-s} a_{k-s}=\frac{k-1}{k}\,, \begin{matrix} f(t)&=\frac t6+\frac{t^2}{27}+\frac{13t^3}{972}+\frac{113t^4}{19440}+\frac{1187t^5}{437400}\\&+\frac{877t^6}{688905}+\frac{14569t^7}{25719120}+\frac{176017t^8}{793618560}+\frac{1745717t^9}{26784626400}\\&+\frac{88217t^{10}}{15345358875}-\frac{147635381t^{11}}{19445638766400}-\frac{3238110769t^{12}}{827323540243200}\\&+\frac{63045343657t^{13}}{37643221081065600}+\frac{24855467017t^{14}}{7125970336860375}+O(t^{15})\end{matrix} f(t) 50 51 60 [78.513621003297250420074188707102682220, 202.58713829274578879553773336619242812, -449.99520262010819218204869756666128052, -1873.4863539770463771221218334858172231, 2366.9955239364074357260471634171465472, 17249.065560767631956266214434624779288, -8940.7592181048466843451670448875449069, -160960.78661872319570785726231645359908, -24829.450164495412949086768442609647625, 1533556.2377505922967945825482291368540] f(x) v(x)=\frac{3x^2}{3x-1}, v_1(x)=v(x), v_{k+1}(x)=v(v_k(x)) c(x)=\lim_{n\to\infty}\left(3v_n(x)-n-\log(n)\right) c(v(x))=c(x)+1 c'(v(x))v'(x)=c'(x) c'(v_{n+1}(x))v'(v_n(x))=c'(v_n(x)) c'(x)=c'(v_{n+1}(x))\prod_{k=0}^{n}v'(v_k(x)) v_n(x)=\frac n3+\frac{\log(n)}3 +\frac{c(x)}3 +o(1) v'(x)=1+O(\frac1{x^2}) \lim_{n\to\infty}c'(v_{n+1}(x))=1 c'(x)=\prod_{k=0}^{\infty}v'(v_k(x)) c(x)=3x-\log(x)+f(\frac1x)","['real-analysis', 'functions']"
60,Putnam 1988 - Exercise A.5 - Generalization and solution verification,Putnam 1988 - Exercise A.5 - Generalization and solution verification,,"I tried to generalize the question given in 1988 Putnam competition, A.5, as follows: Prove that, for all real positive $\alpha$ , there exists a unique function $f$ from the set $\mathbb{R}^+$ of positive real numbers to $\mathbb{R}^+$ such that $$f(f(x)) = \alpha x-f(x) \tag{1}\label{1}.$$ My proof is as follows. For any positive $\alpha$ we have a linear solution given by $f(x) = kx,$ with $$k=-\frac12 + \frac{\sqrt{1+4\alpha}}2>0.$$ Suppose there is another solution $g(x)$ such that, for some $a_0>0$ , $g(a_0) < ka_0$ , i.e., $g(a_0) = (k-\varepsilon_0) a_0,$ with $0 < \varepsilon_0 < k$ . Two iterations of \eqref{1} (recalling that $\alpha =k^2+k$ ) yield \begin{eqnarray} g(g(g(a_0))) &=& g((k^2+\varepsilon_0)a_0) = g(a_1) =\\ &=&k(k+1)(k-\varepsilon_0)a_0 -(k^2+\varepsilon_0)a_0 =\\ &=&\left(k-\frac{k^2+2k+1}{k^2+\varepsilon_0}\varepsilon_0\right)a_1=\\ &=&(k-\varepsilon_1) a_1. \end{eqnarray} Since $\varepsilon_0 < k< 2k$ , we have that $$\varepsilon_1>\left(1+\frac{1}{k^2+k}\right)\varepsilon_0.$$ If $\varepsilon_1 > k$ we have found a contradiction, because $g(a_1) < 0$ . Otherwise we can proceed further with the iterations, and generate $$\varepsilon_n >\left(1+\frac{1}{k^2+k}\right) \varepsilon_{n-1}> \cdots > \left(1+\frac{1}{k^2+k}\right)^n \varepsilon_0.$$ Since $\lim_{n\to \infty}\varepsilon_n = +\infty$ , for $n$ large enough we obtain $g(a_n) < 0$ . If, on the other hand, we find a $g(x)$ such that, for some $a_0$ , we get $g(a_0) > ka_0$ , that is $g(a_0) = (k+\varepsilon_0) a_0$ for some $\varepsilon_0>0$ , then one iteration of \eqref{1} gives \begin{eqnarray} g(g(a_0)) &=& g((k+\varepsilon_0)a_0)= g(a_1)=\\ &=&k(k+1)a_0 - (k+\varepsilon_0)a_0 =\\ &=&\frac{k^2-\varepsilon_0}{k+\varepsilon_0}a_1=\\ &=&\left(k-\frac{k+1}{k+\varepsilon_0}\varepsilon_0\right)a_1<ka_1. \end{eqnarray} And therefore we can again proceed as in the first case shown above. $\blacksquare$ Can you check if The problem statement is true, and if my solution is valid?","I tried to generalize the question given in 1988 Putnam competition, A.5, as follows: Prove that, for all real positive , there exists a unique function from the set of positive real numbers to such that My proof is as follows. For any positive we have a linear solution given by with Suppose there is another solution such that, for some , , i.e., with . Two iterations of \eqref{1} (recalling that ) yield Since , we have that If we have found a contradiction, because . Otherwise we can proceed further with the iterations, and generate Since , for large enough we obtain . If, on the other hand, we find a such that, for some , we get , that is for some , then one iteration of \eqref{1} gives And therefore we can again proceed as in the first case shown above. Can you check if The problem statement is true, and if my solution is valid?","\alpha f \mathbb{R}^+ \mathbb{R}^+ f(f(x)) = \alpha x-f(x) \tag{1}\label{1}. \alpha f(x) = kx, k=-\frac12 + \frac{\sqrt{1+4\alpha}}2>0. g(x) a_0>0 g(a_0) < ka_0 g(a_0) = (k-\varepsilon_0) a_0, 0 < \varepsilon_0 < k \alpha =k^2+k \begin{eqnarray}
g(g(g(a_0))) &=& g((k^2+\varepsilon_0)a_0) = g(a_1) =\\
&=&k(k+1)(k-\varepsilon_0)a_0 -(k^2+\varepsilon_0)a_0 =\\
&=&\left(k-\frac{k^2+2k+1}{k^2+\varepsilon_0}\varepsilon_0\right)a_1=\\
&=&(k-\varepsilon_1) a_1.
\end{eqnarray} \varepsilon_0 < k< 2k \varepsilon_1>\left(1+\frac{1}{k^2+k}\right)\varepsilon_0. \varepsilon_1 > k g(a_1) < 0 \varepsilon_n >\left(1+\frac{1}{k^2+k}\right) \varepsilon_{n-1}> \cdots > \left(1+\frac{1}{k^2+k}\right)^n \varepsilon_0. \lim_{n\to \infty}\varepsilon_n = +\infty n g(a_n) < 0 g(x) a_0 g(a_0) > ka_0 g(a_0) = (k+\varepsilon_0) a_0 \varepsilon_0>0 \begin{eqnarray}
g(g(a_0)) &=& g((k+\varepsilon_0)a_0)= g(a_1)=\\
&=&k(k+1)a_0 - (k+\varepsilon_0)a_0 =\\
&=&\frac{k^2-\varepsilon_0}{k+\varepsilon_0}a_1=\\
&=&\left(k-\frac{k+1}{k+\varepsilon_0}\varepsilon_0\right)a_1<ka_1.
\end{eqnarray} \blacksquare","['real-analysis', 'functions', 'solution-verification', 'contest-math']"
61,"Do these mathematical functions have a name? $f(x)=x^x$, $f(x, a)=x^{ax}$, $f(x,a,b)=x^{ax+b}$, $f(x,a,b,c)=x^{ax^2+bx+c}$","Do these mathematical functions have a name? , , ,","f(x)=x^x f(x, a)=x^{ax} f(x,a,b)=x^{ax+b} f(x,a,b,c)=x^{ax^2+bx+c}","When I run into algebraic patterns in my engineering / physics modeling multiple times, I usually go see what the smart mathematicians have learned about that, and often discover something useful that improves my modeling.  For example, the $w e^w$ patternâ¦ once you realize thatâs the âLambert Wâ function, then you learn all kinds of very useful stuff. However, my searches for this pattern havenât turned up anything.  Maybe it's not really a common pattern.  So, I figured this group would know one way or the otherâ¦ do any of these functions (or generalizations) have names: $$\begin{align} f(x) &= x^x \\ f(x, a) &= x^{a x} \\ f(x, a, b) &= x^{a x + b} \\ f(x, a, b, c) &= x^{a x^2 + b x + c} \\  &= x^{\operatorname{quadratic}(x, a, b, c)} \end{align}$$ If not, if you were a mathematician capturing the properties of these, what would you name these?  (What search terms might turn up properties and/or typical uses?) (Or if you were providing some optimized code to compute these in your modeling, what would you name these?)","When I run into algebraic patterns in my engineering / physics modeling multiple times, I usually go see what the smart mathematicians have learned about that, and often discover something useful that improves my modeling.  For example, the patternâ¦ once you realize thatâs the âLambert Wâ function, then you learn all kinds of very useful stuff. However, my searches for this pattern havenât turned up anything.  Maybe it's not really a common pattern.  So, I figured this group would know one way or the otherâ¦ do any of these functions (or generalizations) have names: If not, if you were a mathematician capturing the properties of these, what would you name these?  (What search terms might turn up properties and/or typical uses?) (Or if you were providing some optimized code to compute these in your modeling, what would you name these?)","w e^w \begin{align}
f(x) &= x^x \\
f(x, a) &= x^{a x} \\
f(x, a, b) &= x^{a x + b} \\
f(x, a, b, c) &= x^{a x^2 + b x + c} \\ 
&= x^{\operatorname{quadratic}(x, a, b, c)}
\end{align}","['functions', 'special-functions']"
62,"Continuous and differentiable function $f(x)$ in $(x_1, x_2)$.",Continuous and differentiable function  in .,"f(x) (x_1, x_2)","Consider the continuous and differentiable function $f(x)$ in $[x_1, x_2]$ . Let $f'(x)$ be its derivative and $f'(x_2) = 0$ Show that there exist a number $c >0$ and a $x_3 \in (x_1, x_2)$ such that $f'(x_3) = c(f(x_3)-f(x_1))$ . Apologies but I haven't touched calculus for more than 20 years. One of the few things I remember is that when the 1st derivative is zero, we have a local minimum or maximum. (I am not a student or anything).","Consider the continuous and differentiable function in . Let be its derivative and Show that there exist a number and a such that . Apologies but I haven't touched calculus for more than 20 years. One of the few things I remember is that when the 1st derivative is zero, we have a local minimum or maximum. (I am not a student or anything).","f(x) [x_1, x_2] f'(x) f'(x_2) = 0 c >0 x_3 \in (x_1, x_2) f'(x_3) = c(f(x_3)-f(x_1))","['calculus', 'functions']"
63,Spivak's Calculus: Chapter 3 Problem 24b,Spivak's Calculus: Chapter 3 Problem 24b,,"24b) Suppose that $f$ is a function such that every number $b$ can be written $b = f(a)$ for some real number $a$ . Prove that there is a function $g$ such that $f \circ g = I$ I think I do understand this question and how to solve it, but I'm struggling to find a way to express my solution in a mathematically rigorous way, particularly when $f$ is not injective. Here's my idea: First of all, if $f$ is injective, then it's trivial. Let $g(x) = a$ , where $x = f(a)$ for any $a \in \text{domain}(f)$ Since $f$ is injective, by definition there is only one value of $a$ that satisfies $x = f(a)$ for each $x$ , which means $g$ is well defined. And $\text{domain}(g) = \text{image}(f)$ (by definition of $g$ ), which from the supposition in the question is $\mathbb{R}$ . Also, $\text{domain}(f) = \text{image}(g)$ , since $f$ and $g$ are injective (but that fact is not important). So $f(g(x))$ is defined for all $x â \mathbb{R}$ . Finally, $f(g(x))$ = $f(a)$ , where $x = f(a)$ for $x â \mathbb{R} \to f(g(x)) = I(x)$ . But now if $f$ is not injective, it gets more complicated. If I keep my original definition of $g$ , being "" $g(x) = a$ , where $x = f(a)$ for any $a \in \text{domain}(f)$ "", then that doesn't work because $g$ is no longer a function. Because since $f$ is not injective, there exists atleast 2 numbers $z$ and $w$ such that $z \neq w$ but $f(z) = f(w)$ , which means there exists $x$ such that: $g(x) = z = w$ . I think the idea is to simply redefine $g$ to simply ""choose"" either $z$ or $w$ , and assign it to $x$ . For example it could choose the smaller of the two. The only difference this would make is now $\text{domain}(f) \subset \text{image}(g)$ , instead of $\text{domain}(f) = \text{image}(g)$ . But since that fact wasn't important before, the conclusion in the question still holds. Here's my question. How do I explicitly write down a definition of $g$ that ""chooses"" the smaller of $z$ or $w$ ? Furthermore, recall there exists at least 2 numbers z and w. There could be arbitrarily more numbers such that $f(z) = f(w) = f(m) = f(n)$ and so on. And that's just one of the arbitrary branches the common values $f$ could take. There could be a different set of numbers $f(z_2)  = f(w_2) = f(m_2)$ and so on, that are not equal to $f(z)$ , etc. This is starting to get very messy. How can I express $g$ mathematically?","24b) Suppose that is a function such that every number can be written for some real number . Prove that there is a function such that I think I do understand this question and how to solve it, but I'm struggling to find a way to express my solution in a mathematically rigorous way, particularly when is not injective. Here's my idea: First of all, if is injective, then it's trivial. Let , where for any Since is injective, by definition there is only one value of that satisfies for each , which means is well defined. And (by definition of ), which from the supposition in the question is . Also, , since and are injective (but that fact is not important). So is defined for all . Finally, = , where for . But now if is not injective, it gets more complicated. If I keep my original definition of , being "" , where for any "", then that doesn't work because is no longer a function. Because since is not injective, there exists atleast 2 numbers and such that but , which means there exists such that: . I think the idea is to simply redefine to simply ""choose"" either or , and assign it to . For example it could choose the smaller of the two. The only difference this would make is now , instead of . But since that fact wasn't important before, the conclusion in the question still holds. Here's my question. How do I explicitly write down a definition of that ""chooses"" the smaller of or ? Furthermore, recall there exists at least 2 numbers z and w. There could be arbitrarily more numbers such that and so on. And that's just one of the arbitrary branches the common values could take. There could be a different set of numbers and so on, that are not equal to , etc. This is starting to get very messy. How can I express mathematically?",f b b = f(a) a g f \circ g = I f f g(x) = a x = f(a) a \in \text{domain}(f) f a x = f(a) x g \text{domain}(g) = \text{image}(f) g \mathbb{R} \text{domain}(f) = \text{image}(g) f g f(g(x)) x â \mathbb{R} f(g(x)) f(a) x = f(a) x â \mathbb{R} \to f(g(x)) = I(x) f g g(x) = a x = f(a) a \in \text{domain}(f) g f z w z \neq w f(z) = f(w) x g(x) = z = w g z w x \text{domain}(f) \subset \text{image}(g) \text{domain}(f) = \text{image}(g) g z w f(z) = f(w) = f(m) = f(n) f f(z_2)  = f(w_2) = f(m_2) f(z) g,['functions']
64,Is there a formula for $f(x)$ where $f(x)=$ the sum all simplest fractions with the numerator$+$denominator equals $x$,Is there a formula for  where  the sum all simplest fractions with the numeratordenominator equals,f(x) f(x)= + x,"Is there a closed-form for $$f(n)=\sum\limits_{\substack{k=1 \\ (k,n)=1}}^{n-1} \frac{k}{n-k}$$ For example, $f(5)=1/4+2/3+3/2+4/1= 6+5/12$ ; $f(6)=5+1/5$ The list of $f(x)$ from $x=1$ to $x=8$ is: $(0,1,5/2,10/3,77/12,26/5,223/20,988/105)$ I'm trying to plot this but I would take a while to do it by hand that's why I ask. If there isn't a nice formula could you write a program that plots it I'm not the best at coding.","Is there a closed-form for For example, ; The list of from to is: I'm trying to plot this but I would take a while to do it by hand that's why I ask. If there isn't a nice formula could you write a program that plots it I'm not the best at coding.","f(n)=\sum\limits_{\substack{k=1 \\ (k,n)=1}}^{n-1} \frac{k}{n-k} f(5)=1/4+2/3+3/2+4/1= 6+5/12 f(6)=5+1/5 f(x) x=1 x=8 (0,1,5/2,10/3,77/12,26/5,223/20,988/105)",['functions']
65,Cat Dog problem using integration,Cat Dog problem using integration,,"Consider this equation : $$\sqrt{\left( \frac{dy\cdot u\,dt}{L}\right)^2+(dy)^2}=v\,dt,$$ where $t$ varies from $0$ to $T$ , and $y$ varies from $0$ to $L$ .  Now how to proceed ? This equation arises out of following problem : A cat sitting in a field suddenly sees a standing dog. To save its life, the cat runs away in a straight line with speed $u$ . Without any delay, the dog starts with running with constant speed $v>u$ to catch the cat. Initially, $v$ is perpendicular to $u$ and $L$ is the initial separation between the two. If the dog always changes its direction so that it is always heading directly at the cat, find the time the dog takes to catch the cat in terms of $v, u$ and $L$ . See my solution below : Let initially dog be at $D$ and cat at $C$ and after time $dt$ they are at $D'$ and $C'$ respectively. Dog velocity is always pointing towards cat. Let $DA = dy, \;AD' = dx$ Let $CC'=udt,\;DD' = vdt$ as interval is very small so $DD'$ can be taken straight line. Also we have $\frac{DA}{DC}= \frac{AD'}{ CC'}$ using triangle property. $\frac{dy}{L}= \frac{dx}{udt}\\ dx = \frac{dy.udt}{L}$ $\sqrt{(dx)^2 + (dy)^2} = DD' = vdt \\ \sqrt{(\frac{dy.udt}{L})^2 + (dy)^2} = vdt $ Here $t$ varies from $0-T$ , and $y$ varies from $0-L$ . Now how to proceed?","Consider this equation : where varies from to , and varies from to .  Now how to proceed ? This equation arises out of following problem : A cat sitting in a field suddenly sees a standing dog. To save its life, the cat runs away in a straight line with speed . Without any delay, the dog starts with running with constant speed to catch the cat. Initially, is perpendicular to and is the initial separation between the two. If the dog always changes its direction so that it is always heading directly at the cat, find the time the dog takes to catch the cat in terms of and . See my solution below : Let initially dog be at and cat at and after time they are at and respectively. Dog velocity is always pointing towards cat. Let Let as interval is very small so can be taken straight line. Also we have using triangle property. Here varies from , and varies from . Now how to proceed?","\sqrt{\left( \frac{dy\cdot u\,dt}{L}\right)^2+(dy)^2}=v\,dt, t 0 T y 0 L u v>u v u L v, u L D C dt D' C' DA = dy, \;AD' = dx CC'=udt,\;DD' = vdt DD' \frac{DA}{DC}= \frac{AD'}{ CC'} \frac{dy}{L}= \frac{dx}{udt}\\ dx = \frac{dy.udt}{L} \sqrt{(dx)^2 + (dy)^2} = DD' = vdt \\ \sqrt{(\frac{dy.udt}{L})^2 + (dy)^2} = vdt  t 0-T y 0-L","['calculus', 'ordinary-differential-equations', 'integration', 'physics', 'mathematical-modeling']"
66,Extremely hard function problem,Extremely hard function problem,,"This problem was a question on a math test I took, and I didn't know how to solve it. How would you solve this? Let $$f(x)=e^{-xe^{-\sqrt{x}}+e^{\sqrt{x}}}+2e^{xe^{-\sqrt{x}}+e^{\sqrt{x}}}.$$ Find $$f(f(f(f(f(f(f(f(f(f(x)))))))))).$$ EDIT For more convenience, the expression of $f(x)$ is given by \begin{align*} f(x) = \exp\bigl(-x\exp(-\sqrt{x}) + \exp(\sqrt{x})\bigr)+{} \\{}+ 2\exp(x\exp(-\sqrt{x}) + +\exp\bigl(\sqrt{x})\bigr). \end{align*}","This problem was a question on a math test I took, and I didn't know how to solve it. How would you solve this? Let Find EDIT For more convenience, the expression of is given by","f(x)=e^{-xe^{-\sqrt{x}}+e^{\sqrt{x}}}+2e^{xe^{-\sqrt{x}}+e^{\sqrt{x}}}. f(f(f(f(f(f(f(f(f(f(x)))))))))). f(x) \begin{align*}
f(x) = \exp\bigl(-x\exp(-\sqrt{x}) + \exp(\sqrt{x})\bigr)+{} \\{}+ 2\exp(x\exp(-\sqrt{x}) + +\exp\bigl(\sqrt{x})\bigr).
\end{align*}",['functions']
67,Functions that are their own inverse.,Functions that are their own inverse.,,"What are the functions that are their own inverse? (thus functions where $ f(f(x)) = x $ for a large domain) I always thought there were only 4: $f(x) = x , f(x) = -x , f(x) = \frac {1}{x} $ and $ f(x) = \frac {-1}{x} $ Later I heard about a fifth one $$f(x) = \ln\left(\frac {e^x+1}{e^x-1}\right) $$ (for $x > 0$) This made me wonder are there more? What are conditions that apply to all these functions to get more, etc.","What are the functions that are their own inverse? (thus functions where $ f(f(x)) = x $ for a large domain) I always thought there were only 4: $f(x) = x , f(x) = -x , f(x) = \frac {1}{x} $ and $ f(x) = \frac {-1}{x} $ Later I heard about a fifth one $$f(x) = \ln\left(\frac {e^x+1}{e^x-1}\right) $$ (for $x > 0$) This made me wonder are there more? What are conditions that apply to all these functions to get more, etc.",,"['algebra-precalculus', 'functions', 'inverse']"
68,counterexamples with complex function,counterexamples with complex function,,"I want to find counterexamples for the following ""states"": if $f:\mathbb{C}\to \mathbb{C}$ be a complex function such that $$|f(x-y)|=|f(x)-f(y)|,\qquad \forall x ,y\in\mathbb{C}.$$ prove or disprove $$f(x+y)=f(x)+f(y),\forall x,y\in\mathbb{C}?$$ Can you give me a hint of what examples may work? Thank you.","I want to find counterexamples for the following ""states"": if be a complex function such that prove or disprove Can you give me a hint of what examples may work? Thank you.","f:\mathbb{C}\to \mathbb{C} |f(x-y)|=|f(x)-f(y)|,\qquad \forall x ,y\in\mathbb{C}. f(x+y)=f(x)+f(y),\forall x,y\in\mathbb{C}?","['functions', 'examples-counterexamples']"
69,Continuous functions need hint,Continuous functions need hint,,"We have continuous functions $f,g:[0;\infty)\longrightarrow[0;\infty)$ with the following properties: $f(0)=g(0)=0$ $g(x)\neq0$ , for any $x>0$ $f(x+g(f(x)))=f(x)$ , for any $x$ Prove that $f(x)=0$ for any $x$ . I need only a hint how to start. So far I've tried something with a sequence with positive terms and limit $0$ . I think that somehow we have to get to: $g(f(x))=0$ for any x, from where the conclusion follows.","We have continuous functions with the following properties: , for any , for any Prove that for any . I need only a hint how to start. So far I've tried something with a sequence with positive terms and limit . I think that somehow we have to get to: for any x, from where the conclusion follows.","f,g:[0;\infty)\longrightarrow[0;\infty) f(0)=g(0)=0 g(x)\neq0 x>0 f(x+g(f(x)))=f(x) x f(x)=0 x 0 g(f(x))=0","['real-analysis', 'functions', 'continuity']"
70,Injection/Surjection between sets of functions,Injection/Surjection between sets of functions,,"Consider three non-empty sets $A$, $B$ and $C$ and a function $ f_1:A \rightarrow B$. Further consider the following definitions $f_2:A^CâB^C : x \mapsto fâx$ and $ f_3 : C^B \rightarrow C^A: yâ¦yâf $. It can be proven:  (a) that if $f_1$ is injective then $f_2$ is injective and $f_3$ is surjective and (b)  that if $f_1$ is surjective then $f_2$ is surjective and $f_3$ is injective. Question: I usually have no problems with proving functions are surjective or injective or with function compositions but I am a little bit lost of what exactly the definitions are stating. Because ""sets of all functions (e.g. from $C$ to $A$ etc.) are involved and because x and y appear on both sides of the functions definitions I am a little bit lost of what is being mapped to what here. I reread the definitions many times but I still lack an intutitive picture of the mapping chain. If somebody could enlighten me with a small intuitive description or maybe  a small graphical sketch of what is being mapped to what so I can understand the problem a little bit better before I start proving.  Thank you.","Consider three non-empty sets $A$, $B$ and $C$ and a function $ f_1:A \rightarrow B$. Further consider the following definitions $f_2:A^CâB^C : x \mapsto fâx$ and $ f_3 : C^B \rightarrow C^A: yâ¦yâf $. It can be proven:  (a) that if $f_1$ is injective then $f_2$ is injective and $f_3$ is surjective and (b)  that if $f_1$ is surjective then $f_2$ is surjective and $f_3$ is injective. Question: I usually have no problems with proving functions are surjective or injective or with function compositions but I am a little bit lost of what exactly the definitions are stating. Because ""sets of all functions (e.g. from $C$ to $A$ etc.) are involved and because x and y appear on both sides of the functions definitions I am a little bit lost of what is being mapped to what here. I reread the definitions many times but I still lack an intutitive picture of the mapping chain. If somebody could enlighten me with a small intuitive description or maybe  a small graphical sketch of what is being mapped to what so I can understand the problem a little bit better before I start proving.  Thank you.",,"['functions', 'elementary-set-theory']"
71,Algebraic functions - $\sin{x}$,Algebraic functions -,\sin{x},"I would like to know an appropriate response to this question: An algebraic function is defined as a function which solves a polynomial equation $p(x,f(x))=0$. Show that the function $f(x) = \sin{x}$ is not algebraic. This is my response: We can observe that $p(x,0)=0$ must have finitely many solutions, unless it is identically $0$, neither of which cases includes $\sin(x)$. is it good?","I would like to know an appropriate response to this question: An algebraic function is defined as a function which solves a polynomial equation $p(x,f(x))=0$. Show that the function $f(x) = \sin{x}$ is not algebraic. This is my response: We can observe that $p(x,0)=0$ must have finitely many solutions, unless it is identically $0$, neither of which cases includes $\sin(x)$. is it good?",,"['abstract-algebra', 'functions']"
72,Problem with Ordered Triples,Problem with Ordered Triples,,"I have been doing set theory for a while, and for a long time I have understood Kuratowski's inductive definition for ordered $n$-tuples: $(x_1,x_2) := \{\{x_1\},\{x_1,x_2\}\}$ $(x_1,x_2,...,x_{k+1}) := ((x_1,x_2,...,x_k),x_{k+1})$ Pretty quickly I understood and accepted the beautiful result that $(x_1,...,x_n) = (y_1,...,y_n)$ if and only if $x_i = y_i$ for all $i \in \{1,...,n\}$, so I moved on and accepted this definition, thinking about ordered n-tuples as abstract objects again - happy that the set theory under the hood was working as it was supposed to. But today I noticed a problem with this definition that I didn't see, and it is to do with ordered triples (or ordered $n$-tuples for $n \geq 3$ to be honest). Given two arbitrary sets $a$ and $b$, the ordered triple $(a,a,b)$ is defined as $((a,a),b) = \{\{\color{blue}{(a,a)}\},\{\color{blue}{(a,a)},b\}\} = \{\{\color{blue}{\{\{a\}\}}\},\{\color{blue}{\{\{a\}\}},b\}\}$. In other words $(a,a,b) = (\{\{a\}\},b)$, and this holds for all sets. Now usually we don't have a domain which includes both $a$ and $\{\{a\}\}$ (or it is clear if we are talking about ordered pairs vs ordered triples), so the distinction is usually clear. But in abstract mathematics that is certainly not always the case. For example take the set $X = \{ \{\},\{\{\}\},\{\{\{\}\}\},...\}$. Then we can imagine the set of arbitrarily long $n$-tuples of $X$, the set $Y = \bigcup_{k=1}^{\infty}(\prod_{i=1}^k X)$. Then because of the above situation, many very simple and intuitive functions just straight up can't be defined. Take the function $P_3 \colon Y \to X \cup \{*\}$ given by $P_3(x_1,...,x_k) = \begin{cases} x_3 &\mbox{if } k \geq 3 \\  * & \mbox{if } k < 3 \end{cases}$ where the set $*$ is some set not contained in $X$. Straight away we run into problems as $P_3(\{\},\{\},\{\}) = \{\}$ and $P_3(\{\{\{\}\}\},\{\}) = *$, which gives us $P_3(\{\},\{\},\{\}) \neq P_3(\{\{\{\}\}\},\{\})$. This is a problem because under Kuratowski's definition of ordered $n$-tuples, we have that $(\{\},\{\},\{\}) = (\{\{\{\}\}\},\{\})$. I know that there are alternative definitions for ordered $n$-tuples, for example a definition such as: $(\color{red}{x_1},\color{blue}{x_2},\color{green}{x_3},...,x_k) := \{\color{red}{\{x_1\}},\color{blue}{\{x_2,\{x_2\}\}},\color{green}{\{x_3,\{x_3\},\{\{x_3\}\}\}},...\}$ where the $i$th entry nests $i-1$ times would solve this problem (at least when the axiom of regularity holds), but since Kuratowski's definition is so widely accepted there must be something I am overlooking. I would love to know why this is not an issue in general mathematics. EDIT: As (somewhat) pointed out in the comments, an even better definition for ordered $n$-tuples would be: $(x_1,...,x_n) := \{\{n\}, \{n, (x_1,...,x_n)_K\}\}$, where $(x_1,...,x_n)_K$ is Kuratowski's definition of ordered $n$-tuples as this solves the problem and holds even in the absence of the axiom of regularity . And even though it has been mentioned that this definition seems to depend on a prior construction of the natural numbers (i.e. the axiom of infinity ), I would disagree as this is an inductive definition - allowing you to define each $n$ sequentially at each inductive step, and does not require the set $\mathbb{N}$ to exist.","I have been doing set theory for a while, and for a long time I have understood Kuratowski's inductive definition for ordered $n$-tuples: $(x_1,x_2) := \{\{x_1\},\{x_1,x_2\}\}$ $(x_1,x_2,...,x_{k+1}) := ((x_1,x_2,...,x_k),x_{k+1})$ Pretty quickly I understood and accepted the beautiful result that $(x_1,...,x_n) = (y_1,...,y_n)$ if and only if $x_i = y_i$ for all $i \in \{1,...,n\}$, so I moved on and accepted this definition, thinking about ordered n-tuples as abstract objects again - happy that the set theory under the hood was working as it was supposed to. But today I noticed a problem with this definition that I didn't see, and it is to do with ordered triples (or ordered $n$-tuples for $n \geq 3$ to be honest). Given two arbitrary sets $a$ and $b$, the ordered triple $(a,a,b)$ is defined as $((a,a),b) = \{\{\color{blue}{(a,a)}\},\{\color{blue}{(a,a)},b\}\} = \{\{\color{blue}{\{\{a\}\}}\},\{\color{blue}{\{\{a\}\}},b\}\}$. In other words $(a,a,b) = (\{\{a\}\},b)$, and this holds for all sets. Now usually we don't have a domain which includes both $a$ and $\{\{a\}\}$ (or it is clear if we are talking about ordered pairs vs ordered triples), so the distinction is usually clear. But in abstract mathematics that is certainly not always the case. For example take the set $X = \{ \{\},\{\{\}\},\{\{\{\}\}\},...\}$. Then we can imagine the set of arbitrarily long $n$-tuples of $X$, the set $Y = \bigcup_{k=1}^{\infty}(\prod_{i=1}^k X)$. Then because of the above situation, many very simple and intuitive functions just straight up can't be defined. Take the function $P_3 \colon Y \to X \cup \{*\}$ given by $P_3(x_1,...,x_k) = \begin{cases} x_3 &\mbox{if } k \geq 3 \\  * & \mbox{if } k < 3 \end{cases}$ where the set $*$ is some set not contained in $X$. Straight away we run into problems as $P_3(\{\},\{\},\{\}) = \{\}$ and $P_3(\{\{\{\}\}\},\{\}) = *$, which gives us $P_3(\{\},\{\},\{\}) \neq P_3(\{\{\{\}\}\},\{\})$. This is a problem because under Kuratowski's definition of ordered $n$-tuples, we have that $(\{\},\{\},\{\}) = (\{\{\{\}\}\},\{\})$. I know that there are alternative definitions for ordered $n$-tuples, for example a definition such as: $(\color{red}{x_1},\color{blue}{x_2},\color{green}{x_3},...,x_k) := \{\color{red}{\{x_1\}},\color{blue}{\{x_2,\{x_2\}\}},\color{green}{\{x_3,\{x_3\},\{\{x_3\}\}\}},...\}$ where the $i$th entry nests $i-1$ times would solve this problem (at least when the axiom of regularity holds), but since Kuratowski's definition is so widely accepted there must be something I am overlooking. I would love to know why this is not an issue in general mathematics. EDIT: As (somewhat) pointed out in the comments, an even better definition for ordered $n$-tuples would be: $(x_1,...,x_n) := \{\{n\}, \{n, (x_1,...,x_n)_K\}\}$, where $(x_1,...,x_n)_K$ is Kuratowski's definition of ordered $n$-tuples as this solves the problem and holds even in the absence of the axiom of regularity . And even though it has been mentioned that this definition seems to depend on a prior construction of the natural numbers (i.e. the axiom of infinity ), I would disagree as this is an inductive definition - allowing you to define each $n$ sequentially at each inductive step, and does not require the set $\mathbb{N}$ to exist.",,"['functions', 'logic', 'set-theory']"
73,How to formally represent a function whose elements are sets?,How to formally represent a function whose elements are sets?,,"Let us suppose that I have two sets: A and B. $A = \{0,2,4,6,8\}$ $B = \{1,3,5,7,9\}$ Let us suppose that I have a function f that maps elements of A and elements of B to the natural numbers ($\mathbb{N}$). I think that I can formalize this function in this way: $f: A \times B \to \mathbb{N}$ However, how can I formalize a function t that maps subsets of A and subsets of B to subsets of $\mathbb{N}$? I think that I can do this, by replacing the sets A, B, and $\mathbb{N}$, of the formal definition of f, by their respective power sets, in this way: $t: \mathcal{P}(A) \times \mathcal{P}(B) \to \mathcal{P}(\mathbb{N})$ Am I correct?","Let us suppose that I have two sets: A and B. $A = \{0,2,4,6,8\}$ $B = \{1,3,5,7,9\}$ Let us suppose that I have a function f that maps elements of A and elements of B to the natural numbers ($\mathbb{N}$). I think that I can formalize this function in this way: $f: A \times B \to \mathbb{N}$ However, how can I formalize a function t that maps subsets of A and subsets of B to subsets of $\mathbb{N}$? I think that I can do this, by replacing the sets A, B, and $\mathbb{N}$, of the formal definition of f, by their respective power sets, in this way: $t: \mathcal{P}(A) \times \mathcal{P}(B) \to \mathcal{P}(\mathbb{N})$ Am I correct?",,"['functions', 'discrete-mathematics', 'elementary-set-theory']"
74,"How do we formally ""identify"" objects using isomorphisms?","How do we formally ""identify"" objects using isomorphisms?",,"i don't have much background in set theory and mathematical logic besides isomorphisms thus i can't quite understand(justify) the way of ""identifying"" integers with naturals in Tao's analysis. That's how i interpret what i have read so far about integers: he constructs integers from naturals(integers are elements of the set $NÃN$ so they are not the same objects as naturals he defined earlier, he uses a notation $(a,b):=a-b$ for them). He defines equality $""=""$ relation between integers(based on equality between naturals), and operations of additions and multiplication for integers(again in terms of natural numbers) After that I have a problem with understanding his next paragraph: The integers $nâ0$ behave in the same way as the natural   numbers n; indeed one can check that $(nâ0) + (mâ0) = (n + m)â0$ and $(nâ0) Ã (mâ0) = nmâ0$. I know it should mean something like this$:$ if we map $(n,0)$ with $n$, then we have a function $f:AâNÃNâ¦N$, where $A$ consists of integers of the form $(n,0)$ that has properties that if $a+b=c$ ($""+""$ and $""=""$ are those defined for integers), then $f(a)+f(b)=f(c)$($""+""$ and $""=""$ are those defined for naturals) and if $aÃb=c$ then $f(a)Ãf(b)=f(c)$(same thing with $""Ã""$ and $""=""$) Furthermore, $(nâ0)$ is equal to $(mâ0)$ if and only if $n = m$. I guess that means that $f$ is injection. Though it's a surjection too. (The mathematical term for this is that there is an isomorphism between the natural numbers $n$ and those integers of the form $nâ0$). Thus we may   ""identify"" the natural numbers with integers by setting $n â¡ nâ0$; From here it begins: What exactly does $""â¡""$ sign mean? Does it stand for my function $f$? Or is it some new relation for integers like our already defined relation $""=""$ but he just doesn't want to overload the sign $""=""$ or something? this does not affect our definitions of addition or multiplication   or equality since they are consistent with each other. Thus for   instance the natural number $3$ is now considered to be the same   as the integer $3â0: 3 = 3â0$. Hey now i wonder what $""=""$ sign means, because we have $""=""$ for naturals, $""=""$ for integers but we don't have $""=""$ for integer-naturals(did he define it implicitly?)(is it the same sign as $""â¡""$?) In particular $0$ is equal to $0â0$   and 1 is equal to $1â0$. Of course, if we set $n$ equal to $nâ0$, then   it will also be equal to any other integer which is equal to $nâ0$,   for instance $3$ is equal not only to $3â0$, but also to $4â1$, $5â2$,   etc. We can now define incrementation on the integers by defining   $x++ := x + 1$ for any integer $x$; this is of course consistent with   our definition of the increment operation for natural numbers. How does this operation work? It looks like it has only one argument from $NÃN$ but then computing an output it uses $1$ from $N$ so operation $""+""$ has one argument from $NÃN$ and the other from N and how it supposed to react to this?! So basically all my questions are about what we can do with isomorpisms and why we can do it.","i don't have much background in set theory and mathematical logic besides isomorphisms thus i can't quite understand(justify) the way of ""identifying"" integers with naturals in Tao's analysis. That's how i interpret what i have read so far about integers: he constructs integers from naturals(integers are elements of the set $NÃN$ so they are not the same objects as naturals he defined earlier, he uses a notation $(a,b):=a-b$ for them). He defines equality $""=""$ relation between integers(based on equality between naturals), and operations of additions and multiplication for integers(again in terms of natural numbers) After that I have a problem with understanding his next paragraph: The integers $nâ0$ behave in the same way as the natural   numbers n; indeed one can check that $(nâ0) + (mâ0) = (n + m)â0$ and $(nâ0) Ã (mâ0) = nmâ0$. I know it should mean something like this$:$ if we map $(n,0)$ with $n$, then we have a function $f:AâNÃNâ¦N$, where $A$ consists of integers of the form $(n,0)$ that has properties that if $a+b=c$ ($""+""$ and $""=""$ are those defined for integers), then $f(a)+f(b)=f(c)$($""+""$ and $""=""$ are those defined for naturals) and if $aÃb=c$ then $f(a)Ãf(b)=f(c)$(same thing with $""Ã""$ and $""=""$) Furthermore, $(nâ0)$ is equal to $(mâ0)$ if and only if $n = m$. I guess that means that $f$ is injection. Though it's a surjection too. (The mathematical term for this is that there is an isomorphism between the natural numbers $n$ and those integers of the form $nâ0$). Thus we may   ""identify"" the natural numbers with integers by setting $n â¡ nâ0$; From here it begins: What exactly does $""â¡""$ sign mean? Does it stand for my function $f$? Or is it some new relation for integers like our already defined relation $""=""$ but he just doesn't want to overload the sign $""=""$ or something? this does not affect our definitions of addition or multiplication   or equality since they are consistent with each other. Thus for   instance the natural number $3$ is now considered to be the same   as the integer $3â0: 3 = 3â0$. Hey now i wonder what $""=""$ sign means, because we have $""=""$ for naturals, $""=""$ for integers but we don't have $""=""$ for integer-naturals(did he define it implicitly?)(is it the same sign as $""â¡""$?) In particular $0$ is equal to $0â0$   and 1 is equal to $1â0$. Of course, if we set $n$ equal to $nâ0$, then   it will also be equal to any other integer which is equal to $nâ0$,   for instance $3$ is equal not only to $3â0$, but also to $4â1$, $5â2$,   etc. We can now define incrementation on the integers by defining   $x++ := x + 1$ for any integer $x$; this is of course consistent with   our definition of the increment operation for natural numbers. How does this operation work? It looks like it has only one argument from $NÃN$ but then computing an output it uses $1$ from $N$ so operation $""+""$ has one argument from $NÃN$ and the other from N and how it supposed to react to this?! So basically all my questions are about what we can do with isomorpisms and why we can do it.",,"['functions', 'logic', 'set-theory', 'number-systems']"
75,"$x^y+y^x>1$ for all $(x, y)\in \mathbb{R_+^2}$ [duplicate]",for all  [duplicate],"x^y+y^x>1 (x, y)\in \mathbb{R_+^2}","This question already has an answer here : Exponential teaser [closed] (1 answer) Closed 7 years ago . Prove that $x^y+y^x>1$ for all $(x, y)\in \mathbb{R_+^2}$.","This question already has an answer here : Exponential teaser [closed] (1 answer) Closed 7 years ago . Prove that $x^y+y^x>1$ for all $(x, y)\in \mathbb{R_+^2}$.",,['inequality']
76,Find the inverse of the following piecewise defined function,Find the inverse of the following piecewise defined function,,"Find the inverse of $f$ if $f(x)=$ $$ \begin{cases} \sqrt{2-x}, &\text{for $x<0$}\\  1-x^2, &\text{for $x \ge 0$} \\  \end{cases} $$ My effort For  $y=\sqrt{2-x}$ ,we find  \begin{array}{c} y=\sqrt{2-x} \\ y^2=2-x  &\text{(I can do this since $\sqrt{2-x}>0$ ,for $x<0$)} \\ x=2-y^2 \end{array} So for this piece of function we have $f^{-1}(x)=2-x^2$ for $x>\sqrt{2}$ since this the range of $f(x)=\sqrt{2-x}$ for $x<0$. Now, for the second part of the function we have  \begin{array}{c} y=1-x^2 \\ x^2=1-y \\ x=\sqrt{1-y} ,&\text{since $x\ge 0 $} \end{array} So for this latter part we have $f^{-1}(x)=\sqrt{1-x}$ which has domain $(-\inf,1]$ . so our piecewise defined function for $f^{-1}$ is \begin{array}{c} 2-x^2 , &\text{for $x> \sqrt{2} $} \\ \sqrt{1-x}, &\text{ for $x\le1$} \\ \end{array} Question Is my effort correct ?Can it be tightened up in some parts ?","Find the inverse of $f$ if $f(x)=$ $$ \begin{cases} \sqrt{2-x}, &\text{for $x<0$}\\  1-x^2, &\text{for $x \ge 0$} \\  \end{cases} $$ My effort For  $y=\sqrt{2-x}$ ,we find  \begin{array}{c} y=\sqrt{2-x} \\ y^2=2-x  &\text{(I can do this since $\sqrt{2-x}>0$ ,for $x<0$)} \\ x=2-y^2 \end{array} So for this piece of function we have $f^{-1}(x)=2-x^2$ for $x>\sqrt{2}$ since this the range of $f(x)=\sqrt{2-x}$ for $x<0$. Now, for the second part of the function we have  \begin{array}{c} y=1-x^2 \\ x^2=1-y \\ x=\sqrt{1-y} ,&\text{since $x\ge 0 $} \end{array} So for this latter part we have $f^{-1}(x)=\sqrt{1-x}$ which has domain $(-\inf,1]$ . so our piecewise defined function for $f^{-1}$ is \begin{array}{c} 2-x^2 , &\text{for $x> \sqrt{2} $} \\ \sqrt{1-x}, &\text{ for $x\le1$} \\ \end{array} Question Is my effort correct ?Can it be tightened up in some parts ?",,"['functions', 'proof-verification']"
77,A Weaker Notion of a Flow in a Metric Space,A Weaker Notion of a Flow in a Metric Space,,"I am seeing the definition of flow in a metric space: $f:M\times \mathbb{R}\rightarrow M$ is one flow if $M$ is metric space, $f$ is continuous and $f(x,t+s)=f(f(x,t),s)$ . Note that the condition does not require $f(x,0)=x$ . My question is this: If $f_t(x):=f(x,t)$ is a homeomorphism for each t, Then we can conclude that $f(x,0)=x$ for all x? If one can suggest examples of flows under this definition I will be very grateful.","I am seeing the definition of flow in a metric space: is one flow if is metric space, is continuous and . Note that the condition does not require . My question is this: If is a homeomorphism for each t, Then we can conclude that for all x? If one can suggest examples of flows under this definition I will be very grateful.","f:M\times \mathbb{R}\rightarrow M M f f(x,t+s)=f(f(x,t),s) f(x,0)=x f_t(x):=f(x,t) f(x,0)=x","['functions', 'metric-spaces', 'dynamical-systems', 'group-actions', 'topological-dynamics']"
78,Proving $f$ cannot be onto,Proving  cannot be onto,f,"If $f$ maps finite sets $A$ to $B$ and $n(A) < n(B)$, prove that $f$ cannot be onto. Proof by contradiction: If $f: AâB$ and $n(A) < n(B)$, $f$ is onto. Since, by definition of a function, $aâA$ cannot be mapped to more than one value $bâB$. This means that $f$ is not onto since $n(A)$ cannot be less than $n(B)$, which violates the contradiction. To me, this explanation seems simple yet complete enough to constitute a proof to the theorem. But the given solution to this problem is as follows: If we assume that $f$ is onto, then the range is $f(A) = B$ so $n(f(A)) = n(B)$. Knowing that $n(A) â¥ n(f(A))$, yields the expression: $n(A) â¥ n(f(A)) = n(B)$. However this is a contradiction to the fact that $n(A) < n(B)$, so $f$ is not onto. Are both proofs to this theorem deemed accurate? Should I always, when encountering these types of problems, try to prove the theorem based on the number of elements in the set versus constructing an argument by definition? Thanks so much!","If $f$ maps finite sets $A$ to $B$ and $n(A) < n(B)$, prove that $f$ cannot be onto. Proof by contradiction: If $f: AâB$ and $n(A) < n(B)$, $f$ is onto. Since, by definition of a function, $aâA$ cannot be mapped to more than one value $bâB$. This means that $f$ is not onto since $n(A)$ cannot be less than $n(B)$, which violates the contradiction. To me, this explanation seems simple yet complete enough to constitute a proof to the theorem. But the given solution to this problem is as follows: If we assume that $f$ is onto, then the range is $f(A) = B$ so $n(f(A)) = n(B)$. Knowing that $n(A) â¥ n(f(A))$, yields the expression: $n(A) â¥ n(f(A)) = n(B)$. However this is a contradiction to the fact that $n(A) < n(B)$, so $f$ is not onto. Are both proofs to this theorem deemed accurate? Should I always, when encountering these types of problems, try to prove the theorem based on the number of elements in the set versus constructing an argument by definition? Thanks so much!",,"['functions', 'discrete-mathematics', 'proof-writing']"
79,Terminology for functions such that $f(x)\ge x$ for all $x$,Terminology for functions such that  for all,f(x)\ge x x,"Is there a common terminology for a real function $f$ such that $$f(x)\ge x$$ for all $x$ ? same question for the conditions $\forall x,f(x)>x$ ; $\forall x,f(x)\le x$ ; $\forall x,f(x)<x$ . (I'm not specific about the domain of definition, I have in mind functions from $\mathbf{R}_+$ to itself but I don't expect this to be important, it could be from any interval to any other, or even from any totally ordered set to itself.) If I had to coin a terminology I would say something like ""dynamically non-decreasing"" but it's a bit ugly.","Is there a common terminology for a real function such that for all ? same question for the conditions ; ; . (I'm not specific about the domain of definition, I have in mind functions from to itself but I don't expect this to be important, it could be from any interval to any other, or even from any totally ordered set to itself.) If I had to coin a terminology I would say something like ""dynamically non-decreasing"" but it's a bit ugly.","f f(x)\ge x x \forall x,f(x)>x \forall x,f(x)\le x \forall x,f(x)<x \mathbf{R}_+","['real-analysis', 'functions', 'terminology', 'dynamical-systems', 'order-theory']"
80,"Show that $f(a,b)$ is one-to-one",Show that  is one-to-one,"f(a,b)","Let $$A=\{(x,y)\in\mathbb R^2:x>0, y>0\}$$ and define $f:A\to\mathbb R^2$ by $$f(a,b)=(a+b^2,2a^2+b).$$ Show that $f$ is one-to-one on $A$. I know that a function is one-to-one if all values of the range are mapped to by at most one value in the domain, but do I show this for $f$?","Let $$A=\{(x,y)\in\mathbb R^2:x>0, y>0\}$$ and define $f:A\to\mathbb R^2$ by $$f(a,b)=(a+b^2,2a^2+b).$$ Show that $f$ is one-to-one on $A$. I know that a function is one-to-one if all values of the range are mapped to by at most one value in the domain, but do I show this for $f$?",,['functions']
81,Prove equation has only one root in a specific interval,Prove equation has only one root in a specific interval,,"Prove that the following equation has only one solution in the interval $[-\text{min}(a_i), +\infty]$: $f(x) = \left(\sum_{i=1}^n \frac{1}{a_i + x}\right)\times \left(\sum_{i=1}^n \frac{a_i b_i}{(a_i + x)^2}\right)  - \left(\sum_{i=1}^n \frac{a_i}{a_i + x}\right) \times \left(\sum_{i=1}^n \frac{b_i}{(a_i + x)^2}\right) =0$ $x\in \mathbb{R}$ $n>1$. $a_i$ and $b_i,\,\, i=1,..., n$, are all positive real numbers. $a_1> a_2> ... > a_n$ $a_i \neq a_j\quad\forall i, j = 1,..,n, i\neq j$. The context of the problem is as follows: $a_i$ are the squared singular values of a random matrix. $b_i$ are the diagonal elements of a sample covariance matrix. I tried solving the equation for different parameter values using Newton's method. It always converges when initialized at zero. The plot of the function in the interval of interest always shows increasing function from the start of the interval, zero crossing, a maximum, then the function continuously decreases. The function approaches zero as $x$ increases following the peak value. We note/can prove the following: $f(x)$ has $n$ discontinuities at $-a_i$. $f(x)$ is continuous in the interval of interest $[-\text{min}(a_i), +\infty]$ = $[-a_n, +\infty]$. $\lim_{x \to +\infty} = 0$. $\lim_{x \to -a_n} = -\infty$. $f(x)$ is infinitely differentiable in the interval of interest. $f(x)$ can be put in the form: $f(x) = \sum_{\{i,j\}} \frac{a_i - a_j}{(a_i + x)(a_j + x)} \left(\frac{b_i}{a_i + x} - \frac{b_j}{a_j + x} \right)$ for all permutations of $\{i,j\}\subset\{1,...,n\}, i< j$. I tried the following steps to prove that $f(x)$ has a single root in the interval $[-\text{min}(a_i), +\infty]$: Assume $x_0\in [-\text{min}(a_i), +\infty]$ is a root. Tried to show that $x_0$ is not a solution of $f^{'}(x)$, but the derivative expression is far more complex to figure that out. Any suggestion for an alternative way to obtain the required proof?","Prove that the following equation has only one solution in the interval $[-\text{min}(a_i), +\infty]$: $f(x) = \left(\sum_{i=1}^n \frac{1}{a_i + x}\right)\times \left(\sum_{i=1}^n \frac{a_i b_i}{(a_i + x)^2}\right)  - \left(\sum_{i=1}^n \frac{a_i}{a_i + x}\right) \times \left(\sum_{i=1}^n \frac{b_i}{(a_i + x)^2}\right) =0$ $x\in \mathbb{R}$ $n>1$. $a_i$ and $b_i,\,\, i=1,..., n$, are all positive real numbers. $a_1> a_2> ... > a_n$ $a_i \neq a_j\quad\forall i, j = 1,..,n, i\neq j$. The context of the problem is as follows: $a_i$ are the squared singular values of a random matrix. $b_i$ are the diagonal elements of a sample covariance matrix. I tried solving the equation for different parameter values using Newton's method. It always converges when initialized at zero. The plot of the function in the interval of interest always shows increasing function from the start of the interval, zero crossing, a maximum, then the function continuously decreases. The function approaches zero as $x$ increases following the peak value. We note/can prove the following: $f(x)$ has $n$ discontinuities at $-a_i$. $f(x)$ is continuous in the interval of interest $[-\text{min}(a_i), +\infty]$ = $[-a_n, +\infty]$. $\lim_{x \to +\infty} = 0$. $\lim_{x \to -a_n} = -\infty$. $f(x)$ is infinitely differentiable in the interval of interest. $f(x)$ can be put in the form: $f(x) = \sum_{\{i,j\}} \frac{a_i - a_j}{(a_i + x)(a_j + x)} \left(\frac{b_i}{a_i + x} - \frac{b_j}{a_j + x} \right)$ for all permutations of $\{i,j\}\subset\{1,...,n\}, i< j$. I tried the following steps to prove that $f(x)$ has a single root in the interval $[-\text{min}(a_i), +\infty]$: Assume $x_0\in [-\text{min}(a_i), +\infty]$ is a root. Tried to show that $x_0$ is not a solution of $f^{'}(x)$, but the derivative expression is far more complex to figure that out. Any suggestion for an alternative way to obtain the required proof?",,"['functions', 'roots']"
82,Why is the trace map on an abelian variety continuous,Why is the trace map on an abelian variety continuous,,"Let $X$ be a (EDIT) variety with a group structure. For $a\in A$, let $t_a$ be the translation on $X$: $t_a(x) = a+x$. Why is the function $f:X\to \mathbf{C}$ given by $$f(a) = \sum_{i} (-1)^i \mathrm{Tr}(t_a^\ast, H^i(X,\mathbf{C}))$$ continuous ? Here I consider the usual singular cohomology with $\mathbf{C}$-coefficients. (The coefficients don't really matter. You can even take $\mathbf{Q}_{\ell}$-coefficients and work with $\ell$-adic cohomology.) I call the function $f$ on $X$ the trace function . Note that one can use the Lefschetz trace formula to see that the image of $f$ lies in $\mathbf{Z}$.","Let $X$ be a (EDIT) variety with a group structure. For $a\in A$, let $t_a$ be the translation on $X$: $t_a(x) = a+x$. Why is the function $f:X\to \mathbf{C}$ given by $$f(a) = \sum_{i} (-1)^i \mathrm{Tr}(t_a^\ast, H^i(X,\mathbf{C}))$$ continuous ? Here I consider the usual singular cohomology with $\mathbf{C}$-coefficients. (The coefficients don't really matter. You can even take $\mathbf{Q}_{\ell}$-coefficients and work with $\ell$-adic cohomology.) I call the function $f$ on $X$ the trace function . Note that one can use the Lefschetz trace formula to see that the image of $f$ lies in $\mathbf{Z}$.",,"['algebraic-geometry', 'algebraic-topology', 'functions', 'arithmetic-geometry', 'abelian-varieties']"
83,Function Shape Reference,Function Shape Reference,,"I'm wondering if their exists a visual/behavioral reference for the fundamental families of functions. I'm not a mathematician so excuse my language if I'm being overly vague. I would like to have a reference where I can go look at images of functions and say: that looks like a behavior/character I want. Or maybe even search on the properties of the function, such as it's periodic, or that the output is always in the [-1, 1] range.","I'm wondering if their exists a visual/behavioral reference for the fundamental families of functions. I'm not a mathematician so excuse my language if I'm being overly vague. I would like to have a reference where I can go look at images of functions and say: that looks like a behavior/character I want. Or maybe even search on the properties of the function, such as it's periodic, or that the output is always in the [-1, 1] range.",,"['soft-question', 'reference-request', 'functions', 'functional-equations']"
84,Show that $f^{-1}(B)=A$,Show that,f^{-1}(B)=A,"I started yesterday my study of functions. Iâm following the book âProofs and Fundamentalsâ , by Ethan D. Bloch, and Iâm having some trouble in starting myself in formal proofs that involve functions. This is one of my problems. Problem: Let $A$ and $B$ be sets and $f \colon A \to B$ be a function. Show that $f^{-1}(B) = A$ . So far, I understand that I will have to show that $f^{-1}(B) \subseteq A$ and $A \subseteq f^{-1}(B)$ . The only definition that I have used is that of a function given by Bloch as a subset of $A \times B$ . So, my proof was something like this. By definition, $f^{-1}(B) = \{a \in A \mid \exists b \in B: f(a) = b\}$ . Let $x \in f^{-1}(B)$ . Then $x \in A$ and it exists some $b \in B$ such that $f(x) = b$ . In particular, $x \in A$ . Hence, $f^{-1}(B) \subseteq A$ . Now, let $a \in A$ . Since $f$ is a function from $A$ to $B$ , there exists a unique ordered pair of the form $(x,y)$ for all $x \in A$ and some $y \in B$ with $y = f(x)$ . So, there must be a unique ordered pair $(a,b)$ with $b \in B$ and $b = f(a)$ . For that, $f(a) \in B$ ; and by definition, $a \in f^{-1}(B)$ . Hence, $A \subseteq f^{-1}(B)$ . Therefore, we have that $f^{-1}(B)=A$ . $\square$ Please give all the feedback to turn this proof as formal as possible. Thank you for your time.","I started yesterday my study of functions. Iâm following the book âProofs and Fundamentalsâ , by Ethan D. Bloch, and Iâm having some trouble in starting myself in formal proofs that involve functions. This is one of my problems. Problem: Let and be sets and be a function. Show that . So far, I understand that I will have to show that and . The only definition that I have used is that of a function given by Bloch as a subset of . So, my proof was something like this. By definition, . Let . Then and it exists some such that . In particular, . Hence, . Now, let . Since is a function from to , there exists a unique ordered pair of the form for all and some with . So, there must be a unique ordered pair with and . For that, ; and by definition, . Hence, . Therefore, we have that . Please give all the feedback to turn this proof as formal as possible. Thank you for your time.","A B f \colon A \to B f^{-1}(B) = A f^{-1}(B) \subseteq A A \subseteq f^{-1}(B) A \times B f^{-1}(B) = \{a \in A \mid \exists b \in B: f(a) = b\} x \in f^{-1}(B) x \in A b \in B f(x) = b x \in A f^{-1}(B) \subseteq A a \in A f A B (x,y) x \in A y \in B y = f(x) (a,b) b \in B b = f(a) f(a) \in B a \in f^{-1}(B) A \subseteq f^{-1}(B) f^{-1}(B)=A \square","['functions', 'elementary-set-theory', 'proof-writing', 'solution-verification']"
85,Is there a function $f:{\mathbb N}\to{\mathbb N}$ that is neither injective nor surjective? [closed],Is there a function  that is neither injective nor surjective? [closed],f:{\mathbb N}\to{\mathbb N},"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question Is there a function $f:{\mathbb N}\to{\mathbb N}$ that is neither injective nor surjective ? I came up with $n\mapsto\sin n$ as not all outputs are mapped and some inputs have the same output, but then I realized $\sin n$ doesn't produce a natural number. I have to map the natural numbers to the natural numbers. I also came up with other ones but they always seem to be total and injective or total and subjective.","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question Is there a function $f:{\mathbb N}\to{\mathbb N}$ that is neither injective nor surjective ? I came up with $n\mapsto\sin n$ as not all outputs are mapped and some inputs have the same output, but then I realized $\sin n$ doesn't produce a natural number. I have to map the natural numbers to the natural numbers. I also came up with other ones but they always seem to be total and injective or total and subjective.",,"['functions', 'elementary-set-theory']"
86,Injection $\mathbb N \times \mathbb N \times \mathbb N \to \mathbb N$,Injection,\mathbb N \times \mathbb N \times \mathbb N \to \mathbb N,I have to give an example of an injection $\mathbb N \times \mathbb N \times \mathbb N \to \mathbb N$. Would something like $f(x)=x^3$ be an answer to this question?,I have to give an example of an injection $\mathbb N \times \mathbb N \times \mathbb N \to \mathbb N$. Would something like $f(x)=x^3$ be an answer to this question?,,['functions']
87,How to solve the functional equation $f(x + f(x +y ) ) = f(2x) + y$?,How to solve the functional equation ?,f(x + f(x +y ) ) = f(2x) + y,"Find all functions $f:\mathbb{R}\rightarrow \mathbb{R}$ that satisfy the following equation: $$ f(x + f(x +y ) ) = f(2x) + y,\quad \forall x,y\in\mathbb{R}$$ The only function I have found is $f(x) = x$, but I think there are more.","Find all functions $f:\mathbb{R}\rightarrow \mathbb{R}$ that satisfy the following equation: $$ f(x + f(x +y ) ) = f(2x) + y,\quad \forall x,y\in\mathbb{R}$$ The only function I have found is $f(x) = x$, but I think there are more.",,"['functions', 'functional-equations']"
88,Inverse of sum of two functions,Inverse of sum of two functions,,"Assuming two functions are invertible, is it true that the inverse of the sum of the two functions is the sum of the inverses (assuming all functions are well behaved)?","Assuming two functions are invertible, is it true that the inverse of the sum of the two functions is the sum of the inverses (assuming all functions are well behaved)?",,"['functions', 'inverse']"
89,How the cardinality of $\mathbb{R^+}$ and $\mathbb{R}$ same?,How the cardinality of  and  same?,\mathbb{R^+} \mathbb{R},"Let me first confirm you that this question is not a duplicate of either this , this or this or any other similar looking problem. Here in the current problem I'm asking to disprove me(most probably I'm wrong). As you can see in this problem as answered by Nicolas that if a map is from $A \to B$ and is bijective then the cardinality of $A$ and $B$ is same. Logarithmic map is from $\mathbb{R^+} \to \mathbb{R}$ and it is a bijective map and therefore it implies that the cardinality of $\mathbb{R^+}$ and $\mathbb{R}$ is same. My logic We can rewrite $\mathbb{R}=\mathbb{R^-} \cup \{0\} \cup \mathbb{R^+}$ Now we can see that $\mathbb{R}$ has all the elements of $\mathbb{R^+}$ and over that it has {0} and elements of $\mathbb{R^-}$. Now using pigeonhole principle , if we pair each element of $\mathbb{R^+}$ to itself from $\mathbb{R^+} \to \mathbb{R}$ (eg. 5.124 is paired to 5.124 and so on) now when the pairing gets over then you have elements of $\mathbb{R^-}$ which have not been paired. Now one can say that since they are infinite sets therefore we cannot talk about pairing as I did above. When we are dealing with the pigeonhole principle then at that time it is not necessary to know the exact numbers involved. Now whatever method you use for pairing you will always end with some elements of $\mathbb{R}$ which have not been paired (acc to pigeonhole principle). Most probably I'm wrong but how?. Kindly make me understand that I'm wrong and the above used logic by me is inappropriate.","Let me first confirm you that this question is not a duplicate of either this , this or this or any other similar looking problem. Here in the current problem I'm asking to disprove me(most probably I'm wrong). As you can see in this problem as answered by Nicolas that if a map is from $A \to B$ and is bijective then the cardinality of $A$ and $B$ is same. Logarithmic map is from $\mathbb{R^+} \to \mathbb{R}$ and it is a bijective map and therefore it implies that the cardinality of $\mathbb{R^+}$ and $\mathbb{R}$ is same. My logic We can rewrite $\mathbb{R}=\mathbb{R^-} \cup \{0\} \cup \mathbb{R^+}$ Now we can see that $\mathbb{R}$ has all the elements of $\mathbb{R^+}$ and over that it has {0} and elements of $\mathbb{R^-}$. Now using pigeonhole principle , if we pair each element of $\mathbb{R^+}$ to itself from $\mathbb{R^+} \to \mathbb{R}$ (eg. 5.124 is paired to 5.124 and so on) now when the pairing gets over then you have elements of $\mathbb{R^-}$ which have not been paired. Now one can say that since they are infinite sets therefore we cannot talk about pairing as I did above. When we are dealing with the pigeonhole principle then at that time it is not necessary to know the exact numbers involved. Now whatever method you use for pairing you will always end with some elements of $\mathbb{R}$ which have not been paired (acc to pigeonhole principle). Most probably I'm wrong but how?. Kindly make me understand that I'm wrong and the above used logic by me is inappropriate.",,"['functions', 'elementary-set-theory', 'intuition', 'infinity', 'pigeonhole-principle']"
90,"Using ""$\cdot$"" as variable placeholder","Using """" as variable placeholder",\cdot,"I've occasionally come across the use of ""$\cdot$"" as placeholder for a variable, most recently in a paper on radial basis functions, which were defined as $$ s(\cdot) = p(\cdot) + \sum_{i=1}^N \lambda_i \phi(|\cdot - x_i|). $$ What's the benefit of writing ""$s(\cdot)$"" rather than ""$s(x)$"", which would be easier to parse (IMO)?","I've occasionally come across the use of ""$\cdot$"" as placeholder for a variable, most recently in a paper on radial basis functions, which were defined as $$ s(\cdot) = p(\cdot) + \sum_{i=1}^N \lambda_i \phi(|\cdot - x_i|). $$ What's the benefit of writing ""$s(\cdot)$"" rather than ""$s(x)$"", which would be easier to parse (IMO)?",,"['functions', 'notation']"
91,"Can the cosine function be written in ""simpler"" expressions?","Can the cosine function be written in ""simpler"" expressions?",,"I recently found that the constants $\pi$ and $\phi=\frac{1+\sqrt{5}}{2} $ can be related by the identity  $$ 2\cos \frac{\pi}{5} = \phi. $$ Is there some way to write the cosine function by ""simpler"" mathematical expressions?","I recently found that the constants $\pi$ and $\phi=\frac{1+\sqrt{5}}{2} $ can be related by the identity  $$ 2\cos \frac{\pi}{5} = \phi. $$ Is there some way to write the cosine function by ""simpler"" mathematical expressions?",,"['functions', 'trigonometry']"
92,Uniqueness of exponential function,Uniqueness of exponential function,,"To my knowledge, the exponential function is the unique function satisfying $f'=f$ and $f(0)=1$ however, unless I've made a mistake, we have $$\frac{\partial}{\partial x} (ax)^x = x (ax)^{x-1} a = ax (ax)^{x-1} = (ax)^x$$ and $$(a0)^0 = 0^0 =1$$ so I feel like I must be missing something special about $e^x$.  Any pointers would be greatly appreciated.","To my knowledge, the exponential function is the unique function satisfying $f'=f$ and $f(0)=1$ however, unless I've made a mistake, we have $$\frac{\partial}{\partial x} (ax)^x = x (ax)^{x-1} a = ax (ax)^{x-1} = (ax)^x$$ and $$(a0)^0 = 0^0 =1$$ so I feel like I must be missing something special about $e^x$.  Any pointers would be greatly appreciated.",,"['functions', 'exponential-function']"
93,"If a function is undefined at a point, is it also discontinuous at that point?","If a function is undefined at a point, is it also discontinuous at that point?",,"I posted a solution here with an illustration (see below) and commented that the function was discontinuous at $x=1$, where it is undefined. Someone told me, no, it is undefined but continuous. Now I'm confused. I would have thought that the point $(1, -1/2)$ in the graph below should be designated with a hollow point (a point that isn't filled in) to demonstrate that that point is not actually on the graph. Furthermore, I thought that this hole would constitute a discontinuity. If I need to be set straight here, could someone please help me out?","I posted a solution here with an illustration (see below) and commented that the function was discontinuous at $x=1$, where it is undefined. Someone told me, no, it is undefined but continuous. Now I'm confused. I would have thought that the point $(1, -1/2)$ in the graph below should be designated with a hollow point (a point that isn't filled in) to demonstrate that that point is not actually on the graph. Furthermore, I thought that this hole would constitute a discontinuity. If I need to be set straight here, could someone please help me out?",,"['real-analysis', 'functions', 'continuity']"
94,"English for ""prolongement"" or ""Fortsetzung""?","English for ""prolongement"" or ""Fortsetzung""?",,"I'm sorry if that's not the right place to ask for, wikipedia failed to give me the correct word... What's the English for a function that is defined on a larger domain than the original function and coincides with it on the original domain? Is it ""extension"" or ""continuation"" or something else?","I'm sorry if that's not the right place to ask for, wikipedia failed to give me the correct word... What's the English for a function that is defined on a larger domain than the original function and coincides with it on the original domain? Is it ""extension"" or ""continuation"" or something else?",,"['functions', 'terminology', 'translation-request', 'mathematical-french', 'mathematical-german']"
95,$F(x)+G(y)= e^{x+y}?$,,F(x)+G(y)= e^{x+y}?,"Are there functions $F(x)$, $G(y)$, such that  $F(x)+G(y)=e^{x+y}$ , where $x,y$ are real numbers? I have been trying all elementary functions, and have no clues on what else I could do.","Are there functions $F(x)$, $G(y)$, such that  $F(x)+G(y)=e^{x+y}$ , where $x,y$ are real numbers? I have been trying all elementary functions, and have no clues on what else I could do.",,"['functions', 'exponential-function']"
96,Is the greatest integer function periodic?,Is the greatest integer function periodic?,,"Can we call the greatest integer function as a periodic function with no fundamental period or is it just non-periodic. Please explain your answer. To my understanding, if we consider $f(x) = [x]$ now, $f(3) = [3] = 3$ and $f(3+0.5) = [3.5] = 3$ So, can't we say that it is periodic ( A constant function is periodic with no fundamental period ) ? But the problem is to derive the fundamental period. EDIT: After checking out some aswer I am quite inquisitive to know is it really necessary to have a fundamental period to call a function periodic? However,If you go by my book it is not.","Can we call the greatest integer function as a periodic function with no fundamental period or is it just non-periodic. Please explain your answer. To my understanding, if we consider $f(x) = [x]$ now, $f(3) = [3] = 3$ and $f(3+0.5) = [3.5] = 3$ So, can't we say that it is periodic ( A constant function is periodic with no fundamental period ) ? But the problem is to derive the fundamental period. EDIT: After checking out some aswer I am quite inquisitive to know is it really necessary to have a fundamental period to call a function periodic? However,If you go by my book it is not.",,['functions']
97,"Prove or disprove: Let $f$ be a non-constant polynomial, then $f(x)f(1/x)=1~\Rightarrow~f(x)=\pm x^n,$ for some $n \in \Bbb N$","Prove or disprove: Let  be a non-constant polynomial, then  for some","f f(x)f(1/x)=1~\Rightarrow~f(x)=\pm x^n, n \in \Bbb N","Prove or disprove: Let $f$ be a non-constant polynomial, then $$f(x)f(1/x)=1~\Rightarrow~f(x)=\pm x^n,$$ for some $n \in \Bbb N$ . I was trying to prove: If $$f(x)=a_0+a_1x+...+a_nx^n,$$ then $a_0=a_1=...=a_{n-1}=0$ and $a_n=\pm 1$ , from the equation $$(a_0+a_1x+...+a_nx^n)(a_0+a_1/x+...+a_n/x^n)=1,$$ I can see this yields $a_0^2+a_1^2+...+a_n^2=1$ , then how to reach at $a_0=a_1=...=a_{n-1}=0$ ?","Prove or disprove: Let be a non-constant polynomial, then for some . I was trying to prove: If then and , from the equation I can see this yields , then how to reach at ?","f f(x)f(1/x)=1~\Rightarrow~f(x)=\pm x^n, n \in \Bbb N f(x)=a_0+a_1x+...+a_nx^n, a_0=a_1=...=a_{n-1}=0 a_n=\pm 1 (a_0+a_1x+...+a_nx^n)(a_0+a_1/x+...+a_n/x^n)=1, a_0^2+a_1^2+...+a_n^2=1 a_0=a_1=...=a_{n-1}=0","['real-analysis', 'functions', 'polynomials']"
98,Finding $\displaystyle \sum \limits _{n=1}^{\infty}\frac{(-1)^n (H_{2n}-H_{n})}{n(2)^n \binom{2n}{n}}$,Finding,\displaystyle \sum \limits _{n=1}^{\infty}\frac{(-1)^n (H_{2n}-H_{n})}{n(2)^n \binom{2n}{n}},I want to find the closed form of: $\displaystyle \tag*{} \sum \limits _{n=1}^{\infty}\frac{(-1)^n (H_{2n}-H_{n})}{n(2)^n \binom{2n}{n}}$ Where $H_{k}$ is $k^{\text{th}}$ harmonic number Can anyone tell me the value of the sum using Mathematica?,I want to find the closed form of: Where is harmonic number Can anyone tell me the value of the sum using Mathematica?,\displaystyle \tag*{} \sum \limits _{n=1}^{\infty}\frac{(-1)^n (H_{2n}-H_{n})}{n(2)^n \binom{2n}{n}} H_{k} k^{\text{th}},"['functions', 'summation']"
99,Is a bijective function always invertible?,Is a bijective function always invertible?,,"I know that in order for a function to be invertible, it must be bijective, but does that mean that all bijective functions are invertible?","I know that in order for a function to be invertible, it must be bijective, but does that mean that all bijective functions are invertible?",,['functions']
