,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,The dual space of a product space,The dual space of a product space,,Suppose $\prod^n L^1(I) $ is the product space of n $L^1$ integrable functions. What would be its dual space of continous linear functionals? would it be $\prod^n L^{\infty}(I)$? Do I need the norm for the product space to define the dual?,Suppose $\prod^n L^1(I) $ is the product space of n $L^1$ integrable functions. What would be its dual space of continous linear functionals? would it be $\prod^n L^{\infty}(I)$? Do I need the norm for the product space to define the dual?,,"['real-analysis', 'functional-analysis', 'lebesgue-integral']"
1,"Prob. 6, Sec. 4.2 in Kreyszig's functional analysis book: Continuity of a subadditive functional at zero implies continuity","Prob. 6, Sec. 4.2 in Kreyszig's functional analysis book: Continuity of a subadditive functional at zero implies continuity",,"Let $X$ be a real normed space, and let $p \colon X \to \mathbb{R}$ be a functional such that  $$ p(x+y) \leq p(x) + p(y) \ \mbox{ for all } \ x, y \in X$$ and such that  $$p(\theta) = 0, \ \mbox{ where $\theta$ denotes the zero vector in $X$.} $$ Suppose that $p$ is continuous at $\theta$. Then how to show that $p$ is continuous at any point $v$ of $X$? Since $p$ is continuous at $\theta$, given $\epsilon > 0$, there is a $\delta >0$ such that, for all $x \in X$ with $\Vert x - \theta \Vert < \delta$, we have $$\vert p(x) - p(\theta) \vert = \vert p(x) \vert < \epsilon.$$ What next?","Let $X$ be a real normed space, and let $p \colon X \to \mathbb{R}$ be a functional such that  $$ p(x+y) \leq p(x) + p(y) \ \mbox{ for all } \ x, y \in X$$ and such that  $$p(\theta) = 0, \ \mbox{ where $\theta$ denotes the zero vector in $X$.} $$ Suppose that $p$ is continuous at $\theta$. Then how to show that $p$ is continuous at any point $v$ of $X$? Since $p$ is continuous at $\theta$, given $\epsilon > 0$, there is a $\delta >0$ such that, for all $x \in X$ with $\Vert x - \theta \Vert < \delta$, we have $$\vert p(x) - p(\theta) \vert = \vert p(x) \vert < \epsilon.$$ What next?",,"['real-analysis', 'analysis', 'functional-analysis', 'normed-spaces']"
2,"Proving that $x,y \in \ell^2(\Bbb N) \implies x+y \in \ell^2(\Bbb N)$.",Proving that .,"x,y \in \ell^2(\Bbb N) \implies x+y \in \ell^2(\Bbb N)","I want to prove that $x,y \in \ell^2(\Bbb N) \implies x+y \in \ell^2(\Bbb N)$. I'm damn sure that there is a quick way to do this, but I'm not seeing it. I am capable of proving Young, Hölder and Minkowski's inequalities to estabilish the result for $\ell^p(\Bbb N)$, but that seems overkill here and I don't want to do that. Can someone point me the way, please? Thanks. Obs.: $\ell^2(\Bbb N) = \left\{  (x_n)_{n \in \Bbb N} \mid x_n \in \Bbb C~ \forall\,n, \text{ and } \sum_{n \in \Bbb N}|x_n|^2 < +\infty \right\}$","I want to prove that $x,y \in \ell^2(\Bbb N) \implies x+y \in \ell^2(\Bbb N)$. I'm damn sure that there is a quick way to do this, but I'm not seeing it. I am capable of proving Young, Hölder and Minkowski's inequalities to estabilish the result for $\ell^p(\Bbb N)$, but that seems overkill here and I don't want to do that. Can someone point me the way, please? Thanks. Obs.: $\ell^2(\Bbb N) = \left\{  (x_n)_{n \in \Bbb N} \mid x_n \in \Bbb C~ \forall\,n, \text{ and } \sum_{n \in \Bbb N}|x_n|^2 < +\infty \right\}$",,"['functional-analysis', 'lp-spaces']"
3,Convex cone of nonnegative functions in L2 has empty interior,Convex cone of nonnegative functions in L2 has empty interior,,"Convex cone $S:=\{f\in L^2(\mathbb{R},\mu):f\geq 0\}$ has empty   interior in $L^2(\mathbb{R},\mu)$ when $\mu$ is Lebesgue measure. I wanted to prove it but i have major holes in my knowledge of measure and integral theory. So, I want to prove that for every $f\in S$ and $\varepsilon >0$ exists some $g\in L^2(\mathbb{R},\mu)$ such that $||f-g||_2<\varepsilon$ and $g$ has at least one negative value. I am a little bit confused with this also, is one negative value enough or i need a set of negative values with positive measure? (there is no a.e. in definition of $S$) So, if only one negative value is enough i can  define function $g$ to be same as $f$ everywhere except in some point $x_0$ and there I put $g(x_0)$ has negative value. Then $g$ would not be nonnegative and $||f-g||_2=\sqrt{\int_{\mathbb{R}}^{}|f-g|^2d\mu}=0$ since one point doesnt effect the integral. Is this ok? What conclusions can i make of $f\in S$ in general? I know it must be bounded. Does $f$ goes to zero when $x\rightarrow\pm\infty$? Is there a type of statement that says something like: $\forall\varepsilon >0$ there exists $E\in\mathcal{B}(\mathbb{R}), \mu(E)>0$ so that $\int_{E}^{}f<\varepsilon$. And if so must it be $\mu(E)=\infty$? I would really appreciate your comments and helpful tips. This is not any type of homework, I graduated years ago, I just never really grasped whole Lebesgue integration and everything that goes with it and i am looking for helpful tips. I apologize in front for my language mistakes since I'm not a native speaker.","Convex cone $S:=\{f\in L^2(\mathbb{R},\mu):f\geq 0\}$ has empty   interior in $L^2(\mathbb{R},\mu)$ when $\mu$ is Lebesgue measure. I wanted to prove it but i have major holes in my knowledge of measure and integral theory. So, I want to prove that for every $f\in S$ and $\varepsilon >0$ exists some $g\in L^2(\mathbb{R},\mu)$ such that $||f-g||_2<\varepsilon$ and $g$ has at least one negative value. I am a little bit confused with this also, is one negative value enough or i need a set of negative values with positive measure? (there is no a.e. in definition of $S$) So, if only one negative value is enough i can  define function $g$ to be same as $f$ everywhere except in some point $x_0$ and there I put $g(x_0)$ has negative value. Then $g$ would not be nonnegative and $||f-g||_2=\sqrt{\int_{\mathbb{R}}^{}|f-g|^2d\mu}=0$ since one point doesnt effect the integral. Is this ok? What conclusions can i make of $f\in S$ in general? I know it must be bounded. Does $f$ goes to zero when $x\rightarrow\pm\infty$? Is there a type of statement that says something like: $\forall\varepsilon >0$ there exists $E\in\mathcal{B}(\mathbb{R}), \mu(E)>0$ so that $\int_{E}^{}f<\varepsilon$. And if so must it be $\mu(E)=\infty$? I would really appreciate your comments and helpful tips. This is not any type of homework, I graduated years ago, I just never really grasped whole Lebesgue integration and everything that goes with it and i am looking for helpful tips. I apologize in front for my language mistakes since I'm not a native speaker.",,"['functional-analysis', 'measure-theory', 'lebesgue-measure']"
4,$\sqrt{y}+\sqrt{x}=\sqrt{A}$. prove that x-intercept + y-intercept of any tangent = A [closed],. prove that x-intercept + y-intercept of any tangent = A [closed],\sqrt{y}+\sqrt{x}=\sqrt{A},"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question This  is equation of a  curve $\sqrt{y}+\sqrt{x}=\sqrt{A}$ $A$ is  a positive constant $T$ is a tangent of  the  curve from any point on it $B$ is the y-intercept  of $T$ $C$ is the x-intercept  of $T$ Prove that $B+C=A.$","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question This  is equation of a  curve is  a positive constant is a tangent of  the  curve from any point on it is the y-intercept  of is the x-intercept  of Prove that",\sqrt{y}+\sqrt{x}=\sqrt{A} A T B T C T B+C=A.,"['calculus', 'functional-analysis', 'functions', 'derivatives']"
5,Dominated positive operator,Dominated positive operator,,"I want that if $H$ Hilbert space where $A$, $B$ are positive operators on $H$ Hilbert space, $0 \leq (Ax|x) \leq (Bx | x)$ $\forall x$, does this mean $(A^2x|x) \leq (B^2x|x)$? Thank you","I want that if $H$ Hilbert space where $A$, $B$ are positive operators on $H$ Hilbert space, $0 \leq (Ax|x) \leq (Bx | x)$ $\forall x$, does this mean $(A^2x|x) \leq (B^2x|x)$? Thank you",,['functional-analysis']
6,"Suppose $\mu(X)=1$ and $f, g $are nonnegative function such that $fg \geq 1$ a.e. prove $(\int fd\mu)(\int gd\mu) \geq 1$.",Suppose  and are nonnegative function such that  a.e. prove .,"\mu(X)=1 f, g  fg \geq 1 (\int fd\mu)(\int gd\mu) \geq 1","I have a problem in $L^p$ space. Suppose $\mu(X)=1$ and $f, g $are nonnegative function such that $fg \geq 1$ a.e. prove $(\int fd\mu)(\int gd\mu) \geq 1$. I have no any idea to prove that.  Holder inequality? thanks","I have a problem in $L^p$ space. Suppose $\mu(X)=1$ and $f, g $are nonnegative function such that $fg \geq 1$ a.e. prove $(\int fd\mu)(\int gd\mu) \geq 1$. I have no any idea to prove that.  Holder inequality? thanks",,"['real-analysis', 'functional-analysis', 'lp-spaces']"
7,Embedding vs continuous injection (in topological vector spaces),Embedding vs continuous injection (in topological vector spaces),,"When working with topological vector spaces (say $X,Y$), the term “embedding” is often used for a continuous injection $f:X\rightarrow Y$. Now, $f$   is of course a bijection onto its image, but it's not necessarily a homeomorphism (as we would normally require of an embedding in topology). Can anyone explain to me exactly what we're loosing by not having $X$   and $f(X)$ homeomorphic? And is there something special about linear spaces that makes whatever we're missing (more or less) irrelevant? I suppose that the subspace topology on $f(X)$   must in some sense be coarser than the topology on $X$   if the inverse of $f$   (defined on the range of $f$  ) fails to be continuous","When working with topological vector spaces (say $X,Y$), the term “embedding” is often used for a continuous injection $f:X\rightarrow Y$. Now, $f$   is of course a bijection onto its image, but it's not necessarily a homeomorphism (as we would normally require of an embedding in topology). Can anyone explain to me exactly what we're loosing by not having $X$   and $f(X)$ homeomorphic? And is there something special about linear spaces that makes whatever we're missing (more or less) irrelevant? I suppose that the subspace topology on $f(X)$   must in some sense be coarser than the topology on $X$   if the inverse of $f$   (defined on the range of $f$  ) fails to be continuous",,"['general-topology', 'functional-analysis']"
8,Compact normed vector space,Compact normed vector space,,Let $V$ be a normed vector space.If $V\neq \{0\}$ is it true that our space cannot be compact?,Let $V$ be a normed vector space.If $V\neq \{0\}$ is it true that our space cannot be compact?,,"['functional-analysis', 'compactness']"
9,A reflexive Banach space is separable iff its dual is separable,A reflexive Banach space is separable iff its dual is separable,,"Let $(X,||\cdot||)$ be a reflexive Banach space. Prove that $X$ is separable if and only if $X'$ (the dual space of $X$) is separable. Does anyone have a hint for me? I have no idea where to begin","Let $(X,||\cdot||)$ be a reflexive Banach space. Prove that $X$ is separable if and only if $X'$ (the dual space of $X$) is separable. Does anyone have a hint for me? I have no idea where to begin",,['functional-analysis']
10,"$p$ is a projection iff $p$ is normal the spectrum of $p$ is contained in $\{0,1\}$",is a projection iff  is normal the spectrum of  is contained in,"p p p \{0,1\}","I want to know why the following claim is true: Let $A$ be a $C^*$-algebra. $p\in A$ is a projection (that means $p^2=p^*=p$) iff p is normal and $\sigma (p)\subseteq \{0,1\}$. ""$\implies$"" why p normal, it is clear. I know that $\sigma(p)\subseteq [-1,1]$, since $\sigma(p)\subseteq [-\|p\|,\|p\|]$ and $p$ projection, therefore: $\|p\|=1$. But its not enough. (If $A$ is a vector space and $p$ an endomorphism, then i know how to prove it, i consider $p^2-p=p(p-1)$ ). Maybe i have to use the continuous functional calculus, but i dont know how. Can anyone help me? And can you give me a hint how to do ""$\impliedby$"" ? Regards Edit: Maybe i could use $f(x)=x^2-x$ and functional calculus to prove ""$\impliedby$"". But I don't know how to do this in detail.","I want to know why the following claim is true: Let $A$ be a $C^*$-algebra. $p\in A$ is a projection (that means $p^2=p^*=p$) iff p is normal and $\sigma (p)\subseteq \{0,1\}$. ""$\implies$"" why p normal, it is clear. I know that $\sigma(p)\subseteq [-1,1]$, since $\sigma(p)\subseteq [-\|p\|,\|p\|]$ and $p$ projection, therefore: $\|p\|=1$. But its not enough. (If $A$ is a vector space and $p$ an endomorphism, then i know how to prove it, i consider $p^2-p=p(p-1)$ ). Maybe i have to use the continuous functional calculus, but i dont know how. Can anyone help me? And can you give me a hint how to do ""$\impliedby$"" ? Regards Edit: Maybe i could use $f(x)=x^2-x$ and functional calculus to prove ""$\impliedby$"". But I don't know how to do this in detail.",,['functional-analysis']
11,Resolvent also self-adjoint operator,Resolvent also self-adjoint operator,,"If I have a self-adjoint operator $U : \operatorname{dom}(U) \subset H \rightarrow H$ and $\lambda \in \rho(U)$, then I assume assume that it is correct that the operator $(U - \lambda I)^{-1} \in L(H)$ is also self-adjoint?(for $\lambda \in \mathbb{R}) I mean, if $U$ would have been bounded, then I guess this would have been clear, as $(U- \lambda I)$ would have been self-adjoint and $(T^*)^{-1}= (T^{-1})^*$ holds, but in this more general setting, I am not so sure anymore. Edit: So one question, if I have a self-adjoint operator $T$ (unbounded) and I have $((T-\lambda)^{-1})^{*}$ where $\lambda \in \rho(T)$, then it is clear that $(T-\overline{\lambda})^{-1}$ is also a bounded operator. So if I now show that $(f,g) \in G(((T-\lambda)^*)^{-1}) \Leftrightarrow  (g,f) \in G((T-\lambda)^*) \text{ and }\forall (h,k) \in G((T-\lambda)): \langle k,g \rangle = \langle h,f \rangle  \Leftrightarrow (f,g) \in G(((T-\lambda)^{-1})^{*}) \text{ and }  \forall (k,h) \in G((T-\lambda)^{-1}) : \langle k,g \rangle  = \langle h,f\rangle$, then this is the full proof?","If I have a self-adjoint operator $U : \operatorname{dom}(U) \subset H \rightarrow H$ and $\lambda \in \rho(U)$, then I assume assume that it is correct that the operator $(U - \lambda I)^{-1} \in L(H)$ is also self-adjoint?(for $\lambda \in \mathbb{R}) I mean, if $U$ would have been bounded, then I guess this would have been clear, as $(U- \lambda I)$ would have been self-adjoint and $(T^*)^{-1}= (T^{-1})^*$ holds, but in this more general setting, I am not so sure anymore. Edit: So one question, if I have a self-adjoint operator $T$ (unbounded) and I have $((T-\lambda)^{-1})^{*}$ where $\lambda \in \rho(T)$, then it is clear that $(T-\overline{\lambda})^{-1}$ is also a bounded operator. So if I now show that $(f,g) \in G(((T-\lambda)^*)^{-1}) \Leftrightarrow  (g,f) \in G((T-\lambda)^*) \text{ and }\forall (h,k) \in G((T-\lambda)): \langle k,g \rangle = \langle h,f \rangle  \Leftrightarrow (f,g) \in G(((T-\lambda)^{-1})^{*}) \text{ and }  \forall (k,h) \in G((T-\lambda)^{-1}) : \langle k,g \rangle  = \langle h,f\rangle$, then this is the full proof?",,"['real-analysis', 'analysis']"
12,An abelian Banach algebra without characters,An abelian Banach algebra without characters,,Can one give an example of an abelian Banach algebra with empty character space? Such algebra must be necessarily non-unital. I couldn't find any examples of such algebras. Thanks!,Can one give an example of an abelian Banach algebra with empty character space? Such algebra must be necessarily non-unital. I couldn't find any examples of such algebras. Thanks!,,"['functional-analysis', 'examples-counterexamples', 'banach-algebras']"
13,Why does a sequence in $\ell^2$ always converge to zero?,Why does a sequence in  always converge to zero?,\ell^2,"I was taking the MOOC on Functional Analysis offered on coursera and in one of the videos in which the professor gives an example of  a sequence which converges in the weak topology but not in the strong topology, he gives an example of an $\ell^2$ sequence $(u_k)=\delta_{kn}$ $u_1=\{1,0,0,...\}$ $u_2=\{0,1,0,...\}$ He then defines the product $\langle u_k,v\rangle$ where $v \in \ell^2$ and claims that $\lim_{k \to \infty}\langle u_k,v\rangle=0$ as $v_k$ is convergent to zero. I do not understand why all the sequences in $\ell^2$ converge to zero.","I was taking the MOOC on Functional Analysis offered on coursera and in one of the videos in which the professor gives an example of  a sequence which converges in the weak topology but not in the strong topology, he gives an example of an $\ell^2$ sequence $(u_k)=\delta_{kn}$ $u_1=\{1,0,0,...\}$ $u_2=\{0,1,0,...\}$ He then defines the product $\langle u_k,v\rangle$ where $v \in \ell^2$ and claims that $\lim_{k \to \infty}\langle u_k,v\rangle=0$ as $v_k$ is convergent to zero. I do not understand why all the sequences in $\ell^2$ converge to zero.",,"['real-analysis', 'functional-analysis']"
14,Orthogonal complement of vector spaces,Orthogonal complement of vector spaces,,Let $V$ be a vector space. Here I do not restrict $V$ to be finite dimensional. Let $S$ be a vector subspace of $V$. Why is $S\subset (S^{\perp})^{\perp}$ rather than $S= (S^{\perp})^{\perp}$?,Let $V$ be a vector space. Here I do not restrict $V$ to be finite dimensional. Let $S$ be a vector subspace of $V$. Why is $S\subset (S^{\perp})^{\perp}$ rather than $S= (S^{\perp})^{\perp}$?,,"['linear-algebra', 'functional-analysis']"
15,"Riesz representation theorem, uniqueness of the measure.","Riesz representation theorem, uniqueness of the measure.",,"This question concerns theorem 2.14 (Riesz representation theorem) of Rudin's book , in particular, his claim that if $\mu_1,\mu_2$ are measures satisfying the hypothesis of the theorem then, $\mu_1=\mu_2$ . However, the question will be made in order to be self contained. Let $(X,\mathfrak{M},\mu)$ be a measure space, where $X$ is a locally compact Hausdorff space. Consider the following conditions (regularity of measures): (c) For every $E\in\mathfrak{M}$ $$\mu(E)=\inf\{\mu(V):\ E\subset V,\ V\ \mbox{open}\}.$$ (d) For every open set $E$ and for every $E\in\mathfrak{M}$ , with $\mu(E)$ , we have that $$\mu(E)=\sup\{\mu(K):\ K\subset E,\ K\ \mbox{compact}\}.$$ Assume that $\mu_1,\mu_2$ are measures satisfying (c) and (d). Based on conditions (c), (d) above, why it is then sufficient to prove that $\mu_1(K)=\mu_2(K)$ for all $K$ compact, in order to prove that $\mu_1=\mu_2$ ? thanks.","This question concerns theorem 2.14 (Riesz representation theorem) of Rudin's book , in particular, his claim that if are measures satisfying the hypothesis of the theorem then, . However, the question will be made in order to be self contained. Let be a measure space, where is a locally compact Hausdorff space. Consider the following conditions (regularity of measures): (c) For every (d) For every open set and for every , with , we have that Assume that are measures satisfying (c) and (d). Based on conditions (c), (d) above, why it is then sufficient to prove that for all compact, in order to prove that ? thanks.","\mu_1,\mu_2 \mu_1=\mu_2 (X,\mathfrak{M},\mu) X E\in\mathfrak{M} \mu(E)=\inf\{\mu(V):\ E\subset V,\ V\ \mbox{open}\}. E E\in\mathfrak{M} \mu(E) \mu(E)=\sup\{\mu(K):\ K\subset E,\ K\ \mbox{compact}\}. \mu_1,\mu_2 \mu_1(K)=\mu_2(K) K \mu_1=\mu_2","['functional-analysis', 'measure-theory', 'riesz-representation-theorem']"
16,Rellich's theorem for Sobolev space on the torus,Rellich's theorem for Sobolev space on the torus,,"From John Roe: Elliptic operators, topology and asymptotic methods , page 73: Let $H^{k}$ be the Soblev space defined on the torus $\mathbb{T}^{n}$ with the discrete $k$-norm: $$ \langle f_{1}, f_{2}\rangle_{k}=(2\pi)^{k}\sum_{v\in \mathbb{Z}^{n}}\tilde{f}_{1}(v)\overline{\tilde{f}_{2}}(v)(1+|v|^{2})^{k} $$ John Roe claimed that there is a Rellich type compact embedding theorem available. If $k_{1}<k_{2}$, then the inclusion operator $H^{k_{2}}\rightarrow H^{k_{1}}$ is a compact linear operator. The proof goes with the following steps: Let $B=\{x:|x|=1,x\in H^{k_{2}}\}$. Let $\epsilon>0$, choose subspace $Z\subset H^{k_{2}}$ such that $\dim (H^{k_{2}}/Z)<\infty$, and for all $f\in B\cap Z$, $|f|_{k_{1}}<\epsilon$. The unit ball of $H^{k_{2}}/Z$ is compact, so can be covered by finitely many balls of radius $\epsilon$. Hence $B$ can be covered by finitely many balls of radius $2\epsilon$ in $H^{k_{1}}$ norm. Since $\epsilon$ is arbitrary, $B$ is totally bounded and compact in $H^{k_{1}}$. Therefore the inclusion map is compact. Here $Z$ can be explicitly constructed by taking it to be the space $$ \{f:\tilde{f}(v)=0,\forall v>N \} $$ where $N$ is some large enough constant. I am fine with the strategy, but I am a little disturbed by $Z$'s construction at here. It is not clear to me that give $N$ large enough, I would be able to force all $f\in B\cap Z$ to have small enough norm. Can someone give me a hint? Thinking this in terms of Fourier series in the circle, it seems the terms $\tilde{f}(v)$ for $v>N$ can be arbitrarily close to $1$ and $|f|$ would also be quite large. For example if $k_{2}=3, k_{1}=2$, then there seem to be no reason $\tilde{f}$'s $H^{2}$ norm should be really small if the first $N-1$ terms are zero. I do not really know otherwise how to construct $Z$.","From John Roe: Elliptic operators, topology and asymptotic methods , page 73: Let $H^{k}$ be the Soblev space defined on the torus $\mathbb{T}^{n}$ with the discrete $k$-norm: $$ \langle f_{1}, f_{2}\rangle_{k}=(2\pi)^{k}\sum_{v\in \mathbb{Z}^{n}}\tilde{f}_{1}(v)\overline{\tilde{f}_{2}}(v)(1+|v|^{2})^{k} $$ John Roe claimed that there is a Rellich type compact embedding theorem available. If $k_{1}<k_{2}$, then the inclusion operator $H^{k_{2}}\rightarrow H^{k_{1}}$ is a compact linear operator. The proof goes with the following steps: Let $B=\{x:|x|=1,x\in H^{k_{2}}\}$. Let $\epsilon>0$, choose subspace $Z\subset H^{k_{2}}$ such that $\dim (H^{k_{2}}/Z)<\infty$, and for all $f\in B\cap Z$, $|f|_{k_{1}}<\epsilon$. The unit ball of $H^{k_{2}}/Z$ is compact, so can be covered by finitely many balls of radius $\epsilon$. Hence $B$ can be covered by finitely many balls of radius $2\epsilon$ in $H^{k_{1}}$ norm. Since $\epsilon$ is arbitrary, $B$ is totally bounded and compact in $H^{k_{1}}$. Therefore the inclusion map is compact. Here $Z$ can be explicitly constructed by taking it to be the space $$ \{f:\tilde{f}(v)=0,\forall v>N \} $$ where $N$ is some large enough constant. I am fine with the strategy, but I am a little disturbed by $Z$'s construction at here. It is not clear to me that give $N$ large enough, I would be able to force all $f\in B\cap Z$ to have small enough norm. Can someone give me a hint? Thinking this in terms of Fourier series in the circle, it seems the terms $\tilde{f}(v)$ for $v>N$ can be arbitrarily close to $1$ and $|f|$ would also be quite large. For example if $k_{2}=3, k_{1}=2$, then there seem to be no reason $\tilde{f}$'s $H^{2}$ norm should be really small if the first $N-1$ terms are zero. I do not really know otherwise how to construct $Z$.",,"['functional-analysis', 'sobolev-spaces', 'compact-operators']"
17,Kadison's Inequality,Kadison's Inequality,,Let $\mathcal{A}$ be a C*-algebra and $\omega$ a positive linear functional. Is there a simple proof for Kadison's inequality: $$|\omega(A)|^2\leq\|\omega\|\cdot\omega(A^*A)$$,Let $\mathcal{A}$ be a C*-algebra and $\omega$ a positive linear functional. Is there a simple proof for Kadison's inequality: $$|\omega(A)|^2\leq\|\omega\|\cdot\omega(A^*A)$$,,"['functional-analysis', 'operator-theory', 'operator-algebras']"
18,"Bounded, surjective linear operator between Banach spaces","Bounded, surjective linear operator between Banach spaces",,"How can I show that for a given surjective linear operator $T: X \to Y$ between Banach spaces, if there exists an $\epsilon > 0$ such that $||Tx|| \geq \epsilon||x||$ for all $x \in X$, then $T$ is bounded? I'm not really sure what to do with the surjectivity here.","How can I show that for a given surjective linear operator $T: X \to Y$ between Banach spaces, if there exists an $\epsilon > 0$ such that $||Tx|| \geq \epsilon||x||$ for all $x \in X$, then $T$ is bounded? I'm not really sure what to do with the surjectivity here.",,"['real-analysis', 'functional-analysis', 'operator-theory', 'banach-spaces']"
19,"approximating continuous function on $[0,1]$ by monotone increasing polynomials",approximating continuous function on  by monotone increasing polynomials,"[0,1]","Let $f\in C[0,1]$ be real-valued. Prove that there is monotone increasing sequence of polynomials $\{p_n(x)\}^\infty_{n=1}$ converging uniformly on $[0,1]$ to $f(x)$. Yea, it should be done by stone-Weierstrass theorem, there I will get simply a sequence of polynomials that converges to $f$. Is there any way we can define this polynomial to make monotone increasing polynomials? thanks for helping","Let $f\in C[0,1]$ be real-valued. Prove that there is monotone increasing sequence of polynomials $\{p_n(x)\}^\infty_{n=1}$ converging uniformly on $[0,1]$ to $f(x)$. Yea, it should be done by stone-Weierstrass theorem, there I will get simply a sequence of polynomials that converges to $f$. Is there any way we can define this polynomial to make monotone increasing polynomials? thanks for helping",,"['real-analysis', 'functional-analysis']"
20,Identifying the dual group of a locally compact abelian group with the spectrum of $ {L^{1}}(G) $.,Identifying the dual group of a locally compact abelian group with the spectrum of ., {L^{1}}(G) ,"Folland stated the following theorem in his book A Course in Abstract Harmonic Analysis on Page 88. The dual group of a locally compact abelian group can be identified with the spectrum of $ {L^{1}}(G) $. It came without a proof, so could anyone kindly provide me with some comments on my attempt below? Proof : Let $ G $ be a locally compact abelian group and $ \widehat{G} $ the dual group of $ G $, i.e., $ \widehat{G} \stackrel{\text{def}}{=} \text{Hom}(G,\mathbb{T}) $, where $ \mathbb{T} \stackrel{\text{def}}{=} \{ z \in \mathbb{C}: |z| = 1 \} $. The spectrum of $ {L^{1}}(G) $, denoted by $ \text{Spec}({L^{1}}(G)) $, is defined as $$ \text{Spec}({L^{1}}(G)) \stackrel{\text{def}}{=} \{ F \in {L^{1}}(G)^{\star} \mid F \not\equiv 0 ~ \text{and} ~ F(f * g) = F(f) \cdot F(g) \}, $$ where $ * $ denotes convolution. In other words, $ \text{Spec}({L^{1}}(G)) $ is the set of all non-zero multiplicative linear functionals on $ {L^{1}}(G) $. To show that $ \widehat{G} $ can be identified with $ \text{Spec}({L^{1}}(G)) $, we need to construct a $ 1 $-$ 1 $ correspondence $ \widehat{G} \to \text{Spec}({L^{1}}(G)) $. Define such a correspondence as follows. Every $ \beta \in \widehat{G} $ defines a multiplicative linear functional $ \hat{\beta} $ on $ {L^{1}}(G) $ by $$ \forall f \in {L^{1}}(G): \quad \hat{\beta}(f) \stackrel{\text{def}}{=} \int_{G} f(g) \beta(g) ~ \mathrm{d}{g}. \quad \blacksquare $$ Question: Did I define the $ 1 $-$ 1 $ correspondence correctly?","Folland stated the following theorem in his book A Course in Abstract Harmonic Analysis on Page 88. The dual group of a locally compact abelian group can be identified with the spectrum of $ {L^{1}}(G) $. It came without a proof, so could anyone kindly provide me with some comments on my attempt below? Proof : Let $ G $ be a locally compact abelian group and $ \widehat{G} $ the dual group of $ G $, i.e., $ \widehat{G} \stackrel{\text{def}}{=} \text{Hom}(G,\mathbb{T}) $, where $ \mathbb{T} \stackrel{\text{def}}{=} \{ z \in \mathbb{C}: |z| = 1 \} $. The spectrum of $ {L^{1}}(G) $, denoted by $ \text{Spec}({L^{1}}(G)) $, is defined as $$ \text{Spec}({L^{1}}(G)) \stackrel{\text{def}}{=} \{ F \in {L^{1}}(G)^{\star} \mid F \not\equiv 0 ~ \text{and} ~ F(f * g) = F(f) \cdot F(g) \}, $$ where $ * $ denotes convolution. In other words, $ \text{Spec}({L^{1}}(G)) $ is the set of all non-zero multiplicative linear functionals on $ {L^{1}}(G) $. To show that $ \widehat{G} $ can be identified with $ \text{Spec}({L^{1}}(G)) $, we need to construct a $ 1 $-$ 1 $ correspondence $ \widehat{G} \to \text{Spec}({L^{1}}(G)) $. Define such a correspondence as follows. Every $ \beta \in \widehat{G} $ defines a multiplicative linear functional $ \hat{\beta} $ on $ {L^{1}}(G) $ by $$ \forall f \in {L^{1}}(G): \quad \hat{\beta}(f) \stackrel{\text{def}}{=} \int_{G} f(g) \beta(g) ~ \mathrm{d}{g}. \quad \blacksquare $$ Question: Did I define the $ 1 $-$ 1 $ correspondence correctly?",,"['real-analysis', 'functional-analysis', 'topological-groups', 'harmonic-analysis', 'banach-algebras']"
21,Weak* compactness of the unit ball,Weak* compactness of the unit ball,,"Things that we know: In any topological space compactness implies sequential compactness If E is any topological space the then the closed unit ball  $$ B_E=\{f\in E^*; \|f\|\leq 1\} $$ is compact in the weak* topology. Now an example of Brezis Book : Let $E=l^{\infty}$ and its dual $E^*\supset l^1$.  Now consider the sequence $(f_n)\subset l^1\subset E^*$ where  $$ f_n=(0, \ldots,0,1,0\ldots) $$ Claim.:  $(f_n)$ has no convergent subsequence in the weak* topology Arguing by contradiction, suppose there is a convergent subsequence $f_{n_k}$  converging to $ f $. So we must have for any $x\in l^{\infty}$ that $$ \left<f_{n_k},x\right>\to \left<f,x\right> $$ On the other hand choose $x_0$ in the following way $$ x=(0,0,\ldots,\underbrace{1}_{n_1}, 0,0\ldots,0,\underbrace{-1}_{n_2},0,0,\ldots,\underbrace{1}_{n_3},0,\ldots,0,\underbrace{-1}_{n_4}, \ldots) $$ then  $$ \left<f_{n_k},x\right>=(-1)^k $$ which does not converge, contradiction! So  $(f_n)$ has no convergent subsequence in the weak* topology MY QUESTION : How this example does not contradict the results $1$ and $2$,  I mean, $\|f_n\|=1$ for all $n$, and  $(f_n)$ has no convergent subsequence in the weak* topology.  On the other hand $B_E=\{f\in E^*; \|f\|\leq 1\}$ is compact in the weak* topology, which means in particular, sequentially compact. ADDENDUM: compactness implies sequential compactness Let X be a compact set and $(x_n)$ a infinite sequence(infinite distinct terms), suppose the opposite i.e that $(x_n)$ does not have a accumulation point. Then for each $x\in X$ there is a neigh. $U_x$ of $x$ but containing only a finite number of elements of $\{x_n\}$. The family $\{U_x\}$ cover $X$, by passing to a finite subcover $\{U_1,\ldots,U_n\}$ we conclude that the set of the terms of $(x_n)$ must be finite. Contradiction!","Things that we know: In any topological space compactness implies sequential compactness If E is any topological space the then the closed unit ball  $$ B_E=\{f\in E^*; \|f\|\leq 1\} $$ is compact in the weak* topology. Now an example of Brezis Book : Let $E=l^{\infty}$ and its dual $E^*\supset l^1$.  Now consider the sequence $(f_n)\subset l^1\subset E^*$ where  $$ f_n=(0, \ldots,0,1,0\ldots) $$ Claim.:  $(f_n)$ has no convergent subsequence in the weak* topology Arguing by contradiction, suppose there is a convergent subsequence $f_{n_k}$  converging to $ f $. So we must have for any $x\in l^{\infty}$ that $$ \left<f_{n_k},x\right>\to \left<f,x\right> $$ On the other hand choose $x_0$ in the following way $$ x=(0,0,\ldots,\underbrace{1}_{n_1}, 0,0\ldots,0,\underbrace{-1}_{n_2},0,0,\ldots,\underbrace{1}_{n_3},0,\ldots,0,\underbrace{-1}_{n_4}, \ldots) $$ then  $$ \left<f_{n_k},x\right>=(-1)^k $$ which does not converge, contradiction! So  $(f_n)$ has no convergent subsequence in the weak* topology MY QUESTION : How this example does not contradict the results $1$ and $2$,  I mean, $\|f_n\|=1$ for all $n$, and  $(f_n)$ has no convergent subsequence in the weak* topology.  On the other hand $B_E=\{f\in E^*; \|f\|\leq 1\}$ is compact in the weak* topology, which means in particular, sequentially compact. ADDENDUM: compactness implies sequential compactness Let X be a compact set and $(x_n)$ a infinite sequence(infinite distinct terms), suppose the opposite i.e that $(x_n)$ does not have a accumulation point. Then for each $x\in X$ there is a neigh. $U_x$ of $x$ but containing only a finite number of elements of $\{x_n\}$. The family $\{U_x\}$ cover $X$, by passing to a finite subcover $\{U_1,\ldots,U_n\}$ we conclude that the set of the terms of $(x_n)$ must be finite. Contradiction!",,"['real-analysis', 'general-topology', 'analysis', 'functional-analysis']"
22,"Tridual-""Reflexive""","Tridual-""Reflexive""",,"Let $X$ be an Banach space, and $X^*$ the space of linear functionals on $X$. The dual of $X^*$ is called the bidual, and if the bidual $X^{**}=X$, we say that $X$ is a reflexive space. It is well known that the $L^p$-spaces ($1<p<\infty$) are reflexive. Now, let us define the tridual to be the dual of the bidual, $X^{***}$. Are there spaces $X$ such that $X^{***}=X$? What about ""reflexivity"" with respect to n-duals? Does this have any application?","Let $X$ be an Banach space, and $X^*$ the space of linear functionals on $X$. The dual of $X^*$ is called the bidual, and if the bidual $X^{**}=X$, we say that $X$ is a reflexive space. It is well known that the $L^p$-spaces ($1<p<\infty$) are reflexive. Now, let us define the tridual to be the dual of the bidual, $X^{***}$. Are there spaces $X$ such that $X^{***}=X$? What about ""reflexivity"" with respect to n-duals? Does this have any application?",,"['functional-analysis', 'banach-spaces']"
23,Justifying that $S=\left\{f \in X: \int f(t)dt=0\right\}$ is compact and connected,Justifying that  is compact and connected,S=\left\{f \in X: \int f(t)dt=0\right\},"Consider the space $X=C[0,1]$ with its usual sup-norm topology. Let $$S=\left\{f \in X: \int f(t)dt=0\right\}.$$ Justify: S is compact. S is connected.","Consider the space $X=C[0,1]$ with its usual sup-norm topology. Let $$S=\left\{f \in X: \int f(t)dt=0\right\}.$$ Justify: S is compact. S is connected.",,"['real-analysis', 'general-topology', 'functional-analysis']"
24,Hahn–Banach Theorem for Normed Spaces: not unique extension,Hahn–Banach Theorem for Normed Spaces: not unique extension,,"Let $\ell^{\infty}$ be the set of bounded sequences in $\mathbb{F}$, with the supremum norm. $c \subset \ell^{\infty}$ the sequences whose limit exists. Then there exists a $f \in (\ell^{\infty})'$, the dual, such that $f(x) = \lim_{n \to \infty} x(n)$ for all $x \in c$. Because we can define it on $c$ and then extend it with the Hahn-Banach theorem for Normed Spaces. My question is if there is another $g \in (\ell^{\infty})'$, $g \not = f$, with $g(x) = f(x) = \lim_{n \to \infty} x(n)$ for all $x \in c$. I tried using two different one-dimensional extensions first but I couldn't finish that proof. Any ideas? Thanks.","Let $\ell^{\infty}$ be the set of bounded sequences in $\mathbb{F}$, with the supremum norm. $c \subset \ell^{\infty}$ the sequences whose limit exists. Then there exists a $f \in (\ell^{\infty})'$, the dual, such that $f(x) = \lim_{n \to \infty} x(n)$ for all $x \in c$. Because we can define it on $c$ and then extend it with the Hahn-Banach theorem for Normed Spaces. My question is if there is another $g \in (\ell^{\infty})'$, $g \not = f$, with $g(x) = f(x) = \lim_{n \to \infty} x(n)$ for all $x \in c$. I tried using two different one-dimensional extensions first but I couldn't finish that proof. Any ideas? Thanks.",,['functional-analysis']
25,If a function f(x) has a p-norm then does it automatically have a (p-1)-norm ? or a (<p)-norm,If a function f(x) has a p-norm then does it automatically have a (p-1)-norm ? or a (<p)-norm,,Hi Id like to know if a function has a p norm does that mean it automatically has a norm for al llower values of p ?. What about higher values ?. I am trying to write a proof and would like to use this if provable. Thanks,Hi Id like to know if a function has a p norm does that mean it automatically has a norm for al llower values of p ?. What about higher values ?. I am trying to write a proof and would like to use this if provable. Thanks,,"['functional-analysis', 'normed-spaces']"
26,Finite dimensional $C^*$-algebras [closed],Finite dimensional -algebras [closed],C^*,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Show that if a $C^*$-algebra $A$ is reflexive as a Banach space, then $A$ must be finite dimentional. I tried to solve it; but, I could not. please help me for this exercise.  Thanks a lot!","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Show that if a $C^*$-algebra $A$ is reflexive as a Banach space, then $A$ must be finite dimentional. I tried to solve it; but, I could not. please help me for this exercise.  Thanks a lot!",,"['functional-analysis', 'operator-theory']"
27,How to show pre-compactness in Holder space?,How to show pre-compactness in Holder space?,,"Let $K \in \mathbb{R}^d$ be a compact set and consider the space of Hölder continuous functions $C^{0,\gamma}(K)$  with norm $||f||_{C^{0,\gamma}}:=||f||_{\infty}+\sup_{x,y \in K,x \neq y}\frac{|f(x)-f(y)|}{|x-y|^{\gamma}}$. Assume we have a bounded sequence $\{f_n\} \subset C^{0,\gamma}(K)$, i.e. $\exists C>0$ s.t. $\sup_{n}||f_n||_{C^{0,\gamma}} \leq C$. Under what conditions can we say the sequence $\{f_n\}$ is pre-compact in $C^{0,\gamma}(K)$? In other words, what are the sufficient conditions that guarantee there exist a subsequence $f_{n_k}\subset f_n$ and a $f \in C^{0,\gamma}(K)$ such that $f_{n_k} \xrightarrow{C^{0,\gamma}}f$ ? Thank you very much!","Let $K \in \mathbb{R}^d$ be a compact set and consider the space of Hölder continuous functions $C^{0,\gamma}(K)$  with norm $||f||_{C^{0,\gamma}}:=||f||_{\infty}+\sup_{x,y \in K,x \neq y}\frac{|f(x)-f(y)|}{|x-y|^{\gamma}}$. Assume we have a bounded sequence $\{f_n\} \subset C^{0,\gamma}(K)$, i.e. $\exists C>0$ s.t. $\sup_{n}||f_n||_{C^{0,\gamma}} \leq C$. Under what conditions can we say the sequence $\{f_n\}$ is pre-compact in $C^{0,\gamma}(K)$? In other words, what are the sufficient conditions that guarantee there exist a subsequence $f_{n_k}\subset f_n$ and a $f \in C^{0,\gamma}(K)$ such that $f_{n_k} \xrightarrow{C^{0,\gamma}}f$ ? Thank you very much!",,"['functional-analysis', 'compactness', 'holder-spaces']"
28,"How to prove in a topological vector space: cl(A) + cl(B) is a subset of cl(A+B), where cl denotes closure?","How to prove in a topological vector space: cl(A) + cl(B) is a subset of cl(A+B), where cl denotes closure?",,"I'm not sure where to really proceed. My process is as follows. Take any $x \in cl(A)+cl(B)$. Assume for a contradiction that $x \notin cl(A+B)$. Then there exists an open set $U$ such that $ x \in U$, and $U \cap (A+B) = \emptyset$. So for all $u \in U$ and $b \in B$ we have $u-b \notin A$. Since addition is continuous, there exists $U'$ open such that $u-b \in U'$ and $U' \cap A = \emptyset$. But then, we have that $X \setminus U$ is closed, and hence $u-b \notin cl(A)$. Am I on the right track, or is there a nicer solution that I've missed entirely?","I'm not sure where to really proceed. My process is as follows. Take any $x \in cl(A)+cl(B)$. Assume for a contradiction that $x \notin cl(A+B)$. Then there exists an open set $U$ such that $ x \in U$, and $U \cap (A+B) = \emptyset$. So for all $u \in U$ and $b \in B$ we have $u-b \notin A$. Since addition is continuous, there exists $U'$ open such that $u-b \in U'$ and $U' \cap A = \emptyset$. But then, we have that $X \setminus U$ is closed, and hence $u-b \notin cl(A)$. Am I on the right track, or is there a nicer solution that I've missed entirely?",,"['general-topology', 'functional-analysis', 'topological-vector-spaces']"
29,"$P_n[0,1]$ be the set of all polynomial of degree atmost $n$ with supnorm is it a closed in $C[0,1]$? [duplicate]",be the set of all polynomial of degree atmost  with supnorm is it a closed in ? [duplicate],"P_n[0,1] n C[0,1]","This question already has answers here : Is the set of polynomials of degree less than or equal to $n$ closed? (2 answers) Closed 10 years ago . $P_n[0,1]$ be the set of all polynomial of degree atmost $n$ with supnorm is it a closed in $C[0,1]$? and $P[0,1]$ is set of all polynomials in $C[0,1]$  I know which is dense in $C[0,1]$ as we know by Weirstrass Polynomial approximation theorem any continous function can be uniformly approximated by sequence of polynomials. Thank you for  help.","This question already has answers here : Is the set of polynomials of degree less than or equal to $n$ closed? (2 answers) Closed 10 years ago . $P_n[0,1]$ be the set of all polynomial of degree atmost $n$ with supnorm is it a closed in $C[0,1]$? and $P[0,1]$ is set of all polynomials in $C[0,1]$  I know which is dense in $C[0,1]$ as we know by Weirstrass Polynomial approximation theorem any continous function can be uniformly approximated by sequence of polynomials. Thank you for  help.",,['functional-analysis']
30,Hahn-Banach Theorem in the C*-algebra,Hahn-Banach Theorem in the C*-algebra,,"What is the Hahn-Banach Theorem in the C*-algebra(or W*-algebra maybe)? If B is an nondense subalgebra of C*-algebra(or W*-algebra maybe), can we get an state f of A which is always zero at the subalgebra B from the version of  Hahn-Banach Theorem?","What is the Hahn-Banach Theorem in the C*-algebra(or W*-algebra maybe)? If B is an nondense subalgebra of C*-algebra(or W*-algebra maybe), can we get an state f of A which is always zero at the subalgebra B from the version of  Hahn-Banach Theorem?",,"['functional-analysis', 'operator-algebras', 'c-star-algebras']"
31,Expectation value of pure state in quantum mechanics,Expectation value of pure state in quantum mechanics,,"It's well known that in quantum mechanics, the expectation value of a self-adojint operator $A$ in pure state $|\psi\rangle$ is $\langle\psi |A|\psi\rangle = \operatorname{Tr}(A |\psi \rangle \langle\psi |)$ . My question: why this equality holds? I can't see it. I am also unable to find the proof anywhere.","It's well known that in quantum mechanics, the expectation value of a self-adojint operator in pure state is . My question: why this equality holds? I can't see it. I am also unable to find the proof anywhere.",A |\psi\rangle \langle\psi |A|\psi\rangle = \operatorname{Tr}(A |\psi \rangle \langle\psi |),"['functional-analysis', 'reference-request', 'operator-theory', 'quantum-mechanics', 'self-adjoint-operators']"
32,Hilbert's Inequality,Hilbert's Inequality,,Could you help me to show the following: The operator  $$ T(f)(x) = \int _0^\infty \frac{f(y)}{x+y}dy $$  satisfies  $$\Vert T(f)\Vert_p \leq C_p \Vert f\Vert_p $$  for  $1 <p< \infty$ where  $$ C_p = \int_0^\infty \frac{t^{-1/p}}{t+1}dt $$ Thanks a lot!,Could you help me to show the following: The operator  $$ T(f)(x) = \int _0^\infty \frac{f(y)}{x+y}dy $$  satisfies  $$\Vert T(f)\Vert_p \leq C_p \Vert f\Vert_p $$  for  $1 <p< \infty$ where  $$ C_p = \int_0^\infty \frac{t^{-1/p}}{t+1}dt $$ Thanks a lot!,,"['real-analysis', 'functional-analysis', 'operator-theory', 'integral-inequality']"
33,What should I know about Sobolev space?,What should I know about Sobolev space?,,"I have done some Sobolev spaces with some embedding theorems, trace theorems etc. Sorry that my question is really vague. If my professor asks me what is great about Sobolev space, what should I answer (details, examples, counterexamples are very much welcome) to make sure that he feels ok this guy knows the concept pretty well. Any readings, insights, examples, counterexamples are most welcome. Thanks for your help.","I have done some Sobolev spaces with some embedding theorems, trace theorems etc. Sorry that my question is really vague. If my professor asks me what is great about Sobolev space, what should I answer (details, examples, counterexamples are very much welcome) to make sure that he feels ok this guy knows the concept pretty well. Any readings, insights, examples, counterexamples are most welcome. Thanks for your help.",,"['real-analysis', 'functional-analysis', 'soft-question', 'sobolev-spaces']"
34,Why is a strongly continuous one-parameter semigroup called a $C_0$-semigroup?,Why is a strongly continuous one-parameter semigroup called a -semigroup?,C_0,Why is a strongly continuous one-parameter semigroup called a $C_0$-semigroup? Isn't $C_0$ the set of continuous functions that vanish at infinity? Thanks and regards!,Why is a strongly continuous one-parameter semigroup called a $C_0$-semigroup? Isn't $C_0$ the set of continuous functions that vanish at infinity? Thanks and regards!,,['functional-analysis']
35,"Does $d(x+u, y + v) \le d(x, y) + d(u,v)$ holds for every metric?",Does  holds for every metric?,"d(x+u, y + v) \le d(x, y) + d(u,v)","The title said it, I want to prove that $$  d(x+u, y + v) \le d(x, y) + d(u,v) $$ for every metric $d$. If the metric is induced by a norm, i.e. $d(x,y) := ||x-y||$, then this is easy. \begin{align*}  d(x+u, y+v) & = ||x+u - (y+v)|| \\              & = ||x-y + u - v|| \\              & \le ||x-y||+||u-v|| \\              & = d(x,y) + d(u,v) \end{align*} But in the general case I have no idea how to get rid of the sums...","The title said it, I want to prove that $$  d(x+u, y + v) \le d(x, y) + d(u,v) $$ for every metric $d$. If the metric is induced by a norm, i.e. $d(x,y) := ||x-y||$, then this is easy. \begin{align*}  d(x+u, y+v) & = ||x+u - (y+v)|| \\              & = ||x-y + u - v|| \\              & \le ||x-y||+||u-v|| \\              & = d(x,y) + d(u,v) \end{align*} But in the general case I have no idea how to get rid of the sums...",,"['general-topology', 'geometry', 'analysis', 'functional-analysis']"
36,approximating Dirac delta with bounded derivatives,approximating Dirac delta with bounded derivatives,,"Consider the Dirac delta distribution $\delta$ in $\mathbf{R}^d$. It is quite standard to approximate it by functions $g_n$ with $\|g_n\|_{L^1} = 1$. Is it possible to choose a sequence of test functions $\{g_n\}$ converging to $\delta$ as a distribution such that their derivatives are $L^1$-bounded? I mean, such that for a given a natural number $k$ there is a constant $M>0$ so that $\|\partial^\mu g_n \|_{L^1} \le M$ for all $n$'s and all multi-indices $|\mu| \le k$?","Consider the Dirac delta distribution $\delta$ in $\mathbf{R}^d$. It is quite standard to approximate it by functions $g_n$ with $\|g_n\|_{L^1} = 1$. Is it possible to choose a sequence of test functions $\{g_n\}$ converging to $\delta$ as a distribution such that their derivatives are $L^1$-bounded? I mean, such that for a given a natural number $k$ there is a constant $M>0$ so that $\|\partial^\mu g_n \|_{L^1} \le M$ for all $n$'s and all multi-indices $|\mu| \le k$?",,"['functional-analysis', 'distribution-theory']"
37,Inequality for dense subset implies inequality for whole set? (PDE),Inequality for dense subset implies inequality for whole set? (PDE),,"Suppose I have an inequality that holds for all $f \in C^\infty(\Omega)$. Then since $C^\infty(\Omega)$ is dense in, say, $H^1(\Omega)$ under the latter norm, does the inequality hold for all $f \in H^1(\Omega)$ too? (Suppose the inequality involves norms in $L^2$ space)","Suppose I have an inequality that holds for all $f \in C^\infty(\Omega)$. Then since $C^\infty(\Omega)$ is dense in, say, $H^1(\Omega)$ under the latter norm, does the inequality hold for all $f \in H^1(\Omega)$ too? (Suppose the inequality involves norms in $L^2$ space)",,"['functional-analysis', 'partial-differential-equations']"
38,"Solution of the Wave Equation, the not so simple direction","Solution of the Wave Equation, the not so simple direction",,"I read that the solution of the one-dimensional wave equation $$  \frac{1}{c^2} \frac{\partial^2 u}{\partial t^2} = \frac{\partial^2 u}{\partial x^2} $$ are exactly the function of the form $$  u(t,x) = f(x + ct) + g(x - ct) $$ with $f$ and $g$ being twice differentiable. To show that every such function is a solution is simply, but what about the other direction, how can I show that if I have a solution $u$ then it must have the form as a sum of two functions f and g? In my textbooks I just find the simple direction, but not the other?","I read that the solution of the one-dimensional wave equation $$  \frac{1}{c^2} \frac{\partial^2 u}{\partial t^2} = \frac{\partial^2 u}{\partial x^2} $$ are exactly the function of the form $$  u(t,x) = f(x + ct) + g(x - ct) $$ with $f$ and $g$ being twice differentiable. To show that every such function is a solution is simply, but what about the other direction, how can I show that if I have a solution $u$ then it must have the form as a sum of two functions f and g? In my textbooks I just find the simple direction, but not the other?",,"['analysis', 'functional-analysis', 'partial-differential-equations']"
39,"Compactness of operator $M: C([0,1]) \rightarrow C([0,1])$",Compactness of operator,"M: C([0,1]) \rightarrow C([0,1])","Let $M: C([0,1]) \rightarrow C([0,1])$ be defined by  $$ Mf(x) = f(x/2), \;\; x\in[0,1]$$ Is this operator compact? I have trouble using limit in operator norm of compact operator, or cauchy subsequences... How do one do this in function spaces? If you can not find a clever counter example that is...","Let $M: C([0,1]) \rightarrow C([0,1])$ be defined by  $$ Mf(x) = f(x/2), \;\; x\in[0,1]$$ Is this operator compact? I have trouble using limit in operator norm of compact operator, or cauchy subsequences... How do one do this in function spaces? If you can not find a clever counter example that is...",,"['functional-analysis', 'operator-theory']"
40,Functional analysis summary,Functional analysis summary,,Anyone knows a good summary containing the most important definitions and theorems about functional analysis.,Anyone knows a good summary containing the most important definitions and theorems about functional analysis.,,"['functional-analysis', 'reference-request', 'operator-theory']"
41,Spectrum and point spectrum of this operator,Spectrum and point spectrum of this operator,,"Let $T\in  \text{Aut}(\ell^2(\mathbb{C}))$ and $T(x)=(a_1 x_1,  a_2  x_2,\ldots)$ where $a=(a_i)_i  \in \ell^\infty(\mathbb{C})$. How can I easily see what is $\sigma(T)$ and $\sigma_p(T)$ (that are the eigenvalues of $T$)? Thanks.","Let $T\in  \text{Aut}(\ell^2(\mathbb{C}))$ and $T(x)=(a_1 x_1,  a_2  x_2,\ldots)$ where $a=(a_i)_i  \in \ell^\infty(\mathbb{C})$. How can I easily see what is $\sigma(T)$ and $\sigma_p(T)$ (that are the eigenvalues of $T$)? Thanks.",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
42,Does the Implicit mapping theorem imply the inverse mapping theorem?,Does the Implicit mapping theorem imply the inverse mapping theorem?,,Does the Implicit mapping theorem  imply the inverse mapping theorem?,Does the Implicit mapping theorem  imply the inverse mapping theorem?,,"['analysis', 'functional-analysis', 'manifolds', 'vector-analysis']"
43,Compact operator on $l^2$,Compact operator on,l^2,Let $A$ be a bounded linear operator on $l^2$ defined by $A(a_n)= \left(\frac{1}{n} a_n\right)$ . Would you help me to prove that $A$ is compact operator. I guess the answer using an approximation by a sequences of finite range operator.,Let be a bounded linear operator on defined by . Would you help me to prove that is compact operator. I guess the answer using an approximation by a sequences of finite range operator.,A l^2 A(a_n)= \left(\frac{1}{n} a_n\right) A,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'compact-operators']"
44,Why the weak * topology on the dual of a Banach space has the stronger meaning of locally compact,Why the weak * topology on the dual of a Banach space has the stronger meaning of locally compact,,"Let us say that for a Hausdorff topological space to be locally compact means that every point has a compact neighborhood.  Why do locally compact have the property that if $x \in U$ and $U$ is open in $X$, then $x$ has a compact neighborhood that is contained in $U$?  If this is not true, which I suspect, then at least it should be true for the spectrum of an abelian C* algebra, as hinted by a proof in Takesaki where he uses this fact without proof.  Recall the spectrum is the set of (nonzero) multiplicative linear functionals on a C* algebra.  Perhaps the level of generality at which locally compact implies the stronger version of locally compact is in between.  Perhaps it holds for some subsets of the dual of a Banach space?","Let us say that for a Hausdorff topological space to be locally compact means that every point has a compact neighborhood.  Why do locally compact have the property that if $x \in U$ and $U$ is open in $X$, then $x$ has a compact neighborhood that is contained in $U$?  If this is not true, which I suspect, then at least it should be true for the spectrum of an abelian C* algebra, as hinted by a proof in Takesaki where he uses this fact without proof.  Recall the spectrum is the set of (nonzero) multiplicative linear functionals on a C* algebra.  Perhaps the level of generality at which locally compact implies the stronger version of locally compact is in between.  Perhaps it holds for some subsets of the dual of a Banach space?",,"['general-topology', 'analysis', 'functional-analysis', 'operator-algebras']"
45,How to construct this metric space,How to construct this metric space,,"Please give an example of metric space that there are two open balls $B(x,\rho_1) \subset B(y,\rho_2)$ for $\rho_1>\rho_2$","Please give an example of metric space that there are two open balls $B(x,\rho_1) \subset B(y,\rho_2)$ for $\rho_1>\rho_2$",,"['real-analysis', 'functional-analysis']"
46,"Closure of space of simple functions in $L^\infty([a,b])$",Closure of space of simple functions in,"L^\infty([a,b])","Let $a,b\in\mathbb R$ and $L^\infty([a,b])$ be a space of all bounded functions $f:[a,b]\to\mathbb R$. It is a metric space with a metric function given by  $$ d(f,g) = \sup\limits_{x\in[a,b]}|f(x) - g(x)|.  $$ Let us say that the function $f\in L^\infty([a,b])$ is in the class $S$, i.e. $f\in S$ if there is a finite partition  $$ \mathcal  T = \{a = t_0<t_1<\dots<t_n = b\} $$ and a sequence of reals $c_0,\dots,c_{n-1}$ such that  $$ f(t) = \sum\limits_{i=0}^{n-2}c_i1_{[t_i,t_{i+1})}(t)+c_{n-1}1_{[t_{n-1},t_n](t)} $$ for all $t\in [a,b]$. I wonder if there is a nice characterization of $\bar S$, the closure of $S$ in $L^\infty([a,b])$. E.g. any continuous on $[a,b]$ function is in $\bar S$ - but it surely is much larger.","Let $a,b\in\mathbb R$ and $L^\infty([a,b])$ be a space of all bounded functions $f:[a,b]\to\mathbb R$. It is a metric space with a metric function given by  $$ d(f,g) = \sup\limits_{x\in[a,b]}|f(x) - g(x)|.  $$ Let us say that the function $f\in L^\infty([a,b])$ is in the class $S$, i.e. $f\in S$ if there is a finite partition  $$ \mathcal  T = \{a = t_0<t_1<\dots<t_n = b\} $$ and a sequence of reals $c_0,\dots,c_{n-1}$ such that  $$ f(t) = \sum\limits_{i=0}^{n-2}c_i1_{[t_i,t_{i+1})}(t)+c_{n-1}1_{[t_{n-1},t_n](t)} $$ for all $t\in [a,b]$. I wonder if there is a nice characterization of $\bar S$, the closure of $S$ in $L^\infty([a,b])$. E.g. any continuous on $[a,b]$ function is in $\bar S$ - but it surely is much larger.",,"['real-analysis', 'functional-analysis']"
47,Proof of inequality (mollifier),Proof of inequality (mollifier),,"Let $J$ be a mollifier, e.g. a function in $J \in C^\infty(\mathbb R^n)$ with the properties $J\geq 0$ and $\int J(x) \mathrm dx=1$ and $J(x)=0$ for all $x$ with $|x|>1.$ Now define $J_\varepsilon (x):=\varepsilon ^{-n}J(\varepsilon ^{-1}x)$ and $$(J_\varepsilon \star u)(x)=\int_{\mathbb R^n}J_\varepsilon (x-y)u(y) \mathrm dy$$ (the symbol $\star$ denotes convolution). How does one prove, that for every function $u \in C^\infty_0(\mathbb R^n)$ (with compact support) the following inequality holds: $$\left \| u-J_\varepsilon  \star u \right \|_1 \leq  c \cdot \varepsilon \left \| u \right \|_{1,1}\quad ?$$ Here, $||u||_{1,1}=||u||_{L^1}+\sum_{j=1}^n||\partial_j u||_{L^1}$.","Let $J$ be a mollifier, e.g. a function in $J \in C^\infty(\mathbb R^n)$ with the properties $J\geq 0$ and $\int J(x) \mathrm dx=1$ and $J(x)=0$ for all $x$ with $|x|>1.$ Now define $J_\varepsilon (x):=\varepsilon ^{-n}J(\varepsilon ^{-1}x)$ and $$(J_\varepsilon \star u)(x)=\int_{\mathbb R^n}J_\varepsilon (x-y)u(y) \mathrm dy$$ (the symbol $\star$ denotes convolution). How does one prove, that for every function $u \in C^\infty_0(\mathbb R^n)$ (with compact support) the following inequality holds: $$\left \| u-J_\varepsilon  \star u \right \|_1 \leq  c \cdot \varepsilon \left \| u \right \|_{1,1}\quad ?$$ Here, $||u||_{1,1}=||u||_{L^1}+\sum_{j=1}^n||\partial_j u||_{L^1}$.",,['functional-analysis']
48,projections in normed linear spaces,projections in normed linear spaces,,"Let $H$ be a Hilbert space and $C$ be a non empty closed convex subset of $H$ and let $x\notin C$. We know that there exists a unique $y_0$ in $C$ such that $\|x-y_0\|=\inf_{y\in C}\|x-y\|$. Call $y_0$, the projection of $x$ onto $C$. The proof of this result heavily depends on the parallelogram law which holds only in Hilbert spaces. Is the result true for just normed spaces also? Have people already studied about this?","Let $H$ be a Hilbert space and $C$ be a non empty closed convex subset of $H$ and let $x\notin C$. We know that there exists a unique $y_0$ in $C$ such that $\|x-y_0\|=\inf_{y\in C}\|x-y\|$. Call $y_0$, the projection of $x$ onto $C$. The proof of this result heavily depends on the parallelogram law which holds only in Hilbert spaces. Is the result true for just normed spaces also? Have people already studied about this?",,['functional-analysis']
49,"Question about ""well-defined""","Question about ""well-defined""",,"I have the following homework: Let $(X, \mu, \Sigma)$ be a measure space. We define a measure preserving transformation to be a measurable map $T: X \rightarrow X$ such that for any $A \in \Sigma, \mu(T^{-1}(A)) = \mu(A)$. Such a transformation induces a transformation $U_T$ on $L^2 (X; \mu)$ given by $$ f \mapsto U_T(f) = f \circ T$$ Show that $U_T$ is a well-defined transformation from $L^2$ to itself. My question: is it enough to show that $f \in L^2 \implies U_T(f) \in L^2$? More generally: when I see the word ""well-defined"", how do I find out what it means? It means something different every time and I never really know what. Thanks for your help.","I have the following homework: Let $(X, \mu, \Sigma)$ be a measure space. We define a measure preserving transformation to be a measurable map $T: X \rightarrow X$ such that for any $A \in \Sigma, \mu(T^{-1}(A)) = \mu(A)$. Such a transformation induces a transformation $U_T$ on $L^2 (X; \mu)$ given by $$ f \mapsto U_T(f) = f \circ T$$ Show that $U_T$ is a well-defined transformation from $L^2$ to itself. My question: is it enough to show that $f \in L^2 \implies U_T(f) \in L^2$? More generally: when I see the word ""well-defined"", how do I find out what it means? It means something different every time and I never really know what. Thanks for your help.",,"['measure-theory', 'functional-analysis']"
50,Hankel function in terms of planewaves,Hankel function in terms of planewaves,,"It is well know that planewaves are a complete basis for solutions to the wave equation. Let us assume a 2D space, and at fixed temporal frequency, the equation reduces to the Helmholtz equation. In cylindrical coordinates, the most appropriate solutions are the two kinds of Hankel functions, representing outgoing and incoming wave solutions. Actually, the Hankel functions should be multiplied by $e^{i m \theta}$ to produce cylindrical harmonics, which are a complete basis. My question is this: If cylindrical harmonics are a complete basis, is there a closed form expression relating them to planewaves? I know that 1st kind Bessel functions $J_m$ have a planewave decomposition by way of the Jacobi-Anger identity. However, a Hankel function's real part is a bessel function while its imaginary part is a 2nd kind Bessel function (Neumann function) with a singularity at the origin. I can't find an analogous expression for expression Neumann functions in terms of planewaves.","It is well know that planewaves are a complete basis for solutions to the wave equation. Let us assume a 2D space, and at fixed temporal frequency, the equation reduces to the Helmholtz equation. In cylindrical coordinates, the most appropriate solutions are the two kinds of Hankel functions, representing outgoing and incoming wave solutions. Actually, the Hankel functions should be multiplied by $e^{i m \theta}$ to produce cylindrical harmonics, which are a complete basis. My question is this: If cylindrical harmonics are a complete basis, is there a closed form expression relating them to planewaves? I know that 1st kind Bessel functions $J_m$ have a planewave decomposition by way of the Jacobi-Anger identity. However, a Hankel function's real part is a bessel function while its imaginary part is a 2nd kind Bessel function (Neumann function) with a singularity at the origin. I can't find an analogous expression for expression Neumann functions in terms of planewaves.",,"['functional-analysis', 'special-functions', 'partial-differential-equations', 'physics']"
51,Hilbert Schmidt Operators as Integral Operators,Hilbert Schmidt Operators as Integral Operators,,"If $H$ is a Hilbert space with norm $\| . \|$, and $A$ is an operator, we call it a Hilbert Schmidt Operator if $$\sum_{n=1}^\infty \|Ax_n\|^2<\infty$$ for some orthonormal basis $\{x_i\}.$ Consider $L^2(X,\mu)$.  How could one prove that every Hilbert Schmidt Operator on this space is given by $$(Af)(x)=\int_X k(x,y)f(y)dy$$ for some $$k(x,y)\in L^2(X\times X, \mu \times \mu).$$ I am not really sure where to start, but I imagine this would be in many textbooks/online notes?  Does this fact have a particular name?  Ideally I would love it if someone could show why it is true, but a reference is useful as well. Thanks for any help!","If $H$ is a Hilbert space with norm $\| . \|$, and $A$ is an operator, we call it a Hilbert Schmidt Operator if $$\sum_{n=1}^\infty \|Ax_n\|^2<\infty$$ for some orthonormal basis $\{x_i\}.$ Consider $L^2(X,\mu)$.  How could one prove that every Hilbert Schmidt Operator on this space is given by $$(Af)(x)=\int_X k(x,y)f(y)dy$$ for some $$k(x,y)\in L^2(X\times X, \mu \times \mu).$$ I am not really sure where to start, but I imagine this would be in many textbooks/online notes?  Does this fact have a particular name?  Ideally I would love it if someone could show why it is true, but a reference is useful as well. Thanks for any help!",,"['integration', 'functional-analysis']"
52,The Gelfand transformation on $\ell^1(\mathbb Z)$ is not isometric. Do you have an example?,The Gelfand transformation on  is not isometric. Do you have an example?,\ell^1(\mathbb Z),"I am looking for an element $(a_n)_{n\in\mathbb Z}\in\ell^1(\mathbb Z)$ with the property $$ \lVert(a_n)\rVert_{\ell^1(\mathbb Z)} > \lVert\sum_{n\in\mathbb Z}a_n z^n\rVert_\infty, $$ where the norm on the right hand side denotes the sup-norm on $\mathcal C(\mathbb T)$ ($\mathbb T$ is the 1-Torus). Motivation: I want to prove that the Gelfand transformation on $\ell^1(\mathbb Z)$ is not isometric.","I am looking for an element $(a_n)_{n\in\mathbb Z}\in\ell^1(\mathbb Z)$ with the property $$ \lVert(a_n)\rVert_{\ell^1(\mathbb Z)} > \lVert\sum_{n\in\mathbb Z}a_n z^n\rVert_\infty, $$ where the norm on the right hand side denotes the sup-norm on $\mathcal C(\mathbb T)$ ($\mathbb T$ is the 1-Torus). Motivation: I want to prove that the Gelfand transformation on $\ell^1(\mathbb Z)$ is not isometric.",,['functional-analysis']
53,"Prove that $\int _Xf_ngd\mu \overset{n\to\infty}{\to}\int _Xfgd\mu$ ,$\forall g\in \mathcal{L}^\infty (\mu )$ if it's true $\forall g\in C_b(X)$","Prove that  , if it's true",\int _Xf_ngd\mu \overset{n\to\infty}{\to}\int _Xfgd\mu \forall g\in \mathcal{L}^\infty (\mu ) \forall g\in C_b(X),"Let $X$ be a Polish space and $\mu :\mathfrak{B}_X\to\overline{\mathbb{R}}$ a finite measure on the Borel subsets of $X$ . Suppose $(f_n)_{n\in\mathbb{N}}$ is a sequence of $\mathcal{L}^1(\mu )$ and $f\in \mathcal{L}^1(\mu )$ . If $\lim_{n\to\infty}\int _Xf_ngd\mu =\int _Xfgd\mu $ for all $g\in C_b(X)$ (continuous and bounded), can we conclude that $\lim_{n\to\infty}\int _Xf_ngd\mu =\int _Xfgd\mu $ for all $g\in \mathcal{L}^\infty (\mu )$ ? Using the 4.4.6 Theorem of the book ""Measure Theory"" (by V.I. Bogachev) and the Theorem 6.3.2 of the book ""Integration and Modern Analysis"" (by Benedetto and Czaja), we can conclude that $\lim_{n\to\infty}\int _Xf_ngd\mu =\int _Xfgd\mu $ , $\forall g\in \mathcal{L}^\infty (\mu )$ if and only if $\lim_{n\to\infty}\int _Bf_nd\mu =\int _Bfd\mu $ , $\forall B\in\mathfrak{B}_X$ . But I don't know how to prove previous limit. Also I wasn't able to find any counterexample.","Let be a Polish space and a finite measure on the Borel subsets of . Suppose is a sequence of and . If for all (continuous and bounded), can we conclude that for all ? Using the 4.4.6 Theorem of the book ""Measure Theory"" (by V.I. Bogachev) and the Theorem 6.3.2 of the book ""Integration and Modern Analysis"" (by Benedetto and Czaja), we can conclude that , if and only if , . But I don't know how to prove previous limit. Also I wasn't able to find any counterexample.",X \mu :\mathfrak{B}_X\to\overline{\mathbb{R}} X (f_n)_{n\in\mathbb{N}} \mathcal{L}^1(\mu ) f\in \mathcal{L}^1(\mu ) \lim_{n\to\infty}\int _Xf_ngd\mu =\int _Xfgd\mu  g\in C_b(X) \lim_{n\to\infty}\int _Xf_ngd\mu =\int _Xfgd\mu  g\in \mathcal{L}^\infty (\mu ) \lim_{n\to\infty}\int _Xf_ngd\mu =\int _Xfgd\mu  \forall g\in \mathcal{L}^\infty (\mu ) \lim_{n\to\infty}\int _Bf_nd\mu =\int _Bfd\mu  \forall B\in\mathfrak{B}_X,"['integration', 'functional-analysis', 'analysis', 'measure-theory', 'lp-spaces']"
54,Notation $D^{m}$ in certain inequalities in $L^{p}$,Notation  in certain inequalities in,D^{m} L^{p},"In this wikipedia article , one can find the so-called ""Gagliardo-Nirenberg inequality, which are of the form $${\displaystyle \|D^{j}u\|_{L^{p}(\mathbb {R} ^{n})}\leq C\|D^{m}u\|_{L^{r}(\mathbb {R} ^{n})}^{\theta }\|u\|_{L^{q}(\mathbb {R} ^{n})}^{1-\theta }}$$ for coefficients $j,m,n,p,q,r,\theta$ satisfying certain relations. I am wondering: What does the notation $D^{m}$ for $m\in\mathbb{N}$ mean in this context? Of course, I am very well aware of the multiindex notation $D^{\alpha}=D^{\alpha_{1}}_{1}\dots D^{\alpha_{d}}_{n}$ . However, in the case above, $j$ and $m$ are just natural numbers and not multiindices. So, I am wondering, what does $D^{j}$ and $D^{m}$ mean. The expression $D^{m}$ might be a shortcut notation for $D^{\alpha}$ for any $\alpha$ with $\vert\alpha\vert=m$ , or it might also be the supremum of all those norms. Any reference or explanation is appreciated.","In this wikipedia article , one can find the so-called ""Gagliardo-Nirenberg inequality, which are of the form for coefficients satisfying certain relations. I am wondering: What does the notation for mean in this context? Of course, I am very well aware of the multiindex notation . However, in the case above, and are just natural numbers and not multiindices. So, I am wondering, what does and mean. The expression might be a shortcut notation for for any with , or it might also be the supremum of all those norms. Any reference or explanation is appreciated.","{\displaystyle \|D^{j}u\|_{L^{p}(\mathbb {R} ^{n})}\leq C\|D^{m}u\|_{L^{r}(\mathbb {R} ^{n})}^{\theta }\|u\|_{L^{q}(\mathbb {R} ^{n})}^{1-\theta }} j,m,n,p,q,r,\theta D^{m} m\in\mathbb{N} D^{\alpha}=D^{\alpha_{1}}_{1}\dots D^{\alpha_{d}}_{n} j m D^{j} D^{m} D^{m} D^{\alpha} \alpha \vert\alpha\vert=m","['real-analysis', 'functional-analysis', 'multivariable-calculus', 'inequality', 'lp-spaces']"
55,A maximal vectorial subspace has a 1-dimensional complement.,A maximal vectorial subspace has a 1-dimensional complement.,,"I have seen this excercise on a book of Functional analysis and I am trying to prove it. Let $X$ be a vectorial space over a field $\Bbb{K} \, ( \Bbb{R} $ or $ \Bbb{C} )$ and $H \subset X$ a proper subspace. Then, the following are equivalent: $H$ is maximal (that is, for every subspace $H \subseteq M \subseteq X \rightarrow H=M \lor X=M$ ) It exists a subspace $L \subseteq X$ such that $\dim L = 1, H \cap L = \{ 0 \}$ and $X= H + L $ . $\dim  X/H  = 1$ It exists a linear functional $\varphi : X \rightarrow \Bbb{K}$ such that $\ker \varphi = H$ It is important to say that the book does not say anything about the dimension of $X$ , in fact there is problem before this about infinite dimensional spaces. This is why I find this problem difficult, the finite case would be very simple. I saw first that $4 \Rightarrow 3$ is easy to prove using the First Isomorhpy Theorem with $\varphi$ . In order to continue, I have tried to prove $3 \Rightarrow 2$ and $1 \Rightarrow 2$ by considering the linear function $$T: X \times H \rightarrow X, T(x,h) = x-h$$ and taking $L := T( X \times H )$ . This satisfies that $H + L = X$ , but I do not know if it works because I am not seeing how to prove $H \cap L = \{ 0 \}$ and $\dim L = 1$ since the possibly infinite dimension of $X$ . Also, I do not have very idea on how to ""reach"" $4$ from one of the others. I thought first on consider $\varphi ( x ) = ||| x + H  ||| $ where $||| \cdot ||| $ is the norm on $X/H$ induced by a norm on $X$ , but I am not sure about it, so any possible help would be appreciated.","I have seen this excercise on a book of Functional analysis and I am trying to prove it. Let be a vectorial space over a field or and a proper subspace. Then, the following are equivalent: is maximal (that is, for every subspace ) It exists a subspace such that and . It exists a linear functional such that It is important to say that the book does not say anything about the dimension of , in fact there is problem before this about infinite dimensional spaces. This is why I find this problem difficult, the finite case would be very simple. I saw first that is easy to prove using the First Isomorhpy Theorem with . In order to continue, I have tried to prove and by considering the linear function and taking . This satisfies that , but I do not know if it works because I am not seeing how to prove and since the possibly infinite dimension of . Also, I do not have very idea on how to ""reach"" from one of the others. I thought first on consider where is the norm on induced by a norm on , but I am not sure about it, so any possible help would be appreciated.","X \Bbb{K} \, ( \Bbb{R}   \Bbb{C} ) H \subset X H H \subseteq M \subseteq X \rightarrow H=M \lor X=M L \subseteq X \dim L = 1, H \cap L = \{ 0 \} X= H + L  \dim  X/H  = 1 \varphi : X \rightarrow \Bbb{K} \ker \varphi = H X 4 \Rightarrow 3 \varphi 3 \Rightarrow 2 1 \Rightarrow 2 T: X \times H \rightarrow X, T(x,h) = x-h L := T( X \times H ) H + L = X H \cap L = \{ 0 \} \dim L = 1 X 4 \varphi ( x ) = ||| x + H  |||  ||| \cdot |||  X/H X","['linear-algebra', 'functional-analysis']"
56,Are complements of proper subspaces dense?,Are complements of proper subspaces dense?,,"Consider a topological vector space $V$ over $K\in\{\mathbb{R, C}\}$ . I ask a simple innocent question: Is the complement of every proper subspace dense? What if the space is normed? Or has an inner-product? This question popped up while reading Andreas Blass's answer to a previous question of mine.",Consider a topological vector space over . I ask a simple innocent question: Is the complement of every proper subspace dense? What if the space is normed? Or has an inner-product? This question popped up while reading Andreas Blass's answer to a previous question of mine.,"V K\in\{\mathbb{R, C}\}","['functional-analysis', 'normed-spaces', 'inner-products', 'topological-vector-spaces']"
57,Spectrum of linear operator $Tf(x) = f(x+1) + f(x-1)$ on $L^2(\mathbb{R})$,Spectrum of linear operator  on,Tf(x) = f(x+1) + f(x-1) L^2(\mathbb{R}),"We are working on the Hilbert space $H = L^2(\mathbb{R})$ and consider the bounded linear operator $T : H \to H$ defined by $(Tf)(x) = f(x+1) + f(x-1)$ . What is the spectrum of $T$ ? What I've tried: It's not so hard to show that $T$ is indeed a linear operator and bounded, with $\|Tf\|^2 \leq 4\|f\|^2$ wrt the $L^2$ norm on $\mathbb{R}$ . Using for instance the functions ${\bf1}_{[-n,n]}$ , I could even show that $\|T\| = 2$ . Also not so hard to show that $T$ is self-adjoint, being the sum of obvious self-adjoint $T_1f(x) = f(x+1)$ and $T_2f(x) = f(x-1)$ , but this can also be proved by straightforward calculation. The spectrum is therefore a subset of $[-\|T\|,\|T\|]$ . I do not know how to proceed.","We are working on the Hilbert space and consider the bounded linear operator defined by . What is the spectrum of ? What I've tried: It's not so hard to show that is indeed a linear operator and bounded, with wrt the norm on . Using for instance the functions , I could even show that . Also not so hard to show that is self-adjoint, being the sum of obvious self-adjoint and , but this can also be proved by straightforward calculation. The spectrum is therefore a subset of . I do not know how to proceed.","H = L^2(\mathbb{R}) T : H \to H (Tf)(x) = f(x+1) + f(x-1) T T \|Tf\|^2 \leq 4\|f\|^2 L^2 \mathbb{R} {\bf1}_{[-n,n]} \|T\| = 2 T T_1f(x) = f(x+1) T_2f(x) = f(x-1) [-\|T\|,\|T\|]","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'lebesgue-integral']"
58,Proof that a certain set is not nowhere dense,Proof that a certain set is not nowhere dense,,"Question: Prove that the set $N=\{f\in C([0,1])|f(0)=0\}$ is a nowhere dense subset of $(C([0,1]),d_{\infty})$ , but not a nowhere dense subset of $(C([0,1]),d_{1})$ , where $d_{\infty}(f,g)=sup_{x\in[0,1]}|f(x)-g(x)|$ and $d_{1}(f,g)=\int_{0}^{1}|f(x)-g(x)|dx$ . My try: I tried my best but cannot prove the second part . The first part of the proof can be found in my lecture notes, which is the following: Proof: Let $f\in C([0,1])$ and $r>0$ . We can clearly choose $a\in\mathbb{R}$ and $\delta>0$ such that $(a-\delta,a+\delta)\subseteq (f(0)-\frac{r}{2},f(0)+\frac{r}{2})\backslash\{0\}$ . Note that $|a-f(0)|\leq\frac{r}{2}$ and $\delta \leq \frac{r}{2}$ . Let $g\in C([0,1])$ denote the continuous function defined by $g=f+a-f(0)$ . We claim that $B(g,\delta)\subseteq B(f,r)$ . Indeed, choose a $h\in B(g,\delta)$ , then $d_{\infty}(f,h)\leq d_{\infty}(f,g)+d_{\infty}(g,h)\leq |a-f(0)|+\delta\leq \frac{r}{2}+\frac{r}{2}=r$ . That is, $h\in B(f,r)$ . Next, we claim that $B(g,\delta)\subseteq C([0,1])\backslash N$ . Indeed, choose a $h\in B(g,\delta)$ , then $|h(0)-a|\leq|h(0)-g(0)|+|g(0)-a|\leq d_{\infty}(h,g)+0\leq\delta$ , hence $h(0)\in (a-\delta,a+\delta)\subseteq (f(0)-\frac{r}{2},f(0)+\frac{r}{2})\backslash\{0\}$ . This means $h(0)\neq 0$ and thus $h\notin N$ .","Question: Prove that the set is a nowhere dense subset of , but not a nowhere dense subset of , where and . My try: I tried my best but cannot prove the second part . The first part of the proof can be found in my lecture notes, which is the following: Proof: Let and . We can clearly choose and such that . Note that and . Let denote the continuous function defined by . We claim that . Indeed, choose a , then . That is, . Next, we claim that . Indeed, choose a , then , hence . This means and thus .","N=\{f\in C([0,1])|f(0)=0\} (C([0,1]),d_{\infty}) (C([0,1]),d_{1}) d_{\infty}(f,g)=sup_{x\in[0,1]}|f(x)-g(x)| d_{1}(f,g)=\int_{0}^{1}|f(x)-g(x)|dx f\in C([0,1]) r>0 a\in\mathbb{R} \delta>0 (a-\delta,a+\delta)\subseteq (f(0)-\frac{r}{2},f(0)+\frac{r}{2})\backslash\{0\} |a-f(0)|\leq\frac{r}{2} \delta \leq \frac{r}{2} g\in C([0,1]) g=f+a-f(0) B(g,\delta)\subseteq B(f,r) h\in B(g,\delta) d_{\infty}(f,h)\leq d_{\infty}(f,g)+d_{\infty}(g,h)\leq |a-f(0)|+\delta\leq \frac{r}{2}+\frac{r}{2}=r h\in B(f,r) B(g,\delta)\subseteq C([0,1])\backslash N h\in B(g,\delta) |h(0)-a|\leq|h(0)-g(0)|+|g(0)-a|\leq d_{\infty}(h,g)+0\leq\delta h(0)\in (a-\delta,a+\delta)\subseteq (f(0)-\frac{r}{2},f(0)+\frac{r}{2})\backslash\{0\} h(0)\neq 0 h\notin N","['real-analysis', 'general-topology', 'functional-analysis']"
59,every rank one operator is a linear combination of rank one idempotents,every rank one operator is a linear combination of rank one idempotents,,"I'm trying to prove a theorem which makes use of the fact that every finite rank operator on a Banach space is a linear combination of rank one idempotents. It's enough to show this for rank one operators. Actually I have found a proof in a paper but I can't understand it at all. I whish someone could offer a new proof or help me clarify the following argumement: Given a rank-one operator $u\in B(X)$ , there exists $\tau(u)\in\mathbb{C}$ such that $u^2=\tau(u)u$ .Moreover, $\tau(u)=0$ or $\tau(u)$ is the only non-zero element in the spectrum of $u$ .(What on earth is $\tau$ ?) Thus if $\tau(u)\neq 0$ ,then $\tau(u)^{-1}u$ is a minimal idempotent (I think this means a rank-one idempotent), and $u=\tau(u)(\tau(u)^{-1}u)$ . Now for $\tau(u)=0$ , let $x\in B(X)$ , and $\lambda\in\mathbb{C}$ be such that $uxu=u$ and $\lambda\gt r(x)$ ( $r(x)$ denotes the spectral radius). Therefore, $e_1=ux$ and $e_2=u(x-\lambda)$ are minimal idempotents satisfying $u=\lambda^{-1}(e_1-e_2)$ , which completes the proof.","I'm trying to prove a theorem which makes use of the fact that every finite rank operator on a Banach space is a linear combination of rank one idempotents. It's enough to show this for rank one operators. Actually I have found a proof in a paper but I can't understand it at all. I whish someone could offer a new proof or help me clarify the following argumement: Given a rank-one operator , there exists such that .Moreover, or is the only non-zero element in the spectrum of .(What on earth is ?) Thus if ,then is a minimal idempotent (I think this means a rank-one idempotent), and . Now for , let , and be such that and ( denotes the spectral radius). Therefore, and are minimal idempotents satisfying , which completes the proof.",u\in B(X) \tau(u)\in\mathbb{C} u^2=\tau(u)u \tau(u)=0 \tau(u) u \tau \tau(u)\neq 0 \tau(u)^{-1}u u=\tau(u)(\tau(u)^{-1}u) \tau(u)=0 x\in B(X) \lambda\in\mathbb{C} uxu=u \lambda\gt r(x) r(x) e_1=ux e_2=u(x-\lambda) u=\lambda^{-1}(e_1-e_2),"['functional-analysis', 'operator-theory', 'operator-algebras']"
60,Every bounded linear operator is an infinitesimal generator,Every bounded linear operator is an infinitesimal generator,,"I'm studying the theory of semigroups from Pazy's book. I'm struggling to understand a specific inequality in the proof of a theorem stating that every bounded linear operator is an infinitesimal generator of some semigroup. How does one get the second inequality, which implies that $A$ is indeed the generator of $T$ ?","I'm studying the theory of semigroups from Pazy's book. I'm struggling to understand a specific inequality in the proof of a theorem stating that every bounded linear operator is an infinitesimal generator of some semigroup. How does one get the second inequality, which implies that is indeed the generator of ?",A T,"['functional-analysis', 'linear-transformations', 'operator-theory', 'semigroup-of-operators']"
61,Is the tensor product of W*-algebras commutative?,Is the tensor product of W*-algebras commutative?,,"According to definition 1.22.10 in Sakai's book if $\mathscr{N}$ and $\mathscr{M}$ are two W $^*$ -algebras its tensor product is defined by \begin{equation} \mathscr{N} \overline{\otimes}\mathscr{M} := (\mathscr{N}_* \otimes_{min^*} \mathscr{M}_*)^*, \end{equation} where $\text{min}^*$ is the dual projective norm and $\mathscr{N}_*$ , $\mathscr{M}_*$ are the corresponding predual spaces of $\mathscr{N}$ and $\mathscr{M}$ . What I would like to know if it is true that $\mathscr{N} \overline{\otimes}\mathscr{M} \cong \mathscr{M} \overline{\otimes}\mathscr{N}$ for this particular norm, that I will call W $^*$ -norm, . According to proposition II.9.2.6 in Blackadar's book when $\mathscr{N}$ and $\mathscr{M}$ are C $^*$ -algebras it is true that \begin{equation} \mathscr{N} {\otimes}_{min \\ max} \mathscr{M} \cong \mathscr{M} {\otimes}_{min \\ max} \mathscr{N}, \end{equation} however, he does not prove this result and a similar property for the case of W $^*$ -algebras is not discussed. In order to prove this isomorphism of W $^*$ -algebras I started by defining the map \begin{equation} s: \mathscr{N} \odot \mathscr{M} \to \mathscr{M} \odot \mathscr{N},  \sum_i n_i \odot m_i  \mapsto  \sum_i m_i \odot n_i,  \end{equation} where $\odot$ denotes the algebraic tensor product; this map has an inverse given by \begin{equation} s': \mathscr{M} \odot \mathscr{N} \to \mathscr{N} \odot \mathscr{M},  \sum_i m_i \odot n_i  \mapsto  \sum_i n_i \odot m_i.  \end{equation} Now, the idea will be to prove that the map $s$ can be extended to an unique norm-preserving map in $\mathcal{B}(\mathscr{N} \overline{\otimes}\mathscr{M}, \mathscr{M} \overline{\otimes}\mathscr{N})$ ; for that I should prove that $s: \mathscr{N} \otimes_\alpha \mathscr{M} \to \mathscr{M} \overline{\otimes} \mathscr{N}$ is bounded where, $\otimes_\alpha$ is the W $^*$ -norm. Then, if the same is done for the map $s': \mathscr{M} \otimes_\alpha \mathscr{N} \to \mathscr{N} \overline{\otimes} \mathscr{M}$ then, I am almost done. However, I am failing to prove that the map $s$ is bounded. One thing I do know is that since $\alpha$ is a cross norm then $||s(m\otimes n)|| = ||m \otimes n||$ but this only works for simple tensors. So, I was wondering if there is any way I can bound these maps so they can be extended? Or perhaps, if there is another way to proceed to prove the isomorphism by using Sakai's language. Thanks in advance.","According to definition 1.22.10 in Sakai's book if and are two W -algebras its tensor product is defined by where is the dual projective norm and , are the corresponding predual spaces of and . What I would like to know if it is true that for this particular norm, that I will call W -norm, . According to proposition II.9.2.6 in Blackadar's book when and are C -algebras it is true that however, he does not prove this result and a similar property for the case of W -algebras is not discussed. In order to prove this isomorphism of W -algebras I started by defining the map where denotes the algebraic tensor product; this map has an inverse given by Now, the idea will be to prove that the map can be extended to an unique norm-preserving map in ; for that I should prove that is bounded where, is the W -norm. Then, if the same is done for the map then, I am almost done. However, I am failing to prove that the map is bounded. One thing I do know is that since is a cross norm then but this only works for simple tensors. So, I was wondering if there is any way I can bound these maps so they can be extended? Or perhaps, if there is another way to proceed to prove the isomorphism by using Sakai's language. Thanks in advance.","\mathscr{N} \mathscr{M} ^* \begin{equation}
\mathscr{N} \overline{\otimes}\mathscr{M} := (\mathscr{N}_* \otimes_{min^*} \mathscr{M}_*)^*,
\end{equation} \text{min}^* \mathscr{N}_* \mathscr{M}_* \mathscr{N} \mathscr{M} \mathscr{N} \overline{\otimes}\mathscr{M} \cong \mathscr{M} \overline{\otimes}\mathscr{N} ^* \mathscr{N} \mathscr{M} ^* \begin{equation}
\mathscr{N} {\otimes}_{min \\ max} \mathscr{M} \cong \mathscr{M} {\otimes}_{min \\ max} \mathscr{N},
\end{equation} ^* ^* \begin{equation}
s: \mathscr{N} \odot \mathscr{M} \to \mathscr{M} \odot \mathscr{N},  \sum_i n_i \odot m_i  \mapsto  \sum_i m_i \odot n_i, 
\end{equation} \odot \begin{equation}
s': \mathscr{M} \odot \mathscr{N} \to \mathscr{N} \odot \mathscr{M},  \sum_i m_i \odot n_i  \mapsto  \sum_i n_i \odot m_i. 
\end{equation} s \mathcal{B}(\mathscr{N} \overline{\otimes}\mathscr{M}, \mathscr{M} \overline{\otimes}\mathscr{N}) s: \mathscr{N} \otimes_\alpha \mathscr{M} \to \mathscr{M} \overline{\otimes} \mathscr{N} \otimes_\alpha ^* s': \mathscr{M} \otimes_\alpha \mathscr{N} \to \mathscr{N} \overline{\otimes} \mathscr{M} s \alpha ||s(m\otimes n)|| = ||m \otimes n||","['functional-analysis', 'banach-spaces', 'tensor-products', 'operator-algebras', 'von-neumann-algebras']"
62,How to give a closed form to $e^{a(x) \frac{d}{dx} + b(x)I}[f]$ in physicists style abuse of notation?,How to give a closed form to  in physicists style abuse of notation?,e^{a(x) \frac{d}{dx} + b(x)I}[f],"In Quantum Mechanics we have the famous time evolution result (here $a$ is a constant) $$ e^{a \frac{d}{dx}}[f] = f(x+a) $$ Which is an abuse of notation but makes sense due to Taylor's Theorem. In this answer I show we can give a closed form to $e^{a(x) \frac{d}{dx}}$ whereas if we can find a constant $r$ and function $q$ so that: $$a(x) = \frac{q(r)}{q'(x)} $$ Then $$ e^{a(x) \frac{d}{dx}} [f] = f(q^{-1}(q(r)+q(x)))$$ . As an example if $q = \ln(x)$ and $r=2$ then: $e^{\ln(2) x \frac{d}{dx}} = f(2x)$ (letting $q(x)=x, r=a$ we also can prove the quantum mechanics result above as special case of this) Now we also know that $e^{b(x)I}[f] = e^{b(x)}f$ where $I$ is the identity operator. So with this in place I am curious if we can generally speaking give some kind of closed form for a generic exponential of a first order linear differential operator: $$ e^{a(x) \frac{d}{dx} + b(x)I}[f] $$ My question is ""what should this evaluate to?"" and to put some boundaries on it, can we expect a general formula which involves finitely many functions $w_1(x) ... w_k(x), c_1(x), ... c_k(x)$ and finitely many non-negative real numbers $d_1 ... d_k$ such that $$ e^{a(x) \frac{d}{dx} + b(x)I}[f] = w_1(x)f^{(d_1)}(c_1(x)) + w_2(x)f^{(d_2)}(c_2(x)) + ... w_k(x)f^{(d_k)}(c_k(x)) $$ Where $f^{(d_k)}$ indicates the $d_k$ fractional derivative of $f$ ? Some Ideas: My first intuition when working with this abuse of notation is to factor it via integration factors (and at this point this is more symbol shuffling than math, I can hardly give a definition of what any of this means): $$ e^{a \frac{d}{dx} + bI} = e^{a(x) e^{-\int \frac{a}{b}}  \left( e^{\int \frac{a}{b}} I \right)' }  $$ But this doesn't necessarily help since I don't have any tools at the moment for evaluating $ e^{\frac{d}{dx} \left(g(x) I \right)} $ . Even something as simple as $e^{\frac{d}{dx}(2I)}$ we know to be $f(x+2)$ . But how does one arrive at $f(x+2)$ from $2f(x)$ which is the interpretation of $2I$ or $e^2f$ which is $e^{2I}$ . It's just absolutely not clear to me how to proceed here. Another part of the trouble is that $a \frac{d}{dx}$ and $bI$ don't necessarily commute and because they do not commute I don't feel comfortable making the either of the jumps $e^{a \frac{d}{dx} + bI} = e^{a \frac{d}{dx}} \circ e^{bI}$ or $e^{bI} \circ e^{a \frac{d}{dx}}$ . (Actually we know for fact both those jumps are wrong from our earlier example) One simplification. If $c$ is a number and we did hypothetically know what $e^{\frac{d}{dx}(a(x)I)}$ was then $e^{c \frac{d}{dx}(a(x)I}$ would obviously just be the $c$ iterate of this linear operator. This comes in handy as $e^{\frac{d}{dx}(2I)} = e^{2 \frac{d}{dx}}$ then must be applying $e^{\frac{d}{dx}}$ twice. Of course $f \rightarrow f(x+1)$ twice is $f(x+2)$ .","In Quantum Mechanics we have the famous time evolution result (here is a constant) Which is an abuse of notation but makes sense due to Taylor's Theorem. In this answer I show we can give a closed form to whereas if we can find a constant and function so that: Then . As an example if and then: (letting we also can prove the quantum mechanics result above as special case of this) Now we also know that where is the identity operator. So with this in place I am curious if we can generally speaking give some kind of closed form for a generic exponential of a first order linear differential operator: My question is ""what should this evaluate to?"" and to put some boundaries on it, can we expect a general formula which involves finitely many functions and finitely many non-negative real numbers such that Where indicates the fractional derivative of ? Some Ideas: My first intuition when working with this abuse of notation is to factor it via integration factors (and at this point this is more symbol shuffling than math, I can hardly give a definition of what any of this means): But this doesn't necessarily help since I don't have any tools at the moment for evaluating . Even something as simple as we know to be . But how does one arrive at from which is the interpretation of or which is . It's just absolutely not clear to me how to proceed here. Another part of the trouble is that and don't necessarily commute and because they do not commute I don't feel comfortable making the either of the jumps or . (Actually we know for fact both those jumps are wrong from our earlier example) One simplification. If is a number and we did hypothetically know what was then would obviously just be the iterate of this linear operator. This comes in handy as then must be applying twice. Of course twice is .","a  e^{a \frac{d}{dx}}[f] = f(x+a)  e^{a(x) \frac{d}{dx}} r q a(x) = \frac{q(r)}{q'(x)}   e^{a(x) \frac{d}{dx}} [f] = f(q^{-1}(q(r)+q(x))) q = \ln(x) r=2 e^{\ln(2) x \frac{d}{dx}} = f(2x) q(x)=x, r=a e^{b(x)I}[f] = e^{b(x)}f I  e^{a(x) \frac{d}{dx} + b(x)I}[f]  w_1(x) ... w_k(x), c_1(x), ... c_k(x) d_1 ... d_k  e^{a(x) \frac{d}{dx} + b(x)I}[f] = w_1(x)f^{(d_1)}(c_1(x)) + w_2(x)f^{(d_2)}(c_2(x)) + ... w_k(x)f^{(d_k)}(c_k(x))  f^{(d_k)} d_k f  e^{a \frac{d}{dx} + bI} = e^{a(x) e^{-\int \frac{a}{b}}  \left( e^{\int \frac{a}{b}} I \right)' }    e^{\frac{d}{dx} \left(g(x) I \right)}  e^{\frac{d}{dx}(2I)} f(x+2) f(x+2) 2f(x) 2I e^2f e^{2I} a \frac{d}{dx} bI e^{a \frac{d}{dx} + bI} = e^{a \frac{d}{dx}} \circ e^{bI} e^{bI} \circ e^{a \frac{d}{dx}} c e^{\frac{d}{dx}(a(x)I)} e^{c \frac{d}{dx}(a(x)I} c e^{\frac{d}{dx}(2I)} = e^{2 \frac{d}{dx}} e^{\frac{d}{dx}} f \rightarrow f(x+1) f(x+2)","['functional-analysis', 'partial-differential-equations', 'operator-theory', 'operator-algebras', 'quantum-field-theory']"
63,Spectral theorem and invertible operators,Spectral theorem and invertible operators,,"Let $\mathcal{H}$ be a (infinite-dimensional) Hilbert space and $A:\mathcal{D}(A)\to\mathcal{H}$ be a densely-defined self-adjoint linear operator. Furthermore, assume that $A$ is injective and that its spectrum is strictly-positive, i.e. $\sigma(A)\subset [a,\infty)$ for some $a>0$ . Now, consider the following two constructions: Since $A$ is injective, $A:\mathcal{D}(A)\to\mathrm{ran}(A)$ is invertible and we get an inverse $A^{-1}:\mathrm{ran}(A)\to\mathcal{H}$ . For an injective self-adjoint operator, the range is dense, which shows that $A^{-1}$ is a densely-defined operator. By the assumption on the spectrum, the function $\sigma(A)\ni\lambda\mapsto\lambda^{-1}$ is well-defined and measurable. Hence, I can apply the spectral theorem to define an operator $A^{-1}$ via $$A^{-1}=\int_{\sigma(A)}\,\lambda^{-1}\,\mathrm{d}P(\lambda)$$ with domain $\mathcal{D}(A^{-1})=\{\omega\in\mathcal{H}\mid \int_{\sigma(A)}\,\lambda^{-2}\,\mathrm{d}\langle P(\lambda)\omega,\omega\rangle_{\mathcal{H}}<\infty\}$ , where $P$ denotes the spectral measure corresponding to $A$ . Are the two operators $A^{-1}$ defined above the same? Of course, by the properties of the spectral calculus, it is clear that $A^{-1}$ constructed as in (2) has similar properties as an inverse, i.e. $AA^{-1}=A^{-1}A=\mathrm{id}$ on the right domains. Hence the two operators defined in (1) and (2) agree on their common domain, I guess. But are the two domain the same in general?","Let be a (infinite-dimensional) Hilbert space and be a densely-defined self-adjoint linear operator. Furthermore, assume that is injective and that its spectrum is strictly-positive, i.e. for some . Now, consider the following two constructions: Since is injective, is invertible and we get an inverse . For an injective self-adjoint operator, the range is dense, which shows that is a densely-defined operator. By the assumption on the spectrum, the function is well-defined and measurable. Hence, I can apply the spectral theorem to define an operator via with domain , where denotes the spectral measure corresponding to . Are the two operators defined above the same? Of course, by the properties of the spectral calculus, it is clear that constructed as in (2) has similar properties as an inverse, i.e. on the right domains. Hence the two operators defined in (1) and (2) agree on their common domain, I guess. But are the two domain the same in general?","\mathcal{H} A:\mathcal{D}(A)\to\mathcal{H} A \sigma(A)\subset [a,\infty) a>0 A A:\mathcal{D}(A)\to\mathrm{ran}(A) A^{-1}:\mathrm{ran}(A)\to\mathcal{H} A^{-1} \sigma(A)\ni\lambda\mapsto\lambda^{-1} A^{-1} A^{-1}=\int_{\sigma(A)}\,\lambda^{-1}\,\mathrm{d}P(\lambda) \mathcal{D}(A^{-1})=\{\omega\in\mathcal{H}\mid
\int_{\sigma(A)}\,\lambda^{-2}\,\mathrm{d}\langle
P(\lambda)\omega,\omega\rangle_{\mathcal{H}}<\infty\} P A A^{-1} A^{-1} AA^{-1}=A^{-1}A=\mathrm{id}","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'spectral-theory', 'self-adjoint-operators']"
64,Is the following operator well-defined?,Is the following operator well-defined?,,"Let $u \in L^2(\Omega \times (0,T))$ where $\Omega \subset \mathbb{R}^n$ is an open bounded set and $T>0$ . Consider the operator $$F(u)=\begin{cases} u \quad \text{ if } \vert u(x,t) \vert \leq k \text{ for almost every } (x,t)\in \Omega \times (0,T)\\ k \quad \text{ if } u(x,t) > k \text{ for almost every } (x,t)\in \Omega \times (0,T)\\ -k \quad \text{ if } u(x,t)<-k \text{ for almost every } (x,t)\in \Omega \times (0,T) \end{cases}$$ Is $F$ well-defined for $u \in L^2(\Omega \times (0,T))$ ? Here is my approach: First, I had doubts that the regularity $L^2(\Omega \times (0,T))$ is not enough, since we cannot talk about pointwise values of $u$ in this case. But then again, I have tried to use the fact that since $u \in L^2(\Omega \times (0,T))$ then it is finite almost everywhere in $\Omega \times (0,T)$ and therefore it must satisfy one of the three cases indicated in the definition of $F$ and hence $F(u)$ is well-defined.","Let where is an open bounded set and . Consider the operator Is well-defined for ? Here is my approach: First, I had doubts that the regularity is not enough, since we cannot talk about pointwise values of in this case. But then again, I have tried to use the fact that since then it is finite almost everywhere in and therefore it must satisfy one of the three cases indicated in the definition of and hence is well-defined.","u \in L^2(\Omega \times (0,T)) \Omega \subset \mathbb{R}^n T>0 F(u)=\begin{cases} u \quad \text{ if } \vert u(x,t) \vert \leq k \text{ for almost every } (x,t)\in \Omega \times (0,T)\\
k \quad \text{ if } u(x,t) > k \text{ for almost every } (x,t)\in \Omega \times (0,T)\\
-k \quad \text{ if } u(x,t)<-k \text{ for almost every } (x,t)\in \Omega \times (0,T)
\end{cases} F u \in L^2(\Omega \times (0,T)) L^2(\Omega \times (0,T)) u u \in L^2(\Omega \times (0,T)) \Omega \times (0,T) F F(u)","['functional-analysis', 'operator-theory', 'lebesgue-integral', 'lebesgue-measure', 'bochner-spaces']"
65,What is a canonical embedding?,What is a canonical embedding?,,"I‘m taking a course in functional analysis and have to show that $ L^1(\mathbb R) \subsetneq (L^\infty(\mathbb R))^* $ ""in the sense of canonical embedding"". What does this mean exactly? Unfortunately, ""canonical embedding"" is no term we defined in the lecture so I assume it is some ""common term"". I think I have to show that there is a function $$ \iota: L^1(\mathbb R) \to (L^\infty(\mathbb R))^* $$ such that $ \iota(L^1(\mathbb R)) \subsetneq (L^\infty(\mathbb R))^* $ . But  just any function is probably not enough and $\iota$ has to satisfy some more properties. For example, i think injectivity would make sense. Can somebody tell me what one means with a ""canonical embedding""? Is it just a topological embedding, i.e. a homeomorphism onto its image as it is mentioned at Wikipedia?","I‘m taking a course in functional analysis and have to show that ""in the sense of canonical embedding"". What does this mean exactly? Unfortunately, ""canonical embedding"" is no term we defined in the lecture so I assume it is some ""common term"". I think I have to show that there is a function such that . But  just any function is probably not enough and has to satisfy some more properties. For example, i think injectivity would make sense. Can somebody tell me what one means with a ""canonical embedding""? Is it just a topological embedding, i.e. a homeomorphism onto its image as it is mentioned at Wikipedia?", L^1(\mathbb R) \subsetneq (L^\infty(\mathbb R))^*   \iota: L^1(\mathbb R) \to (L^\infty(\mathbb R))^*   \iota(L^1(\mathbb R)) \subsetneq (L^\infty(\mathbb R))^*  \iota,['functional-analysis']
66,Prove that the orthogonal projection $P$ does not depend on the chosen orthonormal basis used in the construction of $P$,Prove that the orthogonal projection  does not depend on the chosen orthonormal basis used in the construction of,P P,"Let $\left\{e_1, \ldots, e_n\right\}$ be a finite orthonormal system in an inner product space $(E,\langle\cdot, \cdot\rangle)$ and let us abbreviate $F:=\operatorname{span}\left\{e_1, \ldots, e_n\right\}$ . The mapping $$ P: E \longrightarrow E, \quad P f=\sum_{j=1}^n\left\langle f, e_j\right\rangle e_j $$ is called the orthogonal projection onto the subspace $F$ . I would like to prove that $P$ does only depend on the subspace $F$ and not on the chosen orthonormal basis of $F$ used in the construction of $P$ . My attempt Let $f, g \in E$ such that $g \in F$ and $f-g \perp F$ , I have to prove that $g=P f$ . Since $f-g \perp F$ and $f-Pf\perp F$ , we have that $$\langle f-g, e_i\rangle=\langle f-Pf, e_i\rangle=0\quad \forall i$$ then $$\langle f-g, e_i\rangle-\langle f-Pf, e_i\rangle=0$$ and so $$\langle f-g -(f-Pf), e_i\rangle=0\quad \forall i$$ from which $$\langle Pf-g, e_i\rangle=0\quad \forall i$$ And now? How could I proceed? I think that $Pf-g\perp F$ is not true, so we should have $Pf=g$ .","Let be a finite orthonormal system in an inner product space and let us abbreviate . The mapping is called the orthogonal projection onto the subspace . I would like to prove that does only depend on the subspace and not on the chosen orthonormal basis of used in the construction of . My attempt Let such that and , I have to prove that . Since and , we have that then and so from which And now? How could I proceed? I think that is not true, so we should have .","\left\{e_1, \ldots, e_n\right\} (E,\langle\cdot, \cdot\rangle) F:=\operatorname{span}\left\{e_1, \ldots, e_n\right\} 
P: E \longrightarrow E, \quad P f=\sum_{j=1}^n\left\langle f, e_j\right\rangle e_j
 F P F F P f, g \in E g \in F f-g \perp F g=P f f-g \perp F f-Pf\perp F \langle f-g, e_i\rangle=\langle f-Pf, e_i\rangle=0\quad \forall i \langle f-g, e_i\rangle-\langle f-Pf, e_i\rangle=0 \langle f-g -(f-Pf), e_i\rangle=0\quad \forall i \langle Pf-g, e_i\rangle=0\quad \forall i Pf-g\perp F Pf=g","['functional-analysis', 'projection']"
67,Statement on a neighborhood of $0$ in topological vector spaces,Statement on a neighborhood of  in topological vector spaces,0,"Consider a topological vector space $E$ and let $U\subseteq E$ be a neighborhood of $0$ . I want to understand the proof of the following statement: If $K\subseteq E$ is compact and $U$ is open with $K\subseteq U$ , then there exists an open $W\subseteq E$ with $0\in W$ , such that $K+W\subseteq U$ . The author of the book starts the proof as follows: For every $x\in K$ , one can pick $V$ a neighborhood of $0$ , such that $x+V\subseteq U$ . Unfortunately, I do not understand this step. Of course, since $U$ is a neighborhood of $0$ , I can find an open set, which contains $0$ and translating this by $x$ would be a neighborhood of $x$ , since the translation is an open map. However, I do not understand, why this should still be contained in $U$ . I have basically the following question: How can I guarantee, that the set $V$ is 'small' enough, such that $x+V$ is still contained in $U$ ? Besides that, I want to mention that the statement above is only one bullet point of a Lemma. Only for this statement, the author requires, that $U$ should be open. Maybe it has to do with the openness of $U$ ? Any help is appreciated! Thank you in advance!","Consider a topological vector space and let be a neighborhood of . I want to understand the proof of the following statement: If is compact and is open with , then there exists an open with , such that . The author of the book starts the proof as follows: For every , one can pick a neighborhood of , such that . Unfortunately, I do not understand this step. Of course, since is a neighborhood of , I can find an open set, which contains and translating this by would be a neighborhood of , since the translation is an open map. However, I do not understand, why this should still be contained in . I have basically the following question: How can I guarantee, that the set is 'small' enough, such that is still contained in ? Besides that, I want to mention that the statement above is only one bullet point of a Lemma. Only for this statement, the author requires, that should be open. Maybe it has to do with the openness of ? Any help is appreciated! Thank you in advance!",E U\subseteq E 0 K\subseteq E U K\subseteq U W\subseteq E 0\in W K+W\subseteq U x\in K V 0 x+V\subseteq U U 0 0 x x U V x+V U U U,"['general-topology', 'functional-analysis', 'topological-vector-spaces']"
68,What is the result of $\ell^1 \otimes \ell^1$?,What is the result of ?,\ell^1 \otimes \ell^1,"I recently stumbled upon the concept of a tensor product while studying quantum computing, and felt that my understanding of it from preliminary readings was incomplete. I challenged myself to determine the answer to this question in order to show that I had a full understanding of tensor products. I believe the answer should be $\mathbb{R}^\mathbb{N}$ (excuse the abuse of notation, I'm unfamiliar with a better way of denoting a countably infinite real space) or in fact $\ell^1$ itself once again. Any hints, ideas or explanations are appreciated!","I recently stumbled upon the concept of a tensor product while studying quantum computing, and felt that my understanding of it from preliminary readings was incomplete. I challenged myself to determine the answer to this question in order to show that I had a full understanding of tensor products. I believe the answer should be (excuse the abuse of notation, I'm unfamiliar with a better way of denoting a countably infinite real space) or in fact itself once again. Any hints, ideas or explanations are appreciated!",\mathbb{R}^\mathbb{N} \ell^1,"['functional-analysis', 'tensor-products', 'quantum-computation']"
69,Proving that Sobolev space embeds continuously into space of continuous functions,Proving that Sobolev space embeds continuously into space of continuous functions,,"We say $f \in L^2([-\pi, \pi])$ is an element of the Sobolev space $H^s(\mathbb{T})$ of order $s \geq 0$ if $$\sum_{n \in \mathbb{Z}} |\hat{f}(n)|^2 (1 + |n|^2)^s < \infty.$$ I am trying to prove the following: Let $s > \frac{1}{2}$ . If $f \in H^s(\mathbb{T})$ then $\exists g \in C([-\pi, \pi])$ such that $f = g$ a.e. I have already shown that $H^s(\mathbb{T})$ is a Hilbert space with Hermitian inner product $$\langle f, g \rangle_{H^s(\mathbb{T})} := \sum_{n \in \mathbb{Z}} \hat{f}(n) \overline{\hat{g}(n)} (1 + |n|^2)^s,$$ and I believe I can also show that $\exists C(s) > 0$ such that $$||f||_{\infty} \leq C(s) ||f||_{H^s(\mathbb{T})},$$ with an added hint that the Weierstrass M-test may be useful, but I am overall not sure how to proceed.","We say is an element of the Sobolev space of order if I am trying to prove the following: Let . If then such that a.e. I have already shown that is a Hilbert space with Hermitian inner product and I believe I can also show that such that with an added hint that the Weierstrass M-test may be useful, but I am overall not sure how to proceed.","f \in L^2([-\pi, \pi]) H^s(\mathbb{T}) s \geq 0 \sum_{n \in \mathbb{Z}} |\hat{f}(n)|^2 (1 + |n|^2)^s < \infty. s > \frac{1}{2} f \in H^s(\mathbb{T}) \exists g \in C([-\pi, \pi]) f = g H^s(\mathbb{T}) \langle f, g \rangle_{H^s(\mathbb{T})} := \sum_{n \in \mathbb{Z}} \hat{f}(n) \overline{\hat{g}(n)} (1 + |n|^2)^s, \exists C(s) > 0 ||f||_{\infty} \leq C(s) ||f||_{H^s(\mathbb{T})},","['functional-analysis', 'sobolev-spaces']"
70,"$H$ is Hilbert Space, select $x_n\in H$ such that $||x_n||=n$ then $\exists x \in H$ such that $\sup_n |(x_n,x)|=\infty$","is Hilbert Space, select  such that  then  such that","H x_n\in H ||x_n||=n \exists x \in H \sup_n |(x_n,x)|=\infty","$H$ is Hilbert Space and choose $x_n\in H$ such that $\|x_n\|=n$ then $\exists x \in H$ such that $\sup_n |(x_n,x)|=\infty$ Edit: I did the following : To get a contradiction, Assume $\forall y, \in H \sup_n |(x_n,y)| < M \ne \infty$ And by Riesz Rep. $\forall y\in H, T_n(y)=<y,x_n>$ such that $T_n \in H'$ so $T_n$ is bounded linear functional. Indeed, $\forall y\in H, T_n(y)$ is bounded. Now, applying Uniform Bounded Theorem I can say $||T_n||$ is bounded however $||T_n||=\sup_n \frac {||T_n (y)||}{||y||}\le \sup_n \frac{||y||||x_n||}{||y||}=\sup_n ||x_n||=\sup_n n$ which is not finite. (that doesnt work) And also $||T_n||=\sup_{||y||=1}||T_n (y)||=<y,x_n> \le ||y||||x_n||=||x_n||$ and I could not continue from here.","is Hilbert Space and choose such that then such that Edit: I did the following : To get a contradiction, Assume And by Riesz Rep. such that so is bounded linear functional. Indeed, is bounded. Now, applying Uniform Bounded Theorem I can say is bounded however which is not finite. (that doesnt work) And also and I could not continue from here.","H x_n\in H \|x_n\|=n \exists x \in H \sup_n |(x_n,x)|=\infty \forall y, \in H \sup_n |(x_n,y)| < M \ne \infty \forall y\in H, T_n(y)=<y,x_n> T_n \in H' T_n \forall y\in H, T_n(y) ||T_n|| ||T_n||=\sup_n \frac {||T_n (y)||}{||y||}\le \sup_n \frac{||y||||x_n||}{||y||}=\sup_n ||x_n||=\sup_n n ||T_n||=\sup_{||y||=1}||T_n (y)||=<y,x_n> \le ||y||||x_n||=||x_n||","['functional-analysis', 'solution-verification', 'hilbert-spaces']"
71,Importance of Cameron-Martin space for abstract Wiener space,Importance of Cameron-Martin space for abstract Wiener space,,"I have been reading a wikipedia entry on abstract Wiener space where they give as a motivation the necessity to define $$ \frac{1}{Z}\int_H f(v) e^{-\frac{1}{2} \Vert v\Vert^2} Dv, \tag{1} $$ which they say is an integral often met in physics. Here $H$ is some Hilbert space. The problem apparently is that it is hard to introduce a suirable measure $Dv$ on such space. For example, if one follows a construction of cylinder measures, one can get a nice behaving Gaussian set function, but only on an algebra, and it does not extend well to the $\sigma$ -algebra generated by those cylinder sets. Please correct me if my understanding is wrong here. Instead an idea is to consider a Banach space such that $i:H \to B$ makes $i(H)$ dense in $B$ and yet $B$ is sufficiently large so that the very same (?) cylinder set procedure with measure actually yeilds a nice behaving Gaussian measure $\gamma$ on the whole Borel $\sigma$ -algebra of $B$ . This is apparently a procedure authored by Leonard Grass, who also mentions something like: it is acutally $H$ that $\gamma$ very much depends on, not $B$ . This space $H$ is referred to as the Cameron-Martin space. I am very much lost here and hope that you could help my clarify understanding of this fact. My familiarity is with the classical Wiener space, let's say a Brownian motion law $\gamma_W$ on the Banach space $B_W = C_0(\Bbb R_+,\Bbb R)$ of all continuous function from $\Bbb R_+$ to $\Bbb R$ that start at $0$ . Such construction was done using finite-dimensional distributions, Kolomogorov's extensions theorem and Kolmogorov's continuity theorem. An in particular it so happened that $\gamma_W(C_0^1) = 0$ , i.e. a probability of getting a function with continuous derivative is $0$ . Yet, in the wikipedia article one uses $H_W = L^{2,1}_0(\Bbb R_+, \Bbb R)$ which is the Hilbert space of all continuously differentiable square integrable functions starting at $0$ with the inner product being $$ \langle \sigma_1, \sigma_2 \rangle_{L_0^{2,1}} := \int_0^\infty \dot{\sigma}_1 (t) \dot{\sigma}_2 (t) \, dt. $$ Now what I don't understand at all is: How exactly does $H_W$ help in constructing $\gamma_W$ ? I mean, in the end we'll even end up having $\gamma_W(H_W) = 0$ . How can it matter at all then? In the wikipedia article they use intergal $(1)$ as a motivation to formally define measures on Hilbert spaces. In the end the defined measure gives $0$ weight to $H$ , casting all integral to be $0$ as well. How was this useful then for the original problem?","I have been reading a wikipedia entry on abstract Wiener space where they give as a motivation the necessity to define which they say is an integral often met in physics. Here is some Hilbert space. The problem apparently is that it is hard to introduce a suirable measure on such space. For example, if one follows a construction of cylinder measures, one can get a nice behaving Gaussian set function, but only on an algebra, and it does not extend well to the -algebra generated by those cylinder sets. Please correct me if my understanding is wrong here. Instead an idea is to consider a Banach space such that makes dense in and yet is sufficiently large so that the very same (?) cylinder set procedure with measure actually yeilds a nice behaving Gaussian measure on the whole Borel -algebra of . This is apparently a procedure authored by Leonard Grass, who also mentions something like: it is acutally that very much depends on, not . This space is referred to as the Cameron-Martin space. I am very much lost here and hope that you could help my clarify understanding of this fact. My familiarity is with the classical Wiener space, let's say a Brownian motion law on the Banach space of all continuous function from to that start at . Such construction was done using finite-dimensional distributions, Kolomogorov's extensions theorem and Kolmogorov's continuity theorem. An in particular it so happened that , i.e. a probability of getting a function with continuous derivative is . Yet, in the wikipedia article one uses which is the Hilbert space of all continuously differentiable square integrable functions starting at with the inner product being Now what I don't understand at all is: How exactly does help in constructing ? I mean, in the end we'll even end up having . How can it matter at all then? In the wikipedia article they use intergal as a motivation to formally define measures on Hilbert spaces. In the end the defined measure gives weight to , casting all integral to be as well. How was this useful then for the original problem?","
\frac{1}{Z}\int_H f(v) e^{-\frac{1}{2} \Vert v\Vert^2} Dv, \tag{1}
 H Dv \sigma i:H \to B i(H) B B \gamma \sigma B H \gamma B H \gamma_W B_W = C_0(\Bbb R_+,\Bbb R) \Bbb R_+ \Bbb R 0 \gamma_W(C_0^1) = 0 0 H_W = L^{2,1}_0(\Bbb R_+, \Bbb R) 0 
\langle \sigma_1, \sigma_2 \rangle_{L_0^{2,1}} := \int_0^\infty \dot{\sigma}_1 (t) \dot{\sigma}_2 (t) \, dt.
 H_W \gamma_W \gamma_W(H_W) = 0 (1) 0 H 0","['functional-analysis', 'probability-theory', 'measure-theory', 'stochastic-processes']"
72,"If $x_n \to x$ and $y_n \to y$ weakly. Then $\langle x, y\rangle = \lim_n \langle x_n, y_n\rangle$",If  and  weakly. Then,"x_n \to x y_n \to y \langle x, y\rangle = \lim_n \langle x_n, y_n\rangle","I'm trying to show below property, i.e., Let $(H, \langle \cdot, \cdot\rangle)$ be a real Hilbert space. Let $x,y, x_n, y_n\in H$ such that $x_n \xrightarrow{n \to \infty} x$ and $y_n \xrightarrow{n \to \infty} y$ in the weak topology $\sigma(H, H^*)$ . Then $\langle x, y\rangle = \lim_n \langle x_n, y_n\rangle$ . Could you have a check on my below attempt? Is there another way that does not use below lemma? Thank you so much for your help! Let $\sigma (H, H^*) \otimes \sigma (H, H^*)$ be the product topology of $\sigma (H, H^*)$ and itself. Lemma $\sigma (H, H^*) \otimes \sigma (H, H^*)= \sigma (H^2, (H^2)^*)$ . By above Lemma , $(x_n, y_n) \xrightarrow{n \to \infty} (x, y)$ in $\sigma (H^2, (H^2)^*)$ . Clearly, the map $(u, v) \mapsto \langle u, v \rangle$ belongs to $(H^2)^*$ . The claim then follows.","I'm trying to show below property, i.e., Let be a real Hilbert space. Let such that and in the weak topology . Then . Could you have a check on my below attempt? Is there another way that does not use below lemma? Thank you so much for your help! Let be the product topology of and itself. Lemma . By above Lemma , in . Clearly, the map belongs to . The claim then follows.","(H, \langle \cdot, \cdot\rangle) x,y, x_n, y_n\in H x_n \xrightarrow{n \to \infty} x y_n \xrightarrow{n \to \infty} y \sigma(H, H^*) \langle x, y\rangle = \lim_n \langle x_n, y_n\rangle \sigma (H, H^*) \otimes \sigma (H, H^*) \sigma (H, H^*) \sigma (H, H^*) \otimes \sigma (H, H^*)= \sigma (H^2, (H^2)^*) (x_n, y_n) \xrightarrow{n \to \infty} (x, y) \sigma (H^2, (H^2)^*) (u, v) \mapsto \langle u, v \rangle (H^2)^*","['functional-analysis', 'hilbert-spaces', 'alternative-proof', 'weak-convergence', 'weak-topology']"
73,Does weak convergence in $H^1_0(\Omega)$ imply weak convergence of the weak derivatives in $L^2(\Omega)$?,Does weak convergence in  imply weak convergence of the weak derivatives in ?,H^1_0(\Omega) L^2(\Omega),"Let $\Omega\subset\mathbb{R}^N$ be bounded and consider a sequence of functions $(u_n)_n\subset H^1_0(\Omega)$ such that $u_n\rightharpoonup u\in H^1_0(\Omega)$ . Can we then say that $\partial_i u_n \rightharpoonup \partial_iu$ in $L^2(\Omega)$ for $i=\overline{1,N}$ ? My progress: since the inclusion $H^1_0(\Omega)\subset L^2(\Omega)$ is compact, eventually passing to a subsequence we can assume that $u_n\to u$ in $L^2(\Omega)$ . This allows us to assume that $u_n(x)\to u(x)$ for a.e. $x\in \Omega$ by again eventually passing to a subsequence. I wasn't able to use any of these general facts, I only thought that maybe it is enough to write the definition of $u_n \rightharpoonup u$ in $H^1_0(\Omega)$ , i.e. $$\int_\Omega \nabla u_n\cdot \nabla v \to \int_\Omega \nabla u \cdot \nabla v$$ for all $v\in H^1_0(\Omega)$ . This implies that $$\int_\Omega \partial_i u \cdot \partial_iv\to \int_\Omega \partial_i u \cdot \partial_i v$$ for all $v\in H^1_0(\Omega)$ . Now if for any $w\in L^2(\Omega)$ there would be some $v\in H^1_0(\Omega)$ such that $w=\partial_i v$ , then we would be done. I am not sure if this is true however and I don't know how to proceed.","Let be bounded and consider a sequence of functions such that . Can we then say that in for ? My progress: since the inclusion is compact, eventually passing to a subsequence we can assume that in . This allows us to assume that for a.e. by again eventually passing to a subsequence. I wasn't able to use any of these general facts, I only thought that maybe it is enough to write the definition of in , i.e. for all . This implies that for all . Now if for any there would be some such that , then we would be done. I am not sure if this is true however and I don't know how to proceed.","\Omega\subset\mathbb{R}^N (u_n)_n\subset H^1_0(\Omega) u_n\rightharpoonup u\in H^1_0(\Omega) \partial_i u_n \rightharpoonup \partial_iu L^2(\Omega) i=\overline{1,N} H^1_0(\Omega)\subset L^2(\Omega) u_n\to u L^2(\Omega) u_n(x)\to u(x) x\in \Omega u_n \rightharpoonup u H^1_0(\Omega) \int_\Omega \nabla u_n\cdot \nabla v \to \int_\Omega \nabla u \cdot \nabla v v\in H^1_0(\Omega) \int_\Omega \partial_i u \cdot \partial_iv\to \int_\Omega \partial_i u \cdot \partial_i v v\in H^1_0(\Omega) w\in L^2(\Omega) v\in H^1_0(\Omega) w=\partial_i v","['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'weak-convergence']"
74,"Sequence function on $C[-2,2]$ is Cauchy Sequence",Sequence function on  is Cauchy Sequence,"C[-2,2]","We consider the space $C[-2,2]$ and Euclidian norm $\left\| . \right\|_2$ . We observe the sequence of functions: $$ f_n(x)=\left\{\begin{matrix}0,  & x \notin [0,1]\\ nx,  & x \in [0,\frac{1}{n}]\\ 1,  & x \in [\frac{1}{n},1- \frac{1}{n}] \\ n(1-x)  & x \in [1-\frac{1}{n},1] \end{matrix}\right. $$ Is $f_n(x)$ a Cauchy Sequence wrt $\left\| . \right\|_2$ ? I am struggile to show either of those things. I cannot find counter example and I don´t get far when I try to prove that it is. Any tip or help would be appriciate!",We consider the space and Euclidian norm . We observe the sequence of functions: Is a Cauchy Sequence wrt ? I am struggile to show either of those things. I cannot find counter example and I don´t get far when I try to prove that it is. Any tip or help would be appriciate!,"C[-2,2] \left\| . \right\|_2  f_n(x)=\left\{\begin{matrix}0,
 & x \notin [0,1]\\ nx,
 & x \in [0,\frac{1}{n}]\\ 1,
 & x \in [\frac{1}{n},1- \frac{1}{n}] \\ n(1-x)
 & x \in [1-\frac{1}{n},1]
\end{matrix}\right.  f_n(x) \left\| . \right\|_2","['functional-analysis', 'normed-spaces', 'cauchy-sequences']"
75,"Does the operator have any eigenvalues, also is it compact?","Does the operator have any eigenvalues, also is it compact?",,"Question: Let $H=L^2([0,1],m)$ , where $m$ is the Lebesgue measure, and consider th    e operators $M,S\in L(H,H)$ given by $$ Mf(t)=tf(t), \; Sf(t)=f(1-t), f\in H, t\in [0,1]$$ You are not asked to verify that $M$ and $S$ defined bounded linear operators on $H$ .\ Justify that $M$ is self-adjoint, but not compact. Show that $\lVert Sf\rVert_2 = \lVert f \rVert_2$ , for all $f\in H$ . Does $S$ have any eigenvalues? Is $S$ compact? My Attempt: Note for $f_1\in H$ $$\langle M_t f,f_1\rangle=\int_{[0,1]} tf(t)\overline{f_1(t)}dm(t)=\int_{[0,1]} f(t)\overline{tf_1(t)}dm(t)=\langle f_1, M_{t}f\rangle$$ where we used $t\in [0,1]\subset \mathbb{R}$ . Thus it is self-adjoint. Moreoever by (something we proved in class) it follows that $M$ has no eigenvalues, yet $\sigma(M)=[0,1]$ , and so suppose for the sake of contradiction that $M$ is indeed compact. Then each non-zero $\lambda    \in [0,1]$ would also be an eigenvalue of $M$ , contradictory to the fact that $M$ has no eigen-values. Note $$ \langle Sf,f_1\rangle=\int_{[0,1]}f(1-t)\overline{f_1(t)}dm(t)=\int_{[0,1]}f(u)\overline{f(1-u)}dm(u)=\langle f,Sf\rangle$$ 0 Where we simply made a change of variables. To see $\lVert Sf\rVert_2=\lVert f \rVert_2$ note; $$\lVert Sf\rVert=\int_[0,1] f(1-t)^2 dm(t)=\int_[0,1] f(u)^2dm(u)=\lVert f\rVert  $$ where we made a simple change of variables. So we have shown $S$ is an isometry. Since we have isometry it follows that $$\langle f,f \rangle=\langle Sf, Sf\rangle=\langle \lambda f, \lambda f\rangle =\vert \lambda\vert^2 \langle f,f\rangle$$ from which we clearly see the only possible eigenvalues are $-1,1$ . Suppose for the sake of contradiction that $S$ is compact. Then we must have $\sigma(S)\setminus{\{0\}}=EV(S)\setminus{\{0\}}$ . But $\sigma(S)\setminus{\{0\}}\neq \{-1,1\}=EV(S)\setminus{\{0\}}$ and hence we have reached a contradiction and we conclude that $S$ is not compact. My questions: Does the proof look right?","Question: Let , where is the Lebesgue measure, and consider th    e operators given by You are not asked to verify that and defined bounded linear operators on .\ Justify that is self-adjoint, but not compact. Show that , for all . Does have any eigenvalues? Is compact? My Attempt: Note for where we used . Thus it is self-adjoint. Moreoever by (something we proved in class) it follows that has no eigenvalues, yet , and so suppose for the sake of contradiction that is indeed compact. Then each non-zero would also be an eigenvalue of , contradictory to the fact that has no eigen-values. Note 0 Where we simply made a change of variables. To see note; where we made a simple change of variables. So we have shown is an isometry. Since we have isometry it follows that from which we clearly see the only possible eigenvalues are . Suppose for the sake of contradiction that is compact. Then we must have . But and hence we have reached a contradiction and we conclude that is not compact. My questions: Does the proof look right?","H=L^2([0,1],m) m M,S\in L(H,H)  Mf(t)=tf(t), \; Sf(t)=f(1-t), f\in H, t\in [0,1] M S H M \lVert Sf\rVert_2 = \lVert f \rVert_2 f\in H S S f_1\in H \langle M_t f,f_1\rangle=\int_{[0,1]} tf(t)\overline{f_1(t)}dm(t)=\int_{[0,1]} f(t)\overline{tf_1(t)}dm(t)=\langle f_1, M_{t}f\rangle t\in [0,1]\subset \mathbb{R} M \sigma(M)=[0,1] M \lambda    \in [0,1] M M  \langle Sf,f_1\rangle=\int_{[0,1]}f(1-t)\overline{f_1(t)}dm(t)=\int_{[0,1]}f(u)\overline{f(1-u)}dm(u)=\langle f,Sf\rangle \lVert Sf\rVert_2=\lVert f \rVert_2 \lVert Sf\rVert=\int_[0,1] f(1-t)^2 dm(t)=\int_[0,1] f(u)^2dm(u)=\lVert f\rVert
  S \langle f,f \rangle=\langle Sf, Sf\rangle=\langle \lambda f, \lambda f\rangle =\vert \lambda\vert^2 \langle f,f\rangle -1,1 S \sigma(S)\setminus{\{0\}}=EV(S)\setminus{\{0\}} \sigma(S)\setminus{\{0\}}\neq \{-1,1\}=EV(S)\setminus{\{0\}} S","['functional-analysis', 'operator-theory', 'spectral-theory', 'compact-operators']"
76,Proving the space which consists sequences of finitely many non-zero terms is incomplete with respect to $2$ -norm,Proving the space which consists sequences of finitely many non-zero terms is incomplete with respect to  -norm,2,"In order to prove the space is not complete w.r.t to the given norm, we have to find a Cauchy sequence in the space but it does not converge to an element in the given set. My attempt was taking $(Z^n) = ( (1,0,0, ... ) , (1, 1/2, 0, 0, ... ), ....)$ I tried to prove this is Cauchy and ended up with, here $m>n$ , $\lVert Z^n - Z^m \rVert  \leq \dfrac {(m-n)^{1/2}}{n}$ how could I make this arbitrarily small? ( $<\epsilon$ ) here the $n$ th term of the sequence would be $Z^n = (1,1/2,1/3,...,1/n,0,0,0...)$ So when $n \rightarrow \infty$ , $z^n$ has infinitely many non zero terms, would that be enough to say the space is incomeplete?","In order to prove the space is not complete w.r.t to the given norm, we have to find a Cauchy sequence in the space but it does not converge to an element in the given set. My attempt was taking I tried to prove this is Cauchy and ended up with, here , how could I make this arbitrarily small? ( ) here the th term of the sequence would be So when , has infinitely many non zero terms, would that be enough to say the space is incomeplete?","(Z^n) = ( (1,0,0, ... ) , (1, 1/2, 0, 0, ... ), ....) m>n \lVert Z^n - Z^m \rVert  \leq \dfrac {(m-n)^{1/2}}{n} <\epsilon n Z^n = (1,1/2,1/3,...,1/n,0,0,0...) n \rightarrow \infty z^n","['functional-analysis', 'banach-spaces']"
77,equivalent condition of an element being positive in a $C^*$-algebra,equivalent condition of an element being positive in a -algebra,C^*,"Let $\mathcal{A}$ be a $C^*$ -algebra. Suppose $a,b\in\mathcal{A}$ with $a,b\geq 0$ and $\Vert a\Vert\leq\Vert b\Vert$ . Does it imply $a\leq b$ ? Comments: I could not be able to either prove it or find a counter-example. Any comment is highly appreciated. Thanks in advance.",Let be a -algebra. Suppose with and . Does it imply ? Comments: I could not be able to either prove it or find a counter-example. Any comment is highly appreciated. Thanks in advance.,"\mathcal{A} C^* a,b\in\mathcal{A} a,b\geq 0 \Vert a\Vert\leq\Vert b\Vert a\leq b","['functional-analysis', 'analysis', 'operator-theory', 'operator-algebras']"
78,"If $0 \leq A \leq B$ and $A$ and $B$ commute, then $A^n \leq B^n$","If  and  and  commute, then",0 \leq A \leq B A B A^n \leq B^n,"I am dealing with a problem from an old exam paper which might be simple but it turns out to be difficult for me to show. Here is the problem: Suppose that $0\leq A\leq B$ for self-adjoint elements $A,B$ in a $C^\ast$ -algebra. Then show that if $0\leq A\leq B$ and both $A$ and $B$ commute, then $A^n\leq B^n$ for every positive integer $n$ . More generally, show that if there are positive elements $C_j$ , $1\leq j\leq k$ with $0\leq A\leq C_1\leq C_2\leq \cdots \leq C_k\leq B$ so that any two neighbors in this list commute, then $A^n\leq B^n$ for every positive integer $n$ . I don't want the solution for this but maybe a sketch of strategy/sketch of proof so I can work the details out by my self. If you feel you would like to share a example of a solution then feel free. I just want to prepare for my exam in January. Thanks in advance.","I am dealing with a problem from an old exam paper which might be simple but it turns out to be difficult for me to show. Here is the problem: Suppose that for self-adjoint elements in a -algebra. Then show that if and both and commute, then for every positive integer . More generally, show that if there are positive elements , with so that any two neighbors in this list commute, then for every positive integer . I don't want the solution for this but maybe a sketch of strategy/sketch of proof so I can work the details out by my self. If you feel you would like to share a example of a solution then feel free. I just want to prepare for my exam in January. Thanks in advance.","0\leq A\leq B A,B C^\ast 0\leq A\leq B A B A^n\leq B^n n C_j 1\leq j\leq k 0\leq A\leq C_1\leq C_2\leq \cdots \leq C_k\leq B A^n\leq B^n n","['functional-analysis', 'operator-algebras']"
79,Prove the existence of a fixed point for the sum of two mappings,Prove the existence of a fixed point for the sum of two mappings,,"Let $X$ be a real valued Banach-space and $A \subseteq X$ which is bounded, closed and convex. Furthermore let $f,g,h : A \mapsto X$ be continuous with $f=g+h$ and $g(A)+h(A) \subseteq A$ . Lastly $g$ ist a contraction mapping and $h$ compact map. I'm supposed to show that $f$ has a fixed point $x^* \in A$ . Sadly I am getting nowhere with this. I know by Banach's theorem, that $g$ has a unique fixed point, and by Schauder's theorem, that $h$ has a non-unique fixed point. Obviously these fixed point need not coincide; even if they did it would do me no good. Furthermore I've been told as a hint to look at the map $id_A - g: A \mapsto X$ , where $id_A$ refers to the Identity. I'd appreciate a nudge in the right direction, since I'm getting nowhere with this.","Let be a real valued Banach-space and which is bounded, closed and convex. Furthermore let be continuous with and . Lastly ist a contraction mapping and compact map. I'm supposed to show that has a fixed point . Sadly I am getting nowhere with this. I know by Banach's theorem, that has a unique fixed point, and by Schauder's theorem, that has a non-unique fixed point. Obviously these fixed point need not coincide; even if they did it would do me no good. Furthermore I've been told as a hint to look at the map , where refers to the Identity. I'd appreciate a nudge in the right direction, since I'm getting nowhere with this.","X A \subseteq X f,g,h : A \mapsto X f=g+h g(A)+h(A) \subseteq A g h f x^* \in A g h id_A - g: A \mapsto X id_A","['functional-analysis', 'banach-spaces', 'fixed-point-theorems']"
80,"Two non-comparable metrics on $X=C[0,\pi]$",Two non-comparable metrics on,"X=C[0,\pi]","Problem: Show that the two metrics $$d_1(x,y)=\sup_{[0,\pi]}t^2\lvert {x(t)-y(t)}\rvert\text{ and }d_2(x,y)=\sup_{[0,\pi]}\sin(t)\lvert {x(t)-y(t)}\rvert$$ are not comparable on the set $X=C[0,\pi]$ of real valued continuous function defined on $[0,\pi]$ . In particular, find a set $A\subset{X}$ that is open with the metric $d_1$ but not open with $d_2$ . Here, comparable means convergence of a sequence in one metric implies the convergence of it in the other with the same limit. Since this convergence relation can be characterized by means of being open, problem asks me to show it using open sets. Now, I find it very difficult to construct such a set $A\subset{X}$ . I believe it must be about the relation between the functions $sin(t)$ and $t^2$ . For instance, I tried $A=\{x(t)\in{X} \lvert x(\pi)\gt{0}\}$ and showed that this set is open with respect to $d_1$ . However, I do not know whether it is also open with respect to $d_2$ or not, and even if it is not open, it confuses me a lot, how to show it? Any comment/idea is highly appreciated.","Problem: Show that the two metrics are not comparable on the set of real valued continuous function defined on . In particular, find a set that is open with the metric but not open with . Here, comparable means convergence of a sequence in one metric implies the convergence of it in the other with the same limit. Since this convergence relation can be characterized by means of being open, problem asks me to show it using open sets. Now, I find it very difficult to construct such a set . I believe it must be about the relation between the functions and . For instance, I tried and showed that this set is open with respect to . However, I do not know whether it is also open with respect to or not, and even if it is not open, it confuses me a lot, how to show it? Any comment/idea is highly appreciated.","d_1(x,y)=\sup_{[0,\pi]}t^2\lvert {x(t)-y(t)}\rvert\text{ and }d_2(x,y)=\sup_{[0,\pi]}\sin(t)\lvert {x(t)-y(t)}\rvert X=C[0,\pi] [0,\pi] A\subset{X} d_1 d_2 A\subset{X} sin(t) t^2 A=\{x(t)\in{X} \lvert x(\pi)\gt{0}\} d_1 d_2","['real-analysis', 'general-topology', 'functional-analysis', 'metric-spaces', 'function-spaces']"
81,is the absolute value of function $H^s$ also in $H^s$?,is the absolute value of function  also in ?,H^s H^s,"If $f$ and $g$ are (complex-valued) functions in the Sobolev space $H^s(\mathbb{R}^d)$ then any linear combination $f+\alpha g$ with $\alpha\in\mathbb{C}$ is also in $H^s(\mathbb{R}^d)$ since it is a vector space and, if $s>d/2$ , it can be shown that the product $fg$ is in $H^s(\mathbb{R}^d)$ with $$ \|fg\|_{H^s(\mathbb{R}^d)}\lesssim \|f\|_{H^s(\mathbb{R}^d)}\|g\|_{H^s(\mathbb{R}^d)} $$ I was wondering, however, what can be said about the absolute value of a function in $H^s(\mathbb{R}^d)$ . Is it true that if $f\in H^s(\mathbb{R}^d)$ then also $|f|\in H^s(\mathbb{R}^d)$ ? Here $|\cdot|$ denotes the absolute value in $\mathbb{C}$ since $f$ is possibly complex-valued. I've found two similar questions already (see 1 or 2 ) but none solved in full generality. If someone could help me by giving a hint or providing a reference I'd very much appreciate it, thank you :)","If and are (complex-valued) functions in the Sobolev space then any linear combination with is also in since it is a vector space and, if , it can be shown that the product is in with I was wondering, however, what can be said about the absolute value of a function in . Is it true that if then also ? Here denotes the absolute value in since is possibly complex-valued. I've found two similar questions already (see 1 or 2 ) but none solved in full generality. If someone could help me by giving a hint or providing a reference I'd very much appreciate it, thank you :)","f g H^s(\mathbb{R}^d) f+\alpha g \alpha\in\mathbb{C} H^s(\mathbb{R}^d) s>d/2 fg H^s(\mathbb{R}^d) 
\|fg\|_{H^s(\mathbb{R}^d)}\lesssim \|f\|_{H^s(\mathbb{R}^d)}\|g\|_{H^s(\mathbb{R}^d)}
 H^s(\mathbb{R}^d) f\in H^s(\mathbb{R}^d) |f|\in H^s(\mathbb{R}^d) |\cdot| \mathbb{C} f","['functional-analysis', 'sobolev-spaces', 'fractional-sobolev-spaces']"
82,For every polynomial $P$ of degree not greater than 2012 $\underset{3\leq t \leq 4}{\max}|P(t)|\leq C \underset{0\leq t \leq 1}{\max}|P(t)|$.,For every polynomial  of degree not greater than 2012 .,P \underset{3\leq t \leq 4}{\max}|P(t)|\leq C \underset{0\leq t \leq 1}{\max}|P(t)|,"Can you help me with the following? Prove that there exists constant $C$ such that for every polynomial $P$ of degree not greater than 2012 $\underset{3\leq t \leq 4}{\max}|P(t)|\leq C \underset{0\leq t \leq 1}{\max}|P(t)|$ . I know that set of polynomials on $[a,b]$ is subset of $C[a,b]$ and that $C[a,b]$ is isometric isomorph to $C[0,1]$ for every $a,b$ . So, $$ \underset{3\leq t \leq 4}{\max}|P(t)| = ||P||_{C[3,4]} = ||P||_{C[0,1]} = \underset{0\leq t \leq 1}{\max}|P(t)|,$$ so $C=1$ . I am very suspicious of this solution, can you tell me am I wrong and what should I do instead? Thank you!","Can you help me with the following? Prove that there exists constant such that for every polynomial of degree not greater than 2012 . I know that set of polynomials on is subset of and that is isometric isomorph to for every . So, so . I am very suspicious of this solution, can you tell me am I wrong and what should I do instead? Thank you!","C P \underset{3\leq t \leq 4}{\max}|P(t)|\leq C \underset{0\leq t \leq 1}{\max}|P(t)| [a,b] C[a,b] C[a,b] C[0,1] a,b  \underset{3\leq t \leq 4}{\max}|P(t)| = ||P||_{C[3,4]} = ||P||_{C[0,1]} = \underset{0\leq t \leq 1}{\max}|P(t)|, C=1","['functional-analysis', 'polynomials', 'continuity', 'normed-spaces', 'maxima-minima']"
83,Unclear on distributional derivative,Unclear on distributional derivative,,"Suppose we have a distribution $\phi \in D'(\mathbb{R}^n)$ . The distributional derivative of $\phi$ is defined as $$\phi'(g) = -\phi(g'), \quad \forall g \in C^\infty_C(\mathbb{R}^n).$$ I am clear on this definition and how it is motivated. What has been confusing me is perhaps to due with terminology. Suppose we look at the example of the Heaviside function: $$H(x) \begin{cases} 1, \quad x>0\\ 0, \quad x\leq 0.\end{cases}$$ We can define a distribution $\phi_H$ as $$\phi_H(g) =\langle H, g\rangle = \int H g dx.$$ In textbooks you see that the derivative of the Heaviside function is calculated as $$\langle H', g \rangle = \int H' g dx = -\int Hg'dx = -\int_0^\infty g' dx = g'(0) = \langle\delta, g'\rangle$$ and so we conclude that $H' = \delta$ , where $\delta$ is the Dirac-delta function. My question is do we say that the function $H$ has derivative $\delta$ , or that the distribution induced by $H$ (what I had called $\phi_H$ ) has derivative $\delta$ ? I assume it is the latter, but I see a lot of sources say statements such as ""the derivative of the Heaviside function is the Dirac-delta function"". Is this merely abuse of notation, or do they mean to say ""the distribution induced by the Heaviside function is equal to the Dirac-delta function/distribution"". Further, is there some other connection where one implies the other? From my reading it seems that if a function $f$ induces a distribution $\phi_f$ , and $f$ is differentiable, then the distributional derivative $\phi'_f$ is equal to the distribution induced by $f'$ , $\phi_{f'}$ . Can we say anything more?","Suppose we have a distribution . The distributional derivative of is defined as I am clear on this definition and how it is motivated. What has been confusing me is perhaps to due with terminology. Suppose we look at the example of the Heaviside function: We can define a distribution as In textbooks you see that the derivative of the Heaviside function is calculated as and so we conclude that , where is the Dirac-delta function. My question is do we say that the function has derivative , or that the distribution induced by (what I had called ) has derivative ? I assume it is the latter, but I see a lot of sources say statements such as ""the derivative of the Heaviside function is the Dirac-delta function"". Is this merely abuse of notation, or do they mean to say ""the distribution induced by the Heaviside function is equal to the Dirac-delta function/distribution"". Further, is there some other connection where one implies the other? From my reading it seems that if a function induces a distribution , and is differentiable, then the distributional derivative is equal to the distribution induced by , . Can we say anything more?","\phi \in D'(\mathbb{R}^n) \phi \phi'(g) = -\phi(g'), \quad \forall g \in C^\infty_C(\mathbb{R}^n). H(x) \begin{cases} 1, \quad x>0\\ 0, \quad x\leq 0.\end{cases} \phi_H \phi_H(g) =\langle H, g\rangle = \int H g dx. \langle H', g \rangle = \int H' g dx = -\int Hg'dx = -\int_0^\infty g' dx = g'(0) = \langle\delta, g'\rangle H' = \delta \delta H \delta H \phi_H \delta f \phi_f f \phi'_f f' \phi_{f'}","['functional-analysis', 'distribution-theory', 'dual-spaces']"
84,Is taylor series also an orthogonal projection of a infinitely differentiable function on some subspace?,Is taylor series also an orthogonal projection of a infinitely differentiable function on some subspace?,,"I'm wondering if there exists some inner product $\langle \cdot,\cdot \rangle$ defined on all real infinitely differentiable functions such that $$1, x, x^2, x^3, \ldots$$ are orthonormal w.r.t this inner product? If there does exist such an inner product, denote $$U_j=\text{span}(1,x,\ldots,x^j).$$ Then, is it true that, for an arbitrary infinitely differentiable function $f$ , $P_{U_j}(f)$ is $f$ 's $j$ th order taylor expansion at $x=0$ ?","I'm wondering if there exists some inner product defined on all real infinitely differentiable functions such that are orthonormal w.r.t this inner product? If there does exist such an inner product, denote Then, is it true that, for an arbitrary infinitely differentiable function , is 's th order taylor expansion at ?","\langle \cdot,\cdot \rangle 1, x, x^2, x^3, \ldots U_j=\text{span}(1,x,\ldots,x^j). f P_{U_j}(f) f j x=0","['linear-algebra', 'functional-analysis', 'analysis', 'taylor-expansion', 'orthonormal']"
85,Injective bounded linear operator on Banach space maps non-dense set to dense set.,Injective bounded linear operator on Banach space maps non-dense set to dense set.,,"Let $A\subseteq X$ be a subspace ( $X$ is a Banach space). Let $Y$ be another Banach space. Consider a continuous injective linear functional $f:X\rightarrow Y$ . Suppose $f(X)\subseteq \overline{f(A)}$ , is it true $X\subseteq \overline{A}$ ? I kind of feel this is obvious but cannot figure out a proof. (I guess this might be related to Baire Category theorem, but it seems open mapping theorem cannot be applied here.) The context of the problem is from the proof of Jacod Martingale representation theorem. $\mathcal{S}(A)\subseteq \mathcal{H}^2$ be the closed linear stable space generated by $A$ . The injection from $\mathcal{H}^2$ to $\mathcal{H}^1$ satisfying $\overline{i(S(A))}=\mathcal{H}^1$ . With the statement above, we can conclude $\mathcal{H}^2=\mathcal{S}(A)$ . Any comments or idea? Thanks in advance!","Let be a subspace ( is a Banach space). Let be another Banach space. Consider a continuous injective linear functional . Suppose , is it true ? I kind of feel this is obvious but cannot figure out a proof. (I guess this might be related to Baire Category theorem, but it seems open mapping theorem cannot be applied here.) The context of the problem is from the proof of Jacod Martingale representation theorem. be the closed linear stable space generated by . The injection from to satisfying . With the statement above, we can conclude . Any comments or idea? Thanks in advance!",A\subseteq X X Y f:X\rightarrow Y f(X)\subseteq \overline{f(A)} X\subseteq \overline{A} \mathcal{S}(A)\subseteq \mathcal{H}^2 A \mathcal{H}^2 \mathcal{H}^1 \overline{i(S(A))}=\mathcal{H}^1 \mathcal{H}^2=\mathcal{S}(A),"['real-analysis', 'functional-analysis']"
86,Is self-adjoint operator in a Hilbert space is always positive operator?,Is self-adjoint operator in a Hilbert space is always positive operator?,,"Let me first define the self-adjoint operator. Let $A$ be a bounded operator in a Hilbert space $H$ , then $A$ is said to be a self-adjoint operator if $A^*=A$ . And $A$ is known as a positive operator if $\langle Ax,x \rangle \geq 0$ . What I know is that a positive operator is not always a self-adjoint operator for example we can take the rotation operator in $\mathbb{R}^2$ . My question is whether the self-adjoint operator is always a positive operator? According to me it is not because if $A$ is a self-adjoint operator then $\langle Ax,x \rangle$ is real and when this is greater than or equal to zero then we say it is a positive operator but I am finding it difficult to construct an example.","Let me first define the self-adjoint operator. Let be a bounded operator in a Hilbert space , then is said to be a self-adjoint operator if . And is known as a positive operator if . What I know is that a positive operator is not always a self-adjoint operator for example we can take the rotation operator in . My question is whether the self-adjoint operator is always a positive operator? According to me it is not because if is a self-adjoint operator then is real and when this is greater than or equal to zero then we say it is a positive operator but I am finding it difficult to construct an example.","A H A A^*=A A \langle Ax,x \rangle \geq 0 \mathbb{R}^2 A \langle Ax,x \rangle","['functional-analysis', 'hilbert-spaces', 'positive-semidefinite', 'self-adjoint-operators']"
87,The closure of certain subspace of $\ell_\infty$,The closure of certain subspace of,\ell_\infty,"What is the  closure of the following subspace $A$ of $\ell_\infty$ with the standard sup norm of $\ell_\infty$ : $$A=\{(a_n)\in \ell_\infty\mid (A_n)=a_1+a_2+\ldots+a_n\; \text{belongs to} \;\ell_\infty \}$$ Is it true to say that $\bar{A}$ is the space of  all $(a_n)\in \ell_\infty$ such that the  Cesaro sum $\frac{a_1+a_2 +\ldots +a_n}{n}$ goes to zero? If it is the case, what is a proof?","What is the  closure of the following subspace of with the standard sup norm of : Is it true to say that is the space of  all such that the  Cesaro sum goes to zero? If it is the case, what is a proof?",A \ell_\infty \ell_\infty A=\{(a_n)\in \ell_\infty\mid (A_n)=a_1+a_2+\ldots+a_n\; \text{belongs to} \;\ell_\infty \} \bar{A} (a_n)\in \ell_\infty \frac{a_1+a_2 +\ldots +a_n}{n},"['real-analysis', 'sequences-and-series', 'functional-analysis', 'cesaro-summable']"
88,PDE in S.-T. Yau College Student Mathematics Contests 2019 [closed],PDE in S.-T. Yau College Student Mathematics Contests 2019 [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question This problem is from S.-T. Yau College Student Mathematics Contests 2019. I don't have enough pre-knowledge, but I want to learn. Let $\Omega \subset \mathbb{R}^2$ be a bounded domain with smooth boundary. Prove that, for all $p>1$ and $1\leq q<\infty$ , for all $f\in L^p(\Omega)$ , there exists a unique $u\in H^1_0(\Omega)$ , such that $$\Delta u = |u|^{q-1} u+f  \  \text{in} \ \Omega.$$","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question This problem is from S.-T. Yau College Student Mathematics Contests 2019. I don't have enough pre-knowledge, but I want to learn. Let be a bounded domain with smooth boundary. Prove that, for all and , for all , there exists a unique , such that",\Omega \subset \mathbb{R}^2 p>1 1\leq q<\infty f\in L^p(\Omega) u\in H^1_0(\Omega) \Delta u = |u|^{q-1} u+f  \  \text{in} \ \Omega.,"['functional-analysis', 'partial-differential-equations']"
89,Every contractive self-adjoint operator is the weak limit of projectors,Every contractive self-adjoint operator is the weak limit of projectors,,I try to show that every self-adjoint operator $A$ on Hilbert space $H$ with $\|A\| \leq 1$ is the weak limit of the projectors. My teacher told me that the most important part is to show that for one-dimensional operator and I have done that. But how can I obtain the general case form one-dimensional? I have no idea. Any help is appreciated. Thanks in advance.,I try to show that every self-adjoint operator on Hilbert space with is the weak limit of the projectors. My teacher told me that the most important part is to show that for one-dimensional operator and I have done that. But how can I obtain the general case form one-dimensional? I have no idea. Any help is appreciated. Thanks in advance.,A H \|A\| \leq 1,"['functional-analysis', 'operator-theory', 'weak-convergence', 'self-adjoint-operators']"
90,Prove or disprove: $t \mapsto \mathbb{P}( X_t \in A)$ is measurable,Prove or disprove:  is measurable,t \mapsto \mathbb{P}( X_t \in A),"Let $(X_t)_{t \geq 0}$ be an $\mathbb{R}$ -valued stochastic process and let the law of $X_t$ be given by $\mathbb{P}_t$ , $t \geq 0$ . Let $A \in \mathcal{B}(\mathbb{R})$ be a Borel set. I am interested in the measurability of the following mapping $$ [0, \infty ) \ni t \mapsto \mathbb{P} (X_t \in A) = \mathbb{E}[1_A(X_t)] \in [0, 1]. \tag{1} $$ under the conditions stated below. Here is an example showing that this mapping is not measurable in general. Let $N \subset [0, \infty)$ be a set which is not Borel measurable, and let the random variables $X_t$ , $t \geq 0$ , be such that $\mathbb{P}(X_t =1)=1_N(t)$ . Then clearly $t \mapsto \mathbb{P}(X_t = 1)$ is not measurable. Now assume that: If $(t_n) \subset [0, \infty)$ is such that $t_n \rightarrow t_0 \in [0, \infty)$ , then $\mathbb{P}_{t_n}$ converges weakly to $\mathbb{P}_{t_0}$ . This means that for every continuous and bounded function $f : \mathbb{R} \rightarrow \mathbb{R}$ we have $$ \int_{\mathbb{R}} f(x) \mathbb{P}_{t_n} (dx) = \mathbb{E} [f (X_{t_n})] \overset{n \rightarrow \infty}{\rightarrow} \int_{\mathbb{R}} f(x) \mathbb{P}_{t_0} (dx) = \mathbb{E} [f (X_{t_0})] $$ The assertion is also true for bounded Lipschitz functions. Does this ensure the measurability? Is it maybe possible to approximate the indicator function $x \mapsto 1_A(x)$ by suitable continuous functions which will imply the measurability? Alternatively, is it possible to obtain a right-continuous modification of $(X_t)_{t \geq 0}$ under these conditions? If so, this will ensure the joint measurability of $(t, \omega ) \mapsto X_t (\omega)$ and Tonelli's theorem will yield the measurability of the mapping in $(1)$ . If the answer is affirmative, it would be interesting to see if it also applies to the case where $X_t$ , $t \geq 0$ , are $S$ -valued for a sufficiently nice metric space $S$ .","Let be an -valued stochastic process and let the law of be given by , . Let be a Borel set. I am interested in the measurability of the following mapping under the conditions stated below. Here is an example showing that this mapping is not measurable in general. Let be a set which is not Borel measurable, and let the random variables , , be such that . Then clearly is not measurable. Now assume that: If is such that , then converges weakly to . This means that for every continuous and bounded function we have The assertion is also true for bounded Lipschitz functions. Does this ensure the measurability? Is it maybe possible to approximate the indicator function by suitable continuous functions which will imply the measurability? Alternatively, is it possible to obtain a right-continuous modification of under these conditions? If so, this will ensure the joint measurability of and Tonelli's theorem will yield the measurability of the mapping in . If the answer is affirmative, it would be interesting to see if it also applies to the case where , , are -valued for a sufficiently nice metric space .","(X_t)_{t \geq 0} \mathbb{R} X_t \mathbb{P}_t t \geq 0 A \in \mathcal{B}(\mathbb{R}) 
[0, \infty ) \ni t \mapsto \mathbb{P} (X_t \in A) = \mathbb{E}[1_A(X_t)] \in [0, 1]. \tag{1}
 N \subset [0, \infty) X_t t \geq 0 \mathbb{P}(X_t =1)=1_N(t) t \mapsto \mathbb{P}(X_t = 1) (t_n) \subset [0, \infty) t_n \rightarrow t_0 \in [0, \infty) \mathbb{P}_{t_n} \mathbb{P}_{t_0} f : \mathbb{R} \rightarrow \mathbb{R} 
\int_{\mathbb{R}} f(x) \mathbb{P}_{t_n} (dx) = \mathbb{E} [f (X_{t_n})] \overset{n \rightarrow \infty}{\rightarrow} \int_{\mathbb{R}} f(x) \mathbb{P}_{t_0} (dx) = \mathbb{E} [f (X_{t_0})]
 x \mapsto 1_A(x) (X_t)_{t \geq 0} (t, \omega ) \mapsto X_t (\omega) (1) X_t t \geq 0 S S","['real-analysis', 'functional-analysis', 'probability-theory', 'measure-theory']"
91,"Compressible Navier-Stokes vs Incompressible, which is 'Easier' or usually has shorter computation times for finding numerical solutions?","Compressible Navier-Stokes vs Incompressible, which is 'Easier' or usually has shorter computation times for finding numerical solutions?",,"This is a broad question which might not have a clear answer. I am aware that the incompressible NS equations can be used to approximate the compressible when the Mach number is low, and that this approximation is validated by results in functional analysis. However, I am currently wondering what the 'use' is for this approximation. I remember during my bachelor's degree in physics lessons that we were taught that this approximation was useful as the incompressible version was 'easier' for computing (by hand) exact solutions in specific cases like pipe flow. This just seemed intuitive to me at the time, as there were of course fewer terms. Does this hold true when computing numerical solutions though? Is the incompressible version easier in most or even any cases? I ask as I am aware that the incompressible version can have its own set of problems (for example one can't use the barotropic assumption that the pressure is just the density to the power of some constant in the incompressible case). So perhaps no broad comparisons between the two make sense?","This is a broad question which might not have a clear answer. I am aware that the incompressible NS equations can be used to approximate the compressible when the Mach number is low, and that this approximation is validated by results in functional analysis. However, I am currently wondering what the 'use' is for this approximation. I remember during my bachelor's degree in physics lessons that we were taught that this approximation was useful as the incompressible version was 'easier' for computing (by hand) exact solutions in specific cases like pipe flow. This just seemed intuitive to me at the time, as there were of course fewer terms. Does this hold true when computing numerical solutions though? Is the incompressible version easier in most or even any cases? I ask as I am aware that the incompressible version can have its own set of problems (for example one can't use the barotropic assumption that the pressure is just the density to the power of some constant in the incompressible case). So perhaps no broad comparisons between the two make sense?",,"['functional-analysis', 'partial-differential-equations', 'numerical-methods', 'physics', 'fluid-dynamics']"
92,Space of bounded continuous functions complete [closed],Space of bounded continuous functions complete [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Prove that the space of bounded continuous functions $C^0(F,X):=\{f: F\rightarrow X : f$ is continuous and bounded $\}$ with $X$ Banach space, $F\subset \mathbb{R}$ is complete with the sup norm. I have seen many proves of this for $X=\mathbb{R}$ but how do I do this for an arbitrary Banach space? My idea was to show that a Cauchy sequence $(f_n)_n\in C^0(F,X)$ is also a Cauchy sequence in $X$ and since $X$ is complete it follows $u_k \rightarrow u \in X$ . Now I need to show that $u$ is continuous and bounded. Problem: for $X=\mathbb{R}$ I can use uniformly convergence and the uniform limit theorem but I don't know if these theorems apply for any arbitrary Banach space? How do I prove this statement? Thanks you!","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Prove that the space of bounded continuous functions is continuous and bounded with Banach space, is complete with the sup norm. I have seen many proves of this for but how do I do this for an arbitrary Banach space? My idea was to show that a Cauchy sequence is also a Cauchy sequence in and since is complete it follows . Now I need to show that is continuous and bounded. Problem: for I can use uniformly convergence and the uniform limit theorem but I don't know if these theorems apply for any arbitrary Banach space? How do I prove this statement? Thanks you!","C^0(F,X):=\{f: F\rightarrow X : f \} X F\subset \mathbb{R} X=\mathbb{R} (f_n)_n\in C^0(F,X) X X u_k \rightarrow u \in X u X=\mathbb{R}","['functional-analysis', 'banach-spaces']"
93,Every normed space with countable dimension is separable.,Every normed space with countable dimension is separable.,,"I am trying to figure out if this reult from functional analysis is true. ""Every normed space with countable Hamel dimension is separable."" I know that this hold if the space is of finite dimension and i know that proof using the density of rationals in R, also I am pretty sure that this is true(for the space being of countable dimension) and that the proof of it goes quite similarly as if the space was finite dimensional, with small changes. I just wanted some help for confirmation, not even the proof, just if this is indeed true.","I am trying to figure out if this reult from functional analysis is true. ""Every normed space with countable Hamel dimension is separable."" I know that this hold if the space is of finite dimension and i know that proof using the density of rationals in R, also I am pretty sure that this is true(for the space being of countable dimension) and that the proof of it goes quite similarly as if the space was finite dimensional, with small changes. I just wanted some help for confirmation, not even the proof, just if this is indeed true.",,"['functional-analysis', 'normed-spaces', 'separable-spaces']"
94,Can I prove this inequality only by elementary tools?,Can I prove this inequality only by elementary tools?,,"Let $\Omega\in\mathbb{R}^2$ be a bounded domain, $\forall a,b,c \in \mathbb{R}$ , I hope to prove that there exists a positive constant $\alpha$ such that: $$ \int_{\Omega} (ax_2+b)^2 + ( -ax_1+c)^2 \geqslant \alpha a^2 $$ where $\alpha$ is independent in $a,b,c$ . I really hope for a directly proof instead of the proof by contradiction.","Let be a bounded domain, , I hope to prove that there exists a positive constant such that: where is independent in . I really hope for a directly proof instead of the proof by contradiction.","\Omega\in\mathbb{R}^2 \forall a,b,c \in \mathbb{R} \alpha 
\int_{\Omega} (ax_2+b)^2 + ( -ax_1+c)^2 \geqslant \alpha a^2
 \alpha a,b,c","['functional-analysis', 'analysis', 'inequality', 'integral-inequality']"
95,Is there a closed set which doesn't have a minimal distance to a point?,Is there a closed set which doesn't have a minimal distance to a point?,,"I am currently studying functional analysis and in the lecture we had the following theorem: Let $X$ be a reflexive normed space. Let $A \subset X$ be a convex, closed non-empty subset and let $x_0 \notin A$ be a point. Then there is an $x \in A$ such that $$||x_0 - x||_X=\text{dist}(x_0,A) = \text{inf}_{y \in A} \{||x_0 - y||\}$$ So there is actually a point in $A$ which has minimum distance to $x_0$ . Now I wonder, what would be a counterexample of this statement, if we exclude the convexity? Or the reflexivity? I already am pretty sure that there only can be such a counter example in an infinite dimensional vectorspace, since in a finite dimensional space, we can look at $\mathbb{R}^n$ (because all normes are equivalent) and can define a sequence $x_n$ in $X$ such that $||x_0 - x_n|| \rightarrow \text{dist}(x_0, A)$ for $n \rightarrow \infty$ . The alomost every element in the sequence is in a ball of radius $\text{dist}(x_0, A) +1$ around $x_0$ , so the sequence is bounded and therefore admits a convergent subsequence which converges in $A$ , since it is closed. If I didn't make a mistake, closedness should therefore be sufficiant in finite dimensions, but what about infinite? I am thinking for a while now and I just can't come up with a example.. Looking forward to your replies! Hannes","I am currently studying functional analysis and in the lecture we had the following theorem: Let be a reflexive normed space. Let be a convex, closed non-empty subset and let be a point. Then there is an such that So there is actually a point in which has minimum distance to . Now I wonder, what would be a counterexample of this statement, if we exclude the convexity? Or the reflexivity? I already am pretty sure that there only can be such a counter example in an infinite dimensional vectorspace, since in a finite dimensional space, we can look at (because all normes are equivalent) and can define a sequence in such that for . The alomost every element in the sequence is in a ball of radius around , so the sequence is bounded and therefore admits a convergent subsequence which converges in , since it is closed. If I didn't make a mistake, closedness should therefore be sufficiant in finite dimensions, but what about infinite? I am thinking for a while now and I just can't come up with a example.. Looking forward to your replies! Hannes","X A \subset X x_0 \notin A x \in A ||x_0 - x||_X=\text{dist}(x_0,A) = \text{inf}_{y \in A} \{||x_0 - y||\} A x_0 \mathbb{R}^n x_n X ||x_0 - x_n|| \rightarrow \text{dist}(x_0, A) n \rightarrow \infty \text{dist}(x_0, A) +1 x_0 A",['functional-analysis']
96,Spectral decomposition of compact self-adjoint operator,Spectral decomposition of compact self-adjoint operator,,"Consider the following fragment from Takesaki's book ""Theory of operator algebra I"": I can't quite figure out rigorously why the boxed part of the proof is true. Note that I want to make sure that $n \mapsto \xi_n$ is injective (of course, for distinct $n$ the same $\alpha_n$ may occur). I tried to write $e_0 := 0$ . Then we have the convergence $$x = \sum_{n=1}^\infty x(e_n-e_{n-1})$$ in the norm-topology and $xe_n-xe_{n-1}$ is a linear combination of $\alpha_n$ 's and $t_{\xi_n, \xi_n}$ 's, so at best we can write something like $$x= \sum_{n=1}^\infty \sum_{k=1}^{z_n} \alpha_{k,n} t_{\xi_{k,n}, \xi_{k,n}}.$$ Of course, we still need to eliminate the second sum (depending on $n$ ) and somehow absorb it in the large sum and we also need to ensure that $n \mapsto \xi_n$ is injective in the end product. I can't get these technical details right. Any help will be greatly appreciated!","Consider the following fragment from Takesaki's book ""Theory of operator algebra I"": I can't quite figure out rigorously why the boxed part of the proof is true. Note that I want to make sure that is injective (of course, for distinct the same may occur). I tried to write . Then we have the convergence in the norm-topology and is a linear combination of 's and 's, so at best we can write something like Of course, we still need to eliminate the second sum (depending on ) and somehow absorb it in the large sum and we also need to ensure that is injective in the end product. I can't get these technical details right. Any help will be greatly appreciated!","n \mapsto \xi_n n \alpha_n e_0 := 0 x = \sum_{n=1}^\infty x(e_n-e_{n-1}) xe_n-xe_{n-1} \alpha_n t_{\xi_n, \xi_n} x= \sum_{n=1}^\infty \sum_{k=1}^{z_n} \alpha_{k,n} t_{\xi_{k,n}, \xi_{k,n}}. n n \mapsto \xi_n","['functional-analysis', 'operator-algebras', 'spectral-theory', 'compact-operators']"
97,An application of Baire Category Theorem,An application of Baire Category Theorem,,"I am trying to prove a proposition that $BV[a.b]\cap C[a.b]$ equipped with the $||\cdot||_\infty$ is Baire 1 category set, which will tell us that $E=\{f:V(f)=\infty, f\in C[a,b]\}$ is a dense Baire 2 category set in $C[a.b]$ . My attempt: I define $F_n=\{f: V(f)\leq n, f\in C[a,b]\}$ , then we know that $\cup_{n=1}^{\infty}F_n=BV[a.b]\cap C[a.b]$ . I am trying to show that this is a Baire 1 category set, then we are done. In order to show that, we just need to prove the following: 1. $F_n$ is closed. 2. $F_n$ has no interior point for every n. I have figured out the second claim by using sawtooth functions, but I have some problems when i try to prove the first claim. We suppose $f_n\rightarrow f$ uniformly, then by the definition and some easy calculation, we know that for every $\epsilon>0$ , there exists a $m_0$ such that $V(f)\leq V(f_{m_0})+2n\epsilon$ , where $n$ is the number of partition (where $a=x_0\leq x_1\leq \cdots\leq x_{n}=b$ ). So when n goes larger and larger, we can't give an estimation for $V(f)$ , this is why i get confused. My questions: $F_n$ is closed or not? if so, how to prove that? if not so, how do we prove the proposition at first? Any help will be truly grateful.","I am trying to prove a proposition that equipped with the is Baire 1 category set, which will tell us that is a dense Baire 2 category set in . My attempt: I define , then we know that . I am trying to show that this is a Baire 1 category set, then we are done. In order to show that, we just need to prove the following: 1. is closed. 2. has no interior point for every n. I have figured out the second claim by using sawtooth functions, but I have some problems when i try to prove the first claim. We suppose uniformly, then by the definition and some easy calculation, we know that for every , there exists a such that , where is the number of partition (where ). So when n goes larger and larger, we can't give an estimation for , this is why i get confused. My questions: is closed or not? if so, how to prove that? if not so, how do we prove the proposition at first? Any help will be truly grateful.","BV[a.b]\cap C[a.b] ||\cdot||_\infty E=\{f:V(f)=\infty, f\in C[a,b]\} C[a.b] F_n=\{f: V(f)\leq n, f\in C[a,b]\} \cup_{n=1}^{\infty}F_n=BV[a.b]\cap C[a.b] F_n F_n f_n\rightarrow f \epsilon>0 m_0 V(f)\leq V(f_{m_0})+2n\epsilon n a=x_0\leq x_1\leq \cdots\leq x_{n}=b V(f) F_n","['real-analysis', 'functional-analysis', 'bounded-variation', 'baire-category']"
98,Clarification of showing that something is an involution e.g. *-algebra,Clarification of showing that something is an involution e.g. *-algebra,,"Let $\ell^1(\mathbb{Z}):=\{(x_n)_{n\in\mathbb{Z}}:x_n\in\mathbb{C},\sum_{k\in\mathbb{Z}}|x_n|<+\infty\}$ . Given by $(x^\ast)_n:=\overline{x_{-n}}$ , we want to show that for $x \in \ell^{1}(\mathbb{Z})$ , $\ell^{1}(\mathbb{Z})$ is a $*-algebra$ claim: $(x^\ast)^\ast=x$ , $\forall x\in \ell^1(\mathbb{Z})$ . \begin{equation*}     (x^\ast)^\ast=(\bar{x})^\ast=\bar{\bar{x}}=x. \end{equation*} 2. Let $x,y\in \ell^1(\mathbb{Z})$ and $a,b\in\mathbb{C}$ . Claim: \begin{equation*}     (ax+by)^\ast=\bar{a}x^\ast+\bar{b}y^\ast=\bar{a}\bar{x}+\bar{b}\bar{y}=\overline{ax}+\overline{by}=(ax)^\ast+(by)^\ast=(ax+by)^\ast. \end{equation*} 3. $x,y\in\ell^1(\mathbb{Z}) $ claim: \begin{equation*}     (xy)^\ast=y^\ast x^\ast \end{equation*} But $(xy)^\ast=(\overline{xy})=(yx)$ and then what??? Furthermore, I must show that $*$ is an isometry, which can easily be done if I show that \begin{align*}     ||x||^{2} \leq ||x^{*}x||, \end{align*} but I am not quite sure if that inequality holds $\forall x \in \ell^{1}(\mathbb{Z}) $","Let . Given by , we want to show that for , is a claim: , . 2. Let and . Claim: 3. claim: But and then what??? Furthermore, I must show that is an isometry, which can easily be done if I show that but I am not quite sure if that inequality holds","\ell^1(\mathbb{Z}):=\{(x_n)_{n\in\mathbb{Z}}:x_n\in\mathbb{C},\sum_{k\in\mathbb{Z}}|x_n|<+\infty\} (x^\ast)_n:=\overline{x_{-n}} x \in \ell^{1}(\mathbb{Z}) \ell^{1}(\mathbb{Z}) *-algebra (x^\ast)^\ast=x \forall x\in \ell^1(\mathbb{Z}) \begin{equation*}
    (x^\ast)^\ast=(\bar{x})^\ast=\bar{\bar{x}}=x.
\end{equation*} x,y\in \ell^1(\mathbb{Z}) a,b\in\mathbb{C} \begin{equation*}
    (ax+by)^\ast=\bar{a}x^\ast+\bar{b}y^\ast=\bar{a}\bar{x}+\bar{b}\bar{y}=\overline{ax}+\overline{by}=(ax)^\ast+(by)^\ast=(ax+by)^\ast.
\end{equation*} x,y\in\ell^1(\mathbb{Z})  \begin{equation*}
    (xy)^\ast=y^\ast x^\ast
\end{equation*} (xy)^\ast=(\overline{xy})=(yx) * \begin{align*}
    ||x||^{2} \leq ||x^{*}x||,
\end{align*} \forall x \in \ell^{1}(\mathbb{Z}) ","['calculus', 'linear-algebra', 'functional-analysis', 'operator-theory']"
99,For which $f: \mathbb{Q}\rightarrow\mathbb{Q}^+$ does the sum $\sum_{q\in\mathbb{Q}} f(q)$ converge?,For which  does the sum  converge?,f: \mathbb{Q}\rightarrow\mathbb{Q}^+ \sum_{q\in\mathbb{Q}} f(q),"BACKGROUND: This is not a homework question -- I am not even in school. I am purely interested in the question itself. I actually asked this question in my second semester of real analysis during my math major, but that was years ago. The professor found the question interesting but was unable to provide a satisfying answer. I know the sum $\sum_{q\in\mathbb{Q}\cap[0,\varepsilon)}q$ diverges to $\infty$ (since infinitely many terms are larger than $\frac{\varepsilon}{2}$ ). But $\mathbb{Q}$ is countable, and so there must be some ""sums over the rationals"" which converge. Of course we need to avoid the ambiguity of unordered infinite series with positive and negative terms (since rearrangement of terms does not preserve the sum). So I am only interested in sums of positive terms, i.e. $\sum_{q\in\mathbb{Q}}f(q)$ where $f:\mathbb{Q}\rightarrow\mathbb{Q}^+$ . Intuitively, the density of $\mathbb{Q}$ makes convergence a lot harder to achieve for an arbitrary sum. We won't have success with something like $\sum_{q\in\mathbb{Q}\backslash\{0\}}\frac{1}{q^2}$ , since there will still be too many terms that are bigger than any $\varepsilon>0$ , in this case for all $q\in \mathbb{Q}^{\neq0}\cap\big(-\frac{1}{\sqrt{\varepsilon}},\frac{1}{\sqrt{\varepsilon}}\big)$ . This seems to suggest that functions that have a simple formula for $f(q)$ , written in terms of $q$ , will rarely (almost never?) have a convergent sum. So to make my question a bit more specific and therefore easier to answer, I want to focus my question only on the following example. MY ACTUAL QUESTION: Any rational number can be uniquely described as a fraction in lowest terms. For which positive real numbers $a$ and $b$ does the following sum converge? $$\sum_{\frac{m}{n} \in \mathbb{Q}} \frac{1}{|m|^a+|n|^b}$$ Intuitively, if we use powers of $1$ , then this fraction might--like the harmonic series--not shrink to zero quickly enough for the sum to converge. To further build intuition, I will informally define the "" ${l}^a$ complexity"" of rational numbers to be $$\bigg|\frac{m}{n}\bigg|_a=\big(|m|^a+|n|^a\big)^{\frac{1}{a}}$$ To illustrate, $\big|\frac{-3}{4}\big|_2=(3^2+4^2)^\frac{1}{2}=\sqrt{25}=5$ , but $\big|\frac{-3}{4}\big|_1=(3^1+4^1)^\frac{1}{1}=7$ . To avoid ambiguity, we will choose the canonical representation of $0$ to be the fraction $\frac{0}{1}$ , so that $|0|_a=(0^a+1^a)^\frac{1}{a}=1$ . Since $0=\frac{0}{1}$ is the rational number written with the smallest possible numerator and denominator, we see that $|q|_a \geq 1$ for any $q\in\mathbb{Q}$ . In general, ""more complicated"" rational numbers will have larger $l^a$ complexity than ""simpler"" rational numbers: $\big|\frac{456}{1207}\big|_a>\big|\frac{1}{2}\big|_a$ . This leads to an even smaller and more restrictive question. A SIMPLER QUESTION THAT MIGHT HELP ME MAKE PROGRESS: For which $a>1$ does the following sum converge? $$\sum_{q\in\mathbb{Q}} \frac{1}{|q|_a^a}$$","BACKGROUND: This is not a homework question -- I am not even in school. I am purely interested in the question itself. I actually asked this question in my second semester of real analysis during my math major, but that was years ago. The professor found the question interesting but was unable to provide a satisfying answer. I know the sum diverges to (since infinitely many terms are larger than ). But is countable, and so there must be some ""sums over the rationals"" which converge. Of course we need to avoid the ambiguity of unordered infinite series with positive and negative terms (since rearrangement of terms does not preserve the sum). So I am only interested in sums of positive terms, i.e. where . Intuitively, the density of makes convergence a lot harder to achieve for an arbitrary sum. We won't have success with something like , since there will still be too many terms that are bigger than any , in this case for all . This seems to suggest that functions that have a simple formula for , written in terms of , will rarely (almost never?) have a convergent sum. So to make my question a bit more specific and therefore easier to answer, I want to focus my question only on the following example. MY ACTUAL QUESTION: Any rational number can be uniquely described as a fraction in lowest terms. For which positive real numbers and does the following sum converge? Intuitively, if we use powers of , then this fraction might--like the harmonic series--not shrink to zero quickly enough for the sum to converge. To further build intuition, I will informally define the "" complexity"" of rational numbers to be To illustrate, , but . To avoid ambiguity, we will choose the canonical representation of to be the fraction , so that . Since is the rational number written with the smallest possible numerator and denominator, we see that for any . In general, ""more complicated"" rational numbers will have larger complexity than ""simpler"" rational numbers: . This leads to an even smaller and more restrictive question. A SIMPLER QUESTION THAT MIGHT HELP ME MAKE PROGRESS: For which does the following sum converge?","\sum_{q\in\mathbb{Q}\cap[0,\varepsilon)}q \infty \frac{\varepsilon}{2} \mathbb{Q} \sum_{q\in\mathbb{Q}}f(q) f:\mathbb{Q}\rightarrow\mathbb{Q}^+ \mathbb{Q} \sum_{q\in\mathbb{Q}\backslash\{0\}}\frac{1}{q^2} \varepsilon>0 q\in \mathbb{Q}^{\neq0}\cap\big(-\frac{1}{\sqrt{\varepsilon}},\frac{1}{\sqrt{\varepsilon}}\big) f(q) q a b \sum_{\frac{m}{n} \in \mathbb{Q}} \frac{1}{|m|^a+|n|^b} 1 {l}^a \bigg|\frac{m}{n}\bigg|_a=\big(|m|^a+|n|^a\big)^{\frac{1}{a}} \big|\frac{-3}{4}\big|_2=(3^2+4^2)^\frac{1}{2}=\sqrt{25}=5 \big|\frac{-3}{4}\big|_1=(3^1+4^1)^\frac{1}{1}=7 0 \frac{0}{1} |0|_a=(0^a+1^a)^\frac{1}{a}=1 0=\frac{0}{1} |q|_a \geq 1 q\in\mathbb{Q} l^a \big|\frac{456}{1207}\big|_a>\big|\frac{1}{2}\big|_a a>1 \sum_{q\in\mathbb{Q}} \frac{1}{|q|_a^a}","['sequences-and-series', 'functional-analysis', 'rational-numbers']"
