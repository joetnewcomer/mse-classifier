,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Expectation score of multiple choice test,Expectation score of multiple choice test,,"A multiple choice exam has 100 questions, each with 5 possible answers. One mark is awarded for a correct answer and 1/4 mark is deducted for an incorrect answer. A particular student has probability $p_i$ of knowing the correct answer to the $i$th question, independently of other questions. a) Suppose that if a student does not know the correct answer, he or she guesses randomly. Show that his or her total mark has mean $\sum p_i$ and variance $\sum p_i (1-p_i)+\frac{(100-\sum p_i)}{4}$. b) Show that the total mark for a student who refrains from guessing also has mean $\sum p_i$  but with variance $\sum p_i (1-p_i)$. b) is pretty easy, since it's a simple application of the binomial distribution. I can't really get a) though, mainly since I can't come up with a good-looking expression for the expected score of question number $i$.","A multiple choice exam has 100 questions, each with 5 possible answers. One mark is awarded for a correct answer and 1/4 mark is deducted for an incorrect answer. A particular student has probability $p_i$ of knowing the correct answer to the $i$th question, independently of other questions. a) Suppose that if a student does not know the correct answer, he or she guesses randomly. Show that his or her total mark has mean $\sum p_i$ and variance $\sum p_i (1-p_i)+\frac{(100-\sum p_i)}{4}$. b) Show that the total mark for a student who refrains from guessing also has mean $\sum p_i$  but with variance $\sum p_i (1-p_i)$. b) is pretty easy, since it's a simple application of the binomial distribution. I can't really get a) though, mainly since I can't come up with a good-looking expression for the expected score of question number $i$.",,"['probability', 'statistics']"
1,A twist on a classic high school problem,A twist on a classic high school problem,,"$$\text{""Toss a fair coin, if heads: stop; if tails: toss again.""}$$ Not a particularly fun game, but a classic probability exercise nonetheless; the probability of this process ending is easily shown to be $1:$ $$\frac{1}{2}+\frac{1}{4}+\frac{1}{8}+\cdots =1$$ This made me wonder, what happens if instead of two outcomes, we have three ? In better terms, suppose we randomly generate a number from $\{0,1,2\}$ (each pick is equiprobable); if $0:$ stop, if $1:$ pick again, if $2:$ pick twice $($even if the first pick is $0)$. In the last case, sum the results of both picks, giving us the number of picks required for the next round. Here is an example of such a game: $$\text{start}\to(1)\to(2)\to (1,2)\to (0,2,1)\to (0,1,0)\to (0)\to\text{end}$$ (the numbers in brackets represent the outcomes of each pick) Again, the probability that this process will end is $1$ (justification below). Upon finding this, I was a tad puzzled. Surely this probability cannot be $1$ if the number of possible outcomes is large enough? It turns out that it fails to give $1$ at the next integer. Indeed, if we randomly generate from $\{0,1,2,3\}$, same rules as previous, with the added ""if $3:$ pick thrice "", the probability that the process will end stoops down to $\sqrt{2}-1$. $$\star$$ I was interested in finding an expression which gives us this probability in terms of the largest integer in the initial set (only looking at sets of the form $\{0,1,\cdots \,n\}$ for now); I believe I have found a polynomial whose solutions give the desired probability. There are several issues that I have not managed to solve: the aforementioned polynomial has two distinct roots in $[0,1]$: one is $1$ (when the set is $\{0,1\}$ (coin toss case) or $\{0,1,2\}$, the roots are not distinct). I am almost certain that the desired probability is the lower root. However, I have not found a decent way of supporting this claim. I would like some criticism on my working; I have never studied degree level maths, and even less taken a course in probability, so I may well have abused of some notation and made some assumptions which I shouldn't be allowed to make. Feel free to critise whatever you feel necessary! $$\textbf{Problem}$$ Let $\Omega$ be a set of $\alpha\geq 2$ consecutive integers with smallest element $0:\;\Omega=\{0,1,\cdots\,\alpha-1\}$ Process: Randomly and independently generate elements of $\Omega$ $r_n$ times. If the sum of the results is $r_{n+1}=0$ the process ends. If the sum of the results is $r_{n+1}\geq 1$, randomly and independently generate elements of $\Omega\;r_{n+1}$ times, etc. The process begins with $r_1=1$. What is the probability of this process ending? $$\textbf{Attempted solution}$$ $\phi:$ end of process , $r_n:$ number of picks required at stage $n$ Notice that for $n>1:$ $$ \left\{    \begin{array}{l l}    p(\phi|r_n=0)=0 &\\     p(\phi|r_n=1)=p(\phi|r_1)=p(\phi) & \; (r_n=1\;\text{returns us to the initial conditions})   \end{array} \right.$$ For $r_n\geq 1$ the event $(\phi|r_n)$ is equivalent to: $$\left(\bigcap_{k=1}^{r_n}\phi|i_k\right)$$ where $(i_k)$ requires a single independent pick i.e. $(i_k)\Leftrightarrow (r_1)$ Therefore we may write for $n>1,r_n\geq 1:$ $$p(\phi|r_n)=p\left(\bigcap_{k=1}^{r_n}\phi|i_k\right)=\prod_{k=1}^{r_n}p(\phi|i_k)=p(\phi|r_1)^{r_n}=p(\phi)^{r_n}$$ Additionally, since all results are equipossible, $p(r_n=k\in\Omega)=\dfrac{1}{\alpha}$ The law of total probability gives: $$\begin{align*}p(\phi)&=p(\phi|r_n=1)\\&=\sum_{k=0}^{\alpha-1}p(r_{n+1}=k)p(\phi|r_{n+1}=k)\\&=\frac{1}{\alpha}\sum_{k=0}^{\alpha-1}p(\phi|r_{n+1}=k)\\&=\frac{1}{\alpha}\sum_{k=0}^{\alpha-1}p(\phi)^k\end{align*}$$ For clarity, denote $\lambda$ the desired probability $p(\phi)$. We are left to solve: $$\lambda =\frac{1}{\alpha}\sum_{k=0}^{\alpha-1}\lambda^k\Rightarrow\alpha\lambda =\sum_{k=0}^{\alpha-1}\lambda^k$$ $$\Rightarrow\lambda^{\alpha}-\alpha\lambda^2+\alpha\lambda-1 =0$$ Notice that for $\alpha=2$ this reduces to $(\lambda-1)^2=0\Rightarrow \lambda=1$ which agrees with the coin toss scenario, and $\alpha=3$ gives $(\lambda-1)^3=0\Rightarrow\lambda=1$ which is why my initial twist on the problem also has probability $1$. By Descartes' rule of signs this polynomial has exactly three positive roots. It is easy to show that the these roots lie in $[0,1]$. In fact, two of them are $1$, and the other is $<1$ when $\alpha\geq 4$. This is why, for $\alpha=4$, I believe the probability is the lower solution: $$(\lambda-1)^2(\lambda^2+2\lambda-1)=0\Rightarrow\lambda=\sqrt{2}-1\;\;\text{if}\;\;\lambda\neq 1$$ We can observe that this other solution approaches $0$ when $\alpha\to\infty$ which agrees with intuition. If what I have done so far is correct, and my intuition is correct, how can I justify that the solution is the smallest positive solution to $\lambda^{\alpha}-\alpha\lambda^2+\alpha\lambda-1 =0?$ $$\star$$ Many thanks to anyone who put the effort into reading this through. If those who answer wish to include any probability theory that is beyond the basic tools that I have used, I would be very grateful is you could explicitly name the tools you use, so that I can study them to fully understand your answers.","$$\text{""Toss a fair coin, if heads: stop; if tails: toss again.""}$$ Not a particularly fun game, but a classic probability exercise nonetheless; the probability of this process ending is easily shown to be $1:$ $$\frac{1}{2}+\frac{1}{4}+\frac{1}{8}+\cdots =1$$ This made me wonder, what happens if instead of two outcomes, we have three ? In better terms, suppose we randomly generate a number from $\{0,1,2\}$ (each pick is equiprobable); if $0:$ stop, if $1:$ pick again, if $2:$ pick twice $($even if the first pick is $0)$. In the last case, sum the results of both picks, giving us the number of picks required for the next round. Here is an example of such a game: $$\text{start}\to(1)\to(2)\to (1,2)\to (0,2,1)\to (0,1,0)\to (0)\to\text{end}$$ (the numbers in brackets represent the outcomes of each pick) Again, the probability that this process will end is $1$ (justification below). Upon finding this, I was a tad puzzled. Surely this probability cannot be $1$ if the number of possible outcomes is large enough? It turns out that it fails to give $1$ at the next integer. Indeed, if we randomly generate from $\{0,1,2,3\}$, same rules as previous, with the added ""if $3:$ pick thrice "", the probability that the process will end stoops down to $\sqrt{2}-1$. $$\star$$ I was interested in finding an expression which gives us this probability in terms of the largest integer in the initial set (only looking at sets of the form $\{0,1,\cdots \,n\}$ for now); I believe I have found a polynomial whose solutions give the desired probability. There are several issues that I have not managed to solve: the aforementioned polynomial has two distinct roots in $[0,1]$: one is $1$ (when the set is $\{0,1\}$ (coin toss case) or $\{0,1,2\}$, the roots are not distinct). I am almost certain that the desired probability is the lower root. However, I have not found a decent way of supporting this claim. I would like some criticism on my working; I have never studied degree level maths, and even less taken a course in probability, so I may well have abused of some notation and made some assumptions which I shouldn't be allowed to make. Feel free to critise whatever you feel necessary! $$\textbf{Problem}$$ Let $\Omega$ be a set of $\alpha\geq 2$ consecutive integers with smallest element $0:\;\Omega=\{0,1,\cdots\,\alpha-1\}$ Process: Randomly and independently generate elements of $\Omega$ $r_n$ times. If the sum of the results is $r_{n+1}=0$ the process ends. If the sum of the results is $r_{n+1}\geq 1$, randomly and independently generate elements of $\Omega\;r_{n+1}$ times, etc. The process begins with $r_1=1$. What is the probability of this process ending? $$\textbf{Attempted solution}$$ $\phi:$ end of process , $r_n:$ number of picks required at stage $n$ Notice that for $n>1:$ $$ \left\{    \begin{array}{l l}    p(\phi|r_n=0)=0 &\\     p(\phi|r_n=1)=p(\phi|r_1)=p(\phi) & \; (r_n=1\;\text{returns us to the initial conditions})   \end{array} \right.$$ For $r_n\geq 1$ the event $(\phi|r_n)$ is equivalent to: $$\left(\bigcap_{k=1}^{r_n}\phi|i_k\right)$$ where $(i_k)$ requires a single independent pick i.e. $(i_k)\Leftrightarrow (r_1)$ Therefore we may write for $n>1,r_n\geq 1:$ $$p(\phi|r_n)=p\left(\bigcap_{k=1}^{r_n}\phi|i_k\right)=\prod_{k=1}^{r_n}p(\phi|i_k)=p(\phi|r_1)^{r_n}=p(\phi)^{r_n}$$ Additionally, since all results are equipossible, $p(r_n=k\in\Omega)=\dfrac{1}{\alpha}$ The law of total probability gives: $$\begin{align*}p(\phi)&=p(\phi|r_n=1)\\&=\sum_{k=0}^{\alpha-1}p(r_{n+1}=k)p(\phi|r_{n+1}=k)\\&=\frac{1}{\alpha}\sum_{k=0}^{\alpha-1}p(\phi|r_{n+1}=k)\\&=\frac{1}{\alpha}\sum_{k=0}^{\alpha-1}p(\phi)^k\end{align*}$$ For clarity, denote $\lambda$ the desired probability $p(\phi)$. We are left to solve: $$\lambda =\frac{1}{\alpha}\sum_{k=0}^{\alpha-1}\lambda^k\Rightarrow\alpha\lambda =\sum_{k=0}^{\alpha-1}\lambda^k$$ $$\Rightarrow\lambda^{\alpha}-\alpha\lambda^2+\alpha\lambda-1 =0$$ Notice that for $\alpha=2$ this reduces to $(\lambda-1)^2=0\Rightarrow \lambda=1$ which agrees with the coin toss scenario, and $\alpha=3$ gives $(\lambda-1)^3=0\Rightarrow\lambda=1$ which is why my initial twist on the problem also has probability $1$. By Descartes' rule of signs this polynomial has exactly three positive roots. It is easy to show that the these roots lie in $[0,1]$. In fact, two of them are $1$, and the other is $<1$ when $\alpha\geq 4$. This is why, for $\alpha=4$, I believe the probability is the lower solution: $$(\lambda-1)^2(\lambda^2+2\lambda-1)=0\Rightarrow\lambda=\sqrt{2}-1\;\;\text{if}\;\;\lambda\neq 1$$ We can observe that this other solution approaches $0$ when $\alpha\to\infty$ which agrees with intuition. If what I have done so far is correct, and my intuition is correct, how can I justify that the solution is the smallest positive solution to $\lambda^{\alpha}-\alpha\lambda^2+\alpha\lambda-1 =0?$ $$\star$$ Many thanks to anyone who put the effort into reading this through. If those who answer wish to include any probability theory that is beyond the basic tools that I have used, I would be very grateful is you could explicitly name the tools you use, so that I can study them to fully understand your answers.",,"['probability', 'probability-theory']"
2,Expected value uniform decreasing function,Expected value uniform decreasing function,,"We are given a function $f(n,k)$ as for(i=0;i < k;i++)   n = rand(n); return n; rand is defined as a random number generator that uniformly generates values in the range $[0,n)$. It returns a value strictly less than $n$; also $\operatorname{rand}(0)=0$. What is the expected value of our function $f(n,k)$ given $n$ and $k$?","We are given a function $f(n,k)$ as for(i=0;i < k;i++)   n = rand(n); return n; rand is defined as a random number generator that uniformly generates values in the range $[0,n)$. It returns a value strictly less than $n$; also $\operatorname{rand}(0)=0$. What is the expected value of our function $f(n,k)$ given $n$ and $k$?",,"['probability', 'contest-math']"
3,Optimal Yahtzee (Dice roll) decisions: Probability and weighting choices,Optimal Yahtzee (Dice roll) decisions: Probability and weighting choices,,"I'm a senior in computer science, and I have a hobby of taking on little projects that I find interesting. My current one is a Yahtzee optimal play solver. One would enter their current roll, and it would tell you if/what to hold onto and what to reroll (if any). It will then tell you what field to put your score in after the potential 2 re-rolls of varying sizes. So far, I've come up with the following: I realize calculating the probabilities for all possible configurations takes a lot of math, like ""Probability of yahtzee if you can reroll twice"" is about 1/29. But the probability with just one roll is 1/7776. Big difference. So I am going to write a simulation for ~1 billion random plays to see the (nearly accurate) odds of certain outcomes are after three rolls. So we can assume probabilities of outcomes are out of the way. I plan to create something like this:  Consider a very concrete non-ambiguous example of just numbers. Say your value is 20. If you reroll (in this particular way), you have a 30% chance at 30, a 25% chance at 20, a 35% chance at 5, and a 10% chance at 80. Expected net = E(gain) - E(Loss) = Sum E(val_i - val). So we have E(change/net) = .3*(30 - 20) + .25*(20 - 20) + .35*(5 - 20) + .10*(80 - 20) = 5.75. So odds are if we make the roll, we will get 25.75 instead of our current 20. This is awesome and works great for this nice simple case... but when we speak of yahtzee, it isnt so simple. For instance, we have four of a kind for, say, 5's. We also have a 5's place on the scoreboard. So if we have a 30% chance at 4 of a kind, we also have a 30% chance at four 5's. The point i'm trying to make is that your percentages wont add up to 100%. You could normalize them, but then you run into the problem of reducing weight on ""something you would pick if you got it"" which lowers the expected net value. For instance, say you have 1 1 2 2 3. If you rerolled the 3 to a 1, a 1/6 chance, you could either take the 25 point full house or the 3 point 1's. If we normalized, it would have a < 1/6 chance for full house and < 1/6 for 1's, depending on how many other % are in this normalization. So we are weighting the full house less simply because a paralell case exhists, even though you would likely choose the full house and not the 3 1's (I hope i'm making sense and not just rambling...) . Anyway, i would love if one of your brilliant minds could help me think of an elegant way to do this. That is, given a roll of 5 dice and one of the 31 possible ways to hold back dice and reroll the others, which of the reroll configurations should you do, or should you not reroll (the 32nd choice). This is the ""high level' way of saying this. The lower level version is ""Given the 32 choices (31 ways to reroll, 1 way to not reroll), which will give you the optimal score?"". I got the 32 from (5 choose 0) ways to reroll no dice + (5 choose 1) ways to reroll 1 dice, etc to (5 choose 5) ways to roll 5 dice. I'm just looking for some insight on how to weight your decisions appropriately. My hunch is that you have to do a bit of tricky manipulation such that if you have overlapping cases, you take the maximal case? (Ie. Three 1's vs. a full house with 1 1 1 2 2 after rerolling the 3 in 1 1 3 2 2, you would take that chance multiplied by the full house value, and not put any weight to the 3 1's. This of course assumes we need both a FH and 1's. If you didn't need a full house, it wouldnt even be in the equation). Thanks everyone who takes the time to read this :). John [Edit:] Thanks again for your help. I'm pretty sure I know how to do this now, but I wanted to run it by you to make sure im not misunderstanding anything. I know that you cant fit the entire game tree, but im just writing this in general assuming we had infinite memory. I know i'd actually only be able to use this with some initial non-blank states. Begin algorithm We have 13 boxes, each with a certain number of states.  When we make the tree, we start with all states initialized to ""nothing"", and simply proceed to do all possibilities of the states which gives us all possible end states when completed. Let us look at one such ""leaf"" node, which is at the end of a completed path through our tree. In order to backtrack up the tree and give nodes values (scores), we start here. This nodes value is the sum of all scores in all boxes. To give its parent a value though, we set our value(score) to val := (val - stateScore) + (stateScore*probStateScore); This, from the parents point of view, takes away the guarenteed gain from that node state and changes it to the expected value (since we havent gotten that state yet, it is no longer a given but a probability). So if this nodes value is 300, and the gained score from its last choice was 50 with a probability of 10%, you would set your value to 250 + 5 = 255. Now, you parent takes the max of all its children and sets its own value to val := (max(children) - thisNodesStateScore) + thisNodesStateScore*probOfThisStateScore; By the time we get to the top, we have a set of nodes (first tier of the tree) with the optimal expected values should you pick them. When playing the game, we may roll perhaps a 1 1 2 1 5. We can classify this as a 0 in any state, a 3 of a kind of ones = scoreState(10), 3 ones = scoreState(3), one 5 = scoreState(5), or one 2 = scoreState(2). We observe which of the values of these states is maximal, and choose that state. Continue until the end of the game. End algorithm If this is right, my question was how does the 3 rolls come into this? If you roll 1 1 2 15 and you have 2 rolls left, how do you give the optimal setup to hold and reroll based on the optimal values in the tree? Again, we can assume we know all probabilities of rolling a given setup. Thanks again, and I apologize that this question was so long and time consuming.","I'm a senior in computer science, and I have a hobby of taking on little projects that I find interesting. My current one is a Yahtzee optimal play solver. One would enter their current roll, and it would tell you if/what to hold onto and what to reroll (if any). It will then tell you what field to put your score in after the potential 2 re-rolls of varying sizes. So far, I've come up with the following: I realize calculating the probabilities for all possible configurations takes a lot of math, like ""Probability of yahtzee if you can reroll twice"" is about 1/29. But the probability with just one roll is 1/7776. Big difference. So I am going to write a simulation for ~1 billion random plays to see the (nearly accurate) odds of certain outcomes are after three rolls. So we can assume probabilities of outcomes are out of the way. I plan to create something like this:  Consider a very concrete non-ambiguous example of just numbers. Say your value is 20. If you reroll (in this particular way), you have a 30% chance at 30, a 25% chance at 20, a 35% chance at 5, and a 10% chance at 80. Expected net = E(gain) - E(Loss) = Sum E(val_i - val). So we have E(change/net) = .3*(30 - 20) + .25*(20 - 20) + .35*(5 - 20) + .10*(80 - 20) = 5.75. So odds are if we make the roll, we will get 25.75 instead of our current 20. This is awesome and works great for this nice simple case... but when we speak of yahtzee, it isnt so simple. For instance, we have four of a kind for, say, 5's. We also have a 5's place on the scoreboard. So if we have a 30% chance at 4 of a kind, we also have a 30% chance at four 5's. The point i'm trying to make is that your percentages wont add up to 100%. You could normalize them, but then you run into the problem of reducing weight on ""something you would pick if you got it"" which lowers the expected net value. For instance, say you have 1 1 2 2 3. If you rerolled the 3 to a 1, a 1/6 chance, you could either take the 25 point full house or the 3 point 1's. If we normalized, it would have a < 1/6 chance for full house and < 1/6 for 1's, depending on how many other % are in this normalization. So we are weighting the full house less simply because a paralell case exhists, even though you would likely choose the full house and not the 3 1's (I hope i'm making sense and not just rambling...) . Anyway, i would love if one of your brilliant minds could help me think of an elegant way to do this. That is, given a roll of 5 dice and one of the 31 possible ways to hold back dice and reroll the others, which of the reroll configurations should you do, or should you not reroll (the 32nd choice). This is the ""high level' way of saying this. The lower level version is ""Given the 32 choices (31 ways to reroll, 1 way to not reroll), which will give you the optimal score?"". I got the 32 from (5 choose 0) ways to reroll no dice + (5 choose 1) ways to reroll 1 dice, etc to (5 choose 5) ways to roll 5 dice. I'm just looking for some insight on how to weight your decisions appropriately. My hunch is that you have to do a bit of tricky manipulation such that if you have overlapping cases, you take the maximal case? (Ie. Three 1's vs. a full house with 1 1 1 2 2 after rerolling the 3 in 1 1 3 2 2, you would take that chance multiplied by the full house value, and not put any weight to the 3 1's. This of course assumes we need both a FH and 1's. If you didn't need a full house, it wouldnt even be in the equation). Thanks everyone who takes the time to read this :). John [Edit:] Thanks again for your help. I'm pretty sure I know how to do this now, but I wanted to run it by you to make sure im not misunderstanding anything. I know that you cant fit the entire game tree, but im just writing this in general assuming we had infinite memory. I know i'd actually only be able to use this with some initial non-blank states. Begin algorithm We have 13 boxes, each with a certain number of states.  When we make the tree, we start with all states initialized to ""nothing"", and simply proceed to do all possibilities of the states which gives us all possible end states when completed. Let us look at one such ""leaf"" node, which is at the end of a completed path through our tree. In order to backtrack up the tree and give nodes values (scores), we start here. This nodes value is the sum of all scores in all boxes. To give its parent a value though, we set our value(score) to val := (val - stateScore) + (stateScore*probStateScore); This, from the parents point of view, takes away the guarenteed gain from that node state and changes it to the expected value (since we havent gotten that state yet, it is no longer a given but a probability). So if this nodes value is 300, and the gained score from its last choice was 50 with a probability of 10%, you would set your value to 250 + 5 = 255. Now, you parent takes the max of all its children and sets its own value to val := (max(children) - thisNodesStateScore) + thisNodesStateScore*probOfThisStateScore; By the time we get to the top, we have a set of nodes (first tier of the tree) with the optimal expected values should you pick them. When playing the game, we may roll perhaps a 1 1 2 1 5. We can classify this as a 0 in any state, a 3 of a kind of ones = scoreState(10), 3 ones = scoreState(3), one 5 = scoreState(5), or one 2 = scoreState(2). We observe which of the values of these states is maximal, and choose that state. Continue until the end of the game. End algorithm If this is right, my question was how does the 3 rolls come into this? If you roll 1 1 2 15 and you have 2 rolls left, how do you give the optimal setup to hold and reroll based on the optimal values in the tree? Again, we can assume we know all probabilities of rolling a given setup. Thanks again, and I apologize that this question was so long and time consuming.",,"['probability', 'discrete-mathematics', 'optimization', 'computer-science']"
4,A question related to Buffon's needle,A question related to Buffon's needle,,"The following is an elementary probability question related to a generalization of the famous ""Buffon's needle experiment"" which allows one to estimate $\pi$ by counting how many times a randomly tossed needle crosses a line on a lined sheet of paper.  If we replace the needle with a rigid wire in the shape of any piecewise smooth plane curve, I believe it is well-known that the expected number of line crossings depends only on the length of the wire and not on its specific shape. I am seeking an elementary proof of this fact in the case where the wire consists of two line segments joined end-to-end.  The only parameters here are the lengths of the two line segments and the angle at which they are joined; I would like to prove that the expected number of crossings depends only on the sum of the lengths.  If it helps, I am happy to assume that both line segments are very small compared to the spacing between the lines on the paper.  Any ideas? Added: Several have argued that this follows simply from the linearity of expectation, but I am not convinced.  Suppose it were the case that the expectation for a single segment of length $\ell$ was given by $\ell^2$.  Then if $X$ and $Y$ are the random variables representing the two needles making up the wire we would have $E(X+Y) = E(X) + E(Y) = \ell_X^2 + \ell_Y^2$, and this is not a function of $\ell_X + \ell_Y$ (though it is a function of $\ell_X$ and $\ell_Y$).  Of course we secretly know that $E(X) = C \ell_X$, but my goal in asking this question is to prove this fact without actually calculating anything.","The following is an elementary probability question related to a generalization of the famous ""Buffon's needle experiment"" which allows one to estimate $\pi$ by counting how many times a randomly tossed needle crosses a line on a lined sheet of paper.  If we replace the needle with a rigid wire in the shape of any piecewise smooth plane curve, I believe it is well-known that the expected number of line crossings depends only on the length of the wire and not on its specific shape. I am seeking an elementary proof of this fact in the case where the wire consists of two line segments joined end-to-end.  The only parameters here are the lengths of the two line segments and the angle at which they are joined; I would like to prove that the expected number of crossings depends only on the sum of the lengths.  If it helps, I am happy to assume that both line segments are very small compared to the spacing between the lines on the paper.  Any ideas? Added: Several have argued that this follows simply from the linearity of expectation, but I am not convinced.  Suppose it were the case that the expectation for a single segment of length $\ell$ was given by $\ell^2$.  Then if $X$ and $Y$ are the random variables representing the two needles making up the wire we would have $E(X+Y) = E(X) + E(Y) = \ell_X^2 + \ell_Y^2$, and this is not a function of $\ell_X + \ell_Y$ (though it is a function of $\ell_X$ and $\ell_Y$).  Of course we secretly know that $E(X) = C \ell_X$, but my goal in asking this question is to prove this fact without actually calculating anything.",,"['probability', 'geometry']"
5,Closeness of probability measures,Closeness of probability measures,,Consider a set of probability measures $\{P_n\}$. Suppose $P_n$ converges to $P^*$ weakly and $$ \int \xi^2 P_n(d\xi)< \infty. $$ Can we claim $$ \int \xi^2 P^*(d\xi)<\infty $$ and $$ \lim_{n\to \infty} \int \xi^2 P_n(d\xi) =\int \xi^2 P^*(d\xi)? $$,Consider a set of probability measures $\{P_n\}$. Suppose $P_n$ converges to $P^*$ weakly and $$ \int \xi^2 P_n(d\xi)< \infty. $$ Can we claim $$ \int \xi^2 P^*(d\xi)<\infty $$ and $$ \lim_{n\to \infty} \int \xi^2 P_n(d\xi) =\int \xi^2 P^*(d\xi)? $$,,"['probability', 'general-topology', 'probability-theory', 'convergence-divergence']"
6,A problem about strong law of large numbers of Shiryaev's Probability,A problem about strong law of large numbers of Shiryaev's Probability,,"This is a problem after the section ""Strong Law of Large Numbers"" of Shiryaev's Probability : Let $\xi_1,\xi_2,...$ denote independent and identically distributed random variables such thatt $E|\xi_1|=\infty$. Show that   $$\limsup_{n\to\infty}\left|\frac{S_n}{n}-a_n\right|=\infty\text{ (P-a.s.)}$$   for every sequence of constants $\{a_n\}$. I have no idea about it. Any hint please. Thanks!","This is a problem after the section ""Strong Law of Large Numbers"" of Shiryaev's Probability : Let $\xi_1,\xi_2,...$ denote independent and identically distributed random variables such thatt $E|\xi_1|=\infty$. Show that   $$\limsup_{n\to\infty}\left|\frac{S_n}{n}-a_n\right|=\infty\text{ (P-a.s.)}$$   for every sequence of constants $\{a_n\}$. I have no idea about it. Any hint please. Thanks!",,"['probability', 'probability-theory', 'probability-limit-theorems', 'law-of-large-numbers']"
7,How many rounds does it take to be 99% sure of reaching Expected Value?,How many rounds does it take to be 99% sure of reaching Expected Value?,,"I have a feeling this might be a common question but I was unable to find the right way of asking, and I'm just a hobbyist at stats/math. Say I have a bet that costs six dollars.  If I lose I get nothing, and if I win I get my six dollars back, plus $\$7$ more.  I have a $74$% chance of winning. I intend to stop betting once I reach EV.  How many times must I make the bet before I can be $99$% sure of first reaching cumulative Expected Value?  In other words, assuming $n > 0$, how many rounds until we are $99$% sure of reaching $3.62n$ the first time? I intend to stop betting once I reach break-even.  How many times must I make the bet before I can be $99$% sure of breaking even for the series of bets the first time? This is not homework, I'm seeking a way to communicate a point on a discussion board about how making decisions according to EV is not always wise if you don't have access to many rounds of a +EV scenario.  I'm trying to figure out how to answer these questions for a variety of certainty levels (e.g. $99$%), probabilities (e.g. $74$%), and odds.","I have a feeling this might be a common question but I was unable to find the right way of asking, and I'm just a hobbyist at stats/math. Say I have a bet that costs six dollars.  If I lose I get nothing, and if I win I get my six dollars back, plus $\$7$ more.  I have a $74$% chance of winning. I intend to stop betting once I reach EV.  How many times must I make the bet before I can be $99$% sure of first reaching cumulative Expected Value?  In other words, assuming $n > 0$, how many rounds until we are $99$% sure of reaching $3.62n$ the first time? I intend to stop betting once I reach break-even.  How many times must I make the bet before I can be $99$% sure of breaking even for the series of bets the first time? This is not homework, I'm seeking a way to communicate a point on a discussion board about how making decisions according to EV is not always wise if you don't have access to many rounds of a +EV scenario.  I'm trying to figure out how to answer these questions for a variety of certainty levels (e.g. $99$%), probabilities (e.g. $74$%), and odds.",,['probability']
8,Probability in Rock Paper Scissors competitions,Probability in Rock Paper Scissors competitions,,"My professor gave the following question as a bonus, if two brothers Pat and Steve enter a rock paper scissors competition with $2^n$ players.  In this competition players are randomly paired and then the winners move on to the next round.  What is the probability that at one point in the competition the brothers face each other?  My professor said my answer was wrong, and provided no explanation.  I was wondering where my logic went wrong? This is the solution I gave. We can look at a smaller part of this problem to help solve the larger problem, the smaller part being what is the probability that two people will face each other in an individual round of of the tournament with $2^n$ players.  This problem can also be expressed as the following, given a random pairing of $2^n$ people which includes two brothers Pat and Steve, what is the probability that the brothers will be in the same pair.  This is given by the number of pairings where Pat and Steve are together divided by the total number of pairings.  Notice that the number possible pairings where Pat and Steve are held constant is the number of pairings for $2n-2$ people.  Thus if we can find some function $f(2n)$ that is defined as the number of ways of pairing $2n$ people, then the ratio $\frac{f(2^n-2)}{f(2^n)}$ will give us the desired probability.  To find this ratio, lets consider how many pairings we add by increasing the number of people we are pairing by two.  When this pair is held together there are $f(2n-2)$ pairings, and if we switch one of the people with a new person there are another $f(2n-2)$ pairings.  If we hold one person constant we can pair him with any of the other $2n-1$ people.  Since by summing these all together we get all of the possible pairings, this is $(2n-1)*f(2n-2)$.  Thus the ratio we were looking for is $\frac{f(2^n-2)}{(2^n-1)*f(2^n-2)} = \frac{1}{2^n-1}$.  The probability that both brothers reach the nth round is $\frac{1}{4^n}$, and since these cases are distinct from when the brothers face each other the probability that the brothers face each other in any of the $n$ rounds is the sum $\sum_{i=0}^n \frac{1}{2^{n-i}-1}*\frac{1}{4^n}$.","My professor gave the following question as a bonus, if two brothers Pat and Steve enter a rock paper scissors competition with $2^n$ players.  In this competition players are randomly paired and then the winners move on to the next round.  What is the probability that at one point in the competition the brothers face each other?  My professor said my answer was wrong, and provided no explanation.  I was wondering where my logic went wrong? This is the solution I gave. We can look at a smaller part of this problem to help solve the larger problem, the smaller part being what is the probability that two people will face each other in an individual round of of the tournament with $2^n$ players.  This problem can also be expressed as the following, given a random pairing of $2^n$ people which includes two brothers Pat and Steve, what is the probability that the brothers will be in the same pair.  This is given by the number of pairings where Pat and Steve are together divided by the total number of pairings.  Notice that the number possible pairings where Pat and Steve are held constant is the number of pairings for $2n-2$ people.  Thus if we can find some function $f(2n)$ that is defined as the number of ways of pairing $2n$ people, then the ratio $\frac{f(2^n-2)}{f(2^n)}$ will give us the desired probability.  To find this ratio, lets consider how many pairings we add by increasing the number of people we are pairing by two.  When this pair is held together there are $f(2n-2)$ pairings, and if we switch one of the people with a new person there are another $f(2n-2)$ pairings.  If we hold one person constant we can pair him with any of the other $2n-1$ people.  Since by summing these all together we get all of the possible pairings, this is $(2n-1)*f(2n-2)$.  Thus the ratio we were looking for is $\frac{f(2^n-2)}{(2^n-1)*f(2^n-2)} = \frac{1}{2^n-1}$.  The probability that both brothers reach the nth round is $\frac{1}{4^n}$, and since these cases are distinct from when the brothers face each other the probability that the brothers face each other in any of the $n$ rounds is the sum $\sum_{i=0}^n \frac{1}{2^{n-i}-1}*\frac{1}{4^n}$.",,['probability']
9,What is an approximation for Poisson binomial distribution?,What is an approximation for Poisson binomial distribution?,,"I am looking for an approximation for Poisson binomial distribution: The Poisson binomial distribution is the discrete probability distribution of a sum of $n$ independent Bernoulli trials. you can find its pdf in http://en.wikipedia.org/wiki/Poisson_binomial_distribution In addition, you can find 2 methods for it in the mentioned link. But when I use the second method (using Fourier Transform), the result would be an imaginary number. I also wanted to use approximations in the following paper http://statistics.stanford.edu/~ckirby/techreports/ONR/SOL%20ONR%20467.pdf but the approximations are not clear to me. I would be grateful if somebody explains to me: 1) why do I get imaginary number using the second method ( Fourier transform)? 2) and also for example, how are the probabilities in Table 2 in the paper calculated?","I am looking for an approximation for Poisson binomial distribution: The Poisson binomial distribution is the discrete probability distribution of a sum of $n$ independent Bernoulli trials. you can find its pdf in http://en.wikipedia.org/wiki/Poisson_binomial_distribution In addition, you can find 2 methods for it in the mentioned link. But when I use the second method (using Fourier Transform), the result would be an imaginary number. I also wanted to use approximations in the following paper http://statistics.stanford.edu/~ckirby/techreports/ONR/SOL%20ONR%20467.pdf but the approximations are not clear to me. I would be grateful if somebody explains to me: 1) why do I get imaginary number using the second method ( Fourier transform)? 2) and also for example, how are the probabilities in Table 2 in the paper calculated?",,"['probability', 'statistics', 'probability-theory', 'probability-distributions']"
10,Conditional probability of cows,Conditional probability of cows,,"the question is that if you are a farmer and own six cows: 3 white, 2 black and one that is black on one side and white on the other. Then if you see two black cows (that is 2 black sides of cows) then what is the probability that one of them is the black and white cow? Here is my attempted answer: if $M_1$ and $M_2$ are the events that the first or second cow is the mixed one and $b_1$ and $b_2$ denote that the sides of the first and second cow we see is black. then we are looking for $$P(M_1 \cup M_2 \mid b_1b_2)=\frac{P(M_1b_1b_2)+P(M_2b_1b_2)}{P(b_1b_2)}$$ $$=\frac{2P(M_1)P(b_1\mid M_1)P(b_2\mid M_1b_1)}{P(M_1 \cup M_2)P(b_1b_2\mid M_1 \cup M_2)+[1-P(M_1 \cup M_2)]P(b_1b_2\mid M_1^cM_2^c)}$$ then $P(M_1)$ = $\frac{1}{6}$ as there are $6$ sheep and only $1$ that is mixed. $P(b_1\mid M_1)= \frac{1}{2}$ as it can be one of two sides and $P(b_2\mid M_1b_1)=\frac{2}{5}$ as this is just the probability of choosing a black cow. So the numerator is equal to $\frac{1}{15}$. $P(M_1 \cup M_2) = P(M_1) + P(M_2)$ as they are disjoint and so is equal to $\frac{1}{3}$. Then $P(b_1b_2\mid M_1 \cup M_2)$ is just the probability that the other cow is black and we see the black side of the mixed sheep and so is $\frac{2}{5} *\frac{1}{2}$. Finally $[1-P(M_1 \cup M_2)]=\frac{2}{3}$ and $P(b_1b_2\mid M_1^cM_2^c)$ is $\frac{1}{10}$ as it is the number of all black pairs over the total number of pairs. so putting it all together. I get $\frac{\frac{1}{15}}{\frac{2}{15}}=\frac{1}{2}$ but the answer is supposedly $\approx .3$ EDIT The guy who wrote the paper made a mistake in the answers. It should be $\frac{1}{2}$","the question is that if you are a farmer and own six cows: 3 white, 2 black and one that is black on one side and white on the other. Then if you see two black cows (that is 2 black sides of cows) then what is the probability that one of them is the black and white cow? Here is my attempted answer: if $M_1$ and $M_2$ are the events that the first or second cow is the mixed one and $b_1$ and $b_2$ denote that the sides of the first and second cow we see is black. then we are looking for $$P(M_1 \cup M_2 \mid b_1b_2)=\frac{P(M_1b_1b_2)+P(M_2b_1b_2)}{P(b_1b_2)}$$ $$=\frac{2P(M_1)P(b_1\mid M_1)P(b_2\mid M_1b_1)}{P(M_1 \cup M_2)P(b_1b_2\mid M_1 \cup M_2)+[1-P(M_1 \cup M_2)]P(b_1b_2\mid M_1^cM_2^c)}$$ then $P(M_1)$ = $\frac{1}{6}$ as there are $6$ sheep and only $1$ that is mixed. $P(b_1\mid M_1)= \frac{1}{2}$ as it can be one of two sides and $P(b_2\mid M_1b_1)=\frac{2}{5}$ as this is just the probability of choosing a black cow. So the numerator is equal to $\frac{1}{15}$. $P(M_1 \cup M_2) = P(M_1) + P(M_2)$ as they are disjoint and so is equal to $\frac{1}{3}$. Then $P(b_1b_2\mid M_1 \cup M_2)$ is just the probability that the other cow is black and we see the black side of the mixed sheep and so is $\frac{2}{5} *\frac{1}{2}$. Finally $[1-P(M_1 \cup M_2)]=\frac{2}{3}$ and $P(b_1b_2\mid M_1^cM_2^c)$ is $\frac{1}{10}$ as it is the number of all black pairs over the total number of pairs. so putting it all together. I get $\frac{\frac{1}{15}}{\frac{2}{15}}=\frac{1}{2}$ but the answer is supposedly $\approx .3$ EDIT The guy who wrote the paper made a mistake in the answers. It should be $\frac{1}{2}$",,['probability']
11,Evolution by death and immigration of Poisson distributed population,Evolution by death and immigration of Poisson distributed population,,"This is quite an interesting problem, but I'm not sure how to go about doing it. I know that by using some basic Poisson properties I can figure it out but I'm failing to see how. It goes like this: A population comprises of $X_n$ individuals at time $n=1,2,3...$ Suppose that $X_0$ has Poisson ($\mu$) distribution. Between time $n$ and time $n+1$ each of the $X_n$ individuals dies with probability $p$, independently of the others. The population at time $n+1$ is formed from the survivors together with a random number of immigrants who arrive independently according to a Poisson ($\mu$) distribution. What is the distribution of $X_n$? I feel that I'm close but can't quite get it. It sounds like I could set up a series and then maybe prove it by induction.","This is quite an interesting problem, but I'm not sure how to go about doing it. I know that by using some basic Poisson properties I can figure it out but I'm failing to see how. It goes like this: A population comprises of $X_n$ individuals at time $n=1,2,3...$ Suppose that $X_0$ has Poisson ($\mu$) distribution. Between time $n$ and time $n+1$ each of the $X_n$ individuals dies with probability $p$, independently of the others. The population at time $n+1$ is formed from the survivors together with a random number of immigrants who arrive independently according to a Poisson ($\mu$) distribution. What is the distribution of $X_n$? I feel that I'm close but can't quite get it. It sounds like I could set up a series and then maybe prove it by induction.",,"['probability', 'probability-theory', 'probability-distributions', 'induction']"
12,Lottery with coupon collecting - what prices are fair?,Lottery with coupon collecting - what prices are fair?,,"Assume there is a lottery where you can buy lots for 1\$ each. To win the grand price you have to collect $n$ different coupons $C_1, \ldots, C_n$ where $C_i$ occurs with probability $p_i$. You may assume that there are ""infinitely"" many lots, i.e. the $p_i$ do not change over time and successive drawings are independant. And of course $\sum p_i\le 1$. I specifically want to consider the case where the $p_i$ are far from being equal. Q1: What would the grand prize be worth if the lottery is fair? Q2: What would be a fair price to sell a coupon of type $C_i$ to other players? The obvious answer $1\over p_i$ seems to be wrong because in order to collect all other coupons one has to buy so many lots anyway that it is likely to find a $C_i$ while doing that (unless $p_i\ll p_j$ for $j\ne i$) Q3: Assume two players have collected subsets $A$, $B$ of $\mathcal C=\{C_1, \ldots, C_n\}$ such that $A\cup B=\mathcal C$. If they cooperate, what would be a fair method to share the grand prize?","Assume there is a lottery where you can buy lots for 1\$ each. To win the grand price you have to collect $n$ different coupons $C_1, \ldots, C_n$ where $C_i$ occurs with probability $p_i$. You may assume that there are ""infinitely"" many lots, i.e. the $p_i$ do not change over time and successive drawings are independant. And of course $\sum p_i\le 1$. I specifically want to consider the case where the $p_i$ are far from being equal. Q1: What would the grand prize be worth if the lottery is fair? Q2: What would be a fair price to sell a coupon of type $C_i$ to other players? The obvious answer $1\over p_i$ seems to be wrong because in order to collect all other coupons one has to buy so many lots anyway that it is likely to find a $C_i$ while doing that (unless $p_i\ll p_j$ for $j\ne i$) Q3: Assume two players have collected subsets $A$, $B$ of $\mathcal C=\{C_1, \ldots, C_n\}$ such that $A\cup B=\mathcal C$. If they cooperate, what would be a fair method to share the grand prize?",,"['probability', 'combinatorics']"
13,Quick sort algorithm average case complexity analysis,Quick sort algorithm average case complexity analysis,,"This is for self-study. This question is from Kenneth Rosen's ""Discrete Mathematics and Its Applications"". The quick sort is an efﬁcient algorithm. To sort $a_1,a_2,\ldots,a_n$, this algorithm begins by taking the ﬁrst element $a_1$ and forming two sublists, the ﬁrst containing those elements that are less than $a_1$, in the order they arise, and the second containing those elements greater than $a_1$, in the order they arise. Then $a_1$ is put at the end of the ﬁrst sublist. This procedure is repeated recursively for each sublist, until all sublists contain one item. The ordered list of $n$ items is obtained by combining the sublists of one item in the order they occur. In this exercise we find the average-case complexity of the quick sort algorithm, assuming a uniform distribution on the set of permutations. a) Let X be the number of comparisons used by the quick sort algorithm to sort a list of n distinct integers. Show that the average number of comparisons used by the quick sort algorithm is $E(X)$ (where the sample space is the set of all $n!$ permutations of $n$ integers). b) Let $I(j,k)$ denote the random variable that equals 1 if the $j^{th}$ smallest element and the $k^{th}$ smallest element of the initial list are ever compared as the quick sort algorithm sorts the list and equals 0 otherwise. Show that $X = \sum_{k=2}^{n}\sum_{j=1}^{k-1}I_{j,k}$. c) Show that $E(X) = \sum_{k=2}^{n} \sum_{j=1}^{k-1} p$, where $p$ is the probability that the $j^{th}$ smallest element and the $k^{th}$ smallest element are compared. d) Show that $p$ (the $j^{th}$ smallest element and the $k^{th}$ smallest element are compared), where $k > j$, equals $2/(k − j + 1)$. I didn't have any particular problem with parts a, b and c . I think that I managed to understand parts a , b and c . For part a , this seems obvious from the definition of expected value. E(X) is the average value of the number of comparisons, weighted by the probability that the permutation has a particular order (which is $1/n!$). For part b , I verified that the sum $\sum_{k=2}^{n}\sum_{j=1}^{k-1}I_{j,k}$ gives $I_{1,2} + I_{1,3} + I_{2,3} + I_{1,4} + I_{2,4} + I_{3,4}+\cdots+I_{n-1,n}$, that is, it gives the value of $I_{j,k}$ for every combination of $j$ and $k$. So, it sums 1 to every pair of integers that will be compared. Since the only situation two integers get compared is when one of them the the first element of the list (also called the ""pivot""), this means that these two integers will go each one to separate sublists, so that they will not be compared anymore (in other words, every pair of integers is compared at most once). Therefore, it makes sense to say that the mentioned sum will give $X$, the total number of comparisons made by quick sort. Part c also seems straightforward. The result follows from the linearity of the expected value (the expected value of a sum is the sum of the expected values): $E(X) = E\left(\sum_{k=2}^{n}\sum_{j=1}^{k-1}I_{j,k}\right) = \sum_{k=2}^{n}\sum_{j=1}^{k-1}E(I_{j,k})$. The value of $E(I_{j,k})$ (the expected value of $I_{j,k}$) is 1 times the probability that $I_{j,k}$ gets the value 1; the probability that $I_{j,k}$ gets the value 1 is the probability that the $j^{th}$ smallest element and the $k^{th}$ smallest element are compared, so $I_{j,k} = p$. So, $E(X) = \sum_{k=2}^{n}\sum_{j=1}^{k-1}p$. Part d is where I got stuck. I tried to reason the following way: given a list that will be ordered by quick sort, two integers $a_j$ and $a_k$ will get compared only if one of them is the pivot. Also, if a number that is smaller than $a_k$ and greater than $a_j$ is the pivot, $a_k$ and $a_j$ will go to separate sublists, so that they will never get compared. Otherwise, if the pivot is either greater than both $a_k$ and $a_j$, or smaller than them, $a_j$ and $a_k$ will both go to the same sublist, so that, in another recursive call of the algorithm, they may still get compared. But I'm not sure how to show that the probability that the $j^{th}$ smallest element and the $k^{th}$ smallest element are ever compared is $2/(k − j + 1)$. Could anyone give a hint? I would prefer a hint over a complete solution, so that I can discuss it further in comments to fill in the holes.","This is for self-study. This question is from Kenneth Rosen's ""Discrete Mathematics and Its Applications"". The quick sort is an efﬁcient algorithm. To sort $a_1,a_2,\ldots,a_n$, this algorithm begins by taking the ﬁrst element $a_1$ and forming two sublists, the ﬁrst containing those elements that are less than $a_1$, in the order they arise, and the second containing those elements greater than $a_1$, in the order they arise. Then $a_1$ is put at the end of the ﬁrst sublist. This procedure is repeated recursively for each sublist, until all sublists contain one item. The ordered list of $n$ items is obtained by combining the sublists of one item in the order they occur. In this exercise we find the average-case complexity of the quick sort algorithm, assuming a uniform distribution on the set of permutations. a) Let X be the number of comparisons used by the quick sort algorithm to sort a list of n distinct integers. Show that the average number of comparisons used by the quick sort algorithm is $E(X)$ (where the sample space is the set of all $n!$ permutations of $n$ integers). b) Let $I(j,k)$ denote the random variable that equals 1 if the $j^{th}$ smallest element and the $k^{th}$ smallest element of the initial list are ever compared as the quick sort algorithm sorts the list and equals 0 otherwise. Show that $X = \sum_{k=2}^{n}\sum_{j=1}^{k-1}I_{j,k}$. c) Show that $E(X) = \sum_{k=2}^{n} \sum_{j=1}^{k-1} p$, where $p$ is the probability that the $j^{th}$ smallest element and the $k^{th}$ smallest element are compared. d) Show that $p$ (the $j^{th}$ smallest element and the $k^{th}$ smallest element are compared), where $k > j$, equals $2/(k − j + 1)$. I didn't have any particular problem with parts a, b and c . I think that I managed to understand parts a , b and c . For part a , this seems obvious from the definition of expected value. E(X) is the average value of the number of comparisons, weighted by the probability that the permutation has a particular order (which is $1/n!$). For part b , I verified that the sum $\sum_{k=2}^{n}\sum_{j=1}^{k-1}I_{j,k}$ gives $I_{1,2} + I_{1,3} + I_{2,3} + I_{1,4} + I_{2,4} + I_{3,4}+\cdots+I_{n-1,n}$, that is, it gives the value of $I_{j,k}$ for every combination of $j$ and $k$. So, it sums 1 to every pair of integers that will be compared. Since the only situation two integers get compared is when one of them the the first element of the list (also called the ""pivot""), this means that these two integers will go each one to separate sublists, so that they will not be compared anymore (in other words, every pair of integers is compared at most once). Therefore, it makes sense to say that the mentioned sum will give $X$, the total number of comparisons made by quick sort. Part c also seems straightforward. The result follows from the linearity of the expected value (the expected value of a sum is the sum of the expected values): $E(X) = E\left(\sum_{k=2}^{n}\sum_{j=1}^{k-1}I_{j,k}\right) = \sum_{k=2}^{n}\sum_{j=1}^{k-1}E(I_{j,k})$. The value of $E(I_{j,k})$ (the expected value of $I_{j,k}$) is 1 times the probability that $I_{j,k}$ gets the value 1; the probability that $I_{j,k}$ gets the value 1 is the probability that the $j^{th}$ smallest element and the $k^{th}$ smallest element are compared, so $I_{j,k} = p$. So, $E(X) = \sum_{k=2}^{n}\sum_{j=1}^{k-1}p$. Part d is where I got stuck. I tried to reason the following way: given a list that will be ordered by quick sort, two integers $a_j$ and $a_k$ will get compared only if one of them is the pivot. Also, if a number that is smaller than $a_k$ and greater than $a_j$ is the pivot, $a_k$ and $a_j$ will go to separate sublists, so that they will never get compared. Otherwise, if the pivot is either greater than both $a_k$ and $a_j$, or smaller than them, $a_j$ and $a_k$ will both go to the same sublist, so that, in another recursive call of the algorithm, they may still get compared. But I'm not sure how to show that the probability that the $j^{th}$ smallest element and the $k^{th}$ smallest element are ever compared is $2/(k − j + 1)$. Could anyone give a hint? I would prefer a hint over a complete solution, so that I can discuss it further in comments to fill in the holes.",,"['probability', 'algorithms', 'discrete-mathematics', 'recursive-algorithms']"
14,When to consider the ordering for probability.,When to consider the ordering for probability.,,"A rather fundamental concept which I somewhat failed to grasp and now is jeopardising my further understanding/solving of probability problems.. In the case of this question, where we are to find the probability, that the minimum of two throws of a fair die equals $k$, $k \leq 6, k \in \mathbb{N}$, do we have to account for the ordering of the dice? I.e., assuming $k = 3$, is the probability $P(\{3\}) = \frac{1}{6}\times\frac{4}{6}\times 2$ in order to account for the fact that the first throw could be $3$ and the second throw anything from $3$ onwards OR vice versa (the first throw anything from $3$ onwards and the second throw $= 3$)? Or should it just be $P(\{3\}) = \frac{1}{6}\times\frac{4}{6}$ since the dice are similar and there is no mention that the two dice are unique (e.g. different in colour, size etc.). The general question, hence, is, for cases where coins/dice are involved and are not uniquely labelled, should the order be regarded, if there is no additional mention of a first/second throw? Hope you all get my drift..","A rather fundamental concept which I somewhat failed to grasp and now is jeopardising my further understanding/solving of probability problems.. In the case of this question, where we are to find the probability, that the minimum of two throws of a fair die equals $k$, $k \leq 6, k \in \mathbb{N}$, do we have to account for the ordering of the dice? I.e., assuming $k = 3$, is the probability $P(\{3\}) = \frac{1}{6}\times\frac{4}{6}\times 2$ in order to account for the fact that the first throw could be $3$ and the second throw anything from $3$ onwards OR vice versa (the first throw anything from $3$ onwards and the second throw $= 3$)? Or should it just be $P(\{3\}) = \frac{1}{6}\times\frac{4}{6}$ since the dice are similar and there is no mention that the two dice are unique (e.g. different in colour, size etc.). The general question, hence, is, for cases where coins/dice are involved and are not uniquely labelled, should the order be regarded, if there is no additional mention of a first/second throw? Hope you all get my drift..",,['probability']
15,Soccer and Probability,Soccer and Probability,,"MOTIVATION : I will quote Wikipedia's article on a soccer goalkeeper for the motivation: Some goalkeepers have even scored goals. This most commonly occurs where a goalkeeper has rushed up to the opposite end of the pitch to give his team an attacking advantage in numbers. This rush is risky, as it leaves the goalkeeper's goal undefended. As such, it is normally only done late in a game at set-pieces where the consequences of scoring far outweigh those of conceding a further goal, such as for a team trailing in a knock-out tournament. The mathematical question : Consider the following game (simplified soccer): A single player starts with a score of 0.5 and plays N turns. In each turn, the player has to choose one of 2 strategies: $(p_{-1},p_0,p_1)$ or $(q_{-1},q_0,q_1)$ (these are probability vectors) and then her score is increased by -1, 0 or 1 according to the probabilites dictated by the chosen strategy. The player wins if at the end of the game she has a positive score, and loses if she has a negative score (the player's objective is to win, the only thing that matters is whether the final score is positive or negative). What is the optimal global strategy given $N$, $(p_{-1},p_0,p_1)$ and $(q_{-1},q_0,q_1)$? A global strategy is a function of the number of turns left, the current score and the 2 probability vectors (which are constant for all turns). If this question is hard, it may still may interesting to approximate an optimal global strategy (in what sense?).","MOTIVATION : I will quote Wikipedia's article on a soccer goalkeeper for the motivation: Some goalkeepers have even scored goals. This most commonly occurs where a goalkeeper has rushed up to the opposite end of the pitch to give his team an attacking advantage in numbers. This rush is risky, as it leaves the goalkeeper's goal undefended. As such, it is normally only done late in a game at set-pieces where the consequences of scoring far outweigh those of conceding a further goal, such as for a team trailing in a knock-out tournament. The mathematical question : Consider the following game (simplified soccer): A single player starts with a score of 0.5 and plays N turns. In each turn, the player has to choose one of 2 strategies: $(p_{-1},p_0,p_1)$ or $(q_{-1},q_0,q_1)$ (these are probability vectors) and then her score is increased by -1, 0 or 1 according to the probabilites dictated by the chosen strategy. The player wins if at the end of the game she has a positive score, and loses if she has a negative score (the player's objective is to win, the only thing that matters is whether the final score is positive or negative). What is the optimal global strategy given $N$, $(p_{-1},p_0,p_1)$ and $(q_{-1},q_0,q_1)$? A global strategy is a function of the number of turns left, the current score and the 2 probability vectors (which are constant for all turns). If this question is hard, it may still may interesting to approximate an optimal global strategy (in what sense?).",,"['probability', 'recreational-mathematics', 'game-theory']"
16,Complex Poker Probabilities (Texas Hold 'Em),Complex Poker Probabilities (Texas Hold 'Em),,"I've got two questions: What’s the probability that someone else has a flush, given that you have a flush? Notes:  - there are four people at the table - we don't know anything about the kind of flush. all five cards could be out in front If you have a flush, what’s the probability that someone has a better flush? Both of these seem of quite a bit more complexity than any of the other such questions form I have done.","I've got two questions: What’s the probability that someone else has a flush, given that you have a flush? Notes:  - there are four people at the table - we don't know anything about the kind of flush. all five cards could be out in front If you have a flush, what’s the probability that someone has a better flush? Both of these seem of quite a bit more complexity than any of the other such questions form I have done.",,"['probability', 'combinatorics', 'inclusion-exclusion']"
17,The probability density function of the ratio of two normal R.V.s,The probability density function of the ratio of two normal R.V.s,,"I'm looking for some help with this probability problem. Here's the question: Suppose that $X$ and $Y$ are independent standard normal random variables. Show that the probability density function of $Z = X / |Y|$ is given by   $$ f(t) = \frac{1}{\pi(1+t^2)}, \quad (-\infty < t < \infty). $$ Thanks for looking through my question. -updated- Hi guys, I've looked through the solution and am still thinking, i'm also thinking if its possible to log the expressions and apply convolution theorem... thanks for the answers once again. -updated- tried the solution using first method but couldn't figured out how to complete the last step. Heres how i did it: $f(x,y) = f_{x}(x)f_{y}(y) = \frac{1}{2\pi}e^{-\frac{1}{2}(x^2 + y^2)}$ let Z = X/|Y|, V = X then x = v, y = v/z the Jacobian J = $x_{z}y_{v}-x_{v}y_{z} = \frac{v}{z^2}$ by Transformation theorem, $w(z,v)=f(v,\frac{v}{z})|J| = ???$ Will someone please point out to me how do i proceed from here to obtain f(t)? thanks a lot! -update 3- this is actually a Cauchy density!! thanks guys, i think i got it figured out.","I'm looking for some help with this probability problem. Here's the question: Suppose that $X$ and $Y$ are independent standard normal random variables. Show that the probability density function of $Z = X / |Y|$ is given by   $$ f(t) = \frac{1}{\pi(1+t^2)}, \quad (-\infty < t < \infty). $$ Thanks for looking through my question. -updated- Hi guys, I've looked through the solution and am still thinking, i'm also thinking if its possible to log the expressions and apply convolution theorem... thanks for the answers once again. -updated- tried the solution using first method but couldn't figured out how to complete the last step. Heres how i did it: $f(x,y) = f_{x}(x)f_{y}(y) = \frac{1}{2\pi}e^{-\frac{1}{2}(x^2 + y^2)}$ let Z = X/|Y|, V = X then x = v, y = v/z the Jacobian J = $x_{z}y_{v}-x_{v}y_{z} = \frac{v}{z^2}$ by Transformation theorem, $w(z,v)=f(v,\frac{v}{z})|J| = ???$ Will someone please point out to me how do i proceed from here to obtain f(t)? thanks a lot! -update 3- this is actually a Cauchy density!! thanks guys, i think i got it figured out.",,"['probability', 'normal-distribution']"
18,Random permutations of $\mathbb{Z}_n$,Random permutations of,\mathbb{Z}_n,"In "" The maximum number of Hamiltonian paths in tournaments "" by Noga Alon, the author states the following without proof (equation 3.1): Consider a random permutation $\pi$ of $\mathbb{Z}_n$ . What is the probability that $\pi(i+1)-\pi(i) \pmod{n} <n/2$ for all $i$ ? The claim is that this is $(2+o(1))^{-n}$ , which makes sense and seems like it should be a standard argument. Does anyone have a formal proof?","In "" The maximum number of Hamiltonian paths in tournaments "" by Noga Alon, the author states the following without proof (equation 3.1): Consider a random permutation of . What is the probability that for all ? The claim is that this is , which makes sense and seems like it should be a standard argument. Does anyone have a formal proof?",\pi \mathbb{Z}_n \pi(i+1)-\pi(i) \pmod{n} <n/2 i (2+o(1))^{-n},"['probability', 'combinatorics', 'discrete-mathematics']"
19,How to work with operations/algebra of random variables?,How to work with operations/algebra of random variables?,,"How are operations such as the sum, the product, the quotient, exponentiation, etc. of random variables solved or approached? This question addresses a similar problem but starts one step further: knowing how to find the distribution of a function of random variables. I'm asking for the previous step. Then, my question is how, in general, all the operations over random variables are handled?","How are operations such as the sum, the product, the quotient, exponentiation, etc. of random variables solved or approached? This question addresses a similar problem but starts one step further: knowing how to find the distribution of a function of random variables. I'm asking for the previous step. Then, my question is how, in general, all the operations over random variables are handled?",,"['probability-theory', 'probability']"
20,Renyi parking problem for finite intervals,Renyi parking problem for finite intervals,,"The so called Renyi parking constant gives the covering density of an infinite interval $[0,L]_{L\to\infty}$ that was randomly covered by unit intervals. Covering is only allowed if the place is not occupied by a previously covered interval. The process finishes if the largest uncovered segment is shorter than $1$ . The covering density $C_\infty$ can be exactly expressed by a double integral $$C_\infty=\int_0^\infty \exp\left(-2\int_0^x\dfrac{1-e^{-y}}{y}{d}y\right)dx\approx 0.74759792\ldots \;\text{for} \; L \to \infty,\tag{1}$$ i.e. almost $75\%$ are occupied by disjunct unit intervals. If the interval to be covered is finite then no exact density is known except for the trivial cases $$\begin{matrix}C=&0 \;&\text{for} \; &L \lt 1\\C=&1/L\; &\text{for} \; &1\le L \le 2\\C=&2/3\; &\text{for} \; &L = 3.\end{matrix}\tag{2}$$ The best density approximation for all other cases I could find is already 60 years old (Dvoretzky1964). It evaluates the expected density to $$C=L^{-1}\left(C_\infty (L+1)-1\right) +\mathcal{O}\left[L^{-1}\left(\dfrac{2e}{L}\right)^{L-3/2}\right]\;\text{for} \; L \gt 2,L\ne3.\tag{3}$$ Especially for small $L$ this approximation is very inaccurate. For $L=2.01$ we expect from eq. $(2)$ a density close to $0.5$ but get from eq. $(3)$ $C=0.622+\mathcal{O}\left[0.826\right]$ . For $L=3.01$ we expect from eq. $(2)$ a value close to $0.\overline{6}$ and also get from eq. $(3)$ $C=0.664+\mathcal{O}\left[0.811\right]$ . But for both examples the error term is larger than the expected value. Does a better approximation or exact expression for the expected density exist? What is known about the density distribution for $L\gt2,L\ne3$ ? Dvoretzky, A.; Robbins, H.; On the Parking Problem, Publ. Math. Inst. Hung. Acad. Sci. 9, 209–224 (1964) (there eq.1.3, free download )","The so called Renyi parking constant gives the covering density of an infinite interval that was randomly covered by unit intervals. Covering is only allowed if the place is not occupied by a previously covered interval. The process finishes if the largest uncovered segment is shorter than . The covering density can be exactly expressed by a double integral i.e. almost are occupied by disjunct unit intervals. If the interval to be covered is finite then no exact density is known except for the trivial cases The best density approximation for all other cases I could find is already 60 years old (Dvoretzky1964). It evaluates the expected density to Especially for small this approximation is very inaccurate. For we expect from eq. a density close to but get from eq. . For we expect from eq. a value close to and also get from eq. . But for both examples the error term is larger than the expected value. Does a better approximation or exact expression for the expected density exist? What is known about the density distribution for ? Dvoretzky, A.; Robbins, H.; On the Parking Problem, Publ. Math. Inst. Hung. Acad. Sci. 9, 209–224 (1964) (there eq.1.3, free download )","[0,L]_{L\to\infty} 1 C_\infty C_\infty=\int_0^\infty \exp\left(-2\int_0^x\dfrac{1-e^{-y}}{y}{d}y\right)dx\approx 0.74759792\ldots \;\text{for} \; L \to \infty,\tag{1} 75\% \begin{matrix}C=&0 \;&\text{for} \; &L \lt 1\\C=&1/L\; &\text{for} \; &1\le L \le 2\\C=&2/3\; &\text{for} \; &L = 3.\end{matrix}\tag{2} C=L^{-1}\left(C_\infty (L+1)-1\right) +\mathcal{O}\left[L^{-1}\left(\dfrac{2e}{L}\right)^{L-3/2}\right]\;\text{for} \; L \gt 2,L\ne3.\tag{3} L L=2.01 (2) 0.5 (3) C=0.622+\mathcal{O}\left[0.826\right] L=3.01 (2) 0.\overline{6} (3) C=0.664+\mathcal{O}\left[0.811\right] L\gt2,L\ne3","['probability', 'reference-request']"
21,When does $\prod_i (1-\alpha X_i^2)^2\overset{P}{\rightarrow} 0$ for some $\alpha$?,When does  for some ?,\prod_i (1-\alpha X_i^2)^2\overset{P}{\rightarrow} 0 \alpha,"Define sequence of random variables $E_s$ below where $X_i$ are iid with the standard Cauchy distribution $$E_s = \prod_i^s (1-\alpha X_i^2)^2$$ Does $E_s$ converge to 0 in probability for any value of $\alpha$ ? (if $X_i$ were Gaussian, this would hold when $0<\alpha<2.421249$ ) What are the general conditions on $X_i$ for such $\alpha$ to exist? Bounded fourth moment gives sufficient condition, is it also necessary?","Define sequence of random variables below where are iid with the standard Cauchy distribution Does converge to 0 in probability for any value of ? (if were Gaussian, this would hold when ) What are the general conditions on for such to exist? Bounded fourth moment gives sufficient condition, is it also necessary?",E_s X_i E_s = \prod_i^s (1-\alpha X_i^2)^2 E_s \alpha X_i 0<\alpha<2.421249 X_i \alpha,"['probability', 'probability-theory', 'statistics']"
22,Solving exercise 2.3.5 in Vershynin's HDP book with the best choice of c,Solving exercise 2.3.5 in Vershynin's HDP book with the best choice of c,,"I am starting to work my way through Vershynin's High-Dimensional Probability and have become stuck on Exercise 2.3.5.  The problem is as follows: Let $X_i \sim \text{Bern}(p_i)$ ( $i\in\{1,\dots,N\}$ ) be independent.  Denote $S_N := \sum_i X_i$ and $\mu := ES_N$ .  Then show that there is some absolute constant $c>0$ such that for all $\delta\in (0,1]$ , we have $$P(|S_N-\mu|\geq \delta\mu)\leq 2\exp(-c\mu\delta^2).$$ I have applied Chernoff's inequality to transform the problem into showing the following inequality: $$\left(\frac{e}{1+\delta}\right)^{1+\delta} + \left(\frac{e}{1-\delta}\right)^{1-\delta} \leq 2\exp(1-c\delta^2).$$ Following a process similar to the hint given by the answer to this Math.SE question , I've shown the inequality for some $c<\frac{1}{2}$ .  However, the approach given there requires one to bound each term on the lefthand side by half the righthand side; I think that this loses some efficiency, since one needs to choose one choice of $c$ to bound each term separately even though they are unequal.  Indeed, when I try to bound each term separately I can't use $c=1/2$ , but from plotting the functions I see that $c=1/2$ should work (and it seems that the bound does not hold for $c>1/2$ , so this is the best choice of $c$ ).  Does anyone have a hint (or several) for solving the problem with $c=1/2$ ?","I am starting to work my way through Vershynin's High-Dimensional Probability and have become stuck on Exercise 2.3.5.  The problem is as follows: Let ( ) be independent.  Denote and .  Then show that there is some absolute constant such that for all , we have I have applied Chernoff's inequality to transform the problem into showing the following inequality: Following a process similar to the hint given by the answer to this Math.SE question , I've shown the inequality for some .  However, the approach given there requires one to bound each term on the lefthand side by half the righthand side; I think that this loses some efficiency, since one needs to choose one choice of to bound each term separately even though they are unequal.  Indeed, when I try to bound each term separately I can't use , but from plotting the functions I see that should work (and it seems that the bound does not hold for , so this is the best choice of ).  Does anyone have a hint (or several) for solving the problem with ?","X_i \sim \text{Bern}(p_i) i\in\{1,\dots,N\} S_N := \sum_i X_i \mu := ES_N c>0 \delta\in (0,1] P(|S_N-\mu|\geq \delta\mu)\leq 2\exp(-c\mu\delta^2). \left(\frac{e}{1+\delta}\right)^{1+\delta} + \left(\frac{e}{1-\delta}\right)^{1-\delta} \leq 2\exp(1-c\delta^2). c<\frac{1}{2} c c=1/2 c=1/2 c>1/2 c c=1/2","['probability', 'inequality']"
23,Time Reversal of an Ornstein-Uhlenbeck Process,Time Reversal of an Ornstein-Uhlenbeck Process,,"Suppose we are given a stochastic process $(X_t)_{0\leq t\leq 1}$ which satisfies $$dX_t=-\theta X_tdt+\sigma dB_t,$$ also known as the Ornstein-Uhlenbeck process, where $\theta>0,\sigma\in\mathbb R$ and $X_0=x_0\in\mathbb R$ . The goal of this post is to find coefficients $\bar b(t,x),\bar\sigma(t,x)$ so that the time-reversed process $\bar X_t:=X_{1-t}$ satisfies $$d\bar X_t=\bar b(t,\bar X_t)dt+\bar\sigma(t,\bar X_t)dB_t,\hspace{1cm} 0\leq t<1.$$ The primary reference i am using for this is this paper . I will include screenshots of the relevant parts throughout this post. First, note that the coefficients of the SDE of $X$ satisfy the usual conditions, i.e. $b,\sigma$ are Lipschitz and don't grow significantly faster than $|x|$ . Additionally, it is well-known that $X_t$ is given by $$X_t=e^{-\theta t}x_0+\sigma\int_0^te^{-\theta(t-s)}dB_s$$ and hence by noting that the integrand $e^{-\theta(t-s)}$ is deterministic and by using Itô's isometry one can show that $X_t\sim\mathcal N\big(e^{-\theta t}x_0, \frac{\sigma^2}{2\theta}(1-e^{-2\theta t})\big)$ and hence $X_t$ admits the density $\phi_{\mu_t,\sigma_t}$ , where $\phi_{\mu,\sigma}$ is the gaussian density and $\mu_t=e^{-\theta t}x_0$ and $\sigma_t^2 = \frac{\sigma^2}{2\theta}(1-e^{-2\theta t})$ . Now according to the paper linked above the coefficients of the SDE of $\bar X$ are given by . Since we have $$\partial_x\phi_{\mu,\sigma}(x)=\frac{1}{\sqrt{2\pi}\sigma} \exp\bigg(-\frac12\frac{(x-\mu)^2}{\sigma^2}\bigg)\cdot\bigg(-\frac{x-\mu}{\sigma^2}\bigg)=-\phi_{\mu,\sigma}(x)\frac{x-\mu}{\sigma^2}$$ we get the coefficients $\bar a(t,x)=\sigma^2$ and $$\bar b(t,x)=\theta x-\sigma^2_{1-t}\cdot\frac{x-\mu_{1-t}}{\sigma_{1-t}^2}=\theta x-(x-e^{-\theta t}x_0).$$ Then the backwards process $\bar X_t$ is supposed to obey the SDE $$d\bar X_t = \bigg[(\theta-1)\bar X_t + e^{-\theta t}x_0\bigg]dt + \sigma dB_t.$$ This seems to be wrong, since i see no way why this process should satisfy $\lim_{t\to 1}\bar X_t = x_0$ . Question: Are the calculations given above correct? Is the SDE actually the correct SDE for $\bar X$ ? If not, how do i correctly determine the backwards diffusion?","Suppose we are given a stochastic process which satisfies also known as the Ornstein-Uhlenbeck process, where and . The goal of this post is to find coefficients so that the time-reversed process satisfies The primary reference i am using for this is this paper . I will include screenshots of the relevant parts throughout this post. First, note that the coefficients of the SDE of satisfy the usual conditions, i.e. are Lipschitz and don't grow significantly faster than . Additionally, it is well-known that is given by and hence by noting that the integrand is deterministic and by using Itô's isometry one can show that and hence admits the density , where is the gaussian density and and . Now according to the paper linked above the coefficients of the SDE of are given by . Since we have we get the coefficients and Then the backwards process is supposed to obey the SDE This seems to be wrong, since i see no way why this process should satisfy . Question: Are the calculations given above correct? Is the SDE actually the correct SDE for ? If not, how do i correctly determine the backwards diffusion?","(X_t)_{0\leq t\leq 1} dX_t=-\theta X_tdt+\sigma dB_t, \theta>0,\sigma\in\mathbb R X_0=x_0\in\mathbb R \bar b(t,x),\bar\sigma(t,x) \bar X_t:=X_{1-t} d\bar X_t=\bar b(t,\bar X_t)dt+\bar\sigma(t,\bar X_t)dB_t,\hspace{1cm} 0\leq t<1. X b,\sigma |x| X_t X_t=e^{-\theta t}x_0+\sigma\int_0^te^{-\theta(t-s)}dB_s e^{-\theta(t-s)} X_t\sim\mathcal N\big(e^{-\theta t}x_0, \frac{\sigma^2}{2\theta}(1-e^{-2\theta t})\big) X_t \phi_{\mu_t,\sigma_t} \phi_{\mu,\sigma} \mu_t=e^{-\theta t}x_0 \sigma_t^2 = \frac{\sigma^2}{2\theta}(1-e^{-2\theta t}) \bar X \partial_x\phi_{\mu,\sigma}(x)=\frac{1}{\sqrt{2\pi}\sigma} \exp\bigg(-\frac12\frac{(x-\mu)^2}{\sigma^2}\bigg)\cdot\bigg(-\frac{x-\mu}{\sigma^2}\bigg)=-\phi_{\mu,\sigma}(x)\frac{x-\mu}{\sigma^2} \bar a(t,x)=\sigma^2 \bar b(t,x)=\theta x-\sigma^2_{1-t}\cdot\frac{x-\mu_{1-t}}{\sigma_{1-t}^2}=\theta x-(x-e^{-\theta t}x_0). \bar X_t d\bar X_t = \bigg[(\theta-1)\bar X_t + e^{-\theta t}x_0\bigg]dt + \sigma dB_t. \lim_{t\to 1}\bar X_t = x_0 \bar X","['probability', 'stochastic-processes', 'stochastic-calculus', 'markov-process', 'stochastic-differential-equations']"
24,Is $\liminf\Bbb P(X_nY_n\leq b)\geq\Bbb P(Xy\leq b) $ if $X_n\to X$ in distribution and $Y_n\to y\in\Bbb R$ in probability?,Is  if  in distribution and  in probability?,\liminf\Bbb P(X_nY_n\leq b)\geq\Bbb P(Xy\leq b)  X_n\to X Y_n\to y\in\Bbb R,"Take $b\in\mathbb{R}$ . Suppose $X_n\to X$ in distribution  and suppose $Y_n\to y$ in probability, where $y$ is a constant. How to prove $$\Bbb P(Xy\leq b) \leq \liminf_{n\to\infty}\Bbb P(X_nY_n\leq b)?$$ I've asked the question before but I didn't get any answer. So I tried myself and hopefully someone can follow my reasoning. Note : I know that this follows from Slutsky's theorem, but I'm trying to use this question to prove Slutsky's theorem. My try: Since $X_n\to X$ in distribution, then given $\epsilon>0$ there an $n\in\mathbb{N}$ such that for all $n\geq N$ $$\Bbb P(Xy\leq b)\leq\epsilon+\Bbb P(X_ny\leq b),\;\;\text{ and so }\;\;\; \Bbb P(Xy\leq b)\leq\epsilon+\inf_{n\geq N}\Bbb P(X_ny\leq b).$$ Now we need to use the fact that $Y_n\to y$ in probability. We can write the set $$\{X_ny\leq b\}=\{X_ny\leq b,Y_n\in (y-\epsilon,y+\epsilon) \}\cup \{X_ny\leq b,Y_n\not\in (y-\epsilon,y+\epsilon) \},$$ and so $$ \{X_ny\leq b\}\subseteq\underbrace{\{X_nY_n\leq b+\epsilon}_{:=A_n} \}\cup \underbrace{\{Y_n\not\in (y-\epsilon,y+\epsilon) \}}_{:=B_n},$$ Now we know that $\liminf_{n\to\infty}\Bbb P(B_n)=0$ . Now let's look at $A_n$ . For the sake of simplicity let's assume $X_n>0$ . Then we have that $$A_n=\{X_nY_n\leq b\}\cup \underbrace{\{b<X_nY_n\leq b+\epsilon\}}_{C_n}.$$ In total, we have that $$\Bbb P(X_ny\leq b)\leq \Bbb P(B_n) + \Bbb P(X_nY_n\leq b)+\mathbb{P}(C_n) $$ and $$ \Bbb P(Xy\leq b)\leq \Bbb P(X_nY_n\leq b)+\epsilon + \Bbb P(B_n) +\mathbb{P}(C_n) $$ and so finally we have made the set $\{X_nY_n\leq b\}$ appear. Taking $\liminf$ we have that $$ \Bbb P(Xy\leq b)\leq \liminf_{n\to\infty}\Bbb P(X_nY_n\leq b)+\epsilon  +\liminf_{n\to\infty}\mathbb{P}(C_n) $$ But then is it possible to bound the probability of $C_n=\{b<X_nY_n\leq b+\epsilon\}$ as a function of $\epsilon$ ?","Take . Suppose in distribution  and suppose in probability, where is a constant. How to prove I've asked the question before but I didn't get any answer. So I tried myself and hopefully someone can follow my reasoning. Note : I know that this follows from Slutsky's theorem, but I'm trying to use this question to prove Slutsky's theorem. My try: Since in distribution, then given there an such that for all Now we need to use the fact that in probability. We can write the set and so Now we know that . Now let's look at . For the sake of simplicity let's assume . Then we have that In total, we have that and and so finally we have made the set appear. Taking we have that But then is it possible to bound the probability of as a function of ?","b\in\mathbb{R} X_n\to X Y_n\to y y \Bbb P(Xy\leq b) \leq \liminf_{n\to\infty}\Bbb P(X_nY_n\leq b)? X_n\to X \epsilon>0 n\in\mathbb{N} n\geq N \Bbb P(Xy\leq b)\leq\epsilon+\Bbb P(X_ny\leq b),\;\;\text{ and so }\;\;\; \Bbb P(Xy\leq b)\leq\epsilon+\inf_{n\geq N}\Bbb P(X_ny\leq b). Y_n\to y \{X_ny\leq b\}=\{X_ny\leq b,Y_n\in (y-\epsilon,y+\epsilon) \}\cup \{X_ny\leq b,Y_n\not\in (y-\epsilon,y+\epsilon) \}, 
\{X_ny\leq b\}\subseteq\underbrace{\{X_nY_n\leq b+\epsilon}_{:=A_n} \}\cup \underbrace{\{Y_n\not\in (y-\epsilon,y+\epsilon) \}}_{:=B_n}, \liminf_{n\to\infty}\Bbb P(B_n)=0 A_n X_n>0 A_n=\{X_nY_n\leq b\}\cup \underbrace{\{b<X_nY_n\leq b+\epsilon\}}_{C_n}. \Bbb P(X_ny\leq b)\leq \Bbb P(B_n) + \Bbb P(X_nY_n\leq b)+\mathbb{P}(C_n)   \Bbb P(Xy\leq b)\leq \Bbb P(X_nY_n\leq b)+\epsilon + \Bbb P(B_n) +\mathbb{P}(C_n)  \{X_nY_n\leq b\} \liminf  \Bbb P(Xy\leq b)\leq \liminf_{n\to\infty}\Bbb P(X_nY_n\leq b)+\epsilon  +\liminf_{n\to\infty}\mathbb{P}(C_n)  C_n=\{b<X_nY_n\leq b+\epsilon\} \epsilon","['probability', 'probability-theory', 'measure-theory', 'limsup-and-liminf']"
25,Uniqueness of longest run of Bernoulli experiment,Uniqueness of longest run of Bernoulli experiment,,"In our lecture we prove the statement (Erdös-Rényi law of runs): We consider the probability space $(\Omega:=\{0,1\}^{\mathbb{N}},\mathcal{F},\mathbb{P})$ and define a Bernoulli experiment of length $n$ with probability of success $p$ . Let be $R_n$ the length of the longest run, i.e. $$ R_n:=\max\left\{l-k\mid 0\leq k<l\leq n, \frac{S_l-S_k}{l-k}=1\right\} $$ where $S_l$ , $S_k$ are the number of successes until the $l$ -th and $k$ -th step. Then $$ P\left(\lim\limits_{n\to\infty}\frac{R_n}{\ln(n)}\text{ exists and equals }\frac{1}{\ln\left(\frac{1}{p}\right)}\right)=1. $$ The proof relies on the heuristic assumption that the longest run of the Bernoulli experiment of length $n$ is unique, so that we can use the fact $$1=np^{R_n}\implies R_n=\frac{\ln(n)}{\ln\left(\frac{1}{p}\right)}.$$ To make it clear, if we conduct the experiment $n$ -times, then there is exactly one tupel $\omega\in\Omega$ which contains $R_n$ -many $1$ 's in a row, e.g. $\omega=(0,1,0,\underset{R_n-\text{ many}}{\underbrace{1,1,1,1,\dots,1}},1,1,0,0,1,0,1,1,0,\dots)$ . If we conduct the experiment $(n+1)$ -times, then there is exactly one tupel $\omega'\in\Omega$ which contains $R_{n+1}$ -many $1$ 's in a row, e.g. $\omega'=(0,1,0,\underset{R_{n+1}-\text{ many}}{\underbrace{1,1,1,1,\dots,1}},1,1,0,0,1,0,1,1,0,\dots)$ . And so on... I don't understand why we can simply make this assumption? Maybe someone is more familiar with this and can explain it to me?","In our lecture we prove the statement (Erdös-Rényi law of runs): We consider the probability space and define a Bernoulli experiment of length with probability of success . Let be the length of the longest run, i.e. where , are the number of successes until the -th and -th step. Then The proof relies on the heuristic assumption that the longest run of the Bernoulli experiment of length is unique, so that we can use the fact To make it clear, if we conduct the experiment -times, then there is exactly one tupel which contains -many 's in a row, e.g. . If we conduct the experiment -times, then there is exactly one tupel which contains -many 's in a row, e.g. . And so on... I don't understand why we can simply make this assumption? Maybe someone is more familiar with this and can explain it to me?","(\Omega:=\{0,1\}^{\mathbb{N}},\mathcal{F},\mathbb{P}) n p R_n 
R_n:=\max\left\{l-k\mid 0\leq k<l\leq n, \frac{S_l-S_k}{l-k}=1\right\}
 S_l S_k l k 
P\left(\lim\limits_{n\to\infty}\frac{R_n}{\ln(n)}\text{ exists and equals }\frac{1}{\ln\left(\frac{1}{p}\right)}\right)=1.
 n 1=np^{R_n}\implies R_n=\frac{\ln(n)}{\ln\left(\frac{1}{p}\right)}. n \omega\in\Omega R_n 1 \omega=(0,1,0,\underset{R_n-\text{ many}}{\underbrace{1,1,1,1,\dots,1}},1,1,0,0,1,0,1,1,0,\dots) (n+1) \omega'\in\Omega R_{n+1} 1 \omega'=(0,1,0,\underset{R_{n+1}-\text{ many}}{\underbrace{1,1,1,1,\dots,1}},1,1,0,0,1,0,1,1,0,\dots)","['probability', 'combinatorics', 'probability-theory']"
26,"Maximal inequality of iid random variables $\{X_{ij}\}_{1\leqslant i,j \leqslant n}$",Maximal inequality of iid random variables,"\{X_{ij}\}_{1\leqslant i,j \leqslant n}","Suppose that $\{X_{ij}\}_{1\leqslant i,j\leqslant n}$ are iid random variables with $\mathbb{E}(X_{11})=0$ and $\mathrm{Var}(X_{11})=1$ , does the following convergence hold: $$ \max_{1\leqslant  j\leqslant n}\biggl\{\frac{1}{n^2}\sum_{1\leqslant i\neq i'\leqslant n}(X_{ij}X_{i'j})\biggr\} \to 0 \qquad \text{almost surely}? $$ Comment: I have also posted this question on mathoverflow according to @D.R.'s suggestion. Background I am reading the AoP paper ""Limit of the smallest eigenvalue of a large dimensional sample covariance matrix"" by Z. Bai and Y. Yin (1993). Their Lemma 2 states a generalization of the well-known Marcinkiewicz-Zygmund strong law of large numbers to the case of multiple arrays of iid random variables. [Lemma 2 in Bai and Yin (1993) ] Let $\{\xi_{ij},i,j=1,2,\ldots\}$ be a double array of iid random variables and let $\alpha>1/2,\beta\geqslant 0$ and $M>0$ be constants. Then as $n\to\infty$ , $$ \max_{j\leqslant Mn^{\beta}} \biggl|n^{-\alpha}\sum_{i=1}^n (\xi_{ij}-c)\biggr|\to0\quad \text{almost surely}, $$ if and only if $$ (i)\quad \mathbb{E}|\xi_{11}|^{(1+\beta)/\alpha}<\infty $$ $$ (ii)\quad c =  \left\{ \begin{array}{ll}       \mathbb{E} \,\xi_{11},& \text{if }\alpha\leqslant 1, \\       \text{any number}, &\text{if }\alpha>1. \end{array}  \right.   $$ By our assumptions and taking $\alpha=\beta=M=1$ , $\xi_i=X_{ij}^2$ in this lemma, we have $$ \max_{j\leqslant n}\biggl|\frac{1}{n}\sum_{i,j}X_{ij}^2-1\biggr|\to0\quad \text{almost surely}. $$ This result is for square terms. I wonder if there is a similar result for the cross terms $$ \max_{1\leqslant  j\leqslant n}\biggl\{\frac{1}{n^2}\sum_{i\neq i'}(X_{ij}X_{i'j})\biggr\} \to 0 \qquad \text{almost surely}? $$ Attempt I can prove that $(1/n^2)\sum_{i\neq i'}(X_{ij}X_{i'j})\to 0\; a.s.$ for any fixed $j$ . But I do not know how to deal with the problem with "" $\max$ "". For fixed $j$ , $$ \mathrm{Var}\Bigl(\sum_{i\neq i'}X_{ij}X_{i'j}\Bigr)=2\sum_{i\neq i'}\mathrm{E}\bigl(X_{ij}^2\bigr)\cdot\mathrm{E}\bigl(X_{i'j}^2\bigr)=2(n^2-n), $$ then by Chebyshev's inequality, for any $\varepsilon>0$ , $$ \Pr\biggl(\frac{1}{n^2}\sum_{i\neq i'}(X_{ij}X_{i'j})>\varepsilon\biggr) =O\Bigl(\frac{1}{n^2}\Bigr), $$ which is summable. Hence, by using the Borel-Cantelli lemma, we have $$ \frac{1}{n^2}\sum_{i\neq i'}(X_{ij}X_{i'j})\to 0\qquad  \text{almost surely}.$$ If we consider $\max_{1\leqslant j\leqslant n}$ , and use the trivial inequality to bound it, we have $$ \Pr\biggl(\max_{1\leqslant  j\leqslant n}\biggl\{\frac{1}{n^2}\sum_{i\neq i'}(X_{ij}X_{i'j})\biggr\}> \varepsilon\biggr) \leqslant n\cdot \Pr\biggl(\frac{1}{n^2}\sum_{i\neq i'}(X_{i1}X_{i'1})>\varepsilon\biggr)=O\Bigl(\frac{1}{n}\Bigr),$$ which means $$ \max_{1\leqslant j\leqslant n}\biggl\{\frac{1}{n^2}\sum_{i\neq i'}(X_{ij}X_{i'j})\biggr\}\to 0\qquad  \text{in probability}.\tag{*} $$ How can we improve the result (*) to ""almost surely""?","Suppose that are iid random variables with and , does the following convergence hold: Comment: I have also posted this question on mathoverflow according to @D.R.'s suggestion. Background I am reading the AoP paper ""Limit of the smallest eigenvalue of a large dimensional sample covariance matrix"" by Z. Bai and Y. Yin (1993). Their Lemma 2 states a generalization of the well-known Marcinkiewicz-Zygmund strong law of large numbers to the case of multiple arrays of iid random variables. [Lemma 2 in Bai and Yin (1993) ] Let be a double array of iid random variables and let and be constants. Then as , if and only if By our assumptions and taking , in this lemma, we have This result is for square terms. I wonder if there is a similar result for the cross terms Attempt I can prove that for any fixed . But I do not know how to deal with the problem with "" "". For fixed , then by Chebyshev's inequality, for any , which is summable. Hence, by using the Borel-Cantelli lemma, we have If we consider , and use the trivial inequality to bound it, we have which means How can we improve the result (*) to ""almost surely""?","\{X_{ij}\}_{1\leqslant i,j\leqslant n} \mathbb{E}(X_{11})=0 \mathrm{Var}(X_{11})=1 
\max_{1\leqslant  j\leqslant n}\biggl\{\frac{1}{n^2}\sum_{1\leqslant i\neq i'\leqslant n}(X_{ij}X_{i'j})\biggr\} \to 0 \qquad \text{almost surely}?
 \{\xi_{ij},i,j=1,2,\ldots\} \alpha>1/2,\beta\geqslant 0 M>0 n\to\infty 
\max_{j\leqslant Mn^{\beta}} \biggl|n^{-\alpha}\sum_{i=1}^n (\xi_{ij}-c)\biggr|\to0\quad \text{almost surely},
 
(i)\quad \mathbb{E}|\xi_{11}|^{(1+\beta)/\alpha}<\infty
 
(ii)\quad c =  \left\{
\begin{array}{ll}
      \mathbb{E} \,\xi_{11},& \text{if }\alpha\leqslant 1, \\
      \text{any number}, &\text{if }\alpha>1.
\end{array} 
\right.  
 \alpha=\beta=M=1 \xi_i=X_{ij}^2 
\max_{j\leqslant n}\biggl|\frac{1}{n}\sum_{i,j}X_{ij}^2-1\biggr|\to0\quad \text{almost surely}.
 
\max_{1\leqslant  j\leqslant n}\biggl\{\frac{1}{n^2}\sum_{i\neq i'}(X_{ij}X_{i'j})\biggr\} \to 0 \qquad \text{almost surely}?
 (1/n^2)\sum_{i\neq i'}(X_{ij}X_{i'j})\to 0\; a.s. j \max j 
\mathrm{Var}\Bigl(\sum_{i\neq i'}X_{ij}X_{i'j}\Bigr)=2\sum_{i\neq i'}\mathrm{E}\bigl(X_{ij}^2\bigr)\cdot\mathrm{E}\bigl(X_{i'j}^2\bigr)=2(n^2-n),
 \varepsilon>0 
\Pr\biggl(\frac{1}{n^2}\sum_{i\neq i'}(X_{ij}X_{i'j})>\varepsilon\biggr) =O\Bigl(\frac{1}{n^2}\Bigr),
 
\frac{1}{n^2}\sum_{i\neq i'}(X_{ij}X_{i'j})\to 0\qquad
 \text{almost surely}. \max_{1\leqslant j\leqslant n} 
\Pr\biggl(\max_{1\leqslant  j\leqslant n}\biggl\{\frac{1}{n^2}\sum_{i\neq i'}(X_{ij}X_{i'j})\biggr\}> \varepsilon\biggr)
\leqslant n\cdot \Pr\biggl(\frac{1}{n^2}\sum_{i\neq i'}(X_{i1}X_{i'1})>\varepsilon\biggr)=O\Bigl(\frac{1}{n}\Bigr), 
\max_{1\leqslant j\leqslant n}\biggl\{\frac{1}{n^2}\sum_{i\neq i'}(X_{ij}X_{i'j})\biggr\}\to 0\qquad
 \text{in probability}.\tag{*}
","['probability', 'probability-theory', 'analysis', 'inequality', 'law-of-large-numbers']"
27,What is the probability that the committee will be made up of equal numbers of men and women?,What is the probability that the committee will be made up of equal numbers of men and women?,,"I have the following exercise of multiple option: You have four men and five women to make a committee of four people. If the committee is constituted by taking random people, what is the probability that the committee will be made up of equal numbers of men and women? a) $\frac{1}{5}$ b) $\frac{1}{2}$ c) $\frac{4}{9}$ d) $\frac{20}{21}$ My solution: There's $\binom{9}{4}$ ways to select committee, i.e., there's 126 ways to select committee.  Now, selecting equal number of man and women in group of 4 implies 2 men and 2 women so selecting 2 men of 4 is $\binom{4}{2}=6$ selecting 2 women of 5 is $\binom{5}{2}=10$ so $P(A)= \frac{6 \cdot 10}{126}=\frac{60}{126} = \frac{10}{21}$ but this is not an option ... I don't understand if I am making a mistake. Thanks for your help.","I have the following exercise of multiple option: You have four men and five women to make a committee of four people. If the committee is constituted by taking random people, what is the probability that the committee will be made up of equal numbers of men and women? a) b) c) d) My solution: There's ways to select committee, i.e., there's 126 ways to select committee.  Now, selecting equal number of man and women in group of 4 implies 2 men and 2 women so selecting 2 men of 4 is selecting 2 women of 5 is so but this is not an option ... I don't understand if I am making a mistake. Thanks for your help.",\frac{1}{5} \frac{1}{2} \frac{4}{9} \frac{20}{21} \binom{9}{4} \binom{4}{2}=6 \binom{5}{2}=10 P(A)= \frac{6 \cdot 10}{126}=\frac{60}{126} = \frac{10}{21},"['probability', 'combinatorics']"
28,Probability that two boxes contain the same balls numbered from $1$ to $n$ at any turn,Probability that two boxes contain the same balls numbered from  to  at any turn,1 n,"Choose a number $n\ge2$ . You have two boxes, A and B. Each turn, you add to each box a ball randomly numbered from 1 to n. What is the probability that, eventually, at any turn both boxes contain exactly the same numbers? (except obviously when the boxes are empty) I feel like if $n=2$ , the probability is 100%, while for $n=3$ or greater it isn't 100%, as this problem looks similar to random walks in n dimensions. (Which I learnt about in Youtube's PBS Infinite Series) Can anyone help me solve the problem? Thank you very much.","Choose a number . You have two boxes, A and B. Each turn, you add to each box a ball randomly numbered from 1 to n. What is the probability that, eventually, at any turn both boxes contain exactly the same numbers? (except obviously when the boxes are empty) I feel like if , the probability is 100%, while for or greater it isn't 100%, as this problem looks similar to random walks in n dimensions. (Which I learnt about in Youtube's PBS Infinite Series) Can anyone help me solve the problem? Thank you very much.",n\ge2 n=2 n=3,"['probability', 'combinatorics', 'random-walk']"
29,Prove that the sum of Cauchy distribution random variables divide by a infinite sequence convergence,Prove that the sum of Cauchy distribution random variables divide by a infinite sequence convergence,,"Let $X_1,...,X_n$ are independent identical random variables of standard Cauchy distribution (i.e. the density is $\frac{1}{\pi(1+x^2)}$ ). Let $n \to \infty$ and consider the random variable $S_n=X_1+,...,+X_n$ . Prove: $\frac{S_n}{a_n}\rightarrow0$ a.e. iff $\sum \frac{1}{a_n}<\infty$ . Try to give the necessary and sufficient conditions for which $$ \frac{\max(X_1,...,X_n)}{a_n}\to 0 \quad\text{a.e.} $$ My ideas so far : For problem 1, given $\sum \frac{1}{a_n}<\infty$ , I would like to prove that $\frac{S_n}{a_n}\rightarrow0$ : by Kroencker lemma, I just need to prove that $\sum\frac{X_n}{a_n}<\infty.$ Then I do it by applying Kolmogorov three series theorem: thus I can easily prove the convergence of $\sum\frac{X_n}{a_n}$ . But how to prove the converse? What can I deduce from $\frac{S_n}{a_n}\rightarrow0$ ? Maybe I should try to use characteristic function? For problem 2, I think maybe there is some way to convert $\frac{\max(X_1,...,X_n)}{a_n}$ to a similar form as in problem 1: am I right? Thanks in advance for any tips or help in general.","Let are independent identical random variables of standard Cauchy distribution (i.e. the density is ). Let and consider the random variable . Prove: a.e. iff . Try to give the necessary and sufficient conditions for which My ideas so far : For problem 1, given , I would like to prove that : by Kroencker lemma, I just need to prove that Then I do it by applying Kolmogorov three series theorem: thus I can easily prove the convergence of . But how to prove the converse? What can I deduce from ? Maybe I should try to use characteristic function? For problem 2, I think maybe there is some way to convert to a similar form as in problem 1: am I right? Thanks in advance for any tips or help in general.","X_1,...,X_n \frac{1}{\pi(1+x^2)} n \to \infty S_n=X_1+,...,+X_n \frac{S_n}{a_n}\rightarrow0 \sum \frac{1}{a_n}<\infty 
\frac{\max(X_1,...,X_n)}{a_n}\to 0 \quad\text{a.e.}
 \sum \frac{1}{a_n}<\infty \frac{S_n}{a_n}\rightarrow0 \sum\frac{X_n}{a_n}<\infty. \sum\frac{X_n}{a_n} \frac{S_n}{a_n}\rightarrow0 \frac{\max(X_1,...,X_n)}{a_n}","['probability', 'sequences-and-series', 'probability-theory']"
30,Weak topology and weak convergenge in probability spaces,Weak topology and weak convergenge in probability spaces,,"Let $X$ be a Polish space (metrizable, complete, separable) with $\mathcal{B}(X)$ its borel sigma algebra. Let us consider $\mathcal{P}(X)$ the space of probability measures on $\mathcal{B}(X)$ . We endow it with the weak topology denoted by $\tau^{w}$ given by the functionals \begin{align} Q\to L_{f}(Q) := \int_{X} f(x) Q(dx),\hspace{0.3cm}f\in C_{b}(X),Q\in \mathcal{P}(X)   \end{align} with $C_{b}(X)$ the continuous and bounded real functions, that is a base for the weak topology is given by the sets \begin{align} W(f,x,\delta) : =  \{ \mu\in \mathcal{P}(X),\hspace{0.3cm} |L_f(\mu) - x|<\delta  \}. \end{align} This topology induces a convergence, and it can be proved that this convergence is equal to the one given by the functionals, that is we say that a sequence $(\mu_n)_{n\in\mathbb{N}}$ in $\mathcal{P}(X)$ converges weakly to $\mu\in\mathcal{P}(X)$ , and we write $\mu_n\rightharpoonup\mu$ if \begin{align} L_f(\mu_n)=\int_Xf d\mu_n \to \int_Xfd\mu = L_f(\mu),\hspace{0.3cm}\forall f\in C_b(X). \end{align} Now I want to do what it is written here with the 2-Wasserstein distance, that is to check the mesurability of a markov kernel compounded with a Wasserstein distance, and I want to understand the details. First of all, we are interested in the borel sigma algebra of $(\mathcal{P}(X),\tau^w )$ , let us denote such sigma algebra as $\mathcal{B}(\mathcal{P}(X))$ . Since it can be proved that $(\mathcal{P}(X),\tau^w )$ is Polish as it is stated in this other question, it has a countable base, so it follow that $\mathcal{B}(\mathcal{P}(X))$ is equal to the smallest sigma algebra that makes all $(L_f)_{f\in C_b(X)}$ measurable, and so we can check the measurability of a Markov Kernel by compounding it with $L_f$ for all $f\in C_b(X)$ , is this right? Now I asked myself something more general. For example in the book of Villani, Optimal transport, old and new (2008) , chapter 6, it is stated that \begin{align} \mathcal{P}_p(X) = \{ \mu \in \mathcal{P}(X): \int_X d(x_0,x)^p \mu(dx)<+\infty \} \end{align} is a Polish space with the $p-Wasserstein$ $distance$ , and he proves that \begin{align} \mu_n \rightharpoonup \mu, \hspace{0.3cm}and\hspace{0.3 cm} \int_X d(x,x_0)\mu_n \to \int_X d(x,x_0) \mu \iff W_p(\mu_n,\mu) \to 0. \end{align} Now I was wondering, he defines another notion of convergence and he proves that the Wasserstein distance metrize such convergence. But what about the weak topology induced by the functional that define such convergence, that is \begin{align} \{L_f: f\in C_b(X), x \to d(x,x_0)^p, x_0\in X \}? \end{align} In general if a distance metrize the weak convergence it is not true that it induces the same topoly, I think about $l^1$ where the strong topology and the weak topology induce the same sequences that converge (as said by Brezis), but the strong and the weak topology are different. In this case we have a distance that induces the same sequences which converge, but the topology a priori may be different. When Villani talks about continuity and $lsc$ about $W_p$ , in chapter 6, he always intend sequential continuity and sequential semicontinuity right? He never speak about the weak topology or am I wrong? When he talks about the fact that $\mathcal{P}_p(X)$ is Polish, he intends with respect to the topology induced by the Wasserstein right? Not the weak topology induced by the functionals? However, we are interested in mesurability, so if we see just the sigma algebra generated by the $W_p$ and the borel sigma algebra on $\mathcal{P}_p(X)$ , they are the same I think, and it can be proved by using exactly the $lsc$ with respect to the weak topology on $\mathcal{P}(X)$ and the fact that such topology is metrizable and separable, as I said above. Does it follow in some easy way that the borel sigma algebra of the functionals is the same as the borel sigma algebra of the Wasserstein metric? We just need to prove that $W_p$ metrizes the weak convergence and we have the equality between sigma algebras? More generally, let us consider a set $Y$ with some functional $(L_f,f\in \mathcal{F})$ that induces the weak topology $\tau^w$ on $Y$ ,and it induces a weak convergence on $Y$ given by \begin{align} y_n \rightharpoonup y \iff L_f(y_n)\to L_f(y), \hspace{0.3cm} \forall f\in \mathcal{F}. \end{align} Let us suppose that we succed to find a distance $d$ that metrize the weak convergence, that is \begin{align} y_n \rightharpoonup y \iff d(y_n,y) \to 0. \end{align} When it is true that the borel sets of the weak convergence, the borel sets of the distance $d$ , and the smallest sigma algebra that makes $(L_f,f\in\mathcal{F})$ measurable are equal? That is we have \begin{align} \mathcal{B}(\tau^w) = \mathcal{B}(d) = \sigma( L_f,f\in\mathcal{F} ) ? \end{align} I think that we may need that $d$ induces a metric space searable, but what else?","Let be a Polish space (metrizable, complete, separable) with its borel sigma algebra. Let us consider the space of probability measures on . We endow it with the weak topology denoted by given by the functionals with the continuous and bounded real functions, that is a base for the weak topology is given by the sets This topology induces a convergence, and it can be proved that this convergence is equal to the one given by the functionals, that is we say that a sequence in converges weakly to , and we write if Now I want to do what it is written here with the 2-Wasserstein distance, that is to check the mesurability of a markov kernel compounded with a Wasserstein distance, and I want to understand the details. First of all, we are interested in the borel sigma algebra of , let us denote such sigma algebra as . Since it can be proved that is Polish as it is stated in this other question, it has a countable base, so it follow that is equal to the smallest sigma algebra that makes all measurable, and so we can check the measurability of a Markov Kernel by compounding it with for all , is this right? Now I asked myself something more general. For example in the book of Villani, Optimal transport, old and new (2008) , chapter 6, it is stated that is a Polish space with the , and he proves that Now I was wondering, he defines another notion of convergence and he proves that the Wasserstein distance metrize such convergence. But what about the weak topology induced by the functional that define such convergence, that is In general if a distance metrize the weak convergence it is not true that it induces the same topoly, I think about where the strong topology and the weak topology induce the same sequences that converge (as said by Brezis), but the strong and the weak topology are different. In this case we have a distance that induces the same sequences which converge, but the topology a priori may be different. When Villani talks about continuity and about , in chapter 6, he always intend sequential continuity and sequential semicontinuity right? He never speak about the weak topology or am I wrong? When he talks about the fact that is Polish, he intends with respect to the topology induced by the Wasserstein right? Not the weak topology induced by the functionals? However, we are interested in mesurability, so if we see just the sigma algebra generated by the and the borel sigma algebra on , they are the same I think, and it can be proved by using exactly the with respect to the weak topology on and the fact that such topology is metrizable and separable, as I said above. Does it follow in some easy way that the borel sigma algebra of the functionals is the same as the borel sigma algebra of the Wasserstein metric? We just need to prove that metrizes the weak convergence and we have the equality between sigma algebras? More generally, let us consider a set with some functional that induces the weak topology on ,and it induces a weak convergence on given by Let us suppose that we succed to find a distance that metrize the weak convergence, that is When it is true that the borel sets of the weak convergence, the borel sets of the distance , and the smallest sigma algebra that makes measurable are equal? That is we have I think that we may need that induces a metric space searable, but what else?","X \mathcal{B}(X) \mathcal{P}(X) \mathcal{B}(X) \tau^{w} \begin{align}
Q\to L_{f}(Q) := \int_{X} f(x) Q(dx),\hspace{0.3cm}f\in C_{b}(X),Q\in \mathcal{P}(X)  
\end{align} C_{b}(X) \begin{align}
W(f,x,\delta) : =  \{ \mu\in \mathcal{P}(X),\hspace{0.3cm} |L_f(\mu) - x|<\delta  \}.
\end{align} (\mu_n)_{n\in\mathbb{N}} \mathcal{P}(X) \mu\in\mathcal{P}(X) \mu_n\rightharpoonup\mu \begin{align}
L_f(\mu_n)=\int_Xf d\mu_n \to \int_Xfd\mu = L_f(\mu),\hspace{0.3cm}\forall f\in C_b(X).
\end{align} (\mathcal{P}(X),\tau^w ) \mathcal{B}(\mathcal{P}(X)) (\mathcal{P}(X),\tau^w ) \mathcal{B}(\mathcal{P}(X)) (L_f)_{f\in C_b(X)} L_f f\in C_b(X) \begin{align}
\mathcal{P}_p(X) = \{ \mu \in \mathcal{P}(X): \int_X d(x_0,x)^p \mu(dx)<+\infty \}
\end{align} p-Wasserstein distance \begin{align}
\mu_n \rightharpoonup \mu, \hspace{0.3cm}and\hspace{0.3 cm}
\int_X d(x,x_0)\mu_n \to \int_X d(x,x_0) \mu \iff W_p(\mu_n,\mu) \to 0.
\end{align} \begin{align}
\{L_f: f\in C_b(X), x \to d(x,x_0)^p, x_0\in X \}?
\end{align} l^1 lsc W_p \mathcal{P}_p(X) W_p \mathcal{P}_p(X) lsc \mathcal{P}(X) W_p Y (L_f,f\in \mathcal{F}) \tau^w Y Y \begin{align}
y_n \rightharpoonup y \iff L_f(y_n)\to L_f(y), \hspace{0.3cm} \forall f\in \mathcal{F}.
\end{align} d \begin{align}
y_n \rightharpoonup y \iff d(y_n,y) \to 0.
\end{align} d (L_f,f\in\mathcal{F}) \begin{align}
\mathcal{B}(\tau^w) = \mathcal{B}(d) = \sigma( L_f,f\in\mathcal{F} ) ?
\end{align} d","['probability', 'measure-theory', 'weak-convergence', 'measurable-functions', 'weak-topology']"
31,Maximize the variance of a function of random variable,Maximize the variance of a function of random variable,,"I have a function $f(X)=\exp\left(\frac{-\gamma^2}{a^2X+b^2}\right)$ where $X \sim \mathrm{Binomial}(n,p)$ .  I am interested in finding the value of $\gamma^2$ which maximizes the variance of $f(X)$ for given values of $a$ and $b$ . Definition of variance : $$ \operatorname{var}(f(X))=\mathrm{E}\left(f^2(X)\right)-\left(\mathrm{E}\bigl(f(X) \bigl) \right)^{2} $$ From Expectation of Function of Discrete Random Variable: $$E\left(f^2(X)\right)=\sum_{k = 0}^{n} \exp\left(\frac{-2\gamma^2}{a^2k+b^2}\right) {n \choose k} p^{k} (1-p)^{n-k}$$ $$E\left(f(X)\right)=\sum_{k = 0}^{n} \exp\left(\frac{-\gamma^2}{a^2k+b^2}\right)  {n \choose k} p^{k} (1-p)^{n-k}$$ To me, it seems NOT straightforward how to solve $\mathrm{d}[\operatorname{var}(f(X))]/\mathrm{d}\gamma=0$ to find an expression for optimal $\gamma^2$ . Hence, I am thinking of at least finding a numerically accurate solution through curve-fitting. My aim is to come up with a ""working formula"" for optimal $\gamma$ in terms of the other parameters. Also, I have MATLAB and I am wondering how formulate this problem and find an expression using MATLAB as well. Some context on $f(X)$ : $f(X)$ comes from the complementary CDF of an exponential distribution. There are $X$ signal components with power $a^2$ and a non-signal component with power $b^2$ . Also, $\gamma^2$ is a threshold at which we evaluate the function.","I have a function where .  I am interested in finding the value of which maximizes the variance of for given values of and . Definition of variance : From Expectation of Function of Discrete Random Variable: To me, it seems NOT straightforward how to solve to find an expression for optimal . Hence, I am thinking of at least finding a numerically accurate solution through curve-fitting. My aim is to come up with a ""working formula"" for optimal in terms of the other parameters. Also, I have MATLAB and I am wondering how formulate this problem and find an expression using MATLAB as well. Some context on : comes from the complementary CDF of an exponential distribution. There are signal components with power and a non-signal component with power . Also, is a threshold at which we evaluate the function.","f(X)=\exp\left(\frac{-\gamma^2}{a^2X+b^2}\right) X \sim \mathrm{Binomial}(n,p) \gamma^2 f(X) a b 
\operatorname{var}(f(X))=\mathrm{E}\left(f^2(X)\right)-\left(\mathrm{E}\bigl(f(X) \bigl) \right)^{2}
 E\left(f^2(X)\right)=\sum_{k = 0}^{n} \exp\left(\frac{-2\gamma^2}{a^2k+b^2}\right) {n \choose k} p^{k} (1-p)^{n-k} E\left(f(X)\right)=\sum_{k = 0}^{n} \exp\left(\frac{-\gamma^2}{a^2k+b^2}\right)  {n \choose k} p^{k} (1-p)^{n-k} \mathrm{d}[\operatorname{var}(f(X))]/\mathrm{d}\gamma=0 \gamma^2 \gamma f(X) f(X) X a^2 b^2 \gamma^2","['probability', 'probability-distributions', 'optimization', 'numerical-methods', 'random-variables']"
32,"Draw nickels and dollar coins until $p$ dollars, expectation","Draw nickels and dollar coins until  dollars, expectation",p,"Here's a question from my probability textbook: A bag contains $m$ dollar coins and $n$ nickels. A man is allowed to draw coins one by one until he has drawn at least $p$ dollars. Show that the value of his expectation is ${{np}\over{20(m+1)}} + p$ dollars. Here's what I did. We space our $m$ dollar coins equally so that they partition our $n$ nickels into $m+1$ parts of ${n\over{m+1}}$ nickels each. And each of those parts will have value of ${n\over{20(m+1)}}$ dollars. So then our desired expectation ${{np}\over{20(m+1)}} + p$ dollars is equal to drawing coins up until the $p$ th (evenly spaced) dollar coin. But these are just my observations, I'm not sure if I have even showed what we wanted to show. Have I just merely asserted what we want to show without explanation? How can I conclude the result? What am I missing? Is the problem statement even correct? Update: To clarify, I realize the problem statement means at least $p$ dollar coins, hence the solution method I gave and also Yuri Negometyanov's solution below. But I am more interested in the answer when it's at least $p$ dollars in money (and not at least $p$ dollar coins).","Here's a question from my probability textbook: A bag contains dollar coins and nickels. A man is allowed to draw coins one by one until he has drawn at least dollars. Show that the value of his expectation is dollars. Here's what I did. We space our dollar coins equally so that they partition our nickels into parts of nickels each. And each of those parts will have value of dollars. So then our desired expectation dollars is equal to drawing coins up until the th (evenly spaced) dollar coin. But these are just my observations, I'm not sure if I have even showed what we wanted to show. Have I just merely asserted what we want to show without explanation? How can I conclude the result? What am I missing? Is the problem statement even correct? Update: To clarify, I realize the problem statement means at least dollar coins, hence the solution method I gave and also Yuri Negometyanov's solution below. But I am more interested in the answer when it's at least dollars in money (and not at least dollar coins).",m n p {{np}\over{20(m+1)}} + p m n m+1 {n\over{m+1}} {n\over{20(m+1)}} {{np}\over{20(m+1)}} + p p p p p,"['probability', 'combinatorics', 'algebra-precalculus', 'expected-value']"
33,Sample size calculation for accuracy,Sample size calculation for accuracy,,"In a scientific association, an electoral process for the president of the association will take place. There are 2 candidates, A and B. Every member (of the N in total) will vote either for A or for B. We would like to estimate the percentage of A candidate (let’s call it P) and for this, we use a sample of size $n (n<N)$ . What is the optimum number of n, so that the percentage of voters of A in the sample varies from the real percentage P of voters of A by less than $1%$ (in absolute value), with probability $95%$ ? I have found a wikipedia link https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Normal_approximation_interval but am not sure which formula to use, since there are no numbers for the population $(N)$ and also for $P$ and $(1-P)$ . As I am not at all familiar with statistics and this kind of stuff, I did a bit of research - the only (easy) thing I managed to find is that the value of $z$ for $95%$ is $1.96$ . So we would like $P(|\hat{p}-p| \le 0.01)$ to be $95%$ . But we don't have any indication of $P$ ! (I am not doing any homework - this is a ""real life"" problem to calculate a suggested ""exit poll"" size). Thank you very much in advance! Edit: I now found this equation: $n \geq \left(\dfrac{z_{\alpha/2} \sigma}{\delta}\right)^2$ and wonder if I can use it.","In a scientific association, an electoral process for the president of the association will take place. There are 2 candidates, A and B. Every member (of the N in total) will vote either for A or for B. We would like to estimate the percentage of A candidate (let’s call it P) and for this, we use a sample of size . What is the optimum number of n, so that the percentage of voters of A in the sample varies from the real percentage P of voters of A by less than (in absolute value), with probability ? I have found a wikipedia link https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Normal_approximation_interval but am not sure which formula to use, since there are no numbers for the population and also for and . As I am not at all familiar with statistics and this kind of stuff, I did a bit of research - the only (easy) thing I managed to find is that the value of for is . So we would like to be . But we don't have any indication of ! (I am not doing any homework - this is a ""real life"" problem to calculate a suggested ""exit poll"" size). Thank you very much in advance! Edit: I now found this equation: and wonder if I can use it.",n (n<N) 1% 95% (N) P (1-P) z 95% 1.96 P(|\hat{p}-p| \le 0.01) 95% P n \geq \left(\dfrac{z_{\alpha/2} \sigma}{\delta}\right)^2,"['probability', 'statistics', 'standard-deviation']"
34,An expected value puzzle,An expected value puzzle,,"While working on a larger problem, I encountered this smaller problem that I’ve enjoyed thinking about, but have yet to solve. Shuffle the numbers 0 to 24 into a 5 by 5 matrix. Sort each column in ascending order, then sort each row in ascending order. What’s the expected value of the $(i, j)$ entry?","While working on a larger problem, I encountered this smaller problem that I’ve enjoyed thinking about, but have yet to solve. Shuffle the numbers 0 to 24 into a 5 by 5 matrix. Sort each column in ascending order, then sort each row in ascending order. What’s the expected value of the entry?","(i, j)","['probability', 'matrices', 'expected-value', 'symmetry', 'sorting']"
35,Min/max dice problem,Min/max dice problem,,"Suppose Anne throws two fair dice and the faces show $4$ and $3$ . It is your turn and Anne states that if both dice show a number greater than $4$ and $3$ , you will win the game. What is the probability of you winning the game? (i.e. if your outcome is $4$ and $5$ you will win, as the biggest gets paired with the biggest and smallest with the smallest). By listing the favorable possibilities, we obtain: $$\begin{aligned} &(4,5)&\qquad (4,6) &\qquad (5,6) &\qquad (5,5)&\\ &(5,4)&\qquad (6,4) &\qquad (6,5) &\qquad (6,6)& \end{aligned}$$ so the proability must be $8/36$ or $2/9$ . However, I am interested in knowing why the following way does not work. Let $X_1\sim\text{Unif}\,\{1,6\}$ and $X_2\sim\text{Unif}\,\{1,6\}$ . I need $$\begin{aligned} P(\max\{X_1,X_2\}>4,\min\{X_1,X_2\}>3)&=P(\max\{X_1,X_2\}>4)P(\min\{X_1,X_2\}>3)\\ &=\left[1-P(\max\{X_1,X_2\}\leq4)\right]P(X_1>3,X_2>3)\\ &=\left[1-P(X_1\leq4,X_2\leq4)\right]P(X_1>3)P(X_2>3)\\ &=\left[1-P(X_1\leq4)P(X_2\leq4)\right]\left[1-P(X_1\leq3)\right]\left[1-P(X_2\leq3)\right]\\ &=\left(1-\frac{4}{6}\cdot\frac{4}{6}\right)\left(1-\frac36\right)\left(1-\frac36\right)\\ &=\left[1-\left(\frac{4}{6}\right)^2\right]\left(1-\frac36\right)^2=\frac5{36}. \end{aligned} $$ What is wrong with this approach? Another approach I considered is, $$\begin{aligned} P(\max\{X_1,X_2\}>4,\min\{X_1,X_2\}>3)&=P(\{X_1>4,X_2>3\}\cup\{X_1>3\,X_2>4\})\\ &=P(\{X_1>4,X_2>3\})+P(\{X_1>3\,X_2>4\})\\ &=P(X_1>4)P(X_2>3)+P(X_1>3)P(X_2>4)\\ &=\frac26\cdot\frac36+\frac36\cdot\frac26=\frac13. \end{aligned}$$ Why are the above different? Is it not true that $\max\{X_1,X_2\}>4,\min\{X_1,X_2\}>3 \implies \{X_1>4,X_2>3\}\cup\{X_1>3\,X_2>4\}$ ?","Suppose Anne throws two fair dice and the faces show and . It is your turn and Anne states that if both dice show a number greater than and , you will win the game. What is the probability of you winning the game? (i.e. if your outcome is and you will win, as the biggest gets paired with the biggest and smallest with the smallest). By listing the favorable possibilities, we obtain: so the proability must be or . However, I am interested in knowing why the following way does not work. Let and . I need What is wrong with this approach? Another approach I considered is, Why are the above different? Is it not true that ?","4 3 4 3 4 5 \begin{aligned}
&(4,5)&\qquad (4,6) &\qquad (5,6) &\qquad (5,5)&\\
&(5,4)&\qquad (6,4) &\qquad (6,5) &\qquad (6,6)&
\end{aligned} 8/36 2/9 X_1\sim\text{Unif}\,\{1,6\} X_2\sim\text{Unif}\,\{1,6\} \begin{aligned}
P(\max\{X_1,X_2\}>4,\min\{X_1,X_2\}>3)&=P(\max\{X_1,X_2\}>4)P(\min\{X_1,X_2\}>3)\\
&=\left[1-P(\max\{X_1,X_2\}\leq4)\right]P(X_1>3,X_2>3)\\
&=\left[1-P(X_1\leq4,X_2\leq4)\right]P(X_1>3)P(X_2>3)\\
&=\left[1-P(X_1\leq4)P(X_2\leq4)\right]\left[1-P(X_1\leq3)\right]\left[1-P(X_2\leq3)\right]\\
&=\left(1-\frac{4}{6}\cdot\frac{4}{6}\right)\left(1-\frac36\right)\left(1-\frac36\right)\\
&=\left[1-\left(\frac{4}{6}\right)^2\right]\left(1-\frac36\right)^2=\frac5{36}.
\end{aligned}
 \begin{aligned}
P(\max\{X_1,X_2\}>4,\min\{X_1,X_2\}>3)&=P(\{X_1>4,X_2>3\}\cup\{X_1>3\,X_2>4\})\\
&=P(\{X_1>4,X_2>3\})+P(\{X_1>3\,X_2>4\})\\ &=P(X_1>4)P(X_2>3)+P(X_1>3)P(X_2>4)\\
&=\frac26\cdot\frac36+\frac36\cdot\frac26=\frac13.
\end{aligned} \max\{X_1,X_2\}>4,\min\{X_1,X_2\}>3 \implies \{X_1>4,X_2>3\}\cup\{X_1>3\,X_2>4\}","['probability', 'dice']"
36,Random list lengths,Random list lengths,,"I am trying to analyze analytically what would happen if I build a random simulator as follow: I begin with $ N $ lists of length 1, at each iteration, I will pick a random (non-empty) list, reduce its length by 1. And then, with probably $ p $ , I create a new list of length 1, otherwise, I pick a random (non-empty) list and increase its length by 1. Every iteration keeps the total lengths of the lists constant, and I am interested in the distribution of list lengths. A simple Monte Carlos simulation yield some interesting findings. With $ N = 100 $ and $ p = 0.5 $ , we have, approximately $ P(L = 1) \approx 2 P(L = 2) $ and $ P(L = 2) \approx 2 P(L = 3) $ , and so on. As it is just a simulation, the number is not exact of course. I run the simulator 1,000,000 times to be sure we reach stationary. I really wonder there could be some time-reversible Markov Chain that could explain this, but my skill there is really rusty and some help would be greatly appreciated. Attached below is the code I used to perform the Monte Carlos simulation, just for reproducibility. from random import *  Size = 100 D = {} N = [1] * Size L = Size R = Size p = 50  for i in range(0, Size + 1):     D[i] = 0  for i in range(0, 1000000):     toremove = randint(0, R - 1)     N[toremove] = N[toremove] - 1     if N[toremove] == 0:         N[toremove] = N[R - 1]         N[R - 1] = 0         R = R - 1     tocreate = randint(0, 100)     if tocreate < p:          N[R] = N[R] + 1         R = R + 1     else:         if R == 1:             toappend = 0         else:             toappend = randint(0, R - 1)         N[toappend] = N[toappend] + 1     for n in N:         D[n] = D[n] + 1 print(D) EDIT: To make the problem more tractable for a manual calculation. I reduced the list size to 3. In this case, we have only 3 meaningful states. We have 3 lists of size 1, 1 list of size 2 together with 1 size of size 1, and 1 list of size 3. The transition matrix for these states is as follow (the probability values can be reasoned by a case by case analysis). $\left(\begin{array}{ccc} p & 1-p & 0 \\ \frac{p}{2} & \frac{1}{2} & \frac{1-p}{2} \\ 0 & p & 1-p \end{array}\right)$ For $ p = \frac{1}{2} $ , the stationary probability can be found as the eigen vector of $ T' $ corresponding to eigenvalue 1 to be $\left(\begin{array}{c} \frac{1}{4} \\ \frac{1}{2} \\ \frac{1}{4}  \end{array}\right) $ That explains the list length distribution because the expected number of lists of length 1 will be $ N \times (\frac{1}{4} \times 3 + \frac{1}{2} \times 1) = \frac{5N}{4} $ . The number of list of length 2 would be $ N \times \frac{N}{2} =  $ and the number of lists of length 1 would be $ N \times \frac{1}{4} = \frac{N}{4} $ , which is roughly the doubling that we are seeing. In fact $ \frac{5N}{4} $ matches better to the experiment data than $ N $ . Attached is the octave code for computing the Markov chain stationary state probability as well as the expected list lengths. The 10000 power is used as an easy way to approximate. With this code, now I can easily tune $ p $ and figure $ p $ can be used effectively to change list length distributions. p = 0.5 T = [p, (1-p), 0;p/2,1/2,(1-p)/2;0,p,(1-p)]; ([1,0,0] * T^10000) * [3,0,0;1,1,0;0,0,1] All the above shown Markov chain could be used to analyze the situation. However, it requires a lot of effort to analyze the states in the case by case manner and it certainly won't scale for big $ N $ . I am planning to run this simulator with $ N = 1000000 $ or above.","I am trying to analyze analytically what would happen if I build a random simulator as follow: I begin with lists of length 1, at each iteration, I will pick a random (non-empty) list, reduce its length by 1. And then, with probably , I create a new list of length 1, otherwise, I pick a random (non-empty) list and increase its length by 1. Every iteration keeps the total lengths of the lists constant, and I am interested in the distribution of list lengths. A simple Monte Carlos simulation yield some interesting findings. With and , we have, approximately and , and so on. As it is just a simulation, the number is not exact of course. I run the simulator 1,000,000 times to be sure we reach stationary. I really wonder there could be some time-reversible Markov Chain that could explain this, but my skill there is really rusty and some help would be greatly appreciated. Attached below is the code I used to perform the Monte Carlos simulation, just for reproducibility. from random import *  Size = 100 D = {} N = [1] * Size L = Size R = Size p = 50  for i in range(0, Size + 1):     D[i] = 0  for i in range(0, 1000000):     toremove = randint(0, R - 1)     N[toremove] = N[toremove] - 1     if N[toremove] == 0:         N[toremove] = N[R - 1]         N[R - 1] = 0         R = R - 1     tocreate = randint(0, 100)     if tocreate < p:          N[R] = N[R] + 1         R = R + 1     else:         if R == 1:             toappend = 0         else:             toappend = randint(0, R - 1)         N[toappend] = N[toappend] + 1     for n in N:         D[n] = D[n] + 1 print(D) EDIT: To make the problem more tractable for a manual calculation. I reduced the list size to 3. In this case, we have only 3 meaningful states. We have 3 lists of size 1, 1 list of size 2 together with 1 size of size 1, and 1 list of size 3. The transition matrix for these states is as follow (the probability values can be reasoned by a case by case analysis). For , the stationary probability can be found as the eigen vector of corresponding to eigenvalue 1 to be That explains the list length distribution because the expected number of lists of length 1 will be . The number of list of length 2 would be and the number of lists of length 1 would be , which is roughly the doubling that we are seeing. In fact matches better to the experiment data than . Attached is the octave code for computing the Markov chain stationary state probability as well as the expected list lengths. The 10000 power is used as an easy way to approximate. With this code, now I can easily tune and figure can be used effectively to change list length distributions. p = 0.5 T = [p, (1-p), 0;p/2,1/2,(1-p)/2;0,p,(1-p)]; ([1,0,0] * T^10000) * [3,0,0;1,1,0;0,0,1] All the above shown Markov chain could be used to analyze the situation. However, it requires a lot of effort to analyze the states in the case by case manner and it certainly won't scale for big . I am planning to run this simulator with or above."," N   p   N = 100   p = 0.5   P(L = 1) \approx 2 P(L = 2)   P(L = 2) \approx 2 P(L = 3)  \left(\begin{array}{ccc}
p & 1-p & 0 \\
\frac{p}{2} & \frac{1}{2} & \frac{1-p}{2} \\
0 & p & 1-p
\end{array}\right)  p = \frac{1}{2}   T'  \left(\begin{array}{c}
\frac{1}{4} \\
\frac{1}{2} \\
\frac{1}{4} 
\end{array}\right)
  N \times (\frac{1}{4} \times 3 + \frac{1}{2} \times 1) = \frac{5N}{4}   N \times \frac{N}{2} =    N \times \frac{1}{4} = \frac{N}{4}   \frac{5N}{4}   N   p   p   N   N = 1000000 ",['probability']
37,Variation of Birthday problem - Group of n people,Variation of Birthday problem - Group of n people,,"I know this has been posted several times and I have gone through most of the relevant posts. Here is one which I am having a difficult time to solve: There are 450 people in a room; (1) how many of them are expected to have the same birthday with some other person in the room, (2) with at least 2 other people in the room and (3) with at least 3. (1) is easy - by the pigeonhole principle, 450-365 (or 366) = 85 people are expected to have the same birthday. How do we do (2) and (3)? I am thinking that in 85 people we have $\frac {85*84} {2} = 3570$ possible pairs so the probability for a 3rd person to share one of their birthdays is $1-\frac {364}{365}^{85}$ . And then how do we find the expected number of people for each case? Any help is greatly appreciated! Thank you!","I know this has been posted several times and I have gone through most of the relevant posts. Here is one which I am having a difficult time to solve: There are 450 people in a room; (1) how many of them are expected to have the same birthday with some other person in the room, (2) with at least 2 other people in the room and (3) with at least 3. (1) is easy - by the pigeonhole principle, 450-365 (or 366) = 85 people are expected to have the same birthday. How do we do (2) and (3)? I am thinking that in 85 people we have possible pairs so the probability for a 3rd person to share one of their birthdays is . And then how do we find the expected number of people for each case? Any help is greatly appreciated! Thank you!",\frac {85*84} {2} = 3570 1-\frac {364}{365}^{85},"['probability', 'combinatorics', 'birthday']"
38,"If I reset after each run, how many times do I need to repeat an experiment to have a 75% chance of running it on all the subjects?","If I reset after each run, how many times do I need to repeat an experiment to have a 75% chance of running it on all the subjects?",,Suppose there is a bag with 100 marbles. And I can draw 5 marbles in one attempt. But after that draw I have to put the marbles back. In how many attempts do I have a 75% chance that I have drawn each marble at least once? I wrote a brute force program that calculated this: Marbles = 100. DRAW 5 at a time. Performing 100000 runs. Runs completed = 10000 Runs completed = 20000 Runs completed = 30000 Runs completed = 40000 Runs completed = 50000 Runs completed = 60000 Runs completed = 70000 Runs completed = 80000 Runs completed = 90000 Runs completed = 100000 For 75% confidence you need 115 draws. But how can we mathematically arrive at the same answer?,Suppose there is a bag with 100 marbles. And I can draw 5 marbles in one attempt. But after that draw I have to put the marbles back. In how many attempts do I have a 75% chance that I have drawn each marble at least once? I wrote a brute force program that calculated this: Marbles = 100. DRAW 5 at a time. Performing 100000 runs. Runs completed = 10000 Runs completed = 20000 Runs completed = 30000 Runs completed = 40000 Runs completed = 50000 Runs completed = 60000 Runs completed = 70000 Runs completed = 80000 Runs completed = 90000 Runs completed = 100000 For 75% confidence you need 115 draws. But how can we mathematically arrive at the same answer?,,['probability']
39,A disc inside a square with a sequence of uniform random vectors,A disc inside a square with a sequence of uniform random vectors,,"I passed my probability exam this morning, there was a question that I didn't solve it completely! I have been thinking about it for two hours after the exam but I don't know how it could be solved. Consider: $*$ A square $S = [0,1] \times [0,1]$ $*$ A disc $D$ of radius $1/2$ , centered in $(1/2,1/2)$ . $*$ A sequence $X_1, \dots, X_n, \dots$ of a random vector of $\mathbb{R}^2$ independent and identical from the uniform distribution in the square $S$ . Clarify how it is possible to approximate $\pi$ using the the number of points $X_n$ fall inside the disc $D$ , then use the central limit theorem to calculate the minimum number of samples needed so that the probability of deviating from $\pi$ by more than $0.01$ is less than $0.1 \%$ The only thing I wrote: ""We are using here the Box-Muller method for sampling"" but I don't know how this could be helpful for approximating $\pi$ .","I passed my probability exam this morning, there was a question that I didn't solve it completely! I have been thinking about it for two hours after the exam but I don't know how it could be solved. Consider: A square A disc of radius , centered in . A sequence of a random vector of independent and identical from the uniform distribution in the square . Clarify how it is possible to approximate using the the number of points fall inside the disc , then use the central limit theorem to calculate the minimum number of samples needed so that the probability of deviating from by more than is less than The only thing I wrote: ""We are using here the Box-Muller method for sampling"" but I don't know how this could be helpful for approximating .","* S = [0,1] \times [0,1] * D 1/2 (1/2,1/2) * X_1, \dots, X_n, \dots \mathbb{R}^2 S \pi X_n D \pi 0.01 0.1 \% \pi","['probability', 'probability-theory', 'uniform-distribution']"
40,Find the Conditional Expectation in this case,Find the Conditional Expectation in this case,,"Suppose that the joint density for two random variables is given by $$ f(x,y) =  \frac{e^{-\frac{x}{y}} e^{-y}}{y} $$ where $x,y \in (0, \infty)^2$ . Find the $E(X|Y=y),~$ $\forall y > 0$ . My solution: I would like to find it using the conditional density so I started as $E(X|Y=y) = \int_0^{\infty} y~ f_{X|Y=y}(x,y)dy$ Then, I found the conditional density $f_{X|Y}(x | y)$ for $X$ given that $Y = y,~  \forall y > 0$ . Using the definition, $f_{X|Y}(x | y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}$ . First to find the marginal of $Y$ from the joint as $$f_Y(y)= \int_0^{\infty} \frac{e^{-\frac{x}{y}} e^{-y}}{y} dx = e^{-y}. $$ Following, $$f_{X|Y}(x | y) = \frac{f_{X,Y}(x,y)}{f_Y(y)} = \frac{\frac{e^{-\frac{x}{y}} e^{-y}}{y}}{e^{-y}} = \frac{e^{-\frac{x}{y}} }{y}$$ Finally, $E(X|Y=y) = \int_0^{\infty} y~ f_{X|Y=y}(x,y)dy = \int_0^{\infty} y \frac{e^{-\frac{x}{y}} }{y} dy $ but the integral doesn't converge. What is wrong in my solution? EDIT: I think I did a mistake here $E(X|Y=y) = \int_0^{\infty} y~ f_{X|Y=y}(x,y)dy$ and the it should be as $E(X|Y=y) = \int_0^{\infty} x~ f_{X|Y=y}(x,y)dx = \int_0^{\infty} x \frac{e^{-\frac{x}{y}} }{y} dx = y$ Is this true? Also what is the difference between $E(X/Y)$ and $E(X/Y=y)$ or $f_{X,Y}(x,y)$ and $f_{X,Y=y}(x,y)$ ? thanks for help","Suppose that the joint density for two random variables is given by where . Find the . My solution: I would like to find it using the conditional density so I started as Then, I found the conditional density for given that . Using the definition, . First to find the marginal of from the joint as Following, Finally, but the integral doesn't converge. What is wrong in my solution? EDIT: I think I did a mistake here and the it should be as Is this true? Also what is the difference between and or and ? thanks for help"," f(x,y) =  \frac{e^{-\frac{x}{y}} e^{-y}}{y}  x,y \in (0, \infty)^2 E(X|Y=y),~ \forall y > 0 E(X|Y=y) = \int_0^{\infty} y~ f_{X|Y=y}(x,y)dy f_{X|Y}(x | y) X Y = y,~  \forall y > 0 f_{X|Y}(x | y) = \frac{f_{X,Y}(x,y)}{f_Y(y)} Y f_Y(y)= \int_0^{\infty} \frac{e^{-\frac{x}{y}} e^{-y}}{y} dx = e^{-y}.  f_{X|Y}(x | y) = \frac{f_{X,Y}(x,y)}{f_Y(y)} = \frac{\frac{e^{-\frac{x}{y}} e^{-y}}{y}}{e^{-y}} = \frac{e^{-\frac{x}{y}} }{y} E(X|Y=y) = \int_0^{\infty} y~ f_{X|Y=y}(x,y)dy = \int_0^{\infty} y \frac{e^{-\frac{x}{y}} }{y} dy  E(X|Y=y) = \int_0^{\infty} y~ f_{X|Y=y}(x,y)dy E(X|Y=y) = \int_0^{\infty} x~ f_{X|Y=y}(x,y)dx = \int_0^{\infty} x \frac{e^{-\frac{x}{y}} }{y} dx = y E(X/Y) E(X/Y=y) f_{X,Y}(x,y) f_{X,Y=y}(x,y)","['probability', 'probability-distributions', 'conditional-expectation', 'expected-value']"
41,Finding Probability that Maximum Value of $N + 1$ Random Variables is Larger than a Given Limit,Finding Probability that Maximum Value of  Random Variables is Larger than a Given Limit,N + 1,"For positive random variables $X_{0}, X_{1}, X_{2}, \ldots, X_{N}$ , where $N$ is also a random variable, we know that $X_{1}, X_{2}, \ldots, X_{N - 1}$ are I.I.D. with continuous PDF $f(x)$ and $X_{0} + X_{1} + X_{2} + \ldots + X_{N} = 1$ . What is $P(\max_{i = 0} ^ {N} X_{i} \le d)$ , for a given $d$ ? If an exact solution is not possible, can one find bounds for this probability? Can this problem be solved if $f(x)$ is some well-known distribution (say exponential, log-normal, etc.)? EDIT. An equivalent problem is this: a number of points lie in the interval $[0, 1]$ . If we know that the length of segments between each two consecutive points are I.I.D random variables with PDF $f(x)$ (this does NOT include the distance between $0$ and the first point, or $1$ and the last point), what is the probability that there is no opening larger than $d$ in this interval? $d$ is a given and fixed parameter. EDIT2. A related problem may be this: for a 1-D point process spanning $\mathbb{R}$ where interarrival times are I.I.D. random variables with PDF $f(x)$ , what is the probability of observing an opening bigger that a given value $d$ in the interval $[0, 1]$ ? The spaces between $0$ and the first point falling in the interval and $1$ and the last point falling in the interval count as well. For example, if for some realization there is only one point in the interval $[0, 1]$ at $\frac{1}{2}$ , there are two openings in this interval and both have a length of $0.5$ . If for some other realization there are no points in the interval $[0, 1]$ , there is only one opening in this interval and it has a length of $1$ . Hope this edit clears up the confusion and does not add to it.","For positive random variables , where is also a random variable, we know that are I.I.D. with continuous PDF and . What is , for a given ? If an exact solution is not possible, can one find bounds for this probability? Can this problem be solved if is some well-known distribution (say exponential, log-normal, etc.)? EDIT. An equivalent problem is this: a number of points lie in the interval . If we know that the length of segments between each two consecutive points are I.I.D random variables with PDF (this does NOT include the distance between and the first point, or and the last point), what is the probability that there is no opening larger than in this interval? is a given and fixed parameter. EDIT2. A related problem may be this: for a 1-D point process spanning where interarrival times are I.I.D. random variables with PDF , what is the probability of observing an opening bigger that a given value in the interval ? The spaces between and the first point falling in the interval and and the last point falling in the interval count as well. For example, if for some realization there is only one point in the interval at , there are two openings in this interval and both have a length of . If for some other realization there are no points in the interval , there is only one opening in this interval and it has a length of . Hope this edit clears up the confusion and does not add to it.","X_{0}, X_{1}, X_{2}, \ldots, X_{N} N X_{1}, X_{2}, \ldots, X_{N - 1} f(x) X_{0} + X_{1} + X_{2} + \ldots + X_{N} = 1 P(\max_{i = 0} ^ {N} X_{i} \le d) d f(x) [0, 1] f(x) 0 1 d d \mathbb{R} f(x) d [0, 1] 0 1 [0, 1] \frac{1}{2} 0.5 [0, 1] 1","['probability', 'probability-theory', 'probability-distributions']"
42,Random Walk $\mathbb P(T_0>n $ and $S_n=a) = \mathbb P(T_a=n) =\frac{a}{n} \mathbb P(S_n=a)$,Random Walk  and,\mathbb P(T_0>n  S_n=a) = \mathbb P(T_a=n) =\frac{a}{n} \mathbb P(S_n=a),"Consider the random Walk $S_n$ on $\mathbb Z$ starting in $x=0$ . Let $a\in \mathbb Z$ . Define $T_a(\omega)=\min\{n\in \mathbb N : S_n(\omega)=a\}$ . Show for $a> 0$ $\mathbb P(T_0>n $ and $S_n=a) = \mathbb P(T_a=n) =\frac{a}{n} \mathbb P(S_n=a)$ I tried looking the different possible paths that lead to the different outcomes i.e. $T_0>n $ and $S_n=a$ or $T_a=n$ and it seems reasonable but in no way am I able to rigorously proof this.  I am sorry if this is something very basic to show but when I googled ""random walk"" or similar terms I only found more complicated models and nothing similar to this particular statement.","Consider the random Walk on starting in . Let . Define . Show for and I tried looking the different possible paths that lead to the different outcomes i.e. and or and it seems reasonable but in no way am I able to rigorously proof this.  I am sorry if this is something very basic to show but when I googled ""random walk"" or similar terms I only found more complicated models and nothing similar to this particular statement.",S_n \mathbb Z x=0 a\in \mathbb Z T_a(\omega)=\min\{n\in \mathbb N : S_n(\omega)=a\} a> 0 \mathbb P(T_0>n  S_n=a) = \mathbb P(T_a=n) =\frac{a}{n} \mathbb P(S_n=a) T_0>n  S_n=a T_a=n,"['probability', 'probability-theory', 'random-walk']"
43,"Let $X,Y,X_1,X_2,\ldots$ be i.i.d. and $\phi(x,y)$ a test function. Does $\frac{1}{N^2}\sum_{i,j}\phi(X_i,X_j)\to\mathbb E\phi(X,Y)$ a.s.?",Let  be i.i.d. and  a test function. Does  a.s.?,"X,Y,X_1,X_2,\ldots \phi(x,y) \frac{1}{N^2}\sum_{i,j}\phi(X_i,X_j)\to\mathbb E\phi(X,Y)","Suppose we are given a distribution $\mu$ on $\mathbb R^d$ , and a smooth function $\phi:\mathbb R^d\times\mathbb R^d\to\mathbb R$ with compact support. Let $X_i$ be i.i.d. random variables with distribution $\mu$ . Then is it the case that $$ \frac{1}{N^2}\sum_{i,j=1}^N\phi(X_i,X_j)\to\int_{\mathbb R^d\times\mathbb R^d}\!\phi(x,y)\,\mathrm d\mu(x)\,\mathrm d\mu(y)? $$ For single-variable $\phi$ , this is just the strong law of large numbers, but I don't quite see how to prove it here.","Suppose we are given a distribution on , and a smooth function with compact support. Let be i.i.d. random variables with distribution . Then is it the case that For single-variable , this is just the strong law of large numbers, but I don't quite see how to prove it here.","\mu \mathbb R^d \phi:\mathbb R^d\times\mathbb R^d\to\mathbb R X_i \mu 
\frac{1}{N^2}\sum_{i,j=1}^N\phi(X_i,X_j)\to\int_{\mathbb R^d\times\mathbb R^d}\!\phi(x,y)\,\mathrm d\mu(x)\,\mathrm d\mu(y)?
 \phi","['probability', 'probability-theory']"
44,How to derive the upper bound for the expected number and maximal number of marked vertices in a graph?,How to derive the upper bound for the expected number and maximal number of marked vertices in a graph?,,"Assume we have a graph $G = (V, E)$ with minimal degree $m$ . We mark with a probability (independent from the other vertices) of $p$ each vertex. After that we mark each vertex $v$ iff the vertex $v$ and their neighbors are not marked. So there is a upper bound for the expected value for the number of marked vertices given: $$|V|\left(p + e^{−p(m+1)}\right)$$ And there is also a formula given for the maximal number of marked vertices: $$|V| \frac{1+\ln(m+1)}{m+1}$$ I don't understand how to derive these.",Assume we have a graph with minimal degree . We mark with a probability (independent from the other vertices) of each vertex. After that we mark each vertex iff the vertex and their neighbors are not marked. So there is a upper bound for the expected value for the number of marked vertices given: And there is also a formula given for the maximal number of marked vertices: I don't understand how to derive these.,"G = (V, E) m p v v |V|\left(p + e^{−p(m+1)}\right) |V| \frac{1+\ln(m+1)}{m+1}","['probability', 'graph-theory', 'probabilistic-method']"
45,Existence of functionals on $L^0$,Existence of functionals on,L^0,"Studying a paper about risk measures by F. Delbaen, I bumped into this statement: Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space: if $\mathbb{P}$ is atomless, then there exists no functional $\rho:L^0\to\mathbb{R}$ such that: $\rho(X+a)=\rho(X)-a \quad \forall a \in \mathbb{R},$ $\rho(X+Y)\le \rho(X)+\rho(Y),$ $\rho(\lambda X)=\lambda\rho(X), \quad \forall \lambda>0,$ $X\ge 0 \implies \rho(X)\le 0,$ for every $X\in L^0.$ Here we denote by $L^0$ the linear space of all random variables on $\Omega$ with the metric of the convergence in probability. Then the author assesses that this is a consequence of the analytic Hahn-Banach theorem and of the fact that a continuous functional on $L^0$ must be necessarily null if $\mathbb{P}$ is atomless. Now, I'm full of doubts: first of all I didn't know the statement about the linear functionals on the $L^0$ space: could you give me some reference where to read about it? I tried to google something but didn't find anything. Secondly I didn't really undestand how to use in a clever way the Hahn-Banach theorem: this risk functionals were previously introduced on the space $L^\infty,$ where it is easy to check that they are continuous (wrt to $\|\cdot\|_\infty$ ), so I thought it was natural to use $L^\infty$ as subspace where to use Hahn-Banach, but I don't know which linear functional on $L^\infty$ I shoul use to be sure that it will be continuous on $L^0$ when extended. Any help would be a lot appreciated. Thanks to everybody.","Studying a paper about risk measures by F. Delbaen, I bumped into this statement: Let be a probability space: if is atomless, then there exists no functional such that: for every Here we denote by the linear space of all random variables on with the metric of the convergence in probability. Then the author assesses that this is a consequence of the analytic Hahn-Banach theorem and of the fact that a continuous functional on must be necessarily null if is atomless. Now, I'm full of doubts: first of all I didn't know the statement about the linear functionals on the space: could you give me some reference where to read about it? I tried to google something but didn't find anything. Secondly I didn't really undestand how to use in a clever way the Hahn-Banach theorem: this risk functionals were previously introduced on the space where it is easy to check that they are continuous (wrt to ), so I thought it was natural to use as subspace where to use Hahn-Banach, but I don't know which linear functional on I shoul use to be sure that it will be continuous on when extended. Any help would be a lot appreciated. Thanks to everybody.","(\Omega,\mathcal{F},\mathbb{P}) \mathbb{P} \rho:L^0\to\mathbb{R} \rho(X+a)=\rho(X)-a \quad \forall a \in \mathbb{R}, \rho(X+Y)\le \rho(X)+\rho(Y), \rho(\lambda X)=\lambda\rho(X), \quad \forall \lambda>0, X\ge 0 \implies \rho(X)\le 0, X\in L^0. L^0 \Omega L^0 \mathbb{P} L^0 L^\infty, \|\cdot\|_\infty L^\infty L^\infty L^0","['probability', 'functional-analysis', 'measure-theory', 'lp-spaces', 'risk-assessment']"
46,Birthday Problem without using complement,Birthday Problem without using complement,,"I have a solution to the birthday problem without using complements that is arriving at the wrong answer. I'd like to understand what I am doing wrong. I am not looking for alternate solutions to the problem. Problem Assuming there are only 365 days (ignore leap year), and each day is equally likely to be a birthday, what is the probability that at least 2 people have the same birthday in a room of N people? Sample Space: $365^N$ Event Space ${N\choose 2 }$ pairings for people with the same birthday for each pair, $365$ possible birthdays for remaining $N-2$ people, $365^{(N-2)}$ permutations which we can basically ignore (but still must be counted since they are part of the event space) So I would expect the answer to be: $$\frac{{N\choose 2 } * 365 * 365^{(N-2)}}{365^N} = \frac{{N\choose 2 }}{365}$$ With $N=23$ , I get 69% chance of $2$ people having same birthday, but correct answer is ~50%. So where am I over-counting?","I have a solution to the birthday problem without using complements that is arriving at the wrong answer. I'd like to understand what I am doing wrong. I am not looking for alternate solutions to the problem. Problem Assuming there are only 365 days (ignore leap year), and each day is equally likely to be a birthday, what is the probability that at least 2 people have the same birthday in a room of N people? Sample Space: Event Space pairings for people with the same birthday for each pair, possible birthdays for remaining people, permutations which we can basically ignore (but still must be counted since they are part of the event space) So I would expect the answer to be: With , I get 69% chance of people having same birthday, but correct answer is ~50%. So where am I over-counting?",365^N {N\choose 2 } 365 N-2 365^{(N-2)} \frac{{N\choose 2 } * 365 * 365^{(N-2)}}{365^N} = \frac{{N\choose 2 }}{365} N=23 2,['probability']
47,"If I flip a coin $100$ times, what is the probability that I have a stretch of $30$ coinflips where at least $20$ are heads?","If I flip a coin  times, what is the probability that I have a stretch of  coinflips where at least  are heads?",100 30 20,"CONTEXT: Was wondering if I play $100$ games, how likely is it that I will have a stretch of $30$ games where I think I'm good because I have a $67\%$ winrate but I actually just have a $50\%$ winrate (and am getting lucky). I've done calculations to find out the odds of an individual stretch of $30$ coinflips having at least $20$ heads is roughly $5\%$ ( $0.04937$ ). My initial guess was that you can fit $70$ stretches of $30$ inside of $100$ coinflips, so you could do $1-0.95^{70} = 97\%$ . But this is wrong because overlapping stretches of $30$ have linked probabilities (i.e. if coinflips $1$ - $30$ have $30\%$ heads, it is impossible for coinflips $5$ - $35$ to have $67\%$ heads). If anyone is aware of a general formula for this (for this example $N=100$ , $n=30$ , $x=20$ , $p_i=0.5$ ), that would be great. Thanks.","CONTEXT: Was wondering if I play games, how likely is it that I will have a stretch of games where I think I'm good because I have a winrate but I actually just have a winrate (and am getting lucky). I've done calculations to find out the odds of an individual stretch of coinflips having at least heads is roughly ( ). My initial guess was that you can fit stretches of inside of coinflips, so you could do . But this is wrong because overlapping stretches of have linked probabilities (i.e. if coinflips - have heads, it is impossible for coinflips - to have heads). If anyone is aware of a general formula for this (for this example , , , ), that would be great. Thanks.",100 30 67\% 50\% 30 20 5\% 0.04937 70 30 100 1-0.95^{70} = 97\% 30 1 30 30\% 5 35 67\% N=100 n=30 x=20 p_i=0.5,"['probability', 'statistics']"
48,"Distribution of minimum of difference between uniforms $(0,1)$",Distribution of minimum of difference between uniforms,"(0,1)","Let $U_1,...,U_N$ be a sequence of independent uniformly $(0,1)$ random variables. Define $Y_k := U_k - U_{k+1}$ . Find the distribution of $\min\left\{Y_k\right\}_{k=1}^{N-1}$ . I've get the distribution of $U_k - U_{k+1}$ , but I wasn't able to get the distribution of minimum. Any ideas?","Let be a sequence of independent uniformly random variables. Define . Find the distribution of . I've get the distribution of , but I wasn't able to get the distribution of minimum. Any ideas?","U_1,...,U_N (0,1) Y_k := U_k - U_{k+1} \min\left\{Y_k\right\}_{k=1}^{N-1} U_k - U_{k+1}","['probability', 'probability-theory', 'probability-distributions', 'uniform-distribution']"
49,What is the optimal way to take $16$ question true/false test with four attempts?,What is the optimal way to take  question true/false test with four attempts?,16,"Question: Suppose a student is taking a $16$ -question true/false test with four attempts. They must keep the store that they obtain after the fourth trial. He or she does not know the answer to any question. After the test is completed, the grader tells you how many you got correct but not which ones. What's the best way to maximize the expected value of the fourth attempt? My thoughts: So, to clarify the question, one way to make the expected value equal to $9.5$ is as follows: Attempt 1: Answer question $1$ and leave the rest blank. If the grader tells you that you got $1$ right, you know the answer to question $1$ with certainty. If the grader tells you that you got $0$ correct, then you still know the question to $1$ with certainty (if you put true, then it will be false). Attempt 2: Repeat with question 2. Attempt 3: Repeat with question 3. So, we're guaranteed three questions right, and the expected value for attempt four is $3 + \sum_{i=1}^{13}1 \cdot 1/2 = 3 + 6.5 = 9.5$ . So we're expected to get $9.5$ right. Another thing that someone could do is answer ""TRUE"" for every question on attempt $1$ . That'll tell you how many true/false questions there are in total. Then, on the second attempt, leave the second half of the test blank, and answer TRUE for everything in the first half. This is sort of like a binary search. It tells you how many are true in the first half, and in the first quarter, etc. I didn't get anywhere with this. Is my solution of an expected value of $9.5$ the most optimal solution? What if there were $3$ attempts instead of $4$ ?","Question: Suppose a student is taking a -question true/false test with four attempts. They must keep the store that they obtain after the fourth trial. He or she does not know the answer to any question. After the test is completed, the grader tells you how many you got correct but not which ones. What's the best way to maximize the expected value of the fourth attempt? My thoughts: So, to clarify the question, one way to make the expected value equal to is as follows: Attempt 1: Answer question and leave the rest blank. If the grader tells you that you got right, you know the answer to question with certainty. If the grader tells you that you got correct, then you still know the question to with certainty (if you put true, then it will be false). Attempt 2: Repeat with question 2. Attempt 3: Repeat with question 3. So, we're guaranteed three questions right, and the expected value for attempt four is . So we're expected to get right. Another thing that someone could do is answer ""TRUE"" for every question on attempt . That'll tell you how many true/false questions there are in total. Then, on the second attempt, leave the second half of the test blank, and answer TRUE for everything in the first half. This is sort of like a binary search. It tells you how many are true in the first half, and in the first quarter, etc. I didn't get anywhere with this. Is my solution of an expected value of the most optimal solution? What if there were attempts instead of ?",16 9.5 1 1 1 0 1 3 + \sum_{i=1}^{13}1 \cdot 1/2 = 3 + 6.5 = 9.5 9.5 1 9.5 3 4,['probability']
50,How is convolving Haar measure with itself over subsets enough to define subgroups?,How is convolving Haar measure with itself over subsets enough to define subgroups?,,"In this post , Terry Tao says that Gaussians are ""a subgroup of $\Bbb R$"". When you convolve Haar probability measure on a (compact) subgroup with itself, you get back the same measure, and this can in fact be used as a definition of such subgroups. If you convolve a Gaussian probability measure with itself, you almost get back the same Gaussian measure, but it has spread out by a factor of $\sqrt 2$. So Gaussians are in some sense a ""$\sqrt 2$-approximate group"". I don't understand this comment, or how it means that Gaussians can be viewed as a subgroup of $\Bbb R$. How can you define subgroups through this? Perhaps this? A subset, $H$ of a group $G$ with Haar measure $\mu$ is called a subgroup if $\mu |_H=\mu\ast\mu|_H$. How does this show that a Gaussian is a subgroup of $\Bbb R$?","In this post , Terry Tao says that Gaussians are ""a subgroup of $\Bbb R$"". When you convolve Haar probability measure on a (compact) subgroup with itself, you get back the same measure, and this can in fact be used as a definition of such subgroups. If you convolve a Gaussian probability measure with itself, you almost get back the same Gaussian measure, but it has spread out by a factor of $\sqrt 2$. So Gaussians are in some sense a ""$\sqrt 2$-approximate group"". I don't understand this comment, or how it means that Gaussians can be viewed as a subgroup of $\Bbb R$. How can you define subgroups through this? Perhaps this? A subset, $H$ of a group $G$ with Haar measure $\mu$ is called a subgroup if $\mu |_H=\mu\ast\mu|_H$. How does this show that a Gaussian is a subgroup of $\Bbb R$?",,['probability']
51,Probability of an unordered sample under weighted sampling without replacement,Probability of an unordered sample under weighted sampling without replacement,,"Imagine the following situation: An urn contains $K$ balls of different colours $\mathcal{U}=\{1,\ldots,K\}$, and with different weights $\mathbf{w}=(w_1,\ldots,w_K)$ (where $\sum_i w_i = 1$). You draw from the urn $m \leq K$ times without replacement, with probability of selecting each of the (remaining) balls proportional to their weight, and observed a sample $\mathcal{K} \subset \mathcal{U}$, $|\mathcal{K}|=m$. I want to compute the probability of such a (unordered) sample $\mathcal{K}$. For a particular ordered tuple $\mathbf{k}=(k_1,\ldots,k_m)$ of draws from the urn, the total remaining weight after $i$ draws is $1-w_{k_1}-\ldots-w_{k_i}$, and it follows that $$   \mathbb{P}(\mathbf{k}) = \frac{w_{k_1}}{1}\frac{w_{k_2}}{1-w_{k_1}}\cdots\frac{w_{k_m}}{1-w_{k_1}-\ldots-w_{k_{m-1}}}. $$ For an unordered sample $\mathcal{K}=\{k_1,\ldots,k_m\}$, we must sum over all possible permutations $S_m$ of the elements of $\mathcal{K}$, and the probability of observation is therefore $$    \mathbb{P}(\mathcal{K}) = \sum_{\pi\in S_m} \prod_{i=1}^{m} \frac{w_{k_{\pi(i)}}}{1-w_{k_{\pi(1)}}-\ldots-w_{k_{\pi(i-1)}}}, $$ which can be (slightly) simplified to $$    \mathbb{P}(\mathcal{K}) = w_{k_1}\cdots w_{k_m}\sum_{\pi\in S_m}\Bigg(\prod_{i=1}^{m-1} \big(1-w_{k_{\pi(1)}}-\ldots-w_{k_{\pi(i)}}\big)\Bigg)^{-1}. $$ The last expression is, unfortunately, still computationally intractable even for samples containing about 100 elements -- yet I'd need this for samples of tens of thousands elements, selected from millions of colours initially present in the urn. Yet this is were I'm stuck : I can't see how to simplify this further. Thus my question(s): Does anyone have an idea how to simply the denominator and/or how to replace it by an approximation? Or can anyone point me at literature that deals with such a situation? My eventual goal is to estimate the weights $\mathbf{w}$ from many such (independently taken) samples $\mathcal{K}_1,\ldots,\mathcal{K}_N$ which different sizes $|\mathcal{K}_1|$, $\ldots$, $|\mathcal{K}_N|$, either by a ML or (preferrably) a Bayesian approach.","Imagine the following situation: An urn contains $K$ balls of different colours $\mathcal{U}=\{1,\ldots,K\}$, and with different weights $\mathbf{w}=(w_1,\ldots,w_K)$ (where $\sum_i w_i = 1$). You draw from the urn $m \leq K$ times without replacement, with probability of selecting each of the (remaining) balls proportional to their weight, and observed a sample $\mathcal{K} \subset \mathcal{U}$, $|\mathcal{K}|=m$. I want to compute the probability of such a (unordered) sample $\mathcal{K}$. For a particular ordered tuple $\mathbf{k}=(k_1,\ldots,k_m)$ of draws from the urn, the total remaining weight after $i$ draws is $1-w_{k_1}-\ldots-w_{k_i}$, and it follows that $$   \mathbb{P}(\mathbf{k}) = \frac{w_{k_1}}{1}\frac{w_{k_2}}{1-w_{k_1}}\cdots\frac{w_{k_m}}{1-w_{k_1}-\ldots-w_{k_{m-1}}}. $$ For an unordered sample $\mathcal{K}=\{k_1,\ldots,k_m\}$, we must sum over all possible permutations $S_m$ of the elements of $\mathcal{K}$, and the probability of observation is therefore $$    \mathbb{P}(\mathcal{K}) = \sum_{\pi\in S_m} \prod_{i=1}^{m} \frac{w_{k_{\pi(i)}}}{1-w_{k_{\pi(1)}}-\ldots-w_{k_{\pi(i-1)}}}, $$ which can be (slightly) simplified to $$    \mathbb{P}(\mathcal{K}) = w_{k_1}\cdots w_{k_m}\sum_{\pi\in S_m}\Bigg(\prod_{i=1}^{m-1} \big(1-w_{k_{\pi(1)}}-\ldots-w_{k_{\pi(i)}}\big)\Bigg)^{-1}. $$ The last expression is, unfortunately, still computationally intractable even for samples containing about 100 elements -- yet I'd need this for samples of tens of thousands elements, selected from millions of colours initially present in the urn. Yet this is were I'm stuck : I can't see how to simplify this further. Thus my question(s): Does anyone have an idea how to simply the denominator and/or how to replace it by an approximation? Or can anyone point me at literature that deals with such a situation? My eventual goal is to estimate the weights $\mathbf{w}$ from many such (independently taken) samples $\mathcal{K}_1,\ldots,\mathcal{K}_N$ which different sizes $|\mathcal{K}_1|$, $\ldots$, $|\mathcal{K}_N|$, either by a ML or (preferrably) a Bayesian approach.",,"['probability', 'combinatorics', 'bayesian', 'sampling', 'maximum-likelihood']"
52,"Does there exist some probability space $(\Omega,\mathcal F,\mathbb P)$ that admits random variables with all possible laws on $\mathbb R^n$?",Does there exist some probability space  that admits random variables with all possible laws on ?,"(\Omega,\mathcal F,\mathbb P) \mathbb R^n","I have a question about a statement which intuitively seems like it should be a canonical fact, but which I cannot find in any common textbook on probability. Namely, does there exist a probability space $(\Omega,\mathcal F,\mathbb P)$ such that for any probability measure $\mu$ on $\mathbb R^d$, there exists a random variable $X:\Omega\to\mathbb R^d$ such that $X$ has law $\mu$, i.e. $X_\#\mathbb P=\mu$? Can we do this on a single probability space as $d$ ranges over the natural numbers? I suspect that the space $$([0,1]^\omega,\mathcal B_{[0,1]}^{\otimes\omega},\mathcal L^\omega)$$ should do the trick, where $\mathcal L$ is the Lebesgue measure on $[0,1]$, which I see can simply reduce to proving that $$([0,1]^d,\mathcal B_{[0,1]}^{\otimes d},\mathcal L^d)$$ works for $\mathbb R^d$, but the details of this last part are a bit beyond me.","I have a question about a statement which intuitively seems like it should be a canonical fact, but which I cannot find in any common textbook on probability. Namely, does there exist a probability space $(\Omega,\mathcal F,\mathbb P)$ such that for any probability measure $\mu$ on $\mathbb R^d$, there exists a random variable $X:\Omega\to\mathbb R^d$ such that $X$ has law $\mu$, i.e. $X_\#\mathbb P=\mu$? Can we do this on a single probability space as $d$ ranges over the natural numbers? I suspect that the space $$([0,1]^\omega,\mathcal B_{[0,1]}^{\otimes\omega},\mathcal L^\omega)$$ should do the trick, where $\mathcal L$ is the Lebesgue measure on $[0,1]$, which I see can simply reduce to proving that $$([0,1]^d,\mathcal B_{[0,1]}^{\otimes d},\mathcal L^d)$$ works for $\mathbb R^d$, but the details of this last part are a bit beyond me.",,"['probability', 'probability-theory']"
53,"(Poisson limit theorem) Random variable $X_n$ ~ Bin$(n,p_n)$ convergences to $Z$ ~ Poisson($\lambda$)",(Poisson limit theorem) Random variable  ~ Bin convergences to  ~ Poisson(),"X_n (n,p_n) Z \lambda","$(\star)$ : Let $ X_n $ ~ Bin( $n,p_n$ )  ( $ n \in \mathbb{N} $ ) $ n \cdot p_n  \rightarrow \lambda $ for $ n \rightarrow \infty $ . Then $ X_n$ convergences to Poisson $Z$ ~ Poisson( $\lambda$ ). I have to use the following steps : a) First of all solve this exercise for $ n \cdot p_n = \lambda $ $ \forall n \in \mathbb{N}$ . b) Let $[A,B]$ be a bounded interval.  Show $ \forall k \in \mathbb{N}$ $ \forall a,b  \in [A,B]$ : $| a^k - b^k | = | \int_{min(a,b)}^{max(a,b)} k \cdot x^{k-1} dx | \le k \cdot| a-b| \cdot $ max{ |A|,|B| } $^{k-1}$ c) Let $[A,B]$ be a bounded interval. Show there is a $D > 0 $ , such that $\forall a,b \in [A,B]$ $ \forall n \in \mathbb{N} $ : | $(1+\frac{a}{n})^n - (1+\frac{b}{n})^n | \le D|a-b| $ . d) Now proof  ( $\star$ ). Attempt : a) $n \cdot p_n  = \lambda  \Rightarrow  p_n = \frac{\lambda}{n}$ . So: $\lim_{n \rightarrow \infty} P(X_n = k) = \lim_{n \rightarrow \infty} \binom{n}{k} p_n^k(1-p_n)^{n-k} =$ $\lim_{n \rightarrow \infty} \binom{n}{k} (\frac{\lambda}{n})^k(1-\frac{\lambda}{n})^{n-k} = \frac{\lambda^k}{k!} \lim_{n \rightarrow \infty} \frac{n}{n} \frac{n-1}{n} ... \frac{n-k+1}{n}(1-\frac{\lambda}{n})^n \frac{1}{(1-\frac{\lambda}{n})^k} = \frac{\lambda^k}{k!} \cdot 1\cdot e^{-\lambda} \cdot 1 = e^{-\lambda} \frac{\lambda^k}{k!}  $ . b) Without loss of generality: $ a \le b$ . $| \int_{min(a,b)}^{max(a,b)} k \cdot x^{k-1} dx |  = | \int_{a}^{b} k \cdot x^{k-1} dx | = | x^k|_{a}^{b} | = |b^k -a^k| = |a^k - b^k| $ . second part: for $a = b$ we have $ 0 \le 0 $ and for $ a < b $ we use the mean-value theorem: $\frac{|a^k - b^k|}{|a-b|} = k \cdot |c|^{k-1} \le k \cdot  $ max{|A|,|B|} $^{k-1}$ because $c \in (a,b) \subset [A,B]$ . c) Again the mean-value theorem? $| \frac{(1+\frac{a}{n})^n - (1+\frac{b}{n})^n}{a-b} | = |(1+\frac{c}{n})^{n-1}| $ but why is this $ \le D $ ? I know that $c \in (a,b) $ . d) So now I have to show  that for random variables $X_n$ ~ Bin $(n,p_n)$ with $n \cdot p_n \rightarrow \lambda$ for $ n \rightarrow \infty $ $\Rightarrow $ $X_n $ convergences to $Z$ ~ Poisson( $\lambda$ ). Here is my problem. Unfortunately I don't know how I can use a), b) and c) for this exercise. I hope that your answer can help me. Important remark : It is allowed to use: Let $X_n$ be random variables with values in $\mathbb{N_0}$ . If the sequence of functions $g_n(t) := g_{X_n}(t)$ convergences pointwise to $g(t)$ on a open interval $I$ with $0 \in I $ , then $\exists$ a random variable $X$ with $g(t) = g_X(t) $ and $ \lim_{ n \rightarrow \infty } P (X_n = k) = P(X=k)$ $ \forall k \in \mathbb{N_0}$ .",": Let ~ Bin( )  ( ) for . Then convergences to Poisson ~ Poisson( ). I have to use the following steps : a) First of all solve this exercise for . b) Let be a bounded interval.  Show : max{ |A|,|B| } c) Let be a bounded interval. Show there is a , such that : | . d) Now proof  ( ). Attempt : a) . So: . b) Without loss of generality: . . second part: for we have and for we use the mean-value theorem: max{|A|,|B|} because . c) Again the mean-value theorem? but why is this ? I know that . d) So now I have to show  that for random variables ~ Bin with for convergences to ~ Poisson( ). Here is my problem. Unfortunately I don't know how I can use a), b) and c) for this exercise. I hope that your answer can help me. Important remark : It is allowed to use: Let be random variables with values in . If the sequence of functions convergences pointwise to on a open interval with , then a random variable with and .","(\star)  X_n  n,p_n  n \in \mathbb{N}   n \cdot p_n  \rightarrow \lambda   n \rightarrow \infty   X_n Z \lambda  n \cdot p_n = \lambda   \forall n \in \mathbb{N} [A,B]  \forall k \in \mathbb{N}  \forall a,b  \in [A,B] | a^k - b^k | = | \int_{min(a,b)}^{max(a,b)} k \cdot x^{k-1} dx | \le k \cdot| a-b| \cdot  ^{k-1} [A,B] D > 0  \forall a,b \in [A,B]  \forall n \in \mathbb{N}  (1+\frac{a}{n})^n - (1+\frac{b}{n})^n | \le D|a-b|  \star n \cdot p_n  = \lambda  \Rightarrow  p_n = \frac{\lambda}{n} \lim_{n \rightarrow \infty} P(X_n = k) = \lim_{n \rightarrow \infty} \binom{n}{k} p_n^k(1-p_n)^{n-k} = \lim_{n \rightarrow \infty} \binom{n}{k} (\frac{\lambda}{n})^k(1-\frac{\lambda}{n})^{n-k} = \frac{\lambda^k}{k!} \lim_{n \rightarrow \infty} \frac{n}{n} \frac{n-1}{n} ... \frac{n-k+1}{n}(1-\frac{\lambda}{n})^n \frac{1}{(1-\frac{\lambda}{n})^k} = \frac{\lambda^k}{k!} \cdot 1\cdot e^{-\lambda} \cdot 1 = e^{-\lambda} \frac{\lambda^k}{k!}    a \le b | \int_{min(a,b)}^{max(a,b)} k \cdot x^{k-1} dx |  = | \int_{a}^{b} k \cdot x^{k-1} dx | = | x^k|_{a}^{b} | = |b^k -a^k| = |a^k - b^k|  a = b  0 \le 0   a < b  \frac{|a^k - b^k|}{|a-b|} = k \cdot |c|^{k-1} \le k \cdot   ^{k-1} c \in (a,b) \subset [A,B] | \frac{(1+\frac{a}{n})^n - (1+\frac{b}{n})^n}{a-b} | = |(1+\frac{c}{n})^{n-1}|   \le D  c \in (a,b)  X_n (n,p_n) n \cdot p_n \rightarrow \lambda  n \rightarrow \infty  \Rightarrow  X_n  Z \lambda X_n \mathbb{N_0} g_n(t) := g_{X_n}(t) g(t) I 0 \in I  \exists X g(t) = g_X(t)   \lim_{ n \rightarrow \infty } P (X_n = k) = P(X=k)  \forall k \in \mathbb{N_0}","['probability', 'limits', 'random-variables', 'poisson-distribution', 'binomial-distribution']"
54,Coin Toss Game - Flip Until Failure,Coin Toss Game - Flip Until Failure,,"The Problem You start off with $N$ coins. All coins are fair and land heads with probability $p_f=0.5$ , except one weighted coin which lands heads with a weight $p_w$ . When the game starts perform the following steps: Flip each coin in play If no coin flips heads the game ends. Otherwise remove all coins that flipped heads from the game. Flip all the remaining coins. Repeat until no coin flips heads or all coins are removed from the game. Assuming $n\leq N$ coins have been removed from the game, what is the probability that the weighted coin was removed? i.e. $$P(\text{ Weighted Coin Removed from Play } | \text{ } n \text{ Coins Removed }) = \text{???}$$ My Approach Initially my thought was that the game itself isn't really relevant and I can just look at a single trial of the game. We just need to look at the probability of flipping $n$ heads (where one of which is the weighted coin) over the probability of flipping $n$ heads. For example, let's set $N=3$ , $n=2$ , $p_f=0.5$ , and $p_w=0.1$ . Then the probability of flipping two heads where one of which is the weighted coin is $$2p_wp_f(1-p_f) = 2(0.1)(0.5)(1-0.5) = 0.05.$$ And the probability of flipping two heads where one of which ISN'T the weighted coin is $$(1-p_w)p_f^2 = (0.9)(0.5)^2 = 0.225.$$ So I would think the probability of having already removed the weighted coin once two coins are removed is $$\frac{0.05}{0.05+0.225}\approx 0.182$$ But I wrote a sim that says it should be closer $0.166$ , and I'm sure there's something wrong with my approach needs to take into account the game. Not really sure what I'm doing wrong, but I'm pretty sure I need to take into account the possibility of multiple turns of the game somehow.","The Problem You start off with coins. All coins are fair and land heads with probability , except one weighted coin which lands heads with a weight . When the game starts perform the following steps: Flip each coin in play If no coin flips heads the game ends. Otherwise remove all coins that flipped heads from the game. Flip all the remaining coins. Repeat until no coin flips heads or all coins are removed from the game. Assuming coins have been removed from the game, what is the probability that the weighted coin was removed? i.e. My Approach Initially my thought was that the game itself isn't really relevant and I can just look at a single trial of the game. We just need to look at the probability of flipping heads (where one of which is the weighted coin) over the probability of flipping heads. For example, let's set , , , and . Then the probability of flipping two heads where one of which is the weighted coin is And the probability of flipping two heads where one of which ISN'T the weighted coin is So I would think the probability of having already removed the weighted coin once two coins are removed is But I wrote a sim that says it should be closer , and I'm sure there's something wrong with my approach needs to take into account the game. Not really sure what I'm doing wrong, but I'm pretty sure I need to take into account the possibility of multiple turns of the game somehow.",N p_f=0.5 p_w n\leq N P(\text{ Weighted Coin Removed from Play } | \text{ } n \text{ Coins Removed }) = \text{???} n n N=3 n=2 p_f=0.5 p_w=0.1 2p_wp_f(1-p_f) = 2(0.1)(0.5)(1-0.5) = 0.05. (1-p_w)p_f^2 = (0.9)(0.5)^2 = 0.225. \frac{0.05}{0.05+0.225}\approx 0.182 0.166,"['probability', 'combinatorics']"
55,Find the probability that no kid will have his own pair of shoes,Find the probability that no kid will have his own pair of shoes,,"In the morning, $n$ children come to the kindergarten and leave their shoes in the locker room. Leaving the kindergarten one by one, each child takes one left and one right shoe, accidentally equiprobably choosing them from among the remaining ones. Find the likelihood that none of the children will leave in their own pair of shoes. My thoughts: I assume that decisions are independent based on accidentally equiprobably choosing them from among the remaining ones part. Let $I_l$ and $I_r$ be indicator r.v. for choosing his/her left shoe. Let $A$ be the probability that none of the children will leave in their own pair of shoes $$P(I_l=1)=\frac1n; P(I_r=1)=\frac1n$$ Leaving without his/her pair of shoes can occur in several ways: $1$) Choose his/her left shoe and other (not his/her) right shoe $$P(I_l=1)P(I_r=0)=\left(\frac1n\right)^n\left(1-\frac1n\right)^n$$ $2$) Choose his/her right shoe and other (not his/her) left shoe $$P(I_r=1)P(I_l=0)=\left(\frac1n\right)^n\left(1-\frac1n\right)^n$$ $3$) Nobody chose his/her pair of shoes $$P(I_l=0)P(I_r=0)=\left(1-\frac1n\right)^n\left(1-\frac1n\right)^n$$ Therefore, $$P(A)=2\left(\frac1n\right)^n\left(1-\frac1n\right)^n+\left(1-\frac1n\right)^{2n}$$ Here I assume that kids can distinguish between right and left shoes. If they can not: probability of choosing left shoe out of $2n$ shoes: $$P(\text{left})=\frac{n}{\binom{2n}{2}}$$ by symmetry the same for $P(\text{right})$ $1$) Chose two left shoes included his/her: $$(P(\text{left})P(\text{left}))^n=\left(\frac{n}{\binom{2n}{2}}\cdot\frac{n-1}{\binom{2n-1}{2}}\right)^n$$ Power $n$, because there are $n$ people who make this decisions $2$) Chose two right shoes included his/her: $$(P(\text{right})P(\text{right}))^n=\left(\frac{n}{\binom{2n}{2}}\cdot\frac{n-1}{\binom{2n-1}{2}}\right)^n$$ $3$) Choose one left included his/her and one right excluded his/her own: $$P(\text{left})P(\text{right})=\left(\frac{n}{\binom{2n}{2}}\cdot\frac{n-1}{\binom{2n-1}{2}}\right)^n$$ $4$) Choose one right inlcuded his her and one left excluded his/her own $$P(\text{right})P(\text{left})=\left(\frac{n}{\binom{2n}{2}}\cdot\frac{n-1}{\binom{2n-1}{2}}\right)^n$$","In the morning, $n$ children come to the kindergarten and leave their shoes in the locker room. Leaving the kindergarten one by one, each child takes one left and one right shoe, accidentally equiprobably choosing them from among the remaining ones. Find the likelihood that none of the children will leave in their own pair of shoes. My thoughts: I assume that decisions are independent based on accidentally equiprobably choosing them from among the remaining ones part. Let $I_l$ and $I_r$ be indicator r.v. for choosing his/her left shoe. Let $A$ be the probability that none of the children will leave in their own pair of shoes $$P(I_l=1)=\frac1n; P(I_r=1)=\frac1n$$ Leaving without his/her pair of shoes can occur in several ways: $1$) Choose his/her left shoe and other (not his/her) right shoe $$P(I_l=1)P(I_r=0)=\left(\frac1n\right)^n\left(1-\frac1n\right)^n$$ $2$) Choose his/her right shoe and other (not his/her) left shoe $$P(I_r=1)P(I_l=0)=\left(\frac1n\right)^n\left(1-\frac1n\right)^n$$ $3$) Nobody chose his/her pair of shoes $$P(I_l=0)P(I_r=0)=\left(1-\frac1n\right)^n\left(1-\frac1n\right)^n$$ Therefore, $$P(A)=2\left(\frac1n\right)^n\left(1-\frac1n\right)^n+\left(1-\frac1n\right)^{2n}$$ Here I assume that kids can distinguish between right and left shoes. If they can not: probability of choosing left shoe out of $2n$ shoes: $$P(\text{left})=\frac{n}{\binom{2n}{2}}$$ by symmetry the same for $P(\text{right})$ $1$) Chose two left shoes included his/her: $$(P(\text{left})P(\text{left}))^n=\left(\frac{n}{\binom{2n}{2}}\cdot\frac{n-1}{\binom{2n-1}{2}}\right)^n$$ Power $n$, because there are $n$ people who make this decisions $2$) Chose two right shoes included his/her: $$(P(\text{right})P(\text{right}))^n=\left(\frac{n}{\binom{2n}{2}}\cdot\frac{n-1}{\binom{2n-1}{2}}\right)^n$$ $3$) Choose one left included his/her and one right excluded his/her own: $$P(\text{left})P(\text{right})=\left(\frac{n}{\binom{2n}{2}}\cdot\frac{n-1}{\binom{2n-1}{2}}\right)^n$$ $4$) Choose one right inlcuded his her and one left excluded his/her own $$P(\text{right})P(\text{left})=\left(\frac{n}{\binom{2n}{2}}\cdot\frac{n-1}{\binom{2n-1}{2}}\right)^n$$",,"['probability', 'combinatorics']"
56,Probability on circumference,Probability on circumference,,"Let $\xi$ be uniformly distributed on $\left[-\pi,\,\pi\right]$, $X = \cos \xi$, $Y = \sin \xi$. Is it true that $\Pr \left( X=1\mid Y=0 \right) = 0.5$? It is obvious this problem cannot be solved in term of events as $\Pr \left( Y=0 \right) = 0$. Therefore I am to compute conditional pdf $p \left( x \mid y \right)$. But joint pdf $p \left( x, y \right)$ is distributed on the zero-measured set. So, I'm a bit confused with this. EDIT: The key problem here is that the distribution on the unit circumference is singular in $\mathbb{R}^2$. However I still don't know if this equality is correct in any sense.","Let $\xi$ be uniformly distributed on $\left[-\pi,\,\pi\right]$, $X = \cos \xi$, $Y = \sin \xi$. Is it true that $\Pr \left( X=1\mid Y=0 \right) = 0.5$? It is obvious this problem cannot be solved in term of events as $\Pr \left( Y=0 \right) = 0$. Therefore I am to compute conditional pdf $p \left( x \mid y \right)$. But joint pdf $p \left( x, y \right)$ is distributed on the zero-measured set. So, I'm a bit confused with this. EDIT: The key problem here is that the distribution on the unit circumference is singular in $\mathbb{R}^2$. However I still don't know if this equality is correct in any sense.",,['probability']
57,How exactly is the probability of at least one event happening dependent on the probability of all events happening?,How exactly is the probability of at least one event happening dependent on the probability of all events happening?,,"Say we have $P(A) = 0.60,\, P(B) = 0.50$ . Normally to find the probability of at least one happening, we find the probability of neither of them happening: $$P(A^c \cap B^c) = 0.40 \times 0.50 = 0.20$$ and then subtract it from $1$ ( getting $0.80$). I know that this is incorrect because we are also given that $P(A \cap B) = 0.35$, thus $A,B$ are not independent. How would one go about finding the probability of at least one occurring in this case?","Say we have $P(A) = 0.60,\, P(B) = 0.50$ . Normally to find the probability of at least one happening, we find the probability of neither of them happening: $$P(A^c \cap B^c) = 0.40 \times 0.50 = 0.20$$ and then subtract it from $1$ ( getting $0.80$). I know that this is incorrect because we are also given that $P(A \cap B) = 0.35$, thus $A,B$ are not independent. How would one go about finding the probability of at least one occurring in this case?",,['probability']
58,What is the chance the product of four dice would equal 144?,What is the chance the product of four dice would equal 144?,,"Question Four fair six-sided dice are rolled. Out of the 1296 possibilities, what would result in a product of 144? I started out with listing all possible combinations that lead to this product. 6*6*4*1   $${4\choose2}{2\choose1}{1\choose1} = {4!\over2!1!1!} = 12$$ 6*6*2*2   $${4\choose2}{2\choose2} = {4!\over2!2!} = 6$$ 6*4*3*2   $${4\choose1}{3\choose1}{2\choose1}{1\choose1} = {4!\over1!1!1!1!} = 24$$ 4*4*3*3   $${4\choose2}{2\choose2} = {4!\over2!2!} = 6$$ And then I add all those numbers together. 12+6+24+6 = 48 Obviously this method is inefficient and prone to error. I do not feel confident with my answer (as in, I think it's not even right) and want to know if there's a better way to do this. As a side note I checked out What is the probability of the sum of four dice being 22? but was completely confused on how that worked, so I need some hand-holding here.","Question Four fair six-sided dice are rolled. Out of the 1296 possibilities, what would result in a product of 144? I started out with listing all possible combinations that lead to this product. 6*6*4*1   $${4\choose2}{2\choose1}{1\choose1} = {4!\over2!1!1!} = 12$$ 6*6*2*2   $${4\choose2}{2\choose2} = {4!\over2!2!} = 6$$ 6*4*3*2   $${4\choose1}{3\choose1}{2\choose1}{1\choose1} = {4!\over1!1!1!1!} = 24$$ 4*4*3*3   $${4\choose2}{2\choose2} = {4!\over2!2!} = 6$$ And then I add all those numbers together. 12+6+24+6 = 48 Obviously this method is inefficient and prone to error. I do not feel confident with my answer (as in, I think it's not even right) and want to know if there's a better way to do this. As a side note I checked out What is the probability of the sum of four dice being 22? but was completely confused on how that worked, so I need some hand-holding here.",,"['probability', 'combinatorics', 'dice']"
59,Formal definition of sampling,Formal definition of sampling,,"I can identify sampling when I see it, and I can write a program to sample from a distribution, but I'm wondering if there is a more rigorous, formal way to define sampling. Something more than ""a process of selecting a member of a population according to some distribution."" Is there a deeper definition, or is this as far as it goes?","I can identify sampling when I see it, and I can write a program to sample from a distribution, but I'm wondering if there is a more rigorous, formal way to define sampling. Something more than ""a process of selecting a member of a population according to some distribution."" Is there a deeper definition, or is this as far as it goes?",,"['probability', 'combinatorics', 'statistics', 'proof-writing', 'sampling']"
60,Variational argument with probability measures,Variational argument with probability measures,,"Let $\mathscr M(\mathbb Z^d)$ denote the set of probability measures on $\mathbb Z^d$ Let $\mu \in \mathscr M(\mathbb Z^{d+1}), $. Let $\mu_d $ be the marginal distribution $\sum_{z\in \mathbb Z}\mu(x,z)$ for $x\in \mathbb Z^d$ and $\mu_1=\sum_{x\in \mathbb Z^d}\mu(x,z)$ for $z\in \mathbb Z$. Let $f_d$ be some function which takes measures where the index denotes the dimension of the measure. Assume we have $$f_{d+1}(\mu) \ge \sum_{x\in \mathbb Z^d} \mu_d(x)f_1(\frac {\mu(x,.)}{\mu_d(x)})+\sum_{z\in \mathbb Z} \mu_1(z)f_d(\frac {\mu(.,z)}{\mu_1(z)})$$ My question is: how can I conclude from there that $$\inf_{\nu\in \mathscr M^{d+1}} f_{d+1}(\nu)\ge \inf_{\nu\in\mathscr M^1} f_1(\nu) +\inf_{\nu \in \mathscr M^d} f_d(\nu)$$ The book I am reading says ""varying over $\mu$"" but I don't know what they mean by this. It seems reasonable as $\mu_d(x)$ summed over all $x$ equals 1 and thus we want to minimize the first coordinate in the first sum and vice versa in the second one, but what would be the formal proof?","Let $\mathscr M(\mathbb Z^d)$ denote the set of probability measures on $\mathbb Z^d$ Let $\mu \in \mathscr M(\mathbb Z^{d+1}), $. Let $\mu_d $ be the marginal distribution $\sum_{z\in \mathbb Z}\mu(x,z)$ for $x\in \mathbb Z^d$ and $\mu_1=\sum_{x\in \mathbb Z^d}\mu(x,z)$ for $z\in \mathbb Z$. Let $f_d$ be some function which takes measures where the index denotes the dimension of the measure. Assume we have $$f_{d+1}(\mu) \ge \sum_{x\in \mathbb Z^d} \mu_d(x)f_1(\frac {\mu(x,.)}{\mu_d(x)})+\sum_{z\in \mathbb Z} \mu_1(z)f_d(\frac {\mu(.,z)}{\mu_1(z)})$$ My question is: how can I conclude from there that $$\inf_{\nu\in \mathscr M^{d+1}} f_{d+1}(\nu)\ge \inf_{\nu\in\mathscr M^1} f_1(\nu) +\inf_{\nu \in \mathscr M^d} f_d(\nu)$$ The book I am reading says ""varying over $\mu$"" but I don't know what they mean by this. It seems reasonable as $\mu_d(x)$ summed over all $x$ equals 1 and thus we want to minimize the first coordinate in the first sum and vice versa in the second one, but what would be the formal proof?",,"['probability', 'probability-theory', 'probability-distributions']"
61,Optimal time to renew a library book,Optimal time to renew a library book,,"A real world word problem from my life: I often check out books and DVDs from my local library. The standard check-out period is three weeks. Using the library's website, I can renew any checked out item at any time before it's due to extend the due date to three weeks after the time of renewal. I am allowed to renew an item twice before I must return it. This encourages me to renew items only when they are near their due dates so that I can get the maximum amount of time with my items before running out of renewals. However, the rule is I can't renew an item if another library patron places a hold on it. If someone does, I must return the item by its current due date. This encourages me to renew items early before anybody has a chance to place a hold on it. So if I renew too early, I won't extend the initial three week check-out period by very much. If I renew too late, my item has a greater chance of acquiring a hold, in which case I won't extend the initial check-out period at all. So that leads to the following question: When during a given three week check-out period is the best time for me to renew an item so that I can keep the item for the longest possible time with the lowest risk that a hold will be placed on it before I can renew? I suppose we may assume the probability on any given day that a checked-out item of mine will get a hold placed on it is constant and independent of which day it is during the three week period. Beyond that I have no idea what the actual value of that probability is, except that I know from experience that, for a popular item, it is pretty likely that a hold will get placed on it within, say, $10$ days after I check it out. I'd be interested if anyone can answer my question in general where the probability per day of a hold is $p$. Intuitively, if $p$ is small, then I should renew late; if $p$ is large, then I should renew early. Additionally, I'm also interested if anyone can offer some good estimates of what $p$ might actually be either using my own (very rough) description, or their own experience or analysis.","A real world word problem from my life: I often check out books and DVDs from my local library. The standard check-out period is three weeks. Using the library's website, I can renew any checked out item at any time before it's due to extend the due date to three weeks after the time of renewal. I am allowed to renew an item twice before I must return it. This encourages me to renew items only when they are near their due dates so that I can get the maximum amount of time with my items before running out of renewals. However, the rule is I can't renew an item if another library patron places a hold on it. If someone does, I must return the item by its current due date. This encourages me to renew items early before anybody has a chance to place a hold on it. So if I renew too early, I won't extend the initial three week check-out period by very much. If I renew too late, my item has a greater chance of acquiring a hold, in which case I won't extend the initial check-out period at all. So that leads to the following question: When during a given three week check-out period is the best time for me to renew an item so that I can keep the item for the longest possible time with the lowest risk that a hold will be placed on it before I can renew? I suppose we may assume the probability on any given day that a checked-out item of mine will get a hold placed on it is constant and independent of which day it is during the three week period. Beyond that I have no idea what the actual value of that probability is, except that I know from experience that, for a popular item, it is pretty likely that a hold will get placed on it within, say, $10$ days after I check it out. I'd be interested if anyone can answer my question in general where the probability per day of a hold is $p$. Intuitively, if $p$ is small, then I should renew late; if $p$ is large, then I should renew early. Additionally, I'm also interested if anyone can offer some good estimates of what $p$ might actually be either using my own (very rough) description, or their own experience or analysis.",,"['probability', 'optimization', 'discrete-optimization']"
62,In how many ways we can color $15$ eggs..,In how many ways we can color  eggs..,15,"In how many ways we can color $15$ eggs with colors red, blue, and green, when each egg must  be colored with exactly two distinct colors. My answer is : (1) red and blue colored eggs are in the first box, and (2) red and green colored eggs are in the second box, and (3) blue and green colored eggs are in the third box. So we have $3$ boxes. Any one or two of these  boxes can be empty, because we can put all eggs in one box (that is color every egg with same combination of colors, so all are in one box). Boxes are labeled and objects (eggs) are not. So the answer is $$n+k-1 \choose k-1  $$ so $$ 15 + 3 -1 \choose 15-1$$ Is it correct?","In how many ways we can color $15$ eggs with colors red, blue, and green, when each egg must  be colored with exactly two distinct colors. My answer is : (1) red and blue colored eggs are in the first box, and (2) red and green colored eggs are in the second box, and (3) blue and green colored eggs are in the third box. So we have $3$ boxes. Any one or two of these  boxes can be empty, because we can put all eggs in one box (that is color every egg with same combination of colors, so all are in one box). Boxes are labeled and objects (eggs) are not. So the answer is $$n+k-1 \choose k-1  $$ so $$ 15 + 3 -1 \choose 15-1$$ Is it correct?",,['probability']
63,Wasserstein distance on $\mathbb{R}$,Wasserstein distance on,\mathbb{R},"I have the following problem. Given the Wasserstein distance, defined by $W_1(\mu,\nu)=\inf\limits_{\pi\in\Pi(\mu,\nu)}\int\limits_{\mathbb{R}^2}|x-y|d\pi(x,y)$, whereby $\mu$ and $\nu$ are probability measures on the Borel $\sigma$-algebra on $\mathbb{R}$ and $\Pi(\mu,\nu)$ is the set of all couplings of $(\mu,\nu)$. I also know that $W_1(\mu,\nu) = \int\limits_{-\infty}^{\infty}|F(x)-G(x)|dx$ for the distribution functions $F$ and $G$ of $\mu$ and $\nu$, (i.e $F(x)=\mu((-\infty,x])$). I now want to prove that $W_1(\mu,\nu)=\int\limits_{0}^{1}|F^{-1}(z)-G^{-1}(z)|dz.$ Here we of course define $F^{-1}(z):=\inf\lbrace{}x\in\mathbb{R};F(x)\geq{}z\rbrace$ I don't quite know how to aproach this problem and would be quite grateful for any advice. Thanks","I have the following problem. Given the Wasserstein distance, defined by $W_1(\mu,\nu)=\inf\limits_{\pi\in\Pi(\mu,\nu)}\int\limits_{\mathbb{R}^2}|x-y|d\pi(x,y)$, whereby $\mu$ and $\nu$ are probability measures on the Borel $\sigma$-algebra on $\mathbb{R}$ and $\Pi(\mu,\nu)$ is the set of all couplings of $(\mu,\nu)$. I also know that $W_1(\mu,\nu) = \int\limits_{-\infty}^{\infty}|F(x)-G(x)|dx$ for the distribution functions $F$ and $G$ of $\mu$ and $\nu$, (i.e $F(x)=\mu((-\infty,x])$). I now want to prove that $W_1(\mu,\nu)=\int\limits_{0}^{1}|F^{-1}(z)-G^{-1}(z)|dz.$ Here we of course define $F^{-1}(z):=\inf\lbrace{}x\in\mathbb{R};F(x)\geq{}z\rbrace$ I don't quite know how to aproach this problem and would be quite grateful for any advice. Thanks",,"['probability', 'measure-theory', 'metric-spaces']"
64,Calculate the conditional probability of dependent events involving independent random variables,Calculate the conditional probability of dependent events involving independent random variables,,"Given three independent, non-negative (continuous) random variables $v_1$, $v_2$ and $v_3$ with PDFs $f_{v_1}$, $f_{v_2}$ and $f_{v_3}$ respectively, I want to calculate the probability of satisfying a system of linear inequalities. For example, what is the probability $\mathbb{P}(v_1 \leq q_1 \land [ v_1 + v_3 \leq q_2 \lor v_2 + v_4 \leq q_2])$ of satisfying $v_1 \leq q_1 \;\textbf{and}\; [ v_1 + v_3 \leq q_2 \;\textbf{or}\; v_2 + v_3 \leq q_2 ]$ where $q_i \in \mathbb{Q}$ are rational constants. (Sorry for my abuse of notation!) I can easily calculate the probability for each of the three inequalities (using convolutions) by $\mathbb{P}(v_1 \leq q_1) = \int_{-\infty}^{q_1} f_{v_1}(t)\; dt$, $\mathbb{P}(v_1 + v_3 \leq q_2) = \int_{-\infty}^{q_2} f_{v_1}(t) (\int_{-\infty}^{q_2 - t} f_{v_3}(u)\; du)\; dt$, and $\mathbb{P}(v_2 + v_3 \leq q_2) = \int_{-\infty}^{q_2} f_{v_2}(t) ( \int_{-\infty}^{q_2 - t} f_{v_2}(u)\; du)\; dt$ Let $A$ be the event that $v_1 + v_3 \leq q_2$ and $B$ the event that $v_2 + v_3 \leq q_2$. The sum rule tells us that $\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A \cap B)$, and we know that $\mathbb{P}(A \cap B) = \mathbb{P}(A|B) \mathbb{P}(B) = \mathbb{P}(B | A) \mathbb{P}(A)$. Is it possible to calculate the conditional probabilities $\mathbb{P}(A|B)$ and $\mathbb{P}(B|A)$ knowing only the marginal distributions for $v_1$, $v_2$ and $v_3$?","Given three independent, non-negative (continuous) random variables $v_1$, $v_2$ and $v_3$ with PDFs $f_{v_1}$, $f_{v_2}$ and $f_{v_3}$ respectively, I want to calculate the probability of satisfying a system of linear inequalities. For example, what is the probability $\mathbb{P}(v_1 \leq q_1 \land [ v_1 + v_3 \leq q_2 \lor v_2 + v_4 \leq q_2])$ of satisfying $v_1 \leq q_1 \;\textbf{and}\; [ v_1 + v_3 \leq q_2 \;\textbf{or}\; v_2 + v_3 \leq q_2 ]$ where $q_i \in \mathbb{Q}$ are rational constants. (Sorry for my abuse of notation!) I can easily calculate the probability for each of the three inequalities (using convolutions) by $\mathbb{P}(v_1 \leq q_1) = \int_{-\infty}^{q_1} f_{v_1}(t)\; dt$, $\mathbb{P}(v_1 + v_3 \leq q_2) = \int_{-\infty}^{q_2} f_{v_1}(t) (\int_{-\infty}^{q_2 - t} f_{v_3}(u)\; du)\; dt$, and $\mathbb{P}(v_2 + v_3 \leq q_2) = \int_{-\infty}^{q_2} f_{v_2}(t) ( \int_{-\infty}^{q_2 - t} f_{v_2}(u)\; du)\; dt$ Let $A$ be the event that $v_1 + v_3 \leq q_2$ and $B$ the event that $v_2 + v_3 \leq q_2$. The sum rule tells us that $\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A \cap B)$, and we know that $\mathbb{P}(A \cap B) = \mathbb{P}(A|B) \mathbb{P}(B) = \mathbb{P}(B | A) \mathbb{P}(A)$. Is it possible to calculate the conditional probabilities $\mathbb{P}(A|B)$ and $\mathbb{P}(B|A)$ knowing only the marginal distributions for $v_1$, $v_2$ and $v_3$?",,"['probability', 'inequality', 'probability-distributions']"
65,conditional probability on zero probability events and conditional Radon-Nikodym derivatives,conditional probability on zero probability events and conditional Radon-Nikodym derivatives,,"Consider a stochastic process $\{x_t\}_{t\in T}$ adapted to some filtered probability space $(\Omega,\mathcal{F},\{\mathcal{F}\}_{t\in T},\mathbb{P})$ taking values in the state space $(\mathbb{R},\mathcal{B})$ I wish to consider the probability Pr$(x_t\in\mathcal{A}|x_s)$ where $(s<t)$ This should be a sensible question, as I should be able to assign probability to a question of the form ""What is the chance I obtain an outcome $x_t \in [0.5,0.6]$ given that last time I got $x_s=0.4$"". e.g. a transition probability. Naturally we have Pr$(A| B)=$Pr$(A\cap B)/$Pr$(B)$ but then we have Pr$(B)=$Pr$(x_s)=0$ for any particular value. Now I think that this is where we have the notion of regular conditional probability entering which, as I understand it means we write: $$\text{Pr}(x_t\in \mathcal{A}|x_s=B)=\lim_{\mathcal{B}\to B}\frac{\text{Pr}(x_t\in \mathcal{A}\cap x_s \in \mathcal{B})}{\text{Pr}(x_s\in \mathcal{B})}$$ Vagaries of the meaning of $\lim_{\mathcal{B}\to B}$ aside (which would have to be implementation specific e.g. here $\lim_{r\to 0} \text{Pr}(x_s\in (B-r,B+r)$), is the above correct? Should I understand this as a Radon Nikodym derivative? It seems related, but not identical. How do I relate this to, and formulate it in such a way to be consistent to, how conditional probabilities are usually defined? (as I understand it) viz $$\text{Pr}(x_t\in\mathcal{A}|x_s\in\mathcal{B})=\mathbb{E}_{\mathbb{P}}[1_{\mathcal{A}}(x_t)|\sigma(\mathcal{B})\subseteq\mathcal{F}_s]$$ Surely $$\mathbb{E}_{\mathbb{P}}[1_{\mathcal{A}}(x_t)|\sigma({B})]$$ just wouldn't work? i.e. $\sigma(B)\nsubseteq\mathcal{F}$? Is it legitimate to construct Radon-Nikodym derivatives out of measures formed from regular conditional probabilities? i.e. is this (heuristically) ok? $$\frac{d\mathbb{P}(x_t|x_s=B)}{d\mathbb{Q}(x_t|x_s=B)}=\lim_{\mathcal{A}\to\emptyset}\lim_{\mathcal{B}\to B}\frac{\mathbb{P}(x_t\in\mathcal{A}|x_s\in\mathcal{B})}{\mathbb{Q}(x_t\in\mathcal{A}|x_s\in\mathcal{B})}$$ Thanks. EDIT: Based on discussion in the comments, the issues appears to boil down to why one can write $$\text{Pr}(x_t\in \mathcal{A}|B)=\mathbb{E}_{\mathbb{P}}[1_{\mathcal{A}}(x_t)|\sigma({B})]$$ when $B$ is a zero probability event. What I don't understand is what the sigma algebra generated by a zero probability event looks like and why you can condition on it. Surely the sigma algebra generated by a zero probability event is itself formed from (complements and unions of) zero probability events in $\mathbb{P}$, thus not in $\mathcal{F}$ e.g. $$\sigma(x_s=B)=\{\omega,\omega^c,\emptyset,\Omega\}\nsubseteq\mathcal{F}$$ with $\mathbb{P}(\omega)=0$ such that $\mathbb{E}_{\mathbb{P}}[f(x_t)|\sigma({B})]=\mathbb{E}_{\mathbb{P}}[f(x_t)]$ or $0$? so why can we condition on these? What am I getting wrong here?","Consider a stochastic process $\{x_t\}_{t\in T}$ adapted to some filtered probability space $(\Omega,\mathcal{F},\{\mathcal{F}\}_{t\in T},\mathbb{P})$ taking values in the state space $(\mathbb{R},\mathcal{B})$ I wish to consider the probability Pr$(x_t\in\mathcal{A}|x_s)$ where $(s<t)$ This should be a sensible question, as I should be able to assign probability to a question of the form ""What is the chance I obtain an outcome $x_t \in [0.5,0.6]$ given that last time I got $x_s=0.4$"". e.g. a transition probability. Naturally we have Pr$(A| B)=$Pr$(A\cap B)/$Pr$(B)$ but then we have Pr$(B)=$Pr$(x_s)=0$ for any particular value. Now I think that this is where we have the notion of regular conditional probability entering which, as I understand it means we write: $$\text{Pr}(x_t\in \mathcal{A}|x_s=B)=\lim_{\mathcal{B}\to B}\frac{\text{Pr}(x_t\in \mathcal{A}\cap x_s \in \mathcal{B})}{\text{Pr}(x_s\in \mathcal{B})}$$ Vagaries of the meaning of $\lim_{\mathcal{B}\to B}$ aside (which would have to be implementation specific e.g. here $\lim_{r\to 0} \text{Pr}(x_s\in (B-r,B+r)$), is the above correct? Should I understand this as a Radon Nikodym derivative? It seems related, but not identical. How do I relate this to, and formulate it in such a way to be consistent to, how conditional probabilities are usually defined? (as I understand it) viz $$\text{Pr}(x_t\in\mathcal{A}|x_s\in\mathcal{B})=\mathbb{E}_{\mathbb{P}}[1_{\mathcal{A}}(x_t)|\sigma(\mathcal{B})\subseteq\mathcal{F}_s]$$ Surely $$\mathbb{E}_{\mathbb{P}}[1_{\mathcal{A}}(x_t)|\sigma({B})]$$ just wouldn't work? i.e. $\sigma(B)\nsubseteq\mathcal{F}$? Is it legitimate to construct Radon-Nikodym derivatives out of measures formed from regular conditional probabilities? i.e. is this (heuristically) ok? $$\frac{d\mathbb{P}(x_t|x_s=B)}{d\mathbb{Q}(x_t|x_s=B)}=\lim_{\mathcal{A}\to\emptyset}\lim_{\mathcal{B}\to B}\frac{\mathbb{P}(x_t\in\mathcal{A}|x_s\in\mathcal{B})}{\mathbb{Q}(x_t\in\mathcal{A}|x_s\in\mathcal{B})}$$ Thanks. EDIT: Based on discussion in the comments, the issues appears to boil down to why one can write $$\text{Pr}(x_t\in \mathcal{A}|B)=\mathbb{E}_{\mathbb{P}}[1_{\mathcal{A}}(x_t)|\sigma({B})]$$ when $B$ is a zero probability event. What I don't understand is what the sigma algebra generated by a zero probability event looks like and why you can condition on it. Surely the sigma algebra generated by a zero probability event is itself formed from (complements and unions of) zero probability events in $\mathbb{P}$, thus not in $\mathcal{F}$ e.g. $$\sigma(x_s=B)=\{\omega,\omega^c,\emptyset,\Omega\}\nsubseteq\mathcal{F}$$ with $\mathbb{P}(\omega)=0$ such that $\mathbb{E}_{\mathbb{P}}[f(x_t)|\sigma({B})]=\mathbb{E}_{\mathbb{P}}[f(x_t)]$ or $0$? so why can we condition on these? What am I getting wrong here?",,"['probability', 'probability-theory', 'stochastic-processes']"
66,Picking pairs of socks from a drawer.,Picking pairs of socks from a drawer.,,"There are $n$ socks in a drawer, of $m$ different colours. Initially, the probability of picking a sock of colour $c_i$ at random is $\mathbb{P}(c_i) \cdot 2r$ socks are picked at random, without replacement. What is the probability, $\mathbb{P}(pairs)$, that $r$ pairs of socks are picked? (i.e. all socks are paired) If $r = 1$ (2 socks are chosen): $\mathbb{P}(pairs)$ = $\mathbb{P}$(2 are $c_1$ or 2 are $c_2$ or ... or 2 are $c_m$) ~ $\sum_{k}^{m} {\left[\mathbb{P}(c_k)\right]^2}$ How can this be generalized for r?","There are $n$ socks in a drawer, of $m$ different colours. Initially, the probability of picking a sock of colour $c_i$ at random is $\mathbb{P}(c_i) \cdot 2r$ socks are picked at random, without replacement. What is the probability, $\mathbb{P}(pairs)$, that $r$ pairs of socks are picked? (i.e. all socks are paired) If $r = 1$ (2 socks are chosen): $\mathbb{P}(pairs)$ = $\mathbb{P}$(2 are $c_1$ or 2 are $c_2$ or ... or 2 are $c_m$) ~ $\sum_{k}^{m} {\left[\mathbb{P}(c_k)\right]^2}$ How can this be generalized for r?",,"['probability', 'combinatorics']"
67,Product of two random polynomials,Product of two random polynomials,,"Let $\alpha,\beta$ be two polynomials of the form $$\alpha(X)=\sum_{i=0}^{n}\alpha_iX^i,\quad \quad \beta(X)=\sum_{j=0}^n\beta_jX^j$$ where each coefficient is $1$ with a probability of $p$ and $0$ with probability $1-p$. The coefficients of $\alpha,\beta$ are all independent. Note that $\alpha,\beta$ are of degree at most $n$. What can I say about the distribution of the polynomial $H(X)=\alpha(X)\cdot \beta (X)$? Note that the $k$-th coefficient of $H$ is $$h_k=\sum_{i=0}^k\alpha_i\beta_{k-i},$$ therefore it is distributed in $[0,k+1]$, but how ? Note also that the variables $c_i^{(k)}:=\alpha_i\beta_{k-i}$ are $1$ with probability $p^2$ and $0$ with probability $1-p^2$, and are independent for fixed $k$ so I can treat $h_k$ as the sum of independent random discrete variables, which is fairly easy. However, for different values of $k$ there is correlation between these variables, in other words $H$'s coefficients are not independent. It looks complicated to characterize such correlation, is there any way to measure it ? Thank you all EDIT : As an easy example to see the correlation, note that the probability of $h_1=2$ knowing that $h_0=0$ is $0$.","Let $\alpha,\beta$ be two polynomials of the form $$\alpha(X)=\sum_{i=0}^{n}\alpha_iX^i,\quad \quad \beta(X)=\sum_{j=0}^n\beta_jX^j$$ where each coefficient is $1$ with a probability of $p$ and $0$ with probability $1-p$. The coefficients of $\alpha,\beta$ are all independent. Note that $\alpha,\beta$ are of degree at most $n$. What can I say about the distribution of the polynomial $H(X)=\alpha(X)\cdot \beta (X)$? Note that the $k$-th coefficient of $H$ is $$h_k=\sum_{i=0}^k\alpha_i\beta_{k-i},$$ therefore it is distributed in $[0,k+1]$, but how ? Note also that the variables $c_i^{(k)}:=\alpha_i\beta_{k-i}$ are $1$ with probability $p^2$ and $0$ with probability $1-p^2$, and are independent for fixed $k$ so I can treat $h_k$ as the sum of independent random discrete variables, which is fairly easy. However, for different values of $k$ there is correlation between these variables, in other words $H$'s coefficients are not independent. It looks complicated to characterize such correlation, is there any way to measure it ? Thank you all EDIT : As an easy example to see the correlation, note that the probability of $h_1=2$ knowing that $h_0=0$ is $0$.",,"['probability', 'polynomials']"
68,Weather forecast and probabilities,Weather forecast and probabilities,,"There are two weather stations, station A and station B which are independent of each other. On average, the weather forecast accuracy of station A is $80\%$ and that of station B is $90\%$. Station A predicts that tomorrow will be sunny, whereas station B predicts rain. What is the probability that it rains tomorrow? We are not asking for the exact probability; we are just asking whether it is more likely to rain or not. OK I suppose we must examine the following $4$ cases: a) A and B make the same forecast and both are right b) A and B make the same forecast and both are wrong c) A and B make different forecasts and A is right d) A and B make different forecasts and B is right and of course we are in one of the cases c) or d), since we know they make different forecasts .","There are two weather stations, station A and station B which are independent of each other. On average, the weather forecast accuracy of station A is $80\%$ and that of station B is $90\%$. Station A predicts that tomorrow will be sunny, whereas station B predicts rain. What is the probability that it rains tomorrow? We are not asking for the exact probability; we are just asking whether it is more likely to rain or not. OK I suppose we must examine the following $4$ cases: a) A and B make the same forecast and both are right b) A and B make the same forecast and both are wrong c) A and B make different forecasts and A is right d) A and B make different forecasts and B is right and of course we are in one of the cases c) or d), since we know they make different forecasts .",,"['probability', 'logic']"
69,Robot painting a circular track,Robot painting a circular track,,"A circular track of length $2n$ meters has $2n$ teleporters equally   spaced along the track. Each teleporter, when activated,   instantaneously teleports the object inside to the antipodally   opposite teleporter. Starting at the first teleporter, a robot begins to move clockwise along the   track at a rate of $1$ meter/second. As it moves along the track, the   robot paints the track red. When the robot reaches a teleporter, the   teleporter activates with probability $1/2$ and does not activate with   probability $1/2$. The robot continues moving clockwise    after being teleported. What is the expected number of seconds until the entire track is   painted red? By heuristics, I suspect the quantity is asymptotic to $n\log_{2} (n)$, but I am having trouble proving this (or computing an exact result). Any help would be much appreciated.","A circular track of length $2n$ meters has $2n$ teleporters equally   spaced along the track. Each teleporter, when activated,   instantaneously teleports the object inside to the antipodally   opposite teleporter. Starting at the first teleporter, a robot begins to move clockwise along the   track at a rate of $1$ meter/second. As it moves along the track, the   robot paints the track red. When the robot reaches a teleporter, the   teleporter activates with probability $1/2$ and does not activate with   probability $1/2$. The robot continues moving clockwise    after being teleported. What is the expected number of seconds until the entire track is   painted red? By heuristics, I suspect the quantity is asymptotic to $n\log_{2} (n)$, but I am having trouble proving this (or computing an exact result). Any help would be much appreciated.",,"['probability', 'combinatorics', 'probability-theory', 'expectation']"
70,100 coins problem,100 coins problem,,"100 coins in a circle, clockwise labeled 1-100. Starting at   coin 1, you flip each one moving clockwise. If a coin lands tails, you keep it, if it lands heads, you remove it. After a long time, only one coin will remain. What would you expect its label is The problem sounds pretty tricky but my initiation is that since each coin has an equal chance to become a tail or head, this would really become a uniform distribution so with that said the expected value for uniform distribution would be (100 + 1) /2 = 50.5 is this correct ?","100 coins in a circle, clockwise labeled 1-100. Starting at   coin 1, you flip each one moving clockwise. If a coin lands tails, you keep it, if it lands heads, you remove it. After a long time, only one coin will remain. What would you expect its label is The problem sounds pretty tricky but my initiation is that since each coin has an equal chance to become a tail or head, this would really become a uniform distribution so with that said the expected value for uniform distribution would be (100 + 1) /2 = 50.5 is this correct ?",,['probability']
71,About convergence in probability infinitely often.,About convergence in probability infinitely often.,,"I am confused about the distinction between these two modes of convergence. $$ \lim_{n \rightarrow \infty }P(|X_n - X| > \epsilon) \rightarrow 0 $$ $$ P(|X_n - X| > \epsilon\ \text{ i.o }) = 0 $$ Doesn't the first mode of convergence (in probability) imply the second? But apparently it seems the second is more stronger. Maybe my interpretation of ""infinitely often"" is incorrect. An example of each would be helpful.","I am confused about the distinction between these two modes of convergence. $$ \lim_{n \rightarrow \infty }P(|X_n - X| > \epsilon) \rightarrow 0 $$ $$ P(|X_n - X| > \epsilon\ \text{ i.o }) = 0 $$ Doesn't the first mode of convergence (in probability) imply the second? But apparently it seems the second is more stronger. Maybe my interpretation of ""infinitely often"" is incorrect. An example of each would be helpful.",,"['probability', 'probability-theory', 'measure-theory']"
72,Understanding the random variable definition of Markov chains,Understanding the random variable definition of Markov chains,,"Update This question is answered in section 3.2 of these notes . As a probability novice, I'm struggling to completely understand the definition of a Markov chain as a sequence of random variables. For simplicity, consider discrete-time, homogeneous Markov chains with finite state spaces $S$ which we take to be $\{1, \dots, n\}$.  I understand the following definition of a Markov chain in this context: A Markov chain is a pair $(S,P)$ where $P = (P_{ij})$ is a transition matrix . Given this definition, one can generate a trajectory of the Markov chain consisting of an infinite sequence $s_0, s_1, \dots$ of elements of $S$ by initializing in a state $s_0$ and evolving forward according to the transition probabilities $(P_{ij})$. So far so good -- this is all quite intuitive. However, suppose instead that one considers a Markov chain as a sequence $X_0, X_1, \dots$ of random variables with values in $S$ having the Markov property -- is there a standard mapping between these definitions? In particular, since each $X_k$ is a random variable whose domain is some sample space $\Omega$; $$   X_k:\Omega\to S, $$ and since the transition probabilities are usually described as conditional probabilities; $$   P_{ij} = \mathbf P(X_k = i\mid X_{k-1}=j), $$ or the transpose of this depending on you conventions, presumably there is a sample space $\Omega$ and a probability measure $\mathbf P$ sitting somewhere ? One guess would be that $\Omega$ can be taken to be the set of all sequences $s_0, s_1, \dots$ of elements of $S$, the random variable $X_k$ maps any such sequence to its $k^\mathrm{th}$ element, $$   X_k(s_0, s_1, \dots) = s_k, $$ and $\mathbf P$ is any probability measure on the set of subsets of $\Omega$ that satisfies the Markov property. Is this description of (one direction of) the correspondence between these Markov chain definitions correct and/or standard ?","Update This question is answered in section 3.2 of these notes . As a probability novice, I'm struggling to completely understand the definition of a Markov chain as a sequence of random variables. For simplicity, consider discrete-time, homogeneous Markov chains with finite state spaces $S$ which we take to be $\{1, \dots, n\}$.  I understand the following definition of a Markov chain in this context: A Markov chain is a pair $(S,P)$ where $P = (P_{ij})$ is a transition matrix . Given this definition, one can generate a trajectory of the Markov chain consisting of an infinite sequence $s_0, s_1, \dots$ of elements of $S$ by initializing in a state $s_0$ and evolving forward according to the transition probabilities $(P_{ij})$. So far so good -- this is all quite intuitive. However, suppose instead that one considers a Markov chain as a sequence $X_0, X_1, \dots$ of random variables with values in $S$ having the Markov property -- is there a standard mapping between these definitions? In particular, since each $X_k$ is a random variable whose domain is some sample space $\Omega$; $$   X_k:\Omega\to S, $$ and since the transition probabilities are usually described as conditional probabilities; $$   P_{ij} = \mathbf P(X_k = i\mid X_{k-1}=j), $$ or the transpose of this depending on you conventions, presumably there is a sample space $\Omega$ and a probability measure $\mathbf P$ sitting somewhere ? One guess would be that $\Omega$ can be taken to be the set of all sequences $s_0, s_1, \dots$ of elements of $S$, the random variable $X_k$ maps any such sequence to its $k^\mathrm{th}$ element, $$   X_k(s_0, s_1, \dots) = s_k, $$ and $\mathbf P$ is any probability measure on the set of subsets of $\Omega$ that satisfies the Markov property. Is this description of (one direction of) the correspondence between these Markov chain definitions correct and/or standard ?",,"['probability', 'stochastic-processes', 'markov-chains']"
73,Probability concerning summation of independent trials,Probability concerning summation of independent trials,,"I am have a very hard time solving this particular question. If anyone can help my understanding by providing a helpful solution, it would be much appreciated. Thank you. Consider n independent trials, each of which results in one of the outcomes $1, \dots , k$ with respective probabilities $p_1,\dots,p_k$, $$\sum_{i=1}^{k}p_i = 1$$ Show that if all the $p_i$ are small, then the probability that no trial outcome occurs more than once is approximately equal to $$\exp\left(\frac{-n(n-1)}{2}\left(\sum_{i}^{}p_i^2\right)\right) $$","I am have a very hard time solving this particular question. If anyone can help my understanding by providing a helpful solution, it would be much appreciated. Thank you. Consider n independent trials, each of which results in one of the outcomes $1, \dots , k$ with respective probabilities $p_1,\dots,p_k$, $$\sum_{i=1}^{k}p_i = 1$$ Show that if all the $p_i$ are small, then the probability that no trial outcome occurs more than once is approximately equal to $$\exp\left(\frac{-n(n-1)}{2}\left(\sum_{i}^{}p_i^2\right)\right) $$",,"['probability', 'summation']"
74,Concentration inequalities for $P(\sum_{i=1}^n \epsilon_i X_i > t)$,Concentration inequalities for,P(\sum_{i=1}^n \epsilon_i X_i > t),"Let $\epsilon_i \sim \text{Bernoulli}(p)$ and $X_i \sim \text{Normal}(0, \sigma^2 / n)$ for $i=1,\ldots,n$. I am interested in getting a sub-Gaussian type upper bound for $$ P\left(\sum_i \epsilon_i X_i > t\right).  $$ Ideally, it would look something like  \begin{align} P\left(\sum_i \epsilon_i X_i > t\right) \le K\exp\left(C\frac{-t^2}{2\sigma^2 p}\right) \tag{1} \end{align} for some constants $K$ and $C$, although I'm thinking this isn't true; I'm also not sure how to incorporate $n$ here into $K$ or $C$. It's important that the bound quantifies the deviation in terms of $p$, so that I have good control over what is going on as $p \to 0$. The furthest I've gotten is that, by iterated expectation and the usual Gaussian concentration stuff, \begin{align} P\left(\sum_i \epsilon_i X_i > t\right) \le E\left\{\exp\left(\frac{-t^2 n}{2\sigma^2 \sum_i \epsilon_i}\right)\right\} \tag{2} \end{align} which, for fixed $p$, gives  $$ \limsup_n P\left(\sum_i \epsilon_i X_i > t\right) \le \exp\left(\frac{-t^2}{2\sigma^2 p}\right) $$ by the law of large numbers. But this approach doesn't seem strong enough, since a little bit of numeric investigation shows that (2) is quite a bit worse than (1) as $p \to 0$. Some quantification of how $p$ and $n$ play into the bound (2) would also be good.","Let $\epsilon_i \sim \text{Bernoulli}(p)$ and $X_i \sim \text{Normal}(0, \sigma^2 / n)$ for $i=1,\ldots,n$. I am interested in getting a sub-Gaussian type upper bound for $$ P\left(\sum_i \epsilon_i X_i > t\right).  $$ Ideally, it would look something like  \begin{align} P\left(\sum_i \epsilon_i X_i > t\right) \le K\exp\left(C\frac{-t^2}{2\sigma^2 p}\right) \tag{1} \end{align} for some constants $K$ and $C$, although I'm thinking this isn't true; I'm also not sure how to incorporate $n$ here into $K$ or $C$. It's important that the bound quantifies the deviation in terms of $p$, so that I have good control over what is going on as $p \to 0$. The furthest I've gotten is that, by iterated expectation and the usual Gaussian concentration stuff, \begin{align} P\left(\sum_i \epsilon_i X_i > t\right) \le E\left\{\exp\left(\frac{-t^2 n}{2\sigma^2 \sum_i \epsilon_i}\right)\right\} \tag{2} \end{align} which, for fixed $p$, gives  $$ \limsup_n P\left(\sum_i \epsilon_i X_i > t\right) \le \exp\left(\frac{-t^2}{2\sigma^2 p}\right) $$ by the law of large numbers. But this approach doesn't seem strong enough, since a little bit of numeric investigation shows that (2) is quite a bit worse than (1) as $p \to 0$. Some quantification of how $p$ and $n$ play into the bound (2) would also be good.",,"['probability', 'probability-theory', 'concentration-of-measure']"
75,Question about the $\sigma$-algebra for infinite coin toss,Question about the -algebra for infinite coin toss,\sigma,"Let $\{a_i\}$ be a countable sequence of binary values representing the results of repeated independent fair coin tosses with $a_i= 0$ indicating tail and $a_i = 1$ indicating head. Let $\Omega$ be the sample space consisting of all possible $\{a_i\}$ . The $\sigma$ -algebra is constructed in the following way. Let $\cal F_n, n\in\Bbb N$ be the set of sequences that can be determined by $a_1,a_2,...,a_n$ union $\{\emptyset, \Omega\}$ . For example, let $A_0$ denote the set of sequences with $a_1=0$ , $A_1$ denote the set of sequences with $a_1=1$ , $A_{00}$ denote the set of sequences with $a_1=0,a_2=0$ , $A_{10}$ denote the set of sequences with $a_1=1, a_2=0$ , etc. Then $\cal F_1 = \{\emptyset, \Omega, A_0, A_1\}$ , $\cal F_2 = \{\emptyset, \Omega, A_0, A_1,A_{00},A_{01},A_{10},A_{11}\}$ , and so on. It is not hard to verify that $\cal F_n$ is increasing, i.e. $\cal F_n \subseteq \cal F_{n+1}$ . Define $\cal F_\infty = \bigcup_{i=1}^\infty \cal F_i$ , and we state a result that $\cal F_\infty$ is not a $\sigma$ -algebra. However,  the smallest $\sigma$ -algebra generated by $\cal F_\infty$ , denoted as $\sigma(\cal F_\infty)$ is what we need, and we can define a sensible probability measure on the measurable space $（\Omega, \sigma(\cal F_\infty))$ . My question is : is $\sigma(\cal F_\infty)=2^\Omega$ ? Or in other words why the above construction is necessary? Thank you!","Let be a countable sequence of binary values representing the results of repeated independent fair coin tosses with indicating tail and indicating head. Let be the sample space consisting of all possible . The -algebra is constructed in the following way. Let be the set of sequences that can be determined by union . For example, let denote the set of sequences with , denote the set of sequences with , denote the set of sequences with , denote the set of sequences with , etc. Then , , and so on. It is not hard to verify that is increasing, i.e. . Define , and we state a result that is not a -algebra. However,  the smallest -algebra generated by , denoted as is what we need, and we can define a sensible probability measure on the measurable space . My question is : is ? Or in other words why the above construction is necessary? Thank you!","\{a_i\} a_i= 0 a_i = 1 \Omega \{a_i\} \sigma \cal F_n, n\in\Bbb N a_1,a_2,...,a_n \{\emptyset, \Omega\} A_0 a_1=0 A_1 a_1=1 A_{00} a_1=0,a_2=0 A_{10} a_1=1, a_2=0 \cal F_1 = \{\emptyset, \Omega, A_0, A_1\} \cal F_2 = \{\emptyset, \Omega, A_0, A_1,A_{00},A_{01},A_{10},A_{11}\} \cal F_n \cal F_n \subseteq \cal F_{n+1} \cal F_\infty = \bigcup_{i=1}^\infty \cal F_i \cal F_\infty \sigma \sigma \cal F_\infty \sigma(\cal F_\infty) （\Omega, \sigma(\cal F_\infty)) \sigma(\cal F_\infty)=2^\Omega","['probability', 'measure-theory']"
76,Probability question using fixed steps,Probability question using fixed steps,,"I start life at $0$, I aim to make it to $1$. I can take steps of $\dfrac{1}{2^k}, k>0$, and do so with probability  $\dfrac{1}{2^k}$. What is the expected number of steps to reach $1$ or beyond. What is the probability I will land on $1$? APPENDUM: $\begin{array} {c|c} values&expected\\ \hline 222&2\\ 22N&2\\ 2N2&3\\ N22&3\\ NN2&?\\ N2N&?\\ 2NN&?\\ NNN&? \end{array}$ Let $2$ be the event that we walk $\dfrac12$, and $N$ that we don't. We have $8$ outcomes, but we don't know the value of $?$, so let it be $5$ for those with one $2$, on the grounds that we will need on average $2$ more throws to 'guarantee' a $2$, and $7$ for $NNN$. So the expected value is $\dfrac{32}{8}=4$. This obviously needs some refinement.","I start life at $0$, I aim to make it to $1$. I can take steps of $\dfrac{1}{2^k}, k>0$, and do so with probability  $\dfrac{1}{2^k}$. What is the expected number of steps to reach $1$ or beyond. What is the probability I will land on $1$? APPENDUM: $\begin{array} {c|c} values&expected\\ \hline 222&2\\ 22N&2\\ 2N2&3\\ N22&3\\ NN2&?\\ N2N&?\\ 2NN&?\\ NNN&? \end{array}$ Let $2$ be the event that we walk $\dfrac12$, and $N$ that we don't. We have $8$ outcomes, but we don't know the value of $?$, so let it be $5$ for those with one $2$, on the grounds that we will need on average $2$ more throws to 'guarantee' a $2$, and $7$ for $NNN$. So the expected value is $\dfrac{32}{8}=4$. This obviously needs some refinement.",,['probability']
77,"How to refer to the ""sign"" of the dependence of events?","How to refer to the ""sign"" of the dependence of events?",,"How would you express the inequalities $P(A\cap B)\lessgtr P(A)P(B)$? If two random variables are correlated, $E[XY]\lessgtr E[X]E[Y]$, we call them positively or negatively correlated according to the direction of the inequality. Positively correlated variables tend to vary in the same direction, and negatively correlated variables tend to vary in opposite directions. I just realized that I don't really know how to express the analogue for dependent events – the fact that the events are more or less likely to occur together than one might expect from their individual probabilities. I could say that their indicator variables are positively or negatively correlated, and it seems to be a common abuse of terminology to say that the events themselves are positively or negatively correlated, but that seems suboptimal, since without the adverb indicating the sign we'd call them dependent and not correlated. Is there such a thing as positively or negatively dependent events? A Google search for ""negatively dependent"" mostly turns up definitions of ""negatively dependent random variables"" (e.g. here and here ), not negatively dependent events. How else could this concept be expressed? Is ""positively or negatively correlated"" the least bad option?","How would you express the inequalities $P(A\cap B)\lessgtr P(A)P(B)$? If two random variables are correlated, $E[XY]\lessgtr E[X]E[Y]$, we call them positively or negatively correlated according to the direction of the inequality. Positively correlated variables tend to vary in the same direction, and negatively correlated variables tend to vary in opposite directions. I just realized that I don't really know how to express the analogue for dependent events – the fact that the events are more or less likely to occur together than one might expect from their individual probabilities. I could say that their indicator variables are positively or negatively correlated, and it seems to be a common abuse of terminology to say that the events themselves are positively or negatively correlated, but that seems suboptimal, since without the adverb indicating the sign we'd call them dependent and not correlated. Is there such a thing as positively or negatively dependent events? A Google search for ""negatively dependent"" mostly turns up definitions of ""negatively dependent random variables"" (e.g. here and here ), not negatively dependent events. How else could this concept be expressed? Is ""positively or negatively correlated"" the least bad option?",,"['probability', 'probability-theory', 'terminology']"
78,Frequency from probability,Frequency from probability,,"Assume an event has a probability $p=1/100$ of happening, per trial. Here are three statements that I believe are true: On average, the event is witnessed in a one-hundredth of the the trials. The average number of trials between consecutive events is $100$. It is more likeley than not to witness at least one event in a set of $69$ trials. This is found by computing the probability of the complement, i.e. the probability of no event in $69$ trials, which is $(1-p)^{69}=0.4998...$. I can't understand how statements 2 and 3 can both be true. Is there a flaw in the reasoning somewhere ? Can they both be true? What is the ""frequency"" of the event ?","Assume an event has a probability $p=1/100$ of happening, per trial. Here are three statements that I believe are true: On average, the event is witnessed in a one-hundredth of the the trials. The average number of trials between consecutive events is $100$. It is more likeley than not to witness at least one event in a set of $69$ trials. This is found by computing the probability of the complement, i.e. the probability of no event in $69$ trials, which is $(1-p)^{69}=0.4998...$. I can't understand how statements 2 and 3 can both be true. Is there a flaw in the reasoning somewhere ? Can they both be true? What is the ""frequency"" of the event ?",,[]
79,Distribution of server utilisations in an M/M/c queuing model with an unusual dispatching discipline,Distribution of server utilisations in an M/M/c queuing model with an unusual dispatching discipline,,"I'm studying an M/M/c queuing model with an unusual (?) dispatching discipline: Servers are numbered 1...c The servers have an identical mean service time, exponentially distributed (as usual), which does not vary with time or load If all servers are busy, the transaction is allocated to the first server that becomes free If any servers are free, the transaction is allocated to the free server with the lowest number. I am especially interested in the mean server utilisation ($\rho_i$) for each server (which could be derived from the proportion $p_i$ of jobs served by server $i$), and also its distribution (though I guess that is more difficult). What results are available which give the distribution of traffic going to each server?","I'm studying an M/M/c queuing model with an unusual (?) dispatching discipline: Servers are numbered 1...c The servers have an identical mean service time, exponentially distributed (as usual), which does not vary with time or load If all servers are busy, the transaction is allocated to the first server that becomes free If any servers are free, the transaction is allocated to the free server with the lowest number. I am especially interested in the mean server utilisation ($\rho_i$) for each server (which could be derived from the proportion $p_i$ of jobs served by server $i$), and also its distribution (though I guess that is more difficult). What results are available which give the distribution of traffic going to each server?",,"['probability', 'probability-distributions', 'queueing-theory']"
80,Frog on infinitely many lily pads (Markov chain),Frog on infinitely many lily pads (Markov chain),,"A frog on pad $i$ hops to one of the pads $(1,2,...,i,i+1)$ with equal probability. I know that if the frog starts on pad $k$ the expected number of times the frog jumps, before returning for the first time to $k$ is $e(k-1)!$ (I proved this already). But what is the expected number of times the frog will visit pad $k+1$? I don't know how to find this. I thought that maybe we can use the fact that there is a probability of $1/(k+1)$ of visiting this the first time and then multiply this by the number of times I expect to return at $k+1$ when I start at $k+1$. If this is correct, then what is that expectation? EDIT: Is the answer to the question really $\infty$ as michael says in the comments?","A frog on pad $i$ hops to one of the pads $(1,2,...,i,i+1)$ with equal probability. I know that if the frog starts on pad $k$ the expected number of times the frog jumps, before returning for the first time to $k$ is $e(k-1)!$ (I proved this already). But what is the expected number of times the frog will visit pad $k+1$? I don't know how to find this. I thought that maybe we can use the fact that there is a probability of $1/(k+1)$ of visiting this the first time and then multiply this by the number of times I expect to return at $k+1$ when I start at $k+1$. If this is correct, then what is that expectation? EDIT: Is the answer to the question really $\infty$ as michael says in the comments?",,['probability']
81,Rolling a certain total with a dice,Rolling a certain total with a dice,,"Suppose you roll a $k$-sided die repeatedly, totaling your scores as you go, until you reach or surpass $n$. (For a real-world usage ... if you have a non-looping game board and only move forward, what are your odds of landing on a specific square?) What is the probability that you actually hit $n$? I'm trying to solve this myself and have gotten an ugly closed form for $k=2$, and have a pair of interrelated recursion expressions for $k=3$ . But I feel like there ought to be more elegant solutions than the ones I've achieved, so I thought I'd propose the problem to the community to see if someone else comes up with an answer whilst I work on it.","Suppose you roll a $k$-sided die repeatedly, totaling your scores as you go, until you reach or surpass $n$. (For a real-world usage ... if you have a non-looping game board and only move forward, what are your odds of landing on a specific square?) What is the probability that you actually hit $n$? I'm trying to solve this myself and have gotten an ugly closed form for $k=2$, and have a pair of interrelated recursion expressions for $k=3$ . But I feel like there ought to be more elegant solutions than the ones I've achieved, so I thought I'd propose the problem to the community to see if someone else comes up with an answer whilst I work on it.",,"['probability', 'dice']"
82,Paradoxical Game Show Problem [duplicate],Paradoxical Game Show Problem [duplicate],,"This question already has answers here : Better than random (5 answers) Closed 9 years ago . Here's a problem that has had me scratching my head for a long time: Imagine you're in a game show, and are presented with 2 boxes.  You are told that both boxes contain a sum of cash, but one of the boxes contains twice as much as the other.  You do not know which box has the double prize.  The game works in 2 phases: Choose any of the boxes you want. Look inside the box.  At this point you can decide to keep the contents, or switch to the other box. So imagine that you've chosen a box, and it contains \$100.  From here, you can calculate the ""expected value"" of the other box to be $0.5 \times \$50 + 0.5 \times \$200 = \$125$ and therefore decide to switch. But then it follows that you would have made the same decision for any value $x$ that you would have found in the first box!  So then why not just pick the other box in the first place? In other words, the strategy of ""pick a box at random, and then switch, no matter what"" is equivalent to ""pick a candidate box at random, and then pick the other box, and keep it"", which is also equivalent to ""pick a box at random, and keep it"".  Which means that switching is the same as not switching. But this seems like a paradox, because we just calculated that switching the box after your initial choice increases your expected winnings by a factor of 1.25!","This question already has answers here : Better than random (5 answers) Closed 9 years ago . Here's a problem that has had me scratching my head for a long time: Imagine you're in a game show, and are presented with 2 boxes.  You are told that both boxes contain a sum of cash, but one of the boxes contains twice as much as the other.  You do not know which box has the double prize.  The game works in 2 phases: Choose any of the boxes you want. Look inside the box.  At this point you can decide to keep the contents, or switch to the other box. So imagine that you've chosen a box, and it contains \$100.  From here, you can calculate the ""expected value"" of the other box to be $0.5 \times \$50 + 0.5 \times \$200 = \$125$ and therefore decide to switch. But then it follows that you would have made the same decision for any value $x$ that you would have found in the first box!  So then why not just pick the other box in the first place? In other words, the strategy of ""pick a box at random, and then switch, no matter what"" is equivalent to ""pick a candidate box at random, and then pick the other box, and keep it"", which is also equivalent to ""pick a box at random, and keep it"".  Which means that switching is the same as not switching. But this seems like a paradox, because we just calculated that switching the box after your initial choice increases your expected winnings by a factor of 1.25!",,"['probability', 'expectation']"
83,Probability that two circles in space are linked,Probability that two circles in space are linked,,"Let $C_0$ be a circle centered on the origin, and $C_1$ a circle centered  on $(1,0,0)$, center distance of $1$. Q1 . If both $C_0$ and $C_1$    are randomly oriented and have the same radius   $r > \frac{1}{2}$, what is the probability $P(r)$ that the circles are linked? This is in some sense a straighforward question. Although ""straighforward,"" I am not finding it an easy computation. (I would like an exact expression, although numerical approximations are welcomed.) It may help to start with a simpler question: Q2 . Assume $C_0$ is fixed in the $xy$-plane, and only $C_1$'s orientation   is random. What is the probability $P'(r)$ that the circles are linked? The orientation of $C_1$ is determined by a unit normal vector $\hat{n}$ whose tip is on a unit sphere $S$. The challenge in Q2 is to work out the region $R$ on $S$ that leads to linking. The probability $P'(r)$ is then the area of $R$ divided by $4 \pi$. Even Q2 seems tricky. If anyone can see considerations that simplify the calculations, I would appreciate hearing of them—Thanks!","Let $C_0$ be a circle centered on the origin, and $C_1$ a circle centered  on $(1,0,0)$, center distance of $1$. Q1 . If both $C_0$ and $C_1$    are randomly oriented and have the same radius   $r > \frac{1}{2}$, what is the probability $P(r)$ that the circles are linked? This is in some sense a straighforward question. Although ""straighforward,"" I am not finding it an easy computation. (I would like an exact expression, although numerical approximations are welcomed.) It may help to start with a simpler question: Q2 . Assume $C_0$ is fixed in the $xy$-plane, and only $C_1$'s orientation   is random. What is the probability $P'(r)$ that the circles are linked? The orientation of $C_1$ is determined by a unit normal vector $\hat{n}$ whose tip is on a unit sphere $S$. The challenge in Q2 is to work out the region $R$ on $S$ that leads to linking. The probability $P'(r)$ is then the area of $R$ divided by $4 \pi$. Even Q2 seems tricky. If anyone can see considerations that simplify the calculations, I would appreciate hearing of them—Thanks!",,"['probability', 'geometry', '3d', 'knot-theory']"
84,Expected total number of balls in all bins after throwing balls uniformly randomly to bins that have limited capacity,Expected total number of balls in all bins after throwing balls uniformly randomly to bins that have limited capacity,,"Consider throwing $n$ balls uniformly randomly to $L$ bins. Each bin has capacity $G$, meaning that if a ball is threw to a bin that already has $G$ balls in it, the ball is discarded. Is that possible to determine the expected total number of balls in all bins after throwing $n$ balls?","Consider throwing $n$ balls uniformly randomly to $L$ bins. Each bin has capacity $G$, meaning that if a ball is threw to a bin that already has $G$ balls in it, the ball is discarded. Is that possible to determine the expected total number of balls in all bins after throwing $n$ balls?",,"['probability', 'combinatorics', 'balls-in-bins']"
85,Conditional probability with Poisson processes,Conditional probability with Poisson processes,,"I'm reading a section on conditional logistic models in which a heterogeneous Poisson process is used to make inferences in disease mapping. Basically, the likelihood of a Poisson process is used to describe the events $\{s\}$ within a spatial region $T$ $$L(\{s\}|\Psi) = \frac{1}{m!}\prod_{i=1}^{m}\lambda(s_{i}|\Psi)\exp\{\Lambda_{T}\} $$ where $\Lambda_{T} = \int_{T}\lambda(u|\Psi)du$. $\lambda(s)$ is called the intensity. This quantity determines the rate of case events (detected cases of disease, for example) and $\Lambda_{T}$ is the intensity over the region $T$. Usually for case events, $\lambda(s|\Psi)$ is given by $\lambda_{0}(s|\Psi_{0})\lambda_{1}(s|\Psi_{1})$ in which $\lambda_{0}(s|\Psi_{0})$ is a ""spatially-varying function of the population at risk of the disease in question"" and $\lambda_{1}(s|\Psi_{1})$  includes appropriate predictors. However, in the case of modeling cases and controls, I don't understand what calculation is performed. I quote the relevant paragraph: When a bivariate realization of cases and controls are available it is   possible to make conditional inference on this joint realization.   Define the case events as $s_{i} : i = 1, ..., m$ and the control   events as $s_i : i = m + 1, ...., N$ where $N = m + n$ the total   number of events. Associated with each location is a binary variable   ($y_i$) which labels the event either as a case ($y_i = 1$) or a   control ($y_i = 0$). Assume also that the point process models   governing each event type (case or control) is a heterogeneous Poisson   process with intensity $\lambda(s|ψ)$ for cases and $\lambda_0 (s|ψ_{0})$ for controls. The superposition of the two processes is   also a heterogeneous Poisson process with intensity $λ_0(s|ψ_0) + λ(s|ψ) = λ_0 (s|ψ_0 )[1+λ_1 (s|ψ_1 )]$. Conditioning on the joint   realization of these processes, then it is straightforward to derive   the conditional probability of a case at any location as $$Pr(y_{i}=1) = \frac{λ_0(s_i |ψ_0 )λ_1(s_i |ψ_1 )}{λ_0 (s_i |ψ_0 )[1 + λ_1 (s_i |ψ_1 )]} = p_{i}$$ $$Pr(y_{i}=0) = \frac{1}{1 + λ_1 (s_i |ψ_1)} = 1-p_{i}$$ What is the author calculating in these equations? It seems to be the probability of a case and a control respectively. However, if a Poisson process is modeling each event type, I don't see traces of a Poisson process there. Furthermore, using the previous equations, the likelihood is: $$L(\Psi_{1}|s) = \prod_{i\in \text{cases}}p_{i}\prod_{i\in \text{controls}}(1-p_{i})$$ which seems very reasonable except for the conditioning on $s$ instead of conditioning on the parameters $\Psi$. I would appreciate any help. UPDATE : You can find this section available in Google Books using this link .","I'm reading a section on conditional logistic models in which a heterogeneous Poisson process is used to make inferences in disease mapping. Basically, the likelihood of a Poisson process is used to describe the events $\{s\}$ within a spatial region $T$ $$L(\{s\}|\Psi) = \frac{1}{m!}\prod_{i=1}^{m}\lambda(s_{i}|\Psi)\exp\{\Lambda_{T}\} $$ where $\Lambda_{T} = \int_{T}\lambda(u|\Psi)du$. $\lambda(s)$ is called the intensity. This quantity determines the rate of case events (detected cases of disease, for example) and $\Lambda_{T}$ is the intensity over the region $T$. Usually for case events, $\lambda(s|\Psi)$ is given by $\lambda_{0}(s|\Psi_{0})\lambda_{1}(s|\Psi_{1})$ in which $\lambda_{0}(s|\Psi_{0})$ is a ""spatially-varying function of the population at risk of the disease in question"" and $\lambda_{1}(s|\Psi_{1})$  includes appropriate predictors. However, in the case of modeling cases and controls, I don't understand what calculation is performed. I quote the relevant paragraph: When a bivariate realization of cases and controls are available it is   possible to make conditional inference on this joint realization.   Define the case events as $s_{i} : i = 1, ..., m$ and the control   events as $s_i : i = m + 1, ...., N$ where $N = m + n$ the total   number of events. Associated with each location is a binary variable   ($y_i$) which labels the event either as a case ($y_i = 1$) or a   control ($y_i = 0$). Assume also that the point process models   governing each event type (case or control) is a heterogeneous Poisson   process with intensity $\lambda(s|ψ)$ for cases and $\lambda_0 (s|ψ_{0})$ for controls. The superposition of the two processes is   also a heterogeneous Poisson process with intensity $λ_0(s|ψ_0) + λ(s|ψ) = λ_0 (s|ψ_0 )[1+λ_1 (s|ψ_1 )]$. Conditioning on the joint   realization of these processes, then it is straightforward to derive   the conditional probability of a case at any location as $$Pr(y_{i}=1) = \frac{λ_0(s_i |ψ_0 )λ_1(s_i |ψ_1 )}{λ_0 (s_i |ψ_0 )[1 + λ_1 (s_i |ψ_1 )]} = p_{i}$$ $$Pr(y_{i}=0) = \frac{1}{1 + λ_1 (s_i |ψ_1)} = 1-p_{i}$$ What is the author calculating in these equations? It seems to be the probability of a case and a control respectively. However, if a Poisson process is modeling each event type, I don't see traces of a Poisson process there. Furthermore, using the previous equations, the likelihood is: $$L(\Psi_{1}|s) = \prod_{i\in \text{cases}}p_{i}\prod_{i\in \text{controls}}(1-p_{i})$$ which seems very reasonable except for the conditioning on $s$ instead of conditioning on the parameters $\Psi$. I would appreciate any help. UPDATE : You can find this section available in Google Books using this link .",,"['probability', 'stochastic-processes', 'conditional-probability']"
86,Dividing a deck of cards using only imagination,Dividing a deck of cards using only imagination,,"The idea came up from a discussion I had with my friends. Suppose we want to play a game using a deck of cards, and we can't use any physical materials. If we are intelligent enough, we can remember the types of cards each one has. The problem is that it is even hard to divide the cards uniformly by using only our brains. To divide them properly, each one should not know the types of cards others have. By introducing a 'dealer', it becomes easy. We can ask the dealer to tell each person what cards they will have. But the dealer then can't participate in the game. The question is that how can players divide the deck uniformly by themselves. I think it is important to specify the exact condition for the problem. This is what I have in mind. Each person can uniformly choose a number from a finite set of numbers All players trust each other. That is, if they agreed on a particular procedure on dividing cards, they will actually follow the procedure. The procedure would consist of a sequence of data transfer from one person to other. The receiver will remember the data exactly, and it is impossible to forget it. By the end of the procedure, the conditional probability distribution of cards given all the information each person knows should be uniform. This is far from clear mathematical formulation. So the first question is: How can we formulate this problem exactly into mathematical language? For example, how can we define the concept of data transfer? The question is easy when there are only two people and two cards. One can just simply grab one and pass the other. But the question seems much harder for even three people and three cards. How can three individuals divide three cards uniformly? Or if it is impossible, are there any proof? I think this can be a more fundamental question. Can two people having their own number from 1, 2 or 3, interact with each other to conclude that whether they have same or different numbers, but gain no more information about their opponent's number? Any suggestions for clarification are welcomed. Fixing grammar mistakes and awkward expressions are much welcomed too.","The idea came up from a discussion I had with my friends. Suppose we want to play a game using a deck of cards, and we can't use any physical materials. If we are intelligent enough, we can remember the types of cards each one has. The problem is that it is even hard to divide the cards uniformly by using only our brains. To divide them properly, each one should not know the types of cards others have. By introducing a 'dealer', it becomes easy. We can ask the dealer to tell each person what cards they will have. But the dealer then can't participate in the game. The question is that how can players divide the deck uniformly by themselves. I think it is important to specify the exact condition for the problem. This is what I have in mind. Each person can uniformly choose a number from a finite set of numbers All players trust each other. That is, if they agreed on a particular procedure on dividing cards, they will actually follow the procedure. The procedure would consist of a sequence of data transfer from one person to other. The receiver will remember the data exactly, and it is impossible to forget it. By the end of the procedure, the conditional probability distribution of cards given all the information each person knows should be uniform. This is far from clear mathematical formulation. So the first question is: How can we formulate this problem exactly into mathematical language? For example, how can we define the concept of data transfer? The question is easy when there are only two people and two cards. One can just simply grab one and pass the other. But the question seems much harder for even three people and three cards. How can three individuals divide three cards uniformly? Or if it is impossible, are there any proof? I think this can be a more fundamental question. Can two people having their own number from 1, 2 or 3, interact with each other to conclude that whether they have same or different numbers, but gain no more information about their opponent's number? Any suggestions for clarification are welcomed. Fixing grammar mistakes and awkward expressions are much welcomed too.",,"['probability', 'information-theory']"
87,Average complexity of random-pick comparison sort,Average complexity of random-pick comparison sort,,"Motivation. Suppose we have a number of images that we want to arrange in a linear order from the prettiest to the ugliest. At our disposal we have a trained aesthete, whom we can show two pictures and ask him which is the prettiest. We assume that the aesthete's preferences are unchanging and internally consistent. (That's a pretty big assumption, but this is mathematics: Our assumptions don't have to be likely, only consistent). Our task is to discover the true aesthetic order between the images without paying the aesthete for too much work. Ideally we would use a good close-to-minimal comparison sorting algorithm, such as binary insertion sort which comes within $n$ of the information-theoretic bound of $\log_2 n!$ comparisons. Unfortunately most of the algorithms at hand tend to ask the aesthete runs of questions where he's asked to compare the same image to several other images in succession, and he finds that so boring that he threatens to increase his rates. While we're trying to find a better algorithm, the junior member of the design team suggests just to ask random questions until we know enough (but avoiding questions that we can deduce the answer to already). Is this a good idea? Actual question . Given $n$ , let $R_0$ be the identity relation on $\{1,2,3,\ldots,n\}$ . As long as $R_k$ is not a total order, choose $(a,b)$ uniformly in $\{(a,b) \mid 1\le a<b\le n\}\setminus R_k$ , and let $R_{k+1}$ be the transitive closure of $R_k\cup\{(a,b)\}$ . What is the expected number of steps until $R_k$ is a total order? The ideal answer would give an explicit (and feasible) way to compute it, but just the asymptotic behavior would be interesting to know.","Motivation. Suppose we have a number of images that we want to arrange in a linear order from the prettiest to the ugliest. At our disposal we have a trained aesthete, whom we can show two pictures and ask him which is the prettiest. We assume that the aesthete's preferences are unchanging and internally consistent. (That's a pretty big assumption, but this is mathematics: Our assumptions don't have to be likely, only consistent). Our task is to discover the true aesthetic order between the images without paying the aesthete for too much work. Ideally we would use a good close-to-minimal comparison sorting algorithm, such as binary insertion sort which comes within of the information-theoretic bound of comparisons. Unfortunately most of the algorithms at hand tend to ask the aesthete runs of questions where he's asked to compare the same image to several other images in succession, and he finds that so boring that he threatens to increase his rates. While we're trying to find a better algorithm, the junior member of the design team suggests just to ask random questions until we know enough (but avoiding questions that we can deduce the answer to already). Is this a good idea? Actual question . Given , let be the identity relation on . As long as is not a total order, choose uniformly in , and let be the transitive closure of . What is the expected number of steps until is a total order? The ideal answer would give an explicit (and feasible) way to compute it, but just the asymptotic behavior would be interesting to know.","n \log_2 n! n R_0 \{1,2,3,\ldots,n\} R_k (a,b) \{(a,b) \mid 1\le a<b\le n\}\setminus R_k R_{k+1} R_k\cup\{(a,b)\} R_k","['probability', 'algorithms', 'recreational-mathematics', 'sorting']"
88,Card game probability,Card game probability,,"Suppose the following solitaire with a standard deck. I turn four cards visible on the board and on each turn, I remove those suits that appears more than once in the board. Then I fill the board such that it has four cards and repeat removing. I win the game if I can remove all 52 cards from the board and lose otherwise, i.e. when all cards are from different suit. What is the probability to win this game? I guess we need some kind of generating polynomial but I'm not sure how to solve that kind of problems.","Suppose the following solitaire with a standard deck. I turn four cards visible on the board and on each turn, I remove those suits that appears more than once in the board. Then I fill the board such that it has four cards and repeat removing. I win the game if I can remove all 52 cards from the board and lose otherwise, i.e. when all cards are from different suit. What is the probability to win this game? I guess we need some kind of generating polynomial but I'm not sure how to solve that kind of problems.",,"['probability', 'combinatorics', 'recreational-mathematics', 'generating-functions', 'card-games']"
89,Probability: the expected value in a dice game. [duplicate],Probability: the expected value in a dice game. [duplicate],,"This question already has answers here : Probability of dice sum just greater than 100 (6 answers) Closed 10 years ago . If a dice is thrown till the sum of the numbers appearing on the top face of dice exceeds or equal to 100, what is the most likely sum?","This question already has answers here : Probability of dice sum just greater than 100 (6 answers) Closed 10 years ago . If a dice is thrown till the sum of the numbers appearing on the top face of dice exceeds or equal to 100, what is the most likely sum?",,"['probability', 'expectation']"
90,"What is the probability of picking $3$ $A$'s, $4$ $B$'s, $5$ $C$'s and $8$ $D$'s when you pick $20$ balls?","What is the probability of picking  's,  's,  's and  's when you pick  balls?",3 A 4 B 5 C 8 D 20,"Q: Choose $20$ balls from an urn with infinite numbers of balls. The balls are labeled with $A, B, C, D$ and each has $25$% of chances getting picked. What is the probability of picking $3$ $A$'s, $4$ $B$'s, $5$ $C$'s and $8$ $D$'s when you pick $20$ balls? My approach to this question is: total # of permutations = $4^{20}$ ways of having $8$ $D$'s = ${20 \choose 8}$ ways of having $5$ $C$'s = ${12 \choose 5}$ ways of having $4$ $B$'s = ${7 \choose 4}$ permutation of these = $4!$ Probability: $(4! \cdot {20 \choose 8} \cdot {12 \choose 5} \cdot {7 \choose 4}) / 4^{20}$ I am not sure if I am doing this correctly or not. Can someone please give me some pointers. Also, how to deal with it if the probability distribution is not uniform?","Q: Choose $20$ balls from an urn with infinite numbers of balls. The balls are labeled with $A, B, C, D$ and each has $25$% of chances getting picked. What is the probability of picking $3$ $A$'s, $4$ $B$'s, $5$ $C$'s and $8$ $D$'s when you pick $20$ balls? My approach to this question is: total # of permutations = $4^{20}$ ways of having $8$ $D$'s = ${20 \choose 8}$ ways of having $5$ $C$'s = ${12 \choose 5}$ ways of having $4$ $B$'s = ${7 \choose 4}$ permutation of these = $4!$ Probability: $(4! \cdot {20 \choose 8} \cdot {12 \choose 5} \cdot {7 \choose 4}) / 4^{20}$ I am not sure if I am doing this correctly or not. Can someone please give me some pointers. Also, how to deal with it if the probability distribution is not uniform?",,['probability']
91,Probability: Drawing Aces from a Deck of Cards,Probability: Drawing Aces from a Deck of Cards,,"""You are dealt 13 cards randomly from a pack of 52. What is the probability your hand contains exactly 2 aces?"" I thought about breaking it down into: ${4 \choose 2}$ = number of ways to choose two of four aces. ${48 \choose 11}$ = number of ways to choose 11 cards from the non-aces. ${52 \choose 13}$ = choose any 13 cards from the 52. And then using: $\cfrac{\binom{4}{2} \cdot \binom{48}{11}}{\binom{52}{13}}$ Could anyone confirm this solution or show otherwise?","""You are dealt 13 cards randomly from a pack of 52. What is the probability your hand contains exactly 2 aces?"" I thought about breaking it down into: ${4 \choose 2}$ = number of ways to choose two of four aces. ${48 \choose 11}$ = number of ways to choose 11 cards from the non-aces. ${52 \choose 13}$ = choose any 13 cards from the 52. And then using: $\cfrac{\binom{4}{2} \cdot \binom{48}{11}}{\binom{52}{13}}$ Could anyone confirm this solution or show otherwise?",,['probability']
92,How to determine if binomial events are independent?,How to determine if binomial events are independent?,,"I have a sequence of binary experiment results, something like 1100010000100... My first hypothesis is that these events are independent, but I'd like to know if there is some way to test this.  I could look at the probability of a 1 immediately following another 1, for example, and see if it is close to the overall probability of a 1, but that's just one possible kind of correlation/dependence.  Is there some more general way to look for patterns? Two things that seem like they might be helpful are Fourier transforms and hidden markov models, but I don't really know enough about either to say whether they apply to this situation.  Even just some pointers for further reading would be very helpful.","I have a sequence of binary experiment results, something like 1100010000100... My first hypothesis is that these events are independent, but I'd like to know if there is some way to test this.  I could look at the probability of a 1 immediately following another 1, for example, and see if it is close to the overall probability of a 1, but that's just one possible kind of correlation/dependence.  Is there some more general way to look for patterns? Two things that seem like they might be helpful are Fourier transforms and hidden markov models, but I don't really know enough about either to say whether they apply to this situation.  Even just some pointers for further reading would be very helpful.",,"['probability', 'statistics']"
93,Central Limit Theorem on the Circle,Central Limit Theorem on the Circle,,"I am interested in a circular equivalent to the classical CLT. Is there a necessary and sufficient condition telling when a normalized sum of circular distributed  random variables converges to a WrappedNormal distributed random variable? That is, what conditions do circular i.i.d. random vectors $X_i$ have to satisfy in order to ensure $$\frac{1}{\sqrt{n}} \sum_{i=1}^n X_i \mod 2\pi$$ converges to a WrappedNormal distributed random variable. Is there a similar result for (hyper-)spheres?","I am interested in a circular equivalent to the classical CLT. Is there a necessary and sufficient condition telling when a normalized sum of circular distributed  random variables converges to a WrappedNormal distributed random variable? That is, what conditions do circular i.i.d. random vectors $X_i$ have to satisfy in order to ensure $$\frac{1}{\sqrt{n}} \sum_{i=1}^n X_i \mod 2\pi$$ converges to a WrappedNormal distributed random variable. Is there a similar result for (hyper-)spheres?",,"['probability', 'probability-limit-theorems']"
94,"$A$ tosses a fair coin $n+x$ times, $B$ tosses a fair coin $n$ times","tosses a fair coin  times,  tosses a fair coin  times",A n+x B n,"This is an extension of the $n+1$ vs n problem here: Probability of $5$ fair coin flips having strictly more heads than $4$ fair coin flips So a common way to think about this is to say that after $n$ tries, both players have the same expected number of heads. So player $A$ has a $50\%$ chance of winning because he gets a head with $50\%$ chance on his last try. But if he gets $x$ more tries than player $B$, does that still stand? He wins with probability $1 - \frac{1}{2^x}$? I did the calculations for a few $n$'s and $x$'s and it doesn't seem to be the case. What's the answer here? Thanks!","This is an extension of the $n+1$ vs n problem here: Probability of $5$ fair coin flips having strictly more heads than $4$ fair coin flips So a common way to think about this is to say that after $n$ tries, both players have the same expected number of heads. So player $A$ has a $50\%$ chance of winning because he gets a head with $50\%$ chance on his last try. But if he gets $x$ more tries than player $B$, does that still stand? He wins with probability $1 - \frac{1}{2^x}$? I did the calculations for a few $n$'s and $x$'s and it doesn't seem to be the case. What's the answer here? Thanks!",,['probability']
95,Probability of adjacent seating,Probability of adjacent seating,,"A homework question states: A room holds two rows of six seats each. Two friends are assigned   randomly to the 12 seats. What is the probability that the 2 friends   sit in adjacent seats? Note: Friends sitting behind friends don't count. Friends sitting   diagonally adjacent to each other don't count. Only friends setting   beside each other (left/right) in the same row count. $$      \cdot~~~~~= Empty~seat $$ $$      \times    = Occupied~seat $$ $$     \begin{bmatrix}     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \end{bmatrix} $$ By drawing out the favorable possibilities: $     \begin{bmatrix}     \times & \times & \cdot & \cdot & \cdot & \cdot \\     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \end{bmatrix} $$     \begin{bmatrix}     \cdot & \times & \times & \cdot & \cdot & \cdot \\     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \end{bmatrix} $$     \begin{bmatrix}     \cdot & \cdot & \times & \times & \cdot & \cdot \\     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \end{bmatrix} $$     \begin{bmatrix}     \cdot & \cdot & \cdot & \times & \times & \cdot \\     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \end{bmatrix} $$     \begin{bmatrix}     \cdot & \cdot & \cdot & \cdot & \times  & \times \\     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \end{bmatrix} $ $     \begin{bmatrix}     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \times & \times & \cdot & \cdot & \cdot & \cdot \\     \end{bmatrix} $$     \begin{bmatrix}     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \cdot & \times & \times & \cdot & \cdot & \cdot \\     \end{bmatrix} $$     \begin{bmatrix}     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \cdot & \cdot & \times & \times & \cdot & \cdot \\     \end{bmatrix} $$     \begin{bmatrix}     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \cdot & \cdot & \cdot & \times & \times & \cdot \\     \end{bmatrix} $$     \begin{bmatrix}     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \cdot & \cdot & \cdot & \cdot & \times & \times \\     \end{bmatrix} $ It seems like there are a total of 10 favorable situations. I hope I'm right in saying there are a total of ${12 \choose 2}$ total possible situations (friends can sit in any two seats)? So is the probability that 2 friends sit adjacent to each other in this room of 12 seats:  $$ \frac{10}{{12 \choose 2}} = \frac{10}{66} = 0.1515152$$ Whether that's right or wrong, I guess, what's the better mathematical approach (using the whole ${X \choose Y}$ thing to think about this problem?","A homework question states: A room holds two rows of six seats each. Two friends are assigned   randomly to the 12 seats. What is the probability that the 2 friends   sit in adjacent seats? Note: Friends sitting behind friends don't count. Friends sitting   diagonally adjacent to each other don't count. Only friends setting   beside each other (left/right) in the same row count. $$      \cdot~~~~~= Empty~seat $$ $$      \times    = Occupied~seat $$ $$     \begin{bmatrix}     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \end{bmatrix} $$ By drawing out the favorable possibilities: $     \begin{bmatrix}     \times & \times & \cdot & \cdot & \cdot & \cdot \\     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \end{bmatrix} $$     \begin{bmatrix}     \cdot & \times & \times & \cdot & \cdot & \cdot \\     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \end{bmatrix} $$     \begin{bmatrix}     \cdot & \cdot & \times & \times & \cdot & \cdot \\     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \end{bmatrix} $$     \begin{bmatrix}     \cdot & \cdot & \cdot & \times & \times & \cdot \\     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \end{bmatrix} $$     \begin{bmatrix}     \cdot & \cdot & \cdot & \cdot & \times  & \times \\     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \end{bmatrix} $ $     \begin{bmatrix}     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \times & \times & \cdot & \cdot & \cdot & \cdot \\     \end{bmatrix} $$     \begin{bmatrix}     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \cdot & \times & \times & \cdot & \cdot & \cdot \\     \end{bmatrix} $$     \begin{bmatrix}     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \cdot & \cdot & \times & \times & \cdot & \cdot \\     \end{bmatrix} $$     \begin{bmatrix}     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \cdot & \cdot & \cdot & \times & \times & \cdot \\     \end{bmatrix} $$     \begin{bmatrix}     \cdot & \cdot & \cdot & \cdot & \cdot & \cdot \\     \cdot & \cdot & \cdot & \cdot & \times & \times \\     \end{bmatrix} $ It seems like there are a total of 10 favorable situations. I hope I'm right in saying there are a total of ${12 \choose 2}$ total possible situations (friends can sit in any two seats)? So is the probability that 2 friends sit adjacent to each other in this room of 12 seats:  $$ \frac{10}{{12 \choose 2}} = \frac{10}{66} = 0.1515152$$ Whether that's right or wrong, I guess, what's the better mathematical approach (using the whole ${X \choose Y}$ thing to think about this problem?",,"['probability', 'combinatorics']"
96,Probability of rolling $n$ successes on an open-ended/exploding dice roll,Probability of rolling  successes on an open-ended/exploding dice roll,n,"I'm trying to compute the probability of achieving a certain number of successes when rolling a die pool for both open-ended/exploding and closed tests. Success is defined as a roll above a certain (variable) threshold. If a roll is open-ended, any die which rolls the maximum value triggers an additional die to be rolled. This is for a role-playing game (Burning Wheel Gold). Assume the use of a $n$-sided die. Additionally, we assume $d$ to be the number of dice, $r$ to be the required number of successes, and $c$ to be the minimum value accepted as a success. I'm breaking the question down into two blocks: one for open-ended rolls, and one for closed rolls. Closed roll: For closed rolls, we can define a probability recurrence as follows: $$Pr\left[r,d\right] = \begin{cases} \\1-\frac{c}{n}:Pr\left[d-1,r\right]\\\frac{c}{n}:Pr\left[d-1,r-1\right] \end{cases}$$ With probability $\frac{c}{n}$, a success will be met. However, I'm not sure how to solve this recurrence relation for any number of dice/required successes. There's probably an easier way to do this, but I haven't done much discrete probability. Edit: It looks like a binomial probability distribution works for this part of the problem. This comes in the form of: $${{d}\choose{r}}\left(\frac{c}{n}\right)^{r}\left(1-\frac{c}{n}\right)^{d-r}$$ Open ended roll: For open-ended rolls, we can find the equivalent number of rolled dice. This is going to be equal to: $$d+\sum_{j=1}^{\infty}\left(\frac{d}{6^{j}} \right)=\frac{6d}{5}$$ This implies that, given a number of dice $n$, rolling open-ended results in approximately $\frac{6}{5}n$ dice rolled. If we had an easy way to solve the above for any number of dice $n$, it would be easy: we could just input the non-integer value $n$ and get our result. However, since the above is defined with a recurrence relation is a binomial distribution, and thus uses combinations, it won't work for a non-integer number. Thus, we can define a probability recurrence relation as follows: $$Pr\left[ r,d\right] = \begin{cases} \\1-\frac{c}{n}:Pr\left[d-1,r\right]\\\frac{c-1}{n}:Pr\left[d-1,r-1\right]\\\frac{1}{n}:Pr\left[d,r-1\right] \end{cases}$$ The probability of no significant result is $1-\frac{c}{n}$, the probability of a regular success is $\frac{c-1}{n}$, and the probability of an 'exploding' or open-ended result is $\frac{1}{n}$. However, I don't know how to solve this recurrence relation, either. So these are my questions: For closed rolls, how do I find the probability of $n$ successes? I've looked at existing probability tables (PDF), but they don't actually contain the math for their generation, and it's non-intuitive to discern from the table. Edit: See above; the binomial formula applies. For open rolls, can the closed roll formula be applied to a non-integer number $\frac{6n}{5}$? Edit: No. See above; the binomial formula uses combinations, thus requires integer numbers. So, how do I solve the closed roll recurrence relation and/or find the open probability?","I'm trying to compute the probability of achieving a certain number of successes when rolling a die pool for both open-ended/exploding and closed tests. Success is defined as a roll above a certain (variable) threshold. If a roll is open-ended, any die which rolls the maximum value triggers an additional die to be rolled. This is for a role-playing game (Burning Wheel Gold). Assume the use of a $n$-sided die. Additionally, we assume $d$ to be the number of dice, $r$ to be the required number of successes, and $c$ to be the minimum value accepted as a success. I'm breaking the question down into two blocks: one for open-ended rolls, and one for closed rolls. Closed roll: For closed rolls, we can define a probability recurrence as follows: $$Pr\left[r,d\right] = \begin{cases} \\1-\frac{c}{n}:Pr\left[d-1,r\right]\\\frac{c}{n}:Pr\left[d-1,r-1\right] \end{cases}$$ With probability $\frac{c}{n}$, a success will be met. However, I'm not sure how to solve this recurrence relation for any number of dice/required successes. There's probably an easier way to do this, but I haven't done much discrete probability. Edit: It looks like a binomial probability distribution works for this part of the problem. This comes in the form of: $${{d}\choose{r}}\left(\frac{c}{n}\right)^{r}\left(1-\frac{c}{n}\right)^{d-r}$$ Open ended roll: For open-ended rolls, we can find the equivalent number of rolled dice. This is going to be equal to: $$d+\sum_{j=1}^{\infty}\left(\frac{d}{6^{j}} \right)=\frac{6d}{5}$$ This implies that, given a number of dice $n$, rolling open-ended results in approximately $\frac{6}{5}n$ dice rolled. If we had an easy way to solve the above for any number of dice $n$, it would be easy: we could just input the non-integer value $n$ and get our result. However, since the above is defined with a recurrence relation is a binomial distribution, and thus uses combinations, it won't work for a non-integer number. Thus, we can define a probability recurrence relation as follows: $$Pr\left[ r,d\right] = \begin{cases} \\1-\frac{c}{n}:Pr\left[d-1,r\right]\\\frac{c-1}{n}:Pr\left[d-1,r-1\right]\\\frac{1}{n}:Pr\left[d,r-1\right] \end{cases}$$ The probability of no significant result is $1-\frac{c}{n}$, the probability of a regular success is $\frac{c-1}{n}$, and the probability of an 'exploding' or open-ended result is $\frac{1}{n}$. However, I don't know how to solve this recurrence relation, either. So these are my questions: For closed rolls, how do I find the probability of $n$ successes? I've looked at existing probability tables (PDF), but they don't actually contain the math for their generation, and it's non-intuitive to discern from the table. Edit: See above; the binomial formula applies. For open rolls, can the closed roll formula be applied to a non-integer number $\frac{6n}{5}$? Edit: No. See above; the binomial formula uses combinations, thus requires integer numbers. So, how do I solve the closed roll recurrence relation and/or find the open probability?",,['probability']
97,Analogue of the Schwartz–Zippel lemma for subspaces,Analogue of the Schwartz–Zippel lemma for subspaces,,"Let $f : \mathbb{R}^n \to \mathbb{R}$ be a nonzero multivariate polynomial of total degree $d$ over the reals, and $S \subset \mathbb{R}$ be finite.  Pick a positive integer $k$, choose $y_1, \ldots, y_k$ randomly and uniformly from $S^n$, and consider the $k$-variable polynomial $$g(t_1, \ldots, t_k) = f(t_1 y_1 + \cdots + t_k y_k)$$ Question : Is there a nice upper bound on the probability that $g(t)$ is the zero polynomial? This is similar to the Schwartz-Zippel lemma , but instead of picking a single point we pick a random linear subspace.  Indeed, if $k = 1$, $f$ is homogeneous, and $0 \notin S$, it is exactly the Schwartz-Zippel lemma, and we have $$Pr(g=0) \le \frac{d}{|S|}$$ For general $k$, allowing only one $t_i$ to be nonzero at a time gives $$Pr(g=0) \le \frac{d^k}{|S|^k}$$ However, this bound seems very weak, since it ignores all the cross terms in $g$, so hopefully a much stronger bound exists.","Let $f : \mathbb{R}^n \to \mathbb{R}$ be a nonzero multivariate polynomial of total degree $d$ over the reals, and $S \subset \mathbb{R}$ be finite.  Pick a positive integer $k$, choose $y_1, \ldots, y_k$ randomly and uniformly from $S^n$, and consider the $k$-variable polynomial $$g(t_1, \ldots, t_k) = f(t_1 y_1 + \cdots + t_k y_k)$$ Question : Is there a nice upper bound on the probability that $g(t)$ is the zero polynomial? This is similar to the Schwartz-Zippel lemma , but instead of picking a single point we pick a random linear subspace.  Indeed, if $k = 1$, $f$ is homogeneous, and $0 \notin S$, it is exactly the Schwartz-Zippel lemma, and we have $$Pr(g=0) \le \frac{d}{|S|}$$ For general $k$, allowing only one $t_i$ to be nonzero at a time gives $$Pr(g=0) \le \frac{d^k}{|S|^k}$$ However, this bound seems very weak, since it ignores all the cross terms in $g$, so hopefully a much stronger bound exists.",,"['probability', 'polynomials']"
98,How do factor graph and sum-product algorithm work?,How do factor graph and sum-product algorithm work?,,I'm reading a tutorial on factor graph and its sum-product algorithm. The tutorial is at http://www.isiweb.ee.ethz.ch/papers/arch/aloe-2004-spmagffg.pdf . What I don't understand is the example on page 19. I don't know how they come up with these number! Could you please help me understand where the numbers come from? Thank you.,I'm reading a tutorial on factor graph and its sum-product algorithm. The tutorial is at http://www.isiweb.ee.ethz.ch/papers/arch/aloe-2004-spmagffg.pdf . What I don't understand is the example on page 19. I don't know how they come up with these number! Could you please help me understand where the numbers come from? Thank you.,,['probability']
99,what does $\alpha(N)$ mean in this article?,what does  mean in this article?,\alpha(N),"I'm trying to understand this article: https://i.sstatic.net/Tw6mM.jpg but I'm unsure what $\alpha(N)$ means in this context? Is it the algebraic multiplicity, that's pretty much the only $\alpha$ I have ever seen, but how does this make sense here? Also what is $o(N)$","I'm trying to understand this article: https://i.sstatic.net/Tw6mM.jpg but I'm unsure what $\alpha(N)$ means in this context? Is it the algebraic multiplicity, that's pretty much the only $\alpha$ I have ever seen, but how does this make sense here? Also what is $o(N)$",,"['probability', 'notation']"
