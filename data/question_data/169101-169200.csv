,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,how to properly calculate difference in percent,how to properly calculate difference in percent,,"Suppose, you have x=8 y=10 Then y is 25% more than x, if x is used as the ""base"" value. If y ist the base, then x is 20% less than y. So if I want to say, that the difference between x and y is ... percent, what value could I use? I can think of using 22.5% being in the middle between 20% and 25%, but that does not feel well-founded. Should I not use percentages at all?","Suppose, you have x=8 y=10 Then y is 25% more than x, if x is used as the ""base"" value. If y ist the base, then x is 20% less than y. So if I want to say, that the difference between x and y is ... percent, what value could I use? I can think of using 22.5% being in the middle between 20% and 25%, but that does not feel well-founded. Should I not use percentages at all?",,['statistics']
1,Statistics Confidence Intervals,Statistics Confidence Intervals,,"True or false: a) The center of a 95% CI for the population mean is a random variable? d) Out of 100 95% CI for the mean $\mu$, 95 will contain the mean $\mu$?","True or false: a) The center of a 95% CI for the population mean is a random variable? d) Out of 100 95% CI for the mean $\mu$, 95 will contain the mean $\mu$?",,['statistics']
2,Integral with analytical solution with normal distribution,Integral with analytical solution with normal distribution,,"I received very good answers a couple of days ago in a simpler related problem, see Integral with Normal Distributions , but I am struggling with this new question: Let's define a function $F(\theta)=\int\limits_{-\infty}^{+\infty} \Phi  \left(\theta -a- b x\right) \phi\left(cx- \theta \right) \mathrm d x$ $\theta$ is a relevant parameter and $a$, $b$ and $c$ are all given scalars. $\Phi$ and $\phi$ respectively denote the CDF and PDF of the standard normal distribution I have two questions: Is there a way to express analytically this integral as a function of $\theta$, $a$, $b$ and $c$? (The case with $a=0$, $b=c=1$ is the one solved in the previous question) I want to find conditions on $a$, $b$ and $c$ that make $F'(\theta)<1$.","I received very good answers a couple of days ago in a simpler related problem, see Integral with Normal Distributions , but I am struggling with this new question: Let's define a function $F(\theta)=\int\limits_{-\infty}^{+\infty} \Phi  \left(\theta -a- b x\right) \phi\left(cx- \theta \right) \mathrm d x$ $\theta$ is a relevant parameter and $a$, $b$ and $c$ are all given scalars. $\Phi$ and $\phi$ respectively denote the CDF and PDF of the standard normal distribution I have two questions: Is there a way to express analytically this integral as a function of $\theta$, $a$, $b$ and $c$? (The case with $a=0$, $b=c=1$ is the one solved in the previous question) I want to find conditions on $a$, $b$ and $c$ that make $F'(\theta)<1$.",,"['statistics', 'integration', 'probability-distributions']"
3,Lottery chances,Lottery chances,,"What's statistically more likely to win you the UK lottery (6 numbers out of 1-49),  To play the lottery weekly or to save the money and buy multiple tickets  all in a oner? There is a discussion in the office where a group of 6 people want to play weekly.","What's statistically more likely to win you the UK lottery (6 numbers out of 1-49),  To play the lottery weekly or to save the money and buy multiple tickets  all in a oner? There is a discussion in the office where a group of 6 people want to play weekly.",,"['probability', 'statistics']"
4,binomial random variable,binomial random variable,,"Let $Y$ be a binomial random variable with $n$ trials and probability of success given by $p$. Show that $n-Y$ is a binomial random variable with $n$ trials and probability of success given by $1-p$. I understand why this is true, and can explain in logically, but I just don't know how to prove it in mathematical terms. Any help is greatly appreciated! Thanks!","Let $Y$ be a binomial random variable with $n$ trials and probability of success given by $p$. Show that $n-Y$ is a binomial random variable with $n$ trials and probability of success given by $1-p$. I understand why this is true, and can explain in logically, but I just don't know how to prove it in mathematical terms. Any help is greatly appreciated! Thanks!",,"['probability', 'statistics']"
5,Question from Fundamentals of Biostatistics,Question from Fundamentals of Biostatistics,,"Suppose we observe 84 alchoholics with cirrhosis of the liver, of whom 29 have hepatomas, that is, a liver-cell carcinoma. Suppose we know, based on a large sample, that the risk of hepatoma among alcoholics without cirrhosis of the liver is 24%. What is the probability that we observe exactly 29 alcoholics with cirrhosis of the liver who have hepatomas if the true rate of hepatoma among alcoholics (with or without cirrhosis of the liver) is .24?","Suppose we observe 84 alchoholics with cirrhosis of the liver, of whom 29 have hepatomas, that is, a liver-cell carcinoma. Suppose we know, based on a large sample, that the risk of hepatoma among alcoholics without cirrhosis of the liver is 24%. What is the probability that we observe exactly 29 alcoholics with cirrhosis of the liver who have hepatomas if the true rate of hepatoma among alcoholics (with or without cirrhosis of the liver) is .24?",,[]
6,"Is Cov (X,XY) positive if X,Y >0","Is Cov (X,XY) positive if X,Y >0",,"if X and Y are random variables which both only take values greater than 0 is their covariance $Cov(X,XY)>0$ . I was able to use the law of total covariance to get to: $Cov(X,XY)=E[Cov(X,XY|Y)]+Cov(E[X|Y],YE[X|Y])\\          \quad \quad \quad \quad \quad=E[Y Var(X|Y)]+Cov(E[X|Y],YE[X|Y])$ The first term is clearly +ve but i cannot figure out how to sign the second.",if X and Y are random variables which both only take values greater than 0 is their covariance . I was able to use the law of total covariance to get to: The first term is clearly +ve but i cannot figure out how to sign the second.,"Cov(X,XY)>0 Cov(X,XY)=E[Cov(X,XY|Y)]+Cov(E[X|Y],YE[X|Y])\\
         \quad \quad \quad \quad \quad=E[Y Var(X|Y)]+Cov(E[X|Y],YE[X|Y])","['probability', 'statistics', 'inequality', 'variance', 'covariance']"
7,How to determine which event is the conditional event?,How to determine which event is the conditional event?,,"I know generally conditional probability questions are presented in the form: ""What is the probability of Event A given Event B,"" and from there it can be written as: $P(A|B)$ However, how is that determined when the question doesn't explicitly state the given condition? For example, if we have a question such as, ""What is the probability that a randomly selected baseball player is a pitcher who voted ""Yes"" on the team questionnaire?"" Would it be $P($ Pitcher | Voted Yes $)$ or $P($ Voted Yes| Pitcher $)$ Thank you!","I know generally conditional probability questions are presented in the form: ""What is the probability of Event A given Event B,"" and from there it can be written as: However, how is that determined when the question doesn't explicitly state the given condition? For example, if we have a question such as, ""What is the probability that a randomly selected baseball player is a pitcher who voted ""Yes"" on the team questionnaire?"" Would it be Pitcher | Voted Yes or Voted Yes| Pitcher Thank you!",P(A|B) P( ) P( ),"['probability', 'statistics', 'conditional-probability']"
8,Inequality of entropies for Bernoulli plus Gaussian,Inequality of entropies for Bernoulli plus Gaussian,,"Question: Given $X\sim\text{Bernoulli}(\alpha)$ , $Y\sim\mathcal{N}(0,1)$ , and two non-random constants $C_1$ and $C_2$ such that $C_1>C_2$ . What can we say about the inequality between the two differential entropies $H(C_1X+Y)$ and $H(C_2X+Y)$ ? I.e., is it true that $$ H(C_1X+Y)>H(C_2X+Y). $$ Fact: We know from here that differential entropy is shift invariant but is affected by scaling. Attempt: I am aware that for a single random variable $X$ alone, the entropy $H(X)$ is shift invariant. Hence we can rewrite $$ H(C_1X+Y)=H(\epsilon X+C_1X+Y), $$ for some $\epsilon$ . However, this is not a simple shift because we are shifting by a fraction of a random variable.","Question: Given , , and two non-random constants and such that . What can we say about the inequality between the two differential entropies and ? I.e., is it true that Fact: We know from here that differential entropy is shift invariant but is affected by scaling. Attempt: I am aware that for a single random variable alone, the entropy is shift invariant. Hence we can rewrite for some . However, this is not a simple shift because we are shifting by a fraction of a random variable.","X\sim\text{Bernoulli}(\alpha) Y\sim\mathcal{N}(0,1) C_1 C_2 C_1>C_2 H(C_1X+Y) H(C_2X+Y) 
H(C_1X+Y)>H(C_2X+Y).
 X H(X) 
H(C_1X+Y)=H(\epsilon X+C_1X+Y),
 \epsilon","['probability', 'statistics', 'inequality', 'information-theory', 'entropy']"
9,$E[(X+Y)^2Z^2]\ge E[X^2Z^2]$ when $E[(X+Y)^2]\ge E[X^2]$?,when ?,E[(X+Y)^2Z^2]\ge E[X^2Z^2] E[(X+Y)^2]\ge E[X^2],"Assume that $X,Y,Z$ are three mean-zero random variables, where $E[YX]=0$ , $E[YZ]=0$ , and $E[(X+Y)^2]\ge E[X^2]$ . Does it hold that $E[(X+Y)^2Z^2]\ge E[X^2Z^2]$ ? I know that it holds when $(X,Y,Z)$ follows a multivariate Gaussian distribution, but does it hold for non-Gaussian cases? update: If further assume $ùê∏[ùëãùëç]‚â†0$ , does it hold that $E[(X+Y)^2Z^2]\ge E[X^2Z^2]$ ?","Assume that are three mean-zero random variables, where , , and . Does it hold that ? I know that it holds when follows a multivariate Gaussian distribution, but does it hold for non-Gaussian cases? update: If further assume , does it hold that ?","X,Y,Z E[YX]=0 E[YZ]=0 E[(X+Y)^2]\ge E[X^2] E[(X+Y)^2Z^2]\ge E[X^2Z^2] (X,Y,Z) ùê∏[ùëãùëç]‚â†0 E[(X+Y)^2Z^2]\ge E[X^2Z^2]","['probability', 'statistics']"
10,Reference for the PDF of Gamma distribution,Reference for the PDF of Gamma distribution,,"Is there a well-known reference in statistics to cite that state the PDF of a gamma random variable $$f(x)= \frac{1}{\Gamma{(k) \theta^k}} x^{k-1} e^{-\frac{x}{\theta}}$$ with $\text{mean}= k \theta$ and $\text{variance} = k \theta^2$ also a reference for random variable transformation for the PDF and CDF transformation of variables, for example this relation: $$f_Y(y) = f_X(g^{-1}(y)) \left| \frac{\mathrm d}{\mathrm dy} g^{-1}(y) \right|$$ I am searching for a well known and cited references for these topics.","Is there a well-known reference in statistics to cite that state the PDF of a gamma random variable with and also a reference for random variable transformation for the PDF and CDF transformation of variables, for example this relation: I am searching for a well known and cited references for these topics.",f(x)= \frac{1}{\Gamma{(k) \theta^k}} x^{k-1} e^{-\frac{x}{\theta}} \text{mean}= k \theta \text{variance} = k \theta^2 f_Y(y) = f_X(g^{-1}(y)) \left| \frac{\mathrm d}{\mathrm dy} g^{-1}(y) \right|,"['probability', 'statistics', 'probability-distributions', 'reference-request', 'distribution-theory']"
11,How is P(GB) equal to the P(G)P(B)?,How is P(GB) equal to the P(G)P(B)?,,"I have read the Probability and Statistics for Engineering and the Sciences by Jay Devore, and then I got stuck at the example 3.12 (ch3 Discrete Random Variables and Probability Distributions) as following Starting at a fixed time, we observe the gender of each newborn child at a certain hospital until a boy (B) is born. Let p=P(B), assume that successive births are independent, and define the rv X by x=number of births observed. Then p(1) = P(X=1) = P(B) = p p(2) = P(X=2) = P(GB) = P(G)P(B) = (1-p)p ‚Ä¶ I am little curious and can not figure out that how(why) is P(GB) equal to P(G)P(B) ?","I have read the Probability and Statistics for Engineering and the Sciences by Jay Devore, and then I got stuck at the example 3.12 (ch3 Discrete Random Variables and Probability Distributions) as following Starting at a fixed time, we observe the gender of each newborn child at a certain hospital until a boy (B) is born. Let p=P(B), assume that successive births are independent, and define the rv X by x=number of births observed. Then p(1) = P(X=1) = P(B) = p p(2) = P(X=2) = P(GB) = P(G)P(B) = (1-p)p ‚Ä¶ I am little curious and can not figure out that how(why) is P(GB) equal to P(G)P(B) ?",,"['probability', 'statistics', 'statistical-inference']"
12,What is the expected number of wins in this game?,What is the expected number of wins in this game?,,"Let's imagine a two player game where a player rolls a dice and then can keep the first score or decide to re-roll to get his/her final score. Is there a general formula for the average expected number of points against a player who does the 'common sense' thing and re-rolls if they get less than $\frac{n}{2}+1$ , where $n$ is the dice size.  Each player fixes their re-roll value before the game, it is then unchanged. e.g. 6 sided dice, 3 example games  (...means re-rolls and uses second roll).  player 1 re-rolls if the score is less than 4, r(1)=4.  player 2 re-rolls if the score is less than 5, r(2)=5. game 1)  player 1 rolls 2 ....5   player 2 rolls 3 ...1   result (5,1) 1 point to player 1 game 2)   player 1 rolls 4.    Player 2 rolls 4...5   result (4,5) 1 point to player 2 game 3)  player 1 rolls 6 .   Player 2 rolls 3 ...6   result (6,6) 0.5 points to both players Average score $1.5/3=0.5$ for each player The work done so far is in the answer section below, but it would be interesting if a general result for the expected average points could be found, in terms of the dice size $n$ , and re-roll if the score is less than $r_1$ for player 1 and $r_2$ for player 2.","Let's imagine a two player game where a player rolls a dice and then can keep the first score or decide to re-roll to get his/her final score. Is there a general formula for the average expected number of points against a player who does the 'common sense' thing and re-rolls if they get less than , where is the dice size.  Each player fixes their re-roll value before the game, it is then unchanged. e.g. 6 sided dice, 3 example games  (...means re-rolls and uses second roll).  player 1 re-rolls if the score is less than 4, r(1)=4.  player 2 re-rolls if the score is less than 5, r(2)=5. game 1)  player 1 rolls 2 ....5   player 2 rolls 3 ...1   result (5,1) 1 point to player 1 game 2)   player 1 rolls 4.    Player 2 rolls 4...5   result (4,5) 1 point to player 2 game 3)  player 1 rolls 6 .   Player 2 rolls 3 ...6   result (6,6) 0.5 points to both players Average score for each player The work done so far is in the answer section below, but it would be interesting if a general result for the expected average points could be found, in terms of the dice size , and re-roll if the score is less than for player 1 and for player 2.",\frac{n}{2}+1 n 1.5/3=0.5 n r_1 r_2,"['probability', 'statistics']"
13,Chaces of get $b$ points throwing dices of set $D$,Chaces of get  points throwing dices of set,b D,"I'm currently working on a casino game involving throwing different dice. To adjust the fair pay of each play, I'm trying to develop the formula that describes this scenario: Number of combinations that result in a total point sum of $b$ , knowing that I will throw the dice of a certain set $D = \left\{(d_1, d_2) \mid d_1 = \text{number of dice}, d_2 = \text{number of sides}\right\}$ . Notice that my question is not about throwing just one kind of die (which I know is already solved in this site). I want to describe the chances of a scenario where the player can choose to use any number of dice each with different number of sides in the same throw . In other words, given any combination of dice (for example, let's say I throw $n_4$ dice of $4$ sides, $n_6$ dice of $6$ sides and $n_8$ dice of $8$ sides), how can I calculate the total combinations of throws that results in a total sum of $b$ , for $b = n_4+n_6+n_8, \dots, 4n_46n_68n_8$ ? My work so far: I've noticed that the combinations follow some way of triangular pattern. For example, let's say I throw 2 dice of 6 faces. Then the combinations for each sum are: $2$ : $\{(1,1)\}$ $3$ : $\{(1,2),(2,1)\}$ $4$ : $\{(1,3),(2,2),(3,1)\}$ $5$ : $\{(1,4),(2,3),(3,2),(4,1)\}$ $6$ : $\{(1,5),(2,4),(3,3),(4,2),(5,1)\}$ $7$ : $\{(1,6),(2,5),(3,4),(4,3),(5,2),(6,1)\}$ $8$ : $\{(2,6),(3,5),(4,4),(5,3),(6,2)\}$ $9$ : $\{(3,6),(4,5),(5,4),(6,3)\}$ $10$ : $\{(4,6),(5,5),(6,4)\}$ $11$ : $\{(5,6),(6,5)\}$ $12$ : $\{(6,6)\}$ So for throws where there are just one kind of die (the number of sides is constant) I already have a formula. My problem is defining this rule for different types of die in the same throw. I noticed it always follows a similar triangular like distribution, but it's just not a perfect triangle (like it is when throwing all similar dices). In that case, there were three numbers for which the total number of combinations was max (instead of one or two). Is there a formula for this expression? Any help or hint will be appreciated. Edit: after reading a response from a user, I'm also interested of a solution to the problem where the number is obtained from multiplying the points obtained in each die (instead of adding).","I'm currently working on a casino game involving throwing different dice. To adjust the fair pay of each play, I'm trying to develop the formula that describes this scenario: Number of combinations that result in a total point sum of , knowing that I will throw the dice of a certain set . Notice that my question is not about throwing just one kind of die (which I know is already solved in this site). I want to describe the chances of a scenario where the player can choose to use any number of dice each with different number of sides in the same throw . In other words, given any combination of dice (for example, let's say I throw dice of sides, dice of sides and dice of sides), how can I calculate the total combinations of throws that results in a total sum of , for ? My work so far: I've noticed that the combinations follow some way of triangular pattern. For example, let's say I throw 2 dice of 6 faces. Then the combinations for each sum are: : : : : : : : : : : : So for throws where there are just one kind of die (the number of sides is constant) I already have a formula. My problem is defining this rule for different types of die in the same throw. I noticed it always follows a similar triangular like distribution, but it's just not a perfect triangle (like it is when throwing all similar dices). In that case, there were three numbers for which the total number of combinations was max (instead of one or two). Is there a formula for this expression? Any help or hint will be appreciated. Edit: after reading a response from a user, I'm also interested of a solution to the problem where the number is obtained from multiplying the points obtained in each die (instead of adding).","b D = \left\{(d_1, d_2) \mid d_1 = \text{number of dice}, d_2 = \text{number of sides}\right\} n_4 4 n_6 6 n_8 8 b b = n_4+n_6+n_8, \dots, 4n_46n_68n_8 2 \{(1,1)\} 3 \{(1,2),(2,1)\} 4 \{(1,3),(2,2),(3,1)\} 5 \{(1,4),(2,3),(3,2),(4,1)\} 6 \{(1,5),(2,4),(3,3),(4,2),(5,1)\} 7 \{(1,6),(2,5),(3,4),(4,3),(5,2),(6,1)\} 8 \{(2,6),(3,5),(4,4),(5,3),(6,2)\} 9 \{(3,6),(4,5),(5,4),(6,3)\} 10 \{(4,6),(5,5),(6,4)\} 11 \{(5,6),(6,5)\} 12 \{(6,6)\}","['probability', 'combinatorics', 'statistics', 'combinations', 'dice']"
14,Brain Teaser: Card Drawing until One Color is eliminated,Brain Teaser: Card Drawing until One Color is eliminated,,"I just found such a quant interview question but could not find a similar post in StackExchange. The question is pasted below. Jane offers to play the following game with you. Starting with a standard deck of 52 cards, you take turns drawing two cards. Jane goes first. If the two cards are black, Jane keeps them. If the cards are red, you keep them. If there is one red and one black card, the cards are discarded. When you have gone through the deck, you and Jane combine your cards, shuffle them, and resume, playing until one of the colors is eliminated. If there are red cards remaining, you win $100. What is a fair price to pay to play this game?","I just found such a quant interview question but could not find a similar post in StackExchange. The question is pasted below. Jane offers to play the following game with you. Starting with a standard deck of 52 cards, you take turns drawing two cards. Jane goes first. If the two cards are black, Jane keeps them. If the cards are red, you keep them. If there is one red and one black card, the cards are discarded. When you have gone through the deck, you and Jane combine your cards, shuffle them, and resume, playing until one of the colors is eliminated. If there are red cards remaining, you win $100. What is a fair price to pay to play this game?",,"['probability', 'statistics']"
15,"If 12 dice are rolled, what is the probablity that the minimum value of the 12 dice is 2?","If 12 dice are rolled, what is the probablity that the minimum value of the 12 dice is 2?",,"Here is how I tried solving it: First we need to make sure that we do not roll any 1s in the 12 rolls: $(5/6)^{12} ‚âà 0.1121$ We also need to make sure that at least one of the rolls results in a 2 or higher. The probability of rolling a 2 or higher on a single roll is $5/6$ . The probability of rolling at least one 2 or higher in 12 rolls is $1 - (1/6)^{12} ‚âà 0.9999$ . Therefore, the probability is $P = (5/6)^{12} \cdot 0.9999 ‚âà 0.1121$ , which is the wrong answer. I looked at this question previously asked, however all the answers seems to just use brute force to get all the values of the numerator because it only dealt with 2 dice. Any ideas on how to attempt to solve this problem would greatly be appreciated. Thanks!","Here is how I tried solving it: First we need to make sure that we do not roll any 1s in the 12 rolls: We also need to make sure that at least one of the rolls results in a 2 or higher. The probability of rolling a 2 or higher on a single roll is . The probability of rolling at least one 2 or higher in 12 rolls is . Therefore, the probability is , which is the wrong answer. I looked at this question previously asked, however all the answers seems to just use brute force to get all the values of the numerator because it only dealt with 2 dice. Any ideas on how to attempt to solve this problem would greatly be appreciated. Thanks!",(5/6)^{12} ‚âà 0.1121 5/6 1 - (1/6)^{12} ‚âà 0.9999 P = (5/6)^{12} \cdot 0.9999 ‚âà 0.1121,"['probability', 'sequences-and-series', 'statistics']"
16,Find marginal PDF from joint PDF bound issue,Find marginal PDF from joint PDF bound issue,,"Given the joined density function for x and y is $$f_{XY}(x,y)=\frac{5}{16}{xy^{2}}$$ $$0<x<y,  0<y<2$$ find the marginal density function of Y. I used: $$f_Y(y)=\int_{-\infty}^\infty f_{XY}(x,y) dx $$ $$=\int_0^2 \frac{5}{16}{xy^{2}} dx ‚Äã$$ but had a second thought about the bounds of x: should I use $\int_0^y$ instead of $\int_0^2$ since $0<x<y$ ? Why or why not? What is the standard approach/rules?",Given the joined density function for x and y is find the marginal density function of Y. I used: but had a second thought about the bounds of x: should I use instead of since ? Why or why not? What is the standard approach/rules?,"f_{XY}(x,y)=\frac{5}{16}{xy^{2}} 0<x<y,  0<y<2 f_Y(y)=\int_{-\infty}^\infty f_{XY}(x,y) dx  =\int_0^2 \frac{5}{16}{xy^{2}} dx ‚Äã \int_0^y \int_0^2 0<x<y","['integration', 'statistics', 'probability-distributions']"
17,"Using Central Limit Theorem, find the probability that the average lifetime?","Using Central Limit Theorem, find the probability that the average lifetime?",,"The lifetime of a certain electronic component is a random variable with the expectation of 5000 hours and a standard deviation of $200$ hours. Using Central Limit Theorem, find the probability that the average lifetime of $100$ components is less than $4650$ hours? Let $X$ be a random variable which represents the lifetime if certain electronic components with mean of $500$ hours & standard deviation $200$ hours. $\mu=5000 $ hours $, \sigma= 200$ hours , n = $100$ . My main question is for the Standard Normal Distribution do I use the formula .A Standard Normal variable, usually denoted by Z, can be obtained from a non-standard Normal( $Œº, œÉ)$ random variable X by standardizing, that is, subtracting the mean and dividing by the standard deviation,Using these transformations, any Normal random variable can be obtained from a Standard Normal variable Z; therefore, we need a table of Standard Normal Distribution only Table. $$Z= \frac{X-\mu}{\sigma}\\ X = Œº + œÉZ.$$ or do I use $$Z = \frac{xÃÑ -\mu}{\frac{\sigma}{\sqrt{n}}}\\ $$ . Depending on the selected formula the answer changes accordingly..... Any advise?","The lifetime of a certain electronic component is a random variable with the expectation of 5000 hours and a standard deviation of hours. Using Central Limit Theorem, find the probability that the average lifetime of components is less than hours? Let be a random variable which represents the lifetime if certain electronic components with mean of hours & standard deviation hours. hours hours , n = . My main question is for the Standard Normal Distribution do I use the formula .A Standard Normal variable, usually denoted by Z, can be obtained from a non-standard Normal( random variable X by standardizing, that is, subtracting the mean and dividing by the standard deviation,Using these transformations, any Normal random variable can be obtained from a Standard Normal variable Z; therefore, we need a table of Standard Normal Distribution only Table. or do I use . Depending on the selected formula the answer changes accordingly..... Any advise?","200 100 4650 X 500 200 \mu=5000  , \sigma= 200 100 Œº, œÉ) Z= \frac{X-\mu}{\sigma}\\ X = Œº + œÉZ. Z = \frac{xÃÑ -\mu}{\frac{\sigma}{\sqrt{n}}}\\ ","['probability', 'statistics', 'central-limit-theorem']"
18,"Suppose that $X_1$ and $X_2$ are independent. $Y_1=\max\{X_1, X_2\}$ and $Y=\min\{X_1, X_2\}$. Find the joint pdf of $(Y_1, Y_2)$. [duplicate]",Suppose that  and  are independent.  and . Find the joint pdf of . [duplicate],"X_1 X_2 Y_1=\max\{X_1, X_2\} Y=\min\{X_1, X_2\} (Y_1, Y_2)","This question already has an answer here : Joint distribution of $\min(X_1,\ldots,X_n)$ and $\max(X_1,\ldots,X_n)$. (1 answer) Closed last year . Suppose that $X_1$ and $X_2$ are independent with common pdf $f(x)$ and cdf $F(x)$ . $Y_1=\max\{X_1, X_2\}$ and $Y=\min\{X_1, X_2\}$ . Find the joint pdf of $(Y_1, Y_2)$ . My solution: I have no idea about the pdf of $(Y_1, Y_2)$ but I can find the cdf and pdf of $Y_1$ , $Y_2$ : $$ P(Y_1\le y_1)=F(y_1)^2 $$ and then $f_{Y_1}(y_1)=2F(y_1)f(y_1)$ for $y_1\in A$ . Similarly, $$ P(Y_2\le y_2)=1-(1-F(y_2))^2 $$ and then $f_{Y_2}(y_2)=2(1-F(y_2))f(y_2)$ for $y_2\in A$ . How to go the next step? Update: $$ P(\max\{X_1, X_2\}\le x_1, \min\{X_1, X_2\}\le x_2)=1-P(\max\{X_1, X_2\}\le x_1, \min\{X_1, X_2\}> x_2) $$ $$ =1-P(X_1\le x_1, X_2\le x_1, X_1>x_2, X_2> x_2) $$ When $x_1>x_2$ , we get $$ =1-(F(x_1)-F(x_2))^2 $$","This question already has an answer here : Joint distribution of $\min(X_1,\ldots,X_n)$ and $\max(X_1,\ldots,X_n)$. (1 answer) Closed last year . Suppose that and are independent with common pdf and cdf . and . Find the joint pdf of . My solution: I have no idea about the pdf of but I can find the cdf and pdf of , : and then for . Similarly, and then for . How to go the next step? Update: When , we get","X_1 X_2 f(x) F(x) Y_1=\max\{X_1, X_2\} Y=\min\{X_1, X_2\} (Y_1, Y_2) (Y_1, Y_2) Y_1 Y_2 
P(Y_1\le y_1)=F(y_1)^2
 f_{Y_1}(y_1)=2F(y_1)f(y_1) y_1\in A 
P(Y_2\le y_2)=1-(1-F(y_2))^2
 f_{Y_2}(y_2)=2(1-F(y_2))f(y_2) y_2\in A 
P(\max\{X_1, X_2\}\le x_1, \min\{X_1, X_2\}\le x_2)=1-P(\max\{X_1, X_2\}\le x_1, \min\{X_1, X_2\}> x_2)
 
=1-P(X_1\le x_1, X_2\le x_1, X_1>x_2, X_2> x_2)
 x_1>x_2 
=1-(F(x_1)-F(x_2))^2
","['probability', 'statistics']"
19,Variance of sum of cards with and without replacement,Variance of sum of cards with and without replacement,,"Suppose we draw 2 cards from a standard 52 card deck with value 1 - 13 (from Ace to King). How would expected values and variance compare with or without replacement? $E[X] = 14$ for both cases (linearity of expectation) $Var(X) = E[X^2] - E[X]^2$ however this seems like it would take incredibly long to compute for all the possible sums, is this the right approach? Would the variances even be different?","Suppose we draw 2 cards from a standard 52 card deck with value 1 - 13 (from Ace to King). How would expected values and variance compare with or without replacement? for both cases (linearity of expectation) however this seems like it would take incredibly long to compute for all the possible sums, is this the right approach? Would the variances even be different?",E[X] = 14 Var(X) = E[X^2] - E[X]^2,"['probability', 'statistics', 'expected-value', 'variance', 'card-games']"
20,Understanding why a sequence of random variables is not identically distributed,Understanding why a sequence of random variables is not identically distributed,,Consider the sequence $(X_n)_n$ of mutually independent v.a. whose probability law is defined for $P(X_n=-\sqrt n)= P(X_n=\sqrt n)= \frac{1}{2}$ Why they are not identically distributed?,Consider the sequence of mutually independent v.a. whose probability law is defined for Why they are not identically distributed?,(X_n)_n P(X_n=-\sqrt n)= P(X_n=\sqrt n)= \frac{1}{2},"['probability', 'statistics', 'probability-distributions']"
21,"How do you ""guess"" a candidate for an UMVUE?","How do you ""guess"" a candidate for an UMVUE?",,"The following distribution is given $X \sim \operatorname{BIN}(1, p)$ , then $\mathbb{E}(X)=p$ and $\mathbb{V} \operatorname{ar}(X)=p(1-p)$ . The CRLB is computed with: $$ \begin{aligned} f(x ; p) &=p^x(1-p)^{1-x} \\ \ln f(x ; p) &=x \ln p+(1-x) \ln (1-p) \\ \frac{\partial}{\partial p} \ln f(x ; p) &=\frac{x}{p}-\frac{1-x}{1-p}=\frac{x-p}{p(1-p)} \\ \mathbb{E}\left(\frac{\partial}{\partial p} \ln f(X ; p)\right)^2 &=\mathbb{E}\left(\frac{X-p}{p(1-p)}\right)^2=\frac{\mathbb{E}(X-p)^2}{p^2(1-p)^2}=\frac{\operatorname{Var}(X)}{p^2(1-p)^2}=\frac{1}{p(1-p)} \end{aligned} $$ The CRLB is now obtained as $$ \frac{\left[\tau^{\prime}(p)\right]^2}{n \mathbb{E}\left(\frac{\partial}{\partial p} \ln f(X ; p)\right)^2}=\frac{1}{\frac{n}{p(1-p)}}=\frac{p(1-p)}{n} $$ The subsequent task is to find the UMVUE. Algebraically I know how to check wheter an estimator is an UMVUE, but I find it hard to do this the ""other way around"", so to come up with an UMVUE yourself. The following is a snippet from the solution manual. Looking at your answer for part (a) you should recognize that the CRLB coincides with $\operatorname{Var}(X) / n$ . As an educated guess we therefore try $\hat{p}=\bar{X}$ . First, from $\mathbb{E}(X)=p$ The ""educated guess"" part makes me uncomfortable, because there are so many possebilities to choose from. How do you know that you pick the right one? Feedback on this would be very much appreciated. Questions: Why is $p$ an educated guess? How to make an educated guess yourself? Do you have general advice to come up with an UMVUE yourself?","The following distribution is given , then and . The CRLB is computed with: The CRLB is now obtained as The subsequent task is to find the UMVUE. Algebraically I know how to check wheter an estimator is an UMVUE, but I find it hard to do this the ""other way around"", so to come up with an UMVUE yourself. The following is a snippet from the solution manual. Looking at your answer for part (a) you should recognize that the CRLB coincides with . As an educated guess we therefore try . First, from The ""educated guess"" part makes me uncomfortable, because there are so many possebilities to choose from. How do you know that you pick the right one? Feedback on this would be very much appreciated. Questions: Why is an educated guess? How to make an educated guess yourself? Do you have general advice to come up with an UMVUE yourself?","X \sim \operatorname{BIN}(1, p) \mathbb{E}(X)=p \mathbb{V} \operatorname{ar}(X)=p(1-p) 
\begin{aligned}
f(x ; p) &=p^x(1-p)^{1-x} \\
\ln f(x ; p) &=x \ln p+(1-x) \ln (1-p) \\
\frac{\partial}{\partial p} \ln f(x ; p) &=\frac{x}{p}-\frac{1-x}{1-p}=\frac{x-p}{p(1-p)} \\
\mathbb{E}\left(\frac{\partial}{\partial p} \ln f(X ; p)\right)^2 &=\mathbb{E}\left(\frac{X-p}{p(1-p)}\right)^2=\frac{\mathbb{E}(X-p)^2}{p^2(1-p)^2}=\frac{\operatorname{Var}(X)}{p^2(1-p)^2}=\frac{1}{p(1-p)}
\end{aligned}
 
\frac{\left[\tau^{\prime}(p)\right]^2}{n \mathbb{E}\left(\frac{\partial}{\partial p} \ln f(X ; p)\right)^2}=\frac{1}{\frac{n}{p(1-p)}}=\frac{p(1-p)}{n}
 \operatorname{Var}(X) / n \hat{p}=\bar{X} \mathbb{E}(X)=p p",['statistics']
22,Minimum Probability of Intersection of 3 events theory,Minimum Probability of Intersection of 3 events theory,,"Say you have $P(A) = P(B) = P(C) = 0.9$ , but they are not necessarily independent events. What is the minimum probability of $P(A ‚à© B ‚à© C)$ ? For example, we know that $P(A ‚à™ B) = P(A) + P(B) - P(A ‚à© B) \leq 1$ , so $P(A ‚à© B) \geq P(A) + P(B) - 1 = 0.9 + 0.9 -1 = 0.8$ So the min probability of $P(A ‚à© B)$ is $0.8$ I can only find the maximum probability being $0.8$ because $P(A ‚à© B ‚à© C) \leq P(A ‚à© B), P(B ‚à© C), P(A ‚à© C) = 0.8$ The working I've done so far: $0 \leq P(A ‚à™ B ‚à™  C) \leq1$ $0 \leq P(A) + P(B) +P(C) - P(A ‚à© B) - P(A ‚à© C) - P(B ‚à© C) + P(A‚à©B‚à©C) \leq 1$ $-2.7 \leq P(A ‚à© B ‚à© C) - P(A ‚à© B) -  P(A ‚à© C) -  P(B ‚à© C) \leq -1.7$ $1.7 \leq P(A ‚à© B) +  P(A ‚à© C) + P(B ‚à© C) - P(A ‚à© B ‚à© C) \leq 2.7$ $P(A ‚à© B ‚à© C) + 2.7 \geq P(A ‚à© B) +  P(A ‚à© C) + P(B ‚à© C)$ $P(A ‚à© B ‚à© C) \geq P(A ‚à© B) +  P(A ‚à© C) + P(B ‚à© C) - 2.7$ Since, $0.8\leq P(A ‚à© B)\leq 0.9$ $2.4 \leq P(A ‚à© B) +  P(A ‚à© C) + P(B ‚à© C) \leq 2.7$ So $P(A ‚à© B ‚à© C) >= 2.4 - 2.7$ ? or $2.7 - 2.7$ ? Which is just $0$ ?","Say you have , but they are not necessarily independent events. What is the minimum probability of ? For example, we know that , so So the min probability of is I can only find the maximum probability being because The working I've done so far: Since, So ? or ? Which is just ?","P(A) = P(B) = P(C) = 0.9 P(A ‚à© B ‚à© C) P(A ‚à™ B) = P(A) + P(B) - P(A ‚à© B) \leq 1 P(A ‚à© B) \geq P(A) + P(B) - 1 = 0.9 + 0.9 -1 = 0.8 P(A ‚à© B) 0.8 0.8 P(A ‚à© B ‚à© C) \leq P(A ‚à© B), P(B ‚à© C), P(A ‚à© C) = 0.8 0 \leq P(A ‚à™ B ‚à™  C) \leq1 0 \leq P(A) + P(B) +P(C) - P(A ‚à© B) - P(A ‚à© C) - P(B ‚à© C) + P(A‚à©B‚à©C) \leq 1 -2.7 \leq P(A ‚à© B ‚à© C) - P(A ‚à© B) -  P(A ‚à© C) -  P(B ‚à© C) \leq -1.7 1.7 \leq P(A ‚à© B) +  P(A ‚à© C) + P(B ‚à© C) - P(A ‚à© B ‚à© C) \leq 2.7 P(A ‚à© B ‚à© C) + 2.7 \geq P(A ‚à© B) +  P(A ‚à© C) + P(B ‚à© C) P(A ‚à© B ‚à© C) \geq P(A ‚à© B) +  P(A ‚à© C) + P(B ‚à© C) - 2.7 0.8\leq P(A ‚à© B)\leq 0.9 2.4 \leq P(A ‚à© B) +  P(A ‚à© C) + P(B ‚à© C) \leq 2.7 P(A ‚à© B ‚à© C) >= 2.4 - 2.7 2.7 - 2.7 0","['probability', 'statistics', 'optimization', 'conditional-probability']"
23,confidence interval in terms of the empirical CDF,confidence interval in terms of the empirical CDF,,"Recall that the cumulative distribution function (CDF) of X is defined as: $F(x)=P(w: X(w) \leq x)$ Using the sequence $(X_i)$ estimate the CDF F(x) using the empirical CDF: $$ \bar{F_n}(x) = \frac{1}{n} \sum_{i=1}^n \chi_{(-\infty, x)} (X_i). $$ For each fixed $x \in \mathbb {R}$ , show that $$ \mathbb {I}_{\alpha, n}(x)  = \left\{  y \in \mathbb {R}: \bar{F_n}(x)- \frac{1}{2 \sqrt{n \alpha}} \leq y \leq \bar{F_n}(x) + \frac{1}{2 \sqrt{n \alpha}} \right\} $$ is a $(1-\alpha) \times 100$ % confidence interval for F(x) in the sense that $P(w: F(x) \in \mathbb {I}_{\alpha, n}(x) \geq 1-\alpha)$ How to prove this statement? My attempt: I can convert the $$ \mathbb {I}_{\alpha, n}(x)  = \left\{  y \in \mathbb {R}: \bar{F_n}(x)- \frac{1}{2 \sqrt{n \alpha}} \leq y \leq \bar{F_n}(x) + \frac{1}{2 \sqrt{n \alpha}} \right\} $$ to $$ \mathbb {I}_{\alpha, n}(x)  = \left\{ ny- \frac{\sqrt{n}}{2 \sqrt{ \alpha}} \leq n\bar{F_n}(x) \leq ny+ \frac{\sqrt{n}}{2 \sqrt{ \alpha}}  \right\} $$ Then how to do next?","Recall that the cumulative distribution function (CDF) of X is defined as: Using the sequence estimate the CDF F(x) using the empirical CDF: For each fixed , show that is a % confidence interval for F(x) in the sense that How to prove this statement? My attempt: I can convert the to Then how to do next?","F(x)=P(w: X(w) \leq x) (X_i) 
\bar{F_n}(x) = \frac{1}{n} \sum_{i=1}^n \chi_{(-\infty, x)} (X_i).
 x \in \mathbb {R} 
\mathbb {I}_{\alpha, n}(x)
 = \left\{  y \in \mathbb {R}: \bar{F_n}(x)- \frac{1}{2 \sqrt{n \alpha}} \leq y \leq \bar{F_n}(x) + \frac{1}{2 \sqrt{n \alpha}} \right\}
 (1-\alpha) \times 100 P(w: F(x) \in \mathbb {I}_{\alpha, n}(x) \geq 1-\alpha) 
\mathbb {I}_{\alpha, n}(x)
 = \left\{  y \in \mathbb {R}: \bar{F_n}(x)- \frac{1}{2 \sqrt{n \alpha}} \leq y \leq \bar{F_n}(x) + \frac{1}{2 \sqrt{n \alpha}} \right\}
 
\mathbb {I}_{\alpha, n}(x)
 = \left\{ ny- \frac{\sqrt{n}}{2 \sqrt{ \alpha}} \leq n\bar{F_n}(x) \leq ny+ \frac{\sqrt{n}}{2 \sqrt{ \alpha}}  \right\}
","['statistics', 'confidence-interval']"
24,Function satisfying $F(a)-F(1)=F(1)-F(\frac{1}{a})$,Function satisfying,F(a)-F(1)=F(1)-F(\frac{1}{a}),"What continuous monotone increasing function has the property: $$F(a)-F(1)=F(1)-F(\frac{1}{a}) \space\space\space\space\space\space \forall a>1 $$ The context for this is that I'm looking for a continuous probability distribution on $(0,\infty)$ satisfying: $$P\left(1\le x\le a\right) = P\left(\frac{1}{a} \le x \le 1\right)$$",What continuous monotone increasing function has the property: The context for this is that I'm looking for a continuous probability distribution on satisfying:,"F(a)-F(1)=F(1)-F(\frac{1}{a}) \space\space\space\space\space\space \forall a>1  (0,\infty) P\left(1\le x\le a\right) = P\left(\frac{1}{a} \le x \le 1\right)","['statistics', 'functions', 'probability-distributions', 'statistical-inference', 'monotone-functions']"
25,approximating probability mass function from a large data,approximating probability mass function from a large data,,"I am learning elementary probability; especially I am interested in learning how to find probability mass functions and density functions from data. I think I perfectly understand the theory: For example, let's take $X$ as a random variable which takes values $1$ to $10$ with frequencies $4,4,5,5,6,10,3,3,4,6$ . I know how to calculate the relative frequency from this information, i.e. here $n=50$ data size. Now the approximate will be to perform this experiment sufficient amount of time, and then the relative frequencies converge to probabilities, and we have the distribution approximately. Now, let's say I have data for, let's say, the last five years, 2021 to 2016, where each day I have seen a number between $0$ to $50$ . Trials are independent. Based on this data, can I calculate $P[X=49]$ in $2022$ on a specific day? Thank you very much for helping me find out the PMF of such data.","I am learning elementary probability; especially I am interested in learning how to find probability mass functions and density functions from data. I think I perfectly understand the theory: For example, let's take as a random variable which takes values to with frequencies . I know how to calculate the relative frequency from this information, i.e. here data size. Now the approximate will be to perform this experiment sufficient amount of time, and then the relative frequencies converge to probabilities, and we have the distribution approximately. Now, let's say I have data for, let's say, the last five years, 2021 to 2016, where each day I have seen a number between to . Trials are independent. Based on this data, can I calculate in on a specific day? Thank you very much for helping me find out the PMF of such data.","X 1 10 4,4,5,5,6,10,3,3,4,6 n=50 0 50 P[X=49] 2022","['statistics', 'probability-distributions']"
26,Covariance of Bernoulli random variables,Covariance of Bernoulli random variables,,"Let $X_1,X_2,X_3,X_4\in\{-1,1\}$ be four independent Bernoulli random variables satisfying $\Pr[X_i=-1]=p=1-\Pr[X_i=1]$ . It is quite straightforward to calculate $\mathbb{E}[X_iX_j]=(1-2p)^2+\delta_{ij}4p(1-p)$ , where $\delta_{ij}=1$ if $i=j$ and $0$ otherwise. I would like to calculate $C=\mathbb{E}[X_iX_jX_kX_\ell]-\mathbb{E}[X_iX_j]\mathbb{E}[X_kX_\ell]$ for $i,j,k,\ell\in\{1,2,3,4\}$ . If $i=j$ or $k=\ell$ , then $C=0$ . If $i\neq j$ and $k\neq\ell$ , I have to enumerate various cases such as $i=k$ , $i\neq k$ , etc, but there are quite a few cases to consider. Is there an easy way to calculate $C$ ?","Let be four independent Bernoulli random variables satisfying . It is quite straightforward to calculate , where if and otherwise. I would like to calculate for . If or , then . If and , I have to enumerate various cases such as , , etc, but there are quite a few cases to consider. Is there an easy way to calculate ?","X_1,X_2,X_3,X_4\in\{-1,1\} \Pr[X_i=-1]=p=1-\Pr[X_i=1] \mathbb{E}[X_iX_j]=(1-2p)^2+\delta_{ij}4p(1-p) \delta_{ij}=1 i=j 0 C=\mathbb{E}[X_iX_jX_kX_\ell]-\mathbb{E}[X_iX_j]\mathbb{E}[X_kX_\ell] i,j,k,\ell\in\{1,2,3,4\} i=j k=\ell C=0 i\neq j k\neq\ell i=k i\neq k C","['probability', 'statistics', 'correlation', 'bernoulli-distribution']"
27,Variance of product of Gaussian random variables,Variance of product of Gaussian random variables,,"Suppose I have $r = [r_1, r_2, ..., r_n]$ , which are iid and follow normal distribution of $N(\mu, \sigma^2)$ , then I have weight vector of $h = [h_1, h_2,  ...,h_n]$ , which iid followed $N(0, \sigma_h^2)$ , how can I calculate the $Var(\Sigma_i^nh_ir_i)$ ? suppose $h, r$ independent. How should I deal with the product of two random variables, what is the formula to expand it, I am a bit confused.","Suppose I have , which are iid and follow normal distribution of , then I have weight vector of , which iid followed , how can I calculate the ? suppose independent. How should I deal with the product of two random variables, what is the formula to expand it, I am a bit confused.","r = [r_1, r_2, ..., r_n] N(\mu, \sigma^2) h = [h_1, h_2,  ...,h_n] N(0, \sigma_h^2) Var(\Sigma_i^nh_ir_i) h, r","['statistics', 'random-variables', 'normal-distribution', 'variance']"
28,Finding a confidence interval for a binomial proportion without knowing the mean or variance?,Finding a confidence interval for a binomial proportion without knowing the mean or variance?,,"I'm just learning statistics and I've been given an interesting problem to solve that I'm unsure how to approach. I've dealt with various tests (t-test, chisq test, confidence intervals etc.) but I'm unsure how to apply it to this problem. Given 20,000 products, we take a random sample of 320 products and find that 59 of them are faulty. Identify with 95% confidence the confidence interval of the ratio of faulty products. Since this is all the information we have, I don't know the mean or variance since this was a single trial, or do we assume mean to be 59 and variance 0?.. I've never dealt with this kind of problem before, and I believe I may be overthinking it.","I'm just learning statistics and I've been given an interesting problem to solve that I'm unsure how to approach. I've dealt with various tests (t-test, chisq test, confidence intervals etc.) but I'm unsure how to apply it to this problem. Given 20,000 products, we take a random sample of 320 products and find that 59 of them are faulty. Identify with 95% confidence the confidence interval of the ratio of faulty products. Since this is all the information we have, I don't know the mean or variance since this was a single trial, or do we assume mean to be 59 and variance 0?.. I've never dealt with this kind of problem before, and I believe I may be overthinking it.",,"['statistics', 'confidence-interval']"
29,What are the chances of rolling 2 dice 43 times without rolling a 7?,What are the chances of rolling 2 dice 43 times without rolling a 7?,,"Forgive my very long explanation.  I play craps and I attempt to make my throws less random. I track my throws and collect data from sets of 900 throws.  Obviously, a random thrower is likely to throw around 150 sevens every 900 rolls.  My last set of 900 rolls I rolled 113 sevens or a seven every 7.96 rolls.  The 900 rolls prior to that I rolled 123 sevens or a seven every 7.32 rolls. Obviously. the math will not work out to be the odds of rolling 43 times in a single turn as a player may throw a seven on a come out roll after making the point. I am asking specifically about 43 rolls with no sevens as I recently went to the casino for the first time since the COVID restrictions began.  My first turn I threw 43 times with my first seven on my 44th throw. I hope you made it through my long explanation.  Thank you.","Forgive my very long explanation.  I play craps and I attempt to make my throws less random. I track my throws and collect data from sets of 900 throws.  Obviously, a random thrower is likely to throw around 150 sevens every 900 rolls.  My last set of 900 rolls I rolled 113 sevens or a seven every 7.96 rolls.  The 900 rolls prior to that I rolled 123 sevens or a seven every 7.32 rolls. Obviously. the math will not work out to be the odds of rolling 43 times in a single turn as a player may throw a seven on a come out roll after making the point. I am asking specifically about 43 rolls with no sevens as I recently went to the casino for the first time since the COVID restrictions began.  My first turn I threw 43 times with my first seven on my 44th throw. I hope you made it through my long explanation.  Thank you.",,"['probability', 'statistics', 'dice']"
30,Find maximum likelihood estimator of $f(x;\theta)=\frac{1}{\theta^2}xe^{\frac{-x}{\theta}}$,Find maximum likelihood estimator of,f(x;\theta)=\frac{1}{\theta^2}xe^{\frac{-x}{\theta}},Find maximum likelihood estimator of $\hat{\theta}$ given the pdf $f(x;\theta)=\frac{1}{\theta^2}xe^{\frac{-x}{\theta}}$ I'm stuck on solving this one out. The answer is given as $\frac{\bar{X}}{2}$ in the answer sheet. I think I'm suppose to get to $\hat{\theta}=\frac{\left(\sum _{i=1}^nx_i\:\right)}{2n}=\frac{\bar{X}}{2}$ . I'm having a hard time getting there though. I've done a few problems like this and I found the estimator successfully but this one is giving me a hard time. I think I'm making some computational error somewhere which is causing the problem. Here are the equations I get when I solve them out: (I think I'm doing a computation wrong and it's causing issues maybe) $L(\theta)=\frac{1}{\theta ^{2n}}\cdot e^{\sum _{i=1}^n-\frac{x_i}{\theta }\:}\cdot \left(x_1\cdot x_2\cdot .....\cdot x_n\right)$ $ln\left(L\left(\theta \right)\right)=ln\left(\frac{1}{\theta ^{2n}}\cdot e^{\sum _{i=1}^n-\frac{x_i}{\theta }\:}\cdot \left(x_1\cdot x_2\cdot .....\cdot x_n\right)\right)$ $=-2nln\left(\theta \right)-\sum _{i=1}^n\frac{x_i}{\theta }+ln\left(x_1\cdot x_2\cdot ....\cdot x_n\right)\:$ $\frac{d}{d\theta }\left(L\left(\theta \right)\right)=\frac{d}{d\theta }\left(-2nln\left(\theta \right)-\sum _{i=1}^n\frac{x_i}{\theta }+ln\left(x_1\cdot x_2\cdot ....\cdot x_n\right)\right)\:=0$ $\frac{d}{d\theta \:}\left(L\left(\theta \right)\right)=-\frac{2n}{\theta }-\frac{d}{d\theta }\left(\sum _{i=1}^n\:\frac{x_i}{\theta }\right)+\frac{1}{\left(x_1\cdot x_2\cdot ...\cdot x_n\right)}=0$ $-\frac{2n}{\theta }-\left(\sum _{i=1}^n\:\frac{x_i}{\theta }\right)+\frac{1}{\left(x_1\cdot \:x_2\cdot \:...\cdot \:x_n\right)}=0$ $-\frac{2n}{\theta }-\left(\sum _{i=1}^n\:\frac{x_i}{\theta }\right)=-\frac{1}{\left(x_1\cdot \:x_2\cdot \:...\cdot \:x_n\right)}$ $-\frac{1}{\theta }\left(2n+\sum \:_{i=1}^n\:x_i\right)=-\frac{1}{\left(x_1\cdot \:x_2\cdot \:...\cdot \:x_n\right)}$ $\left(2n+\sum \:_{i=1}^n\:x_i\right)=\frac{\theta }{\left(x_1\cdot \:x_2\cdot \:...\cdot \:x_n\right)}$ $\left(2n+\sum \:_{i=1}^n\:x_i\right)\left(x_1\cdot \:\:x_2\cdot ...\cdot \:\:x_n\right)=\theta $ And this is not what I'm suppose to get. I'm a bit out of practice with calculus so I'm not really sure where the error is and how to fix it.,Find maximum likelihood estimator of given the pdf I'm stuck on solving this one out. The answer is given as in the answer sheet. I think I'm suppose to get to . I'm having a hard time getting there though. I've done a few problems like this and I found the estimator successfully but this one is giving me a hard time. I think I'm making some computational error somewhere which is causing the problem. Here are the equations I get when I solve them out: (I think I'm doing a computation wrong and it's causing issues maybe) And this is not what I'm suppose to get. I'm a bit out of practice with calculus so I'm not really sure where the error is and how to fix it.,\hat{\theta} f(x;\theta)=\frac{1}{\theta^2}xe^{\frac{-x}{\theta}} \frac{\bar{X}}{2} \hat{\theta}=\frac{\left(\sum _{i=1}^nx_i\:\right)}{2n}=\frac{\bar{X}}{2} L(\theta)=\frac{1}{\theta ^{2n}}\cdot e^{\sum _{i=1}^n-\frac{x_i}{\theta }\:}\cdot \left(x_1\cdot x_2\cdot .....\cdot x_n\right) ln\left(L\left(\theta \right)\right)=ln\left(\frac{1}{\theta ^{2n}}\cdot e^{\sum _{i=1}^n-\frac{x_i}{\theta }\:}\cdot \left(x_1\cdot x_2\cdot .....\cdot x_n\right)\right) =-2nln\left(\theta \right)-\sum _{i=1}^n\frac{x_i}{\theta }+ln\left(x_1\cdot x_2\cdot ....\cdot x_n\right)\: \frac{d}{d\theta }\left(L\left(\theta \right)\right)=\frac{d}{d\theta }\left(-2nln\left(\theta \right)-\sum _{i=1}^n\frac{x_i}{\theta }+ln\left(x_1\cdot x_2\cdot ....\cdot x_n\right)\right)\:=0 \frac{d}{d\theta \:}\left(L\left(\theta \right)\right)=-\frac{2n}{\theta }-\frac{d}{d\theta }\left(\sum _{i=1}^n\:\frac{x_i}{\theta }\right)+\frac{1}{\left(x_1\cdot x_2\cdot ...\cdot x_n\right)}=0 -\frac{2n}{\theta }-\left(\sum _{i=1}^n\:\frac{x_i}{\theta }\right)+\frac{1}{\left(x_1\cdot \:x_2\cdot \:...\cdot \:x_n\right)}=0 -\frac{2n}{\theta }-\left(\sum _{i=1}^n\:\frac{x_i}{\theta }\right)=-\frac{1}{\left(x_1\cdot \:x_2\cdot \:...\cdot \:x_n\right)} -\frac{1}{\theta }\left(2n+\sum \:_{i=1}^n\:x_i\right)=-\frac{1}{\left(x_1\cdot \:x_2\cdot \:...\cdot \:x_n\right)} \left(2n+\sum \:_{i=1}^n\:x_i\right)=\frac{\theta }{\left(x_1\cdot \:x_2\cdot \:...\cdot \:x_n\right)} \left(2n+\sum \:_{i=1}^n\:x_i\right)\left(x_1\cdot \:\:x_2\cdot ...\cdot \:\:x_n\right)=\theta ,"['probability', 'statistics', 'solution-verification', 'maximum-likelihood', 'parameter-estimation']"
31,Symmetry of Conditional Distribution,Symmetry of Conditional Distribution,,"Suppose that $X_1, X_2, ..., X_n$ are independently and identically distributed random variables. What is $E(X_1 \mid X_1 + ... + X_n=t)$ ? The solution first tells me that By Symmetry, $$E(X_i \mid X_1 + ... + X_n=t) = E(X_j \mid X_1 + ... + X_n=t)$$ for all $i\neq j$ . Hence, $$E(X_1 \mid X_1 + ... + X_n=t) = \frac{1}{n}E(X_i \mid X_1 + ... + X_n)=t$$ May I know what the question means by symmetry here? My understanding of symmetry is when random variables are generally normally distributed on either side of the mean. Why would the condition of this distribution be symmetrical? Or did I miss out on some other concept? Any help would be greatly appreciated! Thank you!","Suppose that are independently and identically distributed random variables. What is ? The solution first tells me that By Symmetry, for all . Hence, May I know what the question means by symmetry here? My understanding of symmetry is when random variables are generally normally distributed on either side of the mean. Why would the condition of this distribution be symmetrical? Or did I miss out on some other concept? Any help would be greatly appreciated! Thank you!","X_1, X_2, ..., X_n E(X_1 \mid X_1 + ... + X_n=t) E(X_i \mid X_1 + ... + X_n=t) = E(X_j \mid X_1 + ... + X_n=t) i\neq j E(X_1 \mid X_1 + ... + X_n=t) = \frac{1}{n}E(X_i \mid X_1 + ... + X_n)=t","['probability', 'statistics', 'expected-value', 'conditional-expectation']"
32,Why mean is the balancing point?,Why mean is the balancing point?,,"4,5,7,12,34 are the data points. Median is 7. But, why mean would be the balancing point here? I know the mean distribute the data points evenly among individuals, which means if any individual would‚Äôve scored any point, he‚Äôd have scored the mean . But, I don‚Äôt understand this balancing point thing.","4,5,7,12,34 are the data points. Median is 7. But, why mean would be the balancing point here? I know the mean distribute the data points evenly among individuals, which means if any individual would‚Äôve scored any point, he‚Äôd have scored the mean . But, I don‚Äôt understand this balancing point thing.",,['statistics']
33,Robert didn‚Äôt sleep last night and now he is sitting for a multiple choice examination with ...,Robert didn‚Äôt sleep last night and now he is sitting for a multiple choice examination with ...,,Robert didn‚Äôt sleep last night and now he is sitting for a multiple choice examination with 20 questions. He fills in the answers on the bubble sheet randomly without reading the question and each question has 5 possible answers. A.) What is the probability that Robert gets exactly 10 questions right? $P(X=10) = \binom{20}{10}\left( \frac15\right)^{10}\cdot \left(\frac45\right)^{10} = 0.002$ B.) What is the probability that Robert gets two or more questions right? $P(x \ge 2) = 1 - P(x<2) = 1 - [P(x=0) + P(x=1)] = 0.9308$ c.) What is the expected value and variance of the number of questions Roberts gets right? $E(x) = 20(1/5) = 4$ $Var(x) = 20(1/5)(4/5) = 16/5$ Does my thought process seem correct or does my work or my answers seem off somewhere?,Robert didn‚Äôt sleep last night and now he is sitting for a multiple choice examination with 20 questions. He fills in the answers on the bubble sheet randomly without reading the question and each question has 5 possible answers. A.) What is the probability that Robert gets exactly 10 questions right? B.) What is the probability that Robert gets two or more questions right? c.) What is the expected value and variance of the number of questions Roberts gets right? Does my thought process seem correct or does my work or my answers seem off somewhere?,P(X=10) = \binom{20}{10}\left( \frac15\right)^{10}\cdot \left(\frac45\right)^{10} = 0.002 P(x \ge 2) = 1 - P(x<2) = 1 - [P(x=0) + P(x=1)] = 0.9308 E(x) = 20(1/5) = 4 Var(x) = 20(1/5)(4/5) = 16/5,"['statistics', 'solution-verification']"
34,Need help with Pearson criterion (chi-square) to check if the distribution is uniform,Need help with Pearson criterion (chi-square) to check if the distribution is uniform,,"Let's assume we have X - a random variable, and its values are 1, 2, and 3. We also have frequencies for each of the values, which equal to 51, 40, and 65 respectively. So, this will look like this: X 1 2 3 n 51 40 65 And the question is whether the variable X has uniform distribution. I am to use Pearson criterion to check it. I actually do know how to solve it, but I have stumbled across one problem: the number of degrees of freedom is equal to zero, hence, I cannot use tables with critical values for chi-squared, since there is no zero degrees of freedom. What do I do? Is it even possible at all to solve this task using this criterion?","Let's assume we have X - a random variable, and its values are 1, 2, and 3. We also have frequencies for each of the values, which equal to 51, 40, and 65 respectively. So, this will look like this: X 1 2 3 n 51 40 65 And the question is whether the variable X has uniform distribution. I am to use Pearson criterion to check it. I actually do know how to solve it, but I have stumbled across one problem: the number of degrees of freedom is equal to zero, hence, I cannot use tables with critical values for chi-squared, since there is no zero degrees of freedom. What do I do? Is it even possible at all to solve this task using this criterion?",,['statistics']
35,Implementing multiclass logistic regression from scratch,Implementing multiclass logistic regression from scratch,,"This is a sequel to a previous question about implementing binary logistic regression from scratch. Background knowledge: To train a logistic regression model for a classification problem with $K$ classes, we are given a training dataset consisting of feature vectors $x_1, x_2, \ldots, x_N \in \mathbb R^d$ and corresponding one-hot encoded label vectors $y_1, y_2, \ldots, y_N \in \mathbb R^K$ . If example $i$ belongs to class $k$ , then the label vector $y_i$ has a $1$ in the $k$ th position and zeros elsewhere. Our goal is to find vectors $\beta_1, \beta_2, \ldots, \beta_K \in \mathbb R^{d+1}$ such that $$ \tag{1} y_i \approx S\left(\begin{bmatrix} \hat x_i^T \beta_1 \\ \vdots \\ \hat x_i^T \beta_K \end{bmatrix} \right) \quad \text{for } i = 1, \ldots, N. $$ Here $\hat x_i \in \mathbb R^{d+1}$ is the ""augmented"" feature vector obtained by prepending a $1$ to the feature vector $x_i \in \mathbb R^d$ , and $S:\mathbb R^K \to \mathbb R^K$ is the softmax function defined by $$ S(u) = \begin{bmatrix} \frac{e^{u_1}}{e^{u_1} + \cdots + e^{u_K}} \\ \vdots \\ \frac{e^{u_K}}{e^{u_1} + \cdots + e^{u_K}} \end{bmatrix} \quad \text{for all vectors } u = \begin{bmatrix} u_1 \\ \vdots \\ u_K \end{bmatrix} \in \mathbb R^K. $$ The softmax function is useful in machine learning because it converts a vector into a ""probability vector"" (that is, a vector whose components are nonnegative and sum to $1$ ). Equation (1) can be expressed more concisely using vector and matrix notation as follows. Define $$ \beta = \begin{bmatrix} \beta_1 \\ \vdots \\ \beta_K \end{bmatrix} \in \mathbb R^{K(d+1)} \quad \text{and} \quad M_i = \begin{bmatrix} \hat x_i^T & & & \\ & \hat x_i^T & & \\ & & \ddots & \\ & & & \hat x_i^T \end{bmatrix} \in \mathbb R^{K \times K(d+1)}. $$ Then equation (1) says that we hope that $$ y_i \approx S(M_i \beta) \quad \text{for } i = 1, \ldots N. $$ I think of $S(M_i \beta) \in \mathbb R^K$ as being a ""predicted probability vector"" which tells you how strongly our model believes that example $i$ belongs to each of the $K$ classes. And $y_i$ is a ""ground truth"" probability vector which reflects certainty about which of the $K$ classes example $i$ belongs to. We will use the cross-entropy loss function $$ \ell(p,q) = \sum_{k=1}^K -p_k \log(q_k) $$ to measure how well a predicted probability vector $q \in \mathbb R^K$ agrees with a ground truth probability vector $p \in \mathbb R^K$ . Here $\log$ denotes the natural logarithm. The vector $\beta$ will be chosen to minimize the average cross-entropy $$ \tag{2} L(\beta) = \frac{1}{N} \sum_{i=1}^N \ell(y_i, S(M_i \beta)). $$ We can minimize $L(\beta)$ using an optimization algorithm such as gradient descent, stochastic gradient descent, or Newton's method. In order to use such methods, we need to know how to compute the gradient of $L$ . For Newton's method, we also need to know how to compute the Hessian of $L$ . Question: How can we compute the gradient and the Hessian of the average cross-entropy function $L(\beta)$ defined in equation (2)? The goal is to compute the gradient and the Hessian of $L$ with finesse , making good use of vector and matrix notation. (I'll post an answer below.)","This is a sequel to a previous question about implementing binary logistic regression from scratch. Background knowledge: To train a logistic regression model for a classification problem with classes, we are given a training dataset consisting of feature vectors and corresponding one-hot encoded label vectors . If example belongs to class , then the label vector has a in the th position and zeros elsewhere. Our goal is to find vectors such that Here is the ""augmented"" feature vector obtained by prepending a to the feature vector , and is the softmax function defined by The softmax function is useful in machine learning because it converts a vector into a ""probability vector"" (that is, a vector whose components are nonnegative and sum to ). Equation (1) can be expressed more concisely using vector and matrix notation as follows. Define Then equation (1) says that we hope that I think of as being a ""predicted probability vector"" which tells you how strongly our model believes that example belongs to each of the classes. And is a ""ground truth"" probability vector which reflects certainty about which of the classes example belongs to. We will use the cross-entropy loss function to measure how well a predicted probability vector agrees with a ground truth probability vector . Here denotes the natural logarithm. The vector will be chosen to minimize the average cross-entropy We can minimize using an optimization algorithm such as gradient descent, stochastic gradient descent, or Newton's method. In order to use such methods, we need to know how to compute the gradient of . For Newton's method, we also need to know how to compute the Hessian of . Question: How can we compute the gradient and the Hessian of the average cross-entropy function defined in equation (2)? The goal is to compute the gradient and the Hessian of with finesse , making good use of vector and matrix notation. (I'll post an answer below.)","K x_1, x_2, \ldots, x_N \in \mathbb R^d y_1, y_2, \ldots, y_N \in \mathbb R^K i k y_i 1 k \beta_1, \beta_2, \ldots, \beta_K \in \mathbb R^{d+1} 
\tag{1} y_i \approx S\left(\begin{bmatrix} \hat x_i^T \beta_1 \\ \vdots \\ \hat x_i^T \beta_K \end{bmatrix} \right) \quad \text{for } i = 1, \ldots, N.
 \hat x_i \in \mathbb R^{d+1} 1 x_i \in \mathbb R^d S:\mathbb R^K \to \mathbb R^K 
S(u) = \begin{bmatrix} \frac{e^{u_1}}{e^{u_1} + \cdots + e^{u_K}} \\ \vdots \\ \frac{e^{u_K}}{e^{u_1} + \cdots + e^{u_K}} \end{bmatrix} \quad \text{for all vectors } u = \begin{bmatrix} u_1 \\ \vdots \\ u_K \end{bmatrix} \in \mathbb R^K.
 1 
\beta = \begin{bmatrix} \beta_1 \\ \vdots \\ \beta_K \end{bmatrix} \in \mathbb R^{K(d+1)} \quad \text{and} \quad M_i = \begin{bmatrix} \hat x_i^T & & & \\ & \hat x_i^T & & \\ & & \ddots & \\ & & & \hat x_i^T \end{bmatrix} \in \mathbb R^{K \times K(d+1)}.
 
y_i \approx S(M_i \beta) \quad \text{for } i = 1, \ldots N.
 S(M_i \beta) \in \mathbb R^K i K y_i K i 
\ell(p,q) = \sum_{k=1}^K -p_k \log(q_k)
 q \in \mathbb R^K p \in \mathbb R^K \log \beta 
\tag{2} L(\beta) = \frac{1}{N} \sum_{i=1}^N \ell(y_i, S(M_i \beta)).
 L(\beta) L L L(\beta) L","['statistics', 'multivariable-calculus', 'optimization', 'machine-learning', 'logistic-regression']"
36,Variance of $x$ co-ordinate of uniform random point on a circle.,Variance of  co-ordinate of uniform random point on a circle.,x,"Let $P$ be a point uniformly randomly chosen on the perimiter unit circle. Let $X$ denote its $x$ co-ordinate.  What is the Var $[X]$ ? My method By symetery $\mathbb{E}[X] = 0 $ and so Var $[X]$ = $\mathbb{E}[X^2]$ Using a bit of trig I found the CDF of $X^2$ as $ F_{X^2}(t) = \mathbb{P}[X^2 \leq t] = 1-\frac{2cos^{-1}(\sqrt{t})}{\pi}$ . Using Desmos I then differentiated for the PDF and integrated for the expected value which gives $\mathbb{E}[X^2] = \frac{1}{2}$ . I confirmed this answer using a bit of python. Going forward Such a simple answer makes me think there must be a neat little trick to find $\mathbb{E}[X^2] = \frac{1}{2 } $ ? Can someone find an easier way of doing this? Possibly using the law of total variance conditioning on the $y$ co-ordinate? What about parametrizing the points in polar? Then we only deal with  Uniform $[0,2\pi] $ variable? Edit I initially intended on finding the variance of the $x$ co-ordinate of a point selected uniformly on the surface of the unit sphere. Could someone give some pointers for this too ?",Let be a point uniformly randomly chosen on the perimiter unit circle. Let denote its co-ordinate.  What is the Var ? My method By symetery and so Var = Using a bit of trig I found the CDF of as . Using Desmos I then differentiated for the PDF and integrated for the expected value which gives . I confirmed this answer using a bit of python. Going forward Such a simple answer makes me think there must be a neat little trick to find ? Can someone find an easier way of doing this? Possibly using the law of total variance conditioning on the co-ordinate? What about parametrizing the points in polar? Then we only deal with  Uniform variable? Edit I initially intended on finding the variance of the co-ordinate of a point selected uniformly on the surface of the unit sphere. Could someone give some pointers for this too ?,"P X x [X] \mathbb{E}[X] = 0  [X] \mathbb{E}[X^2] X^2  F_{X^2}(t) = \mathbb{P}[X^2 \leq t] = 1-\frac{2cos^{-1}(\sqrt{t})}{\pi} \mathbb{E}[X^2] = \frac{1}{2} \mathbb{E}[X^2] = \frac{1}{2 }  y [0,2\pi]  x","['probability', 'statistics', 'expected-value']"
37,Markov Inequality results seems too high,Markov Inequality results seems too high,,"The Markov Inequality states that $$P(X>\alpha) \le \frac{E[X]}{\alpha}$$ If I flip a fair coin 100 times, I was trying to calculate the probability that there were at least 90 tails in order to determine whether this series of events was an outlier or not. I was expecting that this would be an outlier according to the Markov Inequality. Since heads and tails are equally likely, I stated that $E[X] = 50$ (and that $\alpha = 90$ ), which yields: $$P(X > 90) \le \frac{50}{90} = \frac{5}{9} \approx 0.56$$ This seems absurdly high to me because it is saying that this extreme event could be more likely than not (which would imply that this is not an outlier). I do realize that this is an upper bound, but am I missing something here?","The Markov Inequality states that If I flip a fair coin 100 times, I was trying to calculate the probability that there were at least 90 tails in order to determine whether this series of events was an outlier or not. I was expecting that this would be an outlier according to the Markov Inequality. Since heads and tails are equally likely, I stated that (and that ), which yields: This seems absurdly high to me because it is saying that this extreme event could be more likely than not (which would imply that this is not an outlier). I do realize that this is an upper bound, but am I missing something here?",P(X>\alpha) \le \frac{E[X]}{\alpha} E[X] = 50 \alpha = 90 P(X > 90) \le \frac{50}{90} = \frac{5}{9} \approx 0.56,"['statistics', 'solution-verification']"
38,What would you call an equation that determines the maximum value of a regression line on a bell-shaped scatterplot?,What would you call an equation that determines the maximum value of a regression line on a bell-shaped scatterplot?,,"Please forgive the vagueness of my question, it has been a while since I have done this sort of math and I'm simply looking for the correct type of wording to further research this problem. Given that I have a data set that produces a scatter plot in bell-shaped curve similar to this image: My goal is to create a curve that fits this scatter plot as shown above, and then calculate the maximum value at the peak of the curve. For example, what is the expected value on the x-axis that is most likely to correlate with the highest value on the y-axis. I'm assuming that this will also provide some degree of statistical significance and also require a software such as R. It has been a decade since I have done this type of math and the vocabulary I need to look this up and refresh myself on these concepts is escaping me. Any insight would be appreciated.","Please forgive the vagueness of my question, it has been a while since I have done this sort of math and I'm simply looking for the correct type of wording to further research this problem. Given that I have a data set that produces a scatter plot in bell-shaped curve similar to this image: My goal is to create a curve that fits this scatter plot as shown above, and then calculate the maximum value at the peak of the curve. For example, what is the expected value on the x-axis that is most likely to correlate with the highest value on the y-axis. I'm assuming that this will also provide some degree of statistical significance and also require a software such as R. It has been a decade since I have done this type of math and the vocabulary I need to look this up and refresh myself on these concepts is escaping me. Any insight would be appreciated.",,['statistics']
39,Calculating the probability of winning a game with random numbers.,Calculating the probability of winning a game with random numbers.,,"The game This is a one player game. $n$ numbers are generated uniformly randomly from $0$ to $1$ . These numbers are then written on $n$ tiles. One number per tile.  You may only look at one tile. You must then guess which tile has the largest number on it. Quick example The numbers $0.782$ , $0.432$ and $0.882$ are generated randomly. Each wrote respectively on tiles $1, 2$ and $3$ . You peek at tile $1$ and see $0.782$ and guess this as the largest tile. You are wrong. You loose. Solution for n=2 Naturally in this simple case one peaks at any tile and if it greater than $\frac{1}{2} $ you guess that tile and if it is less you then guess the other tile. Let P denote the random variable that is the value on the tile you peak. $\mathbb{P}[$ You win ] = $\int_{0}^1 \mathbb{P}[$ You win | $P = p ] f(p)    dp $ $f(p) =1 $ clearly. Hence splitting the integral over zero to one half and one half to one yields three quarters. My question General formula for the Probability of winning for a given $n>2$ I want to know when one should ""stick"". I know the expected value of the maximum of $k$ tiles is $\frac{k}{k+1}$ . Should we only stick if our peaked tile is greater than that? Intuitively I feel like no. Is there some recursion we could use? Thanks :)","The game This is a one player game. numbers are generated uniformly randomly from to . These numbers are then written on tiles. One number per tile.  You may only look at one tile. You must then guess which tile has the largest number on it. Quick example The numbers , and are generated randomly. Each wrote respectively on tiles and . You peek at tile and see and guess this as the largest tile. You are wrong. You loose. Solution for n=2 Naturally in this simple case one peaks at any tile and if it greater than you guess that tile and if it is less you then guess the other tile. Let P denote the random variable that is the value on the tile you peak. You win ] = You win | clearly. Hence splitting the integral over zero to one half and one half to one yields three quarters. My question General formula for the Probability of winning for a given I want to know when one should ""stick"". I know the expected value of the maximum of tiles is . Should we only stick if our peaked tile is greater than that? Intuitively I feel like no. Is there some recursion we could use? Thanks :)","n 0 1 n 0.782 0.432 0.882 1, 2 3 1 0.782 \frac{1}{2}  \mathbb{P}[ \int_{0}^1 \mathbb{P}[ P = p ] f(p) 
  dp  f(p) =1  n>2 k \frac{k}{k+1}","['probability', 'statistics', 'random-variables', 'expected-value', 'game-theory']"
40,Can someone explain how to find the t-distribution for estimating the difference in means of two normal populations when variance is not known?,Can someone explain how to find the t-distribution for estimating the difference in means of two normal populations when variance is not known?,,See the question referenced. How do I find the t-part? If my confidence level is $95\%$ what do I do with that number? I know what to do to find the inverse distribution in other estimations but this does not make sense to me. It is the last part of the answers section. I have googled and found out this is the t-distribution: $\frac{x-\mu}{s / \sqrt{n}}$ I insert the numbers from the answers but I get the wrong answer. $$\frac{-10}{4.64/ \sqrt{100}}=-21.5517241379$$ This is not close at all to the answer.,See the question referenced. How do I find the t-part? If my confidence level is what do I do with that number? I know what to do to find the inverse distribution in other estimations but this does not make sense to me. It is the last part of the answers section. I have googled and found out this is the t-distribution: I insert the numbers from the answers but I get the wrong answer. This is not close at all to the answer.,95\% \frac{x-\mu}{s / \sqrt{n}} \frac{-10}{4.64/ \sqrt{100}}=-21.5517241379,"['statistics', 'maximum-likelihood', 'parameter-estimation']"
41,How to interpret minimal sufficient statistics?,How to interpret minimal sufficient statistics?,,"I know the definition of minimal sufficient statistics is: A sufficient statistic T(X) is called a minimal sufficient statistic if, for any other sufficient statistic T'(X), T(X) is a function of T'(X). I want to know how to interpret this definition from function view. T is smaller than T', if T is a function of T'. What does that mean?","I know the definition of minimal sufficient statistics is: A sufficient statistic T(X) is called a minimal sufficient statistic if, for any other sufficient statistic T'(X), T(X) is a function of T'(X). I want to know how to interpret this definition from function view. T is smaller than T', if T is a function of T'. What does that mean?",,"['statistics', 'statistical-inference']"
42,F-distributions and chi-square distributions: Can someone help explain the answer to this problem?,F-distributions and chi-square distributions: Can someone help explain the answer to this problem?,,"Let $X_1, X_2, X_3, X_4$ be independent $\mathscr{N}(\mu,  \sigma^2)$ random variables. Find the distribution of the ratio $$R=\frac{(X_1-X_2)^2}{(X_3-X_4)^2}.$$ Note that $X_1-X_2$ and $X_3-X_4$ are independent $\mathscr{N}(0,  \sigma^2)$ random variables. Thus $W_1=(X_1-X_2)^2/(2\sigma^2)$ and $W_2=(X_3-X_4)^2/(2\sigma^2)$ are independent $\mathcal{x}^2(1)$ random variables. Since $R$ equals $W_1/W_2$ , we conclude $R\sim  F(1,1).$ I understand that an $F$ distribution is the ratio of two chi-squares with their respective degrees of freedom.  But for this one, why is the square of a non-standard normal distribution a chi-square?  Why is it only one degree of freedom?  Moreover, where does the $2\sigma^2$ come from on the denominators for $W_1$ and $W_2$ ?","Let be independent random variables. Find the distribution of the ratio Note that and are independent random variables. Thus and are independent random variables. Since equals , we conclude I understand that an distribution is the ratio of two chi-squares with their respective degrees of freedom.  But for this one, why is the square of a non-standard normal distribution a chi-square?  Why is it only one degree of freedom?  Moreover, where does the come from on the denominators for and ?","X_1, X_2, X_3, X_4 \mathscr{N}(\mu,
 \sigma^2) R=\frac{(X_1-X_2)^2}{(X_3-X_4)^2}. X_1-X_2 X_3-X_4 \mathscr{N}(0,
 \sigma^2) W_1=(X_1-X_2)^2/(2\sigma^2) W_2=(X_3-X_4)^2/(2\sigma^2) \mathcal{x}^2(1) R W_1/W_2 R\sim
 F(1,1). F 2\sigma^2 W_1 W_2","['statistics', 'probability-distributions']"
43,"Knowing that $X$ independent of itself and $ \mathbb{E}[X^2] < \infty $, how to show that $X$ is a constant?","Knowing that  independent of itself and , how to show that  is a constant?",X  \mathbb{E}[X^2] < \infty  X,"I have a random variable $X$ that is independent of itself. How knowing that $$ \mathbb{E}[X^2] < \infty $$ is suppose to help me finding that $X$ is a constant. I already found out that if $X$ is independent, $ \mathbb{P}(X \in A) = 0  $ or $ \mathbb{P}(X \in A) = 1 $ . And I just pick $x \in \mathbb{R}$ and I have $\mathbb{P}(X \le x)^2 = \mathbb{P}(X \le x) \ge \mathbb{P}(X \le x) = 0  $ or $ \mathbb{P}(X \le x) = 1$ But how is it related to that expected value ? I really tried but I do not come with any ideas. Many thanks ! If the question is ambiguous or unclear, please edit it :)","I have a random variable that is independent of itself. How knowing that is suppose to help me finding that is a constant. I already found out that if is independent, or . And I just pick and I have or But how is it related to that expected value ? I really tried but I do not come with any ideas. Many thanks ! If the question is ambiguous or unclear, please edit it :)",X  \mathbb{E}[X^2] < \infty  X X  \mathbb{P}(X \in A) = 0    \mathbb{P}(X \in A) = 1  x \in \mathbb{R} \mathbb{P}(X \le x)^2 = \mathbb{P}(X \le x) \ge \mathbb{P}(X \le x) = 0    \mathbb{P}(X \le x) = 1,"['probability', 'statistics', 'random-variables', 'expected-value']"
44,The average weight of $46$ weightlifters is $106$ kg; how many can weigh $125$ kg if none may drop below $82$ kg?,The average weight of  weightlifters is  kg; how many can weigh  kg if none may drop below  kg?,46 106 125 82,"The average weight of $46$ weightlifters is $106$ kg. If none of the lifters weighs less than $82$ kg, at most how many of them can weigh more than $125$ kg? We are given that $$\overline{X}=\dfrac{x_1+x_2+x_3+\ldots+x_{46}}{46}=106.$$ From here we can conclude $$x_1+x_2+x_3+\ldots+x_{46}=106\times46=4876 \text{ kg }$$ So the total weight of the weightlifters is $4876$ kg. We also know that $x_n\ge82$ kg for every $n$ . I don't know what to do next. Thank you in advance!","The average weight of weightlifters is kg. If none of the lifters weighs less than kg, at most how many of them can weigh more than kg? We are given that From here we can conclude So the total weight of the weightlifters is kg. We also know that kg for every . I don't know what to do next. Thank you in advance!",46 106 82 125 \overline{X}=\dfrac{x_1+x_2+x_3+\ldots+x_{46}}{46}=106. x_1+x_2+x_3+\ldots+x_{46}=106\times46=4876 \text{ kg } 4876 x_n\ge82 n,"['statistics', 'average']"
45,Calculating expected bonus- what's wrong with my solution?,Calculating expected bonus- what's wrong with my solution?,,"An auto insurance company is implementing a new bonus system. In each month, if a policyholder does not have an accident, he or she will receive a $5 cashback bonus from the insurer. Among the 1000 policyholders, 400 are classified as low-risk drivers and 600 are classified as high-risk drivers. In each month, the probability of zero accidents for high-risk drivers is 0.8 and that for low-risk drivers is 0.9. Calculate the expected bonus payment from the insurer to the 1000 policyholders in one year. The question is what's wrong with my (following) solution? Probability of zero accidents $= (0.8\times 0.6) + (0.90 \times 0.4) = 0.84$ Then, the expected payment is given by $$\sum_{x=1}^{12} (0.84^x) \times 1000 \times 5x$$","An auto insurance company is implementing a new bonus system. In each month, if a policyholder does not have an accident, he or she will receive a $5 cashback bonus from the insurer. Among the 1000 policyholders, 400 are classified as low-risk drivers and 600 are classified as high-risk drivers. In each month, the probability of zero accidents for high-risk drivers is 0.8 and that for low-risk drivers is 0.9. Calculate the expected bonus payment from the insurer to the 1000 policyholders in one year. The question is what's wrong with my (following) solution? Probability of zero accidents Then, the expected payment is given by",= (0.8\times 0.6) + (0.90 \times 0.4) = 0.84 \sum_{x=1}^{12} (0.84^x) \times 1000 \times 5x,"['probability', 'statistics', 'solution-verification']"
46,Least squares regression of sine wave,Least squares regression of sine wave,,"Let's say that a sine-like function of a fixed frequency and zero-mean can only vary in amplitude and offset. That is, for variables $a \in R^+$ and $z \in [0..2\pi]$ $$ f(t) = a(\sin(kt + z))$$ (where $k$ is a constant proportional to the fixed frequency) For some set of $n$ samples $(t_1,y_1),(t_2,y_2)...(t_n, y_n)$ we want to fit $a$ and $z$ such that they minimize: $$ L(a,z) = \sum(f(t_i)-y_i)^2 $$ If f was a linear function we could just use ordinary least squares regression. Is there some similar technique for the above function?  What approach would you use to minimize $L$ ?","Let's say that a sine-like function of a fixed frequency and zero-mean can only vary in amplitude and offset. That is, for variables and (where is a constant proportional to the fixed frequency) For some set of samples we want to fit and such that they minimize: If f was a linear function we could just use ordinary least squares regression. Is there some similar technique for the above function?  What approach would you use to minimize ?","a \in R^+ z \in [0..2\pi]  f(t) = a(\sin(kt + z)) k n (t_1,y_1),(t_2,y_2)...(t_n, y_n) a z  L(a,z) = \sum(f(t_i)-y_i)^2  L","['linear-algebra', 'analysis', 'statistics', 'regression']"
47,"How to find the variance of the estimator, $\frac{1}{\bar{X}}$, for $X_i \sim \operatorname{Expo}(\lambda)$?","How to find the variance of the estimator, , for ?",\frac{1}{\bar{X}} X_i \sim \operatorname{Expo}(\lambda),"So I used the method of moments to find an estimator for $\lambda$ : $\frac{1}{\bar{X}}$ . However, I'm having trouble deriving the variance of it: $$\operatorname{Var}\left(\frac{1}{\bar{X}}\right) = \operatorname{Var} \left(\frac{n}{\sum_{i=1}^n X_i}\right)$$ $$= n^2 \operatorname{Var}\left(\frac{1}{\sum_{i=1}^n X_i}\right)$$ I'm not sure how to proceed from here given the denominator is a sum of $X_i$ 's.","So I used the method of moments to find an estimator for : . However, I'm having trouble deriving the variance of it: I'm not sure how to proceed from here given the denominator is a sum of 's.",\lambda \frac{1}{\bar{X}} \operatorname{Var}\left(\frac{1}{\bar{X}}\right) = \operatorname{Var} \left(\frac{n}{\sum_{i=1}^n X_i}\right) = n^2 \operatorname{Var}\left(\frac{1}{\sum_{i=1}^n X_i}\right) X_i,"['statistics', 'statistical-inference', 'variance', 'exponential-distribution', 'parameter-estimation']"
48,Understanding how EM algorithm actually works for missing data,Understanding how EM algorithm actually works for missing data,,"I am currently studying EM algorithm for handling missing data in a data set. I understand that the final goal of EM algorithm is not to impute data, but to calculate the parameters of interest. However, when I am thinking of a practical example I am really struggling to make sense of the E-step: calculate $Q(\theta, \theta^{(k)}) =  \operatorname{E_{Z|X,\theta^{(k)}}} [\ln{p_{XZ}(x, z| \ \theta)}] \nonumber = \int_{\mathcal{Z}} {\ln{p_{XZ}(x, z| \ \theta)} \  p_{Z|X}(z| \ x, \theta^{(k)}) \ dz}$ , where $x$ are the realization of $X$ (i.e. the observed variables) and $z$ are the realization of $Z$ (i.e. the variables with missing values). Now suppose that we have a data set, where all the instances come from a random variable $Z$ which has a bivariate normal distribution, and also suppose that several data are missing in this data set. How will E-step will work in this case (where $\ln{p_{XZ}(x, z| \ \theta)} = \ln{p_{Z}(z| \ \theta)}$ and $p_{Z|X}(z| \ x, \theta^{(k)})=\ln{p_{Z}(z| \ \theta)}$ )? Does an imputation for missing values takes place in E-step and if yes how they are imputed? Will they be imputed by their current value of mean parameter?","I am currently studying EM algorithm for handling missing data in a data set. I understand that the final goal of EM algorithm is not to impute data, but to calculate the parameters of interest. However, when I am thinking of a practical example I am really struggling to make sense of the E-step: calculate , where are the realization of (i.e. the observed variables) and are the realization of (i.e. the variables with missing values). Now suppose that we have a data set, where all the instances come from a random variable which has a bivariate normal distribution, and also suppose that several data are missing in this data set. How will E-step will work in this case (where and )? Does an imputation for missing values takes place in E-step and if yes how they are imputed? Will they be imputed by their current value of mean parameter?","Q(\theta, \theta^{(k)}) =  \operatorname{E_{Z|X,\theta^{(k)}}} [\ln{p_{XZ}(x, z| \ \theta)}] \nonumber = \int_{\mathcal{Z}} {\ln{p_{XZ}(x, z| \ \theta)} \  p_{Z|X}(z| \ x, \theta^{(k)}) \ dz} x X z Z Z \ln{p_{XZ}(x, z| \ \theta)} = \ln{p_{Z}(z| \ \theta)} p_{Z|X}(z| \ x, \theta^{(k)})=\ln{p_{Z}(z| \ \theta)}","['statistics', 'algorithms', 'machine-learning', 'computational-mathematics', 'numerical-optimization']"
49,"If $\alpha = \beta$, why can't the entropy-regularized Wasserstein distance equal $0$?","If , why can't the entropy-regularized Wasserstein distance equal ?",\alpha = \beta 0,"In optimal transportation theory, the optimal re-allocation of probability distribution $\alpha$ 's mass to another distribution $\beta$ is solved by minimizing the Wasserstein distance with respect to the transport plan. $$W (\alpha, \beta) = \min_{\pi\in \Pi(\alpha\beta)} \int c(x,y) \mathrm{d}\pi(x,y) $$ Alternatively, the relative entropy-regularized Wasserstein distance, also called Sinkhorn distance , can be used: $$W_\epsilon (\alpha, \beta) = \min_{\pi\in \Pi(\alpha\beta)} \int c(x,y) \mathrm{d}\pi(x,y) + \epsilon H(\pi \| \alpha \otimes \beta)$$ where $\epsilon$ is the regularization parameter, and relative entropy is $$H(\pi \| \alpha \otimes \beta) = \int \ln \left(\frac{\mathrm{d}\pi (x,y)}{\mathrm{d}\alpha(x)  \mathrm{d}\beta(y)  } \right) \mathrm{d}\pi (x,y) $$ Aude Genevay said that if you try the extreme case where both the source and target distributions are identical, $\alpha = \beta$ , then we would expect the entropy-regularized Wasserstein distance (Sinkhorn distance) to equal $0$ since there is nothing to move, however it is incapable of doing so . Because of this she proposes the Sinkhorn divergence instead, a normalization which does equal $0$ if $\alpha = \beta$ : $$\bar{W}_\epsilon (\alpha, \beta) = W_\epsilon (\alpha, \beta) - \frac{1}{2} [W_\epsilon (\alpha, \alpha) + W_\epsilon (\beta, \beta) ]$$ In other words, $\bar{W}_\epsilon (\alpha, \alpha) = 0$ . Questions Why (or for what levels of regularization) can't the Sinkhorn distance, shown earlier, achieve $0$ ? Does standard optimal transport, which uses the unregularized Wasserstein distance, also suffer from this incapability (even though I know that the Wasserstein distance by itself, without OT, will achieve $0$ )? and why, mathematically, does the Sinkhorn divergence?","In optimal transportation theory, the optimal re-allocation of probability distribution 's mass to another distribution is solved by minimizing the Wasserstein distance with respect to the transport plan. Alternatively, the relative entropy-regularized Wasserstein distance, also called Sinkhorn distance , can be used: where is the regularization parameter, and relative entropy is Aude Genevay said that if you try the extreme case where both the source and target distributions are identical, , then we would expect the entropy-regularized Wasserstein distance (Sinkhorn distance) to equal since there is nothing to move, however it is incapable of doing so . Because of this she proposes the Sinkhorn divergence instead, a normalization which does equal if : In other words, . Questions Why (or for what levels of regularization) can't the Sinkhorn distance, shown earlier, achieve ? Does standard optimal transport, which uses the unregularized Wasserstein distance, also suffer from this incapability (even though I know that the Wasserstein distance by itself, without OT, will achieve )? and why, mathematically, does the Sinkhorn divergence?","\alpha \beta W (\alpha, \beta) = \min_{\pi\in \Pi(\alpha\beta)} \int c(x,y) \mathrm{d}\pi(x,y)  W_\epsilon (\alpha, \beta) = \min_{\pi\in \Pi(\alpha\beta)} \int c(x,y) \mathrm{d}\pi(x,y) + \epsilon H(\pi \| \alpha \otimes \beta) \epsilon H(\pi \| \alpha \otimes \beta) = \int \ln \left(\frac{\mathrm{d}\pi (x,y)}{\mathrm{d}\alpha(x)  \mathrm{d}\beta(y)  } \right) \mathrm{d}\pi (x,y)  \alpha = \beta 0 0 \alpha = \beta \bar{W}_\epsilon (\alpha, \beta) = W_\epsilon (\alpha, \beta) - \frac{1}{2} [W_\epsilon (\alpha, \alpha) + W_\epsilon (\beta, \beta) ] \bar{W}_\epsilon (\alpha, \alpha) = 0 0 0","['statistics', 'probability-distributions', 'entropy', 'regularization', 'optimal-transport']"
50,Does the equality coefficients of linear regression of X onto Y and Y onto X imply coincidence of the lines?,Does the equality coefficients of linear regression of X onto Y and Y onto X imply coincidence of the lines?,,"Let's assume that we consider the model without an intercept $\hat{y_i} = x_i\hat{\beta}$ . So, the formula for $\hat{\beta}$ is $\frac{ \sum\limits_{i=1}^n x_i y_i}{\sum\limits_{j=1}^n x_j^2}$ . I know that $\hat{\beta}_{XY}$ = $\hat{\beta}_{XY}$ if and only if $ \sum\limits_{j=1}^n x_j^2 = \sum\limits_{j=1}^n y_j^2$ (Here, $\beta_{XY}$ means regression coefficient of $X$ onto $Y$ ). If some of the squares indeed equal, we have that $\hat{\beta}_{XY}$ = $\hat{\beta}_{XY}$ , however I don't understand whether it implies  the coincidence of the lines.","Let's assume that we consider the model without an intercept . So, the formula for is . I know that = if and only if (Here, means regression coefficient of onto ). If some of the squares indeed equal, we have that = , however I don't understand whether it implies  the coincidence of the lines.",\hat{y_i} = x_i\hat{\beta} \hat{\beta} \frac{ \sum\limits_{i=1}^n x_i y_i}{\sum\limits_{j=1}^n x_j^2} \hat{\beta}_{XY} \hat{\beta}_{XY}  \sum\limits_{j=1}^n x_j^2 = \sum\limits_{j=1}^n y_j^2 \beta_{XY} X Y \hat{\beta}_{XY} \hat{\beta}_{XY},"['calculus', 'statistics', 'parameter-estimation', 'linear-regression']"
51,"difference between $S^2$, $\sigma_x^2$. and $\sigma^2$?","difference between , . and ?",S^2 \sigma_x^2 \sigma^2,"On $(5),$ $(6),$ and $(7),$ what's the difference between $S^2$ and $\sigma_x^2$ ? Also, why does: $$\sigma_X^2 = \sum \limits_{i=1}^{n} \frac{1}{n^2} \sigma^2 = \frac{\sigma^2}{n}$$ ? I'm assuming $\sigma^2$ is the population variance. It seems like S is a random variable since I can take the expectation of it, but, $\sigma_x$ is the same thing except not a random variable? Let $(X_1, \cdots, X_n)$ be a random sample of $X$ having unknown mean $\mu$ , and variance $\sigma_x^2$ \begin{align} S^2 &= \frac{1}{n} \sum (X_i - \bar{X})^2 \tag{0}\\[4ex] E[S^2] &= E\Big[\frac{1}{n} \sum (X_i - \bar{X})^2 \Big]\tag{1}\\[2ex] &= E\Bigg[\frac{1}{n} \sum \limits_{i=1}^{n}\Big[~[(X_i - \mu)-(\bar{X}-\mu)]^2~\Bigg]\tag{2}\\[2ex] &= E\Bigg[ \frac{1}{n} \sum \limits_{i=1}^{n} \Big[~(X_i-\mu)^2-2(X_i-\mu)(\bar{X}-\mu)+(\bar{X}-\mu)^2~\Big] ~\Bigg]\tag{3}\\[2ex] &= E\Bigg[~\frac{1}{n} \Big[~\sum \limits_{i=1}^{n} (X_i - \mu)^2 - n(\bar{X} - \mu)^2 \Big]~\Bigg]\tag{4}\\[2ex] &= \frac{1}{n} \sum \limits_{i=1}^{n} E\big[(X_i-\mu)^2\big] - E\big[(\bar{X}-\mu)^2\big]\tag{5}\\[2ex] &= \sigma^2 - \sigma_X^2\tag{6}\\[2ex] &= \sigma^2 - \frac{1}{n}\sigma^2\tag{7}\\[2ex] &= \frac{n-1}{n}\sigma^2\tag{8} \end{align} Equation (8) shows that $S^2$ is a biased estimator of $\sigma^2$","On and what's the difference between and ? Also, why does: ? I'm assuming is the population variance. It seems like S is a random variable since I can take the expectation of it, but, is the same thing except not a random variable? Let be a random sample of having unknown mean , and variance Equation (8) shows that is a biased estimator of","(5), (6), (7), S^2 \sigma_x^2 \sigma_X^2 = \sum \limits_{i=1}^{n} \frac{1}{n^2} \sigma^2 = \frac{\sigma^2}{n} \sigma^2 \sigma_x (X_1, \cdots, X_n) X \mu \sigma_x^2 \begin{align}
S^2 &= \frac{1}{n} \sum (X_i - \bar{X})^2 \tag{0}\\[4ex]
E[S^2] &= E\Big[\frac{1}{n} \sum (X_i - \bar{X})^2 \Big]\tag{1}\\[2ex]
&= E\Bigg[\frac{1}{n} \sum \limits_{i=1}^{n}\Big[~[(X_i - \mu)-(\bar{X}-\mu)]^2~\Bigg]\tag{2}\\[2ex]
&= E\Bigg[ \frac{1}{n} \sum \limits_{i=1}^{n} \Big[~(X_i-\mu)^2-2(X_i-\mu)(\bar{X}-\mu)+(\bar{X}-\mu)^2~\Big] ~\Bigg]\tag{3}\\[2ex]
&= E\Bigg[~\frac{1}{n} \Big[~\sum \limits_{i=1}^{n} (X_i - \mu)^2 - n(\bar{X} - \mu)^2 \Big]~\Bigg]\tag{4}\\[2ex]
&= \frac{1}{n} \sum \limits_{i=1}^{n} E\big[(X_i-\mu)^2\big] - E\big[(\bar{X}-\mu)^2\big]\tag{5}\\[2ex]
&= \sigma^2 - \sigma_X^2\tag{6}\\[2ex]
&= \sigma^2 - \frac{1}{n}\sigma^2\tag{7}\\[2ex]
&= \frac{n-1}{n}\sigma^2\tag{8}
\end{align} S^2 \sigma^2","['statistics', 'expected-value', 'standard-deviation', 'sampling']"
52,Does the probability of guessing a perfect multiple choice test score increase by taking the test multiple times?,Does the probability of guessing a perfect multiple choice test score increase by taking the test multiple times?,,"Me and my brother are currently trying to solve a debate. The question is: Does the probability of a student guessing a perfect score on a multiple choice test go up if the student takes the test multiple times over a set period of time. This started by us discussing the probability of guessing every question on the SAT, resulting in a perfect score. He theorizes that by taking the SAT the max number of times he can (48) before a set date (graduation), his chances of guessing a perfect score go up, due to the fact that he has taken it 48 times. We both recognize that each test attempt is an independent event and doesn't affect the outcome of another, so each individual test attempt still has the same probability of guessing a perfect score. However, he believes that by increasing the number of trials, the  chance of getting a perfect score is greater. I say that because each event is independent, each time is the same exact probability and does not change the more that you take it. The way that makes the most sense for me to think of it is imagining 100 locks and 100 keys. You pick 1 key and 1 lock (1 test, and 1 correct set of answers). After each attempt the locks are randomized again, just like each subsequent test and correct set of answers would become random each time. Each time you try the locks (or the test), you would have a 1:100 chance regardless of how many times you try. Which one of us (if either) is correct? And how do we go about solving this problem? Thanks in advance for the help!","Me and my brother are currently trying to solve a debate. The question is: Does the probability of a student guessing a perfect score on a multiple choice test go up if the student takes the test multiple times over a set period of time. This started by us discussing the probability of guessing every question on the SAT, resulting in a perfect score. He theorizes that by taking the SAT the max number of times he can (48) before a set date (graduation), his chances of guessing a perfect score go up, due to the fact that he has taken it 48 times. We both recognize that each test attempt is an independent event and doesn't affect the outcome of another, so each individual test attempt still has the same probability of guessing a perfect score. However, he believes that by increasing the number of trials, the  chance of getting a perfect score is greater. I say that because each event is independent, each time is the same exact probability and does not change the more that you take it. The way that makes the most sense for me to think of it is imagining 100 locks and 100 keys. You pick 1 key and 1 lock (1 test, and 1 correct set of answers). After each attempt the locks are randomized again, just like each subsequent test and correct set of answers would become random each time. Each time you try the locks (or the test), you would have a 1:100 chance regardless of how many times you try. Which one of us (if either) is correct? And how do we go about solving this problem? Thanks in advance for the help!",,"['probability', 'statistics', 'recreational-mathematics']"
53,"If $\sum_{i=k}^n {n \choose i} p^{i}(1-p)^{n-i} \approx 0.05$, how can we find $k$?","If , how can we find ?",\sum_{i=k}^n {n \choose i} p^{i}(1-p)^{n-i} \approx 0.05 k,"Let $n$ be any natural number, let $k\in\{0, \dots, n\}$ , and let $p \in [0, 1]$ . If $\sum_{i=k}^n {n \choose i} p^{i}(1-p)^{n-i} \approx 0.05$ , how can we find $k$ (in terms of $n$ and $p$ )?","Let be any natural number, let , and let . If , how can we find (in terms of and )?","n k\in\{0, \dots, n\} p \in [0, 1] \sum_{i=k}^n {n \choose i} p^{i}(1-p)^{n-i} \approx 0.05 k n p","['probability', 'statistics', 'approximation', 'binomial-distribution', 'algebraic-equations']"
54,Coronavirus test probability given two tests,Coronavirus test probability given two tests,,"So I'm curious about something relevant to me in real life, but it's been forever since I took prop/stats so I don't remember how to calculate it. The accuracy of a COVID test is 70%. Like, if you have the virus, there is a 70% chance the test will come back positive, but a 30% chance you'll get a false negative. If you don't have the virus, there is a 100% chance it will come back negative (I don't think this is strictly true, but false positives with these tests are unlikely, so I'm ignoring them, and I'm fairly certain it's not relevant to this question). I'm almost certain if I had the virus, I would have transmitted it to my girlfriend. Let's assume for the sake of this problem that that's true. If I had the virus, she had it as well. We each took a test, and they each came back negative. What is the probability my negative result is accurate given this information, instead of if I was the only one who had taken the test?","So I'm curious about something relevant to me in real life, but it's been forever since I took prop/stats so I don't remember how to calculate it. The accuracy of a COVID test is 70%. Like, if you have the virus, there is a 70% chance the test will come back positive, but a 30% chance you'll get a false negative. If you don't have the virus, there is a 100% chance it will come back negative (I don't think this is strictly true, but false positives with these tests are unlikely, so I'm ignoring them, and I'm fairly certain it's not relevant to this question). I'm almost certain if I had the virus, I would have transmitted it to my girlfriend. Let's assume for the sake of this problem that that's true. If I had the virus, she had it as well. We each took a test, and they each came back negative. What is the probability my negative result is accurate given this information, instead of if I was the only one who had taken the test?",,"['probability', 'statistics']"
55,Finding unbiased point estimate of population variance,Finding unbiased point estimate of population variance,,"Q.The contents of each of a random sample of 100 cans of a soft drink are measured. The results have a mean of 331.28 ml and a standard deviation of 2.97 ml. Show that an unbiased estimate of the population variance is 8.91 ml. I'm only able to get 2.97^2 which is 8.8209 but that is not what the question wants. How do I obtain 8.91? From my knowledge, an unbiased estimate of population variance is the same as sample variance, so 8.8209 should have been the correct answer, but it isn't. Why?","Q.The contents of each of a random sample of 100 cans of a soft drink are measured. The results have a mean of 331.28 ml and a standard deviation of 2.97 ml. Show that an unbiased estimate of the population variance is 8.91 ml. I'm only able to get 2.97^2 which is 8.8209 but that is not what the question wants. How do I obtain 8.91? From my knowledge, an unbiased estimate of population variance is the same as sample variance, so 8.8209 should have been the correct answer, but it isn't. Why?",,['statistics']
56,Is this proof of Markov's inequality correct?,Is this proof of Markov's inequality correct?,,"Markov's inequality states: Let $X$ be a non-negative random variable and suppose that $\mathbb{E}(X)$ exists. For any $t > 0$ : $$\mathbb{P}(X > t) \leq \frac{\mathbb{E}(X)}{t}$$ My text contains the following proof: Since $X > 0$ , $$ \begin{align} \mathbb{E}(X) &= \int_0^{\infty} xf_X(x)dx \\ &= \int_0^{t} xf_X(x)dx + \int_t^{\infty} xf_X(x)dx \\ &\geq \int_t^{\infty} xf_X(x)dx \\ &\geq t\int_t^{\infty} f_X(x)dx \\ &= t\mathbb{P}(X > t) \end{align} $$ My concern is the step where we remove $x$ from the integral. I think the assumption is that since we know $x$ is non-negative, that removing multiplication by $x$ can only make things smaller. However, for $0 < x < 1$ removing multiplication by $x$ should actually make them bigger. If $f_X$ only has density in that range, then I don't think you can say that $\int_t^{\infty} xf_X(x)dx \geq \int_t^{\infty} f_X(x)dx$ . Unless somehow multiplying by $t$ at the same time gets rid of this problem?","Markov's inequality states: Let be a non-negative random variable and suppose that exists. For any : My text contains the following proof: Since , My concern is the step where we remove from the integral. I think the assumption is that since we know is non-negative, that removing multiplication by can only make things smaller. However, for removing multiplication by should actually make them bigger. If only has density in that range, then I don't think you can say that . Unless somehow multiplying by at the same time gets rid of this problem?","X \mathbb{E}(X) t > 0 \mathbb{P}(X > t) \leq \frac{\mathbb{E}(X)}{t} X > 0  \begin{align} \mathbb{E}(X) &= \int_0^{\infty} xf_X(x)dx \\ &=
\int_0^{t} xf_X(x)dx + \int_t^{\infty} xf_X(x)dx \\ &\geq
\int_t^{\infty} xf_X(x)dx \\ &\geq t\int_t^{\infty} f_X(x)dx \\ &=
t\mathbb{P}(X > t) \end{align}  x x x 0 < x < 1 x f_X \int_t^{\infty} xf_X(x)dx \geq \int_t^{\infty} f_X(x)dx t","['probability', 'statistics', 'inequality', 'solution-verification']"
57,Markov's inequality results negative,Markov's inequality results negative,,"$X$ is the midterm grade (out of $100$ points) of a randomly chosen student. If the average grade is $40$ points, find an upper bound on $Pr[X < 10]$ using Markov's inequality. (Hint: You may need to define a new non-negative random variable.) I encountered this question and applied Markov's inequality but it gave me $P(X < 10)>= 1-\left(\frac{40}{10}\right)$ and that gives us a negative bound. How can I resolve this problem ?","is the midterm grade (out of points) of a randomly chosen student. If the average grade is points, find an upper bound on using Markov's inequality. (Hint: You may need to define a new non-negative random variable.) I encountered this question and applied Markov's inequality but it gave me and that gives us a negative bound. How can I resolve this problem ?",X 100 40 Pr[X < 10] P(X < 10)>= 1-\left(\frac{40}{10}\right),"['probability', 'statistics', 'markov-process']"
58,Rayleigh as exponential family - compute $\mathbb{E}(Y)$ and Var$(Y)$ where Y is a sum of independent squared Rayleigh's distribution,Rayleigh as exponential family - compute  and Var where Y is a sum of independent squared Rayleigh's distribution,\mathbb{E}(Y) (Y),"Prove that X of Rayleigh distribution with pdf $f(x, \sigma) = \frac{x}{\sigma^2}e^{-\frac{x^2}{2\sigma^2}}\mathbb{1}_{(0, \infty)}(x)$ comes from the exponential family and then compute $\mathbb{E}(Y)$ and Var $(Y)$ where $Y = \sum_{k=1}^nX^2_k$ (all $X_k$ are independent). I did the first part: $$ f(x, \sigma) = \frac{x}{\sigma^2}e^{-\frac{x^2}{2\sigma^2}}\mathbb{1}_{(0, \infty)}(x) = xe^{-\frac{1}{2\sigma^2}x^2 - 2\ln(\sigma)}\mathbb{1}_{(0, \infty)}(x) $$ so $$ h(x) = x; \eta_1(\theta) = -\frac{1}{2\sigma^2}; T_1(x)=x^2; B(\theta)=2ln(\sigma) $$ Why is the fact that Rayleigh's comes from an exponential family useful? Are there any equations to quickly solve the second part of the task? I appreciate any help.",Prove that X of Rayleigh distribution with pdf comes from the exponential family and then compute and Var where (all are independent). I did the first part: so Why is the fact that Rayleigh's comes from an exponential family useful? Are there any equations to quickly solve the second part of the task? I appreciate any help.,"f(x, \sigma) = \frac{x}{\sigma^2}e^{-\frac{x^2}{2\sigma^2}}\mathbb{1}_{(0, \infty)}(x) \mathbb{E}(Y) (Y) Y = \sum_{k=1}^nX^2_k X_k 
f(x, \sigma) = \frac{x}{\sigma^2}e^{-\frac{x^2}{2\sigma^2}}\mathbb{1}_{(0, \infty)}(x) =
xe^{-\frac{1}{2\sigma^2}x^2 - 2\ln(\sigma)}\mathbb{1}_{(0, \infty)}(x)
 
h(x) = x; \eta_1(\theta) = -\frac{1}{2\sigma^2}; T_1(x)=x^2; B(\theta)=2ln(\sigma)
","['probability', 'statistics', 'expected-value', 'variance']"
59,Definition of degenerate multivariate normal distribution,Definition of degenerate multivariate normal distribution,,"I am reading some notes and having some trouble with the definition of multivariate normal distribution when the covariance matrix is not invertible. I will state my understanding below, and hopefully someone can chime in with some words of wisdom. Suppose $\Sigma$ is an $n\times n$ matrix. When $\Sigma$ is invertible, we say that a random vector $X$ has multivariate normal distribution with mean $0$ and covariance $\Sigma$ if it has density given by $f_X(x)=\frac{1}{(2\pi)^{n/2}(\det{\Sigma})^{1/2}}\exp(-\frac{1}{2}x^T\Sigma^{-1}x)$ Now, when $\Sigma$ is not invertible, then clearly the above density function is not defined. The notes mention the Cramer-Wold device can be used to define $N(0,\Sigma)$ in this case, and moves on without explicitly doing so. Could somebody please give a simplistic explanation/definition of $N(0,\Sigma)$ when $\Sigma$ is not invertible? Remark: For the univariate normal distribution, I understand that $N(0,0)$ corresponds to the degenerate distribution $\delta_0$ . By degenerate distribution, I mean it is $0$ with probability $1$ . I can not see how this would work in higher dimensions though!","I am reading some notes and having some trouble with the definition of multivariate normal distribution when the covariance matrix is not invertible. I will state my understanding below, and hopefully someone can chime in with some words of wisdom. Suppose is an matrix. When is invertible, we say that a random vector has multivariate normal distribution with mean and covariance if it has density given by Now, when is not invertible, then clearly the above density function is not defined. The notes mention the Cramer-Wold device can be used to define in this case, and moves on without explicitly doing so. Could somebody please give a simplistic explanation/definition of when is not invertible? Remark: For the univariate normal distribution, I understand that corresponds to the degenerate distribution . By degenerate distribution, I mean it is with probability . I can not see how this would work in higher dimensions though!","\Sigma n\times n \Sigma X 0 \Sigma f_X(x)=\frac{1}{(2\pi)^{n/2}(\det{\Sigma})^{1/2}}\exp(-\frac{1}{2}x^T\Sigma^{-1}x) \Sigma N(0,\Sigma) N(0,\Sigma) \Sigma N(0,0) \delta_0 0 1","['probability', 'statistics', 'probability-distributions', 'normal-distribution', 'covariance']"
60,"MLE of uniform $(\theta,\theta^2)$",MLE of uniform,"(\theta,\theta^2)","Let $X_1...X_n$ be from uniform ( $\theta,\theta^2)$ where $\theta>1$ I seek the MLE. I've seen similar problems, but I think this one might be more interesting. Intuitively, we think $X_{(1)}$ should estimate theta. However I think since $\theta >1$ there is no MLE as this function blows up close to one. Is this correct? Edit: bad picture explaining my reasoning:","Let be from uniform ( where I seek the MLE. I've seen similar problems, but I think this one might be more interesting. Intuitively, we think should estimate theta. However I think since there is no MLE as this function blows up close to one. Is this correct? Edit: bad picture explaining my reasoning:","X_1...X_n \theta,\theta^2) \theta>1 X_{(1)} \theta >1","['statistics', 'statistical-inference', 'maximum-likelihood']"
61,Motivation for the definition of the Pearson correlation coefficient,Motivation for the definition of the Pearson correlation coefficient,,"Let $X$ and $Y$ be two random variables with joint distribution $P_{X,Y}$ and marginal distributions $P_X$ and $P_Y$ . The Pearson correlation coefficient is defined to be $$\rho_{X,Y}=\dfrac{\mathbb{E}(XY)-\mathbb{E}(X)\mathbb{E}(Y)}{\sigma_X\sigma_Y}\tag{1}$$ where $\mathbb{E}$ means the mean value and $\sigma_X,\sigma_Y$ are the respective standard deviations. This is meant to be a quantifier of correlation. As put in Wikipedia's page : In statistics, correlation or dependence is any statistical relationship, whether causal or not, between two random variables or bivariate data. My question is: given this intuitive idea about correlation, what is the motivation to define (1) as a quantifier of correlation? How do we motivate definition (1)? It is also hinted upon on the linked page that $\rho_{X,Y}$ is ""Mathematically, it is defined as the quality of least squares fitting to the original data"" . But I still fail to see wy this would be a good quantifier of correlations.","Let and be two random variables with joint distribution and marginal distributions and . The Pearson correlation coefficient is defined to be where means the mean value and are the respective standard deviations. This is meant to be a quantifier of correlation. As put in Wikipedia's page : In statistics, correlation or dependence is any statistical relationship, whether causal or not, between two random variables or bivariate data. My question is: given this intuitive idea about correlation, what is the motivation to define (1) as a quantifier of correlation? How do we motivate definition (1)? It is also hinted upon on the linked page that is ""Mathematically, it is defined as the quality of least squares fitting to the original data"" . But I still fail to see wy this would be a good quantifier of correlations.","X Y P_{X,Y} P_X P_Y \rho_{X,Y}=\dfrac{\mathbb{E}(XY)-\mathbb{E}(X)\mathbb{E}(Y)}{\sigma_X\sigma_Y}\tag{1} \mathbb{E} \sigma_X,\sigma_Y \rho_{X,Y}","['probability', 'statistics', 'definition', 'intuition', 'motivation']"
62,Normalize a vector (an array) - divide by total sum or absolute value?,Normalize a vector (an array) - divide by total sum or absolute value?,,"When I think of normalizing a vector I mean divide each element with the absolute value of the whole vector, i.e. \begin{align} a &= (2, 4, 3, 1) \\ \hat{a} &= \frac{(2, 4, 3, 1)}{\sqrt{30}} \approx (0.37, 0.73, 0.55, 0.18) \end{align} However, I'm reading a programming book (Java) and it says: ""You have a sequence of real numbers and want to return a new normalize sequence whose sum is equal to one. This can be done by dividing each number in the sequence with the total sum of the sequence. For example; $(2, 4, 3, 1)$ should return $(0.2, 0.4, 0.3, 0.1)$ since the sum is $2 + 4+ 3 +1 =10$ ."" But why divide with $10$ and not the absolute value? What have I missed? Is there a different terminology for ""normalization"" in mathematics and computer science, respectively? Of is there actually a fundamental difference between a vector, an array and a sequence?","When I think of normalizing a vector I mean divide each element with the absolute value of the whole vector, i.e. However, I'm reading a programming book (Java) and it says: ""You have a sequence of real numbers and want to return a new normalize sequence whose sum is equal to one. This can be done by dividing each number in the sequence with the total sum of the sequence. For example; should return since the sum is ."" But why divide with and not the absolute value? What have I missed? Is there a different terminology for ""normalization"" in mathematics and computer science, respectively? Of is there actually a fundamental difference between a vector, an array and a sequence?","\begin{align}
a &= (2, 4, 3, 1) \\
\hat{a} &= \frac{(2, 4, 3, 1)}{\sqrt{30}} \approx (0.37, 0.73, 0.55, 0.18)
\end{align} (2, 4, 3, 1) (0.2, 0.4, 0.3, 0.1) 2 + 4+ 3 +1 =10 10","['statistics', 'numerical-methods', 'absolute-value', 'computational-mathematics']"
63,What is the sum of $k$ normal random variables where $k$ is sampled from a Poisson distribution? [duplicate],What is the sum of  normal random variables where  is sampled from a Poisson distribution? [duplicate],k k,"This question already has answers here : Variance of the random sum of a Poisson? (3 answers) Closed 4 years ago . Let's say you have a sequence of i.i.d. random variables $r_1,r_2,r_3,\dots$ that are distributed as $\mathcal N(0,1)$ . Now, consider the process where we sample a $k$ from $\text{Pois}(\lambda)$ and let $z$ equal $$\sum_{i=1}^{k}r_i$$ My question is what the distribution of $z$ is? My first guess is that it would be $\mathcal N(0,\lambda)$ . I do not how I would proof this, however. The variance might be slightly larger due to the uncertainty introduced by the Poisson distribution, for example. Proving the mean is $0$ is easy by symmetry.","This question already has answers here : Variance of the random sum of a Poisson? (3 answers) Closed 4 years ago . Let's say you have a sequence of i.i.d. random variables that are distributed as . Now, consider the process where we sample a from and let equal My question is what the distribution of is? My first guess is that it would be . I do not how I would proof this, however. The variance might be slightly larger due to the uncertainty introduced by the Poisson distribution, for example. Proving the mean is is easy by symmetry.","r_1,r_2,r_3,\dots \mathcal N(0,1) k \text{Pois}(\lambda) z \sum_{i=1}^{k}r_i z \mathcal N(0,\lambda) 0","['statistics', 'normal-distribution', 'poisson-distribution']"
64,Calculating Expected Value with Combinatorics,Calculating Expected Value with Combinatorics,,"A company has 100 employees. For a Christmas team-building exercise, they divide the 100 employees into 25 teams of 4. Randomly and independently, they give an award to 20 employees. -- Find the expected value of the number of awards given to the employees on any given team. What type of distribution is this? So far, I have that there are 100!/(4!^25)*25! combinations for the teams, but don't know where to go from there","A company has 100 employees. For a Christmas team-building exercise, they divide the 100 employees into 25 teams of 4. Randomly and independently, they give an award to 20 employees. -- Find the expected value of the number of awards given to the employees on any given team. What type of distribution is this? So far, I have that there are 100!/(4!^25)*25! combinations for the teams, but don't know where to go from there",,"['combinatorics', 'statistics', 'expected-value']"
65,Confidence Intervals: Influence,Confidence Intervals: Influence,,Why would increasing the sample size decrease the confidence interval width? Wouldn't increasing sample size lead to an increase in the variability (and thus the standard deviation) of the data?,Why would increasing the sample size decrease the confidence interval width? Wouldn't increasing sample size lead to an increase in the variability (and thus the standard deviation) of the data?,,"['statistics', 'confidence-interval']"
66,$X_n$ is bounded in probability and $Y_n$ converges to 0 in probability then $X_nY_n$ congerges to probablity with 0,is bounded in probability and  converges to 0 in probability then  congerges to probablity with 0,X_n Y_n X_nY_n,"I want to show : $X_n$ is bounded in probability and $Y_n \rightarrow 0$ in probability  then $X_nY_n \rightarrow 0 $ in probablity.  I know the following definitions that is Definition 2.17 : We say that $X_n$ is bounded in probability if $X_n = O_P (1)$ , i.e. if for every $\epsilon$ > 0, there exist $M$ and $N$ such that $P(|Xn| < M) > 1 ‚àí \epsilon $ for $n > N$ . So I want to show that for every $\epsilon$ > 0 and $\epsilon '$ > 0 there exist $M>0 $ and $n_o $ such that $P(|X_n| <M) > 1 -\epsilon/2$ $P(|X_n| <\epsilon /M) > 1 -\epsilon'/2$ for every $n>n_0$ Then I want to show that $P(|X_n| <M$ and $|Y_n| <\epsilon /M) > 1-\epsilon' $","I want to show : is bounded in probability and in probability  then in probablity.  I know the following definitions that is Definition 2.17 : We say that is bounded in probability if , i.e. if for every > 0, there exist and such that for . So I want to show that for every > 0 and > 0 there exist and such that for every Then I want to show that and","X_n Y_n \rightarrow 0 X_nY_n \rightarrow 0  X_n X_n = O_P (1) \epsilon M N P(|Xn| < M) >
1 ‚àí \epsilon  n > N \epsilon \epsilon ' M>0  n_o  P(|X_n| <M) > 1 -\epsilon/2 P(|X_n| <\epsilon /M) > 1 -\epsilon'/2 n>n_0 P(|X_n| <M |Y_n| <\epsilon /M) > 1-\epsilon' ","['probability-theory', 'statistics', 'asymptotics']"
67,Computing the Second Moment/Expectation,Computing the Second Moment/Expectation,,"This seems like a relatively simple equation, but I have not really found an explanation that works for me. In my probability class, we were simply given that the kth moment of a random variable X is $E[X^k]$ . Are we supposed to be squaring the probability as well when we are computing the second moment? I.e. computing E[X] means computing $\sum_i iP(X=i)$ . So then is $E[X^2]$ equal to $\sum_i (iP(X=i))^2$ ? Or is it $\sum_i i^2P(X=i^2)$ or $\sum_i i^2P(X=i)$ ? From reading around the internet, I assume it is the last equation, but I do not really understand the intuition behind this. Here's what I understand: Moments are used to determine how much data points are spread out. So the Expectation of {5, 5, 5, 5, 5} is the same as the expectation of {3, 4, 5, 6, 7}, but they have different second moment-expectations. I understand the concept, but not much more. Clarification, intuition, or links to visual representations would be much appreciated Edit: Additionally, if someone could provide an explanation for this simple fact, it would help: "" $E[X_i]^2 = E[X_i] = \frac{1}{2}$ where $X_i$ is 1 if you toss a coin and get heads, and 0 if you get tails."" What is $E[X^2]$ for n coin tosses?","This seems like a relatively simple equation, but I have not really found an explanation that works for me. In my probability class, we were simply given that the kth moment of a random variable X is . Are we supposed to be squaring the probability as well when we are computing the second moment? I.e. computing E[X] means computing . So then is equal to ? Or is it or ? From reading around the internet, I assume it is the last equation, but I do not really understand the intuition behind this. Here's what I understand: Moments are used to determine how much data points are spread out. So the Expectation of {5, 5, 5, 5, 5} is the same as the expectation of {3, 4, 5, 6, 7}, but they have different second moment-expectations. I understand the concept, but not much more. Clarification, intuition, or links to visual representations would be much appreciated Edit: Additionally, if someone could provide an explanation for this simple fact, it would help: "" where is 1 if you toss a coin and get heads, and 0 if you get tails."" What is for n coin tosses?",E[X^k] \sum_i iP(X=i) E[X^2] \sum_i (iP(X=i))^2 \sum_i i^2P(X=i^2) \sum_i i^2P(X=i) E[X_i]^2 = E[X_i] = \frac{1}{2} X_i E[X^2],"['probability', 'statistics', 'expected-value']"
68,Why does the transformation in the scope of the cumulative distribution function work?,Why does the transformation in the scope of the cumulative distribution function work?,,"I am reading some probability courses on the https://www.probabilitycourse.com/chapter4/4_1_3_functions_continuous_var.php . It says the following : Let X be a Uniform(0,1) random variable, and let $Y=e^X$ I would like to ask why the following equation is correct: $$P(e^X \leq y)=P(X \leq \ln y)$$ Intuitively, we can apply the ln operator in the first CDF to get the second CDF. However, I am confused when I expand these 2 cumulative distribution functions into the integral format. $$P(Y \leq y) = P(e^X \leq y)=\int_{{-\infty}}^{y} f_y(y) dy=\int_{{-\infty}}^{y} f_y(e^x) dy=\int_{{-\infty}}^{\ln y} f_y(e^x) e^x dx$$ $$P(X \leq \ln y)=\int_{{-\infty}}^{\ln y} f_x(x) dx$$ $f_x$ and $f_y$ are the corresponding pdfs. I can not see directly that the equation $\int_{{-\infty}}^{\ln y} f_y(e^x) e^x dx = \int_{{-\infty}}^{\ln y} f_x(x) dx$ can really hold . So I would like to ask why the transformation in the scope of  the cumulative distribution function works ? Did I miss some axiom ? I guess it should be a basic question but I can not get it from google. Thank you I agree with @Grada Gukovi's comment, and I find the Method of Transformation will produce the equation $ f_y(e^x) e^x = f_y(y) e^x = f_x(x) $ . What I think in this problem is that , the statement of $P(e^X \leq y)=P(X \leq \ln y)$ should not be a simple transformation without evidence. Because $P(e^X \leq y)$ is the integral for random variable y and $P(X \leq \ln y)$ is the integral for random variable x. This equation is not easy to be derived and gives me lots of worrys.  From my thinking, we can only get this equation after using the Method of Transformation. I guess we can not say $P(e^X \leq y) = P(X \leq \ln y) $ if $(e^X \leq y) = (X \leq \ln y) $ simply.","I am reading some probability courses on the https://www.probabilitycourse.com/chapter4/4_1_3_functions_continuous_var.php . It says the following : Let X be a Uniform(0,1) random variable, and let I would like to ask why the following equation is correct: Intuitively, we can apply the ln operator in the first CDF to get the second CDF. However, I am confused when I expand these 2 cumulative distribution functions into the integral format. and are the corresponding pdfs. I can not see directly that the equation can really hold . So I would like to ask why the transformation in the scope of  the cumulative distribution function works ? Did I miss some axiom ? I guess it should be a basic question but I can not get it from google. Thank you I agree with @Grada Gukovi's comment, and I find the Method of Transformation will produce the equation . What I think in this problem is that , the statement of should not be a simple transformation without evidence. Because is the integral for random variable y and is the integral for random variable x. This equation is not easy to be derived and gives me lots of worrys.  From my thinking, we can only get this equation after using the Method of Transformation. I guess we can not say if simply.",Y=e^X P(e^X \leq y)=P(X \leq \ln y) P(Y \leq y) = P(e^X \leq y)=\int_{{-\infty}}^{y} f_y(y) dy=\int_{{-\infty}}^{y} f_y(e^x) dy=\int_{{-\infty}}^{\ln y} f_y(e^x) e^x dx P(X \leq \ln y)=\int_{{-\infty}}^{\ln y} f_x(x) dx f_x f_y \int_{{-\infty}}^{\ln y} f_y(e^x) e^x dx = \int_{{-\infty}}^{\ln y} f_x(x) dx  f_y(e^x) e^x = f_y(y) e^x = f_x(x)  P(e^X \leq y)=P(X \leq \ln y) P(e^X \leq y) P(X \leq \ln y) P(e^X \leq y) = P(X \leq \ln y)  (e^X \leq y) = (X \leq \ln y) ,"['probability', 'probability-theory', 'statistics', 'probability-distributions', 'random-variables']"
69,Find Uniform Minimum Variance Unbiased estimator (UMVU) using Lehmann Scheff√© - showing statistic is complete,Find Uniform Minimum Variance Unbiased estimator (UMVU) using Lehmann Scheff√© - showing statistic is complete,,"Let $X_1,...,X_n$ be independent copies of a real-valued random variable $X$ where $X$ has Lebesgue density \begin{align*} p_\theta(x) = \begin{cases} \exp(\theta-x),\quad x>\theta  \\  0, \quad\quad\quad\quad\;\ x\leq \theta, \end{cases} \end{align*} where $\theta\in \mathbb{R}$ is an unknown parameter. Let $S:=\min(X_1,...,X_n)$ . Find the Uniform Minimum Variance Unbiased (UMVU) estimator of $\theta$ . I already know that $S$ is sufficient for $\theta$ and that $T:=S-1/n$ is an unbiased estimator of $\theta.$ My idea is to apply the Lehmann-Scheff√© thm. since then the UMVU is given by \begin{align*} \mathbb{E}[T|S]=\mathbb{E}[S-1/n|S]=S-1/n. \end{align*} Is this the correct approach? If yes, for applying Lehmann-Scheff√©, I would also need that S is a complete statistic. How do I show this properly? Edit : I tried to show completeness by definition, i.e. I setup the equation $\mathbb{E}_\theta[g(S)]=0 \;\forall \theta$ for some function $g$ and now want to show that $g(S)=0 \; \mathbb{P}_\theta$ -a.s. for all $\theta$ . Since the $X_i$ are iid it is easy to see that the cdf is $F_S(x)=1-(1-P_\theta(x))^n$ , where $P_\theta(x)$ is the cdf of $X_i$ . By taking the derivative we get the pdf for $S$ : $f_S(x)=n\cdot p_\theta(x)(1-P_\theta (x))^{n-1}$ . $P_\theta (x)$ can be easily calculated and we get \begin{align*} f_S(x)=n\cdot e^{n(\theta-x)}. \end{align*} Hence, $\mathbb{E}_\theta[g(S)]=\int_\theta^\infty g(x)ne^{n(\theta-x)}dx$ has to be $0$ . Is it now enough to say that $g(S)=0 \; \mathbb{P}_\theta$ -a.s. for all $\theta$ , since the exponential function is always positive? Or is there a more rigorous way to show it?","Let be independent copies of a real-valued random variable where has Lebesgue density where is an unknown parameter. Let . Find the Uniform Minimum Variance Unbiased (UMVU) estimator of . I already know that is sufficient for and that is an unbiased estimator of My idea is to apply the Lehmann-Scheff√© thm. since then the UMVU is given by Is this the correct approach? If yes, for applying Lehmann-Scheff√©, I would also need that S is a complete statistic. How do I show this properly? Edit : I tried to show completeness by definition, i.e. I setup the equation for some function and now want to show that -a.s. for all . Since the are iid it is easy to see that the cdf is , where is the cdf of . By taking the derivative we get the pdf for : . can be easily calculated and we get Hence, has to be . Is it now enough to say that -a.s. for all , since the exponential function is always positive? Or is there a more rigorous way to show it?","X_1,...,X_n X X \begin{align*}
p_\theta(x) = \begin{cases} \exp(\theta-x),\quad x>\theta  \\ 
0, \quad\quad\quad\quad\;\ x\leq \theta, \end{cases}
\end{align*} \theta\in \mathbb{R} S:=\min(X_1,...,X_n) \theta S \theta T:=S-1/n \theta. \begin{align*}
\mathbb{E}[T|S]=\mathbb{E}[S-1/n|S]=S-1/n.
\end{align*} \mathbb{E}_\theta[g(S)]=0 \;\forall \theta g g(S)=0 \; \mathbb{P}_\theta \theta X_i F_S(x)=1-(1-P_\theta(x))^n P_\theta(x) X_i S f_S(x)=n\cdot p_\theta(x)(1-P_\theta (x))^{n-1} P_\theta (x) \begin{align*}
f_S(x)=n\cdot e^{n(\theta-x)}.
\end{align*} \mathbb{E}_\theta[g(S)]=\int_\theta^\infty g(x)ne^{n(\theta-x)}dx 0 g(S)=0 \; \mathbb{P}_\theta \theta","['statistics', 'statistical-inference', 'exponential-distribution', 'parameter-estimation']"
70,UMVUE of $P(X_1 \ge t)$ for a two-parameter exponential distribution,UMVUE of  for a two-parameter exponential distribution,P(X_1 \ge t),"I'm attempting to find $(a)$ The UMVUE of $\lambda$ when $\theta$ is known. $(b)$ The UMVUE of $\theta$ when $\lambda$ is known. $(c)$ The UMVUE of $P(X_1 \ge t)$ for a fixed $t > \theta$ when $\lambda$ is known. I'm new to the concept of UMVUE and attempting to self-learn it through a mathematical statistics textbook. I would appreciate some feedback for $(a)$ and $(b)$ in terms of their correctness and some help with $(c)$ . I found a sufficient statistic $T = (X_{(1)}, \sum\limits_{i = 1 }^n {X_i })$ For $(a)$ , when $Œ∏$ is known, $\sum\limits_{i = 1 }^n {X_i }$ is a sufficient and complete statistic for $Œª$ . $E(\sum\limits_{i = 1 }^n {X_i }) = n(\lambda + \theta)$ Therefore $T_1 = \frac{\sum\limits_{i = 1 }^n {X_i }}{n} - \theta = \bar X - \theta$ is the UMVUE of $\lambda$ . For $(b)$ , when $\lambda$ is known, $X_{(1)}$ is sufficient and complete for $\theta$ . $E(X_{(1)}) = \lambda + \theta$ . Therefore $T_2 = X_{(1)} - \lambda$ is the UMVUE of $\theta$ . For $(c)$ , I'm not completely sure how to go about doing this but I'm assuming that the UMVUE would be $P(X_1 \ge t\mid T)$ and that it would be 1 when $t<X_{(1)}$ but I'm unsure how to deal with the other case and whether this is indeed correct.","I'm attempting to find The UMVUE of when is known. The UMVUE of when is known. The UMVUE of for a fixed when is known. I'm new to the concept of UMVUE and attempting to self-learn it through a mathematical statistics textbook. I would appreciate some feedback for and in terms of their correctness and some help with . I found a sufficient statistic For , when is known, is a sufficient and complete statistic for . Therefore is the UMVUE of . For , when is known, is sufficient and complete for . . Therefore is the UMVUE of . For , I'm not completely sure how to go about doing this but I'm assuming that the UMVUE would be and that it would be 1 when but I'm unsure how to deal with the other case and whether this is indeed correct.","(a) \lambda \theta (b) \theta \lambda (c) P(X_1 \ge t) t > \theta \lambda (a) (b) (c) T = (X_{(1)}, \sum\limits_{i = 1 }^n {X_i }) (a) Œ∏ \sum\limits_{i = 1 }^n {X_i } Œª E(\sum\limits_{i = 1 }^n {X_i }) = n(\lambda + \theta) T_1 = \frac{\sum\limits_{i = 1 }^n {X_i }}{n} - \theta = \bar X - \theta \lambda (b) \lambda X_{(1)} \theta E(X_{(1)}) = \lambda + \theta T_2 = X_{(1)} - \lambda \theta (c) P(X_1 \ge t\mid T) t<X_{(1)}","['statistics', 'probability-distributions', 'statistical-inference', 'exponential-distribution', 'parameter-estimation']"
71,Where does the identity matrix come from in the formula for ridge regression coefficients?,Where does the identity matrix come from in the formula for ridge regression coefficients?,,"The formula for the ridge regression coefficients is $$ \beta = {X^{\top}Y}({X^{\top}X+\lambda I})^{-1}$$ I have tried to derive it as follows: The loss is (I am omitting the sum before the square term): $$ L = {(X^{\top}\beta-Y)^2+\lambda\beta^{\top}\beta} $$ Take the derivative and equating to zero: $$ \frac{dL}{d\beta} = 2({X^{\top}\beta-Y)X}+2{\lambda \beta}$$ Equating the derivative to zero (we can get rid of the multipliers $2$ ) and expanding: $$ X^{\top} X\beta- X^{\top} Y +\lambda \beta = 0 $$ Isolating beta: $$ \beta ( X^{\top} X + \lambda) = X^{\top} Y$$ Here in the 4th step, I should somehow arrive at a formula that has $\mathbf I$ right after $\lambda$ . Where I am making a mistake? I know it must be there but I don't understand why it should be there or based on what rule I should add it after $\lambda$ . Thanks.","The formula for the ridge regression coefficients is I have tried to derive it as follows: The loss is (I am omitting the sum before the square term): Take the derivative and equating to zero: Equating the derivative to zero (we can get rid of the multipliers ) and expanding: Isolating beta: Here in the 4th step, I should somehow arrive at a formula that has right after . Where I am making a mistake? I know it must be there but I don't understand why it should be there or based on what rule I should add it after . Thanks.", \beta = {X^{\top}Y}({X^{\top}X+\lambda I})^{-1}  L = {(X^{\top}\beta-Y)^2+\lambda\beta^{\top}\beta}   \frac{dL}{d\beta} = 2({X^{\top}\beta-Y)X}+2{\lambda \beta} 2  X^{\top} X\beta- X^{\top} Y +\lambda \beta = 0   \beta ( X^{\top} X + \lambda) = X^{\top} Y \mathbf I \lambda \lambda,"['linear-algebra', 'matrices', 'statistics', 'regression', 'regularization']"
72,Mean of means and standard deviation,Mean of means and standard deviation,,"I have a set of data with their means $\mu_1,\mu_2,\ldots\mu_n$ and standard deviations $\sigma_1,\sigma_2,\ldots,\sigma_n$ . These values refer to repetitions of the same experiment. How do I calculate the ""mean mean"" (average?) and mean standard deviation summarizing all different experiments $\mu_{tot},\sigma_{tot}$ ? Basically I have $X_1\sim N(\mu_1,\sigma^2_1), X_2\sim N(\mu_2,\sigma^2_2),\ldots,X_n\sim N(\mu_n,\sigma^2_n)$ and $Z=\frac{X_1+X_2+\ldots+X_n}{n}$ . The question is: $Z\sim N(?,?)$","I have a set of data with their means and standard deviations . These values refer to repetitions of the same experiment. How do I calculate the ""mean mean"" (average?) and mean standard deviation summarizing all different experiments ? Basically I have and . The question is:","\mu_1,\mu_2,\ldots\mu_n \sigma_1,\sigma_2,\ldots,\sigma_n \mu_{tot},\sigma_{tot} X_1\sim N(\mu_1,\sigma^2_1), X_2\sim N(\mu_2,\sigma^2_2),\ldots,X_n\sim N(\mu_n,\sigma^2_n) Z=\frac{X_1+X_2+\ldots+X_n}{n} Z\sim N(?,?)","['statistics', 'standard-deviation', 'means']"
73,Probability distribution of discrete variables made of continuous variables,Probability distribution of discrete variables made of continuous variables,,"In my Econometrics class yesterday, our teacher discussed a sample dataset that measured the amount of money spent per patient on doctor's visits in a year. This excluded hospital visits and the cost of drugs. The context was a discussion of generalized linear models, and for the purposes of Stata, he found that a gamma distribution worked best. Good enough. But I started thinking about the dataset itself, and the pdf curve ""total dollars per patient"" might follow. I'm thinking of it as two variables: 1) The number of visits per person (k). Let's use a Poisson distribution with Œª=1, so p(0)=0.368, p(1)=0.368, p(2)=0.184, etc. 2) The cost of each visit (x). Let's use a normal curve with a mean of 50 dollars and a SD of 5 dollars. A person's total expenditure would be the sum of normally distributed variables, or x = N(k50, k25) for k=0 to infinity visits. So a person with no visits would spend nothing, ~.95 of people with one visit would spend between 40 and 60, ~.95 of those with two visits would spend between ~85.86 and ~114.14, three visits would spend ~132.68 and ~167.32, etc. I think a pdf curve would be some combination of these two functions. My guess is that it would look like a vertical line a 0 and a series of decreasing, ever flattening humps at 50, 100, 150 dollars, etc, where the integral of x=(0, inf.) equals 0.632 (because zero visits is p=.0368) Can anyone help me put the pieces together? What would that function be? I've taken through Calc III (multivariate/vector calculus), FYI. Thanks.","In my Econometrics class yesterday, our teacher discussed a sample dataset that measured the amount of money spent per patient on doctor's visits in a year. This excluded hospital visits and the cost of drugs. The context was a discussion of generalized linear models, and for the purposes of Stata, he found that a gamma distribution worked best. Good enough. But I started thinking about the dataset itself, and the pdf curve ""total dollars per patient"" might follow. I'm thinking of it as two variables: 1) The number of visits per person (k). Let's use a Poisson distribution with Œª=1, so p(0)=0.368, p(1)=0.368, p(2)=0.184, etc. 2) The cost of each visit (x). Let's use a normal curve with a mean of 50 dollars and a SD of 5 dollars. A person's total expenditure would be the sum of normally distributed variables, or x = N(k50, k25) for k=0 to infinity visits. So a person with no visits would spend nothing, ~.95 of people with one visit would spend between 40 and 60, ~.95 of those with two visits would spend between ~85.86 and ~114.14, three visits would spend ~132.68 and ~167.32, etc. I think a pdf curve would be some combination of these two functions. My guess is that it would look like a vertical line a 0 and a series of decreasing, ever flattening humps at 50, 100, 150 dollars, etc, where the integral of x=(0, inf.) equals 0.632 (because zero visits is p=.0368) Can anyone help me put the pieces together? What would that function be? I've taken through Calc III (multivariate/vector calculus), FYI. Thanks.",,"['probability', 'statistics', 'probability-distributions']"
74,"$X_1, X_2, ..., X_n \sim Exp(\lambda)$, what's the joint distribution of $X_1, X_1+X_2, ..., X_1+X_2+...X_n$ and is it a uniform ordered distribution?",", what's the joint distribution of  and is it a uniform ordered distribution?","X_1, X_2, ..., X_n \sim Exp(\lambda) X_1, X_1+X_2, ..., X_1+X_2+...X_n","To elaborate on the title, here is the entire problem: Let $X_1, X_2, ..., X_n \thicksim Exp(\lambda)$ be an independent sample. What's the joint distribution of the sequence of $X_1, X_1 + X_2, ..., X_1 + X_2 + ... + X_{n-1}$ with the condition of $X_1 + X_2 + ... + ... + X_n = t$ ? And is this joint distribution equal to an $n-1$ member ordered uniform ( $Unif[0,t]$ ) sample's joint distribution, meaning that: If $Y_1, Y_2, ..., Y_{n-1} \thicksim Unif[0,t]$ independent sample, and we order them: $Y_1^*, Y_2^*, ..., Y_{n-1}^*$ , then are these equal: $$F_{X}(x_1,...,x_{n-1}) = \Bbb{P}(X_1 < x_1, X_1 + X_2 < x_2, ...,~~~ X_1 + X_2 + ... + X_{n-1} < x_{n-1} | X_1 + X_2 + ... + X_n = t) \stackrel{?}{=} \Bbb{P}(Y_1^* < x_1,  Y_2 < x_2, ..., Y_{n-1}^* < x_{n-1}) = F_{Y^*}(x_1,...,x_{n-1})$$ where $F_X$ is the joint distribution function of the $X_1, X_2, ...,X_1 + X_2 + ... + X_{n-1}$ sample with the condition of $\sum_{i=1}^n{X_i} = t$ and $F_{Y^*}$ is the joint distribution function of the $Y_1^*, Y_2^*, ..., Y_{n-1}^*$ sample. If so, prove it; if not, disprove it. The problem is...: ...that $X_1, X_1 + X_2, ..., X_1 + X_2 + ... + X_n$ aren't independent, so calculating the joint distribution function is hard, especially with a condition. Ordered samples also follow a Beta distribution, which is generally tough to deal with: $$\forall k \in \{1,...,n\}: \quad Y_k^* \thicksim \frac{1}{t}Beta(n,n-k+1)$$ Here is what I've tried so far: 1. Introduce new variables: $$A_1 = X_1 \\ A_2 = X_1 + X_2 \\ \vdots \\ A_n = X_1 + X_2 + \dots + X_n$$ This way, we can write up the $X$ 's like so: $$X_1 = A_1 \\ X_2 = A_2 - A_1 \\ X_3 = A_3 - A_2 \\ \vdots \\ X_n = A_n - A_{n-1}$$ We can also calculate the individual distributions of these $A$ 's: $$\forall k \in \{1,...,n\} \quad A_k \thicksim Exp\left(\frac{\lambda}{k}\right)$$ But this didn't lead me much further, since we still can't write up the joint distribution functions of $A$ 's or $X$ 's since they're not independent. 2. I tried thinking outside the box: $X_1 + X_2 + ... + X_k$ could mean the arrival time of a truck, and if they're from an exponential distribution, then their arrival times are expected to be uniform. However, expected value says very little about joint distribution, plus this wouldn't be a very mathematically appropriate proof. Can anyone lead me on the correct path?","To elaborate on the title, here is the entire problem: Let be an independent sample. What's the joint distribution of the sequence of with the condition of ? And is this joint distribution equal to an member ordered uniform ( ) sample's joint distribution, meaning that: If independent sample, and we order them: , then are these equal: where is the joint distribution function of the sample with the condition of and is the joint distribution function of the sample. If so, prove it; if not, disprove it. The problem is...: ...that aren't independent, so calculating the joint distribution function is hard, especially with a condition. Ordered samples also follow a Beta distribution, which is generally tough to deal with: Here is what I've tried so far: 1. Introduce new variables: This way, we can write up the 's like so: We can also calculate the individual distributions of these 's: But this didn't lead me much further, since we still can't write up the joint distribution functions of 's or 's since they're not independent. 2. I tried thinking outside the box: could mean the arrival time of a truck, and if they're from an exponential distribution, then their arrival times are expected to be uniform. However, expected value says very little about joint distribution, plus this wouldn't be a very mathematically appropriate proof. Can anyone lead me on the correct path?","X_1, X_2, ..., X_n \thicksim Exp(\lambda) X_1, X_1 + X_2, ..., X_1 + X_2 + ... + X_{n-1} X_1 + X_2 + ... + ... + X_n = t n-1 Unif[0,t] Y_1, Y_2, ..., Y_{n-1} \thicksim Unif[0,t] Y_1^*, Y_2^*, ..., Y_{n-1}^* F_{X}(x_1,...,x_{n-1}) = \Bbb{P}(X_1 < x_1, X_1 + X_2 < x_2, ...,~~~ X_1 + X_2 + ... + X_{n-1} < x_{n-1} | X_1 + X_2 + ... + X_n = t) \stackrel{?}{=} \Bbb{P}(Y_1^* < x_1,  Y_2 < x_2, ..., Y_{n-1}^* < x_{n-1}) = F_{Y^*}(x_1,...,x_{n-1}) F_X X_1, X_2, ...,X_1 + X_2 + ... + X_{n-1} \sum_{i=1}^n{X_i} = t F_{Y^*} Y_1^*, Y_2^*, ..., Y_{n-1}^* X_1, X_1 + X_2, ..., X_1 + X_2 + ... + X_n \forall k \in \{1,...,n\}: \quad Y_k^* \thicksim \frac{1}{t}Beta(n,n-k+1) A_1 = X_1 \\
A_2 = X_1 + X_2 \\
\vdots \\
A_n = X_1 + X_2 + \dots + X_n X X_1 = A_1 \\
X_2 = A_2 - A_1 \\
X_3 = A_3 - A_2 \\
\vdots \\
X_n = A_n - A_{n-1} A \forall k \in \{1,...,n\} \quad A_k \thicksim Exp\left(\frac{\lambda}{k}\right) A X X_1 + X_2 + ... + X_k","['probability-theory', 'statistics', 'probability-distributions', 'uniform-distribution', 'exponential-distribution']"
75,Determine the value for the constant c that makes the probability statement correct?,Determine the value for the constant c that makes the probability statement correct?,,"$P(c \le |Z|) = 0.016$ where Z is normally distributed . I know that this means that either $Z \ge c$ or $Z \le -c$ , but I'm not sure how to use this to find the value of c.","where Z is normally distributed . I know that this means that either or , but I'm not sure how to use this to find the value of c.",P(c \le |Z|) = 0.016 Z \ge c Z \le -c,"['probability', 'statistics']"
76,How is the log-likelihood for a multinomial logistic regression calculated?,How is the log-likelihood for a multinomial logistic regression calculated?,,"In a multinomial logistic regression, the predicted probability $\pi$ of each outcome $j$ (in a total of $J$ possible outcomes) is given by: $ \pi_j = \frac{e^{A_j}}{1+\sum_{g \neq j}^Je^{A_j}} $ where the value $A_j$ is predicted by a series of predictor variables. For instance, here it is predicted by two covariates ( $x_1$ and $x_2$ ), with their associated regression slopes $\beta_1$ and $\beta_2$ , and the interaction between the two covariates (with associated regression slope $\beta_{12}$ ): $ A_j = e^{(\alpha_j+\beta_{1,j}x_1+\beta_{2,j}x_2+\beta_{12,j}x_1x_2)} $ The model needs to be fitted to real data, and we will want to know how well it fits. For instance, perhaps out of a draw of 10 balls from a sack, 5 were red, 2 were green, and 3 were yellow. We are interested in whether the variables $x_1$ and $x_2$ associated with the sack allow us to predict this result if we plug in the values for $\beta_1$ , $\beta_2$ , and $\beta_{12}$ from the fitted model. To obtain a measure of the goodness-of-fit of the model, we need to calculate the log-likelihood formula for a multinomial logistic regression. I am unsure how to go about this. What is the formula for log-likelihood in a multinomial logistic regression of the kind described above?","In a multinomial logistic regression, the predicted probability of each outcome (in a total of possible outcomes) is given by: where the value is predicted by a series of predictor variables. For instance, here it is predicted by two covariates ( and ), with their associated regression slopes and , and the interaction between the two covariates (with associated regression slope ): The model needs to be fitted to real data, and we will want to know how well it fits. For instance, perhaps out of a draw of 10 balls from a sack, 5 were red, 2 were green, and 3 were yellow. We are interested in whether the variables and associated with the sack allow us to predict this result if we plug in the values for , , and from the fitted model. To obtain a measure of the goodness-of-fit of the model, we need to calculate the log-likelihood formula for a multinomial logistic regression. I am unsure how to go about this. What is the formula for log-likelihood in a multinomial logistic regression of the kind described above?","\pi j J 
\pi_j = \frac{e^{A_j}}{1+\sum_{g \neq j}^Je^{A_j}}
 A_j x_1 x_2 \beta_1 \beta_2 \beta_{12} 
A_j = e^{(\alpha_j+\beta_{1,j}x_1+\beta_{2,j}x_2+\beta_{12,j}x_1x_2)}
 x_1 x_2 \beta_1 \beta_2 \beta_{12}","['statistics', 'regression', 'logistic-regression', 'log-likelihood']"
77,Can probabilities sometimes add to greater than one?,Can probabilities sometimes add to greater than one?,,"I read on my textbook that in a certain scenario, the sum of the probabilities is supposed to equal to one. However, I read an example of an event on this site, and it says in some cases, independent events can add to greater than one. For example, if you add the probability of the chance of getting a red card from a pack of cards OR getting a tails on a coin flip, these events could be greater than one, and the sample space could therefore be greater than one. Is this example, could the probabilities add to greater than one, and is it possible for the sample space to be greater than one? Or is this impossible?","I read on my textbook that in a certain scenario, the sum of the probabilities is supposed to equal to one. However, I read an example of an event on this site, and it says in some cases, independent events can add to greater than one. For example, if you add the probability of the chance of getting a red card from a pack of cards OR getting a tails on a coin flip, these events could be greater than one, and the sample space could therefore be greater than one. Is this example, could the probabilities add to greater than one, and is it possible for the sample space to be greater than one? Or is this impossible?",,['statistics']
78,expectation of absolute value of cauchy distribution & general questions about expectation of absolute value of distributions,expectation of absolute value of cauchy distribution & general questions about expectation of absolute value of distributions,,"The Cauchy distribution has PDF: $$f_X(x) = \frac{1}{\pi(1 + x^2)}$$ Its expectation does not exist. If we wanted to compute the expectation of the absolute value of this distribution, would it be correct to do the following: $$E(|X|) = \int_{-\infty}^{\infty} |x| \cdot \frac{1}{\pi(1 + x^2)} dx = \int_{-\infty}^{0} -x \cdot \frac{1}{\pi(1 + x^2)} dx + \int_{0}^{\infty} x \cdot \frac{1}{\pi(1 + x^2)} dx$$ If I'm not mistaken, neither of the integrals in the above sum of integrals converges, so does this mean that the expectation of the absolute value also does not exist? Furthermore, is this a general result (that if the expectation of the original distribution does not exist, the expectation of the absolute value of the distribution also does not exist), or is it specific to just this distribution? And what about the converse: if the expectation of the absolute value of the distribution does not exist, what can we conclude (if anything) about the expectation of the original distribution?","The Cauchy distribution has PDF: Its expectation does not exist. If we wanted to compute the expectation of the absolute value of this distribution, would it be correct to do the following: If I'm not mistaken, neither of the integrals in the above sum of integrals converges, so does this mean that the expectation of the absolute value also does not exist? Furthermore, is this a general result (that if the expectation of the original distribution does not exist, the expectation of the absolute value of the distribution also does not exist), or is it specific to just this distribution? And what about the converse: if the expectation of the absolute value of the distribution does not exist, what can we conclude (if anything) about the expectation of the original distribution?",f_X(x) = \frac{1}{\pi(1 + x^2)} E(|X|) = \int_{-\infty}^{\infty} |x| \cdot \frac{1}{\pi(1 + x^2)} dx = \int_{-\infty}^{0} -x \cdot \frac{1}{\pi(1 + x^2)} dx + \int_{0}^{\infty} x \cdot \frac{1}{\pi(1 + x^2)} dx,"['probability', 'probability-theory', 'statistics', 'probability-distributions']"
79,Minimum of random variables iid,Minimum of random variables iid,,"I have lots of problems trying to solve problems involving maximum and minimum of random variables. For example: Let $X_{1},X_{2},...,X_{n}$ random variables iid and $f_{X}(x)= \frac{1}{x^{2}}$ when $x\geq 1$ and $f_{X}(x)=0$ in other case. My problem is that I have no idea how to deal with the $Z=min\{X_{1},...,X_{n}\}$ , I should be able to find $F_{Z}(z)$ and $f_{Z}(z)$ . Thanks so much in advance for all your help.","I have lots of problems trying to solve problems involving maximum and minimum of random variables. For example: Let random variables iid and when and in other case. My problem is that I have no idea how to deal with the , I should be able to find and . Thanks so much in advance for all your help.","X_{1},X_{2},...,X_{n} f_{X}(x)= \frac{1}{x^{2}} x\geq 1 f_{X}(x)=0 Z=min\{X_{1},...,X_{n}\} F_{Z}(z) f_{Z}(z)","['probability', 'statistics']"
80,What's the meaning of multiplicative errors and additive errors?,What's the meaning of multiplicative errors and additive errors?,,"Such skewed, thick-tailed data suggest a model with multiplicative errors instead of additive errors. A standard solution is to transform the dependent variable by taking the natural logarithm. Can anyone explain multiplicative errors and additive errors here? Many thanks in advance!","Such skewed, thick-tailed data suggest a model with multiplicative errors instead of additive errors. A standard solution is to transform the dependent variable by taking the natural logarithm. Can anyone explain multiplicative errors and additive errors here? Many thanks in advance!",,['statistics']
81,the expected amount of time that the 3:00 appointment spends at the doctor‚Äôs office.,the expected amount of time that the 3:00 appointment spends at the doctor‚Äôs office.,,"A doctor has scheduled two appointments, one at 2:00 P.M. and the other at 3:00 P.M. The amounts of time that appointments last are independent exponential random variables with mean 60 minutes. Assuming that both patients are on time, find the expected amount of time that the 3:00 appointment spends at the doctor‚Äôs office. I tried to find my own solution by using conditional expectation where : $T_1 (\text{time appointment 2:00 P.M leaves before 3:00 P.M})$ $T_2 (\text{time appointment 2:00 P.M leaves after 3:00 P.M})$ $\mathbb{E}(T_1)=\mathbb{E}(T_2)=60.$ My solution is: $$\mathbb{E}(\text{T spent time})=\mathbb{E}(T{|}T_1\le 60)\mathbb{P}(T_1\le 60)+\mathbb{E}(T{|}T_2\ge 60)\mathbb{P}(T_2\ge 60)$$ $$=\mathbb{E}(T_1)\int _0^{60}\:\frac{1}{60}e^{-\frac{1}{60}t_1}dt_1+\mathbb{E}(T_2)\int _{60}^{\infty }\frac{1}{60}e^{-\frac{1}{60}t_2}dt_2$$ $$=60(1-e^{-1})+60(e^{-1})=60.$$ I see this is wrong answer , and I'm not sure if $$\mathbb{E}(T{|}T_1\le 60)=\mathbb{E}(T_1)$$ $$\mathbb{E}(T{|}T_2\ge 60)=\mathbb{E}(T_2)$$","A doctor has scheduled two appointments, one at 2:00 P.M. and the other at 3:00 P.M. The amounts of time that appointments last are independent exponential random variables with mean 60 minutes. Assuming that both patients are on time, find the expected amount of time that the 3:00 appointment spends at the doctor‚Äôs office. I tried to find my own solution by using conditional expectation where : My solution is: I see this is wrong answer , and I'm not sure if",T_1 (\text{time appointment 2:00 P.M leaves before 3:00 P.M}) T_2 (\text{time appointment 2:00 P.M leaves after 3:00 P.M}) \mathbb{E}(T_1)=\mathbb{E}(T_2)=60. \mathbb{E}(\text{T spent time})=\mathbb{E}(T{|}T_1\le 60)\mathbb{P}(T_1\le 60)+\mathbb{E}(T{|}T_2\ge 60)\mathbb{P}(T_2\ge 60) =\mathbb{E}(T_1)\int _0^{60}\:\frac{1}{60}e^{-\frac{1}{60}t_1}dt_1+\mathbb{E}(T_2)\int _{60}^{\infty }\frac{1}{60}e^{-\frac{1}{60}t_2}dt_2 =60(1-e^{-1})+60(e^{-1})=60. \mathbb{E}(T{|}T_1\le 60)=\mathbb{E}(T_1) \mathbb{E}(T{|}T_2\ge 60)=\mathbb{E}(T_2),"['statistics', 'stochastic-processes', 'conditional-expectation', 'exponential-distribution']"
82,"Proving independence of $N(\mu,\sigma^2)$ sample mean $\bar X$ and variance $S^2$ by change of variables",Proving independence of  sample mean  and variance  by change of variables,"N(\mu,\sigma^2) \bar X S^2","Let $X_1,...,X_n$ are iid sample from $N(\mu,\sigma^2)$ . Then $\bar X$ and $S^2$ are independent. I was stuck on proving above statement. The joint PDF of $(X_1, ... ,X_n)$ is given by $$f(x_1,...,x_n)=\frac{1}{\sqrt {2\pi\sigma^2}}exp \bigg[-\frac{\sum_{i=1}^{n}(x_i-\mu)^2}{2\sigma^2}\bigg]$$ $$=\frac{1}{\sqrt {2\pi\sigma^2}}exp\biggl[-\frac{1}{2\sigma^2}\biggl\{\sum_{i=1}^{n}(x_i-\bar x_n)^2+n(\mu-\bar x_n)^2\biggl\}\biggl] $$ Now, consider the following transformation $y_i=\bar x_n$ and $ y_i=x_i-\bar x_n, i=2,3,...,n$ then $x_1-\bar x_n = -\sum_{i=1}^{n}(x_i-\bar x_n)=-\sum_{i=1}^{n}y_i$ Thus $\sum_{i=1}^{n}(x_i-\bar x_n)^2=\biggl(-\sum_{i=1}^{n}y_i\biggr)^2+\sum_{i=1}^{n}y_i^2$ The joint PDF of $y_1,...,y_n$ is given by $$f(y_1,...,y_n)=J\Biggl(\frac{1}{\sqrt {2\pi\sigma^2}}\Biggr)^n exp\Biggl[\frac{1}{2\sigma^2}\Biggl\{\Biggl(\sum_{i=1}^{n}y_i\Biggr)^2+\sum_{i=1}^{n}y_i^2+n(y_1-\mu)^2\Biggr\}\Biggr]$$ $$=g(y_2,..,y_n)h(y_1)$$ ,where $J$ denotes the Jacobian, $g(y_2,..,y_n)$ is joint PDF of $y2,...,y_n$ and $h(y_1)$ is marginal PDF of $Y_1$ I don't understand how the joint PDF of $y_1,...y_n$ could be broken into such two part. I guess $E(Y_1)=\mu, Var(y_1)=\sigma^2$ such that $Y_1$ follows $N(0,\sigma^2)$ . So, I guess rear part of exponential, $\frac{J}{\sqrt {2\pi\sigma^2}} exp\Biggl[\frac{n(y_1-\mu)^2}{2\sigma^2}\Biggl]$ , means $h$ . But, I'm not sure because of multiple of $n$ . Further, I don't know how $g$ could be derived from  that front part of the exponential. Please give me a hint!","Let are iid sample from . Then and are independent. I was stuck on proving above statement. The joint PDF of is given by Now, consider the following transformation and then Thus The joint PDF of is given by ,where denotes the Jacobian, is joint PDF of and is marginal PDF of I don't understand how the joint PDF of could be broken into such two part. I guess such that follows . So, I guess rear part of exponential, , means . But, I'm not sure because of multiple of . Further, I don't know how could be derived from  that front part of the exponential. Please give me a hint!","X_1,...,X_n N(\mu,\sigma^2) \bar X S^2 (X_1, ... ,X_n) f(x_1,...,x_n)=\frac{1}{\sqrt {2\pi\sigma^2}}exp \bigg[-\frac{\sum_{i=1}^{n}(x_i-\mu)^2}{2\sigma^2}\bigg] =\frac{1}{\sqrt {2\pi\sigma^2}}exp\biggl[-\frac{1}{2\sigma^2}\biggl\{\sum_{i=1}^{n}(x_i-\bar x_n)^2+n(\mu-\bar x_n)^2\biggl\}\biggl]  y_i=\bar x_n  y_i=x_i-\bar x_n, i=2,3,...,n x_1-\bar x_n = -\sum_{i=1}^{n}(x_i-\bar x_n)=-\sum_{i=1}^{n}y_i \sum_{i=1}^{n}(x_i-\bar x_n)^2=\biggl(-\sum_{i=1}^{n}y_i\biggr)^2+\sum_{i=1}^{n}y_i^2 y_1,...,y_n f(y_1,...,y_n)=J\Biggl(\frac{1}{\sqrt {2\pi\sigma^2}}\Biggr)^n exp\Biggl[\frac{1}{2\sigma^2}\Biggl\{\Biggl(\sum_{i=1}^{n}y_i\Biggr)^2+\sum_{i=1}^{n}y_i^2+n(y_1-\mu)^2\Biggr\}\Biggr] =g(y_2,..,y_n)h(y_1) J g(y_2,..,y_n) y2,...,y_n h(y_1) Y_1 y_1,...y_n E(Y_1)=\mu, Var(y_1)=\sigma^2 Y_1 N(0,\sigma^2) \frac{J}{\sqrt {2\pi\sigma^2}} exp\Biggl[\frac{n(y_1-\mu)^2}{2\sigma^2}\Biggl] h n g","['statistics', 'normal-distribution', 'independence', 'jacobian']"
83,"Computing the UMVUE for Uniform$(0,\theta)$",Computing the UMVUE for Uniform,"(0,\theta)","I am having trouble understanding how to compute $\operatorname E[\bar{X}\mid X_{(n)}]$ related to the following premise. Compute the UMVUE using the Rao‚ÄìBlackwell Theorem for the following. $X_1,X_2, \ldots ,X_n$ i.i.d. to $\operatorname{Uniform}(0,\theta)$ . I am able to derive that $\hat{\theta}_\text{MM}=2\bar{X}$ and $\hat{\theta}_\text{MLE}=X_{(n)}$ . Since $\hat{\theta}_\text{MM}$ is unbiased and $X_{(n)}$ is a sufficient estimator, I know that $$\operatorname E[2\bar{X}\mid X_{(n)}]$$ must give us the UMVUE. However, I have no idea how to proceed from here. I appreciate your help.","I am having trouble understanding how to compute related to the following premise. Compute the UMVUE using the Rao‚ÄìBlackwell Theorem for the following. i.i.d. to . I am able to derive that and . Since is unbiased and is a sufficient estimator, I know that must give us the UMVUE. However, I have no idea how to proceed from here. I appreciate your help.","\operatorname E[\bar{X}\mid X_{(n)}] X_1,X_2, \ldots ,X_n \operatorname{Uniform}(0,\theta) \hat{\theta}_\text{MM}=2\bar{X} \hat{\theta}_\text{MLE}=X_{(n)} \hat{\theta}_\text{MM} X_{(n)} \operatorname E[2\bar{X}\mid X_{(n)}]","['probability-theory', 'statistics']"
84,Explain conditional expectations and taking out measurable random variables,Explain conditional expectations and taking out measurable random variables,,"We have the following property of conditional expectations from the point of veiw of measure theory ( $X$ and $Y$ are two random variables): $$\mathbb{E}(XY\mid\mathcal{G})=X\operatorname{\mathbb{E}}(Y\mid\mathcal{G}) $$ when $X$ is $\mathcal{G}$ -measurable. Shreve calls this property: Taking out what is known . Now, I know that how this works in statistics. Also, I know the definition of measurable function in Measure Theory. But I don't get the intuition here. Since when ""measurable"" is the same as ""known""? I always thought that ""measurable"" random variable was one that can be assigned probabilities and events to. This wouldn't make it necessarily known. Can you explain?","We have the following property of conditional expectations from the point of veiw of measure theory ( and are two random variables): when is -measurable. Shreve calls this property: Taking out what is known . Now, I know that how this works in statistics. Also, I know the definition of measurable function in Measure Theory. But I don't get the intuition here. Since when ""measurable"" is the same as ""known""? I always thought that ""measurable"" random variable was one that can be assigned probabilities and events to. This wouldn't make it necessarily known. Can you explain?",X Y \mathbb{E}(XY\mid\mathcal{G})=X\operatorname{\mathbb{E}}(Y\mid\mathcal{G})  X \mathcal{G},"['statistics', 'measure-theory', 'conditional-expectation']"
85,Most powerful test for discrete uniform,Most powerful test for discrete uniform,,"Let $X$ be a random sample from a discrete distribution with the probability mass function $f(x, \theta) =\frac{1}{\theta} , x=1,2,...,\theta;= 0 \ \text{otherwise}   $ where $\theta \ \text {is either 20 or 40} $ is the unknown parameter. Consider testing $H_{0}: \theta = 40$ against $H_{1}: \theta = 20$ Find the uniformly most powerful level $\alpha=0.1$ test for testing $H_{0}$ vs $H_{1}$ I am new to construction of MP tests, and I was trying to use Neyman Pearson Lemma to construct the test but however the ratio is meaningless here as the support of the two distributions are different in the two hypotheses, so how will I tackle this problem?","Let be a random sample from a discrete distribution with the probability mass function where is the unknown parameter. Consider testing against Find the uniformly most powerful level test for testing vs I am new to construction of MP tests, and I was trying to use Neyman Pearson Lemma to construct the test but however the ratio is meaningless here as the support of the two distributions are different in the two hypotheses, so how will I tackle this problem?","X f(x, \theta) =\frac{1}{\theta} , x=1,2,...,\theta;= 0 \ \text{otherwise}    \theta \ \text {is either 20 or 40}  H_{0}: \theta = 40 H_{1}: \theta = 20 \alpha=0.1 H_{0} H_{1}","['statistics', 'statistical-inference']"
86,Covariance for stochastic variables,Covariance for stochastic variables,,"if $X$ and $Y$ are stochastic variables with $\operatorname{Var}(X)=1.34$ and $\operatorname{Cov}(X,Y) = 0.64$, find $\operatorname{Cov}(2X, 3X+2Y)$. No ideas on this one, as I don't see any way of combining the formulas I know to figure this out. I would greatly appreciate some hints","if $X$ and $Y$ are stochastic variables with $\operatorname{Var}(X)=1.34$ and $\operatorname{Cov}(X,Y) = 0.64$, find $\operatorname{Cov}(2X, 3X+2Y)$. No ideas on this one, as I don't see any way of combining the formulas I know to figure this out. I would greatly appreciate some hints",,"['statistics', 'stochastic-processes', 'covariance', 'variance', 'means']"
87,What am I doing wrong in this probability exercise?,What am I doing wrong in this probability exercise?,,"In the experiment of throwing a die $n$ successive times, what's the probability of observing two consecutive 3's? The consecutive threes can be observed in the first and the second throw, in the second and third throw, in the third and fourth throw, in the fourth and fifth throw, ..., and in the (n-1)-th and n-th throw. I would say these combinations account for $(n-1)*6^{n-2}$ favorable outcomes out of a total of $6^{n}$ different possibilities. Then, I concluded the answer had to be something like $(n-1)*6^{n-2}$ over $6^{n}$. Where does my argument go astray? Thanks a bunch for your help","In the experiment of throwing a die $n$ successive times, what's the probability of observing two consecutive 3's? The consecutive threes can be observed in the first and the second throw, in the second and third throw, in the third and fourth throw, in the fourth and fifth throw, ..., and in the (n-1)-th and n-th throw. I would say these combinations account for $(n-1)*6^{n-2}$ favorable outcomes out of a total of $6^{n}$ different possibilities. Then, I concluded the answer had to be something like $(n-1)*6^{n-2}$ over $6^{n}$. Where does my argument go astray? Thanks a bunch for your help",,"['probability', 'probability-theory', 'statistics', 'probability-distributions']"
88,Proof that loss function for linear regression is an ellipsoid,Proof that loss function for linear regression is an ellipsoid,,"I cannot seem to find a proof that $f(\mathbf{\beta}) = \left\lVert \mathbf{y}-\mathbf{X} \mathbf{\beta} \right\rVert^2$ is an ellipsoid, centered at the OLS solution $\hat{\beta}$. Can anyone show how to convert it to the quadratic form of a general ellipsoid, i.e. $(\beta - \hat{\beta})^T \mathbf{A} (\beta - \hat{\beta})$, where $\mathbf{A}$ is positive definite?","I cannot seem to find a proof that $f(\mathbf{\beta}) = \left\lVert \mathbf{y}-\mathbf{X} \mathbf{\beta} \right\rVert^2$ is an ellipsoid, centered at the OLS solution $\hat{\beta}$. Can anyone show how to convert it to the quadratic form of a general ellipsoid, i.e. $(\beta - \hat{\beta})^T \mathbf{A} (\beta - \hat{\beta})$, where $\mathbf{A}$ is positive definite?",,['statistics']
89,Expectation value : trials with and without replacement,Expectation value : trials with and without replacement,,"Two cards are drawn at random from a deck of cards. Let X be the   number of aces obtained. Then the value of E(X) is Direct Method $$ P(X=0)=P(\text{no ace})=\frac{{}^{48}C_2}{{}^{52}C_2}=\frac{48*47}{52*51}\\ P(X=1)=P(1 \text{ ace and }1\text{ non-ace})=\frac{{}^{4}C_1.{}^{48}C_1}{{}^{52}C_2}=\frac{4*48*2}{52*51}\\ P(X=2)=P(2 \text{ non-ace})=\frac{{}^{48}C_2}{{}^{52}C_2}=\frac{4*3}{52*51} $$ $$ E(X)=\frac{384+24}{52*51}=\frac{408}{2652}=\frac{2}{13} $$ Doubt In some references it is solved by considering it a Bernoulli trial, Pls check Method . If the experiment was with replacement, without doubt I'd say it a Bernoulli trial. $$n=2\\p=\frac{4}{52}=\frac{1}{13}\\ E(X)=np=2*\frac{1}{13}=\frac{2}{13}$$ Why do we have the expectation value matching the one with replacement (Bernoulli trial) ?","Two cards are drawn at random from a deck of cards. Let X be the   number of aces obtained. Then the value of E(X) is Direct Method $$ P(X=0)=P(\text{no ace})=\frac{{}^{48}C_2}{{}^{52}C_2}=\frac{48*47}{52*51}\\ P(X=1)=P(1 \text{ ace and }1\text{ non-ace})=\frac{{}^{4}C_1.{}^{48}C_1}{{}^{52}C_2}=\frac{4*48*2}{52*51}\\ P(X=2)=P(2 \text{ non-ace})=\frac{{}^{48}C_2}{{}^{52}C_2}=\frac{4*3}{52*51} $$ $$ E(X)=\frac{384+24}{52*51}=\frac{408}{2652}=\frac{2}{13} $$ Doubt In some references it is solved by considering it a Bernoulli trial, Pls check Method . If the experiment was with replacement, without doubt I'd say it a Bernoulli trial. $$n=2\\p=\frac{4}{52}=\frac{1}{13}\\ E(X)=np=2*\frac{1}{13}=\frac{2}{13}$$ Why do we have the expectation value matching the one with replacement (Bernoulli trial) ?",,"['probability', 'statistics', 'binomial-distribution']"
90,Sum of Poisson and geometric distribution,Sum of Poisson and geometric distribution,,"Suppose that $X$ has Poisson distribution with parameter $Œª$ and that $Y$ has   geometric distribution with parameter $p$ and is independent of $X$. Find a simple formula in terms of $Œª$ and $p$ for $P(X + Y = 2)$ This is what I have so far: Based on $$P(X + Y = n) = \sum_{k=0}^nP(X=k)P(Y=n-k) $$ so $$P(X + Y = 2)=\sum_{k=0}^2{{Œª^ke^{-Œª}}\over k!}p(1-p)^{2-k-1}  $$ $${e^{-Œª}}p(1-p)\sum_{k=0}^2{{Œª^k}\over k!}(1-p)^{-k}  $$ $${e^{-Œª}}p(1-p)\sum_{k=0}^2{\left({{Œª}\over (1-p)}\right)^k {1\over k!}} $$ At this point I do not know how to proceed, or were my previous steps incorrect? [The correct solution is ${e^{-Œª}}p(1-p)+{e^{-Œª}}Œªp$]","Suppose that $X$ has Poisson distribution with parameter $Œª$ and that $Y$ has   geometric distribution with parameter $p$ and is independent of $X$. Find a simple formula in terms of $Œª$ and $p$ for $P(X + Y = 2)$ This is what I have so far: Based on $$P(X + Y = n) = \sum_{k=0}^nP(X=k)P(Y=n-k) $$ so $$P(X + Y = 2)=\sum_{k=0}^2{{Œª^ke^{-Œª}}\over k!}p(1-p)^{2-k-1}  $$ $${e^{-Œª}}p(1-p)\sum_{k=0}^2{{Œª^k}\over k!}(1-p)^{-k}  $$ $${e^{-Œª}}p(1-p)\sum_{k=0}^2{\left({{Œª}\over (1-p)}\right)^k {1\over k!}} $$ At this point I do not know how to proceed, or were my previous steps incorrect? [The correct solution is ${e^{-Œª}}p(1-p)+{e^{-Œª}}Œªp$]",,"['probability', 'statistics', 'probability-distributions']"
91,Variance of dot product of two normalized random vector,Variance of dot product of two normalized random vector,,"Given a set of normalized vectors $\mathbf{x}$ and $\mathbf{y}$ of length $N$,  with each entry independently sampled from $\mathcal{N}(0,1)$ before being divided by the vector norm. By running simulations I got this empirical result: $$var(\mathbf{x}^T\mathbf{y})=\frac{1}{N}$$ Can this be proved?","Given a set of normalized vectors $\mathbf{x}$ and $\mathbf{y}$ of length $N$,  with each entry independently sampled from $\mathcal{N}(0,1)$ before being divided by the vector norm. By running simulations I got this empirical result: $$var(\mathbf{x}^T\mathbf{y})=\frac{1}{N}$$ Can this be proved?",,"['probability', 'statistics', 'random-variables', 'random-matrices']"
92,Under what conditions does $H(X\mid f(Y))=H(X\mid Y)$?,Under what conditions does ?,H(X\mid f(Y))=H(X\mid Y),"I have the problem that I cannot solve: Under what conditions does $H(X‚à£f(Y))=H(X‚à£Y)$? I would like to draw a result about the relation between $p_X(\cdot | g(Y))$ and $p_X(\cdot | Y)$. Are they equal? This is an exercise in the textbook. There is a solution, but I don't think it's correct (more precisely, it is not satisfactory enough). The provided solution is as below. Suggested Solution (not satisfactory). If $H(X|g(Y )) = H(X|Y )$, then $H(X)‚àíH(X|g(Y )) = H(X) ‚àí H(X|Y )$, i.e., $I(X; g(Y )) = I(X; Y )$. This is the condition for equality in the data processing inequality. From the derivation of the inequality, we have equality iff $X ‚Üí g(Y ) ‚Üí Y$ forms a Markov chain. Hence $H(X|g(Y )) = H(X|Y )$ iff $X ‚Üí g(Y ) ‚Üí Y$ . This condition includes many special cases, such as $g$ being one-to-one, and $X$ and $Y$ being independent. However, these two special cases do not exhaust all the possibilities.","I have the problem that I cannot solve: Under what conditions does $H(X‚à£f(Y))=H(X‚à£Y)$? I would like to draw a result about the relation between $p_X(\cdot | g(Y))$ and $p_X(\cdot | Y)$. Are they equal? This is an exercise in the textbook. There is a solution, but I don't think it's correct (more precisely, it is not satisfactory enough). The provided solution is as below. Suggested Solution (not satisfactory). If $H(X|g(Y )) = H(X|Y )$, then $H(X)‚àíH(X|g(Y )) = H(X) ‚àí H(X|Y )$, i.e., $I(X; g(Y )) = I(X; Y )$. This is the condition for equality in the data processing inequality. From the derivation of the inequality, we have equality iff $X ‚Üí g(Y ) ‚Üí Y$ forms a Markov chain. Hence $H(X|g(Y )) = H(X|Y )$ iff $X ‚Üí g(Y ) ‚Üí Y$ . This condition includes many special cases, such as $g$ being one-to-one, and $X$ and $Y$ being independent. However, these two special cases do not exhaust all the possibilities.",,"['probability', 'statistics', 'markov-chains', 'entropy']"
93,How many trials of flipping a coin are needed to be confident in getting very close to the same number of H/T?,How many trials of flipping a coin are needed to be confident in getting very close to the same number of H/T?,,"How many times one would need to flip a coin in order to be very confident of getting close to a $1:1$ ratio of Heads/Tails? By ""very confident"" I mean above $95$% sure, and by ""close to a $1:1$ ratio"" I'm thinking $55$%-$45$% H/T or T/H. I'm running of a simulation where two engines are playing a game against each other, and I'm wondering after how many games I should stop the simulation and check their match score (if the score is close to equal after X number of games, I would infer the engines are most likely equal in strength). I know this is a basic probability/statistics question, but I couldn't find a question addressing this anywhere else.","How many times one would need to flip a coin in order to be very confident of getting close to a $1:1$ ratio of Heads/Tails? By ""very confident"" I mean above $95$% sure, and by ""close to a $1:1$ ratio"" I'm thinking $55$%-$45$% H/T or T/H. I'm running of a simulation where two engines are playing a game against each other, and I'm wondering after how many games I should stop the simulation and check their match score (if the score is close to equal after X number of games, I would infer the engines are most likely equal in strength). I know this is a basic probability/statistics question, but I couldn't find a question addressing this anywhere else.",,"['probability', 'statistics', 'statistical-inference', 'confidence-interval']"
94,Moment generating function of the average of two variables,Moment generating function of the average of two variables,,"I am given two variables $Y_1$ and $Y_2$ obeying an exponential distribution with mean $\beta= 1$ We are asked what the distribution of their average is and the solution must be found using moment generating functions. The solution to this exercise says: Well first, the solution already has a typo since it should be $E[e^{t((1/2)Y_1+(1/2)Y_2)}]$ but moreover, I don't agree that $E[e^{t((1/2)Y_1+(1/2)Y_2)}]=M_{Y_1}(t)M_{Y_2}(t)$ Since $M_{Y_1}(t)M_{Y_2}(t)=E[e^{t(Y_1+Y_2)}]$, from my understanding. So what is the actual solution to this problem?","I am given two variables $Y_1$ and $Y_2$ obeying an exponential distribution with mean $\beta= 1$ We are asked what the distribution of their average is and the solution must be found using moment generating functions. The solution to this exercise says: Well first, the solution already has a typo since it should be $E[e^{t((1/2)Y_1+(1/2)Y_2)}]$ but moreover, I don't agree that $E[e^{t((1/2)Y_1+(1/2)Y_2)}]=M_{Y_1}(t)M_{Y_2}(t)$ Since $M_{Y_1}(t)M_{Y_2}(t)=E[e^{t(Y_1+Y_2)}]$, from my understanding. So what is the actual solution to this problem?",,"['calculus', 'probability', 'statistics', 'probability-distributions', 'moment-generating-functions']"
95,Estimator for $\theta$ using the method of moments,Estimator for  using the method of moments,\theta,"Exercise : Using the method of moments, find the estimator for $\theta$ for a random sample $X_1, \dots, X_n$ that follows the distribution with pdf $f(x) = \theta x^{-2}, \; 0 < \theta \leq x < \infty$, where $\theta$ is the unknown parameter. Attempt : $$m_1' = \bar{X}$$ $$Œº_1' = \int_\theta^xu\theta u^{-2}\mathrm{d}u=\int_\theta^x\theta u^{-1}\mathrm{d}u=\big[\theta \ln u\big]_\theta^x =\theta\ln x - \theta\ln\theta$$ Thus, the estimator is given by : $$m_1' = Œº_1' \Rightarrow \theta\ln x - \theta\ln\theta = \bar{X}$$ But we cannot solve that equation with respect to $\theta$, so we'll take the moments of bigger order : $$m_2' = \frac{1}{n}\sum_{i=1}^nX_i^2$$ $$Œº_2' = \int_\theta^x u^2 \theta u^{-2} \mathrm{d}u = \int_\theta^x \theta \mathrm{d}u = \big[\theta u\big]_\theta^x =\theta x - \theta ^2 $$ Thus the solution of the following quadratic equation for $\theta >0$, gives as the estimator of $\theta$ : $$\theta^2-x\theta +\frac{1}{n}\sum_{i=1}^nX_i^2$$ Question : Is my solution correct ? Shall the upper bound be $x$ or $\infty$ ?","Exercise : Using the method of moments, find the estimator for $\theta$ for a random sample $X_1, \dots, X_n$ that follows the distribution with pdf $f(x) = \theta x^{-2}, \; 0 < \theta \leq x < \infty$, where $\theta$ is the unknown parameter. Attempt : $$m_1' = \bar{X}$$ $$Œº_1' = \int_\theta^xu\theta u^{-2}\mathrm{d}u=\int_\theta^x\theta u^{-1}\mathrm{d}u=\big[\theta \ln u\big]_\theta^x =\theta\ln x - \theta\ln\theta$$ Thus, the estimator is given by : $$m_1' = Œº_1' \Rightarrow \theta\ln x - \theta\ln\theta = \bar{X}$$ But we cannot solve that equation with respect to $\theta$, so we'll take the moments of bigger order : $$m_2' = \frac{1}{n}\sum_{i=1}^nX_i^2$$ $$Œº_2' = \int_\theta^x u^2 \theta u^{-2} \mathrm{d}u = \int_\theta^x \theta \mathrm{d}u = \big[\theta u\big]_\theta^x =\theta x - \theta ^2 $$ Thus the solution of the following quadratic equation for $\theta >0$, gives as the estimator of $\theta$ : $$\theta^2-x\theta +\frac{1}{n}\sum_{i=1}^nX_i^2$$ Question : Is my solution correct ? Shall the upper bound be $x$ or $\infty$ ?",,"['probability', 'statistics', 'probability-distributions', 'parameter-estimation']"
96,"$X$ normally distributed, then $X^T \Sigma ^{-1} X$ follows chi square distribution.","normally distributed, then  follows chi square distribution.",X X^T \Sigma ^{-1} X,"Suppose $X\sim \mathcal{N} _p (0, \Sigma )$. I am not sure why $X^{\top} \Sigma ^{-1} X$ follows a $\chi ^2$-distribution with $p$ degrees of freedom. I think it has something to do with the square root of $\Sigma ^{-1}$, since $$\Sigma ^{-1/2} X \sim \mathcal{N} _p (0, \Sigma ^{-1/2} \Sigma {\Sigma ^{-1/2} }^{\top}) = \mathcal{N} _p (0, \Sigma ^{-1/2} \Sigma ^{1/2} \Sigma ^{1/2}  \Sigma ^{-1/2} ) = \mathcal{N} _p (0, I_p),$$ but how do I know that $\Sigma$ and $\Sigma ^{-1}$ have square roots and how do I know that $\Sigma ^{-1/2}$ is symmetric?","Suppose $X\sim \mathcal{N} _p (0, \Sigma )$. I am not sure why $X^{\top} \Sigma ^{-1} X$ follows a $\chi ^2$-distribution with $p$ degrees of freedom. I think it has something to do with the square root of $\Sigma ^{-1}$, since $$\Sigma ^{-1/2} X \sim \mathcal{N} _p (0, \Sigma ^{-1/2} \Sigma {\Sigma ^{-1/2} }^{\top}) = \mathcal{N} _p (0, \Sigma ^{-1/2} \Sigma ^{1/2} \Sigma ^{1/2}  \Sigma ^{-1/2} ) = \mathcal{N} _p (0, I_p),$$ but how do I know that $\Sigma$ and $\Sigma ^{-1}$ have square roots and how do I know that $\Sigma ^{-1/2}$ is symmetric?",,"['matrices', 'statistics', 'probability-distributions', 'normal-distribution', 'chi-squared']"
97,Convergence in $L^1$ of ratio of random variables,Convergence in  of ratio of random variables,L^1,"If the sequences ${X_n}$ and $Y_n$ converge both almost surely and in $L^1$ to the constants $a$ and $b \ne 0$, respectively, and $Y_n$ is deterministically bounded below by some constant $0 < c \le b$, does this imply that $\mathbb{E}\left[\frac{X_n}{Y_n}\right]$ converges to $\frac{a}{b}$, i.e. does the ratio of $X_n$ and $Y_n$ converge in $L^1$ to $\frac{a}{b}$? [Follow-up: does $\frac{X_n}{Y_n}$ converge almost surely to $\frac{a}{b}$? Edit: Yes, the latter is a trivial consequence of the continuous mapping theorem.] Of course, $\frac{X_n}{Y_n}$ converges in probability to $\frac{a}{b}$, but this does not imply convergence in $L^1$. Intuitively, I think that it should indeed converge in $L^1$, but I am having a tough time taking a crack at this. I've tried using indicator variables, etc., but that does not seem to be the right approach. I would love to know whether this is true, at least for ""nice"" sequences of $X_n$'s and $Y_n$'s [in particular, products and sums of independent Gaussians and finite integer higher powers of independent Gaussians]. I don't need the proof as long as someone can point me to a relevant resource, but if a proof is available I would of course love to see that as well.","If the sequences ${X_n}$ and $Y_n$ converge both almost surely and in $L^1$ to the constants $a$ and $b \ne 0$, respectively, and $Y_n$ is deterministically bounded below by some constant $0 < c \le b$, does this imply that $\mathbb{E}\left[\frac{X_n}{Y_n}\right]$ converges to $\frac{a}{b}$, i.e. does the ratio of $X_n$ and $Y_n$ converge in $L^1$ to $\frac{a}{b}$? [Follow-up: does $\frac{X_n}{Y_n}$ converge almost surely to $\frac{a}{b}$? Edit: Yes, the latter is a trivial consequence of the continuous mapping theorem.] Of course, $\frac{X_n}{Y_n}$ converges in probability to $\frac{a}{b}$, but this does not imply convergence in $L^1$. Intuitively, I think that it should indeed converge in $L^1$, but I am having a tough time taking a crack at this. I've tried using indicator variables, etc., but that does not seem to be the right approach. I would love to know whether this is true, at least for ""nice"" sequences of $X_n$'s and $Y_n$'s [in particular, products and sums of independent Gaussians and finite integer higher powers of independent Gaussians]. I don't need the proof as long as someone can point me to a relevant resource, but if a proof is available I would of course love to see that as well.",,"['probability', 'probability-theory', 'statistics', 'measure-theory', 'convergence-divergence']"
98,Probability of getting full house in poker,Probability of getting full house in poker,,"I have this problem which I have solved, but using two different methods. I am quite new to combinatorics and want to know how to intuitively understand the difference between the following two methods. The problem consist of calculating the probability of getting a full house being dealt a 5-card poker hand. First of, I solve this by simply saying that $P($get full house$)=\frac{2 {13\choose 2} {4 \choose 3} {4 \choose 2}}{{52 \choose 5}}$. This is the right answer according to my text-book. However, at my first attempt at solving this I forgot the factor 2 in the numerator. My reasoning goes like this: All the possible ways of getting a full house consists of all the ways we can combine two different ranks (i.e. ${13 \choose 2}$) times all the possible ways of choosing 3 cards out of 4 suits, times all the possible ways of choosing 2 cards out of 4 suits. Now, all this seems logical to me. The thing that makes me doubt whether I truly understand what I'm doing is how the factor 2 comes in place. I'm thinking: Because we choose two different ranks without regards to order, we have to compensate for those combinations and therefore multiply with $2!$, because obviously it does matter if I (for example) choose the ranks (ace,knights) and in this sequence choose three ace and two knights. On the other hand, I can solve the problem using the method described here: https://math.stackexchange.com/a/808328/518320 Which as well seems intuitively clear, thinking the way the user describe the process in that thread. What is the difference in the two methods? Maybe this is obvious, but I'm new to combinatorics. And is my reasoning above accurate? Thanks!","I have this problem which I have solved, but using two different methods. I am quite new to combinatorics and want to know how to intuitively understand the difference between the following two methods. The problem consist of calculating the probability of getting a full house being dealt a 5-card poker hand. First of, I solve this by simply saying that $P($get full house$)=\frac{2 {13\choose 2} {4 \choose 3} {4 \choose 2}}{{52 \choose 5}}$. This is the right answer according to my text-book. However, at my first attempt at solving this I forgot the factor 2 in the numerator. My reasoning goes like this: All the possible ways of getting a full house consists of all the ways we can combine two different ranks (i.e. ${13 \choose 2}$) times all the possible ways of choosing 3 cards out of 4 suits, times all the possible ways of choosing 2 cards out of 4 suits. Now, all this seems logical to me. The thing that makes me doubt whether I truly understand what I'm doing is how the factor 2 comes in place. I'm thinking: Because we choose two different ranks without regards to order, we have to compensate for those combinations and therefore multiply with $2!$, because obviously it does matter if I (for example) choose the ranks (ace,knights) and in this sequence choose three ace and two knights. On the other hand, I can solve the problem using the method described here: https://math.stackexchange.com/a/808328/518320 Which as well seems intuitively clear, thinking the way the user describe the process in that thread. What is the difference in the two methods? Maybe this is obvious, but I'm new to combinatorics. And is my reasoning above accurate? Thanks!",,"['probability', 'combinatorics', 'probability-theory', 'statistics', 'discrete-mathematics']"
99,Zero conditional mean and zero correlation,Zero conditional mean and zero correlation,,"$\newcommand{\Cov}{\mathrm{Cov}}$ $\newcommand{\E}{\mathrm{E}}$ Is $E(Y|X)=0$ equivalent to $\Cov(X,Y)=0$? I know $E(Y|X)=0$ implies $\Cov(X,Y)=0$, because $\Cov(X,Y) = \E(XY) - \E(X)\E(Y) = \E[\E(XY|X)]-E[X]E[E(Y|X)]=0$ But is the other way around true? Does $\Cov(X,Y)=0$ imply $E(Y|X)=0$? Can anyone give a proof or disproof? Thanks.","$\newcommand{\Cov}{\mathrm{Cov}}$ $\newcommand{\E}{\mathrm{E}}$ Is $E(Y|X)=0$ equivalent to $\Cov(X,Y)=0$? I know $E(Y|X)=0$ implies $\Cov(X,Y)=0$, because $\Cov(X,Y) = \E(XY) - \E(X)\E(Y) = \E[\E(XY|X)]-E[X]E[E(Y|X)]=0$ But is the other way around true? Does $\Cov(X,Y)=0$ imply $E(Y|X)=0$? Can anyone give a proof or disproof? Thanks.",,"['probability', 'statistics', 'linear-regression']"
