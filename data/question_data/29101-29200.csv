,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Reaching a level before another for a random walk,Reaching a level before another for a random walk,,"Suppose we are given a simple random walk starting in $0$, i.e. $(X_k)_{k\in\mathbb{N}}$ with $P[X_k=+1]=P[X_k=-1]=\frac{1}{2}$. What is the probability of hitting the level $a$ before hitting the level $b$, where we assume $b<0<a$ and $|a|\le |b|$. Let's define $$T_a:=\inf\{n|S_n=a\}$$ and similarly $$ T_b:=\inf\{n|S_n=b\}$$ where $S_n:=\sum_{i=1}^nX_i$. Therefore we are interested in the probability $$P[T_a< T_b]$$ I think one needs the reflection principle at some point, but I'm not sure how it is exactly applied.","Suppose we are given a simple random walk starting in $0$, i.e. $(X_k)_{k\in\mathbb{N}}$ with $P[X_k=+1]=P[X_k=-1]=\frac{1}{2}$. What is the probability of hitting the level $a$ before hitting the level $b$, where we assume $b<0<a$ and $|a|\le |b|$. Let's define $$T_a:=\inf\{n|S_n=a\}$$ and similarly $$ T_b:=\inf\{n|S_n=b\}$$ where $S_n:=\sum_{i=1}^nX_i$. Therefore we are interested in the probability $$P[T_a< T_b]$$ I think one needs the reflection principle at some point, but I'm not sure how it is exactly applied.",,"['probability', 'probability-theory', 'random-walk']"
1,A three-way duel (probability puzzle),A three-way duel (probability puzzle),,"This puzzle is taken from Mathematical Puzzles: A Connoisseur's Collection [Peter Winkler]. I don't understand the solution. Alice, Bob, and Carol arrange a three-way duel. Alice is a poor shot, hitting her target only 1/3 of the time on average. Bob is better, hitting his target 2/3 of the time. Carol is a sure shot. They take turns shooting, first Alice, then Bob, the Carol, then back to Alice, and so on until one is left. What is Alice's best course of action? The solution is that Alice is better of missing than hitting Carol or Bob, so she should shoot into the air. Indeed, then Bob will shot Carol, and it can be shown that it gives the greatest probability of survival for Alice. But I wonder if Bob should not voluntary shoot into the air too, so that Carol will do the same, and no one be shot. If this is the case, Alice survival probability is 1. What do you think of it? What is Alice survival probability?","This puzzle is taken from Mathematical Puzzles: A Connoisseur's Collection [Peter Winkler]. I don't understand the solution. Alice, Bob, and Carol arrange a three-way duel. Alice is a poor shot, hitting her target only 1/3 of the time on average. Bob is better, hitting his target 2/3 of the time. Carol is a sure shot. They take turns shooting, first Alice, then Bob, the Carol, then back to Alice, and so on until one is left. What is Alice's best course of action? The solution is that Alice is better of missing than hitting Carol or Bob, so she should shoot into the air. Indeed, then Bob will shot Carol, and it can be shown that it gives the greatest probability of survival for Alice. But I wonder if Bob should not voluntary shoot into the air too, so that Carol will do the same, and no one be shot. If this is the case, Alice survival probability is 1. What do you think of it? What is Alice survival probability?",,"['probability', 'puzzle']"
2,Probability question: $100$ balls with $r$ red balls.,Probability question:  balls with  red balls.,100 r,"Queation: A box contains 100 balls, of which r are red. Suppose that the balls are drawn from the box one at a time, at random, without replacement. Determine (a) the probability that the first ball drawn will be red; (b)the probability that the second ball drawn will be red;(c)the probability that the 50th ball drawn will be red; and (d)the probability that the last ball drawn will be red. Answer: I know that the answer for each of $(a),(b),(c)$ and $(d)$ is $\frac{r}{100}$. For (a), it is trivial. For (b), $Pr$(the second ball drawn will be red)$=Pr$(the first ball drawn is red and second is also red)$+Pr$(the first ball drawn is not red but second is red)$$=\bigg(\frac{r}{100}\frac{r-1}{99}\bigg)+\bigg(\frac{100-r}{100}\frac{r}{99}\bigg)=\bigg(\frac{r}{100}\bigg)$$ But I don't know how to generalize the result.That is how to extend the result for $50$ and $100$ balls as asked in (c) and (d). Please help.thank you.","Queation: A box contains 100 balls, of which r are red. Suppose that the balls are drawn from the box one at a time, at random, without replacement. Determine (a) the probability that the first ball drawn will be red; (b)the probability that the second ball drawn will be red;(c)the probability that the 50th ball drawn will be red; and (d)the probability that the last ball drawn will be red. Answer: I know that the answer for each of $(a),(b),(c)$ and $(d)$ is $\frac{r}{100}$. For (a), it is trivial. For (b), $Pr$(the second ball drawn will be red)$=Pr$(the first ball drawn is red and second is also red)$+Pr$(the first ball drawn is not red but second is red)$$=\bigg(\frac{r}{100}\frac{r-1}{99}\bigg)+\bigg(\frac{100-r}{100}\frac{r}{99}\bigg)=\bigg(\frac{r}{100}\bigg)$$ But I don't know how to generalize the result.That is how to extend the result for $50$ and $100$ balls as asked in (c) and (d). Please help.thank you.",,['probability']
3,Convergence in distribution of Gaussian processes,Convergence in distribution of Gaussian processes,,"Assume given a sequence $(W_n)$ of Gaussian processes indexed by, say, $\mathbb{R}^p$, with mean zero and covariance function $R_n$. This means that for each $n$, the finite-dimensional distributions of $W_n$ are multivariate Gaussian with mean zero, and for each $x,y\in\mathbb{R}^p$, $\textrm{Cov}(W_n(x),W_n(y))=R_n(x,y)$. A priori, each $W_n$ takes its values merely in the space of functions from $\mathbb{R}^p$ to $\mathbb{R}$. To ensure sufficient regularity, assume for definiteness that each $W_n$ in fact takes its values in some Banach space $B$. This could for example be the space of bounded functions, or the space of continuous functions. My question is this: What are sufficient criteria for weak convergence of the sequence $(W_n)$? A few comments: As projections onto finitely many coordinates generally are continuous, it is clear that weak convergence of $W_n$ implies convergence of finite-dimensional distributions. This also means that the candidate limit distribution is uniquely determined by the limits of the finite-dimensional distributions of $W_n$. Therefore, the candidate weak limit $W$ will have to be a Gaussian process as well, taking its values in the same Banach space $B$ as $(W_n)$. What is required for weak convergence of $W_n$ is some notion of tightness, which ideally should be expressed in the relationship between the covariance functions $R_n$ and their limit. One might ask why weak convergence instead of mere convergence of finite-dimensional distributions is interesting: My own main interest is to ensure convergence of functionals such as the supremum as well, and to obtain this, convergence of finite-dimensional distributions in general does not suffice.","Assume given a sequence $(W_n)$ of Gaussian processes indexed by, say, $\mathbb{R}^p$, with mean zero and covariance function $R_n$. This means that for each $n$, the finite-dimensional distributions of $W_n$ are multivariate Gaussian with mean zero, and for each $x,y\in\mathbb{R}^p$, $\textrm{Cov}(W_n(x),W_n(y))=R_n(x,y)$. A priori, each $W_n$ takes its values merely in the space of functions from $\mathbb{R}^p$ to $\mathbb{R}$. To ensure sufficient regularity, assume for definiteness that each $W_n$ in fact takes its values in some Banach space $B$. This could for example be the space of bounded functions, or the space of continuous functions. My question is this: What are sufficient criteria for weak convergence of the sequence $(W_n)$? A few comments: As projections onto finitely many coordinates generally are continuous, it is clear that weak convergence of $W_n$ implies convergence of finite-dimensional distributions. This also means that the candidate limit distribution is uniquely determined by the limits of the finite-dimensional distributions of $W_n$. Therefore, the candidate weak limit $W$ will have to be a Gaussian process as well, taking its values in the same Banach space $B$ as $(W_n)$. What is required for weak convergence of $W_n$ is some notion of tightness, which ideally should be expressed in the relationship between the covariance functions $R_n$ and their limit. One might ask why weak convergence instead of mere convergence of finite-dimensional distributions is interesting: My own main interest is to ensure convergence of functionals such as the supremum as well, and to obtain this, convergence of finite-dimensional distributions in general does not suffice.",,"['probability', 'probability-theory', 'probability-distributions', 'stochastic-processes', 'convergence-divergence']"
4,Probability of getting 'k' heads with 'n' coins,Probability of getting 'k' heads with 'n' coins,,"This is an interview question.( http://www.geeksforgeeks.org/directi-interview-set-1/ ) Given $n$ biased coins, with each coin giving heads with probability $P_i$, find the probability that on tossing the $n$ coins you will obtain exactly $k$ heads. You have to write the formula for this (i.e. the expression that would give $P (n, k)$). I can write a recurrence program for this, but how to write the general expression ?","This is an interview question.( http://www.geeksforgeeks.org/directi-interview-set-1/ ) Given $n$ biased coins, with each coin giving heads with probability $P_i$, find the probability that on tossing the $n$ coins you will obtain exactly $k$ heads. You have to write the formula for this (i.e. the expression that would give $P (n, k)$). I can write a recurrence program for this, but how to write the general expression ?",,['probability']
5,Asymptotic property for coupon collector's problem,Asymptotic property for coupon collector's problem,,"In the classic coupon collector's problem, we let $T_N$ be the time it takes for the collector to collect all of the coupons in the collection. It is easy to see that, in the case where each of the coupons is obtained with probability $\frac1N$ at each step, $T_N$ is a sum of independent geometric random variables which yields $\mathbb E[T_N]=NH_N$ and in turn $\lim_{N\rightarrow\infty}\frac{\mathbb E[T_N]}{N\log N}=1$ . Knowing this, how can one show that : $$\lim_{N\rightarrow\infty}\mathbb P(T_N-N\log N\le Nx)=e^{-e^{-x}},\quad x\in\mathbb R$$ ? I tried multiple different approaches, but nothing has worked thus far. Markov's inequality is a bit useless (as an attempt to exhibit an expectation), and attempting to write $T_N=\sum_{k=0}^{N-1}(T_{k+1}-T_k)$ to get a sum of independent random variables whose laws we know doesn't seem to yield any interesting result either. I feel like it should be possible to express the probability in the left-hand side as $\sum_{k=0}^{N-1}\frac{(-1)^ke^{-kx}}{k!}$ which would give the result by letting $N\rightarrow\infty$ but I don't know how to prove this (nor if it's true for that matter). Any help would be greatly appreciated","In the classic coupon collector's problem, we let be the time it takes for the collector to collect all of the coupons in the collection. It is easy to see that, in the case where each of the coupons is obtained with probability at each step, is a sum of independent geometric random variables which yields and in turn . Knowing this, how can one show that : ? I tried multiple different approaches, but nothing has worked thus far. Markov's inequality is a bit useless (as an attempt to exhibit an expectation), and attempting to write to get a sum of independent random variables whose laws we know doesn't seem to yield any interesting result either. I feel like it should be possible to express the probability in the left-hand side as which would give the result by letting but I don't know how to prove this (nor if it's true for that matter). Any help would be greatly appreciated","T_N \frac1N T_N \mathbb E[T_N]=NH_N \lim_{N\rightarrow\infty}\frac{\mathbb E[T_N]}{N\log N}=1 \lim_{N\rightarrow\infty}\mathbb P(T_N-N\log N\le Nx)=e^{-e^{-x}},\quad x\in\mathbb R T_N=\sum_{k=0}^{N-1}(T_{k+1}-T_k) \sum_{k=0}^{N-1}\frac{(-1)^ke^{-kx}}{k!} N\rightarrow\infty","['probability', 'combinatorics', 'probability-theory', 'probability-distributions']"
6,Kelly Criterion for simultaneous independent bets,Kelly Criterion for simultaneous independent bets,,"I'm trying to obtain a more generic version of the Kelly criterion for when we have simultaneous independent events to bet on, I'm going to focus on the case where we just have 2 different events. In the case where we have just one event the objective is to maximize the function: $$f(x) := p\log(1+bx-x) + (1-p)\log(1-x)$$ $b$ are the odds received and $x$ the fraction of our total wealth that we bet. In the case where we have two events to bet on, I suppose that the function to maximize would be of the form: $$p_1p_2\log(1+x_1b_1+x_2b_2 - x_1-x_2) + p_1(1-p_2)\log(1+x_1b_1- x_1-x_2)+(1-p_1)p_2\log(1+x_2b_2 - x_1-x_2)+(1-p_1)(1-p_2)\log(1- x_1-x_2)$$ As it is differentiable, the problem is equivalent to find the solution of the system of equations: $$p_1p_2\frac{b_1-1}{1+x_1b_1+x_2b_2 - x_1-x_2} + p_1(1-p_2)\frac{b_1-1}{1+x_1b_1- x_1-x_2}=(1-p_1)p_2\frac{1}{1+x_2b_2 - x_1-x_2}+(1-p_1)(1-p_2)\frac{1}{1- x_1-x_2}$$ $$p_1p_2\frac{b_2-1}{1+x_1b_1+x_2b_2 - x_1-x_2} + (1-p_1)p_2\frac{b_2-1}{1+x_2b_2 - x_1-x_2}=p_1(1-p_2)\frac{1}{1+x_1b_1- x_1-x_2}+(1-p_1)(1-p_2)\frac{1}{1- x_1-x_2}$$ However, this seems completely intractable to solve explicitly. I'm asking for your help to do it. Maybe there is some trick to solve it, or I'm not attacking it in the right way. Thank you in advance.","I'm trying to obtain a more generic version of the Kelly criterion for when we have simultaneous independent events to bet on, I'm going to focus on the case where we just have 2 different events. In the case where we have just one event the objective is to maximize the function: $$f(x) := p\log(1+bx-x) + (1-p)\log(1-x)$$ $b$ are the odds received and $x$ the fraction of our total wealth that we bet. In the case where we have two events to bet on, I suppose that the function to maximize would be of the form: $$p_1p_2\log(1+x_1b_1+x_2b_2 - x_1-x_2) + p_1(1-p_2)\log(1+x_1b_1- x_1-x_2)+(1-p_1)p_2\log(1+x_2b_2 - x_1-x_2)+(1-p_1)(1-p_2)\log(1- x_1-x_2)$$ As it is differentiable, the problem is equivalent to find the solution of the system of equations: $$p_1p_2\frac{b_1-1}{1+x_1b_1+x_2b_2 - x_1-x_2} + p_1(1-p_2)\frac{b_1-1}{1+x_1b_1- x_1-x_2}=(1-p_1)p_2\frac{1}{1+x_2b_2 - x_1-x_2}+(1-p_1)(1-p_2)\frac{1}{1- x_1-x_2}$$ $$p_1p_2\frac{b_2-1}{1+x_1b_1+x_2b_2 - x_1-x_2} + (1-p_1)p_2\frac{b_2-1}{1+x_2b_2 - x_1-x_2}=p_1(1-p_2)\frac{1}{1+x_1b_1- x_1-x_2}+(1-p_1)(1-p_2)\frac{1}{1- x_1-x_2}$$ However, this seems completely intractable to solve explicitly. I'm asking for your help to do it. Maybe there is some trick to solve it, or I'm not attacking it in the right way. Thank you in advance.",,"['probability', 'optimization', 'expectation', 'gambling']"
7,Probability that $x^2-y^2$ is divisible by $k$,Probability that  is divisible by,x^2-y^2 k,"Let two numbers $x$ and $y$ be selected from the set of first $n$ natural numbers with replacement(i.e. the two numbers can be same).The question is to find out the probability that $x^2-y^2$ is divisible by $k\in \mathbb{N}$ For $k=2$ Any number can be expressed as $2p,2p+1$.Now $x^2-y^2=(x-y)(x+y)$ If both numbers are of form $2p+1$ then (x-y) would be divisible by $2$ .if two numbers are of different forms then it will not be divisible by $2$.So the probability in this case is $a^2+(1-a)^2$ where $a$ is probability that number chosen is divisible by $2$ which is $\frac{\lfloor \frac{n}{2} \rfloor}{n}$.However this gets complicated with $k=3$ onwards because numbers in different forms may be divisible.In other words if there a generalisation or way to solve for some large $k$.Thanks.","Let two numbers $x$ and $y$ be selected from the set of first $n$ natural numbers with replacement(i.e. the two numbers can be same).The question is to find out the probability that $x^2-y^2$ is divisible by $k\in \mathbb{N}$ For $k=2$ Any number can be expressed as $2p,2p+1$.Now $x^2-y^2=(x-y)(x+y)$ If both numbers are of form $2p+1$ then (x-y) would be divisible by $2$ .if two numbers are of different forms then it will not be divisible by $2$.So the probability in this case is $a^2+(1-a)^2$ where $a$ is probability that number chosen is divisible by $2$ which is $\frac{\lfloor \frac{n}{2} \rfloor}{n}$.However this gets complicated with $k=3$ onwards because numbers in different forms may be divisible.In other words if there a generalisation or way to solve for some large $k$.Thanks.",,['probability']
8,Correlation Coefficient as Cosine,Correlation Coefficient as Cosine,,"I've read that the correlation coefficient between two random variables may be viewed as the cosine as the angle between them, but I can't find any solid explanation. To be concrete, let $X$ and $Y$ be random variables on $(\Omega, \mathcal{F}, P)$ with correlation coefficient $\rho$.  Assume $X,Y \in L^2(\Omega,\mathcal{F},P)$.  The quantity $\rho$ is defined as $$ \rho := \frac{Cov(X,Y)}{\sqrt{Var(X)Var(y)}}. $$ Letting $\mu_X := E(X)$ and $\mu_Y := E(Y)$, note $$ Cov(X,Y) = E((X - \mu_X)(Y - \mu_Y)) = \left< X - \mu_X, Y - \mu_Y\right>_{L^2} $$ and $$ Var(X) = E((X - \mu_X)^2) = ||X - \mu_X||_{L^2}^2, $$ where $L^2 := L^2(\Omega, \mathcal{F}, P)$.  Thus $$ \rho = \frac{\left< X - \mu_X, Y - \mu_Y\right>_{L^2}}{||X - \mu_X||_{L^2} ||Y - \mu_Y||_{L^2}}. \qquad (1) $$ Compare this with the Euclidean space inner product result that for two vectors $x,y \in \mathbb{R}^n$, $$ \cos(\theta) = \frac{x^Ty}{||x||\, ||y||}, $$ where $\theta$ is the angle between $x$ and $y$. The recurring claim I read is that I can think of $\rho$ as the cosine of the ""angle"" between the two random variables, but it seems it only makes sense in terms of $L^2$ inner products.  But in that case, the only notion of ""angle"" between to elements $X,Y \in L^2$ I can think of is $$ \cos(\theta) = \frac{\left< X,Y \right>_{L^2}}{||X||_{L^2} ||Y||_{L^2}}. \qquad (2) $$ So, two questions: Is Eqn. (2) a valid notion of angle in $L^2$? Are Eqns (1) and (2) somehow equlivalent? If both of these are true, I can justify viewing $\rho = \cos(\theta)$.","I've read that the correlation coefficient between two random variables may be viewed as the cosine as the angle between them, but I can't find any solid explanation. To be concrete, let $X$ and $Y$ be random variables on $(\Omega, \mathcal{F}, P)$ with correlation coefficient $\rho$.  Assume $X,Y \in L^2(\Omega,\mathcal{F},P)$.  The quantity $\rho$ is defined as $$ \rho := \frac{Cov(X,Y)}{\sqrt{Var(X)Var(y)}}. $$ Letting $\mu_X := E(X)$ and $\mu_Y := E(Y)$, note $$ Cov(X,Y) = E((X - \mu_X)(Y - \mu_Y)) = \left< X - \mu_X, Y - \mu_Y\right>_{L^2} $$ and $$ Var(X) = E((X - \mu_X)^2) = ||X - \mu_X||_{L^2}^2, $$ where $L^2 := L^2(\Omega, \mathcal{F}, P)$.  Thus $$ \rho = \frac{\left< X - \mu_X, Y - \mu_Y\right>_{L^2}}{||X - \mu_X||_{L^2} ||Y - \mu_Y||_{L^2}}. \qquad (1) $$ Compare this with the Euclidean space inner product result that for two vectors $x,y \in \mathbb{R}^n$, $$ \cos(\theta) = \frac{x^Ty}{||x||\, ||y||}, $$ where $\theta$ is the angle between $x$ and $y$. The recurring claim I read is that I can think of $\rho$ as the cosine of the ""angle"" between the two random variables, but it seems it only makes sense in terms of $L^2$ inner products.  But in that case, the only notion of ""angle"" between to elements $X,Y \in L^2$ I can think of is $$ \cos(\theta) = \frac{\left< X,Y \right>_{L^2}}{||X||_{L^2} ||Y||_{L^2}}. \qquad (2) $$ So, two questions: Is Eqn. (2) a valid notion of angle in $L^2$? Are Eqns (1) and (2) somehow equlivalent? If both of these are true, I can justify viewing $\rho = \cos(\theta)$.",,"['probability', 'probability-theory']"
9,Subtle Twist on the Monty Hall Problem---Does It Make a Difference?,Subtle Twist on the Monty Hall Problem---Does It Make a Difference?,,"In the Monty Hall problem, when the host picks a door and reveals an goat, does it make any difference if he did not know which door the real car was behind, and he just happened to pick a door with a goat?","In the Monty Hall problem, when the host picks a door and reveals an goat, does it make any difference if he did not know which door the real car was behind, and he just happened to pick a door with a goat?",,"['probability', 'monty-hall']"
10,Contradictory recursion,Contradictory recursion,,"I encountered this problem which I find very contradictory to my intuition. Could anyone enlighten me why my recursive formulation is wrong? ""Roll a fair dice until the game stops. The game stops when you get a 4, 5, or 6. For every 1, 2, or 3 your score increases by +1. If the game stops with a 4 or 5, you get paid the accumulated score. If the game stops with a 6 you get nothing. What is the expected payoff of this game?"" Here, my recursive formulation. Let $E$ denote the expected score. First three terms denote the event for 1,2,3 respectively, the fourth and the fifth term denote the event 4,5, the last term is for the event 6. $$E = \frac{1}{6} \left( E + 1 \right) + \frac{1}{6} \left( E + 1 \right) + \frac{1}{6} \left( E + 1 \right) + \frac{1}{6} E + \frac{1}{6} E + \frac{1}{6}\cdot 0\\ = \frac{1}{2}\left( E + 1 \right) + \frac{1}{3} E$$ Solving for $E$, I get $E = 3$. I don't want to take the Markov chain approach with infinite sums. I'd like to take the approach with intuitive recursive equation. The solution guide I have takes a two-step approach of first calculating the expected number of tosses of $\{1,2,3\}$ before the game stops and then computes the expected score conditioning on the output $\{4,5\}$ versus $6$. This approach (while somewhat makes sense) ends up with $\frac{2}{3}$. Could anyone please enlighten me what the problem in my recursive formulation is?","I encountered this problem which I find very contradictory to my intuition. Could anyone enlighten me why my recursive formulation is wrong? ""Roll a fair dice until the game stops. The game stops when you get a 4, 5, or 6. For every 1, 2, or 3 your score increases by +1. If the game stops with a 4 or 5, you get paid the accumulated score. If the game stops with a 6 you get nothing. What is the expected payoff of this game?"" Here, my recursive formulation. Let $E$ denote the expected score. First three terms denote the event for 1,2,3 respectively, the fourth and the fifth term denote the event 4,5, the last term is for the event 6. $$E = \frac{1}{6} \left( E + 1 \right) + \frac{1}{6} \left( E + 1 \right) + \frac{1}{6} \left( E + 1 \right) + \frac{1}{6} E + \frac{1}{6} E + \frac{1}{6}\cdot 0\\ = \frac{1}{2}\left( E + 1 \right) + \frac{1}{3} E$$ Solving for $E$, I get $E = 3$. I don't want to take the Markov chain approach with infinite sums. I'd like to take the approach with intuitive recursive equation. The solution guide I have takes a two-step approach of first calculating the expected number of tosses of $\{1,2,3\}$ before the game stops and then computes the expected score conditioning on the output $\{4,5\}$ versus $6$. This approach (while somewhat makes sense) ends up with $\frac{2}{3}$. Could anyone please enlighten me what the problem in my recursive formulation is?",,"['probability', 'probability-distributions', 'expectation']"
11,Is there an introduction to probability and statistics that balances frequentist and bayesian views?,Is there an introduction to probability and statistics that balances frequentist and bayesian views?,,"Perhaps, roughly, I might be described as advanced undergraduate regarding mathematics. However, I have not learned statistics and have only learned elementary probability. Does there exist a book or monograph that introduces probability and statistics at this level and still covers frequentist and bayesian views (philosophy?) in a balanced manner? It appears to me (but please correct me if I am wrong -- as I have stated I haven't learned this yet) that introductions at this level usually fully adopt a frequentist view and don't really broach the subject. On the other hand, bayesian books appear to be pitched to a more experienced audience and/or are perhaps even more unbalanced, in the sense that they seem anti-frequentist as much as pro-bayesian. To more fully describe my mathematical maturity, I am comfortable with the normal calculus sequence (although somewhat rusty), basic linear algebra, basic set theory, mathematical logic, computability theory, some abstract algebra, very little category theory. I am comfortable with the level of introductory analysis, but have not completed it, and I am not versed in measure theory (I expect I could handle measure theory, but knowledge of it shouldn't be assumed). I am often interested in foundational topics and a philosophical viewpoint, and for example I particularly enjoy reading Peter Smith (e.g. An Introduction to Gödel’s Theorems ).","Perhaps, roughly, I might be described as advanced undergraduate regarding mathematics. However, I have not learned statistics and have only learned elementary probability. Does there exist a book or monograph that introduces probability and statistics at this level and still covers frequentist and bayesian views (philosophy?) in a balanced manner? It appears to me (but please correct me if I am wrong -- as I have stated I haven't learned this yet) that introductions at this level usually fully adopt a frequentist view and don't really broach the subject. On the other hand, bayesian books appear to be pitched to a more experienced audience and/or are perhaps even more unbalanced, in the sense that they seem anti-frequentist as much as pro-bayesian. To more fully describe my mathematical maturity, I am comfortable with the normal calculus sequence (although somewhat rusty), basic linear algebra, basic set theory, mathematical logic, computability theory, some abstract algebra, very little category theory. I am comfortable with the level of introductory analysis, but have not completed it, and I am not versed in measure theory (I expect I could handle measure theory, but knowledge of it shouldn't be assumed). I am often interested in foundational topics and a philosophical viewpoint, and for example I particularly enjoy reading Peter Smith (e.g. An Introduction to Gödel’s Theorems ).",,"['probability', 'statistics', 'reference-request', 'philosophy', 'bayesian']"
12,Is the variance concave?,Is the variance concave?,,"Let $X$ be a discrete random variables with values in the set $\{x_1,\ldots, x_n\}\subset\mathbb{R}$ . Denote by $p_i$ the probability that $X=x_i$ . We can then regard the variance $\mbox{Var}(X)$ as a function of the vector $p\in \Delta^{n-1}\subseteq\mathbb{R}^n$ . Will it be a concave function of $p$ ? With $n=2$ , we get $$\mbox{Var} (X)=p_1p_2(x_1-x_2)^2=p_1(1-p_1)(x_1-x_2)^2$$ which is concave. I'm not sure how to generalize this beyond two dimensions though.","Let be a discrete random variables with values in the set . Denote by the probability that . We can then regard the variance as a function of the vector . Will it be a concave function of ? With , we get which is concave. I'm not sure how to generalize this beyond two dimensions though.","X \{x_1,\ldots, x_n\}\subset\mathbb{R} p_i X=x_i \mbox{Var}(X) p\in \Delta^{n-1}\subseteq\mathbb{R}^n p n=2 \mbox{Var} (X)=p_1p_2(x_1-x_2)^2=p_1(1-p_1)(x_1-x_2)^2","['probability', 'convex-analysis', 'variance']"
13,Probability that a man will hit the target,Probability that a man will hit the target,,"The question is A man can hit a target once in $4$ shots. If he fires 4 shots in succession, what is the probability that he will hit his target? Here is how I am solving it: Since the probability of man hitting the target is $\frac{1}{4}$ so for four consecutive shots it will be $(\frac{1}{4})^4 = \frac{1}{256}$ which is wrong. Now the book takes a different approach and finds the probability that he will not hit the target in one shot = $1 - \frac{1}{4} = \frac{3}{4}$ therefor the probability he will not hit the target in 4 shots is  $(\frac{3}{4})^4$ and thus , the probability that he will hit the target at least in one of the four shots is 1- $(\frac{3}{4})^4$ Although I understand the books approach - I wanted to know why my approach is wrong ? doesnt it also calculate the probability of hitting the target in 4 shots","The question is A man can hit a target once in $4$ shots. If he fires 4 shots in succession, what is the probability that he will hit his target? Here is how I am solving it: Since the probability of man hitting the target is $\frac{1}{4}$ so for four consecutive shots it will be $(\frac{1}{4})^4 = \frac{1}{256}$ which is wrong. Now the book takes a different approach and finds the probability that he will not hit the target in one shot = $1 - \frac{1}{4} = \frac{3}{4}$ therefor the probability he will not hit the target in 4 shots is  $(\frac{3}{4})^4$ and thus , the probability that he will hit the target at least in one of the four shots is 1- $(\frac{3}{4})^4$ Although I understand the books approach - I wanted to know why my approach is wrong ? doesnt it also calculate the probability of hitting the target in 4 shots",,['probability']
14,Is the variance of a sum of infinitely many independent random variables the sum of their variances?,Is the variance of a sum of infinitely many independent random variables the sum of their variances?,,"For $X_i$ independent, is $\operatorname{Var}\left(\sum \limits_{i = 0}^\infty X_i \right) = \sum\limits_{i=0}^\infty \operatorname{Var}(X_i)$? Thanks!","For $X_i$ independent, is $\operatorname{Var}\left(\sum \limits_{i = 0}^\infty X_i \right) = \sum\limits_{i=0}^\infty \operatorname{Var}(X_i)$? Thanks!",,['probability']
15,Probability of the maximum (Levy Stable) random variable in a list being greater than the sum of the rest?,Probability of the maximum (Levy Stable) random variable in a list being greater than the sum of the rest?,,"Original post on Mathoverflow here . Given a list of identical and independently distributed Levy Stable random variables, $(X_0, X_1, \dots, X_{n-1})$, what is the is the probability that the maximum exceeds the sum of the rest?  i.e.: $$ M = \text{Max}(X_0, X_1, \dots, X_{n-1}) $$ $$ \text{Pr}( M > \sum_{j=0}^{n-1} X_j - M ) $$ Where, in Nolan 's notation, $X_j \in S(\alpha, \beta=1, \gamma, \delta=0 ; 0)$, where $\alpha$ is the critical exponent, $\beta$ is the skew, $\gamma$ is the scale parameter and $\delta$ is the shift.  For simplicity, I have taken the skew parameter, $\beta$, to be 1 (maximally skewed to the right) and $\delta=0$ so everything has its mode centered in an interval near 0. From numerical simulations, it appears that for the region of $0 < \alpha < 1$, the probability converges to a constant, irregardless of $n$ or $\gamma$.  Below is a plot of this region for $n=500$, $0< \alpha < 1$, where each point represents the result of 10,000 random draws.  The graph looks exactly the same for $n=100, 200, 300$ and $400$. For $1 < \alpha < 2$ it appears to go as $O(1/n^{\alpha - 1})$ (maybe?) irregardless of $n$ or $\gamma$.  Below is a plot of the probability for $\alpha \in (1.125, 1.3125)$ as a function of $n$.  Note that it is a log-log plot and I have provided the graphs $1/x^{.125}$ and $1/x^{.3125}$ for reference.  It's hard to tell from the graph unless you line them up, but the fit for each is a bit off, and it appears as if the (log-log) slope of the actual data is steeper than my guess for each.  Each point represents 10,000 iterations. For $\alpha=1$ it's not clear (to me) what's going on, but it appears to be a decreasing function dependent on $n$ and $\gamma$. I have tried making a heuristic argument to the in the form of: $$\text{Pr}( M > \sum_{j=0}^{n-1} X_j - M) \le n \text{Pr}( X_0 - \sum_{j=1}^{n-1} X_j > 0 )$$ Then using formula's provided by Nolan (pg. 27) for the parameters of the implicit r.v. $ U = X_0 - \sum_{j=1}^{n-1} X_j$ combined with the tail approximation: $$ \text{Pr}( X > x ) \sim \gamma^{\alpha} c_{\alpha} ( 1 + \beta ) x^{-\alpha} $$ $$ c_{\alpha} = \sin( \pi \alpha / 2) \Gamma(\alpha) / \pi $$ but this leaves me nervous and a bit unsatisfied. Just for comparison, if $X_j$ were taken to be uniform r.v.'s on the unit interval, this function would decrease exponentially quickly.  I imagine similar results hold were the $X_j$'s Gaussian, though any clarification on that point would be appreciated. Getting closed form solutions for this is probably out of the question, as there isn't even a closed form solution for the pdf of Levy-Stable random variables, but getting bounds on what the probability is would be helpful.  I would appreciate any help with regards to how to analyze these types of questions in general such as general methods or references to other work in this area. If this problem is elementary, I would greatly appreciate any reference to a textbook, tutorial or paper that would help me solve problems of this sort. UPDATE :  George Lowther and Shai Covo have answered this question below.  I just wanted to give a few more pictures that compare their answers to some of the numerical experiments that I did. Below is the probability of the maximum element being larger than the rest for a list size of $n=100$ as a function of $\alpha$, $\alpha \in (0,1)$.  Each point represents 10,000 simulations. Below are two graphs for two values of $\alpha \in \{1.53125, 1.875\}$.  Both have the function $ (2/\pi) \sin(\pi \alpha / 2) \Gamma(\alpha) n (( \tan(\pi \alpha/2) (n^{1/\alpha} - n))^{-\alpha} $ with different prescalars in front of them to get them to line up ( $1/4$ and $1/37$, respectively) superimposed for reference. As George Lowther correctly pointed out, for the relatively small $n$ being considered here, the effect of the extra $n^{1/\alpha}$ term (when $1 < \alpha < 2$) is non-negligible and this is why my original reference plots did not line up with the results of the simulations.  Once the full approximation is put in, the fit is much better. When I get around to it, I will try and post some more pictures for the case when $\alpha=1$ as a function of $n$ and $\gamma$.","Original post on Mathoverflow here . Given a list of identical and independently distributed Levy Stable random variables, $(X_0, X_1, \dots, X_{n-1})$, what is the is the probability that the maximum exceeds the sum of the rest?  i.e.: $$ M = \text{Max}(X_0, X_1, \dots, X_{n-1}) $$ $$ \text{Pr}( M > \sum_{j=0}^{n-1} X_j - M ) $$ Where, in Nolan 's notation, $X_j \in S(\alpha, \beta=1, \gamma, \delta=0 ; 0)$, where $\alpha$ is the critical exponent, $\beta$ is the skew, $\gamma$ is the scale parameter and $\delta$ is the shift.  For simplicity, I have taken the skew parameter, $\beta$, to be 1 (maximally skewed to the right) and $\delta=0$ so everything has its mode centered in an interval near 0. From numerical simulations, it appears that for the region of $0 < \alpha < 1$, the probability converges to a constant, irregardless of $n$ or $\gamma$.  Below is a plot of this region for $n=500$, $0< \alpha < 1$, where each point represents the result of 10,000 random draws.  The graph looks exactly the same for $n=100, 200, 300$ and $400$. For $1 < \alpha < 2$ it appears to go as $O(1/n^{\alpha - 1})$ (maybe?) irregardless of $n$ or $\gamma$.  Below is a plot of the probability for $\alpha \in (1.125, 1.3125)$ as a function of $n$.  Note that it is a log-log plot and I have provided the graphs $1/x^{.125}$ and $1/x^{.3125}$ for reference.  It's hard to tell from the graph unless you line them up, but the fit for each is a bit off, and it appears as if the (log-log) slope of the actual data is steeper than my guess for each.  Each point represents 10,000 iterations. For $\alpha=1$ it's not clear (to me) what's going on, but it appears to be a decreasing function dependent on $n$ and $\gamma$. I have tried making a heuristic argument to the in the form of: $$\text{Pr}( M > \sum_{j=0}^{n-1} X_j - M) \le n \text{Pr}( X_0 - \sum_{j=1}^{n-1} X_j > 0 )$$ Then using formula's provided by Nolan (pg. 27) for the parameters of the implicit r.v. $ U = X_0 - \sum_{j=1}^{n-1} X_j$ combined with the tail approximation: $$ \text{Pr}( X > x ) \sim \gamma^{\alpha} c_{\alpha} ( 1 + \beta ) x^{-\alpha} $$ $$ c_{\alpha} = \sin( \pi \alpha / 2) \Gamma(\alpha) / \pi $$ but this leaves me nervous and a bit unsatisfied. Just for comparison, if $X_j$ were taken to be uniform r.v.'s on the unit interval, this function would decrease exponentially quickly.  I imagine similar results hold were the $X_j$'s Gaussian, though any clarification on that point would be appreciated. Getting closed form solutions for this is probably out of the question, as there isn't even a closed form solution for the pdf of Levy-Stable random variables, but getting bounds on what the probability is would be helpful.  I would appreciate any help with regards to how to analyze these types of questions in general such as general methods or references to other work in this area. If this problem is elementary, I would greatly appreciate any reference to a textbook, tutorial or paper that would help me solve problems of this sort. UPDATE :  George Lowther and Shai Covo have answered this question below.  I just wanted to give a few more pictures that compare their answers to some of the numerical experiments that I did. Below is the probability of the maximum element being larger than the rest for a list size of $n=100$ as a function of $\alpha$, $\alpha \in (0,1)$.  Each point represents 10,000 simulations. Below are two graphs for two values of $\alpha \in \{1.53125, 1.875\}$.  Both have the function $ (2/\pi) \sin(\pi \alpha / 2) \Gamma(\alpha) n (( \tan(\pi \alpha/2) (n^{1/\alpha} - n))^{-\alpha} $ with different prescalars in front of them to get them to line up ( $1/4$ and $1/37$, respectively) superimposed for reference. As George Lowther correctly pointed out, for the relatively small $n$ being considered here, the effect of the extra $n^{1/\alpha}$ term (when $1 < \alpha < 2$) is non-negligible and this is why my original reference plots did not line up with the results of the simulations.  Once the full approximation is put in, the fit is much better. When I get around to it, I will try and post some more pictures for the case when $\alpha=1$ as a function of $n$ and $\gamma$.",,"['probability', 'analysis', 'reference-request']"
16,How do I figure out what kind of distribution this is?,How do I figure out what kind of distribution this is?,,"I've sampled a real world process, network ping times. The ""round-trip-time"" is measured in milliseconds. Results are plotted in a histogram: Ping times have a minimum value, but a long upper tail. I want to know what statistical distribution this is, and how to estimate its parameters. Even though the distribution is not a normal distribution, I can still show what I am trying to achieve. The normal distribution uses the function: with the two parameters μ (mean) σ 2 (variance) Parameter estimation The formulas for estimating the two parameters are: Applying these formulas against the data I have in Excel, I get: μ = 10.9558 (mean) σ 2 = 67.4578 (variance) With these parameters I can plot the "" normal "" distribution over top my sampled data: Obviously it's not a normal distribution. A normal distribution has an infinite top and bottom tail, and is symmetrical. This distribution is not symmetrical. What principles would I apply, what flowchart, would I apply to determine what kind of distribution this is? And cutting to the chase, what is the formula for that distribution, and what are the formulas to estimate its parameters? I want to get the distribution so I can get the ""average"" value, as well as the ""spread"": I am actually plotting the histrogram in software, and I want to overlay the theoretical distribution: Tags : sampling, statistics, parameter-estimation, normal-distribution","I've sampled a real world process, network ping times. The ""round-trip-time"" is measured in milliseconds. Results are plotted in a histogram: Ping times have a minimum value, but a long upper tail. I want to know what statistical distribution this is, and how to estimate its parameters. Even though the distribution is not a normal distribution, I can still show what I am trying to achieve. The normal distribution uses the function: with the two parameters μ (mean) σ 2 (variance) Parameter estimation The formulas for estimating the two parameters are: Applying these formulas against the data I have in Excel, I get: μ = 10.9558 (mean) σ 2 = 67.4578 (variance) With these parameters I can plot the "" normal "" distribution over top my sampled data: Obviously it's not a normal distribution. A normal distribution has an infinite top and bottom tail, and is symmetrical. This distribution is not symmetrical. What principles would I apply, what flowchart, would I apply to determine what kind of distribution this is? And cutting to the chase, what is the formula for that distribution, and what are the formulas to estimate its parameters? I want to get the distribution so I can get the ""average"" value, as well as the ""spread"": I am actually plotting the histrogram in software, and I want to overlay the theoretical distribution: Tags : sampling, statistics, parameter-estimation, normal-distribution",,"['probability', 'gamma-function', 'average']"
17,Prove that $\mathbb{E}\exp{\lambda\xi} \le \exp\left(\lambda^2 \Vert\xi\Vert_{\psi_2}^2\right)$,Prove that,\mathbb{E}\exp{\lambda\xi} \le \exp\left(\lambda^2 \Vert\xi\Vert_{\psi_2}^2\right),"Problem: Let $\xi$ be a real random variable. We say that $\xi$ is $\psi_2$ when $\exists \lambda >0$ such that $\mathbb{E}\exp(\xi^2/\lambda^2) \le e$ . We denote by $\Vert \xi \Vert_{\psi_2}$ the infimum of such $\lambda$ , that is \begin{align*}     \Vert \xi \Vert_{\psi_2} = \inf\left\{\lambda > 0: \mathbb{E}\exp(\xi^2/\lambda^2) \le e\right\}. \end{align*} Suppose that $\xi$ is $\psi_2$ and that $\mathbb{E}\xi = 0$ . Prove that $\forall \lambda >0$ $$\mathbb{E}\exp(\lambda \xi) \le \exp\left(\lambda^2 \Vert \xi\Vert_{\psi_2}^2\right).$$ My attempt: By using the inequality $e^{y} \le y+ e^{y^2}$ , we have \begin{align*}     \mathbb{E}\exp(\lambda \xi) &= \int_{-\infty}^{+\infty}\exp(\lambda t) f_{\xi}(t) dt\\     & \le \int_{\infty}^{+\infty}(\lambda t + e^{\lambda^2 t^2})f_\xi(t) dt\\     & \le \lambda \int_{-\infty}^{+\infty}t f_\xi(t)dt + \int_{-\infty}^{+\infty}e^{\lambda^2 t^2}f_\xi(t)dt \\     & = \lambda \mathbb{E}\xi + \int_{-\infty}^{+\infty}e^{\lambda^2 t^2}f_\xi(t)dt = \int_{-\infty}^{+\infty}e^{\lambda^2 t^2}f_\xi(t)dt  \tag{since $\mathbb{E}\xi = 0$}\\ & = \mathbb{E}[\exp(\lambda^2 \xi^2)]\\ & = \mathbb{E}\left[\left(\exp(\xi^2/\Vert \xi\Vert_{\psi_2}^2)\right)^{\lambda^2\Vert \xi \Vert_{\psi_2}^2}\right] \end{align*} Now I am stuck here. I intended to use Jensen's inequality but the function in the exponential is not concave. Hints: I have just got a hint as follows Consider two cases are $\lambda \in ]0,1]$ and $\lambda > 1$ . When $\lambda \in ]0,1]$ use the inequality $e^y \le y + e^{y^2}$ , while for $\lambda >1$ , use the fact that $\lambda \xi \le \dfrac{1}{2}\lambda^2 + \dfrac{1}{2}\xi^2$ .","Problem: Let be a real random variable. We say that is when such that . We denote by the infimum of such , that is Suppose that is and that . Prove that My attempt: By using the inequality , we have Now I am stuck here. I intended to use Jensen's inequality but the function in the exponential is not concave. Hints: I have just got a hint as follows Consider two cases are and . When use the inequality , while for , use the fact that .","\xi \xi \psi_2 \exists \lambda >0 \mathbb{E}\exp(\xi^2/\lambda^2) \le e \Vert \xi \Vert_{\psi_2} \lambda \begin{align*}
    \Vert \xi \Vert_{\psi_2} = \inf\left\{\lambda > 0: \mathbb{E}\exp(\xi^2/\lambda^2) \le e\right\}.
\end{align*} \xi \psi_2 \mathbb{E}\xi = 0 \forall \lambda >0 \mathbb{E}\exp(\lambda \xi) \le \exp\left(\lambda^2 \Vert \xi\Vert_{\psi_2}^2\right). e^{y} \le y+ e^{y^2} \begin{align*}
    \mathbb{E}\exp(\lambda \xi) &= \int_{-\infty}^{+\infty}\exp(\lambda t) f_{\xi}(t) dt\\
    & \le \int_{\infty}^{+\infty}(\lambda t + e^{\lambda^2 t^2})f_\xi(t) dt\\
    & \le \lambda \int_{-\infty}^{+\infty}t f_\xi(t)dt + \int_{-\infty}^{+\infty}e^{\lambda^2 t^2}f_\xi(t)dt \\
    & = \lambda \mathbb{E}\xi + \int_{-\infty}^{+\infty}e^{\lambda^2 t^2}f_\xi(t)dt = \int_{-\infty}^{+\infty}e^{\lambda^2 t^2}f_\xi(t)dt  \tag{since \mathbb{E}\xi = 0}\\
& = \mathbb{E}[\exp(\lambda^2 \xi^2)]\\
& = \mathbb{E}\left[\left(\exp(\xi^2/\Vert \xi\Vert_{\psi_2}^2)\right)^{\lambda^2\Vert \xi \Vert_{\psi_2}^2}\right]
\end{align*} \lambda \in ]0,1] \lambda > 1 \lambda \in ]0,1] e^y \le y + e^{y^2} \lambda >1 \lambda \xi \le \dfrac{1}{2}\lambda^2 + \dfrac{1}{2}\xi^2","['probability', 'inequality', 'probability-distributions', 'random-variables']"
18,Why is the probability that two random chords intersect $2/3$?,Why is the probability that two random chords intersect ?,2/3,"In a circle, a random chord is drawn by connecting a uniformly random point on the circle, with a uniformly random point on the opposite semicircle . (So the chord's length is at least $\sqrt2$ times the radius.) What is the probability that two such independent random chords intersect? I used Excel to run $10^6$ trials, and the proportion of intersecting chords was $0.6665$ , suggesting that the probability is $2/3$ . I am seeking an intuitive explanation for this result. Examples of intuitive explanations Here is an example of an intuitive explanation. Suppose, instead, a random chord is drawn by connecting two uniformly random points on the circle, and we want to find the probability that two such chords intersect. First pick four random points on the circle, labelled $A,B,C,D$ going clockwise. Then pair them randomly, and connect each pair to form two chords. The chords intersect if and only if $A$ is connected to $C$ , which has a probability of $1/3$ .) Here and here are other examples of intuitive explanations. Context I have been thinking about probability questions that have simple answers, but seem to resist intuitive explanation, for example this one . I am also interested in questions about random chords, for example this one . EDIT If a random chord is drawn by connecting a uniformly random point on the circle, with a uniformly random point chosen from the arc with central angle $n\pi$ directly opposite the first point, then what is the probability that two such chords intersect? Well, if $n=0$ , then the probability is obviously $1$ . And if $n=2$ , then the probability is $1/3$ , as explained above. So, assuming that the relationship between $n$ and the probability is linear, then it follows that if $n=1$ (which is the OP) then the probability is indeed $2/3$ . But is it intuitively obvious that the relationship is linear? (In fact, numerical investigation shows that the relationship is linear, i.e. the probability $1-\frac{n}{3}$ .)","In a circle, a random chord is drawn by connecting a uniformly random point on the circle, with a uniformly random point on the opposite semicircle . (So the chord's length is at least times the radius.) What is the probability that two such independent random chords intersect? I used Excel to run trials, and the proportion of intersecting chords was , suggesting that the probability is . I am seeking an intuitive explanation for this result. Examples of intuitive explanations Here is an example of an intuitive explanation. Suppose, instead, a random chord is drawn by connecting two uniformly random points on the circle, and we want to find the probability that two such chords intersect. First pick four random points on the circle, labelled going clockwise. Then pair them randomly, and connect each pair to form two chords. The chords intersect if and only if is connected to , which has a probability of .) Here and here are other examples of intuitive explanations. Context I have been thinking about probability questions that have simple answers, but seem to resist intuitive explanation, for example this one . I am also interested in questions about random chords, for example this one . EDIT If a random chord is drawn by connecting a uniformly random point on the circle, with a uniformly random point chosen from the arc with central angle directly opposite the first point, then what is the probability that two such chords intersect? Well, if , then the probability is obviously . And if , then the probability is , as explained above. So, assuming that the relationship between and the probability is linear, then it follows that if (which is the OP) then the probability is indeed . But is it intuitively obvious that the relationship is linear? (In fact, numerical investigation shows that the relationship is linear, i.e. the probability .)","\sqrt2 10^6 0.6665 2/3 A,B,C,D A C 1/3 n\pi n=0 1 n=2 1/3 n n=1 2/3 1-\frac{n}{3}","['probability', 'geometry', 'circles', 'intuition']"
19,$E[|X-\mu|^n] \le 2 E[|X-\mu|^{n+1}]$ for Integer Random Variables,for Integer Random Variables,E[|X-\mu|^n] \le 2 E[|X-\mu|^{n+1}],"I would like to prove the following moment inequality for all integer random variables ( $X\in\mathbb Z$ ) for which the $n+1$ th moment is defined: $$\mathrm{E}[|X-\mu|^n] \le 2 \mathrm E[|X-\mu|^{n+1}].$$ ( $n\ge1$ , but probably doesn't have to be an integer.) The constant, 2, can't be improved, since it is sharp for the Bernoulli distribution uniform over $\{0,1\}$ . We can assume $\mu=\mathrm E[X]\in[0,1/2]$ by shifting. I know how to show that at least $\mathrm{E}[|X-\mu|^n] \le C \mathrm E[|X-\mu|^{n+1}]$ for some constant $C>0$ , but I wonder how I might get the exact value 2.","I would like to prove the following moment inequality for all integer random variables ( ) for which the th moment is defined: ( , but probably doesn't have to be an integer.) The constant, 2, can't be improved, since it is sharp for the Bernoulli distribution uniform over . We can assume by shifting. I know how to show that at least for some constant , but I wonder how I might get the exact value 2.","X\in\mathbb Z n+1 \mathrm{E}[|X-\mu|^n] \le 2 \mathrm E[|X-\mu|^{n+1}]. n\ge1 \{0,1\} \mu=\mathrm E[X]\in[0,1/2] \mathrm{E}[|X-\mu|^n] \le C \mathrm E[|X-\mu|^{n+1}] C>0",['probability']
20,Can you simulate from a cantor distribution?,Can you simulate from a cantor distribution?,,"Has someone run across a method for generating random variates from a Cantor Distribution ? It seems like its abstract definition prevents this. In essence, can one ""invert"" the Cantor Function ?","Has someone run across a method for generating random variates from a Cantor Distribution ? It seems like its abstract definition prevents this. In essence, can one ""invert"" the Cantor Function ?",,['probability']
21,"The Probability $P_{[m]}$ that exactly $m$ among the $N$ events $A_1,\dots,A_N$ occur simultaneously",The Probability  that exactly  among the  events  occur simultaneously,"P_{[m]} m N A_1,\dots,A_N","For $1\le i_1,i_2,...,i_k\le N$ denote    $$p_{i_1,...,i_k}=\Pr(A_{i_1}\cap A_{i_2}\cap\dots\cap A_{i_k}),$$   $$S_k=\sum\limits_{1\le i_1\le\dots\le i_k\le N}p_{i_1,\dots,i_k}.$$ Show that the probability $P_{[m]}$ that exactly $m$ among the $N$ events $A_1,\dots,A_N$ occur simultaneously is given by    $$P_{[m]}=S_m-\binom{m+1}{m}S_{m+1}+\binom{m+2}{m}S_{m+2}-\dots (-1)^{N-m}\binom{N}{m}S_{N}.$$ We've already proven the inclusion exclusion formula: $$\Pr\left(\bigcup\limits_{i=1}^NA_i\right)=S_1-S_2+S_3-\dots (-1)^{N-1}S_N,$$ but the problem is the factors $\binom{m+1}{m}...$ before $S_i$'s, I cannot really show that.","For $1\le i_1,i_2,...,i_k\le N$ denote    $$p_{i_1,...,i_k}=\Pr(A_{i_1}\cap A_{i_2}\cap\dots\cap A_{i_k}),$$   $$S_k=\sum\limits_{1\le i_1\le\dots\le i_k\le N}p_{i_1,\dots,i_k}.$$ Show that the probability $P_{[m]}$ that exactly $m$ among the $N$ events $A_1,\dots,A_N$ occur simultaneously is given by    $$P_{[m]}=S_m-\binom{m+1}{m}S_{m+1}+\binom{m+2}{m}S_{m+2}-\dots (-1)^{N-m}\binom{N}{m}S_{N}.$$ We've already proven the inclusion exclusion formula: $$\Pr\left(\bigcup\limits_{i=1}^NA_i\right)=S_1-S_2+S_3-\dots (-1)^{N-1}S_N,$$ but the problem is the factors $\binom{m+1}{m}...$ before $S_i$'s, I cannot really show that.",,"['probability', 'combinatorics', 'probability-theory']"
22,Probability $k$ bins are non-empty,Probability  bins are non-empty,k,"The following problem arises in the analysis of Bloom filters . Consider $m$ bins and $N=nk$ balls placed uniformly and independently at random into the bins. A query chooses $k$ bins uniformly and independently at random and asks if they are all non-empty.  The main question is as follows. What is the probability that all $k$ bins in the query are non-empty? It is assumed that this probability will be a function of $k$, $m$ and $n$. The second question is: For what value of $k$ (which is a function of $m$ and $n$) is this probability minimized? The standard version of the analysis taught the world over and reproduced in the wikipedia page linked above contains a ""now the magic occurs"" step which ignores the non-independence of the bins. It gives $k \approx \frac{m}{n} \ln{2}$ as the answer to the second question. Is there a clean and rigorous way of doing this analysis correctly? This is a repost of this one which hasn't had any good answers yet. Clarification. The difficultly arises because the probability that all $k$ bins are non-empty is not $(1-(1-\frac{1}{m})^{kn})^k$. The reason is that the probability that one of the $k$ (not necessarily distinct) bins that is queried is non-empty is dependent on whether the other queries return non-empty bins. An approximate answer or good bounds will suffice.","The following problem arises in the analysis of Bloom filters . Consider $m$ bins and $N=nk$ balls placed uniformly and independently at random into the bins. A query chooses $k$ bins uniformly and independently at random and asks if they are all non-empty.  The main question is as follows. What is the probability that all $k$ bins in the query are non-empty? It is assumed that this probability will be a function of $k$, $m$ and $n$. The second question is: For what value of $k$ (which is a function of $m$ and $n$) is this probability minimized? The standard version of the analysis taught the world over and reproduced in the wikipedia page linked above contains a ""now the magic occurs"" step which ignores the non-independence of the bins. It gives $k \approx \frac{m}{n} \ln{2}$ as the answer to the second question. Is there a clean and rigorous way of doing this analysis correctly? This is a repost of this one which hasn't had any good answers yet. Clarification. The difficultly arises because the probability that all $k$ bins are non-empty is not $(1-(1-\frac{1}{m})^{kn})^k$. The reason is that the probability that one of the $k$ (not necessarily distinct) bins that is queried is non-empty is dependent on whether the other queries return non-empty bins. An approximate answer or good bounds will suffice.",,['probability']
23,The probability of one Gaussian larger than another.,The probability of one Gaussian larger than another.,,"For two Gaussian-distributed variables, $ Pr(X=x) = \frac{1}{\sqrt{2\pi}\sigma_0}e^{-\frac{(x-x_0)^2}{2\sigma_0^2}}$ and $ Pr(Y=y) = \frac{1}{\sqrt{2\pi}\sigma_1}e^{-\frac{(x-x_1)^2}{2\sigma_1^2}}$. What is probability of the case X > Y?","For two Gaussian-distributed variables, $ Pr(X=x) = \frac{1}{\sqrt{2\pi}\sigma_0}e^{-\frac{(x-x_0)^2}{2\sigma_0^2}}$ and $ Pr(Y=y) = \frac{1}{\sqrt{2\pi}\sigma_1}e^{-\frac{(x-x_1)^2}{2\sigma_1^2}}$. What is probability of the case X > Y?",,['probability']
24,Lower bound on Tail Probabilities,Lower bound on Tail Probabilities,,Inequalities such as Markov's and Chebyshev’s provide upper bounds on tail probabilities. Are there similar inequalities that give lower bounds in the form $P(X \geq \alpha)>\theta$?,Inequalities such as Markov's and Chebyshev’s provide upper bounds on tail probabilities. Are there similar inequalities that give lower bounds in the form $P(X \geq \alpha)>\theta$?,,"['probability', 'inequality']"
25,"Kendall notation's ""General distribution"", what does that mean?","Kendall notation's ""General distribution"", what does that mean?",,"The first and second parameters for the Kendall's notation may have a G value, which stands for General distribution , see here . But what does that mean? What is a general distribution ?","The first and second parameters for the Kendall's notation may have a G value, which stands for General distribution , see here . But what does that mean? What is a general distribution ?",,"['probability', 'probability-theory', 'markov-chains', 'markov-process']"
26,Last coupon collected in the coupon collectors problem,Last coupon collected in the coupon collectors problem,,"Consider the classical coupon collectors problem. Given a particular coupon $i$ we can ask for the probability that $i$ is the last coupon collected. We asked this question on cstheory and got a wonderful answer from James Martin introducing us to the idea of Poissonization in coupon collecting: $Pr(L=i) = \displaystyle{\int_{0}^{\infty} n_i e^{n_i t} \prod_{j\neq i} (1-e^{n_j t}) dt}$ where $L$ is the last coupon collected and $n_i$ is the number of coupons of type $i$ , with $\displaystyle{\sum_i n_i = k}$ . For example: $\displaystyle{\int_0^\infty a e^{-a t} \left(1-e^{-b t}\right) \left(1-e^{-c t}\right) \left(1-e^{-d t}\right) \left(1-e^{-e t}\right) \left(1-e^{-f t}\right) \, dt}$ , gives the following in Mathematica: $a \left[\displaystyle{\frac{1}{a}-\frac{1}{a+b}-\frac{1}{a+c}+\frac{1}{a+b+c}-\frac{1}{a+d}+\frac{1}{a+b+d}+\frac{1}{a+c+d}-\frac{1}{a+b+c+d}-} \right.$ $\left. \displaystyle{\frac{1}{a+e}+\frac{1}{a+b+e}+\frac{1}{a+c+e}-\frac{1}{a+b+c+e}+\frac{1}{a+d+e}-\frac{1}{a+b+d+e}-\frac{1}{a+c+d+e}+} \right.$ $\left. \displaystyle{\frac{1}{a+b+c+d+e}-\frac{1}{a+f}+\frac{1}{a+b+f}+\frac{1}{a+c+f}-\frac{1}{a+b+c+f}+\frac{1}{a+d+f}-\frac{1}{a+b+d+f}- }\right.$ $\left. \displaystyle{\frac{1}{a+c+d+f}+\frac{1}{a+b+c+d+f}+\frac{1}{a+e+f}-\frac{1}{a+b+e+f}-\frac{1}{a+c+e+f}+\frac{1}{a+b+c+e+f}-} \right.$ $\left. \displaystyle{\frac{1}{a+d+e+f}+\frac{1}{a+b+d+e+f}+\frac{1}{a+c+d+e+f}-\frac{1}{a+b+c+d+e+f}} \right]$ . The trouble is that this expression takes exponential time in the number of coupons to evaluate and has an exponential number of terms. We are looking for a way to bound this asymptotically in $k$ , but any further references or information would be greatly appreciated.","Consider the classical coupon collectors problem. Given a particular coupon we can ask for the probability that is the last coupon collected. We asked this question on cstheory and got a wonderful answer from James Martin introducing us to the idea of Poissonization in coupon collecting: where is the last coupon collected and is the number of coupons of type , with . For example: , gives the following in Mathematica: . The trouble is that this expression takes exponential time in the number of coupons to evaluate and has an exponential number of terms. We are looking for a way to bound this asymptotically in , but any further references or information would be greatly appreciated.","i i Pr(L=i) = \displaystyle{\int_{0}^{\infty} n_i e^{n_i t} \prod_{j\neq i} (1-e^{n_j t}) dt} L n_i i \displaystyle{\sum_i n_i = k} \displaystyle{\int_0^\infty a e^{-a t} \left(1-e^{-b t}\right) \left(1-e^{-c t}\right) \left(1-e^{-d t}\right) \left(1-e^{-e t}\right) \left(1-e^{-f t}\right) \, dt} a \left[\displaystyle{\frac{1}{a}-\frac{1}{a+b}-\frac{1}{a+c}+\frac{1}{a+b+c}-\frac{1}{a+d}+\frac{1}{a+b+d}+\frac{1}{a+c+d}-\frac{1}{a+b+c+d}-} \right. \left. \displaystyle{\frac{1}{a+e}+\frac{1}{a+b+e}+\frac{1}{a+c+e}-\frac{1}{a+b+c+e}+\frac{1}{a+d+e}-\frac{1}{a+b+d+e}-\frac{1}{a+c+d+e}+} \right. \left. \displaystyle{\frac{1}{a+b+c+d+e}-\frac{1}{a+f}+\frac{1}{a+b+f}+\frac{1}{a+c+f}-\frac{1}{a+b+c+f}+\frac{1}{a+d+f}-\frac{1}{a+b+d+f}- }\right. \left. \displaystyle{\frac{1}{a+c+d+f}+\frac{1}{a+b+c+d+f}+\frac{1}{a+e+f}-\frac{1}{a+b+e+f}-\frac{1}{a+c+e+f}+\frac{1}{a+b+c+e+f}-} \right. \left. \displaystyle{\frac{1}{a+d+e+f}+\frac{1}{a+b+d+e+f}+\frac{1}{a+c+d+e+f}-\frac{1}{a+b+c+d+e+f}} \right] k","['probability', 'combinatorics', 'coupon-collector']"
27,"Besides jointly normal random variable, what other distribution satisfies uncorrelated if and only if independent?","Besides jointly normal random variable, what other distribution satisfies uncorrelated if and only if independent?",,"It is well known that for a jointly normally distributed random variables $(X_1,...,X_n)^T,$ they are uncorrelated if and only if independent. It is also well-known that for any random variable, independent implies uncorrelated but not the converse. Here comes my question: Question: Besides jointly normal random variable, what other distribution satisfies uncorrelated if and only if independent?","It is well known that for a jointly normally distributed random variables they are uncorrelated if and only if independent. It is also well-known that for any random variable, independent implies uncorrelated but not the converse. Here comes my question: Question: Besides jointly normal random variable, what other distribution satisfies uncorrelated if and only if independent?","(X_1,...,X_n)^T,","['probability', 'statistics', 'normal-distribution', 'independence']"
28,Expected maximum of sub-Gaussian,Expected maximum of sub-Gaussian,,"I'm trying to answer the following question from the book high-dimensional probability : Let $X_1,X_2,\dots$ be a sequence of sub-gaussian random variables, which are not necessarily independent. Show that $E\bigg[ \max_i \frac{|X_i|}{\sqrt{1 + \log i}} \bigg] \le CK$ , where $K = \max_i \|X_i\|_{\psi_2}$ . Deduce that for ever $N \ge 2$ we have $E\bigg[ \max_{i \le N} |X_i| \bigg] \le CK \sqrt{\log N}$ . I've tried to figure out what is the distribution of the maximum of Gaussians, but I'm reaching only inequalities that that don't help me answer the question. I've also seen a similar question here . Does anyone have a clue or something to start with in order to answer this question? Thanks!","I'm trying to answer the following question from the book high-dimensional probability : Let be a sequence of sub-gaussian random variables, which are not necessarily independent. Show that , where . Deduce that for ever we have . I've tried to figure out what is the distribution of the maximum of Gaussians, but I'm reaching only inequalities that that don't help me answer the question. I've also seen a similar question here . Does anyone have a clue or something to start with in order to answer this question? Thanks!","X_1,X_2,\dots E\bigg[ \max_i \frac{|X_i|}{\sqrt{1 + \log i}} \bigg] \le CK K = \max_i \|X_i\|_{\psi_2} N \ge 2 E\bigg[ \max_{i \le N} |X_i| \bigg] \le CK \sqrt{\log N}","['probability', 'probability-theory', 'random-variables', 'gauss-sums']"
29,Dice puzzle: pips must sum to 21,Dice puzzle: pips must sum to 21,,"A friend recently told me this little puzzle but to me it seems like there might not be a right answer. Was wondering if there is in fact a best combination in this scenario. Dice rolling war You and a friend decide to have a dice rolling war consisting of 36 battles. Each player will roll 1 die. A battle is won by the player with the higher number of pips, and the winner receives a point. If both players have the same number of pips, neither player receives a point. However, before starting the battles, the players get to choose the number of pips to put on the 6 sides of the die, the constraint being that the number of pips on all sides of the die must summ to 21 and be in the range [1-6]. For example, [4][4][4][4][4][1] would be valid choice. Finally, the person with the most points at the end of 36 rounds wins. Part a) What pips should you choose to give you the best chance of winning? Part b) What is the probability that you will win?","A friend recently told me this little puzzle but to me it seems like there might not be a right answer. Was wondering if there is in fact a best combination in this scenario. Dice rolling war You and a friend decide to have a dice rolling war consisting of 36 battles. Each player will roll 1 die. A battle is won by the player with the higher number of pips, and the winner receives a point. If both players have the same number of pips, neither player receives a point. However, before starting the battles, the players get to choose the number of pips to put on the 6 sides of the die, the constraint being that the number of pips on all sides of the die must summ to 21 and be in the range [1-6]. For example, [4][4][4][4][4][1] would be valid choice. Finally, the person with the most points at the end of 36 rounds wins. Part a) What pips should you choose to give you the best chance of winning? Part b) What is the probability that you will win?",,"['probability', 'puzzle', 'game-theory']"
30,what is the expected number of collisions?,what is the expected number of collisions?,,"Suppose we use a hash function $H$ to hash $N$ distinct balls into $M$ distinct bins. Assuming simple uniform hashing, what is the expected number of collisions? Note that a collision is defined by adding a ball to an already occupied bin. If the already occupied bin has $k$ balls in it, then the number of collisions upon adding a new ball is $k.$ By using expectation, I tried as : => 1 × Probability of collision in first insertion  + 2 × Probability of collision in second insertion  + .......... + n × Probability of collision in nth insertion => $(1 ∗ 0) + (2 ∗ 1/m) + (3 ∗ 2/m) + (4 ∗ 3/m) + … + (n ∗ n−1/m)$ Actually, The answer is $(n^2 - n)/2m$ But, I am not getting the answer. Where am I wrong here ?","Suppose we use a hash function $H$ to hash $N$ distinct balls into $M$ distinct bins. Assuming simple uniform hashing, what is the expected number of collisions? Note that a collision is defined by adding a ball to an already occupied bin. If the already occupied bin has $k$ balls in it, then the number of collisions upon adding a new ball is $k.$ By using expectation, I tried as : => 1 × Probability of collision in first insertion  + 2 × Probability of collision in second insertion  + .......... + n × Probability of collision in nth insertion => $(1 ∗ 0) + (2 ∗ 1/m) + (3 ∗ 2/m) + (4 ∗ 3/m) + … + (n ∗ n−1/m)$ Actually, The answer is $(n^2 - n)/2m$ But, I am not getting the answer. Where am I wrong here ?",,"['probability', 'combinatorics', 'probability-theory', 'probability-distributions']"
31,"Suggest some ""unconventional"" books on probability & statistics","Suggest some ""unconventional"" books on probability & statistics",,"stackexchange, please suggest me some books on probability & statistics that are unconventional in their approach to these subjects. I think it is better to describe what i mean by ""unconventionality"" by example. Some of this kind of books are "" Probability Theory: The Logic of Science "" by E. T. Jaynes . The famous book where the author uses Cox's theorems for the laws of probability and interprets probability as an extension of logic. "" Probability and Finance: It's Only a Game! "" by Shafer and Vovk . In this book the authors derive the laws of probability from game theory. "" Probability via Expectation "" by Peter Whittle . The author develops the theory of probability from axioms on the expectation functional rather than on probability measure. "" Radically Elementary Probability Theory "" by Edward Nelson . The author uses non-standard analysis in his treatment of probability.","stackexchange, please suggest me some books on probability & statistics that are unconventional in their approach to these subjects. I think it is better to describe what i mean by ""unconventionality"" by example. Some of this kind of books are "" Probability Theory: The Logic of Science "" by E. T. Jaynes . The famous book where the author uses Cox's theorems for the laws of probability and interprets probability as an extension of logic. "" Probability and Finance: It's Only a Game! "" by Shafer and Vovk . In this book the authors derive the laws of probability from game theory. "" Probability via Expectation "" by Peter Whittle . The author develops the theory of probability from axioms on the expectation functional rather than on probability measure. "" Radically Elementary Probability Theory "" by Edward Nelson . The author uses non-standard analysis in his treatment of probability.",,"['probability', 'probability-theory', 'statistics', 'reference-request', 'soft-question']"
32,How many variables can be pairwise anticorrelated,How many variables can be pairwise anticorrelated,,"I am working on a computational project involving analysis of data.  Each item of data that I have has a few hundred attributes; I have several million items of data.  The attributes are essentially random variables and I am computing the correlation of each pair of variables.  The formula to do that is: $$ \rho_{xy} = \frac{\mathbb{E}( (X-\mu_{x})(Y-\mu_{y}) )}{\sigma_{x}\sigma_{y}}$$ where $X$ and $Y$ are the attributes.  This value always lies between $+1$ and $-1$.  Intuitively, if $\rho_{xy}\approx +1$ then $X$ and $Y$ typically differ from their respective means in the same way, i.e. if $X$ is above average then so is $Y$ and if $X$ is below average, then so is $Y$.  This is called positive correlation.  Similarly, if $\rho_{xy}\approx -1$ then $X$ and $Y$ typically differ from their means in opposite directions, i.e. if $X$ is above average, then $Y$ is below and vice versa.  This is called negative correlation. From all of my data, I build a correlation matrix $C=[\rho_{ij}]$ which contains the correlation coefficient of the $i^{\text{th}}$ and $j^{\text{th}}$ variable in the $ij$-entry.  I want to view this matrix as an edge-weighted graph and perform clustering.  A ""positive"" clique would correspond to a number of pairwise positively correlated variables.  It is clear that many variables can be pairwise positively correlated; so I could potentially see large ""positive"" cliques in the graph. My question is: How many variables could I see that are pairwise negatively correlated?  Intuition tells me probably only 2.  But I cannot prove this.  Basically, I want to define ""negative"" cliques--a set of nodes all of whose edges are weighted with (nearly) $-1$, and I want to know how large my ""negative"" cliques could be. Edit: Perhaps a better way to ask the question is: to what degree can ""anti-correlation"" be transitive?  I.e. if $x$ is (strongly) anti-correlated to $y$, and $y$ is (strongly) anti-correlated to $z$, how strongly can $x$ and $z$ be anti-correlated? Also, if there is a way to say how large this ""negative"" clique could be as a function of how near the edge weights are to $-1$ that would be helpful.  The idea that there largest negative clique has 2 vertices is working on the assumption that I only have an edge when the weight is exactly $-1$.  If I relax that to an edge when the weight is smaller than $-1+\epsilon$ (small $\epsilon$) then I can probably have slightly more than 2 vertices--how many more is the question (and how does that related to $\epsilon$).","I am working on a computational project involving analysis of data.  Each item of data that I have has a few hundred attributes; I have several million items of data.  The attributes are essentially random variables and I am computing the correlation of each pair of variables.  The formula to do that is: $$ \rho_{xy} = \frac{\mathbb{E}( (X-\mu_{x})(Y-\mu_{y}) )}{\sigma_{x}\sigma_{y}}$$ where $X$ and $Y$ are the attributes.  This value always lies between $+1$ and $-1$.  Intuitively, if $\rho_{xy}\approx +1$ then $X$ and $Y$ typically differ from their respective means in the same way, i.e. if $X$ is above average then so is $Y$ and if $X$ is below average, then so is $Y$.  This is called positive correlation.  Similarly, if $\rho_{xy}\approx -1$ then $X$ and $Y$ typically differ from their means in opposite directions, i.e. if $X$ is above average, then $Y$ is below and vice versa.  This is called negative correlation. From all of my data, I build a correlation matrix $C=[\rho_{ij}]$ which contains the correlation coefficient of the $i^{\text{th}}$ and $j^{\text{th}}$ variable in the $ij$-entry.  I want to view this matrix as an edge-weighted graph and perform clustering.  A ""positive"" clique would correspond to a number of pairwise positively correlated variables.  It is clear that many variables can be pairwise positively correlated; so I could potentially see large ""positive"" cliques in the graph. My question is: How many variables could I see that are pairwise negatively correlated?  Intuition tells me probably only 2.  But I cannot prove this.  Basically, I want to define ""negative"" cliques--a set of nodes all of whose edges are weighted with (nearly) $-1$, and I want to know how large my ""negative"" cliques could be. Edit: Perhaps a better way to ask the question is: to what degree can ""anti-correlation"" be transitive?  I.e. if $x$ is (strongly) anti-correlated to $y$, and $y$ is (strongly) anti-correlated to $z$, how strongly can $x$ and $z$ be anti-correlated? Also, if there is a way to say how large this ""negative"" clique could be as a function of how near the edge weights are to $-1$ that would be helpful.  The idea that there largest negative clique has 2 vertices is working on the assumption that I only have an edge when the weight is exactly $-1$.  If I relax that to an edge when the weight is smaller than $-1+\epsilon$ (small $\epsilon$) then I can probably have slightly more than 2 vertices--how many more is the question (and how does that related to $\epsilon$).",,"['probability', 'correlation']"
33,probability that no two spiders end up at the same vertex?,probability that no two spiders end up at the same vertex?,,"Eight spiders are located on the eight vertices of a cube. When a bell rings, each spider moves (at random, independent of the others) to an adjacent vertex. What is the probability that no two spiders end up at the same vertex? How would I start this problem?","Eight spiders are located on the eight vertices of a cube. When a bell rings, each spider moves (at random, independent of the others) to an adjacent vertex. What is the probability that no two spiders end up at the same vertex? How would I start this problem?",,"['probability', 'combinatorics']"
34,Poisson process and uniform random variable,Poisson process and uniform random variable,,"Question: A single-pump petrol station is running low on petrol. The total   volume of petrol remaining for sale is $100$ litres. Suppose cars arrive to the station according to a Poisson process with   rate $\lambda$, and that each car fills independently of all other   cars and of the arrival process, an amount of petrol that is   distributed as a uniform random variable over $(0, 50)$ - assume for   example that all car tanks have a capacity of $50$ litres and drivers   decide ""at random"" when to refill. We assume that service is instantaneous so that there are no queues at   the station. (a) On average, how many cars will the petrol station fully service   (sell the full amount requested) before it runs out of petrol (and   before any refilling occurs)? (b) How much time will it take on average before the station runs out   of petrol (and before any refilling occurs)? Attempt: I'm not exactly sure where to start with this question part (a) . Let $U$ be uniformly distributed over $(0,50)$, then each time a car arrives at the petrol station, the total volume of petrol decreases by $U$. So define $U_1$ to be the amount of petrol that the first arrival (an ""arrival"" here being when a car arrives at the petrol station and refills) and $U_2$ be that of the second arrival, and so on. Then each $U_i$ is identically and independently distributed as $U$. So by the $N$-th arrival, the station will have $100-\sum_{i=1}^N U_i$ litres of petrol remaining. We stop once $100-\sum_{i=1}^N U_i=0$ and we basically need to find $E[N]$? That's all I've got so far, if someone can provide a solution for (a) (for now), that would be good. EDIT: PROGRESS I don't think I need to use the assumption that cars arrive according to a Poisson process in this part. So, define $U_k$ as the random variable that denotes the amount of petrol that car $k$ fills, $k = 1, 2, 3, \cdots$. Thus, $U_k, k = 1, 2, 3, \cdots$ are independently and identically distributed as a uniform random variable over $(0,50)$. Let $N$ be the random variable that denotes the number of cars that the petrol station can fully service. Now I don't quite get the question. Say we have the following scenario: Car 1 comes with 10L remaining in its tank, so it will fill up 40L, hence the amount of petrol left in the station is now 100-40 = 60L. Car 2 comes with 10L remaining in its tank, so it will fill up 40L, hence the amount of petrol left in the station is now 60-40 = 20L. Car 3 comes with 20L remaining in its tank, so it will fill up 30L, but the petrol station only has 20L left, so does this mean Car 3 just leaves the petrol station filling 0L? My gut feeling is that this cannot happen because each car can only fill an amount BETWEEN 0 and 50, ie, (0,50) [note that the end points are not included]. Hence in this scenario, the petrol station runs ""out"" of petrol at N=3 because it does not have enough to FULLY service Car 3, even though it still has 20L left in the pump. Thus, the petrol station can only service N=2 cars. Is this interpretation correct? If so, how do I find $E[N]$? EDIT 2: working on further... Define $G_N = \sum_{k=1}^N U_k$, then $E[N] = \sum_{n=1}^{\infty} n P(N=n) = \sum_{n=1}^{\infty} n P(G_n \le 100)$ This equivalence comes from the fact that the event $\{N=n\}$ will only happen if $100 - G_n \ge 0$. However, two questions remain, what is the distribution of $G_n$? (How do I derive the distribution of the sum of $n$ iid uniform random variables and second, how do I compute the infinite sum? Furthermore, I should mention that this question can be done without the need of any computer software package or programming. It has a closed form solution with an exact answer, I am feeling that my current approach definitely won't work by hand.","Question: A single-pump petrol station is running low on petrol. The total   volume of petrol remaining for sale is $100$ litres. Suppose cars arrive to the station according to a Poisson process with   rate $\lambda$, and that each car fills independently of all other   cars and of the arrival process, an amount of petrol that is   distributed as a uniform random variable over $(0, 50)$ - assume for   example that all car tanks have a capacity of $50$ litres and drivers   decide ""at random"" when to refill. We assume that service is instantaneous so that there are no queues at   the station. (a) On average, how many cars will the petrol station fully service   (sell the full amount requested) before it runs out of petrol (and   before any refilling occurs)? (b) How much time will it take on average before the station runs out   of petrol (and before any refilling occurs)? Attempt: I'm not exactly sure where to start with this question part (a) . Let $U$ be uniformly distributed over $(0,50)$, then each time a car arrives at the petrol station, the total volume of petrol decreases by $U$. So define $U_1$ to be the amount of petrol that the first arrival (an ""arrival"" here being when a car arrives at the petrol station and refills) and $U_2$ be that of the second arrival, and so on. Then each $U_i$ is identically and independently distributed as $U$. So by the $N$-th arrival, the station will have $100-\sum_{i=1}^N U_i$ litres of petrol remaining. We stop once $100-\sum_{i=1}^N U_i=0$ and we basically need to find $E[N]$? That's all I've got so far, if someone can provide a solution for (a) (for now), that would be good. EDIT: PROGRESS I don't think I need to use the assumption that cars arrive according to a Poisson process in this part. So, define $U_k$ as the random variable that denotes the amount of petrol that car $k$ fills, $k = 1, 2, 3, \cdots$. Thus, $U_k, k = 1, 2, 3, \cdots$ are independently and identically distributed as a uniform random variable over $(0,50)$. Let $N$ be the random variable that denotes the number of cars that the petrol station can fully service. Now I don't quite get the question. Say we have the following scenario: Car 1 comes with 10L remaining in its tank, so it will fill up 40L, hence the amount of petrol left in the station is now 100-40 = 60L. Car 2 comes with 10L remaining in its tank, so it will fill up 40L, hence the amount of petrol left in the station is now 60-40 = 20L. Car 3 comes with 20L remaining in its tank, so it will fill up 30L, but the petrol station only has 20L left, so does this mean Car 3 just leaves the petrol station filling 0L? My gut feeling is that this cannot happen because each car can only fill an amount BETWEEN 0 and 50, ie, (0,50) [note that the end points are not included]. Hence in this scenario, the petrol station runs ""out"" of petrol at N=3 because it does not have enough to FULLY service Car 3, even though it still has 20L left in the pump. Thus, the petrol station can only service N=2 cars. Is this interpretation correct? If so, how do I find $E[N]$? EDIT 2: working on further... Define $G_N = \sum_{k=1}^N U_k$, then $E[N] = \sum_{n=1}^{\infty} n P(N=n) = \sum_{n=1}^{\infty} n P(G_n \le 100)$ This equivalence comes from the fact that the event $\{N=n\}$ will only happen if $100 - G_n \ge 0$. However, two questions remain, what is the distribution of $G_n$? (How do I derive the distribution of the sum of $n$ iid uniform random variables and second, how do I compute the infinite sum? Furthermore, I should mention that this question can be done without the need of any computer software package or programming. It has a closed form solution with an exact answer, I am feeling that my current approach definitely won't work by hand.",,"['probability', 'stochastic-processes']"
35,In search of Probability text recommendations [duplicate],In search of Probability text recommendations [duplicate],,"This question already has answers here : What is the best book to learn probability? (13 answers) Closed 3 years ago . The probability class I recently finished (taught at an upper-undergraduate or lower-graduate level) used the text by Grimmett and Stirzaker. I really disliked this book. I am familiar with measure theory, so it is fine if the book is measure-theoretic. However, I want to make sure the book doesn't neglect to provide a clear explanation of a the basic concepts of probability, and provide exercises for the basic problem-solving techniques. Also, I always love texts that have good motivation and intuitive explanations for things (I guess I prefer some motivating discussion rather than a totally formal text like Rudin, or arguably Ahlfors). I think model texts for what I'm looking for are Spivak's Calculus and Dummit and Foote's Algebra . What I love about these texts are the large amount of (enlightening) exercises. Update: Still looking for a good probability text. Feller's text has come up as a suggestion. Does that one have good exercises?","This question already has answers here : What is the best book to learn probability? (13 answers) Closed 3 years ago . The probability class I recently finished (taught at an upper-undergraduate or lower-graduate level) used the text by Grimmett and Stirzaker. I really disliked this book. I am familiar with measure theory, so it is fine if the book is measure-theoretic. However, I want to make sure the book doesn't neglect to provide a clear explanation of a the basic concepts of probability, and provide exercises for the basic problem-solving techniques. Also, I always love texts that have good motivation and intuitive explanations for things (I guess I prefer some motivating discussion rather than a totally formal text like Rudin, or arguably Ahlfors). I think model texts for what I'm looking for are Spivak's Calculus and Dummit and Foote's Algebra . What I love about these texts are the large amount of (enlightening) exercises. Update: Still looking for a good probability text. Feller's text has come up as a suggestion. Does that one have good exercises?",,"['probability', 'reference-request']"
36,Finding distribution function of $Y/X$ and probability density function of $X+Y$,Finding distribution function of  and probability density function of,Y/X X+Y,"I'm studying for an exam at the moment, and these types of questions have just got me stumped to the point where I need a step-by-step walkthrough... More specifically I've got two questions I just can't get past: Given two random variables $X$ and $Y$ with $ f_X(x)= \left\{   \begin{array}{l l}     xe^{-x} & \quad \text{if $x$ > 0},\\     0 & \quad \text{else}.\\   \end{array} \right. $ $ f_Y(y)= \left\{   \begin{array}{l l}     e^{-y} & \quad \text{if $y$ > 0},\\     0 & \quad \text{else}.\\   \end{array} \right. $ as respective densities, show that $Z = Y/X$ has the following distribution function $ F_Z(z)= \left\{   \begin{array}{l l}     1-\frac1{(1+z)^2} & \quad \text{if $y$ > 0},\\     0 & \quad \text{else}.\\   \end{array} \right. $ Also have to find the density function, but to my knowledge this is just deriving with respect to $z$ and is $\frac2{(z + 1)^3}.$ A very similar question asks to show that: If $X, Y$ are random variables with given densities $ f_X(x)=\frac12x^2e^{-x}  \ \ if \ x >0, $ $ f_Y(y)=e^{-y} \ \ if \ y > 0, $ then $Z = X + Y$ has probability density function $ f_Z(z)= \frac{z^3}6e^{-z}. $ I'm guessing the first step is to find $Z$'s distribution function, but this is the part that stumps me in the first question also. Please help.","I'm studying for an exam at the moment, and these types of questions have just got me stumped to the point where I need a step-by-step walkthrough... More specifically I've got two questions I just can't get past: Given two random variables $X$ and $Y$ with $ f_X(x)= \left\{   \begin{array}{l l}     xe^{-x} & \quad \text{if $x$ > 0},\\     0 & \quad \text{else}.\\   \end{array} \right. $ $ f_Y(y)= \left\{   \begin{array}{l l}     e^{-y} & \quad \text{if $y$ > 0},\\     0 & \quad \text{else}.\\   \end{array} \right. $ as respective densities, show that $Z = Y/X$ has the following distribution function $ F_Z(z)= \left\{   \begin{array}{l l}     1-\frac1{(1+z)^2} & \quad \text{if $y$ > 0},\\     0 & \quad \text{else}.\\   \end{array} \right. $ Also have to find the density function, but to my knowledge this is just deriving with respect to $z$ and is $\frac2{(z + 1)^3}.$ A very similar question asks to show that: If $X, Y$ are random variables with given densities $ f_X(x)=\frac12x^2e^{-x}  \ \ if \ x >0, $ $ f_Y(y)=e^{-y} \ \ if \ y > 0, $ then $Z = X + Y$ has probability density function $ f_Z(z)= \frac{z^3}6e^{-z}. $ I'm guessing the first step is to find $Z$'s distribution function, but this is the part that stumps me in the first question also. Please help.",,"['probability', 'probability-distributions']"
37,Two players toss a coin; probability game doesn't end in 100 tosses?,Two players toss a coin; probability game doesn't end in 100 tosses?,,"Player A and B alternate when flipping a coin. If the number of heads is K more than the number of tails, A wins, if the number of tails is K more than heads, B wins. What is the probability that the game is not over after 100 coin tosses? I started by considering simpler cases like winning if there are 2 more heads/tails than tails/heads in 100 tosses and it is clear the the game finishes at most on the 3rd toss with probability 1, hence it makes sense that with 50 more heads/tails than tails/heads in 100 tosses the game finishes in at most 99 tosses? For more than that I would need to compute the permutations of the different scenarios for winnings and divide by the total number of posibilities for each K, not feasible. I was thinking maybe I could solve it via recursion or some sort of conditioning Need help with ideas, hints and/or intuition please! Also how would that change if the players toss the coins (no alternation) separately and the one to have k more heads/tails than the other wins?","Player A and B alternate when flipping a coin. If the number of heads is K more than the number of tails, A wins, if the number of tails is K more than heads, B wins. What is the probability that the game is not over after 100 coin tosses? I started by considering simpler cases like winning if there are 2 more heads/tails than tails/heads in 100 tosses and it is clear the the game finishes at most on the 3rd toss with probability 1, hence it makes sense that with 50 more heads/tails than tails/heads in 100 tosses the game finishes in at most 99 tosses? For more than that I would need to compute the permutations of the different scenarios for winnings and divide by the total number of posibilities for each K, not feasible. I was thinking maybe I could solve it via recursion or some sort of conditioning Need help with ideas, hints and/or intuition please! Also how would that change if the players toss the coins (no alternation) separately and the one to have k more heads/tails than the other wins?",,"['probability', 'probability-theory', 'conditional-probability']"
38,Retrieve the random variable from its conditional expectations,Retrieve the random variable from its conditional expectations,,"I came across a problem that looks easy but turns out to be extremely hard. The problem goes as follows: $X,Y$ are two independent random variables with support on interval $[0,1]$ and $\mathrm{E}[X]=\mathrm{E}[Y]=\mu \in (0,1)$ . Construct a random variable $Z=f(X,Y)$ as a function of $X,Y$ with the following two properties: $Z$ has support [0,1]. $\mathrm{E}[f(X,Y)|X] = X$ and $E[f(X,Y)|Y]=Y$ . Remark 1. The first example I have is $Z=XY/\mu$ which satisfies 2 but not 1 because $Z$ could take on value $Z=1/\mu>1$ . The second example is $Z=X+Y-\mu$ which satisfies 2 but not 1 again. Remark 2. In fact, my best strategy now is to consider a class of random variables $$ Z= \alpha \frac{XY}{\mu} + (1-\alpha) (X+Y-\mu) + \beta\mathrm{E}[(g(X)-\mathrm{E}g(X))(h(Y)-\mathrm{E}h(Y))] $$ for any functions $g,h$ and scalars $\alpha,\beta$ . $Z$ clearly satisfies 2. But it is very hard to restrict the support of $Z$ to interval $[0,1]$ . I am stuck and I am looking forward to a fresh set of ideas from the community.","I came across a problem that looks easy but turns out to be extremely hard. The problem goes as follows: are two independent random variables with support on interval and . Construct a random variable as a function of with the following two properties: has support [0,1]. and . Remark 1. The first example I have is which satisfies 2 but not 1 because could take on value . The second example is which satisfies 2 but not 1 again. Remark 2. In fact, my best strategy now is to consider a class of random variables for any functions and scalars . clearly satisfies 2. But it is very hard to restrict the support of to interval . I am stuck and I am looking forward to a fresh set of ideas from the community.","X,Y [0,1] \mathrm{E}[X]=\mathrm{E}[Y]=\mu \in (0,1) Z=f(X,Y) X,Y Z \mathrm{E}[f(X,Y)|X] = X E[f(X,Y)|Y]=Y Z=XY/\mu Z Z=1/\mu>1 Z=X+Y-\mu 
Z= \alpha \frac{XY}{\mu} + (1-\alpha) (X+Y-\mu) + \beta\mathrm{E}[(g(X)-\mathrm{E}g(X))(h(Y)-\mathrm{E}h(Y))]
 g,h \alpha,\beta Z Z [0,1]","['probability', 'expected-value', 'conditional-expectation']"
39,PDF of area of triangle with normally-distributed coordinates in any dimensions,PDF of area of triangle with normally-distributed coordinates in any dimensions,,"Question What is the probability distribution function (PDF) of the absolute area of a triangle with normally-distributed coordinates in $\mathbb{R}^m$ $(m \in \mathbb{N}, m\ge2)$ ? A conjecture is given that can be proved or might help to find the correct solution. The triangle vertices in $\mathbb{R}^m$ are $$ \mathbf{\mathrm{X}_1} =(x_1^1,\ldots, x_1^m),\;\;   \mathbf{\mathrm{X}_2}=(x_2^1,\ldots,x_2^m),\;\;    \mathbf{\mathrm{X}_3}=(x_3^1,\ldots,x_3^m)$$ where $x_i^j$ are independent standard normal distributed variables $$x_i^j\sim\mathcal{N}(0,1)$$ The non-oriented area $A$ of a random triangle instance in $\mathbb{R}^m$ is $$A=\|\mathbf{\mathrm{X}_1}-\mathbf{\mathrm{X}_3}\|\, \|\mathbf{\mathrm{X}_2}-\mathbf{\mathrm{X}_3}\| \frac{\sin\alpha}{2}\tag{1}$$ where $\|\cdot\|$ is the Euclidean norm and $\alpha$ is the angle at $\mathbf{\mathrm{X}_3}$ . The expectation value of $A$ is $$\mathbb{E}[A]=\frac{\sqrt{3}}{2}\left(m-1\right)\tag{2}$$ A proof of eq.(2) can be found in this Cross Validated post . Conjecture for PDF The probability distribution of empirical data of $A$ for any tested $m$ can be fitted quite well with the function $$f(A)=\frac{k^{m-1}} {A \mathrm{e}^k (m-2)! }\, \, \text{ with} \, \ k=\frac{2A}{\sqrt{3}} \tag{3}$$ that fulfills also the conditions of a PDF $$\int_0^\infty f(A) \mathrm{d}A=1\ \,\, \text{and}\ \int_0^\infty A f(A)\mathrm{d}A=\mathbb{E}[A]$$ Experimental data is indistinguishable from eq.(3) but a proof is missing. Related question In a similar case the PDF for the volume of a tetrahedron in $\mathbb{R}^3$ was tried to solve in this Math SE post but no full solution was given so far.",Question What is the probability distribution function (PDF) of the absolute area of a triangle with normally-distributed coordinates in ? A conjecture is given that can be proved or might help to find the correct solution. The triangle vertices in are where are independent standard normal distributed variables The non-oriented area of a random triangle instance in is where is the Euclidean norm and is the angle at . The expectation value of is A proof of eq.(2) can be found in this Cross Validated post . Conjecture for PDF The probability distribution of empirical data of for any tested can be fitted quite well with the function that fulfills also the conditions of a PDF Experimental data is indistinguishable from eq.(3) but a proof is missing. Related question In a similar case the PDF for the volume of a tetrahedron in was tried to solve in this Math SE post but no full solution was given so far.,"\mathbb{R}^m (m \in \mathbb{N}, m\ge2) \mathbb{R}^m  \mathbf{\mathrm{X}_1} =(x_1^1,\ldots, x_1^m),\;\;   \mathbf{\mathrm{X}_2}=(x_2^1,\ldots,x_2^m),\;\;    \mathbf{\mathrm{X}_3}=(x_3^1,\ldots,x_3^m) x_i^j x_i^j\sim\mathcal{N}(0,1) A \mathbb{R}^m A=\|\mathbf{\mathrm{X}_1}-\mathbf{\mathrm{X}_3}\|\, \|\mathbf{\mathrm{X}_2}-\mathbf{\mathrm{X}_3}\| \frac{\sin\alpha}{2}\tag{1} \|\cdot\| \alpha \mathbf{\mathrm{X}_3} A \mathbb{E}[A]=\frac{\sqrt{3}}{2}\left(m-1\right)\tag{2} A m f(A)=\frac{k^{m-1}} {A \mathrm{e}^k (m-2)! }\, \, \text{
with} \, \ k=\frac{2A}{\sqrt{3}} \tag{3} \int_0^\infty f(A) \mathrm{d}A=1\ \,\, \text{and}\ \int_0^\infty A f(A)\mathrm{d}A=\mathbb{E}[A] \mathbb{R}^3","['probability', 'normal-distribution', 'triangles', 'simplex', 'geometric-probability']"
40,What do the level sets of the Shannon entropy look like?,What do the level sets of the Shannon entropy look like?,,"The Shannon entropy of a discrete probability distribution $\newcommand{\bs}[1]{\boldsymbol{#1}}\bs p\equiv (p_i)_{i=1}^n$ is defined as $H(\bs p)\equiv -\sum_{i=1}^n p_i \log p_i$ . Consider the corresponding level sets, that is, the sets of the form $$L^{(n)}_\alpha\equiv \left\{(p_1,...,p_n) : \sum_i p_i=1 \text{ and } H(p_1,...,p_n)=\alpha\}\subset\mathbb R^n\right\},\quad\alpha\in[0,\log n].$$ Is there a geometrical characterisation for these sets? Clearly, $L^{(n)}_{\log n}=\{(1,...,1)/n\}$ and $L^{(n)}_{0}=\{\bs e_1,...,\bs e_n\}$ where $(\bs e_i)_j=\delta_{ij}$ . What about the nontrivial cases with $0<\alpha<\log n$ ? For example, in the $n=3$ case the corresponding level sets/contour lines look like in the following: To get a better look at the contour lines we can parametrise the simplex as $$S(s,t)=(1,0,0)+\frac{t}{\sqrt2}(-1,1,0)+\frac{s}{\sqrt{3/2}}(-1/2,-1/2,1),$$ and then plotting $H(S(s,t))$ against $s,t\in\mathbb R^2$ we get We can push this further to visualise single level sets for $n=4$ , by using the parametrisation $$S(s,t,u) = (1,0,0,0) + \frac{t}{\sqrt2}(-1,1,0,0) + \frac{s}{\sqrt{3/2}}(-1/2,-1/2,1,0) + \frac{u}{\sqrt{4/3}}(-1/3,-1/3,-1/3,1),$$ and them plotting the $(s,t,u)$ such that $H(S(s,t,u))=\alpha$ . For example, with $\alpha=\log(3.2)$ we get where the tetrahedron shows how the normalisation constraint on the probabilities is translated into this $(s,t,u)$ space. The fact that $H$ doesn't care about the ordering of the elements in $\bs p$ implies a series of reflection symmetries on the level sets. What else can be said about them? The fact that not all such level sets are closed might make the problem less well-defined, in which case we might restrict our attention to the cases with $\log(n-1)\le \alpha \le \log n$ for which (I think) the level sets should be closed. Alternatively, one might extend the definition of $H$ to let it act on vectors that are not necessarily probability distributions. The Mathematica code to generate the figure can be found here .","The Shannon entropy of a discrete probability distribution is defined as . Consider the corresponding level sets, that is, the sets of the form Is there a geometrical characterisation for these sets? Clearly, and where . What about the nontrivial cases with ? For example, in the case the corresponding level sets/contour lines look like in the following: To get a better look at the contour lines we can parametrise the simplex as and then plotting against we get We can push this further to visualise single level sets for , by using the parametrisation and them plotting the such that . For example, with we get where the tetrahedron shows how the normalisation constraint on the probabilities is translated into this space. The fact that doesn't care about the ordering of the elements in implies a series of reflection symmetries on the level sets. What else can be said about them? The fact that not all such level sets are closed might make the problem less well-defined, in which case we might restrict our attention to the cases with for which (I think) the level sets should be closed. Alternatively, one might extend the definition of to let it act on vectors that are not necessarily probability distributions. The Mathematica code to generate the figure can be found here .","\newcommand{\bs}[1]{\boldsymbol{#1}}\bs p\equiv (p_i)_{i=1}^n H(\bs p)\equiv -\sum_{i=1}^n p_i \log p_i L^{(n)}_\alpha\equiv \left\{(p_1,...,p_n) : \sum_i p_i=1 \text{ and } H(p_1,...,p_n)=\alpha\}\subset\mathbb R^n\right\},\quad\alpha\in[0,\log n]. L^{(n)}_{\log n}=\{(1,...,1)/n\} L^{(n)}_{0}=\{\bs e_1,...,\bs e_n\} (\bs e_i)_j=\delta_{ij} 0<\alpha<\log n n=3 S(s,t)=(1,0,0)+\frac{t}{\sqrt2}(-1,1,0)+\frac{s}{\sqrt{3/2}}(-1/2,-1/2,1), H(S(s,t)) s,t\in\mathbb R^2 n=4 S(s,t,u) = (1,0,0,0) + \frac{t}{\sqrt2}(-1,1,0,0) + \frac{s}{\sqrt{3/2}}(-1/2,-1/2,1,0) + \frac{u}{\sqrt{4/3}}(-1/3,-1/3,-1/3,1), (s,t,u) H(S(s,t,u))=\alpha \alpha=\log(3.2) (s,t,u) H \bs p \log(n-1)\le \alpha \le \log n H","['probability', 'geometry', 'information-theory', 'entropy', 'information-geometry']"
41,Inverse Fourier transform of $\text{sinc}(t)^{1/k}$,Inverse Fourier transform of,\text{sinc}(t)^{1/k},"This question is a follow-up to a statistics question on crossvalidated.SE where we are looking to see if it is possible for the difference of two independent random variables to be uniformly distributed from negative to positive unity.  We have discovered that a necessary condition for this outcome is to have a distribution with a Fourier transform with squared-norm equal to a reciprocal power of the sinc function (the Fourier transform for the uniform distribution).  The present question is seeking to find out if this is possible or not. So, with that in mind, I would like to know if there is any probability density with a characteristic function that is a reciprocal power of the sinc function .  For a density $f$ with this property, the Fourier transform  $\hat{f}$ is the function: $$\hat{f}(t) = \text{sinc}(t)^{1/k} \quad \quad \quad \text{for } k \in \mathbb{N}.$$ For $k=1$ the inverse Fourier transform $f$ is known to be a rectangular pulse function (i.e., a uniform density).  I am mostly interested in the result when $k=2$, but the general result is also of interest to me. Update: It has been pointed out in the comments that $z^{1/k}$ is a multi-valued function, and I have not specified which branch I am using.  Given the above motivation for the problem, unless I am mistaken (and I might be, so please tell me if I am), it should not matter which branch is used.","This question is a follow-up to a statistics question on crossvalidated.SE where we are looking to see if it is possible for the difference of two independent random variables to be uniformly distributed from negative to positive unity.  We have discovered that a necessary condition for this outcome is to have a distribution with a Fourier transform with squared-norm equal to a reciprocal power of the sinc function (the Fourier transform for the uniform distribution).  The present question is seeking to find out if this is possible or not. So, with that in mind, I would like to know if there is any probability density with a characteristic function that is a reciprocal power of the sinc function .  For a density $f$ with this property, the Fourier transform  $\hat{f}$ is the function: $$\hat{f}(t) = \text{sinc}(t)^{1/k} \quad \quad \quad \text{for } k \in \mathbb{N}.$$ For $k=1$ the inverse Fourier transform $f$ is known to be a rectangular pulse function (i.e., a uniform density).  I am mostly interested in the result when $k=2$, but the general result is also of interest to me. Update: It has been pointed out in the comments that $z^{1/k}$ is a multi-valued function, and I have not specified which branch I am using.  Given the above motivation for the problem, unless I am mistaken (and I might be, so please tell me if I am), it should not matter which branch is used.",,"['probability', 'fourier-transform']"
42,"Classic birthday problem turned on its head: With $N$ people, how many are likely to share most common birthday?","Classic birthday problem turned on its head: With  people, how many are likely to share most common birthday?",N,"I have a unique opportunity to present to a very large group of people ($2{,}000$ in a theatre hall) about how chance works and how human intuition can be way off to guess likeliness. Rather than present the classic birthday problem to them (that is discussed many times very well in Math SE), I wanted to have some audience participation instead to illustrate the issue of chance and human intuition on the answer more directly with them, by asking a series of questions (see below) to get to the most common birthday in that entire audience and count how many hands are up for that. If I were to do this, how many people are likely to share that most common birthday ? Obviously, the many permutations among $2{,}000$ people mean that every single person will share so many birthdays with so many other people, and some birthdays will be less likely than others, but what number will I see specifically for that most common one? You can take any kind of confidence criteria that would be reasonable, such as a minimum number to expect with $50\%$ certainty. That way when I know the day-of exactly how many people are actually attending, I can update the final guess appropriately, and of course the answer can be more universally applicable to any crowd of $N$ people similarly. Edit: Since the number isn't likely going to be very high, a follow-up suggestion that I liked was the question ""Given that answer, how many birthdates should I look to ask for, such that $y$ people raise their hands?"" Then I may see that asking just $10$ dates gets over $100$ people, or $15$ gets $300$ etc. and I can get that impressive number I'm looking for. To get the final answer, the questions I'd ask would be: ""Whose birthday is in the first half of the month?"", then list the 6 months that seems to get more hands and pick the winner, then ask of those ""Whose birthday is among days 1-10? 11-20? 21-28/30/31?"", then ask whichever of those 3 groups has the most hands up ""Is it odd or even?"" and then list the 4-6 options and count each until we have a winner. I'll have assistants all over the theatre to help with the counting. I'd appreciate a comment if there's a more efficient way to do this that wouldn't be confusing. (Edit: See comments; this actually isn't as effective as I thought, so other suggestions welcome!) I think this approach for such a large crowd would be most effective, since intuition without any statistics that would lead someone thinking you'd need $183$ people to have a $50/50$ chance that two share a birthday and be shocked to hear it's $23$, could apply the opposite direction and I could suggest that since $2000/365 = 5{.}47$, maybe $5$ or $6$ people would share the most common birthday to add more of an impact when we see the actual answer. I could just pick a random date or my birthday and see the number of hands, but I think this ""most common birthday"" approach could be really effective.","I have a unique opportunity to present to a very large group of people ($2{,}000$ in a theatre hall) about how chance works and how human intuition can be way off to guess likeliness. Rather than present the classic birthday problem to them (that is discussed many times very well in Math SE), I wanted to have some audience participation instead to illustrate the issue of chance and human intuition on the answer more directly with them, by asking a series of questions (see below) to get to the most common birthday in that entire audience and count how many hands are up for that. If I were to do this, how many people are likely to share that most common birthday ? Obviously, the many permutations among $2{,}000$ people mean that every single person will share so many birthdays with so many other people, and some birthdays will be less likely than others, but what number will I see specifically for that most common one? You can take any kind of confidence criteria that would be reasonable, such as a minimum number to expect with $50\%$ certainty. That way when I know the day-of exactly how many people are actually attending, I can update the final guess appropriately, and of course the answer can be more universally applicable to any crowd of $N$ people similarly. Edit: Since the number isn't likely going to be very high, a follow-up suggestion that I liked was the question ""Given that answer, how many birthdates should I look to ask for, such that $y$ people raise their hands?"" Then I may see that asking just $10$ dates gets over $100$ people, or $15$ gets $300$ etc. and I can get that impressive number I'm looking for. To get the final answer, the questions I'd ask would be: ""Whose birthday is in the first half of the month?"", then list the 6 months that seems to get more hands and pick the winner, then ask of those ""Whose birthday is among days 1-10? 11-20? 21-28/30/31?"", then ask whichever of those 3 groups has the most hands up ""Is it odd or even?"" and then list the 4-6 options and count each until we have a winner. I'll have assistants all over the theatre to help with the counting. I'd appreciate a comment if there's a more efficient way to do this that wouldn't be confusing. (Edit: See comments; this actually isn't as effective as I thought, so other suggestions welcome!) I think this approach for such a large crowd would be most effective, since intuition without any statistics that would lead someone thinking you'd need $183$ people to have a $50/50$ chance that two share a birthday and be shocked to hear it's $23$, could apply the opposite direction and I could suggest that since $2000/365 = 5{.}47$, maybe $5$ or $6$ people would share the most common birthday to add more of an impact when we see the actual answer. I could just pick a random date or my birthday and see the number of hands, but I think this ""most common birthday"" approach could be really effective.",,"['probability', 'birthday']"
43,What is the difference between conditional and posterior probability?,What is the difference between conditional and posterior probability?,,"I'm having having understanding the difference between conditional and posterior probability. Conditional probability: ...a measure of the   probability of an event given that (by assumption, presumption,   assertion or evidence) another event has occurred. Source: https://en.wikipedia.org/wiki/Conditional_probability Posterior probability: ...the conditional probability that is   assigned after the relevant evidence or background is taken into   account. Source: https://en.wikipedia.org/wiki/Posterior_probability Are they essentially the same?","I'm having having understanding the difference between conditional and posterior probability. Conditional probability: ...a measure of the   probability of an event given that (by assumption, presumption,   assertion or evidence) another event has occurred. Source: https://en.wikipedia.org/wiki/Conditional_probability Posterior probability: ...the conditional probability that is   assigned after the relevant evidence or background is taken into   account. Source: https://en.wikipedia.org/wiki/Posterior_probability Are they essentially the same?",,['probability']
44,Concerning an infinite server queue with Poisson arrivals,Concerning an infinite server queue with Poisson arrivals,,"Here's the statement of the problem (from Ross's Introduction to Probability Models ): For those unfamiliar with ""infinite server queues,"" they are described here . In this case, however, the service times are not exponentially distributed; rather, they are distributed according to some common distribution $G$. It follows that $X(t)$, the number of customers that have completed service by time $t$ and that arrived at time $s, s\le t,$ is Poisson distributed with mean $$E[X(t)]=\lambda \int_{0}^{t}G(t-s)ds=\lambda \int_{0}^{t}G(y)dy.$$ Similarly, the distribution of $Y(t)$, the number of customers being served at time $t$ and that arrived at time $s, s \le t,$ is Poisson distributed with mean $$E[Y(t)]=\lambda \int_{0}^{t}\bar G(t-s)ds=\lambda \int_{0}^{t}\bar G(y)dy$$ where $\bar G(t-s) = 1 - G(t-s)$. Now, for part $(a)$, let $A =\{\text{the first customer to arrive is also the first to depart} \}$, i.e., our desired event; and suppose the first customer arrives at time $0$ and departs at time $t$. Then, we consider the event $A$ conditioned on the event in which $0$ customers have completed service by time $t$, i.e., $$ \mathbb P[A | X(t) = 0] = \exp\left\{ -\lambda \int_{0}^{t}G(y)dy\right\}.  $$ Ok, I get that. But then, for some reason, the following is the answer: $$ \mathbb P[A] = \int_{0}^{\infty} \left( \exp\left\{ -\lambda \int_{0}^{t}G(y)dy\right\} \right) dG(t).  $$ And I don't really understand where this comes from. If anybody could shed some light on this, I'd really appreciate it. Thanks.","Here's the statement of the problem (from Ross's Introduction to Probability Models ): For those unfamiliar with ""infinite server queues,"" they are described here . In this case, however, the service times are not exponentially distributed; rather, they are distributed according to some common distribution $G$. It follows that $X(t)$, the number of customers that have completed service by time $t$ and that arrived at time $s, s\le t,$ is Poisson distributed with mean $$E[X(t)]=\lambda \int_{0}^{t}G(t-s)ds=\lambda \int_{0}^{t}G(y)dy.$$ Similarly, the distribution of $Y(t)$, the number of customers being served at time $t$ and that arrived at time $s, s \le t,$ is Poisson distributed with mean $$E[Y(t)]=\lambda \int_{0}^{t}\bar G(t-s)ds=\lambda \int_{0}^{t}\bar G(y)dy$$ where $\bar G(t-s) = 1 - G(t-s)$. Now, for part $(a)$, let $A =\{\text{the first customer to arrive is also the first to depart} \}$, i.e., our desired event; and suppose the first customer arrives at time $0$ and departs at time $t$. Then, we consider the event $A$ conditioned on the event in which $0$ customers have completed service by time $t$, i.e., $$ \mathbb P[A | X(t) = 0] = \exp\left\{ -\lambda \int_{0}^{t}G(y)dy\right\}.  $$ Ok, I get that. But then, for some reason, the following is the answer: $$ \mathbb P[A] = \int_{0}^{\infty} \left( \exp\left\{ -\lambda \int_{0}^{t}G(y)dy\right\} \right) dG(t).  $$ And I don't really understand where this comes from. If anybody could shed some light on this, I'd really appreciate it. Thanks.",,"['probability', 'stochastic-processes', 'queueing-theory', 'poisson-process']"
45,Convergence Rate of Sample Average Estimator,Convergence Rate of Sample Average Estimator,,"Let $X_1, X_2,\cdots$ be i.i.d. random variables with $E(X_1) = \mu, Var(X_1) = σ^2> 0$ and let $\bar{X}_n = {X_1 + X_2 + \cdots + X_n \over n}$ be the sample average estimator. Is there a way to calculate how many samples are needed to obtain a solution that is "" $\epsilon$ accurate""?  From Chebyshev's inequality I can get \begin{align} P(|\bar{X}_n - \mu| \geq \epsilon) \leq \frac{Var(\overline{X}_n)}{\epsilon^2} = \frac{σ^2}{n\epsilon^2} \end{align} and can conclude that the convergence rate is linear in $n$ . Are there better bounds for the sample average estimator?","Let be i.i.d. random variables with and let be the sample average estimator. Is there a way to calculate how many samples are needed to obtain a solution that is "" accurate""?  From Chebyshev's inequality I can get and can conclude that the convergence rate is linear in . Are there better bounds for the sample average estimator?","X_1, X_2,\cdots E(X_1) = \mu, Var(X_1) = σ^2> 0 \bar{X}_n = {X_1 + X_2 + \cdots + X_n \over n} \epsilon \begin{align}
P(|\bar{X}_n - \mu| \geq \epsilon) \leq \frac{Var(\overline{X}_n)}{\epsilon^2} = \frac{σ^2}{n\epsilon^2}
\end{align} n","['probability', 'statistics', 'probability-theory', 'parameter-estimation']"
46,How can this technique be applied to a different problem?,How can this technique be applied to a different problem?,,"Here is the problem (copy and pasted if you don't want to click on the link). Six ants simultaneously stand on the six vertices of a regular octahedron, with each ant at a different vertex. Simultaneously and independently, each ant moves from its vertex to one of the four adjacent vertices, each with equal probability. What is the probability that no two ants arrive at the same vertex? Source: 2005 AMC 12B, problem 25 The answer is $\dfrac5{256}$ , but I was wondering if the same techniques used in this problem could be used in a similar one with a cube ( $8$ ants instead of $6$ ). If so, could someone show me how? Thanks! Note: Unsure about tags as this has to do with events with states.","Here is the problem (copy and pasted if you don't want to click on the link). Six ants simultaneously stand on the six vertices of a regular octahedron, with each ant at a different vertex. Simultaneously and independently, each ant moves from its vertex to one of the four adjacent vertices, each with equal probability. What is the probability that no two ants arrive at the same vertex? Source: 2005 AMC 12B, problem 25 The answer is , but I was wondering if the same techniques used in this problem could be used in a similar one with a cube ( ants instead of ). If so, could someone show me how? Thanks! Note: Unsure about tags as this has to do with events with states.",\dfrac5{256} 8 6,"['probability', 'graph-theory', 'contest-math']"
47,Can the Poisson Distribution be used to find the expected value of time of arrival given an expected arrivals per unit time?,Can the Poisson Distribution be used to find the expected value of time of arrival given an expected arrivals per unit time?,,"My understanding of the Poisson Distribution is that its PMF $P(x=k) = \dfrac {\lambda^k e^{-\lambda}} {k!}$ refers to the probability of finding k events given an expected arrival expectancy $\lambda$. This gives me, rather trivially, that the expected value for the number of arrivals is equal to the average number of arrivals $\lambda$. However, suppose I know $\lambda$ is 3 events per day. How can I calculate the expected number of days before $n$ events happen? Can I just invert my $\lambda$, so that my units are now days/event, and use the same distribution? A supplemental question: Currently, the units in my exponent appears to be events/time. Shouldn't I have to multiply by some time $t$, so that the distribution looks like $P(x=k) = \dfrac {(\lambda t)^k e^{-\lambda t}} {k!}$? (I'm taking ""events"" to be unitless...) If so, I would expect my new distribution to be $P(t=k) = \dfrac {(\frac n {\lambda})^{k} e^{ \frac {-n} {\lambda}}} {k!}$, where $n$ is the number of events, $k$ is the amount of time, and $\lambda$ is still in events/time. Thus if, in the above example, I want to know the probability that it would take 1 day for 5 arrivals, I would set $k$ = 1, $n$ = 5, and $\lambda$ = 3. Is there anything wrong with this formulation?","My understanding of the Poisson Distribution is that its PMF $P(x=k) = \dfrac {\lambda^k e^{-\lambda}} {k!}$ refers to the probability of finding k events given an expected arrival expectancy $\lambda$. This gives me, rather trivially, that the expected value for the number of arrivals is equal to the average number of arrivals $\lambda$. However, suppose I know $\lambda$ is 3 events per day. How can I calculate the expected number of days before $n$ events happen? Can I just invert my $\lambda$, so that my units are now days/event, and use the same distribution? A supplemental question: Currently, the units in my exponent appears to be events/time. Shouldn't I have to multiply by some time $t$, so that the distribution looks like $P(x=k) = \dfrac {(\lambda t)^k e^{-\lambda t}} {k!}$? (I'm taking ""events"" to be unitless...) If so, I would expect my new distribution to be $P(t=k) = \dfrac {(\frac n {\lambda})^{k} e^{ \frac {-n} {\lambda}}} {k!}$, where $n$ is the number of events, $k$ is the amount of time, and $\lambda$ is still in events/time. Thus if, in the above example, I want to know the probability that it would take 1 day for 5 arrivals, I would set $k$ = 1, $n$ = 5, and $\lambda$ = 3. Is there anything wrong with this formulation?",,['probability']
48,Probability of determinants being coprime,Probability of determinants being coprime,,"I have a question that is not of particular significance, but I would love to understand the underlying principles. Suppose we have two square $3 \times 3$ matrices, $M_1$ and $M_2$ with $$M_1 = \begin{pmatrix} a_1 & a_2 & a_3 \\ a_4 & a_5 & a_6 \\ a_7 & a_8 & a_9 \end{pmatrix} \qquad\text{and}\qquad M_2 = \begin{pmatrix} b_1 & b_2 & b_3 \\ b_4 & b_5 & b_6 \\ b_7 & b_8 & b_9 \end{pmatrix}$$ with the coefficients $a_n,b_n \in \mathbb{Z}$ and $1 \leq a_n,b_n \leq 9$ What is the probability that the matrices' determinants are coprime, when uniformly random coefficients satisfying the conditions are chosen. I am familiar with the Riemann's $\zeta$ function way to find out the probability of two random integers being coprime, but I have no clue how to apply that here with additional conditions on the numbers given. I did test it mechanically, using Mathematica and the result is around 30%, but I would like to see a proper way to do it. I would love to at least get a few pointers as what to research to tackle this problem. Thank you very much!","I have a question that is not of particular significance, but I would love to understand the underlying principles. Suppose we have two square $3 \times 3$ matrices, $M_1$ and $M_2$ with $$M_1 = \begin{pmatrix} a_1 & a_2 & a_3 \\ a_4 & a_5 & a_6 \\ a_7 & a_8 & a_9 \end{pmatrix} \qquad\text{and}\qquad M_2 = \begin{pmatrix} b_1 & b_2 & b_3 \\ b_4 & b_5 & b_6 \\ b_7 & b_8 & b_9 \end{pmatrix}$$ with the coefficients $a_n,b_n \in \mathbb{Z}$ and $1 \leq a_n,b_n \leq 9$ What is the probability that the matrices' determinants are coprime, when uniformly random coefficients satisfying the conditions are chosen. I am familiar with the Riemann's $\zeta$ function way to find out the probability of two random integers being coprime, but I have no clue how to apply that here with additional conditions on the numbers given. I did test it mechanically, using Mathematica and the result is around 30%, but I would like to see a proper way to do it. I would love to at least get a few pointers as what to research to tackle this problem. Thank you very much!",,"['probability', 'matrices']"
49,Draw tangents at 3 random points on a circle to form a triangle. Show that the probability that a random side is shorter than the diameter is $1/2$.,Draw tangents at 3 random points on a circle to form a triangle. Show that the probability that a random side is shorter than the diameter is .,1/2,"Choose three uniformly random points on a circle, and draw tangents to the circle at those points to form a triangle. (The triangle may or may not contain the circle.) For example: What is the probability, $P$ , that a randomly chosen side of the triangle is shorter than the diameter of the circle? I have found that $P=\frac12$ by using integration, and I will post my answer below. But since the probability is so simple, I am looking for an intuitive explanation . (Having said that, a probability's simplicity is no guarantee that there is an intuitive explanation; for example here and here are probability questions that have answers of $1/2$ but have resisted intuitive explanations.) Edit : If two or more of the tangent lines are parallel or coincident, re-choose the three points.","Choose three uniformly random points on a circle, and draw tangents to the circle at those points to form a triangle. (The triangle may or may not contain the circle.) For example: What is the probability, , that a randomly chosen side of the triangle is shorter than the diameter of the circle? I have found that by using integration, and I will post my answer below. But since the probability is so simple, I am looking for an intuitive explanation . (Having said that, a probability's simplicity is no guarantee that there is an intuitive explanation; for example here and here are probability questions that have answers of but have resisted intuitive explanations.) Edit : If two or more of the tangent lines are parallel or coincident, re-choose the three points.",P P=\frac12 1/2,"['probability', 'geometry', 'triangles', 'intuition', 'geometric-probability']"
50,Expected number of turns to find all pairs in card matching game,Expected number of turns to find all pairs in card matching game,,"Suppose we have a game with $2n$ cards labeled $1,1,2,2,...,n,n$ , such that for every integer $i$ where $1\leq i\leq n$ we have 2 cards labeled with $i$ . Initially, all the cards are placed face-down on a table. Every turn, the player flips over 2 cards one at a time. If they match, which is if the two cards share the same number, the two cards are removed from the board. If they do not match, the two cards are flipped back to their face-down position. The game ends when all pairs have been found, and all the cards have been removed from the table. (This game is known as Concentration). Assume the player has perfect memory, and that even after flipping a card back over, they are able to remember which card has what number on it. My question is: what is the expected number of turns to complete a game given $n$ starting pairs? I have thought about this problem, and have come up with a few observations. Let $E(N,k)$ represent the expected number of moves to win from a state with $2N$ total face-down cards ( $N$ unfound pairs) remaining and $k$ face-down cards that the player knows the value of. No matter what, we have $k\leq N$ , since by PHP, $k>N$ implies that there are at least 2 face-down cards that share a value and where the player knows both their locations. Then the next move would be to flip all these ""known"" face-down pairs until $k\leq N$ again. $E(N,k)=\frac{k}{2N-k}(E(N-1,k-1)+1)+\frac{2N-2k}{2N-k}\cdot\frac{1}{2N-k-1}(E(N-1,k)+1)+\frac{2N-2k}{2N-k}\cdot\frac{2N-2k-2}{2N-k-1}(E(N,k+2)+1)+\frac{2N-2k}{2N-k}\cdot\frac{k}{2N-k-1}(E(N-1,k)+2)$ $E(N,N)=N$ $0\leq a<b\leq N\implies E(N,a)>E(N,b)$ $\lim_{N\to\infty} E(N,0)-E(N,k)=\frac{k}{2}$ $\lim_{N\to\infty} E(N,N-k)-E(N,N)=k$ There exists some constant $X$ such that $\lim_{N\to\infty} E(N,0)=X\cdot N$ . If I am not mistaken, the goal to find the expected number of turns to complete a game with $n$ starting pairs reduces to finding that constant $X$ . However, I am stuck here. I know $\frac{3}{2}<X<\frac{1+\sqrt{5}}{2}$ , but not much more.","Suppose we have a game with cards labeled , such that for every integer where we have 2 cards labeled with . Initially, all the cards are placed face-down on a table. Every turn, the player flips over 2 cards one at a time. If they match, which is if the two cards share the same number, the two cards are removed from the board. If they do not match, the two cards are flipped back to their face-down position. The game ends when all pairs have been found, and all the cards have been removed from the table. (This game is known as Concentration). Assume the player has perfect memory, and that even after flipping a card back over, they are able to remember which card has what number on it. My question is: what is the expected number of turns to complete a game given starting pairs? I have thought about this problem, and have come up with a few observations. Let represent the expected number of moves to win from a state with total face-down cards ( unfound pairs) remaining and face-down cards that the player knows the value of. No matter what, we have , since by PHP, implies that there are at least 2 face-down cards that share a value and where the player knows both their locations. Then the next move would be to flip all these ""known"" face-down pairs until again. There exists some constant such that . If I am not mistaken, the goal to find the expected number of turns to complete a game with starting pairs reduces to finding that constant . However, I am stuck here. I know , but not much more.","2n 1,1,2,2,...,n,n i 1\leq i\leq n i n E(N,k) 2N N k k\leq N k>N k\leq N E(N,k)=\frac{k}{2N-k}(E(N-1,k-1)+1)+\frac{2N-2k}{2N-k}\cdot\frac{1}{2N-k-1}(E(N-1,k)+1)+\frac{2N-2k}{2N-k}\cdot\frac{2N-2k-2}{2N-k-1}(E(N,k+2)+1)+\frac{2N-2k}{2N-k}\cdot\frac{k}{2N-k-1}(E(N-1,k)+2) E(N,N)=N 0\leq a<b\leq N\implies E(N,a)>E(N,b) \lim_{N\to\infty} E(N,0)-E(N,k)=\frac{k}{2} \lim_{N\to\infty} E(N,N-k)-E(N,N)=k X \lim_{N\to\infty} E(N,0)=X\cdot N n X \frac{3}{2}<X<\frac{1+\sqrt{5}}{2}","['probability', 'combinatorics', 'markov-chains', 'game-theory']"
51,How would you go about learning the combination of coins the man has?,How would you go about learning the combination of coins the man has?,,"I am trying to identify the branch of math that would help to solve the following problem: A man has picked $10$ coins out of a bag and has laid them in a row. You cannot see them for yourself, and the heads/tails ratio is unknown. Your goal is to identify the correct heads/tails sequence of the coins by repeatedly picking $10$ coins of your own from the bag, with the man telling you how many match the position of his each time. You cannot decide whether the coins are heads or tails (for the sake of the problem assume they are the same on both sides) and your sequence depends on the order you remove them from the bag. Note that the man only selects his coins once and his never change. For example, if the man has $HTTHHHHTTT$ and you propose $TTTHTHTHHT$ he will let you know that $5$ are a match, however he will not tell you which ones. If on your second try you pull out $THHTTTHTHT$ he will inform you that $3$ match. Without trying every possible combination $(2^{10})$ , how would you go about learning the combination of coins the man has? Comparing the two sample results I see that they share $3$ in common, but I'm not sure if or how that is useful information since I don't know which ones actually match. I suspect it might require statistics/combinatorics, and I was told it could be solved with ""either high school or college math"". This isn't a homework problem so it's possible I'm just being trolled by the person. Any information you can provide for approaching this type of problem is much appreciated. Thank you.","I am trying to identify the branch of math that would help to solve the following problem: A man has picked coins out of a bag and has laid them in a row. You cannot see them for yourself, and the heads/tails ratio is unknown. Your goal is to identify the correct heads/tails sequence of the coins by repeatedly picking coins of your own from the bag, with the man telling you how many match the position of his each time. You cannot decide whether the coins are heads or tails (for the sake of the problem assume they are the same on both sides) and your sequence depends on the order you remove them from the bag. Note that the man only selects his coins once and his never change. For example, if the man has and you propose he will let you know that are a match, however he will not tell you which ones. If on your second try you pull out he will inform you that match. Without trying every possible combination , how would you go about learning the combination of coins the man has? Comparing the two sample results I see that they share in common, but I'm not sure if or how that is useful information since I don't know which ones actually match. I suspect it might require statistics/combinatorics, and I was told it could be solved with ""either high school or college math"". This isn't a homework problem so it's possible I'm just being trolled by the person. Any information you can provide for approaching this type of problem is much appreciated. Thank you.",10 10 HTTHHHHTTT TTTHTHTHHT 5 THHTTTHTHT 3 (2^{10}) 3,"['probability', 'combinatorics', 'statistics', 'discrete-mathematics', 'puzzle']"
52,Bank vaults and probability,Bank vaults and probability,,"A burglar breaks into a bank with the intention to open the vaults and steal some gold coins.   He knows that each vault contains a number of 1 to 100 such coins with equal probability for each number. Since he is what we call an “ethical burglar”, he will only get 100 coins to help some people in need. How many vaults must he breach on average? This is really confusing because we are not given how many vaults we have. Is it safe to say that since the numbers from 1 to 100 have equal probability, then we have 100 vaults?  Then, if vault Number 1 has 1 coin, 2 has 2 etc, we need to open as many that will give sum of 100? And then get the average? I need help with the interpretation and solution please! Ok after having asked several people, here is my interpretation: We may have any number of vaults, not necessarily 100 (maybe more, maybe less) but the number of coins in them has been placed randomly, with equal probability for each number from 1 to 100. The burglar will stop once he has collected 100 or more coins: That is, if, after the last vault, he has 99, he may open another one, with 23 coins, so he will have a total of 122 and this is OK. Any ideas for the solution? Thank you!","A burglar breaks into a bank with the intention to open the vaults and steal some gold coins.   He knows that each vault contains a number of 1 to 100 such coins with equal probability for each number. Since he is what we call an “ethical burglar”, he will only get 100 coins to help some people in need. How many vaults must he breach on average? This is really confusing because we are not given how many vaults we have. Is it safe to say that since the numbers from 1 to 100 have equal probability, then we have 100 vaults?  Then, if vault Number 1 has 1 coin, 2 has 2 etc, we need to open as many that will give sum of 100? And then get the average? I need help with the interpretation and solution please! Ok after having asked several people, here is my interpretation: We may have any number of vaults, not necessarily 100 (maybe more, maybe less) but the number of coins in them has been placed randomly, with equal probability for each number from 1 to 100. The burglar will stop once he has collected 100 or more coins: That is, if, after the last vault, he has 99, he may open another one, with 23 coins, so he will have a total of 122 and this is OK. Any ideas for the solution? Thank you!",,['probability']
53,What is the difference between P(dx) and P(x)dx?,What is the difference between P(dx) and P(x)dx?,,"I often come across the notation $P(dx)$ in statistics papers. Is there a strict mathematical definition for $dx$ inside $P$ ? Examples : What is the exact meaning of $$\int f(x)P(dx)$$ and $$\int f(x)P(x)dx$$ Also sometimes I saw $\frac{P(dx)}{Q(dx)}$ , is it equivalent to $\frac{P(x)}{Q(x)}dx$ ?","I often come across the notation in statistics papers. Is there a strict mathematical definition for inside ? Examples : What is the exact meaning of and Also sometimes I saw , is it equivalent to ?",P(dx) dx P \int f(x)P(dx) \int f(x)P(x)dx \frac{P(dx)}{Q(dx)} \frac{P(x)}{Q(x)}dx,"['probability', 'statistics']"
54,Properties of the Minimum of Two Poisson Random Variables,Properties of the Minimum of Two Poisson Random Variables,,"I stumbled upon the following problem in my research. We are trying to analyze $Z=\min(X,Y)$ where $X \sim Pois(p\lambda)$ and $Y\sim Pois((1-p)\lambda)$. Note that the RVs expectation is related yet not identical but are independent. What we are most interested in is a closed form expression for $\mathbb{E}Z$. Or, alternatively, an expression simple enough to prove with that the expectation $\mathbb{E}Z$ is attained at $p=\frac{1}{2}$ I managed to find very little literature on the subject. I saw that in some places this scenario is called a ""Poisson Race"", but couldn't find anything that is relevant to me. I tried to go the manual way: \begin{equation} \begin{split} \mathbb{E} Z &  = \sum_{n\geq 1} \Pr(min(X,Y) \geq n) \\  & =  \sum_{n\geq 1} \Pr(X\geq n\ \text{and}\ Y\geq n) \\  & = \sum_{n\geq 1} \Pr(X\geq n)\cdot \Pr(Y\geq n) \\ & = \sum_{n\geq 1}\Bigg[\Bigg(\sum_{i\geq n} \frac{(p \lambda)^i e^{-p\lambda}}{i!} \Bigg)\Bigg(\sum_{i\geq n} \frac{((1-p) \lambda)^i e^{-(1-p)\lambda}}{i!} \Bigg)\Bigg] \\ & = e^{-\lambda}\sum_{n\geq 1}\Bigg[\Bigg(\sum_{i\geq n} \frac{(p \lambda)^i}{i!} \Bigg)\Bigg(\sum_{i\geq n} \frac{((1-p) \lambda)^i }{i!} \Bigg)\Bigg] \\ & = e^{-\lambda}\sum_{n\geq 1}\Bigg[\Bigg(e^x-e_{n-1}(p\lambda) \Bigg)\Bigg(e^x - e_{n-1}((1-p)\lambda) \Bigg)\Bigg] \\ \end{split} \end{equation} But this didn't lead to any relatively simple terms. Tried looking into Gamma Taylor partial sums of $e^x$ and Gamma functions $\Gamma (x)$ but again, with no result. What is obvious, due to the symmetry of the function is that the max is attained at $p=\frac{1}{2}$. Does one see any way to prove so without having to derive once and twice and do all the dirty work? $e_n(x)$ is the Exponential Sum Function","I stumbled upon the following problem in my research. We are trying to analyze $Z=\min(X,Y)$ where $X \sim Pois(p\lambda)$ and $Y\sim Pois((1-p)\lambda)$. Note that the RVs expectation is related yet not identical but are independent. What we are most interested in is a closed form expression for $\mathbb{E}Z$. Or, alternatively, an expression simple enough to prove with that the expectation $\mathbb{E}Z$ is attained at $p=\frac{1}{2}$ I managed to find very little literature on the subject. I saw that in some places this scenario is called a ""Poisson Race"", but couldn't find anything that is relevant to me. I tried to go the manual way: \begin{equation} \begin{split} \mathbb{E} Z &  = \sum_{n\geq 1} \Pr(min(X,Y) \geq n) \\  & =  \sum_{n\geq 1} \Pr(X\geq n\ \text{and}\ Y\geq n) \\  & = \sum_{n\geq 1} \Pr(X\geq n)\cdot \Pr(Y\geq n) \\ & = \sum_{n\geq 1}\Bigg[\Bigg(\sum_{i\geq n} \frac{(p \lambda)^i e^{-p\lambda}}{i!} \Bigg)\Bigg(\sum_{i\geq n} \frac{((1-p) \lambda)^i e^{-(1-p)\lambda}}{i!} \Bigg)\Bigg] \\ & = e^{-\lambda}\sum_{n\geq 1}\Bigg[\Bigg(\sum_{i\geq n} \frac{(p \lambda)^i}{i!} \Bigg)\Bigg(\sum_{i\geq n} \frac{((1-p) \lambda)^i }{i!} \Bigg)\Bigg] \\ & = e^{-\lambda}\sum_{n\geq 1}\Bigg[\Bigg(e^x-e_{n-1}(p\lambda) \Bigg)\Bigg(e^x - e_{n-1}((1-p)\lambda) \Bigg)\Bigg] \\ \end{split} \end{equation} But this didn't lead to any relatively simple terms. Tried looking into Gamma Taylor partial sums of $e^x$ and Gamma functions $\Gamma (x)$ but again, with no result. What is obvious, due to the symmetry of the function is that the max is attained at $p=\frac{1}{2}$. Does one see any way to prove so without having to derive once and twice and do all the dirty work? $e_n(x)$ is the Exponential Sum Function",,"['probability', 'optimization', 'poisson-distribution', 'maxima-minima']"
55,"How many turns, on average, does it take for a perfect player to win Concentration?","How many turns, on average, does it take for a perfect player to win Concentration?",,"Let's say a person with perfect memory is playing the card-matching game Concentration . He/she randomly lays out 2n cards (ie. n card pairs) sorted randomly and repeatedly takes turns consisting of flipping over two cards, without looking at the first card . When the cards match they are removed from play. When cards do not match, they are turned back over. The player wins when all pairs are found and all cards are removed. A perfect game is played in just n turns, but even a perfect player (one with perfect memory) couldn't hope to come close to a perfect game as there would still be a lot of guessing required. How to you calculate the expected number of turns required to win for player with perfect memory? EDIT 2 -- clarifying the rules Since all the early answers seem to read this question as you CANNOT look at the first card, I'm editing that into the rules. I originally was thinking you CAN look at the first card (since that's how I'd learned the game and, to my knowledge, that is how it is usually played. For that rule adjustment, I've posted a new question here: How many turns, on average, does it take for a perfect player to win Concentration (adjusted)? EDIT -- Checking answers against a simulation The strategy proposed in AlgorithmsX's answer seems to make sense to me - that is, the game takes place in two distinct stages. Stage 1: flip all cards to learn where they are, and... Stage 2: clean up/perfectly find all matches (since you know where they are). Thus improving on a $2n$ turn game is pure chance; how many matches do you find in Stage 1? To check a given answer, I wrote the below code to simulate the problem. It just randomly shuffles an array with pairs from $0$ to $n-1$ and checks for adjacent pairs that would come up in the sweep during Stage 1 (so a 0-1 pair is a match, but 1-2 is not). This seems like a good way to check answers because (for me personally, at least) it's easier to reason about the simulation than the math. Currently, AlgorithmsX's answer for $n=3$ results in $5.6$, but I would expect it to be $5.4$ barring any errors in my simulation. Some simulated results (1 million trials) n     |  2   |   3   |   4   |   5   |    6    | turns | 3.33 |  5.40 |  7.43 |  9.44 |  11.45  | Code to simulate answer given $n$ function shuffle(array) {   var currentIndex = array.length, temporaryValue, randomIndex;    // While there remain elements to shuffle...   while (0 !== currentIndex) {      // Pick a remaining element...     randomIndex = Math.floor(Math.random() * currentIndex);     currentIndex -= 1;      // And swap it with the current element.     temporaryValue = array[currentIndex];     array[currentIndex] = array[randomIndex];     array[randomIndex] = temporaryValue;   }    return array; }  var simulation = function(n, nTrials){    // make array from 0 to n-1 with pairs   var cards = Array.apply(null, {length: n}).map(Number.call, Number);   cards = cards.concat(cards);    var totalTurns = 0;    var trialsLeft = nTrials;    while(trialsLeft>0){     cards = shuffle(cards)     var matches = 0;     for(var i=0; i<n; i++){       if(cards[2*i]===cards[2*i+1]){         matches++       }     }     totalTurns += 2*n-matches;     trialsLeft--   }   return totalTurns/nTrials; }","Let's say a person with perfect memory is playing the card-matching game Concentration . He/she randomly lays out 2n cards (ie. n card pairs) sorted randomly and repeatedly takes turns consisting of flipping over two cards, without looking at the first card . When the cards match they are removed from play. When cards do not match, they are turned back over. The player wins when all pairs are found and all cards are removed. A perfect game is played in just n turns, but even a perfect player (one with perfect memory) couldn't hope to come close to a perfect game as there would still be a lot of guessing required. How to you calculate the expected number of turns required to win for player with perfect memory? EDIT 2 -- clarifying the rules Since all the early answers seem to read this question as you CANNOT look at the first card, I'm editing that into the rules. I originally was thinking you CAN look at the first card (since that's how I'd learned the game and, to my knowledge, that is how it is usually played. For that rule adjustment, I've posted a new question here: How many turns, on average, does it take for a perfect player to win Concentration (adjusted)? EDIT -- Checking answers against a simulation The strategy proposed in AlgorithmsX's answer seems to make sense to me - that is, the game takes place in two distinct stages. Stage 1: flip all cards to learn where they are, and... Stage 2: clean up/perfectly find all matches (since you know where they are). Thus improving on a $2n$ turn game is pure chance; how many matches do you find in Stage 1? To check a given answer, I wrote the below code to simulate the problem. It just randomly shuffles an array with pairs from $0$ to $n-1$ and checks for adjacent pairs that would come up in the sweep during Stage 1 (so a 0-1 pair is a match, but 1-2 is not). This seems like a good way to check answers because (for me personally, at least) it's easier to reason about the simulation than the math. Currently, AlgorithmsX's answer for $n=3$ results in $5.6$, but I would expect it to be $5.4$ barring any errors in my simulation. Some simulated results (1 million trials) n     |  2   |   3   |   4   |   5   |    6    | turns | 3.33 |  5.40 |  7.43 |  9.44 |  11.45  | Code to simulate answer given $n$ function shuffle(array) {   var currentIndex = array.length, temporaryValue, randomIndex;    // While there remain elements to shuffle...   while (0 !== currentIndex) {      // Pick a remaining element...     randomIndex = Math.floor(Math.random() * currentIndex);     currentIndex -= 1;      // And swap it with the current element.     temporaryValue = array[currentIndex];     array[currentIndex] = array[randomIndex];     array[randomIndex] = temporaryValue;   }    return array; }  var simulation = function(n, nTrials){    // make array from 0 to n-1 with pairs   var cards = Array.apply(null, {length: n}).map(Number.call, Number);   cards = cards.concat(cards);    var totalTurns = 0;    var trialsLeft = nTrials;    while(trialsLeft>0){     cards = shuffle(cards)     var matches = 0;     for(var i=0; i<n; i++){       if(cards[2*i]===cards[2*i+1]){         matches++       }     }     totalTurns += 2*n-matches;     trialsLeft--   }   return totalTurns/nTrials; }",,"['probability', 'card-games']"
56,Monotone Class Theorem and another similar theorem.,Monotone Class Theorem and another similar theorem.,,"I found different statements of the Monotone Class Theorem. On probability Essentials (Jean Jacod and Philip Protter) the Monotone Class Theorem (Theorem 6.2, page 36) is stated as follows: Let $\mathcal{C}$ be a class of subsets of $\Omega$ under finite intersections and containing $\Omega$. Let $\mathcal{B}$ be the smallest class containing $\mathcal{C}$ which is closed under increasing limits and by difference. Then $\mathcal{B} = \sigma ( \mathcal{C})$. While on Wikipedia ( https://en.wikipedia.org/wiki/Monotone_class_theorem ) the theorem is: Let $G$ be an algebra of sets and define $M(G)$ to be the smallest monotone class containing $G$. Then $M(G)$ is precisely the $\sigma$-algebra generated by $G$, i.e. $\sigma(G) = M(G)$. Where a monotone class in a set $R$ is a collection $M$ of subsets of $R$ which contains $R$ and is closed under countable monotone unions and intersections. It looks like the second theorem should be a special case of the first. Does the first prove the second? Is it possible to prove the first from the second? Is there a decent literature on those two theorems?","I found different statements of the Monotone Class Theorem. On probability Essentials (Jean Jacod and Philip Protter) the Monotone Class Theorem (Theorem 6.2, page 36) is stated as follows: Let $\mathcal{C}$ be a class of subsets of $\Omega$ under finite intersections and containing $\Omega$. Let $\mathcal{B}$ be the smallest class containing $\mathcal{C}$ which is closed under increasing limits and by difference. Then $\mathcal{B} = \sigma ( \mathcal{C})$. While on Wikipedia ( https://en.wikipedia.org/wiki/Monotone_class_theorem ) the theorem is: Let $G$ be an algebra of sets and define $M(G)$ to be the smallest monotone class containing $G$. Then $M(G)$ is precisely the $\sigma$-algebra generated by $G$, i.e. $\sigma(G) = M(G)$. Where a monotone class in a set $R$ is a collection $M$ of subsets of $R$ which contains $R$ and is closed under countable monotone unions and intersections. It looks like the second theorem should be a special case of the first. Does the first prove the second? Is it possible to prove the first from the second? Is there a decent literature on those two theorems?",,"['probability', 'probability-theory', 'measure-theory', 'monotone-class-theorem']"
57,When does pairwise independence imply independence?,When does pairwise independence imply independence?,,"We know if a collection of events are independent, then they are pairwise independent. In general, the converse is not true. However, I'm wondering if there's a condition under which the converse holds. I haven't been able to find anything on this. Any help is appreciated.","We know if a collection of events are independent, then they are pairwise independent. In general, the converse is not true. However, I'm wondering if there's a condition under which the converse holds. I haven't been able to find anything on this. Any help is appreciated.",,['probability']
58,Asymptotics for the expected length of the longest streak of heads.,Asymptotics for the expected length of the longest streak of heads.,,"As Introduction to Algorithms (CLRS) describes, the problem is Suppose you flip a fair coin $n$ times. What is the longest streak of consecutive heads that you expect to see? The book claims that the expects is $\Theta(\log{}n)$, and proves that it is both $O(\log{}n)$ and $\Omega(\log{}n)$. I want generize the problem, and look into the $\Theta(\log{}n)$. For example, we're flipping a biased coin with the probability $p$ for head and $q$ for tail, where $p+q=1$. Supposing that the length of the longest streak is $X$, we want to rewrite $EX = A\log{}n + O(1)$, or more precisely, $EX = A\log{}n + B + o(1)$, or something else. How to determine the asymptotics for $EX$? There's something trivial. Supposing that $P_{n,m}=\textrm{ probability that }X<m$, we have $P_{n,m}=qP_{n-1,m}+pqP_{n-2,m}+\cdots+p^{m-1}qP_{n-m,m}$ for $n \ge m$, and $P_{n,m}=1$ for $n<m$, thus $P_{n,m}$ could be solved out (linear difference equation), but there might be no useful formulas to determine the roots of $1-z-\cdots-z^m=0$ where $m>0$. Any help? Thanks!","As Introduction to Algorithms (CLRS) describes, the problem is Suppose you flip a fair coin $n$ times. What is the longest streak of consecutive heads that you expect to see? The book claims that the expects is $\Theta(\log{}n)$, and proves that it is both $O(\log{}n)$ and $\Omega(\log{}n)$. I want generize the problem, and look into the $\Theta(\log{}n)$. For example, we're flipping a biased coin with the probability $p$ for head and $q$ for tail, where $p+q=1$. Supposing that the length of the longest streak is $X$, we want to rewrite $EX = A\log{}n + O(1)$, or more precisely, $EX = A\log{}n + B + o(1)$, or something else. How to determine the asymptotics for $EX$? There's something trivial. Supposing that $P_{n,m}=\textrm{ probability that }X<m$, we have $P_{n,m}=qP_{n-1,m}+pqP_{n-2,m}+\cdots+p^{m-1}qP_{n-m,m}$ for $n \ge m$, and $P_{n,m}=1$ for $n<m$, thus $P_{n,m}$ could be solved out (linear difference equation), but there might be no useful formulas to determine the roots of $1-z-\cdots-z^m=0$ where $m>0$. Any help? Thanks!",,"['probability', 'asymptotics', 'recurrence-relations', 'generating-functions']"
59,Numerical approximation of Levy Flight,Numerical approximation of Levy Flight,,"I'm trying to produce a computer simulation of a Levy Flight in 2-dimensions; an approximation would be ok. Please excuse the simplistic level of this question: my maths is very rusty. My proposed method of plotting the Levy Flight is as follows: Start at the origin, and plot a connected series of points, each being in a random direction $\theta$ and a distance f from the previous point, where the size of f conforms to a power law distribution. Wikipedia suggests this should be of the form $y=x^{-a}$ where $1<a<3$. My problem is that I can't see how to generate values of f using a random number generator: I understand that I can use for example x = rand(1) which will with equal probability (allowing for the limitations of numerical accuracy and pseudo-randomness) take any value between 0 and 1. But here's where my limited math skills start to let me down: to transform this into a suitable value of f , I think I would need to use a 'cumulative distribution function' cdf(x), which maps my equally probable values of x onto some corresponding values of f . I also suspect that cdf(x) would basically be related the integral of $y=x^{-a}$, however I can't see exactly how to do this: Do I need to somehow scale $y=x^{-a}$ so the area under it sums to 1 (in order to be a valid probability density function)? I can't see how this is possible, unless I approximate using discrete values of $x$ and/or choosing a limited interval for values of $x$. Alternatively, could I do an approximation to this by the following method:(1) select a nominal start value of f , say 1. (2) if rand(1)>t (where t is an arbitrary threshold value) then set f=f*k (say k=1.2) and repeat step 2, otherwise stop and use the current value of f . If someone could offer some pointers, I would be very grateful. Thank you. EDIT: Thank you to Chris for the prompt answer which works perfectly! So for $\alpha = 3$ and $x_{\mathrm{min}} = 1$, when I choose 100,000 random values of u in [0,1] I get this distribution of values of $F^{-1}(u) = x_{\mathrm{min}} (1-u)^{-1/\alpha}$: ... which is just what I'm after (there's a little blip at the end for truncated values of $x>8$). In fact, since u is evenly distributed I can get exactly the same distribution using $F^{-1}(u) = u^{-1/\alpha}$ which is shorter. Here's a typical flight plot (for $\alpha=1.5$, 1000 steps): EDIT: Matlab code for the above example: alpha=1.5; s=1000; x=zeros(1,s); y=zeros(1,s);  for n=2:s;     theta=rand*2*pi;     f=rand^(-1/alpha);     x(n)=x(n-1)+f*cos(theta);     y(n)=y(n-1)+f*sin(theta); end;  figure('color', 'white'); axis equal off; line(x,y);","I'm trying to produce a computer simulation of a Levy Flight in 2-dimensions; an approximation would be ok. Please excuse the simplistic level of this question: my maths is very rusty. My proposed method of plotting the Levy Flight is as follows: Start at the origin, and plot a connected series of points, each being in a random direction $\theta$ and a distance f from the previous point, where the size of f conforms to a power law distribution. Wikipedia suggests this should be of the form $y=x^{-a}$ where $1<a<3$. My problem is that I can't see how to generate values of f using a random number generator: I understand that I can use for example x = rand(1) which will with equal probability (allowing for the limitations of numerical accuracy and pseudo-randomness) take any value between 0 and 1. But here's where my limited math skills start to let me down: to transform this into a suitable value of f , I think I would need to use a 'cumulative distribution function' cdf(x), which maps my equally probable values of x onto some corresponding values of f . I also suspect that cdf(x) would basically be related the integral of $y=x^{-a}$, however I can't see exactly how to do this: Do I need to somehow scale $y=x^{-a}$ so the area under it sums to 1 (in order to be a valid probability density function)? I can't see how this is possible, unless I approximate using discrete values of $x$ and/or choosing a limited interval for values of $x$. Alternatively, could I do an approximation to this by the following method:(1) select a nominal start value of f , say 1. (2) if rand(1)>t (where t is an arbitrary threshold value) then set f=f*k (say k=1.2) and repeat step 2, otherwise stop and use the current value of f . If someone could offer some pointers, I would be very grateful. Thank you. EDIT: Thank you to Chris for the prompt answer which works perfectly! So for $\alpha = 3$ and $x_{\mathrm{min}} = 1$, when I choose 100,000 random values of u in [0,1] I get this distribution of values of $F^{-1}(u) = x_{\mathrm{min}} (1-u)^{-1/\alpha}$: ... which is just what I'm after (there's a little blip at the end for truncated values of $x>8$). In fact, since u is evenly distributed I can get exactly the same distribution using $F^{-1}(u) = u^{-1/\alpha}$ which is shorter. Here's a typical flight plot (for $\alpha=1.5$, 1000 steps): EDIT: Matlab code for the above example: alpha=1.5; s=1000; x=zeros(1,s); y=zeros(1,s);  for n=2:s;     theta=rand*2*pi;     f=rand^(-1/alpha);     x(n)=x(n-1)+f*cos(theta);     y(n)=y(n-1)+f*sin(theta); end;  figure('color', 'white'); axis equal off; line(x,y);",,"['probability', 'simulation']"
60,Integral of Brownian motion in a 2-d box,Integral of Brownian motion in a 2-d box,,"Let $A=(a,b)\times (c,d) \subset \mathbb{R}^2$ with $0 \in A$ and $(B_t)$ be standard two dimensional Brownian motion. Additionally, let $\tau_A := \inf \{t\geq 0: B_t \notin A\}$ and let $g:A \to \mathbb{R}$ be a smooth bounded function which can be written as $g(x,y)=u(x)v(y)$ . I am investigating the random variable $$\int_0^{\tau_A} g(B_s) ds$$ in particular I am interested in the expectation $$E[\int_0^{\tau_A} g(B_s) ds].$$ I know that there is a connection to the Dirichlet problem but I am interested in calculating or estimating (in both directions) this expression in a stochastical way. E.g., a bound, which contains the $L^1$ norm of $g$ would be very interesting. Since the domain $A$ is an ""easy"" one and $B_t$ consists of two one dimensional independent Brownian motions $B_t=(B_t^1, B_t^2)$ , I have tried to reduce the problem into one dimension in the following way: \begin{align*}  E[\int_0^{\tau_A} g(B_s) ds] &= E^1 E^2 [\int_0^{\tau_{(a,b)}^1 \wedge  \tau_{(c,d)}^2} g(B_s^1,B_s^2) ds] \\ &= \int_0^{\infty}E^1 \big[ 1_{[0, \tau^1_{(a,b)})}(s)  u(B^1_s) \big] E^2 \big[1_{[0, \tau^2_{(c,d)})}(s) v(B^2_s)\big] d s \end{align*} The superscripts $\{1,2\}$ refer to the distributions of the respective Brownian motion. Now I have no further ideas on how to proceed and am not familiar with tools that could help me here. I would appreciate any help!","Let with and be standard two dimensional Brownian motion. Additionally, let and let be a smooth bounded function which can be written as . I am investigating the random variable in particular I am interested in the expectation I know that there is a connection to the Dirichlet problem but I am interested in calculating or estimating (in both directions) this expression in a stochastical way. E.g., a bound, which contains the norm of would be very interesting. Since the domain is an ""easy"" one and consists of two one dimensional independent Brownian motions , I have tried to reduce the problem into one dimension in the following way: The superscripts refer to the distributions of the respective Brownian motion. Now I have no further ideas on how to proceed and am not familiar with tools that could help me here. I would appreciate any help!","A=(a,b)\times (c,d) \subset \mathbb{R}^2 0 \in A (B_t) \tau_A := \inf \{t\geq 0: B_t \notin A\} g:A \to \mathbb{R} g(x,y)=u(x)v(y) \int_0^{\tau_A} g(B_s) ds E[\int_0^{\tau_A} g(B_s) ds]. L^1 g A B_t B_t=(B_t^1, B_t^2) \begin{align*} 
E[\int_0^{\tau_A} g(B_s) ds] &= E^1 E^2 [\int_0^{\tau_{(a,b)}^1 \wedge  \tau_{(c,d)}^2} g(B_s^1,B_s^2) ds] \\
&= \int_0^{\infty}E^1 \big[ 1_{[0, \tau^1_{(a,b)})}(s)  u(B^1_s) \big] E^2 \big[1_{[0, \tau^2_{(c,d)})}(s) v(B^2_s)\big] d s
\end{align*} \{1,2\}","['probability', 'integration', 'stochastic-processes', 'stochastic-calculus', 'brownian-motion']"
61,Soccer penalty shots,Soccer penalty shots,,"Imagine a scenario where we have a soccer player who is shooting penalty shots. He makes his first shot with probability of failure $1/3$ , then his second with probability of failure $1/5$ and so on, and at the $n$ -th throw the probability of failure is $1/(2n+1)$ . During practice, he shoots $19$ consecutive kicks. What is the probability he succeeds in an even number of kicks? For each throw, the respective probability of success is $$1-\frac{1}{(2n+1)}= \frac{2n}{(2n+1)}$$ To find the total probability of success in an even number of throws, we must add the probability of $0$ successful shots, $2, 4, \cdots, 18$ . But the $2$ successful throws can be, for example, the $1$ st and the $2$ nd, or the $4$ th and the $19$ th. Then, obviously, we will multiply the $2$ . So how do we calculate the individual probabilities? Any help will be highly appreciated!","Imagine a scenario where we have a soccer player who is shooting penalty shots. He makes his first shot with probability of failure , then his second with probability of failure and so on, and at the -th throw the probability of failure is . During practice, he shoots consecutive kicks. What is the probability he succeeds in an even number of kicks? For each throw, the respective probability of success is To find the total probability of success in an even number of throws, we must add the probability of successful shots, . But the successful throws can be, for example, the st and the nd, or the th and the th. Then, obviously, we will multiply the . So how do we calculate the individual probabilities? Any help will be highly appreciated!","1/3 1/5 n 1/(2n+1) 19 1-\frac{1}{(2n+1)}= \frac{2n}{(2n+1)} 0 2, 4, \cdots, 18 2 1 2 4 19 2","['probability', 'combinatorics']"
62,'Markovian Property' vs 'Memoryless Property','Markovian Property' vs 'Memoryless Property',,"The two properties have the commonality in the sense that they predict the future based on the current state, not on the whole history of how the process wandered into the state. Then, what is the main difference btw two..? anyone can help me?","The two properties have the commonality in the sense that they predict the future based on the current state, not on the whole history of how the process wandered into the state. Then, what is the main difference btw two..? anyone can help me?",,"['probability', 'probability-theory', 'statistics', 'statistical-inference']"
63,Show that Brownian motion on the unit circle is exponentially ergodic and has the uniform measure as its invariant distribution.,Show that Brownian motion on the unit circle is exponentially ergodic and has the uniform measure as its invariant distribution.,,"My search results keep bring up planar Brownian motion on the unit disk. However, I am specifically referring to $e^{jW_{t}} = [\cos(W_t),\sin(W_t)]^{T}$ where $W_t$ is Brownian motion. I am at a loss here, so any advice to point me in the right direction would be greatly appreciated. Thanks in advance.","My search results keep bring up planar Brownian motion on the unit disk. However, I am specifically referring to $e^{jW_{t}} = [\cos(W_t),\sin(W_t)]^{T}$ where $W_t$ is Brownian motion. I am at a loss here, so any advice to point me in the right direction would be greatly appreciated. Thanks in advance.",,"['probability', 'stochastic-processes', 'brownian-motion', 'markov-process', 'ergodic-theory']"
64,game theory - coin flipping game,game theory - coin flipping game,,"Lets say $2$ players $A$ and $B$ make a bet, who can have more money at the end after playing the following game: a coin is flipped: with $51\%$ probability it lands tails, with $49\%$ probability it lands heads you win if it lands heads, where you get back your bet $\times 2$. e.g. you bet $\$1$ and it lands heads, then you get back $\$2$ e.g. you bet $\$2$ and it lands tails, then you get back $\$0$ here are the rules to the bet between A and B (the winner of the bet wins $\$100000$): you both start with $\$100$ (given to you for free, you're not allowed to cash this out nor the money you make from the coin game) each player may play the game as many times as they want and bet as much as they want for each time they play the game player A must go first (player A plays the casino games as many times as he wants then decides to stop, after that, A can't play the game anymore) obviously the optimal strategy for player $B$ involves playing until $B$ either goes bankrupt or has more money than $A$ (although it's not obvious what bet sizes to use). what would be the optimal strategy for $A$?","Lets say $2$ players $A$ and $B$ make a bet, who can have more money at the end after playing the following game: a coin is flipped: with $51\%$ probability it lands tails, with $49\%$ probability it lands heads you win if it lands heads, where you get back your bet $\times 2$. e.g. you bet $\$1$ and it lands heads, then you get back $\$2$ e.g. you bet $\$2$ and it lands tails, then you get back $\$0$ here are the rules to the bet between A and B (the winner of the bet wins $\$100000$): you both start with $\$100$ (given to you for free, you're not allowed to cash this out nor the money you make from the coin game) each player may play the game as many times as they want and bet as much as they want for each time they play the game player A must go first (player A plays the casino games as many times as he wants then decides to stop, after that, A can't play the game anymore) obviously the optimal strategy for player $B$ involves playing until $B$ either goes bankrupt or has more money than $A$ (although it's not obvious what bet sizes to use). what would be the optimal strategy for $A$?",,"['probability', 'game-theory']"
65,Shtarkov sum approximation,Shtarkov sum approximation,,"Consider an alphabet $B = \{1, 2, ..., K \}$ and let $B^n$ be the $n$ th fold Cartesian product. $y^n \in B^n$ denotes a sequence of length $n$ with $y_i \in B$ for $1 \leq i \leq n$ . $\mathcal{P}(B)$ denotes the set of all probability distributions on $B$ . Shtarkov sum is defined as $$S_n = \sum_{y^n \in B^n } \sup_{p \in \mathcal{P}(B)} p^n(y^n)$$ where $p^n(y^n) = \prod \limits_{i=1}^n p(y_i)$ Can anyone provide some references containing approximations of $S_n$ ? I am actually trying to see if, for large $n$ , something like $$S_n \approx \frac{K - 1}{2} \log (n)$$ has been proven somewhere? Edit: I found the answer. See below","Consider an alphabet and let be the th fold Cartesian product. denotes a sequence of length with for . denotes the set of all probability distributions on . Shtarkov sum is defined as where Can anyone provide some references containing approximations of ? I am actually trying to see if, for large , something like has been proven somewhere? Edit: I found the answer. See below","B = \{1, 2, ..., K \} B^n n y^n \in B^n n y_i \in B 1 \leq i \leq n \mathcal{P}(B) B S_n = \sum_{y^n \in B^n } \sup_{p \in \mathcal{P}(B)} p^n(y^n) p^n(y^n) = \prod \limits_{i=1}^n p(y_i) S_n n S_n \approx \frac{K - 1}{2} \log (n)","['probability', 'probability-distributions', 'asymptotics', 'information-theory', 'coding-theory']"
66,Heuristics of counting twin primes,Heuristics of counting twin primes,,"I was reading on counting the number of twin primes and I found this heuristic explanation on the Hardy-Littlewood conjecture, which states that $$\pi_2(x)\sim 2\Pi_2 \frac{x}{\log^2(x)},$$ where $\pi_2$ denotes the number of twin primes smaller than $x\in[0,\infty)$ and $$\Pi_2=\prod_{p\geq 3}\left(1-\frac{1}{p}\right)^{-2}\frac{p-2}{p}.$$ The explanation given goes as follows: The prime number theorem states that $\pi(x)\sim\frac{x}{\log(x)}$ where $\pi(x)$ denotes the number of primes smaller than $x\in[0,\infty)$ . Then, we say that the probability that an integer $a\in[1,n]$ is $\frac{1}{\log(n)}$ . Assuming that $a$ and $a+2$ being prime are independent events, the probability of both of them being prime is $\frac{1}{\log^2(n)}$ . However, this is obviously not true since (for example) if $a$ is prime, $a+2$ is more likely to be prime, since it is not divisible by $2$ . We refine this model as follows: given a ""small"" integer $w>0$ we say that the probabily of an integer $a\in[1,n]$ being prime is $0$ if some prime $p\leq w$ divides $a$ and $$\prod_{p\leq w} \left(1-\frac{1}{p}\right)^{-1}\frac{1}{\log(n)}$$ otherwise. Then, we count the number of twin primes smaller than $n$ using this model to get $$2\prod_{p\leq w,\ p\neq 2}\left(1-\frac{1}{p}\right)^{-2}\frac{p-2}{p}\frac{n}{\log^2(n)}.$$ Letting $w\to\infty$ we get the result in the conjecture. What I don't understand is the final counting part. According to my source, the $2$ appears because if $a$ is prime, $a+2$ is odd, and the factor $\frac{p-2}{p}$ appears because out of $p$ numbers, only $p-2$ can be the biggest of a twin prime because the ones congruent to $0$ or $2$ modulus $p$ cannot be. I understant this facts but I don't know how to apply them to calculate the estimated number of twin primes smaller than $n$ . Any insight would be appreciated.","I was reading on counting the number of twin primes and I found this heuristic explanation on the Hardy-Littlewood conjecture, which states that where denotes the number of twin primes smaller than and The explanation given goes as follows: The prime number theorem states that where denotes the number of primes smaller than . Then, we say that the probability that an integer is . Assuming that and being prime are independent events, the probability of both of them being prime is . However, this is obviously not true since (for example) if is prime, is more likely to be prime, since it is not divisible by . We refine this model as follows: given a ""small"" integer we say that the probabily of an integer being prime is if some prime divides and otherwise. Then, we count the number of twin primes smaller than using this model to get Letting we get the result in the conjecture. What I don't understand is the final counting part. According to my source, the appears because if is prime, is odd, and the factor appears because out of numbers, only can be the biggest of a twin prime because the ones congruent to or modulus cannot be. I understant this facts but I don't know how to apply them to calculate the estimated number of twin primes smaller than . Any insight would be appreciated.","\pi_2(x)\sim 2\Pi_2 \frac{x}{\log^2(x)}, \pi_2 x\in[0,\infty) \Pi_2=\prod_{p\geq 3}\left(1-\frac{1}{p}\right)^{-2}\frac{p-2}{p}. \pi(x)\sim\frac{x}{\log(x)} \pi(x) x\in[0,\infty) a\in[1,n] \frac{1}{\log(n)} a a+2 \frac{1}{\log^2(n)} a a+2 2 w>0 a\in[1,n] 0 p\leq w a \prod_{p\leq w} \left(1-\frac{1}{p}\right)^{-1}\frac{1}{\log(n)} n 2\prod_{p\leq w,\ p\neq 2}\left(1-\frac{1}{p}\right)^{-2}\frac{p-2}{p}\frac{n}{\log^2(n)}. w\to\infty 2 a a+2 \frac{p-2}{p} p p-2 0 2 p n","['probability', 'number-theory', 'prime-numbers', 'analytic-number-theory', 'twin-primes']"
67,Cards game and probabilities,Cards game and probabilities,,"From a standard 52-cards deck we randomly pull out 2 cards.   One is black and the other is a 4.   We choose one of the two cards.   What is the probability: The card we pick is a 4 The card we pick is black The card we pick is a face card For 1: I believe it must be 1/2 (since 1 of the 2 cards is a 4) plus the probability for the other card also to be a 4. Since the other card is black, we know there are 2 fours in 26 black cards so 2/26? So finally $1/2+2/26$? Not sure. Similarly, 1/2 + the probability for the ""4"" card to be black - it can't be $1/2+2/4$ though. The black card can be a face card with probability $6/26$. Can you help me out?","From a standard 52-cards deck we randomly pull out 2 cards.   One is black and the other is a 4.   We choose one of the two cards.   What is the probability: The card we pick is a 4 The card we pick is black The card we pick is a face card For 1: I believe it must be 1/2 (since 1 of the 2 cards is a 4) plus the probability for the other card also to be a 4. Since the other card is black, we know there are 2 fours in 26 black cards so 2/26? So finally $1/2+2/26$? Not sure. Similarly, 1/2 + the probability for the ""4"" card to be black - it can't be $1/2+2/4$ though. The black card can be a face card with probability $6/26$. Can you help me out?",,"['probability', 'card-games']"
68,What is symmetry?,What is symmetry?,,"In probability, I have often seen the argument ""and this probability equals $\frac 1n$ by symmetry"" and I have never really understood the formality behind that statement. One of the biggest problems I have had with this line of reasoning is when solving the following problem: There are $n$ small and $m$ large pills in a bottle, every day, one of them is taken at random. If a large pill is taken, it is broken into two small pills, one of them is eaten and the other returned to the flask. If a small pill is taken out, it is eaten. What is the expected value of small pills remaining in the bottle after the last large pill has been taken? The solution used the linearity of expectation and $n+m$ indicator variables, and to calculate the expected value of the first $n$ indicator variables (corresponding to the initial $n$ small pills) it said that it sufficed to consider only the $1+m$ pills consisting of that small pill and the $m$ big ones, and then, by symmetry, the probability that it survived the $m$ large ones was $\frac {1}{m+1}$. The problem is I do not really understand why it suffices to consider only those $m+1$ pills and why they they have probability $\frac {1}{m+1}$ of being chosen last. What are the formalities behind this argument?","In probability, I have often seen the argument ""and this probability equals $\frac 1n$ by symmetry"" and I have never really understood the formality behind that statement. One of the biggest problems I have had with this line of reasoning is when solving the following problem: There are $n$ small and $m$ large pills in a bottle, every day, one of them is taken at random. If a large pill is taken, it is broken into two small pills, one of them is eaten and the other returned to the flask. If a small pill is taken out, it is eaten. What is the expected value of small pills remaining in the bottle after the last large pill has been taken? The solution used the linearity of expectation and $n+m$ indicator variables, and to calculate the expected value of the first $n$ indicator variables (corresponding to the initial $n$ small pills) it said that it sufficed to consider only the $1+m$ pills consisting of that small pill and the $m$ big ones, and then, by symmetry, the probability that it survived the $m$ large ones was $\frac {1}{m+1}$. The problem is I do not really understand why it suffices to consider only those $m+1$ pills and why they they have probability $\frac {1}{m+1}$ of being chosen last. What are the formalities behind this argument?",,"['probability', 'expectation']"
69,Calculate the number of integers in a given interval that are coprime to a given integer,Calculate the number of integers in a given interval that are coprime to a given integer,,"We can calculate the number of integers between $1$ and a given integer n that are relatively prime to n , using Euler function: Let $p_1^{\varepsilon1}\cdot p_2^{\varepsilon2} \cdots p_k^{\varepsilon k}$ be the prime factorization of n . Then $\phi(n)=n\cdot\frac{p_1-1}{p_1}\cdot\frac{p_2-1}{p_2}\cdots\frac{p_k-1}{p_k} $ But why stop here? My question is: Is there a fast algorithm to calculate the number of integers between two integers that are relatively prime to a given integer? According to A059956 , The probability that two integers x and x + y picked at random are relatively prime is $1/\zeta{(2)}$ . Can I estimate the answer to be:  $$\frac{y}{\zeta{(2)}}=\frac{6y}{\pi^2}$$ Is there a better method that can give me a more accurate answer to my question?","We can calculate the number of integers between $1$ and a given integer n that are relatively prime to n , using Euler function: Let $p_1^{\varepsilon1}\cdot p_2^{\varepsilon2} \cdots p_k^{\varepsilon k}$ be the prime factorization of n . Then $\phi(n)=n\cdot\frac{p_1-1}{p_1}\cdot\frac{p_2-1}{p_2}\cdots\frac{p_k-1}{p_k} $ But why stop here? My question is: Is there a fast algorithm to calculate the number of integers between two integers that are relatively prime to a given integer? According to A059956 , The probability that two integers x and x + y picked at random are relatively prime is $1/\zeta{(2)}$ . Can I estimate the answer to be:  $$\frac{y}{\zeta{(2)}}=\frac{6y}{\pi^2}$$ Is there a better method that can give me a more accurate answer to my question?",,"['probability', 'number-theory', 'algorithms', 'prime-numbers', 'zeta-functions']"
70,How to combine the four Theorems in order to prove the statement?,How to combine the four Theorems in order to prove the statement?,,"I have a question concerning a statement about Random Walks on $\mathbb{Z}$. Let $F$ be a distribution on $\mathbb{Z}$ which has mean $0$ and finite variance. Let $\left\{X_1,X_2,\ldots\right\}$ be an i.i.d. sequence of random variables with distribution $F$. Now there is the following statement: $$ \text{Prob}\left\{S_1>0,S_2>0,\ldots,S_n>0\right\}\sim\sigma((2\pi n)^{1/2} E(S_N))^{-1}, $$ where $\sigma$ is the standard deviation of the distribution $F$, $N$ is the stopping time corresponding to the first entrance into $\left\{1,2,\ldots\right\}$ and $E$ denotes expected value. For the proof, it is said, that the following four Theorems have to be combined. I tried a lot. I think one can start with (7.14) on page 415 (and maybe prove that statement afterwards), saying that (see notation below) $$ \frac{1-\tau(s)}{1-s}\sim \frac{e^{-c}}{\sqrt{1-s}}, s\to 1-. $$ The next step probably is to apply Theorems 2, 3, 4. But I am not sure how to do that exactly. Maybe you can help me. -- Some notation before I give the Theorems. Let $\mathfrak{T}_1$ be the epoch of the first entry into the (strictly) positive half-axis defined by $$ \left\{\mathfrak{T}_1=n\right\}=\left\{S_1\leq 0,\ldots,S_{n-1}\leq 0, S_n >0\right\}. $$ Let $\tau_n:=\mathbb{P}(\left\{S_1\leq 0,\ldots,S_{n-1}\leq 0, S_n >0\right\})$ and let $\tau(s)=\sum_{n=1}^{\infty}\tau_n s^n,~~0\leq s\leq 1$ be the generating function of $\mathfrak{T}_1$. A positive function $L$ is said to vary slowly at infinity if for every fixed $x$, $\frac{L(tx)}{L(x)}\to 1, t\to\infty$. Theorem 1 $$ \mathbb{P}\left\{\mathfrak{T}_1 > n\right\}\sim\frac{1}{\sqrt{\pi}}e^{-c}\frac{1}{\sqrt{n}},~~~c:=\sum_{n=1}^{\infty}\frac{1}{n} [\mathbb{P}\left\{S_n > 0\right\}-\frac{1}{2}]. $$ Theorem 2 The generating function of the probabilities $$ p_n=\mathbb{P}\left\{S_1 >0, S_2 >0,\ldots,S_n >0\right\} $$ is given by $$ p(s)=\frac{1}{1-\tau(s)}. $$ That is  $$ \log p(s)=\sum_{n=1}^{\infty}\frac{s^n}{n}\mathbb{P}\left\{S_n>0\right\}. $$ Theorem 3 Let $q_n\geq 0$ and suppose that $$ Q(s)=\sum_{n=0}^{\infty}q_n s^n $$ converges for $0\leq s <1$. If $L$ varies slowly at infinity and $0\leq p <\infty$, then each of the two relations $$ Q(s)\sim\frac{1}{(1-s)^p}L\left(\frac{1}{1-s}\right), s\to 1-~~~(*) $$ and $$ q_0+q_1+\ldots+q_{n-1}\sim\frac{1}{\Gamma(p+1)}n^p L(n), n\to\infty $$ implies the other. Furthermore, if the sequence $\left\{q_n\right\}$ is monotonic and $0<p<\infty$, then $(*)$ is equivalent to $$ q_n\sim\frac{1}{\Gamma(p)}n^{p-1}L(n), n\to\infty. $$ Theorem 4 If $F$ has zero expectation and variance $\sigma^2$ the series $$ \sum_{n=1}^{\infty}\frac{1}{n} [\mathbb{P}\left\{S_n>0\right\}-\frac{1}{2}]=c $$ converges at least conditionally, and $$ \mathbb{E}(S_N)=\frac{\sigma}{\sqrt{2}}e^{-c}. $$ The Theorems are out of Feller, An Introduction to Probability Theory and its Applications which you may see here .","I have a question concerning a statement about Random Walks on $\mathbb{Z}$. Let $F$ be a distribution on $\mathbb{Z}$ which has mean $0$ and finite variance. Let $\left\{X_1,X_2,\ldots\right\}$ be an i.i.d. sequence of random variables with distribution $F$. Now there is the following statement: $$ \text{Prob}\left\{S_1>0,S_2>0,\ldots,S_n>0\right\}\sim\sigma((2\pi n)^{1/2} E(S_N))^{-1}, $$ where $\sigma$ is the standard deviation of the distribution $F$, $N$ is the stopping time corresponding to the first entrance into $\left\{1,2,\ldots\right\}$ and $E$ denotes expected value. For the proof, it is said, that the following four Theorems have to be combined. I tried a lot. I think one can start with (7.14) on page 415 (and maybe prove that statement afterwards), saying that (see notation below) $$ \frac{1-\tau(s)}{1-s}\sim \frac{e^{-c}}{\sqrt{1-s}}, s\to 1-. $$ The next step probably is to apply Theorems 2, 3, 4. But I am not sure how to do that exactly. Maybe you can help me. -- Some notation before I give the Theorems. Let $\mathfrak{T}_1$ be the epoch of the first entry into the (strictly) positive half-axis defined by $$ \left\{\mathfrak{T}_1=n\right\}=\left\{S_1\leq 0,\ldots,S_{n-1}\leq 0, S_n >0\right\}. $$ Let $\tau_n:=\mathbb{P}(\left\{S_1\leq 0,\ldots,S_{n-1}\leq 0, S_n >0\right\})$ and let $\tau(s)=\sum_{n=1}^{\infty}\tau_n s^n,~~0\leq s\leq 1$ be the generating function of $\mathfrak{T}_1$. A positive function $L$ is said to vary slowly at infinity if for every fixed $x$, $\frac{L(tx)}{L(x)}\to 1, t\to\infty$. Theorem 1 $$ \mathbb{P}\left\{\mathfrak{T}_1 > n\right\}\sim\frac{1}{\sqrt{\pi}}e^{-c}\frac{1}{\sqrt{n}},~~~c:=\sum_{n=1}^{\infty}\frac{1}{n} [\mathbb{P}\left\{S_n > 0\right\}-\frac{1}{2}]. $$ Theorem 2 The generating function of the probabilities $$ p_n=\mathbb{P}\left\{S_1 >0, S_2 >0,\ldots,S_n >0\right\} $$ is given by $$ p(s)=\frac{1}{1-\tau(s)}. $$ That is  $$ \log p(s)=\sum_{n=1}^{\infty}\frac{s^n}{n}\mathbb{P}\left\{S_n>0\right\}. $$ Theorem 3 Let $q_n\geq 0$ and suppose that $$ Q(s)=\sum_{n=0}^{\infty}q_n s^n $$ converges for $0\leq s <1$. If $L$ varies slowly at infinity and $0\leq p <\infty$, then each of the two relations $$ Q(s)\sim\frac{1}{(1-s)^p}L\left(\frac{1}{1-s}\right), s\to 1-~~~(*) $$ and $$ q_0+q_1+\ldots+q_{n-1}\sim\frac{1}{\Gamma(p+1)}n^p L(n), n\to\infty $$ implies the other. Furthermore, if the sequence $\left\{q_n\right\}$ is monotonic and $0<p<\infty$, then $(*)$ is equivalent to $$ q_n\sim\frac{1}{\Gamma(p)}n^{p-1}L(n), n\to\infty. $$ Theorem 4 If $F$ has zero expectation and variance $\sigma^2$ the series $$ \sum_{n=1}^{\infty}\frac{1}{n} [\mathbb{P}\left\{S_n>0\right\}-\frac{1}{2}]=c $$ converges at least conditionally, and $$ \mathbb{E}(S_N)=\frac{\sigma}{\sqrt{2}}e^{-c}. $$ The Theorems are out of Feller, An Introduction to Probability Theory and its Applications which you may see here .",,"['probability', 'random-walk']"
71,Probability of Posting a Quad and Trip on 4chan,Probability of Posting a Quad and Trip on 4chan,,"Important Pre-Requisite Knowledge On the image board 4chan, every time you post your post gets a 9 digit post ID. An example of this post ID would be $586794945$. A Quad is a post ID which ends with 4 consecutive identical numbers. For example 586794444 and 586796666 is a Quad. A trip is a post ID which ends with 3 identical numbers. For example 586794333 or 586794555 are both trips. My Question a) What is the probability of receiving a trips post ID b) What is the probability of receiving a quads post ID c) How many posts are necessary (assuming each new post receives a new ID) for 3 trips to show up These are questions I came up with while on the site and I'm looking to see if my answer is correct. I'm pretty sure I know part a,b. I'm having difficulty with part c though, looking for a way to solve that. My Work Part A Our sample space is all possible posting IDs. Therefore $|S| = 10^{9}$ To calculate our $|E|$ we need to know all possible trips. We first pick our three ending letters (10 ways to do this). Then the $4^{th}$ to last digit must be different from the last 3 so we select it in 9 ways. We then have $10^5$ ways to select the starting 5 digits. Therefore, we have $10*9*10^5$ ways to select trips. Therefore, the probability of selecting a trips is $\frac{10*9*10^5}{10^{9}}$ = .009 Part B Similar process to part A. We have the same sample space. 10 ways to select the quads. 9 ways to select the $5^{th}$ to last digit, and finally $10^4$ ways to select the remaining 4 digits. Therefore probability of $\frac{10*9*10^4}{10^9}$ = .0009 Part C Don't really know where to begin. I'm thinking maybe there are $10*9*10^5$ possible trips and $10^9$ total IDs so maybe we have to post $10*9*10^5 - 10^9$ to ensure we get a trips.","Important Pre-Requisite Knowledge On the image board 4chan, every time you post your post gets a 9 digit post ID. An example of this post ID would be $586794945$. A Quad is a post ID which ends with 4 consecutive identical numbers. For example 586794444 and 586796666 is a Quad. A trip is a post ID which ends with 3 identical numbers. For example 586794333 or 586794555 are both trips. My Question a) What is the probability of receiving a trips post ID b) What is the probability of receiving a quads post ID c) How many posts are necessary (assuming each new post receives a new ID) for 3 trips to show up These are questions I came up with while on the site and I'm looking to see if my answer is correct. I'm pretty sure I know part a,b. I'm having difficulty with part c though, looking for a way to solve that. My Work Part A Our sample space is all possible posting IDs. Therefore $|S| = 10^{9}$ To calculate our $|E|$ we need to know all possible trips. We first pick our three ending letters (10 ways to do this). Then the $4^{th}$ to last digit must be different from the last 3 so we select it in 9 ways. We then have $10^5$ ways to select the starting 5 digits. Therefore, we have $10*9*10^5$ ways to select trips. Therefore, the probability of selecting a trips is $\frac{10*9*10^5}{10^{9}}$ = .009 Part B Similar process to part A. We have the same sample space. 10 ways to select the quads. 9 ways to select the $5^{th}$ to last digit, and finally $10^4$ ways to select the remaining 4 digits. Therefore probability of $\frac{10*9*10^4}{10^9}$ = .0009 Part C Don't really know where to begin. I'm thinking maybe there are $10*9*10^5$ possible trips and $10^9$ total IDs so maybe we have to post $10*9*10^5 - 10^9$ to ensure we get a trips.",,"['probability', 'combinatorics', 'solution-verification']"
72,Bingo Probability Problem,Bingo Probability Problem,,"A Bingo card has 25 squares with numbers on 24 of them, the center being a free square. The integers that are placed on the Bingo card are selected randomly and without replacement from 1 to 75, inclusive. When a game is called “cover-up"" is played, balls numbered 1 to 75, inclusive, are selected randomly and without replacement until a player covers each of the numbers on a card. Let X equal the number of balls that must be drawn to cover all the numbers on a single card. (a) Find p.m.f. of X I got (24/X)((51 choose (x-24))/(75 choose x)) and I'm pretty certain it's right. (b) Find the mean and variance of X mean = 72.96 variance = 5.725 (c) If there are 183 people playing the game together, assume indepedence, and let Y be number of balls that must be drawn to cover all the numbers on a single card of the winner (the first person(s) to have his card coverd), find p.m.f. of Y. I have no idea how to find the pmf of Y (d) Find the Mean and Variance of Y. I'm pretty sure I can get it after I find the pmf of Y.","A Bingo card has 25 squares with numbers on 24 of them, the center being a free square. The integers that are placed on the Bingo card are selected randomly and without replacement from 1 to 75, inclusive. When a game is called “cover-up"" is played, balls numbered 1 to 75, inclusive, are selected randomly and without replacement until a player covers each of the numbers on a card. Let X equal the number of balls that must be drawn to cover all the numbers on a single card. (a) Find p.m.f. of X I got (24/X)((51 choose (x-24))/(75 choose x)) and I'm pretty certain it's right. (b) Find the mean and variance of X mean = 72.96 variance = 5.725 (c) If there are 183 people playing the game together, assume indepedence, and let Y be number of balls that must be drawn to cover all the numbers on a single card of the winner (the first person(s) to have his card coverd), find p.m.f. of Y. I have no idea how to find the pmf of Y (d) Find the Mean and Variance of Y. I'm pretty sure I can get it after I find the pmf of Y.",,"['probability', 'probability-distributions']"
73,stopped filtration = filtration generated by stopped process?,stopped filtration = filtration generated by stopped process?,,"I am interested in a proof of the following statement which seems intuitive, but is somehow really tricky: Let $X$ be a stochastic process and let $(\mathcal{F}(t) : t \geq 0)$ be the filtration that it generates (unaugmented). Let $T$ be a bounded stopping time. Then we have $\mathcal{F}(T) = \sigma(X(T \wedge t) : t \geq 0)$ I have a proof at hand (Bain and Crisan, Fundamentals of Stochastic Filtering, page 309), but in my opinion there is a major gap. I will try to explain the idea of proof. Let $V$ be the space of functions $[0,\infty) \rightarrow \mathbb{R}$ equipped with the sigma algebra generated by the cylinder sets. Consider the canonical map $X^T:\Omega \rightarrow V$ which maps $\omega$ to the trajectory $t \mapsto X(t \wedge T(\omega),\omega)$. Then we have $\sigma(X(T \wedge t) : t \geq 0) = \sigma(X^T)$. The difficult part is $\subseteq$. Let $A \in \mathcal{F}(T)$. We want to find a measurable map $g:V \rightarrow \mathbb{R}$ such that $1_A = g \circ X^T$, then we're done. It is now straightforward to show that $1_A$ is constant on sets where the sample paths of $X^T$ are constant. (To be more precise: for $\rho \in \Omega$ consider the set $\mathcal{M}(\rho) = \lbrace \omega : X(\omega,t) = X(\rho,t), 0 \leq t \leq T(\rho) \rbrace$. Then $T$ and $1_A$ are constant on every set of this form). The problem is: this is not sufficient! It suffices to construct a map $g$ such that $1_A = g \circ X^T$, but how we can we know that $g$ is measurable? This is where the proof of Bain and Crisan comes up short IMO. I can show this result only under the assumption that the map $X:\Omega \rightarrow V$ be surjective: Since $A \in \mathcal{F}(\infty)$, we have a measurable map $g$ such that $1_A = g \circ X$. Let $x \in V$. Then $T$ and $1_A$ are constant on the preimage of $x$ under $X$. Therefore, $g(x)$ does not depend on the values of $x$ after time $T$ (which is constant on the preimage of $x$). Since $X$ is surjective, we have $g(x) = g(K^Tx)$, where $K$ is the killing functional $K^tx(s) = x(t \wedge s)$. Hence, $g \circ X = g \circ X^T$, and we are done. I think that this result could be a little bit deeper. I have seen two proofs of this for the special case that $X$ is the coordinate process on $C[0,\infty)$, one is given in the book of Karatzas & Shreve, Lemma 5.4.18. The fact that Karatzas proves this late in the book only in this special case somehow makes me think that the general case is not so easy. I would really appreciate any comment or other reference for this result.","I am interested in a proof of the following statement which seems intuitive, but is somehow really tricky: Let $X$ be a stochastic process and let $(\mathcal{F}(t) : t \geq 0)$ be the filtration that it generates (unaugmented). Let $T$ be a bounded stopping time. Then we have $\mathcal{F}(T) = \sigma(X(T \wedge t) : t \geq 0)$ I have a proof at hand (Bain and Crisan, Fundamentals of Stochastic Filtering, page 309), but in my opinion there is a major gap. I will try to explain the idea of proof. Let $V$ be the space of functions $[0,\infty) \rightarrow \mathbb{R}$ equipped with the sigma algebra generated by the cylinder sets. Consider the canonical map $X^T:\Omega \rightarrow V$ which maps $\omega$ to the trajectory $t \mapsto X(t \wedge T(\omega),\omega)$. Then we have $\sigma(X(T \wedge t) : t \geq 0) = \sigma(X^T)$. The difficult part is $\subseteq$. Let $A \in \mathcal{F}(T)$. We want to find a measurable map $g:V \rightarrow \mathbb{R}$ such that $1_A = g \circ X^T$, then we're done. It is now straightforward to show that $1_A$ is constant on sets where the sample paths of $X^T$ are constant. (To be more precise: for $\rho \in \Omega$ consider the set $\mathcal{M}(\rho) = \lbrace \omega : X(\omega,t) = X(\rho,t), 0 \leq t \leq T(\rho) \rbrace$. Then $T$ and $1_A$ are constant on every set of this form). The problem is: this is not sufficient! It suffices to construct a map $g$ such that $1_A = g \circ X^T$, but how we can we know that $g$ is measurable? This is where the proof of Bain and Crisan comes up short IMO. I can show this result only under the assumption that the map $X:\Omega \rightarrow V$ be surjective: Since $A \in \mathcal{F}(\infty)$, we have a measurable map $g$ such that $1_A = g \circ X$. Let $x \in V$. Then $T$ and $1_A$ are constant on the preimage of $x$ under $X$. Therefore, $g(x)$ does not depend on the values of $x$ after time $T$ (which is constant on the preimage of $x$). Since $X$ is surjective, we have $g(x) = g(K^Tx)$, where $K$ is the killing functional $K^tx(s) = x(t \wedge s)$. Hence, $g \circ X = g \circ X^T$, and we are done. I think that this result could be a little bit deeper. I have seen two proofs of this for the special case that $X$ is the coordinate process on $C[0,\infty)$, one is given in the book of Karatzas & Shreve, Lemma 5.4.18. The fact that Karatzas proves this late in the book only in this special case somehow makes me think that the general case is not so easy. I would really appreciate any comment or other reference for this result.",,"['probability', 'measure-theory', 'probability-theory', 'stochastic-processes']"
74,Solving randomized recurrence relation,Solving randomized recurrence relation,,"I'm looking at the random sequence $x_n$ with $x_0=x_1=1$ and  \begin{equation} x_{n+1}=2x_n\pm x_{n-1} \end{equation} where we choose the $\pm$ sign independently with equal probability. Now considering the recurrence relations $x_{n+1}=2x_n+x_{n-1}$ and $x_{n+1}=2x_n-x_{n-1}$ separately, it is clear that $x_n\rightarrow\infty$ as $n\rightarrow\infty$. However, the sequence $x_n^{1/n}$ seems to tend to a limit near 1.91 (got this from numerical computation and some brute force by a Monte Carlo simulating the $\pm$ sign). Thus the sequence $x_n^{1/n}$ seems to convenge almost surely. I was wondering if anyone could show that the sequence was indeed almost surely converging and/or work out the limit. Thanks in advance. Update: This comment shows that $\lim_{n\rightarrow\infty} |x_n|^{1/n}$ converges almost surely. Let $y_n=\frac{x_n}{2^n}$ then $2^{n+1}y_{n+1}=2^{n+1}y_n\pm 2^{n-1}y_{n-1}$. Hence $y_{n+1}=y_n\pm \frac{1}{4}y_{n-1}$ Embree-Trefethen showed that $\lim_{n\rightarrow\infty} |y_n|^{1/n}$ converges almost surely. See Embree, M.; Trefethen, L. N. (1999), ""Growth and decay of random Fibonacci sequences"". However, finding the almost sure limit accurately or analytically is proving difficult at the moment.","I'm looking at the random sequence $x_n$ with $x_0=x_1=1$ and  \begin{equation} x_{n+1}=2x_n\pm x_{n-1} \end{equation} where we choose the $\pm$ sign independently with equal probability. Now considering the recurrence relations $x_{n+1}=2x_n+x_{n-1}$ and $x_{n+1}=2x_n-x_{n-1}$ separately, it is clear that $x_n\rightarrow\infty$ as $n\rightarrow\infty$. However, the sequence $x_n^{1/n}$ seems to tend to a limit near 1.91 (got this from numerical computation and some brute force by a Monte Carlo simulating the $\pm$ sign). Thus the sequence $x_n^{1/n}$ seems to convenge almost surely. I was wondering if anyone could show that the sequence was indeed almost surely converging and/or work out the limit. Thanks in advance. Update: This comment shows that $\lim_{n\rightarrow\infty} |x_n|^{1/n}$ converges almost surely. Let $y_n=\frac{x_n}{2^n}$ then $2^{n+1}y_{n+1}=2^{n+1}y_n\pm 2^{n-1}y_{n-1}$. Hence $y_{n+1}=y_n\pm \frac{1}{4}y_{n-1}$ Embree-Trefethen showed that $\lim_{n\rightarrow\infty} |y_n|^{1/n}$ converges almost surely. See Embree, M.; Trefethen, L. N. (1999), ""Growth and decay of random Fibonacci sequences"". However, finding the almost sure limit accurately or analytically is proving difficult at the moment.",,"['probability', 'probability-theory', 'approximation', 'recurrence-relations']"
75,Relation between steps and turns in a simple symmetric random walk,Relation between steps and turns in a simple symmetric random walk,,"Let $S_0 = 0, S_n = X_1 + X_2 + \dots + X_n$ , $n\ge 1$ , be a simple symmetric random walk, i.e. $X_i$ , $i\ge 1$ , are iid random variables with $\mathrm P(X_i = 1) = \mathrm P(X_i = -1) = 1/2$ . Denote $\tau = \inf\{n\ge 1: S_n = 0\}$ the time of steps the random walker makes before returning to zero, and let also $\sigma = \#\{1\le k\le \tau-1: X_k X_{k+1} = -1\}$ be the number of turns the walker made. Is it true that $$ \mathrm{E} [\tau - 2\sigma] = 1?\tag{1} $$ The problem here is that $\mathrm{E} [\tau] = \mathrm{E} [\sigma] = \infty$ . Here are some ideas why $(1)$ may be true: For any $x\in \mathbb Z$ , denote $\tau(x) = \#\{0\le k\le \tau-1: S_k = x \}$ the number of steps made from $x$ and $\sigma(x) = \#\{1\le k\le \tau-1: S_k = x, X_k X_{k+1} = -1\}$ the number of turns made in $x$ , $\alpha(x) = \tau(x) - 2\sigma(x)$ . Then, $\alpha(0) = 1$ , and it is easy to show that $\mathrm{E} [\alpha(x)] = 0$ , $x\neq 0$ . However, despite that $\tau - 2\sigma = \sum_{x\in \mathbb Z} \alpha(x)$ , this does not immediately imply $(1)$ : something is needed to swap the sum and expectation signs. Denote $\sigma_n = \#\{1\le k\le n-1: X_k X_{k+1} = -1\}$ , the number of turns before moment $n\ge 1$ and let $M_n = n - 2\sigma_n$ . Then, $M_n$ is a martingale (actually, a simple symmetric random walk) starting from $M_1 = 1$ , and $\tau - 2\sigma = M_\tau$ . But this also does not imply $(1)$ . There are some related approaches, including certain direct enumeration, which confirm $(1)$ but lack rigor. In order to validate these arguments, it suffices to prove that $$ \mathrm{E} [|\tau - 2\sigma|]<\infty. $$ Edit: the symmetry is false. Indeed, $\mathrm{P}(\tau-2\sigma=0) > \mathrm{P}(\tau=2) =1/2$ . Unfortunately, I can't edit the bounty description.","Let , , be a simple symmetric random walk, i.e. , , are iid random variables with . Denote the time of steps the random walker makes before returning to zero, and let also be the number of turns the walker made. Is it true that The problem here is that . Here are some ideas why may be true: For any , denote the number of steps made from and the number of turns made in , . Then, , and it is easy to show that , . However, despite that , this does not immediately imply : something is needed to swap the sum and expectation signs. Denote , the number of turns before moment and let . Then, is a martingale (actually, a simple symmetric random walk) starting from , and . But this also does not imply . There are some related approaches, including certain direct enumeration, which confirm but lack rigor. In order to validate these arguments, it suffices to prove that Edit: the symmetry is false. Indeed, . Unfortunately, I can't edit the bounty description.","S_0 = 0, S_n = X_1 + X_2 + \dots + X_n n\ge 1 X_i i\ge 1 \mathrm P(X_i = 1) = \mathrm P(X_i = -1) = 1/2 \tau = \inf\{n\ge 1: S_n = 0\} \sigma = \#\{1\le k\le \tau-1: X_k X_{k+1} = -1\} 
\mathrm{E} [\tau - 2\sigma] = 1?\tag{1}
 \mathrm{E} [\tau] = \mathrm{E} [\sigma] = \infty (1) x\in \mathbb Z \tau(x) = \#\{0\le k\le \tau-1: S_k = x \} x \sigma(x) = \#\{1\le k\le \tau-1: S_k = x, X_k X_{k+1} = -1\} x \alpha(x) = \tau(x) - 2\sigma(x) \alpha(0) = 1 \mathrm{E} [\alpha(x)] = 0 x\neq 0 \tau - 2\sigma = \sum_{x\in \mathbb Z} \alpha(x) (1) \sigma_n = \#\{1\le k\le n-1: X_k X_{k+1} = -1\} n\ge 1 M_n = n - 2\sigma_n M_n M_1 = 1 \tau - 2\sigma = M_\tau (1) (1) 
\mathrm{E} [|\tau - 2\sigma|]<\infty.
 \mathrm{P}(\tau-2\sigma=0) > \mathrm{P}(\tau=2) =1/2","['probability', 'combinatorics', 'martingales', 'expected-value', 'random-walk']"
76,Probability that sum of integer reciprocals is larger than a fixed number.,Probability that sum of integer reciprocals is larger than a fixed number.,,"Suppose $n$ numbers are drawn independently from the list of $m$ integers $\{1,2,3,\ldots ,m\}$ uniformly at random. Denote these $n$ picks as $x_1,x_2,\ldots x_n$ . Note that $n\geq m$ is possible. Fix a positive integer $C$ . I am trying to determine the probability that $$\sum_{i = 1}^{n} \frac{1}{x_n}\geq C.$$ However I am not really sure where to start as I have not done much work with probability before. Is there some way to get such a probability?",Suppose numbers are drawn independently from the list of integers uniformly at random. Denote these picks as . Note that is possible. Fix a positive integer . I am trying to determine the probability that However I am not really sure where to start as I have not done much work with probability before. Is there some way to get such a probability?,"n m \{1,2,3,\ldots ,m\} n x_1,x_2,\ldots x_n n\geq m C \sum_{i = 1}^{n} \frac{1}{x_n}\geq C.","['probability', 'discrete-mathematics']"
77,7 dancers on a circle,7 dancers on a circle,,"7 dancers are going to participate in a contest. They are initially placed in their positions basis the initial letter of their surname.    At the second part of the contest, they are given random positions around the circle, which are determined by a draw. What is the probability that none of the dancers are in their initial positions or their neighboring? It seems very simple to me but obviously isn't. For each dancer, the probability is $\frac47$ so for all 7 it is $\frac{4^7}{7^7}$ – very simplistic, no?","7 dancers are going to participate in a contest. They are initially placed in their positions basis the initial letter of their surname.    At the second part of the contest, they are given random positions around the circle, which are determined by a draw. What is the probability that none of the dancers are in their initial positions or their neighboring? It seems very simple to me but obviously isn't. For each dancer, the probability is so for all 7 it is – very simplistic, no?",\frac47 \frac{4^7}{7^7},"['probability', 'combinatorics']"
78,Probability of number of people who know a rumor,Probability of number of people who know a rumor,,"Suppose that among a group of $n$ people, some unknown number of people $K$ know a rumor. If someone knows the rumor, there is a probability $p$ that they will tell it to us if we ask. If they don't know the rumor they will always say they don't know it. If I go around and ask each person if they know about the rumor, and $M$ people say they do, what does that tell me about the number of people who actually know the rumor? In particular, what is the distribution $P(K=k|M=m)$ in terms of $P(K)$? Edit: I've been able to show that $P(K=k|M=m)=\frac{b(m,k,p)P(K=k)}{\sum_{j=m}^{n-1}b(m,j,p)P(K=j)}$ where $b(m,k,p)$ is the binomial density function (probability of $m$ successes out of $k$ trials with probability $p$ of success). Is it possible to take this any further?","Suppose that among a group of $n$ people, some unknown number of people $K$ know a rumor. If someone knows the rumor, there is a probability $p$ that they will tell it to us if we ask. If they don't know the rumor they will always say they don't know it. If I go around and ask each person if they know about the rumor, and $M$ people say they do, what does that tell me about the number of people who actually know the rumor? In particular, what is the distribution $P(K=k|M=m)$ in terms of $P(K)$? Edit: I've been able to show that $P(K=k|M=m)=\frac{b(m,k,p)P(K=k)}{\sum_{j=m}^{n-1}b(m,j,p)P(K=j)}$ where $b(m,k,p)$ is the binomial density function (probability of $m$ successes out of $k$ trials with probability $p$ of success). Is it possible to take this any further?",,"['probability', 'statistics', 'expectation', 'bayesian']"
79,Tighter tail bounds for subgaussian random variables,Tighter tail bounds for subgaussian random variables,,"Let $X$ be a random variable on $\mathbb{R}$ satisfying $\mathbb{E}\left[e^{tX}\right] \leq e^{t^2/2}$ for all $t \in \mathbb{R}$ . What is the best explicit upper bound we can give on $\mathbb{P}[X \geq x]$ for $x > 0$ ? A well-known upper bound can be obtained by applying Markov's inequality to the moment generating function of X: For $t>0$ , $$\mathbb{P}[X \geq x] = \mathbb{P}\left[e^{tX}\geq e^{tx}\right] \leq \frac{\mathbb{E}\left[e^{tX}\right]}{e^{tx}} \leq e^{t^2/2-tx}.$$ Setting $t=x$ , yields $$\mathbb{P}[X \geq x] \leq e^{-x^2/2}.$$ How tight is this? Examples of such $X$ include the standard Gaussian and Rademacher distributions. Both satisfy stronger tail bounds, as illustrated by the following plot. This makes me wonder whether stronger bounds hold for all such $X$ . Some more precise questions: Define $$f(x) = \sup \left\{ \mathbb{P}[X\geq x] : X \text{ a random variable satisfying } \mathbb{E}\left[e^{tX}\right] \leq e^{t^2/2} \text{ for all } t \in \mathbb{R} \right\}.$$ What is $f(1)$ ? (We know $f(1) \in \left[\frac12,e^{-1/2}\right]$ , by the Rademacher example and the above tail bound.) What is $\limsup_{x \to \infty} f(x) \cdot e^{x^2/2}$ ? (We know it is $\leq 1$ , by the above tail bound.) What is $\limsup_{x \to \infty} f(x) \cdot e^{x^2/2} \cdot {x}$ ? (We know it is $\geq 1/\sqrt{2\pi}$ , by the Gaussian example [link] .) Any improved bounds on $f$ would interest me. Is there a closed form expression for $f$ ? or some way to numerically approximate $f$ ? A follow-up question would be: Are there are any natural assumptions that in addition to subgaussianity would imply $\mathbb{P}[X \ge x] \le O\left(\frac{e^{-x^2/2}}{x}\right)$ .","Let be a random variable on satisfying for all . What is the best explicit upper bound we can give on for ? A well-known upper bound can be obtained by applying Markov's inequality to the moment generating function of X: For , Setting , yields How tight is this? Examples of such include the standard Gaussian and Rademacher distributions. Both satisfy stronger tail bounds, as illustrated by the following plot. This makes me wonder whether stronger bounds hold for all such . Some more precise questions: Define What is ? (We know , by the Rademacher example and the above tail bound.) What is ? (We know it is , by the above tail bound.) What is ? (We know it is , by the Gaussian example [link] .) Any improved bounds on would interest me. Is there a closed form expression for ? or some way to numerically approximate ? A follow-up question would be: Are there are any natural assumptions that in addition to subgaussianity would imply .","X \mathbb{R} \mathbb{E}\left[e^{tX}\right] \leq e^{t^2/2} t \in \mathbb{R} \mathbb{P}[X \geq x] x > 0 t>0 \mathbb{P}[X \geq x] = \mathbb{P}\left[e^{tX}\geq e^{tx}\right] \leq \frac{\mathbb{E}\left[e^{tX}\right]}{e^{tx}} \leq e^{t^2/2-tx}. t=x \mathbb{P}[X \geq x] \leq e^{-x^2/2}. X X f(x) = \sup \left\{ \mathbb{P}[X\geq x] : X \text{ a random variable satisfying } \mathbb{E}\left[e^{tX}\right] \leq e^{t^2/2} \text{ for all } t \in \mathbb{R} \right\}. f(1) f(1) \in \left[\frac12,e^{-1/2}\right] \limsup_{x \to \infty} f(x) \cdot e^{x^2/2} \leq 1 \limsup_{x \to \infty} f(x) \cdot e^{x^2/2} \cdot {x} \geq 1/\sqrt{2\pi} f f f \mathbb{P}[X \ge x] \le O\left(\frac{e^{-x^2/2}}{x}\right)","['probability', 'gaussian-integral', 'distribution-tails', 'orlicz-spaces']"
80,Best strategy to find a parking spot,Best strategy to find a parking spot,,"New Bounty Edit (2 days remaining on the Bounty): To point out that the only answer given at this time cannot be considered an answer, because it simply gives a hint on how to formally model the problem, which is not what I was looking for, considering I wrote it informally on purpose. Still looking forward to some analyses of this problem! I was wondering about the following problem. Assume the following. you have to find a parking spot for your car in a very busy saturday night to go in a restaurant; you search for this parking spot by basically going around (literally) in the hope to get a spot; of course, (the saturday night is really busy) other people are in the same situation as you are and they are running in circle like you are; the direction of the movement is only one (again, you literally go around); the time frame of the problem lies between 20:00 and 00:00. Finally (of course!); when you start your search at 20:00 there are no free parking spots. Question: What is the best strategy you can use to find a parking spot? Should you stop in a place and wait until one of the cars that you can cover with your eyesight leaves? Or is it better to move around in the hope to find a free parking spot? I was thinking about the following few variables that I think should essentially change the nature of the problem: Cardinality of the set of parking spots (countable vs. uncountable); Cardinality of the set of agents involved in this situation (countable vs. uncountable); Probability of having a car that already occupies a parking spot leaving that lot in function of time (normally distributed, uniformly distributed, etc); Farsightedness of the agents (extreme cases: one place ahead of you, whole circle ahead of you) Hence, a solution should be explicit about what is assumed concerning those variables. [Notice that the in general I assume that the space where you are looking for a spot is homeomorphic to a circle] Any feedback as always is most welcome. PS: As you can guess, where I live it is very (very!) difficult to find a parking spot on Saturday nights... Bounty Edit: As in the bounty text, I would like to know what are reasonable answers to this question (without considering as options using the bus, the tram, a bicycle or an helicopter...).","New Bounty Edit (2 days remaining on the Bounty): To point out that the only answer given at this time cannot be considered an answer, because it simply gives a hint on how to formally model the problem, which is not what I was looking for, considering I wrote it informally on purpose. Still looking forward to some analyses of this problem! I was wondering about the following problem. Assume the following. you have to find a parking spot for your car in a very busy saturday night to go in a restaurant; you search for this parking spot by basically going around (literally) in the hope to get a spot; of course, (the saturday night is really busy) other people are in the same situation as you are and they are running in circle like you are; the direction of the movement is only one (again, you literally go around); the time frame of the problem lies between 20:00 and 00:00. Finally (of course!); when you start your search at 20:00 there are no free parking spots. Question: What is the best strategy you can use to find a parking spot? Should you stop in a place and wait until one of the cars that you can cover with your eyesight leaves? Or is it better to move around in the hope to find a free parking spot? I was thinking about the following few variables that I think should essentially change the nature of the problem: Cardinality of the set of parking spots (countable vs. uncountable); Cardinality of the set of agents involved in this situation (countable vs. uncountable); Probability of having a car that already occupies a parking spot leaving that lot in function of time (normally distributed, uniformly distributed, etc); Farsightedness of the agents (extreme cases: one place ahead of you, whole circle ahead of you) Hence, a solution should be explicit about what is assumed concerning those variables. [Notice that the in general I assume that the space where you are looking for a spot is homeomorphic to a circle] Any feedback as always is most welcome. PS: As you can guess, where I live it is very (very!) difficult to find a parking spot on Saturday nights... Bounty Edit: As in the bounty text, I would like to know what are reasonable answers to this question (without considering as options using the bus, the tram, a bicycle or an helicopter...).",,"['probability', 'recreational-mathematics', 'puzzle', 'decision-theory']"
81,Probability of Intersecting Two Random Segments in a Circle,Probability of Intersecting Two Random Segments in a Circle,,"I designed this problem and tried to solve it but didn't solve. Choose four points $A$, $B$, $C$ and $D$ from inside of a circle uniformly and independent. What is the probability that $AC$ intersects $BD$?","I designed this problem and tried to solve it but didn't solve. Choose four points $A$, $B$, $C$ and $D$ from inside of a circle uniformly and independent. What is the probability that $AC$ intersects $BD$?",,['probability']
82,Modelling risk when market making,Modelling risk when market making,,"I'm interested in learning about algorithmic trading, particularly in bitcoin. Looking at this chart, I can see that I could simultaneously offer a bid that was slightly higher than the highest bid, and an ask that was slightly lower than the current lowest ask. Whenever anyone bought or sold, that would mean that I would always be one of the people they bought/sold from/to. This would allow me to make a profit equal to the gap between the two. The problem I'm having is in calculating the risks. As far as I can tell the variables involved are: Variables out of my control Gap between highest bid and ask offered by others Average price paid for ""pot"" of BTC that I'm trading with Some measure of the volatility of prices over the preceding period (Risk) How much volume would move the market by a given amount higher or lower Variables within my control Maximum exposure in terms of money Maximum difference in ratio between GBP reserve and BTC reserve Size of the gap between my bid/ask prices (out from the exact centre as percentage of total gap) I'm struggling to figure out how to model this effectively though. I studied Computer Science and have a basic grasp of probability theory, but this is a bit beyond me. Any help, or pointers to the ""proper"" formula to model this would be greatly appreciated.","I'm interested in learning about algorithmic trading, particularly in bitcoin. Looking at this chart, I can see that I could simultaneously offer a bid that was slightly higher than the highest bid, and an ask that was slightly lower than the current lowest ask. Whenever anyone bought or sold, that would mean that I would always be one of the people they bought/sold from/to. This would allow me to make a profit equal to the gap between the two. The problem I'm having is in calculating the risks. As far as I can tell the variables involved are: Variables out of my control Gap between highest bid and ask offered by others Average price paid for ""pot"" of BTC that I'm trading with Some measure of the volatility of prices over the preceding period (Risk) How much volume would move the market by a given amount higher or lower Variables within my control Maximum exposure in terms of money Maximum difference in ratio between GBP reserve and BTC reserve Size of the gap between my bid/ask prices (out from the exact centre as percentage of total gap) I'm struggling to figure out how to model this effectively though. I studied Computer Science and have a basic grasp of probability theory, but this is a bit beyond me. Any help, or pointers to the ""proper"" formula to model this would be greatly appreciated.",,"['probability', 'finance', 'economics', 'risk-assessment']"
83,"Does ""50/50 chance of.. . "" convey information?","Does ""50/50 chance of.. . "" convey information?",,"I distinctly remember the professor in the undergrad introductory systems & control course saying that ""when weather forecasters say there's a 50% chance of precipitation, they are conveying no information"". At the time (freshman) I didn't know Shannon or Kolmogorov but it struck me as a strange comment, after all, if true, why bother reporting the numbers in the first place? More recently, in Itzhak Gilboa's Theory of Decision under Uncertainty I found the comment, p.25: First, if we have a random variable X on [0, 1], and we know nothing   about it, we cannot assume that it has a uniform distribution on [0,   1] and pretend that we made a natural choice. So even though the uniform distribution is the maximum entropy distribution (eg among binomial distributions, {rain,no rain}), doesn't saying 50/50 chance convey more information than not knowing the distribution at all? I'm 50% sure some will vote to close this question, but note I'm not asking for a quantification of how much more (if any) information, but rather just a binary yes/no, which should be within the realm of mathematics.","I distinctly remember the professor in the undergrad introductory systems & control course saying that ""when weather forecasters say there's a 50% chance of precipitation, they are conveying no information"". At the time (freshman) I didn't know Shannon or Kolmogorov but it struck me as a strange comment, after all, if true, why bother reporting the numbers in the first place? More recently, in Itzhak Gilboa's Theory of Decision under Uncertainty I found the comment, p.25: First, if we have a random variable X on [0, 1], and we know nothing   about it, we cannot assume that it has a uniform distribution on [0,   1] and pretend that we made a natural choice. So even though the uniform distribution is the maximum entropy distribution (eg among binomial distributions, {rain,no rain}), doesn't saying 50/50 chance convey more information than not knowing the distribution at all? I'm 50% sure some will vote to close this question, but note I'm not asking for a quantification of how much more (if any) information, but rather just a binary yes/no, which should be within the realm of mathematics.",,"['probability', 'statistics', 'information-theory']"
84,Probability of Generating a Connected Graph on the Unit Square,Probability of Generating a Connected Graph on the Unit Square,,"$N$ points are generated randomly on the unit square, with a uniform distribution. What is the probability that they form a connected graph, given that two points are connected iff the distance between them is less than or equal to $d\in(0,\sqrt{2})$? This should obviously be some function of $N$ and $d$.","$N$ points are generated randomly on the unit square, with a uniform distribution. What is the probability that they form a connected graph, given that two points are connected iff the distance between them is less than or equal to $d\in(0,\sqrt{2})$? This should obviously be some function of $N$ and $d$.",,"['probability', 'graph-theory']"
85,"In a circle, where should you draw a line segment of fixed length, to maximize the probability that it will be intersected by a random chord?","In a circle, where should you draw a line segment of fixed length, to maximize the probability that it will be intersected by a random chord?",,"In a circle, a chord will be drawn by connecting two uniformly random points on the circle. Where in the circle should you draw a line segment of fixed length, to maximize the probability that it will be intersected by the chord? My attempts suggest (but do not prove), perhaps counter-intuitively, that the line segment should be drawn so that it is a chord of the circle. ATTEMPT $1$ Let the radius of the circle be $1$ , and let the length of the line segment be $2L$ , where $L<1$ . In deciding where to draw the line segment, the variables are: $p=$ distance between centre of circle and midpoint of line segment $\theta=$ acute angle between line segment, and line through centre of circle and midpoint of line segment. The diagram shows the line segment in red, and one of the randomly chosen points on the circle. For each value of angle $x$ , the probability that the line segment is intersected by the random chord, is $C/\pi$ . The overall probability is the average value of $C/\pi$ , as angle $x$ goes from $0$ to $2\pi$ . It takes a bit of work to express $C$ in terms of $L, p, \theta, x$ : $a=\sqrt{p^2+L^2-2pL\cos{(\pi-\theta)}}$ (cosine rule) $A=\arcsin{\left(\frac{L\sin{(\pi-\theta)}}{a}\right)}$ (sine rule) $b=\sqrt{1^2+a^2-2a\cos{(A+x)}}$ (cosine rule) $c=\sqrt{1^2+p^2-2p\cos{x}}$ (cosine rule) $\cos{B}=\frac{b^2+L^2-c^2}{2bL}=\frac{b^2+(2L)^2-d^2}{4bL}$ (cosine rule) $\implies d=\sqrt{2L^2-b^2+2c^2}$ $C=\arccos{\left(\frac{b^2+d^2-(2L)^2}{2bd}\right)}$ (cosine rule) $P=P(\text{line segment is intersected by chord})=\frac{1}{2\pi}\int_0^{2\pi}\frac{C}{\pi}dx$ Putting all of this into my computer, it seems that, for any value of $L<1$ , $P$ is maximized when the line segment is drawn as a chord of the circle. But trying to prove this analytically seems daunting. ATTEMPT $2$ Consider a disk of radius $r<1$ placed inside a unit circle. The distance between their centres is $t$ , and $P(t)$ is the probability that a random chord (chosen by connecting two uniformly random points on the unit circle) will intersect the disk. We will try to show that $P(t)$ is an increasing function in $t$ . Then in the original question, regard the line segment as a rigid row of many small disks. When the line segment (i.e. row of disks) is a chord of the unit circle, the $t$ -value of each small disk is maximized, so the probability that the line segment is intersected by a random chord is maximized. The diagram shows a disk, and one of the randomly chosen points on the circle. For each value of angle $x$ , the probability that the disk is intersected by the random chord, is $\alpha/\pi$ . The overall probability is the average value of $\alpha/\pi$ as angle $x$ goes from $0$ to $2\pi$ . $\alpha=2\arcsin{\left(\dfrac{r}{\sqrt{1+t^2-2t\cos{x}}}\right)}$ $P(t)=\dfrac{1}{\pi^2}\int_0^{2\pi}\arcsin{\left(\dfrac{r}{\sqrt{1+t^2-2t\cos{x}}}\right)}dx=\dfrac{2}{\pi^2}\int_0^{\pi}\arcsin{\left(\dfrac{r}{\sqrt{1+t^2-2t\cos{x}}}\right)}dx$ We can express the integral as a riemann sum, then differentiate with respect to $t$ , then express the new riemann sum as an integral. So we get: $\dfrac{dP(t)}{dt}=\dfrac{2r}{\pi^2}\int_{0}^{\pi}\dfrac{\cos{x}-t}{(1+t^2-2t\cos{x})\sqrt{1+t^2-2t\cos{x}-r^2}}dx$ Since $r$ will approach $0$ , I think we can ignore the $r^2$ in the denominator. So we just have to show that $\int_{0}^{\pi}\dfrac{\cos{x}-t}{(1+t^2-2t\cos{x})^{1.5}}dx>0$ for $0<t<1$ , but I do not know how to show this. I found a related question , but it has not helped me. ATTEMPT $3$ I tried to use the method in the answer of @Gribouillis below to get an expression for the probability that the line segment will be intersected by a random chord, but it does not seem to make the maximization problem any easier than my ""Attempt $1$ "". EXTRA INFORMATION $P$ seems to be minimized when the line segment's midpoint is at the centre of the circle. The ratio of the maximum to minimum probabilities seems to approach $\pi/2$ as $L\to0$ . Just for fun, I asked my high school students this question, and asked them to use their intuition, with the following choices: 24 students chose A. 18 students chose B. 10 students chose C. 6 students chose D.","In a circle, a chord will be drawn by connecting two uniformly random points on the circle. Where in the circle should you draw a line segment of fixed length, to maximize the probability that it will be intersected by the chord? My attempts suggest (but do not prove), perhaps counter-intuitively, that the line segment should be drawn so that it is a chord of the circle. ATTEMPT Let the radius of the circle be , and let the length of the line segment be , where . In deciding where to draw the line segment, the variables are: distance between centre of circle and midpoint of line segment acute angle between line segment, and line through centre of circle and midpoint of line segment. The diagram shows the line segment in red, and one of the randomly chosen points on the circle. For each value of angle , the probability that the line segment is intersected by the random chord, is . The overall probability is the average value of , as angle goes from to . It takes a bit of work to express in terms of : (cosine rule) (sine rule) (cosine rule) (cosine rule) (cosine rule) (cosine rule) Putting all of this into my computer, it seems that, for any value of , is maximized when the line segment is drawn as a chord of the circle. But trying to prove this analytically seems daunting. ATTEMPT Consider a disk of radius placed inside a unit circle. The distance between their centres is , and is the probability that a random chord (chosen by connecting two uniformly random points on the unit circle) will intersect the disk. We will try to show that is an increasing function in . Then in the original question, regard the line segment as a rigid row of many small disks. When the line segment (i.e. row of disks) is a chord of the unit circle, the -value of each small disk is maximized, so the probability that the line segment is intersected by a random chord is maximized. The diagram shows a disk, and one of the randomly chosen points on the circle. For each value of angle , the probability that the disk is intersected by the random chord, is . The overall probability is the average value of as angle goes from to . We can express the integral as a riemann sum, then differentiate with respect to , then express the new riemann sum as an integral. So we get: Since will approach , I think we can ignore the in the denominator. So we just have to show that for , but I do not know how to show this. I found a related question , but it has not helped me. ATTEMPT I tried to use the method in the answer of @Gribouillis below to get an expression for the probability that the line segment will be intersected by a random chord, but it does not seem to make the maximization problem any easier than my ""Attempt "". EXTRA INFORMATION seems to be minimized when the line segment's midpoint is at the centre of the circle. The ratio of the maximum to minimum probabilities seems to approach as . Just for fun, I asked my high school students this question, and asked them to use their intuition, with the following choices: 24 students chose A. 18 students chose B. 10 students chose C. 6 students chose D.","1 1 2L L<1 p= \theta= x C/\pi C/\pi x 0 2\pi C L, p, \theta, x a=\sqrt{p^2+L^2-2pL\cos{(\pi-\theta)}} A=\arcsin{\left(\frac{L\sin{(\pi-\theta)}}{a}\right)} b=\sqrt{1^2+a^2-2a\cos{(A+x)}} c=\sqrt{1^2+p^2-2p\cos{x}} \cos{B}=\frac{b^2+L^2-c^2}{2bL}=\frac{b^2+(2L)^2-d^2}{4bL} \implies d=\sqrt{2L^2-b^2+2c^2} C=\arccos{\left(\frac{b^2+d^2-(2L)^2}{2bd}\right)} P=P(\text{line segment is intersected by chord})=\frac{1}{2\pi}\int_0^{2\pi}\frac{C}{\pi}dx L<1 P 2 r<1 t P(t) P(t) t t x \alpha/\pi \alpha/\pi x 0 2\pi \alpha=2\arcsin{\left(\dfrac{r}{\sqrt{1+t^2-2t\cos{x}}}\right)} P(t)=\dfrac{1}{\pi^2}\int_0^{2\pi}\arcsin{\left(\dfrac{r}{\sqrt{1+t^2-2t\cos{x}}}\right)}dx=\dfrac{2}{\pi^2}\int_0^{\pi}\arcsin{\left(\dfrac{r}{\sqrt{1+t^2-2t\cos{x}}}\right)}dx t \dfrac{dP(t)}{dt}=\dfrac{2r}{\pi^2}\int_{0}^{\pi}\dfrac{\cos{x}-t}{(1+t^2-2t\cos{x})\sqrt{1+t^2-2t\cos{x}-r^2}}dx r 0 r^2 \int_{0}^{\pi}\dfrac{\cos{x}-t}{(1+t^2-2t\cos{x})^{1.5}}dx>0 0<t<1 3 1 P \pi/2 L\to0","['probability', 'integration', 'geometry', 'optimization', 'circles']"
86,Unbalance in cake-cutting,Unbalance in cake-cutting,,"In cake-cutting, we cut a round cake into $m$ pieces by $n$ cuts. If we seek maximum $m$ pieces with $n$ cuts, we may observe that the area unbalance increases greatly with $m$ . Could we define a mathematical relationship among the unbalance, pieces and cuts? Let's describe it precisely in math notions. Given a unit disk with total area $\pi$ , for a configuration $c$ of $n$ straight lines, $c$ cuts the disk into $m$ pieces, and the area of each piece is $A_i$ . Define the portion of each piece by $p_i = \frac{A_i}{\pi}$ The area unbalance may be described by entropy: $$S_2 = - \sum_{i=1}^{m}p_i \ln p_i$$ The arc length of the outer pieces is also unbalanced, a similar entropy $S_1$ can be introduced: $$S_1 = - \sum_jq_j \ln q_j$$ where $q_j = \frac{L_j}{2 \pi}$ is the portion of the segments of the circumference. Could we describe the relationship among $S_1$ , $S_2$ , $m$ and $n$ ? And given $m$ and $n$ , which cut $c$ leads to the least unbalance $S_1$ and $S_2$ ?","In cake-cutting, we cut a round cake into pieces by cuts. If we seek maximum pieces with cuts, we may observe that the area unbalance increases greatly with . Could we define a mathematical relationship among the unbalance, pieces and cuts? Let's describe it precisely in math notions. Given a unit disk with total area , for a configuration of straight lines, cuts the disk into pieces, and the area of each piece is . Define the portion of each piece by The area unbalance may be described by entropy: The arc length of the outer pieces is also unbalanced, a similar entropy can be introduced: where is the portion of the segments of the circumference. Could we describe the relationship among , , and ? And given and , which cut leads to the least unbalance and ?",m n m n m \pi c n c m A_i p_i = \frac{A_i}{\pi} S_2 = - \sum_{i=1}^{m}p_i \ln p_i S_1 S_1 = - \sum_jq_j \ln q_j q_j = \frac{L_j}{2 \pi} S_1 S_2 m n m n c S_1 S_2,"['probability', 'geometry', 'optimization']"
87,KL Divergence between the sums of random variables.,KL Divergence between the sums of random variables.,,"The relative entropy or Kullback–Leibler distance between two probability density functions $g(x)$ and $f(x)$ is defined as $$D(g\|f) = \int_{x} g(x)\log\frac{g(x)}{f(x)}  dx .$$ We have two random variables $V$ and $W$,  \begin{equation*} \begin{split} &V=X_1+X_2, \text{where}\ X_1\sim g(x), X_2\sim f(x)\ \text{are independent},\\ &W=X_3+X_4, \text{where}\ X_3, X_4\sim f(x)\ \text{are independent}. \end{split} \end{equation*} It is easy to show that  \begin{equation*} \begin{split} &V\sim G(x)=(g\ast f)(x),\\ &W\sim F(x)=(f\ast f)(x), \end{split} \end{equation*} where $(g\ast f)(x) = \int g(\tau)f(x-\tau)d\tau$ is the convolution of $g$ and $f$. The questions are: Is it true that $D(g\|f)> D(G\|F)?$ Is it true that $\frac{1}{2}D(g\|f)> D(G\|F)?$ If we can prove 2, 1 is obviously true.  They are true for Poisson and Gaussian distributions, however, I can't prove for the general cases.","The relative entropy or Kullback–Leibler distance between two probability density functions $g(x)$ and $f(x)$ is defined as $$D(g\|f) = \int_{x} g(x)\log\frac{g(x)}{f(x)}  dx .$$ We have two random variables $V$ and $W$,  \begin{equation*} \begin{split} &V=X_1+X_2, \text{where}\ X_1\sim g(x), X_2\sim f(x)\ \text{are independent},\\ &W=X_3+X_4, \text{where}\ X_3, X_4\sim f(x)\ \text{are independent}. \end{split} \end{equation*} It is easy to show that  \begin{equation*} \begin{split} &V\sim G(x)=(g\ast f)(x),\\ &W\sim F(x)=(f\ast f)(x), \end{split} \end{equation*} where $(g\ast f)(x) = \int g(\tau)f(x-\tau)d\tau$ is the convolution of $g$ and $f$. The questions are: Is it true that $D(g\|f)> D(G\|F)?$ Is it true that $\frac{1}{2}D(g\|f)> D(G\|F)?$ If we can prove 2, 1 is obviously true.  They are true for Poisson and Gaussian distributions, however, I can't prove for the general cases.",,"['probability', 'information-theory']"
88,"Let $X,Y$ have the same distribution on common prob space, do they generate same $\sigma$-algebra?","Let  have the same distribution on common prob space, do they generate same -algebra?","X,Y \sigma","So let $X,Y$ be real random variables on common probability space $(\Omega, \mathcal{F}, P)$, the measures on Borel $(\mathbb{R},\mathcal{B}_{\mathbb{R}})$ induced by $X$ and $Y$ are equal, that is for all $A \in \mathcal{B}_{\mathbb{R}}$. $$ P_{X}(A) = P_{Y}(A)$$ where $$P_{X}(A) := P(X^{-1}(A))$$ and $$P_{Y}(A) := P(Y^{-1}(A))$$ Do $X,Y$ generate the same $\sigma-$algebra? I feel that it might not be necessarily the case but was not able to construct a counter example. Any help would be appreciated","So let $X,Y$ be real random variables on common probability space $(\Omega, \mathcal{F}, P)$, the measures on Borel $(\mathbb{R},\mathcal{B}_{\mathbb{R}})$ induced by $X$ and $Y$ are equal, that is for all $A \in \mathcal{B}_{\mathbb{R}}$. $$ P_{X}(A) = P_{Y}(A)$$ where $$P_{X}(A) := P(X^{-1}(A))$$ and $$P_{Y}(A) := P(Y^{-1}(A))$$ Do $X,Y$ generate the same $\sigma-$algebra? I feel that it might not be necessarily the case but was not able to construct a counter example. Any help would be appreciated",,"['probability', 'measure-theory', 'lebesgue-measure']"
89,Algorithm to compute fastest method of collecting $k$ re-spawning items which spawn at $n$ specified points,Algorithm to compute fastest method of collecting  re-spawning items which spawn at  specified points,k n,"Let $V = v_1, \dots, v_n$ be the locations the items can spawn at, and let $U = u_1, \dots, u_k$ be the current positions of the items. We will assume a new items spawns instantly every time we collect an item, so there are always $k$ items (Assume uniform distribution for spawn location). Let $w$ be the current position of the character. Then $S = (V, U, w)$ is the state of the game. Assume the character can move at a constant speed, so the time metric we care about is proportional to the distance between two points. Essentially I want a function $\text{bestItem}(S)$ that tells me which item in $U$ to go to first to maximize the number of items I collect per hour. This seems similar to shortest path on a clique with weighted edges, but it doesn't stop after one step. Or a traveling salesman problem where the traveling salesman doesn't know all the locations he needs to visit from the start. Is there a name for this problem? I am curious if it is already solved, and how good the greedy method of just always taking the nearest item is compared to the optimal method. Or the method of computing the shortest path through the points of $U$, and updating it after some number of spawns. Has anyone worked with this type of problem and point me at some reading material? My interest is inspired by video games which have mechanics like this. Thanks.","Let $V = v_1, \dots, v_n$ be the locations the items can spawn at, and let $U = u_1, \dots, u_k$ be the current positions of the items. We will assume a new items spawns instantly every time we collect an item, so there are always $k$ items (Assume uniform distribution for spawn location). Let $w$ be the current position of the character. Then $S = (V, U, w)$ is the state of the game. Assume the character can move at a constant speed, so the time metric we care about is proportional to the distance between two points. Essentially I want a function $\text{bestItem}(S)$ that tells me which item in $U$ to go to first to maximize the number of items I collect per hour. This seems similar to shortest path on a clique with weighted edges, but it doesn't stop after one step. Or a traveling salesman problem where the traveling salesman doesn't know all the locations he needs to visit from the start. Is there a name for this problem? I am curious if it is already solved, and how good the greedy method of just always taking the nearest item is compared to the optimal method. Or the method of computing the shortest path through the points of $U$, and updating it after some number of spawns. Has anyone worked with this type of problem and point me at some reading material? My interest is inspired by video games which have mechanics like this. Thanks.",,"['probability', 'discrete-mathematics', 'graph-theory', 'algorithms']"
90,How many players needed for the game to have the highest probability of finishing the fastest?,How many players needed for the game to have the highest probability of finishing the fastest?,,"Welcome to the fictional game of ""color-tag""; the not-so-fast-paced cousin of paintball Where marking your opponent is all that counts! If $A$ marks $B$ with his/her color, then $B$ will be permanently marked with $A$'s color, but at the same time all other people marked with $B$'s color will instantly be permanently marked with $A$'s color as well. The first one to have marked everyone wins, and the game is finished! $m<x$ where $m = 16$, and the number of players, $x$, is put in a room and assigned an unique color. With every hour that progress, all the players have a probability of $1 - \frac{m}{x}$ of successfully marking another player. There is no limit as to how many times a player marks another player. In the event that $A$ marks another player, the player, that is being marked, $B$, is chosen at random; Although players cannot mark themselves. Now, I would like to know what the optimal number of players for the game having the highest probability of being the fastest. That is, how many players are needed for the game to have the highest probability of finishing the fastest? Sounds simple enough, right? It turns out that it sounds simpler than it is; At least in my ears. I've tried to warp my head around it, but I fail to find a viable approach. I started out by calculating $(1 - \frac{16}{32} * \frac{1}{32})^{32}$, thinking that $(1 - \frac{m}{x} * \frac{1}{x})^x$ was the way to go about calculating the fastest possible game with respect to the number of players. I soon realized that there was no way that was going to give me anything near correct results, so I came up with something along the lines of $\sum_{n=0}^{x-1} ((1 - \frac{m}{x}) * \frac{x-n}{x})^n$, which I hoped would get me somewhere; But all it did was feed me an absurdly small number and make me realize that I've never been faced with a problem like this, and that I have no idea of how to solve it. Right now, I'm not even considering that I must find the cases with the highest probabilities of success, then cross check to see which is he fastest; Which I do think is paramount in this problem, alas I know of no way to approach this. Any input (especially tag additions) is greatly appreciated! EDIT 1: Just to make sure there is no confusion: If a player $A$ and another player $B$ both get to mark an opponent (opponents being all the other players) within a hour, then there is a chance, and it is allowed that $A$ marks $B$, and $B$ marks $A$. Marking another player happens instantaneously and simultaneously.","Welcome to the fictional game of ""color-tag""; the not-so-fast-paced cousin of paintball Where marking your opponent is all that counts! If $A$ marks $B$ with his/her color, then $B$ will be permanently marked with $A$'s color, but at the same time all other people marked with $B$'s color will instantly be permanently marked with $A$'s color as well. The first one to have marked everyone wins, and the game is finished! $m<x$ where $m = 16$, and the number of players, $x$, is put in a room and assigned an unique color. With every hour that progress, all the players have a probability of $1 - \frac{m}{x}$ of successfully marking another player. There is no limit as to how many times a player marks another player. In the event that $A$ marks another player, the player, that is being marked, $B$, is chosen at random; Although players cannot mark themselves. Now, I would like to know what the optimal number of players for the game having the highest probability of being the fastest. That is, how many players are needed for the game to have the highest probability of finishing the fastest? Sounds simple enough, right? It turns out that it sounds simpler than it is; At least in my ears. I've tried to warp my head around it, but I fail to find a viable approach. I started out by calculating $(1 - \frac{16}{32} * \frac{1}{32})^{32}$, thinking that $(1 - \frac{m}{x} * \frac{1}{x})^x$ was the way to go about calculating the fastest possible game with respect to the number of players. I soon realized that there was no way that was going to give me anything near correct results, so I came up with something along the lines of $\sum_{n=0}^{x-1} ((1 - \frac{m}{x}) * \frac{x-n}{x})^n$, which I hoped would get me somewhere; But all it did was feed me an absurdly small number and make me realize that I've never been faced with a problem like this, and that I have no idea of how to solve it. Right now, I'm not even considering that I must find the cases with the highest probabilities of success, then cross check to see which is he fastest; Which I do think is paramount in this problem, alas I know of no way to approach this. Any input (especially tag additions) is greatly appreciated! EDIT 1: Just to make sure there is no confusion: If a player $A$ and another player $B$ both get to mark an opponent (opponents being all the other players) within a hour, then there is a chance, and it is allowed that $A$ marks $B$, and $B$ marks $A$. Marking another player happens instantaneously and simultaneously.",,['probability']
91,Expected value of the distance square,Expected value of the distance square,,"Given two points $X,Y$ on two sides of square $[0,1]\times [0,1]$ ($X:(0,1/2),Y:(1,1/2)$ (PS: My original question is $X,Y$ on opposite of a square, but I think that's not the real case) )and $n$ points distributed uniformly(i.i.d) in the square (where $n$ is large, and $A$ denotes the set of $n$ points), can I caluculate the asymptotic behavior of the value $M(n)$, where $M$ is defined as $$M(n)=E\left[\min_{B\subset A} \sum_{k=1}^{|B|+1} d(B_k,B_{k-1})^2\right]$$ where $B_k$ is the $k$th element of $B$,$B_0=X,B_{m+1}=Y$(We let $m=|B|$), and the expected value is taken over all the possible $A$ . That is to say, I would like to compute the expected value of the minimal weight defined as sum of the square of distance. I know that when $n\to\infty,M(n)\to 0$. And in the $1$-dim case, this is easy, since it is only a Poisson process, and the distance between two consecutive points are surely exponential distribution.(Calculation suggests it's about $(n+3)/((n+1)(n+2))$,where $n$ is number of points added) But in the two dimensional case, I got stuck and don't know how to tackle it. This is a problem arouse from the calculation of the cost of a network. Any hint or reference are welcomed, Thanks! (Some computer experiment suggests that the weight is about $\approx 1.1/\sqrt{n}=O(1/\sqrt{n})$. I also wonder if there are some similar results?)","Given two points $X,Y$ on two sides of square $[0,1]\times [0,1]$ ($X:(0,1/2),Y:(1,1/2)$ (PS: My original question is $X,Y$ on opposite of a square, but I think that's not the real case) )and $n$ points distributed uniformly(i.i.d) in the square (where $n$ is large, and $A$ denotes the set of $n$ points), can I caluculate the asymptotic behavior of the value $M(n)$, where $M$ is defined as $$M(n)=E\left[\min_{B\subset A} \sum_{k=1}^{|B|+1} d(B_k,B_{k-1})^2\right]$$ where $B_k$ is the $k$th element of $B$,$B_0=X,B_{m+1}=Y$(We let $m=|B|$), and the expected value is taken over all the possible $A$ . That is to say, I would like to compute the expected value of the minimal weight defined as sum of the square of distance. I know that when $n\to\infty,M(n)\to 0$. And in the $1$-dim case, this is easy, since it is only a Poisson process, and the distance between two consecutive points are surely exponential distribution.(Calculation suggests it's about $(n+3)/((n+1)(n+2))$,where $n$ is number of points added) But in the two dimensional case, I got stuck and don't know how to tackle it. This is a problem arouse from the calculation of the cost of a network. Any hint or reference are welcomed, Thanks! (Some computer experiment suggests that the weight is about $\approx 1.1/\sqrt{n}=O(1/\sqrt{n})$. I also wonder if there are some similar results?)",,"['probability', 'graph-theory', 'stochastic-processes']"
92,What is the average weight of a minimal spanning tree of $n$ randomly selected points in the unit cube?,What is the average weight of a minimal spanning tree of  randomly selected points in the unit cube?,n,"Suppose we pick $n$ random points in the unit cube in $\mathbb{R}_3$, $p_1=\left(x_1,y_1,z_1\right),$ $p_2=\left(x_2,y_2,z_2\right),$ etc. (So, $x_i,y_i,z_i$ are $3n$ uniformly distributed random variables between $0$ and $1$.) Let $\Gamma$ be a complete graph on these $n$ points, and weight each edge $\{p_i,p_j\}$ by $$w_{ij}=\sqrt{\left(x_i-x_j\right)^2+\left(y_i-y_j\right)^2+\left(z_i-z_j\right)^2}.$$ Question: What is the expected value of the total weight of a minimal spanning tree of $\Gamma$? (Note: Here total weight means the sum of all edges in the minimal spanning tree.) A peripheral request: The answer is probably a function of $n$, but I don't have the computing power or a good implementation of Kruskall's algorithm to suggest what this should look like.  If someone could run a simulation to generate this average over many $n$, it might help towards a solution to see this data.","Suppose we pick $n$ random points in the unit cube in $\mathbb{R}_3$, $p_1=\left(x_1,y_1,z_1\right),$ $p_2=\left(x_2,y_2,z_2\right),$ etc. (So, $x_i,y_i,z_i$ are $3n$ uniformly distributed random variables between $0$ and $1$.) Let $\Gamma$ be a complete graph on these $n$ points, and weight each edge $\{p_i,p_j\}$ by $$w_{ij}=\sqrt{\left(x_i-x_j\right)^2+\left(y_i-y_j\right)^2+\left(z_i-z_j\right)^2}.$$ Question: What is the expected value of the total weight of a minimal spanning tree of $\Gamma$? (Note: Here total weight means the sum of all edges in the minimal spanning tree.) A peripheral request: The answer is probably a function of $n$, but I don't have the computing power or a good implementation of Kruskall's algorithm to suggest what this should look like.  If someone could run a simulation to generate this average over many $n$, it might help towards a solution to see this data.",,"['probability', 'graph-theory', 'trees', 'computational-mathematics', 'random-graphs']"
93,"Probability, choose a box and then take exactly two white balls","Probability, choose a box and then take exactly two white balls",,"There are $5$ boxes. There are $5$ white and $3$ black balls in two boxes, and $4$ white and $6$ black balls in the other three boxes. One box is randomly chosen. $3$ balls are randomly taken from the chosen box. What is the probability that exactly $2$ of the chosen balls are white? $A$ - the box with $8$ balls is chosen $\bar{A}$ - the box with $10$ balls is chosen $B$ - exactly two chosen balls are white There are $5$ boxes, $2$ boxes with $8$ balls: $2/5$ . Choosing the box and taking the balls are independent events so I can multiply the probabilities. There are $8$ balls in the box, I need to take $3$ balls $\binom83$ , of which $2$ are white $\binom52$ and $1$ black $\binom31$ (there are $5$ white balls and $3$ black balls): $$P(B \mid A)=\frac{2}{5} \cdot \frac{\dbinom52 \dbinom31}{\dbinom83}$$ Similarly: $$P(B \mid \bar{A})=\frac{3}{5} \cdot \frac{\dbinom42 \dbinom61}{\dbinom{10}3}$$ So now I can calculate $P(B)$ : $$P(B)=P(B \mid A) \cdot P(A)+P(B \mid \bar{A}) \cdot P(\bar{A})$$ Is this correct?","There are boxes. There are white and black balls in two boxes, and white and black balls in the other three boxes. One box is randomly chosen. balls are randomly taken from the chosen box. What is the probability that exactly of the chosen balls are white? - the box with balls is chosen - the box with balls is chosen - exactly two chosen balls are white There are boxes, boxes with balls: . Choosing the box and taking the balls are independent events so I can multiply the probabilities. There are balls in the box, I need to take balls , of which are white and black (there are white balls and black balls): Similarly: So now I can calculate : Is this correct?",5 5 3 4 6 3 2 A 8 \bar{A} 10 B 5 2 8 2/5 8 3 \binom83 2 \binom52 1 \binom31 5 3 P(B \mid A)=\frac{2}{5} \cdot \frac{\dbinom52 \dbinom31}{\dbinom83} P(B \mid \bar{A})=\frac{3}{5} \cdot \frac{\dbinom42 \dbinom61}{\dbinom{10}3} P(B) P(B)=P(B \mid A) \cdot P(A)+P(B \mid \bar{A}) \cdot P(\bar{A}),"['probability', 'combinatorics', 'conditional-probability']"
94,Empirical distribution vs. the true one: How fast $KL( \hat{P}_n || Q)$ converges to $KL( P || Q)$?,Empirical distribution vs. the true one: How fast  converges to ?,KL( \hat{P}_n || Q) KL( P || Q),"Let $X_1,X_2,\dots$ be i.i.d. samples drawn from a discrete space $\mathcal{X}$ according to probability distribution $P$ , and denote the resulting empirical distribution based on n samples by $\hat{P}_n$ . Also let $Q$ be an arbitrary distribution. It is clear that (KL-divergence) \begin{equation}      KL( \hat{P}_n || Q) \stackrel{n\rightarrow \infty}{\longrightarrow} KL(P || Q) \end{equation} but I am wondering if there exist any known quantitative rate of convergence for it. I mean if it can be shown that \begin{equation}     \Pr\Big[ | KL( \hat{P}_n || Q) - KL(P || Q) | \geq \delta\Big] \leq f(\delta, n, |\mathcal{X}|) \end{equation} and what is the best expression for the RHS if there is any. Thanks a lot!","Let be i.i.d. samples drawn from a discrete space according to probability distribution , and denote the resulting empirical distribution based on n samples by . Also let be an arbitrary distribution. It is clear that (KL-divergence) but I am wondering if there exist any known quantitative rate of convergence for it. I mean if it can be shown that and what is the best expression for the RHS if there is any. Thanks a lot!","X_1,X_2,\dots \mathcal{X} P \hat{P}_n Q \begin{equation} 
    KL( \hat{P}_n || Q) \stackrel{n\rightarrow \infty}{\longrightarrow} KL(P || Q)
\end{equation} \begin{equation}
    \Pr\Big[ | KL( \hat{P}_n || Q) - KL(P || Q) | \geq \delta\Big] \leq f(\delta, n, |\mathcal{X}|)
\end{equation}","['probability', 'statistics', 'reference-request', 'information-theory', 'learning']"
95,"How fast does $\lim_{ t \to 0} E \left[ \|Z\|^2 1_{B}(X,X+\sqrt{t} Z) \right]= E \left[ \|Z\|^2 \right] E[1_B(X)]$",How fast does,"\lim_{ t \to 0} E \left[ \|Z\|^2 1_{B}(X,X+\sqrt{t} Z) \right]= E \left[ \|Z\|^2 \right] E[1_B(X)]","Let $X \in \mathbb{R}^n $ and $Z \in \mathbb{R}^n  $ be two independent standard normal random vectors. We are interested in the following quantity: \begin{align} E \left[ \|Z\|^2 1_{B \times B}(X,X+\sqrt{t} Z) \right] \end{align} for some set $B\subset \mathbb{R}^n $ . Assumptions about the set $B$ : 1) Assume that $1>P(Z\in B)>0$ ; 2) (Optional) $B$ is convex. Concretely, we are interested in how this quantity behaves as $t \to 0$ . First, it is easy to show that \begin{align} \lim_{ t \to 0} E \left[ \|Z\|^2 1_{B \times B}(X,X+\sqrt{t} Z) \right]=  E \left[ \|Z\|^2  \right] E[1_B(X)], \end{align} where we have used the dominated convergence theorem and the bound $\|Z\|^2 1_{B \times B}(X,X+\sqrt{t} Z) \le \|Z\|^2$ . My question is: Can we say something about how fast does this approach the limit?  Specificaly, can we say something about $$\lim_{ t \to 0} \frac{d}{dt} E \left[ \|Z\|^2 1_{B \times B}(X,X+\sqrt{t} Z) \right]= ???$$ Edit: The derivative is given by \begin{align} &2 \frac{d}{dt} E \left[ \|Z\|^2 1_{B \times B}(X,X+\sqrt{t} Z) \right]\\ &=\frac{E[\|Z\|^4  1_{B \times B}(X,X+\sqrt{t} Z)]-   (n+2) E[\|Z\|^2  1_{B \times B}(X+\sqrt{t} Z ,X) ]}{t} \end{align} Now, if take the limit as $t \to 0$ of the numerator than we get \begin{align} &\lim_{n \to \infty} E[\|Z\|^4  1_{B \times B}(X,X+\sqrt{t} Z)]-   (n+2) E[\|Z\|^2  1_{B \times B}(X+\sqrt{t} Z ,X) ]\\ &=  E \left[ \|Z\|^4  \right] E[1_B(X)] - (n+2) E \left[ \|Z\|^2  \right] E[1_B(X)]\\ &=0 \end{align} where we have used that the fourth moment is given by $E \left[ \|Z\|^4  \right]=n(n+2)$ . Therefore, we have zero over zero. I tried using L'hospital rule more times, but we keep getting zero over zero no matter how many times we apply  L'hospital rule.","Let and be two independent standard normal random vectors. We are interested in the following quantity: for some set . Assumptions about the set : 1) Assume that ; 2) (Optional) is convex. Concretely, we are interested in how this quantity behaves as . First, it is easy to show that where we have used the dominated convergence theorem and the bound . My question is: Can we say something about how fast does this approach the limit?  Specificaly, can we say something about Edit: The derivative is given by Now, if take the limit as of the numerator than we get where we have used that the fourth moment is given by . Therefore, we have zero over zero. I tried using L'hospital rule more times, but we keep getting zero over zero no matter how many times we apply  L'hospital rule.","X \in \mathbb{R}^n  Z \in \mathbb{R}^n   \begin{align}
E \left[ \|Z\|^2 1_{B \times B}(X,X+\sqrt{t} Z) \right]
\end{align} B\subset \mathbb{R}^n  B 1>P(Z\in B)>0 B t \to 0 \begin{align}
\lim_{ t \to 0} E \left[ \|Z\|^2 1_{B \times B}(X,X+\sqrt{t} Z) \right]=  E \left[ \|Z\|^2  \right] E[1_B(X)],
\end{align} \|Z\|^2 1_{B \times B}(X,X+\sqrt{t} Z) \le \|Z\|^2 \lim_{ t \to 0} \frac{d}{dt} E \left[ \|Z\|^2 1_{B \times B}(X,X+\sqrt{t} Z) \right]= ??? \begin{align}
&2 \frac{d}{dt} E \left[ \|Z\|^2 1_{B \times B}(X,X+\sqrt{t} Z) \right]\\
&=\frac{E[\|Z\|^4  1_{B \times B}(X,X+\sqrt{t} Z)]-   (n+2) E[\|Z\|^2  1_{B \times B}(X+\sqrt{t} Z ,X) ]}{t}
\end{align} t \to 0 \begin{align}
&\lim_{n \to \infty} E[\|Z\|^4  1_{B \times B}(X,X+\sqrt{t} Z)]-   (n+2) E[\|Z\|^2  1_{B \times B}(X+\sqrt{t} Z ,X) ]\\
&=  E \left[ \|Z\|^4  \right] E[1_B(X)] - (n+2) E \left[ \|Z\|^2  \right] E[1_B(X)]\\
&=0
\end{align} E \left[ \|Z\|^4  \right]=n(n+2)","['probability', 'probability-theory', 'normal-distribution', 'expected-value']"
96,Normal orthant probability in six variables,Normal orthant probability in six variables,,"Let $\mathbf{X} \sim N(\mathbf{0}, \mathbf{\Sigma})$ be a $6$ -dimensional Gaussian vector with covariance matrix of the form $$\mathbf{\Sigma} = \begin{pmatrix} 1 & c \\ c & 1 \end{pmatrix} \otimes \begin{pmatrix} 1 & 1/2 & 1/2 \\ 1/2 & 1 & 1/2 \\ 1/2 & 1/2 & 1 \end{pmatrix} = \begin{pmatrix}  1 & 1/2 & 1/2 & c & c/2 & c/2 \\  1/2 & 1 & 1/2 & c/2 & c & c/2 \\ 1/2 & 1/2 & 1 & c/2 & c/2 & c \\ c & c/2 & c/2 & 1 & 1/2 & 1/2 \\ c/2 & c & c/2 & 1/2 & 1 & 1/2 \\ c/2 & c/2 & c & 1/2 & 1/2 & 1 \end{pmatrix}$$ Here $c$ is some constant between $0$ and $1$ . I am interested in $\Pr(\mathbf{X} \geq \mathbf{0})$ , i.e. the probability that all of the six coordinates are non-negative/positive. This is also known as the orthant probability for $\mathbf{X}$ , and explicit formulas for orthant probabilities for arbitrary covariance matrices $\mathbf{\Sigma}$ are known in $2, 3, 4$ dimensions. The analysis seems very tedious and nasty though, and I am not sure if the same techniques generalize easily to $6$ dimensions. For my example of $6$ dimensions, my search has not yet returned any literature, attempting to solve this problem even in special cases with additional structure like above. I also tried computing this probability with Mathematica, but it cannot solve it analytically, and even numerically it seems to have a hard time to return exact results. My question is: is there any way to find the orthant probability for such a structured $6$ -dimensional matrix? Is there any literature I am missing? Or can someone solve this analytically? Edit : The paper https://ieeexplore.ieee.org/document/1054159 describes a derivation of the orthant probability for four variables, where \begin{align} \mathbf{\Sigma} = \begin{pmatrix} 1 & c \\ c & 1 \end{pmatrix} \otimes \begin{pmatrix} 1 & d \\ d & 1 \end{pmatrix}. \end{align} Perhaps it is possible to use similar techniques for this case as well (using a similar path of integration approach), although the reduction at the bottom of page 389 would not go from a $4$ -dimensional orthant probability to a $2$ -dimensional one, which can readily be evaluated, but from $6$ dimensions to $4$ dimensions, and adding another integral over these orthant probabilities. Still, this reference might be useful -- it might inspire similar techniques/approaches to this problem.","Let be a -dimensional Gaussian vector with covariance matrix of the form Here is some constant between and . I am interested in , i.e. the probability that all of the six coordinates are non-negative/positive. This is also known as the orthant probability for , and explicit formulas for orthant probabilities for arbitrary covariance matrices are known in dimensions. The analysis seems very tedious and nasty though, and I am not sure if the same techniques generalize easily to dimensions. For my example of dimensions, my search has not yet returned any literature, attempting to solve this problem even in special cases with additional structure like above. I also tried computing this probability with Mathematica, but it cannot solve it analytically, and even numerically it seems to have a hard time to return exact results. My question is: is there any way to find the orthant probability for such a structured -dimensional matrix? Is there any literature I am missing? Or can someone solve this analytically? Edit : The paper https://ieeexplore.ieee.org/document/1054159 describes a derivation of the orthant probability for four variables, where Perhaps it is possible to use similar techniques for this case as well (using a similar path of integration approach), although the reduction at the bottom of page 389 would not go from a -dimensional orthant probability to a -dimensional one, which can readily be evaluated, but from dimensions to dimensions, and adding another integral over these orthant probabilities. Still, this reference might be useful -- it might inspire similar techniques/approaches to this problem.","\mathbf{X} \sim N(\mathbf{0}, \mathbf{\Sigma}) 6 \mathbf{\Sigma} = \begin{pmatrix} 1 & c \\ c & 1 \end{pmatrix} \otimes \begin{pmatrix} 1 & 1/2 & 1/2 \\ 1/2 & 1 & 1/2 \\ 1/2 & 1/2 & 1 \end{pmatrix} = \begin{pmatrix} 
1 & 1/2 & 1/2 & c & c/2 & c/2 \\ 
1/2 & 1 & 1/2 & c/2 & c & c/2 \\
1/2 & 1/2 & 1 & c/2 & c/2 & c \\
c & c/2 & c/2 & 1 & 1/2 & 1/2 \\
c/2 & c & c/2 & 1/2 & 1 & 1/2 \\
c/2 & c/2 & c & 1/2 & 1/2 & 1
\end{pmatrix} c 0 1 \Pr(\mathbf{X} \geq \mathbf{0}) \mathbf{X} \mathbf{\Sigma} 2, 3, 4 6 6 6 \begin{align}
\mathbf{\Sigma} = \begin{pmatrix} 1 & c \\ c & 1 \end{pmatrix} \otimes \begin{pmatrix} 1 & d \\ d & 1 \end{pmatrix}.
\end{align} 4 2 6 4","['probability', 'multivariable-calculus', 'reference-request', 'multiple-integral', 'geometric-probability']"
97,Constructing a probability measure on the Hypercube with given moments,Constructing a probability measure on the Hypercube with given moments,,"Let $H = [-1, 1]^d$ be the $d$ -dimensional hypercube, and let $\mu \in \text{int} H$ . Under these conditions, I can explicitly construct a tractable probability measure $P$ , supported on on $H$ , which has $\mu$ as its mean. For my purposes, tractability means: (a) $P$ has a density, which can be written down and cheaply evaluated. (b) $P$ can be exactly sampled from, efficiently. This is a relatively simple task, since the problem basically decouples across dimensions; if you can find a probability measure $P_i$ on $[-1,1]$ with mean $\mu_i$ , then setting $P = P_1 (x_1) \cdots P_d (x_d)$ suffices. I've been using the family of random variables given by $P(x) \propto \exp( \langle \theta, x \rangle)$ to do this; the mean of each coordinate is then given by $m_i(\theta) = \coth \theta_i - \theta_i^{-1}$ which is surjective onto $(-1,1)$ and so one can always find a $\theta$ which gives you the mean you want. Now, suppose I want to extend this, and construct a probability measure on $H$ which also has the covariance matrix I want, i.e. let $\Sigma$ be a general $d \times d$ positive semi-definite matrix. Then, I want all the above, plus: \begin{align} \textbf{Var}_{X \sim P} [X] &= \Sigma \end{align} This is more or less possible when $\Sigma$ is diagonal, but otherwise I haven't figured out how to do it. Of course, in the general case, I will need $\Sigma$ to be sufficiently small, as I can't have arbitrarily high variance when constrained to a cube, I've considered sampling from a truncated Gaussian, i.e. sampling from $\mathcal{N}(\mu, \Sigma)$ until you land in $H$ . However, this won't generally have a tractable density, due to the normalising constant. It also won't quite have the right moments, though I can basically forgive this; I ultimately don't mind too much if I only have \begin{align} \mathbf{E}_{X \sim P} [X] &\approx \mu \\ \textbf{Var}_{X \sim P} [X] &\approx \Sigma \end{align} with some control of the bias. I should perhaps highlight that it's not sufficient for my purposes to approximate $\Sigma$ by a diagonal matrix. So, the concise version of my question is: is there a way of explicitly constructing probability measures on the hypercube which have the mean and covariance matrix which I want it to have? There needn't be a 'canonical' / optimal' answer (whatever that might mean here); something functional will entirely suffice. It's also preferable to have a construction where it's easy to adapt things to sample from a range of different $(\mu, \Sigma)$ .","Let be the -dimensional hypercube, and let . Under these conditions, I can explicitly construct a tractable probability measure , supported on on , which has as its mean. For my purposes, tractability means: (a) has a density, which can be written down and cheaply evaluated. (b) can be exactly sampled from, efficiently. This is a relatively simple task, since the problem basically decouples across dimensions; if you can find a probability measure on with mean , then setting suffices. I've been using the family of random variables given by to do this; the mean of each coordinate is then given by which is surjective onto and so one can always find a which gives you the mean you want. Now, suppose I want to extend this, and construct a probability measure on which also has the covariance matrix I want, i.e. let be a general positive semi-definite matrix. Then, I want all the above, plus: This is more or less possible when is diagonal, but otherwise I haven't figured out how to do it. Of course, in the general case, I will need to be sufficiently small, as I can't have arbitrarily high variance when constrained to a cube, I've considered sampling from a truncated Gaussian, i.e. sampling from until you land in . However, this won't generally have a tractable density, due to the normalising constant. It also won't quite have the right moments, though I can basically forgive this; I ultimately don't mind too much if I only have with some control of the bias. I should perhaps highlight that it's not sufficient for my purposes to approximate by a diagonal matrix. So, the concise version of my question is: is there a way of explicitly constructing probability measures on the hypercube which have the mean and covariance matrix which I want it to have? There needn't be a 'canonical' / optimal' answer (whatever that might mean here); something functional will entirely suffice. It's also preferable to have a construction where it's easy to adapt things to sample from a range of different .","H = [-1, 1]^d d \mu \in \text{int} H P H \mu P P P_i [-1,1] \mu_i P = P_1 (x_1) \cdots P_d (x_d) P(x) \propto \exp( \langle \theta, x \rangle) m_i(\theta) = \coth \theta_i - \theta_i^{-1} (-1,1) \theta H \Sigma d \times d \begin{align}
\textbf{Var}_{X \sim P} [X] &= \Sigma
\end{align} \Sigma \Sigma \mathcal{N}(\mu, \Sigma) H \begin{align}
\mathbf{E}_{X \sim P} [X] &\approx \mu \\
\textbf{Var}_{X \sim P} [X] &\approx \Sigma
\end{align} \Sigma (\mu, \Sigma)","['probability', 'probability-distributions', 'covariance', 'sampling', 'moment-problem']"
98,How is Riemann–Stieltjes Integration insufficient for developing modern probability theory?,How is Riemann–Stieltjes Integration insufficient for developing modern probability theory?,,"If we consider Riemann–Stieltjes integration then it can perfectly account for mixed probability distribution (a continuous R.V with some point mass). So why would we still need Lebesgue Integration theory? Is it because the Riemann integrable class is not large enough, or is it because under Riemann integration interchanging limits and integration is too hard(usually requiring uniform convergence)?","If we consider Riemann–Stieltjes integration then it can perfectly account for mixed probability distribution (a continuous R.V with some point mass). So why would we still need Lebesgue Integration theory? Is it because the Riemann integrable class is not large enough, or is it because under Riemann integration interchanging limits and integration is too hard(usually requiring uniform convergence)?",,"['probability', 'integration', 'lebesgue-integral']"
99,Expected maximum of a sequence of i.i.d. Poissons,Expected maximum of a sequence of i.i.d. Poissons,,"Let $X_i \sim \mathrm{Pois}(1)$ be a sequence of $n$ i.i.d. random variables (with Poisson distribution with parameter 1). I'm interested in the asymptotic behavior of $$\mathbb E[\max_{i \in \{1\ldots n\}}X_i],$$ i.e., the expected maximum value of the sequence for large $n$. The exact answer is $$\sum^\infty_{k = 0}\left[1-\left(\sum_{i=0}^k \frac{e^{-1}}{i!}\right)^n\right],$$ but I'm not really sure how to massage this into something that's easy to work with. I think the results I'm looking for are in a paper called ""A note on Poisson maxima,"" but I can't find a copy of it online.","Let $X_i \sim \mathrm{Pois}(1)$ be a sequence of $n$ i.i.d. random variables (with Poisson distribution with parameter 1). I'm interested in the asymptotic behavior of $$\mathbb E[\max_{i \in \{1\ldots n\}}X_i],$$ i.e., the expected maximum value of the sequence for large $n$. The exact answer is $$\sum^\infty_{k = 0}\left[1-\left(\sum_{i=0}^k \frac{e^{-1}}{i!}\right)^n\right],$$ but I'm not really sure how to massage this into something that's easy to work with. I think the results I'm looking for are in a paper called ""A note on Poisson maxima,"" but I can't find a copy of it online.",,"['probability', 'probability-distributions', 'poisson-distribution', 'order-statistics']"
