,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Optimal auction bidding strategy?,Optimal auction bidding strategy?,,"This is an interview question: There are 200 1 dollar coins, each with an equal probability of going into a pot and not. You bid for that pot (get the money in the pot, but you don't know how many coins are in it). The person who offers the highest bid wins the auction. What would you bid (with 1 competitor, 10 competitors)? Now if we just two bid and both players bid optimally, but you have the advantage of knowing how many of the first 10 coins go into the pot, what will be the strategies? How much will you bid and what is your expected payoff? I feel like in the first case it's 100 regardless of how many competitors there are based on the EV, but I also feel like I need to take into account the standard deviation of $\sqrt{50}$ , since the scenario follows a Binomial distribution. I'm not sure how to approach the second part besides calculating the EV as well.","This is an interview question: There are 200 1 dollar coins, each with an equal probability of going into a pot and not. You bid for that pot (get the money in the pot, but you don't know how many coins are in it). The person who offers the highest bid wins the auction. What would you bid (with 1 competitor, 10 competitors)? Now if we just two bid and both players bid optimally, but you have the advantage of knowing how many of the first 10 coins go into the pot, what will be the strategies? How much will you bid and what is your expected payoff? I feel like in the first case it's 100 regardless of how many competitors there are based on the EV, but I also feel like I need to take into account the standard deviation of , since the scenario follows a Binomial distribution. I'm not sure how to approach the second part besides calculating the EV as well.",\sqrt{50},"['probability', 'statistics', 'probability-distributions', 'problem-solving', 'gambling']"
1,Low Number of trials for Bernoulli trial - cannot use normal approximation,Low Number of trials for Bernoulli trial - cannot use normal approximation,,"I am investigating whether an event that can be treated as a Bernoulli trial is statistically likely. However, I only have $ n = 5 $ trials, and so I don't believe I can approximate a normal distribution and employ a hypothesis test. Is there any way around this? I understand that statistics inherently relies on the law of large numbers so I assume I just have too few trials ultimately.","I am investigating whether an event that can be treated as a Bernoulli trial is statistically likely. However, I only have trials, and so I don't believe I can approximate a normal distribution and employ a hypothesis test. Is there any way around this? I understand that statistics inherently relies on the law of large numbers so I assume I just have too few trials ultimately.", n = 5 ,"['statistics', 'normal-distribution', 'hypothesis-testing']"
2,"UMP Test for $f_{\theta}(x)=2\theta^{-2}(\theta-x)I_{(0,\theta)}(x)$",UMP Test for,"f_{\theta}(x)=2\theta^{-2}(\theta-x)I_{(0,\theta)}(x)","I am trying to find the UMP test for the following question: Let X be a sample of size 1 from a  Lebesgue pdf $f_{\theta}$ . Find a UMP test of size $\alpha$ for $$H_{o}:\theta=\theta_{0} \hspace{5mm}  H_{1}:\theta=\theta_{1}$$ when $$f_{\theta}(x)=2\theta^{-2}(\theta-x)I_{(0,\theta)}(x), \hspace{4mm} \theta_0<\theta_1$$ I propose the following test $$T(X) =       \begin{cases}        1  & \theta_0<X<\theta_1 \\         \gamma &  X<\theta_0\\      \end{cases}$$ where $\gamma=\alpha$ to get the desired size. I reject $\theta=\theta_0$ with prob 1 when $\theta_0<X<\theta_1$ because it is not possible that our observation was produced from a r.v with $f_{\theta_0}$ distribution due to the support constraint. For the boundary randomization is required and therefore  since $X\sim f_{\theta_0}$ is a proper r.v then $P_{\theta_0}(X<\theta_0)=1$ and since $P_{\theta_0}(\theta_0<X<\theta_1)=0$ then $\gamma=\alpha$ to get desired size. Is this correct?",I am trying to find the UMP test for the following question: Let X be a sample of size 1 from a  Lebesgue pdf . Find a UMP test of size for when I propose the following test where to get the desired size. I reject with prob 1 when because it is not possible that our observation was produced from a r.v with distribution due to the support constraint. For the boundary randomization is required and therefore  since is a proper r.v then and since then to get desired size. Is this correct?,"f_{\theta} \alpha H_{o}:\theta=\theta_{0} \hspace{5mm}  H_{1}:\theta=\theta_{1} f_{\theta}(x)=2\theta^{-2}(\theta-x)I_{(0,\theta)}(x), \hspace{4mm} \theta_0<\theta_1 T(X) = 
     \begin{cases}
       1  & \theta_0<X<\theta_1 \\ 
       \gamma &  X<\theta_0\\
     \end{cases} \gamma=\alpha \theta=\theta_0 \theta_0<X<\theta_1 f_{\theta_0} X\sim f_{\theta_0} P_{\theta_0}(X<\theta_0)=1 P_{\theta_0}(\theta_0<X<\theta_1)=0 \gamma=\alpha","['statistics', 'hypothesis-testing']"
3,Variance of a sample median,Variance of a sample median,,"Suppose $X_1,\ldots,X_n\sim\text{i.i.d.}\operatorname N(\mu,\sigma^2).$ I think I've only ever seen one way to prove that the sample mean of $X_1,\ldots,X_n$ has a smaller variance than does the sample median, and it uses some moderately hefty results and doesn't say what the variance of the sample median is. Specifically, two theorems are used: The Lehmann–Scheffé theorem from the theory of estimation, and the one-to-one-ness of the two-sided Laplace transform: $$ \left( \mathcal L g\right)(\theta) = \int_{-\infty}^{+\infty} g(x) e^{\theta x} \, dx. \\[16pt] \text{If } \mathcal L g = \mathcal L h \text{ then } g=h \text{ a.e.} $$ Is there an elementary and efficient way to show that the sample median has a larger variance than the sample mean? And (here's the question on a specific definite integral, justifying one of the tags) is there a closed form for the variance of the sample median? (Here someone could possibly object that this whole thing is trivially reducible to the case where $\mu=0$ and $\sigma=1.$ The two theorems mentioned above both have hypotheses saying either than something doesn't change as $(\mu,\sigma^2)$ changes or that something is true of all values of $(\mu,\sigma^2).$ So I suppose you could construe this question like this: Supposing the hypothesis $\mu=0,\sigma=1$ is assumed, since there is clearly no loss of generality. How do you prove the result then? Is this a case where it is better to forgo a simplifying assumption that discards no generality?)","Suppose I think I've only ever seen one way to prove that the sample mean of has a smaller variance than does the sample median, and it uses some moderately hefty results and doesn't say what the variance of the sample median is. Specifically, two theorems are used: The Lehmann–Scheffé theorem from the theory of estimation, and the one-to-one-ness of the two-sided Laplace transform: Is there an elementary and efficient way to show that the sample median has a larger variance than the sample mean? And (here's the question on a specific definite integral, justifying one of the tags) is there a closed form for the variance of the sample median? (Here someone could possibly object that this whole thing is trivially reducible to the case where and The two theorems mentioned above both have hypotheses saying either than something doesn't change as changes or that something is true of all values of So I suppose you could construe this question like this: Supposing the hypothesis is assumed, since there is clearly no loss of generality. How do you prove the result then? Is this a case where it is better to forgo a simplifying assumption that discards no generality?)","X_1,\ldots,X_n\sim\text{i.i.d.}\operatorname N(\mu,\sigma^2). X_1,\ldots,X_n 
\left( \mathcal L g\right)(\theta) = \int_{-\infty}^{+\infty} g(x) e^{\theta x} \, dx. \\[16pt]
\text{If } \mathcal L g = \mathcal L h \text{ then } g=h \text{ a.e.}
 \mu=0 \sigma=1. (\mu,\sigma^2) (\mu,\sigma^2). \mu=0,\sigma=1","['statistics', 'definite-integrals', 'parameter-estimation', 'median']"
4,"Algorithm to compute ""median""","Algorithm to compute ""median""",,"Let $x_1,\dots,x_m\in\mathbb{R}^d$ be a finite set of points.  I define the $d$ -dimensional ""median"" $y\in\mathbb{R}^d$ to be the point minimizing the sum of distances to $x_j$ , $$ y = \arg\min_{z\in\mathbb{R}^d} \sum_{j=1}^m |z-x_j|. $$ (Note that the median might not exist, for example if $x_j$ lie on a straight line). Is there an efficient algorithm to compute $y$ ?  For example, when $m=3$ and $d=2$ there is a construction for the Fermat point of a triangle, which is what I am calling the median here. Thanks!","Let be a finite set of points.  I define the -dimensional ""median"" to be the point minimizing the sum of distances to , (Note that the median might not exist, for example if lie on a straight line). Is there an efficient algorithm to compute ?  For example, when and there is a construction for the Fermat point of a triangle, which is what I am calling the median here. Thanks!","x_1,\dots,x_m\in\mathbb{R}^d d y\in\mathbb{R}^d x_j 
y = \arg\min_{z\in\mathbb{R}^d} \sum_{j=1}^m |z-x_j|.
 x_j y m=3 d=2","['calculus', 'geometry', 'statistics', 'euclidean-geometry', 'median']"
5,"Finding MLE estimator for given density $f(x, \alpha, \beta)$",Finding MLE estimator for given density,"f(x, \alpha, \beta)","I'm having trouble with the following example problem of MLE: Let $X = (X_1, ..., X_n)$ be a trial from i.i.d r.v. with density: $$ g(x) = \frac{\alpha}{x^2}\mathbb{1}_{[\beta, \infty)}(x) $$ where $\beta> 0$ . Write $\alpha$ in terms of $\beta$ to obtain $f(x, \beta)$ Find its likelihood function and draw its graph Using above result get MLE estimator of $\beta$ Could anyone give me a hint on the first task? I'm banging my head against the wall but can't see how $\alpha$ may be written only in terms of $\beta$ . I derived $L$ as $$ L(\textbf{x}, \alpha, \beta) = \frac{\alpha^n}{\prod_\limits{i=1}^n x_i^2}\mathbb{1}_{[\beta, \infty)(X(1))} $$ to maybe find some clues there but without any meaningful effect.",I'm having trouble with the following example problem of MLE: Let be a trial from i.i.d r.v. with density: where . Write in terms of to obtain Find its likelihood function and draw its graph Using above result get MLE estimator of Could anyone give me a hint on the first task? I'm banging my head against the wall but can't see how may be written only in terms of . I derived as to maybe find some clues there but without any meaningful effect.,"X = (X_1, ..., X_n) 
g(x) = \frac{\alpha}{x^2}\mathbb{1}_{[\beta, \infty)}(x)
 \beta> 0 \alpha \beta f(x, \beta) \beta \alpha \beta L 
L(\textbf{x}, \alpha, \beta) = \frac{\alpha^n}{\prod_\limits{i=1}^n x_i^2}\mathbb{1}_{[\beta, \infty)(X(1))}
","['statistics', 'maximum-likelihood', 'log-likelihood']"
6,Should I be using normpdf to answer this question?,Should I be using normpdf to answer this question?,,"If the mean of a sample is 30, and the standard deviation is 10, then how would I evaluate a question that asks me how likely it is that I would obtain a value of $34$ ? Also the size of the sample is 20. I'm confused about this: Would I calculate $P(X=34)=P(Z=\frac{34-30}{8})=P(Z=0.5)$ ? From this I'm confused because a cdf would give me $P(X\leq x )$ and I'm unclear on if I should use normpdf on a TI-84 calculator instead of normcdf. I'm an AP Statistics student and my teacher says never to use normpdf for this class. My second approach would be to see that $Z=\frac{34-30}{4} = 0.5$ so a value of 34 is only half a standard deviation above the mean. This would mean it's pretty likely. Also, does the sample size matter in this situation?","If the mean of a sample is 30, and the standard deviation is 10, then how would I evaluate a question that asks me how likely it is that I would obtain a value of ? Also the size of the sample is 20. I'm confused about this: Would I calculate ? From this I'm confused because a cdf would give me and I'm unclear on if I should use normpdf on a TI-84 calculator instead of normcdf. I'm an AP Statistics student and my teacher says never to use normpdf for this class. My second approach would be to see that so a value of 34 is only half a standard deviation above the mean. This would mean it's pretty likely. Also, does the sample size matter in this situation?",34 P(X=34)=P(Z=\frac{34-30}{8})=P(Z=0.5) P(X\leq x ) Z=\frac{34-30}{4} = 0.5,"['statistics', 'normal-distribution']"
7,UMP test with two distributions derivation,UMP test with two distributions derivation,,"Suppose X has distribution in $\mathcal{P}=\{B(10, \frac{1}{2}), P(1)\}$ (Binomial and Poisson respectively). Let $H_0 := X \stackrel{D}{=} B(10, \frac{1}{2})$ and $H_1 := X \stackrel{D}{=}P(1)$ . Derive an UMP test for $H_0$ with $\alpha = 0.1$ There is also a hint to use tables of Poisson or Binomial distribution. I know $\alpha$ = $\mathbb{P}_0(f_1(x) > cf_0(x)) + \gamma \mathbb{P}_0(f_1(x)=cf_0(x)$ . I calculated $f_1(x) > c f_0(x)$ as $$ \frac{1}{e x!} > c \frac{10!}{(10-x)!x!}2^{-10} \\ \frac{2^{10}}{e} > c 10^{\underline{x}} \\ \frac{2^{10}}{e 10^{\underline{x}}} > c  $$ When I plug that in $$ \alpha = \mathbb{P}_0(f_1(x) > cf_0(x)) + \gamma \mathbb{P}_0(f_1(x)=cf_0(x)  = \\ =  \mathbb{P}_0(\frac{2^{10}}{e 10^{\underline{x}}} > c) + \gamma \mathbb{P}_0(\frac{2^{10}}{e 10^{\underline{x}}} = c) $$ Here I got stuck. I know that I need to assume the $H_0$ is true so $X \stackrel{D}{=} B(10, \frac{1}{2})$ but I have $10^{\underline{X}}$ here. Surely I must be missing something. I usually used CLT here but I have no idea how to do it here. Thank you for any insights.",Suppose X has distribution in (Binomial and Poisson respectively). Let and . Derive an UMP test for with There is also a hint to use tables of Poisson or Binomial distribution. I know = . I calculated as When I plug that in Here I got stuck. I know that I need to assume the is true so but I have here. Surely I must be missing something. I usually used CLT here but I have no idea how to do it here. Thank you for any insights.,"\mathcal{P}=\{B(10, \frac{1}{2}), P(1)\} H_0 := X \stackrel{D}{=} B(10, \frac{1}{2}) H_1 := X \stackrel{D}{=}P(1) H_0 \alpha = 0.1 \alpha \mathbb{P}_0(f_1(x) > cf_0(x)) + \gamma \mathbb{P}_0(f_1(x)=cf_0(x) f_1(x) > c f_0(x) 
\frac{1}{e x!} > c \frac{10!}{(10-x)!x!}2^{-10} \\
\frac{2^{10}}{e} > c 10^{\underline{x}} \\
\frac{2^{10}}{e 10^{\underline{x}}} > c 
 
\alpha = \mathbb{P}_0(f_1(x) > cf_0(x)) + \gamma \mathbb{P}_0(f_1(x)=cf_0(x)  = \\
=  \mathbb{P}_0(\frac{2^{10}}{e 10^{\underline{x}}} > c) + \gamma \mathbb{P}_0(\frac{2^{10}}{e 10^{\underline{x}}} = c)
 H_0 X \stackrel{D}{=} B(10, \frac{1}{2}) 10^{\underline{X}}","['probability', 'statistics', 'hypothesis-testing']"
8,Proving pivotal quantity has given form and using it to get the confidence interval,Proving pivotal quantity has given form and using it to get the confidence interval,,"This is a homework which I don't know how to solve. All other examples of pivotal quantities examples I've tackled were relatively easy, this one though seems hard. Suppose $\rm{X}=(X_1, \dots, X_m)$ and $\rm{Y}=(Y_1, \dots, Y_n)$ are samples from $N(\mu_1, \sigma_1^2)$ and $N(\mu_2, \sigma_2^2)$ respectively. Let $\sigma = \sigma_1^2 = \sigma_2^2$ , $\theta = (\mu_1, \mu_2, \sigma)$ and $g(\theta) = \mu_2 - \mu_1$ . Prove that pivotal quantity of $g(\theta)$ has the form of $$ \frac{\overline{Y}-\overline{X}-g(\theta)}{\sqrt{\frac{(m-1)S_X^2+(n-1)S_Y^2}{n+m-2}}\sqrt{\frac{1}{m}+\frac{1}{n}}} $$ where as usual $S_X^2 = \frac{\sum_1^mX_i-\overline{X_i}}{m-1}$ , $\overline{X} = \frac{\sum_i^nX_i}{m}$ . Use the pivotal quantity to approximate confidence interval of $g(\theta)$ with confidence $1 - \alpha$ . I've got a couple of hints from my professor: for $Z \sim N(0,1)$ and $Y \sim \chi^2_n$ we know $X = \frac{Z}{\sqrt{Y/n}}$ has t-Student distribution with n d.o.f. for $X_i \sim N(0,1)$ we have $\sqrt n (\overline X - \mu)/\sigma \sim N(0,1)$ and $(n-1)S^2/\sigma^2 \sim \chi^2_{n-1}$ I tried playing with the equations but that led me nowhere. I assume I should somehow find the forms shown in the second hint and then move on to the first one. Any help greatly appreciated.","This is a homework which I don't know how to solve. All other examples of pivotal quantities examples I've tackled were relatively easy, this one though seems hard. Suppose and are samples from and respectively. Let , and . Prove that pivotal quantity of has the form of where as usual , . Use the pivotal quantity to approximate confidence interval of with confidence . I've got a couple of hints from my professor: for and we know has t-Student distribution with n d.o.f. for we have and I tried playing with the equations but that led me nowhere. I assume I should somehow find the forms shown in the second hint and then move on to the first one. Any help greatly appreciated.","\rm{X}=(X_1, \dots, X_m) \rm{Y}=(Y_1, \dots, Y_n) N(\mu_1, \sigma_1^2) N(\mu_2, \sigma_2^2) \sigma = \sigma_1^2 = \sigma_2^2 \theta = (\mu_1, \mu_2, \sigma) g(\theta) = \mu_2 - \mu_1 g(\theta) 
\frac{\overline{Y}-\overline{X}-g(\theta)}{\sqrt{\frac{(m-1)S_X^2+(n-1)S_Y^2}{n+m-2}}\sqrt{\frac{1}{m}+\frac{1}{n}}}
 S_X^2 = \frac{\sum_1^mX_i-\overline{X_i}}{m-1} \overline{X} = \frac{\sum_i^nX_i}{m} g(\theta) 1 - \alpha Z \sim N(0,1) Y \sim \chi^2_n X = \frac{Z}{\sqrt{Y/n}} X_i \sim N(0,1) \sqrt n (\overline X - \mu)/\sigma \sim N(0,1) (n-1)S^2/\sigma^2 \sim \chi^2_{n-1}","['probability', 'statistics', 'normal-distribution']"
9,A changing probability relating to primes,A changing probability relating to primes,,"The probability that a process succeeds at step $t$ is $$\left( \prod_{k=1}^{t-1}{ 1-\text{Prime}(p+k)^{-1/c} } \right)(\text{Prime}(p+t))^{-1/c}$$ Here $p$ , $t$ and $c$ are naturals, and $\text{Prime}(x)$ is simply the $x$ th prime. How many steps, on average, does the proccess take until it succeeds, for a given $p$ and $c$ ? MY ATTEMPTS The first thing I tried was to try to convert the prime in the function to a power of $x$ , hoping that I could test it in my math software and get close to the same asymptotics: $$\prod_{k=1}^{t-1}{ \left(1-(\text{Prime}(p)^{d \cdot k})^{-1/c} \right) }\text{Prime}(p+t)$$ The idea was to approximate $\text{Prime}(p+k)$ with $x^{d \cdot  k}$ for $d \approx 1$ , say $d=1.1$ .  But by my calculations, this wasn't exacting enough.  Perhaps I have to rethink $d$ . That was probably my best attempt so far.  I'm still thinking that maybe we can approximate the prime values with a power of $x$ , or some suitable function.  I'm not sure what else to try.  I feel like I'm way off here. Anyways, the idea seems to be to get the product equal to around $1/2$ , which would be an average number of steps or trials.","The probability that a process succeeds at step is Here , and are naturals, and is simply the th prime. How many steps, on average, does the proccess take until it succeeds, for a given and ? MY ATTEMPTS The first thing I tried was to try to convert the prime in the function to a power of , hoping that I could test it in my math software and get close to the same asymptotics: The idea was to approximate with for , say .  But by my calculations, this wasn't exacting enough.  Perhaps I have to rethink . That was probably my best attempt so far.  I'm still thinking that maybe we can approximate the prime values with a power of , or some suitable function.  I'm not sure what else to try.  I feel like I'm way off here. Anyways, the idea seems to be to get the product equal to around , which would be an average number of steps or trials.",t \left( \prod_{k=1}^{t-1}{ 1-\text{Prime}(p+k)^{-1/c} } \right)(\text{Prime}(p+t))^{-1/c} p t c \text{Prime}(x) x p c x \prod_{k=1}^{t-1}{ \left(1-(\text{Prime}(p)^{d \cdot k})^{-1/c} \right) }\text{Prime}(p+t) \text{Prime}(p+k) x^{d \cdot  k} d \approx 1 d=1.1 d x 1/2,"['probability', 'statistics', 'prime-numbers']"
10,What measure of distance does the harmonic mean minimize?,What measure of distance does the harmonic mean minimize?,,The arithmetic mean of a set of numbers minimizes the squared error. The geometric mean minimizes the squared log difference $\left[\log(x)-\log(\overline{x})\right]^2.$ The median minimizes the mean absolute error.  What does the harmonic mean minimize?,The arithmetic mean of a set of numbers minimizes the squared error. The geometric mean minimizes the squared log difference The median minimizes the mean absolute error.  What does the harmonic mean minimize?,\left[\log(x)-\log(\overline{x})\right]^2.,['statistics']
11,Overall equal probabilities when replacing choices,Overall equal probabilities when replacing choices,,"Explanation: I want to choose marbles from a bag x times. Once chosen, the marbles are not put back in the bag. After each choice, some number of new marbles are added to the bag. x is less than the total number of marbles, i.e. not all marbles will be chosen. My goal is to make it so every marble has an equal chance of being chosen overall (or as close as possible). Example 1 (x = 2): Start with marbles A and B. Choose one at random. Let's say B was chosen. Now marble C is added to the bag and the second marble is chosen. A has already had a 50% chance of being chosen, so giving A and C the same odds would mean A was more likely than C. Is there any weighting possible to make it such that A, B, and C were all equally likely in the beginning? I assume it is not possible because C was not available in the beginning. I believe the next best thing would be to make it so A and C were equally likely from the beginning. My guess is that this can be done by making C twice as likely as A for the second draw (A should have 1/3 chance and C should have 2/3 chance). However, I am not sure how to prove it. Example 2 (x = 3): Start with marbles A and B. Again let's say B is chosen. Now Marbles C and D are added and a second is chosen. Again, I want to say C and D should be twice as likely as A. Assuming I was correct before, A should have a 1/5 chance and C and D should both have a 2/5 chance. Let's say C was chosen. Now marbles E and F are added and so the odds of each marble for the third draw should be 0.0909 for A, 0.1818 for C, 0.3636 for E and 0.3636 for F. Is this correct? How can it be shown mathematically? Does my general approach of marbles added after the last draw being twice as likely as the marbles in the draw before that which are twice as likely as the marbles in the draw before that... work?","Explanation: I want to choose marbles from a bag x times. Once chosen, the marbles are not put back in the bag. After each choice, some number of new marbles are added to the bag. x is less than the total number of marbles, i.e. not all marbles will be chosen. My goal is to make it so every marble has an equal chance of being chosen overall (or as close as possible). Example 1 (x = 2): Start with marbles A and B. Choose one at random. Let's say B was chosen. Now marble C is added to the bag and the second marble is chosen. A has already had a 50% chance of being chosen, so giving A and C the same odds would mean A was more likely than C. Is there any weighting possible to make it such that A, B, and C were all equally likely in the beginning? I assume it is not possible because C was not available in the beginning. I believe the next best thing would be to make it so A and C were equally likely from the beginning. My guess is that this can be done by making C twice as likely as A for the second draw (A should have 1/3 chance and C should have 2/3 chance). However, I am not sure how to prove it. Example 2 (x = 3): Start with marbles A and B. Again let's say B is chosen. Now Marbles C and D are added and a second is chosen. Again, I want to say C and D should be twice as likely as A. Assuming I was correct before, A should have a 1/5 chance and C and D should both have a 2/5 chance. Let's say C was chosen. Now marbles E and F are added and so the odds of each marble for the third draw should be 0.0909 for A, 0.1818 for C, 0.3636 for E and 0.3636 for F. Is this correct? How can it be shown mathematically? Does my general approach of marbles added after the last draw being twice as likely as the marbles in the draw before that which are twice as likely as the marbles in the draw before that... work?",,"['probability', 'statistics']"
12,Statistical test for boolean value groups,Statistical test for boolean value groups,,"Intro This question is somewhat of a prequel to this one - but can be seen also as a standalone! I have two distinct populations/measurements of boolean values: $\{x_i\}_{i=1}^{m_1},x_i \in \{0,1\},|x|=m_1$ and $\{y_i\}_{i=1}^{m_2},y_i\in\{0,1\},|y|=m_2$ . Each $x_i$ (and $y_i$ ) is independent of the other boolean values. These numbers represent activity values ( $1$ = active , $0$ = inactive ) of two different group of models, namely the good ones ( $x$ 's) and the bad ones ( $y$ 's). I wanted to find a measurement of how much the (mean) activity of the good models is different than the bad models' activity . So, I started with the average values $a_1=mean(x)$ and $a_2=mean(y)$ and took the difference: $d=a_1-a_2$ . Then I wanted to include a penalty related to the amount of models $m_1,m_2$ and this was solved in this question by introducing a proper scaling function for the difference $d$ . The problem I was considering that if I had two populations of continuous measurements, then I would probably do a Wilcoxon Rank Sum test (use wilcox.test in R for example) and get also a p-value + location parameter shift estimation (a kind of $d$ as is in the respective implementation) for this (for the boolean case, ranking methods are useless right?). So, the p-value would tell how sure I am about this difference - which is kind of what I wanted to solve numerically (by let's say inserting the uncertainty in the final formula) in this other question . All in all, I need a statistical test that would compare boolean values and get me as a result a p-value and the d difference (or similar) so to speak. What I tried So, since I work with two different and independent set of boolean values $\{x_i\}$ and $\{y_i\}$ the words binomial distribution and bionomial test came into my mind (from loooong ago :) But after reading about them for a while and playing with the respective R functions, it turned out not I wanted this to be. The most significant problem for me was that I do not know the probability of success , i.e. $p=P(x_i=1)$ (or $y_i$ for that matter) - actually that's what I want to know for each model category! I tried to use the average $a_1=mean(x)=p$ and then to take a value of the cumulative distribution but it does not give results representative to what I want (the average activity). And the binomial test does not come close to what I want either. For example: $x=\{0,0,0,0,1,0\}, m_1=n=6,p=1/6=0.1667$ and then I would calculate the $P(X\geq 1)=0.665$ , which is way higher than expected. Maybe I am overthinking it, but I believe there should be something close to what I want to do with this boolean dataset that I have. Any directions for distribution(s) or statistical tests that can accommodate my case are welcome! Also posted on Cross Validated .","Intro This question is somewhat of a prequel to this one - but can be seen also as a standalone! I have two distinct populations/measurements of boolean values: and . Each (and ) is independent of the other boolean values. These numbers represent activity values ( = active , = inactive ) of two different group of models, namely the good ones ( 's) and the bad ones ( 's). I wanted to find a measurement of how much the (mean) activity of the good models is different than the bad models' activity . So, I started with the average values and and took the difference: . Then I wanted to include a penalty related to the amount of models and this was solved in this question by introducing a proper scaling function for the difference . The problem I was considering that if I had two populations of continuous measurements, then I would probably do a Wilcoxon Rank Sum test (use wilcox.test in R for example) and get also a p-value + location parameter shift estimation (a kind of as is in the respective implementation) for this (for the boolean case, ranking methods are useless right?). So, the p-value would tell how sure I am about this difference - which is kind of what I wanted to solve numerically (by let's say inserting the uncertainty in the final formula) in this other question . All in all, I need a statistical test that would compare boolean values and get me as a result a p-value and the d difference (or similar) so to speak. What I tried So, since I work with two different and independent set of boolean values and the words binomial distribution and bionomial test came into my mind (from loooong ago :) But after reading about them for a while and playing with the respective R functions, it turned out not I wanted this to be. The most significant problem for me was that I do not know the probability of success , i.e. (or for that matter) - actually that's what I want to know for each model category! I tried to use the average and then to take a value of the cumulative distribution but it does not give results representative to what I want (the average activity). And the binomial test does not come close to what I want either. For example: and then I would calculate the , which is way higher than expected. Maybe I am overthinking it, but I believe there should be something close to what I want to do with this boolean dataset that I have. Any directions for distribution(s) or statistical tests that can accommodate my case are welcome! Also posted on Cross Validated .","\{x_i\}_{i=1}^{m_1},x_i \in \{0,1\},|x|=m_1 \{y_i\}_{i=1}^{m_2},y_i\in\{0,1\},|y|=m_2 x_i y_i 1 0 x y a_1=mean(x) a_2=mean(y) d=a_1-a_2 m_1,m_2 d d \{x_i\} \{y_i\} p=P(x_i=1) y_i a_1=mean(x)=p x=\{0,0,0,0,1,0\}, m_1=n=6,p=1/6=0.1667 P(X\geq 1)=0.665","['statistics', 'boolean-algebra', 'binomial-distribution', 'hypothesis-testing']"
13,Sum of indicators and application of Jensen's inequality,Sum of indicators and application of Jensen's inequality,,"So I have stumbled upon this problem.  Let $X_1, \dots, X_n \sim N(\mu, \sigma^2)$ be iid. Define: $$S  = \frac{1}{n}\sum_{i=1}^n I[X_i > a]$$ $$T = I[\frac{1}{n}\sum_{i=1}^n X_i > a]$$ $a > 0$ . Using Jensen's Inequality prove: $$E(S) > E(T)$$ Now I only manage to prove it by solving the expected values without Jensen's Inequality. Where I get: $$E(S) = 1 - \Phi\left(\frac{a-\mu}{\sigma}\right)$$ And $$E(T) = 1 - \Phi\left(\frac{a-\mu}{\sigma}\sqrt n\right)$$ Which proves the inequality. Where $\Phi$ is the standard normal cdf.  However this is just by using $E(f(X)) = \int_{-\infty}^{\infty} f(x)p(x) dx$ . $p(x)$ is the pdf of $X$ . I struggle seeing why one can apply Jensen on $I(X > a)$ as it is non-convex. Edit: After some thinking I do not belive this is possible, but feel free to prove me wrong.","So I have stumbled upon this problem.  Let be iid. Define: . Using Jensen's Inequality prove: Now I only manage to prove it by solving the expected values without Jensen's Inequality. Where I get: And Which proves the inequality. Where is the standard normal cdf.  However this is just by using . is the pdf of . I struggle seeing why one can apply Jensen on as it is non-convex. Edit: After some thinking I do not belive this is possible, but feel free to prove me wrong.","X_1, \dots, X_n \sim N(\mu, \sigma^2) S  = \frac{1}{n}\sum_{i=1}^n I[X_i > a] T = I[\frac{1}{n}\sum_{i=1}^n X_i > a] a > 0 E(S) > E(T) E(S) = 1 - \Phi\left(\frac{a-\mu}{\sigma}\right) E(T) = 1 - \Phi\left(\frac{a-\mu}{\sigma}\sqrt n\right) \Phi E(f(X)) = \int_{-\infty}^{\infty} f(x)p(x) dx p(x) X I(X > a)","['probability', 'statistics', 'statistical-inference', 'jensen-inequality']"
14,Multivariate normal probability of being inside ellipse,Multivariate normal probability of being inside ellipse,,"Assume that $\mathbf{X}$ is a bivariate normal random variable $$\mathbf{\mu} = E\mathbf{X} = \begin{bmatrix} 0 \\ 2 \end{bmatrix} \  \text{and} \ \Sigma = Cov \ \mathbf{X} = \begin{bmatrix} 3 & 1 \\ 1 & 3 \end{bmatrix} $$ What is the probability that $\mathbf{X}$ falls within the elipse corresponding to $(\mathbf{x} - \mathbf{\mu})^T \Sigma^{-1}(\mathbf{x} - \mathbf{\mu}) = 4.6 ?$ So Im assuming I need to calculate the probability of $x_1$ lying between $x_1$ min and $x_1$ max, and likewise for $x_2$ ? However Im not sure how to do this calculation seeing as the variables $x_1$ and $x_2$ are not independent. It also seems like the endpoints of the ellipse do not match my calculations. I believe the ellipse should have half axe lengths $\sqrt{\lambda_i b}$ and its centered at $\mathbf{\mu}$ . So according to my calculations $x_1$ should lie between -4.28 and +4.28 which seems incorrect from graphical inspection.","Assume that is a bivariate normal random variable What is the probability that falls within the elipse corresponding to So Im assuming I need to calculate the probability of lying between min and max, and likewise for ? However Im not sure how to do this calculation seeing as the variables and are not independent. It also seems like the endpoints of the ellipse do not match my calculations. I believe the ellipse should have half axe lengths and its centered at . So according to my calculations should lie between -4.28 and +4.28 which seems incorrect from graphical inspection.",\mathbf{X} \mathbf{\mu} = E\mathbf{X} = \begin{bmatrix} 0 \\ 2 \end{bmatrix} \  \text{and} \ \Sigma = Cov \ \mathbf{X} = \begin{bmatrix} 3 & 1 \\ 1 & 3 \end{bmatrix}  \mathbf{X} (\mathbf{x} - \mathbf{\mu})^T \Sigma^{-1}(\mathbf{x} - \mathbf{\mu}) = 4.6 ? x_1 x_1 x_1 x_2 x_1 x_2 \sqrt{\lambda_i b} \mathbf{\mu} x_1,"['probability', 'geometry', 'statistics', 'normal-distribution', 'conic-sections']"
15,"Maximize $\sum_{i=1}^n\ln\left(\frac{2x_i}{\theta}\mathbf{1}_{[0,\theta)}(x_i)+\frac{2(1-x_i)}{1-\theta}\mathbf{1}_{[\theta,1]}(x_i)\right)$",Maximize,"\sum_{i=1}^n\ln\left(\frac{2x_i}{\theta}\mathbf{1}_{[0,\theta)}(x_i)+\frac{2(1-x_i)}{1-\theta}\mathbf{1}_{[\theta,1]}(x_i)\right)","I'm trying to solve the following problem: Consider a sample of $n$ i.i.d observations drawn from a distribution characterized by the density function $$f_{\theta}(x)= \begin{cases}{\frac{2 x}{\theta}} & {\text { if } x \in [0, \theta)} \\ {\frac{2(1-x)}{1-\theta}} & {\text { if } x \in[\theta, 1]} \\ {0} & {\text { otherwise }}\end{cases}$$ where the parameter $\theta \in (0,1)$ . Find the maximum likelihood estimator of $\theta$ . My attempt: Let $X=(X_1, \ldots, X_n)$ . Then the log-likelihood function is $$l(\theta;x) = \sum_{i=1}^n \ln \left ( \frac{2 x_i}{\theta} \mathbf{1}_{[0, \theta)} (x_i) + \frac{2(1- x_i)}{1-\theta} \mathbf{1}_{[\theta,1]} (x_i) \right)$$ Let $(X_{(1)}, \ldots, X_{(n)})$ be the order statistics. Then $$l(\theta;x) = \sum_{i=1}^n \ln \left ( \frac{2 x_{(i)}}{\theta} \mathbf{1}_{[0, \theta)} (x_{(i)}) + \frac{2(1- x_{(i)})}{1-\theta} \mathbf{1}_{[\theta,1]} (x_{(i)}) \right)$$ $\textbf{Case 1:}$ $\theta \in [0, x_{(1)}]$ $$l(\theta;x) = \sum_{i=1}^n \ln \left ( \frac{2(1- x_{(i)})}{1-\theta}  \right) = n \ln 2 + \sum_{i=1}^n \ln (1- x_{(i)}) - n \ln (1-\theta)$$ It follows that $$\underset{\theta \in [0, x_{(1)}]}{\text{arg max}} \,\, l(\theta;x) = x_{(1)} \quad \text{and} \quad \max_{\theta \in [0, x_{(1)}]} l(\theta;x) = n \ln 2 + \sum_{i=1}^n \ln (1- x_{(i)}) - n \ln (1-x_{(1)})$$ $\textbf{Case 2:}$ $\theta \in [x_{(k)}, x_{(k+1)}]$ $$\begin{aligned} l(\theta;x) &= \sum_{i=1}^k \ln \left ( \frac{2 x_{(i)}}{\theta} \right) + \sum_{i=k+1}^n \left (\frac{2(1- x_{(i)})}{1-\theta} \right) \\ &= n \ln2+ \sum_{i=1}^k \ln(x_{(i)} ) + \sum_{i=k+1}^n \ln( 1-x_{(i)} ) -k \ln \theta - (n-k) \ln (1 - \theta)\end{aligned}$$ $\textbf{Case 3:}$ $\theta \in [x_{(n)}, 1]$ $$l(\theta;x) = \sum_{i=1}^n \ln \left ( \frac{2x_{(i)}}{\theta}  \right) = n \ln 2 + \sum_{i=1}^n \ln (x_{(i)}) - n \ln (\theta)$$ It follows that $$\underset{\theta \in [x_{(n)},1]}{\text{arg max}} \,\,  l(\theta;x) = x_{(n)} \quad \text{and} \quad \max_{\theta \in [x_{(n)}, 1]} l(\theta;x) = n \ln 2 + \sum_{i=1}^n \ln (x_{(i)}) - n \ln (x_{(n)})$$ My question: In case 2 , the critical point is $\theta' = k/n$ . But I don't know if $k/n \in [x_{(k)}, x_{(k+1)}]$ . Hence I'm unable to find the maximizer in this case. Even if I found it, I'm still unable to compare the values of $l(\theta';x)$ between 3 cases. How can I proceed to find $$\underset{\theta \in [0, 1]}{\operatorname{arg max}} l(\theta;x) \text{ ?}$$ Thank you so much!","I'm trying to solve the following problem: Consider a sample of i.i.d observations drawn from a distribution characterized by the density function where the parameter . Find the maximum likelihood estimator of . My attempt: Let . Then the log-likelihood function is Let be the order statistics. Then It follows that It follows that My question: In case 2 , the critical point is . But I don't know if . Hence I'm unable to find the maximizer in this case. Even if I found it, I'm still unable to compare the values of between 3 cases. How can I proceed to find Thank you so much!","n f_{\theta}(x)= \begin{cases}{\frac{2 x}{\theta}} & {\text { if } x \in [0, \theta)} \\ {\frac{2(1-x)}{1-\theta}} & {\text { if } x \in[\theta, 1]} \\ {0} & {\text { otherwise }}\end{cases} \theta \in (0,1) \theta X=(X_1, \ldots, X_n) l(\theta;x) = \sum_{i=1}^n \ln \left ( \frac{2 x_i}{\theta} \mathbf{1}_{[0, \theta)} (x_i) + \frac{2(1- x_i)}{1-\theta} \mathbf{1}_{[\theta,1]} (x_i) \right) (X_{(1)}, \ldots, X_{(n)}) l(\theta;x) = \sum_{i=1}^n \ln \left ( \frac{2 x_{(i)}}{\theta} \mathbf{1}_{[0, \theta)} (x_{(i)}) + \frac{2(1- x_{(i)})}{1-\theta} \mathbf{1}_{[\theta,1]} (x_{(i)}) \right) \textbf{Case 1:} \theta \in [0, x_{(1)}] l(\theta;x) = \sum_{i=1}^n \ln \left ( \frac{2(1- x_{(i)})}{1-\theta}  \right) = n \ln 2 + \sum_{i=1}^n \ln (1- x_{(i)}) - n \ln (1-\theta) \underset{\theta \in [0, x_{(1)}]}{\text{arg max}} \,\, l(\theta;x) = x_{(1)} \quad \text{and} \quad \max_{\theta \in [0, x_{(1)}]} l(\theta;x) = n \ln 2 + \sum_{i=1}^n \ln (1- x_{(i)}) - n \ln (1-x_{(1)}) \textbf{Case 2:} \theta \in [x_{(k)}, x_{(k+1)}] \begin{aligned} l(\theta;x) &= \sum_{i=1}^k \ln \left ( \frac{2 x_{(i)}}{\theta} \right) + \sum_{i=k+1}^n \left (\frac{2(1- x_{(i)})}{1-\theta} \right) \\ &= n \ln2+ \sum_{i=1}^k \ln(x_{(i)} ) + \sum_{i=k+1}^n \ln( 1-x_{(i)} ) -k \ln \theta - (n-k) \ln (1 - \theta)\end{aligned} \textbf{Case 3:} \theta \in [x_{(n)}, 1] l(\theta;x) = \sum_{i=1}^n \ln \left ( \frac{2x_{(i)}}{\theta}  \right) = n \ln 2 + \sum_{i=1}^n \ln (x_{(i)}) - n \ln (\theta) \underset{\theta \in [x_{(n)},1]}{\text{arg max}} \,\,  l(\theta;x) = x_{(n)} \quad \text{and} \quad \max_{\theta \in [x_{(n)}, 1]} l(\theta;x) = n \ln 2 + \sum_{i=1}^n \ln (x_{(i)}) - n \ln (x_{(n)}) \theta' = k/n k/n \in [x_{(k)}, x_{(k+1)}] l(\theta';x) \underset{\theta \in [0, 1]}{\operatorname{arg max}} l(\theta;x) \text{ ?}","['real-analysis', 'statistics', 'optimization', 'maximum-likelihood', 'order-statistics']"
16,Computation of the estimator of the ELBO in Variational Auto-encoder,Computation of the estimator of the ELBO in Variational Auto-encoder,,"I am reading the paper below by Kingma et.al. https://arxiv.org/pdf/1906.02691.pdf Section 2.4.4 which is titled as ""Computation of $\log q_{\phi}(z|x)$ "": In Eqn. (2.33) the authors explain a relation between the densities of $\epsilon$ and $z$ as follows: \begin{equation} \log q_{\phi}(z|x) = \log p(\epsilon) − \log d_{\phi}(x, \epsilon) \end{equation} How is the second term of the RHS derived? Let me explain my question with more details. Applying Bayes rule and joint probability definition on $\log q_{\phi}(z|x)$ implies $\log \frac{q_{\phi}(z, x)}{q_{\phi}(x)} = \log \frac{q_{\phi}(x|z) q_{\phi}(z)}{q_{\phi}(x)}$ applying log yields $\log q_{\phi}(z|x) = \log q_{\phi}(x|z) + \log q_{\phi}(z) - \log q_{\phi}(x)$ Replacing $\log q_{\phi}(z)$ with $\log p(\epsilon)$ (because of reparametriztion) and rearranging leads to $\log q_{\phi}(z|x) = \log p(\epsilon) + \log q_{\phi}(x|z) - \log q_{\phi}(x)$ However, Eqn. 2.33 in the paper is: $\log q_{\phi}(z|x) = \log p(\epsilon) - \log d_{\phi}(x, \epsilon)$ . I know this is a variable change but I have two questions: 1)  Am I right with what I explained above? 2) I can't understand the sentence which is mentioned after it. That is, ""where the second term is the log of the absolute value of the determinant of the Jacobian matrix $(∂z/∂\epsilon)$ ""","I am reading the paper below by Kingma et.al. https://arxiv.org/pdf/1906.02691.pdf Section 2.4.4 which is titled as ""Computation of "": In Eqn. (2.33) the authors explain a relation between the densities of and as follows: How is the second term of the RHS derived? Let me explain my question with more details. Applying Bayes rule and joint probability definition on implies applying log yields Replacing with (because of reparametriztion) and rearranging leads to However, Eqn. 2.33 in the paper is: . I know this is a variable change but I have two questions: 1)  Am I right with what I explained above? 2) I can't understand the sentence which is mentioned after it. That is, ""where the second term is the log of the absolute value of the determinant of the Jacobian matrix ""","\log q_{\phi}(z|x) \epsilon z \begin{equation}
\log q_{\phi}(z|x) = \log p(\epsilon) − \log d_{\phi}(x, \epsilon)
\end{equation} \log q_{\phi}(z|x) \log \frac{q_{\phi}(z, x)}{q_{\phi}(x)} = \log \frac{q_{\phi}(x|z) q_{\phi}(z)}{q_{\phi}(x)} \log q_{\phi}(z|x) = \log q_{\phi}(x|z) + \log q_{\phi}(z) - \log q_{\phi}(x) \log q_{\phi}(z) \log p(\epsilon) \log q_{\phi}(z|x) = \log p(\epsilon) + \log q_{\phi}(x|z) - \log q_{\phi}(x) \log q_{\phi}(z|x) = \log p(\epsilon) - \log d_{\phi}(x, \epsilon) (∂z/∂\epsilon)","['statistics', 'statistical-inference', 'machine-learning']"
17,Identifying correlation coefficients for each graph,Identifying correlation coefficients for each graph,,"The figure below has six scatter diagrams for hypothetical data.   The  correlation coefficients are given alongside the figure. While the solution is given, someone can ""easily"" identify them by first by checking if they are negative or positive. then, by how the dots are spread. Since I am thinking if there is a better way since I can't identify them without looking at the solution. Wonder if anyone can give a hand, how they would approach them in a more systematical way.","The figure below has six scatter diagrams for hypothetical data.   The  correlation coefficients are given alongside the figure. While the solution is given, someone can ""easily"" identify them by first by checking if they are negative or positive. then, by how the dots are spread. Since I am thinking if there is a better way since I can't identify them without looking at the solution. Wonder if anyone can give a hand, how they would approach them in a more systematical way.",,"['statistics', 'covariance', 'correlation']"
18,Frequency of looped chains in an array of random integers,Frequency of looped chains in an array of random integers,,"Take an array of y random integers in the inclusive range 0 to 99, each integer written in the form ab, where a is the first digit in the integer and b the second. For example, integer 9 is written as 09 for this purpose, a=0 and b=9. Two of the array members a(1)b(1) and a(2)b(2) and are linkable if a(1)=b(2), or b(1)=a(2). Let us create a looped chain of linkable array members of length x. An example of a looped chain of length 4 is 09,95,57,70.  70 links back to 09. Additional rules: (i) in the random generation of array members, repeated integers have a separate member identity in the array (ii) array members are permitted to be members of multiple looped chains, but only to appear once in each chain Then: (I) For the defined array, what is the probability that there exists one or more looped chain(s) of length x, with x < y? (II) Is there a method to generate, or a formula for generating, estimates of how many different possible chains of length x exist within an array of length y? (III) Is there a formula/ method to generalise this in any number base?","Take an array of y random integers in the inclusive range 0 to 99, each integer written in the form ab, where a is the first digit in the integer and b the second. For example, integer 9 is written as 09 for this purpose, a=0 and b=9. Two of the array members a(1)b(1) and a(2)b(2) and are linkable if a(1)=b(2), or b(1)=a(2). Let us create a looped chain of linkable array members of length x. An example of a looped chain of length 4 is 09,95,57,70.  70 links back to 09. Additional rules: (i) in the random generation of array members, repeated integers have a separate member identity in the array (ii) array members are permitted to be members of multiple looped chains, but only to appear once in each chain Then: (I) For the defined array, what is the probability that there exists one or more looped chain(s) of length x, with x < y? (II) Is there a method to generate, or a formula for generating, estimates of how many different possible chains of length x exist within an array of length y? (III) Is there a formula/ method to generalise this in any number base?",,"['probability', 'statistics', 'integers']"
19,Hypothesis testing: carrying capacity of bridges,Hypothesis testing: carrying capacity of bridges,,"A manufacturer claims that, at the moment of stockage, the carrying   capacity (CC) of the produced bridges follows a normal distribution   with $\mu = 2500\, kg$ and $\sigma^2=150^2\, kg^2$ . Moreover the CC of   the different bridges are independent. The CC of the bridges decreases   as time goes by, so after 2 years the manufacturer has to decide   whether to get rid of the bridges or not (independence, normality and   variance are assumed to be preserved!). How many bridges do we have to test such that if the average CC is $2500\, kg$ , then this can be claimed with a certainty of $95\%$ . if the average CC decreases by $150\, kg$ , then it is possible to detect this decrement with a probability of $90\%$ . My attempt: We set $H_0: \mu = 2500$ and $H_A: \mu < 2500$ . Suppose that $\bar{X}$ denotes the average CC of bridges in a sample of size $n$ . Then it is clear that $\bar{X} = N(2500,150^2/n)$ under $H_0$ , where $n$ is the unknown we're solving for. The first bullet points assumes that we're working under the assumption that $H_0$ is true. The second one states that $\bar{X} = N(2350,150^2/n)$ . I feel like I'll have a system of two equations to solve for $n$ . I just don't know how the express 'being able to detect with a probability of $\alpha\%$ ' mathematically. I feel like confidence intervals are an option. For the first one, we have that the sample average will lie in $$[2500-1,96\cdot \frac{150}{\sqrt n}, 2500+1,96\cdot \frac{150}{\sqrt n}].$$ And then we can do the same for the second bullet point. But how do I find $n$ from these intervals? Thanks.","A manufacturer claims that, at the moment of stockage, the carrying   capacity (CC) of the produced bridges follows a normal distribution   with and . Moreover the CC of   the different bridges are independent. The CC of the bridges decreases   as time goes by, so after 2 years the manufacturer has to decide   whether to get rid of the bridges or not (independence, normality and   variance are assumed to be preserved!). How many bridges do we have to test such that if the average CC is , then this can be claimed with a certainty of . if the average CC decreases by , then it is possible to detect this decrement with a probability of . My attempt: We set and . Suppose that denotes the average CC of bridges in a sample of size . Then it is clear that under , where is the unknown we're solving for. The first bullet points assumes that we're working under the assumption that is true. The second one states that . I feel like I'll have a system of two equations to solve for . I just don't know how the express 'being able to detect with a probability of ' mathematically. I feel like confidence intervals are an option. For the first one, we have that the sample average will lie in And then we can do the same for the second bullet point. But how do I find from these intervals? Thanks.","\mu = 2500\, kg \sigma^2=150^2\, kg^2 2500\, kg 95\% 150\, kg 90\% H_0: \mu = 2500 H_A: \mu < 2500 \bar{X} n \bar{X} = N(2500,150^2/n) H_0 n H_0 \bar{X} = N(2350,150^2/n) n \alpha\% [2500-1,96\cdot \frac{150}{\sqrt n}, 2500+1,96\cdot \frac{150}{\sqrt n}]. n","['statistics', 'hypothesis-testing']"
20,Why does the 90th percentile come out to be greater than the greatest number?,Why does the 90th percentile come out to be greater than the greatest number?,,"Why is the 90th percentile of the following numbers 0.193204884? 0.193111065 0.188885706 0.191501273 0.193298704 0.18895934 0.192364606 How can the 90th percentile be greater than the greatest number in the set? I used the formula - =PERCENTILE(R:R,0.9) on excel. [R:R is the excel range which contains the following numbers] However, the 90th perentile of 1,2,3,4,5 comes out to be 4.6 which seems correct.","Why is the 90th percentile of the following numbers 0.193204884? 0.193111065 0.188885706 0.191501273 0.193298704 0.18895934 0.192364606 How can the 90th percentile be greater than the greatest number in the set? I used the formula - =PERCENTILE(R:R,0.9) on excel. [R:R is the excel range which contains the following numbers] However, the 90th perentile of 1,2,3,4,5 comes out to be 4.6 which seems correct.",,"['statistics', 'percentile']"
21,Question about time between poisson events,Question about time between poisson events,,"Suppose that we know the count of Aviation accidents in a specific country in a year has a poisson distribution of $\lambda =5$ . Find probability that 4 or more accident happen in a year? Find probability that no consecutive accidents happen in a 6 month interval We start to count accidents at time $T$ . what is the probability that 5th accident happen before 9th month. My problem is with 2nd and 3rd part. For first part we simply have: $P(X = k) = 5^k e^{-5} / k!$ $answer = 1 - P(X=0) - P(X=1) - P(X=2)- P(X=3) = 0.7412$ For the second part I actually don't know what to do. One approach is that we know in 6 month the distribution is a new poisson with $\lambda = 2.5$ maybe no consecutive accident in 6 month means: $P_{new}(X=0) + P_{new}(X=1)$ For the third part, I think we have poisson with $\lambda = 3.75$ and we want to find $P_{new}(X=5) + P_{new}(X = 6) + ... = 1 -P_{new}(X=0) - P_{new}(X=1) - P_{new}(X=2) - P_{new}(X=3) - P_{new}(X=4) $ Is my approaches right? If not, what should I do?","Suppose that we know the count of Aviation accidents in a specific country in a year has a poisson distribution of . Find probability that 4 or more accident happen in a year? Find probability that no consecutive accidents happen in a 6 month interval We start to count accidents at time . what is the probability that 5th accident happen before 9th month. My problem is with 2nd and 3rd part. For first part we simply have: For the second part I actually don't know what to do. One approach is that we know in 6 month the distribution is a new poisson with maybe no consecutive accident in 6 month means: For the third part, I think we have poisson with and we want to find Is my approaches right? If not, what should I do?",\lambda =5 T P(X = k) = 5^k e^{-5} / k! answer = 1 - P(X=0) - P(X=1) - P(X=2)- P(X=3) = 0.7412 \lambda = 2.5 P_{new}(X=0) + P_{new}(X=1) \lambda = 3.75 P_{new}(X=5) + P_{new}(X = 6) + ... = 1 -P_{new}(X=0) - P_{new}(X=1) - P_{new}(X=2) - P_{new}(X=3) - P_{new}(X=4) ,"['probability', 'statistics', 'poisson-distribution', 'poisson-process']"
22,Normal copula vs Fréchet copula,Normal copula vs Fréchet copula,,"I'm trying to understand how to generate $2$ random variables $U_1,U_2$ which are correlated using the above $2$ methods with a rank correlation $P_s = 0.3$ . First I create $2$ random variables $X_1,X_2$ from $U(0,1)$ $Y_1 = X_1$ and $Y_2 = X_1(P_s) + X_2 \sqrt{(1-Ps^2)}$ Now my $U_1$ and $U_2$ are Inverse $(Y_1,Y_2)$ . (by Inverse it is meant inverse of normal distribution) The above believe is from the normal copula. The Fréchet copula is given by $$C(U_1,U_2) = p \,\min(U_1,U_2) + (1-p)\,\, \max (0,U_1+U_2-1)$$ With limited background in mathematics. I'm not quite sure how to do this, I assume I just use my $P_s$ value in place of $p$ but I'm not sure what the min and max term actually means.  Thanks for any help.","I'm trying to understand how to generate random variables which are correlated using the above methods with a rank correlation . First I create random variables from and Now my and are Inverse . (by Inverse it is meant inverse of normal distribution) The above believe is from the normal copula. The Fréchet copula is given by With limited background in mathematics. I'm not quite sure how to do this, I assume I just use my value in place of but I'm not sure what the min and max term actually means.  Thanks for any help.","2 U_1,U_2 2 P_s = 0.3 2 X_1,X_2 U(0,1) Y_1 = X_1 Y_2 = X_1(P_s) + X_2 \sqrt{(1-Ps^2)} U_1 U_2 (Y_1,Y_2) C(U_1,U_2) = p \,\min(U_1,U_2) + (1-p)\,\, \max (0,U_1+U_2-1) P_s p","['statistics', 'random-variables']"
23,Standard error of variance estimation,Standard error of variance estimation,,We know that a mean estimation is the following $\bar{x}=\frac{1}{n}\sum_{n=1}^{N}x_{n}$ and the standard error of the mean estimation is $Var(\bar{x})=\sigma^{2}/n$ . Also the estimation of variance is $s^{2}=\frac{1}{n-1}\sum_{n=1}^{N}(x_{n}-\bar{x})^{2}$ Is there a way to calculate the standard error of variance ?? $Var(s^{2})=\frac{1}{n-1}nVar((x_{n}-\bar{x})^{2})\frac{n}{n-1}Var(x_{n}^{2}+\bar{x}^{2}-2x_{n}\bar{x})$ How we are supposed to handle the term $Var((x_{n}-\bar{x})^{2})$ ? Lastly $Var(x_{n})=\sigma^{2}$ and $\mathbb{E}(x_{n})=\mu$ .,We know that a mean estimation is the following and the standard error of the mean estimation is . Also the estimation of variance is Is there a way to calculate the standard error of variance ?? How we are supposed to handle the term ? Lastly and .,\bar{x}=\frac{1}{n}\sum_{n=1}^{N}x_{n} Var(\bar{x})=\sigma^{2}/n s^{2}=\frac{1}{n-1}\sum_{n=1}^{N}(x_{n}-\bar{x})^{2} Var(s^{2})=\frac{1}{n-1}nVar((x_{n}-\bar{x})^{2})\frac{n}{n-1}Var(x_{n}^{2}+\bar{x}^{2}-2x_{n}\bar{x}) Var((x_{n}-\bar{x})^{2}) Var(x_{n})=\sigma^{2} \mathbb{E}(x_{n})=\mu,"['statistics', 'estimation', 'variance', 'standard-deviation']"
24,Not sure how to answer this statistics question or if I understand what is being asked.,Not sure how to answer this statistics question or if I understand what is being asked.,,"The first question is what I am unsure about.  I don't know if it is asking what is actually unusual (like the grade value having 100 as the mean) about the test or if it is asking something else like what is rare (unusual because of how small the number is) about the p-value. A new standardized test is required to have a µ = 100 and σ = 10. A class of 30 students completed the test with a mean grade of 95.  Conduct a hypothesis test at α = .05 to determine whether the claim that µ = 100 can be supported using the p-value approach and complete the following. What is unusual about this hypothesis test? (All other questions aside from this one seem to be straightforward, am I overthinking this?) State the null and alternative hypotheses in words and in statistical symbols. What statistical test should be used and why? What is the value of the test statistic and the p-value of that outcome? Interpret the outcome in terms of the original claim.","The first question is what I am unsure about.  I don't know if it is asking what is actually unusual (like the grade value having 100 as the mean) about the test or if it is asking something else like what is rare (unusual because of how small the number is) about the p-value. A new standardized test is required to have a µ = 100 and σ = 10. A class of 30 students completed the test with a mean grade of 95.  Conduct a hypothesis test at α = .05 to determine whether the claim that µ = 100 can be supported using the p-value approach and complete the following. What is unusual about this hypothesis test? (All other questions aside from this one seem to be straightforward, am I overthinking this?) State the null and alternative hypotheses in words and in statistical symbols. What statistical test should be used and why? What is the value of the test statistic and the p-value of that outcome? Interpret the outcome in terms of the original claim.",,"['statistics', 'hypothesis-testing']"
25,Computing 95% confidence interval,Computing 95% confidence interval,,"The question: The gas in bubbles within amber should be a sample of the atmosphere at the time the amber was formed. Measurements on specimens of amber 75 million years ago give these percents of nitrogen: 63.4, 65.0, 64.4, 63.3, 54.8, 64.5, 60.8, 49.1, 51.0. Construct a 95% confidence interval for the true average % nitrogen in the atmosphere at this time. My attempt: I used the following formula for confidence intervals from my textbook: ""A 100(1- $\alpha$ )% confidence interval for $\mu$ is $(\bar{X} - t_{n-1, 1-\frac{\alpha}{2}} \frac{S}{\sqrt{n}}, \bar{X} + t_{n-1, 1-\frac{\alpha}{2}} \frac{S}{\sqrt{n}})$ ."" I know $\bar{X}$ is 59.6, and $n$ is 9. But there are 2 things I'm having trouble with: Firstly, in the answers they say that $S$ is 6.25 when I am calculating it to be 5.89. Secondly, I'm having trouble finding $t_{n-1, 1-\frac{\alpha}{2}}$ . According to the solutions, it is 2.31. But I'm not sure where they got that number from, or how to find $t_{n-1, 1-\frac{\alpha}{2}}$ in general? I thought it was supposed to be 1.96 but that's incorrect. Any help is appreciated.","The question: The gas in bubbles within amber should be a sample of the atmosphere at the time the amber was formed. Measurements on specimens of amber 75 million years ago give these percents of nitrogen: 63.4, 65.0, 64.4, 63.3, 54.8, 64.5, 60.8, 49.1, 51.0. Construct a 95% confidence interval for the true average % nitrogen in the atmosphere at this time. My attempt: I used the following formula for confidence intervals from my textbook: ""A 100(1- )% confidence interval for is ."" I know is 59.6, and is 9. But there are 2 things I'm having trouble with: Firstly, in the answers they say that is 6.25 when I am calculating it to be 5.89. Secondly, I'm having trouble finding . According to the solutions, it is 2.31. But I'm not sure where they got that number from, or how to find in general? I thought it was supposed to be 1.96 but that's incorrect. Any help is appreciated.","\alpha \mu (\bar{X} - t_{n-1, 1-\frac{\alpha}{2}} \frac{S}{\sqrt{n}}, \bar{X} + t_{n-1, 1-\frac{\alpha}{2}} \frac{S}{\sqrt{n}}) \bar{X} n S t_{n-1, 1-\frac{\alpha}{2}} t_{n-1, 1-\frac{\alpha}{2}}","['statistics', 'confidence-interval']"
26,What is a bispectrum analysis?,What is a bispectrum analysis?,,I am in the atmospheric sciences and when I read papers on non linear interactions I came up with this term - bispectrum . It is not very clear what a 2nd order cumulant is . So assuming I have wind speed magnitude across a latitude circle as a function of longitude and time I know that I can take a Fourier expansion of the wind speed across the entire globe. So then I can check for wavenumber from that Fourier expansion. I can also check for the temporal frequency of a wave. Then I am lost. Why would I want to take the bispectrum analysis ? So the paper I am reading talks of a cross spectrum analysis . I am not sure what that means but I am presuming if a particular time series has different temporal frequencies and assuming if the energies associated with these temporal frequencies interact with each other will that show up in a bispectrum analysis as explained in the introduction of this article - Introduction to bispectrum ? Here is a paper(not from my field) but from plasma physics that talks of the cross bispectrum . By taking simple use cases can somebody explain what is a bispectrum and from that a cross bispectrum ?,I am in the atmospheric sciences and when I read papers on non linear interactions I came up with this term - bispectrum . It is not very clear what a 2nd order cumulant is . So assuming I have wind speed magnitude across a latitude circle as a function of longitude and time I know that I can take a Fourier expansion of the wind speed across the entire globe. So then I can check for wavenumber from that Fourier expansion. I can also check for the temporal frequency of a wave. Then I am lost. Why would I want to take the bispectrum analysis ? So the paper I am reading talks of a cross spectrum analysis . I am not sure what that means but I am presuming if a particular time series has different temporal frequencies and assuming if the energies associated with these temporal frequencies interact with each other will that show up in a bispectrum analysis as explained in the introduction of this article - Introduction to bispectrum ? Here is a paper(not from my field) but from plasma physics that talks of the cross bispectrum . By taking simple use cases can somebody explain what is a bispectrum and from that a cross bispectrum ?,,"['statistics', 'fourier-analysis']"
27,Prove that two randomized algorithms approach the same expected value,Prove that two randomized algorithms approach the same expected value,,"I am given two randomized algorithms $f$ and $g$ , that take as input a positive integer $m$ and produce a random non-negative integer. The algorithms are the same except that $g$ receives an small ""advantage"" with a very low probability. I need to prove or disprove that as $m$ grows, the two algorithms tend to behave the same. More concretely, if $h(m):=g(m)-f(m)$ , to show or refute that $$\lim_{m\to\infty} E[h(m)] = 0$$ But I'm stuck because the algorithm is a complex stochastic process. What methodologies can be used to formally prove that the hypothesis holds? Attachments : This is the algorithm. Arrays are 0-indexed, randint is inclusive and [0]*m means an array of m zeroes. def algorithm(m, advantage):     h = [0] * m     i = 1     while i < m:         if advantage and randint(0, m-1) == 0:             prev = h[i-1]         else:             prev = h[i-1] - 1         j = randint(0, i-1)         h[i] = max(prev, h[j]+1)         i += 1     return h[m-1]  def f(m): return algorithm(m, advantage=False) def g(m): return algorithm(m, advantage=True) def h(m): return g(m) - f(m) And the plots of some Monte Carlo simulation plots, which show that the hypothesis might hold:","I am given two randomized algorithms and , that take as input a positive integer and produce a random non-negative integer. The algorithms are the same except that receives an small ""advantage"" with a very low probability. I need to prove or disprove that as grows, the two algorithms tend to behave the same. More concretely, if , to show or refute that But I'm stuck because the algorithm is a complex stochastic process. What methodologies can be used to formally prove that the hypothesis holds? Attachments : This is the algorithm. Arrays are 0-indexed, randint is inclusive and [0]*m means an array of m zeroes. def algorithm(m, advantage):     h = [0] * m     i = 1     while i < m:         if advantage and randint(0, m-1) == 0:             prev = h[i-1]         else:             prev = h[i-1] - 1         j = randint(0, i-1)         h[i] = max(prev, h[j]+1)         i += 1     return h[m-1]  def f(m): return algorithm(m, advantage=False) def g(m): return algorithm(m, advantage=True) def h(m): return g(m) - f(m) And the plots of some Monte Carlo simulation plots, which show that the hypothesis might hold:",f g m g m h(m):=g(m)-f(m) \lim_{m\to\infty} E[h(m)] = 0,"['statistics', 'stochastic-processes', 'algorithms']"
28,Is this proof for inverse transform method valid for any pdf?,Is this proof for inverse transform method valid for any pdf?,,"This is from a uni course that includes a chapter about simulation, and introduces this method for random number generation. While the theorem is about a general $f(x)$ (probability density function), it seems to me the proof assumes an uniform distribution, and therefore it's valid only for that. Am I wrong? Is this particular proof valid for any probability density function? Theorem and proof:","This is from a uni course that includes a chapter about simulation, and introduces this method for random number generation. While the theorem is about a general (probability density function), it seems to me the proof assumes an uniform distribution, and therefore it's valid only for that. Am I wrong? Is this particular proof valid for any probability density function? Theorem and proof:",f(x),"['statistics', 'proof-verification', 'random', 'simulation']"
29,showing the pdf of n-th order statistics,showing the pdf of n-th order statistics,,"I am working on a mathematical stats assignment and I got stuck here. Letting $X_1, X_2, ... ,X_n$ a random sample from uniform(0, $\theta$ ), and Y is n-th order statistic, I need to show that the pdf of Y is: $p(y|\theta) = \frac{ny^{n-1}}{\theta^{n}}, 0<y<\theta$ I know that n-th order is $g_n(y_n) = nf(y_n)[\int_{-\infty}^{y_n}f(x)dx]^{n-1}.$ I plugged in the uniform distribution $f(x)=\frac{1}{\theta}$ and tried to solve the integral, and it didn't show the result I wanted. How should I approach this? Should I assign something else for $f(x)$ ? Also, If I want to find the joint pdf f(y,θ) of Y and θ, which the prior pdf $\lambda(\theta)$ is given, I just multiply $p(y|\theta)$ to get the f(y, $\theta$ ), right? Thanks in advance.","I am working on a mathematical stats assignment and I got stuck here. Letting a random sample from uniform(0, ), and Y is n-th order statistic, I need to show that the pdf of Y is: I know that n-th order is I plugged in the uniform distribution and tried to solve the integral, and it didn't show the result I wanted. How should I approach this? Should I assign something else for ? Also, If I want to find the joint pdf f(y,θ) of Y and θ, which the prior pdf is given, I just multiply to get the f(y, ), right? Thanks in advance.","X_1, X_2, ... ,X_n \theta p(y|\theta) = \frac{ny^{n-1}}{\theta^{n}}, 0<y<\theta g_n(y_n) = nf(y_n)[\int_{-\infty}^{y_n}f(x)dx]^{n-1}. f(x)=\frac{1}{\theta} f(x) \lambda(\theta) p(y|\theta) \theta","['statistics', 'uniform-distribution', 'bayesian', 'order-statistics']"
30,How to compute the MLE of the zero truncated poisson?,How to compute the MLE of the zero truncated poisson?,,"$$P(X = x ) =   \frac{\theta ^ x e^{- \theta} }{x ! \left ( 1 - e^{- \theta} \right )},\ x=1,2,\cdots,\ 0<\theta<\infty$$ Then the likelihood of $(x_1,\cdots,x_n)$ is $$\mathcal L(\theta \mid \boldsymbol y) = \prod_{i=1}^n \frac{e^{-\theta}}{1-e^{-\theta}} \frac{\theta^{x_i}}{x_i!} \propto (e^{\theta} - 1)^{-n} \theta^{n \bar x}$$ so the log-likelihood is $$\ell(\theta \mid \boldsymbol x) = -n \log(e^{\theta} - 1) + n\bar x \log \theta$$ and its derivative with respect to θ is $$\frac{\partial \ell}{\partial \theta} = \frac{e^\theta}{1-e^{\theta}} + \frac{\bar x}{\theta}$$ but I don't know how to compute $\partial \ell/\partial\theta = 0$ , since this does not have a closed form expression. Is there anyone can give me an idea?","Then the likelihood of is so the log-likelihood is and its derivative with respect to θ is but I don't know how to compute , since this does not have a closed form expression. Is there anyone can give me an idea?","P(X = x ) =  
\frac{\theta ^ x e^{- \theta} }{x ! \left ( 1 - e^{- \theta} \right )},\ x=1,2,\cdots,\ 0<\theta<\infty (x_1,\cdots,x_n) \mathcal L(\theta \mid \boldsymbol y) = \prod_{i=1}^n \frac{e^{-\theta}}{1-e^{-\theta}} \frac{\theta^{x_i}}{x_i!} \propto (e^{\theta} - 1)^{-n} \theta^{n \bar x} \ell(\theta \mid \boldsymbol x) = -n \log(e^{\theta} - 1) + n\bar x \log \theta \frac{\partial \ell}{\partial \theta} = \frac{e^\theta}{1-e^{\theta}} + \frac{\bar x}{\theta} \partial \ell/\partial\theta = 0","['statistics', 'poisson-distribution', 'maximum-likelihood']"
31,Rao-Blackwell and Cramer-Rao LB comparison,Rao-Blackwell and Cramer-Rao LB comparison,,"Let $X_1, X_2, \dots, X_n$ be a random sample following the Geometric distribution . $$ \prod\limits_{i=1}^{n} f(x_i|p) = (1-p)^{\sum\limits_{i=1}^n x_i-n}p^n $$ Since the pmf of the Geometric distribution is exponential family, the factorization theorem yields that the statistic $$ T = \sum\limits_{i=1}^n x_i $$ is sufficient and complete. Then, $$ E[T] = E\left[ \sum\limits_{i=1}^n x_i \right] = \sum\limits_{i=1}^n E[x_i] = \frac{n}{p} $$ Therefore, according to Rao-Blackwell , the Minimum Variance Unbiased Estimator of $\frac{1}{p}$ is $$ W = \frac{1}{n} \sum\limits_{i=1}^n x_i $$ Now, Cramer-Rao's Lower Bound : $$ LB = \frac{\left[\left(\frac{1}{p}\right)'\right]^2}{nI(p)} = \frac{1}{n}\frac{1-p}{p}  $$ Question: Is $V[W] = LB$ in this specific example? If so, is there a reason why $W$ has the lowest possible variance that has something to do with the geometric distribution?","Let be a random sample following the Geometric distribution . Since the pmf of the Geometric distribution is exponential family, the factorization theorem yields that the statistic is sufficient and complete. Then, Therefore, according to Rao-Blackwell , the Minimum Variance Unbiased Estimator of is Now, Cramer-Rao's Lower Bound : Question: Is in this specific example? If so, is there a reason why has the lowest possible variance that has something to do with the geometric distribution?","X_1, X_2, \dots, X_n 
\prod\limits_{i=1}^{n} f(x_i|p) = (1-p)^{\sum\limits_{i=1}^n x_i-n}p^n
 
T = \sum\limits_{i=1}^n x_i
 
E[T] = E\left[ \sum\limits_{i=1}^n x_i \right] = \sum\limits_{i=1}^n E[x_i] = \frac{n}{p}
 \frac{1}{p} 
W = \frac{1}{n} \sum\limits_{i=1}^n x_i
 
LB = \frac{\left[\left(\frac{1}{p}\right)'\right]^2}{nI(p)} = \frac{1}{n}\frac{1-p}{p} 
 V[W] = LB W","['statistics', 'probability-distributions', 'variance', 'parameter-estimation']"
32,Can someone explain to me the intuition for the formula for finding the percentile of a value in a data set?,Can someone explain to me the intuition for the formula for finding the percentile of a value in a data set?,,"Basically, my math textbook just gave me the formula without any explanation on about the ""why""/intuition of the formula. Here's the text from the book: • Order the data from smallest to largest. • x = the number of data values counting from the bottom of the data list up to but not including the data value for which you want to find the percentile. • y = the number of data values equal to the data value for which you want to find the percentile. • n = the total number of data. • Calculate $\frac{x + 0.5y} {n} (100)$ . Then round to the nearest integer.","Basically, my math textbook just gave me the formula without any explanation on about the ""why""/intuition of the formula. Here's the text from the book: • Order the data from smallest to largest. • x = the number of data values counting from the bottom of the data list up to but not including the data value for which you want to find the percentile. • y = the number of data values equal to the data value for which you want to find the percentile. • n = the total number of data. • Calculate . Then round to the nearest integer.","\frac{x + 0.5y}
{n}
(100)",['statistics']
33,Training a Boltzmann Machine (Non restricted),Training a Boltzmann Machine (Non restricted),,"I'm reading through Neural Network and Deep Learning by Charu C. Aggarwal , more specifically chapter 6 which treats Restricted Boltzmann Machines, section 6.3. treats Boltzmann Machines. I'll try to summarize the content of the section (because I'd like an answer formulated with a similar notation, but that's not essential) and I'll ask the specific question. A Boltzmann Machine (BM) is essentially a probabilistic model expressed as an undirected graph. If $i$ and $j$ are two nodes of such graph then $w_{ij} = w_{ji}$ is the associated weight for the arc $(i,j)$ , it is also assumed $w_{ii} = 0$ , so there's no self loop (no arc starts and ends in the same node). The states that a BM can model are both visible and hidden , i.e. if $q = m + d$ is the total number of states the $d$ are the visible ones and $m$ are the hidden ones. The state can be represented as a pair of vectors $(\vec{v},\vec{h})$ , ( $\vec{v}$ are the visible states and $\vec{h}$ are the hidden states). The pair represent the sets of all possible states $(\vec{v},\vec{h}) = \vec{s} = (s_1,\ldots,s_q)$ . An important concept in BM is the energy defined as $$ E = - \sum_i b_i s_i - \sum_{i,j: i < j} w_{ij} s_i s_j, \;\;\;(1) $$ and such energy leads to the definition of energy gap $$ \Delta E_i = E_{s_i = 0} - E_{s_i = 1} = b_i + \sum_{j : j \neq i} w_{ij} s_j,  $$ the actual expression follows from a simple calculation. The probability of a specific state is defined as $$ P(\vec{s}) = \frac{e^{-E(\vec{s})}}{Z}, \;\;\;\; (2) $$ where $E(\vec{s})$ is given by $(1)$ and $$ Z = \sum_{\vec{s}} e^{-E(\vec{s})}. $$ Also observe that thanks to the Bayes rule we get: $$ P(s_i = 1 | s_1,\ldots,s_{i-1},s_{i+1},\ldots s_{q}) = \frac{1}{1 + e^{-\Delta E_i}} $$ and such probability can be used to apply either Gibbs Sampling or Markov Chain Monte Carlo to generate samples. Now the bit I don't understand To perform training we want to maximize the likelihood $$ log(P(\vec{s}) = - E(\vec{s}) - \log Z $$ which is fine, but the following equation is drawn out of nowhere $$ \frac{\partial P(\vec{s})}{ \partial w_{ij}} = \left\langle s_i,s_j \right\rangle_{data} - \left\langle s_i, s_j \right\rangle_{model} \;\;\;\; (3) $$ Quoting the book now Here $\left\langle s_i,s_j \right\rangle_{data}$ represents the averaged value of $s_i s_j$ obtained by running the generative process of section 6.1.3, when the visible states are clamped to attribute values in a training point. The averaging is done over a mini-batch of training points. Similarly $\left\langle s_i,s_j \right\rangle_{model}$ represents the averaged value $s_i s_j$ at thermal equilibrium without fixing visible states to training points and simply running the generative process of Section 6.3.1. I've tried to derive the equation by myself but it doesn't lead me to the same expression. Therefore can anyone show me how the equation is derived or point out to a very good reference? The book points to this paper , which I assume is the original one, but it makes use of the KL-Divergence but such measure is not mentioned anywhere. Can anyone show me how to derive the learning algorithm then?","I'm reading through Neural Network and Deep Learning by Charu C. Aggarwal , more specifically chapter 6 which treats Restricted Boltzmann Machines, section 6.3. treats Boltzmann Machines. I'll try to summarize the content of the section (because I'd like an answer formulated with a similar notation, but that's not essential) and I'll ask the specific question. A Boltzmann Machine (BM) is essentially a probabilistic model expressed as an undirected graph. If and are two nodes of such graph then is the associated weight for the arc , it is also assumed , so there's no self loop (no arc starts and ends in the same node). The states that a BM can model are both visible and hidden , i.e. if is the total number of states the are the visible ones and are the hidden ones. The state can be represented as a pair of vectors , ( are the visible states and are the hidden states). The pair represent the sets of all possible states . An important concept in BM is the energy defined as and such energy leads to the definition of energy gap the actual expression follows from a simple calculation. The probability of a specific state is defined as where is given by and Also observe that thanks to the Bayes rule we get: and such probability can be used to apply either Gibbs Sampling or Markov Chain Monte Carlo to generate samples. Now the bit I don't understand To perform training we want to maximize the likelihood which is fine, but the following equation is drawn out of nowhere Quoting the book now Here represents the averaged value of obtained by running the generative process of section 6.1.3, when the visible states are clamped to attribute values in a training point. The averaging is done over a mini-batch of training points. Similarly represents the averaged value at thermal equilibrium without fixing visible states to training points and simply running the generative process of Section 6.3.1. I've tried to derive the equation by myself but it doesn't lead me to the same expression. Therefore can anyone show me how the equation is derived or point out to a very good reference? The book points to this paper , which I assume is the original one, but it makes use of the KL-Divergence but such measure is not mentioned anywhere. Can anyone show me how to derive the learning algorithm then?","i j w_{ij} = w_{ji} (i,j) w_{ii} = 0 q = m + d d m (\vec{v},\vec{h}) \vec{v} \vec{h} (\vec{v},\vec{h}) = \vec{s} = (s_1,\ldots,s_q) 
E = - \sum_i b_i s_i - \sum_{i,j: i < j} w_{ij} s_i s_j, \;\;\;(1)
 
\Delta E_i = E_{s_i = 0} - E_{s_i = 1} = b_i + \sum_{j : j \neq i} w_{ij} s_j, 
 
P(\vec{s}) = \frac{e^{-E(\vec{s})}}{Z}, \;\;\;\; (2)
 E(\vec{s}) (1) 
Z = \sum_{\vec{s}} e^{-E(\vec{s})}.
 
P(s_i = 1 | s_1,\ldots,s_{i-1},s_{i+1},\ldots s_{q}) = \frac{1}{1 + e^{-\Delta E_i}}
 
log(P(\vec{s}) = - E(\vec{s}) - \log Z
 
\frac{\partial P(\vec{s})}{ \partial w_{ij}} = \left\langle s_i,s_j \right\rangle_{data} - \left\langle s_i, s_j \right\rangle_{model} \;\;\;\; (3)
 \left\langle s_i,s_j \right\rangle_{data} s_i s_j \left\langle s_i,s_j \right\rangle_{model} s_i s_j","['calculus', 'statistics', 'proof-explanation', 'statistical-inference', 'machine-learning']"
34,Calculating the Kullback Lieber information Criterion (Quasi Maximum Likelihood Method),Calculating the Kullback Lieber information Criterion (Quasi Maximum Likelihood Method),,"Let the observed random variables $X_1,X_2$ be independent and normally distributed with zero mean and variance respectively $\sigma_1^2$ and $\theta \sigma_1^2$ , where $\theta \in \mathbb{R}$ . The model I am considering consist of the set of probability densities given by $$\left \{  \frac{1}{\sqrt{2 \pi X_1^2}}  \exp \left( \frac{-1}{2 } \right) \frac{1}{\sqrt{2 \pi \beta X_1^2}}  \exp \left( \frac{-X_2^2}{2 \beta X_1^2} \right)  \Bigg|  \beta \in \mathbb{R} \right \}$$ I want to minimize the Kullback-Liebler information criterion that is given by $$E\left[   \log \left(   \frac{\frac{1}{\sqrt{2 \pi  \sigma_1^2}}  \exp \left( \frac{-X_1^2}{2  \sigma_1^2}  \right)\frac{1}{\sqrt{2 \pi \theta \sigma_1^2}}  \exp \left( \frac{-X_2^2}{2  \theta \sigma_1^2}  \right)}{  \frac{1}{\sqrt{2 \pi X_1^2}}  \exp \left( \frac{-1}{2 } \right)  \frac{1}{\sqrt{2 \pi \beta X_1^2}}  \exp \left( \frac{-X_2^2}{2 \beta X_1^2} \right)}    \right)  \right]$$ with respect to $\beta$ . The resulting $\beta^*$ should be the value that minimizes the ""distance"" between the model and the true distribution. I would expect $\beta^* = \theta$ since $X_1^2$ is an unbiased estimator for $\sigma_1^2$ . The problem is quickly reduced to minimizing $$E\left[  \frac{1}{2} \log \beta  + \frac{X_2^2}{2 \beta X_1^2}   \right] = \frac{1}{2} \log \beta + \theta \sigma_1^2 E\left[\frac{1}{2 \beta \sigma_1^2 Y_1^2}\right]$$ where $Y_1 = X_1 / \sigma_1$ is distributed as a standard normal random variable (the independence has been used here). The expectation of an inverse  chi squared is derived here and is $\frac{1}{\nu -2}$ (where $\nu$ are the degrees of freedom, in our case $\nu = 1$ ), so we obtain $$ \frac{1}{2} \log \beta - \frac{\theta}{2 \beta} $$ taking the derivative wrt $\beta$ and imposing the equality with zero one obtains $$\frac{1}{\beta} + \frac{\theta}{\beta^2} = 0 \implies \beta^* = - \theta$$ Unfortunately this makes no sense. Have I made a sign mistake or a deeper mistake involving the understanding of the Kullback Liebler criterion? A good writeup on the Kullback-Liebler information criterion is available in The Quasi Maximum Likelihood Method Theory by Chung Ming Kuan.","Let the observed random variables be independent and normally distributed with zero mean and variance respectively and , where . The model I am considering consist of the set of probability densities given by I want to minimize the Kullback-Liebler information criterion that is given by with respect to . The resulting should be the value that minimizes the ""distance"" between the model and the true distribution. I would expect since is an unbiased estimator for . The problem is quickly reduced to minimizing where is distributed as a standard normal random variable (the independence has been used here). The expectation of an inverse  chi squared is derived here and is (where are the degrees of freedom, in our case ), so we obtain taking the derivative wrt and imposing the equality with zero one obtains Unfortunately this makes no sense. Have I made a sign mistake or a deeper mistake involving the understanding of the Kullback Liebler criterion? A good writeup on the Kullback-Liebler information criterion is available in The Quasi Maximum Likelihood Method Theory by Chung Ming Kuan.","X_1,X_2 \sigma_1^2 \theta \sigma_1^2 \theta \in \mathbb{R} \left \{  \frac{1}{\sqrt{2 \pi X_1^2}}  \exp \left( \frac{-1}{2 } \right) \frac{1}{\sqrt{2 \pi \beta X_1^2}}  \exp \left( \frac{-X_2^2}{2 \beta X_1^2} \right)  \Bigg|  \beta \in \mathbb{R} \right \} E\left[   \log \left(   \frac{\frac{1}{\sqrt{2 \pi  \sigma_1^2}}  \exp \left( \frac{-X_1^2}{2  \sigma_1^2}  \right)\frac{1}{\sqrt{2 \pi \theta \sigma_1^2}}  \exp \left( \frac{-X_2^2}{2  \theta \sigma_1^2}  \right)}{  \frac{1}{\sqrt{2 \pi X_1^2}}  \exp \left( \frac{-1}{2 } \right)  \frac{1}{\sqrt{2 \pi \beta X_1^2}}  \exp \left( \frac{-X_2^2}{2 \beta X_1^2} \right)}    \right)  \right] \beta \beta^* \beta^* = \theta X_1^2 \sigma_1^2 E\left[  \frac{1}{2} \log \beta  + \frac{X_2^2}{2 \beta X_1^2}   \right] = \frac{1}{2} \log \beta + \theta \sigma_1^2 E\left[\frac{1}{2 \beta \sigma_1^2 Y_1^2}\right] Y_1 = X_1 / \sigma_1 \frac{1}{\nu -2} \nu \nu = 1  \frac{1}{2} \log \beta - \frac{\theta}{2 \beta}  \beta \frac{1}{\beta} + \frac{\theta}{\beta^2} = 0 \implies \beta^* = - \theta","['probability', 'statistics', 'optimization', 'statistical-inference', 'maximum-likelihood']"
35,Exponential distribution MLE with lifetime and frequency table,Exponential distribution MLE with lifetime and frequency table,,"\begin{array}{c|c} \hline \text{Lifetime (months)} & \text{Observed frequency} \\  \hline 0-2 & 50 \\  \hline 2-4 & 35 \\  \hline 4-6 & 25 \\ \hline 6-8 & 15 \\ \hline 8-10 & 5 \\ \hline >10 & 10 \\ \hline\end{array} The above is the lifetime and frequency table of $140$ light bulbs. I would like to calculate the MLE of $\lambda $ . I plan to use this formula: $$\lambda = \frac{n}{x_1+x_2 + \ldots + x_n}$$ , where $x_1$ means the lifetime of first bulb but I only know the lifetime of the first bulb is between $0$ to $2$ months so how can I solve this question? Thank you in advance.","The above is the lifetime and frequency table of light bulbs. I would like to calculate the MLE of . I plan to use this formula: , where means the lifetime of first bulb but I only know the lifetime of the first bulb is between to months so how can I solve this question? Thank you in advance.","\begin{array}{c|c}
\hline \text{Lifetime (months)} & \text{Observed frequency} \\ 
\hline 0-2 & 50 \\ 
\hline 2-4 & 35 \\ 
\hline 4-6 & 25 \\
\hline 6-8 & 15 \\
\hline 8-10 & 5 \\
\hline >10 & 10 \\
\hline\end{array} 140 \lambda  \lambda = \frac{n}{x_1+x_2 + \ldots + x_n} x_1 0 2","['statistics', 'probability-distributions', 'exponential-distribution', 'maximum-likelihood']"
36,Why is a set inclusion true regarding the maximum likelihood estimator?,Why is a set inclusion true regarding the maximum likelihood estimator?,,"The following doubt regards a step of a proof of consistency of the maximum likelihood estimator in the case of independent NON identically distributed random variables. Assume the parameter space is given by $\Omega \subset \mathbb{R}$ , denote the maximum likelihood estimator on a sample of $n$ INID random variables $Y_1, \dots, Y_n$ , that have probability densities respectively $f_1(y; \theta) , \dots, f_n(y;\theta)  $ ,  by $\hat{\theta}_n$ and the true parameter value $\theta_0$ . The maximum likelihood estimator $\hat{\theta}_n$ in this framework is taken to be the value that maximizes (for simplicity let's assume it exists) $$\ln \prod_{i= 1 }^n  f_i(Y_i; \theta)$$ Define $\Omega(\eta) := \Omega \setminus B(\theta_0, \eta) $ where $B(a,r)$ is the open ball centered at $a$ of radius $r$ and $\eta > 0$ . Define $$R_n^* = \sup_{\theta} \{ \ln \prod_{i= 1 }^n [ f_i(Y_i; \theta) / f_i( Y_i; \theta_0)  ] : \theta \in \Omega(\eta)   \}$$ I want to prove that $\{ \hat{\theta}_n \in \Omega(\eta)  \} \subset \{ R_n^* \ge 0   \}$ , how can this be seen?","The following doubt regards a step of a proof of consistency of the maximum likelihood estimator in the case of independent NON identically distributed random variables. Assume the parameter space is given by , denote the maximum likelihood estimator on a sample of INID random variables , that have probability densities respectively ,  by and the true parameter value . The maximum likelihood estimator in this framework is taken to be the value that maximizes (for simplicity let's assume it exists) Define where is the open ball centered at of radius and . Define I want to prove that , how can this be seen?","\Omega \subset \mathbb{R} n Y_1, \dots, Y_n f_1(y; \theta) , \dots, f_n(y;\theta)   \hat{\theta}_n \theta_0 \hat{\theta}_n \ln \prod_{i= 1 }^n  f_i(Y_i; \theta) \Omega(\eta) := \Omega \setminus B(\theta_0, \eta)  B(a,r) a r \eta > 0 R_n^* = \sup_{\theta} \{ \ln \prod_{i= 1 }^n [ f_i(Y_i; \theta) / f_i( Y_i; \theta_0)  ] : \theta \in \Omega(\eta)   \} \{ \hat{\theta}_n \in \Omega(\eta)  \} \subset \{ R_n^* \ge 0   \}","['statistics', 'optimization']"
37,The expected weight-ratio between weighted and un-weighted balls when picked from a bin without replacement,The expected weight-ratio between weighted and un-weighted balls when picked from a bin without replacement,,"The Problem The problem, I believe, can be stated in the following way: Given $K$ white balls all with without weight (one can say that the weight is $0$ ) and $N - K$ red balls with individual strictly positive weights $> 0$ , if $n \leq N$ balls are picked at uniformly random without replacement, what is the expected weight ratio between the $k$ selected balls' weights and the total sum of all $N-K$ red balls' weights? Comment: without any knowledge of neither how the weights are distributed among the red balls, nor of how many red balls there are compared to white, I guess that it could be the case that the answer is too general. I have, either way, not been able to come up with the precise algebraic formula for the solution. My Thoughts & Efforts I have in my efforts followed two trains of reasoning, none of which if followed could result in the sought after solution. They are mentioned as to point out that my approach has been towards finding ways that could give a rough idea of the bounds of a solution. The calculations are when no reference is found mostly my own calculation, and as such not reviewed by anyone, so consequently both these paths might be and likely are, subject to a high degree of miscalculations. I highly value any input. The Heaviest Ball (I) - Firstly, the heaviest ball is expected to be one of the first $\lceil {log\ N} \rceil + 1$ visited elements. This I believe can be shown by letting $X$ denote the random variable such that $X_i = 1$ for $1 \leq i \leq N$ represents the event of the heaviest ball being the $i:th$ ball being evaluated, and $X_i = 0$ of it not being the heaviest. For any specific $j$ the expected value of the heaviest being evaluated can be written as in (1). \begin{equation} \mathbb E[X_i] = 0 \times P[X_i=0]  + 1 \times P[X_i=1] = P[X_i=1] \quad \quad (1) \end{equation} If we assume that all such events are mutually independent and that the balls are picked without replacement, then the probability of $P[X_i=1]$ can be written as (2). \begin{equation}\label{fun:fun_ct} P[X_i=1] = \frac{1}{N+1-i} \quad \quad (2) \end{equation} The expected number of tries before an interval from the optimal solution follows from linearity of expectation over the random variables. \begin{align*} \mathbb E[X] &= \sum_{i=1}^n P[X_i]\\ &= \sum_{i=1}^N (\frac{1}{N+1-i}) \\ &< \sum_{i=1}^N \frac{1}{i} \\ &\leq log(N) + 1  \end{align*} From the Wikipedia page on harmonic series [1] the following relation is stated $\sum_{i=1}^{N} \frac{1}{i} \leq log(N) + 1$ which leads me to believe that if $n \geq log(N) + 1$ the, searched for, expected weight ratio should be bounded by $\frac{1}{N-K}$ . If this process is repeated for rounds $r := \lceil \frac{n}{\log(N) + 1} \rceil$ wherein for each round $n$ balls are picked, then by linearity of expectation , should we not receive a weight ratio bounded from above(?) by $\frac{r}{N-K}$ ? The Heaviest m Balls (II) - Secondly, with a arguably severe abuse of terminology, I say that the expected number of red balls after picking $n$ follows from the hypergeometric distribution such that $Y \sim Hypergeometric(N, N-K, n)$ and could, therefore, be expressed, by following the example in [2] , algebraically as the expression $\mathbb E[Y] = \sigma n$ where $\sigma := \frac{N-K}{N}$ . If one re-colors the $m$ heaviest red balls green such that $m < n$ , then by the same reasoning the expected number of green balls after picking $n$ balls, should be $\hat{\sigma} := \frac{N-m}{N}$ . The expected ratio should, therefore, be bounded from below by \begin{equation} L := \frac{\sum_{j=1}^{\hat{\sigma} n} \alpha^{j} + \sum_{j=\hat{\sigma}n +1 }^{\sigma n} \beta^{j}} {\sum_{j=1}^{N-K}\alpha^{j}}  \end{equation} where $\beta^j$ is the weight of $j:th$ lightest ball, and from above by \begin{equation} U_1 := \frac{\sum_{j=1}^{\sigma n} \alpha^{j}}{\sum_{j=1}^{N-K}\alpha^{j}}   \end{equation} where $\alpha^j$ is the weight of the $j:th$ heaviest ball. Comment: we have for the upper-bound here settled with the sequence of the heaviest weights, but if one could compute the expected number of index between $n\sigma$ and $n\hat{\sigma}$ and denote it $\mathbb E[I]$ , then the upper-bound can be tightened to \begin{equation} U_2 := \frac{\sum_{j=1}^{\hat{\sigma} n} \alpha^{j} + \sum_{j=\hat{\sigma}n + \mathbb E[I]}^{\sigma n + \mathbb E[I]} \alpha^{j}} {\sum_{j=1}^{N-K}\alpha^{j}}  \end{equation} It might actually be that case that $\mathbb E[I] = \mathbb E[X]$ I guess, and if that is maybe we could have \begin{equation} U_3 := \frac{\sum_{j=1}^{\hat{\sigma} n} \alpha^{j} + \sum_{j=1}^{\sigma n - \hat{\sigma}n} \alpha^{j(log(N))}} {\sum_{j=1}^{N-K}\alpha^{j}}  \end{equation} Conclusion Finally, my conclusion is that the expected ratio $\mathbb E[Z]$ must be in-between \begin{equation} L  \leq \mathbb E[Z] \leq U_3 \leq U_2 \leq U_1 \end{equation} where $0 \leq Z \leq 1$ is a continuous random variable expressing the ratio in question.","The Problem The problem, I believe, can be stated in the following way: Given white balls all with without weight (one can say that the weight is ) and red balls with individual strictly positive weights , if balls are picked at uniformly random without replacement, what is the expected weight ratio between the selected balls' weights and the total sum of all red balls' weights? Comment: without any knowledge of neither how the weights are distributed among the red balls, nor of how many red balls there are compared to white, I guess that it could be the case that the answer is too general. I have, either way, not been able to come up with the precise algebraic formula for the solution. My Thoughts & Efforts I have in my efforts followed two trains of reasoning, none of which if followed could result in the sought after solution. They are mentioned as to point out that my approach has been towards finding ways that could give a rough idea of the bounds of a solution. The calculations are when no reference is found mostly my own calculation, and as such not reviewed by anyone, so consequently both these paths might be and likely are, subject to a high degree of miscalculations. I highly value any input. The Heaviest Ball (I) - Firstly, the heaviest ball is expected to be one of the first visited elements. This I believe can be shown by letting denote the random variable such that for represents the event of the heaviest ball being the ball being evaluated, and of it not being the heaviest. For any specific the expected value of the heaviest being evaluated can be written as in (1). If we assume that all such events are mutually independent and that the balls are picked without replacement, then the probability of can be written as (2). The expected number of tries before an interval from the optimal solution follows from linearity of expectation over the random variables. From the Wikipedia page on harmonic series [1] the following relation is stated which leads me to believe that if the, searched for, expected weight ratio should be bounded by . If this process is repeated for rounds wherein for each round balls are picked, then by linearity of expectation , should we not receive a weight ratio bounded from above(?) by ? The Heaviest m Balls (II) - Secondly, with a arguably severe abuse of terminology, I say that the expected number of red balls after picking follows from the hypergeometric distribution such that and could, therefore, be expressed, by following the example in [2] , algebraically as the expression where . If one re-colors the heaviest red balls green such that , then by the same reasoning the expected number of green balls after picking balls, should be . The expected ratio should, therefore, be bounded from below by where is the weight of lightest ball, and from above by where is the weight of the heaviest ball. Comment: we have for the upper-bound here settled with the sequence of the heaviest weights, but if one could compute the expected number of index between and and denote it , then the upper-bound can be tightened to It might actually be that case that I guess, and if that is maybe we could have Conclusion Finally, my conclusion is that the expected ratio must be in-between where is a continuous random variable expressing the ratio in question.","K 0 N - K > 0 n \leq N k N-K \lceil {log\ N} \rceil + 1 X X_i = 1 1 \leq i \leq N i:th X_i = 0 j \begin{equation}
\mathbb E[X_i] = 0 \times P[X_i=0]  + 1 \times P[X_i=1] = P[X_i=1] \quad \quad (1)
\end{equation} P[X_i=1] \begin{equation}\label{fun:fun_ct}
P[X_i=1] = \frac{1}{N+1-i} \quad \quad (2)
\end{equation} \begin{align*}
\mathbb E[X] &= \sum_{i=1}^n P[X_i]\\
&= \sum_{i=1}^N (\frac{1}{N+1-i}) \\
&< \sum_{i=1}^N \frac{1}{i} \\
&\leq log(N) + 1 
\end{align*} \sum_{i=1}^{N} \frac{1}{i} \leq log(N) + 1 n \geq log(N) + 1 \frac{1}{N-K} r := \lceil \frac{n}{\log(N) + 1} \rceil n \frac{r}{N-K} n Y \sim Hypergeometric(N, N-K, n) \mathbb E[Y] = \sigma n \sigma := \frac{N-K}{N} m m < n n \hat{\sigma} := \frac{N-m}{N} \begin{equation}
L := \frac{\sum_{j=1}^{\hat{\sigma} n} \alpha^{j} + \sum_{j=\hat{\sigma}n +1 }^{\sigma n} \beta^{j}} {\sum_{j=1}^{N-K}\alpha^{j}} 
\end{equation} \beta^j j:th \begin{equation}
U_1 := \frac{\sum_{j=1}^{\sigma n} \alpha^{j}}{\sum_{j=1}^{N-K}\alpha^{j}}  
\end{equation} \alpha^j j:th n\sigma n\hat{\sigma} \mathbb E[I] \begin{equation}
U_2 := \frac{\sum_{j=1}^{\hat{\sigma} n} \alpha^{j} + \sum_{j=\hat{\sigma}n + \mathbb E[I]}^{\sigma n + \mathbb E[I]} \alpha^{j}} {\sum_{j=1}^{N-K}\alpha^{j}} 
\end{equation} \mathbb E[I] = \mathbb E[X] \begin{equation}
U_3 := \frac{\sum_{j=1}^{\hat{\sigma} n} \alpha^{j} + \sum_{j=1}^{\sigma n - \hat{\sigma}n} \alpha^{j(log(N))}} {\sum_{j=1}^{N-K}\alpha^{j}} 
\end{equation} \mathbb E[Z] \begin{equation}
L  \leq \mathbb E[Z] \leq U_3 \leq U_2 \leq U_1
\end{equation} 0 \leq Z \leq 1","['probability', 'statistics', 'discrete-mathematics', 'expected-value', 'upper-lower-bounds']"
38,Defining a custom probability density function for Maximum likelihood in matlab,Defining a custom probability density function for Maximum likelihood in matlab,,"I am trying to minimise a likelihood function and estimate the parameter value of $\lambda$ by fitting to the following data. $t$ is the time and $N(t)$ si the population measured at those specific time points $t=[0;1;2;3;4;5;6];$ $N(t)=[350000,210000,80000,20000,100,100,100];  $ The probability density function is $f_N(N(t);\lambda t)=\lambda t e^{-\lambda t N(t)}$ . The Cumulative distribution function is $1-e^{-\lambda tN(t)}$ This is the Matlab code I wrote: N=[350000,200000,80000,20000,100,100,100]; t=[0 1 2 3 4 5 6]; cutOff=100; c=(N<=cutOff);%censored data start=1/mean(N);  pdf_lambda=@(N,lambda)lambda.*t.*exp(-lambda.*t.*N); cdf_lambda=@(N,lambda)1-exp(-lambda.*t.*N); [paramEsts,paramCIs] = mle(N, 'censoring',c,'pdf',pdf_lambda, 'cdf',cdf_lambda, ...                            'start',start, 'lower',0); I get an error as Unable to perform assignment because the size of the left side is 1-by-1 and the size of the right side is 1-by-7. This is the first time I am using MLE to fit for data and estimate a parameter. So I don't quite understand what I ma dong wrong here. Can someone please let me know how to fix this issue.","I am trying to minimise a likelihood function and estimate the parameter value of by fitting to the following data. is the time and si the population measured at those specific time points The probability density function is . The Cumulative distribution function is This is the Matlab code I wrote: N=[350000,200000,80000,20000,100,100,100]; t=[0 1 2 3 4 5 6]; cutOff=100; c=(N<=cutOff);%censored data start=1/mean(N);  pdf_lambda=@(N,lambda)lambda.*t.*exp(-lambda.*t.*N); cdf_lambda=@(N,lambda)1-exp(-lambda.*t.*N); [paramEsts,paramCIs] = mle(N, 'censoring',c,'pdf',pdf_lambda, 'cdf',cdf_lambda, ...                            'start',start, 'lower',0); I get an error as Unable to perform assignment because the size of the left side is 1-by-1 and the size of the right side is 1-by-7. This is the first time I am using MLE to fit for data and estimate a parameter. So I don't quite understand what I ma dong wrong here. Can someone please let me know how to fix this issue.","\lambda t N(t) t=[0;1;2;3;4;5;6]; N(t)=[350000,210000,80000,20000,100,100,100];   f_N(N(t);\lambda t)=\lambda t e^{-\lambda t N(t)} 1-e^{-\lambda tN(t)}","['statistics', 'matlab', 'maximum-likelihood']"
39,A Hard Combination Probability Equation From A Reality T.V. Show,A Hard Combination Probability Equation From A Reality T.V. Show,,"I was watching the T.V. show Survivor tonight and miserably failed at wrapping my mathematically out-of-practice post-college brain around a probability equation. Background: At the start of the show, 18 people are randomly divided into 2 tribes (red & blue) of equal size, so 9 each. Then tonight the 15 remaining people (6 red & 9 blue) found out that they would be randomly splitting again...but this time into 3 tribes of 5 (red, blue, & green). When they finished the random tribe swap, they were shocked to find that 5 of the 9 old blue team members remained together on the new blue team, 5 of the 6 old red team members all stayed together (but moved to green...not sure if it's relevant), and finally the remaining 4 of the 9 old blue team members and the 1 remaining old red team member ended up on the red team together. Long story short to the non-mathematically inclined viewer...wow nothing changed (rigged reality tv). But what is the probability of that actually happening? More specifically what is the probability that after all the randomization of teams, 2 of the 3 newly created teams would have 5 people that had previously been on a team together (when there were only 2 teams). Thanks ahead of time!","I was watching the T.V. show Survivor tonight and miserably failed at wrapping my mathematically out-of-practice post-college brain around a probability equation. Background: At the start of the show, 18 people are randomly divided into 2 tribes (red & blue) of equal size, so 9 each. Then tonight the 15 remaining people (6 red & 9 blue) found out that they would be randomly splitting again...but this time into 3 tribes of 5 (red, blue, & green). When they finished the random tribe swap, they were shocked to find that 5 of the 9 old blue team members remained together on the new blue team, 5 of the 6 old red team members all stayed together (but moved to green...not sure if it's relevant), and finally the remaining 4 of the 9 old blue team members and the 1 remaining old red team member ended up on the red team together. Long story short to the non-mathematically inclined viewer...wow nothing changed (rigged reality tv). But what is the probability of that actually happening? More specifically what is the probability that after all the randomization of teams, 2 of the 3 newly created teams would have 5 people that had previously been on a team together (when there were only 2 teams). Thanks ahead of time!",,"['probability', 'statistics', 'combinations', 'random']"
40,Is this an application case of Bayes theorem? Is my book wrong?,Is this an application case of Bayes theorem? Is my book wrong?,,"A sickness has a heterozygote frequency of $\frac{1}{20}$ ie. 1 in 20 people of a population will have the allele combination $Aa$ where a denotes the recessive and A the dominant allele. To become sick the carrier needs to have two $aa$ alleles. A mother is known to have the combination $Aa$ , what is the probability her child will be sick (have $aa$ ) if the combination of the husband is unknown (i.e. $AA, Aa, aa)$ ? Now here is where I struggle. If the husband has $AA$ , the child will never get $aa$ , if the husband has $Aa$ , the child will get $aa$ with a chance of $\frac{1}{4}$ . If the husband has $aa$ (is sick himself) then the child wil get $aa$ with a chance of $\frac{1}{2}$ The book states that the answer a priori is for the child to be sick in this situation is $\frac{1}{20} \frac{1}{2} \frac{1}{2} = \frac{1}{80}$ Shouldn't it instead  be : $\frac{1}{4}\frac{1}{20} + (\textbf{double aa frequency})\cdot \frac{1}{2}$ ?","A sickness has a heterozygote frequency of ie. 1 in 20 people of a population will have the allele combination where a denotes the recessive and A the dominant allele. To become sick the carrier needs to have two alleles. A mother is known to have the combination , what is the probability her child will be sick (have ) if the combination of the husband is unknown (i.e. ? Now here is where I struggle. If the husband has , the child will never get , if the husband has , the child will get with a chance of . If the husband has (is sick himself) then the child wil get with a chance of The book states that the answer a priori is for the child to be sick in this situation is Shouldn't it instead  be : ?","\frac{1}{20} Aa aa Aa aa AA, Aa, aa) AA aa Aa aa \frac{1}{4} aa aa \frac{1}{2} \frac{1}{20} \frac{1}{2} \frac{1}{2} = \frac{1}{80} \frac{1}{4}\frac{1}{20} + (\textbf{double aa frequency})\cdot \frac{1}{2}","['statistics', 'bayes-theorem']"
41,Where did the mean estimator come from?,Where did the mean estimator come from?,,"What was the motivation behind the definition of the mean estimator  : $$\hat{\mu}=\frac{1}{N}\sum_{i=1}^N X_{i}$$ Did we come up with this very form through trial and error ? I do know that it's unbiased but aren't there other estimators that are also unbiased , so why did we favor this particular one ?","What was the motivation behind the definition of the mean estimator  : Did we come up with this very form through trial and error ? I do know that it's unbiased but aren't there other estimators that are also unbiased , so why did we favor this particular one ?",\hat{\mu}=\frac{1}{N}\sum_{i=1}^N X_{i},"['probability', 'statistics', 'math-history']"
42,Finding a smaller dataset with a similar covariance matrix,Finding a smaller dataset with a similar covariance matrix,,"I'm interested in solving the following problem: Given a dataset $\mathcal{X} = \{x_i\}_{i=1}^n\subset\mathbb{R}^p$ , find a smaller set $\mathcal{Y} = \{y_i\}_{i=1}^k\subset{\mathbb{R}^p}$ whose sample covariance matrix, $C_\mathcal{Y}$ , is a good approximation to that of $\mathcal{X}$ , $C_{\mathcal{X}}$ . To make this a little more precise, is there a good way of finding $\mathcal{Y}$ such that $\left\|C_\mathcal{X} - \mathcal{C}_\mathcal{Y}\right\| \le \varepsilon$ , or such that $\left\|C_{\mathcal{X}} - C_{\mathcal{Y}}\right\|$ is near-minimal for fixed $k$ ? One idea would be to choose $\mathcal{Y}$ by sampling $\mathcal{X}$ at random. Perhaps a better way to do this, though, is to make $\mathcal{Y}$ the result of Lloyd's algorithm / $k$ -means on $\mathcal{X}$ , which would help to better summarize the entire dataset. In general, is there a decent way to solve this problem, preferably with good theoretical bounds on $\left\|C_{\mathcal{X}} - C_{\mathcal{Y}}\right\|$ (where $\left\|\cdot\right\|$ is just a common matrix norm, e.g. Frobenius or spectral)? Ideally I could find $\mathcal{Y}$ in time complexity similar to that of Lloyd's algorithm, or at least in time that is sub-quadratic in $n$ (so preferably cheaper than doing something like PCA ). But if you have ideas for methods/algorithms that are more computationally expensive that haven't been mentioned here I'd also appreciate hearing those. Thank you!","I'm interested in solving the following problem: Given a dataset , find a smaller set whose sample covariance matrix, , is a good approximation to that of , . To make this a little more precise, is there a good way of finding such that , or such that is near-minimal for fixed ? One idea would be to choose by sampling at random. Perhaps a better way to do this, though, is to make the result of Lloyd's algorithm / -means on , which would help to better summarize the entire dataset. In general, is there a decent way to solve this problem, preferably with good theoretical bounds on (where is just a common matrix norm, e.g. Frobenius or spectral)? Ideally I could find in time complexity similar to that of Lloyd's algorithm, or at least in time that is sub-quadratic in (so preferably cheaper than doing something like PCA ). But if you have ideas for methods/algorithms that are more computationally expensive that haven't been mentioned here I'd also appreciate hearing those. Thank you!",\mathcal{X} = \{x_i\}_{i=1}^n\subset\mathbb{R}^p \mathcal{Y} = \{y_i\}_{i=1}^k\subset{\mathbb{R}^p} C_\mathcal{Y} \mathcal{X} C_{\mathcal{X}} \mathcal{Y} \left\|C_\mathcal{X} - \mathcal{C}_\mathcal{Y}\right\| \le \varepsilon \left\|C_{\mathcal{X}} - C_{\mathcal{Y}}\right\| k \mathcal{Y} \mathcal{X} \mathcal{Y} k \mathcal{X} \left\|C_{\mathcal{X}} - C_{\mathcal{Y}}\right\| \left\|\cdot\right\| \mathcal{Y} n,"['probability', 'statistics', 'machine-learning']"
43,Finding expectation of joint uniform continuous distribution without integrating,Finding expectation of joint uniform continuous distribution without integrating,,"From SOA sample 138: A machine consists of two components, whose lifetimes have the joint density function $$f(x,y)= \begin{cases} {1\over50}, & \text{for }x>0,y>0,x+y<10 \\ 0, & \text{otherwise} \end{cases}$$ The machine operates until both components fail.   Calculate the expected operational time of the machine. I was able to get the solution by deciding on case $Y>X$ , drawing a triangle with vertices at $(0,0)$ , $(0,10)$ , and $(5,5)$ and then integrating $\int_0^5 \int_{x}^{10-x}{y\over50}\ dy \ dx$ to get $2.5$ , and then doubling by symmetry for the case of $X>Y$ to get $5$ . However the SOA solution does it a different way that I am trying to understand: Suppose the component represented by the random variable $X$ fails last. This is represented by   the triangle with vertices at $(0, 0)$ , $(10, 0)$ and $(5, 5)$ . Because the density is uniform over this   region, the mean value of $X$ and thus the expected operational time of the machine is 5. By   symmetry, if the component represented by the random variable $Y$ fails last, the expected   operational time of the machine is also $5$ . Thus, the unconditional expected operational time of   the machine must be $5$ as well. I bolded the part that I do not understand. Where do they get $5$ just by looking at the triangle, which is $25$ in area?","From SOA sample 138: A machine consists of two components, whose lifetimes have the joint density function The machine operates until both components fail.   Calculate the expected operational time of the machine. I was able to get the solution by deciding on case , drawing a triangle with vertices at , , and and then integrating to get , and then doubling by symmetry for the case of to get . However the SOA solution does it a different way that I am trying to understand: Suppose the component represented by the random variable fails last. This is represented by   the triangle with vertices at , and . Because the density is uniform over this   region, the mean value of and thus the expected operational time of the machine is 5. By   symmetry, if the component represented by the random variable fails last, the expected   operational time of the machine is also . Thus, the unconditional expected operational time of   the machine must be as well. I bolded the part that I do not understand. Where do they get just by looking at the triangle, which is in area?","f(x,y)=
\begin{cases}
{1\over50}, & \text{for }x>0,y>0,x+y<10 \\
0, & \text{otherwise}
\end{cases} Y>X (0,0) (0,10) (5,5) \int_0^5 \int_{x}^{10-x}{y\over50}\ dy \ dx 2.5 X>Y 5 X (0, 0) (10, 0) (5, 5) X Y 5 5 5 25","['probability', 'statistics']"
44,probability that no two people are born on the same day: $n$ people and $k$ days,probability that no two people are born on the same day:  people and  days,n k,"Say we have $n$ people and $k$ days. What is the probability that NO two of the $n$ people are born on the same day? This is of course assuming that $n \leq k$ (otherwise the answer is $0$ by the pigeonhole principle!). I said the answer was: $k \choose n$$\cdot n! \cdot \frac{1}{k^n}$ because in order for this to happen, n distinct birthdays must be chosen, they can be arranged in any way amongst the $n$ people, and there are $k^n$ total arrangements. Is this correct?","Say we have people and days. What is the probability that NO two of the people are born on the same day? This is of course assuming that (otherwise the answer is by the pigeonhole principle!). I said the answer was: because in order for this to happen, n distinct birthdays must be chosen, they can be arranged in any way amongst the people, and there are total arrangements. Is this correct?",n k n n \leq k 0 k \choose n\cdot n! \cdot \frac{1}{k^n} n k^n,"['probability', 'statistics', 'birthday']"
45,"In question of ten married couples to be seated at five different tables, why do we not care about the other tables?","In question of ten married couples to be seated at five different tables, why do we not care about the other tables?",,"The solution to this problem, Ten married couples are to be seated at five different tables, with four people   at each table. Assume random seating, what is the expected number of   married couples that are seated at the same table? says that the probability of any individual married couple sitting at a table together is a Bernoulli random variable and can be calculated with $$P(X_i=1) = {{{18}\choose2}\over{{19}\choose3}}$$ where ${19}\choose3$ is all the combinations of people that can join one husband from couple $i$ in the three remaining places at the table and ${{18}\choose2}$ is the all the combinations of people that can join a couple $i$ in the two remaining places at the table. My question is, why are there not more possibilities to consider because of the many combinations of people sitting at the other tables? For example, although there is only ${19}\choose3$ combinations of people that can join one husband from couple $i$ in the three remaining places at the table, is there not ${{16}\choose4}{{12}\choose4}{{8}\choose4}{{4}\choose4}$ combinations of people who can sit at the other tables, multiplying the possibilities? Is this because these possibilities cancel each other out? Do we say $${{{18}\choose2}{{16}\choose4}{{12}\choose4}{{8}\choose4}{{4}\choose4}\over{{19}\choose3}{{16}\choose4}{{12}\choose4}{{8}\choose4}{{4}\choose4}}= {{{18}\choose2}\over{{19}\choose3}}$$ or is there a reason why that cannot be done? Or is there a reason it is unnecessary?","The solution to this problem, Ten married couples are to be seated at five different tables, with four people   at each table. Assume random seating, what is the expected number of   married couples that are seated at the same table? says that the probability of any individual married couple sitting at a table together is a Bernoulli random variable and can be calculated with where is all the combinations of people that can join one husband from couple in the three remaining places at the table and is the all the combinations of people that can join a couple in the two remaining places at the table. My question is, why are there not more possibilities to consider because of the many combinations of people sitting at the other tables? For example, although there is only combinations of people that can join one husband from couple in the three remaining places at the table, is there not combinations of people who can sit at the other tables, multiplying the possibilities? Is this because these possibilities cancel each other out? Do we say or is there a reason why that cannot be done? Or is there a reason it is unnecessary?",P(X_i=1) = {{{18}\choose2}\over{{19}\choose3}} {19}\choose3 i {{18}\choose2} i {19}\choose3 i {{16}\choose4}{{12}\choose4}{{8}\choose4}{{4}\choose4} {{{18}\choose2}{{16}\choose4}{{12}\choose4}{{8}\choose4}{{4}\choose4}\over{{19}\choose3}{{16}\choose4}{{12}\choose4}{{8}\choose4}{{4}\choose4}}= {{{18}\choose2}\over{{19}\choose3}},"['probability', 'combinatorics', 'statistics']"
46,"Showing $\operatorname{Cov}\left(\bar{X}_n,\frac{1}{n}\sum|X_i-\bar{X}_n|\right)=0$ for i.i.d standard normal $X_1,X_2,\ldots,X_n$",Showing  for i.i.d standard normal,"\operatorname{Cov}\left(\bar{X}_n,\frac{1}{n}\sum|X_i-\bar{X}_n|\right)=0 X_1,X_2,\ldots,X_n","Show that for $X_1,X_2,\ldots,X_n$ i.i.d. standard normal, $$\operatorname{Cov}\left(\bar{X}_n,\frac{1}{n}\sum|X_i-\bar{X}_n|\right)=0$$ where $$\bar{X}_n = \frac{1}{n}\sum X_i$$ What I do first is to write $$\operatorname{Cov}\left(\bar{X}_n,\frac{1}{n}|X_i-\bar{X}_n|\right) = \frac{1}{n}E\left(\bar{X}_n \cdot\sum|X_i-\bar{X}_n|\right)-\frac{1}{n}E(\bar{X}_n)E\left(\sum|X_i-\bar{X}_n|\right)$$ Now, I now that the second part is zero, since $E(X_i)=0$ but then, I have no idea what to do with the absolute values in the first part. Any suggestions?","Show that for i.i.d. standard normal, where What I do first is to write Now, I now that the second part is zero, since but then, I have no idea what to do with the absolute values in the first part. Any suggestions?","X_1,X_2,\ldots,X_n \operatorname{Cov}\left(\bar{X}_n,\frac{1}{n}\sum|X_i-\bar{X}_n|\right)=0 \bar{X}_n = \frac{1}{n}\sum X_i \operatorname{Cov}\left(\bar{X}_n,\frac{1}{n}|X_i-\bar{X}_n|\right) = \frac{1}{n}E\left(\bar{X}_n \cdot\sum|X_i-\bar{X}_n|\right)-\frac{1}{n}E(\bar{X}_n)E\left(\sum|X_i-\bar{X}_n|\right) E(X_i)=0","['statistics', 'normal-distribution', 'covariance', 'expected-value']"
47,Proving $E(\hat s^2)=V(\bar x)$ for finite population,Proving  for finite population,E(\hat s^2)=V(\bar x),"Population is $X_1,X_2,...,X_N$ with large but finite $N$ . Sampling indicator $Z_i \in(0,1)~ \forall i$ , such that $\sum^N _{i=1}Z_i=n$ and $Pr(Z_i=1)=\frac {n}{N}$ . Sample mean in this case is $\bar x=\frac{1}{n}\sum^N _{i=1}Z_iX_i$ , where $E(\bar x)=\bar X$ . Variance of the estimator is $V(\bar x)=(1-\frac {n}{N})\frac {S^2}{n}$ , where $S^2=\sum^N _{i=1}(X_i-\bar X)^2/(N-1)$ is the population variance. Sample variance is $\hat s^2=(1-\frac {n}{N})\frac {s^2}{n}$ , where $s^2=\sum^N _{i=1}Z_i(X_i-\bar x)^2/(n-1)$ . I want to show that $E(\hat s^2)=V(\bar x)$ , i.e.,the sample variance is an unbiased estimator. Note that $Z_i$ is the only random variable here, so does $\bar x$ , because $\bar x$ consists $Z_i$ . I derived the following but do not know how to proceed foward, could someone help me with this please? Thanks! My attempt: \begin{align} E(\hat s^2) &= \frac {1-\frac {n}{N}}{n(n-1)}E\bigl[ \sum^N_{i=1}Z_i(X_i-\bar x)^2 \bigr] \\ &=\frac {1-\frac {n}{N}}{n(n-1)} E\Bigl[ \sum^N_{i=1} Z_i \cdot \bigl( X_i -\bar X) + (\bar X-\bar x) \bigr)^2 \Bigr] \\ &= \frac {1-\frac {n}{N}}{n(n-1)}E\Bigl[\sum^N_{i=1} Z_i \cdot \bigl( (X_i-\bar X)^2+2(X_i-\bar X)(\bar X-\bar x)+(\bar X-\bar x)^2 \bigr) \Bigr]  \end{align} I know that $$E[\sum^N_{i=1}Z_i(X_i-\bar X)^2]=\sum^N_{i=1}E(Z_i)(X_i-\bar X)^2=\sum^N_{i=1}Pr(Z_i=1)(X_i-\bar X)^2=\frac{n}{N}\sum^N_{i=1}(X_i-\bar X)^2$$ How should I deal with the latter terms of $2(X_i-\bar X)(\bar X-\bar x)+(\bar X-\bar x)^2$ ? Any comment would be helpful!","Population is with large but finite . Sampling indicator , such that and . Sample mean in this case is , where . Variance of the estimator is , where is the population variance. Sample variance is , where . I want to show that , i.e.,the sample variance is an unbiased estimator. Note that is the only random variable here, so does , because consists . I derived the following but do not know how to proceed foward, could someone help me with this please? Thanks! My attempt: I know that How should I deal with the latter terms of ? Any comment would be helpful!","X_1,X_2,...,X_N N Z_i \in(0,1)~ \forall i \sum^N _{i=1}Z_i=n Pr(Z_i=1)=\frac {n}{N} \bar x=\frac{1}{n}\sum^N _{i=1}Z_iX_i E(\bar x)=\bar X V(\bar x)=(1-\frac {n}{N})\frac {S^2}{n} S^2=\sum^N _{i=1}(X_i-\bar X)^2/(N-1) \hat s^2=(1-\frac {n}{N})\frac {s^2}{n} s^2=\sum^N _{i=1}Z_i(X_i-\bar x)^2/(n-1) E(\hat s^2)=V(\bar x) Z_i \bar x \bar x Z_i \begin{align}
E(\hat s^2) &= \frac {1-\frac {n}{N}}{n(n-1)}E\bigl[ \sum^N_{i=1}Z_i(X_i-\bar x)^2 \bigr] \\
&=\frac {1-\frac {n}{N}}{n(n-1)} E\Bigl[ \sum^N_{i=1} Z_i \cdot \bigl( X_i -\bar X) + (\bar X-\bar x) \bigr)^2 \Bigr] \\
&= \frac {1-\frac {n}{N}}{n(n-1)}E\Bigl[\sum^N_{i=1} Z_i \cdot \bigl( (X_i-\bar X)^2+2(X_i-\bar X)(\bar X-\bar x)+(\bar X-\bar x)^2 \bigr) \Bigr] 
\end{align} E[\sum^N_{i=1}Z_i(X_i-\bar X)^2]=\sum^N_{i=1}E(Z_i)(X_i-\bar X)^2=\sum^N_{i=1}Pr(Z_i=1)(X_i-\bar X)^2=\frac{n}{N}\sum^N_{i=1}(X_i-\bar X)^2 2(X_i-\bar X)(\bar X-\bar x)+(\bar X-\bar x)^2","['probability', 'statistics', 'sampling']"
48,Conditional Probabilities for a Race? - Sequence of Dependent Events?,Conditional Probabilities for a Race? - Sequence of Dependent Events?,,"I've been getting stumped by what seems to be a super simple conditional probability question... 3 people run a race: A, B, and C. Based on what we know about about their past races, we estimate the probability of each person coming in $1^{st}$ , $2^{nd}$ , and $3^{rd}$ are... |   |  1st  |  2nd  |  3rd  | |---|-------|-------|-------| | A |  0.5  |  0.3  |  0.2  | | B |  0.3  |  0.2  |  0.5  | | C |  0.2  |  0.5  |  0.3  | How likely is it that A runs $1^{st}$ and B runs $2^{nd}$ Given that Person A wins the race, what is the probability that person B comes in second? Here's the main part that's confusing me... Shouldn't $P(B=2|A=1) = P(C=3|A=1)$ since the race will be deterministic as soon as we know 2 of the 3 finishers? I just can't seem to find a way to calculate these probabilities that satisfies that criterium. (Note: It's also possible that this is a trick question with impossible probabilities, in which case I'd really appreciate a derivation that can support this.)","I've been getting stumped by what seems to be a super simple conditional probability question... 3 people run a race: A, B, and C. Based on what we know about about their past races, we estimate the probability of each person coming in , , and are... |   |  1st  |  2nd  |  3rd  | |---|-------|-------|-------| | A |  0.5  |  0.3  |  0.2  | | B |  0.3  |  0.2  |  0.5  | | C |  0.2  |  0.5  |  0.3  | How likely is it that A runs and B runs Given that Person A wins the race, what is the probability that person B comes in second? Here's the main part that's confusing me... Shouldn't since the race will be deterministic as soon as we know 2 of the 3 finishers? I just can't seem to find a way to calculate these probabilities that satisfies that criterium. (Note: It's also possible that this is a trick question with impossible probabilities, in which case I'd really appreciate a derivation that can support this.)",1^{st} 2^{nd} 3^{rd} 1^{st} 2^{nd} P(B=2|A=1) = P(C=3|A=1),"['probability', 'statistics', 'bayesian', 'conditional-probability']"
49,Comparing Fisher Information of sample to that of statistic,Comparing Fisher Information of sample to that of statistic,,"Let $X_1,...,X_n$ be Bernoulli($p$) where $p$ is unknown, and $n>2$, and let $T=X_1+X_2$. My task is to calculate the information about $p$ in the entire sample and compare it to the information about $p$ given by the statistic. After a few lines of work, I obtain the following expression for information contained in the sample: $$I_X(p)= n*E_p[(\frac{X_1p^{-1}(1-p)+X_1+1}{1-p})^2] $$ To calculate this, I first calculated the information given by one observation, and then multiplied that information by $n$. Now, after some work, I obtained the following expression for  information contained in $T$: $$I_T(p)=E_p[(\frac{Tp^{-1}(1-p)-1}{1-p})^2]$$ Now, I know from previous questions that $T$ is sufficient for $p$. Hence, $I_X(p)$ should equal $I_T(p)$. However, I have no idea how I am to compare these two quantities, because one has an $n$, and the other has an $X_2$ (in the $T$). Any advice?","Let $X_1,...,X_n$ be Bernoulli($p$) where $p$ is unknown, and $n>2$, and let $T=X_1+X_2$. My task is to calculate the information about $p$ in the entire sample and compare it to the information about $p$ given by the statistic. After a few lines of work, I obtain the following expression for information contained in the sample: $$I_X(p)= n*E_p[(\frac{X_1p^{-1}(1-p)+X_1+1}{1-p})^2] $$ To calculate this, I first calculated the information given by one observation, and then multiplied that information by $n$. Now, after some work, I obtained the following expression for  information contained in $T$: $$I_T(p)=E_p[(\frac{Tp^{-1}(1-p)-1}{1-p})^2]$$ Now, I know from previous questions that $T$ is sufficient for $p$. Hence, $I_X(p)$ should equal $I_T(p)$. However, I have no idea how I am to compare these two quantities, because one has an $n$, and the other has an $X_2$ (in the $T$). Any advice?",,['statistics']
50,Sufficient statistic based on a random sample of size n where the pmf is $P_{\theta}(X=x) = c(\theta)2^{-x/\theta}$,Sufficient statistic based on a random sample of size n where the pmf is,P_{\theta}(X=x) = c(\theta)2^{-x/\theta},"so the question asks to find a sufficient statistic based on a sample of size n, where $X \sim f_{\theta}(x)$ and  \begin{equation} f_{\theta}(x) = P_{\theta}(X=x) = c(\theta) 2^{-x/\theta}, \quad x = \theta, \theta+1,..., \theta >0 \end{equation} and  \begin{equation} c(\theta) = 2^{1-1/\theta}(2^{1/\theta}-1) \end{equation} I derived that the joint pmf is  \begin{equation} P_{\theta}(X_1 = x_1,...,X_n = x_n) = c(\theta)^{n}2^{-1/\theta \sum x_{i}}\mathbb{I}_{\{X_{(1)}\geqslant \theta\}} \end{equation} My question is, in this case, is a sufficient statistic $T(x) = (\sum x_{i}, X_{(1)})$ or both $\sum x_{i}$ and $X_{(1)}$ can serve as a sufficient statistic?  Thanks so much for your time and consideration.","so the question asks to find a sufficient statistic based on a sample of size n, where $X \sim f_{\theta}(x)$ and  \begin{equation} f_{\theta}(x) = P_{\theta}(X=x) = c(\theta) 2^{-x/\theta}, \quad x = \theta, \theta+1,..., \theta >0 \end{equation} and  \begin{equation} c(\theta) = 2^{1-1/\theta}(2^{1/\theta}-1) \end{equation} I derived that the joint pmf is  \begin{equation} P_{\theta}(X_1 = x_1,...,X_n = x_n) = c(\theta)^{n}2^{-1/\theta \sum x_{i}}\mathbb{I}_{\{X_{(1)}\geqslant \theta\}} \end{equation} My question is, in this case, is a sufficient statistic $T(x) = (\sum x_{i}, X_{(1)})$ or both $\sum x_{i}$ and $X_{(1)}$ can serve as a sufficient statistic?  Thanks so much for your time and consideration.",,['statistics']
51,"What is ""$\ldots$"" called in English when it comes to counting rule for compound events?","What is """" called in English when it comes to counting rule for compound events?",\ldots,"Hi! How do you read this theory in English, mainly GenAm/RP? Theorem one point two. If an operation consists of k steps, of which the first can be done in n-subscript-one ways, for each of these the second step can be done in n-subscript-two ways, for each of the first two the third step can be done in n-subscript-three ways, and so forth, then the whole operation can be done in n-subscript-one times n-subscript-two ellipsis times n-subscript-k ways. Is "" $\ldots$ "" informally called ""all the way down to"" and formally ""and so forth""? In the second case, like ""r = 0,1,2,...,n"". How is this sentance said? r equals zero, one, two, and so on to n. r equals zero, one, two, and so forth to n. r equals zero, one, two, and so on n equals n. r equals zero, one, two, and so forth n equals n. Are they correct? What is your familiar way to say them?","Hi! How do you read this theory in English, mainly GenAm/RP? Theorem one point two. If an operation consists of k steps, of which the first can be done in n-subscript-one ways, for each of these the second step can be done in n-subscript-two ways, for each of the first two the third step can be done in n-subscript-three ways, and so forth, then the whole operation can be done in n-subscript-one times n-subscript-two ellipsis times n-subscript-k ways. Is "" "" informally called ""all the way down to"" and formally ""and so forth""? In the second case, like ""r = 0,1,2,...,n"". How is this sentance said? r equals zero, one, two, and so on to n. r equals zero, one, two, and so forth to n. r equals zero, one, two, and so on n equals n. r equals zero, one, two, and so forth n equals n. Are they correct? What is your familiar way to say them?",\ldots,"['probability', 'combinatorics', 'statistics']"
52,Gamma distribution family and sufficient statistic,Gamma distribution family and sufficient statistic,,"Let X $=X_1,...X_n$ be a random sample iid from the probability density function: $$ f(x;\theta)=\frac{\Gamma(\theta)\sin(\pi\theta)\theta^{1-\theta}}{\pi}e^{-\theta x}x^{-\theta}$$ $x>0, 0<\theta < 1$ Is the distribution a member of the exponential family of probability   distributions? we know that the exponential family member distribution have the following form: $$ f_x(x;\theta)=c(\theta)g(x)\exp \Big\{\sum_{j=1}^{l}Q_j(\theta)T_j(x) \Big\}$$ SOLUTION : $c(\theta)=\frac{\Gamma(\theta)\sin(\pi\theta)\theta^{1-\theta}}{\pi}$ $h(x)=1$ $\nu(\theta)=-\theta$ $T(x)=x + \log(x)$ However i am not sure how these were obtained ? I am aware that  $e^{-\theta x}x^{-\theta} = e^{-\theta(x+\log(x))}$. Then $T(x)$ contains all expression containing x and $c(\theta)$ everything containing $\theta$. What is the purpose of $h(x)$ and $\nu(\theta)?$ I am also interested in finding the sufficient statistic for parameter $\theta$. Now the joint density of $X_1,...,X_n$ is $$ f(x;\theta)= c(\theta)^n e^{-\theta \sum (x_1 + \log x_i)}$$ which comes from the fisher factorization. Therefore $\sum (x_1 + \log x_i)$ is sufficient statistic for $\theta$.","Let X $=X_1,...X_n$ be a random sample iid from the probability density function: $$ f(x;\theta)=\frac{\Gamma(\theta)\sin(\pi\theta)\theta^{1-\theta}}{\pi}e^{-\theta x}x^{-\theta}$$ $x>0, 0<\theta < 1$ Is the distribution a member of the exponential family of probability   distributions? we know that the exponential family member distribution have the following form: $$ f_x(x;\theta)=c(\theta)g(x)\exp \Big\{\sum_{j=1}^{l}Q_j(\theta)T_j(x) \Big\}$$ SOLUTION : $c(\theta)=\frac{\Gamma(\theta)\sin(\pi\theta)\theta^{1-\theta}}{\pi}$ $h(x)=1$ $\nu(\theta)=-\theta$ $T(x)=x + \log(x)$ However i am not sure how these were obtained ? I am aware that  $e^{-\theta x}x^{-\theta} = e^{-\theta(x+\log(x))}$. Then $T(x)$ contains all expression containing x and $c(\theta)$ everything containing $\theta$. What is the purpose of $h(x)$ and $\nu(\theta)?$ I am also interested in finding the sufficient statistic for parameter $\theta$. Now the joint density of $X_1,...,X_n$ is $$ f(x;\theta)= c(\theta)^n e^{-\theta \sum (x_1 + \log x_i)}$$ which comes from the fisher factorization. Therefore $\sum (x_1 + \log x_i)$ is sufficient statistic for $\theta$.",,"['statistics', 'exponential-distribution', 'parameter-estimation']"
53,"Change of variables technique to show that for iid standard normals $X_1,X_2$, $Y_1 = X_1^2 + X_2^2$ has a $\chi^2(2)$ distribution","Change of variables technique to show that for iid standard normals ,  has a  distribution","X_1,X_2 Y_1 = X_1^2 + X_2^2 \chi^2(2)","Suppose $X_1$ and $X_2$ are iid with a common standard normal distribution. Find the joint pdf of $Y_1 = X_1^2 + X_2^2$ and $Y_2=X_2$ and the marginal pdf of $Y_1$. It's easy to see that $Y_1$ has a $\chi^2(2)$ distribution, but this problem asks to show it using change of variables technique.  Here, I can find the Jacobian $\partial(x_1,x_2) / \partial(y_1,y_2) = \frac{1}{2x_1}$, where $x_1^2 = y_1 - y_2^2$. Hence we must have $$f_{Y_1,Y_2}(y_1,y_2) = \frac{1}{2x_1} \frac{1}{2\pi} e^{-y_1^2}.$$ However, in this case we have $x_1 = \pm \sqrt{y_1 - y_2^2}$. How can we integrate $y_2$ out from this pdf to get the marginal pdf of $Y_1$?","Suppose $X_1$ and $X_2$ are iid with a common standard normal distribution. Find the joint pdf of $Y_1 = X_1^2 + X_2^2$ and $Y_2=X_2$ and the marginal pdf of $Y_1$. It's easy to see that $Y_1$ has a $\chi^2(2)$ distribution, but this problem asks to show it using change of variables technique.  Here, I can find the Jacobian $\partial(x_1,x_2) / \partial(y_1,y_2) = \frac{1}{2x_1}$, where $x_1^2 = y_1 - y_2^2$. Hence we must have $$f_{Y_1,Y_2}(y_1,y_2) = \frac{1}{2x_1} \frac{1}{2\pi} e^{-y_1^2}.$$ However, in this case we have $x_1 = \pm \sqrt{y_1 - y_2^2}$. How can we integrate $y_2$ out from this pdf to get the marginal pdf of $Y_1$?",,"['calculus', 'integration', 'statistics', 'probability-distributions']"
54,Does comparing two p-values make sense?,Does comparing two p-values make sense?,,"Does comparing two p-values make sense? For example, the p-value of factors willingness to pay and the number of owned cars is 0.3. The p-value of willingness to pay and the number of owned pets is 0.6. Can I claim that the number of owned cars has a stronger relationship with willingness to pay and the number of owned cars explains willingness to pay more than the number of owned pets does? I know that p-value with less than 0.05 is significant but not sure if the p-value is larger then 0.05 we can compare two p-values.","Does comparing two p-values make sense? For example, the p-value of factors willingness to pay and the number of owned cars is 0.3. The p-value of willingness to pay and the number of owned pets is 0.6. Can I claim that the number of owned cars has a stronger relationship with willingness to pay and the number of owned cars explains willingness to pay more than the number of owned pets does? I know that p-value with less than 0.05 is significant but not sure if the p-value is larger then 0.05 we can compare two p-values.",,"['probability', 'statistics', 'statistical-inference']"
55,Show that the quotient $X/Y$ has the Cauchy distribution.,Show that the quotient  has the Cauchy distribution.,X/Y,"I have a problem with which I'm struggling for a while. Suppose that the random variables $X$ and $Y$ are independent   and that each has the standard normal distribution.   Show that the quotient $X/Y$ has the Cauchy distribution. I know how to solve it by Jacobian and multivariable transformation but I tried to do this a different way and I can't spot a mistake but my answer gives a contradiction. My solution: Let $G$ be the cdf of $X/Y $, then \begin{align*} G(c) &= \mathbb{P}(X/Y \leq c) \\ &= \mathbb{P}(X/Y \leq c \mid Y > 0)\mathbb{P}(Y > 0) + \mathbb{P}(X/Y \leq c \mid Y < 0)\mathbb{P}(Y < 0) \\ &= \frac{1}{2} \big[ \mathbb{P}(X/Y \leq c \mid Y > 0) + \mathbb{P}(X/Y \leq c \mid Y < 0) \big] \\ &= \frac{1}{2} \big[ \mathbb{P}(X \leq cY) + \mathbb{P}(X \geq cY) \big] \\ &= \frac{1}{2}. \end{align*} Where is the mistake?","I have a problem with which I'm struggling for a while. Suppose that the random variables $X$ and $Y$ are independent   and that each has the standard normal distribution.   Show that the quotient $X/Y$ has the Cauchy distribution. I know how to solve it by Jacobian and multivariable transformation but I tried to do this a different way and I can't spot a mistake but my answer gives a contradiction. My solution: Let $G$ be the cdf of $X/Y $, then \begin{align*} G(c) &= \mathbb{P}(X/Y \leq c) \\ &= \mathbb{P}(X/Y \leq c \mid Y > 0)\mathbb{P}(Y > 0) + \mathbb{P}(X/Y \leq c \mid Y < 0)\mathbb{P}(Y < 0) \\ &= \frac{1}{2} \big[ \mathbb{P}(X/Y \leq c \mid Y > 0) + \mathbb{P}(X/Y \leq c \mid Y < 0) \big] \\ &= \frac{1}{2} \big[ \mathbb{P}(X \leq cY) + \mathbb{P}(X \geq cY) \big] \\ &= \frac{1}{2}. \end{align*} Where is the mistake?",,"['probability', 'statistics']"
56,minimum possible penalty of an arbitrary classifier?,minimum possible penalty of an arbitrary classifier?,,"I'm self-studying some ML over the summer and ran into a question that I don't really understand. I don't really understand what (i) is asking. Is the minimum possible penalty not the trivial case in which you correctly predict the test example for a total penalty of 0? They mention multiple cases so it seems like they're asking for something else, but I guess I don't understand what the question is even asking. Would they not phrase the question as expected or average penalty if they were looking for something more? Any one know what I'm missing?","I'm self-studying some ML over the summer and ran into a question that I don't really understand. I don't really understand what (i) is asking. Is the minimum possible penalty not the trivial case in which you correctly predict the test example for a total penalty of 0? They mention multiple cases so it seems like they're asking for something else, but I guess I don't understand what the question is even asking. Would they not phrase the question as expected or average penalty if they were looking for something more? Any one know what I'm missing?",,"['probability', 'statistics', 'machine-learning']"
57,How to find one-sided confidence interval for exponential law,How to find one-sided confidence interval for exponential law,,"Question: Let $X_1,\ldots,X_n \sim \operatorname{Exp}(\lambda)$ iid for some $\lambda>0$. Find an expression for the ""left"" one-sided confidence uniformly most powerful interval for a threshold $1-\alpha$ for the parameter $\lambda>0$ My attempt: We're looking for an interval of the form $[\delta_\alpha,\infty)$ such that $\Bbb P[\lambda\in [\delta_\alpha,\infty)]\geq1-\alpha\ (\iff\Bbb P[\lambda<\delta_\alpha]\leq1-\alpha)$ first we find the $1-\alpha$-quantile: $$\lambda e^{-\lambda x}=1-\alpha\iff -\lambda x=\log \left( \frac{1-\alpha}{\lambda} \right)\iff x=q_{1-\alpha}=-\frac{\log(\frac{1-\alpha}{\lambda})}{\lambda}$$ Then the statistic test we're looking for is $\delta=\Bbb 1\{\tau>q_{1-\alpha}\}$ where $\tau=\sum\limits_{i=1}^n T(X_i)$ where $T$ is from the exponential family form of $\lambda e^{-\lambda x}=\exp\{\eta(\lambda)T(x)-d(\lambda)+S(x)\}=\exp\{\log(\lambda)-\lambda x\}$ But in order to apply the theorem that tells us what the wirght test function is $\eta$ must be strictly increasing and in $C^1$ so we have to choose $\eta(\lambda)=\lambda$ and $T(x)=-x\implies \tau=-\sum\limits_{i=1}^nX_i$ and at this point I feel like I am doing something wrong... Any help is welcome!","Question: Let $X_1,\ldots,X_n \sim \operatorname{Exp}(\lambda)$ iid for some $\lambda>0$. Find an expression for the ""left"" one-sided confidence uniformly most powerful interval for a threshold $1-\alpha$ for the parameter $\lambda>0$ My attempt: We're looking for an interval of the form $[\delta_\alpha,\infty)$ such that $\Bbb P[\lambda\in [\delta_\alpha,\infty)]\geq1-\alpha\ (\iff\Bbb P[\lambda<\delta_\alpha]\leq1-\alpha)$ first we find the $1-\alpha$-quantile: $$\lambda e^{-\lambda x}=1-\alpha\iff -\lambda x=\log \left( \frac{1-\alpha}{\lambda} \right)\iff x=q_{1-\alpha}=-\frac{\log(\frac{1-\alpha}{\lambda})}{\lambda}$$ Then the statistic test we're looking for is $\delta=\Bbb 1\{\tau>q_{1-\alpha}\}$ where $\tau=\sum\limits_{i=1}^n T(X_i)$ where $T$ is from the exponential family form of $\lambda e^{-\lambda x}=\exp\{\eta(\lambda)T(x)-d(\lambda)+S(x)\}=\exp\{\log(\lambda)-\lambda x\}$ But in order to apply the theorem that tells us what the wirght test function is $\eta$ must be strictly increasing and in $C^1$ so we have to choose $\eta(\lambda)=\lambda$ and $T(x)=-x\implies \tau=-\sum\limits_{i=1}^nX_i$ and at this point I feel like I am doing something wrong... Any help is welcome!",,"['statistics', 'statistical-inference', 'confidence-interval']"
58,Why don't terms cancel in this application of Bayes' Rule?,Why don't terms cancel in this application of Bayes' Rule?,,"I have been looking at several different sites trying to wrap my head around the content of Sebastian Thrun's Intro AI course on Udacity. At the moment I'm trying to understand the lesson on ""explaining away"" in the case of two confounding causes. I found this SE Mathematics article but the top answer just left me with more questions. Let  S = It is sunny R = I got a raise H = I am happy The first step in the article linked above is to go from P(R|H,S) to P(R,H,S) / P(H,S) I understand how to make that step. What I don't understand is why the denominator doesn't cancel out the P(S) and the P(H) in the numerator. I thought that P(R,H,S) was the same as P(R)P(H)P(S), so dividing that by P(H)P(S) would leave you with P(R). I've always struggled with math, so I'm sure I'm just missing something dumb.","I have been looking at several different sites trying to wrap my head around the content of Sebastian Thrun's Intro AI course on Udacity. At the moment I'm trying to understand the lesson on ""explaining away"" in the case of two confounding causes. I found this SE Mathematics article but the top answer just left me with more questions. Let  S = It is sunny R = I got a raise H = I am happy The first step in the article linked above is to go from P(R|H,S) to P(R,H,S) / P(H,S) I understand how to make that step. What I don't understand is why the denominator doesn't cancel out the P(S) and the P(H) in the numerator. I thought that P(R,H,S) was the same as P(R)P(H)P(S), so dividing that by P(H)P(S) would leave you with P(R). I've always struggled with math, so I'm sure I'm just missing something dumb.",,"['probability', 'statistics', 'bayes-theorem']"
59,Ranking participants based on tiers and totals,Ranking participants based on tiers and totals,,"I am trying to rank participants based on sets of data that I have. The data used is for a competition. In this competition, you can participate in X amount of events , at the end of the event you participate in you get ranked in a Tier (eg from Tier 1 to Tier 6). Example: Particpants  Tier 1 Tier 2 Tier 3 Total John           2       3     2      7 Smith          1       2     4      7 Tom            3       1     1      5 In this example John was ranked in Tier 1 for 2 events out of the Total 7 he signed up for. The issue I'm having is that I am unsure what formula to use that would rank the participants, the ranking would take into consideration the amount of events you participated in (the higher the better) and the Tier you got per event (the more you have in Tier 1 the better etc). Does such a formula exist? Please tell me if this seems to complex to calculate.","I am trying to rank participants based on sets of data that I have. The data used is for a competition. In this competition, you can participate in X amount of events , at the end of the event you participate in you get ranked in a Tier (eg from Tier 1 to Tier 6). Example: Particpants  Tier 1 Tier 2 Tier 3 Total John           2       3     2      7 Smith          1       2     4      7 Tom            3       1     1      5 In this example John was ranked in Tier 1 for 2 events out of the Total 7 he signed up for. The issue I'm having is that I am unsure what formula to use that would rank the participants, the ranking would take into consideration the amount of events you participated in (the higher the better) and the Tier you got per event (the more you have in Tier 1 the better etc). Does such a formula exist? Please tell me if this seems to complex to calculate.",,"['statistics', 'page-rank']"
60,Determining the statistical significance of the performance of a gambler,Determining the statistical significance of the performance of a gambler,,"Imagine someone claims they win significantly more than they lose when betting on roulette. Presuming that it were possible to have a winning system how could you calculate the statistical significance of their claim? The roulette table has no ""edge"" (i.e. no zero/double zero...). The issue comes with the fact that they are able to change their stake in addition to their odds. Even if they were hopeless at guessing and were wrong far more often than not, provided they only placed small losing bets and very large winning bets they would still come out on top. Their largest bets are 10, their smallest is 1, they are not simply making ever greater bets to recoup their losses. I do not believe there is such a thing as a winning strategy and have no intention of testing this, so please give your answer safe in the knowledge that it won't inspire me to gamble myself into the poor house.","Imagine someone claims they win significantly more than they lose when betting on roulette. Presuming that it were possible to have a winning system how could you calculate the statistical significance of their claim? The roulette table has no ""edge"" (i.e. no zero/double zero...). The issue comes with the fact that they are able to change their stake in addition to their odds. Even if they were hopeless at guessing and were wrong far more often than not, provided they only placed small losing bets and very large winning bets they would still come out on top. Their largest bets are 10, their smallest is 1, they are not simply making ever greater bets to recoup their losses. I do not believe there is such a thing as a winning strategy and have no intention of testing this, so please give your answer safe in the knowledge that it won't inspire me to gamble myself into the poor house.",,"['probability', 'statistics', 'gambling']"
61,Hypothesis testing - Experiment with replacement,Hypothesis testing - Experiment with replacement,,"Exercise : A box contains 4 balls out of which $\theta$ are white and $4-\theta$ are black. Suppose that you want to check the null hypothesis $H_0 : \theta =2$ against the alternative $H_1 : \theta \neq 2$ . You draw 2 balls with replacement from the box and if they are both of the same color you reject the null hypothesis. i) Calculate the confidence level $a$ of the test above. ii) If the box contains 3 white balls, calculate the probability of the type two error for the test above. Question : First of all doea the last phrase means that you draw one ball first and then replace it and draw a second one too? Can someone please clarify me the test mentioned? Generally, I know that : $$a = \mathbb{P}(reject H_0 | H_0 true)$$ How would I express this probability though ? Obviously due to replacement he events are independent and then the probability of drawing 2 of the same color is : $$\mathbb{P}(2black) = \mathbb{P}(black)\cdot  \mathbb{P}(black) = \frac{(4- \theta)^2}{16}$$ $$\mathbb{P}(2white) = \mathbb{P}(white) \cdot  \mathbb{P}(white) = \frac{\theta^2}{16}$$ Also the type II error is : $$P(accept H_0 | H_1 true)$$ Can someone help me formulate the expression for $a$ ? I would really appreciate a thorough explanation.","Exercise : A box contains 4 balls out of which are white and are black. Suppose that you want to check the null hypothesis against the alternative . You draw 2 balls with replacement from the box and if they are both of the same color you reject the null hypothesis. i) Calculate the confidence level of the test above. ii) If the box contains 3 white balls, calculate the probability of the type two error for the test above. Question : First of all doea the last phrase means that you draw one ball first and then replace it and draw a second one too? Can someone please clarify me the test mentioned? Generally, I know that : How would I express this probability though ? Obviously due to replacement he events are independent and then the probability of drawing 2 of the same color is : Also the type II error is : Can someone help me formulate the expression for ? I would really appreciate a thorough explanation.",\theta 4-\theta H_0 : \theta =2 H_1 : \theta \neq 2 a a = \mathbb{P}(reject H_0 | H_0 true) \mathbb{P}(2black) = \mathbb{P}(black)\cdot  \mathbb{P}(black) = \frac{(4- \theta)^2}{16} \mathbb{P}(2white) = \mathbb{P}(white) \cdot  \mathbb{P}(white) = \frac{\theta^2}{16} P(accept H_0 | H_1 true) a,"['probability', 'statistics', 'probability-distributions', 'hypothesis-testing']"
62,Is it possible to characterize the family of distributions where $\frac{d}{dy}(E[X\mid X>y])\geq1$?,Is it possible to characterize the family of distributions where ?,\frac{d}{dy}(E[X\mid X>y])\geq1,"I have the following question, any help is greatly appreciated. Thanks! Let $Q(y)=E[X\mid X>y]$ , the truncated expected value of a given distribution. Is it possible to characterize the family of distributions where $\dfrac{dQ}{dy}\geq1$ ? I know that $$\frac{dQ}{dy}=h(y)(Q(y)-y)$$ where $h(y)$ is the hazard rate at $y$ . But I do not know how to proceed from here. Thanks!","I have the following question, any help is greatly appreciated. Thanks! Let , the truncated expected value of a given distribution. Is it possible to characterize the family of distributions where ? I know that where is the hazard rate at . But I do not know how to proceed from here. Thanks!",Q(y)=E[X\mid X>y] \dfrac{dQ}{dy}\geq1 \frac{dQ}{dy}=h(y)(Q(y)-y) h(y) y,"['probability', 'statistics', 'probability-distributions']"
63,Distinguishing independent Bernoulli trials from a 2-state Markov Chain,Distinguishing independent Bernoulli trials from a 2-state Markov Chain,,"Given is a sequence of zeros and ones $x=(x_1,\dots,x_n)$ that could have been be drawn in one of two ways: 1) as success indicators in Bernoulli experiments with probability of success p (e.g. by tossing a biased coin), or 2) as sequence of states (0 or 1) in a random realisation of a Markov chain with {a transition probabilities matrix $\mathbf{P}.$ The challenge is to determine which way the given data were actually produced and how to estimate the corresponding parameters $p$ of $\mathbf{P}.$","Given is a sequence of zeros and ones $x=(x_1,\dots,x_n)$ that could have been be drawn in one of two ways: 1) as success indicators in Bernoulli experiments with probability of success p (e.g. by tossing a biased coin), or 2) as sequence of states (0 or 1) in a random realisation of a Markov chain with {a transition probabilities matrix $\mathbf{P}.$ The challenge is to determine which way the given data were actually produced and how to estimate the corresponding parameters $p$ of $\mathbf{P}.$",,"['probability', 'statistics']"
64,Probability of equally likely events,Probability of equally likely events,,"I know that the probabilities of 2 equally-likely events is 0.5. Due to the fact that if i repeat the experiment for $N\rightarrow \infty$ the frequences of the 2 events are the same. But, going to a deeper level, why this happens ?","I know that the probabilities of 2 equally-likely events is 0.5. Due to the fact that if i repeat the experiment for $N\rightarrow \infty$ the frequences of the 2 events are the same. But, going to a deeper level, why this happens ?",,"['probability', 'statistics']"
65,Find the probability of the type I error and type II error,Find the probability of the type I error and type II error,,"For a Poisson arrival process with parameter $\lambda$ per hour. Let $Y$ be the number of arrivals in a ten-hour period. Find (i) the probability of the type I error ($\alpha$); (ii) the probability of type II error ($\beta$) at $\lambda = 3.2$ for a test with rejection region  $RR = \{Y : Y > 24 \}$, in testing $H_0$: $\lambda = 2$ vs $H_1$:  $\lambda > 2$.  Then (iii) adjust the $RR$ so the significance level is the closest to $0.05$. what I have already done: 1) I think the way that I to have solve for $\alpha$ is by calculating the $1-P(Y \le 24)$ with $\lambda =20$. which I get $\alpha = .15677$. 2) Then I solved for $\beta$ using $P(Y \le 24)$ with $\lambda = 32$. I get $\beta  = .0881$. 3) For the last part I used $1-P(Y \le c)$ guessing which value of $c$ would give me $\alpha =.05$. I got that $c =27$ because it gives me $\alpha = .05248$. Am I understanding this correctly?","For a Poisson arrival process with parameter $\lambda$ per hour. Let $Y$ be the number of arrivals in a ten-hour period. Find (i) the probability of the type I error ($\alpha$); (ii) the probability of type II error ($\beta$) at $\lambda = 3.2$ for a test with rejection region  $RR = \{Y : Y > 24 \}$, in testing $H_0$: $\lambda = 2$ vs $H_1$:  $\lambda > 2$.  Then (iii) adjust the $RR$ so the significance level is the closest to $0.05$. what I have already done: 1) I think the way that I to have solve for $\alpha$ is by calculating the $1-P(Y \le 24)$ with $\lambda =20$. which I get $\alpha = .15677$. 2) Then I solved for $\beta$ using $P(Y \le 24)$ with $\lambda = 32$. I get $\beta  = .0881$. 3) For the last part I used $1-P(Y \le c)$ guessing which value of $c$ would give me $\alpha =.05$. I got that $c =27$ because it gives me $\alpha = .05248$. Am I understanding this correctly?",,"['probability', 'statistics', 'probability-distributions']"
66,Does the confidence interval that maximizes the parameter estimate have nominal coverage?,Does the confidence interval that maximizes the parameter estimate have nominal coverage?,,"Assume there are two confidence intervals for parameters $\theta_1$ and $\theta_2$, $C_1$ and $C_2$ with upper and lower bounds $[l_1,u_1]$ and $[l_2,u_2]$, respectively. Assume the intervals have nominal coverage $1-\alpha$. The parameter estimates are $\hat{\theta}_1$ and $\hat{\theta}_2$. Now I always (in replications of the experiment) choose the interval with the higher estimate. Does this interval still have nominal coverage? Formally define $$g:=\begin{cases} 1 \quad \text{if} \ \hat{\theta}_1 > \hat{\theta}_2 \\ 2 \quad \text{if} \ \hat{\theta}_1 \le \hat{\theta}_2 \end{cases}$$ with interval  $C_g=[l_g,u_g]$. What is $P(\theta_d \in [l_g,u_g])$? Remark 1 : This seems to hold for two intervals, but fails for generalizations to more than two. I am looking for a proof of this result or a starting point. Remark 2 : I would also be interested if this problem is discussed anywhere in the literature and under which keyword / topic. Remark 3 : The problem can be understood in two ways. 1) The one population case where data $X_n$ are sampled from the same population and two different parameters are estimated on $X_n$ (e.g. mean and median, see BruceET's answer). 2) The two population case where $X_{n_1}$ and $X_{n_2}$ are sampled from two populations with $\theta_1$ and $\theta_2$ the same type of parameters (e.g. both means of potentially different values; this was my original intention with this question). Edit: Based on BruceET's answer I programmed a simulation. It shows good nominal coverage of two-sided intervals. This simulation concerns the (1) scenario in remark 3. n=15 reps=10^5 true_mean = 100 # = true_median in case of normal distribution  set.seed(12345) cover_m = cover_med = cover_g = numeric() for(i in 1:reps){   x   = rnorm(n, true_mean, 10)   m   = mean(x)   med = median(x)   g   = med > m   CI_m   = t.test(x)$conf.int[1:2]   CI_med = wilcox.test(x, conf.int=T)$conf.int[1:2]   CI_g   = CI_m * (1-g) + CI_med * g   cover_m[i]   = CI_m[1] <= true_mean & CI_m[2] >= true_mean   cover_med[i] = CI_med[1] <= true_mean & CI_med[2] >= true_mean   cover_g[i]   = CI_g[1] <= true_mean & CI_g[2] >= true_mean }  apply( cbind(cover_m,cover_med,cover_g), 2,mean)  >cover_m cover_med   cover_g  >0.95278   0.95097   0.95197","Assume there are two confidence intervals for parameters $\theta_1$ and $\theta_2$, $C_1$ and $C_2$ with upper and lower bounds $[l_1,u_1]$ and $[l_2,u_2]$, respectively. Assume the intervals have nominal coverage $1-\alpha$. The parameter estimates are $\hat{\theta}_1$ and $\hat{\theta}_2$. Now I always (in replications of the experiment) choose the interval with the higher estimate. Does this interval still have nominal coverage? Formally define $$g:=\begin{cases} 1 \quad \text{if} \ \hat{\theta}_1 > \hat{\theta}_2 \\ 2 \quad \text{if} \ \hat{\theta}_1 \le \hat{\theta}_2 \end{cases}$$ with interval  $C_g=[l_g,u_g]$. What is $P(\theta_d \in [l_g,u_g])$? Remark 1 : This seems to hold for two intervals, but fails for generalizations to more than two. I am looking for a proof of this result or a starting point. Remark 2 : I would also be interested if this problem is discussed anywhere in the literature and under which keyword / topic. Remark 3 : The problem can be understood in two ways. 1) The one population case where data $X_n$ are sampled from the same population and two different parameters are estimated on $X_n$ (e.g. mean and median, see BruceET's answer). 2) The two population case where $X_{n_1}$ and $X_{n_2}$ are sampled from two populations with $\theta_1$ and $\theta_2$ the same type of parameters (e.g. both means of potentially different values; this was my original intention with this question). Edit: Based on BruceET's answer I programmed a simulation. It shows good nominal coverage of two-sided intervals. This simulation concerns the (1) scenario in remark 3. n=15 reps=10^5 true_mean = 100 # = true_median in case of normal distribution  set.seed(12345) cover_m = cover_med = cover_g = numeric() for(i in 1:reps){   x   = rnorm(n, true_mean, 10)   m   = mean(x)   med = median(x)   g   = med > m   CI_m   = t.test(x)$conf.int[1:2]   CI_med = wilcox.test(x, conf.int=T)$conf.int[1:2]   CI_g   = CI_m * (1-g) + CI_med * g   cover_m[i]   = CI_m[1] <= true_mean & CI_m[2] >= true_mean   cover_med[i] = CI_med[1] <= true_mean & CI_med[2] >= true_mean   cover_g[i]   = CI_g[1] <= true_mean & CI_g[2] >= true_mean }  apply( cbind(cover_m,cover_med,cover_g), 2,mean)  >cover_m cover_med   cover_g  >0.95278   0.95097   0.95197",,"['statistics', 'statistical-inference', 'confidence-interval']"
67,Why was the word “confidence” introduced into statistical practice? What does it convey that “probability” does not?,Why was the word “confidence” introduced into statistical practice? What does it convey that “probability” does not?,,"Edit :Hagen von Eitzen also asks about the word ""likelyhood"".","Edit :Hagen von Eitzen also asks about the word ""likelyhood"".",,"['probability', 'statistics', 'discrete-mathematics']"
68,Continuous random variable is a mathematical trick,Continuous random variable is a mathematical trick,,"Measuring real (physical) events, a random variable can assume only discrete values. Is the use of continuous random variables a mathematical trick cause: it's easier to work with real number ? If yes, are you able to explain this in more detail ?","Measuring real (physical) events, a random variable can assume only discrete values. Is the use of continuous random variables a mathematical trick cause: it's easier to work with real number ? If yes, are you able to explain this in more detail ?",,"['probability', 'statistics']"
69,How can I find the Z score of 0.05?,How can I find the Z score of 0.05?,,"This is the question: To estimate the average speed of cars on a specific highway, an investigator collected speed data from a random sample of 75 cars driving on the highway. The sample mean and sample standard deviation are 58 miles per hour and 15 miles per hour, respectively. Construct a 90% confidence interval for the mean speed. I have the answer for it, and this is the answer: But, I don't understand why Z0.05 =1.645. On the  Standard Normal Distribution Table, P(Z < -1.645) = 0.05. Therefore, Z0.05 should be -1.645 instead of 1.645","This is the question: To estimate the average speed of cars on a specific highway, an investigator collected speed data from a random sample of 75 cars driving on the highway. The sample mean and sample standard deviation are 58 miles per hour and 15 miles per hour, respectively. Construct a 90% confidence interval for the mean speed. I have the answer for it, and this is the answer: But, I don't understand why Z0.05 =1.645. On the  Standard Normal Distribution Table, P(Z < -1.645) = 0.05. Therefore, Z0.05 should be -1.645 instead of 1.645",,"['probability', 'statistics', 'normal-distribution']"
70,Consistency of an unusual estimator for a binomial parameter,Consistency of an unusual estimator for a binomial parameter,,"I have a random sample $X_1, \ldots, X_n$ from a $\operatorname{Bi}(N,p)$ population. How do I show that the estimator $$\hat{p} = \frac{\bar{X}}{\max(X_1,\ldots,X_n)}$$ is consistent? The normal way I would approach such a question is to take the expectation and variance of the estimator and use that $\operatorname{MSE}(\hat{p})=\operatorname{Var}(\hat{p}) + \operatorname{Bias}(\hat{p})^2$, but for a ratio of random variables this would be incredibly messy. Is there an easier alternative?","I have a random sample $X_1, \ldots, X_n$ from a $\operatorname{Bi}(N,p)$ population. How do I show that the estimator $$\hat{p} = \frac{\bar{X}}{\max(X_1,\ldots,X_n)}$$ is consistent? The normal way I would approach such a question is to take the expectation and variance of the estimator and use that $\operatorname{MSE}(\hat{p})=\operatorname{Var}(\hat{p}) + \operatorname{Bias}(\hat{p})^2$, but for a ratio of random variables this would be incredibly messy. Is there an easier alternative?",,"['statistics', 'estimation', 'parameter-estimation']"
71,Bayesian parameter estimation for equation $r_t = Z_t^T\beta$?,Bayesian parameter estimation for equation ?,r_t = Z_t^T\beta,"Consider $r_t = \mathbb{E}[Z_t]^T\beta$; $t= 1, 2, 3, \cdots$, where $r_t \in \mathbb{R}$, $\beta \in \mathbb{R}^d$ and $Z_t$ is a $d$-dimensional random vector. Let's say $\beta$ is an unknown parameter and we would like to estimate it with a Bayesian approach by observing $r_t, Z_t$ for $t=1, 2, 3, \cdots$ (There is no iid assumption on random variables $Z_t$ and their distribution is unknown).How should we proceed? Any ideas? My Approach: In the case that $d=1$, we may say $\mathbb{E}[Z_t] = \frac{1}{\beta}r_t$, and then say that assuming $\frac{1}{\beta} \sim f_\theta$ as a prior and $Z_t = \frac{1}{\beta}r_t$ we get a prior on $Z_t$. Then, we can update $\theta$ with posterior based on our observation $Z_t = z_t$. I have two questions here: First, is my understanding correct in the case that $d=1$? How can I extend it to $d > 1$?","Consider $r_t = \mathbb{E}[Z_t]^T\beta$; $t= 1, 2, 3, \cdots$, where $r_t \in \mathbb{R}$, $\beta \in \mathbb{R}^d$ and $Z_t$ is a $d$-dimensional random vector. Let's say $\beta$ is an unknown parameter and we would like to estimate it with a Bayesian approach by observing $r_t, Z_t$ for $t=1, 2, 3, \cdots$ (There is no iid assumption on random variables $Z_t$ and their distribution is unknown).How should we proceed? Any ideas? My Approach: In the case that $d=1$, we may say $\mathbb{E}[Z_t] = \frac{1}{\beta}r_t$, and then say that assuming $\frac{1}{\beta} \sim f_\theta$ as a prior and $Z_t = \frac{1}{\beta}r_t$ we get a prior on $Z_t$. Then, we can update $\theta$ with posterior based on our observation $Z_t = z_t$. I have two questions here: First, is my understanding correct in the case that $d=1$? How can I extend it to $d > 1$?",,"['probability', 'statistics', 'estimation', 'bayesian', 'parameter-estimation']"
72,In Linear Modelling Why Would I Keep $X_2$ but drop $X_2$ and $X_3$?,In Linear Modelling Why Would I Keep  but drop  and ?,X_2 X_2 X_3,"I'm having trouble with some intuition in Linear Statistical Modelling. I'm working with some data with three predictor variables $X_1$, $X_2$ and $X_3$. I've calculated the $F$ test for whether $X_2$ should be retained in the model containing just $X_1$ and $X_2$. Similarly I've calculated the $F$ test for whether $X_2$ and $X_3$ should be retained in the model containing $X_1$, $X_2$ and $X_3$. The conclusion from the first test is to retain $X_2$.  The $p$-value is less than $0.05$. The conclusion from the second test is to drop $X_2$ and $X_3$.  The $p$-value is greater than $0.1$. So my question is, is this not counter-intuitive?  How could adding another variable $X_3$ make things worse for $X_2$ than it was with just $X_2$ alone? My feeling is that I have made a calculation error because it seems the $p$-value should only get smaller with more information not larger. Any insight into this matter would be greatly apprecaited, thank you! I can't show you the exact data without getting fired.  But here's a baby data set that illustrates the same issue.  The $F$ test for whether you can drop $X_2$ in the model with $Y, X_1, X_2$ has $p$-value $0.06$ while the $F$ test for whether you can drop $X_2$ and $X_3$ in the model with $Y, X_1, X_2, X_3$ is $0.14$.  So how can it get larger like that?  This indicates you need $X_2$ on top of $X_1$ but you can get rid of both $X_2$ and $X_3$ on top of $X_1$.  To me that's a contradiction.  Am I doing something wrong here? $$ Y\ \ \ X_1\ \ \ X_2\ \ \ X_3\\ 48.0\ \ \ 50.0\ \ \ 51.0\ \ \ 2.3\\ 57.0\ \ \ 36.0\ \ \ 46.0\ \ \ 2.3\\ 66.0\ \ \ 40.0\ \ \ 48.0\ \ \ 2.2\\ 70.0\ \ \ 41.0\ \ \ 44.0\ \ \ 1.8\\ 89.0\ \ \ 28.0\ \ \ 43.0\ \ \ 1.8\\ 36.0\ \ \ 49.0\ \ \ 54.0\ \ \ 2.9\\ 46.0\ \ \ 42.0\ \ \ 50.0\ \ \ 2.2\\ 54.0\ \ \ 45.0\ \ \ 48.0\ \ \ 2.4\\ 26.0\ \ \ 52.0\ \ \ 62.0\ \ \ 2.9\\ 77.0\ \ \ 29.0\ \ \ 50.0\ \ \ 2.1\\ 89.0\ \ \ 29.0\ \ \ 48.0\ \ \ 2.4\\ 67.0\ \ \ 43.0\ \ \ 53.0\ \ \ 2.4\\ 47.0\ \ \ 38.0\ \ \ 55.0\ \ \ 2.2\\ 51.0\ \ \ 34.0\ \ \ 51.0\ \ \ 2.3\\ 57.0\ \ \ 53.0\ \ \ 54.0\ \ \ 2.2\\ 66.0\ \ \ 36.0\ \ \ 49.0\ \ \ 2.0\\ 79.0\ \ \ 33.0\ \ \ 56.0\ \ \ 2.5\\ 88.0\ \ \ 29.0\ \ \ 46.0\ \ \ 1.9\\ 60.0\ \ \ 33.0\ \ \ 49.0\ \ \ 2.1\\ 49.0\ \ \ 55.0\ \ \ 51.0\ \ \ 2.4\\ 77.0\ \ \ 29.0\ \ \ 52.0\ \ \ 2.3\\ 52.0\ \ \ 44.0\ \ \ 58.0\ \ \ 2.9\\ 60.0\ \ \ 43.0\ \ \ 50.0\ \ \ 2.3\\ $$","I'm having trouble with some intuition in Linear Statistical Modelling. I'm working with some data with three predictor variables $X_1$, $X_2$ and $X_3$. I've calculated the $F$ test for whether $X_2$ should be retained in the model containing just $X_1$ and $X_2$. Similarly I've calculated the $F$ test for whether $X_2$ and $X_3$ should be retained in the model containing $X_1$, $X_2$ and $X_3$. The conclusion from the first test is to retain $X_2$.  The $p$-value is less than $0.05$. The conclusion from the second test is to drop $X_2$ and $X_3$.  The $p$-value is greater than $0.1$. So my question is, is this not counter-intuitive?  How could adding another variable $X_3$ make things worse for $X_2$ than it was with just $X_2$ alone? My feeling is that I have made a calculation error because it seems the $p$-value should only get smaller with more information not larger. Any insight into this matter would be greatly apprecaited, thank you! I can't show you the exact data without getting fired.  But here's a baby data set that illustrates the same issue.  The $F$ test for whether you can drop $X_2$ in the model with $Y, X_1, X_2$ has $p$-value $0.06$ while the $F$ test for whether you can drop $X_2$ and $X_3$ in the model with $Y, X_1, X_2, X_3$ is $0.14$.  So how can it get larger like that?  This indicates you need $X_2$ on top of $X_1$ but you can get rid of both $X_2$ and $X_3$ on top of $X_1$.  To me that's a contradiction.  Am I doing something wrong here? $$ Y\ \ \ X_1\ \ \ X_2\ \ \ X_3\\ 48.0\ \ \ 50.0\ \ \ 51.0\ \ \ 2.3\\ 57.0\ \ \ 36.0\ \ \ 46.0\ \ \ 2.3\\ 66.0\ \ \ 40.0\ \ \ 48.0\ \ \ 2.2\\ 70.0\ \ \ 41.0\ \ \ 44.0\ \ \ 1.8\\ 89.0\ \ \ 28.0\ \ \ 43.0\ \ \ 1.8\\ 36.0\ \ \ 49.0\ \ \ 54.0\ \ \ 2.9\\ 46.0\ \ \ 42.0\ \ \ 50.0\ \ \ 2.2\\ 54.0\ \ \ 45.0\ \ \ 48.0\ \ \ 2.4\\ 26.0\ \ \ 52.0\ \ \ 62.0\ \ \ 2.9\\ 77.0\ \ \ 29.0\ \ \ 50.0\ \ \ 2.1\\ 89.0\ \ \ 29.0\ \ \ 48.0\ \ \ 2.4\\ 67.0\ \ \ 43.0\ \ \ 53.0\ \ \ 2.4\\ 47.0\ \ \ 38.0\ \ \ 55.0\ \ \ 2.2\\ 51.0\ \ \ 34.0\ \ \ 51.0\ \ \ 2.3\\ 57.0\ \ \ 53.0\ \ \ 54.0\ \ \ 2.2\\ 66.0\ \ \ 36.0\ \ \ 49.0\ \ \ 2.0\\ 79.0\ \ \ 33.0\ \ \ 56.0\ \ \ 2.5\\ 88.0\ \ \ 29.0\ \ \ 46.0\ \ \ 1.9\\ 60.0\ \ \ 33.0\ \ \ 49.0\ \ \ 2.1\\ 49.0\ \ \ 55.0\ \ \ 51.0\ \ \ 2.4\\ 77.0\ \ \ 29.0\ \ \ 52.0\ \ \ 2.3\\ 52.0\ \ \ 44.0\ \ \ 58.0\ \ \ 2.9\\ 60.0\ \ \ 43.0\ \ \ 50.0\ \ \ 2.3\\ $$",,"['statistics', 'statistical-inference']"
73,Canonical decomposition of absorbing chains,Canonical decomposition of absorbing chains,,"An absorbing Markov chain on $n$ states for which $t$ states are transient and $n-t$ states are absorbing can be reordered in a canonical decomposition with transition matrix $$\boldsymbol{P}= \left[ \begin{array}{c|c} \boldsymbol{Q} & \boldsymbol{R} \\ \hline \boldsymbol{0} & \boldsymbol{I} \end{array} \right]$$ where $\boldsymbol{Q}$ is a $t\times t$ matrix and $\boldsymbol{R}$ is a $t\times (n-t)$ matrix.  As usual, $\boldsymbol{0}$ is a matrix of zeros and  $\boldsymbol{I}$ is the identity matrix. An example would be the transition matrix $$\boldsymbol{P'}=\begin{bmatrix} 0 & .6 & 0 &  0& .4 & 0\\   .4&  0&  .6&  0& 0 &0 \\   0&  .4&  0&  .6& 0 & 0\\   0&  0&  .4&  0&  0&.6 \\   0&  0&0  & 0 & 1 &0 \\   0& 0 &0  & 0 &0  & 1 \end{bmatrix}.$$ Now, using the fundamnetal matrix $\boldsymbol{F}=(\boldsymbol{I}-\boldsymbol{Q})^{-1}$, we can calculate absorbtion probabilities and expected times until absorption. One example gives the doubly stochastic transition matrix $$\boldsymbol{T} = \begin{bmatrix} .3 & .5 & .2\\   .2& .4 & .4\\  .5 & .1 & .4 \end{bmatrix}$$ and asks to find $E(S \mid X_0 =1)$ where $S$ is the first time that $X_n=3$. The fundamental matrix is used, and the solution defines $$\boldsymbol{Q}=\begin{bmatrix} .3 & .5\\   .2& .4 \end{bmatrix}.$$ How does this make sense if the matrix is clearly not in its canonical form, and what is an efficient method to transform a matrix into its canonical form?","An absorbing Markov chain on $n$ states for which $t$ states are transient and $n-t$ states are absorbing can be reordered in a canonical decomposition with transition matrix $$\boldsymbol{P}= \left[ \begin{array}{c|c} \boldsymbol{Q} & \boldsymbol{R} \\ \hline \boldsymbol{0} & \boldsymbol{I} \end{array} \right]$$ where $\boldsymbol{Q}$ is a $t\times t$ matrix and $\boldsymbol{R}$ is a $t\times (n-t)$ matrix.  As usual, $\boldsymbol{0}$ is a matrix of zeros and  $\boldsymbol{I}$ is the identity matrix. An example would be the transition matrix $$\boldsymbol{P'}=\begin{bmatrix} 0 & .6 & 0 &  0& .4 & 0\\   .4&  0&  .6&  0& 0 &0 \\   0&  .4&  0&  .6& 0 & 0\\   0&  0&  .4&  0&  0&.6 \\   0&  0&0  & 0 & 1 &0 \\   0& 0 &0  & 0 &0  & 1 \end{bmatrix}.$$ Now, using the fundamnetal matrix $\boldsymbol{F}=(\boldsymbol{I}-\boldsymbol{Q})^{-1}$, we can calculate absorbtion probabilities and expected times until absorption. One example gives the doubly stochastic transition matrix $$\boldsymbol{T} = \begin{bmatrix} .3 & .5 & .2\\   .2& .4 & .4\\  .5 & .1 & .4 \end{bmatrix}$$ and asks to find $E(S \mid X_0 =1)$ where $S$ is the first time that $X_n=3$. The fundamental matrix is used, and the solution defines $$\boldsymbol{Q}=\begin{bmatrix} .3 & .5\\   .2& .4 \end{bmatrix}.$$ How does this make sense if the matrix is clearly not in its canonical form, and what is an efficient method to transform a matrix into its canonical form?",,"['probability', 'matrices']"
74,Convergence in distribution implies convergence in density,Convergence in distribution implies convergence in density,,"Let $\{F_n\}$ be a sequence of absolutely continuous (wrt Lebesgue measure $\mu$) distributions on $R^k$, and $\{f_n\}$ be a corresponding sequence of densities. Suppose $F_n \Rightarrow F$, where $\Rightarrow$ stands for weak convergence. Can we show that $f_n$ converges pointwise to $f$? Here $f$ is the corresponding density of $F$. I know, in general, this is not true if no further assumptions are imposed (see e.g. Sweeting, 1986). How about $F$ is the normal distribution with zero mean and some positive definite covariance matrix $\Sigma$?","Let $\{F_n\}$ be a sequence of absolutely continuous (wrt Lebesgue measure $\mu$) distributions on $R^k$, and $\{f_n\}$ be a corresponding sequence of densities. Suppose $F_n \Rightarrow F$, where $\Rightarrow$ stands for weak convergence. Can we show that $f_n$ converges pointwise to $f$? Here $f$ is the corresponding density of $F$. I know, in general, this is not true if no further assumptions are imposed (see e.g. Sweeting, 1986). How about $F$ is the normal distribution with zero mean and some positive definite covariance matrix $\Sigma$?",,"['real-analysis', 'statistics', 'weak-convergence']"
75,Use Rao-Blackwell Theorem to find the UMVUE,Use Rao-Blackwell Theorem to find the UMVUE,,"Suppose that $X_1,X_2,...,X_n$ is a random sample from a normal distribution, $X_i\sim N(\mu,9)$. Find the UMVUE (uniformly minimum variance unbiased estimator) of $P(X\le c)$ where $c$ is a known constant.  Do this by finding the conditional distribution of $X_1$ given $\bar{X}={\bar{x}}$ and apply the Rao-Blackwell theorem with $T=u(X_1)$, where $u(x_1)=1$ if $x\le c$ and zero otherwise. So clearly the parameter that we're trying to estimate given the problem description can be written as $\Phi\left( \frac{c-\mu}{3} \right)$ where $\Phi$ represents the CDF of the standard normal distribution.  However, I get stuck when I need to try and find the conditional distribution.  Without knowing the joint distribution or the other conditional distribution, how can I possibly find the conditional distribution of $X_1$ given $\bar{X}={\bar{x}}$?","Suppose that $X_1,X_2,...,X_n$ is a random sample from a normal distribution, $X_i\sim N(\mu,9)$. Find the UMVUE (uniformly minimum variance unbiased estimator) of $P(X\le c)$ where $c$ is a known constant.  Do this by finding the conditional distribution of $X_1$ given $\bar{X}={\bar{x}}$ and apply the Rao-Blackwell theorem with $T=u(X_1)$, where $u(x_1)=1$ if $x\le c$ and zero otherwise. So clearly the parameter that we're trying to estimate given the problem description can be written as $\Phi\left( \frac{c-\mu}{3} \right)$ where $\Phi$ represents the CDF of the standard normal distribution.  However, I get stuck when I need to try and find the conditional distribution.  Without knowing the joint distribution or the other conditional distribution, how can I possibly find the conditional distribution of $X_1$ given $\bar{X}={\bar{x}}$?",,"['probability', 'statistics', 'normal-distribution', 'statistical-inference', 'parameter-estimation']"
76,Are Wikipedia and Wolfram Mathworld wrong about the CDF of the beta binomial?,Are Wikipedia and Wolfram Mathworld wrong about the CDF of the beta binomial?,,"Wikipedia and Mathworld claim that the CDF of the beta-binomial distribution is: $$1- \tfrac{\mathrm{B}(\beta+n-k-1,\alpha+k+1)_3F_2(\boldsymbol{a},\boldsymbol{b};k)} {\mathrm{B}(\alpha,\beta)\mathrm{B}(n-k,k+2) (n+1)}$$ where $_3F_2(\boldsymbol{a},\boldsymbol{b};k)$ is the generalized hypergeometric function $$_3F_2(1,\! \alpha\! +\! k\!+ \! 1,k\! -\! n\! +\! 1;k\! +\! 2,k\! +\! 2\! -\! \beta\! -\! n;1)\!$$ This is dubious because $_3F_2(\cdot,\cdot,\cdot;\cdot,\cdot;1)$ is a singularity . Using Sympy, I evaluated that generalized hypergeometric function with the last argument changed to different values near $1$, and here's what I got: In [5]: import mpmath as mp  In [7]: n = 1  In [8]: k = 1  In [9]: alpha = 1  In [10]: beta = 1  In [16]: spec = lambda alpha, beta, n, k: mp.hyp3f2(1, alpha + k + 1, k - n + 1, k + 2, k + 2 - beta      ...: - n, '1.0001')  In [17]: spec(alpha, beta, n, k) Out[17]: mpf('-10000.0000000011')  In [18]: spec = lambda alpha, beta, n, k: mp.hyp3f2(1, alpha + k + 1, k - n + 1, k + 2, k + 2 - beta      ...: - n, '0.99999999')  In [19]: spec(alpha, beta, n, k) Out[19]: mpf('99999999.497524068') So it even changes sign. What is the CDF of the beta binomial?","Wikipedia and Mathworld claim that the CDF of the beta-binomial distribution is: $$1- \tfrac{\mathrm{B}(\beta+n-k-1,\alpha+k+1)_3F_2(\boldsymbol{a},\boldsymbol{b};k)} {\mathrm{B}(\alpha,\beta)\mathrm{B}(n-k,k+2) (n+1)}$$ where $_3F_2(\boldsymbol{a},\boldsymbol{b};k)$ is the generalized hypergeometric function $$_3F_2(1,\! \alpha\! +\! k\!+ \! 1,k\! -\! n\! +\! 1;k\! +\! 2,k\! +\! 2\! -\! \beta\! -\! n;1)\!$$ This is dubious because $_3F_2(\cdot,\cdot,\cdot;\cdot,\cdot;1)$ is a singularity . Using Sympy, I evaluated that generalized hypergeometric function with the last argument changed to different values near $1$, and here's what I got: In [5]: import mpmath as mp  In [7]: n = 1  In [8]: k = 1  In [9]: alpha = 1  In [10]: beta = 1  In [16]: spec = lambda alpha, beta, n, k: mp.hyp3f2(1, alpha + k + 1, k - n + 1, k + 2, k + 2 - beta      ...: - n, '1.0001')  In [17]: spec(alpha, beta, n, k) Out[17]: mpf('-10000.0000000011')  In [18]: spec = lambda alpha, beta, n, k: mp.hyp3f2(1, alpha + k + 1, k - n + 1, k + 2, k + 2 - beta      ...: - n, '0.99999999')  In [19]: spec(alpha, beta, n, k) Out[19]: mpf('99999999.497524068') So it even changes sign. What is the CDF of the beta binomial?",,"['probability', 'statistics', 'hypergeometric-function']"
77,Real time bayesian analysis,Real time bayesian analysis,,"Currently our memcached cluster shields our database from heavy load. If the cache were to go down, it would take our application down with it. With a cold cache, we could avoid this downtime by switching into a ""safe mode"", where $1\%$ of cache miss requests go to master and warm the cache. The remainder of requests go to read replicas, serve potentially stale data and  aren't used to populate the cache(to avoid stale sets). I want to create a model that can recognize when the cache is likely in a cold state. I imagine I could track cache hit rate over a period of time and get a good idea of the mean and variance of the cache hit rate. Given a prior of how frequently I expect to be in a cold state (rare) and a certain hit rate, it seems I could create a posterior distribution that estimates how likely we are to be in a cold state, and switch into ""safe mode"" given some threshold value. What would be the best way to measure hit rate? I could somewhat arbitrarily set a window of say $1$ second or $30$ seconds and measure hit rate in that interval. Although that raises the issue of finding the best window — smaller windows will have larger variance, but too large of a window means the model doesn't trigger ""safe mode"" quickly enough. What I really want is a sliding window where more recent hits weigh more heavily in the models decisions but all previous hits are taken into account as well. What would be the best way to approach this?","Currently our memcached cluster shields our database from heavy load. If the cache were to go down, it would take our application down with it. With a cold cache, we could avoid this downtime by switching into a ""safe mode"", where $1\%$ of cache miss requests go to master and warm the cache. The remainder of requests go to read replicas, serve potentially stale data and  aren't used to populate the cache(to avoid stale sets). I want to create a model that can recognize when the cache is likely in a cold state. I imagine I could track cache hit rate over a period of time and get a good idea of the mean and variance of the cache hit rate. Given a prior of how frequently I expect to be in a cold state (rare) and a certain hit rate, it seems I could create a posterior distribution that estimates how likely we are to be in a cold state, and switch into ""safe mode"" given some threshold value. What would be the best way to measure hit rate? I could somewhat arbitrarily set a window of say $1$ second or $30$ seconds and measure hit rate in that interval. Although that raises the issue of finding the best window — smaller windows will have larger variance, but too large of a window means the model doesn't trigger ""safe mode"" quickly enough. What I really want is a sliding window where more recent hits weigh more heavily in the models decisions but all previous hits are taken into account as well. What would be the best way to approach this?",,"['statistics', 'statistical-inference', 'bayesian', 'bayes-theorem', 'bayesian-network']"
78,"Probability of picking matching socks, after partitioning the drawer.","Probability of picking matching socks, after partitioning the drawer.",,"Apologies if this is a duplicate. I searched and didn't find anything quite like it. Suppose I have a drawer with an equal number of N black socks and N white socks. They're all mixed up. So, my chances of picking a matching pair in the first two selections is (N-1)/(2N-1), right? Well, what if, before I pick the first sock, I randomly (so I don't know the colors of the socks I'm moving) partition the drawer so that there are N socks on each side, and I draw one sock from each side. Do the chances of drawing a matching pair change ? On the one hand, we can see that selection from one side doesn't change the composition of socks on the other side of the partition. However, whichever color I choose from the ""first"" side, it's likely that there are more of that color on that side. On other words, if I draw a black sock from one side, it's more likely that that side had N-1 blacks and 1 white than it is that that side had 1 black and N-1 whites. My suspicion is that I need to do some kind of hypothesis testing, where I consider the chances of every possible partitioning, but that's way above my skill level.","Apologies if this is a duplicate. I searched and didn't find anything quite like it. Suppose I have a drawer with an equal number of N black socks and N white socks. They're all mixed up. So, my chances of picking a matching pair in the first two selections is (N-1)/(2N-1), right? Well, what if, before I pick the first sock, I randomly (so I don't know the colors of the socks I'm moving) partition the drawer so that there are N socks on each side, and I draw one sock from each side. Do the chances of drawing a matching pair change ? On the one hand, we can see that selection from one side doesn't change the composition of socks on the other side of the partition. However, whichever color I choose from the ""first"" side, it's likely that there are more of that color on that side. On other words, if I draw a black sock from one side, it's more likely that that side had N-1 blacks and 1 white than it is that that side had 1 black and N-1 whites. My suspicion is that I need to do some kind of hypothesis testing, where I consider the chances of every possible partitioning, but that's way above my skill level.",,"['probability', 'statistics']"
79,Do you need to know stochastic processes to learn stochastic calculus?,Do you need to know stochastic processes to learn stochastic calculus?,,"I have been researching topics that I can study next year for an independent reading course, and stochastic calculus seems very interesting. i have not studied stochastic processes at all, and from my research online I have found that the two subjects have very little overlap. I don't know how true that is, and I was wondering if its possible to study stochastic calculus without knowing stochastic processes?","I have been researching topics that I can study next year for an independent reading course, and stochastic calculus seems very interesting. i have not studied stochastic processes at all, and from my research online I have found that the two subjects have very little overlap. I don't know how true that is, and I was wondering if its possible to study stochastic calculus without knowing stochastic processes?",,"['statistics', 'stochastic-processes', 'stochastic-calculus']"
80,Birthday Problem Alteration,Birthday Problem Alteration,,"The well-known birthday problem asks how many people must be in a room before the probability of two or more people people sharing a (any) birthday is $>0.5$ and the answer is 23; a common alteration to this is how many people must be in a room before the chance of at least one person sharing your birthday (i.e. one specific date) is again greater than half, the answer is 253. I've been through these proofs and understand them however I want to know how many people must be in a room before the chances of at least two people sharing a specific birthday given at the start of the problem (e.g. 'your' birthday) is greater than half. Clearly the probability of this $=1-P($one or fewer people have this specific birthdate$)=1-P($one person shares this birthdate$)-p($no one shares this birthdate$)$. I've gone through the methods used to calculate the original problems but every answer I get becomes unsolvable when made greater than 0.5, how would I do this?","The well-known birthday problem asks how many people must be in a room before the probability of two or more people people sharing a (any) birthday is $>0.5$ and the answer is 23; a common alteration to this is how many people must be in a room before the chance of at least one person sharing your birthday (i.e. one specific date) is again greater than half, the answer is 253. I've been through these proofs and understand them however I want to know how many people must be in a room before the chances of at least two people sharing a specific birthday given at the start of the problem (e.g. 'your' birthday) is greater than half. Clearly the probability of this $=1-P($one or fewer people have this specific birthdate$)=1-P($one person shares this birthdate$)-p($no one shares this birthdate$)$. I've gone through the methods used to calculate the original problems but every answer I get becomes unsolvable when made greater than 0.5, how would I do this?",,"['statistics', 'birthday']"
81,Mean squared error of a sample covariance matrix,Mean squared error of a sample covariance matrix,,"I am trying prove a claim from some paper that the mean squared error of the sample covariance estimator $\bf{S}=\frac{1}{n}\bf{X}\bf{X}^T$ of the covariance matrix $\Sigma$ is $\mathrm{MSE}(\bf{S})=\frac{1}{n}[\mathrm{tr}(\Sigma^2)+\mathrm{tr}^2(\Sigma)]$. Here $\bf{X}$ are $p\times{}n$ matrices of samples drawn from the multivariate normal distribution $N_p(0,\Sigma)$. $\bf{S}$ and $\Sigma$ are symmetric matrices. The MSE is defined as $\mathrm{MSE}(\bf{S})= \mathbb{E}(\left\lVert \Sigma{}-S \right\rVert^2)$, where $\mathbb{E}()$ is the expectation value and $\left\lVert \bf{A} \right\rVert=\mathrm{tr}(\bf{A}^T\bf{A})^{1/2}$ is the Frobenius norm. Here is my attempt to solving this:  \begin{align}\mathrm{MSE}\left(\bf{S}\right) =& \mathbb{E}(\left\lVert \Sigma{}-\bf{S} \right\rVert^2) \\ =& \mathbb{E}(\mathrm{tr}[(\Sigma{}-\bf{S})^T(\Sigma{}-S)]) \\ =& \mathbb{E}(\mathrm{tr}[\Sigma^2-\Sigma{}\bf{S}-\bf{S}\Sigma{}+\bf{S}^2]) \\ =& \mathrm{tr}[\Sigma^2]-2\mathbb{E}(\mathrm{tr}[\bf{S}\Sigma])+\mathbb{E}(\mathrm{tr}[\bf{S}^2])\\ =& \mathrm{tr}[\Sigma^2]-2 \mathrm{tr}[\mathbb{E}(\bf{S})\Sigma]+\mathrm{tr}[\mathbb{E}(\bf{S}^2)] \end{align} Now the problem has reduced to computing $\mathbb{E}(\bf{S})$ and $\mathbb{E}(\bf{S}^2)$. My initial thoughts were that $\mathbb{E}(\bf{S})=\Sigma$ and $\mathbb{E}(\bf{S}^2)=\Sigma^2$, but then the whole expression above is $0$... Could someone help by pointing out what am I doing wrong? Update: I found some problems with my reasoning. The expectation of $\bf{XX}^T$ is not $\Sigma$. Before going for the expectations, I am still struggling with computing the two necessary traces of the following type: $$\mathrm{tr}(\Sigma{}\bf{XX}^T)=\mathrm{tr}(\Sigma{}\Sigma{}^{1/2}\bf{YY}^T\Sigma{}^{1/2~T})$$ and $$\mathrm{tr}(\bf{XX}^T\bf{XX}^T)=\mathrm{tr}(\Sigma{}^{1/2}\bf{YY}^T\Sigma{}^{1/2~T}\Sigma{}^{1/2}\bf{YY}^T\Sigma{}^{1/2~T}),$$ where $\bf{Y}$ are samples from standard normal distributions and $\Sigma{}^{1/2}$ is a lower triangular matrix as obtained by Cholesky decomposition.","I am trying prove a claim from some paper that the mean squared error of the sample covariance estimator $\bf{S}=\frac{1}{n}\bf{X}\bf{X}^T$ of the covariance matrix $\Sigma$ is $\mathrm{MSE}(\bf{S})=\frac{1}{n}[\mathrm{tr}(\Sigma^2)+\mathrm{tr}^2(\Sigma)]$. Here $\bf{X}$ are $p\times{}n$ matrices of samples drawn from the multivariate normal distribution $N_p(0,\Sigma)$. $\bf{S}$ and $\Sigma$ are symmetric matrices. The MSE is defined as $\mathrm{MSE}(\bf{S})= \mathbb{E}(\left\lVert \Sigma{}-S \right\rVert^2)$, where $\mathbb{E}()$ is the expectation value and $\left\lVert \bf{A} \right\rVert=\mathrm{tr}(\bf{A}^T\bf{A})^{1/2}$ is the Frobenius norm. Here is my attempt to solving this:  \begin{align}\mathrm{MSE}\left(\bf{S}\right) =& \mathbb{E}(\left\lVert \Sigma{}-\bf{S} \right\rVert^2) \\ =& \mathbb{E}(\mathrm{tr}[(\Sigma{}-\bf{S})^T(\Sigma{}-S)]) \\ =& \mathbb{E}(\mathrm{tr}[\Sigma^2-\Sigma{}\bf{S}-\bf{S}\Sigma{}+\bf{S}^2]) \\ =& \mathrm{tr}[\Sigma^2]-2\mathbb{E}(\mathrm{tr}[\bf{S}\Sigma])+\mathbb{E}(\mathrm{tr}[\bf{S}^2])\\ =& \mathrm{tr}[\Sigma^2]-2 \mathrm{tr}[\mathbb{E}(\bf{S})\Sigma]+\mathrm{tr}[\mathbb{E}(\bf{S}^2)] \end{align} Now the problem has reduced to computing $\mathbb{E}(\bf{S})$ and $\mathbb{E}(\bf{S}^2)$. My initial thoughts were that $\mathbb{E}(\bf{S})=\Sigma$ and $\mathbb{E}(\bf{S}^2)=\Sigma^2$, but then the whole expression above is $0$... Could someone help by pointing out what am I doing wrong? Update: I found some problems with my reasoning. The expectation of $\bf{XX}^T$ is not $\Sigma$. Before going for the expectations, I am still struggling with computing the two necessary traces of the following type: $$\mathrm{tr}(\Sigma{}\bf{XX}^T)=\mathrm{tr}(\Sigma{}\Sigma{}^{1/2}\bf{YY}^T\Sigma{}^{1/2~T})$$ and $$\mathrm{tr}(\bf{XX}^T\bf{XX}^T)=\mathrm{tr}(\Sigma{}^{1/2}\bf{YY}^T\Sigma{}^{1/2~T}\Sigma{}^{1/2}\bf{YY}^T\Sigma{}^{1/2~T}),$$ where $\bf{Y}$ are samples from standard normal distributions and $\Sigma{}^{1/2}$ is a lower triangular matrix as obtained by Cholesky decomposition.",,"['linear-algebra', 'statistics', 'expectation']"
82,Kullback-Leibler divergence of two Laplace distributions with different parameters,Kullback-Leibler divergence of two Laplace distributions with different parameters,,"Let the Kullback-Leibler (KL) divergence of two distributions $p(x)$ and $q(x)$ be defined as $D(P||Q) = E_p(\log p(x) - \log q(x))$ Let $p(x) \sim \text{Laplace}(\mu_1, b_1)$ and $q(x) \sim \text{Laplace}(\mu_2, b_2)$ then $ \begin{align} D(P||Q) &= E_p(\log p(x) - \log q(x)) \\ &= E_p\left( \log \frac{b_2}{b_1} - \frac{|x-\mu_1|}{b_1} + \frac{|x-\mu_2|}{b_2}\right)\\ &= \log \frac{b_2}{b_1}  - \frac{1}{b_1}E_p|x-\mu_1| + \frac{1}{b_2}E_p|x-\mu_2|\\ \end{align} $ The first term is a constant. The second term is the median divided by $b_1$ ( IM NOT SURE ABOUT THIS STEP ) The third term is given by $b_1/b_2$, because if $X\sim\text{Laplace}(\mu_1,b_1)$ then $X-c\sim\text{Laplace}(\mu_1-c,b_1)$ from which follows that $|X-c|\sim\text{exp}(b_1^{-1})$ Hence the Kullback-Leibler divergence of two Laplace distributions is given by $ \begin{align} D(P||Q) &= E_p(\log p(x) - \log q(x)) \\ &= \log \frac{b_2}{b_1}  - 1 + \frac{b_1}{b_2} \end{align} $ I couldnt find the correct answer anywhere online so I was wondering if anyone here knows the right answer.","Let the Kullback-Leibler (KL) divergence of two distributions $p(x)$ and $q(x)$ be defined as $D(P||Q) = E_p(\log p(x) - \log q(x))$ Let $p(x) \sim \text{Laplace}(\mu_1, b_1)$ and $q(x) \sim \text{Laplace}(\mu_2, b_2)$ then $ \begin{align} D(P||Q) &= E_p(\log p(x) - \log q(x)) \\ &= E_p\left( \log \frac{b_2}{b_1} - \frac{|x-\mu_1|}{b_1} + \frac{|x-\mu_2|}{b_2}\right)\\ &= \log \frac{b_2}{b_1}  - \frac{1}{b_1}E_p|x-\mu_1| + \frac{1}{b_2}E_p|x-\mu_2|\\ \end{align} $ The first term is a constant. The second term is the median divided by $b_1$ ( IM NOT SURE ABOUT THIS STEP ) The third term is given by $b_1/b_2$, because if $X\sim\text{Laplace}(\mu_1,b_1)$ then $X-c\sim\text{Laplace}(\mu_1-c,b_1)$ from which follows that $|X-c|\sim\text{exp}(b_1^{-1})$ Hence the Kullback-Leibler divergence of two Laplace distributions is given by $ \begin{align} D(P||Q) &= E_p(\log p(x) - \log q(x)) \\ &= \log \frac{b_2}{b_1}  - 1 + \frac{b_1}{b_2} \end{align} $ I couldnt find the correct answer anywhere online so I was wondering if anyone here knows the right answer.",,['statistics']
83,Which statistical test to choose,Which statistical test to choose,,"first I will describe my problem (1), then solutions I found (2) and then pose the question (3). 1) I am a student making simple program for statistical analysis of data for biological laboratory. The situation is as follows: They have a protein and measure some property three times (to eliminate measurement error). Then they mix the same batch of protein with some chemical and measure the same property again twice. In the end they want to know, if the measurements are different enough. (I know the number of measurements is low, but it is the maximum they can do). 2) If we assume, that the samples are independent I would choose Welch's t-test, because we cannot assume the same variance. However they say that, due to the fact that we measure the same batch of protein three times, and then two times with some chemical, the before and after measurements are related samples. But for related samples I only found paired t-tests, which cannot be used here, because there are no explicit pairs. The only thing that comes to my mind is to pair each measurement from each set. 3) How to measure statistically significant difference of a property, when we have 3 measurements of batch of protein before applying a chemical and 2 measurements after applying a chemical. Measurements are repeated to eliminate error in measurement device.","first I will describe my problem (1), then solutions I found (2) and then pose the question (3). 1) I am a student making simple program for statistical analysis of data for biological laboratory. The situation is as follows: They have a protein and measure some property three times (to eliminate measurement error). Then they mix the same batch of protein with some chemical and measure the same property again twice. In the end they want to know, if the measurements are different enough. (I know the number of measurements is low, but it is the maximum they can do). 2) If we assume, that the samples are independent I would choose Welch's t-test, because we cannot assume the same variance. However they say that, due to the fact that we measure the same batch of protein three times, and then two times with some chemical, the before and after measurements are related samples. But for related samples I only found paired t-tests, which cannot be used here, because there are no explicit pairs. The only thing that comes to my mind is to pair each measurement from each set. 3) How to measure statistically significant difference of a property, when we have 3 measurements of batch of protein before applying a chemical and 2 measurements after applying a chemical. Measurements are repeated to eliminate error in measurement device.",,"['statistics', 'hypothesis-testing', 'biology']"
84,Normal Distribution vs. Standard Normal Distribution vs. Gaussian Distribution?,Normal Distribution vs. Standard Normal Distribution vs. Gaussian Distribution?,,"I know that Normal Distribution and Gaussian Distribution are the same thing, but today in class my teacher said that the mean of Gaussian Distribution = 0. I know that this isn't consistent with normal distributions, but rather standard normal distributions. Is the gaussian distribution the same as a normal distribution or a standard normal distribution, or am I wrong in thinking that the mean of every normal distribution can't be 0?","I know that Normal Distribution and Gaussian Distribution are the same thing, but today in class my teacher said that the mean of Gaussian Distribution = 0. I know that this isn't consistent with normal distributions, but rather standard normal distributions. Is the gaussian distribution the same as a normal distribution or a standard normal distribution, or am I wrong in thinking that the mean of every normal distribution can't be 0?",,"['probability', 'statistics']"
85,A and B have 10 dollars each. They bet 1 dollar each time. A wins the final game iff B has no money left.,A and B have 10 dollars each. They bet 1 dollar each time. A wins the final game iff B has no money left.,,"For each bet, A has prob = 0.5 to win the 1 dollar from B. and prob = 0.5 to lose 1 dollar to B. How to calculate the probability that A wins the final game? How about for the initial state A has 20 dollars and B has 10 dollars , what's probability that A wins the final game? How about A and B still have 10 dollars each, and A has prob = 0.6 to win each bet, what's probability that A wins the final game? Thanks!","For each bet, A has prob = 0.5 to win the 1 dollar from B. and prob = 0.5 to lose 1 dollar to B. How to calculate the probability that A wins the final game? How about for the initial state A has 20 dollars and B has 10 dollars , what's probability that A wins the final game? How about A and B still have 10 dollars each, and A has prob = 0.6 to win each bet, what's probability that A wins the final game? Thanks!",,"['probability', 'statistics']"
86,Finding the expected value of the MLE of the multiple linear model,Finding the expected value of the MLE of the multiple linear model,,"For context, the linear model is $$\mathbf{y} = X\mathbf{\beta} + \mathbf{\varepsilon} $$ where $\mathbf{y}$ is the vector of responses $y_i,i=1,2,\ldots,n$, $X$ is the deterministic design matrix $n\times p$ and $\beta$ is the vector of parameters, $p\times 1$. Also, $\varepsilon$ is the vector of uncorrelated errors with zero mean, $\varepsilon_i,i=1,2,\ldots,n$ where $\mathrm{Var}(\varepsilon_i) = \sigma^2.$ Now, the MLE of $\sigma^2$ in the multiple linear model is $$\hat{\sigma}^2 := \frac{1}{n} (y-XB)^T (y-XB) $$ And I'm given the formula that for any random $k\times 1$ vector $u$, and constant $k\times k$ matrix $A$, we have $$\mathbb{E}(u^T A u) = \mathrm{tr}(AV) + \mu^T A \mu$$ where $V=\mathrm{Var}(u), \ \mu = \mathbb{E}(u)$. So I try to apply this to my MLE. $$\hat{\sigma}^2 := \frac{1}{n} \varepsilon^T \varepsilon \\ \mathbb{E}(\hat{\sigma}^2) = \frac{1}{n} \mathbb{E}(\varepsilon ^T I_{n\times n} \varepsilon) $$ with $A = I_{n\times n}, u = \varepsilon$. So $V = \mathrm{Var}(\varepsilon) = \sigma^2 I_{n\times n}, \mu = \mathbb{E}(\varepsilon) = \mathbf{0}$. hence, $$\mathbb{E}(\hat{\sigma}^2) = \frac{1}{n} ( \mathrm{tr}(I_{n\times n}\sigma^2 I_{n\times n}) = \sigma^2.$$ However, this is incorrect as the solution says that it is $\frac{n-p}{n}\sigma^2$ and it also shows me how it's done. However, I'm not sure where I went wrong.","For context, the linear model is $$\mathbf{y} = X\mathbf{\beta} + \mathbf{\varepsilon} $$ where $\mathbf{y}$ is the vector of responses $y_i,i=1,2,\ldots,n$, $X$ is the deterministic design matrix $n\times p$ and $\beta$ is the vector of parameters, $p\times 1$. Also, $\varepsilon$ is the vector of uncorrelated errors with zero mean, $\varepsilon_i,i=1,2,\ldots,n$ where $\mathrm{Var}(\varepsilon_i) = \sigma^2.$ Now, the MLE of $\sigma^2$ in the multiple linear model is $$\hat{\sigma}^2 := \frac{1}{n} (y-XB)^T (y-XB) $$ And I'm given the formula that for any random $k\times 1$ vector $u$, and constant $k\times k$ matrix $A$, we have $$\mathbb{E}(u^T A u) = \mathrm{tr}(AV) + \mu^T A \mu$$ where $V=\mathrm{Var}(u), \ \mu = \mathbb{E}(u)$. So I try to apply this to my MLE. $$\hat{\sigma}^2 := \frac{1}{n} \varepsilon^T \varepsilon \\ \mathbb{E}(\hat{\sigma}^2) = \frac{1}{n} \mathbb{E}(\varepsilon ^T I_{n\times n} \varepsilon) $$ with $A = I_{n\times n}, u = \varepsilon$. So $V = \mathrm{Var}(\varepsilon) = \sigma^2 I_{n\times n}, \mu = \mathbb{E}(\varepsilon) = \mathbf{0}$. hence, $$\mathbb{E}(\hat{\sigma}^2) = \frac{1}{n} ( \mathrm{tr}(I_{n\times n}\sigma^2 I_{n\times n}) = \sigma^2.$$ However, this is incorrect as the solution says that it is $\frac{n-p}{n}\sigma^2$ and it also shows me how it's done. However, I'm not sure where I went wrong.",,['statistics']
87,marginal distribution of $X_2$,marginal distribution of,X_2,"Consider $X_1 = x$ and $n$ a natural number and $p$ between $0$ and $1$ $$X_1 \sim B(n, p) =  \binom{n}{x} p^x q^{n-x}$$ $$X_2 \mid X_1 \sim B(X_1, p)$$ I can prove that $X_2 \sim B(n,p^2)$. Is this the marginal distribution of $X_2$? Can someone elaborate the marginal distribution? EDIT: proof Let's simply look at $X_2$ to start, then $$\mathbb{P}(X_2=x)=\sum_{y=0}^n \mathbb{P}(X_2=x\mid X_1=y)\mathbb{P}(X_1=y)$$ If $y<x$, the conditional probability is $0$, thus $$\mathbb{P}(X_2=x)=\sum_{y=x}^n \mathbb{P}(X_2=x\mid X_1=y)\mathbb{P}(X_1=y)$$ We can now write $$\begin{eqnarray}\mathbb{P}(X_2=x\mid X_1=y) & = & {y \choose x} p^x q^{y-x} \\ \mathbb{P}(X_1=y) & = & {n \choose y} p^y q^{n-y}  \end{eqnarray}$$ and thus $$\mathbb{P}(X_2=x)=\sum_{y=x}^n {y \choose x} p^x q^{y-x} {n \choose y} p^y q^{n-y}$$ We can work out the combinatorial factors and regroup some other factors $$\begin{eqnarray}\mathbb{P}(X_2=x) & = & p^x q^{n-x} \sum_{y=x}^n \frac{n!}{x!(y-x)!(n-y)!} p^y \\ & = &\frac{n!}{x!(n-x)!}p^x q^{n-x} \sum_{y=x}^n \frac{(n-x)!}{(y-x)!((n-x)-(y-x))!} p^y \\ & = &\frac{n!}{x!(n-x)!}p^{2x} q^{n-x} \sum_{z=0}^{n-x} \frac{(n-x)!}{(z)!((n-x)-z)!} p^z \end{eqnarray} $$ In the last step, you recognize with the binomium of Newton $(1+p)^{n-x}$, thus $$\begin{eqnarray}\mathbb{P}(X_2=x) & = & \frac{n!}{x!(n-x)!}p^{2x} q^{n-x} (1+p)^{n-x}\\ & = & \frac{n!}{x!(n-x)!}p^{2x} (1-p)^{n-x} (1+p)^{n-x}\\ & = & \frac{n!}{x!(n-x)!}(p^2)^{x} (1-p^2)^{n-x} \\ \end{eqnarray} $$ This means that $X_2 \sim B(n,p^2)$.","Consider $X_1 = x$ and $n$ a natural number and $p$ between $0$ and $1$ $$X_1 \sim B(n, p) =  \binom{n}{x} p^x q^{n-x}$$ $$X_2 \mid X_1 \sim B(X_1, p)$$ I can prove that $X_2 \sim B(n,p^2)$. Is this the marginal distribution of $X_2$? Can someone elaborate the marginal distribution? EDIT: proof Let's simply look at $X_2$ to start, then $$\mathbb{P}(X_2=x)=\sum_{y=0}^n \mathbb{P}(X_2=x\mid X_1=y)\mathbb{P}(X_1=y)$$ If $y<x$, the conditional probability is $0$, thus $$\mathbb{P}(X_2=x)=\sum_{y=x}^n \mathbb{P}(X_2=x\mid X_1=y)\mathbb{P}(X_1=y)$$ We can now write $$\begin{eqnarray}\mathbb{P}(X_2=x\mid X_1=y) & = & {y \choose x} p^x q^{y-x} \\ \mathbb{P}(X_1=y) & = & {n \choose y} p^y q^{n-y}  \end{eqnarray}$$ and thus $$\mathbb{P}(X_2=x)=\sum_{y=x}^n {y \choose x} p^x q^{y-x} {n \choose y} p^y q^{n-y}$$ We can work out the combinatorial factors and regroup some other factors $$\begin{eqnarray}\mathbb{P}(X_2=x) & = & p^x q^{n-x} \sum_{y=x}^n \frac{n!}{x!(y-x)!(n-y)!} p^y \\ & = &\frac{n!}{x!(n-x)!}p^x q^{n-x} \sum_{y=x}^n \frac{(n-x)!}{(y-x)!((n-x)-(y-x))!} p^y \\ & = &\frac{n!}{x!(n-x)!}p^{2x} q^{n-x} \sum_{z=0}^{n-x} \frac{(n-x)!}{(z)!((n-x)-z)!} p^z \end{eqnarray} $$ In the last step, you recognize with the binomium of Newton $(1+p)^{n-x}$, thus $$\begin{eqnarray}\mathbb{P}(X_2=x) & = & \frac{n!}{x!(n-x)!}p^{2x} q^{n-x} (1+p)^{n-x}\\ & = & \frac{n!}{x!(n-x)!}p^{2x} (1-p)^{n-x} (1+p)^{n-x}\\ & = & \frac{n!}{x!(n-x)!}(p^2)^{x} (1-p^2)^{n-x} \\ \end{eqnarray} $$ This means that $X_2 \sim B(n,p^2)$.",,"['statistics', 'binomial-distribution']"
88,Finding conditional probability and minimum trials in binomial distribution,Finding conditional probability and minimum trials in binomial distribution,,"I have a question like this: A missile protection system is set up in a particular zone. The system consists of $n$ radar sets operating independently. Each set has a probability of $0.95$ of detecting a missile which enters the zone. Question Suppose that there are 6 radar sets operating in a particular day (i.e. $n = 6$), Given that a missile is detected by at least one set, what is the conditional probability that it is only detected by exactly one set? We have: $X \sim B(6, 0.95)$. Therefore: $$P(X = 1 | X \geq 1) = \frac{P(X = 1)}{P(X \geq 1)} = \frac{2}{1122807} \approx 0$$ If the probability of detecting a missile in the zone is required to be at least $0.9999$, what is the smallest $n$ can be? Assuming: $X \sim B(n, 0.95)$. We need: $P(X \geq 1) \geq 0.9999$ or equivalently: $$P(X = 0) \leq 0.0001 = \binom{n}{0}*0.95^{0}*0.05^{n} = 0.05^{n}$$ Therefore, $n \geq 3.0744 $. Minimum $n$ is $4$. Is my solution right?","I have a question like this: A missile protection system is set up in a particular zone. The system consists of $n$ radar sets operating independently. Each set has a probability of $0.95$ of detecting a missile which enters the zone. Question Suppose that there are 6 radar sets operating in a particular day (i.e. $n = 6$), Given that a missile is detected by at least one set, what is the conditional probability that it is only detected by exactly one set? We have: $X \sim B(6, 0.95)$. Therefore: $$P(X = 1 | X \geq 1) = \frac{P(X = 1)}{P(X \geq 1)} = \frac{2}{1122807} \approx 0$$ If the probability of detecting a missile in the zone is required to be at least $0.9999$, what is the smallest $n$ can be? Assuming: $X \sim B(n, 0.95)$. We need: $P(X \geq 1) \geq 0.9999$ or equivalently: $$P(X = 0) \leq 0.0001 = \binom{n}{0}*0.95^{0}*0.05^{n} = 0.05^{n}$$ Therefore, $n \geq 3.0744 $. Minimum $n$ is $4$. Is my solution right?",,"['probability', 'statistics', 'binomial-distribution']"
89,Breakeven Point,Breakeven Point,,"To examine the effectiveness of its four annual advertising promotions, a mail order company has sent a questionnaire to each of its customers, asking how many of the previous year's promotions prompted orders that would not have otherwise been made. The accompanying table lists the probabilities that were derived from the questionnaire, where X is the random variable representing the number of promotions that prompted orders. If we assume that overall customer behavior next year will be the same as last year, what is the expected number of promotions that each customer will take advantage of next year by ordering goods that otherwise would not be purchased? X:  0     1         2       3         4 P(X)    0.078   0.242   0.337   0.16    0.183 A previous analysis of historical records found that the mean value of orders for promotional goods is 29 dollars, with the company earning a gross profit of 29% on each order. Calculate the expected value of the profit contribution next year. Answer is 17.89648 The fixed cost of conducting the four promotions is estimated to be 20000 dollars with a variable cost of 4 dollars per customer for mailing and handling costs. What is the minimum number of customers required by the company in order to cover the cost of promotions? (Round your answer to the next highest integer.) Breakeven point:????? I have tried to do 20000 = (# of customers) (29-4)  But got it wrong.... I don't know what method to use to find the breakeven point. Thank you!","To examine the effectiveness of its four annual advertising promotions, a mail order company has sent a questionnaire to each of its customers, asking how many of the previous year's promotions prompted orders that would not have otherwise been made. The accompanying table lists the probabilities that were derived from the questionnaire, where X is the random variable representing the number of promotions that prompted orders. If we assume that overall customer behavior next year will be the same as last year, what is the expected number of promotions that each customer will take advantage of next year by ordering goods that otherwise would not be purchased? X:  0     1         2       3         4 P(X)    0.078   0.242   0.337   0.16    0.183 A previous analysis of historical records found that the mean value of orders for promotional goods is 29 dollars, with the company earning a gross profit of 29% on each order. Calculate the expected value of the profit contribution next year. Answer is 17.89648 The fixed cost of conducting the four promotions is estimated to be 20000 dollars with a variable cost of 4 dollars per customer for mailing and handling costs. What is the minimum number of customers required by the company in order to cover the cost of promotions? (Round your answer to the next highest integer.) Breakeven point:????? I have tried to do 20000 = (# of customers) (29-4)  But got it wrong.... I don't know what method to use to find the breakeven point. Thank you!",,['statistics']
90,Expected number of throws when encountering a pokemon,Expected number of throws when encountering a pokemon,,"I have a question about using geometric distribution to analyze a spefic issue of the Pokemon Go game. First let me describe the context. When a player throws a ball to catch a pokemon, the success rate is a fixed number p. If the pokemon is not caught by the ball, the probability that it flees is f. If the pokemon does not flee, the player can throw the ball again, and each throw is an independant event. Assuming the player continues to throw balls until either the pokemon is caught or it flees, we would like to calcuatel the expected # of balls the player throws when a pokemon is encountered. I will describe my derivation below, but my result is diffrenet from the well known web site Gamepress, so I'd like to confirm the right answer. There are two conditions: when the player succesds to catch it, and when the pokemon eventually flees. The probability of successfully catching the pokemon is: $$  p + (1-p)(1-f)p + [(1-p)(1-f)]^2p+... $$ $$= p\sum_{x=1}^\infty[(1-p)(1-f)]^{x-1}$$ $$= p\frac{1}{1-(1-p)(1-f)}$$ $$= \frac{p}{p+f-fp}$$ Similary, the probability that the pokemon flees is: $$  (1-p)f + (1-p)(1-f)(1-p)f + (1-p)[(1-f)(1-p)]^2f+... $$ $$= (1-p)f\sum_{x=1}^\infty[(1-p)(1-f)]^{x-1}$$ $$= (1-p)f\frac{1}{1-(1-p)(1-f)}$$ $$= \frac{(1-p)f}{p+f-fp}$$ The expected number of throws at the condition that the pokemon is caught is: $$= p\sum_{x=1}^\infty(x[(1-p)(1-f)]^{x-1})$$ $$= p\frac{d}{dZ}\sum_{x=1}^\infty[Z^x], Z=(1-p)(1-f)$$ $$= p\frac{d}{dZ}\frac{Z}{1-Z}$$ $$= \frac{p}{(1-Z)^2}$$ $$= \frac{p}{(p+f-fp)^2}$$ The expected number of throws when the pokemon flees is: $$= f(1-p)\sum_{x=1}^\infty(x[(1-p)(1-f)]^{x-1})$$ $$= f(1-p)\frac{d}{dZ}\sum_{x=1}^\infty[Z^x], Z=(1-p)(1-f)$$ $$= f(1-p)\frac{d}{dZ}\frac{Z}{1-Z}$$ $$= \frac{f(1-p)}{(1-Z)^2}$$ $$= \frac{f(1-p)}{(p+f-fp)^2}$$ The expected number of throws, without knowing whether the pokemon is caught is The probability of successfully catching the pokemon x The expected number of throws at the condition that the pokemon is caught + the probability that the pokemon flees x The expected number of throws when the pokemon flees: $$ \frac{p}{p+f-fp}\times\frac{p}{(p+f-fp)^2} + \frac{(1-p)f}{p+f-fp}\times\frac{f(1-p)}{(p+f-fp)^2}$$ $$ = \frac{p^2+f^2(1-p)^2}{(p+f-fp)^3}$$ Gamepress does not provide the equation ( https://pokemongo.gamepress.gg/catchcalc#/ ), but it appears it is using the same formula described here: https://www.reddit.com/r/TheSilphRoad/comments/59w7cj/analysis_pok%C3%A9mon_go_catch_calculator_new_tool_to/ Which is $$ \frac{1}{p+f-fp}$$ and appears to be $$ \frac{p}{(p+f-fp)^2} +\frac{f(1-p)}{(p+f-fp)^2}$$ Therefore my question is, which formula is correct, and why? Thanks!","I have a question about using geometric distribution to analyze a spefic issue of the Pokemon Go game. First let me describe the context. When a player throws a ball to catch a pokemon, the success rate is a fixed number p. If the pokemon is not caught by the ball, the probability that it flees is f. If the pokemon does not flee, the player can throw the ball again, and each throw is an independant event. Assuming the player continues to throw balls until either the pokemon is caught or it flees, we would like to calcuatel the expected # of balls the player throws when a pokemon is encountered. I will describe my derivation below, but my result is diffrenet from the well known web site Gamepress, so I'd like to confirm the right answer. There are two conditions: when the player succesds to catch it, and when the pokemon eventually flees. The probability of successfully catching the pokemon is: $$  p + (1-p)(1-f)p + [(1-p)(1-f)]^2p+... $$ $$= p\sum_{x=1}^\infty[(1-p)(1-f)]^{x-1}$$ $$= p\frac{1}{1-(1-p)(1-f)}$$ $$= \frac{p}{p+f-fp}$$ Similary, the probability that the pokemon flees is: $$  (1-p)f + (1-p)(1-f)(1-p)f + (1-p)[(1-f)(1-p)]^2f+... $$ $$= (1-p)f\sum_{x=1}^\infty[(1-p)(1-f)]^{x-1}$$ $$= (1-p)f\frac{1}{1-(1-p)(1-f)}$$ $$= \frac{(1-p)f}{p+f-fp}$$ The expected number of throws at the condition that the pokemon is caught is: $$= p\sum_{x=1}^\infty(x[(1-p)(1-f)]^{x-1})$$ $$= p\frac{d}{dZ}\sum_{x=1}^\infty[Z^x], Z=(1-p)(1-f)$$ $$= p\frac{d}{dZ}\frac{Z}{1-Z}$$ $$= \frac{p}{(1-Z)^2}$$ $$= \frac{p}{(p+f-fp)^2}$$ The expected number of throws when the pokemon flees is: $$= f(1-p)\sum_{x=1}^\infty(x[(1-p)(1-f)]^{x-1})$$ $$= f(1-p)\frac{d}{dZ}\sum_{x=1}^\infty[Z^x], Z=(1-p)(1-f)$$ $$= f(1-p)\frac{d}{dZ}\frac{Z}{1-Z}$$ $$= \frac{f(1-p)}{(1-Z)^2}$$ $$= \frac{f(1-p)}{(p+f-fp)^2}$$ The expected number of throws, without knowing whether the pokemon is caught is The probability of successfully catching the pokemon x The expected number of throws at the condition that the pokemon is caught + the probability that the pokemon flees x The expected number of throws when the pokemon flees: $$ \frac{p}{p+f-fp}\times\frac{p}{(p+f-fp)^2} + \frac{(1-p)f}{p+f-fp}\times\frac{f(1-p)}{(p+f-fp)^2}$$ $$ = \frac{p^2+f^2(1-p)^2}{(p+f-fp)^3}$$ Gamepress does not provide the equation ( https://pokemongo.gamepress.gg/catchcalc#/ ), but it appears it is using the same formula described here: https://www.reddit.com/r/TheSilphRoad/comments/59w7cj/analysis_pok%C3%A9mon_go_catch_calculator_new_tool_to/ Which is $$ \frac{1}{p+f-fp}$$ and appears to be $$ \frac{p}{(p+f-fp)^2} +\frac{f(1-p)}{(p+f-fp)^2}$$ Therefore my question is, which formula is correct, and why? Thanks!",,['statistics']
91,Expected return time and limits in discrete time Markov chain,Expected return time and limits in discrete time Markov chain,,"I have a discrete time Markov chain $\{X_n : n\geq 0\}$ with state space $\{1,2,3,4,5\}$ and transition matrix $P=\begin{pmatrix}0.2&0&0&0.8&0\\ 0&0.5&0&0&0.5\\  0.3&0.2&0.5&0&0\\0.3&0&0&0.7&0\\ 0&0.4&0&0&0.6\end{pmatrix}$ I have the following questions: (a) Calculate $\lim_{n\to\infty}p_{11}^{(n)}$ (b) Calculate the mean recurrence time of state 2, given that $X_0 = 2$. The first thing that strikes me is that this chain is aperiodic but not irreducible. However, it is easy to verify that $f_{11} = 1$, thus state 1 is recurrent and aperiodic. Then the limit in part (a) is equal to $\frac{1}{\sum_{n=1}^{\infty}nf_{11}(n)}$, which is, again, easy to work out. As for part (b), I would let $T$ denote the time of first return to state 2 and calculate $\sum_{n=1}^{\infty}P(T\geqslant n)$ to give the expectation. Here is what I would like to ask: 1.) Is my above reasoning correct? 2.) Is there an easier approach to part (a)? 3.) Could you find the expectation in (b) using $\mu_i = \frac{1}{\pi_i}$? I am not sure if you can, since the chain is not irreducible and so the chain possesses infinitely many stationary distributions.","I have a discrete time Markov chain $\{X_n : n\geq 0\}$ with state space $\{1,2,3,4,5\}$ and transition matrix $P=\begin{pmatrix}0.2&0&0&0.8&0\\ 0&0.5&0&0&0.5\\  0.3&0.2&0.5&0&0\\0.3&0&0&0.7&0\\ 0&0.4&0&0&0.6\end{pmatrix}$ I have the following questions: (a) Calculate $\lim_{n\to\infty}p_{11}^{(n)}$ (b) Calculate the mean recurrence time of state 2, given that $X_0 = 2$. The first thing that strikes me is that this chain is aperiodic but not irreducible. However, it is easy to verify that $f_{11} = 1$, thus state 1 is recurrent and aperiodic. Then the limit in part (a) is equal to $\frac{1}{\sum_{n=1}^{\infty}nf_{11}(n)}$, which is, again, easy to work out. As for part (b), I would let $T$ denote the time of first return to state 2 and calculate $\sum_{n=1}^{\infty}P(T\geqslant n)$ to give the expectation. Here is what I would like to ask: 1.) Is my above reasoning correct? 2.) Is there an easier approach to part (a)? 3.) Could you find the expectation in (b) using $\mu_i = \frac{1}{\pi_i}$? I am not sure if you can, since the chain is not irreducible and so the chain possesses infinitely many stationary distributions.",,"['probability', 'statistics', 'stochastic-processes', 'markov-chains', 'markov-process']"
92,Two symmetrical coins - the difference of the tails,Two symmetrical coins - the difference of the tails,,We have two symmetric coins - A and B. We throw a coin A and a coin B 1000 times (per coin). What is the probability that the difference between the number of tails on coin A and the tails on coin B will be at least 100? Coin throws are independent.,We have two symmetric coins - A and B. We throw a coin A and a coin B 1000 times (per coin). What is the probability that the difference between the number of tails on coin A and the tails on coin B will be at least 100? Coin throws are independent.,,"['probability', 'statistics']"
93,Probability Involving Summing the Number on the Balls,Probability Involving Summing the Number on the Balls,,"Suppose three different balls will be randomly drawn without replacement from an urn containing nine balls, numbered $1$ through $9$. What is the probability that one of the three selected balls will be the one numbered $1$ given that the sum of the numbers on the three selected balls is $10$? Attempted Solution: The only cases where the three balls add up to $10$ are, {$1,4,5$},{$1,3,6$}, {$1,2,7$}, {$2,3,5$} Three of which have a one giving $p = .75$. Is this a valid solution? Is there a way to generalize this for balls numbered $1$ through $n$ with $m$ balls selected, and finding the probability of selecting a ball that is numbered $x$, given that the sum is $s$? Just curious about the last part. I think it ties in with partitions, except partitions allows for repeated values.","Suppose three different balls will be randomly drawn without replacement from an urn containing nine balls, numbered $1$ through $9$. What is the probability that one of the three selected balls will be the one numbered $1$ given that the sum of the numbers on the three selected balls is $10$? Attempted Solution: The only cases where the three balls add up to $10$ are, {$1,4,5$},{$1,3,6$}, {$1,2,7$}, {$2,3,5$} Three of which have a one giving $p = .75$. Is this a valid solution? Is there a way to generalize this for balls numbered $1$ through $n$ with $m$ balls selected, and finding the probability of selecting a ball that is numbered $x$, given that the sum is $s$? Just curious about the last part. I think it ties in with partitions, except partitions allows for repeated values.",,"['probability', 'combinatorics', 'statistics']"
94,Understanding Scatterplot relationships and its causes,Understanding Scatterplot relationships and its causes,,"I'm trying to get started with statistics and probability and stumbled upon a scatterplot. I just don't understand the answer of the question, it's probably pretty easy but I just don't get it. Your mathematical understanding can hopefully help me. Question with Scatterplot I get why a and c is wrong and why b is correct. But I don't get why d and e is not correct. If x increments, y increments too. So if the head length increments, the skull width increments too. That's what the chart shows, doesn't it? In addition, would this Skull width and head length are positively associated. be correct? Why, or why not? Kind regards! Source: Openintro.org, Page 12","I'm trying to get started with statistics and probability and stumbled upon a scatterplot. I just don't understand the answer of the question, it's probably pretty easy but I just don't get it. Your mathematical understanding can hopefully help me. Question with Scatterplot I get why a and c is wrong and why b is correct. But I don't get why d and e is not correct. If x increments, y increments too. So if the head length increments, the skull width increments too. That's what the chart shows, doesn't it? In addition, would this Skull width and head length are positively associated. be correct? Why, or why not? Kind regards! Source: Openintro.org, Page 12",,"['probability', 'statistics', 'graphing-functions']"
95,How to maximise this quantity?(probably related to mutual information),How to maximise this quantity?(probably related to mutual information),,"Suppose I have a $n\times n$ matrix $X$ such that all its entries sum up to 1 and all entries are non-negative. Then, I have to maximize this quantity: $$\sum_{i=1}^n\sum_{j=1}^n \left|x_{ij}-\left(\sum_{k=1}^{n}x_{ik}\right)\cdot\left(\sum_{k=1}^{n}x_{kj}\right)\right|$$. So, I think this should be achieved when $X$ is diagonal, but I don't have a concrete argument. I don't really know how to start with this. This is a homework problem and might be related to quadratic mutual information. I am thankful for any hints or solutions.","Suppose I have a $n\times n$ matrix $X$ such that all its entries sum up to 1 and all entries are non-negative. Then, I have to maximize this quantity: $$\sum_{i=1}^n\sum_{j=1}^n \left|x_{ij}-\left(\sum_{k=1}^{n}x_{ik}\right)\cdot\left(\sum_{k=1}^{n}x_{kj}\right)\right|$$. So, I think this should be achieved when $X$ is diagonal, but I don't have a concrete argument. I don't really know how to start with this. This is a homework problem and might be related to quadratic mutual information. I am thankful for any hints or solutions.",,"['linear-algebra', 'statistics', 'multivariable-calculus', 'information-theory']"
96,Fallacy on using interpretation instead of definition in computing conditional probability? (using multiplication law circularly?),Fallacy on using interpretation instead of definition in computing conditional probability? (using multiplication law circularly?),,"This is a following question after Is the definition of conditional probability misleading . After defining the conditional probability this way, Rice immediately introduced the multiplication law: But isn't this law totally circular (if we don't prove extra things)? If we want to know P(A ∩ B) using this law, we must know P(A | B), but P(A | B) can only be computed using P(A ∩ B) if we follow the definition instead of interpretation. Here is an example Rice uses that could illustrate my point: The method he compute P(A|B) is: ""if a red ball has been removed on the first trial, there are two red balls and one blue ball left. Therefore, P(R2 | R1) = 2/3."" But he is using the interpretation of conditional probability instead of the actual definition. I see nowhere in the definition that says you could compute P(A | B) by assuming B is true while all other background information stay the same. Now here is a subtle thing, in almost all his elementary examples, the P is actually unique. So following the axioms you get the same P. In this example, adding ""R1 is true"" into the background information, you could derive an unique P that happens to be equal to the P(..|B) using the definition of conditional probability. But in general in order to let this to happen, you must prove that the two P are the same (one by incorporating B is true into background knowledge and one by using the definition of conditional probability). Is my thinking in here correct? If so, how to state the interpretation clearly and how to prove this interpretation using the definition of conditional probability?","This is a following question after Is the definition of conditional probability misleading . After defining the conditional probability this way, Rice immediately introduced the multiplication law: But isn't this law totally circular (if we don't prove extra things)? If we want to know P(A ∩ B) using this law, we must know P(A | B), but P(A | B) can only be computed using P(A ∩ B) if we follow the definition instead of interpretation. Here is an example Rice uses that could illustrate my point: The method he compute P(A|B) is: ""if a red ball has been removed on the first trial, there are two red balls and one blue ball left. Therefore, P(R2 | R1) = 2/3."" But he is using the interpretation of conditional probability instead of the actual definition. I see nowhere in the definition that says you could compute P(A | B) by assuming B is true while all other background information stay the same. Now here is a subtle thing, in almost all his elementary examples, the P is actually unique. So following the axioms you get the same P. In this example, adding ""R1 is true"" into the background information, you could derive an unique P that happens to be equal to the P(..|B) using the definition of conditional probability. But in general in order to let this to happen, you must prove that the two P are the same (one by incorporating B is true into background knowledge and one by using the definition of conditional probability). Is my thinking in here correct? If so, how to state the interpretation clearly and how to prove this interpretation using the definition of conditional probability?",,"['probability', 'statistics', 'definition']"
97,Selecting the best statistical analysis,Selecting the best statistical analysis,,"I'm going to begin an experiment about drying leaves. I want to learn about how some special kind of leaves are going to dry themselves in 2 different situation. A group of them will stay in a high density, and the another group I will spread out in a bigger area (for example, 1 m2 for the first, and 3 m2 for the second). Of course, I will repeat this experiment several times. In the end, I will get: Individual weight of the leaves (selecting samples) in the beginning Individual weight along 4 days Individual weight in the end Nutritional composition in the start and in the end I am remembering my knowledge in stats and R, but I am still lost. My question is, which is the best comparison method to analyse this data? I want to know: How the humidity content change along the days To dry this kind of leaves, which drying area is better? Is it statistical significance between both method about losing water and nutrient content? Kind regards! Alex.","I'm going to begin an experiment about drying leaves. I want to learn about how some special kind of leaves are going to dry themselves in 2 different situation. A group of them will stay in a high density, and the another group I will spread out in a bigger area (for example, 1 m2 for the first, and 3 m2 for the second). Of course, I will repeat this experiment several times. In the end, I will get: Individual weight of the leaves (selecting samples) in the beginning Individual weight along 4 days Individual weight in the end Nutritional composition in the start and in the end I am remembering my knowledge in stats and R, but I am still lost. My question is, which is the best comparison method to analyse this data? I want to know: How the humidity content change along the days To dry this kind of leaves, which drying area is better? Is it statistical significance between both method about losing water and nutrient content? Kind regards! Alex.",,['statistics']
98,Can we use chi-square distribution and central limit theorem to find the approximate normal distribution?,Can we use chi-square distribution and central limit theorem to find the approximate normal distribution?,,"If $X_1,\ldots,X_i,\ldots,X_n$ are same normal distribution, $X_i \sim \operatorname{Normal}(0,σ^2)$ , and they are independent. $$ Z = \frac{\sum_{i=1}^n X_i^2} n. $$ What is the distribution of the square of the normal distribution?like $X_i^2$ ,and,what is it mean and variance? I am trying to turn this Z into a normal distribution can we use chi-square distribution and central limit theorem to find the approximate normal distribution ? How to do it？ I do not quite understand the chi-square distribution and central limit theorem, could you answer this question in detail? Any help would be much appreciated! re-edit： I do this works: $$ Z = \frac{\sum_{i=1}^n X_i^2} n= σ^2\sum_{i=1}^n \left(\frac{X_i}{σ}\right)^2. $$ this is a chi-square distribution,and mean $= nσ^2$ , var ${}=2nσ^2$ . is this right? and how to use CLT to find the approximate normal distribution?","If are same normal distribution, , and they are independent. What is the distribution of the square of the normal distribution?like ,and,what is it mean and variance? I am trying to turn this Z into a normal distribution can we use chi-square distribution and central limit theorem to find the approximate normal distribution ? How to do it？ I do not quite understand the chi-square distribution and central limit theorem, could you answer this question in detail? Any help would be much appreciated! re-edit： I do this works: this is a chi-square distribution,and mean , var . is this right? and how to use CLT to find the approximate normal distribution?","X_1,\ldots,X_i,\ldots,X_n X_i \sim \operatorname{Normal}(0,σ^2) 
Z = \frac{\sum_{i=1}^n X_i^2} n.
 X_i^2 
Z = \frac{\sum_{i=1}^n X_i^2} n= σ^2\sum_{i=1}^n \left(\frac{X_i}{σ}\right)^2.
 = nσ^2 {}=2nσ^2","['statistics', 'normal-distribution', 'central-limit-theorem', 'chi-squared']"
99,Different Fokker-Plank Equations after change of variables,Different Fokker-Plank Equations after change of variables,,"Let consider a real-valued stochastic process described by the stochastic differential equation (SDE) in the Ito formulation: \begin{align} dx= x \mu dt + x \sigma dW \tag{1} \label{1} \end{align} where $\mu$ and $\sigma$ are real-valued constants and $W$ is a Wiener process. The corresponding Fokker Plank equation (FPE) reads ( https://en.wikipedia.org/wiki/Fokker%E2%80%93Planck_equation ): \begin{align} \frac{\partial P}{\partial t}=-\frac{\partial }{\partial x}(x \mu P)+ \frac{1}{2} \frac{\partial^2 }{\partial x^2} (x^2 \sigma^2 P) \tag{2} \label{2} \end{align} Eq. \ref{2} can be rewritten as: \begin{align} \frac{\partial P}{\partial t}=(\sigma^2-\mu)P+(2 \sigma^2-\mu)x \frac{\partial P }{\partial x} + \frac{x^2 \sigma^2}{2} \frac{\partial^2 P}{\partial x^2} \tag{3} \label{3} \end{align} If we perform a change of variables in eq. \ref{1}, $y=\log x$, applying Ito change of variables formula ( https://en.wikipedia.org/wiki/It%C3%B4%27s_lemma ) we get: \begin{align} dy=  \biggl(\mu- \frac{\sigma^2}{2}\biggr) dt +  \sigma dW  \tag{4} \label{4} \end{align} which corresponds to the FPE: \begin{align} \frac{\partial P}{\partial t}=\biggl(\frac{\sigma^2}{2} -\mu \biggr)\frac{\partial P }{\partial y}+ \frac{\sigma^2}{2}\frac{\partial^2 P}{\partial y^2}   \tag{5} \label{5} \end{align} If we now take eq. \ref{3} and perform the same change of variables of eq. \ref{4}, we get: \begin{align} \frac{\partial P}{\partial t}=(\sigma^2-\mu)P+\biggl(\frac{3}{2} \sigma^2-\mu \biggr) \frac{\partial P }{\partial y} + \frac{ \sigma^2}{2} \frac{\partial^2 P}{\partial y^2} \tag{6} \label{6} \end{align} I expect eq. \ref{5} and \ref{6} to coincide, but they do not. Can someone please explain me the reason? Where am I wrong? Thanks in advance","Let consider a real-valued stochastic process described by the stochastic differential equation (SDE) in the Ito formulation: \begin{align} dx= x \mu dt + x \sigma dW \tag{1} \label{1} \end{align} where $\mu$ and $\sigma$ are real-valued constants and $W$ is a Wiener process. The corresponding Fokker Plank equation (FPE) reads ( https://en.wikipedia.org/wiki/Fokker%E2%80%93Planck_equation ): \begin{align} \frac{\partial P}{\partial t}=-\frac{\partial }{\partial x}(x \mu P)+ \frac{1}{2} \frac{\partial^2 }{\partial x^2} (x^2 \sigma^2 P) \tag{2} \label{2} \end{align} Eq. \ref{2} can be rewritten as: \begin{align} \frac{\partial P}{\partial t}=(\sigma^2-\mu)P+(2 \sigma^2-\mu)x \frac{\partial P }{\partial x} + \frac{x^2 \sigma^2}{2} \frac{\partial^2 P}{\partial x^2} \tag{3} \label{3} \end{align} If we perform a change of variables in eq. \ref{1}, $y=\log x$, applying Ito change of variables formula ( https://en.wikipedia.org/wiki/It%C3%B4%27s_lemma ) we get: \begin{align} dy=  \biggl(\mu- \frac{\sigma^2}{2}\biggr) dt +  \sigma dW  \tag{4} \label{4} \end{align} which corresponds to the FPE: \begin{align} \frac{\partial P}{\partial t}=\biggl(\frac{\sigma^2}{2} -\mu \biggr)\frac{\partial P }{\partial y}+ \frac{\sigma^2}{2}\frac{\partial^2 P}{\partial y^2}   \tag{5} \label{5} \end{align} If we now take eq. \ref{3} and perform the same change of variables of eq. \ref{4}, we get: \begin{align} \frac{\partial P}{\partial t}=(\sigma^2-\mu)P+\biggl(\frac{3}{2} \sigma^2-\mu \biggr) \frac{\partial P }{\partial y} + \frac{ \sigma^2}{2} \frac{\partial^2 P}{\partial y^2} \tag{6} \label{6} \end{align} I expect eq. \ref{5} and \ref{6} to coincide, but they do not. Can someone please explain me the reason? Where am I wrong? Thanks in advance",,"['probability', 'statistics', 'partial-differential-equations', 'stochastic-processes', 'stochastic-calculus']"
