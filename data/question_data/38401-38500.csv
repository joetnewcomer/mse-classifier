,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,How to choose correct strategy for irreducibility testing in $\mathbb{Z}[X]$?,How to choose correct strategy for irreducibility testing in ?,\mathbb{Z}[X],"In the standard abstract algebra curriculum, one learns a battery of irreducibility tests for factoring polynomials over $\mathbb{Z}$ (equivalently, by Gauss' lemma, over $\mathbb{Q}$).  For instance (not all names standard): Linear Factor Test: A polynomial has a linear factor over $\mathbb{Z}$ if and only if it has a root in $\mathbb{Q}$. Quadratic/Cubic Test: A polynomial of degree 2 or 3 is reducible if and only if it has a linear factor. Brute Force Method: Write out the forms of all possible factorizations.  For instance, after checking a quartic for linear factors, look at $(X^2+aX+b)(X^2+cX+d)$.  Obtain a system of equations for the coefficients.  Determine whether solutions exist.  Ugh.  (Though, more feasible over $\mathbb{Z}_p$.) Mod-$p$ Irreducibility Test: If there exists a prime $p$ such that a polynomial is irreducible over $\mathbb{Z}_p$, then it is irreducible over $\mathbb{Z}$. Eisenstein's Criterion: If there exists a prime $p$ which divides all but the lead coefficient, and whose square does not divide the constant term, then the polynomial is irreducible. Substitution tricks: The reducibility of a given polynomial $f(X)$ is related to the reducibility of other polynomials like $f(aX+b)$ or the reversal $X^n f(1/X)$. Complexify: Factor the polynomial into linear factors over $\mathbb{C}$.  Every higher-degree divisor of the polynomial is a product of several of these linear factors.  Try out all the products of the linear factors and verify that all of them have non-integer coefficients.  (See for instance Jyrki Lahtonen's solution in this post ). Special cases: E.g. cyclotomic polynomials are something you should just know. These are often used in combination.  One can prove that $X^4+X+1$ is irreducible over $\mathbb{Z}$ by showing it's irreducible over $\mathbb{Z}_2$, which in turn can be easily done by the ""brute-force"" approach since there are very few quadratics over $\mathbb{Z}_2$.  Jyrki Lahtonen's solution in this post shows that $f(X):=X^4-10X^2+1$ is irreducible by applying Eisenstein with $p=2$ to the reversal of $\frac{1}{8} f(2X+1)$.  (Gorgeous!) How does one get a sense for which tricks to try when?  There are infinitely many primes $p$ to try with Eisenstein and mod-$p$ tests, though in practice $p$ tends to be small.  Allowing substitution tricks opens up a dizzying array of possibilities.  I'm thinking by analogy with the convergence tests one learns in calculus.  One can just try different approaches until one of them works, but one can also see patterns: a series with powers or factorials is likely amenable to the Ratio Test, terms of ""smaller order"" can be eliminated by the Limit Comparison Test, terms that you know how to bound can be handled by the Comparison Test, and functions you know how to integrate are promising candidates for the Integral Test. Are there analogous clues to look for here?  How might you ""smell"" which test is likely to work with which polynomial?","In the standard abstract algebra curriculum, one learns a battery of irreducibility tests for factoring polynomials over $\mathbb{Z}$ (equivalently, by Gauss' lemma, over $\mathbb{Q}$).  For instance (not all names standard): Linear Factor Test: A polynomial has a linear factor over $\mathbb{Z}$ if and only if it has a root in $\mathbb{Q}$. Quadratic/Cubic Test: A polynomial of degree 2 or 3 is reducible if and only if it has a linear factor. Brute Force Method: Write out the forms of all possible factorizations.  For instance, after checking a quartic for linear factors, look at $(X^2+aX+b)(X^2+cX+d)$.  Obtain a system of equations for the coefficients.  Determine whether solutions exist.  Ugh.  (Though, more feasible over $\mathbb{Z}_p$.) Mod-$p$ Irreducibility Test: If there exists a prime $p$ such that a polynomial is irreducible over $\mathbb{Z}_p$, then it is irreducible over $\mathbb{Z}$. Eisenstein's Criterion: If there exists a prime $p$ which divides all but the lead coefficient, and whose square does not divide the constant term, then the polynomial is irreducible. Substitution tricks: The reducibility of a given polynomial $f(X)$ is related to the reducibility of other polynomials like $f(aX+b)$ or the reversal $X^n f(1/X)$. Complexify: Factor the polynomial into linear factors over $\mathbb{C}$.  Every higher-degree divisor of the polynomial is a product of several of these linear factors.  Try out all the products of the linear factors and verify that all of them have non-integer coefficients.  (See for instance Jyrki Lahtonen's solution in this post ). Special cases: E.g. cyclotomic polynomials are something you should just know. These are often used in combination.  One can prove that $X^4+X+1$ is irreducible over $\mathbb{Z}$ by showing it's irreducible over $\mathbb{Z}_2$, which in turn can be easily done by the ""brute-force"" approach since there are very few quadratics over $\mathbb{Z}_2$.  Jyrki Lahtonen's solution in this post shows that $f(X):=X^4-10X^2+1$ is irreducible by applying Eisenstein with $p=2$ to the reversal of $\frac{1}{8} f(2X+1)$.  (Gorgeous!) How does one get a sense for which tricks to try when?  There are infinitely many primes $p$ to try with Eisenstein and mod-$p$ tests, though in practice $p$ tends to be small.  Allowing substitution tricks opens up a dizzying array of possibilities.  I'm thinking by analogy with the convergence tests one learns in calculus.  One can just try different approaches until one of them works, but one can also see patterns: a series with powers or factorials is likely amenable to the Ratio Test, terms of ""smaller order"" can be eliminated by the Limit Comparison Test, terms that you know how to bound can be handled by the Comparison Test, and functions you know how to integrate are promising candidates for the Integral Test. Are there analogous clues to look for here?  How might you ""smell"" which test is likely to work with which polynomial?",,"['abstract-algebra', 'soft-question', 'irreducible-polynomials']"
1,History behind Exact Sequences.,History behind Exact Sequences.,,I am very much interested in listening to the history behind the exact sequence. We know that the exact sequence is sequence of objects with morphisms such that image of one morphism equals to the kernel of the next one. But how did the whole idea start ? . What is the motivation behind considering the image and kernel equality and linking groups ? . How did the exact sequences come into play ?. I want to hear some on some of the above things. Thank you.,I am very much interested in listening to the history behind the exact sequence. We know that the exact sequence is sequence of objects with morphisms such that image of one morphism equals to the kernel of the next one. But how did the whole idea start ? . What is the motivation behind considering the image and kernel equality and linking groups ? . How did the exact sequences come into play ?. I want to hear some on some of the above things. Thank you.,,"['math-history', 'homological-algebra', 'motivation', 'abstract-algebra']"
2,Ring without distributive law?,Ring without distributive law?,,"I recently came across a binary operation (in a very non-algebraic context - it's a way to organize a certain updating of log-likelihood-ratios) and was idly wondering whether it is any kind of reasonable algebraic object. The answer may well be no but it does satisfy some properties that look like those of a ring. Let $\boxplus \colon \mathbb{R} \times \mathbb{R} \to \mathbb{R}$ be given by $a \boxplus b = \log\left(\frac{1+e^{a+b}}{e^a+e^b}\right)$. It's a fun exercise to check the following properties: $a\boxplus b=b \boxplus a$ $a\boxplus b=0$ iff $a=0$ or $b=0$ $a \boxplus (-b) = (-a) \boxplus b= -(a \boxplus b)$ $a \boxplus \infty = a$, in the sense that $\displaystyle \lim_{x \to \infty} a\boxplus x=a$ $(a\boxplus b) \boxplus c=a \boxplus (b \boxplus c)$ So just looking at these properties I though maybe $(\mathbb{R},+,\boxplus)$ is a commutative ring without identity. But it doesn't satisfy the distributive law. Is there anything that can be said about such a structure? Edit: After a helpful comment from Bill I would like to point out which of these properties I find 'ringlike'. Property 3 is a statement that is true in a ring and doesn't make sense in just the semigroup $(\mathbb{R},\boxplus)$. Property 2 is the definition of an integral domain (if it was a ring). So it seems to me that having $-$ and $0$ puts me in the mind of connecting $\boxplus$ with $+$. But I don't know if this is necessary: is there some theory of semigroups with an extra unary negation operator? Maybe that's all I need.","I recently came across a binary operation (in a very non-algebraic context - it's a way to organize a certain updating of log-likelihood-ratios) and was idly wondering whether it is any kind of reasonable algebraic object. The answer may well be no but it does satisfy some properties that look like those of a ring. Let $\boxplus \colon \mathbb{R} \times \mathbb{R} \to \mathbb{R}$ be given by $a \boxplus b = \log\left(\frac{1+e^{a+b}}{e^a+e^b}\right)$. It's a fun exercise to check the following properties: $a\boxplus b=b \boxplus a$ $a\boxplus b=0$ iff $a=0$ or $b=0$ $a \boxplus (-b) = (-a) \boxplus b= -(a \boxplus b)$ $a \boxplus \infty = a$, in the sense that $\displaystyle \lim_{x \to \infty} a\boxplus x=a$ $(a\boxplus b) \boxplus c=a \boxplus (b \boxplus c)$ So just looking at these properties I though maybe $(\mathbb{R},+,\boxplus)$ is a commutative ring without identity. But it doesn't satisfy the distributive law. Is there anything that can be said about such a structure? Edit: After a helpful comment from Bill I would like to point out which of these properties I find 'ringlike'. Property 3 is a statement that is true in a ring and doesn't make sense in just the semigroup $(\mathbb{R},\boxplus)$. Property 2 is the definition of an integral domain (if it was a ring). So it seems to me that having $-$ and $0$ puts me in the mind of connecting $\boxplus$ with $+$. But I don't know if this is necessary: is there some theory of semigroups with an extra unary negation operator? Maybe that's all I need.",,"['abstract-algebra', 'semigroups']"
3,Proving that a polynomial of the form $(x-a_1)\cdots(x-a_n) + 1$ is irreducible over $\mathbb{Q}$,Proving that a polynomial of the form  is irreducible over,(x-a_1)\cdots(x-a_n) + 1 \mathbb{Q},"I want to prove that for any set of distinct integers $a_1,\ldots,a_n$, the polynomial $$h = (x-a_1)\cdots(x-a_n) + 1$$ is irreducible over the field $\mathbb{Q}$, except for the following special cases which are reducible: $$\left.\begin{cases} a_1 = a\\ a_2 = a+2 \end{cases}\right\} \implies h = (x-a-1)^2$$ and $$\left.\begin{cases} a_1 = a\\ a_2 = a+1\\ a_3 = a+2\\ a_4 = a+3 \end{cases}\right\} \implies h = ((x-a-1)(x-a-2)-1)^2$$","I want to prove that for any set of distinct integers $a_1,\ldots,a_n$, the polynomial $$h = (x-a_1)\cdots(x-a_n) + 1$$ is irreducible over the field $\mathbb{Q}$, except for the following special cases which are reducible: $$\left.\begin{cases} a_1 = a\\ a_2 = a+2 \end{cases}\right\} \implies h = (x-a-1)^2$$ and $$\left.\begin{cases} a_1 = a\\ a_2 = a+1\\ a_3 = a+2\\ a_4 = a+3 \end{cases}\right\} \implies h = ((x-a-1)(x-a-2)-1)^2$$",,"['abstract-algebra', 'polynomials', 'irreducible-polynomials']"
4,"What are all conditions on a finite sequence $x_1,x_2,...,x_m$ such that it is the sequence of orders of elements of a group?",What are all conditions on a finite sequence  such that it is the sequence of orders of elements of a group?,"x_1,x_2,...,x_m","My Definition: The finite sequence $x_1,x_2,...,x_m$ of nonnegative integers is said to be generated by a finite group $G$ iff $n:=|G|=x_1+x_2+\cdots+x_m$. $n$ has $m$ divisors. if $d_1<d_2<\cdots<d_m$ are all divisors of  $n$, for every $k = {1,...,m}$ we have $$x_k=\left|\{x \in G  \mid o(x)=d_k\}\right|.$$ What are all conditions on a finite sequence $x_1,x_2,...,x_m$ such that it is generated by some group $G$? Some conditions I found: For $k = {1,...,m}$ we have $$\phi(d_k)\mid x_k$$ where $m$ and $d_k$ are as above. $x_1=1$. $x_m\leq\phi(n)$ and if $x_m=\phi(d_m)$ then for $k = {1,...,m}$, $$x_k=\phi(d_k) $$ If $x_k\ne 0$ then for every $i$ such that $d_i|d_k$, we have $$x_i\ne 0$$ If $d_k$ is a prime, $$x_k\ne 0$$","My Definition: The finite sequence $x_1,x_2,...,x_m$ of nonnegative integers is said to be generated by a finite group $G$ iff $n:=|G|=x_1+x_2+\cdots+x_m$. $n$ has $m$ divisors. if $d_1<d_2<\cdots<d_m$ are all divisors of  $n$, for every $k = {1,...,m}$ we have $$x_k=\left|\{x \in G  \mid o(x)=d_k\}\right|.$$ What are all conditions on a finite sequence $x_1,x_2,...,x_m$ such that it is generated by some group $G$? Some conditions I found: For $k = {1,...,m}$ we have $$\phi(d_k)\mid x_k$$ where $m$ and $d_k$ are as above. $x_1=1$. $x_m\leq\phi(n)$ and if $x_m=\phi(d_m)$ then for $k = {1,...,m}$, $$x_k=\phi(d_k) $$ If $x_k\ne 0$ then for every $i$ such that $d_i|d_k$, we have $$x_i\ne 0$$ If $d_k$ is a prime, $$x_k\ne 0$$",,"['abstract-algebra', 'group-theory']"
5,Proving a ring in which $r^n=r$ for all $r$ is commutative.,Proving a ring in which  for all  is commutative.,r^n=r r,Let $R$ be a ring with identity such that there is a positive integer $n\geq 2$ for which $r^n=r$ for all $r\in R$ . Prove $R$ is commutative. I had proven before that If $n=2$ it is commutative as follows: $r+s=(r+s)^2=r^2+rs+sr+r^2=r+rs+sr+s\implies 0=rs+sr\implies sr=-rs$ On the other hand $-r=(-1)r=(-1)^2r=r$ . So $sr=-rs=rs$ as desired. I seem to be stumped even with $n=3$ .,Let be a ring with identity such that there is a positive integer for which for all . Prove is commutative. I had proven before that If it is commutative as follows: On the other hand . So as desired. I seem to be stumped even with .,R n\geq 2 r^n=r r\in R R n=2 r+s=(r+s)^2=r^2+rs+sr+r^2=r+rs+sr+s\implies 0=rs+sr\implies sr=-rs -r=(-1)r=(-1)^2r=r sr=-rs=rs n=3,"['abstract-algebra', 'ring-theory']"
6,Mysterious Characterization of $A_5$ inside $S_5$,Mysterious Characterization of  inside,A_5 S_5,"When I was trying to explain a combinatorial curiosity using permutation groups, I finally ended up with another curiosity about the alternating group $A_5$. For any permutation $\pi \in S_5$, let $\chi(\pi)$ denote the number of fixed points of $\pi$. Furthermore, as usual, let $[\pi,\sigma] := \pi^{-1}\sigma^{-1}\pi\sigma$ denote the commutator of two permutations $\pi, \sigma$. Now I found out that the following holds: Let $\sigma \in S_5$ be an arbitrary cycle of length 5. Then we have $$A_5 = \{ \pi \in S_5 : \chi([\sigma, \pi]) + \chi(\sigma^2 [\sigma, \pi]) \in \{2,5\} \}. $$ Isn't that strange!? I verified that equation with a computer, but I have absolutely no idea how to prove it. Even proving the original combinatorial problem wouldn't help immediately, because the group theoretical statement is stronger. Is there any chance to prove that characterization of $A_5$ by group theory?","When I was trying to explain a combinatorial curiosity using permutation groups, I finally ended up with another curiosity about the alternating group $A_5$. For any permutation $\pi \in S_5$, let $\chi(\pi)$ denote the number of fixed points of $\pi$. Furthermore, as usual, let $[\pi,\sigma] := \pi^{-1}\sigma^{-1}\pi\sigma$ denote the commutator of two permutations $\pi, \sigma$. Now I found out that the following holds: Let $\sigma \in S_5$ be an arbitrary cycle of length 5. Then we have $$A_5 = \{ \pi \in S_5 : \chi([\sigma, \pi]) + \chi(\sigma^2 [\sigma, \pi]) \in \{2,5\} \}. $$ Isn't that strange!? I verified that equation with a computer, but I have absolutely no idea how to prove it. Even proving the original combinatorial problem wouldn't help immediately, because the group theoretical statement is stronger. Is there any chance to prove that characterization of $A_5$ by group theory?",,"['abstract-algebra', 'combinatorics', 'group-theory', 'finite-groups', 'permutations']"
7,Intuition behind Hilbert's Nullstellensatz,Intuition behind Hilbert's Nullstellensatz,,"Maybe that's a pointless question, however I'm having problems in ""understanding"" (accepting) the Hilbert's Nullstellensatz. I understand the proof; however, I do not understand the concept in a more constructive way. I think the source of my doubt is in the fact that maximal ideals in $k[x_1, x_2, ..., x_n]$ are always in the form $\mathfrak{m} = (x_1 - a_1, x_2 - a_2, ..., x_n - a_n )$ and in the fact that $k[x_1, x_2, ..., x_n]/\mathfrak{m} \cong k$ if $k$ is algebraically closed. I know that these results follow directly from this result: If $R$ is a finitely generated $k$ -algebra ( $k$ maybe not algebraically closed) and $R$ is a field, then $R/k$ is an algebraic extension (which I think that's anti-intuitive too and all the proofs that I found seems very unnatural). Is there any constructive proof or algorithm to these facts or some illuminating example? Thanks in advance.","Maybe that's a pointless question, however I'm having problems in ""understanding"" (accepting) the Hilbert's Nullstellensatz. I understand the proof; however, I do not understand the concept in a more constructive way. I think the source of my doubt is in the fact that maximal ideals in are always in the form and in the fact that if is algebraically closed. I know that these results follow directly from this result: If is a finitely generated -algebra ( maybe not algebraically closed) and is a field, then is an algebraic extension (which I think that's anti-intuitive too and all the proofs that I found seems very unnatural). Is there any constructive proof or algorithm to these facts or some illuminating example? Thanks in advance.","k[x_1, x_2, ..., x_n] \mathfrak{m} = (x_1 - a_1, x_2 - a_2, ..., x_n - a_n ) k[x_1, x_2, ..., x_n]/\mathfrak{m} \cong k k R k k R R/k","['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'intuition']"
8,field generated by a set,field generated by a set,,"Let $S$ be the set of real numbers which can be written in the form $  \sum_{n\geq0}{ \frac{\epsilon_{n}}{n!}}$ ,where ${\epsilon_n}^2=\epsilon_n$ and let $K$ be the field generated by $S$ , help me to prove or disprove that $K=\mathbb{R}$ where $\mathbb{R}$ is the set of real numbers. Thanks","Let $S$ be the set of real numbers which can be written in the form $  \sum_{n\geq0}{ \frac{\epsilon_{n}}{n!}}$ ,where ${\epsilon_n}^2=\epsilon_n$ and let $K$ be the field generated by $S$ , help me to prove or disprove that $K=\mathbb{R}$ where $\mathbb{R}$ is the set of real numbers. Thanks",,"['abstract-algebra', 'field-theory']"
9,Can octonions be represented by infinite matrices?,Can octonions be represented by infinite matrices?,,"It is sometimes possible to multiply matrices of countably-infinite dimension. (Matrix multiplication is defined in the usual way, with rows and columns multiplied termwise and summed.) However, it turns out the associative property fails in general for infinite matrices, due to conditional convergence of infinite series. Meanwhile, the octonions $\mathbb{O}$ are a unital nonassociative $8$ -dimensional algebra that cannot be represented by $n\times n$ matrices (else they would associate). So it seems natural to ask, is is possible to represent $\mathbb{O}$ by infinite matrices? I suppose one plan would be to take a finite-dimensional representation of the quaternions $\mathbb{H}$ , ""copy and paste"" it into infinite matrices, and then find an infinite matrix for $\ell\in\mathbb{O}$ that squares to $-I$ and satisfies the rules of the Cayley-Dickson construction, but I don't see a way to do this. (I suppose one could also generalize this question to arbitrary nonassociative algebras.)","It is sometimes possible to multiply matrices of countably-infinite dimension. (Matrix multiplication is defined in the usual way, with rows and columns multiplied termwise and summed.) However, it turns out the associative property fails in general for infinite matrices, due to conditional convergence of infinite series. Meanwhile, the octonions are a unital nonassociative -dimensional algebra that cannot be represented by matrices (else they would associate). So it seems natural to ask, is is possible to represent by infinite matrices? I suppose one plan would be to take a finite-dimensional representation of the quaternions , ""copy and paste"" it into infinite matrices, and then find an infinite matrix for that squares to and satisfies the rules of the Cayley-Dickson construction, but I don't see a way to do this. (I suppose one could also generalize this question to arbitrary nonassociative algebras.)",\mathbb{O} 8 n\times n \mathbb{O} \mathbb{H} \ell\in\mathbb{O} -I,"['abstract-algebra', 'matrices', 'representation-theory', 'octonions', 'nonassociative-algebras']"
10,"A ""generalized field"" with $q$ elements, when $q$ is any number?","A ""generalized field"" with  elements, when  is any number?",q q,"It is well-known that if a finite field has $q \in \mathbb{N}$ elements, then $q$ is prime power and $q > 1$. However, various modification of the concept of a ""field"" have been made in order to make sense of $\mathbb{F}_1$, the field with $1$ ""element"". See for instance Mapping $\mathbb{F}_1$-land for an overview. In combinatorics, the notion of a q-analog has a structural interpretation only when $q$ is a prime power (now including $q=1$), which is kind of awkward. Question. Can you think of a reasonable notion of a ""generalized field"" such that, for every natural number $q \geq 1$ there is a ""generalized field"" $\mathbb{F}_q$ with $q$ ""elements""? Here are some minimal requirements: The category of fields should have a fully faithful functor to the category of generalized fields. If $q$ is a prime power, then this embedding should map $\mathbb{F}_q$ to $\mathbb{F}_q$. Every $\mathbb{F}_q$-""module"" should be free. There should be a morphism $\mathbb{F}_q \to \mathbb{F}_{q'}$ if and only if $v_p(q)|v_p(q')$ for each prime $p$. The number of monic irreducible polynomials of degree $n$ over $\mathbb{F}_q$ (suitably defined) should be $\sum_{d|n} \mu(d) \cdot q^{n/d}$.","It is well-known that if a finite field has $q \in \mathbb{N}$ elements, then $q$ is prime power and $q > 1$. However, various modification of the concept of a ""field"" have been made in order to make sense of $\mathbb{F}_1$, the field with $1$ ""element"". See for instance Mapping $\mathbb{F}_1$-land for an overview. In combinatorics, the notion of a q-analog has a structural interpretation only when $q$ is a prime power (now including $q=1$), which is kind of awkward. Question. Can you think of a reasonable notion of a ""generalized field"" such that, for every natural number $q \geq 1$ there is a ""generalized field"" $\mathbb{F}_q$ with $q$ ""elements""? Here are some minimal requirements: The category of fields should have a fully faithful functor to the category of generalized fields. If $q$ is a prime power, then this embedding should map $\mathbb{F}_q$ to $\mathbb{F}_q$. Every $\mathbb{F}_q$-""module"" should be free. There should be a morphism $\mathbb{F}_q \to \mathbb{F}_{q'}$ if and only if $v_p(q)|v_p(q')$ for each prime $p$. The number of monic irreducible polynomials of degree $n$ over $\mathbb{F}_q$ (suitably defined) should be $\sum_{d|n} \mu(d) \cdot q^{n/d}$.",,"['abstract-algebra', 'algebraic-geometry', 'soft-question', 'finite-fields']"
11,Algebraic extensions are isomorphic if the same polynomials have roots,Algebraic extensions are isomorphic if the same polynomials have roots,,"I want to solve the following excercise. Let $K$ be a (perfect) field and $L_1, L_2$ be two algebraic   extensions of $K$ . Then $L_1$ and $L_2$ are isomorphic if every   polynomial $f\in K[X]$ which has a root in $L_1$ has a root in $L_2$ and vice versa. The hint is to use either the Compactness Theorem to reduce to the case of finitely generated subfields of $L_1, L_2$ or to use König's Lemma from Graph Theory. For the finitely generated case let $F=K(a_1,\dots,a_n)$ for some $a_1,\dots,a_n\in L_1$ . By the Primitive Element Theorem we have $F=K(a)$ for some $a\in L_1$ and by assumption the minimal polynomial $\mathfrak{m}_a$ of $a$ over $K$ has a root $b\in L_2$ . Then clearly $K(a)\cong K(b)$ . My problem is that I'm not really sure how I can use the compactness theorem to reduce to this case. It is probably easy, but I think my problem is that I am used to applying the Compactness Theorem to build structures with certain properties and not maps between structures. Question: How can this proof be finished off by the compactness theorem? Are there any general techniques how compactness can be used to build isomorphisms between structures rather than structures? I would also like to see a proof using the König's Lemma approach (because afaik König's Lemma is strictly weaker than the Compactenss Theorem over $\mathrm{ZF}$ (?)) but I dont know how to build the tree in this case. (Maybe we have to assume that $K$ is countable?) Question: Can we prove the above statement (under some reasonable additional assumptions) in $\mathrm{ZF}+$ König's Lemma?","I want to solve the following excercise. Let be a (perfect) field and be two algebraic   extensions of . Then and are isomorphic if every   polynomial which has a root in has a root in and vice versa. The hint is to use either the Compactness Theorem to reduce to the case of finitely generated subfields of or to use König's Lemma from Graph Theory. For the finitely generated case let for some . By the Primitive Element Theorem we have for some and by assumption the minimal polynomial of over has a root . Then clearly . My problem is that I'm not really sure how I can use the compactness theorem to reduce to this case. It is probably easy, but I think my problem is that I am used to applying the Compactness Theorem to build structures with certain properties and not maps between structures. Question: How can this proof be finished off by the compactness theorem? Are there any general techniques how compactness can be used to build isomorphisms between structures rather than structures? I would also like to see a proof using the König's Lemma approach (because afaik König's Lemma is strictly weaker than the Compactenss Theorem over (?)) but I dont know how to build the tree in this case. (Maybe we have to assume that is countable?) Question: Can we prove the above statement (under some reasonable additional assumptions) in König's Lemma?","K L_1, L_2 K L_1 L_2 f\in K[X] L_1 L_2 L_1, L_2 F=K(a_1,\dots,a_n) a_1,\dots,a_n\in L_1 F=K(a) a\in L_1 \mathfrak{m}_a a K b\in L_2 K(a)\cong K(b) \mathrm{ZF} K \mathrm{ZF}+","['abstract-algebra', 'field-theory', 'model-theory', 'axiom-of-choice']"
12,"Meaning of ""kernel""","Meaning of ""kernel""",,"In analysis, there are at least three kinds of "" kernel "" concepts: In probability theory, there is a concept called transition probability , also called probability kernel, from one measure space $X$ to another $Y$. It is actually a family of measures on $Y$, indexed by members of $X$. It can transform a measure on $X$ to a measure on $Y$, in terms of integration. A special case is kernel density estimation of probability density function in statistics, where the kernel is actually a probability kernel. In real/complex analysis, there is a concept called kernel function from a product space $X \times Y$ to $\mathbb{R}$ or $\mathbb{C}$. It can transform some special function: $X \to \mathbb{R}$ or $\mathbb{C}$ to another one:$Y \to \mathbb{R}$ or $\mathbb{C}$. This is used for defining integral transformation In Hilbert space theory, there is concept called positive definite kernel , which is a family of bounded mappings for a family of Hilbert spaces. For every two Hilbert spaces $X$ and $Y$ in the family, there are exactly two members of the kernel, one mapping from $X$ to $Y$ and the other from $Y$ to $X$. I wonder Are they related concepts, since they seem to share some indescribable similarity? Can they be unified? In particular, the first two are similar to each other as the kernels induce transformations on measures and on functions in terms of integrals. It is however not obvious to me how the third one, i.e. the Hilbert space one, is related to the second one. Are they related to the algebraic kernel concepts? Or even to the categorical kernel concept? I feel like some insights and references for catching the general ideas shared across as many kinds of ""kernels"" as possible. Thanks and regards!","In analysis, there are at least three kinds of "" kernel "" concepts: In probability theory, there is a concept called transition probability , also called probability kernel, from one measure space $X$ to another $Y$. It is actually a family of measures on $Y$, indexed by members of $X$. It can transform a measure on $X$ to a measure on $Y$, in terms of integration. A special case is kernel density estimation of probability density function in statistics, where the kernel is actually a probability kernel. In real/complex analysis, there is a concept called kernel function from a product space $X \times Y$ to $\mathbb{R}$ or $\mathbb{C}$. It can transform some special function: $X \to \mathbb{R}$ or $\mathbb{C}$ to another one:$Y \to \mathbb{R}$ or $\mathbb{C}$. This is used for defining integral transformation In Hilbert space theory, there is concept called positive definite kernel , which is a family of bounded mappings for a family of Hilbert spaces. For every two Hilbert spaces $X$ and $Y$ in the family, there are exactly two members of the kernel, one mapping from $X$ to $Y$ and the other from $Y$ to $X$. I wonder Are they related concepts, since they seem to share some indescribable similarity? Can they be unified? In particular, the first two are similar to each other as the kernels induce transformations on measures and on functions in terms of integrals. It is however not obvious to me how the third one, i.e. the Hilbert space one, is related to the second one. Are they related to the algebraic kernel concepts? Or even to the categorical kernel concept? I feel like some insights and references for catching the general ideas shared across as many kinds of ""kernels"" as possible. Thanks and regards!",,"['abstract-algebra', 'analysis', 'probability-theory', 'category-theory', 'hilbert-spaces']"
13,Are all finite fields isomorphic to $\mathbb{F}_p$?,Are all finite fields isomorphic to ?,\mathbb{F}_p,"I've recently started taking some algebra courses and I was wondering whether or not every finite field is isomorphic to $\mathbb{F}_p$, where $p$ is prime.","I've recently started taking some algebra courses and I was wondering whether or not every finite field is isomorphic to $\mathbb{F}_p$, where $p$ is prime.",,"['abstract-algebra', 'field-theory', 'finite-fields']"
14,Must the centralizer of an element of a group be abelian?,Must the centralizer of an element of a group be abelian?,,"Must the centralizer of an element of a group be abelian? I see that the definition of centralizer is: Let $a$ be a fixed element of a group $G$. The centralizer of $a$ in $G$, $C(a)$, is the set of all elements in $G$ that will commute with $a$. In symbols, $C(a)=\{g\in G \mid ga=ag\}$. But this doesn't necessarily mean that the centralizer is abelian, does it?","Must the centralizer of an element of a group be abelian? I see that the definition of centralizer is: Let $a$ be a fixed element of a group $G$. The centralizer of $a$ in $G$, $C(a)$, is the set of all elements in $G$ that will commute with $a$. In symbols, $C(a)=\{g\in G \mid ga=ag\}$. But this doesn't necessarily mean that the centralizer is abelian, does it?",,"['abstract-algebra', 'group-theory']"
15,Show identity of subgroup is same as identity of group,Show identity of subgroup is same as identity of group,,"Let $H$ be a subgroup of $G$ . Let $1_H$ and $1_G$ be the identities of $H$ and $G$ , respectively. Show that $1_H=1_G$ . My attempt is: since we know that the identity of a group is unique, and hence $1_H=1_G$ . Is my proof correct?","Let be a subgroup of . Let and be the identities of and , respectively. Show that . My attempt is: since we know that the identity of a group is unique, and hence . Is my proof correct?",H G 1_H 1_G H G 1_H=1_G 1_H=1_G,"['abstract-algebra', 'group-theory']"
16,A finite field cannot be an ordered field.,A finite field cannot be an ordered field.,,"I am reading baby Rudin and it says all ordered fields with supremum property are isomorphic to $\mathbb R$. Since all ordered  finite fields would have supremum property that must mean none exist. Could someone please show me a proof of this? Thank you very much, Regards.","I am reading baby Rudin and it says all ordered fields with supremum property are isomorphic to $\mathbb R$. Since all ordered  finite fields would have supremum property that must mean none exist. Could someone please show me a proof of this? Thank you very much, Regards.",,"['abstract-algebra', 'field-theory', 'ordered-fields']"
17,Why are abelian groups of interest? What is their usefulness?,Why are abelian groups of interest? What is their usefulness?,,"I am reading about Abelian groups So apparently it is a set, with an associative binary operation, and identity element, an inverse operation and the binary operation must also be symmetric. But it is not clear to me how they are useful. Trying to find why they are important it seems they arise as ""additive structures"" in various systems but this is too abstract for me. Could someone give some less formal/more practical application or usages showing what is important about abelian groups (layman's terms basically)?","I am reading about Abelian groups So apparently it is a set, with an associative binary operation, and identity element, an inverse operation and the binary operation must also be symmetric. But it is not clear to me how they are useful. Trying to find why they are important it seems they arise as ""additive structures"" in various systems but this is too abstract for me. Could someone give some less formal/more practical application or usages showing what is important about abelian groups (layman's terms basically)?",,"['abstract-algebra', 'group-theory', 'abelian-groups', 'motivation']"
18,"If $xy$ is a unit, are $x$ and $y$ units?","If  is a unit, are  and  units?",xy x y,"I know if $x$ and $y$ are units, in say a commutative ring, then $xy$ is a unit with $(xy)^{-1}=y^{-1}x^{-1}$. But if $xy$ is a unit, does it necessarily follow that $x$ and $y$ are units?","I know if $x$ and $y$ are units, in say a commutative ring, then $xy$ is a unit with $(xy)^{-1}=y^{-1}x^{-1}$. But if $xy$ is a unit, does it necessarily follow that $x$ and $y$ are units?",,"['abstract-algebra', 'ring-theory']"
19,In a finite field product of non-square elements is a square,In a finite field product of non-square elements is a square,,"I came across one problem in a finite field as follows: Let $F$ be a finite field. Show that if $a, b\in F$ both are non-squares, then $ab$ is a square. I wanted to prove it by using the idea of Biquadratic field extension. But there is no biquadratic extension over finite fields. Please, any hints for proving above fact? Thanks.","I came across one problem in a finite field as follows: Let be a finite field. Show that if both are non-squares, then is a square. I wanted to prove it by using the idea of Biquadratic field extension. But there is no biquadratic extension over finite fields. Please, any hints for proving above fact? Thanks.","F a, b\in F ab","['abstract-algebra', 'finite-fields']"
20,$S_4$ does not have a normal subgroup of order $8$,does not have a normal subgroup of order,S_4 8,"Question is to prove that : $S_4$ does not have a normal subgroup of order $8$ I do not have any specific idea how to proceed but: Assuming there exists a normal subgroup $H$ of order $8$ in $S_4$,  As $H\unlhd G$, $HK\leq G$ for any subgroup $K\leq G$ and $|HK|=\frac{|H||K|}{|H\cap K|}$ what i am trying to do is try getting an element $ x $ of order $2$ which is not in $H$ and set $K=\{1,x\}$ then $HK$ would be a group of order $16$ which is a contradiction as $S_4$  can not have a subgroup of order $16$. as there are six $2-cycles$ and three  products of disjoint $2$ cycles but $|H|=8$, there does exists an element of order $2$ which is not in $H$ and thus we are done. I am sure this would be the nicest way or the stupidest way one can ever do :P I would be thankful if someone can help me to see if anything is wrong in my approach. I would be thankful if someone can give me a hint for an alternate approach. Thank You :)","Question is to prove that : $S_4$ does not have a normal subgroup of order $8$ I do not have any specific idea how to proceed but: Assuming there exists a normal subgroup $H$ of order $8$ in $S_4$,  As $H\unlhd G$, $HK\leq G$ for any subgroup $K\leq G$ and $|HK|=\frac{|H||K|}{|H\cap K|}$ what i am trying to do is try getting an element $ x $ of order $2$ which is not in $H$ and set $K=\{1,x\}$ then $HK$ would be a group of order $16$ which is a contradiction as $S_4$  can not have a subgroup of order $16$. as there are six $2-cycles$ and three  products of disjoint $2$ cycles but $|H|=8$, there does exists an element of order $2$ which is not in $H$ and thus we are done. I am sure this would be the nicest way or the stupidest way one can ever do :P I would be thankful if someone can help me to see if anything is wrong in my approach. I would be thankful if someone can give me a hint for an alternate approach. Thank You :)",,['abstract-algebra']
21,How many irreducible polynomials of degree $n$ exist over $\mathbb{F}_p$? [duplicate],How many irreducible polynomials of degree  exist over ? [duplicate],n \mathbb{F}_p,"This question already has answers here : Number of monic irreducible polynomials of prime degree $p$ over finite fields (2 answers) Closed 4 years ago . I know that for every $n\in\mathbb{N}$, $n\ge 1$, there exists $p(x)\in\mathbb{F}_p[x]$ s.t. $\deg p(x)=n$ and $p(x)$ is irreducible over $\mathbb{F}_p$. I am interested in counting how many such $p(x)$ there exist (that is, given $n\in\mathbb{N}$, $n\ge 1$, how many irreducible polynomials of degree $n$ exist over $\mathbb{F}_p$). I don't have a counting strategy and I don't expect a closed formula, but maybe we can find something like ""there exist $X$ irreducible polynomials of degree $n$ where $X$ is the number of..."". What are your thoughts ?","This question already has answers here : Number of monic irreducible polynomials of prime degree $p$ over finite fields (2 answers) Closed 4 years ago . I know that for every $n\in\mathbb{N}$, $n\ge 1$, there exists $p(x)\in\mathbb{F}_p[x]$ s.t. $\deg p(x)=n$ and $p(x)$ is irreducible over $\mathbb{F}_p$. I am interested in counting how many such $p(x)$ there exist (that is, given $n\in\mathbb{N}$, $n\ge 1$, how many irreducible polynomials of degree $n$ exist over $\mathbb{F}_p$). I don't have a counting strategy and I don't expect a closed formula, but maybe we can find something like ""there exist $X$ irreducible polynomials of degree $n$ where $X$ is the number of..."". What are your thoughts ?",,"['abstract-algebra', 'polynomials', 'field-theory', 'finite-fields', 'irreducible-polynomials']"
22,Why is the difference of distinct roots of irreducible $f(x)\in\mathbb{Q}[x]$ never rational?,Why is the difference of distinct roots of irreducible  never rational?,f(x)\in\mathbb{Q}[x],"The way I understand it, is that if $f(x)$ is an irreducible polynomial in $\mathbb{Q}[x]$ of degree at least 2, then a difference of distinct roots $a_i-a_j$ is never rational for any of the $a_1,\dots,a_n$ which are the roots of $f(x)$ in $\mathbb{C}$. Why is this? If $a_i-a_j\in\mathbb{Q}$ for some distinct roots, what goes wrong? Would it follow somehow that $f(x)$ is reducible over $\mathbb{Q}$? Or perhaps there's a more direct explanation?","The way I understand it, is that if $f(x)$ is an irreducible polynomial in $\mathbb{Q}[x]$ of degree at least 2, then a difference of distinct roots $a_i-a_j$ is never rational for any of the $a_1,\dots,a_n$ which are the roots of $f(x)$ in $\mathbb{C}$. Why is this? If $a_i-a_j\in\mathbb{Q}$ for some distinct roots, what goes wrong? Would it follow somehow that $f(x)$ is reducible over $\mathbb{Q}$? Or perhaps there's a more direct explanation?",,"['abstract-algebra', 'polynomials', 'field-theory']"
23,How to find all the maximal ideals of $\mathbb Z_n?$,How to find all the maximal ideals of,\mathbb Z_n?,"How to find all the maximal ideals of $\mathbb Z_n?$ I think $(0)$ is the only maximal ideal of $\mathbb Z_n$ for if $a$ is a non-unit in a maximal ideal of $\mathbb Z_n$ then $(a,n)=1\implies\exists~u,v\in\mathbb Z$ such that $au+nv=1\implies au=1~(\equiv\mod n)\implies 1\in$ the maximal ideal ! Am I right?","How to find all the maximal ideals of $\mathbb Z_n?$ I think $(0)$ is the only maximal ideal of $\mathbb Z_n$ for if $a$ is a non-unit in a maximal ideal of $\mathbb Z_n$ then $(a,n)=1\implies\exists~u,v\in\mathbb Z$ such that $au+nv=1\implies au=1~(\equiv\mod n)\implies 1\in$ the maximal ideal ! Am I right?",,"['abstract-algebra', 'ring-theory']"
24,Prove that $f=x^4-4x^2+16\in\mathbb{Q}[x]$ is irreducible,Prove that  is irreducible,f=x^4-4x^2+16\in\mathbb{Q}[x],"Prove that $f=x^4-4x^2+16\in\mathbb{Q}[x]$ is irreducible. I am trying to prove it with Eisenstein's criterion but without success: for p=2 , it divides -4 and the constant coefficient 16, don't divide the leading coeficient 1, but its square 4 divides the constant coefficient 16, so doesn't work. Therefore I tried to find $f(x\pm c)$ which is irreducible: $f(x+1)=x^4+4x^3+2x^2-4x+13$ , but 13 has the divisors: 1 and 13 , so don't exist a prime number p such that to apply the first condition: $p|a_i, i\ne n$ ; the same problem for $f(x-1)=x^4+...+13$ For $f(x+2)=x^4+8x^3+20x^2+16x+16$ is the same problem from where we go, if we set p=2 , that means $2|8, 2|20, 2|16$ , not divide the leading coefficient 1, but its square 4 divide the constant coefficient 16; again, doesn't work.. is same problem for x-2 Now I'll verify for $f(x\pm3)$ , but I think it will be fall... I think if I verify all constant $f(x\pm c)$ it doesn't work with this method...  so have any idea how we can prove that $f$ is irreducible?","Prove that is irreducible. I am trying to prove it with Eisenstein's criterion but without success: for p=2 , it divides -4 and the constant coefficient 16, don't divide the leading coeficient 1, but its square 4 divides the constant coefficient 16, so doesn't work. Therefore I tried to find which is irreducible: , but 13 has the divisors: 1 and 13 , so don't exist a prime number p such that to apply the first condition: ; the same problem for For is the same problem from where we go, if we set p=2 , that means , not divide the leading coefficient 1, but its square 4 divide the constant coefficient 16; again, doesn't work.. is same problem for x-2 Now I'll verify for , but I think it will be fall... I think if I verify all constant it doesn't work with this method...  so have any idea how we can prove that is irreducible?","f=x^4-4x^2+16\in\mathbb{Q}[x] f(x\pm c) f(x+1)=x^4+4x^3+2x^2-4x+13 p|a_i, i\ne n f(x-1)=x^4+...+13 f(x+2)=x^4+8x^3+20x^2+16x+16 2|8, 2|20, 2|16 f(x\pm3) f(x\pm c) f","['abstract-algebra', 'polynomials', 'field-theory', 'irreducible-polynomials']"
25,Why doesn't stuff hold in characteristic non-zero?,Why doesn't stuff hold in characteristic non-zero?,,"There are a bunch of theorems in algebra that require the underlying field to be characteristic 0.  I seem to remember that these all stemmed from one basic fundamental theorem that only holds in characteristic 0 fields, but I can't remember what it was.  Is there a basic fact that doesn't hold in fields of positive characteristic that is the base reason that more advanced theorems require characteristic 0, and if so, what is it?","There are a bunch of theorems in algebra that require the underlying field to be characteristic 0.  I seem to remember that these all stemmed from one basic fundamental theorem that only holds in characteristic 0 fields, but I can't remember what it was.  Is there a basic fact that doesn't hold in fields of positive characteristic that is the base reason that more advanced theorems require characteristic 0, and if so, what is it?",,"['abstract-algebra', 'field-theory']"
26,Examples of a commutative ring without an identity in which a maximal ideal is not a prime ideal,Examples of a commutative ring without an identity in which a maximal ideal is not a prime ideal,,"In a commutative ring with an identity, every maximal ideal is a prime ideal. However, if a commutative ring does not have an identity, I'm not sure this is true. I would like to know the counterexamples, if any. The more examples, the better. EDIT I would like to know the counterexamples other than $2\mathbb{Z}$. The more examples, the better. EDIT I also would like to know the counterexamples that are not given in the Arturo Magidin's answer if any, namely an example of a non-prime maximal ideal which does not contain $R^2$.","In a commutative ring with an identity, every maximal ideal is a prime ideal. However, if a commutative ring does not have an identity, I'm not sure this is true. I would like to know the counterexamples, if any. The more examples, the better. EDIT I would like to know the counterexamples other than $2\mathbb{Z}$. The more examples, the better. EDIT I also would like to know the counterexamples that are not given in the Arturo Magidin's answer if any, namely an example of a non-prime maximal ideal which does not contain $R^2$.",,"['abstract-algebra', 'commutative-algebra', 'ring-theory', 'rngs']"
27,How to find a minimal polynomial (field theory),How to find a minimal polynomial (field theory),,"I was asked to find a minimal polynomial of $$\alpha = \frac{3\sqrt{5} - 2\sqrt{7} + \sqrt{35}}{1 - \sqrt{5} + \sqrt{7}}$$ over Q . I'm not able to find it without the help of WolframAlpha, which says that the minimal polynomial of $\alpha$ is $$19x^4 - 156x^3 - 280x^2 + 2312x + 3596.$$ (Truely it is - $\alpha$ is a root of the above polynomial and the above polynomial is also irreducible over Q .) Can anyone help me with this? Thank you!","I was asked to find a minimal polynomial of $$\alpha = \frac{3\sqrt{5} - 2\sqrt{7} + \sqrt{35}}{1 - \sqrt{5} + \sqrt{7}}$$ over Q . I'm not able to find it without the help of WolframAlpha, which says that the minimal polynomial of $\alpha$ is $$19x^4 - 156x^3 - 280x^2 + 2312x + 3596.$$ (Truely it is - $\alpha$ is a root of the above polynomial and the above polynomial is also irreducible over Q .) Can anyone help me with this? Thank you!",,['abstract-algebra']
28,Why do we show that structures aren't isomorphic by exhibiting a property not shared by one of them?,Why do we show that structures aren't isomorphic by exhibiting a property not shared by one of them?,,"If someone asks me how to prove that two order structures $\langle A,\leq \rangle$ and $\langle B,\preceq \rangle$ are isomorphic I would immediately suggest: try to find a function $f:A\to B$ such that $a \leq b$ iff $f(a) \preceq f(b)$, for all $a,b \in A$. Because given the definitions, this is the natural way the proof goes. But if the same person asks me to show that $\langle A,\leq \rangle$ and $\langle B,\preceq \rangle$ aren't isomorphic , then I'm in trouble. I would start suggesting him: (1) pick up an arbitrary function $f:A\to B$ such that $a \leq b$ iff $f(a) \preceq f(b)$, for all $a,b \in A$, (2) try to find a contradiction. Then most of the times this is where I get stuck. Because I don't find any further information than this generic assumption, and I simply cannot check all possible functions. This started with my (failed) attempt to show that $\langle \mathbb{N},< \rangle$ and $\langle \mathbb{Z},< \rangle$ aren't isomorphic. Then I googled for some answers and I realize most people prove such ""$X$ and $Y$ aren't isomorphic"" statements by showing a property of $X$ (or $Y$) that is not satisfied by $Y$ (or $X$). Like: $\langle \mathbb{N},< \rangle$ is well-ordered, $\langle \mathbb{Z},< \rangle$ isn't. QED. Question: Why is this a legitimate approach? Why is it enough? As a logician, and looking at the definitions, my natural approach to show that two structures aren't isomorphic, is to assume a generic order-preserving mapping and then deriving a contradiction. How is this ""property approach"" in harmony with that?","If someone asks me how to prove that two order structures $\langle A,\leq \rangle$ and $\langle B,\preceq \rangle$ are isomorphic I would immediately suggest: try to find a function $f:A\to B$ such that $a \leq b$ iff $f(a) \preceq f(b)$, for all $a,b \in A$. Because given the definitions, this is the natural way the proof goes. But if the same person asks me to show that $\langle A,\leq \rangle$ and $\langle B,\preceq \rangle$ aren't isomorphic , then I'm in trouble. I would start suggesting him: (1) pick up an arbitrary function $f:A\to B$ such that $a \leq b$ iff $f(a) \preceq f(b)$, for all $a,b \in A$, (2) try to find a contradiction. Then most of the times this is where I get stuck. Because I don't find any further information than this generic assumption, and I simply cannot check all possible functions. This started with my (failed) attempt to show that $\langle \mathbb{N},< \rangle$ and $\langle \mathbb{Z},< \rangle$ aren't isomorphic. Then I googled for some answers and I realize most people prove such ""$X$ and $Y$ aren't isomorphic"" statements by showing a property of $X$ (or $Y$) that is not satisfied by $Y$ (or $X$). Like: $\langle \mathbb{N},< \rangle$ is well-ordered, $\langle \mathbb{Z},< \rangle$ isn't. QED. Question: Why is this a legitimate approach? Why is it enough? As a logician, and looking at the definitions, my natural approach to show that two structures aren't isomorphic, is to assume a generic order-preserving mapping and then deriving a contradiction. How is this ""property approach"" in harmony with that?",,"['abstract-algebra', 'logic']"
29,How to study abstract algebra,How to study abstract algebra,,"I am taking Abstract Algebra course at the university. We are doing chapters 1-20 from Gallian's abstract algebra text book . I am just doing assigned homework everyweek ( About 5 questions from each chapter). Although I am getting an A in all the assignments and midterms, but I am really worried that my understanding might be shallow or just enough to do the homework that I am going to promptly forget when the course is over. My question is how do I know that I am gaining knowledge that would stay with me and not just studying enough to do the assignments. Also, What else can I do other than just doing homework assignments.","I am taking Abstract Algebra course at the university. We are doing chapters 1-20 from Gallian's abstract algebra text book . I am just doing assigned homework everyweek ( About 5 questions from each chapter). Although I am getting an A in all the assignments and midterms, but I am really worried that my understanding might be shallow or just enough to do the homework that I am going to promptly forget when the course is over. My question is how do I know that I am gaining knowledge that would stay with me and not just studying enough to do the assignments. Also, What else can I do other than just doing homework assignments.",,"['abstract-algebra', 'learning']"
30,Proving that an ideal in a PID is maximal if and only if it is generated by an irreducible,Proving that an ideal in a PID is maximal if and only if it is generated by an irreducible,,"Let $R$ be a PID (Principal Ideal Domain) and $x$ is an element R. Prove that the ideal $\langle x\rangle$ is maximal if and only if $x$ is irreducible. Ok, so I know what an irreducible is. I'm thinking that this problem is asking us to set up a proof by contradiction but I can't see how. No one in my study group has any clue.","Let $R$ be a PID (Principal Ideal Domain) and $x$ is an element R. Prove that the ideal $\langle x\rangle$ is maximal if and only if $x$ is irreducible. Ok, so I know what an irreducible is. I'm thinking that this problem is asking us to set up a proof by contradiction but I can't see how. No one in my study group has any clue.",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'ideals']"
31,Are computer integers a finite group (under addition with overflow)?,Are computer integers a finite group (under addition with overflow)?,,"The integers and the integers modulo a prime are both groups under addition. What about the computer representation of integers (e.g. int64)? It's closed under addition, since a sum that is too large wraps around to the negatives. It also inherits the other group properties from the integers (associativity, identity, inverse). So int64 seems like a finite group, but am I missing anything?","The integers and the integers modulo a prime are both groups under addition. What about the computer representation of integers (e.g. int64)? It's closed under addition, since a sum that is too large wraps around to the negatives. It also inherits the other group properties from the integers (associativity, identity, inverse). So int64 seems like a finite group, but am I missing anything?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'computer-science']"
32,The set $\{g^2 | g \in G\}$ in a group $G$,The set  in a group,\{g^2 | g \in G\} G,"Let $G$ be a group. Prove or disprove that $H =\{g^2 | g \in G\}$ is a subgroup of $G$. I tried testing the permutations of $A_4$, however squaring each cycle yielded a cycle in $A_4$ so I'm lacking a counter-example (if there is one). In a nutshell I'm looking for a subgroup such that when you square the permutation cycle, it yields a cycle not in that subgroup. Or, I could be way off base and figure out that there isn't a counter-example and I need to prove that indeed $H$ is a subgroup of $G$.","Let $G$ be a group. Prove or disprove that $H =\{g^2 | g \in G\}$ is a subgroup of $G$. I tried testing the permutations of $A_4$, however squaring each cycle yielded a cycle in $A_4$ so I'm lacking a counter-example (if there is one). In a nutshell I'm looking for a subgroup such that when you square the permutation cycle, it yields a cycle not in that subgroup. Or, I could be way off base and figure out that there isn't a counter-example and I need to prove that indeed $H$ is a subgroup of $G$.",,"['abstract-algebra', 'group-theory']"
33,Basis for $\mathbb{Z}^2$,Basis for,\mathbb{Z}^2,"Let $x = (a, b), y = (c, d) \in \mathbb{Z}^2$. What is the condition on $a, b, c, d$ so that ${x, y}$ is a basis? My answer: $ad\neq bc$ and $gcd(a, c) = gcd(b, d) = 1$. The first condition ensures that they aren't the same vector; the second ensures that we can actually ""get"" all of the integer values/lattice points. Is this correct? Thanks.","Let $x = (a, b), y = (c, d) \in \mathbb{Z}^2$. What is the condition on $a, b, c, d$ so that ${x, y}$ is a basis? My answer: $ad\neq bc$ and $gcd(a, c) = gcd(b, d) = 1$. The first condition ensures that they aren't the same vector; the second ensures that we can actually ""get"" all of the integer values/lattice points. Is this correct? Thanks.",,"['abstract-algebra', 'gcd-and-lcm']"
34,$M$ finitely generated if submodule and quotient are finitely generated.,finitely generated if submodule and quotient are finitely generated.,M,"I know this must be easy. I'm new to modules, so perhaps I must be missing  something important. Let $M$ be an $R$-module. Show that if there exists a submodule $N$ such that $N$ and $M/N$ are finitely generated, then $M$ is finitely generated. If the exact sequence $0 \longrightarrow N \longrightarrow M \longrightarrow M/N \longrightarrow 0 $ (where the second and third arrows are inclusion and projection respectively) splits then $M$ would be isomorphic to the direct sum of $M$ and $M/N$ and the conclusion would follow (I think). But I can't show that it splits. Thank you.","I know this must be easy. I'm new to modules, so perhaps I must be missing  something important. Let $M$ be an $R$-module. Show that if there exists a submodule $N$ such that $N$ and $M/N$ are finitely generated, then $M$ is finitely generated. If the exact sequence $0 \longrightarrow N \longrightarrow M \longrightarrow M/N \longrightarrow 0 $ (where the second and third arrows are inclusion and projection respectively) splits then $M$ would be isomorphic to the direct sum of $M$ and $M/N$ and the conclusion would follow (I think). But I can't show that it splits. Thank you.",,"['abstract-algebra', 'modules']"
35,How to solve this solvable 8th-degree algebraic equation by radicals?,How to solve this solvable 8th-degree algebraic equation by radicals?,,"Solve the following equation in radicals. $$x^8-8x^7+8x^6+40x^5-14x^4-232x^3+488x^2-568x+1=0$$ I use Magma to verify that its Galois group is a solvable group. R := RationalField();  R < x > := PolynomialRing(R);  f := x^8-8*x^7+8*x^6+40*x^5-14*x^4-232*x^3+488*x^2-568*x+1;  G := GaloisGroup(f);  print G; GroupName(G: TeX:=true); IsSolvable(G); The output of Magma(Online) is: Permutation group G acting on a set of cardinality 8 Order = 16 = 2^4     (2, 4)(6, 8)     (1, 2, 3, 4)(5, 6, 7, 8)     (1, 5)(2, 8)(3, 7)(4, 6) C_2\times D_4 true I also tried to calculate with PARI/GP(64-bit)v_2.13.3+GAP(64-bit)v_4.11.1, but failed. gap> LoadPackage(""radiroot""); true gap> x := Indeterminate(Rationals,""x"");; gap> g := UnivariatePolynomial( Rationals, [1,-8,8,40,-14,-232,488,-568,1]); x^8-8x^7+8x^6+40x^5-14x^4-232x^3+488x^2-568x+1 gap>  RootsOfPolynomialAsRadicals(g, ""latex""); ""/tmp/tmp.sfoZ6C/Nst.tex"" Error，AL_EXECUTABLE，the executable for PARI/GP，has to be set at /proc/ cygdrive/C/gap-4.11.1/pkg/aInuth-3.1.2/gap/kantin.gi : 205 called from","Solve the following equation in radicals. I use Magma to verify that its Galois group is a solvable group. R := RationalField();  R < x > := PolynomialRing(R);  f := x^8-8*x^7+8*x^6+40*x^5-14*x^4-232*x^3+488*x^2-568*x+1;  G := GaloisGroup(f);  print G; GroupName(G: TeX:=true); IsSolvable(G); The output of Magma(Online) is: Permutation group G acting on a set of cardinality 8 Order = 16 = 2^4     (2, 4)(6, 8)     (1, 2, 3, 4)(5, 6, 7, 8)     (1, 5)(2, 8)(3, 7)(4, 6) C_2\times D_4 true I also tried to calculate with PARI/GP(64-bit)v_2.13.3+GAP(64-bit)v_4.11.1, but failed. gap> LoadPackage(""radiroot""); true gap> x := Indeterminate(Rationals,""x"");; gap> g := UnivariatePolynomial( Rationals, [1,-8,8,40,-14,-232,488,-568,1]); x^8-8x^7+8x^6+40x^5-14x^4-232x^3+488x^2-568x+1 gap>  RootsOfPolynomialAsRadicals(g, ""latex""); ""/tmp/tmp.sfoZ6C/Nst.tex"" Error，AL_EXECUTABLE，the executable for PARI/GP，has to be set at /proc/ cygdrive/C/gap-4.11.1/pkg/aInuth-3.1.2/gap/kantin.gi : 205 called from",x^8-8x^7+8x^6+40x^5-14x^4-232x^3+488x^2-568x+1=0,"['abstract-algebra', 'polynomials', 'gap']"
36,Non-trivial example of algebraically closed fields,Non-trivial example of algebraically closed fields,,"I'm beginning an introductory course on Galois Theory and we've just started to talk about algebraic closed fields and extensions. The typical example of algebraically closed fields is $\mathbb{C}$ and the typical non-examples are $\mathbb{R}, \mathbb{Q}$ and arbitrary finite fields. I'm trying to find some explicit, non-typical example of algebraically closed fields, but it seems like a complicated task. Any ideas?","I'm beginning an introductory course on Galois Theory and we've just started to talk about algebraic closed fields and extensions. The typical example of algebraically closed fields is $\mathbb{C}$ and the typical non-examples are $\mathbb{R}, \mathbb{Q}$ and arbitrary finite fields. I'm trying to find some explicit, non-typical example of algebraically closed fields, but it seems like a complicated task. Any ideas?",,"['abstract-algebra', 'field-theory']"
37,Is it possible to produce a field with three operations?,Is it possible to produce a field with three operations?,,"A Field $F$ is defined such that: There is a first operation, say $+$ (addition), that is closed, associative and commutative over $F$ , and has an identity element $0 \in F$ and an inverse element $-x \in F$ for each $x \in F$ (that is, $(F, +)$ is a commutative group); There is a second operation, say $\cdot$ (multiplication), that is closed, associative and commutative over $F \setminus \{0\}$ , and has an identity element $1 \in F \setminus \{0\}$ and an inverse $1/x \in F \setminus \{0\}$ for each $x \in F \setminus \{0\}$ (that is, $(F\setminus \{0\}, \cdot)$ is a commutative group); The second operation distributes over the first operation. My question is this : Is it possible to define a third operation, say $*$ , for $F$ such that $(F\setminus \{0,1\}, *)$ , is a commutative group and $*$ distributes over multiplication? In other words, is it possible to have $(F, +, \cdot, *)$ where both $(F,+, \cdot)$ and $(F\setminus \{0\},\cdot, *)$ are fields? My gut feeling is no. In all fields I am familiar with $(\mathbb{Q,R,C,Z}_p)$ , the multiplication is provably equivalent to that field's analytic continuation of iterated addition, but the analytic continuation of iterated multiplication (that is, exponentiation) is provably not a commutative group operation on $(F \setminus \{0,1\})$ (and catastrophically so, it fails on all counts! It's not even well-defined!) However, the coincidence that multiplication is equivalent to iterated addition feels like just that, a coincidence, as the definition of field makes no claims about the relation between the two operations other than the distributive property. Is my gut feeling correct, or am I right to be skeptical?","A Field is defined such that: There is a first operation, say (addition), that is closed, associative and commutative over , and has an identity element and an inverse element for each (that is, is a commutative group); There is a second operation, say (multiplication), that is closed, associative and commutative over , and has an identity element and an inverse for each (that is, is a commutative group); The second operation distributes over the first operation. My question is this : Is it possible to define a third operation, say , for such that , is a commutative group and distributes over multiplication? In other words, is it possible to have where both and are fields? My gut feeling is no. In all fields I am familiar with , the multiplication is provably equivalent to that field's analytic continuation of iterated addition, but the analytic continuation of iterated multiplication (that is, exponentiation) is provably not a commutative group operation on (and catastrophically so, it fails on all counts! It's not even well-defined!) However, the coincidence that multiplication is equivalent to iterated addition feels like just that, a coincidence, as the definition of field makes no claims about the relation between the two operations other than the distributive property. Is my gut feeling correct, or am I right to be skeptical?","F + F 0 \in F -x \in F x \in F (F, +) \cdot F \setminus \{0\} 1 \in F \setminus \{0\} 1/x \in F \setminus \{0\} x \in F \setminus \{0\} (F\setminus \{0\}, \cdot) * F (F\setminus \{0,1\}, *) * (F, +, \cdot, *) (F,+, \cdot) (F\setminus \{0\},\cdot, *) (\mathbb{Q,R,C,Z}_p) (F \setminus \{0,1\})","['abstract-algebra', 'field-theory']"
38,What is the definition of a free abelian group generated by the set $X$?,What is the definition of a free abelian group generated by the set ?,X,"What is the definition of a free abelian group generated by the set $X$? If $X=\{A,B,C,D\}$ what are the elements of the free abelian group on this set?  What is the identity of this group?","What is the definition of a free abelian group generated by the set $X$? If $X=\{A,B,C,D\}$ what are the elements of the free abelian group on this set?  What is the identity of this group?",,"['abstract-algebra', 'group-theory', 'definition', 'abelian-groups', 'free-abelian-group']"
39,Algebra and Analysis [closed],Algebra and Analysis [closed],,"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 8 years ago . Improve this question I'm a math major at university and my tutor told me that for most people it's best to focus on either algebra or analysis, however I have trouble understanding the difference between them. What are the actual differences between algebra and analysis, and how do I tell which is for me?","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 8 years ago . Improve this question I'm a math major at university and my tutor told me that for most people it's best to focus on either algebra or analysis, however I have trouble understanding the difference between them. What are the actual differences between algebra and analysis, and how do I tell which is for me?",,"['abstract-algebra', 'analysis', 'soft-question', 'career-development']"
40,Ring such that $x^4=x$ for all $x$ is commutative,Ring such that  for all  is commutative,x^4=x x,Let $R$ be a ring such that $x^4=x$ for every $x\in R$. Is this ring commutative?,Let $R$ be a ring such that $x^4=x$ for every $x\in R$. Is this ring commutative?,,"['abstract-algebra', 'ring-theory']"
41,Generalization of a ring?,Generalization of a ring?,,"I've just started learning about rings. Rings are one additive abelian group strung together, through the associative law, with another structured operation. Couldn't we continue stringing together operations in this manner (a multi-operation associative law)? Would what I'm thinking be encompassed by the ring definition through something I'm missing? If not, is this done and, if so, do useful objects come out of it?","I've just started learning about rings. Rings are one additive abelian group strung together, through the associative law, with another structured operation. Couldn't we continue stringing together operations in this manner (a multi-operation associative law)? Would what I'm thinking be encompassed by the ring definition through something I'm missing? If not, is this done and, if so, do useful objects come out of it?",,['abstract-algebra']
42,Is there a generalization of the free group that includes infinitely long words?,Is there a generalization of the free group that includes infinitely long words?,,"The free group over a set $S$ only includes finitely-long words made up of letters from $S$ and their inverses. It seems natural to me to also allow infinitely long words. While this would obviously be impossible to operationalize on a computer, in principle these infinitely-long group elements seem perfectly well-defined. Is there some fundamental logical problem with including infinitely long words? If not, has this concept ever been studied? (I know that such a generalization would no longer count as being ""generated"" by $S$ - since by definition every group element needs to be reachable by a finite number of generator multiplications - so you'd need to find a new name.)","The free group over a set $S$ only includes finitely-long words made up of letters from $S$ and their inverses. It seems natural to me to also allow infinitely long words. While this would obviously be impossible to operationalize on a computer, in principle these infinitely-long group elements seem perfectly well-defined. Is there some fundamental logical problem with including infinitely long words? If not, has this concept ever been studied? (I know that such a generalization would no longer count as being ""generated"" by $S$ - since by definition every group element needs to be reachable by a finite number of generator multiplications - so you'd need to find a new name.)",,"['abstract-algebra', 'group-theory', 'free-groups']"
43,Proving $\sqrt{a+\sqrt{b}}=\sqrt{m}+\sqrt{n}\iff a^{2}-b$ is a square,Proving  is a square,\sqrt{a+\sqrt{b}}=\sqrt{m}+\sqrt{n}\iff a^{2}-b,"This is an exercise for the book Abstract Algebra by Dummit and Foote (pg. 530): Let $F$ be a field of characteristic $\neq2$ . Let $a,b\in F$ with $b$   not a square in $F$. Prove $\sqrt{a+\sqrt{b}}=\sqrt{m}+\sqrt{n}$ for   some $m,n\in F$ iff $a^{2}-b$ is a square in $F$. I am having problem proving this claim, I tried to assume $\sqrt{a+\sqrt{b}}=\sqrt{m}+\sqrt{n}$ and I naturally squared both sides, to try and get $a^{2}$ I squared both sides again and then reduced $2b$ from both sides and rearranged to get $$a^{2}-b=(m+n+2\sqrt{mn})^{2}-2\sqrt{b}(a+\sqrt{b})$$ but I don't see how I can use it. Can someone please help me prove this claim ?","This is an exercise for the book Abstract Algebra by Dummit and Foote (pg. 530): Let $F$ be a field of characteristic $\neq2$ . Let $a,b\in F$ with $b$   not a square in $F$. Prove $\sqrt{a+\sqrt{b}}=\sqrt{m}+\sqrt{n}$ for   some $m,n\in F$ iff $a^{2}-b$ is a square in $F$. I am having problem proving this claim, I tried to assume $\sqrt{a+\sqrt{b}}=\sqrt{m}+\sqrt{n}$ and I naturally squared both sides, to try and get $a^{2}$ I squared both sides again and then reduced $2b$ from both sides and rearranged to get $$a^{2}-b=(m+n+2\sqrt{mn})^{2}-2\sqrt{b}(a+\sqrt{b})$$ but I don't see how I can use it. Can someone please help me prove this claim ?",,"['abstract-algebra', 'field-theory']"
44,What is a quotient ring and cosets?,What is a quotient ring and cosets?,,"So I am trying to understand what a coset is and what a quotient ring is. So I am going to tell you guys what I know. And please let me know if my thinking is right or wrong, and if I am missing something. For the rest of this post, assume $R$ is a ring and $I$ is an ideal of that ring. So $I = (m)$ is a principal ideal generated by $m$ where $m \in R$. Now the congruence class of $a$ and $I$ is denoted by $[a]_m$ but this congruence class can also be written as $a + (m)$ or simply $a + I$.  now this congruence class is obviously a set. So is this the coset of it? So for any $a$ that you choose in $R$ and you ""add"" the ideal to it (generated by m which is also in $R$) you get a coset. The quotient ring $R/I$ just means ALL the cosets of $I$ in $R.$ So does this say that if hypothetically speaking $m = 3,$ then $1 + (3)$ is one coset, $2 + (3)$ is another coset and hence the quotient ring is ALL the cosets for every possible $a?$ I hope I make sense. If someone could send me a link to an easy (introduction to algebra) article or a ""tutorial"", that would be appreciated. I am using Hungerford Algebra. If anyone can explain this to me in easy english, that is appreciated. Thanks","So I am trying to understand what a coset is and what a quotient ring is. So I am going to tell you guys what I know. And please let me know if my thinking is right or wrong, and if I am missing something. For the rest of this post, assume $R$ is a ring and $I$ is an ideal of that ring. So $I = (m)$ is a principal ideal generated by $m$ where $m \in R$. Now the congruence class of $a$ and $I$ is denoted by $[a]_m$ but this congruence class can also be written as $a + (m)$ or simply $a + I$.  now this congruence class is obviously a set. So is this the coset of it? So for any $a$ that you choose in $R$ and you ""add"" the ideal to it (generated by m which is also in $R$) you get a coset. The quotient ring $R/I$ just means ALL the cosets of $I$ in $R.$ So does this say that if hypothetically speaking $m = 3,$ then $1 + (3)$ is one coset, $2 + (3)$ is another coset and hence the quotient ring is ALL the cosets for every possible $a?$ I hope I make sense. If someone could send me a link to an easy (introduction to algebra) article or a ""tutorial"", that would be appreciated. I am using Hungerford Algebra. If anyone can explain this to me in easy english, that is appreciated. Thanks",,['abstract-algebra']
45,Nil-Radical equals Jacobson Radical even though not every prime ideal is maximal?,Nil-Radical equals Jacobson Radical even though not every prime ideal is maximal?,,Let's assume we have a commutative ring with identity. Can the Nil-Radical and the Jacobson Radical be equal in a non-trivial case (i.e. not every nonzero prime ideal in said ring is maximal)? Are there any interesting examples of this case?,Let's assume we have a commutative ring with identity. Can the Nil-Radical and the Jacobson Radical be equal in a non-trivial case (i.e. not every nonzero prime ideal in said ring is maximal)? Are there any interesting examples of this case?,,"['abstract-algebra', 'commutative-algebra', 'ring-theory']"
46,Proof of $\mathbb{Q}$ is not cyclic,Proof of  is not cyclic,\mathbb{Q},"So i'm trying to understand the proof of: $\mathbb{Q}$ is not cyclic. So this is the proof: We proceed by contradiction. Suppose $\mathbb Q$ is cyclic then it would be generated by a rational number in the form $\frac{a}{b}$ where $a,b \in \mathbb{Z} $ and $a$, $b$ have no common factors. Also, $a,b \neq 0$. The set $\langle\frac{a}{b}\rangle$ consists of all integer multiples of $\frac{a}{b}$. Therefore, if $\mathbb{Q}=\langle\frac{a}{b}\rangle$, then $\frac{a}{2b}$ is an integer multiple of $\frac {a}{b}$ PROBLEM : Why is $\frac{a}{2b}$ an integer multiple? or how is it an integer multiple. I'm not seeing it because isn't $\frac{a}{b} \times \frac{a}{b}=\left(\frac{a}{b}\right)^2$ Anyways, here is the rest of the proof: but if $c \times \frac{a}{b}=\frac{a}{2b}$ then $c=\frac{1}{2}$ is not an integer. Thus, $\mathbb{Q}$ cannot be generated by a single rational number and is not cyclic. If anyone can clarify that would be great. Also, another problem I have is doesn't this show that $\mathbb{Q}-\{0\}$ is not cyclic because I thought $\mathbb{Q}$ under the operation multplication is not a group unless zero is removed.","So i'm trying to understand the proof of: $\mathbb{Q}$ is not cyclic. So this is the proof: We proceed by contradiction. Suppose $\mathbb Q$ is cyclic then it would be generated by a rational number in the form $\frac{a}{b}$ where $a,b \in \mathbb{Z} $ and $a$, $b$ have no common factors. Also, $a,b \neq 0$. The set $\langle\frac{a}{b}\rangle$ consists of all integer multiples of $\frac{a}{b}$. Therefore, if $\mathbb{Q}=\langle\frac{a}{b}\rangle$, then $\frac{a}{2b}$ is an integer multiple of $\frac {a}{b}$ PROBLEM : Why is $\frac{a}{2b}$ an integer multiple? or how is it an integer multiple. I'm not seeing it because isn't $\frac{a}{b} \times \frac{a}{b}=\left(\frac{a}{b}\right)^2$ Anyways, here is the rest of the proof: but if $c \times \frac{a}{b}=\frac{a}{2b}$ then $c=\frac{1}{2}$ is not an integer. Thus, $\mathbb{Q}$ cannot be generated by a single rational number and is not cyclic. If anyone can clarify that would be great. Also, another problem I have is doesn't this show that $\mathbb{Q}-\{0\}$ is not cyclic because I thought $\mathbb{Q}$ under the operation multplication is not a group unless zero is removed.",,['abstract-algebra']
47,$\mathbb Z[\sqrt{-5}]$ is not a UFD [duplicate],is not a UFD [duplicate],\mathbb Z[\sqrt{-5}],"This question already has answers here : Why is $\mathbb{Z}[\sqrt{-n}], n\ge 3$ not a UFD? (2 answers) Closed 9 years ago . Prove that the ring of integers of $\mathbb Q (\sqrt{-5})$ does not have unique factorisation. Since $-5\equiv 3\pmod 4$, I know that the ring of integers of $\mathbb Q (\sqrt{-5})$ is $\mathbb Z [\sqrt{-5}]$. I assume the way to prove that this does not have a unique factorisation is to give two different factorisations, but what exactly do I use to factorise? Do I consider the polynomial $x+\sqrt{-5}$?","This question already has answers here : Why is $\mathbb{Z}[\sqrt{-n}], n\ge 3$ not a UFD? (2 answers) Closed 9 years ago . Prove that the ring of integers of $\mathbb Q (\sqrt{-5})$ does not have unique factorisation. Since $-5\equiv 3\pmod 4$, I know that the ring of integers of $\mathbb Q (\sqrt{-5})$ is $\mathbb Z [\sqrt{-5}]$. I assume the way to prove that this does not have a unique factorisation is to give two different factorisations, but what exactly do I use to factorise? Do I consider the polynomial $x+\sqrt{-5}$?",,"['abstract-algebra', 'algebraic-number-theory', 'integer-rings']"
48,Ring of formal power series over a field is a principal ideal domain,Ring of formal power series over a field is a principal ideal domain,,"If $K$ is a field, any non-zero ideal in the ring of formal power series $A=K[[X]]$ is of the form $AX^n$ with $n\geq 0$, so $A=K[[X]]$ is a principal ideal ring. I can't see why. Usually when we consider the ring of polynomials $B=K[X]$, the ideals are the multiples of any fixed polynomial $P(x)\in K[X]$. Here, for formal power series, why can we restrict it to $AX^n$?","If $K$ is a field, any non-zero ideal in the ring of formal power series $A=K[[X]]$ is of the form $AX^n$ with $n\geq 0$, so $A=K[[X]]$ is a principal ideal ring. I can't see why. Usually when we consider the ring of polynomials $B=K[X]$, the ideals are the multiples of any fixed polynomial $P(x)\in K[X]$. Here, for formal power series, why can we restrict it to $AX^n$?",,"['abstract-algebra', 'ring-theory', 'ideals']"
49,Prime elements in $\mathbb{Z}[\sqrt{2}]$,Prime elements in,\mathbb{Z}[\sqrt{2}],"What are the prime elements in the ring $\mathbb{Z}[\sqrt{2}]$? Note that since the ring is a PID (and thus a UFD) then prime = irreducible. Even more, it is Euclidean with respect to the absolute value of the norm: $N(a+b\sqrt{2})=a^2-2b^2$ so it has a nice structure. I know that if $N(\alpha)=p$ with $p$ prime integer then $\alpha$ is a prime element. Not a very explicit description but it would do. Nevertheless, I think there are other primes not covered by the above case. What about prime integers, are they still prime in $\mathbb{Z}[\sqrt{2}]$? I am hoping a classification can be found similar to the primes in $\mathbb{Z}[i]$... Edit: As Alex Youcis points out, it is probably useful to keep in mind that all the units in this ring are characterized by $\pm(1-\sqrt{2})^n$, so the search for prime elements should be up to these.","What are the prime elements in the ring $\mathbb{Z}[\sqrt{2}]$? Note that since the ring is a PID (and thus a UFD) then prime = irreducible. Even more, it is Euclidean with respect to the absolute value of the norm: $N(a+b\sqrt{2})=a^2-2b^2$ so it has a nice structure. I know that if $N(\alpha)=p$ with $p$ prime integer then $\alpha$ is a prime element. Not a very explicit description but it would do. Nevertheless, I think there are other primes not covered by the above case. What about prime integers, are they still prime in $\mathbb{Z}[\sqrt{2}]$? I am hoping a classification can be found similar to the primes in $\mathbb{Z}[i]$... Edit: As Alex Youcis points out, it is probably useful to keep in mind that all the units in this ring are characterized by $\pm(1-\sqrt{2})^n$, so the search for prime elements should be up to these.",,"['abstract-algebra', 'ring-theory', 'principal-ideal-domains']"
50,Does existence of a left or right inverse imply existence of inverses?,Does existence of a left or right inverse imply existence of inverses?,,"Suppose $G$ is a set with a binary operation such that: (Associativity) For all $a, b, c \in G$ , $(ab)c = a(bc)$ . (Identity) There is $e \in G$ such that, for all $a \in G$ , $ae = ea = a$ . (Left inverse or right inverse) For all $a \in G$ , $ba = e$ for some $b \in G$ or (note the difference with and) $ac = e$ for some $c \in G$ . Does this imply that every element $a \in G$ has an inverse, i.e. an element that is both a left and right inverse? That is, for all $a \in G$ , is there $a’$ such that $aa’ = a’a = e$ ? In other words, is $G$ a group?","Suppose is a set with a binary operation such that: (Associativity) For all , . (Identity) There is such that, for all , . (Left inverse or right inverse) For all , for some or (note the difference with and) for some . Does this imply that every element has an inverse, i.e. an element that is both a left and right inverse? That is, for all , is there such that ? In other words, is a group?","G a, b, c \in G (ab)c = a(bc) e \in G a \in G ae = ea = a a \in G ba = e b \in G ac = e c \in G a \in G a \in G a’ aa’ = a’a = e G","['abstract-algebra', 'group-theory', 'inverse', 'monoid']"
51,Fields of arbitrary cardinality,Fields of arbitrary cardinality,,"So I took an introductory abstract algebra course a few semesters ago, and we were shown that groups and rings can both be made into products, i.e. if I have some group $G$ (resp. ring $R$) and some indexing set $I$, then I can make a group $G^{I}$ (resp. ring $R^{I}$) with the appropriate cardinality. However, it was also demonstrated that for fields, you cannot keep the multiplicative inverse under a product structure, i.e. if I have fields $F_{1}, F_{2}$, then $F_{1} \times F_{2}$ will still be a ring, but you will not (not just ""not in general"", but won't) have multiplicative inverses for all non-zero (i.e. not $(0, 0)$) elements, as you could pick $(0, x)$, where $x \neq 0$. According to Wikipedia, an ultraproduct will preserve field structure, but I'm not sure what the cardinality of $\prod_{i \in I} F_{i} / \mathscr{U}$ would be in general. I saw another post that said you could make a field of arbitrarily large cardinality by extending a given field through throwing in a whole bunch of ""transcendental"" elements. The example given was that if I had $\mathbb{Q}$, I could start by dumping in the complexes, but then I suppose after that I'd just start throwing in dogs and cats or something; I'm really not sure what that responder meant, and ceteris paribus, my dogs tend to stay inside, so I'd rather keep them out of my fields, particularly the large ones the thread was interested in. Moreover, the thread mentioned earlier seemed more concerned with just making the fields big. My question is a bit more nuanced: Given any cardinality $\kappa > 1$, can I generally construct a field $F$ of a cardinality $\kappa$? Moreover, how vague do I have to be about it (i.e. do I have to use some really choicy methods, or can I make it a bit more straightforward)? Thanks. EDIT: Sorry. I am aware that for finite fields, you are limited to powers of primes. I meant for infinite cardinals.","So I took an introductory abstract algebra course a few semesters ago, and we were shown that groups and rings can both be made into products, i.e. if I have some group $G$ (resp. ring $R$) and some indexing set $I$, then I can make a group $G^{I}$ (resp. ring $R^{I}$) with the appropriate cardinality. However, it was also demonstrated that for fields, you cannot keep the multiplicative inverse under a product structure, i.e. if I have fields $F_{1}, F_{2}$, then $F_{1} \times F_{2}$ will still be a ring, but you will not (not just ""not in general"", but won't) have multiplicative inverses for all non-zero (i.e. not $(0, 0)$) elements, as you could pick $(0, x)$, where $x \neq 0$. According to Wikipedia, an ultraproduct will preserve field structure, but I'm not sure what the cardinality of $\prod_{i \in I} F_{i} / \mathscr{U}$ would be in general. I saw another post that said you could make a field of arbitrarily large cardinality by extending a given field through throwing in a whole bunch of ""transcendental"" elements. The example given was that if I had $\mathbb{Q}$, I could start by dumping in the complexes, but then I suppose after that I'd just start throwing in dogs and cats or something; I'm really not sure what that responder meant, and ceteris paribus, my dogs tend to stay inside, so I'd rather keep them out of my fields, particularly the large ones the thread was interested in. Moreover, the thread mentioned earlier seemed more concerned with just making the fields big. My question is a bit more nuanced: Given any cardinality $\kappa > 1$, can I generally construct a field $F$ of a cardinality $\kappa$? Moreover, how vague do I have to be about it (i.e. do I have to use some really choicy methods, or can I make it a bit more straightforward)? Thanks. EDIT: Sorry. I am aware that for finite fields, you are limited to powers of primes. I meant for infinite cardinals.",,"['abstract-algebra', 'field-theory']"
52,Is the dihedral group $D_n$ nilpotent? solvable?,Is the dihedral group  nilpotent? solvable?,D_n,Is the dihedral group $D_n$ nilpotent? solvable? I'm trying to solve this problem but I've been trying to apply a couple of theorems but have been unsuccessful so far. Can anyone help me?,Is the dihedral group $D_n$ nilpotent? solvable? I'm trying to solve this problem but I've been trying to apply a couple of theorems but have been unsuccessful so far. Can anyone help me?,,"['abstract-algebra', 'group-theory', 'dihedral-groups', 'solvable-groups', 'nilpotent-groups']"
53,A commutative ring $A$ is a field iff $A[x]$ is a PID,A commutative ring  is a field iff  is a PID,A A[x],"Wikipedia says that a commutative ring $A$ is a field iff $A[x]$ is a PID. The ""only if"" part is easy: we just apply the Euclidean algorithm. I've stumbled trying to prove the ""if"" part, though. $\newcommand{\aa}{\mathfrak{a}}$ My best attempt so far: suppose $\aa$ is an ideal of $A$, and $\aa'$ is the ideal of $A[x]$ spanned by $i(\aa)$, where $i: A \hookrightarrow A[x]$ is the natural embedding. $i^{-1}(\aa') = \aa$ for grading reasons ($i(A) = A[x]^0$, and multiplication by a non-zero degree polynomial takes us out of $i(A)$, because $A \cong i(A)$ is integral). $A[x]$ is a PID so $\aa' = (a')$, where $a' = i(a)$ for some $a \in A$. Therefore, $\aa = (a)$, and thus $A$ is also a PID. That's the best way to use the fact that $A[x]$ is a PID that I've found so far. Now I feel like there must be a trick to show that if $a \neq 0$ then $a = 1$, but I don't know how to do this. Any hints?","Wikipedia says that a commutative ring $A$ is a field iff $A[x]$ is a PID. The ""only if"" part is easy: we just apply the Euclidean algorithm. I've stumbled trying to prove the ""if"" part, though. $\newcommand{\aa}{\mathfrak{a}}$ My best attempt so far: suppose $\aa$ is an ideal of $A$, and $\aa'$ is the ideal of $A[x]$ spanned by $i(\aa)$, where $i: A \hookrightarrow A[x]$ is the natural embedding. $i^{-1}(\aa') = \aa$ for grading reasons ($i(A) = A[x]^0$, and multiplication by a non-zero degree polynomial takes us out of $i(A)$, because $A \cong i(A)$ is integral). $A[x]$ is a PID so $\aa' = (a')$, where $a' = i(a)$ for some $a \in A$. Therefore, $\aa = (a)$, and thus $A$ is also a PID. That's the best way to use the fact that $A[x]$ is a PID that I've found so far. Now I feel like there must be a trick to show that if $a \neq 0$ then $a = 1$, but I don't know how to do this. Any hints?",,['abstract-algebra']
54,Is there a non-cyclic group with every subgroup characteristic?,Is there a non-cyclic group with every subgroup characteristic?,,"Suppose $G$ is a group such that every subgroup of $G$ is a characteristic subgroup. Does this mean that $G$ is cyclic? I remember reading that this is true in the finite case, is that right? What about the infinite case?","Suppose $G$ is a group such that every subgroup of $G$ is a characteristic subgroup. Does this mean that $G$ is cyclic? I remember reading that this is true in the finite case, is that right? What about the infinite case?",,"['abstract-algebra', 'group-theory']"
55,"Must a ring (commutative, with 1), in which every non-zero ideal is prime, be a field?","Must a ring (commutative, with 1), in which every non-zero ideal is prime, be a field?",,"An early exercise in Irving Kaplansky's commutative rings asks: Let R be a ring. Suppose that every ideal in R (other than R) is prime. Prove that R is a field. This is easy if we assume the zero ideal is prime. But is this assumption necessary? If every non-zero ideal is prime, then for any non-unit $x \in R$ and with $x^{n+1} \ne 0$ we must have $\langle x \rangle \subseteq \langle x^{n+1} \rangle$ , which requires the existence of an element $y$ satisfying: $$ x(1-x^ny) = 0 $$ The collection of these and similar relations on the elements seems rather restrictive, but I would appreciate a simple and incisive argument to show that the condition that all non-zero ideals are prime can only be met by rings with trivial spectrum, or, if my guess is incorrect and this is untrue, a counter-example.","An early exercise in Irving Kaplansky's commutative rings asks: Let R be a ring. Suppose that every ideal in R (other than R) is prime. Prove that R is a field. This is easy if we assume the zero ideal is prime. But is this assumption necessary? If every non-zero ideal is prime, then for any non-unit and with we must have , which requires the existence of an element satisfying: The collection of these and similar relations on the elements seems rather restrictive, but I would appreciate a simple and incisive argument to show that the condition that all non-zero ideals are prime can only be met by rings with trivial spectrum, or, if my guess is incorrect and this is untrue, a counter-example.","x \in R x^{n+1} \ne 0 \langle x \rangle \subseteq \langle x^{n+1} \rangle y 
x(1-x^ny) = 0
","['abstract-algebra', 'ring-theory', 'commutative-algebra', 'examples-counterexamples', 'maximal-and-prime-ideals']"
56,"If there is a unique left identity, then it is also a right identity","If there is a unique left identity, then it is also a right identity",,"Let $(R,+,\cdot)$ be a ring, and $e \in R$ be an element such that $ea=a$ for all $a\in R$. I'm trying to prove that if $e$ is unique with this property, then $ae=a$ for all $a\in R $. So far I have $e^2 = e$ (using uniqueness), but I am stuck. I saw a proof of this fact for groups which used the existence of inverses, which we don't have here. I wonder if the result is really true here. Can someone help? Thanks.","Let $(R,+,\cdot)$ be a ring, and $e \in R$ be an element such that $ea=a$ for all $a\in R$. I'm trying to prove that if $e$ is unique with this property, then $ae=a$ for all $a\in R $. So far I have $e^2 = e$ (using uniqueness), but I am stuck. I saw a proof of this fact for groups which used the existence of inverses, which we don't have here. I wonder if the result is really true here. Can someone help? Thanks.",,"['abstract-algebra', 'ring-theory']"
57,"Is $\mathbb Q(\sqrt{2},\sqrt{3},\sqrt{5})=\mathbb Q(\sqrt{2}+\sqrt{3}+\sqrt{5})$. [duplicate]",Is . [duplicate],"\mathbb Q(\sqrt{2},\sqrt{3},\sqrt{5})=\mathbb Q(\sqrt{2}+\sqrt{3}+\sqrt{5})","This question already has answers here : How to prove that $\mathbb{Q}[\sqrt{p_1}, \sqrt{p_2}, \ldots,\sqrt{p_n} ] = \mathbb{Q}[\sqrt{p_1}+ \sqrt{p_2}+\cdots + \sqrt{p_n}]$, for $p_i$ prime? (3 answers) Closed 5 years ago . Is $\mathbf Q(\sqrt 2,\sqrt 3,\sqrt 5)=\mathbf Q(\sqrt 2+\sqrt 3+\sqrt 5)$? Say $L=\mathbf Q(\sqrt 2,\sqrt 3,\sqrt 5)$ and $K=\mathbf Q(\sqrt 2+\sqrt 3+\sqrt 5)$. It is easy to show that $\mathbf Q(\sqrt 2,\sqrt 3)=\mathbf Q(\sqrt 2+\sqrt 3)$. Also, $[L:\mathbf Q]=8$. If we assume that $L\neq K$, then we will have $[K:\mathbf Q]=4$. The reason for this is that $K(\sqrt 5)=L$. Now since $K$ is a superfield of $\mathbf Q$, and $[\mathbf Q(\sqrt 5):\mathbf Q]=2$, we have $[K(\sqrt 5):K]\leq 2$. Since we have assume that $K\neq L$, we must have $[K(\sqrt 5):K]=2$. By the tower law, $[K(\sqrt 5):K][K:\mathbf Q]=[K(\sqrt 5):\mathbf Q]=[L:\mathbf Q]=8$, giving $[K:\mathbf Q]=4$. I am not able to make any further progress. Generalization: Let $p_1,\ldots,p_n$ be pairwise distinct primes. Is $\mathbf Q(\sqrt p_1+\cdots+\sqrt p_n)=\mathbf Q(\sqrt p_1,\ldots,\sqrt p_n)$? Just something I think might be useful in solving the above: It is known that if $p_1,\ldots,p_n$ are pairwise distinct primes, then $[\mathbf Q(\sqrt p_1,\ldots,\sqrt p_n):\mathbf Q]=2^n$.","This question already has answers here : How to prove that $\mathbb{Q}[\sqrt{p_1}, \sqrt{p_2}, \ldots,\sqrt{p_n} ] = \mathbb{Q}[\sqrt{p_1}+ \sqrt{p_2}+\cdots + \sqrt{p_n}]$, for $p_i$ prime? (3 answers) Closed 5 years ago . Is $\mathbf Q(\sqrt 2,\sqrt 3,\sqrt 5)=\mathbf Q(\sqrt 2+\sqrt 3+\sqrt 5)$? Say $L=\mathbf Q(\sqrt 2,\sqrt 3,\sqrt 5)$ and $K=\mathbf Q(\sqrt 2+\sqrt 3+\sqrt 5)$. It is easy to show that $\mathbf Q(\sqrt 2,\sqrt 3)=\mathbf Q(\sqrt 2+\sqrt 3)$. Also, $[L:\mathbf Q]=8$. If we assume that $L\neq K$, then we will have $[K:\mathbf Q]=4$. The reason for this is that $K(\sqrt 5)=L$. Now since $K$ is a superfield of $\mathbf Q$, and $[\mathbf Q(\sqrt 5):\mathbf Q]=2$, we have $[K(\sqrt 5):K]\leq 2$. Since we have assume that $K\neq L$, we must have $[K(\sqrt 5):K]=2$. By the tower law, $[K(\sqrt 5):K][K:\mathbf Q]=[K(\sqrt 5):\mathbf Q]=[L:\mathbf Q]=8$, giving $[K:\mathbf Q]=4$. I am not able to make any further progress. Generalization: Let $p_1,\ldots,p_n$ be pairwise distinct primes. Is $\mathbf Q(\sqrt p_1+\cdots+\sqrt p_n)=\mathbf Q(\sqrt p_1,\ldots,\sqrt p_n)$? Just something I think might be useful in solving the above: It is known that if $p_1,\ldots,p_n$ are pairwise distinct primes, then $[\mathbf Q(\sqrt p_1,\ldots,\sqrt p_n):\mathbf Q]=2^n$.",,"['abstract-algebra', 'field-theory', 'extension-field']"
58,"If a functor between categories of modules preserves injectivity and surjectivity, must it be exact?","If a functor between categories of modules preserves injectivity and surjectivity, must it be exact?",,"Let $A$ and $B$ be commutative rings. Let $F$ be a functor from the category of $A$ modules to the category of $B$ modules. Suppose that $F$ preserves injectivity and surjectivity: whenever $f : X\rightarrow Y$ is an injective map of $A$-modules, we have that $F(f) : F(X)\rightarrow F(Y)$ is an injective map of $B$ modules, and similarly for a surjective map. In other words, $F$ is both left and right exact. Is $F$ necessarily exact, in the sense that it takes short exact sequences to short exact sequences? It seems like all of the examples of non-exact functors one usually sees ($Hom$, $\otimes$, etc.) fail to preserve either injectivity or surjectivity, so I am wondering if there are any examples which preserve both.","Let $A$ and $B$ be commutative rings. Let $F$ be a functor from the category of $A$ modules to the category of $B$ modules. Suppose that $F$ preserves injectivity and surjectivity: whenever $f : X\rightarrow Y$ is an injective map of $A$-modules, we have that $F(f) : F(X)\rightarrow F(Y)$ is an injective map of $B$ modules, and similarly for a surjective map. In other words, $F$ is both left and right exact. Is $F$ necessarily exact, in the sense that it takes short exact sequences to short exact sequences? It seems like all of the examples of non-exact functors one usually sees ($Hom$, $\otimes$, etc.) fail to preserve either injectivity or surjectivity, so I am wondering if there are any examples which preserve both.",,"['abstract-algebra', 'category-theory', 'abelian-categories']"
59,"If G is not commutative, then is there always a subgroup that is not a normal subgroup?","If G is not commutative, then is there always a subgroup that is not a normal subgroup?",,"I was having a discussion with a friend of mine about some normal group properties and then came up with the question ""if G is not commutative, then is there always a subgroup that is not a normal subgroup?"" It's probably more easy to solve this in the following form:$$\forall H \leq G : H  \lhd G \Rightarrow \forall a,b \in G : ab=ba$$ My question is, can anybody give a proof, or a counter-example (because I don't think it holds) of this theorem? Thanks!","I was having a discussion with a friend of mine about some normal group properties and then came up with the question ""if G is not commutative, then is there always a subgroup that is not a normal subgroup?"" It's probably more easy to solve this in the following form:$$\forall H \leq G : H  \lhd G \Rightarrow \forall a,b \in G : ab=ba$$ My question is, can anybody give a proof, or a counter-example (because I don't think it holds) of this theorem? Thanks!",,['abstract-algebra']
60,Two finite fields with the same number of elements are isomorphic,Two finite fields with the same number of elements are isomorphic,,"Fraleigh(7ed) Theorem33.12. Let $p$ be a prime and let $n\in\mathbb{Z}^+$. If $E$ and $E'$ are fields of order $p^n$, then $E \simeq E'$. Proof in the text: Both $E$ and $E'$ have $\mathbb{Z}_p$ as prime field, up to isomorphism. By Corollary 33.6(A finite extension $E$ of a finite field $F$ is a simple extension of $F$), $E$ is a simple extension of $\mathbb{Z}_p$ of degree $n$, so there exists an irreducible polynomial $f(x)$ of degree $n$ in $\mathbb{Z}_p[x]$ such that $E\simeq \mathbb{Z}_p[x]/ \langle f(x) \rangle$. Because the elements of $E$ are zeros of $x^{p^n}-x$, *we see that $f(x)$ is a factor of $x^{p^n}-x$ in $\mathbb{Z}_p[x]$* . Because $E'$ also consists of zeros of  $x^{p^n}-x$, we see that $E'$ also contains zeros of irreducible $f(x)$ in $\mathbb{Z}_p[x]$. Thus, because $E'$ also contains exactly $p^n$ elements, $E'$ is also isomorphic to $E\simeq \mathbb{Z}_p[x]/\langle f(x) \rangle$. I don't know why $f(x)$ divides $x^{p^n}-x$. $E$ has a zero $\alpha$ of $f(x)$, but it doesn't need to have all the zeros of $f(x)$. So $f(x)=(x-\alpha)g(x)$ in $E[x]$ and $g(x)$ need not be splitted into linear factors. How can $f(x)$ divide $x^{p^n}-x$?","Fraleigh(7ed) Theorem33.12. Let $p$ be a prime and let $n\in\mathbb{Z}^+$. If $E$ and $E'$ are fields of order $p^n$, then $E \simeq E'$. Proof in the text: Both $E$ and $E'$ have $\mathbb{Z}_p$ as prime field, up to isomorphism. By Corollary 33.6(A finite extension $E$ of a finite field $F$ is a simple extension of $F$), $E$ is a simple extension of $\mathbb{Z}_p$ of degree $n$, so there exists an irreducible polynomial $f(x)$ of degree $n$ in $\mathbb{Z}_p[x]$ such that $E\simeq \mathbb{Z}_p[x]/ \langle f(x) \rangle$. Because the elements of $E$ are zeros of $x^{p^n}-x$, *we see that $f(x)$ is a factor of $x^{p^n}-x$ in $\mathbb{Z}_p[x]$* . Because $E'$ also consists of zeros of  $x^{p^n}-x$, we see that $E'$ also contains zeros of irreducible $f(x)$ in $\mathbb{Z}_p[x]$. Thus, because $E'$ also contains exactly $p^n$ elements, $E'$ is also isomorphic to $E\simeq \mathbb{Z}_p[x]/\langle f(x) \rangle$. I don't know why $f(x)$ divides $x^{p^n}-x$. $E$ has a zero $\alpha$ of $f(x)$, but it doesn't need to have all the zeros of $f(x)$. So $f(x)=(x-\alpha)g(x)$ in $E[x]$ and $g(x)$ need not be splitted into linear factors. How can $f(x)$ divide $x^{p^n}-x$?",,"['abstract-algebra', 'field-theory', 'finite-fields']"
61,A finite field extension of $\mathbb R$ is either $\mathbb R$ or isomorphic to $\mathbb C$,A finite field extension of  is either  or isomorphic to,\mathbb R \mathbb R \mathbb C,Let $F$ be a field containing $\mathbb R$ with the property that $\dim_{\mathbb R}F < \infty.$ Then either $F \cong \mathbb R$ or $F \cong \mathbb C.$ I am trying to prove the above statement. I am not supposed to use Frobenius' theorem as it would just spoil the spirit of the current problem. I am told to  show that every $x \in F \setminus \mathbb R$ is a root of some non-zero polynomial in $F[x]$ with leading coefficient $1$ and some other things. But I am not really been able to prove anything so far. Please help. Thanks in advance.,Let $F$ be a field containing $\mathbb R$ with the property that $\dim_{\mathbb R}F < \infty.$ Then either $F \cong \mathbb R$ or $F \cong \mathbb C.$ I am trying to prove the above statement. I am not supposed to use Frobenius' theorem as it would just spoil the spirit of the current problem. I am told to  show that every $x \in F \setminus \mathbb R$ is a root of some non-zero polynomial in $F[x]$ with leading coefficient $1$ and some other things. But I am not really been able to prove anything so far. Please help. Thanks in advance.,,['abstract-algebra']
62,Order of the smallest group containing all groups of order $n$ as subgroups.,Order of the smallest group containing all groups of order  as subgroups.,n,Let $n\in \Bbb N$ be fixed and $m\in \Bbb N$ be the least number such that there exists a group of order $m$ in which all groups of order $n$ can be (isomorphically) embedded. Can we deduce $n!=m$?,Let $n\in \Bbb N$ be fixed and $m\in \Bbb N$ be the least number such that there exists a group of order $m$ in which all groups of order $n$ can be (isomorphically) embedded. Can we deduce $n!=m$?,,"['abstract-algebra', 'group-theory']"
63,Show that any prime ideal from such a ring is maximal.,Show that any prime ideal from such a ring is maximal.,,"Let R be a commutative ring with an identity such that for all $r\in$ R , there exists some $n>1$ such that $r^n = r$. Show that any prime ideal is  maximal. (Atiyah and MacDonald, Introduction to Commutative Algebra , Chapter 1, Exercise 7.) Any hints?","Let R be a commutative ring with an identity such that for all $r\in$ R , there exists some $n>1$ such that $r^n = r$. Show that any prime ideal is  maximal. (Atiyah and MacDonald, Introduction to Commutative Algebra , Chapter 1, Exercise 7.) Any hints?",,['abstract-algebra']
64,The $2$-category of monoids,The -category of monoids,2,"People sometimes say that monoids are ""categories with one object"". In fact people sometimes suggest that this is the natural definition of a monoid (and likewise ""groupoid with one object"" as the definition of a group). But categories naturally form a $2$-category $\mathbf{Cat}$. So if we took the above definition seriously then we would view monoids as forming a $2$-category $\mathbf{Mon}$. The objects would be monoids and the morphisms would be monoid homomorphisms, but there would also be $2$-morphisms between homomorphisms. A $2$-morphism between $f,g:M\to N$ is an $n\in N$ such that $nf(m)=g(m)n$ for all $m\in M$. If one takes the principle of equivalence seriously then this poses a problem because we lose the ability to talk about the ""underlying set"" of a monoid. There's no $2$-functor $U:\mathbf{Mon}\to\mathbf{Set}$ (treating $\mathbf{Set}$ as a $2$-category with no nontrivial $2$-morphisms) that sends each monoid to its underlying set and each homomorphism to its underlying function. In the $1$-category of monoids this would be given by applying the functor $\mathrm{Hom}(\Bbb N,-)$. But in the $2$-category $\mathbf{Mon}$ two homomorphisms $f,g:\Bbb N\to M$ are isomorphic whenever $f(1)=mg(1)m^{-1}$ for some $m\in M$, so this construction only gives us the set of conjugacy classes of $M$ rather than its set of elements. Clearly this poses a problem if we want to work with monoids and groups. In particular proofs involving finite groups often require the ability to count the number of elements in some subset of a group. It becomes impossible to state Lagrange's Theorem. We also lose the ability to talk about the free group on a set, since we can't construct the adjoint to the nonexistent functor $U$. In light of this, I want to know if it's actually possible to take ""category with one object"" as our definition of monoid, and still be able to prove things in a practical way. I can see two ways to do this: 1) Recover the $1$-category of monoids from $\mathbf{Mon}$ in some natural way or 2) Show that we can reconstruct group theory in a way that never uses concepts like ""order of a group"" or ""free group on a set"" Does anybody know a way to do either of these?","People sometimes say that monoids are ""categories with one object"". In fact people sometimes suggest that this is the natural definition of a monoid (and likewise ""groupoid with one object"" as the definition of a group). But categories naturally form a $2$-category $\mathbf{Cat}$. So if we took the above definition seriously then we would view monoids as forming a $2$-category $\mathbf{Mon}$. The objects would be monoids and the morphisms would be monoid homomorphisms, but there would also be $2$-morphisms between homomorphisms. A $2$-morphism between $f,g:M\to N$ is an $n\in N$ such that $nf(m)=g(m)n$ for all $m\in M$. If one takes the principle of equivalence seriously then this poses a problem because we lose the ability to talk about the ""underlying set"" of a monoid. There's no $2$-functor $U:\mathbf{Mon}\to\mathbf{Set}$ (treating $\mathbf{Set}$ as a $2$-category with no nontrivial $2$-morphisms) that sends each monoid to its underlying set and each homomorphism to its underlying function. In the $1$-category of monoids this would be given by applying the functor $\mathrm{Hom}(\Bbb N,-)$. But in the $2$-category $\mathbf{Mon}$ two homomorphisms $f,g:\Bbb N\to M$ are isomorphic whenever $f(1)=mg(1)m^{-1}$ for some $m\in M$, so this construction only gives us the set of conjugacy classes of $M$ rather than its set of elements. Clearly this poses a problem if we want to work with monoids and groups. In particular proofs involving finite groups often require the ability to count the number of elements in some subset of a group. It becomes impossible to state Lagrange's Theorem. We also lose the ability to talk about the free group on a set, since we can't construct the adjoint to the nonexistent functor $U$. In light of this, I want to know if it's actually possible to take ""category with one object"" as our definition of monoid, and still be able to prove things in a practical way. I can see two ways to do this: 1) Recover the $1$-category of monoids from $\mathbf{Mon}$ in some natural way or 2) Show that we can reconstruct group theory in a way that never uses concepts like ""order of a group"" or ""free group on a set"" Does anybody know a way to do either of these?",,"['abstract-algebra', 'soft-question', 'category-theory', 'monoid', 'higher-category-theory']"
65,What is the exponent of a group?,What is the exponent of a group?,,"I don't really understand the definition: The exponent of a group G is the smallest natural number x such that for all $g \in G,g^x = e$. It seems like it's saying, for EVERY element of the group, when you keep applying the group operation to itself which power to itself gives you e.What is the lowest number that this is true for for all elements of G. First of all, what would even be the point of creating some definition like that, what purpose does something like this serve? I guess, I would see that you could get the lcm of all the exponents that equal e, but it seems like a pretty tedious process to figure out where g's equal e. I am obviously missing something, can someone help me out here? Thanks scores.","I don't really understand the definition: The exponent of a group G is the smallest natural number x such that for all $g \in G,g^x = e$. It seems like it's saying, for EVERY element of the group, when you keep applying the group operation to itself which power to itself gives you e.What is the lowest number that this is true for for all elements of G. First of all, what would even be the point of creating some definition like that, what purpose does something like this serve? I guess, I would see that you could get the lcm of all the exponents that equal e, but it seems like a pretty tedious process to figure out where g's equal e. I am obviously missing something, can someone help me out here? Thanks scores.",,"['abstract-algebra', 'group-theory']"
66,Origin of the terminology projective module,Origin of the terminology projective module,,"Projective modules were introduced in 1956 by Cartan and Eilenberg in their book Homological Algebra .  Does anyone know why they chose the word ""projective""? Does it have something to do with the notion of projection?","Projective modules were introduced in 1956 by Cartan and Eilenberg in their book Homological Algebra .  Does anyone know why they chose the word ""projective""? Does it have something to do with the notion of projection?",,"['abstract-algebra', 'modules', 'terminology', 'projective-module']"
67,When is a product of two ideals strictly included in their intersection?,When is a product of two ideals strictly included in their intersection?,,"Let $I,J$ two ideals in a ring $R$. The product of ideals $IJ$ is included in $I \cap J$. For example we have equality in $\mathbb{Z}$ if generators have no common nontrival factors, in a ring $R$ when $I+J=(1)$, or when $R/IJ$ has no nonzero nilpotent elements. My question is not about equality, instead it is about strict inclusion. Under what conditions $IJ \subsetneq I \cap J$ ? If the question appears a little too general, then my primary aim is to see what happens under the hypothesis that $R$ is a Dedekind domain.","Let $I,J$ two ideals in a ring $R$. The product of ideals $IJ$ is included in $I \cap J$. For example we have equality in $\mathbb{Z}$ if generators have no common nontrival factors, in a ring $R$ when $I+J=(1)$, or when $R/IJ$ has no nonzero nilpotent elements. My question is not about equality, instead it is about strict inclusion. Under what conditions $IJ \subsetneq I \cap J$ ? If the question appears a little too general, then my primary aim is to see what happens under the hypothesis that $R$ is a Dedekind domain.",,"['abstract-algebra', 'commutative-algebra', 'ring-theory', 'ideals']"
68,Correspondence theorem for rings.,Correspondence theorem for rings.,,Could someone provide a reference that includes a full and honest proof of the Correspondence Theorem for rings? Let $A$ be a multiplicative ring with identity and $I$ an ideal of $A$. There is a one-to-one correspondence between the ideals of $A$ that contain $I$ and the ideals of the quotient ring $A/I$.,Could someone provide a reference that includes a full and honest proof of the Correspondence Theorem for rings? Let $A$ be a multiplicative ring with identity and $I$ an ideal of $A$. There is a one-to-one correspondence between the ideals of $A$ that contain $I$ and the ideals of the quotient ring $A/I$.,,"['abstract-algebra', 'reference-request', 'ring-theory']"
69,Irreducible implies minimal polynomial?,Irreducible implies minimal polynomial?,,"In the context of field theory, let's say we are finding the minimal polynomial of the $\sqrt[3] 2$ over $\mathbb{Q}$. Clearly a candidate will be $x^3-2$, which is irreducible by Eisenstein's criterion. Can we then immediately conclude that it is the minimal polynomial? What I am worried is, is there such thing as an irreducible polynomial that is somehow not the minimal polynomial? (I know minimal polynomial implies irreducibility, but not sure about the converse: does irreducible polynomial implies minimality?) Thanks for any help.","In the context of field theory, let's say we are finding the minimal polynomial of the $\sqrt[3] 2$ over $\mathbb{Q}$. Clearly a candidate will be $x^3-2$, which is irreducible by Eisenstein's criterion. Can we then immediately conclude that it is the minimal polynomial? What I am worried is, is there such thing as an irreducible polynomial that is somehow not the minimal polynomial? (I know minimal polynomial implies irreducibility, but not sure about the converse: does irreducible polynomial implies minimality?) Thanks for any help.",,"['abstract-algebra', 'field-theory', 'galois-theory']"
70,"Why do we have ""another"" definition for the kernel?","Why do we have ""another"" definition for the kernel?",,"Why does the definition $\ker(f)=\{(a,a')\in A\times A: f(a)=f(a')\}$ exist?  This definition is for any sort of algebraic system and any sort of function.  But which came first... this definition or the more familiar one?  I haven't seen this used anywhere outside of pure algebra, maybe there are applications in other fields, maybe in functional analysis?  But what's the use?  If a function is injective in this setting then $\ker(f)$ is the diagonal of $A$.  But does this add anything?  Are there isomorphism theorems that use this language?  Do we loose anything or gain anything, when speaking about a function's kernel in this manner? As an example, I had an old homework assignment I found (that prompted me to ask this) Let $f:A\to B$ be surjective.  Then a map $h:A\to C$ can be factored over $f$ (i.e. $h=g\circ f$) for some $g:B\to C$, if only if, $\ker(f)\subset \ker(h)$. If this is the case then the map $g$ is unique. I don't need (or want) a solution to this exercise (I did it years back and posting it here would only take from future students), so please do not post a solution (this is just an example of where the  ""undegraduate"" kernel doesn't work).","Why does the definition $\ker(f)=\{(a,a')\in A\times A: f(a)=f(a')\}$ exist?  This definition is for any sort of algebraic system and any sort of function.  But which came first... this definition or the more familiar one?  I haven't seen this used anywhere outside of pure algebra, maybe there are applications in other fields, maybe in functional analysis?  But what's the use?  If a function is injective in this setting then $\ker(f)$ is the diagonal of $A$.  But does this add anything?  Are there isomorphism theorems that use this language?  Do we loose anything or gain anything, when speaking about a function's kernel in this manner? As an example, I had an old homework assignment I found (that prompted me to ask this) Let $f:A\to B$ be surjective.  Then a map $h:A\to C$ can be factored over $f$ (i.e. $h=g\circ f$) for some $g:B\to C$, if only if, $\ker(f)\subset \ker(h)$. If this is the case then the map $g$ is unique. I don't need (or want) a solution to this exercise (I did it years back and posting it here would only take from future students), so please do not post a solution (this is just an example of where the  ""undegraduate"" kernel doesn't work).",,['abstract-algebra']
71,Every maximal ideal is principal. Is $R$ principal?,Every maximal ideal is principal. Is  principal?,R,"Let $R$ be a commutative ring with 1. If every maximal ideal of $R$ is principal, is $R$ a principal ideal ring?","Let $R$ be a commutative ring with 1. If every maximal ideal of $R$ is principal, is $R$ a principal ideal ring?",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'ideals']"
72,Problem in Jacobson's Basic Algebra (Vol. I),Problem in Jacobson's Basic Algebra (Vol. I),,"It is section $4.4$, exercise number $5$. It says the following: Let $F$ be a field of characteristic $p$. Show that $f(x)=x^p-x-a$ has no multiple roots and that $f(x)$ is irreducible in $F[x]$ if and only if $a\neq c^p-c$ for any $c\in F$. $\bf{Proof:}$ First of all we note that $f'(x)=-1$, hence $\gcd(f,f')=1$, and we see that $f$ contains no multiple roots. Secondly, assume that $a=c^p-c$ for some $c\in F$. Then we have that $$x^p-x-a=x^p-x-(c^p-c)=x^p-c^p-x+c=(x-c)^p-(x-c)=(x-c)((x-c)^{p-1}-1)$$Hence $f(x)$ is reducible. (That is, we have proven that if $f$ is irreducible then $a\neq c^p-c$ for any $c\in F$). For the converse, I was trying to do something along the lines consider $E$ to be a splitting field for $f(x)$. Then, let $b$ be a root of $f(x)$ in $E$. This $b$ satisfies the identity $b^p-b=a$, hence I would like to show the existence of some root $b\in E$ to be actually in our field $F$. This is were I got stuck.","It is section $4.4$, exercise number $5$. It says the following: Let $F$ be a field of characteristic $p$. Show that $f(x)=x^p-x-a$ has no multiple roots and that $f(x)$ is irreducible in $F[x]$ if and only if $a\neq c^p-c$ for any $c\in F$. $\bf{Proof:}$ First of all we note that $f'(x)=-1$, hence $\gcd(f,f')=1$, and we see that $f$ contains no multiple roots. Secondly, assume that $a=c^p-c$ for some $c\in F$. Then we have that $$x^p-x-a=x^p-x-(c^p-c)=x^p-c^p-x+c=(x-c)^p-(x-c)=(x-c)((x-c)^{p-1}-1)$$Hence $f(x)$ is reducible. (That is, we have proven that if $f$ is irreducible then $a\neq c^p-c$ for any $c\in F$). For the converse, I was trying to do something along the lines consider $E$ to be a splitting field for $f(x)$. Then, let $b$ be a root of $f(x)$ in $E$. This $b$ satisfies the identity $b^p-b=a$, hence I would like to show the existence of some root $b\in E$ to be actually in our field $F$. This is were I got stuck.",,"['abstract-algebra', 'field-theory', 'finite-fields', 'positive-characteristic']"
73,What are some theorems made easier by Stone Duality?,What are some theorems made easier by Stone Duality?,,"I have seen a lot of praise for the Stone Duality Theorem, which links the algebraic structure of boolean algebras to the topological structure of stone spaces by a (contravariant) adjoint equivalence of categories. What are some theorems which are made obvious by using duality, or which don't have proofs without duality? I know that it (and its generalizations) have inspired a lot of work in pointless topology , which looks interesting to me, but it's not what I'm looking for. Ideally these proofs should be theorems about boolean algebras or stone spaces - things which someone could have come up with before the duality was known. I'm sure these theorems must exist, because Stone Duality, while independently beautiful, is often cited as a useful and powerful result... So I'm not sure why I'm struggling to find witnesses to its utility. Thanks!","I have seen a lot of praise for the Stone Duality Theorem, which links the algebraic structure of boolean algebras to the topological structure of stone spaces by a (contravariant) adjoint equivalence of categories. What are some theorems which are made obvious by using duality, or which don't have proofs without duality? I know that it (and its generalizations) have inspired a lot of work in pointless topology , which looks interesting to me, but it's not what I'm looking for. Ideally these proofs should be theorems about boolean algebras or stone spaces - things which someone could have come up with before the duality was known. I'm sure these theorems must exist, because Stone Duality, while independently beautiful, is often cited as a useful and powerful result... So I'm not sure why I'm struggling to find witnesses to its utility. Thanks!",,"['abstract-algebra', 'general-topology']"
74,Give example of two non-isomorphic groups that have same as sets.,Give example of two non-isomorphic groups that have same as sets.,,Does there exists two non-isomorphic groups with the following properties: 1.Two groups are same as sets. 2.Two groups have the same identity element. 3.Each element has same inverse in each of the groups. I have done an exercise on isomorphism chapter of J.Gallian's book where all the criteria are fulfilled but they are isomorphic.But is there a non-isomorphic example?,Does there exists two non-isomorphic groups with the following properties: 1.Two groups are same as sets. 2.Two groups have the same identity element. 3.Each element has same inverse in each of the groups. I have done an exercise on isomorphism chapter of J.Gallian's book where all the criteria are fulfilled but they are isomorphic.But is there a non-isomorphic example?,,"['abstract-algebra', 'group-theory']"
75,Tangent space of quotient space,Tangent space of quotient space,,"Let $\pi : M \rightarrow M/G$ be the canonical projection, where $M$ is a manifold and $M/G$ is a quotient manifold. Now, what can we say about $d \pi (p) : T_pM \rightarrow T_p(M/G)$? From my intuition I would say that elements in $T_p(M/G)$ consists of elements in equivalence classes defined by $T_p(G_xp)$. In case that this is true. Does anybody know how to show that $T_p(M/G)$ consists actually of these kind of elements?","Let $\pi : M \rightarrow M/G$ be the canonical projection, where $M$ is a manifold and $M/G$ is a quotient manifold. Now, what can we say about $d \pi (p) : T_pM \rightarrow T_p(M/G)$? From my intuition I would say that elements in $T_p(M/G)$ consists of elements in equivalence classes defined by $T_p(G_xp)$. In case that this is true. Does anybody know how to show that $T_p(M/G)$ consists actually of these kind of elements?",,"['abstract-algebra', 'differential-geometry', 'differential-topology', 'lie-groups', 'lie-algebras']"
76,Why is $S_5$ generated by any combination of a transposition and a 5-cycle?,Why is  generated by any combination of a transposition and a 5-cycle?,S_5,Why is $S_5$ generated by any combination of a transposition and a 5-cycle? Is this true for any prime $p$ (in this case $p=5$)?,Why is $S_5$ generated by any combination of a transposition and a 5-cycle? Is this true for any prime $p$ (in this case $p=5$)?,,"['abstract-algebra', 'combinatorics', 'group-theory', 'finite-groups', 'permutations']"
77,"Do quotient rings have geometric meaning, or geometric intuition?","Do quotient rings have geometric meaning, or geometric intuition?",,"I am wondering if quotient rings have any geometric meaning. For example, I am trying to identify the ring $\mathbb Z[x]/(x^2-3, 2x+4)$ and I am trying to think about lattice points and polynomial graphs but it is a bit overwhelming. But even for something simpler like $\mathbb Z[x]/(x^2)$. Since we are modding out by $x^2$, then we will be left with linear integer polynomials. What do these rings look like in a geometric sense?","I am wondering if quotient rings have any geometric meaning. For example, I am trying to identify the ring $\mathbb Z[x]/(x^2-3, 2x+4)$ and I am trying to think about lattice points and polynomial graphs but it is a bit overwhelming. But even for something simpler like $\mathbb Z[x]/(x^2)$. Since we are modding out by $x^2$, then we will be left with linear integer polynomials. What do these rings look like in a geometric sense?",,"['abstract-algebra', 'geometry', 'ring-theory', 'intuition', 'quotient-spaces']"
78,"What do groups and rings ""look like""?","What do groups and rings ""look like""?",,"Taking undergraduate physics courses, I had to deal with Euclidean vectors often. In classes like Calc III, the concept was also there. I'm not sure if this is why, but I've always had a more intuitive ""picture"" of what a vector space was than other algebraic structures. Even though in a linear algebra course, vector spaces are as arbitrary of a structure as any other, this association with a ""space of scalable directed lines"" stuck. It makes the concept of ""dimension"" of a vector space very intuitive, along with many other things. For rings and groups, and other structures, I have no such intuition. I've heard groups compared to all sorts of things, involving symmetries, and Christmas tree ornaments. I don't see these things. I have completed graduate courses on group theory and am currently self-studying rings, but have little intuition on these things. In other words, if I had to explain a vector space to someone with no knowledge in mathematics, I would probably go the route of explaining the three dimensional space with scalable directed lines, a very concrete example, and could do so in plain language comfortably and intuitively. If I had to explain a group, I would really have no choice but to say ""a group is a set of objects endowed with a binary operation such that..."" What is your intuitive notion of these other algebraic structures? How do you ""visualize"" a group?","Taking undergraduate physics courses, I had to deal with Euclidean vectors often. In classes like Calc III, the concept was also there. I'm not sure if this is why, but I've always had a more intuitive ""picture"" of what a vector space was than other algebraic structures. Even though in a linear algebra course, vector spaces are as arbitrary of a structure as any other, this association with a ""space of scalable directed lines"" stuck. It makes the concept of ""dimension"" of a vector space very intuitive, along with many other things. For rings and groups, and other structures, I have no such intuition. I've heard groups compared to all sorts of things, involving symmetries, and Christmas tree ornaments. I don't see these things. I have completed graduate courses on group theory and am currently self-studying rings, but have little intuition on these things. In other words, if I had to explain a vector space to someone with no knowledge in mathematics, I would probably go the route of explaining the three dimensional space with scalable directed lines, a very concrete example, and could do so in plain language comfortably and intuitively. If I had to explain a group, I would really have no choice but to say ""a group is a set of objects endowed with a binary operation such that..."" What is your intuitive notion of these other algebraic structures? How do you ""visualize"" a group?",,"['abstract-algebra', 'vector-spaces', 'soft-question', 'intuition']"
79,"If $E/F$ is algebraic and every $f\in F[X]$ has a root in $E$, why is $E$ algebraically closed? [duplicate]","If  is algebraic and every  has a root in , why is  algebraically closed? [duplicate]",E/F f\in F[X] E E,"This question already has answers here : Is the sub-field of algebraic elements of a field extension of $K$ containing roots of polynomials over $K$ algebraically closed? (2 answers) Closed 4 years ago . Suppose $E/F$ is an algebraic extension, where every polynomial over $F$ has a root in $E$. It's not clear to me why $E$ is actually algebraically closed. I attempted the following, but I don't think it's correct: I let $f$ be an irreducible polynomial in $E[X]$. I let $\alpha$ be a root in some extension, so $f=m_{\alpha,E}$. Since $\alpha$ is algebraic over $E$, it is also algebraic over $F$, let $m_{\alpha,F}$ be it's minimal polynomial. I now let $K$ be a splitting field of $m_{\alpha,F}$, which is a finite extension since each root has finite degree over $F$. If $m_{\alpha,F}$ is separable, then $K/F$ is also separable, so as a finite, separable extension, we can write $K=F(\beta)$ for some primitive element $\beta$. By assumption, $m_{\alpha,F}$ has a root in $E$, call it $r$. Then we can embed $F(\beta)$ into $r$ by mapping $\beta$ to $r$. It follows that $m_{\alpha,F}$ splits in $E$. Since $f\mid m_{\alpha,F}$, we must also have the $f$ is split in $E$. But what happens if $m_{\alpha,F}$ is not separable? In such case, $F$ must have characteristic $p$. I know we can express $m_{\alpha,F}=g(X^{p^k})$ for some irreducible, separable polynomial $g(X)\in F[X]$. But I'm not sure what follows after that. NB: I say $E$ is algebraically closed if every nonconstant polynomial in $E[X]$ has a root in $E$.","This question already has answers here : Is the sub-field of algebraic elements of a field extension of $K$ containing roots of polynomials over $K$ algebraically closed? (2 answers) Closed 4 years ago . Suppose $E/F$ is an algebraic extension, where every polynomial over $F$ has a root in $E$. It's not clear to me why $E$ is actually algebraically closed. I attempted the following, but I don't think it's correct: I let $f$ be an irreducible polynomial in $E[X]$. I let $\alpha$ be a root in some extension, so $f=m_{\alpha,E}$. Since $\alpha$ is algebraic over $E$, it is also algebraic over $F$, let $m_{\alpha,F}$ be it's minimal polynomial. I now let $K$ be a splitting field of $m_{\alpha,F}$, which is a finite extension since each root has finite degree over $F$. If $m_{\alpha,F}$ is separable, then $K/F$ is also separable, so as a finite, separable extension, we can write $K=F(\beta)$ for some primitive element $\beta$. By assumption, $m_{\alpha,F}$ has a root in $E$, call it $r$. Then we can embed $F(\beta)$ into $r$ by mapping $\beta$ to $r$. It follows that $m_{\alpha,F}$ splits in $E$. Since $f\mid m_{\alpha,F}$, we must also have the $f$ is split in $E$. But what happens if $m_{\alpha,F}$ is not separable? In such case, $F$ must have characteristic $p$. I know we can express $m_{\alpha,F}=g(X^{p^k})$ for some irreducible, separable polynomial $g(X)\in F[X]$. But I'm not sure what follows after that. NB: I say $E$ is algebraically closed if every nonconstant polynomial in $E[X]$ has a root in $E$.",,"['abstract-algebra', 'field-theory']"
80,Product of two primitive polynomials,Product of two primitive polynomials,,"I'm having troubles with one of the problems in the book Introduction to Commutative Algebra by Atiyah and MacDonald. It's on page 11, and is the last part of the second question. Given $R$ a commutative ring with unit. Let $R[x]$ be the ring of polynomials in an indeterminate $x$ with coefficients in $R$ . We say that a polynomial $f = \sum\limits_{i=0}^n r_ix^i \in R[x]$ (with coefficients $r_0, r_1, \ldots, r_n$ ) is primitive if $\langle r_0,r_1,...,r_n\rangle = R$ , i.e., the ideal generated by the coefficients of $f$ is $R$ . Let $f$ and $g$ be two polynomials in $R[x]$ . Prove that $fg$ is primitive iff $f$ and $g$ are both primitive. The $\Rightarrow$ part is easy. Say, $f = \sum\limits_{i=0}^n r_ix^i$ , $g = \sum\limits_{i=0}^m s_ix^i$ ; then $fg = \sum\limits_{i=0}^{m+n} c_ix^i$ , where $c_k = \sum\limits_{i + j = k}r_is_j$ . Since $fg$ is primitive, there exists a set of $\{\alpha_i\} \subset R$ , such that $\sum\limits_{i=0}^{m+n} \alpha_ic_i = 1$ , to prove $f$ is primitive, I just need to write all $c_i$ 's in terms of $r_i$ 's, and $s_j$ 's, then group all $r_i$ accordingly, rearranging  it a little bit, and everything is perfectly done. And the proof of the primitivity of $g$ is basically the same. The $\Leftarrow$ part is just so difficult. Say $f = \sum\limits_{i=0}^n r_ix^i$ , $g = \sum\limits_{i=0}^m s_ix^i$ are both primitive, then there exists $\{\alpha_i\}; \{\beta_i\} \subset R$ , such that $\sum\limits_{i=0}^{n} \alpha_ir_i = 1$ , and $\sum\limits_{i=0}^{m} \beta_is_i = 1$ . At first, I thought of multiplying the two together, but it just didn't work. So, I'm stuck since I cannot see any way other than multiplying the two sums together. I hope you guys can give me a small push on this. Thanks very much in advance, And have a good day.","I'm having troubles with one of the problems in the book Introduction to Commutative Algebra by Atiyah and MacDonald. It's on page 11, and is the last part of the second question. Given a commutative ring with unit. Let be the ring of polynomials in an indeterminate with coefficients in . We say that a polynomial (with coefficients ) is primitive if , i.e., the ideal generated by the coefficients of is . Let and be two polynomials in . Prove that is primitive iff and are both primitive. The part is easy. Say, , ; then , where . Since is primitive, there exists a set of , such that , to prove is primitive, I just need to write all 's in terms of 's, and 's, then group all accordingly, rearranging  it a little bit, and everything is perfectly done. And the proof of the primitivity of is basically the same. The part is just so difficult. Say , are both primitive, then there exists , such that , and . At first, I thought of multiplying the two together, but it just didn't work. So, I'm stuck since I cannot see any way other than multiplying the two sums together. I hope you guys can give me a small push on this. Thanks very much in advance, And have a good day.","R R[x] x R f = \sum\limits_{i=0}^n r_ix^i \in R[x] r_0, r_1, \ldots, r_n \langle r_0,r_1,...,r_n\rangle = R f R f g R[x] fg f g \Rightarrow f = \sum\limits_{i=0}^n r_ix^i g = \sum\limits_{i=0}^m s_ix^i fg = \sum\limits_{i=0}^{m+n} c_ix^i c_k = \sum\limits_{i + j = k}r_is_j fg \{\alpha_i\} \subset R \sum\limits_{i=0}^{m+n} \alpha_ic_i = 1 f c_i r_i s_j r_i g \Leftarrow f = \sum\limits_{i=0}^n r_ix^i g = \sum\limits_{i=0}^m s_ix^i \{\alpha_i\}; \{\beta_i\} \subset R \sum\limits_{i=0}^{n} \alpha_ir_i = 1 \sum\limits_{i=0}^{m} \beta_is_i = 1","['abstract-algebra', 'commutative-algebra', 'polynomials']"
81,Integral domain with two elements that do not have a gcd,Integral domain with two elements that do not have a gcd,,"I have the following example of an integral domain with two elements that do not have a gcd from wikipedia : $R = \mathbb{Z}\left[\sqrt{-3}\,\,\right],\quad a = 4 = 2\cdot 2 = \left(1+\sqrt{-3}\,\,\right)\left(1-\sqrt{-3}\,\,\right),\quad b = \left(1+\sqrt{-3}\,\,\right)\cdot 2.$ The elements $2$ and $1 + \sqrt{−3}$ are two ""maximal common divisors"" (i.e. any common divisor which is a multiple of $2$ is associated to $2$, the same holds for $1 + \sqrt{−3}$), but they are not associated, so there is no greatest common divisor of a and b. I can understand it, but how can I prove or strictly explain that $2$ and $1 + \sqrt{−3}$ are two ""maximal common divisors"" and they are not associated?","I have the following example of an integral domain with two elements that do not have a gcd from wikipedia : $R = \mathbb{Z}\left[\sqrt{-3}\,\,\right],\quad a = 4 = 2\cdot 2 = \left(1+\sqrt{-3}\,\,\right)\left(1-\sqrt{-3}\,\,\right),\quad b = \left(1+\sqrt{-3}\,\,\right)\cdot 2.$ The elements $2$ and $1 + \sqrt{−3}$ are two ""maximal common divisors"" (i.e. any common divisor which is a multiple of $2$ is associated to $2$, the same holds for $1 + \sqrt{−3}$), but they are not associated, so there is no greatest common divisor of a and b. I can understand it, but how can I prove or strictly explain that $2$ and $1 + \sqrt{−3}$ are two ""maximal common divisors"" and they are not associated?",,"['abstract-algebra', 'gcd-and-lcm']"
82,What is the intuition of conjugacy classes?,What is the intuition of conjugacy classes?,,"How can I fully understand what are conjugacy classes are in groups? I know the definition, that $a$ and $b$ are conjugate if $gag^{-1}=b$ for some $g\in G$. But what is the intuition? Using a multiplication table (all the possible multiplications), how can I understand what a conjugacy class is? For example, on Wikipedia you can see this table: How can I relate the idea of a conjugacy class with this table?","How can I fully understand what are conjugacy classes are in groups? I know the definition, that $a$ and $b$ are conjugate if $gag^{-1}=b$ for some $g\in G$. But what is the intuition? Using a multiplication table (all the possible multiplications), how can I understand what a conjugacy class is? For example, on Wikipedia you can see this table: How can I relate the idea of a conjugacy class with this table?",,"['abstract-algebra', 'group-theory', 'intuition']"
83,What is it to be normal?,What is it to be normal?,,"I'm interested to find out why the word 'normal' crops up so many different areas of mathematics, especially but not exclusively in abstract algebra, and how the definitions are related, if at all. Some common examples are: A subgroup $H$ of a group $G$ is normal if $gHg^{-1}=H$ for each $g \in G$ . An algebraic extension $L$ of a field $K$ is normal if every polynomial in $K[X]$ with a root in $L$ splits in $L$ . A topological space $X$ is normal if for any disjoint closed subsets $A,B \subseteq X$ there exist disjoint open subsets $U,V \subseteq X$ with $A \subseteq U$ and $B \subseteq V$ . A real number is normal if, in each base $b$ , each of the digits from $0$ to $b-1$ has asymptotic density $\frac{1}{b}$ in its base- $b$ expansion. A vector $v \in \mathbb{R}^3$ is normal to a $2$ -manifold $X$ at the point $p \in X$ if $\langle v, w \rangle = 0$ for each $w \in T_p X$ . A random variable $X : (\Omega, \mathcal{F}, \mathbb{P}) \to \mathbb{R}$ is normal if its probability density function takes the form $\dfrac{1}{\sqrt{2\pi \sigma^2}} \exp \left \{ -\dfrac{(x-\mu)^2}{2\sigma^2} \right \}$ for some $\mu \in \mathbb{R}$ and $\sigma^2 > 0$ . Normal groups and normal field extensions are related thanks to Galois theory: if $F/K$ is a Galois extension with Galois group $G$ then $H \le G$ is a normal subgroup if and only if $F^H/K$ is a normal extension. But how about normal subgroups and normal topological spaces, for example? Is there a rationale behind using the word normal , or are the meanings disjoint, having evolved in separate fields for unrelated reasons? Or, to whittle this all down to a single question: is there a well-defined notion of 'normality' in mathematics, and if so, what is it?","I'm interested to find out why the word 'normal' crops up so many different areas of mathematics, especially but not exclusively in abstract algebra, and how the definitions are related, if at all. Some common examples are: A subgroup of a group is normal if for each . An algebraic extension of a field is normal if every polynomial in with a root in splits in . A topological space is normal if for any disjoint closed subsets there exist disjoint open subsets with and . A real number is normal if, in each base , each of the digits from to has asymptotic density in its base- expansion. A vector is normal to a -manifold at the point if for each . A random variable is normal if its probability density function takes the form for some and . Normal groups and normal field extensions are related thanks to Galois theory: if is a Galois extension with Galois group then is a normal subgroup if and only if is a normal extension. But how about normal subgroups and normal topological spaces, for example? Is there a rationale behind using the word normal , or are the meanings disjoint, having evolved in separate fields for unrelated reasons? Or, to whittle this all down to a single question: is there a well-defined notion of 'normality' in mathematics, and if so, what is it?","H G gHg^{-1}=H g \in G L K K[X] L L X A,B \subseteq X U,V \subseteq X A \subseteq U B \subseteq V b 0 b-1 \frac{1}{b} b v \in \mathbb{R}^3 2 X p \in X \langle v, w \rangle = 0 w \in T_p X X : (\Omega, \mathcal{F}, \mathbb{P}) \to \mathbb{R} \dfrac{1}{\sqrt{2\pi \sigma^2}} \exp \left \{ -\dfrac{(x-\mu)^2}{2\sigma^2} \right \} \mu \in \mathbb{R} \sigma^2 > 0 F/K G H \le G F^H/K","['abstract-algebra', 'definition']"
84,An exercise with Zariski topology,An exercise with Zariski topology,,"I read this exercise: Prove that the set $S = \{ (n, 2^n, 3^n ) \mid n \in \mathbb{N} \}$ is dense in $\mathbb{C}^3$ with Zariski topology. I have seriously thought about it, but I do not manage to solve the problem. Besides I cannot answer the simpler question if $ \{ (n, 2^n) \mid n \in \mathbb{N} \}$ is Zariski-dense in $\mathbb{C}^2$. However, using Artin's theorem about independence of characters, I can prove that $\{ (2^n, 3^n ) \mid n \in \mathbb{N} \}$ is Zariski-dense in $\mathbb{C}^2$. Can someone give me a hint?","I read this exercise: Prove that the set $S = \{ (n, 2^n, 3^n ) \mid n \in \mathbb{N} \}$ is dense in $\mathbb{C}^3$ with Zariski topology. I have seriously thought about it, but I do not manage to solve the problem. Besides I cannot answer the simpler question if $ \{ (n, 2^n) \mid n \in \mathbb{N} \}$ is Zariski-dense in $\mathbb{C}^2$. However, using Artin's theorem about independence of characters, I can prove that $\{ (2^n, 3^n ) \mid n \in \mathbb{N} \}$ is Zariski-dense in $\mathbb{C}^2$. Can someone give me a hint?",,"['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'field-theory']"
85,Galois ring extension,Galois ring extension,,"Is there an analogous theory to Galois extension of fields for commutative rings? In particular, what does it mean for a ring extension to be Galois? Thanks.","Is there an analogous theory to Galois extension of fields for commutative rings? In particular, what does it mean for a ring extension to be Galois? Thanks.",,"['abstract-algebra', 'commutative-algebra', 'ring-theory', 'galois-theory']"
86,Does a finite ring's additive structure and the structure of its group of units determine its ring structure?,Does a finite ring's additive structure and the structure of its group of units determine its ring structure?,,"Let $A$ and $B$ be finite commutative rings with unity. Denote the additive group structure of each to be $A^{(+)}$ and $B^{(+)}$, and the multiplicative group of units of each to be $A^{(\times)}$ and $B^{(\times)}$ respectively. Supposing that $A^{(+)}\cong B^{(+)}$ and $A^{(\times)}\cong B^{(\times)}$, does it follow then that $A\cong B$?","Let $A$ and $B$ be finite commutative rings with unity. Denote the additive group structure of each to be $A^{(+)}$ and $B^{(+)}$, and the multiplicative group of units of each to be $A^{(\times)}$ and $B^{(\times)}$ respectively. Supposing that $A^{(+)}\cong B^{(+)}$ and $A^{(\times)}\cong B^{(\times)}$, does it follow then that $A\cong B$?",,"['abstract-algebra', 'ring-theory']"
87,"$(G,\circ)$ is an abelian group, where $x\circ y=\frac{x+y+a(1+xy)}{1+xy+a(x+y)}$","is an abelian group, where","(G,\circ) x\circ y=\frac{x+y+a(1+xy)}{1+xy+a(x+y)}","Let $G=(-1,1)$ and $a\in G$ be fixed. Prove that $(G,\circ)$ is an abelian group, where $$x\circ y=\frac{x+y+a(1+xy)}{1+xy+a(x+y)}, \forall x,y\in G.$$ To me, it seems extremely tedious to prove the axioms of the group in this case. Proving associativity is horrendous and I don't believe that any other of the axioms (apart from commutativity) is provable without extremely long computations. In order to avoid this, I tried to use the so-called structure transport i.e. finding a bijective function from $G$ to some well-known group. I couldn't come up with any function, so I don't know how to actually solve this question. I doubt that it can be solved by proving each of the group axioms, but if anyone finds a way to do this I would be both amazed and grateful.","Let and be fixed. Prove that is an abelian group, where To me, it seems extremely tedious to prove the axioms of the group in this case. Proving associativity is horrendous and I don't believe that any other of the axioms (apart from commutativity) is provable without extremely long computations. In order to avoid this, I tried to use the so-called structure transport i.e. finding a bijective function from to some well-known group. I couldn't come up with any function, so I don't know how to actually solve this question. I doubt that it can be solved by proving each of the group axioms, but if anyone finds a way to do this I would be both amazed and grateful.","G=(-1,1) a\in G (G,\circ) x\circ y=\frac{x+y+a(1+xy)}{1+xy+a(x+y)}, \forall x,y\in G. G","['abstract-algebra', 'group-theory', 'abelian-groups']"
88,"Show that the kernel of the map $SL(n, \mathbb{Z}) \to SL(n, \mathbb{Z}/3\mathbb{Z})$ has no torsion.",Show that the kernel of the map  has no torsion.,"SL(n, \mathbb{Z}) \to SL(n, \mathbb{Z}/3\mathbb{Z})","I am trying to show that the kernel of the natural map $SL(n, \mathbb{Z}) \to SL(n, \mathbb{Z}/3\mathbb{Z})$ has no torsion. That is, if $A$ is in the kernel then $A = I$ or $A^n \neq I$ for all $n \in \mathbb{N}\setminus\{0\}$. If $A$ is in the kernel, it is of the form $I + 3B$ where $B$ is an integer matrix. Beyond that, I don't have any ideas. None of the canonical forms seem to be helpful as these are integer valued matrices. As always, any hints would be very much appreciated.","I am trying to show that the kernel of the natural map $SL(n, \mathbb{Z}) \to SL(n, \mathbb{Z}/3\mathbb{Z})$ has no torsion. That is, if $A$ is in the kernel then $A = I$ or $A^n \neq I$ for all $n \in \mathbb{N}\setminus\{0\}$. If $A$ is in the kernel, it is of the form $I + 3B$ where $B$ is an integer matrix. Beyond that, I don't have any ideas. None of the canonical forms seem to be helpful as these are integer valued matrices. As always, any hints would be very much appreciated.",,"['abstract-algebra', 'group-theory', 'matrices']"
89,Non-associative version of a group satisfying these identities: $(xy)y^{-1}=y^{-1}(yx)=x$,Non-associative version of a group satisfying these identities:,(xy)y^{-1}=y^{-1}(yx)=x,"The following identities are a consequence of the group axioms. $$(xy)y^{-1}=x,\quad y^{-1}(yx)=x$$ Notice we haven't mentioned an identity element, and that the above identities make sense even in the absence of associativity. Is there any interest in the generalization of a group where these identities are taken as the sole axioms? The data would consist of an underlying set a law of composition an inversion operator Remark . These axioms allow us to solve simple equations. For example, in the additive group of integers we can argue as follows.$$x+3=4$$ $$\Rightarrow (x+3)+(-3)=4+(-3)$$ $$\Rightarrow x = 4+(-3)$$","The following identities are a consequence of the group axioms. $$(xy)y^{-1}=x,\quad y^{-1}(yx)=x$$ Notice we haven't mentioned an identity element, and that the above identities make sense even in the absence of associativity. Is there any interest in the generalization of a group where these identities are taken as the sole axioms? The data would consist of an underlying set a law of composition an inversion operator Remark . These axioms allow us to solve simple equations. For example, in the additive group of integers we can argue as follows.$$x+3=4$$ $$\Rightarrow (x+3)+(-3)=4+(-3)$$ $$\Rightarrow x = 4+(-3)$$",,['abstract-algebra']
90,Prerequisites for Algebraic Topology,Prerequisites for Algebraic Topology,,"I'd like to self-study Munkres' Topology . I'm already comfortable with point-set topology, so the first part of the book will serve as a nice review with some new theorems every now and then. My main interest is the second part, Algebraic Topology. On that, the author says ""we do assume familiarity with the elements of group theory."" What exactly are the elements of group theory that are needed? Is there a PDF or concise book that would provide me with the elements needed in order to study the second part in Munkres's book? (Please don't recommend tomes such as Dummit & Foote). Thanks.","I'd like to self-study Munkres' Topology . I'm already comfortable with point-set topology, so the first part of the book will serve as a nice review with some new theorems every now and then. My main interest is the second part, Algebraic Topology. On that, the author says ""we do assume familiarity with the elements of group theory."" What exactly are the elements of group theory that are needed? Is there a PDF or concise book that would provide me with the elements needed in order to study the second part in Munkres's book? (Please don't recommend tomes such as Dummit & Foote). Thanks.",,"['abstract-algebra', 'group-theory', 'reference-request', 'algebraic-topology']"
91,What is the prerequisite knowledge for learning Galois theory?,What is the prerequisite knowledge for learning Galois theory?,,What is the prerequisite knowledge for learning Galois theory? I don't know what a ring is.,What is the prerequisite knowledge for learning Galois theory? I don't know what a ring is.,,"['abstract-algebra', 'reference-request', 'soft-question', 'galois-theory']"
92,Weird subfields of $\Bbb{R}$,Weird subfields of,\Bbb{R},"I found this problem, and I can't get an answer to it: Prove that there are subfields of $\Bbb{R}$ that are a) non-measurable. b) of measure zero and continuum cardinality. I can't seem to imagine how to construct such subfields of $\Bbb{R}$ .","I found this problem, and I can't get an answer to it: Prove that there are subfields of that are a) non-measurable. b) of measure zero and continuum cardinality. I can't seem to imagine how to construct such subfields of .",\Bbb{R} \Bbb{R},"['abstract-algebra', 'measure-theory', 'field-theory', 'examples-counterexamples']"
93,Prove that the multiplicative inverse of $a$ modulo $m$ exists if and only if $a$ and $m$ are coprime.,Prove that the multiplicative inverse of  modulo  exists if and only if  and  are coprime.,a m a m,Prove that the multiplicative inverse of $a$ modulo $m$ exists if and only if $a$ and $m$ are coprime. Can someone help me with this?,Prove that the multiplicative inverse of $a$ modulo $m$ exists if and only if $a$ and $m$ are coprime. Can someone help me with this?,,['abstract-algebra']
94,Tensor product of graded algebras,Tensor product of graded algebras,,Why the tensor product of graded algebras is defined with a commutation $\epsilon $ like this : $(a\otimes b)(c\otimes d)= \epsilon(ac\otimes bd)$ ? what is the usefulness of the commutator $\epsilon$ here ? why that tensor product is not defined simply by  $(a\otimes b)(c\otimes d)= (ac\otimes bd)$ ?,Why the tensor product of graded algebras is defined with a commutation $\epsilon $ like this : $(a\otimes b)(c\otimes d)= \epsilon(ac\otimes bd)$ ? what is the usefulness of the commutator $\epsilon$ here ? why that tensor product is not defined simply by  $(a\otimes b)(c\otimes d)= (ac\otimes bd)$ ?,,['abstract-algebra']
95,Proof that a certain subset of the reals is not a ring,Proof that a certain subset of the reals is not a ring,,"Let $A = \{x \sin x : x \in \mathbb{Z}\} \subset \mathbb{R}$. Is $A$ a ring under the usual addition and multiplication operations of $\mathbb{R}$? It looks like it's not, but I can't find something concrete to justify this.","Let $A = \{x \sin x : x \in \mathbb{Z}\} \subset \mathbb{R}$. Is $A$ a ring under the usual addition and multiplication operations of $\mathbb{R}$? It looks like it's not, but I can't find something concrete to justify this.",,"['abstract-algebra', 'ring-theory', 'examples-counterexamples']"
96,An Intuitive Explanation of the Transfer Homomorphism,An Intuitive Explanation of the Transfer Homomorphism,,"I just learned about the transfer homomorphism, and I am having trouble internalizing it. I am learning from 'A Course in the Theory of Groups', and I was hoping that perhaps someone had a more intuitive explanation of the transfer to supplement the book's construction.","I just learned about the transfer homomorphism, and I am having trouble internalizing it. I am learning from 'A Course in the Theory of Groups', and I was hoping that perhaps someone had a more intuitive explanation of the transfer to supplement the book's construction.",,"['abstract-algebra', 'group-theory', 'transfer-theory']"
97,"Why are $i$ and $-i$ ""more indistinguishable"" than $\sqrt{2}$ and $-\sqrt{2}$?","Why are  and  ""more indistinguishable"" than  and ?",i -i \sqrt{2} -\sqrt{2},"Today I learned that two roots of an irreducible polynomial are ""algebraically indistinguishable."" In $\mathbb{Q}(\sqrt{2})$, define the conjugate of $a+b\sqrt{2}$ as $\overline{a+b\sqrt{2}} = a - b\sqrt{2}$. My understanding/intuition on ""algebraically indistinguishable"" is that if $P$ and $Q$ are algebraic expressions (meaning using the ring operations only) in $\mathbb{Q}(\sqrt{2})$ with $P$ = $Q$, then then we also have $\overline{P} = \overline{Q}$ where $\overline{P}$ and $\overline{Q}$ are the algebraic expressions $P$ and $Q$ except every member of $\mathbb{Q}(\sqrt{2})$ in the expression is replaced with its conjugate. For example, $2(3+\sqrt{2})(4+\sqrt{2}) - (6-\sqrt{2}) = 22 + 15\sqrt{2}$ and indeed, $2(3-\sqrt{2})(4-\sqrt{2}) - (6+\sqrt{2}) = 22 - 15\sqrt{2}$. And in $\mathbb{R}(i) = \mathbb{C}$, we're guaranteed the same phenomenon: $2(3+i)(4+i) - (6-i) = 16 + 15i$ $2(3-i)(4-i) - (6+i) = 16 - 15i$ But what I find interesting is that once I involve familiar operations outside of multiplication and addition, this will no longer hold for $\mathbb{Q}(\sqrt{2})$, but it still holds for $\mathbb{R}(i) = \mathbb{C}$. For example, $(-\sqrt{2})^{-\sqrt{2}} \neq \overline{\sqrt{2}^{\sqrt{2}}}$ while on the other hand,$(-i)^{-i} = \overline{i^{i}}$. My initial answer to this is that exponentiation viewed as a binary operation is not closed in $\mathbb{Q}(\sqrt{2})$, so I must view this as an operation on $\mathbb{R}(i) = \mathbb{C}$, but this is a larger field than extending $\mathbb{Q}$ to include the roots of $x^{2}-2$, so in this field with exponentiation, I can now distinguish $\sqrt{2}$ and $-\sqrt{2}$. On the other hand, exponentiation on $\mathbb{R}(i) = \mathbb{C}$ is closed, so even exponentiation does not allow us to algebraically distinguish between $a+bi$ and $a-bi$.","Today I learned that two roots of an irreducible polynomial are ""algebraically indistinguishable."" In $\mathbb{Q}(\sqrt{2})$, define the conjugate of $a+b\sqrt{2}$ as $\overline{a+b\sqrt{2}} = a - b\sqrt{2}$. My understanding/intuition on ""algebraically indistinguishable"" is that if $P$ and $Q$ are algebraic expressions (meaning using the ring operations only) in $\mathbb{Q}(\sqrt{2})$ with $P$ = $Q$, then then we also have $\overline{P} = \overline{Q}$ where $\overline{P}$ and $\overline{Q}$ are the algebraic expressions $P$ and $Q$ except every member of $\mathbb{Q}(\sqrt{2})$ in the expression is replaced with its conjugate. For example, $2(3+\sqrt{2})(4+\sqrt{2}) - (6-\sqrt{2}) = 22 + 15\sqrt{2}$ and indeed, $2(3-\sqrt{2})(4-\sqrt{2}) - (6+\sqrt{2}) = 22 - 15\sqrt{2}$. And in $\mathbb{R}(i) = \mathbb{C}$, we're guaranteed the same phenomenon: $2(3+i)(4+i) - (6-i) = 16 + 15i$ $2(3-i)(4-i) - (6+i) = 16 - 15i$ But what I find interesting is that once I involve familiar operations outside of multiplication and addition, this will no longer hold for $\mathbb{Q}(\sqrt{2})$, but it still holds for $\mathbb{R}(i) = \mathbb{C}$. For example, $(-\sqrt{2})^{-\sqrt{2}} \neq \overline{\sqrt{2}^{\sqrt{2}}}$ while on the other hand,$(-i)^{-i} = \overline{i^{i}}$. My initial answer to this is that exponentiation viewed as a binary operation is not closed in $\mathbb{Q}(\sqrt{2})$, so I must view this as an operation on $\mathbb{R}(i) = \mathbb{C}$, but this is a larger field than extending $\mathbb{Q}$ to include the roots of $x^{2}-2$, so in this field with exponentiation, I can now distinguish $\sqrt{2}$ and $-\sqrt{2}$. On the other hand, exponentiation on $\mathbb{R}(i) = \mathbb{C}$ is closed, so even exponentiation does not allow us to algebraically distinguish between $a+bi$ and $a-bi$.",,"['abstract-algebra', 'complex-numbers', 'field-theory', 'extension-field', 'irreducible-polynomials']"
98,Calculating the Order of An Element in A Group,Calculating the Order of An Element in A Group,,"First of all, I am very new to group theory. The order of an element $g$ of a group $G$ is the smallest positive integer $n: g^n=e$ , the identity element. I understand how to find the order of an element in a group when the group has something to with modulo, for example, in the group $$U(15)=\text{the set of all positive integers less than } n \text{ and relatively prime to } n.$$ $$\text{ which is a group under multiplication by modulo }n=\{1,2,4,7,8,11,13,14\},$$ then $|2|=4$ , because \begin{align*} &2^1=2\\ &2^2=4\\ &2^3=8\\ &2^4=16\mod15=1\\ &\text{So } |2|=4. \end{align*} However, I don't understand how this works for groups that don't have any relation to modulo. Take $(\mathbb{Z},+)$ for instance. If I wanted to find the order of $3$ , then I need to find $n:3^n$ is equal to the identity, which in this case is $0$ . I suppose my question can be summarized as follows: Does the order of an element only make sense if we are dealing with groups dealing with modulo?","First of all, I am very new to group theory. The order of an element of a group is the smallest positive integer , the identity element. I understand how to find the order of an element in a group when the group has something to with modulo, for example, in the group then , because However, I don't understand how this works for groups that don't have any relation to modulo. Take for instance. If I wanted to find the order of , then I need to find is equal to the identity, which in this case is . I suppose my question can be summarized as follows: Does the order of an element only make sense if we are dealing with groups dealing with modulo?","g G n: g^n=e U(15)=\text{the set of all
positive integers less than } n \text{ and relatively prime to } n. \text{ which is a group under multiplication by modulo }n=\{1,2,4,7,8,11,13,14\}, |2|=4 \begin{align*}
&2^1=2\\
&2^2=4\\
&2^3=8\\
&2^4=16\mod15=1\\
&\text{So } |2|=4.
\end{align*} (\mathbb{Z},+) 3 n:3^n 0","['abstract-algebra', 'group-theory']"
99,$\operatorname{Aut}(V)$ is isomorphic to $S_3$,is isomorphic to,\operatorname{Aut}(V) S_3,"I'm currently working my way through Harvard's online abstract algebra lectures (if you're interested, you can find them here ).  The lectures come complete with notes and homework problems.  Of course, since I don't actually go to Harvard, I can't hand in the homework assignments to find out if I'm doing them correctly.  So I've decided to try to crowd source the grading of my solutions.  I'll post individual questions as I finish them and wait for comments.  I would like to get critiques of not just my reasoning but the style of my write ups as well.  Also, any alternative approaches to the problem would be welcome.  I've looked for forums dedicated to these kinds of OCW courses but have not been able to find any.  This surprises me.  It seems like, with the advent of these free online educational resources, an online meeting place for those who take advantage of them would be a natural offshoot.  So this might be a bit of an experiment.  Unless I'm the 873rd person to post something like this here.  If that's the case, sorry for being so long winded. Anyway, on with the question.  This one is assigned in the 4th lecture. Let $V$ denote the Klein 4-group.  Show that $\operatorname{Aut}(V)$ is isomorphic to $S_3$. (I've moved my solution below to keep this question from showing up in the unanswered list.) Thanks...","I'm currently working my way through Harvard's online abstract algebra lectures (if you're interested, you can find them here ).  The lectures come complete with notes and homework problems.  Of course, since I don't actually go to Harvard, I can't hand in the homework assignments to find out if I'm doing them correctly.  So I've decided to try to crowd source the grading of my solutions.  I'll post individual questions as I finish them and wait for comments.  I would like to get critiques of not just my reasoning but the style of my write ups as well.  Also, any alternative approaches to the problem would be welcome.  I've looked for forums dedicated to these kinds of OCW courses but have not been able to find any.  This surprises me.  It seems like, with the advent of these free online educational resources, an online meeting place for those who take advantage of them would be a natural offshoot.  So this might be a bit of an experiment.  Unless I'm the 873rd person to post something like this here.  If that's the case, sorry for being so long winded. Anyway, on with the question.  This one is assigned in the 4th lecture. Let $V$ denote the Klein 4-group.  Show that $\operatorname{Aut}(V)$ is isomorphic to $S_3$. (I've moved my solution below to keep this question from showing up in the unanswered list.) Thanks...",,"['abstract-algebra', 'group-theory', 'finite-groups']"
