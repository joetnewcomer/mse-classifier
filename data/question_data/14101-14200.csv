,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"$\lim\limits_{n\to \infty} \int_0^1 |f(x)-a_nx-b_n| dx=0$ implies $(a_n)_n,(b_n)_n$ are convergent",implies  are convergent,"\lim\limits_{n\to \infty} \int_0^1 |f(x)-a_nx-b_n| dx=0 (a_n)_n,(b_n)_n","Let $f:[0,1] \to \mathbb R$ be a continuous function and the sequences $(a_n)_n,(b_n)_n$ s.t. $$\lim_{n\to \infty}  \int_0^1 |f(x)-a_nx-b_n| dx=0.$$ Prove that $(a_n)_n,(b_n)_n$ are convergent. I know that $$\left|\int_0^1f(x)dx\right| \le \int_0^1|f(x)|dx.$$ Can somebody help me, please?","Let be a continuous function and the sequences s.t. Prove that are convergent. I know that Can somebody help me, please?","f:[0,1] \to \mathbb R (a_n)_n,(b_n)_n \lim_{n\to \infty}  \int_0^1 |f(x)-a_nx-b_n| dx=0. (a_n)_n,(b_n)_n \left|\int_0^1f(x)dx\right| \le \int_0^1|f(x)|dx.","['calculus', 'integration', 'sequences-and-series', 'convergence-divergence']"
1,Is it true that the number is divisible by $p$?,Is it true that the number is divisible by ?,p,"Question: Let $a, b, c$ be positive integers and $p>3$ be a prime ( $ a$ isn't divisible by $p$ ).   Consider a quadratic polynomial $P(x) = ax^2+bx+c$ , and assume that there exists $2 p-1$ consecutive positive integers: $$x+1, x+2, ..., x+2p-1$$ satisfying that $P(x+i)$ is a square number for every $i$ $(1 \leq i \leq 2p-1)$ . Is it true that the number $\Delta = b^2-4ac$ is divisible by $p$ ? I found out that if there exists $i$ in which $1 \leq i \leq p-1$ so that $P(x+i)$ is divisible by $p$ , then $\Delta$ is divisible by not only $p$ , but $p^2$ as well. If $P(x+i)$ is divisible by $p$ , then $p^2|P(x+i)$ and $p^2|P(x+i+p)$ , thus $$p^2|P(x+i+p)-P(x+i) \implies p^2|p(a(2x+2i+p)+b) \implies p|2a(x+i)+b$$ and since $4a\cdot P(x+i)=(2a(x+i)+b)^2-\Delta$ , so $p^2|\Delta$ . However I cannot find any conditions of $a, b, c, p$ so that there exists $i$ in which $1 \leq i \leq p-1$ and $p|P(x+i)$ . Is the question correct or there must be some conditions of $a, b, c, p$ for the question to to be true? (Sorry, English is my second language)","Question: Let be positive integers and be a prime ( isn't divisible by ).   Consider a quadratic polynomial , and assume that there exists consecutive positive integers: satisfying that is a square number for every . Is it true that the number is divisible by ? I found out that if there exists in which so that is divisible by , then is divisible by not only , but as well. If is divisible by , then and , thus and since , so . However I cannot find any conditions of so that there exists in which and . Is the question correct or there must be some conditions of for the question to to be true? (Sorry, English is my second language)","a, b, c p>3  a p P(x) = ax^2+bx+c 2 p-1 x+1, x+2, ..., x+2p-1 P(x+i) i (1 \leq i \leq 2p-1) \Delta = b^2-4ac p i 1 \leq i \leq p-1 P(x+i) p \Delta p p^2 P(x+i) p p^2|P(x+i) p^2|P(x+i+p) p^2|P(x+i+p)-P(x+i) \implies p^2|p(a(2x+2i+p)+b) \implies p|2a(x+i)+b 4a\cdot P(x+i)=(2a(x+i)+b)^2-\Delta p^2|\Delta a, b, c, p i 1 \leq i \leq p-1 p|P(x+i) a, b, c, p","['calculus', 'combinatorics', 'algebra-precalculus', 'geometry', 'number-theory']"
2,How to calculate the integral $\int \frac{a\tan^2{x}+b}{a^2\tan^2{x}+b^2} dx$?,How to calculate the integral ?,\int \frac{a\tan^2{x}+b}{a^2\tan^2{x}+b^2} dx,"How to calculate the integral $\displaystyle\int \dfrac{a\tan^2{x}+b}{a^2\tan^2{x}+b^2} dx$? It seems like a $\arctan$ of what else... but I can not work it out. I have previously asked how to calculate the definite integral between $0$ and $\pi$ here , but the answers there only use complex analysis, so they are of no help for the indefinite integral.","How to calculate the integral $\displaystyle\int \dfrac{a\tan^2{x}+b}{a^2\tan^2{x}+b^2} dx$? It seems like a $\arctan$ of what else... but I can not work it out. I have previously asked how to calculate the definite integral between $0$ and $\pi$ here , but the answers there only use complex analysis, so they are of no help for the indefinite integral.",,"['calculus', 'integration', 'indefinite-integrals', 'trigonometric-integrals']"
3,Evaluate $\int \frac{dx}{(x^2-x+1)\sqrt{x^2+x+1}}$ [duplicate],Evaluate  [duplicate],\int \frac{dx}{(x^2-x+1)\sqrt{x^2+x+1}},"This question already has answers here : Compute the integral $\int\frac{dx}{(x^2-x+1)\sqrt{x^2+x+1}}$ (2 answers) Closed 5 years ago . Evaluate $$I=\int \frac{dx}{(x^2-x+1)\sqrt{x^2+x+1}}$$ My book gave the substitution for $$\int \frac{dx}{P\sqrt{Q}}$$ as $\frac{Q}{P}=t^2$ when $P$ and $Q$ are quadratic expressions So accordingly i used $$\frac{x^2+x+1}{x^2-x+1}=t^2 \tag{1}$$ we get $$\frac{(1-x^2) \, dx}{(x^2-x+1)^2}=t \,dt$$ Then $$I=\int \frac{\sqrt{x^2-x+1}\:dt}{1-x^2}$$ By Componendo Dividendo in $(1)$ we get $$\frac{x^2+1}{x}=\frac{t^2+1}{t^2-1}$$ But how to express integrand purely in terms of $t$?","This question already has answers here : Compute the integral $\int\frac{dx}{(x^2-x+1)\sqrt{x^2+x+1}}$ (2 answers) Closed 5 years ago . Evaluate $$I=\int \frac{dx}{(x^2-x+1)\sqrt{x^2+x+1}}$$ My book gave the substitution for $$\int \frac{dx}{P\sqrt{Q}}$$ as $\frac{Q}{P}=t^2$ when $P$ and $Q$ are quadratic expressions So accordingly i used $$\frac{x^2+x+1}{x^2-x+1}=t^2 \tag{1}$$ we get $$\frac{(1-x^2) \, dx}{(x^2-x+1)^2}=t \,dt$$ Then $$I=\int \frac{\sqrt{x^2-x+1}\:dt}{1-x^2}$$ By Componendo Dividendo in $(1)$ we get $$\frac{x^2+1}{x}=\frac{t^2+1}{t^2-1}$$ But how to express integrand purely in terms of $t$?",,"['calculus', 'indefinite-integrals']"
4,Is this proof of Euler's formula correct?,Is this proof of Euler's formula correct?,,"Let  $$y=\cos \phi+i\sin \phi  \tag{1}$$ Differentiating both sides of equation (1) with respect to $\phi$, we get, $$\begin{align} \frac{dy}{d\phi} &=-\sin \phi+i\cos \phi \\ &=i(\cos \phi-\frac{1}{i}\sin \phi) \\ &=i(\cos\phi+i\sin \phi) \\ &=iy \\ \implies\frac{1}{y}dy &=i\;d\phi \tag{2} \end{align}$$ Integrating both sides of equation (2), we get, $$\begin{align} \int\frac{1}{y}dy&=\int i\;d\phi \\ \implies \ln(y)&=i\phi+c \tag{3} \end{align}$$ Substituting $\phi=0$ in equation (1), we get, $$y=\cos 0+i\sin 0 \implies y=1 \tag{4}$$ Substituting $\phi=0$ and $y=1$ in equation (3) we get, $$\ln(1)=c \implies c=0 \tag{5}$$ Substituting $c=0$ in equation (3) we get, $$\begin{align} \ln(y)&=i\phi \tag{6}\\ \implies e^{i\phi}&=y \tag{7}\\ \therefore e^{i\phi}&=\cos \phi+i\sin \phi \tag{8} \end{align}$$ I found this proof in a book. I think that there is a problem. In $(3)$ and $(6)$, shouldn't $\ln(y)$ be $\ln|y|$ instead? Or is it that, for complex numbers, we do not take the absolute value of the number within the $\ln$?","Let  $$y=\cos \phi+i\sin \phi  \tag{1}$$ Differentiating both sides of equation (1) with respect to $\phi$, we get, $$\begin{align} \frac{dy}{d\phi} &=-\sin \phi+i\cos \phi \\ &=i(\cos \phi-\frac{1}{i}\sin \phi) \\ &=i(\cos\phi+i\sin \phi) \\ &=iy \\ \implies\frac{1}{y}dy &=i\;d\phi \tag{2} \end{align}$$ Integrating both sides of equation (2), we get, $$\begin{align} \int\frac{1}{y}dy&=\int i\;d\phi \\ \implies \ln(y)&=i\phi+c \tag{3} \end{align}$$ Substituting $\phi=0$ in equation (1), we get, $$y=\cos 0+i\sin 0 \implies y=1 \tag{4}$$ Substituting $\phi=0$ and $y=1$ in equation (3) we get, $$\ln(1)=c \implies c=0 \tag{5}$$ Substituting $c=0$ in equation (3) we get, $$\begin{align} \ln(y)&=i\phi \tag{6}\\ \implies e^{i\phi}&=y \tag{7}\\ \therefore e^{i\phi}&=\cos \phi+i\sin \phi \tag{8} \end{align}$$ I found this proof in a book. I think that there is a problem. In $(3)$ and $(6)$, shouldn't $\ln(y)$ be $\ln|y|$ instead? Or is it that, for complex numbers, we do not take the absolute value of the number within the $\ln$?",,"['calculus', 'integration', 'complex-analysis', 'derivatives', 'complex-numbers']"
5,Looking for another way to calculate this integral.,Looking for another way to calculate this integral.,,"Calculate: $$\mathcal{J}=\int_0^{\frac{\sqrt{3}}{2}}{\ln ^2x\frac{\arccos ^3\!\sqrt{1-x^2}}{\sqrt{1-x^2}}}\text{d}x$$ My attempt: $$\int_0^{\frac{\sqrt{3}}{2}}{\ln ^2x\frac{\arccos ^3\!\sqrt{1-x^2}}{\sqrt{1-x^2}}}\text{d}x=\int_0^{\frac{\pi}{3}}{t^3\ln ^2\sin t\text{d}t=\frac{1}{16}}\int_0^{\frac{2\pi}{3}}{t^3\ln^2 \left( \sin \frac{t}{2} \right)}\text{d}t=\frac{1}{16}\mathcal{I} \\ \begin{align*} \mathcal{I}&=\int_0^{\frac{2\pi}{3}}{t^3\ln ^2\left( 2\sin \frac{t}{2} \right)}\text{d}t-2\ln 2\int_0^{\frac{2\pi}{3}}{t^3\ln \left( 2\sin \frac{t}{2} \right)}\text{d}t-\ln ^22\int_0^{\frac{2\pi}{3}}{t^3}\text{d}t \\ &=-\text{Ls}_{6}^{\left( 3 \right)}\left( \frac{2\pi}{3} \right) +2\ln\text{2Ls}_{5}^{\left( 3 \right)}\left( \frac{2\pi}{3} \right) +\frac{4\pi ^4\ln ^22}{81} \end{align*} $$ Hence according to the formula \begin{align*} \zeta \left( n-k,\left\{ 1 \right\} \!^k \right) &-\sum_{j=0}^k{\frac{\left( -i\tau \right) \!^j}{j!}}\text{Li}_{2+k-j,\left\{ 1 \right\} ^{n-k-2}}\left( \text{e}^{i\tau} \right) \\ &=\frac{i^{k+1}\left( -1 \right) \!^{n-1}}{\left( n-1 \right) !}\sum_{r=0}^{n-k-1}{\sum_{m=0}^r{\left( \begin{array}{c} 	n-1\\ 	k,m,r-m\\ \end{array} \right)}}\times \left( \frac{i}{2} \right) \!^r\left( -\pi \right) \!^{r-m}\text{Ls}_{n-\left( r-m \right)}^{\left( k+m \right)}\left( \tau \right) \end{align*} we have $$\begin{align*} \text{Ls}_{6}^{\left( 3 \right)}\left( \frac{2\pi}{3} \right) =&-\frac{946\pi ^6}{76545}-\frac{16\pi ^3}{27}\text{Gl}_{2,1}\left( \frac{2\pi}{3} \right) -\frac{8\pi ^2}{3}\text{Gl}_{3,1}\left( \frac{2\pi}{3} \right) +8\pi \text{Gl}_{4,1}\left( \frac{2\pi}{3} \right) \\ &+12\text{Gl}_{5,1}\left( \frac{2\pi}{3} \right) +6\zeta ^2\left( 3 \right) \end{align*}  \\ \text{Ls}_{5}^{\left( 3 \right)}\left( \frac{2\pi}{3} \right) =\frac{8\pi ^3}{27}\text{Cl}_2\left( \frac{2\pi}{3} \right) -4\pi \text{Cl}_4\left( \frac{2\pi}{3} \right) -\frac{16\pi ^2}{27}\zeta \left( 3 \right) +\frac{242}{27}\zeta \left( 5 \right) $$ and we get \begin{align*} \mathcal{I}=&\frac{946\pi ^6}{76545}+\frac{4\pi ^2\ln ^22}{81}+\frac{16\pi ^3}{27}\text{Gl}_{2,1}\left( \frac{2\pi}{3} \right) +\frac{8\pi ^2}{3}\text{Gl}_{3,1}\left( \frac{2\pi}{3} \right) -8\pi \text{Gl}_{4,1}\left( \frac{2\pi}{3} \right) \\ &-12\text{Gl}_{5,1}\left( \frac{2\pi}{3} \right) +\frac{16\ln 2\pi ^3}{27}\text{Cl}_2\left( \frac{2\pi}{3} \right)  -8\ln 2\pi \text{Cl}_4\left( \frac{2\pi}{3} \right) -6\zeta ^2\left( 3 \right) \\ &-\frac{32\ln 2\pi ^2}{27}\zeta \left( 3 \right) +\frac{848\ln 2}{27}\zeta \left( 5 \right)  \end{align*} So \begin{align*} \mathcal{J}=\frac{1}{16}\mathcal{I}=&\frac{473\pi ^6}{612360}+\frac{\pi ^3}{27}\text{Gl}_{2,1}\left( \frac{2\pi}{3} \right) +\frac{\pi ^2}{6}\text{Gl}_{3,1}\left( \frac{2\pi}{3} \right) -\frac{\pi}{2}\text{Gl}_{4,1}\left( \frac{2\pi}{3} \right)  \\ &-\frac{3}{4}\text{Gl}_{5,1}\left( \frac{2\pi}{3} \right) +\frac{\pi ^3\ln 2}{27}\text{Cl}_2\left( \frac{2\pi}{3} \right) -\frac{\pi \ln 2}{2}\text{Cl}_4\left( \frac{2\pi}{3} \right) +\frac{\pi ^4\ln ^22}{324} \\ &-\frac{2\pi ^2\ln 2}{27}\zeta \left( 3 \right) -\frac{3}{8}\zeta ^2\left( 3 \right) +\frac{121\ln 2}{108}\zeta \left( 5 \right)  \end{align*} Notations: \begin{align*} &\text{Cl}_{a_1,...,a_k}\left( \theta \right) =\begin{cases} 	\Im \text{Li}_{a_1,...,a_k}\left( \text{e}^{i\theta} \right) \,\,\text{if}\,\,a_1+\cdots +a_k\,\,\text{even}\\ 	\Re \text{Li}_{a_1,...,a_k}\left( \text{e}^{i\theta} \right) \,\,\text{if}\,\,a_1+\cdots +a_k\,\,\text{odd}\\ \end{cases} \\ &\text{Gl}_{a_1,...,a_k}\left( \theta \right) =\begin{cases} 	\Re \text{Li}_{a_1,...,a_k}\left( \text{e}^{i\theta} \right) \,\,\text{if}\,\,a_1+\cdots +a_k\,\,\text{even}\\ 	\Im \text{Li}_{a_1,...,a_k}\left( \text{e}^{i\theta} \right) \,\,\text{if}\,\,a_1+\cdots +a_k\,\,\text{odd}\\ \end{cases} \\ &\text{Li}_{a_1,.\!\:.\!\:.\!\:,a_k}\left( z \right) =\sum_{n_1>\cdots >n_k>0}{\frac{z^{n_1}}{n_{1}^{a_1}\cdots n_{k}^{a_k}}} \\ &\zeta \left( a_1,.\!\:.\!\:.\!\:a_k \right) =\text{Li}_{a_1,.\!\:.\!\:.\!\:,a_k}\left( 1 \right)  \\ &\text{Ls}_{n}^{\left( k \right)}\left( \sigma \right) =-\int_0^{\sigma}{\theta ^k\ln ^{n-1-k}\left| 2\sin \frac{\theta}{2} \right|}\,\text{d}\theta \end{align*} So I wonder is there another way to calculate the integral,complex or real method. Thanks!","Calculate: $$\mathcal{J}=\int_0^{\frac{\sqrt{3}}{2}}{\ln ^2x\frac{\arccos ^3\!\sqrt{1-x^2}}{\sqrt{1-x^2}}}\text{d}x$$ My attempt: $$\int_0^{\frac{\sqrt{3}}{2}}{\ln ^2x\frac{\arccos ^3\!\sqrt{1-x^2}}{\sqrt{1-x^2}}}\text{d}x=\int_0^{\frac{\pi}{3}}{t^3\ln ^2\sin t\text{d}t=\frac{1}{16}}\int_0^{\frac{2\pi}{3}}{t^3\ln^2 \left( \sin \frac{t}{2} \right)}\text{d}t=\frac{1}{16}\mathcal{I} \\ \begin{align*} \mathcal{I}&=\int_0^{\frac{2\pi}{3}}{t^3\ln ^2\left( 2\sin \frac{t}{2} \right)}\text{d}t-2\ln 2\int_0^{\frac{2\pi}{3}}{t^3\ln \left( 2\sin \frac{t}{2} \right)}\text{d}t-\ln ^22\int_0^{\frac{2\pi}{3}}{t^3}\text{d}t \\ &=-\text{Ls}_{6}^{\left( 3 \right)}\left( \frac{2\pi}{3} \right) +2\ln\text{2Ls}_{5}^{\left( 3 \right)}\left( \frac{2\pi}{3} \right) +\frac{4\pi ^4\ln ^22}{81} \end{align*} $$ Hence according to the formula \begin{align*} \zeta \left( n-k,\left\{ 1 \right\} \!^k \right) &-\sum_{j=0}^k{\frac{\left( -i\tau \right) \!^j}{j!}}\text{Li}_{2+k-j,\left\{ 1 \right\} ^{n-k-2}}\left( \text{e}^{i\tau} \right) \\ &=\frac{i^{k+1}\left( -1 \right) \!^{n-1}}{\left( n-1 \right) !}\sum_{r=0}^{n-k-1}{\sum_{m=0}^r{\left( \begin{array}{c} 	n-1\\ 	k,m,r-m\\ \end{array} \right)}}\times \left( \frac{i}{2} \right) \!^r\left( -\pi \right) \!^{r-m}\text{Ls}_{n-\left( r-m \right)}^{\left( k+m \right)}\left( \tau \right) \end{align*} we have $$\begin{align*} \text{Ls}_{6}^{\left( 3 \right)}\left( \frac{2\pi}{3} \right) =&-\frac{946\pi ^6}{76545}-\frac{16\pi ^3}{27}\text{Gl}_{2,1}\left( \frac{2\pi}{3} \right) -\frac{8\pi ^2}{3}\text{Gl}_{3,1}\left( \frac{2\pi}{3} \right) +8\pi \text{Gl}_{4,1}\left( \frac{2\pi}{3} \right) \\ &+12\text{Gl}_{5,1}\left( \frac{2\pi}{3} \right) +6\zeta ^2\left( 3 \right) \end{align*}  \\ \text{Ls}_{5}^{\left( 3 \right)}\left( \frac{2\pi}{3} \right) =\frac{8\pi ^3}{27}\text{Cl}_2\left( \frac{2\pi}{3} \right) -4\pi \text{Cl}_4\left( \frac{2\pi}{3} \right) -\frac{16\pi ^2}{27}\zeta \left( 3 \right) +\frac{242}{27}\zeta \left( 5 \right) $$ and we get \begin{align*} \mathcal{I}=&\frac{946\pi ^6}{76545}+\frac{4\pi ^2\ln ^22}{81}+\frac{16\pi ^3}{27}\text{Gl}_{2,1}\left( \frac{2\pi}{3} \right) +\frac{8\pi ^2}{3}\text{Gl}_{3,1}\left( \frac{2\pi}{3} \right) -8\pi \text{Gl}_{4,1}\left( \frac{2\pi}{3} \right) \\ &-12\text{Gl}_{5,1}\left( \frac{2\pi}{3} \right) +\frac{16\ln 2\pi ^3}{27}\text{Cl}_2\left( \frac{2\pi}{3} \right)  -8\ln 2\pi \text{Cl}_4\left( \frac{2\pi}{3} \right) -6\zeta ^2\left( 3 \right) \\ &-\frac{32\ln 2\pi ^2}{27}\zeta \left( 3 \right) +\frac{848\ln 2}{27}\zeta \left( 5 \right)  \end{align*} So \begin{align*} \mathcal{J}=\frac{1}{16}\mathcal{I}=&\frac{473\pi ^6}{612360}+\frac{\pi ^3}{27}\text{Gl}_{2,1}\left( \frac{2\pi}{3} \right) +\frac{\pi ^2}{6}\text{Gl}_{3,1}\left( \frac{2\pi}{3} \right) -\frac{\pi}{2}\text{Gl}_{4,1}\left( \frac{2\pi}{3} \right)  \\ &-\frac{3}{4}\text{Gl}_{5,1}\left( \frac{2\pi}{3} \right) +\frac{\pi ^3\ln 2}{27}\text{Cl}_2\left( \frac{2\pi}{3} \right) -\frac{\pi \ln 2}{2}\text{Cl}_4\left( \frac{2\pi}{3} \right) +\frac{\pi ^4\ln ^22}{324} \\ &-\frac{2\pi ^2\ln 2}{27}\zeta \left( 3 \right) -\frac{3}{8}\zeta ^2\left( 3 \right) +\frac{121\ln 2}{108}\zeta \left( 5 \right)  \end{align*} Notations: \begin{align*} &\text{Cl}_{a_1,...,a_k}\left( \theta \right) =\begin{cases} 	\Im \text{Li}_{a_1,...,a_k}\left( \text{e}^{i\theta} \right) \,\,\text{if}\,\,a_1+\cdots +a_k\,\,\text{even}\\ 	\Re \text{Li}_{a_1,...,a_k}\left( \text{e}^{i\theta} \right) \,\,\text{if}\,\,a_1+\cdots +a_k\,\,\text{odd}\\ \end{cases} \\ &\text{Gl}_{a_1,...,a_k}\left( \theta \right) =\begin{cases} 	\Re \text{Li}_{a_1,...,a_k}\left( \text{e}^{i\theta} \right) \,\,\text{if}\,\,a_1+\cdots +a_k\,\,\text{even}\\ 	\Im \text{Li}_{a_1,...,a_k}\left( \text{e}^{i\theta} \right) \,\,\text{if}\,\,a_1+\cdots +a_k\,\,\text{odd}\\ \end{cases} \\ &\text{Li}_{a_1,.\!\:.\!\:.\!\:,a_k}\left( z \right) =\sum_{n_1>\cdots >n_k>0}{\frac{z^{n_1}}{n_{1}^{a_1}\cdots n_{k}^{a_k}}} \\ &\zeta \left( a_1,.\!\:.\!\:.\!\:a_k \right) =\text{Li}_{a_1,.\!\:.\!\:.\!\:,a_k}\left( 1 \right)  \\ &\text{Ls}_{n}^{\left( k \right)}\left( \sigma \right) =-\int_0^{\sigma}{\theta ^k\ln ^{n-1-k}\left| 2\sin \frac{\theta}{2} \right|}\,\text{d}\theta \end{align*} So I wonder is there another way to calculate the integral,complex or real method. Thanks!",,"['calculus', 'integration', 'definite-integrals']"
6,"Show the series
$\sum_{n=1}^\infty\frac{n^2a_n}{(a_1+a_2+\cdots+a_n)^2}$ is convergent.","Show the series
 is convergent.",\sum_{n=1}^\infty\frac{n^2a_n}{(a_1+a_2+\cdots+a_n)^2},"Assume $a_i>0$ and $\sum\limits_{n=1}^\infty\dfrac{1}{a_i}$ is convergent. Show the series $$\sum_{n=1}^\infty\frac{n^2a_n}{(a_1+a_2+\cdots+a_n)^2}$$ is convergent. Since we can get the convergence of $$\sum_{n=1}^\infty\frac{n}{a_1+a_2+\cdots+a_n},$$ is it feasible to apply Abel's test? Or I should use other methods?","Assume $a_i>0$ and $\sum\limits_{n=1}^\infty\dfrac{1}{a_i}$ is convergent. Show the series $$\sum_{n=1}^\infty\frac{n^2a_n}{(a_1+a_2+\cdots+a_n)^2}$$ is convergent. Since we can get the convergence of $$\sum_{n=1}^\infty\frac{n}{a_1+a_2+\cdots+a_n},$$ is it feasible to apply Abel's test? Or I should use other methods?",,"['calculus', 'sequences-and-series', 'convergence-divergence']"
7,"Find $\int\frac{\tan^2(x)}{\sqrt{x}} \, dx$",Find,"\int\frac{\tan^2(x)}{\sqrt{x}} \, dx","I can not find the next antiderivative $$\displaystyle\int\dfrac{\tan^2(x)}{\sqrt{x}}\,dx$$ I tried with integration by parts the second integral, please help me. My try $$ \begin{aligned} \int \dfrac{\sec^2(x)-1}{\sqrt{x}}\,dx =\int\dfrac{\sec^2(x)}{\sqrt{x}}\,dx-\int\dfrac{dx}{\sqrt{x}}=\int\dfrac{\sec^2(x)}{\sqrt{x}}\,dx-2\cdot\sqrt{x}+C\end{aligned} $$ Thank you so much.","I can not find the next antiderivative $$\displaystyle\int\dfrac{\tan^2(x)}{\sqrt{x}}\,dx$$ I tried with integration by parts the second integral, please help me. My try $$ \begin{aligned} \int \dfrac{\sec^2(x)-1}{\sqrt{x}}\,dx =\int\dfrac{\sec^2(x)}{\sqrt{x}}\,dx-\int\dfrac{dx}{\sqrt{x}}=\int\dfrac{\sec^2(x)}{\sqrt{x}}\,dx-2\cdot\sqrt{x}+C\end{aligned} $$ Thank you so much.",,"['calculus', 'integration', 'trigonometric-integrals']"
8,How to solve this definite integral with involving logarithm: $\int_0^1\left( \ln (4-3^x)+2 \ln(1+3^x)\right)dx$,How to solve this definite integral with involving logarithm:,\int_0^1\left( \ln (4-3^x)+2 \ln(1+3^x)\right)dx,$$\int_0^1\left( \ln (4-3^x)+2 \ln(1+3^x)\right)dx.$$ The answer given $\log 16$. Can anyone explain this question for me ? Thanks a lot.,$$\int_0^1\left( \ln (4-3^x)+2 \ln(1+3^x)\right)dx.$$ The answer given $\log 16$. Can anyone explain this question for me ? Thanks a lot.,,"['calculus', 'integration', 'definite-integrals']"
9,Why Are Sine and Cosine Called Harmonic Functions,Why Are Sine and Cosine Called Harmonic Functions,,"I thought that the definition of a harmonic function f such that $\nabla^2f=0$ In one dimension, doesn't this mean a function who's second derivative is zero? IE $\frac{d^2f}{dy^2}=0$ However, the sine nor cosine function's second derivative does not equal zero, but in many textbooks they are refereed to as harmonic functions. What's going on here?","I thought that the definition of a harmonic function f such that $\nabla^2f=0$ In one dimension, doesn't this mean a function who's second derivative is zero? IE $\frac{d^2f}{dy^2}=0$ However, the sine nor cosine function's second derivative does not equal zero, but in many textbooks they are refereed to as harmonic functions. What's going on here?",,"['calculus', 'multivariable-calculus', 'trigonometry', 'definition']"
10,Solve $2\ddot{y}y - 3(\dot{y})^2 + 8x^2 = 0$,Solve,2\ddot{y}y - 3(\dot{y})^2 + 8x^2 = 0,"Solve differential equation $$2\ddot{y}y - 3(\dot{y})^2  + 8x^2 = 0$$ I know that we have to use some smart substitution here, so that the equation becomes linear. The only thing I came up with is a smart guessed particular solution: $y = x^2$. If we plug this function in, we get: $$2\cdot2\cdot x^2 - 3(2x)^2 +8x^2 = 4x^2 - 12x^2 + 8x^2= 0$$ I made a mistake. The coefficients where different in the exam: $$ \begin{cases}     3\ddot{y}y + 3(\dot{y})^2 - 2x^2 = 0, \\     y(0) = 1, \\     \dot{y}(0) = 0. \end{cases} $$ Does it make the solution easier?","Solve differential equation $$2\ddot{y}y - 3(\dot{y})^2  + 8x^2 = 0$$ I know that we have to use some smart substitution here, so that the equation becomes linear. The only thing I came up with is a smart guessed particular solution: $y = x^2$. If we plug this function in, we get: $$2\cdot2\cdot x^2 - 3(2x)^2 +8x^2 = 4x^2 - 12x^2 + 8x^2= 0$$ I made a mistake. The coefficients where different in the exam: $$ \begin{cases}     3\ddot{y}y + 3(\dot{y})^2 - 2x^2 = 0, \\     y(0) = 1, \\     \dot{y}(0) = 0. \end{cases} $$ Does it make the solution easier?",,"['calculus', 'ordinary-differential-equations']"
11,Closed form for $\sum_{n=1}^{\infty}\frac{(-1)^n}{\sqrt{n^2+a^2}}$,Closed form for,\sum_{n=1}^{\infty}\frac{(-1)^n}{\sqrt{n^2+a^2}},"Do the convergent sum $$\sum_{n=1}^{\infty}\frac{(-1)^n}{\sqrt{n^2+a^2}}$$ posses a closed form? ($a \in \mathbb{R}$) Special case is known, for $a=0$ one recalls well known alternating harmonic series : $$\sum_{n=1}^{\infty}\frac{(-1)^n}{n}=-\ln 2$$","Do the convergent sum $$\sum_{n=1}^{\infty}\frac{(-1)^n}{\sqrt{n^2+a^2}}$$ posses a closed form? ($a \in \mathbb{R}$) Special case is known, for $a=0$ one recalls well known alternating harmonic series : $$\sum_{n=1}^{\infty}\frac{(-1)^n}{n}=-\ln 2$$",,"['calculus', 'summation']"
12,"What is the meaning of $1/(D+a)$, where $D$ is the derivative operator?","What is the meaning of , where  is the derivative operator?",1/(D+a) D,"Today I read the answer to this post , in which the poster integrates $x^5e^x$ by making these manipulations with the differential operator $D$: $$\frac1Dx^5e^x=e^x\frac{1}{1+D}x^5=e^x(1-D+D^2+...)x^5$$ which I was amazed by but yet suspicious of. After reading a bit on differential operators, I know a few properties. For example, $D+a$ (where $a$ is constant) is a polynomial differential operator which comes from the differential equation $y'+ay = q(x)$. Also, for polynomials $f$ and $g$, $f(x)\cdot g(x)=h(x)$ implies $h(D)u=f(D) \circ [g(D)u]$ with $u$ being a function and $f(D), g(D), h(D)$ being polynomial differential operators. Since $(1+x) \cdot \frac1{1+x} = 1$, I know that if we applied the operator $(1+D)$ to some function, $\frac{1}{1+D}$ would invert it back to the original function. However, this still doesn't help me make sense of the meaning of $\frac{1}{1+D}$. For example: If $1+D$ comes from the differential equation $y'+ay+q$, where does $\frac{1}{1+D}$ come from? In other words, if $(1+D)y = 1\cdot y + Dy = y' + y$, how do we compute $\frac{1}{1+D}y$? (Is it even possible, and how does it relate to integration?) How do we justify the power series of the operator? How do we know there are no convergence issues?","Today I read the answer to this post , in which the poster integrates $x^5e^x$ by making these manipulations with the differential operator $D$: $$\frac1Dx^5e^x=e^x\frac{1}{1+D}x^5=e^x(1-D+D^2+...)x^5$$ which I was amazed by but yet suspicious of. After reading a bit on differential operators, I know a few properties. For example, $D+a$ (where $a$ is constant) is a polynomial differential operator which comes from the differential equation $y'+ay = q(x)$. Also, for polynomials $f$ and $g$, $f(x)\cdot g(x)=h(x)$ implies $h(D)u=f(D) \circ [g(D)u]$ with $u$ being a function and $f(D), g(D), h(D)$ being polynomial differential operators. Since $(1+x) \cdot \frac1{1+x} = 1$, I know that if we applied the operator $(1+D)$ to some function, $\frac{1}{1+D}$ would invert it back to the original function. However, this still doesn't help me make sense of the meaning of $\frac{1}{1+D}$. For example: If $1+D$ comes from the differential equation $y'+ay+q$, where does $\frac{1}{1+D}$ come from? In other words, if $(1+D)y = 1\cdot y + Dy = y' + y$, how do we compute $\frac{1}{1+D}y$? (Is it even possible, and how does it relate to integration?) How do we justify the power series of the operator? How do we know there are no convergence issues?",,"['calculus', 'abstract-algebra', 'integration', 'differential-operators']"
13,Prove $\int_{0}^{\infty}{1\over (1+{\phi^{-2}}x^2)(1+{\phi^{-4}}x^2)}dx={\pi\over 2}$,Prove,\int_{0}^{\infty}{1\over (1+{\phi^{-2}}x^2)(1+{\phi^{-4}}x^2)}dx={\pi\over 2},"Prove $\phi$; golden ratio $$I=\int_{0}^{\infty}{1\over (1+{\phi^{-2}}x^2)(1+{\phi^{-4}}x^2)}dx={\pi\over 2}\tag1$$ Let $q=\phi^{-2}$ and $p=\phi^{-4}$ $${1\over (1+qx^2)(1+px^2)}={Ax+B\over 1+qx^2}+{Cx+D\over 1+px^2}\tag2$$ Result $A=0$, $B=\phi$, $C=0$ and $D=-{1\over  \phi}$ Sub the result into $(2)$ and we got $${1\over (1+\phi^{-2}x^2)(1+\phi^{-4}x^2)}={\phi\over 1+\phi^{-2}x^2}-{\phi^{-1}\over 1+\phi^{-4}x^2}$$ Hence $$I=\int_{0}^{\infty}\left({\phi\over 1+\phi^{-2}x^2}-{\phi^{-1}\over 1+\phi^{-4}x^2}\right)dx\tag3$$ Simplified $(3)\rightarrow (4)$ $$I=\phi^3\int_{0}^{\infty}{1\over \phi^2+x^2}dx-\phi^3\int_{0}^{\infty}{1\over \phi^4+x^2}dx\tag4$$ Recall $$\int_{0}^{\infty}{1\over a^2+x^2}dx={\pi \over 2a}\tag5$$ Utilise $(5)$ to brings $(4)$ to $(6)$ $$I=\phi^3\cdot{\pi\over 2\phi}-\phi^3{\pi\over 2\phi^2}\tag6$$ $$I={\pi\over 2}(\phi^2-\phi)={\pi\over 2}\tag7$$ This method it is a bit tedious, can someone tackle integral (1) with a quicker method?","Prove $\phi$; golden ratio $$I=\int_{0}^{\infty}{1\over (1+{\phi^{-2}}x^2)(1+{\phi^{-4}}x^2)}dx={\pi\over 2}\tag1$$ Let $q=\phi^{-2}$ and $p=\phi^{-4}$ $${1\over (1+qx^2)(1+px^2)}={Ax+B\over 1+qx^2}+{Cx+D\over 1+px^2}\tag2$$ Result $A=0$, $B=\phi$, $C=0$ and $D=-{1\over  \phi}$ Sub the result into $(2)$ and we got $${1\over (1+\phi^{-2}x^2)(1+\phi^{-4}x^2)}={\phi\over 1+\phi^{-2}x^2}-{\phi^{-1}\over 1+\phi^{-4}x^2}$$ Hence $$I=\int_{0}^{\infty}\left({\phi\over 1+\phi^{-2}x^2}-{\phi^{-1}\over 1+\phi^{-4}x^2}\right)dx\tag3$$ Simplified $(3)\rightarrow (4)$ $$I=\phi^3\int_{0}^{\infty}{1\over \phi^2+x^2}dx-\phi^3\int_{0}^{\infty}{1\over \phi^4+x^2}dx\tag4$$ Recall $$\int_{0}^{\infty}{1\over a^2+x^2}dx={\pi \over 2a}\tag5$$ Utilise $(5)$ to brings $(4)$ to $(6)$ $$I=\phi^3\cdot{\pi\over 2\phi}-\phi^3{\pi\over 2\phi^2}\tag6$$ $$I={\pi\over 2}(\phi^2-\phi)={\pi\over 2}\tag7$$ This method it is a bit tedious, can someone tackle integral (1) with a quicker method?",,"['calculus', 'integration', 'definite-integrals']"
14,Riemann Sum Approximations: When are trapezoids more accurate than the middle sum?,Riemann Sum Approximations: When are trapezoids more accurate than the middle sum?,,"We can approximate a definite integral, $\int_a^b f(x)dx$ , using a variety of Riemann sums. If $T_n$ and $M_n$ are the nth sums using the trapezoid and midpoint (middle) sum methods and if the second derivative of $f$ is bounded on $[a, b]$ then does the following theorem imply that $M_n$ ""tends to be more accurate"" then $T_n$ ? If $f''$ is continuous on $[a, b]$ and $|f''(x)| \leq K$ , $\forall$ $x \in [a, b]$ . Then, $\left| \int_a^b f(x)dx - T_n \right| \leq K\frac{(b-a)^3}{12n^2}$ and $\left| \int_a^b f(x)dx - M_n \right| \leq K\frac{(b-a)^3}{24n^2}$ For this question let, $E_{T_n} = \left| \int_a^b f(x)dx - T_n \right| $ and $E_{M_n} = \left| \int_a^b f(x)dx - M_n \right| $ The theorem is presented (without proof) in a calculus 2 book. It only really seems to imply that, we can with 100% certainly bound $E_{M_n}$ smaller than we can bound $E_{T_n}$ . But, that says nothing about the actual values of $E_{T_n}$ or $E_{M_n}$ . So, isn't it possible to customize a function so that $E_{T_n} < E_{M_n}$ for a particular n? Could we even make a function so that $E_{T_n} < E_{M_n}$ $\forall n$ ?","We can approximate a definite integral, , using a variety of Riemann sums. If and are the nth sums using the trapezoid and midpoint (middle) sum methods and if the second derivative of is bounded on then does the following theorem imply that ""tends to be more accurate"" then ? If is continuous on and , . Then, and For this question let, and The theorem is presented (without proof) in a calculus 2 book. It only really seems to imply that, we can with 100% certainly bound smaller than we can bound . But, that says nothing about the actual values of or . So, isn't it possible to customize a function so that for a particular n? Could we even make a function so that ?","\int_a^b f(x)dx T_n M_n f [a, b] M_n T_n f'' [a, b] |f''(x)| \leq K \forall x \in [a, b] \left| \int_a^b f(x)dx - T_n \right| \leq K\frac{(b-a)^3}{12n^2} \left| \int_a^b f(x)dx - M_n \right| \leq K\frac{(b-a)^3}{24n^2} E_{T_n} = \left| \int_a^b f(x)dx - T_n \right|  E_{M_n} = \left| \int_a^b f(x)dx - M_n \right|  E_{M_n} E_{T_n} E_{T_n} E_{M_n} E_{T_n} < E_{M_n} E_{T_n} < E_{M_n} \forall n","['calculus', 'numerical-methods', 'riemann-sum', 'approximate-integration']"
15,Product of two hypergeometric functions,Product of two hypergeometric functions,,"For $\Re a, \Re b, \Re c, \Re a', \Re b', \Re c'>0$,  I would calculate the following product $$ {}_2 F_1(a, b; c; x^{-1}) \times \, {}_2 F_1(a', b'; c'; 1-\frac{x}{y}) $$  For all $y>x>1$. Is there a formula that allows me to calculate the above product Thanks in advance.","For $\Re a, \Re b, \Re c, \Re a', \Re b', \Re c'>0$,  I would calculate the following product $$ {}_2 F_1(a, b; c; x^{-1}) \times \, {}_2 F_1(a', b'; c'; 1-\frac{x}{y}) $$  For all $y>x>1$. Is there a formula that allows me to calculate the above product Thanks in advance.",,"['calculus', 'special-functions', 'hypergeometric-function']"
16,A series related to Catalan numbers,A series related to Catalan numbers,,"Recall the definition of Catalan numbers : $$C_n=\frac1{n+1}\binom{2n}n=\frac{2^n(2n-1)!!}{(n+1)!}.\tag1$$ Now consider the following series with a parameter $n\in\mathbb N^+$: $$S_n=\frac{2\cdot18^n}{3\sqrt5}\cdot\sum_{k=1}^\infty\frac{C_{2k}\cdot k^n}{5^{2k}}.\tag2$$ It appears that $S_n$ is always integer (and odd), with the following values for $n=1,2,3,...:$ $$1, 43, 3009, 318507, 46065921, 8482079403, 1899432317889, 501282878789547,...$$ ( click here to see more terms) Can we prove that $S_n$ is always integer (odd)? Can we find an explicit formula for $S_n$ not involving an infinite summation?","Recall the definition of Catalan numbers : $$C_n=\frac1{n+1}\binom{2n}n=\frac{2^n(2n-1)!!}{(n+1)!}.\tag1$$ Now consider the following series with a parameter $n\in\mathbb N^+$: $$S_n=\frac{2\cdot18^n}{3\sqrt5}\cdot\sum_{k=1}^\infty\frac{C_{2k}\cdot k^n}{5^{2k}}.\tag2$$ It appears that $S_n$ is always integer (and odd), with the following values for $n=1,2,3,...:$ $$1, 43, 3009, 318507, 46065921, 8482079403, 1899432317889, 501282878789547,...$$ ( click here to see more terms) Can we prove that $S_n$ is always integer (odd)? Can we find an explicit formula for $S_n$ not involving an infinite summation?",,"['calculus', 'sequences-and-series', 'number-theory', 'hypergeometric-function', 'catalan-numbers']"
17,Evaluate $\int [\cos(\csc^{-1}(\tan(\sec^{-1} (\cot(\sin^{-1}(\sec(\cot^{-1}(\csc(\cos^{-1}(x))))))))))]^2 dx$,Evaluate,\int [\cos(\csc^{-1}(\tan(\sec^{-1} (\cot(\sin^{-1}(\sec(\cot^{-1}(\csc(\cos^{-1}(x))))))))))]^2 dx,I was trying to evaluate the below integral: $$\int \big[\cos(\csc^{-1}(\tan(\sec^{-1}(\cot(\sin^{-1}(\sec(\cot^{-1}(\csc(\cos^{-1}(x))))))))))\big]^2 dx$$ I managed to simplify it  to the below form: $$\int \frac{3x^2-5}{2x^2-3}dx$$ I then got to this form: $$\frac{3x}{2}+C-\frac{1}{2}\int\frac{1}{2x^2-3}dx$$ I'm stuck at this point; could anyone show me how to proceed?,I was trying to evaluate the below integral: I managed to simplify it  to the below form: I then got to this form: I'm stuck at this point; could anyone show me how to proceed?,\int \big[\cos(\csc^{-1}(\tan(\sec^{-1}(\cot(\sin^{-1}(\sec(\cot^{-1}(\csc(\cos^{-1}(x))))))))))\big]^2 dx \int \frac{3x^2-5}{2x^2-3}dx \frac{3x}{2}+C-\frac{1}{2}\int\frac{1}{2x^2-3}dx,"['calculus', 'integration', 'indefinite-integrals']"
18,A simple way to find $\lim_{n\rightarrow\infty}{\frac{1}{n^2}\sum_{k=1}^n{\sqrt{n^2-k^2}}}$,A simple way to find,\lim_{n\rightarrow\infty}{\frac{1}{n^2}\sum_{k=1}^n{\sqrt{n^2-k^2}}},"I was reading an exam paper used to identify gifted high-school students, and I encountered the following problem:  $$\lim_{n\rightarrow\infty}{\frac{1}{n^2}\sum_{k=1}^n{\sqrt{n^2-k^2}}}$$ Using standard calculus techniques, this sum can be easily calculated by treating the sum as a riemann sum, and calculating the corresponding integral. Indeed, if we denote $f(x)=\sqrt{1-x^2}$, we get: $$ \lim_{n\rightarrow\infty}{\frac{1}{n^2}\sum_{k=1}^n{\sqrt{n^2-k^2}}} =  \lim_{n\rightarrow\infty}{\frac{1}{n}\sum_{k=1}^n{f\left(\frac{k}{n}\right)}} =  \int_0^1{f(x)dx}=\frac{\pi}{4} $$ Where the integral is calculated by noting that the area under the graph of $f$, between $0$ and $1$, is a quarter of the unit disk. However, in my country, riemann sums are not taught in high-schools, so using this technique is not an option. Is there a simpler method to calculate this limit?","I was reading an exam paper used to identify gifted high-school students, and I encountered the following problem:  $$\lim_{n\rightarrow\infty}{\frac{1}{n^2}\sum_{k=1}^n{\sqrt{n^2-k^2}}}$$ Using standard calculus techniques, this sum can be easily calculated by treating the sum as a riemann sum, and calculating the corresponding integral. Indeed, if we denote $f(x)=\sqrt{1-x^2}$, we get: $$ \lim_{n\rightarrow\infty}{\frac{1}{n^2}\sum_{k=1}^n{\sqrt{n^2-k^2}}} =  \lim_{n\rightarrow\infty}{\frac{1}{n}\sum_{k=1}^n{f\left(\frac{k}{n}\right)}} =  \int_0^1{f(x)dx}=\frac{\pi}{4} $$ Where the integral is calculated by noting that the area under the graph of $f$, between $0$ and $1$, is a quarter of the unit disk. However, in my country, riemann sums are not taught in high-schools, so using this technique is not an option. Is there a simpler method to calculate this limit?",,"['calculus', 'algebra-precalculus', 'limits']"
19,Proving bounds on an infinite product,Proving bounds on an infinite product,,"Let $p$ be an infinite product, such that $p = 2^{1/4}3^{1/9}4^{1/16}5^{1/25} ...$ Prove that $2.488472296 ≤ p ≤ 2.633367180$. I start this problem by representing p in the infinite product notation:  $$p = \displaystyle \prod_{k=2}^{\infty}k^{1/k^2} $$ I also defined the partial product as $p_n = \displaystyle \prod_{k=2}^{n}k^{1/k^2} $ Taking the logarithm: $p_n = e^{\ln(p_n)} = e^{\sum_{k=2}^{n} \ln(k^{1/k^2})}$ I have no idea how to prove it. Any help would be highly appreciated.","Let $p$ be an infinite product, such that $p = 2^{1/4}3^{1/9}4^{1/16}5^{1/25} ...$ Prove that $2.488472296 ≤ p ≤ 2.633367180$. I start this problem by representing p in the infinite product notation:  $$p = \displaystyle \prod_{k=2}^{\infty}k^{1/k^2} $$ I also defined the partial product as $p_n = \displaystyle \prod_{k=2}^{n}k^{1/k^2} $ Taking the logarithm: $p_n = e^{\ln(p_n)} = e^{\sum_{k=2}^{n} \ln(k^{1/k^2})}$ I have no idea how to prove it. Any help would be highly appreciated.",,"['calculus', 'sequences-and-series', 'inequality', 'infinite-product']"
20,"Calculation of value of $ \int_{0}^{n}\cos\left(\lfloor x \rfloor\cdot \{x\}\right)dx\;,$",Calculation of value of," \int_{0}^{n}\cos\left(\lfloor x \rfloor\cdot \{x\}\right)dx\;,","$(1)$ Calculation of value of $\displaystyle \int_{0}^{n}\cos\left(\lfloor x \rfloor\cdot \{x\}\right)dx\;,$ Where $\lfloor x \rfloor$ is floor function of $x$ and $\{x\} = x-\lfloor x \rfloor.$ and $n$ is a positive integer. $(2)\; $ Calculation of least positive integer $n$ for which $\displaystyle \int_{1}^{n}\lfloor x \rfloor \cdot \lfloor \sqrt{x} \rfloor dx>60\;,$ Where $\lfloor x \rfloor$ is floor function of $x$ $\bf{My\; Try::}$ For $(1)$ one:: We can write $\displaystyle \int_{0}^{n}\cos\left(\lfloor x \rfloor\cdot \{x\}\right)dx = \displaystyle \int_{0}^{n}\cos\left(\lfloor x \rfloor\cdot \left(x-\lfloor x \rfloor\right)\right)dx$ So $\displaystyle \int_{0}^{n}\cos\left(\lfloor x \rfloor\cdot \left(x-\lfloor x \rfloor\right)\right)dx = \int_{0}^{1}\cos(0)dx+\int_{1}^{2}\cos(1\cdot (x-1))dx+\int_{2}^{3}\cos(2\cdot(x-2))dx+..........+\int_{n-1}^{n}\cos((n-1)(x-(n-1)))dx$ Now How can I solve after that, Help me, Thanks $\bf{My\; Try}::$ For $(2)$ one:: We can write $\displaystyle \int_{1}^{n}\lfloor x \rfloor \cdot \lfloor \sqrt{x} \rfloor dx = \int_{0}^{1}0\cdot 0dx+\int_{1}^{2}1\cdot 1dx+\int_{2}^{3}2\cdot 1dx++\int_{3}^{4}3\cdot 1dx+......+\int_{n-1}^{n}(n-1)\lfloor \sqrt{n-1}\rfloor x$ Now How can i solve after that, Help me, Thanks","Calculation of value of Where is floor function of and and is a positive integer. Calculation of least positive integer for which Where is floor function of For one:: We can write So Now How can I solve after that, Help me, Thanks For one:: We can write Now How can i solve after that, Help me, Thanks","(1) \displaystyle \int_{0}^{n}\cos\left(\lfloor x \rfloor\cdot \{x\}\right)dx\;, \lfloor x \rfloor x \{x\} = x-\lfloor x \rfloor. n (2)\;  n \displaystyle \int_{1}^{n}\lfloor x \rfloor \cdot \lfloor \sqrt{x} \rfloor dx>60\;, \lfloor x \rfloor x \bf{My\; Try::} (1) \displaystyle \int_{0}^{n}\cos\left(\lfloor x \rfloor\cdot \{x\}\right)dx = \displaystyle \int_{0}^{n}\cos\left(\lfloor x \rfloor\cdot \left(x-\lfloor x \rfloor\right)\right)dx \displaystyle \int_{0}^{n}\cos\left(\lfloor x \rfloor\cdot \left(x-\lfloor x \rfloor\right)\right)dx = \int_{0}^{1}\cos(0)dx+\int_{1}^{2}\cos(1\cdot (x-1))dx+\int_{2}^{3}\cos(2\cdot(x-2))dx+..........+\int_{n-1}^{n}\cos((n-1)(x-(n-1)))dx \bf{My\; Try}:: (2) \displaystyle \int_{1}^{n}\lfloor x \rfloor \cdot \lfloor \sqrt{x} \rfloor dx = \int_{0}^{1}0\cdot 0dx+\int_{1}^{2}1\cdot 1dx+\int_{2}^{3}2\cdot 1dx++\int_{3}^{4}3\cdot 1dx+......+\int_{n-1}^{n}(n-1)\lfloor \sqrt{n-1}\rfloor x","['calculus', 'integration', 'ceiling-and-floor-functions', 'fractional-part']"
21,Calculus 3 Problem deals with partials,Calculus 3 Problem deals with partials,,"A particle travels along the curve that lies on both the hyperboloid $x^2 + y^2 − z^2 = 1$ and the plane $x + y + z = 0$. When it reaches the point $(\frac23, −\frac34, \frac1{12})$ it flies off on a tangent, and thenceforth travels along a straight line, until it hits the paraboloid $99z = 64y^2 − 81x^2$ . Where does the particle hit the paraboloid? So i thought to solve the plane for each variable then plug them in to the hyperboloid. However im not even sure were to start please help...","A particle travels along the curve that lies on both the hyperboloid $x^2 + y^2 − z^2 = 1$ and the plane $x + y + z = 0$. When it reaches the point $(\frac23, −\frac34, \frac1{12})$ it flies off on a tangent, and thenceforth travels along a straight line, until it hits the paraboloid $99z = 64y^2 − 81x^2$ . Where does the particle hit the paraboloid? So i thought to solve the plane for each variable then plug them in to the hyperboloid. However im not even sure were to start please help...",,"['calculus', 'multivariable-calculus']"
22,What is the value of Exponential Geometric Sum?,What is the value of Exponential Geometric Sum?,,"The sum in question is  $$\sum_{k=0}^\infty x^{a^k}. $$ This comes from a more difficult summation, but if I can find the value of this one then the other one is solved. Does anyone know the exact value of this? Any help in that direction would be really appreciated. The original problem is in this post: A tricky infinite sum-- solution found numerically, need proof $X Y^{\alpha} + X^2 Y^{\alpha + \alpha^2} +X^3 Y^{\alpha + \alpha^2 + \alpha^3} + ...=\sum\limits_{j = 1}^{\infty}X^j \prod\limits_{k = 1}^{j}Y^{\alpha^k}$ where $0 < \alpha < 1, 0 < X < 1$ and $Y>0$","The sum in question is  $$\sum_{k=0}^\infty x^{a^k}. $$ This comes from a more difficult summation, but if I can find the value of this one then the other one is solved. Does anyone know the exact value of this? Any help in that direction would be really appreciated. The original problem is in this post: A tricky infinite sum-- solution found numerically, need proof $X Y^{\alpha} + X^2 Y^{\alpha + \alpha^2} +X^3 Y^{\alpha + \alpha^2 + \alpha^3} + ...=\sum\limits_{j = 1}^{\infty}X^j \prod\limits_{k = 1}^{j}Y^{\alpha^k}$ where $0 < \alpha < 1, 0 < X < 1$ and $Y>0$",,"['calculus', 'sequences-and-series']"
23,"maximum of $f(x)=\sin{(\pi Ax)}\left(\,\csc{(\pi x)}+\csc{(\pi (\frac{1}{A}-x))}\,\right)$",maximum of,"f(x)=\sin{(\pi Ax)}\left(\,\csc{(\pi x)}+\csc{(\pi (\frac{1}{A}-x))}\,\right)","Let a function $f(x)$ be $f(x)=\sin{(\pi Ax)}\left(\,\csc{(\pi x)}+\csc{(\pi (\frac{1}{A}-x))}\,\right)$ where $A\geq 2$ is a positive integer and $\csc{(x)}=\frac{1}{\sin{(x)}}$. I want to prove that on the interval $x\in[0, \frac{1}{2A}]$, $f(x)$ has its maximum at $x=\frac{1}{2A}$. To prove that, I think we have two approaches. First, prove it directly. Second, prove that $f(x)$ is an increasing function  on the interval $x\in[0, \frac{1}{2A}]$. When $A=2$, we are able to take the second approach thanks to a user named egreg. Prove that $\sin{(\pi 2x)}\left(\,\csc{(\pi x)}+\csc{(\pi (0.5-x))}\,\right)$ is an increasing function Now could anybody prove it generally? I am not sure for any $A$, $f(x)$ is increasing on the interval $x\in[0, \frac{1}{2A}]$ (maybe true?), but strongly believe the maximum is $f(\frac{1}{2A})$. The followings are graphs of $f(x)$ when $A=2, 3, 4$, respectively, where $\frac{1}{2A}=0.25, 0.1667, 0.125$.","Let a function $f(x)$ be $f(x)=\sin{(\pi Ax)}\left(\,\csc{(\pi x)}+\csc{(\pi (\frac{1}{A}-x))}\,\right)$ where $A\geq 2$ is a positive integer and $\csc{(x)}=\frac{1}{\sin{(x)}}$. I want to prove that on the interval $x\in[0, \frac{1}{2A}]$, $f(x)$ has its maximum at $x=\frac{1}{2A}$. To prove that, I think we have two approaches. First, prove it directly. Second, prove that $f(x)$ is an increasing function  on the interval $x\in[0, \frac{1}{2A}]$. When $A=2$, we are able to take the second approach thanks to a user named egreg. Prove that $\sin{(\pi 2x)}\left(\,\csc{(\pi x)}+\csc{(\pi (0.5-x))}\,\right)$ is an increasing function Now could anybody prove it generally? I am not sure for any $A$, $f(x)$ is increasing on the interval $x\in[0, \frac{1}{2A}]$ (maybe true?), but strongly believe the maximum is $f(\frac{1}{2A})$. The followings are graphs of $f(x)$ when $A=2, 3, 4$, respectively, where $\frac{1}{2A}=0.25, 0.1667, 0.125$.",,"['calculus', 'trigonometry']"
24,How to find the center of mass of half a torus?,How to find the center of mass of half a torus?,,"Consider a halved solid torus (half a donut). The radius of the torus are $R_1$ and $R_2$.  I need to find its center of mass. The hint they give is that the center of mass of a homogeneous solid object $\Omega \subset \Bbb R^3$ is calculated as $$\overline{x}=\int_{\Omega}\overline{r}d\overline{r}.$$ I really don't understand this formula, I don't know what $\overline{r}$ means and what is $\Omega$ in this case. I'd appreciate that someone explains what this formula means and how to apply it in this problem. Thanks in advance.","Consider a halved solid torus (half a donut). The radius of the torus are $R_1$ and $R_2$.  I need to find its center of mass. The hint they give is that the center of mass of a homogeneous solid object $\Omega \subset \Bbb R^3$ is calculated as $$\overline{x}=\int_{\Omega}\overline{r}d\overline{r}.$$ I really don't understand this formula, I don't know what $\overline{r}$ means and what is $\Omega$ in this case. I'd appreciate that someone explains what this formula means and how to apply it in this problem. Thanks in advance.",,['calculus']
25,Differential calculus vs Integral calculus,Differential calculus vs Integral calculus,,"I have never done integration in my life and I am in first year of university. Is it harder than taking the derivative? I've heard its just going backwards. Also, my high school taught me only differentiation, I don't know why we never touched on integration. I'm going to be starting it next week and I want to know what I'm facing. Is it generally considered harder than differentiation? Thank you in advance.","I have never done integration in my life and I am in first year of university. Is it harder than taking the derivative? I've heard its just going backwards. Also, my high school taught me only differentiation, I don't know why we never touched on integration. I'm going to be starting it next week and I want to know what I'm facing. Is it generally considered harder than differentiation? Thank you in advance.",,"['calculus', 'integration', 'derivatives']"
26,how to find x in $ax + e^x = k$,how to find x in,ax + e^x = k,in my project i have faced with a formula that I can't solve it. a very simplified and basic version of that equation can be rewritten as $ax + e^x = k$. please help me to solve this elementary calculus equation.,in my project i have faced with a formula that I can't solve it. a very simplified and basic version of that equation can be rewritten as $ax + e^x = k$. please help me to solve this elementary calculus equation.,,['calculus']
27,Evaluate $\lim_{n \to \infty} \sum_{j=0}^{n}{{j+n-1} \choose j}\frac{1}{2^{j+n}}$,Evaluate,\lim_{n \to \infty} \sum_{j=0}^{n}{{j+n-1} \choose j}\frac{1}{2^{j+n}},Evaluate $$\lim_{n \to \infty} \sum_{j=0}^{n}{{j+n-1} \choose j}\frac{1}{2^{j+n}}$$ I don't understand where to start.  Please help.,Evaluate $$\lim_{n \to \infty} \sum_{j=0}^{n}{{j+n-1} \choose j}\frac{1}{2^{j+n}}$$ I don't understand where to start.  Please help.,,"['calculus', 'limits', 'binomial-coefficients']"
28,Derivative definition,Derivative definition,,"Let $f$ be a differentiable function in $x_0$. Calculate the following $\lim$: $$\lim_{h\to 0}\frac{f(x_0+2h)-f(x_0-h)}{5h}$$ since we know from theory that $f'(x_0)=\lim_{h\to 0}\frac{f(x_0+h)-f(x_0)}{h}$, then I said that $x_0-h=t$ and $x_0+2h=t+3h$ where $3h=k$ so $$\frac{3}{5}\lim_{k\to 0}\frac{f(t+k)-f(t)}{k}=\frac{3}{5}f'(t)=\frac{3}{5}f'(x_0-h)$$","Let $f$ be a differentiable function in $x_0$. Calculate the following $\lim$: $$\lim_{h\to 0}\frac{f(x_0+2h)-f(x_0-h)}{5h}$$ since we know from theory that $f'(x_0)=\lim_{h\to 0}\frac{f(x_0+h)-f(x_0)}{h}$, then I said that $x_0-h=t$ and $x_0+2h=t+3h$ where $3h=k$ so $$\frac{3}{5}\lim_{k\to 0}\frac{f(t+k)-f(t)}{k}=\frac{3}{5}f'(t)=\frac{3}{5}f'(x_0-h)$$",,"['calculus', 'derivatives']"
29,"When to create transcendental function to solve ""unsolvable problem""?","When to create transcendental function to solve ""unsolvable problem""?",,"$\int \frac{1}{x} dx$ is an unsolvable problem using standard laws of Calculus (power rule) without the use of the function $f(x) = \ln x$ which was handcrafted by mathematicians to solve such problems. If we go back even further, the function $f(x) = \sin x$ was also a transcendental function used to describe the changing relationship between the arc and chord of a circle - it was not until 1682 that Leibniz proved that $\sin x$ was indeed not expressible as an algebraic function. Today, we still have expressions that can't be evaluated precisely such as $\int x^x dx$ because it cannot really be expressed as a function using the standard toolkit of algebraic and transcendental functions that we currently have. This begs the question, when is it appropriate for mathematicians to come up with new transcendental functions as solutions to ""unsolvable problems"" including but certainly not limited to the integral expression presented above?","$\int \frac{1}{x} dx$ is an unsolvable problem using standard laws of Calculus (power rule) without the use of the function $f(x) = \ln x$ which was handcrafted by mathematicians to solve such problems. If we go back even further, the function $f(x) = \sin x$ was also a transcendental function used to describe the changing relationship between the arc and chord of a circle - it was not until 1682 that Leibniz proved that $\sin x$ was indeed not expressible as an algebraic function. Today, we still have expressions that can't be evaluated precisely such as $\int x^x dx$ because it cannot really be expressed as a function using the standard toolkit of algebraic and transcendental functions that we currently have. This begs the question, when is it appropriate for mathematicians to come up with new transcendental functions as solutions to ""unsolvable problems"" including but certainly not limited to the integral expression presented above?",,"['calculus', 'functions', 'soft-question']"
30,Integral using multiple methods,Integral using multiple methods,,"I'm teaching a Calculus II class and we are covering integration techniques.  We've covered $u$-substitution, integration by parts, trig integrals, trigonometric substitutions, partial fractions and integration involving hyperbolic functions.  I want to give my students some integrals to do that can be done using as many of these methods as possible.  So far, I've come up with $\int\frac{x}{x^2-1}dx$ which can be done using partial fractions, $u$-substitution, trigonometric substitution, and a hyperbolic cosine substitution.  I was wondering if anyone had other examples like this. Thanks.","I'm teaching a Calculus II class and we are covering integration techniques.  We've covered $u$-substitution, integration by parts, trig integrals, trigonometric substitutions, partial fractions and integration involving hyperbolic functions.  I want to give my students some integrals to do that can be done using as many of these methods as possible.  So far, I've come up with $\int\frac{x}{x^2-1}dx$ which can be done using partial fractions, $u$-substitution, trigonometric substitution, and a hyperbolic cosine substitution.  I was wondering if anyone had other examples like this. Thanks.",,"['calculus', 'integration', 'big-list', 'education']"
31,How demonstrate the Craig representation for the Gaussian probability function?,How demonstrate the Craig representation for the Gaussian probability function?,,"The Q-function is defined by :  $$Q(x) =\frac{1}{\sqrt{2\pi}} \int_{x}^{\infty}\exp(-\frac{u^2}{2}) \ \mathrm{d}u \ \ (1).$$ According to the wiki page there is an alternative form of the Q-function based on John W. Craig 's work  that is more useful is expressed as: $$Q(x) =\frac{1}{\pi} \int_{0}^{\frac{\pi}{2}}\exp\left(-\frac{x^2}{2\sin^2(\theta)}\right) \ \mathrm{d}\theta  \ \ (2).$$ Craig's proove is based on probabilistic  approach, there for I look for an analytic one. any help will be appreciated. Thanks.","The Q-function is defined by :  $$Q(x) =\frac{1}{\sqrt{2\pi}} \int_{x}^{\infty}\exp(-\frac{u^2}{2}) \ \mathrm{d}u \ \ (1).$$ According to the wiki page there is an alternative form of the Q-function based on John W. Craig 's work  that is more useful is expressed as: $$Q(x) =\frac{1}{\pi} \int_{0}^{\frac{\pi}{2}}\exp\left(-\frac{x^2}{2\sin^2(\theta)}\right) \ \mathrm{d}\theta  \ \ (2).$$ Craig's proove is based on probabilistic  approach, there for I look for an analytic one. any help will be appreciated. Thanks.",,"['calculus', 'probability', 'integration']"
32,Why Doesn't This Integral $\int \frac{\sqrt{x^2 - 9}}{x^2} \ dx$ Work?,Why Doesn't This Integral  Work?,\int \frac{\sqrt{x^2 - 9}}{x^2} \ dx,"I am trying to solve this integral, which is incorrect compared to Wolfram|Alpha . Why doesn't my method work? Find $\int \frac{\sqrt{x^2 - 9}}{x^2} \ dx$ Side work: $\sin{\theta} = \frac{3}{x}$ $x = \frac{3}{\sin{\theta}} = 3 \csc{\theta}$ $dx = -3 \csc{\theta}\cot{\theta} \ d\theta$ $-\int \frac{\sqrt{9\csc^2{\theta} - 9}}{27 \csc^3{\theta}} \cdot 3 \csc{\theta}\tan{\theta} \ d\theta$ $-\int \frac{3 \cdot \sqrt{\csc^2{\theta} - 1}}{27 \csc^3{\theta}} \cdot 3 \csc{\theta}\cot{\theta} \ d\theta$ $-\int \frac{\cot{\theta}\csc{\theta}\cot{\theta}}{3 \csc^3{\theta}} \ d\theta$ $-\frac{1}{3} \int \cos^2{\theta} \ d\theta$ $-\frac{1}{3} \int \frac{1}{2} \left(1 + \cos{\left(2\theta\right)}\right) \ d\theta$ $-\frac{1}{6} \int 1 + \cos{\left(2\theta\right)} \ d\theta$ $-\frac{1}{6} \int \ d\theta + \frac{1}{6} \int \cos{\left(2\theta\right)} \ d\theta$ Sidework: $u = 2\theta$ $du = 2 \ d\theta$ $-\frac{1}{6} \int \ d\theta + \frac{1}{3} \int \cos{u} \ du$ $-\frac{\theta}{6} + \frac{1}{3} \cdot \sin{u} + C$ $-\frac{\theta}{6} + \frac{1}{3} \cdot \sin{2\theta} + C$ Sidework: $\sin{\left(2\theta\right)} = 2 \sin{\theta} \cos{\theta}$ $\sin{\theta} = \frac{3}{x}$ $\cos{\theta} = \frac{\sqrt{x^2 - 9}}{x}$ $\theta = \sin^{-1}{\left(\frac{3}{x}\right)}$ $-\frac{\sin^{-1}{\left(\frac{3}{x}\right)}}{6} + \frac{2}{3} \cdot \frac{3}{x} \cdot \frac{\sqrt{x^2 - 9}}{x} + C$ $-\frac{\sin^{-1}{\left(\frac{3}{x}\right)}}{6} + \frac{2\sqrt{x^2 - 9}}{x^2} + C$ Thank you for your time.","I am trying to solve this integral, which is incorrect compared to Wolfram|Alpha . Why doesn't my method work? Find $\int \frac{\sqrt{x^2 - 9}}{x^2} \ dx$ Side work: $\sin{\theta} = \frac{3}{x}$ $x = \frac{3}{\sin{\theta}} = 3 \csc{\theta}$ $dx = -3 \csc{\theta}\cot{\theta} \ d\theta$ $-\int \frac{\sqrt{9\csc^2{\theta} - 9}}{27 \csc^3{\theta}} \cdot 3 \csc{\theta}\tan{\theta} \ d\theta$ $-\int \frac{3 \cdot \sqrt{\csc^2{\theta} - 1}}{27 \csc^3{\theta}} \cdot 3 \csc{\theta}\cot{\theta} \ d\theta$ $-\int \frac{\cot{\theta}\csc{\theta}\cot{\theta}}{3 \csc^3{\theta}} \ d\theta$ $-\frac{1}{3} \int \cos^2{\theta} \ d\theta$ $-\frac{1}{3} \int \frac{1}{2} \left(1 + \cos{\left(2\theta\right)}\right) \ d\theta$ $-\frac{1}{6} \int 1 + \cos{\left(2\theta\right)} \ d\theta$ $-\frac{1}{6} \int \ d\theta + \frac{1}{6} \int \cos{\left(2\theta\right)} \ d\theta$ Sidework: $u = 2\theta$ $du = 2 \ d\theta$ $-\frac{1}{6} \int \ d\theta + \frac{1}{3} \int \cos{u} \ du$ $-\frac{\theta}{6} + \frac{1}{3} \cdot \sin{u} + C$ $-\frac{\theta}{6} + \frac{1}{3} \cdot \sin{2\theta} + C$ Sidework: $\sin{\left(2\theta\right)} = 2 \sin{\theta} \cos{\theta}$ $\sin{\theta} = \frac{3}{x}$ $\cos{\theta} = \frac{\sqrt{x^2 - 9}}{x}$ $\theta = \sin^{-1}{\left(\frac{3}{x}\right)}$ $-\frac{\sin^{-1}{\left(\frac{3}{x}\right)}}{6} + \frac{2}{3} \cdot \frac{3}{x} \cdot \frac{\sqrt{x^2 - 9}}{x} + C$ $-\frac{\sin^{-1}{\left(\frac{3}{x}\right)}}{6} + \frac{2\sqrt{x^2 - 9}}{x^2} + C$ Thank you for your time.",,"['calculus', 'integration', 'trigonometry', 'triangles']"
33,Calculate $\lim_{n\rightarrow \infty} \frac{1}{n}\sum_{k=1}^{n}k\sin\left(\frac{a}{k}\right)$,Calculate,\lim_{n\rightarrow \infty} \frac{1}{n}\sum_{k=1}^{n}k\sin\left(\frac{a}{k}\right),"I'm trying to calculate $\lim_{n\rightarrow \infty} \frac{1}{n}\sum_{k=1}^{n}k\sin\left(\frac{a}{k}\right)$. Intuitively the answer is $a$, but I can't see any way to show this. Can anyone help? Thanks!","I'm trying to calculate $\lim_{n\rightarrow \infty} \frac{1}{n}\sum_{k=1}^{n}k\sin\left(\frac{a}{k}\right)$. Intuitively the answer is $a$, but I can't see any way to show this. Can anyone help? Thanks!",,"['calculus', 'limits']"
34,"Pointwise, uniformly and absolute convergence of Fourier series","Pointwise, uniformly and absolute convergence of Fourier series",,"I'd really love your help with this one: I got this Fourier series for $f(x)=x$ in $[-\pi,\pi]$: $$\sum_{1}^{\infty}\frac{2(-1)^{n+1}\sin(nx)}{n}$$ and I need to check if it's (i) pointwise converges,(ii) uniformly converges and if (iii) $$\sum_{1}^{\infty}\left|\frac{2(-1)^{n+1}\sin(nx)}{n}\right|$$ converges.. I tried to do it, and I have couple of specific questions that interrupt me. (i) Can I claim that the series is pointwise due to Leibniz test? since $\frac{\sin(nx)}{n} \to 0$? I was told that I need to use Lipschitz continuity here. How do I use it? (ii) I was told that this series is not uniformly converges since $f(x)$ is not continuous in this part. How come ? Is it because we always see those functions who we compute their Fourier series as periodic functions with period of $[0,2\pi]$ so in our case the function in $0$ is not continues? (iii) How come I can't use Dirichlet test for series and claim that the $$\sum_{1}^{\infty}\left|\frac{2(-1)^{n+1}\sin(nx)}n\right|$$ does converges? The test requires a multiple of a series that monotonic converges to $0$ and $\sum_{1}^{N}|\sin(nx)|<M$? Is it wrong? How can you prove that this series does not converge? Thanks you so much guys!","I'd really love your help with this one: I got this Fourier series for $f(x)=x$ in $[-\pi,\pi]$: $$\sum_{1}^{\infty}\frac{2(-1)^{n+1}\sin(nx)}{n}$$ and I need to check if it's (i) pointwise converges,(ii) uniformly converges and if (iii) $$\sum_{1}^{\infty}\left|\frac{2(-1)^{n+1}\sin(nx)}{n}\right|$$ converges.. I tried to do it, and I have couple of specific questions that interrupt me. (i) Can I claim that the series is pointwise due to Leibniz test? since $\frac{\sin(nx)}{n} \to 0$? I was told that I need to use Lipschitz continuity here. How do I use it? (ii) I was told that this series is not uniformly converges since $f(x)$ is not continuous in this part. How come ? Is it because we always see those functions who we compute their Fourier series as periodic functions with period of $[0,2\pi]$ so in our case the function in $0$ is not continues? (iii) How come I can't use Dirichlet test for series and claim that the $$\sum_{1}^{\infty}\left|\frac{2(-1)^{n+1}\sin(nx)}n\right|$$ does converges? The test requires a multiple of a series that monotonic converges to $0$ and $\sum_{1}^{N}|\sin(nx)|<M$? Is it wrong? How can you prove that this series does not converge? Thanks you so much guys!",,"['calculus', 'fourier-analysis']"
35,On Partial Derivative,On Partial Derivative,,"I am having issues with this mathematical concept, but i couldn't point out where, I've tried rereading thomas and stewart for more than 3 times already but still had no clue. I'll try to explain my thought process and will anyone of you please point out my mistakes? given a function $f(x,y)=|xy|^{0.5}$, how do we determine if the partial derivative is defined at a point, lets say (0,0)? I've figured out there are 3 methods. method 1: $$\frac{d}{dx} |xy|^{0.5} =\frac{(x^2*y^2)^{1/4}}{2x}$$ then at $(0,0)$, it is undefined due to division-by-zero, therefore the P.D is undefined. method2: $f(x,0)=0$ $$\frac{df}{dx}(0,0) = \frac{d}{dx}f(x,0)\vert_{y=0} = 0$$ then at $(0,0)$, $f_x(0,0) = 0$. (P.D is defined) method 3: $$\lim_{h\to 0}\frac{f(0+h,0)-f(0,0)}{h} = 0$$ therefore, $f_x(0,0) = 0$ (P.D is defined) So what the differences between these method?? Did i apply those methods correctly? If so, why do i have contradicting solutions? Thanks a lot for the help.","I am having issues with this mathematical concept, but i couldn't point out where, I've tried rereading thomas and stewart for more than 3 times already but still had no clue. I'll try to explain my thought process and will anyone of you please point out my mistakes? given a function $f(x,y)=|xy|^{0.5}$, how do we determine if the partial derivative is defined at a point, lets say (0,0)? I've figured out there are 3 methods. method 1: $$\frac{d}{dx} |xy|^{0.5} =\frac{(x^2*y^2)^{1/4}}{2x}$$ then at $(0,0)$, it is undefined due to division-by-zero, therefore the P.D is undefined. method2: $f(x,0)=0$ $$\frac{df}{dx}(0,0) = \frac{d}{dx}f(x,0)\vert_{y=0} = 0$$ then at $(0,0)$, $f_x(0,0) = 0$. (P.D is defined) method 3: $$\lim_{h\to 0}\frac{f(0+h,0)-f(0,0)}{h} = 0$$ therefore, $f_x(0,0) = 0$ (P.D is defined) So what the differences between these method?? Did i apply those methods correctly? If so, why do i have contradicting solutions? Thanks a lot for the help.",,"['calculus', 'multivariable-calculus']"
36,Arrow in limit operator,Arrow in limit operator,,"In this Wikipedia article , I see a limit operator such as in: $$\lim_{x \searrow 0} \frac{e^{-1/x}}{x^m}=0\,\,;\,\,\,\, m\in \mathbb{N}$$ I am assuming that the downward pointing arrow indicate the limit as $x$ approaches $0$ from the positive direction? Is this conventional? I've seen both  $\displaystyle\lim_{x \rightarrow 0⁺}$ and $\displaystyle\lim_{x \downarrow 0}$, but never before $\displaystyle\lim_{x \searrow 0}$","In this Wikipedia article , I see a limit operator such as in: $$\lim_{x \searrow 0} \frac{e^{-1/x}}{x^m}=0\,\,;\,\,\,\, m\in \mathbb{N}$$ I am assuming that the downward pointing arrow indicate the limit as $x$ approaches $0$ from the positive direction? Is this conventional? I've seen both  $\displaystyle\lim_{x \rightarrow 0⁺}$ and $\displaystyle\lim_{x \downarrow 0}$, but never before $\displaystyle\lim_{x \searrow 0}$",,"['calculus', 'analysis']"
37,Why is the remainder function $R_{n}(x)$ decreasing?,Why is the remainder function  decreasing?,R_{n}(x),"When solving questions like these: Let $f(x)$ be a real function. Find   $f(0.1)$ using its Taylor expansion   such that the error is less than   $10^{-3}$. Find the lowest degree of   Taylor polynomial needed. (if someone can rephrase the question so its more clear that would be great. I didn't quite nail the translation to English) We were explained that usually the process of solving this is finding some degree that works. Then, depending on how 'far' you are from the error term, you start trying lower degrees. When some degree doesn't work anymore, you say the one before it is the minimal. I was wondering though, why the implicit assumption that the remainder function is decreasing? i.e. if degree $k$ doesn't suffice, $1, 2, ..., k-2, k-1$ won't work either. Our professor said that we can rely on this because most functions we're dealing with comply with this property. Why is that?","When solving questions like these: Let $f(x)$ be a real function. Find   $f(0.1)$ using its Taylor expansion   such that the error is less than   $10^{-3}$. Find the lowest degree of   Taylor polynomial needed. (if someone can rephrase the question so its more clear that would be great. I didn't quite nail the translation to English) We were explained that usually the process of solving this is finding some degree that works. Then, depending on how 'far' you are from the error term, you start trying lower degrees. When some degree doesn't work anymore, you say the one before it is the minimal. I was wondering though, why the implicit assumption that the remainder function is decreasing? i.e. if degree $k$ doesn't suffice, $1, 2, ..., k-2, k-1$ won't work either. Our professor said that we can rely on this because most functions we're dealing with comply with this property. Why is that?",,"['calculus', 'sequences-and-series', 'taylor-expansion']"
38,"Basic multivector derivatives $∂_X X = n$ and $∂_X X^2 = 2X$, etc…","Basic multivector derivatives  and , etc…",∂_X X = n ∂_X X^2 = 2X,"Using geometric algebra, one may define the multivector derivative $∂_X$ with respect to a general multivector $X$ as $$ ∂_X ≔ \sum_J 𝒆^J (𝒆_J * ∂_X) $$ where each “component” $𝒆_J * ∂_X$ is defined by $$ (𝒆_J * ∂_X)f(X) ≔ \frac{\mathrm{d}}{\mathrm{d}\tau}f(X + \tau𝒆_J)\big|_{\tau=0} .$$ Notations $A * B \equiv ⟨AB⟩_0$ denotes the scalar product. For any multivector $A$ , we have $𝒆^J(𝒆_J * A) = A$ . In literature, parentheses are often dropped with the understanding that $A*B C ≡ (A*B)C$ . We employ multi-index notation, $𝒆_J = 𝒆_{j_1}∧\cdots∧𝒆_{j_k}$ . (If $k = 0$ then $𝒆_J = 1$ ). Reciprocal bases are reversed , $𝒆^J = 𝒆^{j_k}∧\cdots∧𝒆^{j_1}$ , so that $𝒆^I * 𝒆_J = δ^I_J$ is always satisfied. Problem I’m having a humiliating time trying to sanity-check this definition by verifying, e.g., $∂_X X = n$ , as stated in eq. (2.29) of [2] or eq. (7.8) of [3]. My computation begins as follows. $$ ∂_X X     = \sum_J 𝒆^J (𝒆_J * ∂_X)X     = \sum_J 𝒆^J \frac{\mathrm{d}}{\mathrm{d}\tau} (X + \tau𝒆_J)\big|_{\tau=0}     = \sum_J 𝒆^J 𝒆_J .$$ There seems to be no room for confusion here. But this is not $n$ . Indeed, \begin{align} \sum_J 𝒆^J 𝒆_J &= \sum_{k=0}^n \sum_{j_1 < \cdots < j_k} \underbrace{𝒆^{j_1\cdots j_k}𝒆_{j_k\cdots j_1}}_1 = \sum_{k=0}^n \binom{n}{k} = 2^n .\end{align} This contradicts Proof 46 of [3], which includes the step “ $\sum_{J_d} δ^J{}_J = d$ ” (a sum over multi-indices in $d$ dimensions) — which I can’t see to be true! My failure is easily generalised: in trying to show $∂_X X^2 = 2X$ , we have \begin{align} ∂_X X^2 &= 𝒆^J(𝒆_J * ∂_X)X^2 = 𝒆^J \frac{\mathrm{d}}{\mathrm{d}\tau} (X + \tau𝒆_J)^2\big|_{\tau=0} \\ &= 𝒆^J(𝒆_J X + X 𝒆_J) = 2^n X + 𝒆^J X 𝒆_J .\end{align} Note that it is easy to verify these results with the less general vector derivative , $\vec ∂ ≔ 𝒆^i ∂_i$ where $∂_i = 𝒆_i * ∂_X$ in the notation above. Then, if $X = X^i𝒆_i$ is the position vector, we have $∂_i X = 𝒆_i$ and thus $ \vec ∂ X = 𝒆^i ∂_i X = 𝒆^i 𝒆_i = n $ and $$ \vec ∂ X^2 = 𝒆^i \frac{\mathrm{d}}{\mathrm{d}\tau} (X + \tau𝒆_i)^2\big|_{\tau=0} = 𝒆^i(𝒆_i X + X 𝒆_i) = 2𝒆^i \, 𝒆_i * X = 2X .$$ Clearly I am misinterpreting the way in which the vector derivative $\vec ∂ = 𝒆^i(𝒆_i * ∂_X)$ is ‘generalised’ to have components at all grades, $∂_X = 𝒆^J (𝒆_J * ∂_X)$ . Could someone with fresh eyes help me out? References Lasenby and Doran, “Multivector Lagrangian Fields” – Ch. 1. Hestenes and Sobczyk, “Clifford Algebra to Geometric Calculus” – Ch. 2, §2. Hitzer, “Multivector Differential Calculus” – page 3.","Using geometric algebra, one may define the multivector derivative with respect to a general multivector as where each “component” is defined by Notations denotes the scalar product. For any multivector , we have . In literature, parentheses are often dropped with the understanding that . We employ multi-index notation, . (If then ). Reciprocal bases are reversed , , so that is always satisfied. Problem I’m having a humiliating time trying to sanity-check this definition by verifying, e.g., , as stated in eq. (2.29) of [2] or eq. (7.8) of [3]. My computation begins as follows. There seems to be no room for confusion here. But this is not . Indeed, This contradicts Proof 46 of [3], which includes the step “ ” (a sum over multi-indices in dimensions) — which I can’t see to be true! My failure is easily generalised: in trying to show , we have Note that it is easy to verify these results with the less general vector derivative , where in the notation above. Then, if is the position vector, we have and thus and Clearly I am misinterpreting the way in which the vector derivative is ‘generalised’ to have components at all grades, . Could someone with fresh eyes help me out? References Lasenby and Doran, “Multivector Lagrangian Fields” – Ch. 1. Hestenes and Sobczyk, “Clifford Algebra to Geometric Calculus” – Ch. 2, §2. Hitzer, “Multivector Differential Calculus” – page 3.","∂_X X 
∂_X ≔ \sum_J 𝒆^J (𝒆_J * ∂_X)
 𝒆_J * ∂_X 
(𝒆_J * ∂_X)f(X) ≔ \frac{\mathrm{d}}{\mathrm{d}\tau}f(X + \tau𝒆_J)\big|_{\tau=0}
. A * B \equiv ⟨AB⟩_0 A 𝒆^J(𝒆_J * A) = A A*B C ≡ (A*B)C 𝒆_J = 𝒆_{j_1}∧\cdots∧𝒆_{j_k} k = 0 𝒆_J = 1 𝒆^J = 𝒆^{j_k}∧\cdots∧𝒆^{j_1} 𝒆^I * 𝒆_J = δ^I_J ∂_X X = n 
∂_X X
    = \sum_J 𝒆^J (𝒆_J * ∂_X)X
    = \sum_J 𝒆^J \frac{\mathrm{d}}{\mathrm{d}\tau} (X + \tau𝒆_J)\big|_{\tau=0}
    = \sum_J 𝒆^J 𝒆_J
. n \begin{align}
\sum_J 𝒆^J 𝒆_J &= \sum_{k=0}^n \sum_{j_1 < \cdots < j_k} \underbrace{𝒆^{j_1\cdots j_k}𝒆_{j_k\cdots j_1}}_1 = \sum_{k=0}^n \binom{n}{k} = 2^n
.\end{align} \sum_{J_d} δ^J{}_J = d d ∂_X X^2 = 2X \begin{align}
∂_X X^2 &= 𝒆^J(𝒆_J * ∂_X)X^2 = 𝒆^J \frac{\mathrm{d}}{\mathrm{d}\tau} (X + \tau𝒆_J)^2\big|_{\tau=0}
\\ &= 𝒆^J(𝒆_J X + X 𝒆_J) = 2^n X + 𝒆^J X 𝒆_J
.\end{align} \vec ∂ ≔ 𝒆^i ∂_i ∂_i = 𝒆_i * ∂_X X = X^i𝒆_i ∂_i X = 𝒆_i 
\vec ∂ X = 𝒆^i ∂_i X = 𝒆^i 𝒆_i = n
 
\vec ∂ X^2 = 𝒆^i \frac{\mathrm{d}}{\mathrm{d}\tau} (X + \tau𝒆_i)^2\big|_{\tau=0} = 𝒆^i(𝒆_i X + X 𝒆_i) = 2𝒆^i \, 𝒆_i * X = 2X
. \vec ∂ = 𝒆^i(𝒆_i * ∂_X) ∂_X = 𝒆^J (𝒆_J * ∂_X)","['calculus', 'clifford-algebras', 'geometric-algebras']"
39,Computing time of flight in a medium with a varying index of refraction,Computing time of flight in a medium with a varying index of refraction,,"The index of refraction , $n$ , for some medium, is the speed of light in a vacuum divided by the speed of light in the medium ( $n = \frac{c}{v}$ ). Consider some light source , $p_s$ (at coordinates $[x_p,y_p,z_p]$ ), and some light receiver , $p_r$ (at coordinates $[x_r,y_r,z_r]$ ). Neglecting the effects of refraction, we might calculate the time of flight for a light signal, moving in a straight line from $p_s$ to $p_r$ , as: $T = \frac{1}{c} \cdot \sqrt{(x_p - x_r)^2 + (y_p - y_r)^2 + (z_p - z_r)^2 }$ For a constant index of refraction, we simply replace $c$ by $\frac{c}{n}$ . How, however, might we calculate the time of flight for a light signal traveling in a ""straight line"" when the index of refraction varies as a function of some coordinate (say, depth ( $z$ ))? In this case, of course, light doesn't actually travel in a straight line, in the common sense. What I have so far... Note: This could be very wrong. It's just where I've gotten so far. Using the principle of least time (see), we have that: $T = \int dt$ We have that $v = \frac{ds}{dt}$ . Thus, $T = \int \frac{ds}{v}$ Suppose $n$ is a function of $z$ . Then, $n = n(z)$ . Using $v = \frac{c}{n(z)}$ , we have that: $T = \int \frac{n(z)}{c} ds$ Now, by Pythagoras $ds^s = dx^2 + dy^2 + dz^2$ . So, $ds = \sqrt{dx + dy +dz}$ . Then, $T = \int \frac{n(z)}{c} \sqrt{dx + dy + dz}$ What I want, in the end, is to have a formula such that I can plug in $[x_p,y_p,z_p]$ , $[x_r,y_r,z_r]$ , $n(z)$ , $c$ , and get $T$ . EDIT I've found a reference, here. Unfortunately, I don't quite follow everything. I recreate the argument here. I use the above example, where $n$ is a function of depth, $z$ . We simplify this to a problem in 2-dimensions. We know that the index of refraction, $n$ , at a point $z,x$ is equal to $c/v$ , where $v$ is the velocity of light at that point. We parameterize the path by equations $x = x(u)$ and $z = z(u)$ . The ""optical path length"" from a point $A$ to a point $B$ is then given by: $$L = \int_A^B n\;ds = \int_A^B n\;\sqrt{z^2 + x^2}\;du$$ I don't quite follow what is being done at this point. I know that we want to minimize $L$ ... I'm not sure, however, how this step achieves this. To make this integral an extremum, let $f$ denote the integrand function: $f(z,x,\dot{z},\dot{x}) = n(z,x)\sqrt{z^2+x^2}$ Then the Euler equations are: $$\frac{\partial n}{\partial z} = \frac{d}{du}\Bigg(\frac{\partial f}{\partial \dot{z}}\Bigg)$$ $$\frac{\partial n}{\partial x} = \frac{d}{du}\Bigg(\frac{\partial f}{\partial \dot{x}}\Bigg)$$ Which gives: $\frac{\partial n}{\partial z} \sqrt{\dot{z}^2 + \dot{x}^2} = \frac{d}{du} \Bigg[\ \frac{n\dot{z}}{\sqrt{\dot{z}^2 + \dot{x}^2}}\Bigg]$ $\frac{\partial n}{\partial x} \sqrt{\dot{z}^2 + \dot{x}^2} = \frac{d}{du} \Bigg[\ \frac{n\dot{x}}{\sqrt{\dot{z}^2 + \dot{x}^2}}\Bigg]$ If we define parameter $u$ as spatial path length $s$ , then $z^2 + x^2 = 1$ , and the above equations reduce to: $$\frac{\partial n}{\partial z} = \frac{d}{ds}\Bigg(n \frac{dz}{ds}\Bigg)$$ $$\frac{\partial n}{\partial x} = \frac{d}{ds}\Bigg(n \frac{dx}{ds}\Bigg)$$ I could be looking at this wrong, however this is my interperetation... So, since (in my example) $n$ is a function of $z$ , it occurs to me that we can drop the partial derivatives, and have: $$\frac{dn}{dz} = \frac{d}{ds}\Bigg(n \frac{dz}{ds}\Bigg)$$ Then: $$L = \frac{d}{ds} = \frac{\frac{dn}{dz}}{\Bigg(n \frac{dz}{ds}\Bigg)}$$ Suppose $n(z) = e^z$ , for example... $$L = \frac{e^z}{\Bigg(e^z \frac{dz}{ds}\Bigg)}$$ $\frac{dz}{ds}$ should be a differential equation, yes? Perhaps I'm being slow about this, but it isn't immediately clear to me how I'd then use starting and ending values for $x$ , $y$ , and $z$ to obtain an $L$ . As I recall, the derivative can't simply be ""flipped"" (i.e. this isn't $= \frac{ds}{dz}$ )... but maybe I'm wrong.","The index of refraction , , for some medium, is the speed of light in a vacuum divided by the speed of light in the medium ( ). Consider some light source , (at coordinates ), and some light receiver , (at coordinates ). Neglecting the effects of refraction, we might calculate the time of flight for a light signal, moving in a straight line from to , as: For a constant index of refraction, we simply replace by . How, however, might we calculate the time of flight for a light signal traveling in a ""straight line"" when the index of refraction varies as a function of some coordinate (say, depth ( ))? In this case, of course, light doesn't actually travel in a straight line, in the common sense. What I have so far... Note: This could be very wrong. It's just where I've gotten so far. Using the principle of least time (see), we have that: We have that . Thus, Suppose is a function of . Then, . Using , we have that: Now, by Pythagoras . So, . Then, What I want, in the end, is to have a formula such that I can plug in , , , , and get . EDIT I've found a reference, here. Unfortunately, I don't quite follow everything. I recreate the argument here. I use the above example, where is a function of depth, . We simplify this to a problem in 2-dimensions. We know that the index of refraction, , at a point is equal to , where is the velocity of light at that point. We parameterize the path by equations and . The ""optical path length"" from a point to a point is then given by: I don't quite follow what is being done at this point. I know that we want to minimize ... I'm not sure, however, how this step achieves this. To make this integral an extremum, let denote the integrand function: Then the Euler equations are: Which gives: If we define parameter as spatial path length , then , and the above equations reduce to: I could be looking at this wrong, however this is my interperetation... So, since (in my example) is a function of , it occurs to me that we can drop the partial derivatives, and have: Then: Suppose , for example... should be a differential equation, yes? Perhaps I'm being slow about this, but it isn't immediately clear to me how I'd then use starting and ending values for , , and to obtain an . As I recall, the derivative can't simply be ""flipped"" (i.e. this isn't )... but maybe I'm wrong.","n n = \frac{c}{v} p_s [x_p,y_p,z_p] p_r [x_r,y_r,z_r] p_s p_r T = \frac{1}{c} \cdot \sqrt{(x_p - x_r)^2 + (y_p - y_r)^2 + (z_p - z_r)^2 } c \frac{c}{n} z T = \int dt v = \frac{ds}{dt} T = \int \frac{ds}{v} n z n = n(z) v = \frac{c}{n(z)} T = \int \frac{n(z)}{c} ds ds^s = dx^2 + dy^2 + dz^2 ds = \sqrt{dx + dy +dz} T = \int \frac{n(z)}{c} \sqrt{dx + dy + dz} [x_p,y_p,z_p] [x_r,y_r,z_r] n(z) c T n z n z,x c/v v x = x(u) z = z(u) A B L = \int_A^B n\;ds = \int_A^B n\;\sqrt{z^2 + x^2}\;du L f f(z,x,\dot{z},\dot{x}) = n(z,x)\sqrt{z^2+x^2} \frac{\partial n}{\partial z} = \frac{d}{du}\Bigg(\frac{\partial f}{\partial \dot{z}}\Bigg) \frac{\partial n}{\partial x} = \frac{d}{du}\Bigg(\frac{\partial f}{\partial \dot{x}}\Bigg) \frac{\partial n}{\partial z} \sqrt{\dot{z}^2 + \dot{x}^2} = \frac{d}{du} \Bigg[\ \frac{n\dot{z}}{\sqrt{\dot{z}^2 + \dot{x}^2}}\Bigg] \frac{\partial n}{\partial x} \sqrt{\dot{z}^2 + \dot{x}^2} = \frac{d}{du} \Bigg[\ \frac{n\dot{x}}{\sqrt{\dot{z}^2 + \dot{x}^2}}\Bigg] u s z^2 + x^2 = 1 \frac{\partial n}{\partial z} = \frac{d}{ds}\Bigg(n \frac{dz}{ds}\Bigg) \frac{\partial n}{\partial x} = \frac{d}{ds}\Bigg(n \frac{dx}{ds}\Bigg) n z \frac{dn}{dz} = \frac{d}{ds}\Bigg(n \frac{dz}{ds}\Bigg) L = \frac{d}{ds} = \frac{\frac{dn}{dz}}{\Bigg(n \frac{dz}{ds}\Bigg)} n(z) = e^z L = \frac{e^z}{\Bigg(e^z \frac{dz}{ds}\Bigg)} \frac{dz}{ds} x y z L = \frac{ds}{dz}","['calculus', 'integration', 'physics', 'mathematical-physics', 'calculus-of-variations']"
40,"Volume of region $\{ (x_1,\ldots,x_n)\in \mathbf{R}^n_{>0} \mid \prod_{i=1}^n\max(1,x_i)\leqslant d \}$",Volume of region,"\{ (x_1,\ldots,x_n)\in \mathbf{R}^n_{>0} \mid \prod_{i=1}^n\max(1,x_i)\leqslant d \}","As part of a problem on algebraic number theory, I am faced with the following analysis/calculus exercise: Show that the volume of the set $$E_n:=\Big\{ (x_1,\ldots,x_n)\in \mathbf{R}^n_{>0} :\prod_{i=1}^n\max(1,x_i)\leqslant d \Big\}$$ is equal to $$d\sum_{i=0}^{n-1} \binom{n-1}{i} \frac{(\log d)^i}{i!}.$$ My attempt at solving this problem was as follows. Clearly, $E_n\subset [0,d]^n$ . The volume of $E_n$ equals the following integral (abbreviating $m$ for $\max$ ): $$\int_0^d \int_0^{\frac{d}{m(1,x_1)}}\cdots \int_0^{\frac{d}{m(1,x_1)\cdots m(1,x_{n-2})}} \int_0^{\frac{d}{m(1,x_1)\cdots m(1,x_{n-1})}} 1\, dx_n\,dx_{n-1}\cdots dx_2\,dx_1,$$ which can be simplified into $$d\int_0^d \frac{1}{m(1,x_{1})} \int_0^{\frac{d}{m(1,x_1)}}\frac{1}{m(1,x_{2})}\cdots \int_0^{\frac{d}{m(1,x_1)\cdots m(1,x_{n-2})}} \frac{1}{m(1,x_{n-1})}\,dx_{n-1}\cdots dx_2\,dx_1.$$ I tried to prove the formula by induction. By splitting the middle integral, it evaluates to $1+\log d-\sum_{i=1}^{n-2}\log m(1,x_i)$ . By linearity of the integral, we get $(1+\log d)E_{n-1}$ plus some other integral. However, this gets incredibly messy. Is my approach correct? Is there any more clever way to attack this integral or an other method to prove this formula ? Is there maybe a probabilistic way of calculating its value ? EDIT. In Theorem 6.5 of this article the integral is written as $\int_{y\in \mathbf{R}^n,\sum_i \max(0,y_i)\leq \delta} \exp \sum y_i\,dy$ . Are my integral and this one equal ? Any help is much appreciated. (For the bounty: I would like to have a comprehensive, detailed answer.)","As part of a problem on algebraic number theory, I am faced with the following analysis/calculus exercise: Show that the volume of the set is equal to My attempt at solving this problem was as follows. Clearly, . The volume of equals the following integral (abbreviating for ): which can be simplified into I tried to prove the formula by induction. By splitting the middle integral, it evaluates to . By linearity of the integral, we get plus some other integral. However, this gets incredibly messy. Is my approach correct? Is there any more clever way to attack this integral or an other method to prove this formula ? Is there maybe a probabilistic way of calculating its value ? EDIT. In Theorem 6.5 of this article the integral is written as . Are my integral and this one equal ? Any help is much appreciated. (For the bounty: I would like to have a comprehensive, detailed answer.)","E_n:=\Big\{ (x_1,\ldots,x_n)\in \mathbf{R}^n_{>0} :\prod_{i=1}^n\max(1,x_i)\leqslant d \Big\} d\sum_{i=0}^{n-1} \binom{n-1}{i} \frac{(\log d)^i}{i!}. E_n\subset [0,d]^n E_n m \max \int_0^d \int_0^{\frac{d}{m(1,x_1)}}\cdots \int_0^{\frac{d}{m(1,x_1)\cdots m(1,x_{n-2})}} \int_0^{\frac{d}{m(1,x_1)\cdots m(1,x_{n-1})}} 1\, dx_n\,dx_{n-1}\cdots dx_2\,dx_1, d\int_0^d \frac{1}{m(1,x_{1})} \int_0^{\frac{d}{m(1,x_1)}}\frac{1}{m(1,x_{2})}\cdots \int_0^{\frac{d}{m(1,x_1)\cdots m(1,x_{n-2})}} \frac{1}{m(1,x_{n-1})}\,dx_{n-1}\cdots dx_2\,dx_1. 1+\log d-\sum_{i=1}^{n-2}\log m(1,x_i) (1+\log d)E_{n-1} \int_{y\in \mathbf{R}^n,\sum_i \max(0,y_i)\leq \delta} \exp \sum y_i\,dy","['calculus', 'integration']"
41,"Prove: $\int_{0}^{\pi/2}{\sqrt{1 + \sqrt{1 + (\tan{x})^{2/3}}}\,dx} = \frac{\pi}{2} (3^{1/4} + 3^{3/4} - 2)$",Prove:,"\int_{0}^{\pi/2}{\sqrt{1 + \sqrt{1 + (\tan{x})^{2/3}}}\,dx} = \frac{\pi}{2} (3^{1/4} + 3^{3/4} - 2)","I'm trying to prove $$I := \int_{0}^{\pi/2}{\sqrt{1 + \sqrt{1 + (\tan{x})^{2/3}}}\,dx} = \frac{\pi}{2} (3^{1/4} + 3^{3/4} - 2)$$ which is around $2.5063328837$ . Using the $u$ -substitution $u = \sqrt{-1 + \sqrt{1 + (\tan{x})^{2/3}}}$ , we have \begin{align*} du &= \frac{1}{6}\frac{1}{\sqrt{1 + (\tan{x})^{2/3}}}\frac{1}{\sqrt{-1 + \sqrt{1 + (\tan{x})^{2/3}}}} (\tan{x})^{-1/3} \sec^2{x}\,dx \\ &= \frac{1}{6 u (u^2 + 1)} \frac{1}{\sqrt{(u^2 + 1)^2 - 1}} \left(((u^2 + 1)^2 - 1)^3 + 1\right) \,dx \\ &= \frac{1}{6 u^2 (u^2 + 1)} \frac{1}{\sqrt{u^2 + 2}} \left(u^6 (u^2 + 2)^3 + 1\right) \,dx \end{align*} and thus, $$I = \int_{0}^{\pi/2}{\sqrt{1 + \sqrt{1 + (\tan{x})^{2/3}}}\,dx} = 6 \int_{0}^{\infty}{\frac{u^2 (u^2 + 1) (u^2 + 2)}{u^6 (u^2 + 2)^3 + 1} \,du}$$ So we have the integral of a rational function, where the roots of the denominator can easily be found in closed form; hence using the method of residues, we can get an answer in closed form. Yet, I've done this and it's still not so obvious that the answer miraculously simplifies to $\frac{\pi}{2} (3^{1/4} + 3^{3/4} - 2)$ . My question is, seeing that the answer is so nice, is there a more clever way to solve this integral? I've tried different substitutions, integration by parts, the Feynman trick by putting a parameter in place of the exponent $2/3$ , etc., but they all seem to go nowhere. Thanks!","I'm trying to prove which is around . Using the -substitution , we have and thus, So we have the integral of a rational function, where the roots of the denominator can easily be found in closed form; hence using the method of residues, we can get an answer in closed form. Yet, I've done this and it's still not so obvious that the answer miraculously simplifies to . My question is, seeing that the answer is so nice, is there a more clever way to solve this integral? I've tried different substitutions, integration by parts, the Feynman trick by putting a parameter in place of the exponent , etc., but they all seem to go nowhere. Thanks!","I := \int_{0}^{\pi/2}{\sqrt{1 + \sqrt{1 + (\tan{x})^{2/3}}}\,dx} = \frac{\pi}{2} (3^{1/4} + 3^{3/4} - 2) 2.5063328837 u u = \sqrt{-1 + \sqrt{1 + (\tan{x})^{2/3}}} \begin{align*}
du
&= \frac{1}{6}\frac{1}{\sqrt{1 + (\tan{x})^{2/3}}}\frac{1}{\sqrt{-1 + \sqrt{1 + (\tan{x})^{2/3}}}} (\tan{x})^{-1/3} \sec^2{x}\,dx \\
&= \frac{1}{6 u (u^2 + 1)} \frac{1}{\sqrt{(u^2 + 1)^2 - 1}} \left(((u^2 + 1)^2 - 1)^3 + 1\right) \,dx \\
&= \frac{1}{6 u^2 (u^2 + 1)} \frac{1}{\sqrt{u^2 + 2}} \left(u^6 (u^2 + 2)^3 + 1\right) \,dx
\end{align*} I = \int_{0}^{\pi/2}{\sqrt{1 + \sqrt{1 + (\tan{x})^{2/3}}}\,dx} = 6 \int_{0}^{\infty}{\frac{u^2 (u^2 + 1) (u^2 + 2)}{u^6 (u^2 + 2)^3 + 1} \,du} \frac{\pi}{2} (3^{1/4} + 3^{3/4} - 2) 2/3","['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
42,"Solve $\int_0^1\ln^2\Gamma(x)\,\mathrm{d}x$",Solve,"\int_0^1\ln^2\Gamma(x)\,\mathrm{d}x","I want to solve the following integral but after some work I didn't find a way to go. Could anyone give me a hint? \begin{equation} I=\int_{0}^{1}\ln^2\Gamma(x)\,\mathrm{d}x \end{equation} The answer is \begin{equation} I=\frac{\ln^2 (2\pi)}{3}+\frac{\pi^2}{48}+\frac{\gamma\ln(2\pi)}{6}+\frac{\gamma^2}{12}+\frac{\zeta''(2)}{2\pi^2}-\frac{\zeta'(2)\ln (2\pi)}{\pi^2}-\frac{\gamma\zeta'(2)}{\pi^2} \end{equation} They only give a hint (using the Fourier Series) which I looked up at https://de.wikipedia.org/wiki/Gammafunktion . \begin{equation} \ln\Gamma(x) = \left(\tfrac{1}{2}-x\right) \bigl(\gamma + \ln(2\pi)\bigr) + \frac{1}{2} \ln\frac{\pi}{\sin(\pi x)} + \frac{1}{\pi} \sum_{k=2}^\infty \frac{\ln k}{k} \sin(2\pi k x) \end{equation} Want I have tried so far: squared the series integration by parts and the the fourier series",I want to solve the following integral but after some work I didn't find a way to go. Could anyone give me a hint? The answer is They only give a hint (using the Fourier Series) which I looked up at https://de.wikipedia.org/wiki/Gammafunktion . Want I have tried so far: squared the series integration by parts and the the fourier series,"\begin{equation}
I=\int_{0}^{1}\ln^2\Gamma(x)\,\mathrm{d}x
\end{equation} \begin{equation}
I=\frac{\ln^2 (2\pi)}{3}+\frac{\pi^2}{48}+\frac{\gamma\ln(2\pi)}{6}+\frac{\gamma^2}{12}+\frac{\zeta''(2)}{2\pi^2}-\frac{\zeta'(2)\ln (2\pi)}{\pi^2}-\frac{\gamma\zeta'(2)}{\pi^2}
\end{equation} \begin{equation}
\ln\Gamma(x) = \left(\tfrac{1}{2}-x\right) \bigl(\gamma + \ln(2\pi)\bigr) + \frac{1}{2} \ln\frac{\pi}{\sin(\pi x)} + \frac{1}{\pi} \sum_{k=2}^\infty \frac{\ln k}{k} \sin(2\pi k x)
\end{equation}","['calculus', 'integration', 'definite-integrals']"
43,Closed Form for $\sum\limits_{n=-2a}^\infty(n+a){2a\choose-n}^4$,Closed Form for,\sum\limits_{n=-2a}^\infty(n+a){2a\choose-n}^4,"Do either $~S_4^+(a)~=~\displaystyle\sum_{n=0}^\infty(n+a){2a\choose n}^4~$ or $~S_4^-(a)~=~\displaystyle\sum_{n=-2a}^\infty(n+a){2a\choose-n}^4~$ possess a meaningful closed form expression in terms of the general parameter a ? Ramanujan provided the following result : $~S_4^-\Big(-\tfrac18\Big)~=~\dfrac1{\bigg[\Big(-\tfrac14\Big){\large!}\bigg]^2~\sqrt{8\pi}}~,~$ which would point to a possible closed form expression in terms of $~(2a)!~$ and/or $~(4a)!~$ For lesser values of the exponent, we have Dixon's identity : $$\sum_{n=0}^\infty(-1)^n{2a\choose n}^3 ~=~ \sum_{n=-2a}^\infty(-1)^n{2a\choose-n}^3 ~=~ \cos(a\pi)~{3a\choose a,a},$$ and Vandermonde's identity : $$\sum_{n=0}^\infty(-1)^n{2a\choose n}^2 ~=~ \sum_{n=-2a}^\infty(-1)^n{2a\choose-n}^2 ~=~ \cos(a\pi)~{2a\choose a},$$ $$\sum_{n=0}^\infty{a\choose n}^2 ~=~ \sum_{n=-a}^\infty{a\choose-n}^2 ~=~ {2a\choose a},$$ as well as the binomial theorem : $$\sum_{n=0}^\infty{a\choose n}^1x^n ~=~ (1+x)^a,\qquad\sum_{n=-a}^\infty{a\choose-n}^1x^n ~=~ \Big(1+\tfrac1x\Big)^a.$$","Do either or possess a meaningful closed form expression in terms of the general parameter a ? Ramanujan provided the following result : which would point to a possible closed form expression in terms of and/or For lesser values of the exponent, we have Dixon's identity : and Vandermonde's identity : as well as the binomial theorem :","~S_4^+(a)~=~\displaystyle\sum_{n=0}^\infty(n+a){2a\choose n}^4~ ~S_4^-(a)~=~\displaystyle\sum_{n=-2a}^\infty(n+a){2a\choose-n}^4~ ~S_4^-\Big(-\tfrac18\Big)~=~\dfrac1{\bigg[\Big(-\tfrac14\Big){\large!}\bigg]^2~\sqrt{8\pi}}~,~ ~(2a)!~ ~(4a)!~ \sum_{n=0}^\infty(-1)^n{2a\choose n}^3 ~=~ \sum_{n=-2a}^\infty(-1)^n{2a\choose-n}^3 ~=~ \cos(a\pi)~{3a\choose a,a}, \sum_{n=0}^\infty(-1)^n{2a\choose n}^2 ~=~ \sum_{n=-2a}^\infty(-1)^n{2a\choose-n}^2 ~=~ \cos(a\pi)~{2a\choose a}, \sum_{n=0}^\infty{a\choose n}^2 ~=~ \sum_{n=-a}^\infty{a\choose-n}^2 ~=~ {2a\choose a}, \sum_{n=0}^\infty{a\choose n}^1x^n ~=~ (1+x)^a,\qquad\sum_{n=-a}^\infty{a\choose-n}^1x^n ~=~ \Big(1+\tfrac1x\Big)^a.","['calculus', 'sequences-and-series', 'combinatorics', 'closed-form']"
44,The integral is not iterated integral. Will this fact prevent us from swapping the order of surface and volume integrals? Why? Why not?,The integral is not iterated integral. Will this fact prevent us from swapping the order of surface and volume integrals? Why? Why not?,,"Consider a continuous charge distribution in volume $V'$ . Draw a closed surface $S$ inside the volume $V'$ . Consider the following multiple integral: $$B= \iint_S       \Biggl(     \iiint_{V'}   \left[  \dfrac{\cos(\hat{R},\hat{n})}{R^2}   \rho'\   \right] dV' \Biggl)  dS$$ where $R=|\mathbf{r}-\mathbf{r'}|$ $\mathbf{r'}=(x',y',z')$ is coordinates of source points $\mathbf{r}=(x,y,z)$ is coordinates of field points $\cos(\hat{R},\hat{n})$ is the angle between $R$ and normal to surface element $\rho'$ is the charge density and is continuous throughout the volume $V'$ Since $\mathbf{r} \in S$ , the function is not integrable in domain $V'$ . So we use change of variables: $$B= \iint_S        \Biggl(    \iiint_{V'}   \left[  \dfrac{\cos(\hat{R},\hat{n})}{R^2}   \rho'\ {r'}^2 \sin \theta' \right] d\theta' d\phi' dr'  \Biggr) dS$$ $\bbox[yellow]{\text{Note that in this equation, $\theta'$ and $\phi'$ are w.r.t point $\mathbf{r} \in S $}}$ The inner volume integral is an iterated integral. While computing this iterated integral in spherical coordinates (here $\mathbf{r'}$ varies and $\mathbf{r}$ is constant), we take the origin of our spherical coordinate at point $\mathbf{r} \in S$ . That is, $\mathbf{r}=(0,0,0)$ Therefore after computing this iterated integral, i.e. after applying the limits, we will not be getting a function of $(r,\theta,\phi)$ or $(x,y,z)$ . Instead we will be getting a number. This means we cannot carry out the surface integral by iterated integrals. Will this fact prevent us from swapping the order of surface and volume integrals? Why? Why not? If swapping the order of surface and volume integrals is valid: \begin{align} B &= \iiint_{V'}        \Biggl(    \iint_S   \left[  \dfrac{\cos(\hat{R},\hat{n})}{R^2}   \rho'\ {r'}^2 \sin \theta' \right] dS   \Biggr) d\theta' d\phi' dr'\\   &= \iiint_{V'}        \Biggl(    \iint_S   \left[  \dfrac{\cos(\hat{R},\hat{n})}{R^2}    \right] dS   \Biggr) \rho'\ {r'}^2 \sin \theta' d\theta' d\phi' dr'\\ \end{align} $\bbox[yellow]{\text{Here in this last equation, $\theta'$ and $\phi'$ are w.r.t. which point?}}$ Special note for the answerer This question may or may not be related to Fubini's theorem. If it is, please give the complete statement of Fubini's theorem and please show step-by-step how my question can be explained by Fubini's theorem. Please consider that I am a graduating student of Mathematics and I am learning real analysis (single and multivariable). Please try to explain within the scope of real analysis.","Consider a continuous charge distribution in volume . Draw a closed surface inside the volume . Consider the following multiple integral: where is coordinates of source points is coordinates of field points is the angle between and normal to surface element is the charge density and is continuous throughout the volume Since , the function is not integrable in domain . So we use change of variables: The inner volume integral is an iterated integral. While computing this iterated integral in spherical coordinates (here varies and is constant), we take the origin of our spherical coordinate at point . That is, Therefore after computing this iterated integral, i.e. after applying the limits, we will not be getting a function of or . Instead we will be getting a number. This means we cannot carry out the surface integral by iterated integrals. Will this fact prevent us from swapping the order of surface and volume integrals? Why? Why not? If swapping the order of surface and volume integrals is valid: Special note for the answerer This question may or may not be related to Fubini's theorem. If it is, please give the complete statement of Fubini's theorem and please show step-by-step how my question can be explained by Fubini's theorem. Please consider that I am a graduating student of Mathematics and I am learning real analysis (single and multivariable). Please try to explain within the scope of real analysis.","V' S V' B= \iint_S       \Biggl(     \iiint_{V'}   \left[  \dfrac{\cos(\hat{R},\hat{n})}{R^2}   \rho'\   \right] dV' \Biggl)  dS R=|\mathbf{r}-\mathbf{r'}| \mathbf{r'}=(x',y',z') \mathbf{r}=(x,y,z) \cos(\hat{R},\hat{n}) R \rho' V' \mathbf{r} \in S V' B= \iint_S        \Biggl(    \iiint_{V'}   \left[  \dfrac{\cos(\hat{R},\hat{n})}{R^2}   \rho'\ {r'}^2 \sin \theta' \right] d\theta' d\phi' dr'  \Biggr) dS \bbox[yellow]{\text{Note that in this equation, \theta' and \phi' are w.r.t point \mathbf{r} \in S }} \mathbf{r'} \mathbf{r} \mathbf{r} \in S \mathbf{r}=(0,0,0) (r,\theta,\phi) (x,y,z) \begin{align}
B &= \iiint_{V'}        \Biggl(    \iint_S   \left[  \dfrac{\cos(\hat{R},\hat{n})}{R^2}   \rho'\ {r'}^2 \sin \theta' \right] dS   \Biggr) d\theta' d\phi' dr'\\
  &= \iiint_{V'}        \Biggl(    \iint_S   \left[  \dfrac{\cos(\hat{R},\hat{n})}{R^2}    \right] dS   \Biggr) \rho'\ {r'}^2 \sin \theta' d\theta' d\phi' dr'\\
\end{align} \bbox[yellow]{\text{Here in this last equation, \theta' and \phi' are w.r.t. which point?}}","['calculus', 'multivariable-calculus', 'spherical-coordinates', 'multiple-integral', 'potential-theory']"
45,Similarity between $e^x$ power series and Gamma function integral?,Similarity between  power series and Gamma function integral?,e^x,"The power series for $e^x$ is as follows. $$e^{x} =\sum ^{\infty }_{n=0}\frac{x^{n}}{n!}$$ If we define $n! = \Gamma(n+1)$ , then we have $$n!=\int ^{\infty }_{0} x^{n} e^{-x} dx.$$ An extremely surface level observation is that if we compare the summand/integrand of each equation to their corresponding left-hand-sides, we end up with the following correspondences. $$e^x \longleftrightarrow \frac{x^n}{n!} \hspace{2 in} n! \longleftrightarrow \frac{x^n}{e^x}$$ Very naïvely, one could make the observation that the correspondence on the left looks like an algebraic manipulation of the correspondence on the right (multiply both sides by $n!$ and divide by $e^x$ ). Is this merely coincidence or is there some deeper connection here?","The power series for is as follows. If we define , then we have An extremely surface level observation is that if we compare the summand/integrand of each equation to their corresponding left-hand-sides, we end up with the following correspondences. Very naïvely, one could make the observation that the correspondence on the left looks like an algebraic manipulation of the correspondence on the right (multiply both sides by and divide by ). Is this merely coincidence or is there some deeper connection here?",e^x e^{x} =\sum ^{\infty }_{n=0}\frac{x^{n}}{n!} n! = \Gamma(n+1) n!=\int ^{\infty }_{0} x^{n} e^{-x} dx. e^x \longleftrightarrow \frac{x^n}{n!} \hspace{2 in} n! \longleftrightarrow \frac{x^n}{e^x} n! e^x,"['calculus', 'exponential-function', 'improper-integrals', 'factorial', 'gamma-function']"
46,"If $f(x)<g(x)$, can $\int_a^b f(x)\,dx = \int_a^b g(x)\,dx$?","If , can ?","f(x)<g(x) \int_a^b f(x)\,dx = \int_a^b g(x)\,dx","I couldn't find anything on the internet to clear this up to me. If $f(x)<g(x)$ on an interval $[a, b]$, does that imply $\int_a^b f(x)\,dx \leq \int_a^b g(x)\,dx$ or strictly $\int_a^b f(x)\,dx < \int_a^b g(x)\,dx$. I encountered this problem while trying to prove the latter using the Riemann definition of integration, $$\int_a^b f(x)\,dx = \lim_{n\to\infty} \left(\sum_{i=1}^n f(x_i)\,\Delta x\right)$$ So if $f(x) < g(x)$ for all $x$ in $[a, b]$ and that $x_i \in [a,b]$, $$f(x_i) < g(x_i)$$ $$f(x_i)\,\Delta x < g(x_i)\,\Delta x$$ $$\sum_{i=1}^n f(x_i)\,\Delta x< \sum_{i=1}^n g(x_i)\,\Delta x$$ This is where my confusion is. I know that if $f(x)<g(x)$ on $[a, \infty]$, then $\lim_{x\to a} f(x) \leq \lim_{x\to a} g(x)$, as in the limits could still be equal. That, I can understand. By applying $\lim_{x\to\infty}$ to both Riemann sums, this implies that $\int_a^b f(x)\,dx \leq \int_a^b g(x)\,dx$. This seems to suggest that the integrals could be equal. But I can't seem to wrap my head, intuitively, why this is the case. Is there an example of two functions with strict inequalities but equal integrals. Or, if it's the case that the integrals CAN'T equal each other, is there a more clear proof of it? Thanks.","I couldn't find anything on the internet to clear this up to me. If $f(x)<g(x)$ on an interval $[a, b]$, does that imply $\int_a^b f(x)\,dx \leq \int_a^b g(x)\,dx$ or strictly $\int_a^b f(x)\,dx < \int_a^b g(x)\,dx$. I encountered this problem while trying to prove the latter using the Riemann definition of integration, $$\int_a^b f(x)\,dx = \lim_{n\to\infty} \left(\sum_{i=1}^n f(x_i)\,\Delta x\right)$$ So if $f(x) < g(x)$ for all $x$ in $[a, b]$ and that $x_i \in [a,b]$, $$f(x_i) < g(x_i)$$ $$f(x_i)\,\Delta x < g(x_i)\,\Delta x$$ $$\sum_{i=1}^n f(x_i)\,\Delta x< \sum_{i=1}^n g(x_i)\,\Delta x$$ This is where my confusion is. I know that if $f(x)<g(x)$ on $[a, \infty]$, then $\lim_{x\to a} f(x) \leq \lim_{x\to a} g(x)$, as in the limits could still be equal. That, I can understand. By applying $\lim_{x\to\infty}$ to both Riemann sums, this implies that $\int_a^b f(x)\,dx \leq \int_a^b g(x)\,dx$. This seems to suggest that the integrals could be equal. But I can't seem to wrap my head, intuitively, why this is the case. Is there an example of two functions with strict inequalities but equal integrals. Or, if it's the case that the integrals CAN'T equal each other, is there a more clear proof of it? Thanks.",,"['calculus', 'integration', 'inequality']"
47,Closed form solution for this integral?,Closed form solution for this integral?,,"I'm hitting a road block in finding an expression (closed form preferably) for the following integral: \begin{equation} \int^{+\infty}_0 x^b \left ( 1-\frac{x}{u} \right )^c \exp(-a x^3) dx \end{equation} where $a,b$ are positive constants; $b>1$ is an odd multiple of $0.5$ , while $c$ is a positive or negative odd multiple of $0.5$ ; $u$ is a (positive) parameter. Things I have considered or tried: look up in tables (Gradshsteyn and Ryzhik): there are very few explicit results for integrals involving $\exp(-a x^3)$ (or for the other factors after transforming via $y=x^3$ ). Also, tabulated results involving $\exp(-a x^p)$ for more general $p$ do not include the other factors $x^b (1-x/u)^c$ . One exception is (3.478.3): \begin{equation} \int^{u}_0 x^b (u-x)^c \exp(-a x^3) dx,  \end{equation} but the limits of integration do not match with my case; there is a closed form solution (3.478.1) for the simpler integral \begin{equation} \int^{+\infty}_0 x^{d-1} \exp(-a x^3) dx = \frac{a^{-d/3}}{3} \Gamma(d/3). \end{equation} (NB: there is also an expression for the indefinite integral.) A binomial expansion of $[1-(x/u)]^n$ for integer $n$ would produce a solution in series form. However, in my case, the exponents $b$ and $c$ are strictly half-integer. For the same reason, integration by parts does not lead to a simpler integral without the factor $[1-(x/u)]^c$ ; Wolfram Math online did not produce a result; the integral is an intermediate step in a longer analysis, so numerical solution (with given values for the parameter) is not practical. Grateful for any pointers or solution.","I'm hitting a road block in finding an expression (closed form preferably) for the following integral: where are positive constants; is an odd multiple of , while is a positive or negative odd multiple of ; is a (positive) parameter. Things I have considered or tried: look up in tables (Gradshsteyn and Ryzhik): there are very few explicit results for integrals involving (or for the other factors after transforming via ). Also, tabulated results involving for more general do not include the other factors . One exception is (3.478.3): but the limits of integration do not match with my case; there is a closed form solution (3.478.1) for the simpler integral (NB: there is also an expression for the indefinite integral.) A binomial expansion of for integer would produce a solution in series form. However, in my case, the exponents and are strictly half-integer. For the same reason, integration by parts does not lead to a simpler integral without the factor ; Wolfram Math online did not produce a result; the integral is an intermediate step in a longer analysis, so numerical solution (with given values for the parameter) is not practical. Grateful for any pointers or solution.","\begin{equation}
\int^{+\infty}_0 x^b \left ( 1-\frac{x}{u} \right )^c \exp(-a x^3) dx
\end{equation} a,b b>1 0.5 c 0.5 u \exp(-a x^3) y=x^3 \exp(-a x^p) p x^b (1-x/u)^c \begin{equation}
\int^{u}_0 x^b (u-x)^c \exp(-a x^3) dx, 
\end{equation} \begin{equation}
\int^{+\infty}_0 x^{d-1} \exp(-a x^3) dx = \frac{a^{-d/3}}{3} \Gamma(d/3).
\end{equation} [1-(x/u)]^n n b c [1-(x/u)]^c","['calculus', 'integration']"
48,Which part of the train stays for the longest time in the station?,Which part of the train stays for the longest time in the station?,,"A train with length $L$ is moving towards a train station of length $S$ with speed $v$. The train starts to decelerate with acceleration $-a$ as soon as head reaches the station until completely stops. Right after the train completely stops, it starts to accelerate with acceleration $a$ until its tail leaves the station with speed $v$. Which part of the train stays for the longest time in the station? The correct answer is the mid-part of the train. If the head stays in the station for $t$ and the mid-part of the train stays for $\sqrt{2}t$. Could anyone give me some clue on how to get this?","A train with length $L$ is moving towards a train station of length $S$ with speed $v$. The train starts to decelerate with acceleration $-a$ as soon as head reaches the station until completely stops. Right after the train completely stops, it starts to accelerate with acceleration $a$ until its tail leaves the station with speed $v$. Which part of the train stays for the longest time in the station? The correct answer is the mid-part of the train. If the head stays in the station for $t$ and the mid-part of the train stays for $\sqrt{2}t$. Could anyone give me some clue on how to get this?",,"['calculus', 'algebra-precalculus', 'physics']"
49,Is $x^j+x^k+2$ irreducible whenever $j+k$ is odd?,Is  irreducible whenever  is odd?,x^j+x^k+2 j+k,"Let $j,k$ be positive integers with $j>k$ and consider the polynomial $$f(x)=x^j+x^k+2$$ I want to prove the conjecture : $f(x)$ is irreducible in $\mathbb Q[x]$, whenever $j+k$ is odd. This is true for $j\le 300$ as I checked with PARI/GP. If $f$ has real roots, they obviously must be negative and the absolute value of any root must be less than $2$ for $j>2$. Moreover, $-1$ cannot be a root because of $f(-1)=2$, so $f(x)$ never can have a linear factor. Can we use the bound of the absolute values of the roots and that the constant coefficient is prime to show that $f(x)$ must be irreducible in $\mathbb Q[x]$","Let $j,k$ be positive integers with $j>k$ and consider the polynomial $$f(x)=x^j+x^k+2$$ I want to prove the conjecture : $f(x)$ is irreducible in $\mathbb Q[x]$, whenever $j+k$ is odd. This is true for $j\le 300$ as I checked with PARI/GP. If $f$ has real roots, they obviously must be negative and the absolute value of any root must be less than $2$ for $j>2$. Moreover, $-1$ cannot be a root because of $f(-1)=2$, so $f(x)$ never can have a linear factor. Can we use the bound of the absolute values of the roots and that the constant coefficient is prime to show that $f(x)$ must be irreducible in $\mathbb Q[x]$",,"['calculus', 'roots', 'irreducible-polynomials']"
50,Complex derivative vs. Multivariate derivative,Complex derivative vs. Multivariate derivative,,"I'd like to compare and contrast the derivative across different areas of mathematics just to organize ideas in my head. In this question, $f(x,y)$ means $f: \mathbb{R}^2 \to \mathbb{R}$ and $f(z)$ means $f: \mathbb{C}\to\mathbb{C}$ Limits In multivariate calculus ($f(x,y)$), in order to find the limit of $f(x,y)$ as $(x,y) \rightarrow (x_0,y_0)$, you need to approach $(x_0, y_0)$ from all possible directions in the $xy$ plane. Likewise in complex analysis, in order to find the limit of $f(z)$ as $z \rightarrow z_0$, you need to approach $z_0$ along every path and check the limit. Derivatives In multivariate calculus, you usually talk about a derivative along a single direction. For instance, the partial derivative with respect to $x$ is given by $$\frac{\partial f}{\partial x} = \lim_{h\to\ 0} \frac{f(x+h,y) - f(x,y)}{h}$$ This is the derivative parallel to the x-axis. You can generalize this to a derivative along any straight line direction. It's called a directional derivative. You can further generalize this to the derivative along any arbitrary path (not just straight lines) in your domain. However the two are sort of the same because at any one point on the arbitrary path, the derivative you compute there is a directional derivative at that instant of the path. Anyways, the point is to show that derivatives are taken with respect to directions. For complex-valued functions of a complex variable, the derivative is $$\frac{df(z)}{dz} = \lim_{h\to\ 0} \frac{f(z+h) - f(z)}{h}$$ with the understanding that h is a complex number that approaches $0$ along any path in the complex plane. So the derivative must be checked along every path and every path has to yield the same value of the limit in order for the derivative to exist. Question Why isn't there such notion of a derivative for multivariate functions $f(x,y)$? The domain of a function $f(z)$ is the complex plane. It's a plane. The domain of a function $f(x,y)$ is the $xy$ plane. Also a plane. Why can't I ask for the derivative of $f(x,y)$ at a point P where I check all possible paths as $(x,y) \rightarrow P$ just as I did for the derivative of $f(z)$? Why must I always take the derivative in a specific direction? Likewise, why can't you ask for the derivative of $f(z)$ in a certain direction at $z$? My thoughts Although a complex variable can take values in a complex plane, it's still a '1 dimensional number.' $z = x + iy$ is usually said to be a '2 dimensional number', but this is from the perspective of real numbers (1D) and generalizing to complex numbers (2D). However if I move the starting point in my brain to complex numbers, then a complex number is just a 1D number. Complex numbers live on a plane, but the plane should be thought of as 1D. Therefore just as checking the derivative of a single variable function $f(x)$ as $h$ goes to $0$ on 'all possible paths' is normal, checking the derivative of $f(z)$ as $h$ goes to $0$ on 'all possible paths' is normal because there aren't any paths (the plane is 1D). I can't ask for the $f'(z)$ along a particular direction because there is 'no direction' just as there is really no direction for a 1D real number line. However, I'm still confused why you can't ask for $f'(x,y)$ without specifying a direction. $f'(x,y)$ is always given with respect to a direction.","I'd like to compare and contrast the derivative across different areas of mathematics just to organize ideas in my head. In this question, $f(x,y)$ means $f: \mathbb{R}^2 \to \mathbb{R}$ and $f(z)$ means $f: \mathbb{C}\to\mathbb{C}$ Limits In multivariate calculus ($f(x,y)$), in order to find the limit of $f(x,y)$ as $(x,y) \rightarrow (x_0,y_0)$, you need to approach $(x_0, y_0)$ from all possible directions in the $xy$ plane. Likewise in complex analysis, in order to find the limit of $f(z)$ as $z \rightarrow z_0$, you need to approach $z_0$ along every path and check the limit. Derivatives In multivariate calculus, you usually talk about a derivative along a single direction. For instance, the partial derivative with respect to $x$ is given by $$\frac{\partial f}{\partial x} = \lim_{h\to\ 0} \frac{f(x+h,y) - f(x,y)}{h}$$ This is the derivative parallel to the x-axis. You can generalize this to a derivative along any straight line direction. It's called a directional derivative. You can further generalize this to the derivative along any arbitrary path (not just straight lines) in your domain. However the two are sort of the same because at any one point on the arbitrary path, the derivative you compute there is a directional derivative at that instant of the path. Anyways, the point is to show that derivatives are taken with respect to directions. For complex-valued functions of a complex variable, the derivative is $$\frac{df(z)}{dz} = \lim_{h\to\ 0} \frac{f(z+h) - f(z)}{h}$$ with the understanding that h is a complex number that approaches $0$ along any path in the complex plane. So the derivative must be checked along every path and every path has to yield the same value of the limit in order for the derivative to exist. Question Why isn't there such notion of a derivative for multivariate functions $f(x,y)$? The domain of a function $f(z)$ is the complex plane. It's a plane. The domain of a function $f(x,y)$ is the $xy$ plane. Also a plane. Why can't I ask for the derivative of $f(x,y)$ at a point P where I check all possible paths as $(x,y) \rightarrow P$ just as I did for the derivative of $f(z)$? Why must I always take the derivative in a specific direction? Likewise, why can't you ask for the derivative of $f(z)$ in a certain direction at $z$? My thoughts Although a complex variable can take values in a complex plane, it's still a '1 dimensional number.' $z = x + iy$ is usually said to be a '2 dimensional number', but this is from the perspective of real numbers (1D) and generalizing to complex numbers (2D). However if I move the starting point in my brain to complex numbers, then a complex number is just a 1D number. Complex numbers live on a plane, but the plane should be thought of as 1D. Therefore just as checking the derivative of a single variable function $f(x)$ as $h$ goes to $0$ on 'all possible paths' is normal, checking the derivative of $f(z)$ as $h$ goes to $0$ on 'all possible paths' is normal because there aren't any paths (the plane is 1D). I can't ask for the $f'(z)$ along a particular direction because there is 'no direction' just as there is really no direction for a 1D real number line. However, I'm still confused why you can't ask for $f'(x,y)$ without specifying a direction. $f'(x,y)$ is always given with respect to a direction.",,"['calculus', 'complex-analysis', 'multivariable-calculus']"
51,"Prove: $\forall x \gt 1, \arctan(\frac{1+x}{1-x}) = \arctan(x) - \frac{3\pi}{4}$",Prove:,"\forall x \gt 1, \arctan(\frac{1+x}{1-x}) = \arctan(x) - \frac{3\pi}{4}","What I did is find the derivative of $\arctan\left(\frac{1+x}{1-x}\right)$: $$\frac{d\left[\arctan\left(\frac{1+x}{1-x}\right)\right]}{dx} = \frac{1}{1+x^2}$$ We can notice that that is the derivative of $arctan(x)$ as well. So we can state the following: $$\int\frac{d\left[\arctan\left(\frac{1+x}{1-x}\right)\right]}{dx}\cdot dx = \int\frac{d\arctan(x)}{dx}\cdot dx  $$ Now this is where I'm starting to have hesitations: We want to prove the equality $\forall x \gt 1 $, so what I think I should do is take those integrals from 1 to x. Indeed that works: $$\int_1^x\frac{d\left[\arctan\left(\frac{1+x}{1-x}\right)\right]}{dx}\cdot dx = \int_1^x\frac{d\arctan(x)}{dx}\cdot dx   $$ If we simplify, we'll arrive to the desired equation. There are two problems with the above integral: at $x = 1, \arctan\left(\frac{1+x}{1-x}\right)$ is not defined. However, $$\lim_{x\to1^+}\arctan\left(\frac{1+x}{1-x}\right) = -\frac{\pi}{2}$$ Since we're not interested in x = 1, am I right in thinking that if the following equation is the correct formulation of the problem? $$\lim_{h\to1^+}\left[\int_h^x\frac{d\left[\arctan\left(\frac{1+x}{1-x}\right)\right]}{dx}\cdot dx\right] = \lim_{h\to1^+}\left[\int_h^x\frac{d\arctan(x)}{dx}\cdot dx \right]$$ The other problem is that I don't think that the fact that two functions have equal area under their curve means they're necessarily equal to each other for all x. However if I prove that they are equal at a point $x_0$, and then prove that they are also equal at $x_0+\epsilon$, where $\epsilon\to0^+$, then I prove that they are equal for all x greater than $x_0$ Is my reasoning corret? EDIT : I noticed that I made a rather big copying mistake. Everywhere where I wrote $$\int\arctan\left(\frac{1+x}{1-x}\right)\cdot dx $$ I actually meant: $$\int\frac{d\left[\arctan\left(\frac{1+x}{1-x}\right)\right]}{dx}\cdot dx $$ Which does indeed change the meaning of my equations by A LOT","What I did is find the derivative of $\arctan\left(\frac{1+x}{1-x}\right)$: $$\frac{d\left[\arctan\left(\frac{1+x}{1-x}\right)\right]}{dx} = \frac{1}{1+x^2}$$ We can notice that that is the derivative of $arctan(x)$ as well. So we can state the following: $$\int\frac{d\left[\arctan\left(\frac{1+x}{1-x}\right)\right]}{dx}\cdot dx = \int\frac{d\arctan(x)}{dx}\cdot dx  $$ Now this is where I'm starting to have hesitations: We want to prove the equality $\forall x \gt 1 $, so what I think I should do is take those integrals from 1 to x. Indeed that works: $$\int_1^x\frac{d\left[\arctan\left(\frac{1+x}{1-x}\right)\right]}{dx}\cdot dx = \int_1^x\frac{d\arctan(x)}{dx}\cdot dx   $$ If we simplify, we'll arrive to the desired equation. There are two problems with the above integral: at $x = 1, \arctan\left(\frac{1+x}{1-x}\right)$ is not defined. However, $$\lim_{x\to1^+}\arctan\left(\frac{1+x}{1-x}\right) = -\frac{\pi}{2}$$ Since we're not interested in x = 1, am I right in thinking that if the following equation is the correct formulation of the problem? $$\lim_{h\to1^+}\left[\int_h^x\frac{d\left[\arctan\left(\frac{1+x}{1-x}\right)\right]}{dx}\cdot dx\right] = \lim_{h\to1^+}\left[\int_h^x\frac{d\arctan(x)}{dx}\cdot dx \right]$$ The other problem is that I don't think that the fact that two functions have equal area under their curve means they're necessarily equal to each other for all x. However if I prove that they are equal at a point $x_0$, and then prove that they are also equal at $x_0+\epsilon$, where $\epsilon\to0^+$, then I prove that they are equal for all x greater than $x_0$ Is my reasoning corret? EDIT : I noticed that I made a rather big copying mistake. Everywhere where I wrote $$\int\arctan\left(\frac{1+x}{1-x}\right)\cdot dx $$ I actually meant: $$\int\frac{d\left[\arctan\left(\frac{1+x}{1-x}\right)\right]}{dx}\cdot dx $$ Which does indeed change the meaning of my equations by A LOT",,"['calculus', 'trigonometry']"
52,Find all functions $f$ satisgying the $3$ definite integrals,Find all functions  satisgying the  definite integrals,f 3,"Let $a \in [0,1].$ Find all functions $f:[0,1] \to [0,\infty)$ such that $$\int_{0}^{1}f(x)dx=1$$$$\int_{0}^{1}xf(x)dx=a$$ and $$\int_{0}^{1}x^2f(x)dx=a^2$$ I am having problems on how to start. Please give some hints. Thanks.","Let $a \in [0,1].$ Find all functions $f:[0,1] \to [0,\infty)$ such that $$\int_{0}^{1}f(x)dx=1$$$$\int_{0}^{1}xf(x)dx=a$$ and $$\int_{0}^{1}x^2f(x)dx=a^2$$ I am having problems on how to start. Please give some hints. Thanks.",,['calculus']
53,Integral inequality :$\int_0^1(f'(x))^2dx\geq 32\int_0^1(f(x))^2dx + 16\left(\int_0^{\frac{1}{2}}f(x)dx-\int_{\frac{1}{2}}^1f(x)dx\right)^2$,Integral inequality :,\int_0^1(f'(x))^2dx\geq 32\int_0^1(f(x))^2dx + 16\left(\int_0^{\frac{1}{2}}f(x)dx-\int_{\frac{1}{2}}^1f(x)dx\right)^2,"Assume $f:[0,1]\to \mathbb{R}$ is differentiable and $f'$ is integrable. Given $f\left(\frac{1}{4}\right)=f\left(\frac{3}{4}\right)=f(1)-f(0)=0$, then prove that $$\int_0^1(f'(x))^2dx\geq 32\int_0^1(f(x))^2dx + 16\left(\int_0^{\frac{1}{2}}f(x)dx-\int_{\frac{1}{2}}^1f(x)dx\right)^2$$ My attempt: I tried to make the most out of the given information. Consider the integrals $$I_1=\int_0^{\frac{1}{4}}\left(x-\frac{1}{8}\right)f'(x)dx=\frac{f(0)}{8} - \int_0^{\frac{1}{4}}f(x)dx$$ $$I_2=\int_{\frac{1}{4}}^{\frac{1}{2}}\left(x-\frac{3}{8}\right)f'(x)dx=\frac{f\left(\frac{1}{2}\right)}{8} - \int_{\frac{1}{4}}^{\frac{1}{2}}f(x)dx$$ $$I_3=\int_{\frac{1}{2}}^{\frac{3}{4}}\left(x-\frac{5}{8}\right)f'(x)dx=\frac{f\left(\frac{1}{2}\right)}{8} - \int_{\frac{1}{2}}^{\frac{3}{4}}f(x)dx$$ $$I_4=\int_{\frac{3}{4}}^{1}\left(x-\frac{7}{8}\right)f'(x)dx=\frac{f\left(1\right)}{8} - \int_{\frac{3}{4}}^{1}f(x)dx$$ Notice that $$I_1+I_2-I_3-I_4=-\left(\int_0^{\frac{1}{2}}f(x)dx-\int_{\frac{1}{2}}^1f(x)dx\right)$$ Hence $$\left|\int_0^{\frac{1}{2}}f(x)dx-\int_{\frac{1}{2}}^1f(x)dx\right|^2\leq \left(I_1+I_2-I_3-I_4\right)^2\leq 4\left(|I_1|^2+|I_2|^2+|I_3|^2+|I_4|^2\right)$$ Using C-S inequality, we get $$\left|I_k\right|^2\leq \frac{1}{2^8\times 3}\int_{\frac{k}{4}}^{\frac{k+1}{4}}(f'(x))^2dx ,\quad k\in \{0,1,2,3\}$$ Hence $$\left(\int_0^{\frac{1}{2}}f(x)dx-\int_{\frac{1}{2}}^1f(x)dx\right)^2\leq \frac{4}{2^8\times 3}\int_0^1(f'(x))^2dx$$ Upto this seems fine , but i am having trouble estimating the second term i.e $\int_0^1(f(x))^2dx$. I tried considering integrals like $\int_0^{\frac{1}{4}}xf'(x)f(x)dx,\quad \int_{\frac{1}{4}}^{\frac{1}{2}}\left(x-\frac{1}{2}\right)f'(x)f(x)dx$ etc, but they are not giving satisfactory results. Please see if i can improve this or is there some other approach.","Assume $f:[0,1]\to \mathbb{R}$ is differentiable and $f'$ is integrable. Given $f\left(\frac{1}{4}\right)=f\left(\frac{3}{4}\right)=f(1)-f(0)=0$, then prove that $$\int_0^1(f'(x))^2dx\geq 32\int_0^1(f(x))^2dx + 16\left(\int_0^{\frac{1}{2}}f(x)dx-\int_{\frac{1}{2}}^1f(x)dx\right)^2$$ My attempt: I tried to make the most out of the given information. Consider the integrals $$I_1=\int_0^{\frac{1}{4}}\left(x-\frac{1}{8}\right)f'(x)dx=\frac{f(0)}{8} - \int_0^{\frac{1}{4}}f(x)dx$$ $$I_2=\int_{\frac{1}{4}}^{\frac{1}{2}}\left(x-\frac{3}{8}\right)f'(x)dx=\frac{f\left(\frac{1}{2}\right)}{8} - \int_{\frac{1}{4}}^{\frac{1}{2}}f(x)dx$$ $$I_3=\int_{\frac{1}{2}}^{\frac{3}{4}}\left(x-\frac{5}{8}\right)f'(x)dx=\frac{f\left(\frac{1}{2}\right)}{8} - \int_{\frac{1}{2}}^{\frac{3}{4}}f(x)dx$$ $$I_4=\int_{\frac{3}{4}}^{1}\left(x-\frac{7}{8}\right)f'(x)dx=\frac{f\left(1\right)}{8} - \int_{\frac{3}{4}}^{1}f(x)dx$$ Notice that $$I_1+I_2-I_3-I_4=-\left(\int_0^{\frac{1}{2}}f(x)dx-\int_{\frac{1}{2}}^1f(x)dx\right)$$ Hence $$\left|\int_0^{\frac{1}{2}}f(x)dx-\int_{\frac{1}{2}}^1f(x)dx\right|^2\leq \left(I_1+I_2-I_3-I_4\right)^2\leq 4\left(|I_1|^2+|I_2|^2+|I_3|^2+|I_4|^2\right)$$ Using C-S inequality, we get $$\left|I_k\right|^2\leq \frac{1}{2^8\times 3}\int_{\frac{k}{4}}^{\frac{k+1}{4}}(f'(x))^2dx ,\quad k\in \{0,1,2,3\}$$ Hence $$\left(\int_0^{\frac{1}{2}}f(x)dx-\int_{\frac{1}{2}}^1f(x)dx\right)^2\leq \frac{4}{2^8\times 3}\int_0^1(f'(x))^2dx$$ Upto this seems fine , but i am having trouble estimating the second term i.e $\int_0^1(f(x))^2dx$. I tried considering integrals like $\int_0^{\frac{1}{4}}xf'(x)f(x)dx,\quad \int_{\frac{1}{4}}^{\frac{1}{2}}\left(x-\frac{1}{2}\right)f'(x)f(x)dx$ etc, but they are not giving satisfactory results. Please see if i can improve this or is there some other approach.",,"['calculus', 'integration', 'integral-inequality']"
54,$ \int_0^\infty \ \frac{(x\cdot\cos x - \sin x)^3}{x^6} \ dx$,, \int_0^\infty \ \frac{(x\cdot\cos x - \sin x)^3}{x^6} \ dx,"What is the value of $$ \int_0^\infty \ \frac{(x\cdot\cos x - \sin x)^3}{x^6} \ dx $$ I have no idea how to start with this integral, any hint?","What is the value of $$ \int_0^\infty \ \frac{(x\cdot\cos x - \sin x)^3}{x^6} \ dx $$ I have no idea how to start with this integral, any hint?",,"['calculus', 'integration', 'analysis']"
55,Laplace transforms of powers of cosine (solved!),Laplace transforms of powers of cosine (solved!),,"During the past several hours, while studying the Laplace transform, I've started wondering what \begin{equation} \mathcal{L} \{ \cos^n(at)\}(s) \end{equation} would look like – since it won't appear on your typical transform table. After some thinking and tedious pattern-finding and rearranging (and typing on Wolfram Alpha), I've come up with the following (interesting, yet messy) two formulae: (1) For odd $n$'s ($n=2k+1, k \in \mathbb{N}$), \begin{equation} \mathcal{L}\{\cos^{2k+1} (at)\}(s) = \frac{1}{2^{2k}}\sum_{j=0}^{k} \frac{\binom{2k+1}{k-j}s}{ (2j+1)^2 a^2 + s^2} \tag{1} \end{equation} (2) For even $n$'s ($n=2k, k \in \mathbb{N}$), \begin{equation} \mathcal{L}\{\cos^{2k} (at)\}(s) = \frac{\binom{2k}{k}}{2^{2k}s} +  \frac{1}{2^{2k-1}}\sum_{j=1}^{k} \frac{\binom{2k}{k-j}s}{(2j)^2 a^2 + s^2} \tag{2} \end{equation} So, First of all, are these statements even correct? If they are, how can I prove it using the definition of the transform? I already have a few ideas in my mind, which involve the exponential definition of cosine, ""complexifying"" the Laplace integral (but isn't $s$ already complex?), applying the inverse Laplace transform on each of the series terms, or heck, maybe even the Maclaurin expansion of cosine or some trig identities... it'd be lovely to read some suggestion from you all! I'm also looking at merging the two formulae into a single one that works for every $n$, but the major obstacle seems to be the $ \frac{\binom{2k}{k}}{2^{2k}s} $ term in the even-$n$ formula: where does its weird binomial coefficient come from (1/2 of what the sum's general binomial coefficient would predict)? A similar approach has been tried for $ \sin^n (at) $, with similar results — messy sums which only work for one or the other parity of $n$. How do the two relate to each other, and possibly to the (albeit trivial) transform of $\exp^n{(at)}=\exp{n(at)}$? And how about $ \sinh^n (at) $ and $ \cosh^n (at) $? Thanks in advance, hope this has provided some interesting input EDIT. Following Alex R.'s suggestion, I've tried using \begin{equation} \cos^n (at) = \frac{\left(e^{iat} + e^{-iat}\right)^n}{2^n} \end{equation} The Laplace transform then becomes: \begin{equation} \mathcal{L}\{\cos^{n} (at)\}(s) = \int_{0}^{\infty}2^{-n}\left(e^{iat} + e^{-iat}\right)^n e^{-st} dt \\ = 2^{-n} \int_{0}^{\infty} \sum_{j=0}^{n} \binom{n}{j} e^{(iat)j} e^{(-iat)(n-j)} e^{-st} dt \\ = 2^{-n} \sum_{j=0}^{n} \binom{n}{j} \int_{0}^{\infty} e^{-\big(s+ia(2j-n)\big)t} dt \\ = 2^{-n} \sum_{j=0}^{n} \binom{n}{j} \frac{1}{-\big(s+ia(2j-n)\big)} \left[\lim_{\beta \to \infty} e^{-\big(s+ia(2j-n)\big)\beta} - e^{-\big(s+ia(2j-n)\big)(0)}\right] \end{equation} \begin{equation} = 2^{-n} \sum_{j=0}^{n} \binom{n}{j} \frac{[-1]}{-\big(s+ia(2j-n)\big)} = 2^{-n} \sum_{j=0}^{n} \binom{n}{j} \frac{1}{s+ia(2j-n)} \tag{3} \end{equation} I'm not very satisfied with what I've got — not even sure it's right. And besides that, I can't figure out how it connects with the two formulae given above. Please let me know what you think EDIT 2. We could actually check the result in $(3)$ by the use of the Fourier-Mellin integral below: \begin{equation} f(t)=\mathcal{L}^{-1}\{\hat{f}(s)\} = \frac{1}{2\pi i}\int_{\gamma-i\infty}^{\gamma+i\infty} e^{st} \hat{f}(s) ds \end{equation} where $\gamma \in \mathbb R$ is greater than the real part of all singularities of $\hat{f}(s)$. Applying this formula to the sum in $(3)$, we get \begin{equation} \begin{split} f(t) &= \frac{2^{-n}}{2\pi i} \int_{\gamma-i\infty}^{\gamma+i\infty} e^{st} \sum_{j=0}^{n} \binom{n}{j} \frac{1}{s+ia(n-2j)} ds \\ &= \frac{2^{-n}}{2\pi i} \sum_{j=0}^{n} \binom{n}{j} \int_{\gamma-i\infty}^{\gamma+i\infty} \frac{e^{st}}{s+ia(n-2j)}ds \end{split} \end{equation} All the poles of our sum-defined $\hat{f}(s)$ lie on the imaginary axis, so we can choose any $\gamma > 0 $. Let us now consider the integral alone. We may now close the contour with a semicircle lying on the left side of the plane and call it $\Gamma$. \begin{equation} \newcommand{\Res}{\mathop{\text{Res}}} \oint_\Gamma \frac{e^{st}}{s+ia(n-2j)}ds = 2\pi i \lim_{s\to -ia(n-2j)} e^{st} = 2\pi i e^{-ia(n-2j)t} \tag{4} \end{equation} which can be demonstrated to be equal to the integral over the line $\gamma+iq, \quad -\infty < q <\infty$. We can plug $(4)$ into our formula for $f(t)$ \begin{equation} f(t) = \frac{2^{-n}}{2\pi i} \sum_{j=0}^{n} \binom{n}{j} (2\pi i e^{-ia(n-2j)t}) = 2^n \sum_{j=0}^{n} \binom{n}{j} e^{-(n-j)(iat)}e^{j(iat)} \end{equation} which of course we recognize as being the binomial expansion of \begin{equation} f(t) = \left(\frac{e^{iat} + e^{-iat}}{2}\right)^n = \cos^n(at) \end{equation} I will soon try to prove $(1)$ and $(2)$ by the same means. FINAL EDIT. I just had to expand the result in $(3)$ to obtain \begin{equation} \bbox[5px,border:2px solid red]{ \mathcal{L} \{ \cos^n(at)\}(s) = \frac{1}{2^n}\sum_{j=0}^{n} \binom{n}{j} \frac{s+(n-2j)a}{s^2+(n-2j)^2a^2}} \tag{5} \end{equation} (a big duhhh on my behalf!) We can try out $(5)$ with even or odd $n$'s and it will work, connecting beautifully to the formulae in $(1)$ and $(2)$. The painful asymmetry in $(2)$ can now be explained: it was actually caused by the fact that, if $n=2k$ and $k$ is integer, then the $n$th row in Pascal's triangle contains an odd number of terms – of which $\binom{2k}{k}$ is the central one. Since $\binom{n}{q} = \binom{n}{n-q}$, every other term besides that middle one were appearing twice in the sum, and so they could be reduced to $2\binom{n}{q}$. The asymmetry in $(2)$ was just concealing the underlying symmetry expressed in $(5)$. Finding an expression for the Laplace transform of the powers of sine was trickier, but possible: \begin{equation} \mathcal{L} \{ \sin^n(at)\}(s) = \frac{1}{2^n}\sum_{j=0}^{n} \binom{n}{j} (-1)^{j+\lfloor\frac{n}{2}\rfloor} \frac{s+(n-2j)a}{s^2+(n-2j)^2a^2} \tag{6} \end{equation} It works in a similar fashion for the hyperbolic functions: \begin{equation} \mathcal{L} \{ \cosh^n(at)\}(s) = \frac{1}{2^n}\sum_{j=0}^{n} \binom{n}{j} \frac{s+(n-2j)a}{s^2-(n-2j)^2a^2} \tag{7} \end{equation} \begin{equation} \mathcal{L} \{ \sinh^n(at)\}(s) = \frac{1}{2^n}\sum_{j=0}^{n} \binom{n}{j} (-1)^j \frac{s+(n-2j)a}{s^2-(n-2j)^2a^2} \tag{8} \end{equation}","During the past several hours, while studying the Laplace transform, I've started wondering what \begin{equation} \mathcal{L} \{ \cos^n(at)\}(s) \end{equation} would look like – since it won't appear on your typical transform table. After some thinking and tedious pattern-finding and rearranging (and typing on Wolfram Alpha), I've come up with the following (interesting, yet messy) two formulae: (1) For odd $n$'s ($n=2k+1, k \in \mathbb{N}$), \begin{equation} \mathcal{L}\{\cos^{2k+1} (at)\}(s) = \frac{1}{2^{2k}}\sum_{j=0}^{k} \frac{\binom{2k+1}{k-j}s}{ (2j+1)^2 a^2 + s^2} \tag{1} \end{equation} (2) For even $n$'s ($n=2k, k \in \mathbb{N}$), \begin{equation} \mathcal{L}\{\cos^{2k} (at)\}(s) = \frac{\binom{2k}{k}}{2^{2k}s} +  \frac{1}{2^{2k-1}}\sum_{j=1}^{k} \frac{\binom{2k}{k-j}s}{(2j)^2 a^2 + s^2} \tag{2} \end{equation} So, First of all, are these statements even correct? If they are, how can I prove it using the definition of the transform? I already have a few ideas in my mind, which involve the exponential definition of cosine, ""complexifying"" the Laplace integral (but isn't $s$ already complex?), applying the inverse Laplace transform on each of the series terms, or heck, maybe even the Maclaurin expansion of cosine or some trig identities... it'd be lovely to read some suggestion from you all! I'm also looking at merging the two formulae into a single one that works for every $n$, but the major obstacle seems to be the $ \frac{\binom{2k}{k}}{2^{2k}s} $ term in the even-$n$ formula: where does its weird binomial coefficient come from (1/2 of what the sum's general binomial coefficient would predict)? A similar approach has been tried for $ \sin^n (at) $, with similar results — messy sums which only work for one or the other parity of $n$. How do the two relate to each other, and possibly to the (albeit trivial) transform of $\exp^n{(at)}=\exp{n(at)}$? And how about $ \sinh^n (at) $ and $ \cosh^n (at) $? Thanks in advance, hope this has provided some interesting input EDIT. Following Alex R.'s suggestion, I've tried using \begin{equation} \cos^n (at) = \frac{\left(e^{iat} + e^{-iat}\right)^n}{2^n} \end{equation} The Laplace transform then becomes: \begin{equation} \mathcal{L}\{\cos^{n} (at)\}(s) = \int_{0}^{\infty}2^{-n}\left(e^{iat} + e^{-iat}\right)^n e^{-st} dt \\ = 2^{-n} \int_{0}^{\infty} \sum_{j=0}^{n} \binom{n}{j} e^{(iat)j} e^{(-iat)(n-j)} e^{-st} dt \\ = 2^{-n} \sum_{j=0}^{n} \binom{n}{j} \int_{0}^{\infty} e^{-\big(s+ia(2j-n)\big)t} dt \\ = 2^{-n} \sum_{j=0}^{n} \binom{n}{j} \frac{1}{-\big(s+ia(2j-n)\big)} \left[\lim_{\beta \to \infty} e^{-\big(s+ia(2j-n)\big)\beta} - e^{-\big(s+ia(2j-n)\big)(0)}\right] \end{equation} \begin{equation} = 2^{-n} \sum_{j=0}^{n} \binom{n}{j} \frac{[-1]}{-\big(s+ia(2j-n)\big)} = 2^{-n} \sum_{j=0}^{n} \binom{n}{j} \frac{1}{s+ia(2j-n)} \tag{3} \end{equation} I'm not very satisfied with what I've got — not even sure it's right. And besides that, I can't figure out how it connects with the two formulae given above. Please let me know what you think EDIT 2. We could actually check the result in $(3)$ by the use of the Fourier-Mellin integral below: \begin{equation} f(t)=\mathcal{L}^{-1}\{\hat{f}(s)\} = \frac{1}{2\pi i}\int_{\gamma-i\infty}^{\gamma+i\infty} e^{st} \hat{f}(s) ds \end{equation} where $\gamma \in \mathbb R$ is greater than the real part of all singularities of $\hat{f}(s)$. Applying this formula to the sum in $(3)$, we get \begin{equation} \begin{split} f(t) &= \frac{2^{-n}}{2\pi i} \int_{\gamma-i\infty}^{\gamma+i\infty} e^{st} \sum_{j=0}^{n} \binom{n}{j} \frac{1}{s+ia(n-2j)} ds \\ &= \frac{2^{-n}}{2\pi i} \sum_{j=0}^{n} \binom{n}{j} \int_{\gamma-i\infty}^{\gamma+i\infty} \frac{e^{st}}{s+ia(n-2j)}ds \end{split} \end{equation} All the poles of our sum-defined $\hat{f}(s)$ lie on the imaginary axis, so we can choose any $\gamma > 0 $. Let us now consider the integral alone. We may now close the contour with a semicircle lying on the left side of the plane and call it $\Gamma$. \begin{equation} \newcommand{\Res}{\mathop{\text{Res}}} \oint_\Gamma \frac{e^{st}}{s+ia(n-2j)}ds = 2\pi i \lim_{s\to -ia(n-2j)} e^{st} = 2\pi i e^{-ia(n-2j)t} \tag{4} \end{equation} which can be demonstrated to be equal to the integral over the line $\gamma+iq, \quad -\infty < q <\infty$. We can plug $(4)$ into our formula for $f(t)$ \begin{equation} f(t) = \frac{2^{-n}}{2\pi i} \sum_{j=0}^{n} \binom{n}{j} (2\pi i e^{-ia(n-2j)t}) = 2^n \sum_{j=0}^{n} \binom{n}{j} e^{-(n-j)(iat)}e^{j(iat)} \end{equation} which of course we recognize as being the binomial expansion of \begin{equation} f(t) = \left(\frac{e^{iat} + e^{-iat}}{2}\right)^n = \cos^n(at) \end{equation} I will soon try to prove $(1)$ and $(2)$ by the same means. FINAL EDIT. I just had to expand the result in $(3)$ to obtain \begin{equation} \bbox[5px,border:2px solid red]{ \mathcal{L} \{ \cos^n(at)\}(s) = \frac{1}{2^n}\sum_{j=0}^{n} \binom{n}{j} \frac{s+(n-2j)a}{s^2+(n-2j)^2a^2}} \tag{5} \end{equation} (a big duhhh on my behalf!) We can try out $(5)$ with even or odd $n$'s and it will work, connecting beautifully to the formulae in $(1)$ and $(2)$. The painful asymmetry in $(2)$ can now be explained: it was actually caused by the fact that, if $n=2k$ and $k$ is integer, then the $n$th row in Pascal's triangle contains an odd number of terms – of which $\binom{2k}{k}$ is the central one. Since $\binom{n}{q} = \binom{n}{n-q}$, every other term besides that middle one were appearing twice in the sum, and so they could be reduced to $2\binom{n}{q}$. The asymmetry in $(2)$ was just concealing the underlying symmetry expressed in $(5)$. Finding an expression for the Laplace transform of the powers of sine was trickier, but possible: \begin{equation} \mathcal{L} \{ \sin^n(at)\}(s) = \frac{1}{2^n}\sum_{j=0}^{n} \binom{n}{j} (-1)^{j+\lfloor\frac{n}{2}\rfloor} \frac{s+(n-2j)a}{s^2+(n-2j)^2a^2} \tag{6} \end{equation} It works in a similar fashion for the hyperbolic functions: \begin{equation} \mathcal{L} \{ \cosh^n(at)\}(s) = \frac{1}{2^n}\sum_{j=0}^{n} \binom{n}{j} \frac{s+(n-2j)a}{s^2-(n-2j)^2a^2} \tag{7} \end{equation} \begin{equation} \mathcal{L} \{ \sinh^n(at)\}(s) = \frac{1}{2^n}\sum_{j=0}^{n} \binom{n}{j} (-1)^j \frac{s+(n-2j)a}{s^2-(n-2j)^2a^2} \tag{8} \end{equation}",,"['calculus', 'complex-analysis', 'analysis', 'laplace-transform']"
56,"Construct a continuous function $f$ over $[0,1]$ satisfying $f(0) = f(1)$ but $f(x) \neq f(x+a)$",Construct a continuous function  over  satisfying  but,"f [0,1] f(0) = f(1) f(x) \neq f(x+a)","Suppose $0 < a < 1$ is not of the form $\dfrac{1}{n}$ for positive integer $n$. Construct a continuous function $f$ over $[0,1]$ satisfying $f(0) = f(1)$ but $f(x) \neq f(x+a)$ for all $x \in [0,1-a]$. This is a follow up question to this . I am wondering how it is possible to construct such a function. I would start by saying $g(x) = f(x)-f(x+a) \neq 0$ for all $x$ in the domain and then doing casework on the values of $g(x)$. But this unlike the last question doesn't have a nice casework for the values of $g(x)$ so I am stuck.","Suppose $0 < a < 1$ is not of the form $\dfrac{1}{n}$ for positive integer $n$. Construct a continuous function $f$ over $[0,1]$ satisfying $f(0) = f(1)$ but $f(x) \neq f(x+a)$ for all $x \in [0,1-a]$. This is a follow up question to this . I am wondering how it is possible to construct such a function. I would start by saying $g(x) = f(x)-f(x+a) \neq 0$ for all $x$ in the domain and then doing casework on the values of $g(x)$. But this unlike the last question doesn't have a nice casework for the values of $g(x)$ so I am stuck.",,['calculus']
57,A limit related to super-root (tetration inverse).,A limit related to super-root (tetration inverse).,,"Recall that tetration ${^n}x$ for $n\in\mathbb N$ is defined recursively: ${^1}x=x,\,{^{n+1}}x=x^{({^n}x)}$. Its inverse function with respect to $x$ is called super-root and denoted $\sqrt[n]y_s$ (the index $_s$ is not a variable, but is part of the notation — it stands for ""super""). For $y>1, \sqrt[n]y_s=x$, where $x$ is the unique solution of ${^n}x=y$ satisfying $x>1$. It is known that $\lim\limits_{n\to\infty}\sqrt[n]2_s=\sqrt{2}$. We are interested in the convergence speed. It appears that the following limit exists and is positive: $$\mathcal L=\lim\limits_{n\to\infty}\frac{\sqrt[n]2_s-\sqrt2}{(\ln2)^n}\tag1$$ Numerically, $$\mathcal L\approx0.06857565981132910397655331141550655423...\tag2$$ Can we prove that the limit $(1)$ exists and is positive? Can we prove that the digits given in $(2)$ are correct? Can we find a closed form for $\mathcal L$ or at least a series or integral representation for it?","Recall that tetration ${^n}x$ for $n\in\mathbb N$ is defined recursively: ${^1}x=x,\,{^{n+1}}x=x^{({^n}x)}$. Its inverse function with respect to $x$ is called super-root and denoted $\sqrt[n]y_s$ (the index $_s$ is not a variable, but is part of the notation — it stands for ""super""). For $y>1, \sqrt[n]y_s=x$, where $x$ is the unique solution of ${^n}x=y$ satisfying $x>1$. It is known that $\lim\limits_{n\to\infty}\sqrt[n]2_s=\sqrt{2}$. We are interested in the convergence speed. It appears that the following limit exists and is positive: $$\mathcal L=\lim\limits_{n\to\infty}\frac{\sqrt[n]2_s-\sqrt2}{(\ln2)^n}\tag1$$ Numerically, $$\mathcal L\approx0.06857565981132910397655331141550655423...\tag2$$ Can we prove that the limit $(1)$ exists and is positive? Can we prove that the digits given in $(2)$ are correct? Can we find a closed form for $\mathcal L$ or at least a series or integral representation for it?",,"['calculus', 'limits', 'convergence-divergence', 'closed-form', 'tetration']"
58,"Is there a simple sufficient condition for a function to depend ""only on $r$""?","Is there a simple sufficient condition for a function to depend ""only on ""?",r,"Suppose I were to pose the following problem to a class of calculus students: What is the magnitude of $\nabla f(x,y)$, where $f : \mathbb{R}^2 \to \mathbb{R}$ is the paraboloid function   $$ f(x,y) = x^2 + y^2? $$ If a student produced the incorrect answer $$ |\nabla f(x,y)| = 2x + y,$$ I might say: No, you can tell that can't possibly be right, since it treats $x$ and $y$ on unequal footing. Think geometrically--the paraboloid has radial symmetry about the origin, so your solution should depend only on $r = \sqrt{x^2 + y^2}$. This notion of ""a function depending only on a certain function of its variables"" raises the following question: when does a function $f(x,y)$ depend only on $r = \sqrt{x^2 + y^2}$, or on $|x-y|$, or on some other function $g(x,y)$ of its inputs? More generally, given a function $f: \mathbb{R}^n \to \mathbb{R}$,  is there a simple sufficient condition for $f$ to ""depend only on $g: \mathbb{R}^n \to \mathbb{R}$,"" that is, for there to exist a function $u: \mathbb{R} \to \mathbb{R}$ such that $f = u \circ g$? Here I am thinking of something like the Wirtinger derivatives $\partial / \partial z$ and $\partial / \partial \overline{z}$ in complex analysis, which provide simple tests for dependence only on $z$ or $\overline{z}$, (i.e., (anti)holomorphicity).","Suppose I were to pose the following problem to a class of calculus students: What is the magnitude of $\nabla f(x,y)$, where $f : \mathbb{R}^2 \to \mathbb{R}$ is the paraboloid function   $$ f(x,y) = x^2 + y^2? $$ If a student produced the incorrect answer $$ |\nabla f(x,y)| = 2x + y,$$ I might say: No, you can tell that can't possibly be right, since it treats $x$ and $y$ on unequal footing. Think geometrically--the paraboloid has radial symmetry about the origin, so your solution should depend only on $r = \sqrt{x^2 + y^2}$. This notion of ""a function depending only on a certain function of its variables"" raises the following question: when does a function $f(x,y)$ depend only on $r = \sqrt{x^2 + y^2}$, or on $|x-y|$, or on some other function $g(x,y)$ of its inputs? More generally, given a function $f: \mathbb{R}^n \to \mathbb{R}$,  is there a simple sufficient condition for $f$ to ""depend only on $g: \mathbb{R}^n \to \mathbb{R}$,"" that is, for there to exist a function $u: \mathbb{R} \to \mathbb{R}$ such that $f = u \circ g$? Here I am thinking of something like the Wirtinger derivatives $\partial / \partial z$ and $\partial / \partial \overline{z}$ in complex analysis, which provide simple tests for dependence only on $z$ or $\overline{z}$, (i.e., (anti)holomorphicity).",,"['calculus', 'functions']"
59,Find the derivative of a triple integral function,Find the derivative of a triple integral function,,"The function $f(x)$ is differentiable. And I need to find the derivative of the triple integral function:  $$F(t)=\iiint_V \ f(\ xyz \ ) \ dxdydz \ , \ \ and \ V=\{(x,y,z)|0\leq x\leq t,\ 0\leq y\leq t,\ 0\leq z\leq t,   \ 0\leq t \}$$ I try to let $x=ut,\ y=vt,\ z=wt $ Then the function is $$ F(t)=\iiint_V \ f(\ uvwt^3\ ) \ t^3dudvdw$$ But I don't know how to do it after that.","The function $f(x)$ is differentiable. And I need to find the derivative of the triple integral function:  $$F(t)=\iiint_V \ f(\ xyz \ ) \ dxdydz \ , \ \ and \ V=\{(x,y,z)|0\leq x\leq t,\ 0\leq y\leq t,\ 0\leq z\leq t,   \ 0\leq t \}$$ I try to let $x=ut,\ y=vt,\ z=wt $ Then the function is $$ F(t)=\iiint_V \ f(\ uvwt^3\ ) \ t^3dudvdw$$ But I don't know how to do it after that.",,['calculus']
60,How to find the value of this integral?,How to find the value of this integral?,,"This integral to the value \begin{align} \int_0^1\frac{\ln^2(1+x)\ln^2 x}{1-x}\ dx=&\ \color{blue}{-\frac{13\pi^2}{24}\zeta(3)+\frac{47}{2}\zeta(5)-\frac15\ln^52+\frac{\pi^2}9\ln^32-\frac{49\pi^4}{360}\ln2+\frac{7}2\zeta(3)\ln^22}\\&\color{blue}{-8\operatorname{Li}_4\left(\frac12\right)\ln2-16\operatorname{Li}_5\left(\frac12\right)}, \end{align}    How to find this result?    In fact,I find that $$\int_0^1\frac{\ln(1+x)\ln{x}}{1-x}dx=\zeta(3)-\frac{\pi^2}{4}\ln2$$    $$\int_0^1\frac{\ln^2(1+x)\ln{x}}{1-x}dx=\frac{21}{4}\zeta(3)\ln{2}-\frac{5\pi^2}{12}\ln^2{2}+\frac{1}{6}\ln^4{2}-\frac{7\pi^4}{144}+4\operatorname{Li}_4\left(\frac12\right)$$","This integral to the value \begin{align} \int_0^1\frac{\ln^2(1+x)\ln^2 x}{1-x}\ dx=&\ \color{blue}{-\frac{13\pi^2}{24}\zeta(3)+\frac{47}{2}\zeta(5)-\frac15\ln^52+\frac{\pi^2}9\ln^32-\frac{49\pi^4}{360}\ln2+\frac{7}2\zeta(3)\ln^22}\\&\color{blue}{-8\operatorname{Li}_4\left(\frac12\right)\ln2-16\operatorname{Li}_5\left(\frac12\right)}, \end{align}    How to find this result?    In fact,I find that $$\int_0^1\frac{\ln(1+x)\ln{x}}{1-x}dx=\zeta(3)-\frac{\pi^2}{4}\ln2$$    $$\int_0^1\frac{\ln^2(1+x)\ln{x}}{1-x}dx=\frac{21}{4}\zeta(3)\ln{2}-\frac{5\pi^2}{12}\ln^2{2}+\frac{1}{6}\ln^4{2}-\frac{7\pi^4}{144}+4\operatorname{Li}_4\left(\frac12\right)$$",,"['calculus', 'definite-integrals', 'improper-integrals', 'polylogarithm']"
61,Does $\sum_{n=1}^{\infty}\ln(n\sin(\frac{1}{n}))$ converge? [duplicate],Does  converge? [duplicate],\sum_{n=1}^{\infty}\ln(n\sin(\frac{1}{n})),"This question already has answers here : Prove that $ \sum_{n=1}^\infty \ln\big(n\sin \frac{1}{n}\big)$ converges. (3 answers) Closed 4 years ago . I must determine whether the following series converges: $$\sum_{n=1}^{\infty}\ln\left(n\sin\left(\frac{1}{n}\right)\right)$$ I know that in general, I must use the limit comparison test, but I cannot find an expression to which I can compare it. For instance, I have tried the usual process: For $n$ large, we have that $\lim_{n\to \infty}n\sin\frac1n=1$, and so, $\ln(1)=0$. This fails the divergence test, but it cannot be concluded automatically that the series is convergent either. How may I proceed here? Any help would be appreciated.","This question already has answers here : Prove that $ \sum_{n=1}^\infty \ln\big(n\sin \frac{1}{n}\big)$ converges. (3 answers) Closed 4 years ago . I must determine whether the following series converges: $$\sum_{n=1}^{\infty}\ln\left(n\sin\left(\frac{1}{n}\right)\right)$$ I know that in general, I must use the limit comparison test, but I cannot find an expression to which I can compare it. For instance, I have tried the usual process: For $n$ large, we have that $\lim_{n\to \infty}n\sin\frac1n=1$, and so, $\ln(1)=0$. This fails the divergence test, but it cannot be concluded automatically that the series is convergent either. How may I proceed here? Any help would be appreciated.",,['calculus']
62,How to compute the limit $\lim_{n \to \infty} (1 + 2^n + 3^n +4^n+5^n)^{1/n}$?,How to compute the limit ?,\lim_{n \to \infty} (1 + 2^n + 3^n +4^n+5^n)^{1/n},How to compute the limit $\lim_{n \to \infty} (1 + 2^n + 3^n +4^n+5^n)^{1/n}$? My partial solution: $(1 + 2^n + 3^n +4^n+5^n)^{1/n} \leq (5 \times 5^n)^{1/n}$. Therefore $\lim_{n \to \infty} (1 + 2^n + 3^n +4^n+5^n)^{1/n} \leq \lim_{n \to \infty} 5^{(n+1)/n} = 5$. Thank you very much.,How to compute the limit $\lim_{n \to \infty} (1 + 2^n + 3^n +4^n+5^n)^{1/n}$? My partial solution: $(1 + 2^n + 3^n +4^n+5^n)^{1/n} \leq (5 \times 5^n)^{1/n}$. Therefore $\lim_{n \to \infty} (1 + 2^n + 3^n +4^n+5^n)^{1/n} \leq \lim_{n \to \infty} 5^{(n+1)/n} = 5$. Thank you very much.,,['calculus']
63,How to get the solution to these differential equations,How to get the solution to these differential equations,,"I would like to get from $$ \tan(x) = \frac{y''}{y'} + y' $$ The answer is $$ y = \ln(c_1\tanh^{-1}(\tan(\frac{x}{2}))+c_2) $$ The other equation is $$ \sec(x) = \frac{y''}{y'}+y' $$ The answer is $$ y = \ln(c_1\ln(e^{4\tanh^{-1}(\tan(\frac{x}{2}))}+1)+c_2) $$ I have no idea where to begin, Any advice would be nice.","I would like to get from $$ \tan(x) = \frac{y''}{y'} + y' $$ The answer is $$ y = \ln(c_1\tanh^{-1}(\tan(\frac{x}{2}))+c_2) $$ The other equation is $$ \sec(x) = \frac{y''}{y'}+y' $$ The answer is $$ y = \ln(c_1\ln(e^{4\tanh^{-1}(\tan(\frac{x}{2}))}+1)+c_2) $$ I have no idea where to begin, Any advice would be nice.",,"['calculus', 'integration', 'ordinary-differential-equations']"
64,If $\lim_{x\to\infty} [f(x+1)-f(x)] =l$ then $\lim_{ x\to\infty}f(x)/x =l$ ($f$ is continuous),If  then  ( is continuous),\lim_{x\to\infty} [f(x+1)-f(x)] =l \lim_{ x\to\infty}f(x)/x =l f,"Prove that if $f$ is continuous on $\mathbb R$ and $$\lim_{x \to +\infty}  [f(x+1)-f(x)] = l,$$ then $$\lim_{x\to +\infty} f(x)/x =l.$$ So I've been trying for hours to use the series definition of limits / Cesaro's lemma (if $\lim U(n+1) - U(n) = l$ then $\lim U(n)/n=l$). I'm completly blocked and I can't get it.","Prove that if $f$ is continuous on $\mathbb R$ and $$\lim_{x \to +\infty}  [f(x+1)-f(x)] = l,$$ then $$\lim_{x\to +\infty} f(x)/x =l.$$ So I've been trying for hours to use the series definition of limits / Cesaro's lemma (if $\lim U(n+1) - U(n) = l$ then $\lim U(n)/n=l$). I'm completly blocked and I can't get it.",,"['calculus', 'functional-analysis', 'limits', 'power-series']"
65,Proving Lagrange method by using Implicit Function Theorem,Proving Lagrange method by using Implicit Function Theorem,,"I am trying to show the proof of the Lagrange multiplier method. According to this in general, if $f$ and $g$ are $D+1$ dimensional functions such that $f,g : \mathbb{R}^{D+1} \mapsto \mathbb{R}$, and if the point $p$ with $p=(x',y')$ where $x'$ is a $D$ dimensional vector and $y'$ is a scalar, is a constrained local extremum with subject to the constraint $g(x,y)=0$ and $\dfrac{\partial g(p)}{\partial y} \neq 0$, then at $p$ it is $\nabla f(p) = \lambda \nabla g(p)$. My approach using the implicit function theorem is the following: From the above statement, for $g$, we can determine a ball around $x'$ for a $r > 0$ such that there is a function $h: B(x',r) \mapsto \mathbb{R}$ and it is $g(x,h(x))=0$ for each $x \in B(x',r)$. In this ball, we can state $f$ as $f(x,h(x))$ which always satisfies the constraint. Now, in $B(x',r)$ the unconstrained optimization of $f(x,h(x))$ will give us the constrained extremum point, $(x',y')$ and at $x'$ the gradient of $f(x,h(x))$ wrt $x$ vanishes. So it is at $p=(x',y')$ $$\sum_{i=1}^D \dfrac{\mathrm{d} F}{\mathrm{d} x_i}=\sum_{i=1}^D (\dfrac{\partial F}{\partial x_i} + \dfrac{\partial F}{\partial y}\dfrac{\partial h}{\partial x_i} )=0$$ We can differentiate $g(x,h(x))$ at $p=(x',y')$ wrt to $x$ as well. It should be trivially equal to zero. So, it is $$\sum_{i=1}^D \dfrac{\mathrm{d} g}{\mathrm{d} x_i}=\sum_{i=1}^D (\dfrac{\partial g}{\partial x_i} + \dfrac{\partial g}{\partial y}\dfrac{\partial h}{\partial x_i} )=0$$. I obtained all parts belonging to the gradients of two functions $f$ and $g$ but I am still not able to show $\nabla f(p) = \lambda \nabla g(p)$. What is missing in my construction, how can we reach to this statement from the derivates written above?","I am trying to show the proof of the Lagrange multiplier method. According to this in general, if $f$ and $g$ are $D+1$ dimensional functions such that $f,g : \mathbb{R}^{D+1} \mapsto \mathbb{R}$, and if the point $p$ with $p=(x',y')$ where $x'$ is a $D$ dimensional vector and $y'$ is a scalar, is a constrained local extremum with subject to the constraint $g(x,y)=0$ and $\dfrac{\partial g(p)}{\partial y} \neq 0$, then at $p$ it is $\nabla f(p) = \lambda \nabla g(p)$. My approach using the implicit function theorem is the following: From the above statement, for $g$, we can determine a ball around $x'$ for a $r > 0$ such that there is a function $h: B(x',r) \mapsto \mathbb{R}$ and it is $g(x,h(x))=0$ for each $x \in B(x',r)$. In this ball, we can state $f$ as $f(x,h(x))$ which always satisfies the constraint. Now, in $B(x',r)$ the unconstrained optimization of $f(x,h(x))$ will give us the constrained extremum point, $(x',y')$ and at $x'$ the gradient of $f(x,h(x))$ wrt $x$ vanishes. So it is at $p=(x',y')$ $$\sum_{i=1}^D \dfrac{\mathrm{d} F}{\mathrm{d} x_i}=\sum_{i=1}^D (\dfrac{\partial F}{\partial x_i} + \dfrac{\partial F}{\partial y}\dfrac{\partial h}{\partial x_i} )=0$$ We can differentiate $g(x,h(x))$ at $p=(x',y')$ wrt to $x$ as well. It should be trivially equal to zero. So, it is $$\sum_{i=1}^D \dfrac{\mathrm{d} g}{\mathrm{d} x_i}=\sum_{i=1}^D (\dfrac{\partial g}{\partial x_i} + \dfrac{\partial g}{\partial y}\dfrac{\partial h}{\partial x_i} )=0$$. I obtained all parts belonging to the gradients of two functions $f$ and $g$ but I am still not able to show $\nabla f(p) = \lambda \nabla g(p)$. What is missing in my construction, how can we reach to this statement from the derivates written above?",,"['calculus', 'multivariable-calculus', 'lagrange-multiplier']"
66,How to evaluate $\int_0^ \infty e^{-x\sinh(t)-\frac{1}{2}t}~dt$?,How to evaluate ?,\int_0^ \infty e^{-x\sinh(t)-\frac{1}{2}t}~dt,"$$ \int_0^ \infty e^{-x\sinh(t)-\frac{1}{2}t}~dt $$ I tried doing it by parts and looking for differentials but I just keep getting back to the original expression. I can't think of a clever substitution either. Mathematica is giving me a complex answer with special functions: $$ \frac{e^{-ix}\sqrt{\frac{\pi}{2}}(-i+ie^{2ix}\text{Erfc}[(-1)^{\frac{1}{4}}\sqrt{x}]+\text{Erfi}[(-1)^\frac{1}{4}\sqrt{x}])}{\sqrt{x}}  $$ For real $x>0$, it does evaluate to real answers though.","$$ \int_0^ \infty e^{-x\sinh(t)-\frac{1}{2}t}~dt $$ I tried doing it by parts and looking for differentials but I just keep getting back to the original expression. I can't think of a clever substitution either. Mathematica is giving me a complex answer with special functions: $$ \frac{e^{-ix}\sqrt{\frac{\pi}{2}}(-i+ie^{2ix}\text{Erfc}[(-1)^{\frac{1}{4}}\sqrt{x}]+\text{Erfi}[(-1)^\frac{1}{4}\sqrt{x}])}{\sqrt{x}}  $$ For real $x>0$, it does evaluate to real answers though.",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
67,Confused about differentiation,Confused about differentiation,,"I'm new to calculus and have been taught that $\displaystyle \frac{dy}{dx}$ is the rate of change of y with respect to x. Does $\displaystyle \frac{dy}{dx}$ show how much the variable y changes as x changes? Is there more to understanding this part of calculus, I feel as I'm missing the fundamentals behind differential calculus. Also one thing that I didn't understand is when doing u-substitution integration if we let $u=2x +1$ for example, sometimes I see $\displaystyle du = 2dx \therefore dx = \frac{du}{2}$. What is this known as and why does it work? My teacher school finds $\displaystyle \frac{du}{dx}$ and rearranges this to make $dx$ the subject. Is this an incorrect practice? I have searched for this on here and cannot find a definite answer. What is the correct notation to be used? When differentiating y = f(x) are we always operating on y as in $\displaystyle \frac{d}{dx} (y)$ = $\displaystyle \frac{dy}{dx}$. If you differentiate x^2 w.r.t x as in $\displaystyle \frac{d}{dx}x^2$, are you finding how much x^2 changes as x changes e.g if $x = 1, x^2 = 1, x = 2, x^2 = 4, x = 3, x^2 = 9$ so $x^2$ is 2 times the value of x? If we have something like $y^3$, what does it mean to differentiate $y^3$ with respect to x as in $\displaystyle \frac{d}{dx} y^3$ and how is it done? thanks, I have been looking for the solutions to my problems for quite a while but cannot find an answer that leaves me satisfied. Sorry if questions likethese are not to be asked here.","I'm new to calculus and have been taught that $\displaystyle \frac{dy}{dx}$ is the rate of change of y with respect to x. Does $\displaystyle \frac{dy}{dx}$ show how much the variable y changes as x changes? Is there more to understanding this part of calculus, I feel as I'm missing the fundamentals behind differential calculus. Also one thing that I didn't understand is when doing u-substitution integration if we let $u=2x +1$ for example, sometimes I see $\displaystyle du = 2dx \therefore dx = \frac{du}{2}$. What is this known as and why does it work? My teacher school finds $\displaystyle \frac{du}{dx}$ and rearranges this to make $dx$ the subject. Is this an incorrect practice? I have searched for this on here and cannot find a definite answer. What is the correct notation to be used? When differentiating y = f(x) are we always operating on y as in $\displaystyle \frac{d}{dx} (y)$ = $\displaystyle \frac{dy}{dx}$. If you differentiate x^2 w.r.t x as in $\displaystyle \frac{d}{dx}x^2$, are you finding how much x^2 changes as x changes e.g if $x = 1, x^2 = 1, x = 2, x^2 = 4, x = 3, x^2 = 9$ so $x^2$ is 2 times the value of x? If we have something like $y^3$, what does it mean to differentiate $y^3$ with respect to x as in $\displaystyle \frac{d}{dx} y^3$ and how is it done? thanks, I have been looking for the solutions to my problems for quite a while but cannot find an answer that leaves me satisfied. Sorry if questions likethese are not to be asked here.",,"['calculus', 'soft-question', 'intuition', 'nonstandard-analysis']"
68,Compute $\lim_{n \to \infty} \sum_{k=1}^{n} \frac{n^2 + k}{n^3 + k}$,Compute,\lim_{n \to \infty} \sum_{k=1}^{n} \frac{n^2 + k}{n^3 + k},Compute $$\lim_{n \to \infty} \sum_{k=1}^{n} \frac{n^2 + k}{n^3 + k}$$ I tried: $$ 1 \xleftarrow{n \to \infty} n \cdot \frac{n^2+1}{n^3 + n} \le \sum_{k=1}^{n} \frac{n^2 + k}{n^3 + k} \le n \cdot \frac{n^2 + n}{n^3 +1} \xrightarrow{n \to \infty} 1$$ Hence:$$\lim_{n \to \infty} \sum_{k=1}^{n} \frac{n^2 + k}{n^3 + k} = 1$$ I have no answer to that task and wolfram alpha didn't help me. I will grateful if you could check it.,Compute $$\lim_{n \to \infty} \sum_{k=1}^{n} \frac{n^2 + k}{n^3 + k}$$ I tried: $$ 1 \xleftarrow{n \to \infty} n \cdot \frac{n^2+1}{n^3 + n} \le \sum_{k=1}^{n} \frac{n^2 + k}{n^3 + k} \le n \cdot \frac{n^2 + n}{n^3 +1} \xrightarrow{n \to \infty} 1$$ Hence:$$\lim_{n \to \infty} \sum_{k=1}^{n} \frac{n^2 + k}{n^3 + k} = 1$$ I have no answer to that task and wolfram alpha didn't help me. I will grateful if you could check it.,,['calculus']
69,Evaluating $\int \frac{1}{2+3 \sin\left(x\right)}$,Evaluating,\int \frac{1}{2+3 \sin\left(x\right)},"I'm helping my daughter on her calculus homework and it has been many years for me. The problem is $$ \int \frac{1}{2+3 \sin\left(x\right)} dx $$ From WolframAlpha, the substitution should be $u = \tan\frac{x}{2}$. Once you have the substitution, the solution is quite straightforward. My question is how on earth do you come up with that substitution? Are there any rubrics/recipes? Or is it just intuition?","I'm helping my daughter on her calculus homework and it has been many years for me. The problem is $$ \int \frac{1}{2+3 \sin\left(x\right)} dx $$ From WolframAlpha, the substitution should be $u = \tan\frac{x}{2}$. Once you have the substitution, the solution is quite straightforward. My question is how on earth do you come up with that substitution? Are there any rubrics/recipes? Or is it just intuition?",,['calculus']
70,Monotonicity of functions,Monotonicity of functions,,"Let $f(x) = xe^{x^2} + e^{-x^2}$ I'd like to prove that this function increases monotonically in the interval $(0,1)$. I was able to do it by taking the derivative and proving it was greater than zero. (though it took me quite some time to do that) I wanted to know if there was any other more elegant method to do the same.","Let $f(x) = xe^{x^2} + e^{-x^2}$ I'd like to prove that this function increases monotonically in the interval $(0,1)$. I was able to do it by taking the derivative and proving it was greater than zero. (though it took me quite some time to do that) I wanted to know if there was any other more elegant method to do the same.",,['calculus']
71,Prove the following property of $f(x)$?,Prove the following property of ?,f(x),"Let $$f(x)=|a_1\sin(x)+a_2\sin(2x)+a_3\sin(3x)+...+a_n\sin(nx)|.$$ Given that $f(x)$ is less than or equal to $|\sin(x)|$ for all $x$, prove that $|a_1+a_2+a_3+....|$ is less than or equal to 1.Please keep this at a calculus AB level because that's where I got the problem from. Thanks!","Let $$f(x)=|a_1\sin(x)+a_2\sin(2x)+a_3\sin(3x)+...+a_n\sin(nx)|.$$ Given that $f(x)$ is less than or equal to $|\sin(x)|$ for all $x$, prove that $|a_1+a_2+a_3+....|$ is less than or equal to 1.Please keep this at a calculus AB level because that's where I got the problem from. Thanks!",,"['calculus', 'algebra-precalculus', 'functions']"
72,How can I determine which series comparison test to use?,How can I determine which series comparison test to use?,,"In my textbook, there is a section of questions that's instructions reads ""Test for convergence or divergence, using each one of the following tests once,"" and the test choices it gives me are nth-Term Test p-Series Test Integral Test Limit Comparison Test Geometric Series Test Telescoping Series Test Direct Comparison Test Now, I was able to get most of the problems in this section right on the first try, but when I compared my answers to those in the solutions manual, I found that often the way I chose was not the same as theirs. Sometimes, my solution was simpler, but most of the time, the method they chose was quicker. For one of the problems, I did the limit comparison test and I ended up with a $b_{n}$ that was one, so I was really just doing some convoluted mix between the Limit Comparison Test and the nth-Term Test. How can I develop skills to help me to decide which method to choose? Is there some ""trick"" to deciding which method will be the simplest?","In my textbook, there is a section of questions that's instructions reads ""Test for convergence or divergence, using each one of the following tests once,"" and the test choices it gives me are nth-Term Test p-Series Test Integral Test Limit Comparison Test Geometric Series Test Telescoping Series Test Direct Comparison Test Now, I was able to get most of the problems in this section right on the first try, but when I compared my answers to those in the solutions manual, I found that often the way I chose was not the same as theirs. Sometimes, my solution was simpler, but most of the time, the method they chose was quicker. For one of the problems, I did the limit comparison test and I ended up with a $b_{n}$ that was one, so I was really just doing some convoluted mix between the Limit Comparison Test and the nth-Term Test. How can I develop skills to help me to decide which method to choose? Is there some ""trick"" to deciding which method will be the simplest?",,"['calculus', 'sequences-and-series']"
73,How to turn this sum into an integral?,How to turn this sum into an integral?,,"I have been trying to find the closed form of this sum to no avail.  It was suggested to me to try and turn this sum into an integral and solve it like that.  However, I am confused as to how to do this. If we have a circle of radius $r$ with an $n$-gon inscribed within this circle (i.e. with the same circumradius), we can find the difference of the areas using: $$ A_n =\overbrace{\pi r^2}^\text{Area of circle}-\overbrace{\frac{1}{2} r^2 n \sin \left(\frac{2 \pi}{n}\right)}^\text{Area of n-gon} =r^2\left(\pi-\frac{1}{2} n \sin \left(\frac{2 \pi}{n}\right)\right) $$ I want to find the following sum (starting with $n=3$, i.e. the $n$-gon is a triangle): $$\Lambda=\sum_{n=3}^\infty A_n =  r^2\sum_{n=3}^\infty \left(\pi -\frac{1}{2} n \sin \left(\frac{2 \pi}{n}\right)\right) =  r^2 \lim_{k \rightarrow \infty} \left(\pi (k-3)-\frac{1}{2} \sum_{n=3}^k n \sin \left(\frac{2 \pi}{n}\right)\right) $$ Expanding the $\sin$ using its Taylor's Series, we have $$ \Lambda= \sum_{n=3}^\infty \pi - \frac{1}{2}n\left(\frac{2\pi}{n} - \frac{(\frac{2\pi}{n})^3}{3!} + \cdots \right) =  \frac{1}{2}\sum_{n=3}^\infty \sum_{m = 1}^\infty (-1)^{m+1}\frac{(2\pi)^{2m+1}}{(2m+1)!n^{2m}} $$ I would like some help with turning this sum into an integral to try and solve it.  Any other suggestions for solving this sum are welcome as well. My previous question on this sum can be found here: Convergence and closed form of this infinite series?","I have been trying to find the closed form of this sum to no avail.  It was suggested to me to try and turn this sum into an integral and solve it like that.  However, I am confused as to how to do this. If we have a circle of radius $r$ with an $n$-gon inscribed within this circle (i.e. with the same circumradius), we can find the difference of the areas using: $$ A_n =\overbrace{\pi r^2}^\text{Area of circle}-\overbrace{\frac{1}{2} r^2 n \sin \left(\frac{2 \pi}{n}\right)}^\text{Area of n-gon} =r^2\left(\pi-\frac{1}{2} n \sin \left(\frac{2 \pi}{n}\right)\right) $$ I want to find the following sum (starting with $n=3$, i.e. the $n$-gon is a triangle): $$\Lambda=\sum_{n=3}^\infty A_n =  r^2\sum_{n=3}^\infty \left(\pi -\frac{1}{2} n \sin \left(\frac{2 \pi}{n}\right)\right) =  r^2 \lim_{k \rightarrow \infty} \left(\pi (k-3)-\frac{1}{2} \sum_{n=3}^k n \sin \left(\frac{2 \pi}{n}\right)\right) $$ Expanding the $\sin$ using its Taylor's Series, we have $$ \Lambda= \sum_{n=3}^\infty \pi - \frac{1}{2}n\left(\frac{2\pi}{n} - \frac{(\frac{2\pi}{n})^3}{3!} + \cdots \right) =  \frac{1}{2}\sum_{n=3}^\infty \sum_{m = 1}^\infty (-1)^{m+1}\frac{(2\pi)^{2m+1}}{(2m+1)!n^{2m}} $$ I would like some help with turning this sum into an integral to try and solve it.  Any other suggestions for solving this sum are welcome as well. My previous question on this sum can be found here: Convergence and closed form of this infinite series?",,"['calculus', 'sequences-and-series', 'trigonometry', 'limits', 'circles']"
74,Outline and Goals of a One-Year Calculus Sequence,Outline and Goals of a One-Year Calculus Sequence,,"Our department is considering restructuring our traditional three semester calculus sequence so that the calculus requirement for our majors is satisfied in two semesters. Does your department offer such a two   semester sequence and, if so, could   you provide a rough outline of topics   covered and/or textbooks used? What   are your department's learning goals   for this sequence? If your department   does not offer such a sequence, has it   been considered? We are particularly interested in responses from faculty at small liberal arts colleges. Addendum: It has been suggested that we consider, for the first semester, accelerating the Calculus I (differentiation) part of the course by reviewing for a week and then proceeding with Calculus II (integration) at the usual pace. The second semester is then dedicated to multivariable calculus. If your institution has tried this, feedback on this would be helpful. Note: We intend to offer the abridged sequence only for mathematics majors (or perhaps mathematics and physics majors).","Our department is considering restructuring our traditional three semester calculus sequence so that the calculus requirement for our majors is satisfied in two semesters. Does your department offer such a two   semester sequence and, if so, could   you provide a rough outline of topics   covered and/or textbooks used? What   are your department's learning goals   for this sequence? If your department   does not offer such a sequence, has it   been considered? We are particularly interested in responses from faculty at small liberal arts colleges. Addendum: It has been suggested that we consider, for the first semester, accelerating the Calculus I (differentiation) part of the course by reviewing for a week and then proceeding with Calculus II (integration) at the usual pace. The second semester is then dedicated to multivariable calculus. If your institution has tried this, feedback on this would be helpful. Note: We intend to offer the abridged sequence only for mathematics majors (or perhaps mathematics and physics majors).",,"['calculus', 'education']"
75,Can anyone come up with a method for integrating product of logarithms?,Can anyone come up with a method for integrating product of logarithms?,,"So recently I’ve been studying integrals of products of logarithms $$\int \prod_{n=1}^N \log(x+a_n) dx$$ Can anyone come up with general method for dealing with such integral? Let's start simple, with N = 2. $$ \int \frac{\log(z+m)}{z} dz = \int \frac{\log(1-u)+\log m}{u} du = -Li_2(\frac{-z}{m}) + \log m\log z + C$$ Then we apply integration by parts to $\int \log(x+a)\log(x+b) dx$ , setting $u = \log(x+b)$ and $v = (x+a)\log(x+a)-(x+b)$ . Well, $x+a$ could be written as $(x+b) + (a-b)$ . Yielding $$\int \log(x+a)\log(x+b) dx = (x+a)\log(x+a)\log(x+b) - (x+a)\log(x+a) - (x+b)\log(x+b) + 2x + (b-a)\int\frac{\log(x+a)}{x+b}dx$$ $$=(a-b)Li_2(\frac{x+b}{b-a}) +(x+a)\log(x+a)\log(x+b) - (x+a)\log(x+a) $$ $$-(x+(a-b)\log(a-b)+b)\log(x+b) + 2x + C$$ The case $N = 3$ is a lot more complicated. I wasn't able to come up with a solution until recently. WolframAlpha was able to give solution but cannot provide any human readable derivation to its solution. My solution to $N=3$ goes like this. We apply integration by parts to $\int\frac{log(z)log(z+m)}{z}dz$ setting $u = logz$ and $v = -Li_2(\frac{-z}{m}) + logmlogz$ . Yielding $$\int\frac{log(z)log(z+m)}{z}dz = Li_3(\frac{-z}{m}) - logz Li_2(\frac{-z}{m}) + \frac{1}{2} logmlog^2z + C$$ Now, we apply integration by parts to $\int\frac{log^2z}{z+m}$ setting $u = log^2z$ and $v=log(z+m)$ , hence we get $$\int\frac{log^2z}{z+m} dz = log^2zlog(z+m) - 2\int\frac{logzlog(z+m)}{z} dz = $$ $$-2Li_3(\frac{-z}{m}) + 2logz Li_2(\frac{-z}{m}) + log^2zlog(z+m) - logmlog^2z+ C$$ To keep things neat from here, $$\int log(x+a)log(x+b) dx = A(x, a, b) + C$$ $$\int\frac{log(z)log(z+m)}{z}dz = B(z, m) + C $$ $$\int\frac{log^2z}{z+m} dz = C(z, m) + C$$ We perform a substitution, $z = (y+p)/(y+q)$ . $dz = (q-p)/(y+q)^2 dy$ $$\frac{dz}{z+m} = \frac{\frac{q-p}{(y+q)^2}}{\frac{(1+m)y+(mq+p)}{y+q}} dy = \frac{qdy}{(y)(y+q)} = (\frac{1}{y}-\frac{1}{y+q})dy$$ let's set $mq+p = 0 => m = \frac{-p}{q}$ $$\int(log^2(y+p)-2log(y+p)log(y+q)+log^2(y+q))(\frac{1}{y}-\frac{1}{y+q})dy = C(\frac{y+p}{y+q}, \frac{-p}{q})+C$$ $$\int\frac{log(y+p)log(y+q)}{y}dy = D(y, p, q) + C = \frac{1}{2}(-C(\frac{y+p}{y+q}, \frac{-p}{q})+C(y+p, -p) - C(y+p, q-p) + C(y+q, -q) + \frac{log^3(y+q)}{3})+B(y+q, p-q)+C$$ Finally, we apply integration by parts to $\int log(x+a)log(x+b)log(x+c)$ setting $u=log(x+a)log(x+b)log(x+c)$ and $v=x+c$ $$\int log(x+a)log(x+b)log(x+c)dx = (a-c)D(x+a, b-a, c-a) + (b-c)D(x+b, a-b, c-b) - A(x, a, b) - A(x,a, c) - A(x, b, c) + (x+c)log(x+a)log(x+b)log(x+c)+ C$$ This can be generalized to a method that reduces $\int\frac{\prod_{n=1}^N log(x+a_n)}{x}dx$ to a bunch of integrals of the form $\int\frac{log^2(y+b)\prod_{n=1}^{N-2}log(y+b_n)}{y}dy$ $$\frac{log(y+p)log(y+q)}{y} = \frac{1}{2}(log^2(y+p)+log^2(y+q) - log^2(\frac{y+p}{y+q}))(\frac{1}{y} - \frac{1}{y+q}) + \frac{log(y+p)log(y+q)}{y+q} = $$ $$\frac{q}{2}\frac{log(\frac{y+p}{y+q})}{y(y+q)}+\frac{1}{2}(log^2(y+p)+log^2(y+q))(\frac{1}{y}-\frac{1}{y+q})+\frac{log(y+p)log(y+q)}{y+q}$$ We split $\int\frac{f(y)log(y+p)log(y+q)}{y}dy$ using this. $$\int\frac{f(y)log^2(\frac{y+p}{y+q})}{y(y+q)}dy = \int\frac{f(y)log^2(\frac{y+p}{y+q})}{\frac{y}{y+q}}*\frac{dy}{(y+q)^2} = \frac{1}{q}\int_{z=\frac{y+p}{y+q}}\frac{f(\frac{-qz+p}{z-1})log^2z}{z-\frac{p}{q}}dz$$ Substitute $z = \frac{y+p}{y+q} = 1+\frac{p-q}{y+q} => y = \frac{-qz+p}{z-1}$ . $dz = \frac{q-p}{(y+q)^2}dy$ $$\frac{1}{\frac{y}{y+q}}*\frac{dy}{(y+q)^2}=\frac{\frac{1}{q}}{\frac{(q-p)y}{q(y+q)}}*\frac{(q-p)dy}{(y+q)^2} = \frac{\frac{1}{q}}{\frac{y+p}{y+q}-\frac{p}{q}} dz = \frac{1}{q} \frac{1}{z-\frac{p}{q}} dz$$ We apply integration by parts to $\int\frac{f(y)log(y+p)log(y+q)}{y+q}dy$ setting $u = f(y)log(y+p)$ and $v = \frac{1}{2} log^2(y+q)$ . We have $$\int\frac{f(y)log(y+p)log(y+q)}{y+q} dy = \frac{1}{2}(f(y)log(y+p)log^2(y+q) - \int f'(y) log(y+p) log^2(y+q)dy-\int\frac{f(y)log^2(y+q)}{y+p})$$ $$\int\frac{f(y)log(y+p)log(y+q)}{y}dy = \frac{1}{2} (-\int_{z=\frac{y+p}{y+q}} \frac{f(\frac{-qz+p}{z-1})log^2z}{z-\frac{p}{q}}dz + \int(log^2(y+p)-log^2(y+q))(\frac{1}{y}-\frac{1}{y+q})dy+$$ $$f(y)log(y+p)log^2(y+q) - \int f'(y) log(y+p) log^2(y+q)dy-\int\frac{f(y)log^2(y+q)}{y+p})$$ Setting $f(y) = log(y+r)$ allows us decompose $\int\frac{log(y+p)log(y+q)log(y+r)}{y}dy$ into  bunch of integrals of the form $\int\frac{log(w+P)log^2(w+Q)}{w}dw$ . Solving this integral will let us solve the case $N = 4$ . For the case $N=4$ , WolframAlpha fails to give any answer. I am also stuck when it comes to the case $N=4$","So recently I’ve been studying integrals of products of logarithms Can anyone come up with general method for dealing with such integral? Let's start simple, with N = 2. Then we apply integration by parts to , setting and . Well, could be written as . Yielding The case is a lot more complicated. I wasn't able to come up with a solution until recently. WolframAlpha was able to give solution but cannot provide any human readable derivation to its solution. My solution to goes like this. We apply integration by parts to setting and . Yielding Now, we apply integration by parts to setting and , hence we get To keep things neat from here, We perform a substitution, . let's set Finally, we apply integration by parts to setting and This can be generalized to a method that reduces to a bunch of integrals of the form We split using this. Substitute . We apply integration by parts to setting and . We have Setting allows us decompose into  bunch of integrals of the form . Solving this integral will let us solve the case . For the case , WolframAlpha fails to give any answer. I am also stuck when it comes to the case","\int \prod_{n=1}^N \log(x+a_n) dx  \int \frac{\log(z+m)}{z} dz = \int \frac{\log(1-u)+\log m}{u} du = -Li_2(\frac{-z}{m}) + \log m\log z + C \int \log(x+a)\log(x+b) dx u = \log(x+b) v = (x+a)\log(x+a)-(x+b) x+a (x+b) + (a-b) \int \log(x+a)\log(x+b) dx = (x+a)\log(x+a)\log(x+b) - (x+a)\log(x+a) - (x+b)\log(x+b) + 2x + (b-a)\int\frac{\log(x+a)}{x+b}dx =(a-b)Li_2(\frac{x+b}{b-a}) +(x+a)\log(x+a)\log(x+b) - (x+a)\log(x+a)  -(x+(a-b)\log(a-b)+b)\log(x+b) + 2x + C N = 3 N=3 \int\frac{log(z)log(z+m)}{z}dz u = logz v = -Li_2(\frac{-z}{m}) + logmlogz \int\frac{log(z)log(z+m)}{z}dz = Li_3(\frac{-z}{m}) - logz Li_2(\frac{-z}{m}) + \frac{1}{2} logmlog^2z + C \int\frac{log^2z}{z+m} u = log^2z v=log(z+m) \int\frac{log^2z}{z+m} dz = log^2zlog(z+m) - 2\int\frac{logzlog(z+m)}{z} dz =  -2Li_3(\frac{-z}{m}) + 2logz Li_2(\frac{-z}{m}) + log^2zlog(z+m) - logmlog^2z+ C \int log(x+a)log(x+b) dx = A(x, a, b) + C \int\frac{log(z)log(z+m)}{z}dz = B(z, m) + C  \int\frac{log^2z}{z+m} dz = C(z, m) + C z = (y+p)/(y+q) dz = (q-p)/(y+q)^2 dy \frac{dz}{z+m} = \frac{\frac{q-p}{(y+q)^2}}{\frac{(1+m)y+(mq+p)}{y+q}} dy = \frac{qdy}{(y)(y+q)} = (\frac{1}{y}-\frac{1}{y+q})dy mq+p = 0 => m = \frac{-p}{q} \int(log^2(y+p)-2log(y+p)log(y+q)+log^2(y+q))(\frac{1}{y}-\frac{1}{y+q})dy = C(\frac{y+p}{y+q}, \frac{-p}{q})+C \int\frac{log(y+p)log(y+q)}{y}dy = D(y, p, q) + C = \frac{1}{2}(-C(\frac{y+p}{y+q}, \frac{-p}{q})+C(y+p, -p) - C(y+p, q-p) + C(y+q, -q) + \frac{log^3(y+q)}{3})+B(y+q, p-q)+C \int log(x+a)log(x+b)log(x+c) u=log(x+a)log(x+b)log(x+c) v=x+c \int log(x+a)log(x+b)log(x+c)dx = (a-c)D(x+a, b-a, c-a) + (b-c)D(x+b, a-b, c-b) - A(x, a, b) - A(x,a, c) - A(x, b, c) + (x+c)log(x+a)log(x+b)log(x+c)+ C \int\frac{\prod_{n=1}^N log(x+a_n)}{x}dx \int\frac{log^2(y+b)\prod_{n=1}^{N-2}log(y+b_n)}{y}dy \frac{log(y+p)log(y+q)}{y} = \frac{1}{2}(log^2(y+p)+log^2(y+q) - log^2(\frac{y+p}{y+q}))(\frac{1}{y} - \frac{1}{y+q}) + \frac{log(y+p)log(y+q)}{y+q} =  \frac{q}{2}\frac{log(\frac{y+p}{y+q})}{y(y+q)}+\frac{1}{2}(log^2(y+p)+log^2(y+q))(\frac{1}{y}-\frac{1}{y+q})+\frac{log(y+p)log(y+q)}{y+q} \int\frac{f(y)log(y+p)log(y+q)}{y}dy \int\frac{f(y)log^2(\frac{y+p}{y+q})}{y(y+q)}dy = \int\frac{f(y)log^2(\frac{y+p}{y+q})}{\frac{y}{y+q}}*\frac{dy}{(y+q)^2} = \frac{1}{q}\int_{z=\frac{y+p}{y+q}}\frac{f(\frac{-qz+p}{z-1})log^2z}{z-\frac{p}{q}}dz z = \frac{y+p}{y+q} = 1+\frac{p-q}{y+q} => y = \frac{-qz+p}{z-1} dz = \frac{q-p}{(y+q)^2}dy \frac{1}{\frac{y}{y+q}}*\frac{dy}{(y+q)^2}=\frac{\frac{1}{q}}{\frac{(q-p)y}{q(y+q)}}*\frac{(q-p)dy}{(y+q)^2} = \frac{\frac{1}{q}}{\frac{y+p}{y+q}-\frac{p}{q}} dz = \frac{1}{q} \frac{1}{z-\frac{p}{q}} dz \int\frac{f(y)log(y+p)log(y+q)}{y+q}dy u = f(y)log(y+p) v = \frac{1}{2} log^2(y+q) \int\frac{f(y)log(y+p)log(y+q)}{y+q} dy = \frac{1}{2}(f(y)log(y+p)log^2(y+q) - \int f'(y) log(y+p) log^2(y+q)dy-\int\frac{f(y)log^2(y+q)}{y+p}) \int\frac{f(y)log(y+p)log(y+q)}{y}dy = \frac{1}{2} (-\int_{z=\frac{y+p}{y+q}} \frac{f(\frac{-qz+p}{z-1})log^2z}{z-\frac{p}{q}}dz + \int(log^2(y+p)-log^2(y+q))(\frac{1}{y}-\frac{1}{y+q})dy+ f(y)log(y+p)log^2(y+q) - \int f'(y) log(y+p) log^2(y+q)dy-\int\frac{f(y)log^2(y+q)}{y+p}) f(y) = log(y+r) \int\frac{log(y+p)log(y+q)log(y+r)}{y}dy \int\frac{log(w+P)log^2(w+Q)}{w}dw N = 4 N=4 N=4","['calculus', 'indefinite-integrals', 'computer-algebra-systems']"
76,A little bit nasty double integral,A little bit nasty double integral,,"I have difficulty calculating the following double integral: $$\int_0^1\int_0^1\sqrt{x^2-2mxy+y^2+h^2}\text{d}x\text{d}y$$ where $m\in[-1,1],h\in(0,\infty)$ are constants. What I've tried with the help of others: \begin{align*} I&=2\int_0^{\frac{\pi}{4}}\int_0^{\sec\theta}r\cdot\sqrt{(1-2m\sin\theta\cos\theta)r^2+h^2}\text{d}r\text{d}\theta \end{align*} let $a=1-2m\sin\theta\cos\theta$ , then the inner part looks like this： $$\int r\cdot\sqrt{ar^2+h^2}\text{d}r$$ let $u=ar^2+h^2$ , then the inner part should be: $$\frac1{2a}\int\sqrt{u}\text{d}u=\frac1{3a}u^{\frac32}=\frac1{3a}(ar^2+h^2)^{\frac32}$$ Hence, \begin{align*} \int_0^{\sec\theta}r\sqrt{ar^2+h^2}\text{d}r &=\frac1{3a}[(a\sec^2\theta+h^2)^\frac32-h^3 ]\\ &=\frac{(\tan^2\theta-2m\tan\theta+h^2+1)^\frac32-h^3}{3-6m\sin\theta\cos\theta} \end{align*} So, $$\frac23\int_0^\frac{\pi}{4}\frac{(\tan^2\theta-2m\tan\theta+h^2+1)^\frac32-h^3}{1-2m\sin\theta\cos\theta}\text{d}\theta$$ But I have no idea how to deal with: $$\int_0^{\frac{\pi}{4}}\frac{(\tan^2\theta-2m\tan\theta+h^2+1)^{\frac32}}{1-2m\sin\theta\cos\theta}\text{d}\theta$$ Update: Thanks to @sreysus, we change it to $$\int_0^{\frac{\pi}{4}}\frac{\sqrt{1-2m\sin\theta\cos\theta+h^2}}{\cos^3\theta}\text{d}\theta+\int_0^{\frac{\pi}{4}}\frac{h^2\sqrt{1-2m\sin\theta\cos\theta+h^2}}{\cos\theta-2m\sin\theta\cos\theta}\text{d}\theta$$ What I've tried: \begin{align*} \int_0^{\frac{\pi}{4}}\frac{\sqrt{1-2m\sin\theta\cos\theta+h^2}}{\cos^3\theta}\text{d}\theta &=\int_0^{\frac{\pi}{4}}\frac{\sqrt{1-2m\sin\theta\cos\theta+h^2}}{\cos\theta}\text{d}\tan\theta\\ &=\int_0^{\frac{\pi}{4}}\sqrt{(1+h^2)\sec^2\theta-2m\tan\theta}\text{d}\tan\theta\\ &=\int_0^1\sqrt{(1+h^2)(1+u^2)-2mu}\text{d}u \end{align*} Though it's complicated, I've worked this part out (too complicated to put it here) So I got stuck how to evaluate this part: $$\int_0^{\frac{\pi}{4}}\frac{h^2\sqrt{1-2m\sin\theta\cos\theta+h^2}}{\cos\theta-2m\sin\theta\cos^2\theta}\text{d}\theta$$ where $m\in[-1,1],h\in(0,+\infty)$ are constants. Update: I'm now wondering how to evaluate integral in the form of $$\int\frac{\sqrt{x^2+p}}{x^2+q}\text{d}x$$ Thanks everyone, I've solved it.","I have difficulty calculating the following double integral: where are constants. What I've tried with the help of others: let , then the inner part looks like this： let , then the inner part should be: Hence, So, But I have no idea how to deal with: Update: Thanks to @sreysus, we change it to What I've tried: Though it's complicated, I've worked this part out (too complicated to put it here) So I got stuck how to evaluate this part: where are constants. Update: I'm now wondering how to evaluate integral in the form of Thanks everyone, I've solved it.","\int_0^1\int_0^1\sqrt{x^2-2mxy+y^2+h^2}\text{d}x\text{d}y m\in[-1,1],h\in(0,\infty) \begin{align*}
I&=2\int_0^{\frac{\pi}{4}}\int_0^{\sec\theta}r\cdot\sqrt{(1-2m\sin\theta\cos\theta)r^2+h^2}\text{d}r\text{d}\theta
\end{align*} a=1-2m\sin\theta\cos\theta \int r\cdot\sqrt{ar^2+h^2}\text{d}r u=ar^2+h^2 \frac1{2a}\int\sqrt{u}\text{d}u=\frac1{3a}u^{\frac32}=\frac1{3a}(ar^2+h^2)^{\frac32} \begin{align*}
\int_0^{\sec\theta}r\sqrt{ar^2+h^2}\text{d}r
&=\frac1{3a}[(a\sec^2\theta+h^2)^\frac32-h^3 ]\\
&=\frac{(\tan^2\theta-2m\tan\theta+h^2+1)^\frac32-h^3}{3-6m\sin\theta\cos\theta}
\end{align*} \frac23\int_0^\frac{\pi}{4}\frac{(\tan^2\theta-2m\tan\theta+h^2+1)^\frac32-h^3}{1-2m\sin\theta\cos\theta}\text{d}\theta \int_0^{\frac{\pi}{4}}\frac{(\tan^2\theta-2m\tan\theta+h^2+1)^{\frac32}}{1-2m\sin\theta\cos\theta}\text{d}\theta \int_0^{\frac{\pi}{4}}\frac{\sqrt{1-2m\sin\theta\cos\theta+h^2}}{\cos^3\theta}\text{d}\theta+\int_0^{\frac{\pi}{4}}\frac{h^2\sqrt{1-2m\sin\theta\cos\theta+h^2}}{\cos\theta-2m\sin\theta\cos\theta}\text{d}\theta \begin{align*}
\int_0^{\frac{\pi}{4}}\frac{\sqrt{1-2m\sin\theta\cos\theta+h^2}}{\cos^3\theta}\text{d}\theta
&=\int_0^{\frac{\pi}{4}}\frac{\sqrt{1-2m\sin\theta\cos\theta+h^2}}{\cos\theta}\text{d}\tan\theta\\
&=\int_0^{\frac{\pi}{4}}\sqrt{(1+h^2)\sec^2\theta-2m\tan\theta}\text{d}\tan\theta\\
&=\int_0^1\sqrt{(1+h^2)(1+u^2)-2mu}\text{d}u
\end{align*} \int_0^{\frac{\pi}{4}}\frac{h^2\sqrt{1-2m\sin\theta\cos\theta+h^2}}{\cos\theta-2m\sin\theta\cos^2\theta}\text{d}\theta m\in[-1,1],h\in(0,+\infty) \int\frac{\sqrt{x^2+p}}{x^2+q}\text{d}x","['calculus', 'integration', 'trigonometric-integrals']"
77,Changing Variables in Discrete Calculus,Changing Variables in Discrete Calculus,,"In discrete calculus one soon meets the $h$ -difference operator $$\Delta_h[f(x)] = f(x+h) - f(x)$$ and we often define $\Delta = \Delta_1.$ We can similarly define the indefinite sums $\Delta_h^{-1}$ and set $\Delta^{-1} = \Delta_1^{-1}.$ Most books on discrete calculus only include results for $h=1.$ For example, the above link gives that $$\Delta^{-1}\sin rx = \frac{-\cos(r[x-\frac{1}{2}])}{2\sin\frac{r}{2}}$$ Through an ugly computation I managed to work out that $$\Delta_h^{-1}[\sin rx] = \frac{-\cos(r[x-\frac{h}{2}])}{2\sin\frac{rh}{2}}$$ What I'd like is a uniform procedure for recovering the "" $h$ -version"" from such results. How could I have derived the second formula from the first? Is there something like the change of variable formula in calculus? Maybe some version of 'dimensional analysis' that tells you where to insert $h$ 's? As another example, given that $$\Delta[\log x] = \log(1 + \frac{1}{x})$$ I'd like to be able to see immediately that $$\Delta_h[\log x] = \log(1 + \frac{h}{x})$$ Any help or references would be welcome.","In discrete calculus one soon meets the -difference operator and we often define We can similarly define the indefinite sums and set Most books on discrete calculus only include results for For example, the above link gives that Through an ugly computation I managed to work out that What I'd like is a uniform procedure for recovering the "" -version"" from such results. How could I have derived the second formula from the first? Is there something like the change of variable formula in calculus? Maybe some version of 'dimensional analysis' that tells you where to insert 's? As another example, given that I'd like to be able to see immediately that Any help or references would be welcome.",h \Delta_h[f(x)] = f(x+h) - f(x) \Delta = \Delta_1. \Delta_h^{-1} \Delta^{-1} = \Delta_1^{-1}. h=1. \Delta^{-1}\sin rx = \frac{-\cos(r[x-\frac{1}{2}])}{2\sin\frac{r}{2}} \Delta_h^{-1}[\sin rx] = \frac{-\cos(r[x-\frac{h}{2}])}{2\sin\frac{rh}{2}} h h \Delta[\log x] = \log(1 + \frac{1}{x}) \Delta_h[\log x] = \log(1 + \frac{h}{x}),"['calculus', 'discrete-mathematics', 'summation', 'finite-differences', 'discrete-calculus']"
78,Is there any closed form for the integral $\int_0^{\frac{\pi}{2}} \frac{\ln ^n(\sin x) \ln ^m(\cos x)}{\tan x} d x?$,Is there any closed form for the integral,\int_0^{\frac{\pi}{2}} \frac{\ln ^n(\sin x) \ln ^m(\cos x)}{\tan x} d x?,"Inspired by the question in the post , I started to generalise the integral $$ \begin{aligned} \int_0^{\frac{\pi}{2}} \frac{\ln^n (\sin x) \ln (\cos x)}{\tan x} d x =& \frac{1}{n+1} \int_0^{\frac{\pi}{2}} \ln (\cos x) d\left(\ln ^{n+1}(\sin x)\right) \\ =& \frac{1}{n+1}\left[\ln (\cos x) \ln ^{n+1}(\sin x)\right]_0^{\frac{\pi}{2}}+\frac{1}{n+1} \int_0^{\frac{\pi}{2}} \frac{\sin x \ln ^{n+1}\left(\sin x\right)}{\cos x} d x\\\stackrel{IBP}{=} &\frac{1}{2^{n+2}(n+1)} \int_0^{\frac{\pi}{2}} \frac{\ln ^{n+1}\left(\sin ^2 x\right)}{\cos ^2 x} d\left(\sin ^2 x\right)\\=& \frac{1}{2^{n+2}(n+1)} \int_0^{1} \frac{\ln ^{n+1} y}{1-y} d y \quad \textrm{ where }y=\sin^2 x\end{aligned} $$ We then deal the last integral using an infinite series on the integral $$ \begin{aligned} \int_0^1 \frac{y^a}{1-y} d y=\sum_{k=0}^{\infty} \int_0^1 y ^a\cdot y^k d y =\sum_{k=1}^{\infty} \frac{1}{a+k} \end{aligned} $$ Differentiating both sides w.r.t. $a$ by $n$ times yields $$ \int_0^1 \frac{\ln^{n+1} y}{1-y} d y=\left.\frac{\partial^{n+1}}{\partial a^{n+1}} \int_0^1 \frac{y^a}{1-y} d t\right|_{a=0} =(-1)^{n+1}(n+1) ! \sum_{k=1}^{\infty} \frac{1}{k^{n+2}}= (-1)^{n+1}(n+1) !\zeta(n+2) $$ Then we can conclude that $$\boxed{\int_0^{\frac{\pi}{2}} \frac{\ln^n (\sin x) \ln (\cos x)}{\tan x} d x = \frac{(-1)^{n+1} n !}{2^{n+2}} \zeta(n+2)} $$ For examples, $$ \begin{aligned} &I_1=\frac{1}{8} \zeta(3);\quad  I_2=-\frac{1}{16} \cdot 2 \cdot \zeta(4)=-\frac{\pi^4}{720} ;\quad  I_{12}=-\frac{12 !}{2^{14} }\zeta(12)=-\frac{691 \pi^{12}}{21840} \end{aligned} $$ Similarly, I want to generalise the integral further as $$I(n,m)=\int_0^{\frac{\pi}{2}} \frac{\ln ^n(\sin x) \ln ^m(\cos x)}{\tan x} d x =\frac{m}{2^{n+m}(n+1)} \int_0^1 \frac{\ln ^{n+1} y \ln ^{m-1}(1-y)}{1-y} d y $$ Noticing that $$ \begin{aligned} \int_0^1 y^a(1-y)^bd y =& \int_0^1 y^a(1-y)^{b} d y =B(a+1, b+1) \end{aligned} $$ Therefore $$ \boxed{I(n, m)= \frac{1}{2^{n+2}(n+1)} \left.\frac{\partial^{n+1}}{\partial a^{n+1}} \frac{\partial^{m-1}}{\partial b^{m-1}}\left(\frac{\Gamma(a+1) \Gamma(b+1)}{\Gamma(a+b+2)}\right)\right|_{a=0,b=-1}} $$ My question: Is there a closed form for the last high derivative? Your comments and suggestions are highly appreciated.","Inspired by the question in the post , I started to generalise the integral We then deal the last integral using an infinite series on the integral Differentiating both sides w.r.t. by times yields Then we can conclude that For examples, Similarly, I want to generalise the integral further as Noticing that Therefore My question: Is there a closed form for the last high derivative? Your comments and suggestions are highly appreciated.","
\begin{aligned}
\int_0^{\frac{\pi}{2}} \frac{\ln^n (\sin x) \ln (\cos x)}{\tan x} d x =& \frac{1}{n+1} \int_0^{\frac{\pi}{2}} \ln (\cos x) d\left(\ln ^{n+1}(\sin x)\right) \\
=& \frac{1}{n+1}\left[\ln (\cos x) \ln ^{n+1}(\sin x)\right]_0^{\frac{\pi}{2}}+\frac{1}{n+1} \int_0^{\frac{\pi}{2}} \frac{\sin x \ln ^{n+1}\left(\sin x\right)}{\cos x} d x\\\stackrel{IBP}{=} &\frac{1}{2^{n+2}(n+1)} \int_0^{\frac{\pi}{2}} \frac{\ln ^{n+1}\left(\sin ^2 x\right)}{\cos ^2 x} d\left(\sin ^2 x\right)\\=& \frac{1}{2^{n+2}(n+1)} \int_0^{1} \frac{\ln ^{n+1} y}{1-y} d y \quad \textrm{ where }y=\sin^2 x\end{aligned}
 
\begin{aligned}
\int_0^1 \frac{y^a}{1-y} d y=\sum_{k=0}^{\infty} \int_0^1 y ^a\cdot y^k d y =\sum_{k=1}^{\infty} \frac{1}{a+k}
\end{aligned}
 a n 
\int_0^1 \frac{\ln^{n+1} y}{1-y} d y=\left.\frac{\partial^{n+1}}{\partial a^{n+1}} \int_0^1 \frac{y^a}{1-y} d t\right|_{a=0} =(-1)^{n+1}(n+1) ! \sum_{k=1}^{\infty} \frac{1}{k^{n+2}}= (-1)^{n+1}(n+1) !\zeta(n+2)
 \boxed{\int_0^{\frac{\pi}{2}} \frac{\ln^n (\sin x) \ln (\cos x)}{\tan x} d x = \frac{(-1)^{n+1} n !}{2^{n+2}} \zeta(n+2)}  
\begin{aligned}
&I_1=\frac{1}{8} \zeta(3);\quad  I_2=-\frac{1}{16} \cdot 2 \cdot \zeta(4)=-\frac{\pi^4}{720} ;\quad  I_{12}=-\frac{12 !}{2^{14} }\zeta(12)=-\frac{691 \pi^{12}}{21840}
\end{aligned}
 I(n,m)=\int_0^{\frac{\pi}{2}} \frac{\ln ^n(\sin x) \ln ^m(\cos x)}{\tan x} d x =\frac{m}{2^{n+m}(n+1)} \int_0^1 \frac{\ln ^{n+1} y \ln ^{m-1}(1-y)}{1-y} d y  
\begin{aligned}
\int_0^1 y^a(1-y)^bd y =& \int_0^1 y^a(1-y)^{b} d y =B(a+1, b+1)
\end{aligned}
 
\boxed{I(n, m)= \frac{1}{2^{n+2}(n+1)} \left.\frac{\partial^{n+1}}{\partial a^{n+1}} \frac{\partial^{m-1}}{\partial b^{m-1}}\left(\frac{\Gamma(a+1) \Gamma(b+1)}{\Gamma(a+b+2)}\right)\right|_{a=0,b=-1}}
","['calculus', 'integration', 'improper-integrals', 'gamma-function', 'trigonometric-integrals']"
79,Find the smallest value of $\alpha\in \mathbb{R}$ such that for all $x>0$ you have $\left(1+\frac{1}{x}\right)^{x+\alpha}>e$,Find the smallest value of  such that for all  you have,\alpha\in \mathbb{R} x>0 \left(1+\frac{1}{x}\right)^{x+\alpha}>e,"Find the smallest value of $\alpha\in \mathbb{R}$ such that for all $x>0$ you have $$\left(1+\frac{1}{x}\right)^{x+\alpha}>e$$ By now i have tried the usual, taking logarithm and trying to solve for alpha, there i get the next condition: $$\alpha>\frac{1-\ln\left(1+\frac{1}{x}\right)^x}{\ln\left(1+\frac{1}{x}\right)}$$ so the problem now is to maximize this function, but i didn't get it through standar ways. I know that $\lim_{x\to \infty}f(x)=\frac12$ (where $f$ is the last function), but to say that $\frac12$ is the supremum i need to prove that it's increasing or bounded by $\frac{1}{2}$ and i didn't got any of those two things.","Find the smallest value of such that for all you have By now i have tried the usual, taking logarithm and trying to solve for alpha, there i get the next condition: so the problem now is to maximize this function, but i didn't get it through standar ways. I know that (where is the last function), but to say that is the supremum i need to prove that it's increasing or bounded by and i didn't got any of those two things.",\alpha\in \mathbb{R} x>0 \left(1+\frac{1}{x}\right)^{x+\alpha}>e \alpha>\frac{1-\ln\left(1+\frac{1}{x}\right)^x}{\ln\left(1+\frac{1}{x}\right)} \lim_{x\to \infty}f(x)=\frac12 f \frac12 \frac{1}{2},"['calculus', 'optimization']"
80,A Proof Related to the Fundamental Theorem of Calculus,A Proof Related to the Fundamental Theorem of Calculus,,"Let $f$ be continuous on $\mathbb{R}$ .   Due to FTC I, we know that a function of the form∗ $F(x) = \int_a^xf(t)\operatorname dt$ is always an antiderivative of $f(x)$ . In this   question you will investigate whether all antiderivatives of $f(x)$ can be expressed in this form∗.   For simplicity, let us further assume $f$ is non-negative $(i.e. ∀x ∈ \mathbb{R}, f(x) ≥ 0)$ . (a) Suppose $\lim\limits _{A\rightarrow\infty}\int_0^Af(t)\operatorname dt$ or $\lim\limits _{A\rightarrow-\infty}\int_A^0f(t)\operatorname dt$ is finite, show there is an antiderivative $G(x)$ of $f(x)$ which does   not equal $\int_a^xf(t)\operatorname dt$ for any a $\in \mathbb{R}$ (b)Suppose $\lim\limits _{A\rightarrow\infty}\int_0^Af(t)\operatorname dt=\infty$ and $\lim\limits _{A\rightarrow-\infty}\int_A^0f(t)\operatorname dt=\infty$ , show for any antiderivative $G(x)$ of $f(x), ∃a ∈ \mathbb{R} \text{ s.t.} G(x) = \int_a^xf(t)\operatorname dt$ Hint: Think about whether antiderivatives of f(x) need to have zeroes. What I have tried so far: Look thorugh (a) and (b), it's saying if $f$ is continuous on $\mathbb{R}$ we have: $(\lim\limits _{A\rightarrow\infty}\int_0^Af(t)\operatorname dt=\pm\infty \wedge \lim\limits _{A\rightarrow-\infty}\int_A^0f(t)\operatorname dt=\pm\infty )\leftrightarrow \forall G(x), ∃a ∈ R \text{ s.t.} G(x) = \int_a^xf(t)\operatorname dt$ (This is a stronger version of the question, since negation of finite also include $-\infty$ , I'm not sure if this is still true, but this should implies what the question is asking to prove) By assumption, $f$ is non-negative, then we don't need to consider the $-\infty$ cases, just show the following would be sufficient: $(\lim\limits _{A\rightarrow\infty}\int_0^Af(t)\operatorname dt=\infty \wedge \lim\limits _{A\rightarrow-\infty}\int_A^0f(t)\operatorname dt=\infty )\leftrightarrow \forall G(x), ∃a ∈ R \text{ s.t.} G(x) = \int_a^xf(t)\operatorname dt$ I don't have the Intuition of why this is true, at least it's not very trivial to me.. So, first I tried to break it into definitions: 1. $\lim\limits _{A\rightarrow\infty}\int_0^Af(t)\operatorname dt=\pm\infty$ $\Leftrightarrow \forall N\in \mathbb{R},\exists M\in \mathbb{R} s.t. A>M\rightarrow(\int_0^Af(t)\operatorname dt>N\vee \int_0^Af(t)\operatorname dt<N)$ 2. $\lim\limits _{A\rightarrow-\infty}\int_A^0f(t)\operatorname dt=\pm\infty$ $\Leftrightarrow \forall N\in \mathbb{R},\exists M\in \mathbb{R} s.t. A<M\rightarrow(\int_0^Af(t)\operatorname dt>N\vee \int_0^Af(t)\operatorname dt<N)$ 3. $\forall G(x), ∃a ∈ R \text{ s.t.}G(x) = \int_a^xf(t)\operatorname dt$ (not sure about this one) $\Leftrightarrow\forall G(x), ∃a ∈ R \text{ s.t.}\forall n \in \mathbb{R}, \forall \varepsilon>0, \exists \delta>0\text{ s.t. } \exists P\in \mathbb{P}$ s.t. $( \text{$P$ is a partition of [a,n]} \wedge l(P)<\delta)\rightarrow|S(f(t),P)-G(n)|<\varepsilon$ But those doesn't looks like very useful...where should I start? Any help or hint or suggestion would be appreciated.","Let be continuous on .   Due to FTC I, we know that a function of the form∗ is always an antiderivative of . In this   question you will investigate whether all antiderivatives of can be expressed in this form∗.   For simplicity, let us further assume is non-negative . (a) Suppose or is finite, show there is an antiderivative of which does   not equal for any a (b)Suppose and , show for any antiderivative of Hint: Think about whether antiderivatives of f(x) need to have zeroes. What I have tried so far: Look thorugh (a) and (b), it's saying if is continuous on we have: (This is a stronger version of the question, since negation of finite also include , I'm not sure if this is still true, but this should implies what the question is asking to prove) By assumption, is non-negative, then we don't need to consider the cases, just show the following would be sufficient: I don't have the Intuition of why this is true, at least it's not very trivial to me.. So, first I tried to break it into definitions: 1. 2. 3. (not sure about this one) s.t. But those doesn't looks like very useful...where should I start? Any help or hint or suggestion would be appreciated.","f \mathbb{R} F(x) = \int_a^xf(t)\operatorname dt f(x) f(x) f (i.e. ∀x ∈ \mathbb{R}, f(x) ≥ 0) \lim\limits _{A\rightarrow\infty}\int_0^Af(t)\operatorname dt \lim\limits _{A\rightarrow-\infty}\int_A^0f(t)\operatorname dt G(x) f(x) \int_a^xf(t)\operatorname dt \in \mathbb{R} \lim\limits _{A\rightarrow\infty}\int_0^Af(t)\operatorname dt=\infty \lim\limits _{A\rightarrow-\infty}\int_A^0f(t)\operatorname dt=\infty G(x) f(x), ∃a ∈ \mathbb{R} \text{ s.t.}
G(x) = \int_a^xf(t)\operatorname dt f \mathbb{R} (\lim\limits _{A\rightarrow\infty}\int_0^Af(t)\operatorname dt=\pm\infty \wedge \lim\limits _{A\rightarrow-\infty}\int_A^0f(t)\operatorname dt=\pm\infty )\leftrightarrow \forall G(x), ∃a ∈ R \text{ s.t.}
G(x) = \int_a^xf(t)\operatorname dt -\infty f -\infty (\lim\limits _{A\rightarrow\infty}\int_0^Af(t)\operatorname dt=\infty \wedge \lim\limits _{A\rightarrow-\infty}\int_A^0f(t)\operatorname dt=\infty )\leftrightarrow \forall G(x), ∃a ∈ R \text{ s.t.}
G(x) = \int_a^xf(t)\operatorname dt \lim\limits _{A\rightarrow\infty}\int_0^Af(t)\operatorname dt=\pm\infty \Leftrightarrow \forall N\in \mathbb{R},\exists M\in \mathbb{R} s.t. A>M\rightarrow(\int_0^Af(t)\operatorname dt>N\vee \int_0^Af(t)\operatorname dt<N) \lim\limits _{A\rightarrow-\infty}\int_A^0f(t)\operatorname dt=\pm\infty \Leftrightarrow \forall N\in \mathbb{R},\exists M\in \mathbb{R} s.t. A<M\rightarrow(\int_0^Af(t)\operatorname dt>N\vee \int_0^Af(t)\operatorname dt<N) \forall G(x), ∃a ∈ R \text{ s.t.}G(x) = \int_a^xf(t)\operatorname dt \Leftrightarrow\forall G(x), ∃a ∈ R \text{ s.t.}\forall n \in \mathbb{R}, \forall \varepsilon>0, \exists \delta>0\text{ s.t. } \exists P\in \mathbb{P} ( \text{P is a partition of [a,n]} \wedge l(P)<\delta)\rightarrow|S(f(t),P)-G(n)|<\varepsilon","['calculus', 'integration', 'limits', 'definite-integrals', 'definition']"
81,contour integration $\int_C \frac{\ln^2 z}{\sqrt{z}(1+z^2)}$(1 Short answer),contour integration (1 Short answer),\int_C \frac{\ln^2 z}{\sqrt{z}(1+z^2)},"I solved this question and had a try as shown ... i got similar form ... but not getting correct answer. here is the question: Question 3. $\quad$ (a) By considering the integral of $z^{-1/2}\log^2(z)/(1+z^2)$ around a suitably chosen contour in the cut $z$ plane, prove that $$\int_0^{\infty}\frac{\log^2(t) - \pi^2}{t^{1/2}(1+t^2)}dt = -\frac{\pi^3}{4\sqrt{2}}$$ $\quad$ In your solution, include a diagram that clearly specifies the contour you are using and provide a careful discussion of all required estimates of contributions from contours that you will discard when an appropriate limit is taken. $\quad$ (b) Using the same integration contour as in part (a) with the integrand $z^{-1/2}\log^2(z)/(1-z)$ , find a relation between the integrals $$\int_0^{\infty}\frac{\log^2(t)}{t^{1/2}(1+t)}dt \quad\text{ and }\quad \int_0^{\infty}\frac{dt}{t^{1/2}(1+t)}.$$ $\quad$ Use this relation to deduce, without further contour integration, that $$\int_0^{1}\frac{\log^2(t)}{t^{1/2}(1+t)}dt = \frac{\pi^3}{2}.$$ Here is what I have so far: $\quad$ Ans 3. a) $$\int_0^{\infty}\frac{log^2(t) - \pi^2}{\sqrt{t}(1+t^2)}dt$$ $$\begin{multline}   \shoveleft \text{Consider} \quad f(z) = \frac{log^2(z)}{\sqrt{z}(1+z^2)} \\   \shoveleft \text{Consider} \quad \int_Cf(z)dz \qquad \text{along the C as shown below}   \end{multline}$$ $$\begin{multline}   \shoveleft \text{Poles are at } z = 0 \text{ (not lies[sic] in contour)}, \quad z = \pm i \\    \shoveleft \text{Res }f(z=i) \quad \space \space \space = \quad \lim_{z \rightarrow i}\frac{(z-i)log^2(z)}{\sqrt{z}(z-i)(z+i)} \space = e^{i\pi /4}\frac{\pi^2}{8} \\   \shoveleft \text{Res }f(z=-i) \quad = \quad \lim_{z \rightarrow -i}\frac{(z+i)log^2(z)}{\sqrt{z}(z-i)(z+i)} = -e^{3i\pi /4}\frac{\pi^2}{8} \\   \shoveleft \therefore \quad \int_{C}f(z)dz = 2\pi i\left[\frac{\pi^2}{8}(e^{i\pi /4} - e^{3i\pi /4}) \right] = \frac{i\pi^3}{2\sqrt{2}} \\   \shoveleft \\   \shoveleft \text{Thus,} \\   \shoveleft \quad \int_{AB}f(z)dz + \int_{\Gamma}f(z)dz + \int_{FG}f(z)dz + \int_{\gamma}f(z)dz = \frac{i\pi^3}{2\sqrt{2}} \\   \shoveleft \\   \shoveleft \text{On AB: } z = x \quad \text{and on FG: } z = xe^{2\pi i} \\   \shoveleft \therefore \quad \int_{AB}f(z)dz + \int_{FG}f(z)dz = \int_{r}^{R}\frac{log^2x}{\sqrt{x}(1+x^2)}dx + \int_{R}^{r}\frac{\left( log(xe^{2\pi i}) \right)^2e^{2\pi i}}{\sqrt{xe^{2\pi i}}(1+x^2e^{2\pi i})}dx \\   \shoveleft \\   \shoveleft = \int_{r}^{R}\frac{log^2x}{\sqrt{x}(1+x^2)}dx + \int_{R}^{r}\frac{log^2x - 4\pi^2 +4\pi log(x)i}{\sqrt{x}e^{\pi i}(1+x^2)}dx \\   \shoveleft \\   \shoveleft = \int_{r}^{R}\frac{log^2x}{\sqrt{x}(1+x^2)}dx \ + \space \int_{r}^{R}\frac{log^2x - 4\pi^2 + 4\pi log(x)i}{\sqrt{x}(1+x^2)}dx \quad \because \space e^{\pi i} = -1 \\   \shoveleft \\   \shoveleft = \int_{r}^{R}\frac{2log^2x - 4\pi^2 - 4\pi log(x)i}{\sqrt{x}(1+x^2)}dx \\   \end{multline}$$ $$\begin{multline}   \shoveleft \\   \shoveleft \text{For the circle } \gamma : \space z = re^{i \theta} \\   \shoveleft \text{So, } \int_{\gamma}f(z)dz = \int_{2\pi}^{0} \frac{\left( log(re^{i \theta})\right)^2(rie^{i \theta})}{\sqrt{re^{i \theta}}(1 + r^2 e^{2i \theta})}d\theta = \int_{2\pi}^{0}\frac{\sqrt{r}*ie^{i \theta}*log^2(re^{i \theta})}{e^{i\theta /2}(1 + r^2e^{2i\theta})}d\theta \\   \shoveleft \text{Clearly, if } r \rightarrow 0, \space \int_{\gamma}f(z)dz \rightarrow 0 \\   \end{multline}$$ $$\begin{multline}   \shoveleft \\   \shoveleft \text{Now, on the circle } \Gamma : \space z = Re^{i\theta} \\   \shoveleft \text{So, } \int_{\Gamma}f(z)dz = \int_{0}^{2\pi} \frac{\left( log(Re^{i \theta})\right)^2(Rie^{i \theta})}{\sqrt{Re^{i \theta}}(1 + R^2 e^{2i \theta})}d\theta = \int_{0}^{2\pi}\frac{\sqrt{R}*ie^{i \theta /2}*log^2(Re^{i \theta})}{e^{i\theta /2}(1 + R^2e^{2i\theta})}d\theta \\   \shoveleft = \int_{0}^{2\pi}\frac{ie^{i\theta /2}*log^2(Re^{i\theta})}{R^{3/2}\left(\frac{1}{R^2} + e^{2i\theta}\right)}d\theta \\   \shoveleft \text{if } R \rightarrow \infty, \space \int_{\Gamma}f(z)dz \rightarrow 0 \\   \shoveleft \\   \shoveleft \text{So, we have } \\   \shoveleft \quad \int_{0}^{\infty}\frac{2log^2x - 4\pi^2 +4\pi log(x)i}{\sqrt{x}(1+x^2)}dx = \frac{i\pi^3}{2\sqrt{2}} \\   \shoveleft \quad \qquad \implies +\int_{0}^{\infty}\frac{4\pi log(x)}{\sqrt{x}(1+x^2)}dx = \frac{\pi^3}{2\sqrt{2}} \\   \shoveleft \space \space \qquad \quad \qquad \text{or } \int_{0}^{\infty}\frac{log(x)}{\sqrt{x}(1+x^2)}dx = \frac{\pi^2}{2\sqrt{2}}   \end{multline}$$ I don't understand the explanation in the solution, can anyone explain where is my mistake ? How to arrive at the answer?","I solved this question and had a try as shown ... i got similar form ... but not getting correct answer. here is the question: Question 3. (a) By considering the integral of around a suitably chosen contour in the cut plane, prove that In your solution, include a diagram that clearly specifies the contour you are using and provide a careful discussion of all required estimates of contributions from contours that you will discard when an appropriate limit is taken. (b) Using the same integration contour as in part (a) with the integrand , find a relation between the integrals Use this relation to deduce, without further contour integration, that Here is what I have so far: Ans 3. a) I don't understand the explanation in the solution, can anyone explain where is my mistake ? How to arrive at the answer?","\quad z^{-1/2}\log^2(z)/(1+z^2) z \int_0^{\infty}\frac{\log^2(t) - \pi^2}{t^{1/2}(1+t^2)}dt = -\frac{\pi^3}{4\sqrt{2}} \quad \quad z^{-1/2}\log^2(z)/(1-z) \int_0^{\infty}\frac{\log^2(t)}{t^{1/2}(1+t)}dt \quad\text{ and }\quad \int_0^{\infty}\frac{dt}{t^{1/2}(1+t)}. \quad \int_0^{1}\frac{\log^2(t)}{t^{1/2}(1+t)}dt = \frac{\pi^3}{2}. \quad \int_0^{\infty}\frac{log^2(t) - \pi^2}{\sqrt{t}(1+t^2)}dt \begin{multline}
  \shoveleft \text{Consider} \quad f(z) = \frac{log^2(z)}{\sqrt{z}(1+z^2)} \\
  \shoveleft \text{Consider} \quad \int_Cf(z)dz \qquad \text{along the C as shown below}
  \end{multline} \begin{multline}
  \shoveleft \text{Poles are at } z = 0 \text{ (not lies[sic] in contour)}, \quad z = \pm i \\ 
  \shoveleft \text{Res }f(z=i) \quad \space \space \space = \quad \lim_{z \rightarrow i}\frac{(z-i)log^2(z)}{\sqrt{z}(z-i)(z+i)} \space = e^{i\pi /4}\frac{\pi^2}{8} \\
  \shoveleft \text{Res }f(z=-i) \quad = \quad \lim_{z \rightarrow -i}\frac{(z+i)log^2(z)}{\sqrt{z}(z-i)(z+i)} = -e^{3i\pi /4}\frac{\pi^2}{8} \\
  \shoveleft \therefore \quad \int_{C}f(z)dz = 2\pi i\left[\frac{\pi^2}{8}(e^{i\pi /4} - e^{3i\pi /4}) \right] = \frac{i\pi^3}{2\sqrt{2}} \\
  \shoveleft \\
  \shoveleft \text{Thus,} \\
  \shoveleft \quad \int_{AB}f(z)dz + \int_{\Gamma}f(z)dz + \int_{FG}f(z)dz + \int_{\gamma}f(z)dz = \frac{i\pi^3}{2\sqrt{2}} \\
  \shoveleft \\
  \shoveleft \text{On AB: } z = x \quad \text{and on FG: } z = xe^{2\pi i} \\
  \shoveleft \therefore \quad \int_{AB}f(z)dz + \int_{FG}f(z)dz = \int_{r}^{R}\frac{log^2x}{\sqrt{x}(1+x^2)}dx + \int_{R}^{r}\frac{\left( log(xe^{2\pi i}) \right)^2e^{2\pi i}}{\sqrt{xe^{2\pi i}}(1+x^2e^{2\pi i})}dx \\
  \shoveleft \\
  \shoveleft = \int_{r}^{R}\frac{log^2x}{\sqrt{x}(1+x^2)}dx + \int_{R}^{r}\frac{log^2x - 4\pi^2 +4\pi log(x)i}{\sqrt{x}e^{\pi i}(1+x^2)}dx \\
  \shoveleft \\
  \shoveleft = \int_{r}^{R}\frac{log^2x}{\sqrt{x}(1+x^2)}dx \ + \space \int_{r}^{R}\frac{log^2x - 4\pi^2 + 4\pi log(x)i}{\sqrt{x}(1+x^2)}dx \quad \because \space e^{\pi i} = -1 \\
  \shoveleft \\
  \shoveleft = \int_{r}^{R}\frac{2log^2x - 4\pi^2 - 4\pi log(x)i}{\sqrt{x}(1+x^2)}dx \\
  \end{multline} \begin{multline}
  \shoveleft \\
  \shoveleft \text{For the circle } \gamma : \space z = re^{i \theta} \\
  \shoveleft \text{So, } \int_{\gamma}f(z)dz = \int_{2\pi}^{0} \frac{\left( log(re^{i \theta})\right)^2(rie^{i \theta})}{\sqrt{re^{i \theta}}(1 + r^2 e^{2i \theta})}d\theta = \int_{2\pi}^{0}\frac{\sqrt{r}*ie^{i \theta}*log^2(re^{i \theta})}{e^{i\theta /2}(1 + r^2e^{2i\theta})}d\theta \\
  \shoveleft \text{Clearly, if } r \rightarrow 0, \space \int_{\gamma}f(z)dz \rightarrow 0 \\
  \end{multline} \begin{multline}
  \shoveleft \\
  \shoveleft \text{Now, on the circle } \Gamma : \space z = Re^{i\theta} \\
  \shoveleft \text{So, } \int_{\Gamma}f(z)dz = \int_{0}^{2\pi} \frac{\left( log(Re^{i \theta})\right)^2(Rie^{i \theta})}{\sqrt{Re^{i \theta}}(1 + R^2 e^{2i \theta})}d\theta = \int_{0}^{2\pi}\frac{\sqrt{R}*ie^{i \theta /2}*log^2(Re^{i \theta})}{e^{i\theta /2}(1 + R^2e^{2i\theta})}d\theta \\
  \shoveleft = \int_{0}^{2\pi}\frac{ie^{i\theta /2}*log^2(Re^{i\theta})}{R^{3/2}\left(\frac{1}{R^2} + e^{2i\theta}\right)}d\theta \\
  \shoveleft \text{if } R \rightarrow \infty, \space \int_{\Gamma}f(z)dz \rightarrow 0 \\
  \shoveleft \\
  \shoveleft \text{So, we have } \\
  \shoveleft \quad \int_{0}^{\infty}\frac{2log^2x - 4\pi^2 +4\pi log(x)i}{\sqrt{x}(1+x^2)}dx = \frac{i\pi^3}{2\sqrt{2}} \\
  \shoveleft \quad \qquad \implies +\int_{0}^{\infty}\frac{4\pi log(x)}{\sqrt{x}(1+x^2)}dx = \frac{\pi^3}{2\sqrt{2}} \\
  \shoveleft \space \space \qquad \quad \qquad \text{or } \int_{0}^{\infty}\frac{log(x)}{\sqrt{x}(1+x^2)}dx = \frac{\pi^2}{2\sqrt{2}}
  \end{multline}","['calculus', 'integration', 'complex-analysis', 'contour-integration', 'residue-calculus']"
82,"Does $\lim_{x \to \infty} f(x) = 0$ imply $\int_\delta^\infty \frac{f(x)}{x}\, dx$ converges?",Does  imply  converges?,"\lim_{x \to \infty} f(x) = 0 \int_\delta^\infty \frac{f(x)}{x}\, dx","I'm interested in knowing whether there's a ""largest"" function $f: [\delta, \infty) \to \mathbb{R_{>0}}$ , where $\delta> 0$ , such that $$\int_\delta^{\infty} \frac{f(x)}{x}\, dx < \infty$$ converges. (""Largest"" here is in the sense of big-O asymptotics.) In particular, I'd like to know whether the smallest functions for which this integral diverges are the constant functions. Obviously, any function for which the integral converges must satisfy $f(x) = o(1)$ ; that is to say, $\lim_{x \to \infty} f(x) = 0$ . Any $f$ that satisfies $f = O(x^{-\epsilon})$ for some $\epsilon > 0$ , conversely, obviously works. One can further construct large families of functions $f$ asymptotically between $1$ and any $x^{-\epsilon}$ ; that is, such that $f = o(1)$ but $x^{-\epsilon} = o(f)$ for every $\epsilon > 0$ . (For example, pick two sequences of positive real numbers $a_n, b_n$ both tending to zero, and define $f(x) = \max a_n x^{-b_n}$ .) My one explicit attempt to construct a function $f$ along these lines, though, still gave a finite integral of $\frac{f(x)}{x}\, dx$ . Define: \begin{align*} f(x) = \begin{cases} x^{-1} & x \in [2, 4] \\ \frac{1}{2} x^{-1/2} & x \in [4, 16] \\ \frac{1}{4} x^{-1/4} & x \in [16, 256] \\ \frac{1}{8} x^{-1/8} & x \in [256, 65536] \\ \vdots & \vdots \\ 2^{-n} x^{-1/2^n} & x \in [2^{2^n}, 2^{2^{n+1}}] \\ \vdots & \vdots \end{cases} \end{align*} Then \begin{align*} \int_2^\infty \frac{f(x)}{x}\, dx &= \sum_{n=0}^\infty \frac{1}{2^n} \int_{2^{2^n}}^{2^{2^{n+1}}} x^{-1-1/2^n}\,dx \\ &= -\sum_{n=0}^\infty \left. x^{-1/2^n}\right|_{x=2^{2^n}}^{x=2^{2^{n+1}}} \\ &= \sum_{n=0}^\infty \left( \frac{1}{2^{2^n - n}} - \frac{1}{2^{2^{n+1} - n}} \right) \\ &< \sum_{n=0}^\infty \frac{1}{2^{2^n - n}} \\ &< \sum_{n=0}^\infty \frac{1}{2^n} = 2.  \end{align*}","I'm interested in knowing whether there's a ""largest"" function , where , such that converges. (""Largest"" here is in the sense of big-O asymptotics.) In particular, I'd like to know whether the smallest functions for which this integral diverges are the constant functions. Obviously, any function for which the integral converges must satisfy ; that is to say, . Any that satisfies for some , conversely, obviously works. One can further construct large families of functions asymptotically between and any ; that is, such that but for every . (For example, pick two sequences of positive real numbers both tending to zero, and define .) My one explicit attempt to construct a function along these lines, though, still gave a finite integral of . Define: Then","f: [\delta, \infty) \to \mathbb{R_{>0}} \delta> 0 \int_\delta^{\infty} \frac{f(x)}{x}\, dx < \infty f(x) = o(1) \lim_{x \to \infty} f(x) = 0 f f = O(x^{-\epsilon}) \epsilon > 0 f 1 x^{-\epsilon} f = o(1) x^{-\epsilon} = o(f) \epsilon > 0 a_n, b_n f(x) = \max a_n x^{-b_n} f \frac{f(x)}{x}\, dx \begin{align*}
f(x) = \begin{cases}
x^{-1} & x \in [2, 4] \\
\frac{1}{2} x^{-1/2} & x \in [4, 16] \\
\frac{1}{4} x^{-1/4} & x \in [16, 256] \\
\frac{1}{8} x^{-1/8} & x \in [256, 65536] \\
\vdots & \vdots \\
2^{-n} x^{-1/2^n} & x \in [2^{2^n}, 2^{2^{n+1}}] \\
\vdots & \vdots
\end{cases}
\end{align*} \begin{align*}
\int_2^\infty \frac{f(x)}{x}\, dx &= \sum_{n=0}^\infty \frac{1}{2^n} \int_{2^{2^n}}^{2^{2^{n+1}}} x^{-1-1/2^n}\,dx \\
&= -\sum_{n=0}^\infty \left. x^{-1/2^n}\right|_{x=2^{2^n}}^{x=2^{2^{n+1}}} \\
&= \sum_{n=0}^\infty \left( \frac{1}{2^{2^n - n}} - \frac{1}{2^{2^{n+1} - n}} \right) \\
&< \sum_{n=0}^\infty \frac{1}{2^{2^n - n}} \\
&< \sum_{n=0}^\infty \frac{1}{2^n} = 2. 
\end{align*}","['calculus', 'asymptotics']"
83,How to move forward in Mathematics Studies with poor foundation,How to move forward in Mathematics Studies with poor foundation,,"So I discovered halfway through my first year university math term that my foundation of mathematics is very poor. I would memorize stuff rather than understand it and still get 95+ in high school so that's what I did. I quickly realized that doesn't work at all in university. It's embarrassing but I didn't really even know what a derivative really meant and I'm in University Math! Anyways, I passed my math courses barely with 60-70, and did way better on the finals than I did on my midterms which is a sign that I'm heading in the right direction (I went back and looked at a whole bunch of khan academy high school math concepts) but it was hard to juggle doing that and keeping up with current stuff in class. So now the term is over and I want to prepare for next term. My question is, should I go back and review basically all the high school stuff I memorized (and forgot), or should I just start studying the new material by reading the textbook ahead and actually understanding the concepts through practice this time? (The 2 math classes I had this previous term was Calculus 1 and Algebra/Proofs, and my next 2 classes are Linear Algebra and Calculus 2) Thanks!","So I discovered halfway through my first year university math term that my foundation of mathematics is very poor. I would memorize stuff rather than understand it and still get 95+ in high school so that's what I did. I quickly realized that doesn't work at all in university. It's embarrassing but I didn't really even know what a derivative really meant and I'm in University Math! Anyways, I passed my math courses barely with 60-70, and did way better on the finals than I did on my midterms which is a sign that I'm heading in the right direction (I went back and looked at a whole bunch of khan academy high school math concepts) but it was hard to juggle doing that and keeping up with current stuff in class. So now the term is over and I want to prepare for next term. My question is, should I go back and review basically all the high school stuff I memorized (and forgot), or should I just start studying the new material by reading the textbook ahead and actually understanding the concepts through practice this time? (The 2 math classes I had this previous term was Calculus 1 and Algebra/Proofs, and my next 2 classes are Linear Algebra and Calculus 2) Thanks!",,"['calculus', 'education']"
84,On the integral $\int_1^\infty\big(\{x\}^n-\frac1{n+1}\big)\frac{dx}x$,On the integral,\int_1^\infty\big(\{x\}^n-\frac1{n+1}\big)\frac{dx}x,"According to Dirichlet's test (integral version), $$ I_n=\int_1^\infty\big(\{x\}^n-\frac1{n+1}\big)\frac{dx}x $$ converges, where $n$ is a positive integer and $\{x\}$ denotes the fractional part of $x$ .  Using series, I found out the values of $I_1$ and $I_2$ . $I_1=\frac12\ln(2\pi)-1$ and $I_2=\frac12\ln(2\pi)-\frac12-2\ln A$ , where $A$ denotes Glaisher's constant. My Attempt to Generalize $I_n$ $$I_n=\sum_{m=1}^\infty\int_0^1\big(t^n-\frac1{n+1}\big)\frac{dt}{t+m}\\ =\sum_{m=1}^\infty P_n(m)-\frac1{n+1}\ln\big(1+\frac1m\big)+m^n(-1)^n\ln\big(1+\frac1m\big)\\ =\sum_{m=1}^\infty-\frac1{n+1}\ln\big(1+\frac1m\big)+\frac1{(n+1)m}-\frac1{(n+2)m^2}+\cdots\\ =\frac\gamma{n+1}+\sum_{k=2}^\infty\frac{(-1)^{k-1}\zeta(k)}{n+k}$$ where $P_n$ is a polynomial with $\deg P_n=n-1$ and $\gamma$ denotes Euler's constant. My questions are: (i) Is my answer right? (ii) If my answer is right, can I make it a little bit more   simplified? (iii) How to find the value of $I_3$ ? Edit: the convergence test of $I_n$ Denote $F(x)=\int_1^x\{t\}^n-\frac1{n+1}dt$ , we have $$F(x+1)-F(x)=\int_x^{x+1}\{t\}^ndt-\frac1{n+1}=0.$$ Obviously, $F(x)$ is bounded in $[0,1]$ . So $F(x)$ is bounded in $\mathbb{R}$ . Also, $1/x$ is a decreasing function in $[1,+\infty)$ and $\lim_{x\to\infty}1/x=0$ Hence $I_n$ converges.","According to Dirichlet's test (integral version), converges, where is a positive integer and denotes the fractional part of .  Using series, I found out the values of and . and , where denotes Glaisher's constant. My Attempt to Generalize where is a polynomial with and denotes Euler's constant. My questions are: (i) Is my answer right? (ii) If my answer is right, can I make it a little bit more   simplified? (iii) How to find the value of ? Edit: the convergence test of Denote , we have Obviously, is bounded in . So is bounded in . Also, is a decreasing function in and Hence converges.","
I_n=\int_1^\infty\big(\{x\}^n-\frac1{n+1}\big)\frac{dx}x
 n \{x\} x I_1 I_2 I_1=\frac12\ln(2\pi)-1 I_2=\frac12\ln(2\pi)-\frac12-2\ln A A I_n I_n=\sum_{m=1}^\infty\int_0^1\big(t^n-\frac1{n+1}\big)\frac{dt}{t+m}\\
=\sum_{m=1}^\infty P_n(m)-\frac1{n+1}\ln\big(1+\frac1m\big)+m^n(-1)^n\ln\big(1+\frac1m\big)\\
=\sum_{m=1}^\infty-\frac1{n+1}\ln\big(1+\frac1m\big)+\frac1{(n+1)m}-\frac1{(n+2)m^2}+\cdots\\
=\frac\gamma{n+1}+\sum_{k=2}^\infty\frac{(-1)^{k-1}\zeta(k)}{n+k} P_n \deg P_n=n-1 \gamma I_3 I_n F(x)=\int_1^x\{t\}^n-\frac1{n+1}dt F(x+1)-F(x)=\int_x^{x+1}\{t\}^ndt-\frac1{n+1}=0. F(x) [0,1] F(x) \mathbb{R} 1/x [1,+\infty) \lim_{x\to\infty}1/x=0 I_n","['calculus', 'definite-integrals', 'summation', 'riemann-zeta']"
85,Prove the series $\sum_{n=1}^{\infty}\frac{(-1)^n}{\ln{n}+\sin{n}}$ converge,Prove the series  converge,\sum_{n=1}^{\infty}\frac{(-1)^n}{\ln{n}+\sin{n}},"How to prove this serie $$\sum_{n=1}^{\infty}\frac{(-1)^n}{\ln{n}+\sin{n}}$$ converge? I can't do a comparison test with the Leibniz formula for $\pi$ because the series are not $>0$ for all $n$. I can't do a ratio test because I can't compute the limit, the alternating series test can't be applied, the absolute serie is not convergent. I'm out of ideas. Any clues?","How to prove this serie $$\sum_{n=1}^{\infty}\frac{(-1)^n}{\ln{n}+\sin{n}}$$ converge? I can't do a comparison test with the Leibniz formula for $\pi$ because the series are not $>0$ for all $n$. I can't do a ratio test because I can't compute the limit, the alternating series test can't be applied, the absolute serie is not convergent. I'm out of ideas. Any clues?",,"['calculus', 'sequences-and-series', 'convergence-divergence']"
86,An integral formula for the reciprocal gamma function,An integral formula for the reciprocal gamma function,,"I'm looking to compute an exact integral formula for the reciprocal of the double factorial function, $(2n-1)!!$, or just as easily for the reciprocal gamma function, $\Gamma\left(n+\frac{1}{2}\right)$. I found the post located here and that formula works well for me when, for example, I take $c := 1$. However, there is another known formula that I'm looking to replicate, or at least find a suitable analog to. Namely, that for integers $n \geq 0$ we have that (this formula is found in the appendices of the Concrete Mathematics book, for example):  \begin{align*} \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-n\imath t} e^{e^{\imath t}} dt & = \frac{1}{n!}.  \end{align*}  I have had a look around google and found page 3 of this article and the Hankel loop contour described here , though I am still struggling to find the analog to this formula for the double factorial function case. I believe that the integral formula above is derived from the contour integral for the reciprocal gamma function, but when I perform a change of variable in the loop contour formula and plugin $z \mapsto n + \frac{1}{2}$, Mathematica computes the following result when $n = 3$ (the expected result is acceptably $\frac{8}{105}$, or ideally $\frac{1}{105}$):  \begin{align*} \frac{1}{4\sqrt{\pi}} \int_{-\pi}^{\pi} e^{-(n_3+\frac{1}{2})\imath t} e^{e^{\imath t}} dt & = -\frac{1}{21 e \sqrt{\pi}} + \frac{8}{105} \operatorname{erf}(1).  \end{align*}  The result is obviously close to the intended formula, so I'm thinking that perhaps it's an issue with the bounds on the integral. I would like to keep the bounds of integration finite as in the factorial function formula if possible. Does anyone have any thoughts, advice, or solutions for this problem?","I'm looking to compute an exact integral formula for the reciprocal of the double factorial function, $(2n-1)!!$, or just as easily for the reciprocal gamma function, $\Gamma\left(n+\frac{1}{2}\right)$. I found the post located here and that formula works well for me when, for example, I take $c := 1$. However, there is another known formula that I'm looking to replicate, or at least find a suitable analog to. Namely, that for integers $n \geq 0$ we have that (this formula is found in the appendices of the Concrete Mathematics book, for example):  \begin{align*} \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{-n\imath t} e^{e^{\imath t}} dt & = \frac{1}{n!}.  \end{align*}  I have had a look around google and found page 3 of this article and the Hankel loop contour described here , though I am still struggling to find the analog to this formula for the double factorial function case. I believe that the integral formula above is derived from the contour integral for the reciprocal gamma function, but when I perform a change of variable in the loop contour formula and plugin $z \mapsto n + \frac{1}{2}$, Mathematica computes the following result when $n = 3$ (the expected result is acceptably $\frac{8}{105}$, or ideally $\frac{1}{105}$):  \begin{align*} \frac{1}{4\sqrt{\pi}} \int_{-\pi}^{\pi} e^{-(n_3+\frac{1}{2})\imath t} e^{e^{\imath t}} dt & = -\frac{1}{21 e \sqrt{\pi}} + \frac{8}{105} \operatorname{erf}(1).  \end{align*}  The result is obviously close to the intended formula, so I'm thinking that perhaps it's an issue with the bounds on the integral. I would like to keep the bounds of integration finite as in the factorial function formula if possible. Does anyone have any thoughts, advice, or solutions for this problem?",,"['calculus', 'complex-analysis', 'factorial', 'contour-integration']"
87,Distribution of sum of exponentially distributed variables with arbitrary rates,Distribution of sum of exponentially distributed variables with arbitrary rates,,"Consider independent random variables $X_1, \ldots, X_n$, each of them exponentially distributed with parameters $\lambda_1, \ldots, \lambda_n$. Let us consider the sum $Y= X_1 + \ldots + X_n$. (1) In the case where all the rates are equal ($\lambda_i = \lambda$ for all $i$), we know that the distribution is a Gamma distribution : $$ f_Y(t) = \lambda e^{-\lambda t} \frac{(\lambda t)^{n-1}}{(n-1)!}. $$ (2) In the case where all the rates are different $(\lambda_i \neq \lambda_j $ for all $i,j$), we can also calculate the distribution of $Y$. This time it is given by the hypoexponential distribution : $$ f_Y(t) = \sum_{i=1}^{n} \left( \prod_{j\neq i} \frac{\lambda_j}{\lambda_j - \lambda_i} \right) \lambda_i e^{-\lambda_i t}, $$ where the product is over all $1 \leq j \leq n$, $j \neq i$. For an induction proof see Ross . (3) Now consider the case in which some rates are equal to others but they are not all equal, i.e. the number of unique rates is between $2$ and $n-1$. Is there a general formula for the distribution of the sum in this case? I tried approaching the problem by computing convolutions and trying to find a pattern in the distributions. For example, for two variables $X_1, X_2$ I would calculate $f_{X_1+X_2}(t) = \int\limits_{0}^{t} f_{X_1}(s) f_{X_2}(t-s) ds$, and then do this iteratively for more and more variables where some but not all rates are similar. From the results I obtained I came up with the following conjecture : Assume that there exist $i,j$ such that $\lambda_i = \lambda_j$ and that there exist $m,n,$ such that $\lambda_m \neq \lambda_n$. Define $m$ as the number of distinct rates, $2 \leq m \leq n-1$. Define $n_j$ as the number of variables with rate $\lambda_j$, $1 \leq n_j \leq n$ and $1 \leq j \leq m$. Hence the system is specified by $(m, n_1, \ldots, n_m)$ and rates $(\lambda_1, \ldots, \lambda_m)$. Then the distribution of $Y$ is given by $$ f_Y(t) = \sum_{i=1}^{m} \left[ \prod_{j\neq i} \left(\frac{\lambda_j}{\lambda_j - \lambda_i}\right)^{n_j} \right] \lambda_i^{n_i} \left[ \sum\limits_{k=1}^{n_i} \frac{t^{k-1}}{(k-1)!} \right] e^{-\lambda_i t}, $$ I was not able to proof this by induction or verify it in some other way than by checking results for a small number of variables. Could you prove or disprove the conjecture I made above ? Linked question Distribution of sum of exponential variables with different parameters : a similar question, but it only considers a special case with parameters $(\lambda, \lambda/2, \lambda/3, \ldots, \lambda/n)$, which belongs to case (2) above. I would like to know the general case for arbitrary $\lambda_i$'s.","Consider independent random variables $X_1, \ldots, X_n$, each of them exponentially distributed with parameters $\lambda_1, \ldots, \lambda_n$. Let us consider the sum $Y= X_1 + \ldots + X_n$. (1) In the case where all the rates are equal ($\lambda_i = \lambda$ for all $i$), we know that the distribution is a Gamma distribution : $$ f_Y(t) = \lambda e^{-\lambda t} \frac{(\lambda t)^{n-1}}{(n-1)!}. $$ (2) In the case where all the rates are different $(\lambda_i \neq \lambda_j $ for all $i,j$), we can also calculate the distribution of $Y$. This time it is given by the hypoexponential distribution : $$ f_Y(t) = \sum_{i=1}^{n} \left( \prod_{j\neq i} \frac{\lambda_j}{\lambda_j - \lambda_i} \right) \lambda_i e^{-\lambda_i t}, $$ where the product is over all $1 \leq j \leq n$, $j \neq i$. For an induction proof see Ross . (3) Now consider the case in which some rates are equal to others but they are not all equal, i.e. the number of unique rates is between $2$ and $n-1$. Is there a general formula for the distribution of the sum in this case? I tried approaching the problem by computing convolutions and trying to find a pattern in the distributions. For example, for two variables $X_1, X_2$ I would calculate $f_{X_1+X_2}(t) = \int\limits_{0}^{t} f_{X_1}(s) f_{X_2}(t-s) ds$, and then do this iteratively for more and more variables where some but not all rates are similar. From the results I obtained I came up with the following conjecture : Assume that there exist $i,j$ such that $\lambda_i = \lambda_j$ and that there exist $m,n,$ such that $\lambda_m \neq \lambda_n$. Define $m$ as the number of distinct rates, $2 \leq m \leq n-1$. Define $n_j$ as the number of variables with rate $\lambda_j$, $1 \leq n_j \leq n$ and $1 \leq j \leq m$. Hence the system is specified by $(m, n_1, \ldots, n_m)$ and rates $(\lambda_1, \ldots, \lambda_m)$. Then the distribution of $Y$ is given by $$ f_Y(t) = \sum_{i=1}^{m} \left[ \prod_{j\neq i} \left(\frac{\lambda_j}{\lambda_j - \lambda_i}\right)^{n_j} \right] \lambda_i^{n_i} \left[ \sum\limits_{k=1}^{n_i} \frac{t^{k-1}}{(k-1)!} \right] e^{-\lambda_i t}, $$ I was not able to proof this by induction or verify it in some other way than by checking results for a small number of variables. Could you prove or disprove the conjecture I made above ? Linked question Distribution of sum of exponential variables with different parameters : a similar question, but it only considers a special case with parameters $(\lambda, \lambda/2, \lambda/3, \ldots, \lambda/n)$, which belongs to case (2) above. I would like to know the general case for arbitrary $\lambda_i$'s.",,"['calculus', 'probability', 'probability-distributions']"
88,Given two lines to find their intersection.,Given two lines to find their intersection.,,"I will fully disclose that this is a homework question. I would prefer not to be given an answer directly, and am looking for more of an indication as to whether I am on the right track. The problem with the courses I am working with is that they only show examples, and do not explain exactly how it ""works"". Given $l_1 = (6,-1,0)+t(3,1,-4)$ and $l_2 = (4,0,5)+s(-1,1,5)$ find   the intersection of $l_1$ and $l_2$. First I took $d_1 = (3,1,-4)$ and $d_2 = (-1,1,5)$, Then I made sure that they did not have the same ratio. (if they have the same ratio this would indicate that they are either coincident or parallel) they do not have the same ratio, so they either intersect at a point or are skew. Then I made parametric equations: $l_1:$ $$\begin{align} x & = 6 + 3t\\ y & = -1 + t\\ z & = -4t\\ \end{align}$$ $l_2:$ $$\begin{align} x & = 4 - s\\ y & = s\\ z & = 5 + 5s\\ \end{align}$$ Then I equated them to eachother: $$\begin{align} 6 + 3t & = 4 - s\\ -1 + t & = s\\ -4t &= 5 + 5s\\ \end{align}$$ I moved the unknowns to one side: $$\begin{align} 3t + s & = -2 \qquad & \text{(we'll call this equation $1$)}\\ t - s & = 1 \qquad & \text{(we'll call this equation $2$)}\\ -4t - 5s & = 5 \qquad & \text{(we'll call this equation $3$)}\\ \end{align}$$ This is where it gets tricky. If I take equation $(1)$ and $(2)$, I can cancel out the $s$ value, but the values both become strange, where $t$ is $\frac 34$ and $s$ is $-2 (\frac 34)$, obviously the left and right hand sides don't match. But I I take equation $(2)$ and $(3)$, the left and right hand sides do match, and then if I go to find the point of intersection I get decimal values for coordinates (why would that be the case?) Any help would be great. I just want to know what I'm doing wrong. Please don't just give me the answer. Edit: I am not sure why people are digging this up to down-vote it, and would appreciate a comment explaining your down-vote.","I will fully disclose that this is a homework question. I would prefer not to be given an answer directly, and am looking for more of an indication as to whether I am on the right track. The problem with the courses I am working with is that they only show examples, and do not explain exactly how it ""works"". Given $l_1 = (6,-1,0)+t(3,1,-4)$ and $l_2 = (4,0,5)+s(-1,1,5)$ find   the intersection of $l_1$ and $l_2$. First I took $d_1 = (3,1,-4)$ and $d_2 = (-1,1,5)$, Then I made sure that they did not have the same ratio. (if they have the same ratio this would indicate that they are either coincident or parallel) they do not have the same ratio, so they either intersect at a point or are skew. Then I made parametric equations: $l_1:$ $$\begin{align} x & = 6 + 3t\\ y & = -1 + t\\ z & = -4t\\ \end{align}$$ $l_2:$ $$\begin{align} x & = 4 - s\\ y & = s\\ z & = 5 + 5s\\ \end{align}$$ Then I equated them to eachother: $$\begin{align} 6 + 3t & = 4 - s\\ -1 + t & = s\\ -4t &= 5 + 5s\\ \end{align}$$ I moved the unknowns to one side: $$\begin{align} 3t + s & = -2 \qquad & \text{(we'll call this equation $1$)}\\ t - s & = 1 \qquad & \text{(we'll call this equation $2$)}\\ -4t - 5s & = 5 \qquad & \text{(we'll call this equation $3$)}\\ \end{align}$$ This is where it gets tricky. If I take equation $(1)$ and $(2)$, I can cancel out the $s$ value, but the values both become strange, where $t$ is $\frac 34$ and $s$ is $-2 (\frac 34)$, obviously the left and right hand sides don't match. But I I take equation $(2)$ and $(3)$, the left and right hand sides do match, and then if I go to find the point of intersection I get decimal values for coordinates (why would that be the case?) Any help would be great. I just want to know what I'm doing wrong. Please don't just give me the answer. Edit: I am not sure why people are digging this up to down-vote it, and would appreciate a comment explaining your down-vote.",,['calculus']
89,Evaluating the integral $\frac{1}{2^{2n-2}}\int_0^1\frac{x^{4n}\left(1-x\right)^{4n}}{1+x^2} dx$,Evaluating the integral,\frac{1}{2^{2n-2}}\int_0^1\frac{x^{4n}\left(1-x\right)^{4n}}{1+x^2} dx,"Prove that : $$ \frac{1}{2^{2n-2}}\int \limits_{0}^{1} \dfrac{x^{4n}\left(1-x\right)^{4n}}{1+x^2} dx =$$ $$\sum \limits_{j=0}^{2n-1}\dfrac{(-1)^j}{2^{2n-j-2}\left(8n-j-1\right)\binom{8n-j-2}{4n+j}} + (-1)^n\left(\pi-4\sum \limits_{j=0}^{3n-1}\dfrac{(-1)^j}{2j+1}\right)\,\,\,\,(♣)$$ where $\binom{a}{b}= {}_aC_b=\frac{a!}{b!(a-b)!}$ . I was reading an article on "" $\frac{22}{7}$ exceeds $\pi$ "", when came across the generalized form $(♣)$ . Putting the value of $n=1$ in $(♣)$ , we get the famous Putnam Problem : $$0<\int \limits_0^1\dfrac{x^4(1-x)^4}{1+x^2}dx=\dfrac{22}{7}-\pi.\,\,\,\,(♠)$$ I know how to evaluate $(♠)$ by using expansion and polynomial long-division and then term-wise integration. The other integrals involving $n>1$ provide better approximations of $\pi$ . But I am unable to get even close to evaluating $(♣)$ because of the ' $n$ 's. I tried to do polynomial division but got badly stuck. The $1+x^2$ in the denominator reminds me of $\arctan(x)$ , but what can I do? Can anyone provide a bit of help as to how to evaluate this lovely integral ? Also I would like to know if it is okay to treat $n$ as a real number here instead of a natural number.","Prove that : where . I was reading an article on "" exceeds "", when came across the generalized form . Putting the value of in , we get the famous Putnam Problem : I know how to evaluate by using expansion and polynomial long-division and then term-wise integration. The other integrals involving provide better approximations of . But I am unable to get even close to evaluating because of the ' 's. I tried to do polynomial division but got badly stuck. The in the denominator reminds me of , but what can I do? Can anyone provide a bit of help as to how to evaluate this lovely integral ? Also I would like to know if it is okay to treat as a real number here instead of a natural number."," \frac{1}{2^{2n-2}}\int \limits_{0}^{1} \dfrac{x^{4n}\left(1-x\right)^{4n}}{1+x^2} dx = \sum \limits_{j=0}^{2n-1}\dfrac{(-1)^j}{2^{2n-j-2}\left(8n-j-1\right)\binom{8n-j-2}{4n+j}} + (-1)^n\left(\pi-4\sum \limits_{j=0}^{3n-1}\dfrac{(-1)^j}{2j+1}\right)\,\,\,\,(♣) \binom{a}{b}= {}_aC_b=\frac{a!}{b!(a-b)!} \frac{22}{7} \pi (♣) n=1 (♣) 0<\int \limits_0^1\dfrac{x^4(1-x)^4}{1+x^2}dx=\dfrac{22}{7}-\pi.\,\,\,\,(♠) (♠) n>1 \pi (♣) n 1+x^2 \arctan(x) n","['calculus', 'integration']"
90,How to evaluate $\lim _{x\to \infty }\left(\frac{x+3}{\sqrt{x^2-5x}}\right)^{x^2\sin\left(1/x\right)}$?,How to evaluate ?,\lim _{x\to \infty }\left(\frac{x+3}{\sqrt{x^2-5x}}\right)^{x^2\sin\left(1/x\right)},"How to evaluate $\lim _{x\to \infty }\left(\frac{x+3}{\sqrt{x^2-5x}}\right)^{x^2\sin\left(1/x\right)}$? My Try: $$\lim _{x\to \infty }\left(x^2\sin\left(\frac{1}{x}\right)\ln\left(\frac{x+3}{\sqrt{x^2-5x}}\right)\right) = \lim _{t\to 0 }\left(\frac{1}{t^2}\sin\left(t\right)\ln\left(\frac{\frac{1}{t}+3}{\sqrt{\frac{1}{t^2}-\frac{5}{t}}}\right)\right)$$ Now $\sin(x) \approx x, x \rightarrow 0$ so: $$\approx \lim _{t\to 0 }\left(\frac{1}{t}ln\left(\frac{\left(3t+1\right)\sqrt{-5t+1}}{1-5t}\right)\right)$$ At this point i used the rule of the de l'Hôpital so: $$\lim _{t\to 0 }\left(\frac{1}{t}ln\left(\frac{\left(3t+1\right)\sqrt{-5t+1}}{1-5t}\right)\right) = \lim _{t\to 0}\left(\frac{\frac{-15t+11}{2\left(-5t+1\right)\left(3t+1\right)}}{1}\right) = \frac{11}{2}$$ So: $$\lim _{x\to \infty }\left(\left(\frac{x+3}{\sqrt{x^2-5x}}\right)^{x^2\sin\left(\frac{1}{x}\right)}\right) = \color{red}{e^\frac{11}{2}}$$ Which it is the exact result of the proposed limit. My question is, there is another method, different from mine to get the same result? (Preferably without resorting to de l'Hôpital rule).","How to evaluate $\lim _{x\to \infty }\left(\frac{x+3}{\sqrt{x^2-5x}}\right)^{x^2\sin\left(1/x\right)}$? My Try: $$\lim _{x\to \infty }\left(x^2\sin\left(\frac{1}{x}\right)\ln\left(\frac{x+3}{\sqrt{x^2-5x}}\right)\right) = \lim _{t\to 0 }\left(\frac{1}{t^2}\sin\left(t\right)\ln\left(\frac{\frac{1}{t}+3}{\sqrt{\frac{1}{t^2}-\frac{5}{t}}}\right)\right)$$ Now $\sin(x) \approx x, x \rightarrow 0$ so: $$\approx \lim _{t\to 0 }\left(\frac{1}{t}ln\left(\frac{\left(3t+1\right)\sqrt{-5t+1}}{1-5t}\right)\right)$$ At this point i used the rule of the de l'Hôpital so: $$\lim _{t\to 0 }\left(\frac{1}{t}ln\left(\frac{\left(3t+1\right)\sqrt{-5t+1}}{1-5t}\right)\right) = \lim _{t\to 0}\left(\frac{\frac{-15t+11}{2\left(-5t+1\right)\left(3t+1\right)}}{1}\right) = \frac{11}{2}$$ So: $$\lim _{x\to \infty }\left(\left(\frac{x+3}{\sqrt{x^2-5x}}\right)^{x^2\sin\left(\frac{1}{x}\right)}\right) = \color{red}{e^\frac{11}{2}}$$ Which it is the exact result of the proposed limit. My question is, there is another method, different from mine to get the same result? (Preferably without resorting to de l'Hôpital rule).",,"['calculus', 'limits', 'alternative-proof', 'limits-without-lhopital']"
91,Prove that $ \lim_{x \to \infty} f^{n}(x) = 0$,Prove that, \lim_{x \to \infty} f^{n}(x) = 0,"Let $n$ be a positive integer. Assume $ \lim_{x \to \infty} f(x)$ and $ \lim_{x \to \infty} f^{(n)}(x)$ are both real numbers. Prove that $$ \lim_{x \to \infty} f^{n}(x) = 0$$ We have that $$\lim_{x \to \infty} \frac{f(x)+x^n}{x^n} = \lim_{x \to \infty} \frac{f'(x)+nx^{n-1}}{nx^{n-1}} = \cdots = \lim_{x \to \infty} \frac{f^{(n)}(x)+n!}{n!} = \lim_{x \to \infty}f^{(n+1)}(x) = 1,$$ by L'Hospital's rule. But did I make a mistake or how does this show that $\displaystyle \lim_{x \to \infty} f^{n}(x) = 0$?","Let $n$ be a positive integer. Assume $ \lim_{x \to \infty} f(x)$ and $ \lim_{x \to \infty} f^{(n)}(x)$ are both real numbers. Prove that $$ \lim_{x \to \infty} f^{n}(x) = 0$$ We have that $$\lim_{x \to \infty} \frac{f(x)+x^n}{x^n} = \lim_{x \to \infty} \frac{f'(x)+nx^{n-1}}{nx^{n-1}} = \cdots = \lim_{x \to \infty} \frac{f^{(n)}(x)+n!}{n!} = \lim_{x \to \infty}f^{(n+1)}(x) = 1,$$ by L'Hospital's rule. But did I make a mistake or how does this show that $\displaystyle \lim_{x \to \infty} f^{n}(x) = 0$?",,"['calculus', 'limits', 'derivatives']"
92,Generalizing the Leibniz rule,Generalizing the Leibniz rule,,"Given the Leibniz rule: $$\frac{d}{dy}\int^a_b f(x,y) dx = \int_b^a \frac{\partial f}{\partial y} (x,y) dx$$ How do I prove a more general case using the chain rule and the above: $$\frac{d}{dy} \int_{g_1(y)}^{g_2(y)} f(x,y) dx =?$$ From the fundamental theorem of calculus we have that: $$\frac{d}{dt} \int_{f_2(t)}^{f_1(t)} g(s) ds = g(f_1(t))f'_1(t) - g(f_2(t))f'_2(t)$$ But when I just apply the fundamental theorem of calculus I get an incorrect answer (because I also need to use Leibniz rule itself...).","Given the Leibniz rule: $$\frac{d}{dy}\int^a_b f(x,y) dx = \int_b^a \frac{\partial f}{\partial y} (x,y) dx$$ How do I prove a more general case using the chain rule and the above: $$\frac{d}{dy} \int_{g_1(y)}^{g_2(y)} f(x,y) dx =?$$ From the fundamental theorem of calculus we have that: $$\frac{d}{dt} \int_{f_2(t)}^{f_1(t)} g(s) ds = g(f_1(t))f'_1(t) - g(f_2(t))f'_2(t)$$ But when I just apply the fundamental theorem of calculus I get an incorrect answer (because I also need to use Leibniz rule itself...).",,"['calculus', 'integration', 'multivariable-calculus', 'derivatives', 'leibniz-integral-rule']"
93,What is a proof of this limit of this nested radical?,What is a proof of this limit of this nested radical?,,"It seems as if $$\lim_{x\to 0^+} \sqrt{x+\sqrt[3]{x+\sqrt[4]{\cdots}}}=1$$ I really am at a loss at a proof here. This doesn't come from anywhere, but just out of curiosity. Graphing proves this result fairly well.","It seems as if $$\lim_{x\to 0^+} \sqrt{x+\sqrt[3]{x+\sqrt[4]{\cdots}}}=1$$ I really am at a loss at a proof here. This doesn't come from anywhere, but just out of curiosity. Graphing proves this result fairly well.",,['calculus']
94,Two different definitions of big O notation,Two different definitions of big O notation,,"I find there are two different definitions of big O notations for $f(n)=O(g(n))$ as $n\rightarrow\infty$: There exist $M>0$, and $N\in\mathbb{N}$, such that $|f(n)|\leq M|g(n)|$ for $n\geq N$. There exist $M>0$, such that $|f(n)|\leq M|g(n)|$ for $n\in\mathbb{N}$. I do not which one is right or when two of them is equivalent.","I find there are two different definitions of big O notations for $f(n)=O(g(n))$ as $n\rightarrow\infty$: There exist $M>0$, and $N\in\mathbb{N}$, such that $|f(n)|\leq M|g(n)|$ for $n\geq N$. There exist $M>0$, such that $|f(n)|\leq M|g(n)|$ for $n\in\mathbb{N}$. I do not which one is right or when two of them is equivalent.",,"['calculus', 'limits', 'nonstandard-analysis']"
95,Show there exists a constant such that the inequality holds,Show there exists a constant such that the inequality holds,,"Prove there exists a  constant $c \in (0,1)$  ($c$ should depend on $n$) such that $$\displaystyle \sum_{i=1}^{n} x_i^3\cdot x_{i+1} \le c \sum_{i=1}^n x_i^4$$ holds for all  real numbers $x_i$ such that $\displaystyle \sum_{i=1}^nx_i=0$ and $x_{n+1}=x_1$.","Prove there exists a  constant $c \in (0,1)$  ($c$ should depend on $n$) such that $$\displaystyle \sum_{i=1}^{n} x_i^3\cdot x_{i+1} \le c \sum_{i=1}^n x_i^4$$ holds for all  real numbers $x_i$ such that $\displaystyle \sum_{i=1}^nx_i=0$ and $x_{n+1}=x_1$.",,"['calculus', 'sequences-and-series']"
96,How to explain the behaviour of $\int x^n dx$ near $n = -1$ to a layman?,How to explain the behaviour of  near  to a layman?,\int x^n dx n = -1,"From both sides, this approaches infinity, but when evaluated exactly at $n = -1$, yields $\ln (x)$. This seems similar to the behaviour of solutions to linear ODEs with characteristic polynomials (as the determinant approaches 0, a factor of $x$ appears next to the repeated root). How can I explain this phenomenon to a layman? Obviously, I could show a proof of both, but that is probably not enough to be satisfactory. How does an infinity turn into a logarithm at the drop of a hat? As an aside, is there a name for this behaviour?","From both sides, this approaches infinity, but when evaluated exactly at $n = -1$, yields $\ln (x)$. This seems similar to the behaviour of solutions to linear ODEs with characteristic polynomials (as the determinant approaches 0, a factor of $x$ appears next to the repeated root). How can I explain this phenomenon to a layman? Obviously, I could show a proof of both, but that is probably not enough to be satisfactory. How does an infinity turn into a logarithm at the drop of a hat? As an aside, is there a name for this behaviour?",,"['calculus', 'functions', 'soft-question']"
97,"If $\int_0^xf(t)dt=[f(x)]^2$ but $f(x)\neq 0$, what is $f(x)$?","If  but , what is ?",\int_0^xf(t)dt=[f(x)]^2 f(x)\neq 0 f(x),"From the problems plus in Stewart Calculus 6e, it asks if $f$ is a differentiable function such that $f(x)$ is never $0$ and for any $x$, $\int_0^xf(t)dt=[f(x)]^2$, then what is $f(x)$? I figured since it's differentiable I could take the derivative of both sides to get: $$f(x)=2f(x)f'(x)$$ Since $f(x)$ is never $0$, then  $f'(x)=1/2$. But that means that $f(x)=x/2+c$, which will equal $0$  for $x=-2c$. I can't just take $0$ out of the function, since it has to be differentiable everywhere. So how do I solve this problem?","From the problems plus in Stewart Calculus 6e, it asks if $f$ is a differentiable function such that $f(x)$ is never $0$ and for any $x$, $\int_0^xf(t)dt=[f(x)]^2$, then what is $f(x)$? I figured since it's differentiable I could take the derivative of both sides to get: $$f(x)=2f(x)f'(x)$$ Since $f(x)$ is never $0$, then  $f'(x)=1/2$. But that means that $f(x)=x/2+c$, which will equal $0$  for $x=-2c$. I can't just take $0$ out of the function, since it has to be differentiable everywhere. So how do I solve this problem?",,"['calculus', 'integration', 'ordinary-differential-equations']"
98,Why is this true ? $(1-s)\zeta(s) = \sum_{k=0}^\infty \frac{\Gamma(k+1-s/2) A_k}{\Gamma(1-s/2) k!}$,Why is this true ?,(1-s)\zeta(s) = \sum_{k=0}^\infty \frac{\Gamma(k+1-s/2) A_k}{\Gamma(1-s/2) k!},"On the whole complex plane the following formula is valid : $$(1-s)\zeta(s) =  \sum_{k=0}^\infty \frac{\Gamma(k+1-s/2) A_k}{\Gamma(1-s/2) k!}$$ where $A_k = \sum_{j=0}^k (2j-1) \zeta(2j+2) (k,j)$ and $(k,j)$ is the binomial coefficient. How to show this ?","On the whole complex plane the following formula is valid : $$(1-s)\zeta(s) =  \sum_{k=0}^\infty \frac{\Gamma(k+1-s/2) A_k}{\Gamma(1-s/2) k!}$$ where $A_k = \sum_{j=0}^k (2j-1) \zeta(2j+2) (k,j)$ and $(k,j)$ is the binomial coefficient. How to show this ?",,"['calculus', 'riemann-zeta']"
99,Integrating Pareto tails across a shifted lognormal distribution,Integrating Pareto tails across a shifted lognormal distribution,,"Looking for the integral: With $b>0, L>0, \alpha_0>b,\sigma>0, x>L$ , $$\phi(x;\alpha_0,\sigma_)=\int_b^\infty\alpha  L^{\alpha } x^{-\alpha -1} \frac{e^{-\frac{\left(\log (\alpha -b)-\log (\alpha_0-b)+\frac{\sigma ^2}{2}\right)^2}{2 \sigma ^2}}}{\sqrt{2 \pi } \sigma  (\alpha -b)}d\alpha$$ $\textbf{Background}$: This is the density of a Pareto distribution $\alpha  L^{\alpha } x^{-\alpha -1} $ with its tail exponent $\alpha$ distributed according to a shifted lognormal with mean $\alpha_0$ and lower bound $b$. In other words $\alpha + b$ follows a $\text{LogNormal}\left(\log (\alpha_0-b)-\frac{\sigma ^2}{2},\sigma \right)$.","Looking for the integral: With $b>0, L>0, \alpha_0>b,\sigma>0, x>L$ , $$\phi(x;\alpha_0,\sigma_)=\int_b^\infty\alpha  L^{\alpha } x^{-\alpha -1} \frac{e^{-\frac{\left(\log (\alpha -b)-\log (\alpha_0-b)+\frac{\sigma ^2}{2}\right)^2}{2 \sigma ^2}}}{\sqrt{2 \pi } \sigma  (\alpha -b)}d\alpha$$ $\textbf{Background}$: This is the density of a Pareto distribution $\alpha  L^{\alpha } x^{-\alpha -1} $ with its tail exponent $\alpha$ distributed according to a shifted lognormal with mean $\alpha_0$ and lower bound $b$. In other words $\alpha + b$ follows a $\text{LogNormal}\left(\log (\alpha_0-b)-\frac{\sigma ^2}{2},\sigma \right)$.",,"['calculus', 'integration', 'probability-theory', 'probability-distributions', 'normal-distribution']"
