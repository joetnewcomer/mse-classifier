,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Probability of rolling a ""1"" on a die conditioned on when all rolls are different.","Probability of rolling a ""1"" on a die conditioned on when all rolls are different.",,"So I have this problem: I am rolling a six sided die 3 times.  Conditioned on the rolls all being different, what's the probability at least one die is a ""1"" So I worked it out like this: probability of not getting a 1 on the first roll is 5/6 probability of not getting a 1 on the second roll is 4/6 probability of not getting a 1 on the second roll is 3/6 I then just did (5/6) * (4/6) * (3/6) to get 60/216 possible conditions where you would not roll a 1. Doing 216-60 you get that 158/216 possible solutions (or 13/18) possible solutions for rolling a ""1"" when all numbers are different. Does this make sense? The number seems a bit large and I am not sure how to check it. Thank you in advance.","So I have this problem: I am rolling a six sided die 3 times.  Conditioned on the rolls all being different, what's the probability at least one die is a ""1"" So I worked it out like this: probability of not getting a 1 on the first roll is 5/6 probability of not getting a 1 on the second roll is 4/6 probability of not getting a 1 on the second roll is 3/6 I then just did (5/6) * (4/6) * (3/6) to get 60/216 possible conditions where you would not roll a 1. Doing 216-60 you get that 158/216 possible solutions (or 13/18) possible solutions for rolling a ""1"" when all numbers are different. Does this make sense? The number seems a bit large and I am not sure how to check it. Thank you in advance.",,"['probability', 'dice']"
1,probability summation for an infinite sequence,probability summation for an infinite sequence,,"Very simple case, but don't know how to prove say function $rand$ returns a uniformly sampled value in $(0,1)$ $x_0 = 1$ $x_1 = rand * x_0$ $x_2 = rand * x_1$ ... $x_n = rand * x_{n-1}$ Now the summation $S(n) = \sum_{i=0}^n x_i$ Is $\lim_{n\to\infty} S(n)$ finite? It must be, but how to show ?","Very simple case, but don't know how to prove say function $rand$ returns a uniformly sampled value in $(0,1)$ $x_0 = 1$ $x_1 = rand * x_0$ $x_2 = rand * x_1$ ... $x_n = rand * x_{n-1}$ Now the summation $S(n) = \sum_{i=0}^n x_i$ Is $\lim_{n\to\infty} S(n)$ finite? It must be, but how to show ?",,['probability']
2,Expected value of sample median given the sample mean.,Expected value of sample median given the sample mean.,,"Let $Y$ denote the median and let $\bar{X}$ denote the mean of a random sample of size $n=2k+1$ from a distribution that is $N(\mu,\sigma^2)$. How can I compute $E(Y|\bar{X}=\bar{x})$? Intuitively, because of the normality assumption, it makes sense to claim that $E(Y|\bar{X}=\bar{x})=\bar{x}$ and indeed that is the correct answer. Can that be shown rigorously though? Thanks.","Let $Y$ denote the median and let $\bar{X}$ denote the mean of a random sample of size $n=2k+1$ from a distribution that is $N(\mu,\sigma^2)$. How can I compute $E(Y|\bar{X}=\bar{x})$? Intuitively, because of the normality assumption, it makes sense to claim that $E(Y|\bar{X}=\bar{x})=\bar{x}$ and indeed that is the correct answer. Can that be shown rigorously though? Thanks.",,"['probability', 'statistics', 'probability-theory', 'self-learning', 'normal-distribution']"
3,Maximum Likelihood Function for uniformly distributed points,Maximum Likelihood Function for uniformly distributed points,,"I am currently trying to solve Exercise 22.10 from David MacKay's Book ""Information theory, inference, and learning algorithms"" I have absolutely no idea on how to approach this task, and would highly appreciate if someone could point me to the right direction.","I am currently trying to solve Exercise 22.10 from David MacKay's Book ""Information theory, inference, and learning algorithms"" I have absolutely no idea on how to approach this task, and would highly appreciate if someone could point me to the right direction.",,"['probability', 'statistics']"
4,Drunk problem involving probability of being in a circle.,Drunk problem involving probability of being in a circle.,,"This is the typical drunk problem wherein the person is confined to moving either to the North, South, East, or West but never diagonally with just one step. A step has a length $L$. What is the probability that the drunk will never leave a circle of radius $2L$ after $N$ steps? Obviously, the probability is zero for $N=1$ and $N=2$. For $N=3$, I got it to be $3/4$ although I am not sure whether this is correct. For $N>3$, I am just lost.","This is the typical drunk problem wherein the person is confined to moving either to the North, South, East, or West but never diagonally with just one step. A step has a length $L$. What is the probability that the drunk will never leave a circle of radius $2L$ after $N$ steps? Obviously, the probability is zero for $N=1$ and $N=2$. For $N=3$, I got it to be $3/4$ although I am not sure whether this is correct. For $N>3$, I am just lost.",,"['probability', 'random-walk']"
5,Probability question - how many cycles before all items are chosen,Probability question - how many cycles before all items are chosen,,"I have a container of 100 yellow items. I choose 2 at random and paint each of them blue. I return the items to the container. If I repeat this process, on average how many cycles will I make before all 100 items are painted? It is obviously 50 (100/2) if there is no replacement. But in this case, the items are returned to the container, so the same item could be chosen often. What if we choose 3?","I have a container of 100 yellow items. I choose 2 at random and paint each of them blue. I return the items to the container. If I repeat this process, on average how many cycles will I make before all 100 items are painted? It is obviously 50 (100/2) if there is no replacement. But in this case, the items are returned to the container, so the same item could be chosen often. What if we choose 3?",,"['probability', 'combinatorics']"
6,harder expected value probability question,harder expected value probability question,,"I have a question on expected value. I have the solutions for it but they havent explained exactly what they have done, and i am a bit confused whilst revising for an exam in a few days. Here is the question Suppose 2 teams, A and B, play a series of games that ends when one of them has won 2 games. Suppose that each play is, independently won by player A with probability $p$ Find the expected # of games. So we want to find the expected number of games before one of them wins. I can usually do these types of questions with probability $p$ and $q=(1-p)$ but just not exactly sure why and how for this particular question Solution Let $X$ denote the total # of games played. then for one of the teams to win twice, $X$ can take values in ${2,3}$, and $$EX=2 \times (p^{2}+(1-p)^{2})+3 \times(2p(1-p)^{2} + 2p^{2}(1-p))$$ $$=2p(1-p)+2$$ So what i really want to know is how they have decided the $p's$ and $q=1-p$'s I know there is independence here, so i know that has something to do with it. Please could someone explain exactly how this works so i can master this! Many thanks","I have a question on expected value. I have the solutions for it but they havent explained exactly what they have done, and i am a bit confused whilst revising for an exam in a few days. Here is the question Suppose 2 teams, A and B, play a series of games that ends when one of them has won 2 games. Suppose that each play is, independently won by player A with probability $p$ Find the expected # of games. So we want to find the expected number of games before one of them wins. I can usually do these types of questions with probability $p$ and $q=(1-p)$ but just not exactly sure why and how for this particular question Solution Let $X$ denote the total # of games played. then for one of the teams to win twice, $X$ can take values in ${2,3}$, and $$EX=2 \times (p^{2}+(1-p)^{2})+3 \times(2p(1-p)^{2} + 2p^{2}(1-p))$$ $$=2p(1-p)+2$$ So what i really want to know is how they have decided the $p's$ and $q=1-p$'s I know there is independence here, so i know that has something to do with it. Please could someone explain exactly how this works so i can master this! Many thanks",,"['probability', 'probability-theory']"
7,Probability of a typing monkey backspacing all letters. [duplicate],Probability of a typing monkey backspacing all letters. [duplicate],,"This question already has answers here : Hitting probability of biased random walk on the integer line (4 answers) Closed 10 years ago . Suppose a monkey is typing on a keyboard into a word document. The word document has x letters already in the document. The keyboard has n number keys on it (i.e. keys that cause another digit to appear on the screen) and k backspace keys. If the monkey types for an infinitely long time, what is the probability that at any point there will be 0 characters on the screen?","This question already has answers here : Hitting probability of biased random walk on the integer line (4 answers) Closed 10 years ago . Suppose a monkey is typing on a keyboard into a word document. The word document has x letters already in the document. The keyboard has n number keys on it (i.e. keys that cause another digit to appear on the screen) and k backspace keys. If the monkey types for an infinitely long time, what is the probability that at any point there will be 0 characters on the screen?",,"['probability', 'combinatorics']"
8,Unbiased estimators for the moments of 2 non-independent random variables,Unbiased estimators for the moments of 2 non-independent random variables,,"Let $X$ and $Y$ be two non independent random variables. Suppose to generate $n$ realizations of both variables, and indicate with $(X_i, Y_i)$ their values. Also, let's pose that $X$ and $Y$ are non independent only within a particular realization; in other words, any realization does not affect the result of the others. What can I do to find a statistical unbiased estimator of central moments $$m_{a,b} = \mathbb{E}[(X-\mu_x)^a(Y-\mu_y)^b]$$ which uses the $n$ realizations $(X_i, Y_i)$ except from doing by hand all calculations for each $a$ and $b$? Is there some readings I'm missing? Some additions First of all, I forgot to write these: $$\mu_X = \mathbb{E}[X], \mu_Y = \mathbb{E}[Y]$$","Let $X$ and $Y$ be two non independent random variables. Suppose to generate $n$ realizations of both variables, and indicate with $(X_i, Y_i)$ their values. Also, let's pose that $X$ and $Y$ are non independent only within a particular realization; in other words, any realization does not affect the result of the others. What can I do to find a statistical unbiased estimator of central moments $$m_{a,b} = \mathbb{E}[(X-\mu_x)^a(Y-\mu_y)^b]$$ which uses the $n$ realizations $(X_i, Y_i)$ except from doing by hand all calculations for each $a$ and $b$? Is there some readings I'm missing? Some additions First of all, I forgot to write these: $$\mu_X = \mathbb{E}[X], \mu_Y = \mathbb{E}[Y]$$",,"['probability', 'statistics', 'random-variables']"
9,Maximising probability for financial advice,Maximising probability for financial advice,,"I have the following problem: A financial advisor tries to impress his clients if immediately   following a week in which the ftse index moves by more than   $5\%$ in some direction he correctly predicts that this is the last   week during the calendar year that it moves more than $5\%$ in   that direction. Suppose that in each week the change in the index is independently   up by at least $5\%$, down by at least $5\%$ or neither of   these, with probabilities $p$, $p$ and $1 - 2p$ respectively ($p\le1/2$).   He makes at most one prediction this year. With what strategy   does he maximize the probability of impressing his clients? Source I think the goal is to use backwards induction. I start to formalize everything. Let $X_i$ be a random variable which represents how the market change in week $i$, therefore $P(X_i>0.05)=p=P(X_i<-0.05), P(X_i\in(-5/100, 1/100))=1-2p$ We have $52$ weeks per year so $i\in\{1,...,52\}$ Now lets assume we have $k$ weeks per year where index does not change more that 5%, and $i-k$ where it does. My guess is that he has to wait a specific number a week and than makes the guess, but how can I prove that?","I have the following problem: A financial advisor tries to impress his clients if immediately   following a week in which the ftse index moves by more than   $5\%$ in some direction he correctly predicts that this is the last   week during the calendar year that it moves more than $5\%$ in   that direction. Suppose that in each week the change in the index is independently   up by at least $5\%$, down by at least $5\%$ or neither of   these, with probabilities $p$, $p$ and $1 - 2p$ respectively ($p\le1/2$).   He makes at most one prediction this year. With what strategy   does he maximize the probability of impressing his clients? Source I think the goal is to use backwards induction. I start to formalize everything. Let $X_i$ be a random variable which represents how the market change in week $i$, therefore $P(X_i>0.05)=p=P(X_i<-0.05), P(X_i\in(-5/100, 1/100))=1-2p$ We have $52$ weeks per year so $i\in\{1,...,52\}$ Now lets assume we have $k$ weeks per year where index does not change more that 5%, and $i-k$ where it does. My guess is that he has to wait a specific number a week and than makes the guess, but how can I prove that?",,"['probability', 'combinatorics', 'optimization', 'decision-theory']"
10,"Copulas, implication","Copulas, implication",,"Let $C$ be a copula function. Prove that $C(t,1-t)=0$ for all $t\in[0,1]$ implies that $C(u,v)=\max(u+v-1,0)$. I think the implication other way around is easy to see, however I can't see why the ""upper diagonal"" part of the copula function could not be some type of a different function with $C(u,1)=u$ and $C(1,v)=v$. See the image below - the leftmost plot is the Frechet-Hoeffding lower bound. I need to prove that $C$ is equal to that.","Let $C$ be a copula function. Prove that $C(t,1-t)=0$ for all $t\in[0,1]$ implies that $C(u,v)=\max(u+v-1,0)$. I think the implication other way around is easy to see, however I can't see why the ""upper diagonal"" part of the copula function could not be some type of a different function with $C(u,1)=u$ and $C(1,v)=v$. See the image below - the leftmost plot is the Frechet-Hoeffding lower bound. I need to prove that $C$ is equal to that.",,"['probability', 'special-functions']"
11,I want to show $E(X)=\sum_{n=1}^{\infty}P(X\ge n)$ [closed],I want to show  [closed],E(X)=\sum_{n=1}^{\infty}P(X\ge n),"Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 10 years ago . Improve this question Let $X:\Omega \to \mathbb N$ be a random variable on probability space $(\Omega,\mathcal B,P)$ .show that $$E(X)=\sum_{n=1}^{\infty}P(X\ge n).$$ my definition from $E(X)$ is equal $$E(X)=\int_{\Omega}XdP.$$ $\mathcal B$ is Borel $\sigma $-algebra Thanks. I think we can write $E(X) = \sum_i x_i \cdot P(X = x_i)$. $P( X \ge i ) = P( X = i ) + P( X = i + 1 ) + \dots$ and get summation from both side but this idea for discrete but in question  do not mention X is discrete or Continuous.","Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 10 years ago . Improve this question Let $X:\Omega \to \mathbb N$ be a random variable on probability space $(\Omega,\mathcal B,P)$ .show that $$E(X)=\sum_{n=1}^{\infty}P(X\ge n).$$ my definition from $E(X)$ is equal $$E(X)=\int_{\Omega}XdP.$$ $\mathcal B$ is Borel $\sigma $-algebra Thanks. I think we can write $E(X) = \sum_i x_i \cdot P(X = x_i)$. $P( X \ge i ) = P( X = i ) + P( X = i + 1 ) + \dots$ and get summation from both side but this idea for discrete but in question  do not mention X is discrete or Continuous.",,"['probability', 'probability-theory', 'expectation']"
12,The joint density of the max and min of two independent exponentials,The joint density of the max and min of two independent exponentials,,"Let $X=\min(S,T)$ and $Y=\max(S,T)$ for independent exponential variables $S$ and $T$. Find the joint density of $X$ and $Y$. Are $X$ and $Y$ independent? How would you suggest I approach this?","Let $X=\min(S,T)$ and $Y=\max(S,T)$ for independent exponential variables $S$ and $T$. Find the joint density of $X$ and $Y$. Are $X$ and $Y$ independent? How would you suggest I approach this?",,"['probability', 'probability-distributions']"
13,Probability of an ECM factor,Probability of an ECM factor,,"Suppose I have a composite number $N$ divisible by some prime $p\le x.$ What is the probability that one iteration of ECM finds $p$, given parameters B1 and B2? Usually people look for factors in bands, with the probability of failure set to $1/e$ for primes of a given size. I'm interested in giving probabilistic strength that no sufficiently-small prime was missed. So maybe a number was tested enough to ensure that with probability $1-1/e$ it has no prime factors smaller than $10^{40}$; I'd like to be able to say that if there was a prime factor smaller than $10^{30}$, it would have been found with probability 99.9% (and so, having not found one, either there is no such prime or we have witnessed a rare event).","Suppose I have a composite number $N$ divisible by some prime $p\le x.$ What is the probability that one iteration of ECM finds $p$, given parameters B1 and B2? Usually people look for factors in bands, with the probability of failure set to $1/e$ for primes of a given size. I'm interested in giving probabilistic strength that no sufficiently-small prime was missed. So maybe a number was tested enough to ensure that with probability $1-1/e$ it has no prime factors smaller than $10^{40}$; I'd like to be able to say that if there was a prime factor smaller than $10^{30}$, it would have been found with probability 99.9% (and so, having not found one, either there is no such prime or we have witnessed a rare event).",,"['probability', 'factoring', 'elliptic-curves', 'cryptography', 'prime-factorization']"
14,Finding a moment generating function given E(X) and E(x^2),Finding a moment generating function given E(X) and E(x^2),,"I am trying to find the moment generating function. It takes values in the set {0,1,2} with moments E(X) = 1 and E($X^{2}$) = $ \frac 3 2 $ I know then that M'(0) = 1 and M""(0) =  $\frac 3 2 $ I have read through my course notes/ textbook and have found nothing. If anyone has an idea where I can go with what I have, I would appreciate it.","I am trying to find the moment generating function. It takes values in the set {0,1,2} with moments E(X) = 1 and E($X^{2}$) = $ \frac 3 2 $ I know then that M'(0) = 1 and M""(0) =  $\frac 3 2 $ I have read through my course notes/ textbook and have found nothing. If anyone has an idea where I can go with what I have, I would appreciate it.",,"['probability', 'statistics']"
15,"Let $X$ be a discrete random variable with probability function $P(X=x)=\frac2{3^x}$ for $x = 1,2,3,\ldots$ What is the probability that $X$ is even?",Let  be a discrete random variable with probability function  for  What is the probability that  is even?,"X P(X=x)=\frac2{3^x} x = 1,2,3,\ldots X","Let $X$ be a discrete random variable with probability function $P(X=x) = \frac{2}{3^x}$ for $x = 1,2,3,\ldots$ What is the probability that $X$ is even? I have: $$\frac2{3^2}+\frac2{3^4}+\frac2{3^6}+\ldots$$ which is a geometric series of the form $$\sum_{n=1}^\infty ar^n$$ where $a = \frac29$ and $r=\frac19$. Then I used the formula for finding the sum of a geometric series to find the sum/probability \begin{align} \sum_{n=1}^\infty ar^n &= \frac{a}{1-r} \\  &= \frac{\frac29}{1-\frac19} \\  &= \frac{2/9}{8/9} = \frac28 = \frac14 \end{align} Correct?","Let $X$ be a discrete random variable with probability function $P(X=x) = \frac{2}{3^x}$ for $x = 1,2,3,\ldots$ What is the probability that $X$ is even? I have: $$\frac2{3^2}+\frac2{3^4}+\frac2{3^6}+\ldots$$ which is a geometric series of the form $$\sum_{n=1}^\infty ar^n$$ where $a = \frac29$ and $r=\frac19$. Then I used the formula for finding the sum of a geometric series to find the sum/probability \begin{align} \sum_{n=1}^\infty ar^n &= \frac{a}{1-r} \\  &= \frac{\frac29}{1-\frac19} \\  &= \frac{2/9}{8/9} = \frac28 = \frac14 \end{align} Correct?",,['probability']
16,What's the mode of a bivariate Poisson distribution?,What's the mode of a bivariate Poisson distribution?,,I have been looking at the bivariate Poisson distribution of the form as it is described at Wikipedia: http://en.wikipedia.org/wiki/Poisson_distribution#Bivariate_Poisson_distribution I was now wondering if there is close form expression for the mode of this distribution. I know the mode of the univariate Poisson distribution is $\lfloor \lambda\rfloor$. Thanks for any feedback!,I have been looking at the bivariate Poisson distribution of the form as it is described at Wikipedia: http://en.wikipedia.org/wiki/Poisson_distribution#Bivariate_Poisson_distribution I was now wondering if there is close form expression for the mode of this distribution. I know the mode of the univariate Poisson distribution is $\lfloor \lambda\rfloor$. Thanks for any feedback!,,"['probability', 'statistics', 'probability-distributions']"
17,Find the expected number of '01's in a string,Find the expected number of '01's in a string,,"This is an interview question: For strings of length m + n, with m 0's and n 1's. Find the expected number of switches from 0 to 1 (a switch can be thought of as presence of '01' in the given string). I have tried solving it as follows: Let Xi denote a random variable such that a '01' pattern occurs in the string for a particular '0'. Then W = X1 + X2 + ............. + Xm and we have to find E[W]. Now E[W] = E[X1] + E[X2] + E[X3] + ............... + E[Xm] Now E[X1] is same as finding expectation such that 0 comes before any 1. It should be n/n+1. This holds for all Xi's. Therefore E[W] = mn/n+1. And this is our final answer. Please let me know if this is the right approach.","This is an interview question: For strings of length m + n, with m 0's and n 1's. Find the expected number of switches from 0 to 1 (a switch can be thought of as presence of '01' in the given string). I have tried solving it as follows: Let Xi denote a random variable such that a '01' pattern occurs in the string for a particular '0'. Then W = X1 + X2 + ............. + Xm and we have to find E[W]. Now E[W] = E[X1] + E[X2] + E[X3] + ............... + E[Xm] Now E[X1] is same as finding expectation such that 0 comes before any 1. It should be n/n+1. This holds for all Xi's. Therefore E[W] = mn/n+1. And this is our final answer. Please let me know if this is the right approach.",,"['probability', 'combinatorics', 'expectation']"
18,Random walk on one-dimensional lattice - understanding the expression $pe^{i\theta} + qe^{-i\theta}$,Random walk on one-dimensional lattice - understanding the expression,pe^{i\theta} + qe^{-i\theta},"I've started reading the book - First Steps in Random Walks and in the very first example in Chapter 1 they talk about a random walk on a one-dimensional lattice. If we consider a particle starting from $0$, it says that steps to the right are performed with probability $p$ and steps to the right are performed with probability $q = 1 - p$. The position of the particle after $n$ steps is determined by the number of steps to the right and to the left. It then introduces the following expression that it describes as an instrument that allows for finding the positions of the particle - $$pe^{i\theta} + qe^{-i\theta}$$ with the coefficients $p$ and $q$ being the probabilities that the first step was to the right and left respectively. If we square the expression $$(pe^{i\theta} + qe^{-i\theta})^2 = p^2 e^{2i\theta} + 2pq + q^2 e^{-2i\theta}$$ it says that the coefficient of the first term of the expansion gives the probability that the first two steps were to the right, the second term corresponds to the probability that the first two steps were made in opposite directions, and the coefficient of the third term gives the probability that the first two steps were to the left. Question I don't see the reasoning for the expression $$pe^{i\theta} + qe^{-i\theta}$$ Where are they getting this complex analysis type expression from? Why are we dealing with $\theta$ when we are in a one dimensional space? Why does squaring the expression 'magically' gives the probabilities of where we will be after two steps?","I've started reading the book - First Steps in Random Walks and in the very first example in Chapter 1 they talk about a random walk on a one-dimensional lattice. If we consider a particle starting from $0$, it says that steps to the right are performed with probability $p$ and steps to the right are performed with probability $q = 1 - p$. The position of the particle after $n$ steps is determined by the number of steps to the right and to the left. It then introduces the following expression that it describes as an instrument that allows for finding the positions of the particle - $$pe^{i\theta} + qe^{-i\theta}$$ with the coefficients $p$ and $q$ being the probabilities that the first step was to the right and left respectively. If we square the expression $$(pe^{i\theta} + qe^{-i\theta})^2 = p^2 e^{2i\theta} + 2pq + q^2 e^{-2i\theta}$$ it says that the coefficient of the first term of the expansion gives the probability that the first two steps were to the right, the second term corresponds to the probability that the first two steps were made in opposite directions, and the coefficient of the third term gives the probability that the first two steps were to the left. Question I don't see the reasoning for the expression $$pe^{i\theta} + qe^{-i\theta}$$ Where are they getting this complex analysis type expression from? Why are we dealing with $\theta$ when we are in a one dimensional space? Why does squaring the expression 'magically' gives the probabilities of where we will be after two steps?",,"['probability', 'stochastic-processes', 'markov-chains', 'random-walk']"
19,"definition of ""weak convergence in $L^1$""","definition of ""weak convergence in """,L^1,"I have encountered two definitions of weak convergence in $L^1$: 1) $X_n\rightarrow X$ weakly in $L_1$ iff $\mathrm{E}(X_n\mathrm{1}_A)\rightarrow \mathrm{E}(X\mathrm{1}_A)$ for every measurable set $A$. 2) $X_n\rightarrow X$ weakly in $L_1$ iff $\mathrm{E}(X_n f)\rightarrow \mathrm{E}(X\mathrm{1}f)$ for every (essentially) bounded measurable function $f$. my question: are 1) and 2) equivalent? I see that 2) implies 1) (indicators are bounded), but I have difficulties establishing that 1) implies 2). I tried approximating $f$ by simple functions $f_m$, say, assuming $X_n,X$ are nonnegative for simplicity; the problem: I cannot justify the interchange in the order of taking the limits (first with $n$, and then with $m$). any ideas? I would appreciate any sort of help. many thanks!","I have encountered two definitions of weak convergence in $L^1$: 1) $X_n\rightarrow X$ weakly in $L_1$ iff $\mathrm{E}(X_n\mathrm{1}_A)\rightarrow \mathrm{E}(X\mathrm{1}_A)$ for every measurable set $A$. 2) $X_n\rightarrow X$ weakly in $L_1$ iff $\mathrm{E}(X_n f)\rightarrow \mathrm{E}(X\mathrm{1}f)$ for every (essentially) bounded measurable function $f$. my question: are 1) and 2) equivalent? I see that 2) implies 1) (indicators are bounded), but I have difficulties establishing that 1) implies 2). I tried approximating $f$ by simple functions $f_m$, say, assuming $X_n,X$ are nonnegative for simplicity; the problem: I cannot justify the interchange in the order of taking the limits (first with $n$, and then with $m$). any ideas? I would appreciate any sort of help. many thanks!",,"['probability', 'analysis', 'measure-theory', 'probability-theory', 'weak-convergence']"
20,The probability P[X < g(Y)],The probability P[X < g(Y)],,"Suppose that $X$ and $Y$ are independent continuous random variables having densities $f_X$ and $f_Y$ , respectively. What is the probability of $P[X < g(Y)]$ being $g(\cdot)$ a continous functions?","Suppose that $X$ and $Y$ are independent continuous random variables having densities $f_X$ and $f_Y$ , respectively. What is the probability of $P[X < g(Y)]$ being $g(\cdot)$ a continous functions?",,"['probability', 'probability-theory', 'random-variables']"
21,Prove Poissons' theorem,Prove Poissons' theorem,,"Let $(\Omega, \Sigma, \mathbb{P})$ be a probability space. If $A_1, A_2, \ldots$ are independent events and $\bar{p}_n$ and $N$ are defined as $$ \bar{p}_n=\frac{1}{n}\sum_{i=1}^n\mathbb{P}(A_i) \quad \text{and} \quad N_n=\sum_{i=1}^n \mathbf{1}_{A_i}$$ then $\frac{N_n}{n}-\bar{p}_n \to 0$ in probability. This problem is from Billingsley (3rd edition, #6.5). I currently have the laws of large numbers at my disposal but since the sequence here is not i.i.d., I guess I need to invoke heavier machinery. Thank you for any help!","Let $(\Omega, \Sigma, \mathbb{P})$ be a probability space. If $A_1, A_2, \ldots$ are independent events and $\bar{p}_n$ and $N$ are defined as $$ \bar{p}_n=\frac{1}{n}\sum_{i=1}^n\mathbb{P}(A_i) \quad \text{and} \quad N_n=\sum_{i=1}^n \mathbf{1}_{A_i}$$ then $\frac{N_n}{n}-\bar{p}_n \to 0$ in probability. This problem is from Billingsley (3rd edition, #6.5). I currently have the laws of large numbers at my disposal but since the sequence here is not i.i.d., I guess I need to invoke heavier machinery. Thank you for any help!",,"['probability', 'probability-theory', 'law-of-large-numbers']"
22,Conditional PDFof $Y-X$ given $X=x$ and conditional distribution of $X/Y$ given $Y=y$,Conditional PDFof  given  and conditional distribution of  given,Y-X X=x X/Y Y=y,"Suppose I have a joint distribution with  PDF $f(x,y)$, then the marginal PDF of $X$ is $f_X(x)$ and the marginal PDF of $Y$ is $f_Y(y)$. How are the formula to determine Conditional PDF of  $(Y-X)$ given $X=x$ and Conditional distribution of $(X/Y)$ given $Y=y$? Thanks in Advanced...","Suppose I have a joint distribution with  PDF $f(x,y)$, then the marginal PDF of $X$ is $f_X(x)$ and the marginal PDF of $Y$ is $f_Y(y)$. How are the formula to determine Conditional PDF of  $(Y-X)$ given $X=x$ and Conditional distribution of $(X/Y)$ given $Y=y$? Thanks in Advanced...",,['probability']
23,What almost sure convergence means in the context of strong law of large numbers,What almost sure convergence means in the context of strong law of large numbers,,"According to http://en.wikipedia.org/wiki/Almost_sure_convergence#Almost_sure_convergence , a sequence  of random variables $X_n$, which are a function of a shared sample space $Ω$, is said to converge almost surely to $X$ when: $     \operatorname{Pr}\Big( \omega \in \Omega : \lim_{n \to \infty} X_n(\omega) = X(\omega) \Big) = 1.   $ The strong law of large numbers says the sample average converges almost surely to the expected value: $     \overline{X}_n\ \xrightarrow{a.s.}\ \mu \qquad\textrm{when}\ n \to \infty.   $ I  am confused as to what this means. For every $n$, $\overline{X}_n$ has a different sample space - the cartesian product corresponding to $n$ i.i.d instances of $X$. How can the definition of almost sure convergence apply here? What is the shared sample space?","According to http://en.wikipedia.org/wiki/Almost_sure_convergence#Almost_sure_convergence , a sequence  of random variables $X_n$, which are a function of a shared sample space $Ω$, is said to converge almost surely to $X$ when: $     \operatorname{Pr}\Big( \omega \in \Omega : \lim_{n \to \infty} X_n(\omega) = X(\omega) \Big) = 1.   $ The strong law of large numbers says the sample average converges almost surely to the expected value: $     \overline{X}_n\ \xrightarrow{a.s.}\ \mu \qquad\textrm{when}\ n \to \infty.   $ I  am confused as to what this means. For every $n$, $\overline{X}_n$ has a different sample space - the cartesian product corresponding to $n$ i.i.d instances of $X$. How can the definition of almost sure convergence apply here? What is the shared sample space?",,"['probability', 'measure-theory', 'convergence-divergence']"
24,Expected value with indicator random variables,Expected value with indicator random variables,,"I don't understand the solution for problem 7a at http://www.ma.utexas.edu/users/geir/teaching/m362k/weeklyhw9solns.pdf . Reproduced below for reference: Suppose that A and B each randomly, and independently,   choose 3 of 10 objects. Find the expected number of objects chosen by both A and B. solution: Let $X$ be the number of objects chosen by both A and B. For $1 \le i \le 10$, let $$ \begin{align} X_i = \begin{cases} 1 &\mbox{if } \text{object i is chosen by A and B} \\ 0 &\mbox{otherwise } \end{cases}  \end{align} $$   Then $X = X_1 + ... + X_{10}$. We find $$ E[X_i] = 0\cdot P(X_i = 0) + 1\cdot P(X_i = 1) = P(X_i = 1) = 9/100. $$   By the linearity of expectation, $$E[X] = 10\cdot E[X_i] = 0.9$$ I don't understand how they reduced $E[X_i]$ (don't they need $P(X_i = 2, 3, ..., 10)$ terms?) and how $9/100$ was computed.","I don't understand the solution for problem 7a at http://www.ma.utexas.edu/users/geir/teaching/m362k/weeklyhw9solns.pdf . Reproduced below for reference: Suppose that A and B each randomly, and independently,   choose 3 of 10 objects. Find the expected number of objects chosen by both A and B. solution: Let $X$ be the number of objects chosen by both A and B. For $1 \le i \le 10$, let $$ \begin{align} X_i = \begin{cases} 1 &\mbox{if } \text{object i is chosen by A and B} \\ 0 &\mbox{otherwise } \end{cases}  \end{align} $$   Then $X = X_1 + ... + X_{10}$. We find $$ E[X_i] = 0\cdot P(X_i = 0) + 1\cdot P(X_i = 1) = P(X_i = 1) = 9/100. $$   By the linearity of expectation, $$E[X] = 10\cdot E[X_i] = 0.9$$ I don't understand how they reduced $E[X_i]$ (don't they need $P(X_i = 2, 3, ..., 10)$ terms?) and how $9/100$ was computed.",,"['probability', 'random-variables']"
25,Maximum run of zeros in a $n$-bit binary string,Maximum run of zeros in a -bit binary string,n,"I came to know that, in a random string, one expects the longest sequence of zeros to be roughly of length $\log n$. I want to be able to prove this. For this I need to know the probability that the longest sequence of zeros in a random $n$-bit string is of length $k$. Basically I need a good counting strategy to count the number of such $n$-bit strings i.e., where maximum run of zeros is of length $k$. Can somebody give a hint on how to proceed? I don't want a full answer.","I came to know that, in a random string, one expects the longest sequence of zeros to be roughly of length $\log n$. I want to be able to prove this. For this I need to know the probability that the longest sequence of zeros in a random $n$-bit string is of length $k$. Basically I need a good counting strategy to count the number of such $n$-bit strings i.e., where maximum run of zeros is of length $k$. Can somebody give a hint on how to proceed? I don't want a full answer.",,"['probability', 'binary']"
26,Sum of Random Variables...,Sum of Random Variables...,,"Imagine we repeat the following loop some thousands of times: $$ \begin{align} & \text{array} = []\\ & \text{for n} = 1: 10 000 \\ & k = 0 \\ & \text{while unifrnd}(0,1) < 0.3 \\ & k = k + 1 \\ & \text{end} \\ & \text{if k} \neq 0 \\ & \text{array} = [\text{array,k}] \\ & \text{end} \\ \end{align} $$ whereas ""unifrnd(0,1)"" means a random number drawn from the uniform distribution on the unit interval. My question is then: What is then the value of k, which is the most often observed - except for k = 0? And is that the expectation of k? Thanks very much","Imagine we repeat the following loop some thousands of times: $$ \begin{align} & \text{array} = []\\ & \text{for n} = 1: 10 000 \\ & k = 0 \\ & \text{while unifrnd}(0,1) < 0.3 \\ & k = k + 1 \\ & \text{end} \\ & \text{if k} \neq 0 \\ & \text{array} = [\text{array,k}] \\ & \text{end} \\ \end{align} $$ whereas ""unifrnd(0,1)"" means a random number drawn from the uniform distribution on the unit interval. My question is then: What is then the value of k, which is the most often observed - except for k = 0? And is that the expectation of k? Thanks very much",,[]
27,Geometric Brownian motion,Geometric Brownian motion,,"This question is related to conditional expectation of a geometric Brownian motion. The price of a stock is $10$ times a Geometric Brownian Motion with drift $\mu  = 0.05$ and $\sigma  = 0.2$.   Assume the stock price is $30$ at time $16$. What is the expected value of the stock price at time $25$? The answer is $56.3283$ What formula should I use to get this answer? According to the question, the stock price is $S(t) = 10{e^{x(t)}}$ Should I use $E[Z(t)] = {e^{\mu t + {{\sigma {t^2}} \over 2}}}$? Thanks in advance.","This question is related to conditional expectation of a geometric Brownian motion. The price of a stock is $10$ times a Geometric Brownian Motion with drift $\mu  = 0.05$ and $\sigma  = 0.2$.   Assume the stock price is $30$ at time $16$. What is the expected value of the stock price at time $25$? The answer is $56.3283$ What formula should I use to get this answer? According to the question, the stock price is $S(t) = 10{e^{x(t)}}$ Should I use $E[Z(t)] = {e^{\mu t + {{\sigma {t^2}} \over 2}}}$? Thanks in advance.",,"['probability', 'brownian-motion']"
28,Integral of product of normal cdf and pdf,Integral of product of normal cdf and pdf,,"What do you think, is there a closed form solution of the following Integral $\textbf{ }$ $$\int_{-\infty}^{a-y}n(x)\, N(b-2y-x)\, dx,$$ where $N(x)=\int_{-\infty}^x n(z)\, dz\quad$ and $\quad n(z)=\frac{1}{\sqrt{2\pi}}e^{-\frac{z^2}{2}},\ $ i.e. normal cdf and pdf. Thank you for your contribution.","What do you think, is there a closed form solution of the following Integral $\textbf{ }$ $$\int_{-\infty}^{a-y}n(x)\, N(b-2y-x)\, dx,$$ where $N(x)=\int_{-\infty}^x n(z)\, dz\quad$ and $\quad n(z)=\frac{1}{\sqrt{2\pi}}e^{-\frac{z^2}{2}},\ $ i.e. normal cdf and pdf. Thank you for your contribution.",,"['probability', 'integration', 'probability-distributions', 'definite-integrals']"
29,Find the probability of having 3 cards of the same suit and 2 cards of the same suit in a 5 card hand from a standard 52 card deck? (Method),Find the probability of having 3 cards of the same suit and 2 cards of the same suit in a 5 card hand from a standard 52 card deck? (Method),,"I'm trying to understand why my method doesn't work to answer the question: What is the probability of having 3 cards of the same suit and $2$ cards of the same suit (but a different suit than the first three) in a $5$ card hand from a standard $52$ card deck? The method that seems to work uses combinations. You do: $$ {4 \choose 1}\cdot{13 \choose 3}\cdot{3 \choose 1}\cdot{13 \choose 2} = 267,696 $$ To find the number of successful possibilities and then $$ {52 \choose 5} = 2,598,960 $$ To find the number of total possibilities. So the answer is: $$ \frac{267,696}{2,598,960} $$ I'm wondering why figuring out the individual card chances and then multiplying them doesn't work. My method goes like this:  $$ \frac{12}{51}\cdot\frac{11}{50}\cdot\frac{39}{49}\cdot\frac{12}{48} $$ After you've picked your first card you have a $\frac{12}{51}$ chance of getting a matching second card, then you've a $\frac{11}{50}$ chance of getting your third card to match. For the other two cards you've a $\frac{39}{49}$ chance, because you still have three suits left. You need the next one to match, so now you have a $\frac{12}{48}$ chance. Shouldn't multiplying all of those individual probabilities yield the same answer as the first method? I realize that there are different ways to order the individual probabilities, but when they're all multiplying, shouldn't it all work out to be the same? I've noticed that multiplying the answer to my method by $10$ makes it equal to the first method's answer. Is there a reason that works?","I'm trying to understand why my method doesn't work to answer the question: What is the probability of having 3 cards of the same suit and $2$ cards of the same suit (but a different suit than the first three) in a $5$ card hand from a standard $52$ card deck? The method that seems to work uses combinations. You do: $$ {4 \choose 1}\cdot{13 \choose 3}\cdot{3 \choose 1}\cdot{13 \choose 2} = 267,696 $$ To find the number of successful possibilities and then $$ {52 \choose 5} = 2,598,960 $$ To find the number of total possibilities. So the answer is: $$ \frac{267,696}{2,598,960} $$ I'm wondering why figuring out the individual card chances and then multiplying them doesn't work. My method goes like this:  $$ \frac{12}{51}\cdot\frac{11}{50}\cdot\frac{39}{49}\cdot\frac{12}{48} $$ After you've picked your first card you have a $\frac{12}{51}$ chance of getting a matching second card, then you've a $\frac{11}{50}$ chance of getting your third card to match. For the other two cards you've a $\frac{39}{49}$ chance, because you still have three suits left. You need the next one to match, so now you have a $\frac{12}{48}$ chance. Shouldn't multiplying all of those individual probabilities yield the same answer as the first method? I realize that there are different ways to order the individual probabilities, but when they're all multiplying, shouldn't it all work out to be the same? I've noticed that multiplying the answer to my method by $10$ makes it equal to the first method's answer. Is there a reason that works?",,"['probability', 'combinatorics', 'statistics', 'card-games']"
30,Optimal strategy puzzle,Optimal strategy puzzle,,Play a game with an urn. $75$ blue balls. $25$ red balls. $1$ yellow ball. you get a dollar for every red and if you select the yellow you lose everything. what should be your strategy in the game. you can choose to stop or re-draw after every ball.,Play a game with an urn. $75$ blue balls. $25$ red balls. $1$ yellow ball. you get a dollar for every red and if you select the yellow you lose everything. what should be your strategy in the game. you can choose to stop or re-draw after every ball.,,"['probability', 'optimization']"
31,Random Walk on Z,Random Walk on Z,,Let $S_n$ be the symmetric random walk on $\mathbb{Z}$. How do i calculate $P(\limsup_{n\rightarrow\infty} S_n=\infty)$? I already know that the probability is 1 but I don't really know how to start? Anyone got some advice? The more basic the better! Thanks a lot!,Let $S_n$ be the symmetric random walk on $\mathbb{Z}$. How do i calculate $P(\limsup_{n\rightarrow\infty} S_n=\infty)$? I already know that the probability is 1 but I don't really know how to start? Anyone got some advice? The more basic the better! Thanks a lot!,,"['probability', 'measure-theory', 'probability-theory', 'random-walk']"
32,Probability that at least one fails,Probability that at least one fails,,"A certain component of an electronic device has a probability of $0.1$ of failing. If there are $6$ such components in a circuit. What is the probability that at least one fails? The Answer is $0.47$. My Solution: At least $1$ means more than $1$ failures $P(1\, \text{fail}) = 0.1 \\ P(2\, \text{fails})=0.1\times0.1 \\P(3\, \text{fails})=0.1^{3}\\P(4\, \text{fails})=0.1^{4}\\P(5\, \text{fails})=0.1^{5}\\P(6\, \text{fails})=0.1^6\\ P(\text{Total})=P(1) +P(2)+...+P(6)=0.111111$ Where did I get wrong?","A certain component of an electronic device has a probability of $0.1$ of failing. If there are $6$ such components in a circuit. What is the probability that at least one fails? The Answer is $0.47$. My Solution: At least $1$ means more than $1$ failures $P(1\, \text{fail}) = 0.1 \\ P(2\, \text{fails})=0.1\times0.1 \\P(3\, \text{fails})=0.1^{3}\\P(4\, \text{fails})=0.1^{4}\\P(5\, \text{fails})=0.1^{5}\\P(6\, \text{fails})=0.1^6\\ P(\text{Total})=P(1) +P(2)+...+P(6)=0.111111$ Where did I get wrong?",,['probability']
33,Sum of Cauchy distributed random variables,Sum of Cauchy distributed random variables,,"Problem: Let $X_1, X_2, \ldots $ be independent $C(0,1)$ and set $S_n = \sum_{k=1}^n X_k$. Show that $\frac{1}{n}\sum_{k=1}^n \frac{S_k}{k}\sim C(0,1)$. Using the characteristic function it is easy to get that $\frac{S_k}{k}$ is $C(0,1)$. But $Y_k=\frac{S_k}{k}$ are not independent for different $k$ so that cannot be applied directly in this case.","Problem: Let $X_1, X_2, \ldots $ be independent $C(0,1)$ and set $S_n = \sum_{k=1}^n X_k$. Show that $\frac{1}{n}\sum_{k=1}^n \frac{S_k}{k}\sim C(0,1)$. Using the characteristic function it is easy to get that $\frac{S_k}{k}$ is $C(0,1)$. But $Y_k=\frac{S_k}{k}$ are not independent for different $k$ so that cannot be applied directly in this case.",,['probability']
34,Rigorous probability text for math major,Rigorous probability text for math major,,"Most probability texts that do not use measure theory seemed to be geared toward engineers and the like, while more advanced texts already assume a strong background in measure theory and Lebesgue integration. I'm not too familiar with measure theory, (my analysis background is limited to Rudin's PMA Ch. 1 - 10), so I'd appreciate some recommendations that do not assume an analysis background beyond Rudin's PMA.  I'd be okay with a text that uses measure and Lebesgue theory as long as it sufficiently presents the material on its own. Thank you very much.","Most probability texts that do not use measure theory seemed to be geared toward engineers and the like, while more advanced texts already assume a strong background in measure theory and Lebesgue integration. I'm not too familiar with measure theory, (my analysis background is limited to Rudin's PMA Ch. 1 - 10), so I'd appreciate some recommendations that do not assume an analysis background beyond Rudin's PMA.  I'd be okay with a text that uses measure and Lebesgue theory as long as it sufficiently presents the material on its own. Thank you very much.",,"['probability', 'analysis', 'reference-request']"
35,An irregular 6 faced dice,An irregular 6 faced dice,,An irregular 6 faced dice is such that the probability that it gives 3 even numbers in 5 throws is twice the probability that it gives 2 even numbers in 5 throws. How many sets of exactly 5 trials can be expected to give no even number out of 2500 sets? (1) Nearly 5 (2) Nearly 10 (3) Nearly 15 (4) Nearly 20,An irregular 6 faced dice is such that the probability that it gives 3 even numbers in 5 throws is twice the probability that it gives 2 even numbers in 5 throws. How many sets of exactly 5 trials can be expected to give no even number out of 2500 sets? (1) Nearly 5 (2) Nearly 10 (3) Nearly 15 (4) Nearly 20,,['probability']
36,Is there an exponential bound for $(1+p)^{-n}$ when $p$ is small?,Is there an exponential bound for  when  is small?,(1+p)^{-n} p,Is there an exponential upper bound for $(1+p)^{-n}$ when $0<p<1$? Similarly a exponential lower bound for $(1+p)^n$ will also be good.  Do you know of any resources where one can pick up bounds as such quickly? Thanks.,Is there an exponential upper bound for $(1+p)^{-n}$ when $0<p<1$? Similarly a exponential lower bound for $(1+p)^n$ will also be good.  Do you know of any resources where one can pick up bounds as such quickly? Thanks.,,"['probability', 'inequality']"
37,Chance of getting a good grade,Chance of getting a good grade,,"Lets says theres a question bank of 28 questions.  On the exam, there will be 12 of these questions, and I will have to answer 5. If the only way to get a question right is to study it, how many questions should I study to have a reasonable chance of knowing 5 answers? More generally, how could I find out my expected score as a function of how many questions I study? Obviously if I study 21, then I will get 100%, and if I study less than 5, I'm guaranteed to not get at least 5.","Lets says theres a question bank of 28 questions.  On the exam, there will be 12 of these questions, and I will have to answer 5. If the only way to get a question right is to study it, how many questions should I study to have a reasonable chance of knowing 5 answers? More generally, how could I find out my expected score as a function of how many questions I study? Obviously if I study 21, then I will get 100%, and if I study less than 5, I'm guaranteed to not get at least 5.",,['probability']
38,Chance of being able to quit while ahead in a betting game (Markov chain with gambler's ruin),Chance of being able to quit while ahead in a betting game (Markov chain with gambler's ruin),,"Suppose a player starts with $N$ chips, and is playing a game with odds $O$, betting 1 chip in each iteration.  When the player reaches 0 chips the betting must end. What is the probability that at some point the player has $N+M$ chips (i.e. $M$ more than they started with)? The most interesting question here to me is -- are there games with disfavorable odds where the player is still more likely than not to have more than $N$ chips at some point (e.g. games where the most likely outcome is a downward sawtooth that exceeds $N$ at some points before reaching 0)?","Suppose a player starts with $N$ chips, and is playing a game with odds $O$, betting 1 chip in each iteration.  When the player reaches 0 chips the betting must end. What is the probability that at some point the player has $N+M$ chips (i.e. $M$ more than they started with)? The most interesting question here to me is -- are there games with disfavorable odds where the player is still more likely than not to have more than $N$ chips at some point (e.g. games where the most likely outcome is a downward sawtooth that exceeds $N$ at some points before reaching 0)?",,"['probability', 'markov-chains', 'random-walk']"
39,Maximum and Minimum Variance,Maximum and Minimum Variance,,"Let $p_i =P(X=i)$ and suppose that $p_1+p_2+p_3=1$. If $E[X]=2$, what values of $p_1,p_2,p_3$ (a) maximize and (b) minimize $Var(X)$? So far I have $Var(X)=E[(X-E[X])^2]=E[(X-2)^2 =E[X^2-4X+4]=E[X^2]-E[4X]+E[4]=E[X^2]-8+4=E[X^2]-4$ $E[X^2]=x_1^2p_1+x_2^2p_2+x_3^2p_3$ I'm not considering some information, how can I solve this?","Let $p_i =P(X=i)$ and suppose that $p_1+p_2+p_3=1$. If $E[X]=2$, what values of $p_1,p_2,p_3$ (a) maximize and (b) minimize $Var(X)$? So far I have $Var(X)=E[(X-E[X])^2]=E[(X-2)^2 =E[X^2-4X+4]=E[X^2]-E[4X]+E[4]=E[X^2]-8+4=E[X^2]-4$ $E[X^2]=x_1^2p_1+x_2^2p_2+x_3^2p_3$ I'm not considering some information, how can I solve this?",,['probability']
40,Mean preserving spread vs higher variance,Mean preserving spread vs higher variance,,"In the Wikipedia article for mean-preserving spread , the following is claimed without citation: If B is a mean-preserving spread of A, then B has a higher variance than A; but the converse is not in general true, because the variance is a complete ordering while ordering by mean-preserving spreads is only partial. My intuition about the very meaning of ""B is a mean-preserving spread of A"" has been that the B distribution enjoys the same mean but a higher variance than A. I usually think of this as a risk-averse individual preferring the certainty of winning a dollar to a $.001$ chance of winning $1,000. In my mind, the individual would rank lotteries A and B as follows: Comparing the means of A and B Comparing the variances of A and B And if 1 and 2 turn out to be equal, then the risk-averse individual is indifferent between A and B. But according to this article, that is false. What am I missing?","In the Wikipedia article for mean-preserving spread , the following is claimed without citation: If B is a mean-preserving spread of A, then B has a higher variance than A; but the converse is not in general true, because the variance is a complete ordering while ordering by mean-preserving spreads is only partial. My intuition about the very meaning of ""B is a mean-preserving spread of A"" has been that the B distribution enjoys the same mean but a higher variance than A. I usually think of this as a risk-averse individual preferring the certainty of winning a dollar to a $.001$ chance of winning $1,000. In my mind, the individual would rank lotteries A and B as follows: Comparing the means of A and B Comparing the variances of A and B And if 1 and 2 turn out to be equal, then the risk-averse individual is indifferent between A and B. But according to this article, that is false. What am I missing?",,"['probability', 'stochastic-processes', 'economics']"
41,Division of two random variables of uniform distributions,Division of two random variables of uniform distributions,,"Having X ~ Uniform(0,1), Y ~ Uniform(1,3) independent what's the pdf of Z = X/Y. This means I can write the PDFs as follows $$f_X(x) = 1$$ for $ x \in \left(0,1\right)$ and 0 otherwise $$f_Y(y) = \frac{1}{2}$$ for $x \in \left(1,3\right)$ and 0 otherwise. Using the following formula for division of independent random variables: $$f_Z(u) = \int_0^{\infty}f_Y(y)f_X(yu)dy$$ $f_x(uy)$ is non-zero when $uy \in \left(0,1\right)$ so $y \in \left(0,\frac{1}{u}\right)$. The maximum $u$ is then $\frac{1}{3}$. What would be the right domain of integration in the formula above? Should the resulting PDF be then parameterized by $u$?","Having X ~ Uniform(0,1), Y ~ Uniform(1,3) independent what's the pdf of Z = X/Y. This means I can write the PDFs as follows $$f_X(x) = 1$$ for $ x \in \left(0,1\right)$ and 0 otherwise $$f_Y(y) = \frac{1}{2}$$ for $x \in \left(1,3\right)$ and 0 otherwise. Using the following formula for division of independent random variables: $$f_Z(u) = \int_0^{\infty}f_Y(y)f_X(yu)dy$$ $f_x(uy)$ is non-zero when $uy \in \left(0,1\right)$ so $y \in \left(0,\frac{1}{u}\right)$. The maximum $u$ is then $\frac{1}{3}$. What would be the right domain of integration in the formula above? Should the resulting PDF be then parameterized by $u$?",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables']"
42,Teaching probability by using a deck of cards,Teaching probability by using a deck of cards,,"I plan to teach two sessions of probability to 11th grade students using a deck of cards. My classes will be next week. I have already taught them the basic notions of writing sample spaces, computing conditional probabilities and so on. The problem is that once students get 'trained' to use conditional probability, they use it all the time and do not go back to first principles. A typical example is the question: ""What is the probability that the third card drawn from a pack of cards is a queen?"". The interesting thing is that my untrained 9th grade cousin could answer immediately when I actually used a pack of cards to ask her the question. So that motivated me to teach a couple of classes on probability with a simple apparatus like a deck of cards. Presently I have the following ideas: Let us call the question 'What is the probability that the 4th card is a queen?' as THE question. Deal 5 cards face down and ask THE question. Now flip the third card open and ask THE question. Now flip the flipped card and shuffle the 5 cards and place them in some order face down and ask THE question. Now add two extra black suit cards (tell them the cards are from a black suit) from the deck to the array of five cards and ask THE question. Now tell them that I might have lied about the suit of exactly one of the cards in the previous round and then ask THE question. Further, I plan to do the Monty Hall puzzle and Bertrand's box problem with the pack of cards. I wanted to do a basic gambler's ruin too. But I do not know how to go about it. My question, therefore, to the community is: 1) Would you kindly suggest interesting probability questions using a deck of cards? 2) Are there interesting questions which cannot be asked using a deck of cards? If so, what simple apparatus would I need? P.S: Buffon's needle problem would have been a good suggestion, but the students cannot appreciate continuous sample spaces as of now. That is, I would like examples from discrete sample spaces. Thank you :)","I plan to teach two sessions of probability to 11th grade students using a deck of cards. My classes will be next week. I have already taught them the basic notions of writing sample spaces, computing conditional probabilities and so on. The problem is that once students get 'trained' to use conditional probability, they use it all the time and do not go back to first principles. A typical example is the question: ""What is the probability that the third card drawn from a pack of cards is a queen?"". The interesting thing is that my untrained 9th grade cousin could answer immediately when I actually used a pack of cards to ask her the question. So that motivated me to teach a couple of classes on probability with a simple apparatus like a deck of cards. Presently I have the following ideas: Let us call the question 'What is the probability that the 4th card is a queen?' as THE question. Deal 5 cards face down and ask THE question. Now flip the third card open and ask THE question. Now flip the flipped card and shuffle the 5 cards and place them in some order face down and ask THE question. Now add two extra black suit cards (tell them the cards are from a black suit) from the deck to the array of five cards and ask THE question. Now tell them that I might have lied about the suit of exactly one of the cards in the previous round and then ask THE question. Further, I plan to do the Monty Hall puzzle and Bertrand's box problem with the pack of cards. I wanted to do a basic gambler's ruin too. But I do not know how to go about it. My question, therefore, to the community is: 1) Would you kindly suggest interesting probability questions using a deck of cards? 2) Are there interesting questions which cannot be asked using a deck of cards? If so, what simple apparatus would I need? P.S: Buffon's needle problem would have been a good suggestion, but the students cannot appreciate continuous sample spaces as of now. That is, I would like examples from discrete sample spaces. Thank you :)",,"['probability', 'education']"
43,Example of stationary 2D Gaussian process with non-symmetric auto-covariance function,Example of stationary 2D Gaussian process with non-symmetric auto-covariance function,,"Let $(X_t, Y_t)$ be a stationary 2D Gaussian process , therefore $\mathbb{E}\left(X_t\right) = \mathbb{E}(Y_t) = 0$. I am looking for an explicit example of a valid auto-covariance matrix, i.e: $$  R(h) = \begin{pmatrix} \mathbb{E}\left(X_t X_{t+h}\right) & \mathbb{E}\left(X_t Y_{t+h}\right) \\   \mathbb{E}\left(Y_t X_{t+h}\right) & \mathbb{E}\left(Y_t Y_{t+h}\right) \end{pmatrix} $$ such that $R(h)$ is not symmetric for $h\not=0$. Thank you.","Let $(X_t, Y_t)$ be a stationary 2D Gaussian process , therefore $\mathbb{E}\left(X_t\right) = \mathbb{E}(Y_t) = 0$. I am looking for an explicit example of a valid auto-covariance matrix, i.e: $$  R(h) = \begin{pmatrix} \mathbb{E}\left(X_t X_{t+h}\right) & \mathbb{E}\left(X_t Y_{t+h}\right) \\   \mathbb{E}\left(Y_t X_{t+h}\right) & \mathbb{E}\left(Y_t Y_{t+h}\right) \end{pmatrix} $$ such that $R(h)$ is not symmetric for $h\not=0$. Thank you.",,"['probability', 'stochastic-processes']"
44,Binomial Distribution and Normal Distribution,Binomial Distribution and Normal Distribution,,"Today at school we discussed probability distributions and as usual my mind wandered off and I started thinking: Normally when we have a die, you can make a binomial distribution. So I thought, if you have a die with, instead of 6 sides, an infinite amount of sides, wouldn't the binomial distribution become a normal distribution? If yes, can you also say that when a normal distribution is 'simplified' (with simplified I mean for example going from an n-sided dice to a 6 sided die) it always turns into a binomial distribution, or is that just the case for some examples (like this die example, which is what I assume is true)? p.s. This was our first lesson on probability, so what I might say might sound ridiculous. At the beginning of each chapter I always wonder off like this, sometimes I get nice results and sometimes I fail epicly.","Today at school we discussed probability distributions and as usual my mind wandered off and I started thinking: Normally when we have a die, you can make a binomial distribution. So I thought, if you have a die with, instead of 6 sides, an infinite amount of sides, wouldn't the binomial distribution become a normal distribution? If yes, can you also say that when a normal distribution is 'simplified' (with simplified I mean for example going from an n-sided dice to a 6 sided die) it always turns into a binomial distribution, or is that just the case for some examples (like this die example, which is what I assume is true)? p.s. This was our first lesson on probability, so what I might say might sound ridiculous. At the beginning of each chapter I always wonder off like this, sometimes I get nice results and sometimes I fail epicly.",,['probability']
45,"'Simple"" Chernoff bounds","'Simple"" Chernoff bounds",,"Reading an academic paper I've observed the next claim: A simple Chernoff argument will now show that if an event has a constant probability at every step of occurring and there's independence between the steps then after $O(c*\log n)$ steps the event will happen $O(\log n)$ times with probability greater than $1-1/n^{O(c)}$. Trying to follow this statement I'm trying to find the matching variant of Chernoff inequality and derive using the matching formula  the probability as described in the quote. The model I've suggested is $c*\log n$ i.i.d. random Bernoulli variables, each has similar chance generate an event  $Prob(event)=p$. The expectation of the sum of variables is $p*c*\log n$. I need to find matching Chernoff inequality that shows that probability of getting at least $\log n$ events within $c*\log n$ variables (steps) is at least $1-1/n^{O(c)}$. I'm totally lost in deriving the expression $1-1/n^{O(c)}$ from the Chernoff inequalities I've found. Thanks in advance.","Reading an academic paper I've observed the next claim: A simple Chernoff argument will now show that if an event has a constant probability at every step of occurring and there's independence between the steps then after $O(c*\log n)$ steps the event will happen $O(\log n)$ times with probability greater than $1-1/n^{O(c)}$. Trying to follow this statement I'm trying to find the matching variant of Chernoff inequality and derive using the matching formula  the probability as described in the quote. The model I've suggested is $c*\log n$ i.i.d. random Bernoulli variables, each has similar chance generate an event  $Prob(event)=p$. The expectation of the sum of variables is $p*c*\log n$. I need to find matching Chernoff inequality that shows that probability of getting at least $\log n$ events within $c*\log n$ variables (steps) is at least $1-1/n^{O(c)}$. I'm totally lost in deriving the expression $1-1/n^{O(c)}$ from the Chernoff inequalities I've found. Thanks in advance.",,"['probability', 'inequality', 'distribution-tails']"
46,probability of a large sub-sequence within a huge sequence,probability of a large sub-sequence within a huge sequence,,You toss a fair coin one million times. What is the probability of getting at least one sequence of six heads followed by six tails?,You toss a fair coin one million times. What is the probability of getting at least one sequence of six heads followed by six tails?,,['probability']
47,Using the SLLN to show that the Sample Mean of Arrivals tends to the Arrival Rate for a simple Poisson Process,Using the SLLN to show that the Sample Mean of Arrivals tends to the Arrival Rate for a simple Poisson Process,,"Let $N_t = N([0,t])$ denote a Poisson process with rate $\lambda = 1$ on the interval $[0,1]$. I am wondering how I can use the Law of Large Numbers to formally argue that: $$\frac{N_t}{t} \rightarrow \lambda \quad  \text{  a.s.} $$ As it stands, I can almost prove the required result but I have to to assume that $t \in Z_+$. With this assumption, I can define Poisson random variables on intervals of size $1$ as follows $$N_i = N([i-1,i])$$ where $$\mathbb{E}[N([i-1,i])] = \text{Var}[N([i-1,i])] = 1$$ and $$N_t = N([0,t]) = \sum_{i=1}^t N([i-1,i]) = \sum_{i=1}^t N_i$$ Accordingly, we can use the Law of Large Numbers to state the result above... Given that $t \in \mathbb{R}_+$, this proof needs to be tweaked in some way... But I'm not exactly sure how to do it. Intuitively speaking, I believe that the correct approach would be to decompose $N[0,t]$ into $N[0,\lfloor t\rfloor]$ and $N[\lfloor t\rfloor, t]$, and argue that the latter term $\rightarrow 0$ almost surely. However, I'm not sure how to formally state this.","Let $N_t = N([0,t])$ denote a Poisson process with rate $\lambda = 1$ on the interval $[0,1]$. I am wondering how I can use the Law of Large Numbers to formally argue that: $$\frac{N_t}{t} \rightarrow \lambda \quad  \text{  a.s.} $$ As it stands, I can almost prove the required result but I have to to assume that $t \in Z_+$. With this assumption, I can define Poisson random variables on intervals of size $1$ as follows $$N_i = N([i-1,i])$$ where $$\mathbb{E}[N([i-1,i])] = \text{Var}[N([i-1,i])] = 1$$ and $$N_t = N([0,t]) = \sum_{i=1}^t N([i-1,i]) = \sum_{i=1}^t N_i$$ Accordingly, we can use the Law of Large Numbers to state the result above... Given that $t \in \mathbb{R}_+$, this proof needs to be tweaked in some way... But I'm not exactly sure how to do it. Intuitively speaking, I believe that the correct approach would be to decompose $N[0,t]$ into $N[0,\lfloor t\rfloor]$ and $N[\lfloor t\rfloor, t]$, and argue that the latter term $\rightarrow 0$ almost surely. However, I'm not sure how to formally state this.",,"['probability', 'measure-theory', 'probability-theory', 'law-of-large-numbers']"
48,How can obtain the pdf of y?,How can obtain the pdf of y?,,"I have a problem as follows: $$Y_k=N_k+AS_K \quad ,k=1,\ldots,n.$$$$$$where $\underline{N} \sim N(\underline{0},I)$ and where $S_1,\ldots,S_n$ are i.i.d. random variables, independent of $\underline{N}$ and each taking on the values $+1$ and $-1$ with equal probabilities of $\frac{1}{2}$. I want to obtain pdf of $\underline{Y}$ ?  $A$ is constant value. Can anyone help me! Thank you.","I have a problem as follows: $$Y_k=N_k+AS_K \quad ,k=1,\ldots,n.$$$$$$where $\underline{N} \sim N(\underline{0},I)$ and where $S_1,\ldots,S_n$ are i.i.d. random variables, independent of $\underline{N}$ and each taking on the values $+1$ and $-1$ with equal probabilities of $\frac{1}{2}$. I want to obtain pdf of $\underline{Y}$ ?  $A$ is constant value. Can anyone help me! Thank you.",,"['probability', 'probability-theory', 'stochastic-processes']"
49,Acceptance probability of Metropolis-Hastings,Acceptance probability of Metropolis-Hastings,,"I am an IT guy writing my masters thesis on MCMC methods for use in predicting the outcome of football(soccer) matches. Right now I am trying to wrap my head around MCMC and Metropolis-Hastings in particular. Coming from software development I don't really have the understanding of probability and statistics needed. I do understand how and why the acceptance function of Metropolis-Hastings work, but I can't really wrap my head around how to calculate the acceptance probability $$ min(1, \frac{P(X')}{P(X)} * \frac{Q(X|X')}{Q(X'|X)}) $$ Were $X$ is my previous sample and $X'$ is my randomly generated sample from the proposal distribution $Q$ In trying to understand the algorithm i have created the toy problem where my goal is to estimate a target density $P(X) \sim N(0,1)$, using the proposal distribution $Q(X) \sim N(.,0.25)$ I know this must seem like a really stupid question, but do you actually evaluate the density in $X$ for $P(X)$, and how do you calculate the transition probability $Q(X|X')$? I know this is stupid since $Q$ is symmetric and would cancel out the transition probability (and that this can be done using the Metropolis algorithm), but I need to know how to calculate it correctly. Thanks!","I am an IT guy writing my masters thesis on MCMC methods for use in predicting the outcome of football(soccer) matches. Right now I am trying to wrap my head around MCMC and Metropolis-Hastings in particular. Coming from software development I don't really have the understanding of probability and statistics needed. I do understand how and why the acceptance function of Metropolis-Hastings work, but I can't really wrap my head around how to calculate the acceptance probability $$ min(1, \frac{P(X')}{P(X)} * \frac{Q(X|X')}{Q(X'|X)}) $$ Were $X$ is my previous sample and $X'$ is my randomly generated sample from the proposal distribution $Q$ In trying to understand the algorithm i have created the toy problem where my goal is to estimate a target density $P(X) \sim N(0,1)$, using the proposal distribution $Q(X) \sim N(.,0.25)$ I know this must seem like a really stupid question, but do you actually evaluate the density in $X$ for $P(X)$, and how do you calculate the transition probability $Q(X|X')$? I know this is stupid since $Q$ is symmetric and would cancel out the transition probability (and that this can be done using the Metropolis algorithm), but I need to know how to calculate it correctly. Thanks!",,"['probability', 'normal-distribution', 'markov-chains', 'monte-carlo']"
50,How to prove periodicity is a class property?,How to prove periodicity is a class property?,,"It is said that in a Markov chain, if state $i$ has period $d$ and state $i$ and $j$ are communicate, then state $j$ also has period $d$. I wonder how to prove it?","It is said that in a Markov chain, if state $i$ has period $d$ and state $i$ and $j$ are communicate, then state $j$ also has period $d$. I wonder how to prove it?",,"['probability', 'markov-chains', 'markov-process']"
51,"Why is $\operatorname{Var}(X+Y) = \operatorname{Cov}(X,X) + \operatorname{Cov}(X,Y) + \operatorname{Cov}(Y,X) + \operatorname{Cov}(Y,Y)$",Why is,"\operatorname{Var}(X+Y) = \operatorname{Cov}(X,X) + \operatorname{Cov}(X,Y) + \operatorname{Cov}(Y,X) + \operatorname{Cov}(Y,Y)","I know $\operatorname{Cov}(X,Y) = E[(X-u_x)(Y-u_y)]$ and $$ \operatorname{Cov}(X+Y, Z+W) = \operatorname{Cov}(X,Z) + \operatorname{Cov}(X,W) + \operatorname{Cov}(Y,Z) + \operatorname{Cov}(Y,W), $$ but how does one get $$ \operatorname{Var}(X+Y) = \operatorname{Cov}(X,X) + \operatorname{Cov}(X,Y) + \operatorname{Cov}(Y,X) + \operatorname{Cov}(Y,Y)? $$","I know $\operatorname{Cov}(X,Y) = E[(X-u_x)(Y-u_y)]$ and $$ \operatorname{Cov}(X+Y, Z+W) = \operatorname{Cov}(X,Z) + \operatorname{Cov}(X,W) + \operatorname{Cov}(Y,Z) + \operatorname{Cov}(Y,W), $$ but how does one get $$ \operatorname{Var}(X+Y) = \operatorname{Cov}(X,X) + \operatorname{Cov}(X,Y) + \operatorname{Cov}(Y,X) + \operatorname{Cov}(Y,Y)? $$",,"['probability', 'statistics']"
52,using markov chains to solve a project-euler problem?,using markov chains to solve a project-euler problem?,,"I never learned what markov chain is, but from googling it seems like if there are finite states and each state has probabilities to jump to other states, I can use markov chain. What I'm on is http://projecteuler.net/problem=227 , the chase. ""The Chase"" is a game played with two dice and an even number of   players. The players sit around a table; the game begins with two opposite   players having one die each. On each turn, the two players with a die   roll it. If a player rolls a 1, he passes the die to his neighbour on   the left; if he rolls a 6, he passes the die to his neighbour on the   right; otherwise, he keeps the die for the next turn. The game ends   when one player has both dice after they have been rolled and passed;   that player has then lost. In a game with 100 players, what is the expected number of turns the   game lasts? Give your answer rounded to ten significant digits. N people sit around a table, so I name them 1, 2 ... 100 clockwise.( or counterclockwise, which doesn't matter) person 1 and 51 have the dice at beginning. From description, given N people, state (A, B) is person A and person B having dice. They can move to state(A+1, B), state(A, B+1), state(A+1, B+1) ... state(A-1, B-1). There are 8 distinct states that at least one die changes its owner. I can calculate all the next states and probabilities of them for each state. say probability (a, b) is the probability of finishing a game if person a and b has the dice. if a=b, which is condition of the game to finish, probability (a, b) = 1. if not a=b, I made a function to find the probability : if a=b then return 1. if not a=b, for each next-state from (a, b):    add up (probability of moving to a next-state)*(probability of ending game in that state) so this function will recursively search for whether game could be ended in that state. My concern is that above function could get into endless recursion. for example - start with (1, 10) -> from this state game can't be done in one turn, so I search -- (0, 10), (2, 11) ... I keep searching until I hit (a, b) that a=b. say I am in the middle of search, ended up in (4, 5) and game can be ended in (5, 5). moving from (4, 5) to (5, 5) has P probability. but for (1-P) probability, I have to keep searching. I think there is something I missing about probabilities or I really don't know about markov chain. Any help would be appreciated.","I never learned what markov chain is, but from googling it seems like if there are finite states and each state has probabilities to jump to other states, I can use markov chain. What I'm on is http://projecteuler.net/problem=227 , the chase. ""The Chase"" is a game played with two dice and an even number of   players. The players sit around a table; the game begins with two opposite   players having one die each. On each turn, the two players with a die   roll it. If a player rolls a 1, he passes the die to his neighbour on   the left; if he rolls a 6, he passes the die to his neighbour on the   right; otherwise, he keeps the die for the next turn. The game ends   when one player has both dice after they have been rolled and passed;   that player has then lost. In a game with 100 players, what is the expected number of turns the   game lasts? Give your answer rounded to ten significant digits. N people sit around a table, so I name them 1, 2 ... 100 clockwise.( or counterclockwise, which doesn't matter) person 1 and 51 have the dice at beginning. From description, given N people, state (A, B) is person A and person B having dice. They can move to state(A+1, B), state(A, B+1), state(A+1, B+1) ... state(A-1, B-1). There are 8 distinct states that at least one die changes its owner. I can calculate all the next states and probabilities of them for each state. say probability (a, b) is the probability of finishing a game if person a and b has the dice. if a=b, which is condition of the game to finish, probability (a, b) = 1. if not a=b, I made a function to find the probability : if a=b then return 1. if not a=b, for each next-state from (a, b):    add up (probability of moving to a next-state)*(probability of ending game in that state) so this function will recursively search for whether game could be ended in that state. My concern is that above function could get into endless recursion. for example - start with (1, 10) -> from this state game can't be done in one turn, so I search -- (0, 10), (2, 11) ... I keep searching until I hit (a, b) that a=b. say I am in the middle of search, ended up in (4, 5) and game can be ended in (5, 5). moving from (4, 5) to (5, 5) has P probability. but for (1-P) probability, I have to keep searching. I think there is something I missing about probabilities or I really don't know about markov chain. Any help would be appreciated.",,"['probability', 'project-euler']"
53,Does CLT fail in this case?,Does CLT fail in this case?,,"We have mutually independent random variables $X_n$ with $P(X_n = 2^n) = P(X_n = -2^n) = \frac12$. Of course their means $\mu_n = 0$ and variances $\sigma_n^2 = 4^k$. Let $S_n = \sum_1^n X_k$. Clearly the mean $m_n=E(S_n) = 0$ and variance $s_n^2 = E(S_n^2)=  \sum_1^n \sigma_k^2 = \frac13(4^{n+1}-1)$. I have shown that in this case the law of large numbers does not apply, and need to show that CLT does/does not apply. The only method I know to show that the CLT does apply would be Lindeberg's theorem, which I have tried to apply but I can't seem to get anywhere with. Since $\max_k \sigma_k^2/s_n^2$ does not go to zero, I cannot use Lindeberg's theorem to show that the CLT doesn't apply, so I am lost on how to proceed. How might I proceeed otherwise?","We have mutually independent random variables $X_n$ with $P(X_n = 2^n) = P(X_n = -2^n) = \frac12$. Of course their means $\mu_n = 0$ and variances $\sigma_n^2 = 4^k$. Let $S_n = \sum_1^n X_k$. Clearly the mean $m_n=E(S_n) = 0$ and variance $s_n^2 = E(S_n^2)=  \sum_1^n \sigma_k^2 = \frac13(4^{n+1}-1)$. I have shown that in this case the law of large numbers does not apply, and need to show that CLT does/does not apply. The only method I know to show that the CLT does apply would be Lindeberg's theorem, which I have tried to apply but I can't seem to get anywhere with. Since $\max_k \sigma_k^2/s_n^2$ does not go to zero, I cannot use Lindeberg's theorem to show that the CLT doesn't apply, so I am lost on how to proceed. How might I proceeed otherwise?",,['probability']
54,finding the optimal strategy,finding the optimal strategy,,"You have a deck of 32 playing cards. Somebody draws one card after another and shows them to you. At any point of time you may bet that the next card is black. If it is indeed black you earn $10, otherwise nothing. If you don't do anything you earn nothing as well. Find the optimal strategy. In other words you should find the point of time where the quota of remaining red cards in the deck is maximal. Any hints how to to this?","You have a deck of 32 playing cards. Somebody draws one card after another and shows them to you. At any point of time you may bet that the next card is black. If it is indeed black you earn $10, otherwise nothing. If you don't do anything you earn nothing as well. Find the optimal strategy. In other words you should find the point of time where the quota of remaining red cards in the deck is maximal. Any hints how to to this?",,['probability']
55,Closed form of chi-square divergence between two gaussians,Closed form of chi-square divergence between two gaussians,,"If $f_1$ is the pdf of a $N(\mu,\sigma^2)$ and $f_2$ is the pdf of a $N(\nu,\tau^2)$, can I compute the Chi Squared divergence between $f_1$ and $f_2$ in closed form (as a function of the parameters $\mu, \nu, \sigma^2,\tau^2$)? I've done it with the Kullback Leibler divergence without spending much time, but I can't do the same with the chi-squared. @John: I've tried to integrate directly $\int \frac{f_1^2}{f_2}dx-1$ or equivalently $\int \frac{{(f_1-f_2)}^2}{f_2}dx$ or $\int f_2 (\frac{f_1}{f_2}-1) dx$. All the problem is reconducible to integrate $\int e^{-(ax^2+bx+c)}dx$ for some $a,b,c$ but this integral does not converge for negative values of $a$. In my calculations, the coefficent $a$ is something like the difference of two variances, so it could be negative.","If $f_1$ is the pdf of a $N(\mu,\sigma^2)$ and $f_2$ is the pdf of a $N(\nu,\tau^2)$, can I compute the Chi Squared divergence between $f_1$ and $f_2$ in closed form (as a function of the parameters $\mu, \nu, \sigma^2,\tau^2$)? I've done it with the Kullback Leibler divergence without spending much time, but I can't do the same with the chi-squared. @John: I've tried to integrate directly $\int \frac{f_1^2}{f_2}dx-1$ or equivalently $\int \frac{{(f_1-f_2)}^2}{f_2}dx$ or $\int f_2 (\frac{f_1}{f_2}-1) dx$. All the problem is reconducible to integrate $\int e^{-(ax^2+bx+c)}dx$ for some $a,b,c$ but this integral does not converge for negative values of $a$. In my calculations, the coefficent $a$ is something like the difference of two variances, so it could be negative.",,"['probability', 'statistics']"
56,How to obtain probability function from its probability generating function,How to obtain probability function from its probability generating function,,"For a discrete random variable $X$, we have known the exact expression of its PGF $G(z)=E[z^X]$. The question is how can I get $Pr\{X>k\}$ from this PGF. I want to have an explicit expression of the probability in terms of $G(z)$. The Z-Transform is too complex to use. And an explicit expression is preferred rather than a upper bound. Is there some other way? Thanks!","For a discrete random variable $X$, we have known the exact expression of its PGF $G(z)=E[z^X]$. The question is how can I get $Pr\{X>k\}$ from this PGF. I want to have an explicit expression of the probability in terms of $G(z)$. The Z-Transform is too complex to use. And an explicit expression is preferred rather than a upper bound. Is there some other way? Thanks!",,"['probability', 'probability-distributions']"
57,A proof of the scaling/shift property of variance,A proof of the scaling/shift property of variance,,I would like to show that $Var(aX + b) = a^2 Var(X)$ using a different proof from my book Let $Y = aX + b$ $Var(Y) = E(Y^2) - E[Y]^2$ = $E[(aX + b)^2] - E(aX + b)^2$ = $E[(a^2 X^2 + b^2 + 2abX] - (a\mu+b)^2$ = $a^2E(X^2) + b^2 + 2abE[X] - (a^2\mu^2 + b^2 + 2ab\mu)$ = $a^2E(X^2) + b^2 + 2ab\mu - (a^2E[X]^2 + b^2 + 2ab\mu)$ = $a^2E[X^2] - a^2E[X]^2$ = $a^2(E[X^2]-E[X]^2)$ = $a^2 Var(X)$ My book does like three lines and they start out with $Var(aX + b) = E[(aX + b - (a\mu + b) ) ^2]$ . I don't understand why they substract $(a\mu + b)$ instead of $\mu$ because $Var(X) = E[(X - \mu)^2]$ Is my proof correct?,I would like to show that using a different proof from my book Let = = = = = = = My book does like three lines and they start out with . I don't understand why they substract instead of because Is my proof correct?,Var(aX + b) = a^2 Var(X) Y = aX + b Var(Y) = E(Y^2) - E[Y]^2 E[(aX + b)^2] - E(aX + b)^2 E[(a^2 X^2 + b^2 + 2abX] - (a\mu+b)^2 a^2E(X^2) + b^2 + 2abE[X] - (a^2\mu^2 + b^2 + 2ab\mu) a^2E(X^2) + b^2 + 2ab\mu - (a^2E[X]^2 + b^2 + 2ab\mu) a^2E[X^2] - a^2E[X]^2 a^2(E[X^2]-E[X]^2) a^2 Var(X) Var(aX + b) = E[(aX + b - (a\mu + b) ) ^2] (a\mu + b) \mu Var(X) = E[(X - \mu)^2],"['probability', 'proof-verification', 'random-variables']"
58,Which versions of Chernoff bound are applied to Binomial distribution in these examples?,Which versions of Chernoff bound are applied to Binomial distribution in these examples?,,"There are several versions of Chernoff bounds . I was wodering which versions are applied to computing the probabilities of a Binomial distribution in the following two examples, but couldn't. I have tried to find them out  but not succeeded. From Wikipedia The cumulative distribution function can be expressed as: $$          F(x;n,p) = \Pr(X \le x) = \sum_{i=0}^{\lfloor x \rfloor} {n\choose i}p^i(1-p)^{n-i} $$ For $k ≤ np$, Chernoff's inequality   can be used to derive the   bound $$          F(k;n,p) \leq \exp\left(-\frac{1}{2\,p} \frac{(np-k)^2}{n}\right). \!  $$ From Wikipedia Let $X_1, \dots, X_n$ be independent Bernoulli random variables, each   having probability $p > 1/2$. Then the probability of simultaneous   occurrence of more than n/2 of the events $\{X_k = 1\}$ has an exact   value $S$, where $$          S=\sum\limits_{i = \lfloor \frac{n}{2} \rfloor + 1}^n \binom{n}{i}p^i (1 - p)^{n - i} . $$ The Chernoff bound shows that   $S$   has the following lower bound: $$          S \ge 1 - \mathrm{e}^{- 2n \left( {p - \frac{1}{2}} \right)^2} .  $$ The second one, if I understand correctly, is equivalent to $$  F(n/2;n,p) \leq \mathrm{e}^{- 2n \left( {p - \frac{1}{2}} \right)^2}. $$ I don't think part 2 can be derived from part 1. Granted that part 1 is correct based on some unknown result, then since $n/2 < np$, $$  F(n/2;n,p)  \leq \mathrm{e}^{-  \left( {np - \frac{n}{2}} \right)^2 / (2np)} =  \mathrm{e}^{- n \left( {p - \frac{1}{2}} \right)^2 / (2p)} $$ The RHS is $\leq \mathrm{e}^{- 2n \left( {p - \frac{1}{2}} \right)^2}$ if and only if $p \leq 1/4$ which is contrary to $p >1/2$. Thanks!","There are several versions of Chernoff bounds . I was wodering which versions are applied to computing the probabilities of a Binomial distribution in the following two examples, but couldn't. I have tried to find them out  but not succeeded. From Wikipedia The cumulative distribution function can be expressed as: $$          F(x;n,p) = \Pr(X \le x) = \sum_{i=0}^{\lfloor x \rfloor} {n\choose i}p^i(1-p)^{n-i} $$ For $k ≤ np$, Chernoff's inequality   can be used to derive the   bound $$          F(k;n,p) \leq \exp\left(-\frac{1}{2\,p} \frac{(np-k)^2}{n}\right). \!  $$ From Wikipedia Let $X_1, \dots, X_n$ be independent Bernoulli random variables, each   having probability $p > 1/2$. Then the probability of simultaneous   occurrence of more than n/2 of the events $\{X_k = 1\}$ has an exact   value $S$, where $$          S=\sum\limits_{i = \lfloor \frac{n}{2} \rfloor + 1}^n \binom{n}{i}p^i (1 - p)^{n - i} . $$ The Chernoff bound shows that   $S$   has the following lower bound: $$          S \ge 1 - \mathrm{e}^{- 2n \left( {p - \frac{1}{2}} \right)^2} .  $$ The second one, if I understand correctly, is equivalent to $$  F(n/2;n,p) \leq \mathrm{e}^{- 2n \left( {p - \frac{1}{2}} \right)^2}. $$ I don't think part 2 can be derived from part 1. Granted that part 1 is correct based on some unknown result, then since $n/2 < np$, $$  F(n/2;n,p)  \leq \mathrm{e}^{-  \left( {np - \frac{n}{2}} \right)^2 / (2np)} =  \mathrm{e}^{- n \left( {p - \frac{1}{2}} \right)^2 / (2p)} $$ The RHS is $\leq \mathrm{e}^{- 2n \left( {p - \frac{1}{2}} \right)^2}$ if and only if $p \leq 1/4$ which is contrary to $p >1/2$. Thanks!",,['probability']
59,Expected value of the product of random integers summing to a constant value.,Expected value of the product of random integers summing to a constant value.,,"For $1 \le i \le n$, let  $X_i$  be $n$ integer-valued random variables that sum to the constant $s$. None of the $X_i$ are zero and they can have identical values. I need to find the the expected value of the product of the random variables, i.e. $E[X_1 X_2\cdots X_n]$. I have been told that there is a simple expression for the answer: $$E[X_1X_2\cdots X_n] = s(s+1)(s+2)\cdots(s+n-1)/n(n+1)(n+2)\cdots(2n-1).$$ Example: $s = 9$, $n = 5$. The values $X_1, X_2, X_3, X_4, X_5$ can take are all possible arrangements of the following integer partitions of $9$, i.e. $$5,1,1,1,1$$ $$4,2,1,1,1$$ $$3,3,1,1,1$$ $$3,2,2,1,1$$ $$2,2,2,2,1$$ By direct calculation, $E[X_1X_2X_3X_4X_5] = 715/70 = 143/14$ Using the suggested answer, $E[X_1X_2X_3X_4X_5] = 9\cdot10\cdot12\cdot13/5\cdot6\cdot7\cdot8\cdot9 = 143/14$ I'm not sure whether this is a well-known result, and I have not been able to find any references to it. I have verified that the result holds for various values of s and n, but I am not sure how to prove the result.","For $1 \le i \le n$, let  $X_i$  be $n$ integer-valued random variables that sum to the constant $s$. None of the $X_i$ are zero and they can have identical values. I need to find the the expected value of the product of the random variables, i.e. $E[X_1 X_2\cdots X_n]$. I have been told that there is a simple expression for the answer: $$E[X_1X_2\cdots X_n] = s(s+1)(s+2)\cdots(s+n-1)/n(n+1)(n+2)\cdots(2n-1).$$ Example: $s = 9$, $n = 5$. The values $X_1, X_2, X_3, X_4, X_5$ can take are all possible arrangements of the following integer partitions of $9$, i.e. $$5,1,1,1,1$$ $$4,2,1,1,1$$ $$3,3,1,1,1$$ $$3,2,2,1,1$$ $$2,2,2,2,1$$ By direct calculation, $E[X_1X_2X_3X_4X_5] = 715/70 = 143/14$ Using the suggested answer, $E[X_1X_2X_3X_4X_5] = 9\cdot10\cdot12\cdot13/5\cdot6\cdot7\cdot8\cdot9 = 143/14$ I'm not sure whether this is a well-known result, and I have not been able to find any references to it. I have verified that the result holds for various values of s and n, but I am not sure how to prove the result.",,['probability']
60,Probability question with interarrival times,Probability question with interarrival times,,"(Why did the chicken cross the road?) A chicken wants to cross a single-lane road where the cars arrive according to a Poisson process with rate $\lambda$. She needs at least $k$ minutes to cross the road safely, so she will have to wait until she sees a gap of at least $k$ between the oncoming cars. If the gap between the car that just arrived and the next one is at least $k$ then she starts crossing the road immediately. Let $T$ denote the random time she needs to wait by the road. Find the expected time needed to cross the road.","(Why did the chicken cross the road?) A chicken wants to cross a single-lane road where the cars arrive according to a Poisson process with rate $\lambda$. She needs at least $k$ minutes to cross the road safely, so she will have to wait until she sees a gap of at least $k$ between the oncoming cars. If the gap between the car that just arrived and the next one is at least $k$ then she starts crossing the road immediately. Let $T$ denote the random time she needs to wait by the road. Find the expected time needed to cross the road.",,['probability']
61,Grid-constrained probability question,Grid-constrained probability question,,"A little rusty on my combinatorics/probability, and looking for some pointers on figuring out some probabilities in a game setup. Given a 2-dimensional grid that is divided into 2x2 tiles, with each tile having a specific feature in exactly one of it's four squares, I'm trying to figure out the probability of an overlaid square tile (2x2 minimum, but the interesting cases are larger) having a certain number of feature squares within it. I can brute-force the small cases, but the non-uniform distribution of features (i.e. conditional probabilities based on neighboring squares and grid constraints) as well as the different possible alignments quickly make larger cases a counting nightmare. By way of a little better example, a 2x2 overlay, if aligned to the underlying grid, obviously will have just one feature square. If it's misaligned either horizontally or vertically, it can have 0, 1, or 2 squares, and if it's misaligned in both directions, it could have anywhere between 0 and 4 squares. The probabilities (calculated by just counting the possible combinations) come out to about 20.4% chance of 0 tiles, 60.6% chance of 1, 17.8% for 2, 1.8% for 3, and about 0.1% for all 4. A 3x3 overlay, calculated similarly, has a minimum of 1 square (18.75%), but can have 2, 3, or 4 (maximum) with respective probabilities of 43.75%, 31.25% and 6.25%. Is this a well defined problem that has a (preferably closed-form) formula as a solution? Or is tabulating the possibilities the best that can be done for the higher-order parameters?","A little rusty on my combinatorics/probability, and looking for some pointers on figuring out some probabilities in a game setup. Given a 2-dimensional grid that is divided into 2x2 tiles, with each tile having a specific feature in exactly one of it's four squares, I'm trying to figure out the probability of an overlaid square tile (2x2 minimum, but the interesting cases are larger) having a certain number of feature squares within it. I can brute-force the small cases, but the non-uniform distribution of features (i.e. conditional probabilities based on neighboring squares and grid constraints) as well as the different possible alignments quickly make larger cases a counting nightmare. By way of a little better example, a 2x2 overlay, if aligned to the underlying grid, obviously will have just one feature square. If it's misaligned either horizontally or vertically, it can have 0, 1, or 2 squares, and if it's misaligned in both directions, it could have anywhere between 0 and 4 squares. The probabilities (calculated by just counting the possible combinations) come out to about 20.4% chance of 0 tiles, 60.6% chance of 1, 17.8% for 2, 1.8% for 3, and about 0.1% for all 4. A 3x3 overlay, calculated similarly, has a minimum of 1 square (18.75%), but can have 2, 3, or 4 (maximum) with respective probabilities of 43.75%, 31.25% and 6.25%. Is this a well defined problem that has a (preferably closed-form) formula as a solution? Or is tabulating the possibilities the best that can be done for the higher-order parameters?",,"['probability', 'combinatorics']"
62,The variance in the average of a set of normally distributed random variables,The variance in the average of a set of normally distributed random variables,,"I have a set of $M$ normally distributed random variables, $r_i$, each with an associated mean $u_i$, but the same variance $\sigma^2$.  What is the variance of the average of these $M$ random variables: $\frac{\sum_{i=1}^{M} u_i}{M}$?  How does the variance change as $M$ increases?  What if the $M$ variables have a uniform, rather than a normal distribution, over some interval $[A, B]$?","I have a set of $M$ normally distributed random variables, $r_i$, each with an associated mean $u_i$, but the same variance $\sigma^2$.  What is the variance of the average of these $M$ random variables: $\frac{\sum_{i=1}^{M} u_i}{M}$?  How does the variance change as $M$ increases?  What if the $M$ variables have a uniform, rather than a normal distribution, over some interval $[A, B]$?",,"['probability', 'random', 'normal-distribution']"
63,Boundary conditions on asymmetric random walk recursion formula,Boundary conditions on asymmetric random walk recursion formula,,"A random walker moves at each step two units to the right or one unit to the left, with corresponding probabilities $p$ and $q = 1-p$. The allowed range is $[-A, B]$ and the starting position is $0$. Is the recursion formula $f[z]= p f[z-2] + q f[z+1]$ valid? I'm looking for the three boundary conditions in order to solve the formula. $f(z)=P(S(τ)=B|S(0)=z)$  where $τ=\min \{n≥0:S(n) = B \text{ or } S(n) = −A\}$  where $S(n)$   is the position of the random walker after $n$ steps.","A random walker moves at each step two units to the right or one unit to the left, with corresponding probabilities $p$ and $q = 1-p$. The allowed range is $[-A, B]$ and the starting position is $0$. Is the recursion formula $f[z]= p f[z-2] + q f[z+1]$ valid? I'm looking for the three boundary conditions in order to solve the formula. $f(z)=P(S(τ)=B|S(0)=z)$  where $τ=\min \{n≥0:S(n) = B \text{ or } S(n) = −A\}$  where $S(n)$   is the position of the random walker after $n$ steps.",,"['probability', 'random-walk']"
64,Finding $E(N)$ in this question,Finding  in this question,E(N),"suppose $X_1,X_2,\ldots$ is sequence of independent random variables of $U(0,1)$ if  $N=\min\{n>0 :X_{(n:n)}-X_{(1:n)}>\alpha , 0<\alpha<1\}$ that $X_{(1:n)}$ is smallest order statistic and $X_{(n:n)}$ is largest order statistic. how can find $E(N)$","suppose $X_1,X_2,\ldots$ is sequence of independent random variables of $U(0,1)$ if  $N=\min\{n>0 :X_{(n:n)}-X_{(1:n)}>\alpha , 0<\alpha<1\}$ that $X_{(1:n)}$ is smallest order statistic and $X_{(n:n)}$ is largest order statistic. how can find $E(N)$",,['probability']
65,Average time to find a duplicate with pairwise independence,Average time to find a duplicate with pairwise independence,,"Assume a process that samples uniformly at random from the range $[1,\ldots,n]$. I am interested in the expected time to find a duplicate given only that the sampling process is pairwise independent. That is I would like to find the expected time until a sample matches one of the samples taken before. One way to compute the expected time is $$E=\sum_{x=1}^\infty P(X \geq x).$$  Here $X$ is a random variable that represents the time at which the first duplicate is found. If the samples were fully independent then we would have that  $$\sum_{x=1}^\infty P(X \geq x) = \sum_{x=1}^\infty \prod_{i=1}^{x-1} (1-i/n).$$  We can bound this quantity using the fact that $e^{-2x} \leq 1-x \leq e^{-x}$ when $0 \leq x \leq 0.5$ and then bound the resulting sum using an integral. This gives an asymptotic bound of $\Theta(\sqrt{n})$ steps. How would you perform a similar analysis where we only have pairwise independence and also preferably get an asymptotic result rather than just an upper bound? EDIT: Following Henry's great reply, I would really like to know a lower bound as well as the upper bound he has given.  In particular, does the lower bound for fully independent sampling of $\Omega(\sqrt{n})$ also apply to this pairwise independent case?  Or alternatively, can anyone think of a pairwise independent process that has mean less than order $\sqrt{n}$?","Assume a process that samples uniformly at random from the range $[1,\ldots,n]$. I am interested in the expected time to find a duplicate given only that the sampling process is pairwise independent. That is I would like to find the expected time until a sample matches one of the samples taken before. One way to compute the expected time is $$E=\sum_{x=1}^\infty P(X \geq x).$$  Here $X$ is a random variable that represents the time at which the first duplicate is found. If the samples were fully independent then we would have that  $$\sum_{x=1}^\infty P(X \geq x) = \sum_{x=1}^\infty \prod_{i=1}^{x-1} (1-i/n).$$  We can bound this quantity using the fact that $e^{-2x} \leq 1-x \leq e^{-x}$ when $0 \leq x \leq 0.5$ and then bound the resulting sum using an integral. This gives an asymptotic bound of $\Theta(\sqrt{n})$ steps. How would you perform a similar analysis where we only have pairwise independence and also preferably get an asymptotic result rather than just an upper bound? EDIT: Following Henry's great reply, I would really like to know a lower bound as well as the upper bound he has given.  In particular, does the lower bound for fully independent sampling of $\Omega(\sqrt{n})$ also apply to this pairwise independent case?  Or alternatively, can anyone think of a pairwise independent process that has mean less than order $\sqrt{n}$?",,[]
66,Monte Carlo algorithm that determines if a permutation of the integers 1 through $n$ has already been sorted.,Monte Carlo algorithm that determines if a permutation of the integers 1 through  has already been sorted.,n,"This question is from ""Discrete Mathematics and Its Applications"", from Kenneth Rosen, 6th Edition. Devise a Monte Carlo algorithm that determines whether   a permutation of the integers 1 through $n$ has already been   sorted (that is, it is in increasing order), or instead, is a random   permutation. A step of the algorithm should answer   “true” if it determines the list is not sorted and “unknown”   otherwise. After $k$ steps, the algorithm decides that the integers   are sorted if the answer is “unknown” in each step.   Show that as the number of steps increases, the probability   that the algorithm produces an incorrect answer is   extremely small. [ Hint : For each step, test whether certain   elements are in the correct order. Make sure these   tests are independent.] Here is my attempt at a solution: Algorithm (informal description) : Given a permutation of the integers 1 through $n$, in each step of the algorithm, one element is randomly chosen from the permutation, with a total of $k$ steps. In each step, if the value of the chosen element is $i$, the algorithm checks if the element is in the correct position, that is, if it is in the $i^{th}$ position of the permutation (with $1\leq i\leq n$). If it is in the correct position, the result is ""unknown""; otherwise, the result is ""true"". For example, in the permutation $162453$, the number $4$ is in the $4^{th}$ position, therefore it is in the correct position in the permutation. If all steps give the result ""unknown"" , the algorithm determines that the permutation is sorted; otherwise, it determines that the integers are not sorted. I posted the details as an answer, but I'm not sure whether it is correct and completely consistent. Thank you in advance.","This question is from ""Discrete Mathematics and Its Applications"", from Kenneth Rosen, 6th Edition. Devise a Monte Carlo algorithm that determines whether   a permutation of the integers 1 through $n$ has already been   sorted (that is, it is in increasing order), or instead, is a random   permutation. A step of the algorithm should answer   “true” if it determines the list is not sorted and “unknown”   otherwise. After $k$ steps, the algorithm decides that the integers   are sorted if the answer is “unknown” in each step.   Show that as the number of steps increases, the probability   that the algorithm produces an incorrect answer is   extremely small. [ Hint : For each step, test whether certain   elements are in the correct order. Make sure these   tests are independent.] Here is my attempt at a solution: Algorithm (informal description) : Given a permutation of the integers 1 through $n$, in each step of the algorithm, one element is randomly chosen from the permutation, with a total of $k$ steps. In each step, if the value of the chosen element is $i$, the algorithm checks if the element is in the correct position, that is, if it is in the $i^{th}$ position of the permutation (with $1\leq i\leq n$). If it is in the correct position, the result is ""unknown""; otherwise, the result is ""true"". For example, in the permutation $162453$, the number $4$ is in the $4^{th}$ position, therefore it is in the correct position in the permutation. If all steps give the result ""unknown"" , the algorithm determines that the permutation is sorted; otherwise, it determines that the integers are not sorted. I posted the details as an answer, but I'm not sure whether it is correct and completely consistent. Thank you in advance.",,"['probability', 'algorithms', 'discrete-mathematics', 'monte-carlo']"
67,Basic calculation of an expectation,Basic calculation of an expectation,,"We define $J_{k,n}:=((k-1)2^{-n},k2^{-n}]$ for $n\in \mathbb{N}_0$ and $k=1,\dots,2^n$. Let $W$ be a Brownian Motion. Let $n\ge m$ and we assume $J_{k,n}\subset J_{l,m}$. W.l.o.g $J_{k,n}$ lies in the left half of $J_{l,m}$. Moreover we set $\Delta W([a,b])=W_b-W_a$, which is by definition normal distributed. Hence I know $\Delta W (J_{2k-1,n+1})-\Delta W(J_{2k,n+1})$ and $\Delta W(J_{2l,m+1})$ are independent, since $J_{k,n}$ lies in the left half of $J_{l,m}$. Furthermore, $(l-1)2^{-m}\le (k-1)2^{-n}\le k2^{-n}\le(2l-1)2^{-(m+1)}$.  Why is the following computation true? $$E[(\Delta W (J_{2k-1,n+1})-\Delta W(J_{2k,n+1}))\Delta W(J_{2l-1,m+1})]=2^{-(n+1)}-0-2^{-(n+1)}+0=0$$ They argue that all sub intervals of a dyadic partition have the same length. EDIT: Here is what I did so far: $\Delta W (J_{2k-1,n+1})=W_{(2k-1)2^{-(n+1)}}-W_{(k-1)2^{-n}}$ $\Delta W(J_{2k,n+1}) = W_{k2^{-n}}-W_{(2k-1)2^{-(n+1)}}$ $\Delta W(J_{2l-1,m+1}) = W_{(2l-1)2^{-(m+1)}}-W_{(l-1)2^{-m}}$ $\Delta W (J_{2k-1,n+1})-\Delta W(J_{2k,n+1})=2W_{(2k-1)2^{-(n+1)}}-W_{(k-1)2^{-n}}-W_{k2^{-n}}$ From here, I do not know how to proceed. hulik","We define $J_{k,n}:=((k-1)2^{-n},k2^{-n}]$ for $n\in \mathbb{N}_0$ and $k=1,\dots,2^n$. Let $W$ be a Brownian Motion. Let $n\ge m$ and we assume $J_{k,n}\subset J_{l,m}$. W.l.o.g $J_{k,n}$ lies in the left half of $J_{l,m}$. Moreover we set $\Delta W([a,b])=W_b-W_a$, which is by definition normal distributed. Hence I know $\Delta W (J_{2k-1,n+1})-\Delta W(J_{2k,n+1})$ and $\Delta W(J_{2l,m+1})$ are independent, since $J_{k,n}$ lies in the left half of $J_{l,m}$. Furthermore, $(l-1)2^{-m}\le (k-1)2^{-n}\le k2^{-n}\le(2l-1)2^{-(m+1)}$.  Why is the following computation true? $$E[(\Delta W (J_{2k-1,n+1})-\Delta W(J_{2k,n+1}))\Delta W(J_{2l-1,m+1})]=2^{-(n+1)}-0-2^{-(n+1)}+0=0$$ They argue that all sub intervals of a dyadic partition have the same length. EDIT: Here is what I did so far: $\Delta W (J_{2k-1,n+1})=W_{(2k-1)2^{-(n+1)}}-W_{(k-1)2^{-n}}$ $\Delta W(J_{2k,n+1}) = W_{k2^{-n}}-W_{(2k-1)2^{-(n+1)}}$ $\Delta W(J_{2l-1,m+1}) = W_{(2l-1)2^{-(m+1)}}-W_{(l-1)2^{-m}}$ $\Delta W (J_{2k-1,n+1})-\Delta W(J_{2k,n+1})=2W_{(2k-1)2^{-(n+1)}}-W_{(k-1)2^{-n}}-W_{k2^{-n}}$ From here, I do not know how to proceed. hulik",,['probability']
68,Probability distributions as limits of continuous ones and of discrete ones,Probability distributions as limits of continuous ones and of discrete ones,,"While skipping through the class notes I noticed one exercice that I couldn't solve: Suppose we have $\mu$ - probability distribution in $\mathbb{R}$. Recalling that  $\mu_k \rightarrow \mu$ iff $\int_{\mathbb{R}} f(x)\mu_k(dx) \rightarrow \int_{\mathbb{R}} f(x) \mu(dx)$, $\forall f \in C(\mathbb{R})$, $f$ bounded $k\rightarrow \infty$. We have to show: $\exists \mu_k$ - series of continuous distributions that $\mu_k \rightarrow \mu$. $\exists \mu_k$ - series of discrete distributions that $\mu_k \rightarrow \mu$.","While skipping through the class notes I noticed one exercice that I couldn't solve: Suppose we have $\mu$ - probability distribution in $\mathbb{R}$. Recalling that  $\mu_k \rightarrow \mu$ iff $\int_{\mathbb{R}} f(x)\mu_k(dx) \rightarrow \int_{\mathbb{R}} f(x) \mu(dx)$, $\forall f \in C(\mathbb{R})$, $f$ bounded $k\rightarrow \infty$. We have to show: $\exists \mu_k$ - series of continuous distributions that $\mu_k \rightarrow \mu$. $\exists \mu_k$ - series of discrete distributions that $\mu_k \rightarrow \mu$.",,"['probability', 'probability-distributions']"
69,How do you calculate the average number of lands in your hand in a game of MTG?,How do you calculate the average number of lands in your hand in a game of MTG?,,"(This is actually a question and a half; Please tell me if this should be done otherwise) I have a magic deck of 60 cards. Some of them (say 25) are lands. The first card I draw has a 25/60 chance of being a land. If it is, the next card has a 24/59 chance, whereas if it's not, it has a 25/59 chance. How do you find the average number of lands in your hand? (a hand is seven cards) How do you find the standard deviation of this? How do you graph it?","(This is actually a question and a half; Please tell me if this should be done otherwise) I have a magic deck of 60 cards. Some of them (say 25) are lands. The first card I draw has a 25/60 chance of being a land. If it is, the next card has a 24/59 chance, whereas if it's not, it has a 25/59 chance. How do you find the average number of lands in your hand? (a hand is seven cards) How do you find the standard deviation of this? How do you graph it?",,"['probability', 'probability-distributions', 'recreational-mathematics']"
70,Expected occupied area of a surface covered with possibly overlapping random shapes.,Expected occupied area of a surface covered with possibly overlapping random shapes.,,"Given a surface with area $A$, what is the expected area of the region occupied by $k$ possibly overlapping random circles with equal radii $r$? For example, I would like to estimate the area of the black region of this simulation . If it helps, we can assume the edges of surface wraps around, so the surface is a torus. And instead of random circles, it can also be random squares. I've tried to find an approximation by partitioning the space as a ""pixel"" grid and solve it as a K balls in N buckets problem. But I didn't find how to generalize it from balls to circles.","Given a surface with area $A$, what is the expected area of the region occupied by $k$ possibly overlapping random circles with equal radii $r$? For example, I would like to estimate the area of the black region of this simulation . If it helps, we can assume the edges of surface wraps around, so the surface is a torus. And instead of random circles, it can also be random squares. I've tried to find an approximation by partitioning the space as a ""pixel"" grid and solve it as a K balls in N buckets problem. But I didn't find how to generalize it from balls to circles.",,"['probability', 'geometry']"
71,Estimation for modulus of characteristic function,Estimation for modulus of characteristic function,,"It is well-known that if $\xi$ is an absolutely continuous random variable with characteristic function $\phi(t)$, then for each $\epsilon>0$ one has $\sup\limits_{|t|>\epsilon}|\phi(t)|<1$ (sometimes it is called Cramer's theorem). However, if we can say something about existence of moments of the r.v. then this result can be improved. For instance, if $\mathsf E \xi=0,\, \mathsf E \xi^2<\infty$, then one can conclude(if I do not mistake) that exists such $K>0$ that for all $s \in (0,1)$ $\sup_{|t|>s}|\phi(t)|<e^{-Ks^2}$. The questions are the following: is the statement above true? How one can prove it(I tried to do something with Taylor's expansion and the estimation like $|e^{is}-1-is|\leq |s|^2/2$, but I did not manage to prove it)? Can there be generalization for r.v. that possesses higher moments? Thanks","It is well-known that if $\xi$ is an absolutely continuous random variable with characteristic function $\phi(t)$, then for each $\epsilon>0$ one has $\sup\limits_{|t|>\epsilon}|\phi(t)|<1$ (sometimes it is called Cramer's theorem). However, if we can say something about existence of moments of the r.v. then this result can be improved. For instance, if $\mathsf E \xi=0,\, \mathsf E \xi^2<\infty$, then one can conclude(if I do not mistake) that exists such $K>0$ that for all $s \in (0,1)$ $\sup_{|t|>s}|\phi(t)|<e^{-Ks^2}$. The questions are the following: is the statement above true? How one can prove it(I tried to do something with Taylor's expansion and the estimation like $|e^{is}-1-is|\leq |s|^2/2$, but I did not manage to prove it)? Can there be generalization for r.v. that possesses higher moments? Thanks",,"['probability', 'probability-theory', 'inequality']"
72,Is this moment inequality valid?,Is this moment inequality valid?,,"$X$ is a positive continuous random variable. $E[X^p]$  is the $p$-th moment of $X$, $p\ge2$. Is the following moment inequality valid? $E[X^p]\le (p-1)^{p/2}(E[X^2])^{p/2}$ If so, What is the name of this inequality, and how to prove it?","$X$ is a positive continuous random variable. $E[X^p]$  is the $p$-th moment of $X$, $p\ge2$. Is the following moment inequality valid? $E[X^p]\le (p-1)^{p/2}(E[X^2])^{p/2}$ If so, What is the name of this inequality, and how to prove it?",,"['probability', 'inequality', 'order-statistics']"
73,You roll two dice. What is the probability of the event that they have no common factor greater than unity?,You roll two dice. What is the probability of the event that they have no common factor greater than unity?,,"This question appears in Stirzaker's Elementary Probability (2nd Edition). It is worked example 1.8 (p40). My solution and answer: The answer is $\mathcal{P}(A^c)$ , where: $A = \lbrace (2, 4), (4,2), (2,6), (6,2), (3,6), (6,3), (4,6), (6,4) \rbrace$ . There are 8 pairs, so the probability is $ 1 - 8/36 = 28/36 = 7/9$ . The textbook's solution and answer: It is routine to list the outcomes that do have a common factor greater than unity. They are 13 in number, namely: $\lbrace (i,i); i \geq 2 \rbrace, (2, 4), (4,2), (2,6), (6,2), (3,6), (6,3), (4,6), (6,4)$ . This is the complementary event, so by (1.4.5) the required probability is $ 1 - 13/36 = 23/36 $ Where'd the number 13 come from? Stirzaker enumerates the same set, but says there are 13 members. Where does he get the extra 5? Screenshot of solution: https://i.sstatic.net/JB93C.jpg","This question appears in Stirzaker's Elementary Probability (2nd Edition). It is worked example 1.8 (p40). My solution and answer: The answer is , where: . There are 8 pairs, so the probability is . The textbook's solution and answer: It is routine to list the outcomes that do have a common factor greater than unity. They are 13 in number, namely: . This is the complementary event, so by (1.4.5) the required probability is Where'd the number 13 come from? Stirzaker enumerates the same set, but says there are 13 members. Where does he get the extra 5? Screenshot of solution: https://i.sstatic.net/JB93C.jpg","\mathcal{P}(A^c) A = \lbrace (2, 4), (4,2), (2,6), (6,2), (3,6), (6,3), (4,6), (6,4) \rbrace  1 - 8/36 = 28/36 = 7/9 \lbrace (i,i); i \geq 2 \rbrace, (2, 4), (4,2), (2,6), (6,2), (3,6), (6,3), (4,6), (6,4)  1 - 13/36 = 23/36 ",['probability']
74,Probability of non-empty bins after randomly inserting balls by pairs,Probability of non-empty bins after randomly inserting balls by pairs,,"Given $n$ bins, at each step we choose uniformly two of them (distinct) and insert a ball to both. After $k$ steps, what is the probability that all of the bins are non-empty?","Given $n$ bins, at each step we choose uniformly two of them (distinct) and insert a ball to both. After $k$ steps, what is the probability that all of the bins are non-empty?",,"['probability', 'combinatorics']"
75,Random walk probability/expected value,Random walk probability/expected value,,"With what probability, starting at node $g$, does node $d$ get hit before node $e$ in the graph below? What is the expected value of number of steps you need to hit $\{d,e\}$ (at least one of them) starting from node $g$? Please help me answering the questions, I have no idea where to start. The random walk on the graph is assumed to be uniform.","With what probability, starting at node $g$, does node $d$ get hit before node $e$ in the graph below? What is the expected value of number of steps you need to hit $\{d,e\}$ (at least one of them) starting from node $g$? Please help me answering the questions, I have no idea where to start. The random walk on the graph is assumed to be uniform.",,"['probability', 'graph-theory', 'random-walk']"
76,Alternate strategies to central moments to characterise distributions,Alternate strategies to central moments to characterise distributions,,"Assume a single real-valued variable, and frequent irregular observations of its value over a series of time-spans.  In each time span, I'm assuming the samples are from a distribution of values which the variable assumes during that time span... I intend to compare distributions between time-spans, hoping to find patterns that are otherwise obscured by the detail of the irregular sampling. The most obvious way I can see to characterise these distributions is the first n central moments... so, for example, I can calculate approximations of the Mean, Variance, Skew and Kurtosis for the sample data.  I am aware, however, of distributions which do not have meaningful definitions of central moments (Cauchy distributions, for example) and recognise that trying to characterise such a distribution by approximated central moments is unlikely to provide useful insights. Aside from central moments, what other approaches might I use to try to classify distributions?","Assume a single real-valued variable, and frequent irregular observations of its value over a series of time-spans.  In each time span, I'm assuming the samples are from a distribution of values which the variable assumes during that time span... I intend to compare distributions between time-spans, hoping to find patterns that are otherwise obscured by the detail of the irregular sampling. The most obvious way I can see to characterise these distributions is the first n central moments... so, for example, I can calculate approximations of the Mean, Variance, Skew and Kurtosis for the sample data.  I am aware, however, of distributions which do not have meaningful definitions of central moments (Cauchy distributions, for example) and recognise that trying to characterise such a distribution by approximated central moments is unlikely to provide useful insights. Aside from central moments, what other approaches might I use to try to classify distributions?",,"['probability', 'statistics', 'probability-distributions']"
77,Order Statistic Expectation / Probability,Order Statistic Expectation / Probability,,"Let $Y_1<Y_2$ be order statistics from a random sample of size $2$ from a normal distribution, $\mathcal{N}(\mu,\sigma^2)$, where $\sigma^2$ is known. Show that $P(Y_1<\mu<Y_2)=\frac12$ and find $E(Y_1-Y_2)$. I am not exactly sure how to solve the question above. Any help would be appreciated. Thanks.","Let $Y_1<Y_2$ be order statistics from a random sample of size $2$ from a normal distribution, $\mathcal{N}(\mu,\sigma^2)$, where $\sigma^2$ is known. Show that $P(Y_1<\mu<Y_2)=\frac12$ and find $E(Y_1-Y_2)$. I am not exactly sure how to solve the question above. Any help would be appreciated. Thanks.",,"['probability', 'statistics']"
78,Homework about compound random variable,Homework about compound random variable,,"this is an homework but i really tried hard before surrender, and i think that or I'm very close to the end or I'm as far as possibile..  That's the text: Let $X_1, X_2, ..., X_n$ be independent and identically distributed random variables. And N is a nonnegative integer valued random variable (indipendent to any $X_i$). Let $Z = \Sigma_{i=1}^NX_i$ calculate $Cov(N,Z)$. What I have done: I know that $Cov(N,Z) = E[NZ] -E[N]E[Z]$ What i've done is try to get $E[NZ] = E[\Sigma_{i=1}^N X_i N] =$ $= \Sigma_{n=0}^{\infty} E[\Sigma_{i=1}^N X_i N | N=n] P(N=n)$ = $= \Sigma_{n=0}^{\infty} E[n\Sigma_{i=1}^n X_i]P(N=n) = $ $= \Sigma_{n=0}^{\infty} n E[\Sigma_{i=1}^n X_i]P(N=n) = $ As $X_i$ is iid with any other $X_j$ i use only $X_1$ $=\Sigma_{n=0}^{\infty} nE[\Sigma_{i=1}^n X_1]P(N=n) = $ $=\Sigma_{n=0}^{\infty} n^2 X_1 P(N=n) = X_1\Sigma_{n=0}^{\infty} n^2 P(N=n)$ I know that $\Sigma_{n=0}^{\infty} n P(N=n) = E[N]$ but what about $=\Sigma_{n=0}^{\infty} n^2 P(N=n)$. Thank you","this is an homework but i really tried hard before surrender, and i think that or I'm very close to the end or I'm as far as possibile..  That's the text: Let $X_1, X_2, ..., X_n$ be independent and identically distributed random variables. And N is a nonnegative integer valued random variable (indipendent to any $X_i$). Let $Z = \Sigma_{i=1}^NX_i$ calculate $Cov(N,Z)$. What I have done: I know that $Cov(N,Z) = E[NZ] -E[N]E[Z]$ What i've done is try to get $E[NZ] = E[\Sigma_{i=1}^N X_i N] =$ $= \Sigma_{n=0}^{\infty} E[\Sigma_{i=1}^N X_i N | N=n] P(N=n)$ = $= \Sigma_{n=0}^{\infty} E[n\Sigma_{i=1}^n X_i]P(N=n) = $ $= \Sigma_{n=0}^{\infty} n E[\Sigma_{i=1}^n X_i]P(N=n) = $ As $X_i$ is iid with any other $X_j$ i use only $X_1$ $=\Sigma_{n=0}^{\infty} nE[\Sigma_{i=1}^n X_1]P(N=n) = $ $=\Sigma_{n=0}^{\infty} n^2 X_1 P(N=n) = X_1\Sigma_{n=0}^{\infty} n^2 P(N=n)$ I know that $\Sigma_{n=0}^{\infty} n P(N=n) = E[N]$ but what about $=\Sigma_{n=0}^{\infty} n^2 P(N=n)$. Thank you",,"['probability', 'probability-distributions']"
79,Probability distribution function,Probability distribution function,,"I am trying to develop a function that will allow me to input a random number between 0 and 1 and receive a value. The idea is that the function has a range (for example, 0-100) with a median value of 50. I want something similar to a normal distribution of values: The idea is that if I put in an arbitrary number of random inputs between 0 and 1, the vast majority of outputs will be near 50. Outputs near 0 or 100 would be very rare. I have been attempting to read the Wikipedia article on probability distribution , but the knowledge needed to write a function eludes me. So: what kind of function do I need to use in order for the results of that function to be in a normal distribution with domain [0, 1]. Thanks for the help. Explanations or suggestions on where to find explanations for anything above an Algebra II level would be greatly appreciated.","I am trying to develop a function that will allow me to input a random number between 0 and 1 and receive a value. The idea is that the function has a range (for example, 0-100) with a median value of 50. I want something similar to a normal distribution of values: The idea is that if I put in an arbitrary number of random inputs between 0 and 1, the vast majority of outputs will be near 50. Outputs near 0 or 100 would be very rare. I have been attempting to read the Wikipedia article on probability distribution , but the knowledge needed to write a function eludes me. So: what kind of function do I need to use in order for the results of that function to be in a normal distribution with domain [0, 1]. Thanks for the help. Explanations or suggestions on where to find explanations for anything above an Algebra II level would be greatly appreciated.",,"['probability', 'probability-distributions', 'normal-distribution']"
80,Are these conditions sufficient to calculate this expectation?,Are these conditions sufficient to calculate this expectation?,,We have \begin{aligned} E(Z_1) = A \\ \Pr \{ Z_2 = Z_1 + 1 \} = \frac 1 2  \\ \Pr \{ Z_2 = Z_1 - 1 \} = \frac 1 2  \end{aligned} Are these conditions enough to get $E(Z_2)$?,We have \begin{aligned} E(Z_1) = A \\ \Pr \{ Z_2 = Z_1 + 1 \} = \frac 1 2  \\ \Pr \{ Z_2 = Z_1 - 1 \} = \frac 1 2  \end{aligned} Are these conditions enough to get $E(Z_2)$?,,['probability']
81,Double exponential distribution,Double exponential distribution,,"Let $\zeta$ and $\eta$ be independent random variable with $\exp(\lambda)$ distribution. What is  the distribution of $Z=|\zeta-\eta|$ . I am trying to calculate it by finding $\Pr(\zeta-\eta>x)$, and $\Pr(\eta-\zeta>x)$. Thank you in advance","Let $\zeta$ and $\eta$ be independent random variable with $\exp(\lambda)$ distribution. What is  the distribution of $Z=|\zeta-\eta|$ . I am trying to calculate it by finding $\Pr(\zeta-\eta>x)$, and $\Pr(\eta-\zeta>x)$. Thank you in advance",,"['probability', 'probability-distributions']"
82,Reaction-diffusion equations and stochastic processes,Reaction-diffusion equations and stochastic processes,,"The solution to the Fokker-Planck equation can be thought of as a macroscopic description of the dynamics of a diffusion process . Various results make this heuristic more precise - Ito integration, the Feynman-Kac theorem and so on. Do reaction-diffusion equations have a similar probabilistic interpretation? If so, where can I read about this? Many thanks.","The solution to the Fokker-Planck equation can be thought of as a macroscopic description of the dynamics of a diffusion process . Various results make this heuristic more precise - Ito integration, the Feynman-Kac theorem and so on. Do reaction-diffusion equations have a similar probabilistic interpretation? If so, where can I read about this? Many thanks.",,"['probability', 'stochastic-processes', 'partial-differential-equations']"
83,Magical Loaded Dice and expected values,Magical Loaded Dice and expected values,,"Let's say we have a magical biased die that allows us to set the probability of every side to whatever we want (nonzero and add up to 1, of course).  And let's say this die enforces the condition that the value of every roll must be between 1 and previousRoll + 1 . What would we set the bias on the sides to be to keep the expected value (mean over a large number of rolls) at 3.5, the same as an unbiased non-magical die? More interestingly, what if the die has an arbitrary number of sides?  What if it's output is continuous?","Let's say we have a magical biased die that allows us to set the probability of every side to whatever we want (nonzero and add up to 1, of course).  And let's say this die enforces the condition that the value of every roll must be between 1 and previousRoll + 1 . What would we set the bias on the sides to be to keep the expected value (mean over a large number of rolls) at 3.5, the same as an unbiased non-magical die? More interestingly, what if the die has an arbitrary number of sides?  What if it's output is continuous?",,"['probability', 'statistics', 'probability-theory', 'dice']"
84,Closure of an invariant set,Closure of an invariant set,,"Consider a complete metric compact space $X$. For each $x\in X$ we define a probability measure $T(\cdot|x)$ over a Borel sigma-algebra $\mathcal{B}(X)$. We call a set $A\subset X$ invariant if $T(A|x) = 1$ for all $x\in A$. Does it mean that if $A$ is invariant, the same holds for its closure? I am especially interested in the case when $T$ is Feller continuous or strong Feller continuous. More precisely, denote $$ \mathcal{P}f(x) = \int\limits_X f(y)T(dy|x) $$ and spaces $\mathcal{M}_b$ and $\mathcal{C}_b$ of measurable bounded and continuous bounded functions on $X$. Then Feller continuity means $f(x)\in \mathcal{C}_b \Rightarrow \mathcal{P}f(x)\in\mathcal{C}_b$ and strong Feller continuity means $f(x)\in \mathcal{M}_b \Rightarrow \mathcal{P}f(x)\in\mathcal{C}_b$.","Consider a complete metric compact space $X$. For each $x\in X$ we define a probability measure $T(\cdot|x)$ over a Borel sigma-algebra $\mathcal{B}(X)$. We call a set $A\subset X$ invariant if $T(A|x) = 1$ for all $x\in A$. Does it mean that if $A$ is invariant, the same holds for its closure? I am especially interested in the case when $T$ is Feller continuous or strong Feller continuous. More precisely, denote $$ \mathcal{P}f(x) = \int\limits_X f(y)T(dy|x) $$ and spaces $\mathcal{M}_b$ and $\mathcal{C}_b$ of measurable bounded and continuous bounded functions on $X$. Then Feller continuity means $f(x)\in \mathcal{C}_b \Rightarrow \mathcal{P}f(x)\in\mathcal{C}_b$ and strong Feller continuity means $f(x)\in \mathcal{M}_b \Rightarrow \mathcal{P}f(x)\in\mathcal{C}_b$.",,"['probability', 'measure-theory', 'functional-analysis', 'stochastic-processes']"
85,The processing time of an M/M/1 queue,The processing time of an M/M/1 queue,,"Suppose I have a queue with $\lambda$ and $\mu$. I can calculate the probability that there are 2 objects in the queue trivially, but how can I compute, for example, the probability that it takes an object less than $n$ units of time to be processed?","Suppose I have a queue with $\lambda$ and $\mu$. I can calculate the probability that there are 2 objects in the queue trivially, but how can I compute, for example, the probability that it takes an object less than $n$ units of time to be processed?",,"['probability', 'queueing-theory']"
86,Probability of getting a royal flush with four wild-cards,Probability of getting a royal flush with four wild-cards,,"I am trying to calculate the probability of getting royal flush, if four 5's are wild cards that can be of any suit. I get that the probability of the first card I am picking is $\frac{24}{52}$, but then it seems to be breaking down into many complicated cases (since I can pick which suit the 5 [if I get one] should be of at any time of picking, including the very end). Is there a not complicated way of computing it? Or how can this be calculated?","I am trying to calculate the probability of getting royal flush, if four 5's are wild cards that can be of any suit. I get that the probability of the first card I am picking is $\frac{24}{52}$, but then it seems to be breaking down into many complicated cases (since I can pick which suit the 5 [if I get one] should be of at any time of picking, including the very end). Is there a not complicated way of computing it? Or how can this be calculated?",,[]
87,Proving sets to be independent,Proving sets to be independent,,"I know that I can use P(AB)=P(A)P(B) to prove whether sets are independent. But how can I use this to say that P(A)=0.3 and P(B)=0.4 and P(AUB)=0.6 are or aren't independent? It's fine not to give an outright solution, an explanation would be much more helpful!","I know that I can use P(AB)=P(A)P(B) to prove whether sets are independent. But how can I use this to say that P(A)=0.3 and P(B)=0.4 and P(AUB)=0.6 are or aren't independent? It's fine not to give an outright solution, an explanation would be much more helpful!",,[]
88,Maximum gap among N points on a circle,Maximum gap among N points on a circle,,"If $N$ points on the circumference of a circle are chosen at random, what is the probability $F(\theta)$ that the maximum gap between neighboring points is at least $\theta$?  Because the gaps sum to $2\pi$, the maximum must be at least $2\pi/N$, so $$F(\theta)=1 \text{  for } \theta\le\frac{2\pi}{N}.$$  At the other extreme, the solution to this problem shows that $$F(\theta) = N\left(1 - \frac{\theta}{2\pi}\right)^{N-1} \text{  for } \theta\ge\pi.$$  Is there a closed-form solution for any other values of $\theta$? Update: The general closed-form solution is given in the answer below.  In terms of the notation in the question, it is $$ F(\theta) = \sum_{k=1}^{K} (-1)^{k-1} {N\choose k} \left(1 - \frac{k \theta}{2\pi}\right)^{N-1}, $$ where $K = \min(N, \lfloor{2\pi/\theta}\rfloor)$.  This reduces to the limiting cases given in the question when $\theta \le 2\pi/N$ (in which case $K=N$) and when $\theta \ge \pi$ (in which case $K=1$).","If $N$ points on the circumference of a circle are chosen at random, what is the probability $F(\theta)$ that the maximum gap between neighboring points is at least $\theta$?  Because the gaps sum to $2\pi$, the maximum must be at least $2\pi/N$, so $$F(\theta)=1 \text{  for } \theta\le\frac{2\pi}{N}.$$  At the other extreme, the solution to this problem shows that $$F(\theta) = N\left(1 - \frac{\theta}{2\pi}\right)^{N-1} \text{  for } \theta\ge\pi.$$  Is there a closed-form solution for any other values of $\theta$? Update: The general closed-form solution is given in the answer below.  In terms of the notation in the question, it is $$ F(\theta) = \sum_{k=1}^{K} (-1)^{k-1} {N\choose k} \left(1 - \frac{k \theta}{2\pi}\right)^{N-1}, $$ where $K = \min(N, \lfloor{2\pi/\theta}\rfloor)$.  This reduces to the limiting cases given in the question when $\theta \le 2\pi/N$ (in which case $K=N$) and when $\theta \ge \pi$ (in which case $K=1$).",,"['probability', 'circles']"
89,question about conditional probability for continuous r.v,question about conditional probability for continuous r.v,,"This is related to the content in the book by Grimmett and Stirzaker ""Probability and random processes"" 3rd ed. On page 111, it calculated, as an example, the conditional density function of $X_1+X_2$ given $X_1=X_2$ for two i.i.d. exponential r.v. with parameter $\lambda$. They used two methods, 1) using $Y_1=X_1+X_2$ and $Y_2=X_1/X_2$ and then obtained the result $f_{Y_1\vert Y_3}(y_1\vert y_3)=\lambda^2 y_1 e^{-\lambda y_1}$ for $y_1\ge 0$ 2) using $Y_1=X_1+X_2$ and $Y_3=X_1-X_2$ and then obtained the result $f_{Y_1\vert Y_3}(y_1\vert y_3)=\lambda e^{-\lambda y_1}$ for $y_1\ge 0$ The explanation provided there is that the two results are based on different sets of information. My question is: Does this only occurs for 2 r.v.'s when conditioned on an event with zero probability, or it is in general true even for the condition involving only 1 r.v.? I am a little confused at the situation when the the conditional event has zero probability. Thanks!","This is related to the content in the book by Grimmett and Stirzaker ""Probability and random processes"" 3rd ed. On page 111, it calculated, as an example, the conditional density function of $X_1+X_2$ given $X_1=X_2$ for two i.i.d. exponential r.v. with parameter $\lambda$. They used two methods, 1) using $Y_1=X_1+X_2$ and $Y_2=X_1/X_2$ and then obtained the result $f_{Y_1\vert Y_3}(y_1\vert y_3)=\lambda^2 y_1 e^{-\lambda y_1}$ for $y_1\ge 0$ 2) using $Y_1=X_1+X_2$ and $Y_3=X_1-X_2$ and then obtained the result $f_{Y_1\vert Y_3}(y_1\vert y_3)=\lambda e^{-\lambda y_1}$ for $y_1\ge 0$ The explanation provided there is that the two results are based on different sets of information. My question is: Does this only occurs for 2 r.v.'s when conditioned on an event with zero probability, or it is in general true even for the condition involving only 1 r.v.? I am a little confused at the situation when the the conditional event has zero probability. Thanks!",,['probability']
90,Expected amount of number one can add before reach n,Expected amount of number one can add before reach n,,"Given integer $n$ and real $0\leq d<1$, set $x := 0$, set $c := 0$. set $y := n-x$, if $y < 1-d$, we are done Randomly chose $l\in [1-d, \min(1+d,y)]$, set $x := x + l$, $c := c+1$. Go to 2. So this is a program that count how many random numbers in $[1-d, 1+d]$ one can add until one reach $n$, except the program won't add a number to go over $n$ when one can add a smaller number. What is the expected value of $c$? In one part of my program it output the expected value of $c$ by running the above program many many times. But I don't know if my program is correct, therefore knowing what I should expect will help me test my program's correctness.","Given integer $n$ and real $0\leq d<1$, set $x := 0$, set $c := 0$. set $y := n-x$, if $y < 1-d$, we are done Randomly chose $l\in [1-d, \min(1+d,y)]$, set $x := x + l$, $c := c+1$. Go to 2. So this is a program that count how many random numbers in $[1-d, 1+d]$ one can add until one reach $n$, except the program won't add a number to go over $n$ when one can add a smaller number. What is the expected value of $c$? In one part of my program it output the expected value of $c$ by running the above program many many times. But I don't know if my program is correct, therefore knowing what I should expect will help me test my program's correctness.",,['probability']
91,Chi-square analog for context-dependent distributions,Chi-square analog for context-dependent distributions,,"Lets imagine that we have some experiments. Each experiment may result in one of the outcomes: A, B, C. So we have probability distributions for each experiment $P_A, P_B, P_C$ which is context-dependent, e.g.: $Context_1 \Rightarrow \{P_A^1, P_B^1, P_C^1\},$ experimental outcome is A $Context_2 \Rightarrow \{P_A^2, P_B^2, P_C^2\},$ experimental outcome is B $Context_3 \Rightarrow \{P_A^3, P_B^3, P_C^3\},$ experimental outcome is A $Context_4 \Rightarrow \{P_A^4, P_B^4, P_C^4\},$ experimental outcome is C These probabilities are calculated by some function $F:Context\rightarrow \{P_A, P_B, P_C\}$ I want to estimate an absolute trust rate of this function. In other words, I want to be able to say ""we can trust this function on 86%"" like we do when we deal with Pearson's chi-square test. Any suggestions?","Lets imagine that we have some experiments. Each experiment may result in one of the outcomes: A, B, C. So we have probability distributions for each experiment $P_A, P_B, P_C$ which is context-dependent, e.g.: $Context_1 \Rightarrow \{P_A^1, P_B^1, P_C^1\},$ experimental outcome is A $Context_2 \Rightarrow \{P_A^2, P_B^2, P_C^2\},$ experimental outcome is B $Context_3 \Rightarrow \{P_A^3, P_B^3, P_C^3\},$ experimental outcome is A $Context_4 \Rightarrow \{P_A^4, P_B^4, P_C^4\},$ experimental outcome is C These probabilities are calculated by some function $F:Context\rightarrow \{P_A, P_B, P_C\}$ I want to estimate an absolute trust rate of this function. In other words, I want to be able to say ""we can trust this function on 86%"" like we do when we deal with Pearson's chi-square test. Any suggestions?",,"['probability', 'statistics']"
92,Lottery probability,Lottery probability,,"In the UK the lottery uses numbers $1$ to $49$ and a total of six numbers are picked. It has been said may times that there is as much chance of numbers $1, 2 ,3 ,4 ,5 ,6$ to be picked as any other random combination. My question is this: Let's say that the first $3$ numbers to come out are $1,2$ and $3$. What are the chances of a number between $1$ and $10$ coming out next Vs a number between $11$ and $20$? There are obviously less numbers between $1$ and $10$ now that we already lost $1$ to $3$, so surely the probability is that a number between $11$ and $20$ is more likely? In which case, the chances of a lottery selection of $1,2,3,4,5,6$ is less likely than $2,12,21,28,32,47$ for example...","In the UK the lottery uses numbers $1$ to $49$ and a total of six numbers are picked. It has been said may times that there is as much chance of numbers $1, 2 ,3 ,4 ,5 ,6$ to be picked as any other random combination. My question is this: Let's say that the first $3$ numbers to come out are $1,2$ and $3$. What are the chances of a number between $1$ and $10$ coming out next Vs a number between $11$ and $20$? There are obviously less numbers between $1$ and $10$ now that we already lost $1$ to $3$, so surely the probability is that a number between $11$ and $20$ is more likely? In which case, the chances of a lottery selection of $1,2,3,4,5,6$ is less likely than $2,12,21,28,32,47$ for example...",,['probability']
93,"Probability of winning sweep stakes, put all coupons in one box or split them between boxes?","Probability of winning sweep stakes, put all coupons in one box or split them between boxes?",,"Taken from : here A mall has sweep stakes where they give you a coupon for every X dollars you spend (amount is not important). You fill the coupon with your contact details and put it in the box. Every two weeks, they draw 10 coupons, give their owners prizes, and discard the rest of the coupons. Now, thanks to some very big purchase we made, we have about 300 coupons (going to hurt when filling them). To get the highest probability of winning, should we put all the coupons at once, or split them evenly between the three remaining draws?","Taken from : here A mall has sweep stakes where they give you a coupon for every X dollars you spend (amount is not important). You fill the coupon with your contact details and put it in the box. Every two weeks, they draw 10 coupons, give their owners prizes, and discard the rest of the coupons. Now, thanks to some very big purchase we made, we have about 300 coupons (going to hurt when filling them). To get the highest probability of winning, should we put all the coupons at once, or split them evenly between the three remaining draws?",,['probability']
94,"I've got the same answer to my question via probability and combinations, but I don't know why!","I've got the same answer to my question via probability and combinations, but I don't know why!",,"I am trying to find the answer to the following question: If I am playing poker and am dealt two cards neither of which are spades, what are the chances of two or more of the flop cards (the flop is the first three community cards) being spades. I answered this question in the following way: As I have no spades, there are still 13 spades unseen and a total of 50 cards remaining unseen (52 cards in the pack less my two cards which I've been dealt. If the probability of the first flop card being a spade is p(A) and the second p(B) and the third p(C) then I need to find: p((A∩B)∪(A∩C)∪(B∩C)) so given the formula: p(X∪Y∪Z) = p(X) + p(Y) + p(Z) - p(X∩Y) - p(X∩Z) - p(Y∩Z) + p(X∩Y∩Z) I calculated: p(2 or more spades on flop) = 3(13/50 x 12/49) - 3((13/50 x 12/49) x 11/48) + (13/50 x 12/49 x 11/48) which gives 16.18% What I wanted to do next was solve the question using combinations. Through a process of trial and error I got the same answer, but am a bit confused as to why it works this way. My method was: 13C2 * 48 = 3744 3744 - (3 * 13C3) + 13C3 = 3172 total number possible 3 card combinations on flop = 50C3 = 19600 3172 / 19600 = 16.18% So I get the total number of 2 card combination of spades by 13C2 = 78. Then there are 48 other cards which can form combinations with each of these 2 card combination so 13C2 * 48. Now I'm losing my grasp of whats happening. Why does 13C2 = p(A) + p(B) + p(C)? All I have done to follow is find the number of combos for p(A∩B), p(A∩C), p(B∩C) and p(A∩B∩C) and then crunched the numbers as in the calculation shown above. But even though I (think I've) got the right answer, I've come to it in a try-it-and-see way and can't understand for instance why 13C2 * 48 doesn't give the right answer straight off. Surely that gives the number of 3 card combinations on the flop with 2 or more spades which is what I'm looking for, doesn't it? But I don't get the same answer as with the original calculation if I use that figure. Sorry for the waffle. I hope someone can see where my thinking is going wrong and can help explain the combinations part a bit better for me. Many thanks in advance.","I am trying to find the answer to the following question: If I am playing poker and am dealt two cards neither of which are spades, what are the chances of two or more of the flop cards (the flop is the first three community cards) being spades. I answered this question in the following way: As I have no spades, there are still 13 spades unseen and a total of 50 cards remaining unseen (52 cards in the pack less my two cards which I've been dealt. If the probability of the first flop card being a spade is p(A) and the second p(B) and the third p(C) then I need to find: p((A∩B)∪(A∩C)∪(B∩C)) so given the formula: p(X∪Y∪Z) = p(X) + p(Y) + p(Z) - p(X∩Y) - p(X∩Z) - p(Y∩Z) + p(X∩Y∩Z) I calculated: p(2 or more spades on flop) = 3(13/50 x 12/49) - 3((13/50 x 12/49) x 11/48) + (13/50 x 12/49 x 11/48) which gives 16.18% What I wanted to do next was solve the question using combinations. Through a process of trial and error I got the same answer, but am a bit confused as to why it works this way. My method was: 13C2 * 48 = 3744 3744 - (3 * 13C3) + 13C3 = 3172 total number possible 3 card combinations on flop = 50C3 = 19600 3172 / 19600 = 16.18% So I get the total number of 2 card combination of spades by 13C2 = 78. Then there are 48 other cards which can form combinations with each of these 2 card combination so 13C2 * 48. Now I'm losing my grasp of whats happening. Why does 13C2 = p(A) + p(B) + p(C)? All I have done to follow is find the number of combos for p(A∩B), p(A∩C), p(B∩C) and p(A∩B∩C) and then crunched the numbers as in the calculation shown above. But even though I (think I've) got the right answer, I've come to it in a try-it-and-see way and can't understand for instance why 13C2 * 48 doesn't give the right answer straight off. Surely that gives the number of 3 card combinations on the flop with 2 or more spades which is what I'm looking for, doesn't it? But I don't get the same answer as with the original calculation if I use that figure. Sorry for the waffle. I hope someone can see where my thinking is going wrong and can help explain the combinations part a bit better for me. Many thanks in advance.",,"['combinatorics', 'probability']"
95,If $(X_n)$ is a martingale is $X_n+Y$ a martingale for deterministic $Y$,If  is a martingale is  a martingale for deterministic,(X_n) X_n+Y Y,"If $(X_n)$ is a martingale (with respect to the filtration $\mathcal{A}_n = \sigma(X_0,...,X_n)$ ) is $X_n+Y$ a martingale (with respect to the filtration $\mathcal{F}_n := \sigma(X_0+Y,...,X_n+Y)$ ) for a deterministic $Y$ (meaning $Y$ is a.s. constant). For constant $Y$ (i.e. $Y=a$ ) this is obviously true. However, since $Y$ is a.s. constant we cannot conclude that $\mathcal{A}_n = \mathcal{F}_n$ and thus cannot conclude that $E[X_{n+1} \mid \mathcal{F}_n] = X_n$ . Does the above even hold for $Y$ a.s. constant or do we need $Y$ to be constant? Any help would be appreciated.","If is a martingale (with respect to the filtration ) is a martingale (with respect to the filtration ) for a deterministic (meaning is a.s. constant). For constant (i.e. ) this is obviously true. However, since is a.s. constant we cannot conclude that and thus cannot conclude that . Does the above even hold for a.s. constant or do we need to be constant? Any help would be appreciated.","(X_n) \mathcal{A}_n = \sigma(X_0,...,X_n) X_n+Y \mathcal{F}_n := \sigma(X_0+Y,...,X_n+Y) Y Y Y Y=a Y \mathcal{A}_n = \mathcal{F}_n E[X_{n+1} \mid \mathcal{F}_n] = X_n Y Y","['probability', 'probability-theory', 'conditional-expectation']"
96,Can this integral equation be solved?,Can this integral equation be solved?,,"I am trying to find out the Stationary Distribution of a Continuous State Space Markov Chain. For example, consider a Gaussian Transition Kernel that describes the probability of moving from point $x$ to $x'$ : $$T(x, x') \sim N(x, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x'-x)^2}{2\sigma^2}}$$ I am interested in determining what is the Stationary Distribution for this process. I know that to determine the Stationary Distribution for this problem, we have to find a distribution $\pi(x)$ such that the following relationship holds (Detailed Balance Condition, also called the Reversibility Condition): $$\int T(x, x')\pi(x)dx = \pi(x'), \quad \forall x'$$ Is it possible to solve the above equation for $\pi(x)$ ? I know that in the context of Discrete Time and Discrete State Space Markov Chains, we can find the Stationary Distribution $\pi$ by solving the following equation: $$\pi = P \cdot \pi$$ However, I am not sure how to solve the equivalent equation for the Continuous State Space version. Here is what I tried so far. 1) Intuition When dealing with functions of the Gaussian Distribution, properties of the Gaussian Functions tend to also be Gaussian. This makes me believe that if the Stationary Distribution exists, it also Gaussian. I know that the Gaussian Distribution is symmetric around the mean ( Proof that the gaussian distribution is ""symmetric"". ), i.e. $f(x) = f(-x)$ . This means: $$f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}} = f(-x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(-x-\mu)^2}{2\sigma^2}}$$ I thought of the following way to show this: If the Gaussian Distribution is symmetric around the mean point $\mu$ , this means that any two points $x_1$ and $x_2$ that are equidistant from $\mu$ will have the following properties: $$x_1 - \mu = \mu - x_2$$ $$\mu = \frac{x_1 +x_2}{2}$$ $$f(x_1) = f(x_2)$$ $$f(\mu + \Delta) = f(\mu - \Delta)$$ Symmetry using this condition implies that: $$ \exp\left[ - \frac{1}{2}\left(\frac{x_1 - \mu}{\sigma}\right)^2\right] = \exp\left[-\frac{1}{2}\left(\frac{x_2 - \mu}{\sigma}\right)^2\right] $$ Looking at the LHS, we see: $$ \exp\left[-\frac{1}{2}\left(\frac{x_1 - \frac{{x_1 + x_2}}{2}}{\sigma}\right)^2\right] =  \exp\left[-\frac{1}{2}\left(\frac{\frac{2x_1 - (x_1 + x_2)}{2}}{\sigma}\right)^2\right] = \exp\left[-\frac{1}{2}\left(\frac{\frac{x_1 - x_2)}{2}}{\sigma}\right)^2\right] = \exp\left[-\frac{1}{2}\left( \frac{   {x_1 - x_2)}}   {2\cdot\sigma}\right)^2\right]$$ Now, the same is true for the RHS: $$ \exp\left[-\frac{1}{2}\left(\frac{x_2 - \frac{{x_1 + x_2}}{2}}{\sigma}\right)^2\right] =  \exp\left[-\frac{1}{2}\left(\frac{\frac{2x_2 - (x_1 + x_2)}{2}}{\sigma}\right)^2\right] = \exp\left[-\frac{1}{2}\left(\frac{\frac{x_1 - x_2)}{2}}{\sigma}\right)^2\right] = \exp\left[-\frac{1}{2}\left( \frac{   {x_1 - x_2)}}   {2\cdot\sigma}\right)^2\right]$$ Thus, we can see that LHS = RHS and that the Gaussian Distribution is symmetric around the mean. Going back to the Detailed Balance Condition, we can see that: $$\pi(x)T(x, x') = \pi(x')T(x', x)$$ Thus, if we assume that $\pi(x)$ is a Gaussian, we can write: $$\frac{1}{\sqrt{2\pi\mu^2}}e^{-\frac{(x-\mu)^2}{2\mu^2}} \cdot \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x'-x)^2}{2\sigma^2}} = \frac{1}{\sqrt{2\pi\mu^2}}e^{-\frac{(x'-\mu)^2}{2\mu^2}} \cdot \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-x')^2}{2\sigma^2}}$$ Using the fact that the Gaussian distribution is symmetric, i.e $e^{-\frac{(x'-x)^2}{2\sigma^2}} = e^{-\frac{(x-x')^2}{2\sigma^2}}$ , we can write: $$\frac{1}{\sqrt{2\pi\mu^2}}e^{-\frac{(x-\mu)^2}{2\mu^2}} = \frac{1}{\sqrt{2\pi\mu^2}}e^{-\frac{(x'-\mu)^2}{2\mu^2}}$$ Thus, based on the assumption that $\pi(x)$ is Gaussian, we can show that $\pi(x)$ satisfies the Detailed Balance Condition and is a Stationary Distribution: $$\int T(x, x')\pi(x)dx = \pi(x'), \quad \forall x'$$ Substituting the Gaussian transition kernel $T(x, x')$ and assume $\pi(x)$ is a Gaussian distribution, we get: $$\int \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x'-x)^2}{2\sigma^2}} \cdot \frac{1}{\sqrt{2\pi\mu^2}}e^{-\frac{(x-\mu)^2}{2\mu^2}} dx = \frac{1}{\sqrt{2\pi\mu^2}}e^{-\frac{(x'-\mu)^2}{2\mu^2}}, \quad \forall x'$$ $$\frac{1}{\sqrt{2\pi\mu^2}}e^{-\frac{(x'-\mu)^2}{2\mu^2}} = \frac{1}{\sqrt{2\pi\mu^2}}e^{-\frac{(x'-\mu)^2}{2\mu^2}}, \quad \forall x'$$ But this still has not been proved in my opinion. 2) Computer Simulation I tried to write a computer simulation in R (Programming Language) that simulates random draws from this Transition Kernel and then uses the Kolmogorov-Smirnov test statistic to compare the EDF (empirical distribution function) to the theoretical CDF (cumulative distribution function) of a Normal Distribution. In my opinion, this might be able to show that the Stationary Distribution of this Transition Kernel is Gaussian. library(ggplot2) library(gridExtra)   #parameters of the Gaussian transition kernel mu <- 0 sigma <- 1  # total number of simulations (n) and burn-in observations (m) n <- 1000 m <- 100     chain <- numeric(n)   chain[1] <- rnorm(1, mean = mu, sd = sigma)  #arkov chain for (i in 2:n) {     chain[i] <- rnorm(1, mean = chain[i - 1], sd = sigma) }   df <- data.frame(Value = chain, Time = 1:n)  # indicator variable for before/after burn-in df $Period <- ifelse(df$ Time <= m, ""Before Burn-in"", ""After Burn-in"") df1 = df[df$Period == ""After Burn-in"",]  # trajectory of the Markov chain  p1 <- ggplot(df, aes(x = Time, y = Value)) +     geom_line(aes(color = Period)) +     geom_vline(xintercept = m, linetype = ""dashed"", color = ""gray"") +  # Add burn-in line     labs(         title = paste(""Trajectory of the Markov Chain ("", n, "" simulations)"", sep = """"),         subtitle = paste(""Estimated Mean (μ) after Burn-in:"", round(mean(chain_burned), 3),                          ""\nEstimated SD (σ) after Burn-in:"", round(sd(chain_burned), 3)),         x = ""Time"",         y = ""State""     ) +     theme_minimal() +     scale_color_manual(name = ""Legend"", values = c(""Before Burn-in"" = ""blue"", ""After Burn-in"" = ""red""))  # histogram p2 <- ggplot(df1, aes(x = Value)) +     geom_histogram(aes(y = ..density.., fill = ""Histogram""), bins = 50, alpha = 0.5) +     stat_function(         fun = dnorm,         args = list(mean = mean(chain_burned), sd = sd(chain_burned)),         aes(color = ""Gaussian Density""),         size = 1     ) +     labs(         title = paste(""Estimated Stationary Distribution ("", n, "" simulations)"", sep = """"),         subtitle = paste(""Estimated Mean (μ) after Burn-in:"", round(mean(chain_burned), 3),                          ""\nEstimated SD (σ) after Burn-in:"", round(sd(chain_burned), 3)),         x = ""State"",         y = ""Density""     ) +     theme_minimal() +     scale_fill_manual(name = ""Legend"", values = c(""Histogram"" = ""skyblue"")) +     scale_color_manual(name = ""Legend"", values = c(""Gaussian Density"" = ""red""))  #Kolmogorov-Smirnov statistic ks_result <- ks.test(chain_burned, ""pnorm"", mean = mean(chain_burned), sd = sd(chain_burned))  # EDF vs. CDF plot  p3 <- ggplot(df1, aes(x = Value)) +     stat_ecdf(aes(color = ""EDF"")) +     stat_function(         fun = pnorm,         args = list(mean = mean(chain_burned), sd = sd(chain_burned)),         aes(color = ""CDF""),         linetype = ""dashed"",         size = 1     ) +     labs(         title = paste(             ""EDF of Observed Data vs. CDF of Normal Distribution ("",             n,             "" simulations, KS Statistic:"",             round(ks_result $statistic, 3),             "", p-value:"",             format(ks_result$ p.value, digits = 3),             "")"",             sep = """"         ),         subtitle = if (ks_result$p.value > 0.05) ""Conclusion: EDF is the same as CDF"" else ""Conclusion: EDF is different from CDF"",         x = ""State"",         y = ""Cumulative Probability""     ) +     theme_minimal() +     scale_color_manual(name = ""Legend"", values = c(""EDF"" = ""blue"", ""CDF"" = ""red""))   grid.arrange(p1, p2, p3, ncol=1) However, I am not still not sure if this counts as a proof In general, if we start with a Gaussian Transition Kernel, is it possible to derive the Stationary Distribution from first principles, i.e solve the following integral equation? $$T(x, x') \sim N(x, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x'-x)^2}{2\sigma^2}}$$ $$\int T(x, x')\pi(x)dx = \pi(x'), \quad \forall x'$$ $$\pi(x) \sim ???$$ Or unlike the Discrete State Space version, solving this equation for $\pi$ in the continuous state space version is simply not possible? Thanks!","I am trying to find out the Stationary Distribution of a Continuous State Space Markov Chain. For example, consider a Gaussian Transition Kernel that describes the probability of moving from point to : I am interested in determining what is the Stationary Distribution for this process. I know that to determine the Stationary Distribution for this problem, we have to find a distribution such that the following relationship holds (Detailed Balance Condition, also called the Reversibility Condition): Is it possible to solve the above equation for ? I know that in the context of Discrete Time and Discrete State Space Markov Chains, we can find the Stationary Distribution by solving the following equation: However, I am not sure how to solve the equivalent equation for the Continuous State Space version. Here is what I tried so far. 1) Intuition When dealing with functions of the Gaussian Distribution, properties of the Gaussian Functions tend to also be Gaussian. This makes me believe that if the Stationary Distribution exists, it also Gaussian. I know that the Gaussian Distribution is symmetric around the mean ( Proof that the gaussian distribution is ""symmetric"". ), i.e. . This means: I thought of the following way to show this: If the Gaussian Distribution is symmetric around the mean point , this means that any two points and that are equidistant from will have the following properties: Symmetry using this condition implies that: Looking at the LHS, we see: Now, the same is true for the RHS: Thus, we can see that LHS = RHS and that the Gaussian Distribution is symmetric around the mean. Going back to the Detailed Balance Condition, we can see that: Thus, if we assume that is a Gaussian, we can write: Using the fact that the Gaussian distribution is symmetric, i.e , we can write: Thus, based on the assumption that is Gaussian, we can show that satisfies the Detailed Balance Condition and is a Stationary Distribution: Substituting the Gaussian transition kernel and assume is a Gaussian distribution, we get: But this still has not been proved in my opinion. 2) Computer Simulation I tried to write a computer simulation in R (Programming Language) that simulates random draws from this Transition Kernel and then uses the Kolmogorov-Smirnov test statistic to compare the EDF (empirical distribution function) to the theoretical CDF (cumulative distribution function) of a Normal Distribution. In my opinion, this might be able to show that the Stationary Distribution of this Transition Kernel is Gaussian. library(ggplot2) library(gridExtra)   #parameters of the Gaussian transition kernel mu <- 0 sigma <- 1  # total number of simulations (n) and burn-in observations (m) n <- 1000 m <- 100     chain <- numeric(n)   chain[1] <- rnorm(1, mean = mu, sd = sigma)  #arkov chain for (i in 2:n) {     chain[i] <- rnorm(1, mean = chain[i - 1], sd = sigma) }   df <- data.frame(Value = chain, Time = 1:n)  # indicator variable for before/after burn-in df Time <= m, ""Before Burn-in"", ""After Burn-in"") df1 = df[df$Period == ""After Burn-in"",]  # trajectory of the Markov chain  p1 <- ggplot(df, aes(x = Time, y = Value)) +     geom_line(aes(color = Period)) +     geom_vline(xintercept = m, linetype = ""dashed"", color = ""gray"") +  # Add burn-in line     labs(         title = paste(""Trajectory of the Markov Chain ("", n, "" simulations)"", sep = """"),         subtitle = paste(""Estimated Mean (μ) after Burn-in:"", round(mean(chain_burned), 3),                          ""\nEstimated SD (σ) after Burn-in:"", round(sd(chain_burned), 3)),         x = ""Time"",         y = ""State""     ) +     theme_minimal() +     scale_color_manual(name = ""Legend"", values = c(""Before Burn-in"" = ""blue"", ""After Burn-in"" = ""red""))  # histogram p2 <- ggplot(df1, aes(x = Value)) +     geom_histogram(aes(y = ..density.., fill = ""Histogram""), bins = 50, alpha = 0.5) +     stat_function(         fun = dnorm,         args = list(mean = mean(chain_burned), sd = sd(chain_burned)),         aes(color = ""Gaussian Density""),         size = 1     ) +     labs(         title = paste(""Estimated Stationary Distribution ("", n, "" simulations)"", sep = """"),         subtitle = paste(""Estimated Mean (μ) after Burn-in:"", round(mean(chain_burned), 3),                          ""\nEstimated SD (σ) after Burn-in:"", round(sd(chain_burned), 3)),         x = ""State"",         y = ""Density""     ) +     theme_minimal() +     scale_fill_manual(name = ""Legend"", values = c(""Histogram"" = ""skyblue"")) +     scale_color_manual(name = ""Legend"", values = c(""Gaussian Density"" = ""red""))  #Kolmogorov-Smirnov statistic ks_result <- ks.test(chain_burned, ""pnorm"", mean = mean(chain_burned), sd = sd(chain_burned))  # EDF vs. CDF plot  p3 <- ggplot(df1, aes(x = Value)) +     stat_ecdf(aes(color = ""EDF"")) +     stat_function(         fun = pnorm,         args = list(mean = mean(chain_burned), sd = sd(chain_burned)),         aes(color = ""CDF""),         linetype = ""dashed"",         size = 1     ) +     labs(         title = paste(             ""EDF of Observed Data vs. CDF of Normal Distribution ("",             n,             "" simulations, KS Statistic:"",             round(ks_result p.value, digits = 3),             "")"",             sep = """"         ),         subtitle = if (ks_result$p.value > 0.05) ""Conclusion: EDF is the same as CDF"" else ""Conclusion: EDF is different from CDF"",         x = ""State"",         y = ""Cumulative Probability""     ) +     theme_minimal() +     scale_color_manual(name = ""Legend"", values = c(""EDF"" = ""blue"", ""CDF"" = ""red""))   grid.arrange(p1, p2, p3, ncol=1) However, I am not still not sure if this counts as a proof In general, if we start with a Gaussian Transition Kernel, is it possible to derive the Stationary Distribution from first principles, i.e solve the following integral equation? Or unlike the Discrete State Space version, solving this equation for in the continuous state space version is simply not possible? Thanks!","x x' T(x, x') \sim N(x, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x'-x)^2}{2\sigma^2}} \pi(x) \int T(x, x')\pi(x)dx = \pi(x'), \quad \forall x' \pi(x) \pi \pi = P \cdot \pi f(x) = f(-x) f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}} = f(-x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(-x-\mu)^2}{2\sigma^2}} \mu x_1 x_2 \mu x_1 - \mu = \mu - x_2 \mu = \frac{x_1 +x_2}{2} f(x_1) = f(x_2) f(\mu + \Delta) = f(\mu - \Delta)  \exp\left[ - \frac{1}{2}\left(\frac{x_1 - \mu}{\sigma}\right)^2\right] = \exp\left[-\frac{1}{2}\left(\frac{x_2 - \mu}{\sigma}\right)^2\right]   \exp\left[-\frac{1}{2}\left(\frac{x_1 - \frac{{x_1 + x_2}}{2}}{\sigma}\right)^2\right] =  \exp\left[-\frac{1}{2}\left(\frac{\frac{2x_1 - (x_1 + x_2)}{2}}{\sigma}\right)^2\right] = \exp\left[-\frac{1}{2}\left(\frac{\frac{x_1 - x_2)}{2}}{\sigma}\right)^2\right] = \exp\left[-\frac{1}{2}\left( \frac{ 
 {x_1 - x_2)}}   {2\cdot\sigma}\right)^2\right]  \exp\left[-\frac{1}{2}\left(\frac{x_2 - \frac{{x_1 + x_2}}{2}}{\sigma}\right)^2\right] =  \exp\left[-\frac{1}{2}\left(\frac{\frac{2x_2 - (x_1 + x_2)}{2}}{\sigma}\right)^2\right] = \exp\left[-\frac{1}{2}\left(\frac{\frac{x_1 - x_2)}{2}}{\sigma}\right)^2\right] = \exp\left[-\frac{1}{2}\left( \frac{ 
 {x_1 - x_2)}}   {2\cdot\sigma}\right)^2\right] \pi(x)T(x, x') = \pi(x')T(x', x) \pi(x) \frac{1}{\sqrt{2\pi\mu^2}}e^{-\frac{(x-\mu)^2}{2\mu^2}} \cdot \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x'-x)^2}{2\sigma^2}} = \frac{1}{\sqrt{2\pi\mu^2}}e^{-\frac{(x'-\mu)^2}{2\mu^2}} \cdot \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-x')^2}{2\sigma^2}} e^{-\frac{(x'-x)^2}{2\sigma^2}} = e^{-\frac{(x-x')^2}{2\sigma^2}} \frac{1}{\sqrt{2\pi\mu^2}}e^{-\frac{(x-\mu)^2}{2\mu^2}} = \frac{1}{\sqrt{2\pi\mu^2}}e^{-\frac{(x'-\mu)^2}{2\mu^2}} \pi(x) \pi(x) \int T(x, x')\pi(x)dx = \pi(x'), \quad \forall x' T(x, x') \pi(x) \int \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x'-x)^2}{2\sigma^2}} \cdot \frac{1}{\sqrt{2\pi\mu^2}}e^{-\frac{(x-\mu)^2}{2\mu^2}} dx = \frac{1}{\sqrt{2\pi\mu^2}}e^{-\frac{(x'-\mu)^2}{2\mu^2}}, \quad \forall x' \frac{1}{\sqrt{2\pi\mu^2}}e^{-\frac{(x'-\mu)^2}{2\mu^2}} = \frac{1}{\sqrt{2\pi\mu^2}}e^{-\frac{(x'-\mu)^2}{2\mu^2}}, \quad \forall x' Period <- ifelse(df statistic, 3),
            "", p-value:"",
            format(ks_result T(x, x') \sim N(x, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x'-x)^2}{2\sigma^2}} \int T(x, x')\pi(x)dx = \pi(x'), \quad \forall x' \pi(x) \sim ??? \pi","['probability', 'integration']"
97,Longest Increasing Subsequence Upper Bound,Longest Increasing Subsequence Upper Bound,,"Assume that the sequence $\{X_n\}$ are i.i.d with uniform distribution on $[0,1]$ . Now, define the length longest increasing subsequent as $$L_n=\max\{k:X_{i_1}<X_{i_2}<...<X_{i_k}, 1\leq i_1<i_2<...<i_k\leq n\}.$$ (1) Show that $\mathbb P[L_n\geq 2e\sqrt{n}]<\exp\{-2e\sqrt{n}\}$ (2) Show that for every $a>\frac{1}{3}$ there exists a constant b such that for all large $n$ we have: $$\mathbb P[|L_n-\mathbb E[L_n]|\geq n^a]\leq\exp\{-n^b\}.$$ My attempt : (1) It is not difficult to prove that the upper bound is $\mathbb P[L_n\geq k]\leq \begin{pmatrix}n\\ k\end{pmatrix}\cdot\frac{1}{k!}$ . However, I cannot connect this bound with the bound given in the question. (2) Using Azuma's inequality, I can prove that $$\mathbb P[|L_n-\mathbb E[L_n]|\geq t]\leq2\exp\bigg\{-\frac{t^2}{2n}\bigg\}.$$ Again, I don't know how to get rid of the coefficient 2 outside the exponential and also the coefficient 1/2 inside the exponential. If you have any suggestions, it would be greatly appreciated. Thank you!","Assume that the sequence are i.i.d with uniform distribution on . Now, define the length longest increasing subsequent as (1) Show that (2) Show that for every there exists a constant b such that for all large we have: My attempt : (1) It is not difficult to prove that the upper bound is . However, I cannot connect this bound with the bound given in the question. (2) Using Azuma's inequality, I can prove that Again, I don't know how to get rid of the coefficient 2 outside the exponential and also the coefficient 1/2 inside the exponential. If you have any suggestions, it would be greatly appreciated. Thank you!","\{X_n\} [0,1] L_n=\max\{k:X_{i_1}<X_{i_2}<...<X_{i_k}, 1\leq i_1<i_2<...<i_k\leq n\}. \mathbb P[L_n\geq 2e\sqrt{n}]<\exp\{-2e\sqrt{n}\} a>\frac{1}{3} n \mathbb P[|L_n-\mathbb E[L_n]|\geq n^a]\leq\exp\{-n^b\}. \mathbb P[L_n\geq k]\leq \begin{pmatrix}n\\ k\end{pmatrix}\cdot\frac{1}{k!} \mathbb P[|L_n-\mathbb E[L_n]|\geq t]\leq2\exp\bigg\{-\frac{t^2}{2n}\bigg\}.","['probability', 'sequences-and-series', 'probability-theory', 'inequality', 'stochastic-processes']"
98,"How can I show that the first exit time by a planar Brownian motion is a.s. finite, i.e. $\mathbb{P}_z(\tau_D<\infty)=1$?","How can I show that the first exit time by a planar Brownian motion is a.s. finite, i.e. ?",\mathbb{P}_z(\tau_D<\infty)=1,"I have found the following interesting proposition on planar Brownian motions, but I don't really understand the proof. Let $D$ be a proper simply connected domain and $z\in D$ . Let $B$ be a complex valued Brownian motion starting from $z$ . Then $\mathbb{P}_z(\tau_D<\infty)=1$ where $\tau_D:=\inf\{t\geq 0: B_t\notin D\}$ They have given the following proof: By the Riemann mapping theorem there exists a conformal isomorphism $f:D\rightarrow \mathbb{D}$ . By the conformal invariance theorem there exists a time change $\sigma(t)$ such that $W_t:=f(B_{\sigma(t)})$ is a complex Brownian motion for $t<\tau_{f(D)}=\inf\{t\geq 0: W_t\notin f(D)\}=\inf\{t\geq 0: B_{\sigma(t)}\notin D\}$ . Hence if $t\rightarrow \tau_{f(D)}$ then eventually $|W_t|\geq 1/2$ . But $B$ is neighbourhood recurrent by a previous corollary, so it visits the open set $\{z\in D: |z|<1/2\}=f^{-1}(\{|z|<1/2\})$ at an unbounded set of times a.s. Hence $\tau_D<\infty$ a.s. My first question is, where do i need that $W_t$ is a complex Brownian motion, I mean why can't I only work with $B_t$ instead of $W$ ? Futhermore how does they conclude that $\tau_D<\infty$ ? I thouth about if I can show that $\tau_{f(D)}<\infty$ then $\tau_D$ needs to be finite a.s. since there is only  a time change in the game. Can someone explain me this proof or help me how to proof it similarly. I know the conformal invariance theorem and that a complex Brownian motion is neighbourhood recurrent.","I have found the following interesting proposition on planar Brownian motions, but I don't really understand the proof. Let be a proper simply connected domain and . Let be a complex valued Brownian motion starting from . Then where They have given the following proof: By the Riemann mapping theorem there exists a conformal isomorphism . By the conformal invariance theorem there exists a time change such that is a complex Brownian motion for . Hence if then eventually . But is neighbourhood recurrent by a previous corollary, so it visits the open set at an unbounded set of times a.s. Hence a.s. My first question is, where do i need that is a complex Brownian motion, I mean why can't I only work with instead of ? Futhermore how does they conclude that ? I thouth about if I can show that then needs to be finite a.s. since there is only  a time change in the game. Can someone explain me this proof or help me how to proof it similarly. I know the conformal invariance theorem and that a complex Brownian motion is neighbourhood recurrent.",D z\in D B z \mathbb{P}_z(\tau_D<\infty)=1 \tau_D:=\inf\{t\geq 0: B_t\notin D\} f:D\rightarrow \mathbb{D} \sigma(t) W_t:=f(B_{\sigma(t)}) t<\tau_{f(D)}=\inf\{t\geq 0: W_t\notin f(D)\}=\inf\{t\geq 0: B_{\sigma(t)}\notin D\} t\rightarrow \tau_{f(D)} |W_t|\geq 1/2 B \{z\in D: |z|<1/2\}=f^{-1}(\{|z|<1/2\}) \tau_D<\infty W_t B_t W \tau_D<\infty \tau_{f(D)}<\infty \tau_D,"['probability', 'complex-analysis', 'probability-theory', 'stochastic-processes', 'brownian-motion']"
99,Floor of a random variable with bounded density,Floor of a random variable with bounded density,,"Let $X$ be a random variable on $\mathbb R^+$ with bounded density, and let $\lfloor \cdot \rfloor$ denote the floor function. Show that for $\lambda\in \mathbb R^+$ , $$\lim_{\lambda\to\infty} \mathbb P(\lfloor \lambda X\rfloor \mbox{ is even}) = \frac{1}2.$$ The statement makes intuitive sense to me, but I don't know how to show it. I created this simple example to better understand a problem I'm working on where space is partitioned into equivalence classes, (odd / even, in the case of the example) ""uniformly"" spread out over the space, and fine with respect to the extent of the bounded density. If alternative assumptions on $X$ can be used, I would be curious to hear suggestions.","Let be a random variable on with bounded density, and let denote the floor function. Show that for , The statement makes intuitive sense to me, but I don't know how to show it. I created this simple example to better understand a problem I'm working on where space is partitioned into equivalence classes, (odd / even, in the case of the example) ""uniformly"" spread out over the space, and fine with respect to the extent of the bounded density. If alternative assumptions on can be used, I would be curious to hear suggestions.",X \mathbb R^+ \lfloor \cdot \rfloor \lambda\in \mathbb R^+ \lim_{\lambda\to\infty} \mathbb P(\lfloor \lambda X\rfloor \mbox{ is even}) = \frac{1}2. X,"['probability', 'random-variables']"
