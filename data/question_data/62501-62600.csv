,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,What's the explicit formula for Permutations of Subsets of a Multiset? [duplicate],What's the explicit formula for Permutations of Subsets of a Multiset? [duplicate],,"This question already has answers here : How to find the number of $k$-permutations of $n$ objects with $x$ types, and $r_1, r_2, r_3, \cdots , r_x$ = the number of each type of object? (4 answers) Closed last year . What is the number of permutations of subsets of the multiset $S$ with cardinality $n$ ? A sample problem would be to find the number of ways you can construct ""words"" with three of the letters in the set $\{G,R,E,E,N\}$ . I've looked everywhere and found two identical posts by the same person on MSE and on MO , but no formula was posted. Such formula exists for sets with distinct elements, $P(n,r)$ . The number of permutations of a multiset also exists as the multinomial coefficient. But there seems to be no way to compute the number of permutations of subsets of a multiset given the cardinality, other than going case by case and using logic. I've heard that generating functions can be used to solve such problems (as was written in Maple's help files) but I'm looking for a general solution using combinatorics, although a generating functions solution would be cool too (I have yet to learn generating functions). I played around with this last week, and found a formula when the multiset only contains one element that is duplicated. Let's suppose the number of duplicates is $E$ , the cardinality of the multiset $S$ is $n$ , and that the cardinality of the subsets desired is $P$ . Then, the number of permutations is $$\sum_{k=0}^{E}\binom{P}{k}P(n-E,P-k)$$ This formula only works when $n\geq E+P$ and even then it might not work, and I didn't know how to proceed. Suresh Venkat suggested to sum multinomial coefficients , but I don't understand his reasoning. I originally posted this on MathOverflow , now deleted.","This question already has answers here : How to find the number of $k$-permutations of $n$ objects with $x$ types, and $r_1, r_2, r_3, \cdots , r_x$ = the number of each type of object? (4 answers) Closed last year . What is the number of permutations of subsets of the multiset with cardinality ? A sample problem would be to find the number of ways you can construct ""words"" with three of the letters in the set . I've looked everywhere and found two identical posts by the same person on MSE and on MO , but no formula was posted. Such formula exists for sets with distinct elements, . The number of permutations of a multiset also exists as the multinomial coefficient. But there seems to be no way to compute the number of permutations of subsets of a multiset given the cardinality, other than going case by case and using logic. I've heard that generating functions can be used to solve such problems (as was written in Maple's help files) but I'm looking for a general solution using combinatorics, although a generating functions solution would be cool too (I have yet to learn generating functions). I played around with this last week, and found a formula when the multiset only contains one element that is duplicated. Let's suppose the number of duplicates is , the cardinality of the multiset is , and that the cardinality of the subsets desired is . Then, the number of permutations is This formula only works when and even then it might not work, and I didn't know how to proceed. Suresh Venkat suggested to sum multinomial coefficients , but I don't understand his reasoning. I originally posted this on MathOverflow , now deleted.","S n \{G,R,E,E,N\} P(n,r) E S n P \sum_{k=0}^{E}\binom{P}{k}P(n-E,P-k) n\geq E+P","['combinatorics', 'multisets']"
1,A nicer recurrence for the Eulerian polynomials.,A nicer recurrence for the Eulerian polynomials.,,"I was perusing the subject of Eulerian polynomials. I'm assuming the definition that the Eulerian polynomial is defined by $C_n(t)=\sum_{\pi\in S_n}t^{1+d(\pi)}$, where $d(\pi)$ is the number of descents. The Eulerian polynomials satisfy a standard recurrence $C_n(t)=t(1-t)C'_{n-1}(t)+ntC_{n-1}(t)$. Apparently they also satisfy the more aesthetically pleasing relation $$ C_n(t)=tC'_{n-1}(t)+t^nC'_{n-1}(t^{-1}). $$ The generating function in $t^{-1}$ is troublesome to me. How can one derive this other recurrence relation? Thank you,","I was perusing the subject of Eulerian polynomials. I'm assuming the definition that the Eulerian polynomial is defined by $C_n(t)=\sum_{\pi\in S_n}t^{1+d(\pi)}$, where $d(\pi)$ is the number of descents. The Eulerian polynomials satisfy a standard recurrence $C_n(t)=t(1-t)C'_{n-1}(t)+ntC_{n-1}(t)$. Apparently they also satisfy the more aesthetically pleasing relation $$ C_n(t)=tC'_{n-1}(t)+t^nC'_{n-1}(t^{-1}). $$ The generating function in $t^{-1}$ is troublesome to me. How can one derive this other recurrence relation? Thank you,",,"['combinatorics', 'polynomials', 'recurrence-relations', 'generating-functions', 'eulerian-numbers']"
2,Density of black cells in rule 110,Density of black cells in rule 110,,"Is there a way to compute the limit of the ratio (number of black cells)/(number of white cells), in the rule 110 or rule 30 automaton? With initial state = 1 black cell. Simulation of first 120000 rows shows a quite stable total density of 0.592..., and row-density 0.592... Here is average density of some consecutive columns of height some thousands: How to explain the apparent periodicity? These are quite clearly converging, how to calculate the exact values? (0.62499..==5/8 ??) 0.6249983636387438, 0.5937438636452892, 0.5312544999934545, 0.5937569545353388, 0.624991818193719, 0.6249983636387438, 0.5937569545353388, 0.5312414091034049, 0.5937438636452892, 0.6250049090837686, 0.6249983636387438, 0.5937504090903141, 0.5312479545484298, 0.5937373182002644, 0.624991818193719, 0.6250049090837686, 0.5937569545353388, 0.5312479545484298, 0.5937438636452892, 0.6250049090837686, 0.6250114545287934, 0.5937504090903141, 0.5312479545484298, 0.5937504090903141, 0.6249983636387438, 0.6250114545287934, 0.5937504090903141, 0.5312414091034049, 0.5937634999803637, 0.6250114545287934, 0.6249983636387438, 0.5937438636452892","Is there a way to compute the limit of the ratio (number of black cells)/(number of white cells), in the rule 110 or rule 30 automaton? With initial state = 1 black cell. Simulation of first 120000 rows shows a quite stable total density of 0.592..., and row-density 0.592... Here is average density of some consecutive columns of height some thousands: How to explain the apparent periodicity? These are quite clearly converging, how to calculate the exact values? (0.62499..==5/8 ??) 0.6249983636387438, 0.5937438636452892, 0.5312544999934545, 0.5937569545353388, 0.624991818193719, 0.6249983636387438, 0.5937569545353388, 0.5312414091034049, 0.5937438636452892, 0.6250049090837686, 0.6249983636387438, 0.5937504090903141, 0.5312479545484298, 0.5937373182002644, 0.624991818193719, 0.6250049090837686, 0.5937569545353388, 0.5312479545484298, 0.5937438636452892, 0.6250049090837686, 0.6250114545287934, 0.5937504090903141, 0.5312479545484298, 0.5937504090903141, 0.6249983636387438, 0.6250114545287934, 0.5937504090903141, 0.5312414091034049, 0.5937634999803637, 0.6250114545287934, 0.6249983636387438, 0.5937438636452892",,"['combinatorics', 'algorithms', 'recreational-mathematics', 'automata']"
3,"pigeonhole principle: at least 1 match/hr for 75 hrs, at most 125 matches, then exactly 24 matches in some interval","pigeonhole principle: at least 1 match/hr for 75 hrs, at most 125 matches, then exactly 24 matches in some interval",,"This is for self-study. This question is from Rosen's ""Discrete Mathematics And Its Applications"", 6th edition. An arm wrestler is the champion for a period of 75 hours. (Here, by an hour, we mean a period starting from an exact hour, such as 1 P.M., until the next hour.) The arm wrestler had at least one match an hour, but no more than 125 total matches. 1 - Show that there is a period of consecutive hours during which the arm wrestler had exactly 24 matches. 2 - Is the statement in the previous exercise true if 24 is replaced by a) 2? b) 23? c) 25? d) 30? My solution to part 1 is the following, based on Rosen's solution to a similar problem given as example in the text: 1 - If I consider $a_i$ to be the number of competitions until the $i^{th}$ hour, then, $1\leq a_1<a_2<\cdots<a_{75}\leq 125$, because there are no more than 75 hours and the total number of competitions is no more than 125. Now I will add 24 to all the terms of the above inequality: $25\leq a_1+24<a_2+24<\cdots<a_{75}+24\leq 149$. There are 150 numbers $a_1,\cdots,a_{75},a_1+24,\cdots,a_{75}+24$. By the inequalities above, these numbers range from 1 to 149. Then, by the pigeonhole principle, at least two of them are equal (in a list of 150 integers ranging from 1 to 149, at least two are equal). Because all the numbers $a_1,\cdots,a_{75}$ are distinct, and all numbers $a_1+24,\cdots,a_{75}+24$ are also distinct, it follows that $a_i = a_j + 24$ for some $i > j$. Therefore, from the $(j+1)^{th}$ hour to the $i^{th}$ hour, there were exactly 24 competitions. Now, I will show the attempt at a solution for part 2: 2 - a) The same reasoning as above can be used: $1\leq a_1<a_2<\cdots<a_{75}\leq 125$. Adding 2 to all terms: $3\leq a_1 + 2<a_2 + 2<\cdots<a_{75} + 2\leq 127$ So, there are 150 numbers that range from 1 to 127. Therefore, by the pigeonhole principle, at least $\left \lceil \frac{150}{127} \right \rceil$ = 2 numbers must be equal. So, there is an $a_i = a_j + 2$. This guarantees that there is a period of consecutive hours during which there were exactly 2 competitions. b) The same reasoning as above can be used: $1\leq a_1<a_2<\cdots<a_{75}\leq 125$. Adding 23 to all terms: $24\leq a_1 + 23<a_2 + 23<\cdots<a_{75} + 23\leq 148$ So, there are 150 numbers that range from 1 to 148. Therefore, by the pigeonhole principle, at least $\left \lceil \frac{150}{148} \right \rceil$ = 2 numbers must be equal. So, there is an $a_i = a_j + 23$. This guarantees that there is a period of consecutive hours during which there were exactly 23 competitions. c) $1\leq a_1<a_2<\cdots<a_{75}\leq 125$. Adding 25 to all terms: $26\leq a_1 + 25<a_2 + 25<\cdots<a_{75} + 25\leq 150$ In this case, there are 150 numbers that range from 1 to 150. So, there are not necessarily two equal numbers. Therefore, we can't conclude anything directly. But it is possible to show that the statement is not true for 25, because an explicit counter-example (suggested below in the comments) can be found. Suppose the number of matches until each one of the 75 hours is, respectively: $\{1,2,\cdots,25,51,\cdots,75,101,\cdots,125\}$. Here, there are no pairs of numbers whose difference is 25. d) $1\leq a_1<a_2<\cdots<a_{75}\leq 125$. Adding 30 to all terms: $31\leq a_1 + 30<a_2 + 30<\cdots<a_{75} + 30\leq 155$ In this case, there are 150 numbers that range from 1 to 155. So, we can't apply the pigeonhole principle here, similarly to the above situation. It is not easy to find a counter-example in this case; I think that, for 30, the statement is always true (that is, there is always a period of consecutive hours during which there were exactly 30 matches). But I'm not sure how to prove it. Edit : I think I found a way to prove it, based on the suggestion given by Lopsy; I've included it as an answer to this question. Thank you in advance.","This is for self-study. This question is from Rosen's ""Discrete Mathematics And Its Applications"", 6th edition. An arm wrestler is the champion for a period of 75 hours. (Here, by an hour, we mean a period starting from an exact hour, such as 1 P.M., until the next hour.) The arm wrestler had at least one match an hour, but no more than 125 total matches. 1 - Show that there is a period of consecutive hours during which the arm wrestler had exactly 24 matches. 2 - Is the statement in the previous exercise true if 24 is replaced by a) 2? b) 23? c) 25? d) 30? My solution to part 1 is the following, based on Rosen's solution to a similar problem given as example in the text: 1 - If I consider $a_i$ to be the number of competitions until the $i^{th}$ hour, then, $1\leq a_1<a_2<\cdots<a_{75}\leq 125$, because there are no more than 75 hours and the total number of competitions is no more than 125. Now I will add 24 to all the terms of the above inequality: $25\leq a_1+24<a_2+24<\cdots<a_{75}+24\leq 149$. There are 150 numbers $a_1,\cdots,a_{75},a_1+24,\cdots,a_{75}+24$. By the inequalities above, these numbers range from 1 to 149. Then, by the pigeonhole principle, at least two of them are equal (in a list of 150 integers ranging from 1 to 149, at least two are equal). Because all the numbers $a_1,\cdots,a_{75}$ are distinct, and all numbers $a_1+24,\cdots,a_{75}+24$ are also distinct, it follows that $a_i = a_j + 24$ for some $i > j$. Therefore, from the $(j+1)^{th}$ hour to the $i^{th}$ hour, there were exactly 24 competitions. Now, I will show the attempt at a solution for part 2: 2 - a) The same reasoning as above can be used: $1\leq a_1<a_2<\cdots<a_{75}\leq 125$. Adding 2 to all terms: $3\leq a_1 + 2<a_2 + 2<\cdots<a_{75} + 2\leq 127$ So, there are 150 numbers that range from 1 to 127. Therefore, by the pigeonhole principle, at least $\left \lceil \frac{150}{127} \right \rceil$ = 2 numbers must be equal. So, there is an $a_i = a_j + 2$. This guarantees that there is a period of consecutive hours during which there were exactly 2 competitions. b) The same reasoning as above can be used: $1\leq a_1<a_2<\cdots<a_{75}\leq 125$. Adding 23 to all terms: $24\leq a_1 + 23<a_2 + 23<\cdots<a_{75} + 23\leq 148$ So, there are 150 numbers that range from 1 to 148. Therefore, by the pigeonhole principle, at least $\left \lceil \frac{150}{148} \right \rceil$ = 2 numbers must be equal. So, there is an $a_i = a_j + 23$. This guarantees that there is a period of consecutive hours during which there were exactly 23 competitions. c) $1\leq a_1<a_2<\cdots<a_{75}\leq 125$. Adding 25 to all terms: $26\leq a_1 + 25<a_2 + 25<\cdots<a_{75} + 25\leq 150$ In this case, there are 150 numbers that range from 1 to 150. So, there are not necessarily two equal numbers. Therefore, we can't conclude anything directly. But it is possible to show that the statement is not true for 25, because an explicit counter-example (suggested below in the comments) can be found. Suppose the number of matches until each one of the 75 hours is, respectively: $\{1,2,\cdots,25,51,\cdots,75,101,\cdots,125\}$. Here, there are no pairs of numbers whose difference is 25. d) $1\leq a_1<a_2<\cdots<a_{75}\leq 125$. Adding 30 to all terms: $31\leq a_1 + 30<a_2 + 30<\cdots<a_{75} + 30\leq 155$ In this case, there are 150 numbers that range from 1 to 155. So, we can't apply the pigeonhole principle here, similarly to the above situation. It is not easy to find a counter-example in this case; I think that, for 30, the statement is always true (that is, there is always a period of consecutive hours during which there were exactly 30 matches). But I'm not sure how to prove it. Edit : I think I found a way to prove it, based on the suggestion given by Lopsy; I've included it as an answer to this question. Thank you in advance.",,"['combinatorics', 'discrete-mathematics', 'pigeonhole-principle']"
4,How to check if a polytope is a smooth Fano polytope?,How to check if a polytope is a smooth Fano polytope?,,"Question : We say that a convex lattice polytope $P\subset \mathbb{R}^d$ is a smooth Fano polytope if: The origin is contained in the interior of $P$ The vertices of every facet of $P$ are a $\mathbb{Z}$-basis of $\mathbb{Z}^d$ Now, suppose we have a set $V=\{v_1,\ldots,v_n\}\subset \mathbb{Z}^d$. What is an (preferentially efficient) algorithm for deciding if the convex hull $\text{conv}(V)$ is a smooth Fano polytope? Motivation : I've read a paper that gives an algorithm to classify all smooth Fano polytopes given the dimension $d$ as input ( An algorithm for the classification of smooth Fano polytopes by Mikkel Øbro), and while trying to implement said algorithm I discovered I don't know how to solve this question. For those who are curious, I want to use the algorithm to help me gain some intuition about toric varieties, and use  it to compute known invariants and test conjectures.","Question : We say that a convex lattice polytope $P\subset \mathbb{R}^d$ is a smooth Fano polytope if: The origin is contained in the interior of $P$ The vertices of every facet of $P$ are a $\mathbb{Z}$-basis of $\mathbb{Z}^d$ Now, suppose we have a set $V=\{v_1,\ldots,v_n\}\subset \mathbb{Z}^d$. What is an (preferentially efficient) algorithm for deciding if the convex hull $\text{conv}(V)$ is a smooth Fano polytope? Motivation : I've read a paper that gives an algorithm to classify all smooth Fano polytopes given the dimension $d$ as input ( An algorithm for the classification of smooth Fano polytopes by Mikkel Øbro), and while trying to implement said algorithm I discovered I don't know how to solve this question. For those who are curious, I want to use the algorithm to help me gain some intuition about toric varieties, and use  it to compute known invariants and test conjectures.",,"['geometry', 'combinatorics', 'algorithms', 'computational-geometry']"
5,Does every Latin square contain a diagonal in which no symbol appears thrice?,Does every Latin square contain a diagonal in which no symbol appears thrice?,,"A diagonal of a Latin square is a selection of n entries in which no two entries occur in the same row or column.  For example: the entries marked with an asterisk below form a diagonal. 1  2* 3  4 2  3  4  1* 3  4  1* 2 4* 1  2  3 Theorem :  Every Latin square contains a diagonal in which no symbol appears thrice (or more). The asterisked diagonal in the above example is a diagonal in which no symbol appears thrice. Problem : Prove the above theorem. This is quite a fun problem to solve, but there is a trap.","A diagonal of a Latin square is a selection of n entries in which no two entries occur in the same row or column.  For example: the entries marked with an asterisk below form a diagonal. 1  2* 3  4 2  3  4  1* 3  4  1* 2 4* 1  2  3 Theorem :  Every Latin square contains a diagonal in which no symbol appears thrice (or more). The asterisked diagonal in the above example is a diagonal in which no symbol appears thrice. Problem : Prove the above theorem. This is quite a fun problem to solve, but there is a trap.",,"['combinatorics', 'latin-square']"
6,Compute the largest natural number $n$ such that $2^n$ divides $S=\binom{2}{1}+\binom{4}{2}+\binom{8}{4}+\cdots+\binom{2^{100}}{2^{99}}$,Compute the largest natural number  such that  divides,n 2^n S=\binom{2}{1}+\binom{4}{2}+\binom{8}{4}+\cdots+\binom{2^{100}}{2^{99}},"Honestly, I'm pretty stuck on this. I've made some basic observations, but I'm not sure they'll help. For any positive integer $k$ , $$\binom{2^k}{2^{k-1}}=\frac{(2^k)!}{((2^{k-1})!)^2}$$ I was thinking that the factorial being squared in the denominator might allow for some nice symmetry, but I can't seem to see any. This binomial coefficient also counts the number of ways to choose $2^{k-1}$ objects from a set of $2^k$ objects, but I couldn't find a combinatorial representation for the sum as a whole. Using Legendre's formula, $v_2((2^k)!)=2^k-1$ and $v_2((2^{k-1})!)=2^{k-1}-1$ . So, $v_2 \binom{2^k}{2^{k-1}}=(2^k-1)-2(2^{k-1}-1)=1$ .","Honestly, I'm pretty stuck on this. I've made some basic observations, but I'm not sure they'll help. For any positive integer , I was thinking that the factorial being squared in the denominator might allow for some nice symmetry, but I can't seem to see any. This binomial coefficient also counts the number of ways to choose objects from a set of objects, but I couldn't find a combinatorial representation for the sum as a whole. Using Legendre's formula, and . So, .",k \binom{2^k}{2^{k-1}}=\frac{(2^k)!}{((2^{k-1})!)^2} 2^{k-1} 2^k v_2((2^k)!)=2^k-1 v_2((2^{k-1})!)=2^{k-1}-1 v_2 \binom{2^k}{2^{k-1}}=(2^k-1)-2(2^{k-1}-1)=1,"['combinatorics', 'elementary-number-theory']"
7,Finding the maximum cycle of a given set,Finding the maximum cycle of a given set,,"Problem: Given $4$ circles, we define the following set of rules: i) Any circle which contains $\ge 3 $ elements transfers exactly one of its elements to each of other $3$ circles. ii) Circles which contain $<3$ number of element do not transfer any of its elements to the other three circles. In one operation all rules are applied simultaneously. There are two states which can be achieved under these rules: This is a stable state reached. This is an oscillating state. Question: I am curious to find what is the maximum value of $k$ such that some initial configuration cycles through $k$ distinct configurations and returns to the original configuration (for the first time) after $k$ operations? $k$ is also called the least period of the transformation.","Problem: Given circles, we define the following set of rules: i) Any circle which contains elements transfers exactly one of its elements to each of other circles. ii) Circles which contain number of element do not transfer any of its elements to the other three circles. In one operation all rules are applied simultaneously. There are two states which can be achieved under these rules: This is a stable state reached. This is an oscillating state. Question: I am curious to find what is the maximum value of such that some initial configuration cycles through distinct configurations and returns to the original configuration (for the first time) after operations? is also called the least period of the transformation.",4 \ge 3  3 <3 k k k k,"['combinatorics', 'periodic-functions', 'pattern-recognition']"
8,Statistical distance between two coin-flipping distributions,Statistical distance between two coin-flipping distributions,,"I have two distributions that I suspect are close in statistical (variational) distance i.e. $\sum_{x} \| D_1(x) - D_2(x) \|$ is small. The first distribution is $N$ coin-flips of iid coins with probability $p$ of coming up heads. For the second distribution, I first pick $F$ locations uniformly randomly out of the $N$ and set them to heads. For the remaining locations, I flip iid coins with bias $p' = \frac{pN - F}{N- F}$ . (The rationale for the adjusted probability is so that the expected number of heads match up in both situations.) How close are these distributions in statistical distance? Is there an easy bound one can place? Here I'm thinking of $p = N^{-1/10}$ and $F \le N^{1/100}$ . My progress Let's note that both distributions are permutation symmetric so the statistical distance between the two distributions is equivalent to the statistical distance between random variables $X$ and $Y$ where $X \sim \textrm{Binomial}(N, p)$ and $Y \sim F + \textrm{Binomial}(N-F, p')$ . The intuition as to why these random variables should have similar distribution is that as $N \rightarrow \infty$ , the distributions approach normal distributions which are both centered at $pN$ but $X$ concentrates faster than $Y$ .","I have two distributions that I suspect are close in statistical (variational) distance i.e. is small. The first distribution is coin-flips of iid coins with probability of coming up heads. For the second distribution, I first pick locations uniformly randomly out of the and set them to heads. For the remaining locations, I flip iid coins with bias . (The rationale for the adjusted probability is so that the expected number of heads match up in both situations.) How close are these distributions in statistical distance? Is there an easy bound one can place? Here I'm thinking of and . My progress Let's note that both distributions are permutation symmetric so the statistical distance between the two distributions is equivalent to the statistical distance between random variables and where and . The intuition as to why these random variables should have similar distribution is that as , the distributions approach normal distributions which are both centered at but concentrates faster than .","\sum_{x} \| D_1(x) - D_2(x) \| N p F N p' = \frac{pN - F}{N- F} p = N^{-1/10} F \le N^{1/100} X Y X \sim \textrm{Binomial}(N, p) Y \sim F + \textrm{Binomial}(N-F, p') N \rightarrow \infty pN X Y","['combinatorics', 'probability-distributions', 'binomial-coefficients']"
9,"What is another way to prove the least amount of pence, nickels, dimes and quarters that guarantees making any change exactly?","What is another way to prove the least amount of pence, nickels, dimes and quarters that guarantees making any change exactly?",,"In United States, there are four common coins people carry, \begin{align*} 1 \text{ Penny} &= \$0.01 \\ 1 \text{ Nickel} &= \$0.05 \\ 1 \text{ Dime} &= \$0.10 \\ 1 \text{ Quarter} &= \$0.25 \\ \end{align*} Define making the exact change as not getting any coins back from the cashier, i. e., paying the fractional dollar in exact coins. E. g., one buys two gallons of milk for $\$10.19$ then making the exact change here means paying the fractional dollar as a dime, a nickel and four pence. Some people (like myself) always pay the ceiling of the total bill and end-up with an ever increasing pile of coins under the armrest of their cars. To remedy that, I started thinking if I could assure myself of making the exact change each time, I will be better encouraged to actually take some of those coins with me. Clearly, the more random coins one carries, the greater the probability of making the exact change but, What is the least amount of pence, nickels, dimes and quarters that guarantees making any change exactly? Taking a greedy approach, you can conclude that you need 3 quarters since if you needed four then you are paying in a dollar, 2 dimes since three means you can use a quarter, 1 nickel since two of them mean you can use a dime and 4 pence since five would mean you can use a nickel. Now I want to prove this in a more algebraic way where 4 pence, 1 nickel, 2 dimes and 3 quarters fall out as a solution of something. Let $\lceil x_1\rceil, \lceil x_2\rceil, \lceil x_3\rceil, \lceil x_4\rceil$ be the number of pence, nickels, dimes and quarters then, Assume that we will on average need 2 of each type of coins. The coins will have to sum up to more than $\$0.98$ since otherwise we can't make $\$0.99$ . One way I have done it is using this system, \begin{align*} x_1+x_2+x_3+x_4 &> 8 && \text{By assumption 1}\\ x_1+5x_2+10x_3+25x_4 &> 98 && \text{By observation 2}\\ x_1+x_2 &> 4 && \text{By assumption 1}\\ x_1+5x_2 &> 6 && \text{By an observation similar to 2}\\ \end{align*} Solving this system does yield, $$ \lceil x_1\rceil, \lceil x_2\rceil, \lceil x_3\rceil, \lceil x_4\rceil = 4, 1, 2, 3 $$ But I find this proof to be kinda hand-wavy and obvious in its reverse-engineering. Does someone see a better, more elegant algebraic/combinatoric proof here? Maybe something with the binomials or a generating function?","In United States, there are four common coins people carry, Define making the exact change as not getting any coins back from the cashier, i. e., paying the fractional dollar in exact coins. E. g., one buys two gallons of milk for then making the exact change here means paying the fractional dollar as a dime, a nickel and four pence. Some people (like myself) always pay the ceiling of the total bill and end-up with an ever increasing pile of coins under the armrest of their cars. To remedy that, I started thinking if I could assure myself of making the exact change each time, I will be better encouraged to actually take some of those coins with me. Clearly, the more random coins one carries, the greater the probability of making the exact change but, What is the least amount of pence, nickels, dimes and quarters that guarantees making any change exactly? Taking a greedy approach, you can conclude that you need 3 quarters since if you needed four then you are paying in a dollar, 2 dimes since three means you can use a quarter, 1 nickel since two of them mean you can use a dime and 4 pence since five would mean you can use a nickel. Now I want to prove this in a more algebraic way where 4 pence, 1 nickel, 2 dimes and 3 quarters fall out as a solution of something. Let be the number of pence, nickels, dimes and quarters then, Assume that we will on average need 2 of each type of coins. The coins will have to sum up to more than since otherwise we can't make . One way I have done it is using this system, Solving this system does yield, But I find this proof to be kinda hand-wavy and obvious in its reverse-engineering. Does someone see a better, more elegant algebraic/combinatoric proof here? Maybe something with the binomials or a generating function?","\begin{align*}
1 \text{ Penny} &= \0.01 \\
1 \text{ Nickel} &= \0.05 \\
1 \text{ Dime} &= \0.10 \\
1 \text{ Quarter} &= \0.25 \\
\end{align*} \10.19 \lceil x_1\rceil, \lceil x_2\rceil, \lceil x_3\rceil, \lceil x_4\rceil \0.98 \0.99 \begin{align*}
x_1+x_2+x_3+x_4 &> 8 && \text{By assumption 1}\\
x_1+5x_2+10x_3+25x_4 &> 98 && \text{By observation 2}\\
x_1+x_2 &> 4 && \text{By assumption 1}\\
x_1+5x_2 &> 6 && \text{By an observation similar to 2}\\
\end{align*} 
\lceil x_1\rceil, \lceil x_2\rceil, \lceil x_3\rceil, \lceil x_4\rceil
=
4, 1, 2, 3
","['combinatorics', 'alternative-proof', 'combinatorial-proofs']"
10,IMO combinatorics partitioning prime number products from 1973 shortlist,IMO combinatorics partitioning prime number products from 1973 shortlist,,"Let $P$ be a set of 7 different prime numbers and $C$ a set of 28 different composite numbers each of which is a product of two (not necessarily different) numbers from $P$ . The set $C$ is divided into 7 disjoint four-element subsets such that each of the numbers in one set has a common prime divisor with at least two other numbers in that set. How many such partitions of $C$ are there? Observations: There are $\binom{7}{2}$ possible product pairings consisting of distinct primes from $P$ , and then also 7 prime squares, so together that accounts for the 28 elements in $C$ . Now suppose $p^2$ and $q^2$ were in the same partition. Then the condition would require that the other 2 numbers in the partition both be $pq$ , which is impossible because $C$ contains exactly 28 elements meaning that $C$ contains each product pairing (as formed in the ways discussed above) exactly once. So each of the partitions must contain a unique square, $a$ (say), and must take one of the forms { $a^2, ab, ac, ad$ } or { $a^2, ab, ac, bc$ }. It remains to count the possible ways of pairing the remaining elements in these forms for each of the seven sets. The IMO compendium solution arrives directly to this point before stating: It is now easy to count up the partitions There is a thread from half a decade back on this question but it wasn't solved and got messy. Some tentative thoughts: For the form { $a^2, ab, ac, bc$ }, the problem reduces to the number of bijections of the set { $1,1,2,2,3,3,4,4,5,5,6,6,7,7$ } to { $n_{1a}, n_{1b}, n_{2a}, n_{2b}, ... n_{7a}, n_{7b}$ } such that $n_i\neq i$ and $n_{ia}\neq n_{ib} \ \forall i$ for which the derangement formula (permutations without fixed points) might be a start, though I'm not convinced this is a step forwards. I suspect PIE would work somehow.","Let be a set of 7 different prime numbers and a set of 28 different composite numbers each of which is a product of two (not necessarily different) numbers from . The set is divided into 7 disjoint four-element subsets such that each of the numbers in one set has a common prime divisor with at least two other numbers in that set. How many such partitions of are there? Observations: There are possible product pairings consisting of distinct primes from , and then also 7 prime squares, so together that accounts for the 28 elements in . Now suppose and were in the same partition. Then the condition would require that the other 2 numbers in the partition both be , which is impossible because contains exactly 28 elements meaning that contains each product pairing (as formed in the ways discussed above) exactly once. So each of the partitions must contain a unique square, (say), and must take one of the forms { } or { }. It remains to count the possible ways of pairing the remaining elements in these forms for each of the seven sets. The IMO compendium solution arrives directly to this point before stating: It is now easy to count up the partitions There is a thread from half a decade back on this question but it wasn't solved and got messy. Some tentative thoughts: For the form { }, the problem reduces to the number of bijections of the set { } to { } such that and for which the derangement formula (permutations without fixed points) might be a start, though I'm not convinced this is a step forwards. I suspect PIE would work somehow.","P C P C C \binom{7}{2} P C p^2 q^2 pq C C a a^2, ab, ac, ad a^2, ab, ac, bc a^2, ab, ac, bc 1,1,2,2,3,3,4,4,5,5,6,6,7,7 n_{1a}, n_{1b}, n_{2a}, n_{2b}, ... n_{7a}, n_{7b} n_i\neq i n_{ia}\neq n_{ib} \ \forall i","['combinatorics', 'prime-numbers', 'contest-math']"
11,Find $A^m B^n$ for noncommutative variables,Find  for noncommutative variables,A^m B^n,"Let $$ \begin{cases} AC=CA+\alpha A,\\ BC=CB+\beta B,\\ AB=BA+\gamma C. \end{cases} $$ It is no so hard to find that \begin{gather*} A^n C^m=(C+\alpha n)^m A^n,\\ B^n C^m=(C+\beta n)^m B^n. \end{gather*} Unfortunately I cant find a good formula for $A^m B^n.$ For $m=1$ I have got $$ A B^n=B^n A+n \gamma B^{n-1}(C-\frac{n-1}{2} \beta). $$ Similar, but some complicated formulas I have for $m=2,3$ but I cant see what will  be for arbitrary $m$ and $n.$ Is there any way to present $A^m B^n$ in not ugly form?","Let It is no so hard to find that Unfortunately I cant find a good formula for For I have got Similar, but some complicated formulas I have for but I cant see what will  be for arbitrary and Is there any way to present in not ugly form?","
\begin{cases}
AC=CA+\alpha A,\\
BC=CB+\beta B,\\
AB=BA+\gamma C.
\end{cases}
 \begin{gather*}
A^n C^m=(C+\alpha n)^m A^n,\\
B^n C^m=(C+\beta n)^m B^n.
\end{gather*} A^m B^n. m=1 
A B^n=B^n A+n \gamma B^{n-1}(C-\frac{n-1}{2} \beta).
 m=2,3 m n. A^m B^n","['combinatorics', 'noncommutative-algebra']"
12,Are there infinitely many $n$ s.t. $\prod_i^n a_i = \sum^n_i a_i$ only if the number of $1$ in vector $(a_i)_i \in \mathbb{N}^n$ is $n-2$?,Are there infinitely many  s.t.  only if the number of  in vector  is ?,n \prod_i^n a_i = \sum^n_i a_i 1 (a_i)_i \in \mathbb{N}^n n-2,"For $n \geq 4$ , let $$A_{n} = \left\{ \mathbf{a} = (a_{1}, a_{2}, \ldots, a_{n}) \in \mathbb{N}^{n} : \prod_{i}^{n} a_{i} = \sum_{i}^{n} a_{i} \right\}$$ and for a vector $\mathbf{a} \in \mathbb{N}^{n}$ , let $m(\mathbf{a})$ be the number of $1$ in $\mathbf{a}$ . It is clear that $(n, 2, 1_{1}, 1_{2}, \ldots, 1_{n-2}) \in A_{n}$ which implies that $A_{n} \neq \varnothing$ and there exists a vector $\mathbf{a} \in A_{n}$ such that $m(\mathbf{a}) = n - 2$ . Besides, for each vector $\mathbf{a} \in A_{n}$ , $m(\mathbf{a}) \leq n-2$ holds. There exists some $n \geq 4$ such that for every vector $\mathbf{a} \in A_{n}$ , $m(\mathbf{a})$ is exactly $n - 2$ . After my computing, the solution for $n \leq 1000$ with at most $m$ integers greater than $1$ is presented as follow: Specifically, such $n \leq 1000$ satisfying that the number of $1$ in the vector $\mathbf{a} \in A_{n}$ is exactly $n - 2$ is listed as follow: 4, 6, 7, 9, 10, 15, 16, 22, 24, 31, 34, 36, 49, 66, 76, 91, 97, 112, 114, 126, 142, 174, 210, 231, 330, 442, 444, 664, 714, 780, 784, 966. My question is whether there are infinitely many $n \geq 4$ such that for every vector $\mathbf{a} \in A_{n}$ , the number of $1$ in $\mathbf{a}$ is exactly $n - 2$ . PS: Let $B_{l} = \{ n : \forall \mathbf{a} \in A_{n}, m(\mathbf{a}) \geq n - l \}$ . Actually, I what to know whether the size of $B_{2}$ is infinite. It is welcome if you have an idea about the weak version of this problem: Determine whether the size of $B_{l}$ is infinite for some constant $l$ .","For , let and for a vector , let be the number of in . It is clear that which implies that and there exists a vector such that . Besides, for each vector , holds. There exists some such that for every vector , is exactly . After my computing, the solution for with at most integers greater than is presented as follow: Specifically, such satisfying that the number of in the vector is exactly is listed as follow: 4, 6, 7, 9, 10, 15, 16, 22, 24, 31, 34, 36, 49, 66, 76, 91, 97, 112, 114, 126, 142, 174, 210, 231, 330, 442, 444, 664, 714, 780, 784, 966. My question is whether there are infinitely many such that for every vector , the number of in is exactly . PS: Let . Actually, I what to know whether the size of is infinite. It is welcome if you have an idea about the weak version of this problem: Determine whether the size of is infinite for some constant .","n \geq 4 A_{n} = \left\{ \mathbf{a} = (a_{1}, a_{2}, \ldots, a_{n}) \in \mathbb{N}^{n} : \prod_{i}^{n} a_{i} = \sum_{i}^{n} a_{i} \right\} \mathbf{a} \in \mathbb{N}^{n} m(\mathbf{a}) 1 \mathbf{a} (n, 2, 1_{1}, 1_{2}, \ldots, 1_{n-2}) \in A_{n} A_{n} \neq \varnothing \mathbf{a} \in A_{n} m(\mathbf{a}) = n - 2 \mathbf{a} \in A_{n} m(\mathbf{a}) \leq n-2 n \geq 4 \mathbf{a} \in A_{n} m(\mathbf{a}) n - 2 n \leq 1000 m 1 n \leq 1000 1 \mathbf{a} \in A_{n} n - 2 n \geq 4 \mathbf{a} \in A_{n} 1 \mathbf{a} n - 2 B_{l} = \{ n : \forall \mathbf{a} \in A_{n}, m(\mathbf{a}) \geq n - l \} B_{2} B_{l} l","['combinatorics', 'number-theory']"
13,"How many ways are there to choose subsets $S$ and $T$ of $A=\{1,2,3,,.....,n\}$ so that $S$ contains $T$?",How many ways are there to choose subsets  and  of  so that  contains ?,"S T A=\{1,2,3,,.....,n\} S T","How many ways are there to choose subsets $S$ and $T$ of $A=\{1,2,3,,.....,n\}$ so that $S$ contains $T$ ? My attempt : The number of all subsets of $A$ is $2^n$ . Let's denote this subsets by $S_{\alpha}$ ,where $\alpha$ is the size of each subset so $S=[S_0 ,S_1 ,S_2 ,...,S_n ]$ Suppose we choose $S_3$ so we must to choose a subset T of this $S_3$ for having that $S_3$ contain T, and the number of T in this case is $2^3$ , but we must to note that there are ${ n \choose 3}$ of this $S_3$ , so the number of ways to choose a $S_3$ and T such that $S_3$ contain T is ${n \choose 3}\cdot2^3$ and we will the same thing for each $S_{\alpha}$ for example for $S_{12}$ , the number of ways to choose a $S_{12}$ and T such that $S_{12}$ contain T is ${n \choose 12}\cdot2^{12}$ and so on so the answer is that: ${n \choose 0}\cdot2^{0}+{n \choose 1}\cdot2^{1}+{n \choose 2}\cdot2^{2}+....{n \choose n}\cdot2^{n}$ and that's equal: $\sum_{k=0}^{n}{n \choose k}\cdot2^{k}=\sum_{k=0}^{n}{n \choose k}\cdot2^{k}\cdot1^{n-k}=(1+2)^n=3^n$ What do you think about my answer?","How many ways are there to choose subsets and of so that contains ? My attempt : The number of all subsets of is . Let's denote this subsets by ,where is the size of each subset so Suppose we choose so we must to choose a subset T of this for having that contain T, and the number of T in this case is , but we must to note that there are of this , so the number of ways to choose a and T such that contain T is and we will the same thing for each for example for , the number of ways to choose a and T such that contain T is and so on so the answer is that: and that's equal: What do you think about my answer?","S T A=\{1,2,3,,.....,n\} S T A 2^n S_{\alpha} \alpha S=[S_0 ,S_1 ,S_2 ,...,S_n ] S_3 S_3 S_3 2^3 { n \choose 3} S_3 S_3 S_3 {n \choose 3}\cdot2^3 S_{\alpha} S_{12} S_{12} S_{12} {n \choose 12}\cdot2^{12} {n \choose 0}\cdot2^{0}+{n \choose 1}\cdot2^{1}+{n \choose 2}\cdot2^{2}+....{n \choose n}\cdot2^{n} \sum_{k=0}^{n}{n \choose k}\cdot2^{k}=\sum_{k=0}^{n}{n \choose k}\cdot2^{k}\cdot1^{n-k}=(1+2)^n=3^n","['combinatorics', 'algebra-precalculus']"
14,Number of permutations generated by using $k$ serial stacks,Number of permutations generated by using  serial stacks,k,"Suppose given $k\geq 2$ stacks $S_1,S_2,\dots,S_k$ , and we have $n$ numbers that we can push a number to $S_1$ and pop and push it into $S_2$ and finally we can pop from $S_k$ . How many permutations can generated by this method of using $k$ stacks? Also I read this post but i can't figured out how many stacks we need to generate $n!$ permutation or how many permutation generated by using $k$ stacks?","Suppose given stacks , and we have numbers that we can push a number to and pop and push it into and finally we can pop from . How many permutations can generated by this method of using stacks? Also I read this post but i can't figured out how many stacks we need to generate permutation or how many permutation generated by using stacks?","k\geq 2 S_1,S_2,\dots,S_k n S_1 S_2 S_k k n! k","['combinatorics', 'discrete-mathematics', 'permutations']"
15,"Finding a set of $n-1$ languages, such that everyone speaks at least one language in the set","Finding a set of  languages, such that everyone speaks at least one language in the set",n-1,"For any integer $n$ , the following fact can be proven to be true: Given $n^n+1$ people, where each person speaks a distinct set of $n$ languages, such that any two of these people speak at least one language in common, there exists a set $T$ of $n-1$ languages such that everyone speaks at least one language in $T$ . I know how to prove that fact, and included a proof at the end, but my question is, what is the smallest number you can replace $n^n+1$ by and have that fact still be true ? Letting $t_n$ be this smallest number, then $t_2=4$ , for example. The fact that $t_2>3$ follows from this counterexample with three people: $$ \{\{\text{English},\text{Español}\},\{\text{English},\text{Français}\},\{\text{Español},\text{Français}\}\} $$ Furthermore, it is easy to show that for any four sets of two languages whose intersections are pairwise nonempty, there will exist a single language spoken by all. What I know so far is that $$ \binom{2n-1}{n}< t_n \le  n^n+1 $$ with the lower bound realized by the collection of $n$ -elements subsets of a $(2n-1)$ -element set. I wonder which one of these is asymptotically correct, or if the truth is somewhere between? The proof of $t_n\le n^n+1$ is far from obvious. You can prove the following by induction on $k$ , for each $k\in \{0,1,\dots,n\}$ : Let $S$ be a set of people who each speak $n$ languages, such that every pair of people in $S$ have a language in common, and there is no set $T$ of $n-1$ languages for which everyone in $S$ speaks at least one language in $T$ . Furthermore, let $R$ be a subset of $S$ such that the intersection of all language sets of the people in $R$ has size at least $n-k$ . Then $|R|\le n^k$ . In particular, $S$ itself satisfies this with $k=n$ , so $|S|\le n^n$ , implying any $n^n+1$ sets will have a set $T$ of $n-1$ languages which works, so $t_n\le n^n+1$ . Proof: The base case $k=0$ is obvious. For $k\ge 1$ , let $R$ be a subset for which the intersection $I$ of all language sets of all people in $R$ has size at least $n-k$ . We can assume $|I|\le n-1$ (else $|R|=1$ ), so there must be some person $p\in S$ who speaks no languages in $I$ . Let $p$ speak the languages $l_1,\dots,l_n$ . For each $i\in \{1,\dots,n\}$ , let $R_i$ be the set of people in $R$ who speak $l_i$ . Then the intersection of all the language sets for all people in $R_i$ has size at least $n-k+1$ , since it includes $I\cup \{l_i\}$ . By induction, we have $|R_i|\le n^{k-1}$ , so $$|R|\le |R_1|+\dots+|R_n|\le n\cdot n^{k-1}=n^k.$$","For any integer , the following fact can be proven to be true: Given people, where each person speaks a distinct set of languages, such that any two of these people speak at least one language in common, there exists a set of languages such that everyone speaks at least one language in . I know how to prove that fact, and included a proof at the end, but my question is, what is the smallest number you can replace by and have that fact still be true ? Letting be this smallest number, then , for example. The fact that follows from this counterexample with three people: Furthermore, it is easy to show that for any four sets of two languages whose intersections are pairwise nonempty, there will exist a single language spoken by all. What I know so far is that with the lower bound realized by the collection of -elements subsets of a -element set. I wonder which one of these is asymptotically correct, or if the truth is somewhere between? The proof of is far from obvious. You can prove the following by induction on , for each : Let be a set of people who each speak languages, such that every pair of people in have a language in common, and there is no set of languages for which everyone in speaks at least one language in . Furthermore, let be a subset of such that the intersection of all language sets of the people in has size at least . Then . In particular, itself satisfies this with , so , implying any sets will have a set of languages which works, so . Proof: The base case is obvious. For , let be a subset for which the intersection of all language sets of all people in has size at least . We can assume (else ), so there must be some person who speaks no languages in . Let speak the languages . For each , let be the set of people in who speak . Then the intersection of all the language sets for all people in has size at least , since it includes . By induction, we have , so","n n^n+1 n T n-1 T n^n+1 t_n t_2=4 t_2>3 
\{\{\text{English},\text{Español}\},\{\text{English},\text{Français}\},\{\text{Español},\text{Français}\}\}
 
\binom{2n-1}{n}< t_n \le  n^n+1
 n (2n-1) t_n\le n^n+1 k k\in \{0,1,\dots,n\} S n S T n-1 S T R S R n-k |R|\le n^k S k=n |S|\le n^n n^n+1 T n-1 t_n\le n^n+1 k=0 k\ge 1 R I R n-k |I|\le n-1 |R|=1 p\in S I p l_1,\dots,l_n i\in \{1,\dots,n\} R_i R l_i R_i n-k+1 I\cup \{l_i\} |R_i|\le n^{k-1} |R|\le |R_1|+\dots+|R_n|\le n\cdot n^{k-1}=n^k.","['combinatorics', 'ramsey-theory', 'extremal-combinatorics']"
16,"Robot moves from $(x,y)$ to $(x+y, y)$ or $(x,x+y)$",Robot moves from  to  or,"(x,y) (x+y, y) (x,x+y)","I was working on some coding related to this topic I found on Stack Overflow. This lead me to a math problem I thought would be interesting. I was wondering if one was given a starting point, what points could the robot reach. For instance, if the robot started at $(10,15)$ , which coordinates would be reachable. To restate the problem, A robot moves in the following way. If it is at the point $(x,y)$ , it can move to either $(x+y,y)$ or $(x,x+y)$ . If the robot starts at the point $(10,15)$ , what points are reachable in a finite number of moves? I noticed that each move preserves the greatest common divisor of the two coordinates, so all the coordinates that are reachable must have gcd equal to 5. Moreover, for relatively prime integers $a$ and $b$ , if the robot can move from $(a,b)$ to $(c,d)$ , then it can move from $(na, nb)$ to $(nc, nd)$ . Therefore, we just have to consider the coordinates that are reachable from $(2,3)$ and just multiply each coordinate by 5. However, I'm not sure what coordinates are reachable. There are coordinates like $(35, 75)$ which are not reachable, even though their greatest common divisor is 5. Any help on the question would be great. Thanks!","I was working on some coding related to this topic I found on Stack Overflow. This lead me to a math problem I thought would be interesting. I was wondering if one was given a starting point, what points could the robot reach. For instance, if the robot started at , which coordinates would be reachable. To restate the problem, A robot moves in the following way. If it is at the point , it can move to either or . If the robot starts at the point , what points are reachable in a finite number of moves? I noticed that each move preserves the greatest common divisor of the two coordinates, so all the coordinates that are reachable must have gcd equal to 5. Moreover, for relatively prime integers and , if the robot can move from to , then it can move from to . Therefore, we just have to consider the coordinates that are reachable from and just multiply each coordinate by 5. However, I'm not sure what coordinates are reachable. There are coordinates like which are not reachable, even though their greatest common divisor is 5. Any help on the question would be great. Thanks!","(10,15) (x,y) (x+y,y) (x,x+y) (10,15) a b (a,b) (c,d) (na, nb) (nc, nd) (2,3) (35, 75)","['combinatorics', 'algorithms', 'recursion', 'recursive-algorithms']"
17,Steps to turn on $2^n$ lamps on a roulette wheel,Steps to turn on  lamps on a roulette wheel,2^n,"There are $2^n$ lamps on a roulette wheel. Each time player A decides on a list of lamps to flip (so on becomes off and off becomes on). Player B sees player A's list, and rotates the roulette wheel to a different location. Player A still flip the lights as if they were on the original location. For example, say there are four lights $1,2,3,4$ . Player A decides to flip the switch of lamp $1$ . Player B rotates the wheel to $3,4,1,2$ . Then after this round, lamp $3$ is flipped. At the beginning, some lamps are on and some are off. Prove that regardless of the initial state, for no more than $2^{2n}$ rounds, player A can always turn on all the lights. There is a hint to this problem. Prove by mathematical induction. Suppose there is a way for $2^{k}$ lamps. Consider the case when $2^{k+1}$ . Pair up the lamps that are opposite of each other... I am thinking after we pair up the lamps that are opposite of each other, We define a new state for this $2^{k}$ pairs. If the pair has different states, we treat them as an ""off"" lamp. Otherwise we treat them as an ""on"" light. But there is no way to turn on this ""off"" light in this new, paired up roulette. My idea could be completely off. Certainly, a solution without using this hint is welcome too.","There are lamps on a roulette wheel. Each time player A decides on a list of lamps to flip (so on becomes off and off becomes on). Player B sees player A's list, and rotates the roulette wheel to a different location. Player A still flip the lights as if they were on the original location. For example, say there are four lights . Player A decides to flip the switch of lamp . Player B rotates the wheel to . Then after this round, lamp is flipped. At the beginning, some lamps are on and some are off. Prove that regardless of the initial state, for no more than rounds, player A can always turn on all the lights. There is a hint to this problem. Prove by mathematical induction. Suppose there is a way for lamps. Consider the case when . Pair up the lamps that are opposite of each other... I am thinking after we pair up the lamps that are opposite of each other, We define a new state for this pairs. If the pair has different states, we treat them as an ""off"" lamp. Otherwise we treat them as an ""on"" light. But there is no way to turn on this ""off"" light in this new, paired up roulette. My idea could be completely off. Certainly, a solution without using this hint is welcome too.","2^n 1,2,3,4 1 3,4,1,2 3 2^{2n} 2^{k} 2^{k+1} 2^{k}",['combinatorics']
18,Very hard variation of handshake problem,Very hard variation of handshake problem,,"Here is the problem: There are 1000 people in a hall. Initially one person had his hand painted. Every second everyone shakes their hand with someone else (in the sense that every second 500 couples form and the two people in the same couple shake hands with each other). In addition no two people can ever shake hands more than once. Of course whenever someone with a painted hand shakes the hand of someone who has it clean, it gets it painted. How much time, at most, is needed to paint all the hands? Prove it. Clarification: we are only considering games that run the full length, i.e. the game has to be able to get to the last round after which all possible handshakes have occurred, no dead ends allowed. So the question is posed within the framework of such games. My considerations: I've tried pretty hard to get the answer for a general n people game, or even for this 1000 people game, but there really seems to be nothing helpful to prove it or even guess it or find it easily for large n, especially given the fact that I have manually bashed the first cases for n = 2,4,6,8,10,12 (the answers being 1,2,3,5,6,8 rounds respectively) which look to have no useful relationship whatsoever between eachother or with n. I think the greedy algorithm is optimal, but I haven't even bothered proving that, since it doesn't really help to find the answer to the problem and prove it, so at times I've just tried to assume it, but even then it didn't quite get me anywhere. Also I don't think there is some beautifully simple symmetry argument to get an answer here, because that should hopefully be reflected in the cases for the first few n, but maybe I am missing it, I couldn't think of anything of that kind. What I am thinking now is that the answer might be some really complicated non closed form/non elementary function of n, or possibly some not even expressible function of n (this last statement in the sense that it's some function who's values for each given n are defined to be the ones given by such a game like this one, or some isomorphic problem, and there definitely are such kind of functions out there, so this could be a possibility). But if any of these last options I've given are correct, how could one possibly prove that? Thank you very much for the help, I hope there is someone who can solve this.","Here is the problem: There are 1000 people in a hall. Initially one person had his hand painted. Every second everyone shakes their hand with someone else (in the sense that every second 500 couples form and the two people in the same couple shake hands with each other). In addition no two people can ever shake hands more than once. Of course whenever someone with a painted hand shakes the hand of someone who has it clean, it gets it painted. How much time, at most, is needed to paint all the hands? Prove it. Clarification: we are only considering games that run the full length, i.e. the game has to be able to get to the last round after which all possible handshakes have occurred, no dead ends allowed. So the question is posed within the framework of such games. My considerations: I've tried pretty hard to get the answer for a general n people game, or even for this 1000 people game, but there really seems to be nothing helpful to prove it or even guess it or find it easily for large n, especially given the fact that I have manually bashed the first cases for n = 2,4,6,8,10,12 (the answers being 1,2,3,5,6,8 rounds respectively) which look to have no useful relationship whatsoever between eachother or with n. I think the greedy algorithm is optimal, but I haven't even bothered proving that, since it doesn't really help to find the answer to the problem and prove it, so at times I've just tried to assume it, but even then it didn't quite get me anywhere. Also I don't think there is some beautifully simple symmetry argument to get an answer here, because that should hopefully be reflected in the cases for the first few n, but maybe I am missing it, I couldn't think of anything of that kind. What I am thinking now is that the answer might be some really complicated non closed form/non elementary function of n, or possibly some not even expressible function of n (this last statement in the sense that it's some function who's values for each given n are defined to be the ones given by such a game like this one, or some isomorphic problem, and there definitely are such kind of functions out there, so this could be a possibility). But if any of these last options I've given are correct, how could one possibly prove that? Thank you very much for the help, I hope there is someone who can solve this.",,"['combinatorics', 'discrete-mathematics', 'combinatorial-proofs']"
19,Evaluate the sum $\binom{2n}{n}+\binom{3n}{n}+\binom{4n}{n}+\cdots+\binom{kn}{n}$,Evaluate the sum,\binom{2n}{n}+\binom{3n}{n}+\binom{4n}{n}+\cdots+\binom{kn}{n},Evaluate the sum $$\binom{2n}{n}+\binom{3n}{n}+\binom{4n}{n} + \cdots +\binom{kn}{n}$$ My Attempt: Given sum = coefficient of $x^n$ in the expansion $$\{(1+x)^{n}+(1+x)^{2n}+(1+x)^{3n}+\cdots+(1+x)^{kn}\}-1 \\ = \text{coefficient of $x^n$ in}~~ \frac{(1+x)^n\{(1+x)^{nk}-1\}}{(1+x)^n-1}-1$$ But I am not able to go beyond this or there is some method using combinatorial argument,Evaluate the sum My Attempt: Given sum = coefficient of in the expansion But I am not able to go beyond this or there is some method using combinatorial argument,"\binom{2n}{n}+\binom{3n}{n}+\binom{4n}{n} + \cdots +\binom{kn}{n} x^n \{(1+x)^{n}+(1+x)^{2n}+(1+x)^{3n}+\cdots+(1+x)^{kn}\}-1 \\
= \text{coefficient of x^n in}~~ \frac{(1+x)^n\{(1+x)^{nk}-1\}}{(1+x)^n-1}-1","['combinatorics', 'summation', 'binomial-coefficients']"
20,binomial identity: elementary proof possible?,binomial identity: elementary proof possible?,,"For any $z \in D(0,1) \subseteq \mathbb{C}$ , the series identity $$(1-z)^{1/2} = \sum_{n=0}^\infty {1/2 \choose n} (-z)^n = 1-\sum_{n=1}^\infty \left|{1/2 \choose n}\right|z^n$$ holds. Letting $z \to 1-$ along the real axis, we deduce (aided by the monotone convergence theorem, or an ad hoc argument) that $$\sum_{n=1}^\infty \left|{1/2 \choose n}\right| = 1.$$ Can this identity be proven in an elementary (e.g. combinatorial) way?","For any , the series identity holds. Letting along the real axis, we deduce (aided by the monotone convergence theorem, or an ad hoc argument) that Can this identity be proven in an elementary (e.g. combinatorial) way?","z \in D(0,1) \subseteq \mathbb{C} (1-z)^{1/2} = \sum_{n=0}^\infty {1/2 \choose n} (-z)^n = 1-\sum_{n=1}^\infty \left|{1/2 \choose n}\right|z^n z \to 1- \sum_{n=1}^\infty \left|{1/2 \choose n}\right| = 1.","['combinatorics', 'complex-analysis', 'binomial-coefficients']"
21,Union of sets with pairwise intersection having half of the elements,Union of sets with pairwise intersection having half of the elements,,"Consider $k$ sets $S_1, S_2, \ldots, S_k$, of the following properties: For every $i$, $\left|S_i\right| = p$ For every pair of $i$ and $j$, $\left|S_i \cap S_j\right| = \frac{p}{2}$ Now I need to find the minimum of $\left|\bigcup S_i\right|$ in terms of $k$ and $p$. (Assume $p$ is large enough to be divisible by any small enough integers) Via trial and error I suspect the answer to be $$\frac{\left(2^{m + 1} - 1\right)p}{2^m}$$ where $m = \lfloor\log_2 k\rfloor$, but cannot prove it. That's also why I give that assumption about $p$, so that one do not need to worry about the situation where $\frac{p}{2^m}$ is not an integer. Edition: actually, I verified that my suspected answer is wrong. For example, when $k = 5$, I managed to construct the sets using $\frac{5p}{6}$ elements. Now I am not sure what the actual answer should be. :( Correction: I think I had mistaken $p$ with another variable I used in a larger problem where this proof is required, when giving the $\frac{5p}{6}$ lower bound in the edition above. It should be $\frac{5p}{3}$. An example would be when $k = 5$ and $p = 6$ (to be divisible by both $2$ and $3$), then my $5$ sets would be $$\left\{1, 2, 3, 4, 5, 6\right\}, \left\{1, 2, 3, 7, 8, 9\right\}, \left\{1, 4, 6, 7, 9, 10\right\}, \left\{2, 4, 5, 7, 8, 10\right\}, \left\{3, 5, 6, 8, 9, 10\right\}$$ using $10$ elements. They are obtained basically as I try to ""average"" the occurrences of each number (in this example, specifically, letting each number appear $3$ times). Maybe we can go from here, but how to prove in general that this average is reachable?","Consider $k$ sets $S_1, S_2, \ldots, S_k$, of the following properties: For every $i$, $\left|S_i\right| = p$ For every pair of $i$ and $j$, $\left|S_i \cap S_j\right| = \frac{p}{2}$ Now I need to find the minimum of $\left|\bigcup S_i\right|$ in terms of $k$ and $p$. (Assume $p$ is large enough to be divisible by any small enough integers) Via trial and error I suspect the answer to be $$\frac{\left(2^{m + 1} - 1\right)p}{2^m}$$ where $m = \lfloor\log_2 k\rfloor$, but cannot prove it. That's also why I give that assumption about $p$, so that one do not need to worry about the situation where $\frac{p}{2^m}$ is not an integer. Edition: actually, I verified that my suspected answer is wrong. For example, when $k = 5$, I managed to construct the sets using $\frac{5p}{6}$ elements. Now I am not sure what the actual answer should be. :( Correction: I think I had mistaken $p$ with another variable I used in a larger problem where this proof is required, when giving the $\frac{5p}{6}$ lower bound in the edition above. It should be $\frac{5p}{3}$. An example would be when $k = 5$ and $p = 6$ (to be divisible by both $2$ and $3$), then my $5$ sets would be $$\left\{1, 2, 3, 4, 5, 6\right\}, \left\{1, 2, 3, 7, 8, 9\right\}, \left\{1, 4, 6, 7, 9, 10\right\}, \left\{2, 4, 5, 7, 8, 10\right\}, \left\{3, 5, 6, 8, 9, 10\right\}$$ using $10$ elements. They are obtained basically as I try to ""average"" the occurrences of each number (in this example, specifically, letting each number appear $3$ times). Maybe we can go from here, but how to prove in general that this average is reachable?",,"['combinatorics', 'elementary-set-theory', 'combinatorial-designs']"
22,Unique coverage,Unique coverage,,"Given a collection $A$ of $m$ sets $S_1,\ldots,S_m$ (i.e., $A=\{S_1,\ldots,S_m\}$) such that $|S_1 \cup \ldots \cup S_m| =n$. In other words, $S_1,\ldots,S_m$ covers a ground set of $n$ elements. Is there a constant $0<c<1$ such that for arbitrary $A=\{S_1,\ldots,S_m\}$,  one can always find $B \subseteq A$ such that the number of elements that belong to exactly one set in $B$ is at least $c n$? Conjecture: for $c=1/100$, we can always find a $B \subseteq A$ such that the number of elements that belong to exactly one set in $B$ is at least $n/100$.","Given a collection $A$ of $m$ sets $S_1,\ldots,S_m$ (i.e., $A=\{S_1,\ldots,S_m\}$) such that $|S_1 \cup \ldots \cup S_m| =n$. In other words, $S_1,\ldots,S_m$ covers a ground set of $n$ elements. Is there a constant $0<c<1$ such that for arbitrary $A=\{S_1,\ldots,S_m\}$,  one can always find $B \subseteq A$ such that the number of elements that belong to exactly one set in $B$ is at least $c n$? Conjecture: for $c=1/100$, we can always find a $B \subseteq A$ such that the number of elements that belong to exactly one set in $B$ is at least $n/100$.",,['combinatorics']
23,Number of permutations of six numbers with certain restrictions,Number of permutations of six numbers with certain restrictions,,"There are $6!$ permutations of the numbers $1...6$, like $156234$. in this permutation, $1$ is in the first location, $5$ is in the second, etc. The problem is: how many permutations with the numbers $1...6$ are there that follow this rule: each number is either in the location that is equal to its value, or in a location that differs from its value by $1$ ($+1$ or $-1$), or in a location that differs from its value by $2$ ($+2$ or $-2$). For example: the permutation $245163$ doesn't follow the rule only because $1$ is in the 4th place, and because $3$ is in the 6th place. I solved a weaker version of this problem, in which there are only $4$ numbers with the same rule, by taking the overall number of permutations with the $4$ numbers, subtracting those who had $4$ in the first place and those who had $1$ in their 4th place, and adding those who had $4$ in their first place and $1$ in their 4th place, to avoid subtracting them twice: $4!-3!-3!+2 =  14$. This strategy worked, but once you get to just $5$ numbers, there are just too many cases to add and subtract...","There are $6!$ permutations of the numbers $1...6$, like $156234$. in this permutation, $1$ is in the first location, $5$ is in the second, etc. The problem is: how many permutations with the numbers $1...6$ are there that follow this rule: each number is either in the location that is equal to its value, or in a location that differs from its value by $1$ ($+1$ or $-1$), or in a location that differs from its value by $2$ ($+2$ or $-2$). For example: the permutation $245163$ doesn't follow the rule only because $1$ is in the 4th place, and because $3$ is in the 6th place. I solved a weaker version of this problem, in which there are only $4$ numbers with the same rule, by taking the overall number of permutations with the $4$ numbers, subtracting those who had $4$ in the first place and those who had $1$ in their 4th place, and adding those who had $4$ in their first place and $1$ in their 4th place, to avoid subtracting them twice: $4!-3!-3!+2 =  14$. This strategy worked, but once you get to just $5$ numbers, there are just too many cases to add and subtract...",,['combinatorics']
24,Garden with mushrooms,Garden with mushrooms,,"A farmer cultivates mushrooms in his garden. A greedy neighbor wants to pick some but the farmer is trying to block him. The garden has the form of a 8x6 grid. Rows 1 to 8 from the front to the back and columns A to F from left to right. The mushrooms are planted in the 8th row (6 mushrooms). The farmer is initially standing at the block E7, right in front of the mushrooms and can move at any of his direct surrounding 8 blocks (including those behind him, where the mushrooms are planted).  The neighbor initially stands at block F1 and is trying to reach the mushrooms by walking at any of his directly surrounding blocks (including those situated diagonally in relation to his position). Once the neighbor reaches the farmer, he hits him and can then reach the mushrooms, but if the farmer reaches the neighbor, he hits him also, and he has to back out. The neighbor moves first and then they alternate turns. Will he manage to get at least one mushroom, or the farmer will block him?  To summarize, the ""game"" ends in any of the 3 cases: The farmer reaches the neighbor (walks on his square). In this case, the neighbor has to leave and go home. The neighbor reaches the farmer, even once (walks on his square). Then the farmer has to admit he lost, and let him get the mushrooms! The neighbor reaches one (any) mushroom before the farmer manages to stop him. Describe some of the optimal moves for each of them, using the grid coordinates. I tried to set the neighbor ""chase"" the farmer by trying to be on the same column with him but can't find a general pattern. FYI I found this in an Ukrainian magazine at the Kiev airport - I hope I translated everything correctly!","A farmer cultivates mushrooms in his garden. A greedy neighbor wants to pick some but the farmer is trying to block him. The garden has the form of a 8x6 grid. Rows 1 to 8 from the front to the back and columns A to F from left to right. The mushrooms are planted in the 8th row (6 mushrooms). The farmer is initially standing at the block E7, right in front of the mushrooms and can move at any of his direct surrounding 8 blocks (including those behind him, where the mushrooms are planted).  The neighbor initially stands at block F1 and is trying to reach the mushrooms by walking at any of his directly surrounding blocks (including those situated diagonally in relation to his position). Once the neighbor reaches the farmer, he hits him and can then reach the mushrooms, but if the farmer reaches the neighbor, he hits him also, and he has to back out. The neighbor moves first and then they alternate turns. Will he manage to get at least one mushroom, or the farmer will block him?  To summarize, the ""game"" ends in any of the 3 cases: The farmer reaches the neighbor (walks on his square). In this case, the neighbor has to leave and go home. The neighbor reaches the farmer, even once (walks on his square). Then the farmer has to admit he lost, and let him get the mushrooms! The neighbor reaches one (any) mushroom before the farmer manages to stop him. Describe some of the optimal moves for each of them, using the grid coordinates. I tried to set the neighbor ""chase"" the farmer by trying to be on the same column with him but can't find a general pattern. FYI I found this in an Ukrainian magazine at the Kiev airport - I hope I translated everything correctly!",,['combinatorics']
25,A bijection between Motzkin paths and 3-colored signed Dyck path homomorphs,A bijection between Motzkin paths and 3-colored signed Dyck path homomorphs,,"The generating function $m=m(z)$ for the Motzkin numbers satisfies the functional equation $$ m=1+zm+z^2m^2 $$ (a Motzkin path $P$ with unit steps $u,d,l$ (up, down, level) is either empty or $lP'$ or $uP'dP''$). A simple manipulation yields $$ m(1-3z)=m-3zm=1-2zm+z^2m^2=(1-zm)^2, $$ so that $$ \frac{zm}{(1-zm)^2}=\frac{z}{1-3z}, $$ i.e. $$ \frac{z}{(1-z)^2}\circ(zm)=\frac{z}{1-3z}, $$ where $\circ$ denotes the composition of functions. Inverting the left factor on the left, we obtain $$ zm=\left(zC(-z)^2\right)\circ\frac{z}{1-3z}=\frac{z}{1-3z}C\left(-\frac{z}{1-3z}\right)^2, $$ where $C=C(z)$ is the generating function for the Catalan numbers. My question is: Is there a known bijective proof of this last equation? That would possibly involve some inclusion-exclusion argument or an involution on $3$-colored signed Dyck path homomorphs (i.e. Dyck paths where each edge is replaced with a path each of whose non-initial steps is assigned one of $3$ colors, while the initial step has weight $-1$). Of course, this is just one choice, the combinatorial classes involved may be different.","The generating function $m=m(z)$ for the Motzkin numbers satisfies the functional equation $$ m=1+zm+z^2m^2 $$ (a Motzkin path $P$ with unit steps $u,d,l$ (up, down, level) is either empty or $lP'$ or $uP'dP''$). A simple manipulation yields $$ m(1-3z)=m-3zm=1-2zm+z^2m^2=(1-zm)^2, $$ so that $$ \frac{zm}{(1-zm)^2}=\frac{z}{1-3z}, $$ i.e. $$ \frac{z}{(1-z)^2}\circ(zm)=\frac{z}{1-3z}, $$ where $\circ$ denotes the composition of functions. Inverting the left factor on the left, we obtain $$ zm=\left(zC(-z)^2\right)\circ\frac{z}{1-3z}=\frac{z}{1-3z}C\left(-\frac{z}{1-3z}\right)^2, $$ where $C=C(z)$ is the generating function for the Catalan numbers. My question is: Is there a known bijective proof of this last equation? That would possibly involve some inclusion-exclusion argument or an involution on $3$-colored signed Dyck path homomorphs (i.e. Dyck paths where each edge is replaced with a path each of whose non-initial steps is assigned one of $3$ colors, while the initial step has weight $-1$). Of course, this is just one choice, the combinatorial classes involved may be different.",,"['combinatorics', 'catalan-numbers']"
26,Finding partition with equal sum,Finding partition with equal sum,,"Given a positive integer $n$. Your friend selects numbers $x_1,x_2,\ldots,x_n\ge 0$, not necessarily distinct. You are allowed to ask him the sum of any subset of numbers that you want. At the end, you should answer whether the numbers can be partitioned into two subsets $A,B$ (that is, $A\cup B$ is the set of all numbers, and $A\cap B$ is empty) such that the sum of the numbers in $A$ is the same as in $B$. What is the minimum number of questions that always suffice? If you ask for every number separately, this takes $n$ questions. Is it the best you can do?","Given a positive integer $n$. Your friend selects numbers $x_1,x_2,\ldots,x_n\ge 0$, not necessarily distinct. You are allowed to ask him the sum of any subset of numbers that you want. At the end, you should answer whether the numbers can be partitioned into two subsets $A,B$ (that is, $A\cup B$ is the set of all numbers, and $A\cap B$ is empty) such that the sum of the numbers in $A$ is the same as in $B$. What is the minimum number of questions that always suffice? If you ask for every number separately, this takes $n$ questions. Is it the best you can do?",,"['combinatorics', 'puzzle']"
27,"Find the number of permutations of $1,2,3...,n$ such that $a_{i+1}\neq a_i+1$ for $ i<n $ if $a_i$ is the i-th element in the permutation?",Find the number of permutations of  such that  for  if  is the i-th element in the permutation?,"1,2,3...,n a_{i+1}\neq a_i+1  i<n  a_i","Find the number of permutations of $1,2,3...,n$  such that $a_{i+1}$ does not equal $a_i+1$ if $a_i$ is the $i$-th element in the permutation? I think a good strategy would be to approach this using PIE but I am still not sure about how I could solve it with that method.","Find the number of permutations of $1,2,3...,n$  such that $a_{i+1}$ does not equal $a_i+1$ if $a_i$ is the $i$-th element in the permutation? I think a good strategy would be to approach this using PIE but I am still not sure about how I could solve it with that method.",,"['combinatorics', 'permutations', 'recurrence-relations', 'recursion', 'inclusion-exclusion']"
28,A polynomial equation game,A polynomial equation game,,"Alice and Bob are sitting in a warm, cozy room. As cozy as the room is, there's not much to do, and they soon find themselves rather bored. As you might expect from people as uncreatively named as Alice and Bob, Alice and Bob decide to play a game. They start with a monic polynomial equation $x^n + a_1 x^{n-1} + \cdots + a_n$, where the coefficients $a_i$ are to be determined. Each turn, Alice chooses an integer, and Bob chooses which coefficient that integer is to be. After choosing and placing all $n$ coefficients, if the resulting polynomial has $n$ distinct integer solutions, Alice wins. Otherwise, Bob wins. For which $n$ does Alice have a winning strategy? For $n = 1, 2$ it is fairly easy to see she does. What happens for larger $n$?","Alice and Bob are sitting in a warm, cozy room. As cozy as the room is, there's not much to do, and they soon find themselves rather bored. As you might expect from people as uncreatively named as Alice and Bob, Alice and Bob decide to play a game. They start with a monic polynomial equation $x^n + a_1 x^{n-1} + \cdots + a_n$, where the coefficients $a_i$ are to be determined. Each turn, Alice chooses an integer, and Bob chooses which coefficient that integer is to be. After choosing and placing all $n$ coefficients, if the resulting polynomial has $n$ distinct integer solutions, Alice wins. Otherwise, Bob wins. For which $n$ does Alice have a winning strategy? For $n = 1, 2$ it is fairly easy to see she does. What happens for larger $n$?",,"['combinatorics', 'number-theory']"
29,Closed-Form Solution for Permutation Table,Closed-Form Solution for Permutation Table,,"For given $N,n\in\mathbb N$ I am looking for a formula that generates all $N\choose{n}$ combinations in the following way: E.g. take  $N=3,n=1$. Then there are ${3\choose1}=3$ combinations such that 1| - + + 2| + - + 3| + + - or $N=4,n=0$. Then there are ${4\choose0}=1$ combinations such that 1| + + + + or $N=4,n=1$. Then there are ${4\choose1}=4$ combinations such that 1| - + + + 2| + - + + 3| + + - + 4| + + + - or $N=4,n=2$. Then there are ${4\choose2}=6$ combinations such that 1| - - + + 2| - + - + 3| - + + - 4| + - - + 5| + - + - 6| + + - - So $n$ determines the number of - in each combination (each having $N$ elements). The final order of the combinations does not matter (i.e. whether - - + + or + - + - comes first is irrelevant). But is there a formula for $f_{i,k,n,N}$ (either taking value $-1$ or $+1$) such that we get the set of combinations: $$\left\{(f_{i,k,n,N}\ \text{with}\ i=1,2,\ldots N)\in\mathbb \{-1,1\}^N \mathrel{\bigg|} k=1,2,\ldots, {N\choose n}\right\}$$ Perhaps something like $f_{i,k,n,N}=(-1)^{i+k+\ldots}$ ?","For given $N,n\in\mathbb N$ I am looking for a formula that generates all $N\choose{n}$ combinations in the following way: E.g. take  $N=3,n=1$. Then there are ${3\choose1}=3$ combinations such that 1| - + + 2| + - + 3| + + - or $N=4,n=0$. Then there are ${4\choose0}=1$ combinations such that 1| + + + + or $N=4,n=1$. Then there are ${4\choose1}=4$ combinations such that 1| - + + + 2| + - + + 3| + + - + 4| + + + - or $N=4,n=2$. Then there are ${4\choose2}=6$ combinations such that 1| - - + + 2| - + - + 3| - + + - 4| + - - + 5| + - + - 6| + + - - So $n$ determines the number of - in each combination (each having $N$ elements). The final order of the combinations does not matter (i.e. whether - - + + or + - + - comes first is irrelevant). But is there a formula for $f_{i,k,n,N}$ (either taking value $-1$ or $+1$) such that we get the set of combinations: $$\left\{(f_{i,k,n,N}\ \text{with}\ i=1,2,\ldots N)\in\mathbb \{-1,1\}^N \mathrel{\bigg|} k=1,2,\ldots, {N\choose n}\right\}$$ Perhaps something like $f_{i,k,n,N}=(-1)^{i+k+\ldots}$ ?",,"['combinatorics', 'permutations', 'combinations']"
30,The best worst case scenario in MasterMind,The best worst case scenario in MasterMind,,"In the game of MasterMind , you are trying to guess a sequence of colours.  After each guess, your guess is graded: you find out how many are exactly right, and how many others are the right colour but out of sequence. In an actual game, it's possible to get very lucky and simply guess the correct answer on your first attempt. In a computer simulation, on the other hand, it's possible for the computer to change the correct answer without telling you, as long as it doesn't contradict any previous information it has given you.  I.e. the computer is forcing a worst case scenario upon the guesser.  I've written just such a simulation here: https://github.com/IBwWG/cheatermind My question for you is this: Is it possible, given a configuration of $C >= 2$ colours and $S >= 1$ slots, to determine a formula for the minimum number of moves one would have to make to win against a computer that's cheating this way? For example, the simplest configuration (like a coin toss) would have $M(2,1) = 2$, because the first guess will always be wrong, leaving only one other possibility.  No matter what you guess, it will take a minimum of two guesses to win.","In the game of MasterMind , you are trying to guess a sequence of colours.  After each guess, your guess is graded: you find out how many are exactly right, and how many others are the right colour but out of sequence. In an actual game, it's possible to get very lucky and simply guess the correct answer on your first attempt. In a computer simulation, on the other hand, it's possible for the computer to change the correct answer without telling you, as long as it doesn't contradict any previous information it has given you.  I.e. the computer is forcing a worst case scenario upon the guesser.  I've written just such a simulation here: https://github.com/IBwWG/cheatermind My question for you is this: Is it possible, given a configuration of $C >= 2$ colours and $S >= 1$ slots, to determine a formula for the minimum number of moves one would have to make to win against a computer that's cheating this way? For example, the simplest configuration (like a coin toss) would have $M(2,1) = 2$, because the first guess will always be wrong, leaving only one other possibility.  No matter what you guess, it will take a minimum of two guesses to win.",,"['combinatorics', 'optimization']"
31,"How many triples $(x,y,n)$ are there such that $x^n - y^n = 2^{100}$",How many triples  are there such that,"(x,y,n) x^n - y^n = 2^{100}","How many triples $(x,y) \in \mathbb{N^+}^2$ and $n \gt 1$ are there such that $x^n - y^n = 2^{100}$ I dont know how to start. Any hint will be helpful. I know the identity $x^n-y^n = (x-y)(x^{n-1} + x^{n-2}y + \cdots + xy^{n-2}+y^{n-1})$. I think from here we need some combinatorics to get the rest of answer.","How many triples $(x,y) \in \mathbb{N^+}^2$ and $n \gt 1$ are there such that $x^n - y^n = 2^{100}$ I dont know how to start. Any hint will be helpful. I know the identity $x^n-y^n = (x-y)(x^{n-1} + x^{n-2}y + \cdots + xy^{n-2}+y^{n-1})$. I think from here we need some combinatorics to get the rest of answer.",,"['combinatorics', 'algebra-precalculus']"
32,Rotating Kindergartners at Tables Monthly,Rotating Kindergartners at Tables Monthly,,"My wife teaches AM and PM kindergarten classes. AM has 14 students and PM 11. At the beginning of each month, she puts out a new seating chart where she rotates students in such a way that they (ideally) sit at a different table and with different students for that month. There are 3 students per table, but if numbers force the issue, the last may have more or less. We realize that, by the end of the year, there will be some unavoidable situations where students end up sitting with each other or at the same tables again, and this is okay. She works on this seating diagram every month and it's a huge chore. It's agonizing to see her do this because it's very time-consuming, and I feel helpless. I know there has to be a mathematical way to do it. I did find one formula on here, but couldn't figure out what the variables represented and how to change them to meet her needs as students come and go. Can anyone help me out? It would be even better if I could use Excel to automate this process.  [sorry if the tags are inappropriate; I just guessed]","My wife teaches AM and PM kindergarten classes. AM has 14 students and PM 11. At the beginning of each month, she puts out a new seating chart where she rotates students in such a way that they (ideally) sit at a different table and with different students for that month. There are 3 students per table, but if numbers force the issue, the last may have more or less. We realize that, by the end of the year, there will be some unavoidable situations where students end up sitting with each other or at the same tables again, and this is okay. She works on this seating diagram every month and it's a huge chore. It's agonizing to see her do this because it's very time-consuming, and I feel helpless. I know there has to be a mathematical way to do it. I did find one formula on here, but couldn't figure out what the variables represented and how to change them to meet her needs as students come and go. Can anyone help me out? It would be even better if I could use Excel to automate this process.  [sorry if the tags are inappropriate; I just guessed]",,"['combinatorics', 'linear-programming']"
33,If in all subsets of size k there exist at least one pair of elements in a relation...,If in all subsets of size k there exist at least one pair of elements in a relation...,,"I’ve recently got stuck on a theorem that seems to be true, but I am not sure if I am able to prove it: $\large\forall_{x\in\mathbb{P}_k(\mathbb{N})}\exists_{\left\{ y_1,y_2\right\}\subset x \land y_1 \neq y_2}\; \varphi(y_1,y_2) \rightarrow \exists_{x\in \mathbb{P}_k(\mathbb{N})}\forall_{\left\{y_1,y_2\right\} \subset x \land y_1 \neq y_2}\;\varphi(y_1,y_2)$ Where $\varphi$ is any symmetric predicate, i.e. $\varphi(y_1,y_2) \iff \varphi(y_2,y_1)$, and $\mathbb{P}_k(\mathbb{X})$ is the set of all subsets of $\mathbb{X}$ of size $k$. In simple words: for any symmetric relation on $\mathbb{N}$, if every subset of $\mathbb{N}$ of size k contains at least one pair of related elements, then in some subset of size k all pairs of elements are related. This statement is true for $k = 2$ and for $k = 3$ and while $k = 2$ is easy, $k = 3$ was proved by me using graphs (already a bit harder). I believe the proper method for such a theorem would be a proof by induction, however I can’t make the inductive step. Any thoughts? I really appreciate any help or hint. I also believe this to be quite an interesting theorem. EDIT: My proof was like this: I proved it by deducing without loss of generality how the graph of these relations would behave. I used for this 4 pairs of vertices (each pair having an edge between them, no other edges at the beginning). These edges are given, if by any deductive reasoning we obtain a triangle, then the theorem is proved. Each step of the proof consists of selecting 3 vertices that aren’t connected by any edge and choosing 2 of them and connecting them (in case you can’t do it without the loss of generality, you have to follow all possible routes). At each step you avoid at all cost creating a triangle. I was eventually forced to connect two vertices and by it created a triangle. Should I present the whole proof here? If so do you recommend any tool for drawing graphs and posting it here? Proof : Ramsey’s theorem may be easily used to prove this statement. Solved.","I’ve recently got stuck on a theorem that seems to be true, but I am not sure if I am able to prove it: $\large\forall_{x\in\mathbb{P}_k(\mathbb{N})}\exists_{\left\{ y_1,y_2\right\}\subset x \land y_1 \neq y_2}\; \varphi(y_1,y_2) \rightarrow \exists_{x\in \mathbb{P}_k(\mathbb{N})}\forall_{\left\{y_1,y_2\right\} \subset x \land y_1 \neq y_2}\;\varphi(y_1,y_2)$ Where $\varphi$ is any symmetric predicate, i.e. $\varphi(y_1,y_2) \iff \varphi(y_2,y_1)$, and $\mathbb{P}_k(\mathbb{X})$ is the set of all subsets of $\mathbb{X}$ of size $k$. In simple words: for any symmetric relation on $\mathbb{N}$, if every subset of $\mathbb{N}$ of size k contains at least one pair of related elements, then in some subset of size k all pairs of elements are related. This statement is true for $k = 2$ and for $k = 3$ and while $k = 2$ is easy, $k = 3$ was proved by me using graphs (already a bit harder). I believe the proper method for such a theorem would be a proof by induction, however I can’t make the inductive step. Any thoughts? I really appreciate any help or hint. I also believe this to be quite an interesting theorem. EDIT: My proof was like this: I proved it by deducing without loss of generality how the graph of these relations would behave. I used for this 4 pairs of vertices (each pair having an edge between them, no other edges at the beginning). These edges are given, if by any deductive reasoning we obtain a triangle, then the theorem is proved. Each step of the proof consists of selecting 3 vertices that aren’t connected by any edge and choosing 2 of them and connecting them (in case you can’t do it without the loss of generality, you have to follow all possible routes). At each step you avoid at all cost creating a triangle. I was eventually forced to connect two vertices and by it created a triangle. Should I present the whole proof here? If so do you recommend any tool for drawing graphs and posting it here? Proof : Ramsey’s theorem may be easily used to prove this statement. Solved.",,"['combinatorics', 'graph-theory', 'induction', 'ramsey-theory']"
34,number of distinct rotations of a string,number of distinct rotations of a string,,"How do we count the number of distinct rotations of string ? string s=""ABCD"" has four distinct rotations ""ABCD"", ""BCDA"", ""CDAB"" and ""DABC"" but  ABAB"" has only 2: ""ABAB"" and ""BABA"". More so, a string like ""BBBB"" has only 1 rotation.","How do we count the number of distinct rotations of string ? string s=""ABCD"" has four distinct rotations ""ABCD"", ""BCDA"", ""CDAB"" and ""DABC"" but  ABAB"" has only 2: ""ABAB"" and ""BABA"". More so, a string like ""BBBB"" has only 1 rotation.",,['combinatorics']
35,"Is there a ""balanced knapsacks"" problem with a known result?","Is there a ""balanced knapsacks"" problem with a known result?",,"You're going on a trip with some friends and want to share the load of the camping gear as evenly as possible. Each of you is equally strong, and each of your knapsacks is identical. Can the fairest distribution of the load be obtained without trying the brute-force approach of every possible combination? More formally, given: $n$ knapsacks of equal weight capacity $c$ a set $S$ of packages of arbitrary weights $\{w_1, w_2, ..., w_k\}$ with $\forall i : w_i \leq c, \sum_{i} w_i \leq nc$, all of which are to be put into the knapsacks then we want to minimize the difference between the weight of the heaviest knapsack and the weight of the lightest knapsack. Does this problem have a name and a known strategy for minimizing the stated difference? It seems NP-hard, at least.","You're going on a trip with some friends and want to share the load of the camping gear as evenly as possible. Each of you is equally strong, and each of your knapsacks is identical. Can the fairest distribution of the load be obtained without trying the brute-force approach of every possible combination? More formally, given: $n$ knapsacks of equal weight capacity $c$ a set $S$ of packages of arbitrary weights $\{w_1, w_2, ..., w_k\}$ with $\forall i : w_i \leq c, \sum_{i} w_i \leq nc$, all of which are to be put into the knapsacks then we want to minimize the difference between the weight of the heaviest knapsack and the weight of the lightest knapsack. Does this problem have a name and a known strategy for minimizing the stated difference? It seems NP-hard, at least.",,['combinatorics']
36,Riddle: Assigning Students into Groups,Riddle: Assigning Students into Groups,,"Suppose you had a classroom with 25 students. You want to assign 6 homework assignments over the course of the term and for each of these assignments students will work in groups of 5. But you want to do it so that no two students work in the same group for two different assignments. Is this possible, and if so how? I worked it out for the case of 25 students into groups of 5 and (I believe) $m^2$ students grouped into groups of $m$ if $m$ is a prime power. But these aren't all the possibilities. The conditions for situations that work are clearly if you have $n$ people put into groups of size $k$ you should have that $k$ divides n. But if you want it to work out so that you can have everyone work with everyone else exactly once with constant group sizes it should be the case $k-1$ divides $n-1$ since each student works with $k-1$ new students each time and they have a total of $n-1$ students they need to eventually work with. It turns out that the numbers n that satisfy this are $k + s k(k-1)$ for any nonnegative integer $s$ . So, $s = 0$ is trivial and $s = 1$ corresponds to the squares. So my question is: is it necessarily possible to solve this when $s > 1$ . That is: Is it possible to take a class with $k+s k(k-1)$ students, group them into groups of size $k$ for a series of assignments so that everyone works with everyone else exactly one time? Also, what about cases where there isn't a prime power number of students?","Suppose you had a classroom with 25 students. You want to assign 6 homework assignments over the course of the term and for each of these assignments students will work in groups of 5. But you want to do it so that no two students work in the same group for two different assignments. Is this possible, and if so how? I worked it out for the case of 25 students into groups of 5 and (I believe) students grouped into groups of if is a prime power. But these aren't all the possibilities. The conditions for situations that work are clearly if you have people put into groups of size you should have that divides n. But if you want it to work out so that you can have everyone work with everyone else exactly once with constant group sizes it should be the case divides since each student works with new students each time and they have a total of students they need to eventually work with. It turns out that the numbers n that satisfy this are for any nonnegative integer . So, is trivial and corresponds to the squares. So my question is: is it necessarily possible to solve this when . That is: Is it possible to take a class with students, group them into groups of size for a series of assignments so that everyone works with everyone else exactly one time? Also, what about cases where there isn't a prime power number of students?",m^2 m m n k k k-1 n-1 k-1 n-1 k + s k(k-1) s s = 0 s = 1 s > 1 k+s k(k-1) k,"['combinatorics', 'graph-theory']"
37,How to maximize the number of operations in process,How to maximize the number of operations in process,,"In my research project I have encountered the following problem, concerning a tuple of words in the formal language $L=\{0,1\}^*$, with $\epsilon$ denoting the empty word. If we are given an ordered triple of words  $(a,b,c)$, an operation on that tuple consists of replacing one of the $x\in\{a,b,c\}$ by $x0,\ x1,$ or $y$ such that $x\neq y\in\{a,b,c\}$, e.g: $$(\epsilon,\epsilon,\epsilon)\xrightarrow{b:=b1}(\epsilon,1,\epsilon)\xrightarrow{b:=b0}(\epsilon,10,\epsilon)\xrightarrow{c:=c1}(\epsilon,10,1)\xrightarrow{a:=b}(10,10,1) $$ Given a non-negative integer $h$, we say that $(a,b,c)$ is $h$-complete if the length of each of $a,b,c$ is $h$, that is $|a|=|b|=|c|=h$. We say that a series of operations is healthy if and only any tuple $(a,b,c)$ appears at most once. For example, the sequence $$(\epsilon,\epsilon,\epsilon)\xrightarrow{b:=b0}(\epsilon,1,\epsilon)\xrightarrow{ b:=c}(\epsilon,\epsilon,\epsilon)$$ is not healthy because $(\epsilon,\epsilon,\epsilon)$ appears twice. The length of a tuple $(a,b,c)$ is defined as $|(a,b,c)|=\max(|a|,|b|,|c|)$ My question: What is the maximum number of healthy operations in a sequence which can transform $(\epsilon,\epsilon,\epsilon)$ into an $h$-complete tuple with all the intermediate tuples have length less than or equal to $h$ The minimum number of operations is $h+2$, but I'm interested in the worst case, and my problem consists of a generalization for $n$ words and not just $3$. If you know any references for such problems, or have any idea about this problem, it will be appreciated! Edit : the answer for couples is $f_2(h)=\frac{(h+2)(h+1)}{2}-1$ when we are taking pairs $(x,y)$ instead of $3$-tuples $(a,b,c)$ If $h=1$ there is only two operations which can transform $(\epsilon,\epsilon)$ to $(0,0),(0,1),(1,0),(1,1)$ so: $$f_2(1)=2 $$ Suppose that there is only that the result is true for $h$ given two words of lenght $|x|=|y|=h+1$ my idea is described by the following process: $$(\epsilon,\epsilon)\underbrace{-------\rightarrow}_{m(h) \text{ operations}} \begin{Bmatrix} (0,0)\\ (0,1)\\  (1,0)\\  (0,0) \\ (w,w') \big/ |w|\text{or }|w'|>1 \end{Bmatrix}\underbrace{-------\rightarrow}_{x(h) \text{ operations}}  (x,y)$$ the added intermediate step is necessary (we can not complete the process without passing throught it) and one can prove that : $m(h)\leq h+2$ and clearly $x(h)\leq f_2(h)$ so: $$f_2(h+1)\leq f_2(h)+h+2$$ to complete the proof we have to construct a process with $f_2(h+1)=h+2+f_2(h)$ which can be done using the schema","In my research project I have encountered the following problem, concerning a tuple of words in the formal language $L=\{0,1\}^*$, with $\epsilon$ denoting the empty word. If we are given an ordered triple of words  $(a,b,c)$, an operation on that tuple consists of replacing one of the $x\in\{a,b,c\}$ by $x0,\ x1,$ or $y$ such that $x\neq y\in\{a,b,c\}$, e.g: $$(\epsilon,\epsilon,\epsilon)\xrightarrow{b:=b1}(\epsilon,1,\epsilon)\xrightarrow{b:=b0}(\epsilon,10,\epsilon)\xrightarrow{c:=c1}(\epsilon,10,1)\xrightarrow{a:=b}(10,10,1) $$ Given a non-negative integer $h$, we say that $(a,b,c)$ is $h$-complete if the length of each of $a,b,c$ is $h$, that is $|a|=|b|=|c|=h$. We say that a series of operations is healthy if and only any tuple $(a,b,c)$ appears at most once. For example, the sequence $$(\epsilon,\epsilon,\epsilon)\xrightarrow{b:=b0}(\epsilon,1,\epsilon)\xrightarrow{ b:=c}(\epsilon,\epsilon,\epsilon)$$ is not healthy because $(\epsilon,\epsilon,\epsilon)$ appears twice. The length of a tuple $(a,b,c)$ is defined as $|(a,b,c)|=\max(|a|,|b|,|c|)$ My question: What is the maximum number of healthy operations in a sequence which can transform $(\epsilon,\epsilon,\epsilon)$ into an $h$-complete tuple with all the intermediate tuples have length less than or equal to $h$ The minimum number of operations is $h+2$, but I'm interested in the worst case, and my problem consists of a generalization for $n$ words and not just $3$. If you know any references for such problems, or have any idea about this problem, it will be appreciated! Edit : the answer for couples is $f_2(h)=\frac{(h+2)(h+1)}{2}-1$ when we are taking pairs $(x,y)$ instead of $3$-tuples $(a,b,c)$ If $h=1$ there is only two operations which can transform $(\epsilon,\epsilon)$ to $(0,0),(0,1),(1,0),(1,1)$ so: $$f_2(1)=2 $$ Suppose that there is only that the result is true for $h$ given two words of lenght $|x|=|y|=h+1$ my idea is described by the following process: $$(\epsilon,\epsilon)\underbrace{-------\rightarrow}_{m(h) \text{ operations}} \begin{Bmatrix} (0,0)\\ (0,1)\\  (1,0)\\  (0,0) \\ (w,w') \big/ |w|\text{or }|w'|>1 \end{Bmatrix}\underbrace{-------\rightarrow}_{x(h) \text{ operations}}  (x,y)$$ the added intermediate step is necessary (we can not complete the process without passing throught it) and one can prove that : $m(h)\leq h+2$ and clearly $x(h)\leq f_2(h)$ so: $$f_2(h+1)\leq f_2(h)+h+2$$ to complete the proof we have to construct a process with $f_2(h+1)=h+2+f_2(h)$ which can be done using the schema",,"['combinatorics', 'computer-science', 'computational-complexity']"
38,A curious identity of weighted sums over multi-set permutations.,A curious identity of weighted sums over multi-set permutations.,,"Suppose we have $n$ balls which are the same except colors, denote $S$ to be the set of all different permutations of the balls.(i.e. the swap of two balls with the same color will be the same permutation) We now define a function from $S$ to $\mathbb{N}$ as follow: $$ f(\sigma)=\prod_{i=1}^nm_i $$ where $m_i=i$ if the $i$th ball in $\sigma$ has the same color with its preceding ball, otherwise let $m_i=1$. My question is: Does the identity $$\sum_{\sigma\in S}f(\sigma)=n!$$   hold for all coloring of the balls? Example: We can verify that if all the balls have pairwise distinct colors, then the identity trivially holds. If $n-1$ balls have the same color but one with different color, we will have$$\sum_{\sigma\in S}f(\sigma)=n!\left(\frac{1}{1*2}+\cdots+\frac{1}{i*(i+1)}+\cdots+\frac{1}{n}\right)=n!$$ If two balls have the same color and the rest have all the different colors, we well get$$\sum_{\sigma\in S}f(\sigma)=(n-2)!\left(2+3+\cdots+n+\frac{n(n-1)}{2}-n+1\right)=n!$$ I think the above evidence should not just be some kind of coincidence, but I can not find the combinatorial intuition behind it. So, can anyone prove the above identity?or find an counterexample to disprove it?","Suppose we have $n$ balls which are the same except colors, denote $S$ to be the set of all different permutations of the balls.(i.e. the swap of two balls with the same color will be the same permutation) We now define a function from $S$ to $\mathbb{N}$ as follow: $$ f(\sigma)=\prod_{i=1}^nm_i $$ where $m_i=i$ if the $i$th ball in $\sigma$ has the same color with its preceding ball, otherwise let $m_i=1$. My question is: Does the identity $$\sum_{\sigma\in S}f(\sigma)=n!$$   hold for all coloring of the balls? Example: We can verify that if all the balls have pairwise distinct colors, then the identity trivially holds. If $n-1$ balls have the same color but one with different color, we will have$$\sum_{\sigma\in S}f(\sigma)=n!\left(\frac{1}{1*2}+\cdots+\frac{1}{i*(i+1)}+\cdots+\frac{1}{n}\right)=n!$$ If two balls have the same color and the rest have all the different colors, we well get$$\sum_{\sigma\in S}f(\sigma)=(n-2)!\left(2+3+\cdots+n+\frac{n(n-1)}{2}-n+1\right)=n!$$ I think the above evidence should not just be some kind of coincidence, but I can not find the combinatorial intuition behind it. So, can anyone prove the above identity?or find an counterexample to disprove it?",,['combinatorics']
39,Building a 3D matrix of positive integers,Building a 3D matrix of positive integers,,"I'm trying to build a 3D matrix made up of positive integers that has very specific properties. The matrix dimensions are $N \times N \times (N+1)$ where $N$ is a positive integer. The matrix has two properties: Every one of the $(N+1)$ ""slices"" of size $N \times N$  of the matrix contains each of the numbers $1$ through $N^2$ exactly once. Assuming we look at each such slice as made up of rows and columns, then if we pick any two rows belonging to different slices, they have to have exactly one number in common (due to property 1, it might be sufficient to impose that the two rows have at most one number in common and still get property 2). Any ideas on whether this is easy or hard to achieve, and in the former case, what would be a way to achieve it?","I'm trying to build a 3D matrix made up of positive integers that has very specific properties. The matrix dimensions are $N \times N \times (N+1)$ where $N$ is a positive integer. The matrix has two properties: Every one of the $(N+1)$ ""slices"" of size $N \times N$  of the matrix contains each of the numbers $1$ through $N^2$ exactly once. Assuming we look at each such slice as made up of rows and columns, then if we pick any two rows belonging to different slices, they have to have exactly one number in common (due to property 1, it might be sufficient to impose that the two rows have at most one number in common and still get property 2). Any ideas on whether this is easy or hard to achieve, and in the former case, what would be a way to achieve it?",,"['combinatorics', 'combinatorial-designs']"
40,Maximum number of cyclic quadruplets in tournament,Maximum number of cyclic quadruplets in tournament,,"Consider a tournament with $n$ contestants - that is, a complete graph directed graph $K_n$ where each edge is pointed one way or the other. We call a subset $\{a,b,c\}$ a ""cyclic triplet"" if each of the three wins one of the two games against the other two. It is not hard to find a maximum number of cyclic triplets. We can argue by considering the triplets involving a particular contestant that the maximum number of ""cyclic triplets"" among such triplets occurs when he beats  half of the remaining contestants. Hence the global maximum occurs when everyone beats half the remaining ones. Now, define a subset $\{a,b,c,d\}$ to be a ""cyclic quadruplet"" if two contestants win two games against the other two, while the remaining two win one game. What is the maximum number of cyclic quadruplets?","Consider a tournament with $n$ contestants - that is, a complete graph directed graph $K_n$ where each edge is pointed one way or the other. We call a subset $\{a,b,c\}$ a ""cyclic triplet"" if each of the three wins one of the two games against the other two. It is not hard to find a maximum number of cyclic triplets. We can argue by considering the triplets involving a particular contestant that the maximum number of ""cyclic triplets"" among such triplets occurs when he beats  half of the remaining contestants. Hence the global maximum occurs when everyone beats half the remaining ones. Now, define a subset $\{a,b,c,d\}$ to be a ""cyclic quadruplet"" if two contestants win two games against the other two, while the remaining two win one game. What is the maximum number of cyclic quadruplets?",,"['combinatorics', 'graph-theory']"
41,Sets of size at least $k$ with intersection of size at most $1$ cool problem.,Sets of size at least  with intersection of size at most  cool problem.,k 1,"At the OMM School every student goes to at least $k$ classes and two classes have at most $1$ student in common. Prove there is a set of $k$ classes where all of those classes have the same amount of students. Thank you very much for reading. I have been having trouble finding ways to combine both of the requirements. I have tried looking at the students as sets of classes, classes as sets of students. I tried seeing it as several graphs to no avail. I also tried induction, but I think if it works we need a non-straightforward hypothesis. Thank you very much in advance Regards.","At the OMM School every student goes to at least $k$ classes and two classes have at most $1$ student in common. Prove there is a set of $k$ classes where all of those classes have the same amount of students. Thank you very much for reading. I have been having trouble finding ways to combine both of the requirements. I have tried looking at the students as sets of classes, classes as sets of students. I tried seeing it as several graphs to no avail. I also tried induction, but I think if it works we need a non-straightforward hypothesis. Thank you very much in advance Regards.",,['combinatorics']
42,Determining the number of colourings of regions of a pentagon by Burnside's Lemma,Determining the number of colourings of regions of a pentagon by Burnside's Lemma,,"I have the question: The symmetry of a regular pentagon has 10 elements. Use 4 colours to colour the 5 regions of the pentagon below. Determine what the total number of distinct colourings of the pentagon using Burnside's lemma/counting theorem. (Two colourings are considered to be the same if there is a symmetry of the regular pentagon that maps one colouring to the other) Is this how I would go about a question like this? My solution. I'll refer to each $|\operatorname{fix}(g)|$ by a particular letter. First, I have ' $A$ ', any one of the 4 colours could be chosen for each of the 5 regions. This gives $4^5$ . Then I have the rotations around the centre point, ' $B$ '. There are 4 rotations ( $\frac {1}{5}, \frac 25, \frac 35, \frac 45$ ), with each being able to one of the 4 colours. Therefore I have $4 \times 4$ possible choices. Finally ' $C$ ', I have the rotations in regards to 'cutting' through the edge. There are 5 edges. Each when 'cut' causes 2 'pairs' of opposite regions to swap/transpose. When transposed, these regions must be the colour which they were transposed with. So I have the axis (the cutting edge) which can be one of 4 colours and the each of the pairs which can also be one of the 4 colours. Therefore $C = 5 \times 4^3$ To find the number of colourings, the equation is: $$ \begin{align} \text{#Colourings}  &= \tfrac {1}{10}[A + B + C] \\ &= \tfrac {1}{10}[4^5 + (4 \times 4) + (5\times 4^3)] \\ &= \tfrac {1}{10}[1360] \\ &= 136. \end{align} $$ Is this the correct method to go about a problem like this/have I missed anything?","I have the question: The symmetry of a regular pentagon has 10 elements. Use 4 colours to colour the 5 regions of the pentagon below. Determine what the total number of distinct colourings of the pentagon using Burnside's lemma/counting theorem. (Two colourings are considered to be the same if there is a symmetry of the regular pentagon that maps one colouring to the other) Is this how I would go about a question like this? My solution. I'll refer to each by a particular letter. First, I have ' ', any one of the 4 colours could be chosen for each of the 5 regions. This gives . Then I have the rotations around the centre point, ' '. There are 4 rotations ( ), with each being able to one of the 4 colours. Therefore I have possible choices. Finally ' ', I have the rotations in regards to 'cutting' through the edge. There are 5 edges. Each when 'cut' causes 2 'pairs' of opposite regions to swap/transpose. When transposed, these regions must be the colour which they were transposed with. So I have the axis (the cutting edge) which can be one of 4 colours and the each of the pairs which can also be one of the 4 colours. Therefore To find the number of colourings, the equation is: Is this the correct method to go about a problem like this/have I missed anything?","|\operatorname{fix}(g)| A 4^5 B \frac {1}{5}, \frac 25, \frac 35, \frac 45 4 \times 4 C C = 5 \times 4^3 
\begin{align}
\text{#Colourings} 
&= \tfrac {1}{10}[A + B + C] \\
&= \tfrac {1}{10}[4^5 + (4 \times 4) + (5\times 4^3)] \\
&= \tfrac {1}{10}[1360] \\
&= 136.
\end{align}
","['combinatorics', 'polya-counting-theory']"
43,Sum of product of binomial coefficients and exponential function: $\sum^{n}_{k=0}2^k{{n+1}\choose k}{{r-n-2}\choose {n-k}}$,Sum of product of binomial coefficients and exponential function:,\sum^{n}_{k=0}2^k{{n+1}\choose k}{{r-n-2}\choose {n-k}},"I would like to know how to obtain (if it exists) a closed form expression of the sum $$S=\sum^{n}_{k=0}2^k{{n+1}\choose k}{{r-n-2}\choose {n-k}}$$ So far, I have tried to use the method of exponential generating functions to tackle this problem, but to no avail. That is, $$A(z)B(z)=\left(\sum^{\infty}_{n=0}a_n\frac{z^n}{n!}\right)\left(\sum^{\infty}_{n=0}b_n\frac{z^n}{n!}\right)=\sum^{\infty}_{n=0}\left(\sum^{n}_{k=0}{n\choose k}a_kb_{n-k}\right)\frac{z^n}{n!}$$ I then put the sum into the appropriate format. $$S=(n+1)(r-n-2)!\sum_{k=0}^{n}{n\choose k}\frac{2^k}{(n-k+1)!(r-2n+k-2)!}$$ Leting $a_k=\frac{2^k}{(n-k+1)!}$ and $b_k=\frac{1}{(r-2n+k-2)!}$, $$A(z)=\sum^{\infty}_{k=0}\frac{(2x)^k}{(n-k+1)!k!}=\frac{1}{(n+1)!}(1+2z)^{n+1}$$ $$B(z)=\sum^{\infty}_{k=0}\frac{x^k}{(r-n-k-2)!k!}=\frac{1}{(r-n-2)!}(1+z)^{r-n-2}$$ So $$S=[z^n](1+2z)^{n+1}(1+z)^{r-n-2}$$ and I am stuck. If I let $a_k=\frac{(\sqrt2)^k}{(n-k+1)!}$ and $b_k=\frac{(\sqrt2)^k}{(r-2n+k-2)!}$ I get $$S=[z^n](1+\sqrt2x)^{r-1}={{r-1}\choose n}2^{\frac{n}{2}}$$ but this answer doesn't even make sense since it isn't even an integer. I have no idea how to evaluate this sum, and would greatly appreciate any help offered.","I would like to know how to obtain (if it exists) a closed form expression of the sum $$S=\sum^{n}_{k=0}2^k{{n+1}\choose k}{{r-n-2}\choose {n-k}}$$ So far, I have tried to use the method of exponential generating functions to tackle this problem, but to no avail. That is, $$A(z)B(z)=\left(\sum^{\infty}_{n=0}a_n\frac{z^n}{n!}\right)\left(\sum^{\infty}_{n=0}b_n\frac{z^n}{n!}\right)=\sum^{\infty}_{n=0}\left(\sum^{n}_{k=0}{n\choose k}a_kb_{n-k}\right)\frac{z^n}{n!}$$ I then put the sum into the appropriate format. $$S=(n+1)(r-n-2)!\sum_{k=0}^{n}{n\choose k}\frac{2^k}{(n-k+1)!(r-2n+k-2)!}$$ Leting $a_k=\frac{2^k}{(n-k+1)!}$ and $b_k=\frac{1}{(r-2n+k-2)!}$, $$A(z)=\sum^{\infty}_{k=0}\frac{(2x)^k}{(n-k+1)!k!}=\frac{1}{(n+1)!}(1+2z)^{n+1}$$ $$B(z)=\sum^{\infty}_{k=0}\frac{x^k}{(r-n-k-2)!k!}=\frac{1}{(r-n-2)!}(1+z)^{r-n-2}$$ So $$S=[z^n](1+2z)^{n+1}(1+z)^{r-n-2}$$ and I am stuck. If I let $a_k=\frac{(\sqrt2)^k}{(n-k+1)!}$ and $b_k=\frac{(\sqrt2)^k}{(r-2n+k-2)!}$ I get $$S=[z^n](1+\sqrt2x)^{r-1}={{r-1}\choose n}2^{\frac{n}{2}}$$ but this answer doesn't even make sense since it isn't even an integer. I have no idea how to evaluate this sum, and would greatly appreciate any help offered.",,"['combinatorics', 'summation', 'binomial-coefficients']"
44,Alternating sum of a simple product of binomial coefficients: $\sum_{k=0}^{m} (-1)^k \binom m k \binom n k .$,Alternating sum of a simple product of binomial coefficients:,\sum_{k=0}^{m} (-1)^k \binom m k \binom n k .,"I would like to evaluate the following alternating sum of products of binomial coefficients: $$\sum_{k=0}^{m} (-1)^k \binom m k \binom n k .$$ I had the idea to use Pascal recursion to re-express $\binom n k$ so that we always have $m$ as the upper index and I have been able to come up with nice expressions for  $$ \sum_{k=0}^{m} (-1)^k \binom m k \binom m {k-j},$$ ($j=0$ gives the central binomial coefficient as is well known and the others turn out to be shifted away from the centre by $j$ steps, up to a sign). However we then end up with another alternating sum of products of these solutions with the binomial coefficients that came out of using the recursion. And this sum seems to be even worse to solve, at least combinatorially. Any help appreciated! Thanks in advance.","I would like to evaluate the following alternating sum of products of binomial coefficients: $$\sum_{k=0}^{m} (-1)^k \binom m k \binom n k .$$ I had the idea to use Pascal recursion to re-express $\binom n k$ so that we always have $m$ as the upper index and I have been able to come up with nice expressions for  $$ \sum_{k=0}^{m} (-1)^k \binom m k \binom m {k-j},$$ ($j=0$ gives the central binomial coefficient as is well known and the others turn out to be shifted away from the centre by $j$ steps, up to a sign). However we then end up with another alternating sum of products of these solutions with the binomial coefficients that came out of using the recursion. And this sum seems to be even worse to solve, at least combinatorially. Any help appreciated! Thanks in advance.",,"['combinatorics', 'summation', 'binomial-coefficients']"
45,"Schur functors as spaces of ""flag tensors""?","Schur functors as spaces of ""flag tensors""?",,"Consider the following construction: for a vector space $V$, define $W \subseteq \bigwedge^2 V \otimes V$ by $W = \langle\ \alpha \otimes v : v \in \text{Span}(\alpha) \ \rangle$, that is, $W$ is spanned by ""flag tensors"", as in a 2-plane containing a line. Of course, we can make similar constructions for arbitrary shapes of flags. How is $W$ related to the Schur functor $\mathbb{S}^{2,1}(V)$? (Edit: I have answered this particular instance of the question. See below.) Note that the generators of $W$ satisfy the same ""exchange relations"" used to define the Schur functor (e.g. in Fulton's Young Tableaux ): for example, if $\alpha = x \wedge y$, and $v = ax + by$, then by playing around with the tensors one can show $x \wedge y \otimes v = v \wedge y \otimes x + x \wedge v \otimes y$, which is the defining relation used to construct $\mathbb{S}^{2,1}(V)$ as a quotient of $\bigwedge^2 V \otimes V$ (by modding out by it). This works for all the other exchange relations for other shapes of flag as well. The quotient picture is nice to analyze (e.g. finding a basis takes some relatively straightforward combinatorics), and is very natural for algebraic geometry, since it corresponds to the surjection $H^0(\mathbb{P}(\bigwedge^2 V) \times \mathbb{P}(V),\mathcal{O}(1,1)) \to H^0(Fl^{2,1}(V),\mathcal{O}_{Fl^{2,1}(V)}(1,1)),$ coming from the Plücker embedding of the (2,1)-flag variety. (It's a general fact that the Schur functors give the multigraded components of the flag variety's Plücker coordinate ring in this way.) On the other hand, the setup above with ""flag tensors"" is appealingly simple and I'd like to understand it. For example, the definition of $W$ is clearly functorial and a $GL$-subrepresentation (the condition $v \in \text{Span}(\alpha)$ is $GL$-invariant). Is it actually (or almost) the same space? Is it simply dual to the quotient picture somehow? (Perhaps my $W$ is just $\mathbb{S}^\lambda(V^*)$ or something.) Or is it entirely different? I got confused when I tried to work this out, particularly since (a) there are other ways of constructing Schur functors as subspaces rather than quotients, (b) I'm not sure how to define $W$ for a partition $\lambda$ with repeated column lengths. For instance, $\lambda = (2,2,2,1)$ should come from $Sym^3(\bigwedge^2V) \otimes V$. Should the corresponding ""flag tensors"" be of the form $\alpha_1 \alpha_2 \alpha_3 \otimes v$, where $v \in \text{Span}(\alpha_i)$ for each $i$? Thanks! Edit: A quick way to see that the $W$ given initially is isomorphic to $\mathbb{S}^{2,1}(V)$ is to use the Pieri rule, which in this case says that $\bigwedge^2V \otimes V \cong \mathbb{S}^{2,1}(V) \oplus \bigwedge^3 V$. And the definition guaranteed that $W = \ker\left( \bigwedge^2V \otimes V \to \bigwedge^3 V\right).$","Consider the following construction: for a vector space $V$, define $W \subseteq \bigwedge^2 V \otimes V$ by $W = \langle\ \alpha \otimes v : v \in \text{Span}(\alpha) \ \rangle$, that is, $W$ is spanned by ""flag tensors"", as in a 2-plane containing a line. Of course, we can make similar constructions for arbitrary shapes of flags. How is $W$ related to the Schur functor $\mathbb{S}^{2,1}(V)$? (Edit: I have answered this particular instance of the question. See below.) Note that the generators of $W$ satisfy the same ""exchange relations"" used to define the Schur functor (e.g. in Fulton's Young Tableaux ): for example, if $\alpha = x \wedge y$, and $v = ax + by$, then by playing around with the tensors one can show $x \wedge y \otimes v = v \wedge y \otimes x + x \wedge v \otimes y$, which is the defining relation used to construct $\mathbb{S}^{2,1}(V)$ as a quotient of $\bigwedge^2 V \otimes V$ (by modding out by it). This works for all the other exchange relations for other shapes of flag as well. The quotient picture is nice to analyze (e.g. finding a basis takes some relatively straightforward combinatorics), and is very natural for algebraic geometry, since it corresponds to the surjection $H^0(\mathbb{P}(\bigwedge^2 V) \times \mathbb{P}(V),\mathcal{O}(1,1)) \to H^0(Fl^{2,1}(V),\mathcal{O}_{Fl^{2,1}(V)}(1,1)),$ coming from the Plücker embedding of the (2,1)-flag variety. (It's a general fact that the Schur functors give the multigraded components of the flag variety's Plücker coordinate ring in this way.) On the other hand, the setup above with ""flag tensors"" is appealingly simple and I'd like to understand it. For example, the definition of $W$ is clearly functorial and a $GL$-subrepresentation (the condition $v \in \text{Span}(\alpha)$ is $GL$-invariant). Is it actually (or almost) the same space? Is it simply dual to the quotient picture somehow? (Perhaps my $W$ is just $\mathbb{S}^\lambda(V^*)$ or something.) Or is it entirely different? I got confused when I tried to work this out, particularly since (a) there are other ways of constructing Schur functors as subspaces rather than quotients, (b) I'm not sure how to define $W$ for a partition $\lambda$ with repeated column lengths. For instance, $\lambda = (2,2,2,1)$ should come from $Sym^3(\bigwedge^2V) \otimes V$. Should the corresponding ""flag tensors"" be of the form $\alpha_1 \alpha_2 \alpha_3 \otimes v$, where $v \in \text{Span}(\alpha_i)$ for each $i$? Thanks! Edit: A quick way to see that the $W$ given initially is isomorphic to $\mathbb{S}^{2,1}(V)$ is to use the Pieri rule, which in this case says that $\bigwedge^2V \otimes V \cong \mathbb{S}^{2,1}(V) \oplus \bigwedge^3 V$. And the definition guaranteed that $W = \ker\left( \bigwedge^2V \otimes V \to \bigwedge^3 V\right).$",,"['combinatorics', 'algebraic-geometry', 'representation-theory', 'schubert-calculus']"
46,Number of ways to seat nine people around circular table if no two people from the same country sit in adjacent seats,Number of ways to seat nine people around circular table if no two people from the same country sit in adjacent seats,,"Problem : Nine delegates, three each from three different countries, should be seated at a round table that seats nine people. How many different ways are there to seat them in such a way that no two delegates from the same country sit near each other? All the delegates are different, and arrangements that differ only by rotation are considered the same. Solution: I've found a dull solution for the problem. You just fix some guy from one of the countries in the ""first"" place and build all possible correct arrangements. First you consider all the different ways two other guys from the same country can be placed. And after that one can just see that leftover places are split into one of the three possible groups $1 + 2 + 3$ , $1 + 1 + 4$ , $2+2+2$ . For each of the splits you count number of ways to seat other delegates and thus find the answer. But this method involves drawing a lot of tables and seems like prettified brute force solution. Question: is there another more elegant way of solving the problem? Statement reminds of Lovász local lemma , but this lemma gives only some bound for probability. May be there are some another theorem on coloring or something like this? Thanks in advance for any ideas.","Problem : Nine delegates, three each from three different countries, should be seated at a round table that seats nine people. How many different ways are there to seat them in such a way that no two delegates from the same country sit near each other? All the delegates are different, and arrangements that differ only by rotation are considered the same. Solution: I've found a dull solution for the problem. You just fix some guy from one of the countries in the ""first"" place and build all possible correct arrangements. First you consider all the different ways two other guys from the same country can be placed. And after that one can just see that leftover places are split into one of the three possible groups , , . For each of the splits you count number of ways to seat other delegates and thus find the answer. But this method involves drawing a lot of tables and seems like prettified brute force solution. Question: is there another more elegant way of solving the problem? Statement reminds of Lovász local lemma , but this lemma gives only some bound for probability. May be there are some another theorem on coloring or something like this? Thanks in advance for any ideas.",1 + 2 + 3 1 + 1 + 4 2+2+2,"['combinatorics', 'discrete-mathematics']"
47,Continuity of a map with constrains,Continuity of a map with constrains,,"Let  $A_i$ be a disjoint union of finite number of closed sub intervals of $[0,1]$, $1\leq i\leq n$. Each of $A_i$ has non-empty intersection with $A_j$. However, the intersection of each triple of $A_i$'s is empty. Let $h$ be a map from $[0,1]$ to $[0,1]$, such that for all $i$ the map $h$ sends $A_i$ into its complement. Is it possible to find $A_i$ and $h$, so that $h$ is homeomorphism? I know how to do that for $n=1,2,3$. EDIT, stronger related question: Let  $A_i$ be a family of sets of the circle $S^1$, so that: 1) Each $A_i$ is a union of open intervals 2) for all indices i, j, intersection of $A_i$ and $A_j$ is not empty, 3) for any point p in $S^1$, there are at most two indices, i and j, say, so that p is in $A_i$ and $A_j$. 4) There is h a homeomorphism of $S^1$ so that for all indices i, $hA_i$ contains the complement of $A_i$,","Let  $A_i$ be a disjoint union of finite number of closed sub intervals of $[0,1]$, $1\leq i\leq n$. Each of $A_i$ has non-empty intersection with $A_j$. However, the intersection of each triple of $A_i$'s is empty. Let $h$ be a map from $[0,1]$ to $[0,1]$, such that for all $i$ the map $h$ sends $A_i$ into its complement. Is it possible to find $A_i$ and $h$, so that $h$ is homeomorphism? I know how to do that for $n=1,2,3$. EDIT, stronger related question: Let  $A_i$ be a family of sets of the circle $S^1$, so that: 1) Each $A_i$ is a union of open intervals 2) for all indices i, j, intersection of $A_i$ and $A_j$ is not empty, 3) for any point p in $S^1$, there are at most two indices, i and j, say, so that p is in $A_i$ and $A_j$. 4) There is h a homeomorphism of $S^1$ so that for all indices i, $hA_i$ contains the complement of $A_i$,",,"['general-topology', 'combinatorics']"
48,number of potential couples,number of potential couples,,"A potential couple is a pair of a man and a woman that like each other (assume that 'like' is a symmetric relation). Given a group of $M$ men and $W$ women, I want to know how many different potential couples there are; mark this number by $C(M,W)$. Suppose we know that, in a certain group of men and women, $C(3,3) \geq 1$, i.e., in every triple of men and triple of women, there is at least one man and one woman that like each other. What is a lower bound for $C(M,W)$? I started by looking at $C(3,4)$. If there are 3 men and 4 women, we can put one woman aside, then we know that there is a potential couple within the remaining 3 men and 3 women, then we can put the woman of that couple aside and return the 4th woman, then again we have 3 men and 3 women that must contain a different potential couple, so the total number of couples must be at least 2: $C(3,4) \geq 2$. The same goes for 4 men and 3 women (in general, $C(M,W)=C(W,M)$). Continuing the same way, $C(3,W)=C(W,3) \geq W-2$. A similar calculation leads to: $C(4,W) \geq W-1$. However, for $C(4,6)$ we can get a better bound than $5$ - since $C(3,6) \geq 4$, at least one of the 3 men must be involved in at least 2 potential couples. If we put this man aside, and then bring the 4th man, that 4th man must be involved in 2 potential couples. Therefore, $C(4,6) \geq C(3,6)+2 \geq 6$. In general, for calculating a lower bound on $C(M,W)$, we can EITHER take a lower bound on $C(M-1,W)$, divide it by M, take the ceiling and add, OR take a lower bound on $C(M,W-1)$, divide it by W, take the ceiling and add. So to get the best lower bound, we should take the maximum of these two. I created a spreadsheet with the lower bounds on $C(M,W)$ up to $M=W=21$, where you can see the exact formula that I used. I cannot see any pattern - can you? Can you suggest a closed formula for $C(M,W)$, or at least an asymptotic bound? EDIT: András Salamon helped me clarify what I mean: Let $Q$ be the bipartite graph with 3 vertices in each bipartition, and containing no edges. I am looking for a lower bound on the number of different edges in a $Q$-free bipartite graph with partitions of size $M$ and $W$.","A potential couple is a pair of a man and a woman that like each other (assume that 'like' is a symmetric relation). Given a group of $M$ men and $W$ women, I want to know how many different potential couples there are; mark this number by $C(M,W)$. Suppose we know that, in a certain group of men and women, $C(3,3) \geq 1$, i.e., in every triple of men and triple of women, there is at least one man and one woman that like each other. What is a lower bound for $C(M,W)$? I started by looking at $C(3,4)$. If there are 3 men and 4 women, we can put one woman aside, then we know that there is a potential couple within the remaining 3 men and 3 women, then we can put the woman of that couple aside and return the 4th woman, then again we have 3 men and 3 women that must contain a different potential couple, so the total number of couples must be at least 2: $C(3,4) \geq 2$. The same goes for 4 men and 3 women (in general, $C(M,W)=C(W,M)$). Continuing the same way, $C(3,W)=C(W,3) \geq W-2$. A similar calculation leads to: $C(4,W) \geq W-1$. However, for $C(4,6)$ we can get a better bound than $5$ - since $C(3,6) \geq 4$, at least one of the 3 men must be involved in at least 2 potential couples. If we put this man aside, and then bring the 4th man, that 4th man must be involved in 2 potential couples. Therefore, $C(4,6) \geq C(3,6)+2 \geq 6$. In general, for calculating a lower bound on $C(M,W)$, we can EITHER take a lower bound on $C(M-1,W)$, divide it by M, take the ceiling and add, OR take a lower bound on $C(M,W-1)$, divide it by W, take the ceiling and add. So to get the best lower bound, we should take the maximum of these two. I created a spreadsheet with the lower bounds on $C(M,W)$ up to $M=W=21$, where you can see the exact formula that I used. I cannot see any pattern - can you? Can you suggest a closed formula for $C(M,W)$, or at least an asymptotic bound? EDIT: András Salamon helped me clarify what I mean: Let $Q$ be the bipartite graph with 3 vertices in each bipartition, and containing no edges. I am looking for a lower bound on the number of different edges in a $Q$-free bipartite graph with partitions of size $M$ and $W$.",,"['combinatorics', 'recurrence-relations', 'ramsey-theory']"
49,Creating generating functions for integer partitions,Creating generating functions for integer partitions,,"Say I have a generating function $\Phi_\mathcal{A}$ for the set of partitions $\mathcal{A}$ which have no parts congruent to 2 mod 4, and I have the generating function for $\Phi_\mathcal{B}$ for the set of partitions $\mathcal{B}$ in which the parts divisible by 4 occur at most once, can I multiply the 2 generating functions together to obtain the generating function for the intersection of $\mathcal{A}$ and $\mathcal{B}$ (i.e for the partitions that satisfy both requirements)? And more importantly, is this a technique that I can use for arbitrary such conditions? The reason I ask is because my homework assignment contains several questions which require me to give the generating function for partitions that have some property AND some other property, and I wanted to know if this technique was a good/valid one to use for these problems. Also, is there a similar technique for giving the generating function for integer partitions that have some property OR some other property? Thanks!","Say I have a generating function $\Phi_\mathcal{A}$ for the set of partitions $\mathcal{A}$ which have no parts congruent to 2 mod 4, and I have the generating function for $\Phi_\mathcal{B}$ for the set of partitions $\mathcal{B}$ in which the parts divisible by 4 occur at most once, can I multiply the 2 generating functions together to obtain the generating function for the intersection of $\mathcal{A}$ and $\mathcal{B}$ (i.e for the partitions that satisfy both requirements)? And more importantly, is this a technique that I can use for arbitrary such conditions? The reason I ask is because my homework assignment contains several questions which require me to give the generating function for partitions that have some property AND some other property, and I wanted to know if this technique was a good/valid one to use for these problems. Also, is there a similar technique for giving the generating function for integer partitions that have some property OR some other property? Thanks!",,"['combinatorics', 'generating-functions', 'integer-partitions']"
50,"""8 Dice arranged as a Cube"" Face-Sum Problem","""8 Dice arranged as a Cube"" Face-Sum Problem",,"I found this here : Sum Problem Given eight dice. Build a $2\times 2\times2$ cube, so that the sum of the points on each side is the same. $\hskip2.7in$ Here is one of  20 736 solutions with the sum 14. You find more at the German magazine ""Bild der Wissenschaft 3-1980"". Now I have three ( Question 1 moved here ) questions: Is $14$ the only possible face sum? At least, in the example given, it seems to related to the fact, that on every face two dice-pairs show up, having $n$ and $7-n$ pips . Is this necessary? Sufficient it is... How do they get $20736$? This is the dimension of the related group and factors to $2^8\times 3^4$, the number of group elements, right? i. I can get $2^3$, by the following: In the example given, you can split along the $xy$ ($yz,zx$) plane and then interchange the $2$ blocks of $4$ dice. Wlog, mirroring at $xy$ commutes with $yz$ (both just invert the $z$ resp. $x$ coordinate, right), so we get $2^3$ group lements. $$ $$   ii. The factor $3$ looks related to rotations throught the diagonals. But without my role playing set at hand, I can't work that out. $$ $$   iii. Would rolling the overall die around an axis also count, since back and front always shows a ""rotated"" pattern? This would give six $90^\circ$-rotations and three $180^\circ$-rotations, $9=3^2$ in total.    $$ \\ $$   Where do the missing $2^5\times 3^2$ come from? Is the reference given, online available? EDIT And to not make tehshrike sad again , here's the special question for $D4$: What face sum is possible, so that the sum of the points on each side is the same , when you pile up 4 D4's to a pyramid (plus the octahedron mentioned by Henning) and how many representations, would such a pyramid have? Thanks","I found this here : Sum Problem Given eight dice. Build a $2\times 2\times2$ cube, so that the sum of the points on each side is the same. $\hskip2.7in$ Here is one of  20 736 solutions with the sum 14. You find more at the German magazine ""Bild der Wissenschaft 3-1980"". Now I have three ( Question 1 moved here ) questions: Is $14$ the only possible face sum? At least, in the example given, it seems to related to the fact, that on every face two dice-pairs show up, having $n$ and $7-n$ pips . Is this necessary? Sufficient it is... How do they get $20736$? This is the dimension of the related group and factors to $2^8\times 3^4$, the number of group elements, right? i. I can get $2^3$, by the following: In the example given, you can split along the $xy$ ($yz,zx$) plane and then interchange the $2$ blocks of $4$ dice. Wlog, mirroring at $xy$ commutes with $yz$ (both just invert the $z$ resp. $x$ coordinate, right), so we get $2^3$ group lements. $$ $$   ii. The factor $3$ looks related to rotations throught the diagonals. But without my role playing set at hand, I can't work that out. $$ $$   iii. Would rolling the overall die around an axis also count, since back and front always shows a ""rotated"" pattern? This would give six $90^\circ$-rotations and three $180^\circ$-rotations, $9=3^2$ in total.    $$ \\ $$   Where do the missing $2^5\times 3^2$ come from? Is the reference given, online available? EDIT And to not make tehshrike sad again , here's the special question for $D4$: What face sum is possible, so that the sum of the points on each side is the same , when you pile up 4 D4's to a pyramid (plus the octahedron mentioned by Henning) and how many representations, would such a pyramid have? Thanks",,"['combinatorics', 'recreational-mathematics', 'puzzle', 'dice']"
51,Permutations of a set with a conditional subset,Permutations of a set with a conditional subset,,"Using the digits 1, 2, 3, 5, 6, 8, 0 only once, how many 4-digit numbers could be constructed if the number is even? This is an exercise from an online course I'm taking. The given solution suggests splitting the calculation into two cases, the sum of which gives our answer. Case 1: The last digit is 0. This is simple enough; we have P(6,3) permutations in Case 1. Case 2: The last digit is one of 2, 6, 8. In Case 2, there are fewer choices for the last digit than there are digits. There is a chance that we'll have no numbers for the last digit if they are included in the counting for the previous digits. The written solution suggests 5*5*4*3 is the number of permutations in Case 2. It seems they're not counting 0 for the first digit. Evidently they're also withholding one even number from the calculation to ensure there's at least one available for the last digit. This is the part that I'm having trouble accepting. To my understanding, the reasoning behind using factorials to calculate permutations in the first place is that, throughout a calculation such as with the above Case 1, whenever an object is counted, it is then omitted from the rest of the calculation. In Case 2, the even numbers have a distinguishing property: How is it that we can count 3 possibilities for the last digit and still get the right answer if we are also counting some of those possibilities in the previous digits?","Using the digits 1, 2, 3, 5, 6, 8, 0 only once, how many 4-digit numbers could be constructed if the number is even? This is an exercise from an online course I'm taking. The given solution suggests splitting the calculation into two cases, the sum of which gives our answer. Case 1: The last digit is 0. This is simple enough; we have P(6,3) permutations in Case 1. Case 2: The last digit is one of 2, 6, 8. In Case 2, there are fewer choices for the last digit than there are digits. There is a chance that we'll have no numbers for the last digit if they are included in the counting for the previous digits. The written solution suggests 5*5*4*3 is the number of permutations in Case 2. It seems they're not counting 0 for the first digit. Evidently they're also withholding one even number from the calculation to ensure there's at least one available for the last digit. This is the part that I'm having trouble accepting. To my understanding, the reasoning behind using factorials to calculate permutations in the first place is that, throughout a calculation such as with the above Case 1, whenever an object is counted, it is then omitted from the rest of the calculation. In Case 2, the even numbers have a distinguishing property: How is it that we can count 3 possibilities for the last digit and still get the right answer if we are also counting some of those possibilities in the previous digits?",,"['combinatorics', 'permutations']"
52,Self-avoiding walks,Self-avoiding walks,,"Let $c_n$ be the number of self-avoiding walks in ${\mathbb Z}^2$ of length $n$. Because $c_n$ is a submultiplcative sequence ($c_{n+m} \leq c_nc_m$ for all $n, m \geq 1$), Fekete's lemma tells us that $\lim_{n \rightarrow \infty} c_n^{1/n}$ exists and equals $\inf c_n^{1/n}$. So we can define the connective constant $\mu = \lim_{n \rightarrow \infty} c_n^{1/n}$ that governs the growth rate of $c_n$, and if we happen to know a particular $c_n$ that gives a rigourous upper bound on $\mu$, namely $\mu \leq c_n^{1/n}$. On page 10 of Madras and Slade's 1993 book ""The self-avoiding walk"", a better bound for $\mu$ is given: $$ \mu \leq \left(\frac{c_n}{c_1}\right)^\frac{1}{n-1} ~~~~~(n \geq 2). $$ This bound is attributed to Alm, but the only reference is to an unpublished manuscript of Ahlberg and Janson from 1980. Does anyone know a good proof/reference for this bound? It would be implied by submultiplicativity of $a_n := c_{n+1}/c_1$, which in turn would be implied by the inequality $c_{n+m-1}c_1 \leq c_nc_m$ for all $n, m \geq 1$.","Let $c_n$ be the number of self-avoiding walks in ${\mathbb Z}^2$ of length $n$. Because $c_n$ is a submultiplcative sequence ($c_{n+m} \leq c_nc_m$ for all $n, m \geq 1$), Fekete's lemma tells us that $\lim_{n \rightarrow \infty} c_n^{1/n}$ exists and equals $\inf c_n^{1/n}$. So we can define the connective constant $\mu = \lim_{n \rightarrow \infty} c_n^{1/n}$ that governs the growth rate of $c_n$, and if we happen to know a particular $c_n$ that gives a rigourous upper bound on $\mu$, namely $\mu \leq c_n^{1/n}$. On page 10 of Madras and Slade's 1993 book ""The self-avoiding walk"", a better bound for $\mu$ is given: $$ \mu \leq \left(\frac{c_n}{c_1}\right)^\frac{1}{n-1} ~~~~~(n \geq 2). $$ This bound is attributed to Alm, but the only reference is to an unpublished manuscript of Ahlberg and Janson from 1980. Does anyone know a good proof/reference for this bound? It would be implied by submultiplicativity of $a_n := c_{n+1}/c_1$, which in turn would be implied by the inequality $c_{n+m-1}c_1 \leq c_nc_m$ for all $n, m \geq 1$.",,"['combinatorics', 'reference-request']"
53,Traversing the infinite square grid,Traversing the infinite square grid,,"Suppose we start at $(0.5,0.5)$ in an infinite unit square grid, and our goal is to traverse every square on the board. At move $n$ one must take $a_n$ steps in one of the directions, north,south, east or west. And every square we walk over is marked as visited, we are not allowed to walk over a visited square twice. Is there a sequence of directions, such that we can visit every square of the board exactly once if $a_n=n$? Is there such a sequence if we are allowed to walk in diagonal directions aswell? Is there a general algorithm to check, given $a_n$, if a path exists? Is there a path in any of the above cases for $a_n=n^2$?","Suppose we start at $(0.5,0.5)$ in an infinite unit square grid, and our goal is to traverse every square on the board. At move $n$ one must take $a_n$ steps in one of the directions, north,south, east or west. And every square we walk over is marked as visited, we are not allowed to walk over a visited square twice. Is there a sequence of directions, such that we can visit every square of the board exactly once if $a_n=n$? Is there such a sequence if we are allowed to walk in diagonal directions aswell? Is there a general algorithm to check, given $a_n$, if a path exists? Is there a path in any of the above cases for $a_n=n^2$?",,"['geometry', 'combinatorics', 'number-theory', 'graph-theory', 'combinatorial-game-theory']"
54,Partition function- without duplicates,Partition function- without duplicates,,"Is there a function, equivalent to the partition function, that does not allow duplication? Or, alternatively, for any N, how many partitions would there be- disallowing any that have the same integer appearing more than once. Edit: Sorry, to be more accurate, I'd like to know a function, or even just it's asymptotic complexity, which will produce the partitions of the input, excepting those which have integers that occur more than once. I've only just realized that this is the actual logical equivalent to my problem; I appreciate that I haven't exactly posted much effort into finding it myself. Unless someone comes back and posts a solution relatively quickly, you can expect more from me soon.","Is there a function, equivalent to the partition function, that does not allow duplication? Or, alternatively, for any N, how many partitions would there be- disallowing any that have the same integer appearing more than once. Edit: Sorry, to be more accurate, I'd like to know a function, or even just it's asymptotic complexity, which will produce the partitions of the input, excepting those which have integers that occur more than once. I've only just realized that this is the actual logical equivalent to my problem; I appreciate that I haven't exactly posted much effort into finding it myself. Unless someone comes back and posts a solution relatively quickly, you can expect more from me soon.",,"['number-theory', 'combinatorics']"
55,Mathematics related to the card game SET,Mathematics related to the card game SET,,"Last month, I was introduced to the card game SET. The game raises several interesting questions eg what's the probability that n randomly drawn cards contain k sets, is it possible to end with 12 (or 15) cards which contain no sets... I would like to present the solution to a question like this to undergrads, and through it introduce them to an area of mathematics. For example, as mentioned previously , there is the issue of maximal caps, which Davis and MacLagan's paper relates to projective space and error-correcting codes. Can you give me any similar ideas? Perhaps relating to a variation of SET listed here ?","Last month, I was introduced to the card game SET. The game raises several interesting questions eg what's the probability that n randomly drawn cards contain k sets, is it possible to end with 12 (or 15) cards which contain no sets... I would like to present the solution to a question like this to undergrads, and through it introduce them to an area of mathematics. For example, as mentioned previously , there is the issue of maximal caps, which Davis and MacLagan's paper relates to projective space and error-correcting codes. Can you give me any similar ideas? Perhaps relating to a variation of SET listed here ?",,['combinatorics']
56,No. of ways to arrange a duplicated list of numbers so that a copy of the list appears in order but not necessarily together,No. of ways to arrange a duplicated list of numbers so that a copy of the list appears in order but not necessarily together,,"I was making combinatorics exercises for some students when I stumped myself with a question I came up with. Question Bob has ten blue counters, labelled 1, 2, 3, 4, 5, 1, 2, 3, 4, 5. If he rearranges all ten randomly in a line, how many different arrangements include a subsequence of five counters that read 1, 2, 3, 4, 5 in that order (but not necessarily together)? For example, 1 , 3, 2 , 5, 1, 4, 3 , 4 , 5 , 2 would satisfy the conditions. So what have I tried? I tried simplifying the problem to: two counters (1, 1) in which the number of ways the subsequence 1 appears somewhere is (trivially) 1. four counters (1, 2, 1, 2) in which the number of ways the subsequence 1, 2 appears somewhere is 5. six counters (1, 2, 3, 1, 2, 3) in which the number of ways the subsequence 1, 2, 3 appears somewhere is 47. I verified this in two ways. Firstly, I wrote out all 90 cases and counted manually. Then, I realised that any case where the subsequence 1, 2, 3 appears in order has the subsequence 1, 2 appearing in order. So, any solution to the 6-counter problem is simply a solution to the 4-counter problem, plus two carefully-positioned 3s. This broke the question into 5 cases which were simpler to exhaust. For the question itself, I know the answer is lower than $10P5$ . $10P5$ is the answer to the following method: Given ten positions in a line, pick five to permute (i.e, place the counters 1, 2, 3, 4, 5 on, in a random order). Then place the remaining counters 1, 2, 3, 4, 5 in that order in the remaining positions. However, this grossly overcounts many cases. I think it overcounts each time a case has multiple subsequences of 1, 2, 3, 4, 5. For example, the case of 1, 1, 2, 2, 3, 3, 4, 4, 5, 5 is counted (I think) $2^5 = 32$ times. The case of 1 , 2, 4, 2, 3 , 4 , 3, 5, 5, 1 is counted four times. This is because every subsequence of 1, 2, 3, 4, 5 must include the bolded 1, 3 and 4, but there are two options for the 2s and two options for the 5s. So there are four subsequences of 1, 2, 3, 4, 5 in this case. As a side note, is there a way to generalise this for $2n$ counters, labelled 1 through $n$ twice over?","I was making combinatorics exercises for some students when I stumped myself with a question I came up with. Question Bob has ten blue counters, labelled 1, 2, 3, 4, 5, 1, 2, 3, 4, 5. If he rearranges all ten randomly in a line, how many different arrangements include a subsequence of five counters that read 1, 2, 3, 4, 5 in that order (but not necessarily together)? For example, 1 , 3, 2 , 5, 1, 4, 3 , 4 , 5 , 2 would satisfy the conditions. So what have I tried? I tried simplifying the problem to: two counters (1, 1) in which the number of ways the subsequence 1 appears somewhere is (trivially) 1. four counters (1, 2, 1, 2) in which the number of ways the subsequence 1, 2 appears somewhere is 5. six counters (1, 2, 3, 1, 2, 3) in which the number of ways the subsequence 1, 2, 3 appears somewhere is 47. I verified this in two ways. Firstly, I wrote out all 90 cases and counted manually. Then, I realised that any case where the subsequence 1, 2, 3 appears in order has the subsequence 1, 2 appearing in order. So, any solution to the 6-counter problem is simply a solution to the 4-counter problem, plus two carefully-positioned 3s. This broke the question into 5 cases which were simpler to exhaust. For the question itself, I know the answer is lower than . is the answer to the following method: Given ten positions in a line, pick five to permute (i.e, place the counters 1, 2, 3, 4, 5 on, in a random order). Then place the remaining counters 1, 2, 3, 4, 5 in that order in the remaining positions. However, this grossly overcounts many cases. I think it overcounts each time a case has multiple subsequences of 1, 2, 3, 4, 5. For example, the case of 1, 1, 2, 2, 3, 3, 4, 4, 5, 5 is counted (I think) times. The case of 1 , 2, 4, 2, 3 , 4 , 3, 5, 5, 1 is counted four times. This is because every subsequence of 1, 2, 3, 4, 5 must include the bolded 1, 3 and 4, but there are two options for the 2s and two options for the 5s. So there are four subsequences of 1, 2, 3, 4, 5 in this case. As a side note, is there a way to generalise this for counters, labelled 1 through twice over?",10P5 10P5 2^5 = 32 2n n,"['combinatorics', 'permutations']"
57,Number of flips on a binary string to get m consecutive 1s,Number of flips on a binary string to get m consecutive 1s,,"I am thinking about a deceptively simple problem, at least for my admittedly poor statistics standard. A $k$ long binary string of all $0$ s is given. A random element is chosen, and flipped. What is the expected number of flips until $m$ consecutive $1$ s appear? I would also be content with a ""toroidal"" string, such that for example $110001$ counts as a string with $3$ consecutive $1$ s. I could not make any progress at all. The best I have got so far is considering the string as a vertex of a $k$ -dimensional hypercube. Then the ""flipping"" turns the problem to a random walk on the hypercube. But how to characterise vertices that have $m$ consecutive coordinates equal to $1$ ? Any hint welcome, such as ""read chapter X of textbook Y"", or ""have a look at this technique"". Thanks a lot EDIT Following the remarks from @lulu, I attach below a chart documenting the mean time for reaching $m$ consecutive $1$ s on a string long $k$ , starting from all $0$ s (averages over one thousands trials). The numerical results are (rows for string length, columns for mean flipping time) \begin{equation}   \left(     \begin{array}{*5{c}}      0 & 0 & 0 & 0 & 0 & 0\\      0 & 1 & 0 & 0 & 0 & 0\\      0 &  1 & 3.986 & 0 & 0 & 0\\      0 &  1 &  5.112 & 13.87 & 0 & 0\\      0 &  1 &  6.571 &  18.165 & 43.81 & 96.468\\   \end{array}\right) \end{equation} For completeness's sake I paste below the snippet used to get the numbers and the plot import numpy as np import random import matplotlib.pyplot as plt  def flipping (string_length,m):      s = np.zeros(string_length,dtype=bool)     counter = 0     max_count = 0     count_one = 0     while max_count < m:          count_one = 0         max_count = 0 ## Choose random element to flip, and flip         randelem = np.random.randint(string_length)         s[randelem] = np.logical_not(s[randelem]) ## Count consecutive 1s         for i in range(string_length):             if s[i] == 0:                 count_one = 0             else:                 count_one += 1                 max_count = max(max_count, count_one)                 counter +=  1      return counter,s , max_count    number_of_m = 10 number_of_l = 6 number_of_realis = 1000 ## Initialise array to hold results:  ## rows to string lengths, columns to number of required consecutive ##1s res = np.zeros((number_of_l, number_of_m)) ## choose number of trials, initialise array to hold individual ##results realis = np.zeros(number_of_realis) ## loop using the above defined ""flipping"" function for len in range ( number_of_l):     for m in range (len+1):         for j in range(number_of_realis):             realis[j] = flipping(len, m)[0]         res[len,m] = np.average (realis)  ## plot  for i in range (1, 6):     plt.plot(np.arange(1,i+1),  res[i,1:i+1],label=f""string lenght = {i}"") plt.xlabel(""Number of consecutive 1s"") plt.ylabel(""Mean number of flips"") plt.legend() plt.savefig(""math_stack.png"") I also add a plot for larger $m$ , it is actually quite interesting, it actually reminded me that I would already be quite content getting some result in the limit of string length $\to \infty$ , at fixed $m$ , maybe this is more tractable.","I am thinking about a deceptively simple problem, at least for my admittedly poor statistics standard. A long binary string of all s is given. A random element is chosen, and flipped. What is the expected number of flips until consecutive s appear? I would also be content with a ""toroidal"" string, such that for example counts as a string with consecutive s. I could not make any progress at all. The best I have got so far is considering the string as a vertex of a -dimensional hypercube. Then the ""flipping"" turns the problem to a random walk on the hypercube. But how to characterise vertices that have consecutive coordinates equal to ? Any hint welcome, such as ""read chapter X of textbook Y"", or ""have a look at this technique"". Thanks a lot EDIT Following the remarks from @lulu, I attach below a chart documenting the mean time for reaching consecutive s on a string long , starting from all s (averages over one thousands trials). The numerical results are (rows for string length, columns for mean flipping time) For completeness's sake I paste below the snippet used to get the numbers and the plot import numpy as np import random import matplotlib.pyplot as plt  def flipping (string_length,m):      s = np.zeros(string_length,dtype=bool)     counter = 0     max_count = 0     count_one = 0     while max_count < m:          count_one = 0         max_count = 0 ## Choose random element to flip, and flip         randelem = np.random.randint(string_length)         s[randelem] = np.logical_not(s[randelem]) ## Count consecutive 1s         for i in range(string_length):             if s[i] == 0:                 count_one = 0             else:                 count_one += 1                 max_count = max(max_count, count_one)                 counter +=  1      return counter,s , max_count    number_of_m = 10 number_of_l = 6 number_of_realis = 1000 ## Initialise array to hold results:  ## rows to string lengths, columns to number of required consecutive ##1s res = np.zeros((number_of_l, number_of_m)) ## choose number of trials, initialise array to hold individual ##results realis = np.zeros(number_of_realis) ## loop using the above defined ""flipping"" function for len in range ( number_of_l):     for m in range (len+1):         for j in range(number_of_realis):             realis[j] = flipping(len, m)[0]         res[len,m] = np.average (realis)  ## plot  for i in range (1, 6):     plt.plot(np.arange(1,i+1),  res[i,1:i+1],label=f""string lenght = {i}"") plt.xlabel(""Number of consecutive 1s"") plt.ylabel(""Mean number of flips"") plt.legend() plt.savefig(""math_stack.png"") I also add a plot for larger , it is actually quite interesting, it actually reminded me that I would already be quite content getting some result in the limit of string length , at fixed , maybe this is more tractable.","k 0 m 1 110001 3 1 k m 1 m 1 k 0 \begin{equation}
  \left(
    \begin{array}{*5{c}}
     0 & 0 & 0 & 0 & 0 & 0\\
     0 & 1 & 0 & 0 & 0 & 0\\
     0 &  1 & 3.986 & 0 & 0 & 0\\
     0 &  1 &  5.112 & 13.87 & 0 & 0\\
     0 &  1 &  6.571 &  18.165 & 43.81 & 96.468\\
  \end{array}\right)
\end{equation} m \to \infty m","['combinatorics', 'random-walk', 'binary']"
58,Generalizing Hall's marriage theorem,Generalizing Hall's marriage theorem,,"(This question has been posted on mathoverflow: Generalizing Hall's marriage theorem ) Fix positive integers $m,n,k$ such that $n\geq k$ . Consider a bipartite graph between two sets of vertices $A$ and $B$ consisting of $n$ and $mn$ vertices respectively. Suppose each vertex in $A$ is connected to exactly $mk$ vertices in $B$ and each vertex in $B$ is connected to exactly $k$ vertices in $A$ . (Assume there are no double edges between any pair of vertices.) Is it possible to select a subset $B'$ of $B$ of size $n$ such that each vertex of $A$ is connected to exactly $k$ vertices in $B'$ ? This is trivially true when $k=1$ , whereas the case $k=2$ is equivalent to Hall's marriage theorem. (This follows from Peterson's 2-factor theorem.) Can we say something for general $k$ ?","(This question has been posted on mathoverflow: Generalizing Hall's marriage theorem ) Fix positive integers such that . Consider a bipartite graph between two sets of vertices and consisting of and vertices respectively. Suppose each vertex in is connected to exactly vertices in and each vertex in is connected to exactly vertices in . (Assume there are no double edges between any pair of vertices.) Is it possible to select a subset of of size such that each vertex of is connected to exactly vertices in ? This is trivially true when , whereas the case is equivalent to Hall's marriage theorem. (This follows from Peterson's 2-factor theorem.) Can we say something for general ?","m,n,k n\geq k A B n mn A mk B B k A B' B n A k B' k=1 k=2 k","['combinatorics', 'graph-theory', 'matching-theory']"
59,"$\lim\limits_{n\to\infty}(\frac{\text{number of 1s in the binary numeral of }b^n}{n}) = \log_4(\text{OddPart}(b))$, for any positive integer b?",", for any positive integer b?",\lim\limits_{n\to\infty}(\frac{\text{number of 1s in the binary numeral of }b^n}{n}) = \log_4(\text{OddPart}(b)),"Notation : For any positive integer $x$ , let $\operatorname{Ones}(x)$ denote the Hamming weight of $x$ (i.e., the number of $1$ s in the binary numeral for $x$ ), and let $\operatorname{OddPart}(x)$ denote the odd part of $x$ (i.e. the largest odd divisor of $x$ ). While computing some Hamming weights, I was surprised to see the following behavior: It seems that for any given positive integer $b$ , $\operatorname{Ones}(b^{(10^k)})$ has the same leading decimal digits for all sufficiently large $k$ . Furthermore (with help of OEIS), these leading digits are discovered to be those of $\log_4\operatorname{OddPart}(b)$ in every case except when $b$ is a power of two (in which case there is of course only one $1$ in the numeral of $b$ ). Examples : It's only necessary to look at odd $b$ because $\operatorname{Ones}(b^n) = \operatorname{Ones}(\operatorname{(OddPart}(b))^n),$ since multiplying by a power of two just appends $0$ s to the binary numeral. b     Ones(b^10^9)   Ones(b^10^9)/10^9 ≈ log_4(b) ----------------------------------------------------    1               1         0.0000          0.0000    3       792490796         0.7925          0.7925    5      1160951533         1.1610          1.1610    7      1403656246         1.4037          1.4037    9      1584925047         1.5849          1.5850   11      1729722034         1.7297          1.7297   13      1850206247         1.8502          1.8502   15      1953457439         1.9535          1.9534  123      3471255304         3.4713          3.4713 4567      6078486804         6.0785          6.0785 Numerically, the same behavior is found to occur for ${\operatorname{Ones}(b^n)\over n}$ with sufficiently large $n$ not necessarily a power of ten, leading to the following conjecture: For any positive integer $b$ , $$\lim_\limits{n\to\infty}{\operatorname{Ones}(b^n)\over n}= \log_4 \operatorname{OddPart}(b).$$ Question : Can someone suggest how to prove this, and/or provide a source in the literature? (There is a slightly related question here .) SageMath code for the above table: for b in [1 .. 15, step=2] + [123, 4567]:     if is_odd(b):         ones = (b**10**9).popcount()         print(f""{b:4} {ones:12} {float(ones/10**9):7.4f} {float(log(b,4)):7.4f}"") Update (12/18/2022): The ""random digits"" heuristic described in the comment by @HagenvonEitzen lends plausibility to the following more general conjectures, which do indeed appear to be borne out numerically (using SageMath): For positive integers $p, x$ , define $N_p(x)\overset{def}{=}$ the number of nonzero digits in the base- $p$ numeral for $x$ , $S_p(x)\overset{def}{=}$ the sum of all the digits in the base- $p$ numeral for $x$ . $R_p(x)\overset{def}{=}$ the result of dividing $x$ by the largest power of $p$ that divides $x.$ $Z_p(x)\overset{def}{=}\min\left({e_1^\prime\over e_1},\ldots,{e_k^\prime\over e_k}\right),$ where in standard form the prime factorization of $p$ is $p=\prod_{i=1}^k p_i^{e_i}$ , and $e_i^\prime$ is the exponent of $p_i$ in the prime factorization of $x$ . Claim : If $p, b$ are positive integers, then $$\lim_\limits{n\to\infty}{N_p(b^n)\over n}= {p-1\over p}\big(\log_p(R_p(b))-Z_p(R_p(b))\big).$$ $$\lim_\limits{n\to\infty}{S_p(b^n)\over n}= {p-1\over 2}\big(\log_p(R_p(b))-Z_p(R_p(b))\big).$$ The reasoning is as follows, where we let $r=R_p(b)$ : $r$ is just the result of removing all trailing $0$ s (if any) from the base- $p$ numeral of $b$ , which affects neither the number of nonzero digits nor the sum of all the digits; hence, $N_p(b^n)=N_p(r^n)$ and $S_p(b^n)=S_p(r^n)$ . Now some of the base- $p$ digits of $r^n$ may also be trailing $0$ s. This number (say $z\ge 0$ ) is the largest $m$ such that $p^m$ divides $r^n$ , which is seen to be the largest $m$ such that $m e_i\le n e_i^\prime$ for all $i\in 1..k,$ where the $e_i$ are the exponents in the prime factorization of $p=\prod_{i=1}^\infty p_i^{e_i}$ and $e_i^\prime$ is the exponent of $p_i$ in the prime factorization of $r$ .  Thus $z$ is the largest $m$ such that $m\le n Z_p(r);$ hence, $z\sim n Z_p(r)$ as $n\to\infty$ . Example: $p=2^3 5^7, (e_1,e_2)=(3,7);r=2^1 3^3 5^2,(e_1^\prime,e_2^\prime)=(1,2);Z_p(r)=\min(1/3,2/7)=2/7.$ Hence, (number of base- $p$ digits of $b^n$ that are not trailing $0$ s ) $\sim n \log_p(r)- n Z_p(r).$ If the digits that are not trailing zeros tend to occur with approximately equal frequencies , then we obtain the above results (1) and (2): $$N_p(r^n)\sim n\ \big(\log_p(r)- Z_p(r)\big)\ {p-1\over p}$$ and $$S_p(r^n)\sim n\ \big(\log_p(r)- Z_p(r)\big){0+1+2+...+(p-1)\over p}=n\ \big(\log_p(r)- Z_p(r)\big)\ {p-1\over 2}.$$ Note that $Z_p(r)=0$ iff some prime divisor of $p$ is not a divisor of $r$ .","Notation : For any positive integer , let denote the Hamming weight of (i.e., the number of s in the binary numeral for ), and let denote the odd part of (i.e. the largest odd divisor of ). While computing some Hamming weights, I was surprised to see the following behavior: It seems that for any given positive integer , has the same leading decimal digits for all sufficiently large . Furthermore (with help of OEIS), these leading digits are discovered to be those of in every case except when is a power of two (in which case there is of course only one in the numeral of ). Examples : It's only necessary to look at odd because since multiplying by a power of two just appends s to the binary numeral. b     Ones(b^10^9)   Ones(b^10^9)/10^9 ≈ log_4(b) ----------------------------------------------------    1               1         0.0000          0.0000    3       792490796         0.7925          0.7925    5      1160951533         1.1610          1.1610    7      1403656246         1.4037          1.4037    9      1584925047         1.5849          1.5850   11      1729722034         1.7297          1.7297   13      1850206247         1.8502          1.8502   15      1953457439         1.9535          1.9534  123      3471255304         3.4713          3.4713 4567      6078486804         6.0785          6.0785 Numerically, the same behavior is found to occur for with sufficiently large not necessarily a power of ten, leading to the following conjecture: For any positive integer , Question : Can someone suggest how to prove this, and/or provide a source in the literature? (There is a slightly related question here .) SageMath code for the above table: for b in [1 .. 15, step=2] + [123, 4567]:     if is_odd(b):         ones = (b**10**9).popcount()         print(f""{b:4} {ones:12} {float(ones/10**9):7.4f} {float(log(b,4)):7.4f}"") Update (12/18/2022): The ""random digits"" heuristic described in the comment by @HagenvonEitzen lends plausibility to the following more general conjectures, which do indeed appear to be borne out numerically (using SageMath): For positive integers , define the number of nonzero digits in the base- numeral for , the sum of all the digits in the base- numeral for . the result of dividing by the largest power of that divides where in standard form the prime factorization of is , and is the exponent of in the prime factorization of . Claim : If are positive integers, then The reasoning is as follows, where we let : is just the result of removing all trailing s (if any) from the base- numeral of , which affects neither the number of nonzero digits nor the sum of all the digits; hence, and . Now some of the base- digits of may also be trailing s. This number (say ) is the largest such that divides , which is seen to be the largest such that for all where the are the exponents in the prime factorization of and is the exponent of in the prime factorization of .  Thus is the largest such that hence, as . Example: Hence, (number of base- digits of that are not trailing s ) If the digits that are not trailing zeros tend to occur with approximately equal frequencies , then we obtain the above results (1) and (2): and Note that iff some prime divisor of is not a divisor of .","x \operatorname{Ones}(x) x 1 x \operatorname{OddPart}(x) x x b \operatorname{Ones}(b^{(10^k)}) k \log_4\operatorname{OddPart}(b) b 1 b b \operatorname{Ones}(b^n) = \operatorname{Ones}(\operatorname{(OddPart}(b))^n), 0 {\operatorname{Ones}(b^n)\over n} n b \lim_\limits{n\to\infty}{\operatorname{Ones}(b^n)\over n}= \log_4 \operatorname{OddPart}(b). p, x N_p(x)\overset{def}{=} p x S_p(x)\overset{def}{=} p x R_p(x)\overset{def}{=} x p x. Z_p(x)\overset{def}{=}\min\left({e_1^\prime\over e_1},\ldots,{e_k^\prime\over e_k}\right), p p=\prod_{i=1}^k p_i^{e_i} e_i^\prime p_i x p, b \lim_\limits{n\to\infty}{N_p(b^n)\over n}= {p-1\over p}\big(\log_p(R_p(b))-Z_p(R_p(b))\big). \lim_\limits{n\to\infty}{S_p(b^n)\over n}= {p-1\over 2}\big(\log_p(R_p(b))-Z_p(R_p(b))\big). r=R_p(b) r 0 p b N_p(b^n)=N_p(r^n) S_p(b^n)=S_p(r^n) p r^n 0 z\ge 0 m p^m r^n m m e_i\le n e_i^\prime i\in 1..k, e_i p=\prod_{i=1}^\infty p_i^{e_i} e_i^\prime p_i r z m m\le n Z_p(r); z\sim n Z_p(r) n\to\infty p=2^3 5^7, (e_1,e_2)=(3,7);r=2^1 3^3 5^2,(e_1^\prime,e_2^\prime)=(1,2);Z_p(r)=\min(1/3,2/7)=2/7. p b^n 0 \sim n \log_p(r)- n Z_p(r). N_p(r^n)\sim n\ \big(\log_p(r)- Z_p(r)\big)\ {p-1\over p} S_p(r^n)\sim n\ \big(\log_p(r)- Z_p(r)\big){0+1+2+...+(p-1)\over p}=n\ \big(\log_p(r)- Z_p(r)\big)\ {p-1\over 2}. Z_p(r)=0 p r","['combinatorics', 'elementary-number-theory', 'reference-request', 'binary']"
60,Combinatorial structure of the tesseract,Combinatorial structure of the tesseract,,"On a cube, you can define the notion of ""the next edge around this vertex, in clockwise order."" Formally, if $D$ is the space of darts (edges of the cube with one of the endpoint vertices marked as special), this ""next edge"" function is a permutation $\sigma:D\rightarrow D$ that keeps the special vertex the same. If you also let $\alpha:D\rightarrow D$ be the involution that flips which endpoint is considered special, you get a map $\alpha\circ \sigma$ whose orbits make a nice picture: Now I am trying to do the same thing on a tesseract, but I don't know how to define the ""next edge around this vertex"" function $\sigma:D\rightarrow D$ .  I believe the tesseract is orientable, so it should be possible to choose a $\sigma$ with the right combinatorial properties (even though there's no cross product in 4D). According to my math*, the resulting map $\alpha\circ \sigma$ should have eight orbits (compared to the cube's four orbits shown above). My question is this: Given an edge of the tesseract with one endpoint marked as special, how do I define ""the next edge"" with that same endpoint? More precisely, I think my question is: Question : If $D$ is the space of darts (edges of the tesseract with one of the endpoints marked as special), and $\alpha:D\rightarrow D$ is the involution that changes which endpoint is special, is there a permutation $\sigma:D\rightarrow D$ such that: The cycles of $\sigma$ are exactly the sets of darts with a common special endpoint. Intuitively, $\sigma$ acts like it ""pivots"" darts around their special endpoint. The orbits of $(\alpha \circ \sigma^{-1} \circ \alpha \circ \sigma)$ all have the same size, and there are 2*8 = 16 orbits. (I suppose this means that since there are 32 edges = 64 darts, each orbit is a cycle of 4 points.) Those are the two main constraints. A bonus constraint, sort of difficult to articulate formally, is that I would expect $\sigma$ to interact nicely with the symmetries/rotations of the tesseract. (I think I mean that for every rotation $\rho$ of the tesseract, $\rho^{-1}\sigma\rho = \sigma$ .) I am hoping for a concrete answer, perhaps even in terms of a specific tesseract such as $\langle \pm 1, \pm 1, \pm 1, \pm 1\rangle$ . I would like to understand how unique the answer is---but it is ok if the answer is not unique as long as it has the required combinatorial structure. * Note on my math: If $T$ is the Tutte polynomial of the tesseract graph, then $1+\log_2 |T(-1,-1)|$ is the number of strands in the knotwork, i.e. the desired number of orbits of this permutation $\alpha\circ\sigma$ .","On a cube, you can define the notion of ""the next edge around this vertex, in clockwise order."" Formally, if is the space of darts (edges of the cube with one of the endpoint vertices marked as special), this ""next edge"" function is a permutation that keeps the special vertex the same. If you also let be the involution that flips which endpoint is considered special, you get a map whose orbits make a nice picture: Now I am trying to do the same thing on a tesseract, but I don't know how to define the ""next edge around this vertex"" function .  I believe the tesseract is orientable, so it should be possible to choose a with the right combinatorial properties (even though there's no cross product in 4D). According to my math*, the resulting map should have eight orbits (compared to the cube's four orbits shown above). My question is this: Given an edge of the tesseract with one endpoint marked as special, how do I define ""the next edge"" with that same endpoint? More precisely, I think my question is: Question : If is the space of darts (edges of the tesseract with one of the endpoints marked as special), and is the involution that changes which endpoint is special, is there a permutation such that: The cycles of are exactly the sets of darts with a common special endpoint. Intuitively, acts like it ""pivots"" darts around their special endpoint. The orbits of all have the same size, and there are 2*8 = 16 orbits. (I suppose this means that since there are 32 edges = 64 darts, each orbit is a cycle of 4 points.) Those are the two main constraints. A bonus constraint, sort of difficult to articulate formally, is that I would expect to interact nicely with the symmetries/rotations of the tesseract. (I think I mean that for every rotation of the tesseract, .) I am hoping for a concrete answer, perhaps even in terms of a specific tesseract such as . I would like to understand how unique the answer is---but it is ok if the answer is not unique as long as it has the required combinatorial structure. * Note on my math: If is the Tutte polynomial of the tesseract graph, then is the number of strands in the knotwork, i.e. the desired number of orbits of this permutation .","D \sigma:D\rightarrow D \alpha:D\rightarrow D \alpha\circ \sigma \sigma:D\rightarrow D \sigma \alpha\circ \sigma D \alpha:D\rightarrow D \sigma:D\rightarrow D \sigma \sigma (\alpha \circ \sigma^{-1} \circ \alpha \circ \sigma) \sigma \rho \rho^{-1}\sigma\rho = \sigma \langle \pm 1, \pm 1, \pm 1, \pm 1\rangle T 1+\log_2 |T(-1,-1)| \alpha\circ\sigma","['combinatorics', 'knot-theory', 'polytopes', 'orientation']"
61,How to find a discrete Morse function on this simplicial complex,How to find a discrete Morse function on this simplicial complex,,"I have a graph called partition graph. This graph gives rise to a simplicial complex called box complex $B_{edge}$ . Since this simplicial complex is too big and studying the topological features of it is too difficult I want to simplify this simplicial complex using a discrete Morse function. Definition . Every vertex of a partition graph $\mathcal{P}(3^3)$ is a partition of $\{1,2, ..., 9 \}$ into $3$ cells of size $3$ . Two vertices $u$ and $v$ are adjacent if the intersection of each cell of $u$ with each cell of $v$ is nonempty. This graph is vertex- edge- arc transitive. Definition . The box complex $B_{edge}(G)$ of a graph $G$ is a simplicial complex which vertices are the directed edges of $G$ ; that is, ordered pairs $(u,v)$ with $\{u,v\}\in E$ . The simplices of this box complex are subsets of edge sets of complete bipartite subgraphs of $G$ , where the edges are oriented from the first shore to the second shore. \begin{align*}     B_{edge}(G):=&\{ \overrightarrow{F} \subset A'\times A'': \varnothing \neq A',A'' \subset V,\\     &A'\cap A''=\varnothing, G[A',A'']\ \text{is complete}\} \end{align*} I want to find a discrete Morse function on the box complex $B_{edge}(\mathcal{P}(3^3))$ . A function with less critical simplicies is better.","I have a graph called partition graph. This graph gives rise to a simplicial complex called box complex . Since this simplicial complex is too big and studying the topological features of it is too difficult I want to simplify this simplicial complex using a discrete Morse function. Definition . Every vertex of a partition graph is a partition of into cells of size . Two vertices and are adjacent if the intersection of each cell of with each cell of is nonempty. This graph is vertex- edge- arc transitive. Definition . The box complex of a graph is a simplicial complex which vertices are the directed edges of ; that is, ordered pairs with . The simplices of this box complex are subsets of edge sets of complete bipartite subgraphs of , where the edges are oriented from the first shore to the second shore. I want to find a discrete Morse function on the box complex . A function with less critical simplicies is better.","B_{edge} \mathcal{P}(3^3) \{1,2, ..., 9 \} 3 3 u v u v B_{edge}(G) G G (u,v) \{u,v\}\in E G \begin{align*}
    B_{edge}(G):=&\{ \overrightarrow{F} \subset A'\times A'': \varnothing \neq A',A'' \subset V,\\
    &A'\cap A''=\varnothing, G[A',A'']\ \text{is complete}\}
\end{align*} B_{edge}(\mathcal{P}(3^3))","['combinatorics', 'graph-theory', 'algebraic-topology', 'morse-theory']"
62,"""Math Lotto"" Tickets - finding the minimum winning set","""Math Lotto"" Tickets - finding the minimum winning set",,"""Math lotto"" is played as follows:  a player marks six squares on a 6x6 square. Then six  ""losing squares"" are drawn. A player wins if none of the losing squares are marked on his lottery ticket. 1)Prove that one can complete nine lottery tickets in such a way that at least one of them wins. 2)Prove that this is not possible with only eight tickets. My attempt is as follows; First I divided the square into 6 rectangles (figure 1). If one rectangle doesn't contain a cross then some ticket (ticket 1 to ticket 6) would win the game. Now we consider the case where each rectangle has one cross each. Now take the two rectangles on the top left of the square (figure 2). These have a total of two crosses. The first two columns together contains one cross and the third and fourth columns together contains one cross. There are four cases and we need at least four tickets (ticket 7 to ticket 10) to ensure win. I am only getting a minimum of ten tickets. How do I prove only nine tickets is required and for eight tickets it is not possible? Reference: Combinatorics by Stephan Wagner, Page 42, Problem 49 . https://math.sun.ac.za/swagner/Combinatorics.pdf","""Math lotto"" is played as follows:  a player marks six squares on a 6x6 square. Then six  ""losing squares"" are drawn. A player wins if none of the losing squares are marked on his lottery ticket. 1)Prove that one can complete nine lottery tickets in such a way that at least one of them wins. 2)Prove that this is not possible with only eight tickets. My attempt is as follows; First I divided the square into 6 rectangles (figure 1). If one rectangle doesn't contain a cross then some ticket (ticket 1 to ticket 6) would win the game. Now we consider the case where each rectangle has one cross each. Now take the two rectangles on the top left of the square (figure 2). These have a total of two crosses. The first two columns together contains one cross and the third and fourth columns together contains one cross. There are four cases and we need at least four tickets (ticket 7 to ticket 10) to ensure win. I am only getting a minimum of ten tickets. How do I prove only nine tickets is required and for eight tickets it is not possible? Reference: Combinatorics by Stephan Wagner, Page 42, Problem 49 . https://math.sun.ac.za/swagner/Combinatorics.pdf",,"['combinatorics', 'pigeonhole-principle', 'coloring', 'combinatorial-designs', 'lotteries']"
63,Number of equilateral triangles in triangular grid,Number of equilateral triangles in triangular grid,,"How can we find the number $f(x, y)$ of equilateral triangles that can be made by connecting three points within boundaries $x$ and $y$ ? (Suppose that $x\le y$ ) For example, $f(1, 4) = 15$ because there are $9$ smallest triangles, $3$ triangles that are twice as large, $1$ triangles that are 3 times as large, and $2$ triangle that is turned ( $90$ degrees or $270$ degrees each). example $2$ : $f(3, 6) = 21 + 7 + 3 + 5 + 5 + 3 + 1 + 1 = 46$ I am aware that the difficulty level of this problem is difficult. (I've been thinking about solving this for more than two days.) If it is impossible to find $f(x, y)$ in one formula, I would appreciate it if you could tell me the generalized calculation method. Thank you!","How can we find the number of equilateral triangles that can be made by connecting three points within boundaries and ? (Suppose that ) For example, because there are smallest triangles, triangles that are twice as large, triangles that are 3 times as large, and triangle that is turned ( degrees or degrees each). example : I am aware that the difficulty level of this problem is difficult. (I've been thinking about solving this for more than two days.) If it is impossible to find in one formula, I would appreciate it if you could tell me the generalized calculation method. Thank you!","f(x, y) x y x\le y f(1, 4) = 15 9 3 1 2 90 270 2 f(3, 6) = 21 + 7 + 3 + 5 + 5 + 3 + 1 + 1 = 46 f(x, y)","['combinatorics', 'combinations', 'triangles']"
64,Encoding information by hiding digits,Encoding information by hiding digits,,"Good evening, I have been stumbled by this problem. Two magicians, call them A and B, play a trick: while B is not looking, A asks a spectator to write an n-digit number on a board. A then cancels two digits. B comes back, being able to see the remaining n-2 digits, in order, and the positions of the two cancelled digits. He guesses, correctly, the two cancelled digits in order. For which n is this possible? An easy induction can prove that if the trick works for $n$ , it works for all numbers greater than $n$ . I have found a way to make it work for $n = 20$ : supposing the sum of the first $10$ digits is $k \mod10$ and the sum of the other $10$ digits is $l \mod 10$ , A just hides the $k$ -th and $(10+l)$ -th digit. However, I have not been able to prove this is a lower bound. In fact, the ""natural"" argument leads me to think the true bound is $n \geq 15$ : there are $10^n$ possible numbers, and $b$ can receive $10^{(n-2)}{{n}\choose{2}}$ different strings. For the trick to work, we then need ${{n}\choose{2}} \geq 100$ which implies $n \geq 15$ . Is there a way to explicitly construct the algorithm for the trick in case $n = 15$ ? This is a variation of a well-known problem, which has already been asked about and answered on this site, in which the cancelled digits are adjacent, which results, much more easily, in $n \geq 101$ . Edit: I think the most straightforward solution is to forsake every hope of an explicit construction and apply Hall's marriage theorem (this is akin to finding a perfect matching on the bipartite graph between the set of numbers and the set of strings with two numbers hidden, and this graph satisfies the marriage condition by a double counting argument). I have thus proven that $15$ is the lower bound, but still have not been able to describe the strategy for $15 \leq n < 20$ Edit 2: The magicians are collaborating (there would be no solution if they were not), the spectator is not","Good evening, I have been stumbled by this problem. Two magicians, call them A and B, play a trick: while B is not looking, A asks a spectator to write an n-digit number on a board. A then cancels two digits. B comes back, being able to see the remaining n-2 digits, in order, and the positions of the two cancelled digits. He guesses, correctly, the two cancelled digits in order. For which n is this possible? An easy induction can prove that if the trick works for , it works for all numbers greater than . I have found a way to make it work for : supposing the sum of the first digits is and the sum of the other digits is , A just hides the -th and -th digit. However, I have not been able to prove this is a lower bound. In fact, the ""natural"" argument leads me to think the true bound is : there are possible numbers, and can receive different strings. For the trick to work, we then need which implies . Is there a way to explicitly construct the algorithm for the trick in case ? This is a variation of a well-known problem, which has already been asked about and answered on this site, in which the cancelled digits are adjacent, which results, much more easily, in . Edit: I think the most straightforward solution is to forsake every hope of an explicit construction and apply Hall's marriage theorem (this is akin to finding a perfect matching on the bipartite graph between the set of numbers and the set of strings with two numbers hidden, and this graph satisfies the marriage condition by a double counting argument). I have thus proven that is the lower bound, but still have not been able to describe the strategy for Edit 2: The magicians are collaborating (there would be no solution if they were not), the spectator is not",n n n = 20 10 k \mod10 10 l \mod 10 k (10+l) n \geq 15 10^n b 10^{(n-2)}{{n}\choose{2}} {{n}\choose{2}} \geq 100 n \geq 15 n = 15 n \geq 101 15 15 \leq n < 20,"['combinatorics', 'graph-theory', 'contest-math']"
65,Multivariate Lagrange inversion with powers,Multivariate Lagrange inversion with powers,,"Let the formal power series $\phi_1,\dots,\phi_m$ in the variables $x_1,\dots,x_m$ be defined by \begin{equation}     \phi_i(x_1,\dots,x_m)=x_i\rho_i(\phi_1,\dots,\phi_m),\qquad i = 1,\dots,m \end{equation} for some formal series $\rho_i(x_1,\dots,x_m)$ . Then, for any formal power series $f(x_1,\dots,x_m)$ we have \begin{equation}     [{\vec x}^{\,\vec n}]f(\vec  \phi(\vec  x))      = [{\vec t}^{\,\vec n}]f(\vec  t)       \text{det}[K(\vec  t)]       {\vec \rho}^{\,\vec n}(\vec  t) \end{equation} where $K(\vec  t)$ is a matrix from $\mathbb R^{m\times m}$ , \begin{equation}     K(\vec  t)_{i,j}=\delta_{i,j}-\frac{t_i}{\vec  \rho_i(\vec  t)}\frac{\partial \vec  \rho_i}{\partial t_j}(\vec  t), \qquad i,j\in 1,\dots,m \end{equation} where $\vec  t=(t_1,\dots,t_m)$ , $\vec  n =(n_1,\dots,n_m)$ , ${\vec x}^{\,\vec n}=x_1^{n_1}x_2^{n_2}\cdots x_m^{n_m}$ and $\vec  x(\vec  y)=[x_1(\vec  y),\dots,x_m(\vec  y)]$ . In the case that $m=1$ , we recover the standard Lagrange-inversion formula. Consider the system \begin{equation}     \phi_i(x_1,\dots,x_m)=x_i\rho_i(\phi_1^{p_1},\dots,\phi_m^{p_m}),\qquad i = 1,\dots,m \end{equation} where $p_i$ are integer powers. How can I apply the Lagrange inversion theorem in this case? For a 1-dimensional scenario, my attempt is as follows. The coefficient of $x^n$ in $f(\phi^m(x))$ with $\phi(x) =x\rho(\phi^m(x))$ for $m=1,2,\dots$ . I find \begin{align} [x^n]f(\phi^m(x))=&\frac{n!}{2\pi i}\oint \frac{f(\phi^m(x))}{x^{n+1}}dx\\ =& \frac{(n-1)!}{2\pi i}\oint \frac{1}{x^n}\left(\frac{d}{dz}f(\phi^m(x))\right)dz\\ =& \frac{(n-1)!}{2\pi i}\oint \frac{1}{x^n}\left(f'(\phi^m(x))m\phi^{m-1}(x)\phi'(x)\right)dx\\ =&\frac{m(n-1)!}{2\pi i}\oint\frac{ \rho(\phi^m(x))^n}{\phi^n(x)}\left(f'(\phi^m(x))\phi^{m-1}(x)\phi'(x)\right)dx \end{align} In the last step we considered $x$ as a function of $\phi$ and $\rho$ from above. We now change the volume element and move the $\phi^{m-1}$ term to the denominator to obtain \begin{equation}     [x^n]f(\phi^m(x))=\frac{m(n-1)!}{2\pi i}\oint\frac{ 1}{\phi(x)^{n-m+1}}\left[\rho(\phi^m(x))^nf'(\phi^m(x))\right]d\phi \end{equation} We must then undo the Cauchy formula; however, this is where I am a bit stuck due to the denominator in $\phi(x)$ . My attempt is as follows $$ [x^n]f(\phi^m(x))= \frac{m}{n}[t^{n-m}]\rho(t^m)^nf'(t^m) $$ where we have again simplified $1/n=(n-1)!/n!$ . I am not certain this is correct; however.","Let the formal power series in the variables be defined by for some formal series . Then, for any formal power series we have where is a matrix from , where , , and . In the case that , we recover the standard Lagrange-inversion formula. Consider the system where are integer powers. How can I apply the Lagrange inversion theorem in this case? For a 1-dimensional scenario, my attempt is as follows. The coefficient of in with for . I find In the last step we considered as a function of and from above. We now change the volume element and move the term to the denominator to obtain We must then undo the Cauchy formula; however, this is where I am a bit stuck due to the denominator in . My attempt is as follows where we have again simplified . I am not certain this is correct; however.","\phi_1,\dots,\phi_m x_1,\dots,x_m \begin{equation}
    \phi_i(x_1,\dots,x_m)=x_i\rho_i(\phi_1,\dots,\phi_m),\qquad i = 1,\dots,m
\end{equation} \rho_i(x_1,\dots,x_m) f(x_1,\dots,x_m) \begin{equation}
    [{\vec x}^{\,\vec n}]f(\vec  \phi(\vec  x)) 
    = [{\vec t}^{\,\vec n}]f(\vec  t)
      \text{det}[K(\vec  t)]
      {\vec \rho}^{\,\vec n}(\vec  t)
\end{equation} K(\vec  t) \mathbb R^{m\times m} \begin{equation}
    K(\vec  t)_{i,j}=\delta_{i,j}-\frac{t_i}{\vec  \rho_i(\vec  t)}\frac{\partial \vec  \rho_i}{\partial t_j}(\vec  t), \qquad i,j\in 1,\dots,m
\end{equation} \vec  t=(t_1,\dots,t_m) \vec  n =(n_1,\dots,n_m) {\vec x}^{\,\vec n}=x_1^{n_1}x_2^{n_2}\cdots x_m^{n_m} \vec  x(\vec  y)=[x_1(\vec  y),\dots,x_m(\vec  y)] m=1 \begin{equation}
    \phi_i(x_1,\dots,x_m)=x_i\rho_i(\phi_1^{p_1},\dots,\phi_m^{p_m}),\qquad i = 1,\dots,m
\end{equation} p_i x^n f(\phi^m(x)) \phi(x) =x\rho(\phi^m(x)) m=1,2,\dots \begin{align}
[x^n]f(\phi^m(x))=&\frac{n!}{2\pi i}\oint \frac{f(\phi^m(x))}{x^{n+1}}dx\\
=& \frac{(n-1)!}{2\pi i}\oint \frac{1}{x^n}\left(\frac{d}{dz}f(\phi^m(x))\right)dz\\
=& \frac{(n-1)!}{2\pi i}\oint \frac{1}{x^n}\left(f'(\phi^m(x))m\phi^{m-1}(x)\phi'(x)\right)dx\\
=&\frac{m(n-1)!}{2\pi i}\oint\frac{ \rho(\phi^m(x))^n}{\phi^n(x)}\left(f'(\phi^m(x))\phi^{m-1}(x)\phi'(x)\right)dx
\end{align} x \phi \rho \phi^{m-1} \begin{equation}
    [x^n]f(\phi^m(x))=\frac{m(n-1)!}{2\pi i}\oint\frac{ 1}{\phi(x)^{n-m+1}}\left[\rho(\phi^m(x))^nf'(\phi^m(x))\right]d\phi
\end{equation} \phi(x) 
[x^n]f(\phi^m(x))= \frac{m}{n}[t^{n-m}]\rho(t^m)^nf'(t^m)
 1/n=(n-1)!/n!","['combinatorics', 'power-series', 'lagrange-inversion']"
66,Graph problem on cycles,Graph problem on cycles,,"Given a simple graph $G(V,E)$ with 2020 vertices such that $\deg(v)\geqslant 45$ for every vertex $v\in V(G)$ . Show that one can find a $4$ -cycle in $G$ . I've managed to prove the statement for $n^2$ vertices, all of them with degree $\geqslant n+1$ with a simple Pigeonhole argument counting the number nice edge-pairs (i.e. pairs of edges that share a vertex). One should arrive at $$\binom{n^2}{2}<n^2\cdot \binom{n+1}{2}$$ which is the desired contradiction. However, the argument fails for $2020$ and $\deg\geqslant 45$ . I also tried to apply the idea displayed here (first page) which leads to the inequality $$n(n-1)\geqslant \sum_{u\in V}\deg(u)\cdot (\deg(u)-1)\implies 2020\cdot 2019\geqslant 2020\cdot 45\cdot 44 $$ But this is true and leads, therefore, to no contradiction. Any ideas/hints?","Given a simple graph with 2020 vertices such that for every vertex . Show that one can find a -cycle in . I've managed to prove the statement for vertices, all of them with degree with a simple Pigeonhole argument counting the number nice edge-pairs (i.e. pairs of edges that share a vertex). One should arrive at which is the desired contradiction. However, the argument fails for and . I also tried to apply the idea displayed here (first page) which leads to the inequality But this is true and leads, therefore, to no contradiction. Any ideas/hints?","G(V,E) \deg(v)\geqslant 45 v\in V(G) 4 G n^2 \geqslant n+1 \binom{n^2}{2}<n^2\cdot \binom{n+1}{2} 2020 \deg\geqslant 45 n(n-1)\geqslant \sum_{u\in V}\deg(u)\cdot (\deg(u)-1)\implies 2020\cdot 2019\geqslant 2020\cdot 45\cdot 44 ","['combinatorics', 'graph-theory']"
67,The Hexagonal Property of Pascal's Triangle,The Hexagonal Property of Pascal's Triangle,,"Any hexagon in Pascal's triangle, whose vertices are 6 binomial coefficients surrounding any entry, has the property that: the product of non-adjacent vertices is constant. the greatest common divisor of non-adjacent vertices is constant. Below is one such hexagon. As an example, here we have that $4 \cdot 10  \cdot 15 = 6 \cdot 20  \cdot 5$ , as well as $\gcd(4, 10, 15) = \gcd(6,20,5)$ . $$ 1 \\ 1 \qquad  1\\ 1\qquad 2\qquad 1\\ 1\qquad3\qquad3\qquad1\\ 1\qquad\mathbf{4}\qquad\mathbf{6}\qquad4\qquad1\\ 1\qquad\mathbf{5}\qquad10\qquad\mathbf{10}\qquad5\qquad1 \\ 1\qquad6\qquad\mathbf{15}\qquad\mathbf{20}\qquad15\qquad6\qquad1$$ There is a quick proof here (pdf). The original proof should be in V. E. Hoggatt, Jr., & W. Hansell. ""The Hidden Hexagon Squares."" The Fibonacci Quarterly 9(1971):120, 133. but I cannot access it. I am, however, intereseted in a purely combinatorial proof. I do not know how to approach this at all: I cannot see what the non-adjacent vertices represent and/or I do not know how to remodel their meaning. Can anyone help? EDIT: To specify my question more closely, what I am looking for is some natural bijection between the two sets of triads that create the hexagon. Thanks.","Any hexagon in Pascal's triangle, whose vertices are 6 binomial coefficients surrounding any entry, has the property that: the product of non-adjacent vertices is constant. the greatest common divisor of non-adjacent vertices is constant. Below is one such hexagon. As an example, here we have that , as well as . There is a quick proof here (pdf). The original proof should be in V. E. Hoggatt, Jr., & W. Hansell. ""The Hidden Hexagon Squares."" The Fibonacci Quarterly 9(1971):120, 133. but I cannot access it. I am, however, intereseted in a purely combinatorial proof. I do not know how to approach this at all: I cannot see what the non-adjacent vertices represent and/or I do not know how to remodel their meaning. Can anyone help? EDIT: To specify my question more closely, what I am looking for is some natural bijection between the two sets of triads that create the hexagon. Thanks.","4 \cdot 10  \cdot 15 = 6 \cdot 20  \cdot 5 \gcd(4, 10, 15) = \gcd(6,20,5)  1 \\
1 \qquad  1\\
1\qquad 2\qquad 1\\
1\qquad3\qquad3\qquad1\\
1\qquad\mathbf{4}\qquad\mathbf{6}\qquad4\qquad1\\
1\qquad\mathbf{5}\qquad10\qquad\mathbf{10}\qquad5\qquad1
\\
1\qquad6\qquad\mathbf{15}\qquad\mathbf{20}\qquad15\qquad6\qquad1","['combinatorics', 'binomial-coefficients', 'alternative-proof', 'combinatorial-proofs']"
68,Combinatorial interpretation of rational function on e,Combinatorial interpretation of rational function on e,,"Over the last few weeks I have become obsessed with expressions like $$ \frac{e+4 e^{2}+e^{3}}{(1-e)^{4}}, $$ $$ \frac{e+26 e^{2}+66 e^{3}+26 e^{4}+e^{5}}{(1-e)^{6}}, $$ or $$ \frac{e+120 e^{2}+1191 e^{3}+2416 e^{4}+1191 e^{5}+120 e^{6}+e^{7}}{(1-e)^{8}}. $$ These expressions sparked interest in me because they approximate $3!,5!$ and $7!$ , respectively and are part of a larger family of decent approximations (these approximations are quite good till 16!). One reason why this is true is because the relation between this expressions and polylogarithm, and the later with the gamma function, but I would really like to know if there is another way to justify why they approach factorials. I have delved on analytic combinatorics, and $q$ -analogs that talk about evaluating at roots of unity, poles or saddle points, but none of them seem totally appropriate,  Although they study the idea of evaluating a generating function in transcendental or complex numbers, none of them seem to relate directly to this. PD: a Dual to this identities is the evaluation at $e^{-1}$ , $$\frac{e^{-1}+11 e^{-2}+11 e^{-3} +e^{-4 }}{\left(1-e^{-1}\right)^{5}}$$ these are the same but with a correcting minus sign, so with $e^{-1}$ we get $4!$ while with $e$ we get $-4!$ . I add these  as they make more sense when we convert back to the classic polylogarithms expression $$5! \approx \operatorname{Li}_{-5}(z) = \sum_{k=0}^ \infty k^{5}z^k$$ with $z=\frac{1}{e}$ that needs $|z|<1$ , but I guess the $e$ expressions coincide with the analytic continuation of these series Also Something that made me stick with this subject was that for example $$ \frac{z+26 z^{2}+66 z^{3}+26 z^{4}+z^{5}}{(1-z)^{6}} =\frac{1}{z-1}+\frac{31}{(z-1)^{2}}+\frac{180}{(z-1)^{3}}+\frac{390}{(z-1)^{4}}+\frac{360}{(z-1)^{5}}+\frac{120}{(z-1)^{6}} $$ where something notable is that the last coefficient is exactly 5!, this is because eulerian numbers sum to factorials, but this also seemed crazily connected with the Cauchy residue theorem, only that this one was about $(z-1)^{-n}$ and not about $(z-1)^{-1}$ EDIT: Someone edited out an oeis entry linking this to the eulerian polynomials, so just so you know I'm aware what they are, also I will add a comment that I think it's crucial to finding the connection ""This seems to be connected to this combinatorial problem math.stackexchange.com/questions/257890/simon-newcombs-problem stating the formula $$\sum_{d=0}^{\infty} \frac{A_{d}(t) x^{d}}{(1-t)^{d+1} d !}=\frac{1}{1-t e^{x}}$$ the wikipedia page has the case $x=1$ although it doesn't seem to provide any source, while Jair answers [Comment] is that formula with $t=1/e$ . This seems promising as, that formula is almost a composition of classical analytical combinatorics constructions, and the wikipedia case has a $1/e$ as pole. ""","Over the last few weeks I have become obsessed with expressions like or These expressions sparked interest in me because they approximate and , respectively and are part of a larger family of decent approximations (these approximations are quite good till 16!). One reason why this is true is because the relation between this expressions and polylogarithm, and the later with the gamma function, but I would really like to know if there is another way to justify why they approach factorials. I have delved on analytic combinatorics, and -analogs that talk about evaluating at roots of unity, poles or saddle points, but none of them seem totally appropriate,  Although they study the idea of evaluating a generating function in transcendental or complex numbers, none of them seem to relate directly to this. PD: a Dual to this identities is the evaluation at , these are the same but with a correcting minus sign, so with we get while with we get . I add these  as they make more sense when we convert back to the classic polylogarithms expression with that needs , but I guess the expressions coincide with the analytic continuation of these series Also Something that made me stick with this subject was that for example where something notable is that the last coefficient is exactly 5!, this is because eulerian numbers sum to factorials, but this also seemed crazily connected with the Cauchy residue theorem, only that this one was about and not about EDIT: Someone edited out an oeis entry linking this to the eulerian polynomials, so just so you know I'm aware what they are, also I will add a comment that I think it's crucial to finding the connection ""This seems to be connected to this combinatorial problem math.stackexchange.com/questions/257890/simon-newcombs-problem stating the formula the wikipedia page has the case although it doesn't seem to provide any source, while Jair answers [Comment] is that formula with . This seems promising as, that formula is almost a composition of classical analytical combinatorics constructions, and the wikipedia case has a as pole. ""","
\frac{e+4 e^{2}+e^{3}}{(1-e)^{4}},
 
\frac{e+26 e^{2}+66 e^{3}+26 e^{4}+e^{5}}{(1-e)^{6}},
 
\frac{e+120 e^{2}+1191 e^{3}+2416 e^{4}+1191 e^{5}+120 e^{6}+e^{7}}{(1-e)^{8}}.
 3!,5! 7! q e^{-1} \frac{e^{-1}+11 e^{-2}+11 e^{-3} +e^{-4 }}{\left(1-e^{-1}\right)^{5}} e^{-1} 4! e -4! 5! \approx \operatorname{Li}_{-5}(z) = \sum_{k=0}^ \infty k^{5}z^k z=\frac{1}{e} |z|<1 e  \frac{z+26 z^{2}+66 z^{3}+26 z^{4}+z^{5}}{(1-z)^{6}} =\frac{1}{z-1}+\frac{31}{(z-1)^{2}}+\frac{180}{(z-1)^{3}}+\frac{390}{(z-1)^{4}}+\frac{360}{(z-1)^{5}}+\frac{120}{(z-1)^{6}}  (z-1)^{-n} (z-1)^{-1} \sum_{d=0}^{\infty} \frac{A_{d}(t) x^{d}}{(1-t)^{d+1} d !}=\frac{1}{1-t e^{x}} x=1 t=1/e 1/e","['combinatorics', 'complex-analysis', 'number-theory', 'generating-functions', 'analytic-combinatorics']"
69,Which topological vector spaces have uncountable unordered sums?,Which topological vector spaces have uncountable unordered sums?,,"If $P$ is an uncountable locally finite poset, then the incidence algebra $I(P)$ is a topological vector space (in fact a topological algebra) with the interesting property that every element $f$ can be written uniquely as an uncountable unordered sum $\Sigma_{a,b\in P: a\leq b}f(a,b)1_{[a,b]}$ , i.e. $\{1_{[a,b]}:a,b\in P, a\leq b \}$ constitutes an ""uncountable Schauder basis"" for $I(P)$ .  I find this interesting because for normed vector spaces, a convergent unordered sum can only have countably many nonzero terms. So my question is, what other topological vector spaces have convergent unordered sums with uncountably many nonzero terms?  And also, what other topological vector spaces have this specific ""uncountable Schauder basis"" property, i.e. there exists an uncountable subset such that every element can be written as an unordered sum of scalar multiples of this subset, and such that there exists at least one convergent unordered sum of scalar multiples of this subset with uncountably many nonzero terms?","If is an uncountable locally finite poset, then the incidence algebra is a topological vector space (in fact a topological algebra) with the interesting property that every element can be written uniquely as an uncountable unordered sum , i.e. constitutes an ""uncountable Schauder basis"" for .  I find this interesting because for normed vector spaces, a convergent unordered sum can only have countably many nonzero terms. So my question is, what other topological vector spaces have convergent unordered sums with uncountably many nonzero terms?  And also, what other topological vector spaces have this specific ""uncountable Schauder basis"" property, i.e. there exists an uncountable subset such that every element can be written as an unordered sum of scalar multiples of this subset, and such that there exists at least one convergent unordered sum of scalar multiples of this subset with uncountably many nonzero terms?","P I(P) f \Sigma_{a,b\in P: a\leq b}f(a,b)1_{[a,b]} \{1_{[a,b]}:a,b\in P, a\leq b \} I(P)","['combinatorics', 'functional-analysis', 'normed-spaces', 'topological-vector-spaces', 'schauder-basis']"
70,When is it possible to find a regular $k$-gon in a centered $n$-gon?,When is it possible to find a regular -gon in a centered -gon?,k n,"For $n \geq 3$ , say that a centered $n$ -gon with $L$ layers is given by the origin, $(0,0)$ together with the points $$   \left\{\alpha\zeta_n^j + \beta\zeta_n^{j+1}\ \middle\vert\ 0 \leq j < n, 1 \leq \alpha \leq L, 0 \leq \beta \leq L - \alpha\right\}, $$ where $\zeta_n$ is a primitive $n$ th root of unity. For example, here are the cases when $(n,L) = (3,4)$ , $(n,L) = (4,4)$ , $(n,L) = (5,3)$ , and $(n,L) = (6,3)$ : Question For a given integer $k \geq 3$ , what are the conditions on $n$ and $L$ such that it is possible to find $k$ points that form a regular $k$ -gon in the centered $n$ -gon with $L$ layers? Besides the hexagon in the centered $3$ -gon, are there any examples of $k$ -gons in a centered $n$ -gon where $k\nmid n$ ?","For , say that a centered -gon with layers is given by the origin, together with the points where is a primitive th root of unity. For example, here are the cases when , , , and : Question For a given integer , what are the conditions on and such that it is possible to find points that form a regular -gon in the centered -gon with layers? Besides the hexagon in the centered -gon, are there any examples of -gons in a centered -gon where ?","n \geq 3 n L (0,0) 
  \left\{\alpha\zeta_n^j + \beta\zeta_n^{j+1}\ \middle\vert\ 0 \leq j < n, 1 \leq \alpha \leq L, 0 \leq \beta \leq L - \alpha\right\},
 \zeta_n n (n,L) = (3,4) (n,L) = (4,4) (n,L) = (5,3) (n,L) = (6,3) k \geq 3 n L k k n L 3 k n k\nmid n","['combinatorics', 'geometry', 'polygons']"
71,Random Shuffle of Groups,Random Shuffle of Groups,,"Let's suppose that we have 54 peoples and we arrange them into 9 groups of equal size, so this means that each group will have 6 persons in it. I want to find a procedure, such that the groups are shuffled deterministic in order that people will not meet several times in a group. I couldn't come of with an idea so far. Since each person will meet then 5 new people in each group, this means that we can shuffle the groups up to 10 times. So I will decrease the complexity of this question to come up with a mix such that we will build 10 times new groups. Adding a random element in the shuffling would be an extra!","Let's suppose that we have 54 peoples and we arrange them into 9 groups of equal size, so this means that each group will have 6 persons in it. I want to find a procedure, such that the groups are shuffled deterministic in order that people will not meet several times in a group. I couldn't come of with an idea so far. Since each person will meet then 5 new people in each group, this means that we can shuffle the groups up to 10 times. So I will decrease the complexity of this question to come up with a mix such that we will build 10 times new groups. Adding a random element in the shuffling would be an extra!",,"['combinatorics', 'combinations', 'random']"
72,Sum of numbers on cards decreases,Sum of numbers on cards decreases,,"Alice and Bob play a game with $n$ cards. Alice writes the numbers $1,2,\ldots,n$ once each, and so does Bob (on the same set of cards). Then, they take turns choosing cards according to some specified sequence. In each turn, the player picks the card with his/her smallest number. At the end of the game, Alice notes the sum of her numbers on her cards. Afterwards, the specified sequence is modified by moving some of Alice's turns earlier (no other kind of modification is allowed), and the game is repeated in the same way. Is it true that Alice necessarily gets a smaller or equal sum than before? Example : Alice writes $1, 2, 3, 4$ , Bob writes $1, 3, 4, 2$ . Originally the sequence is Bob, Alice, Bob, Alice. Bob chooses the 1st card, Alice the 2nd, Bob the 4th (because Bob's number on the 4th card is smaller than on the 3rd), and Alice the 3rd, so Alice gets $2+3=5$ . Afterwards, suppose the sequence is modified by moving Alice's first turn to the front, so it is now Alice, Bob, Bob, Alice. Alice chooses the 1st card, Bob the 4th, Bob the 2nd, and Alice the 3rd, so Alice gets $1+3=4$ . To prove that it is true, it would be enough to show that for every $k$ , Alice gets a smaller or equal number in her $k$ -th turn of the original game than in her $k$ -th turn of the modified game. Can this be done possibly by induction?","Alice and Bob play a game with cards. Alice writes the numbers once each, and so does Bob (on the same set of cards). Then, they take turns choosing cards according to some specified sequence. In each turn, the player picks the card with his/her smallest number. At the end of the game, Alice notes the sum of her numbers on her cards. Afterwards, the specified sequence is modified by moving some of Alice's turns earlier (no other kind of modification is allowed), and the game is repeated in the same way. Is it true that Alice necessarily gets a smaller or equal sum than before? Example : Alice writes , Bob writes . Originally the sequence is Bob, Alice, Bob, Alice. Bob chooses the 1st card, Alice the 2nd, Bob the 4th (because Bob's number on the 4th card is smaller than on the 3rd), and Alice the 3rd, so Alice gets . Afterwards, suppose the sequence is modified by moving Alice's first turn to the front, so it is now Alice, Bob, Bob, Alice. Alice chooses the 1st card, Bob the 4th, Bob the 2nd, and Alice the 3rd, so Alice gets . To prove that it is true, it would be enough to show that for every , Alice gets a smaller or equal number in her -th turn of the original game than in her -th turn of the modified game. Can this be done possibly by induction?","n 1,2,\ldots,n 1, 2, 3, 4 1, 3, 4, 2 2+3=5 1+3=4 k k k","['combinatorics', 'induction']"
73,What's the dimension of a Lie algebra generated by transpositions on $n$ objects?,What's the dimension of a Lie algebra generated by transpositions on  objects?,n,"Define a Lie bracket on the group algebra of the permutation group $S_n$ in the following way: $$[\sigma, \tau] = \sigma\circ\tau - \tau\circ\sigma,$$ where $\sigma, \tau \in S_n$ , and the multiplication on permutations is defined as composition. My question is, what is the dimension of the Lie subalgebra generated by transpositions, i.e. $(ij)$ ? My conjecture is that the dimension is given by $C_n - \lfloor \frac{n}{2} \rfloor$ , where $C_n$ is the Catalan number. Is this correct and what is the proof? For example, when $n=3$ , using the cycle notation, we have $$ [(12),(23)] = (132) - (123) \\ [(23),(31)] = (132) - (123) \\ [(31),(12)] = (132) - (123) \\ $$ and $$ [(12), (132) - (123)] = 2((23) - (13)), \text{etc.} $$ Therefore this algebra is $4 = C_3 - 1$ dimensional.","Define a Lie bracket on the group algebra of the permutation group in the following way: where , and the multiplication on permutations is defined as composition. My question is, what is the dimension of the Lie subalgebra generated by transpositions, i.e. ? My conjecture is that the dimension is given by , where is the Catalan number. Is this correct and what is the proof? For example, when , using the cycle notation, we have and Therefore this algebra is dimensional.","S_n [\sigma, \tau] = \sigma\circ\tau - \tau\circ\sigma, \sigma, \tau \in S_n (ij) C_n - \lfloor \frac{n}{2} \rfloor C_n n=3 
[(12),(23)] = (132) - (123) \\
[(23),(31)] = (132) - (123) \\
[(31),(12)] = (132) - (123) \\
 
[(12), (132) - (123)] = 2((23) - (13)), \text{etc.}
 4 = C_3 - 1","['combinatorics', 'permutations', 'lie-algebras', 'catalan-numbers']"
74,Bounds related to satisfiability problem,Bounds related to satisfiability problem,,"This question is regarding MAX-E3SAT problem: Given a set of clauses with exactly three literals, find the maximum number of clauses that can be satisfied. The clauses are expressed as disjunctions of three literals. The literals are variables $x_i\in\{0,1\}$ . Assume that the literals are all distinct in a clause, and no clause has both $x_i$ and $\neg x_i$ as the clause will be trivially satisfied. Furthermore, all clauses are considered to be distinct. Let's say at most a fraction $\alpha$ of the $m$ clauses are satisfiable. Let $k=\sum_i^n (g_i-1)$ , where $n$ is the number of variables and $g_i=\text{max}(\{\text{occurrences of }x_i, \text{occurrences of }\neg x_i\})$ . I want to find lower and upper bounds on the ratio $\frac{m}{k}$ given $\alpha$ . The bounds can be in terms of $\alpha$ . In my attempt I realized that for an instance of E3SAT, with $l$ variables, to be not satisfiable we need $2^l$ clauses at the minimum. So reversing this, if we have $m$ clauses, then the instance is unsatisfiable if it has $< \log_2(m)$ variables. However, I can't seem to find a way to get a constant bound, and carry forward the intuition to any fraction $\alpha$ of the clauses not being satisfiable. Edit: I figured a rather conservative and simple bound for $k$ . Number of occurrences of all the variables in the instance is $3m$ . Then $k< 3m$ . However, this seems to be a very conservative bound.","This question is regarding MAX-E3SAT problem: Given a set of clauses with exactly three literals, find the maximum number of clauses that can be satisfied. The clauses are expressed as disjunctions of three literals. The literals are variables . Assume that the literals are all distinct in a clause, and no clause has both and as the clause will be trivially satisfied. Furthermore, all clauses are considered to be distinct. Let's say at most a fraction of the clauses are satisfiable. Let , where is the number of variables and . I want to find lower and upper bounds on the ratio given . The bounds can be in terms of . In my attempt I realized that for an instance of E3SAT, with variables, to be not satisfiable we need clauses at the minimum. So reversing this, if we have clauses, then the instance is unsatisfiable if it has variables. However, I can't seem to find a way to get a constant bound, and carry forward the intuition to any fraction of the clauses not being satisfiable. Edit: I figured a rather conservative and simple bound for . Number of occurrences of all the variables in the instance is . Then . However, this seems to be a very conservative bound.","x_i\in\{0,1\} x_i \neg x_i \alpha m k=\sum_i^n (g_i-1) n g_i=\text{max}(\{\text{occurrences of }x_i, \text{occurrences of }\neg x_i\}) \frac{m}{k} \alpha \alpha l 2^l m < \log_2(m) \alpha k 3m k< 3m","['combinatorics', 'logic', 'upper-lower-bounds', 'satisfiability']"
75,"Sum $\sum_{(k_1, k_2, k_3): k_1+k_2+k_3=K, \,\, n_1+n_2+n_3=N}k_1^{n_1}\times k_2^{n_2} \times k_3^{n_3}$",Sum,"\sum_{(k_1, k_2, k_3): k_1+k_2+k_3=K, \,\, n_1+n_2+n_3=N}k_1^{n_1}\times k_2^{n_2} \times k_3^{n_3}","Let $k_1, k_2, k_3$ be natural non-negative numbers such that $k_1+k_2+k_3=K$ . Let $n_1, n_2, n_3 \in \{0, \ldots, N\}$ and such that $n_1+n_2+n_3=N$ . Calculate $$ S=\sum_{(k_1, k_2, k_3): k_1+k_2+k_3=K, \,\, n_1+n_2+n_3=N}k_1^{n_1}\times k_2^{n_2} \times k_3^{n_3} $$ My attempt: I am thinking on representing this sum as a chain of sums over each summand $k_j$ . For example, the interior sum would be: $ \sum_{k_3=0}^{K-k_1-k_2}k_3^{n_3}. $ Using Sums of p-th powers formula we can get $$\sum_{k_3=0}^{K-k_1-k_2}k_3^{n_3}=\frac{B_{n_3+1}(K-k_1-k_2+1)-B_{n_3+1}}{n_3}.$$ So, the sum $S$ would be represented as a product of these ratios with Bernoulli numbers $B_n$ . Is there a better way on computing/estimating from above sum $S$ ?","Let be natural non-negative numbers such that . Let and such that . Calculate My attempt: I am thinking on representing this sum as a chain of sums over each summand . For example, the interior sum would be: Using Sums of p-th powers formula we can get So, the sum would be represented as a product of these ratios with Bernoulli numbers . Is there a better way on computing/estimating from above sum ?","k_1, k_2, k_3 k_1+k_2+k_3=K n_1, n_2, n_3 \in \{0, \ldots, N\} n_1+n_2+n_3=N 
S=\sum_{(k_1, k_2, k_3): k_1+k_2+k_3=K, \,\, n_1+n_2+n_3=N}k_1^{n_1}\times k_2^{n_2} \times k_3^{n_3}
 k_j 
\sum_{k_3=0}^{K-k_1-k_2}k_3^{n_3}.
 \sum_{k_3=0}^{K-k_1-k_2}k_3^{n_3}=\frac{B_{n_3+1}(K-k_1-k_2+1)-B_{n_3+1}}{n_3}. S B_n S","['combinatorics', 'number-theory', 'elementary-number-theory', 'bernoulli-numbers', 'bernoulli-polynomials']"
76,"Szemerédi Regularity Lemma - finding regular pairs of ""large"" size","Szemerédi Regularity Lemma - finding regular pairs of ""large"" size",,"The Szemerédi Regularity Lemma states that for every $\epsilon>0$ , there exists a constant $M$ (dependent only on $\epsilon$ ) such that every graph $G$ has a $\epsilon$ -regular partition of its vertex set into at most $M$ parts. If one follows the proof (or other discussion therein) closely, $M$ is actually an astronomically large quantity - basically, $M$ is of the order of $2^{2^{2^{\dots}}}$ where the height is polynomial in $1/\epsilon$ . Thus, by the time one reaches an $\epsilon$ -regular partition guaranteed by the lemma, the part sizes might be some vanishingly small fraction each. Can I do better if I want to find just one $\epsilon$ -regular pair of subsets (not necessarily disjoint or distinct)? Specifically, is it possible to find some $C>0$ such that for every sufficiently small $\epsilon$ (say for all $\epsilon < 1/4$ ), every graph contains some $\epsilon$ -regular pair of vertex subsets (not necessarily disjoint/distinct) such that each is of size at least $(\frac{1}{2})^{(1/\epsilon)^C}|V(G)|$ ? I tried the following approach (which is based on one of the common ways of proving the Szemerédi Regularity Lemma): Let the graph $G$ be given. Start off with $X_0=Y_0=V(G)$ . If $(X_0,Y_0)$ is $\epsilon$ -regular, we are good for this graph $G$ . Otherwise, find $A_0\subset X_0, B_0 \subset Y_0$ which causes the regularity to be violated. Let $X_1$ be the larger of $X_0, X_0-A_0$ and $Y_1$ be the larger of $Y_0, Y_0-B_0$ . Then each of $X_1, Y_1$ is of size $\ge \frac{1}{2}|V(G)|$ . Once again check if $(X_1, Y_1)$ is $\epsilon$ -regular and repeat the above argument. The key then is to show that this process always terminates after a number of steps that is bounded above by polynomial in $1/\epsilon$ . However, this is where I am unable to proceed. I tried to track the energy between the two partitions at each step but the increase in energy is getting smaller geometrically (specifically, the energy between the partitions is guaranteed to increase by $\epsilon^4 (1/4)^k$ at step $k$ ). Thus there is no reason why the process must terminate. Another idea I have : By considering $G$ or its complement, we can reduce the problem to a bipartite graph with $\ge n(n-1)/8$ edges between the ""left"" and ""right"" parts, and the goal is to find a subset on the left and a subset on the right so that these two form a regular pair.","The Szemerédi Regularity Lemma states that for every , there exists a constant (dependent only on ) such that every graph has a -regular partition of its vertex set into at most parts. If one follows the proof (or other discussion therein) closely, is actually an astronomically large quantity - basically, is of the order of where the height is polynomial in . Thus, by the time one reaches an -regular partition guaranteed by the lemma, the part sizes might be some vanishingly small fraction each. Can I do better if I want to find just one -regular pair of subsets (not necessarily disjoint or distinct)? Specifically, is it possible to find some such that for every sufficiently small (say for all ), every graph contains some -regular pair of vertex subsets (not necessarily disjoint/distinct) such that each is of size at least ? I tried the following approach (which is based on one of the common ways of proving the Szemerédi Regularity Lemma): Let the graph be given. Start off with . If is -regular, we are good for this graph . Otherwise, find which causes the regularity to be violated. Let be the larger of and be the larger of . Then each of is of size . Once again check if is -regular and repeat the above argument. The key then is to show that this process always terminates after a number of steps that is bounded above by polynomial in . However, this is where I am unable to proceed. I tried to track the energy between the two partitions at each step but the increase in energy is getting smaller geometrically (specifically, the energy between the partitions is guaranteed to increase by at step ). Thus there is no reason why the process must terminate. Another idea I have : By considering or its complement, we can reduce the problem to a bipartite graph with edges between the ""left"" and ""right"" parts, and the goal is to find a subset on the left and a subset on the right so that these two form a regular pair.","\epsilon>0 M \epsilon G \epsilon M M M 2^{2^{2^{\dots}}} 1/\epsilon \epsilon \epsilon C>0 \epsilon \epsilon < 1/4 \epsilon (\frac{1}{2})^{(1/\epsilon)^C}|V(G)| G X_0=Y_0=V(G) (X_0,Y_0) \epsilon G A_0\subset X_0, B_0 \subset Y_0 X_1 X_0, X_0-A_0 Y_1 Y_0, Y_0-B_0 X_1, Y_1 \ge \frac{1}{2}|V(G)| (X_1, Y_1) \epsilon 1/\epsilon \epsilon^4 (1/4)^k k G \ge n(n-1)/8","['combinatorics', 'graph-theory', 'additive-combinatorics']"
77,Proving that a combinatorial expression is an integer without combinatorics,Proving that a combinatorial expression is an integer without combinatorics,,"The number of ways to tile an $m \times n$ rectangle with dominos is $$S_{m,n} = \prod_{j=1}^{\lceil \frac{m}{2} \rceil} \prod_{k=1}^{\lceil \frac{n}{2} \rceil}\left( 4 \cos^2 \frac{\pi j}{m+1} + 4 \cos^2 \frac{\pi k}{n+1} \right) $$ How can we prove that this expression is an integer without appeal to its combinatorial interpretation? It's been suggested to me that since the expression above is an algebraic integer, it suffices to show that it is rational using Galois theory, but I am not familiar enough with Galois theory to produce such an argument. Edit: Following the hint below, using $\cos(\theta) = \frac{e^{i\theta} + e^{-i\theta}}{2}$ , we have that $\cos^2(\theta) = \frac{e^{2i\theta}  + e^{-2i\theta} + 2}{4}$ with which we can rewrite $$S_{m,n} = \prod_{j=1}^{\lceil \frac{m}{2} \rceil}\prod_{k=1}^{\lceil \frac{n}{2} \rceil} \left(e^{\frac{2\pi i j}{m+1}} + e^{-\frac{2\pi i j}{m+1}}  + e^{\frac{2 \pi i k}{n+1}} + e^{-\frac{2 \pi i k}{n+1}} +4 \right) =\prod_{j=1}^{\lceil \frac{m}{2} \rceil}\prod_{k=1}^{\lceil \frac{n}{2} \rceil} \left(\zeta_{m+1}^j + \zeta_{m+1}^{-j} + \zeta_{n+1}^k + \zeta_{n+1}^{-k} +4 \right) $$ Clearly, $S_{m,n} \in \mathbb{Q}[\zeta_{m+1},\zeta_{n+1}]$ where $\zeta_k = e^\frac{2\pi i }{k}$ . Then $\Gamma(\mathbb{Q}[\zeta_{m+1},\zeta_{n+1}]/\mathbb{Q}) \subseteq (\mathbb{Z}/m \mathbb{Z})^\times \times (\mathbb{Z}/n \mathbb{Z})^\times$ generated by the automorphisms $\zeta_{m+1} \mapsto \zeta_{m+1}^a$ for $1 \leq a < m+1$ relatively prime to $m+1$ and $\zeta_{n+1} \mapsto \zeta_{n+1}^b$ for $1 \leq b < n+1$ relatively prime to $n+1$ . From here, I don't know how to show that $S_{m,n}$ is invariant under this action, as (for example) $\zeta_{m+1}^{\lceil \frac{m}{2} \rceil -1} \mapsto \left(\zeta_{m+1}^{\lceil \frac{m}{2} \rceil -1}\right)^2$ gives rise to a term outside the index of the product. We can rewrite $$S_{m,n} = 2\prod_{j=1}^m \prod_{k=1}^n \left(\cos \frac{\pi j}{m+1} + i \cos \frac{\pi k}{n+1} \right) $$ using the properties of the cosine. We further expand this as above: $$S_{m,n} = \prod_{j=1}^m \prod_{k=1}^n \left(e^{i\frac{\pi j}{m+1}} + e^{-i\frac{\pi j}{m+1}} + e^{i\frac{\pi k}{n+1}} + e^{-i\frac{\pi k}{n+1}} \right)  = \prod_{j=1}^m \prod_{k=1}^n (\zeta_{2m+2}^j + \zeta_{2m+2}^{-j} + \zeta_{2n+2}^k + \zeta_{2n+2}^{-k})$$ but we have the same problem here as above, there are too many automorphisms.","The number of ways to tile an rectangle with dominos is How can we prove that this expression is an integer without appeal to its combinatorial interpretation? It's been suggested to me that since the expression above is an algebraic integer, it suffices to show that it is rational using Galois theory, but I am not familiar enough with Galois theory to produce such an argument. Edit: Following the hint below, using , we have that with which we can rewrite Clearly, where . Then generated by the automorphisms for relatively prime to and for relatively prime to . From here, I don't know how to show that is invariant under this action, as (for example) gives rise to a term outside the index of the product. We can rewrite using the properties of the cosine. We further expand this as above: but we have the same problem here as above, there are too many automorphisms.","m \times n S_{m,n} = \prod_{j=1}^{\lceil \frac{m}{2} \rceil} \prod_{k=1}^{\lceil \frac{n}{2} \rceil}\left( 4 \cos^2 \frac{\pi j}{m+1} + 4 \cos^2 \frac{\pi k}{n+1} \right)  \cos(\theta) = \frac{e^{i\theta} + e^{-i\theta}}{2} \cos^2(\theta) = \frac{e^{2i\theta}  + e^{-2i\theta} + 2}{4} S_{m,n} = \prod_{j=1}^{\lceil \frac{m}{2} \rceil}\prod_{k=1}^{\lceil \frac{n}{2} \rceil} \left(e^{\frac{2\pi i j}{m+1}} + e^{-\frac{2\pi i j}{m+1}}  + e^{\frac{2 \pi i k}{n+1}} + e^{-\frac{2 \pi i k}{n+1}} +4 \right) =\prod_{j=1}^{\lceil \frac{m}{2} \rceil}\prod_{k=1}^{\lceil \frac{n}{2} \rceil} \left(\zeta_{m+1}^j + \zeta_{m+1}^{-j} + \zeta_{n+1}^k + \zeta_{n+1}^{-k} +4 \right)  S_{m,n} \in \mathbb{Q}[\zeta_{m+1},\zeta_{n+1}] \zeta_k = e^\frac{2\pi i }{k} \Gamma(\mathbb{Q}[\zeta_{m+1},\zeta_{n+1}]/\mathbb{Q}) \subseteq (\mathbb{Z}/m \mathbb{Z})^\times \times (\mathbb{Z}/n \mathbb{Z})^\times \zeta_{m+1} \mapsto \zeta_{m+1}^a 1 \leq a < m+1 m+1 \zeta_{n+1} \mapsto \zeta_{n+1}^b 1 \leq b < n+1 n+1 S_{m,n} \zeta_{m+1}^{\lceil \frac{m}{2} \rceil -1} \mapsto \left(\zeta_{m+1}^{\lceil \frac{m}{2} \rceil -1}\right)^2 S_{m,n} = 2\prod_{j=1}^m \prod_{k=1}^n \left(\cos \frac{\pi j}{m+1} + i \cos \frac{\pi k}{n+1} \right)  S_{m,n} = \prod_{j=1}^m \prod_{k=1}^n \left(e^{i\frac{\pi j}{m+1}} + e^{-i\frac{\pi j}{m+1}} + e^{i\frac{\pi k}{n+1}} + e^{-i\frac{\pi k}{n+1}} \right)  = \prod_{j=1}^m \prod_{k=1}^n (\zeta_{2m+2}^j + \zeta_{2m+2}^{-j} + \zeta_{2n+2}^k + \zeta_{2n+2}^{-k})","['combinatorics', 'galois-theory', 'tiling']"
78,"Conjecture about $(0,1)$-matrices",Conjecture about -matrices,"(0,1)","Let $A$ be an $m$ by $n$ $(0,1)$ -matrix. For $1\leq i \leq m$ and $1\leq j \leq n$ , let $f(A,i,j)$ be the number of entries in $A$ not in row $i$ , not in column $j$ , and not equal to $a_{ij}$ . I would like a proof or counterexample to the following conjecture: If $A$ is not all 1's or all 0's, then there exist $i$ and $j$ such that $f(A,i,j)\geq \frac{(m-1)(n-1)-1}{2}$ . Example 1: For $A=\begin{bmatrix} 1 & 0 & 1 & 0\\0 & 1 & 0 & 1 \\1 & 0 & 1 & 0\\0 & 1 & 0 & 1 \\\end{bmatrix}$ , we have $f(A,1,1)=4\geq\frac{3\cdot3-1}{2}$ . Example 2: For $A=\begin{bmatrix} 0 & 1 & 0 & 0 & 1\\1 & 0 & 0 & 1 & 0 \\1 & 0 & 1 & 0 & 1\\0 & 0 & 0 & 0 & 1\\\end{bmatrix}$ , we have $f(A,1,2)=6\geq\frac{3\cdot 4-1}{2}$ .","Let be an by -matrix. For and , let be the number of entries in not in row , not in column , and not equal to . I would like a proof or counterexample to the following conjecture: If is not all 1's or all 0's, then there exist and such that . Example 1: For , we have . Example 2: For , we have .","A m n (0,1) 1\leq i \leq m 1\leq j \leq n f(A,i,j) A i j a_{ij} A i j f(A,i,j)\geq \frac{(m-1)(n-1)-1}{2} A=\begin{bmatrix} 1 & 0 & 1 & 0\\0 & 1 & 0 & 1 \\1 & 0 & 1 & 0\\0 & 1 & 0 & 1 \\\end{bmatrix} f(A,1,1)=4\geq\frac{3\cdot3-1}{2} A=\begin{bmatrix} 0 & 1 & 0 & 0 & 1\\1 & 0 & 0 & 1 & 0 \\1 & 0 & 1 & 0 & 1\\0 & 0 & 0 & 0 & 1\\\end{bmatrix} f(A,1,2)=6\geq\frac{3\cdot 4-1}{2}","['combinatorics', 'matrix-analysis']"
79,"A finite abelian group ""take-away"" game","A finite abelian group ""take-away"" game",,"Fix a finite abelian group $G=\bigoplus_{i=1}^{n} \mathbb{Z}/n_i\mathbb{Z}$ . Suppose we play the following game. For any $1 \leq k < |G| $ , we choose $k$ elements from the group at random without replacement. If the $k$ elements sum to $0$ , we win. Else we lose. Which $k$ should we pick? Of course, $k$ depends on $G$ (which is more or less characterized by the $n_i$ 's). We can ask questions like this for general non-abelian groups, where the order we choose elements matters, and that is precisely the order we perform the group operation. But I suspect it gets hard in this case. Note I $\textit{expressly exclude}$ the case that $k=|G|$ , for the simple fact that it's generally going to be quite likely that the elements sum to $0$ in that case (for instance, if the group has odd order, or has even order and more than one element of order $2$ ). Note also that partial answers are acceptable since this seems to be a not-so-easy problem. For instance, if you have an answer for the specific case where $G$ is cyclic, feel free to mention it.","Fix a finite abelian group . Suppose we play the following game. For any , we choose elements from the group at random without replacement. If the elements sum to , we win. Else we lose. Which should we pick? Of course, depends on (which is more or less characterized by the 's). We can ask questions like this for general non-abelian groups, where the order we choose elements matters, and that is precisely the order we perform the group operation. But I suspect it gets hard in this case. Note I the case that , for the simple fact that it's generally going to be quite likely that the elements sum to in that case (for instance, if the group has odd order, or has even order and more than one element of order ). Note also that partial answers are acceptable since this seems to be a not-so-easy problem. For instance, if you have an answer for the specific case where is cyclic, feel free to mention it.",G=\bigoplus_{i=1}^{n} \mathbb{Z}/n_i\mathbb{Z} 1 \leq k < |G|  k k 0 k k G n_i \textit{expressly exclude} k=|G| 0 2 G,"['combinatorics', 'group-theory']"
80,Deck of 5 cards Shuffling Problem but only allowed to choose two adjacent cards,Deck of 5 cards Shuffling Problem but only allowed to choose two adjacent cards,,"Say I have a deck of 5 cards that are labeled 1, 2, 3, 4, 5. 1 being at the top and 5 being at the bottom. The rules of this game are as follows. You can take only take two adjacent cards (1 2, 2 3, 3 4, or 4 5) and insert them anywhere else in the stack. For example I could take the 1 2 out and put it in between 4 and 5 to make the deck look like 3 4 1 2 5. I cannot change the order of the two adjacent cards I take out and reinsert. With the deck 3 4 1 2 5, I can take for example, the 2 5 and move it to the front to make 2 5 3 4 1. The question is as follows: I use the above rule starting with the deck 1 2 3 4 5. If I use this ""shuffle"" maneuver as many times as I would like, is it possible to get to the deck 2 1 3 4 5. I ran a computer program and it said this isn't possible. In fact I noticed that there were 60 decks possible starting with 1 2 3 4 5. I can't seem prove this without blindly listing all decks. Is there a way to prove that 1 2 3 4 5 cant get to 2 1 3 4 5?","Say I have a deck of 5 cards that are labeled 1, 2, 3, 4, 5. 1 being at the top and 5 being at the bottom. The rules of this game are as follows. You can take only take two adjacent cards (1 2, 2 3, 3 4, or 4 5) and insert them anywhere else in the stack. For example I could take the 1 2 out and put it in between 4 and 5 to make the deck look like 3 4 1 2 5. I cannot change the order of the two adjacent cards I take out and reinsert. With the deck 3 4 1 2 5, I can take for example, the 2 5 and move it to the front to make 2 5 3 4 1. The question is as follows: I use the above rule starting with the deck 1 2 3 4 5. If I use this ""shuffle"" maneuver as many times as I would like, is it possible to get to the deck 2 1 3 4 5. I ran a computer program and it said this isn't possible. In fact I noticed that there were 60 decks possible starting with 1 2 3 4 5. I can't seem prove this without blindly listing all decks. Is there a way to prove that 1 2 3 4 5 cant get to 2 1 3 4 5?",,"['combinatorics', 'permutations', 'card-games']"
81,"Complicated recursion formula, seems similar to Bell numbers?","Complicated recursion formula, seems similar to Bell numbers?",,"I came up with a recursive formula for a problem I was working on.  It is as follows. $$a_n = \Big(\frac{1-q^{f \cdot n}}{1-q^n}\Big)\displaystyle\Big(1+\sum_{i=0}^{n-1}\binom{n}{i}p^{n-i}q^ia_i\Big)$$ Here $a_0 = 0$ $p, q\in [0,1],$ $p + q = 1,$ and $f$ is a positive integer. Is there anyway to give a closed form solution to this equation? Off the top of my head this seems related to Bell Numbers. Other thought were to try setting $$\alpha(n) = \frac{1-q^{f \cdot n}}{1-q^n}$$ and then simplifying $$\frac{a_n}{\alpha(n)} - p\cdot\frac{a_{n-1}}{\alpha(n-1)}$$ using $$\binom{n}{k} = \binom{n-1}{k} + \binom{n-1}{k-1}.$$ I think I keep getting errors, but this should give something close to  $$\frac{a_n}{\alpha(n)} - p\cdot\frac{a_{n-1}}{\alpha(n-1)} = (1-p) + n\cdot p^1q^{n-1}a_{n-1} + \displaystyle\sum_{i=0}^{n-2}\binom{n-i}{i}p^{n-i}q^ia_i.$$ I think $$\displaystyle\sum_{i=0}^{n-2}\binom{n-i}{i}p^{n-i}q^ia_i = p\cdot\displaystyle\sum_{i=0}^{n-2}\binom{n-i}{i}p^{(n-1) - i}q^ia_i = p\Big(\frac{a_{n-i}}{\alpha(n)} - 1\Big).$$ I should then be able to stick this back in and solve. However, I seem to get a different answer, and regardless, this still is far from being a closed form solution. Any suggestions?  Thank you!","I came up with a recursive formula for a problem I was working on.  It is as follows. $$a_n = \Big(\frac{1-q^{f \cdot n}}{1-q^n}\Big)\displaystyle\Big(1+\sum_{i=0}^{n-1}\binom{n}{i}p^{n-i}q^ia_i\Big)$$ Here $a_0 = 0$ $p, q\in [0,1],$ $p + q = 1,$ and $f$ is a positive integer. Is there anyway to give a closed form solution to this equation? Off the top of my head this seems related to Bell Numbers. Other thought were to try setting $$\alpha(n) = \frac{1-q^{f \cdot n}}{1-q^n}$$ and then simplifying $$\frac{a_n}{\alpha(n)} - p\cdot\frac{a_{n-1}}{\alpha(n-1)}$$ using $$\binom{n}{k} = \binom{n-1}{k} + \binom{n-1}{k-1}.$$ I think I keep getting errors, but this should give something close to  $$\frac{a_n}{\alpha(n)} - p\cdot\frac{a_{n-1}}{\alpha(n-1)} = (1-p) + n\cdot p^1q^{n-1}a_{n-1} + \displaystyle\sum_{i=0}^{n-2}\binom{n-i}{i}p^{n-i}q^ia_i.$$ I think $$\displaystyle\sum_{i=0}^{n-2}\binom{n-i}{i}p^{n-i}q^ia_i = p\cdot\displaystyle\sum_{i=0}^{n-2}\binom{n-i}{i}p^{(n-1) - i}q^ia_i = p\Big(\frac{a_{n-i}}{\alpha(n)} - 1\Big).$$ I should then be able to stick this back in and solve. However, I seem to get a different answer, and regardless, this still is far from being a closed form solution. Any suggestions?  Thank you!",,"['combinatorics', 'generating-functions', 'bell-numbers']"
82,What is the best strategy in the game $3 \times 3$?,What is the best strategy in the game ?,3 \times 3,"2 people play The field of the game is a board of size 3 to 3. The horizontals are numbered-numbers from 1 to 3, and verticals from a to c Each player has an army of 100 tanks Before the battle at night, each side secretly places its tanks in an arbitrary way on 9 squares. On any cell, you can put any number of tanks from 0 to 100. In the morning the battle begins. On each of the 9 cells, the player who has more tanks on this cage wins. For the victory on each of the 9 cells is given 1 point. If there is an equal number of tanks on both sides, then the battle on this cage ends in a draw, and both players receive 0.5 points. Question: What strategy is best for obtaining the maximum number of points?","2 people play The field of the game is a board of size 3 to 3. The horizontals are numbered-numbers from 1 to 3, and verticals from a to c Each player has an army of 100 tanks Before the battle at night, each side secretly places its tanks in an arbitrary way on 9 squares. On any cell, you can put any number of tanks from 0 to 100. In the morning the battle begins. On each of the 9 cells, the player who has more tanks on this cage wins. For the victory on each of the 9 cells is given 1 point. If there is an equal number of tanks on both sides, then the battle on this cage ends in a draw, and both players receive 0.5 points. Question: What strategy is best for obtaining the maximum number of points?",,"['combinatorics', 'game-theory']"
83,Probability to draw equal number of red and green marbles,Probability to draw equal number of red and green marbles,,"From an urn containing equal number of red and green marbles, we draw an even number of marbles. Prove that the probability of drawing an equal number of marbles from each color is $\frac{2}{\sqrt{n\pi}}$. I am not sure: I think that the probability is $$\frac{\sum_{k = 2}^{n} C(k, k/2)}{\sum C(n, k)}$$ where k is even.  Then by Stirling's approximation, we have $C(2k, k)= \frac{4^k}{\sqrt{k\pi}}$?","From an urn containing equal number of red and green marbles, we draw an even number of marbles. Prove that the probability of drawing an equal number of marbles from each color is $\frac{2}{\sqrt{n\pi}}$. I am not sure: I think that the probability is $$\frac{\sum_{k = 2}^{n} C(k, k/2)}{\sum C(n, k)}$$ where k is even.  Then by Stirling's approximation, we have $C(2k, k)= \frac{4^k}{\sqrt{k\pi}}$?",,['combinatorics']
84,How many total orders consistent with a partial order?,How many total orders consistent with a partial order?,,"I have a finite set of objects $X$, whose power set is partially ordered by $\subseteq$. Consider all possible total orderings of the power set $\mathscr{P}(X)$ which are compatible with the partial order $\subseteq$ in the sense that $A \subsetneq B \Rightarrow A \prec B$. How many compatible total orders are there? Some orders $\prec$ have the special property that they can be concretely quantified by assigning numerical weights to each element in the set; then a subset has a smaller total weight than another subset if and only if the subsets are related by $\prec$. Specifically, this means that you can find a weight assignment function $f:\mathscr{P}(X)\rightarrow \mathbb{R}^+$ such that every subset's weight is the sum of its elements' weights: $$\forall S\subseteq X,\quad f(S) = \sum_{x\in S} f(\{x\})$$ and the weight respects order in that $f(S) < f(T) \iff S \prec T.$ How many quantifiable total orders are there?  (For my applications, I'm interested in weight assignments where $f(S) = 0 \iff S = \varnothing$.)","I have a finite set of objects $X$, whose power set is partially ordered by $\subseteq$. Consider all possible total orderings of the power set $\mathscr{P}(X)$ which are compatible with the partial order $\subseteq$ in the sense that $A \subsetneq B \Rightarrow A \prec B$. How many compatible total orders are there? Some orders $\prec$ have the special property that they can be concretely quantified by assigning numerical weights to each element in the set; then a subset has a smaller total weight than another subset if and only if the subsets are related by $\prec$. Specifically, this means that you can find a weight assignment function $f:\mathscr{P}(X)\rightarrow \mathbb{R}^+$ such that every subset's weight is the sum of its elements' weights: $$\forall S\subseteq X,\quad f(S) = \sum_{x\in S} f(\{x\})$$ and the weight respects order in that $f(S) < f(T) \iff S \prec T.$ How many quantifiable total orders are there?  (For my applications, I'm interested in weight assignments where $f(S) = 0 \iff S = \varnothing$.)",,"['combinatorics', 'measure-theory', 'order-theory']"
85,Broken stick game,Broken stick game,,"Two players Alice and Bob play the following game consisting of $n-1$ turns. Initially the segment $[0,1]$ is given. Alice and Bob then alternate breaking one segment into two pieces. After all turns have passed, there are $n$ pieces. What is the maximum number of triangles Alice can guarantee forming? If you cannot see the answer for the total can you at least give the answer for the case $n=4$ or higher because I'm lost. Anything would help. Thanks.","Two players Alice and Bob play the following game consisting of $n-1$ turns. Initially the segment $[0,1]$ is given. Alice and Bob then alternate breaking one segment into two pieces. After all turns have passed, there are $n$ pieces. What is the maximum number of triangles Alice can guarantee forming? If you cannot see the answer for the total can you at least give the answer for the case $n=4$ or higher because I'm lost. Anything would help. Thanks.",,"['combinatorics', 'discrete-mathematics']"
86,Where can I find precise examples of ramified coverings of $\mathbb{C}P^1$?,Where can I find precise examples of ramified coverings of ?,\mathbb{C}P^1,"One of the definitions of simple Hurwitz number $h_{g,\mu}$ is that it counts up to automorphisms the number of ramified coverings of $\mathbb{C}P^1$ such that covering space is a connected surface of genus $g$ and covering map has only one non-regular branchpoint with the ramification profile $\mu$. Where can I find examples of such coverings for small $g$ and $\mu$ just not to reinvent them by myself? Maybe anyone can give me a link to any paper or even provide them here? I did some work where proved that different possible ways to calculate Hurwitz numbers give the same results and now just looking for some pretty visual material to illustrate low genus and ramification profile examples.","One of the definitions of simple Hurwitz number $h_{g,\mu}$ is that it counts up to automorphisms the number of ramified coverings of $\mathbb{C}P^1$ such that covering space is a connected surface of genus $g$ and covering map has only one non-regular branchpoint with the ramification profile $\mu$. Where can I find examples of such coverings for small $g$ and $\mu$ just not to reinvent them by myself? Maybe anyone can give me a link to any paper or even provide them here? I did some work where proved that different possible ways to calculate Hurwitz numbers give the same results and now just looking for some pretty visual material to illustrate low genus and ramification profile examples.",,"['combinatorics', 'examples-counterexamples', 'riemann-surfaces', 'geometric-topology', 'covering-spaces']"
87,Sequential square packings,Sequential square packings,,"There are various studies for packing sequential squares of size $1$ to $n$ . We can try to find the smallest square they will pack into, as in tightly packed squares . We can find the smallest square they will fit into, A005842 . We can find an optimal stacking for them. Adam Ponting found an efficient packing for squares of size $1$ to $(2 n+1)^2$ , as seen in his article square packing . I expanded that for Ponting Square Packing . In the below, an offset is used on his method to pack squares of size 32 to 200. A value of 31 can be subtracted from all sizes for a packing of squares 1 to 169. So, what is a square packing?  For the purposes of this article, I'll define it as follows: Up to 4 squares can have 2 fully exposed edges. All other squares must have 2 or more edges fully covered and a third at least partially covered. No holes are allowed in the packing. Ponting mentions only finding packings for an odd square number of sequential squares.  I took a look at order-4 and sizes representable in a 4x4 matrix and found 8 solutions. The second one has squares with sizes {{11, 8, 15,6},{7,12,5,16},{9,4,13,2},{3,10,1,14}}. I haven't been able to find solutions with a 6x6 or higher even matrix. Can anyone find those, or other square packings of sequential squares?","There are various studies for packing sequential squares of size to . We can try to find the smallest square they will pack into, as in tightly packed squares . We can find the smallest square they will fit into, A005842 . We can find an optimal stacking for them. Adam Ponting found an efficient packing for squares of size to , as seen in his article square packing . I expanded that for Ponting Square Packing . In the below, an offset is used on his method to pack squares of size 32 to 200. A value of 31 can be subtracted from all sizes for a packing of squares 1 to 169. So, what is a square packing?  For the purposes of this article, I'll define it as follows: Up to 4 squares can have 2 fully exposed edges. All other squares must have 2 or more edges fully covered and a third at least partially covered. No holes are allowed in the packing. Ponting mentions only finding packings for an odd square number of sequential squares.  I took a look at order-4 and sizes representable in a 4x4 matrix and found 8 solutions. The second one has squares with sizes {{11, 8, 15,6},{7,12,5,16},{9,4,13,2},{3,10,1,14}}. I haven't been able to find solutions with a 6x6 or higher even matrix. Can anyone find those, or other square packings of sequential squares?",1 n 1 (2 n+1)^2,"['combinatorics', 'matrices', 'recreational-mathematics', 'packing-problem', 'tiling']"
88,Determinant of Matrix is Not Zero (combinatorial proof?),Determinant of Matrix is Not Zero (combinatorial proof?),,"Fix $n>k>1$. Define $\mathcal {A}(i,j)$ be the set of all sets $A\subset \{1,\ldots,n\}$ such that: $A$ has $k-1$ elements, $i\not\in A$ and also $j\not\in A$. Also, for $A$ in $\mathcal {A}(i,j)$ let $B_{i,j}(A)= \{1,\ldots,n\}\backslash \left(A\cup\{i,j\}\right)$. Consider the following matrix: $$M=\begin{cases} m_{i,j}=0&\text{ if } i=j, \text{ and }\\ m_{i,j}=\sum_{A\in \mathcal {A}(i,j)}\left( \prod_{l\in A} y_l \prod_{l\in B_{i,j}(A)} x_l\right)&\text{ if } i\neq j\end{cases},$$ where $x_l,y_l>0$ for all $l$. Conjecture : $\det(M)\neq 0$ or more precisely, $\mathrm{sign}(\det(M))=(-1)^{n-1}$. For cases that I can compute with 11G memory and 8 nodes in a Linux cluster, the determinant above has sign $(-1)^{n-1}$. In the case $\mathbf{n=4}$, it is easy to check that the even permutations whose corresponding addends are nonzero (i.e., that have no fixed points) have two cycles of length two. For example, (12)(34) corresponds to the term $+m_{1,2}^2\,m_{3,4}^2$ in the expansion of the det. The odd permutations always come in pairs. For example, both (1234) and (1432) correspond to the term $-m_{1,2}\,m_{2,3}\,m_{3,4}\,m_{1,4}$ so we have $-2m_{1,2}\,m_{2,3}\,m_{3,4}\,m_{1,4}$ in the expansion of the det. Now, by definition of $m_{i,j}$, it is easy to check that:  $$ m_{1,2}^2\,m_{3,4}^2<m_{1,2}\,m_{2,3}\,m_{3,4}\,m_{1,4}+m_{1,2}\,m_{1,3}\,m_{3,4}\,m_{2,4}.$$ Thus, using symmetry, we can show that all positive terms are dominated by the negative terms. For higher $n$, a similar argument should work. I'm trying to 1) identify which are the even permutations (when $n$ is even) and 2) show that there are lots of odd permutations that allow us to kill the terms associated to the even permuations. For odd $n$, it is the opposite. Mathematica code to count the signs of the terms in the expansion of the determinant (it does not work when $k-1=n$ but this case I proved by hand): Dy[k_, n_] :=   Module[{f, i, j, a, b, L, c},    f[i_, j_] :=     Boole[i != j]*     Sum[Product[x[a], {a, s}]*       Product[y[b], {b,          Complement[Delete[Range[n], {{i}, {j}}], s]}], {s,        Subsets[Delete[Range[n], {{i}, {j}}], {k - 1}]}];    L = List @@ Expand[Det[Array[f, {n, n}]]];   c = Count[L, _?Internal`SyntacticNegativeQ];   {c, Length[L]}]","Fix $n>k>1$. Define $\mathcal {A}(i,j)$ be the set of all sets $A\subset \{1,\ldots,n\}$ such that: $A$ has $k-1$ elements, $i\not\in A$ and also $j\not\in A$. Also, for $A$ in $\mathcal {A}(i,j)$ let $B_{i,j}(A)= \{1,\ldots,n\}\backslash \left(A\cup\{i,j\}\right)$. Consider the following matrix: $$M=\begin{cases} m_{i,j}=0&\text{ if } i=j, \text{ and }\\ m_{i,j}=\sum_{A\in \mathcal {A}(i,j)}\left( \prod_{l\in A} y_l \prod_{l\in B_{i,j}(A)} x_l\right)&\text{ if } i\neq j\end{cases},$$ where $x_l,y_l>0$ for all $l$. Conjecture : $\det(M)\neq 0$ or more precisely, $\mathrm{sign}(\det(M))=(-1)^{n-1}$. For cases that I can compute with 11G memory and 8 nodes in a Linux cluster, the determinant above has sign $(-1)^{n-1}$. In the case $\mathbf{n=4}$, it is easy to check that the even permutations whose corresponding addends are nonzero (i.e., that have no fixed points) have two cycles of length two. For example, (12)(34) corresponds to the term $+m_{1,2}^2\,m_{3,4}^2$ in the expansion of the det. The odd permutations always come in pairs. For example, both (1234) and (1432) correspond to the term $-m_{1,2}\,m_{2,3}\,m_{3,4}\,m_{1,4}$ so we have $-2m_{1,2}\,m_{2,3}\,m_{3,4}\,m_{1,4}$ in the expansion of the det. Now, by definition of $m_{i,j}$, it is easy to check that:  $$ m_{1,2}^2\,m_{3,4}^2<m_{1,2}\,m_{2,3}\,m_{3,4}\,m_{1,4}+m_{1,2}\,m_{1,3}\,m_{3,4}\,m_{2,4}.$$ Thus, using symmetry, we can show that all positive terms are dominated by the negative terms. For higher $n$, a similar argument should work. I'm trying to 1) identify which are the even permutations (when $n$ is even) and 2) show that there are lots of odd permutations that allow us to kill the terms associated to the even permuations. For odd $n$, it is the opposite. Mathematica code to count the signs of the terms in the expansion of the determinant (it does not work when $k-1=n$ but this case I proved by hand): Dy[k_, n_] :=   Module[{f, i, j, a, b, L, c},    f[i_, j_] :=     Boole[i != j]*     Sum[Product[x[a], {a, s}]*       Product[y[b], {b,          Complement[Delete[Range[n], {{i}, {j}}], s]}], {s,        Subsets[Delete[Range[n], {{i}, {j}}], {k - 1}]}];    L = List @@ Expand[Det[Array[f, {n, n}]]];   c = Count[L, _?Internal`SyntacticNegativeQ];   {c, Length[L]}]",,"['combinatorics', 'permutations', 'determinant']"
89,"How to find number of integral solutions, containing large number of cases?","How to find number of integral solutions, containing large number of cases?",,"Number of positive unequal integral solutions of the equation $x+y+z=12$ can be found out knowing the cases it involves: $(1, 2, 9) , (1,3,8), (1,4,7), (1,5,6), (2,3,7), (2,4,6) and (3,4,5)$. Thus, the number of positive integral solutions of the above equation = $7×3! = 42$. Now suppose the equation is like this: $a+b+c+d+e=99$. In this equation if we follow the above followed method then it'll take me decades to find out all the cases. What should be my approach now in order to find out the number of solutions?","Number of positive unequal integral solutions of the equation $x+y+z=12$ can be found out knowing the cases it involves: $(1, 2, 9) , (1,3,8), (1,4,7), (1,5,6), (2,3,7), (2,4,6) and (3,4,5)$. Thus, the number of positive integral solutions of the above equation = $7×3! = 42$. Now suppose the equation is like this: $a+b+c+d+e=99$. In this equation if we follow the above followed method then it'll take me decades to find out all the cases. What should be my approach now in order to find out the number of solutions?",,"['combinatorics', 'permutations', 'binomial-coefficients', 'combinations']"
90,Central limit theorem for perfect matching counts,Central limit theorem for perfect matching counts,,"$\require{begingroup}\begingroup \DeclareMathOperator{\Var}{Var}$ Let $N_G$ denote the number of copies of a graph $G$ in the Erdős–Rényi random graph model $G(n,p)$ . We have the law of large numbers for the number of copies of of graph $G$ , i.e., $N_G$ is very close to the expectation $EN_G$ . This means that whenever the expectation tends to zero, $N_G$ also tends to zero and we have $$\frac{N_G - EN_G}{EN_G} \overset{p}{\rightarrow} 0.$$ Now we are interested to know whether the central limit theorem is also true: i.e., \begin{equation} \cfrac{N_G-EN_G}{\sqrt{\Var N_G}}\overset{d}{\rightarrow}\mathcal{N}(0,1), \end{equation} for $\mathcal{N}(0,1)$ the standard normal distribution. As with the Poisson limit theorem for the number of copies of $G$ , this fact can also be proved by the method of moments. So if we can prove that if we have a sequence of random variables and for any $k$ , the $k$ th moment of the sequence tends to the $k$ th moment of a standard normal random variable, then this convergence in distribution also holds. To prove this, we need to prove that the $k$ th moment of $E(\frac{N_G - EN_G}{\sqrt{\Var N_G}})^k$ is equal to $\frac{E(N_G - EN_G)^k}{(\sqrt{\Var N_G})^k}$ when $k$ is even. To do this we use the indicator function and the collection of $k$ vertices that can be pairwise disjoint or maybe not; i.e., maybe the first collection and the second are not disjoint or the the second and third and $\dots$ and maybe all of them are not disjoint! But we can use some notation in this case that maybe will help me. We can consider a graph of relations between our collections and we can say that two collections are related to each other when they are not disjoint. So we can consider a graph on $k$ vertices such that each vertex is one of our collections and two vertices are adjacent when their collection do intersect (have nonempty intersection). And it turns out that there are three situations here for such a graph $H$ on $k$ vertices with the above-mentioned specification. In fact we have a lot of graphs here, i.e., $2^{{k \choose 2}}$ graphs, but we have only three different situations: $H$ has an isolated vertex. $H$ is a perfect matching. else. Now let me put what I said in equations to make it possible to understand the proof of the second case better: Let's drop the denominator.  We have \begin{eqnarray} E(N_G-EN_G)^k &=& E(\sum_i(I_i-EI_i))^k\\ &=&\sum_{i_i,\ldots,i_k\in I}E((I_{i_1}-EI_{i_1})\cdots(I_{i_k}-EI_{i_k})) \end{eqnarray} where $N_G=\sum_iI_i$ . Now $i_j\sim i_k \iff i_j\cap i_k \ne \emptyset$ so we get \begin{equation} =\sum_{H:V(H)=k}\sum_{\overset{(i_1,\ldots,i_k)}{j\sim h \text{ in } H \iff i_j\sim i_h}}E(I_{i_1}-EI_{i_1})\cdots (I_{i_k}-EI_{i_k}) \end{equation} We can prove the first case as follows: Let $i_1$ be an isolated vertex. Then $I_{i_1}$ is independent of $(I_{i_2}, \cdots , I_{i_k})$ . Then $$E((I_{i_1} - EI_{i_1}) \cdots (I_{i_k} - EI_{i_k})) = E(I_{i_1} - EI_{i_1}) E(I_{i_2} - EI_{i_2}) \cdots E(I_{i_k} - EI_{i_k}) = 0$$ and we are done. This means that for the first case we have $o((\Var N_G)^{\frac{k}{2}})$ . Now we need to prove that the sum in the second case converges to $(k-1)!!\Var(N_G)^{k/2}$ . But to prove the second one I need help. Thanks! $\endgroup$","Let denote the number of copies of a graph in the Erdős–Rényi random graph model . We have the law of large numbers for the number of copies of of graph , i.e., is very close to the expectation . This means that whenever the expectation tends to zero, also tends to zero and we have Now we are interested to know whether the central limit theorem is also true: i.e., for the standard normal distribution. As with the Poisson limit theorem for the number of copies of , this fact can also be proved by the method of moments. So if we can prove that if we have a sequence of random variables and for any , the th moment of the sequence tends to the th moment of a standard normal random variable, then this convergence in distribution also holds. To prove this, we need to prove that the th moment of is equal to when is even. To do this we use the indicator function and the collection of vertices that can be pairwise disjoint or maybe not; i.e., maybe the first collection and the second are not disjoint or the the second and third and and maybe all of them are not disjoint! But we can use some notation in this case that maybe will help me. We can consider a graph of relations between our collections and we can say that two collections are related to each other when they are not disjoint. So we can consider a graph on vertices such that each vertex is one of our collections and two vertices are adjacent when their collection do intersect (have nonempty intersection). And it turns out that there are three situations here for such a graph on vertices with the above-mentioned specification. In fact we have a lot of graphs here, i.e., graphs, but we have only three different situations: has an isolated vertex. is a perfect matching. else. Now let me put what I said in equations to make it possible to understand the proof of the second case better: Let's drop the denominator.  We have where . Now so we get We can prove the first case as follows: Let be an isolated vertex. Then is independent of . Then and we are done. This means that for the first case we have . Now we need to prove that the sum in the second case converges to . But to prove the second one I need help. Thanks!","\require{begingroup}\begingroup
\DeclareMathOperator{\Var}{Var} N_G G G(n,p) G N_G EN_G N_G \frac{N_G - EN_G}{EN_G} \overset{p}{\rightarrow} 0. \begin{equation}
\cfrac{N_G-EN_G}{\sqrt{\Var N_G}}\overset{d}{\rightarrow}\mathcal{N}(0,1),
\end{equation} \mathcal{N}(0,1) G k k k k E(\frac{N_G - EN_G}{\sqrt{\Var N_G}})^k \frac{E(N_G - EN_G)^k}{(\sqrt{\Var N_G})^k} k k \dots k H k 2^{{k \choose 2}} H H \begin{eqnarray}
E(N_G-EN_G)^k &=& E(\sum_i(I_i-EI_i))^k\\
&=&\sum_{i_i,\ldots,i_k\in I}E((I_{i_1}-EI_{i_1})\cdots(I_{i_k}-EI_{i_k}))
\end{eqnarray} N_G=\sum_iI_i i_j\sim i_k \iff i_j\cap i_k \ne \emptyset \begin{equation}
=\sum_{H:V(H)=k}\sum_{\overset{(i_1,\ldots,i_k)}{j\sim h \text{ in } H \iff i_j\sim i_h}}E(I_{i_1}-EI_{i_1})\cdots (I_{i_k}-EI_{i_k})
\end{equation} i_1 I_{i_1} (I_{i_2}, \cdots , I_{i_k}) E((I_{i_1} - EI_{i_1}) \cdots (I_{i_k} - EI_{i_k})) = E(I_{i_1} - EI_{i_1}) E(I_{i_2} - EI_{i_2}) \cdots E(I_{i_k} - EI_{i_k}) = 0 o((\Var N_G)^{\frac{k}{2}}) (k-1)!!\Var(N_G)^{k/2} \endgroup","['combinatorics', 'discrete-mathematics', 'graph-theory', 'random-graphs']"
91,"Number of $m$-tuples of $k$-subsets of $\{1,2,\cdots,\ n\}$ with overlaps",Number of -tuples of -subsets of  with overlaps,"m k \{1,2,\cdots,\ n\}","Let $S=\{1,2,\cdots,\ n\}$ and let us consider the collection $\mathcal{A}$ of all $k$-subsets of $S$, where a $k$-subset is nothing but a subset of length $k$, $1\le k\le n$. Let us consider all possible unordered $m$ tuples of distinct elements from $\mathcal{A}$. Clearly, there will be $$N=\displaystyle \binom{\binom{n}{k}}{m}$$ such tuples. Now let me consider all the possible $m$-tuples where there is overlap between the coordinates of the tuple, i.e., let me consider all possible tuples $(C_1,\cdots,\ C_m)$ where $C_i\in \mathcal{A},\ C_i\ne C_j$ whever $i\ne j$ and $\exists$ at least one pair $i,j,\ i\ne j$ such that $C_i\cap C_j\ne \emptyset$. It is not difficult to show that the number of such tuples is $$N-\frac{n!}{m!(k!)^m(n-mk)!}$$ assuming $km\le n$. But what about the number of $m$-tuples when we consider a particular amount of overlap? What I mean to ask is the following: How can we find the number of $m$-tuples of elements of $\mathcal{A}$ when we consider a total overlap of $l<km$? Let me give an example to elucidate what I mean by ""total"" overlap: Let us take $n=8,m=4,l=5$. Then one tuple that satisfies my requirement is the following: $$\{\{1,3,6\},\{3,6,8\},\{1,7,8\},\{4,6,7\}\}$$ with the overlaps at $1,3,6,7,8$. It will be best to give relevant hints/ideas rather than a full solution, if possible. Thanks in advance.","Let $S=\{1,2,\cdots,\ n\}$ and let us consider the collection $\mathcal{A}$ of all $k$-subsets of $S$, where a $k$-subset is nothing but a subset of length $k$, $1\le k\le n$. Let us consider all possible unordered $m$ tuples of distinct elements from $\mathcal{A}$. Clearly, there will be $$N=\displaystyle \binom{\binom{n}{k}}{m}$$ such tuples. Now let me consider all the possible $m$-tuples where there is overlap between the coordinates of the tuple, i.e., let me consider all possible tuples $(C_1,\cdots,\ C_m)$ where $C_i\in \mathcal{A},\ C_i\ne C_j$ whever $i\ne j$ and $\exists$ at least one pair $i,j,\ i\ne j$ such that $C_i\cap C_j\ne \emptyset$. It is not difficult to show that the number of such tuples is $$N-\frac{n!}{m!(k!)^m(n-mk)!}$$ assuming $km\le n$. But what about the number of $m$-tuples when we consider a particular amount of overlap? What I mean to ask is the following: How can we find the number of $m$-tuples of elements of $\mathcal{A}$ when we consider a total overlap of $l<km$? Let me give an example to elucidate what I mean by ""total"" overlap: Let us take $n=8,m=4,l=5$. Then one tuple that satisfies my requirement is the following: $$\{\{1,3,6\},\{3,6,8\},\{1,7,8\},\{4,6,7\}\}$$ with the overlaps at $1,3,6,7,8$. It will be best to give relevant hints/ideas rather than a full solution, if possible. Thanks in advance.",,"['combinatorics', 'discrete-mathematics']"
92,A combinatoric $gcd$ problem,A combinatoric  problem,gcd,"Let $Q(L)$ be the number of pairs of numbers $m , n$ such that $gcd(m,n) = 1$ and $m$ and $n$ are of different pairity, where $m$ is even and $n$ is odd, and $m^2 + n^2$ $\le$ $ L$. $$Q(L) = \sum_{gcd(m,n)=1 \atop {m\space even\atop {n\space odd}}}^{m^2+n^2 \le L}1$$ The number of these pairs corresponds to the number of primitive pythagorean triplets with a hypotenuse $\le$ $L$, in which $gcd(a,b,c) = 1$ and $a,b,c$ are the sides of the triangle. If $L$ is small I can easily enumerate the number of these pairs with a computer, but given sufficiently large $L$ this becomes inefficient. I've been thinking for quite some time but I couldn't myself find a formula or an algorithm, though I have a feeling there is a simple combinatorial approach to this. So is there an efficient way to count these pairs? EDIT In an attempt to solve the above question, I've come up with an idea to perhaps simplify it. Define $T(P,L)$ to be the amount of numbers $\le$ $L$ that are coprime to $P$ , that is: $$T(P,L) = \sum_{k=1\atop {gcd(k,P)=1}}^L1$$ Solving this, I assume, will be a significant step in solving the original question of $Q(L)$ in my approach. Also, if you have another approach in your mind to solving this problem, other than the $GCD$ approach, it'll be excellent as well. Thanks in advance.","Let $Q(L)$ be the number of pairs of numbers $m , n$ such that $gcd(m,n) = 1$ and $m$ and $n$ are of different pairity, where $m$ is even and $n$ is odd, and $m^2 + n^2$ $\le$ $ L$. $$Q(L) = \sum_{gcd(m,n)=1 \atop {m\space even\atop {n\space odd}}}^{m^2+n^2 \le L}1$$ The number of these pairs corresponds to the number of primitive pythagorean triplets with a hypotenuse $\le$ $L$, in which $gcd(a,b,c) = 1$ and $a,b,c$ are the sides of the triangle. If $L$ is small I can easily enumerate the number of these pairs with a computer, but given sufficiently large $L$ this becomes inefficient. I've been thinking for quite some time but I couldn't myself find a formula or an algorithm, though I have a feeling there is a simple combinatorial approach to this. So is there an efficient way to count these pairs? EDIT In an attempt to solve the above question, I've come up with an idea to perhaps simplify it. Define $T(P,L)$ to be the amount of numbers $\le$ $L$ that are coprime to $P$ , that is: $$T(P,L) = \sum_{k=1\atop {gcd(k,P)=1}}^L1$$ Solving this, I assume, will be a significant step in solving the original question of $Q(L)$ in my approach. Also, if you have another approach in your mind to solving this problem, other than the $GCD$ approach, it'll be excellent as well. Thanks in advance.",,"['combinatorics', 'number-theory', 'gcd-and-lcm']"
93,Linear constraints to placing $N$ queens on an $N \times N$ chessboard?,Linear constraints to placing  queens on an  chessboard?,N N \times N,"I'm trying to formulate the problem of placing $N$ queens on an $N \times N$ chessboard such that no two queens share any row, column, or diagonal. I managed to  define my decision variable as $x[n][n]$ , a binary variable indicating if the location is used or not. But I couldn't find a way to write any linear constraints. Any ideas on how to proceed, please?","I'm trying to formulate the problem of placing queens on an chessboard such that no two queens share any row, column, or diagonal. I managed to  define my decision variable as , a binary variable indicating if the location is used or not. But I couldn't find a way to write any linear constraints. Any ideas on how to proceed, please?",N N \times N x[n][n],"['combinatorics', 'linear-programming', 'integer-programming']"
94,Generating function for the number of surjections,Generating function for the number of surjections,,"Let $S_k^n$ be the number of possible surjections from a set of $k$ elements to a set of $n$ elements. We have $$\begin{align} &S_0^0 = 1,\qquad\forall k>0: S_k^0 = 0,\\ &S_n^n = n!,\qquad\forall k<n: S_k^n = 0,\\ &\forall k>n>0: S_k^n = n(S_{k-1}^n + S_{k-1}^{n-1}). \end{align}$$ The last relation can be seen as follows: let $\phi:\underline{k}\to\underline{n}$ be a surjection. Consider the subset $\underline{k-1}\subset\underline{k}$ consisting of the first $k-1$ elements $\{1,2,\ldots,k-1\}$. Then either the restriction of $\phi$ to $\underline{k-1}$ is a surjection, and $\phi(k)$ is any element of $\underline{n}$, or the restriction misses exactly one element among the $n$ elements of $\underline{n}$, and $k$ is mapped to this missed element. Representing the first terms in a grid, we have $$\begin{array}{c|cccccc} n\backslash k & 0 & 1 & 2 & 3 & 4 & 5 & 6\\ \hline 0 & 1 & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} \\ 1 & \color{lightgray}{0} & 1 & 1 & 1 & 1 & 1 & 1\\ 2 & \color{lightgray}{0} & \color{lightgray}{0} & 2 & 6 & 14 & 30 & 62\\ 3 & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} & 6 & 36 & 150 & 540\\ 4 & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} & 24 & 240 & 1560 \end{array}$$ If we extend $S_k^n$ to $n,k<0$ by setting it to zero everywhere, then the last relation is satisfied everywhere except at the point $(k,n) = (0,0)$. I am interested in the generating function of these numbers, that is $$S(x,y) = \sum_{k,n\in\mathbb{Z}} S_k^nx^ky^n.$$ Using the relation above, we obtain $$\begin{align} S(x,y) = & 1 + \sum_{k,n\in\mathbb{Z}}n(S_{k-1}^n + S_{k-1}^{n-1})x^ky^n\\ = & 1 + xy\left(S(x,y) + (1+y)\frac{\partial S}{\partial y}(x,y)\right). \end{align}$$ Moreover, we have the boundary conditions $S(x,0) = 1 = S(0,y)$. According to WolphramAlpha , this is solved by $$S(x,y) = c(x)\left(\frac{y}{(y+1)^{x+1}}\right)^{\frac{1}{x}} + (y+1)^{-\frac{x+1}{x}}{}_2F_1\left(-\frac{1}{x},-\frac{1}{x};\frac{x-1}{x};-y\right).$$ (This was edited after an error in the original question was found by @MickA) Now, just by looking at the equation we know that this function will automatically satisfy the required boundary conditions. How can we fix the function $c(x)$? I am a bit at loss (also because I'm not familiar with hypergeometric functions at all). Also, is it possible derive a closed expression for $S_k^n$ from the resulting solution? Remark: I already know of the formula obtained by inclusion-exclusion principle: $$S_k^n = \sum_{i = 0}^n(-1)^i\binom{n}{i}(n-i)^k$$ for $0\le n\le k$. I am curious to see if this alternative method works, if it gives exactly the same answer, and if it contains any additional information in general.","Let $S_k^n$ be the number of possible surjections from a set of $k$ elements to a set of $n$ elements. We have $$\begin{align} &S_0^0 = 1,\qquad\forall k>0: S_k^0 = 0,\\ &S_n^n = n!,\qquad\forall k<n: S_k^n = 0,\\ &\forall k>n>0: S_k^n = n(S_{k-1}^n + S_{k-1}^{n-1}). \end{align}$$ The last relation can be seen as follows: let $\phi:\underline{k}\to\underline{n}$ be a surjection. Consider the subset $\underline{k-1}\subset\underline{k}$ consisting of the first $k-1$ elements $\{1,2,\ldots,k-1\}$. Then either the restriction of $\phi$ to $\underline{k-1}$ is a surjection, and $\phi(k)$ is any element of $\underline{n}$, or the restriction misses exactly one element among the $n$ elements of $\underline{n}$, and $k$ is mapped to this missed element. Representing the first terms in a grid, we have $$\begin{array}{c|cccccc} n\backslash k & 0 & 1 & 2 & 3 & 4 & 5 & 6\\ \hline 0 & 1 & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} \\ 1 & \color{lightgray}{0} & 1 & 1 & 1 & 1 & 1 & 1\\ 2 & \color{lightgray}{0} & \color{lightgray}{0} & 2 & 6 & 14 & 30 & 62\\ 3 & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} & 6 & 36 & 150 & 540\\ 4 & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} & \color{lightgray}{0} & 24 & 240 & 1560 \end{array}$$ If we extend $S_k^n$ to $n,k<0$ by setting it to zero everywhere, then the last relation is satisfied everywhere except at the point $(k,n) = (0,0)$. I am interested in the generating function of these numbers, that is $$S(x,y) = \sum_{k,n\in\mathbb{Z}} S_k^nx^ky^n.$$ Using the relation above, we obtain $$\begin{align} S(x,y) = & 1 + \sum_{k,n\in\mathbb{Z}}n(S_{k-1}^n + S_{k-1}^{n-1})x^ky^n\\ = & 1 + xy\left(S(x,y) + (1+y)\frac{\partial S}{\partial y}(x,y)\right). \end{align}$$ Moreover, we have the boundary conditions $S(x,0) = 1 = S(0,y)$. According to WolphramAlpha , this is solved by $$S(x,y) = c(x)\left(\frac{y}{(y+1)^{x+1}}\right)^{\frac{1}{x}} + (y+1)^{-\frac{x+1}{x}}{}_2F_1\left(-\frac{1}{x},-\frac{1}{x};\frac{x-1}{x};-y\right).$$ (This was edited after an error in the original question was found by @MickA) Now, just by looking at the equation we know that this function will automatically satisfy the required boundary conditions. How can we fix the function $c(x)$? I am a bit at loss (also because I'm not familiar with hypergeometric functions at all). Also, is it possible derive a closed expression for $S_k^n$ from the resulting solution? Remark: I already know of the formula obtained by inclusion-exclusion principle: $$S_k^n = \sum_{i = 0}^n(-1)^i\binom{n}{i}(n-i)^k$$ for $0\le n\le k$. I am curious to see if this alternative method works, if it gives exactly the same answer, and if it contains any additional information in general.",,"['combinatorics', 'generating-functions', 'hypergeometric-function']"
95,Combinatorics Locks Question,Combinatorics Locks Question,,"A combination lock X number of positions. To open the lock, you move to a certain number in the clockwise direction, then to a number in the counterclockwise direction, and finally to a third number in the clockwise direction. Consecutive numbers in the combination cannot be the same. If there are 1500 students at a high school, what is the smallest number for the number of positions (X), so that each student has a unique combination? How I did it: For the lock, how it goes is that if it has X positions, you have X numbers to choose from to go clockwise. In the counterclockwise position, you have X-1 positions to go to because of the consecutive numbers rule. For the third movement clockwise, you can also go X-1 because you can't move to the second number. Therefore, the number of combinations is (X) * (X-1) * (X-1). So we can just test numbers until we get to 1500 or greater. I tested a couple of numbers and got the answer of 13 positions. Thus, 13 * 12 * 12 = 1872. My textbook says the answer is 12 positions, but how can that be? 12 * 11 * 11 = 1452, which is less than 1500. There wouldn't be enough locks for the 1500 students. Thanks.","A combination lock X number of positions. To open the lock, you move to a certain number in the clockwise direction, then to a number in the counterclockwise direction, and finally to a third number in the clockwise direction. Consecutive numbers in the combination cannot be the same. If there are 1500 students at a high school, what is the smallest number for the number of positions (X), so that each student has a unique combination? How I did it: For the lock, how it goes is that if it has X positions, you have X numbers to choose from to go clockwise. In the counterclockwise position, you have X-1 positions to go to because of the consecutive numbers rule. For the third movement clockwise, you can also go X-1 because you can't move to the second number. Therefore, the number of combinations is (X) * (X-1) * (X-1). So we can just test numbers until we get to 1500 or greater. I tested a couple of numbers and got the answer of 13 positions. Thus, 13 * 12 * 12 = 1872. My textbook says the answer is 12 positions, but how can that be? 12 * 11 * 11 = 1452, which is less than 1500. There wouldn't be enough locks for the 1500 students. Thanks.",,['combinatorics']
96,Counting the size of the largest sets of independent strings,Counting the size of the largest sets of independent strings,,"This question derives from a PPCG coding challenge I posed previously. For a given positive integer $n$ , consider all binary strings of length $2n-1$ .  For a given string $S$ , let $L$ be an array of length $n$ which contains the count of the number of $1$ s in each substring of length $n$ of $S$ . For example, if $n=3$ and $S = 01010$ then $L=[1,2,1]$ . We call $L$ the counting array of $S$ . We say that two strings $S1$ and $S2$ of the same length match if their respective counting arrays $L1$ and $L2$ have the property that $L1[i] \leq 2*L2[i]$ and $L2[i] \leq 2*L1[i]$ for all $i$ . Problem For increasing $n$ starting at $n=1$ , we want to compute the size of the largest set of strings, each of length $2n-1$ so that no two strings match. Known answers For $n=1,2,3,4,5$ the optimal answers are $2,4,10,16,31$ . For $n=6,7,8,9,10$ , the best known values are $47, 76, 112, 168, 235$ from a combination of the answers of joriki and Peter Taylor. The question Plotting these values they appear to be subexponential but it is hard to say much more than that. This leads to the question: How do optimal solutions scale with $n$ ? Question now posed at https://mathoverflow.net/questions/215343/counting-the-size-of-the-largest-sets-of-independent-strings as well.","This question derives from a PPCG coding challenge I posed previously. For a given positive integer , consider all binary strings of length .  For a given string , let be an array of length which contains the count of the number of s in each substring of length of . For example, if and then . We call the counting array of . We say that two strings and of the same length match if their respective counting arrays and have the property that and for all . Problem For increasing starting at , we want to compute the size of the largest set of strings, each of length so that no two strings match. Known answers For the optimal answers are . For , the best known values are from a combination of the answers of joriki and Peter Taylor. The question Plotting these values they appear to be subexponential but it is hard to say much more than that. This leads to the question: How do optimal solutions scale with ? Question now posed at https://mathoverflow.net/questions/215343/counting-the-size-of-the-largest-sets-of-independent-strings as well.","n 2n-1 S L n 1 n S n=3 S = 01010 L=[1,2,1] L S S1 S2 L1 L2 L1[i] \leq 2*L2[i] L2[i] \leq 2*L1[i] i n n=1 2n-1 n=1,2,3,4,5 2,4,10,16,31 n=6,7,8,9,10 47, 76, 112, 168, 235 n",['combinatorics']
97,The distance between the origin and all intersections by the diagonals of a regular polygon,The distance between the origin and all intersections by the diagonals of a regular polygon,,"The geometric center of an n-sided regular polygon is point $O$. Connect all diagonals of the polygon. How many different distances between diagonal-diagonal intersections ($O$ itself is counted) and $O$ are there (i.e. how many concentric circles are in the graph below)? For n = 6, ..., 16, the answer should be 4, 5, 7, 11, 14, 21, 29, 36, 37, 54, 57, if I'm not mistaken. But I don't know the answer for a general n. Multiple junctions are not easy to deal with. The other graphs are being uploaded to imgur so there will be more graphic examples on the way. Thanks! Edit: Imgur down. Will try later.","The geometric center of an n-sided regular polygon is point $O$. Connect all diagonals of the polygon. How many different distances between diagonal-diagonal intersections ($O$ itself is counted) and $O$ are there (i.e. how many concentric circles are in the graph below)? For n = 6, ..., 16, the answer should be 4, 5, 7, 11, 14, 21, 29, 36, 37, 54, 57, if I'm not mistaken. But I don't know the answer for a general n. Multiple junctions are not easy to deal with. The other graphs are being uploaded to imgur so there will be more graphic examples on the way. Thanks! Edit: Imgur down. Will try later.",,['combinatorics']
98,Showing that poset of set of supports of a vector space is semimodular,Showing that poset of set of supports of a vector space is semimodular,,"Let $W$ be a subspace of the vector space $\mathbb{K}^n$, where $\mathbb{K}$ is a field of characteristic $0$. The support of a vector $v = (v_1,\ldots, v_n) \in \mathbb{K}^n$ is given by $\text{supp}(v) = \left\{i : v_i\neq 0\right\}$. Let $L$ denote the set of supports of all vectors in $W$, ordered by reverse inclusion. I want to show that $L$ is a semimodular lattice. By Proposition 3.3.2 in Stanley's Enumerative Combinatorics, vol. 1, we can either show that $L$ is graded (every maximal chain has the same length) and that its rank functions $\rho:L\rightarrow \left\{0,1,\ldots, n \right\}$ satisfies $$ \rho(s)+\rho(t) \geq \rho(s\wedge t)+\rho(s\vee t)$$ for any $s,t \in L$ or we can show that if $s$ and $t$ both cover $s\wedge t$, then $s\vee t$ covers both $s$ and $t$. Here's the problem...I know that the meet of any $s,t \in L$ is $s\cup t$, but I don't know what the join is. Ultimately what I'm trying to show is the $L$ is a geometric lattice, which requires showing that $L$ is semimodular. Perhaps there is a better way of proving this.","Let $W$ be a subspace of the vector space $\mathbb{K}^n$, where $\mathbb{K}$ is a field of characteristic $0$. The support of a vector $v = (v_1,\ldots, v_n) \in \mathbb{K}^n$ is given by $\text{supp}(v) = \left\{i : v_i\neq 0\right\}$. Let $L$ denote the set of supports of all vectors in $W$, ordered by reverse inclusion. I want to show that $L$ is a semimodular lattice. By Proposition 3.3.2 in Stanley's Enumerative Combinatorics, vol. 1, we can either show that $L$ is graded (every maximal chain has the same length) and that its rank functions $\rho:L\rightarrow \left\{0,1,\ldots, n \right\}$ satisfies $$ \rho(s)+\rho(t) \geq \rho(s\wedge t)+\rho(s\vee t)$$ for any $s,t \in L$ or we can show that if $s$ and $t$ both cover $s\wedge t$, then $s\vee t$ covers both $s$ and $t$. Here's the problem...I know that the meet of any $s,t \in L$ is $s\cup t$, but I don't know what the join is. Ultimately what I'm trying to show is the $L$ is a geometric lattice, which requires showing that $L$ is semimodular. Perhaps there is a better way of proving this.",,"['combinatorics', 'discrete-mathematics', 'field-theory', 'order-theory', 'lattice-orders']"
99,Number of circuits that surround the square.,Number of circuits that surround the square.,,"Consider a grid $G$ in the $\mathbb{R}^2$ plane formed by the points $(x,y)$ with integer coordinates i.e. $G=\{(x,y)\in\mathbb{R}^2: x\in\mathbb{Z},\;y\in\mathbb{Z} \}$. For $n>0$ let $B_n$ square centered at $(0,0)$ whose sides have length $2^{n+1} + 1$. Note that $B_n=\{-2^n,\ldots,0,\ldots,+2^n \}\times \{-2^n,\ldots,0,\ldots,+2^n \}$. Consider all the circuits as a finite set of points $p_{0},p_1,\ldots, p_{k-1},p_k,p_{k+1}\ldots, p_n$ such that: the starting point $p_0$ is equal to its endpoint $p_n$, that is, $p_0=p_n $; the circuit trace has no self-intersection; $p_k$ and $p_{k+1}$ are neighbors for $k=0,1,3,\ldots,n $.  By neighboring points we understand the points that are distance 1 according to the metric $d(p,q)=\max\{|x_p-x_q|,|y_p-y_q| \}$ for points $p=(x_p,y_p)$ and $q=(x_q,y_q)$ in $\mathbb{Z}^2$. For an illustration with rectangles $B_2$  and $B_3$ see the figure below. ......................... Question. What is the maximum number of circuits that can be drawn within the square $B_{n+1}$ and out of $B_n$ square? My attempt was to divide the region where the circuit can pass in 8 rectangles. As shown below. And then try to count the number of paths running from side to side of each rectangle. .........................!","Consider a grid $G$ in the $\mathbb{R}^2$ plane formed by the points $(x,y)$ with integer coordinates i.e. $G=\{(x,y)\in\mathbb{R}^2: x\in\mathbb{Z},\;y\in\mathbb{Z} \}$. For $n>0$ let $B_n$ square centered at $(0,0)$ whose sides have length $2^{n+1} + 1$. Note that $B_n=\{-2^n,\ldots,0,\ldots,+2^n \}\times \{-2^n,\ldots,0,\ldots,+2^n \}$. Consider all the circuits as a finite set of points $p_{0},p_1,\ldots, p_{k-1},p_k,p_{k+1}\ldots, p_n$ such that: the starting point $p_0$ is equal to its endpoint $p_n$, that is, $p_0=p_n $; the circuit trace has no self-intersection; $p_k$ and $p_{k+1}$ are neighbors for $k=0,1,3,\ldots,n $.  By neighboring points we understand the points that are distance 1 according to the metric $d(p,q)=\max\{|x_p-x_q|,|y_p-y_q| \}$ for points $p=(x_p,y_p)$ and $q=(x_q,y_q)$ in $\mathbb{Z}^2$. For an illustration with rectangles $B_2$  and $B_3$ see the figure below. ......................... Question. What is the maximum number of circuits that can be drawn within the square $B_{n+1}$ and out of $B_n$ square? My attempt was to divide the region where the circuit can pass in 8 rectangles. As shown below. And then try to count the number of paths running from side to side of each rectangle. .........................!",,"['combinatorics', 'discrete-mathematics', 'discrete-geometry', 'percolation']"
