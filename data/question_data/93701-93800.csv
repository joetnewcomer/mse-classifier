,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Significance of the Triangle Inequality,Significance of the Triangle Inequality,,"After working through a few problems regarding the Cauchy Integral Formula, I'm still a little confused on the significance of the triangle inequality. Why do we use it and what information does it tell us? See the following example below. Determine $\int_{0}^{\infty} \frac{x^2}{(x^2 + 1)^2} dx$ First, we'll create the contour $$ \begin{cases} C_1: Rt & -1 \le t \le 1 \\ C_2:R e^{i\theta} & \ \ \, 0 \le \theta \le \pi \\ C=C_1+C_2 \end{cases} $$ $$ x^2 +1 =0 \Rightarrow x=\pm i \ \ \  ; \ \ \ \ \int_{0}^{\infty} \frac{x^2}{(x^2 + 1)^2} dx = \frac{1}{2}\int_{-\infty}^{\infty} \frac{x^2}{(x^2 + 1)^2} dx$$ $$ \Rightarrow \int_C \frac{z^2}{(z+1)^2}dz = \int_C \frac{z^2}{[(z+i)(z-i)]^2}   = \int_C \frac{z^2}{(z+i)^2 (z-i)^2} $$ $z=-i$ is outside the contour and therefore irrelevant, so choosing $z=i$ for the integration. $$ \Rightarrow z_0=i \ \ \text{and} \ \ f(z)=\frac{z^2}{(z+i)^2} $$ $$ f'(z)=\frac{d}{dz}\left[ \frac{z^2}{(z+i)^2} \right] = \frac{2z}{(z+i)^2}-\frac{2z^2}{(z+i)^3}$$ Therefore, by the Cauchy Integration Formula,  $$ \int_C \frac{f(z)}{(z-i)^2}dz = 2\pi i f'(i) = 2\pi i \left[ \frac{2i}{(2i)^2}-\frac{2i^2}{(2i)^3} \right] = \pi \left[1 + \frac{2}{4i^2} \right] = \pi - \frac{\pi}{2} = \frac{\pi}{2} $$ The following part is where I'm a little confused. I know the work, but am not quite sure why I'm doing it or what the end result is telling us. So, by the triangle inequality, $$ \left| z^2 +1 \right|^2 \le \left( \left|z^2 \right| +1 \right) ^2 = z^4 +2\left| z^2 \right| +1 \Rightarrow \left| \int_C \frac{z^2}{(z+1)^2}dz \right| \le \frac{R^2}{R^4 +2R +1} $$ $$ \Rightarrow \int_{0}^{\infty} \frac{x^2}{(x^2 + 1)^2} dx = \frac{1}{2}\int_{-\infty}^{\infty} \frac{x^2}{(x^2 + 1)^2} dx \le \lim_{R \rightarrow \infty} \int_C \frac{z^2}{(z+1)^2}dz \\ \le \lim_{R \rightarrow \infty} \frac{R^2}{R^4 +2R +1} = 0 $$ $$ \therefore \int_{0}^{\infty} \frac{x^2}{(x^2 + 1)^2} dx = \frac{1}{2}\int_{-\infty}^{\infty} \frac{x^2}{(x^2 + 1)^2} dx = \frac{1}{2} \left[ \frac{\pi}{2} \right] = \frac{\pi}{4} $$ Any help in deciphering the part in the work I pointed out would be very helpful, thank you for your time.","After working through a few problems regarding the Cauchy Integral Formula, I'm still a little confused on the significance of the triangle inequality. Why do we use it and what information does it tell us? See the following example below. Determine $\int_{0}^{\infty} \frac{x^2}{(x^2 + 1)^2} dx$ First, we'll create the contour $$ \begin{cases} C_1: Rt & -1 \le t \le 1 \\ C_2:R e^{i\theta} & \ \ \, 0 \le \theta \le \pi \\ C=C_1+C_2 \end{cases} $$ $$ x^2 +1 =0 \Rightarrow x=\pm i \ \ \  ; \ \ \ \ \int_{0}^{\infty} \frac{x^2}{(x^2 + 1)^2} dx = \frac{1}{2}\int_{-\infty}^{\infty} \frac{x^2}{(x^2 + 1)^2} dx$$ $$ \Rightarrow \int_C \frac{z^2}{(z+1)^2}dz = \int_C \frac{z^2}{[(z+i)(z-i)]^2}   = \int_C \frac{z^2}{(z+i)^2 (z-i)^2} $$ $z=-i$ is outside the contour and therefore irrelevant, so choosing $z=i$ for the integration. $$ \Rightarrow z_0=i \ \ \text{and} \ \ f(z)=\frac{z^2}{(z+i)^2} $$ $$ f'(z)=\frac{d}{dz}\left[ \frac{z^2}{(z+i)^2} \right] = \frac{2z}{(z+i)^2}-\frac{2z^2}{(z+i)^3}$$ Therefore, by the Cauchy Integration Formula,  $$ \int_C \frac{f(z)}{(z-i)^2}dz = 2\pi i f'(i) = 2\pi i \left[ \frac{2i}{(2i)^2}-\frac{2i^2}{(2i)^3} \right] = \pi \left[1 + \frac{2}{4i^2} \right] = \pi - \frac{\pi}{2} = \frac{\pi}{2} $$ The following part is where I'm a little confused. I know the work, but am not quite sure why I'm doing it or what the end result is telling us. So, by the triangle inequality, $$ \left| z^2 +1 \right|^2 \le \left( \left|z^2 \right| +1 \right) ^2 = z^4 +2\left| z^2 \right| +1 \Rightarrow \left| \int_C \frac{z^2}{(z+1)^2}dz \right| \le \frac{R^2}{R^4 +2R +1} $$ $$ \Rightarrow \int_{0}^{\infty} \frac{x^2}{(x^2 + 1)^2} dx = \frac{1}{2}\int_{-\infty}^{\infty} \frac{x^2}{(x^2 + 1)^2} dx \le \lim_{R \rightarrow \infty} \int_C \frac{z^2}{(z+1)^2}dz \\ \le \lim_{R \rightarrow \infty} \frac{R^2}{R^4 +2R +1} = 0 $$ $$ \therefore \int_{0}^{\infty} \frac{x^2}{(x^2 + 1)^2} dx = \frac{1}{2}\int_{-\infty}^{\infty} \frac{x^2}{(x^2 + 1)^2} dx = \frac{1}{2} \left[ \frac{\pi}{2} \right] = \frac{\pi}{4} $$ Any help in deciphering the part in the work I pointed out would be very helpful, thank you for your time.",,"['complex-analysis', 'cauchy-integral-formula']"
1,Integral of $\frac{x^\alpha}{(1 + x^2)^2}$ from 0 to $\infty$ using contour integration for $-1 < \alpha <3$,Integral of  from 0 to  using contour integration for,\frac{x^\alpha}{(1 + x^2)^2} \infty -1 < \alpha <3,"I have tried to evaluate $\int_0^\infty \dfrac{x^\alpha}{(x^2 + 1)^2}\ dx$ for $-1 < \alpha < 3$ using the keyhole contour, but am not sure about my working, especially in defining the analytic branch of log $z$ when we consider the function $f(z) = \dfrac{z^\alpha}{(z^2 + 1)^2}$ where $z^\alpha  = e^{\alpha\text{log}\ z}$. Below is my working: Using the keyhole contour $K_{\varepsilon,M}$ and considering the complex function $\dfrac{z^\alpha}{(z^2 + 1)^2}$, we inspect the integral of the function over each part of the contour (namely $C_{\varepsilon},C_M, I_1$ and $I_2$) in the limit $\varepsilon \to 0,\ M \to \infty$. For $C_{\varepsilon}$, we have $|z^2 +1|$ to be the modulus of points lying on a circle of radius $\varepsilon^2$ centered at $z = 1$ and hence $|z^2 + 1| > 1/2$ for $\varepsilon$ small enough (e.g. $\varepsilon^2 < 1/2$). We thus have:  \begin{align*} \int_{C_{\varepsilon}} \dfrac{z^\alpha}{(z^2 + 1)^2}\ dz \ll \pi\varepsilon\ \text{max}_{C_\varepsilon}\bigg|\dfrac{z^\alpha}{(z^2 + 1)^2}\bigg| \ll 4\pi\varepsilon^{\alpha + 1} \Rightarrow \lim_{\varepsilon \to 0}\int_{C_{\varepsilon}} \dfrac{z^\alpha}{(z^2 + 1)^2}\ dz = 0  \end{align*} For any $z \in C_M$, we have $|z^2 + 1| \geq |z^2| = M^2$ for $M$ big enough. We thus have: \begin{align*} \int_{C_M} \dfrac{z^\alpha}{(z^2 + 1)^2}\ dz \ll 2\pi M \ \text{max}_{C_M}\bigg|\dfrac{z^\alpha}{(z^2 + 1)^2}\bigg| \ll 2\pi M^{\alpha - 3} \Rightarrow \lim_{M \to \infty}\int_{C_M} \dfrac{z^\alpha}{(z^2 + 1)^2}\ dz = 0 \end{align*} For $I_1$, we have $\begin{aligned} = \lim_{\varepsilon \to 0,\  M \to \infty}\int_{I_1}\dfrac{z^\alpha}{(z^2 + 1)^2}\ dz = \int_0^\infty \dfrac{x^\alpha}{(x^2 + 1)^2}\ dx \end{aligned}$. As for $I_2$, we have $z^\alpha = e^{\alpha(\text{ln}x + 2\pi i)} = x^{\alpha}e^{2\pi i\alpha}$, and hence we have $\begin{aligned} = \lim_{\varepsilon \to 0,\  M \to \infty}\int_{I_2}\dfrac{z^\alpha}{(z^2 + 1)^2}\ dz = -e^{2\pi i\alpha}\int_0^\infty \dfrac{x^\alpha}{(x^2 + 1)^2}\ dx \end{aligned}$. Then, by the Residue Theorem, we have: \begin{align*} \int_0^\infty \dfrac{x^\alpha}{(x^2 + 1)^2}\ dx &= \frac{2\pi i}{1 - e^{2\pi i\alpha}}\sum_k \text{Res}\bigg(\dfrac{z^\alpha}{(z^2 + 1)^2}; z_k\bigg) \\ &= \frac{2\pi i}{1 - e^{2\pi i\alpha}}\bigg(\lim_{z \to i} \frac{d}{dz}\bigg(\dfrac{z^\alpha}{(z + i)^2}\bigg) + \lim_{z \to -i} \frac{d}{dz}\bigg(\dfrac{z^\alpha}{(z - i)^2}\bigg)\bigg) \\ &= \frac{2\pi i}{1 - e^{2\pi i\alpha}}\bigg(\frac{\alpha -1}{4}i^{\alpha -3} + \frac{\alpha -1}{4}(-i)^{\alpha -3}\bigg) \\ &= \frac{\pi i(\alpha -1)\text{cos}(\pi(\alpha - 3)/2)}{1 - e^{2\pi i\alpha}}  \end{align*} where the keyhole contour is given as !Keyhole Contour 1 Any help in correcting my working or giving hints or posting your solution is appreciated.","I have tried to evaluate $\int_0^\infty \dfrac{x^\alpha}{(x^2 + 1)^2}\ dx$ for $-1 < \alpha < 3$ using the keyhole contour, but am not sure about my working, especially in defining the analytic branch of log $z$ when we consider the function $f(z) = \dfrac{z^\alpha}{(z^2 + 1)^2}$ where $z^\alpha  = e^{\alpha\text{log}\ z}$. Below is my working: Using the keyhole contour $K_{\varepsilon,M}$ and considering the complex function $\dfrac{z^\alpha}{(z^2 + 1)^2}$, we inspect the integral of the function over each part of the contour (namely $C_{\varepsilon},C_M, I_1$ and $I_2$) in the limit $\varepsilon \to 0,\ M \to \infty$. For $C_{\varepsilon}$, we have $|z^2 +1|$ to be the modulus of points lying on a circle of radius $\varepsilon^2$ centered at $z = 1$ and hence $|z^2 + 1| > 1/2$ for $\varepsilon$ small enough (e.g. $\varepsilon^2 < 1/2$). We thus have:  \begin{align*} \int_{C_{\varepsilon}} \dfrac{z^\alpha}{(z^2 + 1)^2}\ dz \ll \pi\varepsilon\ \text{max}_{C_\varepsilon}\bigg|\dfrac{z^\alpha}{(z^2 + 1)^2}\bigg| \ll 4\pi\varepsilon^{\alpha + 1} \Rightarrow \lim_{\varepsilon \to 0}\int_{C_{\varepsilon}} \dfrac{z^\alpha}{(z^2 + 1)^2}\ dz = 0  \end{align*} For any $z \in C_M$, we have $|z^2 + 1| \geq |z^2| = M^2$ for $M$ big enough. We thus have: \begin{align*} \int_{C_M} \dfrac{z^\alpha}{(z^2 + 1)^2}\ dz \ll 2\pi M \ \text{max}_{C_M}\bigg|\dfrac{z^\alpha}{(z^2 + 1)^2}\bigg| \ll 2\pi M^{\alpha - 3} \Rightarrow \lim_{M \to \infty}\int_{C_M} \dfrac{z^\alpha}{(z^2 + 1)^2}\ dz = 0 \end{align*} For $I_1$, we have $\begin{aligned} = \lim_{\varepsilon \to 0,\  M \to \infty}\int_{I_1}\dfrac{z^\alpha}{(z^2 + 1)^2}\ dz = \int_0^\infty \dfrac{x^\alpha}{(x^2 + 1)^2}\ dx \end{aligned}$. As for $I_2$, we have $z^\alpha = e^{\alpha(\text{ln}x + 2\pi i)} = x^{\alpha}e^{2\pi i\alpha}$, and hence we have $\begin{aligned} = \lim_{\varepsilon \to 0,\  M \to \infty}\int_{I_2}\dfrac{z^\alpha}{(z^2 + 1)^2}\ dz = -e^{2\pi i\alpha}\int_0^\infty \dfrac{x^\alpha}{(x^2 + 1)^2}\ dx \end{aligned}$. Then, by the Residue Theorem, we have: \begin{align*} \int_0^\infty \dfrac{x^\alpha}{(x^2 + 1)^2}\ dx &= \frac{2\pi i}{1 - e^{2\pi i\alpha}}\sum_k \text{Res}\bigg(\dfrac{z^\alpha}{(z^2 + 1)^2}; z_k\bigg) \\ &= \frac{2\pi i}{1 - e^{2\pi i\alpha}}\bigg(\lim_{z \to i} \frac{d}{dz}\bigg(\dfrac{z^\alpha}{(z + i)^2}\bigg) + \lim_{z \to -i} \frac{d}{dz}\bigg(\dfrac{z^\alpha}{(z - i)^2}\bigg)\bigg) \\ &= \frac{2\pi i}{1 - e^{2\pi i\alpha}}\bigg(\frac{\alpha -1}{4}i^{\alpha -3} + \frac{\alpha -1}{4}(-i)^{\alpha -3}\bigg) \\ &= \frac{\pi i(\alpha -1)\text{cos}(\pi(\alpha - 3)/2)}{1 - e^{2\pi i\alpha}}  \end{align*} where the keyhole contour is given as !Keyhole Contour 1 Any help in correcting my working or giving hints or posting your solution is appreciated.",,"['complex-analysis', 'contour-integration']"
2,Differences between the complex derivative and the multivariable derivative.,Differences between the complex derivative and the multivariable derivative.,,"Let $f:G\to\mathbb{C}$, $G\subset\mathbb{C}$ be a complex function, differentiable at $z_0\in G$, where $z_0$ is an limit point of $G$. Now, the derivative at this point is defined to be the limit $$\lim_{z\to z_0}\dfrac{f(z)-f(z_0)}{z-z_0}$$ Now, consider any function $\mathbf{g}:\mathbb{R^2}\to\mathbb{R^2}$, and say $g$ is differentiable at some limit point $\mathbf{x_0}=(x_0,y_0)$ of $\mathbb{R^2}$. In this case, we don't define the derivative to be the limit $$\lim_{\mathbf{x}\to\mathbf{x_0}}\dfrac{\mathbf{g(x)}-\mathbf{g(x_0)}}{\mathbf{x}-\mathbf{x_0}}$$ because if we did, then this definition would also apply to any function $h:\mathbb{R^2}\to\mathbb{R}$, which is not the correct definition. So, my question is, what are the differences between the complex derivative and the multivariable derivative? Why do we define the complex derivative like this?","Let $f:G\to\mathbb{C}$, $G\subset\mathbb{C}$ be a complex function, differentiable at $z_0\in G$, where $z_0$ is an limit point of $G$. Now, the derivative at this point is defined to be the limit $$\lim_{z\to z_0}\dfrac{f(z)-f(z_0)}{z-z_0}$$ Now, consider any function $\mathbf{g}:\mathbb{R^2}\to\mathbb{R^2}$, and say $g$ is differentiable at some limit point $\mathbf{x_0}=(x_0,y_0)$ of $\mathbb{R^2}$. In this case, we don't define the derivative to be the limit $$\lim_{\mathbf{x}\to\mathbf{x_0}}\dfrac{\mathbf{g(x)}-\mathbf{g(x_0)}}{\mathbf{x}-\mathbf{x_0}}$$ because if we did, then this definition would also apply to any function $h:\mathbb{R^2}\to\mathbb{R}$, which is not the correct definition. So, my question is, what are the differences between the complex derivative and the multivariable derivative? Why do we define the complex derivative like this?",,"['complex-analysis', 'derivatives']"
3,Primitive of an holomorphic function,Primitive of an holomorphic function,,"Why does an holomorphic function have a primitive in a simply connected space? Also, it have a primitive only in a simply connected space?","Why does an holomorphic function have a primitive in a simply connected space? Also, it have a primitive only in a simply connected space?",,"['complex-analysis', 'holomorphic-functions']"
4,Why did Riemann believe that all non-trivial zeros of the zeta function lie on the critical line?,Why did Riemann believe that all non-trivial zeros of the zeta function lie on the critical line?,,"Bear with me, I'm fresh out of high school so my level of mathematical knowledge is quite low (probably too low to be trying to understand the Riemann hypothesis, but at least I'm trying). At this current time, I'm trying to make sense of John Derbyshire's (fantastic) book Prime Obsession . One thing that hasn't been explained in the book and to which I cannot find answers within the bounds of my understanding through research, is why exactly Riemann thought his hypothesis was true. From what I understand, Bernhard Riemann was a very intuitive mathematician so it's quite possible that although he did not have a proof for his hypothesis, it made sense to him intuitively. I guess my question is, How does it intuitively make sense that all non-trivial zeros of the zeta function lie on the critical line and not somewhere else?","Bear with me, I'm fresh out of high school so my level of mathematical knowledge is quite low (probably too low to be trying to understand the Riemann hypothesis, but at least I'm trying). At this current time, I'm trying to make sense of John Derbyshire's (fantastic) book Prime Obsession . One thing that hasn't been explained in the book and to which I cannot find answers within the bounds of my understanding through research, is why exactly Riemann thought his hypothesis was true. From what I understand, Bernhard Riemann was a very intuitive mathematician so it's quite possible that although he did not have a proof for his hypothesis, it made sense to him intuitively. I guess my question is, How does it intuitively make sense that all non-trivial zeros of the zeta function lie on the critical line and not somewhere else?",,"['complex-analysis', 'prime-numbers', 'riemann-zeta', 'riemann-hypothesis']"
5,Entire function is polynomial of degree $n$ iff $z^{n}f(1/z) \to \alpha$ as $z \to 0$.,Entire function is polynomial of degree  iff  as .,n z^{n}f(1/z) \to \alpha z \to 0,"I am working through old qualifier questions in analysis over break, and I was hoping someone would be willing to help me verify (and correct) my proof for the following statement. I feel fairly confident in the forward side, but less so in the converse. In particular, am I on the right track in reaching for uniform convergence to move the limit inside the series? If not, what tools should I be reaching for instead? Thank you in advance for any help! Theorem: Let $f$ be an entire function. Prove carefully that $f$ is a polynomial of degree $n$ if and only if there exists $\alpha \in \mathbb{C}$ such that $\lim_{z \to 0} z^{n} f(1/z) = \alpha$. Proof: Suppose first $f$ is a polynomial of degree $n$. Then: $$f(z) = \sum_{k=0}^{n} a_{k}z^{k}$$ And: $$z^{n}f(1/z) = \sum_{k=0}^{n} a_{k} z^{n-k}$$ And $z^{n}f(1/z) \to a_{n}$ as $z \to 0$. So $a_{n}$ is our choice of $\alpha$. Conversely, let $\alpha \in \mathbb{C}$ and suppose $\lim_{z \to 0} z^{n}f(1/z) = \alpha$. As $f$ is entire, we have that $f$ is equal to its power series representation for all $z \in \mathbb{C}$: $$f(z) = \sum_{k=0}^{\infty} \dfrac{f^{(k)}(0)}{k!} z^{k}$$ As $f$ is entire and the Cauchy root test, this power series converges uniformly on $\mathbb{C}$. Now consider: $$z^{n}f(1/z) = \sum_{k=0}^{\infty} \dfrac{f^{(k)}(0)}{k!} z^{n-k}$$ I show that the power series representation of $z^{n}f(1/z)$ converges uniformly using the Weierstrass $M$-test. Let $r > 0$. We have that for any $z \in B_{r}(0)$ that: $$\left|\dfrac{f^{(k)}(0)}{k!} z^{n-k} \right| \leq \left|\dfrac{f^{(k)}(0)}{k!} \right| r^{k}$$ Let $M_{k} := \left|\dfrac{f^{(k)}(0)}{k!} \right| r^{k}$. By the Ratio Test, we see that $\sum M_{k}$ converges absolutely. So by the Weierstrass $M$-test, the power series representation of $z^{n}f(1/z)$ converges uniformly in $B_{r}(0)$. As $r$ was arbitrary, the power series representation of $z^{n}f(1/z)$ converges uniformly everywhere. Thus, we can move the limit inside the series: $$\alpha = \lim_{z \to 0} z^{n} f(1/z) = \lim_{z \to 0} \sum_{k=0}^{\infty} \dfrac{f^{(k)}(0)}{k!} z^{n-k} = \sum_{k=0}^{\infty} \left(\lim_{z \to 0} \dfrac{f^{(k)}(0)}{k!} z^{n-k} \right)  $$ It follows that $\lim_{z \to 0} \dfrac{f^{(k)}(0)}{k!} z^{n-k} = 0$ whenever $|n-k| < 0$, which implies that $f^{(k)}(0) = 0$ whenever $n-k < 0$. Now when $k = n$, $\lim_{z \to 0} \dfrac{f^{(n)}(0)}{k!} z^{0} = \alpha$. So $f$ is a polynomial of degree $n$ (provided $\alpha \neq 0$). QED.","I am working through old qualifier questions in analysis over break, and I was hoping someone would be willing to help me verify (and correct) my proof for the following statement. I feel fairly confident in the forward side, but less so in the converse. In particular, am I on the right track in reaching for uniform convergence to move the limit inside the series? If not, what tools should I be reaching for instead? Thank you in advance for any help! Theorem: Let $f$ be an entire function. Prove carefully that $f$ is a polynomial of degree $n$ if and only if there exists $\alpha \in \mathbb{C}$ such that $\lim_{z \to 0} z^{n} f(1/z) = \alpha$. Proof: Suppose first $f$ is a polynomial of degree $n$. Then: $$f(z) = \sum_{k=0}^{n} a_{k}z^{k}$$ And: $$z^{n}f(1/z) = \sum_{k=0}^{n} a_{k} z^{n-k}$$ And $z^{n}f(1/z) \to a_{n}$ as $z \to 0$. So $a_{n}$ is our choice of $\alpha$. Conversely, let $\alpha \in \mathbb{C}$ and suppose $\lim_{z \to 0} z^{n}f(1/z) = \alpha$. As $f$ is entire, we have that $f$ is equal to its power series representation for all $z \in \mathbb{C}$: $$f(z) = \sum_{k=0}^{\infty} \dfrac{f^{(k)}(0)}{k!} z^{k}$$ As $f$ is entire and the Cauchy root test, this power series converges uniformly on $\mathbb{C}$. Now consider: $$z^{n}f(1/z) = \sum_{k=0}^{\infty} \dfrac{f^{(k)}(0)}{k!} z^{n-k}$$ I show that the power series representation of $z^{n}f(1/z)$ converges uniformly using the Weierstrass $M$-test. Let $r > 0$. We have that for any $z \in B_{r}(0)$ that: $$\left|\dfrac{f^{(k)}(0)}{k!} z^{n-k} \right| \leq \left|\dfrac{f^{(k)}(0)}{k!} \right| r^{k}$$ Let $M_{k} := \left|\dfrac{f^{(k)}(0)}{k!} \right| r^{k}$. By the Ratio Test, we see that $\sum M_{k}$ converges absolutely. So by the Weierstrass $M$-test, the power series representation of $z^{n}f(1/z)$ converges uniformly in $B_{r}(0)$. As $r$ was arbitrary, the power series representation of $z^{n}f(1/z)$ converges uniformly everywhere. Thus, we can move the limit inside the series: $$\alpha = \lim_{z \to 0} z^{n} f(1/z) = \lim_{z \to 0} \sum_{k=0}^{\infty} \dfrac{f^{(k)}(0)}{k!} z^{n-k} = \sum_{k=0}^{\infty} \left(\lim_{z \to 0} \dfrac{f^{(k)}(0)}{k!} z^{n-k} \right)  $$ It follows that $\lim_{z \to 0} \dfrac{f^{(k)}(0)}{k!} z^{n-k} = 0$ whenever $|n-k| < 0$, which implies that $f^{(k)}(0) = 0$ whenever $n-k < 0$. Now when $k = n$, $\lim_{z \to 0} \dfrac{f^{(n)}(0)}{k!} z^{0} = \alpha$. So $f$ is a polynomial of degree $n$ (provided $\alpha \neq 0$). QED.",,['complex-analysis']
6,"What does ""vanish identically"" mean?","What does ""vanish identically"" mean?",,"This is from Stein's Complex Analysis: Suppose that $f$ is holomorphic in a connected open set $\Omega$, has a zero at a point $z_0 \in \Omega$, and does not vanish identicallly in $\Omega$. Then, there exists a neighborhood $U\in\Omega$ of $z_0$, a non-vanishing holomorphic function $g$ on $U$, and a unique positive integer $n$ such that   $$f(z) = (z - z_0)^n g(z) \text{ for all } z\in U$$ I thought that $f$ vanishes identically in $\Omega$ means that $f(z) = 0$ for all $z\in \Omega$? But then in the proof, he wrote Since $\Omega$ is connected and $f$ is not identically zero, we conclude that $f$ is not identically zero in a neighborhood of $z_0$. Why? Why cannot $f$ be identically zero in a neighborhood of $z_0$? It does not contradict the fact that $f$ is not identically zero in $\Omega$.","This is from Stein's Complex Analysis: Suppose that $f$ is holomorphic in a connected open set $\Omega$, has a zero at a point $z_0 \in \Omega$, and does not vanish identicallly in $\Omega$. Then, there exists a neighborhood $U\in\Omega$ of $z_0$, a non-vanishing holomorphic function $g$ on $U$, and a unique positive integer $n$ such that   $$f(z) = (z - z_0)^n g(z) \text{ for all } z\in U$$ I thought that $f$ vanishes identically in $\Omega$ means that $f(z) = 0$ for all $z\in \Omega$? But then in the proof, he wrote Since $\Omega$ is connected and $f$ is not identically zero, we conclude that $f$ is not identically zero in a neighborhood of $z_0$. Why? Why cannot $f$ be identically zero in a neighborhood of $z_0$? It does not contradict the fact that $f$ is not identically zero in $\Omega$.",,['complex-analysis']
7,"$f$ entire but not polynomial then $\lim_{n\to\infty}\sup \{|z|:p_n(z)=0\}\to\infty$, where $p_n$ is $n-th$ Taylor series of $f$","entire but not polynomial then , where  is  Taylor series of",f \lim_{n\to\infty}\sup \{|z|:p_n(z)=0\}\to\infty p_n n-th f,"Let $f(z)=\sum_{k=0}^{\infty}a_kz^k$ be entire and not a polynomial. Let $p_n(z)=\sum_{k=0}^n a_kz^k$ be its $n-th$ Taylor polynomial centered at $0$, and let $r_n=\sup \{|z|:p_n(z)=0\}$. Show that $\lim_{n\to\infty}r_n=\infty$ My thought: $\lim_{n\to\infty}p_n(z)=\lim_{n\to\infty}(z-a_1)(z-a_2)...(z-a_n)=f(z)$, then if $\lim_{n\to\infty}r_n\neq 0$, then this means the zeros of $f$ is bounded by a compact set, then ${z: f(z)=0}$ has a limit point in $\mathbb{C}$, so $f\equiv 0$, which is contradiction with $f$ is polynomial. I feel something is wrong in my proof above, but I can not tell what exactly is not right. Could someone kindly help me with this? Thank you so much!","Let $f(z)=\sum_{k=0}^{\infty}a_kz^k$ be entire and not a polynomial. Let $p_n(z)=\sum_{k=0}^n a_kz^k$ be its $n-th$ Taylor polynomial centered at $0$, and let $r_n=\sup \{|z|:p_n(z)=0\}$. Show that $\lim_{n\to\infty}r_n=\infty$ My thought: $\lim_{n\to\infty}p_n(z)=\lim_{n\to\infty}(z-a_1)(z-a_2)...(z-a_n)=f(z)$, then if $\lim_{n\to\infty}r_n\neq 0$, then this means the zeros of $f$ is bounded by a compact set, then ${z: f(z)=0}$ has a limit point in $\mathbb{C}$, so $f\equiv 0$, which is contradiction with $f$ is polynomial. I feel something is wrong in my proof above, but I can not tell what exactly is not right. Could someone kindly help me with this? Thank you so much!",,"['complex-analysis', 'analysis']"
8,Prove that $\overline{f(z)}$ is differentiable at $a \in D(0;1)$ if and only if $f'(a)=0$,Prove that  is differentiable at  if and only if,\overline{f(z)} a \in D(0;1) f'(a)=0,"Let $f$ be holomorphic in $D(0;1)$ and define $k$ by $k(z)=\overline{f(z)}$. Prove that $k$ is differentiable at $a\in D(0;1)$ if and only if $f'(a)=0$. What I tried was first, assuming $k$ is differentiable and letting $f=u+iv$ we have (first when $h \in \mathbb{R}$) $$k'(z)= \lim_{h \to 0} \frac{u(x+h,y)-u(x,y)}{h} -i\frac{v(x+h,y)-v(x,y)}{h} = u_x -iv_x$$ and when $h=ik, \ k\in \mathbb{R}$ $$k'(z)=\lim_{k \to 0} \frac{u(x,y+k)-u(x,y)}{ik} -\frac{v(x,y+k)-v(x,y)}{h} = \frac{1}{i}u_y -v_y$$ And equating real and imaginary parts, we get that $$u_x=-v_y, \; u_y=v_x$$ Since $f$ is holomorphic, it satisfies the Cauchy-Riemann equations and thus $$u_x=v_y, \; u_y=-v_x$$ so $$f'(a)=-f'(a)$$ and then $f'(a)=0$. I don't know if this works, so please correct me if I'm wrong. Besides that, I'm stuck in proving the other implication. So far I did $$0=f'(a)=\lim_{h\to 0} \frac{f(a+h)-f(h)}{h}=\overline{\lim_{h\to 0}\frac{f(a+h)-f(h)}{h}}=\lim_{h\to 0}\frac{\overline{f(a+h)} -\overline{f(h)}}{\overline{h}}=\overline{f'(a)}=k'(a)$$ But again, I'm not sure if this is right. Any help will be highly appreciate, and thanks in advance!","Let $f$ be holomorphic in $D(0;1)$ and define $k$ by $k(z)=\overline{f(z)}$. Prove that $k$ is differentiable at $a\in D(0;1)$ if and only if $f'(a)=0$. What I tried was first, assuming $k$ is differentiable and letting $f=u+iv$ we have (first when $h \in \mathbb{R}$) $$k'(z)= \lim_{h \to 0} \frac{u(x+h,y)-u(x,y)}{h} -i\frac{v(x+h,y)-v(x,y)}{h} = u_x -iv_x$$ and when $h=ik, \ k\in \mathbb{R}$ $$k'(z)=\lim_{k \to 0} \frac{u(x,y+k)-u(x,y)}{ik} -\frac{v(x,y+k)-v(x,y)}{h} = \frac{1}{i}u_y -v_y$$ And equating real and imaginary parts, we get that $$u_x=-v_y, \; u_y=v_x$$ Since $f$ is holomorphic, it satisfies the Cauchy-Riemann equations and thus $$u_x=v_y, \; u_y=-v_x$$ so $$f'(a)=-f'(a)$$ and then $f'(a)=0$. I don't know if this works, so please correct me if I'm wrong. Besides that, I'm stuck in proving the other implication. So far I did $$0=f'(a)=\lim_{h\to 0} \frac{f(a+h)-f(h)}{h}=\overline{\lim_{h\to 0}\frac{f(a+h)-f(h)}{h}}=\lim_{h\to 0}\frac{\overline{f(a+h)} -\overline{f(h)}}{\overline{h}}=\overline{f'(a)}=k'(a)$$ But again, I'm not sure if this is right. Any help will be highly appreciate, and thanks in advance!",,"['complex-analysis', 'derivatives']"
9,"Using the Weierstrass M-test, show that the series converges uniformly on the given domain","Using the Weierstrass M-test, show that the series converges uniformly on the given domain",,"$\sum_{k \geq 0} \frac{z^k}{z^k+1}$ on the domain $\overline{D}[0, r]$, where $0 \leq r < 1$ I'm honestly not sure how to do this.  My text mentions the Weierstrass M-test but the example they gave after stating it uses a completely different method (looks like a repeat of a previous example) and looks nothing like the M-test.","$\sum_{k \geq 0} \frac{z^k}{z^k+1}$ on the domain $\overline{D}[0, r]$, where $0 \leq r < 1$ I'm honestly not sure how to do this.  My text mentions the Weierstrass M-test but the example they gave after stating it uses a completely different method (looks like a repeat of a previous example) and looks nothing like the M-test.",,['complex-analysis']
10,Order of growth of a complex polynomial,Order of growth of a complex polynomial,,"Question I want to determine the order of growth of a complex polynomial $p(z)$. My attempt We pick $$p(z)=a_nz^n+\ldots +a_1z+a_0$$ then we know that $$|p(z)| \le |a_nz^n|+\ldots +|a_1z|+|a_0|$$ since $e^x$ is increasing we have that $$|p(z)|<e^{|p(z)|} \le e^{|a_nz^n|+\ldots +|a_1z|+|a_0|}=e^{|a_n||z^n|+\ldots +|a_1||z|+|a_0|} \le max\{|a_i|\}e^{max\{|a_i|\}|z|^{n}}$$ The thing is that for small values of $z$ for example $z=0$ the above bound doesn't work and my definition says that the above should hold for all $z \in \mathbb{C}$. I am almost sure that the order of growth should be $n$ but I don't know if this is correct or if there is a better proof to get which is the order of growth of a complex polynomial that you can provide. Definitions. Let $f$ be an entire function. If there exist a positive number $\rho$ and constants $A,B >0$ such that $$|f(z)| \le A e^{B|z|^{\rho}}$$ for all $z \in \mathbb{C}$ then we say that $f$ has order of growth $\le \rho$. We define the order of growth of $f$ as $$\rho_f=inf\{ \rho \}$$","Question I want to determine the order of growth of a complex polynomial $p(z)$. My attempt We pick $$p(z)=a_nz^n+\ldots +a_1z+a_0$$ then we know that $$|p(z)| \le |a_nz^n|+\ldots +|a_1z|+|a_0|$$ since $e^x$ is increasing we have that $$|p(z)|<e^{|p(z)|} \le e^{|a_nz^n|+\ldots +|a_1z|+|a_0|}=e^{|a_n||z^n|+\ldots +|a_1||z|+|a_0|} \le max\{|a_i|\}e^{max\{|a_i|\}|z|^{n}}$$ The thing is that for small values of $z$ for example $z=0$ the above bound doesn't work and my definition says that the above should hold for all $z \in \mathbb{C}$. I am almost sure that the order of growth should be $n$ but I don't know if this is correct or if there is a better proof to get which is the order of growth of a complex polynomial that you can provide. Definitions. Let $f$ be an entire function. If there exist a positive number $\rho$ and constants $A,B >0$ such that $$|f(z)| \le A e^{B|z|^{\rho}}$$ for all $z \in \mathbb{C}$ then we say that $f$ has order of growth $\le \rho$. We define the order of growth of $f$ as $$\rho_f=inf\{ \rho \}$$",,['complex-analysis']
11,How can I know the analytic continuation exists in certain cases?,How can I know the analytic continuation exists in certain cases?,,"As pointed in Does the analytic continuation always exists? we know it doesn't always exist. But: take the $\Gamma$ function: the first definition everyone meet is the integral one: $$ z\mapsto\int_{0}^{+\infty}t^{z-1}e^{-t}\,dt $$ which defines an holomorphic function on the half plane $\{\Re z>0\}$. Moreover we immediately get the functional equation: $$ \Gamma(z+1)=z\Gamma(z)\;,\;\;\;\forall\; \Re z>0. $$ This equation is used to extend the function on the whole complex plane (minus the negative integers)... but: WHY CAN WE DO THIS?! We know that there is an holomorphic function $\Gamma$ which can be expressed as the integral on that half plane. Why are we allowed to write $$ \Gamma\left(\frac12\right)=-\frac12\Gamma\left(-\frac12\right) $$ for example? LHS is defined, RHS, NOT!!! But where's the problem? Simply let's define $\Gamma\left(-\frac12\right)$ in such a way... but why can we do this? How can I know that this function I named $\Gamma$ which is holomorphic on the above half plane admits an extension?","As pointed in Does the analytic continuation always exists? we know it doesn't always exist. But: take the $\Gamma$ function: the first definition everyone meet is the integral one: $$ z\mapsto\int_{0}^{+\infty}t^{z-1}e^{-t}\,dt $$ which defines an holomorphic function on the half plane $\{\Re z>0\}$. Moreover we immediately get the functional equation: $$ \Gamma(z+1)=z\Gamma(z)\;,\;\;\;\forall\; \Re z>0. $$ This equation is used to extend the function on the whole complex plane (minus the negative integers)... but: WHY CAN WE DO THIS?! We know that there is an holomorphic function $\Gamma$ which can be expressed as the integral on that half plane. Why are we allowed to write $$ \Gamma\left(\frac12\right)=-\frac12\Gamma\left(-\frac12\right) $$ for example? LHS is defined, RHS, NOT!!! But where's the problem? Simply let's define $\Gamma\left(-\frac12\right)$ in such a way... but why can we do this? How can I know that this function I named $\Gamma$ which is holomorphic on the above half plane admits an extension?",,"['complex-analysis', 'analytic-continuation']"
12,Another proof of Liouville's theorem.,Another proof of Liouville's theorem.,,Let $f(z)=\sum_{n} a_n z^n$ has radius of convergence $R>0$ and $0<r<R$. Show: $$\frac{1}{2\pi} \int_0^{2\pi} |f(re^{it})|^2 dt= \sum_{n}|a_n|^2r^{2n}$$ Use this equality to prove Liouvelle's Theorem. Can anyone give me a hint to how to proceed with this?,Let $f(z)=\sum_{n} a_n z^n$ has radius of convergence $R>0$ and $0<r<R$. Show: $$\frac{1}{2\pi} \int_0^{2\pi} |f(re^{it})|^2 dt= \sum_{n}|a_n|^2r^{2n}$$ Use this equality to prove Liouvelle's Theorem. Can anyone give me a hint to how to proceed with this?,,['complex-analysis']
13,Why are the trivial zeros of the Riemann zeta function only negative?,Why are the trivial zeros of the Riemann zeta function only negative?,,"The functional equation of the Riemann zeta function is  $$\zeta(s)=2^s\pi^{s-1}\sin(s\pi/2)\Gamma(1-s)\zeta(1-s)$$   clearly $2^s$ and $\pi^{1-s}$ are never equal to zero on the complex plane, and neither is Gamma.  Some of the zeros can be determined by $\sin(s\pi/2)=0$ but this is the case when $s=2n$  This would imply that there is a zero at every even integer, but it's known that the only non-trivial zeros are at the negative even integers.  What am I doing wrong here?","The functional equation of the Riemann zeta function is  $$\zeta(s)=2^s\pi^{s-1}\sin(s\pi/2)\Gamma(1-s)\zeta(1-s)$$   clearly $2^s$ and $\pi^{1-s}$ are never equal to zero on the complex plane, and neither is Gamma.  Some of the zeros can be determined by $\sin(s\pi/2)=0$ but this is the case when $s=2n$  This would imply that there is a zero at every even integer, but it's known that the only non-trivial zeros are at the negative even integers.  What am I doing wrong here?",,"['complex-analysis', 'riemann-zeta', 'riemann-hypothesis']"
14,Value of $1+4\omega+9\omega^{2}+\cdot\cdot\cdot +n ^{2}\omega^{n-1}$,Value of,1+4\omega+9\omega^{2}+\cdot\cdot\cdot +n ^{2}\omega^{n-1},How to find the value of $$1+4\omega+9\omega^{2}+\cdot\cdot\cdot +n ^{2}\omega^{n-1}$$ where $\omega$ is a primitive $n$th root of unity? I am trying to find the value using the fact that $$1+\omega+\omega^{2}+\cdot+\cdot\cdot+\omega^{n-1}=0$$ but did't get the answer. Please suggest me how to solve it. Thanks in advance.,How to find the value of $$1+4\omega+9\omega^{2}+\cdot\cdot\cdot +n ^{2}\omega^{n-1}$$ where $\omega$ is a primitive $n$th root of unity? I am trying to find the value using the fact that $$1+\omega+\omega^{2}+\cdot+\cdot\cdot+\omega^{n-1}=0$$ but did't get the answer. Please suggest me how to solve it. Thanks in advance.,,['complex-analysis']
15,Showing that $\{z\in\mathbb{C}:|z-1|<|z+i|\}$ is an open set,Showing that  is an open set,\{z\in\mathbb{C}:|z-1|<|z+i|\},"Got stuck on some homework (from H. A. Priestley, Complex Analysis). My topology ain't quite up to speed yet. So, I want to show that $S=\{z\in\mathbb{C}:|z-1|<|z+i|\}$ is open. Geometrically it's the points above the line through $1-i$ and the origin. (Eh?) So, essentially what I want to do is to prove that for every $z\in S$, there's a $r>0$ such that $D(z;r)\subset S$. In more concrete words, I want to figure out an $r$ such that the implication $|w-z|<r \Rightarrow |w-1|<|w+i|$ holds. I started to fiddle around with the triangle inequality $$|w-1|=|w-z+z-1|\leq |w-z|+|z-1|$$ and then figured I could set $0<r<|z+i|-|z-1|$, which then would yield $$|w-1|\leq |z+i|$$ but that isn't quite it. I tried to use more terms in the ""triangle inequality trick"" but I can't seem to get it the way I want it. Help me oh math.stackexchange! (If you want, of course.)","Got stuck on some homework (from H. A. Priestley, Complex Analysis). My topology ain't quite up to speed yet. So, I want to show that $S=\{z\in\mathbb{C}:|z-1|<|z+i|\}$ is open. Geometrically it's the points above the line through $1-i$ and the origin. (Eh?) So, essentially what I want to do is to prove that for every $z\in S$, there's a $r>0$ such that $D(z;r)\subset S$. In more concrete words, I want to figure out an $r$ such that the implication $|w-z|<r \Rightarrow |w-1|<|w+i|$ holds. I started to fiddle around with the triangle inequality $$|w-1|=|w-z+z-1|\leq |w-z|+|z-1|$$ and then figured I could set $0<r<|z+i|-|z-1|$, which then would yield $$|w-1|\leq |z+i|$$ but that isn't quite it. I tried to use more terms in the ""triangle inequality trick"" but I can't seem to get it the way I want it. Help me oh math.stackexchange! (If you want, of course.)",,['complex-analysis']
16,"Evaluating $\int_0^{2 \pi} e^{\cos x} \cos (nx - \sin x) \,dx$ using complex analysis",Evaluating  using complex analysis,"\int_0^{2 \pi} e^{\cos x} \cos (nx - \sin x) \,dx","I'm taking a complex analysis course and doing some practice computing residues & evaluating integrals. I pulled out an old book called ""The Cauchy Method of Residues: Theory and Applications, Volume I"" On page 196-197, there are some interesting integrals to evaluate. I'm at 5.4.3.10.: I was able to do question 1, but was stumped at how to even begin with question 2: Evaluate the integral   $$\int_0^{2 \pi} e^{\cos x} \cos (nx - \sin x) \,dx ,$$   where $n$ is an natural number. The answer is simply $\frac{2 \pi}{n}$. Any hints?","I'm taking a complex analysis course and doing some practice computing residues & evaluating integrals. I pulled out an old book called ""The Cauchy Method of Residues: Theory and Applications, Volume I"" On page 196-197, there are some interesting integrals to evaluate. I'm at 5.4.3.10.: I was able to do question 1, but was stumped at how to even begin with question 2: Evaluate the integral   $$\int_0^{2 \pi} e^{\cos x} \cos (nx - \sin x) \,dx ,$$   where $n$ is an natural number. The answer is simply $\frac{2 \pi}{n}$. Any hints?",,"['complex-analysis', 'contour-integration']"
17,Let $f$ be a non-constant analytic function on $\mathbb{D}$ satisfying $|f(z^2)| ≤ |f(z)|$ for $|z| < 1.$,Let  be a non-constant analytic function on  satisfying  for,f \mathbb{D} |f(z^2)| ≤ |f(z)| |z| < 1.,"Let $f$ be a non-constant analytic function on $\mathbb{D}$ satisfying $|f(z^2)| ≤ |f(z)|$ for $|z| < 1.$ $(a)$ Show that $f(0) = 0.$ $(b)$ Show that $f(z)\neq 0$ for $0<|z|<1.$ $(c)$ Show that $f(z) = az^n,$ where $a ∈ \mathbb{C},n ∈ N.$ I know how to do $(b)$ but I'm not sure how to do the other two parts.  Some help would be great thanks.","Let $f$ be a non-constant analytic function on $\mathbb{D}$ satisfying $|f(z^2)| ≤ |f(z)|$ for $|z| < 1.$ $(a)$ Show that $f(0) = 0.$ $(b)$ Show that $f(z)\neq 0$ for $0<|z|<1.$ $(c)$ Show that $f(z) = az^n,$ where $a ∈ \mathbb{C},n ∈ N.$ I know how to do $(b)$ but I'm not sure how to do the other two parts.  Some help would be great thanks.",,['complex-analysis']
18,Best complex analysis references?,Best complex analysis references?,,"I own Gamelin's 'Complex Analysis', but I'm having a bit of a hard time understanding it.  I have also tried watching MIT Open Courseware videos on the subject, but I easily get lost.  Are there any references ( preferably NOT textbooks as I am short on funds at the moment) that server as a smooth transition from calculus to complex analysis?  I have been lucky to have some help from a user on this website, but I would also like some other references so I don't constantly take up his time. Thanks!","I own Gamelin's 'Complex Analysis', but I'm having a bit of a hard time understanding it.  I have also tried watching MIT Open Courseware videos on the subject, but I easily get lost.  Are there any references ( preferably NOT textbooks as I am short on funds at the moment) that server as a smooth transition from calculus to complex analysis?  I have been lucky to have some help from a user on this website, but I would also like some other references so I don't constantly take up his time. Thanks!",,"['complex-analysis', 'reference-request']"
19,Evaluating trigonometric integral using residues,Evaluating trigonometric integral using residues,,"I am trying to evaluate for real positive $\alpha,\beta$ $$\int_{0}^{\infty}\arctan\left(\frac{\alpha}{x}\right)\sin(\beta x)dx$$ using a hint to consider $$\int \log\left(\frac{z+ia}{z}\right) e^{ibz}dz$$ with a branch cut from $0$ to $z=-ia$. However, I am having a lot of difficulty understanding why this hint is useful. I have tried to construct a semicircle contour on the upper halfplane with a smaller semicircle to avoid the point $z=0$ and I have having difficulty on a couple of fronts. First, I cannot seem to conclude that when my smaller semi circle tends to zero, that this section of the contour contributes nothing to the integral, but based on past experience I don't see why it is not true. However, even if I suppose the upper and lower semi circle arcs do not contribute to the integral in the limit, I am left with (since there are no poles in my contour) $$\int_{-\infty}^{\infty} \log\left(\frac{x+i\alpha}{x}\right) e^{i\beta x}dx = \int_{-\infty}^{\infty}\log\left(\frac{x+i\alpha}{x}\right)(\cos(\beta x) + i\sin(\beta x))dx = 0.$$ From here, it seems like I need to evaluate either \begin{equation} \int_{-\infty}^{\infty} \log\left(\frac{x+i\alpha}{x}\right)\cos(\beta x)dx \qquad (1) \end{equation} or  \begin{equation} \int_{-\infty}^{\infty} i\log\left(\frac{x+i\alpha}{x}\right)\sin(\beta x)dx \qquad (2) \end{equation} using contour integration again to get further. If I were to accomplish that, since $\log((x+i\alpha)/x))$ is not an odd or even function, I don't know how I could further reduce my limits of integration to $0$ to $\infty$ to match the limits of integration of my original integral. Even further still, if I were to manage all of this, I don't see how it would introduce a $\arctan(\alpha/x)$ into the expression so I can arrive at an answer. I tried to let $\gamma$ be the solution to (1) and see if this would lead to $\arctan$ showing up eventually, but doing this made it seem like I would not get anywhere.","I am trying to evaluate for real positive $\alpha,\beta$ $$\int_{0}^{\infty}\arctan\left(\frac{\alpha}{x}\right)\sin(\beta x)dx$$ using a hint to consider $$\int \log\left(\frac{z+ia}{z}\right) e^{ibz}dz$$ with a branch cut from $0$ to $z=-ia$. However, I am having a lot of difficulty understanding why this hint is useful. I have tried to construct a semicircle contour on the upper halfplane with a smaller semicircle to avoid the point $z=0$ and I have having difficulty on a couple of fronts. First, I cannot seem to conclude that when my smaller semi circle tends to zero, that this section of the contour contributes nothing to the integral, but based on past experience I don't see why it is not true. However, even if I suppose the upper and lower semi circle arcs do not contribute to the integral in the limit, I am left with (since there are no poles in my contour) $$\int_{-\infty}^{\infty} \log\left(\frac{x+i\alpha}{x}\right) e^{i\beta x}dx = \int_{-\infty}^{\infty}\log\left(\frac{x+i\alpha}{x}\right)(\cos(\beta x) + i\sin(\beta x))dx = 0.$$ From here, it seems like I need to evaluate either \begin{equation} \int_{-\infty}^{\infty} \log\left(\frac{x+i\alpha}{x}\right)\cos(\beta x)dx \qquad (1) \end{equation} or  \begin{equation} \int_{-\infty}^{\infty} i\log\left(\frac{x+i\alpha}{x}\right)\sin(\beta x)dx \qquad (2) \end{equation} using contour integration again to get further. If I were to accomplish that, since $\log((x+i\alpha)/x))$ is not an odd or even function, I don't know how I could further reduce my limits of integration to $0$ to $\infty$ to match the limits of integration of my original integral. Even further still, if I were to manage all of this, I don't see how it would introduce a $\arctan(\alpha/x)$ into the expression so I can arrive at an answer. I tried to let $\gamma$ be the solution to (1) and see if this would lead to $\arctan$ showing up eventually, but doing this made it seem like I would not get anywhere.",,"['complex-analysis', 'contour-integration']"
20,Inverse of the Joukowski map $\phi(z) = z + \frac{1}{z}$,Inverse of the Joukowski map,\phi(z) = z + \frac{1}{z},"We know the Joukowski map $$\phi(z) = z + \frac{1}{z}$$ which maps the upper semidisc of radius $1$ in the lower half plane, and the lower semidisc of radius $1$ in the upper half plane. What is the inverse of this function ? We obtain $z ^{2}-zy + 1 = 0$ and this equation has $2$ solutions, which is the right one ?","We know the Joukowski map $$\phi(z) = z + \frac{1}{z}$$ which maps the upper semidisc of radius $1$ in the lower half plane, and the lower semidisc of radius $1$ in the upper half plane. What is the inverse of this function ? We obtain $z ^{2}-zy + 1 = 0$ and this equation has $2$ solutions, which is the right one ?",,"['complex-analysis', 'analysis']"
21,Is $\cos x$ irreducible as a power series?,Is  irreducible as a power series?,\cos x,Let $\mathbb{Q}_{\mathrm{ent}}[[x]]$ be the ring of entire functions with rational coefficients.  Is  $$ \cos x \;=\; \sum_{n=0}^\infty (-1)^n\!\frac{x^{2n}}{(2n)!} $$ irreducible in $\mathbb{Q}_\mathrm{ent}[[x]]$?,Let $\mathbb{Q}_{\mathrm{ent}}[[x]]$ be the ring of entire functions with rational coefficients.  Is  $$ \cos x \;=\; \sum_{n=0}^\infty (-1)^n\!\frac{x^{2n}}{(2n)!} $$ irreducible in $\mathbb{Q}_\mathrm{ent}[[x]]$?,,"['complex-analysis', 'ring-theory', 'power-series', 'irreducible-polynomials']"
22,Inversion of Laplace transform $F(s)=\log(\frac{s+1}{s})$ (Bromwich integral),Inversion of Laplace transform  (Bromwich integral),F(s)=\log(\frac{s+1}{s}),"I am looking for the inversion of Laplace transform $F(s)=\log(\frac{s+1}{s})$. I started by using the general formula of the Bromwich integral: $\displaystyle \lim_{R\to\infty} \int_{a-iR}^{a+iR} \frac{1}{2\pi i}\log\left(\frac{s+1}{s}\right) e^{st}ds $ Then, I used that: $\displaystyle \log\left(\frac{s+1}{s}\right)=\sum_{n=1}^{\infty} \frac{ (-1)^{n+1} }{n} (1/s)^n $ for $|s|>1$. Since  $|s|>1$ the Bromwich line should be to the right of $1$. So: $\displaystyle \sum_{n=1}^{\infty} \lim_{R\to\infty} \int_{a-iR}^{a+iR} \frac{1}{2\pi i}\frac{ (-1)^{n+1} }{n} (1/s)^n  e^{st}ds $ Can someone help me to continue this?","I am looking for the inversion of Laplace transform $F(s)=\log(\frac{s+1}{s})$. I started by using the general formula of the Bromwich integral: $\displaystyle \lim_{R\to\infty} \int_{a-iR}^{a+iR} \frac{1}{2\pi i}\log\left(\frac{s+1}{s}\right) e^{st}ds $ Then, I used that: $\displaystyle \log\left(\frac{s+1}{s}\right)=\sum_{n=1}^{\infty} \frac{ (-1)^{n+1} }{n} (1/s)^n $ for $|s|>1$. Since  $|s|>1$ the Bromwich line should be to the right of $1$. So: $\displaystyle \sum_{n=1}^{\infty} \lim_{R\to\infty} \int_{a-iR}^{a+iR} \frac{1}{2\pi i}\frac{ (-1)^{n+1} }{n} (1/s)^n  e^{st}ds $ Can someone help me to continue this?",,"['calculus', 'complex-analysis', 'laplace-transform']"
23,A gamma function identity,A gamma function identity,,I am given the impression that the following is true (for at least all positive $\lambda$ - may be even true for any complex $\lambda$) $$ \left\lvert \frac{\Gamma(i\lambda + 1/2)}{\Gamma(i\lambda)} \right\rvert^2 =  \lambda \tanh (\pi \lambda) $$ It would be great if someone can help derive this.,I am given the impression that the following is true (for at least all positive $\lambda$ - may be even true for any complex $\lambda$) $$ \left\lvert \frac{\Gamma(i\lambda + 1/2)}{\Gamma(i\lambda)} \right\rvert^2 =  \lambda \tanh (\pi \lambda) $$ It would be great if someone can help derive this.,,"['real-analysis', 'complex-analysis', 'gamma-function']"
24,"$f,\overline f$ are both analytic in a domain $\Omega$ then $f$ is constant?",are both analytic in a domain  then  is constant?,"f,\overline f \Omega f","is it true if $f,\overline f$ are both analytic in a domain $\Omega$ then $f$ is constant? I am not able to  find out what property of holomorphic map I need to apply. please help.Thank you. $f(z)=u(x,y)+iv(x,y)$, $\bar{f}(z)=u(x,y)-iv(x,y)$","is it true if $f,\overline f$ are both analytic in a domain $\Omega$ then $f$ is constant? I am not able to  find out what property of holomorphic map I need to apply. please help.Thank you. $f(z)=u(x,y)+iv(x,y)$, $\bar{f}(z)=u(x,y)-iv(x,y)$",,['complex-analysis']
25,"If $\theta\in\mathbb{Q}$, is it true that $(\cos \theta + i \sin \theta)^\alpha = \cos(\alpha\theta) + i \sin(\alpha\theta)$?","If , is it true that ?",\theta\in\mathbb{Q} (\cos \theta + i \sin \theta)^\alpha = \cos(\alpha\theta) + i \sin(\alpha\theta),"Is the following true if $\theta\in\mathbb{Q}$? $$(\cos \theta + i \sin \theta)^\alpha = \cos(\alpha\theta) + i \sin(\alpha\theta)$$ Is it true if $\alpha\in\mathbb{R}$? In each case, prove or give a counterexample, whichever is applicable. I am not able to guess except about the de Moivre's theorem.","Is the following true if $\theta\in\mathbb{Q}$? $$(\cos \theta + i \sin \theta)^\alpha = \cos(\alpha\theta) + i \sin(\alpha\theta)$$ Is it true if $\alpha\in\mathbb{R}$? In each case, prove or give a counterexample, whichever is applicable. I am not able to guess except about the de Moivre's theorem.",,"['complex-analysis', 'complex-numbers', 'exponentiation']"
26,Riemann surface arising as a quotient of the upper half-plane.,Riemann surface arising as a quotient of the upper half-plane.,,"Let $H$ be the upper half-plane $\{z \in \mathbb C \mid \Im(z) > 0\}$. For a fixed real $\lambda > 0$, let be the automorphism $$d_\lambda : H \to H, z \mapsto \lambda z .$$ Denote $\Gamma$ the subgroup of $\mathrm{Aut(H)}$ generated by $d_\lambda$. The goal is to determine the Riemann surface $H/\Gamma$. Let's discard the trivial case $\lambda=1$. [ Edit , false : $H/\Gamma$ is open as the open set $\{ z \in H \mid |z|<1 \}$ is a fundamental domain of the holomorphic projection.] One have $\pi_1(H/\Gamma) \simeq \Gamma \simeq \mathbb Z$. Hence, as no compact Riemann surface has $\mathbb Z$ as fundamental group, $H/\Gamma$ must be an open Riemann surface. As I don't know a lot of open Riemann surfaces, I'm tempted to test $\mathbb C^\ast$ and the punctured unit disk $\mathbb D^\ast$ that matches those properties. But $\mathbb C^\ast$ has universal cover $\mathbb C \not\simeq H$, and so $H/\Gamma \not\simeq \mathbb C^\ast$. This leaves me with $\mathbb D^\ast$. How can I show that $H / \Gamma$ is (or isn't) biholomorphic to $\mathbb D^\ast$ ? If it isn't, does this quotient look like a well-know surface ? P.S. Does that kind of quotient have a name ? I'm aware of the name of modular curve when $\Gamma$ is a subgroup of $PSL(2,\mathbb Z)$ which is not the case here.","Let $H$ be the upper half-plane $\{z \in \mathbb C \mid \Im(z) > 0\}$. For a fixed real $\lambda > 0$, let be the automorphism $$d_\lambda : H \to H, z \mapsto \lambda z .$$ Denote $\Gamma$ the subgroup of $\mathrm{Aut(H)}$ generated by $d_\lambda$. The goal is to determine the Riemann surface $H/\Gamma$. Let's discard the trivial case $\lambda=1$. [ Edit , false : $H/\Gamma$ is open as the open set $\{ z \in H \mid |z|<1 \}$ is a fundamental domain of the holomorphic projection.] One have $\pi_1(H/\Gamma) \simeq \Gamma \simeq \mathbb Z$. Hence, as no compact Riemann surface has $\mathbb Z$ as fundamental group, $H/\Gamma$ must be an open Riemann surface. As I don't know a lot of open Riemann surfaces, I'm tempted to test $\mathbb C^\ast$ and the punctured unit disk $\mathbb D^\ast$ that matches those properties. But $\mathbb C^\ast$ has universal cover $\mathbb C \not\simeq H$, and so $H/\Gamma \not\simeq \mathbb C^\ast$. This leaves me with $\mathbb D^\ast$. How can I show that $H / \Gamma$ is (or isn't) biholomorphic to $\mathbb D^\ast$ ? If it isn't, does this quotient look like a well-know surface ? P.S. Does that kind of quotient have a name ? I'm aware of the name of modular curve when $\Gamma$ is a subgroup of $PSL(2,\mathbb Z)$ which is not the case here.",,"['complex-analysis', 'riemann-surfaces', 'hyperbolic-geometry', 'covering-spaces']"
27,Laurent series $z=i$,Laurent series,z=i,"To find the Laurent series expansion for $\frac{1}{1+z^2}$, centered at $z=i$ would using partial fraction decomposition be the right idea? So, $\frac{1}{1+z^2}$=$\frac{1}{(z+i)(z-i)}$=$\frac{\frac{-1}{2i}}{z+i} +\frac{\frac{1}{2i}}{z-i}$?","To find the Laurent series expansion for $\frac{1}{1+z^2}$, centered at $z=i$ would using partial fraction decomposition be the right idea? So, $\frac{1}{1+z^2}$=$\frac{1}{(z+i)(z-i)}$=$\frac{\frac{-1}{2i}}{z+i} +\frac{\frac{1}{2i}}{z-i}$?",,"['complex-analysis', 'laurent-series']"
28,Limit of $f(z)=\frac 1z$ as $z$ approaches $0$?,Limit of  as  approaches ?,f(z)=\frac 1z z 0,"I know that the answer is infinity, but doesn't this contradict the theorem stating that $\displaystyle\lim_{z\to0} \Im(f(z)) = \Im(\displaystyle\lim_{z\to0} f(z))$? I mean, the LHS doesn't exist because $\Im(f(z))$ approaches $-\infty$ and  $\infty$ as $z$ approaches $0$ along the imaginary axis from the positive and negative directions respectively. I know I'm misunderstanding something fundamental, but what is it?","I know that the answer is infinity, but doesn't this contradict the theorem stating that $\displaystyle\lim_{z\to0} \Im(f(z)) = \Im(\displaystyle\lim_{z\to0} f(z))$? I mean, the LHS doesn't exist because $\Im(f(z))$ approaches $-\infty$ and  $\infty$ as $z$ approaches $0$ along the imaginary axis from the positive and negative directions respectively. I know I'm misunderstanding something fundamental, but what is it?",,"['complex-analysis', 'limits']"
29,Proving that a complex number $z$ is real.,Proving that a complex number  is real.,z,"A problem I have in my book is to prove that $z$ is real if and only if $\bar{z} = z$. So far I have got that for $z = x + iy$, if $z$ is real, $y = 0$ and thus $z = x = \bar{z}$ as  $\bar{z} = x - iy$ where $y = 0$ (if I'm right). Now my book mentions something like converse of this, i.e, if $\bar{z} = z$ then $x+iy = x-iy$, where the last equality implies $y = -y$ and thus $y = 0$ (I don't get what equality it's talking about). Also later it's explained that, therefore, $z = x$ and thus is real. (I don't get the second part at all). Can someone please help me to understand this?","A problem I have in my book is to prove that $z$ is real if and only if $\bar{z} = z$. So far I have got that for $z = x + iy$, if $z$ is real, $y = 0$ and thus $z = x = \bar{z}$ as  $\bar{z} = x - iy$ where $y = 0$ (if I'm right). Now my book mentions something like converse of this, i.e, if $\bar{z} = z$ then $x+iy = x-iy$, where the last equality implies $y = -y$ and thus $y = 0$ (I don't get what equality it's talking about). Also later it's explained that, therefore, $z = x$ and thus is real. (I don't get the second part at all). Can someone please help me to understand this?",,"['complex-analysis', 'complex-numbers']"
30,Is an integral in the complex plane an integral over a single number?,Is an integral in the complex plane an integral over a single number?,,"A recent question from Juan Saloman reminded me of something that has nagged me for years, and I have never understood and never heard explained.  (or maybe I just don't remember, but anyway ...)  In the complex plane, can an integral of the general form $\int dz f(z)$ over the complex plane be treated as a straightforward 1-D integral if no path in the complex plane is specified?  I have been in classes where the professors seemed to do just that.  But, I mean, $z$ has two independent parts, right?  In other words, it's the complex plane , not the complex line .  I have seen these kinds of integrals before and sort learned to deal with them in a monkey-see-monkey-do fashion, but never really understood what was going on to my own satisfaction.  Thanks.","A recent question from Juan Saloman reminded me of something that has nagged me for years, and I have never understood and never heard explained.  (or maybe I just don't remember, but anyway ...)  In the complex plane, can an integral of the general form $\int dz f(z)$ over the complex plane be treated as a straightforward 1-D integral if no path in the complex plane is specified?  I have been in classes where the professors seemed to do just that.  But, I mean, $z$ has two independent parts, right?  In other words, it's the complex plane , not the complex line .  I have seen these kinds of integrals before and sort learned to deal with them in a monkey-see-monkey-do fashion, but never really understood what was going on to my own satisfaction.  Thanks.",,"['complex-analysis', 'complex-integration']"
31,"A holomorphic function $f$, injective on $\partial D$, must be injective in $\bar{D}$?","A holomorphic function , injective on , must be injective in ?",f \partial D \bar{D},"Prove: If $f$ is holomorphic on a neighborhood of the closed unit disc $\bar{D}$, and if $f$ is one-to-one on $\partial D$, then $f$ is   one-to-one on $\bar{D}$. (Greene and Krantz's Function Theory of One Complex Variable (3rd), Ch. 5, Problem 17.) Can anyone provide a clue as to how to attack this problem ?","Prove: If $f$ is holomorphic on a neighborhood of the closed unit disc $\bar{D}$, and if $f$ is one-to-one on $\partial D$, then $f$ is   one-to-one on $\bar{D}$. (Greene and Krantz's Function Theory of One Complex Variable (3rd), Ch. 5, Problem 17.) Can anyone provide a clue as to how to attack this problem ?",,['complex-analysis']
32,Julia Set of polynomials,Julia Set of polynomials,,"If $f$ is a polynomial and $z\in\mathbb{C}$, show that either $f^n(z)\rightarrow\infty$ or $\{f^n(z) : n\geq 1\}$ is a bounded set. Here, $f^2(z)=f(f(z))$ and $f^n(z)=f(f^{n-1}(z))$ for $n\geq 2$ I had a proof structured as followed: 1) Suppose $\{f^n(z) : n\geq 1\}$ is unbounded. Then there exists a subsequence $(n_k)$ such that $f^{n_k}(z)\rightarrow\infty$. 2) We are done if we can show that $|f^{k}(z)|$ is monotone everntually. But the trouble is 2) is really tedious to verify. I am just wondering whether there is a more pretty way to do this.","If $f$ is a polynomial and $z\in\mathbb{C}$, show that either $f^n(z)\rightarrow\infty$ or $\{f^n(z) : n\geq 1\}$ is a bounded set. Here, $f^2(z)=f(f(z))$ and $f^n(z)=f(f^{n-1}(z))$ for $n\geq 2$ I had a proof structured as followed: 1) Suppose $\{f^n(z) : n\geq 1\}$ is unbounded. Then there exists a subsequence $(n_k)$ such that $f^{n_k}(z)\rightarrow\infty$. 2) We are done if we can show that $|f^{k}(z)|$ is monotone everntually. But the trouble is 2) is really tedious to verify. I am just wondering whether there is a more pretty way to do this.",,"['complex-analysis', 'fractals']"
33,An entire function $g$ such that $|g(z^2)| \leq e^{|z|}$ and $g(m) = 0 \quad \forall m \in \mathbb{Z}$ is identically $0$,An entire function  such that  and  is identically,g |g(z^2)| \leq e^{|z|} g(m) = 0 \quad \forall m \in \mathbb{Z} 0,I have been trying to solve the following exercise from a collection of old complex analysis qualifier exams. Suppose that $g$ is an entire function that satisfies the inequality $|g(z^2)| \leq e^{|z|}$. Also suppose that $g(m) = 0 \quad \forall m \in \mathbb{Z}$. Then prove that $g(z) \equiv 0$ (i. e. that $g$ is identically $0$). So what I think is that the inequality by putting $z^{1/2}$ gives me $|g(z)| \leq e^{|z|^{1/2}}$ and this means that the entire function $g$ is of finite order and its order $\lambda = \lambda(g) \leq \frac{1}{2}$. Then I have been looking at the basic theorems for finite order entire functions but I don't really see if one of them would be helpful here. So my question is how can I solve this problem? Is it really helpful to look at the theorems for finite order entire functions?,I have been trying to solve the following exercise from a collection of old complex analysis qualifier exams. Suppose that $g$ is an entire function that satisfies the inequality $|g(z^2)| \leq e^{|z|}$. Also suppose that $g(m) = 0 \quad \forall m \in \mathbb{Z}$. Then prove that $g(z) \equiv 0$ (i. e. that $g$ is identically $0$). So what I think is that the inequality by putting $z^{1/2}$ gives me $|g(z)| \leq e^{|z|^{1/2}}$ and this means that the entire function $g$ is of finite order and its order $\lambda = \lambda(g) \leq \frac{1}{2}$. Then I have been looking at the basic theorems for finite order entire functions but I don't really see if one of them would be helpful here. So my question is how can I solve this problem? Is it really helpful to look at the theorems for finite order entire functions?,,['complex-analysis']
34,Why is the sum of residues of $\frac{1}{1+z^n}$ in the upper half plane $1/[in\sin(\pi/n)]$?,Why is the sum of residues of  in the upper half plane ?,\frac{1}{1+z^n} 1/[in\sin(\pi/n)],"Suppose $F_n=1/(1+z^n)$ for $n$ even. I'm curious, why is the sum of residues of $F_n$ in the upper half plane a geometric series whose sum is $1/[in\sin(\pi/n)]$? I know that if $f(z)=\frac{P(z)}{Q(z)}$ has a simple root $a$ of $Q(z)$, then $\text{Res}[f(z),a]=\frac{P(a)}{Q'(a)}$. Hence if $p$ is a pole of $F_n$, then $$ \text{Res}[F_n,p]=\frac{1}{np^{n-1}}=\frac{p}{np^n}=-\frac{p}{n}. $$ By Cauchy's Integral Formula, the sum of the residues in the upper half plane is $$ \sum_{y>0}\text{Res}[F_n,z]=\frac{1}{2\pi i}\int_{-\infty}^\infty F_n(x)dx=\frac{1}{2\pi i}\int_{-\infty}^{\infty}\frac{dx}{1+x^n}. $$ I don't know how to proceed in showing this is a geometric series which sums to $1/[in\sin(\pi/n)]$. I'd appreciate suggestions on how to reach the conclusion. Thanks.","Suppose $F_n=1/(1+z^n)$ for $n$ even. I'm curious, why is the sum of residues of $F_n$ in the upper half plane a geometric series whose sum is $1/[in\sin(\pi/n)]$? I know that if $f(z)=\frac{P(z)}{Q(z)}$ has a simple root $a$ of $Q(z)$, then $\text{Res}[f(z),a]=\frac{P(a)}{Q'(a)}$. Hence if $p$ is a pole of $F_n$, then $$ \text{Res}[F_n,p]=\frac{1}{np^{n-1}}=\frac{p}{np^n}=-\frac{p}{n}. $$ By Cauchy's Integral Formula, the sum of the residues in the upper half plane is $$ \sum_{y>0}\text{Res}[F_n,z]=\frac{1}{2\pi i}\int_{-\infty}^\infty F_n(x)dx=\frac{1}{2\pi i}\int_{-\infty}^{\infty}\frac{dx}{1+x^n}. $$ I don't know how to proceed in showing this is a geometric series which sums to $1/[in\sin(\pi/n)]$. I'd appreciate suggestions on how to reach the conclusion. Thanks.",,"['complex-analysis', 'residue-calculus']"
35,Determining where a function is complex differentiable,Determining where a function is complex differentiable,,"I have a homework question, and I'm having a hard time interpreting it. Question: Where is the function $f(x+iy)=x^4y^5+ixy^3$ complex differentiable? Determine the derivative in such points. My first plan was to find a region for which the following theorem applied: Suppose $f=u+iv$ is a complex-valued function defined on an open set $\Omega$. If $u$ and $v$ are continuously differentiable and satisfy the Cauch-Riemann equations on $\Omega$, then $f$ is holomorphic on $\Omega$ and $f'(z)=\frac{\partial f}{\partial z}$. Of course, $u$ and $v$ are going to be continously differentiable; the only question is, on what region are the Cauchy-Riemann equations satisfied? So, I found that the Cauchy-Riemann equations in this case are the following: $4x^3y^5=3xy^2$ and $5x^4y^4=-y^3$ and the only point at which these equations are satisfied is $(0,0)$. There's a converse to this theorem, but a lone point is not a region, so I'm not sure if either of these theorems are relevant. Is the only way to go back and find at which points $lim_{h\to0} \frac{f(z_{0}+h)-f(z_{0})}{h}$ exists? Thanks.","I have a homework question, and I'm having a hard time interpreting it. Question: Where is the function $f(x+iy)=x^4y^5+ixy^3$ complex differentiable? Determine the derivative in such points. My first plan was to find a region for which the following theorem applied: Suppose $f=u+iv$ is a complex-valued function defined on an open set $\Omega$. If $u$ and $v$ are continuously differentiable and satisfy the Cauch-Riemann equations on $\Omega$, then $f$ is holomorphic on $\Omega$ and $f'(z)=\frac{\partial f}{\partial z}$. Of course, $u$ and $v$ are going to be continously differentiable; the only question is, on what region are the Cauchy-Riemann equations satisfied? So, I found that the Cauchy-Riemann equations in this case are the following: $4x^3y^5=3xy^2$ and $5x^4y^4=-y^3$ and the only point at which these equations are satisfied is $(0,0)$. There's a converse to this theorem, but a lone point is not a region, so I'm not sure if either of these theorems are relevant. Is the only way to go back and find at which points $lim_{h\to0} \frac{f(z_{0}+h)-f(z_{0})}{h}$ exists? Thanks.",,['complex-analysis']
36,Why is it biholomorphic?,Why is it biholomorphic?,,"The proof of Theorem 13.5 in ""Lectures on Riemann Surfaces"" by Otto Forster begins by saying Set $U_1:={\mathbb P}^1 \backslash \infty$ and $U_2:={\mathbb P}^1 \backslash 0$.   Since $U_1 = {\mathbb C}$ and $U_2$ is biholomorphic to ${\mathbb C}$, it follows from (13.4) that $H^1(U_i, {\cal O})=0$. In ""1.5 Examples of Riemann Surfaces"" in the book the maps $\phi_i:U_i \rightarrow {\mathbb C}, i=1,2$ are defined as follows: $\phi_1$ is the identity map and   $$ \phi_2(z) :=  \left\{ \begin{array}{ll} 1/z & \mbox{for} \; z \in {\mathbb C}^*\\ 0   & \mbox{for} \; z = \infty \end{array} \right. $$ But, It seems to me that $\phi_2$ cannot be biholomorphic at $\infty$, because since $\phi_2'(z)=-1/z^2$, $$ \lim_{z\rightarrow \infty} \phi_2'(z) = 0. $$ Could someone point out where I made a mistake ?","The proof of Theorem 13.5 in ""Lectures on Riemann Surfaces"" by Otto Forster begins by saying Set $U_1:={\mathbb P}^1 \backslash \infty$ and $U_2:={\mathbb P}^1 \backslash 0$.   Since $U_1 = {\mathbb C}$ and $U_2$ is biholomorphic to ${\mathbb C}$, it follows from (13.4) that $H^1(U_i, {\cal O})=0$. In ""1.5 Examples of Riemann Surfaces"" in the book the maps $\phi_i:U_i \rightarrow {\mathbb C}, i=1,2$ are defined as follows: $\phi_1$ is the identity map and   $$ \phi_2(z) :=  \left\{ \begin{array}{ll} 1/z & \mbox{for} \; z \in {\mathbb C}^*\\ 0   & \mbox{for} \; z = \infty \end{array} \right. $$ But, It seems to me that $\phi_2$ cannot be biholomorphic at $\infty$, because since $\phi_2'(z)=-1/z^2$, $$ \lim_{z\rightarrow \infty} \phi_2'(z) = 0. $$ Could someone point out where I made a mistake ?",,"['complex-analysis', 'riemann-surfaces']"
37,Convergence of a recursive sequence $z_{n+1} = \frac{1}{2} ( z_n - \frac{1}{z_n}) $,Convergence of a recursive sequence,z_{n+1} = \frac{1}{2} ( z_n - \frac{1}{z_n}) ,"Let $p$ be a complex number. Let $ z_0 = p $ and, for $ n \geq 1 $, define $z_{n+1} = \frac{1}{2} ( z_n - \frac{1}{z_n}) $ if $z_n \neq 0 $. Prove the following: i) If $ \{ z_n \} $ converges to a limit $a$, then $a^2 + 1 = 0 $ ii) If $ p $ is real, then $ \{ z_n \} $, if defined, does not converge iii) If $ p = iq $, where $ q \in \mathbb{R} \backslash \{0\} $, then $ \{ z_n \} $ converges. I have been able to do the first two parts of this (the second is because the sequence would be real, but would have to have a complex limit). I am stuck on the third part, though. Any help would be greatly appreciated. Thanks","Let $p$ be a complex number. Let $ z_0 = p $ and, for $ n \geq 1 $, define $z_{n+1} = \frac{1}{2} ( z_n - \frac{1}{z_n}) $ if $z_n \neq 0 $. Prove the following: i) If $ \{ z_n \} $ converges to a limit $a$, then $a^2 + 1 = 0 $ ii) If $ p $ is real, then $ \{ z_n \} $, if defined, does not converge iii) If $ p = iq $, where $ q \in \mathbb{R} \backslash \{0\} $, then $ \{ z_n \} $ converges. I have been able to do the first two parts of this (the second is because the sequence would be real, but would have to have a complex limit). I am stuck on the third part, though. Any help would be greatly appreciated. Thanks",,['complex-analysis']
38,Roots of derivative of polynomial,Roots of derivative of polynomial,,Suppose f(z) is a polynomial such that its derivatives are non-zero for all $|z| <1$.   Is the restriction of $f$ to $|z|<1$ 1 to 1? I know that $f$ must be locally 1 to 1.   It is obvious that $f$ is 1-1 for polynomials of order 1.  The case of order 2 follows from Gauss-Lucas Thm. I am stuck on how to prove the general case.,Suppose f(z) is a polynomial such that its derivatives are non-zero for all $|z| <1$.   Is the restriction of $f$ to $|z|<1$ 1 to 1? I know that $f$ must be locally 1 to 1.   It is obvious that $f$ is 1-1 for polynomials of order 1.  The case of order 2 follows from Gauss-Lucas Thm. I am stuck on how to prove the general case.,,"['analysis', 'complex-analysis']"
39,Continuous complex function (2 variables),Continuous complex function (2 variables),,"Let $f$ be analytic on the open set $G\subset \mathbb{C}$. What's the best way of showing that the function $\phi:G \times G \to \mathbb{C}$ defined by $\phi(z,w)=[f(z)-f(w)]/(z-w)$ for $z \neq w$ and $\phi(z,z)=f'(z)$ is continuous? This is obvious for $z\neq w$, but I'm having some trouble on the points $(z,z)$. I did it one way but I'm not convinced this is good. Edit: Rudin's Proof (for the continuity on the diagonal) Let $z_0\in G$. Since $f$ is analytic, there exists $r>0$ such that $B(a,r)\subset G$ and $|f'(\zeta)-f'(z_0)|<\epsilon$ for all $\zeta \in B(a,r)$. Getting $z,w\in B(a,r)$, than $\zeta(t)=(1-t)z+tw \in B(a,r)$ for $0\le t\le 1$. Now just use that $\phi(z,w)-\phi(z_0,z_0)=\int_0^1[f'(\zeta(t))-f'(z_0)]dt$ and the $\epsilon$-bound to get the desired continuity.","Let $f$ be analytic on the open set $G\subset \mathbb{C}$. What's the best way of showing that the function $\phi:G \times G \to \mathbb{C}$ defined by $\phi(z,w)=[f(z)-f(w)]/(z-w)$ for $z \neq w$ and $\phi(z,z)=f'(z)$ is continuous? This is obvious for $z\neq w$, but I'm having some trouble on the points $(z,z)$. I did it one way but I'm not convinced this is good. Edit: Rudin's Proof (for the continuity on the diagonal) Let $z_0\in G$. Since $f$ is analytic, there exists $r>0$ such that $B(a,r)\subset G$ and $|f'(\zeta)-f'(z_0)|<\epsilon$ for all $\zeta \in B(a,r)$. Getting $z,w\in B(a,r)$, than $\zeta(t)=(1-t)z+tw \in B(a,r)$ for $0\le t\le 1$. Now just use that $\phi(z,w)-\phi(z_0,z_0)=\int_0^1[f'(\zeta(t))-f'(z_0)]dt$ and the $\epsilon$-bound to get the desired continuity.",,[]
40,Power series expansion without Cauchy theorem,Power series expansion without Cauchy theorem,,"How is the power series expansion of an analytic function at a point constructed, without using Cauchy's theorem (or formula)?","How is the power series expansion of an analytic function at a point constructed, without using Cauchy's theorem (or formula)?",,['complex-analysis']
41,Evaluate $\int_{-1}^{1} \frac{1}{(1+x^4)\sqrt{1-x^2}}dx$ using complex integration,Evaluate  using complex integration,\int_{-1}^{1} \frac{1}{(1+x^4)\sqrt{1-x^2}}dx,"Evaluate $$I=\int_{-1}^{1} \frac{1}{(1+x^4)\sqrt{1-x^2}}dx$$ by integrating along the following complex contour: When we take $R\rightarrow 1$ and $ε\rightarrow 0$ , the contour integral itself will be $2πi$ times the sum of the 4 residues of the function, which we can get easily enough using L'Hopital's rule, or factorising $1+x^4$ and so on. My real trouble comes when we consider the lower integral along the real line, $$\int_{1}^{-1} \frac{1}{(1+x^4)\sqrt{1-x^2}}=\int_{1}^{-1} \frac{1}{(1+x^4)\sqrt{1-xe^{2πi}}\sqrt{1+xe^{2πi}}}$$ Where I have included $e^{2πi}$ explicitly since it's the lower path. My intuition is telling me that this piece of the contour shouldn't just be the same as the piece above because of this $e^{2πi}$ inside the square root. Furthermore, if it were the exact same then the two pieces would cancel exactly... So how we can we separate out the 'effects' of this $e^{2πi}$ to get this piece in the form of constant * $I$ ?","Evaluate by integrating along the following complex contour: When we take and , the contour integral itself will be times the sum of the 4 residues of the function, which we can get easily enough using L'Hopital's rule, or factorising and so on. My real trouble comes when we consider the lower integral along the real line, Where I have included explicitly since it's the lower path. My intuition is telling me that this piece of the contour shouldn't just be the same as the piece above because of this inside the square root. Furthermore, if it were the exact same then the two pieces would cancel exactly... So how we can we separate out the 'effects' of this to get this piece in the form of constant * ?",I=\int_{-1}^{1} \frac{1}{(1+x^4)\sqrt{1-x^2}}dx R\rightarrow 1 ε\rightarrow 0 2πi 1+x^4 \int_{1}^{-1} \frac{1}{(1+x^4)\sqrt{1-x^2}}=\int_{1}^{-1} \frac{1}{(1+x^4)\sqrt{1-xe^{2πi}}\sqrt{1+xe^{2πi}}} e^{2πi} e^{2πi} e^{2πi} I,"['complex-analysis', 'contour-integration']"
42,How to solve $a \cdot x^{2} + b \cdot x + c + \exp\left( d \cdot x + e \right) = 0$ for $x$ where $x \in \mathbb{C} \cup \{ \hat{\infty} \}$?,How to solve  for  where ?,a \cdot x^{2} + b \cdot x + c + \exp\left( d \cdot x + e \right) = 0 x x \in \mathbb{C} \cup \{ \hat{\infty} \},"General Question: How to solve $a \cdot x^{2} + b \cdot x + c + \exp\left( d \cdot x + e \right) = 0$ for $x$ where $x \in \mathbb{C} \cup \left\{ \hat{\infty} \right\} \wedge \left\{ a,\, b,\, c,\, d,\, e \right\} \in \mathbb{C}$ (note: here $e$ is not euler's constant)? Backgrund: When I sometimes calculate with ODEs, I sometimes come across equations of this form. So I'm wondering what a general solution to this would look like? My Trys Since I've often encountered such equations, I've tried a few things accordingly. I'll just name the best (for non-trivial stuff): If $a = 0$ $$ \begin{align*} 0 \cdot x^{2} + b \cdot x + c + \exp\left( d \cdot x + e \right) &= 0\\ b \cdot x + c + \exp\left( d \cdot x + e \right) &= 0\\ \exp\left( d \cdot x + e \right) &= -c - x \cdot b\\ \end{align*} $$ $$ \begin{align*} -x \cdot b - c &= \exp\left( e - \frac{c \cdot d}{b} + x \cdot d + \frac{c \cdot d}{b} \right)\\ -x \cdot b - c &= \exp\left( e - \frac{c \cdot d}{b} + x \cdot d + \frac{c \cdot d}{b} \right)\\ -x \cdot b - c &= \exp\left( e - \frac{c \cdot d}{b} \right) \cdot \exp\left( x \cdot d + \frac{c \cdot d}{b} \right)\\ \end{align*} $$ $$ \begin{align*} -x \cdot b \cdot \exp\left( -x \cdot d - \frac{c \cdot d}{b} \right) - c \cdot \exp\left( -x \cdot d - \frac{c \cdot d}{b} \right) &= \exp\left( e - \frac{c \cdot d}{b} \right)\\ -x \cdot d \cdot \exp\left( -x \cdot d - \frac{c \cdot d}{b} \right) - \frac{c \cdot d}{b} \cdot \exp\left( -x \cdot d - \frac{c \cdot d}{b} \right) &= \frac{d}{b} \cdot \exp\left( e - \frac{c \cdot d}{b} \right)\\ \left( -x \cdot d - \frac{c \cdot d}{b} \right) \cdot \exp\left( -x \cdot d - \frac{c \cdot d}{b} \right) &= \frac{d}{b} \cdot \exp\left( e - \frac{c \cdot d}{b} \right)\\ \end{align*} $$ $$ \begin{align*} -x_{k} \cdot d - \frac{c \cdot d}{b} &= W_{k}\left( \frac{d}{b} \cdot \exp\left( e - \frac{c \cdot d}{b} \right) \right)\\ x_{k} + \frac{c}{b} &= -\frac{1}{d} \cdot W_{k}\left( \frac{d}{b} \cdot \exp\left( e - \frac{c \cdot d}{b} \right) \right)\\ x_{k} &= -\frac{1}{d} \cdot W_{k}\left( \frac{d}{b} \cdot \exp\left( e - \frac{c \cdot d}{b} \right) \right) - \frac{c}{b}\\ \end{align*} $$ $$\fbox{$x_{k} = -\frac{1}{d} \cdot W_{k}\left( \frac{d}{b} \cdot \exp\left( e - \frac{c \cdot d}{b} \right) \right) - \frac{c}{b}$}$$ Where $W_{k}$ is the Lambert W Function... If $a \ne 0$ Completing ... $$ \begin{align*} a \cdot x^{2} + b \cdot x + c + \exp\left( d \cdot x + e \right) &= 0\\ a \cdot x^{2} + b \cdot x + \exp\left( d \cdot x + e \right) &= -c\\ a \cdot x^{2} + b \cdot x + \frac{b^{2}}{4} + \exp\left( d \cdot x + e \right) &= -c + \frac{b^{2}}{4}\\ a \cdot x^{2} + b \cdot x + \frac{b^{2}}{4} + \exp\left( d \cdot x + e \right) &= -c + \frac{b^{2}}{4}\\ x^{2} + \frac{b}{a} \cdot x + \frac{b^{2}}{4 \cdot a^{2}} + \frac{1}{a} \cdot \exp\left( d \cdot x + e \right) &= -\frac{c}{a} + \frac{b^{2}}{4 \cdot a^{2}}\\ \left(x + \frac{b}{2 \cdot a} \right)^{2} + \frac{1}{a} \cdot \exp\left( d \cdot x + e \right) &= -\frac{c}{a} + \frac{b^{2}}{4 \cdot a^{2}}\\ \end{align*} $$ Fail: I can't think of anything useful to add. Substitution + Compliting ... $$ \begin{align*} \left(\underbrace{x + \frac{b}{2 \cdot a}}_{= u} \right)^{2} + \frac{1}{a} \cdot \exp\left( d \cdot x + e \right) &= -\frac{c}{a} + \frac{b^{2}}{4 \cdot a^{2}}\\ u^{2} + \frac{1}{a} \cdot \exp\left( d \cdot \left( u - \frac{b}{2 \cdot a} \right) + e \right) &= -\frac{c}{a} + \frac{b^{2}}{4 \cdot a^{2}}\\ u^{2} + \frac{1}{a} \cdot \exp\left( d \cdot u - \frac{d \cdot b}{2 \cdot a} + e \right) &= -\frac{c}{a} + \frac{b^{2}}{4 \cdot a^{2}}\\ \frac{1}{a} \cdot \exp\left( d \cdot u - \frac{d \cdot b}{2 \cdot a} + e \right) &= -\frac{c}{a} + \frac{b^{2}}{4 \cdot a^{2}} - u^{2}\\ \exp\left( d \cdot u - \frac{d \cdot b}{2 \cdot a} + e \right) &= -c + \frac{b^{2}}{4 \cdot a} - a \cdot u^{2}\\ \exp\left( d \cdot u + f - \frac{d \cdot b}{2 \cdot a} + e - f \right) &= -c + \frac{b^{2}}{4 \cdot a} -  a \cdot u^{2}\\ \exp\left( d \cdot u + f \right) \cdot \exp\left( -\frac{d \cdot b}{2 \cdot a} + e - f \right) &= -c + \frac{b^{2}}{4 \cdot a} -  a \cdot u^{2}\\ \exp\left( -\frac{d \cdot b}{2 \cdot a} + e - f \right) &= \left( -c + \frac{b^{2}}{4 \cdot a} -  a \cdot u^{2} \right) \cdot \exp\left( -d \cdot u - f \right)\\ \end{align*} $$ Fail: Nothing to simplify... Despair $$ \begin{align*} \exp\left( -\frac{d \cdot b}{2 \cdot a} + e - f \right) &= \left( -c + \frac{b^{2}}{4 \cdot a} -  a \cdot u^{2} \right) \cdot \exp\left( -d \cdot u - f \right)\\ -\frac{d \cdot b}{2 \cdot a} + e - f &= \ln\left( \left( -c + \frac{b^{2}}{4 \cdot a} -  a \cdot u^{2} \right) \cdot \exp\left( -d \cdot u - f \right) \right)\\ -\frac{d \cdot b}{2 \cdot a} + e - f &= \ln\left( -c + \frac{b^{2}}{4 \cdot a} -  a \cdot u^{2} \right) + \ln\left( \exp\left( -d \cdot u - f \right) \right)\\ -\frac{d \cdot b}{2 \cdot a} + e - f &= \ln\left( -c + \frac{b^{2}}{4 \cdot a} -  a \cdot u^{2} \right) - d \cdot u - f \\ \end{align*} $$ So there might be a solution in terms of Wright Lambert W functions...","General Question: How to solve for where (note: here is not euler's constant)? Backgrund: When I sometimes calculate with ODEs, I sometimes come across equations of this form. So I'm wondering what a general solution to this would look like? My Trys Since I've often encountered such equations, I've tried a few things accordingly. I'll just name the best (for non-trivial stuff): If Where is the Lambert W Function... If Completing ... Fail: I can't think of anything useful to add. Substitution + Compliting ... Fail: Nothing to simplify... Despair So there might be a solution in terms of Wright Lambert W functions...","a \cdot x^{2} + b \cdot x + c + \exp\left( d \cdot x + e \right) = 0 x x \in \mathbb{C} \cup \left\{ \hat{\infty} \right\} \wedge \left\{ a,\, b,\, c,\, d,\, e \right\} \in \mathbb{C} e a = 0 
\begin{align*}
0 \cdot x^{2} + b \cdot x + c + \exp\left( d \cdot x + e \right) &= 0\\
b \cdot x + c + \exp\left( d \cdot x + e \right) &= 0\\
\exp\left( d \cdot x + e \right) &= -c - x \cdot b\\
\end{align*}
 
\begin{align*}
-x \cdot b - c &= \exp\left( e - \frac{c \cdot d}{b} + x \cdot d + \frac{c \cdot d}{b} \right)\\
-x \cdot b - c &= \exp\left( e - \frac{c \cdot d}{b} + x \cdot d + \frac{c \cdot d}{b} \right)\\
-x \cdot b - c &= \exp\left( e - \frac{c \cdot d}{b} \right) \cdot \exp\left( x \cdot d + \frac{c \cdot d}{b} \right)\\
\end{align*}
 
\begin{align*}
-x \cdot b \cdot \exp\left( -x \cdot d - \frac{c \cdot d}{b} \right) - c \cdot \exp\left( -x \cdot d - \frac{c \cdot d}{b} \right) &= \exp\left( e - \frac{c \cdot d}{b} \right)\\
-x \cdot d \cdot \exp\left( -x \cdot d - \frac{c \cdot d}{b} \right) - \frac{c \cdot d}{b} \cdot \exp\left( -x \cdot d - \frac{c \cdot d}{b} \right) &= \frac{d}{b} \cdot \exp\left( e - \frac{c \cdot d}{b} \right)\\
\left( -x \cdot d - \frac{c \cdot d}{b} \right) \cdot \exp\left( -x \cdot d - \frac{c \cdot d}{b} \right) &= \frac{d}{b} \cdot \exp\left( e - \frac{c \cdot d}{b} \right)\\
\end{align*}
 
\begin{align*}
-x_{k} \cdot d - \frac{c \cdot d}{b} &= W_{k}\left( \frac{d}{b} \cdot \exp\left( e - \frac{c \cdot d}{b} \right) \right)\\
x_{k} + \frac{c}{b} &= -\frac{1}{d} \cdot W_{k}\left( \frac{d}{b} \cdot \exp\left( e - \frac{c \cdot d}{b} \right) \right)\\
x_{k} &= -\frac{1}{d} \cdot W_{k}\left( \frac{d}{b} \cdot \exp\left( e - \frac{c \cdot d}{b} \right) \right) - \frac{c}{b}\\
\end{align*}
 \fbox{x_{k} = -\frac{1}{d} \cdot W_{k}\left( \frac{d}{b} \cdot \exp\left( e - \frac{c \cdot d}{b} \right) \right) - \frac{c}{b}} W_{k} a \ne 0 
\begin{align*}
a \cdot x^{2} + b \cdot x + c + \exp\left( d \cdot x + e \right) &= 0\\
a \cdot x^{2} + b \cdot x + \exp\left( d \cdot x + e \right) &= -c\\
a \cdot x^{2} + b \cdot x + \frac{b^{2}}{4} + \exp\left( d \cdot x + e \right) &= -c + \frac{b^{2}}{4}\\
a \cdot x^{2} + b \cdot x + \frac{b^{2}}{4} + \exp\left( d \cdot x + e \right) &= -c + \frac{b^{2}}{4}\\
x^{2} + \frac{b}{a} \cdot x + \frac{b^{2}}{4 \cdot a^{2}} + \frac{1}{a} \cdot \exp\left( d \cdot x + e \right) &= -\frac{c}{a} + \frac{b^{2}}{4 \cdot a^{2}}\\
\left(x + \frac{b}{2 \cdot a} \right)^{2} + \frac{1}{a} \cdot \exp\left( d \cdot x + e \right) &= -\frac{c}{a} + \frac{b^{2}}{4 \cdot a^{2}}\\
\end{align*}
 
\begin{align*}
\left(\underbrace{x + \frac{b}{2 \cdot a}}_{= u} \right)^{2} + \frac{1}{a} \cdot \exp\left( d \cdot x + e \right) &= -\frac{c}{a} + \frac{b^{2}}{4 \cdot a^{2}}\\
u^{2} + \frac{1}{a} \cdot \exp\left( d \cdot \left( u - \frac{b}{2 \cdot a} \right) + e \right) &= -\frac{c}{a} + \frac{b^{2}}{4 \cdot a^{2}}\\
u^{2} + \frac{1}{a} \cdot \exp\left( d \cdot u - \frac{d \cdot b}{2 \cdot a} + e \right) &= -\frac{c}{a} + \frac{b^{2}}{4 \cdot a^{2}}\\
\frac{1}{a} \cdot \exp\left( d \cdot u - \frac{d \cdot b}{2 \cdot a} + e \right) &= -\frac{c}{a} + \frac{b^{2}}{4 \cdot a^{2}} - u^{2}\\
\exp\left( d \cdot u - \frac{d \cdot b}{2 \cdot a} + e \right) &= -c + \frac{b^{2}}{4 \cdot a} - a \cdot u^{2}\\
\exp\left( d \cdot u + f - \frac{d \cdot b}{2 \cdot a} + e - f \right) &= -c + \frac{b^{2}}{4 \cdot a} -  a \cdot u^{2}\\
\exp\left( d \cdot u + f \right) \cdot \exp\left( -\frac{d \cdot b}{2 \cdot a} + e - f \right) &= -c + \frac{b^{2}}{4 \cdot a} -  a \cdot u^{2}\\
\exp\left( -\frac{d \cdot b}{2 \cdot a} + e - f \right) &= \left( -c + \frac{b^{2}}{4 \cdot a} -  a \cdot u^{2} \right) \cdot \exp\left( -d \cdot u - f \right)\\
\end{align*}
 
\begin{align*}
\exp\left( -\frac{d \cdot b}{2 \cdot a} + e - f \right) &= \left( -c + \frac{b^{2}}{4 \cdot a} -  a \cdot u^{2} \right) \cdot \exp\left( -d \cdot u - f \right)\\
-\frac{d \cdot b}{2 \cdot a} + e - f &= \ln\left( \left( -c + \frac{b^{2}}{4 \cdot a} -  a \cdot u^{2} \right) \cdot \exp\left( -d \cdot u - f \right) \right)\\
-\frac{d \cdot b}{2 \cdot a} + e - f &= \ln\left( -c + \frac{b^{2}}{4 \cdot a} -  a \cdot u^{2} \right) + \ln\left( \exp\left( -d \cdot u - f \right) \right)\\
-\frac{d \cdot b}{2 \cdot a} + e - f &= \ln\left( -c + \frac{b^{2}}{4 \cdot a} -  a \cdot u^{2} \right) - d \cdot u - f \\
\end{align*}
","['complex-analysis', 'algebra-precalculus', 'complex-numbers', 'lambert-w']"
43,Complex analysis on how to find the proper function satisfying the condition,Complex analysis on how to find the proper function satisfying the condition,,"$f$ and $g$ are both holomorphic in $\Bbb{C}$ , and for every $z$ in $\Bbb{C}$ , $$f(z)^2+g(z)^2=1$$ please help me prove there is a $h(z)$ which is holomorphic in $\Bbb{C}$ , such that $f(z)=\cos(h(z)), g(z)=\sin(h(z))$ . I try to suppose the conclusion is wrong, but I failed to find any contradiction here.","and are both holomorphic in , and for every in , please help me prove there is a which is holomorphic in , such that . I try to suppose the conclusion is wrong, but I failed to find any contradiction here.","f g \Bbb{C} z \Bbb{C} f(z)^2+g(z)^2=1 h(z) \Bbb{C} f(z)=\cos(h(z)), g(z)=\sin(h(z))",['complex-analysis']
44,Graphically showing $\operatorname{Re}\left(\frac{1+z}{1-z}\right) = 0$ for $z=\cos\theta+i\sin\theta\neq 1$,Graphically showing  for,\operatorname{Re}\left(\frac{1+z}{1-z}\right) = 0 z=\cos\theta+i\sin\theta\neq 1,"The given complex number is $z = \cos\theta + i\sin\theta$ , where $z$ is not $1$ I have to show that $$\operatorname{Re}\left(\frac{1+z}{1-z}\right) = 0$$ Algebraically, I have managed to do that using trigonometry and Euler's equation. But I can't succeed to imagine it on an Argand diagram using basic angle rules, without solving anything. In this case division, so angle subtraction. The angle should either be $90^\circ$ or $270^\circ$ since it should end up only on the complex part, I tried drawing it on the whiteboard but perhaps I am doing something wrong since I cannot get it to add up. Conceptually this is right.","The given complex number is , where is not I have to show that Algebraically, I have managed to do that using trigonometry and Euler's equation. But I can't succeed to imagine it on an Argand diagram using basic angle rules, without solving anything. In this case division, so angle subtraction. The angle should either be or since it should end up only on the complex part, I tried drawing it on the whiteboard but perhaps I am doing something wrong since I cannot get it to add up. Conceptually this is right.",z = \cos\theta + i\sin\theta z 1 \operatorname{Re}\left(\frac{1+z}{1-z}\right) = 0 90^\circ 270^\circ,"['complex-analysis', 'complex-numbers', 'polar-coordinates']"
45,Confusion with the Fourier Transform and Complex Differentiability: example with compact-supported function,Confusion with the Fourier Transform and Complex Differentiability: example with compact-supported function,,"I have a misconception when applying the Fourier Transform to a compacted-supported function and the characteristics of the function obtained. Intro I am going to list what I believe is true so you can identify were I am making my conceptual mistake: The Fourier Transform of a square-integrable function which is compact-supported in the real line must be an entire analytic function due the Paley–Wiener theorem . An entire function is a complex-valued function that is holomorphic on the whole complex plane, so it is complex differentiable everywhere, so it is satisfying being Analytic , infinitely differentiable or Smooth , and its real-imaginary decomposition constituents fulfill the Cauchy–Riemann equations . If a function $g(z)$ is complex differentiable with the complex variable being described as $z=\sigma+iw$ so the function could be expressed as: $g(\sigma+iw)=u(\sigma,w)+iv(\sigma,w)$ with $u,\,v$ real-valued functions, then each constituents fulfill the Cauchy–Riemann equations as mentioned, which imply that each constituent function is individually an Harmonic function so both functions $u,\,v$ fulfill $\nabla^2 u = \frac{\partial^2 u}{\partial \sigma^2}+\frac{\partial^2 u}{\partial w^2}=0$ and $\nabla^2 v = \frac{\partial^2 v}{\partial \sigma^2}+\frac{\partial^2 v}{\partial w^2}=0$ . The Fourier Transform $\hat{f}(iw)$ of an ""even function"" $f(t)=f(-t)$ is a real-valued function $\hat{f}(iw)\in \mathbb{R}$ . The Fourier Transform $\hat{f}(iw)$ of an real valued function $f(t)$ fulfill that $\hat{f}(iw)^* = \hat{f}(-iw)$ is an Hermitian function . I am using the electrician notation for the Fourier transform using the angular frequency including the imaginary unit as part of the variable. Main text With this, I am going to use the following example to present the problem: $$f(t) = \left(\frac{1-t^2+|1-t^2|}{2}\right)^4 \tag{Eq. 1}\label{Eq. 1}$$ which is ploted here fulfilling is a real-valued function supported on the real line, but different from zero only in $t \in [-1,\,1]$ so it has compact-support. Also it can be seen is an ""even function"" due $(-t)^2 \equiv t^2$ for real-valued $t$ , and it is also square-integrable since $\int\limits_{-\infty}^{\infty}\left|\left(\frac{1-t^2+|1-t^2|}{2}\right)^4\right|^2 dt = \frac{65536}{109395}\approx 0.6 \ll \infty$ . So the function should be fulfilling all the $5$ points of the introduction. As it can be seen here , the Fourier Transform of $f(t)$ of \eqref{Eq. 1} could been described using the Bessel function of First kind $J_{\nu}(w)$ and the Gamma function $\Gamma(w)$ as: $$ \begin{array}{r c l} \hat{f}(iw) = \int\limits_{-\infty}^{\infty} f(t)\ e^{-iwt}dt & = & \text{sgn}(w)\sqrt{\pi}\left(\frac{2}{w}\right)^{4+\frac{1}{2}}\Gamma(4+1)J_{4+\frac{1}{2}}(w)\\ & = & 24\sqrt{\pi}\,\text{sgn}(w)\left(\frac{2}{w}\right)^{\frac{9}{2}}J_{\frac{9}{2}}(w) \tag{Eq. 2}\label{Eq. 2} \end{array}$$ Since this Fourier Transform $\hat{f}(iw)$ should be holomorphic, but is a real-valued function, I am confused how it is verified is being complex differentiable: How is analyzed a real-valued function for complex differentiability? Since the Fourier Transform $\hat{f}(iw) = \hat{f}(\{\sigma\equiv 0\}+iw)$ it will imply that $u(\sigma,w) = 24\sqrt{\pi}\,\text{sgn}(w)\left(\frac{2}{w}\right)^{\frac{9}{2}}J_{\frac{9}{2}}(w)$ and $v(\sigma,w)=0$ : naturally the trivial solution zero function will fulfill $\nabla^2 v = 0$ , but for reviewing $u(\sigma,w)$ I don´t know how to take the derivative respect to $\sigma$ since it is zero , neither I have a function related to $\sigma$ to make some manipulation. Even so, if I take $\frac{\partial^2}{\partial w^2}u(\sigma,w) \neq 0$ is definitely not zero as it can be seen here , so if the Fourier Transform is complex differentiable as is stated on the initial points, surely must be $\sigma$ -related component that is missing. Surely I am having a conceptual mistake, but I cannot figure it out so far. Hope you could explain what I am doing wrong, displaying which functions are going to be $u(\sigma,w)$ and $v(\sigma,w)$ for the Fourier Transform of \eqref{Eq. 2} showing in detail how is proved is complex differentiable. Beforehand, thanks you very much.","I have a misconception when applying the Fourier Transform to a compacted-supported function and the characteristics of the function obtained. Intro I am going to list what I believe is true so you can identify were I am making my conceptual mistake: The Fourier Transform of a square-integrable function which is compact-supported in the real line must be an entire analytic function due the Paley–Wiener theorem . An entire function is a complex-valued function that is holomorphic on the whole complex plane, so it is complex differentiable everywhere, so it is satisfying being Analytic , infinitely differentiable or Smooth , and its real-imaginary decomposition constituents fulfill the Cauchy–Riemann equations . If a function is complex differentiable with the complex variable being described as so the function could be expressed as: with real-valued functions, then each constituents fulfill the Cauchy–Riemann equations as mentioned, which imply that each constituent function is individually an Harmonic function so both functions fulfill and . The Fourier Transform of an ""even function"" is a real-valued function . The Fourier Transform of an real valued function fulfill that is an Hermitian function . I am using the electrician notation for the Fourier transform using the angular frequency including the imaginary unit as part of the variable. Main text With this, I am going to use the following example to present the problem: which is ploted here fulfilling is a real-valued function supported on the real line, but different from zero only in so it has compact-support. Also it can be seen is an ""even function"" due for real-valued , and it is also square-integrable since . So the function should be fulfilling all the points of the introduction. As it can be seen here , the Fourier Transform of of \eqref{Eq. 1} could been described using the Bessel function of First kind and the Gamma function as: Since this Fourier Transform should be holomorphic, but is a real-valued function, I am confused how it is verified is being complex differentiable: How is analyzed a real-valued function for complex differentiability? Since the Fourier Transform it will imply that and : naturally the trivial solution zero function will fulfill , but for reviewing I don´t know how to take the derivative respect to since it is zero , neither I have a function related to to make some manipulation. Even so, if I take is definitely not zero as it can be seen here , so if the Fourier Transform is complex differentiable as is stated on the initial points, surely must be -related component that is missing. Surely I am having a conceptual mistake, but I cannot figure it out so far. Hope you could explain what I am doing wrong, displaying which functions are going to be and for the Fourier Transform of \eqref{Eq. 2} showing in detail how is proved is complex differentiable. Beforehand, thanks you very much.","g(z) z=\sigma+iw g(\sigma+iw)=u(\sigma,w)+iv(\sigma,w) u,\,v u,\,v \nabla^2 u = \frac{\partial^2 u}{\partial \sigma^2}+\frac{\partial^2 u}{\partial w^2}=0 \nabla^2 v = \frac{\partial^2 v}{\partial \sigma^2}+\frac{\partial^2 v}{\partial w^2}=0 \hat{f}(iw) f(t)=f(-t) \hat{f}(iw)\in \mathbb{R} \hat{f}(iw) f(t) \hat{f}(iw)^* = \hat{f}(-iw) f(t) = \left(\frac{1-t^2+|1-t^2|}{2}\right)^4 \tag{Eq. 1}\label{Eq. 1} t \in [-1,\,1] (-t)^2 \equiv t^2 t \int\limits_{-\infty}^{\infty}\left|\left(\frac{1-t^2+|1-t^2|}{2}\right)^4\right|^2 dt = \frac{65536}{109395}\approx 0.6 \ll \infty 5 f(t) J_{\nu}(w) \Gamma(w)  \begin{array}{r c l}
\hat{f}(iw) = \int\limits_{-\infty}^{\infty} f(t)\ e^{-iwt}dt & = & \text{sgn}(w)\sqrt{\pi}\left(\frac{2}{w}\right)^{4+\frac{1}{2}}\Gamma(4+1)J_{4+\frac{1}{2}}(w)\\
& = & 24\sqrt{\pi}\,\text{sgn}(w)\left(\frac{2}{w}\right)^{\frac{9}{2}}J_{\frac{9}{2}}(w) \tag{Eq. 2}\label{Eq. 2}
\end{array} \hat{f}(iw) \hat{f}(iw) = \hat{f}(\{\sigma\equiv 0\}+iw) u(\sigma,w) = 24\sqrt{\pi}\,\text{sgn}(w)\left(\frac{2}{w}\right)^{\frac{9}{2}}J_{\frac{9}{2}}(w) v(\sigma,w)=0 \nabla^2 v = 0 u(\sigma,w) \sigma \sigma \frac{\partial^2}{\partial w^2}u(\sigma,w) \neq 0 \sigma u(\sigma,w) v(\sigma,w)","['complex-analysis', 'derivatives', 'fourier-analysis', 'fourier-transform', 'finite-duration']"
46,"If the roots of unity lie on a circle, do arbitrary polynomial roots also lie on some kind of characteristic curve?","If the roots of unity lie on a circle, do arbitrary polynomial roots also lie on some kind of characteristic curve?",,"I've been learning about roots of unity and how they manifest on the complex plane. I understand that if you take $z^{n}=1$ , then the values of $z$ that satisfy this equation happen to lie on the unit circle with equal angles $\frac{2\pi}{n}$ between them. I tried a couple examples on Wolfram Alpha, here's z^5 = 1 and z^12 = 1 . But I was wondering if a similar strategy could be used for arbitrary complex polynomials, so I decided to tweak the inputs to have more terms. For example, here's z^5 + z^3 = 1 and z^5 - z^3 + z = 1 . The complex plane representations generated by Wolfram Alpha seem to suggest that the solutions might lie on an ellipse instead of a pure circle, or maybe some other characteristic curve. Is this the case?","I've been learning about roots of unity and how they manifest on the complex plane. I understand that if you take , then the values of that satisfy this equation happen to lie on the unit circle with equal angles between them. I tried a couple examples on Wolfram Alpha, here's z^5 = 1 and z^12 = 1 . But I was wondering if a similar strategy could be used for arbitrary complex polynomials, so I decided to tweak the inputs to have more terms. For example, here's z^5 + z^3 = 1 and z^5 - z^3 + z = 1 . The complex plane representations generated by Wolfram Alpha seem to suggest that the solutions might lie on an ellipse instead of a pure circle, or maybe some other characteristic curve. Is this the case?",z^{n}=1 z \frac{2\pi}{n},"['complex-analysis', 'polynomials', 'complex-numbers', 'soft-question']"
47,Prove that $0$ is not an essential singularity (UW Madison Qualifying exam),Prove that  is not an essential singularity (UW Madison Qualifying exam),0,"I'm trying to do this old qualifying exam problem from UW Madison. Let $D^\ast=\{z\in\mathbb{C},0<|z|<1\}$ and $f$ be a non constant holomorphic function on $D^\ast$ . Assume that $\text{Im} f(z)\geq 0$ if $\text{Im} z\geq 0$ and $\text{Im} f(z)\leq 0$ if $\text{Im} z\leq 0$ . Prove that if $z\in D^\ast$ is not real, then $f(z)$ is not real. Show that if $z\in (-1,0)\cup(0,1)$ , then $f'(z)\not=0$ . Prove that $0$ is either a removable singularity with $f'(0)\not=0$ or $0$ is a simple pole of $f$ . What I have thought of so far: If $z\in D^\ast$ and $\text{Im} z>0$ , but $\text{Im} f(z)=0$ , then apply the maximum modulus principle on $\{z|z\in D^\ast,\text{Im} z>0\}$ to $e^{if}$ to obtain a contradiction. This shows that if $z\in D^\ast$ and $\text{Im} z>0$ , then $\text{Im} f(z)>0$ . Similarly if $z\in D^\ast$ and $\text{Im} z<0$ . Furthermore, the reflection principle shows that $f(\overline{z})=\overline{f(z)}$ . If $z\in(-1,0)\cup(1,0)$ , to show that $f'(z)\not=0$ , we use the following fact: fact: If $f$ is a complex valued function continuous on $\overline{D(0,R)}$ and holomorphic on $D(0,R)$ , then for any $z\in D(0,R)$ , we have $$f(z)=\int_0^{2\pi}i \text{Im} f(\xi)\frac{\xi+z}{\xi-z}\frac{d\theta}{2\pi}+K$$ for some constant $K$ , where $\xi=Re^{i\theta}$ . We can differentiate the expression to get an expression of $f'(z)$ in terms of $\text{Im} f$ . This same fact shows that $f'(0)\not=0$ if $0$ is a removable singularity. If $0$ is a pole, $\text{Im} z$ is dominated by the imaginary part of $\frac{C}{z^n}$ for some $n\in\mathbb{Z}^+$ and $C\in\mathbb{R}$ when $|z|>0$ is small, then unless $n\not=1$ , we can find some $z\in D^\ast$ , $\text{Im} z>0$ such that $\text{Im} f(z)<0$ . So if $0$ is a pole, then it is a simple pole. My question is: how to show that $0$ is not an essential singularity? Thanks!!","I'm trying to do this old qualifying exam problem from UW Madison. Let and be a non constant holomorphic function on . Assume that if and if . Prove that if is not real, then is not real. Show that if , then . Prove that is either a removable singularity with or is a simple pole of . What I have thought of so far: If and , but , then apply the maximum modulus principle on to to obtain a contradiction. This shows that if and , then . Similarly if and . Furthermore, the reflection principle shows that . If , to show that , we use the following fact: fact: If is a complex valued function continuous on and holomorphic on , then for any , we have for some constant , where . We can differentiate the expression to get an expression of in terms of . This same fact shows that if is a removable singularity. If is a pole, is dominated by the imaginary part of for some and when is small, then unless , we can find some , such that . So if is a pole, then it is a simple pole. My question is: how to show that is not an essential singularity? Thanks!!","D^\ast=\{z\in\mathbb{C},0<|z|<1\} f D^\ast \text{Im} f(z)\geq 0 \text{Im} z\geq 0 \text{Im} f(z)\leq 0 \text{Im} z\leq 0 z\in D^\ast f(z) z\in (-1,0)\cup(0,1) f'(z)\not=0 0 f'(0)\not=0 0 f z\in D^\ast \text{Im} z>0 \text{Im} f(z)=0 \{z|z\in D^\ast,\text{Im} z>0\} e^{if} z\in D^\ast \text{Im} z>0 \text{Im} f(z)>0 z\in D^\ast \text{Im} z<0 f(\overline{z})=\overline{f(z)} z\in(-1,0)\cup(1,0) f'(z)\not=0 f \overline{D(0,R)} D(0,R) z\in D(0,R) f(z)=\int_0^{2\pi}i \text{Im} f(\xi)\frac{\xi+z}{\xi-z}\frac{d\theta}{2\pi}+K K \xi=Re^{i\theta} f'(z) \text{Im} f f'(0)\not=0 0 0 \text{Im} z \frac{C}{z^n} n\in\mathbb{Z}^+ C\in\mathbb{R} |z|>0 n\not=1 z\in D^\ast \text{Im} z>0 \text{Im} f(z)<0 0 0",['complex-analysis']
48,Questionable Proof in Visual Complex Analysis [duplicate],Questionable Proof in Visual Complex Analysis [duplicate],,"This question already has answers here : Uniqueness of Powerseries in an arbitrarily small neighborhood of $0$ in $\mathbb C$ (3 answers) Closed 4 years ago . I am currently reading the book ""Visual Complex Analysis"". It's a great book so far, but already in the beginning the proof of the identity theorem seems dubious. I mean, it's known from high-school algebra, that you're not allowed to divide by z if you set z = 0. Isn't this proof completely wrong? Some friends I've asked even told me that this theorem is wrong in the reals, so wouldn't a correct proof have to use properties of the complex numbers? Is it even possible to prove this with elementary methods? I've seen proofs that use properties of holomorphic functions but haven't gotten that far in my book yet, so I have no experience with holomorphic functions.","This question already has answers here : Uniqueness of Powerseries in an arbitrarily small neighborhood of $0$ in $\mathbb C$ (3 answers) Closed 4 years ago . I am currently reading the book ""Visual Complex Analysis"". It's a great book so far, but already in the beginning the proof of the identity theorem seems dubious. I mean, it's known from high-school algebra, that you're not allowed to divide by z if you set z = 0. Isn't this proof completely wrong? Some friends I've asked even told me that this theorem is wrong in the reals, so wouldn't a correct proof have to use properties of the complex numbers? Is it even possible to prove this with elementary methods? I've seen proofs that use properties of holomorphic functions but haven't gotten that far in my book yet, so I have no experience with holomorphic functions.",,"['complex-analysis', 'solution-verification', 'alternative-proof']"
49,Are two analytic functions equal if they are equal on the boundary of an open disk?,Are two analytic functions equal if they are equal on the boundary of an open disk?,,"Let $D$ be the open disk in $\mathbb{C}$ with origin $0$ and radius $1$ . Let $f,g: \overline{D} \to \mathbb{C}$ be continuous functions such that $f$ and $g$ are analytic on $D$ and such that $f=g$ on $S^1= \{z \in \mathbb{C}: |z| = 1\}$ . Can I conclude that $f=g$ on $D$ as well? It is enough to show that $\{z\in D: f(z) = g(z)\}$ has a limit point in $D$ but I can't see why this should hold.",Let be the open disk in with origin and radius . Let be continuous functions such that and are analytic on and such that on . Can I conclude that on as well? It is enough to show that has a limit point in but I can't see why this should hold.,"D \mathbb{C} 0 1 f,g: \overline{D} \to \mathbb{C} f g D f=g S^1= \{z \in \mathbb{C}: |z| = 1\} f=g D \{z\in D: f(z) = g(z)\} D",['complex-analysis']
50,Automorphism in complex analysis,Automorphism in complex analysis,,"Just a quick question about naming: in complex analysis, it appears to me that an ""Automorphism"" of $\Omega\subseteq \mathbb C$ means a conformal mapping from a subset $\Omega$ to itself. So, an automorphism doesn't necessarily preserve the group structure of $\mathbb C$ However, in group theory, ""automorphisms"" should be isomorphisms. Why the same word mean such two different things? NOTE Someone appears to say that this is a duplicate question, so let me make it more clear: My question is, does the word ""automorphisms"" mean means completely different things in group theory and complex analysis? Or actually they mean similar things? That question does not mention groups at all.","Just a quick question about naming: in complex analysis, it appears to me that an ""Automorphism"" of means a conformal mapping from a subset to itself. So, an automorphism doesn't necessarily preserve the group structure of However, in group theory, ""automorphisms"" should be isomorphisms. Why the same word mean such two different things? NOTE Someone appears to say that this is a duplicate question, so let me make it more clear: My question is, does the word ""automorphisms"" mean means completely different things in group theory and complex analysis? Or actually they mean similar things? That question does not mention groups at all.",\Omega\subseteq \mathbb C \Omega \mathbb C,"['complex-analysis', 'group-theory', 'notation']"
51,$\sum_{n=-\infty}^{\infty}\frac{1}{(u +n)^2}=\frac{\pi^2}{(\sin \pi u)^2}$,,\sum_{n=-\infty}^{\infty}\frac{1}{(u +n)^2}=\frac{\pi^2}{(\sin \pi u)^2},"I've already see a proof by Marko Riedel which I list it follows: The standard way to treat these sums is to integrate $$ f(z) = \frac{1}{(z+\alpha)^2} \pi \cot(\pi z)$$ along a contour consisting of a circle of radius $R$ and with $R$ going to infinity and hence being larger than $\alpha$ , where the circle does not pass through the poles on the real axis.   Now along the semicircle in the upper half plane we have $$|f(z)| \le \frac{1}{(R-|\alpha|)^2}\pi \left|\frac{e^{i\pi R\exp(i\theta)} + e^{-i\pi R\exp(i\theta)}} {e^{i\pi R\exp(i\theta)} - e^{-i\pi R\exp(i\theta)}}\right|= \frac{1}{(R-|\alpha|)^2} \pi  \left|\frac{e^{2i\pi R\exp(i\theta)}+1}{e^{2i\pi R\exp(i\theta)}-1}\right| < \frac{1}{(R-|\alpha|)^2} \pi   \frac{1+e^{-2\pi R\sin(\theta)}e^{2i\pi R\cos(\theta)}} {1-e^{-2\pi R\sin(\theta)}e^{2i\pi R\cos(\theta)}}$$ This last term is clearly $O(1/R^2)$ as $R$ goes to infinity as the quotient of the two exponentials goes to one since $\exp(-R)$ vanishes and there is no singularity when $\theta = 0$ or $\theta = \pi$ as $R\cos\theta = \pm R$ , which is not an integer by the assumption that the circle avoids the poles and hence cannot be one. My question: It is clear that for each $z=Re^{i \theta}$ , $f(z)=O(1/R^2)$ ，but can this guarantee that the last term on RHS is uniform bounded ? Since $\theta$ varies on a compact interval $[0, \pi]$ , I want to show that for each $ \theta \in [0, \pi]$ , and a fixed positive number $M \gt 1 $ there exist an open ball contains $\theta$ and a fixed $R_{\theta}\gt 0$ , for every $R \ge R_{\theta}$ and $x \in $ the open ball $$\frac{1+e^{-2\pi R\sin(x)}e^{2i\pi R\cos(x)}} {1-e^{-2\pi R\sin(x)}e^{2i\pi R\cos(x)}} \le M$$ For $\theta \neq 0,\pi$ , it is easy to find the desired $R_{\theta}$ and the open ball , but if $\theta = 0$ or $ \theta = \pi$ , for every open ball containing $\theta$ , it behave erratically near $\theta$ , I have no idea how to deal with this .","I've already see a proof by Marko Riedel which I list it follows: The standard way to treat these sums is to integrate along a contour consisting of a circle of radius and with going to infinity and hence being larger than , where the circle does not pass through the poles on the real axis.   Now along the semicircle in the upper half plane we have This last term is clearly as goes to infinity as the quotient of the two exponentials goes to one since vanishes and there is no singularity when or as , which is not an integer by the assumption that the circle avoids the poles and hence cannot be one. My question: It is clear that for each , ，but can this guarantee that the last term on RHS is uniform bounded ? Since varies on a compact interval , I want to show that for each , and a fixed positive number there exist an open ball contains and a fixed , for every and the open ball For , it is easy to find the desired and the open ball , but if or , for every open ball containing , it behave erratically near , I have no idea how to deal with this ."," f(z) = \frac{1}{(z+\alpha)^2} \pi \cot(\pi z) R R \alpha |f(z)| \le \frac{1}{(R-|\alpha|)^2}\pi
\left|\frac{e^{i\pi R\exp(i\theta)} + e^{-i\pi R\exp(i\theta)}}
{e^{i\pi R\exp(i\theta)} - e^{-i\pi R\exp(i\theta)}}\right|=
\frac{1}{(R-|\alpha|)^2} \pi 
\left|\frac{e^{2i\pi R\exp(i\theta)}+1}{e^{2i\pi R\exp(i\theta)}-1}\right| <
\frac{1}{(R-|\alpha|)^2} \pi  
\frac{1+e^{-2\pi R\sin(\theta)}e^{2i\pi R\cos(\theta)}}
{1-e^{-2\pi R\sin(\theta)}e^{2i\pi R\cos(\theta)}} O(1/R^2) R \exp(-R) \theta = 0 \theta = \pi R\cos\theta = \pm R z=Re^{i \theta} f(z)=O(1/R^2) \theta [0, \pi]  \theta \in [0, \pi] M \gt 1  \theta R_{\theta}\gt 0 R \ge R_{\theta} x \in  \frac{1+e^{-2\pi R\sin(x)}e^{2i\pi R\cos(x)}}
{1-e^{-2\pi R\sin(x)}e^{2i\pi R\cos(x)}} \le M \theta \neq 0,\pi R_{\theta} \theta = 0  \theta = \pi \theta \theta",['complex-analysis']
52,Is there a canonical extension of Euler's totient function to the reals?,Is there a canonical extension of Euler's totient function to the reals?,,"Assumption: if a set $X\times Y$ , exists such that $\forall\textbf{u},\textbf{v}\in X\times Y. \left(u_1=v_1\implies u_2=v_2\right)$ , then a function $f$ exists such that $f:X\to Y$ . The set of points $\Phi_\mathbb{N}=\left\{(n,\phi(n))\mid n\in\mathbb{N}\right\}$ describing the graph/image of the totient function is a subset of the reals. By definition, $\forall \textbf{x},\textbf{y}\in\mathbb{R}^2$ , where $x_1< y_1.\exists \textbf{z}\in\mathbb{R}^2:x_1<z_1<y_1$ . Thus, there is a continuous set of points between any two $\textbf{a},\textbf{b}\in\Phi_\mathbb{N}$ . It follows, that there is a a set $\Phi_\mathbb{R}\supset\Phi_\mathbb{N}$ which is the graph of a continuous function $\phi:\mathbb{R}\to\mathbb{R}$ , ( $n\in\mathbb{N}\implies \phi(n)\in\mathbb{N}$ ). Thus, it is at least possible to extend the totient function to the reals without breaking the original definition. Is there a canonical way to do this? If not, what is the most appropriate way to extend the totient function? Note: An extension to the complex numbers is perfectly acceptable too, I just assumed it would be best to ""keep it real"". Note: tagged analysis because that's where I'm going with this. Edit: This might help... probably not, though For coprime $a$ and $n$ $$a^{\phi(n)}\equiv1\mod{n}\qquad\text{(Euler's Theorem)}$$ For $x,y\in\mathbb{R}$ $$x\ \text{mod}\ y^{*}=\frac{|x|}{2\pi}\sum_{k=1}^\infty\frac{1}{k}\Im\left[\exp\left(\frac{2\pi kix}{y}\right)\right]$$ So $$a^{\phi(n)}\ \text{mod}\ n=\frac{|a^{\phi(n)}|}{2\pi}\sum_{k=1}^\infty\frac{1}{k}\Im\left[\exp\left(\frac{2\pi kia^{\phi(n)}}{n}\right)\right]=1\implies$$ $$|a^{\phi(n)}|=2\pi\left(\sum_{k=1}^\infty\frac{1}{k}\Im\left[\exp\left(\frac{2\pi kia^{\phi(n)}}{n}\right)\right]\right)^{-1}=$$ $$-4\pi i\left(\ln\left(1-\exp\left(\frac{2\pi ia^{\phi(n)}}{n}\right)\right)-\ln\left(\exp\left(-\frac{2\pi ia^{\phi(n)}}{n}\right)\left(-1+\exp\left(\frac{2\pi ia^{\phi(n)}}{n}\right)\right)\right)\right)^{-1}$$ Assuming $a^{\phi(n)}$ is positive, let $a^\phi(n)=u$ (because I'm running out of space) $$u=-4\pi i\left(\ln\left(1-\exp\left(\frac{2\pi iu}{n}\right)\right)-\ln\left(\exp\left(-\frac{2\pi iu}{n}\right)\left(-1+\exp\left(\frac{2\pi iu}{n}\right)\right)\right)\right)^{-1}$$ Solve for for $u$ (not sure how), then substitute $a^{\phi(n)}$ back in and take the base- $a$ logarithm to get $\phi(n)$ Assuming all the algebra is correct, this might work... $^*$ If I understand correctly, we can translate $x\equiv z\mod{y}$ to $x\ \text{mod}\ y=z$ , using $\text{mod}$ as a binary operation.","Assumption: if a set , exists such that , then a function exists such that . The set of points describing the graph/image of the totient function is a subset of the reals. By definition, , where . Thus, there is a continuous set of points between any two . It follows, that there is a a set which is the graph of a continuous function , ( ). Thus, it is at least possible to extend the totient function to the reals without breaking the original definition. Is there a canonical way to do this? If not, what is the most appropriate way to extend the totient function? Note: An extension to the complex numbers is perfectly acceptable too, I just assumed it would be best to ""keep it real"". Note: tagged analysis because that's where I'm going with this. Edit: This might help... probably not, though For coprime and For So Assuming is positive, let (because I'm running out of space) Solve for for (not sure how), then substitute back in and take the base- logarithm to get Assuming all the algebra is correct, this might work... If I understand correctly, we can translate to , using as a binary operation.","X\times Y \forall\textbf{u},\textbf{v}\in X\times Y. \left(u_1=v_1\implies u_2=v_2\right) f f:X\to Y \Phi_\mathbb{N}=\left\{(n,\phi(n))\mid n\in\mathbb{N}\right\} \forall \textbf{x},\textbf{y}\in\mathbb{R}^2 x_1< y_1.\exists \textbf{z}\in\mathbb{R}^2:x_1<z_1<y_1 \textbf{a},\textbf{b}\in\Phi_\mathbb{N} \Phi_\mathbb{R}\supset\Phi_\mathbb{N} \phi:\mathbb{R}\to\mathbb{R} n\in\mathbb{N}\implies \phi(n)\in\mathbb{N} a n a^{\phi(n)}\equiv1\mod{n}\qquad\text{(Euler's Theorem)} x,y\in\mathbb{R} x\ \text{mod}\ y^{*}=\frac{|x|}{2\pi}\sum_{k=1}^\infty\frac{1}{k}\Im\left[\exp\left(\frac{2\pi kix}{y}\right)\right] a^{\phi(n)}\ \text{mod}\ n=\frac{|a^{\phi(n)}|}{2\pi}\sum_{k=1}^\infty\frac{1}{k}\Im\left[\exp\left(\frac{2\pi kia^{\phi(n)}}{n}\right)\right]=1\implies |a^{\phi(n)}|=2\pi\left(\sum_{k=1}^\infty\frac{1}{k}\Im\left[\exp\left(\frac{2\pi kia^{\phi(n)}}{n}\right)\right]\right)^{-1}= -4\pi i\left(\ln\left(1-\exp\left(\frac{2\pi ia^{\phi(n)}}{n}\right)\right)-\ln\left(\exp\left(-\frac{2\pi ia^{\phi(n)}}{n}\right)\left(-1+\exp\left(\frac{2\pi ia^{\phi(n)}}{n}\right)\right)\right)\right)^{-1} a^{\phi(n)} a^\phi(n)=u u=-4\pi i\left(\ln\left(1-\exp\left(\frac{2\pi iu}{n}\right)\right)-\ln\left(\exp\left(-\frac{2\pi iu}{n}\right)\left(-1+\exp\left(\frac{2\pi iu}{n}\right)\right)\right)\right)^{-1} u a^{\phi(n)} a \phi(n) ^* x\equiv z\mod{y} x\ \text{mod}\ y=z \text{mod}","['real-analysis', 'complex-analysis', 'number-theory', 'totient-function']"
53,There is no holomorphic function $f$ on the open unit disk such that $f(1/n)=2^{-n}$,There is no holomorphic function  on the open unit disk such that,f f(1/n)=2^{-n},"Prove that there is no holomorphic function $f$ on the open unit disk such that $f(1/n)=2^{-n}$ for $n=2,3,..$ I know a similar question was asked on this website before but this is different. I define $g(z)=2^{-\frac{1}{z}}$, Can I use this function and identity theorem to show that $f=g$ on the disk. But $g$ is not analytic at $z=0$, so we get a contradiction? Is there a loophole in my argument. Edited the definition of function $g$","Prove that there is no holomorphic function $f$ on the open unit disk such that $f(1/n)=2^{-n}$ for $n=2,3,..$ I know a similar question was asked on this website before but this is different. I define $g(z)=2^{-\frac{1}{z}}$, Can I use this function and identity theorem to show that $f=g$ on the disk. But $g$ is not analytic at $z=0$, so we get a contradiction? Is there a loophole in my argument. Edited the definition of function $g$",,['complex-analysis']
54,Real analytic non-holomorphic function from the $\mathbb{C}$ to $\mathbb{C}$,Real analytic non-holomorphic function from the  to,\mathbb{C} \mathbb{C},"This is going to be completely obvious, but I can't seem to get a satisfying answer on my own. Any help would be much appreciated. I thought I understood the definitions of complex vs real analytic functions, but an example I found has proved me wrong. What does it mean for a function to be a real analytic non-holomorphic function from  $\mathbb{C} \rightarrow \mathbb{C}$. It seems to imply having a series expansion but I don't understand how that doesn't make it holomorphic.","This is going to be completely obvious, but I can't seem to get a satisfying answer on my own. Any help would be much appreciated. I thought I understood the definitions of complex vs real analytic functions, but an example I found has proved me wrong. What does it mean for a function to be a real analytic non-holomorphic function from  $\mathbb{C} \rightarrow \mathbb{C}$. It seems to imply having a series expansion but I don't understand how that doesn't make it holomorphic.",,['complex-analysis']
55,Let $a_n$ be a decreasing sequence. Prove that the power series $\sum a_n x^n$ has no roots in $A=\{z\in C:|z|<1\}$,Let  be a decreasing sequence. Prove that the power series  has no roots in,a_n \sum a_n x^n A=\{z\in C:|z|<1\},"Let $a_n$ be a decreasing, positive sequence, in the real space. Prove that the power series $\large p(z)=\sum\limits_{k=0}^{n} a_k z^k$ has no roots in $A=\{z\in C:|z|<1\}$. What I did so far $zp(z) =\sum\limits_{k=1}^{n+1} a_{k} z^k \Rightarrow |zp(z)| \leq \sum\limits_{k=1}^{n+1} a_{k} |z|^k \leq\sum\limits_{k=0}^{n} a_k |z|^k = |p(z)|=|-p(z)|$ (since $a_n$ non decreasing and $|z|<1$) using Rouche's principle $(z-1)p(z)$ has the same amount of roots with $-p(z)$ or $p(z)$. Am I going to the right direction ?","Let $a_n$ be a decreasing, positive sequence, in the real space. Prove that the power series $\large p(z)=\sum\limits_{k=0}^{n} a_k z^k$ has no roots in $A=\{z\in C:|z|<1\}$. What I did so far $zp(z) =\sum\limits_{k=1}^{n+1} a_{k} z^k \Rightarrow |zp(z)| \leq \sum\limits_{k=1}^{n+1} a_{k} |z|^k \leq\sum\limits_{k=0}^{n} a_k |z|^k = |p(z)|=|-p(z)|$ (since $a_n$ non decreasing and $|z|<1$) using Rouche's principle $(z-1)p(z)$ has the same amount of roots with $-p(z)$ or $p(z)$. Am I going to the right direction ?",,"['complex-analysis', 'power-series']"
56,Residue of $\exp(z-z^{-1})$ at $z=0$,Residue of  at,\exp(z-z^{-1}) z=0,"I'm interested in the residue of $\exp(z-z^{-1})$ at $z=0$. We have $(z-z^{-1})^n=\sum_{k=0}^n\binom{n}{k}z^{n-k}(-z)^{-k}=\sum_{k=0}^n \binom{n}{k}(-1)^k z^{n-2k}$ so $\exp(z-z^{-1})=\sum_{n=0}^\infty\frac{1}{n!}\sum_{k=0}^n \binom{n}{k}(-1)^k z^{n-2k}$ But as I see it, I don't really have a chance to get the coefficient $a_{-1}$ since for every odd $n$ there is a $k$ such that $n-2k=-1$. Edit: A non-closed form of the residue would be $\sum_{n\ \text{odd}}\frac{(-1)^{\frac{n+1}{2}}}{\left(\frac{n+1}{2}\right)!\left(\frac{n+-1}{2}\right)!}$","I'm interested in the residue of $\exp(z-z^{-1})$ at $z=0$. We have $(z-z^{-1})^n=\sum_{k=0}^n\binom{n}{k}z^{n-k}(-z)^{-k}=\sum_{k=0}^n \binom{n}{k}(-1)^k z^{n-2k}$ so $\exp(z-z^{-1})=\sum_{n=0}^\infty\frac{1}{n!}\sum_{k=0}^n \binom{n}{k}(-1)^k z^{n-2k}$ But as I see it, I don't really have a chance to get the coefficient $a_{-1}$ since for every odd $n$ there is a $k$ such that $n-2k=-1$. Edit: A non-closed form of the residue would be $\sum_{n\ \text{odd}}\frac{(-1)^{\frac{n+1}{2}}}{\left(\frac{n+1}{2}\right)!\left(\frac{n+-1}{2}\right)!}$",,"['complex-analysis', 'residue-calculus']"
57,Complex Analysis Book to follow Ahlfors.,Complex Analysis Book to follow Ahlfors.,,"I have worked through Ahfors for an introduction to Complex Analysis. I am seeking advice on the books to read to learn more Complex Analysis. At this point, one name suggested to me has been Conway. My background includes Analysis at the US undergrad level -- analysis in euclidean spaces, point set topology, measure theory, basic functional analysis and differentiable manifolds.","I have worked through Ahfors for an introduction to Complex Analysis. I am seeking advice on the books to read to learn more Complex Analysis. At this point, one name suggested to me has been Conway. My background includes Analysis at the US undergrad level -- analysis in euclidean spaces, point set topology, measure theory, basic functional analysis and differentiable manifolds.",,"['complex-analysis', 'analysis', 'reference-request']"
58,Solve equation $x^{1/4}=-1$,Solve equation,x^{1/4}=-1,I tried $1/4\ln(x)=\ln(-1)+2ki\pi$ $\ln(x)=4(i\pi+4ki\pi)$ $x=1$ I must be wrong... Math newbie here. Forgot how to do the complex algebras. Could you please give links or any help.,I tried $1/4\ln(x)=\ln(-1)+2ki\pi$ $\ln(x)=4(i\pi+4ki\pi)$ $x=1$ I must be wrong... Math newbie here. Forgot how to do the complex algebras. Could you please give links or any help.,,"['complex-analysis', 'algebra-precalculus', 'complex-numbers']"
59,"Using complex analysis , how to prove that any holomorphic function $f:\overline{D(0;1)} \to \overline{D(0;1)}$ has a fixed point?","Using complex analysis , how to prove that any holomorphic function  has a fixed point?",f:\overline{D(0;1)} \to \overline{D(0;1)},"Using complex analysis , how to prove that any holomorphic function $f:\overline{D(0;1)} \to \overline{D(0;1)}$ has a fixed point ? From this answer Suppose $f(z)$ is analytic in the closed unit disc... I can see that if $|f(z)|<1$ on $|z|=1$ then I can prove it easily ; but what if that condition doesn't hold ? I am stuck . Please help . Thanks in advance","Using complex analysis , how to prove that any holomorphic function $f:\overline{D(0;1)} \to \overline{D(0;1)}$ has a fixed point ? From this answer Suppose $f(z)$ is analytic in the closed unit disc... I can see that if $|f(z)|<1$ on $|z|=1$ then I can prove it easily ; but what if that condition doesn't hold ? I am stuck . Please help . Thanks in advance",,['complex-analysis']
60,"How to evaluate $PV \int_0^\infty\frac{\cos(\ln x)}{x^2+1}\,dx$?",How to evaluate ?,"PV \int_0^\infty\frac{\cos(\ln x)}{x^2+1}\,dx","I'm trying to show $$PV \int_0^\infty\frac{\cos(\ln x)}{x^2+1}\,dx=\frac{\pi}{2\cosh(\pi/2)}.$$ My textbook says to do this by ""integrating $e^{i\ln z}/(z^2-1)$ around a contour like Figure 7.3 but rotated 90◦ clock- wise so the straight side is along the y axis."" I took the original integral and reformulated it like this: $$I=\int_0^\infty\frac{\cos(\ln x)}{x^2+1}\,dx=\frac{1}{2}\text{ Re}\left[\int_{-\infty}^\infty\frac{e^{i\ln x}}{x^2+1}\,dx\right]$$ Next I set up the contour integral $$\oint_C\frac{e^{i\ln z}}{(z^2-1)}\,dz=2\pi i\sum Res$$ With $\sum Res = Res[z=1]$. I then managed to show that the semicircular paths around the contour go to zero as $R$ and $\epsilon$ go to infinity and zero respectively. This implies the contour integral is equal to the principal value of $f(z)$ evaluated from $-\infty$ to $\infty$. But my problem is that $\frac{1}{2}$ of the real part of the sum of the residues does not equal $\frac{\pi}{2\cosh(\pi/2)}$. Any pointers would be very much appreciated, I've been working on this for quite a while now!","I'm trying to show $$PV \int_0^\infty\frac{\cos(\ln x)}{x^2+1}\,dx=\frac{\pi}{2\cosh(\pi/2)}.$$ My textbook says to do this by ""integrating $e^{i\ln z}/(z^2-1)$ around a contour like Figure 7.3 but rotated 90◦ clock- wise so the straight side is along the y axis."" I took the original integral and reformulated it like this: $$I=\int_0^\infty\frac{\cos(\ln x)}{x^2+1}\,dx=\frac{1}{2}\text{ Re}\left[\int_{-\infty}^\infty\frac{e^{i\ln x}}{x^2+1}\,dx\right]$$ Next I set up the contour integral $$\oint_C\frac{e^{i\ln z}}{(z^2-1)}\,dz=2\pi i\sum Res$$ With $\sum Res = Res[z=1]$. I then managed to show that the semicircular paths around the contour go to zero as $R$ and $\epsilon$ go to infinity and zero respectively. This implies the contour integral is equal to the principal value of $f(z)$ evaluated from $-\infty$ to $\infty$. But my problem is that $\frac{1}{2}$ of the real part of the sum of the residues does not equal $\frac{\pi}{2\cosh(\pi/2)}$. Any pointers would be very much appreciated, I've been working on this for quite a while now!",,"['complex-analysis', 'contour-integration']"
61,Where does the factor of $\frac{1}{2}$ come from in the complex differential operators?,Where does the factor of  come from in the complex differential operators?,\frac{1}{2},"I'm taking complex analysis right now, and while I understand the proof that holomorphism of a function implies the Cauchy-Riemann equations I don't understand why we need the factor of $\frac{1}{2}$ the operator $$\frac{\partial}{\partial z} = \frac{1}{2}(\frac{\partial}{\partial x} + \frac{1}{i} \frac{\partial}{\partial y}).$$ To show that the equations are implied we take the limit definition of holomorphicity with h being either purely real or imaginary and observe that we get partial differentiation with a factor of $\frac{1}{i}$ in front of the $y$ partial derivative when h is imaginary. The book (Complex Analysis by Stein & Shakarchi) then just introduces the operators with the factor included, and the proof seems to assert that it is implied somehow by the limit derivation.  Any assistance would be greatly appreciated.","I'm taking complex analysis right now, and while I understand the proof that holomorphism of a function implies the Cauchy-Riemann equations I don't understand why we need the factor of $\frac{1}{2}$ the operator $$\frac{\partial}{\partial z} = \frac{1}{2}(\frac{\partial}{\partial x} + \frac{1}{i} \frac{\partial}{\partial y}).$$ To show that the equations are implied we take the limit definition of holomorphicity with h being either purely real or imaginary and observe that we get partial differentiation with a factor of $\frac{1}{i}$ in front of the $y$ partial derivative when h is imaginary. The book (Complex Analysis by Stein & Shakarchi) then just introduces the operators with the factor included, and the proof seems to assert that it is implied somehow by the limit derivation.  Any assistance would be greatly appreciated.",,"['complex-analysis', 'complex-numbers']"
62,Laurent expansion of a function,Laurent expansion of a function,,"Consider the function $$f(z) = \frac{e^z+1}{e^z-1}$$ This function has a Laurent expansion about $0$ of the form $$f(z) = \frac{a}{z} + \sum_{n=0}^\infty b_nz^n$$ for constants $a, b_1,\ldots, b_n$. Show that $b_n=0$ for all even $n$. What is the best way to do this? All I can think to do is find the laurent expansion and then show that a few are zero but obviously this doesn't prove it for all even $n$, just a few. If we split $f(z)$ into even and odd parts we have $$f(z) = \frac az +\sum_{k=0}^\infty b_{2k}z^{2k}+\sum_{k=0}^\infty b_{2k+1}z^{2k+1}$$ and how the problem turns into showing the first summation is zero.","Consider the function $$f(z) = \frac{e^z+1}{e^z-1}$$ This function has a Laurent expansion about $0$ of the form $$f(z) = \frac{a}{z} + \sum_{n=0}^\infty b_nz^n$$ for constants $a, b_1,\ldots, b_n$. Show that $b_n=0$ for all even $n$. What is the best way to do this? All I can think to do is find the laurent expansion and then show that a few are zero but obviously this doesn't prove it for all even $n$, just a few. If we split $f(z)$ into even and odd parts we have $$f(z) = \frac az +\sum_{k=0}^\infty b_{2k}z^{2k}+\sum_{k=0}^\infty b_{2k+1}z^{2k+1}$$ and how the problem turns into showing the first summation is zero.",,['complex-analysis']
63,Prove a function is constant. (complex analysis),Prove a function is constant. (complex analysis),,Suppose function $f$ is holomorphic on $\mathbb C-\{0\}$ and satisfies $$|f(z)| \le \sqrt {|z|} + \frac{1}{\sqrt {|z|}}.$$ Prove that $f$ is a constant function. I think it's related to Laurent series representation and ML inequality but I have no idea how to prove it. Can anyone give me some hints? Thanks in advance!,Suppose function is holomorphic on and satisfies Prove that is a constant function. I think it's related to Laurent series representation and ML inequality but I have no idea how to prove it. Can anyone give me some hints? Thanks in advance!,f \mathbb C-\{0\} |f(z)| \le \sqrt {|z|} + \frac{1}{\sqrt {|z|}}. f,['complex-analysis']
64,Analytic continuation for $\zeta(s)$ using finite sums?,Analytic continuation for  using finite sums?,\zeta(s),"$\zeta(s)$ converges for $\sigma >1$ but not for $\sigma =1/2.$ But for some reason for $s = 1/2 + i t $ and fixed finite $N,~$ $\zeta_N(s) =\sum_{n=1}^N\frac{1}{n^s}$ is very close to $\zeta(s)$ as found using analytic continuation for $t$ in some range $$f_1(N) < t < f_2(N). $$ For example, for $N= 1000$ a plot of $\zeta_N(s)$ gives a zero at approximately $t= 568.9,$ and the 319th zeta zero is about $t=568.924$ (per Mathematica). For $N=10000,$ graphically there is a zero at approximately $1783.07,$ and this agrees with Mathematica's 1321st zero, about $1783.08.$ Mathematica has a built-in analytic continuation for $\zeta(s),$ but I don't think that is being engaged here. Does this property evaporate for very large $N$ or is there a reason we should in principle be able to approximate $\zeta(s)$ at $\sigma = 1/2$ for finite $N$ on a suitable range of $t?$ Since this property may not hold for large $N$ there is little point in broadening the question.","$\zeta(s)$ converges for $\sigma >1$ but not for $\sigma =1/2.$ But for some reason for $s = 1/2 + i t $ and fixed finite $N,~$ $\zeta_N(s) =\sum_{n=1}^N\frac{1}{n^s}$ is very close to $\zeta(s)$ as found using analytic continuation for $t$ in some range $$f_1(N) < t < f_2(N). $$ For example, for $N= 1000$ a plot of $\zeta_N(s)$ gives a zero at approximately $t= 568.9,$ and the 319th zeta zero is about $t=568.924$ (per Mathematica). For $N=10000,$ graphically there is a zero at approximately $1783.07,$ and this agrees with Mathematica's 1321st zero, about $1783.08.$ Mathematica has a built-in analytic continuation for $\zeta(s),$ but I don't think that is being engaged here. Does this property evaporate for very large $N$ or is there a reason we should in principle be able to approximate $\zeta(s)$ at $\sigma = 1/2$ for finite $N$ on a suitable range of $t?$ Since this property may not hold for large $N$ there is little point in broadening the question.",,"['complex-analysis', 'riemann-zeta', 'analytic-continuation']"
65,Analytic function on annulus bounded by $\log 1/|z|$ is zero,Analytic function on annulus bounded by  is zero,\log 1/|z|,"Let $f(z)$ be an analytic function on $A(0,1)=\{z\in\mathbb{C}\mid0<|z|<1\}$ such that $$\forall z\in A(0,1)\quad|f(z)|\le\log\bigg(\frac 1 {|z|}\bigg).$$ Prove $f\equiv 0.$ Define $g(z)=e^{f(z)}$ and note that $$\forall z\in A(0,1),\quad |g(z)|=e^{\Re f(z)}\le e^{|f(z)|}\le e^{\log |z|^{-1}}=\frac{1}{|z|}.$$  Now I don't know how to prove $g\equiv c$. Suppose I did that, $f=\ln c$ but since $f(1)=0$ we get the result. As said, I'm struggling with proving that g is constant. I thought doing it By applying Cauchy integral formula but I only succeeded bounding the derivative. How can I prove $g$ is constant ?","Let $f(z)$ be an analytic function on $A(0,1)=\{z\in\mathbb{C}\mid0<|z|<1\}$ such that $$\forall z\in A(0,1)\quad|f(z)|\le\log\bigg(\frac 1 {|z|}\bigg).$$ Prove $f\equiv 0.$ Define $g(z)=e^{f(z)}$ and note that $$\forall z\in A(0,1),\quad |g(z)|=e^{\Re f(z)}\le e^{|f(z)|}\le e^{\log |z|^{-1}}=\frac{1}{|z|}.$$  Now I don't know how to prove $g\equiv c$. Suppose I did that, $f=\ln c$ but since $f(1)=0$ we get the result. As said, I'm struggling with proving that g is constant. I thought doing it By applying Cauchy integral formula but I only succeeded bounding the derivative. How can I prove $g$ is constant ?",,"['complex-analysis', 'analysis', 'cauchy-integral-formula']"
66,There is an entire function $g$ such that $f(z)=g\left(z^{n}\right)$.,There is an entire function  such that .,g f(z)=g\left(z^{n}\right),Let $f$ be an entire function and $\xi=e^{\frac{2\pi i}{n}}$ for some $n\in \mathbb{N}$. Suppose that $f\left(\xi z\right)=f(z)$ for all $z\in \mathbb{C}$. Show that  there is a entire function $g$ such that $f(z)=g\left(z^{n}\right)$ for all $z \in \mathbb{C}$. Remark: I have tried to express $g$ in terms of $f\left(\xi z\right)$ but my attempts have been unsuccessful.,Let $f$ be an entire function and $\xi=e^{\frac{2\pi i}{n}}$ for some $n\in \mathbb{N}$. Suppose that $f\left(\xi z\right)=f(z)$ for all $z\in \mathbb{C}$. Show that  there is a entire function $g$ such that $f(z)=g\left(z^{n}\right)$ for all $z \in \mathbb{C}$. Remark: I have tried to express $g$ in terms of $f\left(\xi z\right)$ but my attempts have been unsuccessful.,,"['complex-analysis', 'complex-integration']"
67,zeros and poles of $\operatorname{Im} f(z) / \operatorname{ Im z }>0$ using argument's principle,zeros and poles of  using argument's principle,\operatorname{Im} f(z) / \operatorname{ Im z }>0,"Hi everyone I find the following exercise and honestly I'm stuck and I can't see how to use the argument's principle in any way. I'd appreciate any help with the exercise. Thank you. Let $f$ a mermorphic function defined on $\mathbb C$ and suppose that $\operatorname{Im} f(z) / \operatorname{ Im z }>0$ for all $z$ outside of the real axis. Show that the poles and zeros of $f$ belongs to $\mathbb R$ and the zeros and poles are interlaced, that is, between two adjacent poles there is exactly a zero and between two adjacent zeros there is a pole (use the argument's principle).","Hi everyone I find the following exercise and honestly I'm stuck and I can't see how to use the argument's principle in any way. I'd appreciate any help with the exercise. Thank you. Let a mermorphic function defined on and suppose that for all outside of the real axis. Show that the poles and zeros of belongs to and the zeros and poles are interlaced, that is, between two adjacent poles there is exactly a zero and between two adjacent zeros there is a pole (use the argument's principle).",f \mathbb C \operatorname{Im} f(z) / \operatorname{ Im z }>0 z f \mathbb R,"['complex-analysis', 'analysis']"
68,Entire functions with finite $L^1$ norm must be identically $0$,Entire functions with finite  norm must be identically,L^1 0,"Another question from Complex Variables: An Introduction by Berenstein and Gay. Show that an entire function has finite $L^1$ norm on $\mathbb{C}$ iff $f\equiv0$. Does this also hold true for $L^2, L^{\infty}$? So, the $L^{\infty}$ case I think just follows from Liouville's Theorem, but the others I'm not sure about. How should I approach these? My intuition would be to use a power series expansion at $0$ for $f$, but the work I've done on paper with this hasn't really gone anywhere fruitful. Edit: As discussed in the comments, there are two cases to consider wrt the behavior at $\infty$: if $f$ has a pole there, then $f$ must be a polynomial so it must have infinite norm. So we are reduced to the case where $f$ has an essential singularity at $\infty$.","Another question from Complex Variables: An Introduction by Berenstein and Gay. Show that an entire function has finite $L^1$ norm on $\mathbb{C}$ iff $f\equiv0$. Does this also hold true for $L^2, L^{\infty}$? So, the $L^{\infty}$ case I think just follows from Liouville's Theorem, but the others I'm not sure about. How should I approach these? My intuition would be to use a power series expansion at $0$ for $f$, but the work I've done on paper with this hasn't really gone anywhere fruitful. Edit: As discussed in the comments, there are two cases to consider wrt the behavior at $\infty$: if $f$ has a pole there, then $f$ must be a polynomial so it must have infinite norm. So we are reduced to the case where $f$ has an essential singularity at $\infty$.",,"['complex-analysis', 'analysis']"
69,"Continued Fraction: Please prove $\frac{1}{e \gamma (x+1,1)}=x+\frac{1}{x+1+\frac{2}{x+2+\frac{3}{x+3+\frac{4}{\dots}}}}$",Continued Fraction: Please prove,"\frac{1}{e \gamma (x+1,1)}=x+\frac{1}{x+1+\frac{2}{x+2+\frac{3}{x+3+\frac{4}{\dots}}}}","I have been playing around with Mathematica and continued fractions and I noticed something. ContinuedFractionK[n, n + x, {n, 1, Infinity}] ==-x + 1/(E Gamma[1 + x] - E Gamma[1 + x, 1])==-x + 1/(E Gamma[1 + x, 0, 1]) $$\underset{n=1}{\overset{\infty }{K}}\frac{n}{n+x}=\frac{1}{e \gamma (x+1,1)}-x$$ In more traditional notation, this means $$\frac{1}{e \gamma (x+1,1)}=x+\frac{1}{x+1+\frac{2}{x+2+\frac{3}{x+3+\frac{4}{\dots}}}}$$ I have verified this to be true for all x I have tested including complex numbers for hundreds of digits. I do not know how to prove my result and would like proof. Mathematica can verify $x\in\{0,1\}$. Failing proof of all x, proof with x being another specific number e.g. 2 gets partial credit. PS. $\gamma (a,b)$ is the lower incomplete gamma function . Note: For whole numbered x, we have $$\frac{1}{e*x!-A000522(x)}=x+\frac{1}{x+1+\frac{2}{x+2+\frac{3}{x+3+\frac{4}{\dots}}}}$$ https://oeis.org/A000522 This is the story of my discovery: I noticed that ContinuedFractionK[n, n, {n, 1, Infinity}] was $\frac{1}{e-1}$ and ContinuedFractionK[n, n + 1, {n, 1, Infinity}] was $\frac{1}{e-2}-1$. Because the answers were both fractions of e, I thought I could find a pattern. ContinuedFractionK[n, n + 2, {n, 1, Infinity}] and onward gave no results, but I didn't let that stop me. I calculated N[ContinuedFractionK[n, n + 2, {n, 1, 10000}], 190] for an approximation and pasted the first 190 digits into Wolfram Alpha where it suggested the possible closed form of $\frac{11-4 e}{2 e-5}$. The closed form matched all digits. I used Wolfram Alpha again to find out N[ContinuedFractionK[n, n + 3, {n, 1, 10000}], 190] suggested $\frac{49-18 e}{2 (3 e-8)}$ and that N[ContinuedFractionK[n, n + 4, {n, 1, 10000}], 190] suggested $-\frac{3 (32 e-87)}{24 e-65}$. Wolfram Alpha failed to be of further help with closed forms, so I made a list of what I knew, used the Expand[] and FullSimplify[] functions on it to get: $\left\{\frac{1}{e-1},\frac{1}{e-2}-1,\frac{1}{2 e-5}-2,\frac{1}{6 e-16}-3,\frac{1}{24 e-65}-4\right\}$. The numbers by the e's were obviously $x!$, outside the fraction was $−x$. This left the numbers {1,2,5,16,65}. A lookup found this: https://oeis.org/A000522 with the formula a(n) = e*Gamma(n+1,1) I thus conjectured that ContinuedFractionK[n, n + x, {n, 1, Infinity}]$=\frac{1}{e \Gamma (x+1)-e \Gamma (x+1,1)}-x$. Every x I have tested on the complex plane has shown this to be correct.","I have been playing around with Mathematica and continued fractions and I noticed something. ContinuedFractionK[n, n + x, {n, 1, Infinity}] ==-x + 1/(E Gamma[1 + x] - E Gamma[1 + x, 1])==-x + 1/(E Gamma[1 + x, 0, 1]) $$\underset{n=1}{\overset{\infty }{K}}\frac{n}{n+x}=\frac{1}{e \gamma (x+1,1)}-x$$ In more traditional notation, this means $$\frac{1}{e \gamma (x+1,1)}=x+\frac{1}{x+1+\frac{2}{x+2+\frac{3}{x+3+\frac{4}{\dots}}}}$$ I have verified this to be true for all x I have tested including complex numbers for hundreds of digits. I do not know how to prove my result and would like proof. Mathematica can verify $x\in\{0,1\}$. Failing proof of all x, proof with x being another specific number e.g. 2 gets partial credit. PS. $\gamma (a,b)$ is the lower incomplete gamma function . Note: For whole numbered x, we have $$\frac{1}{e*x!-A000522(x)}=x+\frac{1}{x+1+\frac{2}{x+2+\frac{3}{x+3+\frac{4}{\dots}}}}$$ https://oeis.org/A000522 This is the story of my discovery: I noticed that ContinuedFractionK[n, n, {n, 1, Infinity}] was $\frac{1}{e-1}$ and ContinuedFractionK[n, n + 1, {n, 1, Infinity}] was $\frac{1}{e-2}-1$. Because the answers were both fractions of e, I thought I could find a pattern. ContinuedFractionK[n, n + 2, {n, 1, Infinity}] and onward gave no results, but I didn't let that stop me. I calculated N[ContinuedFractionK[n, n + 2, {n, 1, 10000}], 190] for an approximation and pasted the first 190 digits into Wolfram Alpha where it suggested the possible closed form of $\frac{11-4 e}{2 e-5}$. The closed form matched all digits. I used Wolfram Alpha again to find out N[ContinuedFractionK[n, n + 3, {n, 1, 10000}], 190] suggested $\frac{49-18 e}{2 (3 e-8)}$ and that N[ContinuedFractionK[n, n + 4, {n, 1, 10000}], 190] suggested $-\frac{3 (32 e-87)}{24 e-65}$. Wolfram Alpha failed to be of further help with closed forms, so I made a list of what I knew, used the Expand[] and FullSimplify[] functions on it to get: $\left\{\frac{1}{e-1},\frac{1}{e-2}-1,\frac{1}{2 e-5}-2,\frac{1}{6 e-16}-3,\frac{1}{24 e-65}-4\right\}$. The numbers by the e's were obviously $x!$, outside the fraction was $−x$. This left the numbers {1,2,5,16,65}. A lookup found this: https://oeis.org/A000522 with the formula a(n) = e*Gamma(n+1,1) I thus conjectured that ContinuedFractionK[n, n + x, {n, 1, Infinity}]$=\frac{1}{e \Gamma (x+1)-e \Gamma (x+1,1)}-x$. Every x I have tested on the complex plane has shown this to be correct.",,"['complex-analysis', 'gamma-function', 'continued-fractions']"
70,How to show if a complex function is analytic?,How to show if a complex function is analytic?,,"Just began the study of complex analysis. Let $$ f(x,y) = x^2 - y^2 + 2 i xy - x - iy. $$ I need to determine if this function is analytic. This means I have to show the partials satisfy the Cauchy-Riemann equations, and that the partials are continuous. So in this case we have $u(x,y) = x^2 - y^2 - x$ and $v(x,y) = 2xy - y$. Now \begin{align*} \frac{\partial v}{\partial y} = 2x - 1 = \frac{\partial u}{\partial x} \end{align*} and \begin{align*} - \frac{\partial u}{\partial y} = - (-2y) = 2 y = \frac{\partial v}{\partial x} \end{align*} Hence the Cauchy-Riemann equations are satisfied, which is a necessary condition for being analytic, but not sufficient. Now I have to show the partials are continuous? How do I do that?","Just began the study of complex analysis. Let $$ f(x,y) = x^2 - y^2 + 2 i xy - x - iy. $$ I need to determine if this function is analytic. This means I have to show the partials satisfy the Cauchy-Riemann equations, and that the partials are continuous. So in this case we have $u(x,y) = x^2 - y^2 - x$ and $v(x,y) = 2xy - y$. Now \begin{align*} \frac{\partial v}{\partial y} = 2x - 1 = \frac{\partial u}{\partial x} \end{align*} and \begin{align*} - \frac{\partial u}{\partial y} = - (-2y) = 2 y = \frac{\partial v}{\partial x} \end{align*} Hence the Cauchy-Riemann equations are satisfied, which is a necessary condition for being analytic, but not sufficient. Now I have to show the partials are continuous? How do I do that?",,['complex-analysis']
71,"$f,g,h$ be a holomorphic functions such that $|f(z)|+|g(z)|+|h(z)|=1$",be a holomorphic functions such that,"f,g,h |f(z)|+|g(z)|+|h(z)|=1","Let $U\subseteq \mathbb{C}$ be a connected open set, and let $f,g,h:U\to\mathbb{C}$ be holomorphic functions such that $$|f(z)|+|g(z)|+|h(z)|=1$$ for all $z\in U$. How does one prove that $f,g,h$ are constant functions? Any hints would be appreciated.","Let $U\subseteq \mathbb{C}$ be a connected open set, and let $f,g,h:U\to\mathbb{C}$ be holomorphic functions such that $$|f(z)|+|g(z)|+|h(z)|=1$$ for all $z\in U$. How does one prove that $f,g,h$ are constant functions? Any hints would be appreciated.",,['complex-analysis']
72,Riemann hypothesis reformulation - again,Riemann hypothesis reformulation - again,,"Yesterday I started to write a paper about the reformulation of the Riemann Hypothesis. My idea was to map the function such that all of the trivial zeros are outside of the unit disk, and the non-trivial zeros are on the circle. Iff RH is true, then the radius of convergence (the distance to the closest singularity from the origin of the taylor series) of the taylor series representing reciprocal of the function is $1$. After some manipulations, I have got 2 conjectures: https://mathoverflow.net/questions/212289/riemann-hypothesis-reformulation-lim-n-to-infty-sum-k-lnka-kn-over-n-s . (Topic deleted from MO.) I would like to know if they really imply RH, or I went wrong somewhere. EDIT: I post the reformulation here: $\zeta(s)$ has its non-trivial zeros on the line $Re(s)=0.5$. It means, that the the taylor series of $$Z(s)={1\over\zeta\left(\frac{1}{2}+\frac{1+s}{1-s}\right)}$$ have its radius of convergence of $1$. (I mapped the right half plane to the unit disc, so trivial zeros are outside of the disk.) Its derivates given by Cauchy's integral formula, and taking the right contour $C$ such that $C(t)=f^{-1}(t-(a-1/2)i)$ with $f(z)=i(z+1)/(z-1)$ the map from $\mathbb{D}\to\mathbb{\overline{H}}$ becames $${Z}^{(n)}(0)=\frac{n!}{2\pi i}\int_{-\infty}^{\infty}{1\over \zeta(a+it)}C_n(t)\;dt$$ with $C_n(t)=C'(t)/C(t)^{n+1}$. WLG letting $1.5>a>1$, and using the dirichlet series for the reciprocal of the zeta function, I got \begin{align*}{Z}^{(n)}(0)&=\frac{n!}{2\pi i}\int_{-\infty}^{\infty}\left[\sum_{k=1}^\infty \frac{\mu(k)}{k^{a+it}}\right]C_n(t)\;dt\\&=\sum_{k=1}^\infty \frac{\mu(k)}{k^a}\int_{-\infty}^{\infty}\frac{n!}{2\pi i}\frac{C_n(t)}{k^{it}}\;dt\\&=\sum_{k=1}^\infty \frac{\mu(k)}{k^a}\int_{-\infty}^{\infty}\frac{n!}{2\pi i}g_k(C(t))C_n(t)\;dt\\&=\sum_{k=1}^\infty \frac{\mu(k)}{k^a}g^{(n)}_{k}(0).\end{align*} $$g_k(t)=1/k^{iC^{-1}(t)}$$ In the last 2 steps, I changed the contour integral to the derivates of a function series, noticing that $g\circ C(t)=1/(k^{it})$. The only singularity of $g$ is at $1$, but $g$ is bounded inside the contour, so I tought the integral and the derivates are the same. For later to have the limits defined, define the function $d\colon\mathbb{N}\mapsto \mathbb{N}$ such that $d(n)$ gives the $n$th square-free integer. $$Z^{(n)}(0)=\sum_{k=1}^{\infty}\frac{\mu(d(k))}{d(k)^2}g^{(n)}_{d(k)}(0)$$ 1. conjecture: Using the ratio test led me to my first question here, such that given a series $$A(n)=\sum_{k=1}^{\infty}a_k(n),$$ $$a_k(n)=\frac{\mu(d(k))}{n!d(k)^2}g^{(n)}_{d(k)}$$ with $|a_k(n)/a_k(n+1)|\to 1$ (Taylor series of $g$ about the origin have its radius of conv. 1) as $n\to \infty$, it is true that $$\lim_{n\to \infty}\left|\frac{A(n)}{A(n+1)}\right|=1.$$ I suppose it is true for some series satisfying certain conditions, but I cannot prove it. 2. conjecture: Using the recurrence relation of the coefficients (due to WolframAlpha): $na_k(n)+(n+2)a_k(n+2)-2(n+1-\ln(k))a_k(n+1)=0$, $$\lim_{n\to \infty}{\sum_k\ln(k)a_k(n)\over\sum_kna_k(n)}=0$$ would imply RH. Does proving the 2 conjectures above prove the Riemann hypothesis? I think it would also prove GRH for Dirichlet L-function with a little change, and with a good choice of $a$ to ensure convergence.","Yesterday I started to write a paper about the reformulation of the Riemann Hypothesis. My idea was to map the function such that all of the trivial zeros are outside of the unit disk, and the non-trivial zeros are on the circle. Iff RH is true, then the radius of convergence (the distance to the closest singularity from the origin of the taylor series) of the taylor series representing reciprocal of the function is $1$. After some manipulations, I have got 2 conjectures: https://mathoverflow.net/questions/212289/riemann-hypothesis-reformulation-lim-n-to-infty-sum-k-lnka-kn-over-n-s . (Topic deleted from MO.) I would like to know if they really imply RH, or I went wrong somewhere. EDIT: I post the reformulation here: $\zeta(s)$ has its non-trivial zeros on the line $Re(s)=0.5$. It means, that the the taylor series of $$Z(s)={1\over\zeta\left(\frac{1}{2}+\frac{1+s}{1-s}\right)}$$ have its radius of convergence of $1$. (I mapped the right half plane to the unit disc, so trivial zeros are outside of the disk.) Its derivates given by Cauchy's integral formula, and taking the right contour $C$ such that $C(t)=f^{-1}(t-(a-1/2)i)$ with $f(z)=i(z+1)/(z-1)$ the map from $\mathbb{D}\to\mathbb{\overline{H}}$ becames $${Z}^{(n)}(0)=\frac{n!}{2\pi i}\int_{-\infty}^{\infty}{1\over \zeta(a+it)}C_n(t)\;dt$$ with $C_n(t)=C'(t)/C(t)^{n+1}$. WLG letting $1.5>a>1$, and using the dirichlet series for the reciprocal of the zeta function, I got \begin{align*}{Z}^{(n)}(0)&=\frac{n!}{2\pi i}\int_{-\infty}^{\infty}\left[\sum_{k=1}^\infty \frac{\mu(k)}{k^{a+it}}\right]C_n(t)\;dt\\&=\sum_{k=1}^\infty \frac{\mu(k)}{k^a}\int_{-\infty}^{\infty}\frac{n!}{2\pi i}\frac{C_n(t)}{k^{it}}\;dt\\&=\sum_{k=1}^\infty \frac{\mu(k)}{k^a}\int_{-\infty}^{\infty}\frac{n!}{2\pi i}g_k(C(t))C_n(t)\;dt\\&=\sum_{k=1}^\infty \frac{\mu(k)}{k^a}g^{(n)}_{k}(0).\end{align*} $$g_k(t)=1/k^{iC^{-1}(t)}$$ In the last 2 steps, I changed the contour integral to the derivates of a function series, noticing that $g\circ C(t)=1/(k^{it})$. The only singularity of $g$ is at $1$, but $g$ is bounded inside the contour, so I tought the integral and the derivates are the same. For later to have the limits defined, define the function $d\colon\mathbb{N}\mapsto \mathbb{N}$ such that $d(n)$ gives the $n$th square-free integer. $$Z^{(n)}(0)=\sum_{k=1}^{\infty}\frac{\mu(d(k))}{d(k)^2}g^{(n)}_{d(k)}(0)$$ 1. conjecture: Using the ratio test led me to my first question here, such that given a series $$A(n)=\sum_{k=1}^{\infty}a_k(n),$$ $$a_k(n)=\frac{\mu(d(k))}{n!d(k)^2}g^{(n)}_{d(k)}$$ with $|a_k(n)/a_k(n+1)|\to 1$ (Taylor series of $g$ about the origin have its radius of conv. 1) as $n\to \infty$, it is true that $$\lim_{n\to \infty}\left|\frac{A(n)}{A(n+1)}\right|=1.$$ I suppose it is true for some series satisfying certain conditions, but I cannot prove it. 2. conjecture: Using the recurrence relation of the coefficients (due to WolframAlpha): $na_k(n)+(n+2)a_k(n+2)-2(n+1-\ln(k))a_k(n+1)=0$, $$\lim_{n\to \infty}{\sum_k\ln(k)a_k(n)\over\sum_kna_k(n)}=0$$ would imply RH. Does proving the 2 conjectures above prove the Riemann hypothesis? I think it would also prove GRH for Dirichlet L-function with a little change, and with a good choice of $a$ to ensure convergence.",,"['real-analysis', 'complex-analysis']"
73,Extending a bounded holomorphic function past its boundary,Extending a bounded holomorphic function past its boundary,,"Suppose I have a bounded holomorphic function on the unit disc, centred at the origin. Can I always extend this beyond the origin to say a disc of radius $1 + \epsilon$ for some $\epsilon > 0$? My guess is that this should be possible since we can take a Taylor expansion about 0, but I can't show that there are not going to be poles/ a limit point of poles at the boundary.","Suppose I have a bounded holomorphic function on the unit disc, centred at the origin. Can I always extend this beyond the origin to say a disc of radius $1 + \epsilon$ for some $\epsilon > 0$? My guess is that this should be possible since we can take a Taylor expansion about 0, but I can't show that there are not going to be poles/ a limit point of poles at the boundary.",,"['complex-analysis', 'taylor-expansion']"
74,A (basic?) contour integration problem,A (basic?) contour integration problem,,"I am trying to prove the following using complex analysis: $$\sum_{n=-\infty}^{\infty}\frac{(-1)^{n}}{a^{2}+n^{2}}=\frac{\pi}{a\sinh(a\pi)}$$ I am told to use the following function: $$f(z)=\frac{1}{(a^{2}+z^{2})\sin(\pi z)}$$ So we note that $f(z)$ has singularities at $z = \{\pm i a, n\}$, where $n \in \mathbb{Z}$. We can use the following contour (which I will call $\Gamma$): By Cauchy's Residue Theorem, we have: $$\lim_{R \to \infty}\oint_{\Gamma}f(z)\:\mathrm{d}z=2\pi i \sum_{n=-\infty}^{\infty}\operatorname{Res}(n,f(z))$$ We can compute the residue at each point: $$\operatorname{Res}(n,f(z))=\frac{(-1)^n}{\pi(a^{2}+n^{2})}$$ So we have: $$\lim_{R\to \infty}\oint_{\Gamma}f(z)\:\mathrm{d}z = 2\pi i \sum_{n=-\infty}^{\infty}\frac{(-1)^{n}}{a^{2}+n^{2}}$$ But we have that: $$\begin{align*}\lim_{R\to\infty}\oint_{\Gamma}f(z)\:\mathrm{d}z = \lim_{R\to\infty}\Bigg(I &+ \int_{-\frac{a}{2}}^{\frac{a}{2}}\frac{\mathrm{d}y}{(a^{2} + (R + iy)^{2}\sin(\pi(R + iy))} \\ &+ \int_{R}^{-R}\frac{\mathrm{d}x}{(a^{2} + (x + ia/2)^{2})\sin(\pi(x+ia/2))} \\  &+ \int_{\frac{a}{2}}^{-\frac{a}{2}}\frac{\mathrm{d}y}{(a^{2} + (iy - R)^{2})\sin(\pi(iy - R))}\Bigg)\end{align*}$$ However, I'm not not sure how to proceed? I'd be grateful for any hints!","I am trying to prove the following using complex analysis: $$\sum_{n=-\infty}^{\infty}\frac{(-1)^{n}}{a^{2}+n^{2}}=\frac{\pi}{a\sinh(a\pi)}$$ I am told to use the following function: $$f(z)=\frac{1}{(a^{2}+z^{2})\sin(\pi z)}$$ So we note that $f(z)$ has singularities at $z = \{\pm i a, n\}$, where $n \in \mathbb{Z}$. We can use the following contour (which I will call $\Gamma$): By Cauchy's Residue Theorem, we have: $$\lim_{R \to \infty}\oint_{\Gamma}f(z)\:\mathrm{d}z=2\pi i \sum_{n=-\infty}^{\infty}\operatorname{Res}(n,f(z))$$ We can compute the residue at each point: $$\operatorname{Res}(n,f(z))=\frac{(-1)^n}{\pi(a^{2}+n^{2})}$$ So we have: $$\lim_{R\to \infty}\oint_{\Gamma}f(z)\:\mathrm{d}z = 2\pi i \sum_{n=-\infty}^{\infty}\frac{(-1)^{n}}{a^{2}+n^{2}}$$ But we have that: $$\begin{align*}\lim_{R\to\infty}\oint_{\Gamma}f(z)\:\mathrm{d}z = \lim_{R\to\infty}\Bigg(I &+ \int_{-\frac{a}{2}}^{\frac{a}{2}}\frac{\mathrm{d}y}{(a^{2} + (R + iy)^{2}\sin(\pi(R + iy))} \\ &+ \int_{R}^{-R}\frac{\mathrm{d}x}{(a^{2} + (x + ia/2)^{2})\sin(\pi(x+ia/2))} \\  &+ \int_{\frac{a}{2}}^{-\frac{a}{2}}\frac{\mathrm{d}y}{(a^{2} + (iy - R)^{2})\sin(\pi(iy - R))}\Bigg)\end{align*}$$ However, I'm not not sure how to proceed? I'd be grateful for any hints!",,"['complex-analysis', 'complex-numbers', 'contour-integration', 'complex-integration']"
75,Residue Theorem and Homologous to zero,Residue Theorem and Homologous to zero,,"This is a very basic question and I couldn't find it posted yet but here it goes; The Residue Theorem states that if $f:G\to \mathbb{C}$ is analytic on $G$- a region and $f$ has isolated singularities $b_1,...,b_k$ and $\gamma$ is homologous to 0, then $$\displaystyle\int_{\gamma}f=2\pi i\sum_1^kn(\gamma;b_s)\mathrm{Res}(f;b_s).$$  To my understanding, if $\gamma$ ""wraps"" around an isolated singularity, $b_i$, (say 1 time), then $\gamma$ would not be homologous to 0 since $n(\gamma;b_i)=1$ in this case ($b_i\in \mathbb{C}-G$). I think I need a better picture of the situation in this case. Thank you for your help!","This is a very basic question and I couldn't find it posted yet but here it goes; The Residue Theorem states that if $f:G\to \mathbb{C}$ is analytic on $G$- a region and $f$ has isolated singularities $b_1,...,b_k$ and $\gamma$ is homologous to 0, then $$\displaystyle\int_{\gamma}f=2\pi i\sum_1^kn(\gamma;b_s)\mathrm{Res}(f;b_s).$$  To my understanding, if $\gamma$ ""wraps"" around an isolated singularity, $b_i$, (say 1 time), then $\gamma$ would not be homologous to 0 since $n(\gamma;b_i)=1$ in this case ($b_i\in \mathbb{C}-G$). I think I need a better picture of the situation in this case. Thank you for your help!",,"['complex-analysis', 'homotopy-theory']"
76,How to define the complex square root $ \sqrt{z} $?,How to define the complex square root ?, \sqrt{z} ,"We need to define the complex square root $ \sqrt{z} $ on a small open $ U \subset \mathbb{C} $, for example a disc. Let put : $ \mathcal{F} (U) = \{\ f: U \to \mathbb {C} \ / \ f \ \text{is continuous} \ \forall z \in U \: \ (f (z))^2 = z \ \} $ Questions: Why is : $ 0 \in U \ \ \Longrightarrow \ \ \mathcal{F} (U) = \emptyset $ ? So either: $ U \subset \mathbb {C}^* $ and connected non-empty: If: $ U = U_1 \bigcup U_2 $, open $ U_1 $ and $ U_2 $ are disjoint, why the application: $ \mathcal{F } (U) \to \mathcal{F} (U_1) \times \mathcal{F} (U_2) $ to which $ f $ combines $ (f_{|U_{1} } , f_{|U_{2}}) $ is a bijection? Thank you in advance.","We need to define the complex square root $ \sqrt{z} $ on a small open $ U \subset \mathbb{C} $, for example a disc. Let put : $ \mathcal{F} (U) = \{\ f: U \to \mathbb {C} \ / \ f \ \text{is continuous} \ \forall z \in U \: \ (f (z))^2 = z \ \} $ Questions: Why is : $ 0 \in U \ \ \Longrightarrow \ \ \mathcal{F} (U) = \emptyset $ ? So either: $ U \subset \mathbb {C}^* $ and connected non-empty: If: $ U = U_1 \bigcup U_2 $, open $ U_1 $ and $ U_2 $ are disjoint, why the application: $ \mathcal{F } (U) \to \mathcal{F} (U_1) \times \mathcal{F} (U_2) $ to which $ f $ combines $ (f_{|U_{1} } , f_{|U_{2}}) $ is a bijection? Thank you in advance.",,"['complex-analysis', 'complex-numbers', 'riemann-surfaces']"
77,Sum of the series $\sum_{k=1}^\infty (-1)^k \frac{2z}{k^2 \pi^2-z^2}\cos kt$,Sum of the series,\sum_{k=1}^\infty (-1)^k \frac{2z}{k^2 \pi^2-z^2}\cos kt,"From the relation: $$\csc z=\frac{1}{z}+\sum_{k=1}^\infty (-1)^k \frac{2z}{z^2-k^2 \pi^2}$$ can we obtain the sum of following series? $$\sum_{k=1}^\infty (-1)^k \frac{2z}{k^2 \pi^2-z^2}\cos kt$$ I have tried using the absolute value, but I got: $$\sum_{k=1}^\infty \left|\frac{2z}{k^2 \pi^2-z^2}\right|$$ and I can not go on. Any suggestions please?","From the relation: $$\csc z=\frac{1}{z}+\sum_{k=1}^\infty (-1)^k \frac{2z}{z^2-k^2 \pi^2}$$ can we obtain the sum of following series? $$\sum_{k=1}^\infty (-1)^k \frac{2z}{k^2 \pi^2-z^2}\cos kt$$ I have tried using the absolute value, but I got: $$\sum_{k=1}^\infty \left|\frac{2z}{k^2 \pi^2-z^2}\right|$$ and I can not go on. Any suggestions please?",,['complex-analysis']
78,Periodic-Like Holomorphic Function,Periodic-Like Holomorphic Function,,"I am reading a paper ( this one ), and the authors (on page 4) implicitly use a result that I do not know. There may be some inaccuracy; I'm inferring the result from the context of the paper. Let $f$ be a holomorphic function from the upper half-plane in $\mathbb{C}$ to $\mathbb{C}$ ( $f:H \rightarrow \mathbb{C})$ . Suppose there is constant $\exp(2 \pi i a)$ with $a>0$ real such that $f(z+1)=\exp(2 \pi i a)f(z)$ . Then, there exists a function $g$ holomorphic near 0 in $H$ such that $f(z)=\exp(2 \pi i a z)g(\exp(2 \pi i z))$ . Proof?","I am reading a paper ( this one ), and the authors (on page 4) implicitly use a result that I do not know. There may be some inaccuracy; I'm inferring the result from the context of the paper. Let be a holomorphic function from the upper half-plane in to ( . Suppose there is constant with real such that . Then, there exists a function holomorphic near 0 in such that . Proof?",f \mathbb{C} \mathbb{C} f:H \rightarrow \mathbb{C}) \exp(2 \pi i a) a>0 f(z+1)=\exp(2 \pi i a)f(z) g H f(z)=\exp(2 \pi i a z)g(\exp(2 \pi i z)),['complex-analysis']
79,"A question on notation: $u(x,y)$ vs. $u(x+iy)$.",A question on notation:  vs. .,"u(x,y) u(x+iy)","In Tao's complex analysis notes, he uses the convention that $$f(z)=u(z)+iv(z)= u(x+iy)+iv(x+iy)$$ implying that the functions are $$u,v:\mathbb{C} \to \mathbb{R}.$$ But in other places I see the convention $$f(z)=u(x,y)+iv(x,y),$$ which implies that they functions are $$u,v:\mathbb{R}^2 \to \mathbb{R}.$$ Does this matter at all? It seems to me that it should, after all there's quite a few differences between the structures of $\mathbb{R}^2$ and $\mathbb{C}$, even though they are similar?","In Tao's complex analysis notes, he uses the convention that $$f(z)=u(z)+iv(z)= u(x+iy)+iv(x+iy)$$ implying that the functions are $$u,v:\mathbb{C} \to \mathbb{R}.$$ But in other places I see the convention $$f(z)=u(x,y)+iv(x,y),$$ which implies that they functions are $$u,v:\mathbb{R}^2 \to \mathbb{R}.$$ Does this matter at all? It seems to me that it should, after all there's quite a few differences between the structures of $\mathbb{R}^2$ and $\mathbb{C}$, even though they are similar?",,"['complex-analysis', 'convention']"
80,Show that an analytic function $f$ has a zero on the unit disc given that $|f(z)|>2$ on the boundary and $f(0) = 1$,Show that an analytic function  has a zero on the unit disc given that  on the boundary and,f |f(z)|>2 f(0) = 1,"Question: Suppose $f$ is analytic in a region A containing the unit disc $D = \{ z: |z| \leq 1 \} $ and such that $|f(z)|>2$ whenever $|z| = 1$. If $f(0) = 1$, show that $f$ has a zero in D. Thoughts: I am studying for an exam in complex analysis and this is one of the more theoretical questions from an old exam. Since my knowledge of complex analysis theory is small, I'm not quite sure how to proceed. I supposed it has something to do with that $f$ must be negative somewhere on $D$ and since the function is analytic in the region, $f$ must have a zero somewhere according the mean-value theorem or an analogous version of it. All input is very much appreciated.","Question: Suppose $f$ is analytic in a region A containing the unit disc $D = \{ z: |z| \leq 1 \} $ and such that $|f(z)|>2$ whenever $|z| = 1$. If $f(0) = 1$, show that $f$ has a zero in D. Thoughts: I am studying for an exam in complex analysis and this is one of the more theoretical questions from an old exam. Since my knowledge of complex analysis theory is small, I'm not quite sure how to proceed. I supposed it has something to do with that $f$ must be negative somewhere on $D$ and since the function is analytic in the region, $f$ must have a zero somewhere according the mean-value theorem or an analogous version of it. All input is very much appreciated.",,['complex-analysis']
81,Show: $f'=0\Rightarrow f=\mbox{const}$,Show:,f'=0\Rightarrow f=\mbox{const},"Let $G\subseteq\mathbb{C}$ be a domain and $f\colon G\to\mathbb{C}$ holomorphic. Show:     $$ f'=0\mbox{ in }G\Rightarrow f\mbox{ is constant} $$ Cauchy-Riemann: $$ f'(z)=f_x(z)=u_x(x,y)+i v_x(x,y), z=x+iy=0\\ \Leftrightarrow u_x(x,y)=0~\wedge v_x(x,y)=0 $$ and $$ f'(z)=-if_y(z)=-iu_y(x,y)+v_y(x,y)=0\\\Leftrightarrow u_y(x,y)=0~\wedge~v_y(x,y)=0 $$ That means: If one derivates u and v to x, one gets 0, and therfore the x-part of these functions must be constant. The ssame for the y-part of u and v. So u and v are constant and so is then f. Is that okay?","Let $G\subseteq\mathbb{C}$ be a domain and $f\colon G\to\mathbb{C}$ holomorphic. Show:     $$ f'=0\mbox{ in }G\Rightarrow f\mbox{ is constant} $$ Cauchy-Riemann: $$ f'(z)=f_x(z)=u_x(x,y)+i v_x(x,y), z=x+iy=0\\ \Leftrightarrow u_x(x,y)=0~\wedge v_x(x,y)=0 $$ and $$ f'(z)=-if_y(z)=-iu_y(x,y)+v_y(x,y)=0\\\Leftrightarrow u_y(x,y)=0~\wedge~v_y(x,y)=0 $$ That means: If one derivates u and v to x, one gets 0, and therfore the x-part of these functions must be constant. The ssame for the y-part of u and v. So u and v are constant and so is then f. Is that okay?",,[]
82,A linear holomorphic function,A linear holomorphic function,,"If $f$ is a holomorphic function on a simply connected open domain $\Omega$, and $f$ is a linear function on the boundary $\Omega$, i.e. $f=az+b$ on $\partial\Omega$. Then, can I say that $f$ is also linear function on $\Omega$?","If $f$ is a holomorphic function on a simply connected open domain $\Omega$, and $f$ is a linear function on the boundary $\Omega$, i.e. $f=az+b$ on $\partial\Omega$. Then, can I say that $f$ is also linear function on $\Omega$?",,['complex-analysis']
83,Finding all Laurent expansions of $f=\frac{1}{z}$,Finding all Laurent expansions of,f=\frac{1}{z},"I have the following homework problem I need help with: Let $G=\{z\in\mathbb{C}:\, z\neq0\}$ and define $f:\, G\to G$ by   $f(z)=\frac{1}{z}$. Find all possible Laurent expansions of $f$ which are not Taylor   expansions and for each such expansion specify in what set the Laurent   series converges. What I tried: For the point $z=z_{0}$ there are Laurent expansions in $$E_{1}:=0<|z|<R$$ and in $$E_{2}:=|z|>R$$ Where $R>0$ is real. I am unsure about in which set the Laurent series converges to $f$ , but it seems that in both cases the Laurent series of $f$ is simply $\frac{1}{z}$ and it converges in all points of $E_{1}$or $E_{2}$ (according to the case). Am I correct ? For $z_{0}\ne0$ the Laurent expansions which is not Taylor is in $$E_{1}:=0\leq|z|<R$$ where $R>|z_{0}|$ and $$E_{2}:=|z|>R$$ where $R<|z_{0}|$. I am not sure about where I should of used $<$ or $\leq$ in the description of $E_{1},E_{2}$. I am also having difficulty finding the Laurent series at $E_{i}$ and telling where it is convergent. Can someone please help me out with the case $z\neq z_0$ and tell me if I did correctly the first case ($z=z_0$) ?","I have the following homework problem I need help with: Let $G=\{z\in\mathbb{C}:\, z\neq0\}$ and define $f:\, G\to G$ by   $f(z)=\frac{1}{z}$. Find all possible Laurent expansions of $f$ which are not Taylor   expansions and for each such expansion specify in what set the Laurent   series converges. What I tried: For the point $z=z_{0}$ there are Laurent expansions in $$E_{1}:=0<|z|<R$$ and in $$E_{2}:=|z|>R$$ Where $R>0$ is real. I am unsure about in which set the Laurent series converges to $f$ , but it seems that in both cases the Laurent series of $f$ is simply $\frac{1}{z}$ and it converges in all points of $E_{1}$or $E_{2}$ (according to the case). Am I correct ? For $z_{0}\ne0$ the Laurent expansions which is not Taylor is in $$E_{1}:=0\leq|z|<R$$ where $R>|z_{0}|$ and $$E_{2}:=|z|>R$$ where $R<|z_{0}|$. I am not sure about where I should of used $<$ or $\leq$ in the description of $E_{1},E_{2}$. I am also having difficulty finding the Laurent series at $E_{i}$ and telling where it is convergent. Can someone please help me out with the case $z\neq z_0$ and tell me if I did correctly the first case ($z=z_0$) ?",,"['complex-analysis', 'laurent-series']"
84,Determining whether a family of power series is normal,Determining whether a family of power series is normal,,"How should I check whether a given family of power series forms a normal family? I am trying to apply Montel's theorem that says that a family of holomorphic functions is normal iff it is uniformly bounded on every compact set but I couldn't verify this boundedness condition. For example, I saw a problem in a book asking to show that the family of power series $\sum_{n=0}^{\infty}a_{n}z^{n}$ with $|a_{n}|\leq n^{2}$ is normal in the open unit disk, but I'm not sure how to do it. Does the fact that each of these series converges uniformly on every smaller closed disk centered at 0 help? A similar problem is to determine whether the family of power series $\sum_{n=1}^{\infty}a_{n}z^{n}$ with $|a_{n}|\leq n$ is normal in the open unit disk.","How should I check whether a given family of power series forms a normal family? I am trying to apply Montel's theorem that says that a family of holomorphic functions is normal iff it is uniformly bounded on every compact set but I couldn't verify this boundedness condition. For example, I saw a problem in a book asking to show that the family of power series $\sum_{n=0}^{\infty}a_{n}z^{n}$ with $|a_{n}|\leq n^{2}$ is normal in the open unit disk, but I'm not sure how to do it. Does the fact that each of these series converges uniformly on every smaller closed disk centered at 0 help? A similar problem is to determine whether the family of power series $\sum_{n=1}^{\infty}a_{n}z^{n}$ with $|a_{n}|\leq n$ is normal in the open unit disk.",,['complex-analysis']
85,A Pick Lemma like problem,A Pick Lemma like problem,,"Let $f$ be analytic on the unit disc $D$ and bounded in modulus by $M$ there. I want to show that $|f'(z)|\le \frac{M}{1-|z|}$ for all $z\in D$. I want to use Schwarz's lemma here after some suitable FLTs, as in the proof of Pick's lemma, but I haven't made progress. Does anyone have an idea? Edited: Forgot a factor of $M$ in the inequality originally.","Let $f$ be analytic on the unit disc $D$ and bounded in modulus by $M$ there. I want to show that $|f'(z)|\le \frac{M}{1-|z|}$ for all $z\in D$. I want to use Schwarz's lemma here after some suitable FLTs, as in the proof of Pick's lemma, but I haven't made progress. Does anyone have an idea? Edited: Forgot a factor of $M$ in the inequality originally.",,['complex-analysis']
86,Pick out the true statements complex analysis,Pick out the true statements complex analysis,,"Pick out the true statements: (a) There exists an analytic function $f$ on $\mathbb{C}$ such that $f(2i) = 0$, $f(0) = 2i$ and $|f(z)|\le 2$ for all $z\in\mathbb{C}$ . (b) There exists an analytic function $f$ in the open unit disc $\{z\in\mathbb{C} : |z| < 1\}$ such that $f(1/2) = 1$ and $f(1/2^n ) = 0$ for all integers $n\ge 2 $. (c) There exists an analytic function  whose real part is given by $u(x, y) = x^2 + y^2$, where $z = x + iy$.","Pick out the true statements: (a) There exists an analytic function $f$ on $\mathbb{C}$ such that $f(2i) = 0$, $f(0) = 2i$ and $|f(z)|\le 2$ for all $z\in\mathbb{C}$ . (b) There exists an analytic function $f$ in the open unit disc $\{z\in\mathbb{C} : |z| < 1\}$ such that $f(1/2) = 1$ and $f(1/2^n ) = 0$ for all integers $n\ge 2 $. (c) There exists an analytic function  whose real part is given by $u(x, y) = x^2 + y^2$, where $z = x + iy$.",,['complex-analysis']
87,"$f(z)=\int_1^\infty e^{-x}x^z\,dx$ is complex analytic",is complex analytic,"f(z)=\int_1^\infty e^{-x}x^z\,dx","Note : I'm refereshing my complex analysis skills in order to learn some analytic number theory. Here's one (basic) claim I'd like to prove and my attempt. My questions are: Is my partial attempt correct? Are there better (or shorter) ways to prove it? I may be going a bit too much into the details instead of using general theorems. I'd like to prove that if $f:\mathbb{C}\rightarrow\mathbb{C}$ is defined by $f(z)=\int_1^\infty e^{-x}x^z\,dx$ then $f$ is complex analytic. My attempt : Define $f_n(z)=\int_1^n e^{-x}x^z\,dx$. Then it's enough to prove that for each $n$, the function $f_n$ is holomoprphic and that $f_n$ converges uniformly on compact sets. As for the first point, the integral is a limit of Riemann sums and each Riemann sum is complex analytic. So it's enough to prove that the Riemann sums converge to the integral uniformly in compact sets (relative to $z$). I think that follows from equicontinuity of $e^{-x} x^z$ in $[1,n]$ and $Re(z)$ being bounded in compact sets. As for the second point, in a compact set $Re(z)$ is bounded, say, by $K$. Then $|x^z|\leq x^K$. Now $$|f_m(z)-f_n(z)|= \left| \int_n^m e^{-x}x^z\,dx\right| \leq\int_n^m e^{-x}|x^z|\,dx \leq \int_n^m e^{-x}x^K \, dx \overset{n,m\rightarrow \infty}{\longrightarrow}0.$$ So, the convergence really is uniform.","Note : I'm refereshing my complex analysis skills in order to learn some analytic number theory. Here's one (basic) claim I'd like to prove and my attempt. My questions are: Is my partial attempt correct? Are there better (or shorter) ways to prove it? I may be going a bit too much into the details instead of using general theorems. I'd like to prove that if $f:\mathbb{C}\rightarrow\mathbb{C}$ is defined by $f(z)=\int_1^\infty e^{-x}x^z\,dx$ then $f$ is complex analytic. My attempt : Define $f_n(z)=\int_1^n e^{-x}x^z\,dx$. Then it's enough to prove that for each $n$, the function $f_n$ is holomoprphic and that $f_n$ converges uniformly on compact sets. As for the first point, the integral is a limit of Riemann sums and each Riemann sum is complex analytic. So it's enough to prove that the Riemann sums converge to the integral uniformly in compact sets (relative to $z$). I think that follows from equicontinuity of $e^{-x} x^z$ in $[1,n]$ and $Re(z)$ being bounded in compact sets. As for the second point, in a compact set $Re(z)$ is bounded, say, by $K$. Then $|x^z|\leq x^K$. Now $$|f_m(z)-f_n(z)|= \left| \int_n^m e^{-x}x^z\,dx\right| \leq\int_n^m e^{-x}|x^z|\,dx \leq \int_n^m e^{-x}x^K \, dx \overset{n,m\rightarrow \infty}{\longrightarrow}0.$$ So, the convergence really is uniform.",,['complex-analysis']
88,Schwarz Lemma - like exercise,Schwarz Lemma - like exercise,,"There's this exercise: let $\,f\,$ be analytic on $$D:=\{z\;\;;\;\;|z|<1\}\,\,,\,|f(z)|\leq 1\,\,,\,\,\forall\,z\in D$$  and $\,z=0\,$  a zero of order $\,m\,$ of $\,f\,$. Prove that $$\forall z\in D\,\,,\,\,|f(z)|\leq |z|^m$$ My solution: Induction on $\,m\,$: for $\,m=1\,$ this is exactly the lemma of Schwarz, thus we can assume truth for $\,k<m\,$ and prove for $\,k=m>1\,$ . Since $\,f(z)=z^mh(z)\,\,,\,h(0)\neq 0\,$ analytic in $\,D\,$ ,  put  $$g(z):=\frac{f(z)}{z}=z^{m-1}h(z)$$ Applying the inductive hypothesis and using Schwarz lemma $\,\,(***)\,\,$ we get that  $$|g(z)|=\left|\frac{f(z)}{z}\right|=|z|^{m-1}|h(z)|\stackrel{ind. hyp.}\leq |z|^{m-1}\Longrightarrow |f(z)|\leq |z^m|$$ and we're done... almost : we still have to prove $\,|g(z)|\leq 1\,$ for all $\,z\in D$ in order to be able to use the inductive hypothesis and this is precisely the part where I have some doubts: this can be proved as follows (all the time we work with $\,z\in D\,$): $(1)\,\,$ For $\,f(z)=z^mh(z)\,$ we apply directly Schwarz lemma and get $$|f(z)|=|z|^m|h(z)|\leq |z|\Longrightarrow |z|^{m-1}h(z)|\leq 1$$ And since now the function $\,f_1(z)=z^{m-1}h(z)\,$ fulfills the conditions of S.L. we get $(2)\,\,$ Applying again the lemma,  $$|f_1(z)|=|z|^{m-1}|h(z)|\leq |z|\Longrightarrow |z^{m-2}h(z)|\leq 1$$and now the function $\,f_2(z):=z^{m-2}h(z)\,$ fulfills the conditions of them  lemma so...etc. In the step$\,m-1\,$ we get  $$|z||h(z)|\leq |z|\Longrightarrow {\color{red}{\mathbf{|h(z)|\leq 1}}}\,$$  and this is what allows us to use the inductive hypothesis in $\,\,(***)\,\,$ above. My question: Is there any way I can't see right now to deduce directly, or in a shorter way, that $\,|h(z)\leq 1\,$ ?","There's this exercise: let $\,f\,$ be analytic on $$D:=\{z\;\;;\;\;|z|<1\}\,\,,\,|f(z)|\leq 1\,\,,\,\,\forall\,z\in D$$  and $\,z=0\,$  a zero of order $\,m\,$ of $\,f\,$. Prove that $$\forall z\in D\,\,,\,\,|f(z)|\leq |z|^m$$ My solution: Induction on $\,m\,$: for $\,m=1\,$ this is exactly the lemma of Schwarz, thus we can assume truth for $\,k<m\,$ and prove for $\,k=m>1\,$ . Since $\,f(z)=z^mh(z)\,\,,\,h(0)\neq 0\,$ analytic in $\,D\,$ ,  put  $$g(z):=\frac{f(z)}{z}=z^{m-1}h(z)$$ Applying the inductive hypothesis and using Schwarz lemma $\,\,(***)\,\,$ we get that  $$|g(z)|=\left|\frac{f(z)}{z}\right|=|z|^{m-1}|h(z)|\stackrel{ind. hyp.}\leq |z|^{m-1}\Longrightarrow |f(z)|\leq |z^m|$$ and we're done... almost : we still have to prove $\,|g(z)|\leq 1\,$ for all $\,z\in D$ in order to be able to use the inductive hypothesis and this is precisely the part where I have some doubts: this can be proved as follows (all the time we work with $\,z\in D\,$): $(1)\,\,$ For $\,f(z)=z^mh(z)\,$ we apply directly Schwarz lemma and get $$|f(z)|=|z|^m|h(z)|\leq |z|\Longrightarrow |z|^{m-1}h(z)|\leq 1$$ And since now the function $\,f_1(z)=z^{m-1}h(z)\,$ fulfills the conditions of S.L. we get $(2)\,\,$ Applying again the lemma,  $$|f_1(z)|=|z|^{m-1}|h(z)|\leq |z|\Longrightarrow |z^{m-2}h(z)|\leq 1$$and now the function $\,f_2(z):=z^{m-2}h(z)\,$ fulfills the conditions of them  lemma so...etc. In the step$\,m-1\,$ we get  $$|z||h(z)|\leq |z|\Longrightarrow {\color{red}{\mathbf{|h(z)|\leq 1}}}\,$$  and this is what allows us to use the inductive hypothesis in $\,\,(***)\,\,$ above. My question: Is there any way I can't see right now to deduce directly, or in a shorter way, that $\,|h(z)\leq 1\,$ ?",,['complex-analysis']
89,Characteristic function of Cauchy distribution.,Characteristic function of Cauchy distribution.,,"When computing the characteristic function of Cauchy distribution, we applied the Cauchy Integration theorem: $$  \int_{C_{R}}\frac{e^{i\alpha z}}{z^{2}+1}dz=\int_{-R}^{R}\frac{e^{i\alpha z}}{z^{2}+1}dz+\int_{\Gamma_{R}}\frac{e^{i\alpha z}}{z^{2}+1}dz=I_{R}+J_{R}  $$ We assume $\alpha>0$ and we use the curve from $(-R,0)$ to $(R,0)$ and back to $(-R,0)$ counter clockwise from the positive half plane (imaginary part $>0$) . $C_{R}$ is the counter-clockwise contour, $\Gamma_{R}$ is the counterclockwise half circle on the upper half plane. The final result is: $$  \pi e^{-\alpha} $$ I am curious where did we use the condition $\alpha>0$ in this derivation? I suspect it to be the choice of the integration contour. But how?  Can we choose $\alpha<0$ while integrate over the same positive contour and get the same result but it is unstable for $\alpha<0$ Thanks in advance.","When computing the characteristic function of Cauchy distribution, we applied the Cauchy Integration theorem: $$  \int_{C_{R}}\frac{e^{i\alpha z}}{z^{2}+1}dz=\int_{-R}^{R}\frac{e^{i\alpha z}}{z^{2}+1}dz+\int_{\Gamma_{R}}\frac{e^{i\alpha z}}{z^{2}+1}dz=I_{R}+J_{R}  $$ We assume $\alpha>0$ and we use the curve from $(-R,0)$ to $(R,0)$ and back to $(-R,0)$ counter clockwise from the positive half plane (imaginary part $>0$) . $C_{R}$ is the counter-clockwise contour, $\Gamma_{R}$ is the counterclockwise half circle on the upper half plane. The final result is: $$  \pi e^{-\alpha} $$ I am curious where did we use the condition $\alpha>0$ in this derivation? I suspect it to be the choice of the integration contour. But how?  Can we choose $\alpha<0$ while integrate over the same positive contour and get the same result but it is unstable for $\alpha<0$ Thanks in advance.",,"['complex-analysis', 'probability-distributions']"
90,Hyperellipticity (or not!) of a Riemann surface and the singularities of the curve,Hyperellipticity (or not!) of a Riemann surface and the singularities of the curve,,"Largely I want to know as to how does one say anything about the hyperellipticity or the genus of the Riemann surface by looking at the algebraic curve and its singularities. To give a specific example, what is the meaning of the statement that, ""a curve of genus 2 can be expressed as a fourth degree plane curve possessing one double point"" ? Does this mean that any Riemann surface of genus 2 is a normalization of a fourth degree algebraic curve in $\mathbb{P}^2$ with one double point? In general the proof says that any compact hyperelliptic Riemann surface of genus $g$ is a normalization of a an algebraic curve of degree $2g+2$ of the form $y^2 = \prod _{i = 1}^{2g+2} (x-a_i)$ So I would have naively thought that a genus $2$ Riemann surface (which is always hyperelliptic) will need a $2\times 2 +2 = 6$ degree algebraic curve. Hence I am not clear as to what to read of the quoted statement. Is something very special happening for genus $2$? Is the general theorem not a sharp statement? The general statement seems to tell me that the $a_i$ being distinct guarantees the smoothness of the algebraic curve except may be at the points at infinity. Now if there is a lower degree curve that can equally well represent the genus $2$ surface then is that necessarily going to be a curve with singularities? If the general statement is not a sharp statement and one can in cases do with lower degree curves than $2g+2$ then how does one derive the genus of the Riemann surface by looking at the algebraic curve and may be its singularities. Is there a ""generalized"" genus formula that works always?","Largely I want to know as to how does one say anything about the hyperellipticity or the genus of the Riemann surface by looking at the algebraic curve and its singularities. To give a specific example, what is the meaning of the statement that, ""a curve of genus 2 can be expressed as a fourth degree plane curve possessing one double point"" ? Does this mean that any Riemann surface of genus 2 is a normalization of a fourth degree algebraic curve in $\mathbb{P}^2$ with one double point? In general the proof says that any compact hyperelliptic Riemann surface of genus $g$ is a normalization of a an algebraic curve of degree $2g+2$ of the form $y^2 = \prod _{i = 1}^{2g+2} (x-a_i)$ So I would have naively thought that a genus $2$ Riemann surface (which is always hyperelliptic) will need a $2\times 2 +2 = 6$ degree algebraic curve. Hence I am not clear as to what to read of the quoted statement. Is something very special happening for genus $2$? Is the general theorem not a sharp statement? The general statement seems to tell me that the $a_i$ being distinct guarantees the smoothness of the algebraic curve except may be at the points at infinity. Now if there is a lower degree curve that can equally well represent the genus $2$ surface then is that necessarily going to be a curve with singularities? If the general statement is not a sharp statement and one can in cases do with lower degree curves than $2g+2$ then how does one derive the genus of the Riemann surface by looking at the algebraic curve and may be its singularities. Is there a ""generalized"" genus formula that works always?",,"['complex-analysis', 'algebraic-geometry', 'differential-geometry', 'riemann-surfaces']"
91,Multiplicative Analytic Functions? [duplicate],Multiplicative Analytic Functions? [duplicate],,"This question already has answers here : Closed 12 years ago . Possible Duplicate: $f(z_1 z_2) = f(z_1) f(z_2)$ for $z_1,z_2\in \mathbb{C}$ then $f(z) = z^k$ for some $k$ How can we characterize the analytic functions defined in the open unit disc $D\subset\mathbb{C}$ that satisfy $f(ab)=f(a)f(b)\text{ }$  for all $a,b\in D$. What happens if we consider larger domains?","This question already has answers here : Closed 12 years ago . Possible Duplicate: $f(z_1 z_2) = f(z_1) f(z_2)$ for $z_1,z_2\in \mathbb{C}$ then $f(z) = z^k$ for some $k$ How can we characterize the analytic functions defined in the open unit disc $D\subset\mathbb{C}$ that satisfy $f(ab)=f(a)f(b)\text{ }$  for all $a,b\in D$. What happens if we consider larger domains?",,['complex-analysis']
92,Bounded integrals imply normal family for $f \in H(U)$ [duplicate],Bounded integrals imply normal family for  [duplicate],f \in H(U),"This question already has an answer here : Closed 13 years ago . Possible Duplicate: Locally bounded Family Let's take $F$ to be the set of all holomorphic functions on the unit disk $U$, for which each $f \in F$ has the property: $\int\int |f(z)|^{2} dx dy \leq 1.$ where the double integral runs over $U$. Is $F$ a normal family?","This question already has an answer here : Closed 13 years ago . Possible Duplicate: Locally bounded Family Let's take $F$ to be the set of all holomorphic functions on the unit disk $U$, for which each $f \in F$ has the property: $\int\int |f(z)|^{2} dx dy \leq 1.$ where the double integral runs over $U$. Is $F$ a normal family?",,['complex-analysis']
93,"if a complex function $f$ is real-differentiable, then $f$ or $\overline{f}$ are complex-differentiable","if a complex function  is real-differentiable, then  or  are complex-differentiable",f f \overline{f},This is an exercise from Remmert's Theory of Complex functions. Let $D\subset \mathbb{C}$ be a domain and $f:D\rightarrow \mathbb{C}$ a real-differentiable function. Assume that the following limit exists: $ \mathrm{lim}_{h\rightarrow 0} \left|  \frac{f(c+h) - f(c)}{h}   \right|.$ Show that either $f$ or $\overline{f}$ is complex-differentiable. I've tried showing that $\frac{\partial f}{\partial \overline{z}} = 0$ or $\frac{\partial \overline{f}}{\partial z} = 0$ by using the fact that there exist continuous functions $g$ and $h$ such that in $D$ one can write $f(z) = f(c) + (z-c)g(z) + (\overline{z} - \overline{c})h(z)$ and that $g(c)= f_{z}(c)$ and $h(c) = f_{\overline{z}}$ and then plugging this into the limit above. Does this approach works and I just can´t see how to do it? Can someone give a hint or a guideline solution to this?,This is an exercise from Remmert's Theory of Complex functions. Let $D\subset \mathbb{C}$ be a domain and $f:D\rightarrow \mathbb{C}$ a real-differentiable function. Assume that the following limit exists: $ \mathrm{lim}_{h\rightarrow 0} \left|  \frac{f(c+h) - f(c)}{h}   \right|.$ Show that either $f$ or $\overline{f}$ is complex-differentiable. I've tried showing that $\frac{\partial f}{\partial \overline{z}} = 0$ or $\frac{\partial \overline{f}}{\partial z} = 0$ by using the fact that there exist continuous functions $g$ and $h$ such that in $D$ one can write $f(z) = f(c) + (z-c)g(z) + (\overline{z} - \overline{c})h(z)$ and that $g(c)= f_{z}(c)$ and $h(c) = f_{\overline{z}}$ and then plugging this into the limit above. Does this approach works and I just can´t see how to do it? Can someone give a hint or a guideline solution to this?,,['complex-analysis']
94,Upper bound for zeros of holomorphic function,Upper bound for zeros of holomorphic function,,"I'd appreciate some help with the following problem form Conway's book on functions of one complex variable: Let $f$ be analytic in $\overline B (0;R)$ with $|f(z)|\le M$ for $|z|\le R$ and $|f(0)|=a>0$. Show that the number of zeros of f in $B(0;R/3)$ is less than or equal to $$\frac{1}{\log(2)}\log\left(\frac M a\right)$$ I know that the number of zeros is given by  $$n = \frac 1 {2\pi i}\int_{|z|=R/3} \frac{f'}{f} \, dz $$ And there is a hint to look at $g(z) = f(z) \prod_{k=1}^n (1-z/z_k)^{-1}$, where the $z_k$ are the zeros of $f$. I have given it some time now, but don't seem to get anywhere. In particular I don't see how the logarithm, $M, a$ come into play. The problem is in the chapter on the maximum modulus theorem, if that's of any help. Might someone maybe give me a hint? Cheers, S.L.","I'd appreciate some help with the following problem form Conway's book on functions of one complex variable: Let $f$ be analytic in $\overline B (0;R)$ with $|f(z)|\le M$ for $|z|\le R$ and $|f(0)|=a>0$. Show that the number of zeros of f in $B(0;R/3)$ is less than or equal to $$\frac{1}{\log(2)}\log\left(\frac M a\right)$$ I know that the number of zeros is given by  $$n = \frac 1 {2\pi i}\int_{|z|=R/3} \frac{f'}{f} \, dz $$ And there is a hint to look at $g(z) = f(z) \prod_{k=1}^n (1-z/z_k)^{-1}$, where the $z_k$ are the zeros of $f$. I have given it some time now, but don't seem to get anywhere. In particular I don't see how the logarithm, $M, a$ come into play. The problem is in the chapter on the maximum modulus theorem, if that's of any help. Might someone maybe give me a hint? Cheers, S.L.",,['complex-analysis']
95,A Torus and the Weierstrass P function?,A Torus and the Weierstrass P function?,,"Let $\wp$ be the Weierstrass function. From what I understand, $\wp$ maps the torus to $CP^1 \times CP^1$ in the following way: $a \mapsto (\wp(a),\wp'(a)) = (z,w)$ Furthermore, the image of this map lies on the zero set of the polynomial $P(z,w) = 4(z-e_1)(z-e_2)(z-e_3) - w^2.$ What I don't get is the description of the inverse to this map, which is supposedly the integral of the differential form $\frac{dz}{w}$ from $\infty$ to a point $Q$ along a path $c$. I don't understand what $\infty$ means here. I don't understand why this is would be the inverse. Heuristically, I see that \begin{equation} \int_\infty^Q \frac{dz}{w} = \int_0^z \frac{\wp'(u)}{\wp'(u)} du = \int_0^a du = a. \end{equation} But unfortunately, the computation above makes little sense. I suppose I am attempting pull-back by setting $z=\wp$ and $w=\wp'$. But isn't this a map into the complex plane, and not the Torus? Also, why is infinity the branch point? More generally, let $w^2 = p(z)$ with degree of $p$ odd. Why is infinity one of the branch points, and why isn't it a branch point when the degree of $p$ is even? Thank you for your time!","Let $\wp$ be the Weierstrass function. From what I understand, $\wp$ maps the torus to $CP^1 \times CP^1$ in the following way: $a \mapsto (\wp(a),\wp'(a)) = (z,w)$ Furthermore, the image of this map lies on the zero set of the polynomial $P(z,w) = 4(z-e_1)(z-e_2)(z-e_3) - w^2.$ What I don't get is the description of the inverse to this map, which is supposedly the integral of the differential form $\frac{dz}{w}$ from $\infty$ to a point $Q$ along a path $c$. I don't understand what $\infty$ means here. I don't understand why this is would be the inverse. Heuristically, I see that \begin{equation} \int_\infty^Q \frac{dz}{w} = \int_0^z \frac{\wp'(u)}{\wp'(u)} du = \int_0^a du = a. \end{equation} But unfortunately, the computation above makes little sense. I suppose I am attempting pull-back by setting $z=\wp$ and $w=\wp'$. But isn't this a map into the complex plane, and not the Torus? Also, why is infinity the branch point? More generally, let $w^2 = p(z)$ with degree of $p$ odd. Why is infinity one of the branch points, and why isn't it a branch point when the degree of $p$ is even? Thank you for your time!",,"['complex-analysis', 'riemann-surfaces', 'elliptic-functions']"
96,Group structure on compact Riemann surface,Group structure on compact Riemann surface,,"I am currently reading chapter 3 of Arithmetic of Elliptic Curves by Silverman. We know that elliptic curves can be viewed as a Riemann surface of genus 1, and there is a well-known group structure on it. I wonder if we can do the same for arbitrary Riemann surfaces of genus 1. The notes of Terence Tao for 246C ( Notes 1, Exercise 43 ) suggests that this can be done by showing for $R$ a point on $X$ , and $P$ , $Q$ points on $X$ , we have some points $P+Q$ such that $$(P)+(Q)-(P+Q)-(R)$$ is a principal divisor. I am not sure how to show this using Riemann-Roch, and how can we use this to get the desired group structure. Thanks in advance.","I am currently reading chapter 3 of Arithmetic of Elliptic Curves by Silverman. We know that elliptic curves can be viewed as a Riemann surface of genus 1, and there is a well-known group structure on it. I wonder if we can do the same for arbitrary Riemann surfaces of genus 1. The notes of Terence Tao for 246C ( Notes 1, Exercise 43 ) suggests that this can be done by showing for a point on , and , points on , we have some points such that is a principal divisor. I am not sure how to show this using Riemann-Roch, and how can we use this to get the desired group structure. Thanks in advance.",R X P Q X P+Q (P)+(Q)-(P+Q)-(R),"['complex-analysis', 'algebraic-geometry']"
97,"If $f$ is analytic defined on $D:=\{z:|z|<1\}$ and $|f(z)|\le 1$, can $f$ be extended continuously to $\overline D$?","If  is analytic defined on  and , can  be extended continuously to ?",f D:=\{z:|z|<1\} |f(z)|\le 1 f \overline D,"If $f$ is analytic defined on $D:=\{z:|z|<1\}$ and $|f(z)|\le 1$ , can $f$ always be extended continuously to $\overline D$ ? In other words, can all analytic functions $f:D\to\overline D$ be extended to continuous functions $\tilde f:\overline D\to\overline D$ (such that $\tilde f|_D=f$ )? Ideally, for $|z_0|=1$ , we could simply define $f(z_0)=\lim_{z\to z_0}f(z)$ . It seems like a reasonable assumption that this extended version of $f$ exists and is continuous, but it's not obvious to me that these limits must exist. This feels like it should be a standard result in complex analysis, but I haven't been able to find a good reference. (Unfortunately, the hope that $f$ can be extended to an analytic function is dashed by the example of $\sqrt{z-1}$ .)","If is analytic defined on and , can always be extended continuously to ? In other words, can all analytic functions be extended to continuous functions (such that )? Ideally, for , we could simply define . It seems like a reasonable assumption that this extended version of exists and is continuous, but it's not obvious to me that these limits must exist. This feels like it should be a standard result in complex analysis, but I haven't been able to find a good reference. (Unfortunately, the hope that can be extended to an analytic function is dashed by the example of .)",f D:=\{z:|z|<1\} |f(z)|\le 1 f \overline D f:D\to\overline D \tilde f:\overline D\to\overline D \tilde f|_D=f |z_0|=1 f(z_0)=\lim_{z\to z_0}f(z) f f \sqrt{z-1},"['complex-analysis', 'analytic-functions', 'analyticity']"
98,Extending holomorphic 1-forms,Extending holomorphic 1-forms,,"I'm working on the following problem: The holomorphic $1$ -form $\frac{dz}{1+z^2}$ , defined on $\mathbb{C}\setminus\{\pm i\}$ , can be extended to a holomorphic $1$ -form $\omega$ on $\mathbb{P}^1\setminus\{\pm i\}$ . My idea is to choose two coordinate neighborhoods of $\mathbb{P}^1\setminus\{ \pm i\}$ (with one of them being a subset of $\mathbb{C} \setminus \{\pm i\}$ ), write down a holomorphic 1-form in each local coordinate, and show that they agree on the overlap. In particular, consider the coordinate patches $(U_1,z)$ and $(U_2, \frac{1}{z})$ where $U_1 = \mathbb{C} \setminus \{ \pm i\}$ and $U_2 = \mathbb{P}^1 \setminus \{0, \pm i\}$ . Let $w = \frac{1}{z}$ , then $f(w)dw = -\frac{1}{1 + w^2}dw$ is a holomorphic 1-form on $U_2$ . On $U_1 \cap U_2$ , one has \begin{equation*}     f(w)dw = f(\frac{1}{z})\frac{\partial w}{\partial z}dz = (-\frac{z^2}{z^2 + 1})\cdot (-\frac{1}{z^2})dz = \frac{dz}{z^2 + 1} \end{equation*} so one can patch $-\frac{dw}{1 + w^2}$ and $\frac{dz}{1+ z^2}$ together to obtain a holomorphic 1-form on $\mathbb{P}^1 \setminus \{ \pm i\}$ . I'm wondering whether this is correct? I'm not so sure because when I compute the pullback form $\tan^{*}(\omega)$ with respect to the map $\tan: \mathbb{C} \to \mathbb{P}^1 \setminus \{ \pm i\}$ , I don't get a unique expression. Specifically, the pullback form on $U_1$ is $dz$ , while the pullback form on $U_2$ is $-\frac{1}{1 + \tan(z)^2}\sec^2(z)dz = -dz$ , so I made at least one conceptual mistake.","I'm working on the following problem: The holomorphic -form , defined on , can be extended to a holomorphic -form on . My idea is to choose two coordinate neighborhoods of (with one of them being a subset of ), write down a holomorphic 1-form in each local coordinate, and show that they agree on the overlap. In particular, consider the coordinate patches and where and . Let , then is a holomorphic 1-form on . On , one has so one can patch and together to obtain a holomorphic 1-form on . I'm wondering whether this is correct? I'm not so sure because when I compute the pullback form with respect to the map , I don't get a unique expression. Specifically, the pullback form on is , while the pullback form on is , so I made at least one conceptual mistake.","1 \frac{dz}{1+z^2} \mathbb{C}\setminus\{\pm i\} 1 \omega \mathbb{P}^1\setminus\{\pm i\} \mathbb{P}^1\setminus\{ \pm i\} \mathbb{C} \setminus \{\pm i\} (U_1,z) (U_2, \frac{1}{z}) U_1 = \mathbb{C} \setminus \{ \pm i\} U_2 = \mathbb{P}^1 \setminus \{0, \pm i\} w = \frac{1}{z} f(w)dw = -\frac{1}{1 + w^2}dw U_2 U_1 \cap U_2 \begin{equation*}
    f(w)dw = f(\frac{1}{z})\frac{\partial w}{\partial z}dz = (-\frac{z^2}{z^2 + 1})\cdot (-\frac{1}{z^2})dz = \frac{dz}{z^2 + 1}
\end{equation*} -\frac{dw}{1 + w^2} \frac{dz}{1+ z^2} \mathbb{P}^1 \setminus \{ \pm i\} \tan^{*}(\omega) \tan: \mathbb{C} \to \mathbb{P}^1 \setminus \{ \pm i\} U_1 dz U_2 -\frac{1}{1 + \tan(z)^2}\sec^2(z)dz = -dz","['complex-analysis', 'differential-geometry', 'riemann-surfaces']"
99,Use Stokes Theorem to Prove Cauchy Integral Formula,Use Stokes Theorem to Prove Cauchy Integral Formula,,"In my undergrad complex analysis, our professor used a quick way to derive the Cauchy integral formula (without Goursat's theorem and all that) with the following setup: Let $U$ be an open set of $\mathbb{C}$ . Consider a complex function $f:U\to\mathbb{C}$ as a zero form on $U$ , i.e., $f\in \Lambda^0(U).$ Then analyticity of $f$ is equivalent to Cauchy-Riemann equation $\partial_{\bar{z}}f=0$ , which is equivalent to the form $f(z)dz\in\Lambda^1(U)$ being closed: $$d(fdz)=df\wedge dz=\partial_{\bar{z}}fd\overline{z}\wedge dz+\partial_{z}fdz\wedge dz=0.$$ Then one can prove the Cauchy integral formula as follows: Suppose $\Omega\subset U$ is a relatively compact set with piecewise smooth boundary and $U$ is an open subset of complex plane, and $f:U\to\mathbb{C}$ is holomorphic. Then for any $a\in \Omega$ , we have $$f(a)=\frac{1}{2\pi I}\int_{\partial\Omega}\frac{f(z)}{z-a}dz.$$ Proof: Let $\Omega_\epsilon=\Omega-D_\epsilon(a).$ Then we consider the one form $f(z)/(z-a)\in\Lambda^1(\Omega_\epsilon).$ By Stoke's theorem ( $\int_{\Sigma}d\omega=\int_{\partial \Sigma}\omega$ ) we have $$ \int_{\partial\Omega_\epsilon}\frac{f(z)}{z-a}dz=\int_{\Omega_\epsilon}d\left(\frac{f(z)}{z-a}dz\right)=0 $$ since $f/(z-a)$ is holomorphic on $\Omega_\epsilon$ . Now $$ \int_{\partial\Omega_\epsilon}\frac{f(z)}{z-a}dz=\int_{\partial\Omega}\frac{f(z)}{z-a}dz-\int_{\partial D_\epsilon(a)}\frac{f(z)}{z-a}dz=0. $$ Taking $\epsilon\to 0$ the second term goes to $2\pi if(a).$ This concludes the proof. However, my graduate complex analysis professor told us that one cannot apply Stoke's theorem directly until one verifies that $f'$ is integrable. I never learned Stoke's theorem properly so I wonder: What do we need to know prior to the proof above about $f,f'$ in order for the proof to be valid? (differentiability of $f'$ or something like that, or even smoothness of $f$ ?) What should we have proved before this point to make the above proof work? Is there a way of using differential forms and Stokes theorem to prove the Cauchy integral formula, without going into the traditional Goursat's theorem for triangles and polygons and all that? Are there any recommended references on this topic? Thanks in advance","In my undergrad complex analysis, our professor used a quick way to derive the Cauchy integral formula (without Goursat's theorem and all that) with the following setup: Let be an open set of . Consider a complex function as a zero form on , i.e., Then analyticity of is equivalent to Cauchy-Riemann equation , which is equivalent to the form being closed: Then one can prove the Cauchy integral formula as follows: Suppose is a relatively compact set with piecewise smooth boundary and is an open subset of complex plane, and is holomorphic. Then for any , we have Proof: Let Then we consider the one form By Stoke's theorem ( ) we have since is holomorphic on . Now Taking the second term goes to This concludes the proof. However, my graduate complex analysis professor told us that one cannot apply Stoke's theorem directly until one verifies that is integrable. I never learned Stoke's theorem properly so I wonder: What do we need to know prior to the proof above about in order for the proof to be valid? (differentiability of or something like that, or even smoothness of ?) What should we have proved before this point to make the above proof work? Is there a way of using differential forms and Stokes theorem to prove the Cauchy integral formula, without going into the traditional Goursat's theorem for triangles and polygons and all that? Are there any recommended references on this topic? Thanks in advance","U \mathbb{C} f:U\to\mathbb{C} U f\in \Lambda^0(U). f \partial_{\bar{z}}f=0 f(z)dz\in\Lambda^1(U) d(fdz)=df\wedge dz=\partial_{\bar{z}}fd\overline{z}\wedge dz+\partial_{z}fdz\wedge dz=0. \Omega\subset U U f:U\to\mathbb{C} a\in \Omega f(a)=\frac{1}{2\pi I}\int_{\partial\Omega}\frac{f(z)}{z-a}dz. \Omega_\epsilon=\Omega-D_\epsilon(a). f(z)/(z-a)\in\Lambda^1(\Omega_\epsilon). \int_{\Sigma}d\omega=\int_{\partial \Sigma}\omega 
\int_{\partial\Omega_\epsilon}\frac{f(z)}{z-a}dz=\int_{\Omega_\epsilon}d\left(\frac{f(z)}{z-a}dz\right)=0
 f/(z-a) \Omega_\epsilon 
\int_{\partial\Omega_\epsilon}\frac{f(z)}{z-a}dz=\int_{\partial\Omega}\frac{f(z)}{z-a}dz-\int_{\partial D_\epsilon(a)}\frac{f(z)}{z-a}dz=0.
 \epsilon\to 0 2\pi if(a). f' f,f' f' f","['complex-analysis', 'differential-forms', 'stokes-theorem']"
