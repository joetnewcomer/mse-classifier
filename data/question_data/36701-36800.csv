,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Expected value of $X$ given $X > 15$,Expected value of  given,X X > 15,"If $X$ is a poisson random variable with $\lambda =\frac{1}{15}$, what is the expected value of $X$ given $X > 15$ ? I should know this but it's been a while since my intro to probability class.","If $X$ is a poisson random variable with $\lambda =\frac{1}{15}$, what is the expected value of $X$ given $X > 15$ ? I should know this but it's been a while since my intro to probability class.",,['probability']
1,Autocorrelation function of derivative,Autocorrelation function of derivative,,"I have a question, I am stuck on for quite some time now. Imagine you can choose a two dimensional autocorrelation function $C_V(x,y)$. From this I can create the two dimensional random process $V(x,y)$ (using the Wiener–Khinchin theorem and phase-randomization). So far so good. What I want in addition, is that the $x$-Integral of the autocorrelation function of the $y$-derivative is zero. So: $\int_{-\infty}^{\infty} C_F(x)\,$d$x = 0$. With: $C_F(s_x) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty}F(x+s_x,y+s_y)F(x,y)\,\text{d}x\,\text{d}y \, |_{s_y=0}$ $F(x,y)=\frac{\partial V(x,y)}{\partial y}$. So the question is, how to choose $C_V(x,y)$ to obtain this (or is it even possible?). Also $C_V$ can be assumed to be radial symmetric. To put this in perspective: I want to look at a particle, moving in the random (but correlated) potential V(x,y), which experiences the sideway Force F(x,y). Currently I am interested in a force with the specific setup above. What I have done so far is calculating : $\int_{-\infty}^{\infty} \frac{\partial^n C_V(x,y)}{\partial y^n}|_{y=0}\,$d$x$ and tried to express it in terms of $C_F$ to connect these two functions. Also played around a lot with mathematica and numerics but did not find any expression linking these two.  The correlation function I usually start with (because of specific reasons to my problem) is : $C_V(x,y)=(1-a(x^2+y^2)) \cdot e^{-b(x^2+y^2)}$ But I am not bound on this form. I hope someone has an idea or knows where to read up something about this. Thanks :)","I have a question, I am stuck on for quite some time now. Imagine you can choose a two dimensional autocorrelation function $C_V(x,y)$. From this I can create the two dimensional random process $V(x,y)$ (using the Wiener–Khinchin theorem and phase-randomization). So far so good. What I want in addition, is that the $x$-Integral of the autocorrelation function of the $y$-derivative is zero. So: $\int_{-\infty}^{\infty} C_F(x)\,$d$x = 0$. With: $C_F(s_x) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty}F(x+s_x,y+s_y)F(x,y)\,\text{d}x\,\text{d}y \, |_{s_y=0}$ $F(x,y)=\frac{\partial V(x,y)}{\partial y}$. So the question is, how to choose $C_V(x,y)$ to obtain this (or is it even possible?). Also $C_V$ can be assumed to be radial symmetric. To put this in perspective: I want to look at a particle, moving in the random (but correlated) potential V(x,y), which experiences the sideway Force F(x,y). Currently I am interested in a force with the specific setup above. What I have done so far is calculating : $\int_{-\infty}^{\infty} \frac{\partial^n C_V(x,y)}{\partial y^n}|_{y=0}\,$d$x$ and tried to express it in terms of $C_F$ to connect these two functions. Also played around a lot with mathematica and numerics but did not find any expression linking these two.  The correlation function I usually start with (because of specific reasons to my problem) is : $C_V(x,y)=(1-a(x^2+y^2)) \cdot e^{-b(x^2+y^2)}$ But I am not bound on this form. I hope someone has an idea or knows where to read up something about this. Thanks :)",,"['probability', 'signal-processing', 'random-walk', 'correlation']"
2,On dispersion of random variables,On dispersion of random variables,,"Let $X$ and $Y$ be two i.i.d. random variables. I am interested in the quantity $$m(X):=\mathbb{E}[X|X>Y] - \mathbb{E}[X|X < Y].$$ It is not hard to see that $m(X) \geq 0$ and that $m(X) = 0$ if and only if $X$ is a constant, almost surely. So, one may think about $m(X)$ as measuring the dispersion of $X$ in a sense. My question is there a relation between $m(X)$ to other known measures of dispersion such as variance of mean absolute deviation?","Let $X$ and $Y$ be two i.i.d. random variables. I am interested in the quantity $$m(X):=\mathbb{E}[X|X>Y] - \mathbb{E}[X|X < Y].$$ It is not hard to see that $m(X) \geq 0$ and that $m(X) = 0$ if and only if $X$ is a constant, almost surely. So, one may think about $m(X)$ as measuring the dispersion of $X$ in a sense. My question is there a relation between $m(X)$ to other known measures of dispersion such as variance of mean absolute deviation?",,"['probability', 'statistics', 'expectation', 'conditional-expectation']"
3,Expected number of heads in n coin tosses,Expected number of heads in n coin tosses,,"What is the expected number of heads in n coin tosses, where the probability of landing one head is p? I know that the probability of having k heads in n tosses is $$\ \binom{n}{k}p^k(1-p)^{n-k}$$ So, the expected number of heads in n tosses is $$\sum_{k=0}^n k\binom{n}{k}p^k(1-p)^{n-k}$$ But I'm not sure how to simplify this further. Any help would be appreciated!","What is the expected number of heads in n coin tosses, where the probability of landing one head is p? I know that the probability of having k heads in n tosses is $$\ \binom{n}{k}p^k(1-p)^{n-k}$$ So, the expected number of heads in n tosses is $$\sum_{k=0}^n k\binom{n}{k}p^k(1-p)^{n-k}$$ But I'm not sure how to simplify this further. Any help would be appreciated!",,"['probability', 'expectation']"
4,Probability in exam (Possibly binomially distributed),Probability in exam (Possibly binomially distributed),,"Question There are $6$ questions on an exam which in each of them has two options to choose from. Each correct answer will result in 1 point. The well prepared student has a probability of $90\%$ of getting a correct answer from each question. The lazy student who has not prepared for the exam will pick a choice randomly on each question. Approximately 2/3 of all students are well prepared. (a) What is the probability that the well prepared student gets 3 points from the exam ? (b) What is the probability that the randomly picked student receives 3 points from the exam ? Attempt to solve: Now i would make assumption that this is binomially distributed. Binomial distribution would be defined as: $$ Pr(k;n,p)=Pr(X=k)=\binom{n}{k}p^k(1-p)^{n-k} $$ We mark well prepared students with random variable $X$ Parameters $P$ = probability for getting a single question correct. $n$ = number of total points from the exam. $k$ = number of points actually recieved from the exam. (a) $P=0.9 \quad$ we know this because it was provided in the question. $n=6 \quad$ 6 points is maximum from the whole exam. $k=3 \quad$ we want probability for exactly 3 points from the exam. $$Pr(X=3)=\binom{6}{3}0.9^3(1-0.9)^{6-3}$$ $$Pr(X=3) \approx 1.46 \%$$ (b) We can mark lazy students with random variable $Y$ $$Pr(Y=3)=\binom{6}{3}0.5^3(1-0.5)^{6-3}$$ $$Pr(Y=3)\approx 31.25\% $$ Now that we have probabilities for both well prepared and lazy students scoring exactly 3 points. And we know that $\frac{2}{3}$ of all students are well prepared and $\frac{1}{3}$ are lazy. We don't know exactly how many well prepared and how many lazy students attend the exam but we do know the proportions of each group. We can mark these proportions with: $A=$ Well prepared student. $B=$ Lazy student. $$A=\frac{2}{3}, \quad B=\frac{1}{3}$$ Now approximately $A*0.0146 \approx $ number of well prepared students scoring exactly 3 points from the exam. $B*0.3125 \approx $ number of lazy students scoring exactly 3 points from the exam. In our case the result will be proportional since we don't know the actual size of these groups. Groups $A$ and $B$ don't have an intersection so in a sense they are independent of each other. $$ Pr(X,Y=3 | x_i,y_i \in A+B)= (A(Pr(X=3)))+(B(Pr(Y=3)))$$ $$ Pr(X,Y=3 | x_i,y_i \in A+B)= (\frac{2}{3}*0.0146)+(\frac{1}{3}*0.3125)  $$ $$ Pr(X,Y=3 | x_i,y_i \in A+B)\approx 11.39\% $$ Now I would like to have some feedback on if my reasoning seems correct. If it isn't correct comment an alternative solution that would be highly appreciated. I have some degree of uncertainty on question (b) whether my solution is correct or not. Thanks, Tuki","Question There are questions on an exam which in each of them has two options to choose from. Each correct answer will result in 1 point. The well prepared student has a probability of of getting a correct answer from each question. The lazy student who has not prepared for the exam will pick a choice randomly on each question. Approximately 2/3 of all students are well prepared. (a) What is the probability that the well prepared student gets 3 points from the exam ? (b) What is the probability that the randomly picked student receives 3 points from the exam ? Attempt to solve: Now i would make assumption that this is binomially distributed. Binomial distribution would be defined as: We mark well prepared students with random variable Parameters = probability for getting a single question correct. = number of total points from the exam. = number of points actually recieved from the exam. (a) we know this because it was provided in the question. 6 points is maximum from the whole exam. we want probability for exactly 3 points from the exam. (b) We can mark lazy students with random variable Now that we have probabilities for both well prepared and lazy students scoring exactly 3 points. And we know that of all students are well prepared and are lazy. We don't know exactly how many well prepared and how many lazy students attend the exam but we do know the proportions of each group. We can mark these proportions with: Well prepared student. Lazy student. Now approximately number of well prepared students scoring exactly 3 points from the exam. number of lazy students scoring exactly 3 points from the exam. In our case the result will be proportional since we don't know the actual size of these groups. Groups and don't have an intersection so in a sense they are independent of each other. Now I would like to have some feedback on if my reasoning seems correct. If it isn't correct comment an alternative solution that would be highly appreciated. I have some degree of uncertainty on question (b) whether my solution is correct or not. Thanks, Tuki","6 90\%  Pr(k;n,p)=Pr(X=k)=\binom{n}{k}p^k(1-p)^{n-k}  X P n k P=0.9 \quad n=6 \quad k=3 \quad Pr(X=3)=\binom{6}{3}0.9^3(1-0.9)^{6-3} Pr(X=3) \approx 1.46 \% Y Pr(Y=3)=\binom{6}{3}0.5^3(1-0.5)^{6-3} Pr(Y=3)\approx 31.25\%  \frac{2}{3} \frac{1}{3} A= B= A=\frac{2}{3}, \quad B=\frac{1}{3} A*0.0146 \approx  B*0.3125 \approx  A B  Pr(X,Y=3 | x_i,y_i \in A+B)= (A(Pr(X=3)))+(B(Pr(Y=3)))  Pr(X,Y=3 | x_i,y_i \in A+B)= (\frac{2}{3}*0.0146)+(\frac{1}{3}*0.3125)    Pr(X,Y=3 | x_i,y_i \in A+B)\approx 11.39\% ","['probability', 'proof-verification', 'probability-distributions']"
5,Conditions on angles between three points on a sphere (which are uniformly distributed),Conditions on angles between three points on a sphere (which are uniformly distributed),,"Question: Let $A,B,C$ be three random, uniformly distributed, independent points on a sphere. What is the probability that none of these three points is at an angle superior than $\pi/2$ from the two others. As of right now, I know that wlog, we can assume that $A$ is on the north pole and that $B$ is on a great circle passing through the north and south pole. Then, I am trying to calculate the area which isn't covered by the northern hemisphere or by the hemisphere centered at $B$ . I have trouble figuring out how to deal clearly with all of these cases. Thank you in advance for you help!","Question: Let be three random, uniformly distributed, independent points on a sphere. What is the probability that none of these three points is at an angle superior than from the two others. As of right now, I know that wlog, we can assume that is on the north pole and that is on a great circle passing through the north and south pole. Then, I am trying to calculate the area which isn't covered by the northern hemisphere or by the hemisphere centered at . I have trouble figuring out how to deal clearly with all of these cases. Thank you in advance for you help!","A,B,C \pi/2 A B B","['calculus', 'probability', 'uniform-distribution', 'independence']"
6,Characterization for the convergence in distribution,Characterization for the convergence in distribution,,"Let $(E,d)$ be a metric space such that the convergence is characterized by the following equivalence \begin{equation} x_n\to x\qquad\text{ if and only if }\qquad f(x_n)\to f(x) \text{ for all }f\in T, \tag{1} \end{equation} where $T$ is a given family of function from $E$ to $\mathbb{R}$, called ""testing functions."" Now, let $X_n$ a sequence of random variable with values in the metric space $E$. Is there a relation between the convergence in distribution of the sequence $X_n$ and the previous equivalence (1)? In particolare we know that $X_n\to X$ in distribution if and only if $$\mathbb{E}[g(X_n)]\to \mathbb{E}[g(X)]\text{ for all }g\in\mathcal{C}_b(E).\tag{2}$$ How can we ""simplify"" (2) using (1)?","Let $(E,d)$ be a metric space such that the convergence is characterized by the following equivalence \begin{equation} x_n\to x\qquad\text{ if and only if }\qquad f(x_n)\to f(x) \text{ for all }f\in T, \tag{1} \end{equation} where $T$ is a given family of function from $E$ to $\mathbb{R}$, called ""testing functions."" Now, let $X_n$ a sequence of random variable with values in the metric space $E$. Is there a relation between the convergence in distribution of the sequence $X_n$ and the previous equivalence (1)? In particolare we know that $X_n\to X$ in distribution if and only if $$\mathbb{E}[g(X_n)]\to \mathbb{E}[g(X)]\text{ for all }g\in\mathcal{C}_b(E).\tag{2}$$ How can we ""simplify"" (2) using (1)?",,"['real-analysis', 'probability', 'functional-analysis', 'measure-theory']"
7,Non-differentiability of a Markov diffusion process,Non-differentiability of a Markov diffusion process,,"I was reading through these notes (link here) on Markov diffusion processes and I'm confused about one of the definitions and its properties. It is stated that the Markov diffusion process satisfies the continuity condition in that $P(|X_t - X_s | \ge \epsilon | X_s = x) = o(t-s)$. It then goes on to say that this condition implies that the sample paths of a diffusion process are not differentiable. I am confused by this statement. From what I understand, the $o$-notation here means that $\lim_{t\rightarrow s} \frac{o(t-s)}{t-s} = 0$. For example, we have that $x^5$ is $o(x)$ as $x\rightarrow 0$. This makes me think that if $f(x)$ is $o(x)$ as $x \rightarrow 0$, i.. the rate of decay of $f(x)$ compared to that of $x$ is faster as $x \rightarrow 0$. Hence, I do not understand why in the link it says: ""the sample paths of a diffusion process are not differentiable : if they where, then the right hand side of the above equation would have to be 0 when  $t-s \ll 1$ "". Can anyone help me show (more rigorously) how this implies that $P(\frac{|X_t - X_s |}{t-s} \ge \epsilon | X_s = x) $ does not approach 0 as $t \rightarrow s$?","I was reading through these notes (link here) on Markov diffusion processes and I'm confused about one of the definitions and its properties. It is stated that the Markov diffusion process satisfies the continuity condition in that $P(|X_t - X_s | \ge \epsilon | X_s = x) = o(t-s)$. It then goes on to say that this condition implies that the sample paths of a diffusion process are not differentiable. I am confused by this statement. From what I understand, the $o$-notation here means that $\lim_{t\rightarrow s} \frac{o(t-s)}{t-s} = 0$. For example, we have that $x^5$ is $o(x)$ as $x\rightarrow 0$. This makes me think that if $f(x)$ is $o(x)$ as $x \rightarrow 0$, i.. the rate of decay of $f(x)$ compared to that of $x$ is faster as $x \rightarrow 0$. Hence, I do not understand why in the link it says: ""the sample paths of a diffusion process are not differentiable : if they where, then the right hand side of the above equation would have to be 0 when  $t-s \ll 1$ "". Can anyone help me show (more rigorously) how this implies that $P(\frac{|X_t - X_s |}{t-s} \ge \epsilon | X_s = x) $ does not approach 0 as $t \rightarrow s$?",,"['probability', 'probability-theory', 'stochastic-processes', 'stochastic-calculus', 'stochastic-analysis']"
8,Probability of the highest roll in two die pools being the same,Probability of the highest roll in two die pools being the same,,"Say we roll n identical, fair dice, each with d sides. (Every side comes up with the same probability.) On each die, the sides are numbered from $1$ to d with no repeating numbers, as you would expect. So it's an ordinary d sided die pool. How would we calculate the odds of the highest rolled die value from a given dice pool equaling the highest rolled die value from a different dice pool?","Say we roll n identical, fair dice, each with d sides. (Every side comes up with the same probability.) On each die, the sides are numbered from $1$ to d with no repeating numbers, as you would expect. So it's an ordinary d sided die pool. How would we calculate the odds of the highest rolled die value from a given dice pool equaling the highest rolled die value from a different dice pool?",,"['probability', 'dice']"
9,Subset sum - probability of solution existence,Subset sum - probability of solution existence,,We have a set of integers in which there may be numbers from $-n$ to $n$ (excluding of course zero). The set contains $2\cdot k$ numbers ($2 \cdot k < n$). We assume that the numbers are random and the probability of random numbers is equal. What is theoretically the chance of a solution existence to solve a subset sum problem for this set of numbers? -- Edit: Number of positive numbers in set is equal number of negative numbers (this is $k$).,We have a set of integers in which there may be numbers from $-n$ to $n$ (excluding of course zero). The set contains $2\cdot k$ numbers ($2 \cdot k < n$). We assume that the numbers are random and the probability of random numbers is equal. What is theoretically the chance of a solution existence to solve a subset sum problem for this set of numbers? -- Edit: Number of positive numbers in set is equal number of negative numbers (this is $k$).,,"['probability', 'combinatorics', 'number-theory', 'statistics']"
10,Equivalence of definitions of a multivariate normal distribution,Equivalence of definitions of a multivariate normal distribution,,"Fix a probability space $(\Omega,\mathcal{F},\mathbb{P})$. I have seen at various times the following definitions of a multivariate Gaussian distribution: A random vector $$X=(X_1,\ldots,X_d):\Omega\to\mathbb{R}^d$$ is a multivariate Gaussian if $\sum_{i=0}^d c_i X_i$ is normally distributed for all $c_i\in\mathbb{R}$. A random vector $$X=(X_1,\ldots,X_d):\Omega\to\mathbb{R}^d$$ is a multivariate Gaussian if there exist independent standard normal random variables $Y_1,\ldots,Y_d:\Omega\to\mathbb{R}$, a matrix $A\in\mathrm{M}_d(\mathbb{R})$, and a vector $v\in\mathbb{R}^d$ such that $$X=AY+v.$$ Now, it is clear that definition 2 implies definition 1, but I don't see why the converse should hold true. I suspect this might simply be an elementary linear algebra trick (such as Gaussian elimination), but I don't know for sure. My main difficulty is somehow obtaining independent random variables from $X_1,\ldots,X_d$ which may be dependent.","Fix a probability space $(\Omega,\mathcal{F},\mathbb{P})$. I have seen at various times the following definitions of a multivariate Gaussian distribution: A random vector $$X=(X_1,\ldots,X_d):\Omega\to\mathbb{R}^d$$ is a multivariate Gaussian if $\sum_{i=0}^d c_i X_i$ is normally distributed for all $c_i\in\mathbb{R}$. A random vector $$X=(X_1,\ldots,X_d):\Omega\to\mathbb{R}^d$$ is a multivariate Gaussian if there exist independent standard normal random variables $Y_1,\ldots,Y_d:\Omega\to\mathbb{R}$, a matrix $A\in\mathrm{M}_d(\mathbb{R})$, and a vector $v\in\mathbb{R}^d$ such that $$X=AY+v.$$ Now, it is clear that definition 2 implies definition 1, but I don't see why the converse should hold true. I suspect this might simply be an elementary linear algebra trick (such as Gaussian elimination), but I don't know for sure. My main difficulty is somehow obtaining independent random variables from $X_1,\ldots,X_d$ which may be dependent.",,"['linear-algebra', 'probability', 'probability-theory', 'normal-distribution']"
11,Likelihood function sufficient statistic,Likelihood function sufficient statistic,,"Let $\mathbb{P} = \{p_{\theta}: \theta \in \Theta\}$ be a family of densities. Assume that the parameter space $\Theta$ is finite, that is $\Theta = \{\theta_0, \theta_1, \cdots, \theta_m\}$. Prove that the likelihood function, which is defined as $T(X) = (p_{\theta}(X))_{\theta \in \Theta}$ is sufficient but in general is not minimal sufficient. Does the notation $T(\mathbf{X}) = (p_{\theta}(\mathbf{X}))_{\theta \in \Theta}$ just mean the likelihood function at a fixed $\theta$? Or does it mean a set of densities? I.e., $T(\mathbf{X}) = (p_{\theta}(\mathbf{X}))_{\theta \in \Theta} = (T_0(\mathbf{X}), \cdots, T_m(\mathbf{X})) = (p_{\theta_0}(\mathbf{X}), \cdots, p_{\theta_m}(\mathbf{X}))$? How do I exactly prove this? Do I apply the factorization theorem? How do I show it is not minimal?","Let $\mathbb{P} = \{p_{\theta}: \theta \in \Theta\}$ be a family of densities. Assume that the parameter space $\Theta$ is finite, that is $\Theta = \{\theta_0, \theta_1, \cdots, \theta_m\}$. Prove that the likelihood function, which is defined as $T(X) = (p_{\theta}(X))_{\theta \in \Theta}$ is sufficient but in general is not minimal sufficient. Does the notation $T(\mathbf{X}) = (p_{\theta}(\mathbf{X}))_{\theta \in \Theta}$ just mean the likelihood function at a fixed $\theta$? Or does it mean a set of densities? I.e., $T(\mathbf{X}) = (p_{\theta}(\mathbf{X}))_{\theta \in \Theta} = (T_0(\mathbf{X}), \cdots, T_m(\mathbf{X})) = (p_{\theta_0}(\mathbf{X}), \cdots, p_{\theta_m}(\mathbf{X}))$? How do I exactly prove this? Do I apply the factorization theorem? How do I show it is not minimal?",,"['probability', 'probability-theory', 'statistics']"
12,Probability ratio convergence in limit,Probability ratio convergence in limit,,"The following is the question : Given random variables $X_1 \leq X_2 \leq \cdots$ such that $E[X_n] \sim A n^{\alpha}$, where $A,\alpha > 0$ ($\sim$ means that the ratio of the two quantities goes to $1$ as $n$ tends to infinitely). Given that $Var(X_n) \leq Bn^\beta$, where $\beta < 2\alpha$, and $B$ is some constant, please show that convergence of $\frac{X_n}{n^\alpha} \to A$ almost surely. Note that $X_n$ are not given independent. What I can conclude is the following : Suppose we drop the asymptotic and just assume equality (we can always compensate for this by fixing some small $\delta > 0$ and choosing sufficiently large $n$ for which the ratio is in $(1-\delta,1+\delta)$) If $Y_n = \frac{X_n}{n^{\alpha}}$, then $\Pr(|Y-A| > \epsilon) \leq \frac{Bn^{\beta-2\alpha}}{\epsilon^2}$, which goes to zero for all $\epsilon$ as $\beta < 2 \alpha$. Hence, we have convergence in probability. This means, furthermore, that there is an a.s. convergent subsequence $Y_{n_k}$ to $A$. In fact, any subsequence of $Y_n$ will have a subsequence convergent to $A$. Now, note that $X_n$ are monotonic, but $Y_n$ need not be. So I cannot conclude from the above that $Y_n \to A$. I need help to finish this argument.","The following is the question : Given random variables $X_1 \leq X_2 \leq \cdots$ such that $E[X_n] \sim A n^{\alpha}$, where $A,\alpha > 0$ ($\sim$ means that the ratio of the two quantities goes to $1$ as $n$ tends to infinitely). Given that $Var(X_n) \leq Bn^\beta$, where $\beta < 2\alpha$, and $B$ is some constant, please show that convergence of $\frac{X_n}{n^\alpha} \to A$ almost surely. Note that $X_n$ are not given independent. What I can conclude is the following : Suppose we drop the asymptotic and just assume equality (we can always compensate for this by fixing some small $\delta > 0$ and choosing sufficiently large $n$ for which the ratio is in $(1-\delta,1+\delta)$) If $Y_n = \frac{X_n}{n^{\alpha}}$, then $\Pr(|Y-A| > \epsilon) \leq \frac{Bn^{\beta-2\alpha}}{\epsilon^2}$, which goes to zero for all $\epsilon$ as $\beta < 2 \alpha$. Hence, we have convergence in probability. This means, furthermore, that there is an a.s. convergent subsequence $Y_{n_k}$ to $A$. In fact, any subsequence of $Y_n$ will have a subsequence convergent to $A$. Now, note that $X_n$ are monotonic, but $Y_n$ need not be. So I cannot conclude from the above that $Y_n \to A$. I need help to finish this argument.",,"['probability', 'probability-theory', 'probability-limit-theorems', 'law-of-large-numbers']"
13,Mean and variance of a Brownian motion process,Mean and variance of a Brownian motion process,,"Say $X(t),t\geq 0,$ denotes a Brownian motion process with drift parameter $\mu=3$ and variance parameter $\sigma^2 = 9$. If $X(0)=10$ I want to find $E[X(2)]$ $Var[X(2)]$ $P(X(2)>20)$ My reasoning is the following: Since the Brownian motion has a Gaussian probability density with mean $t\mu$ and variance $t\sigma^2$, I would say that $E[X(2)] = 2\times 3 = 6$ $Var[X(2)] = 2\times 9 = 18$ $P(X(2)>20) = \int_{20}^\infty{\frac{1}{6\sqrt{2\pi}}e^{-(x-6)^2/36}dx}$ Is my reasoning correct?","Say $X(t),t\geq 0,$ denotes a Brownian motion process with drift parameter $\mu=3$ and variance parameter $\sigma^2 = 9$. If $X(0)=10$ I want to find $E[X(2)]$ $Var[X(2)]$ $P(X(2)>20)$ My reasoning is the following: Since the Brownian motion has a Gaussian probability density with mean $t\mu$ and variance $t\sigma^2$, I would say that $E[X(2)] = 2\times 3 = 6$ $Var[X(2)] = 2\times 9 = 18$ $P(X(2)>20) = \int_{20}^\infty{\frac{1}{6\sqrt{2\pi}}e^{-(x-6)^2/36}dx}$ Is my reasoning correct?",,"['probability', 'probability-theory', 'stochastic-processes', 'brownian-motion']"
14,"If $W$ is a standard Brownian motion, does $W(1)$ take every real number?","If  is a standard Brownian motion, does  take every real number?",W W(1),"Let $(\Omega,\mathcal{F},P)$ be a probability space. Let $W:[0,\infty)\times \Omega\rightarrow\mathbb{R}$ be a standard Brownian motion. Is it true that for all $x\in\mathbb{R}$ there exists $\omega\in\Omega$ such that $W(1,\omega)=x$? I do not know if the question has a positive or negative answer. I know that $P(W(1)\in [a,b])>0$ for all real numbers $a<b$, but I do not think that suffices. I have no idea on how to prove the existence of such an $\omega$, since it seems to me that the proof may use an explicit form of $\Omega$. EDIT : As I read in a comment below, this statement is not true. My doubt came from reading the proof of Lemma 5.22 in An Introduction to Computational Stochastic PDEs . The step I do not completely understand is the following: from $E[W(t)|W(1)]=t \,W(1)$, where $W$ is a Brownian motion and $0\leq t\leq 1$, it is stated that $E[W(t)|W(1)=0]=0$. One of the possible definitions that I studied for $E[W(t)|W(1)]$, and in general for $E[X|Y]$, where $X$ and $Y$ random variables, is $E[X|Y](\omega):=E[X|Y=Y(\omega)]$, where $E[X|Y=y]=\int_{\mathbb{R}} x\,P_{X|Y=y}(dx)$, being $P_{X|Y=y}$ the $P_Y$-unique probability satisfying $P(X\in A,Y\in B)=\int_B P_{X|Y=y}(A)\,P_Y(dy)$. In this example, $E[W(t)|W(1)=W(1)(\omega)]=E[W(t)|W(1)](\omega)=t\,W(1)(\omega)$. I understand that, if $W(1)(\omega)=0$ for some $\omega\in\Omega$, then $E[W(t)|W(1)=0]=t\cdot 0=0$. But if for our particular probability space $(\Omega,\mathcal{F},P)$ and our particular Brownian motion $W$ there is no $\omega$ satisfying $W(1)(\omega)=0$, then I do not see that $E[W(t)|W(1)]=t\,W(1)$ implies that $E[W(t)|W(1)=0]=0$. Could you explain this to me using probability theory, and not just ""intuition""?","Let $(\Omega,\mathcal{F},P)$ be a probability space. Let $W:[0,\infty)\times \Omega\rightarrow\mathbb{R}$ be a standard Brownian motion. Is it true that for all $x\in\mathbb{R}$ there exists $\omega\in\Omega$ such that $W(1,\omega)=x$? I do not know if the question has a positive or negative answer. I know that $P(W(1)\in [a,b])>0$ for all real numbers $a<b$, but I do not think that suffices. I have no idea on how to prove the existence of such an $\omega$, since it seems to me that the proof may use an explicit form of $\Omega$. EDIT : As I read in a comment below, this statement is not true. My doubt came from reading the proof of Lemma 5.22 in An Introduction to Computational Stochastic PDEs . The step I do not completely understand is the following: from $E[W(t)|W(1)]=t \,W(1)$, where $W$ is a Brownian motion and $0\leq t\leq 1$, it is stated that $E[W(t)|W(1)=0]=0$. One of the possible definitions that I studied for $E[W(t)|W(1)]$, and in general for $E[X|Y]$, where $X$ and $Y$ random variables, is $E[X|Y](\omega):=E[X|Y=Y(\omega)]$, where $E[X|Y=y]=\int_{\mathbb{R}} x\,P_{X|Y=y}(dx)$, being $P_{X|Y=y}$ the $P_Y$-unique probability satisfying $P(X\in A,Y\in B)=\int_B P_{X|Y=y}(A)\,P_Y(dy)$. In this example, $E[W(t)|W(1)=W(1)(\omega)]=E[W(t)|W(1)](\omega)=t\,W(1)(\omega)$. I understand that, if $W(1)(\omega)=0$ for some $\omega\in\Omega$, then $E[W(t)|W(1)=0]=t\cdot 0=0$. But if for our particular probability space $(\Omega,\mathcal{F},P)$ and our particular Brownian motion $W$ there is no $\omega$ satisfying $W(1)(\omega)=0$, then I do not see that $E[W(t)|W(1)]=t\,W(1)$ implies that $E[W(t)|W(1)=0]=0$. Could you explain this to me using probability theory, and not just ""intuition""?",,"['probability', 'probability-theory', 'stochastic-processes', 'stochastic-calculus', 'brownian-motion']"
15,Make a point process from another?,Make a point process from another?,,"Blue boats are passing on a river and their arrival times are modeled by a renewal point process. Place red boats on the river according to a point process $P$ such that the arrival times of all of the boats (the superposition process) becomes another renewal process. Find $P$. In other words, find a point process whose superposition with a given renewal process is another renewal process. Note the causality constraint : when you place red boats, you don't have any information about the arrival times of the blue boats in the future. What I found was not enough: A solution for a similar question here , without causality Poisson and alternating renewal processes with superposition a renewal process Renewal Processes Decomposable into i.i.d. Components Superposition and Decomposition of Stationary Point Processes Almost Sure Comparisons of Renewal Processes and Poisson Processes Superposition of Renewal Processes On the Superposition of Point Processes Pairs of renewal processes whose superposition is a renewal process ON QUEUEING SYSTEMS VITH RENEWAL DEPARTURE PROCESSES","Blue boats are passing on a river and their arrival times are modeled by a renewal point process. Place red boats on the river according to a point process $P$ such that the arrival times of all of the boats (the superposition process) becomes another renewal process. Find $P$. In other words, find a point process whose superposition with a given renewal process is another renewal process. Note the causality constraint : when you place red boats, you don't have any information about the arrival times of the blue boats in the future. What I found was not enough: A solution for a similar question here , without causality Poisson and alternating renewal processes with superposition a renewal process Renewal Processes Decomposable into i.i.d. Components Superposition and Decomposition of Stationary Point Processes Almost Sure Comparisons of Renewal Processes and Poisson Processes Superposition of Renewal Processes On the Superposition of Point Processes Pairs of renewal processes whose superposition is a renewal process ON QUEUEING SYSTEMS VITH RENEWAL DEPARTURE PROCESSES",,"['probability', 'probability-theory', 'statistics', 'stochastic-processes', 'queueing-theory']"
16,Conditional expectation and stopping times,Conditional expectation and stopping times,,"I think I found a way to prove a result but I have doubts about it. I may have made a mistake. ($X$ is a geometric Brownian motion and I do not want to use the strong Markov property) I have proved that for any $t \in [0,\infty)$  $$ \mathbb E\bigg[\int_t^\infty G(X_u)~\bigg|~F_t\bigg]= U_t \tag 1 $$ for a certain function $G$ such that it is well defined and a certain process $U$. Can I conclude that for any finite stopping time $\tau$: $$ \mathbb E\bigg[\int_\tau^\infty G(X_u)~\big|~F_\tau]  = U_\tau \text{ ?} $$ I think it is true since for any $\omega \in \Omega$ and (I am not sure about this part because it looks too obvious) we get: \begin{align} \mathbb E\bigg[\int_\tau^\infty G(X_u)~\bigg|~F_\tau\bigg](\omega)&= \mathbb E\bigg[\int_{\tau(\omega)}^\infty G(X_u)~\bigg|~F_{\tau(\omega)}\bigg](\omega) \tag 2 \\ &= U_{\tau(\omega)}(\omega) \end{align} since $\tau$ is finite and by $(1)$. But is $(2)$ true and do you know how to prove it? I read on one forum that it is true and it is called ""local property of conditional expectation"" but I did not find it anywhere else. Thank you in advance for your help. Edit: Does anyone know? It is important because I proved a result using this property and my proof will be wrong if this property is not correct.","I think I found a way to prove a result but I have doubts about it. I may have made a mistake. ($X$ is a geometric Brownian motion and I do not want to use the strong Markov property) I have proved that for any $t \in [0,\infty)$  $$ \mathbb E\bigg[\int_t^\infty G(X_u)~\bigg|~F_t\bigg]= U_t \tag 1 $$ for a certain function $G$ such that it is well defined and a certain process $U$. Can I conclude that for any finite stopping time $\tau$: $$ \mathbb E\bigg[\int_\tau^\infty G(X_u)~\big|~F_\tau]  = U_\tau \text{ ?} $$ I think it is true since for any $\omega \in \Omega$ and (I am not sure about this part because it looks too obvious) we get: \begin{align} \mathbb E\bigg[\int_\tau^\infty G(X_u)~\bigg|~F_\tau\bigg](\omega)&= \mathbb E\bigg[\int_{\tau(\omega)}^\infty G(X_u)~\bigg|~F_{\tau(\omega)}\bigg](\omega) \tag 2 \\ &= U_{\tau(\omega)}(\omega) \end{align} since $\tau$ is finite and by $(1)$. But is $(2)$ true and do you know how to prove it? I read on one forum that it is true and it is called ""local property of conditional expectation"" but I did not find it anywhere else. Thank you in advance for your help. Edit: Does anyone know? It is important because I proved a result using this property and my proof will be wrong if this property is not correct.",,"['probability', 'stochastic-processes', 'brownian-motion', 'conditional-expectation', 'stopping-times']"
17,understanding statement of generalized CLT,understanding statement of generalized CLT,,"Durrett Theorem 3.7.2 Given a sum $S_n=\sum_1^nX_i$ of an iid sequence $X_1,X_2,\ldots,$ Durrett theorem 3.7.2 (image at link) gives necessary and sufficient conditions for the existence of constants $a_n,b_n$ such that $(S_n-b_n)/a_n$ converges weakly to a nondegenerate distribution. I am trying to see how the usual CLT, ie, when $var(X_1)<\infty$, relates to this theorem. Let the $X_i$ have the double exponential distribution, with pdf $f(x)=\exp(-|x|)/2$. The variance is 2 and the density is symmetric so the usual CLT says $S_n/\sqrt{2n}$ converges to a standard normal. Now to Durrett's theorem. Again since the pdf is symmetric condition $(i)$ is met with $\theta=1/2$ and also $b_n=0$. $P(|X_1|>x)=e^{-x}$ so $a_n=\inf\{x:P(|X_1|>x)\le 1/n)\}=\log n.$ So the theorem seems to be saying $S_n/\log n$ converges to a nondegenerate distribution, which cannot be, given the CLT result. So I must have miscalculated $a_n$ or I'm misunderstanding the statement of the theorem. I also do not see how condition $(ii)$ applies. For this example the dropoff of the tails is exponential. Is it possible to put $e^{-x}$ in the form $(ii)$ requires, $x^{-\alpha}L(x)$ for slowly varying $L$ and $\alpha<2$. Why is there a condition limiting how fast the tails drop off? That's the opposite of the usual CLT condition. But $(ii)$ must apply by the necessity direction and the CLT result.","Durrett Theorem 3.7.2 Given a sum $S_n=\sum_1^nX_i$ of an iid sequence $X_1,X_2,\ldots,$ Durrett theorem 3.7.2 (image at link) gives necessary and sufficient conditions for the existence of constants $a_n,b_n$ such that $(S_n-b_n)/a_n$ converges weakly to a nondegenerate distribution. I am trying to see how the usual CLT, ie, when $var(X_1)<\infty$, relates to this theorem. Let the $X_i$ have the double exponential distribution, with pdf $f(x)=\exp(-|x|)/2$. The variance is 2 and the density is symmetric so the usual CLT says $S_n/\sqrt{2n}$ converges to a standard normal. Now to Durrett's theorem. Again since the pdf is symmetric condition $(i)$ is met with $\theta=1/2$ and also $b_n=0$. $P(|X_1|>x)=e^{-x}$ so $a_n=\inf\{x:P(|X_1|>x)\le 1/n)\}=\log n.$ So the theorem seems to be saying $S_n/\log n$ converges to a nondegenerate distribution, which cannot be, given the CLT result. So I must have miscalculated $a_n$ or I'm misunderstanding the statement of the theorem. I also do not see how condition $(ii)$ applies. For this example the dropoff of the tails is exponential. Is it possible to put $e^{-x}$ in the form $(ii)$ requires, $x^{-\alpha}L(x)$ for slowly varying $L$ and $\alpha<2$. Why is there a condition limiting how fast the tails drop off? That's the opposite of the usual CLT condition. But $(ii)$ must apply by the necessity direction and the CLT result.",,"['probability', 'probability-theory', 'statistics']"
18,Triangle forming probability for area,Triangle forming probability for area,,Say you have a stick which breaks randomly into three pieces (we can choose the points randomly). What is the probability that the area is greater than or equal to $0.4$? I can see it has something to do with Heron's formula but I just can't put t together.,Say you have a stick which breaks randomly into three pieces (we can choose the points randomly). What is the probability that the area is greater than or equal to $0.4$? I can see it has something to do with Heron's formula but I just can't put t together.,,['probability']
19,Euclidean distance for points in $\mathbb R^2$,Euclidean distance for points in,\mathbb R^2,"I have a point, call it $x$, located somewhere in a unit square $[0,1]^2$. I drawn $n$ new points, all uniformly and independently, all those in the unit square $[0,1]^2$. What is the expected Euclidean distance between $x$, and the closest of the other $n$ dots? EDIT: thanks all for your nice replies. I do realize it is incredibly difficult. If the $n$ numbers are drawned from a Poisson point processes, a paper by Holroyd et al. (Poisson point proccesses) shows that the probability that two points are separated by a distance larger than r is $Pr(Q>r)=\frac{C}{r^{0.49}}$ I was trying to derive this result limiting myself to points in the unit square but it looks hard.","I have a point, call it $x$, located somewhere in a unit square $[0,1]^2$. I drawn $n$ new points, all uniformly and independently, all those in the unit square $[0,1]^2$. What is the expected Euclidean distance between $x$, and the closest of the other $n$ dots? EDIT: thanks all for your nice replies. I do realize it is incredibly difficult. If the $n$ numbers are drawned from a Poisson point processes, a paper by Holroyd et al. (Poisson point proccesses) shows that the probability that two points are separated by a distance larger than r is $Pr(Q>r)=\frac{C}{r^{0.49}}$ I was trying to derive this result limiting myself to points in the unit square but it looks hard.",,"['probability', 'uniform-distribution']"
20,Sum of exponent of jump times,Sum of exponent of jump times,,"I have the following question. I have a random variabele that is the sum of the exponent of the jumping times $T_i$ of a Poisson process $N(\cdot)$ with parameter $\lambda$. Say: $$B(t) = \sum_{i=1}^{N(t)} e^{-r (t - \ T_i)} $$ I want to know $\mathbb{E}[B(t)]$. I can condition on $N(t)$ to see that $\mathbb{E}[B(t)] = \sum_{i=1}^\infty\mathbb{E}[B(t)|N(t)=k]\mathbb{P}[N(t)=k]$. Where $\mathbb{P}[N(t)=k] = e^{-\lambda t} \frac{(\lambda t)^k}{k!}$ is a Poisson distribution of parameter $\lambda t$. To understand the problem I first calculated $\mathbb{E}[B(t)|N(t)=1]$, where since we condition on having one jump the jump is uniformly distributed: \begin{align} \mathbb{E}[B(t)|N(t)=1]&= \int_0^t \mathbb{P}(T_1=s)e^{-r(t-s)}ds \\ &= \int_0^t \frac{1}{t} e^{-rt}e^{rs}ds \\ &= \frac{e^{-rt}}{t} \int_0^t e^{rs} ds \\ &= \frac{1}{e^{rt}} \left[ \frac{e^{rs}}{r} \right]_0^t \\ &= \frac{1}{te^{rt}} \left( \frac{e^{rt}}{r} - 1 \right) = \left( \frac{1}{tr} - \frac{e^{-rt}}{t} \right) \end{align} Which looks like it makes some sense. I know that the joint distribution of the jump times. Have a joint density distribution of $f(t_1,...,t_n)= \frac{n!}{t^n} 1_{(0 \leq t_1 \leq ... \leq t_n \leq t)}$ so the expected value generalised to some n would look like: \begin{align} \mathbb{E}[B(t)|N(t)=n] &= \int_0^t ... \int_0^t f(t_1,...,t_n) \sum_{i=1}^n e^{-r(t-t_i)} dt_1 ... dt_n \\ &= \int_0^{t_2} ... \int_{t_{n-2}}^t \frac{n!}{t^n} \sum_{i=1}^n e^{-r(t-t_i)} dt_1 ... dt_n \end{align} This I am not so sure how to evaluate. Anyone has an idea?","I have the following question. I have a random variabele that is the sum of the exponent of the jumping times $T_i$ of a Poisson process $N(\cdot)$ with parameter $\lambda$. Say: $$B(t) = \sum_{i=1}^{N(t)} e^{-r (t - \ T_i)} $$ I want to know $\mathbb{E}[B(t)]$. I can condition on $N(t)$ to see that $\mathbb{E}[B(t)] = \sum_{i=1}^\infty\mathbb{E}[B(t)|N(t)=k]\mathbb{P}[N(t)=k]$. Where $\mathbb{P}[N(t)=k] = e^{-\lambda t} \frac{(\lambda t)^k}{k!}$ is a Poisson distribution of parameter $\lambda t$. To understand the problem I first calculated $\mathbb{E}[B(t)|N(t)=1]$, where since we condition on having one jump the jump is uniformly distributed: \begin{align} \mathbb{E}[B(t)|N(t)=1]&= \int_0^t \mathbb{P}(T_1=s)e^{-r(t-s)}ds \\ &= \int_0^t \frac{1}{t} e^{-rt}e^{rs}ds \\ &= \frac{e^{-rt}}{t} \int_0^t e^{rs} ds \\ &= \frac{1}{e^{rt}} \left[ \frac{e^{rs}}{r} \right]_0^t \\ &= \frac{1}{te^{rt}} \left( \frac{e^{rt}}{r} - 1 \right) = \left( \frac{1}{tr} - \frac{e^{-rt}}{t} \right) \end{align} Which looks like it makes some sense. I know that the joint distribution of the jump times. Have a joint density distribution of $f(t_1,...,t_n)= \frac{n!}{t^n} 1_{(0 \leq t_1 \leq ... \leq t_n \leq t)}$ so the expected value generalised to some n would look like: \begin{align} \mathbb{E}[B(t)|N(t)=n] &= \int_0^t ... \int_0^t f(t_1,...,t_n) \sum_{i=1}^n e^{-r(t-t_i)} dt_1 ... dt_n \\ &= \int_0^{t_2} ... \int_{t_{n-2}}^t \frac{n!}{t^n} \sum_{i=1}^n e^{-r(t-t_i)} dt_1 ... dt_n \end{align} This I am not so sure how to evaluate. Anyone has an idea?",,"['probability', 'stochastic-processes', 'markov-chains', 'markov-process', 'poisson-process']"
21,Probability distribution and mathematical expectation in a process of handling tasks,Probability distribution and mathematical expectation in a process of handling tasks,,"Assume there is a task pool which has $m$ unprocessed tasks. There are $n$ processors to process the tasks. The rules of processing tasks are: The processors pick up tasks in the task pool randomly. At each round, all the processors will get a chance to pick up tasks and they are capable of finishing processing the tasks before they get the next chance. A processor has no idea about the choice of the other processors. This means that each time a task could be chosen by multiple processors, and there will be multiple copies of the same result after processing. A processor does not keep a history of the processed tasks. This means it could choose a task which has been processed by itself before. Note that the number of tasks in the task pool does not change: a processed task stays in the pool and could be picked up again. (although unnecessary) Let $x$ denote the number of rounds needed to finish picking up all tasks and processing them. The questions are: What is the probability distribution of $x$? What is the mathematical expectation of $x$? In addition, what if a processor can pick up $p$ tasks and process them in parallel at each round? This time the $p$ tasks are different from each other.","Assume there is a task pool which has $m$ unprocessed tasks. There are $n$ processors to process the tasks. The rules of processing tasks are: The processors pick up tasks in the task pool randomly. At each round, all the processors will get a chance to pick up tasks and they are capable of finishing processing the tasks before they get the next chance. A processor has no idea about the choice of the other processors. This means that each time a task could be chosen by multiple processors, and there will be multiple copies of the same result after processing. A processor does not keep a history of the processed tasks. This means it could choose a task which has been processed by itself before. Note that the number of tasks in the task pool does not change: a processed task stays in the pool and could be picked up again. (although unnecessary) Let $x$ denote the number of rounds needed to finish picking up all tasks and processing them. The questions are: What is the probability distribution of $x$? What is the mathematical expectation of $x$? In addition, what if a processor can pick up $p$ tasks and process them in parallel at each round? This time the $p$ tasks are different from each other.",,['probability']
22,"Question about transportation-entropy inequality (From Villani's book: Optimal Transport, Old and New)","Question about transportation-entropy inequality (From Villani's book: Optimal Transport, Old and New)",,"I was reading Villani's book: Optimal Transportation, Old and New. From page 80-83, he introduced some results about dual formulation of transport inequality. Assume $C(\mu,\nu)$ is the optimal transport distance from probability measure $\mu$ (defined on $\mathcal{X}$) to $\nu$ (defined on $\mathcal{Y}$), with cost function $c(\cdot,\cdot)$. Given a convex functional $F(\cdot)$ defined on $P(\mathcal{X})$, we can define its Legendre Transformation : $L(F)=\Lambda$, so $\Lambda$ is a convex functional on $C_b(\mathcal{X})$. The main result (Theorem 5.26) is: \begin{equation*} \forall \mu \in P(\mathcal{X}), C(\mu,\nu)\leq F(\mu) \end{equation*} and \begin{equation*} \forall \phi \in C_b(\mathcal{Y}), \Lambda(\int_\mathcal{Y}\phi d\nu-\phi^c)\leq 0\quad \phi^c:=\sup_{y\in\mathcal{Y}}(\phi(y)-c(x,y)) \end{equation*} Are equivalent. Well this result is used to analyze transport inequalities. In Example 5.29, the author gives an important application of this result: Assume $\mathcal{Y}=\mathcal{X}$ and consider:  \begin{equation*} F(\mu):=KL(\mu||\nu)=\int_{\mathcal{X}}\ln(\frac{d\mu}{d\nu})d\mu \end{equation*} which is the Kullback Liebller Divergence between measures (also known as relative entropy); We could compute the Legendre Transformation of $F$, which has the following form: \begin{equation*} \Lambda(\phi):=\ln(\int_{\mathcal{X}}e^{\phi}d\nu) \end{equation*} Thus by the previous result, the transportation-entropy inequality  \begin{equation*} C(\mu,\nu)\leq KL(\mu||\nu) \quad \forall \mu\in P(\mathcal{X}) \quad (1) \end{equation*} is equivalent to : \begin{equation} \ln(\int_{\mathcal{X}}e^{\int \phi d\nu-\phi^c}d\nu)\leq 0  \Leftrightarrow e^{\int_{\mathcal{X}}\phi d\nu}\leq (\int_{\mathcal{X}}e^{-\phi^c}d\nu)^{-1} \quad (2) \end{equation} But in the book, the author directly arrives at: \begin{equation} e^{\int_{\mathcal{X}}\phi d\nu}\leq \int_{\mathcal{X}}e^{\phi^c}d\nu \quad (3) \end{equation} If we apply Cauchy inequality, we will deduce from (1) to (3): \begin{equation*} e^{\int_{\mathcal{X}}\phi d\nu}\leq (\int_{\mathcal{X}}e^{-\phi^c}d\nu)^{-1}\leq \int_{\mathcal{X}}e^{\phi^c}d\nu  \end{equation*} But how could we deduce from (3) back to (1)? I am quite confused about it. I even think that $(3)$ and $(1)$ are equivalent is not a trivial corollary from our previous Theorem 5.26. Can any expert in this area help me with this problem? So many thanks!","I was reading Villani's book: Optimal Transportation, Old and New. From page 80-83, he introduced some results about dual formulation of transport inequality. Assume $C(\mu,\nu)$ is the optimal transport distance from probability measure $\mu$ (defined on $\mathcal{X}$) to $\nu$ (defined on $\mathcal{Y}$), with cost function $c(\cdot,\cdot)$. Given a convex functional $F(\cdot)$ defined on $P(\mathcal{X})$, we can define its Legendre Transformation : $L(F)=\Lambda$, so $\Lambda$ is a convex functional on $C_b(\mathcal{X})$. The main result (Theorem 5.26) is: \begin{equation*} \forall \mu \in P(\mathcal{X}), C(\mu,\nu)\leq F(\mu) \end{equation*} and \begin{equation*} \forall \phi \in C_b(\mathcal{Y}), \Lambda(\int_\mathcal{Y}\phi d\nu-\phi^c)\leq 0\quad \phi^c:=\sup_{y\in\mathcal{Y}}(\phi(y)-c(x,y)) \end{equation*} Are equivalent. Well this result is used to analyze transport inequalities. In Example 5.29, the author gives an important application of this result: Assume $\mathcal{Y}=\mathcal{X}$ and consider:  \begin{equation*} F(\mu):=KL(\mu||\nu)=\int_{\mathcal{X}}\ln(\frac{d\mu}{d\nu})d\mu \end{equation*} which is the Kullback Liebller Divergence between measures (also known as relative entropy); We could compute the Legendre Transformation of $F$, which has the following form: \begin{equation*} \Lambda(\phi):=\ln(\int_{\mathcal{X}}e^{\phi}d\nu) \end{equation*} Thus by the previous result, the transportation-entropy inequality  \begin{equation*} C(\mu,\nu)\leq KL(\mu||\nu) \quad \forall \mu\in P(\mathcal{X}) \quad (1) \end{equation*} is equivalent to : \begin{equation} \ln(\int_{\mathcal{X}}e^{\int \phi d\nu-\phi^c}d\nu)\leq 0  \Leftrightarrow e^{\int_{\mathcal{X}}\phi d\nu}\leq (\int_{\mathcal{X}}e^{-\phi^c}d\nu)^{-1} \quad (2) \end{equation} But in the book, the author directly arrives at: \begin{equation} e^{\int_{\mathcal{X}}\phi d\nu}\leq \int_{\mathcal{X}}e^{\phi^c}d\nu \quad (3) \end{equation} If we apply Cauchy inequality, we will deduce from (1) to (3): \begin{equation*} e^{\int_{\mathcal{X}}\phi d\nu}\leq (\int_{\mathcal{X}}e^{-\phi^c}d\nu)^{-1}\leq \int_{\mathcal{X}}e^{\phi^c}d\nu  \end{equation*} But how could we deduce from (3) back to (1)? I am quite confused about it. I even think that $(3)$ and $(1)$ are equivalent is not a trivial corollary from our previous Theorem 5.26. Can any expert in this area help me with this problem? So many thanks!",,"['probability', 'functional-analysis', 'functional-inequalities', 'optimal-transport']"
23,Probability that $n$ vectors drawn from arbitrary independent prob. distributions are linearly independent,Probability that  vectors drawn from arbitrary independent prob. distributions are linearly independent,n,"Let $X_1, X_2, \ldots, X_n \in \mathbb{R}^n$ be continuous random variables in $\mathbb{R}^n$ that are pairwise and elementwise independent. By continuous random variables, it is meant that their distributions do not include any Dirac delta fnc $\delta_x$. My question is: in this general situation, are $X_1, \ldots, X_n$ linearly independent (LI) with propbability 1? That is, is it true that  \begin{equation} \operatorname{Prob}\big ( \operatorname{span} \{ X_1, \ldots, X_n\} = \mathbb{R}^n \big ) = 1\text{?} \end{equation} This is a general version of the topic: Probability that $n$ vectors drawn randomly from $\mathbb{R}^n$ are linearly independent since here we consider a general independent prob. distribution, rather than uniform (or Gaussian) distribution. By referring the related posts above and below: The probability that two vectors are linearly independent. I think the statement above is true as shown in the short proof below. First, the probability of ""$X_1 = 0$"" is zero since the singleton $\{ 0 \}$ is a set of measure zero. Hence, $X_1$ is LI with probability 1. Next, assume that $X_1,\ldots,X_r$ are LI with probability 1 for some $r \in \{1,2,\ldots, n-1\}$. Then, with probability 1, they span an $r$-dimensional subspace of $\mathbb{R}^n$ which is, however, a set of measure zero, too. Hence, the next vector $X_{r+1}$ lies on $\mathbb{R}^n$ outside the subspace with prob. $1$. By this process, $\operatorname{span}\{X_1,\ldots,X_n\} = \mathbb{R}^n$ with prob. $1$. But, I'm just not sure that this proof is correct and has no problem. Many thanks in advance for your comments and discussions! Edited: I think this can be extended to a more general case where the RVs are stochastically dependent. The proof seems to be also true in this dependent case as well---it is relevant to the fact that the distributions include no Dirac delta fnc, not to the stochastic independence.","Let $X_1, X_2, \ldots, X_n \in \mathbb{R}^n$ be continuous random variables in $\mathbb{R}^n$ that are pairwise and elementwise independent. By continuous random variables, it is meant that their distributions do not include any Dirac delta fnc $\delta_x$. My question is: in this general situation, are $X_1, \ldots, X_n$ linearly independent (LI) with propbability 1? That is, is it true that  \begin{equation} \operatorname{Prob}\big ( \operatorname{span} \{ X_1, \ldots, X_n\} = \mathbb{R}^n \big ) = 1\text{?} \end{equation} This is a general version of the topic: Probability that $n$ vectors drawn randomly from $\mathbb{R}^n$ are linearly independent since here we consider a general independent prob. distribution, rather than uniform (or Gaussian) distribution. By referring the related posts above and below: The probability that two vectors are linearly independent. I think the statement above is true as shown in the short proof below. First, the probability of ""$X_1 = 0$"" is zero since the singleton $\{ 0 \}$ is a set of measure zero. Hence, $X_1$ is LI with probability 1. Next, assume that $X_1,\ldots,X_r$ are LI with probability 1 for some $r \in \{1,2,\ldots, n-1\}$. Then, with probability 1, they span an $r$-dimensional subspace of $\mathbb{R}^n$ which is, however, a set of measure zero, too. Hence, the next vector $X_{r+1}$ lies on $\mathbb{R}^n$ outside the subspace with prob. $1$. By this process, $\operatorname{span}\{X_1,\ldots,X_n\} = \mathbb{R}^n$ with prob. $1$. But, I'm just not sure that this proof is correct and has no problem. Many thanks in advance for your comments and discussions! Edited: I think this can be extended to a more general case where the RVs are stochastically dependent. The proof seems to be also true in this dependent case as well---it is relevant to the fact that the distributions include no Dirac delta fnc, not to the stochastic independence.",,"['linear-algebra', 'probability', 'probability-theory', 'measure-theory']"
24,Inverse of multivariate normal under restrictions on marginal CDFs,Inverse of multivariate normal under restrictions on marginal CDFs,,"Is it possible to uniquely define an inverse of a multivariate normal distribution by applying some further restrictions on the values of the CDFs of the marginals? For example, if we insist that the marginal CDFs have to be the same, i.e. $\Phi_1(x_1;\mu_1,\sigma_1) = \Phi_2(x_2;\mu_2,\sigma_2) = ... = \Phi_n(x_n;\mu_n,\sigma_n)$. Is this conditions enough to uniquely define $\Phi^{-1}_{x_1,x_2,...x_n}(p)$? What about a restriction on the combination of marginal CDFs, e.g. minimize $\sum\Phi_i(x_i)$ or $\sum(\Phi_i(x_i))^2$? Are there some general conditions on the restrictions that have to be imposed to guarantee a unique inverse? If a CDF is defined not using rectangular regions, but using ellipsoids, then -  if my understanding is correct - for a 2d case of bivariate normal, the inverse of the CDF at $p$ defines an ellipse given by $$ -2\ln(1-p) = (\mathbf x -\mathbf \mu)^T \mathbf \Sigma^{-1}(\mathbf x-\mathbf \mu)$$ and the condition $\Phi_1(x_1;\mu_1,\sigma_1) = \Phi_2(x_2;\mu_2,\sigma_2)$ defines a straight line by $$\mathbf x = \mathbf\mu + \Phi^{-1}_{0,1}(\alpha) \mathbf \sigma  : \alpha \in (0,1)$$ where $\mathbf x = (x_1,x_2)^T$, $\mathbf\mu = (\mu_1,\mu_2)^T$, and $\mathbf \sigma = (\sigma_1,\sigma_2)^T$. Substituting and solving for $\Phi^{-1}_{0,1}(\alpha)$ gives $$ \Phi^{-1}_{0,1}(\alpha) = \pm \sqrt \frac{-2\ln(1-p)}{\mathbf\sigma^T \mathbf\Sigma^{-1} \mathbf\sigma} $$ Thus, the intersection of the ellipse and the straight line  would give two pairs of points, and one would then take the point falling into the lower left quadrant (relative to the mean $\mathbf \mu$) by taking the negative of the square root above.","Is it possible to uniquely define an inverse of a multivariate normal distribution by applying some further restrictions on the values of the CDFs of the marginals? For example, if we insist that the marginal CDFs have to be the same, i.e. $\Phi_1(x_1;\mu_1,\sigma_1) = \Phi_2(x_2;\mu_2,\sigma_2) = ... = \Phi_n(x_n;\mu_n,\sigma_n)$. Is this conditions enough to uniquely define $\Phi^{-1}_{x_1,x_2,...x_n}(p)$? What about a restriction on the combination of marginal CDFs, e.g. minimize $\sum\Phi_i(x_i)$ or $\sum(\Phi_i(x_i))^2$? Are there some general conditions on the restrictions that have to be imposed to guarantee a unique inverse? If a CDF is defined not using rectangular regions, but using ellipsoids, then -  if my understanding is correct - for a 2d case of bivariate normal, the inverse of the CDF at $p$ defines an ellipse given by $$ -2\ln(1-p) = (\mathbf x -\mathbf \mu)^T \mathbf \Sigma^{-1}(\mathbf x-\mathbf \mu)$$ and the condition $\Phi_1(x_1;\mu_1,\sigma_1) = \Phi_2(x_2;\mu_2,\sigma_2)$ defines a straight line by $$\mathbf x = \mathbf\mu + \Phi^{-1}_{0,1}(\alpha) \mathbf \sigma  : \alpha \in (0,1)$$ where $\mathbf x = (x_1,x_2)^T$, $\mathbf\mu = (\mu_1,\mu_2)^T$, and $\mathbf \sigma = (\sigma_1,\sigma_2)^T$. Substituting and solving for $\Phi^{-1}_{0,1}(\alpha)$ gives $$ \Phi^{-1}_{0,1}(\alpha) = \pm \sqrt \frac{-2\ln(1-p)}{\mathbf\sigma^T \mathbf\Sigma^{-1} \mathbf\sigma} $$ Thus, the intersection of the ellipse and the straight line  would give two pairs of points, and one would then take the point falling into the lower left quadrant (relative to the mean $\mathbf \mu$) by taking the negative of the square root above.",,"['probability', 'probability-distributions', 'normal-distribution']"
25,Number of permutations that map every part of a particular partition away from itself,Number of permutations that map every part of a particular partition away from itself,,"Let $C_1=\{1,2,\dots,c_1\}, \space C_2=\{c_1+1, \dots,c_2\}, \dots \space C_k=\{c_{k-1}+1,\dots, n\}$ be a partition of the set $\{1,2,\dots n\}$. I want to calculate the number of permutations $\sigma \in S_n$ that don't take any element in any part of the partition to that same part; that is, the number $$a_C = \#\{\sigma\in S_n \space | \space \forall k : \forall j \in C_k : \sigma(j) \notin C_k\}$$ My thoughts and ""conjectures"" on the problem: A special case when $|C_j|=d$ is constant and $n=kd$. A further special case of this is $d=4, k=13$ (and $n=52$). This corresponds to a card game where the deck is gone through one card at a time and at the same time counted $1,2,\dots, 13,1,2,\dots, 13,1,2,\dots, 13,1,2,\dots, 13 $. If at any point the number said out loud matches the value of the card laid down (suit doesn't matter), the game is lost. Otherwise, if the end is reached without matches, the game is won. (Trying to calculate the winning probability of this game is how I came up with the general problem.) The case $d=1$ gives the permutations without fixed points . For these the fraction $\frac{a_n}{n!} \to \frac{1}{e}$ as $n\to \infty$. I suspect that for other values of $d$ the limit is $\frac{1}{e^d}$ but I can't find a proof for this. Still, simulation seems to support the claim and there's the heuristic argument that if the events $\sigma(j) \notin C_k$ were independent, the probability of ""$\sigma$ to be good"" would be $(1-\frac{d}{n})^n \to e^{-d}$. For some partitions $a_C=0$: if one part has more than $n/2$ elements, some element must stay in that part after permuting.","Let $C_1=\{1,2,\dots,c_1\}, \space C_2=\{c_1+1, \dots,c_2\}, \dots \space C_k=\{c_{k-1}+1,\dots, n\}$ be a partition of the set $\{1,2,\dots n\}$. I want to calculate the number of permutations $\sigma \in S_n$ that don't take any element in any part of the partition to that same part; that is, the number $$a_C = \#\{\sigma\in S_n \space | \space \forall k : \forall j \in C_k : \sigma(j) \notin C_k\}$$ My thoughts and ""conjectures"" on the problem: A special case when $|C_j|=d$ is constant and $n=kd$. A further special case of this is $d=4, k=13$ (and $n=52$). This corresponds to a card game where the deck is gone through one card at a time and at the same time counted $1,2,\dots, 13,1,2,\dots, 13,1,2,\dots, 13,1,2,\dots, 13 $. If at any point the number said out loud matches the value of the card laid down (suit doesn't matter), the game is lost. Otherwise, if the end is reached without matches, the game is won. (Trying to calculate the winning probability of this game is how I came up with the general problem.) The case $d=1$ gives the permutations without fixed points . For these the fraction $\frac{a_n}{n!} \to \frac{1}{e}$ as $n\to \infty$. I suspect that for other values of $d$ the limit is $\frac{1}{e^d}$ but I can't find a proof for this. Still, simulation seems to support the claim and there's the heuristic argument that if the events $\sigma(j) \notin C_k$ were independent, the probability of ""$\sigma$ to be good"" would be $(1-\frac{d}{n})^n \to e^{-d}$. For some partitions $a_C=0$: if one part has more than $n/2$ elements, some element must stay in that part after permuting.",,"['probability', 'permutations']"
26,"You have 6 red balls, 6 blue, and 6 white. You randomly select a sample of 5 balls.","You have 6 red balls, 6 blue, and 6 white. You randomly select a sample of 5 balls.",,"You have 6 red balls, 6 blue, and 6 white. You randomly select a sample of 5 balls. What are the odds that the sample contains 4 balls of one color and 1 of another color? I thought of it like this: $$P(\text{4 balls of one color and 1 of another color})=\frac{3 \cdot \binom{6}{4}\cdot 2 \binom{6}{1}}{\binom{18}{5}}\approx 0.0630252$$ since you have three choices for the color of the first four balls and only two (since you've can't use the same color that you did for the first four balls) for the last ball. All of this divided by the total number of ways to pick a group of five from the 18 balls you have in total. Is my approach correct?","You have 6 red balls, 6 blue, and 6 white. You randomly select a sample of 5 balls. What are the odds that the sample contains 4 balls of one color and 1 of another color? I thought of it like this: $$P(\text{4 balls of one color and 1 of another color})=\frac{3 \cdot \binom{6}{4}\cdot 2 \binom{6}{1}}{\binom{18}{5}}\approx 0.0630252$$ since you have three choices for the color of the first four balls and only two (since you've can't use the same color that you did for the first four balls) for the last ball. All of this divided by the total number of ways to pick a group of five from the 18 balls you have in total. Is my approach correct?",,"['probability', 'combinatorics', 'discrete-mathematics']"
27,Expected angle between bivariate normal vectors,Expected angle between bivariate normal vectors,,"I am trying to find an expression for the expected angle between two correlated gaussian vectors, i.e., find $E[\theta] = E\left[\cos^{-1}\left(\frac{\bf x_1'x_2}{\|\bf x_1\|\|x_2\|}\right)\right]$ where $\bf x_1$ and $\bf x_2$ $\in R^2$, \begin{equation} \left(\begin{array}{c} \bf x_1\\ \bf x_2\end{array}\right) \sim N(\bf 0,\Sigma) \end{equation} and \begin{equation} \bf \Sigma = \left(\begin{array}{cc} \bf \Sigma_{11} &\bf \Sigma_{12}\\ \bf \Sigma_{21} &\bf \Sigma_{22} \end{array} \right) \end{equation} and $\bf \Sigma_{12}=\bf \Sigma_{21}' \neq \bf 0$. Assume all covariance submatrices are known. Any help will be greatly appreciated.","I am trying to find an expression for the expected angle between two correlated gaussian vectors, i.e., find $E[\theta] = E\left[\cos^{-1}\left(\frac{\bf x_1'x_2}{\|\bf x_1\|\|x_2\|}\right)\right]$ where $\bf x_1$ and $\bf x_2$ $\in R^2$, \begin{equation} \left(\begin{array}{c} \bf x_1\\ \bf x_2\end{array}\right) \sim N(\bf 0,\Sigma) \end{equation} and \begin{equation} \bf \Sigma = \left(\begin{array}{cc} \bf \Sigma_{11} &\bf \Sigma_{12}\\ \bf \Sigma_{21} &\bf \Sigma_{22} \end{array} \right) \end{equation} and $\bf \Sigma_{12}=\bf \Sigma_{21}' \neq \bf 0$. Assume all covariance submatrices are known. Any help will be greatly appreciated.",,"['probability', 'statistics', 'probability-distributions', 'correlation']"
28,Breaking a stick twice - why are $Y$ and $\frac{X}{Y}$ are independent?,Breaking a stick twice - why are  and  are independent?,Y \frac{X}{Y},"A stick of length $L$ is broken at a point which is chosen according to a uniform distribution. We keep the left 'substick' of length $Y$. Then we, in turn, break this 'substick' and keep another left part which is $X$. The book says that r.v.'s $Y$ and $X/Y$ are independent, but I don't understand why. I could use the definition of independence but I can't find the necessary PDFs for that and the book doesn't do that either, just states the fact. Any help would be appreciated.","A stick of length $L$ is broken at a point which is chosen according to a uniform distribution. We keep the left 'substick' of length $Y$. Then we, in turn, break this 'substick' and keep another left part which is $X$. The book says that r.v.'s $Y$ and $X/Y$ are independent, but I don't understand why. I could use the definition of independence but I can't find the necessary PDFs for that and the book doesn't do that either, just states the fact. Any help would be appreciated.",,"['probability', 'probability-theory', 'independence']"
29,Discrete Irwin-Hall distribution? [closed],Discrete Irwin-Hall distribution? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question What is the Irwin-Hall distribution for discrete random variables? That is, if I roll $n$ $k$ -sided die and add their sum together, how will the result be distributed? John D. Cook says: By using generating functions, you can see that the probability of getting a sum of $k$ spots on the five [six-sided] dice is the coefficient of $x^k$ in the expansion of $(x + x^2 + x^3 + x^4 + x^5 + x^6)^5 / 6^5$ But this is all the explanation he gives, and I don't follow. Additionally, I'm wondering if there is a name for this distribution.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question What is the Irwin-Hall distribution for discrete random variables? That is, if I roll -sided die and add their sum together, how will the result be distributed? John D. Cook says: By using generating functions, you can see that the probability of getting a sum of spots on the five [six-sided] dice is the coefficient of in the expansion of But this is all the explanation he gives, and I don't follow. Additionally, I'm wondering if there is a name for this distribution.",n k k x^k (x + x^2 + x^3 + x^4 + x^5 + x^6)^5 / 6^5,"['probability', 'probability-distributions']"
30,Prove these two conditional probabilities are equivalent,Prove these two conditional probabilities are equivalent,,"I saw people using such equivalence $$P(X|\mu) P(\mu | D) = P(X,\mu|D)$$ how to prove it is valid? My attempt: \begin{align} P(X|\mu) P(\mu | D) &= P(X|\mu) \frac{P(\mu,D)}{P(D)}\\ &= P(X|\mu) \frac{P(D|\mu) P(\mu)}{P(D)}\\ &=\frac{P(X,\mu) P(D|\mu)}{P(D)} \end{align} where $P(X,\mu|D) = \frac{P(X,\mu,D)}{P(D)}$. I have stuck here, couldn't figure out why $P(X,\mu,D) = P(X,\mu) P(D|\mu)$. Edited Additional: If instead we have $P(X|\mu,D) P(\mu | D)$, then \begin{align} P(X|\mu,D) P(\mu | D) = \frac{P(X,\mu,D)}{P(\mu,D)} \frac{P(\mu,D)}{P(D)}=P(X,\mu|D) \end{align} seems like in order to obtain such equivalence it implicitly assumes $P(X|\mu,D)=P(X|\mu)$, correct me if I am wrong.","I saw people using such equivalence $$P(X|\mu) P(\mu | D) = P(X,\mu|D)$$ how to prove it is valid? My attempt: \begin{align} P(X|\mu) P(\mu | D) &= P(X|\mu) \frac{P(\mu,D)}{P(D)}\\ &= P(X|\mu) \frac{P(D|\mu) P(\mu)}{P(D)}\\ &=\frac{P(X,\mu) P(D|\mu)}{P(D)} \end{align} where $P(X,\mu|D) = \frac{P(X,\mu,D)}{P(D)}$. I have stuck here, couldn't figure out why $P(X,\mu,D) = P(X,\mu) P(D|\mu)$. Edited Additional: If instead we have $P(X|\mu,D) P(\mu | D)$, then \begin{align} P(X|\mu,D) P(\mu | D) = \frac{P(X,\mu,D)}{P(\mu,D)} \frac{P(\mu,D)}{P(D)}=P(X,\mu|D) \end{align} seems like in order to obtain such equivalence it implicitly assumes $P(X|\mu,D)=P(X|\mu)$, correct me if I am wrong.",,"['probability', 'bayesian']"
31,Expected time for the flower snark graph,Expected time for the flower snark graph,,"I know that the expected time for a random walk to visit all vertices of a complete graph is, $$\mathrm E(G)= (n-1)(1+(1/2)+(1/3)+...+(1/n-1).$$ But what would be the expected time for a random walk to visit all vertices in a flower snark graph which is a cubic regular graph?","I know that the expected time for a random walk to visit all vertices of a complete graph is, $$\mathrm E(G)= (n-1)(1+(1/2)+(1/3)+...+(1/n-1).$$ But what would be the expected time for a random walk to visit all vertices in a flower snark graph which is a cubic regular graph?",,"['probability', 'graph-theory', 'stochastic-processes', 'expectation']"
32,Finding Bayes estimator with inverse-gamma prior and uniform likelihood.,Finding Bayes estimator with inverse-gamma prior and uniform likelihood.,,"Consider an i.i.d. sample of data from a population given by  $$Y_i|\Psi \sim \text{Unif}(0, \Psi), \quad i = 1,2,\ldots, n,$$ with $\Psi$ having a prior distribution given by $$\Psi \sim \text{Inv-}\Gamma(\alpha, \beta),$$ where Inv-$\Gamma$ is the inverse Gamma distribution with pdf  $$f_{\Psi}(z) = \frac{1}{\beta^\alpha\Gamma(\alpha)}\left(\frac{1}{z}\right)^{\alpha+1}\text{exp}\left\{-\frac{1}{\beta z}\right\}\quad \alpha,\beta > 0.$$ I know that the largest order statistic $Y^{(n)}$ is a sufficient statistic for $\psi$. If I want to find the Bayesian estimator of $\psi$ under the squared error loss, I know that this can be found via the following (rather heavy) integral: $$\hat{\psi}_B = \int_{Y^{(n)}}^{\infty}\psi\left[\frac{\left(\frac{1}{\psi}\right)^{\alpha + n + 1}e^{-1/({\beta\psi)}}}{\int_{Y^{(n)}}^{\infty}\left[\left(\frac{1}{\psi}\right)^{\alpha + n + 1}e^{-1/({\beta\psi)}}d\psi\right]}\right]d\psi$$ This can be somewhat simplified to  $$\hat{\psi}_B = \int_{Y^{(n)}}^{\infty}\left[\frac{\psi^{-(\alpha + n )}e^{-1/({\beta\psi)}}}{\int_{Y^{(n)}}^{\infty}\left[\psi^{-(\alpha + n + 1)}e^{-1/({\beta\psi)}}d\psi\right]}\right]d\psi.$$ Directly solving this integral would be pretty hard I feel. But, the resource I am trying to learn this from claims that now this integral can be expressed as  $$\hat{\psi}_B = \frac{1}{\beta(\alpha + n -1)}\frac{Pr\left(\chi_{2(\alpha + n -1)}^2 < 2/(\beta y^{(n)})\right)}{Pr\left(\chi_{2(\alpha + n)}^2< 2/(\beta y^{(n)})\right)},$$ where the probabilities above are the probability that a $\chi^2$ distributed random variable with the given degrees of freedom is less than $2/(\beta y^{(n)})$ (where $y^{(n)}$ is the maximum of the sample). I am generally familiar with the fact that the INVERSE-chi-squared distribution has pdf $$f(x|k) = \frac{2^{-k/2}}{\Gamma(k/2)}x^{k/2 -1}e^{-1/2x}.$$ The large and messy integral from above can be rewritten in the form of the Inverse-chi-squared distribution as follows using the transformation $\psi =\frac{\beta x}{2}$ in the pdf of the Inverse-chi-squared distribution given above (this final form is with a lot of factoring out and cancelling of Gamma functions, powers of $\beta$, etc.): $$\hat{\psi}_B = \beta(\alpha + n -1)\int_{\frac{\beta Y^{(n)}}{2}}^{\infty}\left[\frac{x^{-(\alpha + n )}e^{-1/({\beta x)}}}{\int_{\frac{\beta Y^{(n)}}{2}}^{\infty}\left[x^{-(\alpha + n + 1)}e^{-1/({\beta x)}}dx\right]}\right]dx.$$ It seems that this is tantalizingly close to being able to conclude that this is equivalent to $$\frac{1}{\beta(\alpha + n -1)}\frac{Pr\left(\chi_{2(\alpha + n -1)}^2 < 2/(\beta y^{(n)})\right)}{Pr\left(\chi_{2(\alpha + n)}^2< 2/(\beta y^{(n)})\right)},$$ but I am not quite sure of the details. What route would I need to take to bridge the gap between the integral expression I have and the ratio of probabilities I want to achieve?","Consider an i.i.d. sample of data from a population given by  $$Y_i|\Psi \sim \text{Unif}(0, \Psi), \quad i = 1,2,\ldots, n,$$ with $\Psi$ having a prior distribution given by $$\Psi \sim \text{Inv-}\Gamma(\alpha, \beta),$$ where Inv-$\Gamma$ is the inverse Gamma distribution with pdf  $$f_{\Psi}(z) = \frac{1}{\beta^\alpha\Gamma(\alpha)}\left(\frac{1}{z}\right)^{\alpha+1}\text{exp}\left\{-\frac{1}{\beta z}\right\}\quad \alpha,\beta > 0.$$ I know that the largest order statistic $Y^{(n)}$ is a sufficient statistic for $\psi$. If I want to find the Bayesian estimator of $\psi$ under the squared error loss, I know that this can be found via the following (rather heavy) integral: $$\hat{\psi}_B = \int_{Y^{(n)}}^{\infty}\psi\left[\frac{\left(\frac{1}{\psi}\right)^{\alpha + n + 1}e^{-1/({\beta\psi)}}}{\int_{Y^{(n)}}^{\infty}\left[\left(\frac{1}{\psi}\right)^{\alpha + n + 1}e^{-1/({\beta\psi)}}d\psi\right]}\right]d\psi$$ This can be somewhat simplified to  $$\hat{\psi}_B = \int_{Y^{(n)}}^{\infty}\left[\frac{\psi^{-(\alpha + n )}e^{-1/({\beta\psi)}}}{\int_{Y^{(n)}}^{\infty}\left[\psi^{-(\alpha + n + 1)}e^{-1/({\beta\psi)}}d\psi\right]}\right]d\psi.$$ Directly solving this integral would be pretty hard I feel. But, the resource I am trying to learn this from claims that now this integral can be expressed as  $$\hat{\psi}_B = \frac{1}{\beta(\alpha + n -1)}\frac{Pr\left(\chi_{2(\alpha + n -1)}^2 < 2/(\beta y^{(n)})\right)}{Pr\left(\chi_{2(\alpha + n)}^2< 2/(\beta y^{(n)})\right)},$$ where the probabilities above are the probability that a $\chi^2$ distributed random variable with the given degrees of freedom is less than $2/(\beta y^{(n)})$ (where $y^{(n)}$ is the maximum of the sample). I am generally familiar with the fact that the INVERSE-chi-squared distribution has pdf $$f(x|k) = \frac{2^{-k/2}}{\Gamma(k/2)}x^{k/2 -1}e^{-1/2x}.$$ The large and messy integral from above can be rewritten in the form of the Inverse-chi-squared distribution as follows using the transformation $\psi =\frac{\beta x}{2}$ in the pdf of the Inverse-chi-squared distribution given above (this final form is with a lot of factoring out and cancelling of Gamma functions, powers of $\beta$, etc.): $$\hat{\psi}_B = \beta(\alpha + n -1)\int_{\frac{\beta Y^{(n)}}{2}}^{\infty}\left[\frac{x^{-(\alpha + n )}e^{-1/({\beta x)}}}{\int_{\frac{\beta Y^{(n)}}{2}}^{\infty}\left[x^{-(\alpha + n + 1)}e^{-1/({\beta x)}}dx\right]}\right]dx.$$ It seems that this is tantalizingly close to being able to conclude that this is equivalent to $$\frac{1}{\beta(\alpha + n -1)}\frac{Pr\left(\chi_{2(\alpha + n -1)}^2 < 2/(\beta y^{(n)})\right)}{Pr\left(\chi_{2(\alpha + n)}^2< 2/(\beta y^{(n)})\right)},$$ but I am not quite sure of the details. What route would I need to take to bridge the gap between the integral expression I have and the ratio of probabilities I want to achieve?",,"['probability', 'statistics', 'probability-distributions', 'bayesian', 'gamma-distribution']"
33,Probability of two people meeting on a non-square grid,Probability of two people meeting on a non-square grid,,"Suppose a person leaves from home to the health club (eight blocks east and five blocks north). Furthermore, suppose this person wants to keep the route as short as possible but likes to vary it: There are $C(13,8)$ routes. My question is what the probability would be of two people meeting if one (say, Matt) left from the home to the health club, and someone else (say, Tine) left from the health club to the home. This is similar to a question asked yesterday where there was a square grid. My thought here was that the probability of Matt and Tina meeting would be $\frac{C(13,8)}{2^{13}}$, but that doesn't seem right given that Matt and Tina can walk on different paths even though they will only ever meet 6.5 blocks into their walk. Any idea about how to deduce what the probability would be here?","Suppose a person leaves from home to the health club (eight blocks east and five blocks north). Furthermore, suppose this person wants to keep the route as short as possible but likes to vary it: There are $C(13,8)$ routes. My question is what the probability would be of two people meeting if one (say, Matt) left from the home to the health club, and someone else (say, Tine) left from the health club to the home. This is similar to a question asked yesterday where there was a square grid. My thought here was that the probability of Matt and Tina meeting would be $\frac{C(13,8)}{2^{13}}$, but that doesn't seem right given that Matt and Tina can walk on different paths even though they will only ever meet 6.5 blocks into their walk. Any idea about how to deduce what the probability would be here?",,"['probability', 'combinatorics', 'algebra-precalculus']"
34,determine the probability of each value multiple rolls of dice. stop once same number shown N times,determine the probability of each value multiple rolls of dice. stop once same number shown N times,,"Trying help my daughter with a problem. The problem: Two dice. Each numbered 1-6. Both dice are rolled at the same time to get one of 11 values in the range 2-12. The 11 values have a different probability of occurring: Number 2 has 1/36 probability of being rolled each time (1 + 1). Number 3 has 2/36 probability of being rolled each time (1 + 2 and 2 + 1). and so on. Keep rolling the dice until one of the values has been rolled N times. The first value to be rolled N times is the winner. For each of the 11 values work out the probability of that value being the winner. Independent event probability means the multiplication of probabilities. For N = 2, the probability of getting 3 twice in two rolls is (2/36 * 2/36) = 4/1296 = 1/324. Which means the probability of not getting 3 twice in two rolls is (2/36 * 34/36 + 34/36 * 34/36 + 34/36 * 2/36) = (68/1296 + 1156/1296 + 68/1296) = 1292/1296 = 323/324 But this problem allows me to keep rolling the dice until I get the same value come up N times. Still assuming N = 2, that would the maximum would be rolling all the numbers once, then rolling the  1*11 + 1 = 12. I would need to roll the dice between two and 12 times to guarantee to get two matching values.  I assume I need to add up the various probabilities for rolling 2 to 12 times. I start having trouble because I don't have/know a formula which calculates the probabilities of the different permutations for the different number of rolls. e.g The value 3 would win if you rolled 12 times getting 2,3,4,5,6,7,8,9,12,11,10,3 probability of ((2/36)^2 * (34/36)^12), but how many permutations? The value 3 also wins in these cases rolling only four times. 1,2,3,3 probability of ((2/36)^2 * (34/36)^2) is the same as 3,1,2,3 and so on But value 3 doesn't win in this case 3,1,1,3, so I can't just apply ((2/36)^2 * (34/36)^2) * NumberOfPermutations. Ultimately want to solve for N=8","Trying help my daughter with a problem. The problem: Two dice. Each numbered 1-6. Both dice are rolled at the same time to get one of 11 values in the range 2-12. The 11 values have a different probability of occurring: Number 2 has 1/36 probability of being rolled each time (1 + 1). Number 3 has 2/36 probability of being rolled each time (1 + 2 and 2 + 1). and so on. Keep rolling the dice until one of the values has been rolled N times. The first value to be rolled N times is the winner. For each of the 11 values work out the probability of that value being the winner. Independent event probability means the multiplication of probabilities. For N = 2, the probability of getting 3 twice in two rolls is (2/36 * 2/36) = 4/1296 = 1/324. Which means the probability of not getting 3 twice in two rolls is (2/36 * 34/36 + 34/36 * 34/36 + 34/36 * 2/36) = (68/1296 + 1156/1296 + 68/1296) = 1292/1296 = 323/324 But this problem allows me to keep rolling the dice until I get the same value come up N times. Still assuming N = 2, that would the maximum would be rolling all the numbers once, then rolling the  1*11 + 1 = 12. I would need to roll the dice between two and 12 times to guarantee to get two matching values.  I assume I need to add up the various probabilities for rolling 2 to 12 times. I start having trouble because I don't have/know a formula which calculates the probabilities of the different permutations for the different number of rolls. e.g The value 3 would win if you rolled 12 times getting 2,3,4,5,6,7,8,9,12,11,10,3 probability of ((2/36)^2 * (34/36)^12), but how many permutations? The value 3 also wins in these cases rolling only four times. 1,2,3,3 probability of ((2/36)^2 * (34/36)^2) is the same as 3,1,2,3 and so on But value 3 doesn't win in this case 3,1,1,3, so I can't just apply ((2/36)^2 * (34/36)^2) * NumberOfPermutations. Ultimately want to solve for N=8",,['probability']
35,Finding the probability density function of $X+Y$,Finding the probability density function of,X+Y,"Question: Let $X$ and $Y$ be two independent and identically distributed exponential random variables with parameter $\lambda>0$. Compute the probability density function of $X+Y$. My Answer: I have found the joint probability density function of $X$ and $Y$ to be $f_{X,Y}(x,y)=\lambda^2e^{-\lambda x - \lambda y}$. I then let $Z=X+Y$ and calculated $F_Z(z)=\lambda^2e^{-\lambda z}$. I know I need to integrate $F_Z(z)$ to calculate the density function but am unsure on what the limits should be or if I found $F_Z(z)$ correctly. I was also wondering if there is a quicker way to tackle such questions or if this method is okay.","Question: Let $X$ and $Y$ be two independent and identically distributed exponential random variables with parameter $\lambda>0$. Compute the probability density function of $X+Y$. My Answer: I have found the joint probability density function of $X$ and $Y$ to be $f_{X,Y}(x,y)=\lambda^2e^{-\lambda x - \lambda y}$. I then let $Z=X+Y$ and calculated $F_Z(z)=\lambda^2e^{-\lambda z}$. I know I need to integrate $F_Z(z)$ to calculate the density function but am unsure on what the limits should be or if I found $F_Z(z)$ correctly. I was also wondering if there is a quicker way to tackle such questions or if this method is okay.",,"['probability', 'functions', 'density-function']"
36,Expected winnings on a coin flip game,Expected winnings on a coin flip game,,"A game involves flipping a coin until the first head appears and winning $2^n$ dollars if the first head appears on the $\mathrm{n^{th}}$ coin flip. We want to determine the expected winnings for this game. Based on my understanding on the problem, $$\begin{align}&X=\{ \mathrm{Coin\ Flips}\} \sim\mathrm{Geo}(p=0.5) \\  &W=\{\mathrm{Winnings}\}=2^X\\ &E[W]=E[2^X]=\sum_{n=1}^\infty 2^nP(X=n)=\sum_{n=1}^\infty (2^n)(0.5^n)=\sum_{n=1}^\infty 1=\infty \end{align}$$ However, this doesn't sound right to me because we also know that $$E[X]=\frac{1}{p}=\frac{1}{0.5}=2$$","A game involves flipping a coin until the first head appears and winning $2^n$ dollars if the first head appears on the $\mathrm{n^{th}}$ coin flip. We want to determine the expected winnings for this game. Based on my understanding on the problem, $$\begin{align}&X=\{ \mathrm{Coin\ Flips}\} \sim\mathrm{Geo}(p=0.5) \\  &W=\{\mathrm{Winnings}\}=2^X\\ &E[W]=E[2^X]=\sum_{n=1}^\infty 2^nP(X=n)=\sum_{n=1}^\infty (2^n)(0.5^n)=\sum_{n=1}^\infty 1=\infty \end{align}$$ However, this doesn't sound right to me because we also know that $$E[X]=\frac{1}{p}=\frac{1}{0.5}=2$$",,['probability']
37,Question Regarding Proposed Solution to the (Closed Envelope Version of) Two Envelope Paradox,Question Regarding Proposed Solution to the (Closed Envelope Version of) Two Envelope Paradox,,"Su, Francis, et. al. have a short description of the paradox here: https://www.math.hmc.edu/funfacts/ffiles/20001.6-8.shtml I used that link because it concisely sets forth the paradox both in the basic setting but also given the version where the two envelopes contain $( \, \$2^k, \$2^{k+1}) \,$  with probability $\frac{( \,\frac{2}{3}) \,^k}{3}$ for each integer $k \geq 0$. Where the paradox is formulated by considering one person’s odds when choosing to swap an envelope, my question is whether the paradox might be resolved by considering the paradox from both swapper’s perspective instead of just one (i.e. for one person to swap, there must be another person for the original to swap with). From a single person’s perspective, the paradoxical odds are traditionally given by the equation: $$0.5( \,0.5x) \, + 0.5( \,2x) \, = 1.25x$$ To incorporate a two-person perspective, the equation would be [what one person stands to gain] less [what they stand to lose = what their opponent stands to gain]: $$[ \,0.5( \,0.5x) \, + 0.5( \,2x) \,] \, - [ \,0.5( \,0.5x) \, + 0.5( \,2x) \,] \, = 0$$ The result is that neither person improves their odds by swapping.  Paradox resolved. Comments, suggestions, agree, disagree…? I’m just fishing here.  Thank you!","Su, Francis, et. al. have a short description of the paradox here: https://www.math.hmc.edu/funfacts/ffiles/20001.6-8.shtml I used that link because it concisely sets forth the paradox both in the basic setting but also given the version where the two envelopes contain $( \, \$2^k, \$2^{k+1}) \,$  with probability $\frac{( \,\frac{2}{3}) \,^k}{3}$ for each integer $k \geq 0$. Where the paradox is formulated by considering one person’s odds when choosing to swap an envelope, my question is whether the paradox might be resolved by considering the paradox from both swapper’s perspective instead of just one (i.e. for one person to swap, there must be another person for the original to swap with). From a single person’s perspective, the paradoxical odds are traditionally given by the equation: $$0.5( \,0.5x) \, + 0.5( \,2x) \, = 1.25x$$ To incorporate a two-person perspective, the equation would be [what one person stands to gain] less [what they stand to lose = what their opponent stands to gain]: $$[ \,0.5( \,0.5x) \, + 0.5( \,2x) \,] \, - [ \,0.5( \,0.5x) \, + 0.5( \,2x) \,] \, = 0$$ The result is that neither person improves their odds by swapping.  Paradox resolved. Comments, suggestions, agree, disagree…? I’m just fishing here.  Thank you!",,"['probability', 'probability-theory', 'paradoxes']"
38,Bound of $\mathbb {P} \lbrace \vert X Y-\mathbb{E}X\mathbb{E}Y\vert >t \rbrace$ using Chernoff-Hoeffding inequality,Bound of  using Chernoff-Hoeffding inequality,\mathbb {P} \lbrace \vert X Y-\mathbb{E}X\mathbb{E}Y\vert >t \rbrace,"From the Chernoff-Hoeffding inequality, we know that for $t \geq 0$ we have $$\mathbb{P} \lbrace \vert X-\mathbb{E}X\vert >t\rbrace \leq 2 \exp\left(-\dfrac{t^{2}}{2}\mathbb{E}X\right).$$ What can I say about  $\mathbb{P} \lbrace \vert X Y-\mathbb{E}X\mathbb{E}Y\vert >t \rbrace$, is it possible to extend this result for this special case? Is it true that  $$\mathbb{P} \lbrace \vert X Y-\mathbb{E}X\mathbb{E}Y\vert >t \rbrace \leq \mathbb{P} \lbrace \vert X-\mathbb{E}X\vert >t \rbrace + \mathbb{P} \lbrace \vert Y-\mathbb{E}Y\vert >t \rbrace \leq 4 \exp\left(-\dfrac{t^{2}}{2}(\mathbb{E}X+\mathbb{E}Y) \right)$$ ? Any help or suggestions are welcomed.","From the Chernoff-Hoeffding inequality, we know that for $t \geq 0$ we have $$\mathbb{P} \lbrace \vert X-\mathbb{E}X\vert >t\rbrace \leq 2 \exp\left(-\dfrac{t^{2}}{2}\mathbb{E}X\right).$$ What can I say about  $\mathbb{P} \lbrace \vert X Y-\mathbb{E}X\mathbb{E}Y\vert >t \rbrace$, is it possible to extend this result for this special case? Is it true that  $$\mathbb{P} \lbrace \vert X Y-\mathbb{E}X\mathbb{E}Y\vert >t \rbrace \leq \mathbb{P} \lbrace \vert X-\mathbb{E}X\vert >t \rbrace + \mathbb{P} \lbrace \vert Y-\mathbb{E}Y\vert >t \rbrace \leq 4 \exp\left(-\dfrac{t^{2}}{2}(\mathbb{E}X+\mathbb{E}Y) \right)$$ ? Any help or suggestions are welcomed.",,"['probability', 'sequences-and-series', 'inequality']"
39,What is the average maximum number of pairs such that $x_i > y_i$ for uniformly distributed random variables $X$ and $Y$?,What is the average maximum number of pairs such that  for uniformly distributed random variables  and ?,x_i > y_i X Y,"Given $X \sim U(a, b)$ and $Y \sim U(c, d)$ I would like to find average maximum number of pairs such that for $pair_i = (x_i, y_i): x_i > y_i$ when I have $n$ samples for $X$ and $n$ samples for $Y$. Example: $X$ is uniformly distributed between $1$ and $10$ and $Y$ is uniformly distributed between $3$ and $11$. I draw $5$ samples for each random variable: $$ X = [5, 7, 9, 3, 7] \qquad Y = [6, 9, 4, 8, 5] $$ I could arrange it into pairs: $$ pairs_a:(5, 6) \quad (7, 9) \quad (9,4) \quad (3,8) \quad (7,5) $$ or another example: $$ pairs_b:(9, 8) \quad (7, 6) \quad (7,5) \quad (5,4) \quad (3,9) $$ Here $pairs_a$ gives me 2 pairs where $x_i > y_i$ but $pairs_b$ gives me 4 such pairs. In this example, the maximum number of pairs fulfilling my condition is 4 (nothing will be greater than $9$ coming from Y).","Given $X \sim U(a, b)$ and $Y \sim U(c, d)$ I would like to find average maximum number of pairs such that for $pair_i = (x_i, y_i): x_i > y_i$ when I have $n$ samples for $X$ and $n$ samples for $Y$. Example: $X$ is uniformly distributed between $1$ and $10$ and $Y$ is uniformly distributed between $3$ and $11$. I draw $5$ samples for each random variable: $$ X = [5, 7, 9, 3, 7] \qquad Y = [6, 9, 4, 8, 5] $$ I could arrange it into pairs: $$ pairs_a:(5, 6) \quad (7, 9) \quad (9,4) \quad (3,8) \quad (7,5) $$ or another example: $$ pairs_b:(9, 8) \quad (7, 6) \quad (7,5) \quad (5,4) \quad (3,9) $$ Here $pairs_a$ gives me 2 pairs where $x_i > y_i$ but $pairs_b$ gives me 4 such pairs. In this example, the maximum number of pairs fulfilling my condition is 4 (nothing will be greater than $9$ coming from Y).",,['probability']
40,Randomly dropping needles in a circle?,Randomly dropping needles in a circle?,,"If we were to randomly drop $n$ needles of random length in a circle,   what would be the odds of finding $k$ intersections? This can be asked   as: Randomly place $n$ line segments in a circle. Their length and position is   determined by $2$ random points uniformly and independently set in that circle. What are the odds   that we will find $k$ intersections? After seeing the main part of the calculation for what I believe to be the solution for $P(2,1)$ , I gave up on calculating $P(n,k)$ because the things behind it are out of my scope ( we barely started mentioning integrals ). But I still want to find the $P(n,k)$. Trying to first calculate the same thing, but with points always being on the circle, seems like a simpler thing to do first: Connecting random points on a circle?","If we were to randomly drop $n$ needles of random length in a circle,   what would be the odds of finding $k$ intersections? This can be asked   as: Randomly place $n$ line segments in a circle. Their length and position is   determined by $2$ random points uniformly and independently set in that circle. What are the odds   that we will find $k$ intersections? After seeing the main part of the calculation for what I believe to be the solution for $P(2,1)$ , I gave up on calculating $P(n,k)$ because the things behind it are out of my scope ( we barely started mentioning integrals ). But I still want to find the $P(n,k)$. Trying to first calculate the same thing, but with points always being on the circle, seems like a simpler thing to do first: Connecting random points on a circle?",,"['probability', 'recreational-mathematics', 'geometric-probability']"
41,Seemingly difficult probabilistic method question,Seemingly difficult probabilistic method question,,"Hello I was asked the following question and I really am not sure how to show such results. I believe it could maybe be done using the probabilistic method. Consider a graph on $ m$ vertices, for any pair of vertices , we include an edge between $i$ and $j$ with probability $1/2$. This is done independently and for every pair $i,j$. The question is to show that for any two vertices, with large probability they share at least $\frac{m}{4}-\sqrt{m\log m}$ common neighbours. My thoughts: It seems like it may be possible to use Chernoff bounds, for any given vertex, if we let $X_{i}$ denote the random variable of the number of neighbours of some vertex $i$, I believe $$E[X_{i}]=\frac{m-1}{2}=\mu$$ So that could possibly be used in computing a probability using Chernoff bound. However, I don't see how I can incorporate that we are looking for shared common neighbours. Maybe using pigeonhole principle? Maybe it is related to Ramsey theorem and edge colouring? Or maybe their is a whole different approach that would work a lot more efficiently? Any ideas? Thanks","Hello I was asked the following question and I really am not sure how to show such results. I believe it could maybe be done using the probabilistic method. Consider a graph on $ m$ vertices, for any pair of vertices , we include an edge between $i$ and $j$ with probability $1/2$. This is done independently and for every pair $i,j$. The question is to show that for any two vertices, with large probability they share at least $\frac{m}{4}-\sqrt{m\log m}$ common neighbours. My thoughts: It seems like it may be possible to use Chernoff bounds, for any given vertex, if we let $X_{i}$ denote the random variable of the number of neighbours of some vertex $i$, I believe $$E[X_{i}]=\frac{m-1}{2}=\mu$$ So that could possibly be used in computing a probability using Chernoff bound. However, I don't see how I can incorporate that we are looking for shared common neighbours. Maybe using pigeonhole principle? Maybe it is related to Ramsey theorem and edge colouring? Or maybe their is a whole different approach that would work a lot more efficiently? Any ideas? Thanks",,"['probability', 'discrete-mathematics', 'graph-theory']"
42,Seemingly Identical Random Variables with Different Variances,Seemingly Identical Random Variables with Different Variances,,"In my probability class, we did the following problem regarding expected values/variance: Consider an experiment where you roll a fair, 6-sided dice until you see a 6. Let $T$ be a random variable denoting the total sum, including the final 6. Also, consider an experiment where you roll a fair, 6-sided dice until you see a 1. Let $S$ be a random variable denoting the total sum, including the final 1. a) Which is larger, $E[T]$ or $E[S]$? We showed that $E[T] = E[S] = 21$, by conditioning $T$ and $S$ on a random variable $N$ denoting the total number of rolls. b) Which is larger, $Var[T]$ or $Var[S]$? Here, we showed that $Var[T] > Var[S]$, by again conditioning on $N$. However, I took a different approach to (b). I noted that when we consider the variance of a random variable, we are really concerned with the deviation between a value the random variable can take and it's expectation, not that actual numbers themselves. Also, note each roll is independent of the others. Therefore, let $T = T_1 + T_2 + ... + T_N$, where $T_i$ is the value rolled on the i-th roll, and define $S_i$ similarly. I believe $Var[T_i] = Var[S_i]$ on any given roll before the final one, as in both experiments, the deviations can take the values $-2, 1, 0, 1, 2$ with probability $\frac{1}{5}$. Furthermore, on the last roll of each experiment, the deviations between the values rolled and the expectation are identical, taking the value $3$. If all of the deviations are identical then, how are the variances different? Note: I do understand how to compute the variances by conditioning on $N$, and accept that my answer was wrong. However, I'm specifically looking for where the logic breaks down in my argument, as it seems that the deviations and probabilities are the same for each experiment, which to me implies that the variances should be equal as well.","In my probability class, we did the following problem regarding expected values/variance: Consider an experiment where you roll a fair, 6-sided dice until you see a 6. Let $T$ be a random variable denoting the total sum, including the final 6. Also, consider an experiment where you roll a fair, 6-sided dice until you see a 1. Let $S$ be a random variable denoting the total sum, including the final 1. a) Which is larger, $E[T]$ or $E[S]$? We showed that $E[T] = E[S] = 21$, by conditioning $T$ and $S$ on a random variable $N$ denoting the total number of rolls. b) Which is larger, $Var[T]$ or $Var[S]$? Here, we showed that $Var[T] > Var[S]$, by again conditioning on $N$. However, I took a different approach to (b). I noted that when we consider the variance of a random variable, we are really concerned with the deviation between a value the random variable can take and it's expectation, not that actual numbers themselves. Also, note each roll is independent of the others. Therefore, let $T = T_1 + T_2 + ... + T_N$, where $T_i$ is the value rolled on the i-th roll, and define $S_i$ similarly. I believe $Var[T_i] = Var[S_i]$ on any given roll before the final one, as in both experiments, the deviations can take the values $-2, 1, 0, 1, 2$ with probability $\frac{1}{5}$. Furthermore, on the last roll of each experiment, the deviations between the values rolled and the expectation are identical, taking the value $3$. If all of the deviations are identical then, how are the variances different? Note: I do understand how to compute the variances by conditioning on $N$, and accept that my answer was wrong. However, I'm specifically looking for where the logic breaks down in my argument, as it seems that the deviations and probabilities are the same for each experiment, which to me implies that the variances should be equal as well.",,"['probability', 'expectation', 'conditional-expectation', 'variance']"
43,Probability of two people passing through same point on random walk,Probability of two people passing through same point on random walk,,"Background I've come across this problem and I just can't figure it out. I know it revolves around the ideas of markov chains and/or one dimensional random walks. I've been able to find solutions for some cases of intersections/collisions on one dimensional random walks but they're usually based on both parties starting at the same point e.g. http://mtdevans.com/projects/physics-problems/random-walk-of-two-drunks/ I haven't been able to expand upon these ideas to cover the following problem. Any insight is greatly appreciated, I'm a bit stumped. The Problem Two people are walking randomly on a line. They start 10 metres from each other. At each time interval, each person has a probability of 1/2 to move 1 metre to the left, and probability 1/2 to move 1 metre to the right. What's the probability that after 7 time intervals, the people have passed through the same point? Thanks for any help in advance.","Background I've come across this problem and I just can't figure it out. I know it revolves around the ideas of markov chains and/or one dimensional random walks. I've been able to find solutions for some cases of intersections/collisions on one dimensional random walks but they're usually based on both parties starting at the same point e.g. http://mtdevans.com/projects/physics-problems/random-walk-of-two-drunks/ I haven't been able to expand upon these ideas to cover the following problem. Any insight is greatly appreciated, I'm a bit stumped. The Problem Two people are walking randomly on a line. They start 10 metres from each other. At each time interval, each person has a probability of 1/2 to move 1 metre to the left, and probability 1/2 to move 1 metre to the right. What's the probability that after 7 time intervals, the people have passed through the same point? Thanks for any help in advance.",,"['probability', 'markov-chains', 'random-walk']"
44,Determining how many cards of a Poker hand to discard,Determining how many cards of a Poker hand to discard,,"I am programming a game of 5 Card Poker, and an AI to play it. I have written a function that calculates, for a given card in a hand, the probability of improving the hand if this card is discarded and swapped for another random card dealt from the deck. As of now, the probability is calculated on the assumption that all other 47 cards are still in the deck. This will be refined at a later stage. I now need to write a function that determines which, and how many (0, 1, 2, or 3) cards to discard from a hand. If I have the probability for each of the 5 cards, what is the best way to determine what combination (of up to 3) of these cards will give the largest possibility in improving the hand? What would be a suitable way to determine, based on this accumulated probability, if the cards should actually be discarded or not?","I am programming a game of 5 Card Poker, and an AI to play it. I have written a function that calculates, for a given card in a hand, the probability of improving the hand if this card is discarded and swapped for another random card dealt from the deck. As of now, the probability is calculated on the assumption that all other 47 cards are still in the deck. This will be refined at a later stage. I now need to write a function that determines which, and how many (0, 1, 2, or 3) cards to discard from a hand. If I have the probability for each of the 5 cards, what is the best way to determine what combination (of up to 3) of these cards will give the largest possibility in improving the hand? What would be a suitable way to determine, based on this accumulated probability, if the cards should actually be discarded or not?",,"['probability', 'combinatorics', 'permutations', 'poker']"
45,"Confusion on three ""types"" of Markov Chain Monte Carlo for the same inference","Confusion on three ""types"" of Markov Chain Monte Carlo for the same inference",,"This is a long question but I would be very grateful if someone can help or provide some reference! And I believe this is a common confusion among beginners of MCMC. Background Given a directed graph $G=(V,E)$ where $V$ is the vertex set and $E\subseteq V^2$ , define a labeling function $z:V \to \{1,...,k\}$ where $z$ partitions the graph in to multiple "" communities "" or "" groups "" or so-called "" planted partitions "" $C_1,...,C_k$ $C_i=\{v\in V: z(v)=i\}$ and $z(v),v\in V$ can be viewed as the ""membership"" of vertex $v$ . Now also define: A cross-group edge probability matrix, or the so-called stochastic block matrix ${\bf P}$ where a vertex in partition $i$ has probability ${\bf P}(i,j)$ with a vertex in partition $j$ . $e_{i,j}$ is the number of edges between partition $i$ and partition $j$ observed in $E$ , $n_{i,j}$ is the maximum number of edges between partition $i$ and partition $j$ . Note $e_{i,j}$ and $n_{i,j}$ are determined by $z$ , or we can say they are functions of $z$ . We assume the edge set is generated by the following simple process: for every pair of nodes $u,v$ , let $(u,v) \in E$ by probability ${\bf P}(z(u),z(v))$ . This is the so-called standard stochastic block model. The probability of $E$ given $z,\bf P$ is $\mathbb{P}\left( {E|{z},{\mathbf{P}}} \right) = \mathop \prod \limits_{i,j \in \{ 1, \ldots ,k\} } {\mathbf{P}}{(i,j)^{{e_{i,j}}}}{\left( {1 - {\mathbf{P}}(i,j)} \right)^{{n_{i,j}} - {e_{i,j}}}}$ whose log-likelihood (the MLE of ${\bf P}(i,j)$ is simply $\frac{e_{i,j}}{n_{i,j}}$ , plug this back in above $\Bbb P$ , take log and after some calculation) is $\ln \mathcal{L}\left( z \right) = \mathop \sum \limits_{i,j \in \left\{ {1, \ldots ,k} \right\}} {e_{i,j}}\ln {e_{i,j}} - {n_{i,j}}\ln {n_{i,j}} + \left( {{n_{i,j}} - {e_{i,j}}} \right)\ln \left( {{n_{i,j}} - {e_{i,j}}} \right)$ there is a simplified likelihood when $E$ is assumed sparse, $\ln \mathcal{L} = \mathop \sum \limits_{i,j \in \left\{ {1, \ldots ,k} \right\}} {e_{i,j}}\ln \frac{{{e_{i,j}}}}{{{n_{i,j}}}}$ Markov Chain Monte Carlo Now the job is to infer $z$ . I encountered three different methods that claim themselves as ""Markov Chain Monte Carlo"", or ""Gibbs Sampler"" in different literature. Some of them are not rigorous math or statistics, so they may be wrong and are causing confusions to me. The same idea among them is to change or ""re-sample"" the membership of each vertexes one by one, the difference is how to make the change. Suppose now we are changing the membership of vertex $v$ , Type I. Let $z(v)$ be the one that mostly increases $\ln \cal L$ , that is, $z(v) = \arg {\max _{z(v) \in \{ 1,...,k\} }}\ln \mathcal{L}(z)$ . I am not sure but this does not look like Monte Carlo to me . It looks more like coordinate ascent from optimization. The computation of above is actually not very high, since changing $z(v)$ only requires re-computation of some of $e_{i,j}$ and $n_{i,j}$ . However, Type I makes most sense to me because it tries to maximize the likelihood. Type II. Re-sample $z(v)$ based on the distribution conditioned on $E$ and other values of $z$ , i.e. re-sample based on $\mathbb{P}\left( {z(v)|{z^{( - v)}},E} \right)$ where $z^{(-v)}$ denotes ""given all other values of $z$ "". If we assume the prior of $z$ as uniform, then it is easy to see $\mathbb{P}\left( {z(v)|{z^{( - v)}},E} \right) \propto \mathbb{P}\left( {E|{z^{( - v)}},z(v)} \right)$ through Bayesian's formula, then we basically just re-sample proportional to the likelihood ${\cal L}({z^{( - v)}},z(v))$ . This seems the standard Gibbs sampler that I learned from class , and its stationary distribution is $\mathbb{P}\left( {z|E} \right)$ . But this does not make sense to me . Why sampling $z(v)$ while we can just greedily choose the best one as in Type I? Type III. Randomly choose $t$ from $1,...,k$ , and let $z(v)$ be reassigned as $t$ with probability $\mathbb{P}\left( {z(v) = t|{z^{( - v)}},E} \right)$ (or we say the proposal of $z(v)=t$ is accepted), and let $z(v)$ remains where it was with probability $1-\mathbb{P}\left( {z(v) = t|{z^{( - v)}},E} \right)$ (or we say the proposal of $z(v)=t$ is rejected). This is Monte Carlo, but I am not sure if it is equivalent to type II , not sure if it has $\mathbb{P}\left( {z|E} \right)$ as the stationary distribution. Also I am puzzled why we are doing this ?","This is a long question but I would be very grateful if someone can help or provide some reference! And I believe this is a common confusion among beginners of MCMC. Background Given a directed graph where is the vertex set and , define a labeling function where partitions the graph in to multiple "" communities "" or "" groups "" or so-called "" planted partitions "" and can be viewed as the ""membership"" of vertex . Now also define: A cross-group edge probability matrix, or the so-called stochastic block matrix where a vertex in partition has probability with a vertex in partition . is the number of edges between partition and partition observed in , is the maximum number of edges between partition and partition . Note and are determined by , or we can say they are functions of . We assume the edge set is generated by the following simple process: for every pair of nodes , let by probability . This is the so-called standard stochastic block model. The probability of given is whose log-likelihood (the MLE of is simply , plug this back in above , take log and after some calculation) is there is a simplified likelihood when is assumed sparse, Markov Chain Monte Carlo Now the job is to infer . I encountered three different methods that claim themselves as ""Markov Chain Monte Carlo"", or ""Gibbs Sampler"" in different literature. Some of them are not rigorous math or statistics, so they may be wrong and are causing confusions to me. The same idea among them is to change or ""re-sample"" the membership of each vertexes one by one, the difference is how to make the change. Suppose now we are changing the membership of vertex , Type I. Let be the one that mostly increases , that is, . I am not sure but this does not look like Monte Carlo to me . It looks more like coordinate ascent from optimization. The computation of above is actually not very high, since changing only requires re-computation of some of and . However, Type I makes most sense to me because it tries to maximize the likelihood. Type II. Re-sample based on the distribution conditioned on and other values of , i.e. re-sample based on where denotes ""given all other values of "". If we assume the prior of as uniform, then it is easy to see through Bayesian's formula, then we basically just re-sample proportional to the likelihood . This seems the standard Gibbs sampler that I learned from class , and its stationary distribution is . But this does not make sense to me . Why sampling while we can just greedily choose the best one as in Type I? Type III. Randomly choose from , and let be reassigned as with probability (or we say the proposal of is accepted), and let remains where it was with probability (or we say the proposal of is rejected). This is Monte Carlo, but I am not sure if it is equivalent to type II , not sure if it has as the stationary distribution. Also I am puzzled why we are doing this ?","G=(V,E) V E\subseteq V^2 z:V \to \{1,...,k\} z C_1,...,C_k C_i=\{v\in V: z(v)=i\} z(v),v\in V v {\bf P} i {\bf P}(i,j) j e_{i,j} i j E n_{i,j} i j e_{i,j} n_{i,j} z z u,v (u,v) \in E {\bf P}(z(u),z(v)) E z,\bf P \mathbb{P}\left( {E|{z},{\mathbf{P}}} \right) = \mathop \prod \limits_{i,j \in \{ 1, \ldots ,k\} } {\mathbf{P}}{(i,j)^{{e_{i,j}}}}{\left( {1 - {\mathbf{P}}(i,j)} \right)^{{n_{i,j}} - {e_{i,j}}}} {\bf P}(i,j) \frac{e_{i,j}}{n_{i,j}} \Bbb P \ln \mathcal{L}\left( z \right) = \mathop \sum \limits_{i,j \in \left\{ {1, \ldots ,k} \right\}} {e_{i,j}}\ln {e_{i,j}} - {n_{i,j}}\ln {n_{i,j}} + \left( {{n_{i,j}} - {e_{i,j}}} \right)\ln \left( {{n_{i,j}} - {e_{i,j}}} \right) E \ln \mathcal{L} = \mathop \sum \limits_{i,j \in \left\{ {1, \ldots ,k} \right\}} {e_{i,j}}\ln \frac{{{e_{i,j}}}}{{{n_{i,j}}}} z v z(v) \ln \cal L z(v) = \arg {\max _{z(v) \in \{ 1,...,k\} }}\ln \mathcal{L}(z) z(v) e_{i,j} n_{i,j} z(v) E z \mathbb{P}\left( {z(v)|{z^{( - v)}},E} \right) z^{(-v)} z z \mathbb{P}\left( {z(v)|{z^{( - v)}},E} \right) \propto \mathbb{P}\left( {E|{z^{( - v)}},z(v)} \right) {\cal L}({z^{( - v)}},z(v)) \mathbb{P}\left( {z|E} \right) z(v) t 1,...,k z(v) t \mathbb{P}\left( {z(v) = t|{z^{( - v)}},E} \right) z(v)=t z(v) 1-\mathbb{P}\left( {z(v) = t|{z^{( - v)}},E} \right) z(v)=t \mathbb{P}\left( {z|E} \right)","['probability', 'markov-chains', 'monte-carlo']"
46,Probability of two fixed-length line segments intersecting within a circular domain,Probability of two fixed-length line segments intersecting within a circular domain,,"Imagine placing a line segment P of length a on the XY plane such that its middle is at the origin, but its orientation is random (i.e. random angle). Then suppose you placed another line segment Q of length b (which is less than or equal to a ) such that its centre was randomly chosen within a radius (a+b)/2 from the origin, but its orientation was also random. What would the probability of these two line segments intersecting be? I suspect there may be an integral over the circular surface to be done here, but am not quite sure what to do! Any help much appreciated. Thank you.","Imagine placing a line segment P of length a on the XY plane such that its middle is at the origin, but its orientation is random (i.e. random angle). Then suppose you placed another line segment Q of length b (which is less than or equal to a ) such that its centre was randomly chosen within a radius (a+b)/2 from the origin, but its orientation was also random. What would the probability of these two line segments intersecting be? I suspect there may be an integral over the circular surface to be done here, but am not quite sure what to do! Any help much appreciated. Thank you.",,"['calculus', 'probability', 'geometry', 'geometric-probability']"
47,What is the distribution of this random variable? (Practicing for an exam),What is the distribution of this random variable? (Practicing for an exam),,"I have in my possession a theoretical and practical test that evaluates the knowledge of a semester of the subject Probability and Statistics, that is, a written exam. The same is from July 30, 2013. Clarification: I am not allowed to go online during an evaluation. This test I am doing at home to evaluate myself. Activity 1 The $ 35 $ % of the students who took the first semester of the Computer Technologist, passed the subject MDyL1. It is considered a sample of $ 10 $ students of that semester and the random variable $ X $ : number of students who have passed the subject MDyL1, among the selected $ 10 $ . a) Calculate the probability that more than two students in the sample have passed the subject MDyL1. b) Find the probability that less than half of the students in the sample have passed the subject MDyL1. c) Determine $ E (X) $ and $ Var (X) $ . Can the random variable $X$ have a binomial distribution? That is, each student pass a subject independently. It is known that the probability of that happening is $ p = 0.35 $ , then the number of repetitions of that experiment should be $ n = 10 $ . That is, $ X $ ~ $B (10,0.35)$ , so that: -Using the binomial distribution table- a) $P(X>2) = 1-P(X≤2) = 1-0.2616 = 0.7384$ b) $P(X<5) = P(X≤4) = 0.7515$ c) $E(X) = np = 10 \times 0.35 = 3.5$ $Var(X) = np(1-p) = 3.5 \times 0.65 = 2.275$ Is it okay to assume that each student passes a subject independently? Because the exercise does not clarify it. It says that 35% passes the subject, but not that each has a 35% chance of passing. I hope you can help me. Thank you very much.","I have in my possession a theoretical and practical test that evaluates the knowledge of a semester of the subject Probability and Statistics, that is, a written exam. The same is from July 30, 2013. Clarification: I am not allowed to go online during an evaluation. This test I am doing at home to evaluate myself. Activity 1 The % of the students who took the first semester of the Computer Technologist, passed the subject MDyL1. It is considered a sample of students of that semester and the random variable : number of students who have passed the subject MDyL1, among the selected . a) Calculate the probability that more than two students in the sample have passed the subject MDyL1. b) Find the probability that less than half of the students in the sample have passed the subject MDyL1. c) Determine and . Can the random variable have a binomial distribution? That is, each student pass a subject independently. It is known that the probability of that happening is , then the number of repetitions of that experiment should be . That is, ~ , so that: -Using the binomial distribution table- a) b) c) Is it okay to assume that each student passes a subject independently? Because the exercise does not clarify it. It says that 35% passes the subject, but not that each has a 35% chance of passing. I hope you can help me. Thank you very much."," 35   10   X   10   E (X)   Var (X)  X  p = 0.35   n = 10   X  B (10,0.35) P(X>2) = 1-P(X≤2) = 1-0.2616 = 0.7384 P(X<5) = P(X≤4) = 0.7515 E(X) = np = 10 \times 0.35 = 3.5 Var(X) = np(1-p) = 3.5 \times 0.65 = 2.275","['probability', 'probability-distributions', 'self-learning', 'percentages']"
48,How to calculate the Variance of the Wishart distribution,How to calculate the Variance of the Wishart distribution,,"Let $X \sim \mathcal{W}_p(V,\nu)$ follow a central Wishart distribution with scale matrix $V$ and $\nu$ degrees of freedom. Its p.d.f. is given by: $$ \frac{|\mathbf{X}|^{(\nu-p-1)/2} e^{-\operatorname{tr}(\mathbf{V}^{-1}\mathbf{X})/2}}{2^\frac{\nu p}{2}|{\mathbf V}|^{\nu/2}\Gamma_p(\frac \nu 2)}  $$ The variance can be described by the $n^2 \times n^2$ matrix $$ Cov(vec(X))=\frac{1}{\nu} \left(I_{n^2}+K_{nn}\right)\left(V \otimes V\right), $$ where $K_{nn}$ is the commutation matrix defined by $Kvec(A)=vec(A')$. How can we calculate this covariance matrix? Is there a general way to do it for matrix valued distributions?","Let $X \sim \mathcal{W}_p(V,\nu)$ follow a central Wishart distribution with scale matrix $V$ and $\nu$ degrees of freedom. Its p.d.f. is given by: $$ \frac{|\mathbf{X}|^{(\nu-p-1)/2} e^{-\operatorname{tr}(\mathbf{V}^{-1}\mathbf{X})/2}}{2^\frac{\nu p}{2}|{\mathbf V}|^{\nu/2}\Gamma_p(\frac \nu 2)}  $$ The variance can be described by the $n^2 \times n^2$ matrix $$ Cov(vec(X))=\frac{1}{\nu} \left(I_{n^2}+K_{nn}\right)\left(V \otimes V\right), $$ where $K_{nn}$ is the commutation matrix defined by $Kvec(A)=vec(A')$. How can we calculate this covariance matrix? Is there a general way to do it for matrix valued distributions?",,"['probability', 'probability-theory', 'probability-distributions', 'expectation', 'random-matrices']"
49,How to simulate a Super-Brownian Motion (SBM)?,How to simulate a Super-Brownian Motion (SBM)?,,"I'll start by doing this in MATLAB . A Standard Brownian Motion $dX_t$ can be approximated by a scaled random walk through $\triangle{X}=Z\sqrt{\triangle t}$. Analogously the drift of a Super-Brownian Motion can be approximated as $\dot{W}(t,x)=Z_{x,t}\sqrt{\triangle t}\sqrt{\triangle x}$ where $Z_{x,t}\sim N(0,1)$ or a random variable with variance 1. For example, a Bernoulli random variable taking 1 and -1 each with probability $\frac{1}{2}$ A Super-Brownian Motion is a continuous stochastic process satisfying the differential equation $$\frac{\partial X}{\partial t}=\frac{X''(t,x)}{2}+\sqrt{X}\dot{W}$$ By Feyman-Kac's formula and Ito's Isometry $$E[[\int_0^t\int_{\mathbb{R}}\sqrt{X(s,x)}dW(s,x)]^2]=E[\int_0^t\int_{\mathbb{R}}X(s,x)dxds]$$ Thus we may discretize the solution by $$E[\sum_{s<t}\sum_{s\in\mathbb{R}}\sqrt{X(s,x)}Z_{x,s}\sqrt{\triangle t}\sqrt{\triangle x}]\approx E[\sum_{s<t}\sum_{x\in\mathbb{R}}X(s,x)Z_{x,s}^2\triangle t\triangle x]$$ To simulate the stochastic differential equation, we may have $$\frac{X''(t,x)}{2}\approx \frac{1}{2}X(t,x+\triangle x)+\frac{1}{2}X(t,x-\triangle x)-X(t,x)$$ and $$\frac{\partial X}{\partial t}\approx X(t+\triangle t,x)-X(t,x)$$ For more about simulating Super-Brownian Motion, see Achim Klenke: http://www.aklenke.de .","I'll start by doing this in MATLAB . A Standard Brownian Motion $dX_t$ can be approximated by a scaled random walk through $\triangle{X}=Z\sqrt{\triangle t}$. Analogously the drift of a Super-Brownian Motion can be approximated as $\dot{W}(t,x)=Z_{x,t}\sqrt{\triangle t}\sqrt{\triangle x}$ where $Z_{x,t}\sim N(0,1)$ or a random variable with variance 1. For example, a Bernoulli random variable taking 1 and -1 each with probability $\frac{1}{2}$ A Super-Brownian Motion is a continuous stochastic process satisfying the differential equation $$\frac{\partial X}{\partial t}=\frac{X''(t,x)}{2}+\sqrt{X}\dot{W}$$ By Feyman-Kac's formula and Ito's Isometry $$E[[\int_0^t\int_{\mathbb{R}}\sqrt{X(s,x)}dW(s,x)]^2]=E[\int_0^t\int_{\mathbb{R}}X(s,x)dxds]$$ Thus we may discretize the solution by $$E[\sum_{s<t}\sum_{s\in\mathbb{R}}\sqrt{X(s,x)}Z_{x,s}\sqrt{\triangle t}\sqrt{\triangle x}]\approx E[\sum_{s<t}\sum_{x\in\mathbb{R}}X(s,x)Z_{x,s}^2\triangle t\triangle x]$$ To simulate the stochastic differential equation, we may have $$\frac{X''(t,x)}{2}\approx \frac{1}{2}X(t,x+\triangle x)+\frac{1}{2}X(t,x-\triangle x)-X(t,x)$$ and $$\frac{\partial X}{\partial t}\approx X(t+\triangle t,x)-X(t,x)$$ For more about simulating Super-Brownian Motion, see Achim Klenke: http://www.aklenke.de .",,"['probability', 'stochastic-processes', 'stochastic-integrals', 'simulation']"
50,Moments of the Conditional variance,Moments of the Conditional variance,,"If $X$ and $Y$ are two random variables, then the law of total variance allows us to calculate the first moment of $\text{Var}(X|Y)$ by $$E[\text{Var}(X|Y)] = \text{Var}(X) - \text{Var}(E[X|Y]).$$ In particular we have that $E[\text{Var}(X|Y)] < \text{Var}(X)$. I'm wondering if similar relations may hold for higher moments of $\text{Var}(X|Y)$. For example can we say something about $E[\text{Var}(X|Y)^2]$ compared to  $\text{Var}(X)^2$? I will just comment that for any $n\in \mathbb{N}$ we have the following $$\text{Var}(X|Y)^n \leq E[X^2|Y]^n$$ and so $$E[\text{Var}(X|Y)^n]\leq E[X^{2n}].$$","If $X$ and $Y$ are two random variables, then the law of total variance allows us to calculate the first moment of $\text{Var}(X|Y)$ by $$E[\text{Var}(X|Y)] = \text{Var}(X) - \text{Var}(E[X|Y]).$$ In particular we have that $E[\text{Var}(X|Y)] < \text{Var}(X)$. I'm wondering if similar relations may hold for higher moments of $\text{Var}(X|Y)$. For example can we say something about $E[\text{Var}(X|Y)^2]$ compared to  $\text{Var}(X)^2$? I will just comment that for any $n\in \mathbb{N}$ we have the following $$\text{Var}(X|Y)^n \leq E[X^2|Y]^n$$ and so $$E[\text{Var}(X|Y)^n]\leq E[X^{2n}].$$",,"['probability', 'probability-theory', 'conditional-expectation']"
51,Probabilistic Interpretation of Laplace-Beltrami Spectrum,Probabilistic Interpretation of Laplace-Beltrami Spectrum,,"Given a Riemannian manifold, $(M,g)$, the eigenvalues $\lambda_i$ and eigenfunctions $\phi_i$ of the associated Laplace-Beltrami operator $\Delta_g$ can be used to construct the heat kernel on the manifold, as well as solve the wave and Schrodinger equations (e.g. see this question ). There are some interesting probabilistic facts about these constructs: On the manifold, the infinitesimal generator of Brownian motion is $\Delta_g/2$ (e.g. see here ) The heat kernel (i.e. the smallest positive fundamental solution to $\partial_t u = \Delta_g u$) serves as the transition density function of Brownian motion on the manifold (e.g. see Heat Kernel on a Non-Compact Riemannian Manifold, by  Grigor’yan ), and can be written via a spectral decomposition as: $$  p(x,y,t) = \sum_{i=1}^\infty \exp(-t\lambda_i)\phi_i(x)\phi_i(y) $$ My question is whether there are other stochastic interpretations of the Laplace-Beltrami operator. In particular, do the eigenvalues and eigenvectors themselves have any kind of probabilistic interpretation on their own?","Given a Riemannian manifold, $(M,g)$, the eigenvalues $\lambda_i$ and eigenfunctions $\phi_i$ of the associated Laplace-Beltrami operator $\Delta_g$ can be used to construct the heat kernel on the manifold, as well as solve the wave and Schrodinger equations (e.g. see this question ). There are some interesting probabilistic facts about these constructs: On the manifold, the infinitesimal generator of Brownian motion is $\Delta_g/2$ (e.g. see here ) The heat kernel (i.e. the smallest positive fundamental solution to $\partial_t u = \Delta_g u$) serves as the transition density function of Brownian motion on the manifold (e.g. see Heat Kernel on a Non-Compact Riemannian Manifold, by  Grigor’yan ), and can be written via a spectral decomposition as: $$  p(x,y,t) = \sum_{i=1}^\infty \exp(-t\lambda_i)\phi_i(x)\phi_i(y) $$ My question is whether there are other stochastic interpretations of the Laplace-Beltrami operator. In particular, do the eigenvalues and eigenvectors themselves have any kind of probabilistic interpretation on their own?",,"['probability', 'differential-geometry', 'stochastic-processes', 'riemannian-geometry', 'spectral-theory']"
52,Probability that two multinomial samples are the same?,Probability that two multinomial samples are the same?,,"Say I take $N$ samples (with replacement) from an urn with $M$ balls each a distinct color. I note the result, then repeat the process once again, and note the second result. I'm interested in the probability that the two samples are the same (that is, both had same number of each of the colors present in the sample.) This is obviously the sum of the squares of the PMF of the required multinomial distribution over the weak compositions of $N$ of length $M$, and since the balls are equiprobable, this simplifies to a more efficient scheme by doing the same over the integer partitions of $N$ with appropriate multiplications. For large $N$ this quickly becomes intractable. Is there a better way to calculate the desired result, or a reasonably accurate estimator for cases where $N>>M$?","Say I take $N$ samples (with replacement) from an urn with $M$ balls each a distinct color. I note the result, then repeat the process once again, and note the second result. I'm interested in the probability that the two samples are the same (that is, both had same number of each of the colors present in the sample.) This is obviously the sum of the squares of the PMF of the required multinomial distribution over the weak compositions of $N$ of length $M$, and since the balls are equiprobable, this simplifies to a more efficient scheme by doing the same over the integer partitions of $N$ with appropriate multiplications. For large $N$ this quickly becomes intractable. Is there a better way to calculate the desired result, or a reasonably accurate estimator for cases where $N>>M$?",,"['probability', 'combinatorics', 'balls-in-bins']"
53,"Prob 33, Ch. 3 - Two proofreaders reading a book with n typos - Discrete probability distributions, Blitzstein and Hwang","Prob 33, Ch. 3 - Two proofreaders reading a book with n typos - Discrete probability distributions, Blitzstein and Hwang",,"I would like someone to verify my result to parts (a) and (b) of this problem. A book has $n$ typos. Two proofreaders Prue and Frida independently read the book. Prue catches each typo with probability $p_{1}$ and misses it with probability $q_{1}=1-p_{1}$, and likewise for Frida, who has probabilities $p_{2}$ if catching and $q_{2}=1-p_{2}$ of missing each typo. Let $X_{1}$ be the number of typos caught by Prue, $X_{2}$ be the number of typos caught by Frida and $X$, be the number of typos caught by atleast one of the proofreaders. (a) Find the distribution of $X$. Solution. Define an r.v. $I_{p}$. $$\begin{align} I_{p}&=1 \text{, if Prue catches an error}\\ &=0 \text{, if Prue misses to catch an error} \end{align}$$ We have, $$\begin{align} P(I_{p}=1)&=p_{1}\\ P(I_{p}=0)&=1-p_{1} \end{align}$$ On similar lines, $$\begin{align} P(I_{f}=1)&=p_{2}\\ P(I_{f}=0)&=1-p_{2} \end{align}$$ We have, $\begin{align} P(I_{p}=1\cup{I_{f}}=1)&=P(I_{p}=1)+P(I_{f}=1)-P(I_{p}=1,I_{f}=1)\\ &= p_{1}+p_{2}-p_{1}p_{2} \end{align}$ Thus, define success as, a typo is caught by atleast one of the proof-readers. Each of the $n$ typos can be caught or missed by atleast one proofreader. These can be conceived as $n$ independent Bernoulli trials. Therefore, $X\sim{Binomial(n,p_{1}+p_{2}-p_{1}p_{2})}$. $\displaystyle{P(X=x)={{n}\choose{x}}(p_{1}+p_{2}-p_{1}p_{2})^{x}(1-p_{1}-p_{2}+p_{1}p_{2})^{n-x}}$ (b) For this part only, assume $p_{1}=p_{2}$. Find the conditional distribution of $X_{1}$, given that $X_{1}+X_{2}=t$. Solution. $\begin{align} P(X_{1}=x|X_{1}+X_{2}=t)&=\frac{P(X_{1}=x,X_{1}+X_{2}=t)}{P(X_{1}+X_{2}=t)}\\ &=\frac{{{n}\choose{x}}p^{x}(1-p)^{n-x}{{n}\choose{t-x}}p^{t-x}(1-p)^{n-(t-x)}}{{{2n}\choose{t}}p^{t}(1-p)^{2n-t}}\\ &=\frac{{{n}\choose{x}}{{n}\choose{t-x}}}{{{2n}\choose{t}}} \end{align}$","I would like someone to verify my result to parts (a) and (b) of this problem. A book has $n$ typos. Two proofreaders Prue and Frida independently read the book. Prue catches each typo with probability $p_{1}$ and misses it with probability $q_{1}=1-p_{1}$, and likewise for Frida, who has probabilities $p_{2}$ if catching and $q_{2}=1-p_{2}$ of missing each typo. Let $X_{1}$ be the number of typos caught by Prue, $X_{2}$ be the number of typos caught by Frida and $X$, be the number of typos caught by atleast one of the proofreaders. (a) Find the distribution of $X$. Solution. Define an r.v. $I_{p}$. $$\begin{align} I_{p}&=1 \text{, if Prue catches an error}\\ &=0 \text{, if Prue misses to catch an error} \end{align}$$ We have, $$\begin{align} P(I_{p}=1)&=p_{1}\\ P(I_{p}=0)&=1-p_{1} \end{align}$$ On similar lines, $$\begin{align} P(I_{f}=1)&=p_{2}\\ P(I_{f}=0)&=1-p_{2} \end{align}$$ We have, $\begin{align} P(I_{p}=1\cup{I_{f}}=1)&=P(I_{p}=1)+P(I_{f}=1)-P(I_{p}=1,I_{f}=1)\\ &= p_{1}+p_{2}-p_{1}p_{2} \end{align}$ Thus, define success as, a typo is caught by atleast one of the proof-readers. Each of the $n$ typos can be caught or missed by atleast one proofreader. These can be conceived as $n$ independent Bernoulli trials. Therefore, $X\sim{Binomial(n,p_{1}+p_{2}-p_{1}p_{2})}$. $\displaystyle{P(X=x)={{n}\choose{x}}(p_{1}+p_{2}-p_{1}p_{2})^{x}(1-p_{1}-p_{2}+p_{1}p_{2})^{n-x}}$ (b) For this part only, assume $p_{1}=p_{2}$. Find the conditional distribution of $X_{1}$, given that $X_{1}+X_{2}=t$. Solution. $\begin{align} P(X_{1}=x|X_{1}+X_{2}=t)&=\frac{P(X_{1}=x,X_{1}+X_{2}=t)}{P(X_{1}+X_{2}=t)}\\ &=\frac{{{n}\choose{x}}p^{x}(1-p)^{n-x}{{n}\choose{t-x}}p^{t-x}(1-p)^{n-(t-x)}}{{{2n}\choose{t}}p^{t}(1-p)^{2n-t}}\\ &=\frac{{{n}\choose{x}}{{n}\choose{t-x}}}{{{2n}\choose{t}}} \end{align}$",,"['probability', 'probability-theory', 'probability-distributions', 'independence', 'binomial-distribution']"
54,"Is it true that almost all sequences on [0,1] are equidistributed? and almost none are uniformly equidistributed?","Is it true that almost all sequences on [0,1] are equidistributed? and almost none are uniformly equidistributed?",,"Definition 1 . A sequence $(x_n)$ of real numbers on $[0,1]$ is said to be equidistributed on $[0,1]$ if for any interval $[a,b] \subseteq [0,1]$, the sequence $\frac{\{x_1,\ldots,x_n\} \cap [a,b]}{n}$ converges to $b-a$ as $n \to \infty$. Definition 2 . A sequence $(x_n)$ of real numbers on $[0,1]$ is said to be uniformly equidistributed (or well-distributed ) on $[0,1]$ if for any interval $[a,b] \subseteq [0,1]$, the sequence $\frac{\{x_{k+1},\ldots,x_{k+n}\} \cap [a,b]}{n}$ converges to $b-a$ uniformly in $k$ as $n \to \infty$. For some discussion of these notions, see for example the wikipedia page: https://en.wikipedia.org/wiki/Equidistributed_sequence Question 1 . What is the probability that a random sequence on $[0,1]$ is equidistributed? Particularly, is it true that almost all sequences on $[0,1]$ are equidistributed? Question 2 . What is the probability that a random sequence on $[0,1]$ is uniformly equidistributed? Particularly, is it true that almost none sequences on $[0,1]$ are uniformly equidistributed? Are these some well-known results?","Definition 1 . A sequence $(x_n)$ of real numbers on $[0,1]$ is said to be equidistributed on $[0,1]$ if for any interval $[a,b] \subseteq [0,1]$, the sequence $\frac{\{x_1,\ldots,x_n\} \cap [a,b]}{n}$ converges to $b-a$ as $n \to \infty$. Definition 2 . A sequence $(x_n)$ of real numbers on $[0,1]$ is said to be uniformly equidistributed (or well-distributed ) on $[0,1]$ if for any interval $[a,b] \subseteq [0,1]$, the sequence $\frac{\{x_{k+1},\ldots,x_{k+n}\} \cap [a,b]}{n}$ converges to $b-a$ uniformly in $k$ as $n \to \infty$. For some discussion of these notions, see for example the wikipedia page: https://en.wikipedia.org/wiki/Equidistributed_sequence Question 1 . What is the probability that a random sequence on $[0,1]$ is equidistributed? Particularly, is it true that almost all sequences on $[0,1]$ are equidistributed? Question 2 . What is the probability that a random sequence on $[0,1]$ is uniformly equidistributed? Particularly, is it true that almost none sequences on $[0,1]$ are uniformly equidistributed? Are these some well-known results?",,"['probability', 'equidistribution']"
55,Is the inverse of the standard deviation Sub-Gaussian?,Is the inverse of the standard deviation Sub-Gaussian?,,"A zero mean sub-Gaussian random variable Z satisfies $Eexp(tZ)≤exp(t^2k^2/2)$ for some constant k>0. Let's say we have random variables: $X_1,X_2,...,X_n$ with $EX_i=\mu$ and $Var(X_i)=\sigma^2$. We know that $\hat{\sigma}$ is consistent. I am interested in obtaining tail bounds for the inverse of the estimator of the standard error: $1/\hat{\sigma}$, where $\hat{\sigma}=\sqrt{\frac{1}{n}\sum_{i=1}^n (X_i-\bar{X})^2}$ and $\bar{X}=\frac{1}{n}\sum_{i=1}^nX_i$. I didn't find anything in the literature. If the $X_i$ are standard Gaussian random variables, then $\hat{\sigma}^2$ is distributed according to a chi-squared distribution. Can we prove that if $X_i$ are sub-Gaussian, $\hat{\sigma}$ is sub-Gaussian or sub-exponential? And what about its inverse? Or more generally, can we prove that under some assumptions on the $X_i$, it exists a $n$ such that $1/\hat{\sigma}$ is sub-Gaussian? Thanks you in advance","A zero mean sub-Gaussian random variable Z satisfies $Eexp(tZ)≤exp(t^2k^2/2)$ for some constant k>0. Let's say we have random variables: $X_1,X_2,...,X_n$ with $EX_i=\mu$ and $Var(X_i)=\sigma^2$. We know that $\hat{\sigma}$ is consistent. I am interested in obtaining tail bounds for the inverse of the estimator of the standard error: $1/\hat{\sigma}$, where $\hat{\sigma}=\sqrt{\frac{1}{n}\sum_{i=1}^n (X_i-\bar{X})^2}$ and $\bar{X}=\frac{1}{n}\sum_{i=1}^nX_i$. I didn't find anything in the literature. If the $X_i$ are standard Gaussian random variables, then $\hat{\sigma}^2$ is distributed according to a chi-squared distribution. Can we prove that if $X_i$ are sub-Gaussian, $\hat{\sigma}$ is sub-Gaussian or sub-exponential? And what about its inverse? Or more generally, can we prove that under some assumptions on the $X_i$, it exists a $n$ such that $1/\hat{\sigma}$ is sub-Gaussian? Thanks you in advance",,"['probability', 'statistics', 'asymptotics']"
56,Probabilties using Central Limit Theorem,Probabilties using Central Limit Theorem,,"Let n be an independent random variables and the number of orders in a 120 minute period. Given that $\mu$ is 1.5 minutes and that $\sigma$ is 1 minute use the Central Limit Theorem to find the Largest Value of n which gives a 95% chance of completion in that time. I understand that the mean time per order is 1.5 minutes with a deviation of 1 minute, but I am unsure how to find this without using trial and error. I'm thinking that it's something along the lines of $0.95=P(\frac{X-1}{1.5}<\frac{x_{0.95}-1}{1.5})$ How does this differ from the Chebyshev Inequality in terms of result?","Let n be an independent random variables and the number of orders in a 120 minute period. Given that $\mu$ is 1.5 minutes and that $\sigma$ is 1 minute use the Central Limit Theorem to find the Largest Value of n which gives a 95% chance of completion in that time. I understand that the mean time per order is 1.5 minutes with a deviation of 1 minute, but I am unsure how to find this without using trial and error. I'm thinking that it's something along the lines of $0.95=P(\frac{X-1}{1.5}<\frac{x_{0.95}-1}{1.5})$ How does this differ from the Chebyshev Inequality in terms of result?",,"['real-analysis', 'probability', 'probability-theory', 'central-limit-theorem', 'chebyshev-polynomials']"
57,Standard error of exteremely biased coin,Standard error of exteremely biased coin,,"OK, so I know that the typical standard error of a coin is estimated by $$\sigma_p=\sqrt{ \frac{p*(1-p)}n }$$ where $p$ is the estimated probability and and $n$ is the number of samples. This seems reasonable at high $n$ and $p \sim 0.5$; however, it seems unreasonable if I have $p = 1$ and $n = 20$, $\sigma_p = 0$. Is there a better formula for standard error when $ p \sim 0$ or $p \sim 1$ and $n$ is low? Note: this is a real-world problem and increasing $n$ is non-trivial. Thanks!","OK, so I know that the typical standard error of a coin is estimated by $$\sigma_p=\sqrt{ \frac{p*(1-p)}n }$$ where $p$ is the estimated probability and and $n$ is the number of samples. This seems reasonable at high $n$ and $p \sim 0.5$; however, it seems unreasonable if I have $p = 1$ and $n = 20$, $\sigma_p = 0$. Is there a better formula for standard error when $ p \sim 0$ or $p \sim 1$ and $n$ is low? Note: this is a real-world problem and increasing $n$ is non-trivial. Thanks!",,"['probability', 'statistics']"
58,probability of events after a number of tries,probability of events after a number of tries,,"Suppose a player is playing a game and killing a monster, and the likelihood of a monster dropping an item is given by some probability p.  The player would like to know the probability of getting $\bf{exactly}$ n of these drops in m kills. My thought process is this: If the monster has a probability of dropping an item as p, then the probability of it happening n times in m kills can be visualized by some m-dimensional vector, whose entries can be filled with n checkmarks and (m-n) X's, where the checkmarks mean that the drop has been attained on that kill.  So a 30-vector whose 1st and 30th entries are checkmarks and all other entries are X's correspond to the player receiving a drop on the 1st and 30th kills and nothing on the other kills. To describe this mathematically, I reason that the probability of any given vector configuration is given by $$(1-p)^{m-n}p^n$$  However, the checkmarks can be rearranged in any order, so the expression becomes $$\frac{(1-p)^{m-n}p^nm!}{(m-n)!}$$ I feel as though somehow this is wrong.  Hopefully I am making my thought process clear.","Suppose a player is playing a game and killing a monster, and the likelihood of a monster dropping an item is given by some probability p.  The player would like to know the probability of getting $\bf{exactly}$ n of these drops in m kills. My thought process is this: If the monster has a probability of dropping an item as p, then the probability of it happening n times in m kills can be visualized by some m-dimensional vector, whose entries can be filled with n checkmarks and (m-n) X's, where the checkmarks mean that the drop has been attained on that kill.  So a 30-vector whose 1st and 30th entries are checkmarks and all other entries are X's correspond to the player receiving a drop on the 1st and 30th kills and nothing on the other kills. To describe this mathematically, I reason that the probability of any given vector configuration is given by $$(1-p)^{m-n}p^n$$  However, the checkmarks can be rearranged in any order, so the expression becomes $$\frac{(1-p)^{m-n}p^nm!}{(m-n)!}$$ I feel as though somehow this is wrong.  Hopefully I am making my thought process clear.",,[]
59,Inverting Conditional Expectation,Inverting Conditional Expectation,,"I'm having difficulty finding papers which deal with the following inversion problem. Suppose I stochastic process $Y_t$ (which is described by a certain Hilbert-Space-valued SDE).  I want to know how to characterize all stochastic processes $X_t$ satisfying the following: If $\mathfrak{G}_t$ is the filtration generated by $Y_t$ and $\mathfrak{F}_t$ is the filtration generated by $X_t$, then $$ \mathfrak{G}_t\subseteq \mathfrak{F}_t$$ $\mathbb{E}[X_t \mid \mathfrak{G}_t]=Y_t$. I expect this has something to do with inverting the conditional expectation given $\mathfrak{F}_t$, but how can I do that?","I'm having difficulty finding papers which deal with the following inversion problem. Suppose I stochastic process $Y_t$ (which is described by a certain Hilbert-Space-valued SDE).  I want to know how to characterize all stochastic processes $X_t$ satisfying the following: If $\mathfrak{G}_t$ is the filtration generated by $Y_t$ and $\mathfrak{F}_t$ is the filtration generated by $X_t$, then $$ \mathfrak{G}_t\subseteq \mathfrak{F}_t$$ $\mathbb{E}[X_t \mid \mathfrak{G}_t]=Y_t$. I expect this has something to do with inverting the conditional expectation given $\mathfrak{F}_t$, but how can I do that?",,"['probability', 'probability-theory', 'stochastic-processes', 'conditional-expectation', 'stochastic-integrals']"
60,Sufficient and complete statistic: hypergeometrical distribution,Sufficient and complete statistic: hypergeometrical distribution,,"How can one show that for a r.v. $X$ that is hypergeometrically distributed, i.e. $X\sim H_{N, A, n} (N, n \text{ fixed})$, $X$ is sufficient and complete for the part $\theta = \frac{A}{N}$. So the definition of sufficient is that the conditional distribution $X\mid T=t$ is independent of $\theta$. One can show that sufficency is equivalent to $$f_{\theta}(x) = g(T(x), \theta) h(x).$$ Do I have to use this criterion or is it possible to show it directly? How could I start here? I guess like that: \begin{align} P(X=x) & = \frac{ \binom A x \binom{N-A}{n-x}}{\binom{N}{n}} =\frac{A! (N-A)! (N-n)!}{(A-x)!(N-A-n+x)!N!} \cdot \frac{n!}{x!(n-x)!} \\[10pt] & = \frac{A! (N-A)! (N-n)!}{(A-x)! (N-A-n+x)!N!} \binom n x \end{align} which is probably almost the factorization required? The definition of completness is that if $E_{\theta} h(T) = 0 \text{ } \forall \theta \in \Theta$, then $h(t)=0$ a.s. Do I have to find one specific function to prove this?","How can one show that for a r.v. $X$ that is hypergeometrically distributed, i.e. $X\sim H_{N, A, n} (N, n \text{ fixed})$, $X$ is sufficient and complete for the part $\theta = \frac{A}{N}$. So the definition of sufficient is that the conditional distribution $X\mid T=t$ is independent of $\theta$. One can show that sufficency is equivalent to $$f_{\theta}(x) = g(T(x), \theta) h(x).$$ Do I have to use this criterion or is it possible to show it directly? How could I start here? I guess like that: \begin{align} P(X=x) & = \frac{ \binom A x \binom{N-A}{n-x}}{\binom{N}{n}} =\frac{A! (N-A)! (N-n)!}{(A-x)!(N-A-n+x)!N!} \cdot \frac{n!}{x!(n-x)!} \\[10pt] & = \frac{A! (N-A)! (N-n)!}{(A-x)! (N-A-n+x)!N!} \binom n x \end{align} which is probably almost the factorization required? The definition of completness is that if $E_{\theta} h(T) = 0 \text{ } \forall \theta \in \Theta$, then $h(t)=0$ a.s. Do I have to find one specific function to prove this?",,"['probability', 'probability-theory', 'statistics', 'probability-distributions']"
61,Is there any consistent theory for multivariate multiple regression?,Is there any consistent theory for multivariate multiple regression?,,"Given $X \in R^{n*p}$, representing the regression coefficients as an $p*k$ matrix $B^*$. the multivariate multiple regression model takes the form $Y=XB^* + W$,  where $Y\in R^{n*k}$ denotes the multiple response matrix and $W\in R^{n*k}$ are matrices of zero-mean noise, respectively. G. Obozinski, M. J. Wainwright, and M. I. Jordan. Support union recovery in high-dimensional multivariate regression. The Annals of Statistics, 39(1):1–47, 2011. The THEOREM 1 (Eq.(20)) of this paper provides an upper bound between the multivariate group Lasso solution $\hat{B}$ and regression matrix $B^*$. The upper bound depends on the correlations of design matrices $X$, however, does not consider the relations of response matrix $Y$. For multivariate multiple regression, is there any references providing the consistent theory or support recovery theory considering the relations of response matrix $Y$?","Given $X \in R^{n*p}$, representing the regression coefficients as an $p*k$ matrix $B^*$. the multivariate multiple regression model takes the form $Y=XB^* + W$,  where $Y\in R^{n*k}$ denotes the multiple response matrix and $W\in R^{n*k}$ are matrices of zero-mean noise, respectively. G. Obozinski, M. J. Wainwright, and M. I. Jordan. Support union recovery in high-dimensional multivariate regression. The Annals of Statistics, 39(1):1–47, 2011. The THEOREM 1 (Eq.(20)) of this paper provides an upper bound between the multivariate group Lasso solution $\hat{B}$ and regression matrix $B^*$. The upper bound depends on the correlations of design matrices $X$, however, does not consider the relations of response matrix $Y$. For multivariate multiple regression, is there any references providing the consistent theory or support recovery theory considering the relations of response matrix $Y$?",,"['probability', 'probability-theory', 'statistics']"
62,"Is there a random-seeming language that is a proper subset of $\{s \in \{0,1\}^n: s \text{ has } k \; 1\text{'s}\}$?",Is there a random-seeming language that is a proper subset of ?,"\{s \in \{0,1\}^n: s \text{ has } k \; 1\text{'s}\}","I call a language $L$ a random-seeming language of length $n$ and weight $k$ if $L\subset\{0,1\}^n$, $s\in L \rightarrow (s \text{ has } k \;1\text{'s})$, and $$\forall _{I\subset[n]}\forall_{m\le \min\left(k,|I|\right)} \left(S=\{s \in L: \sum_{i\in I}b_i(s)=m\}\rightarrow\forall_{i\in I}\left[|\{s\in S:b_i(s)=1\}|=\frac {m|S|} {|I|}\right]\right)$$where $b_i(s)$ is the $i^\text{th}$ bit of $s$. Obviously the language $L_\max=\left\{s\in\{0,1\}^n:\sum_{i\in \left[n\right]}b_i(s)=k\right\}$ is random-seeming, but are there any random-seeming languages of length $n$ and weight $k$ smaller than $L_\max$?  More generally, given an integer $l \le |L_\max|$, what is the smallest $\epsilon\ge 0$ such that $$\exists _{L\subset L_\max}\forall _{I\subset[n]}\forall_{m\le \min\left(k,|I|\right)} \left(\left|L\right|\le l \wedge S=\{s \in L: \sum_{i\in I}b_i(s)=m\}\rightarrow\forall_{i\in I}\left[\left|\left|\left\{s\in S:b_i(s)=1\right\}\right|-\frac {m|S|} {|I|}\right|\le\epsilon\right]\right)$$ Note : I included the probability tag because this is essentially a probability question in my mind: a language $L$ is ""random-seeming"" iff for every set of set of digits $I$ and integer $m\le k$, the probability that a random string $s\in \{0,1\}^n$ with $m$ $1$'s in $I$ will be in $L$ is independent of the distribution of the $1$'s in $I$, and in the general problem, $\epsilon$ represents the maximum deviation such a probability can have from the mean probability for any given distribution of $1$'s in any given $I$.  At least, that is what I intended it to mean.  It's possible that I messed up the formal statement above (though I'm pretty sure I got it right), but the point of being random-seeming, is that the number of $1$'s among some of the digits tells you nothing (or in the general case, little) about the distribution of $1$'s in the rest of the digits, only their total number.","I call a language $L$ a random-seeming language of length $n$ and weight $k$ if $L\subset\{0,1\}^n$, $s\in L \rightarrow (s \text{ has } k \;1\text{'s})$, and $$\forall _{I\subset[n]}\forall_{m\le \min\left(k,|I|\right)} \left(S=\{s \in L: \sum_{i\in I}b_i(s)=m\}\rightarrow\forall_{i\in I}\left[|\{s\in S:b_i(s)=1\}|=\frac {m|S|} {|I|}\right]\right)$$where $b_i(s)$ is the $i^\text{th}$ bit of $s$. Obviously the language $L_\max=\left\{s\in\{0,1\}^n:\sum_{i\in \left[n\right]}b_i(s)=k\right\}$ is random-seeming, but are there any random-seeming languages of length $n$ and weight $k$ smaller than $L_\max$?  More generally, given an integer $l \le |L_\max|$, what is the smallest $\epsilon\ge 0$ such that $$\exists _{L\subset L_\max}\forall _{I\subset[n]}\forall_{m\le \min\left(k,|I|\right)} \left(\left|L\right|\le l \wedge S=\{s \in L: \sum_{i\in I}b_i(s)=m\}\rightarrow\forall_{i\in I}\left[\left|\left|\left\{s\in S:b_i(s)=1\right\}\right|-\frac {m|S|} {|I|}\right|\le\epsilon\right]\right)$$ Note : I included the probability tag because this is essentially a probability question in my mind: a language $L$ is ""random-seeming"" iff for every set of set of digits $I$ and integer $m\le k$, the probability that a random string $s\in \{0,1\}^n$ with $m$ $1$'s in $I$ will be in $L$ is independent of the distribution of the $1$'s in $I$, and in the general problem, $\epsilon$ represents the maximum deviation such a probability can have from the mean probability for any given distribution of $1$'s in any given $I$.  At least, that is what I intended it to mean.  It's possible that I messed up the formal statement above (though I'm pretty sure I got it right), but the point of being random-seeming, is that the number of $1$'s among some of the digits tells you nothing (or in the general case, little) about the distribution of $1$'s in the rest of the digits, only their total number.",,"['probability', 'formal-languages']"
63,What is the broadest definition of conditional probability?,What is the broadest definition of conditional probability?,,"The usual definition of conditional probability on a probability space $(\Omega, \sigma, P)$ is~: $$P(A|B) = \frac{P(A \cap B)}{P(B)}$$ which obviously implies that $B$ must not be a negligible set. However this definition appears too restrictive as we sometimes need to compute probabilities conditioned by negligible sets (a usual case is for example an event of the form $B = \{X = x\}$ where $X$ is a continuous random variable and $x$ a real number). Informally speaking we would like to define~: $$P(A|B) = \underset{P(B') > 0}{\lim_{B'\rightarrow B}} \frac{P(A \cap B')}{P(B')}$$ Now the meaning of the limit should be made precise. I'm neither aware of a topology defined on $\sigma$ itself nor convinced it is the way to go. It might also be possible to work with sequences of decreasing events which in some sense ""convergence"" toward $B$: $$B_1 \supset B_2 \supset \cdots \supset B$$ such that: $$\forall x \in \Omega \setminus B, \exists n \in \mathbb N,  x \not\in B_n$$ But I'd like to know if some formal definition already exist.","The usual definition of conditional probability on a probability space $(\Omega, \sigma, P)$ is~: $$P(A|B) = \frac{P(A \cap B)}{P(B)}$$ which obviously implies that $B$ must not be a negligible set. However this definition appears too restrictive as we sometimes need to compute probabilities conditioned by negligible sets (a usual case is for example an event of the form $B = \{X = x\}$ where $X$ is a continuous random variable and $x$ a real number). Informally speaking we would like to define~: $$P(A|B) = \underset{P(B') > 0}{\lim_{B'\rightarrow B}} \frac{P(A \cap B')}{P(B')}$$ Now the meaning of the limit should be made precise. I'm neither aware of a topology defined on $\sigma$ itself nor convinced it is the way to go. It might also be possible to work with sequences of decreasing events which in some sense ""convergence"" toward $B$: $$B_1 \supset B_2 \supset \cdots \supset B$$ such that: $$\forall x \in \Omega \setminus B, \exists n \in \mathbb N,  x \not\in B_n$$ But I'd like to know if some formal definition already exist.",,"['probability', 'measure-theory']"
64,What is the Exact Expected Death Toll Pencentage in the Shooting Room Paradox?,What is the Exact Expected Death Toll Pencentage in the Shooting Room Paradox?,,"In the shooting room paradox $x$ people enter a room, one of them rolls two dice and if they both land on 6 everyone in the room is shot and killed. If not, everyone in the room is taken out and let go on their merry way and $10x$ people are then placed in the room and the experiment continues on like this until one group rolls a double six at which point it is complete. The usual question is ""Knowing that you are entering the room what is the chance that you will get shot?"". It would initially seem like the chance is $1/36$ but over $90\%$ of people that enter the room in any given run of the experiment are actually killed so this is the chance of you getting killed. Taking an example of the experiment starting with one person: If it ends on the first go $1/1$ people involved have been killed giving $100\%$ , if it ends on the second $10/11$ have been killed (the first didn't roll double sixes and was set free) giving approximately $90.91\%$ and $\lim_{n\to \infty} \frac{9\times10^n}{10^{n+1}-1}=0.9$ which is where the answer of $90\%$ comes from. But as this is the absolute minimum proportion of people killed, the actual expected value must be higher than this. If rather than rolling two sixes, the criterion for getting shot was rolling any number at all then the death rate would be $100\%$ and if it was to get any number except 1 on a 100-sided die would we not expect the death rate to be a fair bit higher than $90\%$ ? My question is what is the exact expected value? I think it would be the answer to this difficult summation that I have had no luck conquering: $\frac{1}{36}\sum_{i=0}^\infty\frac{35}{36}^i\times\frac{9\times10^i}{10^{i+1}-1}$ which simplifies a bit to $\frac{9}{36}\sum_{i=0}^\infty\frac{1}{36}^i\times\frac{350^i}{10^{i+1}-1}$ Any help would be greatly appreciated! Thanks :)","In the shooting room paradox people enter a room, one of them rolls two dice and if they both land on 6 everyone in the room is shot and killed. If not, everyone in the room is taken out and let go on their merry way and people are then placed in the room and the experiment continues on like this until one group rolls a double six at which point it is complete. The usual question is ""Knowing that you are entering the room what is the chance that you will get shot?"". It would initially seem like the chance is but over of people that enter the room in any given run of the experiment are actually killed so this is the chance of you getting killed. Taking an example of the experiment starting with one person: If it ends on the first go people involved have been killed giving , if it ends on the second have been killed (the first didn't roll double sixes and was set free) giving approximately and which is where the answer of comes from. But as this is the absolute minimum proportion of people killed, the actual expected value must be higher than this. If rather than rolling two sixes, the criterion for getting shot was rolling any number at all then the death rate would be and if it was to get any number except 1 on a 100-sided die would we not expect the death rate to be a fair bit higher than ? My question is what is the exact expected value? I think it would be the answer to this difficult summation that I have had no luck conquering: which simplifies a bit to Any help would be greatly appreciated! Thanks :)",x 10x 1/36 90\% 1/1 100\% 10/11 90.91\% \lim_{n\to \infty} \frac{9\times10^n}{10^{n+1}-1}=0.9 90\% 100\% 90\% \frac{1}{36}\sum_{i=0}^\infty\frac{35}{36}^i\times\frac{9\times10^i}{10^{i+1}-1} \frac{9}{36}\sum_{i=0}^\infty\frac{1}{36}^i\times\frac{350^i}{10^{i+1}-1},"['probability', 'sequences-and-series', 'summation', 'paradoxes']"
65,How to prove the following properties of infimum and supremum involving the union and intersection of the sets $A_k$,How to prove the following properties of infimum and supremum involving the union and intersection of the sets,A_k,"I am reading a book on probability theory and I have troubles understanding why the following holds $$    \sup_{k \ge n} A_k = \bigcup_{k\ge n} A_k $$ $$ \inf_{k \ge n} A_k = \bigcap_{k\ge n} A_k $$ I know how to define infimum and supremum, but I have troubles proving the above expressions. Unfortunately, the book states those expressions as a definition without proving them. A graphical explanation in terms of a Venn diagram will be very helpful.  Thank you in advance","I am reading a book on probability theory and I have troubles understanding why the following holds $$    \sup_{k \ge n} A_k = \bigcup_{k\ge n} A_k $$ $$ \inf_{k \ge n} A_k = \bigcap_{k\ge n} A_k $$ I know how to define infimum and supremum, but I have troubles proving the above expressions. Unfortunately, the book states those expressions as a definition without proving them. A graphical explanation in terms of a Venn diagram will be very helpful.  Thank you in advance",,"['probability-theory', 'supremum-and-infimum']"
66,Is the $P(\text{You Die})=1$?,Is the ?,P(\text{You Die})=1,"So I was teaching my younger brother Probability and in order to give him some intuition, I told him that events that occur for certain have a probability of $1$. So events such as one dying will have a probability of $1$. Later, I was trying to deduce this result from the definition of Probability. We say that $$P(\text{Event})=\frac{\text{Number of favorable Outcomes}}{\text{Total number of Outcomes}}$$ If we consider $S=\{\text{You Die},\text{You Live\}}$ as the set of all outcomes and the Event $\text{You Die}\in S$ to be a favorable outcome then $P(\text{You Die})=1/2.$ However we know that $P(\text{You Die})=1.$ Is there a way to show that this claim can be deduced from the definition of Probability?","So I was teaching my younger brother Probability and in order to give him some intuition, I told him that events that occur for certain have a probability of $1$. So events such as one dying will have a probability of $1$. Later, I was trying to deduce this result from the definition of Probability. We say that $$P(\text{Event})=\frac{\text{Number of favorable Outcomes}}{\text{Total number of Outcomes}}$$ If we consider $S=\{\text{You Die},\text{You Live\}}$ as the set of all outcomes and the Event $\text{You Die}\in S$ to be a favorable outcome then $P(\text{You Die})=1/2.$ However we know that $P(\text{You Die})=1.$ Is there a way to show that this claim can be deduced from the definition of Probability?",,['probability']
67,"Convergence in $L^2$ of $T_n/\mathbb{E} (T_n)\to 1$, $T_n$ be the first time a Galton Watson has more than $n$ individuals","Convergence in  of ,  be the first time a Galton Watson has more than  individuals",L^2 T_n/\mathbb{E} (T_n)\to 1 T_n n,Let $(N(t))_{t\geq 0}$ be a Galton-Watson process with reproduction law $p=(p_k)_{k\in\mathbb{N}}$ and rate of births $\tau >0$ i.e. we start with one individual and each individual in the system gives birth indepently with rate $\tau $ to a random number of offsprings distributed as $p$.  If $p_0=0$ and $m : = \sum_{n\geq 1}np_n > 1$ then the stopping time  $$T_n := \inf\{t > 0\colon N(t) > n\}$$ is finite a.e. I want to prove that $$\frac{T_n}{\mathbb{E}T_n} \to 1 \text{ in }L^2$$ for this I think we can use dominated convergence and prove first that we have the convergence a.e. and then prove that  $$\sup_n \frac{T_n}{\mathbb{E}T_n} \in L^2$$ But I don't know how to do either of those things. Any help and idea will be appreciated Thanks,Let $(N(t))_{t\geq 0}$ be a Galton-Watson process with reproduction law $p=(p_k)_{k\in\mathbb{N}}$ and rate of births $\tau >0$ i.e. we start with one individual and each individual in the system gives birth indepently with rate $\tau $ to a random number of offsprings distributed as $p$.  If $p_0=0$ and $m : = \sum_{n\geq 1}np_n > 1$ then the stopping time  $$T_n := \inf\{t > 0\colon N(t) > n\}$$ is finite a.e. I want to prove that $$\frac{T_n}{\mathbb{E}T_n} \to 1 \text{ in }L^2$$ for this I think we can use dominated convergence and prove first that we have the convergence a.e. and then prove that  $$\sup_n \frac{T_n}{\mathbb{E}T_n} \in L^2$$ But I don't know how to do either of those things. Any help and idea will be appreciated Thanks,,"['probability', 'stochastic-processes']"
68,"Distribution of the largest interval when partitioning [0,1] into n intervals with n-1 uniformly distributed points.","Distribution of the largest interval when partitioning [0,1] into n intervals with n-1 uniformly distributed points.",,"Let $\lbrace x_1,x_2,...,x_{n-1}\rbrace$ be n-1 points that are independently uniformly distributed on interval [0,1]. They create n segments. What is the expected length of the largest of such n segments? What is the distribution? A good if not complete solution here. Average length of the longest segment","Let $\lbrace x_1,x_2,...,x_{n-1}\rbrace$ be n-1 points that are independently uniformly distributed on interval [0,1]. They create n segments. What is the expected length of the largest of such n segments? What is the distribution? A good if not complete solution here. Average length of the longest segment",,"['probability', 'combinatorics']"
69,An improbable Euchre game -- A 9$\spadesuit$ kind of evening,An improbable Euchre game -- A 9 kind of evening,\spadesuit,"Setup During a game of cutthroat euchre (3 players instead of 4), my girlfriend won the game by playing as her last card, the 9$\spadesuit$.  Given that euchre is played with a deck consisting of 9s, 10s, Js, Qs, Ks, and Aces, and trump was a different suit, this was one of the 3 lowest cards in the deck. That's a pretty awesome way to win the game, but it gets better.  In addition to playing the 9$\spadesuit$, she also took all 5 tricks in that hand and therefore got two points to win the game instead of the standard one point you get for only making your bid. Adding on to the improbable nature of this game, the 9$\spadesuit$ was turned up five times as the bid card -- she turned it up three times, her father turned it up once, and I turned it up once. The game ended with scores of 10, 8, and 3, which meant, since hers was the only two point hand, we played 19 hands. I refer those who are unfamiliar with Euchre to the rule set here . Goal I'd love to figure out the probability of the 9$\spadesuit$ turning up 5 times as the bid card and then extend that probability to include the fact that the the 9$\spadesuit$ was also the card used to win the game by taking all tricks in the final hand. Start of a Solution Because you shuffle between each hand, I believe the probability of any one 9 (since we would have been just as flabbergasted with any 9) coming up 5 times as the bid card in a game of 19 hands is: $$ P_{\text{particular card coming up 5 times}} = \frac{4}{24} \cdot \left(\frac{1}{24}\right)^{4} = \frac{1}{1,990,656} $$ But here is where my stats fail me.  How do I model the probabilities of the hand being played? If I want to model the probability of the 9$\spadesuit$ being the card to win the last hand, do I have to include the probability of the 9$\spadesuit$ not being the last card during the other hands?  I'm thinking something like this pseudo equation: $$ P_{\text{dealt the right 9}} \cdot P_{\text{playing the 9 last}} \cdot P_{\text{taking all tricks}} \cdot P_{\text{something about winning the game?}} \cdot P_{\text{something else?}} $$ I believe we can calculate the first probability via: $$ P_{\text{dealt the right 9}} = 1 - (P_{\text{not being dealt the right 9}}) = 1 - (\frac{23}{24} \cdot \frac{22}{23} \cdot \frac{21}{22} \cdot \frac{20}{21} \cdot \frac{19}{20}) = \frac{5}{24} $$ Can I calculate the second probability via this?  This result is non-intuitive to me. $$ P_{\text{playing the 9 last}} = 1 - P_{\text{not playing the 9 last}} = 1 - (\frac{4}{5} \cdot \frac{3}{4} \cdot \frac{2}{3} \cdot \frac{1}{2}) = \frac{4}{5} $$ Could I use a pre-calculated probability for the fact that she took all 5 of the tricks on the last hand?  If I found a resource online that gave the probability of taking all 5 tricks in a Euchre hand, how would I integrate that?","Setup During a game of cutthroat euchre (3 players instead of 4), my girlfriend won the game by playing as her last card, the 9$\spadesuit$.  Given that euchre is played with a deck consisting of 9s, 10s, Js, Qs, Ks, and Aces, and trump was a different suit, this was one of the 3 lowest cards in the deck. That's a pretty awesome way to win the game, but it gets better.  In addition to playing the 9$\spadesuit$, she also took all 5 tricks in that hand and therefore got two points to win the game instead of the standard one point you get for only making your bid. Adding on to the improbable nature of this game, the 9$\spadesuit$ was turned up five times as the bid card -- she turned it up three times, her father turned it up once, and I turned it up once. The game ended with scores of 10, 8, and 3, which meant, since hers was the only two point hand, we played 19 hands. I refer those who are unfamiliar with Euchre to the rule set here . Goal I'd love to figure out the probability of the 9$\spadesuit$ turning up 5 times as the bid card and then extend that probability to include the fact that the the 9$\spadesuit$ was also the card used to win the game by taking all tricks in the final hand. Start of a Solution Because you shuffle between each hand, I believe the probability of any one 9 (since we would have been just as flabbergasted with any 9) coming up 5 times as the bid card in a game of 19 hands is: $$ P_{\text{particular card coming up 5 times}} = \frac{4}{24} \cdot \left(\frac{1}{24}\right)^{4} = \frac{1}{1,990,656} $$ But here is where my stats fail me.  How do I model the probabilities of the hand being played? If I want to model the probability of the 9$\spadesuit$ being the card to win the last hand, do I have to include the probability of the 9$\spadesuit$ not being the last card during the other hands?  I'm thinking something like this pseudo equation: $$ P_{\text{dealt the right 9}} \cdot P_{\text{playing the 9 last}} \cdot P_{\text{taking all tricks}} \cdot P_{\text{something about winning the game?}} \cdot P_{\text{something else?}} $$ I believe we can calculate the first probability via: $$ P_{\text{dealt the right 9}} = 1 - (P_{\text{not being dealt the right 9}}) = 1 - (\frac{23}{24} \cdot \frac{22}{23} \cdot \frac{21}{22} \cdot \frac{20}{21} \cdot \frac{19}{20}) = \frac{5}{24} $$ Can I calculate the second probability via this?  This result is non-intuitive to me. $$ P_{\text{playing the 9 last}} = 1 - P_{\text{not playing the 9 last}} = 1 - (\frac{4}{5} \cdot \frac{3}{4} \cdot \frac{2}{3} \cdot \frac{1}{2}) = \frac{4}{5} $$ Could I use a pre-calculated probability for the fact that she took all 5 of the tricks on the last hand?  If I found a resource online that gave the probability of taking all 5 tricks in a Euchre hand, how would I integrate that?",,"['probability', 'card-games']"
70,Magic 8 Ball Problem,Magic 8 Ball Problem,,"This problem is probably simple enough to have an analogous problem, I just don't know the name so I'm going to describe it and hopefully somebody can point me in the right direction. The problem is this: estimating the number of sides of a Magic 8 Ball . Let's say you perform the following process: Shake the ""Magic 8 Ball"" and mark down the result If the result has not previously been seen, add it to the set of possible results and label the trial ""N"" (for ""new"") If the result has been previously seen, label the trial ""O"" (for ""old"") Repeat all steps I imagine the following kind of sequence occurring: NNNNONNOONOONOOONOOOONONNOONOOONNOONOOOOOONOOONOOOOOOONOOOOOOOONOOOOOOOO... Now imagine we don't know there are twenty sides to a Magic 8 Ball. Or imagine that you have a Magic 8 Ball with 1000 sides. As the number of ""new"" trials approaches the actual number of sides, we'll get increasingly more ""old"" trials showing up in the mix. Once we've seen all of the possible results, we'll always get ""old"" results. But we're never 100% sure we've seen every single possible result. So here are the questions I'm interested in: As we proceed with trials, can we estimate the total number of ""sides"" of the Magic 8 ball based on the number of ""new"" and ""old"" trials up to this point? Can we calculate a probability that our current estimate is correct, or a probability that some bounded estimate is correct?","This problem is probably simple enough to have an analogous problem, I just don't know the name so I'm going to describe it and hopefully somebody can point me in the right direction. The problem is this: estimating the number of sides of a Magic 8 Ball . Let's say you perform the following process: Shake the ""Magic 8 Ball"" and mark down the result If the result has not previously been seen, add it to the set of possible results and label the trial ""N"" (for ""new"") If the result has been previously seen, label the trial ""O"" (for ""old"") Repeat all steps I imagine the following kind of sequence occurring: NNNNONNOONOONOOONOOOONONNOONOOONNOONOOOOOONOOONOOOOOOONOOOOOOOONOOOOOOOO... Now imagine we don't know there are twenty sides to a Magic 8 Ball. Or imagine that you have a Magic 8 Ball with 1000 sides. As the number of ""new"" trials approaches the actual number of sides, we'll get increasingly more ""old"" trials showing up in the mix. Once we've seen all of the possible results, we'll always get ""old"" results. But we're never 100% sure we've seen every single possible result. So here are the questions I'm interested in: As we proceed with trials, can we estimate the total number of ""sides"" of the Magic 8 ball based on the number of ""new"" and ""old"" trials up to this point? Can we calculate a probability that our current estimate is correct, or a probability that some bounded estimate is correct?",,['probability']
71,Upper bound for distance between actual and sample quantiles,Upper bound for distance between actual and sample quantiles,,"Let $\xi_p$ be pth quantile of the distribution $F(x)$ with derivative at $\xi_p$, $f(\xi_p) >0$. Then, $$ |\hat\xi_{p,n} - \xi_p| \leq \frac{2}{f(\xi_p)}\sqrt{\frac{\log n}{n}} $$ almost surely for large enough $n$ and any $p \in (0,1)$, where $\hat\xi_{p,n}$ is the pth sample quantile from an empirical distribution $F_n(x)$ for $F(x)$ with $1/n$ mass for each observation. I have tried Taylor expansion to get a bound but this approach does not seem to work; it seems like I need to rather work with empirical distribution (using Hoeffding's inequality) rather than sample quantile to derive the term $\log n$, but I am not sure of how I can derive this upper bound.","Let $\xi_p$ be pth quantile of the distribution $F(x)$ with derivative at $\xi_p$, $f(\xi_p) >0$. Then, $$ |\hat\xi_{p,n} - \xi_p| \leq \frac{2}{f(\xi_p)}\sqrt{\frac{\log n}{n}} $$ almost surely for large enough $n$ and any $p \in (0,1)$, where $\hat\xi_{p,n}$ is the pth sample quantile from an empirical distribution $F_n(x)$ for $F(x)$ with $1/n$ mass for each observation. I have tried Taylor expansion to get a bound but this approach does not seem to work; it seems like I need to rather work with empirical distribution (using Hoeffding's inequality) rather than sample quantile to derive the term $\log n$, but I am not sure of how I can derive this upper bound.",,"['probability', 'probability-theory', 'statistics', 'order-statistics', 'quantile']"
72,"If $X$ is independent of $Y$ and $Z$, then $X$ is independent of $(Y,Z)$","If  is independent of  and , then  is independent of","X Y Z X (Y,Z)","I have two questions concerning Independence between random variables and vectors. Let $X,Y,Z,U:\Omega\rightarrow\mathbb{R}$ be random variables. If $X$ is independent of $Y$ and $Z$, is $X$ independent of $(Y,Z)$? If $X$ and $U$ are independent of $Y$ and $Z$, is $(X,U)$ independent of $(Y,Z)$? MOTIVATION: I know that, if $X$ is independent of $(Y,Z)$, then $X$ is independent to both $Y$ and $Z$ (because the real maps $(y,z)\mapsto y$ and $(y,z)\mapsto z$ are measurable). I would like to know if the converse holds, and if not, under which conditions it does (for instance, if the random variables have a certain distribution). I do know that, for 1., if $Y$ and $Z$ are also independent, then $X$ is indeed independent of $(Y,Z)$.","I have two questions concerning Independence between random variables and vectors. Let $X,Y,Z,U:\Omega\rightarrow\mathbb{R}$ be random variables. If $X$ is independent of $Y$ and $Z$, is $X$ independent of $(Y,Z)$? If $X$ and $U$ are independent of $Y$ and $Z$, is $(X,U)$ independent of $(Y,Z)$? MOTIVATION: I know that, if $X$ is independent of $(Y,Z)$, then $X$ is independent to both $Y$ and $Z$ (because the real maps $(y,z)\mapsto y$ and $(y,z)\mapsto z$ are measurable). I would like to know if the converse holds, and if not, under which conditions it does (for instance, if the random variables have a certain distribution). I do know that, for 1., if $Y$ and $Z$ are also independent, then $X$ is indeed independent of $(Y,Z)$.",,"['probability', 'probability-theory', 'measure-theory', 'self-learning', 'independence']"
73,Probability of lines intersecting in a square. [closed],Probability of lines intersecting in a square. [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Suppose that you select two random line segments in a square, by selecting their endpoints uniformly at random. What is the probability that they intersect?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Suppose that you select two random line segments in a square, by selecting their endpoints uniformly at random. What is the probability that they intersect?",,"['probability', 'geometry']"
74,$P_n(A)\rightarrow P(A)$ implies $P$ is a probability measure?,implies  is a probability measure?,P_n(A)\rightarrow P(A) P,"Here is the question: Let $\{P_n\}$ be a sequence of probability measures on $\sigma$-field (Also called $\sigma$-algebra) $\mathcal{F}$. Suppose that there exists some function $P$ on $\mathcal{F}$ satisfying that $P_n(A)\rightarrow P(A)$ for all $A\in\mathcal{F}$. Prove that $P$ is a probability measure. What I try: The only problem is to verify countable additivity of $P$. But I can only prove it under the assumption that $P(A_n)\rightarrow 0$ (or $\sup_nP_n(A_k)\rightarrow0$ as $k\rightarrow0$) when $A_n\downarrow0$. About $\sup_nP_n(A_k)\rightarrow0$: For any $k\in\mathbb{N}$ and any $\epsilon>0$, there exists $N=N(k,\epsilon)\in\mathbb{N}$, such that $|P_n(A_k)-P_N(A_k)|\leqslant\epsilon$ for all $n\geqslant N$. Since $\sup_nP_n(A_k)$ is decreasing, we have $$\lim_k\sup_nP_n(A_k)\leqslant\sup_nP_n(A_k)\leqslant\max_{n\leqslant N}P_n(A_k)+\epsilon.$$ Now I don't know what to do: we can't just let $k\rightarrow\infty$ 'cause $N$ is related to $k$. I can prove the needed assumption: for any $\{A_n\}\subset\mathcal F$ with $A_n\downarrow\emptyset$, we have $P(A_n)\rightarrow0$. So this problem is now solved.","Here is the question: Let $\{P_n\}$ be a sequence of probability measures on $\sigma$-field (Also called $\sigma$-algebra) $\mathcal{F}$. Suppose that there exists some function $P$ on $\mathcal{F}$ satisfying that $P_n(A)\rightarrow P(A)$ for all $A\in\mathcal{F}$. Prove that $P$ is a probability measure. What I try: The only problem is to verify countable additivity of $P$. But I can only prove it under the assumption that $P(A_n)\rightarrow 0$ (or $\sup_nP_n(A_k)\rightarrow0$ as $k\rightarrow0$) when $A_n\downarrow0$. About $\sup_nP_n(A_k)\rightarrow0$: For any $k\in\mathbb{N}$ and any $\epsilon>0$, there exists $N=N(k,\epsilon)\in\mathbb{N}$, such that $|P_n(A_k)-P_N(A_k)|\leqslant\epsilon$ for all $n\geqslant N$. Since $\sup_nP_n(A_k)$ is decreasing, we have $$\lim_k\sup_nP_n(A_k)\leqslant\sup_nP_n(A_k)\leqslant\max_{n\leqslant N}P_n(A_k)+\epsilon.$$ Now I don't know what to do: we can't just let $k\rightarrow\infty$ 'cause $N$ is related to $k$. I can prove the needed assumption: for any $\{A_n\}\subset\mathcal F$ with $A_n\downarrow\emptyset$, we have $P(A_n)\rightarrow0$. So this problem is now solved.",,"['real-analysis', 'probability']"
75,Is a binomial a sum of Bernoulli random variables?,Is a binomial a sum of Bernoulli random variables?,,"I know that, if $X_1,\ldots,X_n\sim \text{Ber}(p)$ are independent, then $X_1+\ldots+X_n\sim\text{Bin}(n,p)$. My question is: if $X\sim \text{Bin}(n,p)$, is it true that there exist independent random variables $X_1,\ldots,X_n\sim\text{Ber}(p)$ such that $X(\omega)=X_1(\omega)+\ldots+X_n(\omega)$ for all $\omega\,$? EDIT: I would like an analytic proof of this fact (if it is true).","I know that, if $X_1,\ldots,X_n\sim \text{Ber}(p)$ are independent, then $X_1+\ldots+X_n\sim\text{Bin}(n,p)$. My question is: if $X\sim \text{Bin}(n,p)$, is it true that there exist independent random variables $X_1,\ldots,X_n\sim\text{Ber}(p)$ such that $X(\omega)=X_1(\omega)+\ldots+X_n(\omega)$ for all $\omega\,$? EDIT: I would like an analytic proof of this fact (if it is true).",,['probability']
76,Estimating the Lower Bound of A Summation Related to Probability,Estimating the Lower Bound of A Summation Related to Probability,,"I am working on a probability problem which requires me to find a lower bound of a sum. The sum is $$\sum_{i=n}^{100}{100\choose i}\left(\frac{80}{100}\right)^i\left(\frac{20}{100}\right)^{100-i}\geq 0.9$$ How do I find $n$ here in order to satisfy the inequality? Wolfram Alpha cannot calculate it, but can we perhaps give an estimate?","I am working on a probability problem which requires me to find a lower bound of a sum. The sum is $$\sum_{i=n}^{100}{100\choose i}\left(\frac{80}{100}\right)^i\left(\frac{20}{100}\right)^{100-i}\geq 0.9$$ How do I find $n$ here in order to satisfy the inequality? Wolfram Alpha cannot calculate it, but can we perhaps give an estimate?",,"['probability', 'summation', 'estimation']"
77,Generating uniformly distributed random elements of $SU(3)$,Generating uniformly distributed random elements of,SU(3),"Say I need to generate a uniformly distributed collection $\{X\}$ of elements of $SU(3)$.  (For concreteness, I will consider the distribution to be uniform if the distribution of  $X$ is identical to the distribution of $gX$ where $g$ can be any element of $SU(3)$.) I know how to generate uniform random elements of $SU(2)$ because it is isomorphic with $SO(3)$ and I know how to generate random rotations.  In past work, I (and other Lattice Gauge Theory people doing Monte-Carlo simulations) needed to generate random $SU(3)$ elements such that the probability of an element is the same as that of its inverse, and such that the probability density near at $SU(3)$ element is non-zero.   However, these are weaker conditions than uniformity, and what we did was to take the product of three elements in three different $SU(2)$ subspaces of $SU(3)$.  We could get arbitrarily close to a uniform distribution by multiplying several such products. But I would like to know how to generate $SU(3)$ elements with uniform distribution, not just almost-uniform distribution.","Say I need to generate a uniformly distributed collection $\{X\}$ of elements of $SU(3)$.  (For concreteness, I will consider the distribution to be uniform if the distribution of  $X$ is identical to the distribution of $gX$ where $g$ can be any element of $SU(3)$.) I know how to generate uniform random elements of $SU(2)$ because it is isomorphic with $SO(3)$ and I know how to generate random rotations.  In past work, I (and other Lattice Gauge Theory people doing Monte-Carlo simulations) needed to generate random $SU(3)$ elements such that the probability of an element is the same as that of its inverse, and such that the probability density near at $SU(3)$ element is non-zero.   However, these are weaker conditions than uniformity, and what we did was to take the product of three elements in three different $SU(2)$ subspaces of $SU(3)$.  We could get arbitrarily close to a uniform distribution by multiplying several such products. But I would like to know how to generate $SU(3)$ elements with uniform distribution, not just almost-uniform distribution.",,"['probability', 'lie-groups', 'haar-measure']"
78,ODE and raw moments,ODE and raw moments,,I've read a piece in MathWorld where a distribution function $P(A)$ satisfies the ODE $$A^{3}(1-2A)P^{(4)}(A)+A^{2}P^{(3)}(A)-4A^{2}P''(A)+8AP'(A)-8P(A)-96(2A-1)=0.\label{a}\tag{1}$$ It is then inferred that the raw moments of $P$ are $$\mu_{n}'=\frac{3\cdot2^{3-n}\left[\left(n+2\right)H_{n+1}+1\right]}{(n+1)(n+2)^{3}(n+3)^{2}}\label{b}\tag{2}$$ Where $\mu_n'=\mathbb{E}[X^n]=\int_0^1x^ndP(x)$ are the raw moments and $H_n = \sum_{k=1}^n\frac{1}{k}$ is the harmonic number. My question is: how is (2) derived from (1)? My guess is this has to do with the Laplace transform but this is my first encounter with this type of ODEs so I don't know how they may be solved.,I've read a piece in MathWorld where a distribution function $P(A)$ satisfies the ODE $$A^{3}(1-2A)P^{(4)}(A)+A^{2}P^{(3)}(A)-4A^{2}P''(A)+8AP'(A)-8P(A)-96(2A-1)=0.\label{a}\tag{1}$$ It is then inferred that the raw moments of $P$ are $$\mu_{n}'=\frac{3\cdot2^{3-n}\left[\left(n+2\right)H_{n+1}+1\right]}{(n+1)(n+2)^{3}(n+3)^{2}}\label{b}\tag{2}$$ Where $\mu_n'=\mathbb{E}[X^n]=\int_0^1x^ndP(x)$ are the raw moments and $H_n = \sum_{k=1}^n\frac{1}{k}$ is the harmonic number. My question is: how is (2) derived from (1)? My guess is this has to do with the Laplace transform but this is my first encounter with this type of ODEs so I don't know how they may be solved.,,"['probability', 'ordinary-differential-equations', 'laplace-transform', 'harmonic-numbers']"
79,Intuition of the relation between poisson process and order statistics,Intuition of the relation between poisson process and order statistics,,"Lemma: Let $T_n$ be the time of the nth arrival in a Poisson process and $U_k$, $k=1,2....n$ be independent uniform on $(0,1)$. Then the order statistics of $U_1, U_2,....,U_n$ have the same distribution of $(T_1/T_{N+1},T_2/T_{N+1},...,T_N/T_{N+1})$. I could prove the lemma by simply find out the joint density of the above vector which is $n!$ for both case. However, I would like to know is there any intuition that I could understand the lemma without directly calculate the answer. I have read this post , but I think that it may be unrelated to the problem, though not for sure.","Lemma: Let $T_n$ be the time of the nth arrival in a Poisson process and $U_k$, $k=1,2....n$ be independent uniform on $(0,1)$. Then the order statistics of $U_1, U_2,....,U_n$ have the same distribution of $(T_1/T_{N+1},T_2/T_{N+1},...,T_N/T_{N+1})$. I could prove the lemma by simply find out the joint density of the above vector which is $n!$ for both case. However, I would like to know is there any intuition that I could understand the lemma without directly calculate the answer. I have read this post , but I think that it may be unrelated to the problem, though not for sure.",,"['probability', 'probability-distributions']"
80,Transformation of random variables exercise,Transformation of random variables exercise,,"I want to know if my solution to the following exercise is correct: Let $X$ be a gamma distributed random variable with parameter 2, meaning with distribution $$P_X(\mathrm{d}x)=\mathbb{1}_{\{x>0\}}xe^{-x}\mathrm{d}x$$ And let $U$ be a uniform distributed random variable on $[0,1]$ that is independent of $X$. Define$$Y_1=UX\qquad \text{ and }\qquad Y_2=(1-U)X$$ What's the distribution of $(Y_1,Y_2)$ and prove that $Y_1$ and $Y_2$ are independent with exponential distribution. Determine the parameter. Solution:  The inverse $T^{-1}(y_1,y_2)$ of the transformation $T(x,u)$ is: $$X=Y_1 +Y_2$$ $$U=\frac{Y_1}{Y_1+Y_2}$$ Jacobi matrix of $T^{-1}$ is $$J_{T^{-1}}=\begin{pmatrix}1 & 1\\ \frac{y_2}{(y_1+y_2)^2} & \frac{-y_1}{(y_1+y_2)^2} \end{pmatrix}$$ With $|Det(J_{T^{-1}})|=\frac{1}{(y_1+y_2)}$, the old joined density is $$f_{X,U}=\mathbb{1}_{\{x>0\}}xe^{-x}\mathbb{1}_{[0,1]}(y)$$ and now for the new joint density $$f_{Y_1,Y_2}=f_{X,U}\cdot|Det(J_{T^{-1}})|=f_{X,U}\left(y_1+y_2,\frac{y_1}{y_1+y_2}\right)\frac{1}{(y_1+y_2)}$$ $$=\mathbb{1}_{\{y_1+y_2>0\}}e^{-(y_1+y_2)}\mathbb{1}_{[0,1]}\left(\frac{y_1}{y_1+y_2}\right)\frac{(y_1+y_2)}{(y_1+y_2)}$$ $$=\mathbb{1}_{\{y_1+y_2>0\}}\mathbb{1}_{\left\{\frac{y_1}{y_1+y_2}\right\}\in[0,1]}e^{-(y_1+y_2)}$$ So we have an exponential distribution with parameter $\lambda=1$. Independence follows from $f_{Y_1,Y_2}=f_{Y_1}f_{Y_2}$ $$\mathbb{1}_{\{y_1+y_2>0\}}\mathbb{1}_{\left\{\frac{y_1}{y_1+y_2}\right\}\in[0,1]}e^{-(y_1+y_2)}=\mathbb{1}_{\{y_1>0\}}e^{-y_1}\mathbb{1}_{\{y_2>0\}}e^{-y_2}$$ What confuses me is the indicator function especially $\mathbb{1}_{\left\{\frac{y_1}{y_1+y_2}\right\}\in[0,1]}$ So I don't know if I did this correct. Thanks a lot for help!","I want to know if my solution to the following exercise is correct: Let $X$ be a gamma distributed random variable with parameter 2, meaning with distribution $$P_X(\mathrm{d}x)=\mathbb{1}_{\{x>0\}}xe^{-x}\mathrm{d}x$$ And let $U$ be a uniform distributed random variable on $[0,1]$ that is independent of $X$. Define$$Y_1=UX\qquad \text{ and }\qquad Y_2=(1-U)X$$ What's the distribution of $(Y_1,Y_2)$ and prove that $Y_1$ and $Y_2$ are independent with exponential distribution. Determine the parameter. Solution:  The inverse $T^{-1}(y_1,y_2)$ of the transformation $T(x,u)$ is: $$X=Y_1 +Y_2$$ $$U=\frac{Y_1}{Y_1+Y_2}$$ Jacobi matrix of $T^{-1}$ is $$J_{T^{-1}}=\begin{pmatrix}1 & 1\\ \frac{y_2}{(y_1+y_2)^2} & \frac{-y_1}{(y_1+y_2)^2} \end{pmatrix}$$ With $|Det(J_{T^{-1}})|=\frac{1}{(y_1+y_2)}$, the old joined density is $$f_{X,U}=\mathbb{1}_{\{x>0\}}xe^{-x}\mathbb{1}_{[0,1]}(y)$$ and now for the new joint density $$f_{Y_1,Y_2}=f_{X,U}\cdot|Det(J_{T^{-1}})|=f_{X,U}\left(y_1+y_2,\frac{y_1}{y_1+y_2}\right)\frac{1}{(y_1+y_2)}$$ $$=\mathbb{1}_{\{y_1+y_2>0\}}e^{-(y_1+y_2)}\mathbb{1}_{[0,1]}\left(\frac{y_1}{y_1+y_2}\right)\frac{(y_1+y_2)}{(y_1+y_2)}$$ $$=\mathbb{1}_{\{y_1+y_2>0\}}\mathbb{1}_{\left\{\frac{y_1}{y_1+y_2}\right\}\in[0,1]}e^{-(y_1+y_2)}$$ So we have an exponential distribution with parameter $\lambda=1$. Independence follows from $f_{Y_1,Y_2}=f_{Y_1}f_{Y_2}$ $$\mathbb{1}_{\{y_1+y_2>0\}}\mathbb{1}_{\left\{\frac{y_1}{y_1+y_2}\right\}\in[0,1]}e^{-(y_1+y_2)}=\mathbb{1}_{\{y_1>0\}}e^{-y_1}\mathbb{1}_{\{y_2>0\}}e^{-y_2}$$ What confuses me is the indicator function especially $\mathbb{1}_{\left\{\frac{y_1}{y_1+y_2}\right\}\in[0,1]}$ So I don't know if I did this correct. Thanks a lot for help!",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables']"
81,Concentration of infinite-dimensional Gaussian Measure,Concentration of infinite-dimensional Gaussian Measure,,"I have the question about finding the subspace of concentration of a Gaussian Measure. More precisely: $\textbf{Question:}$ Assume we have a separable Hilbert space $\ell_2$ with Borel $\sigma$-algebra $B(\ell_2)$ and a centered Gaussian measure $\mu$, i.e. we consider the probability space $(\ell_2, B(\ell_2), \mu)$. There is also a linear continuous operator $Q:\ell_2 \rightarrow (\mathbb{R}^{\infty},\rho)$, where $\rho$ is a metric defined by the formula: \begin{equation}  \rho(x,y) = \sum\limits_{k=1}^{\infty}\frac{1}{2}\frac{|x_k - y_k|}{1 + |x_k - y_k|}, \, x,y\in \mathbb{R}^{\infty}. \end{equation} Operator $Q$ pushforwards $\mu$ on $\ell_2$ to measure $Q_{*}(\mu)$ on $\mathbb{R}^{\infty}$. How to check that still measure $Q_{*}$ concentrates on $\ell_2\subset \mathbb{R}^{\infty}$, i.e. $Q_{*}(\mu)[\ell_2] = 1$? $\textbf{Comment:}$ Thanks for the notes of Natan Eldredge from Cornell Univ. I have some ideas how to do it. At first one should say that Gaussian measure on a Hilbert space in this case defined uniquely by its covariance operator on a dual space $\Sigma^{-2} = \mathrm{Cov}(\mu)$ which is of a trace class operator.  So operator $Q$ expands the norm of a Gaussian vector and geometrically the idea is to check that a new covariance operator of $Q_*(\mu)$ is also of a ""trace"" class. However the propery of being a trace class operator has no rigorous meaning, since $Q_*(\mu)$ is a measure not on a Hilbert space, but on $(\mathbb{R}^{\infty},\rho)$. So one should do a bit different construction. Having a quadratic form $\Sigma^{-2}$ on $\ell_2$ it is possible to write explicitly the new quadratic form on $(\mathbb{R}^{\infty},\rho)^*$ which is  $Q\Sigma^{-2}Q^*$. It induces the Hilbert structure on dual space $(\mathbb{R}^{\infty},\rho)^*$ which is a dual space for Cameron-Martic space (ofcourse having a completion before in a new scalar product norm). Hence we can find a Cameron-Martin space of measure $Q_*(\mu)$.  After that we aim to do the reconstruction of concentrtation space, via finding the measurable norm for this Cameron-Martin space -- if we want to prove that measure $Q_*$ concentrates on $\ell_2$ we check that $\|\cdot\|_2$ is a measurable norm in this CM space. If it is so, we find the completion of CM space in this norm and we are done. $\textbf{Minor Question:}$ The last argument above is kind of obvious, but still not clear a bit. It is related to the uniqueness of reconstruction of space via CM space (obviously it is not unique),  but to make the full proof one should say that the reconstructed space with reconstructed Gaussian measure coincide with the measure I began -- $Q_*(\mu)$. Any suggestions? Also if you find any mistake in my comment, please welcome to remark. It took me some effort to get this construction (however the question sounds rather naturally for Gaussian measures) and I havent seen any links related to such question.","I have the question about finding the subspace of concentration of a Gaussian Measure. More precisely: $\textbf{Question:}$ Assume we have a separable Hilbert space $\ell_2$ with Borel $\sigma$-algebra $B(\ell_2)$ and a centered Gaussian measure $\mu$, i.e. we consider the probability space $(\ell_2, B(\ell_2), \mu)$. There is also a linear continuous operator $Q:\ell_2 \rightarrow (\mathbb{R}^{\infty},\rho)$, where $\rho$ is a metric defined by the formula: \begin{equation}  \rho(x,y) = \sum\limits_{k=1}^{\infty}\frac{1}{2}\frac{|x_k - y_k|}{1 + |x_k - y_k|}, \, x,y\in \mathbb{R}^{\infty}. \end{equation} Operator $Q$ pushforwards $\mu$ on $\ell_2$ to measure $Q_{*}(\mu)$ on $\mathbb{R}^{\infty}$. How to check that still measure $Q_{*}$ concentrates on $\ell_2\subset \mathbb{R}^{\infty}$, i.e. $Q_{*}(\mu)[\ell_2] = 1$? $\textbf{Comment:}$ Thanks for the notes of Natan Eldredge from Cornell Univ. I have some ideas how to do it. At first one should say that Gaussian measure on a Hilbert space in this case defined uniquely by its covariance operator on a dual space $\Sigma^{-2} = \mathrm{Cov}(\mu)$ which is of a trace class operator.  So operator $Q$ expands the norm of a Gaussian vector and geometrically the idea is to check that a new covariance operator of $Q_*(\mu)$ is also of a ""trace"" class. However the propery of being a trace class operator has no rigorous meaning, since $Q_*(\mu)$ is a measure not on a Hilbert space, but on $(\mathbb{R}^{\infty},\rho)$. So one should do a bit different construction. Having a quadratic form $\Sigma^{-2}$ on $\ell_2$ it is possible to write explicitly the new quadratic form on $(\mathbb{R}^{\infty},\rho)^*$ which is  $Q\Sigma^{-2}Q^*$. It induces the Hilbert structure on dual space $(\mathbb{R}^{\infty},\rho)^*$ which is a dual space for Cameron-Martic space (ofcourse having a completion before in a new scalar product norm). Hence we can find a Cameron-Martin space of measure $Q_*(\mu)$.  After that we aim to do the reconstruction of concentrtation space, via finding the measurable norm for this Cameron-Martin space -- if we want to prove that measure $Q_*$ concentrates on $\ell_2$ we check that $\|\cdot\|_2$ is a measurable norm in this CM space. If it is so, we find the completion of CM space in this norm and we are done. $\textbf{Minor Question:}$ The last argument above is kind of obvious, but still not clear a bit. It is related to the uniqueness of reconstruction of space via CM space (obviously it is not unique),  but to make the full proof one should say that the reconstructed space with reconstructed Gaussian measure coincide with the measure I began -- $Q_*(\mu)$. Any suggestions? Also if you find any mistake in my comment, please welcome to remark. It took me some effort to get this construction (however the question sounds rather naturally for Gaussian measures) and I havent seen any links related to such question.",,"['probability', 'functional-analysis']"
82,MLE and unbiased estimator of $P\{X_{i}=1\}$ given poisson distribution,MLE and unbiased estimator of  given poisson distribution,P\{X_{i}=1\},"$\{X_{i}: 1\leq i \leq n\}$ is an i.i.d. Poisson random sample with unknown mean $\lambda$. Find the MLE of $P\{X_{i}=1\}$. Is the MLE unbiased? Does there exist an unbiased estimator of $P\{X_{i}=1\}$ whose variance achieves the Cramer-Rao lower bound? My thoughts: MLE of $\lambda$ is $\bar{X}$. Thus, MLE of $P\{X_{i}=1\}=\lambda e^{-\lambda}$ would be $\bar{X} e^{- \bar{X} }$. Because $E\bar{X} e^{- \bar{X} }=\lambda e^{-1/n-n\lambda+n\lambda e^{-1/n}}\ne \lambda e^{-\lambda }$, (Made a mistake before, as the expectation calculated as $\lambda e^{n-1-n\lambda+n\lambda/e}$) the MLE is biased. I have calculated the Cramer-Rao lower bound as $\lambda(1-\lambda)^2 e^{-2\lambda}/n$. But I don't know how to start from here. And how to show whether there exists an unbiased estimator generally?","$\{X_{i}: 1\leq i \leq n\}$ is an i.i.d. Poisson random sample with unknown mean $\lambda$. Find the MLE of $P\{X_{i}=1\}$. Is the MLE unbiased? Does there exist an unbiased estimator of $P\{X_{i}=1\}$ whose variance achieves the Cramer-Rao lower bound? My thoughts: MLE of $\lambda$ is $\bar{X}$. Thus, MLE of $P\{X_{i}=1\}=\lambda e^{-\lambda}$ would be $\bar{X} e^{- \bar{X} }$. Because $E\bar{X} e^{- \bar{X} }=\lambda e^{-1/n-n\lambda+n\lambda e^{-1/n}}\ne \lambda e^{-\lambda }$, (Made a mistake before, as the expectation calculated as $\lambda e^{n-1-n\lambda+n\lambda/e}$) the MLE is biased. I have calculated the Cramer-Rao lower bound as $\lambda(1-\lambda)^2 e^{-2\lambda}/n$. But I don't know how to start from here. And how to show whether there exists an unbiased estimator generally?",,"['probability', 'statistics', 'estimation', 'poisson-distribution']"
83,Maximize sum with no two consecutive variables,Maximize sum with no two consecutive variables,,"Random variables $x_1,x_2,\dots,x_{100}$ are drawn independently from the uniform distribution over $(0,1)$. After knowing the values, we are allowed to choose a subset of them as long as no two consecutive variables are chosen. We want to maximize the sum of the chosen variables. In expectation, how high can we make it? One way to choose is to ignore the values and always choose $x_1,x_3,x_5,\dots,x_{99}$. Since each variable has an expectation of $1/2$, this gives an expected sum of $50$. But it should be possible to do better if we consider the realized values.","Random variables $x_1,x_2,\dots,x_{100}$ are drawn independently from the uniform distribution over $(0,1)$. After knowing the values, we are allowed to choose a subset of them as long as no two consecutive variables are chosen. We want to maximize the sum of the chosen variables. In expectation, how high can we make it? One way to choose is to ignore the values and always choose $x_1,x_3,x_5,\dots,x_{99}$. Since each variable has an expectation of $1/2$, this gives an expected sum of $50$. But it should be possible to do better if we consider the realized values.",,"['probability', 'random-variables']"
84,Conditional expected value of mutlitple draws from uniform distribution,Conditional expected value of mutlitple draws from uniform distribution,,"There are $m$ i.i.d. draws of $x$ made from a uniform distribution on $[0,1]$. The $n$ ($n\leq m$) lowest draws are ""winners"", i.e. if we write $x_1\leq\ldots\leq x_n\ldots\leq x_m$, the draws $x_1$ to $x_n$ are ""winning draws"". Now player/draw $i$ learns his $x_i$ and the fact that he is a winner, i.e. $i\in[1,n]$. What is the expected value of the remaining $(n-1)$ winning draws, given $i$'s knowledge of his own draw and the fact that he is a winner (but not knowing his ""rank""/position among the winners). EDIT: With the help of the comments below, this is what I have managed to do (credits to the commentators!): The unconditional expected value of the winning draws is $\frac{1}{n}\sum_{i=1}^n \frac{i}{1+m}=\frac{n+1}{2(m+1)}$. Obviously, the unconditional cdf is given by $F(x)=x$ for $x\in[0,1]$. $i$ can be the 1st, 2nd, ... nth of the winners. For each rank, compute the expected value of the remaining $n-1$ winners (distributed below/above him, depending on $i$'s rank) and weight it by the probability of this rank. The expected value of the remaining winners, conditional on $x_i$ and the knowledge that $i$ is a ""winner"", can hence be computed by (incomplete and possibly wrong!): \begin{alignat*}{3} \frac{1}{n-1}\bigg(% 	&(1-x_i)^{m-1}			&\cdot\binom{m-1}{0}	&[(1-1)\frac{x_i}{2}	&+\sum_{k=1}^{n-1}(x_i+(1-x_i)E[x_{(k)}^{m-1}])]\\ +	&(1-x_i)^{m-2}x_i^1		&\cdot\binom{m-1}{1}	&[(2-1)\frac{x_i}{2}	&+\sum_{k=1}^{n-2}(x_i+(1-x_i)E[x_{(k)}^{m-2}])]\\ +	&\ldots\\ +	&(1-x_i)^{m-j-2}x_i^{j-1}	&\cdot\binom{m-1}{j-1}	&[(j-1)\frac{x_i}{2}	&+\sum_{k=1}^{n-j}(x_i+(1-x_i)E[x_{(k)}^{m-j}])]\\ +	&\ldots\\ +	&(1-x_i)^{m-n-1}x_i^{n-1}	&\cdot\binom{m-1}{n-1}	&[(n-1)\frac{x_i}{2}	&+\sum_{k=1}^{n-n}(x_i+(1-x_i)E[x_{(k)}^{m-n}])]% \bigg) \end{alignat*} QUESTIONS: Is the above correct? For example, am I missing a normalisation? Is it correct that if in addition $i$ also knew his ""rank"", rather than using the summation above, he would only consider the respective summand indicating the correct position. (From the comments, this seems to be correct.) How does this change a potential normalisation? Is it correct that $$ E[x_{(k)}^{m-j}]=\frac{k}{m+1-j} $$ in the equation above, with $x_{(k)}^{m-j}$ being (if I understand it correctly) the k-th lowest out of $m-j$ iid draws? If I was also interested in the expected square of the other ""winners"" (not the square of the expected other winners), I would need to modify the formula above such that: replace $(j-1)\frac{x_i}{2}$ by $$E[\sum_{k=1}^{j-1}x_k^2|x_k\sim U(0,x_i), \text{ iid}]=\frac{x_i^2 (2j-1)}{6j}$$ and $E[x_{(k)}^{m-j}]$ by $$E[(x_{(k)}^{m-j})^2]=(\frac{k}{m+1-j})^2$$ Also, should I delete my lengthy (and wrong) comments below? Should I make this question more ""canonical"" (and if so, how)?","There are $m$ i.i.d. draws of $x$ made from a uniform distribution on $[0,1]$. The $n$ ($n\leq m$) lowest draws are ""winners"", i.e. if we write $x_1\leq\ldots\leq x_n\ldots\leq x_m$, the draws $x_1$ to $x_n$ are ""winning draws"". Now player/draw $i$ learns his $x_i$ and the fact that he is a winner, i.e. $i\in[1,n]$. What is the expected value of the remaining $(n-1)$ winning draws, given $i$'s knowledge of his own draw and the fact that he is a winner (but not knowing his ""rank""/position among the winners). EDIT: With the help of the comments below, this is what I have managed to do (credits to the commentators!): The unconditional expected value of the winning draws is $\frac{1}{n}\sum_{i=1}^n \frac{i}{1+m}=\frac{n+1}{2(m+1)}$. Obviously, the unconditional cdf is given by $F(x)=x$ for $x\in[0,1]$. $i$ can be the 1st, 2nd, ... nth of the winners. For each rank, compute the expected value of the remaining $n-1$ winners (distributed below/above him, depending on $i$'s rank) and weight it by the probability of this rank. The expected value of the remaining winners, conditional on $x_i$ and the knowledge that $i$ is a ""winner"", can hence be computed by (incomplete and possibly wrong!): \begin{alignat*}{3} \frac{1}{n-1}\bigg(% 	&(1-x_i)^{m-1}			&\cdot\binom{m-1}{0}	&[(1-1)\frac{x_i}{2}	&+\sum_{k=1}^{n-1}(x_i+(1-x_i)E[x_{(k)}^{m-1}])]\\ +	&(1-x_i)^{m-2}x_i^1		&\cdot\binom{m-1}{1}	&[(2-1)\frac{x_i}{2}	&+\sum_{k=1}^{n-2}(x_i+(1-x_i)E[x_{(k)}^{m-2}])]\\ +	&\ldots\\ +	&(1-x_i)^{m-j-2}x_i^{j-1}	&\cdot\binom{m-1}{j-1}	&[(j-1)\frac{x_i}{2}	&+\sum_{k=1}^{n-j}(x_i+(1-x_i)E[x_{(k)}^{m-j}])]\\ +	&\ldots\\ +	&(1-x_i)^{m-n-1}x_i^{n-1}	&\cdot\binom{m-1}{n-1}	&[(n-1)\frac{x_i}{2}	&+\sum_{k=1}^{n-n}(x_i+(1-x_i)E[x_{(k)}^{m-n}])]% \bigg) \end{alignat*} QUESTIONS: Is the above correct? For example, am I missing a normalisation? Is it correct that if in addition $i$ also knew his ""rank"", rather than using the summation above, he would only consider the respective summand indicating the correct position. (From the comments, this seems to be correct.) How does this change a potential normalisation? Is it correct that $$ E[x_{(k)}^{m-j}]=\frac{k}{m+1-j} $$ in the equation above, with $x_{(k)}^{m-j}$ being (if I understand it correctly) the k-th lowest out of $m-j$ iid draws? If I was also interested in the expected square of the other ""winners"" (not the square of the expected other winners), I would need to modify the formula above such that: replace $(j-1)\frac{x_i}{2}$ by $$E[\sum_{k=1}^{j-1}x_k^2|x_k\sim U(0,x_i), \text{ iid}]=\frac{x_i^2 (2j-1)}{6j}$$ and $E[x_{(k)}^{m-j}]$ by $$E[(x_{(k)}^{m-j})^2]=(\frac{k}{m+1-j})^2$$ Also, should I delete my lengthy (and wrong) comments below? Should I make this question more ""canonical"" (and if so, how)?",,"['probability', 'statistics', 'order-statistics']"
85,A probability question that uses the binomial expansion,A probability question that uses the binomial expansion,,"The question is as follow: (i) Find the binomial expansion of $(1-x)^{-3}$ up to and including $x^{4}$. (ii) A player throws a 6-sided fair die at random. If he gets an even number, he loses the game and the game ends. If he gets a ""1"", ""3""  or ""5"" he throws the die again. He wins the game if he gets either ""3"" or ""5"" thrice consecutively (eg. 335, 555, 353) and the game ends. Find the exact probability of him winning the game. I have been thinking about this question for quite a while. Obviously, the author of the question wants us to solve part (ii) with the help of part (i). However, to solve part (ii), it looks more an infinite series to me (the possible combinations of winning the game). Could anyone contribute to solve this question please?","The question is as follow: (i) Find the binomial expansion of $(1-x)^{-3}$ up to and including $x^{4}$. (ii) A player throws a 6-sided fair die at random. If he gets an even number, he loses the game and the game ends. If he gets a ""1"", ""3""  or ""5"" he throws the die again. He wins the game if he gets either ""3"" or ""5"" thrice consecutively (eg. 335, 555, 353) and the game ends. Find the exact probability of him winning the game. I have been thinking about this question for quite a while. Obviously, the author of the question wants us to solve part (ii) with the help of part (i). However, to solve part (ii), it looks more an infinite series to me (the possible combinations of winning the game). Could anyone contribute to solve this question please?",,['probability']
86,$\small| U-\frac{m}{n}\small| \leq \frac{1}{n^3}$,,\small| U-\frac{m}{n}\small| \leq \frac{1}{n^3},"Let $U$ be uniform distributed in $[0,1]$ . Show that with probability $1$ there's maximum a finite amount of $n \in \mathbb N$, so that the inequality $\small| U-\frac{m}{n}\small| \leq \frac{1}{n^3}$ is true for $m \in \mathbb N$. I have tried for two days and I couldn't solve it.","Let $U$ be uniform distributed in $[0,1]$ . Show that with probability $1$ there's maximum a finite amount of $n \in \mathbb N$, so that the inequality $\small| U-\frac{m}{n}\small| \leq \frac{1}{n^3}$ is true for $m \in \mathbb N$. I have tried for two days and I couldn't solve it.",,"['probability', 'inequality', 'stochastic-processes', 'uniform-distribution']"
87,$2D$ random walk stopping time,random walk stopping time,2D,"A $2D$ random walk starts at $(X_0, Y_0) = (k, k)$ where $k>0$ is an integer. At each step $(X_{n+1}, Y_{n+1}) = (X_{n}-1, Y_{n})$ or $(X_{n+1}, Y_{n+1}) = (X_{n}, Y_{n}-1)$ with the same probability. The process stops when $X_n = 0$ or $Y_n=0$. Let $t$ be the number of moves before stopping. I want to calculate $\Bbb E(t)$. A straight forward calculation gives $$\Bbb E(t) = 2k(1-\frac{C(2k, k)}{2^{2k}}).$$ Apparently there is an elegant solution using martingales. So far, I've shown that $X_n + \frac{n}{2}$, $Y_n+\frac{n}{2}$ (and their combinations such as $X_n - Y_n$), $(X_n-Y_n)^2 - \frac{n}{2} $, $\frac{C(X_n+Y_n, X_n)}{2^{X_n+Y_n}}$ and $\alpha^{-X_n}\beta^{-Y_n}$ (where $\alpha+ \beta = 2$) are martingales.","A $2D$ random walk starts at $(X_0, Y_0) = (k, k)$ where $k>0$ is an integer. At each step $(X_{n+1}, Y_{n+1}) = (X_{n}-1, Y_{n})$ or $(X_{n+1}, Y_{n+1}) = (X_{n}, Y_{n}-1)$ with the same probability. The process stops when $X_n = 0$ or $Y_n=0$. Let $t$ be the number of moves before stopping. I want to calculate $\Bbb E(t)$. A straight forward calculation gives $$\Bbb E(t) = 2k(1-\frac{C(2k, k)}{2^{2k}}).$$ Apparently there is an elegant solution using martingales. So far, I've shown that $X_n + \frac{n}{2}$, $Y_n+\frac{n}{2}$ (and their combinations such as $X_n - Y_n$), $(X_n-Y_n)^2 - \frac{n}{2} $, $\frac{C(X_n+Y_n, X_n)}{2^{X_n+Y_n}}$ and $\alpha^{-X_n}\beta^{-Y_n}$ (where $\alpha+ \beta = 2$) are martingales.",,"['probability', 'stochastic-processes', 'martingales', 'random-walk']"
88,de Bruijn sequence and sequence waiting time,de Bruijn sequence and sequence waiting time,,"this is quite a vague question, more of a puzzle than a question. I've spotted that two problems concerning word combinatorics have the same answer. I feel like there should be a connection, but I have none. Length of 'unwrapped' de Bruijn sequence is (in binary case) $2^{n} + n - 1$ (de Bruijn word is such a shortest word containing all words of length $n$ as subwords, e.g. for $n=2$ the word 00110) Imagine an experiment consisting of sequence of coin tosses. We can (and we want to!) stop this truly tedious activity if we spot a predetermined sequence. It's possible to compute an expected time of this, more precisely expected time of the first occurrence of the given sequence. For example for three heads in a row, HHH, it is 14 coin tosses. Let's look at this experiment as the organizers. We have lots of subjects and for each of them we generate randomly and uniformly some $n$-word ($n$ is fixed), we are interested in the average time it takes for subjects to complete their task. More precisely, now even the predetermined sequence is chosen randomly. The answer is again $2^n + n - 1$, as is computed in here . It works for larger alphabets as well (and more sided coins??). Is there a connection? If not precise, at least some heuristics. Or is it just a pure coincidence? (Coincidences in maths? There's no such thing I want to believe.)","this is quite a vague question, more of a puzzle than a question. I've spotted that two problems concerning word combinatorics have the same answer. I feel like there should be a connection, but I have none. Length of 'unwrapped' de Bruijn sequence is (in binary case) $2^{n} + n - 1$ (de Bruijn word is such a shortest word containing all words of length $n$ as subwords, e.g. for $n=2$ the word 00110) Imagine an experiment consisting of sequence of coin tosses. We can (and we want to!) stop this truly tedious activity if we spot a predetermined sequence. It's possible to compute an expected time of this, more precisely expected time of the first occurrence of the given sequence. For example for three heads in a row, HHH, it is 14 coin tosses. Let's look at this experiment as the organizers. We have lots of subjects and for each of them we generate randomly and uniformly some $n$-word ($n$ is fixed), we are interested in the average time it takes for subjects to complete their task. More precisely, now even the predetermined sequence is chosen randomly. The answer is again $2^n + n - 1$, as is computed in here . It works for larger alphabets as well (and more sided coins??). Is there a connection? If not precise, at least some heuristics. Or is it just a pure coincidence? (Coincidences in maths? There's no such thing I want to believe.)",,"['probability', 'recreational-mathematics', 'combinatorics-on-words']"
89,Two tower problem,Two tower problem,,"Suppose that we have two towers of equal height $N$ , each tower consisting of $N$ coins piled on top of each other. Now suppose we have a machine or whatever that takes a coin from one of the towers and move it to the other one. That is, a coin can be moved from tower $A$ to tower $B$ with $50\%$ probability or from $B$ to $A$ with $50\%$ probability. The question is: How many such moves on average will it take before the height of either tower $A$ or tower $B$ i zero? It can be transformed into an equivalent problem, where a machine prints $0$ or $1$ with equal probability and we want to find the average length of the sequence before there are $N$ more $0$ 's than $1$ 's or the other way around. I think I have solved it, though I'm not sure my though process is correct. The solution is: Let $f(n)$ be the average number of steps, where $n$ is the height of the towers. Now, suppose we double the height of each tower and we want to find $f(2n)$ . By definition, the average number of steps required before either tower $A$ or $B$ have height $n$ is $f(n)$ . From here, there is an equal probability that we either go back to the starting position or that the tower becomes empty. So: $$f(2n) = f(n) + 0.5[f(n) + f(2n)] + 0.5f(n)$$ Solving for $f(2n)$ we get: $$f(2n) = 4f(n)$$ Hence, $f(n)$ must take the form $f(n)=cn^2$ , where $c$ is a constant. Since $f(1) = 1 \Rightarrow c=1$ , the solution is: $f(n) = n^2$ .","Suppose that we have two towers of equal height , each tower consisting of coins piled on top of each other. Now suppose we have a machine or whatever that takes a coin from one of the towers and move it to the other one. That is, a coin can be moved from tower to tower with probability or from to with probability. The question is: How many such moves on average will it take before the height of either tower or tower i zero? It can be transformed into an equivalent problem, where a machine prints or with equal probability and we want to find the average length of the sequence before there are more 's than 's or the other way around. I think I have solved it, though I'm not sure my though process is correct. The solution is: Let be the average number of steps, where is the height of the towers. Now, suppose we double the height of each tower and we want to find . By definition, the average number of steps required before either tower or have height is . From here, there is an equal probability that we either go back to the starting position or that the tower becomes empty. So: Solving for we get: Hence, must take the form , where is a constant. Since , the solution is: .",N N A B 50\% B A 50\% A B 0 1 N 0 1 f(n) n f(2n) A B n f(n) f(2n) = f(n) + 0.5[f(n) + f(2n)] + 0.5f(n) f(2n) f(2n) = 4f(n) f(n) f(n)=cn^2 c f(1) = 1 \Rightarrow c=1 f(n) = n^2,['probability']
90,upper bound of the expectation of the maximum of a bunch of random variables,upper bound of the expectation of the maximum of a bunch of random variables,,"I met one technical problem in my project, and I wish some reference here.. Suppose $\{X_i\}_{i=1}^n$ are independent random variables. Are there some inequalities that give upper bound of $\mathbb{E}[\max_{1\leq i\leq n}X_i]$ ? By now I only know one such inequality give by Aven (1985) , that is, if $\{X_i\}_{i=1}^n$ is a sequence of random variables, then $\mathbb{E}[\max_{1\leq i\leq n}X_i] \leq \max_{1\leq i\leq n}\mathbb{E}[X_i]+\sqrt{\frac{n-1}{n}\sum_{i=1}^nVar(X_i)}$ Above inequality does not use the fact that $\{X_i\}_{i=1}^n$ are independent. I was wondering if there are some other similar inequalities that I can consider. Many thanks.","I met one technical problem in my project, and I wish some reference here.. Suppose are independent random variables. Are there some inequalities that give upper bound of ? By now I only know one such inequality give by Aven (1985) , that is, if is a sequence of random variables, then Above inequality does not use the fact that are independent. I was wondering if there are some other similar inequalities that I can consider. Many thanks.",\{X_i\}_{i=1}^n \mathbb{E}[\max_{1\leq i\leq n}X_i] \{X_i\}_{i=1}^n \mathbb{E}[\max_{1\leq i\leq n}X_i] \leq \max_{1\leq i\leq n}\mathbb{E}[X_i]+\sqrt{\frac{n-1}{n}\sum_{i=1}^nVar(X_i)} \{X_i\}_{i=1}^n,"['probability', 'expected-value', 'order-statistics']"
91,Sally and I EACH flip a fair coin.,Sally and I EACH flip a fair coin.,,"We then each guess what the other person got: I guess what side Sally's coin landed on, and Sally guesses what side my coin landed on. We win as long as at least one of us is correct. I understand that to ensure that we win every single time (regardless of actual coin toss results), I should guess that Sally got the same result as me, and Sally should guess that we got different results. This is because the set of results {HH, HT, TH, TT} is such that we both either get the same result or different results. However, say Sally forgets the strategy, and she guesses at random (1/2 chance she guesses that I got heads; 1/2 chance she guesses that I got tails). If I don't change my strategy (and keep on guessing that Sally and I got the same result), then we only win 75% of the time. My question is as follows: how can I re-strategize such that we win more often (given that Sally guesses randomly)?","We then each guess what the other person got: I guess what side Sally's coin landed on, and Sally guesses what side my coin landed on. We win as long as at least one of us is correct. I understand that to ensure that we win every single time (regardless of actual coin toss results), I should guess that Sally got the same result as me, and Sally should guess that we got different results. This is because the set of results {HH, HT, TH, TT} is such that we both either get the same result or different results. However, say Sally forgets the strategy, and she guesses at random (1/2 chance she guesses that I got heads; 1/2 chance she guesses that I got tails). If I don't change my strategy (and keep on guessing that Sally and I got the same result), then we only win 75% of the time. My question is as follows: how can I re-strategize such that we win more often (given that Sally guesses randomly)?",,"['probability', 'discrete-mathematics', 'contest-math']"
92,Moments of the number of roots of polynomials over finite fields,Moments of the number of roots of polynomials over finite fields,,"Let $F:=\{f\in\mathbb{F}_q[X_1,\ldots,X_n]: \textrm{deg}(f)\leq d\}$ be the set containing all $n$-variate polynomials of degree less than or equal to $d$ over finite field $\mathbb{F}_q$ of prime power $q$. Suppose that $f$ is chosen uniformly at random from $F$ and let $N(f)$ be the number of distinct roots of $f$ in $\mathbb{F}_q$, namely $N(f)=\#\{(x_1,\ldots,x_n)\in\mathbb{F}_q^n:f(x_1,\ldots,x_n)=0\}$. I am interested in (the upper bound of) the $m$-th moment $\mathbb{E}[(N(f))^m]$ for $m\geq 1$. By Schwartz–Zippel lemma, there is an upper bound $\mathbb{E}[(N(f))^m]\leq (dq^{n-1})^m$. Is this the best possible upper bound?","Let $F:=\{f\in\mathbb{F}_q[X_1,\ldots,X_n]: \textrm{deg}(f)\leq d\}$ be the set containing all $n$-variate polynomials of degree less than or equal to $d$ over finite field $\mathbb{F}_q$ of prime power $q$. Suppose that $f$ is chosen uniformly at random from $F$ and let $N(f)$ be the number of distinct roots of $f$ in $\mathbb{F}_q$, namely $N(f)=\#\{(x_1,\ldots,x_n)\in\mathbb{F}_q^n:f(x_1,\ldots,x_n)=0\}$. I am interested in (the upper bound of) the $m$-th moment $\mathbb{E}[(N(f))^m]$ for $m\geq 1$. By Schwartz–Zippel lemma, there is an upper bound $\mathbb{E}[(N(f))^m]\leq (dq^{n-1})^m$. Is this the best possible upper bound?",,"['probability', 'abstract-algebra', 'polynomials', 'finite-fields']"
93,What is the expected distance from the mean of a multivariate Gaussian?,What is the expected distance from the mean of a multivariate Gaussian?,,"For a multivariate Gaussian distribution $p(x) = N(x\mid \mu,\Sigma)$, what is $E[\|x-\mu\|]$? I know from this question that $E[|x-\mu|]=\sigma\sqrt{2/\pi}$ for univariate Gaussians. But I couldn't find a definition of standard deviation for multivariate Gaussians. Could it be something like $\|\sqrt{\boldsymbol\lambda}\|\sqrt{2/\pi}$, where $\boldsymbol\lambda$ is the eigenvalues of $\Sigma$?","For a multivariate Gaussian distribution $p(x) = N(x\mid \mu,\Sigma)$, what is $E[\|x-\mu\|]$? I know from this question that $E[|x-\mu|]=\sigma\sqrt{2/\pi}$ for univariate Gaussians. But I couldn't find a definition of standard deviation for multivariate Gaussians. Could it be something like $\|\sqrt{\boldsymbol\lambda}\|\sqrt{2/\pi}$, where $\boldsymbol\lambda$ is the eigenvalues of $\Sigma$?",,"['probability', 'integration', 'statistics', 'multivariable-calculus', 'normal-distribution']"
94,Finding a formula for the expected value,Finding a formula for the expected value,,"Assume we have $n$ dice, and each die has $10$ sides. We roll the dice and add all subsets of dice that are of equal value, then find the highest number. For example if we roll five dice and get: $1,1,5,5,7$ we have $2\times 1=2,\  2\times 5=10 ,\ 1\times 7=7$, so our result is then $10$ since that is the highest number. How to find a formula for finding the expected value for $n$ dice?","Assume we have $n$ dice, and each die has $10$ sides. We roll the dice and add all subsets of dice that are of equal value, then find the highest number. For example if we roll five dice and get: $1,1,5,5,7$ we have $2\times 1=2,\  2\times 5=10 ,\ 1\times 7=7$, so our result is then $10$ since that is the highest number. How to find a formula for finding the expected value for $n$ dice?",,"['probability', 'statistics']"
95,Poisson Process: indepedent increment,Poisson Process: indepedent increment,,"Let $\{N(t): t\geq0\}$ be a Poisson process of rate $\lambda$, and let $S_n$ denote the time until the $n_{th}$ event occurs. compute $P(S_3>5|N(2)=1)$ Attempt: Notice that $P(S_3>5)=P(N(5)<3)$. Therefore, we write $P(N(5)<3|N(2)=1)$. Using indepedent increment, this is equivalent as $P(N(5)-N(2)\leq1)=P(N(3)\leq1)=e^{-3\lambda}(1+3\lambda)$ . What do you guys think?","Let $\{N(t): t\geq0\}$ be a Poisson process of rate $\lambda$, and let $S_n$ denote the time until the $n_{th}$ event occurs. compute $P(S_3>5|N(2)=1)$ Attempt: Notice that $P(S_3>5)=P(N(5)<3)$. Therefore, we write $P(N(5)<3|N(2)=1)$. Using indepedent increment, this is equivalent as $P(N(5)-N(2)\leq1)=P(N(3)\leq1)=e^{-3\lambda}(1+3\lambda)$ . What do you guys think?",,"['probability', 'probability-theory', 'poisson-distribution', 'poisson-process', 'exponential-distribution']"
96,"For a simple random walk $S_n$ and for a stopping time $\tau$, what is the intuitive interpretation of $P(\tau < \infty) = 1$?","For a simple random walk  and for a stopping time , what is the intuitive interpretation of ?",S_n \tau P(\tau < \infty) = 1,"Suppose we have a simple random walk $S_n$ and we define a stopping time to be $\tau = min\{n: S_n = A \ \text{or} \ S_n = -B\}$. That is, we stop the first time we hit $A$ or $-B$. With this, I have two questions I was hoping someone might yield some insight into: The first is why $P(\tau < \infty)$ must be either equal to $1$ or $0$ but cannot be anything in between, say, like $\frac{1}{3}$? The second is how exactly do we interpret the statement that $P(\tau < \infty) = 1$? I know that formally it can be written as $P(\omega \in \Omega : \tau(\omega) < \infty) = 1$. Is it right to say that this means: $P(\omega \in \Omega : \tau(\omega) < \infty) = 1 \implies $**""Go and search through all elements in $\Omega$. Take each element $\omega$ and plug it into $\tau(\omega)$. If $\tau(\omega) < \infty$, sound the alerts and note down this specific $\omega$.  Then, collect all such $\omega$ that cause $\tau(\omega) < \infty$. If we found at least one $\omega$ such that $\tau(\omega) < \infty$, then we say $P(\tau < \infty) = 1$. If our search was a failure and did not yield any $\omega$ where $\tau(\omega) < \infty$, we say $P(\tau < \infty) = 0$.""** What is confusing to me here is if $P(\omega \in \Omega : \tau(\omega) < \infty)$ means 1) taking all $\omega$ that satisfy $\tau(\omega) < \infty$, then dividing by the total number of all in $\Omega$, or 2) taking all $\omega$ that satisfy $\tau(\omega) < \infty$, then noting that the probability of such a set must be $1$ since we found at least one such $\omega$, hence theres a chance that we may stumble across it? Thanks so much!","Suppose we have a simple random walk $S_n$ and we define a stopping time to be $\tau = min\{n: S_n = A \ \text{or} \ S_n = -B\}$. That is, we stop the first time we hit $A$ or $-B$. With this, I have two questions I was hoping someone might yield some insight into: The first is why $P(\tau < \infty)$ must be either equal to $1$ or $0$ but cannot be anything in between, say, like $\frac{1}{3}$? The second is how exactly do we interpret the statement that $P(\tau < \infty) = 1$? I know that formally it can be written as $P(\omega \in \Omega : \tau(\omega) < \infty) = 1$. Is it right to say that this means: $P(\omega \in \Omega : \tau(\omega) < \infty) = 1 \implies $**""Go and search through all elements in $\Omega$. Take each element $\omega$ and plug it into $\tau(\omega)$. If $\tau(\omega) < \infty$, sound the alerts and note down this specific $\omega$.  Then, collect all such $\omega$ that cause $\tau(\omega) < \infty$. If we found at least one $\omega$ such that $\tau(\omega) < \infty$, then we say $P(\tau < \infty) = 1$. If our search was a failure and did not yield any $\omega$ where $\tau(\omega) < \infty$, we say $P(\tau < \infty) = 0$.""** What is confusing to me here is if $P(\omega \in \Omega : \tau(\omega) < \infty)$ means 1) taking all $\omega$ that satisfy $\tau(\omega) < \infty$, then dividing by the total number of all in $\Omega$, or 2) taking all $\omega$ that satisfy $\tau(\omega) < \infty$, then noting that the probability of such a set must be $1$ since we found at least one such $\omega$, hence theres a chance that we may stumble across it? Thanks so much!",,"['probability', 'probability-theory', 'stochastic-processes', 'martingales', 'random-walk']"
97,Eliminating Repeat Numbers from a Hat,Eliminating Repeat Numbers from a Hat,,"Inspired by this question . Inside a hat there are $n$ slips of paper with the integers $1$ through $n$ on them. The numbers on slips $\{1,2,\ldots,r\}$ are erased and replaced with the numbers $\{r+1,r+2,\ldots,2r\}$ respectively $\left(\text{assume }r\leq\frac{n}{2}\right)$. What is the expected value of papers that need to be picked out of the hat for all the numbers in the hat (without replacement) to be unique? (For each element of $\{r+1,r+2,\ldots,2r\}$, at least one paper containing that element has been chosen). I have tried to use similar logic to the linked question, but I do not know how to incorporate repeats into the calculations.","Inspired by this question . Inside a hat there are $n$ slips of paper with the integers $1$ through $n$ on them. The numbers on slips $\{1,2,\ldots,r\}$ are erased and replaced with the numbers $\{r+1,r+2,\ldots,2r\}$ respectively $\left(\text{assume }r\leq\frac{n}{2}\right)$. What is the expected value of papers that need to be picked out of the hat for all the numbers in the hat (without replacement) to be unique? (For each element of $\{r+1,r+2,\ldots,2r\}$, at least one paper containing that element has been chosen). I have tried to use similar logic to the linked question, but I do not know how to incorporate repeats into the calculations.",,"['probability', 'combinatorics']"
98,Probability of a run of $n$ cards of the same color?,Probability of a run of  cards of the same color?,n,"A magician friend hit me with this one: given a shuffled deck, what is the probability that it contains at least one run of at least $n$ cards of the same color — for example, four reds or four blacks in a row?","A magician friend hit me with this one: given a shuffled deck, what is the probability that it contains at least one run of at least $n$ cards of the same color — for example, four reds or four blacks in a row?",,"['probability', 'card-games']"
99,Relationship between binomial and negative binomial distributions (how to extend the probability space?),Relationship between binomial and negative binomial distributions (how to extend the probability space?),,"I wonder a technique to extend the discrete probability space. Here's an example from Concrete Mathematics EXERCISE 8.17: Let $X_{n,p}$ and $Y_{n,p}$ have the binomial and negative binomial distributions, respectively, with parameters $(n,p)$. Prove that $\Pr(Y_{n,p}\le m) = \Pr(X_{m+n,p}\ge n)$. The answer to the problem is also from Concrete Mathematics : \begin{align} \Pr(Y_{n,p}\le m)  &= \Pr(Y_{n,p}+n \le m+n) \\ &= \hbox{probability that we need $\le m+n$} \tag{1}\\ &= \hbox{probability that $m+n$ tosses yield $\ge n$ heads} \tag{2} \\ &= \Pr(X_{m+n,p}\ge n) \end{align} Well, (1) and (2) are describing the same thing, but they're in different probability spaces, so we should extend these two probability spaces into a unique probability space, ensuring that the probability of each event doesn't change. How can we do it? I haven't a clear idea. And the more general problem arises: How to extend a probability space? Is there any technique to do it, at least, treat part of problems? Thanks for your help!","I wonder a technique to extend the discrete probability space. Here's an example from Concrete Mathematics EXERCISE 8.17: Let $X_{n,p}$ and $Y_{n,p}$ have the binomial and negative binomial distributions, respectively, with parameters $(n,p)$. Prove that $\Pr(Y_{n,p}\le m) = \Pr(X_{m+n,p}\ge n)$. The answer to the problem is also from Concrete Mathematics : \begin{align} \Pr(Y_{n,p}\le m)  &= \Pr(Y_{n,p}+n \le m+n) \\ &= \hbox{probability that we need $\le m+n$} \tag{1}\\ &= \hbox{probability that $m+n$ tosses yield $\ge n$ heads} \tag{2} \\ &= \Pr(X_{m+n,p}\ge n) \end{align} Well, (1) and (2) are describing the same thing, but they're in different probability spaces, so we should extend these two probability spaces into a unique probability space, ensuring that the probability of each event doesn't change. How can we do it? I haven't a clear idea. And the more general problem arises: How to extend a probability space? Is there any technique to do it, at least, treat part of problems? Thanks for your help!",,"['probability', 'probability-distributions']"
