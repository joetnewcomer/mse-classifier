,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Picking $4$ balls from $16$ balls. Chance that we get exactly $2$ different colors?,Picking  balls from  balls. Chance that we get exactly  different colors?,4 16 2,"Suppose $4$ balls will be randomly selected from a collection of $4$ red balls, $4$ blue balls, $4$ yellow balls, and $4$ green balls. What is the chance that exactly two of the colors will be present? Attempted Solution: Picking $2$ groups of colors out of the $4$ and then picking $4$ balls from the $8$ balls gives: $4\choose2$$\frac{8\choose{4}}{16\choose4}$ But then there's the cases where all four balls balls selected from the $16$ are the same color giving: $4\choose2$$\frac{8\choose{4}}{16\choose4}$ - $\frac{4\choose{1}}{16\choose4}$ = $.2286$. Did I do this correctly? If so, and you have another method, I would be interested in seeing that as well.","Suppose $4$ balls will be randomly selected from a collection of $4$ red balls, $4$ blue balls, $4$ yellow balls, and $4$ green balls. What is the chance that exactly two of the colors will be present? Attempted Solution: Picking $2$ groups of colors out of the $4$ and then picking $4$ balls from the $8$ balls gives: $4\choose2$$\frac{8\choose{4}}{16\choose4}$ But then there's the cases where all four balls balls selected from the $16$ are the same color giving: $4\choose2$$\frac{8\choose{4}}{16\choose4}$ - $\frac{4\choose{1}}{16\choose4}$ = $.2286$. Did I do this correctly? If so, and you have another method, I would be interested in seeing that as well.",,"['probability', 'combinatorics']"
1,Why uniform distribution on sphere of radius $\sqrt n$ isotropic?,Why uniform distribution on sphere of radius  isotropic?,\sqrt n,"Definition. A random vector $X = (X_1, \cdots, X_n)$ is said to be isotropic if $\mathbb{E}[XX^T] = I$. Now let $X \sim \text{Unif}(\sqrt n S^{n-1})$ where $S^{n-1}$ denotes unit sphere (surface of unit ball) in $\mathbb{R}^n$. I want to show that $X$ is isotropic. Any help? My Intuition : It can be proved that $X$ is isotropic iff $\mathbb{E}\left[\left<X, x\right>^2\right] = \|x\|^2$ for all $x \in \mathbb{R}^n$ which intuitively means all marginal projections of $X$ have unit variance. This intuition helps to get a sence of why uniform distribution on the surface of sphere should be isotropic but how to show that rigorously?","Definition. A random vector $X = (X_1, \cdots, X_n)$ is said to be isotropic if $\mathbb{E}[XX^T] = I$. Now let $X \sim \text{Unif}(\sqrt n S^{n-1})$ where $S^{n-1}$ denotes unit sphere (surface of unit ball) in $\mathbb{R}^n$. I want to show that $X$ is isotropic. Any help? My Intuition : It can be proved that $X$ is isotropic iff $\mathbb{E}\left[\left<X, x\right>^2\right] = \|x\|^2$ for all $x \in \mathbb{R}^n$ which intuitively means all marginal projections of $X$ have unit variance. This intuition helps to get a sence of why uniform distribution on the surface of sphere should be isotropic but how to show that rigorously?",,"['linear-algebra', 'probability', 'probability-theory']"
2,Overcounting in combinatorics problem,Overcounting in combinatorics problem,,"Disclaimer: this is a homework exercise, please don't give me the full solution! I'd just like a hint in the right direction. A box contains 30 red balls, 30 white balls, and 30 blue balls. If 10 balls are selected at random, without replacement, what is the probability that at least one color will be missing from the selection? My reasoning so far has been to look at the event that every colour is present, and then just do $1 - $ that value. We can think of it as selecting 3 balls, one from each colour, and then filling the remaining 7 spaces with any other balls. Selecting 1 ball from 30 three times is $30^3$ combinations. Then, selecting 7 balls from 87 is $C_7^{87}$ combinations, and the total combinations is their product. However, this turns out to be larger than $C_{10}^{90}$, which is the total amount of ways 10 balls can be selected from 90 balls. Clearly, I've overcounted somewhere, but I have no idea where! I've been stuck on this for hours and I can't see where I'm going wrong.","Disclaimer: this is a homework exercise, please don't give me the full solution! I'd just like a hint in the right direction. A box contains 30 red balls, 30 white balls, and 30 blue balls. If 10 balls are selected at random, without replacement, what is the probability that at least one color will be missing from the selection? My reasoning so far has been to look at the event that every colour is present, and then just do $1 - $ that value. We can think of it as selecting 3 balls, one from each colour, and then filling the remaining 7 spaces with any other balls. Selecting 1 ball from 30 three times is $30^3$ combinations. Then, selecting 7 balls from 87 is $C_7^{87}$ combinations, and the total combinations is their product. However, this turns out to be larger than $C_{10}^{90}$, which is the total amount of ways 10 balls can be selected from 90 balls. Clearly, I've overcounted somewhere, but I have no idea where! I've been stuck on this for hours and I can't see where I'm going wrong.",,"['probability', 'combinatorics']"
3,What is the probability that a random ordering of the $7$ integers results in one run up followed by one run down?,What is the probability that a random ordering of the  integers results in one run up followed by one run down?,7,"Suppose that the integers from $1$ to $7$ are randomly ordered from left to right. If the ordering consists of an initial increasing sequence followed by a decreasing sequence, then we say that we have one run up followed by one run down. What is the probability that a random ordering of the $7$ integers results in one run up followed by one run down. My attempt: I think I did this right, but I am looking for verification or other interesting methods to approach this. I noted that $7$ must not be in position $1$ or $7$. When considering $7$ to be in position $2$, you have $6\choose1$ different possibilities for position $1$, and positions $3$-$7$ would only have one possibility (the remaining digits in decreasing order). Similarly, we $6\choose2$, $6\choose3$. $6\choose4$, and $6\choose5$ possibilities when $7$ is in the $3^{rd}$, $4^{th}$, $5^{th}$, and $6^{th}$ spot, respectively. This gives $p$ =  ${{6\choose1}+{6\choose2}+{6\choose3}+{6\choose4}+{6\choose5}\over 7!}$ $=$ $.0123$","Suppose that the integers from $1$ to $7$ are randomly ordered from left to right. If the ordering consists of an initial increasing sequence followed by a decreasing sequence, then we say that we have one run up followed by one run down. What is the probability that a random ordering of the $7$ integers results in one run up followed by one run down. My attempt: I think I did this right, but I am looking for verification or other interesting methods to approach this. I noted that $7$ must not be in position $1$ or $7$. When considering $7$ to be in position $2$, you have $6\choose1$ different possibilities for position $1$, and positions $3$-$7$ would only have one possibility (the remaining digits in decreasing order). Similarly, we $6\choose2$, $6\choose3$. $6\choose4$, and $6\choose5$ possibilities when $7$ is in the $3^{rd}$, $4^{th}$, $5^{th}$, and $6^{th}$ spot, respectively. This gives $p$ =  ${{6\choose1}+{6\choose2}+{6\choose3}+{6\choose4}+{6\choose5}\over 7!}$ $=$ $.0123$",,"['probability', 'combinatorics', 'statistics', 'permutations']"
4,"If a random variable $X$ is measurable with respect to the tail $\sigma$-algebra, then it is constant a.s.","If a random variable  is measurable with respect to the tail -algebra, then it is constant a.s.",X \sigma,"Consider Kolmogorov's Zero-One law: Suppose that $(X_n)_{n \in \mathbb{N}}$ is a sequence of independent   random variables. Then any event belonging to the tail   $\sigma$-algebra $\bigcap_{n \in \mathbb{N}}\sigma(X_n,X_{n+1},\dots)$   has probability $0$ or $1$. Now the book says: Every random variable $X$ which is measurable with respect to the tail   $\sigma$-algebra is a.s. constant. I do not quite see this, but I think it should be easy. So since $X$ is measurable with respect to the tail $\sigma$-algebra, we have that $$\{X \leq t\} \in \bigcap_{n \in \mathbb{N}}\sigma(X_n,X_{n+1},\dots)$$ for all $t \in \mathbb{R}$. Similarly also $\{X \geq t\}$. So by $$\{X = t\} = \{X \leq t\} \cap \{X \geq t\}$$ we get that $P(X = t)$ is either $0$ or $1$. Why should it be $1$ for some $t$? Or how does one see this?","Consider Kolmogorov's Zero-One law: Suppose that $(X_n)_{n \in \mathbb{N}}$ is a sequence of independent   random variables. Then any event belonging to the tail   $\sigma$-algebra $\bigcap_{n \in \mathbb{N}}\sigma(X_n,X_{n+1},\dots)$   has probability $0$ or $1$. Now the book says: Every random variable $X$ which is measurable with respect to the tail   $\sigma$-algebra is a.s. constant. I do not quite see this, but I think it should be easy. So since $X$ is measurable with respect to the tail $\sigma$-algebra, we have that $$\{X \leq t\} \in \bigcap_{n \in \mathbb{N}}\sigma(X_n,X_{n+1},\dots)$$ for all $t \in \mathbb{R}$. Similarly also $\{X \geq t\}$. So by $$\{X = t\} = \{X \leq t\} \cap \{X \geq t\}$$ we get that $P(X = t)$ is either $0$ or $1$. Why should it be $1$ for some $t$? Or how does one see this?",,"['probability', 'measure-theory']"
5,Prove that $X^2$ and $Y^2$ are independent if $X$ and $Y$ are independent - am I right?,Prove that  and  are independent if  and  are independent - am I right?,X^2 Y^2 X Y,$X$ and $Y$ are independent r.v's. I want to prove that $X^2$ and $Y^2$ are also independent. Here's my reasoning: $P(X=x)=P(X=x|Y=y) \implies P(X=x)=P(X=x|Y=y^2) \implies P(X=x^2)=P(X=x^2|Y=y^2)$,and are independent r.v's. I want to prove that and are also independent. Here's my reasoning:,X Y X^2 Y^2 P(X=x)=P(X=x|Y=y) \implies P(X=x)=P(X=x|Y=y^2) \implies P(X=x^2)=P(X=x^2|Y=y^2),"['probability', 'probability-theory', 'independence']"
6,Adding a constant to an exponential random variable,Adding a constant to an exponential random variable,,"Let $θ$ be an unknown constant. Let $W_1,…,W_n$ be independent exponential random variables each with parameter 1. Let $X_i=θ+W_i$. How do I calculate the distribution of $X_1$, given θ? Notice that I don't look for a conditional probability here since $θ$ is a constant. My guess is that $P_X(x;θ)= e^{-(x_1-θ)}$ but I'm not sure. Thank you.","Let $θ$ be an unknown constant. Let $W_1,…,W_n$ be independent exponential random variables each with parameter 1. Let $X_i=θ+W_i$. How do I calculate the distribution of $X_1$, given θ? Notice that I don't look for a conditional probability here since $θ$ is a constant. My guess is that $P_X(x;θ)= e^{-(x_1-θ)}$ but I'm not sure. Thank you.",,"['probability', 'random-variables', 'exponential-distribution']"
7,Sample Space as the image of a Random Variable?,Sample Space as the image of a Random Variable?,,"My understanding is that a random variable $X$ is a function that goes from a sample space $\Omega$ to a measurable space $E$, where $\Omega$ is part of a probability space (along with a sigma-algebra $F$ and a measurable function $\mu$) and where $E$ is tipically $\mathbb R$. A sample space is a set of all the possible  ""outcomes"" that may arise in an experiment, $F$ could be thought of as a set of ""events"" (which are, in turn, sets of outcomes), and $\mu$ is a measure used to assign probabilities to events in $F$. I am not a mathematician , and I only have very superficial knowledge of Probability Theory and Measure Theory. Nonetheless, I am interested on having a general intuition of the concepts I've mentioned above, and to learn how to correctly use the vocabulary of Probability and Statistics. Thus, I am concerned about the way the terms ""Outcome"" and ""Sample Space"" seem to be used in different places; particularly when it's implied that the codomain or the image of $X$ is the Sample Space of $X$ , and/or that $X$ ""takes the values of"" the ""outcomes"" (which I believe are both wrong given the definitions above). Some examples include: Wikipedia's article on ""Random Variates"": A random variate is a particular outcome of a random variable Reading ahead it's clear what they mean: that a Random Variate is a particular value that a r.v. can take. Thus, that sentence says that an ""outcome"" is a possible value for a r.v., and not a value where the r.v., as a function, is evaluated. An answer at Cross Validated, on the nature of ""Sample"" and ""Outcome"": So the Sample Space will be ""{Heads, Tails}"", which will be the domain of the random variable, while the ""outcome space"", its range, will be {5,17} Since the ""outcome space"" is the range of a r.v., then ""outcomes"" are elements of the range and not of the domain, according to his definition. Wikipedia's article on PDF's : In probability theory, a probability density function (PDF), or density of a continuous random variable, is a function, whose value at any given sample (or point) in the sample space (the set of possible values taken by the random variable) can be interpreted as […] I always thought intuitively that a PDF helps in solving problems like finding the probability that $ X \le k $, by making integrals from minus infinity to k. Thus, the domain of a PDF is the image of X, and not the domain of X, right? The one that confused me the most (although I can't find it now) was one that said something along the lines of ""X is a discrete r.v. if its sample space is discrete"". I believe that's totally wrong if we define the sample space of X as its domain! So my conclusion is that it's extremely common to find the terms ""sample space"" and ""outcome"" used to refer to the image of a random variable and its possible values. Nonetheless, that usage is fundamentally different from the one used in more ""formal"" treatments of probability theory, and one must be always alert as to what definition is being used . So my questions are: Is my conclusion right, or am I missing something? Is it possible to define a r.v. where both its domain and its image are the same sample space? I'm unsure if that even makes sense, but that may make it acceptable to say things like the ones I've cited. I'm specially interested in that if $\Omega$ and $E$ can both be $\mathbb R$?! Is it possible to make a probability space ""around"" $E$ (the codomain of X)? So that $E$ is also a Sample Space? Thanks!","My understanding is that a random variable $X$ is a function that goes from a sample space $\Omega$ to a measurable space $E$, where $\Omega$ is part of a probability space (along with a sigma-algebra $F$ and a measurable function $\mu$) and where $E$ is tipically $\mathbb R$. A sample space is a set of all the possible  ""outcomes"" that may arise in an experiment, $F$ could be thought of as a set of ""events"" (which are, in turn, sets of outcomes), and $\mu$ is a measure used to assign probabilities to events in $F$. I am not a mathematician , and I only have very superficial knowledge of Probability Theory and Measure Theory. Nonetheless, I am interested on having a general intuition of the concepts I've mentioned above, and to learn how to correctly use the vocabulary of Probability and Statistics. Thus, I am concerned about the way the terms ""Outcome"" and ""Sample Space"" seem to be used in different places; particularly when it's implied that the codomain or the image of $X$ is the Sample Space of $X$ , and/or that $X$ ""takes the values of"" the ""outcomes"" (which I believe are both wrong given the definitions above). Some examples include: Wikipedia's article on ""Random Variates"": A random variate is a particular outcome of a random variable Reading ahead it's clear what they mean: that a Random Variate is a particular value that a r.v. can take. Thus, that sentence says that an ""outcome"" is a possible value for a r.v., and not a value where the r.v., as a function, is evaluated. An answer at Cross Validated, on the nature of ""Sample"" and ""Outcome"": So the Sample Space will be ""{Heads, Tails}"", which will be the domain of the random variable, while the ""outcome space"", its range, will be {5,17} Since the ""outcome space"" is the range of a r.v., then ""outcomes"" are elements of the range and not of the domain, according to his definition. Wikipedia's article on PDF's : In probability theory, a probability density function (PDF), or density of a continuous random variable, is a function, whose value at any given sample (or point) in the sample space (the set of possible values taken by the random variable) can be interpreted as […] I always thought intuitively that a PDF helps in solving problems like finding the probability that $ X \le k $, by making integrals from minus infinity to k. Thus, the domain of a PDF is the image of X, and not the domain of X, right? The one that confused me the most (although I can't find it now) was one that said something along the lines of ""X is a discrete r.v. if its sample space is discrete"". I believe that's totally wrong if we define the sample space of X as its domain! So my conclusion is that it's extremely common to find the terms ""sample space"" and ""outcome"" used to refer to the image of a random variable and its possible values. Nonetheless, that usage is fundamentally different from the one used in more ""formal"" treatments of probability theory, and one must be always alert as to what definition is being used . So my questions are: Is my conclusion right, or am I missing something? Is it possible to define a r.v. where both its domain and its image are the same sample space? I'm unsure if that even makes sense, but that may make it acceptable to say things like the ones I've cited. I'm specially interested in that if $\Omega$ and $E$ can both be $\mathbb R$?! Is it possible to make a probability space ""around"" $E$ (the codomain of X)? So that $E$ is also a Sample Space? Thanks!",,"['probability', 'probability-theory', 'random-variables']"
8,Convergence in probability and pointwise convergence of densities?,Convergence in probability and pointwise convergence of densities?,,"Are there any theorems that connect these two concepts, in particular, is there a result that states that convergence in probability of a sequence of continuous random variables $\{X_n\}_{n\geq 0}$ to another r.v. $X$ (also with a density) implies that the corresponding sequence of densities converge pointwise to the density of $X$? Or is there perhaps an obvious counterexample to this idea (c.f. convergence in distribution does not imply pointwise convergence of densities).","Are there any theorems that connect these two concepts, in particular, is there a result that states that convergence in probability of a sequence of continuous random variables $\{X_n\}_{n\geq 0}$ to another r.v. $X$ (also with a density) implies that the corresponding sequence of densities converge pointwise to the density of $X$? Or is there perhaps an obvious counterexample to this idea (c.f. convergence in distribution does not imply pointwise convergence of densities).",,"['probability', 'probability-theory', 'statistics', 'probability-distributions']"
9,Did computers render useless the teaching of approximating the Binomial with Poisson and Normal distribution?,Did computers render useless the teaching of approximating the Binomial with Poisson and Normal distribution?,,"When considering a binomial distribution with large $n$, it is (was?) usefull to use the Poisson or Normal distribution instead. One of the reason being the difficuty to compute the binomial coefficient for large $n$. Computers have since grown in performance and algorithms in efficiency. Is it still worth teaching students about approximating $B(n;p)$ with $Po(np)$ for small values of $np$ (or small values of $n(1-p)$) and with $N(np;np(1-p))$ otherwise? An ideal answer would include reference (personal or theoretical) to what is actually done in practice and to the applications of such approximations in undergraduate or graduate courses.","When considering a binomial distribution with large $n$, it is (was?) usefull to use the Poisson or Normal distribution instead. One of the reason being the difficuty to compute the binomial coefficient for large $n$. Computers have since grown in performance and algorithms in efficiency. Is it still worth teaching students about approximating $B(n;p)$ with $Po(np)$ for small values of $np$ (or small values of $n(1-p)$) and with $N(np;np(1-p))$ otherwise? An ideal answer would include reference (personal or theoretical) to what is actually done in practice and to the applications of such approximations in undergraduate or graduate courses.",,"['probability', 'probability-distributions', 'approximation', 'computational-mathematics']"
10,meaning multiplying an outcome by its probability,meaning multiplying an outcome by its probability,,I was reading about the expected value in probability theory. What is the meaning of multiplying an outcome by its probability. For example if I multiply and amount of money by an interest rate I get the iterest amount. What would mean to multiply an outcome by its probability?,I was reading about the expected value in probability theory. What is the meaning of multiplying an outcome by its probability. For example if I multiply and amount of money by an interest rate I get the iterest amount. What would mean to multiply an outcome by its probability?,,['probability']
11,Cauchy CDF derivation from standard normal?,Cauchy CDF derivation from standard normal?,,"I'm studying Probability, from the book ""Introduction to probability"" by Joseph K. Blitzstein and Jessica Hwang page 294 talks about Cauchy CDF, it says: Let $X$ and $Y \sim N(0,1)$ (Standard Normal) and let $T = \frac{X}{Y}$. The distribution of $T$ is called Cauchy Distribution. The CDF of $T$ is: $$F_T(t) = P(T \le t) = P\Big(\frac{X}{Y} \le t\Big) = P\Big(\frac{X}{|Y|} \le t\Big)$$ since the r.v.s $\frac{X}{Y}$ and $\frac{X}{|Y|}$ are identically distributed by the symmetry of the standard Normal distribution. I have few questions: Random variable has some similarity with function which we can manipulate it for example if I have function in general(like a high school math function) ex. $f(x) = x+2$ and another $g(x) = x+2$ then if I do $\frac{f(x)}{g(x)} =1$ I get $1$. lets talk about the r.v.s $X$ and $Y$, if it is identical shouldn't I get $\frac{X}{Y} = 1$? Why $P(\frac{X}{Y} \le t) = P(\frac{X}{|Y|} \le t)$ ? I know symmetry of standard normal talks about if $Z$ has standard normal distribution then $-Z$ and $Z$ has the same distribution but in this case it is the absolute value of $Y$, what does that mean? When we talk about manipulating r.v.s ex. $Y = X-1$ it is to minus all the support of $X$ by $1$ to get distribution of $Y$ but what about the r.v.s divide by another r.v.s? Do we think of it as a function that already crystallised into a number? Or how we think about it? I really have no clue about what this is about. Please give me detail and step by step answer. I'm a newbie.","I'm studying Probability, from the book ""Introduction to probability"" by Joseph K. Blitzstein and Jessica Hwang page 294 talks about Cauchy CDF, it says: Let $X$ and $Y \sim N(0,1)$ (Standard Normal) and let $T = \frac{X}{Y}$. The distribution of $T$ is called Cauchy Distribution. The CDF of $T$ is: $$F_T(t) = P(T \le t) = P\Big(\frac{X}{Y} \le t\Big) = P\Big(\frac{X}{|Y|} \le t\Big)$$ since the r.v.s $\frac{X}{Y}$ and $\frac{X}{|Y|}$ are identically distributed by the symmetry of the standard Normal distribution. I have few questions: Random variable has some similarity with function which we can manipulate it for example if I have function in general(like a high school math function) ex. $f(x) = x+2$ and another $g(x) = x+2$ then if I do $\frac{f(x)}{g(x)} =1$ I get $1$. lets talk about the r.v.s $X$ and $Y$, if it is identical shouldn't I get $\frac{X}{Y} = 1$? Why $P(\frac{X}{Y} \le t) = P(\frac{X}{|Y|} \le t)$ ? I know symmetry of standard normal talks about if $Z$ has standard normal distribution then $-Z$ and $Z$ has the same distribution but in this case it is the absolute value of $Y$, what does that mean? When we talk about manipulating r.v.s ex. $Y = X-1$ it is to minus all the support of $X$ by $1$ to get distribution of $Y$ but what about the r.v.s divide by another r.v.s? Do we think of it as a function that already crystallised into a number? Or how we think about it? I really have no clue about what this is about. Please give me detail and step by step answer. I'm a newbie.",,"['probability', 'probability-distributions']"
12,Expected value of $X^n$,Expected value of,X^n,"Given: $F_X(x)$ is a CDF and: $E[X] = \int\limits_0^\infty (1-F_X (x))\, dx\ $ How do I prove: $E[X^n] = \int\limits_0^\infty nx^{n-1}(1-F_X(x))dx   $","Given: $F_X(x)$ is a CDF and: $E[X] = \int\limits_0^\infty (1-F_X (x))\, dx\ $ How do I prove: $E[X^n] = \int\limits_0^\infty nx^{n-1}(1-F_X(x))dx   $",,['probability']
13,Calculus of Variations in Probability Theory,Calculus of Variations in Probability Theory,,"Are there any places where the Calculus of Variations shows up (i.e. is used) in probability? It seems like it should be natural for functional optimization to appear (as it does in statistics, where it seems to appear in somewhat more applied areas, like regression and machine learning; or its use in stochastic optimal control theory), but I do not know of any interesting probabilistic problems that can be cast in a variational light, but are more on theoretical side, or maybe proofs of theorems in probability that use variational techniques. I suppose the Malliavin Calculus is related, but it seems more like an answer to the ""reverse"" question :)","Are there any places where the Calculus of Variations shows up (i.e. is used) in probability? It seems like it should be natural for functional optimization to appear (as it does in statistics, where it seems to appear in somewhat more applied areas, like regression and machine learning; or its use in stochastic optimal control theory), but I do not know of any interesting probabilistic problems that can be cast in a variational light, but are more on theoretical side, or maybe proofs of theorems in probability that use variational techniques. I suppose the Malliavin Calculus is related, but it seems more like an answer to the ""reverse"" question :)",,"['probability', 'functional-analysis', 'probability-theory', 'calculus-of-variations', 'malliavin-calculus']"
14,"Minimal sufficient statistic of $\operatorname{Uniform}(-\theta,\theta)$",Minimal sufficient statistic of,"\operatorname{Uniform}(-\theta,\theta)","I am seeking clarification on why both the vector $(X_{(1)},X_{(n)})^T$ and $\max\{-X_{(1)},X_{(n)}\}$ are sufficient for $\operatorname{Unif}(-\theta,\theta)$, but only $\max\{-X_{(1)},X_{(n)}\}$ is minimal sufficient, as stated here .   Can this be explained by the fact that while both can describe the data adequately, $\max\{-X_{(1)},X_{(n)}\}$ is of lesser dimension and is thus minimal sufficient? Using the definition of minimal sufficiency ($T(X)$ is minimal sufficient if $T(x)=T(y) \iff \frac{\mathcal{L}(x;\theta)}{\mathcal{L}(y;\theta)}$ does not depend on $\theta$), I run into issues as with either choice of statistic, I need to analyze $$\frac{\mathbb{1}_{[\max\{-X_{(1)},X_{(n)}\}<\theta]}}{\mathbb{1}_{[\max\{-Y_{(1)},Y_{(n)}\}<\theta]}}$$ or $$\frac{\mathbb{1}_{[-\theta<X_{(1)}]}\mathbb{1}_{[X_{(n)}<\theta]}}{\mathbb{1}_{[-\theta<Y_{(1)}]}\mathbb{1}_{[Y_{(n)}<\theta]}}$$ which may be $\frac{0}{0}$.  Even when not $\frac{0}{0}$, I'm having trouble seeing why the former is not dependent on $\theta$, but the latter is dependent on $\theta$ if $T(X)=T(Y)$.","I am seeking clarification on why both the vector $(X_{(1)},X_{(n)})^T$ and $\max\{-X_{(1)},X_{(n)}\}$ are sufficient for $\operatorname{Unif}(-\theta,\theta)$, but only $\max\{-X_{(1)},X_{(n)}\}$ is minimal sufficient, as stated here .   Can this be explained by the fact that while both can describe the data adequately, $\max\{-X_{(1)},X_{(n)}\}$ is of lesser dimension and is thus minimal sufficient? Using the definition of minimal sufficiency ($T(X)$ is minimal sufficient if $T(x)=T(y) \iff \frac{\mathcal{L}(x;\theta)}{\mathcal{L}(y;\theta)}$ does not depend on $\theta$), I run into issues as with either choice of statistic, I need to analyze $$\frac{\mathbb{1}_{[\max\{-X_{(1)},X_{(n)}\}<\theta]}}{\mathbb{1}_{[\max\{-Y_{(1)},Y_{(n)}\}<\theta]}}$$ or $$\frac{\mathbb{1}_{[-\theta<X_{(1)}]}\mathbb{1}_{[X_{(n)}<\theta]}}{\mathbb{1}_{[-\theta<Y_{(1)}]}\mathbb{1}_{[Y_{(n)}<\theta]}}$$ which may be $\frac{0}{0}$.  Even when not $\frac{0}{0}$, I'm having trouble seeing why the former is not dependent on $\theta$, but the latter is dependent on $\theta$ if $T(X)=T(Y)$.",,"['probability', 'statistics']"
15,Probability of double matchings,Probability of double matchings,,"Yesterday, I solved this problem question from probability theory: Two similar decks of $N$ distinct cards are matched against a similar target deck. Find the probability of exactly $m \leq N$ matches. I proceeded in the following manner. Let $A_i$ denote the event that $i^{\text{th}}$ card is matched (from both the decks) against the target deck. Therefore, let $$P(\text{E = exactly $m$ match occurs})(N,m)$$ (don't mind the bad notation please) then $$P(N,m) = S_m - \binom{m+1}{m}S_{m+1} + \binom{m+2}{m}S_{m+2} + \ldots + \binom{N}{m} S_{N}$$ where $S_1 = \sum_{1\leq i \leq N} P(A_i)$, $S_2 = \sum_{1\leq i \lt j \leq N} P(A_i \cap A_j) \ldots$ Clearly, we have $$S_{m+k} = \binom{N}{m+k} \frac{(N-m-k)!^2}{N!^2}$$ Therefore,  \begin{align*} P(N,m) &= \sum_{k=0}^{N-m} (-1)^k \binom{m+k}{m} \binom{N}{m+k} \frac{(N-m-k)!^2}{N!^2} \\  &= \frac{1}{m!} \frac{1}{N!} \sum_{k=0}^{N-m} (-1)^k \frac{(N-m-k)!}{k!} \end{align*} After obtaining the above expression, I thought if there exists some nice closed formula for the series. So I plugged it on W|A but it doesn't returns one (in terms of elementary functions). Next, I started wondering, how does this probability function behaves as $N \rightarrow \infty$. Because this limit might be actual translation of some real world phenomena (although that is something to be considered about, later on). So, I first tried to check for $m=0$ \begin{align*} \lim_{N \rightarrow \infty} P(N,0) &= \lim_{N \rightarrow \infty} \frac{1}{N!} \sum_{k=0}^{N} (-1)^k \frac{(N-k)!}{k!} \\ &= \lim_{N \rightarrow \infty} \left(1 - \frac{1}{N} + \frac{1}{2!}\frac{1}{N(N-1)} - \ldots \right) \end{align*} It doesn't strikes me on how to solve this limit, as I cannot evaluate the limit pointwise since it is an infinite sum. So I thought of setting up a recurrence (which may help?). This is what I found: $$P(N+2,0) = P(N+1,0) + \frac{P(N,0)}{(N+1)(N+2)} + \frac{(-1)^{N}}{(N+2)!^2}$$ But again, I still couldn't figure out much. I even expressed this as an integral (just because sometimes, it does help) and then tried to do some manipulations, but still no clue $$P(N,0) = (N+1) \int_0^1 \sum_{k=0}^N\frac{ t^k(1-t)^{N-k}}{k!^2} \mathrm{d}t$$ So these are the questions, I am trying to find a solution to: Is there any nice closed form for the expression? How does the probability function, which I derived, behaves when $N \rightarrow \infty$ for a fixed $m$? What happens as $N \rightarrow \infty$ and $m \rightarrow \infty$? Any help would be appreciated. Edit 1 : I figured out that $P(N,0) \rightarrow 1$ as $n \rightarrow \infty$ with some computations but I guess, it still requires a rigorous proof.","Yesterday, I solved this problem question from probability theory: Two similar decks of $N$ distinct cards are matched against a similar target deck. Find the probability of exactly $m \leq N$ matches. I proceeded in the following manner. Let $A_i$ denote the event that $i^{\text{th}}$ card is matched (from both the decks) against the target deck. Therefore, let $$P(\text{E = exactly $m$ match occurs})(N,m)$$ (don't mind the bad notation please) then $$P(N,m) = S_m - \binom{m+1}{m}S_{m+1} + \binom{m+2}{m}S_{m+2} + \ldots + \binom{N}{m} S_{N}$$ where $S_1 = \sum_{1\leq i \leq N} P(A_i)$, $S_2 = \sum_{1\leq i \lt j \leq N} P(A_i \cap A_j) \ldots$ Clearly, we have $$S_{m+k} = \binom{N}{m+k} \frac{(N-m-k)!^2}{N!^2}$$ Therefore,  \begin{align*} P(N,m) &= \sum_{k=0}^{N-m} (-1)^k \binom{m+k}{m} \binom{N}{m+k} \frac{(N-m-k)!^2}{N!^2} \\  &= \frac{1}{m!} \frac{1}{N!} \sum_{k=0}^{N-m} (-1)^k \frac{(N-m-k)!}{k!} \end{align*} After obtaining the above expression, I thought if there exists some nice closed formula for the series. So I plugged it on W|A but it doesn't returns one (in terms of elementary functions). Next, I started wondering, how does this probability function behaves as $N \rightarrow \infty$. Because this limit might be actual translation of some real world phenomena (although that is something to be considered about, later on). So, I first tried to check for $m=0$ \begin{align*} \lim_{N \rightarrow \infty} P(N,0) &= \lim_{N \rightarrow \infty} \frac{1}{N!} \sum_{k=0}^{N} (-1)^k \frac{(N-k)!}{k!} \\ &= \lim_{N \rightarrow \infty} \left(1 - \frac{1}{N} + \frac{1}{2!}\frac{1}{N(N-1)} - \ldots \right) \end{align*} It doesn't strikes me on how to solve this limit, as I cannot evaluate the limit pointwise since it is an infinite sum. So I thought of setting up a recurrence (which may help?). This is what I found: $$P(N+2,0) = P(N+1,0) + \frac{P(N,0)}{(N+1)(N+2)} + \frac{(-1)^{N}}{(N+2)!^2}$$ But again, I still couldn't figure out much. I even expressed this as an integral (just because sometimes, it does help) and then tried to do some manipulations, but still no clue $$P(N,0) = (N+1) \int_0^1 \sum_{k=0}^N\frac{ t^k(1-t)^{N-k}}{k!^2} \mathrm{d}t$$ So these are the questions, I am trying to find a solution to: Is there any nice closed form for the expression? How does the probability function, which I derived, behaves when $N \rightarrow \infty$ for a fixed $m$? What happens as $N \rightarrow \infty$ and $m \rightarrow \infty$? Any help would be appreciated. Edit 1 : I figured out that $P(N,0) \rightarrow 1$ as $n \rightarrow \infty$ with some computations but I guess, it still requires a rigorous proof.",,"['probability', 'probability-theory', 'asymptotics']"
16,Why don't billionaires (or multi-millionaires for that matter) use the Martingale betting system?,Why don't billionaires (or multi-millionaires for that matter) use the Martingale betting system?,,"Here is the link to my simulation: (The data is based on using the Martingale betting system in European Roulette) https://docs.google.com/spreadsheets/d/1GH48faKeK5clonmYO6aySzchGeRhp7nx8Kc0cA0UFVA/edit?usp=sharing As you can see, there is a linear growth rate with a few dips here and there, but overall, it seems to be profitable. So back to my question, why don't rich people just make a simple program, hook it up to some online casino and make money?","Here is the link to my simulation: (The data is based on using the Martingale betting system in European Roulette) https://docs.google.com/spreadsheets/d/1GH48faKeK5clonmYO6aySzchGeRhp7nx8Kc0cA0UFVA/edit?usp=sharing As you can see, there is a linear growth rate with a few dips here and there, but overall, it seems to be profitable. So back to my question, why don't rich people just make a simple program, hook it up to some online casino and make money?",,"['probability', 'analysis', 'statistics', 'gambling']"
17,Binomial or Uniform Probability?,Binomial or Uniform Probability?,,"What is the probability of rolling exactly two sixes in $7$ rolls of a die? I know this is a binomial probability. $P(X=2)=\binom{7}{2}(1/6)^2(5/6)^5$. By the definition of probability formula ""Probability formula is the ratio of number of favorable outcomes to the total number of possible outcomes."" Then why probability of rolling exactly two sixes in $7$ rolls of a die isn't $=2/42$? The denominator is $42$ because in one die there are $6$ faces, and in $7$ rolls of a die, there are $7\times 6=42$ faces.","What is the probability of rolling exactly two sixes in $7$ rolls of a die? I know this is a binomial probability. $P(X=2)=\binom{7}{2}(1/6)^2(5/6)^5$. By the definition of probability formula ""Probability formula is the ratio of number of favorable outcomes to the total number of possible outcomes."" Then why probability of rolling exactly two sixes in $7$ rolls of a die isn't $=2/42$? The denominator is $42$ because in one die there are $6$ faces, and in $7$ rolls of a die, there are $7\times 6=42$ faces.",,['probability']
18,A fair coin is tossed repeatedly and independently until two consecutive heads or two consecutive tails appear? [duplicate],A fair coin is tossed repeatedly and independently until two consecutive heads or two consecutive tails appear? [duplicate],,"This question already has an answer here : Tossing a fair coin until two consecutive tosses are the same (1 answer) Closed 4 years ago . A fair coin is tossed repeatedly and independently until two consecutive heads or two consecutive tails appear . What is the probability of the number of tosses ? I tried it as : For success, either we end up getting HH,THH,HTHH,............ TT,HTT,THTT,............. Then, Add up both the successes. Am I right with my understanding ?","This question already has an answer here : Tossing a fair coin until two consecutive tosses are the same (1 answer) Closed 4 years ago . A fair coin is tossed repeatedly and independently until two consecutive heads or two consecutive tails appear . What is the probability of the number of tosses ? I tried it as : For success, either we end up getting HH,THH,HTHH,............ TT,HTT,THTT,............. Then, Add up both the successes. Am I right with my understanding ?",,"['probability', 'combinatorics', 'combinations']"
19,$\Pr[X > 0] \geq \frac{E[X]^2}{E[X^2]}$,,\Pr[X > 0] \geq \frac{E[X]^2}{E[X^2]},"Given $X$ is a finite non-negative discrete random variable that is not equal to identical zero. Prove that $$\Pr[X > 0] \geq \frac{E[X]^2}{E[X^2]}$$ My attempt: $$\Pr[X > 0] = \sum_{i = 1}^n\Pr[X = i]$$ $$E[X]^2 = \left(\sum_{i = 0}^n \Pr[X = i] \cdot i\right)^2$$ $$E[X^2] = \sum_{i = 0}^n \Pr[X = i]\cdot i^2$$ $$\Pr[X > 0] \cdot E[X^2] \geq E[X]^2 \iff \sum_{i = 1}^n\Pr[X = i] \cdot \sum_{i = 0}^n \Pr[X = i]\cdot i^2 \geq \left(\sum_{i = 0}^n \Pr[X = i] \cdot i\right)^2$$ $$\left( \Pr[X = 1] + \dotso +\Pr[X = n]\right)\cdot \left( \Pr[X = 0] \cdot 0 + \Pr[X = 1] \cdot 1^2+ \dotso + \Pr[X = n] \cdot n^2\right) \geq \left( \Pr[X = 0] \cdot 0 + \Pr[X = 1] \cdot  1 + \dotso \Pr[X = n] \cdot n\right)^2$$ Also notice that $\Pr[X = i] = \Pr[X  = j], \ i \neq j$, here I'm not sure about $\Pr[X = i] = \frac{1}{n}$ or $\Pr[X = i] = \frac{1}{n + 1}$, because of $0$ (intuitively it should be $\frac{1}{n + 1}$), but I think in this problem I don't need the exact value of $\Pr[X = i]$, so let $\forall i \ \Pr[X = i] = p$ $$n \cdot p (p + 4p + 9p + \dotso +n^2p ) \geq (p + 2p + \dotso + np)^2$$ What should I do next?","Given $X$ is a finite non-negative discrete random variable that is not equal to identical zero. Prove that $$\Pr[X > 0] \geq \frac{E[X]^2}{E[X^2]}$$ My attempt: $$\Pr[X > 0] = \sum_{i = 1}^n\Pr[X = i]$$ $$E[X]^2 = \left(\sum_{i = 0}^n \Pr[X = i] \cdot i\right)^2$$ $$E[X^2] = \sum_{i = 0}^n \Pr[X = i]\cdot i^2$$ $$\Pr[X > 0] \cdot E[X^2] \geq E[X]^2 \iff \sum_{i = 1}^n\Pr[X = i] \cdot \sum_{i = 0}^n \Pr[X = i]\cdot i^2 \geq \left(\sum_{i = 0}^n \Pr[X = i] \cdot i\right)^2$$ $$\left( \Pr[X = 1] + \dotso +\Pr[X = n]\right)\cdot \left( \Pr[X = 0] \cdot 0 + \Pr[X = 1] \cdot 1^2+ \dotso + \Pr[X = n] \cdot n^2\right) \geq \left( \Pr[X = 0] \cdot 0 + \Pr[X = 1] \cdot  1 + \dotso \Pr[X = n] \cdot n\right)^2$$ Also notice that $\Pr[X = i] = \Pr[X  = j], \ i \neq j$, here I'm not sure about $\Pr[X = i] = \frac{1}{n}$ or $\Pr[X = i] = \frac{1}{n + 1}$, because of $0$ (intuitively it should be $\frac{1}{n + 1}$), but I think in this problem I don't need the exact value of $\Pr[X = i]$, so let $\forall i \ \Pr[X = i] = p$ $$n \cdot p (p + 4p + 9p + \dotso +n^2p ) \geq (p + 2p + \dotso + np)^2$$ What should I do next?",,"['probability', 'discrete-mathematics', 'inequality', 'random-variables', 'expectation']"
20,Bayes rule with multiple tests,Bayes rule with multiple tests,,"Say you are given the following \begin{align*} P(cancer) &= 0.008,            & P(\neg cancer) &= 0.992\\ P(\oplus|cancer) &= 0.98,      & P(\ominus|cancer) &= 0.02\\ P(\oplus|\neg cancer) &= 0.03, & P(\ominus|\neg cancer) &= 0.97 \end{align*} and you test a patient to see if they have cancer or not and it returns positive. If the patient wants to be tested another time, and it once again returns positive, what happens to the probability that the patient has cancer after testing a second time?","Say you are given the following \begin{align*} P(cancer) &= 0.008,            & P(\neg cancer) &= 0.992\\ P(\oplus|cancer) &= 0.98,      & P(\ominus|cancer) &= 0.02\\ P(\oplus|\neg cancer) &= 0.03, & P(\ominus|\neg cancer) &= 0.97 \end{align*} and you test a patient to see if they have cancer or not and it returns positive. If the patient wants to be tested another time, and it once again returns positive, what happens to the probability that the patient has cancer after testing a second time?",,"['probability', 'bayes-theorem']"
21,Probability of an event in relationship with a certain geometrical representation,Probability of an event in relationship with a certain geometrical representation,,"A recent post ( https://math.stackexchange.com/q/1979286 ) asked the following question [in substance: I have slightly modified it]: ""What is the probability of the event $$\tag{1}\cos(\theta_1)+\cos(\theta_2)+\cos(\theta_2-\theta_1)+1 \leq 0 $$ given that $\theta_1$ and $\theta_2$ are independent, uniformly distributed random variables on $[0,2\pi)$""? I gave an answer relying on a geometrical interpretation. While elaborating this answer, at a certain step, I made an error, and replaced, in (1), the constant term $+1$ by $-1$. Surprisingly, the unfavorable regions of the square $[0,2\pi) \times [0,2\pi)$, appeared as the interiors of four truncated elliptical regions as displayed on the bottom figure  (obtained by Geogebra). My question is therefore twofold: 1) What is the probability of the event $$\tag{2}\cos(\theta_1)+\cos(\theta_2)+\cos(\theta_2-\theta_1)-1 \leq 0 ? $$ with $\theta_1$ and $\theta_2$ independent, uniformly distributed random variables on $[0,2\pi)$? 2) Why are these frontier curves elliptical, with puzzling equation for the ""mother""-ellipse centered in $0$: $$(\theta_1)^2+(\theta_2)^2-\theta_1\theta_2=\left(\frac{\pi}{2}\right)^2 \ \ ?$$ the other ones being translated from this one. Remark about question 1: this probability  can hopefully be obtained using a different (non geometrical) approach.","A recent post ( https://math.stackexchange.com/q/1979286 ) asked the following question [in substance: I have slightly modified it]: ""What is the probability of the event $$\tag{1}\cos(\theta_1)+\cos(\theta_2)+\cos(\theta_2-\theta_1)+1 \leq 0 $$ given that $\theta_1$ and $\theta_2$ are independent, uniformly distributed random variables on $[0,2\pi)$""? I gave an answer relying on a geometrical interpretation. While elaborating this answer, at a certain step, I made an error, and replaced, in (1), the constant term $+1$ by $-1$. Surprisingly, the unfavorable regions of the square $[0,2\pi) \times [0,2\pi)$, appeared as the interiors of four truncated elliptical regions as displayed on the bottom figure  (obtained by Geogebra). My question is therefore twofold: 1) What is the probability of the event $$\tag{2}\cos(\theta_1)+\cos(\theta_2)+\cos(\theta_2-\theta_1)-1 \leq 0 ? $$ with $\theta_1$ and $\theta_2$ independent, uniformly distributed random variables on $[0,2\pi)$? 2) Why are these frontier curves elliptical, with puzzling equation for the ""mother""-ellipse centered in $0$: $$(\theta_1)^2+(\theta_2)^2-\theta_1\theta_2=\left(\frac{\pi}{2}\right)^2 \ \ ?$$ the other ones being translated from this one. Remark about question 1: this probability  can hopefully be obtained using a different (non geometrical) approach.",,"['probability', 'trigonometry', 'geometric-probability']"
22,Random Walk on graph with five vertices,Random Walk on graph with five vertices,,"Consider a random walk on the following graph: The random walk starts from the vertex $V_1$ and moves to one neighbouring vertex (each is reached with the same probability) in the next step. For example $P(V_2 \to V_5) = 1/3$ and $P(V_3 \to V_4)=1/4$. I want to calculate the following probabilities: $P$(the random walk returns to $V_1$ after exactly $3$ steps) $P$(the random walk returns to $V_1$ after exactly $4$ steps) $P$(the random walk returns to $V_1$ before it reaches $V_5$) What is the average number of steps until the random walk reaches $V_5$? The first two questions are straight forward, I got $1/9$ and $13/162$. For the last question I had do solve a linear system and got $16/3$ as solution. I would appreciate it if anybody could tell me if my calculations are right and can help me with the third question.","Consider a random walk on the following graph: The random walk starts from the vertex $V_1$ and moves to one neighbouring vertex (each is reached with the same probability) in the next step. For example $P(V_2 \to V_5) = 1/3$ and $P(V_3 \to V_4)=1/4$. I want to calculate the following probabilities: $P$(the random walk returns to $V_1$ after exactly $3$ steps) $P$(the random walk returns to $V_1$ after exactly $4$ steps) $P$(the random walk returns to $V_1$ before it reaches $V_5$) What is the average number of steps until the random walk reaches $V_5$? The first two questions are straight forward, I got $1/9$ and $13/162$. For the last question I had do solve a linear system and got $16/3$ as solution. I would appreciate it if anybody could tell me if my calculations are right and can help me with the third question.",,"['probability', 'probability-theory', 'graph-theory', 'random-walk', 'random-graphs']"
23,How many ways can multiple artworks be displayed? [closed],How many ways can multiple artworks be displayed? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question There are 6 landscapes, 5 portraits, and 7 still lifes available for an art display. Two of each type of painting are selected. The paintings are each hung in one of six locations in the gallery. In how many ways could the art be displayed?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question There are 6 landscapes, 5 portraits, and 7 still lifes available for an art display. Two of each type of painting are selected. The paintings are each hung in one of six locations in the gallery. In how many ways could the art be displayed?",,"['probability', 'permutations', 'combinations', 'factorial', 'order-statistics']"
24,"Rock, Paper, Scissors Probability For Multiple Players","Rock, Paper, Scissors Probability For Multiple Players",,"Let the number of players for a game of rock, paper, scissors be $n$. In each round of the game, each player chooses one of rock, paper, or scissors. Then, if exactly two of the three options have been chosen, the players who chose the losing option among those two are eliminated. (For example, if everybody chooses either rock or paper, those choosing rock are eliminated.) Otherwise, everyone stays in the game. The game continues until all but one player has been eliminated. How would you work out the probability that a winner is determined after $k$ rounds? (Assuming each choice is equally as likely)","Let the number of players for a game of rock, paper, scissors be $n$. In each round of the game, each player chooses one of rock, paper, or scissors. Then, if exactly two of the three options have been chosen, the players who chose the losing option among those two are eliminated. (For example, if everybody chooses either rock or paper, those choosing rock are eliminated.) Otherwise, everyone stays in the game. The game continues until all but one player has been eliminated. How would you work out the probability that a winner is determined after $k$ rounds? (Assuming each choice is equally as likely)",,"['probability', 'recreational-mathematics']"
25,Markov Chain Help,Markov Chain Help,,"I'm very far removed from Linear Algebra or statistics that I honestly do not remember Markov Chains. I'm trying to figure out this problem.  Hopefully someone can tell me how to complete this.  Excuse my lack to proper formatting with this question. How is s3 even solved?  I thought a Markov Chain rows has to be equal to 1.  Is this even a Markov Chain Question? Write a function answer(m) that takes an array of array of nonnegative ints representing how many times that state has gone to the    next state and return an array of ints for each terminal state giving the exact probabilities of each terminal state, represented    as the numerator for each state, then the denominator for all of them at the end and in simplest form. The matrix is at most 10 by    10. It is guaranteed that no matter which state the ore is in, there is a path from that state to a terminal state. That is, the    processing will always eventually end in a stable state. The ore starts in state 0. The denominator will fit within a signed    32-bit integer during the calculation, as long as the fraction is simplified regularly. For example, consider the matrix m: [ [0,1,0,0,0,1],  # s0, the initial state, goes to s1 and s5 with equal probability [4,0,0,3,2,0],  # s1 can become s0, s3, or s4, but with different probabilities [0,0,0,0,0,0],  # s2 is terminal, and unreachable (never observed in practice) [0,0,0,0,0,0],  # s3 is terminal [0,0,0,0,0,0],  # s4 is terminal [0,0,0,0,0,0],  # s5 is terminal ] So, we can consider different paths to terminal states, such as: s0 -> s1 -> s3 s0 -> s1 -> s0 -> s1 -> s0 -> s1 -> s4 s0 -> s1 -> s0 -> s5 Tracing the probabilities of each, we find that s2 has probability 0 s3 has probability 3/14 s4 has probability 1/7 s5 has probability 9/14","I'm very far removed from Linear Algebra or statistics that I honestly do not remember Markov Chains. I'm trying to figure out this problem.  Hopefully someone can tell me how to complete this.  Excuse my lack to proper formatting with this question. How is s3 even solved?  I thought a Markov Chain rows has to be equal to 1.  Is this even a Markov Chain Question? Write a function answer(m) that takes an array of array of nonnegative ints representing how many times that state has gone to the    next state and return an array of ints for each terminal state giving the exact probabilities of each terminal state, represented    as the numerator for each state, then the denominator for all of them at the end and in simplest form. The matrix is at most 10 by    10. It is guaranteed that no matter which state the ore is in, there is a path from that state to a terminal state. That is, the    processing will always eventually end in a stable state. The ore starts in state 0. The denominator will fit within a signed    32-bit integer during the calculation, as long as the fraction is simplified regularly. For example, consider the matrix m: [ [0,1,0,0,0,1],  # s0, the initial state, goes to s1 and s5 with equal probability [4,0,0,3,2,0],  # s1 can become s0, s3, or s4, but with different probabilities [0,0,0,0,0,0],  # s2 is terminal, and unreachable (never observed in practice) [0,0,0,0,0,0],  # s3 is terminal [0,0,0,0,0,0],  # s4 is terminal [0,0,0,0,0,0],  # s5 is terminal ] So, we can consider different paths to terminal states, such as: s0 -> s1 -> s3 s0 -> s1 -> s0 -> s1 -> s0 -> s1 -> s4 s0 -> s1 -> s0 -> s5 Tracing the probabilities of each, we find that s2 has probability 0 s3 has probability 3/14 s4 has probability 1/7 s5 has probability 9/14",,"['probability', 'markov-chains']"
26,Probability - reduced sample space,Probability - reduced sample space,,"In a bridge game, 52 cards are dealt equally to players E, W, N, S. If N and S have a total of 8 spades among them, what is the probability that E has 3 of the remaining 5 spades? And the answer is: $$\frac{(^5C_3)(^{21}C_{10})}{^{26}C_{13}}=0.339$$ Reasoning goes: Choose 3 spades for E (first term in numerator) Choose the other 10 cards out of the 21 cards (second term in numerator) Denominator: choose 13 out of 26 cards for E. And so my question is: what is the reduced sample space here actually? Why is it 26 cards as the sample space for both numerator and the denominator? Why not 52 cards (i.e. all four players)?","In a bridge game, 52 cards are dealt equally to players E, W, N, S. If N and S have a total of 8 spades among them, what is the probability that E has 3 of the remaining 5 spades? And the answer is: Reasoning goes: Choose 3 spades for E (first term in numerator) Choose the other 10 cards out of the 21 cards (second term in numerator) Denominator: choose 13 out of 26 cards for E. And so my question is: what is the reduced sample space here actually? Why is it 26 cards as the sample space for both numerator and the denominator? Why not 52 cards (i.e. all four players)?",\frac{(^5C_3)(^{21}C_{10})}{^{26}C_{13}}=0.339,"['probability', 'permutations', 'combinations']"
27,Measure of distance between two gaussian distributions,Measure of distance between two gaussian distributions,,"let' say I have two different phenomena classes, and I extract two different kinds of values for each of them. For example, comparing two different leaves, I extract length and weight of several hundreds of instances. From this experimental observation values, I calculate the mean and standard derivation, and assume they follow a normal distribution, so: $L_{1}\sim\mathcal N(\mu_{11},\sigma_{11})$ Length distribution for first class of leaf $W_{1}\sim\mathcal N(\mu_{21},\sigma_{22})$ Weight distribution for first class of leaf $L_{2}\sim\mathcal N(\mu_{31},\sigma_{32})$ Length distribution for second class of leaf $W_{2}\sim\mathcal N(\mu_{41},\sigma_{42})$ Weight distribution for second class of leaf I want to take the characteristic that better distinguishes between both classes, so I need some kind of measurement of distance between $L_{1},L_{2}$ and $W_{1},W_{2}$, to take the one with longest distance. Which mathematical notion helps me here?","let' say I have two different phenomena classes, and I extract two different kinds of values for each of them. For example, comparing two different leaves, I extract length and weight of several hundreds of instances. From this experimental observation values, I calculate the mean and standard derivation, and assume they follow a normal distribution, so: $L_{1}\sim\mathcal N(\mu_{11},\sigma_{11})$ Length distribution for first class of leaf $W_{1}\sim\mathcal N(\mu_{21},\sigma_{22})$ Weight distribution for first class of leaf $L_{2}\sim\mathcal N(\mu_{31},\sigma_{32})$ Length distribution for second class of leaf $W_{2}\sim\mathcal N(\mu_{41},\sigma_{42})$ Weight distribution for second class of leaf I want to take the characteristic that better distinguishes between both classes, so I need some kind of measurement of distance between $L_{1},L_{2}$ and $W_{1},W_{2}$, to take the one with longest distance. Which mathematical notion helps me here?",,"['probability', 'statistics', 'pattern-recognition']"
28,"Probability of 20 heads without getting 2 tails in a row, versus 10 heads without getting 1 tail","Probability of 20 heads without getting 2 tails in a row, versus 10 heads without getting 1 tail",,Are the odds of flipping a coin and getting 20 heads without getting 2 tails in a row the same as flipping a coin and getting 10 heads without getting 1 tail?,Are the odds of flipping a coin and getting 20 heads without getting 2 tails in a row the same as flipping a coin and getting 10 heads without getting 1 tail?,,['probability']
29,Intuition of the Mean wait time in queuing system,Intuition of the Mean wait time in queuing system,,"In queuing theory, (with a single queue and a single server) writing $A$ for the service rate (of customers) and $B$ for the arrival rate (of customers) we know that the average time a customer waits in the system is given by, $$W=\frac{1}{A-B}$$ What is the intuitive interpretation of this equation? What I understand from basic intuition is that $A$ customers gets service in 1 sec (as $A$ is the service rate) so, one customer should get service in $1/A$ seconds. Now, $B$ means, $B$ customers comes in 1 second (the arrival might be bursty or not depending on the probability distribution). So, $(A-B)$ is , how many more customers can the server serve per second, right? So, why is the waiting time $W=1/(A-B)$? How can I understand this relationship intuitively?","In queuing theory, (with a single queue and a single server) writing $A$ for the service rate (of customers) and $B$ for the arrival rate (of customers) we know that the average time a customer waits in the system is given by, $$W=\frac{1}{A-B}$$ What is the intuitive interpretation of this equation? What I understand from basic intuition is that $A$ customers gets service in 1 sec (as $A$ is the service rate) so, one customer should get service in $1/A$ seconds. Now, $B$ means, $B$ customers comes in 1 second (the arrival might be bursty or not depending on the probability distribution). So, $(A-B)$ is , how many more customers can the server serve per second, right? So, why is the waiting time $W=1/(A-B)$? How can I understand this relationship intuitively?",,"['probability', 'probability-theory', 'probability-distributions', 'queueing-theory']"
30,Is the Fermat primality test secure enough for very big numbers?,Is the Fermat primality test secure enough for very big numbers?,,"The random variable $X_m$ is the number of trials before $n\notin\mathbb P\wedge n\mid 2^{n-1}-1$ where $n$ is an odd random integer  $2^{m-1} < n < 2^m$. Computer simulations makes me believe that $\text E[\log X_m]=\frac{m}{6}$ and that $\operatorname{Var}[\log X_m]<1$. I'm looking for some kind of proof of this conjecture and would like to know how to compute or estimate $P(X_{1000}=1)$, given that the conjecture is true. The context is: how secure is the Fermat primality test with base $2$ on numbers with $1000$ binary bits? Compared with the probability of hardware errors? Well, perhaps the 10 in the logarithm doesn't flag for an exact $\frac{m}{6}$. The regression line is $\log N= 0.1666\cdot m+0.006$ which is interpreted as $N=10^{\frac{m}{6}}$ but might also be interpreted as $N=\pi^{\frac{m}{3}}$ within the marginals. $\overset{..}{\smile}$ $3251$ simulations total so far. Some lower experiments $(m=10)$ has been removed, since lower intervalls gives more irregular results. In some intervalls there are no discrepancies. Also long time running results from $m=40$ is included, so the equation of the line of regression has changed a little. Diagram of the mean values of each m","The random variable $X_m$ is the number of trials before $n\notin\mathbb P\wedge n\mid 2^{n-1}-1$ where $n$ is an odd random integer  $2^{m-1} < n < 2^m$. Computer simulations makes me believe that $\text E[\log X_m]=\frac{m}{6}$ and that $\operatorname{Var}[\log X_m]<1$. I'm looking for some kind of proof of this conjecture and would like to know how to compute or estimate $P(X_{1000}=1)$, given that the conjecture is true. The context is: how secure is the Fermat primality test with base $2$ on numbers with $1000$ binary bits? Compared with the probability of hardware errors? Well, perhaps the 10 in the logarithm doesn't flag for an exact $\frac{m}{6}$. The regression line is $\log N= 0.1666\cdot m+0.006$ which is interpreted as $N=10^{\frac{m}{6}}$ but might also be interpreted as $N=\pi^{\frac{m}{3}}$ within the marginals. $\overset{..}{\smile}$ $3251$ simulations total so far. Some lower experiments $(m=10)$ has been removed, since lower intervalls gives more irregular results. In some intervalls there are no discrepancies. Also long time running results from $m=40$ is included, so the equation of the line of regression has changed a little. Diagram of the mean values of each m",,"['probability', 'algorithms', 'prime-numbers', 'conjectures', 'primality-test']"
31,Calculating the probability of an event giving the union and complement,Calculating the probability of an event giving the union and complement,,"There are two independent events. The probability that both occurs at the same time is $\frac{1}{6}$ and the probability that none of them happens is $\frac{2}{3}$. What is the probability that only one of them occurs? I'm trying to solve it but I cannot find a way to solve it to just one event. Here's what I did: We know that $P(A\cap B) = \frac{1}{6}$ and $[1 - P(A)] \cdot [1 - P(B)] = \frac{2}{3}$ So, $$[1 - P(A)] \cdot [1 - P(B)] = \frac{2}{3} $$ $$1 - P(A) - P(B) + P(A) \cdot P(B) = \frac{2}{3}$$ $$ 1 - P(A) - P(B) +  \frac{1}{6}= \frac{2}{3}$$ As can be seen, I cannot can solve for just $P(A)$ or just $P(B)$. Can someone give me a hint what a I'm doing wrong? I already know that the answer for this question is $\frac{1}{6}$","There are two independent events. The probability that both occurs at the same time is $\frac{1}{6}$ and the probability that none of them happens is $\frac{2}{3}$. What is the probability that only one of them occurs? I'm trying to solve it but I cannot find a way to solve it to just one event. Here's what I did: We know that $P(A\cap B) = \frac{1}{6}$ and $[1 - P(A)] \cdot [1 - P(B)] = \frac{2}{3}$ So, $$[1 - P(A)] \cdot [1 - P(B)] = \frac{2}{3} $$ $$1 - P(A) - P(B) + P(A) \cdot P(B) = \frac{2}{3}$$ $$ 1 - P(A) - P(B) +  \frac{1}{6}= \frac{2}{3}$$ As can be seen, I cannot can solve for just $P(A)$ or just $P(B)$. Can someone give me a hint what a I'm doing wrong? I already know that the answer for this question is $\frac{1}{6}$",,['probability']
32,Expected value of the Max of three exponential random variables,Expected value of the Max of three exponential random variables,,"So the question asks: Let $X_1,X_2,X_3\sim \operatorname{Exp}(\lambda)$ be independent (exponential) random variables (with $\lambda> 0$). (a) Find the probability density function of the random variable $Z = \max \{X_1,X_2,X_3\}$. (b) Let $T = X_1+X_2/2+X_3/3$, use moment generating functions to prove $Z\sim T$ (same distribution). Find $E[Z]$ and $\operatorname{Var}[Z]$. So far I got: (a)$F(x) = 1-e^{-\lambda x}$ $F_Z(z) = P (Z \leq z) = P(\max(X_1,X_2,X_3) ≤ z) = P(X_1\leq z, X_2 \leq z, X_3 \leq z)= P(X_1\leq z)P(X_2\leq z) P(X_3\leq z) = (1-e^{-\lambda z})^3$ $f_Z(z) = F_Z'(z) = (1-e^{-\lambda z})^3 =3\lambda e^{-3\lambda z}(e^{\lambda z}-1)^2$ (b) for this part, I did not quite understand what it wanted me to prove actually... I got: $M_X(t) = λ/(λ-t )$ $M_Z(t) = M_{X_1}(t)M_{X_2}(t) M_{X_3}(t) = [\lambda/(\lambda-t )]  [\lambda /(2(\lambda-t) ]  [\lambda /(3(\lambda-t) ]=  [\lambda/(\lambda-t)]^3/6$ So what does it mean by  proving $Z\sim T$ (same distribution) ? And for the $E[Z]$ and $\text{Var} [Z]$, I actually tried to do it using the standard method which is $$ E[Z]=\int z\cdot3\lambda e^{-3\lambda z}(e^{\lambda z}-1)^2dz $$ which becomes super complicated... So is there a simple way to calculate the $E[Z]$ and $\text{Var} [Z]$ without literally solving the integration?","So the question asks: Let $X_1,X_2,X_3\sim \operatorname{Exp}(\lambda)$ be independent (exponential) random variables (with $\lambda> 0$). (a) Find the probability density function of the random variable $Z = \max \{X_1,X_2,X_3\}$. (b) Let $T = X_1+X_2/2+X_3/3$, use moment generating functions to prove $Z\sim T$ (same distribution). Find $E[Z]$ and $\operatorname{Var}[Z]$. So far I got: (a)$F(x) = 1-e^{-\lambda x}$ $F_Z(z) = P (Z \leq z) = P(\max(X_1,X_2,X_3) ≤ z) = P(X_1\leq z, X_2 \leq z, X_3 \leq z)= P(X_1\leq z)P(X_2\leq z) P(X_3\leq z) = (1-e^{-\lambda z})^3$ $f_Z(z) = F_Z'(z) = (1-e^{-\lambda z})^3 =3\lambda e^{-3\lambda z}(e^{\lambda z}-1)^2$ (b) for this part, I did not quite understand what it wanted me to prove actually... I got: $M_X(t) = λ/(λ-t )$ $M_Z(t) = M_{X_1}(t)M_{X_2}(t) M_{X_3}(t) = [\lambda/(\lambda-t )]  [\lambda /(2(\lambda-t) ]  [\lambda /(3(\lambda-t) ]=  [\lambda/(\lambda-t)]^3/6$ So what does it mean by  proving $Z\sim T$ (same distribution) ? And for the $E[Z]$ and $\text{Var} [Z]$, I actually tried to do it using the standard method which is $$ E[Z]=\int z\cdot3\lambda e^{-3\lambda z}(e^{\lambda z}-1)^2dz $$ which becomes super complicated... So is there a simple way to calculate the $E[Z]$ and $\text{Var} [Z]$ without literally solving the integration?",,"['probability', 'integration', 'probability-distributions', 'moment-generating-functions']"
33,Probability of Normal Distribution with Unknown Mean,Probability of Normal Distribution with Unknown Mean,,"I am still quite new to the whole idea of probability and statistics and am not sure how to do this question. The random variable R, also normally distributed, has a standard deviation of 3.59 with unknown mean is unknown. Find the greatest possible value of $P(-3.74<R<5.82)$. I tried to integrate the normal distribution function using Maclaurin's expansion but it just got very messy and I'm sure there is a better way of doing it.","I am still quite new to the whole idea of probability and statistics and am not sure how to do this question. The random variable R, also normally distributed, has a standard deviation of 3.59 with unknown mean is unknown. Find the greatest possible value of $P(-3.74<R<5.82)$. I tried to integrate the normal distribution function using Maclaurin's expansion but it just got very messy and I'm sure there is a better way of doing it.",,"['probability', 'statistics', 'normal-distribution']"
34,"If a fair six-sided die is rolled four times, in how many outcomes is the value of each roll at least as large as the value of the previous roll?","If a fair six-sided die is rolled four times, in how many outcomes is the value of each roll at least as large as the value of the previous roll?",,"Suppose you roll a fair 6-sided die four times. Let C be the event that the value of each roll is at least as large as the value of the previous roll. What is the probability of C? I know that $$\omega = 6^4 = 1296$$ I also know that to get P(C),  I need to divide C by $\omega$ But what is the fastest/simpler way to get C? I could write all the sets that would qualify but that would A: be time consuming. B: error prone. Is there a formula to find C in this case?","Suppose you roll a fair 6-sided die four times. Let C be the event that the value of each roll is at least as large as the value of the previous roll. What is the probability of C? I know that $$\omega = 6^4 = 1296$$ I also know that to get P(C),  I need to divide C by $\omega$ But what is the fastest/simpler way to get C? I could write all the sets that would qualify but that would A: be time consuming. B: error prone. Is there a formula to find C in this case?",,['probability']
35,How does one find the density of the $k$th ordered statistic?,How does one find the density of the th ordered statistic?,k,"Let $X_1,\ldots,X_n$ be $n$ iid random variables. Suppose they are arranged in increasing order  $$X_{(1)}\leq\cdots\leq X_{(n)}$$ The first ordered statistic is always the minimum of the sample $$Y_1 \equiv X_{(1)}=\min\{\,X_1,\ldots,X_n\,\}$$ For a sample of size $n$, the $n$th order statistic is the maximum, that is, $$Y_n \equiv X_{(n)}=\max\{\,X_1,\ldots,X_n\,\}$$ According to Wolfram Mathworld ( here ), if $X$ has a probability density function $f(x)$ and cumulative distribution function $F(x)$, then the probability $Y_r$ is given $$f_{Y_r} = \frac{N!}{(r-1)!(N-r)!} [F(x)]^{r-1} [1-F(x)]^{N-r}f(x)$$ My Questions Is an ordered statistic merely the ordering of a collection of random variables from highest to lowest? But I thought a random variable was a collection of values (e.g. $\lbrace 1,2,3,4,5,6 \rbrace$), so how can we rank them? How do I derive that formula for $f_{Y_r}$? I googled it several times and I don't get how I found a would be derivation here I think on slide 4, but I don't follow what's going on.","Let $X_1,\ldots,X_n$ be $n$ iid random variables. Suppose they are arranged in increasing order  $$X_{(1)}\leq\cdots\leq X_{(n)}$$ The first ordered statistic is always the minimum of the sample $$Y_1 \equiv X_{(1)}=\min\{\,X_1,\ldots,X_n\,\}$$ For a sample of size $n$, the $n$th order statistic is the maximum, that is, $$Y_n \equiv X_{(n)}=\max\{\,X_1,\ldots,X_n\,\}$$ According to Wolfram Mathworld ( here ), if $X$ has a probability density function $f(x)$ and cumulative distribution function $F(x)$, then the probability $Y_r$ is given $$f_{Y_r} = \frac{N!}{(r-1)!(N-r)!} [F(x)]^{r-1} [1-F(x)]^{N-r}f(x)$$ My Questions Is an ordered statistic merely the ordering of a collection of random variables from highest to lowest? But I thought a random variable was a collection of values (e.g. $\lbrace 1,2,3,4,5,6 \rbrace$), so how can we rank them? How do I derive that formula for $f_{Y_r}$? I googled it several times and I don't get how I found a would be derivation here I think on slide 4, but I don't follow what's going on.",,"['probability', 'statistics']"
36,Probability of winning a game between players A and B?,Probability of winning a game between players A and B?,,"The following problem is from A First Course in Probability by Sheldon Ross, and it was assigned as homework by my professor. I was wondering if you guys could help me find a answer to the problem. $A$ and $B$ flip coins. $A$ starts and continues flipping until a tails occurs, at which point $B$ starts flipping and continues until there is a tail. Then $A$ takes over, and so on. Let $P_1$ be the probability of the coin's landing on heads when $A$ flips and $P_2$ when $B$ flips. The winner of the game is the first one to get a total of two heads. What is the probability that $A$ wins? What is the probability that $A$ wins if the winner of the game is the first one to get a total of three heads?","The following problem is from A First Course in Probability by Sheldon Ross, and it was assigned as homework by my professor. I was wondering if you guys could help me find a answer to the problem. $A$ and $B$ flip coins. $A$ starts and continues flipping until a tails occurs, at which point $B$ starts flipping and continues until there is a tail. Then $A$ takes over, and so on. Let $P_1$ be the probability of the coin's landing on heads when $A$ flips and $P_2$ when $B$ flips. The winner of the game is the first one to get a total of two heads. What is the probability that $A$ wins? What is the probability that $A$ wins if the winner of the game is the first one to get a total of three heads?",,['probability']
37,"Let $Z \sim Z(0, 1)$ be a standard normal random variable. Find the PDF of $|Z|$.",Let  be a standard normal random variable. Find the PDF of .,"Z \sim Z(0, 1) |Z|","Let $Z \sim Z(0, 1)$ be a standard normal random variable. Find   the PDF of $|Z|$. My approach: I let $Y = |Z|$, found the CDF and then took the first derivative to get the PDF. For $0 \leq y \leq 1$, the CDF is given by: $$F_Y(y) = P(Y \leq y)$$ $$= P(-y \leq Z \leq y)$$ $$= F_Z(y) - F_Z(-y) \tag{$*$}$$ Hence the PDF is given by, $$f_Y(y) = \frac{d}{dy}(F_Y(y))$$ $$= \frac{d}{dy}(F_Z(y) - F_Z(-y)) \; \text{by }(*)$$ $$= \frac{d}{dy}(F_Z(y)) - (\frac{d}{dy}F_Z(-y))$$ $$=1\cdot f_Z(y)-(-1\cdot f_Z(-y))$$ $$=f_Z(y)+f_Z(-y))$$ The PDF of a standard normal distribution is given by $f_X(x) = \frac{1}{\sqrt{2\pi}} e^\frac{-x^2}{2}$ so we have, $$=\frac{1}{\sqrt{2\pi}} e^\frac{-y^2}{2}+\frac{1}{\sqrt{2\pi}} e^\frac{y^2}{2}$$ I am not too sure if this is the correct answer and approach to this question so any help would be really appreciated.","Let $Z \sim Z(0, 1)$ be a standard normal random variable. Find   the PDF of $|Z|$. My approach: I let $Y = |Z|$, found the CDF and then took the first derivative to get the PDF. For $0 \leq y \leq 1$, the CDF is given by: $$F_Y(y) = P(Y \leq y)$$ $$= P(-y \leq Z \leq y)$$ $$= F_Z(y) - F_Z(-y) \tag{$*$}$$ Hence the PDF is given by, $$f_Y(y) = \frac{d}{dy}(F_Y(y))$$ $$= \frac{d}{dy}(F_Z(y) - F_Z(-y)) \; \text{by }(*)$$ $$= \frac{d}{dy}(F_Z(y)) - (\frac{d}{dy}F_Z(-y))$$ $$=1\cdot f_Z(y)-(-1\cdot f_Z(-y))$$ $$=f_Z(y)+f_Z(-y))$$ The PDF of a standard normal distribution is given by $f_X(x) = \frac{1}{\sqrt{2\pi}} e^\frac{-x^2}{2}$ so we have, $$=\frac{1}{\sqrt{2\pi}} e^\frac{-y^2}{2}+\frac{1}{\sqrt{2\pi}} e^\frac{y^2}{2}$$ I am not too sure if this is the correct answer and approach to this question so any help would be really appreciated.",,"['probability', 'probability-distributions', 'proof-verification']"
38,probability calculation for bayesian network,probability calculation for bayesian network,,"I am studying Bayesian belief networks and in that I am struggling to understand how probabilities are calculated.  I found this article here and the network is this: The associated probabilities are: I don't understand how the probability P(Tampering=true|Report=T) is calculated. How I did it was P(Alarm=T|Tampering=T,Fire=T)*P(Leaving=T|Alarm=T)*P(Report=T|Leaving=T)*P(Tampering=T)+ P(Alarm=T|Tampering=T,Fire=F)*P(Leaving=T|Alarm=T)*P(Report=T|Leaving=T)*P(Tampering=T)+ P(Alarm=F|Tampering=T,Fire=T)*P(Leaving=T|Alarm=F)*P(Report=T|Leaving=T)*P(Tampering=T)+   P(Alarm=F|Tampering=T,Fire=F)*P(Leaving=T|Alarm=F)*P(Report=T|Leaving=T)*P(Tampering=T)+ P(Alarm=T|Tampering=T,Fire=T)*P(Leaving=F|Alarm=T)*P(Report=T|Leaving=F)*P(Tampering=T)+ P(Alarm=T|Tampering=T,Fire=F)*P(Leaving=F|Alarm=T)*P(Report=T|Leaving=F)*P(Tampering=T)+ P(Alarm=F|Tampering=T,Fire=T)*P(Leaving=F|Alarm=F)*P(Report=T|Leaving=F)*P(Tampering=T)+ P(Alarm=F|Tampering=T,Fire=F)*P(Leaving=F|Alarm=F)*P(Report=T|Leaving=F)*P(Tampering=T) which gives me a value= 0.017989 But the given answer for P(tampering=T|report=T) = 0.399 How do I calculate this probability","I am studying Bayesian belief networks and in that I am struggling to understand how probabilities are calculated.  I found this article here and the network is this: The associated probabilities are: I don't understand how the probability P(Tampering=true|Report=T) is calculated. How I did it was P(Alarm=T|Tampering=T,Fire=T)*P(Leaving=T|Alarm=T)*P(Report=T|Leaving=T)*P(Tampering=T)+ P(Alarm=T|Tampering=T,Fire=F)*P(Leaving=T|Alarm=T)*P(Report=T|Leaving=T)*P(Tampering=T)+ P(Alarm=F|Tampering=T,Fire=T)*P(Leaving=T|Alarm=F)*P(Report=T|Leaving=T)*P(Tampering=T)+   P(Alarm=F|Tampering=T,Fire=F)*P(Leaving=T|Alarm=F)*P(Report=T|Leaving=T)*P(Tampering=T)+ P(Alarm=T|Tampering=T,Fire=T)*P(Leaving=F|Alarm=T)*P(Report=T|Leaving=F)*P(Tampering=T)+ P(Alarm=T|Tampering=T,Fire=F)*P(Leaving=F|Alarm=T)*P(Report=T|Leaving=F)*P(Tampering=T)+ P(Alarm=F|Tampering=T,Fire=T)*P(Leaving=F|Alarm=F)*P(Report=T|Leaving=F)*P(Tampering=T)+ P(Alarm=F|Tampering=T,Fire=F)*P(Leaving=F|Alarm=F)*P(Report=T|Leaving=F)*P(Tampering=T) which gives me a value= 0.017989 But the given answer for P(tampering=T|report=T) = 0.399 How do I calculate this probability",,"['probability', 'statistics', 'bayesian-network']"
39,Probability of $ \sum_{n=1}^\infty \frac{x_n}{2^n} \leq p$ for Bernoulli sequence,Probability of  for Bernoulli sequence, \sum_{n=1}^\infty \frac{x_n}{2^n} \leq p,"Probability of $ \sum_{n=1}^\infty \frac{x_n}{2^n} \leq p$  for a  Bernoulli(1/2) sequence $(x_n)$ and $p \in [0,1]$. I know that the answer should be just $p$ but how can you prove it? Say for $p= 1/2$ I can look at it as 1-( Probability of being greater than 1/2) which is 1/2 since if our first term in the sequence is 1 then we're done. But how one shows for general $p$?","Probability of $ \sum_{n=1}^\infty \frac{x_n}{2^n} \leq p$  for a  Bernoulli(1/2) sequence $(x_n)$ and $p \in [0,1]$. I know that the answer should be just $p$ but how can you prove it? Say for $p= 1/2$ I can look at it as 1-( Probability of being greater than 1/2) which is 1/2 since if our first term in the sequence is 1 then we're done. But how one shows for general $p$?",,"['probability', 'probability-theory']"
40,How can I convert this percentage into odds?,How can I convert this percentage into odds?,,"How can I convert the percentage 0.000007151123842% into odds, so the outcome would be 1 in 13983816. Basically, I am looking for a way to convert any positive percentage into odds so the outcome gives me 1 in N.","How can I convert the percentage 0.000007151123842% into odds, so the outcome would be 1 in 13983816. Basically, I am looking for a way to convert any positive percentage into odds so the outcome gives me 1 in N.",,['probability']
41,Probability in knockout games.,Probability in knockout games.,,"Suppose in a knockout tournament 32 players p1 , p2 .....p32 participate. In each round players are divided into pairs at random and winner goes to the next round. If p5 reaches semifinal what is the probability that p1 wins the tournament? All players are equally skilled.","Suppose in a knockout tournament 32 players p1 , p2 .....p32 participate. In each round players are divided into pairs at random and winner goes to the next round. If p5 reaches semifinal what is the probability that p1 wins the tournament? All players are equally skilled.",,"['probability', 'probability-theory', 'probability-distributions']"
42,"Given a variable $X$ with a PDF, what is the PDF of $\sqrt{X}$","Given a variable  with a PDF, what is the PDF of",X \sqrt{X},"I feel this is simple and I'm overlooking something really basic. Let's say a have a variable $x$ which obeys the exponential distribution . So if collect 100000 occurrences of $x$ and plot its histogram along with the formula for the exponential distribution (with $\lambda=1$), we have the following graph, where the blue bars are the ""actual"" values taken experimentally and the green line is theoretical prediction. Now to my question: If instead I get the occurrences of $x^{1/2}$ instead of $x$ (with $x$ still obeying the same PDF), take the histogram of the 100000 positions array and plot it, I have something like the following graph. The problem is that I can't figure out the probability distribution in this case. I have found similar answers here and here but none of them quite solve it for me. Any help is appreciated. Thank you.","I feel this is simple and I'm overlooking something really basic. Let's say a have a variable $x$ which obeys the exponential distribution . So if collect 100000 occurrences of $x$ and plot its histogram along with the formula for the exponential distribution (with $\lambda=1$), we have the following graph, where the blue bars are the ""actual"" values taken experimentally and the green line is theoretical prediction. Now to my question: If instead I get the occurrences of $x^{1/2}$ instead of $x$ (with $x$ still obeying the same PDF), take the histogram of the 100000 positions array and plot it, I have something like the following graph. The problem is that I can't figure out the probability distribution in this case. I have found similar answers here and here but none of them quite solve it for me. Any help is appreciated. Thank you.",,"['probability', 'statistics', 'probability-distributions', 'random-variables']"
43,Expectation with respect to empirical distribution,Expectation with respect to empirical distribution,,"Let $(\Omega,\mathcal{A})$ be a measure space and $X$ a random variable with distribution $P$ . The expectation of some measurable function $g$ with respect to $P$ is $$ \mathbb{E}_P[g(X)] = \int_\Omega g(X(\omega))\, dP(\omega). $$ The empirical distribution $Q$ of i.i.d. samples $x_1,\dotsc,x_n$ from $P$ is defined as $$ Q(B) = \frac{1}{n} \sum_{i=1}^n \mathbb{1}_B(x_i) \quad B \in \mathcal{A} \,. $$ I know that $$ \mathbb{E}_Q[g(X)] = \frac{1}{n} \sum_{i=1}^n g(x_i) $$ but it is not obvoius how to derive this starting with $$ \mathbb{E}_Q[g(X)] = \int_\Omega g(X(\omega))\, d\left[ \frac{1}{n} \sum_{i=1}^n \mathbb{1}_\omega(x_i) \right] $$",Let be a measure space and a random variable with distribution . The expectation of some measurable function with respect to is The empirical distribution of i.i.d. samples from is defined as I know that but it is not obvoius how to derive this starting with,"(\Omega,\mathcal{A}) X P g P 
\mathbb{E}_P[g(X)] = \int_\Omega g(X(\omega))\, dP(\omega).
 Q x_1,\dotsc,x_n P 
Q(B) = \frac{1}{n} \sum_{i=1}^n \mathbb{1}_B(x_i) \quad B \in \mathcal{A} \,.
 
\mathbb{E}_Q[g(X)] = \frac{1}{n} \sum_{i=1}^n g(x_i)
 
\mathbb{E}_Q[g(X)] = \int_\Omega g(X(\omega))\, d\left[ \frac{1}{n} \sum_{i=1}^n \mathbb{1}_\omega(x_i) \right]
","['probability', 'measure-theory', 'probability-theory']"
44,Expected value complex random variable,Expected value complex random variable,,"I want to check that if $X: \Omega \to \mathbb{C}$ is a random variable, then the inequality $| \mathbb{E} X| \le \mathbb{E} |X|$ also holds like in the real case. We can write $$X = \Re X + i \cdot  \Im X$$ And $$|X| = \sqrt{(\Re X)^2 + (\Im X)^2}, \ \ \ \mathbb{E}|X|= \int_{\Omega} \sqrt{(\Re X)^2 + (\Im X)^2}$$ $$|\mathbb{E}X| = | \int_{\Omega} (\Re X + i \cdot \Im X) \text{d}P| = | \int_{\Omega} \Re X \text{d}P + i \int_{\Omega} \Im X \text{d}P| = \sqrt{ ( \int_{\Omega} \Re X \text{d}P)^2 +  ( \int_{\Omega} \Im X \text{d}P ) ^2}  $$ What can I use now to finish the argument? Could you give me a hint?","I want to check that if $X: \Omega \to \mathbb{C}$ is a random variable, then the inequality $| \mathbb{E} X| \le \mathbb{E} |X|$ also holds like in the real case. We can write $$X = \Re X + i \cdot  \Im X$$ And $$|X| = \sqrt{(\Re X)^2 + (\Im X)^2}, \ \ \ \mathbb{E}|X|= \int_{\Omega} \sqrt{(\Re X)^2 + (\Im X)^2}$$ $$|\mathbb{E}X| = | \int_{\Omega} (\Re X + i \cdot \Im X) \text{d}P| = | \int_{\Omega} \Re X \text{d}P + i \int_{\Omega} \Im X \text{d}P| = \sqrt{ ( \int_{\Omega} \Re X \text{d}P)^2 +  ( \int_{\Omega} \Im X \text{d}P ) ^2}  $$ What can I use now to finish the argument? Could you give me a hint?",,"['probability', 'probability-theory', 'random-variables']"
45,Probabilistic method: vertex disjoint cycles in digraphs,Probabilistic method: vertex disjoint cycles in digraphs,,"Let us say that a di-graph is $k$-regular if every vertex has precisely $k$ out-edges. The following theorem appears in a book I am currently studying Theorem. Every $k$-regular graph $D$ has a collection of $r = \lfloor k/(3 \log{k}) \rfloor$ vertex-disjoint cycles. The proof in the book goes as follows. Color the vertices of $D$ choosing colors from $\{1,\ldots,r\}$ uniformly at random. For a vertex $v \in V(D)$ define the event $A_v$ that $v$ does not have any out-neighbor of the same color. The author then claims it is enough to show $$Pr[\cap_{v \in V(D)} \overline{A}_v] > 0,$$ and argues how to derive this bound using the Lovasz Local Lemma. What I am wondering is: Is there any reason we are disregarding to estimate the probability that   each color $r$ is represented in the coloring of $D$?","Let us say that a di-graph is $k$-regular if every vertex has precisely $k$ out-edges. The following theorem appears in a book I am currently studying Theorem. Every $k$-regular graph $D$ has a collection of $r = \lfloor k/(3 \log{k}) \rfloor$ vertex-disjoint cycles. The proof in the book goes as follows. Color the vertices of $D$ choosing colors from $\{1,\ldots,r\}$ uniformly at random. For a vertex $v \in V(D)$ define the event $A_v$ that $v$ does not have any out-neighbor of the same color. The author then claims it is enough to show $$Pr[\cap_{v \in V(D)} \overline{A}_v] > 0,$$ and argues how to derive this bound using the Lovasz Local Lemma. What I am wondering is: Is there any reason we are disregarding to estimate the probability that   each color $r$ is represented in the coloring of $D$?",,"['probability', 'combinatorics', 'graph-theory', 'probabilistic-method']"
46,"Expectation, variance and indicator variables","Expectation, variance and indicator variables",,"If we have three events $A_i$ with $i=1,2,3$ with probability $\frac{1}{5}, \frac{1}{4}, \frac{1}{3}$ respectively. Let $X$ be the number of these events that occur. Trying to write down a formula for $X$ in terms of indicators in order to find the expectation of $X$. Afterwards trying to find $\operatorname{Var}(X)$ if each event is disjoint (case 1), each event is independent (case 2), and $A_{1} \subseteq A_{2} \subseteq A_{3} $(case 3). Any suggestions of how to tackle this problem?","If we have three events $A_i$ with $i=1,2,3$ with probability $\frac{1}{5}, \frac{1}{4}, \frac{1}{3}$ respectively. Let $X$ be the number of these events that occur. Trying to write down a formula for $X$ in terms of indicators in order to find the expectation of $X$. Afterwards trying to find $\operatorname{Var}(X)$ if each event is disjoint (case 1), each event is independent (case 2), and $A_{1} \subseteq A_{2} \subseteq A_{3} $(case 3). Any suggestions of how to tackle this problem?",,"['probability', 'expectation']"
47,"Comparing probabilities of drawing balls of certain color, with and without replacement","Comparing probabilities of drawing balls of certain color, with and without replacement",,"Please read carefully how I solved this question: A bag contains 4 white 2 black 3 red balls. A ball is drawn from the bag 1-by-1. (i) Find the probability that $5^{th}$ ball is red. Consider both with and without replacement. (ii) 3^rd and 7^th are red. Find the probability that $9^{th}$ ball is black. Consider both with and without replacement. (i) (a) with replacement. $$P=\frac39=\frac13$$ (b) without replacement. Let's make an array of 9 elements where i^th element denote which ball is taken out in i^th turn, then we can have red in 5^th position with probability:$$P=\frac{\binom31\binom82\binom622!2!4!}{9!}=\frac13$$ [select one red ball to put in 5^th position, then select positions on array for black and remaining red then arrange them divided by total arrangements] (ii) (a) with replacement. $$P=\frac29$$ (b) without replacement. Let's make an array of 9 elements where i^th element denote which ball is taken out in i^th turn, then we have red in 3rd and 7th position red,we can have black in 9^th position with probability:$$P=\frac{\binom32\binom212!6!2!}{\binom322!7!}=\frac27$$ [select two red balls for 3 and 7 position then select one black ball for last position and then select position for red and remaining black balls on array then arrange] Why did drawing with or without replacement make no difference in the first and second can be obtained by considering 3^rd and 7^th balls were never there?","Please read carefully how I solved this question: A bag contains 4 white 2 black 3 red balls. A ball is drawn from the bag 1-by-1. (i) Find the probability that $5^{th}$ ball is red. Consider both with and without replacement. (ii) 3^rd and 7^th are red. Find the probability that $9^{th}$ ball is black. Consider both with and without replacement. (i) (a) with replacement. $$P=\frac39=\frac13$$ (b) without replacement. Let's make an array of 9 elements where i^th element denote which ball is taken out in i^th turn, then we can have red in 5^th position with probability:$$P=\frac{\binom31\binom82\binom622!2!4!}{9!}=\frac13$$ [select one red ball to put in 5^th position, then select positions on array for black and remaining red then arrange them divided by total arrangements] (ii) (a) with replacement. $$P=\frac29$$ (b) without replacement. Let's make an array of 9 elements where i^th element denote which ball is taken out in i^th turn, then we have red in 3rd and 7th position red,we can have black in 9^th position with probability:$$P=\frac{\binom32\binom212!6!2!}{\binom322!7!}=\frac27$$ [select two red balls for 3 and 7 position then select one black ball for last position and then select position for red and remaining black balls on array then arrange] Why did drawing with or without replacement make no difference in the first and second can be obtained by considering 3^rd and 7^th balls were never there?",,"['probability', 'combinatorics']"
48,A Question about Shuffling a Deck of Cards,A Question about Shuffling a Deck of Cards,,"Currently I am following Sheldon Ross' A first course in probability. And I got stuck in this question: Consider the following technique for shuffling a deck of $n$ cards: For any initial ordering of the cards, go through the deck one card at a time and at each card, flip a fair coin. If the coin comes up-heads, then leave the card where it is; if the coin comes up-tails, then move that card to the end of the deck. After the coin has been flipped $n$ times, say that one round has been completed. For instance, if $n=4$ and the initial ordering is $(1,2,3, 4)$, then if the successive flips result in the outcome $(H,T,T,H)$ then the ordering at the end of the round is $(1,4,2,3)$. Assuming that all possible outcomes of the sequence of $n$ coin flips are equally likely, what is the probability that the ordering after one round is the same as the initial ordering? The book says the answer is $\frac{n+1}{2^n}$, but the answer I got is $\frac{2}{2^n}$ since we have two successive flips that will produce the same ordering (I.e.  $(H,H,...,H)$ and $(T,T,...,T)$)? Thanks on any hint/help.","Currently I am following Sheldon Ross' A first course in probability. And I got stuck in this question: Consider the following technique for shuffling a deck of $n$ cards: For any initial ordering of the cards, go through the deck one card at a time and at each card, flip a fair coin. If the coin comes up-heads, then leave the card where it is; if the coin comes up-tails, then move that card to the end of the deck. After the coin has been flipped $n$ times, say that one round has been completed. For instance, if $n=4$ and the initial ordering is $(1,2,3, 4)$, then if the successive flips result in the outcome $(H,T,T,H)$ then the ordering at the end of the round is $(1,4,2,3)$. Assuming that all possible outcomes of the sequence of $n$ coin flips are equally likely, what is the probability that the ordering after one round is the same as the initial ordering? The book says the answer is $\frac{n+1}{2^n}$, but the answer I got is $\frac{2}{2^n}$ since we have two successive flips that will produce the same ordering (I.e.  $(H,H,...,H)$ and $(T,T,...,T)$)? Thanks on any hint/help.",,"['probability', 'combinatorics']"
49,Four consecutive heads from ten coin flips [duplicate],Four consecutive heads from ten coin flips [duplicate],,"This question already has answers here : Probability of tossing a fair coin with at least $k$ consecutive heads (5 answers) Closed 9 years ago . If we flip a fair coin $10$ times, what is the probability we get $\ge 4$ consecutive heads? An approach would be to consider the probability of all consecutive heads, cut off by tails, e.g., HHHHTxxxxx THHHHTxxxx ... HHHHHTxxxx THHHHHTxxxx ... but this is complicated, and also has a problem that some patterns overlap (e.g., HHHHTHHHHT). Is there a simpler way to do this?","This question already has answers here : Probability of tossing a fair coin with at least $k$ consecutive heads (5 answers) Closed 9 years ago . If we flip a fair coin $10$ times, what is the probability we get $\ge 4$ consecutive heads? An approach would be to consider the probability of all consecutive heads, cut off by tails, e.g., HHHHTxxxxx THHHHTxxxx ... HHHHHTxxxx THHHHHTxxxx ... but this is complicated, and also has a problem that some patterns overlap (e.g., HHHHTHHHHT). Is there a simpler way to do this?",,['probability']
50,Bivariate distribution with normal conditions,Bivariate distribution with normal conditions,,"Define the joint pdf of $(X,Y)$ as: $$f(x,y)\propto \exp(-1/2[Ax^2y^2+x^2+y^2-2Bxy-2Cx-Dy]),$$ where $A,B,C,D$ are constants. Show that the distribution of $X\mid Y=y$ is normal with mean $\frac{By+C}{Ay^2+1}$ and variance $\frac{1}{Ay^2+1}$. Derive a corresponding result for the distribution of $Y\mid X=x$. Attempt: I tried to integrate the equation w.r.t. $x$ in order to find $X\mid Y=y$. However, I'm not sure if I am correct: $$\int_{-\infty}^{\infty}\exp(-1/2[Ax^2y^2+x^2+y^2-2Bxy-2Cx-Dy])\,dx$$ $$ =\left[\frac{\exp[-1/2[Ax^2y^2+x^2+y^2-2Bxy-2Cx-Dy]}{-Axy^2-1/2+By+C}\right]_{-\infty}^{\infty}$$ Whatever the value of the previous integration (call it ""Q""), then we would divide the original equation by ""Q"", i.e.: $$ \frac{f_{X,Y}(x,y)}{Q}$$ Which would give us $f_{X\mid Y=y}(X\mid Y=y)$. How do I go about evaluating $$ =\left[\frac{\exp[-1/2[Ax^2y^2+x^2+y^2-2Bxy-2Cx-Dy]}{-Axy^2-1/2+By+C}\right]_{-\infty}^{\infty}\text{ ?}$$","Define the joint pdf of $(X,Y)$ as: $$f(x,y)\propto \exp(-1/2[Ax^2y^2+x^2+y^2-2Bxy-2Cx-Dy]),$$ where $A,B,C,D$ are constants. Show that the distribution of $X\mid Y=y$ is normal with mean $\frac{By+C}{Ay^2+1}$ and variance $\frac{1}{Ay^2+1}$. Derive a corresponding result for the distribution of $Y\mid X=x$. Attempt: I tried to integrate the equation w.r.t. $x$ in order to find $X\mid Y=y$. However, I'm not sure if I am correct: $$\int_{-\infty}^{\infty}\exp(-1/2[Ax^2y^2+x^2+y^2-2Bxy-2Cx-Dy])\,dx$$ $$ =\left[\frac{\exp[-1/2[Ax^2y^2+x^2+y^2-2Bxy-2Cx-Dy]}{-Axy^2-1/2+By+C}\right]_{-\infty}^{\infty}$$ Whatever the value of the previous integration (call it ""Q""), then we would divide the original equation by ""Q"", i.e.: $$ \frac{f_{X,Y}(x,y)}{Q}$$ Which would give us $f_{X\mid Y=y}(X\mid Y=y)$. How do I go about evaluating $$ =\left[\frac{\exp[-1/2[Ax^2y^2+x^2+y^2-2Bxy-2Cx-Dy]}{-Axy^2-1/2+By+C}\right]_{-\infty}^{\infty}\text{ ?}$$",,"['probability', 'probability-theory', 'probability-distributions', 'conditional-probability', 'statistical-inference']"
51,"Minimum number of attempts to guess a PIN code, given constraints","Minimum number of attempts to guess a PIN code, given constraints",,"I'm playing a video game at the moment called Sleeping Dogs, in which some of the mini-missions are to 'hack' a security camera, by guessing a four-digit PIN code. Here are the rules: 1) You are allowed 6 attempts to enter a four-digit PIN code. After 6 attempts, the PIN code resets to a random (other) one. 2) Repeated digits are not allowed (e.g. $9981, 1131, 5555,$ etc. are not allowed). 3)  If the correct digit is in the correct place, that digit will be green. If the correct digit (i.e. a digit that is in the actual PIN) is in the incorrect place, that digit will be amber. If an incorrect digit is entered (i.e. a digit that is not in the actual PIN), that digit will be red. e.g. Suppose that the actual code is $\boxed{1234}.$ If I entered $1427$, it would show up as $$\color{green}1\color{orange}4\color{orange}2\color{red}7.$$ My question is this: What is the minimum number of attempts in order to guarantee entry to the system, (can it be achieved with certainty in fewer than six attempts)? There seem to be so many factors that I can't come up with a quick solution. Any hints/tips would be welcome. (Background info-- I'm familiar with elementary probability and statistics).","I'm playing a video game at the moment called Sleeping Dogs, in which some of the mini-missions are to 'hack' a security camera, by guessing a four-digit PIN code. Here are the rules: 1) You are allowed 6 attempts to enter a four-digit PIN code. After 6 attempts, the PIN code resets to a random (other) one. 2) Repeated digits are not allowed (e.g. $9981, 1131, 5555,$ etc. are not allowed). 3)  If the correct digit is in the correct place, that digit will be green. If the correct digit (i.e. a digit that is in the actual PIN) is in the incorrect place, that digit will be amber. If an incorrect digit is entered (i.e. a digit that is not in the actual PIN), that digit will be red. e.g. Suppose that the actual code is $\boxed{1234}.$ If I entered $1427$, it would show up as $$\color{green}1\color{orange}4\color{orange}2\color{red}7.$$ My question is this: What is the minimum number of attempts in order to guarantee entry to the system, (can it be achieved with certainty in fewer than six attempts)? There seem to be so many factors that I can't come up with a quick solution. Any hints/tips would be welcome. (Background info-- I'm familiar with elementary probability and statistics).",,"['probability', 'statistics']"
52,Proof of Double Expectation of a Conditional Expectation,Proof of Double Expectation of a Conditional Expectation,,"There is a proof of  $$ E(E(Y|x)) = E(Y) $$ $Proof:$ WLOG, suppose X and Y are two continuous random variables. Let $E(Y|x)=m(x) =\int_{-\infty}^{\infty} yf(y|x)\, dy$ Then  $$ E(E(Y|x))=E(m(x))= \int_{-\infty}^{\infty} m(x) f(x) \, dx =\int_{-\infty}^{\infty} \Big(\int_{-\infty}^{\infty} yf(y|x)\, dy\Big) f(x)\, dx $$ $$ =\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} y\frac{f(x,y)}{f(x)}f(x)\, dy \, dx  =\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} yf(x,y)\, dy \, dx = E(Y) $$ My question is why $$\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} yf(x,y)\, dy \, dx=\int_{-\infty}^{\infty} yf(y)\, dy=E(Y)$$","There is a proof of  $$ E(E(Y|x)) = E(Y) $$ $Proof:$ WLOG, suppose X and Y are two continuous random variables. Let $E(Y|x)=m(x) =\int_{-\infty}^{\infty} yf(y|x)\, dy$ Then  $$ E(E(Y|x))=E(m(x))= \int_{-\infty}^{\infty} m(x) f(x) \, dx =\int_{-\infty}^{\infty} \Big(\int_{-\infty}^{\infty} yf(y|x)\, dy\Big) f(x)\, dx $$ $$ =\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} y\frac{f(x,y)}{f(x)}f(x)\, dy \, dx  =\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} yf(x,y)\, dy \, dx = E(Y) $$ My question is why $$\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} yf(x,y)\, dy \, dx=\int_{-\infty}^{\infty} yf(y)\, dy=E(Y)$$",,['probability']
53,Hearthstone Arena Probability,Hearthstone Arena Probability,,"In the online card game, Hearthstone, there is a play mode called Arena.  Players who enter the arena build decks (commonly referred to as drafting) and play until they win 12 matches or lose 3 matches .  Since the decks are built 'randomly,' and the matches are also random, we can assume that each player has a 0.5 chance of winning and a 0.5 chance of losing. What would be the best way to calculate the probability of ending with exactly 0 wins, 1 win, 2 wins, ..., and 12 wins?  Since the arena ends after any 3 loses there are branches of the binomial tree that would never occur. ie Completing 3 matches have the following possible outcomes.  WWW, WWL, WLW, WLL, LLL, LLW, LWL, LWW.  Since LLL fulfills the 'lose 3 match requirement' LLLL and LLLW can not occur.  Likewise during a 5th round, WLLLW, WLLLL, LWLLW, LWLLL, LLWLW, LLWLL, LLLWW, LLLWL, LLLLWL, LLLLL can not occur.","In the online card game, Hearthstone, there is a play mode called Arena.  Players who enter the arena build decks (commonly referred to as drafting) and play until they win 12 matches or lose 3 matches .  Since the decks are built 'randomly,' and the matches are also random, we can assume that each player has a 0.5 chance of winning and a 0.5 chance of losing. What would be the best way to calculate the probability of ending with exactly 0 wins, 1 win, 2 wins, ..., and 12 wins?  Since the arena ends after any 3 loses there are branches of the binomial tree that would never occur. ie Completing 3 matches have the following possible outcomes.  WWW, WWL, WLW, WLL, LLL, LLW, LWL, LWW.  Since LLL fulfills the 'lose 3 match requirement' LLLL and LLLW can not occur.  Likewise during a 5th round, WLLLW, WLLLL, LWLLW, LWLLL, LLWLW, LLWLL, LLLWW, LLLWL, LLLLWL, LLLLL can not occur.",,"['probability', 'binomial-theorem']"
54,Prove $X_n \xrightarrow P 0$ as $n \rightarrow \infty$ iff $\lim_{n \to \infty} E(\frac{|X_n|}{|X_n|+1} )= 0$,Prove  as  iff,X_n \xrightarrow P 0 n \rightarrow \infty \lim_{n \to \infty} E(\frac{|X_n|}{|X_n|+1} )= 0,"Let $X_1, X_2, ...$ be a sequence of real-valued random variables. Prove $X_n \xrightarrow P  0$ as $n \rightarrow \infty$ iff $\lim_{n \to \infty} E(\frac{|X_n|}{|X_n|+1} )= 0$ Attempt: Suppose $X_n \xrightarrow P  0$ as $n \rightarrow \infty$. Then since $X_1, X_2, ...$  is uniformly integrable and E(|X|)<$\infty$, then $\lim_{n \to \infty} E(X_n) = E(X)$. Since $X_n \xrightarrow P  0$ as $n \rightarrow \infty$, then $\lim_{n \to \infty} E(\frac{|X_n|}{|X_n|+1} )$ must be equal to 0.","Let $X_1, X_2, ...$ be a sequence of real-valued random variables. Prove $X_n \xrightarrow P  0$ as $n \rightarrow \infty$ iff $\lim_{n \to \infty} E(\frac{|X_n|}{|X_n|+1} )= 0$ Attempt: Suppose $X_n \xrightarrow P  0$ as $n \rightarrow \infty$. Then since $X_1, X_2, ...$  is uniformly integrable and E(|X|)<$\infty$, then $\lim_{n \to \infty} E(X_n) = E(X)$. Since $X_n \xrightarrow P  0$ as $n \rightarrow \infty$, then $\lim_{n \to \infty} E(\frac{|X_n|}{|X_n|+1} )$ must be equal to 0.",,"['real-analysis', 'probability', 'statistics', 'convergence-divergence', 'expectation']"
55,Intersection of countable many sets of measure $1$,Intersection of countable many sets of measure,1,"Consider a probability space $(X,\mathscr M,\mu)$ and a collection of measurable sets $\{A_n\}_{n\in\mathbb N}$ such that $\mu (A_n)=1$ for every $n$. Then I don't unterstand the following result: $$\mu\left(\bigcap_{n\in\mathbb N}A_n\right)=1$$ Any idea about it? Many thanks in advance.","Consider a probability space $(X,\mathscr M,\mu)$ and a collection of measurable sets $\{A_n\}_{n\in\mathbb N}$ such that $\mu (A_n)=1$ for every $n$. Then I don't unterstand the following result: $$\mu\left(\bigcap_{n\in\mathbb N}A_n\right)=1$$ Any idea about it? Many thanks in advance.",,"['probability', 'measure-theory']"
56,Intuition in probability theory,Intuition in probability theory,,"Good afternoon. Could you please suggest me some books or may be articles where I can read about the intuition of Kolmogorov's axiomatics. I know it, I can solve university problems but I can't feel it. I know measure theory, but it doesn't help me with the understanding such questions like: ""Why exactly sigma-algebra?"", ""Why not semi-algebra?"", ""Where did we get it from?"", ""Where's the logic here?"" and so on... I can't feel the use of measure theory in probability theory .","Good afternoon. Could you please suggest me some books or may be articles where I can read about the intuition of Kolmogorov's axiomatics. I know it, I can solve university problems but I can't feel it. I know measure theory, but it doesn't help me with the understanding such questions like: ""Why exactly sigma-algebra?"", ""Why not semi-algebra?"", ""Where did we get it from?"", ""Where's the logic here?"" and so on... I can't feel the use of measure theory in probability theory .",,"['probability', 'measure-theory', 'probability-theory']"
57,Conditioning on information about the moments of a random variable is trivial,Conditioning on information about the moments of a random variable is trivial,,"Say we have some random variable, $X$. Is it always trivial to condition on information about the moments of $X$? For example, suppose we know that $\mathbb{E}(X)$ is positive. But $\mathbb{E}\left(X|\mathbb{E}(X)>0\right)=\mathbb{E}(X)$ since the thing in the conditioning set is just some generic fact about a constant. Same is true for $X,Y$ have some joint distribution. $\mathbb{E}(X|\mathbb{E}(X)>\mathbb{E}(Y))=\mathbb{E}(X)$.","Say we have some random variable, $X$. Is it always trivial to condition on information about the moments of $X$? For example, suppose we know that $\mathbb{E}(X)$ is positive. But $\mathbb{E}\left(X|\mathbb{E}(X)>0\right)=\mathbb{E}(X)$ since the thing in the conditioning set is just some generic fact about a constant. Same is true for $X,Y$ have some joint distribution. $\mathbb{E}(X|\mathbb{E}(X)>\mathbb{E}(Y))=\mathbb{E}(X)$.",,"['probability', 'statistics', 'expectation']"
58,Probability that a card drawn is King on condition that the card is a Heart,Probability that a card drawn is King on condition that the card is a Heart,,"From a standard deck of 52 cards, what is the probability that a randomly drawn card is a King, on condition that the card drawn is a Heart? I used the conditional probability formula and got: Probability that the card is a King AND a Heart: $\frac{1}{52}$ Probability that the card is a Heart: $\frac{13}{52}$ So: $\frac{\frac{1}{52}}{\frac{13}{52}} = \frac{1}{13}$. Is this correct?","From a standard deck of 52 cards, what is the probability that a randomly drawn card is a King, on condition that the card drawn is a Heart? I used the conditional probability formula and got: Probability that the card is a King AND a Heart: $\frac{1}{52}$ Probability that the card is a Heart: $\frac{13}{52}$ So: $\frac{\frac{1}{52}}{\frac{13}{52}} = \frac{1}{13}$. Is this correct?",,"['probability', 'conditional-probability']"
59,Expected value of number of tosses until we get $k$ tails and $k$ heads,Expected value of number of tosses until we get  tails and  heads,k k,"Let $k$ be a fixed positive number. We toss a normal coin until we get at least $k$ heads and at least $k$ tails (not necessarily consecutively). Let $X$ be number of needed tosses. Find distribution of $X$ and its expected value. So this is my attempt: first of all, we see that $P(X=j)$ is $0$ for $j<2k$. For $j \ge 2k$ we have the following: Let A be the event that in the last toss we get a head. Let B be the event that in the last toss we get a tail. So: $P(X=j) = P(X=j | A) P(A) + P(X=j|B) P(B) = $ ${j-1}\choose{k-1}$$ (\frac{1}{2})^{j-1} \frac{1}{2}$ + ${j-1}\choose{k}$$ (\frac{1}{2})^{j-1} \frac{1}{2} = (\frac{1}{2})^j [$$ {j-1}\choose{k-1}$ ${j-1}\choose{k} $$] = (\frac{1}{2})^j $${j}\choose{k}$ So I found the distribution of $X$. But the problem comes with the expected value: $E(X) = \sum_{j=2k}^\infty j (\frac{1}{2})^j $${j}\choose{k} $=... How to compute it? May you help me and show me how?","Let $k$ be a fixed positive number. We toss a normal coin until we get at least $k$ heads and at least $k$ tails (not necessarily consecutively). Let $X$ be number of needed tosses. Find distribution of $X$ and its expected value. So this is my attempt: first of all, we see that $P(X=j)$ is $0$ for $j<2k$. For $j \ge 2k$ we have the following: Let A be the event that in the last toss we get a head. Let B be the event that in the last toss we get a tail. So: $P(X=j) = P(X=j | A) P(A) + P(X=j|B) P(B) = $ ${j-1}\choose{k-1}$$ (\frac{1}{2})^{j-1} \frac{1}{2}$ + ${j-1}\choose{k}$$ (\frac{1}{2})^{j-1} \frac{1}{2} = (\frac{1}{2})^j [$$ {j-1}\choose{k-1}$ ${j-1}\choose{k} $$] = (\frac{1}{2})^j $${j}\choose{k}$ So I found the distribution of $X$. But the problem comes with the expected value: $E(X) = \sum_{j=2k}^\infty j (\frac{1}{2})^j $${j}\choose{k} $=... How to compute it? May you help me and show me how?",,['probability']
60,"Let $X_1$ and $X_2$ are independent $N(0, \sigma^2)$ random variables. What is the distribution of $X_1^2 + X_2^2$?",Let  and  are independent  random variables. What is the distribution of ?,"X_1 X_2 N(0, \sigma^2) X_1^2 + X_2^2","Let $X_1$ and $X_2$ are independent $N(0, \sigma^2)$ which means (mean = 0, variance = $\sigma^2$) random variables. What is the distribution of $X_1^2 + X_2^2$? My approach is that  $X_1\sim N(0, \sigma^2)$ and $X_2\sim N(0, \sigma^2)$ Then $X_1^2$ and $X_2^2$ have chi-squared distribution with 1 degree of freedom. (I am not sure the degree of freedom and not sure how to show it as well(please help on this)) Then I found the moment-generating function for $X_1^2$ and $X_2^2$;$$m_{X_1^2} = (1-2t)^{-1/2}$$ and $$m_{X_2^2} = (1-2t)^{-1/2}$$ So the moment generating function for $X_1^2 + X_2^2$ is $$m_{X_1^2}(t) m_{X_2^2}(t) = (1-2t)^{-2/2}$$ So $X_1^2 + X_2^2$ has a chi-squared distribution with 2 degrees of freedom. Is this correct?","Let $X_1$ and $X_2$ are independent $N(0, \sigma^2)$ which means (mean = 0, variance = $\sigma^2$) random variables. What is the distribution of $X_1^2 + X_2^2$? My approach is that  $X_1\sim N(0, \sigma^2)$ and $X_2\sim N(0, \sigma^2)$ Then $X_1^2$ and $X_2^2$ have chi-squared distribution with 1 degree of freedom. (I am not sure the degree of freedom and not sure how to show it as well(please help on this)) Then I found the moment-generating function for $X_1^2$ and $X_2^2$;$$m_{X_1^2} = (1-2t)^{-1/2}$$ and $$m_{X_2^2} = (1-2t)^{-1/2}$$ So the moment generating function for $X_1^2 + X_2^2$ is $$m_{X_1^2}(t) m_{X_2^2}(t) = (1-2t)^{-2/2}$$ So $X_1^2 + X_2^2$ has a chi-squared distribution with 2 degrees of freedom. Is this correct?",,"['probability', 'probability-distributions', 'normal-distribution']"
61,Probability of rolling 3 sixes in 6 rolls [closed],Probability of rolling 3 sixes in 6 rolls [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I roll a die six times. What is the probability of rolling at least 3 sixes? Please share the formula as well, so I can figure it out myself in future.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I roll a die six times. What is the probability of rolling at least 3 sixes? Please share the formula as well, so I can figure it out myself in future.",,"['probability', 'dice']"
62,Is there a standard proof for $\mathbb P(S^X_n\text{ hits }A\text{ before }B) >\mathbb P(S^Y_n\text{ hits }A\text{ before }B)$?,Is there a standard proof for ?,\mathbb P(S^X_n\text{ hits }A\text{ before }B) >\mathbb P(S^Y_n\text{ hits }A\text{ before }B),"Let $X_i$ and $Y_i$ be two continuous random variables on $\mathbb{R}$ having distribution functions $F$ and $G$, respectively satisfying $G(y)>F(y)$ for all $y$. Let futhermore $S^X_n=\sum_{i=1}^n X_i$, $S^Y_n=\sum_{i=1}^n Y_i$, $A>0$, and $B<0$, Then, I wonder if there is a simple/standard proof for the following: $$ \mathbb P(S^X_n\text{ hits }A\text{ before }B) > \mathbb P(S^Y_n\text{ hits }A\text{ before }B) $$ Note: Both $X$ and $Y$ have negative means. Thanks alot.","Let $X_i$ and $Y_i$ be two continuous random variables on $\mathbb{R}$ having distribution functions $F$ and $G$, respectively satisfying $G(y)>F(y)$ for all $y$. Let futhermore $S^X_n=\sum_{i=1}^n X_i$, $S^Y_n=\sum_{i=1}^n Y_i$, $A>0$, and $B<0$, Then, I wonder if there is a simple/standard proof for the following: $$ \mathbb P(S^X_n\text{ hits }A\text{ before }B) > \mathbb P(S^Y_n\text{ hits }A\text{ before }B) $$ Note: Both $X$ and $Y$ have negative means. Thanks alot.",,"['probability', 'probability-theory', 'stochastic-processes']"
63,Mean time spent in transient states/Markov chain,Mean time spent in transient states/Markov chain,,"I dont get this in my book: For transient states $i$ and $j$ , let $s_{ij}$ denote the expected number of time periods that the markov chain is in state $j$ , given that it starts in state $i$. Let $\delta_{i,j} = 1$ when $i = j$ and let it be $0$ otherwise.Condition of the initial transition to obtain: $s_{ij} = \delta_{i,j} + \sum_k P_{ik}s_{kj} = \delta_{i,j} + \sum\limits^t P_{ik}s_{kj} $ can someone show me how , if i condition of the initial transition, obtain the above equation ?  or explain in how do interpret the equation?","I dont get this in my book: For transient states $i$ and $j$ , let $s_{ij}$ denote the expected number of time periods that the markov chain is in state $j$ , given that it starts in state $i$. Let $\delta_{i,j} = 1$ when $i = j$ and let it be $0$ otherwise.Condition of the initial transition to obtain: $s_{ij} = \delta_{i,j} + \sum_k P_{ik}s_{kj} = \delta_{i,j} + \sum\limits^t P_{ik}s_{kj} $ can someone show me how , if i condition of the initial transition, obtain the above equation ?  or explain in how do interpret the equation?",,"['probability', 'statistics', 'stochastic-processes', 'markov-chains']"
64,Bell's inequality,Bell's inequality,,"Let $\xi, \eta, \zeta$ be random variables such that $|\xi|, |\eta|, |\zeta| \le 1$. I need to prove such inequality: $|\mathbb{E}(\zeta \xi)-\mathbb{E}(\zeta \eta)| \le 1 - \mathbb{E}(\xi \eta)$ Even with assumption that $\zeta, \xi, \eta$ are independent, I failed with it. I've even tried to prove $(\mathbb{E}( \xi)-\mathbb{E}( \eta))^2 \le (1 - \mathbb{E}(\xi \eta))^2$ with help of estimation: $(\mathbb{E}(\xi-\eta))^2 \le (\mathbb{E}(\xi-\eta)^2) = 2 - 2\mathbb{E}(\xi \eta)$ but $2 - 2\mathbb{E}(\xi \eta) \ge (1 - \mathbb{E}(\xi \eta))^2$. Does anybody know how to prove the statement?","Let $\xi, \eta, \zeta$ be random variables such that $|\xi|, |\eta|, |\zeta| \le 1$. I need to prove such inequality: $|\mathbb{E}(\zeta \xi)-\mathbb{E}(\zeta \eta)| \le 1 - \mathbb{E}(\xi \eta)$ Even with assumption that $\zeta, \xi, \eta$ are independent, I failed with it. I've even tried to prove $(\mathbb{E}( \xi)-\mathbb{E}( \eta))^2 \le (1 - \mathbb{E}(\xi \eta))^2$ with help of estimation: $(\mathbb{E}(\xi-\eta))^2 \le (\mathbb{E}(\xi-\eta)^2) = 2 - 2\mathbb{E}(\xi \eta)$ but $2 - 2\mathbb{E}(\xi \eta) \ge (1 - \mathbb{E}(\xi \eta))^2$. Does anybody know how to prove the statement?",,"['probability', 'inequality', 'random-variables']"
65,What's the probability of someone winning Warren Buffett's March Madness challenge?,What's the probability of someone winning Warren Buffett's March Madness challenge?,,"Billionaire Warren Buffett is giving away $1 billion (references 1 , 2 , 3 ) to anyone who can pick a perfect March Madness bracket. Roughly speaking, what is the probability that Buffett will have to pay up?","Billionaire Warren Buffett is giving away $1 billion (references 1 , 2 , 3 ) to anyone who can pick a perfect March Madness bracket. Roughly speaking, what is the probability that Buffett will have to pay up?",,['probability']
66,The normal approximation of Poisson distribution,The normal approximation of Poisson distribution,,"(I've read the related questions here but found no satisfying answer, as I would prefer a rigorous proof for this because this is a homework problem) Prove: If $X_\alpha$ follows the Poisson distribution $\pi(\alpha)$, then $$\lim_{\alpha\rightarrow\infty}P\{\frac{X_\alpha-\alpha}{\sqrt{\alpha}} \leq u \} = \Phi(u)$$ where $\Phi(u)$ is the cdf of normal distribution $N(0,1)$ Hint: use the Laplace transform $E(e^{-\lambda(X_\alpha-\alpha)/\sqrt{\alpha}})$, show that as $\alpha\rightarrow\infty$ it converges to $e^{\lambda^2/2}$ I did the transform but failed to sum the series(which is essentially doing nothing) Here's what I got: $$g(\lambda)=\sum_{n=0}^{\infty} \frac{e^{-\alpha}}{n!}\alpha^n e^{-\frac{\lambda(n-\alpha)}{\sqrt{\alpha}}}$$ and $\lim_{\alpha\rightarrow\infty} g(\lambda)=e^{-\lambda^2}$ is what I'm trying to arrive at. I tried L'Hospital only to find that the result is identical to the original ratio.","(I've read the related questions here but found no satisfying answer, as I would prefer a rigorous proof for this because this is a homework problem) Prove: If $X_\alpha$ follows the Poisson distribution $\pi(\alpha)$, then $$\lim_{\alpha\rightarrow\infty}P\{\frac{X_\alpha-\alpha}{\sqrt{\alpha}} \leq u \} = \Phi(u)$$ where $\Phi(u)$ is the cdf of normal distribution $N(0,1)$ Hint: use the Laplace transform $E(e^{-\lambda(X_\alpha-\alpha)/\sqrt{\alpha}})$, show that as $\alpha\rightarrow\infty$ it converges to $e^{\lambda^2/2}$ I did the transform but failed to sum the series(which is essentially doing nothing) Here's what I got: $$g(\lambda)=\sum_{n=0}^{\infty} \frac{e^{-\alpha}}{n!}\alpha^n e^{-\frac{\lambda(n-\alpha)}{\sqrt{\alpha}}}$$ and $\lim_{\alpha\rightarrow\infty} g(\lambda)=e^{-\lambda^2}$ is what I'm trying to arrive at. I tried L'Hospital only to find that the result is identical to the original ratio.",,"['probability', 'sequences-and-series', 'probability-theory', 'probability-distributions']"
67,Biology: Wright-Fisher model of genetic drift,Biology: Wright-Fisher model of genetic drift,,"In evolutionary biology (in population genetics to be more accurate) exists the concept of genetic drift. It describes how an allele (gene variant) (that has no advantage or disadvantage in terms of reproductive succes) vary through time. Below is a classical model to describe this process of genetic drift. This model is called the Wright-Fisher model of genetic drift: $$\frac{(2N)!}{k!(2N-k)!}p^kq^{2N-k} \Leftrightarrow \binom{2N}{k}p^kq^{2N-k}$$ where $\binom{2N}{k}$ is the binomial coefficient. This formula gives the probability of obtaining $k$ copies of an allele at generation $t+1$ given that there is a frequency of $p$ of this allele in the population at generation $t$. $N$ is the population size and $2N$ is the number of copies of each gene (this model applies to diploid population only). My questions are: 1) From this formula, how can we calculate the probability of extinction of an allele in say 120 generations starting at a given frequency, let's say 0.2? and 2) How can we calculate the probability of extinction rather than fixation of an allele starting at frequency $p$ if we wait an infinite amount of time? Question 2) has already been answered. Remain Question 1) In 1969, Kimura and Ohta showed that assuming an initial frequency of $p$, the mean time to fixation $\bar t_1(p)$ is: $$\bar t_1(p)=-4N\left(\frac{1-p}{p}\right)\ln(1-p)$$ similarly they showed that the mean time to loss $\bar t_0(p)$ is $$\bar t_0(p)=-4N\left(\frac{p}{1-p}\right)\ln(p)$$ Combining the two, they found that the mean persistence time of an allele $\bar t(p)$ is given by $\bar t(p) = (1-p)\bar t_0(p) + p\bar t_1(p)$ which equals $$\bar t(p)=-4N\cdot \left((1-p)\cdot \ln(1-p)+p\cdot \ln(p)\right)$$ It does not answer my questions though! I asked this same question on Biology.SE ( here ) a month ago but did not get an answer yet. I hope mathematician will be able to help me with that. On this biology.SE post, @GriffinEvo found via simulations that the probability of extinction of an allele starting at frequency $p$ if we wait an infinite amount of time is $1-p$ (which answer to question 2) ). How can we mathematically demonstrate that result? And don't forget question 1) :D","In evolutionary biology (in population genetics to be more accurate) exists the concept of genetic drift. It describes how an allele (gene variant) (that has no advantage or disadvantage in terms of reproductive succes) vary through time. Below is a classical model to describe this process of genetic drift. This model is called the Wright-Fisher model of genetic drift: $$\frac{(2N)!}{k!(2N-k)!}p^kq^{2N-k} \Leftrightarrow \binom{2N}{k}p^kq^{2N-k}$$ where $\binom{2N}{k}$ is the binomial coefficient. This formula gives the probability of obtaining $k$ copies of an allele at generation $t+1$ given that there is a frequency of $p$ of this allele in the population at generation $t$. $N$ is the population size and $2N$ is the number of copies of each gene (this model applies to diploid population only). My questions are: 1) From this formula, how can we calculate the probability of extinction of an allele in say 120 generations starting at a given frequency, let's say 0.2? and 2) How can we calculate the probability of extinction rather than fixation of an allele starting at frequency $p$ if we wait an infinite amount of time? Question 2) has already been answered. Remain Question 1) In 1969, Kimura and Ohta showed that assuming an initial frequency of $p$, the mean time to fixation $\bar t_1(p)$ is: $$\bar t_1(p)=-4N\left(\frac{1-p}{p}\right)\ln(1-p)$$ similarly they showed that the mean time to loss $\bar t_0(p)$ is $$\bar t_0(p)=-4N\left(\frac{p}{1-p}\right)\ln(p)$$ Combining the two, they found that the mean persistence time of an allele $\bar t(p)$ is given by $\bar t(p) = (1-p)\bar t_0(p) + p\bar t_1(p)$ which equals $$\bar t(p)=-4N\cdot \left((1-p)\cdot \ln(1-p)+p\cdot \ln(p)\right)$$ It does not answer my questions though! I asked this same question on Biology.SE ( here ) a month ago but did not get an answer yet. I hope mathematician will be able to help me with that. On this biology.SE post, @GriffinEvo found via simulations that the probability of extinction of an allele starting at frequency $p$ if we wait an infinite amount of time is $1-p$ (which answer to question 2) ). How can we mathematically demonstrate that result? And don't forget question 1) :D",,"['probability', 'probability-distributions', 'mathematical-modeling', 'applications', 'biology']"
68,"$E[X]=1.8$, where $X$ is the total number of successes of 3 trials. What is the largest/smallest $P\{X=3\}$ can be?",", where  is the total number of successes of 3 trials. What is the largest/smallest  can be?",E[X]=1.8 X P\{X=3\},"Since each trial has the same probability of success, $p$, can you not uniquely solve for $p$? I.e: Let, $X_{i} = 1$ if the $i^{th}$ trial is a success ($0$ otherwise). Then, $X=\sum_{i=1}^{3}X_{i}$, and $E[X]  = E[\sum_{i=1}^{3}X_{i}] = \sum_{i=1}^{3}E[X_{i}] = \sum_{i=1}^{3}p =3p =1.8$ So, $p=0.6$, and $P\{X=3\}=0.6^{3}$ I thought what I did was sound, but the textbook says the answer to (a) is $0.6$ and (b) is $0$. Their reasoning (for (a)) is as follows: However, how can the above be true if all three trials have the same probability of success? That is, how can $P\{X=1\}$ and $P\{X=2\}$ be zero, when $P\{X=3\}$ is nonzero?","Since each trial has the same probability of success, $p$, can you not uniquely solve for $p$? I.e: Let, $X_{i} = 1$ if the $i^{th}$ trial is a success ($0$ otherwise). Then, $X=\sum_{i=1}^{3}X_{i}$, and $E[X]  = E[\sum_{i=1}^{3}X_{i}] = \sum_{i=1}^{3}E[X_{i}] = \sum_{i=1}^{3}p =3p =1.8$ So, $p=0.6$, and $P\{X=3\}=0.6^{3}$ I thought what I did was sound, but the textbook says the answer to (a) is $0.6$ and (b) is $0$. Their reasoning (for (a)) is as follows: However, how can the above be true if all three trials have the same probability of success? That is, how can $P\{X=1\}$ and $P\{X=2\}$ be zero, when $P\{X=3\}$ is nonzero?",,"['probability', 'expectation']"
69,Roll summing over a long stretch,Roll summing over a long stretch,,Say I roll a 6-sided die until its sum exceeds $X$. What is E(rolls)?,Say I roll a 6-sided die until its sum exceeds $X$. What is E(rolls)?,,"['probability', 'dice', 'expectation']"
70,Likelihood of sum of dice roll is exactly 1 million,Likelihood of sum of dice roll is exactly 1 million,,"A board game is set up such that there is a number line with squares numbered 0..1 million. You roll a standard 6 sided die and move forward the number of spaces that you roll. Eventually you will either land on, or pass the 1 millionth spot. What is the probability you land exactly on the 1 millionth spot? In other words, what is the probability that after a number of rolls the sum is exactly 1 million","A board game is set up such that there is a number line with squares numbered 0..1 million. You roll a standard 6 sided die and move forward the number of spaces that you roll. Eventually you will either land on, or pass the 1 millionth spot. What is the probability you land exactly on the 1 millionth spot? In other words, what is the probability that after a number of rolls the sum is exactly 1 million",,"['probability', 'dice']"
71,Simplify $\sum_{k=0}^n \frac{1}{k!(n-k!)}.$,Simplify,\sum_{k=0}^n \frac{1}{k!(n-k!)}.,"Is there a way to simplify the expression $$\sum_{k=0}^n \frac{1}{k!(n-k)!}?$$ This came up when I was trying to determine $\mathbb{P}(X+Y =r)$ given a joint mass probability $$m_{X,Y}(j,k) = \frac{c(j+k)a^{j+k}}{j!k!},$$ where $j$ and $k$ are non-negative integers and $a,c>0$ are constants.","Is there a way to simplify the expression $$\sum_{k=0}^n \frac{1}{k!(n-k)!}?$$ This came up when I was trying to determine $\mathbb{P}(X+Y =r)$ given a joint mass probability $$m_{X,Y}(j,k) = \frac{c(j+k)a^{j+k}}{j!k!},$$ where $j$ and $k$ are non-negative integers and $a,c>0$ are constants.",,"['probability', 'sequences-and-series', 'arithmetic', 'binomial-coefficients']"
72,Expected shortest path in random graph,Expected shortest path in random graph,,"Consider all connected graphs with $n$ verticies where each vertex connects to $k$ other verticies. We choose such a graph at random. What is the expected value of the shortest path between two random points? What is the expected value of the maximal shortest path? If an exact solution would be too complicated, I would also appreciate an approximate solution for $k<<n$.","Consider all connected graphs with $n$ verticies where each vertex connects to $k$ other verticies. We choose such a graph at random. What is the expected value of the shortest path between two random points? What is the expected value of the maximal shortest path? If an exact solution would be too complicated, I would also appreciate an approximate solution for $k<<n$.",,"['probability', 'random-graphs']"
73,Counting Question,Counting Question,,"Been wrestling with the following counting question for about an hour. I will explain my reasoning for counting in the question and I request any BETTER WAY to make this calculation or corrections if my counting is wrong. ""If each coded item in a catalog begins with 3 distinct letters followed by 4 distinct   nonzero digits, find the probability of randomly selecting one of these coded items with the first letter a vowel and the last digit even."" I first calculate the sample space: 26 * 25 * 24 * 9 * 8 * 7 * 6 = 47,174,400 This is done using the simple ""placeholder"" technique for counting. Now I must calculate the special case such that the first letter is a vowel and the last digit even. The ""placeholder"" technique confuses me here. 5 * 25 * 24 * 9 * 8 * 7 * 4 = 6,048,000 So probability  is 6048000/47,174,400. I can't  help but think this is wrong. What about the case where the code has a vowel BEFORE the last vowel, for example. Does this not make the calculation the following: 5 * 25 * 24 * 9 * 8 * 7 * 3 Because one vowel has already been seleccted BEFORE the last vowel... there are fewer choices. Should I need to add up all the permutations in which there is a vowel previous to the last vowel? That seems agonizing... what theorems and rules can I get both the correct and easiest path to the answer? After some Google-ry, I found this explanation for the solution in a textbook. How do they get this? What witchery is this? Why is it so different than the other answers?:","Been wrestling with the following counting question for about an hour. I will explain my reasoning for counting in the question and I request any BETTER WAY to make this calculation or corrections if my counting is wrong. ""If each coded item in a catalog begins with 3 distinct letters followed by 4 distinct   nonzero digits, find the probability of randomly selecting one of these coded items with the first letter a vowel and the last digit even."" I first calculate the sample space: 26 * 25 * 24 * 9 * 8 * 7 * 6 = 47,174,400 This is done using the simple ""placeholder"" technique for counting. Now I must calculate the special case such that the first letter is a vowel and the last digit even. The ""placeholder"" technique confuses me here. 5 * 25 * 24 * 9 * 8 * 7 * 4 = 6,048,000 So probability  is 6048000/47,174,400. I can't  help but think this is wrong. What about the case where the code has a vowel BEFORE the last vowel, for example. Does this not make the calculation the following: 5 * 25 * 24 * 9 * 8 * 7 * 3 Because one vowel has already been seleccted BEFORE the last vowel... there are fewer choices. Should I need to add up all the permutations in which there is a vowel previous to the last vowel? That seems agonizing... what theorems and rules can I get both the correct and easiest path to the answer? After some Google-ry, I found this explanation for the solution in a textbook. How do they get this? What witchery is this? Why is it so different than the other answers?:",,"['probability', 'combinatorics', 'statistics']"
74,What's the probability that an NFL team with a given win/loss record makes the playoffs?,What's the probability that an NFL team with a given win/loss record makes the playoffs?,,"For example, if I know that a team has a record of 11 wins and 5 losses, but no nothing about the records of any other teams, what is the probability that this team makes the playoffs? The current (simplified) NFL rules for playoffs are that the team must either have the best record in its division (three other teams), OR have one of the best two records among teams in the conference that did not win the division. So I suppose what I'm trying to figure out is: What is the probability that at least one out of three teams has a better win-loss record? This is easy if I assume that the win/loss records of each team in the division are independent (they aren't because each team plays each team in the division twice), but how inaccurate will that make the final answer? What is the probability that at least two other teams had a better win/loss record, but did not win their division? I really have no idea where to begin with this. Again, the odds of two teams having a better win/loss record is easy, but I'm not sure how to incorporate them winning their division. (I mentioned 11-5 as an example record, but really I'm trying to solve this in general for any number of wins/losses, teams in a division, divisions, and teams in a conference)","For example, if I know that a team has a record of 11 wins and 5 losses, but no nothing about the records of any other teams, what is the probability that this team makes the playoffs? The current (simplified) NFL rules for playoffs are that the team must either have the best record in its division (three other teams), OR have one of the best two records among teams in the conference that did not win the division. So I suppose what I'm trying to figure out is: What is the probability that at least one out of three teams has a better win-loss record? This is easy if I assume that the win/loss records of each team in the division are independent (they aren't because each team plays each team in the division twice), but how inaccurate will that make the final answer? What is the probability that at least two other teams had a better win/loss record, but did not win their division? I really have no idea where to begin with this. Again, the odds of two teams having a better win/loss record is easy, but I'm not sure how to incorporate them winning their division. (I mentioned 11-5 as an example record, but really I'm trying to solve this in general for any number of wins/losses, teams in a division, divisions, and teams in a conference)",,"['probability', 'statistics']"
75,$P(X \ge 450)$ in Possion distribution,in Possion distribution,P(X \ge 450),"The number of pedestrians that cross the street in one minute has Poisson distribution $\def\Pois{\operatorname{Pois}}\Pois(8)$. Find the probability that at least $450$ pedestrians will cross the street in $1$ hour. The number of pedestrians that cross the street in one hour has $\Pois(480)$ distribution. So, $$\begin{align} P(X \ge 450) & = 1 - P(X < 450) \\ & = 1 - \sum_{i = 0}^{449}\frac{450^i}{i!}e^{-450} \\ & = 1 - e^{-450}\sum_{i = 0}^{449}\frac{450^i}{i!},\end{align}$$ and I am stuck here.","The number of pedestrians that cross the street in one minute has Poisson distribution $\def\Pois{\operatorname{Pois}}\Pois(8)$. Find the probability that at least $450$ pedestrians will cross the street in $1$ hour. The number of pedestrians that cross the street in one hour has $\Pois(480)$ distribution. So, $$\begin{align} P(X \ge 450) & = 1 - P(X < 450) \\ & = 1 - \sum_{i = 0}^{449}\frac{450^i}{i!}e^{-450} \\ & = 1 - e^{-450}\sum_{i = 0}^{449}\frac{450^i}{i!},\end{align}$$ and I am stuck here.",,"['probability', 'probability-distributions']"
76,Linearity of conditional expectation (proof for n joint random variables),Linearity of conditional expectation (proof for n joint random variables),,"Linearity of conditional expectation: I want to prove $$E\left(\sum_{i=1}^n a_i X_i|Y=y\right)=\sum_{i=1}^n a_i~ E(X_i|Y=y)$$ where $X_i, Y$ are random variables and $a_i \in \mathbb{R}$. I tried using induction (the usual, assume it's true for n=k, and prove it for n=k+1), so I get, in the continuous case, $$E\left(\sum_{i=1}^{k+1} a_i X_i|Y=y\right)\\=E\left(\sum_{i=1}^{k} a_i X_i+a_{k+1}X_{k+1}|Y=y\right)\\=\underbrace{\int_{-\infty}^{\infty}...\int_{-\infty}^{\infty}}_{k+1~ \text{integrals}}(a_1x_1+...+a_kx_k+a_{k+1}x_{k+1})~f_{X_1,...,X_k,X_{k+1}|Y}(x_1,...,x_{k+1}|y)~dx_1...dx_{k+1}\\=\underbrace{\int_{-\infty}^{\infty}...\int_{-\infty}^{\infty}}_{k+1~ \text{integrals}}(a_1x_1+...+a_kx_k)~f_{X_1,...,X_k,X_{k+1}|Y}(x_1,...,x_{k+1}|y)~dx_1...dx_{k+1}\\+\underbrace{\int_{-\infty}^{\infty}...\int_{-\infty}^{\infty}}_{k+1~ \text{integrals}}(a_{k+1}x_{k+1})~f_{X_1,...,X_k,X_{k+1}|Y}(x_1,...,x_{k+1}|y)~dx_1...dx_{k+1} $$ On the last step I separated the $(k+1)^{\text{th}}$ ""term"" since I'm trying to find a way to use the induction hypothesis... but I need to do something to get rid of the $(k+1)^{\text{th}}$ integral, as well the $(k+1)^{\text{th}}$ random variable in the underlying conditional distribution I know this is very long to write, I'm just hoping that I can get some hints on how to proceed further (or if there's perhaps a simpler method).","Linearity of conditional expectation: I want to prove $$E\left(\sum_{i=1}^n a_i X_i|Y=y\right)=\sum_{i=1}^n a_i~ E(X_i|Y=y)$$ where $X_i, Y$ are random variables and $a_i \in \mathbb{R}$. I tried using induction (the usual, assume it's true for n=k, and prove it for n=k+1), so I get, in the continuous case, $$E\left(\sum_{i=1}^{k+1} a_i X_i|Y=y\right)\\=E\left(\sum_{i=1}^{k} a_i X_i+a_{k+1}X_{k+1}|Y=y\right)\\=\underbrace{\int_{-\infty}^{\infty}...\int_{-\infty}^{\infty}}_{k+1~ \text{integrals}}(a_1x_1+...+a_kx_k+a_{k+1}x_{k+1})~f_{X_1,...,X_k,X_{k+1}|Y}(x_1,...,x_{k+1}|y)~dx_1...dx_{k+1}\\=\underbrace{\int_{-\infty}^{\infty}...\int_{-\infty}^{\infty}}_{k+1~ \text{integrals}}(a_1x_1+...+a_kx_k)~f_{X_1,...,X_k,X_{k+1}|Y}(x_1,...,x_{k+1}|y)~dx_1...dx_{k+1}\\+\underbrace{\int_{-\infty}^{\infty}...\int_{-\infty}^{\infty}}_{k+1~ \text{integrals}}(a_{k+1}x_{k+1})~f_{X_1,...,X_k,X_{k+1}|Y}(x_1,...,x_{k+1}|y)~dx_1...dx_{k+1} $$ On the last step I separated the $(k+1)^{\text{th}}$ ""term"" since I'm trying to find a way to use the induction hypothesis... but I need to do something to get rid of the $(k+1)^{\text{th}}$ integral, as well the $(k+1)^{\text{th}}$ random variable in the underlying conditional distribution I know this is very long to write, I'm just hoping that I can get some hints on how to proceed further (or if there's perhaps a simpler method).",,"['probability', 'probability-theory']"
77,Probability Question about Tennis Games!,Probability Question about Tennis Games!,,"$2^{n}$ players enter a single elimination tennis tournament. You can assume that the players are of equal ability. Find the probability that two particular players meet each other in the tournament. I could't make a serious attempt on the question, hope you can excuse me this time.","$2^{n}$ players enter a single elimination tennis tournament. You can assume that the players are of equal ability. Find the probability that two particular players meet each other in the tournament. I could't make a serious attempt on the question, hope you can excuse me this time.",,['probability']
78,Density function as derivative (Self-study),Density function as derivative (Self-study),,"I'm trying to do the Society of Actuaries' example problems.  I am having trouble with no. 62, which says: A random variable $X$ has CDF   $$ F(x) =  \begin{cases} 0 & \text{for $x < 1$} \\               \frac{x^2 - 2x + 2}{2} & \text{for $1 \leq x < 2$} \\               1 & \text{for $x \geq 2$} \end{cases} $$   Compute the variance of $X$. I understand the basic steps for computing the variance: Transform the CDF into a density $f$, by differentiating. Compute the expectation $E(X)$ by integrating $x f(x)$ Compute the expectation $E(X^2)$ by integrating $x^2 f(x)$ Compute the variance $V(X) = E(X^2) - E(X)^2$. The problem I'm having is that the density I compute does not match up with the one in the solutions page.  In particular, I get $$f(x) = \begin{cases} x - 1 & \text{for $1 \leq x < 2$}\\                        0     & \text{otherwise} \end{cases} $$ whereas they get $$  f(x) =  \begin{cases} \frac{1}{2} & \text{for $x = 1$} \\               x - 1       & \text{for $1 \leq x < 2$}\\               0           & \text{otherwise} \end{cases} $$ Where is that $\frac{1}{2}$ coming from? Edit:  I corrected the CDF, and now the derivative (if not the density) is correct.","I'm trying to do the Society of Actuaries' example problems.  I am having trouble with no. 62, which says: A random variable $X$ has CDF   $$ F(x) =  \begin{cases} 0 & \text{for $x < 1$} \\               \frac{x^2 - 2x + 2}{2} & \text{for $1 \leq x < 2$} \\               1 & \text{for $x \geq 2$} \end{cases} $$   Compute the variance of $X$. I understand the basic steps for computing the variance: Transform the CDF into a density $f$, by differentiating. Compute the expectation $E(X)$ by integrating $x f(x)$ Compute the expectation $E(X^2)$ by integrating $x^2 f(x)$ Compute the variance $V(X) = E(X^2) - E(X)^2$. The problem I'm having is that the density I compute does not match up with the one in the solutions page.  In particular, I get $$f(x) = \begin{cases} x - 1 & \text{for $1 \leq x < 2$}\\                        0     & \text{otherwise} \end{cases} $$ whereas they get $$  f(x) =  \begin{cases} \frac{1}{2} & \text{for $x = 1$} \\               x - 1       & \text{for $1 \leq x < 2$}\\               0           & \text{otherwise} \end{cases} $$ Where is that $\frac{1}{2}$ coming from? Edit:  I corrected the CDF, and now the derivative (if not the density) is correct.",,"['calculus', 'probability']"
79,Does introducing penalties for getting true/false questions incorrect result in higher skill penetration (less luck/variance)?,Does introducing penalties for getting true/false questions incorrect result in higher skill penetration (less luck/variance)?,,"A student is asked to answer 50 true/false questions and he would get 35 right and 15 incorrect if he had to put his best guesses for each question down. Now, for each question he has a certain confidence of getting the problem correct and if we start imposing penalties for getting a question wrong, he can easily adapt by only answering questions with a confidence level tantamount to the relation [point penalty if wrong]/[point reward if right], and leave all the other one's blank. Is there a way for the test designer to design a reward/penalty scheme that maximizes skill penetration and reduces the role of luck and, if so, what factors does the designer have to look out for? Assume that the test questions have increasing difficulty in a fashion that we cover the full spectrum of confidence on the student. EDIT: Another idea would be to let the student gamble with points. Also setting a limit on each question and a global gambling limit. Is there any reasonable scheme to reduce the role of luck in general on true and false questions?","A student is asked to answer 50 true/false questions and he would get 35 right and 15 incorrect if he had to put his best guesses for each question down. Now, for each question he has a certain confidence of getting the problem correct and if we start imposing penalties for getting a question wrong, he can easily adapt by only answering questions with a confidence level tantamount to the relation [point penalty if wrong]/[point reward if right], and leave all the other one's blank. Is there a way for the test designer to design a reward/penalty scheme that maximizes skill penetration and reduces the role of luck and, if so, what factors does the designer have to look out for? Assume that the test questions have increasing difficulty in a fashion that we cover the full spectrum of confidence on the student. EDIT: Another idea would be to let the student gamble with points. Also setting a limit on each question and a global gambling limit. Is there any reasonable scheme to reduce the role of luck in general on true and false questions?",,"['probability', 'statistics', 'soft-question', 'education', 'game-theory']"
80,Joint probability of geometric random variables,Joint probability of geometric random variables,,"$X$ and $Y$ are geometric, independent random variables with parameters $x$ and $y$ respectively. Use their joint P.M.F. to compute an approximate summation for $P(X<Y)$. I've setup the problem: $\sum_{i=1}^j \sum_{j=j}^\infty x(1-x)^{i-1} y(y-1)^{j-1}$ But I have no idea how to simplify further from here.","$X$ and $Y$ are geometric, independent random variables with parameters $x$ and $y$ respectively. Use their joint P.M.F. to compute an approximate summation for $P(X<Y)$. I've setup the problem: $\sum_{i=1}^j \sum_{j=j}^\infty x(1-x)^{i-1} y(y-1)^{j-1}$ But I have no idea how to simplify further from here.",,"['probability', 'statistics']"
81,Combinatorics Distribution - Number of integer solutions Concept Explanation,Combinatorics Distribution - Number of integer solutions Concept Explanation,,"I reading my textbook and I don't understand the concept of distributions or number of solutions to an equation.  It's explained that this problem is 1/4 types of sampling/distributions problems.  An example is provided to illustrate: In how many ways can 4 identical jobs (indistinguishable balls) be distributed among 26 members (urns) without exclusion (since one member can do multiple jobs)? A sample outcome might be: $\text{_____________}$ |  A  |  B  |  C  |...|  Z  | $\text{--------------------}$ $\text{_____________}$ |  o  | oo|    |   |    ||| o  | $\text{_____________}$ |  A  |  B  |  C  |...  |  Z  | $\text{--------------------}$ Thus, the question is reduced to, ""How many $(26-1+4)$ letter words are there consisting of four circles and $(26-1)$ vertical lines?""  Therefore, the solution is:  $\binom{26-1+4}{4}$ I really don't understand why its $(26-1+4)$.  There's only 26 different spots or ""urns"" to place the 4 jobs.  Can someone please explain? I looked through another text to try and understand and I found it explained as such: There are $\binom{n+r-1}{r-1}$ distinct nonnegative integer valued vectors $(x_1,...,x_r$ satisfying the equation $(x_1 + ... + x_r = x_n$ for $x\ge0$. $\spadesuit$ How in the world are they deriving this?  For distinct positive integers I understand: Assume I have 8 balls (n=8) and I have 3 urns (r=3): o^o^o^o^o^o^o^o, where o represents  a ball and ^ represents a place holder where an urn could be placed.  For this scenario: There are $\binom{n-1}{r-1}$ distinct positive integer valued vectors $(x_1,...,x_n)$ satisfying the equation:  $x_1 + ... + x_n = n, x_i>0, i=1,..,r$ $\clubsuit$ It's clear that I could have this specific case ooo|ooo|oo.  Here the bar represents a divide for the urn and you see I have 3 sections.  So that case is clear.  Can anyone please explain this problem to me?  I don't understand the nonnegative integer case. Also, people who post tend to be crazy smart and explain things very in a complicated manner.  I'd appreciate it if it could be explained in layman's terms as much as possible. Thank you!!!","I reading my textbook and I don't understand the concept of distributions or number of solutions to an equation.  It's explained that this problem is 1/4 types of sampling/distributions problems.  An example is provided to illustrate: In how many ways can 4 identical jobs (indistinguishable balls) be distributed among 26 members (urns) without exclusion (since one member can do multiple jobs)? A sample outcome might be: $\text{_____________}$ |  A  |  B  |  C  |...|  Z  | $\text{--------------------}$ $\text{_____________}$ |  o  | oo|    |   |    ||| o  | $\text{_____________}$ |  A  |  B  |  C  |...  |  Z  | $\text{--------------------}$ Thus, the question is reduced to, ""How many $(26-1+4)$ letter words are there consisting of four circles and $(26-1)$ vertical lines?""  Therefore, the solution is:  $\binom{26-1+4}{4}$ I really don't understand why its $(26-1+4)$.  There's only 26 different spots or ""urns"" to place the 4 jobs.  Can someone please explain? I looked through another text to try and understand and I found it explained as such: There are $\binom{n+r-1}{r-1}$ distinct nonnegative integer valued vectors $(x_1,...,x_r$ satisfying the equation $(x_1 + ... + x_r = x_n$ for $x\ge0$. $\spadesuit$ How in the world are they deriving this?  For distinct positive integers I understand: Assume I have 8 balls (n=8) and I have 3 urns (r=3): o^o^o^o^o^o^o^o, where o represents  a ball and ^ represents a place holder where an urn could be placed.  For this scenario: There are $\binom{n-1}{r-1}$ distinct positive integer valued vectors $(x_1,...,x_n)$ satisfying the equation:  $x_1 + ... + x_n = n, x_i>0, i=1,..,r$ $\clubsuit$ It's clear that I could have this specific case ooo|ooo|oo.  Here the bar represents a divide for the urn and you see I have 3 sections.  So that case is clear.  Can anyone please explain this problem to me?  I don't understand the nonnegative integer case. Also, people who post tend to be crazy smart and explain things very in a complicated manner.  I'd appreciate it if it could be explained in layman's terms as much as possible. Thank you!!!",,"['probability', 'combinatorics', 'probability-theory']"
82,Conditional Probability or Intersection - Second Problem,Conditional Probability or Intersection - Second Problem,,"The question that I asked at Is the Event a Conditional Probability or an Intersection? may be similar, but I'm confused over the following question from a different textbook. I'd be shocked if two textbooks make the same mistake! It's Example 2e on P61 and 62 in A First Course in Pr , 8th ed, by Sheldon Ross. Problem: I'm undecided as to whether to take French or chemistry. I estimate that the probability of receiving an A grade would be $\frac{1}{2}$ in French and $\frac{2}{3}$ in chemistry. If I decide based on the flip of a fair coin, what's the probability that I get an A in chemistry? Given Solution: Let $C$ be the event that I take chemistry and $A$ denote the event that I receive an A in whatever course I take. Then the desired probability is: $Pr(A \cap C) = Pr(C)Pr(A|C) = (1/2)(2/3) $ . $ \Large 1.$ Why is the probability that I get an A in chemistry $Pr(A \cap C)$ and NOT $Pr(A|C)$ ? How do I decide which is right? $ \Large 2.$ Why is $\frac{2}{3} = Pr(A|C)$ and NOT $Pr(A \cap C)$ ? How do I decide which is right?","The question that I asked at Is the Event a Conditional Probability or an Intersection? may be similar, but I'm confused over the following question from a different textbook. I'd be shocked if two textbooks make the same mistake! It's Example 2e on P61 and 62 in A First Course in Pr , 8th ed, by Sheldon Ross. Problem: I'm undecided as to whether to take French or chemistry. I estimate that the probability of receiving an A grade would be in French and in chemistry. If I decide based on the flip of a fair coin, what's the probability that I get an A in chemistry? Given Solution: Let be the event that I take chemistry and denote the event that I receive an A in whatever course I take. Then the desired probability is: . Why is the probability that I get an A in chemistry and NOT ? How do I decide which is right? Why is and NOT ? How do I decide which is right?",\frac{1}{2} \frac{2}{3} C A Pr(A \cap C) = Pr(C)Pr(A|C) = (1/2)(2/3)   \Large 1. Pr(A \cap C) Pr(A|C)  \Large 2. \frac{2}{3} = Pr(A|C) Pr(A \cap C),[]
83,Notation for $X - \mathbb{E}(X)$?,Notation for ?,X - \mathbb{E}(X),"Let $X$ be a random variable with expectation value $\mathbb{E}(X)=\mu$. Is there a (reasonably standard) notation to denote the ""centered"" random variable $X - \mu$? And, while I'm at it, if $X_i$ is a random variable, $\forall\,i \in \mathbf{n} \equiv \{0,\dots,n-1\}$, and if $\overline{X} = \frac{1}{n}\sum_{i\in\mathbf{n}} X_i$, is there a notation for the random variable $X_i - \overline{X}$?  (This second question is ""secondary"".  Feel free to disregard it.)","Let $X$ be a random variable with expectation value $\mathbb{E}(X)=\mu$. Is there a (reasonably standard) notation to denote the ""centered"" random variable $X - \mu$? And, while I'm at it, if $X_i$ is a random variable, $\forall\,i \in \mathbf{n} \equiv \{0,\dots,n-1\}$, and if $\overline{X} = \frac{1}{n}\sum_{i\in\mathbf{n}} X_i$, is there a notation for the random variable $X_i - \overline{X}$?  (This second question is ""secondary"".  Feel free to disregard it.)",,"['probability', 'statistics', 'notation', 'convention']"
84,Softmax function and modelling probability distributions,Softmax function and modelling probability distributions,,"Hinton in his neural network course on Coursera says that ""Any probability distribution P over discrete states (P(x) > 0 for all x) can be represented as the output of a softmax unit for some inputs."" I was trying to prove it but didn't manage. Do you know of a proof of this?","Hinton in his neural network course on Coursera says that ""Any probability distribution P over discrete states (P(x) > 0 for all x) can be represented as the output of a softmax unit for some inputs."" I was trying to prove it but didn't manage. Do you know of a proof of this?",,"['probability', 'probability-distributions', 'pattern-recognition']"
85,"If $A\subseteq B$, can $A$ and $B$ be independent?","If , can  and  be independent?",A\subseteq B A B,"I know that in probability theory, to say that two events are independent  means that the occurrence of one does not affect the probability of the other. But if $A$ is a subset of $B$, then $A$ and $B$ are not independent right? Also I do not understand the second part at all. Can somebody help me out?","I know that in probability theory, to say that two events are independent  means that the occurrence of one does not affect the probability of the other. But if $A$ is a subset of $B$, then $A$ and $B$ are not independent right? Also I do not understand the second part at all. Can somebody help me out?",,['probability']
86,Distribution of largest sample from normal distribution.,Distribution of largest sample from normal distribution.,,"Given $n$ independent random variables $X_i$ with normal distribution, mean $\mu$, variance $\sigma^2$, what is the distribution of $\max\limits_{i=1}^n(X_i)$ ? In particular I am interested in whether it would be Normal or close to Normal as well, and what the mean and variance would be.","Given $n$ independent random variables $X_i$ with normal distribution, mean $\mu$, variance $\sigma^2$, what is the distribution of $\max\limits_{i=1}^n(X_i)$ ? In particular I am interested in whether it would be Normal or close to Normal as well, and what the mean and variance would be.",,"['probability', 'normal-distribution']"
87,(yet another) length of random segment,(yet another) length of random segment,,"Take a random point $Z$, i.d. in [0,1], which defines a stick. Break the stick in two, (random i.d.). Take the left part of the broken stick and break it again in two (i.d.) You thus obtain three sticks. What is the expected length of the stick where $Z$ is located? (Prove its $5/9$. Can you come up with an intuitive reason for that?) Generalise for n breaks of the stick in the left (i.e. always breaking the segment near the origin). (Edit: solution was found analytically and tested on MC simulation. would be interesting to see if there is an intuitive reason though.) // (Hope you enjoyed this series of puzzles - this was the last one!)","Take a random point $Z$, i.d. in [0,1], which defines a stick. Break the stick in two, (random i.d.). Take the left part of the broken stick and break it again in two (i.d.) You thus obtain three sticks. What is the expected length of the stick where $Z$ is located? (Prove its $5/9$. Can you come up with an intuitive reason for that?) Generalise for n breaks of the stick in the left (i.e. always breaking the segment near the origin). (Edit: solution was found analytically and tested on MC simulation. would be interesting to see if there is an intuitive reason though.) // (Hope you enjoyed this series of puzzles - this was the last one!)",,['probability']
88,Asymptotics of system of linear equations,Asymptotics of system of linear equations,,I have a system of linear equations as follows. $$M(p) = 1+\frac{n-p-1}{n}M(n-1) + \frac{2}{n} N(p-1) + \frac{p-1}{n}M(p-1)$$    $$N(p) = 1+\frac{n-p-1}{n}M(n-1) + \frac{p}{n}N(p-1)$$    $$M(1) = 1+\frac{n-2}{n}M(n-1) + \frac{2}{n}N(0)$$    $$N(0) = 1+\frac{n-1}{n}M(n-1)$$ $M(p)$ is defined for $1 \leq p \leq n-1$.  $N(p)$ is defined for $0 \leq p \leq n-2$.  What is $M(n-1)$?,I have a system of linear equations as follows. $$M(p) = 1+\frac{n-p-1}{n}M(n-1) + \frac{2}{n} N(p-1) + \frac{p-1}{n}M(p-1)$$    $$N(p) = 1+\frac{n-p-1}{n}M(n-1) + \frac{p}{n}N(p-1)$$    $$M(1) = 1+\frac{n-2}{n}M(n-1) + \frac{2}{n}N(0)$$    $$N(0) = 1+\frac{n-1}{n}M(n-1)$$ $M(p)$ is defined for $1 \leq p \leq n-1$.  $N(p)$ is defined for $0 \leq p \leq n-2$.  What is $M(n-1)$?,,"['linear-algebra', 'probability']"
89,Question about Benford's law,Question about Benford's law,,"A set of numbers is said to satisfy Benford's law if the leading digit d (d ∈ {1, ..., 9}) occurs with probability, $$ P(d)=\log_{10}(d+1)-\log_{10}d$$ With Birkhoff's Ergodic Theorem  is possible to prove that the sequence $2^n$( for example) satisfies the Benford's law. The Fibonacci sequence satisfies Berford's law?","A set of numbers is said to satisfy Benford's law if the leading digit d (d ∈ {1, ..., 9}) occurs with probability, $$ P(d)=\log_{10}(d+1)-\log_{10}d$$ With Birkhoff's Ergodic Theorem  is possible to prove that the sequence $2^n$( for example) satisfies the Benford's law. The Fibonacci sequence satisfies Berford's law?",,['probability']
90,Finding the exact stationary distribution for a biased random walk on a bounded interval,Finding the exact stationary distribution for a biased random walk on a bounded interval,,"Imagine we have a biased random walk on an interval $[0, L]$, where the probability of taking a $+1$ step is $p$ and the probability of taking a $-1$ step is $(1-p)$.  At the reflecting boundary $0$, the walker will take a $+1$ step with probability $p$ or remain in place, and at the reflecting boundary $L$, the walker will take a $-1$ step with probability $(1-p)$ or remain in place. My guess is that having some $+1$ step probability of $p$ and $-1$ step probability of $q$, where $(p + q) < 1$, would make no difference, that what matters is the ratio $\frac{p}{q}$. Is it possible to find an exact stationary distribution for this Markov process by solving the following recurrence relations?: $P(X=0) = (1-p)P(X=0) + (1-p)P(X=1)$ $P(X=L) = pP(X=L-1) + p(X=L)$ $P(X=n) = pP(X=n-1) + (1-p)P(X=n+1)$ Where: $0 < n < L$ If anyone is able to find a solution, please do let me know what techniques you used!  I haven't made much traction here myself, and I'd actually like to learn how to solve these sorts of constant coefficient recurrence relation problems. For the user Henry's exact solution for the above problem without the reflecting boundary at $L$: $\pi(X=n) = (\frac{p}{q})^n(1-\frac{p}{q})$ Please see: Probability distribution for the position of a biased random walker on the positive integers","Imagine we have a biased random walk on an interval $[0, L]$, where the probability of taking a $+1$ step is $p$ and the probability of taking a $-1$ step is $(1-p)$.  At the reflecting boundary $0$, the walker will take a $+1$ step with probability $p$ or remain in place, and at the reflecting boundary $L$, the walker will take a $-1$ step with probability $(1-p)$ or remain in place. My guess is that having some $+1$ step probability of $p$ and $-1$ step probability of $q$, where $(p + q) < 1$, would make no difference, that what matters is the ratio $\frac{p}{q}$. Is it possible to find an exact stationary distribution for this Markov process by solving the following recurrence relations?: $P(X=0) = (1-p)P(X=0) + (1-p)P(X=1)$ $P(X=L) = pP(X=L-1) + p(X=L)$ $P(X=n) = pP(X=n-1) + (1-p)P(X=n+1)$ Where: $0 < n < L$ If anyone is able to find a solution, please do let me know what techniques you used!  I haven't made much traction here myself, and I'd actually like to learn how to solve these sorts of constant coefficient recurrence relation problems. For the user Henry's exact solution for the above problem without the reflecting boundary at $L$: $\pi(X=n) = (\frac{p}{q})^n(1-\frac{p}{q})$ Please see: Probability distribution for the position of a biased random walker on the positive integers",,"['probability', 'markov-chains']"
91,How to prove these two random variables are independent?,How to prove these two random variables are independent?,,"If $X$ and $Y$ are independent Gamma random variables with parameters $(\alpha,\lambda)$ and $(\beta,\lambda)$ respectively, how to show that $U=X+Y$ and $V=X/(X+Y)$ are independent?","If $X$ and $Y$ are independent Gamma random variables with parameters $(\alpha,\lambda)$ and $(\beta,\lambda)$ respectively, how to show that $U=X+Y$ and $V=X/(X+Y)$ are independent?",,"['probability', 'probability-distributions']"
92,Approximation of binomial distribution with normal distribution,Approximation of binomial distribution with normal distribution,,"The Central Limit Theorem implies that near the center of mass we can approximate the binomial distribution with the normal distribution: $$ P(B(n,p) \geq i) \approx P(Z \geq \frac{i - n p}{\sqrt{n p (1-p)}}) $$ where $Z$ is the standard normal. I am interested in cases where $n \rightarrow \infty$ while $p$ remains constant. However, I am integrating a function over all integers $i$, so I cannot assume that $i$ itself is bounded. So the standard Central Limit Theorem, which only asserts that the above approximation holds pointwise in the limit, is not adequate for me. Are there any references which give explicit (or asymptotic) error estimates for this type of approximation?","The Central Limit Theorem implies that near the center of mass we can approximate the binomial distribution with the normal distribution: $$ P(B(n,p) \geq i) \approx P(Z \geq \frac{i - n p}{\sqrt{n p (1-p)}}) $$ where $Z$ is the standard normal. I am interested in cases where $n \rightarrow \infty$ while $p$ remains constant. However, I am integrating a function over all integers $i$, so I cannot assume that $i$ itself is bounded. So the standard Central Limit Theorem, which only asserts that the above approximation holds pointwise in the limit, is not adequate for me. Are there any references which give explicit (or asymptotic) error estimates for this type of approximation?",,"['probability', 'probability-distributions', 'asymptotics']"
93,"I have 2 tosses of a die, $X$ is the $\min$ and $Y$ is the $\max$","I have 2 tosses of a die,  is the  and  is the",X \min Y \max,"If we let $X_1$ be the toss of the first die, and $X_2$ be the toss of the second die, and as stated in the title, $X=\min(X_1,X_2)$ and $Y=\max(X_1,X_2)$. I'm asked to find $E(Y|X=x)$ and I know that it's $$\sum_{y=1}^6yP(Y=y|X=x)$$ But I'm just a little stuck on the conditional probability part. I know that when $x=1$ the expected value is $\frac{41}{11}$ but I don't understand how that is. I keep getting $\frac{41}{36}$, because $$\begin{align}&\sum_{y=1}^6yP(Y=y|X=1)\\ &\qquad=1\left(\frac{1}{36}\right)+2\left(\frac{2}{36}\right)+3\left(\frac{2}{36}\right)+4\left(\frac{2}{36}\right)+5\left(\frac{2}{36}\right)+6\left(\frac{2}{36}\right)\\ &\qquad=\frac{41}{36}\end{align}$$ Where did I go wrong?","If we let $X_1$ be the toss of the first die, and $X_2$ be the toss of the second die, and as stated in the title, $X=\min(X_1,X_2)$ and $Y=\max(X_1,X_2)$. I'm asked to find $E(Y|X=x)$ and I know that it's $$\sum_{y=1}^6yP(Y=y|X=x)$$ But I'm just a little stuck on the conditional probability part. I know that when $x=1$ the expected value is $\frac{41}{11}$ but I don't understand how that is. I keep getting $\frac{41}{36}$, because $$\begin{align}&\sum_{y=1}^6yP(Y=y|X=1)\\ &\qquad=1\left(\frac{1}{36}\right)+2\left(\frac{2}{36}\right)+3\left(\frac{2}{36}\right)+4\left(\frac{2}{36}\right)+5\left(\frac{2}{36}\right)+6\left(\frac{2}{36}\right)\\ &\qquad=\frac{41}{36}\end{align}$$ Where did I go wrong?",,"['probability', 'probability-theory']"
94,Expected number of cards fixed in a deck after a certain operation,Expected number of cards fixed in a deck after a certain operation,,"Problem: Given a standard deck of $52$ cards, extract 26 of the cards at random in one of the $52 \choose{26}$ possible ways and place them on the top of the deck is the same relative order as they were before being selected. What is the expected number of cards that now occupy the same position in the deck as before? This nice problem is due to Jim Propp.","Problem: Given a standard deck of $52$ cards, extract 26 of the cards at random in one of the $52 \choose{26}$ possible ways and place them on the top of the deck is the same relative order as they were before being selected. What is the expected number of cards that now occupy the same position in the deck as before? This nice problem is due to Jim Propp.",,"['probability', 'problem-solving']"
95,Probability for #suits in 5 card poker hand,Probability for #suits in 5 card poker hand,,"Given a 5 card poker hand from a standard deck, I'm looking to calculate the probability of getting: all 1 suit, 2 different suits, 3 different suits or 4 different suits.  All one suit is straight-forward -  $\frac{\binom{13}{5}*\binom{4}{1}}{\binom{52}{5}}$- pick five different ranks, each from the same suit. Likewise, 4 seems fairly simple: $\frac{\binom{4}{1}\binom{13}{2}\binom{13}{1}^3}{\binom{52}{5}}$ - pick one suit to grab two cards from, then pick one card from each other suit. Its on 2 and 3 that I get kind of stuck - I'm not sure how to set them up! I don't see why something along the lines of $\frac{\binom{4}{2}*\binom{26}{6} - \binom{13}{5}*\binom{4}{1}}{\binom{52}{5}}$ doesn't work for 2 suits; i.e. picking 2 suits, choose 5 cards, subtracting off the ways in which you could end up with one suit.  Similarly, for 3 I would expect $\frac{\binom{4}{3}*\binom{39}{5}-\binom{4}{2}*\binom{26}{5}}{\binom{52}{5}}$ to give the answer (picking 5 cards from the group containing 3 suits, subtracting off those hands with fewer than 3 suits), but if I sum the probabilities it comes out incorrectly. Thank you very much for your help!","Given a 5 card poker hand from a standard deck, I'm looking to calculate the probability of getting: all 1 suit, 2 different suits, 3 different suits or 4 different suits.  All one suit is straight-forward -  $\frac{\binom{13}{5}*\binom{4}{1}}{\binom{52}{5}}$- pick five different ranks, each from the same suit. Likewise, 4 seems fairly simple: $\frac{\binom{4}{1}\binom{13}{2}\binom{13}{1}^3}{\binom{52}{5}}$ - pick one suit to grab two cards from, then pick one card from each other suit. Its on 2 and 3 that I get kind of stuck - I'm not sure how to set them up! I don't see why something along the lines of $\frac{\binom{4}{2}*\binom{26}{6} - \binom{13}{5}*\binom{4}{1}}{\binom{52}{5}}$ doesn't work for 2 suits; i.e. picking 2 suits, choose 5 cards, subtracting off the ways in which you could end up with one suit.  Similarly, for 3 I would expect $\frac{\binom{4}{3}*\binom{39}{5}-\binom{4}{2}*\binom{26}{5}}{\binom{52}{5}}$ to give the answer (picking 5 cards from the group containing 3 suits, subtracting off those hands with fewer than 3 suits), but if I sum the probabilities it comes out incorrectly. Thank you very much for your help!",,"['probability', 'card-games']"
96,Possible combinations for 20 character alphanumeric identifier,Possible combinations for 20 character alphanumeric identifier,,"I need to know the total possible unique variations there can be on an identifier that is made up of 20 alphanumeric characters, where the characters are A to Z (all upper case), and the digits 0 to 9.","I need to know the total possible unique variations there can be on an identifier that is made up of 20 alphanumeric characters, where the characters are A to Z (all upper case), and the digits 0 to 9.",,['probability']
97,Joint density of the smallest and largest random variables among finite independent random variables with common density,Joint density of the smallest and largest random variables among finite independent random variables with common density,,"I am trying to show the following result. Let $X_1, \ldots,X_n$ be independent random variables with the common density $f$ and distribution function $F$. If $X$ is the smallest and $Y$ the largest among them, the joint density of the pair $(X, Y)$ for $y>x$ is given by $$n(n-1)f(x)f(y)[F(y)-F(x)]^{n-2}$$ Some thoughts towards a partial solution Attempt 1: Given they all share the same density, the Joint density can be calculated as $$f_{X,Y}( x,y) = f_{Y\mid X}( y\mid x) f( x) = f_{X\mid Y}( x\mid y) f( y)$$ So we can choose $x$ in $n$ ways and fixing $x$, we can pick the maximum random variable as $C_{1}^{n-1} = (n-1)$ so this explains $n(n-1)f(x)f(y)$ part but i am unsure why we have the difference of the distribution functions of the $y$ and $x$ times $(n-2)$. i know we have $n-2$ variables to still account for and they are being integrated out. Hence we should have $(n-2)$ terms but why the difference ? Attempt 2: The sample space corresponding to $X_1, \ldots,X_n$ is the $n$-dimensional hypercube $\Gamma $ defined by $x_k=f$ and the probabilities equal the $n$-dimensional volume. The natural sample space with the $X_k$ as coordinate variables is the subset $\Omega$ of $\Gamma$ containing all points such that $x_1\leq \cdots \leq x_n$. The hypercube contains $n!$ congruent replicas of the set $\Omega$ and in each the ordered $n$-tuple $(X_1,\ldots,X_n)$ coincides with a fixed permutation of $X_1,\ldots, X_n$. I am not sure i am getting anywhere with these thoughts. Any help would be much appreciated.","I am trying to show the following result. Let $X_1, \ldots,X_n$ be independent random variables with the common density $f$ and distribution function $F$. If $X$ is the smallest and $Y$ the largest among them, the joint density of the pair $(X, Y)$ for $y>x$ is given by $$n(n-1)f(x)f(y)[F(y)-F(x)]^{n-2}$$ Some thoughts towards a partial solution Attempt 1: Given they all share the same density, the Joint density can be calculated as $$f_{X,Y}( x,y) = f_{Y\mid X}( y\mid x) f( x) = f_{X\mid Y}( x\mid y) f( y)$$ So we can choose $x$ in $n$ ways and fixing $x$, we can pick the maximum random variable as $C_{1}^{n-1} = (n-1)$ so this explains $n(n-1)f(x)f(y)$ part but i am unsure why we have the difference of the distribution functions of the $y$ and $x$ times $(n-2)$. i know we have $n-2$ variables to still account for and they are being integrated out. Hence we should have $(n-2)$ terms but why the difference ? Attempt 2: The sample space corresponding to $X_1, \ldots,X_n$ is the $n$-dimensional hypercube $\Gamma $ defined by $x_k=f$ and the probabilities equal the $n$-dimensional volume. The natural sample space with the $X_k$ as coordinate variables is the subset $\Omega$ of $\Gamma$ containing all points such that $x_1\leq \cdots \leq x_n$. The hypercube contains $n!$ congruent replicas of the set $\Omega$ and in each the ordered $n$-tuple $(X_1,\ldots,X_n)$ coincides with a fixed permutation of $X_1,\ldots, X_n$. I am not sure i am getting anywhere with these thoughts. Any help would be much appreciated.",,"['probability', 'combinatorics', 'geometry', 'probability-distributions']"
98,When should I grab a bag of money?,When should I grab a bag of money?,,"100 small bags of coins are placed in a large cauldron. The 99 of these bags that contain pennies have the same size. The single small bag of quarters is twice the size of a single bag of pennies. The probability of grabbing each bag is proportional to its size. 100 people get to each randomly grab a bag from this cauldron. If I want to grab the bag of quarters, when I should I grab a bag? For instance, should I do it first? Second? Last? My current hunch is that it does not matter. After all, the bags are randomly distributed, so this scenario should be no different from someone just randomly distributing all the bags at the same time. Is this reasoning sound?","100 small bags of coins are placed in a large cauldron. The 99 of these bags that contain pennies have the same size. The single small bag of quarters is twice the size of a single bag of pennies. The probability of grabbing each bag is proportional to its size. 100 people get to each randomly grab a bag from this cauldron. If I want to grab the bag of quarters, when I should I grab a bag? For instance, should I do it first? Second? Last? My current hunch is that it does not matter. After all, the bags are randomly distributed, so this scenario should be no different from someone just randomly distributing all the bags at the same time. Is this reasoning sound?",,['probability']
99,What's the probability that one goldfish eats more than 2 pellets?,What's the probability that one goldfish eats more than 2 pellets?,,"I scatter 10 pellets among the 7 goldfish in my tank. Assuming each goldfish has equal probability of obtaining any pellet, what is the probability that at least one goldfish eats over 2 pellets? I tried to solve this problem by asking the reverse question: What is the probability that no goldfish eats over 2 pellets? And then complementing the solution. However, I couldn't find how this latter question is easier to solve. I am thinking about manually drawing out the possibilities, but figured that'd take long (7 is a lot of fish).","I scatter 10 pellets among the 7 goldfish in my tank. Assuming each goldfish has equal probability of obtaining any pellet, what is the probability that at least one goldfish eats over 2 pellets? I tried to solve this problem by asking the reverse question: What is the probability that no goldfish eats over 2 pellets? And then complementing the solution. However, I couldn't find how this latter question is easier to solve. I am thinking about manually drawing out the possibilities, but figured that'd take long (7 is a lot of fish).",,['probability']
