,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,showing $\|x\| \leq \lim_{n\to \infty} \inf \|x_n\|$,showing,\|x\| \leq \lim_{n\to \infty} \inf \|x_n\|,"showing $$\|x\| \leq \lim_{n\to \infty} \inf \|x_n\|$$ where $x_n \to x$ weakly, and we are working under a normed space. I am given a hint that $$\|x\| = \sup_{\|\phi\| = 1} |\phi(x)|$$ where $\phi \in X^\star$. My idea was to choose $\phi$ s.t. $\phi(x) = \|x\|$, and somehow use the hint. The hint however says that for this particular phi we have that $\|x\| \geq |\phi(x)| = \lim_{n \to \infty} |\phi(x_n)|$ which already is in the incorrect direction. Any guidance please.","showing $$\|x\| \leq \lim_{n\to \infty} \inf \|x_n\|$$ where $x_n \to x$ weakly, and we are working under a normed space. I am given a hint that $$\|x\| = \sup_{\|\phi\| = 1} |\phi(x)|$$ where $\phi \in X^\star$. My idea was to choose $\phi$ s.t. $\phi(x) = \|x\|$, and somehow use the hint. The hint however says that for this particular phi we have that $\|x\| \geq |\phi(x)| = \lim_{n \to \infty} |\phi(x_n)|$ which already is in the incorrect direction. Any guidance please.",,"['calculus', 'real-analysis', 'functional-analysis', 'normed-spaces']"
1,The algebraic dual space of a TVS is complete,The algebraic dual space of a TVS is complete,,"(Treves Exercise 5.4) Let $E$ be a TVS and $E^*$ its algebraic dual. Provide $E^*$ with the topology of pointwise convergence in $E$. A basis of neighborhoods of zero in this topology is provided by the sets   $$W(S,\epsilon) = \left\{x^* \in E^* : \sup\limits_{x\in S} |x^*(x)| \leq \epsilon\right\} $$   as $S$ ranges over the family of finite subsets of $E$ and $\epsilon$ over the set of numbers $>$ 0. Prove that $E^*$ is complete. This is what I have so far: Let $\mathscr{F}$ be a Cauchy filter on $E^*$. Define $\Phi_x:E^* \rightarrow \mathbb{C}$ by $$\Phi_x(x^*) = x^*(x). $$ Then $\Phi_x$ is continuous and linear, which implies $\Phi_x$ is uniformly continuous. Hence $\Phi_x\mathscr{F}$ is a Cauchy filter on $\mathbb{C}$. But $\mathbb{C}$ is complete, so there exists a $\lambda_x \in \mathbb{C}$ such that $\Phi_x\mathscr{F} \rightarrow \lambda_x$. This defines a function $\varphi^*:E\rightarrow \mathbb{C}$ by $\varphi^*(x) = \lambda_x$. How can I show that $\varphi^*$ is linear so that $\varphi^* \in E^*$? Also, how would I show $\mathscr{F} \rightarrow \varphi^*$?","(Treves Exercise 5.4) Let $E$ be a TVS and $E^*$ its algebraic dual. Provide $E^*$ with the topology of pointwise convergence in $E$. A basis of neighborhoods of zero in this topology is provided by the sets   $$W(S,\epsilon) = \left\{x^* \in E^* : \sup\limits_{x\in S} |x^*(x)| \leq \epsilon\right\} $$   as $S$ ranges over the family of finite subsets of $E$ and $\epsilon$ over the set of numbers $>$ 0. Prove that $E^*$ is complete. This is what I have so far: Let $\mathscr{F}$ be a Cauchy filter on $E^*$. Define $\Phi_x:E^* \rightarrow \mathbb{C}$ by $$\Phi_x(x^*) = x^*(x). $$ Then $\Phi_x$ is continuous and linear, which implies $\Phi_x$ is uniformly continuous. Hence $\Phi_x\mathscr{F}$ is a Cauchy filter on $\mathbb{C}$. But $\mathbb{C}$ is complete, so there exists a $\lambda_x \in \mathbb{C}$ such that $\Phi_x\mathscr{F} \rightarrow \lambda_x$. This defines a function $\varphi^*:E\rightarrow \mathbb{C}$ by $\varphi^*(x) = \lambda_x$. How can I show that $\varphi^*$ is linear so that $\varphi^* \in E^*$? Also, how would I show $\mathscr{F} \rightarrow \varphi^*$?",,"['functional-analysis', 'topological-vector-spaces']"
2,Equation demonstration,Equation demonstration,,"Let $\delta f \equiv \frac{\Delta f}{f}$ show that: $$\matrix{\delta(xy) &=& \delta x + \delta y\\ \delta(x/y) &=& \delta x - \delta y\\ \delta(x+y) &=& \frac{x}{x+y}{\delta x} + \frac{y}{x+y}{\delta y}}$$ Using floating point arithmetics, I am trying to demonstrate those formulas. For the first formula, I have tried something like this: I know that $f(xy)= f(x)f(y)$ $$\Delta f \approx \sum_{i=1}^n\Delta x_i \frac{\partial f}{\partial x}$$ But I got stuck even at the first equation. Any guidance, example or help would be appreciated.","Let $\delta f \equiv \frac{\Delta f}{f}$ show that: $$\matrix{\delta(xy) &=& \delta x + \delta y\\ \delta(x/y) &=& \delta x - \delta y\\ \delta(x+y) &=& \frac{x}{x+y}{\delta x} + \frac{y}{x+y}{\delta y}}$$ Using floating point arithmetics, I am trying to demonstrate those formulas. For the first formula, I have tried something like this: I know that $f(xy)= f(x)f(y)$ $$\Delta f \approx \sum_{i=1}^n\Delta x_i \frac{\partial f}{\partial x}$$ But I got stuck even at the first equation. Any guidance, example or help would be appreciated.",,"['analysis', 'functional-analysis', 'numerical-methods', 'floating-point']"
3,Does an essentially self-adjoint operator have the same kernel as its closure?,Does an essentially self-adjoint operator have the same kernel as its closure?,,"Let $H$ be a Hilbert space and let $A : D(A) \subset H \to H$ be an essentially self-adjoint operator. Let $\overline A$ be the unique self-adjoint extension of $A$. Question: Is it true that $\ker(A) = \ker(\overline A)$? I don't really see any reason for this to be true, so I tried constructing a counterexample... but somehow this is not so easy to do! For instance, I tried starting with the negative Laplacian $\Delta = - \frac{d^2}{dx^2}$ on $L^2(S^1)$ with domain $\mathrm{dom}(\Delta) = C^\infty(S^1)$. This is an essentially self-adjoint operator and the closure $\overline \Delta$ is easily understood if we look to the frequency domain. On $\ell^2(\mathbb{Z})$, we find $\overline \Delta$ is conjugate to the diagonal operator $D$ on $\ell^2(\mathbb{Z})$ given by $D(a_n) = (n^2a_n)$ and with domain $\{ (a_n) \in \ell^2(\mathbb{Z}) : (na_n) \in \ell^2(\mathbb{Z})\}$. From this, we conclude that $\Delta$ and $\overline \Delta$ have the same one-dimensional kernel.  $$\ker(\Delta) = \ker(\overline \Delta) = \{\text{constant functions}\} \subset L^2(S^1).$$ Next I tried to replace $\Delta$ by its restriction $\Delta_S$ to some smaller subspace $S \subset C^\infty(S^1)$ such that $S$ intersects trivially with the constant functions, but still manages to be a core for $\Delta$, i.e. has $\overline \Delta_S = \overline \Delta$. However, every subspace $S$ like this I try turns out to give a non essentially self-adjoint $\Delta_S$. For instance, taking $S = \{f \in C^\infty(S^1) : f(p) = 0\}$ for some point $p$ fails. So does taking $S$ to be the smooth functions vanishing on a whole neighbourhood of some point $p$. Any thoughts?","Let $H$ be a Hilbert space and let $A : D(A) \subset H \to H$ be an essentially self-adjoint operator. Let $\overline A$ be the unique self-adjoint extension of $A$. Question: Is it true that $\ker(A) = \ker(\overline A)$? I don't really see any reason for this to be true, so I tried constructing a counterexample... but somehow this is not so easy to do! For instance, I tried starting with the negative Laplacian $\Delta = - \frac{d^2}{dx^2}$ on $L^2(S^1)$ with domain $\mathrm{dom}(\Delta) = C^\infty(S^1)$. This is an essentially self-adjoint operator and the closure $\overline \Delta$ is easily understood if we look to the frequency domain. On $\ell^2(\mathbb{Z})$, we find $\overline \Delta$ is conjugate to the diagonal operator $D$ on $\ell^2(\mathbb{Z})$ given by $D(a_n) = (n^2a_n)$ and with domain $\{ (a_n) \in \ell^2(\mathbb{Z}) : (na_n) \in \ell^2(\mathbb{Z})\}$. From this, we conclude that $\Delta$ and $\overline \Delta$ have the same one-dimensional kernel.  $$\ker(\Delta) = \ker(\overline \Delta) = \{\text{constant functions}\} \subset L^2(S^1).$$ Next I tried to replace $\Delta$ by its restriction $\Delta_S$ to some smaller subspace $S \subset C^\infty(S^1)$ such that $S$ intersects trivially with the constant functions, but still manages to be a core for $\Delta$, i.e. has $\overline \Delta_S = \overline \Delta$. However, every subspace $S$ like this I try turns out to give a non essentially self-adjoint $\Delta_S$. For instance, taking $S = \{f \in C^\infty(S^1) : f(p) = 0\}$ for some point $p$ fails. So does taking $S$ to be the smooth functions vanishing on a whole neighbourhood of some point $p$. Any thoughts?",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'unbounded-operators']"
4,"Functional analysis, weak* convergence","Functional analysis, weak* convergence",,"in lecture notes in the Internet i found the following example for weak and weak* convergence. The unit vectors $\{e_n\}_{n\in \mathbb{N}} $ converges in $l_1$ weak* towards $0 $ but not weak to $0$. $e_n \not\stackrel{w}{\rightarrow} 0$: For the dual of $l_1$ we know, that $l_1^* \cong l_\infty$ holds. For example the sequence $y=(1,1,1,1,1,....) $ is in $l_\infty$ and we geht $y(e_n)=\sum_{i=1}^\infty e_ny_i=y_i \stackrel{n\rightarrow \infty}{\not\rightarrow} 0$, hence not weak convergent. I think this is correct, but I do not understand the following explanation for the weak* convergence:\  For a sequence $(f_j)_{j\in \mathbb{N}}\in c_0$ we get $f_j(e_n)=\sum_{j=1}^\infty f_je_n=f_n\stackrel{n\rightarrow \infty}{\rightarrow}0 $ If the sequence is really taken out of $c_0$ I understand the explanation, but for weak* convergence the sequence is normally taken out of the dual, in our case the $l_1^*$ which is not conjugated to $c_0$. In addition it holds $c_0 \subset l_\infty$ so we can´t consider $l_1^*\cong l_\infty$ as a subset of $c_0$ and use the property of $c_0$, as for example in the cases of $l_p$ for $p\in (1,\infty)$. Now I ask myself, is this example correct? It would be great, if somebody can explain it. Thanks in advance.  Hias","in lecture notes in the Internet i found the following example for weak and weak* convergence. The unit vectors $\{e_n\}_{n\in \mathbb{N}} $ converges in $l_1$ weak* towards $0 $ but not weak to $0$. $e_n \not\stackrel{w}{\rightarrow} 0$: For the dual of $l_1$ we know, that $l_1^* \cong l_\infty$ holds. For example the sequence $y=(1,1,1,1,1,....) $ is in $l_\infty$ and we geht $y(e_n)=\sum_{i=1}^\infty e_ny_i=y_i \stackrel{n\rightarrow \infty}{\not\rightarrow} 0$, hence not weak convergent. I think this is correct, but I do not understand the following explanation for the weak* convergence:\  For a sequence $(f_j)_{j\in \mathbb{N}}\in c_0$ we get $f_j(e_n)=\sum_{j=1}^\infty f_je_n=f_n\stackrel{n\rightarrow \infty}{\rightarrow}0 $ If the sequence is really taken out of $c_0$ I understand the explanation, but for weak* convergence the sequence is normally taken out of the dual, in our case the $l_1^*$ which is not conjugated to $c_0$. In addition it holds $c_0 \subset l_\infty$ so we can´t consider $l_1^*\cong l_\infty$ as a subset of $c_0$ and use the property of $c_0$, as for example in the cases of $l_p$ for $p\in (1,\infty)$. Now I ask myself, is this example correct? It would be great, if somebody can explain it. Thanks in advance.  Hias",,"['functional-analysis', 'weak-convergence']"
5,Banach fixed point theorem,Banach fixed point theorem,,"Given $(X,d)$ complete with $A \subset X$ closed, and $f: A \to A$ satisfying   $$ d(f^{n}(x),f^{n}(y)) \leqslant a_{n}d(x,y) \hspace{3mm} \forall x,y \in A \hspace{3mm} n \in \mathbb{N}$$    where $a_{n} > 0$ and $\sum_{n=1}^{\infty} a_{n} < \infty$, show that $f$ has a unique fixed point. Obviously, I want to show that $f$ has a unique fixed point. Since $A \subset X$ is closed in the complete space $(X,d)$, then $(A,d)$ is complete. Do I simply need to show that $f$ is a contraction? (Banach Fixed Point Theorem). I feel that I am missing something.","Given $(X,d)$ complete with $A \subset X$ closed, and $f: A \to A$ satisfying   $$ d(f^{n}(x),f^{n}(y)) \leqslant a_{n}d(x,y) \hspace{3mm} \forall x,y \in A \hspace{3mm} n \in \mathbb{N}$$    where $a_{n} > 0$ and $\sum_{n=1}^{\infty} a_{n} < \infty$, show that $f$ has a unique fixed point. Obviously, I want to show that $f$ has a unique fixed point. Since $A \subset X$ is closed in the complete space $(X,d)$, then $(A,d)$ is complete. Do I simply need to show that $f$ is a contraction? (Banach Fixed Point Theorem). I feel that I am missing something.",,"['functional-analysis', 'metric-spaces', 'fixed-point-theorems']"
6,"Parseval relation on inner product space for $\langle x,y \rangle$",Parseval relation on inner product space for,"\langle x,y \rangle","Exercise 3.6-4 in Kreyszig asks to show that $\langle x,y \rangle = \sum_k \langle x,e_k \rangle \overline{\langle y,e_k \rangle}$ using the ""Parseval relation"": $\sum_k |\langle x, e_k \rangle |^2 = ||x||^2$, for all $x \in X$, where the $(e_k)$ form an orthonormal set. I'm a bit stumped here. I see how the relation on $||x||^2$ would follow from the first, but not the other way around.","Exercise 3.6-4 in Kreyszig asks to show that $\langle x,y \rangle = \sum_k \langle x,e_k \rangle \overline{\langle y,e_k \rangle}$ using the ""Parseval relation"": $\sum_k |\langle x, e_k \rangle |^2 = ||x||^2$, for all $x \in X$, where the $(e_k)$ form an orthonormal set. I'm a bit stumped here. I see how the relation on $||x||^2$ would follow from the first, but not the other way around.",,['functional-analysis']
7,Lipschitz map between metric and normed spaces,Lipschitz map between metric and normed spaces,,"Let be $F:(X,d)\to V$ a map between $(X,d)$ metric space and $V$ normed space, such that for each $f\in V'$ (linear and continuous), $f\circ F$ is lipschitz map. Show that $F$ is a Lipschitz map. I try something like that: Proof: For every $f\in V'$, there are $C_f, L_f >0$ such that, for every $x,y\in X$ $$|f(x)|\le C_f |x|$$ and $$|f(F(x)-F(y))|=|f(F(x))-f(F(y))|\le L_f d(x,y).$$ If $F(x)-F(y)\neq 0$, by Hahn-Banach theorem, there is $f_{xy}\in V'$ such that $$f_{xy}(F(x)-F(y))=|F(x)-F(y)|.$$ So, $$|f_{xy}(F(x))-f_{xy}(F(y))|=|F(x)-F(y)|\le L_{f_{xy}}d(x,y).$$ I stopped here. How can I to standardize the constant $L_{f_{xy}}$? Is it the good way to solve the problem? Any help? I appreciate.","Let be $F:(X,d)\to V$ a map between $(X,d)$ metric space and $V$ normed space, such that for each $f\in V'$ (linear and continuous), $f\circ F$ is lipschitz map. Show that $F$ is a Lipschitz map. I try something like that: Proof: For every $f\in V'$, there are $C_f, L_f >0$ such that, for every $x,y\in X$ $$|f(x)|\le C_f |x|$$ and $$|f(F(x)-F(y))|=|f(F(x))-f(F(y))|\le L_f d(x,y).$$ If $F(x)-F(y)\neq 0$, by Hahn-Banach theorem, there is $f_{xy}\in V'$ such that $$f_{xy}(F(x)-F(y))=|F(x)-F(y)|.$$ So, $$|f_{xy}(F(x))-f_{xy}(F(y))|=|F(x)-F(y)|\le L_{f_{xy}}d(x,y).$$ I stopped here. How can I to standardize the constant $L_{f_{xy}}$? Is it the good way to solve the problem? Any help? I appreciate.",,"['functional-analysis', 'metric-spaces', 'normed-spaces', 'lipschitz-functions']"
8,States in a $C^*$-algebra bounded?,States in a -algebra bounded?,C^*,"A functional $\phi$ on a $C^*$-algebra $A$ with unit element, i.e. $\phi: A \rightarrow \mathbb{C}$ is called a state if $\phi(T^*T) \ge 0$ for all $T \in A$ and $\phi( \operatorname{id}) = 1.$ Now, I started wondering whether such a functional $\phi$ is automatically bounded or not?","A functional $\phi$ on a $C^*$-algebra $A$ with unit element, i.e. $\phi: A \rightarrow \mathbb{C}$ is called a state if $\phi(T^*T) \ge 0$ for all $T \in A$ and $\phi( \operatorname{id}) = 1.$ Now, I started wondering whether such a functional $\phi$ is automatically bounded or not?",,"['functional-analysis', 'operator-algebras']"
9,Fermat like equation for meromorphic functions.,Fermat like equation for meromorphic functions.,,"I found this question in Conway, and really have no idea how to answer it.  Can anyone provide any hints? For each integer $n\geq 1$ determine all meromorphic functions on $\mathbb{C}$ $f$ and $g$ with poles at $\infty$ such that $f^n+g^n =1$.","I found this question in Conway, and really have no idea how to answer it.  Can anyone provide any hints? For each integer $n\geq 1$ determine all meromorphic functions on $\mathbb{C}$ $f$ and $g$ with poles at $\infty$ such that $f^n+g^n =1$.",,"['complex-analysis', 'analysis', 'functional-analysis']"
10,Is there any popular name for this theorem in the standard literature?,Is there any popular name for this theorem in the standard literature?,,"Let $X$ be a normed space. Then $X$ is a Banach space if and only if the absolute convergence of any series in $X$ implies the conditional convergence of that series. Is there any name given to the above result in the standard literature on the normed space theory? And, is there any name given to the property of absolute convergence of a series implying conditional convergence? How do we prove this theorem? My effort: Suppose that $X$ is a Banach space. Let $\sum_n x_n$ be an absolutely convergent series in $X$. Then the sequence $(\alpha_n)_{n\in \mathbb{N}}$, where  $$\alpha_n \colon= \Vert x_1 \Vert + \cdots + \Vert x_n \Vert \ \mbox{ for all } \ n \in \mathbb{N},$$ is a Cauchy sequence in $\mathbb{R}$. Thus, given a real number $\epsilon>0$, we can find a natural number $N$ such that  $$\vert \alpha_m - \alpha_n \vert < \epsilon \ \mbox{ for all } \ m, n \in \mathbb{N} \ \mbox{ such that } \ m > N \ \mbox{ and } \ n > N. $$ Now let $m, n \in \mathbb{N}$ such that $n > m > N$. Then  $$ \begin{align} \left\Vert \sum_{k=1}^n x_k - \sum_{k=1}^m x_k\right\Vert  &= \left\Vert \sum_{k=m+1}^n x_k \right\Vert \\  &\leq \sum_{k=m+1}^n \Vert x_k \Vert \\  &= \alpha_n - \alpha_m \\ &= \vert \alpha_n - \alpha_m \vert \\ &< \epsilon. \end{align} $$ Thus the sequence $\left(\sum_{k=1}^n x_k \right)_{n\in\mathbb{N}}$ of partial sums of the series $\sum_n x_n$ is Cauchy and hence convergent. Conversely, suppose that the absolute convergence of any series in $X$ implies convergence of that series. Suppose that $(x_n)$ is a Cauchy sequence in $X$. We need to show that this sequence converges in $X$. How to?","Let $X$ be a normed space. Then $X$ is a Banach space if and only if the absolute convergence of any series in $X$ implies the conditional convergence of that series. Is there any name given to the above result in the standard literature on the normed space theory? And, is there any name given to the property of absolute convergence of a series implying conditional convergence? How do we prove this theorem? My effort: Suppose that $X$ is a Banach space. Let $\sum_n x_n$ be an absolutely convergent series in $X$. Then the sequence $(\alpha_n)_{n\in \mathbb{N}}$, where  $$\alpha_n \colon= \Vert x_1 \Vert + \cdots + \Vert x_n \Vert \ \mbox{ for all } \ n \in \mathbb{N},$$ is a Cauchy sequence in $\mathbb{R}$. Thus, given a real number $\epsilon>0$, we can find a natural number $N$ such that  $$\vert \alpha_m - \alpha_n \vert < \epsilon \ \mbox{ for all } \ m, n \in \mathbb{N} \ \mbox{ such that } \ m > N \ \mbox{ and } \ n > N. $$ Now let $m, n \in \mathbb{N}$ such that $n > m > N$. Then  $$ \begin{align} \left\Vert \sum_{k=1}^n x_k - \sum_{k=1}^m x_k\right\Vert  &= \left\Vert \sum_{k=m+1}^n x_k \right\Vert \\  &\leq \sum_{k=m+1}^n \Vert x_k \Vert \\  &= \alpha_n - \alpha_m \\ &= \vert \alpha_n - \alpha_m \vert \\ &< \epsilon. \end{align} $$ Thus the sequence $\left(\sum_{k=1}^n x_k \right)_{n\in\mathbb{N}}$ of partial sums of the series $\sum_n x_n$ is Cauchy and hence convergent. Conversely, suppose that the absolute convergence of any series in $X$ implies convergence of that series. Suppose that $(x_n)$ is a Cauchy sequence in $X$. We need to show that this sequence converges in $X$. How to?",,"['real-analysis', 'analysis', 'functional-analysis', 'normed-spaces', 'absolute-convergence']"
11,"If a linear operator preserves positive functions, then it leaves some linear functional invariant","If a linear operator preserves positive functions, then it leaves some linear functional invariant",,"I have the following question which I cannot seem to make any progress on: Suppose that $T:C[0,1]\to C[0,1]$ is a linear operator satisfying that $Tf\geq 0$ whenever $f\geq 0$, and $T1=1$. Show that there exists a linear functional $\ell:C[0,1]$ satisfying $\ell(1)=1, \ell(f)\geq 0$ if $f\geq 0$ and $\ell(Tf)=\ell(f)$. My biggest issue is with the last condition, I just don't see how we know enough about $T$ to construct something that satisfies this. An obvious candidate would be $T^{-1}$ but how do we know that even exists or is well defined?","I have the following question which I cannot seem to make any progress on: Suppose that $T:C[0,1]\to C[0,1]$ is a linear operator satisfying that $Tf\geq 0$ whenever $f\geq 0$, and $T1=1$. Show that there exists a linear functional $\ell:C[0,1]$ satisfying $\ell(1)=1, \ell(f)\geq 0$ if $f\geq 0$ and $\ell(Tf)=\ell(f)$. My biggest issue is with the last condition, I just don't see how we know enough about $T$ to construct something that satisfies this. An obvious candidate would be $T^{-1}$ but how do we know that even exists or is well defined?",,"['functional-analysis', 'banach-spaces']"
12,"If every rearrangement of a Schauder basis is also a basis, it is an unconditional one","If every rearrangement of a Schauder basis is also a basis, it is an unconditional one",,"Let $(e_n)_{n=1}^{\infty}$ be a Schauder basis for the Banach space $X$. Suppose for any bijection $\sigma:\mathbb N \to \mathbb N$, $(e_{\sigma(n)})_{n=1}^{\infty}$ is also a Schauder basis, then is it true that $(e_n)_{n=1}^{\infty}$ is an unconditional Schauder basis?(The question is raised by one of my friends. The converse is part of the definition .) I have tried very hard to prove that  for any $x \in X$, there exists $(a_n)_{n=1}^{\infty}$ such that $$\sum _{n=1}^{\infty}a_n e_n=x=\sum _{n=1}^{\infty}a_{\sigma(n)} e_{\sigma(n)}$$ Since there is no conditions about the absolute convergence, we cannot use the proof for ""absolute convergence $\Rightarrow$ unconditional convergence"". Can anybody show me a proof or an counterexample for this?","Let $(e_n)_{n=1}^{\infty}$ be a Schauder basis for the Banach space $X$. Suppose for any bijection $\sigma:\mathbb N \to \mathbb N$, $(e_{\sigma(n)})_{n=1}^{\infty}$ is also a Schauder basis, then is it true that $(e_n)_{n=1}^{\infty}$ is an unconditional Schauder basis?(The question is raised by one of my friends. The converse is part of the definition .) I have tried very hard to prove that  for any $x \in X$, there exists $(a_n)_{n=1}^{\infty}$ such that $$\sum _{n=1}^{\infty}a_n e_n=x=\sum _{n=1}^{\infty}a_{\sigma(n)} e_{\sigma(n)}$$ Since there is no conditions about the absolute convergence, we cannot use the proof for ""absolute convergence $\Rightarrow$ unconditional convergence"". Can anybody show me a proof or an counterexample for this?",,"['functional-analysis', 'banach-spaces', 'schauder-basis']"
13,Show that $(l_1)^* \cong l_{\infty}$,Show that,(l_1)^* \cong l_{\infty},"Suppose that $l_1 = \{ (x_n)_{n \in \mathbb{N}} | \sum|x_n| < \infty \}$ and $l_{\infty} = \{ (x_n)_{n \in \mathbb{N}}| \sup|x_n| < \infty \}$. Show that $(l_1)^* \cong l_{\infty}$, where $(l_1)^*$ is a dual space of $l_1$. My attempt: Define a map $L: l_{\infty} \rightarrow (l_1)^*$ given by  $$L(x)(y) = \sum_{n \in \mathbb{N}}{x_ny_n}$$ where $y = (y_n)_{n \in \mathbb{N}} \in l_1$. My aim is to show that $L$ is an isometric isomorphism. Clearly $L$ is linear and and injective (choose $y = e_n$ for all $n \in \mathbb{N})$. How to show that $L$ is a surjection and isometry?","Suppose that $l_1 = \{ (x_n)_{n \in \mathbb{N}} | \sum|x_n| < \infty \}$ and $l_{\infty} = \{ (x_n)_{n \in \mathbb{N}}| \sup|x_n| < \infty \}$. Show that $(l_1)^* \cong l_{\infty}$, where $(l_1)^*$ is a dual space of $l_1$. My attempt: Define a map $L: l_{\infty} \rightarrow (l_1)^*$ given by  $$L(x)(y) = \sum_{n \in \mathbb{N}}{x_ny_n}$$ where $y = (y_n)_{n \in \mathbb{N}} \in l_1$. My aim is to show that $L$ is an isometric isomorphism. Clearly $L$ is linear and and injective (choose $y = e_n$ for all $n \in \mathbb{N})$. How to show that $L$ is a surjection and isometry?",,"['functional-analysis', 'isometry', 'dual-spaces']"
14,"Let $a_f=\text{ arg} \min_{a} \int \left|f(x)-a\right| dx$ and $a_g= \text{ arg} \min_{a} \int \left|g(x)-a\right| dx$, is $a_f \le a_g$?","Let  and , is ?",a_f=\text{ arg} \min_{a} \int \left|f(x)-a\right| dx a_g= \text{ arg} \min_{a} \int \left|g(x)-a\right| dx a_f \le a_g,"Let $ f(x) \le g(x) $ and assume that $g(x),f(x) \in L^1$ let  \begin{align} a_f= \text{ arg} \min_{a } \int_A \left|f(x)-a\right| dx\\ a_g=\text{ arg} \min_{a } \int_A \left|g(x)-a\right| dx \end{align} where $A \subseteq \mathbb{R}$. We assume that such $a_f$ and $a_g$ exist and $|a_f|,|a_g| < \infty$. Is $a_f \le a_g$? How would one approach this problem? Thank you.","Let $ f(x) \le g(x) $ and assume that $g(x),f(x) \in L^1$ let  \begin{align} a_f= \text{ arg} \min_{a } \int_A \left|f(x)-a\right| dx\\ a_g=\text{ arg} \min_{a } \int_A \left|g(x)-a\right| dx \end{align} where $A \subseteq \mathbb{R}$. We assume that such $a_f$ and $a_g$ exist and $|a_f|,|a_g| < \infty$. Is $a_f \le a_g$? How would one approach this problem? Thank you.",,"['integration', 'functional-analysis', 'optimization', 'lp-spaces']"
15,Normed Linear Space - maximum norm vs. $||f||_1$,Normed Linear Space - maximum norm vs.,||f||_1,"For $f$ in $C[a,b]$ define $$|| f ||_1 =\int_a^b |f|.$$  a. Show that this is a norm on $C[a,b]$. b. Show that there is no number $c \geq0$ for which $$||f||_{max} \leq c ||f||_1 \ for \ all  \ f \ in  \ C[a,b]$$ c. Show there is a $c\geq 0$ for which $$||f||_1 \leq c||f||_{max}  \ for \ all  \ f  \ in  \ C[a,b]$$ (where $||f||_{max}=\max\limits_{x \in [a,b]} |f(x)|)$ I proved a. by showing all norm properties (the triangle inequality, positive homogeneity and nonnegativity). I also proved part b. by false assumption that leaded me to contradiction Any help on part c. Thanks","For $f$ in $C[a,b]$ define $$|| f ||_1 =\int_a^b |f|.$$  a. Show that this is a norm on $C[a,b]$. b. Show that there is no number $c \geq0$ for which $$||f||_{max} \leq c ||f||_1 \ for \ all  \ f \ in  \ C[a,b]$$ c. Show there is a $c\geq 0$ for which $$||f||_1 \leq c||f||_{max}  \ for \ all  \ f  \ in  \ C[a,b]$$ (where $||f||_{max}=\max\limits_{x \in [a,b]} |f(x)|)$ I proved a. by showing all norm properties (the triangle inequality, positive homogeneity and nonnegativity). I also proved part b. by false assumption that leaded me to contradiction Any help on part c. Thanks",,"['real-analysis', 'functional-analysis', 'measure-theory', 'inequality', 'normed-spaces']"
16,"linear, non-surjective isometry $T:\ell^p(\mathbb{Z})\to \ell^p(\mathbb{Z})$","linear, non-surjective isometry",T:\ell^p(\mathbb{Z})\to \ell^p(\mathbb{Z}),"I need help to find a linear, non-surjective isometry $T:\ell^p(\mathbb{Z})\to \ell^p(\mathbb{Z})$ for $1\le p\le\infty$. I tried different things, for example if $f:\mathbb{Z}\to\mathbb{Z}, z\mapsto 2z$, then I considered $T(x)=x\circ f$. But $T(x)(z)=x_{f(z)}=x_{2z}$, i.e. $$T((\ldots,x_{-1},x_0,x_1,x_2,\ldots))=(\ldots,x_{-2},x_0,x_2,\ldots)$$and then $T$ need not to be injective. I tried other ideas but I don't have a suitable idea. Could you help me?","I need help to find a linear, non-surjective isometry $T:\ell^p(\mathbb{Z})\to \ell^p(\mathbb{Z})$ for $1\le p\le\infty$. I tried different things, for example if $f:\mathbb{Z}\to\mathbb{Z}, z\mapsto 2z$, then I considered $T(x)=x\circ f$. But $T(x)(z)=x_{f(z)}=x_{2z}$, i.e. $$T((\ldots,x_{-1},x_0,x_1,x_2,\ldots))=(\ldots,x_{-2},x_0,x_2,\ldots)$$and then $T$ need not to be injective. I tried other ideas but I don't have a suitable idea. Could you help me?",,"['sequences-and-series', 'functional-analysis', 'isometry']"
17,Bounded linear functional is necessarily continuous proof verification,Bounded linear functional is necessarily continuous proof verification,,"I want to prove that a bounded linear functional $f$, must be continuous. I have defined: $f$ is bounded means that $\exists c> 0, |f(x)|\leq c\|x\|, \quad \forall x\in X$ and continuous means that $x_n\to x \implies f(x_n)\to f(x)$. Proof: Let $f$ be bounded. Then $\exists c, |f(x)| \leq c\|x\|$ Then \begin{align} &\lim_{n\to\infty} |f(x_n-x)|\leq \lim_{n\to\infty} c\|x_n-x\|\\ \implies& \lim_{n\to\infty} |f(x_n)-f(x)|\leq c\|x-x\|=0\\ \implies& \lim_{n\to\infty} f(x_n)=f(x) \end{align} Is that all there is to it? I used linearity in the second line, but what if we removed the condition that $f$ is linear. Is a non-linear bounded functional $f$ necessarily continuous","I want to prove that a bounded linear functional $f$, must be continuous. I have defined: $f$ is bounded means that $\exists c> 0, |f(x)|\leq c\|x\|, \quad \forall x\in X$ and continuous means that $x_n\to x \implies f(x_n)\to f(x)$. Proof: Let $f$ be bounded. Then $\exists c, |f(x)| \leq c\|x\|$ Then \begin{align} &\lim_{n\to\infty} |f(x_n-x)|\leq \lim_{n\to\infty} c\|x_n-x\|\\ \implies& \lim_{n\to\infty} |f(x_n)-f(x)|\leq c\|x-x\|=0\\ \implies& \lim_{n\to\infty} f(x_n)=f(x) \end{align} Is that all there is to it? I used linearity in the second line, but what if we removed the condition that $f$ is linear. Is a non-linear bounded functional $f$ necessarily continuous",,"['linear-algebra', 'functional-analysis', 'proof-verification']"
18,Generalization of piece-wise linear functions over a metric space,Generalization of piece-wise linear functions over a metric space,,"Suppose we want to construct a function $f$ from a compact metric space $(X,\rho)$ to a Euclidean space $\mathbb{R}^n$ that is Lipschitz continuous with a constant $L$: $$ \forall x,y \in X . ||f(x)-f(y)|| \leq L \cdot \rho(x, y) $$ Suppose that there is a sequence of unequal points $\{x_1,...x_N\}$ in $X$ such that all metrics $\rho(x_i,x_j)$ are known and $f(x_i)=a_i$ for some $a_i$ in $\mathbb{R}^n$ whereas: $$ \forall x_i,x_j \in \{x_1,...x_N\} . ||a_i-a_j|| \leq L \cdot \rho(x_i, x_j) $$ Suppose also that $\{x_1,...x_N\}$ form a finite cover of $X$ by balls of some suitable (known) radius. Is there any way to construct $f$ for all the points in $X$ so that it's Lipschitz continuous with a constant $L$? My first idea was to use something like: $$f(x):=f\left(x_{i}\right)+\left(f\left(x_{j}\right)-f\left(x_{i}\right)\right)\cdot\dfrac{\rho\left(x,x_{i}\right)}{\rho\left(x_{i},x_{j}\right)}$$ But it only works for the points ""between"" $x_i$ and $x_j$, and there may be other points of the net that interfere. The question has been also posted here since there might be some research potential.","Suppose we want to construct a function $f$ from a compact metric space $(X,\rho)$ to a Euclidean space $\mathbb{R}^n$ that is Lipschitz continuous with a constant $L$: $$ \forall x,y \in X . ||f(x)-f(y)|| \leq L \cdot \rho(x, y) $$ Suppose that there is a sequence of unequal points $\{x_1,...x_N\}$ in $X$ such that all metrics $\rho(x_i,x_j)$ are known and $f(x_i)=a_i$ for some $a_i$ in $\mathbb{R}^n$ whereas: $$ \forall x_i,x_j \in \{x_1,...x_N\} . ||a_i-a_j|| \leq L \cdot \rho(x_i, x_j) $$ Suppose also that $\{x_1,...x_N\}$ form a finite cover of $X$ by balls of some suitable (known) radius. Is there any way to construct $f$ for all the points in $X$ so that it's Lipschitz continuous with a constant $L$? My first idea was to use something like: $$f(x):=f\left(x_{i}\right)+\left(f\left(x_{j}\right)-f\left(x_{i}\right)\right)\cdot\dfrac{\rho\left(x,x_{i}\right)}{\rho\left(x_{i},x_{j}\right)}$$ But it only works for the points ""between"" $x_i$ and $x_j$, and there may be other points of the net that interfere. The question has been also posted here since there might be some research potential.",,"['functional-analysis', 'metric-spaces', 'approximation', 'lipschitz-functions']"
19,Reflexivity of intersection of two $L^p$ space,Reflexivity of intersection of two  space,L^p,"Q:Prove that the linear space $L^{p_1}\cap L^{p_2}$ $(p_1\neq p_2)$ with norm defined by $$\|f\|_{L^{p_1}\cap L^{p_2}}=\|f\|_{L^{p_1}}+\|f\|_{L^{p_2}}$$ is a reflexive Banach space. I've tried several ways to prove the reflexivity. Such as proving it's a closed subspace of $L^{p_1}$ $(/L^{p_2})$, proving it is a uniformly convex space but all failed. But it seems really complicated to prove directly that it is reflexive. Can someone show a way for me? Thanks for your help!","Q:Prove that the linear space $L^{p_1}\cap L^{p_2}$ $(p_1\neq p_2)$ with norm defined by $$\|f\|_{L^{p_1}\cap L^{p_2}}=\|f\|_{L^{p_1}}+\|f\|_{L^{p_2}}$$ is a reflexive Banach space. I've tried several ways to prove the reflexivity. Such as proving it's a closed subspace of $L^{p_1}$ $(/L^{p_2})$, proving it is a uniformly convex space but all failed. But it seems really complicated to prove directly that it is reflexive. Can someone show a way for me? Thanks for your help!",,"['functional-analysis', 'analysis', 'lp-spaces', 'reflexive-space']"
20,"Definition of ""Extension"" of Bounded Linear Transformation","Definition of ""Extension"" of Bounded Linear Transformation",,"I have been given the problem of proving the B.L.T. Theorem for my homework which states, Every bounded linear transformation $\mathsf{T}$ from a normed vector space X to a complete, normed vector space Y can be uniquely extended to a bounded linear transformation $\tilde{\mathsf{T}}$ from the completion of X to Y. In addition, the operator norm of $\mathsf{T}$ is $c$ iff the norm of $\tilde{\mathsf{T}}$ is $c$. What exactly does this theorem mean by, 'extension from $\mathsf{T}$ to $\tilde{\mathsf{T}}$ ?'","I have been given the problem of proving the B.L.T. Theorem for my homework which states, Every bounded linear transformation $\mathsf{T}$ from a normed vector space X to a complete, normed vector space Y can be uniquely extended to a bounded linear transformation $\tilde{\mathsf{T}}$ from the completion of X to Y. In addition, the operator norm of $\mathsf{T}$ is $c$ iff the norm of $\tilde{\mathsf{T}}$ is $c$. What exactly does this theorem mean by, 'extension from $\mathsf{T}$ to $\tilde{\mathsf{T}}$ ?'",,"['real-analysis', 'functional-analysis', 'operator-theory']"
21,What is predual space to Radon measures with finite moment?,What is predual space to Radon measures with finite moment?,,"Define for any $p\in\mathbb{N}$ space $\mathcal{M}^p(\mathbb{R}_+)$ as measures with finite $p -$moment, i.e. such Radon measures $\mu$ that $\int_0^\infty x^p d\mu(x) <C_{p,\mu}$. What is the predual space of $\mathcal{M}^p(\mathbb{R}_+)$? What is dual of $C^p(\mathbb{R}_+) -$ space of all continuous functions $f$ such that $\sup_{x\in\mathbb{R}_+}|\frac{f}{x^p}|< C_{p,f}$ ? Obviously I would like to have rigorous argument why I can intrgrate one agaist the other, although the previous two questions are important to me as they give me much more insight. Any comprehensive reference to similar spaces, their properties, duals and so on is much appreciated. Best regards and thank you for your answer.","Define for any $p\in\mathbb{N}$ space $\mathcal{M}^p(\mathbb{R}_+)$ as measures with finite $p -$moment, i.e. such Radon measures $\mu$ that $\int_0^\infty x^p d\mu(x) <C_{p,\mu}$. What is the predual space of $\mathcal{M}^p(\mathbb{R}_+)$? What is dual of $C^p(\mathbb{R}_+) -$ space of all continuous functions $f$ such that $\sup_{x\in\mathbb{R}_+}|\frac{f}{x^p}|< C_{p,f}$ ? Obviously I would like to have rigorous argument why I can intrgrate one agaist the other, although the previous two questions are important to me as they give me much more insight. Any comprehensive reference to similar spaces, their properties, duals and so on is much appreciated. Best regards and thank you for your answer.",,"['functional-analysis', 'measure-theory']"
22,Sobolev spaces over closed domains.,Sobolev spaces over closed domains.,,"I am currently working through books on Sobolev spaces and I notice that these spaces are almost always defined over open domains, i.e. we look at $W^{m,p}(\Omega)$, where $\Omega$ is open. Because these spaces are equivalence classes and ignore sets of measure $0$, my intuition tells me that we should have $W^{m,p}(\Omega) = W^{m,p}(\bar{\Omega})$ and that all the results given for the space $W^{m,p}(\Omega)$ could equally be given for $W^{m,p}(\bar{\Omega})$.  Is my intuition on this correct?","I am currently working through books on Sobolev spaces and I notice that these spaces are almost always defined over open domains, i.e. we look at $W^{m,p}(\Omega)$, where $\Omega$ is open. Because these spaces are equivalence classes and ignore sets of measure $0$, my intuition tells me that we should have $W^{m,p}(\Omega) = W^{m,p}(\bar{\Omega})$ and that all the results given for the space $W^{m,p}(\Omega)$ could equally be given for $W^{m,p}(\bar{\Omega})$.  Is my intuition on this correct?",,"['functional-analysis', 'sobolev-spaces']"
23,Norm of an integral operator $L^1 \rightarrow L^\infty$,Norm of an integral operator,L^1 \rightarrow L^\infty,"Let $T:L^1(\mathbb{R}^n)\rightarrow L^\infty(\mathbb{R}^n)$ be an integral operator, i.e. there exist $K:\mathbb{R}^n\times\mathbb{R}^n\rightarrow\mathbb{R}^n$ such that for all $f\in L^1(\mathbb{R}^n)$ it holds $$Tf(x):=\int_{\mathbb{R}^n}K(x,y)f(y)\:dy\quad\text{for all }x\in\mathbb{R}^n.$$ Does anyone knows how to prove that $\|T\|_{L^1\rightarrow L^\infty}=\sup_{x,y}|K(x,y)|$?","Let $T:L^1(\mathbb{R}^n)\rightarrow L^\infty(\mathbb{R}^n)$ be an integral operator, i.e. there exist $K:\mathbb{R}^n\times\mathbb{R}^n\rightarrow\mathbb{R}^n$ such that for all $f\in L^1(\mathbb{R}^n)$ it holds $$Tf(x):=\int_{\mathbb{R}^n}K(x,y)f(y)\:dy\quad\text{for all }x\in\mathbb{R}^n.$$ Does anyone knows how to prove that $\|T\|_{L^1\rightarrow L^\infty}=\sup_{x,y}|K(x,y)|$?",,"['functional-analysis', 'integral-transforms']"
24,"Prove that ${\{f_n\}}_{n\in\Bbb{N}}$ has a subsequence that converges uniformly to a continuous function on $[0,1]$",Prove that  has a subsequence that converges uniformly to a continuous function on,"{\{f_n\}}_{n\in\Bbb{N}} [0,1]","Consider the sequence ${\{f_n\}}_{n\in\Bbb{N}}$, where for each $n\in \Bbb{N}$ the function $f_n:[0,1] \to \Bbb{R}$ is absolutely continuous and satisfies $f_n(0)=13$ and $$\int_{[0,1]}|f_n'|^4dx \le 7$$ The integration is Lebesgue integration. Prove that ${\{f_n\}}_{n\in\Bbb{N}}$ has a subsequence that converges uniformly to a continuous function on $[0,1]$. If $f_n$ is absolutely continuous, then $f_n$ is of bounded variation and $f_n=\int|f'_n|dx$. That is all I can think about now. Then I have no clue what to do next about this question. Could someone provide some help?","Consider the sequence ${\{f_n\}}_{n\in\Bbb{N}}$, where for each $n\in \Bbb{N}$ the function $f_n:[0,1] \to \Bbb{R}$ is absolutely continuous and satisfies $f_n(0)=13$ and $$\int_{[0,1]}|f_n'|^4dx \le 7$$ The integration is Lebesgue integration. Prove that ${\{f_n\}}_{n\in\Bbb{N}}$ has a subsequence that converges uniformly to a continuous function on $[0,1]$. If $f_n$ is absolutely continuous, then $f_n$ is of bounded variation and $f_n=\int|f'_n|dx$. That is all I can think about now. Then I have no clue what to do next about this question. Could someone provide some help?",,"['real-analysis', 'functional-analysis']"
25,"Prob. 9, Sec. 4.3, in Kreyszig's Functional Analysis Book: Proof of the Hahn Banach Theorem without Zorn's Lemma [duplicate]","Prob. 9, Sec. 4.3, in Kreyszig's Functional Analysis Book: Proof of the Hahn Banach Theorem without Zorn's Lemma [duplicate]",,"This question already has answers here : Hahn-Banach Theorem for separable spaces without Zorn's Lemma (2 answers) Closed 8 years ago . Here's Theorem 4.3-2 (i.e. the Hahn Banach theorem for normed spaces): Let $f$ be a bounded linear functional defined on a subspace $Z$ of a normed space $X$ . Then there exists a bounbed linear functional $\tilde{f}$ on $X$ such that $$\tilde{f}(x) = f(x) \ \mbox{ for all } \ x\in Z,$$ and $$\Vert \tilde{f} \Vert_X = \Vert f \Vert_Z, $$ where $$\lVert f \rVert_Z := \sup \left\{ \frac{ \lvert f(x) \rvert }{\lVert x \rVert} \colon x \in Z, x \neq 0 \right\} \ \mbox{ if } Z \neq \{ 0 \}; \\  \mbox{ otherwise } \lVert f \rVert_Z := 0.$$ And, $$\Vert \tilde{f} \Vert_X \colon= \sup \left\{ \ \frac{ \vert \tilde{f}(x) \vert }{\Vert x \Vert} \ \colon \ x \in X, \ x \neq 0 \ \right\}.$$ I think I'm clear about the proof of this beautiful result. It uses the Hahn Banach Theorem for Complex Vector Spaces, which uses the Hahn Banach Theorem for Real Vector spaces, and the latter uses the Zorn's lemma. Now if $X$ is a separable normed space, then is there a proof of the above result that doesn't involve the use of the Zorn's lemma?","This question already has answers here : Hahn-Banach Theorem for separable spaces without Zorn's Lemma (2 answers) Closed 8 years ago . Here's Theorem 4.3-2 (i.e. the Hahn Banach theorem for normed spaces): Let be a bounded linear functional defined on a subspace of a normed space . Then there exists a bounbed linear functional on such that and where And, I think I'm clear about the proof of this beautiful result. It uses the Hahn Banach Theorem for Complex Vector Spaces, which uses the Hahn Banach Theorem for Real Vector spaces, and the latter uses the Zorn's lemma. Now if is a separable normed space, then is there a proof of the above result that doesn't involve the use of the Zorn's lemma?","f Z X \tilde{f} X \tilde{f}(x) = f(x) \ \mbox{ for all } \ x\in Z, \Vert \tilde{f} \Vert_X = \Vert f \Vert_Z,  \lVert f \rVert_Z := \sup \left\{ \frac{ \lvert f(x) \rvert }{\lVert x \rVert} \colon x \in Z, x \neq 0 \right\} \ \mbox{ if } Z \neq \{ 0 \}; \\  \mbox{ otherwise } \lVert f \rVert_Z := 0. \Vert \tilde{f} \Vert_X \colon= \sup \left\{ \ \frac{ \vert \tilde{f}(x) \vert }{\Vert x \Vert} \ \colon \ x \in X, \ x \neq 0 \ \right\}. X","['real-analysis', 'functional-analysis', 'operator-theory', 'normed-spaces', 'axiom-of-choice']"
26,Functional Derivative ${\delta q_a(t)}/{\delta q_b(t')}$,Functional Derivative,{\delta q_a(t)}/{\delta q_b(t')},"$\newcommand{\fdv}[2]{\frac{\delta #1}{\delta #2}}$ $\newcommand{\dv}[2]{\frac{\mathrm{d} #1}{\mathrm{d}#2}}$ $\newcommand{\pdv}[2]{\frac{\partial #1}{\partial #2}}$ I'm from a physics background and I've always known the definition to be related to the Euler-Lagrange Equations i.e. $$\fdv {L(q,\dot q)} {q(t)} = \pdv{L}{q} - \dv{}{t} \pdv{L}{\dot q} \; ,$$ where $\dot q$ denotes the derivative of the function $q$ with respect to $t$. However with this definition I cannot prove a fact that I've seen in a lecture video about Quantum Field Theory, which is $$\fdv{q_a(t)}{q_b(t')} = \delta_{ab} \delta(t-t') \; , \tag 1$$ where $\delta(t-t')$ is the Dirac delta function/distribution and $\delta_{ab}$ is the Kroneker delta. I don't know how I should make sense out of this equation let alone prove it because $q_a(t)$ is not a functional but a function . I'd appreciate if someone can explain what is meant by the equation (1) and give a proof thereof.","$\newcommand{\fdv}[2]{\frac{\delta #1}{\delta #2}}$ $\newcommand{\dv}[2]{\frac{\mathrm{d} #1}{\mathrm{d}#2}}$ $\newcommand{\pdv}[2]{\frac{\partial #1}{\partial #2}}$ I'm from a physics background and I've always known the definition to be related to the Euler-Lagrange Equations i.e. $$\fdv {L(q,\dot q)} {q(t)} = \pdv{L}{q} - \dv{}{t} \pdv{L}{\dot q} \; ,$$ where $\dot q$ denotes the derivative of the function $q$ with respect to $t$. However with this definition I cannot prove a fact that I've seen in a lecture video about Quantum Field Theory, which is $$\fdv{q_a(t)}{q_b(t')} = \delta_{ab} \delta(t-t') \; , \tag 1$$ where $\delta(t-t')$ is the Dirac delta function/distribution and $\delta_{ab}$ is the Kroneker delta. I don't know how I should make sense out of this equation let alone prove it because $q_a(t)$ is not a functional but a function . I'd appreciate if someone can explain what is meant by the equation (1) and give a proof thereof.",,"['functional-analysis', 'physics', 'functional-calculus']"
27,Projections: Ordering,Projections: Ordering,,Given a unital C*-algebra $1\in\mathcal{A}$. Consider projections: $$P^2=P=P^*\quad P'^2=P'=P'^*$$ Order them by: $$P\leq P':\iff\sigma(\Delta P)\geq0\quad(\Delta P:=P'-P)$$ Then equivalently:   $$P\leq P'\iff P=PP'=P'P\iff\Delta P^2=\Delta P=\Delta P^*$$ How can I check this? (Operator algebraic proof?),Given a unital C*-algebra $1\in\mathcal{A}$. Consider projections: $$P^2=P=P^*\quad P'^2=P'=P'^*$$ Order them by: $$P\leq P':\iff\sigma(\Delta P)\geq0\quad(\Delta P:=P'-P)$$ Then equivalently:   $$P\leq P'\iff P=PP'=P'P\iff\Delta P^2=\Delta P=\Delta P^*$$ How can I check this? (Operator algebraic proof?),,"['functional-analysis', 'operator-algebras', 'c-star-algebras']"
28,"Existence of the continuous spectrum of a possibly-unbounded, linear self-adjoint operator on a complex Hilbert space","Existence of the continuous spectrum of a possibly-unbounded, linear self-adjoint operator on a complex Hilbert space",,"Let $\mathbf{A}$ be a possibly-unbounded, linear self-adjoint operator on an infinte-dimensional, complex separable Hilbert space $\mathcal{H}$, and suppose we know the matrix elements $\langle j|\mathbf{A}|k\rangle$ of $\mathbf{A}$ on a basis $\{|n\rangle\}_{n\in\mathbb{N}}$. Are there theorems helping in the explicit calculation of the spectrum of $\mathbf{A}$ using the aforementioned matrix elements? If not, are there theorems giving necessary and/or sufficient conditions for the existence of the continuous spectrum of $\mathbf{A}$? Thanks in andvance.","Let $\mathbf{A}$ be a possibly-unbounded, linear self-adjoint operator on an infinte-dimensional, complex separable Hilbert space $\mathcal{H}$, and suppose we know the matrix elements $\langle j|\mathbf{A}|k\rangle$ of $\mathbf{A}$ on a basis $\{|n\rangle\}_{n\in\mathbb{N}}$. Are there theorems helping in the explicit calculation of the spectrum of $\mathbf{A}$ using the aforementioned matrix elements? If not, are there theorems giving necessary and/or sufficient conditions for the existence of the continuous spectrum of $\mathbf{A}$? Thanks in andvance.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
29,Can every vector space (over $\mathbb{R}$ or $\mathbb{C}$) can be a Banach space (or Hilbert space)?,Can every vector space (over  or ) can be a Banach space (or Hilbert space)?,\mathbb{R} \mathbb{C},"For a vector space $V$ over $\mathbb{R}$ (or $\mathbb{C}$ ) with Hamel basis of cardinality $\kappa$ such that $\kappa^{\aleph_0} = \kappa$ , can we define inner product(or norm) on $V$ such that $V$ is a Hilbert space (or Banach Space)? (The condition $\kappa^{\aleph_0} = \kappa$ is necessary because Arthur Kruse showed in ""Badly incomplete normed linear spaces"" (Math. Z. 83 (1964) 314--320) that a Banach space of infinite (Hamel) dimension $\kappa$ exists if and only if $\kappa^{\aleph_0} = \kappa$ .)","For a vector space over (or ) with Hamel basis of cardinality such that , can we define inner product(or norm) on such that is a Hilbert space (or Banach Space)? (The condition is necessary because Arthur Kruse showed in ""Badly incomplete normed linear spaces"" (Math. Z. 83 (1964) 314--320) that a Banach space of infinite (Hamel) dimension exists if and only if .)",V \mathbb{R} \mathbb{C} \kappa \kappa^{\aleph_0} = \kappa V V \kappa^{\aleph_0} = \kappa \kappa \kappa^{\aleph_0} = \kappa,"['functional-analysis', 'hilbert-spaces']"
30,Show that $\{ x_n \} \overset{T}{\mapsto} \{ \sum_{k=1}^{\infty} a_{nk} x_k \}$ is compact,Show that  is compact,\{ x_n \} \overset{T}{\mapsto} \{ \sum_{k=1}^{\infty} a_{nk} x_k \},"Can someone help me with this question? Let $\ell^2$ be the space of complex sequences $\{ x_1, x_2, \ldots \}$ that $\sum_{n=1}^{\infty} \lvert x_n \rvert ^2 < \infty$. If $\mu$ be Counting Measure on $\mathbb{N}$, then $\ell^2$ is $L^2(\mathbb{N}, \mu)$, and thus a Hilbert space. Now suppose that $\{ a_{ij} \}$ is a complex multi index sequence such that $\sum_{i, j} \lvert a_{ij} \rvert ^2 < \infty$. Thus, we can define $T : \ell^2 \rightarrow \ell^2$ \begin{equation} \{ x_n \}_{n=1}^{\infty} \overset{T}{\mapsto} \{ x'_n \}_{n=1}^{\infty}, \qquad x'_n = \sum_{k=1}^{\infty} a_{nk} x_k \ . \end{equation} Show that $T$ is well defined, means that we have $\{ x'_n \}_{n=1}^{\infty}$, $T$ is Bounded, and $T$ is Compact. Thanks in advance. Edit: I already proved number 1 and 2. For number 2, I proved that if $\sum_{n=1}^{\infty} \lvert x_n \rvert ^2 < 1$, then we have $\sum_{n=1}^{\infty} \lvert \sum_{k=1}^{\infty} a_{nk} x_k \rvert ^2 < \infty$. I couldn't prove number 3 with definition of compact operators, or other equivalent definitions, such as being limit of finite-rank operators.","Can someone help me with this question? Let $\ell^2$ be the space of complex sequences $\{ x_1, x_2, \ldots \}$ that $\sum_{n=1}^{\infty} \lvert x_n \rvert ^2 < \infty$. If $\mu$ be Counting Measure on $\mathbb{N}$, then $\ell^2$ is $L^2(\mathbb{N}, \mu)$, and thus a Hilbert space. Now suppose that $\{ a_{ij} \}$ is a complex multi index sequence such that $\sum_{i, j} \lvert a_{ij} \rvert ^2 < \infty$. Thus, we can define $T : \ell^2 \rightarrow \ell^2$ \begin{equation} \{ x_n \}_{n=1}^{\infty} \overset{T}{\mapsto} \{ x'_n \}_{n=1}^{\infty}, \qquad x'_n = \sum_{k=1}^{\infty} a_{nk} x_k \ . \end{equation} Show that $T$ is well defined, means that we have $\{ x'_n \}_{n=1}^{\infty}$, $T$ is Bounded, and $T$ is Compact. Thanks in advance. Edit: I already proved number 1 and 2. For number 2, I proved that if $\sum_{n=1}^{\infty} \lvert x_n \rvert ^2 < 1$, then we have $\sum_{n=1}^{\infty} \lvert \sum_{k=1}^{\infty} a_{nk} x_k \rvert ^2 < \infty$. I couldn't prove number 3 with definition of compact operators, or other equivalent definitions, such as being limit of finite-rank operators.",,"['functional-analysis', 'hilbert-spaces', 'compact-operators']"
31,"$M$ and $N$ are subspaces of a Hilbert space. If $M\subset N$, show that $N^{\perp}\subset M^{\perp}$. Show also that $(M^{\perp})^{\perp}=M$.","and  are subspaces of a Hilbert space. If , show that . Show also that .",M N M\subset N N^{\perp}\subset M^{\perp} (M^{\perp})^{\perp}=M,"$M$ and $N$ are subspaces of a Hilbert space. If $M\subset N$, show that $N^{\perp}\subset M^{\perp}$. Show also that $(M^{\perp})^{\perp}=M$. I know that the orthogonal complement of $X$ is the set $X^{\perp}=\{x\in H : x{\perp}X\}$ where $X$ is any subset of a Hilbert space $H$. I'm not sure how to proceed. Any hints or solutions are greatly appreciated.","$M$ and $N$ are subspaces of a Hilbert space. If $M\subset N$, show that $N^{\perp}\subset M^{\perp}$. Show also that $(M^{\perp})^{\perp}=M$. I know that the orthogonal complement of $X$ is the set $X^{\perp}=\{x\in H : x{\perp}X\}$ where $X$ is any subset of a Hilbert space $H$. I'm not sure how to proceed. Any hints or solutions are greatly appreciated.",,"['functional-analysis', 'hilbert-spaces', 'orthogonality']"
32,Riesz-Fischer theorem,Riesz-Fischer theorem,,"The aim of this exercise is to prove the Riesz-Fischer theorem for Hilbert spaces that aren't separable. Let $I$ an index set and $1\leq p \leq \infty$. Let    $\mathcal{F}=\{F\subset I: F$  is finite$\}$. Given $(a_i)_{i\in >  I}\subset \mathbb{K}$, we define: $$\Vert (a_i)_{i\in I} \Vert_p = \sup_{F\in\mathcal{F}}\left( \sum_{i\in F} |a_i|^p\right)^{1/p} \qquad \mbox{and} \qquad \Vert (a_i)_{i\in I}\Vert_\infty = \sup_{i\in I}|a_i| $$ Prove that $l_p(I)=\{ (a_i)_{i\in I}\} \subset \mathbb{K}:\Vert (a_i)_{i\in I} \Vert_p <\infty  \}$ is a Banach space with the norm $\Vert\cdot\Vert_p$. $l_p(I)'$ is isometrically isomorphic to $l_q(I)$ where $1/p+1/q = 1$. Given a orthonormal basis $S=\{x_i: i\in I\}$ for a Hilbert space $H$, prove that H is isometrically isomorphic to $l_2(I)$. Prove that every Hilbert Space $H$ is isometrically isomorphic to $H'$. The second item is quite the same proof of $ l_p (\mathbb{N})$, and the 4 follows immediately from 3. I'm having problems to prove item 3. The map $T:H \longrightarrow l_2(I)$ defined by $T(x)=( \langle x, x_i\rangle)_{i\in I}$ is a linear isometry. I need help to prove that T is surjective, then I can use the open map theorem and conclude the proof. : Let $y=(a_i)_{i\in I} \in l_2(I)$, consider $\sum_{i\in I} a_ix_i$. How can I show that this sum converge to an element of $H$? (I used summability, but I'm not satisfied with my argument, there is a proof that don't requires summability?)","The aim of this exercise is to prove the Riesz-Fischer theorem for Hilbert spaces that aren't separable. Let $I$ an index set and $1\leq p \leq \infty$. Let    $\mathcal{F}=\{F\subset I: F$  is finite$\}$. Given $(a_i)_{i\in >  I}\subset \mathbb{K}$, we define: $$\Vert (a_i)_{i\in I} \Vert_p = \sup_{F\in\mathcal{F}}\left( \sum_{i\in F} |a_i|^p\right)^{1/p} \qquad \mbox{and} \qquad \Vert (a_i)_{i\in I}\Vert_\infty = \sup_{i\in I}|a_i| $$ Prove that $l_p(I)=\{ (a_i)_{i\in I}\} \subset \mathbb{K}:\Vert (a_i)_{i\in I} \Vert_p <\infty  \}$ is a Banach space with the norm $\Vert\cdot\Vert_p$. $l_p(I)'$ is isometrically isomorphic to $l_q(I)$ where $1/p+1/q = 1$. Given a orthonormal basis $S=\{x_i: i\in I\}$ for a Hilbert space $H$, prove that H is isometrically isomorphic to $l_2(I)$. Prove that every Hilbert Space $H$ is isometrically isomorphic to $H'$. The second item is quite the same proof of $ l_p (\mathbb{N})$, and the 4 follows immediately from 3. I'm having problems to prove item 3. The map $T:H \longrightarrow l_2(I)$ defined by $T(x)=( \langle x, x_i\rangle)_{i\in I}$ is a linear isometry. I need help to prove that T is surjective, then I can use the open map theorem and conclude the proof. : Let $y=(a_i)_{i\in I} \in l_2(I)$, consider $\sum_{i\in I} a_ix_i$. How can I show that this sum converge to an element of $H$? (I used summability, but I'm not satisfied with my argument, there is a proof that don't requires summability?)",,"['functional-analysis', 'hilbert-spaces', 'lp-spaces']"
33,Prove that the map $f: \alpha I + \beta A^*A \mapsto \alpha + \beta ||A||^2 $ is unital,Prove that the map  is unital,f: \alpha I + \beta A^*A \mapsto \alpha + \beta ||A||^2 ,"Fix $A \in {\mathcal{A}}$, where $({\mathcal{A}},||\cdot||,*)$ is a $C^*$-algebra with unit $I$. Prove that the linear form $$ f(D_{\alpha,\beta}) = \alpha + \beta ||A||^2,~~D_{\alpha,\beta} \in \mathcal{D} $$ defined on the subspace ${\mathcal{D}}:= \{ \alpha I + \beta A^* A~~\alpha,\beta \in \mathbb{C}\} \subset {\mathcal{A}}$ has norm one. Note 1: my attempt: consider the quotient: $$ \frac{|\alpha I + \beta ||A||^2 |^2}{|| \alpha I + \beta A^* A  ||^2} = \frac{|\alpha|^2+|\beta|^2 ||A||^4 + 2Re(\alpha\overline{\beta})||A||^2}{|| ~|\alpha|^2+|\beta|^2 (A^* A)^2 + 2Re(\alpha\overline{\beta})(A^* A)~ ||} $$ where in the denominator I used the $C^*$-algebra property, $||A^* A||=||A||^2$ for all $A \in {\mathcal{A}}$. I am tempted to transform further the operator norm in the denominator but what is the theorem saying that we can do so? Note 2: if you are interested, this is an intermediate step in some book to prove the following: Theorem . For any $A \in {\mathcal{A}}$, there exists a unital ($||\omega||=1$) positive linear functional ($\omega : {\mathcal{A}} \to \mathbb{C}$) such that $\omega(A^* A) = ||A||^2$. Proof . By Hahn-Banach, extend $f: {\mathcal{D}} \to \mathbb{C}$ as above to ${\mathcal{A}}$ into a norm $1$ continuous linear form $\omega$. We conclude using a previous Lemma: ($\omega$ is positive) $\iff$ ($\omega$ is continuous and $||\omega||=\omega(I)$)","Fix $A \in {\mathcal{A}}$, where $({\mathcal{A}},||\cdot||,*)$ is a $C^*$-algebra with unit $I$. Prove that the linear form $$ f(D_{\alpha,\beta}) = \alpha + \beta ||A||^2,~~D_{\alpha,\beta} \in \mathcal{D} $$ defined on the subspace ${\mathcal{D}}:= \{ \alpha I + \beta A^* A~~\alpha,\beta \in \mathbb{C}\} \subset {\mathcal{A}}$ has norm one. Note 1: my attempt: consider the quotient: $$ \frac{|\alpha I + \beta ||A||^2 |^2}{|| \alpha I + \beta A^* A  ||^2} = \frac{|\alpha|^2+|\beta|^2 ||A||^4 + 2Re(\alpha\overline{\beta})||A||^2}{|| ~|\alpha|^2+|\beta|^2 (A^* A)^2 + 2Re(\alpha\overline{\beta})(A^* A)~ ||} $$ where in the denominator I used the $C^*$-algebra property, $||A^* A||=||A||^2$ for all $A \in {\mathcal{A}}$. I am tempted to transform further the operator norm in the denominator but what is the theorem saying that we can do so? Note 2: if you are interested, this is an intermediate step in some book to prove the following: Theorem . For any $A \in {\mathcal{A}}$, there exists a unital ($||\omega||=1$) positive linear functional ($\omega : {\mathcal{A}} \to \mathbb{C}$) such that $\omega(A^* A) = ||A||^2$. Proof . By Hahn-Banach, extend $f: {\mathcal{D}} \to \mathbb{C}$ as above to ${\mathcal{A}}$ into a norm $1$ continuous linear form $\omega$. We conclude using a previous Lemma: ($\omega$ is positive) $\iff$ ($\omega$ is continuous and $||\omega||=\omega(I)$)",,"['functional-analysis', 'operator-algebras', 'c-star-algebras']"
34,Example of tempered distribution,Example of tempered distribution,,"I am learning about tempered distributions. Today we learned that on $\mathbb{R}^n$, $\frac{1}{|x|^p}$ is a tempered distribution as long as $0 < p < n$. My question is, what goes wrong when $p \geq n$? A reference would be highly appreciated.","I am learning about tempered distributions. Today we learned that on $\mathbb{R}^n$, $\frac{1}{|x|^p}$ is a tempered distribution as long as $0 < p < n$. My question is, what goes wrong when $p \geq n$? A reference would be highly appreciated.",,"['real-analysis', 'functional-analysis', 'reference-request', 'fourier-analysis']"
35,"Prob. 8, Sec. 4.2 in Kreyszig's functional analysis book: Nonnegativity of a subadditive functional outside a sphere implies nonnegativity","Prob. 8, Sec. 4.2 in Kreyszig's functional analysis book: Nonnegativity of a subadditive functional outside a sphere implies nonnegativity",,"If a subadditive functional $p$ defined on a normed space $X$ is non-negative outside a sphere $\{ \ x \in X \ \colon \ \Vert x \Vert = r \ \}$ , then how to show that $p$ is non-negative for all $x \in X$ ? For all $x, y \in X$ , we have $p(x+y) \leq p(x) + p(y)$ . And, $p(x) \geq 0$ for all $x \in X$ such that $\Vert x \Vert > r$ , where $r$ is a given positive real number. Let $v \in X$ be arbitrary. Let $v$ be non-zero. Let $$x \colon =  \frac{r+1}{\Vert v \Vert  }  v.$$ Then $\Vert x \Vert = r+1$ . So we must have $p(x) \geq 0$ . What next? PS: Here is a solution: First, we show that $$ n p(x) \geq p(nx) \ \mbox{ for all } n \in \mathbb{N}. \tag{0} $$ For $n = 1$ , this holds trivially. So if this holds for any given $n \in \mathbb{N}$ , then we find that $$ (n+1)p(x) = np(x) + p(x) \geq p(nx) + p(x) \geq p(nx+x) = p\big( (n+1) x \big). $$ Hence (0) holds for all natural numbers $n$ . We are given that, there is a (non-negative) real number $r$ such that $$ p(x) \geq 0 \ \mbox{ for all } x \in X \mbox{ such that } \lVert x \rVert > r. \tag{1} $$ Let $x \in X$ such that $\lVert x \rVert \leq r$ . There are two cases according as $\lVert x \rVert > 0$ or $\lVert x \rVert = 0$ . Case 1: If $\lVert x \rVert > 0$ , then let us choose a natural number $n$ such that $$ \lVert nx \rVert = n \lVert x \rVert > r. $$ This along with (0) amd (1) above yields $$ n p(x) \geq p(nx) \geq 0, $$ and as $n > 0$ , so we obtain $$ p(x) \geq 0. $$ Before considering the case $\lVert x \rVert = 0$ , we note that, for any $x, y \in X$ , we have $$ p(x) = p(x - y + y) \leq p(x-y) + p(y), $$ and so $$ p(x) - p(y) \leq p(x-y),   $$ which is the same as $$ p(x-y) \geq p(x) - p(y). \tag{2} $$ Case 2: If $\lVert x \rVert = 0$ , then $x = \mathbf{0}_X$ , the zero vector in $X$ . In this case we use (2) above and find that, for any $x \in X$ , $$ p\left( \mathbf{0}_X \right) = p\big(x - x \big) \geq p(x) - p(x) = 0, $$ and so $$  p\left( \mathbf{0}_X \right) \geq 0, $$ as required. Is this proof correct? If so, is it clear enough?","If a subadditive functional defined on a normed space is non-negative outside a sphere , then how to show that is non-negative for all ? For all , we have . And, for all such that , where is a given positive real number. Let be arbitrary. Let be non-zero. Let Then . So we must have . What next? PS: Here is a solution: First, we show that For , this holds trivially. So if this holds for any given , then we find that Hence (0) holds for all natural numbers . We are given that, there is a (non-negative) real number such that Let such that . There are two cases according as or . Case 1: If , then let us choose a natural number such that This along with (0) amd (1) above yields and as , so we obtain Before considering the case , we note that, for any , we have and so which is the same as Case 2: If , then , the zero vector in . In this case we use (2) above and find that, for any , and so as required. Is this proof correct? If so, is it clear enough?","p X \{ \ x \in X \ \colon \ \Vert x \Vert = r \ \} p x \in X x, y \in X p(x+y) \leq p(x) + p(y) p(x) \geq 0 x \in X \Vert x \Vert > r r v \in X v x \colon =  \frac{r+1}{\Vert v \Vert  }  v. \Vert x \Vert = r+1 p(x) \geq 0  n p(x) \geq p(nx) \ \mbox{ for all } n \in \mathbb{N}. \tag{0}  n = 1 n \in \mathbb{N}  (n+1)p(x) = np(x) + p(x) \geq p(nx) + p(x) \geq p(nx+x) = p\big( (n+1) x \big).  n r  p(x) \geq 0 \ \mbox{ for all } x \in X \mbox{ such that } \lVert x \rVert > r. \tag{1}  x \in X \lVert x \rVert \leq r \lVert x \rVert > 0 \lVert x \rVert = 0 \lVert x \rVert > 0 n  \lVert nx \rVert = n \lVert x \rVert > r.   n p(x) \geq p(nx) \geq 0,  n > 0  p(x) \geq 0.  \lVert x \rVert = 0 x, y \in X  p(x) = p(x - y + y) \leq p(x-y) + p(y),   p(x) - p(y) \leq p(x-y),     p(x-y) \geq p(x) - p(y). \tag{2}  \lVert x \rVert = 0 x = \mathbf{0}_X X x \in X  p\left( \mathbf{0}_X \right) = p\big(x - x \big) \geq p(x) - p(x) = 0,    p\left( \mathbf{0}_X \right) \geq 0, ","['real-analysis', 'analysis', 'functional-analysis', 'normed-spaces']"
36,"$\mathcal{L}_2$ continuous functions with $f(0)=\alpha$ are dense in $\mathcal{L}_2 [-1,1]$",continuous functions with  are dense in,"\mathcal{L}_2 f(0)=\alpha \mathcal{L}_2 [-1,1]","Let $X=\mathcal{L}_2 [-1,1]$ and for any scalar $\alpha$ we define $E_\alpha=\{f\in \mathcal{L}: f \text{ continuous in } [-1,1] \text{ and } f(0)=\alpha \}$. Prove $E_\alpha$ is convex for any $\alpha$. Prove $E_\alpha$ is dense in $\mathcal{L}_2$ Prove there is no $f\in X^*$ that separates $E_\alpha$ and $E_\beta$ for $\alpha \neq \beta$. Part 1 is easy because for $f,g\in E_\alpha$ we have $\gamma f(0) +(1-\gamma)g(0)=\gamma \alpha + (1-\gamma)\alpha =\alpha$. I'm having trouble with 2 and 3. I don't know how to approach 2: I can't use the density of step functions with value $\alpha$ at zero as they are not continuous, and I can't use Luzin's theorem in $[-1,1]$ because I need the function to be continuous everywhere in the interval. I also don't see how polynomial approximations help here. How do I attack 2 and 3?  Edit: I was also hinted that in 3 i might want to describe $f(E_\alpha)$ for any $f\in X^*$, but I don't know how to follow through. Thanks in advance.","Let $X=\mathcal{L}_2 [-1,1]$ and for any scalar $\alpha$ we define $E_\alpha=\{f\in \mathcal{L}: f \text{ continuous in } [-1,1] \text{ and } f(0)=\alpha \}$. Prove $E_\alpha$ is convex for any $\alpha$. Prove $E_\alpha$ is dense in $\mathcal{L}_2$ Prove there is no $f\in X^*$ that separates $E_\alpha$ and $E_\beta$ for $\alpha \neq \beta$. Part 1 is easy because for $f,g\in E_\alpha$ we have $\gamma f(0) +(1-\gamma)g(0)=\gamma \alpha + (1-\gamma)\alpha =\alpha$. I'm having trouble with 2 and 3. I don't know how to approach 2: I can't use the density of step functions with value $\alpha$ at zero as they are not continuous, and I can't use Luzin's theorem in $[-1,1]$ because I need the function to be continuous everywhere in the interval. I also don't see how polynomial approximations help here. How do I attack 2 and 3?  Edit: I was also hinted that in 3 i might want to describe $f(E_\alpha)$ for any $f\in X^*$, but I don't know how to follow through. Thanks in advance.",,"['analysis', 'functional-analysis', 'lp-spaces']"
37,"Prob. 7, Sec. 3.8, in Erwine Kreyszig's INTRODUCTORY FUNCTIONAL ANALYSIS WITH APPLICATIONS: The dual space of a Hilbert space is a Hilbert space.","Prob. 7, Sec. 3.8, in Erwine Kreyszig's INTRODUCTORY FUNCTIONAL ANALYSIS WITH APPLICATIONS: The dual space of a Hilbert space is a Hilbert space.",,"Here's Prob. 7, Sec. 3.8 in Introductory Functional Analysis With Applications by Erwine Kreyszig: Show that the dual space $H^\prime$ of a Hilbert space $H$ is a Hilbert space with inner product $\langle \ \cdot \ , \ \cdot \ \rangle_1$ defined by    $$\langle f_z, f_v \rangle_1 \ = \ \overline{\langle z, v \rangle} \ = \ \langle v, z \rangle,$$   where $f_z(x) = \langle x, z \rangle$ for all $x \in X$. Now I know that each bounded linear functional $f \in H^\prime$ can be written as $f = f_z$, for a unique $z \in H$ with $\Vert z \Vert = \Vert f \Vert$. The sum of two bounded linear functionals on any normed space is again a bounded linear functional, and so is the scalar multiple of any bounded linear functional. Moreover, for each $z \in H$ and for each $w \in H$, we have  $$\left( f_z + f_w \right) (x) = f_z(x) + f_w(x) = \langle x, z \rangle + \langle x, w \rangle = \langle x, z+w \rangle = f_{z+w}(x)$$  for all $x \in H$. So $f_{z+w} = f_z + f_w$. For $z \in H$ and for any scalar $\alpha$, we have  $$f_{\alpha z} (x) = \langle x, \alpha z \rangle = \overline{\alpha} \langle x, z \rangle = \overline{\alpha} f_z (x) \ \mbox{ for all } \ x \in H.$$ So, $f_{\alpha z} = \overline{\alpha } f_z$. Thus the mapping $z \mapsto f_z$ of $H$ into $H^\prime$ is surjective, isometric, and conjugate linear. Moreover, the set of all bounded linear functionals on any normed space is itself a normed space, rather a Banach space. But how to show that the inner product given by Kreyszig is the (only) natural one (i.e. that which fits into what we already know from the normed space theory)?","Here's Prob. 7, Sec. 3.8 in Introductory Functional Analysis With Applications by Erwine Kreyszig: Show that the dual space $H^\prime$ of a Hilbert space $H$ is a Hilbert space with inner product $\langle \ \cdot \ , \ \cdot \ \rangle_1$ defined by    $$\langle f_z, f_v \rangle_1 \ = \ \overline{\langle z, v \rangle} \ = \ \langle v, z \rangle,$$   where $f_z(x) = \langle x, z \rangle$ for all $x \in X$. Now I know that each bounded linear functional $f \in H^\prime$ can be written as $f = f_z$, for a unique $z \in H$ with $\Vert z \Vert = \Vert f \Vert$. The sum of two bounded linear functionals on any normed space is again a bounded linear functional, and so is the scalar multiple of any bounded linear functional. Moreover, for each $z \in H$ and for each $w \in H$, we have  $$\left( f_z + f_w \right) (x) = f_z(x) + f_w(x) = \langle x, z \rangle + \langle x, w \rangle = \langle x, z+w \rangle = f_{z+w}(x)$$  for all $x \in H$. So $f_{z+w} = f_z + f_w$. For $z \in H$ and for any scalar $\alpha$, we have  $$f_{\alpha z} (x) = \langle x, \alpha z \rangle = \overline{\alpha} \langle x, z \rangle = \overline{\alpha} f_z (x) \ \mbox{ for all } \ x \in H.$$ So, $f_{\alpha z} = \overline{\alpha } f_z$. Thus the mapping $z \mapsto f_z$ of $H$ into $H^\prime$ is surjective, isometric, and conjugate linear. Moreover, the set of all bounded linear functionals on any normed space is itself a normed space, rather a Banach space. But how to show that the inner product given by Kreyszig is the (only) natural one (i.e. that which fits into what we already know from the normed space theory)?",,"['real-analysis', 'analysis', 'functional-analysis', 'hilbert-spaces', 'inner-products']"
38,"Folland, ""Real Analysis"", Chapter 5.3, Exercise 36.","Folland, ""Real Analysis"", Chapter 5.3, Exercise 36.",,"Folland, ""Real Analysis"", Chapter 5.3, Exercise 36: Let $\mathcal{X}$ be a separable Banach space and let $\mu$ be   counting measure on $\mathbf{N}$.  Suppose that   $\left\{x_n\right\}_1^\infty$ is a countable dense subset of the unit   ball of $\mathcal{X}$, and define $T \colon L^1(\mu) \to \mathcal{X}$   by $Tf = \sum_1^\infty f(n) x_n$.  (a)  $T$ is bounded.  (b)  $T$ is   surjective. I have proved (a).  I would like help on (b).  Here are my ideas so far. Say we want to show $y \in \mathcal{X}$ is in the image of $T$.  Reduce to the case $||y|| = 1$ and let $x_{n_m} \to y$.  My thought is to produce for each $N$ a function $f_N \in L^1(\mu)$ such that $||y - \sum_n^\infty f(n)x_n|| < 1/N$ and also such that the $f_N$ converge in $L^1(\mu)$ to some $f \in L^1(\mu)$.  Then use the continuity of $T$ to conclude $T(f) = y$. The way I have been setting up my inequalities is as follows. Pick $M_N$ such that for all $m > M_N$, $||y - x_{n_m}|| < 1/N$.  Then I want to define $f_N$ so that $$\sum_n^\infty f_N(n) = \sum_{m > M_N}^\infty f_N(m) = 1, $$ hence $$||y - T(f_N)|| = ||\sum_{m > M_N}^\infty f_N(m) y + \sum_n^\infty f_N(n)x_n|| \leq \sum_{m > M_N}^\infty f_N(m) || y - x_{n_m} || < \frac{1}{N}. $$  Presumably, if the $f_N$ are appropriately chosen, then I can find a dominating function and apply the Dominated Convergence Theorem to finish up. However, getting all these hypotheses to hold simultaneously has been difficult.  In essence, the difficulty seems to be in requiring that the $f_N$ be ""normalized"" as well as possess a dominating function.  If this method is feasible, at least it seems to require a bit of analysis to show the desired series all converge.  Perhaps I am missing something cleaner.  If so, a simpler solution would be much appreciated. -Thanks.","Folland, ""Real Analysis"", Chapter 5.3, Exercise 36: Let $\mathcal{X}$ be a separable Banach space and let $\mu$ be   counting measure on $\mathbf{N}$.  Suppose that   $\left\{x_n\right\}_1^\infty$ is a countable dense subset of the unit   ball of $\mathcal{X}$, and define $T \colon L^1(\mu) \to \mathcal{X}$   by $Tf = \sum_1^\infty f(n) x_n$.  (a)  $T$ is bounded.  (b)  $T$ is   surjective. I have proved (a).  I would like help on (b).  Here are my ideas so far. Say we want to show $y \in \mathcal{X}$ is in the image of $T$.  Reduce to the case $||y|| = 1$ and let $x_{n_m} \to y$.  My thought is to produce for each $N$ a function $f_N \in L^1(\mu)$ such that $||y - \sum_n^\infty f(n)x_n|| < 1/N$ and also such that the $f_N$ converge in $L^1(\mu)$ to some $f \in L^1(\mu)$.  Then use the continuity of $T$ to conclude $T(f) = y$. The way I have been setting up my inequalities is as follows. Pick $M_N$ such that for all $m > M_N$, $||y - x_{n_m}|| < 1/N$.  Then I want to define $f_N$ so that $$\sum_n^\infty f_N(n) = \sum_{m > M_N}^\infty f_N(m) = 1, $$ hence $$||y - T(f_N)|| = ||\sum_{m > M_N}^\infty f_N(m) y + \sum_n^\infty f_N(n)x_n|| \leq \sum_{m > M_N}^\infty f_N(m) || y - x_{n_m} || < \frac{1}{N}. $$  Presumably, if the $f_N$ are appropriately chosen, then I can find a dominating function and apply the Dominated Convergence Theorem to finish up. However, getting all these hypotheses to hold simultaneously has been difficult.  In essence, the difficulty seems to be in requiring that the $f_N$ be ""normalized"" as well as possess a dominating function.  If this method is feasible, at least it seems to require a bit of analysis to show the desired series all converge.  Perhaps I am missing something cleaner.  If so, a simpler solution would be much appreciated. -Thanks.",,"['real-analysis', 'functional-analysis', 'measure-theory']"
39,Unit ball separable $\Longrightarrow$ Space separable,Unit ball separable  Space separable,\Longrightarrow,"Given a normed space $X$ and assume it is also a locally convex space in some other topology (e.g. weak or weak* if it's a dual). Assume that the unit ball $B_X$ is separable in this topology. Is it then true that the $X$ is separable in this topology? I think that this is true. Let $D\subset B_X$ be dense. Then $\bigcup_{n\in\mathbb{N}} n D $ is dense in $X$, right? My attempt for the proof: Given $x\in X$, then $\frac{1}{N} x \in B_X$ for some $N$ large enough. Now there exists a sequence $(y_n)_n \subset D$ such that $y_n \to \frac{1}{N}x$ as $n\to\infty$. Hence $N y_n \to x$ and clearly $Ny_n \in N D$. Remark: In my definition of a LCS, the topology is also Hausdorff.","Given a normed space $X$ and assume it is also a locally convex space in some other topology (e.g. weak or weak* if it's a dual). Assume that the unit ball $B_X$ is separable in this topology. Is it then true that the $X$ is separable in this topology? I think that this is true. Let $D\subset B_X$ be dense. Then $\bigcup_{n\in\mathbb{N}} n D $ is dense in $X$, right? My attempt for the proof: Given $x\in X$, then $\frac{1}{N} x \in B_X$ for some $N$ large enough. Now there exists a sequence $(y_n)_n \subset D$ such that $y_n \to \frac{1}{N}x$ as $n\to\infty$. Hence $N y_n \to x$ and clearly $Ny_n \in N D$. Remark: In my definition of a LCS, the topology is also Hausdorff.",,"['functional-analysis', 'banach-spaces', 'normed-spaces', 'weak-convergence']"
40,Non-compactness of the resolvent,Non-compactness of the resolvent,,"Consider a complete non-compact Riemannian manifold $M$ and the resolvent of the Laplacian $(-\Delta + \lambda I)^{-1}$. It is known that the resolvent is in general not a compact operator. I am trying to understand why not. I realize that the proof in the compact setting does not follow through for the non-compact case because of the failure of compact Sobolev embedding. I would be happy to see why the resolvent is not compact even for $M = \mathbb{R}^n$, and a justification for general non-compact $M$ would be excellent. Thanks.","Consider a complete non-compact Riemannian manifold $M$ and the resolvent of the Laplacian $(-\Delta + \lambda I)^{-1}$. It is known that the resolvent is in general not a compact operator. I am trying to understand why not. I realize that the proof in the compact setting does not follow through for the non-compact case because of the failure of compact Sobolev embedding. I would be happy to see why the resolvent is not compact even for $M = \mathbb{R}^n$, and a justification for general non-compact $M$ would be excellent. Thanks.",,"['functional-analysis', 'differential-geometry', 'reference-request', 'microlocal-analysis']"
41,Gaining some insight about Picard–Lindelöf theorem.,Gaining some insight about Picard–Lindelöf theorem.,,"In class I have been introduced to the Picard–Lindelöf theorem. It was written down in all its technical glory.Now: the important things to remember from it were that if a function is continuous; and, suffices Lipschitz-continuity, then there is a unique solution to the given differential equation for that function. This is all very technical and surely not meant for me to be understood at this stage, but still i'd like to maybe gain some intuition behind this, especially the Lipschitz-continuity.","In class I have been introduced to the Picard–Lindelöf theorem. It was written down in all its technical glory.Now: the important things to remember from it were that if a function is continuous; and, suffices Lipschitz-continuity, then there is a unique solution to the given differential equation for that function. This is all very technical and surely not meant for me to be understood at this stage, but still i'd like to maybe gain some intuition behind this, especially the Lipschitz-continuity.",,"['functional-analysis', 'ordinary-differential-equations']"
42,A necessary and sufficient criterion for an element of a multiplier $ C^{*} $-algebra to be positive.,A necessary and sufficient criterion for an element of a multiplier -algebra to be positive., C^{*} ,"I am trying to find a reference for the following assertion: Let $ A $ be a $ C^{*} $-algebra, and let $ M(A) $ denote its multiplier algebra. Then $ m $ is a positive element of $ M(A) $ if and only if $ a^{*} m a $ is a positive element of $ A $ for all $ a \in A $. In other words,   $$ m \in M(A)_{\geq} \iff (\forall a \in A)(a^{*} m a \in A_{\geq}). $$ The forward implication is trivial because if $ m \in M(A)_{\geq} $, then there exists an $ n \in M(A) $ such that $ m = n^{*} n $, so $$ \forall a \in A: \quad     a^{*} m a =   a^{*} n^{*} n a =   (n a)^{*} (n a) \in A_{\geq}. $$ Note: $ A $ is an ideal of $ M(A) $, so $ n a \in A $ for all $ a \in A $. I have absolutely no idea how to prove the backward implication though. Thank you very much for your gracious help.","I am trying to find a reference for the following assertion: Let $ A $ be a $ C^{*} $-algebra, and let $ M(A) $ denote its multiplier algebra. Then $ m $ is a positive element of $ M(A) $ if and only if $ a^{*} m a $ is a positive element of $ A $ for all $ a \in A $. In other words,   $$ m \in M(A)_{\geq} \iff (\forall a \in A)(a^{*} m a \in A_{\geq}). $$ The forward implication is trivial because if $ m \in M(A)_{\geq} $, then there exists an $ n \in M(A) $ such that $ m = n^{*} n $, so $$ \forall a \in A: \quad     a^{*} m a =   a^{*} n^{*} n a =   (n a)^{*} (n a) \in A_{\geq}. $$ Note: $ A $ is an ideal of $ M(A) $, so $ n a \in A $ for all $ a \in A $. I have absolutely no idea how to prove the backward implication though. Thank you very much for your gracious help.",,"['functional-analysis', 'reference-request', 'operator-algebras', 'c-star-algebras']"
43,How would I show a functional is linear and bounded?,How would I show a functional is linear and bounded?,,"Using the following results, for any $f \in H^1(a,b)$, $f$ is continuous on $[a,b]$, and therefore, $$ \int_a^b f(x) dx = f(\zeta)$$ for some $\zeta \in (a,b)$. In addition $$f(c) = f(\zeta) + \int_\zeta^c f'(x)dx.$$ How would I go about showing the functional defined as  $\ell \in (H^1 (a,b))'$ by $$ \ell(v) = v(c), v \in H^1 (a,b)$$ for some $c \in [a,b]$, is linear and bounded on $H^1(a,b)$?","Using the following results, for any $f \in H^1(a,b)$, $f$ is continuous on $[a,b]$, and therefore, $$ \int_a^b f(x) dx = f(\zeta)$$ for some $\zeta \in (a,b)$. In addition $$f(c) = f(\zeta) + \int_\zeta^c f'(x)dx.$$ How would I go about showing the functional defined as  $\ell \in (H^1 (a,b))'$ by $$ \ell(v) = v(c), v \in H^1 (a,b)$$ for some $c \in [a,b]$, is linear and bounded on $H^1(a,b)$?",,"['functional-analysis', 'sobolev-spaces']"
44,"Spectrum of operator $Af(t) = \int_0^{t^2} f(s)ds$ on $L^2[0,1]$",Spectrum of operator  on,"Af(t) = \int_0^{t^2} f(s)ds L^2[0,1]","Consider a linear operator $A\colon L^2[0,1]\rightarrow L^2[0,1]$ that acts as follows: $$Af(t) = \int_0^{t^2} f(s)ds$$ The problem is to compute its spectrum. I know that the operator is compact (it is an integral operator with kernel $K(t,s)=\mathbb I\{s\leq t^2\}$), so its spectrum consists of 0 and eigenvalues. Writing an equation for its eigenvalue $\lambda$, I got $$ \begin{cases} 2t\; f(t^2) = \lambda f'(t) \\ f(0) = 0 \end{cases}  $$ I have no idea how to deal with this system or what I can do else. Thank you for help.","Consider a linear operator $A\colon L^2[0,1]\rightarrow L^2[0,1]$ that acts as follows: $$Af(t) = \int_0^{t^2} f(s)ds$$ The problem is to compute its spectrum. I know that the operator is compact (it is an integral operator with kernel $K(t,s)=\mathbb I\{s\leq t^2\}$), so its spectrum consists of 0 and eigenvalues. Writing an equation for its eigenvalue $\lambda$, I got $$ \begin{cases} 2t\; f(t^2) = \lambda f'(t) \\ f(0) = 0 \end{cases}  $$ I have no idea how to deal with this system or what I can do else. Thank you for help.",,"['functional-analysis', 'ordinary-differential-equations', 'operator-theory', 'spectral-theory']"
45,Arveson spectrum for a unitary representation of a group on a Hilbert space,Arveson spectrum for a unitary representation of a group on a Hilbert space,,"Let $G = \mathbb{R}$. By Stone's theorem, $U(t)\in\mathcal{B}(\mathcal{H})$ is generated by a self-adjoint operator $H$ (for which there is a resolution of the identity P(p), by the spectral theorem)  $$ U(t) = e^{i t H} = \int_{\mathbb{R}} e^{i pt} d P(p)$$ One can thus define a spectral subspace, e.g. of eigenvectors of $H$ with eigenvalues in $[p_1,p_2]$, given by $(P(p_2)-P(p_1))\mathcal{H}$. Let's denote it $\mathcal{H}^U([p_1,p_2])$. More generally, for a uniformly bounded action $\alpha$ of a locally compact group $G$ on a Banach space $X$, one can define the $\alpha$-spectrum $\mathrm{Sp}_{\alpha}(a)$ of $ x\in X$ as the set of maximal ideals of $L^1(G)$ containing $\mathcal{I}(a):=\{f\in L^1(G),\ \alpha_f(a) := \int_{G} f(x)\alpha_x(b) \operatorname{d}\! x \stackrel{!}{=}0\}$ By [8.2 p.218][1], maximal ideals are the kernels of the ""characters"" of $L^1(G)$ which are themselves in bijection with characters of the group via Fourier transform:  $$  \forall\ \Phi: L^1(G) \rightarrow \mathbb{C}\ \text{ algebra morphism},\ \exists !\ \gamma\in\hat{G} \ \text{ s.t. }\   \Phi(f)= \int_G \overline{\gamma(x)} f(x)\operatorname{d}\!\mu (x)=: \hat{f}(\gamma)  $$ The $\alpha$-spectrum can thus also be defined as a subset of the dual group $\hat{G}$  $$   \mathrm{Sp}_{\alpha}(a) := \{\gamma\in \hat{G},\ \hat{f}(\gamma) = 0,\ \forall\ f\in \mathcal{I}(a)\} $$ Now for a given subset $S\subset \hat{G}$ one can associate the following spectral subspaces   $$  X^{\alpha}(S) := \overline{\{a\in X,\ \mathrm{Sp}_{\alpha}(a)\subseteq S\}} $$ $$  X^{\alpha}_0(S) := \overline{\mathrm{Span}\{\alpha_f(a),\ \forall\ a\in X,\ f\in L^1(G),\ \mathrm{supp}(\hat{f})\subseteq S\}}     $$ (Relation between them: [Lemma 3.2.39 p.253][2]) [Bratteli, Robinson][2] say p.251 that it is ""easy to derive""/ p.258 that it is ""easily verified"" that $$ \mathcal{H}([p_1,p_2]) = \mathcal{H}^U ([p_1,p_2])$$ where l.h.s. is given by the projections of the spectral theorem for the generator $H$ and r.h.s. is the abstract definition with $X:=\mathcal{H}$ and $\alpha:= U$ Question: how do we see this? I have also seen, for $G= \mathbb{R}$ the following definition   $$  \mathrm{Sp}_{\alpha}(a):=\{p\in\mathbb{R},\ \forall\ U\ni p\ \text{neighborhood},\ \exists\ f\in L^1(\mathbb{R}),\ \mathrm{supp}(\hat{f})\subset U \ , \enspace \alpha_f(a)\neq 0 \}  $$ Which I find more accessible, and I guess it does agree with the one above by [3.2.40 (2) p.254][2] [1]: ""A course in functional analysis"", Conway, (actually works even if $L^1(G)$ is not unital) ; or Thm. 34B p.136-137 for some algebra of measure containing $L^1(G)$,  ""Introduction to abstract harmonic analysis"", Loomis [2]: ""Operator algebras and Quantum statistical mechanics vol. 1"", Bratelli, Robinson","Let $G = \mathbb{R}$. By Stone's theorem, $U(t)\in\mathcal{B}(\mathcal{H})$ is generated by a self-adjoint operator $H$ (for which there is a resolution of the identity P(p), by the spectral theorem)  $$ U(t) = e^{i t H} = \int_{\mathbb{R}} e^{i pt} d P(p)$$ One can thus define a spectral subspace, e.g. of eigenvectors of $H$ with eigenvalues in $[p_1,p_2]$, given by $(P(p_2)-P(p_1))\mathcal{H}$. Let's denote it $\mathcal{H}^U([p_1,p_2])$. More generally, for a uniformly bounded action $\alpha$ of a locally compact group $G$ on a Banach space $X$, one can define the $\alpha$-spectrum $\mathrm{Sp}_{\alpha}(a)$ of $ x\in X$ as the set of maximal ideals of $L^1(G)$ containing $\mathcal{I}(a):=\{f\in L^1(G),\ \alpha_f(a) := \int_{G} f(x)\alpha_x(b) \operatorname{d}\! x \stackrel{!}{=}0\}$ By [8.2 p.218][1], maximal ideals are the kernels of the ""characters"" of $L^1(G)$ which are themselves in bijection with characters of the group via Fourier transform:  $$  \forall\ \Phi: L^1(G) \rightarrow \mathbb{C}\ \text{ algebra morphism},\ \exists !\ \gamma\in\hat{G} \ \text{ s.t. }\   \Phi(f)= \int_G \overline{\gamma(x)} f(x)\operatorname{d}\!\mu (x)=: \hat{f}(\gamma)  $$ The $\alpha$-spectrum can thus also be defined as a subset of the dual group $\hat{G}$  $$   \mathrm{Sp}_{\alpha}(a) := \{\gamma\in \hat{G},\ \hat{f}(\gamma) = 0,\ \forall\ f\in \mathcal{I}(a)\} $$ Now for a given subset $S\subset \hat{G}$ one can associate the following spectral subspaces   $$  X^{\alpha}(S) := \overline{\{a\in X,\ \mathrm{Sp}_{\alpha}(a)\subseteq S\}} $$ $$  X^{\alpha}_0(S) := \overline{\mathrm{Span}\{\alpha_f(a),\ \forall\ a\in X,\ f\in L^1(G),\ \mathrm{supp}(\hat{f})\subseteq S\}}     $$ (Relation between them: [Lemma 3.2.39 p.253][2]) [Bratteli, Robinson][2] say p.251 that it is ""easy to derive""/ p.258 that it is ""easily verified"" that $$ \mathcal{H}([p_1,p_2]) = \mathcal{H}^U ([p_1,p_2])$$ where l.h.s. is given by the projections of the spectral theorem for the generator $H$ and r.h.s. is the abstract definition with $X:=\mathcal{H}$ and $\alpha:= U$ Question: how do we see this? I have also seen, for $G= \mathbb{R}$ the following definition   $$  \mathrm{Sp}_{\alpha}(a):=\{p\in\mathbb{R},\ \forall\ U\ni p\ \text{neighborhood},\ \exists\ f\in L^1(\mathbb{R}),\ \mathrm{supp}(\hat{f})\subset U \ , \enspace \alpha_f(a)\neq 0 \}  $$ Which I find more accessible, and I guess it does agree with the one above by [3.2.40 (2) p.254][2] [1]: ""A course in functional analysis"", Conway, (actually works even if $L^1(G)$ is not unital) ; or Thm. 34B p.136-137 for some algebra of measure containing $L^1(G)$,  ""Introduction to abstract harmonic analysis"", Loomis [2]: ""Operator algebras and Quantum statistical mechanics vol. 1"", Bratelli, Robinson",,"['functional-analysis', 'operator-algebras', 'harmonic-analysis', 'c-star-algebras', 'von-neumann-algebras']"
46,For any sequence from Frechet spaces there exists a sequence that takes it to zero,For any sequence from Frechet spaces there exists a sequence that takes it to zero,,"I am trying to prove following for Frechet spaces($X$): Show that any sequence $(x_n) \subset X$ there exists a sequence $(\lambda_n)$ with $\lambda_n \neq 0$, $\lambda_n \downarrow 0$ such that $\lambda_n x_n \to 0$ in $X$. But I don't really know how to start. I think need to show after $\exists N$ such that for $n>N$ $\lambda _n x_n$ is in a small neighborhood, but how to do this for any sequence from $X$. Or maybe there is a different way. Any help is appreciated.","I am trying to prove following for Frechet spaces($X$): Show that any sequence $(x_n) \subset X$ there exists a sequence $(\lambda_n)$ with $\lambda_n \neq 0$, $\lambda_n \downarrow 0$ such that $\lambda_n x_n \to 0$ in $X$. But I don't really know how to start. I think need to show after $\exists N$ such that for $n>N$ $\lambda _n x_n$ is in a small neighborhood, but how to do this for any sequence from $X$. Or maybe there is a different way. Any help is appreciated.",,"['real-analysis', 'functional-analysis']"
47,About a technique used in the proof of Hahn-Banach Theorem,About a technique used in the proof of Hahn-Banach Theorem,,"Recall Hahn-Banach (cf. Kreyszig's book) : If $X$ is a real vector space with a sublinear functional $p$ and if   $f$ is linear on a subspace $Z$ with $p(z)\geq f(z),\ z\in Z$,   then there exists an extension $F$ of $f$ on $X$ s.t. $$  \ p(x)\geq F(x),\ x\in X,\quad\rm{and}\tag{1} $$ $$F(z)=f(z),\ z\in Z.\tag{2}$$ Try and Question : In the proof there exists following technique : For $y_1\in X-Z$, define $$ F(y+ay_1):=f(y)+ac $$ This is linear. So we must show (1). To do this, in the book we have $$ f(y)-f(z)\leq p(y+y_1)+ p(-y_1-z) $$ for all $y,\ z\in Z$. This inequality and remaining part of the proof  is computational. But I do not know how we consider such inequality ? I have a question : How do we make this inequality ? Subsequent argument implies that we must take linearity from a norm (Note that norm is sublinear). Is there more approachable proof ? So have $$ f(y)-p(y+y_1)\leq p(-y_1-z)+f(z) )$$ If sup of lefthand side is $m_0$ and inf of righthand side is $m$, then we have $$ m_0 \leq c\leq m $$ That is, when we extend $f$, we must find suitable bounds $m_0,\ m_1$ : (1) $X=l^2,\ Z=(e_1)\oplus \cdots \oplus (e_{n-1})$ and $ f(x)=\frac{1}{\sqrt{n}}                       \sum_{i=1}^{n-1} x_i$ Then we have extensions : $$                       F_1(x) = \frac{1}{\sqrt{n}}                       \sum_{i=1}^{n} x_i,\ F_2(x)=\frac{1}{\sqrt{n}}                       \sum_{i=1}^{n-1} x_i$$ (2) $X=l^\infty,\ Z=(e_1)$ and $ f(x)=x_1$ Then we can have only one extension $$ F(x)=x_1 $$ In these example, wrt $X$, we have bounds $m_0,\ m_1$. The book, without detailed calculations or concrete example, gives a concise proof. Can you explain how we consider the above inequality ? Thank you.","Recall Hahn-Banach (cf. Kreyszig's book) : If $X$ is a real vector space with a sublinear functional $p$ and if   $f$ is linear on a subspace $Z$ with $p(z)\geq f(z),\ z\in Z$,   then there exists an extension $F$ of $f$ on $X$ s.t. $$  \ p(x)\geq F(x),\ x\in X,\quad\rm{and}\tag{1} $$ $$F(z)=f(z),\ z\in Z.\tag{2}$$ Try and Question : In the proof there exists following technique : For $y_1\in X-Z$, define $$ F(y+ay_1):=f(y)+ac $$ This is linear. So we must show (1). To do this, in the book we have $$ f(y)-f(z)\leq p(y+y_1)+ p(-y_1-z) $$ for all $y,\ z\in Z$. This inequality and remaining part of the proof  is computational. But I do not know how we consider such inequality ? I have a question : How do we make this inequality ? Subsequent argument implies that we must take linearity from a norm (Note that norm is sublinear). Is there more approachable proof ? So have $$ f(y)-p(y+y_1)\leq p(-y_1-z)+f(z) )$$ If sup of lefthand side is $m_0$ and inf of righthand side is $m$, then we have $$ m_0 \leq c\leq m $$ That is, when we extend $f$, we must find suitable bounds $m_0,\ m_1$ : (1) $X=l^2,\ Z=(e_1)\oplus \cdots \oplus (e_{n-1})$ and $ f(x)=\frac{1}{\sqrt{n}}                       \sum_{i=1}^{n-1} x_i$ Then we have extensions : $$                       F_1(x) = \frac{1}{\sqrt{n}}                       \sum_{i=1}^{n} x_i,\ F_2(x)=\frac{1}{\sqrt{n}}                       \sum_{i=1}^{n-1} x_i$$ (2) $X=l^\infty,\ Z=(e_1)$ and $ f(x)=x_1$ Then we can have only one extension $$ F(x)=x_1 $$ In these example, wrt $X$, we have bounds $m_0,\ m_1$. The book, without detailed calculations or concrete example, gives a concise proof. Can you explain how we consider the above inequality ? Thank you.",,"['real-analysis', 'functional-analysis', 'banach-spaces', 'normed-spaces']"
48,Spectral Measures: Helffer-Sjöstrand,Spectral Measures: Helffer-Sjöstrand,,Given a Hilbert space $\mathcal{H}$. Consider a Hamiltonian: $$H:\mathcal{D}(H)\to\mathcal{H}:\quad H=H^*$$ Regard a function: $$f\in\mathcal{C}^\infty_0(\mathbb{R}):\quad f(\mathbb{R})\subseteq\mathbb{R}$$ And an extension: $$f_E\in\mathcal{C}^\infty_0(\mathbb{C}):\quad f_E\restriction_\mathbb{R}=f\quad\bar{\partial}f_E\restriction=0$$ Then one has: $$f(H)=-\frac{1}{\pi}\int_\mathbb{C}\overline{\partial}f_E(z)R(z)\mathrm{d}\lambda_\mathbb{C}(z)$$ How can I check this?,Given a Hilbert space $\mathcal{H}$. Consider a Hamiltonian: $$H:\mathcal{D}(H)\to\mathcal{H}:\quad H=H^*$$ Regard a function: $$f\in\mathcal{C}^\infty_0(\mathbb{R}):\quad f(\mathbb{R})\subseteq\mathbb{R}$$ And an extension: $$f_E\in\mathcal{C}^\infty_0(\mathbb{C}):\quad f_E\restriction_\mathbb{R}=f\quad\bar{\partial}f_E\restriction=0$$ Then one has: $$f(H)=-\frac{1}{\pi}\int_\mathbb{C}\overline{\partial}f_E(z)R(z)\mathrm{d}\lambda_\mathbb{C}(z)$$ How can I check this?,,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'spectral-theory']"
49,Dual space of weighted $L^p(\omega)$,Dual space of weighted,L^p(\omega),"Let $\omega \in A_p$, where $A_p$ is the family of Muckenhoupt weights . I'm wondering what is the topological dual space of $L^p(\omega)$. Is it isometrically isomorphic to $L^q(\omega)$? (1/p + 1/q = 1) I have the feeling that the answer would be something like $L^q(\omega ^{1/q})$ but I don't know how to check this. My attemp: If $f \in L^p(\omega)$ and $g \in L^q(\omega)$ then $f \omega^{1/p} \in L^p$ and $g \omega^{1/q} \in L^q$ and hence, by Hölder inequality, $fg \in L^1(\omega)$. I'm not sure what this means. Should $fg$ belong to unweighted $L^1$ of is this right? Does this mean $<f,g>$ can be interpreted as a weighted pair of duality in some sense? I think I have some confussion with the concept ""pair of duality"". Any clarification or help with all this confusion would be really really appreciated. Thanks.","Let $\omega \in A_p$, where $A_p$ is the family of Muckenhoupt weights . I'm wondering what is the topological dual space of $L^p(\omega)$. Is it isometrically isomorphic to $L^q(\omega)$? (1/p + 1/q = 1) I have the feeling that the answer would be something like $L^q(\omega ^{1/q})$ but I don't know how to check this. My attemp: If $f \in L^p(\omega)$ and $g \in L^q(\omega)$ then $f \omega^{1/p} \in L^p$ and $g \omega^{1/q} \in L^q$ and hence, by Hölder inequality, $fg \in L^1(\omega)$. I'm not sure what this means. Should $fg$ belong to unweighted $L^1$ of is this right? Does this mean $<f,g>$ can be interpreted as a weighted pair of duality in some sense? I think I have some confussion with the concept ""pair of duality"". Any clarification or help with all this confusion would be really really appreciated. Thanks.",,"['analysis', 'functional-analysis', 'lp-spaces', 'duality-theorems']"
50,Prove that in a C*-algebra only orthogonal projections can sum to a projection,Prove that in a C*-algebra only orthogonal projections can sum to a projection,,"Let $A$ be a $C^*$-algebra, and let $p_1, \ldots, p_n \in A$ be projections, meaning $p_i = p_i^* = p_i^2$. Now assume that the sum $p = p_1 + \ldots + p_n$ is also a projection. How can one show that this implies that the $p_i$'s must be orthogonal, i.e. $p_ip_j = 0$ whenever $i \neq j$?","Let $A$ be a $C^*$-algebra, and let $p_1, \ldots, p_n \in A$ be projections, meaning $p_i = p_i^* = p_i^2$. Now assume that the sum $p = p_1 + \ldots + p_n$ is also a projection. How can one show that this implies that the $p_i$'s must be orthogonal, i.e. $p_ip_j = 0$ whenever $i \neq j$?",,"['functional-analysis', 'c-star-algebras', 'projection']"
51,Invariance of the Fredholm index under finite-dimensional perturbations,Invariance of the Fredholm index under finite-dimensional perturbations,,"Let's call a linear map $f : V \to W$ between vector spaces over some field Fredholm if $\ker(f)$ and $\mathrm{coker}(f)$ are finite-dimensional. (Equivalently, it represents an isomorphism in the abelian quotient category (vector spaces)/(finite-dim. vector spaces).) We can then define the Fredholm index by $$\mathrm{ind}(f) := \dim(\ker(f))-\dim(\mathrm{coker}(f)).$$ Is it true that $\mathrm{ind}(f+g)=\mathrm{ind}(f)$ if $g : V \to W$ has finite-dimensional range? I have tried to write down exact sequences and use that the Euler characteristic vanishes on such sequences, but this didn't work out. Another idea would be the following: We may assume wlog that $\mathrm{im}(g)$ is $1$-dimensional. Then write $g = w \otimes \alpha$ for some $\alpha \in V^*$ and $w \in W \setminus \{0\}$. Now two cases appear: 1) $w \in \mathrm{im}(f)$. 2) $w \notin \mathrm{im}(f)$. I have tried to compute $\dim(\ker(f+g))$ and $\dim(\mathrm{coker}(f+g))$ in each case, but didn't succeed. PS: I have borrowed the terminology for linear operators between Hilbert spaces ( Fredholm operator ). I don't know if this is standard. Notice that the proof in the Wikipedia article that the index is invariant under compact perturbations is analytic and therefore probably cannot be used here.","Let's call a linear map $f : V \to W$ between vector spaces over some field Fredholm if $\ker(f)$ and $\mathrm{coker}(f)$ are finite-dimensional. (Equivalently, it represents an isomorphism in the abelian quotient category (vector spaces)/(finite-dim. vector spaces).) We can then define the Fredholm index by $$\mathrm{ind}(f) := \dim(\ker(f))-\dim(\mathrm{coker}(f)).$$ Is it true that $\mathrm{ind}(f+g)=\mathrm{ind}(f)$ if $g : V \to W$ has finite-dimensional range? I have tried to write down exact sequences and use that the Euler characteristic vanishes on such sequences, but this didn't work out. Another idea would be the following: We may assume wlog that $\mathrm{im}(g)$ is $1$-dimensional. Then write $g = w \otimes \alpha$ for some $\alpha \in V^*$ and $w \in W \setminus \{0\}$. Now two cases appear: 1) $w \in \mathrm{im}(f)$. 2) $w \notin \mathrm{im}(f)$. I have tried to compute $\dim(\ker(f+g))$ and $\dim(\mathrm{coker}(f+g))$ in each case, but didn't succeed. PS: I have borrowed the terminology for linear operators between Hilbert spaces ( Fredholm operator ). I don't know if this is standard. Notice that the proof in the Wikipedia article that the index is invariant under compact perturbations is analytic and therefore probably cannot be used here.",,"['linear-algebra', 'functional-analysis', 'category-theory', 'exact-sequence']"
52,"Alternating series, even terms, factorial, boundedness","Alternating series, even terms, factorial, boundedness",,"I need to determine whether there exists $M>0$ such that $$| \sum_{n=0}^{\infty} \frac{(-1)^n x_{2n}}{\sqrt{n!}}| \le M \sqrt{\sum_{n=0}^{\infty}|x_n|^2}$$ $\{x_n\} \in \mathcal{l}^2, \ \ x_n \in \mathbb{K}$ I don't know what to use here. Could you help?","I need to determine whether there exists $M>0$ such that $$| \sum_{n=0}^{\infty} \frac{(-1)^n x_{2n}}{\sqrt{n!}}| \le M \sqrt{\sum_{n=0}^{\infty}|x_n|^2}$$ $\{x_n\} \in \mathcal{l}^2, \ \ x_n \in \mathbb{K}$ I don't know what to use here. Could you help?",,"['sequences-and-series', 'functional-analysis']"
53,"weak convergence of $L^2$ implies weak convergence of $W_0^{1,2}$ (up to a subsequence)?",weak convergence of  implies weak convergence of  (up to a subsequence)?,"L^2 W_0^{1,2}","In the paper that I am reading, it says that if $\{u_n\}$ are bounded in $W_0^{1,2} (\Omega)$ (bounded $\Omega\subset \mathbb{R}^N$)  and $u_n \rightharpoonup u$ weakly in $L^2 (\Omega)$, then there exist a further subsequence such that $u_{n_k} \rightharpoonup u$ in $W_0^{1,2}(\Omega)$. How do we know it is still the same limit? I know that $I: W_0^{1,p}(\Omega) \rightarrow L^2(\Omega)$ is continuous and dense for bounded $\Omega$ and $p\geq 2$. And here is my second question, given $X,Y$ are Banach spaces and $T:X\rightarrow Y$ is continuous and dense, can we say if $x_n \rightharpoonup x$ weakly in $X$, then $T(x_n) \rightharpoonup T(x)$ weakly in $Y$? If this is true, then the above is clear, since the subsequence also converges to $u$ weakly in $L^2$. If not what other conditions we need? I know compact is too strong since we actually get if $x_n \rightharpoonup x$ weakly in $X$, then $T(x_n) \rightarrow T(x)$ strongly in $Y$. Thank you very much!","In the paper that I am reading, it says that if $\{u_n\}$ are bounded in $W_0^{1,2} (\Omega)$ (bounded $\Omega\subset \mathbb{R}^N$)  and $u_n \rightharpoonup u$ weakly in $L^2 (\Omega)$, then there exist a further subsequence such that $u_{n_k} \rightharpoonup u$ in $W_0^{1,2}(\Omega)$. How do we know it is still the same limit? I know that $I: W_0^{1,p}(\Omega) \rightarrow L^2(\Omega)$ is continuous and dense for bounded $\Omega$ and $p\geq 2$. And here is my second question, given $X,Y$ are Banach spaces and $T:X\rightarrow Y$ is continuous and dense, can we say if $x_n \rightharpoonup x$ weakly in $X$, then $T(x_n) \rightharpoonup T(x)$ weakly in $Y$? If this is true, then the above is clear, since the subsequence also converges to $u$ weakly in $L^2$. If not what other conditions we need? I know compact is too strong since we actually get if $x_n \rightharpoonup x$ weakly in $X$, then $T(x_n) \rightarrow T(x)$ strongly in $Y$. Thank you very much!",,"['real-analysis', 'functional-analysis', 'operator-theory', 'sobolev-spaces', 'weak-convergence']"
54,Use Poisson summation formula to prove Gaussian sum formula,Use Poisson summation formula to prove Gaussian sum formula,,"The Poisson summation formula states that for any Schwartz function $f$, $\sum\limits_{k\in\mathbb{Z}}f(k)=\sum\limits_{k\in\mathbb{Z}}\hat{f}(k)$, where $\hat{f}$ is the Fourier transform of $f$. The question that I am trying to solve asks me to use this fact to show that $G(t)=\sum\limits_{k\in\mathbb{Z}}e^{-\pi tk^2}$ satisfies $G(t)=t^{-1/2}G(t^{-1})$ and in particular $G(t)\sim t^{-1/2}$ as $t\to 0$ (i.e. $\lim\limits_{t\to 0} t^{1/2}G(t)=1$). I tried computing the Fourier transform of $e^{-\pi tk^2}$ but I can't seem to go anywhere. I'm fairly certain that this is supposed to be an easy question but I just can't seem to find my way to the solution. Any help would be much appreciated.","The Poisson summation formula states that for any Schwartz function $f$, $\sum\limits_{k\in\mathbb{Z}}f(k)=\sum\limits_{k\in\mathbb{Z}}\hat{f}(k)$, where $\hat{f}$ is the Fourier transform of $f$. The question that I am trying to solve asks me to use this fact to show that $G(t)=\sum\limits_{k\in\mathbb{Z}}e^{-\pi tk^2}$ satisfies $G(t)=t^{-1/2}G(t^{-1})$ and in particular $G(t)\sim t^{-1/2}$ as $t\to 0$ (i.e. $\lim\limits_{t\to 0} t^{1/2}G(t)=1$). I tried computing the Fourier transform of $e^{-\pi tk^2}$ but I can't seem to go anywhere. I'm fairly certain that this is supposed to be an easy question but I just can't seem to find my way to the solution. Any help would be much appreciated.",,['functional-analysis']
55,Sequence is not in any $\ell^p$ space,Sequence is not in any  space,\ell^p,"We know the sequence {$\frac{1}{ln(n)}$} such that $(n>=2)$ converges to $zero$ but is not in any $L_p$ space because of $$\sum_{n=2}^{\infty}\left|{\frac{1}{ln(n)}}\right|^p ={\infty}$$ for any $(p>1)$ . Now let we have the following sequences :  $$x_n=\left(\frac{1}{\sqrt[n]{n}}-1\right)$$ $$y_n=\left(\sqrt[n]{n}-1\right)$$ Such that ($n>=1$)  Clearly : $x_n$ and $y_n$ converge to $zero$ But .Do you think also they are not in any $L_p$ Space ( I mean that $$\sum_{n=1}^{\infty}\left|\frac{1}{\sqrt[n]{n}}-1\right|^p={\infty}??$$ $$\sum_{n=1}^{\infty}\left|\sqrt[n]{n}-1\right|^p={\infty}??$$ For any $p>1$). I think yes  $$\sum_{n=1}^{\infty}|x_n|^p={\infty}$$ and $$\sum_{n=1}^{\infty}|y_n|^p={\infty}$$ For any $p>1$ Maybe I'm not correct , but I want the correct answer and the proof . With all my respect","We know the sequence {$\frac{1}{ln(n)}$} such that $(n>=2)$ converges to $zero$ but is not in any $L_p$ space because of $$\sum_{n=2}^{\infty}\left|{\frac{1}{ln(n)}}\right|^p ={\infty}$$ for any $(p>1)$ . Now let we have the following sequences :  $$x_n=\left(\frac{1}{\sqrt[n]{n}}-1\right)$$ $$y_n=\left(\sqrt[n]{n}-1\right)$$ Such that ($n>=1$)  Clearly : $x_n$ and $y_n$ converge to $zero$ But .Do you think also they are not in any $L_p$ Space ( I mean that $$\sum_{n=1}^{\infty}\left|\frac{1}{\sqrt[n]{n}}-1\right|^p={\infty}??$$ $$\sum_{n=1}^{\infty}\left|\sqrt[n]{n}-1\right|^p={\infty}??$$ For any $p>1$). I think yes  $$\sum_{n=1}^{\infty}|x_n|^p={\infty}$$ and $$\sum_{n=1}^{\infty}|y_n|^p={\infty}$$ For any $p>1$ Maybe I'm not correct , but I want the correct answer and the proof . With all my respect",,"['real-analysis', 'sequences-and-series', 'functional-analysis', 'lp-spaces']"
56,"Finding an explicit formula for $\int_\Gamma (z - A)^{-1} dz$, where $A$ is an operator on $l^p$","Finding an explicit formula for , where  is an operator on",\int_\Gamma (z - A)^{-1} dz A l^p,"I am working on an example from the spectral theory of linear operators on Banach spaces. This is example 6.10 from chapter VII of Conway's A Course in Functional Analysis. Let $\{\alpha_n \}_{n=1}^\infty \subset l^\infty$. For $1 \le p \le \infty$, define the bounded linear operator $A: l^p \to l^p$ by $Ax(n) = \alpha_n x(n)$ for all $x \in l^p$. It's not too difficult to show that the spectrum of $A$, denoted by $\sigma(A)$, equals $\text{cl} \left(\{\alpha_n\}_{n=1}^\infty\right)$. Suppose now that, for some index $k \in \mathbb{N}$, $\alpha_k$ is an isolated point with respect to the subspace topology on $\sigma(A)$. Then the singleton $\{\alpha_k\}$ is a clopen set in $\sigma(A)$. And we can find a smooth contour $\Gamma$ that winds once around $\{\alpha_k\}$ but not around $\sigma(A)\setminus \{\alpha_k\}$. According to the Riesz functional calculus, we may define a new bounded operator on $l^p$ by: $$E( \alpha_k; A) = \int_\Gamma (z - A)^{-1} dz.$$ And by proposition 4.11 earlier in the chapter, $E(\alpha_k ; A)$ is a idempotent. That is $E(\alpha_k ; A) \circ E(\alpha_k ; A) = E(\alpha_k ; A)$. Now, I think I understand this example so far. But then, Conway goes on to claim that $E(\alpha_k ; A)$ is equal the operator $P: l^p \to l^p $ defined  by $Px(n) = \chi_{N_k}(n)x(n)$ where $\chi_{N_k}$ is the characteristic function (defined on $\mathbb{N}$) of $N_k = \{n \in \mathbb{N} : \alpha_n = \alpha_k \}$. I'm not able to show why $E(\alpha_k ; A) = P$ as claimed. This is equality is puzzling me because I am not sure how to get started with the operator $\int_\Gamma (z - A)^{-1} dz$. Is there a trick that I could use to explicitly compute $\left( \int_\Gamma (z - A)^{-1} dz \right) x$ for arbitrary $x \in l^p$? I think the only useful observation I have made to this point is that it's clear $P$ is an idempotent (as it must be if we are to have $P = E(\alpha_k ; A)$). Hints or solutions are greatly appreciated.","I am working on an example from the spectral theory of linear operators on Banach spaces. This is example 6.10 from chapter VII of Conway's A Course in Functional Analysis. Let $\{\alpha_n \}_{n=1}^\infty \subset l^\infty$. For $1 \le p \le \infty$, define the bounded linear operator $A: l^p \to l^p$ by $Ax(n) = \alpha_n x(n)$ for all $x \in l^p$. It's not too difficult to show that the spectrum of $A$, denoted by $\sigma(A)$, equals $\text{cl} \left(\{\alpha_n\}_{n=1}^\infty\right)$. Suppose now that, for some index $k \in \mathbb{N}$, $\alpha_k$ is an isolated point with respect to the subspace topology on $\sigma(A)$. Then the singleton $\{\alpha_k\}$ is a clopen set in $\sigma(A)$. And we can find a smooth contour $\Gamma$ that winds once around $\{\alpha_k\}$ but not around $\sigma(A)\setminus \{\alpha_k\}$. According to the Riesz functional calculus, we may define a new bounded operator on $l^p$ by: $$E( \alpha_k; A) = \int_\Gamma (z - A)^{-1} dz.$$ And by proposition 4.11 earlier in the chapter, $E(\alpha_k ; A)$ is a idempotent. That is $E(\alpha_k ; A) \circ E(\alpha_k ; A) = E(\alpha_k ; A)$. Now, I think I understand this example so far. But then, Conway goes on to claim that $E(\alpha_k ; A)$ is equal the operator $P: l^p \to l^p $ defined  by $Px(n) = \chi_{N_k}(n)x(n)$ where $\chi_{N_k}$ is the characteristic function (defined on $\mathbb{N}$) of $N_k = \{n \in \mathbb{N} : \alpha_n = \alpha_k \}$. I'm not able to show why $E(\alpha_k ; A) = P$ as claimed. This is equality is puzzling me because I am not sure how to get started with the operator $\int_\Gamma (z - A)^{-1} dz$. Is there a trick that I could use to explicitly compute $\left( \int_\Gamma (z - A)^{-1} dz \right) x$ for arbitrary $x \in l^p$? I think the only useful observation I have made to this point is that it's clear $P$ is an idempotent (as it must be if we are to have $P = E(\alpha_k ; A)$). Hints or solutions are greatly appreciated.",,"['functional-analysis', 'spectral-theory']"
57,Trace class operator is an ideal,Trace class operator is an ideal,,"To show that trace class operators space is an ideal, we need to show that $\|uv\|_1\leq \|u\|\|v\|_1$ where $u,v \in B(H)$ and $\|u\|_1 = tr(|u|)$. Murphy in his book (C*-algebras and operator theory) prove it as below: Let $u=w|u|$ and $vu = w'|vu|$ be the polar decomposition of $u$ and $vu$ respectively and $w''=w'vw$ . Then $|vu| = w'^*vu=w''|u|$. Hence, $|vu|^2=|u| w''^*w''|u| \leq |u|^2\|w''\|^2 \leq |u|^2\|v\|^2$, so $|vu|\leq |u|\|v\|$. and he continues his proof to get the desired inequality. But I can not understand how he concludes $|u| w''^*w''|u| \leq |u|^2\|w''\|^2$. Please help me. Thanks.","To show that trace class operators space is an ideal, we need to show that $\|uv\|_1\leq \|u\|\|v\|_1$ where $u,v \in B(H)$ and $\|u\|_1 = tr(|u|)$. Murphy in his book (C*-algebras and operator theory) prove it as below: Let $u=w|u|$ and $vu = w'|vu|$ be the polar decomposition of $u$ and $vu$ respectively and $w''=w'vw$ . Then $|vu| = w'^*vu=w''|u|$. Hence, $|vu|^2=|u| w''^*w''|u| \leq |u|^2\|w''\|^2 \leq |u|^2\|v\|^2$, so $|vu|\leq |u|\|v\|$. and he continues his proof to get the desired inequality. But I can not understand how he concludes $|u| w''^*w''|u| \leq |u|^2\|w''\|^2$. Please help me. Thanks.",,"['functional-analysis', 'operator-theory', 'c-star-algebras', 'compact-operators']"
58,Existence of adjoint operator in Euclidean space,Existence of adjoint operator in Euclidean space,,"If we define the adjoint operator of linear operator $A:E\to E$, where $E$ is a complex or real Euclidean, $n$- or $\infty$-dimensional, space, as operator $A^\ast:E\to E$ such that $\forall x,y\in E\quad \langle Ax,y\rangle=\langle x,A^\ast y\rangle$, I wonder whether for any $A$ the adjoint exists. If it does, how can we prove it? In the case that it exists, I think -please correct me if I am wrong- it is unique as in the case of the adjoint operator of linear operator $A:E\to E_1$, with $E$ a Banach space, defined as $A^\star: E_1^\star\to E^\star$, $f\mapsto f\circ A$. Thank you very much for any answer!","If we define the adjoint operator of linear operator $A:E\to E$, where $E$ is a complex or real Euclidean, $n$- or $\infty$-dimensional, space, as operator $A^\ast:E\to E$ such that $\forall x,y\in E\quad \langle Ax,y\rangle=\langle x,A^\ast y\rangle$, I wonder whether for any $A$ the adjoint exists. If it does, how can we prove it? In the case that it exists, I think -please correct me if I am wrong- it is unique as in the case of the adjoint operator of linear operator $A:E\to E_1$, with $E$ a Banach space, defined as $A^\star: E_1^\star\to E^\star$, $f\mapsto f\circ A$. Thank you very much for any answer!",,"['functional-analysis', 'operator-theory', 'banach-spaces']"
59,Reiterate Volterra integral operator is a contraction,Reiterate Volterra integral operator is a contraction,,"I read in Kolmogorov and Fomin's Элементы теории функций и функционального анализа (p. 472 here ) the statement that Volterra operator $A:L_2[a,b]\to L_2[a,b]$ defined by$$(A\varphi)(s):=\int_{[a,s]}K(s,t)\varphi(t)d\mu_t+f(s)$$with $K\in L_2([a,b]^2)$, $f\in L_2[a,b]$, is such that $A^n$ is a contraction for some $n\in\mathbb{N}$ if $K$ is bounded . Kolmogorov and Fomin say that the proof consists of literaly repeating the reasonings of the proof for the case, which can be seen in this translation from Introductory Real Analysis , $A:C[a,b]\to C[a,b]$, $\varphi\mapsto \int_a^s K(s,t)\varphi(t)dt+f$ with $K\in C([a,b]^2)$, $f\in C[a,b]$. How can it be adapted, or how can it be otherwise proved that $A^n:L_2[a,b]\to L_2[a,b]$ is a contraction for some $n$? I thank you very much!!!","I read in Kolmogorov and Fomin's Элементы теории функций и функционального анализа (p. 472 here ) the statement that Volterra operator $A:L_2[a,b]\to L_2[a,b]$ defined by$$(A\varphi)(s):=\int_{[a,s]}K(s,t)\varphi(t)d\mu_t+f(s)$$with $K\in L_2([a,b]^2)$, $f\in L_2[a,b]$, is such that $A^n$ is a contraction for some $n\in\mathbb{N}$ if $K$ is bounded . Kolmogorov and Fomin say that the proof consists of literaly repeating the reasonings of the proof for the case, which can be seen in this translation from Introductory Real Analysis , $A:C[a,b]\to C[a,b]$, $\varphi\mapsto \int_a^s K(s,t)\varphi(t)dt+f$ with $K\in C([a,b]^2)$, $f\in C[a,b]$. How can it be adapted, or how can it be otherwise proved that $A^n:L_2[a,b]\to L_2[a,b]$ is a contraction for some $n$? I thank you very much!!!",,"['functional-analysis', 'metric-spaces', 'operator-theory', 'hilbert-spaces', 'normed-spaces']"
60,Spectrum of a Self-Adjoint Operator is Real,Spectrum of a Self-Adjoint Operator is Real,,"Preparing for an exam in functional analysis, I'm trying to show that for a self-adjoint operator $A$, $\sigma(A) \subset \mathbb{R}$. I came across the following proof in the book (or rather, lecture notes) we're using for the course. The proof is even stronger, giving bounds for the spectrum. However, I have issue with the proof. Here is the proof: Let $m = \inf_{||x||=1}{\langle Ax, x \rangle}$ and $M= \sup_{||x|=1}{\langle Ax, x \rangle}$. Let $\lambda \in \mathbb{C} \backslash [m,M]$. Define $d = \mathrm{dist}(\lambda, [m,M])$. By the Cauchy Schwarz inequality we have $||(A- \lambda I)x|| \ge |\langle (A- \lambda I)x, x \rangle| =|\langle Ax, x \rangle - \lambda| \ge d$. Thus $||A-\lambda I||$ is bounded below and is hence invertible. My problem wiht this proof is 2-fold. First, this seems to assume that (if $||x||=1$, then) $\langle Ax,x \rangle \in \mathbb{R}$. Further, I don't see how this uses the fact that $A$ is self-adjoint! If I had to guess, $A$ self-adjoint implies that $\langle Ax,x \rangle \in \mathbb{R}$ (when $||x|| = 1$), but I don't seem to be able to figure out how to make that connection. Any help is appreciated. Thanks in advance.","Preparing for an exam in functional analysis, I'm trying to show that for a self-adjoint operator $A$, $\sigma(A) \subset \mathbb{R}$. I came across the following proof in the book (or rather, lecture notes) we're using for the course. The proof is even stronger, giving bounds for the spectrum. However, I have issue with the proof. Here is the proof: Let $m = \inf_{||x||=1}{\langle Ax, x \rangle}$ and $M= \sup_{||x|=1}{\langle Ax, x \rangle}$. Let $\lambda \in \mathbb{C} \backslash [m,M]$. Define $d = \mathrm{dist}(\lambda, [m,M])$. By the Cauchy Schwarz inequality we have $||(A- \lambda I)x|| \ge |\langle (A- \lambda I)x, x \rangle| =|\langle Ax, x \rangle - \lambda| \ge d$. Thus $||A-\lambda I||$ is bounded below and is hence invertible. My problem wiht this proof is 2-fold. First, this seems to assume that (if $||x||=1$, then) $\langle Ax,x \rangle \in \mathbb{R}$. Further, I don't see how this uses the fact that $A$ is self-adjoint! If I had to guess, $A$ self-adjoint implies that $\langle Ax,x \rangle \in \mathbb{R}$ (when $||x|| = 1$), but I don't seem to be able to figure out how to make that connection. Any help is appreciated. Thanks in advance.",,"['functional-analysis', 'operator-theory']"
61,Find an approximation of the unit ball as a weak-limit of a sequence in the unit sphere,Find an approximation of the unit ball as a weak-limit of a sequence in the unit sphere,,"Let $H$ be an infinite dimensional Hilbert space. It is well known that the weak-closure of the unit ball is the unit sphere. But I want to prove it as basicaly as possible, using the weakly-sequential deffinition of closure, by actually finding a convering sequence of members of B. It is clear to me that $\overline S \subset B$ since $B$ is strong-closed and convex. For the hard and interesting part, I figured out that I could pick an orthonormal basis for $H$,$\{e_a\}_{a\in A}$, and given a $x\in B$ write it as $x=\sum_{n=1}^\infty \langle x,e_n\rangle e_n$ for $(e_n)_{n=1}^{\infty} \subset \{e_a\}_{a\in A}$. Couldn't go any further. Please guide me a bit, and let me know if you think that what I'm trying to do is possible. A nice hint would be welcomed :) Thanks!","Let $H$ be an infinite dimensional Hilbert space. It is well known that the weak-closure of the unit ball is the unit sphere. But I want to prove it as basicaly as possible, using the weakly-sequential deffinition of closure, by actually finding a convering sequence of members of B. It is clear to me that $\overline S \subset B$ since $B$ is strong-closed and convex. For the hard and interesting part, I figured out that I could pick an orthonormal basis for $H$,$\{e_a\}_{a\in A}$, and given a $x\in B$ write it as $x=\sum_{n=1}^\infty \langle x,e_n\rangle e_n$ for $(e_n)_{n=1}^{\infty} \subset \{e_a\}_{a\in A}$. Couldn't go any further. Please guide me a bit, and let me know if you think that what I'm trying to do is possible. A nice hint would be welcomed :) Thanks!",,"['real-analysis', 'functional-analysis']"
62,I need help with a proof: invertibility of $b-\lambda$ in $B$ iff $b-\lambda $ invertible in $A$,I need help with a proof: invertibility of  in  iff  invertible in,b-\lambda B b-\lambda  A,"Let $A$ be a unital $C^\ast$ algebra and let $B$ be a $\ast$ subalgebra such that $B \oplus \mathbb C = A$ and such that the unit in $B$, $1_B$, is not equal to the unit in $A$. I am trying to show: If $\lambda \in \mathbb C$ is non-zero then $b-\lambda\cdot 1_B$ is invertible in $B$ if and only if $b-\lambda \cdot 1_A$ is invertible in $A$. (see Murphy's book at the top of page 45). I started the proof like this: Let $b-\lambda\cdot 1_B$ be invertible in $B$. Then it is also invertible in $A$. Let $a \in A$ denote its inverse. Then $$ ba - \lambda 1_B a = 1_A$$ Now the goal is to find $c \in A$ such that $(b -\lambda 1_A)c = 1_A$. Somehow I have to show that $1_B a = 1_A c$ but I can't seem to do it. So this leads nowhere. Can someone help me prove this please?","Let $A$ be a unital $C^\ast$ algebra and let $B$ be a $\ast$ subalgebra such that $B \oplus \mathbb C = A$ and such that the unit in $B$, $1_B$, is not equal to the unit in $A$. I am trying to show: If $\lambda \in \mathbb C$ is non-zero then $b-\lambda\cdot 1_B$ is invertible in $B$ if and only if $b-\lambda \cdot 1_A$ is invertible in $A$. (see Murphy's book at the top of page 45). I started the proof like this: Let $b-\lambda\cdot 1_B$ be invertible in $B$. Then it is also invertible in $A$. Let $a \in A$ denote its inverse. Then $$ ba - \lambda 1_B a = 1_A$$ Now the goal is to find $c \in A$ such that $(b -\lambda 1_A)c = 1_A$. Somehow I have to show that $1_B a = 1_A c$ but I can't seem to do it. So this leads nowhere. Can someone help me prove this please?",,['functional-analysis']
63,Prove that $f(x) = |x|$ belongs to $D'( \mathbb{R})$,Prove that  belongs to,f(x) = |x| D'( \mathbb{R}),"Prove that $f : \mathbb{R} \rightarrow \mathbb{R}, f(x) = |x|$ belongs to $D'(\mathbb{R})$ and find its first and second distributional derivatives, $f', f''$. To prove its linearity I used the linearity of the integral so: $\langle f, \alpha\phi+\beta\psi \rangle = \int_\mathbb{R}{|x|[\alpha\phi(x) + \beta\psi(x)]dx} = \alpha \langle f, \phi \rangle +\beta \langle f, \psi \rangle$ Then I tried to proved its continuity showing that $|\int_\mathbb{R}{|x|\phi(x)dx}| <M||\phi||_{D(\mathbb{R})}$ : $$\left|\int_\mathbb{R}{|x|\phi(x)dx}\right| \leq \left|\int_\mathbb{R}{|x| |\phi(x)|dx}\right| = \left|\int_{\operatorname{supp}(\phi)}{|x| |\phi(x)|dx}\right| \leq ||\phi||\int_{\operatorname{supp}(\phi)}{|x|dx}$$ but $\int_{\operatorname{supp}(\phi)}|x|dx$ doesn't converge if $\operatorname{supp}(\phi) = \mathbb{R}$. So I tried to prove continuity by showing that it's continuous in zero. $\langle f, 0 \rangle = 0$ $\langle f, \phi_k \rangle - \langle f, \phi \rangle = \int_\mathbb{R}|x|(\phi_k-\phi)dx \leq \sup|\phi_k-\phi|\int_\mathbb{R}|x|dx \rightarrow 0$ for $\phi_k \rightarrow\ \phi$ Is this correct? Do I have to make some observations to justify it? Is generally more convenient or easier to prove continuity in the latter way than in the former?","Prove that $f : \mathbb{R} \rightarrow \mathbb{R}, f(x) = |x|$ belongs to $D'(\mathbb{R})$ and find its first and second distributional derivatives, $f', f''$. To prove its linearity I used the linearity of the integral so: $\langle f, \alpha\phi+\beta\psi \rangle = \int_\mathbb{R}{|x|[\alpha\phi(x) + \beta\psi(x)]dx} = \alpha \langle f, \phi \rangle +\beta \langle f, \psi \rangle$ Then I tried to proved its continuity showing that $|\int_\mathbb{R}{|x|\phi(x)dx}| <M||\phi||_{D(\mathbb{R})}$ : $$\left|\int_\mathbb{R}{|x|\phi(x)dx}\right| \leq \left|\int_\mathbb{R}{|x| |\phi(x)|dx}\right| = \left|\int_{\operatorname{supp}(\phi)}{|x| |\phi(x)|dx}\right| \leq ||\phi||\int_{\operatorname{supp}(\phi)}{|x|dx}$$ but $\int_{\operatorname{supp}(\phi)}|x|dx$ doesn't converge if $\operatorname{supp}(\phi) = \mathbb{R}$. So I tried to prove continuity by showing that it's continuous in zero. $\langle f, 0 \rangle = 0$ $\langle f, \phi_k \rangle - \langle f, \phi \rangle = \int_\mathbb{R}|x|(\phi_k-\phi)dx \leq \sup|\phi_k-\phi|\int_\mathbb{R}|x|dx \rightarrow 0$ for $\phi_k \rightarrow\ \phi$ Is this correct? Do I have to make some observations to justify it? Is generally more convenient or easier to prove continuity in the latter way than in the former?",,"['functional-analysis', 'distribution-theory']"
64,Cardinality of basis of endormophism algebra,Cardinality of basis of endormophism algebra,,"Is there a relation between the cardinality of the basis of a vector space $V$ over $k$ and the cardinality of the basis of $\operatorname{End}{V}$, the set of $k$-linear endormophisms of $V$, over $k$?  Please give me some hints, thanks. (I know that if $\dim{V}$ is finite then $\operatorname{End}{V}$ has dimension $(\dim{V})^2$. But the standard basis used here, viz the 'Kronecker delta' linear maps, doesn't work if $\dim{V}$ is infinite because for example the identity linear map from $k^\mathbb{N}$ to itself is not a finite linear combination of these Kronecker delta maps...)","Is there a relation between the cardinality of the basis of a vector space $V$ over $k$ and the cardinality of the basis of $\operatorname{End}{V}$, the set of $k$-linear endormophisms of $V$, over $k$?  Please give me some hints, thanks. (I know that if $\dim{V}$ is finite then $\operatorname{End}{V}$ has dimension $(\dim{V})^2$. But the standard basis used here, viz the 'Kronecker delta' linear maps, doesn't work if $\dim{V}$ is infinite because for example the identity linear map from $k^\mathbb{N}$ to itself is not a finite linear combination of these Kronecker delta maps...)",,['linear-algebra']
65,Uniqueness of projection in a Banach space,Uniqueness of projection in a Banach space,,"Let $X$ be a Banach space, $M$ be a subspace of $X$ and $x \in X$ be any vector in $X$. Consider $\displaystyle \hat{x}_M=\arg \inf_{m\in M}\|x - m\|$. Under what conditions for $l_p$ norms $p = 1,...,\infty$ is $\hat{x}_M$ unique? Assume that solutions to this infimization problem exist. Note: Uniqueness may not be possible for all $l_p$ norms. I am aware about counter examples in $l_\infty$ but would like to know counter examples as well as restrictions under which uniqueness would prevail in other $l_p$ norms.","Let $X$ be a Banach space, $M$ be a subspace of $X$ and $x \in X$ be any vector in $X$. Consider $\displaystyle \hat{x}_M=\arg \inf_{m\in M}\|x - m\|$. Under what conditions for $l_p$ norms $p = 1,...,\infty$ is $\hat{x}_M$ unique? Assume that solutions to this infimization problem exist. Note: Uniqueness may not be possible for all $l_p$ norms. I am aware about counter examples in $l_\infty$ but would like to know counter examples as well as restrictions under which uniqueness would prevail in other $l_p$ norms.",,"['functional-analysis', 'convex-analysis', 'banach-spaces', 'locally-convex-spaces']"
66,Greatest open ball of invertible elements in a Banach algebra,Greatest open ball of invertible elements in a Banach algebra,,"Let $a$ be an invertible element of a Banach algebra $A$. Then we know that also each $a+b$ with $b\in A$ and $||b||<||a^{-1}||^{-1}$ is invertible. Now my question is whether $B_{||a^{-1}||^{-1}}(a)$ is already the greatest open ball of invertible elements around $a$? Or, in other words, is the following true: For all invertible $a\in A$ there is a $b\in A$ such that $||b||=||a^{-1}||^{-1}$ and $a+b$ is not invertible.","Let $a$ be an invertible element of a Banach algebra $A$. Then we know that also each $a+b$ with $b\in A$ and $||b||<||a^{-1}||^{-1}$ is invertible. Now my question is whether $B_{||a^{-1}||^{-1}}(a)$ is already the greatest open ball of invertible elements around $a$? Or, in other words, is the following true: For all invertible $a\in A$ there is a $b\in A$ such that $||b||=||a^{-1}||^{-1}$ and $a+b$ is not invertible.",,"['functional-analysis', 'banach-algebras']"
67,Why are the hypotheses of Zorn's lemma met in this proof about decomposing a Hilbert space into invariant subspaces?,Why are the hypotheses of Zorn's lemma met in this proof about decomposing a Hilbert space into invariant subspaces?,,"Let $H$ be a separable complex Hilbert space and let $\mathcal{A} \subset B(H)$ be an algebra of bounded linear operators on $H$ which is closed under adjoints. I've just read a very short proof that $H$ can be written as a Hilbert space direct sum of closed $\mathcal{A}$-cyclic subspaces.  Here a subspace, $V$, is $\mathcal{A}$-cyclic if there exists $v\in V$ such that $V=\overline{\mathcal{A}v}$. The proof starts by invoking Zorn's lemma: ""By Zorn's lemma, let $V$ be a closed $\mathcal{A}$-invariant subspace maximal with respect to the existence of such a decomposition."" I don't quite see how the conditions of Zorn's lemma are met, however. In particular, if $\{V_i\}_{i\in I}$ is a set of closed $\mathcal{A}$-invariant subspaces totally ordered by inclusion and if each $V_i$ can be written as a Hilbert space direct sum of $\mathcal{A}$-cyclic subspaces, why is this chain bounded above?  I feel like there are some subtleties to do with orderings.  My only thought is to maybe imbed a co-final ordinal in $I$ and use transfinite induction (???)  Or am i over thinking this?","Let $H$ be a separable complex Hilbert space and let $\mathcal{A} \subset B(H)$ be an algebra of bounded linear operators on $H$ which is closed under adjoints. I've just read a very short proof that $H$ can be written as a Hilbert space direct sum of closed $\mathcal{A}$-cyclic subspaces.  Here a subspace, $V$, is $\mathcal{A}$-cyclic if there exists $v\in V$ such that $V=\overline{\mathcal{A}v}$. The proof starts by invoking Zorn's lemma: ""By Zorn's lemma, let $V$ be a closed $\mathcal{A}$-invariant subspace maximal with respect to the existence of such a decomposition."" I don't quite see how the conditions of Zorn's lemma are met, however. In particular, if $\{V_i\}_{i\in I}$ is a set of closed $\mathcal{A}$-invariant subspaces totally ordered by inclusion and if each $V_i$ can be written as a Hilbert space direct sum of $\mathcal{A}$-cyclic subspaces, why is this chain bounded above?  I feel like there are some subtleties to do with orderings.  My only thought is to maybe imbed a co-final ordinal in $I$ and use transfinite induction (???)  Or am i over thinking this?",,"['functional-analysis', 'set-theory']"
68,"The isomorphism of the Morrey space $L^{2, n} (\Omega)$ and $L^{\infty} \cap L^2 (\Omega)$",The isomorphism of the Morrey space  and,"L^{2, n} (\Omega) L^{\infty} \cap L^2 (\Omega)","The Morrey space $L^{2, \nu} (\Omega)$ for an open set $\Omega \subset \mathbb{R}^n$ and for $1 \leq \nu \leq n$ is defined as $$L^{2, n} (\Omega) = \{ f \in L^2(\Omega); \hspace{2mm} [f]^2_{L^{2, \nu}} = \sup_{x_0 \in \Omega, \hspace{1mm} 0<r<1} \left( r^{-\nu} \int_{\Omega_r(x_0)}|f|^2 dx \right) < \infty \}$$ where $\Omega_r(x_0) = \Omega \cap B_r(x_0)$ with $B_r(x_0) \subset \mathbb{R}^n$ the ball with radius $r$. I've read that  $L^{2, n} (\Omega) \cong L^{\infty} \cap L^2 (\Omega)$. I can see that we can embed $L^{\infty} \cap L^2 (\Omega)$ in the space $L^{2, n} (\Omega)$. But how can one see the other embedding? Thanks in advance for any help!","The Morrey space $L^{2, \nu} (\Omega)$ for an open set $\Omega \subset \mathbb{R}^n$ and for $1 \leq \nu \leq n$ is defined as $$L^{2, n} (\Omega) = \{ f \in L^2(\Omega); \hspace{2mm} [f]^2_{L^{2, \nu}} = \sup_{x_0 \in \Omega, \hspace{1mm} 0<r<1} \left( r^{-\nu} \int_{\Omega_r(x_0)}|f|^2 dx \right) < \infty \}$$ where $\Omega_r(x_0) = \Omega \cap B_r(x_0)$ with $B_r(x_0) \subset \mathbb{R}^n$ the ball with radius $r$. I've read that  $L^{2, n} (\Omega) \cong L^{\infty} \cap L^2 (\Omega)$. I can see that we can embed $L^{\infty} \cap L^2 (\Omega)$ in the space $L^{2, n} (\Omega)$. But how can one see the other embedding? Thanks in advance for any help!",,"['functional-analysis', 'lp-spaces']"
69,"Compact closure in $C([0,2])$",Compact closure in,"C([0,2])","a) Does the closure of $\left\{f_n(x)=\sin(x^n):n=1,2,3\dots\right\}$ form the a compact subset of $C([0,2])?$ b) Does the closure of $\left\{f_n(x)=\sin(x^\frac1n):n=1,2,3\dots\right\}$ form the a compact subset of $C([0,2])?$ I think yes for a) because it is uniformly bounded and for equicontinuous $$\begin{align}|f_n(x)-f_n(y)|&=|\sin(x^n)-\sin(y^n)|\\ &\le|x^n-y^n|\\&=|x-y||x^{n-1}+x^{n-2}y+...+y^{n-1}|\\ &\le M|x-y|\lt \epsilon \end{align}$$ Isn't it correct? please, if I'm wrong then correct me. I think b) is not true but i don't have right counterexample. Your help will be appreciated..","a) Does the closure of $\left\{f_n(x)=\sin(x^n):n=1,2,3\dots\right\}$ form the a compact subset of $C([0,2])?$ b) Does the closure of $\left\{f_n(x)=\sin(x^\frac1n):n=1,2,3\dots\right\}$ form the a compact subset of $C([0,2])?$ I think yes for a) because it is uniformly bounded and for equicontinuous $$\begin{align}|f_n(x)-f_n(y)|&=|\sin(x^n)-\sin(y^n)|\\ &\le|x^n-y^n|\\&=|x-y||x^{n-1}+x^{n-2}y+...+y^{n-1}|\\ &\le M|x-y|\lt \epsilon \end{align}$$ Isn't it correct? please, if I'm wrong then correct me. I think b) is not true but i don't have right counterexample. Your help will be appreciated..",,"['real-analysis', 'functional-analysis', 'compactness']"
70,A question on a lemma about the product map,A question on a lemma about the product map,,"Here is a Lemma in the book “C*-algebras and Finite-Dimensional Approximations”: Lemma 3.8.4. Let $A$ be a C*-algebra, $M\subset B(H)$ be a con Neumann algebra and $\phi: A\rightarrow M$ be a completely positive map. Assume that the product map   $$\phi \times \iota_{M}: A\odot M’ \rightarrow B(H),~\phi(\sum\limits_{i}a_{i}\otimes m_{i}’)=\sum\limits_{i}\phi(a_{i})m_{i}’.$$   is continuous with respect to the spatial (or minimal) tensor product norm and let $\pi: M\rightarrow B(K)$ be any normal representation. Then the product map $$(\pi \circ \phi)\times \iota_{\pi(M)’}: A\odot \pi(M)’\rightarrow B(K).$$   is also min-continuous (That is, continuous with respect to the spatial (or minimal) tensor product norm). Proof. Any normal representation of $M$ can be identified with the cut-down by a projection in the commutant of the representation $M\otimes 1_{K}\subset B(H\otimes K)$. Hence it suffices to show that the product map with the commutant in this particular representation is min-continuous. Since $(M\otimes 1_{K})'\cap B(H\otimes K)=M'\bar{\otimes} B(K)$ (Here, the $\bar{\otimes}$ denote the tensor product of two von Neumann algebra) -- just think of $B(H\otimes K)$ as matrices with entries in $B(H)$ -- we thus have to show that   $$(\phi\otimes1_{B(K)})\times\iota_{M'\bar{\otimes}B(K)}: A\odot(M'\bar{\otimes B(K)}~)\rightarrow B(H\otimes K)$$   is min-continuous. But, excepet for the horrific notation required, this is easy since $(\phi\otimes1_{B(K)})\times\iota_{M'\bar{\otimes}B(K)}$ is a point-strong limit of min-continuous maps (with uniformly bounded norms). More precisely, if $P\in B(K)$ is a finite-rank projection, then the map   $$(\phi\otimes1_{B(PK)})\times\iota_{M'\bar{\otimes}B(PK)}: A\odot(M'\bar{\otimes B(PK)}~)\rightarrow B(H\otimes PK)$$ is min-continuous and its norm is bounded by $||\phi\times \iota_{M'}||$ because it can be identified with $$(\phi\times\iota_{M'})\otimes id_{B(PK)}: (A\odot M')\odot B(PK)\rightarrow B(H\otimes PK)$$ (Here, it use the Exercise 3.5.1 in this book). Finally, taking a net $\{P_{\lambda}\}$ of finite-rank projections which converge to $1_{K}$ in the strong operator topology and fixing $$x=\sum a_{i}\otimes T_{i}\in A\odot (M'\bar{\otimes}B(K)),$$   it is easy to check that    $$(\phi\otimes 1_{B(P_{\lambda}K)})\times \iota_{M'\otimes B(P_{\lambda}K)}((1_{H}\otimes P_{\lambda})x(1_{H}\otimes P_{\lambda}))\rightarrow (\phi \otimes 1_{B(K)})\times \iota_{M'\bar{\otimes}B(K)}(x).$$   in the strong operator topology. This completes the proof. I have three questions on the proof above: How to comprehend the first sentence ""Any normal representation of $M$ can be identified with the cut-down by a projection in the commutant of the representation $M\otimes 1_{K}\subset B(H\otimes K)$."" Why does $(M\otimes 1_{K})'\cap B(H\otimes K)=M'\bar{\otimes} B(K)$ hold? How to check the last srong operator topology $$(\phi\otimes 1_{B(P_{\lambda}K)})\times \iota_{M'\otimes B(P_{\lambda}K)}((1_{H}\otimes P_{\lambda})x(1_{H}\otimes P_{\lambda}))\rightarrow (\phi \otimes 1_{B(K)})\times \iota_{M'\bar{\otimes}B(K)}(x).$$","Here is a Lemma in the book “C*-algebras and Finite-Dimensional Approximations”: Lemma 3.8.4. Let $A$ be a C*-algebra, $M\subset B(H)$ be a con Neumann algebra and $\phi: A\rightarrow M$ be a completely positive map. Assume that the product map   $$\phi \times \iota_{M}: A\odot M’ \rightarrow B(H),~\phi(\sum\limits_{i}a_{i}\otimes m_{i}’)=\sum\limits_{i}\phi(a_{i})m_{i}’.$$   is continuous with respect to the spatial (or minimal) tensor product norm and let $\pi: M\rightarrow B(K)$ be any normal representation. Then the product map $$(\pi \circ \phi)\times \iota_{\pi(M)’}: A\odot \pi(M)’\rightarrow B(K).$$   is also min-continuous (That is, continuous with respect to the spatial (or minimal) tensor product norm). Proof. Any normal representation of $M$ can be identified with the cut-down by a projection in the commutant of the representation $M\otimes 1_{K}\subset B(H\otimes K)$. Hence it suffices to show that the product map with the commutant in this particular representation is min-continuous. Since $(M\otimes 1_{K})'\cap B(H\otimes K)=M'\bar{\otimes} B(K)$ (Here, the $\bar{\otimes}$ denote the tensor product of two von Neumann algebra) -- just think of $B(H\otimes K)$ as matrices with entries in $B(H)$ -- we thus have to show that   $$(\phi\otimes1_{B(K)})\times\iota_{M'\bar{\otimes}B(K)}: A\odot(M'\bar{\otimes B(K)}~)\rightarrow B(H\otimes K)$$   is min-continuous. But, excepet for the horrific notation required, this is easy since $(\phi\otimes1_{B(K)})\times\iota_{M'\bar{\otimes}B(K)}$ is a point-strong limit of min-continuous maps (with uniformly bounded norms). More precisely, if $P\in B(K)$ is a finite-rank projection, then the map   $$(\phi\otimes1_{B(PK)})\times\iota_{M'\bar{\otimes}B(PK)}: A\odot(M'\bar{\otimes B(PK)}~)\rightarrow B(H\otimes PK)$$ is min-continuous and its norm is bounded by $||\phi\times \iota_{M'}||$ because it can be identified with $$(\phi\times\iota_{M'})\otimes id_{B(PK)}: (A\odot M')\odot B(PK)\rightarrow B(H\otimes PK)$$ (Here, it use the Exercise 3.5.1 in this book). Finally, taking a net $\{P_{\lambda}\}$ of finite-rank projections which converge to $1_{K}$ in the strong operator topology and fixing $$x=\sum a_{i}\otimes T_{i}\in A\odot (M'\bar{\otimes}B(K)),$$   it is easy to check that    $$(\phi\otimes 1_{B(P_{\lambda}K)})\times \iota_{M'\otimes B(P_{\lambda}K)}((1_{H}\otimes P_{\lambda})x(1_{H}\otimes P_{\lambda}))\rightarrow (\phi \otimes 1_{B(K)})\times \iota_{M'\bar{\otimes}B(K)}(x).$$   in the strong operator topology. This completes the proof. I have three questions on the proof above: How to comprehend the first sentence ""Any normal representation of $M$ can be identified with the cut-down by a projection in the commutant of the representation $M\otimes 1_{K}\subset B(H\otimes K)$."" Why does $(M\otimes 1_{K})'\cap B(H\otimes K)=M'\bar{\otimes} B(K)$ hold? How to check the last srong operator topology $$(\phi\otimes 1_{B(P_{\lambda}K)})\times \iota_{M'\otimes B(P_{\lambda}K)}((1_{H}\otimes P_{\lambda})x(1_{H}\otimes P_{\lambda}))\rightarrow (\phi \otimes 1_{B(K)})\times \iota_{M'\bar{\otimes}B(K)}(x).$$",,"['functional-analysis', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras']"
71,"If $h$ is closer to $f$ than to $g$, its integral on $\{f > g\}$ must ""agree"" with $f$'s?","If  is closer to  than to , its integral on  must ""agree"" with 's?",h f g \{f > g\} f,"I have the following question (a result I would like to prove, with an admirable record of failing at it so far) -- I actually do not know if it is obvious or just plain wrong. Let $f,g,h\colon [0,1]\to\mathbb{R}_+$ be 3 (integrable) functions such that $\int_{[0,1]}f=\int_{[0,1]}g=\int_{[0,1]}h=1$; set $$A_{fg}\stackrel{\rm def}{=}\left\{x\in[0,1]\mid f(x) > g(x)\right\}$$ and write $\omega_f=\int_{A_{fg}} f$, $\omega_g=\int_{A_{fg}} g$, $\omega_h=\int_{A_{fg}} h$. Suppose $\int_{[0,1]} \lvert g - h\rvert \geq \int_{[0,1]} \lvert f - h\rvert + \gamma$, for some constant $\gamma > 0$. Can we prove a quantitative bound on $\omega_h$, namely that it must be ""closer to $\omega_f$ than to $\omega_g$?"". I hope that a statement of this form holds: There exists an absolute constant $c>0$ (e.g., $1/10$) such that $\omega_h > \frac{\omega_f+\omega_g}{2}+c\cdot\gamma$. It does sound ""intuitive"" to me, yet I have learnt not to give too much credit to my intuition. Especially since I have been struggling with this for one day now, and quite a few sheets of paper: I know how to prove it with the extra assumption that $\int_{[0,1]} \lvert f - h\rvert \leq \frac{\gamma}{10}$, but this is not enough for my purpose. Small note: one can assume without loss of generality $f,g,h$ to be ""regular enough"" (continuous, for instance).","I have the following question (a result I would like to prove, with an admirable record of failing at it so far) -- I actually do not know if it is obvious or just plain wrong. Let $f,g,h\colon [0,1]\to\mathbb{R}_+$ be 3 (integrable) functions such that $\int_{[0,1]}f=\int_{[0,1]}g=\int_{[0,1]}h=1$; set $$A_{fg}\stackrel{\rm def}{=}\left\{x\in[0,1]\mid f(x) > g(x)\right\}$$ and write $\omega_f=\int_{A_{fg}} f$, $\omega_g=\int_{A_{fg}} g$, $\omega_h=\int_{A_{fg}} h$. Suppose $\int_{[0,1]} \lvert g - h\rvert \geq \int_{[0,1]} \lvert f - h\rvert + \gamma$, for some constant $\gamma > 0$. Can we prove a quantitative bound on $\omega_h$, namely that it must be ""closer to $\omega_f$ than to $\omega_g$?"". I hope that a statement of this form holds: There exists an absolute constant $c>0$ (e.g., $1/10$) such that $\omega_h > \frac{\omega_f+\omega_g}{2}+c\cdot\gamma$. It does sound ""intuitive"" to me, yet I have learnt not to give too much credit to my intuition. Especially since I have been struggling with this for one day now, and quite a few sheets of paper: I know how to prove it with the extra assumption that $\int_{[0,1]} \lvert f - h\rvert \leq \frac{\gamma}{10}$, but this is not enough for my purpose. Small note: one can assume without loss of generality $f,g,h$ to be ""regular enough"" (continuous, for instance).",,"['functional-analysis', 'definite-integrals']"
72,"Convergence in $L^p$ plus bounded gradient implies that the limit belongs to $W^{1,p}$?",Convergence in  plus bounded gradient implies that the limit belongs to ?,"L^p W^{1,p}","I have a question with this problem I have found in the latest edition of the book Functional analysis, Sobolev Spaces author Haim Brezis pag 264 Remark 4 Let $(u_n) \subset W^{1,p} $ such that $u_n \longrightarrow u$ in $L^p$ and $(\nabla u_n)$ is bounded in $(L^p)^N$ to conclude that $u \in W^{1,p} $. I appreciate any help beforehand.","I have a question with this problem I have found in the latest edition of the book Functional analysis, Sobolev Spaces author Haim Brezis pag 264 Remark 4 Let $(u_n) \subset W^{1,p} $ such that $u_n \longrightarrow u$ in $L^p$ and $(\nabla u_n)$ is bounded in $(L^p)^N$ to conclude that $u \in W^{1,p} $. I appreciate any help beforehand.",,"['functional-analysis', 'sobolev-spaces', 'lp-spaces']"
73,Is a function $f$ with $f(X)\perp (I-f)(X)$ necessarily linear?,Is a function  with  necessarily linear?,f f(X)\perp (I-f)(X),"Let $X$ be a real or complex inner-product space, and let $f : X\rightarrow X$ be a function such that every element of $f(X)$ is orthogonal to every element of $(I-f)(X)$. Prove or give a counterexample to the claim that $f=P$ where $P$ is a linear, orthogonal projection, i.e., $$            P^{2}=P,\;\; (Px,y)=(x,Py),\;\; x,y \in X. $$","Let $X$ be a real or complex inner-product space, and let $f : X\rightarrow X$ be a function such that every element of $f(X)$ is orthogonal to every element of $(I-f)(X)$. Prove or give a counterexample to the claim that $f=P$ where $P$ is a linear, orthogonal projection, i.e., $$            P^{2}=P,\;\; (Px,y)=(x,Py),\;\; x,y \in X. $$",,"['functional-analysis', 'inner-products']"
74,Weak* convergence in $(L^q)^*$ and convergence in $L^p$,Weak* convergence in  and convergence in,(L^q)^* L^p,"Let $\{\phi_n\}$ be a sequence in $L^p(X)$. Assume that $\phi_n\to \phi$ weak* under the natural identification $L^p\cong (L^q)^*$. Of course, it is not true in general that $\phi_n\to \phi$ in $L^p$ and we can't even hope for $\|\phi_n\|_p \to \|\phi\|_p$. My question is whether something can be said about the relation between $\|\phi\|_p$ and $\lim_n \|\phi_n\|_p$. I guess that the correct relation should be something like $$ \|\phi\|_p\le \liminf \|\phi_n\|_p $$ at least in some cases. (If it helps, feel free to consider special cases for $1\le p\le\infty$ and/or $X$). Thanks!","Let $\{\phi_n\}$ be a sequence in $L^p(X)$. Assume that $\phi_n\to \phi$ weak* under the natural identification $L^p\cong (L^q)^*$. Of course, it is not true in general that $\phi_n\to \phi$ in $L^p$ and we can't even hope for $\|\phi_n\|_p \to \|\phi\|_p$. My question is whether something can be said about the relation between $\|\phi\|_p$ and $\lim_n \|\phi_n\|_p$. I guess that the correct relation should be something like $$ \|\phi\|_p\le \liminf \|\phi_n\|_p $$ at least in some cases. (If it helps, feel free to consider special cases for $1\le p\le\infty$ and/or $X$). Thanks!",,"['real-analysis', 'functional-analysis', 'lp-spaces', 'harmonic-analysis', 'weak-convergence']"
75,Linear and monotone mapping,Linear and monotone mapping,,"Let $f:\mathbb{R}^n \rightarrow \mathbb{R}^n$ be continuous and monotone , i.e., $$ \left( f(x) - f(y) \right)^\top \left( x-y\right) \geq 0$$ for all $x,y \in \mathbb{R}^n$. Say for which matrices $A \in \mathbb{R}^{n \times n}$, the function $x \mapsto A f(x)$ is monotone as well.","Let $f:\mathbb{R}^n \rightarrow \mathbb{R}^n$ be continuous and monotone , i.e., $$ \left( f(x) - f(y) \right)^\top \left( x-y\right) \geq 0$$ for all $x,y \in \mathbb{R}^n$. Say for which matrices $A \in \mathbb{R}^{n \times n}$, the function $x \mapsto A f(x)$ is monotone as well.",,"['real-analysis', 'analysis', 'functional-analysis', 'operator-theory', 'hilbert-spaces']"
76,Does weakly differentiable and $L^{\infty}$ imply continuity,Does weakly differentiable and  imply continuity,L^{\infty},"Suppose $\Omega \subset \mathbb{R}^d$ is open, connected and bounded. Is $$W^{1,1}(\Omega)\cap L^{\infty}(\Omega) \subset C(\bar{\Omega})?$$ Here $W^{1,1}$ denotes the space of all weakly differentiable functions with weak derivative in $L^1$ and $C$ the space of continuous functions. For $d=1$ the answer is yes as already $W^{1,1}(\Omega) \subset C(\bar{\Omega})$ . For $d\geq 2$ I know that there exist functions in $W^{1,1}$ which are not continuous (e.g. $\log(\log(1/|x|))$ ). However this function is not in $L^\infty$ .","Suppose is open, connected and bounded. Is Here denotes the space of all weakly differentiable functions with weak derivative in and the space of continuous functions. For the answer is yes as already . For I know that there exist functions in which are not continuous (e.g. ). However this function is not in .","\Omega \subset \mathbb{R}^d W^{1,1}(\Omega)\cap L^{\infty}(\Omega) \subset C(\bar{\Omega})? W^{1,1} L^1 C d=1 W^{1,1}(\Omega) \subset C(\bar{\Omega}) d\geq 2 W^{1,1} \log(\log(1/|x|)) L^\infty","['functional-analysis', 'continuity', 'weak-derivatives']"
77,Question about finite rank operators,Question about finite rank operators,,"Let $X$ be a normed space, $\mathcal{F}(X)$ the algebra of all operators on $X$ with finite fank, then $\mathcal{F}(X)$ is the unique minimal ideal of $\mathcal{K}(X)$ the algebra of all compact operators on $X$. I want to show that any non-zero ideal $\cal{I}$ of $\mathcal{K}(X)$ necessarily contains all operators with rank one. But I can not show a rank one operator $P$ can be written as $AT$, where $T\in\cal{I}$, $A\in\mathcal{K}(X)$. Thanks a lot.","Let $X$ be a normed space, $\mathcal{F}(X)$ the algebra of all operators on $X$ with finite fank, then $\mathcal{F}(X)$ is the unique minimal ideal of $\mathcal{K}(X)$ the algebra of all compact operators on $X$. I want to show that any non-zero ideal $\cal{I}$ of $\mathcal{K}(X)$ necessarily contains all operators with rank one. But I can not show a rank one operator $P$ can be written as $AT$, where $T\in\cal{I}$, $A\in\mathcal{K}(X)$. Thanks a lot.",,"['functional-analysis', 'operator-theory', 'operator-algebras']"
78,Find a norm of operator form l1 to l1,Find a norm of operator form l1 to l1,,"I have an operator $A: \ell_1 \to \ell_1, Ax = (x_1+x_2, x_1-x_2, x_3,...,x_k,...)$ AFAIK, norm of $\ell_1$ is $\sum_{n=1}^{\infty}|x_n|$ How to find a norm of this operator?","I have an operator $A: \ell_1 \to \ell_1, Ax = (x_1+x_2, x_1-x_2, x_3,...,x_k,...)$ AFAIK, norm of $\ell_1$ is $\sum_{n=1}^{\infty}|x_n|$ How to find a norm of this operator?",,['functional-analysis']
79,Trouble finishing a (direct) proof that $\ell^2(A)$ is a complete metric space,Trouble finishing a (direct) proof that  is a complete metric space,\ell^2(A),"Let $A$ be any non-empty set. We can define summations of non-negative numbers over this index set by using a supremum of summations over finite subsets of $A$. That is, $$\sum\limits_{\alpha \in A} x_\alpha = \sup \{\sum\limits_{\alpha \in F} x_\alpha \vert \ F \subseteq A \ \text{is finite}\}.$$ Define $$\ell^2(A) = \{f: A \to \mathbb{C} \ \vert \sum\limits_{\alpha \in A} \lvert f(\alpha) \rvert^2< \infty \}.$$ Clearly $\ell^2(A)$ is a $\mathbb{C}$-vector space with pointwise addition and scaling. We give this vector space a norm according to $\|f\|^2= \sum\limits_{\alpha \in A} \lvert f(\alpha) \rvert^2$. This is the same as the standard definition of $L^2(\mu)$ where $\mu$ is counting measure on $A$. It is a well-known result that this norm gives $\ell^2(A)$ the structure of a Banach space. The main issue here is to show that the metric induced by this norm is complete. Following a comment in Gerald Folland's excellent text on real analysis, it should be ""rather easy"" to prove completeness directly. To that end, we take a Cauchy sequence $(f_n) \in \ell^2(A)^\mathbb{N}$ and hope to show convergence with respect to the metric. It isn't hard to show that for each $\alpha \in A$, $f_n(\alpha)$ is a Cauchy sequence in $\mathbb{C}$ with the usual distance metric. By completeness of this metric space, we know that $f_n(\alpha)$ converges to some number $z_\alpha \in \mathbb{C}$. We define a function $f: A \to \mathbb{C}$ by $f(\alpha)=z_{\alpha}$. Of course, $f$ is our candidate for the limit of the original sequence. To show that $f \in \ell^2(A)$, let $F \subseteq A$ be a finite subset of A and let $\epsilon >0$. Take $N \in \mathbb{N}$ so that $\|f-f_n\|<\epsilon \ \ \ \forall n \geq N$. Thus, if $n \geq N$, then $\|f_n\| < \|f_N\| + \epsilon$. Let $B = \max\{\|f_1\|, \|f_2\|, ..., \|f_{N-1}\|, \|f_N\|+\epsilon\}$. Then evidently $\|f_n\| \leq B \ \ \ \forall n \in \mathbb{N}$. Using this upper bound on the sequence, we conclude that $$\sum\limits_{\alpha \in F} \lvert f(\alpha) \rvert^2 = \lim_{n \to \infty} \sum\limits_{\alpha \in F} \lvert f_n(\alpha) \rvert^2 \leq \limsup_{n \to \infty} \sum\limits_{\alpha \in A} \lvert f_n(\alpha) \rvert^2 = \limsup_{n \to \infty} \|f_n\|^2 \leq  B^2$$ Since this is true for every finite subset $F \subseteq A$, it follows that $$\|f\|^2= \sum\limits_{\alpha \in A} \lvert f(\alpha) \rvert^2=\sup \{\sum\limits_{\alpha \in F} \lvert f(\alpha) \rvert^2 \vert \ F \subseteq A \ \text{is finite}\} \leq B^2 < \infty $$ Now comes the part that is troubling me. We would like to say that $$ \lim_{n \to \infty} \sum\limits_{\alpha \in A} \|f(\alpha)-f_n(\alpha) \|^2 = 0 $$ Indeed, each term in the summation converges to $0$, but the trouble is in trying to exchange the two limiting operations $\lim$ and $\sup$. Here is what I thought I should do, but I haven't been successful. For each $n \in \mathbb{N}$, we can choose a sequence $(F_{n,m})$ of finite subsets of A such that $$\lim_{m \to \infty} \sum\limits_{\alpha \in F_{n,m}} \|f(\alpha)-f_n(\alpha) \|^2 = \sum\limits_{\alpha \in A} \|f(\alpha)-f_n(\alpha) \|^2 $$ Then the statement above that we wanted to prove becomes $$\lim_{n \to \infty} \lim_{m \to \infty} \sum\limits_{\alpha \in F_{n,m}} \|f(\alpha)-f_n(\alpha) \|^2 =0$$ I wasn't successful in justifying that we can exchange these limits. I would very much appreciate some help in completing this proof with a minimum of hand-waving. I understand that we can characterize completeness in a normed vector space according to convergence of absolutely convergent series, and that this can be used to prove completeness of $L^p(\mu)$ in a more general sense. However, it seems like a good lesson in basic analysis to carry this direct proof through to the end. As a side note, I kicked around another idea which might be relevant: If $\sum\limits_{\alpha \in A} x_\alpha < \infty$, then I believe we can control the ""tail"" of this series in the sense that $\forall \epsilon >0, \exists$ finite $F \subseteq A$ such that $\sum\limits_{\alpha \in E^C} x_\alpha < \epsilon \ \ \forall E \subseteq A$ with $E \supseteq F$. Thanks for your time and suggestions.","Let $A$ be any non-empty set. We can define summations of non-negative numbers over this index set by using a supremum of summations over finite subsets of $A$. That is, $$\sum\limits_{\alpha \in A} x_\alpha = \sup \{\sum\limits_{\alpha \in F} x_\alpha \vert \ F \subseteq A \ \text{is finite}\}.$$ Define $$\ell^2(A) = \{f: A \to \mathbb{C} \ \vert \sum\limits_{\alpha \in A} \lvert f(\alpha) \rvert^2< \infty \}.$$ Clearly $\ell^2(A)$ is a $\mathbb{C}$-vector space with pointwise addition and scaling. We give this vector space a norm according to $\|f\|^2= \sum\limits_{\alpha \in A} \lvert f(\alpha) \rvert^2$. This is the same as the standard definition of $L^2(\mu)$ where $\mu$ is counting measure on $A$. It is a well-known result that this norm gives $\ell^2(A)$ the structure of a Banach space. The main issue here is to show that the metric induced by this norm is complete. Following a comment in Gerald Folland's excellent text on real analysis, it should be ""rather easy"" to prove completeness directly. To that end, we take a Cauchy sequence $(f_n) \in \ell^2(A)^\mathbb{N}$ and hope to show convergence with respect to the metric. It isn't hard to show that for each $\alpha \in A$, $f_n(\alpha)$ is a Cauchy sequence in $\mathbb{C}$ with the usual distance metric. By completeness of this metric space, we know that $f_n(\alpha)$ converges to some number $z_\alpha \in \mathbb{C}$. We define a function $f: A \to \mathbb{C}$ by $f(\alpha)=z_{\alpha}$. Of course, $f$ is our candidate for the limit of the original sequence. To show that $f \in \ell^2(A)$, let $F \subseteq A$ be a finite subset of A and let $\epsilon >0$. Take $N \in \mathbb{N}$ so that $\|f-f_n\|<\epsilon \ \ \ \forall n \geq N$. Thus, if $n \geq N$, then $\|f_n\| < \|f_N\| + \epsilon$. Let $B = \max\{\|f_1\|, \|f_2\|, ..., \|f_{N-1}\|, \|f_N\|+\epsilon\}$. Then evidently $\|f_n\| \leq B \ \ \ \forall n \in \mathbb{N}$. Using this upper bound on the sequence, we conclude that $$\sum\limits_{\alpha \in F} \lvert f(\alpha) \rvert^2 = \lim_{n \to \infty} \sum\limits_{\alpha \in F} \lvert f_n(\alpha) \rvert^2 \leq \limsup_{n \to \infty} \sum\limits_{\alpha \in A} \lvert f_n(\alpha) \rvert^2 = \limsup_{n \to \infty} \|f_n\|^2 \leq  B^2$$ Since this is true for every finite subset $F \subseteq A$, it follows that $$\|f\|^2= \sum\limits_{\alpha \in A} \lvert f(\alpha) \rvert^2=\sup \{\sum\limits_{\alpha \in F} \lvert f(\alpha) \rvert^2 \vert \ F \subseteq A \ \text{is finite}\} \leq B^2 < \infty $$ Now comes the part that is troubling me. We would like to say that $$ \lim_{n \to \infty} \sum\limits_{\alpha \in A} \|f(\alpha)-f_n(\alpha) \|^2 = 0 $$ Indeed, each term in the summation converges to $0$, but the trouble is in trying to exchange the two limiting operations $\lim$ and $\sup$. Here is what I thought I should do, but I haven't been successful. For each $n \in \mathbb{N}$, we can choose a sequence $(F_{n,m})$ of finite subsets of A such that $$\lim_{m \to \infty} \sum\limits_{\alpha \in F_{n,m}} \|f(\alpha)-f_n(\alpha) \|^2 = \sum\limits_{\alpha \in A} \|f(\alpha)-f_n(\alpha) \|^2 $$ Then the statement above that we wanted to prove becomes $$\lim_{n \to \infty} \lim_{m \to \infty} \sum\limits_{\alpha \in F_{n,m}} \|f(\alpha)-f_n(\alpha) \|^2 =0$$ I wasn't successful in justifying that we can exchange these limits. I would very much appreciate some help in completing this proof with a minimum of hand-waving. I understand that we can characterize completeness in a normed vector space according to convergence of absolutely convergent series, and that this can be used to prove completeness of $L^p(\mu)$ in a more general sense. However, it seems like a good lesson in basic analysis to carry this direct proof through to the end. As a side note, I kicked around another idea which might be relevant: If $\sum\limits_{\alpha \in A} x_\alpha < \infty$, then I believe we can control the ""tail"" of this series in the sense that $\forall \epsilon >0, \exists$ finite $F \subseteq A$ such that $\sum\limits_{\alpha \in E^C} x_\alpha < \epsilon \ \ \forall E \subseteq A$ with $E \supseteq F$. Thanks for your time and suggestions.",,"['real-analysis', 'functional-analysis', 'measure-theory', 'metric-spaces', 'normed-spaces']"
80,Chain rule for weak derivatives of $f(u)$ where $f'$ is not bounded but $u$ is?,Chain rule for weak derivatives of  where  is not bounded but  is?,f(u) f' u,"Let $f:\mathbb{R} \to \mathbb{R}$ be $C^1$. Suppose $u$ has a weak derivative $u_x$. I want the chain rule $$\partial_x (f(u)) = f'(u)u_x$$ to hold. We know this holds if $f'$ is bounded. But I don't have that. But I do have $u$ is bounded almost everywhere, so $|f'(u)| \leq C$. Is this then enough for me to use the chain rule?","Let $f:\mathbb{R} \to \mathbb{R}$ be $C^1$. Suppose $u$ has a weak derivative $u_x$. I want the chain rule $$\partial_x (f(u)) = f'(u)u_x$$ to hold. We know this holds if $f'$ is bounded. But I don't have that. But I do have $u$ is bounded almost everywhere, so $|f'(u)| \leq C$. Is this then enough for me to use the chain rule?",,"['functional-analysis', 'sobolev-spaces', 'weak-derivatives']"
81,"$X$ complete normed space $\implies\mathrm B(X,Y)$ complete normed space?",complete normed space  complete normed space?,"X \implies\mathrm B(X,Y)","$\newcommand{\N}{\mathbf N}\renewcommand{\leq}{\leqslant}\renewcommand{\geq}{\geqslant}  \newcommand{\eps}{\varepsilon}$I was looking through the functional analysis notes of TWK (on his webpage https://www.dpmms.cam.ac.uk/~twk/ ) and was trying to answer the following question: If $X$ is a complete normed space and $Y$ is a normed space, is $\mathrm B(X,Y)$ complete? ($\mathrm B(X,Y)$ is the normed space of bounded linear operators from $X$ to $Y$, with as norm the operator norm). It seems to me that this is not the case, and I have thought of (what I think is) a counterexample. I'm not completely sure about the last step I made and therefore would like to ask you to verify that it is correct, show me how to correct it, or tell me that my counterexample is wrong and why. Claim If $X$ is a complete normed space and $Y$ a normed space, $\mathrm B(X,Y)$ is not necessarily complete: Proof Consider $X=\ell^\infty(\N),Y=c_{00}(\N)$ ($c_{00}(\N)$ is the set of sequences of compact support), with the norm on $Y$ the $\ell^1$ norm. Let, for $n\in\N_{\geq 1}$, $T_n:X\to Y$ be given by  $$(x_1,x_2,x_3,\ldots,x_n,x_{n+1},\ldots)\mapsto\left(\frac{x_1}{1^2},\frac{x_2}{2^2},\frac{x_3}{3^2},\ldots,\frac{x_n}{n^2},0,0,\ldots\right)$$ For every $n\in \N_{\geq 1}$, $T_n$ is linear. Furthermore each $T_n$ is bounded: Let $x=(x_n)\in X$. Then $\|x\|=\sup|x_n|<\infty$. So  $$\|T_nx\|=\sum\limits_{k=1}^n\frac{|x_k|}{k^2}\leq \sum\limits_{k=1}^n\frac{\sup|x_n|}{k^2}=\sum\limits_{k=1}^n\frac{1}{k^2}\|x\|\leq\frac{\pi^2}{6}\|x\|$$ We conclude that for all $n\in\N_{\geq 1}, T_n\in \mathrm B(X,Y)$, because $$\|T_n\|\leq \frac{\pi^2}{6}$$ Furthermore $(T_n)$ is a Cauchy sequence in $\mathrm B(X,Y)$: Let $\eps>0$. $\sum_{k=1}^\infty\frac{1}{k^2}$ converges, so there is an $N\in\N$ such that $\forall m,n\geq N$ we have $\sum_{k=m}^n \frac{1}{k^2}=\left|\sum_{k=m}^n \frac{1}{k^2}\right|<\frac{\eps}{2}$. Now let $x=(x_n)\in X$. Then $\|x\|=\sup |x_n|<\infty$ so for $m,n\geq N$ (wlog we assume $m<n$), we have $$\|(T_n-T_m)x\|=\sum\limits_{k=m+1}^n\frac{|x_k|}{k^2}\leq\sum\limits_{k=m+1}^n \frac{\sup|x_n|}{k^2}<\frac{\eps}{2}\|x\|$$ And from this it follows that for $m,n\geq N$  $$\|T_n-T_m\|\leq \frac{\eps}{2}<\eps$$ Finally, $(T_n)$ does not converge: This is the step that I'm not completely sure about. My idea is as follows We have $\mathrm B(X,\ell^1(\N))\supset \mathrm B(X,Y)$. $\mathrm B(X,\ell^1(\N))$ is complete (because $\ell^1(\N)$ is complete) and $(T_n)$ is also a Cauchy sequence in $\mathrm B(X,\ell^1(\N))$ and so it converges to a $T\in \mathrm B(X,\ell^1(\N))$. In fact we can give $T$ explicitly, for $x=(x_n)\in\ell^\infty(\N)$ we have $(Tx)_n=\frac{x_n}{n^2}$ for each $n\in\N_{\geq 1}$. Now it is clear that $T$ does not map $\ell^\infty(\N)$ into $c_{00}(\N)$ (consider the sequence with all entries equal to $1$ and what it gets mapped to) and so $T\not\in \mathrm B(X,Y)$. If $(T_n)$ would converge in $\mathrm B(X,Y)$ then it would converge to the same limit in $\mathrm B(X,\ell^1(\N))$ (because we consider $\mathrm B(X,Y)$ as a metric subspace of $\mathrm B(X,\ell^1(\N))$) so by uniqueness of limits in $\mathrm B(X,\ell^1(\N))$ we conclude that $(T_n)$ does not converge in $\mathrm B(X,Y)$. This shows that $X$ being a complete normed space does not necessarily imply that $\mathrm B(X,Y)$ is complete.","$\newcommand{\N}{\mathbf N}\renewcommand{\leq}{\leqslant}\renewcommand{\geq}{\geqslant}  \newcommand{\eps}{\varepsilon}$I was looking through the functional analysis notes of TWK (on his webpage https://www.dpmms.cam.ac.uk/~twk/ ) and was trying to answer the following question: If $X$ is a complete normed space and $Y$ is a normed space, is $\mathrm B(X,Y)$ complete? ($\mathrm B(X,Y)$ is the normed space of bounded linear operators from $X$ to $Y$, with as norm the operator norm). It seems to me that this is not the case, and I have thought of (what I think is) a counterexample. I'm not completely sure about the last step I made and therefore would like to ask you to verify that it is correct, show me how to correct it, or tell me that my counterexample is wrong and why. Claim If $X$ is a complete normed space and $Y$ a normed space, $\mathrm B(X,Y)$ is not necessarily complete: Proof Consider $X=\ell^\infty(\N),Y=c_{00}(\N)$ ($c_{00}(\N)$ is the set of sequences of compact support), with the norm on $Y$ the $\ell^1$ norm. Let, for $n\in\N_{\geq 1}$, $T_n:X\to Y$ be given by  $$(x_1,x_2,x_3,\ldots,x_n,x_{n+1},\ldots)\mapsto\left(\frac{x_1}{1^2},\frac{x_2}{2^2},\frac{x_3}{3^2},\ldots,\frac{x_n}{n^2},0,0,\ldots\right)$$ For every $n\in \N_{\geq 1}$, $T_n$ is linear. Furthermore each $T_n$ is bounded: Let $x=(x_n)\in X$. Then $\|x\|=\sup|x_n|<\infty$. So  $$\|T_nx\|=\sum\limits_{k=1}^n\frac{|x_k|}{k^2}\leq \sum\limits_{k=1}^n\frac{\sup|x_n|}{k^2}=\sum\limits_{k=1}^n\frac{1}{k^2}\|x\|\leq\frac{\pi^2}{6}\|x\|$$ We conclude that for all $n\in\N_{\geq 1}, T_n\in \mathrm B(X,Y)$, because $$\|T_n\|\leq \frac{\pi^2}{6}$$ Furthermore $(T_n)$ is a Cauchy sequence in $\mathrm B(X,Y)$: Let $\eps>0$. $\sum_{k=1}^\infty\frac{1}{k^2}$ converges, so there is an $N\in\N$ such that $\forall m,n\geq N$ we have $\sum_{k=m}^n \frac{1}{k^2}=\left|\sum_{k=m}^n \frac{1}{k^2}\right|<\frac{\eps}{2}$. Now let $x=(x_n)\in X$. Then $\|x\|=\sup |x_n|<\infty$ so for $m,n\geq N$ (wlog we assume $m<n$), we have $$\|(T_n-T_m)x\|=\sum\limits_{k=m+1}^n\frac{|x_k|}{k^2}\leq\sum\limits_{k=m+1}^n \frac{\sup|x_n|}{k^2}<\frac{\eps}{2}\|x\|$$ And from this it follows that for $m,n\geq N$  $$\|T_n-T_m\|\leq \frac{\eps}{2}<\eps$$ Finally, $(T_n)$ does not converge: This is the step that I'm not completely sure about. My idea is as follows We have $\mathrm B(X,\ell^1(\N))\supset \mathrm B(X,Y)$. $\mathrm B(X,\ell^1(\N))$ is complete (because $\ell^1(\N)$ is complete) and $(T_n)$ is also a Cauchy sequence in $\mathrm B(X,\ell^1(\N))$ and so it converges to a $T\in \mathrm B(X,\ell^1(\N))$. In fact we can give $T$ explicitly, for $x=(x_n)\in\ell^\infty(\N)$ we have $(Tx)_n=\frac{x_n}{n^2}$ for each $n\in\N_{\geq 1}$. Now it is clear that $T$ does not map $\ell^\infty(\N)$ into $c_{00}(\N)$ (consider the sequence with all entries equal to $1$ and what it gets mapped to) and so $T\not\in \mathrm B(X,Y)$. If $(T_n)$ would converge in $\mathrm B(X,Y)$ then it would converge to the same limit in $\mathrm B(X,\ell^1(\N))$ (because we consider $\mathrm B(X,Y)$ as a metric subspace of $\mathrm B(X,\ell^1(\N))$) so by uniqueness of limits in $\mathrm B(X,\ell^1(\N))$ we conclude that $(T_n)$ does not converge in $\mathrm B(X,Y)$. This shows that $X$ being a complete normed space does not necessarily imply that $\mathrm B(X,Y)$ is complete.",,"['functional-analysis', 'normed-spaces']"
82,Gilbarg Trudinger: Hölder continuity in chapter 8,Gilbarg Trudinger: Hölder continuity in chapter 8,,"I'm trying to track the behaviour of the coefficients in Theorems 8.22 and Theorem 8.24. Particularly, I'm considering the behaviour w.r.t. to the distance from $\Omega'$ to $\partial \Omega$ I'll state an abbreviated version of theorem 8.22 Theorem 8.22 If $u\in W^{1,2}(\Omega)$ is a weak solution of a linear elliptic pde in divergence form in $\Omega$, then $u$ is locally Hölder continuous in $\Omega$ and for any Ball $B_{R_0}(y)\subset \Omega$ and $R\leq  R_0$ we have   $$ \text{osc}_{B_R(y)}(u)\leq CR^\alpha(R_0^{-\alpha} \sup_{B_{R_0}(y)} |u| +k)$$   where $C=C(R_0)$ and $\alpha=\alpha(R_0)$ Theorem 8.24 gives an estimate on the Hölder norm for compact sets $\Omega'\subset\subset \Omega$ of the form $$||u||_{C^\alpha(\Omega')}\leq C (||u||_{L^2(\Omega)}+k)\tag{1}$$ where $C$ and $\alpha$ both depend on the distance of $\Omega'$ to $\partial \Omega$ and $k$ doesn't bother me :). What I discovered, when proving the local Hölder continuity of $u$ in Theorem 8.22 from the oscillation estimate is that the $C$ for the estimate (1) also depends on the size of $\Omega '$. Has anybody already considered this? Why do I believe this? Let $\Omega'\subset \Omega$ and choose $R_0$ so small that $B_{R_0}(\Omega')\subset \Omega$ (Hence the dependence on the distance of the boundary). The oscillation estimates does only hold on balls. Hence, due to compactness we find a finite covering of $\Omega'$ consisting of balls $B_{R}(x_k)$, $k=1,...n$. To show local Hölder continuity fix $x,y\in\Omega'$ and compute (in the worst case, i.e. x,y not in the same ball, i.e. $|x-y|>R$) and $1\leq l\leq n$,  $$|u(x)-u(y)|\leq |u(x)-u(x_1)|+ ... + |u(x_l)-u(y)| \leq C lR^{\alpha}\leq  C n|x-y|^\alpha \tag{2}$$ (I negelected $k$ Now $n$ depends obviously on the covering, so in particular on the radius $R$ which depends on $R_0$. However, the number $n$ depends on the size of $\Omega'$ and $R$. So the question is : Is there another way to show estimate $(2)$ without using the size of the domain? Is my covering argument wrong? Edit: Or is there another way to show the local Hölder continuity, starting  from the oscillation estimate? Edit2: In addition, it is stated that the constants $C$ and $\alpha$ are independent of $R_0$ and $R$ in the case of the Laplace-operator and that consequently the constant $C$ in $(1)$ shall be independent of the shape $\Omega$ and $\Omega'$. Does this sound reasonable?","I'm trying to track the behaviour of the coefficients in Theorems 8.22 and Theorem 8.24. Particularly, I'm considering the behaviour w.r.t. to the distance from $\Omega'$ to $\partial \Omega$ I'll state an abbreviated version of theorem 8.22 Theorem 8.22 If $u\in W^{1,2}(\Omega)$ is a weak solution of a linear elliptic pde in divergence form in $\Omega$, then $u$ is locally Hölder continuous in $\Omega$ and for any Ball $B_{R_0}(y)\subset \Omega$ and $R\leq  R_0$ we have   $$ \text{osc}_{B_R(y)}(u)\leq CR^\alpha(R_0^{-\alpha} \sup_{B_{R_0}(y)} |u| +k)$$   where $C=C(R_0)$ and $\alpha=\alpha(R_0)$ Theorem 8.24 gives an estimate on the Hölder norm for compact sets $\Omega'\subset\subset \Omega$ of the form $$||u||_{C^\alpha(\Omega')}\leq C (||u||_{L^2(\Omega)}+k)\tag{1}$$ where $C$ and $\alpha$ both depend on the distance of $\Omega'$ to $\partial \Omega$ and $k$ doesn't bother me :). What I discovered, when proving the local Hölder continuity of $u$ in Theorem 8.22 from the oscillation estimate is that the $C$ for the estimate (1) also depends on the size of $\Omega '$. Has anybody already considered this? Why do I believe this? Let $\Omega'\subset \Omega$ and choose $R_0$ so small that $B_{R_0}(\Omega')\subset \Omega$ (Hence the dependence on the distance of the boundary). The oscillation estimates does only hold on balls. Hence, due to compactness we find a finite covering of $\Omega'$ consisting of balls $B_{R}(x_k)$, $k=1,...n$. To show local Hölder continuity fix $x,y\in\Omega'$ and compute (in the worst case, i.e. x,y not in the same ball, i.e. $|x-y|>R$) and $1\leq l\leq n$,  $$|u(x)-u(y)|\leq |u(x)-u(x_1)|+ ... + |u(x_l)-u(y)| \leq C lR^{\alpha}\leq  C n|x-y|^\alpha \tag{2}$$ (I negelected $k$ Now $n$ depends obviously on the covering, so in particular on the radius $R$ which depends on $R_0$. However, the number $n$ depends on the size of $\Omega'$ and $R$. So the question is : Is there another way to show estimate $(2)$ without using the size of the domain? Is my covering argument wrong? Edit: Or is there another way to show the local Hölder continuity, starting  from the oscillation estimate? Edit2: In addition, it is stated that the constants $C$ and $\alpha$ are independent of $R_0$ and $R$ in the case of the Laplace-operator and that consequently the constant $C$ in $(1)$ shall be independent of the shape $\Omega$ and $\Omega'$. Does this sound reasonable?",,"['functional-analysis', 'partial-differential-equations', 'holder-spaces']"
83,"Let $X$ be a reflexive Banach space. $T\in\mathcal{L}(X,X)\,\Longleftrightarrow\, $if $x_n\rightharpoonup x$, then $T(x_n)\rightharpoonup T(x)$","Let  be a reflexive Banach space. if , then","X T\in\mathcal{L}(X,X)\,\Longleftrightarrow\,  x_n\rightharpoonup x T(x_n)\rightharpoonup T(x)","I have the forward direction: $(\Longrightarrow)$ Let $T\in\mathcal{L}(X,X)$ and let $f\in X^*$. Since both $T$ and $f$ are bounded, then both $T$ and $f$ are continuous in the norm topology. Then $f\circ T$ is continuous with respect to the norm topology, and therefore bounded. Thus $f\circ T\in X^*$. Since $x_n\rightharpoonup x$, then $(f\circ T)(x_n)\to (f\circ T)(x)\Longleftrightarrow f(T(x_n))\to f(T(x))$. Since our choice of $f$ was arbitrary, we conclude that $T(x_n)\rightharpoonup T(x)$. The reverse direction is going to require the use of reflexivity, but I have no idea where to begin with this. Any help would be appreciated.","I have the forward direction: $(\Longrightarrow)$ Let $T\in\mathcal{L}(X,X)$ and let $f\in X^*$. Since both $T$ and $f$ are bounded, then both $T$ and $f$ are continuous in the norm topology. Then $f\circ T$ is continuous with respect to the norm topology, and therefore bounded. Thus $f\circ T\in X^*$. Since $x_n\rightharpoonup x$, then $(f\circ T)(x_n)\to (f\circ T)(x)\Longleftrightarrow f(T(x_n))\to f(T(x))$. Since our choice of $f$ was arbitrary, we conclude that $T(x_n)\rightharpoonup T(x)$. The reverse direction is going to require the use of reflexivity, but I have no idea where to begin with this. Any help would be appreciated.",,['functional-analysis']
84,Why is this estimate using a compact embedding in a sobolev space true?,Why is this estimate using a compact embedding in a sobolev space true?,,"Let $\Omega\subset\mathbb{R}^3$ be a bounded Lipschitz-domain. We then have, for $s\in[1,6)$ the compact embedding $H^1(\Omega)\stackrel{c}{\hookrightarrow}L^s(\Omega)$ ensuring the existence of a $C>0$ such that $$\|u\|_{L^s(\Omega)}\leq C \|u\|_{H^1(\Omega)}\leq C\left(\|u\|_{L^2(\Omega)}+\|\nabla u\|_{L^2(\Omega)^3}\right)$$ for all $u\in H^1(\Omega)$. I came across a different conclusion in this paper (in the middle of p. 8). This conclusion being: For all $\alpha>0$ there exists $C(\alpha,\Omega)>0$ such that $$\|u\|_{L^4(\Omega)}\leq \alpha\|\nabla u\|_{L^2(\Omega)^3}+C(\alpha,\Omega)\|u\|_{L^2(\Omega)}$$ for all $u\in H^1(\Omega)$. My questions: 1) Why is this statement true? I fear that this is trivial, but I fail to come up with a justification. Maybe a hint or a good reference would already do the trick for me. 2) Beyond that: Is it possible to determine the order of (an optimal) $C(\alpha,\Omega)$ w.r.t. $\alpha$? (Possibly something like $C(\alpha,\Omega)= \mathcal{O}(\alpha^{-1})$ when fixing $\Omega$).","Let $\Omega\subset\mathbb{R}^3$ be a bounded Lipschitz-domain. We then have, for $s\in[1,6)$ the compact embedding $H^1(\Omega)\stackrel{c}{\hookrightarrow}L^s(\Omega)$ ensuring the existence of a $C>0$ such that $$\|u\|_{L^s(\Omega)}\leq C \|u\|_{H^1(\Omega)}\leq C\left(\|u\|_{L^2(\Omega)}+\|\nabla u\|_{L^2(\Omega)^3}\right)$$ for all $u\in H^1(\Omega)$. I came across a different conclusion in this paper (in the middle of p. 8). This conclusion being: For all $\alpha>0$ there exists $C(\alpha,\Omega)>0$ such that $$\|u\|_{L^4(\Omega)}\leq \alpha\|\nabla u\|_{L^2(\Omega)^3}+C(\alpha,\Omega)\|u\|_{L^2(\Omega)}$$ for all $u\in H^1(\Omega)$. My questions: 1) Why is this statement true? I fear that this is trivial, but I fail to come up with a justification. Maybe a hint or a good reference would already do the trick for me. 2) Beyond that: Is it possible to determine the order of (an optimal) $C(\alpha,\Omega)$ w.r.t. $\alpha$? (Possibly something like $C(\alpha,\Omega)= \mathcal{O}(\alpha^{-1})$ when fixing $\Omega$).",,"['functional-analysis', 'sobolev-spaces', 'compact-operators']"
85,Does homeomorphism imply an equivalent norm?,Does homeomorphism imply an equivalent norm?,,"Can we find a banach space X on which there are two non-equivalent norms, but they induce the same topology? I am almost sure that there should be such example, otherwise it would seem to be a rather strong and surprising result. (Note that we should look for an infinite dimensional X , and the homeomorphism f , if it exists, can not be linear by the open mapping theorem.)","Can we find a banach space X on which there are two non-equivalent norms, but they induce the same topology? I am almost sure that there should be such example, otherwise it would seem to be a rather strong and surprising result. (Note that we should look for an infinite dimensional X , and the homeomorphism f , if it exists, can not be linear by the open mapping theorem.)",,['functional-analysis']
86,How to build a compact support for a function,How to build a compact support for a function,,"I was wondering if it is possible to build a distribution with compact support from a function. More precisely, consider a compact set $\mathbf{K}\subset\mathbb{R}^2\setminus\{0\}$, and a function $h:\mathbb{R}^2\to\mathbb{R}^2$ of class $\mathcal{C}^1$ such that, for every $y\in\mathbf{K}$, $h(y)\neq0$. Then, if there exists a compact set $\widetilde{\mathbf{K}}\supsetneq\mathbf{K}$ the distribution \begin{equation*} 	\tilde{h}(y)=\left\{\begin{array}{rcl} 					h(y),&\text{if}&y\in\mathbf{K},\\ 					h(y)\exp\left(-\dfrac{|y|_\mathbf{K}^2}{\mathtt{dist}^2\left(y,\mathbb{R}^2\setminus\widetilde{\mathbf{K}}\right)}\right),&\text{if}&y\in\mathtt{int}\left(\widetilde{\mathbf{K}}\right)\setminus\mathbf{K},\\ 					0,&\text{if}&\text{otherwise}\\ 				\end{array}\right. \end{equation*} is such that $\mathtt{supp}(\tilde{h})=\widetilde{\mathbf{K}}$ and, for every $y\in\mathbf{K}$, $\tilde{h}(y)=h(y)$. Is this correct? Notation. $|y|_\mathbf{K}$ is the Hausdorff point-to-set distance: $|y|_\mathbf{K}:=\inf\{|x-y|:x\in\mathbf{K},y\notin\mathbf{K}\}$. Analogously, $\mathtt{dist}\left(y,\mathbb{R}^2\setminus\widetilde{\mathbf{K}}\right)$ is the is the Hausdorff point-to-set distance from $y$ to $\mathbb{R}^2\setminus\widetilde{\mathbf{K}}$. Thanks in advance.","I was wondering if it is possible to build a distribution with compact support from a function. More precisely, consider a compact set $\mathbf{K}\subset\mathbb{R}^2\setminus\{0\}$, and a function $h:\mathbb{R}^2\to\mathbb{R}^2$ of class $\mathcal{C}^1$ such that, for every $y\in\mathbf{K}$, $h(y)\neq0$. Then, if there exists a compact set $\widetilde{\mathbf{K}}\supsetneq\mathbf{K}$ the distribution \begin{equation*} 	\tilde{h}(y)=\left\{\begin{array}{rcl} 					h(y),&\text{if}&y\in\mathbf{K},\\ 					h(y)\exp\left(-\dfrac{|y|_\mathbf{K}^2}{\mathtt{dist}^2\left(y,\mathbb{R}^2\setminus\widetilde{\mathbf{K}}\right)}\right),&\text{if}&y\in\mathtt{int}\left(\widetilde{\mathbf{K}}\right)\setminus\mathbf{K},\\ 					0,&\text{if}&\text{otherwise}\\ 				\end{array}\right. \end{equation*} is such that $\mathtt{supp}(\tilde{h})=\widetilde{\mathbf{K}}$ and, for every $y\in\mathbf{K}$, $\tilde{h}(y)=h(y)$. Is this correct? Notation. $|y|_\mathbf{K}$ is the Hausdorff point-to-set distance: $|y|_\mathbf{K}:=\inf\{|x-y|:x\in\mathbf{K},y\notin\mathbf{K}\}$. Analogously, $\mathtt{dist}\left(y,\mathbb{R}^2\setminus\widetilde{\mathbf{K}}\right)$ is the is the Hausdorff point-to-set distance from $y$ to $\mathbb{R}^2\setminus\widetilde{\mathbf{K}}$. Thanks in advance.",,"['real-analysis', 'functional-analysis', 'functions', 'distribution-theory']"
87,Sobolev spaces on non open sets,Sobolev spaces on non open sets,,"in the definition of Wikipedia and several books the Sobolevspace $W^{k,p}(\Omega)$ is defined on a open subset $\Omega\subset \mathbb{R}^d$. Why does $\Omega$ have to be open? Why is [0,1] not possible? Best wishes and thanks for answers :)","in the definition of Wikipedia and several books the Sobolevspace $W^{k,p}(\Omega)$ is defined on a open subset $\Omega\subset \mathbb{R}^d$. Why does $\Omega$ have to be open? Why is [0,1] not possible? Best wishes and thanks for answers :)",,"['functional-analysis', 'sobolev-spaces']"
88,Proof or counterexample: $L^p$-boundedness gives a.e. convergent subsequence?,Proof or counterexample: -boundedness gives a.e. convergent subsequence?,L^p,"Let $\Omega\subset\mathbb{R}^{d}$ open and let $f_{n}\in L^{2}\left(\Omega\right)$ be bounded. Then there is obviously a weakly convergent subsequence. Is there also a subsequence converging almost everywhere? Do you know of a counterexample, i.e., a weakly convergent (or bounded) sequence without any subsequence converging almost everywhere? Thanks a lot in advance! :-)","Let $\Omega\subset\mathbb{R}^{d}$ open and let $f_{n}\in L^{2}\left(\Omega\right)$ be bounded. Then there is obviously a weakly convergent subsequence. Is there also a subsequence converging almost everywhere? Do you know of a counterexample, i.e., a weakly convergent (or bounded) sequence without any subsequence converging almost everywhere? Thanks a lot in advance! :-)",,"['real-analysis', 'functional-analysis', 'sobolev-spaces', 'weak-convergence', 'almost-everywhere']"
89,"$H^{-1}(\Omega)$ given an inner product involving inverse Laplacian, explanation required","given an inner product involving inverse Laplacian, explanation required",H^{-1}(\Omega),"Let $\Omega$ be a bounded domain and define $V=L^2(\Omega)$ and $H=H^{-1}(\Omega)$. Endow $H$ with the inner product $$(f,g)_{H} = \langle f, (-\Delta)^{-1}g \rangle_{H^{-1}, H^1}$$ where $(-\Delta)^{-1}g = \tilde g$ is the solution of $-\Delta \tilde g = g$  on $\Omega$, $\tilde g= 0$ on $\Gamma$. In Lions' Quelques methodes... on page 192, he uses this set up to deal with a PDE of the form $$u_t - \nabla \cdot (|u|\nabla u) = f.$$ Now, we have a Hilbert triple $V \subset H \subset V^*$. I remember that we identify $H$ with its dual, but not $V$ with its dual. But $V^*= (L^2)^* = L^2$. So how should I think of the dual of $V$? I ask because Lions then says the following: ...standard theory from before tells us there is a unique $u \in L^2(0,T;V)$ with $u_t \in L^2(0,T;V^*)$ such that   $$(u'(t), v)_H + a(u(t),v) = L(t)(v)$$   where $a(u,v) = \frac{1}{2}\int_\Omega |u|uv$ (and $L(t)$ is given but it's not relevant here). My question is, why does Lions write $(u_t,v)_H$ and not $\langle u_t, v \rangle_{V^*,V}$? We only know that $u_t \in L^2(0,T;V^*)$, don't know that it's in $L^2(0,T;H)$. But if we did identify $V^* = L^2$, then we get $L^2 \subset H^{-1} \subset L^2$ (but this would mean $L^2=H^{-1}$!!!), and the duality pairing becomes the $H^{-1}$ inner product as defined above so it kinda makes sense. Finally, any references to other work where PDEs are tackled with the pivot space equal to $H^{-1}$ with the inverse Laplacian are hugely appreciated. Thanks.","Let $\Omega$ be a bounded domain and define $V=L^2(\Omega)$ and $H=H^{-1}(\Omega)$. Endow $H$ with the inner product $$(f,g)_{H} = \langle f, (-\Delta)^{-1}g \rangle_{H^{-1}, H^1}$$ where $(-\Delta)^{-1}g = \tilde g$ is the solution of $-\Delta \tilde g = g$  on $\Omega$, $\tilde g= 0$ on $\Gamma$. In Lions' Quelques methodes... on page 192, he uses this set up to deal with a PDE of the form $$u_t - \nabla \cdot (|u|\nabla u) = f.$$ Now, we have a Hilbert triple $V \subset H \subset V^*$. I remember that we identify $H$ with its dual, but not $V$ with its dual. But $V^*= (L^2)^* = L^2$. So how should I think of the dual of $V$? I ask because Lions then says the following: ...standard theory from before tells us there is a unique $u \in L^2(0,T;V)$ with $u_t \in L^2(0,T;V^*)$ such that   $$(u'(t), v)_H + a(u(t),v) = L(t)(v)$$   where $a(u,v) = \frac{1}{2}\int_\Omega |u|uv$ (and $L(t)$ is given but it's not relevant here). My question is, why does Lions write $(u_t,v)_H$ and not $\langle u_t, v \rangle_{V^*,V}$? We only know that $u_t \in L^2(0,T;V^*)$, don't know that it's in $L^2(0,T;H)$. But if we did identify $V^* = L^2$, then we get $L^2 \subset H^{-1} \subset L^2$ (but this would mean $L^2=H^{-1}$!!!), and the duality pairing becomes the $H^{-1}$ inner product as defined above so it kinda makes sense. Finally, any references to other work where PDEs are tackled with the pivot space equal to $H^{-1}$ with the inverse Laplacian are hugely appreciated. Thanks.",,"['functional-analysis', 'reference-request', 'partial-differential-equations', 'sobolev-spaces']"
90,Prove the Contraction Mapping Theorem.,Prove the Contraction Mapping Theorem.,,"Prove the Contraction Mapping Theorem. Let $(X,d)$ be a complete metric space and $g : X \rightarrow X$ be a map such that $\forall x,y \in X, d(g(x), g(y)) \le \lambda d(x,y)$ for some $0<\lambda  < 1$. Then $g$ has a unique fixed point $x^* \in X $, and it attracts everything, i.e. for any $x_0 \in X$ , the sequence of iterates $x_0, g(x_0), g(g(x_0))$, ... converges to the fixed point $x^* \in X$. The hint I am given are for existence and convergence - prove that the sequence is Cauchy. For uniqueness, choose two fixed points of $g$ and apply the map to both. Still a bit do not know how to proceed after looking at the hint. Could anyone help me based on those hints?","Prove the Contraction Mapping Theorem. Let $(X,d)$ be a complete metric space and $g : X \rightarrow X$ be a map such that $\forall x,y \in X, d(g(x), g(y)) \le \lambda d(x,y)$ for some $0<\lambda  < 1$. Then $g$ has a unique fixed point $x^* \in X $, and it attracts everything, i.e. for any $x_0 \in X$ , the sequence of iterates $x_0, g(x_0), g(g(x_0))$, ... converges to the fixed point $x^* \in X$. The hint I am given are for existence and convergence - prove that the sequence is Cauchy. For uniqueness, choose two fixed points of $g$ and apply the map to both. Still a bit do not know how to proceed after looking at the hint. Could anyone help me based on those hints?",,"['real-analysis', 'analysis', 'functional-analysis', 'ordinary-differential-equations', 'fixed-point-theorems']"
91,How is the $l^p$ space separable?,How is the  space separable?,l^p,"I have been asked to prove that the $l^p$ space for $1\leq p<\infty$ is separable. A space is separable when we can find a dense countable subset of that space. The argument given in my book is the following: Take a sequence $\{a_1,a_2,\dots\}$. There exists $n\in \Bbb{N}$ such that $\sum\limits_{i=1}^{\infty}{|a_{n+i}|^p}<\epsilon/2$. Now take the sequence $\{r_1,r_2,\dots,r_n,0,0,\dots\}$, where $r_1,r_2,\dots,r_n\in\Bbb{Q}$ and $\sum\limits_{j=1}^{n}{|a_{j}-r_j|^p}<\epsilon/2$. Then the set of all such sequences (consisting of rational numbers and $0$'s) is countable. I wonder why such a set is countable. The $n\in\Bbb{N}$ for which $\sum\limits_{i=1}^{\infty}{|a_{n+i}|^p}<\epsilon/2$ does not have a definite upper bound. It can go on increasing. So the dense subset that we're talking about may actually be $\underbrace{\Bbb{Q}\times\Bbb{Q}\times\dots}_{\Bbb{Z}\text{ times}}$, which is uncountable. Thanks in advance!","I have been asked to prove that the $l^p$ space for $1\leq p<\infty$ is separable. A space is separable when we can find a dense countable subset of that space. The argument given in my book is the following: Take a sequence $\{a_1,a_2,\dots\}$. There exists $n\in \Bbb{N}$ such that $\sum\limits_{i=1}^{\infty}{|a_{n+i}|^p}<\epsilon/2$. Now take the sequence $\{r_1,r_2,\dots,r_n,0,0,\dots\}$, where $r_1,r_2,\dots,r_n\in\Bbb{Q}$ and $\sum\limits_{j=1}^{n}{|a_{j}-r_j|^p}<\epsilon/2$. Then the set of all such sequences (consisting of rational numbers and $0$'s) is countable. I wonder why such a set is countable. The $n\in\Bbb{N}$ for which $\sum\limits_{i=1}^{\infty}{|a_{n+i}|^p}<\epsilon/2$ does not have a definite upper bound. It can go on increasing. So the dense subset that we're talking about may actually be $\underbrace{\Bbb{Q}\times\Bbb{Q}\times\dots}_{\Bbb{Z}\text{ times}}$, which is uncountable. Thanks in advance!",,['functional-analysis']
92,Compact kernel operator on $L^p$ space,Compact kernel operator on  space,L^p,"Let $\displaystyle U_1 \subset \mathbb R^{n_1}$ and $\displaystyle U_2  \subset \mathbb R^{n_2} $ measurable sets, $\displaystyle 1 < p,q <  \infty $ and consider the measurable function $\displaystyle K:U_1  \times U_2 \to \mathbb R $ with $$\displaystyle \|K\|= \left(  \int_{U_1} \Big( \int_{U_2} |\,K(x,y) |^{p^{'}} dy  \Big)^{q/p^{'}} dx \right)^{1/q} < \infty ,$$  where $\displaystyle \frac{1}{p} +  \frac{1}{p^{'}} =1$. Prove that the operator $T:\displaystyle L^p (U_2) \to L^q (U_1) $, with   $\displaystyle (Tf)(x)= \int_{U_2} K(x,y) f(y) dy $,  is compact. I tried to prove it by the definition of the compact operator but I didn't made it. Is there some other way to do it?","Let $\displaystyle U_1 \subset \mathbb R^{n_1}$ and $\displaystyle U_2  \subset \mathbb R^{n_2} $ measurable sets, $\displaystyle 1 < p,q <  \infty $ and consider the measurable function $\displaystyle K:U_1  \times U_2 \to \mathbb R $ with $$\displaystyle \|K\|= \left(  \int_{U_1} \Big( \int_{U_2} |\,K(x,y) |^{p^{'}} dy  \Big)^{q/p^{'}} dx \right)^{1/q} < \infty ,$$  where $\displaystyle \frac{1}{p} +  \frac{1}{p^{'}} =1$. Prove that the operator $T:\displaystyle L^p (U_2) \to L^q (U_1) $, with   $\displaystyle (Tf)(x)= \int_{U_2} K(x,y) f(y) dy $,  is compact. I tried to prove it by the definition of the compact operator but I didn't made it. Is there some other way to do it?",,"['real-analysis', 'functional-analysis', 'operator-theory', 'lp-spaces', 'compact-operators']"
93,The Trace Class Operators Form a Banach Space,The Trace Class Operators Form a Banach Space,,I want examining the trace class operators $L_1(H)$ of a separable Hilbert space $H$ with the norm $||A||_1=\sum\limits^{\infty}_{n=1}\lambda_n$ where $\lambda_n$ are the eigenvalues of $(A^*A)^{1/2}.$  A text I am reading says that this space $L_1(H)$ is a Banach space with respect to that norm. It does not provide any proof though so I tried to but I am having difficulty.  I would appreciate if someone could either link me a proof or provide one here.  Thanks! ** Someone has posted below an answer using dual spaces.  I am still curious though if there is another way to do it more traditionally. **,I want examining the trace class operators $L_1(H)$ of a separable Hilbert space $H$ with the norm $||A||_1=\sum\limits^{\infty}_{n=1}\lambda_n$ where $\lambda_n$ are the eigenvalues of $(A^*A)^{1/2}.$  A text I am reading says that this space $L_1(H)$ is a Banach space with respect to that norm. It does not provide any proof though so I tried to but I am having difficulty.  I would appreciate if someone could either link me a proof or provide one here.  Thanks! ** Someone has posted below an answer using dual spaces.  I am still curious though if there is another way to do it more traditionally. **,,"['functional-analysis', 'eigenvalues-eigenvectors', 'banach-spaces', 'hilbert-spaces', 'trace']"
94,"In a Hilbert space, every bounded and closed set is weakly relatively compact.","In a Hilbert space, every bounded and closed set is weakly relatively compact.",,"My aim is to prove that in a Hilbert space, any bounded sequence has a weakly convergent subsequence. To prove this, I'm trying to prove that: In a Hilbert space, every bounded and closed set is weakly relatively compact I have tried it via Banach-Alaoglu theorem but I find it difficult as this theorem applies to the dual space with the weak-* topology and not the weak one. Anyway I have the feeling that there is an easier way to prove it. Any help would be highly appreciated. Thank you.","My aim is to prove that in a Hilbert space, any bounded sequence has a weakly convergent subsequence. To prove this, I'm trying to prove that: In a Hilbert space, every bounded and closed set is weakly relatively compact I have tried it via Banach-Alaoglu theorem but I find it difficult as this theorem applies to the dual space with the weak-* topology and not the weak one. Anyway I have the feeling that there is an easier way to prove it. Any help would be highly appreciated. Thank you.",,"['analysis', 'functional-analysis', 'hilbert-spaces', 'compactness', 'weak-convergence']"
95,Norm of diagonal operator,Norm of diagonal operator,,"Let $\{e_n\}$ be the usual basis for $l^2$ and $\{\alpha_n\}$ be a bounded sequence of scalars. For all n, define $Ae_n=\alpha_n e_n$ on $l^2$ . Show that $||A||=\sup\alpha_n$ . I can show $||A||\leq\sup\alpha_n$ easily. My problem is showing $||A||\geq\sup\alpha_n$ . I  can  not find  a  suitable element of $l^2$ for it.","Let be the usual basis for and be a bounded sequence of scalars. For all n, define on . Show that . I can show easily. My problem is showing . I  can  not find  a  suitable element of for it.",\{e_n\} l^2 \{\alpha_n\} Ae_n=\alpha_n e_n l^2 ||A||=\sup\alpha_n ||A||\leq\sup\alpha_n ||A||\geq\sup\alpha_n l^2,['functional-analysis']
96,Pointwise Ergodic Theorem - one particular estimate,Pointwise Ergodic Theorem - one particular estimate,,"I am struggling with an estimate in a proof of the pointwise ergodic theorem discussed in T. Ward and M. Einsiedler: Ergodic Theory with a view towards Number Theory, which is left as an exercise. I will first give a description of the proof in order to clarify notation, then point out the estimate which is giving me troubles and then state what I have ``found out'' up to now (which is not so much unfortunately): Pointwise Ergodic Theorem: Let $(X,\mathscr{B},\mu)$ be a probability space, $T:(X,\mathscr{B})\to(X,\mathscr{B})$ measue-preserving, $f:X\to\mathbb{C}$ an integrable, measureable function, i.e. $\int_{X}|f|\operatorname{d}\mu<\infty$. Let $$A_{N}(f)(x):=\frac{1}{N}\sum_{n=0}^{N-1}f(T^{n}(x))\quad \forall x\in X, \forall N\geq 1$$ Then there exists an integrable function $f^{\ast}$ such that the sequence $(A_{N}(f))_{N\in\mathbb{N}}$ converges to $f^{\ast}$ pointwise almost everywhere. Let's quickly discuss the structure of the proof, which tells us what we know already and which estimate is giving me trouble. The proof: We start by assuming that $f$ is almost surely bounded . Once we have checked this case, we will use density of $L_{\mu}^{\infty}(X,\mathscr{B})$ in $L_{\mu}^{1}(X,\mathscr{B})$ to deduce the general case. We know from the mean ergodic theorem (which does not yet require the boundedness of $f$), that we can find an almost surely $T$-invariant, integrable function $F$ such that:   $$F={\lim_{N\to\infty}}^{L_{\mu}^{1}}A_{N}(f)$$   i.e. $\lVert F-A_{N}(f)\rVert_{1}\stackrel{N\to\infty}{\longrightarrow}0$. The claim hence becomes: let $F$ be a representative of the $L_{\mu}^{1}\cap L_{\mu}^{\infty}$-limit of $(A_{N}(f))$, then $A_{N}(f)$ converges to $F$ pointwise almost surely.   This claim is formalized as follows:    $$\mu(\{x\in X; \lim\sup_{N\to\infty}|F(x)-A_{N}(f)(x)|>0\})=0$$   Note that the claim would follow from:   $$\mu(\{x\in X; \lim\sup_{N\to\infty}|F(x)-A_{N}(f)(x)|>\epsilon\})<2\epsilon \quad\forall\epsilon>0$$ by some standard argumentation (here my estimate is a bit weaker than in the original reference but this should not affect the result). Fix $M\in\mathbb{N}$ and $\epsilon>0$, then we know from the maximal ergodic theorem applied to the functions $g_{1}:=F-A_{M}(f)$ and $g_{2}:=A_{M}(f)-F$ (this is why the 2 pops up in my discussion) that:   $$\mu(\{x\in X;\sup_{n\geq 1}|A_{N}(F-A_{M}(f))|>\epsilon\})<2\epsilon$$ Now comes the critical estimate: The authors state that for fixed $M\in\mathbb{N}$ holds:   $$\begin{equation}\exists N_{0}\in\mathbb{N}\exists C_{M}>0:\quad N\geq N_{0}\Rightarrow|A_{N}(f)-A_{N}(A_{M}(f))|\leq C_{M}\frac{\lVert f\rVert_{\infty}}{N}\end{equation}$$   Given the critical estimate and $A_{N}$-invariance of $F$, we find:   $$\begin{align}\{x\in X;\lim\sup_{N\to\infty}|F(x)-A_{N}(f)(x)|>\epsilon\}=&\{x\in X;\lim\sup_{N\to\infty}|F(x)-A_{N}(A_{M}(f))|>\epsilon\}\\ \stackrel{\mu}{=}&\{x\in X;\lim\sup_{N\to\infty}|A_{N}(F-A_{M}(f))(x)|>\epsilon\}\\ \subseteq & \{x\in X;\sup_{N\geq1}|A_{N}(F-A_{M}(f))(x)|\}\end{align}$$   where for $A,B\in\mathscr{B}$ holds $A\stackrel{\mu}{=}B$ if $\mu(A\Delta B)=0$. This readily proves the claim. I turn to you for the critical estimate: I do not manage to get the $N$ in the denominator. My idea was to do the following: I was about to check that $A_{N}(A_{M}(f))\to F$ in $L_{\mu}^{1}$ which sounds quite intuitive, i.e. both sequences have the same limit. This sounds quite obvious as the limit is $T$-invariant. Then I intended to use boundedness of $f$ to find a uniform estimate for the difference. But I always have the problem that the summation over $n$ and $N^{-1}$ cancel each other. Furthermore all those estimates are but almost surely. Could you please given me a hint on why the critical estimate holds? Note that I am particularly interested in getting this proof to work, not in any proof of the Pointwise Convergence Theorem. Detailed Estimate: Thanks to @Davide Giraudo, I think I managed to prove it if $f$ is honestly bounded. In what follows let $\xi:=(\xi_{n})_{n\in\mathbb{N}}$ be a bounded sequence and $U_{N}(\xi):=\sum_{n=0}^{N-1}\xi_{n}$. Using his idea, we get:   $$U_{N}(U_{M}(\xi))=\sum_{n=0}^{N-1}\sum_{m=n}^{M+n-1}\xi_{m}$$   A little drawing and induction shows that for fixed $M\in\mathbb{N}$ and $N\in\mathbb{N}$ way larger than $M$, we get:   $$\begin{align}U_{N}(U_{M}(\xi))=&\sum_{m=0}^{M-1}(m+1)\xi_{m}+M\sum_{m=M}^{N-1}\xi_{m}+\sum_{m=N}^{M+N-2}(M+N-1-m)\xi_{m}\\ =&U_{N}(\xi)+\sum_{m=0}^{M-1}m\xi_{m}+(M-1)\sum_{m=M}^{N-1}\xi_{m}+\sum_{m=N}^{M+N-2}(M+N-1-m)\xi_{m}\end{align}$$   so that:   $$U_{N}(U_{M}(\xi))-MU_{N}(\xi)=\sum_{m=0}^{M-1}(m+1-M)\xi_{m}+\sum_{m=N}^{M+N-2}(M+N-1-m)\xi_{m}$$   As $|m+1-M|\leq M$ for $m\in\{0,\ldots,M-1\}$ and $|M+N-1-m|\leq M+|N-m|\leq 2M$ for $m\in\{N,\ldots,M+N-2\}$, we find that for $x\equiv (f(T^{n}(x)))_{n\in\mathbb{N}}$ holds:   $$\begin{align}|A_{N}(A_{M}(x))-A_{N}(x)|=&\frac{1}{NM}|U_{N}(U_{M}(x))-MU_{N}(x)|\\ \leq &\frac{1}{NM}\left\{\sum_{m=0}^{M-1}2M\lVert f\rVert_{\infty}+\sum_{m=N}^{M+N-2}2M\lVert f\rVert_{\infty}\right\}\leq\frac{2M}{N}\lVert f\rVert_{\infty}\end{align}$$ It remains for me to ensure that if $f$ is almost surely bounded, the estimate still holds almost everywhere. Range of validity of the estimate: This is in fact easy. Let $f$ lmost surely bounded, then there exists $B\subseteq\mathscr{B}$ with $\mu(B)=1$ and $f|_{B}$ bounded by $\lVert f\rVert_{\infty}$. Look at $B':=\cap_{n\geq 0}T^{-n}(B)$, then $\mu(B')=1$ as its complement is a countable union of nullsets and the estimate clearly holds on $B'$. But this requires us to change to:   $$\{x\in X;\lim\sup_{N\to\infty}|F(x)-A_{N}(f)(x)|>\epsilon\}\stackrel{\mu}{=}\{x\in X;\lim\sup_{N\to\infty}|F(x)-A_{N}(A_{M}(f))|\}$$   instead of a strict equality. But this doesn't pose any problems.","I am struggling with an estimate in a proof of the pointwise ergodic theorem discussed in T. Ward and M. Einsiedler: Ergodic Theory with a view towards Number Theory, which is left as an exercise. I will first give a description of the proof in order to clarify notation, then point out the estimate which is giving me troubles and then state what I have ``found out'' up to now (which is not so much unfortunately): Pointwise Ergodic Theorem: Let $(X,\mathscr{B},\mu)$ be a probability space, $T:(X,\mathscr{B})\to(X,\mathscr{B})$ measue-preserving, $f:X\to\mathbb{C}$ an integrable, measureable function, i.e. $\int_{X}|f|\operatorname{d}\mu<\infty$. Let $$A_{N}(f)(x):=\frac{1}{N}\sum_{n=0}^{N-1}f(T^{n}(x))\quad \forall x\in X, \forall N\geq 1$$ Then there exists an integrable function $f^{\ast}$ such that the sequence $(A_{N}(f))_{N\in\mathbb{N}}$ converges to $f^{\ast}$ pointwise almost everywhere. Let's quickly discuss the structure of the proof, which tells us what we know already and which estimate is giving me trouble. The proof: We start by assuming that $f$ is almost surely bounded . Once we have checked this case, we will use density of $L_{\mu}^{\infty}(X,\mathscr{B})$ in $L_{\mu}^{1}(X,\mathscr{B})$ to deduce the general case. We know from the mean ergodic theorem (which does not yet require the boundedness of $f$), that we can find an almost surely $T$-invariant, integrable function $F$ such that:   $$F={\lim_{N\to\infty}}^{L_{\mu}^{1}}A_{N}(f)$$   i.e. $\lVert F-A_{N}(f)\rVert_{1}\stackrel{N\to\infty}{\longrightarrow}0$. The claim hence becomes: let $F$ be a representative of the $L_{\mu}^{1}\cap L_{\mu}^{\infty}$-limit of $(A_{N}(f))$, then $A_{N}(f)$ converges to $F$ pointwise almost surely.   This claim is formalized as follows:    $$\mu(\{x\in X; \lim\sup_{N\to\infty}|F(x)-A_{N}(f)(x)|>0\})=0$$   Note that the claim would follow from:   $$\mu(\{x\in X; \lim\sup_{N\to\infty}|F(x)-A_{N}(f)(x)|>\epsilon\})<2\epsilon \quad\forall\epsilon>0$$ by some standard argumentation (here my estimate is a bit weaker than in the original reference but this should not affect the result). Fix $M\in\mathbb{N}$ and $\epsilon>0$, then we know from the maximal ergodic theorem applied to the functions $g_{1}:=F-A_{M}(f)$ and $g_{2}:=A_{M}(f)-F$ (this is why the 2 pops up in my discussion) that:   $$\mu(\{x\in X;\sup_{n\geq 1}|A_{N}(F-A_{M}(f))|>\epsilon\})<2\epsilon$$ Now comes the critical estimate: The authors state that for fixed $M\in\mathbb{N}$ holds:   $$\begin{equation}\exists N_{0}\in\mathbb{N}\exists C_{M}>0:\quad N\geq N_{0}\Rightarrow|A_{N}(f)-A_{N}(A_{M}(f))|\leq C_{M}\frac{\lVert f\rVert_{\infty}}{N}\end{equation}$$   Given the critical estimate and $A_{N}$-invariance of $F$, we find:   $$\begin{align}\{x\in X;\lim\sup_{N\to\infty}|F(x)-A_{N}(f)(x)|>\epsilon\}=&\{x\in X;\lim\sup_{N\to\infty}|F(x)-A_{N}(A_{M}(f))|>\epsilon\}\\ \stackrel{\mu}{=}&\{x\in X;\lim\sup_{N\to\infty}|A_{N}(F-A_{M}(f))(x)|>\epsilon\}\\ \subseteq & \{x\in X;\sup_{N\geq1}|A_{N}(F-A_{M}(f))(x)|\}\end{align}$$   where for $A,B\in\mathscr{B}$ holds $A\stackrel{\mu}{=}B$ if $\mu(A\Delta B)=0$. This readily proves the claim. I turn to you for the critical estimate: I do not manage to get the $N$ in the denominator. My idea was to do the following: I was about to check that $A_{N}(A_{M}(f))\to F$ in $L_{\mu}^{1}$ which sounds quite intuitive, i.e. both sequences have the same limit. This sounds quite obvious as the limit is $T$-invariant. Then I intended to use boundedness of $f$ to find a uniform estimate for the difference. But I always have the problem that the summation over $n$ and $N^{-1}$ cancel each other. Furthermore all those estimates are but almost surely. Could you please given me a hint on why the critical estimate holds? Note that I am particularly interested in getting this proof to work, not in any proof of the Pointwise Convergence Theorem. Detailed Estimate: Thanks to @Davide Giraudo, I think I managed to prove it if $f$ is honestly bounded. In what follows let $\xi:=(\xi_{n})_{n\in\mathbb{N}}$ be a bounded sequence and $U_{N}(\xi):=\sum_{n=0}^{N-1}\xi_{n}$. Using his idea, we get:   $$U_{N}(U_{M}(\xi))=\sum_{n=0}^{N-1}\sum_{m=n}^{M+n-1}\xi_{m}$$   A little drawing and induction shows that for fixed $M\in\mathbb{N}$ and $N\in\mathbb{N}$ way larger than $M$, we get:   $$\begin{align}U_{N}(U_{M}(\xi))=&\sum_{m=0}^{M-1}(m+1)\xi_{m}+M\sum_{m=M}^{N-1}\xi_{m}+\sum_{m=N}^{M+N-2}(M+N-1-m)\xi_{m}\\ =&U_{N}(\xi)+\sum_{m=0}^{M-1}m\xi_{m}+(M-1)\sum_{m=M}^{N-1}\xi_{m}+\sum_{m=N}^{M+N-2}(M+N-1-m)\xi_{m}\end{align}$$   so that:   $$U_{N}(U_{M}(\xi))-MU_{N}(\xi)=\sum_{m=0}^{M-1}(m+1-M)\xi_{m}+\sum_{m=N}^{M+N-2}(M+N-1-m)\xi_{m}$$   As $|m+1-M|\leq M$ for $m\in\{0,\ldots,M-1\}$ and $|M+N-1-m|\leq M+|N-m|\leq 2M$ for $m\in\{N,\ldots,M+N-2\}$, we find that for $x\equiv (f(T^{n}(x)))_{n\in\mathbb{N}}$ holds:   $$\begin{align}|A_{N}(A_{M}(x))-A_{N}(x)|=&\frac{1}{NM}|U_{N}(U_{M}(x))-MU_{N}(x)|\\ \leq &\frac{1}{NM}\left\{\sum_{m=0}^{M-1}2M\lVert f\rVert_{\infty}+\sum_{m=N}^{M+N-2}2M\lVert f\rVert_{\infty}\right\}\leq\frac{2M}{N}\lVert f\rVert_{\infty}\end{align}$$ It remains for me to ensure that if $f$ is almost surely bounded, the estimate still holds almost everywhere. Range of validity of the estimate: This is in fact easy. Let $f$ lmost surely bounded, then there exists $B\subseteq\mathscr{B}$ with $\mu(B)=1$ and $f|_{B}$ bounded by $\lVert f\rVert_{\infty}$. Look at $B':=\cap_{n\geq 0}T^{-n}(B)$, then $\mu(B')=1$ as its complement is a countable union of nullsets and the estimate clearly holds on $B'$. But this requires us to change to:   $$\{x\in X;\lim\sup_{N\to\infty}|F(x)-A_{N}(f)(x)|>\epsilon\}\stackrel{\mu}{=}\{x\in X;\lim\sup_{N\to\infty}|F(x)-A_{N}(A_{M}(f))|\}$$   instead of a strict equality. But this doesn't pose any problems.",,"['functional-analysis', 'probability-theory', 'ergodic-theory']"
97,Dolbeault cohomology and analytic regularity,Dolbeault cohomology and analytic regularity,,"Let $M$ be a complex analytic $n$-manifold. The Dolbeault cohomology complex is defined using a quotient space of smooth differential forms. My question is : would it make a big difference if we were to use $C^n$ sections instead, or $C^2$, or even differential forms in Sobolev spaces ? (obviously with at least enough regularity to define $\overline{\partial}$) EDIT A bit more precision : if I were to consider the quotient space $A/B$, where $A$ is the space of $C^1$ $(p,q)$-forms $\alpha$ for which $\overline{\partial} \alpha=0$ and $B$ is the set of $\overline{\partial}$ of $C^2 (p,q-1)$-forms, would I get the same dimension as $H^{p,q}$ ? What if I were to replace $C^2$ and $C^1$ by Sobolev spaces with distributional derivatives of order $2$ and $1$ in $L^p$ ?","Let $M$ be a complex analytic $n$-manifold. The Dolbeault cohomology complex is defined using a quotient space of smooth differential forms. My question is : would it make a big difference if we were to use $C^n$ sections instead, or $C^2$, or even differential forms in Sobolev spaces ? (obviously with at least enough regularity to define $\overline{\partial}$) EDIT A bit more precision : if I were to consider the quotient space $A/B$, where $A$ is the space of $C^1$ $(p,q)$-forms $\alpha$ for which $\overline{\partial} \alpha=0$ and $B$ is the set of $\overline{\partial}$ of $C^2 (p,q-1)$-forms, would I get the same dimension as $H^{p,q}$ ? What if I were to replace $C^2$ and $C^1$ by Sobolev spaces with distributional derivatives of order $2$ and $1$ in $L^p$ ?",,"['functional-analysis', 'complex-geometry', 'homology-cohomology']"
98,Do Incomplete Normed Vector Spaces Whose Duals Are Reflexive Exist?,Do Incomplete Normed Vector Spaces Whose Duals Are Reflexive Exist?,,"It is clear to me that if $X$ is a Banach space and its dual $X^*$ is reflexive, then $X$ is also reflexive (that is, the natural map between $X$ and its double dual $X^{**}$ is a surjective isometric isomorphism). However, I suspect that the conclusion fails to be true if we remove the completeness hypothesis, but I can't formalize this argument. Are there famous examples of incomplete (and hence non-reflexive) normed vector spaces whose duals are still reflexive? Or does the reflexivity of $X^*$ imply that $X$ is reflexive (and hence Banach) even if without assuming ab initio that $X$ is a Banach space?","It is clear to me that if $X$ is a Banach space and its dual $X^*$ is reflexive, then $X$ is also reflexive (that is, the natural map between $X$ and its double dual $X^{**}$ is a surjective isometric isomorphism). However, I suspect that the conclusion fails to be true if we remove the completeness hypothesis, but I can't formalize this argument. Are there famous examples of incomplete (and hence non-reflexive) normed vector spaces whose duals are still reflexive? Or does the reflexivity of $X^*$ imply that $X$ is reflexive (and hence Banach) even if without assuming ab initio that $X$ is a Banach space?",,['functional-analysis']
99,Subspace of Tempered Distributions,Subspace of Tempered Distributions,,"Let ${S_{h}}'(\mathbb{R}^{n})$ be the space of tempered distributions such that if $u\in {S_{h}}'(\mathbb{R}^{n})$, then $\lim_{\lambda\rightarrow \infty}{||\phi(\lambda D)u||_{\infty}} = 0$ for all $\phi$ compactly supported smooth functions. For $\phi \in C_{c}^{\infty}(\mathbb{R}^{n})$, we define $\phi(\lambda D)u$ by the Fourier transform $F[\phi(\lambda D)u] = \phi(\lambda t)F[u](t)$. What do distributions in this subspace behave like? Also, how can I show that any function in $L^{p} + L^{q}$ belongs to this subspace for $p$ and $q$ finite? What happens in the case of $L^{\infty}$?","Let ${S_{h}}'(\mathbb{R}^{n})$ be the space of tempered distributions such that if $u\in {S_{h}}'(\mathbb{R}^{n})$, then $\lim_{\lambda\rightarrow \infty}{||\phi(\lambda D)u||_{\infty}} = 0$ for all $\phi$ compactly supported smooth functions. For $\phi \in C_{c}^{\infty}(\mathbb{R}^{n})$, we define $\phi(\lambda D)u$ by the Fourier transform $F[\phi(\lambda D)u] = \phi(\lambda t)F[u](t)$. What do distributions in this subspace behave like? Also, how can I show that any function in $L^{p} + L^{q}$ belongs to this subspace for $p$ and $q$ finite? What happens in the case of $L^{\infty}$?",,"['real-analysis', 'analysis', 'functional-analysis', 'fourier-analysis', 'lp-spaces']"
