,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Determine all functions $f:\mathbb{Z}\to\mathbb{Z}$ such that $f\big(f(n)\big)=-(q-p)\,f(n)+pq\,n$ for all $n\in\mathbb{Z}$.",Determine all functions  such that  for all .,"f:\mathbb{Z}\to\mathbb{Z} f\big(f(n)\big)=-(q-p)\,f(n)+pq\,n n\in\mathbb{Z}","Let $p$ and $q$ be integers.  Let $S$ be a subset of $\mathbb{Z}$ , and $f:S\to S$ .  Consider the functional equation of the form $$f\big(f(n)\big)=-(q-p)\,f(n)+pq\,n\text{ for each }n\in S\,.\tag{*}$$ If $p$ and $q$ satisfy $0<p<q$ , and $S=\mathbb{Z}_{\geq 0}$ or $S=\mathbb{Z}_{>0}$ , then the only solution is known to be $$f(n)=pn\text{ for all }n\in S\,.$$ See here and here for references. The case of my particular interest is when $S=\mathbb{Z}$ .  We know that there are at least two solutions: $$f(n)=pn\text{ for all }n\in\mathbb{Z}$$ and $$f(n)=-qn\text{ for all }n\in\mathbb{Z}\,.$$ Are there other solutions when $S=\mathbb{Z}$ ? What happens if $p<q$ does not hold (but they are still positive integers)?  What can happen if we simply allow $p$ and $q$ to be any integer?  How would these changes affect the cases $S=\mathbb{Z}_{\geq 0}$ , $S=\mathbb{Z}_{>0}$ , and $S=\mathbb{Z}$ ?  (For example, when $p=1$ and $q=-1$ , then there can be other solutions such as $f(n)=n+1$ for all $n\in S$ .) If you feel particularly enthusiastic today, then you can also consider the case where $p$ and $q$ are nonintegral, not necessarily real, algebraic integers such that $q-p$ and $pq$ are both integers.  In this version of the problem (except for a few pairs $(p,q)$ ), I do not expect a solution in any of the cases $S=\mathbb{Z}_{\geq 0}$ , $S=\mathbb{Z}_{>0}$ , and $S=\mathbb{Z}$ . The trivial case $p=q=0$ is completely solved.  Other known trivial cases are $p=q=1$ and $p=q=\sqrt{-1}$ .  However, I do not know other results even when $p=q$ . Here is a nontrivial example for a nonintegral pair $(p,q)$ . When $S=\mathbb{Z}_{\geq0}$ or $S=\mathbb{Z}_{>0}$ , there exists a strictly increasing function $f:S\to S$ such that $$f\big(f(n)\big)=3n\text{ for all }n\in S\,.$$ (This is an example when $p=q=\sqrt{3}$ .) This may be (or may not be) helpful.  Here, $f^0:=\text{id}_S$ and $$f^k:=f\circ f^{k-1}$$ for $k\in\mathbb{Z}_{\geq 1}$ .  If $p+q\neq 0$ , then $$f^k(n)=p^k\,\left(\frac{qn+f(n)}{p+q}\right)+(-q)^k\,\left(\frac{pn-f(n)}{p+q}\right)$$ for all $n\in S$ and $k\in\mathbb{Z}_{\geq 0}$ .  On the other hand, if $q=-p$ and $p\neq 0$ , $$f^{k}(n)=p^k\,n+k\,p^{k-1}\,\big(f(n)-pn\big)$$ for all $n\in S$ and $k\in\mathbb{Z}_{\geq 0}$ .","Let and be integers.  Let be a subset of , and .  Consider the functional equation of the form If and satisfy , and or , then the only solution is known to be See here and here for references. The case of my particular interest is when .  We know that there are at least two solutions: and Are there other solutions when ? What happens if does not hold (but they are still positive integers)?  What can happen if we simply allow and to be any integer?  How would these changes affect the cases , , and ?  (For example, when and , then there can be other solutions such as for all .) If you feel particularly enthusiastic today, then you can also consider the case where and are nonintegral, not necessarily real, algebraic integers such that and are both integers.  In this version of the problem (except for a few pairs ), I do not expect a solution in any of the cases , , and . The trivial case is completely solved.  Other known trivial cases are and .  However, I do not know other results even when . Here is a nontrivial example for a nonintegral pair . When or , there exists a strictly increasing function such that (This is an example when .) This may be (or may not be) helpful.  Here, and for .  If , then for all and .  On the other hand, if and , for all and .","p q S \mathbb{Z} f:S\to S f\big(f(n)\big)=-(q-p)\,f(n)+pq\,n\text{ for each }n\in S\,.\tag{*} p q 0<p<q S=\mathbb{Z}_{\geq 0} S=\mathbb{Z}_{>0} f(n)=pn\text{ for all }n\in S\,. S=\mathbb{Z} f(n)=pn\text{ for all }n\in\mathbb{Z} f(n)=-qn\text{ for all }n\in\mathbb{Z}\,. S=\mathbb{Z} p<q p q S=\mathbb{Z}_{\geq 0} S=\mathbb{Z}_{>0} S=\mathbb{Z} p=1 q=-1 f(n)=n+1 n\in S p q q-p pq (p,q) S=\mathbb{Z}_{\geq 0} S=\mathbb{Z}_{>0} S=\mathbb{Z} p=q=0 p=q=1 p=q=\sqrt{-1} p=q (p,q) S=\mathbb{Z}_{\geq0} S=\mathbb{Z}_{>0} f:S\to S f\big(f(n)\big)=3n\text{ for all }n\in S\,. p=q=\sqrt{3} f^0:=\text{id}_S f^k:=f\circ f^{k-1} k\in\mathbb{Z}_{\geq 1} p+q\neq 0 f^k(n)=p^k\,\left(\frac{qn+f(n)}{p+q}\right)+(-q)^k\,\left(\frac{pn-f(n)}{p+q}\right) n\in S k\in\mathbb{Z}_{\geq 0} q=-p p\neq 0 f^{k}(n)=p^k\,n+k\,p^{k-1}\,\big(f(n)-pn\big) n\in S k\in\mathbb{Z}_{\geq 0}","['functions', 'recurrence-relations', 'functional-equations', 'recursion', 'integers']"
1,Multivariable function Integrable for what values?,Multivariable function Integrable for what values?,,"For what values of $\alpha,\beta \in \mathbb{R}$ will the function $$f:(0,1]\times(0,1] \to \mathbb{R}: (x,y) \mapsto x^\alpha y^\alpha (x+y)^\beta$$ be integrable? Normally, I don't have problems solving these integrals using Fubini's theorem and by a change of variables. However, I don't seem to find the right change of variables? Any hints? Thank you!","For what values of will the function be integrable? Normally, I don't have problems solving these integrals using Fubini's theorem and by a change of variables. However, I don't seem to find the right change of variables? Any hints? Thank you!","\alpha,\beta \in \mathbb{R} f:(0,1]\times(0,1] \to \mathbb{R}: (x,y) \mapsto x^\alpha y^\alpha (x+y)^\beta","['integration', 'functions', 'lebesgue-integral', 'fubini-tonelli-theorems']"
2,Finding null space and image,Finding null space and image,,"Let $T(f(x)) = g(x) = \int_{-1}^{1}f(t)(t-x)^2dt$ be a linear transformation from $V$ to $V$ where $V$ is the vector space of continuous functions on $[-1 , 1]$ . Find $\text{Nul}(T)$ and $\text{Im}(T)$ . I really have no idea about the solution . Can $x$ be considered constant in the integral ? And then how to evaluate integral ?",Let be a linear transformation from to where is the vector space of continuous functions on . Find and . I really have no idea about the solution . Can be considered constant in the integral ? And then how to evaluate integral ?,"T(f(x)) = g(x) = \int_{-1}^{1}f(t)(t-x)^2dt V V V [-1 , 1] \text{Nul}(T) \text{Im}(T) x","['linear-algebra', 'integration', 'functions', 'vector-spaces', 'linear-transformations']"
3,Proving a function is a fixed point,Proving a function is a fixed point,,"I'm taking a class in University which involves proving the correctness of computer programs and I'm really bad a proofs, I don't really understand them at all. Can anyone tell me if my proof actually makes any sense, I frequently think I've written a proof but usually I've proved nothing. Given this (T1 is a function that takes another function (F) as one of its parameters): T1(F,x,y) == if y = 0 then x else F(x−1,y−1) I had to suggest a fixed point solution, I suggested: f1(x,y) == x - y Because T1 is a recursive function that implements subtraction. And below I had to prove my suggestion was correct. To show T1(f1) = f1  T1(f1, x, y) == if y = 0 then x else f1(x−1,y−1)  if y = 0 then x else (x-1) - (y-1)  if y = 0 then x else x - y - 2  x - y - 2 = f1(x-1,y-1)  x - y = f1(x,y) Does my proof have some obvious hole in it that I'm not seeing or is there some mistake I can't see, I think it works but I'm not really sure why it proves anything?","I'm taking a class in University which involves proving the correctness of computer programs and I'm really bad a proofs, I don't really understand them at all. Can anyone tell me if my proof actually makes any sense, I frequently think I've written a proof but usually I've proved nothing. Given this (T1 is a function that takes another function (F) as one of its parameters): T1(F,x,y) == if y = 0 then x else F(x−1,y−1) I had to suggest a fixed point solution, I suggested: f1(x,y) == x - y Because T1 is a recursive function that implements subtraction. And below I had to prove my suggestion was correct. To show T1(f1) = f1  T1(f1, x, y) == if y = 0 then x else f1(x−1,y−1)  if y = 0 then x else (x-1) - (y-1)  if y = 0 then x else x - y - 2  x - y - 2 = f1(x-1,y-1)  x - y = f1(x,y) Does my proof have some obvious hole in it that I'm not seeing or is there some mistake I can't see, I think it works but I'm not really sure why it proves anything?",,"['functions', 'proof-writing', 'fixed-point-theorems']"
4,a problem on composition of functions,a problem on composition of functions,,"Let $f \colon A \to A$ be a function such that $f \circ f=f$ .  If $f$ is one-to-one then prove that $f$ is also onto. I know in my head that the func. $f$ is $f(x)=x$ , but I can't develop a proof for the above statement.","Let be a function such that .  If is one-to-one then prove that is also onto. I know in my head that the func. is , but I can't develop a proof for the above statement.",f \colon A \to A f \circ f=f f f f f(x)=x,['functions']
5,Applying a function a non-integer amount of times,Applying a function a non-integer amount of times,,"Taking the principal log of a real or complex number an infinite number of times converges one of two particular values in the complex plane.  These values are $-W(-1)^*$ given a seed value with $\Im(z) \ge 0$ , and $-W(-1)$ otherwise (with $W$ being the principal branch of the Lambert W function .) While converging these values appear to ""spiral"" around this number in a way reminiscent of certain systems of differential equations. However, function application is a discrete operation, so relating the two might be a bit of a fool's errand.  I'm aware that it is possible to extend the differentiation operator in this manner.  But that may be specific to differentiation, and it might not be possible with general function application. So, is there a method for a general function?  What about the specific function log?  Is there a class of functions for which this works?","Taking the principal log of a real or complex number an infinite number of times converges one of two particular values in the complex plane.  These values are given a seed value with , and otherwise (with being the principal branch of the Lambert W function .) While converging these values appear to ""spiral"" around this number in a way reminiscent of certain systems of differential equations. However, function application is a discrete operation, so relating the two might be a bit of a fool's errand.  I'm aware that it is possible to extend the differentiation operator in this manner.  But that may be specific to differentiation, and it might not be possible with general function application. So, is there a method for a general function?  What about the specific function log?  Is there a class of functions for which this works?",-W(-1)^* \Im(z) \ge 0 -W(-1) W,['functions']
6,"Looking for a terminology for ""sameness"" of functions","Looking for a terminology for ""sameness"" of functions",,"Consider the situation described in the following diagram, namely: $A$ , $A'$ , $B$ , and $B'$ are sets. $\alpha:A\rightarrow A'$ and $\beta:B\rightarrow B'$ are bijections. $f:A\rightarrow B$ and $\ f':A'\rightarrow B'$ . The following equations are satisfied. $$ f = \beta^{-1} \circ f' \circ \alpha\\ f' = \beta\circ f \circ \alpha^{-1} $$ In a sense $f$ and $f'$ are the same function, in that each can be computed in terms of the other, with no information being lost or gained. Is there an accepted terminology for this sameness of $f$ and $f'$ ?","Consider the situation described in the following diagram, namely: , , , and are sets. and are bijections. and . The following equations are satisfied. In a sense and are the same function, in that each can be computed in terms of the other, with no information being lost or gained. Is there an accepted terminology for this sameness of and ?","A A' B B' \alpha:A\rightarrow A' \beta:B\rightarrow B' f:A\rightarrow B \ f':A'\rightarrow B' 
f = \beta^{-1} \circ f' \circ \alpha\\
f' = \beta\circ f \circ \alpha^{-1}
 f f' f f'","['functions', 'category-theory', 'terminology']"
7,Find the domain of x $\left \lfloor x \right \rfloor + \left \lfloor x+\frac{1}{2} \right \rfloor + \left \lfloor x-\frac{1}{3} \right \rfloor =8$,Find the domain of x,\left \lfloor x \right \rfloor + \left \lfloor x+\frac{1}{2} \right \rfloor + \left \lfloor x-\frac{1}{3} \right \rfloor =8,"Find the domain of x $$\left  \lfloor x \right \rfloor + \left  \lfloor x+\frac{1}{2}  \right \rfloor   + \left  \lfloor x-\frac{1}{3}  \right \rfloor    =8$$  My approach When x is an integer $x+x+x-1=8$ or x=3 But for case when x is not an integer i am not able to substitute, manually x is $\frac{10}{3}$ which i did by trial method. My final answer is $3\le x <\frac{10}{3} $","Find the domain of x $$\left  \lfloor x \right \rfloor + \left  \lfloor x+\frac{1}{2}  \right \rfloor   + \left  \lfloor x-\frac{1}{3}  \right \rfloor    =8$$  My approach When x is an integer $x+x+x-1=8$ or x=3 But for case when x is not an integer i am not able to substitute, manually x is $\frac{10}{3}$ which i did by trial method. My final answer is $3\le x <\frac{10}{3} $",,['functions']
8,Continuous function that takes rationals to irrationals and vice-versa?,Continuous function that takes rationals to irrationals and vice-versa?,,"In this question - https://www.quora.com/Can-you-create-a-continuous-function-that-takes-rational-numbers-to-irrational-ones-and-vice-versa How $|f(\Bbb{Q})| \leq |\Bbb{Q}|$ ? in the first answer, I understood that $|f(\Bbb{Q}^c)| \leq |\Bbb{Q}|$ de to the fact that $|$Codomain$| \leq |$range$|$. After that how do I think of this? - It then follows that f is a constant function because a non-constant continuous real-valued function has an uncountable image. Also any other approach to this question?","In this question - https://www.quora.com/Can-you-create-a-continuous-function-that-takes-rational-numbers-to-irrational-ones-and-vice-versa How $|f(\Bbb{Q})| \leq |\Bbb{Q}|$ ? in the first answer, I understood that $|f(\Bbb{Q}^c)| \leq |\Bbb{Q}|$ de to the fact that $|$Codomain$| \leq |$range$|$. After that how do I think of this? - It then follows that f is a constant function because a non-constant continuous real-valued function has an uncountable image. Also any other approach to this question?",,"['calculus', 'real-analysis', 'functions', 'continuity', 'rational-numbers']"
9,Does every function have a graph?,Does every function have a graph?,,"I'm having trouble understanding this. My friend said it doesn't, but I disagree, though I'm not sure. Given a function $f:A \to B$, the graph of $f$ is defined by $G(f) = \{(x,y)| x \in A , y = f(x)\}$. Then, is it true that if a function exists, its graph exist (Even though there may be no geometric interpretation)? I think this is true, since in the ""worst"" case it would be the empty set, which exists...","I'm having trouble understanding this. My friend said it doesn't, but I disagree, though I'm not sure. Given a function $f:A \to B$, the graph of $f$ is defined by $G(f) = \{(x,y)| x \in A , y = f(x)\}$. Then, is it true that if a function exists, its graph exist (Even though there may be no geometric interpretation)? I think this is true, since in the ""worst"" case it would be the empty set, which exists...",,['functions']
10,every nonsurjective continuous function from $S^2$ to $S^2$ there exist a fixed point?,every nonsurjective continuous function from  to  there exist a fixed point?,S^2 S^2,can someone please help me to show for every nonsurjective continuous function from $S^2$ to $S^2$ there exist a fixed point? i think since the fuction is not surjective it doesn't contain at least one point of $S^2$ so it's like a function from $S^2$ to $R^2$ and by Borsuk-Ulam there exist a point x s.t. f(x)=f(-x) but i'm not sure if this can help...,can someone please help me to show for every nonsurjective continuous function from $S^2$ to $S^2$ there exist a fixed point? i think since the fuction is not surjective it doesn't contain at least one point of $S^2$ so it's like a function from $S^2$ to $R^2$ and by Borsuk-Ulam there exist a point x s.t. f(x)=f(-x) but i'm not sure if this can help...,,"['functions', 'algebraic-topology', 'fixed-point-theorems']"
11,Finding the x's for which f(x) is a whole number,Finding the x's for which f(x) is a whole number,,"I'm trying to improve my math skills and I found this exercise in my book. We have the following function: $$f: \mathbb R\to \mathbb R$$  $$f(x) = \frac {4x+1}3$$ I've been asked to find out one value for $x$ such that $f(x)$ is a whole number. I found some solutions and afterwards I determined that for all $$x_n=\frac {3^{2n}-1}4$$  where n is a natural number different from 0 , $f(x_n)$ is a whole number. I'm not 100% sure this is correct but it seems to work for all positive even powers of 3. I've been trying to prove that this formula is corect, but I didn't succeed. Could anyone point me out on how to prove this kind of problems, and what to watch out for? Thanks.","I'm trying to improve my math skills and I found this exercise in my book. We have the following function: $$f: \mathbb R\to \mathbb R$$  $$f(x) = \frac {4x+1}3$$ I've been asked to find out one value for $x$ such that $f(x)$ is a whole number. I found some solutions and afterwards I determined that for all $$x_n=\frac {3^{2n}-1}4$$  where n is a natural number different from 0 , $f(x_n)$ is a whole number. I'm not 100% sure this is correct but it seems to work for all positive even powers of 3. I've been trying to prove that this formula is corect, but I didn't succeed. Could anyone point me out on how to prove this kind of problems, and what to watch out for? Thanks.",,"['functions', 'elementary-set-theory']"
12,Does there exists such a function?,Does there exists such a function?,,"A function from $f:\mathbb{R} \rightarrow \mathbb{R}$ such that : a. $f$ is bijective, b. $f’(0)=1$ (in particular, $f$ is differentiable and therefore continuous at 0), and c. $f^{-1}$ is not continuous at 0. I think it exists! But don’t know how to find it. Thanks for any help!","A function from $f:\mathbb{R} \rightarrow \mathbb{R}$ such that : a. $f$ is bijective, b. $f’(0)=1$ (in particular, $f$ is differentiable and therefore continuous at 0), and c. $f^{-1}$ is not continuous at 0. I think it exists! But don’t know how to find it. Thanks for any help!",,"['functions', 'derivatives']"
13,A question about real-analytic functions vanishing on an open set,A question about real-analytic functions vanishing on an open set,,"Real analytic functions are defined as functions on the Euclidean spaces with convergent power series at each point. My question is that, is there some kind of identity theorem for real analytic functions? My book (John Lee's smooth manifolds) says on p.46 that a real-analytic function defined on a connected domain and vanishes on an open set is identically zero. But I have the impression that this kind of fact holds for holomorphic functions only. Am I missing something?","Real analytic functions are defined as functions on the Euclidean spaces with convergent power series at each point. My question is that, is there some kind of identity theorem for real analytic functions? My book (John Lee's smooth manifolds) says on p.46 that a real-analytic function defined on a connected domain and vanishes on an open set is identically zero. But I have the impression that this kind of fact holds for holomorphic functions only. Am I missing something?",,"['real-analysis', 'functions', 'analyticity', 'analytic-functions']"
14,Are all smooth functions Lipschitz?,Are all smooth functions Lipschitz?,,Can we prove the following statement:  $$\|\triangledown f(x)-\triangledown f(y)\|\leq\beta\|x-y\|\xrightarrow{?} \| f(x)-f(y)\|\leq L\|x-y\|$$ i.e. every smooth function is Lipschitz? If it is not correct please tell me under what conditions it can be correct. In the comments of this question an example is given that exponential function is smooth and is not Lipschitz. However I can't find any $\beta$ such that $\|e^x-e^y\|\leq \beta\|x-y\|$ and derivative of exponential equals to itself!,Can we prove the following statement:  $$\|\triangledown f(x)-\triangledown f(y)\|\leq\beta\|x-y\|\xrightarrow{?} \| f(x)-f(y)\|\leq L\|x-y\|$$ i.e. every smooth function is Lipschitz? If it is not correct please tell me under what conditions it can be correct. In the comments of this question an example is given that exponential function is smooth and is not Lipschitz. However I can't find any $\beta$ such that $\|e^x-e^y\|\leq \beta\|x-y\|$ and derivative of exponential equals to itself!,,"['functions', 'lipschitz-functions']"
15,Odd function composition,Odd function composition,,Let $f: \Bbb R \to \Bbb R$ be an odd function. Is the compositon of $ \underbrace{f \circ f \circ f \circ \cdots \circ f}_{\text{$n$ times}}$ odd or even? Do I need to prove it with separate cases for $n$ even and $n$ odd?,Let be an odd function. Is the compositon of odd or even? Do I need to prove it with separate cases for even and odd?,f: \Bbb R \to \Bbb R  \underbrace{f \circ f \circ f \circ \cdots \circ f}_{\text{n times}} n n,"['functions', 'function-and-relation-composition']"
16,What's the correct way to define a function? (codomain and surjectivity),What's the correct way to define a function? (codomain and surjectivity),,"Here's a common definition of a function (for example, Wiki follows this definition ): A relation between sets $A$ and $B$ is any subset $R \subseteq A \times B$.  We say that this relation is a function if it satisfies the property   $$ (a,b_1) \in R \text{ and }(a,b_2) \in R \implies b_1 = b_2 $$ This definition of a function is good for most purposes.  Certainly, we can find the domain and range of a function defined in this way.  This also allows us to answer such questions as Is the set $\{(1,2),(2,5),(3,5)\}$ a function? (answer: yes) With such a definition, we could certainly go on to define a function's domain and range. The problem with this definition, however, is that it includes no notion of a codomain.  This presents a problem when we want to answer a question such as Are the functions $f:\Bbb R \to \Bbb R$ given by $f(x) = x^2$ and $g:\Bbb R \to [0,\infty)$ given by $g(x) = x^2$ the same function?  (answer: no) On the one hand, the ""graphs"" of the function are the same.  If we are to believe that these functions are merely subsets of a Cartesian product, then we should say that $f = g$ since both are merely the set $\{(x,x^2) : x \in \Bbb R\}$.  On the other hand, we would like to say that ""the function $g$ is surjective, but the function $f$ is not"".  If surjectivity is a property of functions, then the fact that $f$ and $g$ do not share this property should mean that $f \neq g$. So what gives?   Is there a setting in which both of these questions are well-posed?  If someone has a reference that handles all this well, I would appreciate it. Edit: Wiki apparrarently has a discussion of this issue here","Here's a common definition of a function (for example, Wiki follows this definition ): A relation between sets $A$ and $B$ is any subset $R \subseteq A \times B$.  We say that this relation is a function if it satisfies the property   $$ (a,b_1) \in R \text{ and }(a,b_2) \in R \implies b_1 = b_2 $$ This definition of a function is good for most purposes.  Certainly, we can find the domain and range of a function defined in this way.  This also allows us to answer such questions as Is the set $\{(1,2),(2,5),(3,5)\}$ a function? (answer: yes) With such a definition, we could certainly go on to define a function's domain and range. The problem with this definition, however, is that it includes no notion of a codomain.  This presents a problem when we want to answer a question such as Are the functions $f:\Bbb R \to \Bbb R$ given by $f(x) = x^2$ and $g:\Bbb R \to [0,\infty)$ given by $g(x) = x^2$ the same function?  (answer: no) On the one hand, the ""graphs"" of the function are the same.  If we are to believe that these functions are merely subsets of a Cartesian product, then we should say that $f = g$ since both are merely the set $\{(x,x^2) : x \in \Bbb R\}$.  On the other hand, we would like to say that ""the function $g$ is surjective, but the function $f$ is not"".  If surjectivity is a property of functions, then the fact that $f$ and $g$ do not share this property should mean that $f \neq g$. So what gives?   Is there a setting in which both of these questions are well-posed?  If someone has a reference that handles all this well, I would appreciate it. Edit: Wiki apparrarently has a discussion of this issue here",,"['functions', 'discrete-mathematics', 'elementary-set-theory', 'definition']"
17,"$a+b+c = 13$; if $b/a=c/b$, find the maximum and minimum values of $a$ and the corresponding $b$ and $c$","; if , find the maximum and minimum values of  and the corresponding  and",a+b+c = 13 b/a=c/b a b c,"Question : The sum of $3$ integers $a,b$ and $c$ is $13$. If $\dfrac{b}{a}=\dfrac{c}{b}$, find the maximum and minimum values of $a$ and the corresponding $b$ and $c$. To tackle this problem I let $x=\dfrac{b}{a}=\dfrac{c}{b}$ because I wanted to create a quadratic equation in order to use the discriminant theorem.  From the equation above I can deduce that $b=ax$ and $c=ax^2$. Because $a+b+c=13$. Therefore; $$a+ax+ax^2=13$$ $$\implies 1+x+x^2-\frac{13}{a} = 0 $$  (where $a \ne 0$, $b \ne 0$, $c \ne 0$) I can only work up to here. I do not know how to use the discriminant theorem to work out the maximum and minimum of $a$, $b$ and $c$.","Question : The sum of $3$ integers $a,b$ and $c$ is $13$. If $\dfrac{b}{a}=\dfrac{c}{b}$, find the maximum and minimum values of $a$ and the corresponding $b$ and $c$. To tackle this problem I let $x=\dfrac{b}{a}=\dfrac{c}{b}$ because I wanted to create a quadratic equation in order to use the discriminant theorem.  From the equation above I can deduce that $b=ax$ and $c=ax^2$. Because $a+b+c=13$. Therefore; $$a+ax+ax^2=13$$ $$\implies 1+x+x^2-\frac{13}{a} = 0 $$  (where $a \ne 0$, $b \ne 0$, $c \ne 0$) I can only work up to here. I do not know how to use the discriminant theorem to work out the maximum and minimum of $a$, $b$ and $c$.",,"['functions', 'quadratics']"
18,Can every possible 'imaginary number' be expressed in terms of $i$?,Can every possible 'imaginary number' be expressed in terms of ?,i,"The domain of the function $f(x)=\sqrt{x}$ can be extended to all real numbers by introducing a new number, $i=\sqrt{-1}$. Can this be done for any function, say $\arcsin{x}$, or $\log{x}$? What is $\arcsin{2}$? Or $\log{-3}$?","The domain of the function $f(x)=\sqrt{x}$ can be extended to all real numbers by introducing a new number, $i=\sqrt{-1}$. Can this be done for any function, say $\arcsin{x}$, or $\log{x}$? What is $\arcsin{2}$? Or $\log{-3}$?",,"['functions', 'complex-numbers', 'inverse-function']"
19,Why does this function output negative values for most primes?,Why does this function output negative values for most primes?,,"I recently played around with wolframalpha, and I found a very interesting property. This function: $$f(x)=\sin(\cos(x-1)!)$$ yields a negative output for most prime numbers when only integer inputs are graphed. The beginning of the function (close to $y$-axis) is very interesting. For $x=3, x=7, x=11, x=13, x=17, x=23, x=29, x=31, x=47$ which are all primes, the output is negative. Of course, later on there are less prime inputs that give a negative output, but still prime number inputs dominate the function's negative output values. Why does this happen, can this be somehow explained?","I recently played around with wolframalpha, and I found a very interesting property. This function: $$f(x)=\sin(\cos(x-1)!)$$ yields a negative output for most prime numbers when only integer inputs are graphed. The beginning of the function (close to $y$-axis) is very interesting. For $x=3, x=7, x=11, x=13, x=17, x=23, x=29, x=31, x=47$ which are all primes, the output is negative. Of course, later on there are less prime inputs that give a negative output, but still prime number inputs dominate the function's negative output values. Why does this happen, can this be somehow explained?",,"['functions', 'trigonometry', 'prime-numbers', 'factorial']"
20,Is there a name for a functionalistic / operations-like approach?,Is there a name for a functionalistic / operations-like approach?,,"I find it a lot easier to think about e.g. integration as int(a, b, f(x), x) rather than $\int_{a}^{b}{f(x)}dx$. And even addition seems more intuitive as add(a,b) rather than $a+b$. Is there a term for thinking like that or is this just being weird with notation?","I find it a lot easier to think about e.g. integration as int(a, b, f(x), x) rather than $\int_{a}^{b}{f(x)}dx$. And even addition seems more intuitive as add(a,b) rather than $a+b$. Is there a term for thinking like that or is this just being weird with notation?",,"['integration', 'functions', 'binary-operations']"
21,How to verbally state $f(y\mid x)\;?$,How to verbally state,f(y\mid x)\;?,"How do we verbally state: $\large f(y\mid x)\;?$ I'm familiar with $f(x)$ as ""$f$ of $x$"" and $f(x,y)$ as ""$f$ of $x$ and $y$"" (or $f$ of $x, y$), but what does the vertical line mean and how to state this verbally so that a screen reader would read it correctly?","How do we verbally state: $\large f(y\mid x)\;?$ I'm familiar with $f(x)$ as ""$f$ of $x$"" and $f(x,y)$ as ""$f$ of $x$ and $y$"" (or $f$ of $x, y$), but what does the vertical line mean and how to state this verbally so that a screen reader would read it correctly?",,"['functions', 'notation', 'terminology']"
22,Find the integral values of $a$ for which $f(x)$ is onto.,Find the integral values of  for which  is onto.,a f(x),"A function $f:\mathbb R\rightarrow\mathbb R$ is defined by $f(x)=\dfrac{ax^2+6x-8}{a+6x-8x^2}$. Find the integral values of $a$ for which $f$ is onto(surjective). My attempt: As given in question co-domain of the function is $\mathbb R$ so range of the function should also be $\mathbb R$ for the function to be surjective. So range of $f(x)\in (-\infty,\infty)$ and this is only true if the denominator of $f(x)$ approaches zero for some $a$ and $x$. So I used desmos to see at what values of $a$ and $x$,denominator of $f(x)$ gets zero and I found that at $a$ between $(-1.5,0)$, $f(x)$ gets close to zero and hence $f(x)$ tends to $\pm\infty$ But my answer is wrong, the correct answer is $a\in [2,14]$ for $f(x)\in(-\infty,\infty)$ I don't know how to do this, thanks in advance!","A function $f:\mathbb R\rightarrow\mathbb R$ is defined by $f(x)=\dfrac{ax^2+6x-8}{a+6x-8x^2}$. Find the integral values of $a$ for which $f$ is onto(surjective). My attempt: As given in question co-domain of the function is $\mathbb R$ so range of the function should also be $\mathbb R$ for the function to be surjective. So range of $f(x)\in (-\infty,\infty)$ and this is only true if the denominator of $f(x)$ approaches zero for some $a$ and $x$. So I used desmos to see at what values of $a$ and $x$,denominator of $f(x)$ gets zero and I found that at $a$ between $(-1.5,0)$, $f(x)$ gets close to zero and hence $f(x)$ tends to $\pm\infty$ But my answer is wrong, the correct answer is $a\in [2,14]$ for $f(x)\in(-\infty,\infty)$ I don't know how to do this, thanks in advance!",,"['calculus', 'functions']"
23,Show that there exists a fixed point for this (set theoretic) class function,Show that there exists a fixed point for this (set theoretic) class function,,"I see that this question might be trivial but I can't seem to figure it out myself: Suppose that $F:ON\to ON$ is a class function: that is, for every ordinal $\alpha$ there is unique ordinal $F(\alpha)$ corresponding. Suppose that $F$ satisfies following conditions: $\alpha < \beta \implies F(\alpha)<F(\beta)$ i.e. $F$ is monotonic $F(\lambda)=\bigcup\{F(\gamma):\gamma<\lambda\}$ for limit ordinals $\lambda$ Show that, then there exists $\alpha \in ON$ such that $F(\alpha)=\alpha$. The hint suggested to prove $\alpha\le F(\alpha)$ for every ordinals, which can be done by induction on $\alpha$. Also suggested by hint, I constructed a ""candidate"" $\alpha$: By recursion, there is $f:\omega \to f[\omega]$ such that $f(0)=0$ and $f(n+1)=F(f(n))$, and then set $$\alpha=\bigcup f[\omega]$$ The problem is I don't see how this might help me. It is clearly suggested that above $\alpha$ works, but I have no information regarding $F(\alpha)$ at this point that proving $F(\alpha)\subset \alpha$ seems impossible.","I see that this question might be trivial but I can't seem to figure it out myself: Suppose that $F:ON\to ON$ is a class function: that is, for every ordinal $\alpha$ there is unique ordinal $F(\alpha)$ corresponding. Suppose that $F$ satisfies following conditions: $\alpha < \beta \implies F(\alpha)<F(\beta)$ i.e. $F$ is monotonic $F(\lambda)=\bigcup\{F(\gamma):\gamma<\lambda\}$ for limit ordinals $\lambda$ Show that, then there exists $\alpha \in ON$ such that $F(\alpha)=\alpha$. The hint suggested to prove $\alpha\le F(\alpha)$ for every ordinals, which can be done by induction on $\alpha$. Also suggested by hint, I constructed a ""candidate"" $\alpha$: By recursion, there is $f:\omega \to f[\omega]$ such that $f(0)=0$ and $f(n+1)=F(f(n))$, and then set $$\alpha=\bigcup f[\omega]$$ The problem is I don't see how this might help me. It is clearly suggested that above $\alpha$ works, but I have no information regarding $F(\alpha)$ at this point that proving $F(\alpha)\subset \alpha$ seems impossible.",,"['functions', 'set-theory', 'ordinals']"
24,Let $f:A\to B$ and $g:B\to C$. Suppose $g\circ f$ is a bijection. Then $f$ is injective and $g$ is surjective onto $C$.,Let  and . Suppose  is a bijection. Then  is injective and  is surjective onto .,f:A\to B g:B\to C g\circ f f g C,"I think proving $f$ is injective is fairly simple: Let $x_1,x_2\in A$ s.t. $f(x_1)=f(x_2)$. Then, $g\circ f(x_1)=g\circ f(x_2)$. Thus, as $g\circ f$ is bijective, we have that $x_1=x_2$. Thus, $f$ is injective. Proving $g$ is onto $C$ is a little more difficult for me. I have the following, but I am unsure of its correctness: Let $y\in C$. Then, because $g\circ f$ is bijective, there is some $x\in A$ s.t. $g\circ f(x)=y$. Note that $f(x)\in B$. *Thus, $g\circ f(x)\in C$. **Thus, there is some $x\in B$ s.t. $g(x)=y$. Thus, $g$ is onto C. My uncertainty comes from the leap from * to **. Does this progression follow? Thanks!","I think proving $f$ is injective is fairly simple: Let $x_1,x_2\in A$ s.t. $f(x_1)=f(x_2)$. Then, $g\circ f(x_1)=g\circ f(x_2)$. Thus, as $g\circ f$ is bijective, we have that $x_1=x_2$. Thus, $f$ is injective. Proving $g$ is onto $C$ is a little more difficult for me. I have the following, but I am unsure of its correctness: Let $y\in C$. Then, because $g\circ f$ is bijective, there is some $x\in A$ s.t. $g\circ f(x)=y$. Note that $f(x)\in B$. *Thus, $g\circ f(x)\in C$. **Thus, there is some $x\in B$ s.t. $g(x)=y$. Thus, $g$ is onto C. My uncertainty comes from the leap from * to **. Does this progression follow? Thanks!",,"['functions', 'proof-verification']"
25,a set $X$ is infinite iff there isn't a bijection from $I_n\subset N$ to it,a set  is infinite iff there isn't a bijection from  to it,X I_n\subset N,"Consider the set: $$I_n = \{p\in \mathbb{N}; 1<p\le n\}$$ My book says that a set is finite when it's not empty or when there exists, for some $n\in \mathbb{N}$, a bijection: $$\phi: I_n\to X$$ Then, it defines an infinite set as a set that is not finite. This can be understood as: a set $X$ is infinite when it's not empty and for all $n\in \mathbb{N}$, there isn't any bijection $\phi: I_n \to X$ Later, my teacher gave a list of exercises, in which one of them is: Prove that a set $X$ is infinite iff it's no empty neither has a bijection $f: I_n \to X$ no matter which $n\in \mathbb{N}$ Well, I know that: $\to$ if there isn't a surjective function $f: I_n \to X$, then there isn't also a bijective function $f: I_n\to X$, because bijectivity is surjectivity with injectivity, and by the definition, this set is not finite, that is, infinite. $\leftarrow$ well, since $X$ is infinite, then it's not finite, which means that there isn't any bijective function from $I_n$ to $X$, so I know that this function must be either only injective, only surjective, or none of them. I must prove now that surjectivity must always fail , but I can't see anymore assumptions to use here. Intuitively I know that there can't possibly exist a surjective function from $I_n$ to an infinite set because all members of $I_n$ must be mapped to a unique element in $X$, but there are infinite elements in $X$. Could someone help me?","Consider the set: $$I_n = \{p\in \mathbb{N}; 1<p\le n\}$$ My book says that a set is finite when it's not empty or when there exists, for some $n\in \mathbb{N}$, a bijection: $$\phi: I_n\to X$$ Then, it defines an infinite set as a set that is not finite. This can be understood as: a set $X$ is infinite when it's not empty and for all $n\in \mathbb{N}$, there isn't any bijection $\phi: I_n \to X$ Later, my teacher gave a list of exercises, in which one of them is: Prove that a set $X$ is infinite iff it's no empty neither has a bijection $f: I_n \to X$ no matter which $n\in \mathbb{N}$ Well, I know that: $\to$ if there isn't a surjective function $f: I_n \to X$, then there isn't also a bijective function $f: I_n\to X$, because bijectivity is surjectivity with injectivity, and by the definition, this set is not finite, that is, infinite. $\leftarrow$ well, since $X$ is infinite, then it's not finite, which means that there isn't any bijective function from $I_n$ to $X$, so I know that this function must be either only injective, only surjective, or none of them. I must prove now that surjectivity must always fail , but I can't see anymore assumptions to use here. Intuitively I know that there can't possibly exist a surjective function from $I_n$ to an infinite set because all members of $I_n$ must be mapped to a unique element in $X$, but there are infinite elements in $X$. Could someone help me?",,"['functions', 'elementary-set-theory']"
26,"what does linearly independent in C[0, 1] mean?","what does linearly independent in C[0, 1] mean?",,"This is a question from my textbook I'm not quite sure what C[0, 1] mean, I tried to google the similar question and found that $C[0,1]$ usually denotes the collection of continuous functions $f: [0,1]\to \mathbb{R}$, but I'm still not quite sure what $f: [0,1]$ means, does $[0,1]$ means the domain of the function, can anyone give me a straightforward example","This is a question from my textbook I'm not quite sure what C[0, 1] mean, I tried to google the similar question and found that $C[0,1]$ usually denotes the collection of continuous functions $f: [0,1]\to \mathbb{R}$, but I'm still not quite sure what $f: [0,1]$ means, does $[0,1]$ means the domain of the function, can anyone give me a straightforward example",,"['linear-algebra', 'functions', 'vector-spaces']"
27,Why are trigonometric functions defined in the context of right triangles?,Why are trigonometric functions defined in the context of right triangles?,,"Couldn't we just use a different, fixed angle? Is there something special about the ratios of the sides in a right triangle? Is the pythagorean theorem somehow involved?","Couldn't we just use a different, fixed angle? Is there something special about the ratios of the sides in a right triangle? Is the pythagorean theorem somehow involved?",,"['functions', 'trigonometry']"
28,How to show Cantor function is uniformly continuous?,How to show Cantor function is uniformly continuous?,,"Cantor function $f$ is defined by $f: \Delta \to [0,1]$ by $$f(\sum_{n=1}^{\infty} \frac{2b_n}{3^n}) = \sum_{n=1}^{\infty} \frac{b_n}{2^n}, b_n \in \{0,1\}$$ , where $\Delta$ is a Cantor set and each $x\in\Delta$ can be written as $x=\sum_{n=1}^{\infty} \frac{2b_n}{3^n}$ , where $b_n = 0$ or $1$ . I read ""Cantor function is uniformly continuous"" on wikipedia https://en.wikipedia.org/wiki/Cantor_function and wiki also claims that it is Holder continuous of exponent $\alpha = \frac {\log2}{\log3}$ . So how to prove it is uniformly continuous and even how to get $\alpha = \frac {\log2}{\log3}$ ?","Cantor function is defined by by , where is a Cantor set and each can be written as , where or . I read ""Cantor function is uniformly continuous"" on wikipedia https://en.wikipedia.org/wiki/Cantor_function and wiki also claims that it is Holder continuous of exponent . So how to prove it is uniformly continuous and even how to get ?","f f: \Delta \to [0,1] f(\sum_{n=1}^{\infty} \frac{2b_n}{3^n}) = \sum_{n=1}^{\infty} \frac{b_n}{2^n}, b_n \in \{0,1\} \Delta x\in\Delta x=\sum_{n=1}^{\infty} \frac{2b_n}{3^n} b_n = 0 1 \alpha = \frac {\log2}{\log3} \alpha = \frac {\log2}{\log3}","['functions', 'continuity', 'uniform-continuity']"
29,How can one determine if a function should have parenthesis around their argument?,How can one determine if a function should have parenthesis around their argument?,,"I have noticed that there are a select few functions that are acceptable if their argument is not in parenthesis. For example, here are a few functions I noted do not require an arguement: Trig or hyperbolic functions: $\sin x,\coth x,\cdots$ The factorial function: $x!$ is an acceptable function of $x$ And logarithms, for example: $\log x$ So I was under the impression that all functions must have parenthesis $\sin (x)$ for example, in my mind, would be the correct notation, and so on. A few functions do actually require parens, like polylogs $\operatorname{Li}_2 x$ is not good. I can't really differentiate when a function must or doesn't need parenthesis around the argument. Thank you.","I have noticed that there are a select few functions that are acceptable if their argument is not in parenthesis. For example, here are a few functions I noted do not require an arguement: Trig or hyperbolic functions: $\sin x,\coth x,\cdots$ The factorial function: $x!$ is an acceptable function of $x$ And logarithms, for example: $\log x$ So I was under the impression that all functions must have parenthesis $\sin (x)$ for example, in my mind, would be the correct notation, and so on. A few functions do actually require parens, like polylogs $\operatorname{Li}_2 x$ is not good. I can't really differentiate when a function must or doesn't need parenthesis around the argument. Thank you.",,['functions']
30,Finding ranks and nullities of linear maps,Finding ranks and nullities of linear maps,,"I am confused about ranks, nullities and bases of the kernel. From what I understand the rank is the dimension of a vector space generated by a matrix. How would I do the following examples? Find the ranks and nullities of the following linear maps $T \colon U \to V$ , and find bases of the kernel and image of $T$ in each case. (i) $U = \mathbb{R}^4$ , $V = \mathbb{R}^4$ , $T(\alpha, \beta, \gamma, \delta) = (\alpha - \gamma, \gamma-\delta, \alpha-\beta, \beta-\delta)$ ; (ii) $U = \mathbb{R}[x]_{\leq 5}$ , $V = \mathbb{R}[x]_{\leq 5}$ (polynomials of degree at most $5$ over $\mathbb{R}$ ), $T(f) = f'''$ (third derivative of $f \in U$ ). ( Source )","I am confused about ranks, nullities and bases of the kernel. From what I understand the rank is the dimension of a vector space generated by a matrix. How would I do the following examples? Find the ranks and nullities of the following linear maps , and find bases of the kernel and image of in each case. (i) , , ; (ii) , (polynomials of degree at most over ), (third derivative of ). ( Source )","T \colon U \to V T U = \mathbb{R}^4 V = \mathbb{R}^4 T(\alpha, \beta, \gamma, \delta) = (\alpha - \gamma, \gamma-\delta, \alpha-\beta, \beta-\delta) U = \mathbb{R}[x]_{\leq 5} V = \mathbb{R}[x]_{\leq 5} 5 \mathbb{R} T(f) = f''' f \in U","['linear-algebra', 'functions', 'vector-spaces']"
31,Find all functions so that $f\left(\frac{x}{f(y)}\right) = \frac{x}{f(x\sqrt{y})}$ [closed],Find all functions so that  [closed],f\left(\frac{x}{f(y)}\right) = \frac{x}{f(x\sqrt{y})},"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I have to find all functions so that $$ f\left(\frac{x}{f(y)}\right) = \frac{x}{f(x\sqrt{y})} $$ I have no idea how to solve this one. Any help would be appreciated!","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I have to find all functions so that $$ f\left(\frac{x}{f(y)}\right) = \frac{x}{f(x\sqrt{y})} $$ I have no idea how to solve this one. Any help would be appreciated!",,['functions']
32,Prove that if $f(x)=a/(x+b)$ then $f((x_1+x_2)/2)\le(f(x_1)+f(x_2))/2$,Prove that if  then,f(x)=a/(x+b) f((x_1+x_2)/2)\le(f(x_1)+f(x_2))/2,This exercise : If  $f(x)=a/(x+b)$ then : $$ f((x_1+x_2)/2)\le(f(x_1)+f(x_2))/2$$ was in my math olympiad today (for 16 years olds).  I proved this by saying this is true due to Jensen's inequality. Is this an acceptable answer?(with leaving aside  the fact that i didn't prove the function is convex since it can't be done with the info we got until now). Does it have any other way of proving this?,This exercise : If  $f(x)=a/(x+b)$ then : $$ f((x_1+x_2)/2)\le(f(x_1)+f(x_2))/2$$ was in my math olympiad today (for 16 years olds).  I proved this by saying this is true due to Jensen's inequality. Is this an acceptable answer?(with leaving aside  the fact that i didn't prove the function is convex since it can't be done with the info we got until now). Does it have any other way of proving this?,,['functions']
33,"Prove that $g'(t)$ vanishes for $t=\frac{3}{2}$ and $2,g(t)$ is maximum when $t=\frac{3}{2}$ and $g(t)$ is minimum at $t=1.$",Prove that  vanishes for  and  is maximum when  and  is minimum at,"g'(t) t=\frac{3}{2} 2,g(t) t=\frac{3}{2} g(t) t=1.","Let $f(x)= \left\{ \begin{array}{lcc}              x+1,  & 0 \leq x \leq 1 \\              \\ 2x^2-6x+6, & 1 < x \leq 2 \\              \\               \end{array}    \right.$ and $g(t)=\int_{t-1}^{t}f(x)dx$ for $t\in[1,2]$ Then prove that $g'(t)$ vanishes for $t=\frac{3}{2}$ and $2,g(t)$ is maximum when $t=\frac{3}{2}$ and $g(t)$ is minimum at $t=1.$ I found $g'(t)=f(t)-f(t-1)$ Put $g'(t)=f(t)-f(t-1)=0$ As $t\in[1,2]$ so $f(t)=2t^2-6t+6$ and as $t-1\in[0,1]$ so $f(t-1)=(t-1)+1=t$ $g'(t)=2t^2-7t+6=0$ gives $t=\frac{3}{2}$ and $2$. $g''(t)=4t-7$ $g''(\frac{3}{2})=-1$,so $g(t)$ is maximum when $t=\frac{3}{2}$ But i do not understand how $g(t)$ is minimum at $t=1.$ Please help me.","Let $f(x)= \left\{ \begin{array}{lcc}              x+1,  & 0 \leq x \leq 1 \\              \\ 2x^2-6x+6, & 1 < x \leq 2 \\              \\               \end{array}    \right.$ and $g(t)=\int_{t-1}^{t}f(x)dx$ for $t\in[1,2]$ Then prove that $g'(t)$ vanishes for $t=\frac{3}{2}$ and $2,g(t)$ is maximum when $t=\frac{3}{2}$ and $g(t)$ is minimum at $t=1.$ I found $g'(t)=f(t)-f(t-1)$ Put $g'(t)=f(t)-f(t-1)=0$ As $t\in[1,2]$ so $f(t)=2t^2-6t+6$ and as $t-1\in[0,1]$ so $f(t-1)=(t-1)+1=t$ $g'(t)=2t^2-7t+6=0$ gives $t=\frac{3}{2}$ and $2$. $g''(t)=4t-7$ $g''(\frac{3}{2})=-1$,so $g(t)$ is maximum when $t=\frac{3}{2}$ But i do not understand how $g(t)$ is minimum at $t=1.$ Please help me.",,"['calculus', 'real-analysis', 'functions']"
34,"Proof of Lipschitz continuity of coordinate map in $C[0,\infty)$",Proof of Lipschitz continuity of coordinate map in,"C[0,\infty)","consider continuous function space $C[0,\infty)$ with metric $$d(\omega_1,\omega_2)=\sum_{n=1}^\infty\frac{1}{2^n}\left[(\sup_{t\in[0,n]}|\omega_1(t)-\omega_2(t)|)\wedge 1\right]$$ where $\omega_1,\omega_2\in C[0,\infty)$ I want to show that for any $t$, the coordinate map $\pi_t(\omega):=\omega(t)$ is Lipschitz continuous. I'm only able to show that $\pi_t$ is continuous without using $\epsilon-\delta$: if $d(\omega_n,\omega)\to 0$, then we can have they converge uniformly in each bounded interval. If not, there exist $n_0$ and $\epsilon\in(0,1)$ such that $\sup_{t\in[0,n_0]}|\omega_n(t)-\omega(t)|\ge \epsilon$,so  $(\sup_{t\in[0,n]}|\omega_n(t)-\omega(t)|)\wedge 1\ge \epsilon$ is true for any $n\ge n_0$. thus we have  $$d(\omega_n,\omega)\ge\sum_{n=n_0}^\infty\frac{1}{2^n}\left[(\sup_{t\in[0,n]}|\omega_n(t)-\omega(t)|)\wedge 1\right]\ge \sum_{n=n_0}^\infty\frac{1}{2^n}\epsilon\ge \frac{\epsilon}{2^{n_0-1}}$$ is a contradiction. then $\omega_n\to\omega$ uniformly in $[0,t]$, $\pi_t(\omega_n)\to\pi_t(\omega)$ in particular. but I can't prove the continuity above using $\epsilon-\delta$ which I think is more rigorous. (if $d(\omega_n,\omega)<\epsilon$, what can we say about $\sup_{t\in[0,N]}|\omega_n(t)-\omega(t)|$? ) moreover , it is actually lipschitz continuous, but I don't know how to get the lipschitz constant. Thanks a lot!","consider continuous function space $C[0,\infty)$ with metric $$d(\omega_1,\omega_2)=\sum_{n=1}^\infty\frac{1}{2^n}\left[(\sup_{t\in[0,n]}|\omega_1(t)-\omega_2(t)|)\wedge 1\right]$$ where $\omega_1,\omega_2\in C[0,\infty)$ I want to show that for any $t$, the coordinate map $\pi_t(\omega):=\omega(t)$ is Lipschitz continuous. I'm only able to show that $\pi_t$ is continuous without using $\epsilon-\delta$: if $d(\omega_n,\omega)\to 0$, then we can have they converge uniformly in each bounded interval. If not, there exist $n_0$ and $\epsilon\in(0,1)$ such that $\sup_{t\in[0,n_0]}|\omega_n(t)-\omega(t)|\ge \epsilon$,so  $(\sup_{t\in[0,n]}|\omega_n(t)-\omega(t)|)\wedge 1\ge \epsilon$ is true for any $n\ge n_0$. thus we have  $$d(\omega_n,\omega)\ge\sum_{n=n_0}^\infty\frac{1}{2^n}\left[(\sup_{t\in[0,n]}|\omega_n(t)-\omega(t)|)\wedge 1\right]\ge \sum_{n=n_0}^\infty\frac{1}{2^n}\epsilon\ge \frac{\epsilon}{2^{n_0-1}}$$ is a contradiction. then $\omega_n\to\omega$ uniformly in $[0,t]$, $\pi_t(\omega_n)\to\pi_t(\omega)$ in particular. but I can't prove the continuity above using $\epsilon-\delta$ which I think is more rigorous. (if $d(\omega_n,\omega)<\epsilon$, what can we say about $\sup_{t\in[0,N]}|\omega_n(t)-\omega(t)|$? ) moreover , it is actually lipschitz continuous, but I don't know how to get the lipschitz constant. Thanks a lot!",,"['real-analysis', 'functions', 'continuity']"
35,Indicator function notation,Indicator function notation,,"Which of the following is correct: $$t \mapsto t\textbf{1}_B(t)$$  or $$ t \mapsto t\textbf{1}_B$$ for some set $B$? Here $\textbf{1}$ denotes the indicator function, and the function I am trying to define equals $t$ when $t\in B$.","Which of the following is correct: $$t \mapsto t\textbf{1}_B(t)$$  or $$ t \mapsto t\textbf{1}_B$$ for some set $B$? Here $\textbf{1}$ denotes the indicator function, and the function I am trying to define equals $t$ when $t\in B$.",,"['functions', 'notation']"
36,Domain of the given function,Domain of the given function,,"A function $y(x)$ is defined as $$ 2^y+2^x=2 $$ The question is about finding it's domain. Pretty simple. By observing the function I could say all the negative numbers are in the domain. But, I think $0$ is included in the domain because the function is defined at $0$ . The text book says $0$ is not included. How is that?","A function $y(x)$ is defined as $$ 2^y+2^x=2 $$ The question is about finding it's domain. Pretty simple. By observing the function I could say all the negative numbers are in the domain. But, I think $0$ is included in the domain because the function is defined at $0$ . The text book says $0$ is not included. How is that?",,['functions']
37,Inverse of an ordered pair?,Inverse of an ordered pair?,,"Let $f: A \to B$ be a bijective function where $A = [0, 2\pi)$ and $B$ is the unit circle. Find the inverse of $f(\theta) = (\cos\theta, \sin\theta)$. I don't understand what it means to take the inverse of an ordered pair. I see that the function is mapping points from the interval $[0, 2\pi)$ to coordinates on the unit circle in $\mathbb{R^2}$ plane, so we have to take those coordinates back into the interval $[0, 2\pi)$. I would guess this involves some two-variable function $f(x,y)$ with inverse functions $\cos^{-1}x$ and $\sin^{-1}x$ since we want the value of the inverse function to be a real number in the interval $[0, 2\pi)$.","Let $f: A \to B$ be a bijective function where $A = [0, 2\pi)$ and $B$ is the unit circle. Find the inverse of $f(\theta) = (\cos\theta, \sin\theta)$. I don't understand what it means to take the inverse of an ordered pair. I see that the function is mapping points from the interval $[0, 2\pi)$ to coordinates on the unit circle in $\mathbb{R^2}$ plane, so we have to take those coordinates back into the interval $[0, 2\pi)$. I would guess this involves some two-variable function $f(x,y)$ with inverse functions $\cos^{-1}x$ and $\sin^{-1}x$ since we want the value of the inverse function to be a real number in the interval $[0, 2\pi)$.",,"['functions', 'trigonometry', 'circles', 'inverse']"
38,"Does every positive rational number appear once and exactly once in the sequence $\{f^n(0)\}$ , where $f(x):=\frac1{2 \lfloor x \rfloor -x+1} $","Does every positive rational number appear once and exactly once in the sequence  , where",\{f^n(0)\} f(x):=\frac1{2 \lfloor x \rfloor -x+1} ,"Consider the map $f:\mathbb Q^+ \to \mathbb Q^+$ defined as $f(x):=\dfrac1{2 \lfloor x \rfloor -x+1} , \forall x \in \mathbb Q^+$ ; then is the function $g:\mathbb Z^+ \to \mathbb Q^+$ defined as $g(n):=f^n(1)=\underbrace{(f \circ f \circ \ldots f}_{n \text{ times}})(1)$ a bijection?  That is, do the iterates of $f()$ hit all positive rationals?","Consider the map $f:\mathbb Q^+ \to \mathbb Q^+$ defined as $f(x):=\dfrac1{2 \lfloor x \rfloor -x+1} , \forall x \in \mathbb Q^+$ ; then is the function $g:\mathbb Z^+ \to \mathbb Q^+$ defined as $g(n):=f^n(1)=\underbrace{(f \circ f \circ \ldots f}_{n \text{ times}})(1)$ a bijection?  That is, do the iterates of $f()$ hit all positive rationals?",,"['elementary-number-theory', 'functions']"
39,What is the symbol you'd use for Boolean results?,What is the symbol you'd use for Boolean results?,,"What I mean is that $\mathbb{CRZ}$ etc. are used for different classes of numbers, allowing me to do stuff like this: $$f:\mathbb{R}\to\mathbb{R}$$ $$f:x\mapsto 3x$$ But say I have an expression like this: $$g:x\mapsto x>4$$ What symbol would you use to represent a boolean result? a $\mathbb B$?","What I mean is that $\mathbb{CRZ}$ etc. are used for different classes of numbers, allowing me to do stuff like this: $$f:\mathbb{R}\to\mathbb{R}$$ $$f:x\mapsto 3x$$ But say I have an expression like this: $$g:x\mapsto x>4$$ What symbol would you use to represent a boolean result? a $\mathbb B$?",,"['functions', 'notation', 'boolean-algebra']"
40,Recursive functions.,Recursive functions.,,"If you have a recursive function  $$g(x) = f(f(x))$$ and you know that $$f(0) = 0, f'(0) = 1, f''(0) = 2$$ Will then $$g(0) = 0, g'(0) = 1, g''(0) = 2$$ ?","If you have a recursive function  $$g(x) = f(f(x))$$ and you know that $$f(0) = 0, f'(0) = 1, f''(0) = 2$$ Will then $$g(0) = 0, g'(0) = 1, g''(0) = 2$$ ?",,"['functions', 'derivatives', 'recursion']"
41,Ideals for commutative ring and equivalent statements,Ideals for commutative ring and equivalent statements,,"I need help solving a problem I have. Let $R$ be a commutative ring. Prove that for the ideals $I$ and $J$ of $R$ the following two conditions are equivalent. (a) The function $R\to R/I\times R/J$ given by $x\to(x+I,x+J)$ , is surjective. (b) $R=I+J$ . My thought for $a\implies b$ have I taken $(c+I,d+J)$ must have some $\alpha$ where $\phi(\alpha)=(\alpha+I,\alpha+J)=(c+I,d+J)$ which gives me that $\alpha-c\in I$ and $\alpha-d\in J$ meaning it is in one of the equivalence classes of the initial, after that I am kinda stuck. For $b\implies a$ I am completely stuck, it feels like to me it shouldn't work but I am not entirely certain how to tackle it. How should I go about solving it?","I need help solving a problem I have. Let be a commutative ring. Prove that for the ideals and of the following two conditions are equivalent. (a) The function given by , is surjective. (b) . My thought for have I taken must have some where which gives me that and meaning it is in one of the equivalence classes of the initial, after that I am kinda stuck. For I am completely stuck, it feels like to me it shouldn't work but I am not entirely certain how to tackle it. How should I go about solving it?","R I J R R\to R/I\times R/J x\to(x+I,x+J) R=I+J a\implies b (c+I,d+J) \alpha \phi(\alpha)=(\alpha+I,\alpha+J)=(c+I,d+J) \alpha-c\in I \alpha-d\in J b\implies a","['abstract-algebra', 'functions', 'ideals']"
42,Continuity of $a^x$ when it's defined by the ordinary way,Continuity of  when it's defined by the ordinary way,a^x,"I've searched for the discussion of proving the continuity of exponential function, in most cases the function is defined by power series or inverse of log function where the log is defined by integration of $1/x$. Does anyone know the prove (or sketch of prove) of $a^x$ being continuous when considered as real values function, where $a^x$ is defined the ordinary way, that is, When $x$ is positive integer, $a^x$ is $a$ multiply x times, $a^{-x}=\frac{1}{a^x}$, $a^{1/x}$ is the unique number $b$ that satisfies $b^x=a$. For general real number r, define $a^r=sup\{a^q, q\in Q, q\leq r\}$","I've searched for the discussion of proving the continuity of exponential function, in most cases the function is defined by power series or inverse of log function where the log is defined by integration of $1/x$. Does anyone know the prove (or sketch of prove) of $a^x$ being continuous when considered as real values function, where $a^x$ is defined the ordinary way, that is, When $x$ is positive integer, $a^x$ is $a$ multiply x times, $a^{-x}=\frac{1}{a^x}$, $a^{1/x}$ is the unique number $b$ that satisfies $b^x=a$. For general real number r, define $a^r=sup\{a^q, q\in Q, q\leq r\}$",,"['calculus', 'real-analysis']"
43,How to prove this version of the Cantor-Schroder-Bernstein theorem?,How to prove this version of the Cantor-Schroder-Bernstein theorem?,,"My text states the Cantor-Schroder-Bernstein theorem as follows: Suppose that $X$ and $Y$ are non-empty sets such that $|X|>|Y|$ . Then, any function $f:X\rightarrow Y$ is not an injection, i.e. there exists distinct elements $x_1$ and $x_2\in X$ such that $f(x_1)=f(x_2)$ My first question is: This version of the theorem is different than what I have seen in other texts, which typically takes this form. How is the theorem stated in my text equivalent to the version stated in the Proofwiki? This looks more like the pigeonhole principle to me (without requiring that $X$ and $Y$ be finite sets). I'd like some help on proving this theorem as stated in my text. What I've tried: I will prove the contrapositive of the theorem, namely: For non empty sets $X$ and $Y$ , if $f:X\rightarrow Y$ is an injection, then $|X|\le |Y|$ So, if $f$ is an injection, then $f$ may or may not be a surjection. If $f$ is also a surjection, then we have a bijection $X\rightarrow Y$ , which means each $X$ and $Y$ can be paired together. Hence, both $X$ and $Y$ have the same cardinality. if $f$ is not surjective, then this means $\exists y \in Y,\forall x\in X,f(x)\ne y$ . This means that there is at least one element in $y$ that can't be paired with an element in $X$ . Hence we conclude that the cardinality of $Y$ is larger that the cardinality of $X$ . Therefore, $|X|\le |Y|$ as required. Is my proof acceptable? I feel a bit uneasy stating that $X$ and $Y$ can or can not be paired, but given the information in the theorem, I don't know of a more precise way to write this proof. EDIT : Asaf Karagila's comment made me reread my text and found the following definition of comparing the cardinalities of two sets: Two sets $X$ and $Y$ have the same cardinality, written $|X|=|Y|$ , if there are equipotent, i.e. there is a bijection $X\rightarrow$ Y. If there is an injection $X\rightarrow Y$ , then we write $|X|\le |Y|$ . We write $|X|<|Y|$ to mean that $|X|\le |Y|$ and $|X|\ne|Y|$ and say that $X$ has smaller cardinality than $Y$ . So, in light of the above definition, the contrapositive of the theorem is true because the definition above makes it true. Is that all there is to it?","My text states the Cantor-Schroder-Bernstein theorem as follows: Suppose that and are non-empty sets such that . Then, any function is not an injection, i.e. there exists distinct elements and such that My first question is: This version of the theorem is different than what I have seen in other texts, which typically takes this form. How is the theorem stated in my text equivalent to the version stated in the Proofwiki? This looks more like the pigeonhole principle to me (without requiring that and be finite sets). I'd like some help on proving this theorem as stated in my text. What I've tried: I will prove the contrapositive of the theorem, namely: For non empty sets and , if is an injection, then So, if is an injection, then may or may not be a surjection. If is also a surjection, then we have a bijection , which means each and can be paired together. Hence, both and have the same cardinality. if is not surjective, then this means . This means that there is at least one element in that can't be paired with an element in . Hence we conclude that the cardinality of is larger that the cardinality of . Therefore, as required. Is my proof acceptable? I feel a bit uneasy stating that and can or can not be paired, but given the information in the theorem, I don't know of a more precise way to write this proof. EDIT : Asaf Karagila's comment made me reread my text and found the following definition of comparing the cardinalities of two sets: Two sets and have the same cardinality, written , if there are equipotent, i.e. there is a bijection Y. If there is an injection , then we write . We write to mean that and and say that has smaller cardinality than . So, in light of the above definition, the contrapositive of the theorem is true because the definition above makes it true. Is that all there is to it?","X Y |X|>|Y| f:X\rightarrow Y x_1 x_2\in X f(x_1)=f(x_2) X Y X Y f:X\rightarrow Y |X|\le |Y| f f f X\rightarrow Y X Y X Y f \exists y \in Y,\forall x\in X,f(x)\ne y y X Y X |X|\le |Y| X Y X Y |X|=|Y| X\rightarrow X\rightarrow Y |X|\le |Y| |X|<|Y| |X|\le |Y| |X|\ne|Y| X Y","['functions', 'elementary-set-theory', 'proof-verification', 'proof-writing']"
44,Bijection between natural numbers $\mathbb{N}$ and natural plane $\mathbb{N} \times \mathbb{N}$ [duplicate],Bijection between natural numbers  and natural plane  [duplicate],\mathbb{N} \mathbb{N} \times \mathbb{N},"This question already has answers here : bijection between $\mathbb{N}$ and $\mathbb{N}\times\mathbb{N}$ [duplicate] (3 answers) Closed 9 years ago . I know that is possible to build a bijection between the set of natural numbers $\mathbb{N}$ and the natural plane (the cartesian product of $\mathbb{N}$ by itself, $\mathbb{N} \times \mathbb{N} = \mathbb{N}^2$. This is done by diagonally traversing the plane from zero upwards with triangles of growing size. Is there a simple algebraic form for that bijection? That is, is it possible to write explicitly some invertible $f(i, j): \mathbb{N} \times \mathbb{N} \leftrightarrow \mathbb{N}$? I need to index in a simple way couples of natural numbers.","This question already has answers here : bijection between $\mathbb{N}$ and $\mathbb{N}\times\mathbb{N}$ [duplicate] (3 answers) Closed 9 years ago . I know that is possible to build a bijection between the set of natural numbers $\mathbb{N}$ and the natural plane (the cartesian product of $\mathbb{N}$ by itself, $\mathbb{N} \times \mathbb{N} = \mathbb{N}^2$. This is done by diagonally traversing the plane from zero upwards with triangles of growing size. Is there a simple algebraic form for that bijection? That is, is it possible to write explicitly some invertible $f(i, j): \mathbb{N} \times \mathbb{N} \leftrightarrow \mathbb{N}$? I need to index in a simple way couples of natural numbers.",,"['elementary-number-theory', 'functions', 'elementary-set-theory']"
45,A constant function,A constant function,,"$f:\mathbb{Z}\to \mathbb{R}$ is bounded above and satisfies  $$f(n)\le \frac{f(n+1)+f(n-1)}{2}$$ Does it follow $f$ is constant ? There was a dreadful typo in the previous question (in the previous question, the domain of $f$ was $\mathbb N$, here, it is $\mathbb Z$), I am posting a new one. Thanks for helping.","$f:\mathbb{Z}\to \mathbb{R}$ is bounded above and satisfies  $$f(n)\le \frac{f(n+1)+f(n-1)}{2}$$ Does it follow $f$ is constant ? There was a dreadful typo in the previous question (in the previous question, the domain of $f$ was $\mathbb N$, here, it is $\mathbb Z$), I am posting a new one. Thanks for helping.",,['functions']
46,Let $f(x)=x \cdot \sqrt {x-1}$ is $f(0)=0$ or $f(0)$ undefined?,Let  is  or  undefined?,f(x)=x \cdot \sqrt {x-1} f(0)=0 f(0),"Let $f(x)=x \cdot \sqrt {x-1}$ Normally, do you consider $f(0)=0$ or undefined? Thanks in advance","Let $f(x)=x \cdot \sqrt {x-1}$ Normally, do you consider $f(0)=0$ or undefined? Thanks in advance",,['functions']
47,Find a continuous function on the reals where $f(x) >0$ and $f'(x) < 0$ and $f''(x) < 0$,Find a continuous function on the reals where  and  and,f(x) >0 f'(x) < 0 f''(x) < 0,We need to find a function $f(x)$ where $f(x) >0 $and $f'(x) < 0$ and $f''(x) < 0$ where $f$ is continuous for all real numbers. We have tried $ f(x) = \sqrt{-x}$ however this is not defined for $x>0$ and therefore is only continuous where $x<0$. Is there even such a function? Because $f$ is positive but decreasing (...increasingly) Any help is appreciated.  Thanks.,We need to find a function $f(x)$ where $f(x) >0 $and $f'(x) < 0$ and $f''(x) < 0$ where $f$ is continuous for all real numbers. We have tried $ f(x) = \sqrt{-x}$ however this is not defined for $x>0$ and therefore is only continuous where $x<0$. Is there even such a function? Because $f$ is positive but decreasing (...increasingly) Any help is appreciated.  Thanks.,,"['calculus', 'functions', 'derivatives', 'continuity']"
48,Concept of a function and Idea of a formula as a function; History of,Concept of a function and Idea of a formula as a function; History of,,"Enderton Elements of Set Theory , p. 43 (1977, Academic Press), writes: There was a reluctance to separate the concept of a function itself from the idea of a written formula defining the function. What is the basis for the above historical claim? And at around what point did the concept of a function itself from the idea of a formula become firmly separated? It seems interesting that what is today regarded as an elementary mistake had a strong historical basis. Fuller quote from Enderton:","Enderton Elements of Set Theory , p. 43 (1977, Academic Press), writes: There was a reluctance to separate the concept of a function itself from the idea of a written formula defining the function. What is the basis for the above historical claim? And at around what point did the concept of a function itself from the idea of a formula become firmly separated? It seems interesting that what is today regarded as an elementary mistake had a strong historical basis. Fuller quote from Enderton:",,['functions']
49,Solution of definite integrals involving incomplete Gamma function,Solution of definite integrals involving incomplete Gamma function,,"The solution of the integral $$\int_0^{\infty}e^{-\beta x}\gamma(\nu,\alpha \sqrt x)dx $$ is given as $$2^{-\frac{1}{2}\nu}\alpha^{\nu}\beta^{\frac{1}{2}\nu-1}\Gamma(\nu)\exp(\frac{\alpha^2}{8\beta})D_{-\nu}(\frac{\alpha}{\sqrt{2\beta}})$$ [Re $\beta>0$, Re $\nu>0$]. I need to calculate the same integral for finite limit such as $0$ to $a$. So how can I calculate $\{\int_0^{a}e^{-\beta x}\gamma(\nu,\alpha \sqrt x)dx\}$. Is there any given form of solution for this definite integration?","The solution of the integral $$\int_0^{\infty}e^{-\beta x}\gamma(\nu,\alpha \sqrt x)dx $$ is given as $$2^{-\frac{1}{2}\nu}\alpha^{\nu}\beta^{\frac{1}{2}\nu-1}\Gamma(\nu)\exp(\frac{\alpha^2}{8\beta})D_{-\nu}(\frac{\alpha}{\sqrt{2\beta}})$$ [Re $\beta>0$, Re $\nu>0$]. I need to calculate the same integral for finite limit such as $0$ to $a$. So how can I calculate $\{\int_0^{a}e^{-\beta x}\gamma(\nu,\alpha \sqrt x)dx\}$. Is there any given form of solution for this definite integration?",,"['integration', 'functions', 'definite-integrals', 'special-functions', 'improper-integrals']"
50,What is the proper way to find the inverse of a function?,What is the proper way to find the inverse of a function?,,"I am a little confused on the subject of inverse functions and the methods used to do the transformation from function to inverse. How do you make an inverse? Just so i can avoid any ambiguity in my question, let's change it to the following: Would anyone on this fantastic website be kind enough to list the steps of ""inversing"", may be the word, the simple function of $$f(x)= \frac{(x-3)}{2}$$","I am a little confused on the subject of inverse functions and the methods used to do the transformation from function to inverse. How do you make an inverse? Just so i can avoid any ambiguity in my question, let's change it to the following: Would anyone on this fantastic website be kind enough to list the steps of ""inversing"", may be the word, the simple function of $$f(x)= \frac{(x-3)}{2}$$",,"['functions', 'inverse']"
51,Formal proof: $f: A \rightarrow B$ is injective if $f$ is surjective and $|A| = |B| <\infty$,Formal proof:  is injective if  is surjective and,f: A \rightarrow B f |A| = |B| <\infty,"Formal proof: $f: A \rightarrow B$ is injective if $f$ is surjective and $|A| = |B| < \infty$ How does one proof formally that $f$ must be injective if the above criterion is satisfied ? Informally it is easy to see $f$ must be injective, since otherwise $\exists a,a^{'} \in A: f(a)=f(a^{'})$, but then there remains $|A| - 2$ elements in $A$, $|B| - 1$ elements in $B$ and $|A| - 2 < |B| - 1$ by the assumption $|A| = |B|$, which in turn implies $f(A - \{a, a^{'}\}) \subsetneq B - \{f(a)\}$ since $|f(A - \{a, a^{'}\})| < |B - \{f(a)\}|$. I guess you will agree this is not a very ""beautiful"" proof and it is probably not very rigorous ? I will be happy to read about your thoughts and ideas. Thanks","Formal proof: $f: A \rightarrow B$ is injective if $f$ is surjective and $|A| = |B| < \infty$ How does one proof formally that $f$ must be injective if the above criterion is satisfied ? Informally it is easy to see $f$ must be injective, since otherwise $\exists a,a^{'} \in A: f(a)=f(a^{'})$, but then there remains $|A| - 2$ elements in $A$, $|B| - 1$ elements in $B$ and $|A| - 2 < |B| - 1$ by the assumption $|A| = |B|$, which in turn implies $f(A - \{a, a^{'}\}) \subsetneq B - \{f(a)\}$ since $|f(A - \{a, a^{'}\})| < |B - \{f(a)\}|$. I guess you will agree this is not a very ""beautiful"" proof and it is probably not very rigorous ? I will be happy to read about your thoughts and ideas. Thanks",,"['elementary-set-theory', 'functions']"
52,"Show there are distinct $\xi,\eta$ s.t. $\frac{a}{f'(\xi)}+\frac{b}{f'(\eta)}=a+b$",Show there are distinct  s.t.,"\xi,\eta \frac{a}{f'(\xi)}+\frac{b}{f'(\eta)}=a+b","Let $f:[0,1]\to\mathbb{R}$ be continuous. Suppose $f$ is differentiable on $(0,1)$ and $f(0)=0,f(1)=1$. Show that for any positive real numbers $a,b$, there are distinct points $\xi,\eta\in(0,1)$ s.t. $$\frac{a}{f'(\xi)}+\frac{b}{f'(\eta)}=a+b$$ The word distinct makes this problem much harder.","Let $f:[0,1]\to\mathbb{R}$ be continuous. Suppose $f$ is differentiable on $(0,1)$ and $f(0)=0,f(1)=1$. Show that for any positive real numbers $a,b$, there are distinct points $\xi,\eta\in(0,1)$ s.t. $$\frac{a}{f'(\xi)}+\frac{b}{f'(\eta)}=a+b$$ The word distinct makes this problem much harder.",,"['calculus', 'functions']"
53,How to prove Cauchy Criterion for limits,How to prove Cauchy Criterion for limits,,"Let $A$ be a nonempty subset of $\mathbb R$ and $f: A\rightarrow \mathbb R$. Suppose $c$ is a cluster point of $A$. Suppose the limit of $f(x)$ at $c$ does not exist. Show that there exists $\varepsilon>0$ and two sequences $(x_n)$ and $(y_n)$ in $A\setminus \{c\}$, both converging to $c$, such that $|f(x_n)-f(y_n)|\geq\varepsilon$ for all $n\in\mathbb N$. limit of $f(x)$ exists if and only if for all $\varepsilon>0$, there exists $\delta>0$ such that if $x,y\in A$ with $0<|x-c|$ ,$|y-c|<\delta$, then $|f(x)-f(y)|<\varepsilon$. I have made some efforts on this but failed. My plan for question 1: the limit of $f(x)$ at $c$ doesn't exist means for every $L$ in $\mathbb R$ there is some $\varepsilon>0$ such that for any $\delta>0$ there is a $x_\delta≠c $ in the $\delta$-neighborhood of $c$ such that $|f(x_\delta)-f(c)|≥\varepsilon$. Then, since we can find an arbitrary sequence $(y_n)$ in $A\setminus \{c\}$ converging to $c$, by letting $L_n=f(y_n)$ and $\delta_n=1/n$, we can find $\varepsilon_n>0$ so that there is a $x_n≠c$ in the $1/n$-neighborhood of c such that $|f(x_n)-f(y_n)|≥\varepsilon_n$. And it also follows that $(x_n)$ converges to c. So we just need to let $\varepsilon=inf${$\varepsilon_1, \varepsilon_2,...,\varepsilon_n,...$}. Here the question comes that I cannot assure $\varepsilon>0$. Can anybody give a hand? Thanks very much!!","Let $A$ be a nonempty subset of $\mathbb R$ and $f: A\rightarrow \mathbb R$. Suppose $c$ is a cluster point of $A$. Suppose the limit of $f(x)$ at $c$ does not exist. Show that there exists $\varepsilon>0$ and two sequences $(x_n)$ and $(y_n)$ in $A\setminus \{c\}$, both converging to $c$, such that $|f(x_n)-f(y_n)|\geq\varepsilon$ for all $n\in\mathbb N$. limit of $f(x)$ exists if and only if for all $\varepsilon>0$, there exists $\delta>0$ such that if $x,y\in A$ with $0<|x-c|$ ,$|y-c|<\delta$, then $|f(x)-f(y)|<\varepsilon$. I have made some efforts on this but failed. My plan for question 1: the limit of $f(x)$ at $c$ doesn't exist means for every $L$ in $\mathbb R$ there is some $\varepsilon>0$ such that for any $\delta>0$ there is a $x_\delta≠c $ in the $\delta$-neighborhood of $c$ such that $|f(x_\delta)-f(c)|≥\varepsilon$. Then, since we can find an arbitrary sequence $(y_n)$ in $A\setminus \{c\}$ converging to $c$, by letting $L_n=f(y_n)$ and $\delta_n=1/n$, we can find $\varepsilon_n>0$ so that there is a $x_n≠c$ in the $1/n$-neighborhood of c such that $|f(x_n)-f(y_n)|≥\varepsilon_n$. And it also follows that $(x_n)$ converges to c. So we just need to let $\varepsilon=inf${$\varepsilon_1, \varepsilon_2,...,\varepsilon_n,...$}. Here the question comes that I cannot assure $\varepsilon>0$. Can anybody give a hand? Thanks very much!!",,"['real-analysis', 'functions']"
54,show that any continuous function can be approximated uniformly,show that any continuous function can be approximated uniformly,,"I do not know where to start because i have not dealt with a question like this before. I feel that i have to use the Stone-Weierstrass theorem, but im not sure how to use it.","I do not know where to start because i have not dealt with a question like this before. I feel that i have to use the Stone-Weierstrass theorem, but im not sure how to use it.",,"['functions', 'approximation']"
55,Set-builder notation function definition,Set-builder notation function definition,,"I know that a function is a subset $f \subseteq X \times Y$ such that \begin{eqnarray} \forall x \in X, \exists ! y \in Y | (x,y) \in f \end{eqnarray} First, is it possible to express what a function is using the set-builder notation? I'm thinking about \begin{eqnarray} f = \{(x,y) | (x \in X) \wedge (\exists ! y \in Y) \wedge ((x,y) \in f)\} \end{eqnarray} Is this correct? Does the recursion (I mean the fact that $f$ is both in the left-hand side of the equality and the right-hand side) give any problem? Another thing I came up with is the following: ""A function $f$ is a member of the set \begin{eqnarray} F = \{f | f \in (X \times Y) \wedge (\forall x \in X) \wedge (\exists ! y \in Y) \wedge ((x,y) \in f)\} \end{eqnarray}"" Can this be taken as a definition of what is a function? Can you give me any reference to a book, site etc. where a set-builder definition of what is a function is given? Another curiosity I have is if those definitions I gave (if correct) have something to do with higher-order logic rather than first-order logic. Thank you, Luca PS. This is my first post so please be kind :)","I know that a function is a subset $f \subseteq X \times Y$ such that \begin{eqnarray} \forall x \in X, \exists ! y \in Y | (x,y) \in f \end{eqnarray} First, is it possible to express what a function is using the set-builder notation? I'm thinking about \begin{eqnarray} f = \{(x,y) | (x \in X) \wedge (\exists ! y \in Y) \wedge ((x,y) \in f)\} \end{eqnarray} Is this correct? Does the recursion (I mean the fact that $f$ is both in the left-hand side of the equality and the right-hand side) give any problem? Another thing I came up with is the following: ""A function $f$ is a member of the set \begin{eqnarray} F = \{f | f \in (X \times Y) \wedge (\forall x \in X) \wedge (\exists ! y \in Y) \wedge ((x,y) \in f)\} \end{eqnarray}"" Can this be taken as a definition of what is a function? Can you give me any reference to a book, site etc. where a set-builder definition of what is a function is given? Another curiosity I have is if those definitions I gave (if correct) have something to do with higher-order logic rather than first-order logic. Thank you, Luca PS. This is my first post so please be kind :)",,"['elementary-set-theory', 'functions', 'definition']"
56,Example of an injective function $g$ and function $f$ such that $g\circ f$ is not injective,Example of an injective function  and function  such that  is not injective,g f g\circ f,"Give an example of a function $g$ which is injective, but for which its composition with $f$ is not, namely $g\circ f$. I suspect that $f(x)=0$ and $g(x)=x$ will do, am I right?","Give an example of a function $g$ which is injective, but for which its composition with $f$ is not, namely $g\circ f$. I suspect that $f(x)=0$ and $g(x)=x$ will do, am I right?",,"['functions', 'elementary-set-theory', 'examples-counterexamples', 'function-and-relation-composition']"
57,Is the statement true?,Is the statement true?,,While working on composition of functions with itself that I have noticed a periodic behavior for f(x). $$f(x)=x^2-1$$ $$f(0)=-1$$ $$f(f(x))=f^2(x)=(x^2-1)^2-1=x^4-2x^2=x^2(x^2-2)$$ $$f^2(0)=0$$ $$f(f(f(x)))=f^3(x)=(x^2-1)^2((x^2-1)^2-2)=(x^2-1)^2(x^4-2x^2-1)$$ $$f^3(0)=-1$$ $$f(f(f(f(x))))=f^4(x)=x^4(x^2-2)^2[(x^2-1)^4-2(x^2-1)^2-1]$$ $$f^4(0)=0$$ I calculated that $f^5(0)=-1$ I could not proceed more because it became  very complex. I suggest that If n is odd then $f^n(0)=-1$ If n is even then $f^n(0)=0$ Can you please help me how I can prove it or disprove the statement above? Thanks EDIT: I have used induction as Stefan mentioned in his answer as hint I proved the statement Proof: $$f^{n+2}(x)=f^{n}(f^{2}(x))$$ $$f^{n+2}(x)=f^{n}(x^2(x^2-2))$$ We got for $x=0$ $$f^{n+2}(0)=f^{n}(0)$$ We know  $$f(0)=-1$$ $$f^{3}(0)=f(0)=-1$$ $$f^{5}(0)=f^3(0)=-1$$ Thus  If n is odd then $f^n(0)=-1$ We know  $$f^2(0)=0$$ $$f^{4}(0)=f^2(0)=0$$ $$f^{6}(0)=f^4(0)=0$$ Thus  If n is even then $f^n(0)=0$ Thanks to Stefan for hint,While working on composition of functions with itself that I have noticed a periodic behavior for f(x). $$f(x)=x^2-1$$ $$f(0)=-1$$ $$f(f(x))=f^2(x)=(x^2-1)^2-1=x^4-2x^2=x^2(x^2-2)$$ $$f^2(0)=0$$ $$f(f(f(x)))=f^3(x)=(x^2-1)^2((x^2-1)^2-2)=(x^2-1)^2(x^4-2x^2-1)$$ $$f^3(0)=-1$$ $$f(f(f(f(x))))=f^4(x)=x^4(x^2-2)^2[(x^2-1)^4-2(x^2-1)^2-1]$$ $$f^4(0)=0$$ I calculated that $f^5(0)=-1$ I could not proceed more because it became  very complex. I suggest that If n is odd then $f^n(0)=-1$ If n is even then $f^n(0)=0$ Can you please help me how I can prove it or disprove the statement above? Thanks EDIT: I have used induction as Stefan mentioned in his answer as hint I proved the statement Proof: $$f^{n+2}(x)=f^{n}(f^{2}(x))$$ $$f^{n+2}(x)=f^{n}(x^2(x^2-2))$$ We got for $x=0$ $$f^{n+2}(0)=f^{n}(0)$$ We know  $$f(0)=-1$$ $$f^{3}(0)=f(0)=-1$$ $$f^{5}(0)=f^3(0)=-1$$ Thus  If n is odd then $f^n(0)=-1$ We know  $$f^2(0)=0$$ $$f^{4}(0)=f^2(0)=0$$ $$f^{6}(0)=f^4(0)=0$$ Thus  If n is even then $f^n(0)=0$ Thanks to Stefan for hint,,"['functions', 'function-and-relation-composition']"
58,How do I solve such logarithm,How do I solve such logarithm,,"I understand that $\log_b n = x \iff b^x = n$ But all examples I see is with values that I naturally know how to calculate (like $2^x = 8, x=3$) What if I don't? For example, how do I solve for $x$ when: $$\log_{1.03} 2 = x\quad ?$$ $$\log_{8} 33 = x\quad ?$$","I understand that $\log_b n = x \iff b^x = n$ But all examples I see is with values that I naturally know how to calculate (like $2^x = 8, x=3$) What if I don't? For example, how do I solve for $x$ when: $$\log_{1.03} 2 = x\quad ?$$ $$\log_{8} 33 = x\quad ?$$",,"['functions', 'logarithms']"
59,Linear transformation invertible or not?,Linear transformation invertible or not?,,"Let $ T:\mathbb{R}^2 \rightarrow \mathbb{R}^2$ be a linear transformation defined such that the inner product of $\langle T(v), v \rangle = 0$ for all $v$ in $\mathbb{R}^2$. Is $T$ invertible or not? Attempt: If $T$ has eigenvalues (i.e., it's characteristic polynomial splits), then $0$ is an eigenvalue. This is because $T(v) = kv$ ($k$ is an eigenvalue). Therefore $\langle Tv, v\rangle  = \langle kv, v\rangle  = k\langle v, v\rangle  = 0$. Since $v$ is anything in $\mathbb{R}^2$, it is not necessarily $0$, which implies $k = 0$. So if a transformation has a $0$ eigenvalue, it is not invertible. If $T$ doesn't have eigenvalues, then it's not injective and thus not invertible. Help! Am I close?","Let $ T:\mathbb{R}^2 \rightarrow \mathbb{R}^2$ be a linear transformation defined such that the inner product of $\langle T(v), v \rangle = 0$ for all $v$ in $\mathbb{R}^2$. Is $T$ invertible or not? Attempt: If $T$ has eigenvalues (i.e., it's characteristic polynomial splits), then $0$ is an eigenvalue. This is because $T(v) = kv$ ($k$ is an eigenvalue). Therefore $\langle Tv, v\rangle  = \langle kv, v\rangle  = k\langle v, v\rangle  = 0$. Since $v$ is anything in $\mathbb{R}^2$, it is not necessarily $0$, which implies $k = 0$. So if a transformation has a $0$ eigenvalue, it is not invertible. If $T$ doesn't have eigenvalues, then it's not injective and thus not invertible. Help! Am I close?",,"['abstract-algebra', 'functions']"
60,"Finding extreme values, intervals of increasing / decreasing.","Finding extreme values, intervals of increasing / decreasing.",,"So, we got a function for example, $y=\dfrac{2x^2}{x+2}$. I have to find extreme values and intervals of increasing (decreasing). So... we start off by finding $f'(x)$. Right.. once we find it, we have to equal it to $0$. So, $f'(x)=0$. Once we find values for $x$ to be $0$, we set our points to be $M_1 (x_1,y_1)$ and $M_2 (x_2,y_2)$ Then we continue to find $y_1$, $y_2$ by replacing the values of $x_1$,$x_2$ we found earlier on the main function. And we get the two points... Ok, I hope I'm doing good so far. Next to do is to find the $f''(x)$. Once we find it, we can see which one is $<0$ and which one is $>0$, for example if, $f''(x_1)>0 - \min ($concave$)$, and if $f''(x)<0 - \max ($convex$)$. Am I doing it right?","So, we got a function for example, $y=\dfrac{2x^2}{x+2}$. I have to find extreme values and intervals of increasing (decreasing). So... we start off by finding $f'(x)$. Right.. once we find it, we have to equal it to $0$. So, $f'(x)=0$. Once we find values for $x$ to be $0$, we set our points to be $M_1 (x_1,y_1)$ and $M_2 (x_2,y_2)$ Then we continue to find $y_1$, $y_2$ by replacing the values of $x_1$,$x_2$ we found earlier on the main function. And we get the two points... Ok, I hope I'm doing good so far. Next to do is to find the $f''(x)$. Once we find it, we can see which one is $<0$ and which one is $>0$, for example if, $f''(x_1)>0 - \min ($concave$)$, and if $f''(x)<0 - \max ($convex$)$. Am I doing it right?",,['functions']
61,Question on functions and derivatives,Question on functions and derivatives,,"I can't seem to get this subject very well. Let $f(x)$ be twice differentiable on $[0,1]$, and that there is a constant $A$ so that $|f''(x)|\le A$. Show that if $f(0)=f(1)=0$, then $|f'(x)|\le {A\over2}$ for all $x\in[0,1]$. Thanks in advance for any help. Would prefer hints please for my learning. Thanks!","I can't seem to get this subject very well. Let $f(x)$ be twice differentiable on $[0,1]$, and that there is a constant $A$ so that $|f''(x)|\le A$. Show that if $f(0)=f(1)=0$, then $|f'(x)|\le {A\over2}$ for all $x\in[0,1]$. Thanks in advance for any help. Would prefer hints please for my learning. Thanks!",,"['calculus', 'functions', 'derivatives']"
62,Does anyone know of any additive periodic functions?,Does anyone know of any additive periodic functions?,,"Does anyone know of any periodic functions satisfying $f(xy)=f(x)+f(y)$ when $\gcd(x,y)=1$. I'm looking for a function other then $1_{d\mid k}$ which is equal to $1$ if $d$ divides $k$ and $0$ if it doesn't.","Does anyone know of any periodic functions satisfying $f(xy)=f(x)+f(y)$ when $\gcd(x,y)=1$. I'm looking for a function other then $1_{d\mid k}$ which is equal to $1$ if $d$ divides $k$ and $0$ if it doesn't.",,"['functions', 'periodic-functions']"
63,"Is shifting a continuous function a ""(pointwise) continuous process""","Is shifting a continuous function a ""(pointwise) continuous process""",,"$\def\R{\mathbb R}$If $f\colon \R\to\R$ is a continuous function and $(x_n)$ is a sequence such that $\lim_{n\to\infty}x_n = 0$, then is it true that the sequence of functions $y_n = f(\cdot+x_n)$ has pointwise limit $f$? Obviously $y_n$ is not a uniform convergent sequence of functions, e.g. $f(x) = x^2$ and take any $(x_n)$ with $x_n\to 0$. I suspect it is true. This one has been bugging me all morning.","$\def\R{\mathbb R}$If $f\colon \R\to\R$ is a continuous function and $(x_n)$ is a sequence such that $\lim_{n\to\infty}x_n = 0$, then is it true that the sequence of functions $y_n = f(\cdot+x_n)$ has pointwise limit $f$? Obviously $y_n$ is not a uniform convergent sequence of functions, e.g. $f(x) = x^2$ and take any $(x_n)$ with $x_n\to 0$. I suspect it is true. This one has been bugging me all morning.",,"['real-analysis', 'functions']"
64,"Suppose I have a function $y=x+1$, then is this function the same as $y=\frac{ x^2+x}{x } $?","Suppose I have a function , then is this function the same as ?",y=x+1 y=\frac{ x^2+x}{x } ,Suppose I have a function $y=x+1$ Then is this funcion the same as $y=\frac{ x^2+x}{x } $ ? The domain of x in the first function is $R$ and in the second function is $x\neq 0$.,Suppose I have a function $y=x+1$ Then is this funcion the same as $y=\frac{ x^2+x}{x } $ ? The domain of x in the first function is $R$ and in the second function is $x\neq 0$.,,['functions']
65,Simple functional equation. Find $f:\mathbb Q\longrightarrow\mathbb Q$ (own),Simple functional equation. Find  (own),f:\mathbb Q\longrightarrow\mathbb Q,"Find the functions $f : \mathbb{Q} \mapsto \mathbb{Q}$ knowing that $$2f\left(f\left(x\right)+f\left(y\right)\right)=f\left(f\left(x+y\right)\right)+x+y,\ \forall x,\ y\in\mathbb{Q}  $$","Find the functions $f : \mathbb{Q} \mapsto \mathbb{Q}$ knowing that $$2f\left(f\left(x\right)+f\left(y\right)\right)=f\left(f\left(x+y\right)\right)+x+y,\ \forall x,\ y\in\mathbb{Q}  $$",,['functions']
66,$|S_X|=|S_Y| \Leftrightarrow |X|=|Y|$,,|S_X|=|S_Y| \Leftrightarrow |X|=|Y|,"Reading this problem I remembered trying to solve the following problem. For a set $A$, denote by $S_A=\{ f : A \to A | f \text{ is bijective }\}$. Denote by $|X|$ the cardinal number of $|X|$. Prove that for two sets $X,Y$ we have $|X|=|Y| \Leftrightarrow |S_X|=|S_Y|$. I didn't manage to solve the case where $X,Y$ are infinite, and don't even know how to start. I tried to represent $X$ as a subset of $Y$( if $|X|<|Y|$) and maybe find a permutation in $S_Y \setminus S_X$.","Reading this problem I remembered trying to solve the following problem. For a set $A$, denote by $S_A=\{ f : A \to A | f \text{ is bijective }\}$. Denote by $|X|$ the cardinal number of $|X|$. Prove that for two sets $X,Y$ we have $|X|=|Y| \Leftrightarrow |S_X|=|S_Y|$. I didn't manage to solve the case where $X,Y$ are infinite, and don't even know how to start. I tried to represent $X$ as a subset of $Y$( if $|X|<|Y|$) and maybe find a permutation in $S_Y \setminus S_X$.",,"['elementary-set-theory', 'functions', 'cardinals', 'symmetric-groups']"
67,Name of property describing the number of times a function changes concavity?,Name of property describing the number of times a function changes concavity?,,"For example, $f(x)=\sin x$ changes concavity an infinite number of times, $f(x)=x^3-x$ has two regions of concavity (changing concavity once), and $f(x)=x$ changes $0$ times. Is there a name for this property?","For example, $f(x)=\sin x$ changes concavity an infinite number of times, $f(x)=x^3-x$ has two regions of concavity (changing concavity once), and $f(x)=x$ changes $0$ times. Is there a name for this property?",,"['calculus', 'functions', 'polynomials', 'terminology']"
68,How to create a one to one correspondence between two sets?,How to create a one to one correspondence between two sets?,,"I am stuck with, Give a one to one correspondence between Z+ and positive even   integers. Now, I don't have an idea how to show that there is a one to one correspondence between the two. I would be thankful for some hints.","I am stuck with, Give a one to one correspondence between Z+ and positive even   integers. Now, I don't have an idea how to show that there is a one to one correspondence between the two. I would be thankful for some hints.",,[]
69,"Prove a monotonic function is linear given its ""integrals are linear""","Prove a monotonic function is linear given its ""integrals are linear""",,"This problem is from the MIT Primes 2023 problem set (it's okay to post now): Let $f : \mathbb R \to \mathbb R$ be a monotonic function. Suppose that $k, l, m, n \in \mathbb R$ with $km \neq 0$ satisfy that for all $y \in \mathbb R$ $$ \int _y^{y+1}f\left(x\right)dx=ky + l \qquad \text{and} \qquad \int _y^{y+\sqrt{2}}f\left(x\right)dx=my+n $$ Prove that $f$ is linear. Here is my partial solution to this: Let $$ F(x) = \int f(x) dx $$ Then \begin{align*} F(y + 1) - F(y) &= ky + l \\ F(y + \sqrt{2}) - F(y) &= my + n \end{align*} Differentiating, we get \begin{align*} f(y + 1) - f(y) &= k \\ f(y + \sqrt{2}) - f(y) &= m \end{align*} This implies $f'(y + 1) = f'(y)$ and $f'(y + \sqrt{2}) = f'(y)$ . In other words $f' : \mathbb R \to \mathbb R$ is a periodic function with periods $1$ and $\sqrt{2}$ , implying that $f'$ is a constant function, which in turn implies that $f$ is linear. As far as I can tell, the issue with my solution is that $f'$ has to be continuous . How might I solve the problem?","This problem is from the MIT Primes 2023 problem set (it's okay to post now): Let be a monotonic function. Suppose that with satisfy that for all Prove that is linear. Here is my partial solution to this: Let Then Differentiating, we get This implies and . In other words is a periodic function with periods and , implying that is a constant function, which in turn implies that is linear. As far as I can tell, the issue with my solution is that has to be continuous . How might I solve the problem?","f : \mathbb R \to \mathbb R k, l, m, n \in \mathbb R km \neq 0 y \in \mathbb R 
\int _y^{y+1}f\left(x\right)dx=ky + l
\qquad \text{and} \qquad
\int _y^{y+\sqrt{2}}f\left(x\right)dx=my+n
 f 
F(x) = \int f(x) dx
 \begin{align*}
F(y + 1) - F(y) &= ky + l \\
F(y + \sqrt{2}) - F(y) &= my + n
\end{align*} \begin{align*}
f(y + 1) - f(y) &= k \\
f(y + \sqrt{2}) - f(y) &= m
\end{align*} f'(y + 1) = f'(y) f'(y + \sqrt{2}) = f'(y) f' : \mathbb R \to \mathbb R 1 \sqrt{2} f' f f'","['calculus', 'integration', 'functions', 'periodic-functions', 'monotone-functions']"
70,Are these numbers always integers?,Are these numbers always integers?,,"Consider the following two alternating sequences: $$ A=\bigg\lbrace f^{(1)1}(x),\cdot\cdot\cdot \bigg \rbrace \bigg|_{x=1/e}=\bigg \lbrace-1,2,-6,32,-320,4452,-70798, \cdot\cdot\cdot \bigg \rbrace$$ $$B=\bigg\lbrace f^{(1)1}(x),\cdot\cdot\cdot \bigg \rbrace \bigg|_{x=e}=\bigg \lbrace-1,10,-150,3088,-81220,2603748, \cdot\cdot\cdot \bigg \rbrace$$ for $f(x)=\exp\bigg(\frac{1}{\log x} \bigg)$ and $f^{(n)n}(x)$ means ""nth derivative of the nth power of $f$ "" and where each term in $A$ is understood to be evaluated at $x=1/e$ , and each term in $B$ is understood to be evaluated at $x=e.$ Are these numbers always even except the first term? Are these numbers always integers? Note that $f^{(4)2}(x)$ evaluated at $x=1/e$ is not integral. So not every combination gives an integral value. I'm not sure why this pattern occurs with the derivatives.","Consider the following two alternating sequences: for and means ""nth derivative of the nth power of "" and where each term in is understood to be evaluated at , and each term in is understood to be evaluated at Are these numbers always even except the first term? Are these numbers always integers? Note that evaluated at is not integral. So not every combination gives an integral value. I'm not sure why this pattern occurs with the derivatives."," A=\bigg\lbrace f^{(1)1}(x),\cdot\cdot\cdot \bigg \rbrace \bigg|_{x=1/e}=\bigg \lbrace-1,2,-6,32,-320,4452,-70798, \cdot\cdot\cdot \bigg \rbrace B=\bigg\lbrace f^{(1)1}(x),\cdot\cdot\cdot \bigg \rbrace \bigg|_{x=e}=\bigg \lbrace-1,10,-150,3088,-81220,2603748, \cdot\cdot\cdot \bigg \rbrace f(x)=\exp\bigg(\frac{1}{\log x} \bigg) f^{(n)n}(x) f A x=1/e B x=e. f^{(4)2}(x) x=1/e","['calculus', 'sequences-and-series', 'elementary-number-theory', 'functions', 'derivatives']"
71,How to find an explicit formula for this function?,How to find an explicit formula for this function?,,"Let us take $$ \mathbb{N} := \{ 1, 2, 3, \ldots \}, $$ and let the function $f \colon \mathbb{N} \longrightarrow \mathbb{N} \times \mathbb{N}$ have the following values: $$ \begin{align}  & f(1) := (1, 1), \\  & f(2) := (1, 2), f(3) := (2, 1), \\ & f(4) := (1, 3), f(5) := (2, 2), f(6) := (3, 1), \\ & f(7) := (1, 4), f(8) := (2, 3), f(9) := (3, 2), f(10) := (4, 1), \\ & f(11) := (1, 5), f(12) := (2, 4), f(13) := (3, 3), f(14) := (4, 2), f(15) := (5, 1), \\ & \ldots.  \end{align} $$ Apparently, this function $f$ is bijective. How to find an explicit formula for this function? How to rigorously show that this function is bijective? I know that the inverse function $f^{-1} \colon \mathbb{N} \times \mathbb{N} \longrightarrow \mathbb{N}$ is given by the formula $$ f^{-1} (m, n) := \frac{ (m+n -2 ) (m + n -1 ) }{2} + m.  $$","Let us take and let the function have the following values: Apparently, this function is bijective. How to find an explicit formula for this function? How to rigorously show that this function is bijective? I know that the inverse function is given by the formula","
\mathbb{N} := \{ 1, 2, 3, \ldots \},
 f \colon \mathbb{N} \longrightarrow \mathbb{N} \times \mathbb{N} 
\begin{align} 
& f(1) := (1, 1), \\ 
& f(2) := (1, 2), f(3) := (2, 1), \\
& f(4) := (1, 3), f(5) := (2, 2), f(6) := (3, 1), \\
& f(7) := (1, 4), f(8) := (2, 3), f(9) := (3, 2), f(10) := (4, 1), \\
& f(11) := (1, 5), f(12) := (2, 4), f(13) := (3, 3), f(14) := (4, 2), f(15) := (5, 1), \\
& \ldots. 
\end{align}
 f f^{-1} \colon \mathbb{N} \times \mathbb{N} \longrightarrow \mathbb{N} 
f^{-1} (m, n) := \frac{ (m+n -2 ) (m + n -1 ) }{2} + m. 
","['functions', 'elementary-set-theory', 'derivation-of-formulae']"
72,"What purpose does the adjective ""monotonically"" serve in the context of a ""monotonically increasing/decreasing function""?","What purpose does the adjective ""monotonically"" serve in the context of a ""monotonically increasing/decreasing function""?",,"Why employ the adjective ""monotonically"" when referring to an ""increasing"" or ""decreasing"" function? Forsooth, if the function is indeed exhibiting an upward or downward trend, it is inherently ""monotonic"". Thus, it would seem that the term ""monotonically"" serves no purpose but to belabor the point, leading one to question its necessity.","Why employ the adjective ""monotonically"" when referring to an ""increasing"" or ""decreasing"" function? Forsooth, if the function is indeed exhibiting an upward or downward trend, it is inherently ""monotonic"". Thus, it would seem that the term ""monotonically"" serves no purpose but to belabor the point, leading one to question its necessity.",,"['functions', 'terminology', 'monotone-functions']"
73,How to solve this functional integral?,How to solve this functional integral?,,"Here is a little integral I made, but I think my solving steps could be flawed: $$\int{f'(x)\cdot f(x)^{\left(\frac{f(x)}{\ln{f(x)}}\right)}dx}$$ for $f(x)>1$ . My solution: using $a^{\frac{1}{\ln(a)}}=e$ , $f(x)^{\left(\frac{f(x)}{\ln{f(x)}}\right)}=e^{f(x)}$ , since $f(x)>1$ (This is where I think I'm wrong) Therefore our integral becomes: $$\int{f'(x)\cdot e^{f(x)}dx}$$ $=e^{f(x)}+C$ Leaving us with a fairly nice answer. However, as mentioned before I feel as if there is something wrong with my first step. Im thinking that you aren't able to use that property with entire functions instead of just constants, right? Is it actually correct? If not, why?","Here is a little integral I made, but I think my solving steps could be flawed: for . My solution: using , , since (This is where I think I'm wrong) Therefore our integral becomes: Leaving us with a fairly nice answer. However, as mentioned before I feel as if there is something wrong with my first step. Im thinking that you aren't able to use that property with entire functions instead of just constants, right? Is it actually correct? If not, why?",\int{f'(x)\cdot f(x)^{\left(\frac{f(x)}{\ln{f(x)}}\right)}dx} f(x)>1 a^{\frac{1}{\ln(a)}}=e f(x)^{\left(\frac{f(x)}{\ln{f(x)}}\right)}=e^{f(x)} f(x)>1 \int{f'(x)\cdot e^{f(x)}dx} =e^{f(x)}+C,"['calculus', 'integration', 'functions', 'indefinite-integrals']"
74,What is the simplest function to generate this curve shape?,What is the simplest function to generate this curve shape?,,"I'm looking for the most straightforward function that generates this shape: The best I've found so far is: $\frac{1}{1+(\frac{x}{\alpha})^\beta}$ , where $\alpha$ is the middle point at which the function moves from 1 to 0 (0.25 in the illustration) and $\beta$ controls how steep is that transition (200 in the illustration). What I don't like about my current solution is that I need to set $\beta$ to a high arbitrary number to get a steep transition, which is what I need for my application. Any suggestions? Thanks! Edit : The function and its derivative need to be continuous.","I'm looking for the most straightforward function that generates this shape: The best I've found so far is: , where is the middle point at which the function moves from 1 to 0 (0.25 in the illustration) and controls how steep is that transition (200 in the illustration). What I don't like about my current solution is that I need to set to a high arbitrary number to get a steep transition, which is what I need for my application. Any suggestions? Thanks! Edit : The function and its derivative need to be continuous.",\frac{1}{1+(\frac{x}{\alpha})^\beta} \alpha \beta \beta,"['functions', 'soft-question']"
75,"Let $f(x)=2\arccos x+4\operatorname{ arccot } x-3x^2-2x+10, x\in[-1,1]$. If $[a,b]$ is the range of $f(x)$, find $4a-b$.","Let . If  is the range of , find .","f(x)=2\arccos x+4\operatorname{ arccot } x-3x^2-2x+10, x\in[-1,1] [a,b] f(x) 4a-b","Question: Let $f(x)=2\arccos x+4\operatorname{ arccot } x-3x^2-2x+10, x\in[-1,1]$ . If $[a,b]$ is the range of $f(x)$ , find $4a-b$ . Method $1:$ $f'(x)=-\frac{2}{\sqrt{1-x^2}}-\frac{4}{1+x^2}-6x-2$ 1st, 2nd and 4th terms are always negative. But not 3rd. Thus, can we say $f'(x)$ is negative? Method $2:$ $\arccos x, \operatorname{ arccot } x, -2x$ are always decreasing. But not $-3x^2$ . Thus, can we say $f(x)$ is decreasing?","Question: Let . If is the range of , find . Method 1st, 2nd and 4th terms are always negative. But not 3rd. Thus, can we say is negative? Method are always decreasing. But not . Thus, can we say is decreasing?","f(x)=2\arccos x+4\operatorname{ arccot } x-3x^2-2x+10, x\in[-1,1] [a,b] f(x) 4a-b 1: f'(x)=-\frac{2}{\sqrt{1-x^2}}-\frac{4}{1+x^2}-6x-2 f'(x) 2: \arccos x, \operatorname{ arccot } x, -2x -3x^2 f(x)","['calculus', 'functions', 'derivatives', 'trigonometry', 'inverse-function']"
76,Proving without using the given condition,Proving without using the given condition,,"Let $f:\;\mathbb R\longmapsto\;\mathbb R$ , $A,B\subset\mathbb R$ . Suppose we have $f(A)\subseteq B$ , then prove (1) $f^{-1}(\overline{A})=\overline{f^{-1}(A)}$ ; (2) $f^{-1}(A \cup B)=f^{-1}(A) \cup f^{-1}(B)$ ; (3) $f^{-1}(A \cap B)=f^{-1}(A) \cap f^{-1}(B)$ . By 357725 , 291777 and 228711 ,  one can  prove the above 3 formulas as follows (1) $$ \begin{aligned} f^{-1}(\overline{A}) &:=\{x \in \operatorname{dom}(f): f(x) \in \overline A \} \\ &=\{x \in \operatorname{dom}(f): f(x) \notin A \} \\ &=: \overline{f^{-1}(A)}. \end{aligned} $$ (2) $$ \begin{aligned} f^{-1}(A \cup B) &:=\{x \in \operatorname{dom}(f): f(x) \in A \cup B\} \\ &=\{x \in \operatorname{dom}(f): f(x) \in A \text { or } f(x) \in B\} \\ &=\{x \in \operatorname{dom}(f): f(x) \in A\} \cup\{x \in \operatorname{dom}(f): f(x) \in B\} \\ &=: f^{-1}(A) \cup f^{-1}(B) . \end{aligned} $$ (3) $$ \begin{aligned} f^{-1}(A \cap B) &:=\{x \in \operatorname{dom}(f): f(x) \in A \cap B\} \\ &=\{x \in \operatorname{dom}(f): f(x) \in A \text { and } f(x) \in B\} \\ &=\{x \in \operatorname{dom}(f): f(x) \in A\} \cap\{x \in \operatorname{dom}(f): f(x) \in B\} \\ &=: f^{-1}(A) \cap f^{-1}(B). \end{aligned} $$ It seems that I prove the processes without using the condition Suppose we have $f(A)\subseteq B$ . Is this condition unnecessary?  Or am I missing something?  A counterexample?","Let , . Suppose we have , then prove (1) ; (2) ; (3) . By 357725 , 291777 and 228711 ,  one can  prove the above 3 formulas as follows (1) (2) (3) It seems that I prove the processes without using the condition Suppose we have . Is this condition unnecessary?  Or am I missing something?  A counterexample?","f:\;\mathbb R\longmapsto\;\mathbb R A,B\subset\mathbb R f(A)\subseteq B f^{-1}(\overline{A})=\overline{f^{-1}(A)} f^{-1}(A \cup B)=f^{-1}(A) \cup f^{-1}(B) f^{-1}(A \cap B)=f^{-1}(A) \cap f^{-1}(B) 
\begin{aligned}
f^{-1}(\overline{A}) &:=\{x \in \operatorname{dom}(f): f(x) \in \overline A \} \\
&=\{x \in \operatorname{dom}(f): f(x) \notin A \} \\
&=: \overline{f^{-1}(A)}.
\end{aligned}
 
\begin{aligned}
f^{-1}(A \cup B) &:=\{x \in \operatorname{dom}(f): f(x) \in A \cup B\} \\
&=\{x \in \operatorname{dom}(f): f(x) \in A \text { or } f(x) \in B\} \\
&=\{x \in \operatorname{dom}(f): f(x) \in A\} \cup\{x \in \operatorname{dom}(f): f(x) \in B\} \\
&=: f^{-1}(A) \cup f^{-1}(B) .
\end{aligned}
 
\begin{aligned}
f^{-1}(A \cap B) &:=\{x \in \operatorname{dom}(f): f(x) \in A \cap B\} \\
&=\{x \in \operatorname{dom}(f): f(x) \in A \text { and } f(x) \in B\} \\
&=\{x \in \operatorname{dom}(f): f(x) \in A\} \cap\{x \in \operatorname{dom}(f): f(x) \in B\} \\
&=: f^{-1}(A) \cap f^{-1}(B).
\end{aligned}
 f(A)\subseteq B","['functions', 'elementary-set-theory']"
77,Notation of functions that take other functions as arguments,Notation of functions that take other functions as arguments,,"With the usual function notation, one denotes functions as $f: A \to B$ , where $A$ and $B$ are sets (see here ), e.g. $f: \mathbb{R} \to \mathbb{R}$ for $f(x) = x^2$ . My question is: What would the notation be if a function $f$ takes another function $g: C \to D$ , where $C$ and $D$ are again sets, as its argument? Would it be $\require{enclose}      \enclose{horizontalstrike}{f: D \to B}$ ? Or $\require{enclose}      \enclose{horizontalstrike}{f: C \to B}$ ? Or something else? I am leaning towards the second option because set $\require{enclose}      \enclose{horizontalstrike}D$ should match set $\require{enclose}      \enclose{horizontalstrike}A$ as the output of function $\require{enclose}      \enclose{horizontalstrike}g$ is the input to $\require{enclose}      \enclose{horizontalstrike}f$ . I am not sure whether this is always the case and whether I am missing something, however. Edit: Matthew Towers is absolutely right, what I was wrongfully thinking of was composition of functions. The question, however, is targeted at a function that takes another function as input and I do not know what the notation would look like in that case.","With the usual function notation, one denotes functions as , where and are sets (see here ), e.g. for . My question is: What would the notation be if a function takes another function , where and are again sets, as its argument? Would it be ? Or ? Or something else? I am leaning towards the second option because set should match set as the output of function is the input to . I am not sure whether this is always the case and whether I am missing something, however. Edit: Matthew Towers is absolutely right, what I was wrongfully thinking of was composition of functions. The question, however, is targeted at a function that takes another function as input and I do not know what the notation would look like in that case.","f: A \to B A B f: \mathbb{R} \to \mathbb{R} f(x) = x^2 f g: C \to D C D \require{enclose}
     \enclose{horizontalstrike}{f: D \to B} \require{enclose}
     \enclose{horizontalstrike}{f: C \to B} \require{enclose}
     \enclose{horizontalstrike}D \require{enclose}
     \enclose{horizontalstrike}A \require{enclose}
     \enclose{horizontalstrike}g \require{enclose}
     \enclose{horizontalstrike}f","['functions', 'notation']"
78,extension Rolle's theorem for limit values,extension Rolle's theorem for limit values,,"Rolle's theorem states that: If a real-valued function $f$ is continuous on a proper closed interval $[a, b]$ , differentiable on the open interval $(a, b)$ , and $f (a) = f (b)$ , then there exists at least one $c$ in the open interval $(a, b)$ such that ${\displaystyle f'(c)=0}$ . Exercise: Show that Rolle's theorem is true in case $f$ is defined and differentiable in the open interval  ] $a, b\left[\right.$ , and $\lim\limits_{x\to a^+}f(x)=\lim\limits_{x\to b^-}f(x)$ . Note that $a$ could be $-\infty$ and $b$ could be $+\infty$ . Furthermore the two limits could also be infinite. My attempt: Let choose $a_1, b_1$ so that $a<a_1<b_1<b$ . Now we have the following cases: $f(a_1)=f(b_1)$ , $f(a_1)<f(b_1)$ or $f(a_1)>f(b_1)$ . When $f(a_1)=f(b_1)$ we can directly apply Rolle's theorem on $]a_1,b_1[$ so $ \exists c \in ]a_1,b_1[$ such that $f′(c)=0$ . If $f(a_1)<f(b_1)$ then there is a real number $z$ such that $f(a_1)<z<f(b_1)$ and by the intermediate value theorem we have $a_2 \in ]a_1,b_1[$ which $f(a_2)=z$ . Now, again we can apply Rolle's theorem to the restriction of $f$ to $[a_2,b_1]$ . The case when $f(a_1)>f(b_1)$ can be done similarly. My question: Is this proof correct or I am missing something? Thank you in advance.","Rolle's theorem states that: If a real-valued function is continuous on a proper closed interval , differentiable on the open interval , and , then there exists at least one in the open interval such that . Exercise: Show that Rolle's theorem is true in case is defined and differentiable in the open interval  ] , and . Note that could be and could be . Furthermore the two limits could also be infinite. My attempt: Let choose so that . Now we have the following cases: , or . When we can directly apply Rolle's theorem on so such that . If then there is a real number such that and by the intermediate value theorem we have which . Now, again we can apply Rolle's theorem to the restriction of to . The case when can be done similarly. My question: Is this proof correct or I am missing something? Thank you in advance.","f [a, b] (a, b) f (a) = f (b) c (a, b) {\displaystyle f'(c)=0} f a, b\left[\right. \lim\limits_{x\to a^+}f(x)=\lim\limits_{x\to b^-}f(x) a -\infty b +\infty a_1, b_1 a<a_1<b_1<b f(a_1)=f(b_1) f(a_1)<f(b_1) f(a_1)>f(b_1) f(a_1)=f(b_1) ]a_1,b_1[  \exists c \in ]a_1,b_1[ f′(c)=0 f(a_1)<f(b_1) z f(a_1)<z<f(b_1) a_2 \in ]a_1,b_1[ f(a_2)=z f [a_2,b_1] f(a_1)>f(b_1)","['real-analysis', 'calculus', 'functions', 'derivatives']"
79,Discontinuity of $b$-Metric,Discontinuity of -Metric,b,"Here I have a definition of $b$ -metric on a set: Let $s \geq 1$ , $X$ is any nonempty set, and $p:X \times X \rightarrow [0,\infty)$ that satisfied $p(x,y)=0$ iff $x=y$ $p(x,y)=p(y,x)$ $p(x,z)\leq s[p(x,y)+p(y,z)]$ for all $x,y,z\in X$ . The function $p$ is called $b$ -metric on $X$ . I have showed that if I have $X = \mathbb{N}\cup\{\infty\}$ and $d: X \times X \rightarrow \mathbb{R}$ where $$d(m,n) = \begin{cases} 		0&,\text{for }m = n\\ 		\left|\dfrac{1}{m} - \dfrac{1}{n}\right|&, \text{ for } m\text{ and } n\text{ are both even or } m\text{ is even and } n=\infty\text{ or}\\  		&\ \ m=\infty\text{ and } n\text{ is even }\\ 		8&, \text{ for } m\text{ and } n\text{ are both odd or } m\text{ is odd and } n=\infty \text{ or }\\  		&\ \ m=\infty\text{ and } n\text{ is odd }\\ 		5&, \text{ others}. 		\end{cases}$$ then $d$ is $b$ -metric on $X$ with $s=3$ , I want to show that $d$ (as function on a metric space) discontinuous at $(\infty,1) \in X \times X$ and this was how I tried to show the discontinuity. Let $f: X\rightarrow\mathbb{R}$ where $f(x) = d(2x,1)$ for all $x\in X$ (the metric I use for $X$ and $\mathbb{R}$ is usual metric). I choose $\varepsilon_0 = 2$ . By Archimedean Properties, for all $N > 0$ we have $m_N \in \mathbb{N}$ such that $N \leq m_N$ . Thus \begin{align*} 		|f(2m_N) - f(\infty)| = {} & |d(2m_N,1) - d(\infty,1)|\\ 		= {} & |5 - 8| = 3 > \varepsilon_0. 		\end{align*} So, $f$ discontinuous at $\infty$ . And intuitively, $d$ discontinuous at $(\infty,1) \in X \times X$ . My question is: Is there any properties I can use such that my intuitive (the last line) is right? Any help is appreciated :(","Here I have a definition of -metric on a set: Let , is any nonempty set, and that satisfied iff for all . The function is called -metric on . I have showed that if I have and where then is -metric on with , I want to show that (as function on a metric space) discontinuous at and this was how I tried to show the discontinuity. Let where for all (the metric I use for and is usual metric). I choose . By Archimedean Properties, for all we have such that . Thus So, discontinuous at . And intuitively, discontinuous at . My question is: Is there any properties I can use such that my intuitive (the last line) is right? Any help is appreciated :(","b s \geq 1 X p:X \times X \rightarrow [0,\infty) p(x,y)=0 x=y p(x,y)=p(y,x) p(x,z)\leq s[p(x,y)+p(y,z)] x,y,z\in X p b X X = \mathbb{N}\cup\{\infty\} d: X \times X \rightarrow \mathbb{R} d(m,n) = \begin{cases}
		0&,\text{for }m = n\\
		\left|\dfrac{1}{m} - \dfrac{1}{n}\right|&, \text{ for } m\text{ and } n\text{ are both even or } m\text{ is even and } n=\infty\text{ or}\\ 
		&\ \ m=\infty\text{ and } n\text{ is even }\\
		8&, \text{ for } m\text{ and } n\text{ are both odd or } m\text{ is odd and } n=\infty \text{ or }\\ 
		&\ \ m=\infty\text{ and } n\text{ is odd }\\
		5&, \text{ others}.
		\end{cases} d b X s=3 d (\infty,1) \in X \times X f: X\rightarrow\mathbb{R} f(x) = d(2x,1) x\in X X \mathbb{R} \varepsilon_0 = 2 N > 0 m_N \in \mathbb{N} N \leq m_N \begin{align*}
		|f(2m_N) - f(\infty)| = {} & |d(2m_N,1) - d(\infty,1)|\\
		= {} & |5 - 8| = 3 > \varepsilon_0.
		\end{align*} f \infty d (\infty,1) \in X \times X","['real-analysis', 'functions', 'metric-spaces']"
80,How to rigorously prove from set theory that functions can be composed?,How to rigorously prove from set theory that functions can be composed?,,This is a follow up to my previous question about existence and uniqueness of piecewise functions. Suppose we are given two functions $f:S \rightarrow T$ and $g:T \rightarrow U$ . How does one prove from ZFC set theory that there is a unique function $h:S \rightarrow U$ which is the composition of those two functions?,This is a follow up to my previous question about existence and uniqueness of piecewise functions. Suppose we are given two functions and . How does one prove from ZFC set theory that there is a unique function which is the composition of those two functions?,f:S \rightarrow T g:T \rightarrow U h:S \rightarrow U,"['functions', 'elementary-set-theory']"
81,How to smooth out 2 corners in a piecewise function?,How to smooth out 2 corners in a piecewise function?,,"I have been experimenting with this a lot, but it eventually proves itself to be trickier than I expected. Let \begin{equation} f(z) =       \begin{cases}         1, &z<0  \\         \frac{1}{2} + \frac{1}{10} \sqrt{25-20z + 20 \sin(\pi z)}, &0<z<1  \\         \frac{1}{2} + \frac{1}{10} \sqrt5, &z>1       \end{cases}     \end{equation} be a piecewise smooth function, smooth everywhere, and differentiable everywhere but $z=0$ and $z=1$ . My idea is to smooth out the ""corners"" possibly by extracting a small domain around them, and replace this with a function g such that f and g can be glued together into a new function H that is everywhere smooth. I would extract a small stripe of width $2\delta$ , for $\delta$ small enough, left and right of $z=0$ , and do the same, left and right of $z=1$ . This would result in: \begin{equation} H(z) =       \begin{cases}         1, &z<-\delta  \\          g_1 (z), &-\delta < z < \delta \\         \frac{1}{2} + \frac{1}{10} \sqrt{25-20z + 20 \sin(\pi z)}, &\delta<z<1-\delta  \\         g_2 (z), &1-\delta < z < 1+\delta \\         \frac{1}{2} + \frac{1}{10} \sqrt5, &z>1+\delta       \end{cases}     \end{equation} so that -finally- $H(z)$ is everywhere smooth. My question is: can someone give me a suitable example for $g_1$ and $g_2$ and preferably explain to me the thinking process? Thanks in advance!","I have been experimenting with this a lot, but it eventually proves itself to be trickier than I expected. Let be a piecewise smooth function, smooth everywhere, and differentiable everywhere but and . My idea is to smooth out the ""corners"" possibly by extracting a small domain around them, and replace this with a function g such that f and g can be glued together into a new function H that is everywhere smooth. I would extract a small stripe of width , for small enough, left and right of , and do the same, left and right of . This would result in: so that -finally- is everywhere smooth. My question is: can someone give me a suitable example for and and preferably explain to me the thinking process? Thanks in advance!","\begin{equation} f(z) =
      \begin{cases}
        1, &z<0  \\
        \frac{1}{2} + \frac{1}{10} \sqrt{25-20z + 20 \sin(\pi z)}, &0<z<1  \\
        \frac{1}{2} + \frac{1}{10} \sqrt5, &z>1
      \end{cases}
    \end{equation} z=0 z=1 2\delta \delta z=0 z=1 \begin{equation} H(z) =
      \begin{cases}
        1, &z<-\delta  \\
         g_1 (z), &-\delta < z < \delta \\
        \frac{1}{2} + \frac{1}{10} \sqrt{25-20z + 20 \sin(\pi z)}, &\delta<z<1-\delta  \\
        g_2 (z), &1-\delta < z < 1+\delta \\
        \frac{1}{2} + \frac{1}{10} \sqrt5, &z>1+\delta
      \end{cases}
    \end{equation} H(z) g_1 g_2","['calculus', 'functions', 'derivatives', 'smooth-functions', 'piecewise-continuity']"
82,Help proving $\lim_{h \to 0} \int_{1}^{5} f(x+h)dx = \int_{1}^{5}f(x)dx$,Help proving,\lim_{h \to 0} \int_{1}^{5} f(x+h)dx = \int_{1}^{5}f(x)dx,"Suppose a function $f$ is integrable on $[0,6]$ . Prove that $$\lim_{h \to 0} \int_{1}^{5} f(x+h)dx = \int_{1}^{5}f(x)dx$$ This seems like the easiest thing, I would normally just bring the limit inside the integral and evaluate $f(x+h)$ to $f(x)$ , but its asking to prove that this is the case and I haven't even used the fact that its integrable on $[0,6]$ . I tried the epsilon delta proof this way. Let $\epsilon > 0$ and assume $$\left|\int_{1}^{5}f(x+h)dx - \int_{1}^{5}f(x)dx\right| < \epsilon$$ I tried to find a $\delta$ so that $|f(x+h)-f(x)| < \delta$ , but had no luck. Any help would be appreciated.","Suppose a function is integrable on . Prove that This seems like the easiest thing, I would normally just bring the limit inside the integral and evaluate to , but its asking to prove that this is the case and I haven't even used the fact that its integrable on . I tried the epsilon delta proof this way. Let and assume I tried to find a so that , but had no luck. Any help would be appreciated.","f [0,6] \lim_{h \to 0} \int_{1}^{5} f(x+h)dx = \int_{1}^{5}f(x)dx f(x+h) f(x) [0,6] \epsilon > 0 \left|\int_{1}^{5}f(x+h)dx - \int_{1}^{5}f(x)dx\right| < \epsilon \delta |f(x+h)-f(x)| < \delta","['calculus', 'integration', 'functions']"
83,How to extracting formula from a number sequence,How to extracting formula from a number sequence,,"I have following sequence: | Term  | Value | |-------+-------+ | 0     | 0     | | 1     | 1     | | 2     | 2     | | 3     | 2     | | 4     | 3     | | 5     | 3     | | 6     | 3     | | 7     | 3     | and so on... which the relation is T(n)=T(floor(n/2))+1, T(0)=0 , I am wondering how to extract the exact function of it.","I have following sequence: | Term  | Value | |-------+-------+ | 0     | 0     | | 1     | 1     | | 2     | 2     | | 3     | 2     | | 4     | 3     | | 5     | 3     | | 6     | 3     | | 7     | 3     | and so on... which the relation is T(n)=T(floor(n/2))+1, T(0)=0 , I am wondering how to extract the exact function of it.",,"['functions', 'recurrence-relations']"
84,Find all functions $f$ such that $f(mn) = f(m)f(n)$ and...,Find all functions  such that  and...,f f(mn) = f(m)f(n),"Find all functions $f : N → N$ such that (a) $f(2) = 2$ (b) $f(mn) = f(m)f(n)$ for all $m, n ∈ N$ (c) $f(m) < f(n)$ for $m < n$ First, I substituted $m=1,n=2$ to get $f(1)=1$ . Next, we can easily notice that all powers of $2$ will be equal to themselves. That is $f(4)=4,f(8)=8$ , and so on. Now, the next step I'm not so sure is correct. As $f(4)>f(3)>f(2)$ , and $f : N → N$ , I think $f(3)$ can only be $3$ but again I'm not so sure. If it is so, then I believe the only possible function is $f(x)=x$ . Now for the next part of the problem- What happens if the third condition is not given to us? Unfortunately I don't even have the answer to the problem let alone a solution. Any hints would also be helpful, thanks.","Find all functions such that (a) (b) for all (c) for First, I substituted to get . Next, we can easily notice that all powers of will be equal to themselves. That is , and so on. Now, the next step I'm not so sure is correct. As , and , I think can only be but again I'm not so sure. If it is so, then I believe the only possible function is . Now for the next part of the problem- What happens if the third condition is not given to us? Unfortunately I don't even have the answer to the problem let alone a solution. Any hints would also be helpful, thanks.","f : N → N f(2) = 2 f(mn) = f(m)f(n) m, n ∈ N f(m) < f(n) m < n m=1,n=2 f(1)=1 2 f(4)=4,f(8)=8 f(4)>f(3)>f(2) f : N → N f(3) 3 f(x)=x","['functions', 'discrete-mathematics', 'contest-math', 'functional-equations']"
85,"Bijection between the power set of $\mathbb{Z}_+$ and the set of all infinite sequences $(x_n)_{n=1}^\infty$ with $x_n\in\{0,1\}$",Bijection between the power set of  and the set of all infinite sequences  with,"\mathbb{Z}_+ (x_n)_{n=1}^\infty x_n\in\{0,1\}","Proposition. There is a bijective correspondence between $\mathscr P{(\mathbb{Z_+})}$ , the power set of $\mathbb{Z_+}$ , and $X^\omega$ , the set of all infinite sequences of elements of $X$ , where $X=\{0,1\}$ . ( Source: Munkres Topology 7.3) Proof Let $f: \mathscr P{(\mathbb{Z_+})} \to X^\omega$ . Define $f(A) = (x_i)_{i\in\mathbb{Z_+}}$ , for $A \in \mathscr P{(\mathbb{Z_+})}$ , such that if $i \in A$ , $x_i = 1$ , otherwise $x_i = 0$ . We first show $f$ is an injection.  Suppose $A,A' \in \mathscr P{(\mathbb{Z_+})}$ such that $A=A'$ . It follows that $A,A' \subset \mathbb{Z_+}$ . Consider $f(A)$ and $f(A')$ .  Then $f(A) = x \in X^\omega$ and $f(A') = x^{'} \in X^\omega$ .  By definition of $X^\omega$ , $x = (x_i)_{i\in\mathbb{Z_+}}$ and $x^{'} = (x^{'}_i)_{i\in\mathbb{Z_+}}$ for $x_i$ , $x^{'}_i \in X$ . It follows from the definition of $f$ , that $\forall j\in\mathbb{Z_+}$ , if $j\in A$ , then $x_j = 1$ . Since $A = A'$ by assumption, $\forall j\in A$ , $j\in A'$ and $x^{'}_j = 1$ .  Hence $\forall j\in \mathbb{Z_+} \cap A = \mathbb{Z_+} \cap A^{'}$ , $x_j = 1 = x^{'}_j$ .  Further, $\forall j\in \mathbb{Z_+} - A = \mathbb{Z_+} - A^{'}$ , $x_j = 0 = x^{'}_j$ .  Thus $\forall j\in\mathbb{Z_+}$ , $x_j = x^{'}_j$ .  Hence, $x = x^{'}$ .  Therefore, $f$ is an injection. To show $f$ is a surjection, arbitrarily choose $x \in X^\omega$ .  Then $x = (x_i)_{\mathbb{i\in Z_+}}$ , such that each $x_i\in X = \{0,1\}$ .  Construct a set $A$ , as follows.For each $i\in \mathbb{Z_+}$ , if $x_i=1$ , let $i$ be an element of $A$ .  Whether empty or not, $A \subset \mathbb{Z_+}$ .  Thus $A \in\mathscr{P(\mathbb{Z_+})}$ .  Hence $\forall x\in X^\omega$ , $\exists A\in\mathscr{P(\mathbb{Z_+})}$ , such that $x = f(A)$ .  Therefore, $f$ is a surjection. We have show there exists a bijective correspondence between $\mathscr P{(\mathbb{Z_+})}$ and $X^\omega$ . Question I would appreciate a verification of this proof.  Also, is there a better way to notate the definition of $f$ above.","Proposition. There is a bijective correspondence between , the power set of , and , the set of all infinite sequences of elements of , where . ( Source: Munkres Topology 7.3) Proof Let . Define , for , such that if , , otherwise . We first show is an injection.  Suppose such that . It follows that . Consider and .  Then and .  By definition of , and for , . It follows from the definition of , that , if , then . Since by assumption, , and .  Hence , .  Further, , .  Thus , .  Hence, .  Therefore, is an injection. To show is a surjection, arbitrarily choose .  Then , such that each .  Construct a set , as follows.For each , if , let be an element of .  Whether empty or not, .  Thus .  Hence , , such that .  Therefore, is a surjection. We have show there exists a bijective correspondence between and . Question I would appreciate a verification of this proof.  Also, is there a better way to notate the definition of above.","\mathscr P{(\mathbb{Z_+})} \mathbb{Z_+} X^\omega X X=\{0,1\} f: \mathscr P{(\mathbb{Z_+})} \to X^\omega f(A) = (x_i)_{i\in\mathbb{Z_+}} A \in \mathscr P{(\mathbb{Z_+})} i \in A x_i = 1 x_i = 0 f A,A' \in \mathscr P{(\mathbb{Z_+})} A=A' A,A' \subset \mathbb{Z_+} f(A) f(A') f(A) = x \in X^\omega f(A') = x^{'} \in X^\omega X^\omega x = (x_i)_{i\in\mathbb{Z_+}} x^{'} = (x^{'}_i)_{i\in\mathbb{Z_+}} x_i x^{'}_i \in X f \forall j\in\mathbb{Z_+} j\in A x_j = 1 A = A' \forall j\in A j\in A' x^{'}_j = 1 \forall j\in \mathbb{Z_+} \cap A = \mathbb{Z_+} \cap A^{'} x_j = 1 = x^{'}_j \forall j\in \mathbb{Z_+} - A = \mathbb{Z_+} - A^{'} x_j = 0 = x^{'}_j \forall j\in\mathbb{Z_+} x_j = x^{'}_j x = x^{'} f f x \in X^\omega x = (x_i)_{\mathbb{i\in Z_+}} x_i\in X = \{0,1\} A i\in \mathbb{Z_+} x_i=1 i A A \subset \mathbb{Z_+} A \in\mathscr{P(\mathbb{Z_+})} \forall x\in X^\omega \exists A\in\mathscr{P(\mathbb{Z_+})} x = f(A) f \mathscr P{(\mathbb{Z_+})} X^\omega f","['sequences-and-series', 'functions', 'elementary-set-theory', 'solution-verification']"
86,Composite function. Textbook answer incorrect?,Composite function. Textbook answer incorrect?,,"I am practicing composite functions and I can't get the same answer as the back of the textbook but I am confident in my calculations which leads me to believe the book is wrong. Question Let a be a positive number, $f:[2,\infty)\rightarrow \mathbb{R}, f(x)=a-x $ and let $g:(-\infty,1]\rightarrow\mathbb{R}, g(x)=x^2+a$ . Find all values of $a$ for which both $f\circ g$ and $g\circ f$ exist. My attempt I know for $g\circ f$ , $Ran$ $f$ must be a subset of $dom$ $g$ and for $f\circ g$ , $Ran$ $g$ must be a subset of $dom$ $f$ therefore: $dom$ $g= (-\infty,1]$ and $Ran$ $f=(-\infty, a-2]$ $dom$ $f= [2,\infty)$ and $Ran$ $g=[1+a,\infty)$ When I solve I am left with: $a-2 \leq 1 $ and; $1+a \geq 2 $ Therefore $a \in [1,3]$ The solution in the textbook shows the answer to be $a \in [2,3]$ Can someone please help me out. Am I correct or is the textbook correct? If I have made an error can you please help me solve this. Thank you","I am practicing composite functions and I can't get the same answer as the back of the textbook but I am confident in my calculations which leads me to believe the book is wrong. Question Let a be a positive number, and let . Find all values of for which both and exist. My attempt I know for , must be a subset of and for , must be a subset of therefore: and and When I solve I am left with: and; Therefore The solution in the textbook shows the answer to be Can someone please help me out. Am I correct or is the textbook correct? If I have made an error can you please help me solve this. Thank you","f:[2,\infty)\rightarrow \mathbb{R}, f(x)=a-x  g:(-\infty,1]\rightarrow\mathbb{R}, g(x)=x^2+a a f\circ g g\circ f g\circ f Ran f dom g f\circ g Ran g dom f dom g= (-\infty,1] Ran f=(-\infty, a-2] dom f= [2,\infty) Ran g=[1+a,\infty) a-2 \leq 1  1+a \geq 2  a \in [1,3] a \in [2,3]","['calculus', 'functions', 'relations', 'function-and-relation-composition']"
87,Proof verification for exercise 3.5.2 in Tao's Analysis I: Prove that the generalized definition of a Cartesian product is a set,Proof verification for exercise 3.5.2 in Tao's Analysis I: Prove that the generalized definition of a Cartesian product is a set,,"The second portion of Exercise 3.5.2 in Tao's Analysis I reads as follows: Suppose we define an ordered $n$ -tuple to be a surjective function $x:\{i \in \mathbb N : 1 \leq i \leq n \} \to X$ whose range is some arbitrary set $X$ (so different ordered $n$ -tuples are allowed to have different ranges); we then write $x_i$ for $x(i)$ , and also write $x$ as $(x_i)_{1 \leq i \leq n}$ . Show that if $(X_i)_{1 \leq i \leq n}$ are an ordered $n$ -tuple of sets, then the Cartesian product, as defined in Definition 3.5.7, is indeed a set. (Hint: use exercise 3.4.7 and the axiom of specification. Definition 3.5.7 : $\prod\limits_{1\leq i \leq n } X_i :=\{(x_i)_{1\leq i \leq n}:x_i \in X_i \text{ for all } 1 \leq i \leq n \}$ . Conclusion of Exercise 3.4.7 (proven earlier): The collection of all partial functions from $X$ to $Y$ is itself a set. Here, a partial function from $X$ to $Y$ is defined as any function $f: X' \to Y'$ whose domain $X'$ is a subset of $X$ and whose range $Y'$ is a subset of $Y$ . Axiom of Specification : Let $A$ be a set, and for each $x \in A$ , let $P(x)$ be a property pertaining to $x$ . Then there exists a set, called $\{x \in A: P(x) \text{ is true}\}$ whose elements are precisely the elements $x$ in $A$ for which $P(x)$ is true. I am seeking clarification regarding the validity of my proof. I also invoked the Axiom of Union , which Tao states as follows: Let $A$ be a set, all of whose elements are themselves sets. Then there exists a set $\bigcup A$ whose elements are precisely those objects which are elements of the elements of $A$ . Here is the proof: Assume there exists a set $\mathbb W = \{A,B,C,D,...\}$ Let $X$ be a function defined as $X:\{1,2,...,n\} \to \mathbb W$ . Therefore, as a hypothetical example, $X_1 = A$ , $X_2 =D$ , etc. (Here, $X_1=A$ can be interpreted to mean $X(1)=A$ ...i.e. $X$ is mapping the element $1$ to the set $A$ ) Consider the overarching domain and codomain: $ \mathbb N \to \bigcup \mathbb W$ . Let $\Psi ': \{1,2,...,n\} \to Y'$ where $Y' \subseteq \bigcup \mathbb W$ and, obviously, $\{1,2,...,n\} \subseteq \mathbb N$ . Clearly, $\Psi'$ is a partial function from $ \mathbb N \to \bigcup \mathbb W$ . Let $\Omega$ be the set of all partial functions, of which $\Psi'$ is certainly a member. (This set exists by exercise 3.4.7) Now, let's further equip $\Psi'$ with some arbitrary (but strategic) mapping rule of the following form: $\Psi': 1 \mapsto a' \in X_1$ , $\Psi': 2 \mapsto b' \in X_2$ , $\Psi': 3 \mapsto c' \in X_3$ , ... etc. In line with Tao's notation, we would say $\Psi'_1 = \Psi' (1) = a'$ . We can imagine that there are many other partial functions in $\Omega$ that share a similar mapping strategy to $\Psi'$ . For example, $\Psi'': \{1,2,...,n\} \to Y''$ where $\Psi'': 1 \mapsto a'' \in X_1$ , $\Psi'': 2 \mapsto b'' \in X_2$ , $\Psi'': 3 \mapsto c'' \in X_3$ , ... etc. It is apparent that $\Psi'$ (and its other variants) are behaving like the ordered $n$ -tuple function $(x_i)_{1 \leq i \leq n}$ that Tao described earlier. Therefore, using the Axiom of Specification , we can hand pick these functions from $\Omega$ and form a set out of them: $\{\Psi:\Psi \in \Omega\ \text { and }\forall i \text { such that  } 1 \leq i \leq n \ \Psi_i \in X_i \}$ My claim is that this is identical to the Cartesian set definition and therefore I have demonstrated that this is, indeed, a set. Any critiques would be greatly appreciated! Cheers~","The second portion of Exercise 3.5.2 in Tao's Analysis I reads as follows: Suppose we define an ordered -tuple to be a surjective function whose range is some arbitrary set (so different ordered -tuples are allowed to have different ranges); we then write for , and also write as . Show that if are an ordered -tuple of sets, then the Cartesian product, as defined in Definition 3.5.7, is indeed a set. (Hint: use exercise 3.4.7 and the axiom of specification. Definition 3.5.7 : . Conclusion of Exercise 3.4.7 (proven earlier): The collection of all partial functions from to is itself a set. Here, a partial function from to is defined as any function whose domain is a subset of and whose range is a subset of . Axiom of Specification : Let be a set, and for each , let be a property pertaining to . Then there exists a set, called whose elements are precisely the elements in for which is true. I am seeking clarification regarding the validity of my proof. I also invoked the Axiom of Union , which Tao states as follows: Let be a set, all of whose elements are themselves sets. Then there exists a set whose elements are precisely those objects which are elements of the elements of . Here is the proof: Assume there exists a set Let be a function defined as . Therefore, as a hypothetical example, , , etc. (Here, can be interpreted to mean ...i.e. is mapping the element to the set ) Consider the overarching domain and codomain: . Let where and, obviously, . Clearly, is a partial function from . Let be the set of all partial functions, of which is certainly a member. (This set exists by exercise 3.4.7) Now, let's further equip with some arbitrary (but strategic) mapping rule of the following form: , , , ... etc. In line with Tao's notation, we would say . We can imagine that there are many other partial functions in that share a similar mapping strategy to . For example, where , , , ... etc. It is apparent that (and its other variants) are behaving like the ordered -tuple function that Tao described earlier. Therefore, using the Axiom of Specification , we can hand pick these functions from and form a set out of them: My claim is that this is identical to the Cartesian set definition and therefore I have demonstrated that this is, indeed, a set. Any critiques would be greatly appreciated! Cheers~","n x:\{i \in \mathbb N : 1 \leq i \leq n \} \to X X n x_i x(i) x (x_i)_{1 \leq i \leq n} (X_i)_{1 \leq i \leq n} n \prod\limits_{1\leq i \leq n } X_i :=\{(x_i)_{1\leq i \leq n}:x_i \in X_i \text{ for all } 1 \leq i \leq n \} X Y X Y f: X' \to Y' X' X Y' Y A x \in A P(x) x \{x \in A: P(x) \text{ is true}\} x A P(x) A \bigcup A A \mathbb W = \{A,B,C,D,...\} X X:\{1,2,...,n\} \to \mathbb W X_1 = A X_2 =D X_1=A X(1)=A X 1 A  \mathbb N \to \bigcup \mathbb W \Psi ': \{1,2,...,n\} \to Y' Y' \subseteq \bigcup \mathbb W \{1,2,...,n\} \subseteq \mathbb N \Psi'  \mathbb N \to \bigcup \mathbb W \Omega \Psi' \Psi' \Psi': 1 \mapsto a' \in X_1 \Psi': 2 \mapsto b' \in X_2 \Psi': 3 \mapsto c' \in X_3 \Psi'_1 = \Psi' (1) = a' \Omega \Psi' \Psi'': \{1,2,...,n\} \to Y'' \Psi'': 1 \mapsto a'' \in X_1 \Psi'': 2 \mapsto b'' \in X_2 \Psi'': 3 \mapsto c'' \in X_3 \Psi' n (x_i)_{1 \leq i \leq n} \Omega \{\Psi:\Psi \in \Omega\ \text { and }\forall i \text { such that  } 1 \leq i \leq n \ \Psi_i \in X_i \}","['functions', 'set-theory', 'solution-verification']"
88,"Why do mathematicians say ""map"" and ""mapping"" when talking about functions?","Why do mathematicians say ""map"" and ""mapping"" when talking about functions?",,"I don't know if this is the right place to ask this, but I realized I've been using the word ""map"" to mean ""function"" for some time now and I have no idea why. When did people start using ""map"" this way, and how is it connected to the usual meaning of ""map"" (a visual representation of an area)? The only thing I can think is that charts on a manifold are very much like maps in the traditional sense, but most functions aren't manifold charts.","I don't know if this is the right place to ask this, but I realized I've been using the word ""map"" to mean ""function"" for some time now and I have no idea why. When did people start using ""map"" this way, and how is it connected to the usual meaning of ""map"" (a visual representation of an area)? The only thing I can think is that charts on a manifold are very much like maps in the traditional sense, but most functions aren't manifold charts.",,"['functions', 'terminology', 'math-history']"
89,"Finding $x$, $y$ that minimize $(\frac{\sqrt3\sin y}{\sqrt2\sin(x+y)}+1)(\frac{\sqrt2\sin x}{3\sin y}+1)^2(\frac{\sin(x+y)}{7\sqrt3\sin x}+1)^4$","Finding ,  that minimize",x y (\frac{\sqrt3\sin y}{\sqrt2\sin(x+y)}+1)(\frac{\sqrt2\sin x}{3\sin y}+1)^2(\frac{\sin(x+y)}{7\sqrt3\sin x}+1)^4,"This problem was given in 2018 in the entrance exams for MSU(8th problem). The only information online about the exam is its answers and is supposedly aimed at highschool students. I am in a maths-oriented high school so we are studying what we would in the 1st year in uni. The problem is: Find all pairs of $x,y \in (0;\frac{\pi}{2}) $ where $f(x,y) = f_{min}$ . (When is this equal to its minimum value) $$ f(x,y) =   \left(\frac{\sqrt3\sin y} {\sqrt2\sin(x+y)} + 1\right)\left(\frac{\sqrt2\sin x}{3\sin y} + 1\right)^2\left( \frac{\sin(x+y)}{7\sqrt3\sin x} + 1\right)^4  $$ I only want a starting point, how do I approach this? Derivatives? Or do the (...)^4 ?","This problem was given in 2018 in the entrance exams for MSU(8th problem). The only information online about the exam is its answers and is supposedly aimed at highschool students. I am in a maths-oriented high school so we are studying what we would in the 1st year in uni. The problem is: Find all pairs of where . (When is this equal to its minimum value) I only want a starting point, how do I approach this? Derivatives? Or do the (...)^4 ?","x,y \in (0;\frac{\pi}{2})  f(x,y) = f_{min}  f(x,y) =   \left(\frac{\sqrt3\sin y} {\sqrt2\sin(x+y)} + 1\right)\left(\frac{\sqrt2\sin x}{3\sin y} + 1\right)^2\left( \frac{\sin(x+y)}{7\sqrt3\sin x} + 1\right)^4  ","['functions', 'trigonometry']"
90,Always increasing condition of a function,Always increasing condition of a function,,"In a classroom I was told today that the function is always increasing if $f'(X)\ge0$ . Interestingly my teacher took a function as $f(x)=x^3+3x^2+3x+5$ which is always increasing although at $x=-1$ , derivative will be zero. Now this equal to zero disturbed me a lot. Suppose there is a function which is increasing and then for some continuous interval it gets constant and after that interval it again starts increasing. Now $f'(x)\ge0$ will be satisfied in such a case, but is such a function always increasing, obviously its no. I tried to google it but couldn't find such a case. What am I missing here?","In a classroom I was told today that the function is always increasing if . Interestingly my teacher took a function as which is always increasing although at , derivative will be zero. Now this equal to zero disturbed me a lot. Suppose there is a function which is increasing and then for some continuous interval it gets constant and after that interval it again starts increasing. Now will be satisfied in such a case, but is such a function always increasing, obviously its no. I tried to google it but couldn't find such a case. What am I missing here?",f'(X)\ge0 f(x)=x^3+3x^2+3x+5 x=-1 f'(x)\ge0,"['calculus', 'functions', 'derivatives']"
91,Is it possible to express this property in a compact way?,Is it possible to express this property in a compact way?,,"If $f_{a}: \mathbb{R} \to \mathbb{R}$ for all $a \in \mathbb{R}$ , and if there is some $x \in \mathbb{R}$ such that $f_{a}(x) \leq f_{a}(y)$ for all $y \in \mathbb{R}$ and all $a \in \mathbb{R}$ , I am after a compact way to express this property of $x$ , preferably in terms of argmax or argmin. Taking argmin $_{y, a}f_{a}(y)$ certainly gives an undesired result (for the unwanted additional argument).","If for all , and if there is some such that for all and all , I am after a compact way to express this property of , preferably in terms of argmax or argmin. Taking argmin certainly gives an undesired result (for the unwanted additional argument).","f_{a}: \mathbb{R} \to \mathbb{R} a \in \mathbb{R} x \in \mathbb{R} f_{a}(x) \leq f_{a}(y) y \in \mathbb{R} a \in \mathbb{R} x _{y, a}f_{a}(y)","['functions', 'soft-question', 'maxima-minima']"
92,"Name for a ""location"" property of a function","Name for a ""location"" property of a function",,"Let $L$ be an operator that maps any well-behaved (with bounded integral) function $f:\mathbb{R} \rightarrow\mathbb{R}$ to a number $L_f\in\mathbb{R}$ , such that if $g(x)=f(x-d)$ for all $x\in\mathbb{R}$ , then $L_g=L_f+d$ . Subject to the above condition, $L_f$ could be, for example: the centroid $\frac{\int_{-\infty}^\infty xf(x)dx}{\int_{-\infty}^\infty f(x)dx}$ $\inf \arg \max_x⁡{f(x)}$ the median $\inf \arg \max_x⁡{f'(x)}$ or any other domain point serving as some kind of ""anchor"" to the function's ""signature"", such that it ""moves along"" when the function is translated. Is there a name for such a property/operator in general?","Let be an operator that maps any well-behaved (with bounded integral) function to a number , such that if for all , then . Subject to the above condition, could be, for example: the centroid the median or any other domain point serving as some kind of ""anchor"" to the function's ""signature"", such that it ""moves along"" when the function is translated. Is there a name for such a property/operator in general?",L f:\mathbb{R} \rightarrow\mathbb{R} L_f\in\mathbb{R} g(x)=f(x-d) x\in\mathbb{R} L_g=L_f+d L_f \frac{\int_{-\infty}^\infty xf(x)dx}{\int_{-\infty}^\infty f(x)dx} \inf \arg \max_x⁡{f(x)} \inf \arg \max_x⁡{f'(x)},"['functions', 'terminology', 'means']"
93,Periodic functions whose sum is null,Periodic functions whose sum is null,,"If $f_1,\ldots,f_n:\mathbb{R}\rightarrow\mathbb{R}$ are periodic functions such that $$ \lim\limits_{x\rightarrow +\infty}{(f_1(x)+\ldots+f_n(x))}=0 $$ how can I prove that $f_1+\ldots+f_n=0$ ?",If are periodic functions such that how can I prove that ?,"f_1,\ldots,f_n:\mathbb{R}\rightarrow\mathbb{R}  \lim\limits_{x\rightarrow +\infty}{(f_1(x)+\ldots+f_n(x))}=0  f_1+\ldots+f_n=0","['real-analysis', 'functions', 'periodic-functions']"
94,What is the mathematical notation for mentioning variables names explicitly in a function assignment?,What is the mathematical notation for mentioning variables names explicitly in a function assignment?,,"I have a function with two parameters: $f(s,t)$ . I want to assign to the function $\alpha$ and $\beta$ : $f(\alpha,\beta)=5$ . But I don't want the reader to confuse $s$ and $t$ (the function's variables) from the values $\alpha$ and $\beta$ . I want to mention explcitly which is assigned to $s$ and which is assigned to $t$ . So I would like to denote it, for example, like this: $f(s=\beta,t=\alpha)=5$ , or like this $f(s:\beta,t:\alpha)=5$ . Is there a convention for such a notation? What is the correct notation?","I have a function with two parameters: . I want to assign to the function and : . But I don't want the reader to confuse and (the function's variables) from the values and . I want to mention explcitly which is assigned to and which is assigned to . So I would like to denote it, for example, like this: , or like this . Is there a convention for such a notation? What is the correct notation?","f(s,t) \alpha \beta f(\alpha,\beta)=5 s t \alpha \beta s t f(s=\beta,t=\alpha)=5 f(s:\beta,t:\alpha)=5","['functions', 'notation']"
95,Inverses of Surjective and Injective Functions,Inverses of Surjective and Injective Functions,,"Can you explain if the inverse of a bijective function is always a bijection, and the same for the inverses of a surjection and injection (i.e. is the inverse of a surjective function always surjective) Additionally, can you explain why compositions of bijections are always bijections (and same for surjection/injection) This isn't for homework or anything, my textbook notes are just vague and I would appreciate some more background on this topic!","Can you explain if the inverse of a bijective function is always a bijection, and the same for the inverses of a surjection and injection (i.e. is the inverse of a surjective function always surjective) Additionally, can you explain why compositions of bijections are always bijections (and same for surjection/injection) This isn't for homework or anything, my textbook notes are just vague and I would appreciate some more background on this topic!",,"['functions', 'relations', 'inverse-function', 'function-and-relation-composition']"
96,Prove that the mapping of a number to its XOR with some constant c is bijective,Prove that the mapping of a number to its XOR with some constant c is bijective,,"Prove that $x \mapsto x \oplus c$ is a bijection over the range $[0, b]$ , regardless of the value of constant $c$ , where $b = 2^{k} - 1, k \in I^{+}$ .","Prove that is a bijection over the range , regardless of the value of constant , where .","x \mapsto x \oplus c [0, b] c b = 2^{k} - 1, k \in I^{+}","['functions', 'discrete-mathematics', 'binary']"
97,"""Etymology"" of symbols for injections and surjections","""Etymology"" of symbols for injections and surjections",,Excuse me if this sounds silly. Does anybody know why injections and surjections are sometimes denoted symbolically as $f:V\hookrightarrow W$ and $g:V\twoheadrightarrow W$ ? How do the arrows $\hookrightarrow$ and $\twoheadrightarrow$ convey the meanings of injections and surjections?,Excuse me if this sounds silly. Does anybody know why injections and surjections are sometimes denoted symbolically as and ? How do the arrows and convey the meanings of injections and surjections?,f:V\hookrightarrow W g:V\twoheadrightarrow W \hookrightarrow \twoheadrightarrow,"['functions', 'notation', 'terminology']"
98,Symmetry in function given by double sum,Symmetry in function given by double sum,,"I had to deal with this function: $$ f_n(x_1,x_2)=(x_2-x_1)^{n-1}\sum_{m=0}^{n-1}\sum_{j=0}^{n-m-1}C(n,m,j)\left(\frac{x_2}{x_2-x_1}\right)^m\left(\frac{x_2(1-x_1)}{x_2-x_1}\right)^j $$ where $$C(n,m,j)=\frac{(-n+1)_m}{m!}\frac{(-n+m+1)_j(n)_j}{j!(m+2)_j}$$ or $$C(n,m,j)=\frac{(-1)^{m+j}(n+j-1)!(m+1)}{j!(n-m-j-1)!(m+j+1)!}$$ (Here $(x)_j=x(x+1)\cdots (x+j-1)$ is the Pochhammer symbol or rising factorial). I computed several cases and it seems that $f_n(x_1,x_2)$ is a symmetic function for every $n$ , even though that is not apparent at first sight. Can one bring the function to another form that is explicitly symmetric? I have tried playing with hypergeometric identites, but there are so many of them and I didn't get anywhere. EDIT: Playing with particular cases, it seems the function is given by $$f_n(x_1,x_2)=\sum_{i=1}^{n}\sum_{j=1}^iA_{i,j}x_1^{n-1-i+j}x_2^{n-j}$$ and some of the coefficients are recognizable: $$A_{i,1}=A_{i,i}={2n-i-1\choose n-1}{n-1\choose n-i}\frac{1}{(n-i+1)}$$ and $$A_{n,j}={n-1\choose j-1}{n\choose j-1}\frac{1}{j}$$","I had to deal with this function: where or (Here is the Pochhammer symbol or rising factorial). I computed several cases and it seems that is a symmetic function for every , even though that is not apparent at first sight. Can one bring the function to another form that is explicitly symmetric? I have tried playing with hypergeometric identites, but there are so many of them and I didn't get anywhere. EDIT: Playing with particular cases, it seems the function is given by and some of the coefficients are recognizable: and"," f_n(x_1,x_2)=(x_2-x_1)^{n-1}\sum_{m=0}^{n-1}\sum_{j=0}^{n-m-1}C(n,m,j)\left(\frac{x_2}{x_2-x_1}\right)^m\left(\frac{x_2(1-x_1)}{x_2-x_1}\right)^j  C(n,m,j)=\frac{(-n+1)_m}{m!}\frac{(-n+m+1)_j(n)_j}{j!(m+2)_j} C(n,m,j)=\frac{(-1)^{m+j}(n+j-1)!(m+1)}{j!(n-m-j-1)!(m+j+1)!} (x)_j=x(x+1)\cdots (x+j-1) f_n(x_1,x_2) n f_n(x_1,x_2)=\sum_{i=1}^{n}\sum_{j=1}^iA_{i,j}x_1^{n-1-i+j}x_2^{n-j} A_{i,1}=A_{i,i}={2n-i-1\choose n-1}{n-1\choose n-i}\frac{1}{(n-i+1)} A_{n,j}={n-1\choose j-1}{n\choose j-1}\frac{1}{j}","['functions', 'polynomials', 'summation', 'hypergeometric-function']"
99,Is restriction of a function necessarily limited to a subset of the domain?,Is restriction of a function necessarily limited to a subset of the domain?,,"A pretty basic question but I cannot find it either here or on the net. The usual definition of restriction of a function $f : X \to Y$ , to a set $X'$ (denoted by $f{\restriction_{X'}}$ ) assumes that $X' \subset X$ , i.e. the restricted domain is a subset of the original domain . See for example the Wikipedia definition of restriction . However, in certain contexts it may be simpler and very natural to extend this concept to any set $X'$ , simply by considering $X \cap X'$ ; thus writing $f{\restriction_{X'}}$ directly instead of $f{\restriction_{X' \cap X}}$ , because: the intent is clear even if $X'$ is not a subset of the domain; it saves some characters; if the domain of the function has no established name, than this operation requires even more characters, (something like $f{\restriction_{X'  \cap {\operatorname {dom} f} }}$ ); if the function is constructed as an expression (like $g\circ h$ ), then this becomes even more complex and requires unnecessary repetition $(g \circ h){\restriction_{X' \cap \operatorname {dom}(g \circ h) }}$ . Naturally, if such expressions become abundant, it is possible to add a short remark on the extended usage. However, I am still curious whether such extension would be considered (even a minor) abuse of notation without any remark? there is some deeper reason why the ""usual"" definition assumes that the restriction is limited to subsets of the domain? This constraint seems completely unnecessary. Note: Despite using the ""usual"" definition, even the Wikipedia article hints at the possibility of the ""extended"" one: Informally, the restriction of $f$ to $A$ is the same function as $f$ , but is only defined on $\displaystyle A\cap \operatorname {dom} f$ . because if we had really assumed $A \subset \operatorname {dom} f$ then it would have been enough to write ""... but is only defined on $A$ "".","A pretty basic question but I cannot find it either here or on the net. The usual definition of restriction of a function , to a set (denoted by ) assumes that , i.e. the restricted domain is a subset of the original domain . See for example the Wikipedia definition of restriction . However, in certain contexts it may be simpler and very natural to extend this concept to any set , simply by considering ; thus writing directly instead of , because: the intent is clear even if is not a subset of the domain; it saves some characters; if the domain of the function has no established name, than this operation requires even more characters, (something like ); if the function is constructed as an expression (like ), then this becomes even more complex and requires unnecessary repetition . Naturally, if such expressions become abundant, it is possible to add a short remark on the extended usage. However, I am still curious whether such extension would be considered (even a minor) abuse of notation without any remark? there is some deeper reason why the ""usual"" definition assumes that the restriction is limited to subsets of the domain? This constraint seems completely unnecessary. Note: Despite using the ""usual"" definition, even the Wikipedia article hints at the possibility of the ""extended"" one: Informally, the restriction of to is the same function as , but is only defined on . because if we had really assumed then it would have been enough to write ""... but is only defined on "".",f : X \to Y X' f{\restriction_{X'}} X' \subset X X' X \cap X' f{\restriction_{X'}} f{\restriction_{X' \cap X}} X' f{\restriction_{X'  \cap {\operatorname {dom} f} }} g\circ h (g \circ h){\restriction_{X' \cap \operatorname {dom}(g \circ h) }} f A f \displaystyle A\cap \operatorname {dom} f A \subset \operatorname {dom} f A,"['functions', 'elementary-set-theory', 'notation']"
