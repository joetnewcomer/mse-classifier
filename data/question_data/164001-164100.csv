,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Proving $f^2$ integrable implies $f$ is integrable.,Proving  integrable implies  is integrable.,f^2 f,"I'm trying to prove the next proposition: Let $f:R\subset\mathbb{R}^n\rightarrow\mathbb{R}$ bounded such as $f(x)\geq c>0$ for all $x\in R,$ where $R$ is a closed rectangle. If $f^2$ is Riemann integrable over $R$ then $f$ also is Riemann integrable . I'm lost. My attemp begings defining a new function $f(x)-c\geq0,$ so $\sup\{(f(x)-c)^2:x\in R_{i}\}=\sup^2\{f(x)-c:x\in R_{i}\},$ where $R_{i}$ are the rectangles induced by the partition, and a similar expression with the infimum. I use the integrability of $f^2$ to try bounding the difference between superior and inferior sums of $f$, but the inequalities are useless because of properties of supremum and infimum. I'd aprecciate any kind of help. Thanks in advance.","I'm trying to prove the next proposition: Let $f:R\subset\mathbb{R}^n\rightarrow\mathbb{R}$ bounded such as $f(x)\geq c>0$ for all $x\in R,$ where $R$ is a closed rectangle. If $f^2$ is Riemann integrable over $R$ then $f$ also is Riemann integrable . I'm lost. My attemp begings defining a new function $f(x)-c\geq0,$ so $\sup\{(f(x)-c)^2:x\in R_{i}\}=\sup^2\{f(x)-c:x\in R_{i}\},$ where $R_{i}$ are the rectangles induced by the partition, and a similar expression with the infimum. I use the integrability of $f^2$ to try bounding the difference between superior and inferior sums of $f$, but the inequalities are useless because of properties of supremum and infimum. I'd aprecciate any kind of help. Thanks in advance.",,"['calculus', 'integration', 'measure-theory', 'multivariable-calculus']"
1,"Why are theorems such as the Baire Category Theorem proved for $C([0,1])$ and not more general spaces?",Why are theorems such as the Baire Category Theorem proved for  and not more general spaces?,"C([0,1])","In analysis I see that the proof of the Baire Category Theorem is proved for the set of all continuous functions on $[0,1]$, $C([0,1])$. However, I was wondering if the BCT would also hold for the set of continuous functions $C: \mathbb{R} \to \mathbb{R}$ as well. Is it just simpler to prove results for $C([0,1])$ or does it only hold on the mapping $C: [0,1] \to \mathbb{R}$? Thanks!","In analysis I see that the proof of the Baire Category Theorem is proved for the set of all continuous functions on $[0,1]$, $C([0,1])$. However, I was wondering if the BCT would also hold for the set of continuous functions $C: \mathbb{R} \to \mathbb{R}$ as well. Is it just simpler to prove results for $C([0,1])$ or does it only hold on the mapping $C: [0,1] \to \mathbb{R}$? Thanks!",,"['real-analysis', 'measure-theory', 'baire-category']"
2,Is there a probability measure on the Cantor set?,Is there a probability measure on the Cantor set?,,I know that the Lebesgue measure of the Cantor set is $0$. Is there a finite positive regular measure on the Cantor set?,I know that the Lebesgue measure of the Cantor set is $0$. Is there a finite positive regular measure on the Cantor set?,,"['measure-theory', 'lebesgue-measure', 'cantor-set']"
3,Several questions about Riesz–Markov–Kakutani representation theorem,Several questions about Riesz–Markov–Kakutani representation theorem,,"This is a list of questions about Riesz–Markov–Kakutani representation theorem . 1)If $f\in L^1(\mu)$, is it true that $\phi(f)=\int_Xfd\mu$, where $\mu$ is given by the theorem?  I am quite sure it is correct, since $C_c(X)$ is dense in $L^1(\mu)$. And we can extract a subsequence that pointwise converges to $f$. 2)If $X$ is not locally compact, does the theorem still stands? If not, does there exist a non-regular measure such that $\phi(f)=\int_Xfd\mu$? The property of locally compact is a must to use Urysohn lemma in the proof. The reason why Urysohn lemma (or partition unity) is widely used is because the way we construct the measure. So I am thinking if we can construct the same measure in another way that we can avoid Urysohn lemma. 3) If $X$ is not Hausdorff, what will happen as stated in 2)? 4)If $X$ is normal and not locally compact?","This is a list of questions about Riesz–Markov–Kakutani representation theorem . 1)If $f\in L^1(\mu)$, is it true that $\phi(f)=\int_Xfd\mu$, where $\mu$ is given by the theorem?  I am quite sure it is correct, since $C_c(X)$ is dense in $L^1(\mu)$. And we can extract a subsequence that pointwise converges to $f$. 2)If $X$ is not locally compact, does the theorem still stands? If not, does there exist a non-regular measure such that $\phi(f)=\int_Xfd\mu$? The property of locally compact is a must to use Urysohn lemma in the proof. The reason why Urysohn lemma (or partition unity) is widely used is because the way we construct the measure. So I am thinking if we can construct the same measure in another way that we can avoid Urysohn lemma. 3) If $X$ is not Hausdorff, what will happen as stated in 2)? 4)If $X$ is normal and not locally compact?",,"['real-analysis', 'measure-theory', 'riesz-representation-theorem']"
4,A footnote about outer measure,A footnote about outer measure,,This is the theorem about in Royden's real analysis book. And in the book there is a footnote I am confusing: Can anyone help me understanding it with examples~~~,This is the theorem about in Royden's real analysis book. And in the book there is a footnote I am confusing: Can anyone help me understanding it with examples~~~,,"['real-analysis', 'measure-theory']"
5,Hypothesis of dominated convergence theorem,Hypothesis of dominated convergence theorem,,"The dominated convergence theorem says : Suppose $(f_n)$ is a sequence of measurable function s.t. $f_n(x)\longrightarrow f(x)$ a.e. as $n\to \infty $. If $|f_n(x)|\leq g(x)$ and $g$ is integrable, then $$\lim_{n\to\infty }\int f_n=\int f.$$ Quest 1) If $|f|$ is integrable, do we directly have $\lim_{n\to\infty }\int f_n=\int f$ or we need to have $|f_n(x)|\leq |f(x)|$ ? Quest 2) If no, I have that $g$ is continuous with compact support (and thus integrable). Why the dominated convergence theorem allows me to conclude that $$\lim_{\delta\to 1}\int g(\delta x)dx=\int g(x)dx\ \ ?$$ Don't talks about change the variable $u=\delta x$ to prove it, it's not my question (I know how to prove this). My question is precisely : Why can we conclude using dominated convergence ? Because we don't necessarily have $|g(\delta x)|\leq g(x)$, and thus I'm a little annoyed by this argument.","The dominated convergence theorem says : Suppose $(f_n)$ is a sequence of measurable function s.t. $f_n(x)\longrightarrow f(x)$ a.e. as $n\to \infty $. If $|f_n(x)|\leq g(x)$ and $g$ is integrable, then $$\lim_{n\to\infty }\int f_n=\int f.$$ Quest 1) If $|f|$ is integrable, do we directly have $\lim_{n\to\infty }\int f_n=\int f$ or we need to have $|f_n(x)|\leq |f(x)|$ ? Quest 2) If no, I have that $g$ is continuous with compact support (and thus integrable). Why the dominated convergence theorem allows me to conclude that $$\lim_{\delta\to 1}\int g(\delta x)dx=\int g(x)dx\ \ ?$$ Don't talks about change the variable $u=\delta x$ to prove it, it's not my question (I know how to prove this). My question is precisely : Why can we conclude using dominated convergence ? Because we don't necessarily have $|g(\delta x)|\leq g(x)$, and thus I'm a little annoyed by this argument.",,['measure-theory']
6,Almost sure and $L_1$ convergence to different limits?,Almost sure and  convergence to different limits?,L_1,"Let $X_n, n \geq 1$ be random variables. Suppose that $X_n \rightarrow 0$ $\mathbb P$-a.s. as $n \rightarrow \infty$. Moreover, suppose that $E[X_n]=1$. Now is it clear that there cannot be $L^1$-convergence? Why? Because the limit would need to be 0, whereas the mean converges to 1? But convergence of the mean hasn't directly to do with $L^1$-convergence, because for that we would consider the mean of the difference? So why can we conclude that we do not have $L^1$-convergence? What would we need to have $L^1$-convergence?","Let $X_n, n \geq 1$ be random variables. Suppose that $X_n \rightarrow 0$ $\mathbb P$-a.s. as $n \rightarrow \infty$. Moreover, suppose that $E[X_n]=1$. Now is it clear that there cannot be $L^1$-convergence? Why? Because the limit would need to be 0, whereas the mean converges to 1? But convergence of the mean hasn't directly to do with $L^1$-convergence, because for that we would consider the mean of the difference? So why can we conclude that we do not have $L^1$-convergence? What would we need to have $L^1$-convergence?",,"['probability', 'measure-theory', 'convergence-divergence', 'random-variables', 'almost-everywhere']"
7,Having trouble justifying order of integral and sum,Having trouble justifying order of integral and sum,,"I'm trying to prove that $\mu$ is a measure on $\mathcal{M}$, where $\mu(E) = \int_{E}f$, $f: \mathbb{R} \to [0, \infty]$ is a Lebesgue measurable funciton, and $\mathcal{M}$ consists of all the Lebesgue measurable subsets of $\mathbb{R}$. Right now, I'm trying to show countable additivity: $\mu(\cup_{k=1}^{\infty}E_{k}) = \cup_{k=1}^{\infty}\mu(E_{k})$, where the $E_{k}$ are disjoint. So far, I have that $\mu(\cup_{k=1}^{\infty}E_{k}) = \int_{\cup_{k=1}^{\infty}E_{k}}f = \int f 1_{\cup_{k=1}^{\infty}E_{k}}$ (where $1_{\cup_{k=1}^{\infty}E_{k}}$ is an indicator function) $= \int \sum_{k=1}^{\infty}f 1_{E_{k}}$, and on the next step, I need to switch the $\int$ and the $\sum$. I would like to use Monotone Convergence Theorem to get the job done, but $f 1_{E_{k}}$, while nonnegative, is not necessarily increasing (or is it?). So, how do I get this to look like something that is monotone increasing so that I can apply the theorem I need?","I'm trying to prove that $\mu$ is a measure on $\mathcal{M}$, where $\mu(E) = \int_{E}f$, $f: \mathbb{R} \to [0, \infty]$ is a Lebesgue measurable funciton, and $\mathcal{M}$ consists of all the Lebesgue measurable subsets of $\mathbb{R}$. Right now, I'm trying to show countable additivity: $\mu(\cup_{k=1}^{\infty}E_{k}) = \cup_{k=1}^{\infty}\mu(E_{k})$, where the $E_{k}$ are disjoint. So far, I have that $\mu(\cup_{k=1}^{\infty}E_{k}) = \int_{\cup_{k=1}^{\infty}E_{k}}f = \int f 1_{\cup_{k=1}^{\infty}E_{k}}$ (where $1_{\cup_{k=1}^{\infty}E_{k}}$ is an indicator function) $= \int \sum_{k=1}^{\infty}f 1_{E_{k}}$, and on the next step, I need to switch the $\int$ and the $\sum$. I would like to use Monotone Convergence Theorem to get the job done, but $f 1_{E_{k}}$, while nonnegative, is not necessarily increasing (or is it?). So, how do I get this to look like something that is monotone increasing so that I can apply the theorem I need?",,"['real-analysis', 'measure-theory']"
8,Gap in My Understanding of Measurable Functions as Pointwise Limits of Simple Functions,Gap in My Understanding of Measurable Functions as Pointwise Limits of Simple Functions,,"I've been thinking back to the proof that in $\mathbb{R}$, a measurable function $f:\mathbb{R}\to\mathbb{R}$ is the pointwise limit of increasing simple functions $s_n$. As far as the intuitive picture of it goes, Pugh and Folland both have excellent visualizations that convince me that ""morally"", such a theorem is correct (and are also a great deal of help is making sense of the messy algebra). However, when I think of a function such as the identity on the unit interval (""y=x"" from grade school), it is definitely measurable as it's continuous, but the fact that it takes on uncountably many values in the interval jars with my understanding that a simple function can only take on finitely many (and in the limit, increases to a countable number of values taken on). What part(s) am I really failing to grasp here?","I've been thinking back to the proof that in $\mathbb{R}$, a measurable function $f:\mathbb{R}\to\mathbb{R}$ is the pointwise limit of increasing simple functions $s_n$. As far as the intuitive picture of it goes, Pugh and Folland both have excellent visualizations that convince me that ""morally"", such a theorem is correct (and are also a great deal of help is making sense of the messy algebra). However, when I think of a function such as the identity on the unit interval (""y=x"" from grade school), it is definitely measurable as it's continuous, but the fact that it takes on uncountably many values in the interval jars with my understanding that a simple function can only take on finitely many (and in the limit, increases to a countable number of values taken on). What part(s) am I really failing to grasp here?",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
9,Are borel sets topologies?,Are borel sets topologies?,,"I was reading about borel sets in big Rudin and something I noticed was that borel sets of a measurable space contain all open sets of the space. So my question is, are borel sets topologies or did I misread something.","I was reading about borel sets in big Rudin and something I noticed was that borel sets of a measurable space contain all open sets of the space. So my question is, are borel sets topologies or did I misread something.",,"['general-topology', 'measure-theory']"
10,"Royden Real Analysis, Chapter $3$ Proposition $9$","Royden Real Analysis, Chapter  Proposition",3 9,"This is from Royden Real Analysis Chapter $3$ Proposition $9$ Page $60$ Let $f_{n}$ be a sequence of measurable functions on $E$ that converges pointwise almost everywhere on $E$ to the function $f$ . Then $f$ is measurable. In the proof author have introduced natural numbers $n$ and $k$ for which $f_{j}(x)<c-1/n$ for all $j\geq k$ The proof is completed by stating the following.  Since the union of a countable collection of measurable sets is measurable $\left \{ x \in E | f(x)< c \right \}$ = $\bigcup_{1\leq k,n<\infty}$$[\bigcap_{j=k}^{\infty}\left \{ x\in E\left | f_{j}(x)<c-1/n \right \} \right]$ is measurable. Hence $f$ is measurable. I do not understand the purpose of introducing $n$ in this proof. Is it possible to avoid introducing $n$ and just use $f_{j}(x)<c$ and take union over $k$ alone.","This is from Royden Real Analysis Chapter $3$ Proposition $9$ Page $60$ Let $f_{n}$ be a sequence of measurable functions on $E$ that converges pointwise almost everywhere on $E$ to the function $f$ . Then $f$ is measurable. In the proof author have introduced natural numbers $n$ and $k$ for which $f_{j}(x)<c-1/n$ for all $j\geq k$ The proof is completed by stating the following.  Since the union of a countable collection of measurable sets is measurable $\left \{ x \in E | f(x)< c \right \}$ = $\bigcup_{1\leq k,n<\infty}$$[\bigcap_{j=k}^{\infty}\left \{ x\in E\left | f_{j}(x)<c-1/n \right \} \right]$ is measurable. Hence $f$ is measurable. I do not understand the purpose of introducing $n$ in this proof. Is it possible to avoid introducing $n$ and just use $f_{j}(x)<c$ and take union over $k$ alone.",,['measure-theory']
11,Compactness of Set of Probability Measures,Compactness of Set of Probability Measures,,"I'm currently studying Information Theory from Csiszar and Korner, ""Information Theory: Coding theorems for Discrete Memoryless Sources"". There are several questions pertaining to the set of all probability measures on the underlying space. I figured if I prove the following lemma, it will make things easier: Let $\mathcal{X}$ be a finite set. Let $\mathcal{P}=\mathcal{P}(\mathcal{X})$ be the set of all probability measures that can be defined on $\mathcal{X}$. Under the total variation metric i.e. for any two measures $P,Q \in \mathcal{P}$ $$d_{TV}(P,Q) := \sum_{x \in \mathcal{X}}|P(x)-Q(x)|$$ Prove that $(\mathcal{P},d_{TV})$ is compact. I'm actually looking for a simple proof of this. For instance, I wanted to use the result that a metric space is compact iff it is complete and totally bounded. Completeness was easy as I could just use the completeness of $\mathbb{R}$ in a pointwise fashion and show the pointwise limit is a measure. Finiteness of $\mathcal{X}$ helps greatly here. So all that is left is Totally Boundedness. Unfortunately, while I did start by assuming an $\epsilon$-cover of $\mathcal{P}$, I could not find a way to pick finitely many that would cover the whole space. I'm sure that finiteness of $\mathcal{X}$ would help here as well. The other idea, in fact the property I wanted to use, was to show sequential compactness since this is equivalent to compactness. But even here I'm not sure how to go about things. Kindly help me in this regard in the form of subtle hints and tips. If I get it, I'll post my solution and credit the most helpful hint. Update: It turns out I could use the fact that $\mathcal{P}$ is convex. Since any measure is a convex combination of degenerate distributions... Could I use this I wonder?","I'm currently studying Information Theory from Csiszar and Korner, ""Information Theory: Coding theorems for Discrete Memoryless Sources"". There are several questions pertaining to the set of all probability measures on the underlying space. I figured if I prove the following lemma, it will make things easier: Let $\mathcal{X}$ be a finite set. Let $\mathcal{P}=\mathcal{P}(\mathcal{X})$ be the set of all probability measures that can be defined on $\mathcal{X}$. Under the total variation metric i.e. for any two measures $P,Q \in \mathcal{P}$ $$d_{TV}(P,Q) := \sum_{x \in \mathcal{X}}|P(x)-Q(x)|$$ Prove that $(\mathcal{P},d_{TV})$ is compact. I'm actually looking for a simple proof of this. For instance, I wanted to use the result that a metric space is compact iff it is complete and totally bounded. Completeness was easy as I could just use the completeness of $\mathbb{R}$ in a pointwise fashion and show the pointwise limit is a measure. Finiteness of $\mathcal{X}$ helps greatly here. So all that is left is Totally Boundedness. Unfortunately, while I did start by assuming an $\epsilon$-cover of $\mathcal{P}$, I could not find a way to pick finitely many that would cover the whole space. I'm sure that finiteness of $\mathcal{X}$ would help here as well. The other idea, in fact the property I wanted to use, was to show sequential compactness since this is equivalent to compactness. But even here I'm not sure how to go about things. Kindly help me in this regard in the form of subtle hints and tips. If I get it, I'll post my solution and credit the most helpful hint. Update: It turns out I could use the fact that $\mathcal{P}$ is convex. Since any measure is a convex combination of degenerate distributions... Could I use this I wonder?",,"['general-topology', 'measure-theory', 'probability-distributions', 'metric-spaces']"
12,Non-measurable sets and sigma-algebra definition,Non-measurable sets and sigma-algebra definition,,"I´m starting to study about measure theory, but I have problems regarding the definition of measure space. In my class we saw that there exists sets that are not measurable(Vitali sets in $\mathbb R$) and in order to avoid this problem we define  a sigma-algebra on a set $X$ and we call the elements of $\Sigma$ ""measurable sets"" But the problem I have is that how can we guarantee that with this ""definition"" we cannot construct a non-measurable set. Is there a theorem that says that there can´t be non-measurable sets on a sigma-algebra over $X$ with that definition? Or I just need to assume that we cannot find such sets over these circumstances?","I´m starting to study about measure theory, but I have problems regarding the definition of measure space. In my class we saw that there exists sets that are not measurable(Vitali sets in $\mathbb R$) and in order to avoid this problem we define  a sigma-algebra on a set $X$ and we call the elements of $\Sigma$ ""measurable sets"" But the problem I have is that how can we guarantee that with this ""definition"" we cannot construct a non-measurable set. Is there a theorem that says that there can´t be non-measurable sets on a sigma-algebra over $X$ with that definition? Or I just need to assume that we cannot find such sets over these circumstances?",,"['measure-theory', 'soft-question', 'terminology', 'lebesgue-measure']"
13,Why can distributions be completely defined as probability measures on $\mathbb{R}$?,Why can distributions be completely defined as probability measures on ?,\mathbb{R},"In my textbook, it states that ""Part of the beauty of distributions comes from the fact that two statisticians, who are in different parts of the world working on completely different problems with completely different probability spaces, may both find the same distribution extremely useful; they can even discuss this distribution together in the common language of probability measures on $\mathbb{R}$, without worrying about whether they have completely different $\Omega$'s."" I am a bit confused by this statement because I don't get how one can have different $\Omega$'s without changing the problem at hand. Is there a trivial way to see why this is true?","In my textbook, it states that ""Part of the beauty of distributions comes from the fact that two statisticians, who are in different parts of the world working on completely different problems with completely different probability spaces, may both find the same distribution extremely useful; they can even discuss this distribution together in the common language of probability measures on $\mathbb{R}$, without worrying about whether they have completely different $\Omega$'s."" I am a bit confused by this statement because I don't get how one can have different $\Omega$'s without changing the problem at hand. Is there a trivial way to see why this is true?",,"['probability', 'measure-theory']"
14,Why is the Dynkin system generated by open intervals in $\mathbb{R}$ the Borel $\sigma$-algebra?,Why is the Dynkin system generated by open intervals in  the Borel -algebra?,\mathbb{R} \sigma,"Suppose $\mathcal{B}$ is a collection of subsets of $\mathbb{R}$ which contains the open sets, and is closed under complements and countable disjoint unions. Then $\mathcal{B}$ contains the Dynkin system generated by open intervals. I want to show that $\mathcal{B}$ contains all the Borel sets. According to http://www.ams.org/journals/proc/2000-128-02/S0002-9939-99-05507-0/S0002-9939-99-05507-0.pdf the Dynkin system generated by open balls in $\mathbb{R}^d$ is the Borel $\sigma$-algebra, and that the $d = 1$ case is easy and well-known. Can anyone provide a proof or reference for this special case?","Suppose $\mathcal{B}$ is a collection of subsets of $\mathbb{R}$ which contains the open sets, and is closed under complements and countable disjoint unions. Then $\mathcal{B}$ contains the Dynkin system generated by open intervals. I want to show that $\mathcal{B}$ contains all the Borel sets. According to http://www.ams.org/journals/proc/2000-128-02/S0002-9939-99-05507-0/S0002-9939-99-05507-0.pdf the Dynkin system generated by open balls in $\mathbb{R}^d$ is the Borel $\sigma$-algebra, and that the $d = 1$ case is easy and well-known. Can anyone provide a proof or reference for this special case?",,"['measure-theory', 'descriptive-set-theory']"
15,Is a bijective projection function measure preserving?,Is a bijective projection function measure preserving?,,"A subspace with dimension strictly less than the dimension of vector space has (Lebesgue) $measure=0$. Let $V$ be a vector space with $dimension=n$. To show that some set $S$ in V is zero-measure, is it enough to show the existence of bijective projection between $S$ and a subset of a subspace of $V$ with $dimension < n$?","A subspace with dimension strictly less than the dimension of vector space has (Lebesgue) $measure=0$. Let $V$ be a vector space with $dimension=n$. To show that some set $S$ in V is zero-measure, is it enough to show the existence of bijective projection between $S$ and a subset of a subspace of $V$ with $dimension < n$?",,"['measure-theory', 'lebesgue-measure', 'descriptive-set-theory', 'geometric-measure-theory']"
16,A continuous function on a closed subset of real line can be continuously extended [duplicate],A continuous function on a closed subset of real line can be continuously extended [duplicate],,"This question already has an answer here : Extension of continuous function on a closed subset of $\mathbb{R}$ (1 answer) Closed 8 years ago . I need help with this question as I'm not sure Let $f$ be a continuous function on $K$ which is closed in the real line. Show that there exists a continuous $F$ on all of $R$ such that $F(x)=f(x)$ on $K$. So I'm not sure which theorem to use in Folland to prove this. If anyone can hint on what to do, I'd be grateful.","This question already has an answer here : Extension of continuous function on a closed subset of $\mathbb{R}$ (1 answer) Closed 8 years ago . I need help with this question as I'm not sure Let $f$ be a continuous function on $K$ which is closed in the real line. Show that there exists a continuous $F$ on all of $R$ such that $F(x)=f(x)$ on $K$. So I'm not sure which theorem to use in Folland to prove this. If anyone can hint on what to do, I'd be grateful.",,"['real-analysis', 'measure-theory', 'continuity']"
17,$\sigma$ finite measure.,finite measure.,\sigma,"Assume $\mu$ is a $\sigma$-finite measure on  $(\Omega,\mathcal{F})$, i.e. exist finite $A_n\in\mathcal{F}$ such that $\bigcup A_n=\Omega,\mu(A_n)<\infty$. $\mathcal{P}$ is a $\pi$-system with $\sigma(\mathcal P)=\mathcal  F$, can we find such $A_n\in\mathcal P$? (Is $\mu$ a $\sigma$-finite measure on  $\mathcal{P}$?) This problem is from ""the uniqueness of measure extension"": If $\nu_1,\nu_2$ are two measure that agree on $\mathcal{P}$, then they agree on $\sigma(\mathcal{P})$ under the condition that $\nu_i$ is $\sigma$-finite measure on $\mathcal{P}$. I wonder if it can be replaced by $\sigma$-finite measure on  $\mathcal{F}=\sigma(\mathcal P)$. I got stuck on the final step on the original proof. (Refer to Durrett http://www.math.duke.edu/~rtd/PTE/PTE4_1.pdf page 361 thm A1.5)","Assume $\mu$ is a $\sigma$-finite measure on  $(\Omega,\mathcal{F})$, i.e. exist finite $A_n\in\mathcal{F}$ such that $\bigcup A_n=\Omega,\mu(A_n)<\infty$. $\mathcal{P}$ is a $\pi$-system with $\sigma(\mathcal P)=\mathcal  F$, can we find such $A_n\in\mathcal P$? (Is $\mu$ a $\sigma$-finite measure on  $\mathcal{P}$?) This problem is from ""the uniqueness of measure extension"": If $\nu_1,\nu_2$ are two measure that agree on $\mathcal{P}$, then they agree on $\sigma(\mathcal{P})$ under the condition that $\nu_i$ is $\sigma$-finite measure on $\mathcal{P}$. I wonder if it can be replaced by $\sigma$-finite measure on  $\mathcal{F}=\sigma(\mathcal P)$. I got stuck on the final step on the original proof. (Refer to Durrett http://www.math.duke.edu/~rtd/PTE/PTE4_1.pdf page 361 thm A1.5)",,"['real-analysis', 'measure-theory']"
18,Beppo Levi theorem,Beppo Levi theorem,,"In Beppo Levi's theorem, we require that the sequence of measurable functions are $\text{increasing}$. However, does a convergence result for integrals exist which deals with arbitrary sequences of measurable functions  $(u_j)$ (as long as they are positive) that are not necessarily increasing, with $u$ being the $\liminf, $\limsup, or even the $\lim$ of these functions? Or are such results derivable from Beppo Levi? One of these are Fatou's Lemma, but I am less interested in inequalities. Are there others?","In Beppo Levi's theorem, we require that the sequence of measurable functions are $\text{increasing}$. However, does a convergence result for integrals exist which deals with arbitrary sequences of measurable functions  $(u_j)$ (as long as they are positive) that are not necessarily increasing, with $u$ being the $\liminf, $\limsup, or even the $\lim$ of these functions? Or are such results derivable from Beppo Levi? One of these are Fatou's Lemma, but I am less interested in inequalities. Are there others?",,['measure-theory']
19,"A ""paradox"" involving the dominated convergence theorem","A ""paradox"" involving the dominated convergence theorem",,"I have the following question regarding the dominated convergence theorem. I was trying to apply it, but then got a contradiction that I could not resolve. Let $\zeta := |.|$ be the counting measure: We can calculate the geometric series ($n \geq 1$)$$\sum_{k=0}^{\infty} \left(\frac{1}{n+1}\right)^{k} = \frac{1}{1 - (n+1)^{-1}} = \frac{n+1}{n}$$ The functions $f_{n}(k) := \left(\frac{1}{n+1}\right)^k $ are measurable functions on the measure space $(\mathbb{N},\mathcal{P(\mathbb{N})}, \zeta)$. Obviously, for $n \to \infty$,they converge pointwise to the zero function $f_{0}(k) := 0$. We also have $$\int_{\mathbb{N}} | f_{n}(k)| d\zeta(k) \leq \int_{\mathbb{N}} \left(\frac{1}{2}\right)^{k} d\zeta(k) = \sum_{k=0}^{\infty} \left(\frac{1}{2}\right)^{k} = 2 $$ so we have an integrable dominating function for the sequence $f_{n}$. By the dominated convergence theorem, we get $$\lim_{n\to\infty} \int_{\mathbb{N}} f_{n}(k) d\zeta(k) = \int_{\mathbb{N}}f_0 (k) d\zeta(k) \quad \Leftrightarrow \quad \lim_{n \to \infty}\sum_{k=0}^{\infty} \left(\frac{1}{n+1}\right)^{k} = 0$$ A contradiction to the formula above that tells us that the limit is equal to 1. Where did I go wrong?","I have the following question regarding the dominated convergence theorem. I was trying to apply it, but then got a contradiction that I could not resolve. Let $\zeta := |.|$ be the counting measure: We can calculate the geometric series ($n \geq 1$)$$\sum_{k=0}^{\infty} \left(\frac{1}{n+1}\right)^{k} = \frac{1}{1 - (n+1)^{-1}} = \frac{n+1}{n}$$ The functions $f_{n}(k) := \left(\frac{1}{n+1}\right)^k $ are measurable functions on the measure space $(\mathbb{N},\mathcal{P(\mathbb{N})}, \zeta)$. Obviously, for $n \to \infty$,they converge pointwise to the zero function $f_{0}(k) := 0$. We also have $$\int_{\mathbb{N}} | f_{n}(k)| d\zeta(k) \leq \int_{\mathbb{N}} \left(\frac{1}{2}\right)^{k} d\zeta(k) = \sum_{k=0}^{\infty} \left(\frac{1}{2}\right)^{k} = 2 $$ so we have an integrable dominating function for the sequence $f_{n}$. By the dominated convergence theorem, we get $$\lim_{n\to\infty} \int_{\mathbb{N}} f_{n}(k) d\zeta(k) = \int_{\mathbb{N}}f_0 (k) d\zeta(k) \quad \Leftrightarrow \quad \lim_{n \to \infty}\sum_{k=0}^{\infty} \left(\frac{1}{n+1}\right)^{k} = 0$$ A contradiction to the formula above that tells us that the limit is equal to 1. Where did I go wrong?",,"['sequences-and-series', 'measure-theory']"
20,The measure of a (not necessarily disjoint) union,The measure of a (not necessarily disjoint) union,,"Let $(X,\Sigma,\mu)$ be a measurable space. Prove that, for $A,B \in \Sigma$, $\mu(A) + \mu(B) = \mu(A \cup B) + \mu(A \cap B)$. Sorry that I don't have many thoughts to add here, but I really don't know where to get started with this proof. Obviously this reduces to the countable additivity axiom when $A$ and $B$ are disjoint, so perhaps I need to be clever with symmetric differences and make use of that? Please, only give hints, not full solutions.","Let $(X,\Sigma,\mu)$ be a measurable space. Prove that, for $A,B \in \Sigma$, $\mu(A) + \mu(B) = \mu(A \cup B) + \mu(A \cap B)$. Sorry that I don't have many thoughts to add here, but I really don't know where to get started with this proof. Obviously this reduces to the countable additivity axiom when $A$ and $B$ are disjoint, so perhaps I need to be clever with symmetric differences and make use of that? Please, only give hints, not full solutions.",,"['measure-theory', 'elementary-set-theory']"
21,Does $G_{\delta}+q$ sets cover $\Bbb{R}$ a.e,Does  sets cover  a.e,G_{\delta}+q \Bbb{R},"Let $G_{\delta}$ be countable intersections of given open sets with positive Lebesgue measure on $[a,b]$. My question is that if  $G_{\delta}+q$ covers $\Bbb{R}$ a.e, i.e. is  $$ \bigcup_{q \in \mathbb{Q}}(q+G_{\delta})=\Bbb{R}-N $$ true? ($N$ is of Lebesgue measure zero). $G_{\delta}$ must be uncountable for it has positive Lebesgue measure. But it may has empty interior. I need help on this question.","Let $G_{\delta}$ be countable intersections of given open sets with positive Lebesgue measure on $[a,b]$. My question is that if  $G_{\delta}+q$ covers $\Bbb{R}$ a.e, i.e. is  $$ \bigcup_{q \in \mathbb{Q}}(q+G_{\delta})=\Bbb{R}-N $$ true? ($N$ is of Lebesgue measure zero). $G_{\delta}$ must be uncountable for it has positive Lebesgue measure. But it may has empty interior. I need help on this question.",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
22,Two different definitions of General Measurable Function,Two different definitions of General Measurable Function,,"I've noticed two different kinds of definitions for a Measurable Function . In Folland's Real Analysis Modern Techniques : If $(X, \mathcal {M})$ and $(Y, \mathcal {N})$ are measurable spaces, a mapping $f: X \to Y$ is called $(\mathcal {M}, \mathcal {N})$-measurable , or just measurable when $\mathcal {M}$ and $\mathcal {N}$ are understood, if $f^{-1}(E) \in \mathcal {M}$ for all $E \in \mathcal {N}$. In Halmos' Measure Theory : Suppose now that in addition to the set $X$ we are given also a $\sigma$-ring $\mathcal {S}$ of subsets of $X$ so that $(X, \mathcal {S})$ is a measurable space. For every real valued (and also for every extended real valued) function $f$ on $X$ we shall write $$N(f) = \{x: f(x) \ne 0 \};$$   if a real valued function $f$ is such that, for every Borel subset $M$ of the real line the set $N(f) \cap f^{-1}(M)$ is measurable, then $f$ is called a measurable function . I think both kinds of Measurable Function above are talking about a more general edition compared with Lebesgue measurable function. Basically, the difference between them two general measurable functions is whether singling $0$ out of codomain. Why does Halmos do such a removal? Or it is just a evolving process of measure theory from Halmos to Folland coz Folland's book comes out much later?","I've noticed two different kinds of definitions for a Measurable Function . In Folland's Real Analysis Modern Techniques : If $(X, \mathcal {M})$ and $(Y, \mathcal {N})$ are measurable spaces, a mapping $f: X \to Y$ is called $(\mathcal {M}, \mathcal {N})$-measurable , or just measurable when $\mathcal {M}$ and $\mathcal {N}$ are understood, if $f^{-1}(E) \in \mathcal {M}$ for all $E \in \mathcal {N}$. In Halmos' Measure Theory : Suppose now that in addition to the set $X$ we are given also a $\sigma$-ring $\mathcal {S}$ of subsets of $X$ so that $(X, \mathcal {S})$ is a measurable space. For every real valued (and also for every extended real valued) function $f$ on $X$ we shall write $$N(f) = \{x: f(x) \ne 0 \};$$   if a real valued function $f$ is such that, for every Borel subset $M$ of the real line the set $N(f) \cap f^{-1}(M)$ is measurable, then $f$ is called a measurable function . I think both kinds of Measurable Function above are talking about a more general edition compared with Lebesgue measurable function. Basically, the difference between them two general measurable functions is whether singling $0$ out of codomain. Why does Halmos do such a removal? Or it is just a evolving process of measure theory from Halmos to Folland coz Folland's book comes out much later?",,"['real-analysis', 'measure-theory']"
23,Calculate $\iint{f d\mu dv}$ and $\iint{f dv d\mu}$,Calculate  and,\iint{f d\mu dv} \iint{f dv d\mu},"The purpose of this problem is to show that in Fubini-Tonelli theorem, the condition $f \in L^{+}(X \times Y)$ or $f \in L^1$ is necessary. Here is the problem: Let $X = Y = \mathbb{N}$, $\mathcal{M} = \mathcal{N} = \mathcal{P}(\mathbb{N})$, $\mu = v =$ counting measure. Define $f(m, n) = 1$ if $m = n$, $f(m, n) = -1$ if $m = n + 1$ and $f(m, n) = 0$ otherwise. Then $\int{|f|}d(\mu \times v) = \infty$ and $\iint{fd\mu dv}$ and $\iint{fdvd\mu}$ exist but are not equal. I can prove that $\int{|f|}d(\mu \times v) = \infty$, but I don't know how to calculate $\iint{fd\mu dv}$ and $\iint{fdvd\mu}$. Anyone can help me. I really appreciate.","The purpose of this problem is to show that in Fubini-Tonelli theorem, the condition $f \in L^{+}(X \times Y)$ or $f \in L^1$ is necessary. Here is the problem: Let $X = Y = \mathbb{N}$, $\mathcal{M} = \mathcal{N} = \mathcal{P}(\mathbb{N})$, $\mu = v =$ counting measure. Define $f(m, n) = 1$ if $m = n$, $f(m, n) = -1$ if $m = n + 1$ and $f(m, n) = 0$ otherwise. Then $\int{|f|}d(\mu \times v) = \infty$ and $\iint{fd\mu dv}$ and $\iint{fdvd\mu}$ exist but are not equal. I can prove that $\int{|f|}d(\mu \times v) = \infty$, but I don't know how to calculate $\iint{fd\mu dv}$ and $\iint{fdvd\mu}$. Anyone can help me. I really appreciate.",,"['real-analysis', 'integration', 'measure-theory']"
24,"Distributions, PDFs, and Random Variables in Measure Theory","Distributions, PDFs, and Random Variables in Measure Theory",,"I'm currently reading a book on measure-theoretic probability theory, and I'm having trouble seeing how the familiar objects distributions, pdfs/pmfs, and random variables from my calc-based prob/stat classes fit into this new language: $$\begin{array} A(\Omega,\scr H,\mathbb{P}) & \stackrel{X}{\longrightarrow} & (E,\scr E,\mu) \\ \ & & \downarrow{\hat{\mathbb{P}}:= \mathbb{P}\circ X^{-1}} \\  & \ & ([0,1],\scr B([0,1])) \end{array} $$ Let $\mu$ be a measure on the measurable space $(E,\scr E)$. $\hat{\mathbb{P}}=\mathbb{P}\circ X^{-1}$ is the distribution of the random variable $X$, and it too is a measure on $(E,\scr E)$. The probability density function $f_X$ of $X$ is the Radon-Nikodym derivative of $\hat{\mathbb{P}}$ relative to $\mu$. Then $\hat{\mathbb{P}}(A):=\mathbb{P}(X^{-1}(A))=\int_A d(\mathbb{P}\circ X^{-1})=\int_Ad\mu f_X$ defines a probability measure on $(E,\scr E)$. I'm a little confused because I see that in many sources that $f_X$ is the distribution of $X$, not the density, so I'm not sure if it's a notational thing or I'm not understanding things. The two examples I saw in my calc-based prob/stat classes were Discrete: In this case, the image of $X$ is countable. $(E,\scr E)$ is usually $(N,2^N)$, $N\subseteq\mathbb{Z}$. Since every measure $\mu$ on the discrete space $(N,2^N)$ is discrete, $\mu(A)=\sum_{x\in E}m(x)\delta_x(A)$ (which implies $\int_A d\mu f=\sum_{x\in A}m(x)f(x)$=$\sum_{x\in A}\mu(x)f(x)$), the distribution $\mathbb{P}\circ X^{-1}$ has this form. Then since singletons are measurable sets, $\hat{\mathbb{P}}(\{x_0\})=\int_{x_0}d\mu f_X=\mu(x_0)f_X(x_0)$. Here I'm a litte confused about the presence of the $\mu(x_0)$ term, since We need $\hat{\mathbb{P}}(\{x_0\})=f_X(x_0).$ Continuous: In this case, the image of $X$ is uncountable. $(E,\scr E,\mu)$ is usually $(\mathbb{R}^n,\scr B(\mathbb{R}^n),\lambda)$, with the Lebesgue measure $\lambda$ defined on it. If anyone could point to any misunderstandings and correct them, it would be greatly appreciated.","I'm currently reading a book on measure-theoretic probability theory, and I'm having trouble seeing how the familiar objects distributions, pdfs/pmfs, and random variables from my calc-based prob/stat classes fit into this new language: $$\begin{array} A(\Omega,\scr H,\mathbb{P}) & \stackrel{X}{\longrightarrow} & (E,\scr E,\mu) \\ \ & & \downarrow{\hat{\mathbb{P}}:= \mathbb{P}\circ X^{-1}} \\  & \ & ([0,1],\scr B([0,1])) \end{array} $$ Let $\mu$ be a measure on the measurable space $(E,\scr E)$. $\hat{\mathbb{P}}=\mathbb{P}\circ X^{-1}$ is the distribution of the random variable $X$, and it too is a measure on $(E,\scr E)$. The probability density function $f_X$ of $X$ is the Radon-Nikodym derivative of $\hat{\mathbb{P}}$ relative to $\mu$. Then $\hat{\mathbb{P}}(A):=\mathbb{P}(X^{-1}(A))=\int_A d(\mathbb{P}\circ X^{-1})=\int_Ad\mu f_X$ defines a probability measure on $(E,\scr E)$. I'm a little confused because I see that in many sources that $f_X$ is the distribution of $X$, not the density, so I'm not sure if it's a notational thing or I'm not understanding things. The two examples I saw in my calc-based prob/stat classes were Discrete: In this case, the image of $X$ is countable. $(E,\scr E)$ is usually $(N,2^N)$, $N\subseteq\mathbb{Z}$. Since every measure $\mu$ on the discrete space $(N,2^N)$ is discrete, $\mu(A)=\sum_{x\in E}m(x)\delta_x(A)$ (which implies $\int_A d\mu f=\sum_{x\in A}m(x)f(x)$=$\sum_{x\in A}\mu(x)f(x)$), the distribution $\mathbb{P}\circ X^{-1}$ has this form. Then since singletons are measurable sets, $\hat{\mathbb{P}}(\{x_0\})=\int_{x_0}d\mu f_X=\mu(x_0)f_X(x_0)$. Here I'm a litte confused about the presence of the $\mu(x_0)$ term, since We need $\hat{\mathbb{P}}(\{x_0\})=f_X(x_0).$ Continuous: In this case, the image of $X$ is uncountable. $(E,\scr E,\mu)$ is usually $(\mathbb{R}^n,\scr B(\mathbb{R}^n),\lambda)$, with the Lebesgue measure $\lambda$ defined on it. If anyone could point to any misunderstandings and correct them, it would be greatly appreciated.",,"['probability', 'measure-theory', 'self-learning']"
25,Show $\int_E {(f_1 + f_2)d\mu } = \int_E {f_1 d\mu } + \int_E {f_2 d\mu } $,Show,\int_E {(f_1 + f_2)d\mu } = \int_E {f_1 d\mu } + \int_E {f_2 d\mu } ,"In my textbook, given a measure space $(\Omega,F,\mu)$, the integration for a non-negative $F$ measurable function $f$ on $E$ is defined as $$\int_E f\ \mathsf d\mu  = \sup_{0 \le h \le f} I_E\left( h \right)$$ where $h$ is simple function on $E$, i.e. $$h = \sum_{k = 1}^N {a_k}{\chi _{{E_k}}}\left( x \right)$$ and $${I_E}\left( h \right) = \sum_{k = 1}^N {a_k}\mu \left( {{E_k}} \right).$$ Now the question is to show, using a previous result $I_E(g+h)=I_E(g)+I_E(h)$: $$\int_E {(f_1 + f_1)\ \mathsf d\mu }  = \int_E {f_1\ \mathsf d\mu }  + \int_E {f_2\ \mathsf d\mu } $$   where $f_1$ and $f_2$ are all non-negative $F$-measurable functions. I am able to show $$\int_E \left( {{f_1} + {f_2}} \right)\ \mathsf d\mu  \ge \int_E {f_1}\ \mathsf d\mu  + \int_E {f_2}\ \mathsf d\mu .$$ Let \begin{align}\int_E {f_1}d\mu  &= \sup_{0 \le h \le {f_1}} {I_E}\left( h \right),\\ \int_E {f_2}d\mu  &= \sup_{0 \le g \le {f_2}} {I_E}\left( g \right).\end{align} Define sets \begin{align} A &= \left\{ {{I_E}\left( {u} \right):0 \le u \le {f_1} + {f_2}} \right\},\\ B &= \left\{ {{I_E}\left( h \right) + {I_E}\left( g \right):0 \le h \le {f_1},\;0 \le g \le {f_2}} \right\}\end{align} It is obvious that $B \subseteq A$ since $$0 \le h+g\le f_1+f_2$$ for any $h,g$ and $$I_E(g+h)=I_E(g)+I_E(h).$$ Thus we have \begin{align}\sup B \le \sup A \Rightarrow \sup B &= \mathop {\sup }\limits_{0 \le h \le {f_1},0 \le g \le {f_2}} \left[ {{I_E}\left( h \right) + {I_E}\left( g \right)} \right]\\ &= \sup\limits_{0 \le h \le {f_1}} {I_E}\left( h \right) + \sup\limits_{0 \le g \le {f_2}} {I_E}\left( g \right)\\ &\le \sup\limits_{0 \le u \le {f_1} + {f_2}} {I_E}\left( {u} \right)\end{align} But I have difficulty proving the opposite inequality . If I can prove every $u$ can be written as $u=h+g$ for some $h,g$, then the prove is done. But it seems it is hard to prove ""every $u$ can be written as $u=h+g$"". There could be another way around. Thank you!","In my textbook, given a measure space $(\Omega,F,\mu)$, the integration for a non-negative $F$ measurable function $f$ on $E$ is defined as $$\int_E f\ \mathsf d\mu  = \sup_{0 \le h \le f} I_E\left( h \right)$$ where $h$ is simple function on $E$, i.e. $$h = \sum_{k = 1}^N {a_k}{\chi _{{E_k}}}\left( x \right)$$ and $${I_E}\left( h \right) = \sum_{k = 1}^N {a_k}\mu \left( {{E_k}} \right).$$ Now the question is to show, using a previous result $I_E(g+h)=I_E(g)+I_E(h)$: $$\int_E {(f_1 + f_1)\ \mathsf d\mu }  = \int_E {f_1\ \mathsf d\mu }  + \int_E {f_2\ \mathsf d\mu } $$   where $f_1$ and $f_2$ are all non-negative $F$-measurable functions. I am able to show $$\int_E \left( {{f_1} + {f_2}} \right)\ \mathsf d\mu  \ge \int_E {f_1}\ \mathsf d\mu  + \int_E {f_2}\ \mathsf d\mu .$$ Let \begin{align}\int_E {f_1}d\mu  &= \sup_{0 \le h \le {f_1}} {I_E}\left( h \right),\\ \int_E {f_2}d\mu  &= \sup_{0 \le g \le {f_2}} {I_E}\left( g \right).\end{align} Define sets \begin{align} A &= \left\{ {{I_E}\left( {u} \right):0 \le u \le {f_1} + {f_2}} \right\},\\ B &= \left\{ {{I_E}\left( h \right) + {I_E}\left( g \right):0 \le h \le {f_1},\;0 \le g \le {f_2}} \right\}\end{align} It is obvious that $B \subseteq A$ since $$0 \le h+g\le f_1+f_2$$ for any $h,g$ and $$I_E(g+h)=I_E(g)+I_E(h).$$ Thus we have \begin{align}\sup B \le \sup A \Rightarrow \sup B &= \mathop {\sup }\limits_{0 \le h \le {f_1},0 \le g \le {f_2}} \left[ {{I_E}\left( h \right) + {I_E}\left( g \right)} \right]\\ &= \sup\limits_{0 \le h \le {f_1}} {I_E}\left( h \right) + \sup\limits_{0 \le g \le {f_2}} {I_E}\left( g \right)\\ &\le \sup\limits_{0 \le u \le {f_1} + {f_2}} {I_E}\left( {u} \right)\end{align} But I have difficulty proving the opposite inequality . If I can prove every $u$ can be written as $u=h+g$ for some $h,g$, then the prove is done. But it seems it is hard to prove ""every $u$ can be written as $u=h+g$"". There could be another way around. Thank you!",,"['real-analysis', 'measure-theory', 'lebesgue-integral']"
26,Help with a proof regarding simple functions.,Help with a proof regarding simple functions.,,"The question is If $f>g≥0$, then there exists non-negative measurable simple functions $f_k↗f$ s.t. $f_k≥g$ for all $k$. My attempt. Using a theorem in my text book For every non-negative function $f$, there exists a sequence $f_k$ of non-negative simple functions s.t. $f_k↗f$. Suppose $g_k$ is a sequence of non-negative simple function s.t. $g_k↗g$. For any $k$, $f-g_k>0$, then there exists non-negative simple functions $h_j↗f-g_k$, thus $h_j+g_k↗f$ with respect to $j$. But I got stuck here. Sine $g_k\le g$, I cannot conclude $h_j+g_k \ge g$. Hope someone can help. Thank you!","The question is If $f>g≥0$, then there exists non-negative measurable simple functions $f_k↗f$ s.t. $f_k≥g$ for all $k$. My attempt. Using a theorem in my text book For every non-negative function $f$, there exists a sequence $f_k$ of non-negative simple functions s.t. $f_k↗f$. Suppose $g_k$ is a sequence of non-negative simple function s.t. $g_k↗g$. For any $k$, $f-g_k>0$, then there exists non-negative simple functions $h_j↗f-g_k$, thus $h_j+g_k↗f$ with respect to $j$. But I got stuck here. Sine $g_k\le g$, I cannot conclude $h_j+g_k \ge g$. Hope someone can help. Thank you!",,"['real-analysis', 'measure-theory']"
27,convergence of step functions in $L^1$ norm,convergence of step functions in  norm,L^1,"Let $f \in L^1 (m)$. For $k=1,2,3,...$, let $f_k$ be the step function defined by    $$ f_k (x) = k\int_{j/k}^{\frac{j+1}{k}} f(t)dt \  \text{  for  $\frac{j}{k}<x<\frac{j+1}{k}$, $j=0,\pm1,\cdots$.} $$   Show that $f_k$ converges to $f$ in $L_1$ norm. This one seems more direct but when I do the $\|f_n - f\|_1$, I have trouble switching the two integrals.","Let $f \in L^1 (m)$. For $k=1,2,3,...$, let $f_k$ be the step function defined by    $$ f_k (x) = k\int_{j/k}^{\frac{j+1}{k}} f(t)dt \  \text{  for  $\frac{j}{k}<x<\frac{j+1}{k}$, $j=0,\pm1,\cdots$.} $$   Show that $f_k$ converges to $f$ in $L_1$ norm. This one seems more direct but when I do the $\|f_n - f\|_1$, I have trouble switching the two integrals.",,['measure-theory']
28,Difference between generator and the sigma algebra generated by this generator,Difference between generator and the sigma algebra generated by this generator,,"Suppose $X$ is any set and $\mathcal{F} \subseteq 2^X $. By definition, I have learnt that $\sigma( \mathcal{F} ) $ is the smallest $\sigma$-algebra that contains $\mathcal{F} $. I am trying to understand the difference between $\sigma( \mathcal{F} ) $ and $\mathcal{F} $. With specific example, suppose $\mathcal{F} = \{ f(A) : A \in \mathcal{G} \} $ where $\mathcal{G} $ is a $\sigma$-algebra. I am trying to understand $\sigma( \mathcal{F} ) $ and $f$ is a real-valued function defined on $X$. Obviously, $\sigma( \mathcal{F} ) $ contains all the $f(A) $ for $A \in \mathcal{G} $. What else does it contain? Because we don't have $\sigma( \mathcal{F} ) = \mathcal{F} $.","Suppose $X$ is any set and $\mathcal{F} \subseteq 2^X $. By definition, I have learnt that $\sigma( \mathcal{F} ) $ is the smallest $\sigma$-algebra that contains $\mathcal{F} $. I am trying to understand the difference between $\sigma( \mathcal{F} ) $ and $\mathcal{F} $. With specific example, suppose $\mathcal{F} = \{ f(A) : A \in \mathcal{G} \} $ where $\mathcal{G} $ is a $\sigma$-algebra. I am trying to understand $\sigma( \mathcal{F} ) $ and $f$ is a real-valued function defined on $X$. Obviously, $\sigma( \mathcal{F} ) $ contains all the $f(A) $ for $A \in \mathcal{G} $. What else does it contain? Because we don't have $\sigma( \mathcal{F} ) = \mathcal{F} $.",,['real-analysis']
29,Lebesgue integration,Lebesgue integration,,"if $f : \mathbb{R} \to \mathbb{R}$ is continuous function which is Lebesgue integrable on $\mathbb{R}$ then show that there is sequence $x_n$ which goes to infinity and $x_n f(x_n)$ goes to $0$.  Since $f$ is Lebesgue integrable on $\mathbb{R}$. It is finite almost every where. Also $f$ is continuous what can we use it to prove our result. Please, provide any hint.","if $f : \mathbb{R} \to \mathbb{R}$ is continuous function which is Lebesgue integrable on $\mathbb{R}$ then show that there is sequence $x_n$ which goes to infinity and $x_n f(x_n)$ goes to $0$.  Since $f$ is Lebesgue integrable on $\mathbb{R}$. It is finite almost every where. Also $f$ is continuous what can we use it to prove our result. Please, provide any hint.",,"['sequences-and-series', 'measure-theory', 'lebesgue-integral']"
30,Complex Measures: Norm,Complex Measures: Norm,,Given a measure space $\Omega$. Consider a complex measure: $$\mu:\Sigma(\Omega)\to\mathbb{C}:\quad\mu\left(\biguplus_kA_k\right)=\sum_k\mu(A_k)$$ Regard the total variation: $$|\mu|(A):=\sup_{\uplus_kA_K=A}|\mu(A_k)|$$ Then the norm is finite: $$\|\mu\|:=|\mu|(\Omega)<\infty$$ Is there an elegant proof?,Given a measure space $\Omega$. Consider a complex measure: $$\mu:\Sigma(\Omega)\to\mathbb{C}:\quad\mu\left(\biguplus_kA_k\right)=\sum_k\mu(A_k)$$ Regard the total variation: $$|\mu|(A):=\sup_{\uplus_kA_K=A}|\mu(A_k)|$$ Then the norm is finite: $$\|\mu\|:=|\mu|(\Omega)<\infty$$ Is there an elegant proof?,,"['real-analysis', 'sequences-and-series', 'measure-theory']"
31,Do Riemann and Lebesgue integrals always agree?,Do Riemann and Lebesgue integrals always agree?,,"I know that on a closed bounded interval, say $[a,b]$ in $R^1$, if a function is Riemann integral, then it is Lebesgue integrable, and the values of those two integrals are the same. But, is this true in general?? If $A$ is some set in $\mathbb{R}^n$, and if $f$ is Riemann integrable on $A$, then is it true that $f$ is also Lebesgue integrable and the value of this integral is the same as that of Riemann integral? It seems that it should be true when $A$ is bounded, but what happens when $A$ is unbounded, for example, if $A = \mathbb{R}^n$?","I know that on a closed bounded interval, say $[a,b]$ in $R^1$, if a function is Riemann integral, then it is Lebesgue integrable, and the values of those two integrals are the same. But, is this true in general?? If $A$ is some set in $\mathbb{R}^n$, and if $f$ is Riemann integrable on $A$, then is it true that $f$ is also Lebesgue integrable and the value of this integral is the same as that of Riemann integral? It seems that it should be true when $A$ is bounded, but what happens when $A$ is unbounded, for example, if $A = \mathbb{R}^n$?",,"['measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
32,Can anyone clarify why this is?,Can anyone clarify why this is?,,"The question is to prove: $$I=\int_{-\infty}^{\infty}e^{-x^2}\,\Bbb dx=\sqrt{\pi}.$$ Let \begin{align} I_r&=\int_{-r}^{r}e^{-x^2}\,\Bbb dx \\ \implies I_r^2&=\int_{-r}^{r}e^{-x^2}\,\Bbb dx\int_{-r}^{r}e^{-y^2}\,\Bbb dy \\ &=\iint_{[-r,r]^2} e^{-x^2-y^2}\,\Bbb dx\,\Bbb dy. \end{align} $x^2+y^2\leq r^2=D_r$ $$K_r=\iint_{D_r}{e^{-x^2-y^2}}\,\Bbb dx\,\Bbb dy$$ $$0\leq I_r-K_r=\int_{Q_r \setminus D_r}e^{-x^2-y^2}\,\Bbb dx\,\Bbb dy\leq e^{-r^2}\mu(Q_r)=e^{-r^2}4r^2\rightarrow0; r\rightarrow \infty.$$ The rest is clear to me just this last inequality: $\leq e^{-r^2}\mu(Q_r)$ , where $\mu(A)$ is a measure of $A$ . I’ll type out the rest of the proof if need be, for educational purposes $\ldots$","The question is to prove: Let The rest is clear to me just this last inequality: , where is a measure of . I’ll type out the rest of the proof if need be, for educational purposes","I=\int_{-\infty}^{\infty}e^{-x^2}\,\Bbb dx=\sqrt{\pi}. \begin{align} I_r&=\int_{-r}^{r}e^{-x^2}\,\Bbb dx \\ \implies I_r^2&=\int_{-r}^{r}e^{-x^2}\,\Bbb dx\int_{-r}^{r}e^{-y^2}\,\Bbb dy \\ &=\iint_{[-r,r]^2} e^{-x^2-y^2}\,\Bbb dx\,\Bbb dy. \end{align} x^2+y^2\leq r^2=D_r K_r=\iint_{D_r}{e^{-x^2-y^2}}\,\Bbb dx\,\Bbb dy 0\leq I_r-K_r=\int_{Q_r \setminus D_r}e^{-x^2-y^2}\,\Bbb dx\,\Bbb dy\leq e^{-r^2}\mu(Q_r)=e^{-r^2}4r^2\rightarrow0; r\rightarrow \infty. \leq e^{-r^2}\mu(Q_r) \mu(A) A \ldots","['calculus', 'integration', 'measure-theory']"
33,The irrational rotation is ergodic. The proof should use the idea of density point.,The irrational rotation is ergodic. The proof should use the idea of density point.,,"Consider $f_{\alpha}:S^{1}\rightarrow S^{1}$ the rotation of unit circle of angle  $2\pi\alpha$, and let $\mu$ the Lebesgue measure in $S^{1}$. Let $\alpha$ irrational, show that $\left(f,\mu\right)$ is ergodic.  You should use the idea of density point. Remark: This is a idea of the proof: I understand the idea of proof, I do not understand is why it says: A small neighborhood of the $y_{0}$ consist basically of points of the set $B$.","Consider $f_{\alpha}:S^{1}\rightarrow S^{1}$ the rotation of unit circle of angle  $2\pi\alpha$, and let $\mu$ the Lebesgue measure in $S^{1}$. Let $\alpha$ irrational, show that $\left(f,\mu\right)$ is ergodic.  You should use the idea of density point. Remark: This is a idea of the proof: I understand the idea of proof, I do not understand is why it says: A small neighborhood of the $y_{0}$ consist basically of points of the set $B$.",,"['measure-theory', 'lebesgue-measure', 'ergodic-theory']"
34,Is there a null-set whose translations generate the set of all null-sets?,Is there a null-set whose translations generate the set of all null-sets?,,"Under the Lebesgue measure, is there a null-set $N$ whose translations generate the set of all null-sets when closed under countable unions and countable intersections? I know that such an $N$ cannot be countable, since the set of all countable sets produce nothing new under countable unions and countable intersections.","Under the Lebesgue measure, is there a null-set $N$ whose translations generate the set of all null-sets when closed under countable unions and countable intersections? I know that such an $N$ cannot be countable, since the set of all countable sets produce nothing new under countable unions and countable intersections.",,"['measure-theory', 'lebesgue-measure']"
35,Help with a Royden exercise of measure,Help with a Royden exercise of measure,,"I'm solving the exercise 12, of section 4 The General Lebesgue Integral from the Royden's book Real Analysis 3rd edition: Let $g$ be an integrable function on a set $E$ and suppose that $(f_n)$ is a sequence of measurable functions such that $\vert f_n(x)\vert \leq g(x)$ a.e. on $E$. Then $$\int_E \underline{\lim}f_n \leq \underline{\lim}\int_E f_n$$ I've been able to prove it using Fatou's lemma, but my math teacher asked to prove it with dominated convergence theorem, and I can't do it. Is it possible? I'll appreciate any suggestions, thanks!","I'm solving the exercise 12, of section 4 The General Lebesgue Integral from the Royden's book Real Analysis 3rd edition: Let $g$ be an integrable function on a set $E$ and suppose that $(f_n)$ is a sequence of measurable functions such that $\vert f_n(x)\vert \leq g(x)$ a.e. on $E$. Then $$\int_E \underline{\lim}f_n \leq \underline{\lim}\int_E f_n$$ I've been able to prove it using Fatou's lemma, but my math teacher asked to prove it with dominated convergence theorem, and I can't do it. Is it possible? I'll appreciate any suggestions, thanks!",,"['measure-theory', 'lebesgue-integral', 'lebesgue-measure', 'alternative-proof']"
36,What is the motivation/applications for the definition of Lebesgue measure on $\mathbb R^n$?,What is the motivation/applications for the definition of Lebesgue measure on ?,\mathbb R^n,"The definition of the Lebesgue measure on $\mathbb R^n$ is fundamentally tied up with the following assumption: The measure of the cartesian product of $n$ intervals should be the product of the lengths of those intervals. That is to say, to define measure on $\mathbb R^n$, we just blindly generalize the formula for the area of a rectangle or the volume of a cuboid. Why do this? Cartesian products of intervals, and the concept of multiplying their lengths together, are only relevant in $\mathbb R^2$ and $\mathbb R^3$. In fact, even there, they're only relevant when those sets are being interpreted as models for physical space. If I was working on a two-variable problem in which the variables were temperature and pressure, then measuring the ""size"" of the set of all configurations with temperature in $[0, 2]$ and pressure in $[5, 3]$ (say) by multiplying together $|2-0|$ and $|5-3|$ would seem like a very irrelevant thing to do. And if I'm working on an $n$-variable problem, then claiming that this operation could possibly provide a useful notion of the ""size"" of a set just seems absurd.","The definition of the Lebesgue measure on $\mathbb R^n$ is fundamentally tied up with the following assumption: The measure of the cartesian product of $n$ intervals should be the product of the lengths of those intervals. That is to say, to define measure on $\mathbb R^n$, we just blindly generalize the formula for the area of a rectangle or the volume of a cuboid. Why do this? Cartesian products of intervals, and the concept of multiplying their lengths together, are only relevant in $\mathbb R^2$ and $\mathbb R^3$. In fact, even there, they're only relevant when those sets are being interpreted as models for physical space. If I was working on a two-variable problem in which the variables were temperature and pressure, then measuring the ""size"" of the set of all configurations with temperature in $[0, 2]$ and pressure in $[5, 3]$ (say) by multiplying together $|2-0|$ and $|5-3|$ would seem like a very irrelevant thing to do. And if I'm working on an $n$-variable problem, then claiming that this operation could possibly provide a useful notion of the ""size"" of a set just seems absurd.",,"['real-analysis', 'measure-theory', 'motivation']"
37,Measure Spaces: Uniform & Integral Convergence,Measure Spaces: Uniform & Integral Convergence,,"Given a measure space $\Omega$. Consider a sequence of measurable functions $f_n$ Suppose it converges pointwise: $f_n\to f$ Can one find increasing subsets with uniform convergence: $$A_N\uparrow\Omega:\quad\|f-f_n\|_{A_N}\stackrel{n\to\infty}{\to}0$$ Or at least with convergence in integral norm: $$A_N\uparrow\Omega:\quad\int_{A_N}|f-f_n|\mathrm{d}\mu\stackrel{n\to\infty}{\to}0$$ (Not passing over to subsequences!) Some first basic examples allow that: $$f_n:=\chi_{(n,n+1]}:\quad\|f-f_n\|_{A_N}\stackrel{n\to\infty}{\to}0\quad(A_N:=(0,N])$$ $$g_n:=x^n:\quad\|g-g_n\|_{B_N}\stackrel{n\to\infty}{\to}0\quad(B_N:=(0,1-\frac{1}{N}])$$ $$h_n:=x^{1/n}:\quad\|h-h_n\|_{C_N}\stackrel{n\to\infty}{\to}0\quad(C_N:=(\frac{1}{N},1])$$ So I wonder: Are there are examples where both can't hold?","Given a measure space $\Omega$. Consider a sequence of measurable functions $f_n$ Suppose it converges pointwise: $f_n\to f$ Can one find increasing subsets with uniform convergence: $$A_N\uparrow\Omega:\quad\|f-f_n\|_{A_N}\stackrel{n\to\infty}{\to}0$$ Or at least with convergence in integral norm: $$A_N\uparrow\Omega:\quad\int_{A_N}|f-f_n|\mathrm{d}\mu\stackrel{n\to\infty}{\to}0$$ (Not passing over to subsequences!) Some first basic examples allow that: $$f_n:=\chi_{(n,n+1]}:\quad\|f-f_n\|_{A_N}\stackrel{n\to\infty}{\to}0\quad(A_N:=(0,N])$$ $$g_n:=x^n:\quad\|g-g_n\|_{B_N}\stackrel{n\to\infty}{\to}0\quad(B_N:=(0,1-\frac{1}{N}])$$ $$h_n:=x^{1/n}:\quad\|h-h_n\|_{C_N}\stackrel{n\to\infty}{\to}0\quad(C_N:=(\frac{1}{N},1])$$ So I wonder: Are there are examples where both can't hold?",,"['integration', 'measure-theory', 'convergence-divergence', 'lebesgue-integral', 'examples-counterexamples']"
38,Benefits of alternative formulation of the integral (general measure),Benefits of alternative formulation of the integral (general measure),,"Let $(X,\mathcal{M},\mu)$ be a measure space and $f:X\to \mathbb{R}^+$ a measurable map. Set $$F(t) = \mu (\{x\in X \mid f(x)>t\})$$ and define $$\int_X f\,d\mu := \int_0^\infty F(t)\,dt,$$ where the integral on the right is the Riemann integral. Since $F$ is monotonically decreasing, we know that the Riemann integral always exists (assuming the limit is finite). Apparently, this definition agrees with the typical construction of the integral, where we define the integral for simple functions and then approximate from below the integral on the left with integrals of simple functions taking the supremum. My question is the following: What is the advantage of this alternate definition? I realize that one can piggyback on results derived from the Riemann integral, but since the main goal is always to prove convergence theorems, does it actually help there?","Let $(X,\mathcal{M},\mu)$ be a measure space and $f:X\to \mathbb{R}^+$ a measurable map. Set $$F(t) = \mu (\{x\in X \mid f(x)>t\})$$ and define $$\int_X f\,d\mu := \int_0^\infty F(t)\,dt,$$ where the integral on the right is the Riemann integral. Since $F$ is monotonically decreasing, we know that the Riemann integral always exists (assuming the limit is finite). Apparently, this definition agrees with the typical construction of the integral, where we define the integral for simple functions and then approximate from below the integral on the left with integrals of simple functions taking the supremum. My question is the following: What is the advantage of this alternate definition? I realize that one can piggyback on results derived from the Riemann integral, but since the main goal is always to prove convergence theorems, does it actually help there?",,"['integration', 'measure-theory']"
39,Prove that every set that is content zero is also measure zero.,Prove that every set that is content zero is also measure zero.,,"Prove that every set that is content zero is also measure zero. I understand that this is true, but am not sure how exactly to prove it.","Prove that every set that is content zero is also measure zero. I understand that this is true, but am not sure how exactly to prove it.",,"['real-analysis', 'measure-theory']"
40,Convergence in $L_p$ and elsewhere,Convergence in  and elsewhere,L_p,"Let $\|f\|_p:=(\int_X|f|^pd\mu)^{1/p}$ and let $L_p$ be the space of (the classes of equivalence of) complex or real measurable functions such that $\int_X|f|^p d\mu<\infty$ exists. In Kolmgorov-Fomin's Элементы теории функций и функционального анализа I find the following interesting properties that are valid for any space $X$ such that $\mu(X)<\infty$: If sequence $\{f_n\}\subset L_2(X,\mu)$ converges with respect to the metric of $L_2(X,\mu)$, it also converges with respect to the metric of $L_1(X,\mu)$ [to the same function, I would say]. If sequence $\{f_n\}$ [where I think that it necessary that we intend $\{f_n\}\subset L_2(X,\mu)$] uniformly converges, it also converged with respect to norm $\|\cdot\|_2$ [to the same function, I would say] If sequence $\{f_n\}$ of summable functions [belonging to $L_2(X,\mu)$, I would say, of course] converges with respect to $\|\cdot\|_2$, it also converges in $X$ in measure [to the same function, I would say]. If sequence $\{f_n\}$ converges with respect to $\|\|_1$, it is possible to extract a subsequence $\{f_{n_k}\}$ from it that converges almost everywhere [punctually]. From the proofs given by Kolmogorov and Fomin (pp. 387-388 here ) for the case of $L_2(X,\mu)$ I am convinced that all that I have written also holds by substituting $L_2$ and $\|\cdot\|_2$ with $L_p$ and $\|\cdot\|_p$, $p\geq 1$. With the precisation that we should have $\{f_n\}\subset L_p(X,\mu)$ at the second point. Is all that I have written correct? Thank you for any answer!!!","Let $\|f\|_p:=(\int_X|f|^pd\mu)^{1/p}$ and let $L_p$ be the space of (the classes of equivalence of) complex or real measurable functions such that $\int_X|f|^p d\mu<\infty$ exists. In Kolmgorov-Fomin's Элементы теории функций и функционального анализа I find the following interesting properties that are valid for any space $X$ such that $\mu(X)<\infty$: If sequence $\{f_n\}\subset L_2(X,\mu)$ converges with respect to the metric of $L_2(X,\mu)$, it also converges with respect to the metric of $L_1(X,\mu)$ [to the same function, I would say]. If sequence $\{f_n\}$ [where I think that it necessary that we intend $\{f_n\}\subset L_2(X,\mu)$] uniformly converges, it also converged with respect to norm $\|\cdot\|_2$ [to the same function, I would say] If sequence $\{f_n\}$ of summable functions [belonging to $L_2(X,\mu)$, I would say, of course] converges with respect to $\|\cdot\|_2$, it also converges in $X$ in measure [to the same function, I would say]. If sequence $\{f_n\}$ converges with respect to $\|\|_1$, it is possible to extract a subsequence $\{f_{n_k}\}$ from it that converges almost everywhere [punctually]. From the proofs given by Kolmogorov and Fomin (pp. 387-388 here ) for the case of $L_2(X,\mu)$ I am convinced that all that I have written also holds by substituting $L_2$ and $\|\cdot\|_2$ with $L_p$ and $\|\cdot\|_p$, $p\geq 1$. With the precisation that we should have $\{f_n\}\subset L_p(X,\mu)$ at the second point. Is all that I have written correct? Thank you for any answer!!!",,"['measure-theory', 'convergence-divergence', 'metric-spaces', 'lebesgue-integral', 'lp-spaces']"
41,Convergence a.e and in norm implies convergence in $L^p$ for $0<p<1$,Convergence a.e and in norm implies convergence in  for,L^p 0<p<1,"We know that for $p\ge1$ , given a positive measure $\mu$ on a set $X$ if $f_n\to f$ almost everywhere, $f,f_n\in L^p(\mu)$ for all $n$, and $||f_n||_p\to ||f||_p$ as $n\to \infty$ then $||f-f_n||_p\to 0$ (See here ) Will this remain true for $0<p<1$? The inequality we get here is $|f-f_n|^p<|f|^p+|f_n|^p$. I found this problem in big Rudin, where he suggests: By using Egorov's theorem write $X=A \cup B$ such that $\int_A |f|^p \le \varepsilon$, and $\mu(B)\le \infty$  and $f_n\to f$ uniformly on $B$ and then applying Fatou's lemma to $\int_B|f_n|^p$. This doesn't seem like a direct application of Egorov's since the space is not given to have finite measure.","We know that for $p\ge1$ , given a positive measure $\mu$ on a set $X$ if $f_n\to f$ almost everywhere, $f,f_n\in L^p(\mu)$ for all $n$, and $||f_n||_p\to ||f||_p$ as $n\to \infty$ then $||f-f_n||_p\to 0$ (See here ) Will this remain true for $0<p<1$? The inequality we get here is $|f-f_n|^p<|f|^p+|f_n|^p$. I found this problem in big Rudin, where he suggests: By using Egorov's theorem write $X=A \cup B$ such that $\int_A |f|^p \le \varepsilon$, and $\mu(B)\le \infty$  and $f_n\to f$ uniformly on $B$ and then applying Fatou's lemma to $\int_B|f_n|^p$. This doesn't seem like a direct application of Egorov's since the space is not given to have finite measure.",,['measure-theory']
42,"Why is convergence w.r.t $\mathcal L^p$-norm of a sequence $(f_n)$ of $\mathcal E-\mathcal B(\mathbb R)$-functions called ""convergence in $p$-mean""?","Why is convergence w.r.t -norm of a sequence  of -functions called ""convergence in -mean""?",\mathcal L^p (f_n) \mathcal E-\mathcal B(\mathbb R) p,"In measure-theory, why is convergence with respect to the $\mathcal L^p$-norm of a sequence $(f_n)_{n \in \mathbb N}$ of $\mathcal E-\mathcal B(\mathbb R)$-measurable functions called ""convergence in $p$-mean"" ? I've tried reasoning about this name, but can't really find a good reason.","In measure-theory, why is convergence with respect to the $\mathcal L^p$-norm of a sequence $(f_n)_{n \in \mathbb N}$ of $\mathcal E-\mathcal B(\mathbb R)$-measurable functions called ""convergence in $p$-mean"" ? I've tried reasoning about this name, but can't really find a good reason.",,"['measure-theory', 'soft-question', 'lp-spaces']"
43,Convergence of sequence of integrals.,Convergence of sequence of integrals.,,"Let $(\mathcal{X}, \mathcal{A}, \mu)$ be a measure space, $f_n: \mathcal{X} \to \Bbb R$ a sequence of measurable functions, and $g_n:\mathcal{X} \to \Bbb R$ integrable functions such that $|f_n| \leq g_n$. Let $f$ and $g$ measurable functions, $g$ integrable, with $f_n(x) \to f(x)$ and $g_n(x) \to g(x)$. If $\int_{\mathcal{X}} g_n  \ \mathrm{d}\mu \to \int_{\mathcal{X}} g \ \mathrm{d}\mu $, then $\int_{\mathcal{X}} f_n \ \mathrm{d}\mu \to \int_{\mathcal{X}} f \ \mathrm{d}\mu $. I think that the idea is to dominate all those $f_n$ with some integrable function, and then by the Dominated Convergence Theorem, we're done. The problem is that each $f_n$ is dominated by $g_n$, it's not the same function dominating all of them. Ok, I know that: $$f_n \leq |f_n(x)| \leq g_n(x) \implies |f(x)| \leq g(x) \quad \mbox{and}\quad \int_{\mathcal{X}} f_n \ \mathrm{d}\mu \leq \int_{\mathcal{X}} g_n \ \mathrm{d}\mu.$$ Taking limits, we get: $$\limsup \int_{\mathcal{X}} f_n \ \mathrm{d}\mu \leq \int_{\mathcal{X}} g \ \mathrm{d}\mu $$ But other than this, I don't know how to do it. Can someone give me some help (or hints of how to use this info)? Thanks.","Let $(\mathcal{X}, \mathcal{A}, \mu)$ be a measure space, $f_n: \mathcal{X} \to \Bbb R$ a sequence of measurable functions, and $g_n:\mathcal{X} \to \Bbb R$ integrable functions such that $|f_n| \leq g_n$. Let $f$ and $g$ measurable functions, $g$ integrable, with $f_n(x) \to f(x)$ and $g_n(x) \to g(x)$. If $\int_{\mathcal{X}} g_n  \ \mathrm{d}\mu \to \int_{\mathcal{X}} g \ \mathrm{d}\mu $, then $\int_{\mathcal{X}} f_n \ \mathrm{d}\mu \to \int_{\mathcal{X}} f \ \mathrm{d}\mu $. I think that the idea is to dominate all those $f_n$ with some integrable function, and then by the Dominated Convergence Theorem, we're done. The problem is that each $f_n$ is dominated by $g_n$, it's not the same function dominating all of them. Ok, I know that: $$f_n \leq |f_n(x)| \leq g_n(x) \implies |f(x)| \leq g(x) \quad \mbox{and}\quad \int_{\mathcal{X}} f_n \ \mathrm{d}\mu \leq \int_{\mathcal{X}} g_n \ \mathrm{d}\mu.$$ Taking limits, we get: $$\limsup \int_{\mathcal{X}} f_n \ \mathrm{d}\mu \leq \int_{\mathcal{X}} g \ \mathrm{d}\mu $$ But other than this, I don't know how to do it. Can someone give me some help (or hints of how to use this info)? Thanks.",,"['real-analysis', 'integration', 'measure-theory']"
44,Every analytic subset of $\Bbb{R}$ is the projection of a $G_\delta$ set $G \subset \Bbb{R} \times \Bbb{R}$,Every analytic subset of  is the projection of a  set,\Bbb{R} G_\delta G \subset \Bbb{R} \times \Bbb{R},"In the answer to this question , respectively in this post it is claimed that every analytic subset of $\Bbb{R}$ is the projection of a $G_\delta$ set. My definition of an analytic set comes from Dudley, Real Analysis and Probability, Theorem 13.2.1. This theorem shows that for a Polish space $Y$ (e.g. $Y = \Bbb{R}$ ), the following conditions are equivalent (for $\emptyset \neq A \subset Y$ ): $A = f(\Bbb{N}^\infty)$ for some continuous $f$ . $A = f(\Bbb{N}^\infty)$ for some Borel measurable $f$ . $A = f(X)$ for some Polish space $X$ and continuous $f$ . $A = f(X)$ for some Polish space $X$ and Borel measurable $f$ . $A = f(B)$ for some Borel set $B$ in a Polish space $X$ and $f : B \to Y$ continuous. $A = f(B)$ for some Borel set $B$ in a Polish space $X$ and $f : B \to Y$ Borel measurable. A set $A$ for which this is true is called an analytic subset $A$ of $Y$ . I can show that each analytic subset $\emptyset \neq A \subset \Bbb{R}$ is the projection of some Borel set $B \subset \Bbb{R}^2$ , because we also know from Dudley, Theorem 13.1.1 that $\Bbb{N}^\infty$ is Borel-isomorphic to $\Bbb{R}$ . Let $\Phi : \Bbb{R} \to \Bbb{N}^\infty$ denote the Borel-isomorphism. So if $A = f(\Bbb{N}^\infty)$ for some Borel-measurable $f : \Bbb{N}^\infty \to \Bbb{R}$ , then $$ A = (f\circ \Phi)(\Bbb{R}) = \pi_2 (\mathrm{graph}(f \circ \Phi)). $$ But Lemma 13.2.2 in Dudley shows that the graph of a Borel-measurable function is a Borel-measurable subset of the product space. However, this only shows that $A$ is the projection of a Borel-set $B\subset \Bbb{R}^2$ , it does not show that we can take $B$ to be a $G_\delta$ set. So my question is: Is it indeed true that each analytic subset of $\Bbb{R}$ (or more generally of any polish space $X$ ) is the projection of a $G_\delta$ subset $G \subset \Bbb{R} \times \Bbb{R}$ (or of $X \times X$ )? If so, can you provide a (more or less) elementary proof or a hint to a location, where I might find such a proof?","In the answer to this question , respectively in this post it is claimed that every analytic subset of is the projection of a set. My definition of an analytic set comes from Dudley, Real Analysis and Probability, Theorem 13.2.1. This theorem shows that for a Polish space (e.g. ), the following conditions are equivalent (for ): for some continuous . for some Borel measurable . for some Polish space and continuous . for some Polish space and Borel measurable . for some Borel set in a Polish space and continuous. for some Borel set in a Polish space and Borel measurable. A set for which this is true is called an analytic subset of . I can show that each analytic subset is the projection of some Borel set , because we also know from Dudley, Theorem 13.1.1 that is Borel-isomorphic to . Let denote the Borel-isomorphism. So if for some Borel-measurable , then But Lemma 13.2.2 in Dudley shows that the graph of a Borel-measurable function is a Borel-measurable subset of the product space. However, this only shows that is the projection of a Borel-set , it does not show that we can take to be a set. So my question is: Is it indeed true that each analytic subset of (or more generally of any polish space ) is the projection of a subset (or of )? If so, can you provide a (more or less) elementary proof or a hint to a location, where I might find such a proof?","\Bbb{R} G_\delta Y Y = \Bbb{R} \emptyset \neq A \subset Y A = f(\Bbb{N}^\infty) f A = f(\Bbb{N}^\infty) f A = f(X) X f A = f(X) X f A = f(B) B X f : B \to Y A = f(B) B X f : B \to Y A A Y \emptyset \neq A \subset \Bbb{R} B \subset \Bbb{R}^2 \Bbb{N}^\infty \Bbb{R} \Phi : \Bbb{R} \to \Bbb{N}^\infty A = f(\Bbb{N}^\infty) f : \Bbb{N}^\infty \to \Bbb{R} 
A = (f\circ \Phi)(\Bbb{R}) = \pi_2 (\mathrm{graph}(f \circ \Phi)).
 A B\subset \Bbb{R}^2 B G_\delta \Bbb{R} X G_\delta G \subset \Bbb{R} \times \Bbb{R} X \times X","['measure-theory', 'descriptive-set-theory']"
45,$L^p$ integral on every measurable subset of $\Bbb R$,integral on every measurable subset of,L^p \Bbb R,"Suppose $f:\Bbb R \to \Bbb R$ is in $L^p$ for some $p>1$ and also in $L^1$. Prove there exist constants $c>0$ an $\alpha \in (0,1)$ such that $\int_A|f(x)|dx\le cm(A)^{\alpha}$, for every Borel measurable set $A\subset \Bbb R$, where $m$ Lebesgue measure. Actually, I didn't get any concrete idea how to start. I tried Holders, splitting $f(x)$ into two parts with conjugate powers. It took me nowhere.. Can you just give me idea so that i can start it..","Suppose $f:\Bbb R \to \Bbb R$ is in $L^p$ for some $p>1$ and also in $L^1$. Prove there exist constants $c>0$ an $\alpha \in (0,1)$ such that $\int_A|f(x)|dx\le cm(A)^{\alpha}$, for every Borel measurable set $A\subset \Bbb R$, where $m$ Lebesgue measure. Actually, I didn't get any concrete idea how to start. I tried Holders, splitting $f(x)$ into two parts with conjugate powers. It took me nowhere.. Can you just give me idea so that i can start it..",,"['real-analysis', 'measure-theory', 'lp-spaces']"
46,Measurable set indicator functions - need clarification on a book's statement,Measurable set indicator functions - need clarification on a book's statement,,"A book I'm reading says the following about indicator functions $\chi_A$ : But unless I'm missing something, how can that that be? If $B$ is for example the set $(-2,2)$, $1 \in B$, but since $B$ contains both $0$ and $1$, $\chi_A^{-1}(B) = \{x \in A\} \cup \{x \not \in A\} = S \neq A$.  Similarly, if $B$ is, say, the set $(-1, 0.5)$, then even though $1 \not \in B$, $\chi_A^{-1}(B)= \{x \not \in A\} \neq \{\emptyset\}$.","A book I'm reading says the following about indicator functions $\chi_A$ : But unless I'm missing something, how can that that be? If $B$ is for example the set $(-2,2)$, $1 \in B$, but since $B$ contains both $0$ and $1$, $\chi_A^{-1}(B) = \{x \in A\} \cup \{x \not \in A\} = S \neq A$.  Similarly, if $B$ is, say, the set $(-1, 0.5)$, then even though $1 \not \in B$, $\chi_A^{-1}(B)= \{x \not \in A\} \neq \{\emptyset\}$.",,"['measure-theory', 'elementary-set-theory']"
47,$\lim_{A \to \infty} \int_0^{A} \int_0^{\infty} \sin(x) e^{-xt}dtdx$,,\lim_{A \to \infty} \int_0^{A} \int_0^{\infty} \sin(x) e^{-xt}dtdx,"I would like to compute the following integral: $$\lim_{A \to \infty} \int_0^{A} \int_0^{\infty} \sin(x) e^{-xt}dtdx \qquad (1)$$ I would like to swap the order of integration because then the integral becomes easier (I could evaluate it by taking its imaginary part as was done Here or i could do a partial integration two times to get that: $$\lim_{A \to \infty} \int_0^{A} \int_0^{\infty} \sin(x) e^{-xt}dxdt = \lim_{A \to \infty}\int_0^A\dfrac{1}{1+t^2}dt=\frac{\pi}{2}$$ In order to do that i need to apply Fubini-Lebesgue, because the function $\sin(x)e^{-xt}$ takes also negative values, but i can't show that $$\lim_{A \to \infty} \int_0^{A} \int_0^{\infty} |\sin(x)| e^{-xt}dtdx < \infty$$ I tried to approximate the function in this way: $$|\sin(x)e^{-xt}|\le e^{-xt}$$ but $$\lim_{A \to \infty} \int_0^{A} \int_0^{\infty}e^{-xt}dtdx = \infty$$ How can i use Fubini-Lebesuge to evaluate $(1)$? Any hint would be really appreciated, thank you! I also tried to bound $$\lim_{A \to \infty} \int_0^{A} \int_0^{\infty} |\sin(x)| e^{-xt}dtdx \le \lim_{A\to \infty}A$$ but $\lim_{A\to \infty} = \infty$ hence again this argument does not work","I would like to compute the following integral: $$\lim_{A \to \infty} \int_0^{A} \int_0^{\infty} \sin(x) e^{-xt}dtdx \qquad (1)$$ I would like to swap the order of integration because then the integral becomes easier (I could evaluate it by taking its imaginary part as was done Here or i could do a partial integration two times to get that: $$\lim_{A \to \infty} \int_0^{A} \int_0^{\infty} \sin(x) e^{-xt}dxdt = \lim_{A \to \infty}\int_0^A\dfrac{1}{1+t^2}dt=\frac{\pi}{2}$$ In order to do that i need to apply Fubini-Lebesgue, because the function $\sin(x)e^{-xt}$ takes also negative values, but i can't show that $$\lim_{A \to \infty} \int_0^{A} \int_0^{\infty} |\sin(x)| e^{-xt}dtdx < \infty$$ I tried to approximate the function in this way: $$|\sin(x)e^{-xt}|\le e^{-xt}$$ but $$\lim_{A \to \infty} \int_0^{A} \int_0^{\infty}e^{-xt}dtdx = \infty$$ How can i use Fubini-Lebesuge to evaluate $(1)$? Any hint would be really appreciated, thank you! I also tried to bound $$\lim_{A \to \infty} \int_0^{A} \int_0^{\infty} |\sin(x)| e^{-xt}dtdx \le \lim_{A\to \infty}A$$ but $\lim_{A\to \infty} = \infty$ hence again this argument does not work",,"['integration', 'measure-theory']"
48,Is the completion of a saturated measure saturated?,Is the completion of a saturated measure saturated?,,"A measure $\mu$ on $(X,\mathcal{M})$ is saturated if every locally measurable set belongs to $\mathcal{M}$.  A set $E\subset X$ is locally measurable if $E\cap A\in \mathcal{M}$ whenever $A\in\mathcal{M}$ with $\mu(A)<\infty$. It is easy to check that a $\sigma$-finite measure is saturated.  Thus a  a related, much weaker, true statement is that the completion of a $\sigma$-finite measure is $\sigma$-finite, hence saturated. EDIT: In the context of inducing an outer measure $\mu^*$ on $X$ from a measure $\mu$ on $(X,\mathcal M)$ (namely, by letting $\mu^{*}(E)=\text{inf}\{\sum_1^\infty\mu(A_j): A_j\in\mathcal M, E\subset\bigcup_1^\infty A_j\}$), and then restricting it to the $\sigma$-algebra $\mathcal{M}^*$ of $\mu^*$-measurable sets to obtain a (complete) measure $\bar{\mu}$ (i.e., letting $\bar{\mu}=\mu^*|\mathcal{M^*})$, Michael Greinecker's counterexample has the following significance: In general, $\bar{\mu}$ is the saturation of the completion of $\mu$. Of course, if $\mu$ is $\sigma$-finite, then $\bar{\mu}$ is just the completion of $\mu$. But $\bar{\mu}$ may not just be the completion of $\mu$, even if $\mu$ is saturated.","A measure $\mu$ on $(X,\mathcal{M})$ is saturated if every locally measurable set belongs to $\mathcal{M}$.  A set $E\subset X$ is locally measurable if $E\cap A\in \mathcal{M}$ whenever $A\in\mathcal{M}$ with $\mu(A)<\infty$. It is easy to check that a $\sigma$-finite measure is saturated.  Thus a  a related, much weaker, true statement is that the completion of a $\sigma$-finite measure is $\sigma$-finite, hence saturated. EDIT: In the context of inducing an outer measure $\mu^*$ on $X$ from a measure $\mu$ on $(X,\mathcal M)$ (namely, by letting $\mu^{*}(E)=\text{inf}\{\sum_1^\infty\mu(A_j): A_j\in\mathcal M, E\subset\bigcup_1^\infty A_j\}$), and then restricting it to the $\sigma$-algebra $\mathcal{M}^*$ of $\mu^*$-measurable sets to obtain a (complete) measure $\bar{\mu}$ (i.e., letting $\bar{\mu}=\mu^*|\mathcal{M^*})$, Michael Greinecker's counterexample has the following significance: In general, $\bar{\mu}$ is the saturation of the completion of $\mu$. Of course, if $\mu$ is $\sigma$-finite, then $\bar{\mu}$ is just the completion of $\mu$. But $\bar{\mu}$ may not just be the completion of $\mu$, even if $\mu$ is saturated.",,['measure-theory']
49,"Exercise, measure theory","Exercise, measure theory",,"I need help with this exercise: This exercise is in a chapter where I learn the monotone convergence theorem and Fatous lemma, so I assume I shall use them. Since $\textbf{1}_Ef_n\rightarrow \textbf{1}_Ef$, this exercise would have been very easy if the sequences were increasing, sadly they are not. Using Fatou's lemma I get: $\liminf_{n \rightarrow \infty} \int_Ef_nd\mu \ge \int\liminf_{n \rightarrow \infty}\textbf{1}_Ef_n d\mu=\int_Ef d\mu$. If I could get another with lim sup, I would maybe be able to be done. Another problem is that since the $f_n$'s may not be increasing, I do not really know that: $lim_{n \rightarrow \infty}\int_Ef_nd\mu$ even exist?, because this sequence may not even be monotone? I guess I should use the part where the entire integral is less than infinity. But I do not really see how to use it. I guess this tells me that the function is finite a.e., but how does that help?","I need help with this exercise: This exercise is in a chapter where I learn the monotone convergence theorem and Fatous lemma, so I assume I shall use them. Since $\textbf{1}_Ef_n\rightarrow \textbf{1}_Ef$, this exercise would have been very easy if the sequences were increasing, sadly they are not. Using Fatou's lemma I get: $\liminf_{n \rightarrow \infty} \int_Ef_nd\mu \ge \int\liminf_{n \rightarrow \infty}\textbf{1}_Ef_n d\mu=\int_Ef d\mu$. If I could get another with lim sup, I would maybe be able to be done. Another problem is that since the $f_n$'s may not be increasing, I do not really know that: $lim_{n \rightarrow \infty}\int_Ef_nd\mu$ even exist?, because this sequence may not even be monotone? I guess I should use the part where the entire integral is less than infinity. But I do not really see how to use it. I guess this tells me that the function is finite a.e., but how does that help?",,['measure-theory']
50,Set of measure zero and $C^{1}$ functions,Set of measure zero and  functions,C^{1},Does a $C^{1}$ function map a set of measure zero into a set of measure zero?,Does a $C^{1}$ function map a set of measure zero into a set of measure zero?,,"['measure-theory', 'lebesgue-measure']"
51,How to apply the Hölder's inequality in a clever way?,How to apply the Hölder's inequality in a clever way?,,"Here is the problem: Let $f\in L^p(\mathbb R^n)\cap L^q(\mathbb R^n)$ and $s\in[p,q]$. Show that $f\in L^s(\mathbb R^n)$ I'm almost sure that this is a simple exercise on Hölder's inequality yet I can't find the right $a,b>1$ with $$\frac{1}{a}+\frac{1}{b}=1$$ to apply the inequality. Whether you'll give a hint or a full solution (which I expect to be very short), please explain your thought process. I guess it's like with the $\varepsilon/\delta$-proofs where things happen to appear out of the blue but we know that it's because of some scratch-work before.","Here is the problem: Let $f\in L^p(\mathbb R^n)\cap L^q(\mathbb R^n)$ and $s\in[p,q]$. Show that $f\in L^s(\mathbb R^n)$ I'm almost sure that this is a simple exercise on Hölder's inequality yet I can't find the right $a,b>1$ with $$\frac{1}{a}+\frac{1}{b}=1$$ to apply the inequality. Whether you'll give a hint or a full solution (which I expect to be very short), please explain your thought process. I guess it's like with the $\varepsilon/\delta$-proofs where things happen to appear out of the blue but we know that it's because of some scratch-work before.",,"['real-analysis', 'measure-theory', 'inequality', 'lp-spaces']"
52,Prove a set contains an interval centered at zero.,Prove a set contains an interval centered at zero.,,"Prove that if $E \subset [0,1]$ has positive measure, then the set $E-E = \{x-y : x,y \in E\}$ contains an interval centered around zero. Hint: consider the function $h(x)=\textbf{1}_{-E} \star \textbf{1}_{E} $. Ideas: use the continuity of h(x)?","Prove that if $E \subset [0,1]$ has positive measure, then the set $E-E = \{x-y : x,y \in E\}$ contains an interval centered around zero. Hint: consider the function $h(x)=\textbf{1}_{-E} \star \textbf{1}_{E} $. Ideas: use the continuity of h(x)?",,"['real-analysis', 'measure-theory']"
53,Motivation behind the definition of measurability,Motivation behind the definition of measurability,,A set $A$ is measurable if for any subset $E$ of $\Bbb R$ the following holds: $$ m_{*}(E \cap A) + m_{*}(E \cap A^c) = m_{*}(E).$$ What is the motivation behind such definition ?,A set $A$ is measurable if for any subset $E$ of $\Bbb R$ the following holds: $$ m_{*}(E \cap A) + m_{*}(E \cap A^c) = m_{*}(E).$$ What is the motivation behind such definition ?,,['measure-theory']
54,Measure and Probability,Measure and Probability,,Can someone tell me that how did the idea to relate measure and probability come?(What's the conceptual history of measure and probability?),Can someone tell me that how did the idea to relate measure and probability come?(What's the conceptual history of measure and probability?),,"['probability', 'measure-theory', 'math-history']"
55,convergence of conditional expectations,convergence of conditional expectations,,"Let $\xi$ be a measurable partition on a compact metric space $X$. We can assume that $\xi$ is generated by a countable measurable sets $E_i$, that is,  $\xi = \vee_{i=1}^{\infty} \{ E_i , X \backslash E_i \}$. Now the conditional expectation $E(\phi | \mathcal{B}(\xi))$ of a bounded measurable function $\phi$ is defined by $\lim_{n \rightarrow \infty } E(\phi | \mathcal{B}_n) $, where $\mathcal{B}_n$ is the finite sigma-algebra generated by sets $E_1,...,E_n$. My question is: if for a uniformly bounded measurable functions we have a pointwise limit $\phi_m \rightarrow \phi$, then $E(\phi_m | \mathcal{B}(\xi))$ converges to $E(\phi | \mathcal{B}(\xi))$ pointwise? This statement is implicitly assumed in the proof of disintegration into conditional measures in http://w3.impa.br/~viana/out/rokhlin.pdf .","Let $\xi$ be a measurable partition on a compact metric space $X$. We can assume that $\xi$ is generated by a countable measurable sets $E_i$, that is,  $\xi = \vee_{i=1}^{\infty} \{ E_i , X \backslash E_i \}$. Now the conditional expectation $E(\phi | \mathcal{B}(\xi))$ of a bounded measurable function $\phi$ is defined by $\lim_{n \rightarrow \infty } E(\phi | \mathcal{B}_n) $, where $\mathcal{B}_n$ is the finite sigma-algebra generated by sets $E_1,...,E_n$. My question is: if for a uniformly bounded measurable functions we have a pointwise limit $\phi_m \rightarrow \phi$, then $E(\phi_m | \mathcal{B}(\xi))$ converges to $E(\phi | \mathcal{B}(\xi))$ pointwise? This statement is implicitly assumed in the proof of disintegration into conditional measures in http://w3.impa.br/~viana/out/rokhlin.pdf .",,"['measure-theory', 'conditional-probability']"
56,Does uniform integrability plus convergence in measure imply convergence in $L^1$?,Does uniform integrability plus convergence in measure imply convergence in ?,L^1,"Does uniform integrability plus convergence in measure imply convergence in $L^1$? I know this holds on a probability space. Does it hold on a general measure space? I have tried googling. It returned very few results on UI on measure spaces, and none of them mentioned a result like the one in the title. This comes from a discussion about another question. The proof i have seen for a probability space breaks for a general measure space. By UI, i mean $\sup_{f}\int_{|f|>h} |f|d\mu $ goes to $0$ as $h$ goes to infinity.","Does uniform integrability plus convergence in measure imply convergence in $L^1$? I know this holds on a probability space. Does it hold on a general measure space? I have tried googling. It returned very few results on UI on measure spaces, and none of them mentioned a result like the one in the title. This comes from a discussion about another question. The proof i have seen for a probability space breaks for a general measure space. By UI, i mean $\sup_{f}\int_{|f|>h} |f|d\mu $ goes to $0$ as $h$ goes to infinity.",,"['measure-theory', 'convergence-divergence', 'lebesgue-integral', 'uniform-integrability']"
57,Application of the Dominated Convergence Theorem,Application of the Dominated Convergence Theorem,,"$$lim_{n \to \infty} \int_0^1(1 - e^{\frac{-x^2}{n}})x^{-1/2}dx$$ I want to use the Dominated Convergence Theorem to solve this. Let $f_n = (1 - e^{\frac{-x^2}{n}})x^{-1/2}$. Step 1: Determining convergence of $f_n$ Fix $x$ to be some constant number. Now, bringing the limit inside the integral, we have $lim_{n \to \infty}(1 - \frac{1}{e^{\frac{k}{n}}})t$ where $k, t$ are constants. As $n \to \infty, \ \frac{1}{e^{\frac{k}{n}}} \to 1$ So we get $(1 - 1)t = 0$ So $f_n$ converges to the zero function $f_0$. Note that it doesn't converge at $x = 0$ as we have a division by zero but on $(0, 1]$ it converges to $f_0$ and the measure of $\{0\}$   is $0$ so we have convergence almost everywhere. Step 2: Determining a dominating function $g$ Now, when $x \in (0, 1)$, for all $n$ we have, $$e^{\frac{1}{n}} > 1$$ $$\implies e^{\frac{x^2}{n}} \ge 1$$ $$\implies 0 < \frac{1}{e^{\frac{x^2}{n}}} \le 1$$ $$\implies -1 \le - \frac{1}{e^{\frac{x^2}{n}}} < 0$$ $$\implies 0 \le 1 - \frac{1}{e^{\frac{x^2}{n}}} < 1$$ $$\implies \mid 1 - \frac{1}{e^{\frac{x^2}{n}}}\mid < 1$$ $$\implies \mid (1 - \frac{1}{e^{\frac{x^2}{n}}})x^{-1/2}\mid < x^{-1/2}$$ Let $g = x^{-1/2}$ $g$ is integrable as $\int_0^\pi x^{-1/2} = 2\sqrt{x} \mid_0^\pi = 2\sqrt\pi$ So we have a sequence of integrable functions $f_n$ that converges a.e. to the function $f_0$. Let $g = \frac{1}{\sqrt{x}}$. By the dominated convergence theorem as $\mid f_n \mid \le g$ on $(0, 1)$ for all $n$ we have that $$\int_0^1 f_0 = lim_{n \to \infty} \int_0^1 f_n $$ And the integral of the zero function $f_0$ is $0$ so we have that $$lim_{n \to \infty} \int_0^1(1 - e^{\frac{-x^2}{n}})x^{-1/2}dx = 0$$ Have I made any mistakes here? In particular, I have an issue with the way I brought the limit inside the integral in step 1. I couldn't apply the Monotone Convergence Theorem as we have decreasing sequence, so is there some other way to justify bringing it inside the integral?","$$lim_{n \to \infty} \int_0^1(1 - e^{\frac{-x^2}{n}})x^{-1/2}dx$$ I want to use the Dominated Convergence Theorem to solve this. Let $f_n = (1 - e^{\frac{-x^2}{n}})x^{-1/2}$. Step 1: Determining convergence of $f_n$ Fix $x$ to be some constant number. Now, bringing the limit inside the integral, we have $lim_{n \to \infty}(1 - \frac{1}{e^{\frac{k}{n}}})t$ where $k, t$ are constants. As $n \to \infty, \ \frac{1}{e^{\frac{k}{n}}} \to 1$ So we get $(1 - 1)t = 0$ So $f_n$ converges to the zero function $f_0$. Note that it doesn't converge at $x = 0$ as we have a division by zero but on $(0, 1]$ it converges to $f_0$ and the measure of $\{0\}$   is $0$ so we have convergence almost everywhere. Step 2: Determining a dominating function $g$ Now, when $x \in (0, 1)$, for all $n$ we have, $$e^{\frac{1}{n}} > 1$$ $$\implies e^{\frac{x^2}{n}} \ge 1$$ $$\implies 0 < \frac{1}{e^{\frac{x^2}{n}}} \le 1$$ $$\implies -1 \le - \frac{1}{e^{\frac{x^2}{n}}} < 0$$ $$\implies 0 \le 1 - \frac{1}{e^{\frac{x^2}{n}}} < 1$$ $$\implies \mid 1 - \frac{1}{e^{\frac{x^2}{n}}}\mid < 1$$ $$\implies \mid (1 - \frac{1}{e^{\frac{x^2}{n}}})x^{-1/2}\mid < x^{-1/2}$$ Let $g = x^{-1/2}$ $g$ is integrable as $\int_0^\pi x^{-1/2} = 2\sqrt{x} \mid_0^\pi = 2\sqrt\pi$ So we have a sequence of integrable functions $f_n$ that converges a.e. to the function $f_0$. Let $g = \frac{1}{\sqrt{x}}$. By the dominated convergence theorem as $\mid f_n \mid \le g$ on $(0, 1)$ for all $n$ we have that $$\int_0^1 f_0 = lim_{n \to \infty} \int_0^1 f_n $$ And the integral of the zero function $f_0$ is $0$ so we have that $$lim_{n \to \infty} \int_0^1(1 - e^{\frac{-x^2}{n}})x^{-1/2}dx = 0$$ Have I made any mistakes here? In particular, I have an issue with the way I brought the limit inside the integral in step 1. I couldn't apply the Monotone Convergence Theorem as we have decreasing sequence, so is there some other way to justify bringing it inside the integral?",,"['real-analysis', 'measure-theory']"
58,"Lebesgue-measurable, Borel set, open set","Lebesgue-measurable, Borel set, open set",,"Let $A$ be a Borel set in $(\mathbb{R},\mathcal{B})$ with positive Lebesgue-measure $\lambda(A)>0$. Show that for any $\varepsilon > 0$ there is an open interval I so that     $$ \lambda(A\cap I)\geq (1-\varepsilon)\lambda(I). $$ Hello! As a Borel-set, $A$ is Lebesgue-measurable. For any Lebesgue-measurable set, there is an open set $I\supset A$ with $\mu(I\setminus A)<\varepsilon$. Form this I follow that $\lambda(I\cap A)=\lambda(I)-\lambda(I\setminus A)>\lambda(I)-\varepsilon$. ... I do not see how I can prove the wanted result.","Let $A$ be a Borel set in $(\mathbb{R},\mathcal{B})$ with positive Lebesgue-measure $\lambda(A)>0$. Show that for any $\varepsilon > 0$ there is an open interval I so that     $$ \lambda(A\cap I)\geq (1-\varepsilon)\lambda(I). $$ Hello! As a Borel-set, $A$ is Lebesgue-measurable. For any Lebesgue-measurable set, there is an open set $I\supset A$ with $\mu(I\setminus A)<\varepsilon$. Form this I follow that $\lambda(I\cap A)=\lambda(I)-\lambda(I\setminus A)>\lambda(I)-\varepsilon$. ... I do not see how I can prove the wanted result.",,['measure-theory']
59,Properties of a pseudo-metric on a measure space,Properties of a pseudo-metric on a measure space,,"Given a measure space $\left(X,\mathcal{F},\mu\right)$   and two $\mathcal{F}-\mbox{measurable}$   functions $f,g:\left(X,\mathcal{F}\right)\to\mathbb{R}$   we define the following:$$d\left(f,g\right)=\inf_{a>0}\left(a+\mu\left(\left\{ x\in X\;|\;\left|f\left(x\right)-g\left(x\right)\right|>a\right\} \right)\right)$$  It can be shown that $d$   is symmetric and admits the triangle inequality. I'm trying to show that given two functions $f,g:\left(X,\mathcal{F}\right)\to\mathbb{R}$   and $\alpha\in\mathbb{R}$   : $$d\left(\alpha f,\alpha g\right)\leq\max\left\{ 1,\left|\alpha\right|\right\} \cdot d\left(f,g\right)$$  I've tried going at it from a couple of directions but I always get stuck with an inequality involving $\mu\left(\left\{ x\in X\;|\;\max\left\{ 1,\left|\alpha\right|\right\} \left|f\left(x\right)-g\left(x\right)\right|>a\right\} \right)$   and no way to extract that pesky maximum outside. Also regardless of this question I think that convergence relative to $d$ is equivalent to convergence in measure relative to $\mu$ is that true? Help would be appreciated.","Given a measure space $\left(X,\mathcal{F},\mu\right)$   and two $\mathcal{F}-\mbox{measurable}$   functions $f,g:\left(X,\mathcal{F}\right)\to\mathbb{R}$   we define the following:$$d\left(f,g\right)=\inf_{a>0}\left(a+\mu\left(\left\{ x\in X\;|\;\left|f\left(x\right)-g\left(x\right)\right|>a\right\} \right)\right)$$  It can be shown that $d$   is symmetric and admits the triangle inequality. I'm trying to show that given two functions $f,g:\left(X,\mathcal{F}\right)\to\mathbb{R}$   and $\alpha\in\mathbb{R}$   : $$d\left(\alpha f,\alpha g\right)\leq\max\left\{ 1,\left|\alpha\right|\right\} \cdot d\left(f,g\right)$$  I've tried going at it from a couple of directions but I always get stuck with an inequality involving $\mu\left(\left\{ x\in X\;|\;\max\left\{ 1,\left|\alpha\right|\right\} \left|f\left(x\right)-g\left(x\right)\right|>a\right\} \right)$   and no way to extract that pesky maximum outside. Also regardless of this question I think that convergence relative to $d$ is equivalent to convergence in measure relative to $\mu$ is that true? Help would be appreciated.",,"['real-analysis', 'measure-theory']"
60,"Almost uniform convergence of $f_n(x) = x^n$ on the interval $[0, 1]$?",Almost uniform convergence of  on the interval ?,"f_n(x) = x^n [0, 1]","Consider $f_n(x) = x^n$ on the interval $[0, 1]$. This converges pointwise to $$f = \begin{cases} 0, & \mbox{if } 0 \le x < 1\ \\ 1, & \mbox{if } x = 1 \end{cases}$$ Now I know $f_n(x)$ doesn't converge uniformly to $f$ but does it converge almost uniformly? For any $\delta > 0$ we can can take the subset $(1 - \epsilon, 1]$ of $[0, 1]$ such that $\epsilon < \delta$. Then as the measure of this subset is $\epsilon < \delta$ and $f_n(x)$ converges to $f$ on the complement of this subset we have almost uniform convergence. Is my understanding correct here?","Consider $f_n(x) = x^n$ on the interval $[0, 1]$. This converges pointwise to $$f = \begin{cases} 0, & \mbox{if } 0 \le x < 1\ \\ 1, & \mbox{if } x = 1 \end{cases}$$ Now I know $f_n(x)$ doesn't converge uniformly to $f$ but does it converge almost uniformly? For any $\delta > 0$ we can can take the subset $(1 - \epsilon, 1]$ of $[0, 1]$ such that $\epsilon < \delta$. Then as the measure of this subset is $\epsilon < \delta$ and $f_n(x)$ converges to $f$ on the complement of this subset we have almost uniform convergence. Is my understanding correct here?",,"['real-analysis', 'measure-theory']"
61,Distributional Laplacian of logarithm and the Dirac delta distribution,Distributional Laplacian of logarithm and the Dirac delta distribution,,"Consider $S(\mathbb{R}^2)$ the space of rapidly decreasing functions . Consider $F(x) = \displaystyle\frac{1}{2 \pi} \ln|x| , x \in \mathbb{R}^2 - \{ 0 \}$. I want to prove this  : $\Delta F = \delta $ in $S^{'}(\mathbb{R}^2).$ My try: For every $\varphi \in S({\mathbb{R}}^2)$ we have $$\langle \Delta F, \varphi\rangle  = \langle F , \Delta \varphi\rangle  = \displaystyle\int_{\mathbb{R}^2} F(x) \Delta\varphi(x) \ dx = \displaystyle\lim_{r \rightarrow + \infty} \displaystyle\lim_{\epsilon \rightarrow 0^{+} } \displaystyle\int_{\epsilon \leq |x| \leq R} F(x) \Delta \varphi(x) \ dx $$ I don't know how to prove this :$\displaystyle\lim_{r \rightarrow + \infty} \displaystyle\lim_{\epsilon \rightarrow 0^{+} } \displaystyle\int_{\epsilon \leq |x| \leq R} F(x) \Delta\varphi(x) \ dx = \varphi (0) = \delta(\varphi)$ I don't know what to do from here.","Consider $S(\mathbb{R}^2)$ the space of rapidly decreasing functions . Consider $F(x) = \displaystyle\frac{1}{2 \pi} \ln|x| , x \in \mathbb{R}^2 - \{ 0 \}$. I want to prove this  : $\Delta F = \delta $ in $S^{'}(\mathbb{R}^2).$ My try: For every $\varphi \in S({\mathbb{R}}^2)$ we have $$\langle \Delta F, \varphi\rangle  = \langle F , \Delta \varphi\rangle  = \displaystyle\int_{\mathbb{R}^2} F(x) \Delta\varphi(x) \ dx = \displaystyle\lim_{r \rightarrow + \infty} \displaystyle\lim_{\epsilon \rightarrow 0^{+} } \displaystyle\int_{\epsilon \leq |x| \leq R} F(x) \Delta \varphi(x) \ dx $$ I don't know how to prove this :$\displaystyle\lim_{r \rightarrow + \infty} \displaystyle\lim_{\epsilon \rightarrow 0^{+} } \displaystyle\int_{\epsilon \leq |x| \leq R} F(x) \Delta\varphi(x) \ dx = \varphi (0) = \delta(\varphi)$ I don't know what to do from here.",,"['measure-theory', 'partial-differential-equations', 'distribution-theory', 'laplacian']"
62,"if $\mu(A)>0$, and $f<g$ in $A$, then $\int_A f\ d\mu <\int_A g\ d \mu$","if , and  in , then",\mu(A)>0 f<g A \int_A f\ d\mu <\int_A g\ d \mu,"here is my doubt: Let $(X,\mathcal{T}, \mu)$ be a measure space, $f,g:X\to \overline{\mathbb{R}}$ measurable functions (indeed with finite integral), and $A \in \mathcal{T}$ such that $\mu(A)>0$ and   $$ f(x)<g(x)\quad \forall x \in A $$   then $\int_A f\ d\mu<\int_A g\ d\mu$. Any hint in order to prove (or disprove) it would be wellcome. Thanks in advance!","here is my doubt: Let $(X,\mathcal{T}, \mu)$ be a measure space, $f,g:X\to \overline{\mathbb{R}}$ measurable functions (indeed with finite integral), and $A \in \mathcal{T}$ such that $\mu(A)>0$ and   $$ f(x)<g(x)\quad \forall x \in A $$   then $\int_A f\ d\mu<\int_A g\ d\mu$. Any hint in order to prove (or disprove) it would be wellcome. Thanks in advance!",,['measure-theory']
63,Monotone convergence theorem to evaluate improper integral,Monotone convergence theorem to evaluate improper integral,,"My book says that the equality $$\int_{(0,1]}x^{-3/4}d\mu=\lim_{t\rightarrow 0^+}\int_{[t,1]}x^{-3/4}d\mu$$ follows from the monotone convergence theorem. Why is it so? I can't see how to apply monotone convergence theorem here.","My book says that the equality $$\int_{(0,1]}x^{-3/4}d\mu=\lim_{t\rightarrow 0^+}\int_{[t,1]}x^{-3/4}d\mu$$ follows from the monotone convergence theorem. Why is it so? I can't see how to apply monotone convergence theorem here.",,"['real-analysis', 'measure-theory', 'lebesgue-integral']"
64,Limit of infinite measure union,Limit of infinite measure union,,"Let $A_1,A_2,\ldots$ be Lebesgue measurable subsets of $\mathbb{R}$. It is certainly true, by monotonicity of $\mu$, that $$\mu\left(\bigcup_{i=1}^nA_i\right)\leq \mu\left(\bigcup_{i=1}^\infty A_i\right)$$ Is it true that $$\lim_{n\rightarrow\infty}\mu\left(\bigcup_{i=1}^nA_i\right)= \mu\left(\bigcup_{i=1}^\infty A_i\right)?$$ I've tried to think about the case where $\mu\left(\bigcup_{i=1}^\infty A_i\right)$ is infinite, but still can't find any counterexample.","Let $A_1,A_2,\ldots$ be Lebesgue measurable subsets of $\mathbb{R}$. It is certainly true, by monotonicity of $\mu$, that $$\mu\left(\bigcup_{i=1}^nA_i\right)\leq \mu\left(\bigcup_{i=1}^\infty A_i\right)$$ Is it true that $$\lim_{n\rightarrow\infty}\mu\left(\bigcup_{i=1}^nA_i\right)= \mu\left(\bigcup_{i=1}^\infty A_i\right)?$$ I've tried to think about the case where $\mu\left(\bigcup_{i=1}^\infty A_i\right)$ is infinite, but still can't find any counterexample.",,"['real-analysis', 'measure-theory']"
65,A monotone class in $\mathbb{R}$ which is closed under complement but is not a sigma-algebra,A monotone class in  which is closed under complement but is not a sigma-algebra,\mathbb{R},Like the title says I'm looking for an example of a monotone class $ \mathcal{M}\subseteq\mathcal{P}\left(\mathbb{R}\right)$ such that $\mathbb{R}\in\mathcal{M}$ and $ \mathcal{M}$ is closed under complement but is not sigma-algebra. I'm guessing the idea is to find such a family of sets that isn't closed under finite intersection but I haven't come up with anything thus far. Thanks in advance!,Like the title says I'm looking for an example of a monotone class $ \mathcal{M}\subseteq\mathcal{P}\left(\mathbb{R}\right)$ such that $\mathbb{R}\in\mathcal{M}$ and $ \mathcal{M}$ is closed under complement but is not sigma-algebra. I'm guessing the idea is to find such a family of sets that isn't closed under finite intersection but I haven't come up with anything thus far. Thanks in advance!,,"['real-analysis', 'measure-theory']"
66,The definition of Borel sigma algebra,The definition of Borel sigma algebra,,"In the text of Probability Essentials by J.Jacod & P.Protter, a theorem: The Borel $ \sigma $- algebra of $R $ is generated by intervals of the form $(-\infty,a ]$, where $a \in Q$. As far as I've known the Borel sigma algebra is generated by all open subsets of $R$, which surely contains sets like (x, y), here x is irrational. So my question is how can 'a', in theorem, a rational generate such set (x, y).","In the text of Probability Essentials by J.Jacod & P.Protter, a theorem: The Borel $ \sigma $- algebra of $R $ is generated by intervals of the form $(-\infty,a ]$, where $a \in Q$. As far as I've known the Borel sigma algebra is generated by all open subsets of $R$, which surely contains sets like (x, y), here x is irrational. So my question is how can 'a', in theorem, a rational generate such set (x, y).",,"['real-analysis', 'measure-theory']"
67,proof that convergence in mean implies convergence in probability,proof that convergence in mean implies convergence in probability,,"I'm attempting to understand a proof, but I am failing to see how a step is pulled off. Claim: $\text{if } f_n \longrightarrow_{L_p} f$ then $f_n \longrightarrow_{P} f$ Proof: Let $\epsilon > 0$. Then $P\left( \left\lbrace \omega: |f_n(\omega) - f(\omega)| > \epsilon \right\rbrace \right)  = P \left( \left\lbrace \omega: |f_n(\omega) - f(\omega)|^p > \epsilon^p \right\rbrace \right) \\$ $ \leq \frac{1}{\epsilon^p} \int_\Omega |f_n(\omega) - f(\omega)|^pdP(\omega) \longrightarrow_n 0$ I understand that this would show convergence in probability since by assumption the integral converges to zero. Its the step before that (moving from equality to inequality) that I am miffed by. This is my attempt: $P \left( \left\lbrace \omega: |f_n(\omega) - f(\omega)|^p > \epsilon^p \right\rbrace \right) = \int_\Omega I[|f_n(\omega) - f(\omega)|^p > \epsilon^p]dP(\omega) \\ = \frac{\epsilon^p}{\epsilon^p} \int_\Omega I[|f_n(\omega) - f(\omega)|^p > \epsilon^p]dP(\omega) \\ = \frac{1}{\epsilon^p} \int_\Omega \epsilon^p I[|f_n(\omega) - f(\omega)|^p > \epsilon^p]dP(\omega) \\ \leq \frac{1}{\epsilon^p} \int_\Omega |f_n(\omega) - f(\omega)|^pdP(\omega) $ The last being from the fact that $\epsilon^p$ times the indicator will be $\epsilon^p$ or 0 unless the indicator is satisfied, which is less than $|f_n(\omega) - f(\omega)|$ for those $\omega$ since if the indicator is 1, $|f_n(\omega) - f(\omega)| > \epsilon^p$. But this feels way to loose (especially since we haven't changed the fact that were integrating over $\Omega$). Any help making this more clear/rigorous would be great. Thanks!","I'm attempting to understand a proof, but I am failing to see how a step is pulled off. Claim: $\text{if } f_n \longrightarrow_{L_p} f$ then $f_n \longrightarrow_{P} f$ Proof: Let $\epsilon > 0$. Then $P\left( \left\lbrace \omega: |f_n(\omega) - f(\omega)| > \epsilon \right\rbrace \right)  = P \left( \left\lbrace \omega: |f_n(\omega) - f(\omega)|^p > \epsilon^p \right\rbrace \right) \\$ $ \leq \frac{1}{\epsilon^p} \int_\Omega |f_n(\omega) - f(\omega)|^pdP(\omega) \longrightarrow_n 0$ I understand that this would show convergence in probability since by assumption the integral converges to zero. Its the step before that (moving from equality to inequality) that I am miffed by. This is my attempt: $P \left( \left\lbrace \omega: |f_n(\omega) - f(\omega)|^p > \epsilon^p \right\rbrace \right) = \int_\Omega I[|f_n(\omega) - f(\omega)|^p > \epsilon^p]dP(\omega) \\ = \frac{\epsilon^p}{\epsilon^p} \int_\Omega I[|f_n(\omega) - f(\omega)|^p > \epsilon^p]dP(\omega) \\ = \frac{1}{\epsilon^p} \int_\Omega \epsilon^p I[|f_n(\omega) - f(\omega)|^p > \epsilon^p]dP(\omega) \\ \leq \frac{1}{\epsilon^p} \int_\Omega |f_n(\omega) - f(\omega)|^pdP(\omega) $ The last being from the fact that $\epsilon^p$ times the indicator will be $\epsilon^p$ or 0 unless the indicator is satisfied, which is less than $|f_n(\omega) - f(\omega)|$ for those $\omega$ since if the indicator is 1, $|f_n(\omega) - f(\omega)| > \epsilon^p$. But this feels way to loose (especially since we haven't changed the fact that were integrating over $\Omega$). Any help making this more clear/rigorous would be great. Thanks!",,"['probability', 'measure-theory', 'convergence-divergence']"
68,Intersection of a directed family of large sets,Intersection of a directed family of large sets,,"Fix an $0\lt\varepsilon \lt 1$ (you may assume, if required, that $\varepsilon\lt \frac{1}{2}$ or, indeed, that $\varepsilon$ is sufficiently small for any argument you may wish to do). Let $G$ be a family of subsets of $[0,1]$ such that every element of $G$ has Lebesgue measure greater than $1-\varepsilon$ and which is downward directed, i.e. for every $X,Y\in G$ there is a $Z\in G$ satisfying $Z\subseteq X\cap Y$. Assume in addition that for all $X,Y\in G$ the symmetric difference $X\triangle Y$ has nonzero measure. Is $\bigcap G$ necessarily measurable and, if so, does it have measure at least $1-\varepsilon$? Both questions are easily seen to have a positive answer if $G$ is countable, but we make no such assumption here. What I have tried to do is to approximate the elements of $G$ from below by compact sets and then trying to show that this derived family of compact sets has the finite intersection property. I can't quite get it to work, but this would at least show that $\bigcap G$ is nonempty. Then again, I'm not sure how this would help in answering the actual questions.","Fix an $0\lt\varepsilon \lt 1$ (you may assume, if required, that $\varepsilon\lt \frac{1}{2}$ or, indeed, that $\varepsilon$ is sufficiently small for any argument you may wish to do). Let $G$ be a family of subsets of $[0,1]$ such that every element of $G$ has Lebesgue measure greater than $1-\varepsilon$ and which is downward directed, i.e. for every $X,Y\in G$ there is a $Z\in G$ satisfying $Z\subseteq X\cap Y$. Assume in addition that for all $X,Y\in G$ the symmetric difference $X\triangle Y$ has nonzero measure. Is $\bigcap G$ necessarily measurable and, if so, does it have measure at least $1-\varepsilon$? Both questions are easily seen to have a positive answer if $G$ is countable, but we make no such assumption here. What I have tried to do is to approximate the elements of $G$ from below by compact sets and then trying to show that this derived family of compact sets has the finite intersection property. I can't quite get it to work, but this would at least show that $\bigcap G$ is nonempty. Then again, I'm not sure how this would help in answering the actual questions.",,"['measure-theory', 'set-theory']"
69,Generated semiring,Generated semiring,,"In Pap E., Handbook of Measure Theory, Vol.1 (Elsevier), p.30, ""For any class $\mathcal{F}$ of subsets of $S$ [$S$ is a non-empty base set] there is a smallest semiring containing $\mathcal{F}$, and called the semiring generated by $\mathcal{F}$.""  Since the intersection of semirings is not necessarily semiring (see is-the-intersection-of-an-arbitrary-collection-of-semirings-a-semiring ), the usual method that works for rings (etc.) in this case not works. So (a) it can be proved by a different method (b) there is a counterexample.  Can someone give detailed answer?","In Pap E., Handbook of Measure Theory, Vol.1 (Elsevier), p.30, ""For any class $\mathcal{F}$ of subsets of $S$ [$S$ is a non-empty base set] there is a smallest semiring containing $\mathcal{F}$, and called the semiring generated by $\mathcal{F}$.""  Since the intersection of semirings is not necessarily semiring (see is-the-intersection-of-an-arbitrary-collection-of-semirings-a-semiring ), the usual method that works for rings (etc.) in this case not works. So (a) it can be proved by a different method (b) there is a counterexample.  Can someone give detailed answer?",,"['real-analysis', 'measure-theory', 'elementary-set-theory']"
70,Layer-Cake for general functions,Layer-Cake for general functions,,The Layer-Cake representation of a non-negative measureable function $f:\mathbb{R}^n\longrightarrow \mathbb{R}$ is given by $$f(x) = \int^{\infty}_{0} \mathbb{I}_{\{y\ \in\ \mathbb{R}^n|f(y)>t\}}(x)\ dt$$ Can this be generalized to functions that are not necessarily non-negative. For a non-positive function $-f$ will do. But what about the others?,The Layer-Cake representation of a non-negative measureable function $f:\mathbb{R}^n\longrightarrow \mathbb{R}$ is given by $$f(x) = \int^{\infty}_{0} \mathbb{I}_{\{y\ \in\ \mathbb{R}^n|f(y)>t\}}(x)\ dt$$ Can this be generalized to functions that are not necessarily non-negative. For a non-positive function $-f$ will do. But what about the others?,,"['calculus', 'real-analysis', 'probability', 'measure-theory']"
71,"$E^p$ is a ring, but not a $\sigma$-ring","is a ring, but not a -ring",E^p \sigma,"An interval in $\mathbb{R}^p$ is defined as a set of the form $\{ \vec{x} \in \mathbb{R}^p : \forall i=1,2,...,p \quad a_i \le x_i \le b_i \}$, where the inequalities can be strict or not, and the numbers $a_i,b_i$ are allowed to be infinite. An elementary set is a set which is a union of a finite amount of intervals. The class of all elementary sets is denoted by $E^p$. It is left as a comment in Rudin to verify that $E^p$ is a ring, yet not a $\sigma$-ring, that is a countable union of such sets need not be necessarily elementary. Showing that it's a ring I kind of get (although I don't know if there's a truly simple way of showing that the compliment of an elementary set is elementary), but I'm having trouble thinking up a counterexample to the countable union property...","An interval in $\mathbb{R}^p$ is defined as a set of the form $\{ \vec{x} \in \mathbb{R}^p : \forall i=1,2,...,p \quad a_i \le x_i \le b_i \}$, where the inequalities can be strict or not, and the numbers $a_i,b_i$ are allowed to be infinite. An elementary set is a set which is a union of a finite amount of intervals. The class of all elementary sets is denoted by $E^p$. It is left as a comment in Rudin to verify that $E^p$ is a ring, yet not a $\sigma$-ring, that is a countable union of such sets need not be necessarily elementary. Showing that it's a ring I kind of get (although I don't know if there's a truly simple way of showing that the compliment of an elementary set is elementary), but I'm having trouble thinking up a counterexample to the countable union property...",,"['measure-theory', 'lebesgue-integral']"
72,Why is $\infty-\infty$ undefined in measure theory?,Why is  undefined in measure theory?,\infty-\infty,"Some additions to the title: I stumbled over this problem going through my measure theory lecture notes; the author explicitly mentions that he leaves $\infty-\infty$ undefined. I would like to know what goes wrong, if I would define $l:=\infty-\infty$ for $l\in\overline{\mathbb{R}}$. I tried to derive contradictions by playing with arithmetical rules in $\overline{\mathbb{R}}$ but couldn't obtain a contradiction. Here's an example where I merely try to obtain a contradiction by   assuming that $r:=\infty-\infty\in\mathbb{R}$ (as opposed to   $\overline{\mathbb{R}}$). \begin{eqnarray*}  & \infty=\infty\\ \Rightarrow & \infty=\infty+2\\ > \Rightarrow & > \infty+\left(-\infty\right)=\left(\infty+2\right)+\left(-\infty\right) > \end{eqnarray*} an here the attempt breaks down, since this extended   addition doesn't have to be associative, so one can't conclude   \begin{eqnarray*} \Rightarrow & r=r+2\\ \Rightarrow & 0=2.  \end{eqnarray*} EDIT A lot of people gave me answers in which they motivated why $\infty-\infty$ doesn't make sense. This is not what I'm looking for! Motivations are nice, but only a concrete contradiction gives certainty that it absolutely makes no sense to assign a number, or $\pm \infty$ to the above expression.","Some additions to the title: I stumbled over this problem going through my measure theory lecture notes; the author explicitly mentions that he leaves $\infty-\infty$ undefined. I would like to know what goes wrong, if I would define $l:=\infty-\infty$ for $l\in\overline{\mathbb{R}}$. I tried to derive contradictions by playing with arithmetical rules in $\overline{\mathbb{R}}$ but couldn't obtain a contradiction. Here's an example where I merely try to obtain a contradiction by   assuming that $r:=\infty-\infty\in\mathbb{R}$ (as opposed to   $\overline{\mathbb{R}}$). \begin{eqnarray*}  & \infty=\infty\\ \Rightarrow & \infty=\infty+2\\ > \Rightarrow & > \infty+\left(-\infty\right)=\left(\infty+2\right)+\left(-\infty\right) > \end{eqnarray*} an here the attempt breaks down, since this extended   addition doesn't have to be associative, so one can't conclude   \begin{eqnarray*} \Rightarrow & r=r+2\\ \Rightarrow & 0=2.  \end{eqnarray*} EDIT A lot of people gave me answers in which they motivated why $\infty-\infty$ doesn't make sense. This is not what I'm looking for! Motivations are nice, but only a concrete contradiction gives certainty that it absolutely makes no sense to assign a number, or $\pm \infty$ to the above expression.",,"['measure-theory', 'definition']"
73,"Is it neccessarily the case that $f$ is measurable, if it's measurable in each variable?","Is it neccessarily the case that  is measurable, if it's measurable in each variable?",f,"A well-known example of a function that is continuous in each variable but fails to be jointly continuous is: $$ f(x,y) = \begin{cases}        \frac{xy}{x^2 + y^2} & (x,y) \neq (0,0) \\       0 & (x,y) = (0,0) \\    \end{cases} $$ Question$1$: Is this function ""jointly"" measurable? It seems to me it suffices to ask whether the preimage of each element in the $\pi$-system that generates $\mathcal B(\Bbb R)$ is measurable. Thus it reduces to whether $f^{-1}((-\infty,a])$ is measurable and it is(union of a Borel set and a singleton, or the relative complement of a singleton with respect to a Borel set). Question$2$ : Given $f :  X \times Y \to Z$. For each $x_0 \in X$, $f(x_0,\cdot): Y \to Z$ is a measurable function, and for each $y_0 \in Y$, $f(\cdot, y_0): X \to Z$ is also a measurable function. Is it neccessarily the case that $f$ is measurable?","A well-known example of a function that is continuous in each variable but fails to be jointly continuous is: $$ f(x,y) = \begin{cases}        \frac{xy}{x^2 + y^2} & (x,y) \neq (0,0) \\       0 & (x,y) = (0,0) \\    \end{cases} $$ Question$1$: Is this function ""jointly"" measurable? It seems to me it suffices to ask whether the preimage of each element in the $\pi$-system that generates $\mathcal B(\Bbb R)$ is measurable. Thus it reduces to whether $f^{-1}((-\infty,a])$ is measurable and it is(union of a Borel set and a singleton, or the relative complement of a singleton with respect to a Borel set). Question$2$ : Given $f :  X \times Y \to Z$. For each $x_0 \in X$, $f(x_0,\cdot): Y \to Z$ is a measurable function, and for each $y_0 \in Y$, $f(\cdot, y_0): X \to Z$ is also a measurable function. Is it neccessarily the case that $f$ is measurable?",,['measure-theory']
74,"$f$ measurable, $f=g$ almost everywhere, complete measure space [duplicate]","measurable,  almost everywhere, complete measure space [duplicate]",f f=g,"This question already has an answer here : Counterexample for a non-measurable function? (1 answer) Closed 10 years ago . Let $X$ be a nonempty set, $\mathcal{X}$ a $\sigma$-algebra of subsets of $X$, and $\mu$ a measure on $\mathcal{X}$ (i.e., $\mu:X\to[0,+\infty]$, $\mu(\phi)=0$, and $\mu$ is countably additive. Proposition: If $f:X\to R$ is a measurable function, $f=g$ almost everywhere, then $g$ is a measurable function. Can this proposition be proved in the the measure space is not complete ($\mathcal{X}$ contains all subsets of measure zero)? If not, can someone provide a counterexample? Thanks.","This question already has an answer here : Counterexample for a non-measurable function? (1 answer) Closed 10 years ago . Let $X$ be a nonempty set, $\mathcal{X}$ a $\sigma$-algebra of subsets of $X$, and $\mu$ a measure on $\mathcal{X}$ (i.e., $\mu:X\to[0,+\infty]$, $\mu(\phi)=0$, and $\mu$ is countably additive. Proposition: If $f:X\to R$ is a measurable function, $f=g$ almost everywhere, then $g$ is a measurable function. Can this proposition be proved in the the measure space is not complete ($\mathcal{X}$ contains all subsets of measure zero)? If not, can someone provide a counterexample? Thanks.",,['measure-theory']
75,exercise on uniform integrability,exercise on uniform integrability,,"I cannot figure out the following exercise: Let $F$ be the family of functions $f$ on $[0,1]$, each of which is (Lebesgue) integrable over $[0,1]$ and has $\int_a^b|f|\le b-a$ for all $[a,b]\subseteq[0,1]$. Is $F$ uniformly integrable over $[0,1]$?","I cannot figure out the following exercise: Let $F$ be the family of functions $f$ on $[0,1]$, each of which is (Lebesgue) integrable over $[0,1]$ and has $\int_a^b|f|\le b-a$ for all $[a,b]\subseteq[0,1]$. Is $F$ uniformly integrable over $[0,1]$?",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'uniform-integrability']"
76,"Product of two functions converging in $L^1(X,\mu)$",Product of two functions converging in,"L^1(X,\mu)","Let $f_n\to f$ in $L^1(X,\mu)$, $\mu(X)<\infty$, and let $\{g_n\}$ be a sequence of measurable functions such that $|g_n|\le M<\infty\ \forall n$ with some constant $M$, and $g_n\to g$ almost everywhere. Prove that $g_nf_n\to gf$ in $L^1(X,\mu)$. This is a question from one of my past papers, but unfortunately there is no solution provided. Here is as far as I have gotten: $$\int|gf-g_nf_n|=\int|(f-f_n)g_n+(g-g_n)f|\le\int|f-f_n||g_n|+\int|g-g_n||f|$$ $$\le M\int|f-f_n|+\int|g-g_n||f|$$ We know that $f_n\to f$ in $L^1$, so $\int|f-f_n|\to 0$, and by Lebesgue's bounded convergence theorem it follows that $\int|g-g_n|\to 0$. But I am unsure whether this also implies $\int|g-g_n||f|\to0$.","Let $f_n\to f$ in $L^1(X,\mu)$, $\mu(X)<\infty$, and let $\{g_n\}$ be a sequence of measurable functions such that $|g_n|\le M<\infty\ \forall n$ with some constant $M$, and $g_n\to g$ almost everywhere. Prove that $g_nf_n\to gf$ in $L^1(X,\mu)$. This is a question from one of my past papers, but unfortunately there is no solution provided. Here is as far as I have gotten: $$\int|gf-g_nf_n|=\int|(f-f_n)g_n+(g-g_n)f|\le\int|f-f_n||g_n|+\int|g-g_n||f|$$ $$\le M\int|f-f_n|+\int|g-g_n||f|$$ We know that $f_n\to f$ in $L^1$, so $\int|f-f_n|\to 0$, and by Lebesgue's bounded convergence theorem it follows that $\int|g-g_n|\to 0$. But I am unsure whether this also implies $\int|g-g_n||f|\to0$.",,"['measure-theory', 'convergence-divergence']"
77,A Borel measurable function which is not continuous,A Borel measurable function which is not continuous,,I want to find a example of Borel measurable function which is not continuous. I think that it is a simple or step function or semicontinuous function. Please help me for find it. Thanks.,I want to find a example of Borel measurable function which is not continuous. I think that it is a simple or step function or semicontinuous function. Please help me for find it. Thanks.,,"['real-analysis', 'measure-theory']"
78,An identity involving Radon-Nikodym derivatives,An identity involving Radon-Nikodym derivatives,,"The following result was stated without proof in [HAL] (note 4 to section 32 ""Derivatives of Signed Measures"", p. 136). If $\mu_0$, $\mu_1$, and $\mu_2$ are finite measures, and if $$ \begin{array}{lcl} f_1 & = & \frac{d\mu_0}{d\left(\mu_0+\mu_1\right)} \\ f_2 & = & \frac{d\mu_0}{d\left(\mu_0+\mu_2\right)} \\ f & = & \frac{d\mu_0}{d\left(\mu_0+\mu_1+\mu_2\right)} \end{array} $$ then we have $\left(\mu_0+\mu_1+\mu_2\right)$-a.e., $$ f(x) =  \begin{cases} \frac{f_1(x)f_2(x)}{f_1(x)+f_2(x)-f_1(x)f_2(x)} &\mbox{if }f_1(x)f_2(x)\neq0,\\ 0 &\mbox{if }f_1(x)=f_2(x)=0 \end{cases} \space\space\mbox{(Alexander)} $$ An intuitive, symbolic proof was suggested by postmortes in another thread : Write $$ \begin{array}{lcl} d\mu_0 & = & f_1 d\left(\mu_0+\mu_1\right)\space\space\mbox{(Gary)} \\ d\mu_0 & = & f_2 d\left(\mu_0+\mu_2\right)\space\space\mbox{(Terrence)}\\ d\mu_0 & = & f d\left(\mu_0+\mu_1+\mu_2\right)\space\space\mbox{(Leon)} \end{array} $$ Multiply (Gary) and (Terrence) throughout by $f_2$ and $f_1$, respectively, to obtain $$ \begin{array}{lcl} f_2d\mu_0 & = & f_1f_2 d\left(\mu_0+\mu_1\right) \\ f_1d\mu_0 & = & f_1f_2 d\left(\mu_0+\mu_2\right) \end{array} $$ Add up to obtain $$ (f_1+f_2)d\mu_0= 2f_1f_2d\mu_0 + f_1f_2d\mu_2 + f_1f_2d\mu_1 $$ Subtract $f_1f_2d\mu_0$ from both sides to obtain $$ \left(f_1 + f_2 - f_1f_2\right)d\mu_0 = f_1f_2d\left(\mu_0 + \mu_1 +\mu_2\right) $$ Finally divide both sides by $d\left(\mu_0+\mu_1+\mu_2\right)$ and use (Leon) to obtain (Alexander). Unfortunately, i fail to see how to turn these symbolic manipulations into a rigorous argument. Any help will be welcome. References [HAL] Halmos, Paul Richard. ""Measure Theory"". Springer-Verlag, 1974.","The following result was stated without proof in [HAL] (note 4 to section 32 ""Derivatives of Signed Measures"", p. 136). If $\mu_0$, $\mu_1$, and $\mu_2$ are finite measures, and if $$ \begin{array}{lcl} f_1 & = & \frac{d\mu_0}{d\left(\mu_0+\mu_1\right)} \\ f_2 & = & \frac{d\mu_0}{d\left(\mu_0+\mu_2\right)} \\ f & = & \frac{d\mu_0}{d\left(\mu_0+\mu_1+\mu_2\right)} \end{array} $$ then we have $\left(\mu_0+\mu_1+\mu_2\right)$-a.e., $$ f(x) =  \begin{cases} \frac{f_1(x)f_2(x)}{f_1(x)+f_2(x)-f_1(x)f_2(x)} &\mbox{if }f_1(x)f_2(x)\neq0,\\ 0 &\mbox{if }f_1(x)=f_2(x)=0 \end{cases} \space\space\mbox{(Alexander)} $$ An intuitive, symbolic proof was suggested by postmortes in another thread : Write $$ \begin{array}{lcl} d\mu_0 & = & f_1 d\left(\mu_0+\mu_1\right)\space\space\mbox{(Gary)} \\ d\mu_0 & = & f_2 d\left(\mu_0+\mu_2\right)\space\space\mbox{(Terrence)}\\ d\mu_0 & = & f d\left(\mu_0+\mu_1+\mu_2\right)\space\space\mbox{(Leon)} \end{array} $$ Multiply (Gary) and (Terrence) throughout by $f_2$ and $f_1$, respectively, to obtain $$ \begin{array}{lcl} f_2d\mu_0 & = & f_1f_2 d\left(\mu_0+\mu_1\right) \\ f_1d\mu_0 & = & f_1f_2 d\left(\mu_0+\mu_2\right) \end{array} $$ Add up to obtain $$ (f_1+f_2)d\mu_0= 2f_1f_2d\mu_0 + f_1f_2d\mu_2 + f_1f_2d\mu_1 $$ Subtract $f_1f_2d\mu_0$ from both sides to obtain $$ \left(f_1 + f_2 - f_1f_2\right)d\mu_0 = f_1f_2d\left(\mu_0 + \mu_1 +\mu_2\right) $$ Finally divide both sides by $d\left(\mu_0+\mu_1+\mu_2\right)$ and use (Leon) to obtain (Alexander). Unfortunately, i fail to see how to turn these symbolic manipulations into a rigorous argument. Any help will be welcome. References [HAL] Halmos, Paul Richard. ""Measure Theory"". Springer-Verlag, 1974.",,['measure-theory']
79,What does the notation mean?,What does the notation mean?,,"Given a measure space $(\Omega,\mathcal{F},\upsilon)$ and a $p>0$. What does the following mean? $$ \|f\|_p=(\upsilon|f|^p)^{1/p}$$","Given a measure space $(\Omega,\mathcal{F},\upsilon)$ and a $p>0$. What does the following mean? $$ \|f\|_p=(\upsilon|f|^p)^{1/p}$$",,"['measure-theory', 'notation']"
80,$\int_Ef>\int f−\epsilon$,,\int_Ef>\int f−\epsilon,"Show that if $f\in L^+$ and $\int f<\infty$ then, for every $\epsilon>0$, there exists $E\in M$ such that $\mu(E)<\infty$ and $\int_Ef>\int f−\epsilon$. I can somewhat understand why this should be true - mainly by the definition of integrals involving $\sup\{\int\phi\}$, where $\phi$ is a simple function. But how do you go about writing a rigorous proof of this?","Show that if $f\in L^+$ and $\int f<\infty$ then, for every $\epsilon>0$, there exists $E\in M$ such that $\mu(E)<\infty$ and $\int_Ef>\int f−\epsilon$. I can somewhat understand why this should be true - mainly by the definition of integrals involving $\sup\{\int\phi\}$, where $\phi$ is a simple function. But how do you go about writing a rigorous proof of this?",,['measure-theory']
81,Inequalities between Gauss and Lebesgue measures,Inequalities between Gauss and Lebesgue measures,,"Consider $[0,1]$ and let $\mu$ be the lebesgue measure and $\lambda$ be Gauss's measure: $\lambda(B)=\int_B \frac{1}{1+x}dx$ I want to show that there exists positive constants $a$ and $A$ such that $$a \mu(B) \leq \lambda(B) \leq A \mu(B)$$ for all Lebesgue measurable sets $B$. Now, the right hand side inequality is easy after noting that $\frac{1}{1+x} \leq 1 $ for all $x \in [0,1]$, we get $A=1$. But what about the left hand side inequality? I thought about proving it for intervals and then using that every Lebesgue measurable set can be approximated by a union of intervals. Does this make sense? However, if this method of proof was ok and I considered the interval $[a,b]$, I would still need to prove that $$f(a,b) = \frac{\ln(\frac{1+b}{1+a})}{b-a}$$ is bounded below by something strictly greater than $0$ in the triangle with vertices $(0,0), (0,1)$ and $(1,1)$. Welcome any thoughts, comments, ideas, etc. Thanks as usual!","Consider $[0,1]$ and let $\mu$ be the lebesgue measure and $\lambda$ be Gauss's measure: $\lambda(B)=\int_B \frac{1}{1+x}dx$ I want to show that there exists positive constants $a$ and $A$ such that $$a \mu(B) \leq \lambda(B) \leq A \mu(B)$$ for all Lebesgue measurable sets $B$. Now, the right hand side inequality is easy after noting that $\frac{1}{1+x} \leq 1 $ for all $x \in [0,1]$, we get $A=1$. But what about the left hand side inequality? I thought about proving it for intervals and then using that every Lebesgue measurable set can be approximated by a union of intervals. Does this make sense? However, if this method of proof was ok and I considered the interval $[a,b]$, I would still need to prove that $$f(a,b) = \frac{\ln(\frac{1+b}{1+a})}{b-a}$$ is bounded below by something strictly greater than $0$ in the triangle with vertices $(0,0), (0,1)$ and $(1,1)$. Welcome any thoughts, comments, ideas, etc. Thanks as usual!",,['measure-theory']
82,Why is $\{x:f(x)\ge a\}=\bigcap_{n=1}^\infty\{x: f(x)\gt a-\frac{1}{n}\}$ and $\{x: f(x)\gt a\}=\bigcup_{n=1}^\infty\{x: f(x)\ge a+\frac{1}{n}\}$?,Why is  and ?,\{x:f(x)\ge a\}=\bigcap_{n=1}^\infty\{x: f(x)\gt a-\frac{1}{n}\} \{x: f(x)\gt a\}=\bigcup_{n=1}^\infty\{x: f(x)\ge a+\frac{1}{n}\},"It is known from measure theory that for all $a \in \mathbb{R}$, the following are equivalent: $f$ is measurable. The set $\{x : f(x) \ge a\}$ is measurable. The set $\{x : f(x) \gt a\}$ is measurable. In virtually all textbooks, for the proof of the above is as follows: $2 \rightarrow 3$: $\{x : f(x) \ge a\} = \bigcap_{n=1}^{\infty}\{x: f(x) \gt a - \frac{1}{n}\}$ $3 \rightarrow 2$: $\{x : f(x) \gt a\} = \bigcup_{n=1}^{\infty}\{x: f(x) \ge a + \frac{1}{n}\}$ Can someone clarify as to why those equalities above hold? I'm having difficult picturing it. For instance, why is: $$\bigcup_{n=1}^{\infty}\{x: f(x) \ge a + \tfrac{1}{n}\} = \{x : f(x) \ge a + 1\} \cup\cdots \cup \{x: f(x) \ge a\}$$ equal to: $\{x: f(x) \gt a\}$ and NOT: $\{x: f(x) \ge a\}$?","It is known from measure theory that for all $a \in \mathbb{R}$, the following are equivalent: $f$ is measurable. The set $\{x : f(x) \ge a\}$ is measurable. The set $\{x : f(x) \gt a\}$ is measurable. In virtually all textbooks, for the proof of the above is as follows: $2 \rightarrow 3$: $\{x : f(x) \ge a\} = \bigcap_{n=1}^{\infty}\{x: f(x) \gt a - \frac{1}{n}\}$ $3 \rightarrow 2$: $\{x : f(x) \gt a\} = \bigcup_{n=1}^{\infty}\{x: f(x) \ge a + \frac{1}{n}\}$ Can someone clarify as to why those equalities above hold? I'm having difficult picturing it. For instance, why is: $$\bigcup_{n=1}^{\infty}\{x: f(x) \ge a + \tfrac{1}{n}\} = \{x : f(x) \ge a + 1\} \cup\cdots \cup \{x: f(x) \ge a\}$$ equal to: $\{x: f(x) \gt a\}$ and NOT: $\{x: f(x) \ge a\}$?",,"['measure-theory', 'elementary-set-theory']"
83,set of critical values is measurable,set of critical values is measurable,,I am reading John Milnor's Topology from a differentiable viewpoint. In Chapter 3 be proves Sard's theorem and claims (page 18) that if $g:R^n\to R^p$ is smooth with set of critical points $C'$ then $g(C')$ is measurable. It is written that this follows from the fact that $g(C')$ can be expressed as a countable union of compact subsets. Can someone explain why $g(C')$ can be expressed in such a way?,I am reading John Milnor's Topology from a differentiable viewpoint. In Chapter 3 be proves Sard's theorem and claims (page 18) that if $g:R^n\to R^p$ is smooth with set of critical points $C'$ then $g(C')$ is measurable. It is written that this follows from the fact that $g(C')$ can be expressed as a countable union of compact subsets. Can someone explain why $g(C')$ can be expressed in such a way?,,"['measure-theory', 'differential-geometry', 'differential-topology']"
84,Countable Sequence of Events,Countable Sequence of Events,,"My Question: Let $(\Omega,\mathcal{F},\textbf{P})$ be a probability triple such that $\Omega$ is ${countable}$. Prove that it is impossible for there to exist a sequence $A_1,A_2,\ldots \in \mathcal{F}$ which is ${independent}$ such that $\textbf{P}(A_i)=\frac{1}{2}$ for each $i$. Hint: First prove that for each $\omega\in \Omega$, and for each $n\in \mathbb{N}$ we have $P(\{\omega\})\leq \frac{1}{2^n}$. Then derive a contradiction. My Work: Let $\omega \in \Omega$ be arbitrary. Then since $\textbf{P}(\Omega)=\textbf{P}(\bigcup \{\omega\})=1$, and $(\Omega,\mathcal{F},\textbf{P})$ is a valid probability triple, then $\textbf{P}$ is countably additive, so that $\textbf{P}(\bigcup \{\omega\})=\sum\limits_{n=1}^\infty \textbf{P}(A_n)$. Here I am not sure where to go.  My problem: I am really not seeing how to go about this problem. Any help is appreciated.","My Question: Let $(\Omega,\mathcal{F},\textbf{P})$ be a probability triple such that $\Omega$ is ${countable}$. Prove that it is impossible for there to exist a sequence $A_1,A_2,\ldots \in \mathcal{F}$ which is ${independent}$ such that $\textbf{P}(A_i)=\frac{1}{2}$ for each $i$. Hint: First prove that for each $\omega\in \Omega$, and for each $n\in \mathbb{N}$ we have $P(\{\omega\})\leq \frac{1}{2^n}$. Then derive a contradiction. My Work: Let $\omega \in \Omega$ be arbitrary. Then since $\textbf{P}(\Omega)=\textbf{P}(\bigcup \{\omega\})=1$, and $(\Omega,\mathcal{F},\textbf{P})$ is a valid probability triple, then $\textbf{P}$ is countably additive, so that $\textbf{P}(\bigcup \{\omega\})=\sum\limits_{n=1}^\infty \textbf{P}(A_n)$. Here I am not sure where to go.  My problem: I am really not seeing how to go about this problem. Any help is appreciated.",,"['probability', 'measure-theory']"
85,Total variation,Total variation,,"I cannot decide if the next function has bounded variation: in the segment $(0,1)$ $$f(x)=\begin{cases} \frac{1}{m^{2} n^{2}},&\text{if $x$ is rational}\\\\ 0,&\text{otherwise}. \end{cases}$$ the rational $x$ is $m/n$ and it is the reduced form. so far  showed  it is not absolute continuous thanks","I cannot decide if the next function has bounded variation: in the segment $(0,1)$ $$f(x)=\begin{cases} \frac{1}{m^{2} n^{2}},&\text{if $x$ is rational}\\\\ 0,&\text{otherwise}. \end{cases}$$ the rational $x$ is $m/n$ and it is the reduced form. so far  showed  it is not absolute continuous thanks",,"['measure-theory', 'lebesgue-integral']"
86,Notation related to the Borel hierarchy,Notation related to the Borel hierarchy,,"I'm reading an article where the author uses many classes in the Borel hierarchy: namely, $\mathcal F_\sigma$, $G_\delta$, $\mathcal F_{\sigma\delta}$, etc. In this context, he mentions the class $\mathcal F\cap\mathcal G$ (no subscripts). Does anyone knows what this notation means?","I'm reading an article where the author uses many classes in the Borel hierarchy: namely, $\mathcal F_\sigma$, $G_\delta$, $\mathcal F_{\sigma\delta}$, etc. In this context, he mentions the class $\mathcal F\cap\mathcal G$ (no subscripts). Does anyone knows what this notation means?",,"['measure-theory', 'notation', 'descriptive-set-theory']"
87,Finite Partitions of the Unit Interval,Finite Partitions of the Unit Interval,,"Does the unit interval have a finite partition $P$ such that no element of $P$ contains an open interval? I would think that the answer is no , because each element of $P$ would have Lebesgue measure zero, but what if the elements of $P$ are not measurable?","Does the unit interval have a finite partition $P$ such that no element of $P$ contains an open interval? I would think that the answer is no , because each element of $P$ would have Lebesgue measure zero, but what if the elements of $P$ are not measurable?",,"['measure-theory', 'elementary-set-theory', 'examples-counterexamples', 'set-partition']"
88,Integration a function of a single variable over a 2-dim measure,Integration a function of a single variable over a 2-dim measure,,"Let $(X,\mathfrak B(X))$ and $(Y,\mathfrak B(Y))$ be two measurable spaces and let $\mu$ be a finite measure on the product $\sigma$-algebra $\mathfrak B(X)\otimes \mathfrak B(Y)$. Let $f:X\to\Bbb R$ be a bounded $\mathfrak B(X)$-measurable function and define $\nu(A) = \mu(A\times Y)$ to be a measure on $\mathfrak B(X)$. How to show that $$   \int_{X\times Y}f(x)\mu(\mathrm dx\times \mathrm dy) = \int_Xf(x)\nu(\mathrm dx). $$ I guess, this is completely trivial, however I couldn't come with a completely formal solution. Perhaps, that shall follow from some change of variables equality and the fact that $\nu$ is a pushforward measure of $\mu$ under the projection $\pi_X$? Or from the fact that $f:X\times Y\to\Bbb R$ is $\mathfrak B(X)\otimes \{\emptyset,Y\}$-measurable function and both measures coincide on this $\sigma$-algebra?","Let $(X,\mathfrak B(X))$ and $(Y,\mathfrak B(Y))$ be two measurable spaces and let $\mu$ be a finite measure on the product $\sigma$-algebra $\mathfrak B(X)\otimes \mathfrak B(Y)$. Let $f:X\to\Bbb R$ be a bounded $\mathfrak B(X)$-measurable function and define $\nu(A) = \mu(A\times Y)$ to be a measure on $\mathfrak B(X)$. How to show that $$   \int_{X\times Y}f(x)\mu(\mathrm dx\times \mathrm dy) = \int_Xf(x)\nu(\mathrm dx). $$ I guess, this is completely trivial, however I couldn't come with a completely formal solution. Perhaps, that shall follow from some change of variables equality and the fact that $\nu$ is a pushforward measure of $\mu$ under the projection $\pi_X$? Or from the fact that $f:X\times Y\to\Bbb R$ is $\mathfrak B(X)\otimes \{\emptyset,Y\}$-measurable function and both measures coincide on this $\sigma$-algebra?",,['measure-theory']
89,"$f,g:\,(X,\mu)\to\mathbb{R}$, $f=g$ a.e then if $g$ is Lebesgue measurable then so if $f$?",",  a.e then if  is Lebesgue measurable then so if ?","f,g:\,(X,\mu)\to\mathbb{R} f=g g f","I have an observation in my real analysis lecture notes that states that if $f,g:\,(X,\mu)\to\mathbb{R}$ (with Borel's -$\sigma$ algebra ) and $f=g$ almost everywhere then if $g$ is Lebesgue measurable then so if $f$. I don't understand why this is true, can someone please explain ? I tried looking at some Borel set and on it source, but I can't figure why if we change $g$ in some measure $0$ of points then the source is still in Lebesgue -$\sigma$ algebra","I have an observation in my real analysis lecture notes that states that if $f,g:\,(X,\mu)\to\mathbb{R}$ (with Borel's -$\sigma$ algebra ) and $f=g$ almost everywhere then if $g$ is Lebesgue measurable then so if $f$. I don't understand why this is true, can someone please explain ? I tried looking at some Borel set and on it source, but I can't figure why if we change $g$ in some measure $0$ of points then the source is still in Lebesgue -$\sigma$ algebra",,"['real-analysis', 'measure-theory']"
90,Showing the Existence of a Finite Measure Open Set,Showing the Existence of a Finite Measure Open Set,,"Let $E \subseteq \mathbb{R}$ s.t. $\mu^*(E) < \infty$ for some outer measure $\mu^*$ on $\mathcal{P(\mathbb{R})}$.  Must there exist an open set $O$ s.t. $O \supseteq E$ and $\mu(O) < \infty$?  What if we let $\mu$ and $\mu^*$ be the Lebesgue Outer Measure and Lebesgue Measure respectively? I'm reading a proof which seems to assume that, at least the case of the Lebesgue setting, there must exist such an $O$.  But I'm thinking that if we let $E = \mathbb{N}$ then $m^*(E) = 0 < \infty$ yet I can't think of an open set $O$ that contains $\mathbb{N}$ with finite outer measure so I'm confused.","Let $E \subseteq \mathbb{R}$ s.t. $\mu^*(E) < \infty$ for some outer measure $\mu^*$ on $\mathcal{P(\mathbb{R})}$.  Must there exist an open set $O$ s.t. $O \supseteq E$ and $\mu(O) < \infty$?  What if we let $\mu$ and $\mu^*$ be the Lebesgue Outer Measure and Lebesgue Measure respectively? I'm reading a proof which seems to assume that, at least the case of the Lebesgue setting, there must exist such an $O$.  But I'm thinking that if we let $E = \mathbb{N}$ then $m^*(E) = 0 < \infty$ yet I can't think of an open set $O$ that contains $\mathbb{N}$ with finite outer measure so I'm confused.",,['measure-theory']
91,extending a measure from a semiring to an algebra,extending a measure from a semiring to an algebra,,"let $\mu: S \to \mathbb{R}  $ be a finite additive measure defined on the semiring $S$. Let $B(S) = $ {$A \subseteq \Omega$ | $A$ or $ A^{\mathsf{c}}$  $\in A(S)$ } $A(S)$ is the ring constructed by disjoint unions of the semiring $S$ (minimal Ring) 1) Show that $B(S)$ is an algebra (contains $\Omega $ and contains $B^\mathsf{c}$, for all B $\in$ $B(S)$. 2)If $A(S)$ is not an algebra, so given any t $\in$ $[-\infty,+\infty]$ show that there is a unique finitelly additive measure $\mu_t : B(S) \to \mathbb{R} \cup $ {$t$} extending $\mu$ such that $\mu_t$  ($\Omega$)= t 3) If $\mu$ is $\sigma$-additive and $\Omega$ $\notin$ { $\cup_{i=1}^\infty S_n$ | $S_n$ $\in S$}, so $\mu_t$ is $\sigma$-additive I already thank you who get involved with the problem .","let $\mu: S \to \mathbb{R}  $ be a finite additive measure defined on the semiring $S$. Let $B(S) = $ {$A \subseteq \Omega$ | $A$ or $ A^{\mathsf{c}}$  $\in A(S)$ } $A(S)$ is the ring constructed by disjoint unions of the semiring $S$ (minimal Ring) 1) Show that $B(S)$ is an algebra (contains $\Omega $ and contains $B^\mathsf{c}$, for all B $\in$ $B(S)$. 2)If $A(S)$ is not an algebra, so given any t $\in$ $[-\infty,+\infty]$ show that there is a unique finitelly additive measure $\mu_t : B(S) \to \mathbb{R} \cup $ {$t$} extending $\mu$ such that $\mu_t$  ($\Omega$)= t 3) If $\mu$ is $\sigma$-additive and $\Omega$ $\notin$ { $\cup_{i=1}^\infty S_n$ | $S_n$ $\in S$}, so $\mu_t$ is $\sigma$-additive I already thank you who get involved with the problem .",,['measure-theory']
92,Inner Measures of Subsets,Inner Measures of Subsets,,"How can I show that for $A \subset B$, it must be true that $m_*(A) \leq m_*(B)$?  That is, the inner measure of A is less than or equal to the inner measure of B ?  I understand how to show a similar proof for the outer measure, but is there an explicit way to show it for inner measure?  Do I just extend the outer measure proof by showing that $\forall A$, $m_*(A) \leq m^*(A)$?  How would I show that this wouldn't then violate the inner measure inequality (if, say, the inner measure of the set differs more greatly from it's outer measure than the subset does.)","How can I show that for $A \subset B$, it must be true that $m_*(A) \leq m_*(B)$?  That is, the inner measure of A is less than or equal to the inner measure of B ?  I understand how to show a similar proof for the outer measure, but is there an explicit way to show it for inner measure?  Do I just extend the outer measure proof by showing that $\forall A$, $m_*(A) \leq m^*(A)$?  How would I show that this wouldn't then violate the inner measure inequality (if, say, the inner measure of the set differs more greatly from it's outer measure than the subset does.)",,"['real-analysis', 'measure-theory']"
93,Sigma Algebras generated by two classes of subsets,Sigma Algebras generated by two classes of subsets,,"If $A_1$ and $A_2$ are two collection of subsets in $\Omega$  (Sample Space), I need to prove that  $$\sigma(A_1) \subseteq \sigma(A_2).$$  I understand that there exist minimal unique $\sigma$-algebras generated by $A_1$ & $A_2$ respectively. However, I am not sure what needs to be demonstrated mathematically, in order to prove the subset status. I tried to construct an example for this. Let A1={1,2} , A2={1,2,3} , Ω={1,2,3,4} Then, σ(A1)={∅,Ω,{1,2},{3,4}} σ(A2)={∅,Ω,{1,2,3},{4}} How can I proceed beyond this. I am confused as how to interpret the subsets as opposed to elements. Appreciate your comments. Thank you.","If $A_1$ and $A_2$ are two collection of subsets in $\Omega$  (Sample Space), I need to prove that  $$\sigma(A_1) \subseteq \sigma(A_2).$$  I understand that there exist minimal unique $\sigma$-algebras generated by $A_1$ & $A_2$ respectively. However, I am not sure what needs to be demonstrated mathematically, in order to prove the subset status. I tried to construct an example for this. Let A1={1,2} , A2={1,2,3} , Ω={1,2,3,4} Then, σ(A1)={∅,Ω,{1,2},{3,4}} σ(A2)={∅,Ω,{1,2,3},{4}} How can I proceed beyond this. I am confused as how to interpret the subsets as opposed to elements. Appreciate your comments. Thank you.",,['measure-theory']
94,Continuous probability measures on the unit circle,Continuous probability measures on the unit circle,,"Is there a continuous probability measure on the unit circle in the complex plane - $\sigma$  with full support, such that $\hat{\sigma}(n_k)\rightarrow1$ as $k\rightarrow\infty$ for some increasing sequence of integers $\ n_k$","Is there a continuous probability measure on the unit circle in the complex plane - $\sigma$  with full support, such that $\hat{\sigma}(n_k)\rightarrow1$ as $k\rightarrow\infty$ for some increasing sequence of integers $\ n_k$",,"['measure-theory', 'fourier-analysis']"
95,Lebesgue measure on Riemann integrable function in $\mathbb{R}^2$,Lebesgue measure on Riemann integrable function in,\mathbb{R}^2,"As mentioned in a few of my other questions, I am new to measure theory and learning it on my own. I came across an interesting exercise and I would be grateful for/interested in any thoughts. Setup: Let $\lambda_2$ be a Lebesgue measure on $\mathbb{R}^2$ such that: $\lambda_2((a,b]$x$(c,d])=(b-a)(d-c)$ for all finite, real $a < b, c < d$. Questions (The exercise mentions parenthetically that these questions can he proven without referring to any results or information beyond what is given): Show $\lambda_2(B$ x $\{a\})$ and $\lambda_2(\{a\}$ x $B)=0$, $a\in\mathbb{R},B\in\mathcal{B}(\mathbb{R})$. For $f(x) \geq 0$ Riemann-integrable on the finite interval [a,b], show that $$\lambda_2(\{(x,y):0\leq y\leq f(x),a\leq x\leq b\})=\int_a^b f(x)dx.$$ For 2., what little I have grasped with measure theory is that in $\mathbb{R}^2$, measure works very similarly to ""area"", but what is tripping me up is the caveat that these assumptions/results are not needed. Any help is greatly appreciated as always.","As mentioned in a few of my other questions, I am new to measure theory and learning it on my own. I came across an interesting exercise and I would be grateful for/interested in any thoughts. Setup: Let $\lambda_2$ be a Lebesgue measure on $\mathbb{R}^2$ such that: $\lambda_2((a,b]$x$(c,d])=(b-a)(d-c)$ for all finite, real $a < b, c < d$. Questions (The exercise mentions parenthetically that these questions can he proven without referring to any results or information beyond what is given): Show $\lambda_2(B$ x $\{a\})$ and $\lambda_2(\{a\}$ x $B)=0$, $a\in\mathbb{R},B\in\mathcal{B}(\mathbb{R})$. For $f(x) \geq 0$ Riemann-integrable on the finite interval [a,b], show that $$\lambda_2(\{(x,y):0\leq y\leq f(x),a\leq x\leq b\})=\int_a^b f(x)dx.$$ For 2., what little I have grasped with measure theory is that in $\mathbb{R}^2$, measure works very similarly to ""area"", but what is tripping me up is the caveat that these assumptions/results are not needed. Any help is greatly appreciated as always.",,['measure-theory']
96,Prove Continuous functions are borel functions,Prove Continuous functions are borel functions,,"Take $f: (a,b) \to \mathbb{R}$ , continuous for all $x_{0}\in (a,b)$ and take $(Ω = (a,b) , F = ( (a,b) ⋂  B(\mathbb{R}))$ where $B(\mathbb{R})$ is the Borel $\sigma$-algebra. Prove $f$ is a borel function by showing that $\{x \in(a,b): f(x) < c \}$ is in $F$. I know that continuity of f means that for all $x\in(a,b)$ and all $\varepsilon>0$ there exists a $\delta>0$ such that $|x-x_{0}| < \delta$ implies $|f(x)-f(x_{0})| < \varepsilon$. But Then I am stuck, how would I use these facts to help me ? Thanks in advance for any help","Take $f: (a,b) \to \mathbb{R}$ , continuous for all $x_{0}\in (a,b)$ and take $(Ω = (a,b) , F = ( (a,b) ⋂  B(\mathbb{R}))$ where $B(\mathbb{R})$ is the Borel $\sigma$-algebra. Prove $f$ is a borel function by showing that $\{x \in(a,b): f(x) < c \}$ is in $F$. I know that continuity of f means that for all $x\in(a,b)$ and all $\varepsilon>0$ there exists a $\delta>0$ such that $|x-x_{0}| < \delta$ implies $|f(x)-f(x_{0})| < \varepsilon$. But Then I am stuck, how would I use these facts to help me ? Thanks in advance for any help",,['measure-theory']
97,Understanding Fatou's lemma,Understanding Fatou's lemma,,"I want to prove that (without using Fatou's lemma) for every $k \in N$ let $f_k$ be a nonnegative sequence $f_k(1),f_k(2),\ldots$ $$\sum^\infty_{n=1}\liminf_{k \to \infty} f_k(n) \le \liminf_{k \to \infty} \sum^\infty_{n=1}f_k(n)$$ Can you give some hint for me about that? hat","I want to prove that (without using Fatou's lemma) for every $k \in N$ let $f_k$ be a nonnegative sequence $f_k(1),f_k(2),\ldots$ $$\sum^\infty_{n=1}\liminf_{k \to \infty} f_k(n) \le \liminf_{k \to \infty} \sum^\infty_{n=1}f_k(n)$$ Can you give some hint for me about that? hat",,['measure-theory']
98,How to compute $\lim_{\beta\to \infty} \beta \mu(f \geq \beta)$?,How to compute ?,\lim_{\beta\to \infty} \beta \mu(f \geq \beta),"Let $(X, \Omega, \mu)$ be a measure space. Given that $f(x) = \frac{1}{x(1-\log x)}$, on $[0,1]$, how can I compute $\lim_{\beta\to \infty} \beta \mu(f \geq \beta)$?","Let $(X, \Omega, \mu)$ be a measure space. Given that $f(x) = \frac{1}{x(1-\log x)}$, on $[0,1]$, how can I compute $\lim_{\beta\to \infty} \beta \mu(f \geq \beta)$?",,['measure-theory']
99,Deriving Cauchy's inequality with Fubini's theorem,Deriving Cauchy's inequality with Fubini's theorem,,"The exercise is the following: Let $f,g: X \to \mathbb K$ be two measurable functions such that $|f|^2, |g|^2 \in \mathcal L^1$. Making use of Fubini's theorem and by considering the function $$(x,y) \mapsto |f(x)g(x) f(y) g(y)|$$   derive Cauchy's inequality:   $$\left(\int_X |fg|\, d\mu \right)^2 \le \left(\int_X |f|^2 \, d\mu \right)\left(\int_X |g|^2\, d\mu\right)$$ I can prove that $\int_{X\times X} |f(x)g(x)f(y)g(y)| \, d(\mu\otimes \mu)= \left(\int_X |fg|\, d\mu\right)^2$ by an application of Fubini with $A = \{f\ne 0\}\cup \{g\ne 0\}$, which is $\sigma$-finite, since it can be written as a union $$A = \bigcup_{n = 1}^\infty (\{|f|^2>1/n\}\cup\{|g|^2\ge 1/n\})$$ where all sets on the RHS have to have finite measure, since $f,g \in L^2$. So $$ \begin{align*} \int_{X\times X} |f(x)g(x)f(y)g(y)| \, d(\mu\otimes \mu) &= \int_{A\times A} |f(x)g(x)f(y)g(y)| \, d(\mu\otimes \mu) \\ &= \left(\int_A |fg|\, d\mu\right)^2 \\ &= \left(\int_X |fg|\, d\mu\right)^2 \end{align*} $$ But I don't really see how to prove $$\int_{X\times X} |f(x)g(x)f(y)g(y)| \, d(\mu\otimes \mu)\le \left(\int_X |f|^2 \, d\mu\right)\left( \int_X |g|^2\, d\mu\right)$$ without making use of Young's inequality (or AM-GM). I think one should be able to see this last inequality directly somehow. Why I don't want to use AM-GM: The derivation in this exercise should probably be an alternative to the usual one, where one integrates $$\frac{|fg|}{\Vert f\Vert_2 \Vert g\Vert_2} \le \frac12 \left(\frac{|f|^2}{\Vert f\Vert_2^2}+\frac{|g|^2}{\Vert g \Vert_2^2}\right)$$ Some help would be very much appreciated, thanks! =)","The exercise is the following: Let $f,g: X \to \mathbb K$ be two measurable functions such that $|f|^2, |g|^2 \in \mathcal L^1$. Making use of Fubini's theorem and by considering the function $$(x,y) \mapsto |f(x)g(x) f(y) g(y)|$$   derive Cauchy's inequality:   $$\left(\int_X |fg|\, d\mu \right)^2 \le \left(\int_X |f|^2 \, d\mu \right)\left(\int_X |g|^2\, d\mu\right)$$ I can prove that $\int_{X\times X} |f(x)g(x)f(y)g(y)| \, d(\mu\otimes \mu)= \left(\int_X |fg|\, d\mu\right)^2$ by an application of Fubini with $A = \{f\ne 0\}\cup \{g\ne 0\}$, which is $\sigma$-finite, since it can be written as a union $$A = \bigcup_{n = 1}^\infty (\{|f|^2>1/n\}\cup\{|g|^2\ge 1/n\})$$ where all sets on the RHS have to have finite measure, since $f,g \in L^2$. So $$ \begin{align*} \int_{X\times X} |f(x)g(x)f(y)g(y)| \, d(\mu\otimes \mu) &= \int_{A\times A} |f(x)g(x)f(y)g(y)| \, d(\mu\otimes \mu) \\ &= \left(\int_A |fg|\, d\mu\right)^2 \\ &= \left(\int_X |fg|\, d\mu\right)^2 \end{align*} $$ But I don't really see how to prove $$\int_{X\times X} |f(x)g(x)f(y)g(y)| \, d(\mu\otimes \mu)\le \left(\int_X |f|^2 \, d\mu\right)\left( \int_X |g|^2\, d\mu\right)$$ without making use of Young's inequality (or AM-GM). I think one should be able to see this last inequality directly somehow. Why I don't want to use AM-GM: The derivation in this exercise should probably be an alternative to the usual one, where one integrates $$\frac{|fg|}{\Vert f\Vert_2 \Vert g\Vert_2} \le \frac12 \left(\frac{|f|^2}{\Vert f\Vert_2^2}+\frac{|g|^2}{\Vert g \Vert_2^2}\right)$$ Some help would be very much appreciated, thanks! =)",,"['real-analysis', 'measure-theory']"
