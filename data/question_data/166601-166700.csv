,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,What is Expected Prediction Error (EPE) a function of?,What is Expected Prediction Error (EPE) a function of?,,"Context I am self-studying Elements of Statistical Learning (2nd ed), by Friedman, Hastie & Tibshirani. I have a question with regards to what the EPE, as defined in this text, is a function of. Namely, on page 10 (equation 2.9), EPE is defined as: $\text{EPE}(f) = \text{E}_{X, Y}(Y - f(X))^2$ This implies that EPE is a function of the learner, $f$, and that it is an expectation over the joint distribution of $X$ and $Y$. I accept and understand this definition, since it distinguishes EPE from mean squared error (MSE), which is defined for some $x_0 \in \Omega_X$ as: $\text{MSE}(x_0) = \text{E}_{\mathcal{T}}(y_0 - \hat{f}(x_0))^2$ Where $\mathcal{T}$ represents the training set, and $\hat{f}$ represents the corresponding learner. Note that the above equation assumes the relationship between $X$ and $Y$ is deterministic -- $y_0$ is assumed to be a constant. Question Where my confusion arises is in the use of EPE on page 18 (equation 2.27). The context of its use is this: the relationship between $Y$ (the dependent variable) and $X$ (the independent variable) is assumed to be linear in $X$: $Y = X^T\beta + \epsilon$, where $\epsilon \sim \mathcal{N}(0, \sigma^2)$ independently of $X$. Then, for some arbitrary test point $x_0$, equation 2.27 is stated in the following manner: $\text{EPE}(x_0) = \text{E}_{y_0|x_0}\text{E}_{\mathcal{T}}(y_0 - \hat{y}_0)^2$, where $\mathcal{T}$ is the training set. My issue with the above is that I cannot see how the use of EPE in equation 2.27 is equivalent to that of equation 2.9; is there a way to show that they are? Or is the latter notation incorrect, and EPE is only a function of the learner? Related question I have just taken a look at the ""related questions"" after posting this one, and have found the following question . It appears to express a similar sentiment as mine. The accepted answer, as I understand it, seemingly implies the usage of EPE in equation 2.27 is inconsistent. If this is the case, and the two usages cannot be consolidated, I suppose this question can be taken down as a duplicate (? New here.).","Context I am self-studying Elements of Statistical Learning (2nd ed), by Friedman, Hastie & Tibshirani. I have a question with regards to what the EPE, as defined in this text, is a function of. Namely, on page 10 (equation 2.9), EPE is defined as: $\text{EPE}(f) = \text{E}_{X, Y}(Y - f(X))^2$ This implies that EPE is a function of the learner, $f$, and that it is an expectation over the joint distribution of $X$ and $Y$. I accept and understand this definition, since it distinguishes EPE from mean squared error (MSE), which is defined for some $x_0 \in \Omega_X$ as: $\text{MSE}(x_0) = \text{E}_{\mathcal{T}}(y_0 - \hat{f}(x_0))^2$ Where $\mathcal{T}$ represents the training set, and $\hat{f}$ represents the corresponding learner. Note that the above equation assumes the relationship between $X$ and $Y$ is deterministic -- $y_0$ is assumed to be a constant. Question Where my confusion arises is in the use of EPE on page 18 (equation 2.27). The context of its use is this: the relationship between $Y$ (the dependent variable) and $X$ (the independent variable) is assumed to be linear in $X$: $Y = X^T\beta + \epsilon$, where $\epsilon \sim \mathcal{N}(0, \sigma^2)$ independently of $X$. Then, for some arbitrary test point $x_0$, equation 2.27 is stated in the following manner: $\text{EPE}(x_0) = \text{E}_{y_0|x_0}\text{E}_{\mathcal{T}}(y_0 - \hat{y}_0)^2$, where $\mathcal{T}$ is the training set. My issue with the above is that I cannot see how the use of EPE in equation 2.27 is equivalent to that of equation 2.9; is there a way to show that they are? Or is the latter notation incorrect, and EPE is only a function of the learner? Related question I have just taken a look at the ""related questions"" after posting this one, and have found the following question . It appears to express a similar sentiment as mine. The accepted answer, as I understand it, seemingly implies the usage of EPE in equation 2.27 is inconsistent. If this is the case, and the two usages cannot be consolidated, I suppose this question can be taken down as a duplicate (? New here.).",,"['statistics', 'terminology', 'statistical-inference', 'descriptive-statistics']"
1,"Approximating a multinomial as $p(\xi_1,\ldots,\xi_N)\propto\exp\left(-\frac{n}{2}\sum_{i=1}^N\frac{(\xi_i-p_i)^2}{p_i}\right)$",Approximating a multinomial as,"p(\xi_1,\ldots,\xi_N)\propto\exp\left(-\frac{n}{2}\sum_{i=1}^N\frac{(\xi_i-p_i)^2}{p_i}\right)","Question Suppose we have a multinomial distribution with $N$ possible outcomes, with probabilities $p_1,\ldots,p_N$. We sample this $n$ times, and denote the observed frequency of the $i$th outcome as $\xi_i$. In [1] the author claims that the distribution of the $\xi_i$ in the limit of large $n$ is: $$p(\xi_1,\ldots,\xi_N)\propto\exp\left(-\frac{n}{2}\sum_{i=1}^N\frac{(\xi_i-p_i)^2}{p_i}\right).\;\;\;\;\;(1)$$ We can see immediately that this must be an approximation, as it assigns nonzero probabilities for $\xi_1+\cdots+\xi_N>1$. However we can see that these have vanishing probability in the limit $n\rightarrow\infty$. My question is how do we derive (1) from the multinomial distribution, and show that they match in the $n\rightarrow\infty$ limit? My thoughts My first thought would be to appeal to the central limit theorem. The multinomial distribution has mean $\mu_i=p_i$ and covariance matrix $\Sigma_{ij}=\delta_{ij}p_i-p_ip_j$, so we would expect this in the large $n$ limit to be described by a multivariate Gaussian with mean $\mu$ and covariance $\frac{1}{n}\Sigma$. However, things are complicated by the fact that the multinomial covariance is singular (since $\xi_N$ is determined by the other $\xi_i$s), and so the multivariate Gaussian is not defined. To address this, we may try and consider only the first $\xi_1,\ldots,\xi_{N-1}$, which have a non-singular covariance matrix and hence well-defined multivariate Gaussian distribution. Let's take the Binomial distribution $N=2$. The frequency $\xi_1$, this has mean $p_1$ and variance $p_1(1-p_1)$, so this would be described the the Gaussian: $$\propto\exp\left(-\frac{n}{2}\frac{(\xi_1-p_1)^2}{p_1(1-p_1)}\right).\;\;\;\;\;(2)$$ The expression (1) gives: $$\propto\exp\left(-\frac{n}{2}\left(\frac{(\xi_1-p_1)^2}{p_1}+\frac{(\xi_2-p_2)^2}{p_2}\right)\right).\;\;\;\;\;(3)$$ If we substitute $\xi_2\rightarrow 1-\xi_1$, $p_2\rightarrow 1-p_1$ into (3), we can verify that this gives the same answer as (2). I have verified that this also works for $N=4$. I'm sure that if I just bashed out the algebra for general $N$ we would get agreement between the central limit theorem and (1) when we restrict the latter to $\xi_1+\cdots+\xi_N=1,p_1+\cdots+p_N=1$. However, how can we start with the multinomial distribution and derive (1) as a limit which is valid everywhere? One idea would be to say that (1) goes to zero as $n\rightarrow\infty$ when you are not on that plane, however I am a bit uncomfortable with this as it goes to zero everywhere except the mean as $n\rightarrow\infty$, so I don't know if that argument is good enough. [1] Wootters, William K. ""Statistical distance and Hilbert space."" Physical Review D 23.2 (1981): 357.","Question Suppose we have a multinomial distribution with $N$ possible outcomes, with probabilities $p_1,\ldots,p_N$. We sample this $n$ times, and denote the observed frequency of the $i$th outcome as $\xi_i$. In [1] the author claims that the distribution of the $\xi_i$ in the limit of large $n$ is: $$p(\xi_1,\ldots,\xi_N)\propto\exp\left(-\frac{n}{2}\sum_{i=1}^N\frac{(\xi_i-p_i)^2}{p_i}\right).\;\;\;\;\;(1)$$ We can see immediately that this must be an approximation, as it assigns nonzero probabilities for $\xi_1+\cdots+\xi_N>1$. However we can see that these have vanishing probability in the limit $n\rightarrow\infty$. My question is how do we derive (1) from the multinomial distribution, and show that they match in the $n\rightarrow\infty$ limit? My thoughts My first thought would be to appeal to the central limit theorem. The multinomial distribution has mean $\mu_i=p_i$ and covariance matrix $\Sigma_{ij}=\delta_{ij}p_i-p_ip_j$, so we would expect this in the large $n$ limit to be described by a multivariate Gaussian with mean $\mu$ and covariance $\frac{1}{n}\Sigma$. However, things are complicated by the fact that the multinomial covariance is singular (since $\xi_N$ is determined by the other $\xi_i$s), and so the multivariate Gaussian is not defined. To address this, we may try and consider only the first $\xi_1,\ldots,\xi_{N-1}$, which have a non-singular covariance matrix and hence well-defined multivariate Gaussian distribution. Let's take the Binomial distribution $N=2$. The frequency $\xi_1$, this has mean $p_1$ and variance $p_1(1-p_1)$, so this would be described the the Gaussian: $$\propto\exp\left(-\frac{n}{2}\frac{(\xi_1-p_1)^2}{p_1(1-p_1)}\right).\;\;\;\;\;(2)$$ The expression (1) gives: $$\propto\exp\left(-\frac{n}{2}\left(\frac{(\xi_1-p_1)^2}{p_1}+\frac{(\xi_2-p_2)^2}{p_2}\right)\right).\;\;\;\;\;(3)$$ If we substitute $\xi_2\rightarrow 1-\xi_1$, $p_2\rightarrow 1-p_1$ into (3), we can verify that this gives the same answer as (2). I have verified that this also works for $N=4$. I'm sure that if I just bashed out the algebra for general $N$ we would get agreement between the central limit theorem and (1) when we restrict the latter to $\xi_1+\cdots+\xi_N=1,p_1+\cdots+p_N=1$. However, how can we start with the multinomial distribution and derive (1) as a limit which is valid everywhere? One idea would be to say that (1) goes to zero as $n\rightarrow\infty$ when you are not on that plane, however I am a bit uncomfortable with this as it goes to zero everywhere except the mean as $n\rightarrow\infty$, so I don't know if that argument is good enough. [1] Wootters, William K. ""Statistical distance and Hilbert space."" Physical Review D 23.2 (1981): 357.",,"['statistics', 'probability-distributions', 'probability-limit-theorems']"
2,Distribution of rounded normally distributed values,Distribution of rounded normally distributed values,,"Suppose I draw some values from $X_i \sim {\mathcal{N}( \mu, \, \sigma^2 )} $ and then round them to the nearest integer.  Are those rounded values then Binomial distributed?","Suppose I draw some values from $X_i \sim {\mathcal{N}( \mu, \, \sigma^2 )} $ and then round them to the nearest integer.  Are those rounded values then Binomial distributed?",,"['statistics', 'normal-distribution', 'binomial-distribution']"
3,Prove Standard deviation greater than or equal to Mean deviation,Prove Standard deviation greater than or equal to Mean deviation,,Ho do we prove that the standard deviation is greater than or equal to the mean deviation about the arithmetic mean ? $$ \sqrt\frac{\sum_{i=1}^{n}(x_i-\bar{x})^2}{n}\geq\frac{\sum_{i=1}^{n}|x_i-\bar{x}|}{n} $$ and under what conditions we get the equality ? I think i understand that it is because of the squaring in standard deviation which tends to give more weightage to the data far from the central tendency.,Ho do we prove that the standard deviation is greater than or equal to the mean deviation about the arithmetic mean ? $$ \sqrt\frac{\sum_{i=1}^{n}(x_i-\bar{x})^2}{n}\geq\frac{\sum_{i=1}^{n}|x_i-\bar{x}|}{n} $$ and under what conditions we get the equality ? I think i understand that it is because of the squaring in standard deviation which tends to give more weightage to the data far from the central tendency.,,"['statistics', 'standard-deviation']"
4,Any generalization for Wishart distribution?,Any generalization for Wishart distribution?,,"Let $x_1$, $x_2$,.. $x_n$ be independent and identically distributed draws from a p-dimensional multivariate normal distribution, i.e.,  $x_i \sim N_p(0, A)$ (A is the co-variance matrix) and they form a $p\times n$ data matrix $X=[x_1 \;\; x_2 \;\; .. x_n]$. In that case, the distribution of a p × p random matrix $M=XX^T$ is said to have the Wishart distribution. Can you kindly tell me, if there is any distribution function available for $XX^T$ when $X=[x_1 \;\; x_2 \;\; .. x_n]$, where each $x_i \sim N_p(0, A_i)$, i.e., they are independent but not identically distributed.  Thank you very much.","Let $x_1$, $x_2$,.. $x_n$ be independent and identically distributed draws from a p-dimensional multivariate normal distribution, i.e.,  $x_i \sim N_p(0, A)$ (A is the co-variance matrix) and they form a $p\times n$ data matrix $X=[x_1 \;\; x_2 \;\; .. x_n]$. In that case, the distribution of a p × p random matrix $M=XX^T$ is said to have the Wishart distribution. Can you kindly tell me, if there is any distribution function available for $XX^T$ when $X=[x_1 \;\; x_2 \;\; .. x_n]$, where each $x_i \sim N_p(0, A_i)$, i.e., they are independent but not identically distributed.  Thank you very much.",,"['statistics', 'random-variables', 'normal-distribution']"
5,Find the minimum-variance unbiased estimator for given $\tau(\theta)$,Find the minimum-variance unbiased estimator for given,\tau(\theta),"Let $X = (X_1, \dots, X_n)$ - a sample from the distribution $U (0,\theta)$. Prove that $T(X) = X_{(n)}$ is complete and sufficient estimation for $\theta$ and find the minimum-variance unbiased estimator $T^*(X)$ for a differentiable function $\tau(\theta)$. The proof of sufficiency can be very easily carried out using the factorization criterion. I have done it. Next we need to prove completness. By the definition we need to prove that $\mathbb{P}(g(x) = 0) = 1$ from $$\mathbb{E}_{\theta}g(T(X)) = \displaystyle\int\limits_{[0,\theta]}g(x)\frac{n y^{n-1}}{\theta^n}dx = 0, \quad \forall \theta > 0$$ It can be easily done if $g(x)$ continuous.  $\displaystyle\int\limits_{0}^\theta g(x)y^{n-1}dx = 0 $ $g(\theta)\theta^{n-1} = 0$. Than $g(\theta) = 0$. It works for continuous functions but how to prove it for all $g(x)$ such that $\mathbb{E}_{\theta}g(T(X))$ exists? And next I need to find the minimum-variance unbiased estimator $T^*(X)$ for a differentiable function $\tau(\theta)$. It seems like it is connected with the first question and can be done using something like Lehmann–Scheffé theorem, but I do not know how to do it exactly. Great thanks for the help!","Let $X = (X_1, \dots, X_n)$ - a sample from the distribution $U (0,\theta)$. Prove that $T(X) = X_{(n)}$ is complete and sufficient estimation for $\theta$ and find the minimum-variance unbiased estimator $T^*(X)$ for a differentiable function $\tau(\theta)$. The proof of sufficiency can be very easily carried out using the factorization criterion. I have done it. Next we need to prove completness. By the definition we need to prove that $\mathbb{P}(g(x) = 0) = 1$ from $$\mathbb{E}_{\theta}g(T(X)) = \displaystyle\int\limits_{[0,\theta]}g(x)\frac{n y^{n-1}}{\theta^n}dx = 0, \quad \forall \theta > 0$$ It can be easily done if $g(x)$ continuous.  $\displaystyle\int\limits_{0}^\theta g(x)y^{n-1}dx = 0 $ $g(\theta)\theta^{n-1} = 0$. Than $g(\theta) = 0$. It works for continuous functions but how to prove it for all $g(x)$ such that $\mathbb{E}_{\theta}g(T(X))$ exists? And next I need to find the minimum-variance unbiased estimator $T^*(X)$ for a differentiable function $\tau(\theta)$. It seems like it is connected with the first question and can be done using something like Lehmann–Scheffé theorem, but I do not know how to do it exactly. Great thanks for the help!",,"['statistics', 'statistical-inference', 'uniform-distribution', 'parameter-estimation']"
6,Reference Request - Statistics Book with exercises,Reference Request - Statistics Book with exercises,,"I'm looking for an as complete as possible statistics book with exercises, including the following topics: Probability Review Random Variables and Samples Descriptive Statistics Estimation (confidence intervals for mean of population, probability, difference of means of population etc) Hypothesis Tests Chi Square Test Linear Regression Analysis of Variance Non parametric tests (Kolmogorov-Smirnov, Friedman, Kruskal-Wallis, Sign test etc)","I'm looking for an as complete as possible statistics book with exercises, including the following topics: Probability Review Random Variables and Samples Descriptive Statistics Estimation (confidence intervals for mean of population, probability, difference of means of population etc) Hypothesis Tests Chi Square Test Linear Regression Analysis of Variance Non parametric tests (Kolmogorov-Smirnov, Friedman, Kruskal-Wallis, Sign test etc)",,"['statistics', 'reference-request']"
7,What proportion of my friend's calzones were the best he had made so far?,What proportion of my friend's calzones were the best he had made so far?,,"(True story:) A friend of mine was making a calzone and said it wasn't the best he had ever made. It got me wondering, what fraction of the calzones he has made were the best he had made at the time? Assume he makes $n$ calzones, each with a quality chosen i.i.d. from a normal distribution (he never improves at all).  Asymptotically, what proportion of the calzones he makes are the best he had made so far? My intuition says it should be something like $1/\sqrt{n}$?","(True story:) A friend of mine was making a calzone and said it wasn't the best he had ever made. It got me wondering, what fraction of the calzones he has made were the best he had made at the time? Assume he makes $n$ calzones, each with a quality chosen i.i.d. from a normal distribution (he never improves at all).  Asymptotically, what proportion of the calzones he makes are the best he had made so far? My intuition says it should be something like $1/\sqrt{n}$?",,"['statistics', 'order-statistics']"
8,Which math class can I take to learn how to derive statistical models,Which math class can I take to learn how to derive statistical models,,"I have taken several stats classes and. Have seen many models in action like the normal, poisson, dirchet, etc. and seen several inference tests in action like chisq, ttest and anova. However I'm interested in the theory behind such distributions, and also in the method by which the lookup values for test statistics and p-values are calculated for given inference tests. What type of book or math class do I need to take to learn this? Additionally, if anyone can recommend online courses or resources that deal with such topics I would be grateful.","I have taken several stats classes and. Have seen many models in action like the normal, poisson, dirchet, etc. and seen several inference tests in action like chisq, ttest and anova. However I'm interested in the theory behind such distributions, and also in the method by which the lookup values for test statistics and p-values are calculated for given inference tests. What type of book or math class do I need to take to learn this? Additionally, if anyone can recommend online courses or resources that deal with such topics I would be grateful.",,['statistics']
9,UMVUE of $ \frac{1}{\theta}$ coming from $f(x) = \theta x^{\theta - 1}$.,UMVUE of  coming from ., \frac{1}{\theta} f(x) = \theta x^{\theta - 1},"Let $X_1, \ldots, X_n$ be i.i.d. sampled from the distribution $$ f(x; \theta) = \theta x^{\theta - 1}, $$ where $x \in (0, 1)$ and $\theta > 0$ . Show that $$ T(x_{1}, \ldots, x_{n}) = - \frac{1}{n} \sum_{i = 1}^n \ln(x_i) $$ is a Unique Minimum Variance Unbiased Estimator (UMVUE) of $\dfrac{1}{\theta} $ . I know that $g(T) = E[h(x) \mid T(x)]$ is UMVUE if $h(x)$ is an unbiased estimator and $T(x)$ is a complete sufficient statistic. I tried guessing that $\dfrac{1}{x}$ would be a UE of $\dfrac{1}{\theta}$ using $E\left( \dfrac{k}{x} \right) = \int_0^1 \left( \dfrac{k}{x} \right) \cdot \theta \cdot x^{\theta-1} \ dx$ , which gives $\dfrac{k \theta}{\theta - 1}$ , so $\dfrac{\theta-1}{x}$ is UE of $\theta$ . Here, we can apply invariance property to see that $\dfrac{x}{\theta - 1}$ is UE of $\dfrac{1}{\theta}$ . I also know that the MLE of $\dfrac{1}{\theta}$ is $-\dfrac{1}{n} \sum_{i = 1}^n \ln(x_i)$ . However, I'm having trouble with actually calculating $g(T)$ .","Let be i.i.d. sampled from the distribution where and . Show that is a Unique Minimum Variance Unbiased Estimator (UMVUE) of . I know that is UMVUE if is an unbiased estimator and is a complete sufficient statistic. I tried guessing that would be a UE of using , which gives , so is UE of . Here, we can apply invariance property to see that is UE of . I also know that the MLE of is . However, I'm having trouble with actually calculating .","X_1, \ldots, X_n 
f(x; \theta) = \theta x^{\theta - 1},
 x \in (0, 1) \theta > 0 
T(x_{1}, \ldots, x_{n}) = - \frac{1}{n} \sum_{i = 1}^n \ln(x_i)
 \dfrac{1}{\theta}  g(T) = E[h(x) \mid T(x)] h(x) T(x) \dfrac{1}{x} \dfrac{1}{\theta} E\left( \dfrac{k}{x} \right) = \int_0^1 \left( \dfrac{k}{x} \right) \cdot \theta \cdot x^{\theta-1} \ dx \dfrac{k \theta}{\theta - 1} \dfrac{\theta-1}{x} \theta \dfrac{x}{\theta - 1} \dfrac{1}{\theta} \dfrac{1}{\theta} -\dfrac{1}{n} \sum_{i = 1}^n \ln(x_i) g(T)",['statistics']
10,Statistics question Conditional Probability,Statistics question Conditional Probability,,"Question: Of three cards, one is painted red on both sides; one is painted black on both sides; and one is painted red on one side and black on the other. A card is randomly chosen and placed on a table. If the side facing up is red, what is the probability that the other side is also red? My Attempt: number designates side and letter the colour Card 1: R1 R2 Card 2: B1 B2 Card 3: R1 B2 P(R2|R1) = P(R1R2)/P(R1) P(R2|R1) = (1/3)/(1/2) P(R2|R1) = 2/3 I did this in a conditional probability manner but my instinct says the answer should just be 1/2...","Question: Of three cards, one is painted red on both sides; one is painted black on both sides; and one is painted red on one side and black on the other. A card is randomly chosen and placed on a table. If the side facing up is red, what is the probability that the other side is also red? My Attempt: number designates side and letter the colour Card 1: R1 R2 Card 2: B1 B2 Card 3: R1 B2 P(R2|R1) = P(R1R2)/P(R1) P(R2|R1) = (1/3)/(1/2) P(R2|R1) = 2/3 I did this in a conditional probability manner but my instinct says the answer should just be 1/2...",,"['statistics', 'conditional-probability']"
11,Asymptotic efficiency of maximum likelihood estimate,Asymptotic efficiency of maximum likelihood estimate,,"Let us consider a simple statistical model $\{f_{\theta}\}$ where $\theta\in U$, an open subset of $\mathbb{R}$. Let $X_1,\dots,X_n$ be sample drawn from $f_{\theta}$. I know, under some regularity assumptions, that $$ n \text{Var}_{\theta}\left(\hat{\theta}_{MLE}(X_1,\dots.X_n)\right)\to 1/I_{\theta},$$ where $I_{\theta}$ is the Fisher information. Can someone provide a proof (or a link to a reference) to the above result? In the books I have, I could find only proof of the following (relevant) result which is actually called asymptotic normality: $$\sqrt{n}\left(\hat{\theta}_{MLE}(X_1,\dots.X_n)-\theta\right)\stackrel{d}{\to} \mathcal{N}(0,1/I_{\theta}).$$ Thank you.","Let us consider a simple statistical model $\{f_{\theta}\}$ where $\theta\in U$, an open subset of $\mathbb{R}$. Let $X_1,\dots,X_n$ be sample drawn from $f_{\theta}$. I know, under some regularity assumptions, that $$ n \text{Var}_{\theta}\left(\hat{\theta}_{MLE}(X_1,\dots.X_n)\right)\to 1/I_{\theta},$$ where $I_{\theta}$ is the Fisher information. Can someone provide a proof (or a link to a reference) to the above result? In the books I have, I could find only proof of the following (relevant) result which is actually called asymptotic normality: $$\sqrt{n}\left(\hat{\theta}_{MLE}(X_1,\dots.X_n)-\theta\right)\stackrel{d}{\to} \mathcal{N}(0,1/I_{\theta}).$$ Thank you.",,"['statistics', 'statistical-inference']"
12,Calculating success chance from algorithm,Calculating success chance from algorithm,,"Not super sure this is the right *exchange for this question, but here we go. Let's say I'm writing a game, and in this game the player may attack another unit. The chance of hitting is an ""opposed roll"" that looks something like this: An attack lands if: (attack * random() + attack * random()) is greater than or equal to (defense * random() + defense * random()) Where attack and defense are both numbers > 0 and random() returns a (pseudo) random number between 0 and 1 (not including 1). The reason it looks like it does is to ensure that there is a bias towards the ""average value"" (or rather, towards double the average value, but it doesn't really matter). How would one go about calculating the ""hit chance"" for this algorithm (in order to display it to the user)? Thanks!","Not super sure this is the right *exchange for this question, but here we go. Let's say I'm writing a game, and in this game the player may attack another unit. The chance of hitting is an ""opposed roll"" that looks something like this: An attack lands if: (attack * random() + attack * random()) is greater than or equal to (defense * random() + defense * random()) Where attack and defense are both numbers > 0 and random() returns a (pseudo) random number between 0 and 1 (not including 1). The reason it looks like it does is to ensure that there is a bias towards the ""average value"" (or rather, towards double the average value, but it doesn't really matter). How would one go about calculating the ""hit chance"" for this algorithm (in order to display it to the user)? Thanks!",,['statistics']
13,Why are these estimates to the German tank problem different?,Why are these estimates to the German tank problem different?,,"Suppose that I observe $k=4$ tanks with serial numbers $2,6,7,14$.   What is the best estimate for the total number of tanks $n$? I assume the observations are drawn from a discrete uniform distribution with the interval $[1,n]$. I know that for a $[0,1]$ interval the expected maximum draw $m$ for $k$ draws is  $1 - (1/(1+k))$. So I estimate $\frac {k}{k+1}$$(n-1)≈$ $m$, rearranged so $n≈$ $\frac {k+1 }{k}$$m+1$. But the frequentist estimate from Wikipedia is defined as: $n ≈ m-1 + $$\frac {m}{k}$ I suspect there is some flaw in the way I have extrapolated from one interval to another, but I would welcome an explanation of why I have gone wrong!","Suppose that I observe $k=4$ tanks with serial numbers $2,6,7,14$.   What is the best estimate for the total number of tanks $n$? I assume the observations are drawn from a discrete uniform distribution with the interval $[1,n]$. I know that for a $[0,1]$ interval the expected maximum draw $m$ for $k$ draws is  $1 - (1/(1+k))$. So I estimate $\frac {k}{k+1}$$(n-1)≈$ $m$, rearranged so $n≈$ $\frac {k+1 }{k}$$m+1$. But the frequentist estimate from Wikipedia is defined as: $n ≈ m-1 + $$\frac {m}{k}$ I suspect there is some flaw in the way I have extrapolated from one interval to another, but I would welcome an explanation of why I have gone wrong!",,['statistics']
14,Best estimate for random values,Best estimate for random values,,"Due to work related issues I can't discuss the exact question I want to ask, but I thought of a silly little example that conveys the same idea. Lets say the number of candy that comes in a package is a random variable with mean $\mu$ and a standard deviation $s$, after about 2 months of data gathering we've got about 100000 measurements and a pretty good estimate of $\mu$ and $s$. Lets say that said candy comes in 5 flavours that are NOT identically distributed (we know the mean and standard deviation for each flavor, lets call them $\mu_1$ through $\mu_5$ and $s_1$ trough $s_5$). Lets say that next month we will get a new batch (several packages) of candy from our supplier and we would like to estimate the amount of candy we will get for each flavour. Is there a better way than simply assuming that we'll get ""around"" the mean for each flavour taking into account that the amount of candy we'll get is around $\mu$? I have access to all the measurements made, so if anything is needed (higher order moments, other relevant data, etc.) I can compute it and update the question as needed. Cheers and thanks!","Due to work related issues I can't discuss the exact question I want to ask, but I thought of a silly little example that conveys the same idea. Lets say the number of candy that comes in a package is a random variable with mean $\mu$ and a standard deviation $s$, after about 2 months of data gathering we've got about 100000 measurements and a pretty good estimate of $\mu$ and $s$. Lets say that said candy comes in 5 flavours that are NOT identically distributed (we know the mean and standard deviation for each flavor, lets call them $\mu_1$ through $\mu_5$ and $s_1$ trough $s_5$). Lets say that next month we will get a new batch (several packages) of candy from our supplier and we would like to estimate the amount of candy we will get for each flavour. Is there a better way than simply assuming that we'll get ""around"" the mean for each flavour taking into account that the amount of candy we'll get is around $\mu$? I have access to all the measurements made, so if anything is needed (higher order moments, other relevant data, etc.) I can compute it and update the question as needed. Cheers and thanks!",,"['statistics', 'random', 'estimation']"
15,"Who established the word "" Degree of freedom "" in statistics?","Who established the word "" Degree of freedom "" in statistics?",,"I wonder who is the first one that established and applied the word : ""degree of freedom"" in statistics? Why he/she need degree of freedom in the calculation of many statistical values?","I wonder who is the first one that established and applied the word : ""degree of freedom"" in statistics? Why he/she need degree of freedom in the calculation of many statistical values?",,"['statistics', 'terminology', 'physics', 'math-history']"
16,What does relaxing the iid assumptions mean? Intuitive and technical perspectives.,What does relaxing the iid assumptions mean? Intuitive and technical perspectives.,,I believe the most restrictive assumption we can place on a series of observations is that they are iid. It is possible to relax these assumptions. For example relaxing the independent distribution results in independent heterogeneously distributed random variables. In other words the distribution of each random variables can itself vary. What does this mean? There must be some importance or we would not bother to specify the properties of the distribution. Can the distribution depend on preceding observations or would this break the independent observation restriction that we still have in place? Can anyone think of any intuitive examples to help explain this (in the same way that tossing a fair coin or rolling a fair die are good examples of iid observations) and any important statistical concepts that arise out of relaxing this assumption? My degree is not in statistics although I am quite interested in this subject. Thank you all so much.,I believe the most restrictive assumption we can place on a series of observations is that they are iid. It is possible to relax these assumptions. For example relaxing the independent distribution results in independent heterogeneously distributed random variables. In other words the distribution of each random variables can itself vary. What does this mean? There must be some importance or we would not bother to specify the properties of the distribution. Can the distribution depend on preceding observations or would this break the independent observation restriction that we still have in place? Can anyone think of any intuitive examples to help explain this (in the same way that tossing a fair coin or rolling a fair die are good examples of iid observations) and any important statistical concepts that arise out of relaxing this assumption? My degree is not in statistics although I am quite interested in this subject. Thank you all so much.,,"['statistics', 'random']"
17,How do I find the MLE of $\theta$ when x is dependent on $\theta$?,How do I find the MLE of  when x is dependent on ?,\theta \theta,"Let $X_{1},X_{2},...,X_{n}$ represent a random sample from a distribution with pdf: $f(x; \theta)=e^{-(x-\theta)}, \theta \le x<\infty, -\infty<\theta<\infty$ | zero elsewhere I need to find the MLE $\hat {\theta}$ of $\theta$. Since the support space of the pdf is dependent on $\theta$, do I need to express the pdf in terms of an indicator function? i.e. $f(x; \theta)=e^{-(x-\theta)}I_{(\theta,\infty)}(x)$ If so, do I find the MLE in the standard manner? i.e. $L(x;\theta)=\displaystyle \prod^{n}_{i=1} f(X_{i};\theta)=e^{-(\sum^{n}_{i=1}X_{i}-n\theta)}I_{(\theta,\infty)}(X_{(1)})$ $\ln L(x;\theta)=-\displaystyle \sum^{n}_{i=1} X_{i} +n\theta +\ln I_{(\theta,\infty)}(X_{(1)})$ The next step would be to take the partial derivative of the log-likelihood function with respect to $\theta$, but how would I find the partial derivative of the indicator function? Am I approaching this question in the correct manner? Any help would be greatly appreciated!","Let $X_{1},X_{2},...,X_{n}$ represent a random sample from a distribution with pdf: $f(x; \theta)=e^{-(x-\theta)}, \theta \le x<\infty, -\infty<\theta<\infty$ | zero elsewhere I need to find the MLE $\hat {\theta}$ of $\theta$. Since the support space of the pdf is dependent on $\theta$, do I need to express the pdf in terms of an indicator function? i.e. $f(x; \theta)=e^{-(x-\theta)}I_{(\theta,\infty)}(x)$ If so, do I find the MLE in the standard manner? i.e. $L(x;\theta)=\displaystyle \prod^{n}_{i=1} f(X_{i};\theta)=e^{-(\sum^{n}_{i=1}X_{i}-n\theta)}I_{(\theta,\infty)}(X_{(1)})$ $\ln L(x;\theta)=-\displaystyle \sum^{n}_{i=1} X_{i} +n\theta +\ln I_{(\theta,\infty)}(X_{(1)})$ The next step would be to take the partial derivative of the log-likelihood function with respect to $\theta$, but how would I find the partial derivative of the indicator function? Am I approaching this question in the correct manner? Any help would be greatly appreciated!",,"['statistics', 'statistical-inference', 'exponential-distribution', 'maximum-likelihood']"
18,Working out minimum sample size,Working out minimum sample size,,"I have just started a course in statistics and have some general questions that have arisen trying to solve the following question: A survey organisation wants to take a simple random sample in order to estimate the percentage of people who have seen a certain programme. The sample is to be as small as possible. The estimate is specified to be within 1 percentage point of the true value; $\textit{i.e.}$, the width of the interval centered on the sample proportion who watched the programme should be 1%. The population from which the sample is to be taken is very large. Past experience suggests the population percentage to be in the range 20% to 40%. What size sample should be taken? I think I have to use this and solve for n $$1.96\sqrt{\frac{\pi (1-\pi)}{n}} = .01$$ where $\pi$ is the sample estimated proportion of people who watch the programme. Now does this mean that I am 95% sure that I am within 1% accuracy?  I also am not aware as to how I can find $\pi$ though I have read I could use the population standard deviation instead and suspect I would have to use that as I am given some information- that the pop proportion is 20%-40%. Finally in general what is being said here: $$\pi \pm 1.96\sqrt{\frac{\pi (1-\pi)}{n}} = .01$$ My notes at the moment just say it contains the population mean 95% of the time.... why? I think if I had some graphical understanding of what was going on everything would be much simpler for me.","I have just started a course in statistics and have some general questions that have arisen trying to solve the following question: A survey organisation wants to take a simple random sample in order to estimate the percentage of people who have seen a certain programme. The sample is to be as small as possible. The estimate is specified to be within 1 percentage point of the true value; $\textit{i.e.}$, the width of the interval centered on the sample proportion who watched the programme should be 1%. The population from which the sample is to be taken is very large. Past experience suggests the population percentage to be in the range 20% to 40%. What size sample should be taken? I think I have to use this and solve for n $$1.96\sqrt{\frac{\pi (1-\pi)}{n}} = .01$$ where $\pi$ is the sample estimated proportion of people who watch the programme. Now does this mean that I am 95% sure that I am within 1% accuracy?  I also am not aware as to how I can find $\pi$ though I have read I could use the population standard deviation instead and suspect I would have to use that as I am given some information- that the pop proportion is 20%-40%. Finally in general what is being said here: $$\pi \pm 1.96\sqrt{\frac{\pi (1-\pi)}{n}} = .01$$ My notes at the moment just say it contains the population mean 95% of the time.... why? I think if I had some graphical understanding of what was going on everything would be much simpler for me.",,['statistics']
19,What is the distribution of a data set,What is the distribution of a data set,,"I understand what the probability distribution is. I also have a personal understanding/interpretation of the concept of distribution of a dataset . Whenever I see this expression I imagine a graph with frequency as the y-axis and the members of the data set on the x-axis, for each of them(members of the data set) the graph containing a point at the corresponding frequency level. Is this the correct interpretation ? Is ""distribution of a datset"" = ""probability distribution"" ? To me it doesn't look like the two concepts are the same thing.(probably subtly related but not the same thing) I was unable to find a standard definition of this concept. Can you provide me with a pointer to a resource defining it ? When authors say: ""Two data sets drawn from the same underlying distribution"", what exactly do they mean by ""underlying distribution"" ? Do they mean the same thing as I mentioned above, i.e. a graph like :frequency vs each member of the data set ?","I understand what the probability distribution is. I also have a personal understanding/interpretation of the concept of distribution of a dataset . Whenever I see this expression I imagine a graph with frequency as the y-axis and the members of the data set on the x-axis, for each of them(members of the data set) the graph containing a point at the corresponding frequency level. Is this the correct interpretation ? Is ""distribution of a datset"" = ""probability distribution"" ? To me it doesn't look like the two concepts are the same thing.(probably subtly related but not the same thing) I was unable to find a standard definition of this concept. Can you provide me with a pointer to a resource defining it ? When authors say: ""Two data sets drawn from the same underlying distribution"", what exactly do they mean by ""underlying distribution"" ? Do they mean the same thing as I mentioned above, i.e. a graph like :frequency vs each member of the data set ?",,"['statistics', 'probability-distributions', 'data-analysis']"
20,Finding the MLE for parameter $\theta$ from distribution of the form $e^{-|x-\theta|}$ [duplicate],Finding the MLE for parameter  from distribution of the form  [duplicate],\theta e^{-|x-\theta|},"This question already has answers here : Finding the maximum likelihood estimator (3 answers) Closed 4 years ago . this is my first post so I apologize if the formatting is a little rocky. I'm currently going through ""Probability and Statistics"" 4th ed by DeGroot/Schervish, and I was wondering if somebody could help me out on two related problems (7.5.10, 7.6.1). The first question is as follows: Suppose that $ X_1, \dots, X_n $ form a random sample from a distribution for which the p.d.f. $ f(x|\theta) $ is as follows: $$ f(x|\theta) = \frac{1}{2} e^{-|x-\theta|} \text{ for } -\infty < x < \infty $$ Also, suppose that the value of $ \theta $ is unknown, for $ -\infty < \theta < \infty $. We will find the M.L.E. of $ \theta $. The likelihood function is given by $$ f_n(\mathbf{x}|\theta) = \frac{1}{2^n} e^{-\sum_{i=1}^n |x_i - \theta|}$$ and will be maximized when $ \sum_{i=1}^n |x_i - \theta| $ is minimized. By choosing $ \theta $ to be a median value of $ x_1, \dots, x_n $, we accomplish the minimization task. More specifically, note that the likelihood function has log \begin{align*} \log f(\mathbf{x}|\theta) &= -n \log 2 - \sum_{i=1}^n |x_i - \theta| \\ &= n \left ( - \log 2 - \frac{1}{n} \sum_{i=1}^n |x_i - \theta| \right ) \end{align*} Now, we see that the M.L.E. will minimize the sum in the log likelihood shown above. We can also see that $ \frac{1}{n} \sum_{i=1}^n |x_i - \theta| = E(|X-\theta|)$ for $ X $ having a discrete distribution assigning probability $ \frac{1}{n} $ to each of $ x_1, \dots, x_n $, and 0 everywhere else. So now we can see that, by choosing $ \hat{\theta} $ to be a median of $ x_1, \dots, x_n $, then the log likelihood will be minimized. This follows from the fact that the median of a distribution minimizes the mean absolute error. The second question is to find the MLE of $e^{-\frac{1}{\theta}}$, which by the invariance property of MLEs, should just be $e^{-\frac{1}{\hat{\theta}}}$. My problem is that the answer in the back of the book (for the second question) is given as $\left ( \prod_{i=1}^n x_i \right)^{\frac{1}{n}}$, and I'm having trouble reconciling that with my answer. You'd think it'd be pretty straightforward, but... Any help would be appreciated!","This question already has answers here : Finding the maximum likelihood estimator (3 answers) Closed 4 years ago . this is my first post so I apologize if the formatting is a little rocky. I'm currently going through ""Probability and Statistics"" 4th ed by DeGroot/Schervish, and I was wondering if somebody could help me out on two related problems (7.5.10, 7.6.1). The first question is as follows: Suppose that $ X_1, \dots, X_n $ form a random sample from a distribution for which the p.d.f. $ f(x|\theta) $ is as follows: $$ f(x|\theta) = \frac{1}{2} e^{-|x-\theta|} \text{ for } -\infty < x < \infty $$ Also, suppose that the value of $ \theta $ is unknown, for $ -\infty < \theta < \infty $. We will find the M.L.E. of $ \theta $. The likelihood function is given by $$ f_n(\mathbf{x}|\theta) = \frac{1}{2^n} e^{-\sum_{i=1}^n |x_i - \theta|}$$ and will be maximized when $ \sum_{i=1}^n |x_i - \theta| $ is minimized. By choosing $ \theta $ to be a median value of $ x_1, \dots, x_n $, we accomplish the minimization task. More specifically, note that the likelihood function has log \begin{align*} \log f(\mathbf{x}|\theta) &= -n \log 2 - \sum_{i=1}^n |x_i - \theta| \\ &= n \left ( - \log 2 - \frac{1}{n} \sum_{i=1}^n |x_i - \theta| \right ) \end{align*} Now, we see that the M.L.E. will minimize the sum in the log likelihood shown above. We can also see that $ \frac{1}{n} \sum_{i=1}^n |x_i - \theta| = E(|X-\theta|)$ for $ X $ having a discrete distribution assigning probability $ \frac{1}{n} $ to each of $ x_1, \dots, x_n $, and 0 everywhere else. So now we can see that, by choosing $ \hat{\theta} $ to be a median of $ x_1, \dots, x_n $, then the log likelihood will be minimized. This follows from the fact that the median of a distribution minimizes the mean absolute error. The second question is to find the MLE of $e^{-\frac{1}{\theta}}$, which by the invariance property of MLEs, should just be $e^{-\frac{1}{\hat{\theta}}}$. My problem is that the answer in the back of the book (for the second question) is given as $\left ( \prod_{i=1}^n x_i \right)^{\frac{1}{n}}$, and I'm having trouble reconciling that with my answer. You'd think it'd be pretty straightforward, but... Any help would be appreciated!",,['statistics']
21,A question on confidence,A question on confidence,,"So, I've been reviewing some of my old stats courses in preparation for an interview I have in a couple of days. I'm a bit stuck on a particular question and hope you could help. A drug trial gives the result that the drug works better than the placebo, with 95% conﬁdence. What exactly does this statement mean? What further assumptions are needed to be able to deduce that the probability of the drug working is actually 95%? My answer to the first part is... 95% confidence means that there is a 1 in 20 chance that the difference could have been observed by chance i.e. if the experiment was conducted many times. Any suggestion for part 2? Thanks in advance.","So, I've been reviewing some of my old stats courses in preparation for an interview I have in a couple of days. I'm a bit stuck on a particular question and hope you could help. A drug trial gives the result that the drug works better than the placebo, with 95% conﬁdence. What exactly does this statement mean? What further assumptions are needed to be able to deduce that the probability of the drug working is actually 95%? My answer to the first part is... 95% confidence means that there is a 1 in 20 chance that the difference could have been observed by chance i.e. if the experiment was conducted many times. Any suggestion for part 2? Thanks in advance.",,['statistics']
22,Prove the sample variance is an unbiased estimator,Prove the sample variance is an unbiased estimator,,I'm trying to prove that the sample variance is an unbiased estimator. I know that I need to find the expected value of the sample variance estimator $$\sum_i\frac{(M_i - \bar{M})^2}{n-1}$$ but I get stuck finding the expected value of the $M_i\bar{M}$ term. Any clues? I would also like to calculate the variance of the sample variance. In short I would like to calculate $\mathrm{Var}(M_i - \bar{M})^2$ but again that term rears its ugly head.,I'm trying to prove that the sample variance is an unbiased estimator. I know that I need to find the expected value of the sample variance estimator $$\sum_i\frac{(M_i - \bar{M})^2}{n-1}$$ but I get stuck finding the expected value of the $M_i\bar{M}$ term. Any clues? I would also like to calculate the variance of the sample variance. In short I would like to calculate $\mathrm{Var}(M_i - \bar{M})^2$ but again that term rears its ugly head.,,"['statistics', 'parameter-estimation']"
23,Poisson Process - Courts,Poisson Process - Courts,,IITK sports facility has $4$ tennis courts. Players arrive at the courts at a Poisson rate of one pair per $10$ min and use a court for an exponentially distributed time with mean $40$ min. Suppose that a pair of players arrives and finds all courts busy and $k$ other pairs waiting in queue. How long will they have to wait to get a court on the average?,IITK sports facility has $4$ tennis courts. Players arrive at the courts at a Poisson rate of one pair per $10$ min and use a court for an exponentially distributed time with mean $40$ min. Suppose that a pair of players arrives and finds all courts busy and $k$ other pairs waiting in queue. How long will they have to wait to get a court on the average?,,"['statistics', 'stochastic-processes']"
24,"Finding UMP test for $\text{Cauchy}(0, \theta)$ distribution",Finding UMP test for  distribution,"\text{Cauchy}(0, \theta)","If $X$ follows $\text{Cauchy}(0, \theta)$ distribution, construct a UMP size $\alpha$ test for testing $H_0:\theta=\theta_0$ against $H_1:\theta>\theta_0$ My attempt: Let us take any $\theta_1>\theta_0$ . First we have to find a most powerful test of size $\alpha$ for testing $H_0:\theta=\theta_0$ against $H'_1:\theta=\theta_1$ Now, $f_\theta (x)=\frac{\theta}{\pi(x^2+\theta^2)}$ , $x\in\mathbb R, \theta>0$ So, $\lambda(x)=\frac{f_{\theta_1}(x)}{f_{\theta_0}(x)}=\frac{\theta_1(x^2+\theta_0^2)}{\theta_0(x^2+\theta_1^2)}$ $\frac{d\lambda(x)}{dx^2}>0$ , so $\lambda(x)$ is an increasing function of $x^2$ or $|x|$ , i.e, $\lambda(x)>k \iff |x|>c$ Therefore, by N-P lemma, a most powerful test of size $\alpha$ for testing $H_0:\theta=\theta_0$ against $H'_1:\theta=\theta_1$ is given by, $\phi(x)= 1$ if $|x|>c$ $\phi(x)= 0$ if $|x|<c$ where c is such that $E_{\theta_0}\phi(x)=\alpha$ , i.e, $P_{\theta_0}(|X|>c)=\alpha$ I'm getting stuck here. I cannot understand how to find the value of c. If $X$ follows $\text{Cauchy}(0, \theta_0)$ , then what does $|X|$ follow? Any kind of hints and suggestions are appreciated. Thanks in advance.","If follows distribution, construct a UMP size test for testing against My attempt: Let us take any . First we have to find a most powerful test of size for testing against Now, , So, , so is an increasing function of or , i.e, Therefore, by N-P lemma, a most powerful test of size for testing against is given by, if if where c is such that , i.e, I'm getting stuck here. I cannot understand how to find the value of c. If follows , then what does follow? Any kind of hints and suggestions are appreciated. Thanks in advance.","X \text{Cauchy}(0, \theta) \alpha H_0:\theta=\theta_0 H_1:\theta>\theta_0 \theta_1>\theta_0 \alpha H_0:\theta=\theta_0 H'_1:\theta=\theta_1 f_\theta (x)=\frac{\theta}{\pi(x^2+\theta^2)} x\in\mathbb R, \theta>0 \lambda(x)=\frac{f_{\theta_1}(x)}{f_{\theta_0}(x)}=\frac{\theta_1(x^2+\theta_0^2)}{\theta_0(x^2+\theta_1^2)} \frac{d\lambda(x)}{dx^2}>0 \lambda(x) x^2 |x| \lambda(x)>k \iff |x|>c \alpha H_0:\theta=\theta_0 H'_1:\theta=\theta_1 \phi(x)= 1 |x|>c \phi(x)= 0 |x|<c E_{\theta_0}\phi(x)=\alpha P_{\theta_0}(|X|>c)=\alpha X \text{Cauchy}(0, \theta_0) |X|","['statistics', 'statistical-inference', 'hypothesis-testing']"
25,Find out if $\hat{\tau}$ is an unbiased estimator,Find out if  is an unbiased estimator,\hat{\tau},"I got given a pdf: $$f(x)=\tau x \exp\left(\frac{-\tau x^2}{2}\right)$$ $x,\tau >0$ I found $$E(X)=\sqrt{\frac{\pi}{2\tau}}$$ And I used the method of moments method to find: $$\hat{\tau}=\frac{\pi}{2\bar{x}^2}$$ Now, from what I found out is that an estimator is unbiased if $E(\hat{\tau})=\tau$, but I have: $$E(\hat{\tau})=E\left(\frac{\pi}{2\bar{x}^2}\right)=\frac{\pi}{2}E\left(\frac{1}{\bar{x}^2}\right)$$ and I have no idea how to calculate $E\left(\frac{1}{\bar{x}^2}\right)$","I got given a pdf: $$f(x)=\tau x \exp\left(\frac{-\tau x^2}{2}\right)$$ $x,\tau >0$ I found $$E(X)=\sqrt{\frac{\pi}{2\tau}}$$ And I used the method of moments method to find: $$\hat{\tau}=\frac{\pi}{2\bar{x}^2}$$ Now, from what I found out is that an estimator is unbiased if $E(\hat{\tau})=\tau$, but I have: $$E(\hat{\tau})=E\left(\frac{\pi}{2\bar{x}^2}\right)=\frac{\pi}{2}E\left(\frac{1}{\bar{x}^2}\right)$$ and I have no idea how to calculate $E\left(\frac{1}{\bar{x}^2}\right)$",,"['statistics', 'means']"
26,Mean Squared Error Maximum uniform distribution,Mean Squared Error Maximum uniform distribution,,"Let $X_1,\ldots,X_n$ be Uniform Distributed Random variables on $[0,\theta]$ and let T be $\max\{X_1,\ldots,X_n\}$ an estimator for $\theta$. I derived that the $F_T(x)=(\frac{x}{\theta})^n$ for $0<x<\theta$. Then I calculated the expected value of $T$, $$\operatorname{E}[T]=\int_0^\theta x\cdot\frac{nx^{n-1}}{\theta^n} \, dx=\frac n {n+1} \theta$$ and that $$ \operatorname{Var}(T)=\int_0^\theta x^2 \frac{nx^{n-1}}{\theta^n} \, dx - \left(\frac n {n+1}\theta \right)^2 = \frac n {n+2}\theta^2 - \left(\frac n {n+1} \theta\right)^2=\frac{n\theta^2}{(n+2)(n+1)^2}. $$ When I now determine the Mean Squared Error of $T$, I find: $$\operatorname{MSE}(T)=\operatorname{Var}(T)-(\operatorname{E}[T]-\theta)^2 = \frac{n\theta^2}{(n+2)(n+1)^2} - \left(\frac n {n+1}\theta-\theta\right)^2 = \frac{-2\theta^2}{(n+1)^2(n+2)}$$ However, as $\theta>0$, the Mean Squared Error of $T$ is negative so I was wondering whether anything was wrong with this calculation. Could anyone help me please?","Let $X_1,\ldots,X_n$ be Uniform Distributed Random variables on $[0,\theta]$ and let T be $\max\{X_1,\ldots,X_n\}$ an estimator for $\theta$. I derived that the $F_T(x)=(\frac{x}{\theta})^n$ for $0<x<\theta$. Then I calculated the expected value of $T$, $$\operatorname{E}[T]=\int_0^\theta x\cdot\frac{nx^{n-1}}{\theta^n} \, dx=\frac n {n+1} \theta$$ and that $$ \operatorname{Var}(T)=\int_0^\theta x^2 \frac{nx^{n-1}}{\theta^n} \, dx - \left(\frac n {n+1}\theta \right)^2 = \frac n {n+2}\theta^2 - \left(\frac n {n+1} \theta\right)^2=\frac{n\theta^2}{(n+2)(n+1)^2}. $$ When I now determine the Mean Squared Error of $T$, I find: $$\operatorname{MSE}(T)=\operatorname{Var}(T)-(\operatorname{E}[T]-\theta)^2 = \frac{n\theta^2}{(n+2)(n+1)^2} - \left(\frac n {n+1}\theta-\theta\right)^2 = \frac{-2\theta^2}{(n+1)^2(n+2)}$$ However, as $\theta>0$, the Mean Squared Error of $T$ is negative so I was wondering whether anything was wrong with this calculation. Could anyone help me please?",,[]
27,Calculating parallel program's execution time,Calculating parallel program's execution time,,"I am trying to calculate the probable execution time of a highly parallelizable program, where the execution's 70%-80% can run in parallel. I read about the topic, but mostly people mention simple situations, but I have another condition the parallelization have to abide. A thread have to perform a specific job it gets from the server, which can be calculated as a best and worst case scenario's average (example.: best 500ms, worst 1500ms, then let's say a job's execution time we use to calculate is 1000ms) and there is an m number, which is a maximum number of jobs that can run in the same time. Meaning, even if I have 200 threads that can run jobs parallel, the server won't give out a job only if the number of currently running job count is smaller than m . I would like to plot out a few graphs for myself for analysation purposes, but I don't know how to implement the smaller than m condition. If I have 1 679 616 (36^4) number of jobs and one job would take 1000ms. One thread would take 19,44 days to complete all of them, if it can always take a job.","I am trying to calculate the probable execution time of a highly parallelizable program, where the execution's 70%-80% can run in parallel. I read about the topic, but mostly people mention simple situations, but I have another condition the parallelization have to abide. A thread have to perform a specific job it gets from the server, which can be calculated as a best and worst case scenario's average (example.: best 500ms, worst 1500ms, then let's say a job's execution time we use to calculate is 1000ms) and there is an m number, which is a maximum number of jobs that can run in the same time. Meaning, even if I have 200 threads that can run jobs parallel, the server won't give out a job only if the number of currently running job count is smaller than m . I would like to plot out a few graphs for myself for analysation purposes, but I don't know how to implement the smaller than m condition. If I have 1 679 616 (36^4) number of jobs and one job would take 1000ms. One thread would take 19,44 days to complete all of them, if it can always take a job.",,['statistics']
28,Derive the bias and MSE of the estimator $\hat{\beta}$,Derive the bias and MSE of the estimator,\hat{\beta},"Let $Y_1, Y_2, \ldots, Y_n$ denote a random sample of size $n$ from a population whose density is given by  $$ f(y)= \begin{cases}        3\beta^3 y^{-4} & \beta \leq y \\       0 & \text{elsewhere}    \end{cases} $$ where $\beta > 0$ is unknown. (This is a Pareto distribution) Consider the estimator $\hat{\beta} = \min(Y_1, Y_2, \ldots, Y_n)$. a. Derive the bias of the estimator $\hat{\beta}$. b. Derive MSE($\hat{\beta}$). For part a Since this is an estimator that is dealing with random variables, and I only need the minimum, then I can represent this as ordered statistics. Namely, $\hat{\beta} = Y_{(1)}$. Using the formula for ordered statistics, the pdf is: $$ g_{(1)}(Y_{(1)}) = n(1-F(y))^{n-1}f(y) $$ My first question arises here, I am not sure how I am supposed to find $F(y)$ (and I am assuming that $f(y)$ is the given distribution above). Checking against the solution, I know that the pdf is supposed to be: $$ g_{(1)}(Y_{(1)}) = 3n\beta^{3n}y^{(-3n-1)} $$ After solving getting the pdf of $Y_{(1)}$, I can then use it in the bias formula. $$ Bias(\hat{\beta}) = E[\hat{\beta}] - \beta \\ Bias(\hat{\beta}) = E[3n\beta^{3n}y^{(-3n-1)}] - \beta $$ My second question arises here. I'm not really sure how I am supposed to find the expectation. Namely, I don't know how I am supposed to treat the $y$ variable. I think that the $\beta$ variable is supposed to be treated the same way as a random variable, and that $n$ is supposed to be treated as a constant. After solving for the expectation, I should be able to get the Bias. For part b $$ MSE(\hat{\beta}) = Bias(\hat{\beta})^2 + Var(\hat{\beta}) $$ The bias part of this formula should follow from part a. This would leave just the variance to calculate. I would expect to use the variance formula: $$ Var(\hat{\beta}) = E[\hat{\beta}^2] - E[\hat{\beta}]^2 $$ And I would also expect that both expectations in this formula could be calculated using the same methods in part a. Is this correct?","Let $Y_1, Y_2, \ldots, Y_n$ denote a random sample of size $n$ from a population whose density is given by  $$ f(y)= \begin{cases}        3\beta^3 y^{-4} & \beta \leq y \\       0 & \text{elsewhere}    \end{cases} $$ where $\beta > 0$ is unknown. (This is a Pareto distribution) Consider the estimator $\hat{\beta} = \min(Y_1, Y_2, \ldots, Y_n)$. a. Derive the bias of the estimator $\hat{\beta}$. b. Derive MSE($\hat{\beta}$). For part a Since this is an estimator that is dealing with random variables, and I only need the minimum, then I can represent this as ordered statistics. Namely, $\hat{\beta} = Y_{(1)}$. Using the formula for ordered statistics, the pdf is: $$ g_{(1)}(Y_{(1)}) = n(1-F(y))^{n-1}f(y) $$ My first question arises here, I am not sure how I am supposed to find $F(y)$ (and I am assuming that $f(y)$ is the given distribution above). Checking against the solution, I know that the pdf is supposed to be: $$ g_{(1)}(Y_{(1)}) = 3n\beta^{3n}y^{(-3n-1)} $$ After solving getting the pdf of $Y_{(1)}$, I can then use it in the bias formula. $$ Bias(\hat{\beta}) = E[\hat{\beta}] - \beta \\ Bias(\hat{\beta}) = E[3n\beta^{3n}y^{(-3n-1)}] - \beta $$ My second question arises here. I'm not really sure how I am supposed to find the expectation. Namely, I don't know how I am supposed to treat the $y$ variable. I think that the $\beta$ variable is supposed to be treated the same way as a random variable, and that $n$ is supposed to be treated as a constant. After solving for the expectation, I should be able to get the Bias. For part b $$ MSE(\hat{\beta}) = Bias(\hat{\beta})^2 + Var(\hat{\beta}) $$ The bias part of this formula should follow from part a. This would leave just the variance to calculate. I would expect to use the variance formula: $$ Var(\hat{\beta}) = E[\hat{\beta}^2] - E[\hat{\beta}]^2 $$ And I would also expect that both expectations in this formula could be calculated using the same methods in part a. Is this correct?",,['statistics']
29,Why does the variance formula has a square term?,Why does the variance formula has a square term?,,"I was reading about variance from Head First Statistics : And then - Q. I find the reasoning a little absurd. Wouldn't just taking the absolute distance suffice if cancelling out of the terms was the reason ? Why do squares to make it positive and complicate the calculations further (In terms of computations on a computer, square would be costlier than subtraction, right?) ?","I was reading about variance from Head First Statistics : And then - Q. I find the reasoning a little absurd. Wouldn't just taking the absolute distance suffice if cancelling out of the terms was the reason ? Why do squares to make it positive and complicate the calculations further (In terms of computations on a computer, square would be costlier than subtraction, right?) ?",,"['statistics', 'covariance']"
30,Why sample statistics converge to the right parameter,Why sample statistics converge to the right parameter,,"We know that for sample/empirical distribution function $F_n(x)$ we have that a) $F_n(x)\xrightarrow[p]{}F(x)$ (pointwise convergence) b) $\dfrac{\sqrt{n}(F_n(x)-F(x))}{\sqrt{F(x)(1-F(x))}}\xrightarrow[d]{}N(0,1)$ c) $F_n$ converges uniformly in probability to F. My question is how do we prove that the sample moments of order $k$, and sample central moments of order $k$ converge to $E(X^k)$ and $E(X-E(X))^k$ respectively? (I think need to use the above empirical distribution function properties, but I do not know how, or which...) Any help would be appreciated. If you know how to explain that the sample statistics converge, without using any property of the empirical distribution, I would also be thankful.","We know that for sample/empirical distribution function $F_n(x)$ we have that a) $F_n(x)\xrightarrow[p]{}F(x)$ (pointwise convergence) b) $\dfrac{\sqrt{n}(F_n(x)-F(x))}{\sqrt{F(x)(1-F(x))}}\xrightarrow[d]{}N(0,1)$ c) $F_n$ converges uniformly in probability to F. My question is how do we prove that the sample moments of order $k$, and sample central moments of order $k$ converge to $E(X^k)$ and $E(X-E(X))^k$ respectively? (I think need to use the above empirical distribution function properties, but I do not know how, or which...) Any help would be appreciated. If you know how to explain that the sample statistics converge, without using any property of the empirical distribution, I would also be thankful.",,['statistics']
31,Probability of a gaussian distribution in another gaussian distribution,Probability of a gaussian distribution in another gaussian distribution,,"Assume we have a Gaussian distribution $p(x) \sim  \mathcal{N}(\mu_p,\Sigma_p)$ For any point $X$, it is easy to compute the density of $x$ in $p$: $$p(x) = \frac{1}{|2\pi \Sigma_p|^\frac{1}{2}}e^{-\frac{1}{2}(x-\mu_p)^T\Sigma_p^{-1}(x-\mu_p)}$$ Now suppose that we have another Gaussian distribution  $q(x) \sim  \mathcal{N}(\mu_q,\Sigma_q)$ ** What is the expectation of q(x) in p(x) . I mean, if we randomly sample a point $x$ from P, what is the **expected probability of x in Q? NOTE: I need the solution in closed form. Thanks!","Assume we have a Gaussian distribution $p(x) \sim  \mathcal{N}(\mu_p,\Sigma_p)$ For any point $X$, it is easy to compute the density of $x$ in $p$: $$p(x) = \frac{1}{|2\pi \Sigma_p|^\frac{1}{2}}e^{-\frac{1}{2}(x-\mu_p)^T\Sigma_p^{-1}(x-\mu_p)}$$ Now suppose that we have another Gaussian distribution  $q(x) \sim  \mathcal{N}(\mu_q,\Sigma_q)$ ** What is the expectation of q(x) in p(x) . I mean, if we randomly sample a point $x$ from P, what is the **expected probability of x in Q? NOTE: I need the solution in closed form. Thanks!",,"['statistics', 'probability-distributions', 'normal-distribution']"
32,"How do I compute ""AUC"" Area under the curve number, if all I have are my TPR and FPR values?","How do I compute ""AUC"" Area under the curve number, if all I have are my TPR and FPR values?",,"I am trying to rank my neural network, which is trained for binary classification.  That is, given a set of input signals, it outputs either a 1 or a 0. I have a training set, where I have the actual desired outcomes (of 1 or 0). After I train my network, I check the output to the input.  From this, I can easily see how many true positives (TP), false positives (FP), true negatives (TN) and false negatives (FN) I have. From the TP, FP, TN, FN, I can compute the TPR and the FPR (true and false positive rates). But I do not know how to compute the AUC score from this data. I would appreciate any help Thanks Lyle","I am trying to rank my neural network, which is trained for binary classification.  That is, given a set of input signals, it outputs either a 1 or a 0. I have a training set, where I have the actual desired outcomes (of 1 or 0). After I train my network, I check the output to the input.  From this, I can easily see how many true positives (TP), false positives (FP), true negatives (TN) and false negatives (FN) I have. From the TP, FP, TN, FN, I can compute the TPR and the FPR (true and false positive rates). But I do not know how to compute the AUC score from this data. I would appreciate any help Thanks Lyle",,"['statistics', 'signal-processing', 'neural-networks']"
33,Why are squares chosen as a weighting method for quantifying the deviations from a mean?,Why are squares chosen as a weighting method for quantifying the deviations from a mean?,,"Reading about variance and it occurred to me that this squaring business seems to be used many places in statistics. I think I understand that the square is used to help ""weight"" values which are further from the mean more heavily, so they don't get swallowed up in when there are a lot of less-deviant values? but, why was squaring chosen, and not cubing? Are there situations where it would make more sense to cube the deviations and not square them? Or was squaring just chosen because it made the deviations powerful, but not too powerful?","Reading about variance and it occurred to me that this squaring business seems to be used many places in statistics. I think I understand that the square is used to help ""weight"" values which are further from the mean more heavily, so they don't get swallowed up in when there are a lot of less-deviant values? but, why was squaring chosen, and not cubing? Are there situations where it would make more sense to cube the deviations and not square them? Or was squaring just chosen because it made the deviations powerful, but not too powerful?",,['statistics']
34,Getting a single-value estimation of trust in a computed mean,Getting a single-value estimation of trust in a computed mean,,"Suppose I have a number N of independent ratings of a given item, where each rating is an integer between 1 and 7 (inclusive).  For simplicity sake, let us assume the ratings are normally distributed, though the mean and stddev will be different for each item. I'm looking for a single number which will reflect how much trust I should  put into the currently calculated mean.  As an example, if I have N=1000  where every single rating is of 4, this trust should be pretty close to 100%. If on the other hand I have only N=2 where one rating is 1 and the other is 7, my trust that the mean is 4 should be very low. I realise that a compute-trust function such as the one I've described  above will likely need further parameterisation beyond the set of ratings. If you prefer, I can reformulate compute-trust in terms of ""with 95% confidence, what is the probability that the population mean will be found within a given interval around the sample mean?"" Any thoughts on how I can compute this trust in a manner that is statistically  sound? Edit: changed 'median' to 'mean'.","Suppose I have a number N of independent ratings of a given item, where each rating is an integer between 1 and 7 (inclusive).  For simplicity sake, let us assume the ratings are normally distributed, though the mean and stddev will be different for each item. I'm looking for a single number which will reflect how much trust I should  put into the currently calculated mean.  As an example, if I have N=1000  where every single rating is of 4, this trust should be pretty close to 100%. If on the other hand I have only N=2 where one rating is 1 and the other is 7, my trust that the mean is 4 should be very low. I realise that a compute-trust function such as the one I've described  above will likely need further parameterisation beyond the set of ratings. If you prefer, I can reformulate compute-trust in terms of ""with 95% confidence, what is the probability that the population mean will be found within a given interval around the sample mean?"" Any thoughts on how I can compute this trust in a manner that is statistically  sound? Edit: changed 'median' to 'mean'.",,['statistics']
35,Is a small or a large population more likely to be dominated by its outliers?,Is a small or a large population more likely to be dominated by its outliers?,,"Prior to 1947, American baseball was racially segregated, with the so-called Major Leagues open only to white players. Black players played in smaller leagues called the ""Negro Leagues"".  Teams in each league played games only against other teams in the same league. Until this year , it was the policy of Major League Baseball that statistics from Negro League play were not incorporated into the official statistics.  For example, a Negro League player who had accumulated a large number of home runs would not have been included on the list of players with the most home runs, regardless of how their total compared with those of players in the Major Leagues.  And if a player had played in both Negro and Major leagues, only their Major League performance was counted in the official statistics. One rationale given for this policy decision was that the Negro Leagues were much smaller than the Major Leagues. The argument was that hitting a large number of home runs in the Negro Leagues might not be as difficult as doing the same in the National League, because the pitchers in the National League would overall have been better than those in the Negro Leagues. My question is whether this is mathematically plausible. The Major League populations of pitchers were certainly larger than those of Negro Leagues, and so might include most of the really excellent pitchers.  But by the same argument a larger league would also have included more sub-par pitchers.  In fact, the great majority of professional baseball players are below-average performers, because talent (however measured) is heavily right-skewed.  I can't guess which effect will dominate the other. (Perhaps neither.) In this question I am only interested in the mathematics , and not in any sort of historical or policy issues. For concreteness: Let's suppose that baseball talent in any particular area (home run hitting or what have you) is normally distributed in the general population but professional baseball players are drawn from the rightmost tail of this distribution, say the people who are $4.5$ or more standard deviations above the mean.       (This is why talent distributions are right-skewed.) Suppose that the population of baseball players has been arbitrarily (uniformly randomly) divided into a small group with fraction $f$ of all players, and a large group with $1-f$ fraction of the players.  (Historically, I think around $f\approx \frac18$ of players played in the Negro Leagues.) My question is : Are the outliers in the small group more extreme, relative to the rest of their group, than the outliers in the large group are relative to the rest of the large group? I imagine that probability theory has a standard definition of an ""outlier"" and a way to measure how extreme a particular outlier is.  Is this correct? Perhaps the answer is as simple as comparing the expected standard deviations of the two groups?  I don't know.","Prior to 1947, American baseball was racially segregated, with the so-called Major Leagues open only to white players. Black players played in smaller leagues called the ""Negro Leagues"".  Teams in each league played games only against other teams in the same league. Until this year , it was the policy of Major League Baseball that statistics from Negro League play were not incorporated into the official statistics.  For example, a Negro League player who had accumulated a large number of home runs would not have been included on the list of players with the most home runs, regardless of how their total compared with those of players in the Major Leagues.  And if a player had played in both Negro and Major leagues, only their Major League performance was counted in the official statistics. One rationale given for this policy decision was that the Negro Leagues were much smaller than the Major Leagues. The argument was that hitting a large number of home runs in the Negro Leagues might not be as difficult as doing the same in the National League, because the pitchers in the National League would overall have been better than those in the Negro Leagues. My question is whether this is mathematically plausible. The Major League populations of pitchers were certainly larger than those of Negro Leagues, and so might include most of the really excellent pitchers.  But by the same argument a larger league would also have included more sub-par pitchers.  In fact, the great majority of professional baseball players are below-average performers, because talent (however measured) is heavily right-skewed.  I can't guess which effect will dominate the other. (Perhaps neither.) In this question I am only interested in the mathematics , and not in any sort of historical or policy issues. For concreteness: Let's suppose that baseball talent in any particular area (home run hitting or what have you) is normally distributed in the general population but professional baseball players are drawn from the rightmost tail of this distribution, say the people who are or more standard deviations above the mean.       (This is why talent distributions are right-skewed.) Suppose that the population of baseball players has been arbitrarily (uniformly randomly) divided into a small group with fraction of all players, and a large group with fraction of the players.  (Historically, I think around of players played in the Negro Leagues.) My question is : Are the outliers in the small group more extreme, relative to the rest of their group, than the outliers in the large group are relative to the rest of the large group? I imagine that probability theory has a standard definition of an ""outlier"" and a way to measure how extreme a particular outlier is.  Is this correct? Perhaps the answer is as simple as comparing the expected standard deviations of the two groups?  I don't know.",4.5 f 1-f f\approx \frac18,['statistics']
36,Minimax Estimator for Normal Random Vector,Minimax Estimator for Normal Random Vector,,"Question. Suppose $Y_i \sim N(\mu_1, 1)$ . Let $Y := (Y_1, Y_2)$ , and $T_y = (Y_1, 0)$ . Denote $\Theta$ as the space of all estimators $\mu := (\mu_1, \mu_2)$ . Is it necessarily true that $\hat{\mu}$ is minimax if $$\Theta := \{\mu : \mu_2 = 0\} \quad\quad\text{or}\quad\quad \Theta := \{\mu : \mu_1 = 0\}.$$ I'm not quite sure how to show these statements. Starting with the leftmost, the risk function is $$ \begin{align} R(\mu, T_Y) &= \mathbb{E}||T_Y - \mu||^2  \\ &= \mathbb{E}||(Y_1 - \mu_1, 0)^T||^2 \\ &= \mathbb{E}\left(Y_1^2 - 2Y_1\mu_1 + \mu_1^2\right) \\ &= \mathbb{E}Y_1^2 - 2\mu_1\mathbb{E}Y_1 + \mu_1^2 \\ &= 1 + \mu_1^2 - \mu_1^2 \\ &= 1. \end{align} $$ So, $\hat{\mu}$ is a minimax estimator if $$\sup_{\mu \in \Theta}\mathbb{E}||\hat{\mu} - \mu||^2 = \inf_T\sup_{\mu \in \Theta} R(\mu, T_Y) = 1$$ Not sure how to proceed? I'm assuming the other statement will be similart to solve.","Question. Suppose . Let , and . Denote as the space of all estimators . Is it necessarily true that is minimax if I'm not quite sure how to show these statements. Starting with the leftmost, the risk function is So, is a minimax estimator if Not sure how to proceed? I'm assuming the other statement will be similart to solve.","Y_i \sim N(\mu_1, 1) Y := (Y_1, Y_2) T_y = (Y_1, 0) \Theta \mu := (\mu_1, \mu_2) \hat{\mu} \Theta := \{\mu : \mu_2 = 0\} \quad\quad\text{or}\quad\quad \Theta := \{\mu : \mu_1 = 0\}. 
\begin{align}
R(\mu, T_Y) &= \mathbb{E}||T_Y - \mu||^2  \\
&= \mathbb{E}||(Y_1 - \mu_1, 0)^T||^2 \\
&= \mathbb{E}\left(Y_1^2 - 2Y_1\mu_1 + \mu_1^2\right) \\
&= \mathbb{E}Y_1^2 - 2\mu_1\mathbb{E}Y_1 + \mu_1^2 \\
&= 1 + \mu_1^2 - \mu_1^2 \\
&= 1.
\end{align}
 \hat{\mu} \sup_{\mu \in \Theta}\mathbb{E}||\hat{\mu} - \mu||^2 = \inf_T\sup_{\mu \in \Theta} R(\mu, T_Y) = 1","['statistics', 'statistical-inference', 'decision-theory', 'parameter-estimation']"
37,How many points uniquely determine a skew normal distribution?,How many points uniquely determine a skew normal distribution?,,"The normal distribution pdf is defined to be: $$ \phi(x| \mu, \sigma)=\frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{(x-\mu)^{2}}{2\sigma^2}} $$ The cdf is given by: $$ \Phi(x)=\int_{-\infty}^{x} \phi(t) dt $$ If we are given the value of $\phi(x)$ at three distinct points, this is sufficient to uniquely determine $\mu$ and $\sigma$ . The pdf of the general skew normal distribution is defined to be: $$ f(x)=\frac{2}{\omega} \phi\left(\frac{x-\xi}{\omega}\right) \Phi\left(\alpha\left(\frac{x-\xi}{\omega}\right)\right) $$ How many points are needed to determine $\xi$ , $\omega$ and $\alpha$ ? Even though we have one more variable than in the non-skewed case, it looks like two skew normal distributions can only intersect in two places. So maybe we need only three again? @Rahul points out in the comments that the pdf of two skew normal distributions can in fact  intersect at three points. This leads to the guess, is four points sufficient to uniquely determine the distribution?","The normal distribution pdf is defined to be: The cdf is given by: If we are given the value of at three distinct points, this is sufficient to uniquely determine and . The pdf of the general skew normal distribution is defined to be: How many points are needed to determine , and ? Even though we have one more variable than in the non-skewed case, it looks like two skew normal distributions can only intersect in two places. So maybe we need only three again? @Rahul points out in the comments that the pdf of two skew normal distributions can in fact  intersect at three points. This leads to the guess, is four points sufficient to uniquely determine the distribution?","
\phi(x| \mu, \sigma)=\frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{(x-\mu)^{2}}{2\sigma^2}}
 
\Phi(x)=\int_{-\infty}^{x} \phi(t) dt
 \phi(x) \mu \sigma 
f(x)=\frac{2}{\omega} \phi\left(\frac{x-\xi}{\omega}\right) \Phi\left(\alpha\left(\frac{x-\xi}{\omega}\right)\right)
 \xi \omega \alpha",['calculus']
38,Showing Independence of $S^2$ and $\bar{X}$ if variance is unknown,Showing Independence of  and  if variance is unknown,S^2 \bar{X},"I have a question regarding the use of Basu's Lemma. Assume that $$X \sim N(\theta, \sigma^2).$$ In that case, we can use Basu's Lemma to show that $$\bar{X}$$ and $$S^2= \frac{1}{n-1}\sum(X_i-\bar{X})^2$$ are independent, if we show that $T:=\bar{X}$ is complete and sufficient (e.g. by the definition of exponential families) and that the distribution of $S^2$ does not depend on $\theta$ which is the case here. However, when $\sigma^2$ would be unknown as well, the distribution of $S^2$ would depend on $\theta$ . Can we still use Basu's Lemma somehow to show independence in that case ? I was confused by the following statement in the book Statistical Inference by Casella and Berger on p.289:","I have a question regarding the use of Basu's Lemma. Assume that In that case, we can use Basu's Lemma to show that and are independent, if we show that is complete and sufficient (e.g. by the definition of exponential families) and that the distribution of does not depend on which is the case here. However, when would be unknown as well, the distribution of would depend on . Can we still use Basu's Lemma somehow to show independence in that case ? I was confused by the following statement in the book Statistical Inference by Casella and Berger on p.289:","X \sim N(\theta, \sigma^2). \bar{X} S^2= \frac{1}{n-1}\sum(X_i-\bar{X})^2 T:=\bar{X} S^2 \theta \sigma^2 S^2 \theta","['statistics', 'probability-distributions', 'normal-distribution', 'independence']"
39,Expectation of sample precision matrix,Expectation of sample precision matrix,,"Let $x_{i} \sim N(0, \Sigma_{d \times d})$ be $n$ i.i.d. Gaussian vectors, and let $X$ be an $n \times d$ matrix, whose $i$ -th row is equal to $x_{i}$ . It is then known that $$ \mathbb{E}[(X^{\mathsf{T}}X)^{-1}] = \frac{1}{n - d - 1}\Sigma^{-1} $$ since $(X^{T}X)^{-1}$ follows an Inverse-Wishart distribution. Now, if we replace the Gaussian distribution, with any other distribution and the same covariance matrix, we would still get $$ \mathbb{E}[X^{T}X] = n\Sigma $$ and so $$ \mathbb{E}[(X^{T}X)^{-1}] \geq \frac{1}{n} \Sigma^{-1}. $$ My question is, in what cases can $\mathbb{E}[(X^{\mathsf{T}}X)^{-1}]$ be computed and does it have to be proportional to $\Sigma^{-1}$ ? If it cannot be computed, what are known ways to upper bound it? Any references even tangentially related would be much appreciated.","Let be i.i.d. Gaussian vectors, and let be an matrix, whose -th row is equal to . It is then known that since follows an Inverse-Wishart distribution. Now, if we replace the Gaussian distribution, with any other distribution and the same covariance matrix, we would still get and so My question is, in what cases can be computed and does it have to be proportional to ? If it cannot be computed, what are known ways to upper bound it? Any references even tangentially related would be much appreciated.","x_{i} \sim N(0, \Sigma_{d \times d}) n X n \times d i x_{i} 
\mathbb{E}[(X^{\mathsf{T}}X)^{-1}] = \frac{1}{n - d - 1}\Sigma^{-1}
 (X^{T}X)^{-1} 
\mathbb{E}[X^{T}X] = n\Sigma
 
\mathbb{E}[(X^{T}X)^{-1}] \geq \frac{1}{n} \Sigma^{-1}.
 \mathbb{E}[(X^{\mathsf{T}}X)^{-1}] \Sigma^{-1}","['statistics', 'reference-request', 'random-matrices']"
40,Chi Square Contingency Table - Formula Derivation,Chi Square Contingency Table - Formula Derivation,,"A chi-square distribution is constructed from normal random variables $X_i i=1,...n$ , each with normal distribution and mean $\mu$ and variance $\sigma^2$.  Transforming to standard normal and squaring, i.e.: $$\frac{(X_i - \bar{X})^2}{\operatorname{Var}(X_i)}\sim N(0,1)^2$$ Then add these over all your $n$ random variables, then you get $\chi^2_{n-1}$ - a chi-square with $n-1$ degrees of freedom. For contingency tables, suppose there are $k$ categories of observations $O_i, i = 1, \ldots , k,$ each with probability $p_i$. The statistic we’re proposing, assuming $O_i \sim \operatorname{Normal}$, is: $$\frac{(O_i-np_i)^2}{\operatorname{Var}(O_i)} \sim N(0,1)^2$$ The variance of each observation is $np_i(1-p_i)$ For contingency tables, a test to see if the underlying mean is the same across categories, the standard equation taught for calculating the Chi-Square statistic is: $$\sum_{i=1}^k\frac{(O_i-np_i)^2}{np_i} \sim \chi^2_{n-1}$$ So, where in the equation for assessing contingency tables does the term $(1-p_i)$ disappear to?","A chi-square distribution is constructed from normal random variables $X_i i=1,...n$ , each with normal distribution and mean $\mu$ and variance $\sigma^2$.  Transforming to standard normal and squaring, i.e.: $$\frac{(X_i - \bar{X})^2}{\operatorname{Var}(X_i)}\sim N(0,1)^2$$ Then add these over all your $n$ random variables, then you get $\chi^2_{n-1}$ - a chi-square with $n-1$ degrees of freedom. For contingency tables, suppose there are $k$ categories of observations $O_i, i = 1, \ldots , k,$ each with probability $p_i$. The statistic we’re proposing, assuming $O_i \sim \operatorname{Normal}$, is: $$\frac{(O_i-np_i)^2}{\operatorname{Var}(O_i)} \sim N(0,1)^2$$ The variance of each observation is $np_i(1-p_i)$ For contingency tables, a test to see if the underlying mean is the same across categories, the standard equation taught for calculating the Chi-Square statistic is: $$\sum_{i=1}^k\frac{(O_i-np_i)^2}{np_i} \sim \chi^2_{n-1}$$ So, where in the equation for assessing contingency tables does the term $(1-p_i)$ disappear to?",,"['statistics', 'independence', 'actuarial-science', 'chi-squared']"
41,Proving a function of the empirical distribution is a Martingale,Proving a function of the empirical distribution is a Martingale,,"Let $X_1, \dots, X_n$ be a sequence of i.i.d. random variables with distribution function $G$, let $$ G_t = \frac{\# \{ k : X_k \leq t \}}{n} $$ define the empirical distribution relative to the random variables. Set $A_t  = \sqrt{n} (G_t - G(t))$, $$ M_t = \frac{A_t}{1 - G(t)}\ \ \ \ \ B_t = A_t + \int_{-\infty}^t M_s\ dG(s)\ \ \ \ \ V_t = B_t^2 - G_t $$ It is rather simpler to verify that $M_t$ and $B_t$ are martingales with respect to the filtration $\Sigma_t = \sigma(G_s: s \leq t)$, but however I try to compute that $V_t$ is a martingale, I end up with an incredibly difficult calculation. Is there any easy way to see that $V_t$ is a martingale?","Let $X_1, \dots, X_n$ be a sequence of i.i.d. random variables with distribution function $G$, let $$ G_t = \frac{\# \{ k : X_k \leq t \}}{n} $$ define the empirical distribution relative to the random variables. Set $A_t  = \sqrt{n} (G_t - G(t))$, $$ M_t = \frac{A_t}{1 - G(t)}\ \ \ \ \ B_t = A_t + \int_{-\infty}^t M_s\ dG(s)\ \ \ \ \ V_t = B_t^2 - G_t $$ It is rather simpler to verify that $M_t$ and $B_t$ are martingales with respect to the filtration $\Sigma_t = \sigma(G_s: s \leq t)$, but however I try to compute that $V_t$ is a martingale, I end up with an incredibly difficult calculation. Is there any easy way to see that $V_t$ is a martingale?",,"['statistics', 'stochastic-processes', 'martingales', 'empirical-processes']"
42,Controlling the number of nonzero components in the LASSO solution,Controlling the number of nonzero components in the LASSO solution,,"Let $A$ be a real $m \times n$ matrix. The Lasso optimization problem is $$ \text{minimize} \quad \frac12 \| Ax - b \|_2^2 + \lambda \| x \|_1 $$ The optimization variable is $x \in \mathbb R^n$. The $\ell_1$-norm regularization term encourages $x$ to be sparse, so Lasso is useful for finding a sparse vector $x$ that satisfies $Ax \approx b$.  The parameter $\lambda > 0$ controls how sparse the solution to the Lasso problem is. Question: Suppose I know that I would like for the solution to the Lasso problem to have exactly $p$ nonzero entries.  Are there any techniques or tricks or heuristics for choosing a value of $\lambda$ such that the solution to the Lasso problem has exactly (or at least approximately) $p$ nonzero entries?","Let $A$ be a real $m \times n$ matrix. The Lasso optimization problem is $$ \text{minimize} \quad \frac12 \| Ax - b \|_2^2 + \lambda \| x \|_1 $$ The optimization variable is $x \in \mathbb R^n$. The $\ell_1$-norm regularization term encourages $x$ to be sparse, so Lasso is useful for finding a sparse vector $x$ that satisfies $Ax \approx b$.  The parameter $\lambda > 0$ controls how sparse the solution to the Lasso problem is. Question: Suppose I know that I would like for the solution to the Lasso problem to have exactly $p$ nonzero entries.  Are there any techniques or tricks or heuristics for choosing a value of $\lambda$ such that the solution to the Lasso problem has exactly (or at least approximately) $p$ nonzero entries?",,"['statistics', 'convex-optimization', 'sparsity']"
43,A question about the Laplace transform of the probability distribution function,A question about the Laplace transform of the probability distribution function,,"I am an undergraduate, who has just begun getting into probability theory. Recently we learned of the moment generating function of a random variable can be used to find moments, and the moment generating function is defined as $$ MGFx(t) =  E[e^{tX}] =\begin{cases} \sum e^{tx}p(x), & \text{if X is discrete}\\ \int e^{tx}f(x)dx,\ & \text{if X is continuous} \end{cases}$$  The moment generating function can also be viewed as a Laplace transform of the probability density function of the random variable X, by replacing s with -t , $${\scr L}(pdf(X))=M_X(t)=\int_0^\infty f(x)e^{xt}\,dt$$ From here, one may take derivations with respect to t of $M_x(t)$, and then evaluate the derivative at t = 0, to find the respective moment of the probability distribution function, i.e. $$ \frac{d^{n}}{dt^{n}}\ M_x(t) = M^n_X(t) $$ $$ M^n_X(0) = E[X^n], n =1,2,3,...$$ When I have dealt with the Laplace transform of a function in the past, for differential equations, the text stated that the transform redefines a function $f(t)$ such that the function is now defined by a complex variable s, where $s = \sigma +i\omega$, and $${\scr L}(f(t))=\int_0^\infty f(t)e^{-st}\,dt =F(s)$$ For the majority of differential equations that I have dealt with, that involve a Laplace transform to solve, we are converting to from a function of time(t) to one of frequency(s), and the transformed function now has computation done on it in the complex frequency domain until the transform is reversed. My question is that for the Laplace transform of a probability distribution function, what does the complex domain that the function is transformed to represent? More specifically what is the variable ""t"" that is introduced, and what is the meaning of the derivative of the moment generating function, with respect to t? Is the variable t arbitrary or is it the representation of something? Thank you.","I am an undergraduate, who has just begun getting into probability theory. Recently we learned of the moment generating function of a random variable can be used to find moments, and the moment generating function is defined as $$ MGFx(t) =  E[e^{tX}] =\begin{cases} \sum e^{tx}p(x), & \text{if X is discrete}\\ \int e^{tx}f(x)dx,\ & \text{if X is continuous} \end{cases}$$  The moment generating function can also be viewed as a Laplace transform of the probability density function of the random variable X, by replacing s with -t , $${\scr L}(pdf(X))=M_X(t)=\int_0^\infty f(x)e^{xt}\,dt$$ From here, one may take derivations with respect to t of $M_x(t)$, and then evaluate the derivative at t = 0, to find the respective moment of the probability distribution function, i.e. $$ \frac{d^{n}}{dt^{n}}\ M_x(t) = M^n_X(t) $$ $$ M^n_X(0) = E[X^n], n =1,2,3,...$$ When I have dealt with the Laplace transform of a function in the past, for differential equations, the text stated that the transform redefines a function $f(t)$ such that the function is now defined by a complex variable s, where $s = \sigma +i\omega$, and $${\scr L}(f(t))=\int_0^\infty f(t)e^{-st}\,dt =F(s)$$ For the majority of differential equations that I have dealt with, that involve a Laplace transform to solve, we are converting to from a function of time(t) to one of frequency(s), and the transformed function now has computation done on it in the complex frequency domain until the transform is reversed. My question is that for the Laplace transform of a probability distribution function, what does the complex domain that the function is transformed to represent? More specifically what is the variable ""t"" that is introduced, and what is the meaning of the derivative of the moment generating function, with respect to t? Is the variable t arbitrary or is it the representation of something? Thank you.",,"['statistics', 'random-variables', 'laplace-transform', 'moment-generating-functions']"
44,Derivative of expected log likelihood in a logistic regression model,Derivative of expected log likelihood in a logistic regression model,,"Consider the univariate logistic regression model: $$ P(Y = 1\mid X = x) = \psi(x\beta_0)\equiv \frac 1 {1+\exp\{-x \beta_0\}},\quad\text{for all $x$, and some unknown $\beta_0\in\mathbb{R}$.} $$ Assume that, $X$ has a finite positive variance and marginal distribution $Q(x)$. The score function based on one sample $(Y,X)$ is, $$ Z(\beta :Y,X) = X\cdot\big\{Y-\psi(X\beta)\big\}. $$ The expected log-likelihood based on one sample is $$ M(\beta)\equiv \mathbf{E}\left[Y\log\psi(X\beta) + (1-Y)\log\big\{1-\psi(X\beta) \big\} \right], $$ where, $\mathbf{E}$ denotes expectation under the true joint distribution of $(Y,X)$ under the parameter $\beta_0$. My questions are: (i) How to show that $M(\beta)$ is finite for all $\beta$. (ii) Is, $M^\prime(\beta)=\mathbf{E}\big(Z(\beta:Y,X)\big)$, for all $\beta$. If so, then what are the required conditions.","Consider the univariate logistic regression model: $$ P(Y = 1\mid X = x) = \psi(x\beta_0)\equiv \frac 1 {1+\exp\{-x \beta_0\}},\quad\text{for all $x$, and some unknown $\beta_0\in\mathbb{R}$.} $$ Assume that, $X$ has a finite positive variance and marginal distribution $Q(x)$. The score function based on one sample $(Y,X)$ is, $$ Z(\beta :Y,X) = X\cdot\big\{Y-\psi(X\beta)\big\}. $$ The expected log-likelihood based on one sample is $$ M(\beta)\equiv \mathbf{E}\left[Y\log\psi(X\beta) + (1-Y)\log\big\{1-\psi(X\beta) \big\} \right], $$ where, $\mathbf{E}$ denotes expectation under the true joint distribution of $(Y,X)$ under the parameter $\beta_0$. My questions are: (i) How to show that $M(\beta)$ is finite for all $\beta$. (ii) Is, $M^\prime(\beta)=\mathbf{E}\big(Z(\beta:Y,X)\big)$, for all $\beta$. If so, then what are the required conditions.",,"['statistics', 'estimation', 'maximum-likelihood', 'logistic-regression']"
45,Likelihood function & MLE without known values of observed data,Likelihood function & MLE without known values of observed data,,"Question : Let $X_1,\dots,X_n$ be iid exponential rate $\lambda$. Suppose we don't know the observed values of our experiments, but we know that $k$ values were $\le M$ and the remaining $n-k$ were $>M$ for some constant $M$. Find the MLE of $\lambda$. I need to find the likelihood function $L(\lambda; \vec x) $, which is typically defined as $ \prod_{i=1}^n f(x_i;\lambda)$ for iid data. Now, I intuitively believe that the $L(\lambda; \vec x)$ will equal ${n \choose k} [P(X \le M)]^k [P(X > M)]^{n-k}$, but I'm not satisfied with my explanation why. The likelihood function is defined as $L(\theta) = f(x_1,\dots,x_n;\theta)$, where $\theta$ is allowed to vary. I don't know how to relate this definition in terms of the pdf to the fact that precisely $k$ observed values were $\le M$. Can someone help with a more rigorous explanation?","Question : Let $X_1,\dots,X_n$ be iid exponential rate $\lambda$. Suppose we don't know the observed values of our experiments, but we know that $k$ values were $\le M$ and the remaining $n-k$ were $>M$ for some constant $M$. Find the MLE of $\lambda$. I need to find the likelihood function $L(\lambda; \vec x) $, which is typically defined as $ \prod_{i=1}^n f(x_i;\lambda)$ for iid data. Now, I intuitively believe that the $L(\lambda; \vec x)$ will equal ${n \choose k} [P(X \le M)]^k [P(X > M)]^{n-k}$, but I'm not satisfied with my explanation why. The likelihood function is defined as $L(\theta) = f(x_1,\dots,x_n;\theta)$, where $\theta$ is allowed to vary. I don't know how to relate this definition in terms of the pdf to the fact that precisely $k$ observed values were $\le M$. Can someone help with a more rigorous explanation?",,"['statistics', 'statistical-inference']"
46,"Geometric mean, harmonic mean and loss functions","Geometric mean, harmonic mean and loss functions",,Consider a sequence $(x_i)_{i \in I}$ of real numbers indexed on a set $I$. The mode of the series is the minimizing argument for the $L_0$ loss $$ \text{mode}[ \; (x_i)_{i \in I} \; ] = \arg\min_{u \in \mathbb{R}} \; \; \sum_{i \in I} \; | x_i - u|^0 $$ The median is the minimizing argument for the $L_1$ loss $$ \text{median}[ \; (x_i)_{i \in I} \; ] = \arg\min_{u \in \mathbb{R}} \; \; \sum_{i \in I} \; | x_i - u|^1 $$ The arithmetic mean is the minimizing argument for the $L_2$ loss $$ \text{arithmetic mean}[ \; (x_i)_{i \in I} \; ] = \arg\min_{u \in \mathbb{R}} \; \; \sum_{i \in I} \; | x_i - u|^2 $$ Can we find similar results for the harmonic mean or the geometric mean? Thanks!,Consider a sequence $(x_i)_{i \in I}$ of real numbers indexed on a set $I$. The mode of the series is the minimizing argument for the $L_0$ loss $$ \text{mode}[ \; (x_i)_{i \in I} \; ] = \arg\min_{u \in \mathbb{R}} \; \; \sum_{i \in I} \; | x_i - u|^0 $$ The median is the minimizing argument for the $L_1$ loss $$ \text{median}[ \; (x_i)_{i \in I} \; ] = \arg\min_{u \in \mathbb{R}} \; \; \sum_{i \in I} \; | x_i - u|^1 $$ The arithmetic mean is the minimizing argument for the $L_2$ loss $$ \text{arithmetic mean}[ \; (x_i)_{i \in I} \; ] = \arg\min_{u \in \mathbb{R}} \; \; \sum_{i \in I} \; | x_i - u|^2 $$ Can we find similar results for the harmonic mean or the geometric mean? Thanks!,,"['statistics', 'average', 'means']"
47,What's the most accurate way to estimate a percentile from multiple partial percentiles?,What's the most accurate way to estimate a percentile from multiple partial percentiles?,,"There exists 3 sets of numbers. I have the 99th percentile (p99) of each set and the cardinality of the set, but not the values in the set themselves. p99: 540, cardinality: 215 p99: 288, cardinality: 4 p99: 432, cardinality: 78 What is the most accurate way to estimate the combined p99 of those 3 sets without having access to the original data? Right now I'm debating the follow 2 options: Simply use the p99 value of the set with the highest cardinality. Use a weighted average of the p99 values Are there better, more accurate options?","There exists 3 sets of numbers. I have the 99th percentile (p99) of each set and the cardinality of the set, but not the values in the set themselves. p99: 540, cardinality: 215 p99: 288, cardinality: 4 p99: 432, cardinality: 78 What is the most accurate way to estimate the combined p99 of those 3 sets without having access to the original data? Right now I'm debating the follow 2 options: Simply use the p99 value of the set with the highest cardinality. Use a weighted average of the p99 values Are there better, more accurate options?",,"['statistics', 'approximation', 'percentile']"
48,Random sphere-valued fields,Random sphere-valued fields,,"I would like to generate random functions from an $m$-sphere $S^m$ to an $n$-sphere $S^n$ that are not too wild, some kind of generalization of random Gaussian fields . More precisely, I want $f(x)$, for any $x\in S^m$, to be a random point on $S^n$ with uniform probability distribution, and a property that $f(x)$ and $f(y)$ are probably close to each other, whenever $x$ and $y$ are close. (The analogy in Gaussian processes is that the covariance decays via some given function) One question I have in mind is to see, how often a random function is homotopically trivial. Is there a way to define such maps algorithmically and/or a reference to a rigorous definition of such sphere-valued fields?","I would like to generate random functions from an $m$-sphere $S^m$ to an $n$-sphere $S^n$ that are not too wild, some kind of generalization of random Gaussian fields . More precisely, I want $f(x)$, for any $x\in S^m$, to be a random point on $S^n$ with uniform probability distribution, and a property that $f(x)$ and $f(y)$ are probably close to each other, whenever $x$ and $y$ are close. (The analogy in Gaussian processes is that the covariance decays via some given function) One question I have in mind is to see, how often a random function is homotopically trivial. Is there a way to define such maps algorithmically and/or a reference to a rigorous definition of such sphere-valued fields?",,"['statistics', 'random-variables', 'homotopy-theory']"
49,Intuitive explanation of requirement for achieving the Cramer Rao Lower Bound,Intuitive explanation of requirement for achieving the Cramer Rao Lower Bound,,"this question relates to the requirement for achieving CRLB. I know that for a random sample $Y_1, \ldots, Y_n$, an estimator $U$ of $g(\theta)$ is MVUE (i.e. it is unbiased and also $\operatorname{Var}(U) = \frac{[\frac{\delta}{\delta\theta}g(\theta)]^2}{I_Y{(\theta})}$), then it also achieves its CRLB. However if the logic flows the other way, that is to say, for the unbiased estimator $U$, $U$ achieves its CRLB iff $s(\theta;y) = b(\theta)(h(y) - g(\theta))$. My question: Can someone please explain, intuitively, this requirement $s(\theta;y) = b(\theta)(h(y) - g(\theta))$ please? Many thanks","this question relates to the requirement for achieving CRLB. I know that for a random sample $Y_1, \ldots, Y_n$, an estimator $U$ of $g(\theta)$ is MVUE (i.e. it is unbiased and also $\operatorname{Var}(U) = \frac{[\frac{\delta}{\delta\theta}g(\theta)]^2}{I_Y{(\theta})}$), then it also achieves its CRLB. However if the logic flows the other way, that is to say, for the unbiased estimator $U$, $U$ achieves its CRLB iff $s(\theta;y) = b(\theta)(h(y) - g(\theta))$. My question: Can someone please explain, intuitively, this requirement $s(\theta;y) = b(\theta)(h(y) - g(\theta))$ please? Many thanks",,"['statistics', 'statistical-inference', 'parameter-estimation']"
50,How to compute uniformly distributed points on an ellipse,How to compute uniformly distributed points on an ellipse,,"The ellipse can be parametrized in polar coordinates by $$r(\theta)=\frac{1}{a+\cos\theta}$$ up to a scaling factor, and $a>1$. Suppose we measure $S$, the distance along the ellipse from the $\theta=0$ point, where $r$ is minimal. The metric gives small changes of S with respect to $\theta$: $$dS^2=dr^2+r^2d\theta^2$$ which leads to $$dS=\sqrt{r^2+\left(\frac{dr}{d\theta}\right)^2}d\theta.$$ and finally to $$dS=\frac{\sqrt{a^2+2 a\cos\theta+1}}{(a+\cos\theta)^2}d\theta.$$ Integrating we get $$S(\theta)=\int_0^\theta \frac{\sqrt{a^2+2 a\cos{u}+1}}{(a+\cos{u})^2}du=F(\theta)$$ Now we have to generate a set $\{s_i\}$ of uniformly distributed numbers over $[0,1)$ and solve $$Ls_i=F(\theta_i)$$ where $L$ is the total length aroung the ellipse. However, the above integral involves elliptic functions and the inversion is not possible analytically. Is there any other way of doing this, perhaps geometrically before setting up some kind of root finding method? Thanks a bunch!","The ellipse can be parametrized in polar coordinates by $$r(\theta)=\frac{1}{a+\cos\theta}$$ up to a scaling factor, and $a>1$. Suppose we measure $S$, the distance along the ellipse from the $\theta=0$ point, where $r$ is minimal. The metric gives small changes of S with respect to $\theta$: $$dS^2=dr^2+r^2d\theta^2$$ which leads to $$dS=\sqrt{r^2+\left(\frac{dr}{d\theta}\right)^2}d\theta.$$ and finally to $$dS=\frac{\sqrt{a^2+2 a\cos\theta+1}}{(a+\cos\theta)^2}d\theta.$$ Integrating we get $$S(\theta)=\int_0^\theta \frac{\sqrt{a^2+2 a\cos{u}+1}}{(a+\cos{u})^2}du=F(\theta)$$ Now we have to generate a set $\{s_i\}$ of uniformly distributed numbers over $[0,1)$ and solve $$Ls_i=F(\theta_i)$$ where $L$ is the total length aroung the ellipse. However, the above integral involves elliptic functions and the inversion is not possible analytically. Is there any other way of doing this, perhaps geometrically before setting up some kind of root finding method? Thanks a bunch!",,"['statistics', 'trigonometry', 'probability-distributions', 'metric-spaces']"
51,"What is ${\rm cov}(e_i, \hat y_i)$ in simple linear regression?",What is  in simple linear regression?,"{\rm cov}(e_i, \hat y_i)","The model is $y_i = \beta_0 + \beta_1x_i + \epsilon_i$ What is ${\rm cov}(e_i, \hat y_i)$? What is ${\rm cov}(\epsilon_i, \hat \beta_1)$? What is ${\rm cov}(e_i, \epsilon_i)$? For 1, I am writing  ${\rm cov}(e_i, \hat y_i)$ as \begin{align} {\rm cov}(e_i, \hat \beta_0+\hat\beta_1x_i)        &= {\rm cov}(e_i, \hat\beta_0) + x_i {\rm var}(e_i, \hat\beta_1)  \\      &= {\rm cov}(\bar y - \hat \beta_1 \bar x, y_i-\bar y - \hat \beta_1(x_i-\bar x))  \\      &= {\rm cov}(\bar y, y_i) - {\rm var}(\bar y) - \bar x {\rm cov}(\hat \beta_1, y_i) + (x_i -\bar x)\bar x{\rm var}(\hat \beta_1)  \\      &= \frac{\sigma^2}{n}-\frac{\sigma^2}{n}-\frac{(x_i - \bar x)\bar x}{\sum (x_i - \bar x)^2}\sigma^2 + \frac{(x_i - \bar x)\bar x}{\sum (x_i - \bar x)^2}\sigma^2  \\      &= 0 \end{align} For 2, ${\rm cov}(\epsilon_i, \hat \beta_1) = {\rm cov}(\epsilon_i, \frac{\sum (x_i - \bar x)y_i}{\sum (x_i - \bar x)^2} = \frac{(x_i - \bar x)}{\sum (x_i - \bar x)^2}\sigma^2$ For 3,  \begin{align}{\rm cov}(e_i, \epsilon_i)     &=  {\rm cov}(\epsilon_i, y_i-\bar y - \hat \beta_1(x_i-\bar x) )  \\    &= {\rm cov}(\epsilon_i, y_i) - {\rm cov}(\epsilon_i, \bar y) - {\rm cov}(\epsilon_i, \hat \beta_1(x_i - \bar x))  \\    &= \sigma^2 - \frac{\sigma^2}{n} - \frac{(x_i - \bar x)^2}{\sum (x_i - \bar x)^2}\sigma^2 \end{align} Can someone look at my derivation and tell me if there is any mistake?","The model is $y_i = \beta_0 + \beta_1x_i + \epsilon_i$ What is ${\rm cov}(e_i, \hat y_i)$? What is ${\rm cov}(\epsilon_i, \hat \beta_1)$? What is ${\rm cov}(e_i, \epsilon_i)$? For 1, I am writing  ${\rm cov}(e_i, \hat y_i)$ as \begin{align} {\rm cov}(e_i, \hat \beta_0+\hat\beta_1x_i)        &= {\rm cov}(e_i, \hat\beta_0) + x_i {\rm var}(e_i, \hat\beta_1)  \\      &= {\rm cov}(\bar y - \hat \beta_1 \bar x, y_i-\bar y - \hat \beta_1(x_i-\bar x))  \\      &= {\rm cov}(\bar y, y_i) - {\rm var}(\bar y) - \bar x {\rm cov}(\hat \beta_1, y_i) + (x_i -\bar x)\bar x{\rm var}(\hat \beta_1)  \\      &= \frac{\sigma^2}{n}-\frac{\sigma^2}{n}-\frac{(x_i - \bar x)\bar x}{\sum (x_i - \bar x)^2}\sigma^2 + \frac{(x_i - \bar x)\bar x}{\sum (x_i - \bar x)^2}\sigma^2  \\      &= 0 \end{align} For 2, ${\rm cov}(\epsilon_i, \hat \beta_1) = {\rm cov}(\epsilon_i, \frac{\sum (x_i - \bar x)y_i}{\sum (x_i - \bar x)^2} = \frac{(x_i - \bar x)}{\sum (x_i - \bar x)^2}\sigma^2$ For 3,  \begin{align}{\rm cov}(e_i, \epsilon_i)     &=  {\rm cov}(\epsilon_i, y_i-\bar y - \hat \beta_1(x_i-\bar x) )  \\    &= {\rm cov}(\epsilon_i, y_i) - {\rm cov}(\epsilon_i, \bar y) - {\rm cov}(\epsilon_i, \hat \beta_1(x_i - \bar x))  \\    &= \sigma^2 - \frac{\sigma^2}{n} - \frac{(x_i - \bar x)^2}{\sum (x_i - \bar x)^2}\sigma^2 \end{align} Can someone look at my derivation and tell me if there is any mistake?",,"['statistics', 'regression', 'covariance']"
52,Intuition behind (statistical) completeness,Intuition behind (statistical) completeness,,"I was wondering if any of the members of the MSE community would like to share his/her intuition about completeness in statistics. For the sake of ""completeness"", here's the definition, taken from Wikipedia : Consider a random variable $X$ whose probability distribution belongs to a parametric family of probability distributions $P_\theta$ parametrized by $\theta$ . The statistic $T$ is said to be complete for the distribution of $X$ if for every measurable function $g$ (which must be independent of $\theta$ ) the following implication holds: $$E(g(T(X))) = 0 \mbox{ for all }\theta \mbox{ implies that }P_\theta(g(T(X)) = 0) = 1\mbox{ for all }\theta.$$ Now, to give you an idea of what kind of answer I am looking for, here's how I think about (minimal) sufficiency: I think of a statistic as a partition of the sample space. In that context, a statistic is sufficient for $\theta$ if this partition does not result in a loss of ""information"" about $\theta$ ; it is minimal sufficient if it is the coarsest partition which does not result in a loss of information (superlatives carry a uniqueness connotation, which I am ignoring here).","I was wondering if any of the members of the MSE community would like to share his/her intuition about completeness in statistics. For the sake of ""completeness"", here's the definition, taken from Wikipedia : Consider a random variable whose probability distribution belongs to a parametric family of probability distributions parametrized by . The statistic is said to be complete for the distribution of if for every measurable function (which must be independent of ) the following implication holds: Now, to give you an idea of what kind of answer I am looking for, here's how I think about (minimal) sufficiency: I think of a statistic as a partition of the sample space. In that context, a statistic is sufficient for if this partition does not result in a loss of ""information"" about ; it is minimal sufficient if it is the coarsest partition which does not result in a loss of information (superlatives carry a uniqueness connotation, which I am ignoring here).",X P_\theta \theta T X g \theta E(g(T(X))) = 0 \mbox{ for all }\theta \mbox{ implies that }P_\theta(g(T(X)) = 0) = 1\mbox{ for all }\theta. \theta \theta,"['statistics', 'intuition', 'random-variables']"
53,Multilinear or Tensor Regression?,Multilinear or Tensor Regression?,,"Given input data $x_t\in \mathbb{R}^n$ and output data $y_t\in\mathbb{R}^m$, the closed form solution to $\min_A \sum_t \|y_t - Ax_t\|^2_2$ is given by $A = (XX^T)^{-1}XY^T$ where $x_t$ form the columns of $X$ and similarly for $Y$. This is the solution to least-squares regression. Suppose instead of one set of inputs, we had $k$ sets of inputs $x^1_t,\ldots,x^k_t$ from vector spaces $\mathbb{R}^{n_1},\ldots,\mathbb{R}^{n_k}$ and we wanted to find the multilinear map $A$ from $\mathbb{R}^{n_1}\times\ldots\times\mathbb{R}^{n_k}$ to $\mathbb{R}^m$ that minimizes $$\sum_t \|y_t - A(x^1_t,\ldots,x^k_t)\|^2_2$$ Is there a closed form solution to this? Trying the usual method (write out multilinear map in index notation, take derivatives and set to zero) it looks like $$A = \sum_t y_t \otimes (X^1X^{1T})^{-1}x^1_t \otimes \ldots \otimes (X^kX^{kT})^{-1}x^k_t$$ might work, where $\otimes$ denotes outer product, but my algebra could be wrong. It does, at least, reduce to the least squares regression case when $k=1$.","Given input data $x_t\in \mathbb{R}^n$ and output data $y_t\in\mathbb{R}^m$, the closed form solution to $\min_A \sum_t \|y_t - Ax_t\|^2_2$ is given by $A = (XX^T)^{-1}XY^T$ where $x_t$ form the columns of $X$ and similarly for $Y$. This is the solution to least-squares regression. Suppose instead of one set of inputs, we had $k$ sets of inputs $x^1_t,\ldots,x^k_t$ from vector spaces $\mathbb{R}^{n_1},\ldots,\mathbb{R}^{n_k}$ and we wanted to find the multilinear map $A$ from $\mathbb{R}^{n_1}\times\ldots\times\mathbb{R}^{n_k}$ to $\mathbb{R}^m$ that minimizes $$\sum_t \|y_t - A(x^1_t,\ldots,x^k_t)\|^2_2$$ Is there a closed form solution to this? Trying the usual method (write out multilinear map in index notation, take derivatives and set to zero) it looks like $$A = \sum_t y_t \otimes (X^1X^{1T})^{-1}x^1_t \otimes \ldots \otimes (X^kX^{kT})^{-1}x^k_t$$ might work, where $\otimes$ denotes outer product, but my algebra could be wrong. It does, at least, reduce to the least squares regression case when $k=1$.",,"['statistics', 'regression', 'tensors', 'multilinear-algebra']"
54,Motivation behind standard deviation?,Motivation behind standard deviation?,,"Let's take the numbers 0-10.  Their mean is 5, and the individual deviations from 5 are -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5 And so the average (magnitude of) deviation from the mean is $30/11 \approx 2.72$. However, this is not the standard deviation.  The standard deviation is $\sqrt{10} \approx 3.16$. The first mean-deviation is a simpler and by far more intuitive definition of the ""standard-deviation"" , so I'm sure it's the first definition statisticians worked with.  However, for some reason they decided to adopt the second definition instead.  What is the reasoning behind that decision?","Let's take the numbers 0-10.  Their mean is 5, and the individual deviations from 5 are -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5 And so the average (magnitude of) deviation from the mean is $30/11 \approx 2.72$. However, this is not the standard deviation.  The standard deviation is $\sqrt{10} \approx 3.16$. The first mean-deviation is a simpler and by far more intuitive definition of the ""standard-deviation"" , so I'm sure it's the first definition statisticians worked with.  However, for some reason they decided to adopt the second definition instead.  What is the reasoning behind that decision?",,"['intuition', 'statistics', 'standard-deviation']"
55,Solved problems book in Mathematical statistics,Solved problems book in Mathematical statistics,,"Are there some solved problems book in Mathematical statistics? Or some set of solutions for qualifying exams preparation? Say to the level of Casella, Berger, Statistical Inference , or, Hogg et al., Introduction to Mathematical Statistics . I'm preparing for a qualifying exam on this subject.","Are there some solved problems book in Mathematical statistics? Or some set of solutions for qualifying exams preparation? Say to the level of Casella, Berger, Statistical Inference , or, Hogg et al., Introduction to Mathematical Statistics . I'm preparing for a qualifying exam on this subject.",,['reference-request']
56,"What quality of a distribution describes the ""spikiness"" of its density, and how do I get a good density plot of a spiky distribution?","What quality of a distribution describes the ""spikiness"" of its density, and how do I get a good density plot of a spiky distribution?",,"I'm a programmer, not a math guy, so please answer in English. ;) Suppose I have a multi-modal univariate distribution like: .. . ..                         ...........                    .. . .. . but with each ""cluster"" (where each clusters is normally distributed) much further apart and more clusters. If I do a density plot of this with R, it's going to be spiky, but some of the less dense spikes might not be smooth because the ""optimal"" bandwidth was dominated by the more dense clusters. Compare to a unimodal distribution like: .          .         . ..    .  . . ... .. . .      .. .    .   .      . The density plot of this distribution would look just fine. What property describes the multi-modality of a distribution? I'm pretty sure that the former distribution would be better modeled by separating each cluster into a separate distribution and doing a density plot on it separately. But I'm unsure how to separate the distribution into these clusters robustly.","I'm a programmer, not a math guy, so please answer in English. ;) Suppose I have a multi-modal univariate distribution like: .. . ..                         ...........                    .. . .. . but with each ""cluster"" (where each clusters is normally distributed) much further apart and more clusters. If I do a density plot of this with R, it's going to be spiky, but some of the less dense spikes might not be smooth because the ""optimal"" bandwidth was dominated by the more dense clusters. Compare to a unimodal distribution like: .          .         . ..    .  . . ... .. . .      .. .    .   .      . The density plot of this distribution would look just fine. What property describes the multi-modality of a distribution? I'm pretty sure that the former distribution would be better modeled by separating each cluster into a separate distribution and doing a density plot on it separately. But I'm unsure how to separate the distribution into these clusters robustly.",,"['statistics', 'normal-distribution']"
57,Quantitative Analysis of Structure of Gaussian Mixture Model,Quantitative Analysis of Structure of Gaussian Mixture Model,,"I am fitting a Gaussian Mixture Model to high-dimensional data (40 dimensions). I have trained the model using EM, learned the parameters and now I want to know quantitatively: What is most important in capturing the structure of the data, the   means or the covariance matrices? Currently, I can think of measuring the Euclidean distance between different means or the cosine of the principal eigenvectors of the different covariance matrices to measure if the direction of variability each covariance matrix captures is similar or different to the rest. Any ideas ?","I am fitting a Gaussian Mixture Model to high-dimensional data (40 dimensions). I have trained the model using EM, learned the parameters and now I want to know quantitatively: What is most important in capturing the structure of the data, the   means or the covariance matrices? Currently, I can think of measuring the Euclidean distance between different means or the cosine of the principal eigenvectors of the different covariance matrices to measure if the direction of variability each covariance matrix captures is similar or different to the rest. Any ideas ?",,"['statistics', 'machine-learning']"
58,Standard Deviation: Why divide by $(N-1)$ rather than $N$?,Standard Deviation: Why divide by  rather than ?,(N-1) N,"The forumlae for standard deviation seems to be the square root of the sum of the squared deviation from mean divided by $N-1$. Why isn't it simply the square root of the mean of the squared deviation from mean?  i.e, divided by $N$. Why is it divided by $N-1$ rather than $N$?","The forumlae for standard deviation seems to be the square root of the sum of the squared deviation from mean divided by $N-1$. Why isn't it simply the square root of the mean of the squared deviation from mean?  i.e, divided by $N$. Why is it divided by $N-1$ rather than $N$?",,"['statistics', 'standard-deviation']"
59,Standard deviation of the weighted mean [duplicate],Standard deviation of the weighted mean [duplicate],,"This question already has an answer here : Sampling error with weighted mean (1 answer) Closed 10 years ago . How do you find the standard deviation of the weighted mean? The weighted mean is defined: $\bar{x}_w = \frac{\sum{wx}}{\sum{w}}$ The weighted standard deviation (since it is not specified, I take it as of the distribution) is defined: $$s_w = \sqrt{\frac{N'\sum_{i=1}^N {w_i(x_i-\bar{x}_w)^2}}{(N'-1)\sum_{i=1}^N{w_i}}},$$ where $N'$ is the number of nonzero weights, and $\bar x_w$ is the weighted mean of the sample ( source ) For an unweighted sample, calculating the standard deviation of the mean from the standard deviation of the distribution is described on Wikipedia . How do I calculate it for the weighted mean, and how is the expression derived?","This question already has an answer here : Sampling error with weighted mean (1 answer) Closed 10 years ago . How do you find the standard deviation of the weighted mean? The weighted mean is defined: $\bar{x}_w = \frac{\sum{wx}}{\sum{w}}$ The weighted standard deviation (since it is not specified, I take it as of the distribution) is defined: $$s_w = \sqrt{\frac{N'\sum_{i=1}^N {w_i(x_i-\bar{x}_w)^2}}{(N'-1)\sum_{i=1}^N{w_i}}},$$ where $N'$ is the number of nonzero weights, and $\bar x_w$ is the weighted mean of the sample ( source ) For an unweighted sample, calculating the standard deviation of the mean from the standard deviation of the distribution is described on Wikipedia . How do I calculate it for the weighted mean, and how is the expression derived?",,"['statistics', 'normal-distribution', 'average', 'standard-deviation']"
60,It is always true that X < Y. Is it possible for X and Y to be independent? Why?,It is always true that X < Y. Is it possible for X and Y to be independent? Why?,,X and Y are random variables. It is always true that X < Y. Is it possible for X and Y to be independent? Why?,X and Y are random variables. It is always true that X < Y. Is it possible for X and Y to be independent? Why?,,"['statistics', 'random-variables', 'independence']"
61,"Is it possible that two density functions that have the same mean and variance, but different distributions?","Is it possible that two density functions that have the same mean and variance, but different distributions?",,"Is it possible that two density functions that have the same mean and variance, but different distributions? Can you give an example?","Is it possible that two density functions that have the same mean and variance, but different distributions? Can you give an example?",,"['statistics', 'probability-distributions']"
62,"Probability that $\max(U_1,U_2) > U_3$ for independent uniform random variables $U_i$",Probability that  for independent uniform random variables,"\max(U_1,U_2) > U_3 U_i","Suppose $U_1$, $U_2$ and $U_3$ are independent uniform $(0,1)$. I am supposed to find $P(\max(U_1,U_2) > U_3)$. What I rewrote the question as was this is equal to: $$2P(U_1>U_3) - P(U_1 \mathrm{ and }\,\, U_2 > 3) = 2(1/2) - 1/3 = 2/3.$$ Can someone check to see if $2/3$ is also what they got? Thanks","Suppose $U_1$, $U_2$ and $U_3$ are independent uniform $(0,1)$. I am supposed to find $P(\max(U_1,U_2) > U_3)$. What I rewrote the question as was this is equal to: $$2P(U_1>U_3) - P(U_1 \mathrm{ and }\,\, U_2 > 3) = 2(1/2) - 1/3 = 2/3.$$ Can someone check to see if $2/3$ is also what they got? Thanks",,['statistics']
63,Why is there not a simpler way to calculate the standard deviation?,Why is there not a simpler way to calculate the standard deviation?,,"Steps of getting standard deviation. http://www.techbookreport.com/tutorials/stddev-30-secs.html : Work out the average (mean value) of your set of numbers Work out the difference between each number and the mean Square the differences Add up the square of all the differences Divide this by one less than the number of numbers in your set -   this is called the variance Take the square root of the variance and you've got the standard   deviation Am I missing out something, or why do we need to square the differences in step 3? Why not simply do a Abs (multiply all negative numbers by -1) in step 3? Also, my second question is why do we need to divide by one less than the number of numbers in the set in step 5? why not simply divide by the number of numbers?","Steps of getting standard deviation. http://www.techbookreport.com/tutorials/stddev-30-secs.html : Work out the average (mean value) of your set of numbers Work out the difference between each number and the mean Square the differences Add up the square of all the differences Divide this by one less than the number of numbers in your set -   this is called the variance Take the square root of the variance and you've got the standard   deviation Am I missing out something, or why do we need to square the differences in step 3? Why not simply do a Abs (multiply all negative numbers by -1) in step 3? Also, my second question is why do we need to divide by one less than the number of numbers in the set in step 5? why not simply divide by the number of numbers?",,"['statistics', 'standard-deviation']"
64,What is the variance of a constant? [closed],What is the variance of a constant? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Given a constant $c$, I know that $\text{E}(c)=c$, but what about the variance of $c$?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Given a constant $c$, I know that $\text{E}(c)=c$, but what about the variance of $c$?",,"['statistics', 'probability-distributions', 'variance']"
65,Binomial Coefficient Summation Equivalence,Binomial Coefficient Summation Equivalence,,"Following on a previous question, I'm supposed to prove the following:   $$ \sum_{i=0}^{n-1} \binom{2n-2-i}{n-1} =  \sum_{i=0}^{n-1} \binom{n-1+i}{i}.$$   Is there any simple conversion to come from the first term to the second one?","Following on a previous question, I'm supposed to prove the following:   $$ \sum_{i=0}^{n-1} \binom{2n-2-i}{n-1} =  \sum_{i=0}^{n-1} \binom{n-1+i}{i}.$$   Is there any simple conversion to come from the first term to the second one?",,"['statistics', 'summation', 'binomial-coefficients', 'binomial-distribution']"
66,Why add the number 1 to find the median number,Why add the number 1 to find the median number,,"Example 1: There are 45 numbers 45 plus 1 is 46, then divide by 2 and you get 23 So the median is the 23rd number in the sorted list. Example2: There are 66 numbers 66 plus 1 is 67, then divide by 2 and you get 33.5 33 and a half? That means that the 33rd and 34th numbers in the sorted list are the two middle numbers. So to find the median: add the 33rd and 34th numbers together and divide by 2 Why do we have to add the number 1 regardless to find the median ?","Example 1: There are 45 numbers 45 plus 1 is 46, then divide by 2 and you get 23 So the median is the 23rd number in the sorted list. Example2: There are 66 numbers 66 plus 1 is 67, then divide by 2 and you get 33.5 33 and a half? That means that the 33rd and 34th numbers in the sorted list are the two middle numbers. So to find the median: add the 33rd and 34th numbers together and divide by 2 Why do we have to add the number 1 regardless to find the median ?",,"['statistics', 'median']"
67,Is math capable of predicting social evolution?,Is math capable of predicting social evolution?,,"By the way math and statistics are evolving, it seems possible to me that with time, and as the population increases, we are going to be able to create mathematical models that predict social movements, and I've heard there is some research focused on small predictions like elections and such, but is it mathematically possible, or likely, that math is evolving to a point where we will be able to know with a relatively low error the probability of certain social events to happen? I mean something like what happened in the middle east, or 2008's crisis, or even a more time consuming evolution. Of course it would not be able to predict individual actions that somehow affect in a significant way this evolution, or natural catastrophes. More specifically, are there theories being developed? How far are we from this kind of thing? Is it even mathematically possible? Or there are too many variables? And what happens if we consider that the population may never stop increasing (hypothetically)?","By the way math and statistics are evolving, it seems possible to me that with time, and as the population increases, we are going to be able to create mathematical models that predict social movements, and I've heard there is some research focused on small predictions like elections and such, but is it mathematically possible, or likely, that math is evolving to a point where we will be able to know with a relatively low error the probability of certain social events to happen? I mean something like what happened in the middle east, or 2008's crisis, or even a more time consuming evolution. Of course it would not be able to predict individual actions that somehow affect in a significant way this evolution, or natural catastrophes. More specifically, are there theories being developed? How far are we from this kind of thing? Is it even mathematically possible? Or there are too many variables? And what happens if we consider that the population may never stop increasing (hypothetically)?",,"['statistics', 'soft-question']"
68,Is the median always between the mode and the mean for a unimodal distribution?,Is the median always between the mode and the mean for a unimodal distribution?,,"Is it ALWAYS the case that, for a unimodal probability distribution, the median is between the mode and mean?","Is it ALWAYS the case that, for a unimodal probability distribution, the median is between the mode and mean?",,['statistics']
69,Regarding Research in Artificial Intelligence [closed],Regarding Research in Artificial Intelligence [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 6 years ago . Improve this question Which mathematical areas are important for research purposes in artificial intelligence? Specifically, If I have Masters in Statistics how much it will be beneficial for research in artificial intelligence?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 6 years ago . Improve this question Which mathematical areas are important for research purposes in artificial intelligence? Specifically, If I have Masters in Statistics how much it will be beneficial for research in artificial intelligence?",,"['statistics', 'artificial-intelligence']"
70,"The data set $\{x_1,\dots,x_{10}\}$ has a mean $\mu=10$ and a standard deviation $\sigma=3$. Find the value of $\sum_{i=1}^{10}[(x_i-12)^2]$.",The data set  has a mean  and a standard deviation . Find the value of .,"\{x_1,\dots,x_{10}\} \mu=10 \sigma=3 \sum_{i=1}^{10}[(x_i-12)^2]","Problem The data set $\{x_1,\dots,x_{10}\}$ has a mean $\mu=10$ and a standard deviation $\sigma=3$. Find the value of $$\sum_{i=1}^{10}\left[\left(x_i-12\right)^2\right]$$ My solution Using formulae for variance and mean, $$\mu = \frac{1}{10}\sum_{1=1}^{10}x_i = 10 \implies \sum_{1=1}^{10}x_i = 100$$ $$\sigma^2 = \frac{1}{10}\sum_{i=1}^{10}\left(x_i^2\right)-\mu^2 = 9 \implies \sum_{i=1}^{10}x_i^2 = 10\left(9+\mu^2\right) = 1090$$ Then, with a bit of algebra, $$\begin{align} \sum_{i=1}^{10}\left[(x_i-12)^2\right] &= \sum_{i=1}^{10}\left(x_i^2-24x_i+144\right) \\ &= \sum_{i=1}^{10}\left(x_i^2\right)-24\sum_{i=1}^{10}\left(x_i\right)+\sum_{i=1}^{10}\left(144\right) \\ &= 1040-24\left(100\right)+144\cdot10 \\ &= 130 \end{align}$$ Question Is there another (significantly different) approach to solving this problem? Any input is welcome! I believe that I had originally tried to somehow arrive at a univariate function that mapped the mean to the variance and then evaluate that for a mean equal to $12$, but I soon realized that I had erroneously parenthesized the $\mu^2$ with the $x_i^2$ term  in the argument of the summation formula for $\sigma^2$, so that approach definitely wouldn’t work.","Problem The data set $\{x_1,\dots,x_{10}\}$ has a mean $\mu=10$ and a standard deviation $\sigma=3$. Find the value of $$\sum_{i=1}^{10}\left[\left(x_i-12\right)^2\right]$$ My solution Using formulae for variance and mean, $$\mu = \frac{1}{10}\sum_{1=1}^{10}x_i = 10 \implies \sum_{1=1}^{10}x_i = 100$$ $$\sigma^2 = \frac{1}{10}\sum_{i=1}^{10}\left(x_i^2\right)-\mu^2 = 9 \implies \sum_{i=1}^{10}x_i^2 = 10\left(9+\mu^2\right) = 1090$$ Then, with a bit of algebra, $$\begin{align} \sum_{i=1}^{10}\left[(x_i-12)^2\right] &= \sum_{i=1}^{10}\left(x_i^2-24x_i+144\right) \\ &= \sum_{i=1}^{10}\left(x_i^2\right)-24\sum_{i=1}^{10}\left(x_i\right)+\sum_{i=1}^{10}\left(144\right) \\ &= 1040-24\left(100\right)+144\cdot10 \\ &= 130 \end{align}$$ Question Is there another (significantly different) approach to solving this problem? Any input is welcome! I believe that I had originally tried to somehow arrive at a univariate function that mapped the mean to the variance and then evaluate that for a mean equal to $12$, but I soon realized that I had erroneously parenthesized the $\mu^2$ with the $x_i^2$ term  in the argument of the summation formula for $\sigma^2$, so that approach definitely wouldn’t work.",,"['statistics', 'summation', 'standard-deviation', 'means', 'variance']"
71,Least Square Approximation for Exponential Functions,Least Square Approximation for Exponential Functions,,"I'm a little confused on how to approach the following problem. Use the least square method to fit a curve of the form $y=a\cdot b^x$ to a collection of $n$ data points $(x_1,y_1),...,(x_n,y_n)$ Find $a$ and $b$. From what I understand. Given data {$(x_1,y_1),...,(x_n,y_n)$}, we may define the error associated to $y=a\cdot b^x$ by \begin{equation} E(c,d)=\sum_{i=1}^{n}(y_i-a\cdot b^{x_i})^2 \end{equation} The goal is to find values of $a$ and $b$ that minimize the error. In multivariable calculus we learn that this requires us to find the values of $(a,b)$ such that \begin{array} d \frac{\partial E}{\partial a}=0  & & \frac{\partial E}{\partial b}=0 \end{array} Differentiating $E(a,b)$ yields: \begin{eqnarray} \frac{\partial E}{\partial a}&=&\sum_{i=1}^n2(y_i-a\cdot b^{x_i})(-b^{x_i})=0\\ \frac{\partial E}{\partial b}&=&\sum_{i=1}^n2(y_i-a\cdot b^{x_i})(-a\cdot b^{x_i-1}x_i)=0\\ \end{eqnarray} I know that the least square method tries to minimize the error, but I can't help but feel that I doing this somewhat wrong since this isn't a polynomial - but an exponential - function. The alternative was for me to take the natural log of $y=a\cdot b^x$ to get: \begin{equation} \ln{y}=\ln{a}+x\ln{b} \end{equation} Then defining $\ln{y}=Y$,$\ln{a}=A$ and $\ln{b}=B$ to get: \begin{equation} Y=A+xB \end{equation} Then from here apply the least square method to my new linear equation. Any suggestions or feedback on what I can do to solve this problem? Thank you for your time.","I'm a little confused on how to approach the following problem. Use the least square method to fit a curve of the form $y=a\cdot b^x$ to a collection of $n$ data points $(x_1,y_1),...,(x_n,y_n)$ Find $a$ and $b$. From what I understand. Given data {$(x_1,y_1),...,(x_n,y_n)$}, we may define the error associated to $y=a\cdot b^x$ by \begin{equation} E(c,d)=\sum_{i=1}^{n}(y_i-a\cdot b^{x_i})^2 \end{equation} The goal is to find values of $a$ and $b$ that minimize the error. In multivariable calculus we learn that this requires us to find the values of $(a,b)$ such that \begin{array} d \frac{\partial E}{\partial a}=0  & & \frac{\partial E}{\partial b}=0 \end{array} Differentiating $E(a,b)$ yields: \begin{eqnarray} \frac{\partial E}{\partial a}&=&\sum_{i=1}^n2(y_i-a\cdot b^{x_i})(-b^{x_i})=0\\ \frac{\partial E}{\partial b}&=&\sum_{i=1}^n2(y_i-a\cdot b^{x_i})(-a\cdot b^{x_i-1}x_i)=0\\ \end{eqnarray} I know that the least square method tries to minimize the error, but I can't help but feel that I doing this somewhat wrong since this isn't a polynomial - but an exponential - function. The alternative was for me to take the natural log of $y=a\cdot b^x$ to get: \begin{equation} \ln{y}=\ln{a}+x\ln{b} \end{equation} Then defining $\ln{y}=Y$,$\ln{a}=A$ and $\ln{b}=B$ to get: \begin{equation} Y=A+xB \end{equation} Then from here apply the least square method to my new linear equation. Any suggestions or feedback on what I can do to solve this problem? Thank you for your time.",,"['statistics', 'multivariable-calculus', 'least-squares']"
72,Calculate the confidence interval of parameter of exponential distribution?,Calculate the confidence interval of parameter of exponential distribution?,,"How can I calculate the confidence interval for parameter $\alpha$ of   exponential distribution ? I think I can use test-t . Knowing that: $$mean = {1\over\alpha}$$ I found that : $${1\over {\bar X + \frac{S}{\sqrt{n}}\cdot t_{\alpha/2,n - 1}}}<\alpha<{1\over {\bar X - \frac{S}{\sqrt{n}}\cdot t_{\alpha/2,n - 1}}}$$ Is this right? In general, can I use test-t for determining the confidence interval of an exponential distribution ? If not, is there any other possibility to do this ?","How can I calculate the confidence interval for parameter $\alpha$ of   exponential distribution ? I think I can use test-t . Knowing that: $$mean = {1\over\alpha}$$ I found that : $${1\over {\bar X + \frac{S}{\sqrt{n}}\cdot t_{\alpha/2,n - 1}}}<\alpha<{1\over {\bar X - \frac{S}{\sqrt{n}}\cdot t_{\alpha/2,n - 1}}}$$ Is this right? In general, can I use test-t for determining the confidence interval of an exponential distribution ? If not, is there any other possibility to do this ?",,"['statistics', 'statistical-inference']"
73,"Why do Mean, Median, Mode, and Range present in school lessons?","Why do Mean, Median, Mode, and Range present in school lessons?",,"I studied in East Europe and post Soviet mathematical education program have no Median , Mode , and Range terms. Mean (or average) on other hand was studied (with root mean square and sometimes with geometric mean ). Looking to education English sites I see a lot of lessons about Median, Mode, and Range. These statistical parameters are strange for me. Why west schools use them? Have Median and Mode any sense in mathematical statistics (in science)?","I studied in East Europe and post Soviet mathematical education program have no Median , Mode , and Range terms. Mean (or average) on other hand was studied (with root mean square and sometimes with geometric mean ). Looking to education English sites I see a lot of lessons about Median, Mode, and Range. These statistical parameters are strange for me. Why west schools use them? Have Median and Mode any sense in mathematical statistics (in science)?",,"['statistics', 'education', 'median']"
74,Covariance of order statistics (uniform case),Covariance of order statistics (uniform case),,"Let $X_1, \ldots, X_n$ be uniformly distributed on $[0,1]$ and $X_{(1)}, ..., X_{(n)}$ the corresponding order statistic. I want to calculate $Cov(X_{(j)}, X_{(k)})$ for $j, k \in \{1, \ldots, n\}$. The problem is of course to calculate $\mathbb{E}[X_{(j)}X_{(k)}]$. The joint density of $X_{(j)}$ and $X_{(k)}$ is given by $$f_{X_{(j)}, X_{(k)}}=\binom{n}{k}\binom{k}{j-1}x^{j-1}(y-x)^{k-1-j}(1-y)^{n-k}$$ where $0\leq x\leq y\leq 1$. (I used the general formula here .) Sadly, I see no other way to calculate $\mathbb{E}[X_{(j)}X_{(k)}]$ than by $$\mathbb{E}[X_{(j)}X_{(k)}]=\binom{n}{k}\binom{k}{j-1}\int_0^1\int_0^yxyx^{j-1}(y-x)^{k-1-j}(1-y)^{n-k}\,dx\,dy.$$ But this integral is too much for me. I tried integration by parts, but got lost along the way. Is there a trick to do it? Did I even get the limits of integration right? Apart from that, I wonder if there's a smart approach to solve the whole problem more elegantly.","Let $X_1, \ldots, X_n$ be uniformly distributed on $[0,1]$ and $X_{(1)}, ..., X_{(n)}$ the corresponding order statistic. I want to calculate $Cov(X_{(j)}, X_{(k)})$ for $j, k \in \{1, \ldots, n\}$. The problem is of course to calculate $\mathbb{E}[X_{(j)}X_{(k)}]$. The joint density of $X_{(j)}$ and $X_{(k)}$ is given by $$f_{X_{(j)}, X_{(k)}}=\binom{n}{k}\binom{k}{j-1}x^{j-1}(y-x)^{k-1-j}(1-y)^{n-k}$$ where $0\leq x\leq y\leq 1$. (I used the general formula here .) Sadly, I see no other way to calculate $\mathbb{E}[X_{(j)}X_{(k)}]$ than by $$\mathbb{E}[X_{(j)}X_{(k)}]=\binom{n}{k}\binom{k}{j-1}\int_0^1\int_0^yxyx^{j-1}(y-x)^{k-1-j}(1-y)^{n-k}\,dx\,dy.$$ But this integral is too much for me. I tried integration by parts, but got lost along the way. Is there a trick to do it? Did I even get the limits of integration right? Apart from that, I wonder if there's a smart approach to solve the whole problem more elegantly.",,"['statistics', 'order-statistics']"
75,Rating system incorporating experience,Rating system incorporating experience,,"I am looking to rank players on something and right now I am using a win-loss percentage to ""rank"" the players. The issue is that I have some people who just beat out the 5 game threshold and have a win/loss ratio of say 5 wins, 1 loss for 83% and then I have someone who has 54 wins and 10 losses for ~82%. I want to ""rank"" the more experienced player higher than the other, but I have no idea how to include ""experience"" as part of the formula. I know there are many many ways this can be done, I am just interested in a few of the most simplistic accurate and common approaches and perhaps links to rating theory discussion when only knowing the wins and losses.","I am looking to rank players on something and right now I am using a win-loss percentage to ""rank"" the players. The issue is that I have some people who just beat out the 5 game threshold and have a win/loss ratio of say 5 wins, 1 loss for 83% and then I have someone who has 54 wins and 10 losses for ~82%. I want to ""rank"" the more experienced player higher than the other, but I have no idea how to include ""experience"" as part of the formula. I know there are many many ways this can be done, I am just interested in a few of the most simplistic accurate and common approaches and perhaps links to rating theory discussion when only knowing the wins and losses.",,['statistics']
76,Mean and Variance of Methods of Moment Estimate and Maximum Likelihood Estimate of Uniform Distribution.,Mean and Variance of Methods of Moment Estimate and Maximum Likelihood Estimate of Uniform Distribution.,,"Let $X_1, X_2,\ldots, X_n$ be i.i.d. uniform on $[0, \theta ]$. a.  Find the method of moments estimate of $\theta$ and its mean and variance b.  Find the MLE of $\theta$  and its mean and variance. Thank you for answering, I really appreciate it. My answers were: a. $\hat{\theta} = 2 \bar{X}$ b. $\hat{\theta} = X_n$ I'm not just sure about my solution,   I don't also know how to start solving for the mean and variance considering the MLE and MME.","Let $X_1, X_2,\ldots, X_n$ be i.i.d. uniform on $[0, \theta ]$. a.  Find the method of moments estimate of $\theta$ and its mean and variance b.  Find the MLE of $\theta$  and its mean and variance. Thank you for answering, I really appreciate it. My answers were: a. $\hat{\theta} = 2 \bar{X}$ b. $\hat{\theta} = X_n$ I'm not just sure about my solution,   I don't also know how to start solving for the mean and variance considering the MLE and MME.",,['statistics']
77,How do you calculate percentile?,How do you calculate percentile?,,Say I have the following numbers: 10 10 9 5 4 4 4 1 How do i go about calculating the percentile for each score?  Is there a standard formula for figuring this out?,Say I have the following numbers: 10 10 9 5 4 4 4 1 How do i go about calculating the percentile for each score?  Is there a standard formula for figuring this out?,,"['statistics', 'algorithms']"
78,Expected Value of a DnD/Baldur's Gate Feat,Expected Value of a DnD/Baldur's Gate Feat,,"The Baldur's gate feat Savage Attacker lets you reroll an attack, and choose the better of the two attacks. I am attempting to calculate the expected benefit of this feat. Assume, for the sake of simplicity, that a melee attack has a 1d10 damage, which means it follows a discrete uniform distribution with integer values from 1 to 10 (equiprobable). $$A_1\text{ follows Discrete }U(1,10)$$ If we have savage attack, we take two rolls, and then the better of the two. How do I calculate the expected value of the benefit: $$E[|A_1-A_2|] $$ Update 1: I found this video by Stand-Up Math which calculates the actual probabilities (and not just the expected value)","The Baldur's gate feat Savage Attacker lets you reroll an attack, and choose the better of the two attacks. I am attempting to calculate the expected benefit of this feat. Assume, for the sake of simplicity, that a melee attack has a 1d10 damage, which means it follows a discrete uniform distribution with integer values from 1 to 10 (equiprobable). If we have savage attack, we take two rolls, and then the better of the two. How do I calculate the expected value of the benefit: Update 1: I found this video by Stand-Up Math which calculates the actual probabilities (and not just the expected value)","A_1\text{ follows Discrete }U(1,10) E[|A_1-A_2|] ","['statistics', 'probability-distributions', 'expected-value', 'uniform-distribution']"
79,Chi square goodness-of-fit test for Uniform distribution using Matlab,Chi square goodness-of-fit test for Uniform distribution using Matlab,,"I need to test random numbers generators in 1, 2 and 3 dimensions. Criteria of test is that generated numbers are from uniform distribution. I am doing this using Matlab . I'm told to use Chi-2 test statistic $$\chi^2=\sum^B_{i=1}\frac{(expected(i)-observed(i))^2}{expected(i)}$$ where $B$ is number of bins, $expected(i)=\frac{N}{B}$ for all $i$ is expected number of elements in $i_{th}$ bin and $N$ is number of generated numbers. What I have done is that I generated $N\times 1$ matrix of random numbers for $1D$ $N\times 2$ matrix of random numbers for $2D$ $N\times 3$ matrix of random numbers for $3D$ Then, I set a number of bins (B) for each component of matrix elements and I created zero matrices of sizes $1\times B$ for $1D$ $B\times B$ for $2D$ $B\times B\times B$ for $3D$ and, using loops, I counted how many generated numbers are in which bin and those were, actually, values $observed(i)$. At this point I am able to calculate $\chi^2$ test statistic for all 3 dimensions. I know how to read $\chi^2$ table but I don't know how to check significance using Matlab. I'm also not sure about degrees of freedom, but I think it's $B-1$ for $1D$, $BB-1$ for $2D$ and $BBB-1$ for $3D$ since we don't have to estimate any parameter for uniform distribution. I would appreciate some help. Thanks!","I need to test random numbers generators in 1, 2 and 3 dimensions. Criteria of test is that generated numbers are from uniform distribution. I am doing this using Matlab . I'm told to use Chi-2 test statistic $$\chi^2=\sum^B_{i=1}\frac{(expected(i)-observed(i))^2}{expected(i)}$$ where $B$ is number of bins, $expected(i)=\frac{N}{B}$ for all $i$ is expected number of elements in $i_{th}$ bin and $N$ is number of generated numbers. What I have done is that I generated $N\times 1$ matrix of random numbers for $1D$ $N\times 2$ matrix of random numbers for $2D$ $N\times 3$ matrix of random numbers for $3D$ Then, I set a number of bins (B) for each component of matrix elements and I created zero matrices of sizes $1\times B$ for $1D$ $B\times B$ for $2D$ $B\times B\times B$ for $3D$ and, using loops, I counted how many generated numbers are in which bin and those were, actually, values $observed(i)$. At this point I am able to calculate $\chi^2$ test statistic for all 3 dimensions. I know how to read $\chi^2$ table but I don't know how to check significance using Matlab. I'm also not sure about degrees of freedom, but I think it's $B-1$ for $1D$, $BB-1$ for $2D$ and $BBB-1$ for $3D$ since we don't have to estimate any parameter for uniform distribution. I would appreciate some help. Thanks!",,"['statistics', 'matlab']"
80,Shifted Exponential Distribution and MLE,Shifted Exponential Distribution and MLE,,"I was doing my homework and the following problem came up! We have the CDF of an exponential distribution that is shifted $L$ units where $L>0$ and $x>=L$. The CDF is: $$1-e^{-\lambda(x-L)}$$ The question says that we should assume that the following data are lifetimes of electric motors, in hours, which are: $$\begin{align*} 153.52,103.23,31.75,28.91,37.91,7.11,99.21,31.77,11.01,217.40 \end{align*}$$ Please note that the $mean$ of these numbers is: $72.182$ Now the question has two parts which I will go through one by one: Part1: Evaluate the log likelihood for the data when $\lambda=0.02$ and $L=3.555$. Now the way I approached the problem was to take the derivative of the CDF with respect to $\lambda$ to get the PDF which is: $$(x-L)e^{-\lambda(x-L)}$$ Then since we have $n$ observations where $n=10$, we have the following joint pdf, due to independence: $$(x_i-L)^ne^{-\lambda(x_i-L)n}$$ which can be rewritten as the following log likelihood: $$n\ln(x_i-L)-\lambda\sum_{i=1}^n(x_i-L)$$ Is this the correct approach? Because it would take quite a while and be pretty cumbersome to evaluate $n\ln(x_i-L)$ for every observation? Part2: The question also asks for the ML Estimate of $L$. So assuming the log likelihood is correct, we can take the derivative with respect to $L$ and get: $\frac{n}{x_i-L}+\lambda=0$ and solve for $L$? Is this correct? Because I am not quite sure on how I should proceed? Thanks so much for your help! I greatly appreciate it :)","I was doing my homework and the following problem came up! We have the CDF of an exponential distribution that is shifted $L$ units where $L>0$ and $x>=L$. The CDF is: $$1-e^{-\lambda(x-L)}$$ The question says that we should assume that the following data are lifetimes of electric motors, in hours, which are: $$\begin{align*} 153.52,103.23,31.75,28.91,37.91,7.11,99.21,31.77,11.01,217.40 \end{align*}$$ Please note that the $mean$ of these numbers is: $72.182$ Now the question has two parts which I will go through one by one: Part1: Evaluate the log likelihood for the data when $\lambda=0.02$ and $L=3.555$. Now the way I approached the problem was to take the derivative of the CDF with respect to $\lambda$ to get the PDF which is: $$(x-L)e^{-\lambda(x-L)}$$ Then since we have $n$ observations where $n=10$, we have the following joint pdf, due to independence: $$(x_i-L)^ne^{-\lambda(x_i-L)n}$$ which can be rewritten as the following log likelihood: $$n\ln(x_i-L)-\lambda\sum_{i=1}^n(x_i-L)$$ Is this the correct approach? Because it would take quite a while and be pretty cumbersome to evaluate $n\ln(x_i-L)$ for every observation? Part2: The question also asks for the ML Estimate of $L$. So assuming the log likelihood is correct, we can take the derivative with respect to $L$ and get: $\frac{n}{x_i-L}+\lambda=0$ and solve for $L$? Is this correct? Because I am not quite sure on how I should proceed? Thanks so much for your help! I greatly appreciate it :)",,"['statistics', 'statistical-inference']"
81,How to read a histogram?,How to read a histogram?,,"I posted the following question over on StackOverflow, and I think I am having a hard time understanding exactly how a histogram works. I have the following set of numbers between 0 and 9: [1] 1 0 1 4 0 0 7 3 5 3 8 9 1 3 3 1 2 0 7 5 8 6 2 0 2 3 6 9 9 7 8 9 4 9 2 1 3   [38] 1 1 4 9 1 4 4 2 6 3 7 7 4 7 5 1 9 0 2 2 3 9 1 1 1 5 0 6 3 4 8 1 0 3 9 6 2   [75] 6 4 7 1 4 1 5 4 8 9 2 9 9 8 9 6 3 6 4 6 2 9 1 2 0 5 9 2 7 7 2 8 8 5 0 6 0  [112] 0 2 9 0 4 7 7 1 5 7 9 4 6 1 5 7 6 5 0 4 8 7 6 1 8 7 3 7 3 1 0 3 4 5 4 0 5  [149] 4 0 3 5 1 0 8 3 7 0 9 6 6 9 5 4 6 9 3 5 4 2 4 8 7 7 5 8 8 8 2 6 9 3 1 0 4  [186] 1 5 9 0 6 2 1 3 0 6 0 0 8 3 2 0 0 6 0 0 4 7 2 7 1 9 9 3 9 8 4 6 6 5 3 8 1  [223] 8 7 1 3 7 6 3 6 3 6 3 2 3 2 2 7 9 2 3 2 7 5 5 8 8 2 0 1 4 0 6 3 7 1 1 1 4  [260] 7 0 2 9 2 0 5 6 0 8 9 6 2 0 0 7 2 0 4 2 0 9 1 6 9 3 0 0 2 0 6 8 4 0 7 2 1  [297] 9 5 2 4 8 5 2 9 7 9 2 9 7 4 9 3 2 7 3 6 3 6 8 8 3 7 0 9 2 7 9 0 5 4 5 8 4  [334] 3 3 1 7 8 9 7 6 2 1 7 0 5 6 5 2 9 5 4 6 2 2 2 9 0 7 7 2 2 6 3 4 2 0 5 9 6  [371] 2 1 9 0 6 0 4 8 4 3 1 5 4 2 9 5 7 3 1 5 4 5 3 7 3 8 6 2 4 6 1 1 4 0 0 5 8  [408] 6 7 4 2 8 0 2 5 4 8 3 0 6 4 8 6 4 1 8 1 5 4 9 4 3 2 0 5 0 7 9 2 9 8 9 6 5  [445] 2 4 4 6 4 8 4 1 7 5 8 9 5 9 3 2 5 8 2 2 7 2 8 4 1 9 3 6 0 2 2 9 1 2 7 2 1  [482] 3 4 9 1 8 0 2 2 3 4 1 3 7 4 1 4 1 5 9 6 9 0 5 7 6 8 2 0 7 3 5 8 2 8 2 4 8  [519] 5 8 9 7 1 2 4 5 5 1 8 1 4 4 6 5 8 9 2 3 0 5 1 4 0 5 1 2 9 2 4 1 6 8 0 4 9  [556] 0 0 5 9 2 3 5 9 4 4 3 9 2 3 5 6 5 2 7 2 4 2 4 7 2 5 3 7 6 1 0 7 5 4 5 1 6  [593] 9 7 1 6 3 3 1 2 2 0 5 0 6 8 3 6 7 7 3 8 1 7 9 3 9 2 8 3 7 4 1 2 3 6 5 0 1  [630] 8 6 9 2 1 6 0 2 8 0 8 8 9 1 2 2 1 4 8 1 4 4 5 1 8 7 7 9 7 0 6 9 4 5 6 2 5  [667] 7 4 7 2 3 0 8 4 8 0 0 9 7 7 9 8 2 1 6 5 5 1 1 9 7 7 8 6 4 7 5 3 1 6 4 5 7  [704] 4 1 8 3 5 1 7 1 1 8 6 4 3 8 3 1 2 8 9 0 9 1 2 3 3 0 3 0 2 0 3 3 8 3 5 7 0  [741] 5 9 0 5 9 1 5 1 1 2 6 5 5 4 5 1 6 0 2 2 8 0 7 1 0 8 5 6 3 2 9 4 3 6 0 3 4  [778] 1 5 9 3 0 5 0 6 2 7 6 6 6 9 6 7 8 2 0 6 0 8 9 5 3 6 7 4 3 9 7 2 0 4 7 2 2  [815] 8 2 7 0 4 0 5 2 8 7 7 9 1 4 0 1 1 2 3 6 2 0 6 6 1 9 4 5 2 7 7 8 9 5 8 3 8  [852] 5 6 2 0 9 7 1 8 2 6 9 8 4 9 4 1 3 8 4 0 7 7 3 7 6 6 8 8 2 7 0 4 3 7 7 0 8  [889] 4 7 4 0 6 9 8 6 0 1 6 4 5 2 7 3 6 2 2 9 2 7 4 8 7 2 9 5 3 4 8 0 4 4 6 5 6  [926] 1 2 2 8 4 5 7 8 0 6 8 9 1 7 7 2 6 3 9 9 1 0 4 2 5 4 4 9 2 6 7 2 8 3 3 2 7  [963] 0 4 7 0 7 7 8 1 7 3 7 8 0 1 0 2 9 7 6 2 2 6 9 0 6 8 8 9 6 3 5 0 2 2 5 9 6 [1000] 4 Which produces the following histogram: From what I have heard this is expected.  I had assumed that a histogram would display the count of each occurrence of each number in my set.  But this does not seem to be right, because 10 numbers occur in my set and there are only 9 columns in my histogram.  Can someone explain what each of those 9 columns represents?","I posted the following question over on StackOverflow, and I think I am having a hard time understanding exactly how a histogram works. I have the following set of numbers between 0 and 9: [1] 1 0 1 4 0 0 7 3 5 3 8 9 1 3 3 1 2 0 7 5 8 6 2 0 2 3 6 9 9 7 8 9 4 9 2 1 3   [38] 1 1 4 9 1 4 4 2 6 3 7 7 4 7 5 1 9 0 2 2 3 9 1 1 1 5 0 6 3 4 8 1 0 3 9 6 2   [75] 6 4 7 1 4 1 5 4 8 9 2 9 9 8 9 6 3 6 4 6 2 9 1 2 0 5 9 2 7 7 2 8 8 5 0 6 0  [112] 0 2 9 0 4 7 7 1 5 7 9 4 6 1 5 7 6 5 0 4 8 7 6 1 8 7 3 7 3 1 0 3 4 5 4 0 5  [149] 4 0 3 5 1 0 8 3 7 0 9 6 6 9 5 4 6 9 3 5 4 2 4 8 7 7 5 8 8 8 2 6 9 3 1 0 4  [186] 1 5 9 0 6 2 1 3 0 6 0 0 8 3 2 0 0 6 0 0 4 7 2 7 1 9 9 3 9 8 4 6 6 5 3 8 1  [223] 8 7 1 3 7 6 3 6 3 6 3 2 3 2 2 7 9 2 3 2 7 5 5 8 8 2 0 1 4 0 6 3 7 1 1 1 4  [260] 7 0 2 9 2 0 5 6 0 8 9 6 2 0 0 7 2 0 4 2 0 9 1 6 9 3 0 0 2 0 6 8 4 0 7 2 1  [297] 9 5 2 4 8 5 2 9 7 9 2 9 7 4 9 3 2 7 3 6 3 6 8 8 3 7 0 9 2 7 9 0 5 4 5 8 4  [334] 3 3 1 7 8 9 7 6 2 1 7 0 5 6 5 2 9 5 4 6 2 2 2 9 0 7 7 2 2 6 3 4 2 0 5 9 6  [371] 2 1 9 0 6 0 4 8 4 3 1 5 4 2 9 5 7 3 1 5 4 5 3 7 3 8 6 2 4 6 1 1 4 0 0 5 8  [408] 6 7 4 2 8 0 2 5 4 8 3 0 6 4 8 6 4 1 8 1 5 4 9 4 3 2 0 5 0 7 9 2 9 8 9 6 5  [445] 2 4 4 6 4 8 4 1 7 5 8 9 5 9 3 2 5 8 2 2 7 2 8 4 1 9 3 6 0 2 2 9 1 2 7 2 1  [482] 3 4 9 1 8 0 2 2 3 4 1 3 7 4 1 4 1 5 9 6 9 0 5 7 6 8 2 0 7 3 5 8 2 8 2 4 8  [519] 5 8 9 7 1 2 4 5 5 1 8 1 4 4 6 5 8 9 2 3 0 5 1 4 0 5 1 2 9 2 4 1 6 8 0 4 9  [556] 0 0 5 9 2 3 5 9 4 4 3 9 2 3 5 6 5 2 7 2 4 2 4 7 2 5 3 7 6 1 0 7 5 4 5 1 6  [593] 9 7 1 6 3 3 1 2 2 0 5 0 6 8 3 6 7 7 3 8 1 7 9 3 9 2 8 3 7 4 1 2 3 6 5 0 1  [630] 8 6 9 2 1 6 0 2 8 0 8 8 9 1 2 2 1 4 8 1 4 4 5 1 8 7 7 9 7 0 6 9 4 5 6 2 5  [667] 7 4 7 2 3 0 8 4 8 0 0 9 7 7 9 8 2 1 6 5 5 1 1 9 7 7 8 6 4 7 5 3 1 6 4 5 7  [704] 4 1 8 3 5 1 7 1 1 8 6 4 3 8 3 1 2 8 9 0 9 1 2 3 3 0 3 0 2 0 3 3 8 3 5 7 0  [741] 5 9 0 5 9 1 5 1 1 2 6 5 5 4 5 1 6 0 2 2 8 0 7 1 0 8 5 6 3 2 9 4 3 6 0 3 4  [778] 1 5 9 3 0 5 0 6 2 7 6 6 6 9 6 7 8 2 0 6 0 8 9 5 3 6 7 4 3 9 7 2 0 4 7 2 2  [815] 8 2 7 0 4 0 5 2 8 7 7 9 1 4 0 1 1 2 3 6 2 0 6 6 1 9 4 5 2 7 7 8 9 5 8 3 8  [852] 5 6 2 0 9 7 1 8 2 6 9 8 4 9 4 1 3 8 4 0 7 7 3 7 6 6 8 8 2 7 0 4 3 7 7 0 8  [889] 4 7 4 0 6 9 8 6 0 1 6 4 5 2 7 3 6 2 2 9 2 7 4 8 7 2 9 5 3 4 8 0 4 4 6 5 6  [926] 1 2 2 8 4 5 7 8 0 6 8 9 1 7 7 2 6 3 9 9 1 0 4 2 5 4 4 9 2 6 7 2 8 3 3 2 7  [963] 0 4 7 0 7 7 8 1 7 3 7 8 0 1 0 2 9 7 6 2 2 6 9 0 6 8 8 9 6 3 5 0 2 2 5 9 6 [1000] 4 Which produces the following histogram: From what I have heard this is expected.  I had assumed that a histogram would display the count of each occurrence of each number in my set.  But this does not seem to be right, because 10 numbers occur in my set and there are only 9 columns in my histogram.  Can someone explain what each of those 9 columns represents?",,"['statistics', 'math-software']"
82,Cramer-Rao Lower Bound when the support for $x$ depends on $\theta$?,Cramer-Rao Lower Bound when the support for  depends on ?,x \theta,"Are there any grounds for the following claim? For distributions for which the support in $x$ depends on $\theta$, the   CRLB $=0$. For a quick example (Casella-Berger, Example 7.3.13 ): Let $X_1,\dots,X_n$ be iid with pdf $f(x\mid\theta) = 1/\theta, 0 < x <\theta$. There, CB used the typical formula for Fisher information $I(\theta)$ to get CRLB $= \theta^2/n$ and subsequently showed that for the unbiased estimator $\hat{\theta} = \frac{n+1}{n}X_{(n)}$, $\mathrm{Var}\hat{\theta} = \frac{1}{n(n+2)}\theta^2$ which is uniformly smaller than the CRLB and thus Cramer-Rao Inequality is violated. However, my lecturer disagrees with this approach as CB ignored the indicator function $\mathbf{1}_{(0<x<\theta)}$ when taking the derivative of the log-likelihood function. His approach was to note that because the likelihood function is not continuous in $\theta$, it is not differentiable in $\theta$. In situations like these, we should define $I(\theta) = +\infty$ and thus CRLB $= 0$, in which case the Cramer-Rao Inequality was not violated. I Google'd a bit but did not find any references to validate this alternative approach although it does make some sense (although I can't seem to grasp the significance of having CRLB $= 0$). Has anyone come across something like this before?","Are there any grounds for the following claim? For distributions for which the support in $x$ depends on $\theta$, the   CRLB $=0$. For a quick example (Casella-Berger, Example 7.3.13 ): Let $X_1,\dots,X_n$ be iid with pdf $f(x\mid\theta) = 1/\theta, 0 < x <\theta$. There, CB used the typical formula for Fisher information $I(\theta)$ to get CRLB $= \theta^2/n$ and subsequently showed that for the unbiased estimator $\hat{\theta} = \frac{n+1}{n}X_{(n)}$, $\mathrm{Var}\hat{\theta} = \frac{1}{n(n+2)}\theta^2$ which is uniformly smaller than the CRLB and thus Cramer-Rao Inequality is violated. However, my lecturer disagrees with this approach as CB ignored the indicator function $\mathbf{1}_{(0<x<\theta)}$ when taking the derivative of the log-likelihood function. His approach was to note that because the likelihood function is not continuous in $\theta$, it is not differentiable in $\theta$. In situations like these, we should define $I(\theta) = +\infty$ and thus CRLB $= 0$, in which case the Cramer-Rao Inequality was not violated. I Google'd a bit but did not find any references to validate this alternative approach although it does make some sense (although I can't seem to grasp the significance of having CRLB $= 0$). Has anyone come across something like this before?",,['statistics']
83,What is the intuition behind the formula $\frac{1}{1+f(x)}$,What is the intuition behind the formula,\frac{1}{1+f(x)},What is the intuition of $\frac{1}{1+f(x)}$ ? I often see formulas of such style in statistics. For example sigmoid function is of form $\frac{1}{1+e^{-x}}$. Why is $\frac{1}{1+f(x)}$ used frequently? What is its intuition?,What is the intuition of $\frac{1}{1+f(x)}$ ? I often see formulas of such style in statistics. For example sigmoid function is of form $\frac{1}{1+e^{-x}}$. Why is $\frac{1}{1+f(x)}$ used frequently? What is its intuition?,,['statistics']
84,Prerequisites to prove central limit theorem,Prerequisites to prove central limit theorem,,"What are the prerequisites to prove the central limit theorem? In my statistics textbook it is stated without a complete proof, so I guess I need more than calculus. However, do I need more than undergraduate real and complex analysis? In what book can I find a complete proof of the central limit theorem?","What are the prerequisites to prove the central limit theorem? In my statistics textbook it is stated without a complete proof, so I guess I need more than calculus. However, do I need more than undergraduate real and complex analysis? In what book can I find a complete proof of the central limit theorem?",,"['statistics', 'central-limit-theorem']"
85,The derivation of the Wald interval,The derivation of the Wald interval,,"I'm asking about the binomial proportion confidence interval , also known as the Wald interval. Recall that $$\lim_{n \to \infty}{P_p \left( -z_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}+\bar{X_n} \leq p \leq z_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}+\bar{X_n} \right)} = 1-\alpha, $$ with $\sigma = \sqrt{p(1-p)}$. Starting from the expression above, and the fact that for $\hat{p}=\dfrac{\sum X_i}{n},\ \hat{\sigma}=\sqrt{\hat{p}(1-\hat{p})}$  is consistent for $\sigma$ ($X_i \sim \rm Bin(1,p) )$, what argument can I use to show that  $$\left[-z_{1-\frac{\alpha}{2}}\frac{\hat{\sigma}}{\sqrt{n}}+\bar{X_n} ,\  z_{1-\frac{\alpha}{2}}\frac{\hat{\sigma}}{\sqrt{n}}+\bar{X_n}\right]$$ is a confidence interval?","I'm asking about the binomial proportion confidence interval , also known as the Wald interval. Recall that $$\lim_{n \to \infty}{P_p \left( -z_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}+\bar{X_n} \leq p \leq z_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}+\bar{X_n} \right)} = 1-\alpha, $$ with $\sigma = \sqrt{p(1-p)}$. Starting from the expression above, and the fact that for $\hat{p}=\dfrac{\sum X_i}{n},\ \hat{\sigma}=\sqrt{\hat{p}(1-\hat{p})}$  is consistent for $\sigma$ ($X_i \sim \rm Bin(1,p) )$, what argument can I use to show that  $$\left[-z_{1-\frac{\alpha}{2}}\frac{\hat{\sigma}}{\sqrt{n}}+\bar{X_n} ,\  z_{1-\frac{\alpha}{2}}\frac{\hat{\sigma}}{\sqrt{n}}+\bar{X_n}\right]$$ is a confidence interval?",,"['statistics', 'statistical-inference']"
86,relation between covariance matrix and SVD of a given matrix,relation between covariance matrix and SVD of a given matrix,,"Suppose there is a given matrix $M$ of $m \times n$ dimensions. What is the relationship (if any) of its covariance matrix and its SVD's singular values matrix? This page says that ""the SVD represents an expansion of the original data in a coordinate system where the covariance matrix is diagonal"", but I can't understand it clearly. Thanks!","Suppose there is a given matrix $M$ of $m \times n$ dimensions. What is the relationship (if any) of its covariance matrix and its SVD's singular values matrix? This page says that ""the SVD represents an expansion of the original data in a coordinate system where the covariance matrix is diagonal"", but I can't understand it clearly. Thanks!",,"['linear-algebra', 'statistics']"
87,Help on finding the math behind the 68/95/99 rule for Normal distribution,Help on finding the math behind the 68/95/99 rule for Normal distribution,,"I also see on the section on the Central Limit Theorem that the normal distribution is used and gives the graph of the 68/95/99 rule .  However, I haven't seen the actual math used to prove this or how it gets computed.  Can anyone give me a link or explain/show how the math behind the statement is done?","I also see on the section on the Central Limit Theorem that the normal distribution is used and gives the graph of the 68/95/99 rule .  However, I haven't seen the actual math used to prove this or how it gets computed.  Can anyone give me a link or explain/show how the math behind the statement is done?",,"['statistics', 'reference-request']"
88,Prove $\sum_{i=1}^n$$w_i^2\geq\frac{1}{n}$ given $\sum_{i=1}^n w_i=1$,Prove  given,\sum_{i=1}^n w_i^2\geq\frac{1}{n} \sum_{i=1}^n w_i=1,"I was looking at my stats textbook and they claim that the sample variance of a weighted distribution involving i.i.d. $x_i$s will be smallest when each of the weights is equal. I follow this argument up to the point where I reach $\sum_{i=1}^n$$w_i^2\geq\frac{1}{n}$ given $\sum_{i=1}^n w_i=1$ (this result obtained due to the fact that $Var(\bar{x_w})= \sigma^2\sum_{i=1}^nw_i^2$ and $Var(\bar{x})=\frac{\sigma^2}{n}$, so setting them equal and cancelling the $\sigma^2$ on each side yields that inequality, where $\bar{x_w}$ is the weighted average). Trying out a few examples, it seems pretty obvious that the inequality holds, but the book offers no mathematical justification and I was hoping someone here could help put it more concretely - I'm not sure how to approach it myself. Any thoughts?","I was looking at my stats textbook and they claim that the sample variance of a weighted distribution involving i.i.d. $x_i$s will be smallest when each of the weights is equal. I follow this argument up to the point where I reach $\sum_{i=1}^n$$w_i^2\geq\frac{1}{n}$ given $\sum_{i=1}^n w_i=1$ (this result obtained due to the fact that $Var(\bar{x_w})= \sigma^2\sum_{i=1}^nw_i^2$ and $Var(\bar{x})=\frac{\sigma^2}{n}$, so setting them equal and cancelling the $\sigma^2$ on each side yields that inequality, where $\bar{x_w}$ is the weighted average). Trying out a few examples, it seems pretty obvious that the inequality holds, but the book offers no mathematical justification and I was hoping someone here could help put it more concretely - I'm not sure how to approach it myself. Any thoughts?",,"['statistics', 'inequality']"
89,Joint entropy of a random variable with itself,Joint entropy of a random variable with itself,,"If A and B are two independent random variables with $n_A$ and $n_B$ number of possible values, then the joint random variable AB would have $n_A \times n_B$ number of possible values and the joint entropy is simply additive $$H(AB)  = H(A) + H(B)$$ But what is $H(AB)$ if A and B are not independent, for example, if they are identical?","If A and B are two independent random variables with and number of possible values, then the joint random variable AB would have number of possible values and the joint entropy is simply additive But what is if A and B are not independent, for example, if they are identical?",n_A n_B n_A \times n_B H(AB)  = H(A) + H(B) H(AB),"['statistics', 'random-variables', 'information-theory']"
90,How to find MLE of this piecewise pdf?,How to find MLE of this piecewise pdf?,,"Suppose $X_1,\ldots, X_n$ are i.i.d. random variables having pdf $$ f_{\theta}(x)=\left\{\begin{array}{ll}{\theta,} & {0 \leqslant x \leqslant 1} \\ {1-\theta,} & {1<x \leqslant 2}\end{array}\right. $$ Give the maximum likelihood estimate of $\theta$ . I know the likelihood function of $(X_1,\ldots, X_n)$ is $$\ell(\theta;x)=\prod_{i=1}^{n}\left[\theta I(0<x_i<1)+(1-\theta)I(1<x_i<2)\right]$$ But I don't know how to compute $\frac{\partial \log \ell(\theta)}{\partial \theta}=0$ to get $\hat{\theta}$ . Is there anyone can tell me？",Suppose are i.i.d. random variables having pdf Give the maximum likelihood estimate of . I know the likelihood function of is But I don't know how to compute to get . Is there anyone can tell me？,"X_1,\ldots, X_n 
f_{\theta}(x)=\left\{\begin{array}{ll}{\theta,} & {0 \leqslant x \leqslant 1} \\ {1-\theta,} & {1<x \leqslant 2}\end{array}\right.
 \theta (X_1,\ldots, X_n) \ell(\theta;x)=\prod_{i=1}^{n}\left[\theta I(0<x_i<1)+(1-\theta)I(1<x_i<2)\right] \frac{\partial \log \ell(\theta)}{\partial \theta}=0 \hat{\theta}","['statistics', 'statistical-inference', 'maximum-likelihood', 'parameter-estimation']"
91,On the distribution of a normalized Gaussian vector,On the distribution of a normalized Gaussian vector,,"Let $x=(x_1,\ldots,x_n)\in\mathbb{R}^n$ be an $n$ -dimensional random vector that follows the normal distribution with mean vector $\mu$ and covariance matrix $\Sigma=\operatorname{diag}\left(\sigma_1^2, \ldots, \sigma_d^2\right)$ ; in other words, each element of $x$ is a uni-variate normal distribution with mean and variance. I'm interested in the distribution of the normalized vector $$ \tilde{x} = \frac{x}{\lVert x \rVert}=\frac{x}{\sqrt{x_1^2+\ldots+x_n^2}}. $$ Since $x_i$ 's are independent, I though about studying each random variable separately; i.e.: $$ \tilde{x}_i = \frac{x_i}{\sqrt{x_1^2+\ldots+x_n^2}}, $$ or something like this $$ \tilde{x}_i = \frac{x_i}{\sqrt{x_i^2+a}},\quad a>0, $$ but I cannot think of any useful strategy. Using the definition of expectation and variance would lead to painful integrations, I think. My goal is to normalize the mean vector, and simultaneously transform the variances so as not to ""break"" my set's structure; even a heuristic/approximating approach would suffice.","Let be an -dimensional random vector that follows the normal distribution with mean vector and covariance matrix ; in other words, each element of is a uni-variate normal distribution with mean and variance. I'm interested in the distribution of the normalized vector Since 's are independent, I though about studying each random variable separately; i.e.: or something like this but I cannot think of any useful strategy. Using the definition of expectation and variance would lead to painful integrations, I think. My goal is to normalize the mean vector, and simultaneously transform the variances so as not to ""break"" my set's structure; even a heuristic/approximating approach would suffice.","x=(x_1,\ldots,x_n)\in\mathbb{R}^n n \mu \Sigma=\operatorname{diag}\left(\sigma_1^2, \ldots, \sigma_d^2\right) x 
\tilde{x} = \frac{x}{\lVert x \rVert}=\frac{x}{\sqrt{x_1^2+\ldots+x_n^2}}.
 x_i 
\tilde{x}_i = \frac{x_i}{\sqrt{x_1^2+\ldots+x_n^2}},
 
\tilde{x}_i = \frac{x_i}{\sqrt{x_i^2+a}},\quad a>0,
","['statistics', 'random-variables', 'normal-distribution']"
92,Statistics Olympiad Problem,Statistics Olympiad Problem,,"Given that the mean, median, range and the only mode of 200 integers are also 200. If $A$ is the largest integer among those 200 integers, find the maximum value of $A$ . I have asked some of my friends and colleagues to solve this problem, but no one give me a light. Attempt: Assuming first that all the numbers are $200$ .  To maximize $A$ , but satisfies all the criterion given, we need to make $A$ ascending while descending the value of other numbers.  Logically, $100, 200, 200, \cdots, 300$ still satisfies. Maybe we have $A_{\text{max}} = 300$ ?  I don't know how to approach it clearly.","Given that the mean, median, range and the only mode of 200 integers are also 200. If is the largest integer among those 200 integers, find the maximum value of . I have asked some of my friends and colleagues to solve this problem, but no one give me a light. Attempt: Assuming first that all the numbers are .  To maximize , but satisfies all the criterion given, we need to make ascending while descending the value of other numbers.  Logically, still satisfies. Maybe we have ?  I don't know how to approach it clearly.","A A 200 A A 100, 200, 200, \cdots, 300 A_{\text{max}} = 300",['statistics']
93,"How can ""relative frequency histogram"" become a ""probability density curve""?","How can ""relative frequency histogram"" become a ""probability density curve""?",,"Suppose I've rolled two dice and took the sum, for $25$ times; then plotted the results on below  histogram. If I added up all the heights, I get the total $25$ as expected : $$1+1+1+3+2+7+2+1+4+2+1=25$$ No issues so far. Next, if I want a relative frequency histogram, I just need to scale the heights of the bars by $1/25$ . Here if I add up all the heights , I will get $1$ . No issues here too. In this video of khan academy and everywhere they say that the ""area"" under a relative frequency histogram equals 1 . I don't know how this is true and it is throwing me off completely. I only see that the heights add up to 1 . Maybe I'm missing something... Any help ? EDIT : In above histogram the bin width is $1$ , so it may not be a good example. Kindly also consider general histograms like below :","Suppose I've rolled two dice and took the sum, for times; then plotted the results on below  histogram. If I added up all the heights, I get the total as expected : No issues so far. Next, if I want a relative frequency histogram, I just need to scale the heights of the bars by . Here if I add up all the heights , I will get . No issues here too. In this video of khan academy and everywhere they say that the ""area"" under a relative frequency histogram equals 1 . I don't know how this is true and it is throwing me off completely. I only see that the heights add up to 1 . Maybe I'm missing something... Any help ? EDIT : In above histogram the bin width is , so it may not be a good example. Kindly also consider general histograms like below :",25 25 1+1+1+3+2+7+2+1+4+2+1=25 1/25 1 1,"['statistics', 'probability-distributions']"
94,Mode of lognormal distribution,Mode of lognormal distribution,,"Suppose $$y=e^{x}$$ where x is normal with mean mu and variance sigma. Then I see how to derive mode of f(y) (distribution of y), as we need to find the value y that makes $$f'(y)==0$$ However, why is mode not simply $$e^{\mu}$$? y is a monotonic function of x, and so when x reaches its mode, then y should also reach its mode. The mode of x is its mean (mu) hence y's mode should be $$e^{\mu}$$ what mistake have I made? Thanks","Suppose $$y=e^{x}$$ where x is normal with mean mu and variance sigma. Then I see how to derive mode of f(y) (distribution of y), as we need to find the value y that makes $$f'(y)==0$$ However, why is mode not simply $$e^{\mu}$$? y is a monotonic function of x, and so when x reaches its mode, then y should also reach its mode. The mode of x is its mean (mu) hence y's mode should be $$e^{\mu}$$ what mistake have I made? Thanks",,['statistics']
95,Over-determined and Under-determined systems,Over-determined and Under-determined systems,,"How do I show that a system is both over-determined and under-determined? I am supposed to come up with a matrix that satisfies both but am not really sure I understand what types of equations would satisfy these criteria. If anyone could give me an example and maybe a format to go by, I would appreciate it.","How do I show that a system is both over-determined and under-determined? I am supposed to come up with a matrix that satisfies both but am not really sure I understand what types of equations would satisfy these criteria. If anyone could give me an example and maybe a format to go by, I would appreciate it.",,['statistics']
96,Understanding the Beta-function,Understanding the Beta-function,,"I always forget whether the beta function, B$(\alpha, \beta)$, is defined as $\Gamma(\alpha+\beta)/\Gamma(\alpha)\Gamma(\beta)$ or $\Gamma(\alpha)\Gamma(\beta)/\Gamma(\alpha+\beta)$. Is there an intuitive way, preferably as a normalising constant for the beta distribution, I can understand this function so I never have to look it up again. :)","I always forget whether the beta function, B$(\alpha, \beta)$, is defined as $\Gamma(\alpha+\beta)/\Gamma(\alpha)\Gamma(\beta)$ or $\Gamma(\alpha)\Gamma(\beta)/\Gamma(\alpha+\beta)$. Is there an intuitive way, preferably as a normalising constant for the beta distribution, I can understand this function so I never have to look it up again. :)",,"['statistics', 'probability-distributions']"
97,Why the natural log is there in MLE?,Why the natural log is there in MLE?,,Why do we use natural log for MLE?,Why do we use natural log for MLE?,,"['statistics', 'statistical-inference', 'standard-deviation']"
98,Why can we assume that the expected value of the error term is zero? [closed],Why can we assume that the expected value of the error term is zero? [closed],,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 years ago . Improve this question Why can we assume that the expected value of the error term in a linear regression model is zero? This is with regard to a simple linear regression.,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 years ago . Improve this question Why can we assume that the expected value of the error term in a linear regression model is zero? This is with regard to a simple linear regression.,,"['statistics', 'regression', 'economics']"
99,Obtaining cumulants using the characteristic function,Obtaining cumulants using the characteristic function,,"If a random variable $x$ has a characteristic function $\phi(\omega)$, then the $n^{\mathrm{th}}$ moment of the distribution of $x$, $\mu_n$ can be calculated as: $$\mu_n = \imath^{-n}\left[\frac{d^n}{d\omega^n}\phi(\omega)\right]_{\omega=0}$$ Is there a similar formula to compute the $n^{\mathrm{th}}$ cumulant of the distribution, $\kappa_n$ in terms of the characteristic function? Wolfram MathWorld lists a formula as: $$\ln[\phi(\omega)]=\sum_{n=0}^\infty\kappa_n \frac{(\imath \omega)^n}{n!}$$ However, this is not helpful in obtaining the $n^\mathrm{tm}$ cumulant (or if it is, I don't know how).","If a random variable $x$ has a characteristic function $\phi(\omega)$, then the $n^{\mathrm{th}}$ moment of the distribution of $x$, $\mu_n$ can be calculated as: $$\mu_n = \imath^{-n}\left[\frac{d^n}{d\omega^n}\phi(\omega)\right]_{\omega=0}$$ Is there a similar formula to compute the $n^{\mathrm{th}}$ cumulant of the distribution, $\kappa_n$ in terms of the characteristic function? Wolfram MathWorld lists a formula as: $$\ln[\phi(\omega)]=\sum_{n=0}^\infty\kappa_n \frac{(\imath \omega)^n}{n!}$$ However, this is not helpful in obtaining the $n^\mathrm{tm}$ cumulant (or if it is, I don't know how).",,"['statistics', 'probability-distributions', 'generating-functions', 'characteristic-functions']"
