,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Algebraization of integral calculus,Algebraization of integral calculus,,"It is well known that the differential calculus has a nice algebraization in terms of the differential rings but what about integral calculus? Of course, one sometimes defines an integral in a differential ring $R$ with a derivation $\partial$ as a projection $\pi: R\rightarrow \tilde R$, where $\tilde R$ is a quotient of $R$ w.r.t. the following equivalence relation: $f\sim g$ iff $f-g$ is in the image of $\partial$, but this is not very intuitive and apparently corresponds to the idea of definite integral over a fixed domain rather than to that of an indefinite one. So my question is: Are there algebraic counterparts for the concept of an indefinite integral?","It is well known that the differential calculus has a nice algebraization in terms of the differential rings but what about integral calculus? Of course, one sometimes defines an integral in a differential ring $R$ with a derivation $\partial$ as a projection $\pi: R\rightarrow \tilde R$, where $\tilde R$ is a quotient of $R$ w.r.t. the following equivalence relation: $f\sim g$ iff $f-g$ is in the image of $\partial$, but this is not very intuitive and apparently corresponds to the idea of definite integral over a fixed domain rather than to that of an indefinite one. So my question is: Are there algebraic counterparts for the concept of an indefinite integral?",,"['calculus', 'abstract-algebra', 'integration']"
1,"Proving $_4F_3\left(\frac{1}{2},\frac{3}{4},\frac{3}{4},1;\frac{5}{4},\frac{5}{4}, \frac{3}{2};1\right)=\frac{\Gamma^8(1/4)}{768\pi^3}$",Proving,"_4F_3\left(\frac{1}{2},\frac{3}{4},\frac{3}{4},1;\frac{5}{4},\frac{5}{4}, \frac{3}{2};1\right)=\frac{\Gamma^8(1/4)}{768\pi^3}","I have been trying to Prove the following Sum. $$\frac{\Gamma^2(5/4)}{\Gamma^2(3/4)}\sum_{r=0}^{\infty}\left(\frac{1}{2r+1}\right)\frac{\Gamma^2(r+3/4)}{\Gamma^2(r+5/4)}=\frac{\Gamma^8(1/4)}{768\pi^3}$$ Or in terms of Pochhammer Symbol: $$\sum_{r=0}^{\infty}\left(\frac{1}{2r+1}\right)\frac{(3/4)_r^2}{(5/4)_r^2}=\frac{\Gamma^8(1/4)}{768\pi^3}$$ One may convert it into a Hypergeometric Representation which gives: $$_4F_3\left(\frac{1}{2},\frac{3}{4},\frac{3}{4},1;\frac{5}{4},\frac{5}{4}, \frac{3}{2};1\right)=\frac{1}{768\pi^3}\Gamma^8\left(\frac{1}{4}\right)$$ Also note that, $$\sum_{i=1}^3b_i-\sum_{i=1}^{4}a_i=1$$ I just mentioned the above because I heard it's a kind of Property of such Functions. I don't see how a $8$ th Power Gamma Term appears. The following List at Functions.Wolfram doesn't have any similar ones nor am I able to use any formulas either. One may use the following to Numerically Test it. N[HypergeometricPFQ[{1/2,3/4,3/4,1},{5/4,5/4,3/2},1],300]-Gamma[1/4]^8/Pi^3*1/768 EDIT: I was able to Convert it to an Integral: $$\int_{0}^{1}\int_{0}^{1}\frac{\ln(1+xy)-\ln(1-xy)}{\sqrt{xy(1-x^2)(1-y^2)}}dxdy=\frac{\Gamma^4(1/4)}{48}$$","I have been trying to Prove the following Sum. Or in terms of Pochhammer Symbol: One may convert it into a Hypergeometric Representation which gives: Also note that, I just mentioned the above because I heard it's a kind of Property of such Functions. I don't see how a th Power Gamma Term appears. The following List at Functions.Wolfram doesn't have any similar ones nor am I able to use any formulas either. One may use the following to Numerically Test it. N[HypergeometricPFQ[{1/2,3/4,3/4,1},{5/4,5/4,3/2},1],300]-Gamma[1/4]^8/Pi^3*1/768 EDIT: I was able to Convert it to an Integral:","\frac{\Gamma^2(5/4)}{\Gamma^2(3/4)}\sum_{r=0}^{\infty}\left(\frac{1}{2r+1}\right)\frac{\Gamma^2(r+3/4)}{\Gamma^2(r+5/4)}=\frac{\Gamma^8(1/4)}{768\pi^3} \sum_{r=0}^{\infty}\left(\frac{1}{2r+1}\right)\frac{(3/4)_r^2}{(5/4)_r^2}=\frac{\Gamma^8(1/4)}{768\pi^3} _4F_3\left(\frac{1}{2},\frac{3}{4},\frac{3}{4},1;\frac{5}{4},\frac{5}{4},
\frac{3}{2};1\right)=\frac{1}{768\pi^3}\Gamma^8\left(\frac{1}{4}\right) \sum_{i=1}^3b_i-\sum_{i=1}^{4}a_i=1 8 \int_{0}^{1}\int_{0}^{1}\frac{\ln(1+xy)-\ln(1-xy)}{\sqrt{xy(1-x^2)(1-y^2)}}dxdy=\frac{\Gamma^4(1/4)}{48}","['calculus', 'sequences-and-series', 'hypergeometric-function']"
2,Solving $\lim_{n\to\infty}\sqrt n\int_0^{\frac12}(1-3x^2+x^4)^n\mathrm{d}x$,Solving,\lim_{n\to\infty}\sqrt n\int_0^{\frac12}(1-3x^2+x^4)^n\mathrm{d}x,"$$\lim_{n\to\infty}\sqrt n\int_0^{\frac12}(1-3x^2+x^4)^n\:\mathrm{d}x=0.5116...$$ Attempting the limit above. I'm only average in calculus, and none of the usual methods seem to work. I did find these equivalent forms of $1-3x^2+x^4$ that are useless to me but may give you some ideas: $(x+\varphi)(x-\varphi)(x+\varphi-1)(x-\varphi+1)$ , where $\varphi=\frac{1+\sqrt5}2$ $(x^2-\varphi^2)(x^2-(\varphi-1)^2)$ $(x^2+(2\varphi-1)x+1)(x^2-(2\varphi-1)x+1)$ $(x^2-x-1)(x^2+x-1)$ $(x^2-1)^2-x^2$ $\left(x^2-\frac32\right)^2-\frac54$ If the polynomial's domain is restricted to $[0,\varphi-1]$ , its inverse is $\sqrt{\frac32-\sqrt{x+\frac54}}.$ I've found these two infinite series that should be equivalent to the limit by ""solving"" the integral. The first series is derived from expanding $\left(\left(x^2-\frac32\right)^2-\frac54\right)^n$ with the binomial theorem: $$\lim_{n\to\infty}\sqrt n\left(-\frac54\right)^n\sum_{m=0}^n\binom nm\left(-\frac95\right)^m\sum_{k=0}^{2m}\frac1{2k+1}\binom{2m}k\left(-\frac16\right)^k$$ Wolfram Alpha evaluated the indefinite integral as an infinite series , so calculating the integral itself is likely a bad idea. Attached to its answer was a unit complex correction term of some sort that should be $1$ when $0\le x\le\frac12$ . The second series simplifies the output from Wolfram Alpha, where $x^{\bar n}=x(x+1)\cdots(x+n-1)$ is the rising factorial: $$\lim_{n\to\infty}\sqrt{n}\sum_{i=0}^{\infty}\sum_{j=0}^{\infty}\frac{\varphi^{2\left(i-j\right)}}{\left(2i+2j+1\right)4^{i+j}}\frac{(-n)^{\bar i}}{i!}\frac{(-n)^{\bar{j}}}{j!}$$ The only context I have for this problem was that I received it from someone else who sent it after getting stuck, who had received it from someone else who sent it after getting stuck. How should this integral be solved?","Attempting the limit above. I'm only average in calculus, and none of the usual methods seem to work. I did find these equivalent forms of that are useless to me but may give you some ideas: , where If the polynomial's domain is restricted to , its inverse is I've found these two infinite series that should be equivalent to the limit by ""solving"" the integral. The first series is derived from expanding with the binomial theorem: Wolfram Alpha evaluated the indefinite integral as an infinite series , so calculating the integral itself is likely a bad idea. Attached to its answer was a unit complex correction term of some sort that should be when . The second series simplifies the output from Wolfram Alpha, where is the rising factorial: The only context I have for this problem was that I received it from someone else who sent it after getting stuck, who had received it from someone else who sent it after getting stuck. How should this integral be solved?","\lim_{n\to\infty}\sqrt n\int_0^{\frac12}(1-3x^2+x^4)^n\:\mathrm{d}x=0.5116... 1-3x^2+x^4 (x+\varphi)(x-\varphi)(x+\varphi-1)(x-\varphi+1) \varphi=\frac{1+\sqrt5}2 (x^2-\varphi^2)(x^2-(\varphi-1)^2) (x^2+(2\varphi-1)x+1)(x^2-(2\varphi-1)x+1) (x^2-x-1)(x^2+x-1) (x^2-1)^2-x^2 \left(x^2-\frac32\right)^2-\frac54 [0,\varphi-1] \sqrt{\frac32-\sqrt{x+\frac54}}. \left(\left(x^2-\frac32\right)^2-\frac54\right)^n \lim_{n\to\infty}\sqrt n\left(-\frac54\right)^n\sum_{m=0}^n\binom nm\left(-\frac95\right)^m\sum_{k=0}^{2m}\frac1{2k+1}\binom{2m}k\left(-\frac16\right)^k 1 0\le x\le\frac12 x^{\bar n}=x(x+1)\cdots(x+n-1) \lim_{n\to\infty}\sqrt{n}\sum_{i=0}^{\infty}\sum_{j=0}^{\infty}\frac{\varphi^{2\left(i-j\right)}}{\left(2i+2j+1\right)4^{i+j}}\frac{(-n)^{\bar i}}{i!}\frac{(-n)^{\bar{j}}}{j!}","['calculus', 'integration', 'limits']"
3,Clarification of the $u$-substitution theorem,Clarification of the -substitution theorem,u,"I came across this phrasing of the theorem justifying u-substitution: Let $F(x)$ be an antiderivative of $f(x)$ in an interval $I.$ Let $\phi$ from $J$ to $I$ , $\phi(t) = x$ be a differentiable function. Then $\int f(x)dx=\int f(\phi(t))\phi^{\prime}(t)dt.$ I am confused about the assumptions part - first of all, why can we assume that there exists a function $\phi$ such that $\phi(t)=x$ ? Secondly, we know that the image of $\phi$ over $J$ is a subset of $I$ . Why aren't we demanding that the image of $\phi$ will be equal to $I$ , and not just a subset? In my mind, we are ""losing"" some $x$ values that are not given by $\phi(t)$ if it is strictly contained. Lastly, in the final steps of the proof of this theorem, we said that $F(\phi(t))+c=F(x)+c=\int f(x)dx.$ Why can we treat $x$ just like a ""dummy"" variable? We assumed it equals a function $\phi(t)$ after all.","I came across this phrasing of the theorem justifying u-substitution: Let be an antiderivative of in an interval Let from to , be a differentiable function. Then I am confused about the assumptions part - first of all, why can we assume that there exists a function such that ? Secondly, we know that the image of over is a subset of . Why aren't we demanding that the image of will be equal to , and not just a subset? In my mind, we are ""losing"" some values that are not given by if it is strictly contained. Lastly, in the final steps of the proof of this theorem, we said that Why can we treat just like a ""dummy"" variable? We assumed it equals a function after all.",F(x) f(x) I. \phi J I \phi(t) = x \int f(x)dx=\int f(\phi(t))\phi^{\prime}(t)dt. \phi \phi(t)=x \phi J I \phi I x \phi(t) F(\phi(t))+c=F(x)+c=\int f(x)dx. x \phi(t),"['calculus', 'integration', 'indefinite-integrals', 'substitution']"
4,Geometric intuition for why $\int_0^\theta \cos xdx = \sin\theta$,Geometric intuition for why,\int_0^\theta \cos xdx = \sin\theta,"Why is $\int_0^\theta \cos x dx = \sin\theta$ ? How does the area under the cosine curve from 0 to some angle $\theta$ relate to the unit circle definition of $\sin\theta$ , i.e, as the vertical distance travelled across the unit circle circumference from 0 to $\theta$ . Is there a way to see how these two geometric pictures relate to each other, so as to develop an intuition for the equality?","Why is ? How does the area under the cosine curve from 0 to some angle relate to the unit circle definition of , i.e, as the vertical distance travelled across the unit circle circumference from 0 to . Is there a way to see how these two geometric pictures relate to each other, so as to develop an intuition for the equality?",\int_0^\theta \cos x dx = \sin\theta \theta \sin\theta \theta,"['calculus', 'intuition', 'trigonometric-integrals']"
5,Convergence of a sequence defined by an integral,Convergence of a sequence defined by an integral,,"Let me state the problem first. It is one of my calculus exercises. $$a_n = \int_0^{\pi/2} \frac{\sin^2x}{1+\sin^2 nx}dx$$ Show that $a_n$ converges and find its limit. The only theorem I know about the convergence of the sequence is monotone convergence theorem, but I cannot find out whether $a_n$ is monotone. The sequences defined by integral ususally gives the recurrence relation by IBP, but in this approach, effective choice of $u$ and $v'$ seems to be unclear. Thanks in advance for all solutions, ideas, and hints.","Let me state the problem first. It is one of my calculus exercises. Show that converges and find its limit. The only theorem I know about the convergence of the sequence is monotone convergence theorem, but I cannot find out whether is monotone. The sequences defined by integral ususally gives the recurrence relation by IBP, but in this approach, effective choice of and seems to be unclear. Thanks in advance for all solutions, ideas, and hints.",a_n = \int_0^{\pi/2} \frac{\sin^2x}{1+\sin^2 nx}dx a_n a_n u v',"['calculus', 'integration', 'sequences-and-series', 'definite-integrals']"
6,"Prove $3\int_{0}^{1}\frac{x\arctan x}{3x^2+1}\,\mathrm dx -\int_{0}^{1}\frac{x\arctan x}{x^2+3}\,\mathrm dx =\frac23 G-\frac {\pi}{12}\ln(2+\sqrt{3})$",Prove,"3\int_{0}^{1}\frac{x\arctan x}{3x^2+1}\,\mathrm dx -\int_{0}^{1}\frac{x\arctan x}{x^2+3}\,\mathrm dx =\frac23 G-\frac {\pi}{12}\ln(2+\sqrt{3})","Prove that $$ I =3\int_{0}^{1}\frac{x\arctan x}{3x^2+1}\,\mathrm dx -\int_{0}^{1}\frac{x\arctan x}{x^2+3}\,\mathrm dx =\frac23 G-\frac {\pi}{12}\ln(2+\sqrt{3}). $$ where, $G$ is catalan's constant Above two Integrals are a part of a integral which I was trying to solve. Let $I=3I_{1}-I_{2}$ Attempt:-1 $$I_{1}=\int_{0}^{1}\frac{x\arctan x}{x^2+3}\,\mathrm dx$$ $$\implies I_{1}=\int_{0}^{1}\frac{x}{x^2+3}\sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{2n-1} x^{2n-1}\,\mathrm dx$$ $$\implies I_{1}=\sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{2n-1}\int_{0}^{1}\frac{x^{2n}}{x^2+3}\,\mathrm dx.$$ From my previous question 1 we have $$ \int_{0}^{1}\frac{x^{2n}}{x^{2}+3}\,\mathrm dx =(-3)^{n}\frac{\pi}{6\sqrt{3}}+\sum_{k=0}^{n-1}\frac{(-3)^{n-1-k}}{2k+1}. $$ Therefore, $$ I_{1}=\sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{2n-1}\bigg[(-3)^{n}\frac{\pi}{6\sqrt{3}}+\sum_{k=0}^{n-1}\frac{(-3)^{n-1-k}}{2k+1}\bigg], $$ $$ I_{1}=\sum_{n=1}^{\infty}\sum_{k=0}^{n-1}\frac{(-1)^{2n-k}\space 3^{n-1-k}}{(2k+1)(2n-1)}-\frac{\pi}{6\sqrt{3}}\sum_{n=1}^{\infty}\frac{3^{n}}{2n-1}. $$ Using Desmos Both of the series diverges so $I_{1}$ is of the form $\infty -\infty$ which have a finite answer. Same thing goes with $I_{2}$ . Attempt:- 2: Try to convert one integral into another. Substitute $x=\frac{1}{x}$ in $I_{1}$ , we get $$I_{1}=-\frac{3\pi}{2}\int_{1}^{\infty}\frac{x}{x^2+3} \,\mathrm dx  +3\int_{1}^{\infty}\frac{x \space tan^{-1}x}{x^2+3} \,\mathrm dx $$ $$\implies I=-\frac{3\pi}{2}\int_{1}^{\infty}\frac{x}{x^2+3} \,\mathrm dx -\int_{0}^{\infty}\frac{x \space tan^{-1}x}{x^2+3} \,\mathrm dx  +4\int_{1}^{\infty}\frac{x \space tan^{-1}x}{x^2+3} \,\mathrm dx$$ Surprisingly all three integrals diverges and convergence of $I$ is maintained by negative and positive sign. How can I prove the original result? Thank you for your help!","Prove that where, is catalan's constant Above two Integrals are a part of a integral which I was trying to solve. Let Attempt:-1 From my previous question 1 we have Therefore, Using Desmos Both of the series diverges so is of the form which have a finite answer. Same thing goes with . Attempt:- 2: Try to convert one integral into another. Substitute in , we get Surprisingly all three integrals diverges and convergence of is maintained by negative and positive sign. How can I prove the original result? Thank you for your help!","
I
=3\int_{0}^{1}\frac{x\arctan x}{3x^2+1}\,\mathrm dx
-\int_{0}^{1}\frac{x\arctan x}{x^2+3}\,\mathrm dx
=\frac23 G-\frac {\pi}{12}\ln(2+\sqrt{3}).
 G I=3I_{1}-I_{2} I_{1}=\int_{0}^{1}\frac{x\arctan x}{x^2+3}\,\mathrm dx \implies I_{1}=\int_{0}^{1}\frac{x}{x^2+3}\sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{2n-1} x^{2n-1}\,\mathrm dx \implies I_{1}=\sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{2n-1}\int_{0}^{1}\frac{x^{2n}}{x^2+3}\,\mathrm dx. 
\int_{0}^{1}\frac{x^{2n}}{x^{2}+3}\,\mathrm dx
=(-3)^{n}\frac{\pi}{6\sqrt{3}}+\sum_{k=0}^{n-1}\frac{(-3)^{n-1-k}}{2k+1}.
 
I_{1}=\sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{2n-1}\bigg[(-3)^{n}\frac{\pi}{6\sqrt{3}}+\sum_{k=0}^{n-1}\frac{(-3)^{n-1-k}}{2k+1}\bigg],
 
I_{1}=\sum_{n=1}^{\infty}\sum_{k=0}^{n-1}\frac{(-1)^{2n-k}\space 3^{n-1-k}}{(2k+1)(2n-1)}-\frac{\pi}{6\sqrt{3}}\sum_{n=1}^{\infty}\frac{3^{n}}{2n-1}.
 I_{1} \infty -\infty I_{2} x=\frac{1}{x} I_{1} I_{1}=-\frac{3\pi}{2}\int_{1}^{\infty}\frac{x}{x^2+3} \,\mathrm dx
 +3\int_{1}^{\infty}\frac{x \space tan^{-1}x}{x^2+3} \,\mathrm dx  \implies I=-\frac{3\pi}{2}\int_{1}^{\infty}\frac{x}{x^2+3} \,\mathrm dx -\int_{0}^{\infty}\frac{x \space tan^{-1}x}{x^2+3} \,\mathrm dx  +4\int_{1}^{\infty}\frac{x \space tan^{-1}x}{x^2+3} \,\mathrm dx I","['calculus', 'integration', 'sequences-and-series', 'definite-integrals']"
7,How to compute $\int_{0}^{+\infty}\frac{x^2\mathrm{d}x}{e^{x}-1}$ analytically?,How to compute  analytically?,\int_{0}^{+\infty}\frac{x^2\mathrm{d}x}{e^{x}-1},"Does anyone know how to compute analytically the following integral: $$\int\limits_{0}^{+\infty}\dfrac{x^2\mathrm{d}x}{e^{x}-1}$$ It should be equal to $2\zeta(3)$ according to Maple. I tried the following using the binomial theorem for negative integer exponents: $$I = \int\limits^{+\infty}_{0} e^{-x}(1-e^{-x})^{-1}x^2\mathrm{d}x = \int\limits^{+\infty}_{0}\left[\sum_{k=0}^{+\infty}(-1)^k(-1)^ke^{-(k+1)x}\right]x^2\mathrm{d}x=\int\limits^{+\infty}_{0}\left[\sum_{k=0}^{+\infty}(-1)^{2k}e^{-(k+1)x}\right]x^2\mathrm{d}x$$ After another change of variables, $y=(k+1)x$ : $$I = \sum_{k=0}^{+\infty}(-1)^{2k} \frac{1}{(k+1)^3}\int\limits_0^{+\infty} y^2e^{-y}\mathrm{d}y$$ The keen eye might recognize $\int\limits_0^{+\infty} y^2e^{-y}\mathrm{d}y$ as the gamma function, $\Gamma(3)=(3-1)!=2$ . This, together with a slight nudge to the bottom limit of the summation we can rewrite things as: $$I = \Gamma(3)\sum_{k=1}^{+\infty} \dfrac{(-1)^{2k}}{k^3}$$ And i see immediately (since the beginning in fact...) an infinite sum that makes me troubles and i can't get rid of. I tried to found if i did any trivial error but i'm focusing since to many hours to found it. That's why I need an external view to point me out my obvious error. Thanks in advance for your help","Does anyone know how to compute analytically the following integral: It should be equal to according to Maple. I tried the following using the binomial theorem for negative integer exponents: After another change of variables, : The keen eye might recognize as the gamma function, . This, together with a slight nudge to the bottom limit of the summation we can rewrite things as: And i see immediately (since the beginning in fact...) an infinite sum that makes me troubles and i can't get rid of. I tried to found if i did any trivial error but i'm focusing since to many hours to found it. That's why I need an external view to point me out my obvious error. Thanks in advance for your help",\int\limits_{0}^{+\infty}\dfrac{x^2\mathrm{d}x}{e^{x}-1} 2\zeta(3) I = \int\limits^{+\infty}_{0} e^{-x}(1-e^{-x})^{-1}x^2\mathrm{d}x = \int\limits^{+\infty}_{0}\left[\sum_{k=0}^{+\infty}(-1)^k(-1)^ke^{-(k+1)x}\right]x^2\mathrm{d}x=\int\limits^{+\infty}_{0}\left[\sum_{k=0}^{+\infty}(-1)^{2k}e^{-(k+1)x}\right]x^2\mathrm{d}x y=(k+1)x I = \sum_{k=0}^{+\infty}(-1)^{2k} \frac{1}{(k+1)^3}\int\limits_0^{+\infty} y^2e^{-y}\mathrm{d}y \int\limits_0^{+\infty} y^2e^{-y}\mathrm{d}y \Gamma(3)=(3-1)!=2 I = \Gamma(3)\sum_{k=1}^{+\infty} \dfrac{(-1)^{2k}}{k^3},"['calculus', 'integration', 'riemann-zeta']"
8,Evaluate integral $\int (x^2-1)(x^3-3x)^{4/3} \mathop{dx}$,Evaluate integral,\int (x^2-1)(x^3-3x)^{4/3} \mathop{dx},"How can I evaluate this integral $$\int (x^2-1)(x^3-3x)^{4/3} \mathop{dx}=\;\;?$$ My attempt : I tried using substitution $x=\sec\theta$ , $dx=\sec\theta\ \tan\theta d\theta$ , $$\int (\sec^2\theta-1)(\sec^3\theta-3\sec\theta)^{4/3}    \sec\theta\ \tan\theta d\theta $$ $$=\int \tan^2\theta \sec^4\theta(1-3\cos^2\theta)^{4/3} \sec\theta\ \tan\theta d\theta $$ $$=\int \tan^3\theta \sec^5\theta(1-3\cos^2\theta)^{4/3}\ d\theta $$ $$=\int\dfrac{ \sin^3\theta}{ \cos^8\theta}(1-3\cos^2\theta)^{4/3}\ d\theta $$ I can't see if this substitution will work or not. This has become so complicated. Please help me solve this integral.","How can I evaluate this integral My attempt : I tried using substitution , , I can't see if this substitution will work or not. This has become so complicated. Please help me solve this integral.","\int (x^2-1)(x^3-3x)^{4/3} \mathop{dx}=\;\;? x=\sec\theta dx=\sec\theta\ \tan\theta d\theta \int (\sec^2\theta-1)(\sec^3\theta-3\sec\theta)^{4/3} 
  \sec\theta\ \tan\theta d\theta  =\int \tan^2\theta \sec^4\theta(1-3\cos^2\theta)^{4/3} \sec\theta\ \tan\theta d\theta  =\int \tan^3\theta \sec^5\theta(1-3\cos^2\theta)^{4/3}\ d\theta  =\int\dfrac{ \sin^3\theta}{ \cos^8\theta}(1-3\cos^2\theta)^{4/3}\ d\theta ",['calculus']
9,Verify whether a function is injective,Verify whether a function is injective,,"I'm trying to learn how to verify whether a function is injective. This is my function: $g=e^{1-y^2}-1$ How should I proceed in veryfing whether it is injective or not? In my lecture, we verified using the definition by checking whether the function is always increasing or decreasing (we started with only some part of a function and continued to add the rest of the function while always verifying whether $f(x_1)<f(x_2)$ for all $x_1<x_2$ ). However, with this function, the approach seems too difficult to do. Is there any way to verify whether it is injective or not? Thanks","I'm trying to learn how to verify whether a function is injective. This is my function: How should I proceed in veryfing whether it is injective or not? In my lecture, we verified using the definition by checking whether the function is always increasing or decreasing (we started with only some part of a function and continued to add the rest of the function while always verifying whether for all ). However, with this function, the approach seems too difficult to do. Is there any way to verify whether it is injective or not? Thanks",g=e^{1-y^2}-1 f(x_1)<f(x_2) x_1<x_2,['calculus']
10,How derivative of matrix leads to its transpose?,How derivative of matrix leads to its transpose?,,"I'm deriving backpropagation step of training neural networks using vectorized equations. Following are two forward propagation equations between last hidden layer and output layer. $$ Z^{[2]} = W^{[2]}A^{[1]} + b^{[2]} $$ $$ A^{[2]} = \hat{y} = g(Z^{[2]})$$ Where $g(z)$ is activation function. Now in backpropagation, we calculate the change in cost function ( $J$ ) w.r.t. all the parameters. I've successfully calculated $\partial{J}/\partial{A^{[2]}}$ and $\partial{J}/\partial{Z^{[2]}}$ using chain rule. Now to calculate $\partial{J}/\partial{W^{[2]}}$ , I've formed following chain $$ \frac{\partial{J}}{\partial{W^{[2]}}} = \frac{\partial{J}}{\partial{A^{[2]}}} \frac{\partial{A^{[2]}}}{\partial{Z^{[2]}}}  \frac{\partial{Z^{[2]}}}{\partial{W^{[2]}}}$$ Now to calculate $\frac{\partial{Z^{[2]}}}{\partial{W^{[2]}}}$ , I used $ Z^{[2]} = W^{[2]}A^{[1]} + b^{[2]} $ equation which simply gives the derivation $ A^{[1]} $ . But in literature , it's given as $ A^{[1]^{T}} $ , which is transpose of my answer. By checking dimensions of the answer, I could verify that the answer should be $ A^{[1]^{T}} $ instead if $ A^{[1]} $ . But is there any general rule for such cases using which I could directly tell whether the derivative will be the transpose of a matrix or not without verifying dimensions? I've also checked matrix cookbook but couldn't find any related thumb rules.","I'm deriving backpropagation step of training neural networks using vectorized equations. Following are two forward propagation equations between last hidden layer and output layer. Where is activation function. Now in backpropagation, we calculate the change in cost function ( ) w.r.t. all the parameters. I've successfully calculated and using chain rule. Now to calculate , I've formed following chain Now to calculate , I used equation which simply gives the derivation . But in literature , it's given as , which is transpose of my answer. By checking dimensions of the answer, I could verify that the answer should be instead if . But is there any general rule for such cases using which I could directly tell whether the derivative will be the transpose of a matrix or not without verifying dimensions? I've also checked matrix cookbook but couldn't find any related thumb rules.", Z^{[2]} = W^{[2]}A^{[1]} + b^{[2]}   A^{[2]} = \hat{y} = g(Z^{[2]}) g(z) J \partial{J}/\partial{A^{[2]}} \partial{J}/\partial{Z^{[2]}} \partial{J}/\partial{W^{[2]}}  \frac{\partial{J}}{\partial{W^{[2]}}} = \frac{\partial{J}}{\partial{A^{[2]}}} \frac{\partial{A^{[2]}}}{\partial{Z^{[2]}}}  \frac{\partial{Z^{[2]}}}{\partial{W^{[2]}}} \frac{\partial{Z^{[2]}}}{\partial{W^{[2]}}}  Z^{[2]} = W^{[2]}A^{[1]} + b^{[2]}   A^{[1]}   A^{[1]^{T}}   A^{[1]^{T}}   A^{[1]} ,"['calculus', 'derivatives', 'partial-derivative', 'machine-learning', 'neural-networks']"
11,$\sum\limits_{n=1}^{\infty}\arctan{\frac{2}{n^2+n+4}}$,,\sum\limits_{n=1}^{\infty}\arctan{\frac{2}{n^2+n+4}},$$\sum\limits_{n=1}^{\infty}\arctan{\frac{2}{n^2+n+4}}$$ We know that : $\arctan{x} - \arctan{y} = \arctan{\frac{x-y}{1+xy}}$ for every $ xy > 1 $ I need to find two numbers which satisfy: $ab = n^2+2n+3 $ and $ a-b =2$ in order to telescope. Edit: I am very sorry on the denominator it should have been $n^2+n+4$ not $n^2+2n+4$ Similarly here : $$\sum\limits_{n=1}^{\infty}\arctan{\frac{8n}{n^4-2n^2+5}}$$ The result should be $ \arctan 2 $ on the first one and $ \pi/2 + \arctan2  $ on the second one.,We know that : for every I need to find two numbers which satisfy: and in order to telescope. Edit: I am very sorry on the denominator it should have been not Similarly here : The result should be on the first one and on the second one.,\sum\limits_{n=1}^{\infty}\arctan{\frac{2}{n^2+n+4}} \arctan{x} - \arctan{y} = \arctan{\frac{x-y}{1+xy}}  xy > 1  ab = n^2+2n+3   a-b =2 n^2+n+4 n^2+2n+4 \sum\limits_{n=1}^{\infty}\arctan{\frac{8n}{n^4-2n^2+5}}  \arctan 2   \pi/2 + \arctan2  ,"['calculus', 'sequences-and-series', 'trigonometry', 'telescopic-series']"
12,Why do two definitons of curvature give different answers?,Why do two definitons of curvature give different answers?,,"In section 13.4 problem 33 of Calculus third edition early transcedentals by Jon Rogawski and Colin Adams, it states Let $$s(t)=\int_{-\infty}^t\|r'(u)\| \ du$$ for Bernoulli spiral   $$r(t)= \langle e^t\cos(4t),e^t\sin(4t) \rangle$$ Show that the radius of curvature is   porportional to $s(t)$ Though my textbook states the curvature $k(t)$ is equal to $$\frac{\|T'(t)\|}{\|r'(t)\|}$$ which is also (for arbitrary regular parametrizations) $$\frac{\|r'(t) \times r''(t)\|}{\|r'(t)\|^3}$$ I get different answers applying both methods. Method one $$T(t)=\frac{r'(t)}{\|r'(t)\|}$$ $$r'(t)=\langle e^t\cos{\left(4t\right)}-4e^t\sin{\left(4t\right)}, e^t\sin(4t)+4e^t \cos(4t) \rangle$$ $$\|r'(t)\|=\sqrt{17}e^t$$ $$T(t)=\frac{1}{\sqrt{17}e^t}{\langle e^t\cos{\left(4t\right)}-4e^t\sin{\left(4t\right)}, e^t\sin(4t)+4e^t \cos(4t) \rangle}=\frac{1}{\sqrt{17}}{\langle \cos{\left(4t\right)}-4\sin{\left(4t\right)}, \sin(4t)+4 \cos(4t) \rangle}$$ $$T'(t)=\frac{1}{\sqrt{17}}{\langle -4\sin{\left(4t\right)}-16\cos{\left(4t\right)}, 4\cos(4t)-16 \sin(4t) \rangle}$$ $$\|T'(t)\|=\frac{1}{\sqrt{17}}\sqrt{16+256}=\frac{\sqrt{272}}{\sqrt{17}}=4$$ $$k(t)=\frac{\|T'(t)\|}{\|r'(t)\|}=\frac{4}{\sqrt{17}e^{2t}}$$ The eqution $s(t)$ is $$\int_{-\infty}^{t}\|r'(t)\| \ du=\int_{-\infty}^{t}\sqrt{17}e^t=\sqrt{17}e^t$$ Hence the ratio of $s(t)$ to the radius of curvature $k(t)$ is $$\frac{\sqrt{17}e^t}{4\sqrt{17}e^t}=1/4$$ Method Two In the second method we calculate $$\frac{\|r'(t) \times r''(t)\|}{\|r'(t)\|^3}$$ We already know $$\|r'(t)\|=\sqrt{17}e^t$$ $$\|r'(t)\|^3=17\sqrt{17}e^{3t}$$ Calcuating $$r''(t)$$, we get $$r''(t)=\langle -15e^t\cos(4t)-8e^t\sin(4t), -15e^t\sin(4t)+8e^t\cos(4t) \rangle $$ Hence $\|r'(t)\times r''(t)\|$ is equals to $$\sqrt{68}e^t=2\sqrt{17}e^{t}$$ Hence $$\frac{\|r'(t) \times r''(t)\|}{\|r'(t)\|^3}=\frac{2}{17 e^{2t}}$$ With this we know the ratio of $s(t)$ to radius of curvature is $$\frac{\sqrt{17}e^t}{\frac{2}{17} e^{2t}}=\frac{17\sqrt{17}}{2}e^t$$ Reasons for different answers One possibility is in the textbook. They state, ""In practice we compute the curvature using the following formula,   which is valid for abitrary regular paramterizations $$\frac{\|r'(t) \times r''(t)\|}{\|r'(t)\|^3}$$ However I'm not sure what ""arbitrary regular parmaterization"" means. How does this give us two different answers?","In section 13.4 problem 33 of Calculus third edition early transcedentals by Jon Rogawski and Colin Adams, it states Let $$s(t)=\int_{-\infty}^t\|r'(u)\| \ du$$ for Bernoulli spiral   $$r(t)= \langle e^t\cos(4t),e^t\sin(4t) \rangle$$ Show that the radius of curvature is   porportional to $s(t)$ Though my textbook states the curvature $k(t)$ is equal to $$\frac{\|T'(t)\|}{\|r'(t)\|}$$ which is also (for arbitrary regular parametrizations) $$\frac{\|r'(t) \times r''(t)\|}{\|r'(t)\|^3}$$ I get different answers applying both methods. Method one $$T(t)=\frac{r'(t)}{\|r'(t)\|}$$ $$r'(t)=\langle e^t\cos{\left(4t\right)}-4e^t\sin{\left(4t\right)}, e^t\sin(4t)+4e^t \cos(4t) \rangle$$ $$\|r'(t)\|=\sqrt{17}e^t$$ $$T(t)=\frac{1}{\sqrt{17}e^t}{\langle e^t\cos{\left(4t\right)}-4e^t\sin{\left(4t\right)}, e^t\sin(4t)+4e^t \cos(4t) \rangle}=\frac{1}{\sqrt{17}}{\langle \cos{\left(4t\right)}-4\sin{\left(4t\right)}, \sin(4t)+4 \cos(4t) \rangle}$$ $$T'(t)=\frac{1}{\sqrt{17}}{\langle -4\sin{\left(4t\right)}-16\cos{\left(4t\right)}, 4\cos(4t)-16 \sin(4t) \rangle}$$ $$\|T'(t)\|=\frac{1}{\sqrt{17}}\sqrt{16+256}=\frac{\sqrt{272}}{\sqrt{17}}=4$$ $$k(t)=\frac{\|T'(t)\|}{\|r'(t)\|}=\frac{4}{\sqrt{17}e^{2t}}$$ The eqution $s(t)$ is $$\int_{-\infty}^{t}\|r'(t)\| \ du=\int_{-\infty}^{t}\sqrt{17}e^t=\sqrt{17}e^t$$ Hence the ratio of $s(t)$ to the radius of curvature $k(t)$ is $$\frac{\sqrt{17}e^t}{4\sqrt{17}e^t}=1/4$$ Method Two In the second method we calculate $$\frac{\|r'(t) \times r''(t)\|}{\|r'(t)\|^3}$$ We already know $$\|r'(t)\|=\sqrt{17}e^t$$ $$\|r'(t)\|^3=17\sqrt{17}e^{3t}$$ Calcuating $$r''(t)$$, we get $$r''(t)=\langle -15e^t\cos(4t)-8e^t\sin(4t), -15e^t\sin(4t)+8e^t\cos(4t) \rangle $$ Hence $\|r'(t)\times r''(t)\|$ is equals to $$\sqrt{68}e^t=2\sqrt{17}e^{t}$$ Hence $$\frac{\|r'(t) \times r''(t)\|}{\|r'(t)\|^3}=\frac{2}{17 e^{2t}}$$ With this we know the ratio of $s(t)$ to radius of curvature is $$\frac{\sqrt{17}e^t}{\frac{2}{17} e^{2t}}=\frac{17\sqrt{17}}{2}e^t$$ Reasons for different answers One possibility is in the textbook. They state, ""In practice we compute the curvature using the following formula,   which is valid for abitrary regular paramterizations $$\frac{\|r'(t) \times r''(t)\|}{\|r'(t)\|^3}$$ However I'm not sure what ""arbitrary regular parmaterization"" means. How does this give us two different answers?",,"['calculus', 'algebra-precalculus', 'curvature']"
13,Why it is necessary to maximize and then minimize Lagrangian in hard margin SVM?,Why it is necessary to maximize and then minimize Lagrangian in hard margin SVM?,,"I was learning about support vector machines from Andrew Ng video lectures. I figured it out. I understand why we try to minimize $\frac{1}{2} w^2$. Margin (width) of the support vector is $2/\|w\|$. We want to maximize width it means that we also want to minimize $\|w\|$ from the equation $2/\|w\|$. It is true that we also want to minimize $\frac{1}{2}\|w\|^2$. Now we use Lagrange expression here, $$L = \frac{1}{2}\|w\|^2 + \sum_i α_i(y_i(w \bullet x+b)-1).$$ To find the minimum of $\frac{1}{2}\|w\|^2$, we apply gradient; $∇L = 0$. From the $∇L = 0$ equation, we get $Σ_iα_iy_i = 0$ and $w = Σ_iαi_iy_ix_i$. Then by using $Σ_iα_iy_i = 0$ and $w = Σ_iα_iy_ix_i$ equations and putting this in the Lagrange expression we end up with $$L(w,b,α) = \sum_iα_i-\frac{1}{2}\sum_{i,j}y_iy_jα_iα_j(x_i\bullet x_j).$$ I really understand up to here, but the professor said that we want to maximize  $L$ (w.r.t $α$) and at the same time minimize it w.r.t $w$ and $b$ here, so the final Lagrangian primal problem becomes $$min_{w,b}max_α L(w, b, α)$$ $$s.t.$$ $$α_i >= 0, i=1,2 ..., m$$ why?  I really don't understand. Why are we trying to maximize and then minimize the Lagrange expression ($L$)? Any intuitive explanation will help.","I was learning about support vector machines from Andrew Ng video lectures. I figured it out. I understand why we try to minimize $\frac{1}{2} w^2$. Margin (width) of the support vector is $2/\|w\|$. We want to maximize width it means that we also want to minimize $\|w\|$ from the equation $2/\|w\|$. It is true that we also want to minimize $\frac{1}{2}\|w\|^2$. Now we use Lagrange expression here, $$L = \frac{1}{2}\|w\|^2 + \sum_i α_i(y_i(w \bullet x+b)-1).$$ To find the minimum of $\frac{1}{2}\|w\|^2$, we apply gradient; $∇L = 0$. From the $∇L = 0$ equation, we get $Σ_iα_iy_i = 0$ and $w = Σ_iαi_iy_ix_i$. Then by using $Σ_iα_iy_i = 0$ and $w = Σ_iα_iy_ix_i$ equations and putting this in the Lagrange expression we end up with $$L(w,b,α) = \sum_iα_i-\frac{1}{2}\sum_{i,j}y_iy_jα_iα_j(x_i\bullet x_j).$$ I really understand up to here, but the professor said that we want to maximize  $L$ (w.r.t $α$) and at the same time minimize it w.r.t $w$ and $b$ here, so the final Lagrangian primal problem becomes $$min_{w,b}max_α L(w, b, α)$$ $$s.t.$$ $$α_i >= 0, i=1,2 ..., m$$ why?  I really don't understand. Why are we trying to maximize and then minimize the Lagrange expression ($L$)? Any intuitive explanation will help.",,"['calculus', 'convex-optimization', 'lagrange-multiplier', 'machine-learning']"
14,Prove function is not differentiable even though all directional derivatives exist and it is continuous.,Prove function is not differentiable even though all directional derivatives exist and it is continuous.,,"In the following link , the function below is provided as an example of a function being continuous and all directional derivatives existing. Yet, it is not differentiable. How do I prove that this is not differentiable? $$ f(x,y)=  \begin{cases}     \frac{y^3}{x^2+y^2},& \text{if } (x,y) \neq (0,0)\\     0,              & \text{otherwise} \end{cases} $$","In the following link , the function below is provided as an example of a function being continuous and all directional derivatives existing. Yet, it is not differentiable. How do I prove that this is not differentiable? $$ f(x,y)=  \begin{cases}     \frac{y^3}{x^2+y^2},& \text{if } (x,y) \neq (0,0)\\     0,              & \text{otherwise} \end{cases} $$",,"['calculus', 'limits', 'derivatives', 'continuity']"
15,"Justification behind the working of ""integration by substitution""","Justification behind the working of ""integration by substitution""",,"I am very confused about ""integration by substitution"". For example: We know that $\int\ x^2 dx$ = $x^3/3 +C$. Just for doing it, maybe for the sake of practicing, or for testing with integration by substitution, we could have made the substitution $x^2=u$. Then $x=u^{1/2}$ and $dx= (u^{-1/2}/2) du$. Consequently: $\int\ x^2 dx = \int\ u (u^{-1/2}/2) du = (1/2) \int\ u^{1/2} du = (1/3) u^{3/2} + C$ Since $u^{3/2} = x^{3}$, we see that we got the right answer. My question is, why did we get the right answer? This method look like magic to me, since I don't know the justification behind it. How do we prove that we can make the change of variable and change the $dx$ accordingly to obtain the right answer. ""Integration by parts"" is based on the product rule, for example. On what differentiation rule or rules is based integration by substitution? Is it the chain rule? By the way, I have no idea what I am doing. I just want to know the logic behind it. I have not see an explanation in the books I have searched. It seems to be introduced by examples, without justification. I am sorry if my question is bad, I am really confused right now.","I am very confused about ""integration by substitution"". For example: We know that $\int\ x^2 dx$ = $x^3/3 +C$. Just for doing it, maybe for the sake of practicing, or for testing with integration by substitution, we could have made the substitution $x^2=u$. Then $x=u^{1/2}$ and $dx= (u^{-1/2}/2) du$. Consequently: $\int\ x^2 dx = \int\ u (u^{-1/2}/2) du = (1/2) \int\ u^{1/2} du = (1/3) u^{3/2} + C$ Since $u^{3/2} = x^{3}$, we see that we got the right answer. My question is, why did we get the right answer? This method look like magic to me, since I don't know the justification behind it. How do we prove that we can make the change of variable and change the $dx$ accordingly to obtain the right answer. ""Integration by parts"" is based on the product rule, for example. On what differentiation rule or rules is based integration by substitution? Is it the chain rule? By the way, I have no idea what I am doing. I just want to know the logic behind it. I have not see an explanation in the books I have searched. It seems to be introduced by examples, without justification. I am sorry if my question is bad, I am really confused right now.",,"['calculus', 'integration']"
16,How to prove $\sqrt 2 x + \sqrt {2{x^2} + 2x + 1} + \sqrt {2{x^2} - 10x + 13} + \sqrt {2{x^2} - 22x + 73} \geq \sqrt{157}$?,How to prove ?,\sqrt 2 x + \sqrt {2{x^2} + 2x + 1} + \sqrt {2{x^2} - 10x + 13} + \sqrt {2{x^2} - 22x + 73} \geq \sqrt{157},"$$ \quad{\forall x\in \mathbb{R}:\\ \sqrt 2 x + \sqrt {2{x^2} + 2x + 1}  + \sqrt {2{x^2} - 10x + 13}  + \sqrt {2{x^2} - 22x + 73} \geq \sqrt{157}}$$ I want to prove this.I tried to graph it and see whats going on ... https://www.desmos.com/calculator/xgjovvkal6 I also tried to prove it by derivation ,but it become complicated . Can anybody give me an idea ? I am thankful in advance.","$$ \quad{\forall x\in \mathbb{R}:\\ \sqrt 2 x + \sqrt {2{x^2} + 2x + 1}  + \sqrt {2{x^2} - 10x + 13}  + \sqrt {2{x^2} - 22x + 73} \geq \sqrt{157}}$$ I want to prove this.I tried to graph it and see whats going on ... https://www.desmos.com/calculator/xgjovvkal6 I also tried to prove it by derivation ,but it become complicated . Can anybody give me an idea ? I am thankful in advance.",,"['calculus', 'algebra-precalculus', 'inequality', 'roots', 'radicals']"
17,"Evaluate double integral $\int_{-1}^1 \int_{-4|x|}^{|x|} e^{x+y} \, dy \, dx$ involving absolute values",Evaluate double integral  involving absolute values,"\int_{-1}^1 \int_{-4|x|}^{|x|} e^{x+y} \, dy \, dx","I have the following question on my assignment, and I have no idea how to take this integral. I tried using the online integral calculator , but it says the function is unintegratable (yet it spits out this number: $3.679137994987764$, which my homework says is wrong, and I don't understand how it got). However, my homework insists there is an answer. The problem is $$\int_{-1}^1 \int_{-4|x|}^{|x|} e^{x+y} \, dy \, dx.$$ I was able to do the internal integral, and get $$\int_{-1}^1 e^{x+|x|}-e^{x-4|x|} \, dx$$ However, I have no idea what to do from here. Do I split the integral up into two pieces (one from $-1$ to $0$, and the other from $0$ to one), and treat this problem in a similar manner to $\int|x| \,dx$? Edit: I tried solving it like Zain Patel's answer demonstrates, but the program isn't accepting his answer, nor the one I get. Breaking the integral up, we get: $$\int_{-1}^{0}e^{x-x}-e^{5x}dx+\int_{0}^{1}e^{x+x}-e^{-3x}dx$$ Taking the integral, I get the following, which is different than Zain's answer. $$x-\frac{1}{5}e^{5x}|_{-1}^{0}+\frac{1}{2}e^{2x}-\frac{1}{3}e^{-3x}|_{0}^{1}$$ Solving, I get $$\frac{-1}{30}+\frac{1}{5e^5}+\frac{e^2}{2}-\frac{1}{3e^3}$$ Does anyone see where a potential error is? Edit 2: Tony K pointed out that my last integral was incorrect. It should be positive, not negative. $$\frac{-1}{30}+\frac{1}{5e^5}+\frac{e^2}{2}+\frac{1}{3e^3}$$","I have the following question on my assignment, and I have no idea how to take this integral. I tried using the online integral calculator , but it says the function is unintegratable (yet it spits out this number: $3.679137994987764$, which my homework says is wrong, and I don't understand how it got). However, my homework insists there is an answer. The problem is $$\int_{-1}^1 \int_{-4|x|}^{|x|} e^{x+y} \, dy \, dx.$$ I was able to do the internal integral, and get $$\int_{-1}^1 e^{x+|x|}-e^{x-4|x|} \, dx$$ However, I have no idea what to do from here. Do I split the integral up into two pieces (one from $-1$ to $0$, and the other from $0$ to one), and treat this problem in a similar manner to $\int|x| \,dx$? Edit: I tried solving it like Zain Patel's answer demonstrates, but the program isn't accepting his answer, nor the one I get. Breaking the integral up, we get: $$\int_{-1}^{0}e^{x-x}-e^{5x}dx+\int_{0}^{1}e^{x+x}-e^{-3x}dx$$ Taking the integral, I get the following, which is different than Zain's answer. $$x-\frac{1}{5}e^{5x}|_{-1}^{0}+\frac{1}{2}e^{2x}-\frac{1}{3}e^{-3x}|_{0}^{1}$$ Solving, I get $$\frac{-1}{30}+\frac{1}{5e^5}+\frac{e^2}{2}-\frac{1}{3e^3}$$ Does anyone see where a potential error is? Edit 2: Tony K pointed out that my last integral was incorrect. It should be positive, not negative. $$\frac{-1}{30}+\frac{1}{5e^5}+\frac{e^2}{2}+\frac{1}{3e^3}$$",,"['calculus', 'integration', 'definite-integrals', 'absolute-value']"
18,Differentiate $\displaystyle y = a^{x ^{a^{x^\cdots}}}$. [closed],Differentiate . [closed],\displaystyle y = a^{x ^{a^{x^\cdots}}},"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Could anyone help with this question: Edit: Reducing it to one of these options would be great!","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Could anyone help with this question: Edit: Reducing it to one of these options would be great!",,"['calculus', 'derivatives', 'infinite-product']"
19,Evaluating $\sum_{n \geq 0} \frac{x^{8n}}{(8n)!}$ [duplicate],Evaluating  [duplicate],\sum_{n \geq 0} \frac{x^{8n}}{(8n)!},"This question already has answers here : Sum of $\sum \limits_{n=0}^{\infty} \frac{1}{(kn)!}$ (3 answers) Closed 7 years ago . $$\sum_{n \geq 0} \frac{x^{8n}}{(8n)!}$$ Here's my try: $$\sum_{n \geq 0, \text{even}} \frac{x^{4n}}{(4n)!}$$ $$=\sum_{n \geq 0} \frac{(-1)^n+1^n}{2} \frac{x^{4n}}{(4n)!}$$ By convergence I can split the sums. $$=\frac{1}{2} \sum_{n \geq 0} \frac{x^{4n}}{(4n)!}+\frac{1}{2} \sum_{n \geq 0} (-1)^n \frac{x^{4n}}{(4n)!}$$ Now consider, $$\sum_{n \geq 0} \frac{x^{4n}}{(4n)!}$$ $$=\sum_{n \geq 0, \text{even}} \frac{x^{2n}}{(2n)!}$$ $$=\sum_{n \geq 0} \frac{(-1)^n+1^n}{2} \frac{x^{2n}}{(2n)!}$$ $$=\frac{1}{2} \left( \cos(x)+\cosh (x) \right)$$ Now if I find, $$\sum_{n \geq 0} (-1)^n \frac{x^{4n}}{(4n)!}$$ I'll be done with the problem. How do I do that? Bonus question: Compute $$\sum_{n \geq 0} \frac{x^{3n}}{(3n)!}$$ For this one I'm out of ideas.","This question already has answers here : Sum of $\sum \limits_{n=0}^{\infty} \frac{1}{(kn)!}$ (3 answers) Closed 7 years ago . $$\sum_{n \geq 0} \frac{x^{8n}}{(8n)!}$$ Here's my try: $$\sum_{n \geq 0, \text{even}} \frac{x^{4n}}{(4n)!}$$ $$=\sum_{n \geq 0} \frac{(-1)^n+1^n}{2} \frac{x^{4n}}{(4n)!}$$ By convergence I can split the sums. $$=\frac{1}{2} \sum_{n \geq 0} \frac{x^{4n}}{(4n)!}+\frac{1}{2} \sum_{n \geq 0} (-1)^n \frac{x^{4n}}{(4n)!}$$ Now consider, $$\sum_{n \geq 0} \frac{x^{4n}}{(4n)!}$$ $$=\sum_{n \geq 0, \text{even}} \frac{x^{2n}}{(2n)!}$$ $$=\sum_{n \geq 0} \frac{(-1)^n+1^n}{2} \frac{x^{2n}}{(2n)!}$$ $$=\frac{1}{2} \left( \cos(x)+\cosh (x) \right)$$ Now if I find, $$\sum_{n \geq 0} (-1)^n \frac{x^{4n}}{(4n)!}$$ I'll be done with the problem. How do I do that? Bonus question: Compute $$\sum_{n \geq 0} \frac{x^{3n}}{(3n)!}$$ For this one I'm out of ideas.",,"['calculus', 'algebra-precalculus', 'taylor-expansion']"
20,"Is there a general formula for $I(m,n)$? [duplicate]",Is there a general formula for ? [duplicate],"I(m,n)","This question already has answers here : Closed form for $ \int_0^\infty {\frac{{{x^n}}}{{1 + {x^m}}}dx }$ (11 answers) Closed 7 years ago . Consider the integral $$I(m,n):=\int_0^{\infty} \frac{x^m}{x^n+1}\,\mathrm dx$$ For $m=0$, a general formula is $$I(0,n)=\frac{\frac{\pi}{n}}{\sin\left(\frac{\pi}{n}\right)}$$ Some other values are $$I(1,3)=\frac{2\pi}{3\sqrt{3}}$$ $$I(1,4)=\frac{\pi}{4}$$ $$I(2,4)=\frac{\pi}{2\sqrt{2}}$$ For natural $m,n$ the integral exists if and only if $n\ge m+2$. Is there a general formula for $I(m,n)$ with integers $m,n$ and $0\le m\le n-2$ ?","This question already has answers here : Closed form for $ \int_0^\infty {\frac{{{x^n}}}{{1 + {x^m}}}dx }$ (11 answers) Closed 7 years ago . Consider the integral $$I(m,n):=\int_0^{\infty} \frac{x^m}{x^n+1}\,\mathrm dx$$ For $m=0$, a general formula is $$I(0,n)=\frac{\frac{\pi}{n}}{\sin\left(\frac{\pi}{n}\right)}$$ Some other values are $$I(1,3)=\frac{2\pi}{3\sqrt{3}}$$ $$I(1,4)=\frac{\pi}{4}$$ $$I(2,4)=\frac{\pi}{2\sqrt{2}}$$ For natural $m,n$ the integral exists if and only if $n\ge m+2$. Is there a general formula for $I(m,n)$ with integers $m,n$ and $0\le m\le n-2$ ?",,"['calculus', 'integration', 'definite-integrals', 'closed-form']"
21,Inverse of cosh(x),Inverse of cosh(x),,"My goal is to find the inverse of $y=\cosh(x)$ Therefore: $$x=\cosh(y)=\frac{e^y+e^{-y}}{2}=\frac{e^{2y}+1}{2e^y}$$ If we define $k=e^y$ then: $$k^2-2xk+1=0$$ $$k=e^{y}=x\pm\sqrt{x^2-1}$$ $$y=\ln(x\pm\sqrt{x^2-1})=\cosh^{-1}(x)$$ However, apparently: $\cosh^{-1}(x)=\ln(x+\sqrt{x^2-1})$ is right, but NOT $\cosh^{-1}(x)=\ln(x-\sqrt{x^2-1})$ What step did I miss?","My goal is to find the inverse of $y=\cosh(x)$ Therefore: $$x=\cosh(y)=\frac{e^y+e^{-y}}{2}=\frac{e^{2y}+1}{2e^y}$$ If we define $k=e^y$ then: $$k^2-2xk+1=0$$ $$k=e^{y}=x\pm\sqrt{x^2-1}$$ $$y=\ln(x\pm\sqrt{x^2-1})=\cosh^{-1}(x)$$ However, apparently: $\cosh^{-1}(x)=\ln(x+\sqrt{x^2-1})$ is right, but NOT $\cosh^{-1}(x)=\ln(x-\sqrt{x^2-1})$ What step did I miss?",,"['calculus', 'inverse', 'hyperbolic-functions', 'inverse-function']"
22,If $\int_{0}^{\frac{\pi}{4}}\tan^6(x) \sec(x) dx = I$ then express $\int_{0}^{\frac{\pi}{4}} \tan^8(x) \sec(x) dx$ in terms of $I$,If  then express  in terms of,\int_{0}^{\frac{\pi}{4}}\tan^6(x) \sec(x) dx = I \int_{0}^{\frac{\pi}{4}} \tan^8(x) \sec(x) dx I,how can I proceed with this exercise? If $$\int_{0}^{\frac{\pi}{4}} \tan^6(x) \sec(x) dx = I$$ then express $$\int_{0}^{\frac{\pi}{4}} \tan^8(x) \sec(x) dx$$ in terms of $I$. What I've got so far: $$\int_{0}^{\frac{\pi}{4}} \tan^8(x) \sec(x) dx = \int_{0}^{\frac{\pi}{4}} \tan^2(x) \tan^6(x) \sec(x) dx = \int_{0}^{\frac{\pi}{4}} \left( \sec^2(x) - 1 \right) \tan^6(x) \sec(x) dx = \\ = - \int_{0}^{\frac{\pi}{4}} \tan^6(x) \sec(x) dx + \int_{0}^{\frac{\pi}{4}} \tan^6(x) \sec^3(x) dx = -I + \cdots$$ Any help is highly appreciated. $\\$ (Exercise 50 from Stewart's Calculus book section chapter 7.2 7th edition),how can I proceed with this exercise? If $$\int_{0}^{\frac{\pi}{4}} \tan^6(x) \sec(x) dx = I$$ then express $$\int_{0}^{\frac{\pi}{4}} \tan^8(x) \sec(x) dx$$ in terms of $I$. What I've got so far: $$\int_{0}^{\frac{\pi}{4}} \tan^8(x) \sec(x) dx = \int_{0}^{\frac{\pi}{4}} \tan^2(x) \tan^6(x) \sec(x) dx = \int_{0}^{\frac{\pi}{4}} \left( \sec^2(x) - 1 \right) \tan^6(x) \sec(x) dx = \\ = - \int_{0}^{\frac{\pi}{4}} \tan^6(x) \sec(x) dx + \int_{0}^{\frac{\pi}{4}} \tan^6(x) \sec^3(x) dx = -I + \cdots$$ Any help is highly appreciated. $\\$ (Exercise 50 from Stewart's Calculus book section chapter 7.2 7th edition),,"['calculus', 'integration', 'trigonometry']"
23,Why don't we start studying calculus via series instead of the calculus on finite expressions?,Why don't we start studying calculus via series instead of the calculus on finite expressions?,,"It seems that historically, there were two trends on the idea of integration: Newton's work which depended on infinite series. Leibniz work which depended on the dream of integration of elementary functions in a finite combination of basic functions which was later proved to be impossible by Liouville. I'll call it ""calculus on finite expressions"" . I took a course of calculus and it seems that integration via Leibniz way becomes increasingly complicated as the course progress. I didn't have a course on series yet but it seems that most of the functions can be represented as infinite power series and the integration on power series (integrating term by term) is often an easier task. Until now, I guess I had more evidence that calculus on series is way more simpler and powerful than the calculus on finite expressions. My doubts are: Is this correct? Why don't we start studying calculus via series instead of the calculus on finite expressions? Most of the books authors seem to think different about this matter because of their choice of order in the subjects. But Kuratowski's: Introduction to Calculus starts already with sequences and series, so I guess that perhaps that claim could be true. Although there is also another hypothesis: He could be lecturing in an educational system in which the calculus of finite expressions was taught early in high-school.","It seems that historically, there were two trends on the idea of integration: Newton's work which depended on infinite series. Leibniz work which depended on the dream of integration of elementary functions in a finite combination of basic functions which was later proved to be impossible by Liouville. I'll call it ""calculus on finite expressions"" . I took a course of calculus and it seems that integration via Leibniz way becomes increasingly complicated as the course progress. I didn't have a course on series yet but it seems that most of the functions can be represented as infinite power series and the integration on power series (integrating term by term) is often an easier task. Until now, I guess I had more evidence that calculus on series is way more simpler and powerful than the calculus on finite expressions. My doubts are: Is this correct? Why don't we start studying calculus via series instead of the calculus on finite expressions? Most of the books authors seem to think different about this matter because of their choice of order in the subjects. But Kuratowski's: Introduction to Calculus starts already with sequences and series, so I guess that perhaps that claim could be true. Although there is also another hypothesis: He could be lecturing in an educational system in which the calculus of finite expressions was taught early in high-school.",,"['calculus', 'sequences-and-series', 'analysis', 'education']"
24,"Find the product, if we know 5 of them","Find the product, if we know 5 of them",,"We have 4 positive,but not necessarily integers $a, b, c,$ and $d$. So we have 6 options how multiply two of them. And we know 5 of 6 products $2, 3, 4, 5$ and $6$. Find the last product.","We have 4 positive,but not necessarily integers $a, b, c,$ and $d$. So we have 6 options how multiply two of them. And we know 5 of 6 products $2, 3, 4, 5$ and $6$. Find the last product.",,"['calculus', 'combinatorics']"
25,Integrate $\int \sqrt{\frac{x}{x+1}}dx$,Integrate,\int \sqrt{\frac{x}{x+1}}dx,"In order to integrate $$\int \sqrt{\frac{x}{x+1}}dx$$ I did $$x = \tan^2\theta $$ $$\int \sqrt{\frac{x}{x+1}}dx = \int\sqrt{\frac{\tan^2(\theta)}{\tan^2(\theta)+1}} \ 2\tan(\theta)\sec^2(\theta)d\theta \\= \int \frac{|\tan(\theta)|}{|\sec^2(\theta)|}2\tan(\theta)\sec^2(\theta)d\theta = \int \tan^3\theta d\theta = \int\frac{\sin^3 \theta}{\cos^3 \theta}d\theta$$ $$p = \cos\theta \implies dp = -\sin\theta d\theta$$ $$\int\frac{\sin^3 \theta}{\cos^3 \theta}d\theta = -\int\frac{(1-p^2)(-\sin\theta)}{p^3 }d\theta \\= -\int \frac{1-p^2}{p^3}dp = -\int \frac{1}{p^3}dp +\int \frac{1}{p}dp \\= -\frac{p^{-2}}{-2}+\ln|p| = -\frac{(\cos\theta)^{-2}}{-2}+\ln|\cos\theta|$$ $$x = \tan^2\theta \implies \tan\theta= \sqrt{x}\implies \theta = \arctan\sqrt{x}$$ $$= -\frac{(\cos\arctan\sqrt{x})^{-2}}{-2}+\ln|\cos\arctan\sqrt{x}|$$ But the result seems a little bit different from wolfram alpha. I Know there may be easier ways to solve this integral. But my question is about this method I choose specifically. Is the answer correct? Also, if it is, is there a way to reduce $\cos\arctan()$ to something simpler?","In order to integrate I did But the result seems a little bit different from wolfram alpha. I Know there may be easier ways to solve this integral. But my question is about this method I choose specifically. Is the answer correct? Also, if it is, is there a way to reduce to something simpler?",\int \sqrt{\frac{x}{x+1}}dx x = \tan^2\theta  \int \sqrt{\frac{x}{x+1}}dx = \int\sqrt{\frac{\tan^2(\theta)}{\tan^2(\theta)+1}} \ 2\tan(\theta)\sec^2(\theta)d\theta \\= \int \frac{|\tan(\theta)|}{|\sec^2(\theta)|}2\tan(\theta)\sec^2(\theta)d\theta = \int \tan^3\theta d\theta = \int\frac{\sin^3 \theta}{\cos^3 \theta}d\theta p = \cos\theta \implies dp = -\sin\theta d\theta \int\frac{\sin^3 \theta}{\cos^3 \theta}d\theta = -\int\frac{(1-p^2)(-\sin\theta)}{p^3 }d\theta \\= -\int \frac{1-p^2}{p^3}dp = -\int \frac{1}{p^3}dp +\int \frac{1}{p}dp \\= -\frac{p^{-2}}{-2}+\ln|p| = -\frac{(\cos\theta)^{-2}}{-2}+\ln|\cos\theta| x = \tan^2\theta \implies \tan\theta= \sqrt{x}\implies \theta = \arctan\sqrt{x} = -\frac{(\cos\arctan\sqrt{x})^{-2}}{-2}+\ln|\cos\arctan\sqrt{x}| \cos\arctan(),"['calculus', 'integration', 'indefinite-integrals']"
26,Why is the derivative of $x^2$ not $2x+1$?,Why is the derivative of  not ?,x^2 2x+1,"If the derivative is the change of the function at each step, it could be expressed as: $$f(x)+f'(x)=f(x+1)$$ Therefore if $f(x)=c$ $$c+f'(x)=c \implies f'(x)=0$$ This is also correct for $f(x)=cx$ $$cx+f'(x)=c(x+1) \implies f'(x)=c$$ However, it doesn't work for $f(x)=x^2$ $$x^2+f'(x)=(x+1)^2=x^2+2x+1 \implies f'(x)=2x+1$$ Where am I wrong in my reasoning?","If the derivative is the change of the function at each step, it could be expressed as: $$f(x)+f'(x)=f(x+1)$$ Therefore if $f(x)=c$ $$c+f'(x)=c \implies f'(x)=0$$ This is also correct for $f(x)=cx$ $$cx+f'(x)=c(x+1) \implies f'(x)=c$$ However, it doesn't work for $f(x)=x^2$ $$x^2+f'(x)=(x+1)^2=x^2+2x+1 \implies f'(x)=2x+1$$ Where am I wrong in my reasoning?",,"['calculus', 'derivatives']"
27,"How to find the derivative of a function defined by an integral? Namely, $f(y)=\int_0^{y^2} e^{-x^2y^2}dx$","How to find the derivative of a function defined by an integral? Namely,",f(y)=\int_0^{y^2} e^{-x^2y^2}dx,Find at each point of its domain the derivative of the function $f: \mathbb{R} \rightarrow \mathbb{R}$ $$f(y)=\int_0^{y^2} e^{-x^2y^2}dx$$ $$$$ Is the domain of the function $\mathbb{R}$ because of the exponential? Do I have to set $f(y)=h(y^2)$ and then use  $$\frac{d h(y^2)}{dy}=\frac{d h(y^2)}{dy^2} \cdot \frac{dy^2}{dy}$$ Or is there an other way to find the derivative?,Find at each point of its domain the derivative of the function $f: \mathbb{R} \rightarrow \mathbb{R}$ $$f(y)=\int_0^{y^2} e^{-x^2y^2}dx$$ $$$$ Is the domain of the function $\mathbb{R}$ because of the exponential? Do I have to set $f(y)=h(y^2)$ and then use  $$\frac{d h(y^2)}{dy}=\frac{d h(y^2)}{dy^2} \cdot \frac{dy^2}{dy}$$ Or is there an other way to find the derivative?,,"['calculus', 'integration', 'derivatives']"
28,Integration of $\int_{0}^{\frac{1}{2}}\frac{\sin^{-1}(x)}{\sqrt{1-x^2}} dx$ ??,Integration of  ??,\int_{0}^{\frac{1}{2}}\frac{\sin^{-1}(x)}{\sqrt{1-x^2}} dx,"I was solving the integration of inverse trigonometric function and faced a question which i find it hard to understand. I need to find the definite integration of this function. $$\int_{0}^{\frac{1}{2}}\frac{\sin^{-1}(x)}{\sqrt{1-x^2}} dx$$ I tried to use the substitutional method by $$u= \sin^{-1}(x)$$ and getting $\dfrac{du}{dx}= \dfrac{1}{\sqrt{1-x^2}}$ and $dx= du(\sqrt{1-x^2})$ but when i substitute that into the function, it does not make any sense. This is where i got stuck  (not even sure if i did in the right way or not..) am i doing it right? Should I use another method to approach to the answer? (Sorry if this question is duplicating, i could not find an appropriate answer..)","I was solving the integration of inverse trigonometric function and faced a question which i find it hard to understand. I need to find the definite integration of this function. $$\int_{0}^{\frac{1}{2}}\frac{\sin^{-1}(x)}{\sqrt{1-x^2}} dx$$ I tried to use the substitutional method by $$u= \sin^{-1}(x)$$ and getting $\dfrac{du}{dx}= \dfrac{1}{\sqrt{1-x^2}}$ and $dx= du(\sqrt{1-x^2})$ but when i substitute that into the function, it does not make any sense. This is where i got stuck  (not even sure if i did in the right way or not..) am i doing it right? Should I use another method to approach to the answer? (Sorry if this question is duplicating, i could not find an appropriate answer..)",,"['calculus', 'integration', 'trigonometry', 'definite-integrals']"
29,LogSine Integral $\int_0^{\pi/3}\ln^n\big(2\sin\frac{\theta}{2}\big)\mathrm d\theta$,LogSine Integral,\int_0^{\pi/3}\ln^n\big(2\sin\frac{\theta}{2}\big)\mathrm d\theta,"I am trying to integrate a special case of the log sine integral $\rm{Ls}_n(\sigma)$ at $\sigma=\pi/3$ : $$ \rm{Ls}_{n}\big(\tfrac{\pi}{3}\big)=-\int_0^{\pi/3}\bigg[\ln\big(2\sin\tfrac{\theta}{2}\big)\bigg]^{n-1}\mathrm d\theta $$ where $n$ is a non-negative integer. This problem is strongly related to the hypergeometric form of the Log Sine integral. The closed form is rather simple, although I am having trouble computing it. We can use standard log rules on the inside expression, although I am not sure how this will help us...Thanks","I am trying to integrate a special case of the log sine integral at : where is a non-negative integer. This problem is strongly related to the hypergeometric form of the Log Sine integral. The closed form is rather simple, although I am having trouble computing it. We can use standard log rules on the inside expression, although I am not sure how this will help us...Thanks","\rm{Ls}_n(\sigma) \sigma=\pi/3 
\rm{Ls}_{n}\big(\tfrac{\pi}{3}\big)=-\int_0^{\pi/3}\bigg[\ln\big(2\sin\tfrac{\theta}{2}\big)\bigg]^{n-1}\mathrm d\theta
 n","['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'contour-integration']"
30,Find $\int \limits_0^\pi \sin(\sin(x))\sin(x)\mathrm dx$,Find,\int \limits_0^\pi \sin(\sin(x))\sin(x)\mathrm dx,Compute $\displaystyle \int \limits_0^\pi \sin(\sin(x))\sin(x)\mathrm dx$. I have no idea how to integrate of this. I do need some help. Thanks,Compute $\displaystyle \int \limits_0^\pi \sin(\sin(x))\sin(x)\mathrm dx$. I have no idea how to integrate of this. I do need some help. Thanks,,"['calculus', 'integration', 'definite-integrals']"
31,"What is the difference between ""differentiable"" and ""continuous""","What is the difference between ""differentiable"" and ""continuous""",,"I have always treated them as the same thing. But recently, some people have told me that the two terms are different. So now I am wondering, What is the difference between ""differentiable"" and ""continuous""? I just don't want to say the wrong thing. For example, I don't want to say, ""$\frac{x^2}{x^4-2x^3}$ is not differentiable at $x=0$"" when really, it should be ""discontinuous"". Please help","I have always treated them as the same thing. But recently, some people have told me that the two terms are different. So now I am wondering, What is the difference between ""differentiable"" and ""continuous""? I just don't want to say the wrong thing. For example, I don't want to say, ""$\frac{x^2}{x^4-2x^3}$ is not differentiable at $x=0$"" when really, it should be ""discontinuous"". Please help",,"['calculus', 'derivatives', 'continuity']"
32,Help with Spivak Calculus Ch3 Problem 6a,Help with Spivak Calculus Ch3 Problem 6a,,"Yet again I find myself stuck on a Spivak question. This time it is simply the question that isn't clear to me. It states: If $x_1, ..., x_n$ are distinct numbers, find a polynomial function $f_i$, of degree $n-1$ which is 1 at $x_i$ and 0 at $x_j$ for $j\neq i$. Hint: the product of all $(x-x_j)$ for $j\neq i$, is 0 at $x_j$ if $j\neq i$. This product is usually denoted by: $$\prod_{\begin{smallmatrix}{j=1}\\ {j\neq i} \end{smallmatrix}}^n(x-x_j)$$ To be honest I don't know where to begin. I understand how to create a polynomial equation for a given set of results but this is quite strange. I'm not sure exactly what the author is expecting. The answer book shows: $$f_i(x)={\prod_{\begin{smallmatrix}{j=1}\\ {j\neq i} \end{smallmatrix}}^n(x-x_j)}/{\prod_{\begin{smallmatrix}{j=1}\\ {j\neq i} \end{smallmatrix}}^n(x_i-x_j)}$$ Which I have expanded out just fine but don't know what to do with.","Yet again I find myself stuck on a Spivak question. This time it is simply the question that isn't clear to me. It states: If $x_1, ..., x_n$ are distinct numbers, find a polynomial function $f_i$, of degree $n-1$ which is 1 at $x_i$ and 0 at $x_j$ for $j\neq i$. Hint: the product of all $(x-x_j)$ for $j\neq i$, is 0 at $x_j$ if $j\neq i$. This product is usually denoted by: $$\prod_{\begin{smallmatrix}{j=1}\\ {j\neq i} \end{smallmatrix}}^n(x-x_j)$$ To be honest I don't know where to begin. I understand how to create a polynomial equation for a given set of results but this is quite strange. I'm not sure exactly what the author is expecting. The answer book shows: $$f_i(x)={\prod_{\begin{smallmatrix}{j=1}\\ {j\neq i} \end{smallmatrix}}^n(x-x_j)}/{\prod_{\begin{smallmatrix}{j=1}\\ {j\neq i} \end{smallmatrix}}^n(x_i-x_j)}$$ Which I have expanded out just fine but don't know what to do with.",,"['calculus', 'polynomials']"
33,"Does the integral $\int_{1}^{\infty} \sin(x\log x) \,\mathrm{d}x$ converge?",Does the integral  converge?,"\int_{1}^{\infty} \sin(x\log x) \,\mathrm{d}x",I tried a couple of substitutions but have so far gotten nowhere. Can anyone guide me in the right direction? Thanks for your time.,I tried a couple of substitutions but have so far gotten nowhere. Can anyone guide me in the right direction? Thanks for your time.,,['calculus']
34,Show that $f(x)=x^2$ is continuous at $a=2$ using the $\delta-\epsilon$ definition of continuity.,Show that  is continuous at  using the  definition of continuity.,f(x)=x^2 a=2 \delta-\epsilon,"So we want to find a $\delta>0$   such that for all $2-\delta<x<2+\delta$  , we will have $4-\epsilon<x^{2}<4+\epsilon$ for all $\epsilon>0$  . If we can find a way to express $\delta$  as a function $\delta (\epsilon)$,  $\delta:\mathbb{R}_+ \to \mathbb{R}_+ $ then we will have solved the problem. But I can't see how to relate $\epsilon$ to $\delta$ in this case. My initial reaction is write $(2-\delta)^2<x^2<(2+\delta)^2$, this makes the two inequalities look related, but I am not sure where to go from here.","So we want to find a $\delta>0$   such that for all $2-\delta<x<2+\delta$  , we will have $4-\epsilon<x^{2}<4+\epsilon$ for all $\epsilon>0$  . If we can find a way to express $\delta$  as a function $\delta (\epsilon)$,  $\delta:\mathbb{R}_+ \to \mathbb{R}_+ $ then we will have solved the problem. But I can't see how to relate $\epsilon$ to $\delta$ in this case. My initial reaction is write $(2-\delta)^2<x^2<(2+\delta)^2$, this makes the two inequalities look related, but I am not sure where to go from here.",,"['calculus', 'continuity', 'epsilon-delta']"
35,Integration by parts: $\int xe^{-x}dx$,Integration by parts:,\int xe^{-x}dx,"This is a pretty straight forward integral to me, but I don't understand how my teacher got the answer: $$(-xe^{-x})-e^{-x}+C$$ Here is the original problem: $$\int xe^{-x}dx$$ Here are my steps to solve it: $$u=x$$ $$du=dx$$ $$dv=e^{-x}dx$$ $$v=-e^{-x}$$ So rewriting the problem I get: $$(-xe^{-x})- \int -e^{-x}dx$$ Solving the above integral I get (I factored out the negative one to get a positive $e^{-x}$): $$(-xe^{-x})+e^{-x}+C$$ Did I solve this incorrectly?","This is a pretty straight forward integral to me, but I don't understand how my teacher got the answer: $$(-xe^{-x})-e^{-x}+C$$ Here is the original problem: $$\int xe^{-x}dx$$ Here are my steps to solve it: $$u=x$$ $$du=dx$$ $$dv=e^{-x}dx$$ $$v=-e^{-x}$$ So rewriting the problem I get: $$(-xe^{-x})- \int -e^{-x}dx$$ Solving the above integral I get (I factored out the negative one to get a positive $e^{-x}$): $$(-xe^{-x})+e^{-x}+C$$ Did I solve this incorrectly?",,"['calculus', 'integration']"
36,Approximate the integral $\int_0^\pi \sin(x^3)\mathrm{d}x$ with a standard pocket calculator,Approximate the integral  with a standard pocket calculator,\int_0^\pi \sin(x^3)\mathrm{d}x,"I came over the following integral $$   \int_0^\pi \sin(x^3) \mathrm{d}x $$ when a friend of mine tried to approximate it. The most obvious way is to use Taylor's formula, and then turn the integral into a sum. Eg $$ \int_0^\pi \sin(x^3) \mathrm{d}x \approx \sum_{k=0}^N \frac{1}{2} \frac{(-1)^k \pi^{3k+2}}{(3k+2)(2k+1)!} $$ The problem is the nominator increases much more rapidly than the denominator for the first 30 terms or so. Much faster than what a standard calculator can deal with. This can be seen here https://i.sstatic.net/O8aX0.jpg By using the midpoint rule instead, the sum turns into $$    \int_0^\pi \sin(x^3) \mathrm{d}x \approx \frac{\pi}{2}\sum_{k=0}^N f\left( \frac{\pi}{2} \frac{2k-1}{N}\right) $$ Which converges to two decimal places in $36$ iterations, however to obtain a higher accuracy the convergence is slower than the Taylor series. As a final note I also tried using the substitution $u \mapsto u^3$ , but the series expansion did not improve. My question is as follows: What is the least terms needed to approximate the integral to $3$ digits accuracy under the restrictions of using a standard pocket calculator? To clearify the calculator does not have more than 8 digits accuracy, and can use sine and cosine. Oh, I also tried Simpsons that did not improve the convergence. Could Romberg, or Gaussian lead to faster convergence?","I came over the following integral when a friend of mine tried to approximate it. The most obvious way is to use Taylor's formula, and then turn the integral into a sum. Eg The problem is the nominator increases much more rapidly than the denominator for the first 30 terms or so. Much faster than what a standard calculator can deal with. This can be seen here https://i.sstatic.net/O8aX0.jpg By using the midpoint rule instead, the sum turns into Which converges to two decimal places in iterations, however to obtain a higher accuracy the convergence is slower than the Taylor series. As a final note I also tried using the substitution , but the series expansion did not improve. My question is as follows: What is the least terms needed to approximate the integral to digits accuracy under the restrictions of using a standard pocket calculator? To clearify the calculator does not have more than 8 digits accuracy, and can use sine and cosine. Oh, I also tried Simpsons that did not improve the convergence. Could Romberg, or Gaussian lead to faster convergence?","
  \int_0^\pi \sin(x^3) \mathrm{d}x
 
\int_0^\pi \sin(x^3) \mathrm{d}x \approx \sum_{k=0}^N \frac{1}{2} \frac{(-1)^k \pi^{3k+2}}{(3k+2)(2k+1)!}
 
   \int_0^\pi \sin(x^3) \mathrm{d}x \approx \frac{\pi}{2}\sum_{k=0}^N f\left( \frac{\pi}{2} \frac{2k-1}{N}\right)
 36 u \mapsto u^3 3","['calculus', 'integration', 'definite-integrals', 'approximation']"
37,Help to understand proof to show that a function is uniformly continous in a certain interval (Spivak),Help to understand proof to show that a function is uniformly continous in a certain interval (Spivak),,"This excerpt relates to the following proof: If $f$ is continous on $[a,b]$, then $f$ is uniformly continuous $[a,b]$. For $\epsilon > 0$ let's say that $f$ is $\epsilon$-good on $[a,b]$ if there is some $\delta > 0$ such that, for all $y$ and $z$ in $[a,b]$, if $|y-z|<\delta$ , then $|f(x)-f(z)|<\epsilon$ Consider any $\epsilon > 0$. Let $A=\{x:a\leq x \leq b$ and $f$ is $\epsilon$-good on $[a,x]\}$ Then, the proof went on to show that $A$ has a least upper bound, $\alpha$ and that $\alpha=b$. Here's the part I don't understand: ... So $f$ is surely $\epsilon$-good on the interval $[\alpha - \delta_0, \alpha + \delta_0]$. On the other hand, since $\alpha$ is the least upper bound of $A$, it is also clear that $f$ is $\epsilon$-good on $[a, \alpha- \delta_0]$. I don't understand how we can conclude that $f$ is $\epsilon$-good $[a, \alpha- \delta_0]$ just from knowing that $\alpha$ is the least upper bound of $A$. How do we know that $f$ is $\epsilon$-good for each number in the interval from $a$ up to and including $\alpha-\delta_0$? Here's my understanding of the proof: Suppose $a=1$ and 5 is the least upper bound of $A$. Then, just by knowing that $f$ is $\epsilon$-good on $[5-\delta_0,5+\delta_0]$ we can conclude that $f$ is $\epsilon$-good on the intervals $[a,2],[a,3]$ all the way to $[a, 5-\delta_0]$. I feel like I am missing some property of the least upper bound that is preventing me from understanding this proof. The proof also claims that $f$ is $\epsilon$-good on $[a, b - \delta_0]$ which I also don't understand but I guess the explanation would be similar to $f$ being $\epsilon$-good on $[a,\alpha-\delta_0]$. Thank you in advance for any help provided.","This excerpt relates to the following proof: If $f$ is continous on $[a,b]$, then $f$ is uniformly continuous $[a,b]$. For $\epsilon > 0$ let's say that $f$ is $\epsilon$-good on $[a,b]$ if there is some $\delta > 0$ such that, for all $y$ and $z$ in $[a,b]$, if $|y-z|<\delta$ , then $|f(x)-f(z)|<\epsilon$ Consider any $\epsilon > 0$. Let $A=\{x:a\leq x \leq b$ and $f$ is $\epsilon$-good on $[a,x]\}$ Then, the proof went on to show that $A$ has a least upper bound, $\alpha$ and that $\alpha=b$. Here's the part I don't understand: ... So $f$ is surely $\epsilon$-good on the interval $[\alpha - \delta_0, \alpha + \delta_0]$. On the other hand, since $\alpha$ is the least upper bound of $A$, it is also clear that $f$ is $\epsilon$-good on $[a, \alpha- \delta_0]$. I don't understand how we can conclude that $f$ is $\epsilon$-good $[a, \alpha- \delta_0]$ just from knowing that $\alpha$ is the least upper bound of $A$. How do we know that $f$ is $\epsilon$-good for each number in the interval from $a$ up to and including $\alpha-\delta_0$? Here's my understanding of the proof: Suppose $a=1$ and 5 is the least upper bound of $A$. Then, just by knowing that $f$ is $\epsilon$-good on $[5-\delta_0,5+\delta_0]$ we can conclude that $f$ is $\epsilon$-good on the intervals $[a,2],[a,3]$ all the way to $[a, 5-\delta_0]$. I feel like I am missing some property of the least upper bound that is preventing me from understanding this proof. The proof also claims that $f$ is $\epsilon$-good on $[a, b - \delta_0]$ which I also don't understand but I guess the explanation would be similar to $f$ being $\epsilon$-good on $[a,\alpha-\delta_0]$. Thank you in advance for any help provided.",,"['calculus', 'algebra-precalculus']"
38,Calculating an improper integral as a limit of a sum.,Calculating an improper integral as a limit of a sum.,,"This question arose from a solution I saw yesterday: Suppose f is continuous on (0,1] and has an infinite discontinuity at 0. If the improper integral $\int_0^1 f(x) dx$ converges, is it always the case that: $$\int_0^1 f(x) dx = \displaystyle\lim_{n\to\infty}\sum_{i=1}^{n}f\left(\frac{i}{n}\right)\frac{1}{n}$$ and, if so, how does one justify this equality?","This question arose from a solution I saw yesterday: Suppose f is continuous on (0,1] and has an infinite discontinuity at 0. If the improper integral $\int_0^1 f(x) dx$ converges, is it always the case that: $$\int_0^1 f(x) dx = \displaystyle\lim_{n\to\infty}\sum_{i=1}^{n}f\left(\frac{i}{n}\right)\frac{1}{n}$$ and, if so, how does one justify this equality?",,['calculus']
39,Two questions about Euler's number $e$,Two questions about Euler's number,e,"I am on derivatives at the moment and I just bumped into this number $e$, ""Euler's number"" . I am told that this number is special especially when I take the derivative of $e^x$ , because its slope of any point is 1. Also it is an irrational ($2.71828\ldots$) number that never ends, like $\pi$. So I have two questions, I can't understand What is so special about this fact that it's slope is always 1? Where do we humans use this number that is so useful, how did Mr Euler come up with this number? and how come this number is a constant? where can we find this number in nature?","I am on derivatives at the moment and I just bumped into this number $e$, ""Euler's number"" . I am told that this number is special especially when I take the derivative of $e^x$ , because its slope of any point is 1. Also it is an irrational ($2.71828\ldots$) number that never ends, like $\pi$. So I have two questions, I can't understand What is so special about this fact that it's slope is always 1? Where do we humans use this number that is so useful, how did Mr Euler come up with this number? and how come this number is a constant? where can we find this number in nature?",,"['calculus', 'derivatives', 'constants']"
40,Integrate rational function $\frac{x^2}{1+x^4}$,Integrate rational function,\frac{x^2}{1+x^4},Integrate $$\int\frac{x^2dx}{1+x^4}$$ I've factored the denominator to $(x^2-\sqrt{2}x+1)(x^2+\sqrt{2}x+1)$ and got stuck.,Integrate $$\int\frac{x^2dx}{1+x^4}$$ I've factored the denominator to $(x^2-\sqrt{2}x+1)(x^2+\sqrt{2}x+1)$ and got stuck.,,"['calculus', 'integration']"
41,$ \lim_{n\to\infty}{\left(\frac12\cdot\frac34\cdot\frac56\cdots\frac{2n-1}{2n}\right)}=0 $,, \lim_{n\to\infty}{\left(\frac12\cdot\frac34\cdot\frac56\cdots\frac{2n-1}{2n}\right)}=0 ,"Prove that   $$ \lim_{n\to\infty}{\left(\frac12\cdot\frac34\cdot\frac56\cdot\ldots\cdot\frac{2n-1}{2n}\right)}=0. $$ Transforming it to factorial obviously doesn't help at all, so I've noted $A_n$ as above product and noticed $1/2<2/3$, $3/4<4/5$, ..., $(2n-1)/(2n)<(2n)/(2n+1)$, so $A_n<1/\sqrt{2n+1}$. Now it's kind of obvious that $A_n$ approached $0$ as $n$ approaches infinity, but I'm not sure about formality of this proof. Is it safe to conclude that $A_n\to0^+ \text{when } n\to\infty$ from $A_n>0 \land A_n<1/\sqrt{2n+1}=0^+ \text{when } n\to\infty$?","Prove that   $$ \lim_{n\to\infty}{\left(\frac12\cdot\frac34\cdot\frac56\cdot\ldots\cdot\frac{2n-1}{2n}\right)}=0. $$ Transforming it to factorial obviously doesn't help at all, so I've noted $A_n$ as above product and noticed $1/2<2/3$, $3/4<4/5$, ..., $(2n-1)/(2n)<(2n)/(2n+1)$, so $A_n<1/\sqrt{2n+1}$. Now it's kind of obvious that $A_n$ approached $0$ as $n$ approaches infinity, but I'm not sure about formality of this proof. Is it safe to conclude that $A_n\to0^+ \text{when } n\to\infty$ from $A_n>0 \land A_n<1/\sqrt{2n+1}=0^+ \text{when } n\to\infty$?",,"['calculus', 'limits', 'solution-verification']"
42,integrate $\int_{\frac{\pi}{4}}^{\frac{\pi}{2}}{\ln{(\ln{\tan{x}})}dx} $,integrate,\int_{\frac{\pi}{4}}^{\frac{\pi}{2}}{\ln{(\ln{\tan{x}})}dx} ,"Evaluate this integrate $$\int_{\frac{\pi}{4}}^{\frac{\pi}{2}}{\ln{(\ln{\tan{x}})}dx} $$ My friend tian_275461 proposed this integrate,but I have no idea about it.","Evaluate this integrate $$\int_{\frac{\pi}{4}}^{\frac{\pi}{2}}{\ln{(\ln{\tan{x}})}dx} $$ My friend tian_275461 proposed this integrate,but I have no idea about it.",,['calculus']
43,"Compute the limit $\displaystyle \lim_{x\rightarrow 0}\frac{n!x^n-\sin x\sin 2x \sin 3x\cdots\sin nx}{x^{n+2}}\;\;,$",Compute the limit,"\displaystyle \lim_{x\rightarrow 0}\frac{n!x^n-\sin x\sin 2x \sin 3x\cdots\sin nx}{x^{n+2}}\;\;,","How can I calculate the given limit $$\displaystyle \lim_{x\rightarrow 0}\frac{n!x^n-\sin x\sin 2x \sin 3x\cdots\sin nx}{x^{n+2}}\,,$$ where $n\in\mathbb{N}$ .",How can I calculate the given limit where .,"\displaystyle \lim_{x\rightarrow 0}\frac{n!x^n-\sin x\sin 2x \sin 3x\cdots\sin nx}{x^{n+2}}\,, n\in\mathbb{N}",['calculus']
44,How to show $f'(0)$ exist and is equal to $1$? [duplicate],How to show  exist and is equal to ? [duplicate],f'(0) 1,"This question already has answers here : Prove that $f'(a)=\lim_{x\rightarrow a}f'(x)$. (6 answers) Closed 6 years ago . Assume that $f$ be continuous on $\mathbb{R}$, $f'(x)$ exists for all $x\neq 0$, and $\lim_{x\rightarrow 0} f'(x)=1$. We need to show $f'(0)$ exist and is equal to $1$. $f'(0)=\lim_{x\rightarrow 0}\frac{f(x)-f(0)}{x}$, $\lim_{x\rightarrow 0}f'(x)=1\Rightarrow\lim_{x\rightarrow 0}\lim_{h\rightarrow 0}\frac{f(x+h)-f(x)}{h}=1$...am I going in the right direction? Please help.","This question already has answers here : Prove that $f'(a)=\lim_{x\rightarrow a}f'(x)$. (6 answers) Closed 6 years ago . Assume that $f$ be continuous on $\mathbb{R}$, $f'(x)$ exists for all $x\neq 0$, and $\lim_{x\rightarrow 0} f'(x)=1$. We need to show $f'(0)$ exist and is equal to $1$. $f'(0)=\lim_{x\rightarrow 0}\frac{f(x)-f(0)}{x}$, $\lim_{x\rightarrow 0}f'(x)=1\Rightarrow\lim_{x\rightarrow 0}\lim_{h\rightarrow 0}\frac{f(x+h)-f(x)}{h}=1$...am I going in the right direction? Please help.",,"['calculus', 'derivatives']"
45,Can the Sum Rule for derivatives be extended to infinite series?,Can the Sum Rule for derivatives be extended to infinite series?,,"I wrote an answer here , which I'm not sure works. The sum rule for differentiation of two functions says that $D(u+v) = D(u) + D(v)$ where $D$ indicates the derivative, and $u$ and $v$ two functions.  The sum rule can get extended to any finite set of functions.  Since numbers can get regarded as functions, this implies that for any finite series $S=a + b + \dots+z$ we can evaluate $D(S).$  Can we extend the sum rule to differentiation of convergent infinite series?  Divergent infinite series?  Why or why not?","I wrote an answer here , which I'm not sure works. The sum rule for differentiation of two functions says that $D(u+v) = D(u) + D(v)$ where $D$ indicates the derivative, and $u$ and $v$ two functions.  The sum rule can get extended to any finite set of functions.  Since numbers can get regarded as functions, this implies that for any finite series $S=a + b + \dots+z$ we can evaluate $D(S).$  Can we extend the sum rule to differentiation of convergent infinite series?  Divergent infinite series?  Why or why not?",,"['calculus', 'derivatives']"
46,Why isn't an odd improper integral equal to zero,Why isn't an odd improper integral equal to zero,,"My calculus book says that the integral of $\frac1x$ cannot cross zero. Now it seems obvious that because of symmetry, there will always be an interval whose integrals are equal in magnitude and opposite insign, so cancel, even though they do not converge. Now typing into wolframalpha I got ""does not converge"" and only at the bottom did the expected result appeared ($\ln|b|-\ln|a|$) as ""Cauchy principal value"" (CPV, which I looked up on wikipedia). Why that fancyness? Does this has some implications in some application area? And also, when I ask wolframalpha about ""integral of cos/sin from $0$ to $\frac\pi2$"", I get infinity (intuitive, looking at the plot, although $\ln|sin(\frac\pi2)|-\ln|sin(0)|$ is admittedly wrong ) as ""CPV"", but when I ask for ""integral of cos/sin from $0$ to $\pi$"" which I expect to be zero, because the plot is symmetric/odd I get ""does not converge"" and there is no CPV result either. Why?","My calculus book says that the integral of $\frac1x$ cannot cross zero. Now it seems obvious that because of symmetry, there will always be an interval whose integrals are equal in magnitude and opposite insign, so cancel, even though they do not converge. Now typing into wolframalpha I got ""does not converge"" and only at the bottom did the expected result appeared ($\ln|b|-\ln|a|$) as ""Cauchy principal value"" (CPV, which I looked up on wikipedia). Why that fancyness? Does this has some implications in some application area? And also, when I ask wolframalpha about ""integral of cos/sin from $0$ to $\frac\pi2$"", I get infinity (intuitive, looking at the plot, although $\ln|sin(\frac\pi2)|-\ln|sin(0)|$ is admittedly wrong ) as ""CPV"", but when I ask for ""integral of cos/sin from $0$ to $\pi$"" which I expect to be zero, because the plot is symmetric/odd I get ""does not converge"" and there is no CPV result either. Why?",,"['calculus', 'integration', 'improper-integrals', 'symmetry']"
47,integration with indicator function,integration with indicator function,,"I was trying to solve the following simple integration involving indicator function $I_{(a,b]}$ in a journal article. Here are the equations (in LaTeX notation): $$ f(u) = \int_{0}^{1} (I_{(0,s]}(u) - s)\; ds\tag{1} $$ $$ g(u,v) = \int_{0}^{1} (I_{(0,s]}(u) - s)(I_{(0,s]}(v) - s)\; ds\tag{2} $$ where $0 < u, v < 1$. I was thinking that the integration will be simply just $$ f(u) = \int_{0}^{1} (1 - s)\; ds\tag{1} $$ $$   g(u,v) = \int_{0}^{1} (1 - s)(1 - s)\; ds \tag{2} $$ But, I'm not so sure about this. The constraint on both $u$ and $v$ confused me. Any pointer to this solution? Thanks Wayan","I was trying to solve the following simple integration involving indicator function $I_{(a,b]}$ in a journal article. Here are the equations (in LaTeX notation): $$ f(u) = \int_{0}^{1} (I_{(0,s]}(u) - s)\; ds\tag{1} $$ $$ g(u,v) = \int_{0}^{1} (I_{(0,s]}(u) - s)(I_{(0,s]}(v) - s)\; ds\tag{2} $$ where $0 < u, v < 1$. I was thinking that the integration will be simply just $$ f(u) = \int_{0}^{1} (1 - s)\; ds\tag{1} $$ $$   g(u,v) = \int_{0}^{1} (1 - s)(1 - s)\; ds \tag{2} $$ But, I'm not so sure about this. The constraint on both $u$ and $v$ confused me. Any pointer to this solution? Thanks Wayan",,['calculus']
48,Finding $\delta$ with given $\varepsilon$ for $f(x)=4x^2 +x +3$ and $x\to3$,Finding  with given  for  and,\delta \varepsilon f(x)=4x^2 +x +3 x\to3,"$f(x)=4x^2 +x +3$ and the limit as x approaches $-3$ of $f(-3)= 36$, Find $\delta$ such that $0<|x+3|<\delta \longrightarrow |f(x)-36|<.003$ I have tried: $|(x+3)(4x-11)|<0.003$ $0<|x+3|<\frac{0.003}{|4x-11|}$ Assume $-4<x<-2$ $\delta= .000111$ or $0.000158$  Both came back as incorrect. Where have I gone wrong? EDIT: Problem solved via Henry's answer. Thank you all for the help! $\delta=0.000130$","$f(x)=4x^2 +x +3$ and the limit as x approaches $-3$ of $f(-3)= 36$, Find $\delta$ such that $0<|x+3|<\delta \longrightarrow |f(x)-36|<.003$ I have tried: $|(x+3)(4x-11)|<0.003$ $0<|x+3|<\frac{0.003}{|4x-11|}$ Assume $-4<x<-2$ $\delta= .000111$ or $0.000158$  Both came back as incorrect. Where have I gone wrong? EDIT: Problem solved via Henry's answer. Thank you all for the help! $\delta=0.000130$",,"['calculus', 'limits', 'epsilon-delta']"
49,Integrals as Probabilities,Integrals as Probabilities,,"Firstly, I'm not a mathematician as will become evident in a quick moment. I was pondering some maths the other day and had an interesting thought: If you encased an integrable function over some range in a primitive with an easily computable area, the probability that a random point within said primitive also exists below that function's curve, scaled by the area of the primitive, is the indefinite integral of the function over that domain. So let's say I want to ""solve"" for $\pi$. Exploiting a circle's symmetry, I can define $\pi$ as: $$4 \int_{0}^{1}\sqrt{1-x^2} \,dx$$ Which I can ""encase"" in the unit square. Since the area of the unit square is 1, $\pi$ is just 4 * the probability that a point chosen at random within the unit square is below the quarter-circle's arc. I'm sure this is well known, and so my questions are: What is this called? Is there anything significant about this--for instance, is the relationship between the integral and the encasing object of interest--or is it just another way of phrasing indefinite integrals? Sorry if this is painfully elementary!","Firstly, I'm not a mathematician as will become evident in a quick moment. I was pondering some maths the other day and had an interesting thought: If you encased an integrable function over some range in a primitive with an easily computable area, the probability that a random point within said primitive also exists below that function's curve, scaled by the area of the primitive, is the indefinite integral of the function over that domain. So let's say I want to ""solve"" for $\pi$. Exploiting a circle's symmetry, I can define $\pi$ as: $$4 \int_{0}^{1}\sqrt{1-x^2} \,dx$$ Which I can ""encase"" in the unit square. Since the area of the unit square is 1, $\pi$ is just 4 * the probability that a point chosen at random within the unit square is below the quarter-circle's arc. I'm sure this is well known, and so my questions are: What is this called? Is there anything significant about this--for instance, is the relationship between the integral and the encasing object of interest--or is it just another way of phrasing indefinite integrals? Sorry if this is painfully elementary!",,"['calculus', 'probability']"
50,Help understanding the definition of tangent vector or tangent plane?,Help understanding the definition of tangent vector or tangent plane?,,"Here is what my textbook told me: Assuming the formula for surface $\Sigma$ is $$F(x,y,z) = 0$$  Suppose $X_0 = (x_0, y_0, z_0)$ is a point on the surface $\Sigma$ and we assuming F(x,y,z) is differentiable and $$\mathbf{J}F(X_0) = (\frac{\partial F(X_0)}{\partial x}, \frac{\partial F(X_0)}{\partial y}, \frac{\partial F(X_0)}{\partial z}) \neq 0$$  Draw a line $\Gamma$ in the surface $\Sigma$ passing through the point $X_0$, assuming the equations for $\Sigma$ is $$x = x(t), y = y(t), z = z(t)$$  $t = t_0$ correspond to the point $X_0$ and $x'(t_0), y'(t_0), z'(t_0)$ does not all vanish. Because of the line $\Gamma$ is on the surface $\Sigma$, so $$F(x(t), y(t), z(t)) = 0$$ So $$ \frac{dF}{dt}\mid_{t=t_0} = {F_x}'(X_0)x'(t_0) + {F_y}'(X_0)y'(t_0) + {F_z}'(X_0)z'(t_0) = 0 $$ So $$ ({F_x}'(X_0), {F_y}'(X_0), {F_z}'(X_0))\cdot(x'(t_0), y'(t_0), z'(t_0)) = 0 $$ We know the vector $\mathbf{T} = (x'(t_0), y'(t_0), z'(t_0))$ is the tangent vector for the line $\Gamma$ on the point $X_0$ My questions are Why the vector $\mathbf{T}$ is the tangent vector for line $\Gamma$ at point $X_0$? Why the $\mathbf{J}F(X_0)$ should not equal to zero? What if it is zero? Why $x'(t_0), y'(t_0), z'(t_0)$ should not all vanish? What if all vanish?","Here is what my textbook told me: Assuming the formula for surface $\Sigma$ is $$F(x,y,z) = 0$$  Suppose $X_0 = (x_0, y_0, z_0)$ is a point on the surface $\Sigma$ and we assuming F(x,y,z) is differentiable and $$\mathbf{J}F(X_0) = (\frac{\partial F(X_0)}{\partial x}, \frac{\partial F(X_0)}{\partial y}, \frac{\partial F(X_0)}{\partial z}) \neq 0$$  Draw a line $\Gamma$ in the surface $\Sigma$ passing through the point $X_0$, assuming the equations for $\Sigma$ is $$x = x(t), y = y(t), z = z(t)$$  $t = t_0$ correspond to the point $X_0$ and $x'(t_0), y'(t_0), z'(t_0)$ does not all vanish. Because of the line $\Gamma$ is on the surface $\Sigma$, so $$F(x(t), y(t), z(t)) = 0$$ So $$ \frac{dF}{dt}\mid_{t=t_0} = {F_x}'(X_0)x'(t_0) + {F_y}'(X_0)y'(t_0) + {F_z}'(X_0)z'(t_0) = 0 $$ So $$ ({F_x}'(X_0), {F_y}'(X_0), {F_z}'(X_0))\cdot(x'(t_0), y'(t_0), z'(t_0)) = 0 $$ We know the vector $\mathbf{T} = (x'(t_0), y'(t_0), z'(t_0))$ is the tangent vector for the line $\Gamma$ on the point $X_0$ My questions are Why the vector $\mathbf{T}$ is the tangent vector for line $\Gamma$ at point $X_0$? Why the $\mathbf{J}F(X_0)$ should not equal to zero? What if it is zero? Why $x'(t_0), y'(t_0), z'(t_0)$ should not all vanish? What if all vanish?",,"['calculus', 'geometry']"
51,Tractrix-like curves,Tractrix-like curves,,"Is there a common name for curves, obtained from dragging a point along another curve, similar to how tractrix is obtained by dragging a point along a line? What is a parametric equation of such curve given the parametric equation of a curve along which the master goes?","Is there a common name for curves, obtained from dragging a point along another curve, similar to how tractrix is obtained by dragging a point along a line? What is a parametric equation of such curve given the parametric equation of a curve along which the master goes?",,"['calculus', 'geometry', 'analytic-geometry', 'plane-curves']"
52,constraints on the sum and product of roots of quadratic equation assuming less than unity roots,constraints on the sum and product of roots of quadratic equation assuming less than unity roots,,"I am solving a math contest problem. Assume we have the quadratic equation $x^2+a_1x+a_2=0$ where $a_1,a_2\in \mathbb{R}$ are real numbers. The roots of this equation can be found as (from equation it can be inferred that $a_1 = -(p_1+p_2), a_2 = p_1p_2$ ) $$p_1,p_2 = -\frac{a_1}{2}\pm \sqrt{\frac{a_1^2}{4}-a_2}$$ Now assume that $|p_1|< 1, |p_2|< 1$ , in other words the module of the roots is lesser than unity (in the case of real roots, it translates to the fact that their absolute value is less than one). The claim is twofold $|a_2| < 1$ $|a_1| < a_2+1$ proving the first one very easy since $|a_2|=|p_1p_2| \le |p_1||p_2|< 1$ . However, the second one is almost impossible to prove! If we assume the roots are real, then by using $|p_i|< 1$ we can say $$-1< -\frac{a_1}{2}\pm \sqrt{\frac{a_1^2}{4}-a_2}< 1 \Rightarrow -1+\frac{a_1}{2} < \pm \sqrt{\frac{a_1^2}{4}-a_2}< 1 + \frac{a_1}{2}$$ then this gives two inequalities which can be manipulated to get similar results with a lot of mental gymnastics! But I don't know what to do in general! Is there any simpler way to reach the conclusion? What can be done in general case (complex conjugate roots and real distinct roots)? Thank you! =================================Edit=============================== For the complex conjugate pair, we can write $p_1 = p_r+ip_i, p_2 = p_1-ip_i$ and by substitution we get two true statements $$(1+p_r)^2+p_i^2 > 0 , (p_r-1)^2+p_i^2 > 0$$ and this prove the complex case. However, I am trying to find a way to drive the second statement using the given assumptions! Is there a way?","I am solving a math contest problem. Assume we have the quadratic equation where are real numbers. The roots of this equation can be found as (from equation it can be inferred that ) Now assume that , in other words the module of the roots is lesser than unity (in the case of real roots, it translates to the fact that their absolute value is less than one). The claim is twofold proving the first one very easy since . However, the second one is almost impossible to prove! If we assume the roots are real, then by using we can say then this gives two inequalities which can be manipulated to get similar results with a lot of mental gymnastics! But I don't know what to do in general! Is there any simpler way to reach the conclusion? What can be done in general case (complex conjugate roots and real distinct roots)? Thank you! =================================Edit=============================== For the complex conjugate pair, we can write and by substitution we get two true statements and this prove the complex case. However, I am trying to find a way to drive the second statement using the given assumptions! Is there a way?","x^2+a_1x+a_2=0 a_1,a_2\in \mathbb{R} a_1 = -(p_1+p_2), a_2 = p_1p_2 p_1,p_2 = -\frac{a_1}{2}\pm \sqrt{\frac{a_1^2}{4}-a_2} |p_1|< 1, |p_2|< 1 |a_2| < 1 |a_1| < a_2+1 |a_2|=|p_1p_2| \le |p_1||p_2|< 1 |p_i|< 1 -1< -\frac{a_1}{2}\pm \sqrt{\frac{a_1^2}{4}-a_2}< 1 \Rightarrow -1+\frac{a_1}{2} < \pm \sqrt{\frac{a_1^2}{4}-a_2}< 1 + \frac{a_1}{2} p_1 = p_r+ip_i, p_2 = p_1-ip_i (1+p_r)^2+p_i^2 > 0 , (p_r-1)^2+p_i^2 > 0","['calculus', 'complex-numbers', 'contest-math', 'roots', 'quadratics']"
53,"To integrate $\int_0^{2\pi}\sqrt{\theta^2+1}\ d\theta$, why choose the change of variables $u=\theta+\sqrt{\theta^2+1}$?","To integrate , why choose the change of variables ?",\int_0^{2\pi}\sqrt{\theta^2+1}\ d\theta u=\theta+\sqrt{\theta^2+1},"In order to find the length of the curve $r=\theta,\ \theta\in[0, 2\pi]$ , the integral that must be solved is $$\int_0^{2\pi}\sqrt{\theta^2+1}\ d\theta$$ For which my proffesor opted to use the following change of variable: $u=\theta+\sqrt{\theta^2+1}$ , since $$\theta=\frac{u^2-1}{2u}$$ and $$d\theta=\frac{u^2+1}{2u^2}du$$ And from there he wrote directly the solution $$L=\frac{1}{2}[\theta\sqrt{\theta^2+1}+log|\theta+\sqrt{\theta^2+1}|]^{2\pi}_0$$ However, I do not undersand why is this the change of variable he decided to use.","In order to find the length of the curve , the integral that must be solved is For which my proffesor opted to use the following change of variable: , since and And from there he wrote directly the solution However, I do not undersand why is this the change of variable he decided to use.","r=\theta,\ \theta\in[0, 2\pi] \int_0^{2\pi}\sqrt{\theta^2+1}\ d\theta u=\theta+\sqrt{\theta^2+1} \theta=\frac{u^2-1}{2u} d\theta=\frac{u^2+1}{2u^2}du L=\frac{1}{2}[\theta\sqrt{\theta^2+1}+log|\theta+\sqrt{\theta^2+1}|]^{2\pi}_0","['calculus', 'integration', 'definite-integrals', 'change-of-variable']"
54,Maximizing/minimizing $f(\theta) = \sqrt{2}\cos(\theta)-4\sin(\theta)$,Maximizing/minimizing,f(\theta) = \sqrt{2}\cos(\theta)-4\sin(\theta),"Assume that $f : [0, 2\pi]\rightarrow \mathbb{R}$ is a function such that $f(\theta) = \sqrt{2}\cos(\theta)-4\sin(\theta)$ . Then, how can we maximize/minimize $f$ ? We can re-parametrize our function $f$ by defining another function $g : [-1, 1]\rightarrow \mathbb{R}$ function such that for every $t\in [-1, 1]$ , $$g(t) = \sqrt{2}\sqrt{1-t^2}-4t$$ $$\frac{dg}{dt} = \frac{d}{dt}\left(\sqrt{2}\sqrt{1-t^2}-4t\right) = \frac{\sqrt{2}t}{\sqrt{1-t^2}} + 4 = 0$$ From which we conclude that $g$ attains its maximum/minimum at $\left(-\frac{2\sqrt{2}}{3}, g\left(-\frac{2\sqrt{2}}{3}\right)\right), (1, g(1))\in \mathbb{R}^2$ respectively.","Assume that is a function such that . Then, how can we maximize/minimize ? We can re-parametrize our function by defining another function function such that for every , From which we conclude that attains its maximum/minimum at respectively.","f : [0, 2\pi]\rightarrow \mathbb{R} f(\theta) = \sqrt{2}\cos(\theta)-4\sin(\theta) f f g : [-1, 1]\rightarrow \mathbb{R} t\in [-1, 1] g(t) = \sqrt{2}\sqrt{1-t^2}-4t \frac{dg}{dt} = \frac{d}{dt}\left(\sqrt{2}\sqrt{1-t^2}-4t\right) = \frac{\sqrt{2}t}{\sqrt{1-t^2}} + 4 = 0 g \left(-\frac{2\sqrt{2}}{3}, g\left(-\frac{2\sqrt{2}}{3}\right)\right), (1, g(1))\in \mathbb{R}^2",['calculus']
55,Is it true that $f'(\xi_1)(\xi_1-a)+f'(\xi_2)(\xi_2-b)+f(a)+f(b)=0$ if some conditions are met?,Is it true that  if some conditions are met?,f'(\xi_1)(\xi_1-a)+f'(\xi_2)(\xi_2-b)+f(a)+f(b)=0,"Problem : if function $f$ is continuous on the closed interval $[a,b]$ and differentiable on the open interval $(a,b)$ , and $$\int_a^b f(x)dx=0$$ Prove that there exists two distinct real numbers $\xi_1,\xi_2\in(a,b)$ such that $$f'(\xi_1)(\xi_1-a)+f'(\xi_2)(\xi_2-b)+f(a)+f(b)=0$$ I suspect I should use some sort of mean value theorem to prove this problem, but I tried all forms of the theorem listed on the Wikipedia page without any success. I am beginning to suspect this problem might be wrong and am looking for counter-example. Any help from you is greatly appreciated!","Problem : if function is continuous on the closed interval and differentiable on the open interval , and Prove that there exists two distinct real numbers such that I suspect I should use some sort of mean value theorem to prove this problem, but I tried all forms of the theorem listed on the Wikipedia page without any success. I am beginning to suspect this problem might be wrong and am looking for counter-example. Any help from you is greatly appreciated!","f [a,b] (a,b) \int_a^b f(x)dx=0 \xi_1,\xi_2\in(a,b) f'(\xi_1)(\xi_1-a)+f'(\xi_2)(\xi_2-b)+f(a)+f(b)=0","['calculus', 'examples-counterexamples']"
56,Taylor Series coordinate free form,Taylor Series coordinate free form,,"I am reading about the ""coordinate-free form"" of a Taylor series, it says, Let $f:\mathbb{R}^n\rightarrow\mathbb{R}$ be differentiable, $x$ and $\delta r$ be vectors then $$f(x+\delta r)=f(x)+[\delta r \cdot \nabla f(x)]+[\delta r\cdot (H(x) \delta r)] + ...$$ where $H(x)$ is the Hessian with entries $H(x)_{i,j}=f_{x_ix_j}$ and $x_i$ for $1\le i\le n$ is the standard basis I don't understand what comes after the ""..."" and would appreciate it if someone could tell me(or point me to an existing explanation that I cannot find). I know already what taylor series are in multiple dimensions, but I haven't seen them written in this form before.","I am reading about the ""coordinate-free form"" of a Taylor series, it says, Let be differentiable, and be vectors then where is the Hessian with entries and for is the standard basis I don't understand what comes after the ""..."" and would appreciate it if someone could tell me(or point me to an existing explanation that I cannot find). I know already what taylor series are in multiple dimensions, but I haven't seen them written in this form before.","f:\mathbb{R}^n\rightarrow\mathbb{R} x \delta r f(x+\delta r)=f(x)+[\delta r \cdot \nabla f(x)]+[\delta r\cdot (H(x) \delta r)] + ... H(x) H(x)_{i,j}=f_{x_ix_j} x_i 1\le i\le n","['calculus', 'multivariable-calculus', 'taylor-expansion', 'definition']"
57,"Show that $\{(x_1,x_2):x_1x_2\geq4,x_1>0,x_2>0\}$ is a convex set",Show that  is a convex set,"\{(x_1,x_2):x_1x_2\geq4,x_1>0,x_2>0\}","Trying to show that the set $S = \{(x_1,x_2):x_1x_2\geq4,x_1>0,x_2>0\}$ is convex. I tried proving by definition, let $x=(x_1,x_2)$ and $y=(y_1,y_2)$ and $\lambda\in[0,1]$ We want to show that $\lambda x + (1-\lambda)y \in S$ for $\lambda=1$ and $\lambda=0$ the answer is trivial. for $\lambda \in (0,1)$ I got a bit stuck What I tried was $\lambda x + (1-\lambda)y = \lambda(x_1,x_2) + (1 - \lambda)(y_1,y_2) = \lambda(x_1,x_2) - \lambda(y_1,y_2) + (y_1,y_2) = (\lambda x_1 - \lambda y_1 + y_1, \lambda x_2 - \lambda y_2 + y_2)$ So now if we can prove that $(\lambda x_1 - \lambda y_1 + y_1)\times(\lambda x_2 - \lambda y_2 + \lambda y_2) \geq 4$ we are done. I got stuck here, I tried looking for a way with the mean inequality but with no success. I think I am way off base, perhaps Jensen's inequality or something in that domain might be what I am looking for.","Trying to show that the set is convex. I tried proving by definition, let and and We want to show that for and the answer is trivial. for I got a bit stuck What I tried was So now if we can prove that we are done. I got stuck here, I tried looking for a way with the mean inequality but with no success. I think I am way off base, perhaps Jensen's inequality or something in that domain might be what I am looking for.","S = \{(x_1,x_2):x_1x_2\geq4,x_1>0,x_2>0\} x=(x_1,x_2) y=(y_1,y_2) \lambda\in[0,1] \lambda x + (1-\lambda)y \in S \lambda=1 \lambda=0 \lambda \in (0,1) \lambda x + (1-\lambda)y = \lambda(x_1,x_2) + (1 - \lambda)(y_1,y_2) = \lambda(x_1,x_2) - \lambda(y_1,y_2) + (y_1,y_2) = (\lambda x_1 - \lambda y_1 + y_1, \lambda x_2 - \lambda y_2 + y_2) (\lambda x_1 - \lambda y_1 + y_1)\times(\lambda x_2 - \lambda y_2 + \lambda y_2) \geq 4","['calculus', 'optimization', 'convex-analysis', 'convex-optimization']"
58,How to find the limit that involves the factorials?,How to find the limit that involves the factorials?,,"$$ \lim_{n\to\infty}\left(\int_a^b((x-a)(b-x))^n\mathrm{d}x\right)^{\frac{1}{n}}$$ I have found the form of the integrand to be $$\frac{(n!)^2}{(2n+1)!}(b-a)^{2n+1}$$ Now, splitting the limit into two different parts i would need to solve $$\lim_{n\to\infty}(\frac{(n!)^2}{(2n+1)!} )^{\frac{1}{n}}$$ My mind went to Stirling's approximation formula but i don't think it could help.","I have found the form of the integrand to be Now, splitting the limit into two different parts i would need to solve My mind went to Stirling's approximation formula but i don't think it could help.", \lim_{n\to\infty}\left(\int_a^b((x-a)(b-x))^n\mathrm{d}x\right)^{\frac{1}{n}} \frac{(n!)^2}{(2n+1)!}(b-a)^{2n+1} \lim_{n\to\infty}(\frac{(n!)^2}{(2n+1)!} )^{\frac{1}{n}},"['calculus', 'integration', 'limits', 'factorial']"
59,"Finding $\int \frac {e^x \sqrt{e^x - 1}}{e^x+3}\,dx$ by substituting $t^2=e^x-1$",Finding  by substituting,"\int \frac {e^x \sqrt{e^x - 1}}{e^x+3}\,dx t^2=e^x-1","Let's consider the following integral: $$\int \frac {e^x \sqrt{e^x - 1}}{e^x+3}\,dx$$ And let's take the substitution $t^2=e^x-1$ . Then, we get $2tdt=e^xdx$ and so: $$\int \frac {e^x \sqrt{e^x - 1}}{e^x+3}\,dx = 2\int \frac {t \sqrt{t^2}}{t^2+4}\,dt$$ So, can we take $\sqrt{t^2}=t$ there? It seems to me that we could do that only if we say at the beginning, when we took the substitution, that $t$ is non-negative. However, I've never seen that anybody has  written anything like that in any solution of antiderivative problems. So, if we want to be formal, should we write that we take non-negative $t$ ?","Let's consider the following integral: And let's take the substitution . Then, we get and so: So, can we take there? It seems to me that we could do that only if we say at the beginning, when we took the substitution, that is non-negative. However, I've never seen that anybody has  written anything like that in any solution of antiderivative problems. So, if we want to be formal, should we write that we take non-negative ?","\int \frac {e^x \sqrt{e^x - 1}}{e^x+3}\,dx t^2=e^x-1 2tdt=e^xdx \int \frac {e^x \sqrt{e^x - 1}}{e^x+3}\,dx = 2\int \frac {t \sqrt{t^2}}{t^2+4}\,dt \sqrt{t^2}=t t t","['calculus', 'integration', 'substitution']"
60,Integrating $\frac{1}{(1-x)^2} $ into two different-looking functions,Integrating  into two different-looking functions,\frac{1}{(1-x)^2} ,"Background I want to ""trick"" some students by showing that $$\int \frac{1}{(1-x)^2} \mathrm dx = \frac1{1-x} + C$$ in one instance and $$\int \frac{1}{(1-x)^2} \mathrm dx = \frac x{1-x} + C$$ in another. Obviously these look like two different results due to the different numerator, but as the more astute will point out, the difference between these functions is a constant, and they therefore have the same derivative. Question When solving the integral, using the substitution $u = 1-x$ we naturally arrive that the first results, but is there a way of solving the integral that ""naturally"" yields the second result?","Background I want to ""trick"" some students by showing that in one instance and in another. Obviously these look like two different results due to the different numerator, but as the more astute will point out, the difference between these functions is a constant, and they therefore have the same derivative. Question When solving the integral, using the substitution we naturally arrive that the first results, but is there a way of solving the integral that ""naturally"" yields the second result?",\int \frac{1}{(1-x)^2} \mathrm dx = \frac1{1-x} + C \int \frac{1}{(1-x)^2} \mathrm dx = \frac x{1-x} + C u = 1-x,"['calculus', 'integration', 'derivatives', 'indefinite-integrals']"
61,Evaluating $\sum_{n=1}^\infty\frac{\overline{H}_nH_{n/2}}{n^2}$,Evaluating,\sum_{n=1}^\infty\frac{\overline{H}_nH_{n/2}}{n^2},"I ma trying to prove $$S=\sum_{n=1}^\infty\frac{\overline{H}_nH_{n/2}}{n^2}=\frac1{24}\ln^42-\frac14\ln^22\zeta(2)+\frac{21}{8}\ln2\zeta(3)-\frac{9}{8}\zeta(4)+\operatorname{Li}_4\left(\frac12\right)$$ where $\overline{H}_n$ is the alternating harmonic number and $H_n$ is the harmonic number. I need this sum to complete my solution here . Here is my trial, Following @user97357329's note in the comments of the same link above $$\sum_{n=1}^\infty f(n)=\sum_{n=1}^\infty f(2n-1)+\sum_{n=1}^\infty f(2n)$$ Giving us $$S=\underbrace{\sum_{n=1}^\infty\frac{\overline{H}_{2n-1}H_{n-1/2}}{(2n-1)^2}}_{\large S_1}+\frac14\underbrace{\sum_{n=1}^\infty\frac{\overline{H}_{2n}H_{n}}{n^2}}_{\large S_2}$$ I managed to evaluate $S_2$ using $\overline{H}_{2n}=H_{2n}-H_n$ . Regarding $S_1$ , I used $\overline{H}_{2n-1}=H_{2n}-H_n+\frac1{2n}$ and $H_{n-1/2}=2H_{2n}-H_n-2\ln2$ therefore $$S_1=2\sum_{n=1}^\infty\frac{H_{2n}^2}{(2n-1)^2}-\color{blue}{\sum_{n=1}^\infty\frac{H_nH_{2n}}{(2n-1)^2}}-2\ln2\sum_{n=1}^\infty\frac{H_{2n}}{(2n-1)^2}+\color{red}{\sum_{n=1}^\infty\frac{2H_{2n}-H_n-2\ln2}{2n(2n-1)^2}}$$ and I am stuck with the blue and red sums, any idea? Thank you.","I ma trying to prove where is the alternating harmonic number and is the harmonic number. I need this sum to complete my solution here . Here is my trial, Following @user97357329's note in the comments of the same link above Giving us I managed to evaluate using . Regarding , I used and therefore and I am stuck with the blue and red sums, any idea? Thank you.",S=\sum_{n=1}^\infty\frac{\overline{H}_nH_{n/2}}{n^2}=\frac1{24}\ln^42-\frac14\ln^22\zeta(2)+\frac{21}{8}\ln2\zeta(3)-\frac{9}{8}\zeta(4)+\operatorname{Li}_4\left(\frac12\right) \overline{H}_n H_n \sum_{n=1}^\infty f(n)=\sum_{n=1}^\infty f(2n-1)+\sum_{n=1}^\infty f(2n) S=\underbrace{\sum_{n=1}^\infty\frac{\overline{H}_{2n-1}H_{n-1/2}}{(2n-1)^2}}_{\large S_1}+\frac14\underbrace{\sum_{n=1}^\infty\frac{\overline{H}_{2n}H_{n}}{n^2}}_{\large S_2} S_2 \overline{H}_{2n}=H_{2n}-H_n S_1 \overline{H}_{2n-1}=H_{2n}-H_n+\frac1{2n} H_{n-1/2}=2H_{2n}-H_n-2\ln2 S_1=2\sum_{n=1}^\infty\frac{H_{2n}^2}{(2n-1)^2}-\color{blue}{\sum_{n=1}^\infty\frac{H_nH_{2n}}{(2n-1)^2}}-2\ln2\sum_{n=1}^\infty\frac{H_{2n}}{(2n-1)^2}+\color{red}{\sum_{n=1}^\infty\frac{2H_{2n}-H_n-2\ln2}{2n(2n-1)^2}},"['calculus', 'integration', 'sequences-and-series', 'closed-form', 'harmonic-numbers']"
62,Is it true that if $f(f(x))$ is continuous and strictly decreasing then $f$ is continuous$?$,Is it true that if  is continuous and strictly decreasing then  is continuous,f(f(x)) f ?,"Is it true that if $f(f(x))$ is continuous and strictly decreasing then $f$ is continuous $?$ First of all, how can $f(f(x))$ be strictly decreasing. If $f(x)$ is increasing then $f(f(x))$ is also increasing and if $f(x)$ is decreasing, then $f(f(x))$ is increasing again. I think this statement is trivially true. If we use Boolean algebra, if $p$ is not true then $p \Rightarrow q$ is always true. Am I thinking correctly $?$","Is it true that if is continuous and strictly decreasing then is continuous First of all, how can be strictly decreasing. If is increasing then is also increasing and if is decreasing, then is increasing again. I think this statement is trivially true. If we use Boolean algebra, if is not true then is always true. Am I thinking correctly",f(f(x)) f ? f(f(x)) f(x) f(f(x)) f(x) f(f(x)) p p \Rightarrow q ?,['calculus']
63,Intriguing Limit,Intriguing Limit,,"Prove that: $$L=\lim_{n\to\infty} \frac {\sqrt 2 n^{\left(n-\frac 12\right)}}{n!}\left(\frac {(2\sqrt[n] {n} -1)^n}{n^2}\right)^{ \frac {n\left(n-\frac 12\right)}{\ln^2 n}}=\sqrt {\frac {e}{\pi}}$$ My method: Properties I am going to use : 1)Stirling's approximation: $$n!\sim\sqrt {2\pi n} \left(\frac ne\right)^n$$ 2)Property 2 : $$\sqrt[n] {n}\sim 1+\frac {\ln n}{n}+\frac{\ln^2 n}{2n^2}$$ 3)Property 3: For all continuous and differentiable functions $f,g$ (In their domain respectively),  if $\lim_{x\to\infty} g(x)=0$ then for large enough $x$ we have $$(1+g(x))^{f(x)}\sim e^{f(x)\cdot g(x)}$$ Using Stirling's approximation we get $$L=\lim_{n\to\infty} \frac {e^n}{\sqrt{\pi} n}\left(\frac {\displaystyle (2\sqrt[n]{n} -1)^n}{n^2}\right)^{\frac {n\left(n-\frac 12\right)}{\ln^2n}}$$ Using Property 2 we get $$L=\lim_{n\to\infty} \frac {e^n}{\sqrt {\pi} n}\left(\frac { \left(1+\frac {2\ln n}{n}+\frac{\ln^2n}{n^2}\right)^n}{n^2}\right)^{\frac {n\left(n-\frac 12\right)}{\ln^2n}}$$ And using the property 3 we get $$L=\lim_{n\to\infty} \frac {e^n}{\sqrt{\pi} n} \displaystyle \frac {e^{\frac {n(2n-1)}{\ln n}}\cdot e^{ \left(n-\frac 12\right)}}{ n^{\frac {n(2n-1)}{\ln^2 n}}}$$ Using that $$n^{\frac {n(2n-1)}{\ln^2 n}}=e^{\frac {n(2n-1)}{\ln n}}$$ Using this alongwith previous results we get $$L=\lim_{n\to\infty} \frac {e^n}{\sqrt{\pi} n} \displaystyle \frac {e^{\frac {n(2n-1)}{\ln n}}}{e^{ \frac {n(2n-1)}{\ln n}}}\cdot e^{ \left(n-\frac 12\right)}=\lim_{n\to\infty} \frac {e^{2n}}{\sqrt{e\pi} n}$$ Which  clearly doesn't converge.Can someone please point out my mistake in above working. Also some new suggestions to solve this question will be quite beneficial.","Prove that: My method: Properties I am going to use : 1)Stirling's approximation: 2)Property 2 : 3)Property 3: For all continuous and differentiable functions (In their domain respectively),  if then for large enough we have Using Stirling's approximation we get Using Property 2 we get And using the property 3 we get Using that Using this alongwith previous results we get Which  clearly doesn't converge.Can someone please point out my mistake in above working. Also some new suggestions to solve this question will be quite beneficial.","L=\lim_{n\to\infty} \frac {\sqrt 2 n^{\left(n-\frac 12\right)}}{n!}\left(\frac {(2\sqrt[n] {n} -1)^n}{n^2}\right)^{ \frac {n\left(n-\frac 12\right)}{\ln^2 n}}=\sqrt {\frac {e}{\pi}} n!\sim\sqrt {2\pi n} \left(\frac ne\right)^n \sqrt[n] {n}\sim 1+\frac {\ln n}{n}+\frac{\ln^2 n}{2n^2} f,g \lim_{x\to\infty} g(x)=0 x (1+g(x))^{f(x)}\sim e^{f(x)\cdot g(x)} L=\lim_{n\to\infty} \frac {e^n}{\sqrt{\pi} n}\left(\frac {\displaystyle (2\sqrt[n]{n} -1)^n}{n^2}\right)^{\frac {n\left(n-\frac 12\right)}{\ln^2n}} L=\lim_{n\to\infty} \frac {e^n}{\sqrt {\pi} n}\left(\frac { \left(1+\frac {2\ln n}{n}+\frac{\ln^2n}{n^2}\right)^n}{n^2}\right)^{\frac {n\left(n-\frac 12\right)}{\ln^2n}} L=\lim_{n\to\infty} \frac {e^n}{\sqrt{\pi} n} \displaystyle \frac {e^{\frac {n(2n-1)}{\ln n}}\cdot e^{ \left(n-\frac 12\right)}}{ n^{\frac {n(2n-1)}{\ln^2 n}}} n^{\frac {n(2n-1)}{\ln^2 n}}=e^{\frac {n(2n-1)}{\ln n}} L=\lim_{n\to\infty} \frac {e^n}{\sqrt{\pi} n} \displaystyle \frac {e^{\frac {n(2n-1)}{\ln n}}}{e^{ \frac {n(2n-1)}{\ln n}}}\cdot e^{ \left(n-\frac 12\right)}=\lim_{n\to\infty} \frac {e^{2n}}{\sqrt{e\pi} n}","['calculus', 'limits']"
64,what does it mean by determinant of Jacobian matrix = 0?,what does it mean by determinant of Jacobian matrix = 0?,,I have an example: $$ u={x+y\over 1-xy} $$ $$ v = \tan^{-1}(x)+\tan^{-1}(y) $$ So by calculating the determinant of the Jacobian matrix I get zero. Does it mean there is no functional relationship between u and v? What does $|J|=0$ mean?,I have an example: So by calculating the determinant of the Jacobian matrix I get zero. Does it mean there is no functional relationship between u and v? What does mean?, u={x+y\over 1-xy}   v = \tan^{-1}(x)+\tan^{-1}(y)  |J|=0,"['calculus', 'linear-algebra', 'jacobian']"
65,The limit as a function on functions?,The limit as a function on functions?,,"Is the observation that, "" The limit is a function on functions ,"" true or meaningful? Since the limit is unique, if it exists, then the pair $\displaystyle(c,\lim_{x\to c}f(x))$ itself defines a function for some function $f$. I was just thinking about the idea and wanted some outside feedback.","Is the observation that, "" The limit is a function on functions ,"" true or meaningful? Since the limit is unique, if it exists, then the pair $\displaystyle(c,\lim_{x\to c}f(x))$ itself defines a function for some function $f$. I was just thinking about the idea and wanted some outside feedback.",,"['calculus', 'limits']"
66,Summation problem: $f(x)=1+\sum_{n=1}^{\infty}\frac{x^n}{n}$,Summation problem:,f(x)=1+\sum_{n=1}^{\infty}\frac{x^n}{n},"I want to evaluate this summation: $$S=1+x+\frac{x^2}{2}+\frac{x^3}{3}+\frac{x^4}{4}+...+...$$ where, $|x|<1$ Here it is my approach $$S=1+\sum_{n=1}^{\infty}\frac{x^n}{n}=f(x)$$ $$f'(x)=1+x+x^2+x^3+...+...=\frac{1}{1-x}$$ $$f(x)=\int f'(x)dx=\int \frac{1}{1-x} dx=-\ln(1-x)+C$$ $$f(0)=1 \Longrightarrow  C=1 $$ $$S=1-\ln(1-x)$$ And here is my problem: I calculated this sum for only $|x|<1$ . Then, I checked in Wolfram Alpha and I saw that, this sum $f(x)$ converges for $x=-1$ . But, this creating a contradiction with my solution. Because, the series $$f'(x)=1+x+x^2+x^3+...+...=\frac{1}{1-x}$$ for $x=-1$ doesn't converge, diverges. Therefore, there is a problem in my solution. But I can not find the source of the problem. How can I prove the formula $f(x)=1-\ln(1-x)$ is also correct at the point $x=-1$ ? Thank you very much.","I want to evaluate this summation: where, Here it is my approach And here is my problem: I calculated this sum for only . Then, I checked in Wolfram Alpha and I saw that, this sum converges for . But, this creating a contradiction with my solution. Because, the series for doesn't converge, diverges. Therefore, there is a problem in my solution. But I can not find the source of the problem. How can I prove the formula is also correct at the point ? Thank you very much.",S=1+x+\frac{x^2}{2}+\frac{x^3}{3}+\frac{x^4}{4}+...+... |x|<1 S=1+\sum_{n=1}^{\infty}\frac{x^n}{n}=f(x) f'(x)=1+x+x^2+x^3+...+...=\frac{1}{1-x} f(x)=\int f'(x)dx=\int \frac{1}{1-x} dx=-\ln(1-x)+C f(0)=1 \Longrightarrow  C=1  S=1-\ln(1-x) |x|<1 f(x) x=-1 f'(x)=1+x+x^2+x^3+...+...=\frac{1}{1-x} x=-1 f(x)=1-\ln(1-x) x=-1,"['calculus', 'sequences-and-series', 'convergence-divergence', 'power-series', 'sequence-of-function']"
67,Limit of sequence $a_1=1$ and $a_{n+1}=\frac{2a_n}{4a_n+1}$,Limit of sequence  and,a_1=1 a_{n+1}=\frac{2a_n}{4a_n+1},"I'm reading Sudhir R. Ghorpade and Balmohan V. Limayes: A Course in Calculus and Real Analysis and ran into a small issue with exercise 9 iii of chapter 2. We are asked to find the limit of the following sequence $$a_1=1$$ $$a_{n+1}=\frac{2a_n}{4a_n+1}$$ To start, I show that $$a_{n+1}-a_n = \frac{2(a_n-a_{n-1})}{(4a_n+1)^2}$$ Now, since $a_n \leq 1$, we have that  $$4a_n+1 \leq 5$$ Which I then use to derive the inequality $$|a_{n+1}-a_n| \leq \frac{2}{25}|a_n - a_{n-1}|$$ This, by an earlier result in the chapter, implies the sequence is Cauchy and therefore convergent. Let $a_n \to a$, then $a_{n+1} \to a$ and we can rewrite  $$a_{n+1}=\frac{2a_n}{4a_n+1}$$ $$a=\frac{2a}{4a+1}$$ Solving for a gives the solutions $0$ and $1/4$. How do I know which one is the right one?","I'm reading Sudhir R. Ghorpade and Balmohan V. Limayes: A Course in Calculus and Real Analysis and ran into a small issue with exercise 9 iii of chapter 2. We are asked to find the limit of the following sequence $$a_1=1$$ $$a_{n+1}=\frac{2a_n}{4a_n+1}$$ To start, I show that $$a_{n+1}-a_n = \frac{2(a_n-a_{n-1})}{(4a_n+1)^2}$$ Now, since $a_n \leq 1$, we have that  $$4a_n+1 \leq 5$$ Which I then use to derive the inequality $$|a_{n+1}-a_n| \leq \frac{2}{25}|a_n - a_{n-1}|$$ This, by an earlier result in the chapter, implies the sequence is Cauchy and therefore convergent. Let $a_n \to a$, then $a_{n+1} \to a$ and we can rewrite  $$a_{n+1}=\frac{2a_n}{4a_n+1}$$ $$a=\frac{2a}{4a+1}$$ Solving for a gives the solutions $0$ and $1/4$. How do I know which one is the right one?",,"['calculus', 'sequences-and-series', 'analysis', 'limits']"
68,Prove or contradict: Between each two solutions of $\arctan x = \sin x$ exists a solution for $1-\cos x = x^2 \cos x$,Prove or contradict: Between each two solutions of  exists a solution for,\arctan x = \sin x 1-\cos x = x^2 \cos x,"Prove or contradict: Between each two solutions of $\arctan x = \sin x$ exists a solution for $1-\cos x = x^2 \cos x$ I have this question in a sample exam and I don't even know what would be a good way to approach this. I though about finding the ranges where the two difference functions have different slopes or something, but I'm not quite sure..","Prove or contradict: Between each two solutions of $\arctan x = \sin x$ exists a solution for $1-\cos x = x^2 \cos x$ I have this question in a sample exam and I don't even know what would be a good way to approach this. I though about finding the ranges where the two difference functions have different slopes or something, but I'm not quite sure..",,"['calculus', 'trigonometry']"
69,Extrema of an infinite product of sinc functions,Extrema of an infinite product of sinc functions,,"Consider the function $$f(x)=\prod_{n=0}^\infty\operatorname{sinc}\left(\frac{\pi \, x}{2^n}\right),\tag1$$ where $\operatorname{sinc}(z)$ denotes the sinc function . It arises as a Fourier transform of the Rvachev $\operatorname{up}(x)$ function, which is basically a shifted version of the Fabius function (see, for example $^{[1]}$ $\!^{[2]}$ $\!^{[3]}$ ). Curiously, if we take a finite partial product from $(1)$ with at least 2 terms, its Fourier transform will be a continuous piecewise-polynomial function with finite support (and with continuous derivatives of progressively higher orders as we include more terms). We restrict our attention only to $x\ge0$. The function $f(x)$ has zeros at positive integers, and oscillates with a quickly decaying amplitude. Its signs on the intervals between consecutive zeros follow the same pattern as the Thue–Morse sequence . It appears that $f(x)$ has exactly one extremum on each interval between consecutive zeros (minimum or maximum, depending on its sign on that interval) — but I have not been able to find a complete rigorous proof of it. Can you propose one? Update: I extracted the second part of my original question into a separate one and edited it significantly. The following is just an interesting observation: Let us denote the value of the extremum on the interval $n<x<n+1$ as $\epsilon_n$. The absolute values of the extrema $|\epsilon_n|$ generally tend to decrease as $n$ increases, but they do not decrease strictly monotonically and, in fact, show quite irregular behavior, sometimes increasing sporadically. Here is how their graph looks on log scale:","Consider the function $$f(x)=\prod_{n=0}^\infty\operatorname{sinc}\left(\frac{\pi \, x}{2^n}\right),\tag1$$ where $\operatorname{sinc}(z)$ denotes the sinc function . It arises as a Fourier transform of the Rvachev $\operatorname{up}(x)$ function, which is basically a shifted version of the Fabius function (see, for example $^{[1]}$ $\!^{[2]}$ $\!^{[3]}$ ). Curiously, if we take a finite partial product from $(1)$ with at least 2 terms, its Fourier transform will be a continuous piecewise-polynomial function with finite support (and with continuous derivatives of progressively higher orders as we include more terms). We restrict our attention only to $x\ge0$. The function $f(x)$ has zeros at positive integers, and oscillates with a quickly decaying amplitude. Its signs on the intervals between consecutive zeros follow the same pattern as the Thue–Morse sequence . It appears that $f(x)$ has exactly one extremum on each interval between consecutive zeros (minimum or maximum, depending on its sign on that interval) — but I have not been able to find a complete rigorous proof of it. Can you propose one? Update: I extracted the second part of my original question into a separate one and edited it significantly. The following is just an interesting observation: Let us denote the value of the extremum on the interval $n<x<n+1$ as $\epsilon_n$. The absolute values of the extrema $|\epsilon_n|$ generally tend to decrease as $n$ increases, but they do not decrease strictly monotonically and, in fact, show quite irregular behavior, sometimes increasing sporadically. Here is how their graph looks on log scale:",,"['calculus', 'sequences-and-series', 'maxima-minima', 'infinite-product']"
70,Let f be a continuous and differentiable function such that f(a)=f(b)=0,Let f be a continuous and differentiable function such that f(a)=f(b)=0,,"Let $f:[a,b] \rightarrow \mathbb{R} $  be a continuous function in $[a,b]$ and differentiable in $(a,b)$   such that $f(a)=f(b)=0$ . Show that $7f(c)+cf'(c)=0$ for some $c \in (a,b)$. I tried to use rolle's theorem and the mean value theorem, but got stuck.  Any hint will be appreciated.","Let $f:[a,b] \rightarrow \mathbb{R} $  be a continuous function in $[a,b]$ and differentiable in $(a,b)$   such that $f(a)=f(b)=0$ . Show that $7f(c)+cf'(c)=0$ for some $c \in (a,b)$. I tried to use rolle's theorem and the mean value theorem, but got stuck.  Any hint will be appreciated.",,['calculus']
71,Asymptotic behaviour of the solution of $\ \ln(x)+e^x=c\ $ for large $c\ $?,Asymptotic behaviour of the solution of  for large ?,\ \ln(x)+e^x=c\  c\ ,"What is the asymptotic behaviour of the solution of the equation $$\ln(x)+e^x=c$$ for large $c$ ? It it clear that $\ln(c)$ is a good approximation. Experimenting with large numbers , I found out that $$\ln(c)-\frac{\ln(\ln(c))}{c}$$ is an excellent approximation. The difference between this number and the solution seems to be of order $O(\frac{1}{c^2})$. A series expansion of the solution for $c\rightarrow\infty$ in terms of $c$ would be vey nice. How can I find the first few terms , lets say upto order $\frac{1}{c^3}$ ?","What is the asymptotic behaviour of the solution of the equation $$\ln(x)+e^x=c$$ for large $c$ ? It it clear that $\ln(c)$ is a good approximation. Experimenting with large numbers , I found out that $$\ln(c)-\frac{\ln(\ln(c))}{c}$$ is an excellent approximation. The difference between this number and the solution seems to be of order $O(\frac{1}{c^2})$. A series expansion of the solution for $c\rightarrow\infty$ in terms of $c$ would be vey nice. How can I find the first few terms , lets say upto order $\frac{1}{c^3}$ ?",,"['calculus', 'sequences-and-series', 'asymptotics']"
72,Show that for $a_i>0$ $\frac{a_1+\cdots+a_n}{n}$ converges to $0$ if and only if $\frac{a_1^2+\cdots+a_n^2}{n}$ converges to $0$.,Show that for   converges to  if and only if  converges to .,a_i>0 \frac{a_1+\cdots+a_n}{n} 0 \frac{a_1^2+\cdots+a_n^2}{n} 0,"Let $\{a_n\}$ be a bounded and positive sequence. Show that $$\lim_{n\to \infty}\frac{a_1+\cdots+a_n}{n}=0$$ if and only if $$\lim_{n\to \infty}\frac{a_1^2+\cdots+a_n^2}{n}=0.$$ My attempt: The ""$\Rightarrow$"" is obvious. Note that  $$\frac{a_1^2+\cdots+a_n^2}{n}\leq |M|\cdot\frac{a_1+\cdots+a_n}{n} $$ where $|M|$ is the bound of the sequence. So the convergence of the right side implies the convergence of the left side. As for the converse direction, I really have no idea... @kimchi lover points out using the Cauchy-Schwarz inequality and I had the following attempt... $$\frac{a_1+\cdots+a_n}{n}=\frac{\frac{1}{\sqrt{n}}(a_1+\cdots+a_n)}{\frac{1}{\sqrt{n}}n}\leq \frac{(a_1^2+\cdots+a_n^2)(\frac{1}{n}+\cdots+\frac{1}{n})}{\sqrt{n}}$$","Let $\{a_n\}$ be a bounded and positive sequence. Show that $$\lim_{n\to \infty}\frac{a_1+\cdots+a_n}{n}=0$$ if and only if $$\lim_{n\to \infty}\frac{a_1^2+\cdots+a_n^2}{n}=0.$$ My attempt: The ""$\Rightarrow$"" is obvious. Note that  $$\frac{a_1^2+\cdots+a_n^2}{n}\leq |M|\cdot\frac{a_1+\cdots+a_n}{n} $$ where $|M|$ is the bound of the sequence. So the convergence of the right side implies the convergence of the left side. As for the converse direction, I really have no idea... @kimchi lover points out using the Cauchy-Schwarz inequality and I had the following attempt... $$\frac{a_1+\cdots+a_n}{n}=\frac{\frac{1}{\sqrt{n}}(a_1+\cdots+a_n)}{\frac{1}{\sqrt{n}}n}\leq \frac{(a_1^2+\cdots+a_n^2)(\frac{1}{n}+\cdots+\frac{1}{n})}{\sqrt{n}}$$",,"['calculus', 'sequences-and-series', 'limits']"
73,"$\int_{0}^{\frac{\pi}{2}}\frac{d\theta}{a + \sin^2(\theta)} = \frac{\pi}{2\sqrt{a(a+1)}}$, for $a > 0$",", for",\int_{0}^{\frac{\pi}{2}}\frac{d\theta}{a + \sin^2(\theta)} = \frac{\pi}{2\sqrt{a(a+1)}} a > 0,"I want to show that $$\int_{0}^{\frac{\pi}{2}}\frac{d\theta}{a + \sin^2(\theta)} = \frac{\pi}{2\sqrt{a(a+1)}}$$ for $a > 0$ . I try several methods Substitutions to rationalize The famous $U = \tan(\frac{\theta}{2})$ Multiplying by conjugates and other calculus techniques and still, I can not prove the equality. Anyone can give me a hint of how should I begin to work this integral? I'm very ashamed that I can not solve this problem.","I want to show that for . I try several methods Substitutions to rationalize The famous Multiplying by conjugates and other calculus techniques and still, I can not prove the equality. Anyone can give me a hint of how should I begin to work this integral? I'm very ashamed that I can not solve this problem.",\int_{0}^{\frac{\pi}{2}}\frac{d\theta}{a + \sin^2(\theta)} = \frac{\pi}{2\sqrt{a(a+1)}} a > 0 U = \tan(\frac{\theta}{2}),"['calculus', 'integration', 'definite-integrals', 'trigonometric-integrals']"
74,Calculate $\lim_{x\to a}(2-\frac{x}{a} )^{\tan( \frac{\pi x}{2a})}$,Calculate,\lim_{x\to a}(2-\frac{x}{a} )^{\tan( \frac{\pi x}{2a})},"I would like to calculate    $$\lim\limits_{x\to a}\left(2-\dfrac{x}{a} \right)^{\tan\left( \dfrac{\pi x}{2a}\right)},\quad a \in\mathbb{R}^* \,\,\text{fixed} $$ we've  $$\left(2-\dfrac{x}{a} \right)^{\tan\left( \dfrac{\pi x}{2a}\right)}=e^{\tan\left( \dfrac{\pi x}{2a}\right)\ln\left(2-\dfrac{x}{a} \right)}.$$ Note that: $$\ln\left(2-\dfrac{x}{a} \right)\sim_{a}1-\dfrac{x}{2}.$$ Now we have $\dfrac{\pi x}{2a}\underset{x\to a}{\longrightarrow} \dfrac{\pi}{2}$, i.e.$\dfrac{\pi x}{2a}-\dfrac{\pi}{2}  \underset{x\to a}{\longrightarrow} 0$ and $\tan h \sim_{0}h.$ I'm stuck. Update: here is another way : \begin{aligned} \left(2-\dfrac{x}{a} \right)^{\tan\left( \dfrac{\pi x}{2a}\right)}&=\exp\left[{\tan\left( \dfrac{\pi x}{2a}\right)\ln\left(2-\dfrac{x}{a} \right)}\right].\\ &=\exp\left[ \left(1-\dfrac{x}{a}\right)\tan\left(\dfrac{\pi x}{2a}-\dfrac{\pi}{2}+\dfrac{\pi}{2} \right).\dfrac{\ln\left(2-\dfrac{x}{a} \right)}{1-\dfrac{x}{a}}\right]\\ &=\exp\left[ -\dfrac{\left(1-\dfrac{x}{a} \right)}{\tan\left(\dfrac{\pi x}{2a}-\dfrac{\pi}{2} \right)}.\dfrac{\ln\left(2-\dfrac{x}{a} \right)}{\left(1-\dfrac{x}{a}\right)}\right]\\ &=\exp\left[ -\dfrac{\left(1-\dfrac{x}{a} \right)}{\tan\left(-\dfrac{\pi}{2}\left(1-\dfrac{x}{a} \right)\right)}.\dfrac{\ln\left(2-\dfrac{x}{a} \right)}{\left(1-\dfrac{x}{a}\right)}\right]\\ &=\exp\left[ \dfrac{2}{\pi} \dfrac{\dfrac{\pi}{2}\left(1-\dfrac{x}{a} \right)}{\tan\left(\dfrac{\pi}{2}\left(1-\dfrac{x}{a} \right)\right)}.\dfrac{\ln\left(2-\dfrac{x}{a} \right)}{\left(1-\dfrac{x}{a}\right)}\right]\\ \end{aligned} Thus  $$\lim\limits_{x\to a}\left(2-\dfrac{x}{a} \right)^{\tan\left(\dfrac{\pi x}{2a}\right)}  =e^{\dfrac{2}{\pi}} $$ Am i right beside i'm intersted in way which use equivalents","I would like to calculate    $$\lim\limits_{x\to a}\left(2-\dfrac{x}{a} \right)^{\tan\left( \dfrac{\pi x}{2a}\right)},\quad a \in\mathbb{R}^* \,\,\text{fixed} $$ we've  $$\left(2-\dfrac{x}{a} \right)^{\tan\left( \dfrac{\pi x}{2a}\right)}=e^{\tan\left( \dfrac{\pi x}{2a}\right)\ln\left(2-\dfrac{x}{a} \right)}.$$ Note that: $$\ln\left(2-\dfrac{x}{a} \right)\sim_{a}1-\dfrac{x}{2}.$$ Now we have $\dfrac{\pi x}{2a}\underset{x\to a}{\longrightarrow} \dfrac{\pi}{2}$, i.e.$\dfrac{\pi x}{2a}-\dfrac{\pi}{2}  \underset{x\to a}{\longrightarrow} 0$ and $\tan h \sim_{0}h.$ I'm stuck. Update: here is another way : \begin{aligned} \left(2-\dfrac{x}{a} \right)^{\tan\left( \dfrac{\pi x}{2a}\right)}&=\exp\left[{\tan\left( \dfrac{\pi x}{2a}\right)\ln\left(2-\dfrac{x}{a} \right)}\right].\\ &=\exp\left[ \left(1-\dfrac{x}{a}\right)\tan\left(\dfrac{\pi x}{2a}-\dfrac{\pi}{2}+\dfrac{\pi}{2} \right).\dfrac{\ln\left(2-\dfrac{x}{a} \right)}{1-\dfrac{x}{a}}\right]\\ &=\exp\left[ -\dfrac{\left(1-\dfrac{x}{a} \right)}{\tan\left(\dfrac{\pi x}{2a}-\dfrac{\pi}{2} \right)}.\dfrac{\ln\left(2-\dfrac{x}{a} \right)}{\left(1-\dfrac{x}{a}\right)}\right]\\ &=\exp\left[ -\dfrac{\left(1-\dfrac{x}{a} \right)}{\tan\left(-\dfrac{\pi}{2}\left(1-\dfrac{x}{a} \right)\right)}.\dfrac{\ln\left(2-\dfrac{x}{a} \right)}{\left(1-\dfrac{x}{a}\right)}\right]\\ &=\exp\left[ \dfrac{2}{\pi} \dfrac{\dfrac{\pi}{2}\left(1-\dfrac{x}{a} \right)}{\tan\left(\dfrac{\pi}{2}\left(1-\dfrac{x}{a} \right)\right)}.\dfrac{\ln\left(2-\dfrac{x}{a} \right)}{\left(1-\dfrac{x}{a}\right)}\right]\\ \end{aligned} Thus  $$\lim\limits_{x\to a}\left(2-\dfrac{x}{a} \right)^{\tan\left(\dfrac{\pi x}{2a}\right)}  =e^{\dfrac{2}{\pi}} $$ Am i right beside i'm intersted in way which use equivalents",,"['calculus', 'limits', 'proof-verification', 'asymptotics', 'alternative-proof']"
75,How may we show that $\int_{0}^{\infty}{e^x+e^{-x}-3\over (e^x+e^{-x})^2-1}\cdot \ln(x)\mathrm dx={\pi \ln(2)\over 3\sqrt{3}}?$,How may we show that,\int_{0}^{\infty}{e^x+e^{-x}-3\over (e^x+e^{-x})^2-1}\cdot \ln(x)\mathrm dx={\pi \ln(2)\over 3\sqrt{3}}?,Consider $(1)$ $$\int_{0}^{\infty}{e^x+e^{-x}-3\over (e^x+e^{-x})^2-1}\cdot \ln(x)\mathrm dx={\pi \ln(2)\over 3\sqrt{3}}\tag1$$ My try: $x=-\ln(t)$ then $(1)$ becomes $$\int_{0}^{1}{t^2-3t+1\over 2t+1}\cdot{\ln(-\ln t)}\mathrm dt\tag2$$ Split $(2):$ $$\color{blue}{\int_{0}^{1}{\ln(-\ln t)}\mathrm dt}+\int_{0}^{1}{t^2-5t\over 2t+1}\cdot{\ln(-\ln t)}\mathrm dt\tag3$$ $$\color{blue}{\gamma}+\int_{0}^{1}{t^2-5t\over 2t+1}\cdot{\ln(-\ln t)}\mathrm dt\tag4$$ Where $\gamma$ is Euler-Mascheroni Constant . How may we prove $(1)?$,Consider $(1)$ $$\int_{0}^{\infty}{e^x+e^{-x}-3\over (e^x+e^{-x})^2-1}\cdot \ln(x)\mathrm dx={\pi \ln(2)\over 3\sqrt{3}}\tag1$$ My try: $x=-\ln(t)$ then $(1)$ becomes $$\int_{0}^{1}{t^2-3t+1\over 2t+1}\cdot{\ln(-\ln t)}\mathrm dt\tag2$$ Split $(2):$ $$\color{blue}{\int_{0}^{1}{\ln(-\ln t)}\mathrm dt}+\int_{0}^{1}{t^2-5t\over 2t+1}\cdot{\ln(-\ln t)}\mathrm dt\tag3$$ $$\color{blue}{\gamma}+\int_{0}^{1}{t^2-5t\over 2t+1}\cdot{\ln(-\ln t)}\mathrm dt\tag4$$ Where $\gamma$ is Euler-Mascheroni Constant . How may we prove $(1)?$,,"['calculus', 'integration', 'definite-integrals']"
76,"How do we find closed form of $\int_{0}^{1}{\sqrt{x^n\over 1-x^m}}\mathrm dx=F(n,m)?$",How do we find closed form of,"\int_{0}^{1}{\sqrt{x^n\over 1-x^m}}\mathrm dx=F(n,m)?","Consider this integral Motivated by this question $$\int_{0}^{1}{\sqrt{x^n\over 1-x^m}}\mathrm dx=F(n,m)\tag1$$   Where $n\ge -1$ and $m\ge 1$ We note the following values for $F(n,m):$ $$F(-1,1)=\pi$$ $$F(1,1)={\pi\over 2}$$ $$F(1,3)={\pi\over 3}$$ Where $k $ is an integer, what are other values of $ n$ and $m$ that will give ${\pi\over k}$? I guess to answer this question we have to find the closed form for $(1)$","Consider this integral Motivated by this question $$\int_{0}^{1}{\sqrt{x^n\over 1-x^m}}\mathrm dx=F(n,m)\tag1$$   Where $n\ge -1$ and $m\ge 1$ We note the following values for $F(n,m):$ $$F(-1,1)=\pi$$ $$F(1,1)={\pi\over 2}$$ $$F(1,3)={\pi\over 3}$$ Where $k $ is an integer, what are other values of $ n$ and $m$ that will give ${\pi\over k}$? I guess to answer this question we have to find the closed form for $(1)$",,"['calculus', 'integration', 'definite-integrals']"
77,Is the product of two derivative functions still a derivative function?,Is the product of two derivative functions still a derivative function?,,"Is the product of two derivative functions still a derivative function? I.e., given two differentiable functions $f$ and $g$, is there always a differentiable function $k$ with $f'g'= k'$  ?","Is the product of two derivative functions still a derivative function? I.e., given two differentiable functions $f$ and $g$, is there always a differentiable function $k$ with $f'g'= k'$  ?",,"['calculus', 'derivatives']"
78,Taylor expansion using stirling's approximation,Taylor expansion using stirling's approximation,,"This is from a statistical physics problem, but it is the mathematics behind it that I am stuck on here: Consider a large number $N$ of distinguishable particles distributed   among $M$ boxes. We know that the total number of possible microstates is   $$\Omega=M^N$$  and that the number of microstates with a distribution   among the boxes given by the configuration $[n_1, n_2, ..., n_M]$ is   given by $$\frac{N!}{\prod_{j=1}^M (n_j)!}\tag{1}$$    In the most likely configuration there are $$n_0 = \frac{N}{M}$$ particles in each box. Let $\Omega_0$ denote the statistical weight of this configuration and $p_0$ its probability. Now consider moving $\delta n$ particles from box $1$ to box $2$, giving the new configuration   $$[n_0 − δn, n_0 + δn, n_0, n_0, ..., n_0]$$   Show that $$\fbox{$\color{blue}{\delta\left(\ln\Omega_{\{n\}}\right)\approx -\delta n\ln (n_0)-\frac{(\delta n)^2}{2 n_0}}$}$$   (Hint: you should use Stirling’s approximation here) The image below shows the situation: Here is the answer as written by the author: This might be a bit hard to read so I have typed it out word for word below: $$\ln\Omega_{\{n\}}=\ln(N!)-\sum_j\ln (n_j!)$$   The change in $\ln\Omega$ due to a change $\delta n$ in ONE box is   $$\delta(\ln\Omega_{\{n\}})=-\ln([n_0+\delta_n]!)+\ln(n_0!)$$   Taylor expand $\ln (n!)$ $\color{red}{\text{(To second 2nd order since we are already at a maximum for}}$ $\color{red}{\ln\Omega_{\{n\}}}$$\color{red}{)}$ using Stirling:   $$\ln (n!)\approx \underbrace{n_0\ln (n_0)-n_0}_{0th}+\underbrace{\ln (n_0)\cdot\delta_n}_{1st}+\underbrace{\frac{(\delta n)^2}{2n_0}}_{2nd}+\cdots$$   $$\implies \delta(\ln\Omega_{\{n\}})=-\ln (n_0)\cdot\delta n-\frac{(\delta n)^2}{2n_0}$$ The red bracket can be ignored as it was just used in the previous part of the question where we had to show that $$n_0=\frac{N}{M}$$ is the most likely configuration which we did my differentiating and setting to zero to maximize. Finally I get to my question: I understand everything up to the point where it says ""Taylor expand $\ln n!$"", firstly where on earth is $n$ even defined? I see $n_0$ and $N$ but not $n$. I can only assume that the author meant 'Taylor expand $\ln([n_0+\delta_n]!)$' since I fail to see how that expression could ever get the factors $n_0$ and $\delta_n$. I know that the general Taylor expansion formula is given by  $$f(a)+\frac {f'(a)}{1!} (x-a)+ \frac{f''(a)}{2!} (x-a)^2+\frac{f^{(3)}(a)}{3!}(x-a)^3+ \cdots$$ and that Stirlings approximation is as follows $$\ln(k!)\approx k\ln k - k +\frac12\ln k$$ I have used both these formulae, but not both together. I'm very confused about how to proceed with this, so I naively apply Stirlings approximation first: $$\ln([n+\delta n]!)\approx (n+\delta n)\ln(n+\delta n)-(n+\delta n)+\frac12\ln(n+\delta n)$$ But now I am completely stuck. Could someone please explain how the author was able to reach the result? EDIT: A comment below raised an important point. So I will just mention that for the purposes of this question the statistical weight $\Omega$ is equal to the number of microstates . EDIT#2: I must apologize there was a contradiction in my question due to a typo. What I needed to show was that $$\fbox{$\color{blue}{\delta\left(\ln\Omega_{\{n\}}\right)\approx -\delta n\ln (n_0)-\frac{(\delta n^2)}{2 n_0}}$}$$ and this is given in blue in the first quotation box, very sorry about this. EDIT#3: I acknowledge that those of you that answered actually figured out that there must be a similar expression when considering both boxes. So as promised here is part 2 of the question as written by the author: I'll type it word for word again anyway just in case it's hard to read: For a change to TWO boxes, moving $\delta n$ from $1$ to $2$,   $$\delta\left(\ln\Omega_{\{n\}}\right)=-\ln (n_0)\cdot(-\delta n)-\frac{\left(-\delta n\right)^2}{2n_0}$$   $$\qquad\qquad\qquad\qquad\qquad-\ln (n_0)\cdot(+\delta n)-\frac{\left(+\delta n\right)^2}{2n_0}=-\frac{\delta n^2}{n_0}$$   $$\color{red}{\Huge{\star}}\quad\ln\Omega_{\{n\}}=\ln\Omega_0-\frac{\delta n^2}{n_0}$$ Many thanks.","This is from a statistical physics problem, but it is the mathematics behind it that I am stuck on here: Consider a large number $N$ of distinguishable particles distributed   among $M$ boxes. We know that the total number of possible microstates is   $$\Omega=M^N$$  and that the number of microstates with a distribution   among the boxes given by the configuration $[n_1, n_2, ..., n_M]$ is   given by $$\frac{N!}{\prod_{j=1}^M (n_j)!}\tag{1}$$    In the most likely configuration there are $$n_0 = \frac{N}{M}$$ particles in each box. Let $\Omega_0$ denote the statistical weight of this configuration and $p_0$ its probability. Now consider moving $\delta n$ particles from box $1$ to box $2$, giving the new configuration   $$[n_0 − δn, n_0 + δn, n_0, n_0, ..., n_0]$$   Show that $$\fbox{$\color{blue}{\delta\left(\ln\Omega_{\{n\}}\right)\approx -\delta n\ln (n_0)-\frac{(\delta n)^2}{2 n_0}}$}$$   (Hint: you should use Stirling’s approximation here) The image below shows the situation: Here is the answer as written by the author: This might be a bit hard to read so I have typed it out word for word below: $$\ln\Omega_{\{n\}}=\ln(N!)-\sum_j\ln (n_j!)$$   The change in $\ln\Omega$ due to a change $\delta n$ in ONE box is   $$\delta(\ln\Omega_{\{n\}})=-\ln([n_0+\delta_n]!)+\ln(n_0!)$$   Taylor expand $\ln (n!)$ $\color{red}{\text{(To second 2nd order since we are already at a maximum for}}$ $\color{red}{\ln\Omega_{\{n\}}}$$\color{red}{)}$ using Stirling:   $$\ln (n!)\approx \underbrace{n_0\ln (n_0)-n_0}_{0th}+\underbrace{\ln (n_0)\cdot\delta_n}_{1st}+\underbrace{\frac{(\delta n)^2}{2n_0}}_{2nd}+\cdots$$   $$\implies \delta(\ln\Omega_{\{n\}})=-\ln (n_0)\cdot\delta n-\frac{(\delta n)^2}{2n_0}$$ The red bracket can be ignored as it was just used in the previous part of the question where we had to show that $$n_0=\frac{N}{M}$$ is the most likely configuration which we did my differentiating and setting to zero to maximize. Finally I get to my question: I understand everything up to the point where it says ""Taylor expand $\ln n!$"", firstly where on earth is $n$ even defined? I see $n_0$ and $N$ but not $n$. I can only assume that the author meant 'Taylor expand $\ln([n_0+\delta_n]!)$' since I fail to see how that expression could ever get the factors $n_0$ and $\delta_n$. I know that the general Taylor expansion formula is given by  $$f(a)+\frac {f'(a)}{1!} (x-a)+ \frac{f''(a)}{2!} (x-a)^2+\frac{f^{(3)}(a)}{3!}(x-a)^3+ \cdots$$ and that Stirlings approximation is as follows $$\ln(k!)\approx k\ln k - k +\frac12\ln k$$ I have used both these formulae, but not both together. I'm very confused about how to proceed with this, so I naively apply Stirlings approximation first: $$\ln([n+\delta n]!)\approx (n+\delta n)\ln(n+\delta n)-(n+\delta n)+\frac12\ln(n+\delta n)$$ But now I am completely stuck. Could someone please explain how the author was able to reach the result? EDIT: A comment below raised an important point. So I will just mention that for the purposes of this question the statistical weight $\Omega$ is equal to the number of microstates . EDIT#2: I must apologize there was a contradiction in my question due to a typo. What I needed to show was that $$\fbox{$\color{blue}{\delta\left(\ln\Omega_{\{n\}}\right)\approx -\delta n\ln (n_0)-\frac{(\delta n^2)}{2 n_0}}$}$$ and this is given in blue in the first quotation box, very sorry about this. EDIT#3: I acknowledge that those of you that answered actually figured out that there must be a similar expression when considering both boxes. So as promised here is part 2 of the question as written by the author: I'll type it word for word again anyway just in case it's hard to read: For a change to TWO boxes, moving $\delta n$ from $1$ to $2$,   $$\delta\left(\ln\Omega_{\{n\}}\right)=-\ln (n_0)\cdot(-\delta n)-\frac{\left(-\delta n\right)^2}{2n_0}$$   $$\qquad\qquad\qquad\qquad\qquad-\ln (n_0)\cdot(+\delta n)-\frac{\left(+\delta n\right)^2}{2n_0}=-\frac{\delta n^2}{n_0}$$   $$\color{red}{\Huge{\star}}\quad\ln\Omega_{\{n\}}=\ln\Omega_0-\frac{\delta n^2}{n_0}$$ Many thanks.",,"['calculus', 'derivatives', 'taylor-expansion', 'approximation', 'statistical-mechanics']"
79,Integral $\int (\cot^{2}x+\cot^{4}x)\mathrm{d}x$,Integral,\int (\cot^{2}x+\cot^{4}x)\mathrm{d}x,"I am having difficulties with integrating this function: $$\int (\cot^{2}x+\cot^{4}x)\mathrm{d}x$$ I separated the function in two and calculated $\int \cot^2x\mathrm{d}x$ : $$\int \cot^2x\mathrm{d}x=\int (-1+1+\cot^2x)\mathrm{d}x=-\int \mathrm{d}x+\int (1+\cot^2x)\mathrm{d}x=-x-\cot x+c$$ But I don't know how to deal with $\int \cot^4x\mathrm{d}x$ . I assume that there is a shorter solution somewhere but I'm not sure. In addition, this is a high school level question, I'm only familiar with primitives of simple functions, integration by parts and trigonometric replacement. Any help would be appreciated, thanks in advance. Solution $$\int (\cot^{2}x+\cot^{4}x)\mathrm{d}x=\int \cot^{2}x\cdot(\cot^{2}x+1)\mathrm{d}x=\int (\cot^{2}x\cdot\csc^{2}x)\mathrm{d}x$$ Let's assume $u:=\cot x$ Then $\mathrm{d}u=-\csc^2x\mathrm{d}x$ . So we have: $$\int (\cot^{2}x\cdot\csc^{2}x)\mathrm{d}x=-\int u^2\mathrm{d}u=-\frac{u^3}{3}+c=-\frac{\cot^2x}{3}+c$$ N. S. and MyGlasses, thank you for your help.","I am having difficulties with integrating this function: I separated the function in two and calculated : But I don't know how to deal with . I assume that there is a shorter solution somewhere but I'm not sure. In addition, this is a high school level question, I'm only familiar with primitives of simple functions, integration by parts and trigonometric replacement. Any help would be appreciated, thanks in advance. Solution Let's assume Then . So we have: N. S. and MyGlasses, thank you for your help.",\int (\cot^{2}x+\cot^{4}x)\mathrm{d}x \int \cot^2x\mathrm{d}x \int \cot^2x\mathrm{d}x=\int (-1+1+\cot^2x)\mathrm{d}x=-\int \mathrm{d}x+\int (1+\cot^2x)\mathrm{d}x=-x-\cot x+c \int \cot^4x\mathrm{d}x \int (\cot^{2}x+\cot^{4}x)\mathrm{d}x=\int \cot^{2}x\cdot(\cot^{2}x+1)\mathrm{d}x=\int (\cot^{2}x\cdot\csc^{2}x)\mathrm{d}x u:=\cot x \mathrm{d}u=-\csc^2x\mathrm{d}x \int (\cot^{2}x\cdot\csc^{2}x)\mathrm{d}x=-\int u^2\mathrm{d}u=-\frac{u^3}{3}+c=-\frac{\cot^2x}{3}+c,"['calculus', 'integration', 'indefinite-integrals']"
80,"Two limits involving integrals: $\lim_{\varepsilon\to 0^+}\left(\int_0^{1-\varepsilon}\frac{\ln (1-x)}{x\ln^p x}dx-f_p(\varepsilon)\right)$, $p=1,2$.","Two limits involving integrals: , .","\lim_{\varepsilon\to 0^+}\left(\int_0^{1-\varepsilon}\frac{\ln (1-x)}{x\ln^p x}dx-f_p(\varepsilon)\right) p=1,2","By applying the Taylor series expansion to $\ln x$, as $x \to 1$, one has the Laurent series expansion,  $$ \frac1{\ln x}=-\frac1{1-x}+\frac{1}{2}+O\left(1-x\right) $$ then clearly $$ \begin{align} &\lim_{\varepsilon \to 0^+} \int_0^{1-\varepsilon} \frac{\ln (1-x)}{x\ln x}\:dx=\infty  \\\\&\lim_{\varepsilon \to 0^+} \int_0^{1-\varepsilon} \frac{\ln (1-x)}{x\ln^2 x}\:dx=-\infty. \end{align} $$ Thus I'm designing the following related limits. Question . Find $f_1(\varepsilon)$, $f_2(\varepsilon)$ and find a closed form of $c_1$, $c_2$ such that   $$ \begin{align} &\lim_{\varepsilon \to 0^+} \left(\int_0^{1-\varepsilon} \frac{\ln (1-x)}{x\ln x}\:dx-f_1(\varepsilon)\right)=c_1  \tag1 \\\\& \lim_{\varepsilon \to 0^+} \left(\int_0^{1-\varepsilon} \frac{\ln (1-x)}{x\ln^2 x}\:dx-f_2(\varepsilon)\right)=c_2. \tag2 \end{align} $$ Edit . A complete answer is now given below.","By applying the Taylor series expansion to $\ln x$, as $x \to 1$, one has the Laurent series expansion,  $$ \frac1{\ln x}=-\frac1{1-x}+\frac{1}{2}+O\left(1-x\right) $$ then clearly $$ \begin{align} &\lim_{\varepsilon \to 0^+} \int_0^{1-\varepsilon} \frac{\ln (1-x)}{x\ln x}\:dx=\infty  \\\\&\lim_{\varepsilon \to 0^+} \int_0^{1-\varepsilon} \frac{\ln (1-x)}{x\ln^2 x}\:dx=-\infty. \end{align} $$ Thus I'm designing the following related limits. Question . Find $f_1(\varepsilon)$, $f_2(\varepsilon)$ and find a closed form of $c_1$, $c_2$ such that   $$ \begin{align} &\lim_{\varepsilon \to 0^+} \left(\int_0^{1-\varepsilon} \frac{\ln (1-x)}{x\ln x}\:dx-f_1(\varepsilon)\right)=c_1  \tag1 \\\\& \lim_{\varepsilon \to 0^+} \left(\int_0^{1-\varepsilon} \frac{\ln (1-x)}{x\ln^2 x}\:dx-f_2(\varepsilon)\right)=c_2. \tag2 \end{align} $$ Edit . A complete answer is now given below.",,"['calculus', 'integration', 'limits', 'definite-integrals', 'improper-integrals']"
81,$\int \frac{\sqrt{x}}{x-1}dx $,,\int \frac{\sqrt{x}}{x-1}dx ,"I wished to solve $$\int \frac{\sqrt{x}}{x-1}dx \tag{1}$$ through hyperbolic trig substitution. My work is as follows: Let $\sqrt{x}=\tanh (\theta)$. Then $(1)$ becomes $$\int -2\tanh^2(\theta)\ d\theta=-2\theta+2\tanh(\theta) +C.$$ Subbing back in yields $$-2\text{arctanh}\big(\sqrt{x}\big)+2\sqrt{x} +C. $$ Using $$\text{arctanh}(m)=\frac{1}{2}\ln\Big(\frac{1+m}{1-m} \Big) $$ I arrive at the answer $$2\sqrt{x}+\ln\Big(\frac{1-\sqrt{x}}{1+\sqrt{x}} \Big) +C. $$ However, the answer key and other integration methods suggest the answer $$ 2\sqrt{x}+\ln\Big(\frac{\sqrt{x}-1}{1+\sqrt{x}} \Big) +C. $$ Where did I go wrong?","I wished to solve $$\int \frac{\sqrt{x}}{x-1}dx \tag{1}$$ through hyperbolic trig substitution. My work is as follows: Let $\sqrt{x}=\tanh (\theta)$. Then $(1)$ becomes $$\int -2\tanh^2(\theta)\ d\theta=-2\theta+2\tanh(\theta) +C.$$ Subbing back in yields $$-2\text{arctanh}\big(\sqrt{x}\big)+2\sqrt{x} +C. $$ Using $$\text{arctanh}(m)=\frac{1}{2}\ln\Big(\frac{1+m}{1-m} \Big) $$ I arrive at the answer $$2\sqrt{x}+\ln\Big(\frac{1-\sqrt{x}}{1+\sqrt{x}} \Big) +C. $$ However, the answer key and other integration methods suggest the answer $$ 2\sqrt{x}+\ln\Big(\frac{\sqrt{x}-1}{1+\sqrt{x}} \Big) +C. $$ Where did I go wrong?",,['calculus']
82,Any hints on how to prove that $\ln{1\over 2\sin\left({90\over \pi}\right)}=\sum_{n=1}^{\infty}{(-1)^{n-1}B_{2n}\over 2n(2n)!}$?,Any hints on how to prove that ?,\ln{1\over 2\sin\left({90\over \pi}\right)}=\sum_{n=1}^{\infty}{(-1)^{n-1}B_{2n}\over 2n(2n)!},"How do you prove that $$ \ln\left(1 \over 2\sin\left(1/2\right)\right) = \sum_{n = 1}^{\infty}{\left(-1\right)^{n - 1}\,B_{2n} \over 2n\left(2n\right)!}\ ?\tag1 $$ where $B_{2n}$ is a Bernoulli number Any hints?","How do you prove that $$ \ln\left(1 \over 2\sin\left(1/2\right)\right) = \sum_{n = 1}^{\infty}{\left(-1\right)^{n - 1}\,B_{2n} \over 2n\left(2n\right)!}\ ?\tag1 $$ where $B_{2n}$ is a Bernoulli number Any hints?",,"['calculus', 'sequences-and-series']"
83,How to integrate $\frac{dx}{(x-p)\sqrt {(x-p)(x-q)}} $?,How to integrate ?,\frac{dx}{(x-p)\sqrt {(x-p)(x-q)}} ,How to integrate $\frac{dx}{(x-p)\sqrt {(x-p)(x-q)}} $ ? I tried substituting $x=1/t$ but that's making it more complicated. Any suggestions?,How to integrate $\frac{dx}{(x-p)\sqrt {(x-p)(x-q)}} $ ? I tried substituting $x=1/t$ but that's making it more complicated. Any suggestions?,,['calculus']
84,Prove the convergence and find the sum of series $\sum\limits_{n=1}^{\infty}\left(n^3\sin\frac{\pi}{3^n}\right)$.,Prove the convergence and find the sum of series .,\sum\limits_{n=1}^{\infty}\left(n^3\sin\frac{\pi}{3^n}\right),"We know that $0<\sin\frac{\pi}{3^n}\le\frac{\sqrt 3}{2},\forall n\ge 1$. How to find the boundary for $n^3\sin\frac{\pi}{3^n}$ (how to use comparison test here)? I tried using the ratio test, but the limit $$\lim\limits_{n\to\infty}\left((n+1)^3\sin\frac{\pi}{3^{n+1}}\cdot \frac{1}{n^3\sin\frac{\pi}{3^n}}\right)$$ isn't that easy to evaluate.","We know that $0<\sin\frac{\pi}{3^n}\le\frac{\sqrt 3}{2},\forall n\ge 1$. How to find the boundary for $n^3\sin\frac{\pi}{3^n}$ (how to use comparison test here)? I tried using the ratio test, but the limit $$\lim\limits_{n\to\infty}\left((n+1)^3\sin\frac{\pi}{3^{n+1}}\cdot \frac{1}{n^3\sin\frac{\pi}{3^n}}\right)$$ isn't that easy to evaluate.",,"['calculus', 'sequences-and-series', 'convergence-divergence']"
85,derivative on endpoints,derivative on endpoints,,"what's the derivative of $f(x)= x^{2}$ ($x\geq 0$) when x=0? from my understand, it doesn't exist because even $\lim_{h \to 0^{+}}\frac{f(x+h)-f(x)}{h}$ is 0, but  $\lim_{h \to 0^{-}}\frac{f(x+h)-f(x)}{h}$ doesn't exist, am I correct?","what's the derivative of $f(x)= x^{2}$ ($x\geq 0$) when x=0? from my understand, it doesn't exist because even $\lim_{h \to 0^{+}}\frac{f(x+h)-f(x)}{h}$ is 0, but  $\lim_{h \to 0^{-}}\frac{f(x+h)-f(x)}{h}$ doesn't exist, am I correct?",,"['calculus', 'derivatives']"
86,Prove $\int_0^\infty \frac{x^{k-1} + x^{-k-1}}{x^a + x^{-a}}dx = \frac{\pi}{a \cos(\frac{\pi k}{2a})}$.,Prove .,\int_0^\infty \frac{x^{k-1} + x^{-k-1}}{x^a + x^{-a}}dx = \frac{\pi}{a \cos(\frac{\pi k}{2a})},"I need help in proving this identity $$\int_0^\infty \frac{x^{k-1} + x^{-k-1}}{x^a + x^{-a}}dx = \frac{\pi}{a \cos(\frac{\pi k}{2a})}$$ for $0<k<a.$ It might be done using residues, but I don't know which contour to choose.","I need help in proving this identity $$\int_0^\infty \frac{x^{k-1} + x^{-k-1}}{x^a + x^{-a}}dx = \frac{\pi}{a \cos(\frac{\pi k}{2a})}$$ for $0<k<a.$ It might be done using residues, but I don't know which contour to choose.",,"['calculus', 'integration', 'definite-integrals', 'closed-form']"
87,Infinite product equality $\prod_{n=1}^{\infty} \left(1-x^n+x^{2n}\right) = \prod_{n=1}^{\infty} \frac1{1+x^{2n-1}+x^{4n-2}}$,Infinite product equality,\prod_{n=1}^{\infty} \left(1-x^n+x^{2n}\right) = \prod_{n=1}^{\infty} \frac1{1+x^{2n-1}+x^{4n-2}},"Prove the following equation ($|x|<1$) $$\prod_{n=1}^{\infty} \left(1-x^n+x^{2n}\right) = \prod_{n=1}^{\infty} \frac1{1+x^{2n-1}+x^{4n-2}}$$ I made this question and I have the following answer but I think it may be incomplete. If anyone can point out a flaw in my proof or give a better proof then it would be appreciated. My solution: $$\begin{align} &f(x)=\prod_{n=1}^{\infty} \left(1-x^n+x^{2n}\right)\\ &N(p,q)=\{n\in\mathbb N \mid n\ne (2m-1)2^{k-1};m,k\in\mathbb N,2m-1\leq p,k\leq q\}\\ &f(x)(1+x+x^2)=(1+x+x^2)(1-x+x^2)\prod_{n\in N(1,1)}^{\infty} \left(1-x^n+x^{2n}\right)\\ &=(1+x^2+x^4)\prod_{n\in N(1,1)}^{\infty} \left(1-x^n+x^{2n}\right)=(1+x^2+x^4)(1-x^2+x^4)\prod_{n\in N(1,2)}^{\infty} \left(1-x^n+x^{2n}\right)\\ &=(1+x^4+x^8)\prod_{n\in N(1,2)}^{\infty} \left(1-x^n+x^{2n}\right)=(1+x^4+x^8)(1-x^4+x^8)\prod_{n\in N(1,3)}^{\infty} \left(1-x^n+x^{2n}\right)\\ &=(1+x^8+x^{16})\prod_{n\in N(1,3)}^{\infty} \left(1-x^n+x^{2n}\right)=\cdots\\ &=\lim_{k\to\infty}(1+x^{2^k}+x^{2^{k+1}})\prod_{n\in N(1,k)}^{} \left(1-x^n+x^{2n}\right)=\prod_{n\in N(1,\infty)}^{} \left(1-x^n+x^{2n}\right)\\ &\text{Similarly,}\\ &f(x)(1+x+x^2)(1+x^3+x^6)=\prod_{n\in N(3,\infty)}^{} \left(1-x^n+x^{2n}\right)\\ &f(x)(1+x+x^2)(1+x^3+x^6)(1+x^5+x^{10})=\prod_{n\in N(5,\infty)}^{} \left(1-x^n+x^{2n}\right)\\ &\cdots\\ &f(x)\prod_{m=1}^{\infty} \left(1+x^{2m-1}+x^{2(2m-1)}\right)=\lim_{p\to\infty} \prod_{n\in N(p,\infty)}^{} \left(1-x^n+x^{2n}\right)=1 \end{align}$$ (*) Is it obvious that $\{(2m-1)\cdot2^{k-1}\mid m,k\in \mathbb N\}$ is equivalent to $\mathbb N$, or should I also prove it? Thanks.","Prove the following equation ($|x|<1$) $$\prod_{n=1}^{\infty} \left(1-x^n+x^{2n}\right) = \prod_{n=1}^{\infty} \frac1{1+x^{2n-1}+x^{4n-2}}$$ I made this question and I have the following answer but I think it may be incomplete. If anyone can point out a flaw in my proof or give a better proof then it would be appreciated. My solution: $$\begin{align} &f(x)=\prod_{n=1}^{\infty} \left(1-x^n+x^{2n}\right)\\ &N(p,q)=\{n\in\mathbb N \mid n\ne (2m-1)2^{k-1};m,k\in\mathbb N,2m-1\leq p,k\leq q\}\\ &f(x)(1+x+x^2)=(1+x+x^2)(1-x+x^2)\prod_{n\in N(1,1)}^{\infty} \left(1-x^n+x^{2n}\right)\\ &=(1+x^2+x^4)\prod_{n\in N(1,1)}^{\infty} \left(1-x^n+x^{2n}\right)=(1+x^2+x^4)(1-x^2+x^4)\prod_{n\in N(1,2)}^{\infty} \left(1-x^n+x^{2n}\right)\\ &=(1+x^4+x^8)\prod_{n\in N(1,2)}^{\infty} \left(1-x^n+x^{2n}\right)=(1+x^4+x^8)(1-x^4+x^8)\prod_{n\in N(1,3)}^{\infty} \left(1-x^n+x^{2n}\right)\\ &=(1+x^8+x^{16})\prod_{n\in N(1,3)}^{\infty} \left(1-x^n+x^{2n}\right)=\cdots\\ &=\lim_{k\to\infty}(1+x^{2^k}+x^{2^{k+1}})\prod_{n\in N(1,k)}^{} \left(1-x^n+x^{2n}\right)=\prod_{n\in N(1,\infty)}^{} \left(1-x^n+x^{2n}\right)\\ &\text{Similarly,}\\ &f(x)(1+x+x^2)(1+x^3+x^6)=\prod_{n\in N(3,\infty)}^{} \left(1-x^n+x^{2n}\right)\\ &f(x)(1+x+x^2)(1+x^3+x^6)(1+x^5+x^{10})=\prod_{n\in N(5,\infty)}^{} \left(1-x^n+x^{2n}\right)\\ &\cdots\\ &f(x)\prod_{m=1}^{\infty} \left(1+x^{2m-1}+x^{2(2m-1)}\right)=\lim_{p\to\infty} \prod_{n\in N(p,\infty)}^{} \left(1-x^n+x^{2n}\right)=1 \end{align}$$ (*) Is it obvious that $\{(2m-1)\cdot2^{k-1}\mid m,k\in \mathbb N\}$ is equivalent to $\mathbb N$, or should I also prove it? Thanks.",,"['calculus', 'sequences-and-series', 'infinite-product']"
88,The subspace associated with the affine set $C$ is the nullspace of $A$.,The subspace associated with the affine set  is the nullspace of .,C A,"This is an example from my book: Example 2.1: The solution set of a system of linear equations, $C = \{ x | Ax = b\}$,  Where  $A \in R^{m\times n}$ and $b \in R^m$, is an affine set. To show this suppose $x_1, x_2 \in C$ then for any $\theta$ we have: $ A(\theta x_1 + (1-\theta)x_2) = \theta Ax_1 + (1-\theta)Ax_2 = \theta b + (1-\theta)b = b $ Which shows that the affine combination $\theta x_1 +(1-\theta)x_2 $ is also in C.  The subspace associated with the affine set $C$ is the nullspace of $A$. I understand the proof but I cant understand the last sentence. From what I know if $x$ is a solution for $Ax = b$ Then every linear combination of x is a also a solution, And that is the definition of the range space. What am I missing here?","This is an example from my book: Example 2.1: The solution set of a system of linear equations, $C = \{ x | Ax = b\}$,  Where  $A \in R^{m\times n}$ and $b \in R^m$, is an affine set. To show this suppose $x_1, x_2 \in C$ then for any $\theta$ we have: $ A(\theta x_1 + (1-\theta)x_2) = \theta Ax_1 + (1-\theta)Ax_2 = \theta b + (1-\theta)b = b $ Which shows that the affine combination $\theta x_1 +(1-\theta)x_2 $ is also in C.  The subspace associated with the affine set $C$ is the nullspace of $A$. I understand the proof but I cant understand the last sentence. From what I know if $x$ is a solution for $Ax = b$ Then every linear combination of x is a also a solution, And that is the definition of the range space. What am I missing here?",,"['calculus', 'linear-algebra']"
89,Hypergeometric function values and the Baxter constant,Hypergeometric function values and the Baxter constant,,"While I was working on this question by @Vladimir Reshetnikov, I've found the following relations between Gaussian hypergeometric function values and the Baxter constant: $$\begin{align}{_2F_1}\left(\begin{array}c\tfrac13,\tfrac13\\1\end{array}\middle|\,-1\right) &\stackrel{?}{=} \frac{1}{2^{\small2/3}}\,C^2_\text{B4CC},\\ {_2F_1}\left(\begin{array}c\tfrac23,\tfrac23\\1\end{array}\middle|\,-1\right) &\stackrel{?}{=} \frac{1}{2}\,C^2_\text{B4CC},\\ {_2F_1}\left(\begin{array}c\tfrac13,\tfrac13\\1\end{array}\middle|\,\frac19\right) &\stackrel{?}{=} \frac{1}{\sqrt[3]{3}}\,C^2_\text{B4CC},\\ {_2F_1}\left(\begin{array}c\tfrac23,\tfrac23\\1\end{array}\middle|\,\frac19\right) &\stackrel{?}{=} \frac{\sqrt[3]{3}}{2}\,C^2_\text{B4CC},\\ {_2F_1}\left(\begin{array}c\tfrac13,\tfrac13\\1\end{array}\middle|\,9\right) &\stackrel{?}{=} \frac{3-i\sqrt3}{6}\,C^2_\text{B4CC},\\ {_2F_1}\left(\begin{array}c\tfrac23,\tfrac23\\1\end{array}\middle|\,9\right) &\stackrel{?}{=} -\frac{i}{2\sqrt3}\,C^2_\text{B4CC},\\ \end{align}$$ where ${_2F_1}$ is the Gaussian hypergeometric function , and $$ C^2_\text{B4CC} = \frac{3}{4\pi^2}\Gamma^3\left(\tfrac{1}{3}\right) \approx 1.460998486206318358158873117846059697\dots $$ is Baxter's four-coloring constant . The first two identity are known, but with the last four relations I've never met before. How could we prove these identities? In this paper , there is another connection between a hypergeometric value and Baxter constant.","While I was working on this question by @Vladimir Reshetnikov, I've found the following relations between Gaussian hypergeometric function values and the Baxter constant: $$\begin{align}{_2F_1}\left(\begin{array}c\tfrac13,\tfrac13\\1\end{array}\middle|\,-1\right) &\stackrel{?}{=} \frac{1}{2^{\small2/3}}\,C^2_\text{B4CC},\\ {_2F_1}\left(\begin{array}c\tfrac23,\tfrac23\\1\end{array}\middle|\,-1\right) &\stackrel{?}{=} \frac{1}{2}\,C^2_\text{B4CC},\\ {_2F_1}\left(\begin{array}c\tfrac13,\tfrac13\\1\end{array}\middle|\,\frac19\right) &\stackrel{?}{=} \frac{1}{\sqrt[3]{3}}\,C^2_\text{B4CC},\\ {_2F_1}\left(\begin{array}c\tfrac23,\tfrac23\\1\end{array}\middle|\,\frac19\right) &\stackrel{?}{=} \frac{\sqrt[3]{3}}{2}\,C^2_\text{B4CC},\\ {_2F_1}\left(\begin{array}c\tfrac13,\tfrac13\\1\end{array}\middle|\,9\right) &\stackrel{?}{=} \frac{3-i\sqrt3}{6}\,C^2_\text{B4CC},\\ {_2F_1}\left(\begin{array}c\tfrac23,\tfrac23\\1\end{array}\middle|\,9\right) &\stackrel{?}{=} -\frac{i}{2\sqrt3}\,C^2_\text{B4CC},\\ \end{align}$$ where ${_2F_1}$ is the Gaussian hypergeometric function , and $$ C^2_\text{B4CC} = \frac{3}{4\pi^2}\Gamma^3\left(\tfrac{1}{3}\right) \approx 1.460998486206318358158873117846059697\dots $$ is Baxter's four-coloring constant . The first two identity are known, but with the last four relations I've never met before. How could we prove these identities? In this paper , there is another connection between a hypergeometric value and Baxter constant.",,"['calculus', 'special-functions', 'closed-form', 'hypergeometric-function', 'constants']"
90,"If $\sum a_n = +\infty$, with $a_n ≥0$, then we can find two disjoint subseries diverging","If , with , then we can find two disjoint subseries diverging",\sum a_n = +\infty a_n ≥0,"While trying to solve a problem from my measure theory class, I started to wonder about the following result: Consider a sequence of positive terms $\left \{ a_n \right \}_{n=1}^\infty$ such that $\sum a_n = +\infty$. Is it always possible to find two disjoint subsequences $\left \{a_{n_j} \right \}_{j=1}^\infty$ and $\left \{a_{k_j} \right \}_{j=1}^\infty$ such that? $$\sum_{j=1}^\infty a_{n_j}=+\infty=\sum_{j=1}^\infty a_{k_j}$$ (Disjoint means$\ \left \{a_{n_j} : j \in \mathbb{N}\right \} \cap \left \{a_{k_j} : j \in \mathbb{N}\right \}=\emptyset$ ) Intuitively, it seems true, but I wasn't able to prove it, nor think of a counterexample. Given a infinite set $I\subset \mathbb{N}$, since $$\sum_{n \in I}a_n + \sum_{n \not \in I}a_n = \sum_{n=1}^\infty a_n = +\infty$$ It follows that one of the two sums on the left must be divergent. If both are, we are done. If they are not, applying the same process to the divergent sum we obtain a sequence $I_1 \subset I_2 \subset ...\subset \mathbb{N}$ such that $$\sum_{n \in I_k}a_n =+\infty \ \text{and} \ \sum_{n \not \in I_k}a_n <+\infty$$ for all $k=1,2,...$ I got this far, although I'm don't know whether this is useful at all. Any thoughts? Thanks in advance!","While trying to solve a problem from my measure theory class, I started to wonder about the following result: Consider a sequence of positive terms $\left \{ a_n \right \}_{n=1}^\infty$ such that $\sum a_n = +\infty$. Is it always possible to find two disjoint subsequences $\left \{a_{n_j} \right \}_{j=1}^\infty$ and $\left \{a_{k_j} \right \}_{j=1}^\infty$ such that? $$\sum_{j=1}^\infty a_{n_j}=+\infty=\sum_{j=1}^\infty a_{k_j}$$ (Disjoint means$\ \left \{a_{n_j} : j \in \mathbb{N}\right \} \cap \left \{a_{k_j} : j \in \mathbb{N}\right \}=\emptyset$ ) Intuitively, it seems true, but I wasn't able to prove it, nor think of a counterexample. Given a infinite set $I\subset \mathbb{N}$, since $$\sum_{n \in I}a_n + \sum_{n \not \in I}a_n = \sum_{n=1}^\infty a_n = +\infty$$ It follows that one of the two sums on the left must be divergent. If both are, we are done. If they are not, applying the same process to the divergent sum we obtain a sequence $I_1 \subset I_2 \subset ...\subset \mathbb{N}$ such that $$\sum_{n \in I_k}a_n =+\infty \ \text{and} \ \sum_{n \not \in I_k}a_n <+\infty$$ for all $k=1,2,...$ I got this far, although I'm don't know whether this is useful at all. Any thoughts? Thanks in advance!",,"['calculus', 'sequences-and-series']"
91,"Mistake with Integration with Beta, Gamma, Digamma Fuctions","Mistake with Integration with Beta, Gamma, Digamma Fuctions",,"Problem: Evaluate: $$I=\int_0^{\pi/2} \ln(\sin(x))\tan(x)dx$$ I tried to attempt it by using the Beta, Gamma and Digamma Functions. My approach was as follows: $$$$ Consider $$I(a,b)=\int_0^{\pi/2} \sin^a(x)\sin^b(x)\cos^{-b}(x)dx$$ $$$$ $$=\dfrac{1}{2}\beta\bigg (\dfrac{a+b+1}{2},\dfrac{1-b}{2}\bigg )= \dfrac{1}{2} \dfrac{\Gamma(\frac{a+b+1}{2})\Gamma(\frac{1-b}{2})}{\Gamma(\frac{a+2}{2})}$$ Now, $$\dfrac{1}{2}\dfrac{\partial}{\partial a} \beta\bigg (\dfrac{a+b+1}{2},\dfrac{1-b}{2}\bigg )\bigg |_{a=0,b=1} = \int_0^{\pi/2}\ln(\sin(x))\sin^a(x)\tan^b(x)dx \bigg |_{a=0,b=1} = I$$ Now, $$\dfrac{\partial}{\partial a} \beta\bigg (\dfrac{a+b+1}{2},\dfrac{1-b}{2}\bigg )$$ $$$$ $$=\dfrac{1}{2} \dfrac{\Gamma(\frac{1-b}{2})}{(\Gamma(\frac{a+2}{2}))^2}\bigg (\Gamma '\bigg (\frac{a+b+1}{2}\bigg )\Gamma \bigg ( \frac{a+2}{2}\bigg ) - \Gamma '\bigg ( \frac{a+2}{2}\bigg )\Gamma \bigg (\frac{a+b+1}{2}\bigg )\bigg ) $$ $$$$ $$= \dfrac{1}{2}\dfrac{\Gamma(\frac{1-b}{2})}{\Gamma(\frac{a+2}{2})}\bigg (\psi\bigg ( \frac{a+b+1}{2}\bigg )\Gamma \bigg (\frac{a+b+1}{2}\bigg ) - \psi\bigg ( \frac{a+2}{2}\bigg )\Gamma \bigg (\frac{a+b+1}{2}\bigg )\bigg )$$ $$$$ $$=\dfrac{1}{2} \dfrac{\Gamma(\frac{a+b+1}{2})\Gamma(\frac{1-b}{2})}{\Gamma(\frac{a+2}{2})}\bigg (\psi\bigg ( \frac{a+b+1}{2}\bigg )-\psi\bigg ( \frac{a+2}{2}\bigg )\bigg )$$ $$$$ $$\Rightarrow\dfrac{\partial}{\partial a} \beta\bigg (\dfrac{a+b+1}{2},\dfrac{1-b}{2}\bigg )=\dfrac{1}{2} \dfrac{\Gamma(\frac{a+b+1}{2})\Gamma(\frac{1-b}{2})}{\Gamma(\frac{a+2}{2})}\bigg (\psi\bigg ( \frac{a+b+1}{2}\bigg )-\psi\bigg ( \frac{a+2}{2}\bigg )\bigg )$$ $$$$ $$\Longrightarrow \dfrac{1}{2} \dfrac{\partial}{\partial a} \beta \bigg ( \dfrac{a+b+1}{2} ,\dfrac{1-b}{2} \bigg ) \bigg |_{a=0,b=1} = I $$ $$$$ $$=\dfrac{1}{2}\times \dfrac{1}{2} \dfrac{\Gamma(\frac{a+b+1}{2})\Gamma(\frac{1-b}{2})}{\Gamma(\frac{a+2}{2})}\bigg (\psi\bigg ( \frac{a+b+1}{2}\bigg )-\psi\bigg ( \frac{a+2}{2}\bigg )\bigg ) \bigg |_{a=0,b=1}$$ $$$$ $$ =\dfrac{1}{4}\dfrac{\Gamma(0)\Gamma(1)}{\Gamma(1)}\bigg (\psi\bigg ( 1 \bigg )-\psi\bigg (1\bigg )\bigg )$$ $$$$ Could somebody tell me where I have gone wrong?","Problem: Evaluate: I tried to attempt it by using the Beta, Gamma and Digamma Functions. My approach was as follows: Consider Now, Now, Could somebody tell me where I have gone wrong?","I=\int_0^{\pi/2} \ln(\sin(x))\tan(x)dx  I(a,b)=\int_0^{\pi/2} \sin^a(x)\sin^b(x)\cos^{-b}(x)dx  =\dfrac{1}{2}\beta\bigg (\dfrac{a+b+1}{2},\dfrac{1-b}{2}\bigg )= \dfrac{1}{2} \dfrac{\Gamma(\frac{a+b+1}{2})\Gamma(\frac{1-b}{2})}{\Gamma(\frac{a+2}{2})} \dfrac{1}{2}\dfrac{\partial}{\partial a} \beta\bigg (\dfrac{a+b+1}{2},\dfrac{1-b}{2}\bigg )\bigg |_{a=0,b=1} = \int_0^{\pi/2}\ln(\sin(x))\sin^a(x)\tan^b(x)dx \bigg |_{a=0,b=1} = I \dfrac{\partial}{\partial a} \beta\bigg (\dfrac{a+b+1}{2},\dfrac{1-b}{2}\bigg )  =\dfrac{1}{2} \dfrac{\Gamma(\frac{1-b}{2})}{(\Gamma(\frac{a+2}{2}))^2}\bigg (\Gamma '\bigg (\frac{a+b+1}{2}\bigg )\Gamma \bigg ( \frac{a+2}{2}\bigg ) - \Gamma '\bigg ( \frac{a+2}{2}\bigg )\Gamma \bigg (\frac{a+b+1}{2}\bigg )\bigg )   = \dfrac{1}{2}\dfrac{\Gamma(\frac{1-b}{2})}{\Gamma(\frac{a+2}{2})}\bigg (\psi\bigg ( \frac{a+b+1}{2}\bigg )\Gamma \bigg (\frac{a+b+1}{2}\bigg ) - \psi\bigg ( \frac{a+2}{2}\bigg )\Gamma \bigg (\frac{a+b+1}{2}\bigg )\bigg )  =\dfrac{1}{2} \dfrac{\Gamma(\frac{a+b+1}{2})\Gamma(\frac{1-b}{2})}{\Gamma(\frac{a+2}{2})}\bigg (\psi\bigg ( \frac{a+b+1}{2}\bigg )-\psi\bigg ( \frac{a+2}{2}\bigg )\bigg )  \Rightarrow\dfrac{\partial}{\partial a} \beta\bigg (\dfrac{a+b+1}{2},\dfrac{1-b}{2}\bigg )=\dfrac{1}{2} \dfrac{\Gamma(\frac{a+b+1}{2})\Gamma(\frac{1-b}{2})}{\Gamma(\frac{a+2}{2})}\bigg (\psi\bigg ( \frac{a+b+1}{2}\bigg )-\psi\bigg ( \frac{a+2}{2}\bigg )\bigg )  \Longrightarrow \dfrac{1}{2} \dfrac{\partial}{\partial a} \beta \bigg ( \dfrac{a+b+1}{2} ,\dfrac{1-b}{2} \bigg ) \bigg |_{a=0,b=1} = I   =\dfrac{1}{2}\times \dfrac{1}{2} \dfrac{\Gamma(\frac{a+b+1}{2})\Gamma(\frac{1-b}{2})}{\Gamma(\frac{a+2}{2})}\bigg (\psi\bigg ( \frac{a+b+1}{2}\bigg )-\psi\bigg ( \frac{a+2}{2}\bigg )\bigg ) \bigg |_{a=0,b=1}   =\dfrac{1}{4}\dfrac{\Gamma(0)\Gamma(1)}{\Gamma(1)}\bigg (\psi\bigg ( 1 \bigg )-\psi\bigg (1\bigg )\bigg ) ","['calculus', 'integration', 'definite-integrals', 'gamma-function', 'beta-function']"
92,Exterior derivative of a 2-form,Exterior derivative of a 2-form,,"I want to prove that the exterior derivative of a 2-form in $\mathbb{R}^n$: $${\alpha = \sum a_{ij} dx_i \wedge dx_j}$$ is: $${d \alpha = \sum (\frac{\partial a_{ij}}{\partial x_k} + \frac{\partial a_{jk}}{\partial x_i} - \frac{\partial a_{ik}}{\partial x_j})dx_i \wedge dx_j \wedge dx_k.}$$ The thing is that I'm stucked after taking the differential of the function $a_{ij}$ and then multiplying the $dx_k$ term from the 1-form that comes out from ${da_{ij} = \sum \frac{\partial a_{ij}}{\partial x_k}dx_k}$. The answer seems very pleasant (permutating the indices $i,j,k$), but I missed the simple algebraic step that takes to it.","I want to prove that the exterior derivative of a 2-form in $\mathbb{R}^n$: $${\alpha = \sum a_{ij} dx_i \wedge dx_j}$$ is: $${d \alpha = \sum (\frac{\partial a_{ij}}{\partial x_k} + \frac{\partial a_{jk}}{\partial x_i} - \frac{\partial a_{ik}}{\partial x_j})dx_i \wedge dx_j \wedge dx_k.}$$ The thing is that I'm stucked after taking the differential of the function $a_{ij}$ and then multiplying the $dx_k$ term from the 1-form that comes out from ${da_{ij} = \sum \frac{\partial a_{ij}}{\partial x_k}dx_k}$. The answer seems very pleasant (permutating the indices $i,j,k$), but I missed the simple algebraic step that takes to it.",,"['calculus', 'multivariable-calculus', 'differential-forms']"
93,How to evaluate $\int_0^{\infty} \bigg(\frac{e^{-x}}{\sinh(x)} - \frac{e^{-3x}}{x}\bigg) \; dx$,How to evaluate,\int_0^{\infty} \bigg(\frac{e^{-x}}{\sinh(x)} - \frac{e^{-3x}}{x}\bigg) \; dx,"Evaluate the integral below $$\int_0^{\infty} \bigg(\frac{e^{-x}}{\sinh(x)} - \frac{e^{-3x}}{x}\bigg) \; dx$$ Using Wolfram I get the integral is $\gamma + \log\bigg(\frac{3}{2}\bigg)$, where $\gamma$ is The Euler-Mascheroni constant. I split the integral into two parts. For the first one, I tried to use $\sinh(x) = \frac{e^{x}-e^{-x}}{2}=\frac{e^{-x}}{2}(\frac{e^{2x}-1}{2})$ and the first integral became $$\int_0^{\infty} \frac{2}{e^{2x}-1} \; dx=\int_0^{\infty} \frac{2e^{-2x}}{1-e^{-2x}} \; dx$$ Then, I use substitution $u=1-e^{-2x}$. $$\int_0^{\infty} \frac{2e^{-2x}}{1-e^{-2x}} \; dx=-4\int_0^{1} \frac{du}{u} = -4\ln u\;\bigg|_0^1 = \infty$$ The second integral also diverges. Where I made a mistake? How is the way to get a result like Wolfram output?","Evaluate the integral below $$\int_0^{\infty} \bigg(\frac{e^{-x}}{\sinh(x)} - \frac{e^{-3x}}{x}\bigg) \; dx$$ Using Wolfram I get the integral is $\gamma + \log\bigg(\frac{3}{2}\bigg)$, where $\gamma$ is The Euler-Mascheroni constant. I split the integral into two parts. For the first one, I tried to use $\sinh(x) = \frac{e^{x}-e^{-x}}{2}=\frac{e^{-x}}{2}(\frac{e^{2x}-1}{2})$ and the first integral became $$\int_0^{\infty} \frac{2}{e^{2x}-1} \; dx=\int_0^{\infty} \frac{2e^{-2x}}{1-e^{-2x}} \; dx$$ Then, I use substitution $u=1-e^{-2x}$. $$\int_0^{\infty} \frac{2e^{-2x}}{1-e^{-2x}} \; dx=-4\int_0^{1} \frac{du}{u} = -4\ln u\;\bigg|_0^1 = \infty$$ The second integral also diverges. Where I made a mistake? How is the way to get a result like Wolfram output?",,['calculus']
94,The limit of composition of two functions,The limit of composition of two functions,,"I need your help in solving this limits problem. Let $f$ and $g$ be two functions defined everywhere. If $\lim_{u\to b} f(u) = c$    and $\lim_{x\to a} g(x) = b$, then you may believe that $\lim_{x\to a} f(g(x)) = c$. This   problem shows that this is not always true. Consider functions $f$ and $g$ defined as follows: $g(x) = 0$ for all $x \in\mathbb  R$ and   $$    f(u) = \begin{cases} 0, \quad & \text{ if } u \ne 0, \\            1, &\text{ if } u = 0\end{cases}$$ (a) Compute $\lim_{u\to 0} f(u)$ (b) Compute $f(g(x))$ for $x \in\mathbb R$ and hence compute $\lim_{x\to 0} f(g(x))$. (c) Can you redefine $f(0)$ so that $\lim_{x\to 0} f(g(x)) = f(\lim_{x\to 0} g(x))$ ? I tried solving and was getting my solution but it's confusing and I am not able to confirm it. So I need your answer to help me out.","I need your help in solving this limits problem. Let $f$ and $g$ be two functions defined everywhere. If $\lim_{u\to b} f(u) = c$    and $\lim_{x\to a} g(x) = b$, then you may believe that $\lim_{x\to a} f(g(x)) = c$. This   problem shows that this is not always true. Consider functions $f$ and $g$ defined as follows: $g(x) = 0$ for all $x \in\mathbb  R$ and   $$    f(u) = \begin{cases} 0, \quad & \text{ if } u \ne 0, \\            1, &\text{ if } u = 0\end{cases}$$ (a) Compute $\lim_{u\to 0} f(u)$ (b) Compute $f(g(x))$ for $x \in\mathbb R$ and hence compute $\lim_{x\to 0} f(g(x))$. (c) Can you redefine $f(0)$ so that $\lim_{x\to 0} f(g(x)) = f(\lim_{x\to 0} g(x))$ ? I tried solving and was getting my solution but it's confusing and I am not able to confirm it. So I need your answer to help me out.",,"['calculus', 'limits', 'function-and-relation-composition']"
95,Integral $\int\limits_0^1 \frac{\ln x\ln ( 1 - zx )}{1 - x} dx$,Integral,\int\limits_0^1 \frac{\ln x\ln ( 1 - zx )}{1 - x} dx,How can I evaluate following logarithmic integral: $$\int\limits_0^1 \frac{\ln x\ln ( 1 - zx )}{1 - x} dx$$,How can I evaluate following logarithmic integral: $$\int\limits_0^1 \frac{\ln x\ln ( 1 - zx )}{1 - x} dx$$,,"['calculus', 'integration', 'definite-integrals', 'logarithms', 'improper-integrals']"
96,Evaluation of $\int\frac{\ln(\cos x+\sqrt{\cos 2x})}{\sin^2 x}dx$,Evaluation of,\int\frac{\ln(\cos x+\sqrt{\cos 2x})}{\sin^2 x}dx,Evaluation of $\displaystyle \int\frac{\ln(\cos x+\sqrt{\cos 2x})}{\sin^2 x}dx$ My Try:: Let $\displaystyle I = \int \frac{\ln(\cos x+\sqrt{\cos 2x})}{\sin^2 x}dx = \int \ln(\cos x+\sqrt{\cos 2x})\cdot \csc^2 xdx$ So $\displaystyle I = -\ln\left(\cos x+\sqrt{\cos 2x}\right)\cdot \cot x+\int \frac{1}{\left(\cos x+\sqrt{\cos 2x}\right)}\cdot \left(-\sin x-\frac{1}{2\sqrt{\cos 2x}}\cdot 2\cdot \sin 2x\right)\cdot \cot xdx$ Now How Can I solve after that Help me Thanks,Evaluation of $\displaystyle \int\frac{\ln(\cos x+\sqrt{\cos 2x})}{\sin^2 x}dx$ My Try:: Let $\displaystyle I = \int \frac{\ln(\cos x+\sqrt{\cos 2x})}{\sin^2 x}dx = \int \ln(\cos x+\sqrt{\cos 2x})\cdot \csc^2 xdx$ So $\displaystyle I = -\ln\left(\cos x+\sqrt{\cos 2x}\right)\cdot \cot x+\int \frac{1}{\left(\cos x+\sqrt{\cos 2x}\right)}\cdot \left(-\sin x-\frac{1}{2\sqrt{\cos 2x}}\cdot 2\cdot \sin 2x\right)\cdot \cot xdx$ Now How Can I solve after that Help me Thanks,,['calculus']
97,Find the length of the curve $x^{2k}+y^{2k} =1$,Find the length of the curve,x^{2k}+y^{2k} =1,"I want to find an expression for length and find the limit $k\rightarrow \infty$ The answer is obviously 8, if we look at the graphs.","I want to find an expression for length and find the limit $k\rightarrow \infty$ The answer is obviously 8, if we look at the graphs.",,"['calculus', 'integration', 'limits', 'definite-integrals', 'parametric']"
98,"How do I find $f(0)$, $f'(0)$, and $f'(x)$ given $f(x+y)=f(x)+f(y)+x^2y+xy^2$ and $\lim_{x\to0}\frac{f(x)}{x}=1$?","How do I find , , and  given  and ?",f(0) f'(0) f'(x) f(x+y)=f(x)+f(y)+x^2y+xy^2 \lim_{x\to0}\frac{f(x)}{x}=1,"How can I find $f(0)$, $f'(0)$, and $f'(x)$ given that $f(x+y)=f(x)+f(y)+x^2y+xy^2$ and $\lim_{x\to0}\frac{f(x)}{x}=1$.","How can I find $f(0)$, $f'(0)$, and $f'(x)$ given that $f(x+y)=f(x)+f(y)+x^2y+xy^2$ and $\lim_{x\to0}\frac{f(x)}{x}=1$.",,['calculus']
99,Calculate the Gauss integral without squaring it first,Calculate the Gauss integral without squaring it first,,"We know that the integral $$ I = \int_{-\infty}^{\infty}  e^{-x^2}\ \mathrm{d} x $$ can be calculated by first squaring it and then treat it as a $2$ -dimensional integral in the plane and integrate it in polar coordinates. Are there any other ways to calculate it?  I know that we may use the relation $$\Gamma(x)\, \Gamma(1-x) = \frac{\pi}{\sin{\pi x}}$$ but this, in effect, is still taking the square. Well, after I write down the above text, I figure that maybe there is no way to calculate it without squaring, since, after all, the result contains a square root, and it seems no elementary function can ""naturally"" produce a square root of $\pi$ starting from natural numbers (though I don't know how to describe this more concretely; you are also welcome to comment on this point ).  Nevertheless I still post this question in case there are some other ideas. EDIT: the Fourier transformation method at Computing the Gaussian integral with Fourier methods? appears kind of cheat to me, since the very proof of the Fourier transformation formula actually makes use of the value of the Gauss integral (at least in this wiki page http://en.wikipedia.org/wiki/Fourier_inversion_theorem#Proof ). Thank you.","We know that the integral can be calculated by first squaring it and then treat it as a -dimensional integral in the plane and integrate it in polar coordinates. Are there any other ways to calculate it?  I know that we may use the relation but this, in effect, is still taking the square. Well, after I write down the above text, I figure that maybe there is no way to calculate it without squaring, since, after all, the result contains a square root, and it seems no elementary function can ""naturally"" produce a square root of starting from natural numbers (though I don't know how to describe this more concretely; you are also welcome to comment on this point ).  Nevertheless I still post this question in case there are some other ideas. EDIT: the Fourier transformation method at Computing the Gaussian integral with Fourier methods? appears kind of cheat to me, since the very proof of the Fourier transformation formula actually makes use of the value of the Gauss integral (at least in this wiki page http://en.wikipedia.org/wiki/Fourier_inversion_theorem#Proof ). Thank you.","
I = \int_{-\infty}^{\infty}  e^{-x^2}\ \mathrm{d} x
 2 \Gamma(x)\, \Gamma(1-x) = \frac{\pi}{\sin{\pi x}} \pi","['calculus', 'integration', 'algebra-precalculus', 'definite-integrals', 'improper-integrals']"
