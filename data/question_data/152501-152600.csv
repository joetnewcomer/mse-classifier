,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,About example of continuous function on $\mathbb{R}$ which cannot be uniformly approximated by polynomials? [duplicate],About example of continuous function on  which cannot be uniformly approximated by polynomials? [duplicate],\mathbb{R},This question already has an answer here : Closed 12 years ago . Possible Duplicate: Weierstrass approximation does not hold on the entire Real Line If a function $f: \mathbb{R}\rightarrow \mathbb{R}$ is continuous then $f$ can be uniformly approximated  by smooth functions (see here ). By the Weierstrass approximation theorem $f$ can be uniformly approximated by polynomials on each compact subinterval of $\mathbb{R}$. What is example of continuous function $f: \mathbb{R}\rightarrow \mathbb{R}$ which cannot be uniformly approximated by polynomials on the whole $\mathbb{R}$? Thanks,This question already has an answer here : Closed 12 years ago . Possible Duplicate: Weierstrass approximation does not hold on the entire Real Line If a function $f: \mathbb{R}\rightarrow \mathbb{R}$ is continuous then $f$ can be uniformly approximated  by smooth functions (see here ). By the Weierstrass approximation theorem $f$ can be uniformly approximated by polynomials on each compact subinterval of $\mathbb{R}$. What is example of continuous function $f: \mathbb{R}\rightarrow \mathbb{R}$ which cannot be uniformly approximated by polynomials on the whole $\mathbb{R}$? Thanks,,['analysis']
1,Prove that $\frac{1}{n} \sum_{k=2}^n \frac{1}{\log k}$ converges to $0$,Prove that  converges to,\frac{1}{n} \sum_{k=2}^n \frac{1}{\log k} 0,"Prove that $\frac{1}{n} \sum_{k=2}^n \frac{1}{\log k}$ converges to $0.$ Okay, seriously, it's like this question is mocking me.  I know it converges to $0$.  I can feel it in my blood.  I even proved it was Cauchy, but then realized that didn't tell me what the limit was .  I've been working on this for an hour, so can one of you math geniuses help me? Thanks!","Prove that $\frac{1}{n} \sum_{k=2}^n \frac{1}{\log k}$ converges to $0.$ Okay, seriously, it's like this question is mocking me.  I know it converges to $0$.  I can feel it in my blood.  I even proved it was Cauchy, but then realized that didn't tell me what the limit was .  I've been working on this for an hour, so can one of you math geniuses help me? Thanks!",,['analysis']
2,Irrationality of $ \frac{1}{\pi} \arccos{\frac{1}{\sqrt{n}}}$,Irrationality of, \frac{1}{\pi} \arccos{\frac{1}{\sqrt{n}}},"This paper arxiv.org/pdf/0911.1933 discusses, regarding the irrationality of certain trigonometric functions. Recently, i encountered this problem which says states the given function, $$ f(n)=\frac{1}{\pi} \arccos{\frac{1}{\sqrt{n}}}$$ is irrational for every odd $n \geq 3$. But i couldn't find the proof anywhere. Can anyone provide me with the proof.","This paper arxiv.org/pdf/0911.1933 discusses, regarding the irrationality of certain trigonometric functions. Recently, i encountered this problem which says states the given function, $$ f(n)=\frac{1}{\pi} \arccos{\frac{1}{\sqrt{n}}}$$ is irrational for every odd $n \geq 3$. But i couldn't find the proof anywhere. Can anyone provide me with the proof.",,['real-analysis']
3,Speed of Convergence for some series (double sum),Speed of Convergence for some series (double sum),,"For $\alpha>2$ , i want to find the speed of convergence of $$S_n=\sum_{i=1}^n\sum_{j=n-i+1}^n i^{-\alpha}j^{-\alpha}.$$ In particular, i want $\sum_{i=1}^n\sum_{j=n-i+1}^n i^{-\alpha}j^{-\alpha}\leq Cn^{-\alpha+1-\epsilon}$ for some $C,\epsilon>0$ . My first attempt was to estimate by integrals $$\sum_{i=1}^n\sum_{j=n-i+1}^n i^{-\alpha}j^{-\alpha}\leq \int_{x=1}^n\int_{y=n-x+1}^n x^{-\alpha}y^{-\alpha}dxdy\\=\int_{x=1}^nx^{-\alpha}(n^{-\alpha+1})dx+\int_{x=1}^nx^{-\alpha}(n-x+1)^{-\alpha+1}dx$$ but the second integral on the left is not an easy one. My second attempt was to show that $$n^{\alpha-1+\epsilon}\sum_{i=1}^n\sum_{j=n-i+1}^n i^{-\alpha}j^{-\alpha}$$ is bounded.","For , i want to find the speed of convergence of In particular, i want for some . My first attempt was to estimate by integrals but the second integral on the left is not an easy one. My second attempt was to show that is bounded.","\alpha>2 S_n=\sum_{i=1}^n\sum_{j=n-i+1}^n i^{-\alpha}j^{-\alpha}. \sum_{i=1}^n\sum_{j=n-i+1}^n i^{-\alpha}j^{-\alpha}\leq Cn^{-\alpha+1-\epsilon} C,\epsilon>0 \sum_{i=1}^n\sum_{j=n-i+1}^n i^{-\alpha}j^{-\alpha}\leq \int_{x=1}^n\int_{y=n-x+1}^n x^{-\alpha}y^{-\alpha}dxdy\\=\int_{x=1}^nx^{-\alpha}(n^{-\alpha+1})dx+\int_{x=1}^nx^{-\alpha}(n-x+1)^{-\alpha+1}dx n^{\alpha-1+\epsilon}\sum_{i=1}^n\sum_{j=n-i+1}^n i^{-\alpha}j^{-\alpha}","['real-analysis', 'sequences-and-series', 'analysis', 'asymptotics', 'riemann-zeta']"
4,"Find the limit of $a_1 = 1 $ , $ a_{n+1} = \frac{\sqrt{1+a_n^2}-1}{a_n}$ , $n \in \mathbb{N}$","Find the limit of  ,  ,",a_1 = 1   a_{n+1} = \frac{\sqrt{1+a_n^2}-1}{a_n} n \in \mathbb{N},"$a_1 = 1 $ , $ a_{n+1} = \frac{\sqrt{1+a_n^2}-1}{a_n}$ , $n \in \mathbb{N}$ It is easy to prove that the limit exists: the boundary of that expression is $0$ and it is monotonically decreasing. The problem is to actually find the limit (it is $0$ ) because if I take arithmetic of limits: $ \lim_{x \to +\infty} a_{n+1} =  \frac{\sqrt{1+ \lim_{n \to +\infty} a_n^2+1}}{\lim_{n \to +\infty} a_n}$ $g = \frac{\sqrt{1+g^2+1}}{g}  \implies g^2 = {\sqrt{1+g^2}-1} \implies g^2 + 1 = {\sqrt{1+g^2}} \implies 0 = 0$",", , It is easy to prove that the limit exists: the boundary of that expression is and it is monotonically decreasing. The problem is to actually find the limit (it is ) because if I take arithmetic of limits:",a_1 = 1   a_{n+1} = \frac{\sqrt{1+a_n^2}-1}{a_n} n \in \mathbb{N} 0 0  \lim_{x \to +\infty} a_{n+1} =  \frac{\sqrt{1+ \lim_{n \to +\infty} a_n^2+1}}{\lim_{n \to +\infty} a_n} g = \frac{\sqrt{1+g^2+1}}{g}  \implies g^2 = {\sqrt{1+g^2}-1} \implies g^2 + 1 = {\sqrt{1+g^2}} \implies 0 = 0,"['real-analysis', 'sequences-and-series', 'limits', 'analysis']"
5,"find $ \lim\limits_{n\to\infty}\int_{0}^{1}1/(1+x^{n})\,dx $",find," \lim\limits_{n\to\infty}\int_{0}^{1}1/(1+x^{n})\,dx ","First of all, English is not my native language, but Chinses is. I tried to spilt the integration interval into 2 pieces: $ [0, 1-1/n] $ and $ [1-1/n, 1] $ . In both intervals I use the mean value theorem: $$ 	\int_{0}^{1-1/n}\frac{1}{1+x^{n}}\,dx=\frac{1}{1+\xi_{n}^{n}}\left( 1-\frac{1}{n} \right), \qquad \text{and} \qquad \int_{1-1/n}^{1}\frac{1}{1+x^{n}}\,dx=\frac{1}{1+\eta_{n}^{n}}\frac{1}{n}, 	$$ where $ \xi_{n}\in(0, 1-1/n), \eta_{n}\in(1-1/n, 1) $ .I found that the latter formula has a limit of $ 0 $ when $ n\to\infty $ . However I can't handle the previous formula. Does anyone has some thoughts?","First of all, English is not my native language, but Chinses is. I tried to spilt the integration interval into 2 pieces: and . In both intervals I use the mean value theorem: where .I found that the latter formula has a limit of when . However I can't handle the previous formula. Does anyone has some thoughts?"," [0, 1-1/n]   [1-1/n, 1]  
	\int_{0}^{1-1/n}\frac{1}{1+x^{n}}\,dx=\frac{1}{1+\xi_{n}^{n}}\left( 1-\frac{1}{n} \right), \qquad \text{and} \qquad \int_{1-1/n}^{1}\frac{1}{1+x^{n}}\,dx=\frac{1}{1+\eta_{n}^{n}}\frac{1}{n},
	  \xi_{n}\in(0, 1-1/n), \eta_{n}\in(1-1/n, 1)   0   n\to\infty ","['calculus', 'analysis']"
6,"If $f,g$ are any two functions with $f>g$, then there is a continuous function $h$ such that $f>h>g$","If  are any two functions with , then there is a continuous function  such that","f,g f>g h f>h>g","Is the following claim true? Let $f,g : [a,b] \to \mathbb{R} $ be any two functions such that $f>g$ . Then there exists a continuous function $h:[a,b] \to \mathbb{R}$ such that $f>h>g$ . I have no idea how to approach this, although the claim seems true to me. That being said, I am not interested in a proof, if the claim does happen to be correct ( I would like to find it for myself). However, I welcome counter examples, if the claim is false! I merely want to know whether or not the claim is true. Any help would be greatly appreciated!","Is the following claim true? Let be any two functions such that . Then there exists a continuous function such that . I have no idea how to approach this, although the claim seems true to me. That being said, I am not interested in a proof, if the claim does happen to be correct ( I would like to find it for myself). However, I welcome counter examples, if the claim is false! I merely want to know whether or not the claim is true. Any help would be greatly appreciated!","f,g : [a,b] \to \mathbb{R}  f>g h:[a,b] \to \mathbb{R} f>h>g","['real-analysis', 'calculus']"
7,prove that $\int_{a}^b f \ + \int_{f(a)}^{f(b)} \ f^{-1}=bf(b)-af(a)$ [duplicate],prove that  [duplicate],\int_{a}^b f \ + \int_{f(a)}^{f(b)} \ f^{-1}=bf(b)-af(a),"This question already has answers here : Show rigorously that the sum of integrals of $f$ and of its inverse is $bf(b)-af(a)$ (6 answers) Closed 5 years ago . Let $0 <a <b\ $ let $f >0 $ be continuous and strictly increasing  function on $ [a,b]$ . Prove that $$\int_{a}^b f \  + \int_{f(a)}^{f(b)} \ f^{-1}=bf(b)-af(a)$$ How to approach this problem . Any Hint? I am suppose to do it without using antiderivatives.",This question already has answers here : Show rigorously that the sum of integrals of $f$ and of its inverse is $bf(b)-af(a)$ (6 answers) Closed 5 years ago . Let let be continuous and strictly increasing  function on . Prove that How to approach this problem . Any Hint? I am suppose to do it without using antiderivatives.,"0 <a <b\  f >0   [a,b] \int_{a}^b f \  + \int_{f(a)}^{f(b)} \ f^{-1}=bf(b)-af(a)","['calculus', 'real-analysis', 'integration', 'analysis']"
8,How to prove that gcd of two numbers is one.,How to prove that gcd of two numbers is one.,,"For $l \in \mathbb{N}$ I'm to prove that the greatest common divisor,  $\gcd(8l^2+20l+13,4l+2) = 1$. I've tried induction, but I couldn't pull off, now I'm at a loss of how to even begin to solve this. PS: It's also possible that it's not possible to prove it, because it's not correct.","For $l \in \mathbb{N}$ I'm to prove that the greatest common divisor,  $\gcd(8l^2+20l+13,4l+2) = 1$. I've tried induction, but I couldn't pull off, now I'm at a loss of how to even begin to solve this. PS: It's also possible that it's not possible to prove it, because it's not correct.",,['analysis']
9,"How can I calculate $\int_0^\infty\frac{r^{n-1}}{(1+r^2)^{(n+1)/2}}\,dr$?",How can I calculate ?,"\int_0^\infty\frac{r^{n-1}}{(1+r^2)^{(n+1)/2}}\,dr","How can I calculate:  $$ \displaystyle\int_0^\infty \frac{r^{n-1}}{(1+r^2)^\frac{n+1}{2}}\,dr $$ I encountered this integral in proving that a function is an approximation to the identity. But I don't know how to solve this integral. I would greatly appreciate any help.","How can I calculate:  $$ \displaystyle\int_0^\infty \frac{r^{n-1}}{(1+r^2)^\frac{n+1}{2}}\,dr $$ I encountered this integral in proving that a function is an approximation to the identity. But I don't know how to solve this integral. I would greatly appreciate any help.",,"['real-analysis', 'integration', 'complex-analysis', 'analysis', 'fourier-analysis']"
10,Is it true that $\operatorname{Im} f$ is closed in $\Bbb R$?,Is it true that  is closed in ?,\operatorname{Im} f \Bbb R,Let $f:\Bbb R\to \Bbb R$ be a continuous function  such that $f(i)=0\ \forall i\in \Bbb Z$ .Then is it true  that $\operatorname{Im} f$ is closed in $\Bbb R$? Let $x_n$ be a sequence in  $\operatorname{Im} f$ such that $x_n\to x$ We should show that $x\in  \operatorname{Im} f$. How should I proceed now?,Let $f:\Bbb R\to \Bbb R$ be a continuous function  such that $f(i)=0\ \forall i\in \Bbb Z$ .Then is it true  that $\operatorname{Im} f$ is closed in $\Bbb R$? Let $x_n$ be a sequence in  $\operatorname{Im} f$ such that $x_n\to x$ We should show that $x\in  \operatorname{Im} f$. How should I proceed now?,,"['real-analysis', 'analysis']"
11,How to prove this inequality $ \left|\frac{{\sin x}}{x} - \frac{{\sin y}}{y}\right| \le \sqrt {2\left|\frac{1}{x} - \frac{1}{y}\right|}$ [closed],How to prove this inequality  [closed], \left|\frac{{\sin x}}{x} - \frac{{\sin y}}{y}\right| \le \sqrt {2\left|\frac{1}{x} - \frac{1}{y}\right|},"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question $$ \left|\frac{{\sin x}}{x} - \frac{{\sin y}}{y}\right| \leqslant \sqrt {2\left|\frac{1}{x} - \frac{1}{y}\right|} $$ I tried to prove this by using mean value theorem, but I failed. Could you help me? Thanks!","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question $$ \left|\frac{{\sin x}}{x} - \frac{{\sin y}}{y}\right| \leqslant \sqrt {2\left|\frac{1}{x} - \frac{1}{y}\right|} $$ I tried to prove this by using mean value theorem, but I failed. Could you help me? Thanks!",,"['calculus', 'analysis', 'inequality']"
12,"Two non-negative functions $\,f,g$, such that $\,f \not\in \mathcal O(g)$ and $ g \not\in \mathcal O(\,f)$","Two non-negative functions , such that  and","\,f,g \,f \not\in \mathcal O(g)  g \not\in \mathcal O(\,f)","Show that there exist two non-negative functions $\,f,g: \mathbb{N} \rightarrow \mathbb{R}$ such that $\,f \not\in \mathcal O(g)$ and $ g \not\in \mathcal O(\,f)$. It would be easy two find two such functions for which one can also take negative values, but I can't seem to find two non-negative functions. Can anybody help please?","Show that there exist two non-negative functions $\,f,g: \mathbb{N} \rightarrow \mathbb{R}$ such that $\,f \not\in \mathcal O(g)$ and $ g \not\in \mathcal O(\,f)$. It would be easy two find two such functions for which one can also take negative values, but I can't seem to find two non-negative functions. Can anybody help please?",,"['analysis', 'algorithms', 'computational-complexity']"
13,Putnam 2009 B1 (rational number as factorial),Putnam 2009 B1 (rational number as factorial),,"Show that every positive rational number can be written as a quotient of products of factorials of (not necessarily distinct) primes. For example, $ \frac{10}9=\frac{2!\cdot 5!}{3!\cdot 3!\cdot 3!}.$ I used the idea: $$\frac{a}{b} = \frac{\prod x_{k}!}{\prod y_{j}!} \implies a = \frac{(b)\cdot\prod x_{k}!}{\prod y_{j}!}$$ Then I said suppose it holds for: $$\varphi = \{1, 2, 3.... a-1\}$$ Then since for $a > 1$: $$\frac{a}{2} < a-1$$ It follows from strong induction, $$\frac{a}{2!} = \frac{(b)\cdot\prod x_{k}!}{\prod y_{j}!}$$ $$\frac{a}{b} = 2! \cdot \frac{ \prod x_{k}!}{\prod y_{j}!}$$","Show that every positive rational number can be written as a quotient of products of factorials of (not necessarily distinct) primes. For example, $ \frac{10}9=\frac{2!\cdot 5!}{3!\cdot 3!\cdot 3!}.$ I used the idea: $$\frac{a}{b} = \frac{\prod x_{k}!}{\prod y_{j}!} \implies a = \frac{(b)\cdot\prod x_{k}!}{\prod y_{j}!}$$ Then I said suppose it holds for: $$\varphi = \{1, 2, 3.... a-1\}$$ Then since for $a > 1$: $$\frac{a}{2} < a-1$$ It follows from strong induction, $$\frac{a}{2!} = \frac{(b)\cdot\prod x_{k}!}{\prod y_{j}!}$$ $$\frac{a}{b} = 2! \cdot \frac{ \prod x_{k}!}{\prod y_{j}!}$$",,"['calculus', 'real-analysis', 'analysis', 'contest-math']"
14,Continuous function on a compact set with no fixed points,Continuous function on a compact set with no fixed points,,"I'm reviewing this problem for my analysis qual. Let $f:X\rightarrow X$ be a continuous mapping from a metric space to itself. Assume $f $ has no fixed points. Prove that, if $X $ is compact, there exists an $\epsilon $ such that $d (x, f (x)) \ge \epsilon $ for every $x\in X $. I'm having trouble figuring out what to do. I predict having to take neighborhoods of every $x\in X $ and find a finite subcover. But I'm not sure where that gets me in terms of the fixed point thing. I know that $f (x) \ne x $ means each center of the balls comprising the finite subcover will have to move, but I don't know what that gets me. Help?","I'm reviewing this problem for my analysis qual. Let $f:X\rightarrow X$ be a continuous mapping from a metric space to itself. Assume $f $ has no fixed points. Prove that, if $X $ is compact, there exists an $\epsilon $ such that $d (x, f (x)) \ge \epsilon $ for every $x\in X $. I'm having trouble figuring out what to do. I predict having to take neighborhoods of every $x\in X $ and find a finite subcover. But I'm not sure where that gets me in terms of the fixed point thing. I know that $f (x) \ne x $ means each center of the balls comprising the finite subcover will have to move, but I don't know what that gets me. Help?",,"['analysis', 'continuity', 'compactness']"
15,How to calculate $\int_{-\infty}^\infty\frac{x^2+2x}{x^4+x^2+1}dx$?,How to calculate ?,\int_{-\infty}^\infty\frac{x^2+2x}{x^4+x^2+1}dx,"I want to calculate the following integral: $$I:=\displaystyle\int_{-\infty}^\infty\underbrace{\frac{x^2+2x}{x^4+x^2+1}}_{=:f(x)}dx$$ Of course, I could try to determine $\int f(x)\;dx$ in terms of integration by parts. However, I don't think that's the way one should do this. So, what's the trick to calculate $I$?","I want to calculate the following integral: $$I:=\displaystyle\int_{-\infty}^\infty\underbrace{\frac{x^2+2x}{x^4+x^2+1}}_{=:f(x)}dx$$ Of course, I could try to determine $\int f(x)\;dx$ in terms of integration by parts. However, I don't think that's the way one should do this. So, what's the trick to calculate $I$?",,"['real-analysis', 'integration', 'complex-analysis', 'analysis']"
16,Prove $1-\frac{1}{2}-\frac{1}{3}+\frac{1}{4}+\frac{1}{5}-\frac{1}{6}-\frac{1}{7}+\cdots$ converges.,Prove  converges.,1-\frac{1}{2}-\frac{1}{3}+\frac{1}{4}+\frac{1}{5}-\frac{1}{6}-\frac{1}{7}+\cdots,"Consider the series: $1-\frac{1}{2}-\frac{1}{3}+\frac{1}{4}+\frac{1}{5}-\frac{1}{6}-\frac{1}{7}+\cdots$ Is it convergent? I believe I need to find a way to split the terms into additive and subtraction terms, however I'm not sure how to do this and as a result prove the outcome.","Consider the series: $1-\frac{1}{2}-\frac{1}{3}+\frac{1}{4}+\frac{1}{5}-\frac{1}{6}-\frac{1}{7}+\cdots$ Is it convergent? I believe I need to find a way to split the terms into additive and subtraction terms, however I'm not sure how to do this and as a result prove the outcome.",,"['sequences-and-series', 'analysis']"
17,How to understand both closed and open set in topology?,How to understand both closed and open set in topology?,,"We've defined the connectedness in topology in class in this way that a topological space is connected if the only both open and closed set is empty set or the whole set. Now I got the explanation from Wikipedia:""Now consider the space $X$ which consists of the union of the two open intervals $(0,1)$ and $(2,3)$ of $\mathbb{R}$. The topology on $X$ is inherited as the subspace topology from the ordinary topology on the real line $\mathbb{R}$. In $X$, the set $(0,1)$ is clopen, as is the set $(2,3)$. This is a quite typical example: whenever a space is made up of a finite number of disjoint connected components in this way, the components will be clopen."" I understand the last line of the explanation, because it corresponds to our definition of connectedness. But Can anyone tell me why $(0,1)\bigcup(2,3)$ are both open and closed(by definition)?I understand it's open but why it's closed? A set is said to be open if there always exists a neighborhood of each point in this set and the neighborhood also is contained in the set. A set is said to be closed if its complement is open. Thanks for helping me :)","We've defined the connectedness in topology in class in this way that a topological space is connected if the only both open and closed set is empty set or the whole set. Now I got the explanation from Wikipedia:""Now consider the space $X$ which consists of the union of the two open intervals $(0,1)$ and $(2,3)$ of $\mathbb{R}$. The topology on $X$ is inherited as the subspace topology from the ordinary topology on the real line $\mathbb{R}$. In $X$, the set $(0,1)$ is clopen, as is the set $(2,3)$. This is a quite typical example: whenever a space is made up of a finite number of disjoint connected components in this way, the components will be clopen."" I understand the last line of the explanation, because it corresponds to our definition of connectedness. But Can anyone tell me why $(0,1)\bigcup(2,3)$ are both open and closed(by definition)?I understand it's open but why it's closed? A set is said to be open if there always exists a neighborhood of each point in this set and the neighborhood also is contained in the set. A set is said to be closed if its complement is open. Thanks for helping me :)",,"['general-topology', 'analysis', 'connectedness']"
18,Uniform Continuity of $f(x)=x^3$,Uniform Continuity of,f(x)=x^3,"1.)Determine whether $f(x)=x^3$ is uniformly continuous on [0,2) So far, I have $\delta$ = 2 and $\epsilon$ = 8, and plan on using the sandwich theorem with $x^2$ and eventually equating $\delta = \epsilon$.","1.)Determine whether $f(x)=x^3$ is uniformly continuous on [0,2) So far, I have $\delta$ = 2 and $\epsilon$ = 8, and plan on using the sandwich theorem with $x^2$ and eventually equating $\delta = \epsilon$.",,"['analysis', 'continuity']"
19,"For every $f\in C[0,1]$ there is a sequence of even polynomials which converges uniformly on $[0,1]$ to f",For every  there is a sequence of even polynomials which converges uniformly on  to f,"f\in C[0,1] [0,1]","For every $f\in C[0,1]$ there is a sequence of even polynomials which converges uniformly on $[0,1]$ to f ? What I have tried: f is continuous on $D:=[0,1]$, let  $(x_k)_{k\in \mathbb{N}} \in D$  converge to $y \in D$, then it must hold that (sequence definition of continuity):  $$\lim _{k \rightarrow \infty} x_k=y\Rightarrow \lim_{n \rightarrow \infty} f(x_k)=f(y)  $$ a sequence of even polynomials: $a_k= \sum_{k=0}^{x_k}a_kx^{2k} $ don't see anything more... how does one show this ? Doesn't one need to know that every f is analytic to show this ? edit: the theorem by stone-weierstrass was proven already at this point...","For every $f\in C[0,1]$ there is a sequence of even polynomials which converges uniformly on $[0,1]$ to f ? What I have tried: f is continuous on $D:=[0,1]$, let  $(x_k)_{k\in \mathbb{N}} \in D$  converge to $y \in D$, then it must hold that (sequence definition of continuity):  $$\lim _{k \rightarrow \infty} x_k=y\Rightarrow \lim_{n \rightarrow \infty} f(x_k)=f(y)  $$ a sequence of even polynomials: $a_k= \sum_{k=0}^{x_k}a_kx^{2k} $ don't see anything more... how does one show this ? Doesn't one need to know that every f is analytic to show this ? edit: the theorem by stone-weierstrass was proven already at this point...",,"['real-analysis', 'analysis', 'multivariable-calculus']"
20,Distance in at most countable metric spaces,Distance in at most countable metric spaces,,"I am trying to show that in an at most countable metric space $ X $, there exists some distance $ \delta \gt 0$, such that for all $ x, y \in X $, $d(x, y) \neq \delta$. I am trying to show this by contradiction: I suppose that for every $ \delta \gt 0$, there exists some $ x, y \in X $, such that $d(x, y)=\delta $, and then show there is an injection from the positive reals to $ X $, implying that $ X $ is uncountable and giving me my contradiction. I was just wondering if someone could help me define that injection. I am having trouble making it well defined. Thanks.","I am trying to show that in an at most countable metric space $ X $, there exists some distance $ \delta \gt 0$, such that for all $ x, y \in X $, $d(x, y) \neq \delta$. I am trying to show this by contradiction: I suppose that for every $ \delta \gt 0$, there exists some $ x, y \in X $, such that $d(x, y)=\delta $, and then show there is an injection from the positive reals to $ X $, implying that $ X $ is uncountable and giving me my contradiction. I was just wondering if someone could help me define that injection. I am having trouble making it well defined. Thanks.",,"['general-topology', 'analysis']"
21,Infinite sum and integral,Infinite sum and integral,,I have a question regarding a sum. Is the following expression finite and can be calculated? $$\lim_{a\to\infty}\frac{1}{a}\sum_{b=0}^a \left(\frac{b}{a}\right)^2$$ Could I also approximate the sum by an integral since the upper index grows to infinity like $$\lim_{a\to\infty}\int_{b=0}^a~db \frac{b^2}{a^3}$$ which would be $<\infty$?,I have a question regarding a sum. Is the following expression finite and can be calculated? $$\lim_{a\to\infty}\frac{1}{a}\sum_{b=0}^a \left(\frac{b}{a}\right)^2$$ Could I also approximate the sum by an integral since the upper index grows to infinity like $$\lim_{a\to\infty}\int_{b=0}^a~db \frac{b^2}{a^3}$$ which would be $<\infty$?,,"['real-analysis', 'sequences-and-series', 'complex-analysis', 'analysis']"
22,Does there exist a variation of Minkowski's inequality with differences instead of sum.,Does there exist a variation of Minkowski's inequality with differences instead of sum.,,I seek something of the form $\|f-g\|_p \leq |\|f\|_p-\|g\|_p|$.,I seek something of the form $\|f-g\|_p \leq |\|f\|_p-\|g\|_p|$.,,['analysis']
23,Lower semi-continuous function which is unbounded on compact set.,Lower semi-continuous function which is unbounded on compact set.,,"Every lower semi-continuous functions attains an infimum/minimum on a compact set, do you know examples of lower semi-continuous functions which are unbounded and/or don't attain their maximum/supremum?","Every lower semi-continuous functions attains an infimum/minimum on a compact set, do you know examples of lower semi-continuous functions which are unbounded and/or don't attain their maximum/supremum?",,"['general-topology', 'analysis', 'functional-analysis']"
24,WolframAlpha blows simple substitution?,WolframAlpha blows simple substitution?,,"I am to find a formula for the n-th derivative of $$\frac{1+x}{1-x}$$ I came up with $$\frac{(-1)^{n+1} \times 2 \times n!}{(1-x)^{n+1}}$$ This seems right, but I noticed that WolframAlpha somehow manages to eat the sign for any n. For example, for $n=2$ I have: $\frac{-4}{(1-x)^{3}}$, but WolframAlpha gives $\frac{4}{(1-x)^3}$. I am not particularly good at calculating, but I would like to think that I have mastered the numbers below $10$ so I'm pretty sure I'm right here and WolframAlpha did something very weird. EDIT: Yep, my derivative is wrong. BUT this still doesn't answer the question why WolframAlpha responds with a positive fraction all the time - I didn't ask it to calculate a derivate, I just entered my formula. PS: Who removed my WolframAlpha input? That was sort of essential to the question, I was never that interested in the derivative itself, I just wanted to know why WA responded that way. (Exact input: (-1)^(n+1)*2*n!/((1-x)^(n+1)), n=2 )","I am to find a formula for the n-th derivative of $$\frac{1+x}{1-x}$$ I came up with $$\frac{(-1)^{n+1} \times 2 \times n!}{(1-x)^{n+1}}$$ This seems right, but I noticed that WolframAlpha somehow manages to eat the sign for any n. For example, for $n=2$ I have: $\frac{-4}{(1-x)^{3}}$, but WolframAlpha gives $\frac{4}{(1-x)^3}$. I am not particularly good at calculating, but I would like to think that I have mastered the numbers below $10$ so I'm pretty sure I'm right here and WolframAlpha did something very weird. EDIT: Yep, my derivative is wrong. BUT this still doesn't answer the question why WolframAlpha responds with a positive fraction all the time - I didn't ask it to calculate a derivate, I just entered my formula. PS: Who removed my WolframAlpha input? That was sort of essential to the question, I was never that interested in the derivative itself, I just wanted to know why WA responded that way. (Exact input: (-1)^(n+1)*2*n!/((1-x)^(n+1)), n=2 )",,"['analysis', 'derivatives', 'wolfram-alpha']"
25,"Simple example of a continuous onto function mapping $[0,1]$ to $\mathbb R$",Simple example of a continuous onto function mapping  to,"[0,1] \mathbb R","There should exist such a function, but I cannot think of any example. Onto continuous functions mapping $(0,1)$ to $\mathbb R$ are easy to find. Edit: Sorry - I mentioned Tietze extension theorem proved the existence of such a function - that was wrong. I mixed it up with a different question.","There should exist such a function, but I cannot think of any example. Onto continuous functions mapping $(0,1)$ to $\mathbb R$ are easy to find. Edit: Sorry - I mentioned Tietze extension theorem proved the existence of such a function - that was wrong. I mixed it up with a different question.",,"['real-analysis', 'analysis', 'functions']"
26,Evaluating the integral $\mathop{\lim}\limits_{n \to \infty} \int_{-1}^{1} f(t)\cos^{2}(nt) \ dt $,Evaluating the integral,\mathop{\lim}\limits_{n \to \infty} \int_{-1}^{1} f(t)\cos^{2}(nt) \ dt ,"Given that $f\colon [-1,1] \to \mathbb{R}$ is a continuous function such that $ \int_{-1}^{1} f(t) \ dt =1$, how do I evaluate the limit of this integral: $$\lim_{n \to \infty} \int_{-1}^{1} f(t) \cos^{2}{nt} \,dt$$ What I did was to write $\cos^{2}{nt} = \frac{1+\cos{2nt}}{2}$ and substitute it in the integral so that I can make use of the given hypothesis of $\int_{-1}^{1} f(t) \ dt =1$. So the integral becomes, \begin{align*} \int_{-1}^{1} f(t)\cos^{2}{nt} \ dt = \int_{-1}^{1} f(t) \biggl[\frac{1+\cos{2nt}}{2}\biggr] \ dt  &  \\  \hspace{3cm} = \frac{1}{2}\int_{-1}^{1}f(t) \ dt + \int_{-1}^{1} \frac{f(t)\cos{2nt}}{2} \ dt \end{align*} But I don't really know how I can evaluate the second integral and also I can't realize as to why that integral condition on $f$ has been assumed. Moreover without assuming that condition on $f$ is it possible to evaluate this integral? If yes, then what would the answer be?","Given that $f\colon [-1,1] \to \mathbb{R}$ is a continuous function such that $ \int_{-1}^{1} f(t) \ dt =1$, how do I evaluate the limit of this integral: $$\lim_{n \to \infty} \int_{-1}^{1} f(t) \cos^{2}{nt} \,dt$$ What I did was to write $\cos^{2}{nt} = \frac{1+\cos{2nt}}{2}$ and substitute it in the integral so that I can make use of the given hypothesis of $\int_{-1}^{1} f(t) \ dt =1$. So the integral becomes, \begin{align*} \int_{-1}^{1} f(t)\cos^{2}{nt} \ dt = \int_{-1}^{1} f(t) \biggl[\frac{1+\cos{2nt}}{2}\biggr] \ dt  &  \\  \hspace{3cm} = \frac{1}{2}\int_{-1}^{1}f(t) \ dt + \int_{-1}^{1} \frac{f(t)\cos{2nt}}{2} \ dt \end{align*} But I don't really know how I can evaluate the second integral and also I can't realize as to why that integral condition on $f$ has been assumed. Moreover without assuming that condition on $f$ is it possible to evaluate this integral? If yes, then what would the answer be?",,['real-analysis']
27,"If sequence $a_n>0$ is decreasing to $0$ and $\sum_{k=1}^\infty a_n=\infty$, prove $\sum_{n=1}^\infty\frac{a_n}{e^{S_n}}<\infty$","If sequence  is decreasing to  and , prove",a_n>0 0 \sum_{k=1}^\infty a_n=\infty \sum_{n=1}^\infty\frac{a_n}{e^{S_n}}<\infty,"If sequence $a_n>0$ is decreasing to $0$ for all $n\geq 1$ and $\sum_{n=1}^\infty a_n=\infty$ , is it always true that $\sum_{n=1}^\infty\frac{a_n}{e^{S_n}}<\infty$ , where $S_n=\sum_{k=1}^na_k$ is the partial sum? If yes, how to prove; if no, is there any counterexample? I have tried $a_n=\frac{1}{n}$ , in that case $e^{S_n}\sim n$ when $n$ is large, so $\sum_{n=1}^\infty \frac{a_n}{e^{S_n}} \sim \sum_{n=1}^\infty \frac{1}{n^2}<\infty$ . I also tried $a_n=\frac{1}{n\ln n}$ , in this case $e^{S_n}\sim \ln n$ when $n$ is large, so $\sum_{n=1}^\infty \frac{a_n}{e^{S_n}} \sim \sum_{n=1}^\infty \frac{1}{n(\ln n)^2}<\infty$ by Cauchy condensation test.","If sequence is decreasing to for all and , is it always true that , where is the partial sum? If yes, how to prove; if no, is there any counterexample? I have tried , in that case when is large, so . I also tried , in this case when is large, so by Cauchy condensation test.",a_n>0 0 n\geq 1 \sum_{n=1}^\infty a_n=\infty \sum_{n=1}^\infty\frac{a_n}{e^{S_n}}<\infty S_n=\sum_{k=1}^na_k a_n=\frac{1}{n} e^{S_n}\sim n n \sum_{n=1}^\infty \frac{a_n}{e^{S_n}} \sim \sum_{n=1}^\infty \frac{1}{n^2}<\infty a_n=\frac{1}{n\ln n} e^{S_n}\sim \ln n n \sum_{n=1}^\infty \frac{a_n}{e^{S_n}} \sim \sum_{n=1}^\infty \frac{1}{n(\ln n)^2}<\infty,"['real-analysis', 'sequences-and-series', 'analysis']"
28,Can there be a $C^1$ everywhere but $C^2$ nowhere function?,Can there be a  everywhere but  nowhere function?,C^1 C^2,"Obviously examples of continuous-everywhere and differentiable-nowhere functions abundant. Similarly there are examples of everywhere-smooth nowhere-analytic functions. And I'm well aware of the various differentiability properties of the family of functions $$f_n(x) = x^n \sin(1/x), \quad n=0,1,2,\ldots$$ Namely that $f_2(x)$ is differentiable by not $C^1$ (etc. for higher values of $n$ ). But a colleague just asked me if there are any examples of $C^1$ functions that are nowhere $C^2$ , and I came up blank. I would imagine the same kind of construction could be asked about functions that are differentiable everywhere, but $C^1$ nowhere.","Obviously examples of continuous-everywhere and differentiable-nowhere functions abundant. Similarly there are examples of everywhere-smooth nowhere-analytic functions. And I'm well aware of the various differentiability properties of the family of functions Namely that is differentiable by not (etc. for higher values of ). But a colleague just asked me if there are any examples of functions that are nowhere , and I came up blank. I would imagine the same kind of construction could be asked about functions that are differentiable everywhere, but nowhere.","f_n(x) = x^n \sin(1/x), \quad n=0,1,2,\ldots f_2(x) C^1 n C^1 C^2 C^1","['real-analysis', 'analysis', 'derivatives']"
29,$\lim _{n \to \infty} \int_{0}^1 f \left(\frac{x}{n}\right) dx =0$ find $f(0) ?$,find,\lim _{n \to \infty} \int_{0}^1 f \left(\frac{x}{n}\right) dx =0 f(0) ?,let $f:\mathbb{R} \to \mathbb{R}$ be a continuous function such that $$\lim _{n \to \infty} \int_{0}^1 f \left(\frac{x}{n}\right) dx =0$$ Then what we can say about $f(0) \ $ ?? how  to approach this problem . Any hint .,let be a continuous function such that Then what we can say about ?? how  to approach this problem . Any hint .,f:\mathbb{R} \to \mathbb{R} \lim _{n \to \infty} \int_{0}^1 f \left(\frac{x}{n}\right) dx =0 f(0) \ ,"['calculus', 'real-analysis', 'integration', 'analysis']"
30,product of two analytic functions is 0,product of two analytic functions is 0,,"Let $U$ be a subset of $\mathbb{C}$, which is not connected. How can I find two analytic functions $f$ and $g$ from $U$ to $\mathbb{C}$ such that $f\neq0$ and $g\neq0$. But $f\cdot g = 0$. thanks for any hint.","Let $U$ be a subset of $\mathbb{C}$, which is not connected. How can I find two analytic functions $f$ and $g$ from $U$ to $\mathbb{C}$ such that $f\neq0$ and $g\neq0$. But $f\cdot g = 0$. thanks for any hint.",,"['complex-analysis', 'analysis']"
31,Convergence of series - Which test?,Convergence of series - Which test?,,"I want to check for convergence the series $\displaystyle{\sum_{n=m}^{\infty}\binom{n}{m}^{-1}}$. $$$$ I have done the following: We use the ratio test. We have that $$a_n=\binom{n}{m}^{-1}=\left (\frac{n!}{m!(n-m)!}\right )^{-1}=\frac{m!(n-m)!}{n!}$$ and $$a_{n+1}=\binom{n+1}{m}^{-1}=\left (\frac{(n+1)!}{m!(n+1-m)!}\right )^{-1}=\frac{m!(n+1-m)!}{(n+1)!}$$ Therefore we get \begin{align*}\left |\frac{a_{n+1}}{a_n}\right |&=\frac{m!(n-m+1)!}{(n+1)!}\cdot \frac{n!}{m!(n-m)!}\\ & =\frac{(n-m)!(n-m+1)}{n!(n+1)}\cdot \frac{n!}{(n-m)!}\\ & =\frac{(n-m+1)}{(n+1)}\underset{n\rightarrow \infty}{\longrightarrow }1\end{align*} So, we cannot say something by the ratio test. Which convergence test should we use instead?","I want to check for convergence the series $\displaystyle{\sum_{n=m}^{\infty}\binom{n}{m}^{-1}}$. $$$$ I have done the following: We use the ratio test. We have that $$a_n=\binom{n}{m}^{-1}=\left (\frac{n!}{m!(n-m)!}\right )^{-1}=\frac{m!(n-m)!}{n!}$$ and $$a_{n+1}=\binom{n+1}{m}^{-1}=\left (\frac{(n+1)!}{m!(n+1-m)!}\right )^{-1}=\frac{m!(n+1-m)!}{(n+1)!}$$ Therefore we get \begin{align*}\left |\frac{a_{n+1}}{a_n}\right |&=\frac{m!(n-m+1)!}{(n+1)!}\cdot \frac{n!}{m!(n-m)!}\\ & =\frac{(n-m)!(n-m+1)}{n!(n+1)}\cdot \frac{n!}{(n-m)!}\\ & =\frac{(n-m+1)}{(n+1)}\underset{n\rightarrow \infty}{\longrightarrow }1\end{align*} So, we cannot say something by the ratio test. Which convergence test should we use instead?",,"['sequences-and-series', 'analysis', 'convergence-divergence']"
32,What is a nice way to prove that : $\frac{t}{t+1} \le 1-e^{-t}\le \frac{2t}{1+t}$,What is a nice way to prove that :,\frac{t}{t+1} \le 1-e^{-t}\le \frac{2t}{1+t},I am trying to prove that for $t>0$$$\frac{t}{t+1} \le 1-e^{-t}\le \frac{2t}{1+t}$$ I know that Simplest or nicest proof that $1+x \le e^x$ taking $$e^{-x} \le \frac{1}{1+x} \implies 1-e^{-x}\ge \frac{x}{x+1}$$ Now I don't know to prove the other inequality.,I am trying to prove that for $t>0$$$\frac{t}{t+1} \le 1-e^{-t}\le \frac{2t}{1+t}$$ I know that Simplest or nicest proof that $1+x \le e^x$ taking $$e^{-x} \le \frac{1}{1+x} \implies 1-e^{-x}\ge \frac{x}{x+1}$$ Now I don't know to prove the other inequality.,,"['calculus', 'real-analysis', 'analysis', 'inequality', 'exponential-function']"
33,Show that $\sinh x$ is strictly increasing,Show that  is strictly increasing,\sinh x,"Can someone help me with this analysis question: I have to show that $\sinh(x)$ is strictly increasing on all of $\Bbb R$, and that $\cosh(x)$ is strictly increasing on the interval: $[0,\infty)$ and strictly decreasing on the interval: $(-\infty, 0]$. I'm not allowed to differentiate or anything like that. I think I have to do it with inequalities. I've been giving a hint to use the trigonometric addition formulas.","Can someone help me with this analysis question: I have to show that $\sinh(x)$ is strictly increasing on all of $\Bbb R$, and that $\cosh(x)$ is strictly increasing on the interval: $[0,\infty)$ and strictly decreasing on the interval: $(-\infty, 0]$. I'm not allowed to differentiate or anything like that. I think I have to do it with inequalities. I've been giving a hint to use the trigonometric addition formulas.",,"['real-analysis', 'analysis']"
34,"If A is an infinite set and B is at most countable set, prove that A and $A \cup B$ have the same cardinality","If A is an infinite set and B is at most countable set, prove that A and  have the same cardinality",A \cup B,"I am trying to prove: If A is an infinite set and B is at most countable set, prove that A and $A \cup B$ have the same cardinality. Set definitions here are from baby Rudin. Attempt: There are 4 possible cases: 1.A is countable and B is finite. 2.A is countable and B is countable. 3.A is uncountable and B is finite. 4.A is uncountable and B is countable. Then for each case I need to show that $A \cup B \sim A$. I can prove 1-3, but I am unsure how to prove case 4. And in general, it seems that my proof strategy is inefficient and there exist much faster proof then proof by cases.","I am trying to prove: If A is an infinite set and B is at most countable set, prove that A and $A \cup B$ have the same cardinality. Set definitions here are from baby Rudin. Attempt: There are 4 possible cases: 1.A is countable and B is finite. 2.A is countable and B is countable. 3.A is uncountable and B is finite. 4.A is uncountable and B is countable. Then for each case I need to show that $A \cup B \sim A$. I can prove 1-3, but I am unsure how to prove case 4. And in general, it seems that my proof strategy is inefficient and there exist much faster proof then proof by cases.",,"['real-analysis', 'analysis', 'elementary-set-theory']"
35,How to prove that $2$ is the only solution of the equation $x=\sqrt{2}^x$?,How to prove that  is the only solution of the equation ?,2 x=\sqrt{2}^x,"I tried to prove that $2$ is the only solution to the equation $x=\sqrt{2}^x$ without any results. Here's my try : Let $f:[0,+\infty)\rightarrow\mathbb{R}$ such that $f(x)=\sqrt{2}^x-x$. Thus, $f'(x)=\sqrt{2}^x\ln\sqrt2-1$. $f'$ converges to $0$ when $x=\log_{\sqrt2}\frac{1}{\ln\sqrt2}$. The derivate should keep it's sign to prove that $f$ has exactly one solution, I can't understand what is going on. Please, help","I tried to prove that $2$ is the only solution to the equation $x=\sqrt{2}^x$ without any results. Here's my try : Let $f:[0,+\infty)\rightarrow\mathbb{R}$ such that $f(x)=\sqrt{2}^x-x$. Thus, $f'(x)=\sqrt{2}^x\ln\sqrt2-1$. $f'$ converges to $0$ when $x=\log_{\sqrt2}\frac{1}{\ln\sqrt2}$. The derivate should keep it's sign to prove that $f$ has exactly one solution, I can't understand what is going on. Please, help",,"['analysis', 'functions']"
36,$\lim \limits_{x \rightarrow \infty} \sqrt[]{x^2+2x+3}-\sqrt[]{x^2-x+5}.$ [duplicate],[duplicate],\lim \limits_{x \rightarrow \infty} \sqrt[]{x^2+2x+3}-\sqrt[]{x^2-x+5}.,"This question already has answers here : Evaluating $\lim\limits_{x\to \infty}\sqrt[6]{x^{6}+x^{5}}-\sqrt[6]{x^{6}-x^{5}}$ (5 answers) Closed 7 years ago . I am trying to formally evaluate the following limit: $$\lim \limits_{x \rightarrow \infty} \sqrt[]{x^2+2x+3}-\sqrt[]{x^2-x+5}.$$ Empirically, the limit seems to be converging to $1.5$, although I am not sure how to formally prove this.  I had one idea thus far: it appears the constant terms within the square roots do not matter, so I rewrote the limit as $$\lim \limits_{x \rightarrow \infty} \sqrt[]{x^2+2x-3}-\sqrt[]{x^2-x-6} =\lim \limits_{x \rightarrow \infty} \sqrt[]{(x+3)(x-1)}-\sqrt[]{(x+2)(x-3)}.$$ In each square root, there are two factors.  I assumed that in the limit the geometric mean of the two factors (i.e. square root of the product) is equal to their arithmetic mean.  This is a step I am not quite certain of, and if it is true I would like to prove it. However, as I found it led to the correct answer, since $$\lim \limits_{x \rightarrow \infty} \frac{(x+3)+(x-1)}{2}-\frac{(x+2)+(x-3)}{2}=\lim \limits_{x \rightarrow \infty} (x+1)-(x-0.5)=1.5.$$ I am not sure if the result was coincidental, but if not, I would like some help formalizing each of my steps.  I would also like to hear of alternate approaches that do not alter the original problem in the way I did.","This question already has answers here : Evaluating $\lim\limits_{x\to \infty}\sqrt[6]{x^{6}+x^{5}}-\sqrt[6]{x^{6}-x^{5}}$ (5 answers) Closed 7 years ago . I am trying to formally evaluate the following limit: $$\lim \limits_{x \rightarrow \infty} \sqrt[]{x^2+2x+3}-\sqrt[]{x^2-x+5}.$$ Empirically, the limit seems to be converging to $1.5$, although I am not sure how to formally prove this.  I had one idea thus far: it appears the constant terms within the square roots do not matter, so I rewrote the limit as $$\lim \limits_{x \rightarrow \infty} \sqrt[]{x^2+2x-3}-\sqrt[]{x^2-x-6} =\lim \limits_{x \rightarrow \infty} \sqrt[]{(x+3)(x-1)}-\sqrt[]{(x+2)(x-3)}.$$ In each square root, there are two factors.  I assumed that in the limit the geometric mean of the two factors (i.e. square root of the product) is equal to their arithmetic mean.  This is a step I am not quite certain of, and if it is true I would like to prove it. However, as I found it led to the correct answer, since $$\lim \limits_{x \rightarrow \infty} \frac{(x+3)+(x-1)}{2}-\frac{(x+2)+(x-3)}{2}=\lim \limits_{x \rightarrow \infty} (x+1)-(x-0.5)=1.5.$$ I am not sure if the result was coincidental, but if not, I would like some help formalizing each of my steps.  I would also like to hear of alternate approaches that do not alter the original problem in the way I did.",,"['real-analysis', 'analysis', 'limits']"
37,Decide if the series converges and prove it using comparison test: $\sum_{k=1}^{\infty}\frac{1}{2k+3}$,Decide if the series converges and prove it using comparison test:,\sum_{k=1}^{\infty}\frac{1}{2k+3},"Decide if the series converges and prove it using comparison test:   $\sum_{k=1}^{\infty}\frac{1}{2k+3}$ $$\frac{1}{2k+3} <\frac{1}{2k}<\frac{1}{k}$$ and since $\sum_{k=1}^{\infty}\frac{1}{k}$ diverges (we have defined that in our readings, so I can claim it here), the complete series will diverge, too. Did I do everything correctly? What makes me feel a bit unsure is that there is no ""$\leq$"" sign anywhere and when I look up the comparison test on the internet, I don't see any ""<"" or "">"" in the definition. Is it correct anyway?","Decide if the series converges and prove it using comparison test:   $\sum_{k=1}^{\infty}\frac{1}{2k+3}$ $$\frac{1}{2k+3} <\frac{1}{2k}<\frac{1}{k}$$ and since $\sum_{k=1}^{\infty}\frac{1}{k}$ diverges (we have defined that in our readings, so I can claim it here), the complete series will diverge, too. Did I do everything correctly? What makes me feel a bit unsure is that there is no ""$\leq$"" sign anywhere and when I look up the comparison test on the internet, I don't see any ""<"" or "">"" in the definition. Is it correct anyway?",,"['calculus', 'sequences-and-series', 'analysis', 'convergence-divergence']"
38,How to show that $f(x)=|x|$ is continuous?,How to show that  is continuous?,f(x)=|x|,"Show that the function $f:\mathbb{R}\to\mathbb{R}$, defined by $f(x)=|x|$ is continuous. I only know how to prove the function is continuous at some point. How to prove this one? To prove that it is continuous at all $x_0$?","Show that the function $f:\mathbb{R}\to\mathbb{R}$, defined by $f(x)=|x|$ is continuous. I only know how to prove the function is continuous at some point. How to prove this one? To prove that it is continuous at all $x_0$?",,"['analysis', 'proof-verification']"
39,Can you find the maximum or minimum of an equation without calculus? [closed],Can you find the maximum or minimum of an equation without calculus? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Without using calculus is it possible to find provably and exactly the maximum value or the minimum value of a quadratic equation $$ y:=ax^2+bx+c $$ (and also without completing the square)? I'd love to know the answer.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Without using calculus is it possible to find provably and exactly the maximum value or the minimum value of a quadratic equation $$ y:=ax^2+bx+c $$ (and also without completing the square)? I'd love to know the answer.",,['analysis']
40,$\mu(A \cap I) \le a \mu(I)$ implies $\mu(A) = 0$? [duplicate],implies ? [duplicate],\mu(A \cap I) \le a \mu(I) \mu(A) = 0,"This question already has answers here : Prove Borel Measurable Set A with the following property has measure 0. (4 answers) Closed 5 years ago . Let $\mu$ be lebesgue measure on $\mathbb{R}$, $0<a<1$. If $\mu(A \cap I) \le a \mu(I)$ holds for any interval $I$, can I say $\mu(A)=0$? I tried to construct a counterexample by considering something similar to cantor set but failed. Can anyone give some comments? Thanks!","This question already has answers here : Prove Borel Measurable Set A with the following property has measure 0. (4 answers) Closed 5 years ago . Let $\mu$ be lebesgue measure on $\mathbb{R}$, $0<a<1$. If $\mu(A \cap I) \le a \mu(I)$ holds for any interval $I$, can I say $\mu(A)=0$? I tried to construct a counterexample by considering something similar to cantor set but failed. Can anyone give some comments? Thanks!",,"['real-analysis', 'analysis', 'measure-theory', 'lebesgue-measure']"
41,Is it true that every bounded sequence with the following property converges?,Is it true that every bounded sequence with the following property converges?,,Is it true that every bounded sequence $\{a_n\}$ of real numbers such that $|{a_n - a_{n-1}}|<1/n$ for all $\ge2$ is convergent?,Is it true that every bounded sequence $\{a_n\}$ of real numbers such that $|{a_n - a_{n-1}}|<1/n$ for all $\ge2$ is convergent?,,['analysis']
42,Why aren't all real numbers equal to one another?,Why aren't all real numbers equal to one another?,,"I know, stupid question. But humor me for a sec. First off, we know that all real numbers have two numbers which are infinitely close to them, right?  That would seem to be, for any given value of x, x Â± y where y = .000...1 But here's the thing: y + .999... = 1 Right? And, of course, we all know that .999... = 1, so that means that y = 0, right? Which means that all numbers infinitely close to one another, which represents the entirety of the real number line, are equal, right? Something here is screwed up, but for the life of me I can't figure out what. PS, I wasn't sure what tag to give this, so feel free to edit them.","I know, stupid question. But humor me for a sec. First off, we know that all real numbers have two numbers which are infinitely close to them, right?  That would seem to be, for any given value of x, x Â± y where y = .000...1 But here's the thing: y + .999... = 1 Right? And, of course, we all know that .999... = 1, so that means that y = 0, right? Which means that all numbers infinitely close to one another, which represents the entirety of the real number line, are equal, right? Something here is screwed up, but for the life of me I can't figure out what. PS, I wasn't sure what tag to give this, so feel free to edit them.",,"['analysis', 'fake-proofs']"
43,When to use $\times$ and $\otimes$,When to use  and,\times \otimes,"Im wondering when to use $\times$ and when to use $\otimes$. In some cases it seems very straightforward, for example $\times$ can be used when combining two elements into an n-tupel (for a product with n elements), for example in the case of the scalar product: $$(.,.):V\times V\rightarrow\mathbb{C}:(u,v)\mapsto u\cdot v.$$ For the $\otimes$ i've seen it been used when for example one constructs for example the basis  for a $L^2$-Hilbert space where the x,y and z-coordinates can be split up. This yields: $$f_{nml}(x,y,z)=f_n(x)\otimes f_m(y)\otimes f_l(z).$$ I was wondering if there was a general rule om when to use $\times$ and when to use $\otimes$ ?","Im wondering when to use $\times$ and when to use $\otimes$. In some cases it seems very straightforward, for example $\times$ can be used when combining two elements into an n-tupel (for a product with n elements), for example in the case of the scalar product: $$(.,.):V\times V\rightarrow\mathbb{C}:(u,v)\mapsto u\cdot v.$$ For the $\otimes$ i've seen it been used when for example one constructs for example the basis  for a $L^2$-Hilbert space where the x,y and z-coordinates can be split up. This yields: $$f_{nml}(x,y,z)=f_n(x)\otimes f_m(y)\otimes f_l(z).$$ I was wondering if there was a general rule om when to use $\times$ and when to use $\otimes$ ?",,"['linear-algebra', 'abstract-algebra', 'group-theory', 'analysis']"
44,How can I prove $\lim_{n \rightarrow \infty} \ln(n) / \ln(n+1) = 1$?,How can I prove ?,\lim_{n \rightarrow \infty} \ln(n) / \ln(n+1) = 1,"How can I prove $\lim_{n \rightarrow \infty} \ln(n) / \ln(n+1) = 1$ ? I have looked through all my logarithm rules to find something useful, but the only thing that comes close is $\ln(a/b) = \ln(a)-\ln(b)$. How can I proceed ?","How can I prove $\lim_{n \rightarrow \infty} \ln(n) / \ln(n+1) = 1$ ? I have looked through all my logarithm rules to find something useful, but the only thing that comes close is $\ln(a/b) = \ln(a)-\ln(b)$. How can I proceed ?",,"['real-analysis', 'sequences-and-series', 'analysis', 'limits']"
45,Why $\log xy=\log x+\log y$?,Why ?,\log xy=\log x+\log y,It is of course well known and basic formula. I am just curious. Is there a proof for it? How to prove that $\log xy=\log x+\log y$?,It is of course well known and basic formula. I am just curious. Is there a proof for it? How to prove that $\log xy=\log x+\log y$?,,"['calculus', 'real-analysis', 'analysis']"
46,How may I prove that $2^{\frac{1}{3}}+3^\frac{1}{2}$ is not a rational number?,How may I prove that  is not a rational number?,2^{\frac{1}{3}}+3^\frac{1}{2},How may I prove that  $$2^{\frac{1}{3}}+3^\frac{1}{2}$$ is not a rational number? Thank for any help. Jean,How may I prove that  $$2^{\frac{1}{3}}+3^\frac{1}{2}$$ is not a rational number? Thank for any help. Jean,,"['analysis', 'elementary-number-theory']"
47,"Let $(a_n)_n$ be a convergent sequence of integers , what can we say about $(a_n)_n$","Let  be a convergent sequence of integers , what can we say about",(a_n)_n (a_n)_n,"Let $(a_n)_n$ be a convergent sequence of integers , what can we say about $(a_n)_n$? (I don't understand what is meant by this question)","Let $(a_n)_n$ be a convergent sequence of integers , what can we say about $(a_n)_n$? (I don't understand what is meant by this question)",,['analysis']
48,Does every line segment in $\mathbb{R}^n$ contains a point having only rational coordinates?,Does every line segment in  contains a point having only rational coordinates?,\mathbb{R}^n,Let $S$ be the subset of $\mathbb{R}^n$ consisting of all points which have only rational coordinates. I know that $S$ is a dense subset of $\mathbb{R}^n$. Is it true that every line segment in $\mathbb{R}^n$ intersects S?,Let $S$ be the subset of $\mathbb{R}^n$ consisting of all points which have only rational coordinates. I know that $S$ is a dense subset of $\mathbb{R}^n$. Is it true that every line segment in $\mathbb{R}^n$ intersects S?,,"['general-topology', 'analysis', 'multivariable-calculus']"
49,"The set of all continuous functions $f:[0,1]\rightarrow R$ satisfying $ \int_{0}^{1}t^{n}f(t)dt=0$",The set of all continuous functions  satisfying,"f:[0,1]\rightarrow R  \int_{0}^{1}t^{n}f(t)dt=0","I was thinking about the problem: The set of all continuous functions $f:[0,1]\rightarrow R$ satisfying $$\int_0^1 t^n f(t) \, dt=0,\qquad n=1,2,\ldots$$ (a) $\text{is empty},$   (b) $\text{contains a single element},$   (c) $\text{is countably infinite},$   (d) $\text{is uncountably infinite}.$ I am stuck on it and do not know how to proceed.Please help.Thanks in advance for your time.","I was thinking about the problem: The set of all continuous functions $f:[0,1]\rightarrow R$ satisfying $$\int_0^1 t^n f(t) \, dt=0,\qquad n=1,2,\ldots$$ (a) $\text{is empty},$   (b) $\text{contains a single element},$   (c) $\text{is countably infinite},$   (d) $\text{is uncountably infinite}.$ I am stuck on it and do not know how to proceed.Please help.Thanks in advance for your time.",,"['real-analysis', 'analysis', 'integration']"
50,Finding the min of an integral,Finding the min of an integral,,"So I have to find the following $$\min_{a,b,c\in\mathbb{R}}\int_{-1}^{1} |x^3-a-bx-cx^2|^2dx$$ I have a hint at a solution which says to consider $X=\{\mbox{polynomials of degree} \leq 2\}$. So then we have $$\min_{a,b,c\in\mathbb{R}}\int_{-1}^{1} |x^3-a-bx-cx^2|^2dx=\inf_{g\in X} ||x^3-g||$$ for some $g\in X$ Where the norm $||.||$ is defined using the inner product $<f,g>=\int_{-1}^{1} f(x)\bar{g(x)}dx$ So then I think I'm supposed to use an orthogonal projection somehow I think (and maybe find some orthonormal basis?) but I'm a bit lost as to how to do any of this. Thanks for any help. For completeness I am putting my solution (from the answers below). The problem reduces to finding a basis for $X$ and then orthonarmalizing it. We then use the fact that the orthohgonal projection onto the space $X$ will give the minimal distance to it so we need to calculate: $$||x^3-P(x^3)||$$ where $P(x^3)=\sum_{i=1}^{3} <x^3,e_i>e_i$ for an orthonormal basis $\{e_i\}$. Noting that the set $\{1,x,x^2\}$ spans the space $X$ we then apply the gram-schmidt process to this set to give a set of orthogonal vectors: $$\{1,x,(x^2-\frac{1}{3})\}$$. This basis now needs to be normalized but if we notice that in : $$\sum_{i=1}^{3} <x^3,e_i>e_i$$ The first and third terms will cancel as the integrand will be odd, so we only need to normailze the middle vector which gives $\{\sqrt{\frac{3}{2}\}}$. And so $$P(x^3)=<x^3,\sqrt{\frac{3}{2}}x>\sqrt{\frac{3}{2}}x=\frac{3}{5}x$$ So we now have $||x^3-\frac{3x}{5}||=\sqrt{\int_{-1}^{1} (x^3-\frac{3x}{5})^2dx}=\sqrt{\frac{8}{175}}$ Which is the desired distance","So I have to find the following $$\min_{a,b,c\in\mathbb{R}}\int_{-1}^{1} |x^3-a-bx-cx^2|^2dx$$ I have a hint at a solution which says to consider $X=\{\mbox{polynomials of degree} \leq 2\}$. So then we have $$\min_{a,b,c\in\mathbb{R}}\int_{-1}^{1} |x^3-a-bx-cx^2|^2dx=\inf_{g\in X} ||x^3-g||$$ for some $g\in X$ Where the norm $||.||$ is defined using the inner product $<f,g>=\int_{-1}^{1} f(x)\bar{g(x)}dx$ So then I think I'm supposed to use an orthogonal projection somehow I think (and maybe find some orthonormal basis?) but I'm a bit lost as to how to do any of this. Thanks for any help. For completeness I am putting my solution (from the answers below). The problem reduces to finding a basis for $X$ and then orthonarmalizing it. We then use the fact that the orthohgonal projection onto the space $X$ will give the minimal distance to it so we need to calculate: $$||x^3-P(x^3)||$$ where $P(x^3)=\sum_{i=1}^{3} <x^3,e_i>e_i$ for an orthonormal basis $\{e_i\}$. Noting that the set $\{1,x,x^2\}$ spans the space $X$ we then apply the gram-schmidt process to this set to give a set of orthogonal vectors: $$\{1,x,(x^2-\frac{1}{3})\}$$. This basis now needs to be normalized but if we notice that in : $$\sum_{i=1}^{3} <x^3,e_i>e_i$$ The first and third terms will cancel as the integrand will be odd, so we only need to normailze the middle vector which gives $\{\sqrt{\frac{3}{2}\}}$. And so $$P(x^3)=<x^3,\sqrt{\frac{3}{2}}x>\sqrt{\frac{3}{2}}x=\frac{3}{5}x$$ So we now have $||x^3-\frac{3x}{5}||=\sqrt{\int_{-1}^{1} (x^3-\frac{3x}{5})^2dx}=\sqrt{\frac{8}{175}}$ Which is the desired distance",,"['analysis', 'hilbert-spaces']"
51,The series $\sum_{n=1}^\infty \frac{n}{n+1}$,The series,\sum_{n=1}^\infty \frac{n}{n+1},"$$\sum_{n=1}^\infty \frac{n}{n+1}$$ I have $\displaystyle\lim_{n \to{+}\infty}{\frac{n}{n+1}}=\displaystyle\lim_{n \to{+}\infty}{\frac{\frac{n}{n}}{\frac{n}{n}+\frac{1}{n}}}=\displaystyle\lim_{n \to{+}\infty}{\frac{1}{1+\frac{1}{n}}}=1$ Since this is not 0, the series diverges by the divergence test. Is it right to my result?","$$\sum_{n=1}^\infty \frac{n}{n+1}$$ I have $\displaystyle\lim_{n \to{+}\infty}{\frac{n}{n+1}}=\displaystyle\lim_{n \to{+}\infty}{\frac{\frac{n}{n}}{\frac{n}{n}+\frac{1}{n}}}=\displaystyle\lim_{n \to{+}\infty}{\frac{1}{1+\frac{1}{n}}}=1$ Since this is not 0, the series diverges by the divergence test. Is it right to my result?",,"['sequences-and-series', 'analysis']"
52,Newbie question about the re-application of a function on its result,Newbie question about the re-application of a function on its result,,"This is a newbie question, but I would be grateful for any reference that you could give. let $f(x) \in \mathbb{A}$, where $x \in \mathbb{A}$ Is there a symbol to indicate the repeated application of $f$ unto its results, in a manner similar to $\sum$ and $\prod$? Thank you!","This is a newbie question, but I would be grateful for any reference that you could give. let $f(x) \in \mathbb{A}$, where $x \in \mathbb{A}$ Is there a symbol to indicate the repeated application of $f$ unto its results, in a manner similar to $\sum$ and $\prod$? Thank you!",,"['analysis', 'notation']"
53,Show that $\displaystyle\lim_{n \to \infty} \prod_{k=1}^{n} \left(1-2^{k-1-n}\right)$ exists and strictly positive.,Show that  exists and strictly positive.,\displaystyle\lim_{n \to \infty} \prod_{k=1}^{n} \left(1-2^{k-1-n}\right),"I have a question regarding limit calculations. As part of something I'm working on, I faced the challenge of calculating the limit $$ \lim_{n \to \infty}\prod_{k = 1}^{n} \left(1 - 2^{k-1-n}\right) $$ This was challenging for me and I couldn't solve this by now, although numerical calculation shows the limit exists and is strictly positive $\left(\approx 0.289\right)$ . I couldn't prove it. For my purposes it is sufficient to show the limit exists and is strictly positive. I will appreciate any help.","I have a question regarding limit calculations. As part of something I'm working on, I faced the challenge of calculating the limit This was challenging for me and I couldn't solve this by now, although numerical calculation shows the limit exists and is strictly positive . I couldn't prove it. For my purposes it is sufficient to show the limit exists and is strictly positive. I will appreciate any help.","
\lim_{n \to \infty}\prod_{k = 1}^{n} \left(1 - 2^{k-1-n}\right)
 \left(\approx 0.289\right)","['real-analysis', 'calculus', 'sequences-and-series', 'limits', 'analysis']"
54,Proof of this series converging to zero does not convince me,Proof of this series converging to zero does not convince me,,"I have a function $F$ that is bounded and such that $F(x) \to 0$ whenever $x\to 0$ . Then, I have the following series $$ \sum_{k=0}^\infty \frac{F(2^{k+1}\delta)}{2^k} $$ for $\delta > 0$ . I want to show that this series converges to $0$ as $\delta\to 0$ . Proof from the book which I don't understand Given $\epsilon > 0$ we choose $N$ so large that $$ \sum_{k \geq N} \frac{1}{2^k} < \epsilon. $$ Then, by making $\delta$ sufficiently small, we have (since $F(x)\to 0$ as $x\to 0$ ) $$ F(2^k \delta) < \frac{\epsilon}{N} $$ whenever $k=0, 1, \ldots, N-1$ . Since $F$ is bounded then the result follows. What I don't understand I am very lost by this proof. What is it doing in the first step? How does it know I can find such an $N$ ? And how does it know that by choosing $\delta$ sufficiently small, I can bound $F(2^k \delta)$ ?","I have a function that is bounded and such that whenever . Then, I have the following series for . I want to show that this series converges to as . Proof from the book which I don't understand Given we choose so large that Then, by making sufficiently small, we have (since as ) whenever . Since is bounded then the result follows. What I don't understand I am very lost by this proof. What is it doing in the first step? How does it know I can find such an ? And how does it know that by choosing sufficiently small, I can bound ?","F F(x) \to 0 x\to 0 
\sum_{k=0}^\infty \frac{F(2^{k+1}\delta)}{2^k}
 \delta > 0 0 \delta\to 0 \epsilon > 0 N 
\sum_{k \geq N} \frac{1}{2^k} < \epsilon.
 \delta F(x)\to 0 x\to 0 
F(2^k \delta) < \frac{\epsilon}{N}
 k=0, 1, \ldots, N-1 F N \delta F(2^k \delta)","['real-analysis', 'calculus', 'sequences-and-series', 'limits', 'analysis']"
55,$\int_0^\infty \frac{t}{e^t-1}dt$ without using series,without using series,\int_0^\infty \frac{t}{e^t-1}dt,"How to compute $\int_0^\infty \frac{t}{e^t-1}dt$ ? I know how to do this by using series, but I'm interested in other solutions. For example, is this possible to do with complex analysis? If it is, what is contour of integration? Any help is welcome. Thanks in advance.","How to compute ? I know how to do this by using series, but I'm interested in other solutions. For example, is this possible to do with complex analysis? If it is, what is contour of integration? Any help is welcome. Thanks in advance.",\int_0^\infty \frac{t}{e^t-1}dt,"['integration', 'analysis', 'definite-integrals']"
56,Are there extensions of Euler's infinite product for sine function?,Are there extensions of Euler's infinite product for sine function?,,"Euler product about sine function is $\frac{\sin(x)}{x} = \prod_{n=1}^\infty \left ( 1- \left(\frac{x}{n\pi}\right)^2 \right)$ I wonder if there is known results about slight modification of above product. Does there exists analytic expression about following infinite product? $\prod_{n=1}^\infty \left( 1- \left( \frac{x}{n\pi + a}\right)^2\right)$ I can't find out what it is, even though it is a slight modification.","Euler product about sine function is I wonder if there is known results about slight modification of above product. Does there exists analytic expression about following infinite product? I can't find out what it is, even though it is a slight modification.",\frac{\sin(x)}{x} = \prod_{n=1}^\infty \left ( 1- \left(\frac{x}{n\pi}\right)^2 \right) \prod_{n=1}^\infty \left( 1- \left( \frac{x}{n\pi + a}\right)^2\right),"['analysis', 'complex-analysis']"
57,Question about $x \sin(1/x)$ at $x = 0$,Question about  at,x \sin(1/x) x = 0,"I know that $f(x) = \sin(1/x)x$ takes the value $0$ at $x=0$ . What else can we say about the function $f(x)$ at $x=0$ ? More specifically, is $f$ continuous at $x=0$ ? Is it even differentiable at $x=0$ ? Thank you!","I know that takes the value at . What else can we say about the function at ? More specifically, is continuous at ? Is it even differentiable at ? Thank you!",f(x) = \sin(1/x)x 0 x=0 f(x) x=0 f x=0 x=0,"['real-analysis', 'calculus', 'complex-analysis', 'analysis']"
58,Does $\lim |a_n-b_n|=0$ imply $\lim |f(a_n)-f(b_n)|=0$?,Does  imply ?,\lim |a_n-b_n|=0 \lim |f(a_n)-f(b_n)|=0,"Let $f:\mathbb{R}_{\geq 0}\to\mathbb{R}_{\geq 0}$ a continuous function and $(a_n)$ , $(b_n)$ two sequences with values in $\mathbb{R}_{\geq 0}$ and $\lim |a_n-b_n|=0$ . Does this imply $$\lim |f(a_n)-f(b_n)|=0?$$ Hint: the sequences $a,b$ needn't to be convergent. Althoug I know this statements holds for uniformly continuous functions, I think it is not true for continuous functions generally. But no counterexample comes into my mind. Has anyone an idea?","Let a continuous function and , two sequences with values in and . Does this imply Hint: the sequences needn't to be convergent. Althoug I know this statements holds for uniformly continuous functions, I think it is not true for continuous functions generally. But no counterexample comes into my mind. Has anyone an idea?","f:\mathbb{R}_{\geq 0}\to\mathbb{R}_{\geq 0} (a_n) (b_n) \mathbb{R}_{\geq 0} \lim |a_n-b_n|=0 \lim |f(a_n)-f(b_n)|=0? a,b","['real-analysis', 'limits', 'analysis', 'continuity', 'examples-counterexamples']"
59,Finding the limit of the given series,Finding the limit of the given series,,"What is the best way to find the following limit: $$\lim_{n \to \infty} \frac{((n+1)(n+2)\cdots(n+n))^{\frac1n}}{n} $$ And what is the final value? I tried finding patterns of $\frac i n$ in the limit, but havenât reached any conclusion.","What is the best way to find the following limit: And what is the final value? I tried finding patterns of in the limit, but havenât reached any conclusion.",\lim_{n \to \infty} \frac{((n+1)(n+2)\cdots(n+n))^{\frac1n}}{n}  \frac i n,"['sequences-and-series', 'limits', 'analysis', 'definite-integrals', 'exponential-function']"
60,"Let $f:[0,1] \rightarrow\mathbb R$ be a continuous map such that $f(0)=f(1)$",Let  be a continuous map such that,"f:[0,1] \rightarrow\mathbb R f(0)=f(1)","Let $f:[0,1] \rightarrow \mathbb R$ be a continuous map such that $f(0)=f(1) .$ Let $n \geq 2$ Show that there is some $x \in[0,1]$ such that $f(x)=f\left(x+\frac{1}{n}\right) .$ My attempt. Assume $f(x)\neq f(x+1/n)$ for all $x$ . Then either $f(x)<f(x+1/n)$ or $f(x)>f(x+1/n)$ . WLOG, assume $f(x)<f(x+1/n)$ . Then $f(0) So how can I get a contradiction? May you help?","Let be a continuous map such that Let Show that there is some such that My attempt. Assume for all . Then either or . WLOG, assume . Then $f(0) So how can I get a contradiction? May you help?","f:[0,1] \rightarrow \mathbb R f(0)=f(1) . n \geq 2 x \in[0,1] f(x)=f\left(x+\frac{1}{n}\right) . f(x)\neq f(x+1/n) x f(x)<f(x+1/n) f(x)>f(x+1/n) f(x)<f(x+1/n)",['real-analysis']
61,How to show $f\equiv 0$?,How to show ?,f\equiv 0,"$f(x)$ is differentiable, and  for any $x\in \mathbb R$ , $|f'(x)|\le \lambda |x|$ , then how to show $f\equiv 0$ ? This is a question my student ask me, but I don't know how to deal it. So ask help here. Thanks for any hint or answer.","is differentiable, and  for any , , then how to show ? This is a question my student ask me, but I don't know how to deal it. So ask help here. Thanks for any hint or answer.",f(x) x\in \mathbb R |f'(x)|\le \lambda |x| f\equiv 0,['analysis']
62,Prove that $\sqrt[n]{n} < (1 + \frac{1}{\sqrt{n}})^2$ for all n in the naturals.,Prove that  for all n in the naturals.,\sqrt[n]{n} < (1 + \frac{1}{\sqrt{n}})^2,I need to prove that $\sqrt[n]{n} < (1 + \frac{1}{\sqrt{n}})^2$ for all n in the naturals. I started by using Bernoulli's inequality: $(1+\frac{2}{\sqrt{n}}) < (1 + \frac{1}{\sqrt{n}})^2$ I can say that: $(1+\frac{2}{\sqrt{n}}) = (1+\frac{2\sqrt{n}}{n})$ I can also subtract the one and divide by 2 on the left side without changing the inequality (because it makes it even smaller): $(\frac{\sqrt{n}}{n}) < (1 + \frac{1}{\sqrt{n}})^2$ But now I am stuck...,I need to prove that for all n in the naturals. I started by using Bernoulli's inequality: I can say that: I can also subtract the one and divide by 2 on the left side without changing the inequality (because it makes it even smaller): But now I am stuck...,\sqrt[n]{n} < (1 + \frac{1}{\sqrt{n}})^2 (1+\frac{2}{\sqrt{n}}) < (1 + \frac{1}{\sqrt{n}})^2 (1+\frac{2}{\sqrt{n}}) = (1+\frac{2\sqrt{n}}{n}) (\frac{\sqrt{n}}{n}) < (1 + \frac{1}{\sqrt{n}})^2,"['real-analysis', 'analysis']"
63,"What is wrong in my ""proof"" that $\cup_{k=N}^{\infty} E_k - \cap_{k=N}^{\infty} E_k = \emptyset$","What is wrong in my ""proof"" that",\cup_{k=N}^{\infty} E_k - \cap_{k=N}^{\infty} E_k = \emptyset,"I was doing a problem involving limits of sets, and I wanted to figure out what $$\bigcup_{k=N}^{\infty} E_k - \bigcap_{k=N}^{\infty} E_k$$ is. I got that it is empty, which is obviously false (for instance, $E_k = \{k \}$ is a counterexample). The following is my ""proof."" Could you please take a look and point out the mistake? Thanks. We begin with the original: $$\bigcup_{k=N}^{\infty} E_k - \bigcap_{k=N}^{\infty} E_k.$$ Definition of set difference $$\left(\bigcup_{k=N}^{\infty} E_k  \right) \bigcap \left( \bigcap_{k=N}^{\infty} E_k\right)^c$$ DeMorgan's Law $$\left(\bigcup_{k=N}^{\infty} E_k  \right) \bigcap \left(\bigcup_{k=N}^{\infty} E_k^c \right) $$ Distribution Law $$\bigcup_{k=N}^{\infty} \left[ E_k \bigcap \left(\bigcup_{k=N}^{\infty} E_k^c   \right) \right] $$ Distribution Law again $$\bigcup_{k=N}^{\infty}\left[ \bigcup_{k=N}^{\infty} E_k \cap E_k^c\right]$$ $$=\bigcup_{k=N}^{\infty}\left[ \bigcup_{k=N}^{\infty} \emptyset\right] $$ $$= \emptyset$$","I was doing a problem involving limits of sets, and I wanted to figure out what is. I got that it is empty, which is obviously false (for instance, is a counterexample). The following is my ""proof."" Could you please take a look and point out the mistake? Thanks. We begin with the original: Definition of set difference DeMorgan's Law Distribution Law Distribution Law again",\bigcup_{k=N}^{\infty} E_k - \bigcap_{k=N}^{\infty} E_k E_k = \{k \} \bigcup_{k=N}^{\infty} E_k - \bigcap_{k=N}^{\infty} E_k. \left(\bigcup_{k=N}^{\infty} E_k  \right) \bigcap \left( \bigcap_{k=N}^{\infty} E_k\right)^c \left(\bigcup_{k=N}^{\infty} E_k  \right) \bigcap \left(\bigcup_{k=N}^{\infty} E_k^c \right)  \bigcup_{k=N}^{\infty} \left[ E_k \bigcap \left(\bigcup_{k=N}^{\infty} E_k^c   \right) \right]  \bigcup_{k=N}^{\infty}\left[ \bigcup_{k=N}^{\infty} E_k \cap E_k^c\right] =\bigcup_{k=N}^{\infty}\left[ \bigcup_{k=N}^{\infty} \emptyset\right]  = \emptyset,"['real-analysis', 'analysis', 'elementary-set-theory']"
64,Solve $3x(2+\sqrt{9x^2 + 3}) + (4x-2)(\sqrt{x^2 - x +1}+1) = 0$ for $x\in \mathbb{R}$,Solve  for,3x(2+\sqrt{9x^2 + 3}) + (4x-2)(\sqrt{x^2 - x +1}+1) = 0 x\in \mathbb{R},"Solve the equation in $ \mathbb{R}$ : $$3x(2+\sqrt{9x^2 + 3}) + (4x-2)(\sqrt{x^2 - x +1}+1) = 0$$ I've been tried to solve this question for  3 hours, but can't find out any answers. Just like I running in the maze, if I represent $\sqrt{9x^2 + 3} = A$ , $ \sqrt{x^{2}-x+1}= B$ Finally we've got $2A^{2} -15 = 18B^2 + 9\sqrt{4B^2 +1}$ , which is not help me to find relation between $A$ and $B$ anymore. I just wonder if we have a nice solution approaches to the problem. I appreciate any suggestion and help. Thank you.","Solve the equation in : I've been tried to solve this question for  3 hours, but can't find out any answers. Just like I running in the maze, if I represent , Finally we've got , which is not help me to find relation between and anymore. I just wonder if we have a nice solution approaches to the problem. I appreciate any suggestion and help. Thank you.", \mathbb{R} 3x(2+\sqrt{9x^2 + 3}) + (4x-2)(\sqrt{x^2 - x +1}+1) = 0 \sqrt{9x^2 + 3} = A  \sqrt{x^{2}-x+1}= B 2A^{2} -15 = 18B^2 + 9\sqrt{4B^2 +1} A B,"['algebra-precalculus', 'analysis', 'functions', 'polynomials', 'roots']"
65,"Let $a_n \to 0$, then $\lim_{n \to \infty} (a_{n+1}-a_n)n $ equals to ??","Let , then  equals to ??",a_n \to 0 \lim_{n \to \infty} (a_{n+1}-a_n)n ,"Let $a_n \to 0.$ Then $$\lim_{n \to \infty} (a_{n+1}-a_n)n $$ equals to ?? I have taken a few examples and got that the limit equals to zero. It seems that the limit is zero, but how to prove it in general ? or my guess is wrong... Please provide some hint. Thank you.","Let Then equals to ?? I have taken a few examples and got that the limit equals to zero. It seems that the limit is zero, but how to prove it in general ? or my guess is wrong... Please provide some hint. Thank you.",a_n \to 0. \lim_{n \to \infty} (a_{n+1}-a_n)n ,"['real-analysis', 'calculus', 'sequences-and-series', 'analysis']"
66,The space of all finite-degree polynomials $\mathbb{P}$ is not complete in any norm. [closed],The space of all finite-degree polynomials  is not complete in any norm. [closed],\mathbb{P},"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Let $\mathbb{P}$ denote the space of all finite degree polynomials in one   variable. Show that $\mathbb{P}$ is never complete with respect to $P_1$ norm, i.e., $\|\cdot\|_1$ by giving an example Cauchy sequence that does   not converge inside $\mathbb{P}$ ?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Let denote the space of all finite degree polynomials in one   variable. Show that is never complete with respect to norm, i.e., by giving an example Cauchy sequence that does   not converge inside ?",\mathbb{P} \mathbb{P} P_1 \|\cdot\|_1 \mathbb{P},"['real-analysis', 'analysis', 'polynomials', 'cauchy-sequences', 'complete-spaces']"
67,"Counterexample: If $\sum_{n=1}^{\infty}a_n=1$ and each $a_n\geq 0,$ then $\lim\limits_{n\to}na_n=0$",Counterexample: If  and each  then,"\sum_{n=1}^{\infty}a_n=1 a_n\geq 0, \lim\limits_{n\to}na_n=0","I'm studying for an exam and I ran into these problems. I'm having a feeling that this is not true. Hence, I don't need to prove. I need to just provide a counterexample. However, the appropriate example is not just coming. Any help? Prove or give a counterexample: If $\sum_{n=1}^{\infty}a_n=1$ and each $a_n\geq 0,$ then $\lim\limits_{n\to\infty}na_n=0$ If $a_n\geq 0$ and $\sum_{n=1}^{\infty}a_n$ converges, then $\lim\limits_{n\to\infty}na_n=0$","I'm studying for an exam and I ran into these problems. I'm having a feeling that this is not true. Hence, I don't need to prove. I need to just provide a counterexample. However, the appropriate example is not just coming. Any help? Prove or give a counterexample: If $\sum_{n=1}^{\infty}a_n=1$ and each $a_n\geq 0,$ then $\lim\limits_{n\to\infty}na_n=0$ If $a_n\geq 0$ and $\sum_{n=1}^{\infty}a_n$ converges, then $\lim\limits_{n\to\infty}na_n=0$",,"['real-analysis', 'sequences-and-series', 'analysis', 'limits']"
68,"Is the squaring function uniformly continuous on $[0, +\infty)$?",Is the squaring function uniformly continuous on ?,"[0, +\infty)","Is the function $f: I \to I, ~x \mapsto x^2$ uniformly continuous on $I :=[0, +\infty)$? I know that $f$ is uniformly continuous on every interval of the form $[0, b]$, where $b$ is a positive real number.","Is the function $f: I \to I, ~x \mapsto x^2$ uniformly continuous on $I :=[0, +\infty)$? I know that $f$ is uniformly continuous on every interval of the form $[0, b]$, where $b$ is a positive real number.",,"['calculus', 'real-analysis', 'analysis', 'continuity', 'uniform-continuity']"
69,Let $X$ locally compact and $\sigma$-compact. Then any open subset is also $\sigma$-compact,Let  locally compact and -compact. Then any open subset is also -compact,X \sigma \sigma,"Im stuck with this exercise Show that if $X$ is locally compact and $\sigma$-compact then any open subset is also $\sigma$-compact. Note: here locally compactness imply that the space is also Hausdorff. This exercise is the last part of a longer exercise where the previous part was this . If the linked exercise would be true (but it is not) then a locally compact and $\sigma$-compact space would be separable, and because I also know that open sets of locally compact spaces are also locally compact then the proof would be (I guess) easier to prove following this path. However, as I said, the statement of $X$ being locally compact and $\sigma$-compact imply that it is also separable is not true in general. Then its possible that also this part of the exercise is wrong (that is, that the statement to be proved would be false). In any case I dont find something to work to prove the statement. My first attempt was trying to show that if $X$ is LindelÃ¶f, $\sigma$-compact and locally compact then any open set is also LindelÃ¶f, but I dont found a way to show it, thus I'm lost again in the starting point. The exercise appear (as stated in the linked question) in a book of analysis so it is supposed that it can be solved using elementary notions of topology. Can someone confirm if the statement to be proved is really true or if, by the contrary, it is other mistake in the book? If it would be solvable, can someone give me a hint? Thank you.","Im stuck with this exercise Show that if $X$ is locally compact and $\sigma$-compact then any open subset is also $\sigma$-compact. Note: here locally compactness imply that the space is also Hausdorff. This exercise is the last part of a longer exercise where the previous part was this . If the linked exercise would be true (but it is not) then a locally compact and $\sigma$-compact space would be separable, and because I also know that open sets of locally compact spaces are also locally compact then the proof would be (I guess) easier to prove following this path. However, as I said, the statement of $X$ being locally compact and $\sigma$-compact imply that it is also separable is not true in general. Then its possible that also this part of the exercise is wrong (that is, that the statement to be proved would be false). In any case I dont find something to work to prove the statement. My first attempt was trying to show that if $X$ is LindelÃ¶f, $\sigma$-compact and locally compact then any open set is also LindelÃ¶f, but I dont found a way to show it, thus I'm lost again in the starting point. The exercise appear (as stated in the linked question) in a book of analysis so it is supposed that it can be solved using elementary notions of topology. Can someone confirm if the statement to be proved is really true or if, by the contrary, it is other mistake in the book? If it would be solvable, can someone give me a hint? Thank you.",,"['general-topology', 'analysis']"
70,"Prob. 3, Sec. 3.4, in Bartle & Sherbert's INTRO TO REAL ANALYSIS, 4th ed: Does this sequence converge?","Prob. 3, Sec. 3.4, in Bartle & Sherbert's INTRO TO REAL ANALYSIS, 4th ed: Does this sequence converge?",,"Let the sequence $\left( f_n \right)_{n \in \mathbb{N} }$ be given by  $$ f_1 \colon= 1, \qquad f_2 \colon= 1, \qquad \mbox{ and } \qquad f_n \colon= f_{n-1} + f_{n-2} \ \mbox{ for all } n \in \mathbb{N} \mbox{ such that } n > 2. $$ That is, $\left( f_n \right)_{n \in \mathbb{N} }$ is the famous Fibonacci sequence. Now let the sequence $\left( x_n \right)_{n \in \mathbb{N} }$ be given by  $$ x_n \colon= \frac{f_{n+1} }{f_n} \ \mbox{ for all } n \in  \mathbb{N}. $$ Thus we have  $$ x_1 = \frac{f_2}{f_1} = 1, $$ and  $$ x_n = \frac{ f_n + f_{n-1} }{f_n} = 1 + \frac{f_{n-1}}{f_n} \ \mbox{ for all } n \in  \mathbb{N} \mbox{ such that } n \geq 2. $$ Does the sequence $\left( x_n \right)_{n \in \mathbb{N} }$ converge in $\mathbb{R}$? If so, then what is $\lim_{n \to \infty} x_n$? My Attempt: First, we note that $$ f_1 = f_2 = 1, \ f_3 = f_2+ f_1 = 2, \ f_4 = f_3 + f_2 = 3, \ f_5 = f_4 + f_3 = 5, \ f_6 = f_5 + f_4 = 8, \\ f_7 = f_6 + f_5 = 13, \ f_8 = f_7 + f_6 = 21, \ f_9 = f_8 + f_7 = 34, \ f_{10} = f_9 + f_8 = 55. \\ f_{11} = f_{10} + f_9 = 89, \ f_{12} = f_{11} + f_{10} = 144, \ f_{13} = f_{12} + f_{11} = 233, \\ f_{14} = f_{13} + f_{12} = 377. $$   So    $$ x_1 = \frac{f_2}{f_1} = 1, \ x_2 = \frac{f_3}{f_2} = 2, \ x_3 = \frac{f_4}{f_3} = \frac{3}{2}, \ x_4 = \frac{f_5}{f_4} = \frac{5}{3}, \ x_5 = \frac{f_6}{f_5} = \frac{8}{5}, \\ x_6 = \frac{f_7}{f_6} = \frac{13}{8}, \ x_7 =  \frac{f_8}{f_7} = \frac{21}{13}, \ x_8 = \frac{f_9}{f_8} = \frac{34}{21}, \ x_9 = \frac{f_{10}}{f_9} = \frac{55}{34}, \ x_{10} = \frac{f_{11}}{f_{10}} = \frac{89}{55}, \\ x_{11} = \frac{f_{12}}{f_{11}} = \frac{144}{89}, \ x_{12} = \frac{f_{13}}{f_{12}} = \frac{233}{144}, \ x_{13} = \frac{f_{14}}{f_{13}} = \frac{377}{233}.     $$ From these calculations we notice that    $$ x_1 < x_3 < x_5 < x_7 < x_9 < x_{11} < x_{13} < 2, $$    and    $$ x_2 > x_4 > x_6 > x_8 > x_{10} > x_{12} > 0.  $$ How to proceed from here? How to show that  $$ x_{2n-1} < x_{2n+1} \ \mbox{ and } \ x_{2n} > x_{2n+2} \ \mbox{ for all } n \in \mathbb{N}?$$ And, how to show that the subsequence $\left( x_{2n-1} \right)_{n \in \mathbb{N} }$ of $\left(x_n \right)_{n \in \mathbb{N}}$ is bounded above? Can we treat it as obvious that the subsequence $\left( x_{2n} \right)_{n \in \mathbb{N} }$ of $\left( x_n \right)_{n \in \mathbb{N} }$ is bounded from below by $0$? Once we have shown that the subsequence $\left( x_{2n-1} \right)_{n \in \mathbb{N} }$ is increasing and bounded from above, then let us put  $$ x^\prime \colon= \lim_{n \to \infty} x_{2n-1}. $$ And, once we have shown that the subsequence $\left( x_{2n} \right)_{n \in \mathbb{N} }$ is decreasing and bounded from below, then let us put  $$ x^* \colon= \lim_{n \to \infty} x_{2n}. $$ How to proceed from here? Can we show that $x^{\prime} = x^*$? And, once we have shown this, then how to find $\lim_{n \to \infty} x_n$?","Let the sequence $\left( f_n \right)_{n \in \mathbb{N} }$ be given by  $$ f_1 \colon= 1, \qquad f_2 \colon= 1, \qquad \mbox{ and } \qquad f_n \colon= f_{n-1} + f_{n-2} \ \mbox{ for all } n \in \mathbb{N} \mbox{ such that } n > 2. $$ That is, $\left( f_n \right)_{n \in \mathbb{N} }$ is the famous Fibonacci sequence. Now let the sequence $\left( x_n \right)_{n \in \mathbb{N} }$ be given by  $$ x_n \colon= \frac{f_{n+1} }{f_n} \ \mbox{ for all } n \in  \mathbb{N}. $$ Thus we have  $$ x_1 = \frac{f_2}{f_1} = 1, $$ and  $$ x_n = \frac{ f_n + f_{n-1} }{f_n} = 1 + \frac{f_{n-1}}{f_n} \ \mbox{ for all } n \in  \mathbb{N} \mbox{ such that } n \geq 2. $$ Does the sequence $\left( x_n \right)_{n \in \mathbb{N} }$ converge in $\mathbb{R}$? If so, then what is $\lim_{n \to \infty} x_n$? My Attempt: First, we note that $$ f_1 = f_2 = 1, \ f_3 = f_2+ f_1 = 2, \ f_4 = f_3 + f_2 = 3, \ f_5 = f_4 + f_3 = 5, \ f_6 = f_5 + f_4 = 8, \\ f_7 = f_6 + f_5 = 13, \ f_8 = f_7 + f_6 = 21, \ f_9 = f_8 + f_7 = 34, \ f_{10} = f_9 + f_8 = 55. \\ f_{11} = f_{10} + f_9 = 89, \ f_{12} = f_{11} + f_{10} = 144, \ f_{13} = f_{12} + f_{11} = 233, \\ f_{14} = f_{13} + f_{12} = 377. $$   So    $$ x_1 = \frac{f_2}{f_1} = 1, \ x_2 = \frac{f_3}{f_2} = 2, \ x_3 = \frac{f_4}{f_3} = \frac{3}{2}, \ x_4 = \frac{f_5}{f_4} = \frac{5}{3}, \ x_5 = \frac{f_6}{f_5} = \frac{8}{5}, \\ x_6 = \frac{f_7}{f_6} = \frac{13}{8}, \ x_7 =  \frac{f_8}{f_7} = \frac{21}{13}, \ x_8 = \frac{f_9}{f_8} = \frac{34}{21}, \ x_9 = \frac{f_{10}}{f_9} = \frac{55}{34}, \ x_{10} = \frac{f_{11}}{f_{10}} = \frac{89}{55}, \\ x_{11} = \frac{f_{12}}{f_{11}} = \frac{144}{89}, \ x_{12} = \frac{f_{13}}{f_{12}} = \frac{233}{144}, \ x_{13} = \frac{f_{14}}{f_{13}} = \frac{377}{233}.     $$ From these calculations we notice that    $$ x_1 < x_3 < x_5 < x_7 < x_9 < x_{11} < x_{13} < 2, $$    and    $$ x_2 > x_4 > x_6 > x_8 > x_{10} > x_{12} > 0.  $$ How to proceed from here? How to show that  $$ x_{2n-1} < x_{2n+1} \ \mbox{ and } \ x_{2n} > x_{2n+2} \ \mbox{ for all } n \in \mathbb{N}?$$ And, how to show that the subsequence $\left( x_{2n-1} \right)_{n \in \mathbb{N} }$ of $\left(x_n \right)_{n \in \mathbb{N}}$ is bounded above? Can we treat it as obvious that the subsequence $\left( x_{2n} \right)_{n \in \mathbb{N} }$ of $\left( x_n \right)_{n \in \mathbb{N} }$ is bounded from below by $0$? Once we have shown that the subsequence $\left( x_{2n-1} \right)_{n \in \mathbb{N} }$ is increasing and bounded from above, then let us put  $$ x^\prime \colon= \lim_{n \to \infty} x_{2n-1}. $$ And, once we have shown that the subsequence $\left( x_{2n} \right)_{n \in \mathbb{N} }$ is decreasing and bounded from below, then let us put  $$ x^* \colon= \lim_{n \to \infty} x_{2n}. $$ How to proceed from here? Can we show that $x^{\prime} = x^*$? And, once we have shown this, then how to find $\lim_{n \to \infty} x_n$?",,"['real-analysis', 'sequences-and-series', 'analysis', 'limits', 'convergence-divergence']"
71,Estimate from below of the sine (and from above of cosine),Estimate from below of the sine (and from above of cosine),,"I'm trying to do the following exercise with no success. I'm asked to prove that $$\sin(x) \ge x-\frac{x^3}{2}\,, \qquad \forall x\in [0,1]$$ By using Taylor's expansion, it's basically immediate that one has the better estimate $$\sin(x) \ge x-\frac{x^3}{6}\,, \qquad \forall x\in [0,1]$$ as the tail converges absolutely, and one can check that the difference of consecutive terms is positive. I suppose then, there is a more elementary way to get the first one. Question is: how? Relatedly, the same exercise asks me to prove that $$\cos(x) \le \frac{1}{\sqrt{1+x^2}}\,,\qquad \forall x\in [0,1]$$ which again I can prove by using differentiation techniques. But these haven't been explained at that point of the text, so I wonder how to do it ""elementarly"".","I'm trying to do the following exercise with no success. I'm asked to prove that $$\sin(x) \ge x-\frac{x^3}{2}\,, \qquad \forall x\in [0,1]$$ By using Taylor's expansion, it's basically immediate that one has the better estimate $$\sin(x) \ge x-\frac{x^3}{6}\,, \qquad \forall x\in [0,1]$$ as the tail converges absolutely, and one can check that the difference of consecutive terms is positive. I suppose then, there is a more elementary way to get the first one. Question is: how? Relatedly, the same exercise asks me to prove that $$\cos(x) \le \frac{1}{\sqrt{1+x^2}}\,,\qquad \forall x\in [0,1]$$ which again I can prove by using differentiation techniques. But these haven't been explained at that point of the text, so I wonder how to do it ""elementarly"".",,"['calculus', 'real-analysis', 'analysis', 'trigonometry', 'inequality']"
72,Closed form of the $n^{th}$-derivative of $f(x) = \arctan x$,Closed form of the -derivative of,n^{th} f(x) = \arctan x,"My problem is about characterization of the $n^{th}$-derivative of  $$f(x) = \arctan x$$ We were asked to solve the following questions Show that $$ f^{(n)} (x) = \frac{P_n(x)}{(1+x^2)^{n}}~~~n\ge1$$ Where $P_n$ is polynomial of degree to be specify. Find a recurrent relationships Between the $P_n's.$ Then, Give the expression of $P_n(x) . $ My attempt I was able to prove just comparison with derivative that $$ P_{n+1}(x) = (1+x^2)P'_n(x) -2nx P_n(x)$$ This therefore gives a solution to questions 1. and 2.  Note that from this, since $P_1 = 1$ we have $$\deg P_n = n-1$$ I do not know how to solve the last Question.","My problem is about characterization of the $n^{th}$-derivative of  $$f(x) = \arctan x$$ We were asked to solve the following questions Show that $$ f^{(n)} (x) = \frac{P_n(x)}{(1+x^2)^{n}}~~~n\ge1$$ Where $P_n$ is polynomial of degree to be specify. Find a recurrent relationships Between the $P_n's.$ Then, Give the expression of $P_n(x) . $ My attempt I was able to prove just comparison with derivative that $$ P_{n+1}(x) = (1+x^2)P'_n(x) -2nx P_n(x)$$ This therefore gives a solution to questions 1. and 2.  Note that from this, since $P_1 = 1$ we have $$\deg P_n = n-1$$ I do not know how to solve the last Question.",,"['real-analysis', 'analysis', 'derivatives', 'polynomials', 'closed-form']"
73,$ f(x)\leq f(x+\frac{1}{n} )$ for all $x\in \mathbb{R}$ and $n\geq 1$ . Prove that $f$ is non-decreasing .,for all  and  . Prove that  is non-decreasing ., f(x)\leq f(x+\frac{1}{n} ) x\in \mathbb{R} n\geq 1 f,Let $f:\mathbb{R} \rightarrow \mathbb{R}$ be a continuous function such that $ f(x)\leq f(x+\frac{1}{n} )$ for all $x\in \mathbb{R}$ and $n\geq 1$ . Prove that $f$ is non-decreasing . I realy don't have any ideas. My first try was that by archemddian and well ordering  property there exists a smallest $n$ such that $n(y-x)\geq 1  $ where it was chosen such that $y>x$ .  Now if $y=x+\frac{1}{n} $ Then $f(y)=f(x+\frac{1}{n}) >f(x) $ . Now if $y>x+\frac{1}{n} $  i have no idea how to proceed . So provide a solution . Thank you .,Let $f:\mathbb{R} \rightarrow \mathbb{R}$ be a continuous function such that $ f(x)\leq f(x+\frac{1}{n} )$ for all $x\in \mathbb{R}$ and $n\geq 1$ . Prove that $f$ is non-decreasing . I realy don't have any ideas. My first try was that by archemddian and well ordering  property there exists a smallest $n$ such that $n(y-x)\geq 1  $ where it was chosen such that $y>x$ .  Now if $y=x+\frac{1}{n} $ Then $f(y)=f(x+\frac{1}{n}) >f(x) $ . Now if $y>x+\frac{1}{n} $  i have no idea how to proceed . So provide a solution . Thank you .,,"['calculus', 'real-analysis', 'analysis']"
74,proof Intermediate Value Theorem,proof Intermediate Value Theorem,,"Intermediate Value Theorem The idea of the proof is to look for the first point at which the graph of f crosses the axis. Let X = {x â [a, b] | f (y) â¤ 0 for all y â [a, x]}. Then X is non-empty since a â X and X â [a, b] so it is bounded. Hence by the Completeness Axiom, X has a least upper bound Î± (say). We claim that f (Î±) = 0. how can be written it formal?","Intermediate Value Theorem The idea of the proof is to look for the first point at which the graph of f crosses the axis. Let X = {x â [a, b] | f (y) â¤ 0 for all y â [a, x]}. Then X is non-empty since a â X and X â [a, b] so it is bounded. Hence by the Completeness Axiom, X has a least upper bound Î± (say). We claim that f (Î±) = 0. how can be written it formal?",,"['calculus', 'real-analysis', 'analysis', 'limits', 'convergence-divergence']"
75,"show that for $n=1,2,...,$ the number $1+1/2+1/3+...+1/n-\ln(n)$ is positive",show that for  the number  is positive,"n=1,2,..., 1+1/2+1/3+...+1/n-\ln(n)","show that for $n=1,2,...,$ the number  $1+\frac{1}{2}+\frac{1}{3}+...+\frac{1}{n}-\ln(n)$ is positive, that it decreases as $n$ increases, and hence that the sequence of these numbers converges to a limit between $0$ and $1$ (Euler's constant). I'm trying to prove this by induction on $n$ and I made the base step, I could not with the inductive step because to do so suppose that for $n=1,2,\dots,$ it is true that $1+\frac{1}{2}+\frac{1}{3}+\dots+\frac{1}{n}-\ln(n)$ is positive and let's see that $1+\frac{1}{2}+\frac{1}{3}+...+\frac{1}{n}+\frac{1}{n+1}-\ln(n+1)$ is positive,  We see that \begin{align} &1+\frac{1}{2}+\frac{1}{3}+\dots+\frac{1}{n}+\frac{1}{n+1})-\ln(n+1)\\ =&1+\frac{1}{2}+\frac{1}{3}+\dots+\frac{1}{n}-\ln(n)+\frac{1}{n+1}-\ln(n+1)+\ln(n)\\ >&\frac{1}{n+1}-\ln(n+1)+\ln(n) \end{align} But I do not know how to prove that $\frac{1}{n+1}-\ln(n+1)+\ln(n)>0$  what do you say? Can you do what I did?","show that for $n=1,2,...,$ the number  $1+\frac{1}{2}+\frac{1}{3}+...+\frac{1}{n}-\ln(n)$ is positive, that it decreases as $n$ increases, and hence that the sequence of these numbers converges to a limit between $0$ and $1$ (Euler's constant). I'm trying to prove this by induction on $n$ and I made the base step, I could not with the inductive step because to do so suppose that for $n=1,2,\dots,$ it is true that $1+\frac{1}{2}+\frac{1}{3}+\dots+\frac{1}{n}-\ln(n)$ is positive and let's see that $1+\frac{1}{2}+\frac{1}{3}+...+\frac{1}{n}+\frac{1}{n+1}-\ln(n+1)$ is positive,  We see that \begin{align} &1+\frac{1}{2}+\frac{1}{3}+\dots+\frac{1}{n}+\frac{1}{n+1})-\ln(n+1)\\ =&1+\frac{1}{2}+\frac{1}{3}+\dots+\frac{1}{n}-\ln(n)+\frac{1}{n+1}-\ln(n+1)+\ln(n)\\ >&\frac{1}{n+1}-\ln(n+1)+\ln(n) \end{align} But I do not know how to prove that $\frac{1}{n+1}-\ln(n+1)+\ln(n)>0$  what do you say? Can you do what I did?",,"['real-analysis', 'sequences-and-series', 'analysis', 'induction', 'logarithms']"
76,Show that $\frac {1} {r-1} = \frac {1} {r+1} + \frac {2} {r^2+1} + \frac {4} {r^4+1} +\cdots$,Show that,\frac {1} {r-1} = \frac {1} {r+1} + \frac {2} {r^2+1} + \frac {4} {r^4+1} +\cdots,"Problem: Show that $$\frac {1} {r-1} = \frac {1} {r+1} + \frac {2} {r^2+1} + \frac {4} {r^4+1} +\cdots $$ for all $r > 1$, with a hint given that $\displaystyle\frac {1} {r-1} - \frac {1} {r+1} = \frac {2} {r^2-1}$. Thoughts : I am having difficulty seeing a connection from the hint to the problem. Any insights appreciated.","Problem: Show that $$\frac {1} {r-1} = \frac {1} {r+1} + \frac {2} {r^2+1} + \frac {4} {r^4+1} +\cdots $$ for all $r > 1$, with a hint given that $\displaystyle\frac {1} {r-1} - \frac {1} {r+1} = \frac {2} {r^2-1}$. Thoughts : I am having difficulty seeing a connection from the hint to the problem. Any insights appreciated.",,"['sequences-and-series', 'analysis']"
77,Does this sequences convergence? $a_{n} = n \cdot \sin(\frac{2}{n})$ for $n \rightarrow \infty$?,Does this sequences convergence?  for ?,a_{n} = n \cdot \sin(\frac{2}{n}) n \rightarrow \infty,"Does this sequences convergence for $n \rightarrow \infty$? $$a_{n} = n \cdot \sin(\frac{2}{n}) $$? Very problematic task.. $n$ alone would diverge to $\infty$ and $sin(\frac{2}{n})$ would converge to $0$. So we got $\infty \cdot 0$ which means we need to use HÃ´pital's rule. For use this rule we need fraction: $$\frac{n}{\frac{1}{sin(\frac{2}{n})}}$$ $$\left ( n\right )' = 1$$ $$\left (\frac{1}{sin(\frac{2}{n})} \right )' = \frac{2 cos(\frac{2}{n})}{n^{2} \cdot sin^{2}(\frac{2}{n})}$$ $$\Rightarrow$$ $$\frac{1}{\frac{2 cos(\frac{2}{n})}{n^{2} \cdot sin^{2}(\frac{2}{n})}} = \frac{n^{2} \cdot sin^{2}(\frac{2}{n})}{2 cos(\frac{2}{n})}$$ Problem still remains, $$\frac{\infty^{2} \cdot 0^{2}}{2 \cdot 1}$$ I would just say that the sequence diverges.. No idea what else I can do. What you think about my solution?","Does this sequences convergence for $n \rightarrow \infty$? $$a_{n} = n \cdot \sin(\frac{2}{n}) $$? Very problematic task.. $n$ alone would diverge to $\infty$ and $sin(\frac{2}{n})$ would converge to $0$. So we got $\infty \cdot 0$ which means we need to use HÃ´pital's rule. For use this rule we need fraction: $$\frac{n}{\frac{1}{sin(\frac{2}{n})}}$$ $$\left ( n\right )' = 1$$ $$\left (\frac{1}{sin(\frac{2}{n})} \right )' = \frac{2 cos(\frac{2}{n})}{n^{2} \cdot sin^{2}(\frac{2}{n})}$$ $$\Rightarrow$$ $$\frac{1}{\frac{2 cos(\frac{2}{n})}{n^{2} \cdot sin^{2}(\frac{2}{n})}} = \frac{n^{2} \cdot sin^{2}(\frac{2}{n})}{2 cos(\frac{2}{n})}$$ Problem still remains, $$\frac{\infty^{2} \cdot 0^{2}}{2 \cdot 1}$$ I would just say that the sequence diverges.. No idea what else I can do. What you think about my solution?",,"['calculus', 'sequences-and-series', 'analysis', 'convergence-divergence']"
78,Decide if the series converges and prove it using comparison test: $\sum_{k=1}^{\infty}\frac{3k^{2}+k+1}{k^{4}+k^{3}+4}$,Decide if the series converges and prove it using comparison test:,\sum_{k=1}^{\infty}\frac{3k^{2}+k+1}{k^{4}+k^{3}+4},Decide if the series converges and prove it using comparison test:   $\sum_{k=1}^{\infty}\frac{3k^{2}+k+1}{k^{4}+k^{3}+4}$ $$\sum_{k=1}^{\infty}\frac{3k^{2}+k+1}{k^{4}+k^{3}+4}< \frac{k^{2}+k}{k^{4}+k^{3}} < \frac{k^{2}}{k^{4}} \leq \frac{1}{k^{2}}$$ We know (from our readings) that $\sum_{k=1}^{\infty}\frac{1}{k^{2}}$ is a converging series. Thus the complete series will converge. Did I do everything correctly?,Decide if the series converges and prove it using comparison test:   $\sum_{k=1}^{\infty}\frac{3k^{2}+k+1}{k^{4}+k^{3}+4}$ $$\sum_{k=1}^{\infty}\frac{3k^{2}+k+1}{k^{4}+k^{3}+4}< \frac{k^{2}+k}{k^{4}+k^{3}} < \frac{k^{2}}{k^{4}} \leq \frac{1}{k^{2}}$$ We know (from our readings) that $\sum_{k=1}^{\infty}\frac{1}{k^{2}}$ is a converging series. Thus the complete series will converge. Did I do everything correctly?,,"['calculus', 'sequences-and-series', 'analysis', 'convergence-divergence']"
79,Very strange - what's the limit of $\lim_{x \rightarrow 0}\frac{sin(x)+cos(x)}{x}$?,Very strange - what's the limit of ?,\lim_{x \rightarrow 0}\frac{sin(x)+cos(x)}{x},"What's the limit of: $\lim_{x \rightarrow 0}\frac{sin(x)+cos(x)}{x}$ ? $\lim_{x \rightarrow 0} \left (sin(x) + cos(x) \right) = sin(0)+cos(0) = 1 $ $\lim_{x \rightarrow 0} x = 0$ $\Rightarrow \frac{1}{0} \Rightarrow$ L'HÃ´pital's rule is needed $f'(x) = cos(x) - sin(x)$ $g'(x) = 1$ $\Rightarrow $ $\lim_{x\rightarrow 0} \left (cos(x) - sin(x) \right ) = cos(0) -sin(0) = 1-0 = 1$ So 1 will be the limit? No way because as it looks like, the denumerator will be too small and thus the complete function will go towards $\infty$ for $x \rightarrow 0$. This is very confusing for me :S Maybe the mistake is using L'HÃ´pital?","What's the limit of: $\lim_{x \rightarrow 0}\frac{sin(x)+cos(x)}{x}$ ? $\lim_{x \rightarrow 0} \left (sin(x) + cos(x) \right) = sin(0)+cos(0) = 1 $ $\lim_{x \rightarrow 0} x = 0$ $\Rightarrow \frac{1}{0} \Rightarrow$ L'HÃ´pital's rule is needed $f'(x) = cos(x) - sin(x)$ $g'(x) = 1$ $\Rightarrow $ $\lim_{x\rightarrow 0} \left (cos(x) - sin(x) \right ) = cos(0) -sin(0) = 1-0 = 1$ So 1 will be the limit? No way because as it looks like, the denumerator will be too small and thus the complete function will go towards $\infty$ for $x \rightarrow 0$. This is very confusing for me :S Maybe the mistake is using L'HÃ´pital?",,"['calculus', 'analysis', 'functions']"
80,"How to evaluate $\int_{0}^{\infty }\frac{\ln( 1+x^{4} )}{1+x^{2}}{d}x~,~\int_{0}^{1}\frac{\arctan x}{x}\frac{1-x^{4}}{1+x^{4}}{d}x$",How to evaluate,"\int_{0}^{\infty }\frac{\ln( 1+x^{4} )}{1+x^{2}}{d}x~,~\int_{0}^{1}\frac{\arctan x}{x}\frac{1-x^{4}}{1+x^{4}}{d}x","How to evaluate these two integrals below $$\int_{0}^{\infty }\frac{\ln\left ( 1+x^{4} \right )}{1+x^{2}}\mathrm{d}x$$ $$\int_{0}^{1}\frac{\arctan x}{x}\frac{1-x^{4}}{1+x^{4}}\mathrm{d}x$$ For the first one, I tried to use $$\mathcal{I}'(s)=\int_{0}^{\infty }\frac{x^4}{(1+sx^4)(1+x^{2})}\mathrm{d}x$$ but it seems hard to solve.","How to evaluate these two integrals below For the first one, I tried to use but it seems hard to solve.",\int_{0}^{\infty }\frac{\ln\left ( 1+x^{4} \right )}{1+x^{2}}\mathrm{d}x \int_{0}^{1}\frac{\arctan x}{x}\frac{1-x^{4}}{1+x^{4}}\mathrm{d}x \mathcal{I}'(s)=\int_{0}^{\infty }\frac{x^4}{(1+sx^4)(1+x^{2})}\mathrm{d}x,"['calculus', 'integration', 'analysis']"
81,"Proving that $\{(x,y):x^2-2x+y^2=0\}\cup \{(x,0):x\in [2,3]\}$ is connected",Proving that  is connected,"\{(x,y):x^2-2x+y^2=0\}\cup \{(x,0):x\in [2,3]\}","Let $E=\{(x,y):x^2-2x+y^2=0\}\cup \{(x,0):x\in [2,3]\}$. It appears to me from the sketch that this set is connected. However, I have no idea how to prove this, since the set is not convex, and we probably cannot use the line connecting any two points of the set argument to show the set is connected. I have almost no experience proving things like that, would appreciate some help.","Let $E=\{(x,y):x^2-2x+y^2=0\}\cup \{(x,0):x\in [2,3]\}$. It appears to me from the sketch that this set is connected. However, I have no idea how to prove this, since the set is not convex, and we probably cannot use the line connecting any two points of the set argument to show the set is connected. I have almost no experience proving things like that, would appreciate some help.",,"['real-analysis', 'general-topology', 'analysis']"
82,Proof for $e^{\frac{1}{n+1}}-1-\frac{1}{n}\leq0$,Proof for,e^{\frac{1}{n+1}}-1-\frac{1}{n}\leq0,"I'm looking for a proof of $e^{\frac{1}{n+1}}-1-\frac{1}{n}\leq0$, optionally $\ln(n)+\frac{1}{n+1}\leq \ln(n+1)$","I'm looking for a proof of $e^{\frac{1}{n+1}}-1-\frac{1}{n}\leq0$, optionally $\ln(n)+\frac{1}{n+1}\leq \ln(n+1)$",,"['real-analysis', 'analysis', 'inequality']"
83,Evaluating the integral $\int_{-\infty}^\infty \frac{\sin^2(x)}{x^2}e^{i t x} dx$,Evaluating the integral,\int_{-\infty}^\infty \frac{\sin^2(x)}{x^2}e^{i t x} dx,"I want to evaluate the integral $$\int_{-\infty}^\infty \frac{\sin^2(x)}{x^2}e^{i t x} dx$$ for all $t \in \mathbb{R}$. I would preferably do it using the tools of complex analysis, but since I haven't found any other thread dealing with this integral at all so far, I'd be open to any approach. I must admit that I haven't really found a way to start. The function $f(z) := \frac{\sin^2(z)}{z^2}e^{i t z}$ has an isolated singularity (a removable singularity, with continuation $f(0) = 1$, to be precice) at $z = 0$. I think a clever way would be to integrate over the edge of rectangle, semicircle or ""slice of cake"" (the edges of which we then would let go against $-â$ and $â$), then maybe somehow apply the Cauchy theorem or Residue theorem. But I don't know how to concretely do that, or how to even get started with that. On a more general note, I'm having trouble understanding how to transform a ""normal"" integral over a real interval into one where we integrate over the edges of a geometric shape; and I also don't know, based on which pattern one can see with geometric shape fits best. Are there any tips or hints on how to get more intuition for that? (Apart from, obviously, dealing with these integrals regularly, what I'm trying to do but where I'm still failing a lot of times.) I also noticed that the above integrals looks strikingly similar to the Fourier transformed of $f$ (or, even more similar to the formula for the inverse transformed). So maybe this could help us with this integral? I'm not really sure though.","I want to evaluate the integral $$\int_{-\infty}^\infty \frac{\sin^2(x)}{x^2}e^{i t x} dx$$ for all $t \in \mathbb{R}$. I would preferably do it using the tools of complex analysis, but since I haven't found any other thread dealing with this integral at all so far, I'd be open to any approach. I must admit that I haven't really found a way to start. The function $f(z) := \frac{\sin^2(z)}{z^2}e^{i t z}$ has an isolated singularity (a removable singularity, with continuation $f(0) = 1$, to be precice) at $z = 0$. I think a clever way would be to integrate over the edge of rectangle, semicircle or ""slice of cake"" (the edges of which we then would let go against $-â$ and $â$), then maybe somehow apply the Cauchy theorem or Residue theorem. But I don't know how to concretely do that, or how to even get started with that. On a more general note, I'm having trouble understanding how to transform a ""normal"" integral over a real interval into one where we integrate over the edges of a geometric shape; and I also don't know, based on which pattern one can see with geometric shape fits best. Are there any tips or hints on how to get more intuition for that? (Apart from, obviously, dealing with these integrals regularly, what I'm trying to do but where I'm still failing a lot of times.) I also noticed that the above integrals looks strikingly similar to the Fourier transformed of $f$ (or, even more similar to the formula for the inverse transformed). So maybe this could help us with this integral? I'm not really sure though.",,"['integration', 'complex-analysis', 'analysis', 'fourier-analysis']"
84,Proving convergence by the comparison test,Proving convergence by the comparison test,,"I need to prove the convergence of the following series : $$\sum_{n=1}^{\infty} \frac{1}{(3n-2)(3n+1)}$$ I suppose I need to find two series like $$\sum_{n=1}^{\infty}(k_1a_n + k_2b_n) = \sum_{n=1}^{\infty} = k_1\sum_{n=1}^{\infty}a_n  + k_2\sum_{n=1}^{\infty}b_n$$ I thought that the series $a_n$ and $b_n$ can be the partial sums, so $$\sum_{n=1}^{\infty} \frac{1}{(3n-2)(3n+1)} =  \frac{1}{3}\sum_{n=1}^{\infty} \frac{1}{(3n+1)} - \frac{1}{3}\sum_{n=1}^{\infty} \frac{1}{(3n-2)}$$ I know, by the comparison test, that if $a_n$ and $b_n$ converge, the main series will it too. But, how can I demonstrate that the series $a_n$ and $b_n$ converge?","I need to prove the convergence of the following series : $$\sum_{n=1}^{\infty} \frac{1}{(3n-2)(3n+1)}$$ I suppose I need to find two series like $$\sum_{n=1}^{\infty}(k_1a_n + k_2b_n) = \sum_{n=1}^{\infty} = k_1\sum_{n=1}^{\infty}a_n  + k_2\sum_{n=1}^{\infty}b_n$$ I thought that the series $a_n$ and $b_n$ can be the partial sums, so $$\sum_{n=1}^{\infty} \frac{1}{(3n-2)(3n+1)} =  \frac{1}{3}\sum_{n=1}^{\infty} \frac{1}{(3n+1)} - \frac{1}{3}\sum_{n=1}^{\infty} \frac{1}{(3n-2)}$$ I know, by the comparison test, that if $a_n$ and $b_n$ converge, the main series will it too. But, how can I demonstrate that the series $a_n$ and $b_n$ converge?",,"['real-analysis', 'sequences-and-series', 'analysis', 'convergence-divergence', 'summation']"
85,How is $\left|\frac{xy}{\sqrt{x^2+y^2}}\right| \leq \frac{\sqrt{|xy|}}{\sqrt{2}}$,How is,\left|\frac{xy}{\sqrt{x^2+y^2}}\right| \leq \frac{\sqrt{|xy|}}{\sqrt{2}},"$$\left|\frac{xy}{\sqrt{x^2+y^2}}\right| \leq \frac{\sqrt{|xy|}}{\sqrt{2}}$$ Does this apply in general, because here in this example i have $x \to 0, y \to 0$. Some inequality is used I believe to prove this one, but I do not see which.","$$\left|\frac{xy}{\sqrt{x^2+y^2}}\right| \leq \frac{\sqrt{|xy|}}{\sqrt{2}}$$ Does this apply in general, because here in this example i have $x \to 0, y \to 0$. Some inequality is used I believe to prove this one, but I do not see which.",,['analysis']
86,Prove a function is not differentiable using continuity,Prove a function is not differentiable using continuity,,"Given the function $f(x) = |8x^3 â 1|$ in the set $A = [0, 1].$ Prove that the function is not differentiable at $x = \frac12.$ The answer in my book is as follows: $$\lim_{x \to \frac12-} \dfrac{f(x)-f(1/2)}{x-1/2} = -6$$  $$\lim_{x \to \frac12+} \dfrac{f(x)-f(1/2)}{x-1/2} = 6$$ Can anyone explain how the $6$'s were derived. I understand that as $x$ tends to $\frac12$ from the negative side, the bottom will be negative, so thats why the first one is a minus. But how do you get to the $6$, what am I missing? Obviously $f(\frac12)=0$ but what do you make $f(x)=$ as $x$ tends to $\frac12$ Thanks","Given the function $f(x) = |8x^3 â 1|$ in the set $A = [0, 1].$ Prove that the function is not differentiable at $x = \frac12.$ The answer in my book is as follows: $$\lim_{x \to \frac12-} \dfrac{f(x)-f(1/2)}{x-1/2} = -6$$  $$\lim_{x \to \frac12+} \dfrac{f(x)-f(1/2)}{x-1/2} = 6$$ Can anyone explain how the $6$'s were derived. I understand that as $x$ tends to $\frac12$ from the negative side, the bottom will be negative, so thats why the first one is a minus. But how do you get to the $6$, what am I missing? Obviously $f(\frac12)=0$ but what do you make $f(x)=$ as $x$ tends to $\frac12$ Thanks",,"['real-analysis', 'complex-analysis', 'analysis', 'derivatives', 'continuity']"
87,Continuity of a function $f: \mathbb{R}^2 \to \mathbb{R}$,Continuity of a function,f: \mathbb{R}^2 \to \mathbb{R},"It's easy to check that the function $$ f_1(x, y) = \begin{cases}\frac{x y}{x^2 + y^2} &\text{if (x, y) â  (0, 0)}\\0&\text{if (x, y) = (0, 0)}\end{cases}$$ is not continuous in $0$, because e.g. the sequence $f(\frac{1}{n}, \frac{1}{n})_{n \in \mathbb{N}}$ won't converge against $0$. But how can I prove that the very similar function $f_2$, defined as: $$ f_2(x, y) = \begin{cases}\frac{x y^2}{x^2 + y^2} &\text{if (x, y) â  (0, 0)}\\0&\text{if (x, y) = (0, 0)}\end{cases}$$ actually is continuous in $0$? Choosing any sequence of $\mathbb{R}^2$ that converges against $(0, 0)$ didn't lead anywhere so far, and I imagine that using the $\epsilon-\delta$-criteria could maybe work, but would probably get to complicated and that there's hopefully an easier way to check this.","It's easy to check that the function $$ f_1(x, y) = \begin{cases}\frac{x y}{x^2 + y^2} &\text{if (x, y) â  (0, 0)}\\0&\text{if (x, y) = (0, 0)}\end{cases}$$ is not continuous in $0$, because e.g. the sequence $f(\frac{1}{n}, \frac{1}{n})_{n \in \mathbb{N}}$ won't converge against $0$. But how can I prove that the very similar function $f_2$, defined as: $$ f_2(x, y) = \begin{cases}\frac{x y^2}{x^2 + y^2} &\text{if (x, y) â  (0, 0)}\\0&\text{if (x, y) = (0, 0)}\end{cases}$$ actually is continuous in $0$? Choosing any sequence of $\mathbb{R}^2$ that converges against $(0, 0)$ didn't lead anywhere so far, and I imagine that using the $\epsilon-\delta$-criteria could maybe work, but would probably get to complicated and that there's hopefully an easier way to check this.",,"['real-analysis', 'analysis', 'multivariable-calculus', 'continuity']"
88,a limit property at infinity,a limit property at infinity,,"Let $k\in(0,1)$ is fixed and $L$ is a finite value. Is it possible to say if $\lim_{x\to\infty}f(x)=L$ then $\lim_{x\to\infty}f(kx)=L.$","Let $k\in(0,1)$ is fixed and $L$ is a finite value. Is it possible to say if $\lim_{x\to\infty}f(x)=L$ then $\lim_{x\to\infty}f(kx)=L.$",,"['calculus', 'real-analysis', 'analysis', 'limits']"
89,How to prove that $\int_{0}^{\infty}{\frac{e^{-nx}}{\sqrt{x}}}\mathrm dx$ exists,How to prove that  exists,\int_{0}^{\infty}{\frac{e^{-nx}}{\sqrt{x}}}\mathrm dx,"I am trying to show that the integral $\int_{0}^{\infty}{\frac{e^{-nx}}{\sqrt{x}}}\mathrm dx$ exists ($n$ is a natural number). I tried to use the comparison theorem by bounding from above the integrand by another function which is integrable, but I wasn't successful. The same question for this integral as well : $\int_{0}^{\infty}x^2e^{-nx}\mathrm dx$ Any help is much appreciated? Thanks!","I am trying to show that the integral $\int_{0}^{\infty}{\frac{e^{-nx}}{\sqrt{x}}}\mathrm dx$ exists ($n$ is a natural number). I tried to use the comparison theorem by bounding from above the integrand by another function which is integrable, but I wasn't successful. The same question for this integral as well : $\int_{0}^{\infty}x^2e^{-nx}\mathrm dx$ Any help is much appreciated? Thanks!",,"['real-analysis', 'integration', 'analysis', 'improper-integrals']"
90,Suggestions for a real analysis reference.,Suggestions for a real analysis reference.,,Can anyone suggest some real analysis book which has a geometric presentation of the concepts with pictorial representation.,Can anyone suggest some real analysis book which has a geometric presentation of the concepts with pictorial representation.,,"['real-analysis', 'general-topology', 'analysis', 'reference-request', 'book-recommendation']"
91,finding $\lim_{n \rightarrow +\infty}\frac{n}{2^n}= ?$ [duplicate],finding  [duplicate],\lim_{n \rightarrow +\infty}\frac{n}{2^n}= ?,"This question already has answers here : How to prove that exponential grows faster than polynomial? (15 answers) Closed 6 years ago . Finding the limit below..: $$\lim_{n \rightarrow +\infty}\frac{n}{2^n}= ?$$ I really think its 0. But intuitively, infinity over infinity. how can that be? indeterminate forms? Thanks","This question already has answers here : How to prove that exponential grows faster than polynomial? (15 answers) Closed 6 years ago . Finding the limit below..: $$\lim_{n \rightarrow +\infty}\frac{n}{2^n}= ?$$ I really think its 0. But intuitively, infinity over infinity. how can that be? indeterminate forms? Thanks",,"['real-analysis', 'analysis']"
92,Proving Every open set in $\Bbb R$ is a countable union of open intervals. [duplicate],Proving Every open set in  is a countable union of open intervals. [duplicate],\Bbb R,This question already has answers here : Any open subset of $\Bbb R$ is a countable union of disjoint open intervals (17 answers) Closed 10 years ago . This question is from William R. Wade's Introduction to Analysis book: Prove that every open set in $\Bbb R$ is a countable union of open intervals. I have no ideas honestly. Thank you.,This question already has answers here : Any open subset of $\Bbb R$ is a countable union of disjoint open intervals (17 answers) Closed 10 years ago . This question is from William R. Wade's Introduction to Analysis book: Prove that every open set in $\Bbb R$ is a countable union of open intervals. I have no ideas honestly. Thank you.,,"['calculus', 'real-analysis', 'general-topology', 'analysis', 'self-learning']"
93,Write an expression in powers of $(x+1)$ and $(y-1)$ for $x^2+xy+y^2$,Write an expression in powers of  and  for,(x+1) (y-1) x^2+xy+y^2,Write an expression in powers of $(x+1)$ and $(y-1)$ for $x^2+xy+y^2$ I calculated $f_x=2x+y $ $f_{xx}=2 $ $f_y=x+2y$ $f_{yy}=2$ And then what I need to do? What is the formula to solve the question ?,Write an expression in powers of $(x+1)$ and $(y-1)$ for $x^2+xy+y^2$ I calculated $f_x=2x+y $ $f_{xx}=2 $ $f_y=x+2y$ $f_{yy}=2$ And then what I need to do? What is the formula to solve the question ?,,"['calculus', 'real-analysis', 'analysis']"
94,convexity and lower semi-continuity for weak convergence,convexity and lower semi-continuity for weak convergence,,"My question is a general one, whose answer can probably be found in any decent convex analysis book. I unfortunately don't have any at hand right now, so here it is: Let's consider a ""reasonable"" Banach space $X$ (say at least reflexive and separable as usual), a convex subset $C\subset X$ and a function $\Phi:C\to\mathbb{R}$ which is continuous for the strong $X$ topology and convex. What do I need to assume for $\Phi$ to be weakly lower-semicontinuous? Clearly differentiability works with the classical trick $x_n\rightharpoonup x$ and $\Phi(x_k)\geq \Phi(x)+D\Phi(x).(x_k-x)$, but I guess there must be less restrictive conditions than differentiability? Thank you!","My question is a general one, whose answer can probably be found in any decent convex analysis book. I unfortunately don't have any at hand right now, so here it is: Let's consider a ""reasonable"" Banach space $X$ (say at least reflexive and separable as usual), a convex subset $C\subset X$ and a function $\Phi:C\to\mathbb{R}$ which is continuous for the strong $X$ topology and convex. What do I need to assume for $\Phi$ to be weakly lower-semicontinuous? Clearly differentiability works with the classical trick $x_n\rightharpoonup x$ and $\Phi(x_k)\geq \Phi(x)+D\Phi(x).(x_k-x)$, but I guess there must be less restrictive conditions than differentiability? Thank you!",,"['analysis', 'convex-analysis']"
95,The wedge sum of two circles has fixed point property?,The wedge sum of two circles has fixed point property?,,"The wedge sum of two circles has fixed point property? I'm trying to find a continuous map from the wedge sum to itself, that this property fails, I couldn't find it, I need help. Thanks","The wedge sum of two circles has fixed point property? I'm trying to find a continuous map from the wedge sum to itself, that this property fails, I couldn't find it, I need help. Thanks",,"['general-topology', 'analysis', 'algebraic-topology', 'fixed-point-theorems']"
96,supremum norm and submultiplicativity,supremum norm and submultiplicativity,,"If $f$, $g \in C(S)$ where $S$ is a compact set in $\mathbb{R}^n$ then it is true that $$\lVert fg \rVert \leq \lVert f \rVert \lVert g \rVert$$ where the norm is the usual supremum norm.  Why is this not true if $S$ is not compact? What other conditions can $S$ satisfy so that this is true?","If $f$, $g \in C(S)$ where $S$ is a compact set in $\mathbb{R}^n$ then it is true that $$\lVert fg \rVert \leq \lVert f \rVert \lVert g \rVert$$ where the norm is the usual supremum norm.  Why is this not true if $S$ is not compact? What other conditions can $S$ satisfy so that this is true?",,"['analysis', 'normed-spaces']"
97,analysis question,analysis question,,"Suppose $f(x) \in \mathbb{R}[x]$ is such that $\operatorname{deg}{f(x)} = 2011$, then $\exists \: c \in \mathbb{R}$ such that $f(c) = f'(c)$. How can I prove/disprove the above statement. Any hints?","Suppose $f(x) \in \mathbb{R}[x]$ is such that $\operatorname{deg}{f(x)} = 2011$, then $\exists \: c \in \mathbb{R}$ such that $f(c) = f'(c)$. How can I prove/disprove the above statement. Any hints?",,"['real-analysis', 'analysis']"
98,Does a dense $G_\delta$ subset of a complete metric space without isolated points contain a perfect set?,Does a dense  subset of a complete metric space without isolated points contain a perfect set?,G_\delta,"Let $(X,d)$ be a complete metric space without isolated points. Is it true that each dense $G_\delta$ subset of $X$ contains a nonempty perfect set (i.e. closed without isolated points)? Thanks.","Let $(X,d)$ be a complete metric space without isolated points. Is it true that each dense $G_\delta$ subset of $X$ contains a nonempty perfect set (i.e. closed without isolated points)? Thanks.",,"['general-topology', 'analysis', 'descriptive-set-theory']"
99,Why do we have the notions of both 'norm' and 'metric'?,Why do we have the notions of both 'norm' and 'metric'?,,"In the case of vectors in euclidean space, for instance, we can express one in terms of the other--i.e. length is distance from zero, distance is the length of the vector difference.  Does this break down somewhere?","In the case of vectors in euclidean space, for instance, we can express one in terms of the other--i.e. length is distance from zero, distance is the length of the vector difference.  Does this break down somewhere?",,"['general-topology', 'analysis', 'metric-spaces', 'normed-spaces']"
