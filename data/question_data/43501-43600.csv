,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Understanding examples of subfield and prime subfield of a finite field,Understanding examples of subfield and prime subfield of a finite field,,"I have already taken a look at this answer . Somehow it did not answer my question. As I can find, in various literatures, A lecture note, Definition 4.1 : Let $F$ be a field. A subset $K$ that is itself a field under the operations of $F$ is called a subfield of $F$. Another lecture note, Section 7.4.2 : A subfield $G$ of a field $F$ is a subset of the field that is itself a field under the operations of $F$. Now, if we consider the operations of the field to be  $+ \bmod n$ and $\times \bmod n$. We find that $\mathbb{Z}_2$ and $\mathbb{Z}_5$ are both fields under these operations. But in order to get a good feeling of subfields, we try to  consider $\mathbb{Z}_{3^2} = \mathbb{Z}_9$. We find that this not a field under the afore stated operations. Not all the non-zero elements, notably 3 and 9 ($\gcd(3,9) \not=1$ and $\gcd(6,9) \not=1$), do not have multiplicative inverses. Indeed, as Wikipedia states , Even though all fields of size $p$ are isomorphic to $\mathbb{Z}/p\mathbb{Z}$, for $n \ge 2$ the   ring $\mathbb{Z}/p^n\mathbb{Z}$ (the ring of integers modulo $p^n$) is not a field. The   element $p$ $(\bmod\ p^n)$ is nonzero and has no multiplicative inverse. Looking for examples, we find one here for $GF(2^3)$. This is based on polynomials. Now, coming to my original point on (understanding) subfield or prime subfield of finite fields, please tell me, Whether it is totally impossible to construct purely numerical examples of  fields of size $p^n$. Given a (non-numerical) field of size $p^n$, (one can be found in page 90 (16) of this document ), what is the best way to identify the subfield(s) and prime subfield? I appreciate an answer which nurtures my intuition, not a theoretical one which puts me deep in difficult mathematical terms.","I have already taken a look at this answer . Somehow it did not answer my question. As I can find, in various literatures, A lecture note, Definition 4.1 : Let $F$ be a field. A subset $K$ that is itself a field under the operations of $F$ is called a subfield of $F$. Another lecture note, Section 7.4.2 : A subfield $G$ of a field $F$ is a subset of the field that is itself a field under the operations of $F$. Now, if we consider the operations of the field to be  $+ \bmod n$ and $\times \bmod n$. We find that $\mathbb{Z}_2$ and $\mathbb{Z}_5$ are both fields under these operations. But in order to get a good feeling of subfields, we try to  consider $\mathbb{Z}_{3^2} = \mathbb{Z}_9$. We find that this not a field under the afore stated operations. Not all the non-zero elements, notably 3 and 9 ($\gcd(3,9) \not=1$ and $\gcd(6,9) \not=1$), do not have multiplicative inverses. Indeed, as Wikipedia states , Even though all fields of size $p$ are isomorphic to $\mathbb{Z}/p\mathbb{Z}$, for $n \ge 2$ the   ring $\mathbb{Z}/p^n\mathbb{Z}$ (the ring of integers modulo $p^n$) is not a field. The   element $p$ $(\bmod\ p^n)$ is nonzero and has no multiplicative inverse. Looking for examples, we find one here for $GF(2^3)$. This is based on polynomials. Now, coming to my original point on (understanding) subfield or prime subfield of finite fields, please tell me, Whether it is totally impossible to construct purely numerical examples of  fields of size $p^n$. Given a (non-numerical) field of size $p^n$, (one can be found in page 90 (16) of this document ), what is the best way to identify the subfield(s) and prime subfield? I appreciate an answer which nurtures my intuition, not a theoretical one which puts me deep in difficult mathematical terms.",,"['abstract-algebra', 'field-theory', 'finite-fields']"
1,Construction of the projective plane over $\mathbb{F}_3$,Construction of the projective plane over,\mathbb{F}_3,"I have a question about constructing  projective plane over $\mathbb{F}_3$. We first establish seven equivalence classes $P= \{ [0,0,1], [0,1,0], [1,0,0], [0,1,1], [1,1,0], [1,0,1], [1,1,1] \}$. Given a triple $(a_0, a_1, a_2) \in \mathbb{F}^3_3 \setminus (0, 0, 0)$ we define the line $L(a_0, a_1, a_2)$ as follows: $L(a_0, a_1, a_2) := \{ [x_0; x_1; x_2] \in P : a_0x_0 + a_1x_1 + a_2x_2 = 0 \}$. It is quite easy for $L(0,0,1), L(0,1,0), L(1,0,0)$, because here we take the points which have zero on the first, second and third coordinate. It gets more difficult for me for $L(0,1,1)$, because here we need to have $x_1+x_2=0$. Do we treat the coordinates of the points as elements of $\mathbb{F}_2$ or $\mathbb{F}_3$? There are $26$ nonzero triples in $\mathbb{F}^3_3 $. Do we check all 26 $L(x_0, x_1, x_2) $ sets? Please help, because I really want to understand it. Thank you.","I have a question about constructing  projective plane over $\mathbb{F}_3$. We first establish seven equivalence classes $P= \{ [0,0,1], [0,1,0], [1,0,0], [0,1,1], [1,1,0], [1,0,1], [1,1,1] \}$. Given a triple $(a_0, a_1, a_2) \in \mathbb{F}^3_3 \setminus (0, 0, 0)$ we define the line $L(a_0, a_1, a_2)$ as follows: $L(a_0, a_1, a_2) := \{ [x_0; x_1; x_2] \in P : a_0x_0 + a_1x_1 + a_2x_2 = 0 \}$. It is quite easy for $L(0,0,1), L(0,1,0), L(1,0,0)$, because here we take the points which have zero on the first, second and third coordinate. It gets more difficult for me for $L(0,1,1)$, because here we need to have $x_1+x_2=0$. Do we treat the coordinates of the points as elements of $\mathbb{F}_2$ or $\mathbb{F}_3$? There are $26$ nonzero triples in $\mathbb{F}^3_3 $. Do we check all 26 $L(x_0, x_1, x_2) $ sets? Please help, because I really want to understand it. Thank you.",,"['abstract-algebra', 'discrete-mathematics', 'finite-fields', 'projective-geometry']"
2,Inverse image of prime ideal in noncommutative ring,Inverse image of prime ideal in noncommutative ring,,"We say an ideal $P\neq R$ in a ring $R$ is prime, if for any two ideals $I,J$ of $R$ the following implication holds: if $IJ\subseteq P$ then $I\subseteq P$ or $J\subseteq P$. If $f\colon R \to S$ is a homomorphism of noncommutative rings and $P$ is a prime ideal in $S$, is $f^{-1}(P)$ a prime ideal in $R$? Of course, the above statement is true for commutative $R$ and $S$. I managed to prove it for noncommutative $R$ and $S$ when $f$ is an epimorphism.","We say an ideal $P\neq R$ in a ring $R$ is prime, if for any two ideals $I,J$ of $R$ the following implication holds: if $IJ\subseteq P$ then $I\subseteq P$ or $J\subseteq P$. If $f\colon R \to S$ is a homomorphism of noncommutative rings and $P$ is a prime ideal in $S$, is $f^{-1}(P)$ a prime ideal in $R$? Of course, the above statement is true for commutative $R$ and $S$. I managed to prove it for noncommutative $R$ and $S$ when $f$ is an epimorphism.",,"['abstract-algebra', 'ideals']"
3,Are algebraic numbers analogous to group elements with finite order?,Are algebraic numbers analogous to group elements with finite order?,,"Would you say that the ""elements with finite order"" in group theory are analogous to ""algebraic numbers"" in field theory? I thought this is the case since requiring an algebraic number $\alpha$ to be the root of a polynomial (i.e. requiring a finite combination of terms in $\alpha$ using $+$ and $\times$ to give the identity zero) is like the two-operation equivalent of an element $g$ in group theory having finite order (where there is only one operation $\times$ and we require a term in $g$ which is required to give the identity 1). However I don't think the analogy is quite complete because in the case of the polynomial we are allowed to also multiply powers of $\alpha$ by other elements of the field to achieve the identity.","Would you say that the ""elements with finite order"" in group theory are analogous to ""algebraic numbers"" in field theory? I thought this is the case since requiring an algebraic number $\alpha$ to be the root of a polynomial (i.e. requiring a finite combination of terms in $\alpha$ using $+$ and $\times$ to give the identity zero) is like the two-operation equivalent of an element $g$ in group theory having finite order (where there is only one operation $\times$ and we require a term in $g$ which is required to give the identity 1). However I don't think the analogy is quite complete because in the case of the polynomial we are allowed to also multiply powers of $\alpha$ by other elements of the field to achieve the identity.",,"['abstract-algebra', 'group-theory', 'soft-question', 'algebraic-number-theory']"
4,$G$ is locally compact semitopological group. There exists a neighborhood $U$ of $1$ such that $\overline{UU}$ is compact.,is locally compact semitopological group. There exists a neighborhood  of  such that  is compact.,G U 1 \overline{UU},"Let $G$ be a group and $\mathcal T$  be a locally compact topology on $G$ such that for any $a\in G$ the functions $x \mapsto ax$ and $x\mapsto xa$ are continuous on $G$. How to prove elementarily that: There's some neighborhood $U$ of $1$, the identity element of the group $G$, such that $\overline{UU}$ is compact. There's some neighborhood $V$ of $1$, such that $\overline{V^{-1}}$ is compact. ? Assume $\mathcal T$ is Hausdorff . By elementary I mean not to use Ellis or other strong theorems in (semi-)Topological Groups Theory without proof. Using only theorems in pure Topology or pure Group Theory is what I call elementary.    For example I appreciate using any result in Uniform Spaces; because a locally compact Haudorff Space is uniformizable. Also according to this thread it seems there's a minimal uniformity on $G$.","Let $G$ be a group and $\mathcal T$  be a locally compact topology on $G$ such that for any $a\in G$ the functions $x \mapsto ax$ and $x\mapsto xa$ are continuous on $G$. How to prove elementarily that: There's some neighborhood $U$ of $1$, the identity element of the group $G$, such that $\overline{UU}$ is compact. There's some neighborhood $V$ of $1$, such that $\overline{V^{-1}}$ is compact. ? Assume $\mathcal T$ is Hausdorff . By elementary I mean not to use Ellis or other strong theorems in (semi-)Topological Groups Theory without proof. Using only theorems in pure Topology or pure Group Theory is what I call elementary.    For example I appreciate using any result in Uniform Spaces; because a locally compact Haudorff Space is uniformizable. Also according to this thread it seems there's a minimal uniformity on $G$.",,"['abstract-algebra', 'general-topology']"
5,In a finite cyclic group there is only one subgroup of order $k$.,In a finite cyclic group there is only one subgroup of order .,k,"If $G$ is a cyclic group of order $n$ and $k|n$, then $G$ has a subgroup of order $k$, it's easy to prove, but what I'm having troubles to show is there is only one subgroup of order $k$. I need help here Thanks a lot","If $G$ is a cyclic group of order $n$ and $k|n$, then $G$ has a subgroup of order $k$, it's easy to prove, but what I'm having troubles to show is there is only one subgroup of order $k$. I need help here Thanks a lot",,"['abstract-algebra', 'group-theory']"
6,"If $\phi(\alpha)$ is prime in $\mathbb{Z}$, show that $\alpha$ is prime in $\mathbb{Z}[i]$ [duplicate]","If  is prime in , show that  is prime in  [duplicate]",\phi(\alpha) \mathbb{Z} \alpha \mathbb{Z}[i],"This question already has answers here : Is it true that $a+bi$ is prime in $\mathbb{Z}[i]$ if and only if $a^2+b^2$ is prime in $\mathbb{Z}$? [closed] (3 answers) Closed 11 years ago . If $\alpha=a+bi$ is a Gaussian integer, let $\phi(\alpha)=a^2+b^2$. If $\phi(\alpha)$ is prime in $\mathbb{Z}$, show that $\alpha$ is prime in $\mathbb{Z}[i]$. I use the idea that if $a^2+b^2=p$ where $p$ is prime number, then $\mathbb{Z}[i]/(a+bi) \cong \mathbb{Z}_p$. Hence, $(a+bi)$ is a maximal ideal since $\mathbb{Z}_p$ is a field. So, $(a+bi)$ is a prime ideal and hence $a+bi$ is a prime element. Is this proof works? EDIT: $\mathbb{Z}[i]/(a+bi) \cong \mathbb{Z}_p$ is proved in my class so I think I can straight away use it here. By the way, in the proof of $\mathbb{Z}[i]/(a+bi) \cong \mathbb{Z}_p$, my lecturer said that $a^2+b^2=p$ implies $\gcd(a,b)=1$. I can't figure out the proof of this. I start with contradiction, i.e. $d=\gcd(a,b)>1$. Then $d(\frac{a^2}{d}+\frac{b^2}{d})=p \implies d |p \implies d=p \implies a^2+b^2=\gcd(a,b)$, contradiction. Is this proof work ?","This question already has answers here : Is it true that $a+bi$ is prime in $\mathbb{Z}[i]$ if and only if $a^2+b^2$ is prime in $\mathbb{Z}$? [closed] (3 answers) Closed 11 years ago . If $\alpha=a+bi$ is a Gaussian integer, let $\phi(\alpha)=a^2+b^2$. If $\phi(\alpha)$ is prime in $\mathbb{Z}$, show that $\alpha$ is prime in $\mathbb{Z}[i]$. I use the idea that if $a^2+b^2=p$ where $p$ is prime number, then $\mathbb{Z}[i]/(a+bi) \cong \mathbb{Z}_p$. Hence, $(a+bi)$ is a maximal ideal since $\mathbb{Z}_p$ is a field. So, $(a+bi)$ is a prime ideal and hence $a+bi$ is a prime element. Is this proof works? EDIT: $\mathbb{Z}[i]/(a+bi) \cong \mathbb{Z}_p$ is proved in my class so I think I can straight away use it here. By the way, in the proof of $\mathbb{Z}[i]/(a+bi) \cong \mathbb{Z}_p$, my lecturer said that $a^2+b^2=p$ implies $\gcd(a,b)=1$. I can't figure out the proof of this. I start with contradiction, i.e. $d=\gcd(a,b)>1$. Then $d(\frac{a^2}{d}+\frac{b^2}{d})=p \implies d |p \implies d=p \implies a^2+b^2=\gcd(a,b)$, contradiction. Is this proof work ?",,['abstract-algebra']
7,A question about polynomial rings,A question about polynomial rings,,"This may be a trivial question.  We say an ideal $I$ in a ring $R$  is $k$-generated iff $I$ is generated by at most $k$ elements of $R$. Let $F$ be a field. Is it true that every ideal in $F[x_1,x_2,....,x_n]$ is $n-$generated. (This is true when $n=1$, because $F[x_1]$ is a PID) Second question: Is it true that every ideal in $F[x_1,x_2,x_3,...]$ is generated by a countable set of elements of $F[x_1,x_2,x_3,...]$ ? Thank you","This may be a trivial question.  We say an ideal $I$ in a ring $R$  is $k$-generated iff $I$ is generated by at most $k$ elements of $R$. Let $F$ be a field. Is it true that every ideal in $F[x_1,x_2,....,x_n]$ is $n-$generated. (This is true when $n=1$, because $F[x_1]$ is a PID) Second question: Is it true that every ideal in $F[x_1,x_2,x_3,...]$ is generated by a countable set of elements of $F[x_1,x_2,x_3,...]$ ? Thank you",,"['abstract-algebra', 'ring-theory']"
8,What are the sets of integers obtained from multiplication/division from a given set of primes called?,What are the sets of integers obtained from multiplication/division from a given set of primes called?,,"We are given some (finite) set of primes $P=\{p_1, p_2, \ldots, p_n\}$. Define the following two sets: $S$ is the set of all integers that can be generated from $P$ by multiplying members of any subset of $P$, possibly by repeating some of them. That is:  $$S=\{z|z=\prod^{n}_{i=1}p_i^{x_i}\wedge {x_i}\mbox{ is a non-negative integer}\}$$ $T$ is the set of all rational numbers that can be generated from $P$ by multiplying and dividing members of any subset of $P$, possibly by repeating some of them. That is:  $$T=\{z|z=\prod^{n}_{i=1}p_i^{x_i}\wedge {x_i}\mbox{ is an integer}\}$$ Is there any name given to $S$ and $T$?","We are given some (finite) set of primes $P=\{p_1, p_2, \ldots, p_n\}$. Define the following two sets: $S$ is the set of all integers that can be generated from $P$ by multiplying members of any subset of $P$, possibly by repeating some of them. That is:  $$S=\{z|z=\prod^{n}_{i=1}p_i^{x_i}\wedge {x_i}\mbox{ is a non-negative integer}\}$$ $T$ is the set of all rational numbers that can be generated from $P$ by multiplying and dividing members of any subset of $P$, possibly by repeating some of them. That is:  $$T=\{z|z=\prod^{n}_{i=1}p_i^{x_i}\wedge {x_i}\mbox{ is an integer}\}$$ Is there any name given to $S$ and $T$?",,"['abstract-algebra', 'terminology']"
9,"Group with more than one element and with no proper, nontrivial sub groups must have prime order.","Group with more than one element and with no proper, nontrivial sub groups must have prime order.",,"I want to show that if $G$ is a group with more than one element, and that $G$ has no proper non-trivial subgroups. Prove that $|G|$ is prime. (Do not assume at the outset that |G| is finite). My question is not that how to prove it.  I am saying that suppose $|G|\geq 2$ possibly $|G|=\infty.$ By assumption the only subgroups of $G$ are $\{e\}$ and $G$, i.e., the trivial groups. Let $a$ be non-identity element in $G$. Consider $\langle a\rangle$. Then  $\langle a\rangle=G.$ So $G$ is cyclic. My question is, why can I say that $G=\langle a\rangle$. I know there are only two subgroups and $\langle a\rangle\neq e$ because $a\neq e$. Therefore we must have $G=\langle a\rangle$. But my problem is why cant I say that consider $a,b\in G$ and then we look at $\langle a,b\rangle$. And then I say $G=\langle a,b\rangle$ and then I cannot say that $G$ is cyclic, and then I will have problem proving question.","I want to show that if $G$ is a group with more than one element, and that $G$ has no proper non-trivial subgroups. Prove that $|G|$ is prime. (Do not assume at the outset that |G| is finite). My question is not that how to prove it.  I am saying that suppose $|G|\geq 2$ possibly $|G|=\infty.$ By assumption the only subgroups of $G$ are $\{e\}$ and $G$, i.e., the trivial groups. Let $a$ be non-identity element in $G$. Consider $\langle a\rangle$. Then  $\langle a\rangle=G.$ So $G$ is cyclic. My question is, why can I say that $G=\langle a\rangle$. I know there are only two subgroups and $\langle a\rangle\neq e$ because $a\neq e$. Therefore we must have $G=\langle a\rangle$. But my problem is why cant I say that consider $a,b\in G$ and then we look at $\langle a,b\rangle$. And then I say $G=\langle a,b\rangle$ and then I cannot say that $G$ is cyclic, and then I will have problem proving question.",,['abstract-algebra']
10,Abelian groups whose subgroup lattice is chain,Abelian groups whose subgroup lattice is chain,,"Let $G=Z(p^k)$ where $k=1,2,..,\infty$. The group $G$ has exactly one subgroup series. Does exist an other infinite abelian group with this property?","Let $G=Z(p^k)$ where $k=1,2,..,\infty$. The group $G$ has exactly one subgroup series. Does exist an other infinite abelian group with this property?",,"['abstract-algebra', 'group-theory']"
11,Irreducible polynomial in $\mathbb{F}_{p}[x]$,Irreducible polynomial in,\mathbb{F}_{p}[x],I'm studing for an exam and I am stuck on the following practice problem. Consider the the ring $R=\mathbb{F}_{p}[x]$.    How many irreducible polynomials of degree 4 exist in $R$?,I'm studing for an exam and I am stuck on the following practice problem. Consider the the ring $R=\mathbb{F}_{p}[x]$.    How many irreducible polynomials of degree 4 exist in $R$?,,['abstract-algebra']
12,"Finding what $\langle(135)(246),(12)(34)(56)\rangle\subset S_{6}$ is isomorphic to",Finding what  is isomorphic to,"\langle(135)(246),(12)(34)(56)\rangle\subset S_{6}","I am doing an exercise that asks me to find what $\langle(135)(246),(12)(34)(56)\rangle\subset S_{6}$ is isomorphic to. I am allowed to only use the groups $D_n,S_n,\mathbb{Z}_n$ and the direct sums ) where $S_n$ is the permutatin group of $n$ elements, $D_n$ is the dihedral group of order $2n$. I have noted that the first element is of order $3$ and that the second one is of order $2$. I also noted that these elements commutes hence generate an abelian group. I can also say that this group is of order at least $6$ since $gcd(2,3)=1$. How can I find what is Finding $\langle(135)(246),(12)(34)(56)\rangle\subset S_{6}$ ? If there was a good argument that say that this group is at most of order $6$ then I can clain that since the only groups of order $6$ are $S_3$ and $\mathbb{Z}_6$ and $S_3$ is non abelian then this group is isomorphic to $\mathbb{Z}_6$. Can someone please help with this problem ?","I am doing an exercise that asks me to find what $\langle(135)(246),(12)(34)(56)\rangle\subset S_{6}$ is isomorphic to. I am allowed to only use the groups $D_n,S_n,\mathbb{Z}_n$ and the direct sums ) where $S_n$ is the permutatin group of $n$ elements, $D_n$ is the dihedral group of order $2n$. I have noted that the first element is of order $3$ and that the second one is of order $2$. I also noted that these elements commutes hence generate an abelian group. I can also say that this group is of order at least $6$ since $gcd(2,3)=1$. How can I find what is Finding $\langle(135)(246),(12)(34)(56)\rangle\subset S_{6}$ ? If there was a good argument that say that this group is at most of order $6$ then I can clain that since the only groups of order $6$ are $S_3$ and $\mathbb{Z}_6$ and $S_3$ is non abelian then this group is isomorphic to $\mathbb{Z}_6$. Can someone please help with this problem ?",,"['abstract-algebra', 'group-theory', 'permutations']"
13,Associativity: why does $((a \ast b) \ast c) = (a \ast (b \ast c))$ mean we can bracket longer expressions however we like? [duplicate],Associativity: why does  mean we can bracket longer expressions however we like? [duplicate],((a \ast b) \ast c) = (a \ast (b \ast c)),"This question already has answers here : Closed 12 years ago . Possible Duplicate: How does one actually show from associativity that one can drop parentheses? In some ways this question seems obvious, but it is rarely covered.  The normal definition given for a binary operation $\ast$ on a set $S$ is that, for all $a,b,c \in S$:  $$((a \ast b) \ast c)=(a \ast (b \ast c)) \tag{Assoc}$$ It is normal then to go straight from here to assuming that given any string of members of $S$, we can bracket them however we like.  For example, if we have the string $(a,b,c,d,e,f)$, where $a,b,c,d,e,f \in S$, then:  $$\Bigl((a \ast b) \ast \bigl(c \ast ((d \ast e) \ast f)\bigr)\Bigr)=\Bigl(a \ast \Bigl(\bigl((b \ast c) \ast d\bigr) \ast (e \ast f)\Bigr)\Bigr).$$ We can prove this particular identity by repeated use of (Assoc):  $$\begin{align*} ((a \ast b) \ast (c \ast ((d \ast e) \ast f))) &= (a \ast (b \ast (c \ast ((d \ast e) \ast f))))\\ &=(a \ast (b \ast (c \ast (d \ast (e \ast f)))))\\ &=(a \ast ((b \ast c) \ast (d \ast (e \ast f))))\\ &=(a \ast (((b \ast c) \ast d) \ast (e \ast f))). \end{align*}$$ However, I am looking for a neat, formal proof for the general case.  This will involve coming up with some way of coding a 'bracketing'.  One thought I had was to write the string of things we are multiplying together as the ordered $n$-tuple $(a_1,a_2,a_3,\ldots ,a_n)$ and then considering the $(n-1)$-tuple of pairs of adjacent elements $(j_1,j_2,\ldots,j_{n-1})$ where $j_i=(a_i,a_{i+1})$.  Then we can order the $j_i$ to define a bracketing - for example, if we have $(a_1,a_2,a_3,a_4)$, the order $(j_2,j_3,j_1)$ corresponds to the bracketing $(a_1 \ast ((a_2 \ast a_3) \ast a_4))$ where we first bracket together around the second $\ast$, then around the third and then around the first.  The bracketing need not be unique to the ording of the $j_i$ - $(j_3,j_1,j_2)$ and $(j_1,j_3,j_2)$ both correspond to the bracketing $((a_1 \ast a_2) \ast (a_3 \ast a_4))$, but we have a surjective mapping from the set of orders of the $j_i$ to the set of bracketings.  The statement (Ass) above then corresponds to the statement that the product represented by $(\ldots,j_i,j_{i+1},\ldots)$ is the same as the product represented by $(\ldots,j_{i+1},j_i,\ldots)$.  We can write this as $(\ldots,j_i,j_{i+1},\ldots) \backsimeq (\ldots,j_{i+1},j_i,\ldots)$.  If we can show that this implies that any ordering $(j_{i_1},j_{i_2},\ldots,j_{i_n}) \backsimeq (j_1,j_2,\ldots,j_n)$ then we win. Has anybody got any ideas?","This question already has answers here : Closed 12 years ago . Possible Duplicate: How does one actually show from associativity that one can drop parentheses? In some ways this question seems obvious, but it is rarely covered.  The normal definition given for a binary operation $\ast$ on a set $S$ is that, for all $a,b,c \in S$:  $$((a \ast b) \ast c)=(a \ast (b \ast c)) \tag{Assoc}$$ It is normal then to go straight from here to assuming that given any string of members of $S$, we can bracket them however we like.  For example, if we have the string $(a,b,c,d,e,f)$, where $a,b,c,d,e,f \in S$, then:  $$\Bigl((a \ast b) \ast \bigl(c \ast ((d \ast e) \ast f)\bigr)\Bigr)=\Bigl(a \ast \Bigl(\bigl((b \ast c) \ast d\bigr) \ast (e \ast f)\Bigr)\Bigr).$$ We can prove this particular identity by repeated use of (Assoc):  $$\begin{align*} ((a \ast b) \ast (c \ast ((d \ast e) \ast f))) &= (a \ast (b \ast (c \ast ((d \ast e) \ast f))))\\ &=(a \ast (b \ast (c \ast (d \ast (e \ast f)))))\\ &=(a \ast ((b \ast c) \ast (d \ast (e \ast f))))\\ &=(a \ast (((b \ast c) \ast d) \ast (e \ast f))). \end{align*}$$ However, I am looking for a neat, formal proof for the general case.  This will involve coming up with some way of coding a 'bracketing'.  One thought I had was to write the string of things we are multiplying together as the ordered $n$-tuple $(a_1,a_2,a_3,\ldots ,a_n)$ and then considering the $(n-1)$-tuple of pairs of adjacent elements $(j_1,j_2,\ldots,j_{n-1})$ where $j_i=(a_i,a_{i+1})$.  Then we can order the $j_i$ to define a bracketing - for example, if we have $(a_1,a_2,a_3,a_4)$, the order $(j_2,j_3,j_1)$ corresponds to the bracketing $(a_1 \ast ((a_2 \ast a_3) \ast a_4))$ where we first bracket together around the second $\ast$, then around the third and then around the first.  The bracketing need not be unique to the ording of the $j_i$ - $(j_3,j_1,j_2)$ and $(j_1,j_3,j_2)$ both correspond to the bracketing $((a_1 \ast a_2) \ast (a_3 \ast a_4))$, but we have a surjective mapping from the set of orders of the $j_i$ to the set of bracketings.  The statement (Ass) above then corresponds to the statement that the product represented by $(\ldots,j_i,j_{i+1},\ldots)$ is the same as the product represented by $(\ldots,j_{i+1},j_i,\ldots)$.  We can write this as $(\ldots,j_i,j_{i+1},\ldots) \backsimeq (\ldots,j_{i+1},j_i,\ldots)$.  If we can show that this implies that any ordering $(j_{i_1},j_{i_2},\ldots,j_{i_n}) \backsimeq (j_1,j_2,\ldots,j_n)$ then we win. Has anybody got any ideas?",,['abstract-algebra']
14,When a prime ideal is a maximal ideal [duplicate],When a prime ideal is a maximal ideal [duplicate],,"This question already has answers here : If every prime ideal is maximal, what can we say about the ring? (5 answers) Closed 9 years ago . In a commutative ring with unit every maximal ideal is prime. Under what conditions does the converse occur?","This question already has answers here : If every prime ideal is maximal, what can we say about the ring? (5 answers) Closed 9 years ago . In a commutative ring with unit every maximal ideal is prime. Under what conditions does the converse occur?",,['abstract-algebra']
15,Maximal ideals of an algebra,Maximal ideals of an algebra,,How do I find the maximal ideals of the algebra of holomorphic functions in one variable?thanks.,How do I find the maximal ideals of the algebra of holomorphic functions in one variable?thanks.,,"['abstract-algebra', 'complex-analysis']"
16,What elements in a tensor algebra are invertible?,What elements in a tensor algebra are invertible?,,A question was brought up to me about if it is possible to come up with a module that has no non trivial invertible elements in its respective tensor algebra.  I am not sure if this is trivial based on the following fact but I thought it would be a good starting point: Let $T(V) = \oplus_{k=0}^{\infty} T^k(V)$ be the tensor algebra of a finite vector space $V$. How do you show the only invertible elements in $T(V)$ are nonzero scalars (0-tensors)?,A question was brought up to me about if it is possible to come up with a module that has no non trivial invertible elements in its respective tensor algebra.  I am not sure if this is trivial based on the following fact but I thought it would be a good starting point: Let $T(V) = \oplus_{k=0}^{\infty} T^k(V)$ be the tensor algebra of a finite vector space $V$. How do you show the only invertible elements in $T(V)$ are nonzero scalars (0-tensors)?,,"['abstract-algebra', 'tensor-products']"
17,Different version of Gauss's Lemma,Different version of Gauss's Lemma,,"Let $A$ be a domain with field of fractions $K$ . Let $f, g \in A[X]$ with $g$ monic. Show that if $f/g \in K[X]$ then $f/g \in A[X]$ . So I tried the direct approach by just assuming $f/g$ has a coefficient $a/b$ and then multiplying out with $g$ with the purpose of getting that $f$ has an ""irrational"" coefficient; but I can't finisnh.","Let be a domain with field of fractions . Let with monic. Show that if then . So I tried the direct approach by just assuming has a coefficient and then multiplying out with with the purpose of getting that has an ""irrational"" coefficient; but I can't finisnh.","A K f, g \in A[X] g f/g \in K[X] f/g \in A[X] f/g a/b g f",['abstract-algebra']
18,"Is isomorphism of two subgroups, one of them normal, enough to guarantee that the other is normal as well?","Is isomorphism of two subgroups, one of them normal, enough to guarantee that the other is normal as well?",,"Let $G$ be a group and $H$, $K$ subgroups such that $H$ is normal in $G$ and $H$, $K$ are isomorphic. After some thought i intuitively concluded that $K$ is not necessarilly normal in $G$. Is that the case? Any rigorous argument? (e.g. counterexample)","Let $G$ be a group and $H$, $K$ subgroups such that $H$ is normal in $G$ and $H$, $K$ are isomorphic. After some thought i intuitively concluded that $K$ is not necessarilly normal in $G$. Is that the case? Any rigorous argument? (e.g. counterexample)",,['abstract-algebra']
19,Special types of extensions of fields,Special types of extensions of fields,,"Let $K$ be a field. Let $p$ be any prime number. Can one always construct an algebraic extension $K_p$ of $K$ with the following properties? (1) If $L$ is a finite extension of $K$ contained in $K_p$, then $[L:K]$ is coprime to $p$. (2) If $L$ is a finite extension of $K_p$, then $[L:K_p]$ is a power of $p$. If yes, how?","Let $K$ be a field. Let $p$ be any prime number. Can one always construct an algebraic extension $K_p$ of $K$ with the following properties? (1) If $L$ is a finite extension of $K$ contained in $K_p$, then $[L:K]$ is coprime to $p$. (2) If $L$ is a finite extension of $K_p$, then $[L:K_p]$ is a power of $p$. If yes, how?",,"['abstract-algebra', 'prime-numbers', 'field-theory']"
20,Smith normal form help,Smith normal form help,,"I want to find the structure of the abelian group: $$G=\frac{\mathbb{Z}^{3}}{\langle (2,0,10),(0,4,8),(4,-4,12) \rangle}$$ The Smith normal form of the matrix associated to $G$ is: $$P= \left( \begin{array}{ccc} 2 & 0 & 0 & 0\\ 0 & 4 & 0 & 0\\ 0 & 0 & 0 & 0\end{array} \right),$$ which is correct (verified it with software). Thus the decomposition of $G$ as a direct sum of cyclic groups is $\mathbb{Z}_{2} \oplus \mathbb{Z}_{4} \oplus \mathbb{Z}$ yes? why the answer is $\mathbb{Z}_{2} \oplus \mathbb{Z}_{4} \oplus \mathbb{Z} \oplus \mathbb{Z}$, i.e why the extra summand $\mathbb{Z}$?. I thought that we only look at the elements of the diagonal of $P$ which in this case there are only three: $2,4,0$. What am I doing incorrect? Can you please explain?","I want to find the structure of the abelian group: $$G=\frac{\mathbb{Z}^{3}}{\langle (2,0,10),(0,4,8),(4,-4,12) \rangle}$$ The Smith normal form of the matrix associated to $G$ is: $$P= \left( \begin{array}{ccc} 2 & 0 & 0 & 0\\ 0 & 4 & 0 & 0\\ 0 & 0 & 0 & 0\end{array} \right),$$ which is correct (verified it with software). Thus the decomposition of $G$ as a direct sum of cyclic groups is $\mathbb{Z}_{2} \oplus \mathbb{Z}_{4} \oplus \mathbb{Z}$ yes? why the answer is $\mathbb{Z}_{2} \oplus \mathbb{Z}_{4} \oplus \mathbb{Z} \oplus \mathbb{Z}$, i.e why the extra summand $\mathbb{Z}$?. I thought that we only look at the elements of the diagonal of $P$ which in this case there are only three: $2,4,0$. What am I doing incorrect? Can you please explain?",,['abstract-algebra']
21,Thoughts that guide a proof in abstract algebra,Thoughts that guide a proof in abstract algebra,,"I would like to know which strategies you use when proving abstract theorems. I have a particular example in mind. I worked some hours on a proof of the following: In the given diagram modules with corresponding module homomorphisms are shown. The homomorphisms f and g are in fact isomorphisms. Furthermore the rows are exact sequences. Task: Show that also h is an isomorphism. \begin{array}{ccccccc} 0 & \to & A & \to & C & \to & B & \to & 0 \\ & & \downarrow f & & \downarrow h & & \downarrow g \\ 0 & \to & A' & \to & C' & \to & B' & \to & 0 \end{array} I would like to not present my thoughts right from the start, so I don't spoil any nice ideas. To me it is very interesting which strategies you use to prove the theorem. Do you start working in a mechanical way? Do you try to convince yourself of the truth of the theorem using some heuristic reasoning? Do you forget about the goal at first and derive some properties that might help? Do you work with some mental images?","I would like to know which strategies you use when proving abstract theorems. I have a particular example in mind. I worked some hours on a proof of the following: In the given diagram modules with corresponding module homomorphisms are shown. The homomorphisms f and g are in fact isomorphisms. Furthermore the rows are exact sequences. Task: Show that also h is an isomorphism. \begin{array}{ccccccc} 0 & \to & A & \to & C & \to & B & \to & 0 \\ & & \downarrow f & & \downarrow h & & \downarrow g \\ 0 & \to & A' & \to & C' & \to & B' & \to & 0 \end{array} I would like to not present my thoughts right from the start, so I don't spoil any nice ideas. To me it is very interesting which strategies you use to prove the theorem. Do you start working in a mechanical way? Do you try to convince yourself of the truth of the theorem using some heuristic reasoning? Do you forget about the goal at first and derive some properties that might help? Do you work with some mental images?",,['abstract-algebra']
22,Why are cubics separable over fields that are not characteristic 2 or 3,Why are cubics separable over fields that are not characteristic 2 or 3,,"Why is it that cubics are separable over fields that are not of characteristic $2$ or $3$? This is the starting point for some a discussion of the Galois group of a cubic, but I seem to be stuck right off the bat.","Why is it that cubics are separable over fields that are not of characteristic $2$ or $3$? This is the starting point for some a discussion of the Galois group of a cubic, but I seem to be stuck right off the bat.",,"['abstract-algebra', 'polynomials', 'galois-theory']"
23,How do you show the ring of formal laurent series is well-defined?,How do you show the ring of formal laurent series is well-defined?,,"The only place I've encountered well-definition is with proving an operation defined on an equivalence class is independent of the choice of representative. On my homework, it asks us to show that the ring of formal Laurent series is well-defined, and I don't understand what exactly I need to show. However, I don't understand what I'm trying to prove. I've read the wikipedia article and don't understand how there is anything to prove in this case. If anyone could either point me to some better references explaining well-definition or explain what I need to do to prove that a laurent series is well-defined, I would appreciate it. Thanks, :)","The only place I've encountered well-definition is with proving an operation defined on an equivalence class is independent of the choice of representative. On my homework, it asks us to show that the ring of formal Laurent series is well-defined, and I don't understand what exactly I need to show. However, I don't understand what I'm trying to prove. I've read the wikipedia article and don't understand how there is anything to prove in this case. If anyone could either point me to some better references explaining well-definition or explain what I need to do to prove that a laurent series is well-defined, I would appreciate it. Thanks, :)",,"['abstract-algebra', 'terminology', 'ring-theory']"
24,Does the abelianisation functor $\mathrm{Grp} → \mathrm{AbGrp}$ preserve composition?,Does the abelianisation functor  preserve composition?,\mathrm{Grp} → \mathrm{AbGrp},"I am to show there is a functor $F : \mathrm{Grp} → \mathrm{AbGrp}$ . I have already checked that the assignments $F_0(G) := G_{\mathrm{ab}} := G/[G,G]$ and $F_1  (f \colon G → H) := \bar{f}: G_{\mathrm{ab}} → H_{\mathrm{ab}}$ are well-defined. (Using some elementary algebra theorems about factoring through quotients.) In checking that $F$ preserves composition, however, I run into some trouble. I have seen that for $f \colon G → H$ and $g \colon H → K$ group homomorphisms, $F_1(g ∘ f) = \overline{g ∘ f}$ and $F_1(f) ∘ F_1(g) = \bar{f} ∘ \bar{g}$ are both maps $G_{\mathrm{ab}} → K_{\mathrm{ab}}$ . (All this required some verification using factorisation through quotient groups to the abelianised groups.) However, I fail to see that these maps are the same ! I could of course evaluate them on the elements of $G_{\mathrm{ab}}$ , but I’m learning category theory and therefore want to show this not the ‘intrinsic’ way but the ‘extrinsic’ way. Now I drew the following diagrams, to show my thinking: such that both $\bar{f}, \bar{g}$ , and $\overline{g ∘ f}$ appear. Now what I know is that, for instance $g ∘ f = \overline{g ∘ f} ∘ \pi_G$ . What I’d like to do is just chase the diagrams to show $\overline{g ∘ f} = \bar{g} ∘ \bar{f}$ holds. What would help is if $\pi_H$ would be the identity¹, which would be so if $H$ were already abelian. Because then, we would just conclude that $$\overline{g ∘ f} ∘ \pi_G = \bar{g} ∘ \bar{f} ∘ \pi_G \,. $$ Which would bring us a lot closer. (Still not sure how to finish then, though.) ¹In a sense, this should indeed be true, because $\bar{f}$ , I think, should automatically map to an abelian group (one of the aforementioned elementary algebra theorems). HOWEVER, and this is where I get really confused, at no point was $H$ itself to be required anything but a general group! I feel like I’m really close here, so could someone help me fill in the gaps / patch up the mistakes in my thinking? Best wishes!","I am to show there is a functor . I have already checked that the assignments and are well-defined. (Using some elementary algebra theorems about factoring through quotients.) In checking that preserves composition, however, I run into some trouble. I have seen that for and group homomorphisms, and are both maps . (All this required some verification using factorisation through quotient groups to the abelianised groups.) However, I fail to see that these maps are the same ! I could of course evaluate them on the elements of , but I’m learning category theory and therefore want to show this not the ‘intrinsic’ way but the ‘extrinsic’ way. Now I drew the following diagrams, to show my thinking: such that both , and appear. Now what I know is that, for instance . What I’d like to do is just chase the diagrams to show holds. What would help is if would be the identity¹, which would be so if were already abelian. Because then, we would just conclude that Which would bring us a lot closer. (Still not sure how to finish then, though.) ¹In a sense, this should indeed be true, because , I think, should automatically map to an abelian group (one of the aforementioned elementary algebra theorems). HOWEVER, and this is where I get really confused, at no point was itself to be required anything but a general group! I feel like I’m really close here, so could someone help me fill in the gaps / patch up the mistakes in my thinking? Best wishes!","F : \mathrm{Grp} → \mathrm{AbGrp} F_0(G) := G_{\mathrm{ab}} := G/[G,G] F_1  (f \colon G → H) := \bar{f}: G_{\mathrm{ab}} → H_{\mathrm{ab}} F f \colon G → H g \colon H → K F_1(g ∘ f) = \overline{g ∘ f} F_1(f) ∘ F_1(g) = \bar{f} ∘ \bar{g} G_{\mathrm{ab}} → K_{\mathrm{ab}} G_{\mathrm{ab}} \bar{f}, \bar{g} \overline{g ∘ f} g ∘ f = \overline{g ∘ f} ∘ \pi_G \overline{g ∘ f} = \bar{g} ∘ \bar{f} \pi_H H \overline{g ∘ f} ∘ \pi_G = \bar{g} ∘ \bar{f} ∘ \pi_G \,.
 \bar{f} H","['abstract-algebra', 'category-theory', 'abelian-groups', 'functors']"
25,There is no natural isomorphism between torsion functor and identity,There is no natural isomorphism between torsion functor and identity,,"Let $\mathcal{C}$ be the full subcategory of $\textbf{Ab}$ whose objects are finitely generated abelian groups. Let $F:\mathcal{C}\rightarrow\mathcal{C}$ be the functor sending $A\in\mathcal{C}$ to $A_{\text{tor}}\oplus A/A_{\text{tor}}$ . I want to show there is not natural isomorphism $F\rightarrow\text{id}_{\mathcal{C}}$ . For the sake of contradiction, suppose there exists a natural isomorphism $u:F\rightarrow\text{id}_\mathcal{C}$ . For each $A\in\textbf{Ab}$ , let $v(A):=\iota_{A,2}\circ\pi_A$ where $\pi_A:A\rightarrow A/A_{\text{tor}}$ is the canonical surjection and $\iota_{A,2}:A/A_{\text{tor}}\rightarrow A_{\text{tor}}\oplus A/A_{\text{tor}}$ is the canonical injection. Clearly $v:\text{id}_{\mathcal{C}}\rightarrow F$ is a natural transformation. Thus we have $u\circ v:\text{id}_{\mathcal{C}}\rightarrow\text{id}_{\mathcal{C}}$ and so there exists $n\in\mathbb{Z}$ such that $$u(A)\circ v(A)=n\cdot\text{id}_A$$ for all $A\in\mathcal{C}$ . In fact $n=u(\mathbb{Z})(v(\mathbb{Z})(1))=u(\mathbb{Z})(0,\pi_{\mathbb{Z}}(1))$ . To get a contradiction, it's sufficient to show that necessarily $n=\pm1$ . How to prove this? Edit: Note that $A_{\text{tor}}$ is the torsion subgroup of the abelian group $A$ .","Let be the full subcategory of whose objects are finitely generated abelian groups. Let be the functor sending to . I want to show there is not natural isomorphism . For the sake of contradiction, suppose there exists a natural isomorphism . For each , let where is the canonical surjection and is the canonical injection. Clearly is a natural transformation. Thus we have and so there exists such that for all . In fact . To get a contradiction, it's sufficient to show that necessarily . How to prove this? Edit: Note that is the torsion subgroup of the abelian group .","\mathcal{C} \textbf{Ab} F:\mathcal{C}\rightarrow\mathcal{C} A\in\mathcal{C} A_{\text{tor}}\oplus A/A_{\text{tor}} F\rightarrow\text{id}_{\mathcal{C}} u:F\rightarrow\text{id}_\mathcal{C} A\in\textbf{Ab} v(A):=\iota_{A,2}\circ\pi_A \pi_A:A\rightarrow A/A_{\text{tor}} \iota_{A,2}:A/A_{\text{tor}}\rightarrow A_{\text{tor}}\oplus A/A_{\text{tor}} v:\text{id}_{\mathcal{C}}\rightarrow F u\circ v:\text{id}_{\mathcal{C}}\rightarrow\text{id}_{\mathcal{C}} n\in\mathbb{Z} u(A)\circ v(A)=n\cdot\text{id}_A A\in\mathcal{C} n=u(\mathbb{Z})(v(\mathbb{Z})(1))=u(\mathbb{Z})(0,\pi_{\mathbb{Z}}(1)) n=\pm1 A_{\text{tor}} A","['abstract-algebra', 'group-theory', 'category-theory', 'abelian-groups', 'finitely-generated']"
26,"Question on $(2, 1+\sqrt{-5})$ as a submodule of $\mathbb{Z}[\sqrt{-5}]$.",Question on  as a submodule of .,"(2, 1+\sqrt{-5}) \mathbb{Z}[\sqrt{-5}]","Let $R$ be the ring $\mathbb{Z}[\sqrt{-5}]$ and $I$ the ideal generated by $2$ and $1+\sqrt{-5}$ , $I=(2, 1+\sqrt{-5})$ . Show that $I$ is not R-module isomorphic to $R$ but $I\bigoplus I$ is R-module isomorphic to $R^2$ . My attempt thus far: It can be shown that $I$ is not principal, and thus not generated by a single element. Since $R$ is generated by $1$ , if there were an isomorphism $\phi: R \rightarrow I$ , $\phi(1)$ must generate $I$ . By contradiction, $I$ cannot be isomorphic to $R$ . However, I am unable to prove the second part of the question. I see that $R^2$ has rank 2, so if we can find a basis for $I\bigoplus I$ , say $(x,y)$ , then there is a direct isomorphism $\phi: R^2 \rightarrow I \bigoplus I$ , $\phi(1,0)=x$ , $\phi(0,1)=y$ . However, it's not immediately obvious to me what I should take as the basis for $I\bigoplus I$ ; is there a nonconstructive way of showing the two modules are isomorphic?","Let be the ring and the ideal generated by and , . Show that is not R-module isomorphic to but is R-module isomorphic to . My attempt thus far: It can be shown that is not principal, and thus not generated by a single element. Since is generated by , if there were an isomorphism , must generate . By contradiction, cannot be isomorphic to . However, I am unable to prove the second part of the question. I see that has rank 2, so if we can find a basis for , say , then there is a direct isomorphism , , . However, it's not immediately obvious to me what I should take as the basis for ; is there a nonconstructive way of showing the two modules are isomorphic?","R \mathbb{Z}[\sqrt{-5}] I 2 1+\sqrt{-5} I=(2, 1+\sqrt{-5}) I R I\bigoplus I R^2 I R 1 \phi: R \rightarrow I \phi(1) I I R R^2 I\bigoplus I (x,y) \phi: R^2 \rightarrow I \bigoplus I \phi(1,0)=x \phi(0,1)=y I\bigoplus I","['abstract-algebra', 'ring-theory', 'modules', 'ideals', 'free-modules']"
27,A group of order $150$ has at least $4$ conjugacy classes made by elements of order a power of $5$?,A group of order  has at least  conjugacy classes made by elements of order a power of ?,150 4 5,"Let be $G$ a group of order $150$ and $g \in G\,\,$ s.t. $|g|=25\,$ : Prove that $\exists \,\,K\lhd G\,\,$ s.t. $K \simeq C_5$ . $\,\,$ Say whether $\exists \,\,h \in G\,\,$ s.t. $|h| =15$ . $\,\,$ Prove that if $\,\,\exists\,\, t\in G/K$ s.t. $\,\,|t|=15$ then $G/K$ has only one $5$ -Sylow; in this case how many elements of order $15$ does $G$ have? $\,$ Prove that $G$ has at least $4$ conjugacy classes made by elements of order a power of $5$ . I am struggling with the last part of this exercise, any help will be greatly appreciated. My solution: We know, by hypothesis, that $\exists \,\,g\in G$ s.t. $|g|=25\,\,$ and this means that $C_{25} \leqslant G\,$ , where $\langle g \rangle = C_{25}\,$ , which is abelian because $25$ is the square of a prime, but it is also a $5$ -Sylow of $G$ , because $150=2 \cdot 3 \cdot 5^2$ , hence, for the Sylow's Theorems, the conjugacy action of $G$ on $C_{25}$ is transitive, which implies $C_{25} \lhd G\,\,$ . Observing that $g^5 \in C_{25}$ and that $|g^5|=5$ in $C_{25}$ , we have $C_5 \simeq \langle g^5 \rangle \lhd C_{25}\,\, \Rightarrow \,\, C_5 \lhd G$ . $G$ has an element $h$ of order $15 \iff C_{15}\leqslant G$ . Let be $P \in{\rm Sylow}_3(G)$ , now $|P| = 3$ which is a prime, therefore $P \simeq C_3$ . We have seen that $C_5 \lhd G$ , thus $H := C_3C_5 \leqslant G$ . From this: $C_3 \cap C_5 = \{1\}$ , $|C_3C_5| = 15 = |H|$ and $C_3, C_5 \lhd H$ because they are the only $3$ -Sylow and the only $5$ -Sylow in $H$ ; hence $H \simeq C_3 \times C_5 \simeq C_{15} \leqslant G$ . $h$ is the generator of $C_{15}$ . By hypothesis $C_{15} \leqslant G/K$ , with $K \simeq C_{25}$ . Now $|G/K|=30 =3 \cdot 2 \cdot 5$ and $[G/K : C_{15}]=2$ , which is the minimum prime that divides the order of $G/K$ , that implies $C_{15} \lhd G/K\,\,$ . We can observe that $C_{15}$ has only one $5$ -Sylow $Q$ , hence $Q \lhd C_{15} \lhd G/K$ , therefore $Q \lhd G/K$ , which means that $Q$ is the only $5$ -Sylow of $G/K$ . Any idea about the last two requests? Thank you.","Let be a group of order and s.t. : Prove that s.t. . Say whether s.t. . Prove that if s.t. then has only one -Sylow; in this case how many elements of order does have? Prove that has at least conjugacy classes made by elements of order a power of . I am struggling with the last part of this exercise, any help will be greatly appreciated. My solution: We know, by hypothesis, that s.t. and this means that , where , which is abelian because is the square of a prime, but it is also a -Sylow of , because , hence, for the Sylow's Theorems, the conjugacy action of on is transitive, which implies . Observing that and that in , we have . has an element of order . Let be , now which is a prime, therefore . We have seen that , thus . From this: , and because they are the only -Sylow and the only -Sylow in ; hence . is the generator of . By hypothesis , with . Now and , which is the minimum prime that divides the order of , that implies . We can observe that has only one -Sylow , hence , therefore , which means that is the only -Sylow of . Any idea about the last two requests? Thank you.","G 150 g \in G\,\, |g|=25\, \exists \,\,K\lhd G\,\, K \simeq C_5 \,\, \exists \,\,h \in G\,\, |h| =15 \,\, \,\,\exists\,\, t\in G/K \,\,|t|=15 G/K 5 15 G \, G 4 5 \exists \,\,g\in G |g|=25\,\, C_{25} \leqslant G\, \langle g \rangle = C_{25}\, 25 5 G 150=2 \cdot 3 \cdot 5^2 G C_{25} C_{25} \lhd G\,\, g^5 \in C_{25} |g^5|=5 C_{25} C_5 \simeq \langle g^5 \rangle \lhd C_{25}\,\, \Rightarrow \,\, C_5 \lhd G G h 15 \iff C_{15}\leqslant G P \in{\rm Sylow}_3(G) |P| = 3 P \simeq C_3 C_5 \lhd G H := C_3C_5 \leqslant G C_3 \cap C_5 = \{1\} |C_3C_5| = 15 = |H| C_3, C_5 \lhd H 3 5 H H \simeq C_3 \times C_5 \simeq C_{15} \leqslant G h C_{15} C_{15} \leqslant G/K K \simeq C_{25} |G/K|=30 =3 \cdot 2 \cdot 5 [G/K : C_{15}]=2 G/K C_{15} \lhd G/K\,\, C_{15} 5 Q Q \lhd C_{15} \lhd G/K Q \lhd G/K Q 5 G/K","['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory']"
28,"If $A \times B$ is a Lie group, are both $A$ and $B$ Lie groups?","If  is a Lie group, are both  and  Lie groups?",A \times B A B,"Suppose $A,B$ are smooth manifolds and there exists a binary operation on the product manifold $A \times B$ making it into a Lie group. Does this guarantee that there exist binary operations on both $A$ and $B$ making them each into Lie groups? If the answer is yes, can it be done in such a way that the product group $A \times B$ is equal to the original Lie group? If the answer to that is yes, is it necessary? I tried briefly to find a counterexample browsing a table of Lie groups but was unsuccessful.","Suppose are smooth manifolds and there exists a binary operation on the product manifold making it into a Lie group. Does this guarantee that there exist binary operations on both and making them each into Lie groups? If the answer is yes, can it be done in such a way that the product group is equal to the original Lie group? If the answer to that is yes, is it necessary? I tried briefly to find a counterexample browsing a table of Lie groups but was unsuccessful.","A,B A \times B A B A \times B",['abstract-algebra']
29,Definition of tensor product of rings,Definition of tensor product of rings,,"Let $X=\operatorname{Spec} A,Y=\operatorname{Spec}B$ and $Z=\operatorname{Spec}C$ be affine schemes, with $A,B,C$ commutative rings. According to Wikipedia, the following holds: $X \times_Y Z\cong \operatorname{Spec}\left( A\otimes_B C \right)$ . Question: What is the tensor products of rings? Do we view $A$ and $C$ as $B$ -algebras in some kind of way?","Let and be affine schemes, with commutative rings. According to Wikipedia, the following holds: . Question: What is the tensor products of rings? Do we view and as -algebras in some kind of way?","X=\operatorname{Spec} A,Y=\operatorname{Spec}B Z=\operatorname{Spec}C A,B,C X \times_Y Z\cong \operatorname{Spec}\left( A\otimes_B C \right) A C B","['abstract-algebra', 'algebraic-geometry', 'ring-theory', 'tensor-products', 'schemes']"
30,Further interesting examples? Obtaining (co)monoids from dual objects,Further interesting examples? Obtaining (co)monoids from dual objects,,"1. Context Obtaining (co)monoids from dual objects Let $(C, \otimes,  I, a, l,r)$ be a monoidal category. To simplify notation (and work with string diagrams) we assume that $C$ is strict. Let $V \in C$ be a right dualizable object, i.e. there exists an object $V^* \in C$ and morphisms $b_V: I \rightarrow V \otimes V^*$ , $d_V: V^* \otimes V \rightarrow I$ that satisfy the zigzag-identities. It seems, this data alone induces the structure of a monoid object $(V \otimes V^*, \mu, \eta)$ where $\mu = (r_V \otimes id_{V^*})\circ (id_V \otimes d_V \otimes id_{V^*})$ and $\eta =b_V$ . This can be verified by using the zigzag identities. Analogously, it seems we have the structure of a comonoid object $(V^* \otimes V, \Delta, \epsilon)$ where $\Delta:(id_{V^*} \otimes b_V \otimes id_V)\circ (r^{-1}_{V^*} \otimes id_V)$ and $\epsilon=d_V$ . Two motivating examples The category of endofunctors $End(C)$ of any small category $C$ . It becomes a monoidal category in the following way: Composition of functors is the monoidal product. The monoidal unit is given by the identity functor on $C$ . As the composition of functors is associative this category is strict. A right dual to an object $F \in End(C)$ is a right adjoint functor to that functor $F$ . (Co)monads are (co)monoid objects in the category of endofunctors. Hence, above construction shows how one can obtain a (co)monad from a pair of adjoint functors (i.e. by suitably composing the pair of adjoint functors, and defining the respective natural transformations as described above.) Consider the monoidal category of finite dimensional vector spaces (over a field) with tensor product of vector spaces as the monoidal product. This category is rigid. (The dual vector space is precisely the right/left dual object. Evaluation and coevaluation are the morphisms $d$ and $b$ respectively.) Let $V$ be an object in that category. We then have the identification $End(V) \cong V \otimes V^*$ . The above construction hence endows $End(V)$ with the structure of a unital, associative algebra. 2. Questions This algebra structure is the same as the the algebra structure on $End(V)$ given by the composition of maps (multiplication) and $\eta (1_{\mathbb k})=id_V$ (unit). Correct? By the above construction we can turn $V \otimes V^* \cong End(V)$ into a coalgebra. Is the induced coproduct $\Delta:End(V) \rightarrow End(V) \otimes End(V)$ simply the diagonal map $\Delta(f)=f \otimes f$ ? What is the counit specified on a basis of $End(V)$ ? What are other (enlightening or interesting) examples of the above construction (obtaining (co)monoids from dual objects) in other monoidal categories from the ones mentioned?","1. Context Obtaining (co)monoids from dual objects Let be a monoidal category. To simplify notation (and work with string diagrams) we assume that is strict. Let be a right dualizable object, i.e. there exists an object and morphisms , that satisfy the zigzag-identities. It seems, this data alone induces the structure of a monoid object where and . This can be verified by using the zigzag identities. Analogously, it seems we have the structure of a comonoid object where and . Two motivating examples The category of endofunctors of any small category . It becomes a monoidal category in the following way: Composition of functors is the monoidal product. The monoidal unit is given by the identity functor on . As the composition of functors is associative this category is strict. A right dual to an object is a right adjoint functor to that functor . (Co)monads are (co)monoid objects in the category of endofunctors. Hence, above construction shows how one can obtain a (co)monad from a pair of adjoint functors (i.e. by suitably composing the pair of adjoint functors, and defining the respective natural transformations as described above.) Consider the monoidal category of finite dimensional vector spaces (over a field) with tensor product of vector spaces as the monoidal product. This category is rigid. (The dual vector space is precisely the right/left dual object. Evaluation and coevaluation are the morphisms and respectively.) Let be an object in that category. We then have the identification . The above construction hence endows with the structure of a unital, associative algebra. 2. Questions This algebra structure is the same as the the algebra structure on given by the composition of maps (multiplication) and (unit). Correct? By the above construction we can turn into a coalgebra. Is the induced coproduct simply the diagonal map ? What is the counit specified on a basis of ? What are other (enlightening or interesting) examples of the above construction (obtaining (co)monoids from dual objects) in other monoidal categories from the ones mentioned?","(C, \otimes,  I, a, l,r) C V \in C V^* \in C b_V: I \rightarrow V \otimes V^* d_V: V^* \otimes V \rightarrow I (V \otimes V^*, \mu, \eta) \mu = (r_V \otimes id_{V^*})\circ (id_V \otimes d_V \otimes id_{V^*}) \eta =b_V (V^* \otimes V, \Delta, \epsilon) \Delta:(id_{V^*} \otimes b_V \otimes id_V)\circ (r^{-1}_{V^*} \otimes id_V) \epsilon=d_V End(C) C C F \in End(C) F d b V End(V) \cong V \otimes V^* End(V) End(V) \eta (1_{\mathbb k})=id_V V \otimes V^* \cong End(V) \Delta:End(V) \rightarrow End(V) \otimes End(V) \Delta(f)=f \otimes f End(V)","['abstract-algebra', 'category-theory', 'examples-counterexamples', 'dual-spaces', 'monoidal-categories']"
31,"Showing that $(\mathbb{C}[x,y]/(xy))_x\cong \mathbb{C}[x]_x$",Showing that,"(\mathbb{C}[x,y]/(xy))_x\cong \mathbb{C}[x]_x","I'd like to understand rigorously why $(\mathbb{C}[x,y]/(xy))_x\cong \mathbb{C}[x]_x$ . Intuitively, it seems reasonable. However I'd like to know whether the kernel of the map I've constructed for the isomorphism is correct. We can start with a map $f:\mathbb{C}[x,y]\rightarrow \mathbb{C}[x]_x$ mapping $f(x,y) \mapsto f(x,0)\mapsto f(x,0)/1$ . If the kernel of this map is $(xy)$ ,we get a map $f:\mathbb{C}[x,y]/(xy)\rightarrow \mathbb{C}[x]_x$ . This gives us an induced map from $(\mathbb{C}[x,y]/(xy))_x\rightarrow \mathbb{C}[x]_x$ by the universal property of localization, and it is not hard to show that this is a bijection. However, is the kernel in fact $(xy)$ ? We have $\rm ker f= \{f(x,y)\in \mathbb{C}[x,y]\mid f(x,0)/1=0/x^n \text{ for some $n$}\}$ , and so the kernel consists of elements of the form $x^nf(x,y)$ where $f(x,0)=0$ or $x=0$ . Does this imply that the kernel is $(xy)$ ?","I'd like to understand rigorously why . Intuitively, it seems reasonable. However I'd like to know whether the kernel of the map I've constructed for the isomorphism is correct. We can start with a map mapping . If the kernel of this map is ,we get a map . This gives us an induced map from by the universal property of localization, and it is not hard to show that this is a bijection. However, is the kernel in fact ? We have , and so the kernel consists of elements of the form where or . Does this imply that the kernel is ?","(\mathbb{C}[x,y]/(xy))_x\cong \mathbb{C}[x]_x f:\mathbb{C}[x,y]\rightarrow \mathbb{C}[x]_x f(x,y) \mapsto f(x,0)\mapsto f(x,0)/1 (xy) f:\mathbb{C}[x,y]/(xy)\rightarrow \mathbb{C}[x]_x (\mathbb{C}[x,y]/(xy))_x\rightarrow \mathbb{C}[x]_x (xy) \rm ker f= \{f(x,y)\in \mathbb{C}[x,y]\mid f(x,0)/1=0/x^n \text{ for some n}\} x^nf(x,y) f(x,0)=0 x=0 (xy)","['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'localization']"
32,Does Hilbert's theorem 90 hold for local rings?,Does Hilbert's theorem 90 hold for local rings?,,"Let $R$ be a local ring (commutative with 1). Let $G$ be a finite subgroup of $\text{Aut}(R)$ preserving the maximal ideal. Then it seems to me that we also have: $$H^1(G,R^\times) = 0$$ Is this correct? (The classical Hilbert theorem 90 states this when $R$ is a field). Here's the argument: First, you need the Lemma: If $g_1,\ldots,g_n$ are distinct automorphisms of $R$ , then if for $c_i\in R$ , $\sum_{i=1}^n c_ig_i = 0$ (as a function $R\rightarrow R$ ), then each $c_i = 0$ . Indeed, one may assume that there is a minimal such relation, where $c_1g_1 + \cdots + c_rg_r = 0$ with $c_1,\ldots,c_r$ all nonzero. In this case we must have $r > 1$ since $c_1g_1 = 0$ means $c_1g_1(1) = c_1\cdot 1 = 0$ so $c_1 = 0$ . Now since $g_1\ne g_r$ , let $a\in R$ be such that $g_1(a)\ne g_r(a)$ . Let $x\in R$ be arbitrary. We have: $$\sum_{i=1}^r c_ig_i(ax) = \sum_{i=1}^r c_ig_i(a)g_i(x) = \sum_{i=1}^rc_ig_i(x) = 0$$ Multiplying the last sum by $g_r(a)$ and subtracting from the second sum, we get: $$\sum_{i=1}^rc_i(g_i(a)-g_r(a))g_i(x) = \sum_{i=1}^{r-1}c_i(g_i(a)-g_r(a))g_i(x) = 0$$ Since this holds for all $x\in R$ , this gives a shorter relation and by our choice of $a$ , the coefficients are not all zero, since $c_1(g_1(a) - g_r(a))\ne 0$ . To prove the theorem, we now proceed as usual: Let $\alpha : G\rightarrow R^\times$ be a 1-cocycle, so $\alpha$ satisfies $\alpha(gh) = \alpha(g)\cdot (g.\alpha(h))$ . In particular, we have $g.\alpha(h) = \alpha(g)^{-1}\alpha(gh)$ . Applying the above result to the residue field $R/\mathfrak{m}$ , the linear combination $$\sum_{g\in G}\alpha(g)\cdot g$$ is nonzero in the residue field. Thus, there exists a $\theta\in R$ such that $$\beta := \sum_{g\in G}\alpha(g)\cdot g(\theta) \in R^\times$$ Then, for each $h\in G$ , we have $$h(\beta) = h\left(\sum_{g\in G}\alpha(g)\cdot g(\theta)\right) = \sum_{g\in G}h(\alpha(g))\cdot (hg)(\theta) = \sum_{g\in G}(\alpha(h)^{-1}\alpha(hg))\cdot (hg)(\theta) = \alpha(h)^{-1}\sum_{g\in G}\alpha(hg)\cdot (hg)(\theta) = \alpha(h)^{-1}\beta$$ Thus, $\alpha(h) = \frac{\beta}{h(\beta)} = \frac{h(\beta^{-1})}{\beta^{-1}}$ , so $\alpha$ is a coboundary. Does this seem right? I just want to record this here since I find it strange that I've never seen this simple generalization, which doesn't require any real additional technology to state or prove.","Let be a local ring (commutative with 1). Let be a finite subgroup of preserving the maximal ideal. Then it seems to me that we also have: Is this correct? (The classical Hilbert theorem 90 states this when is a field). Here's the argument: First, you need the Lemma: If are distinct automorphisms of , then if for , (as a function ), then each . Indeed, one may assume that there is a minimal such relation, where with all nonzero. In this case we must have since means so . Now since , let be such that . Let be arbitrary. We have: Multiplying the last sum by and subtracting from the second sum, we get: Since this holds for all , this gives a shorter relation and by our choice of , the coefficients are not all zero, since . To prove the theorem, we now proceed as usual: Let be a 1-cocycle, so satisfies . In particular, we have . Applying the above result to the residue field , the linear combination is nonzero in the residue field. Thus, there exists a such that Then, for each , we have Thus, , so is a coboundary. Does this seem right? I just want to record this here since I find it strange that I've never seen this simple generalization, which doesn't require any real additional technology to state or prove.","R G \text{Aut}(R) H^1(G,R^\times) = 0 R g_1,\ldots,g_n R c_i\in R \sum_{i=1}^n c_ig_i = 0 R\rightarrow R c_i = 0 c_1g_1 + \cdots + c_rg_r = 0 c_1,\ldots,c_r r > 1 c_1g_1 = 0 c_1g_1(1) = c_1\cdot 1 = 0 c_1 = 0 g_1\ne g_r a\in R g_1(a)\ne g_r(a) x\in R \sum_{i=1}^r c_ig_i(ax) = \sum_{i=1}^r c_ig_i(a)g_i(x) = \sum_{i=1}^rc_ig_i(x) = 0 g_r(a) \sum_{i=1}^rc_i(g_i(a)-g_r(a))g_i(x) = \sum_{i=1}^{r-1}c_i(g_i(a)-g_r(a))g_i(x) = 0 x\in R a c_1(g_1(a) - g_r(a))\ne 0 \alpha : G\rightarrow R^\times \alpha \alpha(gh) = \alpha(g)\cdot (g.\alpha(h)) g.\alpha(h) = \alpha(g)^{-1}\alpha(gh) R/\mathfrak{m} \sum_{g\in G}\alpha(g)\cdot g \theta\in R \beta := \sum_{g\in G}\alpha(g)\cdot g(\theta) \in R^\times h\in G h(\beta) = h\left(\sum_{g\in G}\alpha(g)\cdot g(\theta)\right) = \sum_{g\in G}h(\alpha(g))\cdot (hg)(\theta) = \sum_{g\in G}(\alpha(h)^{-1}\alpha(hg))\cdot (hg)(\theta) = \alpha(h)^{-1}\sum_{g\in G}\alpha(hg)\cdot (hg)(\theta) = \alpha(h)^{-1}\beta \alpha(h) = \frac{\beta}{h(\beta)} = \frac{h(\beta^{-1})}{\beta^{-1}} \alpha","['abstract-algebra', 'algebraic-geometry']"
33,Formal power series are a euclidean ring,Formal power series are a euclidean ring,,"Denote by $F[[T]]$ the ring of formal power series over a field $F$ (i.e expressions of the form $\sum_{n=0}^{\infty}a_nT^n$ , $a_i \in F$ ). I need to show that this is a euclidean ring with respect to the norm $\mathrm{ord}(\sum a_iT^i) = \min\{n \mid a_n \neq 0\}$ . This just feels too trivial and I think I am missing something obvious, so I would like to get a feedback on my proof (if it is even correct). Take $f,g$ in the ring. If $\mathrm{ord}(g) < \mathrm{ord}(f)$ we get $g=f \cdot 0 + g$ , so we can divide $g$ by $f$ and get a remainder. Now suppose $\mathrm{ord}(g)=n>\mathrm{ord}(f)=k$ . I claim $f\mid g$ and therefore $g=fq+0$ for some $q$ . First, if $f=T^k$ then obviously $f\mid g$ . So take $q_1$ such that $g=T^kq_1$ . Now since $\mathrm{ord}(f) = k$ we can write $f=T^kf_1$ for some $f_1$ that is invertible (since the coefficient of $1=T^0$ in it is nonzero). Taking $q = f_1^{-1}q_1$ we get $g=fq$ , so $f\mid g$ and we are done. Is this true? Am I missing something? This is suspicious for me because it seems like I proved that whenever $\mathrm{ord}(g) > \mathrm{ord}(f)$ we have $f\mid g$ which seems like a much stronger result than what I was asked to prove.","Denote by the ring of formal power series over a field (i.e expressions of the form , ). I need to show that this is a euclidean ring with respect to the norm . This just feels too trivial and I think I am missing something obvious, so I would like to get a feedback on my proof (if it is even correct). Take in the ring. If we get , so we can divide by and get a remainder. Now suppose . I claim and therefore for some . First, if then obviously . So take such that . Now since we can write for some that is invertible (since the coefficient of in it is nonzero). Taking we get , so and we are done. Is this true? Am I missing something? This is suspicious for me because it seems like I proved that whenever we have which seems like a much stronger result than what I was asked to prove.","F[[T]] F \sum_{n=0}^{\infty}a_nT^n a_i \in F \mathrm{ord}(\sum a_iT^i) = \min\{n \mid a_n \neq 0\} f,g \mathrm{ord}(g) < \mathrm{ord}(f) g=f \cdot 0 + g g f \mathrm{ord}(g)=n>\mathrm{ord}(f)=k f\mid g g=fq+0 q f=T^k f\mid g q_1 g=T^kq_1 \mathrm{ord}(f) = k f=T^kf_1 f_1 1=T^0 q = f_1^{-1}q_1 g=fq f\mid g \mathrm{ord}(g) > \mathrm{ord}(f) f\mid g","['abstract-algebra', 'ring-theory', 'field-theory', 'power-series', 'formal-power-series']"
34,Non-Naturality of the Splitting in the Universal Coefficient Formula,Non-Naturality of the Splitting in the Universal Coefficient Formula,,"I want to show the non-naturality of the splitting in the universal coefficient formula for homology. The s.e.s. is $$0\to H_q(X,X';R)\otimes_R N\to H_q(X,X';N)\to Tor^R_1(H_{q-1}(X,X';R),N)\to 0$$ where $R$ is a PID and $N$ an $R-$ module. I found a counter example with the map $\mathbb{RP}^2\to S^2$ that collapses the 1-cell of $\mathbb{RP}^2$ to a point, but I don't get why this map works.","I want to show the non-naturality of the splitting in the universal coefficient formula for homology. The s.e.s. is where is a PID and an module. I found a counter example with the map that collapses the 1-cell of to a point, but I don't get why this map works.","0\to H_q(X,X';R)\otimes_R N\to H_q(X,X';N)\to Tor^R_1(H_{q-1}(X,X';R),N)\to 0 R N R- \mathbb{RP}^2\to S^2 \mathbb{RP}^2","['abstract-algebra', 'algebraic-topology', 'homological-algebra']"
35,Group with exactly $2$ elements of order $6$ has a normal subgroup of order $3$,Group with exactly  elements of order  has a normal subgroup of order,2 6 3,"Let $G$ be a group with exactly $2$ elements of order $6$ . Prove that $G$ has a normal subgroup of order $3$ . Since there is an element of order $6$ , by Lagrange's Theorem, the order of $G$ must be a multiple of $6$ . That means that both $2$ and $3$ are also divisors of the order of $G$ , so, again by Cauchy's Theorem, $G$ must contain elements of order $2$ and order $3$ as well, respectively. I suppose I'm not sure where to proceed from here. How can we use the fact that $G$ has exactly $2$ elements of order $6$ ? Would Sylow Theorems be helpful here at all ? I don't see how - since we don't know the exact order of $G$ here, which is when I'm used to using the Sylow Theorems. Any help would be appreciated. Thanks!","Let be a group with exactly elements of order . Prove that has a normal subgroup of order . Since there is an element of order , by Lagrange's Theorem, the order of must be a multiple of . That means that both and are also divisors of the order of , so, again by Cauchy's Theorem, must contain elements of order and order as well, respectively. I suppose I'm not sure where to proceed from here. How can we use the fact that has exactly elements of order ? Would Sylow Theorems be helpful here at all ? I don't see how - since we don't know the exact order of here, which is when I'm used to using the Sylow Theorems. Any help would be appreciated. Thanks!",G 2 6 G 3 6 G 6 2 3 G G 2 3 G 2 6 G,"['abstract-algebra', 'group-theory', 'normal-subgroups']"
36,Which one of these is an abelian group?,Which one of these is an abelian group?,,"Consider the sets $$G_1=\{x+y\sqrt{3} | x,y \in \mathbb{Z}, x^2-3y^2=1\}$$ and $$G_2=\{x+y\sqrt{3} | x,y \in \mathbb{Q}, x^2-3y^2=1\}.$$ Which one of $(G_1,\cdot)$ and $(G_2, \cdot)$ is an abelian group, where $\cdot$ denotes the multiplication of the real numbers? I think that both of them are abelian groups, because to me it seems that they both satisfy the group axioms(they are commutative and associative due to the fact that the multiplication of reals satisfies these conditions etc). However, my book says that only $(G_2,\cdot)$ is a group without providing any explanation. I don't understand why $(G_1,\cdot)$ isn't a group.","Consider the sets and Which one of and is an abelian group, where denotes the multiplication of the real numbers? I think that both of them are abelian groups, because to me it seems that they both satisfy the group axioms(they are commutative and associative due to the fact that the multiplication of reals satisfies these conditions etc). However, my book says that only is a group without providing any explanation. I don't understand why isn't a group.","G_1=\{x+y\sqrt{3} | x,y \in \mathbb{Z}, x^2-3y^2=1\} G_2=\{x+y\sqrt{3} | x,y \in \mathbb{Q}, x^2-3y^2=1\}. (G_1,\cdot) (G_2, \cdot) \cdot (G_2,\cdot) (G_1,\cdot)","['abstract-algebra', 'group-theory']"
37,Does there exist an endofunctor of the category of countable sets that lacks an initial algebra?,Does there exist an endofunctor of the category of countable sets that lacks an initial algebra?,,"There exist endofunctors of $\mathbf{Set}$ that are deficient inasmuch as they lack an initial algebra. The canonical example is the covariant powerset functor (the initial algebra of $\mathcal{P}$ , if it existed, would include the whole cumulative hierarchy). Now let $\mathbf{Set}_{< \aleph_1}$ denote the category of countable sets. I'm curious to know if there exist endofunctors of $\mathbf{Set}_{< \aleph_1}$ that also lack an initial algebra. Since we can't take powersets while remaining in the countable realm, it will be interesting to see if anyone can find an example of such a thing.","There exist endofunctors of that are deficient inasmuch as they lack an initial algebra. The canonical example is the covariant powerset functor (the initial algebra of , if it existed, would include the whole cumulative hierarchy). Now let denote the category of countable sets. I'm curious to know if there exist endofunctors of that also lack an initial algebra. Since we can't take powersets while remaining in the countable realm, it will be interesting to see if anyone can find an example of such a thing.",\mathbf{Set} \mathcal{P} \mathbf{Set}_{< \aleph_1} \mathbf{Set}_{< \aleph_1},"['abstract-algebra', 'category-theory', 'set-theory', 'foundations']"
38,Is there a natural example of a divisible torsioned (= periodic) abelian group?,Is there a natural example of a divisible torsioned (= periodic) abelian group?,,"The following are easy to verify: (I) Every ordered group is torsion-free. (II) Every non-trivial torsion-free group is infinite. Also, if $G$ is a non-trivial divisible group of a finite order $n,$ then for a non-zero element $a\in G$ we can not find an element $b$ with $a=\underbrace{b+\ldots+b}_{n-times}.$ Because, using Lagrange's theorem, the element $\underbrace{b+\ldots+b}_{n-times}$ would be equal to zero for any $b\in G.$ Hence, we also have the following: (III) Every non-trivial divisible group is infinite. Using a compactness argument from model theory and the fact that every finitely generated torsion-free abelian group is isomorphic to some $\mathbb{Z}^{n},$ we also have that: (IV) Every torsion-free abelian group is orderable. Hence, in the realm of abelian groups torsion-free coincides with orderable. The following are some typical examples for the aforementioned notions in the realm of abelian groups: 1- $\langle\mathbb{Z},+,0\rangle$ is non-didivisible torsion-free. 2- $\langle\mathbb{Q},+,0\rangle, \langle\mathbb{R},+,0\rangle, $ and $\langle\mathbb{C},+,0\rangle$ all are divisible torsion-free. 3- For any $n,$ the group $\langle(\mathbb{Z}_{n})^{\omega},+,0\rangle$ is infinite non-divisible and torsion (=periodic). The situation remains almost unchanged if you consider the above examples with their natural multiplications: 1- $\langle\mathbb{Z}^{+},.,1\rangle$ is not a group at all! 2- $\langle\mathbb{Q}^{+},.,1\rangle$ and $\langle\mathbb{R}^{+},.,1\rangle$ are torsion-free but non-divisible: there is no element like $a$ with $-1=a.a.$ 3- $\langle\mathbb{C}^{+},.,1\rangle$ is torsion-free and divisible since, as a consequence of being an algebraically closed field, for every $a,$ the equation $x^n=a$ has always a solution in $\mathbb{C}^{+}.$ 4- $\langle\mathbb{Z}^{+}_{n},.,1\rangle$ is a group if and only if $n$ is prime. In this case also, $\langle(\mathbb{Z}^{+}_{p})^{\omega},.,1\rangle$ is torsioned non-divisible. Now, my question is if there exists a divisible torsioned(=periodic) abelian group built using numerical examples? In fact, due to some decidability concerns, I am more interested in additive examples.","The following are easy to verify: (I) Every ordered group is torsion-free. (II) Every non-trivial torsion-free group is infinite. Also, if is a non-trivial divisible group of a finite order then for a non-zero element we can not find an element with Because, using Lagrange's theorem, the element would be equal to zero for any Hence, we also have the following: (III) Every non-trivial divisible group is infinite. Using a compactness argument from model theory and the fact that every finitely generated torsion-free abelian group is isomorphic to some we also have that: (IV) Every torsion-free abelian group is orderable. Hence, in the realm of abelian groups torsion-free coincides with orderable. The following are some typical examples for the aforementioned notions in the realm of abelian groups: 1- is non-didivisible torsion-free. 2- and all are divisible torsion-free. 3- For any the group is infinite non-divisible and torsion (=periodic). The situation remains almost unchanged if you consider the above examples with their natural multiplications: 1- is not a group at all! 2- and are torsion-free but non-divisible: there is no element like with 3- is torsion-free and divisible since, as a consequence of being an algebraically closed field, for every the equation has always a solution in 4- is a group if and only if is prime. In this case also, is torsioned non-divisible. Now, my question is if there exists a divisible torsioned(=periodic) abelian group built using numerical examples? In fact, due to some decidability concerns, I am more interested in additive examples.","G n, a\in G b a=\underbrace{b+\ldots+b}_{n-times}. \underbrace{b+\ldots+b}_{n-times} b\in G. \mathbb{Z}^{n}, \langle\mathbb{Z},+,0\rangle \langle\mathbb{Q},+,0\rangle, \langle\mathbb{R},+,0\rangle,  \langle\mathbb{C},+,0\rangle n, \langle(\mathbb{Z}_{n})^{\omega},+,0\rangle \langle\mathbb{Z}^{+},.,1\rangle \langle\mathbb{Q}^{+},.,1\rangle \langle\mathbb{R}^{+},.,1\rangle a -1=a.a. \langle\mathbb{C}^{+},.,1\rangle a, x^n=a \mathbb{C}^{+}. \langle\mathbb{Z}^{+}_{n},.,1\rangle n \langle(\mathbb{Z}^{+}_{p})^{\omega},.,1\rangle","['abstract-algebra', 'group-theory', 'logic', 'model-theory', 'abelian-groups']"
39,Extension Theorems,Extension Theorems,,"If we were to abstractly represent ""analytic continuation"" from complex analysis, it would look something like this: ""If $f$ is a function with property $P$ on a set $U$ satisfying some conditions $C$ , then $f$ can be uniquely extended to a bigger set $Q$ such that $P\subset Q$ and $f$ still has property $P$ ."" In measure theory, the Caratheodory Extension Theorem says that any measure $\mu$ defined on a ring $R$ of subsets can be extended to the sigma algebra generated by $R$ and this extension is unique as long as the $\mu$ is sigma finite. So in a way, subaddativity and sigma-finiteness for measures are analogous to complex-analytic for functions. Question 1: What are some other examples of such unique extension theorems, say in combinatorics, or group theory? Question 2: Is there a nice unification (""categorification?"") of these extension theorems? Specially, in what ways must property $P$ be special? Edit: I would like to re-emphasize that the extension should be unique .","If we were to abstractly represent ""analytic continuation"" from complex analysis, it would look something like this: ""If is a function with property on a set satisfying some conditions , then can be uniquely extended to a bigger set such that and still has property ."" In measure theory, the Caratheodory Extension Theorem says that any measure defined on a ring of subsets can be extended to the sigma algebra generated by and this extension is unique as long as the is sigma finite. So in a way, subaddativity and sigma-finiteness for measures are analogous to complex-analytic for functions. Question 1: What are some other examples of such unique extension theorems, say in combinatorics, or group theory? Question 2: Is there a nice unification (""categorification?"") of these extension theorems? Specially, in what ways must property be special? Edit: I would like to re-emphasize that the extension should be unique .",f P U C f Q P\subset Q f P \mu R R \mu P,"['abstract-algebra', 'complex-analysis', 'measure-theory']"
40,Suppose that $G$ is a group of order $924=2^2\cdot3\cdot7\cdot 11$. Prove that $G$ has an element of order $77$.,Suppose that  is a group of order . Prove that  has an element of order .,G 924=2^2\cdot3\cdot7\cdot 11 G 77,"Suppose that $G$ is a group of order $924=2^2\cdot3\cdot7\cdot 11$ . Prove that $G$ has an element of order $77$ . My attempt: By Sylow theorems, we know that there exist elements $ a, b\in G$ with $o(a)=7 $ and $o(b)=11$ . Note that $\gcd(7,11)=1$ , so if we can show that $ab=ba$ then we are through. Consider the group $\langle a \rangle$ acting on the set $\Omega=\{g\in G: o(g)=11\}$ by $$ a^k\cdot g:=a^kga^{-k}\ , k=1,2,...,7. $$ Note that the element and its conjugate have the same order and we can easily check that it is a well-defined $\langle a\rangle$ group action on $\Omega$ . Now by the Burnside's lemma , we know that the number of orbits, denoted by $|\Omega/\langle a\rangle|$ : $$ |\Omega/\langle a\rangle|=\frac{1}{7}\sum_{a^{k}\in\langle a\rangle}|\Omega^{a^k}| $$ where $\Omega^{a^k}=\{g\in\Omega:a^k\cdot g=g\}$ . Now suppose the converse, i.e., there are not elements fixed by $a^k$ in $\Omega$ if $k\ne 7$ ( $a^7=e$ the unit), then $$ |\Omega/\langle a\rangle|=\frac{1}{7}\sum_{e}|\Omega^{e}|=\frac{|\Omega|}{7}\in\mathbb Z. $$ So $\displaystyle 7\vert |\Omega|$ . But the number of Sylow $11$ -subgroups $n_{11}| 12\cdot 7$ and $n_{11}\equiv 1\pmod {11}$ , we have $n_{11}=1$ or $n_{11}=12$ and in either case, $|\Omega|=11-1=10$ and $|\Omega|=12\cdot (11-1)=12\cdot 10=120$ , respectively. But neither $7$ divides $10$ nor $7$ divides $120$ and we are done. Is my reasoning right? Moreover, I am looking for other solutions without using Burnside's lemma. Thank you.","Suppose that is a group of order . Prove that has an element of order . My attempt: By Sylow theorems, we know that there exist elements with and . Note that , so if we can show that then we are through. Consider the group acting on the set by Note that the element and its conjugate have the same order and we can easily check that it is a well-defined group action on . Now by the Burnside's lemma , we know that the number of orbits, denoted by : where . Now suppose the converse, i.e., there are not elements fixed by in if ( the unit), then So . But the number of Sylow -subgroups and , we have or and in either case, and , respectively. But neither divides nor divides and we are done. Is my reasoning right? Moreover, I am looking for other solutions without using Burnside's lemma. Thank you.","G 924=2^2\cdot3\cdot7\cdot 11 G 77  a, b\in G o(a)=7  o(b)=11 \gcd(7,11)=1 ab=ba \langle a \rangle \Omega=\{g\in G: o(g)=11\}  a^k\cdot g:=a^kga^{-k}\ , k=1,2,...,7.  \langle a\rangle \Omega |\Omega/\langle a\rangle|  |\Omega/\langle a\rangle|=\frac{1}{7}\sum_{a^{k}\in\langle a\rangle}|\Omega^{a^k}|  \Omega^{a^k}=\{g\in\Omega:a^k\cdot g=g\} a^k \Omega k\ne 7 a^7=e  |\Omega/\langle a\rangle|=\frac{1}{7}\sum_{e}|\Omega^{e}|=\frac{|\Omega|}{7}\in\mathbb Z.  \displaystyle 7\vert |\Omega| 11 n_{11}| 12\cdot 7 n_{11}\equiv 1\pmod {11} n_{11}=1 n_{11}=12 |\Omega|=11-1=10 |\Omega|=12\cdot (11-1)=12\cdot 10=120 7 10 7 120","['abstract-algebra', 'group-theory', 'proof-verification']"
41,How in general does one construct a cycle graph for a group?,How in general does one construct a cycle graph for a group?,,"I think I know how to interpret a cycle graph for a group, but I don’t know how to construct one. In particular, I don’t know a general rule of how to find the “basic elements” which to take the powers of. Is there a general algorithm for constructing the cycle graph of a finite group, which always ensures that you get the correct unique cycle graph?","I think I know how to interpret a cycle graph for a group, but I don’t know how to construct one. In particular, I don’t know a general rule of how to find the “basic elements” which to take the powers of. Is there a general algorithm for constructing the cycle graph of a finite group, which always ensures that you get the correct unique cycle graph?",,"['abstract-algebra', 'group-theory', 'graph-theory', 'finite-groups']"
42,Is the intersection of Frattini subgroup and a Sylow subgroup contained in the Frattini subgroup of the Sylow subgroup?,Is the intersection of Frattini subgroup and a Sylow subgroup contained in the Frattini subgroup of the Sylow subgroup?,,"Suppose $G$ is a finite group, $P$ is a Sylow p-subgroup of $G$ . Is it always true, that $\Phi(G) \cap P$ is a subgroup of $\Phi(P)$ ? Here $\Phi(G)$ is the Frattini subgroup of $G$ . I managed to solve the problem for the following cases: $P \cong C_{p^n}$ for some $n$ . Then, because if $p\mid |G|$ , then $p\mid |G/\Phi(G)|$ , $\Phi(G) \cap P \cong C_{p^m}$ , where $m < n$ . Thus it is a subgroup of $\Phi(P)$ . $G$ is nilpotent. Then $G$ is the direct product of its Slow subgroups: $G = Syl_{p_1}(G) \times … \times Syl_{p_n}(G)$ . Thus $\Phi(G) = \Phi(Syl_{p_1}(G))\times … \times \Phi(Syl_{p_n}(G))$ . And that means $\Phi(G) \cap P = \Phi(P)$ However, I do not know, how to solve this problem in general.","Suppose is a finite group, is a Sylow p-subgroup of . Is it always true, that is a subgroup of ? Here is the Frattini subgroup of . I managed to solve the problem for the following cases: for some . Then, because if , then , , where . Thus it is a subgroup of . is nilpotent. Then is the direct product of its Slow subgroups: . Thus . And that means However, I do not know, how to solve this problem in general.",G P G \Phi(G) \cap P \Phi(P) \Phi(G) G P \cong C_{p^n} n p\mid |G| p\mid |G/\Phi(G)| \Phi(G) \cap P \cong C_{p^m} m < n \Phi(P) G G G = Syl_{p_1}(G) \times … \times Syl_{p_n}(G) \Phi(G) = \Phi(Syl_{p_1}(G))\times … \times \Phi(Syl_{p_n}(G)) \Phi(G) \cap P = \Phi(P),"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory', 'frattini-subgroup']"
43,Showing that $F$ is not representable [closed],Showing that  is not representable [closed],F,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question As I'm trying to find (counter)examples of representable functors, I tried looking up some instructive examples. One of the counterexamples I'm having trouble with, is the following: Show that the functor $$ F:CRings \rightarrow Sets: R \mapsto \left\{r^2 \rvert r \in R\right\}$$ is not representable. Any help is appreciated :)","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question As I'm trying to find (counter)examples of representable functors, I tried looking up some instructive examples. One of the counterexamples I'm having trouble with, is the following: Show that the functor is not representable. Any help is appreciated :)", F:CRings \rightarrow Sets: R \mapsto \left\{r^2 \rvert r \in R\right\},"['abstract-algebra', 'commutative-algebra', 'category-theory', 'functors', 'representable-functor']"
44,Finding a homomorphism between groups with a given kernel,Finding a homomorphism between groups with a given kernel,,"What is a homomorphism defined on the group of invertible upper-triangular $3\times 3$ matrices whose kernel consists of matrices $\begin{bmatrix} 1 & 0 & a \\ 0 & 1 & 0 \\ 0 &0 & 1\end{bmatrix}$ ? I want to use this to study the quotient group, also is there always a way to find a group homomorphism, once the kernel is given and one the group is known in general ? What changes when the diagonal entries in the group of upper triangular matrices are all equal to one . I prefer a correct answer as much as easy to follow explanation, because my backgroud in algebra does not go beyond ""first abstract algebra course"" Thank you.","What is a homomorphism defined on the group of invertible upper-triangular matrices whose kernel consists of matrices ? I want to use this to study the quotient group, also is there always a way to find a group homomorphism, once the kernel is given and one the group is known in general ? What changes when the diagonal entries in the group of upper triangular matrices are all equal to one . I prefer a correct answer as much as easy to follow explanation, because my backgroud in algebra does not go beyond ""first abstract algebra course"" Thank you.",3\times 3 \begin{bmatrix} 1 & 0 & a \\ 0 & 1 & 0 \\ 0 &0 & 1\end{bmatrix},"['abstract-algebra', 'group-theory']"
45,Proving the number of commuting pairs of elements in $G$ equals number of conjugacy classes in $G$ times $|G|$,Proving the number of commuting pairs of elements in  equals number of conjugacy classes in  times,G G |G|,"Let $G$ be a finite group. Let $N$ be the number of conjugacy classes of $G$ . Prove that the number of all pairs $\left(a,b\right)\in G \times G$ satisfying $ab = ba$ is $N \cdot \left|G\right|$ . The first part of this problem asks to describe $\operatorname{Hom}(\mathbb{Z}^2,G)$ as a subset of $G \times G$ which turned out that $\operatorname{Hom}(\mathbb{Z}^2,G)$ is the set of pairs of elements which commute in G. Now, I am trying to understand, and later show the fact that $\#\operatorname{Hom}(\mathbb{Z}^2,G) = \#G \cdot N$ where $N$ is the number of orbits of the group action of conjugation by $G$ on itself. My first guess was to try constructing a bijection between the two sides of the equality but I am having a hard time understanding $\#G \cdot N$ as a set. Is this a correct approach?","Let be a finite group. Let be the number of conjugacy classes of . Prove that the number of all pairs satisfying is . The first part of this problem asks to describe as a subset of which turned out that is the set of pairs of elements which commute in G. Now, I am trying to understand, and later show the fact that where is the number of orbits of the group action of conjugation by on itself. My first guess was to try constructing a bijection between the two sides of the equality but I am having a hard time understanding as a set. Is this a correct approach?","G N G \left(a,b\right)\in G \times G ab = ba N \cdot \left|G\right| \operatorname{Hom}(\mathbb{Z}^2,G) G \times G \operatorname{Hom}(\mathbb{Z}^2,G) \#\operatorname{Hom}(\mathbb{Z}^2,G) = \#G \cdot N N G \#G \cdot N","['abstract-algebra', 'group-theory', 'group-actions']"
46,"If $A\cong B$, then $A\otimes C\cong B\otimes C$.","If , then .",A\cong B A\otimes C\cong B\otimes C,"I think this is kind of true, since $\square\otimes C$ is a functor, so it preserves the isomorphism. But what if we consider the example, $\mathbb{Z}\otimes\mathbb{Z}_2$ is not isomorphic to $2\mathbb{Z}\otimes\mathbb{Z}_2$ . Because the latter is trivial while the first is not. We can also consider the exact sequences: $$0\to\mathbb{Z}\to\mathbb{Z}\to\mathbb{Z}_2\to0,$$ where the first map is simply multiple by 2, and $$0\to2\mathbb{Z}\to\mathbb{Z}\to\mathbb{Z}_2\to0,$$ where the first map is the inclusion. If we tensor by $\mathbb{Z}_2$ we will get $$\mathbb{Z}_2\to\mathbb{Z}_2\to\mathbb{Z}_2\to0$$ and $$(0\to)X\to\mathbb{Z}_2\to\mathbb{Z}_2\to0$$ respectively. Apparently, the first one is the famous counterexample of non-left-exactness of tensor product. But the second one we just inject a submodule (ideal) to the whole module (ring). If $r\otimes m$ is 0 in $\mathbb{Z}\otimes\mathbb{Z}_2$ , then apparently it is 0 in $2\mathbb{Z}\otimes\mathbb{Z}_2$ . So we have the left exactness of the tensor product. This is again weird, since the two exact sequences are isomorphic (by wiki), why do I have different result?","I think this is kind of true, since is a functor, so it preserves the isomorphism. But what if we consider the example, is not isomorphic to . Because the latter is trivial while the first is not. We can also consider the exact sequences: where the first map is simply multiple by 2, and where the first map is the inclusion. If we tensor by we will get and respectively. Apparently, the first one is the famous counterexample of non-left-exactness of tensor product. But the second one we just inject a submodule (ideal) to the whole module (ring). If is 0 in , then apparently it is 0 in . So we have the left exactness of the tensor product. This is again weird, since the two exact sequences are isomorphic (by wiki), why do I have different result?","\square\otimes C \mathbb{Z}\otimes\mathbb{Z}_2 2\mathbb{Z}\otimes\mathbb{Z}_2 0\to\mathbb{Z}\to\mathbb{Z}\to\mathbb{Z}_2\to0, 0\to2\mathbb{Z}\to\mathbb{Z}\to\mathbb{Z}_2\to0, \mathbb{Z}_2 \mathbb{Z}_2\to\mathbb{Z}_2\to\mathbb{Z}_2\to0 (0\to)X\to\mathbb{Z}_2\to\mathbb{Z}_2\to0 r\otimes m \mathbb{Z}\otimes\mathbb{Z}_2 2\mathbb{Z}\otimes\mathbb{Z}_2","['abstract-algebra', 'modules']"
47,Finite dimensional irreducible representations of a semisimple Lie Algebra separate points of the universal enveloping algebra.,Finite dimensional irreducible representations of a semisimple Lie Algebra separate points of the universal enveloping algebra.,,"Let $\mathfrak{g}$ be a semisimple Lie Algebra, and $U(\mathfrak g)$ the universal enveloping algebra . We know that for every representation $\rho: \mathfrak g \to \mathfrak{gl}(V)$ , there exists a representation $\tilde{\rho} : U(\mathfrak g) \to \mathfrak{gl}(V)$ , such that $\rho = \tilde{\rho} \circ \iota$ , where $\iota: \mathfrak g \to U(\mathfrak g)$ is the natural inclusion. Besides that, using the standard notations, $\tilde{\rho}(X_1 \cdot \ldots\cdot X_n) = \rho(X_1) \ldots \rho(X_n).$ I'm very stuck in this problem Question: Show that the finite dimensional irreducible representations of a semisimple Lie Algebra $\mathfrak g$ separate points of the universal algebra $U(\mathfrak g)$ , i.e; if $a \in U(\mathfrak g)$ satisfies $\tilde{\rho}(a) =0$ , for every irreducible  representation $\rho: \mathfrak g \to \mathfrak{gl}(V)$ , then $a=0$ . Can anyone help me?","Let be a semisimple Lie Algebra, and the universal enveloping algebra . We know that for every representation , there exists a representation , such that , where is the natural inclusion. Besides that, using the standard notations, I'm very stuck in this problem Question: Show that the finite dimensional irreducible representations of a semisimple Lie Algebra separate points of the universal algebra , i.e; if satisfies , for every irreducible  representation , then . Can anyone help me?",\mathfrak{g} U(\mathfrak g) \rho: \mathfrak g \to \mathfrak{gl}(V) \tilde{\rho} : U(\mathfrak g) \to \mathfrak{gl}(V) \rho = \tilde{\rho} \circ \iota \iota: \mathfrak g \to U(\mathfrak g) \tilde{\rho}(X_1 \cdot \ldots\cdot X_n) = \rho(X_1) \ldots \rho(X_n). \mathfrak g U(\mathfrak g) a \in U(\mathfrak g) \tilde{\rho}(a) =0 \rho: \mathfrak g \to \mathfrak{gl}(V) a=0,"['abstract-algebra', 'lie-algebras', 'semisimple-lie-algebras']"
48,Are there any non-orientable integral domains?,Are there any non-orientable integral domains?,,"Let $R$ be an integral domain. Let $R_0=R-\{0\}$ and $R^*$ be the unit group of $R$. An orientation of $R$ (my terminology) is a submonoid $N\subseteq R_0$ which intersects each associate equivalence class at exactly one point. That is, if $x\sim y$ (i.e. $x=uy$ for some $u\in R^*$) where $x,y\in N$ then $x=y$, and if $x\in R_0$ then there exists $y\in N$ such that $x\sim y$. For example, $\Bbb Z^+$ is an orientation of $\Bbb Z$, and if $k$ is a field then the set of monic polynomials is an orientation of $k[X]$. Does every integral domain have an orientation? For PIDs, the answer is yes: For each prime ideal $P$, pick a prime generator $P=(p)$, and let $N$ be the set of products of these generators. Since $R$ is a UFD, no two distinct products can be associate, and moreover if $x\in R_0$ then $x$ is a product of primes, and for each prime $q_i$, if $p_i$ is the chosen generator of $(q_i)$ then $p_i\sim q_i$ so $x$ is associate to $\sum_ip_i$. There are non-orientable commutative rings that are not integral domains. For example, in $\Bbb Z/6\Bbb Z$, there are only two units, so every square must be in $N$ (since either $x\in N$ or $-x\in N$ implies $x^2\in N$), so the only possible structure is $\{1,3,4\}$; but $3\cdot 4=0$ so this is not a submonoid.","Let $R$ be an integral domain. Let $R_0=R-\{0\}$ and $R^*$ be the unit group of $R$. An orientation of $R$ (my terminology) is a submonoid $N\subseteq R_0$ which intersects each associate equivalence class at exactly one point. That is, if $x\sim y$ (i.e. $x=uy$ for some $u\in R^*$) where $x,y\in N$ then $x=y$, and if $x\in R_0$ then there exists $y\in N$ such that $x\sim y$. For example, $\Bbb Z^+$ is an orientation of $\Bbb Z$, and if $k$ is a field then the set of monic polynomials is an orientation of $k[X]$. Does every integral domain have an orientation? For PIDs, the answer is yes: For each prime ideal $P$, pick a prime generator $P=(p)$, and let $N$ be the set of products of these generators. Since $R$ is a UFD, no two distinct products can be associate, and moreover if $x\in R_0$ then $x$ is a product of primes, and for each prime $q_i$, if $p_i$ is the chosen generator of $(q_i)$ then $p_i\sim q_i$ so $x$ is associate to $\sum_ip_i$. There are non-orientable commutative rings that are not integral domains. For example, in $\Bbb Z/6\Bbb Z$, there are only two units, so every square must be in $N$ (since either $x\in N$ or $-x\in N$ implies $x^2\in N$), so the only possible structure is $\{1,3,4\}$; but $3\cdot 4=0$ so this is not a submonoid.",,"['abstract-algebra', 'ring-theory', 'integral-domain']"
49,Logarithmic height of algebraic numbers,Logarithmic height of algebraic numbers,,Let $a$ and $b$ algebraic numbers over $\mathbb{Q}$. Do you know (or recall) if there are simple uppper bounds relating the logarithmic height of $ab$  (or $a/b$) with the logarithmic height of $a$ and the logarithmic height of $b$? With logarithmic height of $a$ I mean here the logarithm of the absolute value of the largest (in the sense of absolute value) coefficient of the minimal polynomial of $a$. Thanks for your answers.,Let $a$ and $b$ algebraic numbers over $\mathbb{Q}$. Do you know (or recall) if there are simple uppper bounds relating the logarithmic height of $ab$  (or $a/b$) with the logarithmic height of $a$ and the logarithmic height of $b$? With logarithmic height of $a$ I mean here the logarithm of the absolute value of the largest (in the sense of absolute value) coefficient of the minimal polynomial of $a$. Thanks for your answers.,,"['abstract-algebra', 'number-theory', 'reference-request', 'algebraic-number-theory', 'arithmetic-geometry']"
50,Homomorphisms from $\mathbb Q$ to a finitely generated abelian group,Homomorphisms from  to a finitely generated abelian group,\mathbb Q,"Let $G$ be a finitely generated abelian group. Prove that there is no non-trivial homomophism from $\mathbb Q$ to $G$. I believe this has to do with divisibility. $\mathbb Q$ is divisible. The image of it under a group homomorphism must be divisible. If $G$ were finite, this would imply that the image is the trivial subgroup since any divisible finite group is trivial. But $G$ is not necessarily finite. What should the argument be like instead?","Let $G$ be a finitely generated abelian group. Prove that there is no non-trivial homomophism from $\mathbb Q$ to $G$. I believe this has to do with divisibility. $\mathbb Q$ is divisible. The image of it under a group homomorphism must be divisible. If $G$ were finite, this would imply that the image is the trivial subgroup since any divisible finite group is trivial. But $G$ is not necessarily finite. What should the argument be like instead?",,"['abstract-algebra', 'group-theory', 'group-homomorphism']"
51,"Homomorphisms between a finite group and $(\mathbb R,+)$",Homomorphisms between a finite group and,"(\mathbb R,+)","I'm trying to prove that any homomorphism from a finite group to $(\mathbb R,+)$ and from $(\mathbb R,+)$ to a finite group must be trivial. What I have so far: let $G$ be a finite group and $f: G\to \mathbb R$ a homomorphism. Since $G$ is finite, for every element $x\in G$ there is a positive $n$ such that $x^n=e$. Then $0=f(e)=f(x^n)=f(x)\cdot n\implies f(x)=0$. So $f$ is trivial. Is that correct? For the other statement, that's what I have (not sure if it's the right direction). Let $f: \mathbb R\to G$ be a homomorphism. Let $a=f(1)$. Since $G$ is finite, $a^n=e$ for $n\in \mathbb N$. Then $e=a^n=[f(1)]^n=f(n)$. This implies $f(n\mathbb Z)=e$. is this helpful at all?","I'm trying to prove that any homomorphism from a finite group to $(\mathbb R,+)$ and from $(\mathbb R,+)$ to a finite group must be trivial. What I have so far: let $G$ be a finite group and $f: G\to \mathbb R$ a homomorphism. Since $G$ is finite, for every element $x\in G$ there is a positive $n$ such that $x^n=e$. Then $0=f(e)=f(x^n)=f(x)\cdot n\implies f(x)=0$. So $f$ is trivial. Is that correct? For the other statement, that's what I have (not sure if it's the right direction). Let $f: \mathbb R\to G$ be a homomorphism. Let $a=f(1)$. Since $G$ is finite, $a^n=e$ for $n\in \mathbb N$. Then $e=a^n=[f(1)]^n=f(n)$. This implies $f(n\mathbb Z)=e$. is this helpful at all?",,"['abstract-algebra', 'group-theory', 'group-homomorphism']"
52,Understanding Gauss's product formula as cited in Golomb's Shift Register Sequences,Understanding Gauss's product formula as cited in Golomb's Shift Register Sequences,,"In his book Shift Register Sequences , Solomon Golomb refers to ""Gauss's product formula"" : The basic device here is “Gauss's product formula” [39] which expresses the “product” of any two cosets as a sum of cosets. (This ""product"" is in terms of evaluation with 1's and 0's. It has nothing to do with multiplication in the factor group.) I'm completely lost. What is he talking about? The cosets here in Golomb's example are cyclotomic cosets $\bmod 2^N - 1$ for $N=5$, with $$\begin{align} C_0 &= \{1,2,4,8,16\} \cr C_1 &= \{3,6,12,24,17\} \cr C_2 &= \{9,18,5,10,20\} \cr C_3 &= \{27,23,15,30,29\} \cr C_4 &= \{19,7,14,28,25\} \cr C_5 &= \{26,21,11,22,13\} \end{align}$$ I understand what these cosets are (elements in the same coset are produced by multiplying by powers of 2, $\bmod 2^N-1$), but how can you possibly ""multiply"" or ""add"" them, and write equations regarding $C_iC_j$?","In his book Shift Register Sequences , Solomon Golomb refers to ""Gauss's product formula"" : The basic device here is “Gauss's product formula” [39] which expresses the “product” of any two cosets as a sum of cosets. (This ""product"" is in terms of evaluation with 1's and 0's. It has nothing to do with multiplication in the factor group.) I'm completely lost. What is he talking about? The cosets here in Golomb's example are cyclotomic cosets $\bmod 2^N - 1$ for $N=5$, with $$\begin{align} C_0 &= \{1,2,4,8,16\} \cr C_1 &= \{3,6,12,24,17\} \cr C_2 &= \{9,18,5,10,20\} \cr C_3 &= \{27,23,15,30,29\} \cr C_4 &= \{19,7,14,28,25\} \cr C_5 &= \{26,21,11,22,13\} \end{align}$$ I understand what these cosets are (elements in the same coset are produced by multiplying by powers of 2, $\bmod 2^N-1$), but how can you possibly ""multiply"" or ""add"" them, and write equations regarding $C_iC_j$?",,"['abstract-algebra', 'finite-fields']"
53,Burnside's transfer theorem in group theory,Burnside's transfer theorem in group theory,,"While reading this I read the following (slightly rephrased, and edited according to comments) : ""Burnside's transfer theorem : If a $p$ -Sylow subgroup $P$ of a finite group $G$ is included in its normalizer's center, i.e. $P \leq Z(N_G(P))$ , then there is a normal subgroup $N$ of order $|G|/|P|$ such that $P \cap N = 1$ , and $G = N  \rtimes P$ "" What is the proof and/or applications (within pure math) of the above theorem other than classification of group of order 30? You are welcome to just provide a link. I wasn't able to find one online.","While reading this I read the following (slightly rephrased, and edited according to comments) : ""Burnside's transfer theorem : If a -Sylow subgroup of a finite group is included in its normalizer's center, i.e. , then there is a normal subgroup of order such that , and "" What is the proof and/or applications (within pure math) of the above theorem other than classification of group of order 30? You are welcome to just provide a link. I wasn't able to find one online.",p P G P \leq Z(N_G(P)) N |G|/|P| P \cap N = 1 G = N  \rtimes P,"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory']"
54,Exercise about primes in the ring of Gaussian integers,Exercise about primes in the ring of Gaussian integers,,"Let $p$ be a prime in $\mathbb{Z}$ of the form $4n + 1, n \in \mathbb{N}$. Show that $\left(\frac{-1}{p}\right) = 1$ (here $\left(\frac{\#}{p}\right)$ is the Legendre symbol). Hence prove that $p$ is not a prime in the ring $\mathbb{Z}[i]$. Here is my solution: Since $p > 2$, we have $\left(\frac{-1}{p}\right) = 1$ if and only if $(-1)^{\frac{p - 1}{2}} \equiv_p 1$ if and only $(-1)^{2n} \equiv_p 1$ which is true. Now suppose $p$ is prime in $\mathbb{Z}[i]$, which means that there exists $x \in \mathbb{Z}$ such that $-1 \equiv_p x^2$, from which $p \mid (x^2 + 1) = (x - i)(x + i)$ and, since $p$ is prime, $p \mid (x - i)$ or $p \mid (x + i)$. In either case we have $m + ni \in \mathbb{Z}[i]$ such that $p(m + ni) = x \pm i$, which implies $pn = x$, that is $p \mid x$, and $x^2 + 1 \equiv_p 1$, which is not congruent to $0$, contradiction. Is it correct? thanks in advance Edit: (I've tried to write it better using Robert Soupe advice) Since $p>2$ we have $(-1)^{(p-1)/2}\equiv_p (-1)^{2n} \equiv_p 1$, that is $\left(\frac{-1}{p} \right)= 1$. Now suppose $p$ is prime in $\mathbb{Z}[i]$, this means that there exists $x \in \mathbb{Z}$ such that $x^2 \equiv_p -1$, hence $p \mid (x^2 + 1) = (x - i)(x + i)$ and, since $p$ is prime, $p \mid (x + i)$. Therefore there exists $m + ni \in \mathbb{Z}[i]$ such that $p(m + ni) = x + i$, but this is absurd because $p$ does not divide $1$. We can conclude that $p$ is not prime in $\mathbb{Z}[i]$.","Let $p$ be a prime in $\mathbb{Z}$ of the form $4n + 1, n \in \mathbb{N}$. Show that $\left(\frac{-1}{p}\right) = 1$ (here $\left(\frac{\#}{p}\right)$ is the Legendre symbol). Hence prove that $p$ is not a prime in the ring $\mathbb{Z}[i]$. Here is my solution: Since $p > 2$, we have $\left(\frac{-1}{p}\right) = 1$ if and only if $(-1)^{\frac{p - 1}{2}} \equiv_p 1$ if and only $(-1)^{2n} \equiv_p 1$ which is true. Now suppose $p$ is prime in $\mathbb{Z}[i]$, which means that there exists $x \in \mathbb{Z}$ such that $-1 \equiv_p x^2$, from which $p \mid (x^2 + 1) = (x - i)(x + i)$ and, since $p$ is prime, $p \mid (x - i)$ or $p \mid (x + i)$. In either case we have $m + ni \in \mathbb{Z}[i]$ such that $p(m + ni) = x \pm i$, which implies $pn = x$, that is $p \mid x$, and $x^2 + 1 \equiv_p 1$, which is not congruent to $0$, contradiction. Is it correct? thanks in advance Edit: (I've tried to write it better using Robert Soupe advice) Since $p>2$ we have $(-1)^{(p-1)/2}\equiv_p (-1)^{2n} \equiv_p 1$, that is $\left(\frac{-1}{p} \right)= 1$. Now suppose $p$ is prime in $\mathbb{Z}[i]$, this means that there exists $x \in \mathbb{Z}$ such that $x^2 \equiv_p -1$, hence $p \mid (x^2 + 1) = (x - i)(x + i)$ and, since $p$ is prime, $p \mid (x + i)$. Therefore there exists $m + ni \in \mathbb{Z}[i]$ such that $p(m + ni) = x + i$, but this is absurd because $p$ does not divide $1$. We can conclude that $p$ is not prime in $\mathbb{Z}[i]$.",,"['abstract-algebra', 'group-theory', 'proof-writing', 'prime-numbers', 'gaussian-integers']"
55,"Does there exist non trivial group homomorphism from $S_3$ to ( $\mathbb Q $,+)","Does there exist non trivial group homomorphism from  to ( ,+)",S_3 \mathbb Q ,"Let $G = S_3$ be the permutatiin group of 3 symbols.Then $G$ is isomorphic to a subgroup of a cyclic group There exists a cyclic group $H$ such that $G$ maps homomorphically onto $H$. $G$ is a product of cyclic groups there exists a nontrivial group homomorphism from $G$ to the additive group  ($\mathbb Q $,+) of rational numbers 1 option is clearly false since subgroup of a cyclic group is again cyclic and $G$ can't be isomorphic to a cyclic group 2 option  is true since there is an epimorphism from $G$ onto $\mathbb Z_2 $ 3 option  is false since $G$ is non commutative Now I only get trivial homomorphism from $G$ to additive group of rational numbers. So option 4 is false. Am I right?","Let $G = S_3$ be the permutatiin group of 3 symbols.Then $G$ is isomorphic to a subgroup of a cyclic group There exists a cyclic group $H$ such that $G$ maps homomorphically onto $H$. $G$ is a product of cyclic groups there exists a nontrivial group homomorphism from $G$ to the additive group  ($\mathbb Q $,+) of rational numbers 1 option is clearly false since subgroup of a cyclic group is again cyclic and $G$ can't be isomorphic to a cyclic group 2 option  is true since there is an epimorphism from $G$ onto $\mathbb Z_2 $ 3 option  is false since $G$ is non commutative Now I only get trivial homomorphism from $G$ to additive group of rational numbers. So option 4 is false. Am I right?",,"['abstract-algebra', 'group-theory', 'rational-numbers', 'cyclic-groups', 'group-homomorphism']"
56,Completion commutes with finite direct sums,Completion commutes with finite direct sums,,"I have been reading a couple of different places, that completion of module (or the $I$-adic completion to be more exact) commutes with finite direct sums. I was told, that it follows from the fact, that completion is an additive functor, but as I haven't worked with functors before, that doesn't make much sense to me, and I was wondering if it could be proven in another way (maybe from using the definition of completion only). I've been trying to work it around my self, but doesn't seem to get anywhere.","I have been reading a couple of different places, that completion of module (or the $I$-adic completion to be more exact) commutes with finite direct sums. I was told, that it follows from the fact, that completion is an additive functor, but as I haven't worked with functors before, that doesn't make much sense to me, and I was wondering if it could be proven in another way (maybe from using the definition of completion only). I've been trying to work it around my self, but doesn't seem to get anywhere.",,"['abstract-algebra', 'commutative-algebra']"
57,Is the image of $\Phi_n(x) \in \mathbb{Z}[x]$ in $\mathbb{F}_q[x]$ still a cyclotomic polynomial?,Is the image of  in  still a cyclotomic polynomial?,\Phi_n(x) \in \mathbb{Z}[x] \mathbb{F}_q[x],"Let $\Phi_n(x) \in \mathbb{Z}[x]$ denote the $n$-th cyclotomic polynomial, and let $\mathbb{F}_q$ be the finite field with $p^k = q$ elements ($p$ prime). Let $\Phi'_n(x)$ be the reduction of $\Phi_n(x)$ mod $p$ (i.e., $\Phi'_n(x)$ is the image of $\Phi_n(x)$ in $\mathbb{F}_q[x]$). Is it true that $\Phi'_n(x)$ is the $n$-th cyclotomic polynomial in $\mathbb{F}_q$; that is, are the roots of $\Phi_n'(x)$ precisely the primitive $n$-th roots of unity in $\mathbb{F}_q$? If so, I want to prove this is the case, but I'm not sure how I'd go about doing this.","Let $\Phi_n(x) \in \mathbb{Z}[x]$ denote the $n$-th cyclotomic polynomial, and let $\mathbb{F}_q$ be the finite field with $p^k = q$ elements ($p$ prime). Let $\Phi'_n(x)$ be the reduction of $\Phi_n(x)$ mod $p$ (i.e., $\Phi'_n(x)$ is the image of $\Phi_n(x)$ in $\mathbb{F}_q[x]$). Is it true that $\Phi'_n(x)$ is the $n$-th cyclotomic polynomial in $\mathbb{F}_q$; that is, are the roots of $\Phi_n'(x)$ precisely the primitive $n$-th roots of unity in $\mathbb{F}_q$? If so, I want to prove this is the case, but I'm not sure how I'd go about doing this.",,"['abstract-algebra', 'galois-theory', 'finite-fields', 'cyclotomic-polynomials']"
58,Precise definition of Dihedral Group,Precise definition of Dihedral Group,,"I am studying "" Abstract Algebra "" written by dummit/foote. In page 23, This book defines the concept of dihedral group as follows: For each n = 3, 4, 5, etc... ,  The set of symmetries of a regular n-gon, where a symmetry is any rigid motion of the n-gon which can be effected by taking a copy back on the original n-gon so it exaclty covers it. I can understand what it means but I have some curious about this definition because this definition is not rigorous for me. What is the definition of rigid motion? what is copy back? Can we admit this kind of vague terminology in math? I tried to find other book which describing the concept symmetry. In the book "" A first course in Abstract Algebra, this book defines a symmetry of geometrical figure as a rearrangement of the figure preserving the arrangement of its sides and vertices as well as its distance and angles. I thought that this definition is also depending on our intuition... and not rigourous if we compare this with set theory, real analysis, or other mathematical definition... So, In summary... Q1. I understood that symmetry is a transformation which preserves shape, angle, distances... in intuitive meaning Did I understand well? Q2. If I understood well, what is a precise and rigorous definition of symmetry? as we did in set theory, real analysis, etc... Q3. Can we deal geometry by using a precise and rigorous method only using axiom, set, logic ??","I am studying "" Abstract Algebra "" written by dummit/foote. In page 23, This book defines the concept of dihedral group as follows: For each n = 3, 4, 5, etc... ,  The set of symmetries of a regular n-gon, where a symmetry is any rigid motion of the n-gon which can be effected by taking a copy back on the original n-gon so it exaclty covers it. I can understand what it means but I have some curious about this definition because this definition is not rigorous for me. What is the definition of rigid motion? what is copy back? Can we admit this kind of vague terminology in math? I tried to find other book which describing the concept symmetry. In the book "" A first course in Abstract Algebra, this book defines a symmetry of geometrical figure as a rearrangement of the figure preserving the arrangement of its sides and vertices as well as its distance and angles. I thought that this definition is also depending on our intuition... and not rigourous if we compare this with set theory, real analysis, or other mathematical definition... So, In summary... Q1. I understood that symmetry is a transformation which preserves shape, angle, distances... in intuitive meaning Did I understand well? Q2. If I understood well, what is a precise and rigorous definition of symmetry? as we did in set theory, real analysis, etc... Q3. Can we deal geometry by using a precise and rigorous method only using axiom, set, logic ??",,"['abstract-algebra', 'group-theory', 'geometry', 'symmetry']"
59,In what algebraic structure does repeated addition equal multiplication?,In what algebraic structure does repeated addition equal multiplication?,,"I'm trying to figure out for which algebraic structure $$\underbrace{a+a+\cdots+a}_{n \text{-times}} = a * n$$ is true. Now I know the question ' Is all multiplication repeated addition? ' has been asked many times with the answer: NO because you cannot express non-integer (such as fractions or complex numbers) multiples as repeated addition.  However I'm pretty sure that the reverse is true; that ' Repeated addition is always multiplication ' So my first thought was that Rings would be the appropriate algebraic structure for this, seeing that they have both addition and multiplication. However, the definition of a ring does not mention this property. So I was thinking about this property and it seems like it holds for many rings, including the following: Integers Rationals Reals Complex numbers $m\times m$ Matrix Ring Polynomials where multiplication is scaling by a number But... Then I ran into the Boolean ring where $\lor$ is the addition in the ring, and $\land$ is the multiplication. So... $$???\,\,\underbrace{a\lor a\lor\cdots\lor a}_{n \text{-times}} = a \land n \,\,???$$ Now the problem is the type of the entity is totally different (true/false values). This doesn't even make sense; or does it? If this isn't true, then I'm not sure where that leaves me then, since it would imply that this property doesn't hold for rings in general.  But then what does it hold for? Any insight would be greatly apprecitated. :)","I'm trying to figure out for which algebraic structure $$\underbrace{a+a+\cdots+a}_{n \text{-times}} = a * n$$ is true. Now I know the question ' Is all multiplication repeated addition? ' has been asked many times with the answer: NO because you cannot express non-integer (such as fractions or complex numbers) multiples as repeated addition.  However I'm pretty sure that the reverse is true; that ' Repeated addition is always multiplication ' So my first thought was that Rings would be the appropriate algebraic structure for this, seeing that they have both addition and multiplication. However, the definition of a ring does not mention this property. So I was thinking about this property and it seems like it holds for many rings, including the following: Integers Rationals Reals Complex numbers $m\times m$ Matrix Ring Polynomials where multiplication is scaling by a number But... Then I ran into the Boolean ring where $\lor$ is the addition in the ring, and $\land$ is the multiplication. So... $$???\,\,\underbrace{a\lor a\lor\cdots\lor a}_{n \text{-times}} = a \land n \,\,???$$ Now the problem is the type of the entity is totally different (true/false values). This doesn't even make sense; or does it? If this isn't true, then I'm not sure where that leaves me then, since it would imply that this property doesn't hold for rings in general.  But then what does it hold for? Any insight would be greatly apprecitated. :)",,"['abstract-algebra', 'ring-theory', 'products']"
60,$\exists g\in G: H\cap gPg^{-1}$ is a Sylow $p-$subgroup of $H$,is a Sylow subgroup of,\exists g\in G: H\cap gPg^{-1} p- H,"Question: If $P$ is a Sylow $p-$subgroup of $G$ and $H\leq G$ with $p||H|$ then $\exists g\in G: H\cap gPg^{-1}$ is a Sylow $p-$subgroup of $H$. Attempt: We consider the action $H\times G/P\to G/P$ with $(h,xP)\to hxP$ and we know that  $$|G/P|=\sum_{x\in S}|[xP]_{H}|=\sum_{x\in S}|H:H\cap xPx^{-1}|$$ since $|[xP]_{H}|=|H:Stab_H(xP)|=|H\cap xPx^{-1}|$. Now, $P$ is a Sylow $p-$subgroup of $G$ so $p\nmid |G/P|=m$ so from above $\exists g\in G:p\nmid |H:H\cap gPg^{-1}|$ If $|H:H\cap gPg^{-1}|\not=1$: we have that $p\nmid |H:H\cap gPg^{-1}|$ and $H\cap gPg^{-1}$is a $p-$subgroup of $H$( please explain this statement ) so $H\cap gPg^{-1}$ is a Sylow $p-$subgroup of $H$. If $|H:H\cap gPg^{-1}|=1$ then $H=H\cap gPg^{-1}\Rightarrow H\leq gPg^{-1}(= $$p-$group) and therefore $H\cap gPg^{-1}$ is a Sylow $p-$subgroup of $H$. Is this proof correct? Is there a quicker way to prove the initial statement?","Question: If $P$ is a Sylow $p-$subgroup of $G$ and $H\leq G$ with $p||H|$ then $\exists g\in G: H\cap gPg^{-1}$ is a Sylow $p-$subgroup of $H$. Attempt: We consider the action $H\times G/P\to G/P$ with $(h,xP)\to hxP$ and we know that  $$|G/P|=\sum_{x\in S}|[xP]_{H}|=\sum_{x\in S}|H:H\cap xPx^{-1}|$$ since $|[xP]_{H}|=|H:Stab_H(xP)|=|H\cap xPx^{-1}|$. Now, $P$ is a Sylow $p-$subgroup of $G$ so $p\nmid |G/P|=m$ so from above $\exists g\in G:p\nmid |H:H\cap gPg^{-1}|$ If $|H:H\cap gPg^{-1}|\not=1$: we have that $p\nmid |H:H\cap gPg^{-1}|$ and $H\cap gPg^{-1}$is a $p-$subgroup of $H$( please explain this statement ) so $H\cap gPg^{-1}$ is a Sylow $p-$subgroup of $H$. If $|H:H\cap gPg^{-1}|=1$ then $H=H\cap gPg^{-1}\Rightarrow H\leq gPg^{-1}(= $$p-$group) and therefore $H\cap gPg^{-1}$ is a Sylow $p-$subgroup of $H$. Is this proof correct? Is there a quicker way to prove the initial statement?",,"['abstract-algebra', 'group-theory', 'proof-verification', 'proof-explanation', 'group-actions']"
61,Galois group of $ X^6-2tX^3+1 $ over $ \mathbb{Q}(t) $,Galois group of  over, X^6-2tX^3+1   \mathbb{Q}(t) ,"As in the question, I am asked to determine the Galois group of $$f(X)= X^6-2tX^3+1 \in \mathbb{Q}(t)[X] $$ over $  \mathbb{Q}(t) $. First, I should prove that $ f $ is irreducible over $ \mathbb{Q}(t) $ and to do this I thought of the poynomial $ g(X)=f(X^\frac{1}{3})=X^2-2tX+1 $ since $ g(X-1)=X^2-2(t+1)X+2(t+1) $ is Eisenstein with respect to the prime element $ 2(t+1) $ of $ \mathbb{Q}[t] $ but I am not sure if this is enough to conclude that $ f $ is irreducible. Furthermore, we have that the splitting field $ L $ of $ f $ over $ \mathbb{Q}(t) $ is $ \mathbb{Q}(\alpha, \omega) $ where $ \alpha $ is a root of $ f $ and $ \omega $ is a primitive third root of unity. Starting from here, I would like to compute the Galois group of $ f $. I would appreciate any help regarding both questions. Thank you!","As in the question, I am asked to determine the Galois group of $$f(X)= X^6-2tX^3+1 \in \mathbb{Q}(t)[X] $$ over $  \mathbb{Q}(t) $. First, I should prove that $ f $ is irreducible over $ \mathbb{Q}(t) $ and to do this I thought of the poynomial $ g(X)=f(X^\frac{1}{3})=X^2-2tX+1 $ since $ g(X-1)=X^2-2(t+1)X+2(t+1) $ is Eisenstein with respect to the prime element $ 2(t+1) $ of $ \mathbb{Q}[t] $ but I am not sure if this is enough to conclude that $ f $ is irreducible. Furthermore, we have that the splitting field $ L $ of $ f $ over $ \mathbb{Q}(t) $ is $ \mathbb{Q}(\alpha, \omega) $ where $ \alpha $ is a root of $ f $ and $ \omega $ is a primitive third root of unity. Starting from here, I would like to compute the Galois group of $ f $. I would appreciate any help regarding both questions. Thank you!",,"['abstract-algebra', 'galois-theory', 'irreducible-polynomials', 'splitting-field']"
62,Difference between Aut(V) and GL(V),Difference between Aut(V) and GL(V),,"In some texts they treat them as the same but in others they seem they would not necessarily be the same. Please correct me in the following. 1) Let V be a vector space of finite dimension n on a field F (not necessarily the real numbers or complex numbers), then Aut(V) = GL(V) (not just isomorphic but equal to each other). 2) What if V has infinite dimension on a field F, is there a difference between Aut(V) and GL(V)? I had this question because for example, if A is a finite-dimensional non-associative algebra over F, the book i am reading just states Aut(A) as a subgroup of GL(A) (screenshot is attached below). They use this fact in here too. I don't think they are referring to a trivial subgroup, so I guess they are not equal to each other for some situations. If GL(V) and Aut(V) are not always the same, could you please state a generalized concept for each of those groups? Thanks in avance!","In some texts they treat them as the same but in others they seem they would not necessarily be the same. Please correct me in the following. 1) Let V be a vector space of finite dimension n on a field F (not necessarily the real numbers or complex numbers), then Aut(V) = GL(V) (not just isomorphic but equal to each other). 2) What if V has infinite dimension on a field F, is there a difference between Aut(V) and GL(V)? I had this question because for example, if A is a finite-dimensional non-associative algebra over F, the book i am reading just states Aut(A) as a subgroup of GL(A) (screenshot is attached below). They use this fact in here too. I don't think they are referring to a trivial subgroup, so I guess they are not equal to each other for some situations. If GL(V) and Aut(V) are not always the same, could you please state a generalized concept for each of those groups? Thanks in avance!",,"['abstract-algebra', 'group-theory']"
63,Should one study number theory before studying abstract algebra?,Should one study number theory before studying abstract algebra?,,"My question is the opposite of the question posted here . I have started studying abstract algebra independently. I'm wondering if it is necessary, or at least advised, to have studied elementary number theory prior to studying abstract algebra, say at the level of Dummit and Foote's Abstract Algebra or Knapp's Basic Algebra .","My question is the opposite of the question posted here . I have started studying abstract algebra independently. I'm wondering if it is necessary, or at least advised, to have studied elementary number theory prior to studying abstract algebra, say at the level of Dummit and Foote's Abstract Algebra or Knapp's Basic Algebra .",,"['abstract-algebra', 'elementary-number-theory', 'soft-question']"
64,"In a normal extension of a field, is there an automorphism that maps irreducible factors of a certain irreducible polynomial? [duplicate]","In a normal extension of a field, is there an automorphism that maps irreducible factors of a certain irreducible polynomial? [duplicate]",,"This question already has an answer here : If $F/k$ normal, $g,h \in F[X]$ monic irreducible factors of $f \in k[X]$, then $\exists\ \sigma \in Aut(F/k)$ s.t. $g^\sigma = h$. (1 answer) Closed 5 years ago . Let $F$ be a field, $f(x)$ be an irreducible polynomial in $F[x]$ and $E/F$ be a normal extension. Show that if $g(x)$, $h(x)$ are irreducible factors of $f(x)$ in $E[x]$ then there exists an automorphism $\sigma$ of $E$ over $F$ such that $\sigma(g)=h$. Does this result hold if we do not assume normal extension? What I've tried so far: Let $\overline{F}$ be the algebraic closure of $F$. Then, by definition, $f(x)\in F[x]$ splits completely over $\overline{F}$. So $$f(x)=(x-\alpha_1)\cdots(x-\alpha_n)(x-\beta_1)\cdots(x-\beta_m) (x-\gamma_1)\cdots(x-\gamma_k)$$ Since $g(x)$ and $h(x)$ are irreducible factors of $f(x)\in E[x]$ then we can write, without loss of generality, $n\leq m$ and $$g(x)=(x-\alpha_1)\cdots(x-\alpha_n)\qquad h(x)=(x-\beta_1)\cdots(x-\beta_m)$$ I want to define a map $\sigma:E\rightarrow E$ which maps $\alpha_i$ to $\beta_i$ (with this I can conclude $\sigma(g)=h$, right?). But the problems are: 1) I don't know $n=m$. 2) I don't know $\alpha_i,\beta_i\in E$. 3) Even if $\alpha_i,\beta_i\in E$, I'd only have a map on a subset of $E$. I don't know if I can extend this map to the whole $E$. EDIT: The question above can be found on Serge Lang's Algebra, Revised Third Edition, Volme 1, Chapter V, exercise 26, and is stated as: Let $k$ be a field, $f(X)$ an irreducible polynomial in $k[X]$, and   let $K$ be a finite normal extension of $k$. If $g$, $h$ are monic   irreducible factors of $f(X)$ in $K[X]$, show that there exists an   automorphism $\sigma$ of $K$ over $k$ such that $\sigma = h^\sigma$.   Give an example when this conclusion is not valid if $K$ is not normal   over $k$.","This question already has an answer here : If $F/k$ normal, $g,h \in F[X]$ monic irreducible factors of $f \in k[X]$, then $\exists\ \sigma \in Aut(F/k)$ s.t. $g^\sigma = h$. (1 answer) Closed 5 years ago . Let $F$ be a field, $f(x)$ be an irreducible polynomial in $F[x]$ and $E/F$ be a normal extension. Show that if $g(x)$, $h(x)$ are irreducible factors of $f(x)$ in $E[x]$ then there exists an automorphism $\sigma$ of $E$ over $F$ such that $\sigma(g)=h$. Does this result hold if we do not assume normal extension? What I've tried so far: Let $\overline{F}$ be the algebraic closure of $F$. Then, by definition, $f(x)\in F[x]$ splits completely over $\overline{F}$. So $$f(x)=(x-\alpha_1)\cdots(x-\alpha_n)(x-\beta_1)\cdots(x-\beta_m) (x-\gamma_1)\cdots(x-\gamma_k)$$ Since $g(x)$ and $h(x)$ are irreducible factors of $f(x)\in E[x]$ then we can write, without loss of generality, $n\leq m$ and $$g(x)=(x-\alpha_1)\cdots(x-\alpha_n)\qquad h(x)=(x-\beta_1)\cdots(x-\beta_m)$$ I want to define a map $\sigma:E\rightarrow E$ which maps $\alpha_i$ to $\beta_i$ (with this I can conclude $\sigma(g)=h$, right?). But the problems are: 1) I don't know $n=m$. 2) I don't know $\alpha_i,\beta_i\in E$. 3) Even if $\alpha_i,\beta_i\in E$, I'd only have a map on a subset of $E$. I don't know if I can extend this map to the whole $E$. EDIT: The question above can be found on Serge Lang's Algebra, Revised Third Edition, Volme 1, Chapter V, exercise 26, and is stated as: Let $k$ be a field, $f(X)$ an irreducible polynomial in $k[X]$, and   let $K$ be a finite normal extension of $k$. If $g$, $h$ are monic   irreducible factors of $f(X)$ in $K[X]$, show that there exists an   automorphism $\sigma$ of $K$ over $k$ such that $\sigma = h^\sigma$.   Give an example when this conclusion is not valid if $K$ is not normal   over $k$.",,"['abstract-algebra', 'galois-theory']"
65,Definition of split chain complex,Definition of split chain complex,,"I'm trying to reconcile two definitions in homological algebra. One of them is standard and the other is found in Weibel's Homological Algebra (so probably also standard, but I can't say from my own experience.) First, an exact sequence $0\to A\to B\to C\to 0$ in an abelian category is split if any of the following equivalent conditions hold: the map $A\to B$ has a section, the map $B\to C$ has a retract, $B=A\oplus C'$ for some subobject $C'$ of $B$, and $B=A'\oplus C$ for some quotient object $A'$ of $B$. Second, Weibel defines a chain complex $C_\bullet$ to be split if there are maps $s_n:C_n\to C_{n+1}$ such that $d_{n+1}s_nd_{n+1}=d_{n+1}$. Such a chain complex has very nice properties: the maps $s_n$ induce splittings of $C_n$ and $Z_n(C_\bullet)$. Although Weibel's definition has nice properties, it comes from nowhere.  Is there some way to view his definition as a particular case of the first? It seems like if you just constructed the right short exact sequence of chain complexes, perhaps something involving a shifted complex like $C[-1]_\bullet$, then these two definitions could be reconciled. I can't see how to do it, though.","I'm trying to reconcile two definitions in homological algebra. One of them is standard and the other is found in Weibel's Homological Algebra (so probably also standard, but I can't say from my own experience.) First, an exact sequence $0\to A\to B\to C\to 0$ in an abelian category is split if any of the following equivalent conditions hold: the map $A\to B$ has a section, the map $B\to C$ has a retract, $B=A\oplus C'$ for some subobject $C'$ of $B$, and $B=A'\oplus C$ for some quotient object $A'$ of $B$. Second, Weibel defines a chain complex $C_\bullet$ to be split if there are maps $s_n:C_n\to C_{n+1}$ such that $d_{n+1}s_nd_{n+1}=d_{n+1}$. Such a chain complex has very nice properties: the maps $s_n$ induce splittings of $C_n$ and $Z_n(C_\bullet)$. Although Weibel's definition has nice properties, it comes from nowhere.  Is there some way to view his definition as a particular case of the first? It seems like if you just constructed the right short exact sequence of chain complexes, perhaps something involving a shifted complex like $C[-1]_\bullet$, then these two definitions could be reconciled. I can't see how to do it, though.",,"['abstract-algebra', 'definition', 'homological-algebra']"
66,$G$ is abelian iff all the Sylow subgroups of $G$ are normal,is abelian iff all the Sylow subgroups of  are normal,G G,"Here $p_{i}$ ’s are distinct primes and $O(G) = p_{1}^{2} \dotsm p_{n}^{2}$ . Then we need to show that $G$ is abelian if and only if all the Sylow subgroups of $G$ are normal. How to solve this question? Also a little modification to the above leads to a different scenario as $O(G) = p_{1} \cdot p_{2} \cdot p_{3} \cdot\dots\cdot p_{n}$ , $G$ is cyclic if and only if all the Sylow subgroups of $G$ are normal. I think for both problems the method is same. Is it correct or will some different concepts be used? Please elaborate.","Here ’s are distinct primes and . Then we need to show that is abelian if and only if all the Sylow subgroups of are normal. How to solve this question? Also a little modification to the above leads to a different scenario as , is cyclic if and only if all the Sylow subgroups of are normal. I think for both problems the method is same. Is it correct or will some different concepts be used? Please elaborate.",p_{i} O(G) = p_{1}^{2} \dotsm p_{n}^{2} G G O(G) = p_{1} \cdot p_{2} \cdot p_{3} \cdot\dots\cdot p_{n} G G,"['abstract-algebra', 'group-theory', 'finite-groups', 'normal-subgroups', 'sylow-theory']"
67,"A ""functional"" definition of simple group?","A ""functional"" definition of simple group?",,"We usually give the definition of simple group as follows, Simple Group. A group $(G,\circ)$ is said to be simple if it contains no proper nontrivial normal subgroup of $G$ . Where by trivial normal subgroup of a group $G$ we mean $\langle e\rangle$ where $e$ is the identity element of $G$ . Also, we may give the definition of a connected topological space as follows, Connected Topological Space. A topological space $(X,\mathfrak{T})$ is said to be connected if it contains no proper nontrivial clopen subset of $X$ . I couldn't help but notice the similarity between these two definitions (especially the italicized parts of the definitions) and so I tried to formulate the definition of Simple Groups in an analogous manner of the following definition of Connected Topological Spaces, A topological space $(X,\mathfrak{T})$ is said to be connected if for all continuous function $f:X\to\{0,1\}$ , it is constant. A ""natural"" analogue of this definition in case of simple groups can be, Definition. A group $(G,\circ)$ is said to be simple if for all homomorphisms $f:G\to\mathbb{Z}_2$ , it is constant. However, I can't prove (or disprove) whether the above definition is equivalent to the definition of simple groups that I mentioned previously. Questions Can anyone help me in this? If the definition is not equivalent then can some ""functional"" definition of a simple group be given?","We usually give the definition of simple group as follows, Simple Group. A group is said to be simple if it contains no proper nontrivial normal subgroup of . Where by trivial normal subgroup of a group we mean where is the identity element of . Also, we may give the definition of a connected topological space as follows, Connected Topological Space. A topological space is said to be connected if it contains no proper nontrivial clopen subset of . I couldn't help but notice the similarity between these two definitions (especially the italicized parts of the definitions) and so I tried to formulate the definition of Simple Groups in an analogous manner of the following definition of Connected Topological Spaces, A topological space is said to be connected if for all continuous function , it is constant. A ""natural"" analogue of this definition in case of simple groups can be, Definition. A group is said to be simple if for all homomorphisms , it is constant. However, I can't prove (or disprove) whether the above definition is equivalent to the definition of simple groups that I mentioned previously. Questions Can anyone help me in this? If the definition is not equivalent then can some ""functional"" definition of a simple group be given?","(G,\circ) G G \langle e\rangle e G (X,\mathfrak{T}) X (X,\mathfrak{T}) f:X\to\{0,1\} (G,\circ) f:G\to\mathbb{Z}_2",['abstract-algebra']
68,Too Restrictive Axiom- Example,Too Restrictive Axiom- Example,,Can someone give me an example of an object where the rules (axioms) are so restrictive that the result leads to few mathematical structures?,Can someone give me an example of an object where the rules (axioms) are so restrictive that the result leads to few mathematical structures?,,"['abstract-algebra', 'axioms']"
69,$R ≅ R/I$ prove that for any two-sided ideals $A$ and $B$ we have $A⊆B $ or $B⊆A$,prove that for any two-sided ideals  and  we have  or,R ≅ R/I A B A⊆B  B⊆A,Assume that $R$ is a ring such that for any two-sided ideal $I$ of $R$ we have $R ≅ R/I$. Prove that for any two-sided ideals $A$ and $B$ we have $A⊆B$ or $B⊆A$ . I try to solve with proof by contradiction and this property that $A∩B$ is also an ideal but i could not find any thing useful.,Assume that $R$ is a ring such that for any two-sided ideal $I$ of $R$ we have $R ≅ R/I$. Prove that for any two-sided ideals $A$ and $B$ we have $A⊆B$ or $B⊆A$ . I try to solve with proof by contradiction and this property that $A∩B$ is also an ideal but i could not find any thing useful.,,"['abstract-algebra', 'ring-theory', 'ideals']"
70,Does there always exist an irreducible polynomial of degree $d$ over $\mathbb{Z}/p\mathbb{Z}$? [duplicate],Does there always exist an irreducible polynomial of degree  over ? [duplicate],d \mathbb{Z}/p\mathbb{Z},This question already has answers here : How many irreducible polynomials of degree $n$ exist over $\mathbb{F}_p$? [duplicate] (3 answers) Existence of irreducible polynomials over finite field (2 answers) Closed 7 years ago . Let $p$ be a prime and let $d$ be a positive integer. Does there always exist an irreducible (i.e. unfactorable) polynomial of degree $d$ over $\mathbb{Z}/p\mathbb{Z}$?,This question already has answers here : How many irreducible polynomials of degree $n$ exist over $\mathbb{F}_p$? [duplicate] (3 answers) Existence of irreducible polynomials over finite field (2 answers) Closed 7 years ago . Let $p$ be a prime and let $d$ be a positive integer. Does there always exist an irreducible (i.e. unfactorable) polynomial of degree $d$ over $\mathbb{Z}/p\mathbb{Z}$?,,"['abstract-algebra', 'polynomials']"
71,Why Differential Forms on Riemann surfaces?,Why Differential Forms on Riemann surfaces?,,"I am working with Rick Miranda's ""Algebraic Curves and Riemann Surfaces"". Right now I am in chapter four ""Integration on Riemann Surfaces"" and struggle with it a lot!:( It starts with the definition of holomorphic 1-forms which is as follows: Definition: A holomorphic 1-form on an open set $V\subset \mathbb C$ is an expression $\omega$ of the form $$\omega=f(z)\text{dz}$$ where $f$ is a holomorphic function on $V$. We say that $\omega$ is a holomorphic 1-form in the coordinate z. -- The main problem for me is now that i can't really work with this expression. What is $\omega=f(z)\text{dz}$? Why should we define something like this/ what is the benefit from that? We already have a notion for the integral of a function on submanifolds. Why we should not apply this here? Because of this open question I am not able to understand the definitions which come later for example the following two: Definition: A $C^{\infty}$ 1-form on an open set $V\subset \mathbb C$ is an expression $\omega$ of the form $$\omega=f(z,\overline{z})\text{dz}+g(z,\overline{z})\text{d}\overline{\text{z}}$$ where $f$ and $g$ are $C^{\infty}$ function on $V$. We say that $\omega$ is a $C^{\infty}$ 1-form in the coordinate $z$. I think my problems with this definition are the same as above. Definition: A $C^{\infty}$ 2-form on an open set $V\subset \mathbb C$ is an expression $\eta$ of the form $$\eta=f(z,\overline{z})\text{dz}\wedge\text{d}\overline{\text{z}}$$ where $f$ is a $C^{\infty}$ function on $V$. We say that $\eta$ is a $C^{\infty}$ 2-form in the coordinate $z$. My additional problem/question here is: What is $\wedge?$. At this point its the first time that the author introduces this symbol. I would be very very glad if someone can make this clear for me. I appreciate any kind of help.","I am working with Rick Miranda's ""Algebraic Curves and Riemann Surfaces"". Right now I am in chapter four ""Integration on Riemann Surfaces"" and struggle with it a lot!:( It starts with the definition of holomorphic 1-forms which is as follows: Definition: A holomorphic 1-form on an open set $V\subset \mathbb C$ is an expression $\omega$ of the form $$\omega=f(z)\text{dz}$$ where $f$ is a holomorphic function on $V$. We say that $\omega$ is a holomorphic 1-form in the coordinate z. -- The main problem for me is now that i can't really work with this expression. What is $\omega=f(z)\text{dz}$? Why should we define something like this/ what is the benefit from that? We already have a notion for the integral of a function on submanifolds. Why we should not apply this here? Because of this open question I am not able to understand the definitions which come later for example the following two: Definition: A $C^{\infty}$ 1-form on an open set $V\subset \mathbb C$ is an expression $\omega$ of the form $$\omega=f(z,\overline{z})\text{dz}+g(z,\overline{z})\text{d}\overline{\text{z}}$$ where $f$ and $g$ are $C^{\infty}$ function on $V$. We say that $\omega$ is a $C^{\infty}$ 1-form in the coordinate $z$. I think my problems with this definition are the same as above. Definition: A $C^{\infty}$ 2-form on an open set $V\subset \mathbb C$ is an expression $\eta$ of the form $$\eta=f(z,\overline{z})\text{dz}\wedge\text{d}\overline{\text{z}}$$ where $f$ is a $C^{\infty}$ function on $V$. We say that $\eta$ is a $C^{\infty}$ 2-form in the coordinate $z$. My additional problem/question here is: What is $\wedge?$. At this point its the first time that the author introduces this symbol. I would be very very glad if someone can make this clear for me. I appreciate any kind of help.",,"['abstract-algebra', 'complex-analysis', 'riemannian-geometry', 'riemann-surfaces']"
72,Polynomials generating the same $p$-adic fields,Polynomials generating the same -adic fields,p,"I wonder if the following fact is true: Pick $l\in \mathbb N$ a number and let $f,g\in \mathbb Z_p[x]$ be monic polynomials with coefficients in the ring of $p$-adic integers such that $f\equiv g \pmod{p^l}$ and they are irreducible mod $p^l$. Then the roots of $f$ generate the same field as the roots of $g$. Can someone help me proving this or finding a counterexample?","I wonder if the following fact is true: Pick $l\in \mathbb N$ a number and let $f,g\in \mathbb Z_p[x]$ be monic polynomials with coefficients in the ring of $p$-adic integers such that $f\equiv g \pmod{p^l}$ and they are irreducible mod $p^l$. Then the roots of $f$ generate the same field as the roots of $g$. Can someone help me proving this or finding a counterexample?",,"['abstract-algebra', 'polynomials', 'algebraic-number-theory', 'p-adic-number-theory']"
73,Localization Preserves Euclidean Domains,Localization Preserves Euclidean Domains,,"I'm wanting to prove that given a ring $A$ (by ""ring"" I mean a commutative ring with identity ) and a multiplicative subset $S \subset A$: if $A$ is an Euclidean Domain, and $0 \notin S$ then $S^{-1}A$ (localization of A at S) is also an Euclidean Domain. I'm trying to produce an Euclidean Function in $S^{-1}A$ using the Euclidean Function $N:A \rightarrow \mathbb{N}$, that I already have from $A$ but I'm having trouble trying to define it in a way that works and verifies the properties an Euclidean Function must verify. Does any one mind giving me hints? I don't really want a solution.. I would like to work it myself. Thanks in advance. :)","I'm wanting to prove that given a ring $A$ (by ""ring"" I mean a commutative ring with identity ) and a multiplicative subset $S \subset A$: if $A$ is an Euclidean Domain, and $0 \notin S$ then $S^{-1}A$ (localization of A at S) is also an Euclidean Domain. I'm trying to produce an Euclidean Function in $S^{-1}A$ using the Euclidean Function $N:A \rightarrow \mathbb{N}$, that I already have from $A$ but I'm having trouble trying to define it in a way that works and verifies the properties an Euclidean Function must verify. Does any one mind giving me hints? I don't really want a solution.. I would like to work it myself. Thanks in advance. :)",,"['abstract-algebra', 'ring-theory', 'euclidean-algorithm', 'localization']"
74,Verifying the Jacobi identity for the semidirect product of Lie algebras,Verifying the Jacobi identity for the semidirect product of Lie algebras,,"Given Lie algebras $S$ and $I$ and a Lie homomorphism $\theta \colon S\to \operatorname{Der} I$ , we have the semidirect product to be the vector space $S\oplus I$ with operation $$   (s_{1},x_{1})(s_{2}x_{2})   :=   ([s_{1},s_{2}],[x_{1},x_{2}]+\theta(s_{1})x_{2}-\theta(s_{2})x_{1}). $$ Show that this is a Lie algebra. So I can easily verify the skew-symmetric but I can't seem to work out a nice way of proving the Jacobi identity. Am I missing a simple trick or must you perform the tedious calculation to show this? Thanks.","Given Lie algebras and and a Lie homomorphism , we have the semidirect product to be the vector space with operation Show that this is a Lie algebra. So I can easily verify the skew-symmetric but I can't seem to work out a nice way of proving the Jacobi identity. Am I missing a simple trick or must you perform the tedious calculation to show this? Thanks.","S I \theta \colon S\to \operatorname{Der} I S\oplus I 
  (s_{1},x_{1})(s_{2}x_{2})
  :=
  ([s_{1},s_{2}],[x_{1},x_{2}]+\theta(s_{1})x_{2}-\theta(s_{2})x_{1}).
","['abstract-algebra', 'lie-algebras', 'semidirect-product']"
75,prove that maximal ideal in $\mathbb{Z}$ generated by a prime number,prove that maximal ideal in  generated by a prime number,\mathbb{Z},"I am trying to prove $(a)$ is a maximal ideal in $\mathbb{Z}$,  if and only if $a$ is prime number. Now I wrote: assume $a \in\mathbb{Z}$, while it's not prime number we can write as $a=xy$, for some integers $x$ and $y$. then $(a)\subset (x)$ and $(a)\subset (y)$ while if $(a)$ is maximal ideal, it's not exist $(k)$ such that $(a)\subset (k)\subset\mathbb{Z}$. so $(a)$ cannot be maximal ideal. we can say by contradictory if $a$ is prime, $(a)$ is maximal ideal. is this correct?  and how to prove the other way.","I am trying to prove $(a)$ is a maximal ideal in $\mathbb{Z}$,  if and only if $a$ is prime number. Now I wrote: assume $a \in\mathbb{Z}$, while it's not prime number we can write as $a=xy$, for some integers $x$ and $y$. then $(a)\subset (x)$ and $(a)\subset (y)$ while if $(a)$ is maximal ideal, it's not exist $(k)$ such that $(a)\subset (k)\subset\mathbb{Z}$. so $(a)$ cannot be maximal ideal. we can say by contradictory if $a$ is prime, $(a)$ is maximal ideal. is this correct?  and how to prove the other way.",,"['abstract-algebra', 'ideals']"
76,Nontrivial subring with identity of a ring without identity [duplicate],Nontrivial subring with identity of a ring without identity [duplicate],,"This question already has answers here : Example of a ring without unity that has a subring with unity? [duplicate] (2 answers) Closed 8 years ago . I'm looking for an example a ring and a subring with $R \subset S$ such that $R$ has 1 but $S$ does not. Its easy to choose R to be the trivial ring with $0=1$, but are there any more exotic examples of this phenomenon?","This question already has answers here : Example of a ring without unity that has a subring with unity? [duplicate] (2 answers) Closed 8 years ago . I'm looking for an example a ring and a subring with $R \subset S$ such that $R$ has 1 but $S$ does not. Its easy to choose R to be the trivial ring with $0=1$, but are there any more exotic examples of this phenomenon?",,['abstract-algebra']
77,An irreducible polynomial in a subfield of $\mathbb{C}$ has no multiple roots in $\mathbb{C}$,An irreducible polynomial in a subfield of  has no multiple roots in,\mathbb{C} \mathbb{C},"Let $K\subset \mathbb{C}$ be a subfield and $f\in K[t]$ an irreducible polynomial. Show that $f$ has no multiple roots in $\mathbb{C}$. If I understand this question correctly, I must show that there is no $a \in \mathbb{C}$ such that $(t-a)^n|f$ in $F[t]$ with $n>1$. So suppose $(t-a)^2|f$ and $f=(t-a)^2h$. Then we have $f'=2(t-a)h+(t-a)^2h' \Rightarrow (t-a)|f'$ so $\gcd(f,f'$) is not constant. Therefore $f$ is divisible by some square of non-constant polynomial in $F[t]$, which is a contradiction. Is my argument correct? Thank you.","Let $K\subset \mathbb{C}$ be a subfield and $f\in K[t]$ an irreducible polynomial. Show that $f$ has no multiple roots in $\mathbb{C}$. If I understand this question correctly, I must show that there is no $a \in \mathbb{C}$ such that $(t-a)^n|f$ in $F[t]$ with $n>1$. So suppose $(t-a)^2|f$ and $f=(t-a)^2h$. Then we have $f'=2(t-a)h+(t-a)^2h' \Rightarrow (t-a)|f'$ so $\gcd(f,f'$) is not constant. Therefore $f$ is divisible by some square of non-constant polynomial in $F[t]$, which is a contradiction. Is my argument correct? Thank you.",,"['abstract-algebra', 'ring-theory']"
78,Prove $G$ is a group (unusual star operation).,Prove  is a group (unusual star operation).,G,"I've come across another rather simple question, but I'm having trouble with $G$'s defined operation. Let $(G,\circ)$ be a group and $x_0 \in G$. Consider the operation $*$ defined in $G$ by $a * b = a \circ x_0 \circ b, a,b\in G$. a) Knowing $*$ is associative, show $(G,*)$ is a group. Well, so far I've got this: Since $x_0 \in G$, G is non-empty. Closed under multiplication: Let $a,b \in G$. $a * b = a \circ x_0 \circ b$. Since all $a, b,$ and $x_0$ are in $G$, then its product is in $G$ as well. Identity: $a * 1_G = a$ (I don't think I've got this one quite right, because I'm messing with inverses, and that's probably not required) $a * 1_G = a == a \circ x_0 \circ 1_G = a == a^-1 \circ a \circ x_0^-1 \circ 1_G = a^-1 \circ a == x_0 \circ 1_G = 1_G == x_0 = 1_G$ I'm left with proving the inverse element, which should probably be done before the identity. Or maybe I should re-think my identity strategy. I'm a bit lost here. Any help? Thanks. EDIT: What I mean is: Clearly, we need the concept of inverses to work out the group's identity element. Thing is, I proved it before proving the very existence of the inverse element. Is this not a problem?","I've come across another rather simple question, but I'm having trouble with $G$'s defined operation. Let $(G,\circ)$ be a group and $x_0 \in G$. Consider the operation $*$ defined in $G$ by $a * b = a \circ x_0 \circ b, a,b\in G$. a) Knowing $*$ is associative, show $(G,*)$ is a group. Well, so far I've got this: Since $x_0 \in G$, G is non-empty. Closed under multiplication: Let $a,b \in G$. $a * b = a \circ x_0 \circ b$. Since all $a, b,$ and $x_0$ are in $G$, then its product is in $G$ as well. Identity: $a * 1_G = a$ (I don't think I've got this one quite right, because I'm messing with inverses, and that's probably not required) $a * 1_G = a == a \circ x_0 \circ 1_G = a == a^-1 \circ a \circ x_0^-1 \circ 1_G = a^-1 \circ a == x_0 \circ 1_G = 1_G == x_0 = 1_G$ I'm left with proving the inverse element, which should probably be done before the identity. Or maybe I should re-think my identity strategy. I'm a bit lost here. Any help? Thanks. EDIT: What I mean is: Clearly, we need the concept of inverses to work out the group's identity element. Thing is, I proved it before proving the very existence of the inverse element. Is this not a problem?",,"['abstract-algebra', 'group-theory']"
79,Germs and local ring.,Germs and local ring.,,"I'm having trouble understanding the following argument (which I believe to be somewhat incomplete or flawed). Let $A=C(X)$ be the set of continuous functions from the topological space $X$ to the complex plane $\mathbb{C}$. We define $m_{x} = \{f \in C(X): f(x) = 0 \}$ and $A_x$ the ring of germs at point $x$. The statement is the following $A_x \simeq A_{m_x}$. (1) I don't see how one defines $A_{m_x}$ since the set contains global functions that might not be well-defined as we quotient by functions $f$ such that $f(x) \neq 0$, but it doesn't necessarily mean that $f \neq 0$. Though it's indeed well defined in a neighborhood of $x$. (2) Now using the universal property of localization, we sure want to define $\phi : A_{m_x} \rightarrow A_x$ s.t we have $\phi(a/s) = \iota(a)\iota(s)^{-1}$ where $\iota$ is the inclusion map $\iota: A \rightarrow A_x$. We want $\phi$ to be an isomorphism. It is surjective; now we want it to be one-on-one. Now I don't see how this is possible as $\phi(a/s) = 0$ iff $a = 0$ in a neighborhood of $x$, which doesn't imply that $a=0$ globally. I guess there's something I don't really fathom, or my textbook might just be flawed. Anyway, thanks for your help.","I'm having trouble understanding the following argument (which I believe to be somewhat incomplete or flawed). Let $A=C(X)$ be the set of continuous functions from the topological space $X$ to the complex plane $\mathbb{C}$. We define $m_{x} = \{f \in C(X): f(x) = 0 \}$ and $A_x$ the ring of germs at point $x$. The statement is the following $A_x \simeq A_{m_x}$. (1) I don't see how one defines $A_{m_x}$ since the set contains global functions that might not be well-defined as we quotient by functions $f$ such that $f(x) \neq 0$, but it doesn't necessarily mean that $f \neq 0$. Though it's indeed well defined in a neighborhood of $x$. (2) Now using the universal property of localization, we sure want to define $\phi : A_{m_x} \rightarrow A_x$ s.t we have $\phi(a/s) = \iota(a)\iota(s)^{-1}$ where $\iota$ is the inclusion map $\iota: A \rightarrow A_x$. We want $\phi$ to be an isomorphism. It is surjective; now we want it to be one-on-one. Now I don't see how this is possible as $\phi(a/s) = 0$ iff $a = 0$ in a neighborhood of $x$, which doesn't imply that $a=0$ globally. I guess there's something I don't really fathom, or my textbook might just be flawed. Anyway, thanks for your help.",,"['abstract-algebra', 'general-topology', 'commutative-algebra', 'germs']"
80,"$0^{th}$ tensor power, $V^{\otimes 0} = \Bbb F$, definition, or mathematical construction?","tensor power, , definition, or mathematical construction?",0^{th} V^{\otimes 0} = \Bbb F,"95% sure I will be told it's just a definition, move on etc: Is there mathematical reason why the $0^{th}$ tensor power is defined as: $$V^{\otimes 0} = \Bbb F$$ Where $\Bbb F$ is the field that vectorspace $V$ lies over. We define the $n^{th}$ tensor power of $V$ as: $$ V^{\otimes n}=V\otimes V\otimes \cdots \otimes V$$ with basis: $$\{v^{i_1}\otimes v^{i_2} \otimes \cdots \otimes v^{i_n}: 1\leq i_k \leq n\}$$ For some reason I feel like $V^{\otimes 0}$ should equal the trivial vectorspace. So is it just a definition? If so, what is the motivation for this choice. Thanks.","95% sure I will be told it's just a definition, move on etc: Is there mathematical reason why the tensor power is defined as: Where is the field that vectorspace lies over. We define the tensor power of as: with basis: For some reason I feel like should equal the trivial vectorspace. So is it just a definition? If so, what is the motivation for this choice. Thanks.",0^{th} V^{\otimes 0} = \Bbb F \Bbb F V n^{th} V  V^{\otimes n}=V\otimes V\otimes \cdots \otimes V \{v^{i_1}\otimes v^{i_2} \otimes \cdots \otimes v^{i_n}: 1\leq i_k \leq n\} V^{\otimes 0},"['abstract-algebra', 'vector-spaces', 'tensor-products']"
81,Why are units called units?,Why are units called units?,,"Why are units in abstract algebra called units? Is it just because they generalize the notion of $-1$ and $1$?, and the like? There's often a sense that units don't matter, when talking about things like irreducibility- is the name unit supposed to trivialize them somehow?","Why are units in abstract algebra called units? Is it just because they generalize the notion of $-1$ and $1$?, and the like? There's often a sense that units don't matter, when talking about things like irreducibility- is the name unit supposed to trivialize them somehow?",,"['abstract-algebra', 'terminology']"
82,Group Ring to Hopf Algebra -- I'm missing something simple,Group Ring to Hopf Algebra -- I'm missing something simple,,"I've been working through Federico Ardila's online Hopf algebra lectures and hoped to check my understanding so far by constructing the Hopf algebra of a very small group ring from scratch. But I've failed, which has left me in a state of perplexity. I chose $G=\mathbb{Z}/2\mathbb{Z}$ and $\mathbb{k}=\mathbb{Z}/3\mathbb{Z}$. So my group ring $\mathbb{k}G$ is the set of all formal $\mathbb{k}$-linear combinations of the two elements of $G$ (I'll call them $e$ and $a$ to avoid confusion with the coefficients, which I'll write as 0, 1, 2). On top of this structure we have: Multiplication as defined here . Comultiplication as $r\mapsto r\otimes r$, for each $r\in \mathbb{k}G$ The unit as $g\mapsto 1_\mathbb{k}$ for $g\in G$, extended linearly (so, for example, it maps $2e + a\mapsto 2 + 1 = 3 = 0 \mod 3$) The counit as $\lambda \mapsto \lambda e$ for all $\lambda\in \mathbb{k}$ The antipode as $g\mapsto g^{-1}$, extended linearly. But in this case, that's just the identity. With these definitions, I hoped this diagram would commute: but it blinking doesn't . Example: Along the top path: $(e + a)\to (e + a)\otimes (e + a)\to (e + a)\otimes (e + a)\to (2e + 2a)$ Through the middle: $(e + a)\to 2\to (2e)$. And it's obvious why: products in the group ring don't always annihilate the $a$ element, but the counit-unit sequence does. So this could never work. Hopefully I've explained what I've done in enough detail that whatever fundamental thing I've misunderstood isn't elided in the process. I'm hoping someone will be kind and patient enough to unpick it and point to the thing I've stupidly misunderstood!","I've been working through Federico Ardila's online Hopf algebra lectures and hoped to check my understanding so far by constructing the Hopf algebra of a very small group ring from scratch. But I've failed, which has left me in a state of perplexity. I chose $G=\mathbb{Z}/2\mathbb{Z}$ and $\mathbb{k}=\mathbb{Z}/3\mathbb{Z}$. So my group ring $\mathbb{k}G$ is the set of all formal $\mathbb{k}$-linear combinations of the two elements of $G$ (I'll call them $e$ and $a$ to avoid confusion with the coefficients, which I'll write as 0, 1, 2). On top of this structure we have: Multiplication as defined here . Comultiplication as $r\mapsto r\otimes r$, for each $r\in \mathbb{k}G$ The unit as $g\mapsto 1_\mathbb{k}$ for $g\in G$, extended linearly (so, for example, it maps $2e + a\mapsto 2 + 1 = 3 = 0 \mod 3$) The counit as $\lambda \mapsto \lambda e$ for all $\lambda\in \mathbb{k}$ The antipode as $g\mapsto g^{-1}$, extended linearly. But in this case, that's just the identity. With these definitions, I hoped this diagram would commute: but it blinking doesn't . Example: Along the top path: $(e + a)\to (e + a)\otimes (e + a)\to (e + a)\otimes (e + a)\to (2e + 2a)$ Through the middle: $(e + a)\to 2\to (2e)$. And it's obvious why: products in the group ring don't always annihilate the $a$ element, but the counit-unit sequence does. So this could never work. Hopefully I've explained what I've done in enough detail that whatever fundamental thing I've misunderstood isn't elided in the process. I'm hoping someone will be kind and patient enough to unpick it and point to the thing I've stupidly misunderstood!",,"['abstract-algebra', 'group-theory', 'hopf-algebras']"
83,Is $G/H$ always a subgroup of $G$?,Is  always a subgroup of ?,G/H G,"Given a normal subgroup $H$ of a finite group $G$, is there always an injective homomorphism   $$\varphi:G/H\to G?$$   In other words, is $G/H$ a subgroup of $G$? If we pick an arbitrary representative element of each coset, we can get an injective map $\varphi:G/H\to G$, but I am not sure if we can always choose the $g_i$'s to get a homomorphism. The requirement would be that if $\{g_i\}$ is the chosen set of representatives of the cosets of $G$ by $H$, then for each $i,j$ we have that $g_ig_j$ is the chosen representative for the coset $g_ig_jH$, i.e. $g_ig_jH=g_kH$ for a unique $k$. Can we always choose some $g_i$ to satisfy that?","Given a normal subgroup $H$ of a finite group $G$, is there always an injective homomorphism   $$\varphi:G/H\to G?$$   In other words, is $G/H$ a subgroup of $G$? If we pick an arbitrary representative element of each coset, we can get an injective map $\varphi:G/H\to G$, but I am not sure if we can always choose the $g_i$'s to get a homomorphism. The requirement would be that if $\{g_i\}$ is the chosen set of representatives of the cosets of $G$ by $H$, then for each $i,j$ we have that $g_ig_j$ is the chosen representative for the coset $g_ig_jH$, i.e. $g_ig_jH=g_kH$ for a unique $k$. Can we always choose some $g_i$ to satisfy that?",,"['abstract-algebra', 'group-theory']"
84,$R$ is a unique factorization domain $\iff$ every prime minimal over a principal ideal is also principal,is a unique factorization domain  every prime minimal over a principal ideal is also principal,R \iff,"I'm trying to show that a ring $R$ is a unique factorization domain $\iff$ every prime minimal over a principal ideal is also principal. I think the idea is to use the principal ideal theorem of Krull, but I don't know how to connect principal ideal properties with unique factorization domain properties. I know that ""principal ideal domain $\implies$ unique factorization domain"", which helps me if I prove $R$ is principal from the second statement, but that is as far as I can go right now. PS: assume $R$ is a commutative ring with unity. Thanks.","I'm trying to show that a ring $R$ is a unique factorization domain $\iff$ every prime minimal over a principal ideal is also principal. I think the idea is to use the principal ideal theorem of Krull, but I don't know how to connect principal ideal properties with unique factorization domain properties. I know that ""principal ideal domain $\implies$ unique factorization domain"", which helps me if I prove $R$ is principal from the second statement, but that is as far as I can go right now. PS: assume $R$ is a commutative ring with unity. Thanks.",,"['abstract-algebra', 'commutative-algebra', 'unique-factorization-domains']"
85,Ideals of non semi-simple group rings.,Ideals of non semi-simple group rings.,,"I worked for a long time on complex group rings and complex twisted group rings. In those cases the algebra is semi-simple and its structure is well understood from the decomposition to irreducible (projective in the twisted case) representations. For example $$\mathbb{C}S_3\cong \mathbb{C}\oplus \mathbb{C}\oplus M_2(\mathbb{C}).$$ Now I am trying to deal with a non-simple case in which the group is non-commutative (in the commutative case it is much easier). Now, I am stuck in the following example. Let  $$G=C_7\rtimes C_3,$$ where the action of $C_3$ on $C_7$ is by sending its generator $\sigma$ to $\sigma ^4$. Describe (as best as you can) the ring structure of the group ring $$\mathbb{F}_3G.$$ Here the group ring is not semi-simple. However, I am trying to find a maximal (length) chain of ideals $I_0,I_1,\ldots ,I_k$ such that $$\{0\}=I_0\subseteq I_1 \subseteq I_2 \subseteq \ldots \subseteq I_k=\mathbb{F}_3G.$$ So far I made no progress. Thanks in advance for any help.","I worked for a long time on complex group rings and complex twisted group rings. In those cases the algebra is semi-simple and its structure is well understood from the decomposition to irreducible (projective in the twisted case) representations. For example $$\mathbb{C}S_3\cong \mathbb{C}\oplus \mathbb{C}\oplus M_2(\mathbb{C}).$$ Now I am trying to deal with a non-simple case in which the group is non-commutative (in the commutative case it is much easier). Now, I am stuck in the following example. Let  $$G=C_7\rtimes C_3,$$ where the action of $C_3$ on $C_7$ is by sending its generator $\sigma$ to $\sigma ^4$. Describe (as best as you can) the ring structure of the group ring $$\mathbb{F}_3G.$$ Here the group ring is not semi-simple. However, I am trying to find a maximal (length) chain of ideals $I_0,I_1,\ldots ,I_k$ such that $$\{0\}=I_0\subseteq I_1 \subseteq I_2 \subseteq \ldots \subseteq I_k=\mathbb{F}_3G.$$ So far I made no progress. Thanks in advance for any help.",,"['abstract-algebra', 'group-theory', 'ring-theory']"
86,How to prove group generated $\langle a \rangle$ by element $a$ is normal subgroup of G iff a is the center of G?,How to prove group generated  by element  is normal subgroup of G iff a is the center of G?,\langle a \rangle a,"Problem: Let $G$ denote a group, and $H$ a subgroup of $G$. Suppose $a$ to be an element of $ G$ of order 2. Prove that $\langle a \rangle$ is a normal subgroup of $G$ iff  a is   in the center of G. My Work and thoughts: Let's suppose $a\in G$ has order 2. This implies $a^2=e$ Further suppose $\langle a \rangle$ is normal subgroup of $G$. Define $N_G(H)= \{a\in G|aH a^-1\}= \langle a \rangle$ as normalizer. $(h\in H)$ NTS $aha^{-1 }= ah=ha$ because $C_G(H)=\{a\in G|ah=ha\}$. Is this the right idea? Of course I'm starting with $P \Rightarrow Q$ direction then I'll do $Q  \Rightarrow P$. I'm stuck. I'm not sure how to continue.","Problem: Let $G$ denote a group, and $H$ a subgroup of $G$. Suppose $a$ to be an element of $ G$ of order 2. Prove that $\langle a \rangle$ is a normal subgroup of $G$ iff  a is   in the center of G. My Work and thoughts: Let's suppose $a\in G$ has order 2. This implies $a^2=e$ Further suppose $\langle a \rangle$ is normal subgroup of $G$. Define $N_G(H)= \{a\in G|aH a^-1\}= \langle a \rangle$ as normalizer. $(h\in H)$ NTS $aha^{-1 }= ah=ha$ because $C_G(H)=\{a\in G|ah=ha\}$. Is this the right idea? Of course I'm starting with $P \Rightarrow Q$ direction then I'll do $Q  \Rightarrow P$. I'm stuck. I'm not sure how to continue.",,"['abstract-algebra', 'group-theory']"
87,"$G$, group. $a,b\in G$. Show that $|a|=|a^{-1}|; |ab|=|ba|$, and $|a|=|cac^{-1}|, \forall c\in G$. [duplicate]",", group. . Show that , and . [duplicate]","G a,b\in G |a|=|a^{-1}|; |ab|=|ba| |a|=|cac^{-1}|, \forall c\in G","This question already has answers here : Order of conjugate of an element given the order of its conjugate (4 answers) An element of a group has the same order as its inverse (4 answers) Closed 8 years ago . Isn't it obvious for $|a|=|a^{-1}|$, since $\langle a\rangle = \langle a^{-1} \rangle$? For $|ab|=|ba|$, I think we should go like this: $e=(ab)^n\Rightarrow e=(ab)(ab)^{n-1}\Rightarrow (ab)^{-1}=(ab)^{n-1}\Rightarrow b^{-1}a^{-1}=(ab)^{n-1}\Rightarrow a^{-1}=b(ab)^{n-1}$ But I get stuck here, since I don't know whether to get from here to $e=(ba)^n$. For $|a|=|cac^{-1}|$, do I have to show that $\langle a\rangle = \langle cac^{-1}\rangle$?","This question already has answers here : Order of conjugate of an element given the order of its conjugate (4 answers) An element of a group has the same order as its inverse (4 answers) Closed 8 years ago . Isn't it obvious for $|a|=|a^{-1}|$, since $\langle a\rangle = \langle a^{-1} \rangle$? For $|ab|=|ba|$, I think we should go like this: $e=(ab)^n\Rightarrow e=(ab)(ab)^{n-1}\Rightarrow (ab)^{-1}=(ab)^{n-1}\Rightarrow b^{-1}a^{-1}=(ab)^{n-1}\Rightarrow a^{-1}=b(ab)^{n-1}$ But I get stuck here, since I don't know whether to get from here to $e=(ba)^n$. For $|a|=|cac^{-1}|$, do I have to show that $\langle a\rangle = \langle cac^{-1}\rangle$?",,"['abstract-algebra', 'group-theory']"
88,Embedding $\mathbb{F}_{q^2}^*$ into $GL_2(\mathbb{F}_{q})$,Embedding  into,\mathbb{F}_{q^2}^* GL_2(\mathbb{F}_{q}),"If we see $\mathbb{F}_{q^2}$ as a $2$-dimensional vector space over $\mathbb{F}_{q}$ (and pick a base) then we can identify $\operatorname{Aut}_{\mathbb{F}_{q}}(\mathbb{F}_{q^2})$ with $GL_2(\mathbb{F}_{q})$. Therefore we can embed $\mathbb{F}_{q^2}^*$ into $GL_2(\mathbb{F}_{q})$, by the natural action of $\mathbb{F}_{q^2}^*$ on $\mathbb{F}_{q^2}$. However, I have difficulty to concretely visualise the subgroup $E$ of $GL_2(\mathbb{F}_{q})$ that should be congruent to $\mathbb{F}_{q^2}^*$. Is there a nice way to see this group $E$?","If we see $\mathbb{F}_{q^2}$ as a $2$-dimensional vector space over $\mathbb{F}_{q}$ (and pick a base) then we can identify $\operatorname{Aut}_{\mathbb{F}_{q}}(\mathbb{F}_{q^2})$ with $GL_2(\mathbb{F}_{q})$. Therefore we can embed $\mathbb{F}_{q^2}^*$ into $GL_2(\mathbb{F}_{q})$, by the natural action of $\mathbb{F}_{q^2}^*$ on $\mathbb{F}_{q^2}$. However, I have difficulty to concretely visualise the subgroup $E$ of $GL_2(\mathbb{F}_{q})$ that should be congruent to $\mathbb{F}_{q^2}^*$. Is there a nice way to see this group $E$?",,"['abstract-algebra', 'field-theory', 'finite-fields']"
89,"If $I$ is a maximal ideal in $R$, $(I,x)$ is a maximal ideal in $R[x]$","If  is a maximal ideal in ,  is a maximal ideal in","I R (I,x) R[x]","Click Link to Original Text Let $R$ be a commutative ring with $1$, and $I$ is an ideal of $R$.  Then, $(I) = I[x]$ is an ideal in $R[x]$.  I was able to prove, via first isomorphism, that $\frac{R[x]}{(I)}$ is isomomorphic to $\frac{R}{I}[x]$.  It follows that if $I$ is a prime ideal, then $(I)$ is a prime ideal in $R[x]$. Then the author noted that, if $I$ is maximal, it does not mean that $(I) = I[x]$ is maximal.  If my understanding is correct, it is because while $R/I$ is a field, $\frac{R}{I}[x]$ may still only be an integral domain.  Finally, the author added that $(I, x)$ is a maximal ideal in $R[x]$.  What does the notation $(I, x)$ stand for?","Click Link to Original Text Let $R$ be a commutative ring with $1$, and $I$ is an ideal of $R$.  Then, $(I) = I[x]$ is an ideal in $R[x]$.  I was able to prove, via first isomorphism, that $\frac{R[x]}{(I)}$ is isomomorphic to $\frac{R}{I}[x]$.  It follows that if $I$ is a prime ideal, then $(I)$ is a prime ideal in $R[x]$. Then the author noted that, if $I$ is maximal, it does not mean that $(I) = I[x]$ is maximal.  If my understanding is correct, it is because while $R/I$ is a field, $\frac{R}{I}[x]$ may still only be an integral domain.  Finally, the author added that $(I, x)$ is a maximal ideal in $R[x]$.  What does the notation $(I, x)$ stand for?",,"['abstract-algebra', 'ring-theory']"
90,What is $\mathbb{Z}[i] \otimes_{\mathbb{Z}[2i]} \mathbb{Z}[i]$?,What is ?,\mathbb{Z}[i] \otimes_{\mathbb{Z}[2i]} \mathbb{Z}[i],"What is $\mathbb{Z}[i] \otimes_{\mathbb{Z}[2i]} \mathbb{Z}[i]$? Also, since $\mathbb{Z}[i]$ is a PID, we should be able to write this $\mathbb{Z}[i]$-module as a direct sum of cyclic $\mathbb{Z}[i]$-modules. Can we?","What is $\mathbb{Z}[i] \otimes_{\mathbb{Z}[2i]} \mathbb{Z}[i]$? Also, since $\mathbb{Z}[i]$ is a PID, we should be able to write this $\mathbb{Z}[i]$-module as a direct sum of cyclic $\mathbb{Z}[i]$-modules. Can we?",,"['abstract-algebra', 'ring-theory']"
91,Transitivity of the discriminant of number fields,Transitivity of the discriminant of number fields,,"Let $M/L/K$ be a tower of number fields with discriminant of $M/K: d_M$ and of $L/K: d_L$. I would like to find a transitivity theorem for the discriminant and by letting $p_i$ and $q_i$ be integral basis for $M$ and $L$ respectively and $A =[a_{ij}]$ the transition matrix between the basis, a calculation gives: $$[M:L]^{[L:K]}d_L = \det(A)^2d_M$$ However, these two links give different(even from each other) answers: Divisibility of discriminants in number field extensions $([M:L]^2 d_L = \det(A)^2 d_M)$ Quadratic subfield of cyclotomic field (discriminant of $M$ is divisible by discriminant of $L$ to the power $[M:L]$ Both of these are given in the accepted answers and use different notation. Which of the three is correct?(The last one is not strictly contradictory but probably often will be...).","Let $M/L/K$ be a tower of number fields with discriminant of $M/K: d_M$ and of $L/K: d_L$. I would like to find a transitivity theorem for the discriminant and by letting $p_i$ and $q_i$ be integral basis for $M$ and $L$ respectively and $A =[a_{ij}]$ the transition matrix between the basis, a calculation gives: $$[M:L]^{[L:K]}d_L = \det(A)^2d_M$$ However, these two links give different(even from each other) answers: Divisibility of discriminants in number field extensions $([M:L]^2 d_L = \det(A)^2 d_M)$ Quadratic subfield of cyclotomic field (discriminant of $M$ is divisible by discriminant of $L$ to the power $[M:L]$ Both of these are given in the accepted answers and use different notation. Which of the three is correct?(The last one is not strictly contradictory but probably often will be...).",,"['abstract-algebra', 'algebraic-number-theory', 'galois-theory', 'extension-field']"
92,Example of a ring where all but two of its elements are units,Example of a ring where all but two of its elements are units,,"One way of viewing a field is just as a ring where all but one of its elements (namely $0$) is a unit. I'm looking for rings (commutative with a 1) where all but two of its elements are units. I found one fairly trivial example, $\mathbb Z/4 \mathbb Z,$ and I think I may have a proof that it's the only example of such a ring that's finite: If $R$ is some finite ring, then considering $R$ as an additive group and applying the structure theorem for finite abelian groups, we get that $R$ is isomorphic to a direct product of groups of the form $\mathbb Z/n_i \mathbb Z,$ and the $n_i$ are coprime. I believe that this means that $R$ is also isomorphic to this as a ring (is this correct?). For each $n_i$ the size of $\left(\mathbb Z/n_i \mathbb Z\right)^*$ is $\phi(n_i).$ Let $n=|R|$. Since $\phi$ is multiplicative over coprime elements, we have $n=\Pi_i n_i$ and $|R^*|=n-2=\Pi_i \phi(n_i)$. But $\phi(n_i)\leq n_i-1,$ so obviously there can only be one factor $\mathbb Z/n_1 \mathbb Z$. Then $n_1=n$ and all we need is that $\phi(n)=n-2$. Writing $n$ as a product of primes $n=2^{r_2}3^{r_3}5^{r_5}\cdots$ we get  $$\phi(n)= n-2=\phi(2^{r_2})\phi(3^{r_3}) \phi(5^{r_5})\cdots\\ =(2^{r_2}-2^{r_2-1})(3^{r_3}-3^{r_3-1})(5^{r_5}-5^{r_5-1})\cdots $$ Again, it's clear that there can only be one factor as otherwise the expression for $\phi(n)$ in the final line would be too small. Say $n=p^{r_p}$ and $p^{r_p}-2=p^{r_p}-p^{r_p-1}$ Then $p^{r_p-1}=2$. Hence $p=2$ and $r_p=2$ i.e. $n=4.$ Can anyone tell me whether this proof is correct or not. My main question: are there any more examples with infinite rings? I feel like the answer is no because it seems very hard to have so many units, but I have no idea how to start to prove this in general. I tried local rings: If $R$ was a local ring, with unique maximal ideal $I$, then $R=I\sqcup R^*$ so I need a maximal ideal containing all but two elements which seems impossible, but again I don't know how to prove it. Most of my intuition for this being false is coming from Lagrange I think. Lagrange says that subgroups can't get too large, in particular that if $|G|=n$ then any proper subgroup $H$ must have $|H| \leq n/2$. But Lagrange doesn't work for infinite groups, so I don't know if this intuition is at all valid.","One way of viewing a field is just as a ring where all but one of its elements (namely $0$) is a unit. I'm looking for rings (commutative with a 1) where all but two of its elements are units. I found one fairly trivial example, $\mathbb Z/4 \mathbb Z,$ and I think I may have a proof that it's the only example of such a ring that's finite: If $R$ is some finite ring, then considering $R$ as an additive group and applying the structure theorem for finite abelian groups, we get that $R$ is isomorphic to a direct product of groups of the form $\mathbb Z/n_i \mathbb Z,$ and the $n_i$ are coprime. I believe that this means that $R$ is also isomorphic to this as a ring (is this correct?). For each $n_i$ the size of $\left(\mathbb Z/n_i \mathbb Z\right)^*$ is $\phi(n_i).$ Let $n=|R|$. Since $\phi$ is multiplicative over coprime elements, we have $n=\Pi_i n_i$ and $|R^*|=n-2=\Pi_i \phi(n_i)$. But $\phi(n_i)\leq n_i-1,$ so obviously there can only be one factor $\mathbb Z/n_1 \mathbb Z$. Then $n_1=n$ and all we need is that $\phi(n)=n-2$. Writing $n$ as a product of primes $n=2^{r_2}3^{r_3}5^{r_5}\cdots$ we get  $$\phi(n)= n-2=\phi(2^{r_2})\phi(3^{r_3}) \phi(5^{r_5})\cdots\\ =(2^{r_2}-2^{r_2-1})(3^{r_3}-3^{r_3-1})(5^{r_5}-5^{r_5-1})\cdots $$ Again, it's clear that there can only be one factor as otherwise the expression for $\phi(n)$ in the final line would be too small. Say $n=p^{r_p}$ and $p^{r_p}-2=p^{r_p}-p^{r_p-1}$ Then $p^{r_p-1}=2$. Hence $p=2$ and $r_p=2$ i.e. $n=4.$ Can anyone tell me whether this proof is correct or not. My main question: are there any more examples with infinite rings? I feel like the answer is no because it seems very hard to have so many units, but I have no idea how to start to prove this in general. I tried local rings: If $R$ was a local ring, with unique maximal ideal $I$, then $R=I\sqcup R^*$ so I need a maximal ideal containing all but two elements which seems impossible, but again I don't know how to prove it. Most of my intuition for this being false is coming from Lagrange I think. Lagrange says that subgroups can't get too large, in particular that if $|G|=n$ then any proper subgroup $H$ must have $|H| \leq n/2$. But Lagrange doesn't work for infinite groups, so I don't know if this intuition is at all valid.",,"['abstract-algebra', 'ring-theory']"
93,Why isn't there necessarily a direct sum of rings?,Why isn't there necessarily a direct sum of rings?,,"I've just seen on Wikipedia that we can't speak of direct sum of rings. Let $R$ and $S$ be rings. It says we can't have a direct sum of rings because the direct sum $R\times S$ doesn't receive a natural ring homomorphism. I don't understand what it means by this, and why we need this natural ring homomorphism to have direct sum of rings.","I've just seen on Wikipedia that we can't speak of direct sum of rings. Let and be rings. It says we can't have a direct sum of rings because the direct sum doesn't receive a natural ring homomorphism. I don't understand what it means by this, and why we need this natural ring homomorphism to have direct sum of rings.",R S R\times S,"['abstract-algebra', 'ring-theory', 'direct-sum', 'direct-product']"
94,What does $\Bbb{Z}/(2) \times \Bbb{Z}/(3) \times \dots$ do?,What does  do?,\Bbb{Z}/(2) \times \Bbb{Z}/(3) \times \dots,"Take the product of rings $M = \Bbb{Z}/(2) \times \Bbb{Z}/(3) \times \dots$ over the primes or in general take any infinite set of quotient modules of a ring $R$ and form their product.  It's true then that a copy of  $R$ lies in the product.  So $\Bbb{Z}$ lies in the infinite product, M. Can any more be said about $M$?  Can we identify all points in $M$ that don't lie in the isomorphic image of $\Bbb{Z}$, into a ""point at infinity"" and also introduce $\Bbb{Z} \cup \{\infty\}$, so that $\Bbb{Z} \cup \{\infty\} \approx M / \sim$ somehow?","Take the product of rings $M = \Bbb{Z}/(2) \times \Bbb{Z}/(3) \times \dots$ over the primes or in general take any infinite set of quotient modules of a ring $R$ and form their product.  It's true then that a copy of  $R$ lies in the product.  So $\Bbb{Z}$ lies in the infinite product, M. Can any more be said about $M$?  Can we identify all points in $M$ that don't lie in the isomorphic image of $\Bbb{Z}$, into a ""point at infinity"" and also introduce $\Bbb{Z} \cup \{\infty\}$, so that $\Bbb{Z} \cup \{\infty\} \approx M / \sim$ somehow?",,"['abstract-algebra', 'ring-theory', 'infinite-product']"
95,Semisimplicity is equivalent to each simple left module is projective?,Semisimplicity is equivalent to each simple left module is projective?,,"As it is well-known, a ring with unity $R$ is semisimple if and only if each left $R$-module is projective. My question: Is semisimplicity of $R$ equivalent to each simple left $R$-module being projective? I think it is true for a finite dimensional algebra $R$. But, in general, I could not reach any conclusion. Any help would be thanked!","As it is well-known, a ring with unity $R$ is semisimple if and only if each left $R$-module is projective. My question: Is semisimplicity of $R$ equivalent to each simple left $R$-module being projective? I think it is true for a finite dimensional algebra $R$. But, in general, I could not reach any conclusion. Any help would be thanked!",,"['abstract-algebra', 'ring-theory', 'noncommutative-algebra', 'projective-module']"
96,"Show that $\sqrt{7}\notin\mathbb{Q}(\alpha)$, with $\alpha$ a root of $X^7+6X^3+3X+15$","Show that , with  a root of",\sqrt{7}\notin\mathbb{Q}(\alpha) \alpha X^7+6X^3+3X+15,"Let $f=X^7+6X^3+3X+15\in\mathbb{Q}[x]$, and $\alpha\in\mathbb{C}$ such that $f(\alpha)=0$. I want to show $\sqrt{7}\notin\mathbb{Q}(\alpha)$ First of all, by Eisenstein's criterion, $f$ is irreducible in $Q[x]$, so we can say that $\deg (\text{Irr}(\alpha,\mathbb{Q}))=7=\left[\mathbb{Q}(\alpha):\mathbb{Q}\right]$. Then, $\left\{1,\alpha,\ldots,\alpha^6\right\}$ is a $\mathbb{Q}$-basis of $\mathbb{Q}(\alpha)$. Then, $\sqrt{7}\in\mathbb{Q}(\alpha)\Longleftrightarrow \sqrt{7}=\lambda_0 1+\lambda_1\alpha+\cdots+\lambda_6\alpha^6$ with $\lambda_i\in\mathbb{Q}$. But I get stuck here. How should I proceed?","Let $f=X^7+6X^3+3X+15\in\mathbb{Q}[x]$, and $\alpha\in\mathbb{C}$ such that $f(\alpha)=0$. I want to show $\sqrt{7}\notin\mathbb{Q}(\alpha)$ First of all, by Eisenstein's criterion, $f$ is irreducible in $Q[x]$, so we can say that $\deg (\text{Irr}(\alpha,\mathbb{Q}))=7=\left[\mathbb{Q}(\alpha):\mathbb{Q}\right]$. Then, $\left\{1,\alpha,\ldots,\alpha^6\right\}$ is a $\mathbb{Q}$-basis of $\mathbb{Q}(\alpha)$. Then, $\sqrt{7}\in\mathbb{Q}(\alpha)\Longleftrightarrow \sqrt{7}=\lambda_0 1+\lambda_1\alpha+\cdots+\lambda_6\alpha^6$ with $\lambda_i\in\mathbb{Q}$. But I get stuck here. How should I proceed?",,"['abstract-algebra', 'polynomials', 'field-theory', 'extension-field', 'irreducible-polynomials']"
97,A field is Noetherian,A field is Noetherian,,"I heard that a field is always Noetherian  and here Noetherian means that every ideal is finitely generated.  Then, because a field has two ideals, 0 and the field itself, does this mean every field have to be finitely generated? Where I got it wrong?","I heard that a field is always Noetherian  and here Noetherian means that every ideal is finitely generated.  Then, because a field has two ideals, 0 and the field itself, does this mean every field have to be finitely generated? Where I got it wrong?",,['abstract-algebra']
98,Infinite algebraic extension of a finite field,Infinite algebraic extension of a finite field,,"I have recently started studying algebraic field extensions and I got to know that algebraic closures $\overline{F}$ of finite fields $F$ are infinite. Therefore, I've asked myself the following question and couldn't come up with an answer. Suppose $F$ was a finite field, i.e. $|F| < \infty$. Is it possible to construct an algebraic extension $F'$ of $F$ sucht that $|F'| = \infty$ and $F' \subsetneq \overline{F}$? Meaning, that $F'$ is not algebraically closed.","I have recently started studying algebraic field extensions and I got to know that algebraic closures $\overline{F}$ of finite fields $F$ are infinite. Therefore, I've asked myself the following question and couldn't come up with an answer. Suppose $F$ was a finite field, i.e. $|F| < \infty$. Is it possible to construct an algebraic extension $F'$ of $F$ sucht that $|F'| = \infty$ and $F' \subsetneq \overline{F}$? Meaning, that $F'$ is not algebraically closed.",,"['abstract-algebra', 'finite-fields', 'field-theory']"
99,"Why is the extension $k(x,\sqrt{1-x^2})/k$ purely transcendental?",Why is the extension  purely transcendental?,"k(x,\sqrt{1-x^2})/k","Consider the function field $k(x,\sqrt{1-x^2})$ of the circle over an algebraically closed field $k$. Is $k(x,\sqrt{1-x^2})$ a purely transcendental extension over $k$? I'm curious because I was reading the answer here . The proof shows $k(x+\sqrt{1-x^2})=k(x,\sqrt{1-x^2})$. However, there is line which says,  $$ (x+\sqrt{1-x^2})^2 = x^2 + 2 \sqrt{1 - x^2} + (1 - x^2) = 2 \sqrt{1-x^2} + 1. $$ But I think $$ (x+\sqrt{1-x^2})^2 = x^2 + 2x\sqrt{1 - x^2} + (1 - x^2)=2x\sqrt{1-x^2}+1 $$ so, assuming $\operatorname{char}(k)\neq 2$, I believe at most one can conclude is $x\sqrt{1-x^2}\in k(x+\sqrt{1-x^2})$. I've been struggling to salvage this. How can you show $k(x,\sqrt{1-x^2})$ is a purely transcendental extension over $k$? Is the extension still purely transcendental when $\operatorname{char}(k)=2$?","Consider the function field $k(x,\sqrt{1-x^2})$ of the circle over an algebraically closed field $k$. Is $k(x,\sqrt{1-x^2})$ a purely transcendental extension over $k$? I'm curious because I was reading the answer here . The proof shows $k(x+\sqrt{1-x^2})=k(x,\sqrt{1-x^2})$. However, there is line which says,  $$ (x+\sqrt{1-x^2})^2 = x^2 + 2 \sqrt{1 - x^2} + (1 - x^2) = 2 \sqrt{1-x^2} + 1. $$ But I think $$ (x+\sqrt{1-x^2})^2 = x^2 + 2x\sqrt{1 - x^2} + (1 - x^2)=2x\sqrt{1-x^2}+1 $$ so, assuming $\operatorname{char}(k)\neq 2$, I believe at most one can conclude is $x\sqrt{1-x^2}\in k(x+\sqrt{1-x^2})$. I've been struggling to salvage this. How can you show $k(x,\sqrt{1-x^2})$ is a purely transcendental extension over $k$? Is the extension still purely transcendental when $\operatorname{char}(k)=2$?",,"['abstract-algebra', 'algebraic-geometry', 'field-theory', 'extension-field', 'algebraic-curves']"
