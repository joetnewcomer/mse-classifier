,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,A very basic probability question,A very basic probability question,,Suppose that I have $n$ objects and I make $m$ choices (with repetitions) out of the objects. Then what is the probability that no two of my choices are the same?,Suppose that I have $n$ objects and I make $m$ choices (with repetitions) out of the objects. Then what is the probability that no two of my choices are the same?,,['probability']
1,Probability of a fair die appearing to be biased,Probability of a fair die appearing to be biased,,"I'm interested in the probability of a die appearing to be biased when it is, in fact, fair. I'm trying to derive a result given, without proof, on YouTube: http://youtu.be/6guXMfg88Z8?t=1m29s The basic idea is this: you suspect a fair 20 sided die to be biased. The video claims that, if you roll your dice 100 times, there is a 1-in-50 chance of you getting an excess of threes by pure chance. I've tried to count the cases, but I'm getting into trouble. Let's say there are $k$ threes, then there are $$\frac{100!}{k! \ (100-k)!}$$ ways of distributing the threes amongst the 100 throws. The next part is where I'm getting stuck. I need to count the number of ways of distributing the other 19 numbers amongst the remaining $100-k$ throws. I suspect that this might be related to the number of partitions of $100-k$.","I'm interested in the probability of a die appearing to be biased when it is, in fact, fair. I'm trying to derive a result given, without proof, on YouTube: http://youtu.be/6guXMfg88Z8?t=1m29s The basic idea is this: you suspect a fair 20 sided die to be biased. The video claims that, if you roll your dice 100 times, there is a 1-in-50 chance of you getting an excess of threes by pure chance. I've tried to count the cases, but I'm getting into trouble. Let's say there are $k$ threes, then there are $$\frac{100!}{k! \ (100-k)!}$$ ways of distributing the threes amongst the 100 throws. The next part is where I'm getting stuck. I need to count the number of ways of distributing the other 19 numbers amongst the remaining $100-k$ throws. I suspect that this might be related to the number of partitions of $100-k$.",,"['probability', 'combinatorics', 'dice']"
2,Conditional probabilities and order of operation,Conditional probabilities and order of operation,,"I see terms of the form $P(A|B,C)$ a fair bit. Which of the following is true? $P(A|B,C)$ is the joint probability of $A|B$ and $C$ $P(A|B,C)$ is the probability of $A$ given both $B$ and $C$","I see terms of the form $P(A|B,C)$ a fair bit. Which of the following is true? $P(A|B,C)$ is the joint probability of $A|B$ and $C$ $P(A|B,C)$ is the probability of $A$ given both $B$ and $C$",,['probability']
3,Game Theory Matching a Deck of Cards,Game Theory Matching a Deck of Cards,,"Moderator Note: This question is from a contest which ended 1 Dec 2012. Suppose we have a deck of cards labeled from $1$ to $52$. Let them be shuffled in a random configuration, then made visible. Two players, player $A$ and $B$ play a game in which they try to organize the deck back to the order $1,2,3,...,52$. The players alternate turns with $A$ going first. The rules are as follows: i) On each turn, you may only switch adjacent cards. ii) Once a certain conﬁguration of cards has been reached, it may not be repeated. iii) The player that orders the deck as $1,2,3,...,52$ after his move wins. iv) If your opponent makes a move from where it is impossible to reach the configuration $1,2,3,...,52$, you win. v) If the cards are already initially ordered $1,2,3,...,52$, player $B$ wins. I have two questions regarding this game: If both $A$ and $B$ play optimally, how can you tell who wins? What is the probability that player $A$ wins? I was thinking along the broad lines of finding some sort of invariant, but other than that I have no clue. Any help is appreciated. Thank you!","Moderator Note: This question is from a contest which ended 1 Dec 2012. Suppose we have a deck of cards labeled from $1$ to $52$. Let them be shuffled in a random configuration, then made visible. Two players, player $A$ and $B$ play a game in which they try to organize the deck back to the order $1,2,3,...,52$. The players alternate turns with $A$ going first. The rules are as follows: i) On each turn, you may only switch adjacent cards. ii) Once a certain conﬁguration of cards has been reached, it may not be repeated. iii) The player that orders the deck as $1,2,3,...,52$ after his move wins. iv) If your opponent makes a move from where it is impossible to reach the configuration $1,2,3,...,52$, you win. v) If the cards are already initially ordered $1,2,3,...,52$, player $B$ wins. I have two questions regarding this game: If both $A$ and $B$ play optimally, how can you tell who wins? What is the probability that player $A$ wins? I was thinking along the broad lines of finding some sort of invariant, but other than that I have no clue. Any help is appreciated. Thank you!",,"['probability', 'game-theory', 'contest-math', 'card-games']"
4,What is the probability distribution of a single genome base pair,What is the probability distribution of a single genome base pair,,"in the genome we have 4 nucleotides (A,T,C,G). Now given a nucleotide sequence like AGT CG TA CG ATCT CG , we can count the number of ""CG"" pairs. That's 3 in this case. (we count all the pairs so, ACT has pairs AC and CT) Now I would like to test the significance of my results, or how likely is it that I would get 3 CG pairs if that sequence was random. I could test that with a permutation test, but that's not completely accurate and might also take time. Now the question: What is the probability distribution of such CG pair, given the length of the sequence and the count of each element (A,C,T,G), so that I could calculate the exact probability that my result could come from a random sequence.","in the genome we have 4 nucleotides (A,T,C,G). Now given a nucleotide sequence like AGT CG TA CG ATCT CG , we can count the number of ""CG"" pairs. That's 3 in this case. (we count all the pairs so, ACT has pairs AC and CT) Now I would like to test the significance of my results, or how likely is it that I would get 3 CG pairs if that sequence was random. I could test that with a permutation test, but that's not completely accurate and might also take time. Now the question: What is the probability distribution of such CG pair, given the length of the sequence and the count of each element (A,C,T,G), so that I could calculate the exact probability that my result could come from a random sequence.",,"['probability', 'combinatorics', 'sequences-and-series', 'probability-distributions']"
5,"Let X and Y be random variables with joint pdf $f(x,y)=x+y$ for $0<x<1$ and $0<y<1$. Are X and Y independent? My heart says yes but my math says no.",Let X and Y be random variables with joint pdf  for  and . Are X and Y independent? My heart says yes but my math says no.,"f(x,y)=x+y 0<x<1 0<y<1","I am using the fact that $X$ and $Y$ are independent if and only if $f_X(x)f_Y(y)=f(x,y)$. So I have $$f_{X} (x)=\int_{0}^{1}f(x,y)dy\\=\int_{0}^{1}x+ydy\\=[xy+\frac{y^{2}}{2}]_{y=0}^{y=1}\\=x+\frac{1}{2}$$ and by basically exactly the same math, $f_Y(y)=y+\frac{1}{2}$. Then $$f_X(x)f_y(y)=(x+\frac{1}{2})(y+\frac{1}{2})=xy+\frac{1}{2}(x+y)+\frac{1}{4}\ne f(x,y)$$ And hence they are not independent. But can that be right? Why would the value of X have anything to do with the value of Y? It's not like one is a function of the other. Or have I made a simple mistake? I looked through a couple of times and I'm pretty sure my math is right...","I am using the fact that $X$ and $Y$ are independent if and only if $f_X(x)f_Y(y)=f(x,y)$. So I have $$f_{X} (x)=\int_{0}^{1}f(x,y)dy\\=\int_{0}^{1}x+ydy\\=[xy+\frac{y^{2}}{2}]_{y=0}^{y=1}\\=x+\frac{1}{2}$$ and by basically exactly the same math, $f_Y(y)=y+\frac{1}{2}$. Then $$f_X(x)f_y(y)=(x+\frac{1}{2})(y+\frac{1}{2})=xy+\frac{1}{2}(x+y)+\frac{1}{4}\ne f(x,y)$$ And hence they are not independent. But can that be right? Why would the value of X have anything to do with the value of Y? It's not like one is a function of the other. Or have I made a simple mistake? I looked through a couple of times and I'm pretty sure my math is right...",,['probability']
6,Independent events and Dependent events,Independent events and Dependent events,,"I have a question regarding these strikingly similar problems with contradicting solutions. This is somewhat long, so prepare Probblem 1 Consider a bag of ten coins, nine are fair, but one is weighted with both sides heads. You randomly select a coin and toss it five times. Let $2s$ denote the event of selecting the weighted coin (that is the 2-sided coin) and $N$ be the even you select a regular coin and $5H$ be the event of getting five heads in a row. What is a) $P(5H | 2s)$ b) $P(5H | N)$ c) $P(5H)$ d) $P(2s | 5H)$ Solution 1 a) Simply 1 b) $\frac{1}{2^5}$ c) $\frac{1}{2^5}\frac{9}{10}+ \frac{1}{10} = \frac{41}{320}$ d) $P(2s|5H) = \dfrac{P(5H|2s)P(2s)}{P(5H)} = \frac{32}{41}$ From the Solution 1 , it seems that $P(2s|5H) \neq P(2s)P(5H)$ That is the event of picking out the weighted coin affects the probability of getting 5H. Here is part of my question, isn't there also some tiny probability of getting 5H from picking the normal one as well? Doesn't make sense why the events of picking the coin and getting 5H is dependent . Read on the next question Problem 2 A diagnostic test for an eye disease is 88% accurate of the time and 2.4% of the population actually has the disease. Let $ED$ be the event of having the eye disease and $p$ be the event of testing positive. Find the probability that a) the patient tests positive b) the patient has the disease and tests positive Solution 2 Here is a tree diagram a) $0.02122 + 0.011712 = 0.13824$ b) $P(ED | p) = \dfrac{P(\text{ED and p})}{P(p)} =\frac{0.02122}{0.13824 }= 0.1535$ From Solution 2 , it looks like $P(\text{ED and  p}) = P(\text{ED})P(p)$ which means that having the eye disease and testing positive are independent events? After trying out the same formula from Problem 1 , it also seems that $$P(\text{ED | p}) = \dfrac{P(\text{ED and  p})}{P(p)} = \dfrac{P(\text{p | ED})P(ED)}{P(p)} =  0.1535$$ Also, when the question asks ""the patient has the disease and tests positive"", how do I know that it is $P(ED | p)$ and not $P(p | ED)$? I am very confused in general with this. Could anyone clarify for me? Thanks","I have a question regarding these strikingly similar problems with contradicting solutions. This is somewhat long, so prepare Probblem 1 Consider a bag of ten coins, nine are fair, but one is weighted with both sides heads. You randomly select a coin and toss it five times. Let $2s$ denote the event of selecting the weighted coin (that is the 2-sided coin) and $N$ be the even you select a regular coin and $5H$ be the event of getting five heads in a row. What is a) $P(5H | 2s)$ b) $P(5H | N)$ c) $P(5H)$ d) $P(2s | 5H)$ Solution 1 a) Simply 1 b) $\frac{1}{2^5}$ c) $\frac{1}{2^5}\frac{9}{10}+ \frac{1}{10} = \frac{41}{320}$ d) $P(2s|5H) = \dfrac{P(5H|2s)P(2s)}{P(5H)} = \frac{32}{41}$ From the Solution 1 , it seems that $P(2s|5H) \neq P(2s)P(5H)$ That is the event of picking out the weighted coin affects the probability of getting 5H. Here is part of my question, isn't there also some tiny probability of getting 5H from picking the normal one as well? Doesn't make sense why the events of picking the coin and getting 5H is dependent . Read on the next question Problem 2 A diagnostic test for an eye disease is 88% accurate of the time and 2.4% of the population actually has the disease. Let $ED$ be the event of having the eye disease and $p$ be the event of testing positive. Find the probability that a) the patient tests positive b) the patient has the disease and tests positive Solution 2 Here is a tree diagram a) $0.02122 + 0.011712 = 0.13824$ b) $P(ED | p) = \dfrac{P(\text{ED and p})}{P(p)} =\frac{0.02122}{0.13824 }= 0.1535$ From Solution 2 , it looks like $P(\text{ED and  p}) = P(\text{ED})P(p)$ which means that having the eye disease and testing positive are independent events? After trying out the same formula from Problem 1 , it also seems that $$P(\text{ED | p}) = \dfrac{P(\text{ED and  p})}{P(p)} = \dfrac{P(\text{p | ED})P(ED)}{P(p)} =  0.1535$$ Also, when the question asks ""the patient has the disease and tests positive"", how do I know that it is $P(ED | p)$ and not $P(p | ED)$? I am very confused in general with this. Could anyone clarify for me? Thanks",,['probability']
7,Probability that a set of 'N' random binary strings are all at least a certain Hamming distance 'k' apart,Probability that a set of 'N' random binary strings are all at least a certain Hamming distance 'k' apart,,"Imagine I have a set of $N$ binary strings of length $L$, where I generate each string randomly (say, by flipping a coin for each bit).  What is the probability that all $N$ strings are at least a Hamming distance $k$ apart? I would be happy with a good lower bound estimate on the probability that all strings are unique.  We can estimate the relative sizes of $N$, $L$, and $k$ as: $N >> L$ (by at least an order of magnitude), $5 \leq L \leq 100$, and $k < L$.","Imagine I have a set of $N$ binary strings of length $L$, where I generate each string randomly (say, by flipping a coin for each bit).  What is the probability that all $N$ strings are at least a Hamming distance $k$ apart? I would be happy with a good lower bound estimate on the probability that all strings are unique.  We can estimate the relative sizes of $N$, $L$, and $k$ as: $N >> L$ (by at least an order of magnitude), $5 \leq L \leq 100$, and $k < L$.",,"['probability', 'combinatorics']"
8,Markov and independent random variables,Markov and independent random variables,,"This is a part of an exercise in Durrett's probability book. Consider the Markov chain on $\{1,2,\cdots,N\}$ with $p_{ij}=1/(i-1)$ when $j<i, p_{11}=1$ and $p_{ij}=0$ otherwise. Suppose that we start at point $k$. We let $I_j=1$ if $X_n$ visits $j$. Then $I_1,I_2,\cdots,I_{k-1}$ are independent. I don't find it obvious that $I_1,\cdots,I_{k-1}$ are independent. It is possible to prove the independence if we calculate all $P(\cap_{j\in J\subset\{1,\cdots,k-1\}}I_j)$, but this work is long and tedious. Since the independence was written as an obvious thing in this exercise, I assume that there is an easier way.","This is a part of an exercise in Durrett's probability book. Consider the Markov chain on $\{1,2,\cdots,N\}$ with $p_{ij}=1/(i-1)$ when $j<i, p_{11}=1$ and $p_{ij}=0$ otherwise. Suppose that we start at point $k$. We let $I_j=1$ if $X_n$ visits $j$. Then $I_1,I_2,\cdots,I_{k-1}$ are independent. I don't find it obvious that $I_1,\cdots,I_{k-1}$ are independent. It is possible to prove the independence if we calculate all $P(\cap_{j\in J\subset\{1,\cdots,k-1\}}I_j)$, but this work is long and tedious. Since the independence was written as an obvious thing in this exercise, I assume that there is an easier way.",,"['probability', 'markov-chains']"
9,subsets probability question,subsets probability question,,"Consider a set $\Omega$ with $N$ distinct members, and a function $f$ defined on $\Omega$ that takes the values 0,1 such that $ \frac{1}{N} \sum_{x \in \Omega } f(x)=p$. For a subset $S⊆Ω$ of size n, define the sample proportion $p:= p(S)= \frac{1}{n} \sum_{x\in S} f(x)$. If each subset of size $n$ is chosen with equal probability, calculate the expectation and standard deviation of the random variable $p$.","Consider a set $\Omega$ with $N$ distinct members, and a function $f$ defined on $\Omega$ that takes the values 0,1 such that $ \frac{1}{N} \sum_{x \in \Omega } f(x)=p$. For a subset $S⊆Ω$ of size n, define the sample proportion $p:= p(S)= \frac{1}{n} \sum_{x\in S} f(x)$. If each subset of size $n$ is chosen with equal probability, calculate the expectation and standard deviation of the random variable $p$.",,['probability']
10,Relationship between binomial and negative binomial distributions (how to extend the probability space?),Relationship between binomial and negative binomial distributions (how to extend the probability space?),,"I wonder a technique to extend the discrete probability space. Here's an example from Concrete Mathematics EXERCISE 8.17: Let $X_{n,p}$ and $Y_{n,p}$ have the binomial and negative binomial distributions, respectively, with parameters $(n,p)$. Prove that $\Pr(Y_{n,p}\le m) = \Pr(X_{m+n,p}\ge n)$. The answer to the problem is also from Concrete Mathematics : \begin{align} \Pr(Y_{n,p}\le m)  &= \Pr(Y_{n,p}+n \le m+n) \\ &= \hbox{probability that we need $\le m+n$} \tag{1}\\ &= \hbox{probability that $m+n$ tosses yield $\ge n$ heads} \tag{2} \\ &= \Pr(X_{m+n,p}\ge n) \end{align} Well, (1) and (2) are describing the same thing, but they're in different probability spaces, so we should extend these two probability spaces into a unique probability space, ensuring that the probability of each event doesn't change. How can we do it? I haven't a clear idea. And the more general problem arises: How to extend a probability space? Is there any technique to do it, at least, treat part of problems? Thanks for your help!","I wonder a technique to extend the discrete probability space. Here's an example from Concrete Mathematics EXERCISE 8.17: Let $X_{n,p}$ and $Y_{n,p}$ have the binomial and negative binomial distributions, respectively, with parameters $(n,p)$. Prove that $\Pr(Y_{n,p}\le m) = \Pr(X_{m+n,p}\ge n)$. The answer to the problem is also from Concrete Mathematics : \begin{align} \Pr(Y_{n,p}\le m)  &= \Pr(Y_{n,p}+n \le m+n) \\ &= \hbox{probability that we need $\le m+n$} \tag{1}\\ &= \hbox{probability that $m+n$ tosses yield $\ge n$ heads} \tag{2} \\ &= \Pr(X_{m+n,p}\ge n) \end{align} Well, (1) and (2) are describing the same thing, but they're in different probability spaces, so we should extend these two probability spaces into a unique probability space, ensuring that the probability of each event doesn't change. How can we do it? I haven't a clear idea. And the more general problem arises: How to extend a probability space? Is there any technique to do it, at least, treat part of problems? Thanks for your help!",,"['probability', 'probability-distributions']"
11,Generate the outcome of the flip of a fair coin (A question from A First Course In Probability by Ross),Generate the outcome of the flip of a fair coin (A question from A First Course In Probability by Ross),,"The book asks the question: Suppose that we want to generate the outcome   of the flip of a fair coin, but that all we have at   our disposal is a biased coin which lands on heads   with some unknown probability p that need not be   equal to 0.5. Could we use the procedure that continues   to flip the coin until the last two flips are   different and then lets the result be the outcome   of the final flip to generate the outcome of the flip of a fair coin ? An analysis made showed that the probability of answering H is $p(1-p)$ [this is since the only case that answers H is the case that the curent flip is H and the previews flip is T]. the same argument shows that the probability of answering T is also $p(1-p)$. I have 2 questions: Why, even if $p=0.5$ we get the conclusion that the probability of answering H is not 0.5 ? [I know $p(1-p) \not=0.5 $ for any real p, but what is the reason intuitivly ? My intuition  sais that by symmetry the answer is 0.5] How is it possible that we got $P(H)+P(T)\not=1$ ?","The book asks the question: Suppose that we want to generate the outcome   of the flip of a fair coin, but that all we have at   our disposal is a biased coin which lands on heads   with some unknown probability p that need not be   equal to 0.5. Could we use the procedure that continues   to flip the coin until the last two flips are   different and then lets the result be the outcome   of the final flip to generate the outcome of the flip of a fair coin ? An analysis made showed that the probability of answering H is $p(1-p)$ [this is since the only case that answers H is the case that the curent flip is H and the previews flip is T]. the same argument shows that the probability of answering T is also $p(1-p)$. I have 2 questions: Why, even if $p=0.5$ we get the conclusion that the probability of answering H is not 0.5 ? [I know $p(1-p) \not=0.5 $ for any real p, but what is the reason intuitivly ? My intuition  sais that by symmetry the answer is 0.5] How is it possible that we got $P(H)+P(T)\not=1$ ?",,"['probability', 'probability-theory']"
12,What are the restrictions on the covariance matrix of a nonnegative multivariate distribution.,What are the restrictions on the covariance matrix of a nonnegative multivariate distribution.,,"This question is a step in answering this question on the stats.se. Given a distribution $F(X_1,\ldots,X_n)$ on the nonnegative orthant $\mathbb{R}_+^n$ (i.e. each of the marginals is supported on the nonnegative reals).  Where the mean of each marginal is 1 (i.e. $E(X_i)=1$ for all $i$).  What are the restrictions on the covariance matrix (assuming that it exists, other than positive semi-definiteness)? The idea is to be able to recognize a covariance matrix as coming from a nonegative multivariate distribution.  For example $\pmatrix{4&-3\\-3& 4}$ is a perfectly fine covariance matrix, it is symmetric and positive definite, but it cannot come from a non-negative multivariate ditribution with mean $\mathbf 1$ because $\text{Cov}(X_1,X_2)=E(X_1X_2)-1\ge-1$ as $E(X_1X_2)$ is positive.  I am certain that this is not the only such restriction.","This question is a step in answering this question on the stats.se. Given a distribution $F(X_1,\ldots,X_n)$ on the nonnegative orthant $\mathbb{R}_+^n$ (i.e. each of the marginals is supported on the nonnegative reals).  Where the mean of each marginal is 1 (i.e. $E(X_i)=1$ for all $i$).  What are the restrictions on the covariance matrix (assuming that it exists, other than positive semi-definiteness)? The idea is to be able to recognize a covariance matrix as coming from a nonegative multivariate distribution.  For example $\pmatrix{4&-3\\-3& 4}$ is a perfectly fine covariance matrix, it is symmetric and positive definite, but it cannot come from a non-negative multivariate ditribution with mean $\mathbf 1$ because $\text{Cov}(X_1,X_2)=E(X_1X_2)-1\ge-1$ as $E(X_1X_2)$ is positive.  I am certain that this is not the only such restriction.",,"['probability', 'functional-analysis']"
13,How to calculate the probability of an event when you don't know the initial probabilities?,How to calculate the probability of an event when you don't know the initial probabilities?,,"Say there are two coins: coin A is fair, but coin B always comes up heads. A friend then flips one of the two coins, and you observe that the coin came up heads. How do you calculate the probability that this was coin A, when you don't know if your friend chose the coin randomly or not?","Say there are two coins: coin A is fair, but coin B always comes up heads. A friend then flips one of the two coins, and you observe that the coin came up heads. How do you calculate the probability that this was coin A, when you don't know if your friend chose the coin randomly or not?",,['probability']
14,Normal Distribution and Conditional Probability,Normal Distribution and Conditional Probability,,"Suppose that exam scores were distributed normally. Let the mean be 80 and standard deviation be 8. If it is known that a student's score is greater than 75, what is the probability that his score is greater than 90? I am a bit confused by the wording of the question. Should this be considered a case of conditional probability? Is my approach correct? This is know I thought about it: $$P(Y > 90 | Y >75) = \frac{P(Y > 90 \cap Y > 75)}{P(Y > 75)} = \frac{P(Y > 90)}{P(Y > 75)}.$$","Suppose that exam scores were distributed normally. Let the mean be 80 and standard deviation be 8. If it is known that a student's score is greater than 75, what is the probability that his score is greater than 90? I am a bit confused by the wording of the question. Should this be considered a case of conditional probability? Is my approach correct? This is know I thought about it: $$P(Y > 90 | Y >75) = \frac{P(Y > 90 \cap Y > 75)}{P(Y > 75)} = \frac{P(Y > 90)}{P(Y > 75)}.$$",,['probability']
15,How to find the moment generating function of this distribution,How to find the moment generating function of this distribution,,"If $f(x) = 0.5 e^{-|x|}$ for $-\infty < x < \infty$, how would you find the moment generating function for this? Also how would you find the distribution of $Y = |X|$? Attempt: $$E(e^{tX}) = \int_{-\infty}^\infty f(x) e^{tx} \; dx.$$","If $f(x) = 0.5 e^{-|x|}$ for $-\infty < x < \infty$, how would you find the moment generating function for this? Also how would you find the distribution of $Y = |X|$? Attempt: $$E(e^{tX}) = \int_{-\infty}^\infty f(x) e^{tx} \; dx.$$",,['probability']
16,Question on proof of Hoeffding identity,Question on proof of Hoeffding identity,,"In this paper , there is a proof of Hoeffding identity for covariance (see page 541 or page 5 in pdf file, Theorem 1.11). A part of the proof is the following equality: $$ 2\text{cov}(X,Y) = 2(E(XY)-E(X)E(Y))=E((X_1-X_2)(Y_1 - Y_2))$$ As far as I understand this transition is done by taking into account that$\ (X_1,Y_1)$ is iid copy of$\ (X_2,Y_2)$. It should be pretty simple, but I'm having hard time writing this explicitly. Can you please give me a hint?","In this paper , there is a proof of Hoeffding identity for covariance (see page 541 or page 5 in pdf file, Theorem 1.11). A part of the proof is the following equality: $$ 2\text{cov}(X,Y) = 2(E(XY)-E(X)E(Y))=E((X_1-X_2)(Y_1 - Y_2))$$ As far as I understand this transition is done by taking into account that$\ (X_1,Y_1)$ is iid copy of$\ (X_2,Y_2)$. It should be pretty simple, but I'm having hard time writing this explicitly. Can you please give me a hint?",,['probability']
17,Cards and probability,Cards and probability,,"There are four cards in a hat. Three cards have 0 on one side and 1 on the other, while the fourth card has a 0 on both sides. If I observe that one side of a card I have chosen at random has a 0 on it, what is the probability of the card I have chosen being the one with 0 on both sides? I think the answer's $\frac{2}{5}$ since we're accounting for sides only. We have five sides with a 0, and the two sided card has two of those 0s. Am I making a mistake?","There are four cards in a hat. Three cards have 0 on one side and 1 on the other, while the fourth card has a 0 on both sides. If I observe that one side of a card I have chosen at random has a 0 on it, what is the probability of the card I have chosen being the one with 0 on both sides? I think the answer's $\frac{2}{5}$ since we're accounting for sides only. We have five sides with a 0, and the two sided card has two of those 0s. Am I making a mistake?",,['probability']
18,One ball is drawn from 2 boxes of white/black balls. What is the probability of getting one ball of each color?,One ball is drawn from 2 boxes of white/black balls. What is the probability of getting one ball of each color?,,"In box A there are $7$ white balls and $5$ black balls. In box B there are $2$ white balls and $4$ black balls.   One ball is drawn from each box. What is the probability of getting one ball of each color? In order to find the possible cases I multiplied the 12 balls in the box A by the $6$ balls in box B. There are $72$ possible cases. Then I set $2$ different events: A-""draw a ball from box A"". W-""draw a white ball"". Then I thought, there are $2$ situations where the drawn balls can have different colors.I can remove a black ball from box A and a white ball from box B or the inverse. $P(\bar{W}|A) \cdot P(W|\bar{A})=\frac{5}{12}\cdot \frac{2}{6}=\frac{10}{72}$ $P(W|A) \cdot P(\bar{W}|\bar{A})=\frac{7}{12} \cdot \frac{4}{6}=\frac{28}{72}$ Then I added the two probabilities:$\frac{38}{72}$ But the result don't mix with the book solutions. Who is wrong? Thanks. The book solution is $\frac{19}{72}$","In box A there are $7$ white balls and $5$ black balls. In box B there are $2$ white balls and $4$ black balls.   One ball is drawn from each box. What is the probability of getting one ball of each color? In order to find the possible cases I multiplied the 12 balls in the box A by the $6$ balls in box B. There are $72$ possible cases. Then I set $2$ different events: A-""draw a ball from box A"". W-""draw a white ball"". Then I thought, there are $2$ situations where the drawn balls can have different colors.I can remove a black ball from box A and a white ball from box B or the inverse. $P(\bar{W}|A) \cdot P(W|\bar{A})=\frac{5}{12}\cdot \frac{2}{6}=\frac{10}{72}$ $P(W|A) \cdot P(\bar{W}|\bar{A})=\frac{7}{12} \cdot \frac{4}{6}=\frac{28}{72}$ Then I added the two probabilities:$\frac{38}{72}$ But the result don't mix with the book solutions. Who is wrong? Thanks. The book solution is $\frac{19}{72}$",,[]
19,"Chance to pick 3 balls out of 6 (with replacement, order doesn't matter)","Chance to pick 3 balls out of 6 (with replacement, order doesn't matter)",,"You have an urn with 6 numbered balls and you pull out 3 (with replacement).  What is the chance of getting 3 different numbers when the order doesn't matter? I have two solutions that both seem reasonable. Looking at chances: Chance to pick the first ball: 6/6 Chance to pick the second ball: 5/6 Chance to pick the third ball: 4/6 i.e. 20/36 Looking at possibilities (combinatorics): To get 3 different balls out of a urn with 6 when no number can be repeated and the order doesn't matter is the same as a lottery. Therefore there are  ${6 \choose 3}$ = 20  possibilities. Looking at all possibilities, I have 6*6*6 = 216. i.e. 20/216 Which one is wrong and why?","You have an urn with 6 numbered balls and you pull out 3 (with replacement).  What is the chance of getting 3 different numbers when the order doesn't matter? I have two solutions that both seem reasonable. Looking at chances: Chance to pick the first ball: 6/6 Chance to pick the second ball: 5/6 Chance to pick the third ball: 4/6 i.e. 20/36 Looking at possibilities (combinatorics): To get 3 different balls out of a urn with 6 when no number can be repeated and the order doesn't matter is the same as a lottery. Therefore there are  ${6 \choose 3}$ = 20  possibilities. Looking at all possibilities, I have 6*6*6 = 216. i.e. 20/216 Which one is wrong and why?",,"['probability', 'combinatorics']"
20,Showing a function of random walk is a martingale,Showing a function of random walk is a martingale,,"I would like a hint for the following problem: Consider a biased random walk on the integers with probability $p<1/2$ of moving to the right and probability $1-p$ of moving to the left.  Let $S_n$ be the value at time $n$ and assume that $S_0=a$, where $0<a<N$. Show that $M_n=[(1-p)/p]^{S_{n}}$ is a martingale. I need to show that $\mathbb{E}[M_{n+1}|S_{0}, \dots S_{n}] = M_{n}$. However $$ \begin{align} \mathbb{E}[M_{n+1}|S_{0}, \dots, S_{n}] &= \mathbb{E}[[(1-p)/p]^{S_{n+1}}|S_{0}, \dots, S_{n}] \\ &= \mathbb{E}[[(1-p)/p]^{S_{n+1}}|S_{n}] &&\text{(By Markovity.)} \\ &= [(1-p)/p]^{p(S_{n}+1) + (1-p)(S_{n}-1)} \\ &= [(1-p)/p]^{S_{n}+2p-1}, \end{align} $$ which is not what I need. So it seems that either I'm making a mistake or the problem is wrong. Am I making a mistake? Is $M_n$ a martingale?","I would like a hint for the following problem: Consider a biased random walk on the integers with probability $p<1/2$ of moving to the right and probability $1-p$ of moving to the left.  Let $S_n$ be the value at time $n$ and assume that $S_0=a$, where $0<a<N$. Show that $M_n=[(1-p)/p]^{S_{n}}$ is a martingale. I need to show that $\mathbb{E}[M_{n+1}|S_{0}, \dots S_{n}] = M_{n}$. However $$ \begin{align} \mathbb{E}[M_{n+1}|S_{0}, \dots, S_{n}] &= \mathbb{E}[[(1-p)/p]^{S_{n+1}}|S_{0}, \dots, S_{n}] \\ &= \mathbb{E}[[(1-p)/p]^{S_{n+1}}|S_{n}] &&\text{(By Markovity.)} \\ &= [(1-p)/p]^{p(S_{n}+1) + (1-p)(S_{n}-1)} \\ &= [(1-p)/p]^{S_{n}+2p-1}, \end{align} $$ which is not what I need. So it seems that either I'm making a mistake or the problem is wrong. Am I making a mistake? Is $M_n$ a martingale?",,"['probability', 'martingales']"
21,The probability of obtaining at least one roll of x from k dice each with a different number of faces,The probability of obtaining at least one roll of x from k dice each with a different number of faces,,"Assume you have k dice, each with some random number of sides, 1...n.  I'm trying to figure out, after rolling all k dice, what is the probability of obtaining at least one roll with a given value x - say, perhaps, 1?  What is the probability of obtaining no 1s at all?  I can write this by hand for 2-3 dice, and I'm trying to see if there's a way to write it for k dice. And can this be generalized to a point where, say, some of your dice have no 1s on them to begin with?  So the probability of rolling a 1 for that particular die = 0.","Assume you have k dice, each with some random number of sides, 1...n.  I'm trying to figure out, after rolling all k dice, what is the probability of obtaining at least one roll with a given value x - say, perhaps, 1?  What is the probability of obtaining no 1s at all?  I can write this by hand for 2-3 dice, and I'm trying to see if there's a way to write it for k dice. And can this be generalized to a point where, say, some of your dice have no 1s on them to begin with?  So the probability of rolling a 1 for that particular die = 0.",,"['probability', 'probability-theory', 'dice']"
22,Samples in the convex body vs. samples on the convex surface,Samples in the convex body vs. samples on the convex surface,,"Let $K$ be a bounded convex body in $\mathbb{R}^n$. Suppose we have a sampler $\mathcal{S}_1$ that can generate points uniformly distributed in $\mathrm{int}K$, and another sampler $\mathcal{S}_2$ that can generate points uniformly distributed on $\partial K$. The figure below illustrates two samplers. Let $\{\mathbf{x}^j\}_{j=1}^M$ be $M$ samples generated by $\mathcal{S_1}$ and $\{\mathbf{y}^j\}_{j=1}^M$ by $M$ samples generated by $\mathcal{S_2}$. Denote the empirical centroid $\mathbf{u}$, $\mathbf{v}$ as $\mathbf{u}=\frac{1}{M}\sum_j \mathbf{x}^j$ and $\mathbf{v}=\frac{1}{M}\sum_j \mathbf{y}^j$, respectively. My questions are: Are $\mathbf{u}$ and $\mathbf{v}$ same or not? If not, can anyone provide a lower and upper bound of $\|\mathbf{u}-\mathbf{v}\|$? Thanks","Let $K$ be a bounded convex body in $\mathbb{R}^n$. Suppose we have a sampler $\mathcal{S}_1$ that can generate points uniformly distributed in $\mathrm{int}K$, and another sampler $\mathcal{S}_2$ that can generate points uniformly distributed on $\partial K$. The figure below illustrates two samplers. Let $\{\mathbf{x}^j\}_{j=1}^M$ be $M$ samples generated by $\mathcal{S_1}$ and $\{\mathbf{y}^j\}_{j=1}^M$ by $M$ samples generated by $\mathcal{S_2}$. Denote the empirical centroid $\mathbf{u}$, $\mathbf{v}$ as $\mathbf{u}=\frac{1}{M}\sum_j \mathbf{x}^j$ and $\mathbf{v}=\frac{1}{M}\sum_j \mathbf{y}^j$, respectively. My questions are: Are $\mathbf{u}$ and $\mathbf{v}$ same or not? If not, can anyone provide a lower and upper bound of $\|\mathbf{u}-\mathbf{v}\|$? Thanks",,"['probability', 'geometry', 'statistics', 'sampling']"
23,Monotonic transformation of continuous random variable are continuous,Monotonic transformation of continuous random variable are continuous,,"This appeared as a throwaway statement in a proof - that a strictly monotonic (increasing) transformation of a continuously distributed random variable (I am assuming that this means that the distribution function is continuous, not that the random variable is absolutely continuous) is also a continuously distributed random variable. So the setup $X:\left(\Omega, \mathscr{F}, \mathbb{P}\right) \longmapsto \left(\mathbb{R}, \mathscr{B}(\mathbb{R}), \mathbb{P}_X\right)$ and $h: \mathbb{R} \longmapsto \mathbb{R}$ and $h(X) = Y$, where clearly $h$ needs to be measurable. So the claim is that if $h$ is monotonic, then $Y$ is a continuously distributed random variable. A proof or a reference to a textbook would be appreciated.","This appeared as a throwaway statement in a proof - that a strictly monotonic (increasing) transformation of a continuously distributed random variable (I am assuming that this means that the distribution function is continuous, not that the random variable is absolutely continuous) is also a continuously distributed random variable. So the setup $X:\left(\Omega, \mathscr{F}, \mathbb{P}\right) \longmapsto \left(\mathbb{R}, \mathscr{B}(\mathbb{R}), \mathbb{P}_X\right)$ and $h: \mathbb{R} \longmapsto \mathbb{R}$ and $h(X) = Y$, where clearly $h$ needs to be measurable. So the claim is that if $h$ is monotonic, then $Y$ is a continuously distributed random variable. A proof or a reference to a textbook would be appreciated.",,"['probability', 'statistics', 'measure-theory', 'probability-theory', 'probability-distributions']"
24,What is the probability of picking a random prime < n?,What is the probability of picking a random prime < n?,,"If I shoot in the dark and pick a random number that's $<n$, what's the probability that the number will be prime? How many guesses, on average, would it take to get a prime number? I would really like to understand the reasoning behind the answer, and not just a one-line formula.","If I shoot in the dark and pick a random number that's $<n$, what's the probability that the number will be prime? How many guesses, on average, would it take to get a prime number? I would really like to understand the reasoning behind the answer, and not just a one-line formula.",,"['probability', 'prime-numbers']"
25,Probability of a binary event,Probability of a binary event,,"Let's say we have a parameter $r$ and a binary event $A$ repeatedly happens. The event is binary, so the outcome is either $0$ or $1$. We have collected a lot of data of the form $\{\{r_1,A_1\},\{r_2,A_2\},\cdots,\{r_n,A_n\}\}$ where $r_i\in\mathbb{R}$ and $A_i\in\{0,1\}$. For example: $\{\{-3,0\},\{-2,1\},\{2,1\},\{2,1\},\{1,0\}\}$ Can we somehow estimate the probability of $A$ being $1$ for a certain $r$. From the example data, it seems when $r=2$ that $A=1$ quite certainly. But the data sample is very very large and I'm totally at a loss at how to estimate this probability. When there are a lot of positive outcomes for certain values of $r$ than that increases the probability of a positive outcome for other values close to $r$. How can all this be accumulated in order to predict (and how confidently) the probability of a positive outcome once we set an arbitrary $r$?","Let's say we have a parameter $r$ and a binary event $A$ repeatedly happens. The event is binary, so the outcome is either $0$ or $1$. We have collected a lot of data of the form $\{\{r_1,A_1\},\{r_2,A_2\},\cdots,\{r_n,A_n\}\}$ where $r_i\in\mathbb{R}$ and $A_i\in\{0,1\}$. For example: $\{\{-3,0\},\{-2,1\},\{2,1\},\{2,1\},\{1,0\}\}$ Can we somehow estimate the probability of $A$ being $1$ for a certain $r$. From the example data, it seems when $r=2$ that $A=1$ quite certainly. But the data sample is very very large and I'm totally at a loss at how to estimate this probability. When there are a lot of positive outcomes for certain values of $r$ than that increases the probability of a positive outcome for other values close to $r$. How can all this be accumulated in order to predict (and how confidently) the probability of a positive outcome once we set an arbitrary $r$?",,"['probability', 'statistics']"
26,Question on distribution of the sum of indicator variable,Question on distribution of the sum of indicator variable,,"Let $X_1,\dots,X_n$ are i.i.d random variables with geometric distribution, and the successful probability is $p$ for each $X_i$. So for any $X_i$, the probability mass function is $\Pr(X_i=k)=(1-p)^{k-1}p$ Define a list of indicator variables $Y_1,\dots,Y_n$, which for  an integer $b>0$, $$ Y_i=\left\{ \begin{aligned} 1 && X_i \le b\\ 0 && X_i >b  \end{aligned} \right. $$ So my question is what is the distribution of $\sum\limits_{i=1}^n Y_i?$","Let $X_1,\dots,X_n$ are i.i.d random variables with geometric distribution, and the successful probability is $p$ for each $X_i$. So for any $X_i$, the probability mass function is $\Pr(X_i=k)=(1-p)^{k-1}p$ Define a list of indicator variables $Y_1,\dots,Y_n$, which for  an integer $b>0$, $$ Y_i=\left\{ \begin{aligned} 1 && X_i \le b\\ 0 && X_i >b  \end{aligned} \right. $$ So my question is what is the distribution of $\sum\limits_{i=1}^n Y_i?$",,['probability']
27,Finding the probability that red ball is among the $10$ balls,Finding the probability that red ball is among the  balls,10,"A box contains $20$ balls all of different colors including the red color. If we select $10$ balls randomly without replacement, what is the probability that the red ball will be among these $10$ balls? What I think is that: If we let $X$ to be the number of balls we select until we get the red ball, then $X$ will be a random variable with range $ 1,2,3, \ldots ,20 $, and the probability of getting the red ball will be $1/20$, so our probability will be $$\left(\frac{1}{20} \right)^{10} ,$$ is that right?! I'm not sure about the distribution of $X$?","A box contains $20$ balls all of different colors including the red color. If we select $10$ balls randomly without replacement, what is the probability that the red ball will be among these $10$ balls? What I think is that: If we let $X$ to be the number of balls we select until we get the red ball, then $X$ will be a random variable with range $ 1,2,3, \ldots ,20 $, and the probability of getting the red ball will be $1/20$, so our probability will be $$\left(\frac{1}{20} \right)^{10} ,$$ is that right?! I'm not sure about the distribution of $X$?",,"['probability', 'combinatorics']"
28,Expected value for a random variable,Expected value for a random variable,,"I have 25000 numbers and I randomly pick one by ony until I get one that I've already picked. I want to know the expected number of picks that need to be made. The expected value in my opinion should be calculated as 1/25000*1 + (24999/25000)*(2/25000) 2 + (24999/25000) (24998/25000)*(3/25000)*3 + ... Is this formula correct? What would be the solution? Best, Will","I have 25000 numbers and I randomly pick one by ony until I get one that I've already picked. I want to know the expected number of picks that need to be made. The expected value in my opinion should be calculated as 1/25000*1 + (24999/25000)*(2/25000) 2 + (24999/25000) (24998/25000)*(3/25000)*3 + ... Is this formula correct? What would be the solution? Best, Will",,['probability']
29,Incandescent light bulb lifetime - exponential distribution?,Incandescent light bulb lifetime - exponential distribution?,,"It's been said that incandescent light bulbs lifetime has exponential distribution. As I understand, this means a 10,000 hours time-to-failure has the same probability no matter how long the light bulb was used until now (i.e. the ""memorylessness"" property). On the other hand, Wikipedia says that ""(a light bulb's) Lifetime is approximately proportional to $V^{−16}$"". Doesn't this mean that if the lifetime is 10,000 hours and 5,000 hours have passed, failure in 10,000 hours is less likely than in 5,000 hours?","It's been said that incandescent light bulbs lifetime has exponential distribution. As I understand, this means a 10,000 hours time-to-failure has the same probability no matter how long the light bulb was used until now (i.e. the ""memorylessness"" property). On the other hand, Wikipedia says that ""(a light bulb's) Lifetime is approximately proportional to $V^{−16}$"". Doesn't this mean that if the lifetime is 10,000 hours and 5,000 hours have passed, failure in 10,000 hours is less likely than in 5,000 hours?",,"['probability', 'probability-distributions', 'physics']"
30,What is the average rotation angle needed to change the color of a sphere?,What is the average rotation angle needed to change the color of a sphere?,,"A sphere is painted in black and white. We are looking in the direction of the center of the sphere and see, in the direction of our vision, a point with a given color. When the sphere is rotated, at the end of the rotation we might see the same or a different color. The coloring of the sphere is given; we know how the white and black color is distributed. The coloring is also ""nice"" (no fractals); the black patches have borders that are smooth and infinitely differentiable curves. How can I calculate the average angle required to change from black to white? The question is very general. So a simple sub-case would be: if one hemisphere of the sphere is black, the other is white, and if one starts in a situation where the random starting point is black, what would the average angle be? Starting from this subcase, what would be the way to calculate the average angle for a general black-and-white coloring?","A sphere is painted in black and white. We are looking in the direction of the center of the sphere and see, in the direction of our vision, a point with a given color. When the sphere is rotated, at the end of the rotation we might see the same or a different color. The coloring of the sphere is given; we know how the white and black color is distributed. The coloring is also ""nice"" (no fractals); the black patches have borders that are smooth and infinitely differentiable curves. How can I calculate the average angle required to change from black to white? The question is very general. So a simple sub-case would be: if one hemisphere of the sphere is black, the other is white, and if one starts in a situation where the random starting point is black, what would the average angle be? Starting from this subcase, what would be the way to calculate the average angle for a general black-and-white coloring?",,"['probability', 'geometry', 'stochastic-processes', 'computational-geometry', 'spherical-geometry']"
31,"What's the probability of rolling at least $k$ on $n$ dice with $s_1,\ldots,s_n$ sides?",What's the probability of rolling at least  on  dice with  sides?,"k n s_1,\ldots,s_n","Is there a way to determine the chance of rolling at least $k$ on $n$ dice with $s_1,\ldots,s_n$ sides? Example: What is the chance of rolling a sum of at least 13 on 3 dice with 6, 8, and 10 sides? I know that the chance of rolling exactly $k$ on $n$ dice with $s$ sides is $$F_{s,n}(k)=\sum_{i=1}^{k-n+1} F_{s,1}(i)F_{s,n-1}(k-1)$$ where $F_{s,1}(k)=\frac{1}{s}$ for all $1\leq k\leq s$ and $0$ otherwise (see this Wikipedia page ), but I am not sure how to either generalize it for differently sided dice or combine it for different values of $s$. Note: This will be done programmatically so efficiency is very important to me.","Is there a way to determine the chance of rolling at least $k$ on $n$ dice with $s_1,\ldots,s_n$ sides? Example: What is the chance of rolling a sum of at least 13 on 3 dice with 6, 8, and 10 sides? I know that the chance of rolling exactly $k$ on $n$ dice with $s$ sides is $$F_{s,n}(k)=\sum_{i=1}^{k-n+1} F_{s,1}(i)F_{s,n-1}(k-1)$$ where $F_{s,1}(k)=\frac{1}{s}$ for all $1\leq k\leq s$ and $0$ otherwise (see this Wikipedia page ), but I am not sure how to either generalize it for differently sided dice or combine it for different values of $s$. Note: This will be done programmatically so efficiency is very important to me.",,"['probability', 'dice']"
32,Questions about geometric distribution,Questions about geometric distribution,,"I have some trouble understanding the record value for a sequence of i.i.d. random variables of geometric distribution. Following quotation is from Univariate discrete distributions By Norman Lloyd Johnson, Adrienne W. Kemp, Samuel Kotz . The lack-of-memory property of the   geometric distribution gives it a role   comparable to that of the exponential   distribution. There are a number of   characterizations of the geometric   distribution based on record values. For the  record time $T_n$, If $X_j$ is observed at time $j$ ,   then the record time sequence $\{T_n ,n \geq 0\}$ is defined as   $T_0 = 1$   with probability $1$ and $T_n = \min\{j : X_j > X_{t_{n−1}} \}$ for   $n\geq 1$. Is there a typo in $T_n = \min \{j : X_j >     X_{t_{n−1}} \}$? Should it be instead $T_n     = \min\{j : X_j > X_{T_{n−1}} \}$? For the  record value $R_n$, The record value sequence   $\{R_n \}$ is defined as $R_n =X_{T_n} , n = 0, 1, 2, ...$. Suppose   that the $X_j$ ’s are iid geometric   variables with pmf $$p_x = p(1 − p)^{x−1}, x = 1, 2, ...$$ Then $R_n     =X_{T_n} = \sum_{j=0}^{n} X_j$ is   distributed as the sum of $n + 1$ iid   geometric variables. why does the second equality in ""$R_n =X_{T_n} = \sum_{j=0}^{n} X_j$ "" hold? For the process of the record values $\{ R_n, n \in \mathbb{N}\}$, Each of the following properties   characterizes the geometric   distribution: (i) Independence: The rv’s $R_0 , R_1  - R_0 , ... , R_{n+1} - R_n ,...$ are independent. (ii) Same Distribution: $R_{n+1} - R_n$ has the same distribution as   $R_0$ . (iii) Constant Regression: $E[R_{n+1}- R_n |R_n ]$ is constant. How to show that the three properties hold? Are they derived from the memoryless property of geometric distribution? What else can we say about the process based on the memoryless property of geometric distribution? Thanks for your advice!","I have some trouble understanding the record value for a sequence of i.i.d. random variables of geometric distribution. Following quotation is from Univariate discrete distributions By Norman Lloyd Johnson, Adrienne W. Kemp, Samuel Kotz . The lack-of-memory property of the   geometric distribution gives it a role   comparable to that of the exponential   distribution. There are a number of   characterizations of the geometric   distribution based on record values. For the  record time $T_n$, If $X_j$ is observed at time $j$ ,   then the record time sequence $\{T_n ,n \geq 0\}$ is defined as   $T_0 = 1$   with probability $1$ and $T_n = \min\{j : X_j > X_{t_{n−1}} \}$ for   $n\geq 1$. Is there a typo in $T_n = \min \{j : X_j >     X_{t_{n−1}} \}$? Should it be instead $T_n     = \min\{j : X_j > X_{T_{n−1}} \}$? For the  record value $R_n$, The record value sequence   $\{R_n \}$ is defined as $R_n =X_{T_n} , n = 0, 1, 2, ...$. Suppose   that the $X_j$ ’s are iid geometric   variables with pmf $$p_x = p(1 − p)^{x−1}, x = 1, 2, ...$$ Then $R_n     =X_{T_n} = \sum_{j=0}^{n} X_j$ is   distributed as the sum of $n + 1$ iid   geometric variables. why does the second equality in ""$R_n =X_{T_n} = \sum_{j=0}^{n} X_j$ "" hold? For the process of the record values $\{ R_n, n \in \mathbb{N}\}$, Each of the following properties   characterizes the geometric   distribution: (i) Independence: The rv’s $R_0 , R_1  - R_0 , ... , R_{n+1} - R_n ,...$ are independent. (ii) Same Distribution: $R_{n+1} - R_n$ has the same distribution as   $R_0$ . (iii) Constant Regression: $E[R_{n+1}- R_n |R_n ]$ is constant. How to show that the three properties hold? Are they derived from the memoryless property of geometric distribution? What else can we say about the process based on the memoryless property of geometric distribution? Thanks for your advice!",,"['probability', 'statistics', 'stochastic-processes', 'probability-distributions']"
33,Probability from a collection of independent predictions,Probability from a collection of independent predictions,,"Reframed question: Team A and Team B will be playing each other in a sporting event where there is one winner and one loser; a tie is impossible.  A man, wanting to make money from placing a bet on the winner, consults with three omniscient seers.  These seers know the outcome of the game already, being omniscient. The first seer informs the man (truthfully) that he randomly lies 20% of the time when telling the outcome of a sporting event, telling the truth the rest of the time. The second seer says (truthfully) that he is just like the first, except he lies 40% of the time. The third seer says (truthfully) that he is just like the first and second seers, except he lies 70% of the time. The first seer tells the man that team A will win. The second seer tells the man that team A will lose. The third seer tells the man that team A will win. What is the probability that team A will win? Each seers' determination of whether to lie is independent of the others.  You can imagine that each seer rolls a ten sided die to make their decision of whether to lie. After the above question is answered, I am curious if someone can come up with a general formula for any number of seers with any probability of lying, with any set of predictions.","Reframed question: Team A and Team B will be playing each other in a sporting event where there is one winner and one loser; a tie is impossible.  A man, wanting to make money from placing a bet on the winner, consults with three omniscient seers.  These seers know the outcome of the game already, being omniscient. The first seer informs the man (truthfully) that he randomly lies 20% of the time when telling the outcome of a sporting event, telling the truth the rest of the time. The second seer says (truthfully) that he is just like the first, except he lies 40% of the time. The third seer says (truthfully) that he is just like the first and second seers, except he lies 70% of the time. The first seer tells the man that team A will win. The second seer tells the man that team A will lose. The third seer tells the man that team A will win. What is the probability that team A will win? Each seers' determination of whether to lie is independent of the others.  You can imagine that each seer rolls a ten sided die to make their decision of whether to lie. After the above question is answered, I am curious if someone can come up with a general formula for any number of seers with any probability of lying, with any set of predictions.",,"['probability', 'statistics']"
34,$20$% in one year vs $4$% per year over $5$ years,% in one year vs % per year over  years,20 4 5,I am looking for information for some extended family members. A medical procedure has a $4$% chance of stroke per year over $5$ years.  One family member has said that that is a $20$% chance of stroke over all ($5\times 4$%).  Others argue that it is less because $4$% each year is smaller.  I am not sure how to frame this question in order to get an accurate answer.  Is the chance of something happening being $4$% a year for $5$ years the same as say an instantaneous $20$% chance of something happening?,I am looking for information for some extended family members. A medical procedure has a $4$% chance of stroke per year over $5$ years.  One family member has said that that is a $20$% chance of stroke over all ($5\times 4$%).  Others argue that it is less because $4$% each year is smaller.  I am not sure how to frame this question in order to get an accurate answer.  Is the chance of something happening being $4$% a year for $5$ years the same as say an instantaneous $20$% chance of something happening?,,['probability']
35,Probability in a game of Contract Bridge,Probability in a game of Contract Bridge,,"in a game of contract bridge, partner and me together have 11 cards in a suite. The remaining 2 cards in the same suite can be distributed amongst our opponents as either 1-1 or 2-0. What is the probability that it will be distributed as 1-1 and what is the probability it will be distributed as 2-0? Once the above is solved, how can you extend it if more cards are missing. That is, let us assume that partner and me have 8 cards between us. How do you calculate the probability for the distributions (5-0, 4-1, 3-2)?","in a game of contract bridge, partner and me together have 11 cards in a suite. The remaining 2 cards in the same suite can be distributed amongst our opponents as either 1-1 or 2-0. What is the probability that it will be distributed as 1-1 and what is the probability it will be distributed as 2-0? Once the above is solved, how can you extend it if more cards are missing. That is, let us assume that partner and me have 8 cards between us. How do you calculate the probability for the distributions (5-0, 4-1, 3-2)?",,"['probability', 'card-games']"
36,Probability Distribution with different probabilities,Probability Distribution with different probabilities,,"Suppose there are 9 events, that have a probability of 10%, 20%, 30%, ..., 90% of being a success. How would I find the probability of exactly n number of these events succeeding? For n = 1, I'm thinking it is something like (first succeeds) -> (1-0.9) * 0.8 * 0.7 * 0.6 ... 0.1 (second succeeds) -> 0.9 * (1-0.8) * 0.7 * 0.6 ... 0.1 (...) (last) and then adding them up. The probabilities might not always be an an Arithmetic Progression, hoping to find a solution that doesn't depend on that.","Suppose there are 9 events, that have a probability of 10%, 20%, 30%, ..., 90% of being a success. How would I find the probability of exactly n number of these events succeeding? For n = 1, I'm thinking it is something like (first succeeds) -> (1-0.9) * 0.8 * 0.7 * 0.6 ... 0.1 (second succeeds) -> 0.9 * (1-0.8) * 0.7 * 0.6 ... 0.1 (...) (last) and then adding them up. The probabilities might not always be an an Arithmetic Progression, hoping to find a solution that doesn't depend on that.",,['combinatorics']
37,Transformation of Random Variables,Transformation of Random Variables,,Suppose $f_{X}(x) = xe^{-x^2/2}$ for $x>0$ and $Y = \ln X$. Find the density function for $Y$. So we want to find $P(Y \leq y)$. This is the same thing as $P(\ln X \leq y)$ or $P(X \leq e^{y})$. Thus $f_{Y}(y) = f_{X}(e^y)$? Or does $f_{Y}(y) = F_{X}(e^y)$ since $P(X \leq x) = F_{X}(x)$?,Suppose $f_{X}(x) = xe^{-x^2/2}$ for $x>0$ and $Y = \ln X$. Find the density function for $Y$. So we want to find $P(Y \leq y)$. This is the same thing as $P(\ln X \leq y)$ or $P(X \leq e^{y})$. Thus $f_{Y}(y) = f_{X}(e^y)$? Or does $f_{Y}(y) = F_{X}(e^y)$ since $P(X \leq x) = F_{X}(x)$?,,['probability']
38,Does $E[E[X|X\le Y]]=E[X]$?,Does ?,E[E[X|X\le Y]]=E[X],"This is a question I came up with while doing some related calculations. Let $X$ be a random variable defined on some probability space $(\Omega, \mathcal A, P)$ . To make everything as nicely behaved as possible, let $X$ be supported on $[a,b]\subset \mathbb R$ , and assume that $X$ has a density $f$ that is continuous and strictly positive on $[a, b]$ . Denote the cdf of $X$ by $F$ . Define $\phi: [a,b]\to \mathbb R$ by $$ \phi(t) = \begin{cases} E[X|X\le t]=\frac{1}{F(t)} \int_a^t x f(x) dx, & t \in (a,b],\\ a, & t=a. \end{cases} $$ Now let $Y$ be another random variable on $(\Omega, \mathcal A, P)$ , independent of $X$ . Assume that $Y$ is also supported on $[a,b]$ and that $Y$ has a density $g$ that is strictly positive and continuous on $[a,b]$ . Denote the cdf of $Y$ by $G$ . Question: Is it true that $$\tag{1} E[\phi(Y)] = E[X]? $$ Some remarks: Note that we can write $(1)$ in the suggestive form $E[E[X|X\le Y]] = E[X]$ . But I'm not sure whether this is a valid application of the law of iterated expectations. I've tried to verify $(1)$ directly but so far I haven't succeeded. Here is what I have so far: \begin{align} E[\phi(Y)] &= \int_a^b \frac{1}{F(y)} \int_a^y x f(x)\, dx\, g(y) dy\\ &= \int_a^b \frac{1}{F(y)} \left([xF(x)]_a^y-\int_a^y F(x)\, dx\,\right) g(y) dy\\ &= \int_a^b  \left(y-\int_a^y F(x)\, dx\,\right) g(y) dy, \end{align} where the first equality follows from the definition, the second from integration by parts and the third because $F(a)=0$ . But I don't know how to continue from here (or if $(1)$ even holds). Thank you!","This is a question I came up with while doing some related calculations. Let be a random variable defined on some probability space . To make everything as nicely behaved as possible, let be supported on , and assume that has a density that is continuous and strictly positive on . Denote the cdf of by . Define by Now let be another random variable on , independent of . Assume that is also supported on and that has a density that is strictly positive and continuous on . Denote the cdf of by . Question: Is it true that Some remarks: Note that we can write in the suggestive form . But I'm not sure whether this is a valid application of the law of iterated expectations. I've tried to verify directly but so far I haven't succeeded. Here is what I have so far: where the first equality follows from the definition, the second from integration by parts and the third because . But I don't know how to continue from here (or if even holds). Thank you!","X (\Omega, \mathcal A, P) X [a,b]\subset \mathbb R X f [a, b] X F \phi: [a,b]\to \mathbb R 
\phi(t) =
\begin{cases}
E[X|X\le t]=\frac{1}{F(t)} \int_a^t x f(x) dx, & t \in (a,b],\\
a, & t=a.
\end{cases}
 Y (\Omega, \mathcal A, P) X Y [a,b] Y g [a,b] Y G \tag{1}
E[\phi(Y)] = E[X]?
 (1) E[E[X|X\le Y]] = E[X] (1) \begin{align}
E[\phi(Y)]
&= \int_a^b \frac{1}{F(y)} \int_a^y x f(x)\, dx\, g(y) dy\\
&= \int_a^b \frac{1}{F(y)} \left([xF(x)]_a^y-\int_a^y F(x)\, dx\,\right) g(y) dy\\
&= \int_a^b  \left(y-\int_a^y F(x)\, dx\,\right) g(y) dy,
\end{align} F(a)=0 (1)","['real-analysis', 'calculus', 'probability', 'integration', 'probability-theory']"
39,Evaluating $\lim_{n\to\infty}\sum_{i=1}^n \exp\left(\frac{-|x-X_i|^2}{2(\sigma/n)^2}\right)$,Evaluating,\lim_{n\to\infty}\sum_{i=1}^n \exp\left(\frac{-|x-X_i|^2}{2(\sigma/n)^2}\right),"Let $X_1,...,X_n\stackrel{iid}{\sim} \mu$ where has a density with respect to the Lebesgue measure on $\mathbb{R}$ : $\mu(dx)=\rho(x)dx$ . For every $x$ show $$ \lim_{n\to\infty}\sum_{i=1}^n \exp\left(\frac{-|x-X_i|^2}{2(\sigma/n)^2}\right)=\rho(x)\sigma\sqrt{2\pi}. $$ I am very confident the result is true as it has been empirically verified. I arrived at this conjecture because of the following formal argument: \begin{align} \sum_{i=1}^n \exp\left(\frac{-|x-X_i|^2}{2(\sigma/n)^2}\right)&\approx n \int\exp\left(\frac{-|x-y|^2}{2(\sigma/n)^2}\right)\rho(y)dy\\ &=\sigma\sqrt{2\pi}\left[\int\frac{n}{\sigma\sqrt{2\pi}}\exp\left(\frac{-|y|^2}{2(\sigma/n)^2}\right)\rho(x+y)dy\right]\\ &\xrightarrow{n\to\infty}\sigma\sqrt{2\pi}\int\delta(y)\rho(x+y)dy=\sigma\sqrt{2\pi}\rho(x) \end{align} where I have used the law of large numbers (this is really the part where I am not being precise), the weak convergence of the gaussian to the Dirac delta, and finally the definition of the Dirac delta.","Let where has a density with respect to the Lebesgue measure on : . For every show I am very confident the result is true as it has been empirically verified. I arrived at this conjecture because of the following formal argument: where I have used the law of large numbers (this is really the part where I am not being precise), the weak convergence of the gaussian to the Dirac delta, and finally the definition of the Dirac delta.","X_1,...,X_n\stackrel{iid}{\sim} \mu \mathbb{R} \mu(dx)=\rho(x)dx x 
\lim_{n\to\infty}\sum_{i=1}^n \exp\left(\frac{-|x-X_i|^2}{2(\sigma/n)^2}\right)=\rho(x)\sigma\sqrt{2\pi}.
 \begin{align}
\sum_{i=1}^n \exp\left(\frac{-|x-X_i|^2}{2(\sigma/n)^2}\right)&\approx n \int\exp\left(\frac{-|x-y|^2}{2(\sigma/n)^2}\right)\rho(y)dy\\
&=\sigma\sqrt{2\pi}\left[\int\frac{n}{\sigma\sqrt{2\pi}}\exp\left(\frac{-|y|^2}{2(\sigma/n)^2}\right)\rho(x+y)dy\right]\\
&\xrightarrow{n\to\infty}\sigma\sqrt{2\pi}\int\delta(y)\rho(x+y)dy=\sigma\sqrt{2\pi}\rho(x)
\end{align}","['real-analysis', 'probability', 'sequences-and-series', 'limits', 'normal-distribution']"
40,Probability distribution of sum of many differently weighted coins,Probability distribution of sum of many differently weighted coins,,"Imagine that we have $100$ coins, which each have a random weight between $0$ and $1$ $\left(~\mbox{but we know the weights}~\right)$ : That is to say, we have $100$ known numbers $p_{1}, p_{2},\ldots, p_{100} \in \left[0, 1\right]$ such that coin $n$ has probability $p_{n}$ of flipping heads, which we treat as an outcome of $1$ , and probability $1 - p_{n}$ of flipping tails, which we treat as an outcome of $0$ . We want the probability distribution of the sum of these $100$ coins. How can we compute it efficiently, exactly if possible or approximately if not possible $?$ .","Imagine that we have coins, which each have a random weight between and : That is to say, we have known numbers such that coin has probability of flipping heads, which we treat as an outcome of , and probability of flipping tails, which we treat as an outcome of . We want the probability distribution of the sum of these coins. How can we compute it efficiently, exactly if possible or approximately if not possible .","100 0 1 \left(~\mbox{but we know the weights}~\right) 100 p_{1}, p_{2},\ldots, p_{100} \in \left[0, 1\right] n p_{n} 1 1 - p_{n} 0 100 ?","['probability', 'probability-distributions']"
41,Urn problem with intermediate step,Urn problem with intermediate step,,"Suppose there is an urn containing 120 black and 30 white balls. Now, you randomly draw 100 balls (without replacement). Then, you draw 2 balls again (without replacement) from the selected 100 balls. What is the probability that both balls drawn are white? Intuitively, I would say that the intermediate step of selecting the 100 balls should not matter. Thus, I would calculate it as $\frac{30}{150} \times \frac{29}{149}$ . My question would be: How can one formally model the intermediate step with the 100 balls and show that it does not matter?","Suppose there is an urn containing 120 black and 30 white balls. Now, you randomly draw 100 balls (without replacement). Then, you draw 2 balls again (without replacement) from the selected 100 balls. What is the probability that both balls drawn are white? Intuitively, I would say that the intermediate step of selecting the 100 balls should not matter. Thus, I would calculate it as . My question would be: How can one formally model the intermediate step with the 100 balls and show that it does not matter?",\frac{30}{150} \times \frac{29}{149},['probability']
42,solution using symmetry to probability question involving 3 jurors,solution using symmetry to probability question involving 3 jurors,,"Consider the following problem: Alice has decided to participate in a jury with three members, with the verdict decided by majority. To express her disinterest in the case, she decides to vote by flipping a fair coin. The other two members make the correct decision with probability $p \in (0, 1)$ . How does this arrangement compare to a judge who makes the correct decision with probability $p$ ? The probability the correct decision is made in the former scenario can be calculated as $\frac{p^2}{2} + \frac{p^2}{2} + 2\left(\frac{p(1-p)}{2}\right) = p$ , so the probabilities are the same. Because they are the same, I am wondering if there is a more elegant solution that argues by symmetry?","Consider the following problem: Alice has decided to participate in a jury with three members, with the verdict decided by majority. To express her disinterest in the case, she decides to vote by flipping a fair coin. The other two members make the correct decision with probability . How does this arrangement compare to a judge who makes the correct decision with probability ? The probability the correct decision is made in the former scenario can be calculated as , so the probabilities are the same. Because they are the same, I am wondering if there is a more elegant solution that argues by symmetry?","p \in (0, 1) p \frac{p^2}{2} + \frac{p^2}{2} + 2\left(\frac{p(1-p)}{2}\right) = p","['probability', 'recreational-mathematics', 'problem-solving', 'puzzle']"
43,What is the probability of drawing 5 cards of the same type from a deck of 52 cards?,What is the probability of drawing 5 cards of the same type from a deck of 52 cards?,,"My textbook has the following problem: There is 52 cards in a deck and 13 cards of each type/color. You are drawing 5 cards. Whats the probability of all these 5 cards being the same type? My solution: There is a $\frac{52}{52}$ probability of drawing the first card, then a $\frac{12}{51}$ chance of drawing a second card of the same type as the first one and so on... $$\frac{52}{52} \cdot \frac{12}{51} \cdot \frac{11}{50} \cdot \frac{10}{49} \cdot \frac{9}{48} = \frac{33}{16660}$$ I solved the same problem by calculating the individual probabilities for each card type and then adding all the probabilities together: $$4\cdot(\frac{13}{52} \cdot \frac{12}{51} \cdot \frac{11}{50} \cdot \frac{10}{49} \cdot \frac{9}{48}) = \frac{33}{16660}$$ My textbook says the solution is $(\frac{13}{51} \cdot \frac{12}{50} \cdot \frac{11}{49} \cdot \frac{10}{48})$ without any explanation. Although I don't see how you arrive at this answer. Whats wrong with my way of solving the problem and how do you arrive at the textbooks solution?","My textbook has the following problem: There is 52 cards in a deck and 13 cards of each type/color. You are drawing 5 cards. Whats the probability of all these 5 cards being the same type? My solution: There is a probability of drawing the first card, then a chance of drawing a second card of the same type as the first one and so on... I solved the same problem by calculating the individual probabilities for each card type and then adding all the probabilities together: My textbook says the solution is without any explanation. Although I don't see how you arrive at this answer. Whats wrong with my way of solving the problem and how do you arrive at the textbooks solution?",\frac{52}{52} \frac{12}{51} \frac{52}{52} \cdot \frac{12}{51} \cdot \frac{11}{50} \cdot \frac{10}{49} \cdot \frac{9}{48} = \frac{33}{16660} 4\cdot(\frac{13}{52} \cdot \frac{12}{51} \cdot \frac{11}{50} \cdot \frac{10}{49} \cdot \frac{9}{48}) = \frac{33}{16660} (\frac{13}{51} \cdot \frac{12}{50} \cdot \frac{11}{49} \cdot \frac{10}{48}),"['probability', 'combinatorics', 'card-games']"
44,$\int_{-\infty}^{\infty}\exp\left(-\frac{\beta}{4}\left(y^2+x^2-1\right)^2\right)dy$,,\int_{-\infty}^{\infty}\exp\left(-\frac{\beta}{4}\left(y^2+x^2-1\right)^2\right)dy,"I'm interested in the following integral: \begin{equation} P_\beta(x) = \int_{-\infty}^{\infty}\exp\left(-\frac{\beta}{4}\left(y^2+x^2-1\right)^2\right)dy, \end{equation} where $\beta>0$ . For context, this integral comes from the probability density function of the displacement (or velocity) of a Van der Pol-Rayleigh oscillator, as shown by Talmadge 1991 (eqn. 9). This integral is very similar in form to this question which has already been answered on here, however Did's method was only correct for $a>0$ , $b >0$ . For my specific case, $b<0$ ( $x^2-1<0$ ) forms an important solution case. Through some trial and error with Mathematica/MATLAB, I was able to find the general solution for my case: \begin{equation} P_\beta(x) = \sqrt{|x^2-1|}\exp\left(-\frac{\beta}{4}\left(x^2-1\right)^2\right) F(x^2-1,\beta), \end{equation} where \begin{equation} F(x^2-1,\beta) = \sqrt{2}{K}_{1/4}\left(\frac{\beta}{4}\left(x^2-1\right)^2\right)+2 H\left(-(x^2-1)\right){I}_{1/4}\left(\frac{\beta}{4}\left(x^2-1\right)^2\right), \end{equation} and where $I_{\nu}(z)$ , $K_{\nu}(z)$ are the modified Bessel functions of the first and second kind, respectively, and where $H(x)$ is the Heaviside function. When $x^2-1>0$ , I can see how the solution is formed, but I'm struggling with the $x^2-1<0$ case. Any insights or hints would be greatly appreciated.","I'm interested in the following integral: where . For context, this integral comes from the probability density function of the displacement (or velocity) of a Van der Pol-Rayleigh oscillator, as shown by Talmadge 1991 (eqn. 9). This integral is very similar in form to this question which has already been answered on here, however Did's method was only correct for , . For my specific case, ( ) forms an important solution case. Through some trial and error with Mathematica/MATLAB, I was able to find the general solution for my case: where and where , are the modified Bessel functions of the first and second kind, respectively, and where is the Heaviside function. When , I can see how the solution is formed, but I'm struggling with the case. Any insights or hints would be greatly appreciated.","\begin{equation}
P_\beta(x) = \int_{-\infty}^{\infty}\exp\left(-\frac{\beta}{4}\left(y^2+x^2-1\right)^2\right)dy,
\end{equation} \beta>0 a>0 b >0 b<0 x^2-1<0 \begin{equation}
P_\beta(x) = \sqrt{|x^2-1|}\exp\left(-\frac{\beta}{4}\left(x^2-1\right)^2\right) F(x^2-1,\beta),
\end{equation} \begin{equation}
F(x^2-1,\beta) = \sqrt{2}{K}_{1/4}\left(\frac{\beta}{4}\left(x^2-1\right)^2\right)+2 H\left(-(x^2-1)\right){I}_{1/4}\left(\frac{\beta}{4}\left(x^2-1\right)^2\right),
\end{equation} I_{\nu}(z) K_{\nu}(z) H(x) x^2-1>0 x^2-1<0","['calculus', 'probability', 'integration', 'bessel-functions']"
45,Prove that $\mathbb{P}\left(\Vert A \Vert \ge cK(\sqrt{N} + \sqrt{K} + t)\right) \le 2\exp(-t^2)$,Prove that,\mathbb{P}\left(\Vert A \Vert \ge cK(\sqrt{N} + \sqrt{K} + t)\right) \le 2\exp(-t^2),"Problem: Let $A = (a_{ij}): l_2^k \to l_2^N$ be a random matrix whose coefficients $a_{ij}$ are independent, centered, $\psi_2$ (the definition is in this post) and satisfy. \begin{align*}         \exists K>0, \forall i,j: \Vert a_{ij}\Vert_{\psi_2} \le K. \end{align*} Prove that $\exists c >0$ (independent of everything) such that $\forall t>0$ \begin{align*}    \mathbb{P}\left(\Vert A \Vert \ge cK(\sqrt{N} + \sqrt{K} + t)\right) \le 2\exp(-t^2). \end{align*} My attempt: There is two closely related inequality that I have proved but I have not thought how to combine it to tackle with the problem $\forall x \in S^{k-1}$ , $\forall y \in S^{N-1}$ , $\forall t >0$ \begin{align*}         \mathbb{P}\left(\sum_{i,j}a_{ij}x_jy_i > t\right) \le \exp\left(-\dfrac{t^2}{4K^2}\right).     \end{align*} Let $\mathcal{N}$ be an $\varepsilon$ -net of $S^{k-1}$ and $\mathcal{M}$ be an $\varepsilon$ -net of $S^{N-1}$ \begin{align*}         \sup_{x \in \mathcal{N},\ y \in \mathcal{M}} \langle Ax,y\rangle  \le \Vert A \Vert \le \dfrac{1}{1-2\varepsilon} \sup_{x \in \mathcal{N}, y \in \mathcal{M}} \langle Ax,y \rangle. \tag{*}     \end{align*} I wonder is there any relation between $\mathbb{P}(\Vert A\Vert>\text{constant})$ with $\mathbb{P}\left(\sum_{i,j}a_{ij}x_jy_i > \text{constant}\right)$","Problem: Let be a random matrix whose coefficients are independent, centered, (the definition is in this post) and satisfy. Prove that (independent of everything) such that My attempt: There is two closely related inequality that I have proved but I have not thought how to combine it to tackle with the problem , , Let be an -net of and be an -net of I wonder is there any relation between with","A = (a_{ij}): l_2^k \to l_2^N a_{ij} \psi_2 \begin{align*}
        \exists K>0, \forall i,j: \Vert a_{ij}\Vert_{\psi_2} \le K.
\end{align*} \exists c >0 \forall t>0 \begin{align*}
   \mathbb{P}\left(\Vert A \Vert \ge cK(\sqrt{N} + \sqrt{K} + t)\right) \le 2\exp(-t^2).
\end{align*} \forall x \in S^{k-1} \forall y \in S^{N-1} \forall t >0 \begin{align*}
        \mathbb{P}\left(\sum_{i,j}a_{ij}x_jy_i > t\right) \le \exp\left(-\dfrac{t^2}{4K^2}\right).
    \end{align*} \mathcal{N} \varepsilon S^{k-1} \mathcal{M} \varepsilon S^{N-1} \begin{align*}
        \sup_{x \in \mathcal{N},\ y \in \mathcal{M}} \langle Ax,y\rangle  \le \Vert A \Vert \le \dfrac{1}{1-2\varepsilon} \sup_{x \in \mathcal{N}, y \in \mathcal{M}} \langle Ax,y \rangle. \tag{*}
    \end{align*} \mathbb{P}(\Vert A\Vert>\text{constant}) \mathbb{P}\left(\sum_{i,j}a_{ij}x_jy_i > \text{constant}\right)","['probability', 'functional-analysis', 'inequality', 'metric-spaces', 'inner-products']"
46,How to prove a result about the accumulation point / cluster point in Brownian Motion?,How to prove a result about the accumulation point / cluster point in Brownian Motion?,,"I have a standard Brownian motion, $B(t)$ , $t\ge0$ . I am trying to prove the following result: Every $t > 0$ is an accumulation point (i. e., cluster point) of $(s: B(s) = B(t))$ from the right, with probability $1$ . That is, I would like to prove that, for any fixed $t > 0,$ $P[$ inf $(s > t : B(s) = B(t)) = t] = 1$ I am new to analysis and preparing for finals that's scheduled for next week.  Any insight or advice on this proof will be very helpful.  Thanks a lot! $EDIT:$ I have a follow-up question that kind of takes off from the above, and is posted here: Proof regarding cluster point in Brownian motion","I have a standard Brownian motion, , . I am trying to prove the following result: Every is an accumulation point (i. e., cluster point) of from the right, with probability . That is, I would like to prove that, for any fixed inf I am new to analysis and preparing for finals that's scheduled for next week.  Any insight or advice on this proof will be very helpful.  Thanks a lot! I have a follow-up question that kind of takes off from the above, and is posted here: Proof regarding cluster point in Brownian motion","B(t) t\ge0 t > 0 (s: B(s) = B(t)) 1 t > 0, P[ (s > t : B(s) = B(t)) = t] = 1 EDIT:","['real-analysis', 'calculus', 'probability', 'probability-theory', 'random-variables']"
47,How to apply queuing theory to find the long run proportion of customers who leave the system?,How to apply queuing theory to find the long run proportion of customers who leave the system?,,"I am trying to apply queuing theory / birth and death process to the following. Suppose customers arrive in a restaurant according to a Poisson process with rate $\lambda = 1$ . Suppose there are $2$ counters in the restaurant. Customers are served in counter $1$ in Exponential $(1)$ amount of time, and customers are served in counter $2$ in Exponential $(2)$ amount of time. Usage of counters by each customer is independent of the usage of counters by other customers.  When a customer comes, s/he chooses counter $2$ if it's free/available, otherwise the customer goes to counter $1$ . If both counters are occupied, the customer leaves. Here, I am trying to calculate the long run proportion of customers that leave because both counters are occupied. I have been trying to set up the balance equations but I am not sure that's the correct approach.  I'm preparing for the upcoming finals and I'd be grateful for any help on how to solve this.  Thank you so much. $EDIT:$ I tried to model this as an $M/M/2$ queue, and I get the following results: I take the state space to be $S = (0, 1, 2),$ where each state refers to the number of customers in the system. The balance equations are $\lambda P_0 = (\mu_1 + \mu_2)P_1$ $\lambda P_1 = (\mu_1 + \mu_2)P_2$ And the normalizing equation is: $P_0 + P_1 + P_2 = 1$ Solving this gives me $P_0 = \frac{9}{13}, P_1 = \frac{3}{13},$ and $P_2 = \frac{1}{13}$ Is this correct?  I am doubtful about the logic I have used to arrive at the balance equations, especially because of the fact that customers prefer counter $2$ over counter $1$ . If this is correct, then, I have $P_2$ , which is the long run probability that a customer leaves because both counters are occupied.  With this, how can I find the long run proportion of customers that leave because both counters are occupied?  Thank you for any help.","I am trying to apply queuing theory / birth and death process to the following. Suppose customers arrive in a restaurant according to a Poisson process with rate . Suppose there are counters in the restaurant. Customers are served in counter in Exponential amount of time, and customers are served in counter in Exponential amount of time. Usage of counters by each customer is independent of the usage of counters by other customers.  When a customer comes, s/he chooses counter if it's free/available, otherwise the customer goes to counter . If both counters are occupied, the customer leaves. Here, I am trying to calculate the long run proportion of customers that leave because both counters are occupied. I have been trying to set up the balance equations but I am not sure that's the correct approach.  I'm preparing for the upcoming finals and I'd be grateful for any help on how to solve this.  Thank you so much. I tried to model this as an queue, and I get the following results: I take the state space to be where each state refers to the number of customers in the system. The balance equations are And the normalizing equation is: Solving this gives me and Is this correct?  I am doubtful about the logic I have used to arrive at the balance equations, especially because of the fact that customers prefer counter over counter . If this is correct, then, I have , which is the long run probability that a customer leaves because both counters are occupied.  With this, how can I find the long run proportion of customers that leave because both counters are occupied?  Thank you for any help.","\lambda = 1 2 1 (1) 2 (2) 2 1 EDIT: M/M/2 S = (0, 1, 2), \lambda P_0 = (\mu_1 + \mu_2)P_1 \lambda P_1 = (\mu_1 + \mu_2)P_2 P_0 + P_1 + P_2 = 1 P_0 = \frac{9}{13}, P_1 = \frac{3}{13}, P_2 = \frac{1}{13} 2 1 P_2","['probability', 'stochastic-processes', 'random-variables', 'exponential-distribution', 'queueing-theory']"
48,Random points in 2-sphere,Random points in 2-sphere,,"Say we have the PDF of uniformly picking a random point in the unit $2$ -sphere, with distance from origin of the point being $r$ , given as $$ f_R(r) = \begin{cases}     3r^2 & 0 \leq r \leq 1 \\     0 & \text{otherwise} \end{cases} $$ We then want to extend this to n points. How would I find the distributions of $X$ , where $X$ is the second furthest point from the origin of these $n$ points? I imagine it is something along the lines of considering spheres within the sphere, but this isn't getting me anywhere.","Say we have the PDF of uniformly picking a random point in the unit -sphere, with distance from origin of the point being , given as We then want to extend this to n points. How would I find the distributions of , where is the second furthest point from the origin of these points? I imagine it is something along the lines of considering spheres within the sphere, but this isn't getting me anywhere.","2 r 
f_R(r) = \begin{cases}
    3r^2 & 0 \leq r \leq 1 \\
    0 & \text{otherwise}
\end{cases}
 X X n","['probability', 'probability-distributions', 'geometric-probability']"
49,Law of total expectation and conditioning to find expectation.,Law of total expectation and conditioning to find expectation.,,"I have a lottery in which a random number $𝑁$ tickets are sold, where $𝑁$ has PMF given by $$p_N(n) = \frac{\lambda^{n-1}e^{-\lambda}}{(n-1)!}, \quad n = 1, 2, \ldots$$ The tickets are numbered $1, 2, … , 𝑁$ , and a single winning ticket is drawn uniformly at random. Let $𝑋$ denote the number on the winning ticket. I want to find the Expectation and Variance of X. My thinking so far for the expectation is to use the law of total expectation, i.e. say $E[X] = E[E[X \mid N]]$ , and then use the fact $E[X] = \sum_{n=1}^{\infty} E[X \mid N=n]P(N=n)$ . So surely $E[X \mid N=n] = \frac{n+1}{2}$ as it is uniform, then I should be able to evaluate the sum? Feels like I am missing something obvious, like something within the sum. Any pointers appreciated, thanks in advance.","I have a lottery in which a random number tickets are sold, where has PMF given by The tickets are numbered , and a single winning ticket is drawn uniformly at random. Let denote the number on the winning ticket. I want to find the Expectation and Variance of X. My thinking so far for the expectation is to use the law of total expectation, i.e. say , and then use the fact . So surely as it is uniform, then I should be able to evaluate the sum? Feels like I am missing something obvious, like something within the sum. Any pointers appreciated, thanks in advance.","𝑁 𝑁 p_N(n) = \frac{\lambda^{n-1}e^{-\lambda}}{(n-1)!}, \quad n = 1, 2, \ldots 1, 2, … , 𝑁 𝑋 E[X] = E[E[X \mid N]] E[X] = \sum_{n=1}^{\infty} E[X \mid N=n]P(N=n) E[X \mid N=n] = \frac{n+1}{2}","['probability', 'probability-distributions', 'conditional-expectation']"
50,Does the law of truly large numbers/infinite monkey theorem hold with an ever decreasing probability?,Does the law of truly large numbers/infinite monkey theorem hold with an ever decreasing probability?,,"Recently I've been considering a game (I'm unsure if it has a proper name and is an already studied problem), and it proceeds as follows. Flip a coin, selecting a value of either 0 or 1. Append the result to the sequence of past flips. If the last flip has marked the repetition of the past history of the sequence (i.e. the first half of the sequence now equals the second half), the game terminates. Otherwise, keep playing the game. Some example runs where the game terminates might be 11, or 00, or 101101, or 1001110011, etc. But the longer sequences get exponentially less likely to be repeated, for instance had the last example ended instead with a 0, we would then need to just by chance get the precise sequence of subsequent flips 1001110010 to form 1001110010[|]1001110010. Thus after a certain point, it seems as though we are bound to keep failing forever, eternally making the required sequence we must repeat to finish the game longer and longer. And running some basic simulations of 1000 different random seeds for this game reveals a curious distribution of game lengths: Game Length Occurrences (/1000) 2 521 4 127 6 59 8 15 10 13 12 3 14 1 16 2 18 1 22 1 > 1,000,000 257 Here the final category the game was manually terminated after iterating beyond 1 million in length (as these sequences seem to run forever or for a very long time). The rarest game lengths are actually the intermediate length games, with a decent portion falling into this exceedingly long case instead. This pattern is interesting to me, and my question ultimately is, do these sequences truly run forever ? Past a certain point does this probabilistic game become truly hopeless, even though at each step as the sequence gets longer there is a non-zero probability of the past history of the sequence happening to exactly reoccur? I liken this game by analogy to moving twice as far away from a quantum tunnelling particle every time it fails to tunnel to your location, which also seems to imply it would never catch you even given infinite time. Or perhaps if the works of Shakespeare expanded by an additional character with each wrong keypress by the monkey at the typewriter, multiplying the difficulty. But at the same time this logic contrasts with my intuition about the law of truly large numbers, which says given infinite time any events with non-zero probability will eventually happen. So how is the law affected in the case where the probability in question is not constant, but eternally decreasing (halving with each failure in this case)? Edit: As an interesting aside, if we instead roll a 10 sided die, the result from the long runs becomes a sequence of random digits, e.g. 943669542398...; and I notice by definition this sequence avoids repetitions, and so if we put a decimal point before it, 0.943669542398... for instance, we are essentially constructing an irrational number. The distribution also shifts such that the vast majority of runs end up in the long seemingly endless case.","Recently I've been considering a game (I'm unsure if it has a proper name and is an already studied problem), and it proceeds as follows. Flip a coin, selecting a value of either 0 or 1. Append the result to the sequence of past flips. If the last flip has marked the repetition of the past history of the sequence (i.e. the first half of the sequence now equals the second half), the game terminates. Otherwise, keep playing the game. Some example runs where the game terminates might be 11, or 00, or 101101, or 1001110011, etc. But the longer sequences get exponentially less likely to be repeated, for instance had the last example ended instead with a 0, we would then need to just by chance get the precise sequence of subsequent flips 1001110010 to form 1001110010[|]1001110010. Thus after a certain point, it seems as though we are bound to keep failing forever, eternally making the required sequence we must repeat to finish the game longer and longer. And running some basic simulations of 1000 different random seeds for this game reveals a curious distribution of game lengths: Game Length Occurrences (/1000) 2 521 4 127 6 59 8 15 10 13 12 3 14 1 16 2 18 1 22 1 > 1,000,000 257 Here the final category the game was manually terminated after iterating beyond 1 million in length (as these sequences seem to run forever or for a very long time). The rarest game lengths are actually the intermediate length games, with a decent portion falling into this exceedingly long case instead. This pattern is interesting to me, and my question ultimately is, do these sequences truly run forever ? Past a certain point does this probabilistic game become truly hopeless, even though at each step as the sequence gets longer there is a non-zero probability of the past history of the sequence happening to exactly reoccur? I liken this game by analogy to moving twice as far away from a quantum tunnelling particle every time it fails to tunnel to your location, which also seems to imply it would never catch you even given infinite time. Or perhaps if the works of Shakespeare expanded by an additional character with each wrong keypress by the monkey at the typewriter, multiplying the difficulty. But at the same time this logic contrasts with my intuition about the law of truly large numbers, which says given infinite time any events with non-zero probability will eventually happen. So how is the law affected in the case where the probability in question is not constant, but eternally decreasing (halving with each failure in this case)? Edit: As an interesting aside, if we instead roll a 10 sided die, the result from the long runs becomes a sequence of random digits, e.g. 943669542398...; and I notice by definition this sequence avoids repetitions, and so if we put a decimal point before it, 0.943669542398... for instance, we are essentially constructing an irrational number. The distribution also shifts such that the vast majority of runs end up in the long seemingly endless case.",,"['probability', 'sequences-and-series', 'binary']"
51,Are there any known lower bounds on $xP(X>x)$ when $E(X) =\infty$?,Are there any known lower bounds on  when ?,xP(X>x) E(X) =\infty,"I have encountered following problem while I was working on something. For what follows, let $X$ be a non-negative random variable. If we know $E(X^p)\leq \infty$ , then it is well known that $x^pP(X>x) \to 0$ as $x\to \infty$ . This also implies that $x^pP(X>x)$ is a bounded function in $x$ . Now, if we know $E(X) = \infty$ , then are there any known lower bounds on $xP(X>x)$ under some ""nice"" assumptions ? (for example, X having a positive density on $[0,\infty)$ ). For example, if $X$ has some mass at $\infty$ , say $P(X= \infty) = p$ , then $xP(X>x) \geq xp$ for all $x \geq 0$ .","I have encountered following problem while I was working on something. For what follows, let be a non-negative random variable. If we know , then it is well known that as . This also implies that is a bounded function in . Now, if we know , then are there any known lower bounds on under some ""nice"" assumptions ? (for example, X having a positive density on ). For example, if has some mass at , say , then for all .","X E(X^p)\leq \infty x^pP(X>x) \to 0 x\to \infty x^pP(X>x) x E(X) = \infty xP(X>x) [0,\infty) X \infty P(X= \infty) = p xP(X>x) \geq xp x \geq 0","['probability', 'measure-theory', 'reference-request', 'stochastic-analysis', 'reference-works']"
52,Isomorphism between tetrahedron and cube paths,Isomorphism between tetrahedron and cube paths,,"Consider the following two problems: A bug is sitting on vertex $A$ of a regular tetrahedron. At the start of each minute, he randomly chooses one of the edges at the vertex he is currently sitting on and crawls along that edge to the adjacent vertex. It takes him one minute to crawl to the next vertex, at which point he chooses another edge (at random) and starts crawling again. What is the probability that, after 6 minutes, he is back at vertex $A$ ? Same as 1., except the bug is crawling along the edges of a cube. We can compute the probability of both to find that they are both $\frac{61}{243}$ , which probably implies there exists an isomorphism between the paths on the cube and the tetrahedron. However, I don't quite see what or how the morphism can be built, because there are $4$ states for where the bug can be on the cube, while there are only $2$ states for where the bug can be on the tetrahedron. I am not necessarily asking for a fully rigorous argument, some solid intuition (preferably geometric) will be accepted as well. (Of course, a rigorous argument will be accepted.)","Consider the following two problems: A bug is sitting on vertex of a regular tetrahedron. At the start of each minute, he randomly chooses one of the edges at the vertex he is currently sitting on and crawls along that edge to the adjacent vertex. It takes him one minute to crawl to the next vertex, at which point he chooses another edge (at random) and starts crawling again. What is the probability that, after 6 minutes, he is back at vertex ? Same as 1., except the bug is crawling along the edges of a cube. We can compute the probability of both to find that they are both , which probably implies there exists an isomorphism between the paths on the cube and the tetrahedron. However, I don't quite see what or how the morphism can be built, because there are states for where the bug can be on the cube, while there are only states for where the bug can be on the tetrahedron. I am not necessarily asking for a fully rigorous argument, some solid intuition (preferably geometric) will be accepted as well. (Of course, a rigorous argument will be accepted.)",A A \frac{61}{243} 4 2,"['probability', 'combinatorics', 'random-walk']"
53,Is there a name for this probabilistic paradox?,Is there a name for this probabilistic paradox?,,"Let $X\sim Exp(1)$ and $Y\sim Exp(\lambda)$ , independent. Then, \begin{align} f_{X|Y=mX}(x) = \frac{f_{X,Y}(x,mx) }{\int f_{X,Y}(x,mx) \:dx }=\frac{f_X(x)f_Y(mx) }{\int f_X(x)f_Y(mx) \:dx } = \frac{e^{-(1+\lambda m)x}}{\int e^{-(1+\lambda m)x} dx} = (1+m\lambda)e^{-(1+\lambda m)x}  \end{align} So $X|_{Y=mX} \sim Exp(1+m\lambda)$ . That means $E[X|Y=mX]=\frac{1}{1+ \lambda m} < 1$ whenever $m>0$ . This makes sense mathematically. $X|_{Y=0}\sim Exp(1)$ , $f_{X,Y}(0,0)$ is the same for all $m$ , but $f_{X,Y}(x,mx)<f_{X,Y}(x,m'x)$ if $m'<m$ . The practical implication seems weird, though. Your friend gets to your house via one Poisson bus and one Poisson train. You expect someone to wait 1 minute for a train. But they tell you they waited $m$ times as long for the bus than they did for the train, and now you gotta revise your expectation about the train down? Edit: I think the reason for the (seeming) violation of the Tower property is that I incorrectly defined $f_{X|Y=mX}$ . It should instead be $$ f_{X|Y=mX}(x) = \frac{xf_{X,Y}(x,mx) }{\int x f_{X,Y}(x,mx) \:dx} = \frac{xe^{-(1+\lambda m)x}}{\int xe^{-(1+\lambda m)x} dx} $$ Think about it like the flag of Seychelles: the width of the ""ray"" is twice as large if you go twice as far out. (Aside: this is indeed Borel's paradox) This means that \begin{align} E[X|Y=mX]= \frac{\int x^2e^{-(1+\lambda m)x} dx}{\int xe^{-(1+\lambda m)x} dx} = \frac{2}{1+\lambda m} \end{align} The distribution of slopes is the distribution of $M:=Y/X$ \begin{align} f_{M}(m) &= \int_0^\infty f_Y(y) f_{1/X}(m/y) y^{-1}\:dy\\     &= \int_0^\infty \lambda e^{-\lambda y}\left(\frac{y}{m}\right)^2 e^{-y/m} y^{-1} \:dy\\     &= \frac{\lambda}{m^2} \int_0^\infty y e^{-y(\lambda + \frac{1}{m}) } \:dy \\     &= \frac{\lambda}{m^2}\frac{1}{(\frac{1}{m} + \lambda)^2}\\     &= \frac{\lambda}{ (1+\lambda m)^2} \end{align} The Law of Iterated Expectaions holds for this definition of the conditional density: \begin{align} \int E[X|Y/X = m] \: dP(M\leq m) = \int_0^\infty \frac{2\lambda}{ (1+\lambda m)^3} \:dm = -\frac{1}{(1+\lambda m)^2}\bigg|_0^\infty = 1 = EX \end{align}","Let and , independent. Then, So . That means whenever . This makes sense mathematically. , is the same for all , but if . The practical implication seems weird, though. Your friend gets to your house via one Poisson bus and one Poisson train. You expect someone to wait 1 minute for a train. But they tell you they waited times as long for the bus than they did for the train, and now you gotta revise your expectation about the train down? Edit: I think the reason for the (seeming) violation of the Tower property is that I incorrectly defined . It should instead be Think about it like the flag of Seychelles: the width of the ""ray"" is twice as large if you go twice as far out. (Aside: this is indeed Borel's paradox) This means that The distribution of slopes is the distribution of The Law of Iterated Expectaions holds for this definition of the conditional density:","X\sim Exp(1) Y\sim Exp(\lambda) \begin{align}
f_{X|Y=mX}(x) = \frac{f_{X,Y}(x,mx) }{\int f_{X,Y}(x,mx) \:dx }=\frac{f_X(x)f_Y(mx) }{\int f_X(x)f_Y(mx) \:dx } = \frac{e^{-(1+\lambda m)x}}{\int e^{-(1+\lambda m)x} dx} = (1+m\lambda)e^{-(1+\lambda m)x} 
\end{align} X|_{Y=mX} \sim Exp(1+m\lambda) E[X|Y=mX]=\frac{1}{1+ \lambda m} < 1 m>0 X|_{Y=0}\sim Exp(1) f_{X,Y}(0,0) m f_{X,Y}(x,mx)<f_{X,Y}(x,m'x) m'<m m f_{X|Y=mX} 
f_{X|Y=mX}(x) = \frac{xf_{X,Y}(x,mx) }{\int x f_{X,Y}(x,mx) \:dx} = \frac{xe^{-(1+\lambda m)x}}{\int xe^{-(1+\lambda m)x} dx}
 \begin{align}
E[X|Y=mX]= \frac{\int x^2e^{-(1+\lambda m)x} dx}{\int xe^{-(1+\lambda m)x} dx} = \frac{2}{1+\lambda m}
\end{align} M:=Y/X \begin{align}
f_{M}(m) &= \int_0^\infty f_Y(y) f_{1/X}(m/y) y^{-1}\:dy\\
    &= \int_0^\infty \lambda e^{-\lambda y}\left(\frac{y}{m}\right)^2 e^{-y/m} y^{-1} \:dy\\
    &= \frac{\lambda}{m^2} \int_0^\infty y e^{-y(\lambda + \frac{1}{m}) } \:dy \\
    &= \frac{\lambda}{m^2}\frac{1}{(\frac{1}{m} + \lambda)^2}\\
    &= \frac{\lambda}{ (1+\lambda m)^2}
\end{align} \begin{align}
\int E[X|Y/X = m] \: dP(M\leq m) = \int_0^\infty \frac{2\lambda}{ (1+\lambda m)^3} \:dm = -\frac{1}{(1+\lambda m)^2}\bigg|_0^\infty = 1 = EX
\end{align}","['probability', 'probability-theory', 'probability-distributions', 'terminology', 'paradoxes']"
54,Law of Large Numbers: How Much More Powerful is Weak Law vs Strong Law?,Law of Large Numbers: How Much More Powerful is Weak Law vs Strong Law?,,"In mathematics, we often learn the following statements: Convergence in Probability implies Convergence in Distribution Strong Law of Large Numbers implies Weak Law of Large Numbers I am trying to create mathematical examples to compare the strength (i.e. implication) for both of these statements. For example - perhaps we can show simulate some random data and show that for the same data:  Strong Law of Large Numbers requires fewer samples to achieve the same results as the Weak Law of Large Numbers?  (I am not sure if this is possible or would even serve to demonstrate and compare the strength of Weak Law vs Strong Law) Maybe we can simulate some random data and show that for the same data: Convergence in Probability requires fewer samples to achieve the same results as Convergence in Distribution? (I am not sure if this is possible or would even serve to demonstrate and compare the strength of Convergence in Probability vs Convergence in Distribution) For example - here is an R simulation that I think might be able to show the Law of Large Numbers (I am not sure if Strong Law or Weak Law): The sample average becomes closer and closer to the population average as the size of the sample increases: set.seed(123) n <- 1000 sample_means <- numeric(n) for (i in 1:n) {   x <- rnorm(i, mean = 0, sd = 1)   sample_means[i] <- mean(x) } plot(sample_means, type = ""l"", main = ""Law of Large Numbers: Convergence of Sample Mean to Population Mean"", xlab = ""Sample Size"", ylab = ""Sample Mean"") abline(h = 0, col = ""red"") Is it somehow possible to ""overlay"" a second example on this plot and compare an example for the other Law of Large Numbers - and thus compare the strengths of both laws? Can something similar be done for Convergence in Probability vs Convergence in Distribution? Thanks! References: Creating A Mathematical Example for Convergence in Distribution","In mathematics, we often learn the following statements: Convergence in Probability implies Convergence in Distribution Strong Law of Large Numbers implies Weak Law of Large Numbers I am trying to create mathematical examples to compare the strength (i.e. implication) for both of these statements. For example - perhaps we can show simulate some random data and show that for the same data:  Strong Law of Large Numbers requires fewer samples to achieve the same results as the Weak Law of Large Numbers?  (I am not sure if this is possible or would even serve to demonstrate and compare the strength of Weak Law vs Strong Law) Maybe we can simulate some random data and show that for the same data: Convergence in Probability requires fewer samples to achieve the same results as Convergence in Distribution? (I am not sure if this is possible or would even serve to demonstrate and compare the strength of Convergence in Probability vs Convergence in Distribution) For example - here is an R simulation that I think might be able to show the Law of Large Numbers (I am not sure if Strong Law or Weak Law): The sample average becomes closer and closer to the population average as the size of the sample increases: set.seed(123) n <- 1000 sample_means <- numeric(n) for (i in 1:n) {   x <- rnorm(i, mean = 0, sd = 1)   sample_means[i] <- mean(x) } plot(sample_means, type = ""l"", main = ""Law of Large Numbers: Convergence of Sample Mean to Population Mean"", xlab = ""Sample Size"", ylab = ""Sample Mean"") abline(h = 0, col = ""red"") Is it somehow possible to ""overlay"" a second example on this plot and compare an example for the other Law of Large Numbers - and thus compare the strengths of both laws? Can something similar be done for Convergence in Probability vs Convergence in Distribution? Thanks! References: Creating A Mathematical Example for Convergence in Distribution",,"['probability', 'convergence-divergence', 'law-of-large-numbers']"
55,"Distribution of the ratio of sample range to sample standard deviation for normal when $\,n=3$",Distribution of the ratio of sample range to sample standard deviation for normal when,"\,n=3","Let $X_{1},X_{2},X_{3}$ be i.i.d samples from $N(\mu,\sigma^2)$ . Let $u$ denotes $$u=\frac{X_{(3)}-X_{(1)}}{S_{3}}\text{ , where }\,X_{(i)}\text{ denotes the }i^{\text{th}}\,\text{order statistic,}\\S_{3}=\sqrt{\frac{\sum_{i=1}^3(X_i-\bar{X})^2}{2}}$$ Now I know the density function of $\,u\,$ is $$f(u)=\frac{3}{\pi}\left(1-\frac{u^2}{4}\right)^{-\frac{1}{2}}(\sqrt{3}\le u\le2)$$ But how to get that? Does anyone have any ideas?  Would appreciate some help.",Let be i.i.d samples from . Let denotes Now I know the density function of is But how to get that? Does anyone have any ideas?  Would appreciate some help.,"X_{1},X_{2},X_{3} N(\mu,\sigma^2) u u=\frac{X_{(3)}-X_{(1)}}{S_{3}}\text{ , where }\,X_{(i)}\text{ denotes the }i^{\text{th}}\,\text{order statistic,}\\S_{3}=\sqrt{\frac{\sum_{i=1}^3(X_i-\bar{X})^2}{2}} \,u\, f(u)=\frac{3}{\pi}\left(1-\frac{u^2}{4}\right)^{-\frac{1}{2}}(\sqrt{3}\le u\le2)","['probability', 'statistics', 'probability-distributions', 'normal-distribution']"
56,Probability of holding two balls at the same time,Probability of holding two balls at the same time,,"Imagine having five persons around a round table. Two consecutive person hold in their hand a ball. Each turn, a person gives the ball to one of its neighbour. How many turns should you wait so that one person holds the two balls at the same time ? For the moment, I've made some effort studying the distance between the two balls $d_k$ which takes value within $0, 1, 2, 3$ . Initially, $d_1 = 1$ . I'm interested in the mean value of $k$ such that $d_k = 0$ . What I have observed is : -> if $d_k = 1$ then, the next turn, $d_{k+1} = 1$ with probability $3/4$ and $d_{k+1} = 2$ otherwise.\ -> if $d_k = 2$ then, the next turn, $d_{k+1} = 2$ with probability $1/2$ , $d_{k+1} = 0$ with probability $1/4$ and $d_{k+1} = 3$ with probability $1/4$ .\ But I don't succed in finding the law of $d_k$ , any help ?","Imagine having five persons around a round table. Two consecutive person hold in their hand a ball. Each turn, a person gives the ball to one of its neighbour. How many turns should you wait so that one person holds the two balls at the same time ? For the moment, I've made some effort studying the distance between the two balls which takes value within . Initially, . I'm interested in the mean value of such that . What I have observed is : -> if then, the next turn, with probability and otherwise.\ -> if then, the next turn, with probability , with probability and with probability .\ But I don't succed in finding the law of , any help ?","d_k 0, 1, 2, 3 d_1 = 1 k d_k = 0 d_k = 1 d_{k+1} = 1 3/4 d_{k+1} = 2 d_k = 2 d_{k+1} = 2 1/2 d_{k+1} = 0 1/4 d_{k+1} = 3 1/4 d_k","['probability', 'sequences-and-series']"
57,Expected number of non-uniform draws until collision?,Expected number of non-uniform draws until collision?,,"Edit May 9 -- high-level summary of the issue here . $R$ gives a good proxy for estimating collision time, with a slight undercount. Random matrices and graphs give distributions with longer time until collision than what you'd expect by looking at their values of $R$ Suppose I do IID draws from multinomial distribution with probabilities $p_1,\ldots,p_n$ . Is there a nice approximation for the $x(p)$ , the expected number of draws from $p$ until collision, ie, drawing some $i$ more than once? In the case of $p_1=p_2=\dots=p_n$ , this was shown to be the following $$x(p)=\sqrt{\frac{\pi n}{2}}$$ From simulations , the following appears to be a lower bound $$x(p)\approx \sqrt{\frac{\pi R}{2}}$$ where $R=\frac{1}{\|p\|^2}$ and $\|p\|^2=p_1^2+\ldots+p_n^2$ is the probability of observing a collision in two IID draws from $p$ . Distributions were taken to be of the form $p_i\propto i^{-c}$ with $c$ varying","Edit May 9 -- high-level summary of the issue here . gives a good proxy for estimating collision time, with a slight undercount. Random matrices and graphs give distributions with longer time until collision than what you'd expect by looking at their values of Suppose I do IID draws from multinomial distribution with probabilities . Is there a nice approximation for the , the expected number of draws from until collision, ie, drawing some more than once? In the case of , this was shown to be the following From simulations , the following appears to be a lower bound where and is the probability of observing a collision in two IID draws from . Distributions were taken to be of the form with varying","R R p_1,\ldots,p_n x(p) p i p_1=p_2=\dots=p_n x(p)=\sqrt{\frac{\pi n}{2}} x(p)\approx \sqrt{\frac{\pi R}{2}} R=\frac{1}{\|p\|^2} \|p\|^2=p_1^2+\ldots+p_n^2 p p_i\propto i^{-c} c","['probability', 'expected-value', 'multinomial-distribution']"
58,Determining if a process is a martingale,Determining if a process is a martingale,,"Let $Z(t)$ be a standard brownian motion, given $W(t) = t^{2} Z(t) -2\int_0^t sZ(s) ds$ , determine if this is a martingale process! We know that a process is martingale if $E[W(t+1)|F(t)] = W(t)$ , with $F(t)$ as a filtration process. I think we should start by writing down $E[W(t+1)|F(t)]$ first, which is $E[(t+1)^{2} Z(t+1) -2\int_0^{t+1} sZ(s) ds|F(t)]$ . This can be split into two terms: First term: $E[(t+1)^{2} Z(t+1)|F(t)]$ which I believe would be $(t+1)^2Z(t)$ , since a standard brownian motion is a martingale. Second term: $-2E[\int_0^{t+1} sZ(s) ds|F(t)]$ for this part, i think we need to use integration by parts, but I ended up with $\int Z(s) ds$ and I'm not sure how to proceed with that result. Am I doing the right steps? Thanks in advance","Let be a standard brownian motion, given , determine if this is a martingale process! We know that a process is martingale if , with as a filtration process. I think we should start by writing down first, which is . This can be split into two terms: First term: which I believe would be , since a standard brownian motion is a martingale. Second term: for this part, i think we need to use integration by parts, but I ended up with and I'm not sure how to proceed with that result. Am I doing the right steps? Thanks in advance",Z(t) W(t) = t^{2} Z(t) -2\int_0^t sZ(s) ds E[W(t+1)|F(t)] = W(t) F(t) E[W(t+1)|F(t)] E[(t+1)^{2} Z(t+1) -2\int_0^{t+1} sZ(s) ds|F(t)] E[(t+1)^{2} Z(t+1)|F(t)] (t+1)^2Z(t) -2E[\int_0^{t+1} sZ(s) ds|F(t)] \int Z(s) ds,"['probability', 'stochastic-processes', 'brownian-motion', 'martingales', 'random-walk']"
59,Independence among order statistics,Independence among order statistics,,"Given i.i.d uniform variables $X_1, ..., X_n \sim U[0,1]$ , is it true that the event $X_i \leq \min_{k \in [i-1]} X_k$ is independent of $X_j \leq \min_{k \in [j-1]} X_k$ for any $i > j$ ? The answer seems to be yes through symmetry: $\Pr(X_i \leq \min_{k \in [i-1]} X_k | X_j \leq \min_{k \in [j-1]} X_k) = \Pr(X_i \leq \min_{k \in [i-1]} X_k | X_l \leq \min_{k \in [j-1]} X_k)$ for any $l \in [j-1]$ , but I don't have a rigorous proof. Also, if the above is true, it seems then that this statement is true regardless of the distribution of $X_i$ ?","Given i.i.d uniform variables , is it true that the event is independent of for any ? The answer seems to be yes through symmetry: for any , but I don't have a rigorous proof. Also, if the above is true, it seems then that this statement is true regardless of the distribution of ?","X_1, ..., X_n \sim U[0,1] X_i \leq \min_{k \in [i-1]} X_k X_j \leq \min_{k \in [j-1]} X_k i > j \Pr(X_i \leq \min_{k \in [i-1]} X_k | X_j \leq \min_{k \in [j-1]} X_k) = \Pr(X_i \leq \min_{k \in [i-1]} X_k | X_l \leq \min_{k \in [j-1]} X_k) l \in [j-1] X_i","['probability', 'probability-distributions', 'uniform-distribution', 'order-statistics']"
60,Dividing 200 people in 3 unequal rooms and probability of certain combinations,Dividing 200 people in 3 unequal rooms and probability of certain combinations,,"We have 3 rooms (say 1, 2 and 3). Room 1 can take 50 people, room 2 can take 50 and room 3 can take 100. I understand that the number of ways of assigning 200 people to these 3 rooms is $200 \choose 50$$ 150 \choose 50$ . The question is what is the probability that Alice (A) and Bob (B) end up in the same room while Charlotte (C) ends up in a different room. My solution I first divided the event $E$ = {A and B in same room, C in different room} in the disjoint events $E1$ = {{A and B in room 1, C in room 2} $\cup$ {A and B in room 1, C in room 3}}  , $E2$ = {{A and B in room 2, C in room 1} $\cup$ {A and B in room 2, C in room 3}} and $E3$ = {{A and B in room 3, C in room 1} $\cup$ {A and B in room 3, C in room 2}}. I calculated the possible cases for E1 in the following way: $197 \choose 48$$149 \choose 49$ $+$ $197 \choose 47$ $149 \choose 50$ . My reasoning for the case A and B in 1 while C in 2 was that I first pick the people that will make up room 1 alongside A and B (excluding C) and then pick the people that will make up room 2 alongside C (room 3 will then be uniquely determined). The reasoning for the case A and B in 1 while C in 3 was analogous. Similar reasonings were employed to calculate the favorable cases for $E2$ and $E3$ : $|E2|$ = $197 \choose 49$$148 \choose 48$ $+$ $197 \choose 50$ $147 \choose 48$ $|E3|$ = $197 \choose 49$$148 \choose 50$ $+$ $197 \choose 50$ $147 \choose 49$ The probability was then simply calculated by summing the favorable cases for $E1$ , $E2$ and $E3$ and finally dividing by the total number of cases. I am wondering if this method is correct. Furthermore, if it is correct, I am wondering if there is a simpler method since this method requires dealing with awfully big numbers. Thank you for your help.","We have 3 rooms (say 1, 2 and 3). Room 1 can take 50 people, room 2 can take 50 and room 3 can take 100. I understand that the number of ways of assigning 200 people to these 3 rooms is . The question is what is the probability that Alice (A) and Bob (B) end up in the same room while Charlotte (C) ends up in a different room. My solution I first divided the event = {A and B in same room, C in different room} in the disjoint events = {{A and B in room 1, C in room 2} {A and B in room 1, C in room 3}}  , = {{A and B in room 2, C in room 1} {A and B in room 2, C in room 3}} and = {{A and B in room 3, C in room 1} {A and B in room 3, C in room 2}}. I calculated the possible cases for E1 in the following way: . My reasoning for the case A and B in 1 while C in 2 was that I first pick the people that will make up room 1 alongside A and B (excluding C) and then pick the people that will make up room 2 alongside C (room 3 will then be uniquely determined). The reasoning for the case A and B in 1 while C in 3 was analogous. Similar reasonings were employed to calculate the favorable cases for and : = = The probability was then simply calculated by summing the favorable cases for , and and finally dividing by the total number of cases. I am wondering if this method is correct. Furthermore, if it is correct, I am wondering if there is a simpler method since this method requires dealing with awfully big numbers. Thank you for your help.",200 \choose 50 150 \choose 50 E E1 \cup E2 \cup E3 \cup 197 \choose 48149 \choose 49 + 197 \choose 47 149 \choose 50 E2 E3 |E2| 197 \choose 49148 \choose 48 + 197 \choose 50 147 \choose 48 |E3| 197 \choose 49148 \choose 50 + 197 \choose 50 147 \choose 49 E1 E2 E3,"['probability', 'combinatorics']"
61,How do I find the probability distributions for multiple dice rolls for dice with a differing number of sides?,How do I find the probability distributions for multiple dice rolls for dice with a differing number of sides?,,"I have been learning how to play Dungeons and Dragons recently, and have bought my first set of dice. The standard DnD dice are: 1d4 1d6 1d8 1d10 1d10 × 10 [10, 20, 30... 90, 100] 1d12 1d20 I was thinking about inventive ways to determine successes or failures as a DM, and I came up with the Super Roll ! A super roll is rolling all seven of the standard dice, and being asked to roll above a particular number. I think this limit should be constant when asked to make a super roll, but I need to determine what this limit should be. I therefore want to calculate the probability distribution so I can pick a limit with an appropriate chance of succeeding at a super roll. I could simulate this with Python and get an approximation of the distribution, but where's the fun in that? I want to do this in a proper way and learn some maths along the way. But I've hit a wall. Researching this, there is a lot of information about rolling multiple dice. But in every case they always roll dice with the same number of sides . I watched 3Blue1Brown's video about convolutions where Grant begins by explaining how convolutions can be used to add two random variables. In his example, he selects two 6-sided dice. He goes on to say how this becomes a useful tool if, for example, the weightings of these probabilities for a given side isn't uniform. And he gives the formula for a discrete convolution: $$(a * b)_{n} = \sum_{\substack{i,j \\ i+j=n}} a_{i}\cdot b_{j}$$ But I don't want this. My dice aren't biased, instead it is only the number of side that is changing. I have worked through an example by hand using the sliding windows method to convolve two dice rolls, 1d4 with 1d6. It worked, and I methodically calculated the probabilities P(X=x). However in the video Grant then uses python to calculate a convolution. He convolves $(1,2,3) * (4,5,6) = (4,13,28,27,18)$ . For my example, 1d4 and 1d6. The convolution is $(1,2,3,4) * (1,2,3,4,5,6) = (1,4,10,20,30,40,43,38,24)$ , or if I do it in the order I did for the sliding windows, $(1,2,3,4) * (6,5,4,3,2,1) = (6,17,32,50,40,30,20,11,4)$ And I don't see how this is helpful to my problem. What do I need to do here? How can I use convolutions to calculate all values of P(X=x). Any help would be greatly appreciated.","I have been learning how to play Dungeons and Dragons recently, and have bought my first set of dice. The standard DnD dice are: 1d4 1d6 1d8 1d10 1d10 × 10 [10, 20, 30... 90, 100] 1d12 1d20 I was thinking about inventive ways to determine successes or failures as a DM, and I came up with the Super Roll ! A super roll is rolling all seven of the standard dice, and being asked to roll above a particular number. I think this limit should be constant when asked to make a super roll, but I need to determine what this limit should be. I therefore want to calculate the probability distribution so I can pick a limit with an appropriate chance of succeeding at a super roll. I could simulate this with Python and get an approximation of the distribution, but where's the fun in that? I want to do this in a proper way and learn some maths along the way. But I've hit a wall. Researching this, there is a lot of information about rolling multiple dice. But in every case they always roll dice with the same number of sides . I watched 3Blue1Brown's video about convolutions where Grant begins by explaining how convolutions can be used to add two random variables. In his example, he selects two 6-sided dice. He goes on to say how this becomes a useful tool if, for example, the weightings of these probabilities for a given side isn't uniform. And he gives the formula for a discrete convolution: But I don't want this. My dice aren't biased, instead it is only the number of side that is changing. I have worked through an example by hand using the sliding windows method to convolve two dice rolls, 1d4 with 1d6. It worked, and I methodically calculated the probabilities P(X=x). However in the video Grant then uses python to calculate a convolution. He convolves . For my example, 1d4 and 1d6. The convolution is , or if I do it in the order I did for the sliding windows, And I don't see how this is helpful to my problem. What do I need to do here? How can I use convolutions to calculate all values of P(X=x). Any help would be greatly appreciated.","(a * b)_{n} = \sum_{\substack{i,j \\ i+j=n}} a_{i}\cdot b_{j} (1,2,3) * (4,5,6) = (4,13,28,27,18) (1,2,3,4) * (1,2,3,4,5,6) = (1,4,10,20,30,40,43,38,24) (1,2,3,4) * (6,5,4,3,2,1) = (6,17,32,50,40,30,20,11,4)","['probability', 'probability-theory', 'random-variables', 'convolution', 'dice']"
62,Probability of Trees Being Planted Correctly,Probability of Trees Being Planted Correctly,,"OK, so here is a real-world problem that I am actually facing, right now. I ordered ten almond trees from a nursery: 6 Texas Mission (TM), and 4 Hall's Hardy (HH) which are pollinators for each other. I have two plots that the trees are to go in, one with 6 holes and one with 4. So in the 6 hole plot I need 4 TM and 2 HH in between the TM. In the 4 hole plot I need 2 TM and 2 HH. I absolutely must have pollinators near each other (in the same plot) or they will not bear fruit and all is for naught. The problem is ... THE VENDOR DID NOT LABEL THE TREES!!! And it's looking like there's no way to tell them apart until they bloom which is too late. So ... if I just plant the trees at random in the holes, what is the probability of the following: I really do appreciate any help I can get here.","OK, so here is a real-world problem that I am actually facing, right now. I ordered ten almond trees from a nursery: 6 Texas Mission (TM), and 4 Hall's Hardy (HH) which are pollinators for each other. I have two plots that the trees are to go in, one with 6 holes and one with 4. So in the 6 hole plot I need 4 TM and 2 HH in between the TM. In the 4 hole plot I need 2 TM and 2 HH. I absolutely must have pollinators near each other (in the same plot) or they will not bear fruit and all is for naught. The problem is ... THE VENDOR DID NOT LABEL THE TREES!!! And it's looking like there's no way to tell them apart until they bloom which is too late. So ... if I just plant the trees at random in the holes, what is the probability of the following: I really do appreciate any help I can get here.",,['probability']
63,"If $\frac{P(E_n)}{P(F_n)} \to 1$, does $\frac{P(A \cap F_n)}{P(A \cap E_n)} \to 1$?","If , does ?",\frac{P(E_n)}{P(F_n)} \to 1 \frac{P(A \cap F_n)}{P(A \cap E_n)} \to 1,"Let $(\Omega, \mathcal F, P)$ be a probability space. Let $E_1\supset E_2\supset ...$ and $F_1 \supset F_2 \supset...$ be two decreasing sequences of events in $\mathcal F$ with the following properties. $E_n \subset F_n$ . $\bigcap_n E_n  = \bigcap_n F_n \neq \emptyset$ . $P(E_n) > 0$ . Let $A \in \mathcal F$ . Let's assume in addition that $P(A \cap E_n)>0$ . Question. If $P(E_n)/P(F_n) \to 1$ , does $P(A \cap F_n)/P(A \cap E_n) \to 1$ as well? The answer is obviously yes if $P(A \cap \bigcap_nE_n)>0$ , so we can assume this isn't the case. Heuristically, it seems to me that the answer should be yes: $P(F_n)$ and $P(E_n)$ are decreasing to the same limit at the same rate and $P(A \cap E_n)$ and $P(A \cap F_n)$ are decreasing to the same limit. I can't see why intersecting with a single set $A$ would change the rates of convergence, so it seems like the result should hold. I think I'm just missing an easy algebraic trick or something like that, however, because I haven't been able to prove this.","Let be a probability space. Let and be two decreasing sequences of events in with the following properties. . . . Let . Let's assume in addition that . Question. If , does as well? The answer is obviously yes if , so we can assume this isn't the case. Heuristically, it seems to me that the answer should be yes: and are decreasing to the same limit at the same rate and and are decreasing to the same limit. I can't see why intersecting with a single set would change the rates of convergence, so it seems like the result should hold. I think I'm just missing an easy algebraic trick or something like that, however, because I haven't been able to prove this.","(\Omega, \mathcal F, P) E_1\supset E_2\supset ... F_1 \supset F_2 \supset... \mathcal F E_n \subset F_n \bigcap_n E_n  = \bigcap_n F_n \neq \emptyset P(E_n) > 0 A \in \mathcal F P(A \cap E_n)>0 P(E_n)/P(F_n) \to 1 P(A \cap F_n)/P(A \cap E_n) \to 1 P(A \cap \bigcap_nE_n)>0 P(F_n) P(E_n) P(A \cap E_n) P(A \cap F_n) A","['real-analysis', 'probability']"
64,Two hundred people are assigned a number and enter a room. Matching numbers leave. What will be the highest total in the room?,Two hundred people are assigned a number and enter a room. Matching numbers leave. What will be the highest total in the room?,,"I thought up this expected value problem: Two hundred people are each assigned an integer from 1-100 so that there is a pair of each number. They are standing outside of a large waiting room. A random person will enter the room, one at a time. If their pair is there, they both continue on their way, otherwise they wait in the room until their pair arrives. This goes on until there are no people left outside of the waiting room. Question: What is the expected value of what will be the greatest sum of the values in the waiting room? A pair that immediately leaves doesn't contribute to the sum. My thoughts: The lower bound is clearly 100 , if everyone got their pair immediately. The upper bound is 1+2+3+...+100 = 5050 , if there were no pairs for the first 100 people. In the simplified case of 4 people (1,1,2,2) there are 8 orders that will lead to a 2 and 1 being in the room at the same time and 16 orders of 2 being alone, so the expected value should be $\frac{8(2+1)+16(2)}{4!} = 2 \frac 13$ . How can this idea be applied to the larger group?","I thought up this expected value problem: Two hundred people are each assigned an integer from 1-100 so that there is a pair of each number. They are standing outside of a large waiting room. A random person will enter the room, one at a time. If their pair is there, they both continue on their way, otherwise they wait in the room until their pair arrives. This goes on until there are no people left outside of the waiting room. Question: What is the expected value of what will be the greatest sum of the values in the waiting room? A pair that immediately leaves doesn't contribute to the sum. My thoughts: The lower bound is clearly 100 , if everyone got their pair immediately. The upper bound is 1+2+3+...+100 = 5050 , if there were no pairs for the first 100 people. In the simplified case of 4 people (1,1,2,2) there are 8 orders that will lead to a 2 and 1 being in the room at the same time and 16 orders of 2 being alone, so the expected value should be . How can this idea be applied to the larger group?",\frac{8(2+1)+16(2)}{4!} = 2 \frac 13,"['probability', 'statistics', 'recreational-mathematics', 'problem-solving']"
65,How many random numbers must be drawn on average to make the sequence fall for the first time?,How many random numbers must be drawn on average to make the sequence fall for the first time?,,"Consider a game in which random numbers are constantly selected with equal probability in the interval [0, 1] until the first time the number selected is smaller than the previous one. Then, how many random numbers need to be drawn on average for this to happen? I saw the answer elsewhere, but it was explained in a way that I had trouble understanding, so have to re-ask here, if anyone could explain in a more understandable way. BTW, this is the thought process I had when handling this question, not sure at which step the error was introduced: Probability of needing to draw 2 times: $\frac{1}{2}$ Probability of needing to draw 3 times: On the basis that the first two is increasing (probability is $\frac{1}{2}$ ), the probability that the third time decreasing is again $\frac{1}{2}$ , so the final probability of needing to draw 3 times is $(\frac{1}{2})^2$ ... Probability of needing to draw n+1 times: $(\frac{1}{2})^n$ Therefore the average number of times needed to draw = $\sum_{n=1}^\infty \frac{n+1}{2^n}=3$","Consider a game in which random numbers are constantly selected with equal probability in the interval [0, 1] until the first time the number selected is smaller than the previous one. Then, how many random numbers need to be drawn on average for this to happen? I saw the answer elsewhere, but it was explained in a way that I had trouble understanding, so have to re-ask here, if anyone could explain in a more understandable way. BTW, this is the thought process I had when handling this question, not sure at which step the error was introduced: Probability of needing to draw 2 times: Probability of needing to draw 3 times: On the basis that the first two is increasing (probability is ), the probability that the third time decreasing is again , so the final probability of needing to draw 3 times is ... Probability of needing to draw n+1 times: Therefore the average number of times needed to draw =",\frac{1}{2} \frac{1}{2} \frac{1}{2} (\frac{1}{2})^2 (\frac{1}{2})^n \sum_{n=1}^\infty \frac{n+1}{2^n}=3,"['probability', 'sequences-and-series', 'probability-theory']"
66,"Drawing without replacement, order matters - probability function","Drawing without replacement, order matters - probability function",,"I'm not a mathematician, so the description of my problem might seem a little verbose: In a multiple-choice test there is a set of three questions and a set of five possible answers. To each of the three questions one of the five answers is the correct one. No answer can be assigned twice. So three of the $5$ answers will be assigned to one of the three questions and two answers will be left. I would now like to calculate the average score that would result from random answers if each correct answer yields one point. If I'm not mistaken, in this case I have $n!(/n-r)!=60$ possible answer combinations, but I don't know what formula I use to calculate the probability of randomly hitting a combination with $0, 1, 2$ or $3$ correct answers. As far as I can see, this is a draw without replacement where the order matters, so I can neither treat it like a dice problem (e.g. ""How likely are exactly three sixes in ten throws?"" - binomial distribution) nor like a control sample (""How likely is it that exactly $5$ of these $100$ screws are defective?"" - hypergeometric distribution), because then either the non-replacement or the order is not taken into account. I wrote down all $60$ possible permutations and added up how many points each of them would yield. If I counted correctly, there ... -... is one possible permutation that yields all three points, -... are $6$ permutations that yield 2 points, -... are $21$ permutations that yield 1 point, -... are $32$ permutations that yield 0 points. The table is in German, but I think it's not hard to guess what means what: https://i.sstatic.net/g6gZB.jpg Can someone help me with that? Thanks in advance!","I'm not a mathematician, so the description of my problem might seem a little verbose: In a multiple-choice test there is a set of three questions and a set of five possible answers. To each of the three questions one of the five answers is the correct one. No answer can be assigned twice. So three of the answers will be assigned to one of the three questions and two answers will be left. I would now like to calculate the average score that would result from random answers if each correct answer yields one point. If I'm not mistaken, in this case I have possible answer combinations, but I don't know what formula I use to calculate the probability of randomly hitting a combination with or correct answers. As far as I can see, this is a draw without replacement where the order matters, so I can neither treat it like a dice problem (e.g. ""How likely are exactly three sixes in ten throws?"" - binomial distribution) nor like a control sample (""How likely is it that exactly of these screws are defective?"" - hypergeometric distribution), because then either the non-replacement or the order is not taken into account. I wrote down all possible permutations and added up how many points each of them would yield. If I counted correctly, there ... -... is one possible permutation that yields all three points, -... are permutations that yield 2 points, -... are permutations that yield 1 point, -... are permutations that yield 0 points. The table is in German, but I think it's not hard to guess what means what: https://i.sstatic.net/g6gZB.jpg Can someone help me with that? Thanks in advance!","5 n!(/n-r)!=60 0, 1, 2 3 5 100 60 6 21 32","['probability', 'combinatorics']"
67,"Does the Law of Large Number ""work better"" for some distributions compared to others?","Does the Law of Large Number ""work better"" for some distributions compared to others?",,"Does the law of large numbers ""work better"" for certain types of distributions compared to others? For example, imagine one country where the distribution of income is normally distributed - and imagine another country (same sized population as the first) in which most people earn almost no money, and there is one trillionaire. Using the law of large numbers, average incomes calculated from random samples using the first country will tend to reflect the true average income of this country .... but in the second country, random samples will likely not be close to true mean unless the trillionaire citizen is included in the sample, and even if he is included, it might not be close. Thus, in heavily skewed , irregular and multimodal distributions such as the second country - does the law of large numbers some how work ""worse"" than the first country? Although increasing the sample size in both countries will likely produce estimates closer to the real mean income .... I have a feeling that fewer random samples are required if the distribution is less irregular... thus, the law of large numbers indirectly is affected by the type of distribution. Is this true? And if this is true, what does this phenomena (i.e. sample size/accuracy relationship vs irregularity of distribution) referred to? In general, can we relate the ""irregularity"" of a probability distribution to its ""skewness""? Thanks!","Does the law of large numbers ""work better"" for certain types of distributions compared to others? For example, imagine one country where the distribution of income is normally distributed - and imagine another country (same sized population as the first) in which most people earn almost no money, and there is one trillionaire. Using the law of large numbers, average incomes calculated from random samples using the first country will tend to reflect the true average income of this country .... but in the second country, random samples will likely not be close to true mean unless the trillionaire citizen is included in the sample, and even if he is included, it might not be close. Thus, in heavily skewed , irregular and multimodal distributions such as the second country - does the law of large numbers some how work ""worse"" than the first country? Although increasing the sample size in both countries will likely produce estimates closer to the real mean income .... I have a feeling that fewer random samples are required if the distribution is less irregular... thus, the law of large numbers indirectly is affected by the type of distribution. Is this true? And if this is true, what does this phenomena (i.e. sample size/accuracy relationship vs irregularity of distribution) referred to? In general, can we relate the ""irregularity"" of a probability distribution to its ""skewness""? Thanks!",,"['probability', 'statistics', 'law-of-large-numbers']"
68,Applying Chebyshev's inequality to a sequence of independent random variables,Applying Chebyshev's inequality to a sequence of independent random variables,,"Let $X_1, \dots, X_n$ be independent random variables. Assume that $E[X_k] = 0$ and $σ^2_k = E[X^2_k] < \infty$ for each $k$ . I want to show that for all $\epsilon > 0$ , $$ P( \max_k |S_k| \ge \epsilon) ≤ \frac{1}{\epsilon^2} \sum^n_{k=1} σ^2_k $$ where $S_k = X_1 + X_2 + \dots + X_k$ . My thoughts: by Chebyshev, $P(|X_k| \ge \epsilon) \le \frac{1}{\epsilon^2} \sigma_k^2$ for all $k$ . Taking sum over $K$ , we have $$ \sum_{k=1}^n P(|X_k| \ge \epsilon) \le \frac{1}{\epsilon^2} \sum^n_{k=1} σ^2_k $$ But I am having difficulty connecting $P(|X_k| \ge \epsilon)$ to $P( \max_k |S_k| \ge \epsilon)$ . Since the $X_k$ 's are independent, I know $ \sum_{k=1}^n P(|X_k| \ge \epsilon) = P(\max_k |X_k| \ge \epsilon)$ . But I don't know how to proceed next. Can someone give me a hint? Thanks in advance!","Let be independent random variables. Assume that and for each . I want to show that for all , where . My thoughts: by Chebyshev, for all . Taking sum over , we have But I am having difficulty connecting to . Since the 's are independent, I know . But I don't know how to proceed next. Can someone give me a hint? Thanks in advance!","X_1, \dots, X_n E[X_k] = 0 σ^2_k = E[X^2_k] < \infty k \epsilon > 0 
P( \max_k |S_k| \ge \epsilon) ≤ \frac{1}{\epsilon^2} \sum^n_{k=1} σ^2_k
 S_k = X_1 + X_2 + \dots + X_k P(|X_k| \ge \epsilon) \le \frac{1}{\epsilon^2} \sigma_k^2 k K 
\sum_{k=1}^n P(|X_k| \ge \epsilon) \le \frac{1}{\epsilon^2} \sum^n_{k=1} σ^2_k
 P(|X_k| \ge \epsilon) P( \max_k |S_k| \ge \epsilon) X_k 
\sum_{k=1}^n P(|X_k| \ge \epsilon) = P(\max_k |X_k| \ge \epsilon)","['probability', 'probability-theory', 'independence']"
69,Application of Lindeberg-Feller Theorem,Application of Lindeberg-Feller Theorem,,"I want to prove that for independent variables $X_1,X_2,\dots$ $$\frac{\sum\limits_{k=1}^n X_k}{\sqrt{\mathbb V\left(\sum\limits_{k=1}^n X_k\right)}}\xrightarrow{n\to\infty}\mathcal N(0,1),$$ where $\mathbb P(X_n = n) = \mathbb P(X_n = -n) = \frac{1}{2}$ . I cant use the normal CLT because the $X_n$ are not identically distributed. I have to use the Lindeberg-Feller Theorem. I know that $\mathbb E(X_n) = 0$ and that $\mathbb V(X_n) = n^2$ and that therefore $$\mathbb V\left(\sum\limits_{k=1}^n X_k\right) = \sum\limits_{k=1}^n\mathbb V(X_k) = \sum\limits_{k=1}^n k^2 = \frac{n(n+1)(2n+1)}{6}.$$ I know that I need to find $X_{n,k}$ with $\sum\limits_{k=1}^{k_n}\mathbb E(X_{n,k}^2)\xrightarrow{n\to\infty}1$ and $\sum\limits_{k=1}^{k_n}\mathbb E(X_{n,k}^2 \mathbf 1_{\{|X_{n,k}|>\varepsilon\}})\xrightarrow{n\to\infty}0$ for all $\varepsilon >0$ . How can I find such $X_{n,k}$ . Any help is appreciated.",I want to prove that for independent variables where . I cant use the normal CLT because the are not identically distributed. I have to use the Lindeberg-Feller Theorem. I know that and that and that therefore I know that I need to find with and for all . How can I find such . Any help is appreciated.,"X_1,X_2,\dots \frac{\sum\limits_{k=1}^n X_k}{\sqrt{\mathbb V\left(\sum\limits_{k=1}^n X_k\right)}}\xrightarrow{n\to\infty}\mathcal N(0,1), \mathbb P(X_n = n) = \mathbb P(X_n = -n) = \frac{1}{2} X_n \mathbb E(X_n) = 0 \mathbb V(X_n) = n^2 \mathbb V\left(\sum\limits_{k=1}^n X_k\right) = \sum\limits_{k=1}^n\mathbb V(X_k) = \sum\limits_{k=1}^n k^2 = \frac{n(n+1)(2n+1)}{6}. X_{n,k} \sum\limits_{k=1}^{k_n}\mathbb E(X_{n,k}^2)\xrightarrow{n\to\infty}1 \sum\limits_{k=1}^{k_n}\mathbb E(X_{n,k}^2 \mathbf 1_{\{|X_{n,k}|>\varepsilon\}})\xrightarrow{n\to\infty}0 \varepsilon >0 X_{n,k}","['probability', 'probability-theory']"
70,How can I prove that this is a martingale?,How can I prove that this is a martingale?,,"We define $S_0=0$ and $S_n=X_1+...+X_n$ where $(X_n)$ is an i.i.d. sequence such that $\Bbb{P}(X_1=-1)=\Bbb{P}(X_1=1)=1/2$ . We define $\mathfrak{F}_n=\sigma(S_0,...,S_n)$ . I want to show that $(P(S_n,n))_{n\geq 0}$ is an $\mathfrak{F}_n$ -martingale ( $P$ is a polynomial in 2 variables) if for all $l,m\in \Bbb{Z}$ $$P(l+1,m+1)-2P(l,m)+P(l-1,m+1)=0$$ I know that I need to show that $\Bbb{E}(P(S_{n+1},n+1)|\mathfrak{F}_n)=P(S_n,n)$ somehow I don't see how to work with the polynomial case, how can I split this up to get somehow a sum of conditional expectations? I know that this has to do with the equality from above. Could someone maybe give me a hint?","We define and where is an i.i.d. sequence such that . We define . I want to show that is an -martingale ( is a polynomial in 2 variables) if for all I know that I need to show that somehow I don't see how to work with the polynomial case, how can I split this up to get somehow a sum of conditional expectations? I know that this has to do with the equality from above. Could someone maybe give me a hint?","S_0=0 S_n=X_1+...+X_n (X_n) \Bbb{P}(X_1=-1)=\Bbb{P}(X_1=1)=1/2 \mathfrak{F}_n=\sigma(S_0,...,S_n) (P(S_n,n))_{n\geq 0} \mathfrak{F}_n P l,m\in \Bbb{Z} P(l+1,m+1)-2P(l,m)+P(l-1,m+1)=0 \Bbb{E}(P(S_{n+1},n+1)|\mathfrak{F}_n)=P(S_n,n)","['probability', 'probability-theory', 'conditional-expectation']"
71,Distribution of Minimum Distance between repeated integers in a sequence,Distribution of Minimum Distance between repeated integers in a sequence,,"Let $a$ be an integer sequence containing unique consecutive integers $(1, 2, ..., N)$ Let $b$ be any random permutation of $a$ . For example, $(N, 1, ..., 2)$ . Assume $b$ is chosen uniformly from the set of all  permutations of $a$ . Let $c$ be the sequence of $b$ appended to $a$ . Using the two lines above as an example, $c=(1, 2, ..., N, N, 1, ..., 2)$ Let $D$ be the minimum distance between any two repeated elements of $c$ . In the example above, since $N$ immediately follows $N$ , $D=1$ . If $c$ were instead $(1, 2, 3, 2, 3, 1)$ , $D$ would be $2$ since both twos (and threes) are two elements apart in the sequence. Given $D$ varies with the randomly selected permutation of $b$ , $D$ is a random variable. What is the distribution of $D$ as a function of $N$ ? Edit: I wrote some python code to calculate the empirical distribution up to N = 11, in case this helps identify some patterns. Here is the code and the output: def mindist(alist, blist):   min_dist = 9999999999   for item in alist:     b_ind = blist.index(item) + len(alist)     delta = b_ind - alist.index(item)     if delta < min_dist:       min_dist = delta   return min_dist  import itertools for N in range(3, 11 + 1):   distribution = {}   print(N)   aa = list(range(1, N + 1))   permutations = list(itertools.permutations(aa))   for bb in permutations:     md = mindist(aa, list(bb))     if md in distribution.keys():       distribution[md] += 1     else:       distribution[md] = 1   print(distribution)   print('-'*80) Output: 3 {3: 1, 2: 3, 1: 2} -------------------------------------------------------------------------------- 4 {4: 1, 3: 7, 2: 10, 1: 6} -------------------------------------------------------------------------------- 5 {5: 1, 4: 15, 3: 38, 2: 42, 1: 24} -------------------------------------------------------------------------------- 6 {6: 1, 5: 31, 4: 130, 3: 222, 2: 216, 1: 120} -------------------------------------------------------------------------------- 7 {7: 1, 6: 63, 5: 422, 4: 1050, 3: 1464, 2: 1320, 1: 720} -------------------------------------------------------------------------------- 8 {8: 1, 7: 127, 6: 1330, 5: 4686, 4: 8856, 3: 10920, 2: 9360, 1: 5040} -------------------------------------------------------------------------------- 9 {9: 1, 8: 255, 7: 4118, 6: 20202, 5: 50424, 4: 80520, 3: 91440, 2: 75600, 1: 40320} -------------------------------------------------------------------------------- 10 {10: 1, 9: 511, 8: 12610, 7: 85182, 6: 276696, 5: 558120, 4: 795600, 3: 851760, 2: 685440, 1: 362880} -------------------------------------------------------------------------------- 11 {11: 1, 10: 1023, 9: 38342, 8: 353850, 7: 1481784, 6: 3723720, 5: 6502320, 4: 8542800, 3: 8749440, 2: 6894720, 1: 3628800} --------------------------------------------------------------------------------","Let be an integer sequence containing unique consecutive integers Let be any random permutation of . For example, . Assume is chosen uniformly from the set of all  permutations of . Let be the sequence of appended to . Using the two lines above as an example, Let be the minimum distance between any two repeated elements of . In the example above, since immediately follows , . If were instead , would be since both twos (and threes) are two elements apart in the sequence. Given varies with the randomly selected permutation of , is a random variable. What is the distribution of as a function of ? Edit: I wrote some python code to calculate the empirical distribution up to N = 11, in case this helps identify some patterns. Here is the code and the output: def mindist(alist, blist):   min_dist = 9999999999   for item in alist:     b_ind = blist.index(item) + len(alist)     delta = b_ind - alist.index(item)     if delta < min_dist:       min_dist = delta   return min_dist  import itertools for N in range(3, 11 + 1):   distribution = {}   print(N)   aa = list(range(1, N + 1))   permutations = list(itertools.permutations(aa))   for bb in permutations:     md = mindist(aa, list(bb))     if md in distribution.keys():       distribution[md] += 1     else:       distribution[md] = 1   print(distribution)   print('-'*80) Output: 3 {3: 1, 2: 3, 1: 2} -------------------------------------------------------------------------------- 4 {4: 1, 3: 7, 2: 10, 1: 6} -------------------------------------------------------------------------------- 5 {5: 1, 4: 15, 3: 38, 2: 42, 1: 24} -------------------------------------------------------------------------------- 6 {6: 1, 5: 31, 4: 130, 3: 222, 2: 216, 1: 120} -------------------------------------------------------------------------------- 7 {7: 1, 6: 63, 5: 422, 4: 1050, 3: 1464, 2: 1320, 1: 720} -------------------------------------------------------------------------------- 8 {8: 1, 7: 127, 6: 1330, 5: 4686, 4: 8856, 3: 10920, 2: 9360, 1: 5040} -------------------------------------------------------------------------------- 9 {9: 1, 8: 255, 7: 4118, 6: 20202, 5: 50424, 4: 80520, 3: 91440, 2: 75600, 1: 40320} -------------------------------------------------------------------------------- 10 {10: 1, 9: 511, 8: 12610, 7: 85182, 6: 276696, 5: 558120, 4: 795600, 3: 851760, 2: 685440, 1: 362880} -------------------------------------------------------------------------------- 11 {11: 1, 10: 1023, 9: 38342, 8: 353850, 7: 1481784, 6: 3723720, 5: 6502320, 4: 8542800, 3: 8749440, 2: 6894720, 1: 3628800} --------------------------------------------------------------------------------","a (1, 2, ..., N) b a (N, 1, ..., 2) b a c b a c=(1, 2, ..., N, N, 1, ..., 2) D c N N D=1 c (1, 2, 3, 2, 3, 1) D 2 D b D D N","['probability', 'combinatorics', 'discrete-mathematics', 'probability-distributions', 'permutations']"
72,Computing the bias of the estimator $e^{-t/\theta}$,Computing the bias of the estimator,e^{-t/\theta},"I have a random variable with exponential distribution, X~ Exp( $\frac{1}{\theta}$ ) and I need to estimate $\zeta=\mathbb{P}(x>3)$ . I know that $e^{-3/\hat{\theta}}$ is the maximum likehood estimator of $\zeta$ , with $\hat{\theta}=\bar{x}=\sum_{i=1}^{n}x_{i}/n$ . Now I have to compute the MSE of $e^{-3/\hat{\theta}}$ but I don't know  how to start. I know that I need the bias and variance and but how can I compute the mean of $e^{-3/\hat{\theta}}$ ? How can I find its density function? My theacher said that we could use a symbolic calculator to compute an integral in this exercise so I think the answer will be related to compute $\int\theta\cdot g(\theta)d\theta$ with $g$ the density function of $\theta$ .","I have a random variable with exponential distribution, X~ Exp( ) and I need to estimate . I know that is the maximum likehood estimator of , with . Now I have to compute the MSE of but I don't know  how to start. I know that I need the bias and variance and but how can I compute the mean of ? How can I find its density function? My theacher said that we could use a symbolic calculator to compute an integral in this exercise so I think the answer will be related to compute with the density function of .",\frac{1}{\theta} \zeta=\mathbb{P}(x>3) e^{-3/\hat{\theta}} \zeta \hat{\theta}=\bar{x}=\sum_{i=1}^{n}x_{i}/n e^{-3/\hat{\theta}} e^{-3/\hat{\theta}} \int\theta\cdot g(\theta)d\theta g \theta,"['probability', 'probability-theory', 'statistics', 'probability-distributions']"
73,Probability that both red and blue cards exist in a pack of 10 cards?,Probability that both red and blue cards exist in a pack of 10 cards?,,"You are given a pack of 10 cards. Each card has 0.05 probability of being a red card and also 0.05 probability of being a blue card (red and blue cards are rare). What is the probability that the pack has at least 1 red card and at least 1 blue card? I tried solving this problem by enumerating all possible red and blue cards combination: $$\mathbb{P}(\geq 1 \text{ red card and } \geq 1 \text{ blue card}) = \sum_{r=1}^9 \sum_{b=1}^{10 - r} {10 \choose r} {10 - r \choose b} 0.05^r 0.05^b (1 - 0.05 - 0.05)^{10-r-b}$$ However, this is very difficult to compute, especially if the number of cards in the pack gets larger (more than 10). Is there a more clever, simpler way to solve this problem?","You are given a pack of 10 cards. Each card has 0.05 probability of being a red card and also 0.05 probability of being a blue card (red and blue cards are rare). What is the probability that the pack has at least 1 red card and at least 1 blue card? I tried solving this problem by enumerating all possible red and blue cards combination: However, this is very difficult to compute, especially if the number of cards in the pack gets larger (more than 10). Is there a more clever, simpler way to solve this problem?",\mathbb{P}(\geq 1 \text{ red card and } \geq 1 \text{ blue card}) = \sum_{r=1}^9 \sum_{b=1}^{10 - r} {10 \choose r} {10 - r \choose b} 0.05^r 0.05^b (1 - 0.05 - 0.05)^{10-r-b},"['probability', 'statistics', 'discrete-mathematics', 'contest-math', 'puzzle']"
74,"Dynamic dice game, how to reasonably estimate answer by hand without laboriously calculating","Dynamic dice game, how to reasonably estimate answer by hand without laboriously calculating",,"Here's a question from my probability textbook: A casino comes up with a fancy dice game. It allows you to roll a dice as many times as you want unless a $6$ appears. After each roll, if $1$ appears, you will win $\$1$ ; if $2$ appears, you will win $\$2$ ; $\ldots$ ; if $5$ appears, you win $\$5$ , but if $6$ appears all the money you have won in the game is lost and the game stops. After each roll, if the dice number is $1$ - $5$ , you can decide whether to keep the money or keep on rolling. How much are you willing to pay to play the game (if you are risk neutral)? It's been asked before on MSE multiple times: When to stop rolling a die in a game where 6 loses everything Dynamic dice game: optimal price to enter A dynamic dice game Here's the answer to the question in my book: Assuming that we have accumulated $n$ dollars, the decision to have another roll or not depends on the expected profit versus expected loss. If we decide to have an extra roll, our expected payoff will become $${1\over6}(n + 1) + {1\over6}(n + 2) + {1\over6}(n + 3) + {1\over6}(n + 4) + {1\over6}(n + 5) + {1\over6} \times 0 = {5\over6}n + 2.5.$$ We have another roll if the expected payoff ${5\over6}n + 2.5 > n$ , which means that we should keep rolling if the money is no more than $\$14$ . Considering that we will stop rolling when $n \ge 15$ , the maximum payoff of the game is $\$19$ (the dice rolls a $5$ after reaching the state $n = 14$ ). We then have the following: $f(19) = 19$ , $f(18) = 18$ , $f(17) = 17$ , $f(16) = 16$ , and $f(15) = 15$ . When $n \le 14$ , we will keep on rolling, so $E[f(n) \mid n \le 14] = {1\over6} \sum_{i = 1}^5 E[f(n + i)]$ . Using this equation, we can calculate the value for $E[f(n)]$ recursively for all $n = 14, 13, \ldots, 0$ . After laboriously calculating or writing a program, we get $E[f(0)] = 6.15$ , and so we are willing to pay at most $\$6.15$ for this game. However, I'm wondering if there's a quick way by hand to get a reasonable/""good enough"" estimate for $E[f(0)]$ without having to do multiple ""average-five-numbers-and-repeat"" as the book suggests. Is there?","Here's a question from my probability textbook: A casino comes up with a fancy dice game. It allows you to roll a dice as many times as you want unless a appears. After each roll, if appears, you will win ; if appears, you will win ; ; if appears, you win , but if appears all the money you have won in the game is lost and the game stops. After each roll, if the dice number is - , you can decide whether to keep the money or keep on rolling. How much are you willing to pay to play the game (if you are risk neutral)? It's been asked before on MSE multiple times: When to stop rolling a die in a game where 6 loses everything Dynamic dice game: optimal price to enter A dynamic dice game Here's the answer to the question in my book: Assuming that we have accumulated dollars, the decision to have another roll or not depends on the expected profit versus expected loss. If we decide to have an extra roll, our expected payoff will become We have another roll if the expected payoff , which means that we should keep rolling if the money is no more than . Considering that we will stop rolling when , the maximum payoff of the game is (the dice rolls a after reaching the state ). We then have the following: , , , , and . When , we will keep on rolling, so . Using this equation, we can calculate the value for recursively for all . After laboriously calculating or writing a program, we get , and so we are willing to pay at most for this game. However, I'm wondering if there's a quick way by hand to get a reasonable/""good enough"" estimate for without having to do multiple ""average-five-numbers-and-repeat"" as the book suggests. Is there?","6 1 \1 2 \2 \ldots 5 \5 6 1 5 n {1\over6}(n + 1) + {1\over6}(n + 2) + {1\over6}(n + 3) + {1\over6}(n + 4) + {1\over6}(n + 5) + {1\over6} \times 0 = {5\over6}n + 2.5. {5\over6}n + 2.5 > n \14 n \ge 15 \19 5 n = 14 f(19) = 19 f(18) = 18 f(17) = 17 f(16) = 16 f(15) = 15 n \le 14 E[f(n) \mid n \le 14] = {1\over6} \sum_{i = 1}^5 E[f(n + i)] E[f(n)] n = 14, 13, \ldots, 0 E[f(0)] = 6.15 \6.15 E[f(0)]","['probability', 'expected-value', 'game-theory', 'estimation', 'dynamic-programming']"
75,roll until lose game with changing probability,roll until lose game with changing probability,,"Start with probability p $= 1$ Keep rolling until you get a failure. Modify p after each roll, multiplying it by k Count the number of successes. event_count = 0     p = 1     while random() < p:         event_count += 1         p *= k $E$ = expected value of event_count at the end I'm looking for a formula for k in terms of $E$ . (This would be the inversion of the function for $E$ , given k .) random() gives a continuous uniform distribution $[0, 1)$ The probability p changes at each iteration (multiplied by k ). event_count will always be at least $1$ , since p starts at $1$ , so the first random roll will always be a success. If k $>= 1$ , event_count is infinity. If k $<= 0$ , event_count is $1$ . So the interesting values of k are $(0, 1)$ Some samples give these numbers: E: k             1.0: 0.0,             1.01: 0.01,             1.1: 0.099,             1.25: 0.238,             1.5: 0.42,             2.0: 0.645,             3.0: 0.833,             4.0: 0.904,             5.0: 0.938,             6.0: 0.957,             7.0: 0.9685, Most of these digits are significant. I found $0.968$ to be pretty reliably giving $E < 7$ and $0.969$ to reliably give $E > 7$ What's the formula to relate $E$ and k ?","Start with probability p Keep rolling until you get a failure. Modify p after each roll, multiplying it by k Count the number of successes. event_count = 0     p = 1     while random() < p:         event_count += 1         p *= k = expected value of event_count at the end I'm looking for a formula for k in terms of . (This would be the inversion of the function for , given k .) random() gives a continuous uniform distribution The probability p changes at each iteration (multiplied by k ). event_count will always be at least , since p starts at , so the first random roll will always be a success. If k , event_count is infinity. If k , event_count is . So the interesting values of k are Some samples give these numbers: E: k             1.0: 0.0,             1.01: 0.01,             1.1: 0.099,             1.25: 0.238,             1.5: 0.42,             2.0: 0.645,             3.0: 0.833,             4.0: 0.904,             5.0: 0.938,             6.0: 0.957,             7.0: 0.9685, Most of these digits are significant. I found to be pretty reliably giving and to reliably give What's the formula to relate and k ?","= 1 E E E [0, 1) 1 1 >= 1 <= 0 1 (0, 1) 0.968 E < 7 0.969 E > 7 E","['probability', 'expected-value']"
76,A random walk on half the number line,A random walk on half the number line,,Consider a symmetric random walk on the number line where steps are size $1$ .  If a step from $0$ tries to go to $-1$ you stay at $0$ instead. You start at $0$ and we want to compute the expected time to reach $x>0$ . From numerical experiments it seems to be $x(x+1)$ .  How can this be proved?,Consider a symmetric random walk on the number line where steps are size .  If a step from tries to go to you stay at instead. You start at and we want to compute the expected time to reach . From numerical experiments it seems to be .  How can this be proved?,1 0 -1 0 0 x>0 x(x+1),[]
77,"Let $X\sim B(n,p)$. How to calculate the expected value $E[\bar{X}]$,where $\bar{X}=|X-E[X]|$?","Let . How to calculate the expected value ,where ?","X\sim B(n,p) E[\bar{X}] \bar{X}=|X-E[X]|","Let $X\sim B(n,p)$ . How to calculate the the expected value $E[\bar{X}]$ ,where $\bar{X}=|X-E[X]|$ ? Recently I want to prove that \begin{equation} \begin{aligned} f(n)&=\frac1nE[\bar{X}] = \frac1nE[|X-np|]=\frac1n\sum_{i=0}^{n}[C_n^i p^i (1-p)^{n-i}|i - np|] \end{aligned} \end{equation} is decreasing over $\mathbb{Z}^+$ , so need to know how to calculate the expected value $E[\bar{X}]$ . Of course, I would also really appreciate it if you know how to prove it. Edited on July 16, 2022 The previous $f(n)$ missed a coefficient of $\frac1n$ . After correction, I can already prove that $f(n)$ is decreasing over $\mathbb{Z}^+$ . The left side of the following figure is the image of $E[\bar{X}]$ , and the right side is the image of the current $f(n)$ .","Let . How to calculate the the expected value ,where ? Recently I want to prove that is decreasing over , so need to know how to calculate the expected value . Of course, I would also really appreciate it if you know how to prove it. Edited on July 16, 2022 The previous missed a coefficient of . After correction, I can already prove that is decreasing over . The left side of the following figure is the image of , and the right side is the image of the current .","X\sim B(n,p) E[\bar{X}] \bar{X}=|X-E[X]| \begin{equation}
\begin{aligned}
f(n)&=\frac1nE[\bar{X}] = \frac1nE[|X-np|]=\frac1n\sum_{i=0}^{n}[C_n^i p^i (1-p)^{n-i}|i - np|]
\end{aligned}
\end{equation} \mathbb{Z}^+ E[\bar{X}] f(n) \frac1n f(n) \mathbb{Z}^+ E[\bar{X}] f(n)","['probability', 'probability-theory', 'probability-distributions', 'binomial-distribution']"
78,A construction of an uncountable product of independent Bernoulli variables,A construction of an uncountable product of independent Bernoulli variables,,"I have an intuitive stochastic process as follows, but not sure how to construct it rigorously on some probability space. Consider the unit interval $[0,1]$ , each point $x\in [0,1]$ is associated with an independent Bernoulli( $0.5$ ) random variable. Then each realization can be viewed as a function $f$ from $[0,1]$ to $\{0,1\}$ . The level set $\{x: f(x) = 1\}$ is then a random set on $[0,1]$ . I want to argue the set is almost surely (Lebesgue)-measurable, and almost-surely has measure $0.5$ . However, the above construction does not seem to be rigorous. Therefore, I want to know if there exists a probability space $\Omega$ that admits the a stochastic process $f(t,\omega) \in \{0,1\}$ , such that $1.$ all the finite dimensional distribution is a product of independent Bernoulli. $2.$ For almost every $\omega$ , the set $\{x: f(x,\omega) = 1\}$ is measurable, and has probability $0.5$ . It seems the first condition can be guaranteed using the Kolmogorov's extension theorem. But I have not idea how to guarantee the second condition.","I have an intuitive stochastic process as follows, but not sure how to construct it rigorously on some probability space. Consider the unit interval , each point is associated with an independent Bernoulli( ) random variable. Then each realization can be viewed as a function from to . The level set is then a random set on . I want to argue the set is almost surely (Lebesgue)-measurable, and almost-surely has measure . However, the above construction does not seem to be rigorous. Therefore, I want to know if there exists a probability space that admits the a stochastic process , such that all the finite dimensional distribution is a product of independent Bernoulli. For almost every , the set is measurable, and has probability . It seems the first condition can be guaranteed using the Kolmogorov's extension theorem. But I have not idea how to guarantee the second condition.","[0,1] x\in [0,1] 0.5 f [0,1] \{0,1\} \{x: f(x) = 1\} [0,1] 0.5 \Omega f(t,\omega) \in \{0,1\} 1. 2. \omega \{x: f(x,\omega) = 1\} 0.5","['probability', 'probability-theory', 'measure-theory', 'stochastic-processes', 'bernoulli-distribution']"
79,What is the probability of rolling 6 on two cubes when we only count the higher of the two numbers,What is the probability of rolling 6 on two cubes when we only count the higher of the two numbers,,"We roll a six-sided die twice in a row and count the larger of the two different numbers. How likely is it to get a 6 this way? (This problem was translated and there isn't any additional information). I am very confused - firstly, I tried counting all of the different possibilities which would fit the criteria such as rolling: 1,6 2,6 3,6 4,6 5,6 6,1 6,2 6,3 6,4 6,5 There are 10 different possibilities where the higher of the 2 numbers would be 6, so I originally wrote the answer such as 10/36 But then I came with more possibilities and I do not know if they are correct such as: Counting an additional 11th possibility of rolling 6,6 (I don't know if it should be included due to the two numbers being the same value, so I don't know if it counts as a six, because otherwise I would assert that 6 is bigger than 6) Reducing the total number of possibilities from 36 to 21 (so that I would remove the repeating ones but I am not sure if it's correct)","We roll a six-sided die twice in a row and count the larger of the two different numbers. How likely is it to get a 6 this way? (This problem was translated and there isn't any additional information). I am very confused - firstly, I tried counting all of the different possibilities which would fit the criteria such as rolling: 1,6 2,6 3,6 4,6 5,6 6,1 6,2 6,3 6,4 6,5 There are 10 different possibilities where the higher of the 2 numbers would be 6, so I originally wrote the answer such as 10/36 But then I came with more possibilities and I do not know if they are correct such as: Counting an additional 11th possibility of rolling 6,6 (I don't know if it should be included due to the two numbers being the same value, so I don't know if it counts as a six, because otherwise I would assert that 6 is bigger than 6) Reducing the total number of possibilities from 36 to 21 (so that I would remove the repeating ones but I am not sure if it's correct)",,['probability']
80,"Prove equation $E(h(X)\,e^{-Y})=E(e^{-Y})\, E(h(X-\operatorname{Cov}(X,Y)))$",Prove equation,"E(h(X)\,e^{-Y})=E(e^{-Y})\, E(h(X-\operatorname{Cov}(X,Y)))","Prove: $$ E\bigl(h(X)\, e^{-Y}\bigr)  = E\bigl(e^{-Y}\bigr) \, E\bigl(h(X-\operatorname{Cov}(X,Y))\bigr) $$ when $X$ , $Y$ are both normally distributed, $h(X)$ is a function of $X$ . I think it can be proved by definition and maybe conditional distribution. But I am stuck in the calcultation of conditional expected value of $h(X)$ given $Y$ and cannot get result I want to see. Maybe this idea is wrong. Can you solve this problem or give a reachable idea? Thank you very much!","Prove: when , are both normally distributed, is a function of . I think it can be proved by definition and maybe conditional distribution. But I am stuck in the calcultation of conditional expected value of given and cannot get result I want to see. Maybe this idea is wrong. Can you solve this problem or give a reachable idea? Thank you very much!","
E\bigl(h(X)\, e^{-Y}\bigr) 
= E\bigl(e^{-Y}\bigr) \, E\bigl(h(X-\operatorname{Cov}(X,Y))\bigr)
 X Y h(X) X h(X) Y","['probability', 'probability-distributions', 'normal-distribution', 'expected-value']"
81,Estimate Poisson parameter,Estimate Poisson parameter,,"1. Background: Given a parameter $k\in\mathbb{R}^+$ . I have a bunch of positive data pairs $\{(a_i,b_i)|a_i\in\mathbb{R}^+, b_i\in\mathbb{R}^+\}_{i=1}^N$ . For each pair $(a_i,b_i)$ , an observation value $y_i$ is generated by: $$ y_i=\frac{1}{k}(A_i-B_i),~~~~A_i\sim \text{Pois}(ka_i),~~~~B_i\sim \text{Pois}(kb_i), $$ where $A_i$ and $B_i$ are independent. In other words, each $y_i$ is generated by the following three steps: $(1.1)$ Get $a_i$ and randomly pick a value for $A_i$ from $\text{Pois}(ka_i)$ . $(1.2)$ Get $b_i$ and randomly pick a value for $B_i$ from $\text{Pois}(kb_i)$ . $(1.3)$ Perform $y_i=\frac{1}{k}(A_i-B_i)$ . 2. My Question: Now I have a bunch of data points and observation values $\{(a_i,b_i,y_i)\}_{i=1}^N$ . How can I estimate the unknown latent parameter $k\in\mathbb{R}^+$ (globally unified)? 3. My Efforts: $(3.1)$ I may know that the expected value and variance of each $y_i$ can be calculated by: \begin{align} E(y_i)&=\frac{1}{k}[E(A_i)-E(B_i)]=\frac{1}{k}(ka_i-kb_i)=a_i-b_i,\\ D(y_i)&=\frac{1}{k^2}[D(A_i)+D(B_i)]=\frac{1}{k^2}(ka_i+kb_i)=\frac{1}{k}(a_i+b_i). \end{align} $(3.2)$ There are actually $N$ independent nested distributions. For the $i$ -th observation, I can not calculate the variance (since there is only one observation $y_i$ ) to perform maximum likelihood estimation (MLE) or moment estimation (ME) with using $D(y_i)=\frac{1}{k}(a_i+b_i)$ . $(3.3)$ I am confused by how to find a best $k$ that can fit the data points and observations well, by starting from some convincing ideas like MLE or ME? $(3.4)$ Since there may be actually not only one distribution, but exist $N$ compounded distributions, and each compounded distribution correspond to only one data point and observation $(a_i,b_i,y_i)$ , I have no idea about finding the best $k$ . 4. Update (1): I start from the idea of maximum likelihood estimation (MLE). First, let $Y_i$ be a random variable corresponding to $y_i$ , then I have: \begin{align} P(Y_i=s)&=\sum_{n=0}^\infty P(A_i=n+ks)P(B_i=n)\\ &=\sum_{n=0}^\infty \frac{(ka_i)^{n+ks}e^{-ka_i}}{(n+ks)!}\times \frac{(kb_i)^{n}e^{-kb_i}}{n!}\\ &=(ka_i)^{ks}e^{-k(a_i+b_i)}\sum_{n=0}^\infty \frac{(k^2a_ib_i)^n}{n!(n+ks)!}. \end{align} From Wolfram , I have: \begin{align} P(Y_i=s)&=(ka_i)^{ks}e^{-k(a_i+b_i)}\sum_{n=0}^\infty \frac{(k^2a_ib_i)^n}{n!(n+ks)!}\\ &=(ka_i)^{ks}e^{-k(a_i+b_i)} (k^2a_ib_i)^{-\frac{ks}{2}}I_{ks}(2k\sqrt{a_ib_i})\\ &=(\frac{a_i}{b_i})^{\frac{ks}{2}}e^{-k(a_i+b_i)}I_{ks}(2k\sqrt{a_ib_i}), \end{align} where $I_{ks}(\cdot)$ is the modified Bessel function of the first kind. Using the idea of MLE, I want to solve the following problem: \begin{align} \hat{k}&=\underset{k}{\arg\max}~\prod_{i=1}^N{P(Y_i=y_i|k)}\\ &=\underset{k}{\arg\max}~\sum_{i=1}^N{lnP(Y_i=y_i|k)}\\ &=\underset{k}{\arg\max}~\sum_{i=1}^N{ln\left[(\frac{a_i}{b_i})^{\frac{ky_i}{2}}e^{-k(a_i+b_i)}I_{ky_i}(2k\sqrt{a_ib_i})\right]}\\ &=\underset{k}{\arg\max}~\sum_{i=1}^N{\frac{ky_i}{2}ln(\frac{a_i}{b_i})-k(a_i+b_i)+ln\left[I_{ky_i}(2k\sqrt{a_ib_i})\right]}\\ &=\underset{k}{\arg\max}~\sum_{i=1}^N{k\left[\frac{y_i}{2}ln(\frac{a_i}{b_i})-(a_i+b_i)\right]+ln\left[I_{ky_i}(2k\sqrt{a_ib_i})\right]}. \end{align} Due to the existence of $ln\left[I_{ky_i}(2k\sqrt{a_ib_i})\right]$ , I am stucked and think that it is too hard for me to get the derivative and the optimal $k$ . The derivative of the above infinite series is also quite complicated: Link . After a long struggle, I am still failed to get the answer. I am not sure if the above steps are all correct. Could you please figure it out for me? 5. Update (2): Following the suggestion from @BinxuWang王彬旭, I write the following Python program for simulation: import numpy as np from scipy.stats import skellam  data_len = 80 max_value = 1.0 A = np.random.rand(data_len,) * max_value  B = np.random.rand(data_len,) * max_value  k_gt = 100.0  Y_observed = (np.random.poisson(k_gt * A) - np.random.poisson(k_gt * B)) / k_gt  for k in range(9):     k = 10 ** (k - 4)     Y_k = Y_observed * k     mu1 = A * k     mu2 = B * k     L = np.sum(np.log(skellam._pmf(Y_k, mu1, mu2)))  # L = sum(log(...))     print(k, L) The output is: 0.0001 -0.031569807095909126 0.001 -0.2549938771522239 0.01 -1.9421743846032573 0.1 -13.274040574073975 1 -66.80138745123028 10 -162.06597061912214 100 -278.81300414250535 1000 nan 10000 nan The true value of $k$ is $100$ . However, I see that the optimal $k$ given by this program will always be zero, since the likelihood evaluation value may monotonically decrease in $(0,+\infty)$ . And even when $k=100$ , I can not see that it peaks the maximal value. Similar phenomenons are observed with various combinations of data_len , max_value and k_gt . Is my implementation wrong, or I missed something? 6. Update (3): It seems that the following approach inspired by a comment from Zhihu works. Let $Z_i=\frac{Y_i-(a_i-b_i)}{\sqrt{a_i+b_i}}$ , then we have $E(Z_i)=0$ and $D(Z_i)=\frac{1}{k}$ . Although different $Z_i$ s might not obey the same latent population distribution, I write the following program for test: import numpy as np  data_len = 1000000 max_value = 1e3  for i in range(10):     k_gt = np.random.rand(1,) * 1e4      A = np.random.rand(data_len,) * max_value      B = np.random.rand(data_len,) * max_value       Y_observed = (np.random.poisson(k_gt * A) - np.random.poisson(k_gt * B)) / k_gt      z = (Y_observed - (A - B)) / ((A + B) ** 0.5)     k_hat = 1 / z.var()     #print('E(z) =', z.mean())     #print('D(z) =', z.var())     print('True k =', k_gt)     print('Estimated k = ', k_hat)     print('===') The output is: True k = [2298.1854775] Estimated k =  2300.5718461385372 === True k = [7922.65659395] Estimated k =  7917.124293172064 === True k = [263.85265814] Estimated k =  263.6420801776157 === True k = [6645.19567678] Estimated k =  6648.825624909179 === True k = [9224.97551002] Estimated k =  9221.90494158757 === True k = [5343.45415427] Estimated k =  5343.7859362020945 === True k = [3711.94735707] Estimated k =  3722.572332730343 === True k = [5075.17847329] Estimated k =  5071.739140612038 === True k = [4805.75795587] Estimated k =  4806.967854078318 === True k = [1378.56419652] Estimated k =  1379.657342920305 === I think this method may be sensible since it gives estimation $\hat{k}$ quite close to the latent true $k$ . And when the sample number data_len increases, the estimation becomes more accurate.","1. Background: Given a parameter . I have a bunch of positive data pairs . For each pair , an observation value is generated by: where and are independent. In other words, each is generated by the following three steps: Get and randomly pick a value for from . Get and randomly pick a value for from . Perform . 2. My Question: Now I have a bunch of data points and observation values . How can I estimate the unknown latent parameter (globally unified)? 3. My Efforts: I may know that the expected value and variance of each can be calculated by: There are actually independent nested distributions. For the -th observation, I can not calculate the variance (since there is only one observation ) to perform maximum likelihood estimation (MLE) or moment estimation (ME) with using . I am confused by how to find a best that can fit the data points and observations well, by starting from some convincing ideas like MLE or ME? Since there may be actually not only one distribution, but exist compounded distributions, and each compounded distribution correspond to only one data point and observation , I have no idea about finding the best . 4. Update (1): I start from the idea of maximum likelihood estimation (MLE). First, let be a random variable corresponding to , then I have: From Wolfram , I have: where is the modified Bessel function of the first kind. Using the idea of MLE, I want to solve the following problem: Due to the existence of , I am stucked and think that it is too hard for me to get the derivative and the optimal . The derivative of the above infinite series is also quite complicated: Link . After a long struggle, I am still failed to get the answer. I am not sure if the above steps are all correct. Could you please figure it out for me? 5. Update (2): Following the suggestion from @BinxuWang王彬旭, I write the following Python program for simulation: import numpy as np from scipy.stats import skellam  data_len = 80 max_value = 1.0 A = np.random.rand(data_len,) * max_value  B = np.random.rand(data_len,) * max_value  k_gt = 100.0  Y_observed = (np.random.poisson(k_gt * A) - np.random.poisson(k_gt * B)) / k_gt  for k in range(9):     k = 10 ** (k - 4)     Y_k = Y_observed * k     mu1 = A * k     mu2 = B * k     L = np.sum(np.log(skellam._pmf(Y_k, mu1, mu2)))  # L = sum(log(...))     print(k, L) The output is: 0.0001 -0.031569807095909126 0.001 -0.2549938771522239 0.01 -1.9421743846032573 0.1 -13.274040574073975 1 -66.80138745123028 10 -162.06597061912214 100 -278.81300414250535 1000 nan 10000 nan The true value of is . However, I see that the optimal given by this program will always be zero, since the likelihood evaluation value may monotonically decrease in . And even when , I can not see that it peaks the maximal value. Similar phenomenons are observed with various combinations of data_len , max_value and k_gt . Is my implementation wrong, or I missed something? 6. Update (3): It seems that the following approach inspired by a comment from Zhihu works. Let , then we have and . Although different s might not obey the same latent population distribution, I write the following program for test: import numpy as np  data_len = 1000000 max_value = 1e3  for i in range(10):     k_gt = np.random.rand(1,) * 1e4      A = np.random.rand(data_len,) * max_value      B = np.random.rand(data_len,) * max_value       Y_observed = (np.random.poisson(k_gt * A) - np.random.poisson(k_gt * B)) / k_gt      z = (Y_observed - (A - B)) / ((A + B) ** 0.5)     k_hat = 1 / z.var()     #print('E(z) =', z.mean())     #print('D(z) =', z.var())     print('True k =', k_gt)     print('Estimated k = ', k_hat)     print('===') The output is: True k = [2298.1854775] Estimated k =  2300.5718461385372 === True k = [7922.65659395] Estimated k =  7917.124293172064 === True k = [263.85265814] Estimated k =  263.6420801776157 === True k = [6645.19567678] Estimated k =  6648.825624909179 === True k = [9224.97551002] Estimated k =  9221.90494158757 === True k = [5343.45415427] Estimated k =  5343.7859362020945 === True k = [3711.94735707] Estimated k =  3722.572332730343 === True k = [5075.17847329] Estimated k =  5071.739140612038 === True k = [4805.75795587] Estimated k =  4806.967854078318 === True k = [1378.56419652] Estimated k =  1379.657342920305 === I think this method may be sensible since it gives estimation quite close to the latent true . And when the sample number data_len increases, the estimation becomes more accurate.","k\in\mathbb{R}^+ \{(a_i,b_i)|a_i\in\mathbb{R}^+, b_i\in\mathbb{R}^+\}_{i=1}^N (a_i,b_i) y_i 
y_i=\frac{1}{k}(A_i-B_i),~~~~A_i\sim \text{Pois}(ka_i),~~~~B_i\sim \text{Pois}(kb_i),
 A_i B_i y_i (1.1) a_i A_i \text{Pois}(ka_i) (1.2) b_i B_i \text{Pois}(kb_i) (1.3) y_i=\frac{1}{k}(A_i-B_i) \{(a_i,b_i,y_i)\}_{i=1}^N k\in\mathbb{R}^+ (3.1) y_i \begin{align}
E(y_i)&=\frac{1}{k}[E(A_i)-E(B_i)]=\frac{1}{k}(ka_i-kb_i)=a_i-b_i,\\
D(y_i)&=\frac{1}{k^2}[D(A_i)+D(B_i)]=\frac{1}{k^2}(ka_i+kb_i)=\frac{1}{k}(a_i+b_i).
\end{align} (3.2) N i y_i D(y_i)=\frac{1}{k}(a_i+b_i) (3.3) k (3.4) N (a_i,b_i,y_i) k Y_i y_i \begin{align}
P(Y_i=s)&=\sum_{n=0}^\infty P(A_i=n+ks)P(B_i=n)\\
&=\sum_{n=0}^\infty \frac{(ka_i)^{n+ks}e^{-ka_i}}{(n+ks)!}\times \frac{(kb_i)^{n}e^{-kb_i}}{n!}\\
&=(ka_i)^{ks}e^{-k(a_i+b_i)}\sum_{n=0}^\infty \frac{(k^2a_ib_i)^n}{n!(n+ks)!}.
\end{align} \begin{align}
P(Y_i=s)&=(ka_i)^{ks}e^{-k(a_i+b_i)}\sum_{n=0}^\infty \frac{(k^2a_ib_i)^n}{n!(n+ks)!}\\
&=(ka_i)^{ks}e^{-k(a_i+b_i)} (k^2a_ib_i)^{-\frac{ks}{2}}I_{ks}(2k\sqrt{a_ib_i})\\
&=(\frac{a_i}{b_i})^{\frac{ks}{2}}e^{-k(a_i+b_i)}I_{ks}(2k\sqrt{a_ib_i}),
\end{align} I_{ks}(\cdot) \begin{align}
\hat{k}&=\underset{k}{\arg\max}~\prod_{i=1}^N{P(Y_i=y_i|k)}\\
&=\underset{k}{\arg\max}~\sum_{i=1}^N{lnP(Y_i=y_i|k)}\\
&=\underset{k}{\arg\max}~\sum_{i=1}^N{ln\left[(\frac{a_i}{b_i})^{\frac{ky_i}{2}}e^{-k(a_i+b_i)}I_{ky_i}(2k\sqrt{a_ib_i})\right]}\\
&=\underset{k}{\arg\max}~\sum_{i=1}^N{\frac{ky_i}{2}ln(\frac{a_i}{b_i})-k(a_i+b_i)+ln\left[I_{ky_i}(2k\sqrt{a_ib_i})\right]}\\
&=\underset{k}{\arg\max}~\sum_{i=1}^N{k\left[\frac{y_i}{2}ln(\frac{a_i}{b_i})-(a_i+b_i)\right]+ln\left[I_{ky_i}(2k\sqrt{a_ib_i})\right]}.
\end{align} ln\left[I_{ky_i}(2k\sqrt{a_ib_i})\right] k k 100 k (0,+\infty) k=100 Z_i=\frac{Y_i-(a_i-b_i)}{\sqrt{a_i+b_i}} E(Z_i)=0 D(Z_i)=\frac{1}{k} Z_i \hat{k} k","['probability', 'statistics', 'random-variables', 'poisson-distribution', 'maximum-likelihood']"
82,Sequence of random variables converging to zero arbitrarily slowly,Sequence of random variables converging to zero arbitrarily slowly,,"The following question occurred to me: Suppose $X_n$ is a sequence of positive random variables satisfying for all $\delta>0$ , $P(X_n < \delta) \to 1$ . Is it true that there must exist a sequence $a_n \to 0$ so that $X_n = O_P(a_n)$ ? My inclination is that this is false, but I cannot come up with a counter example. Such a counter example sequence of random variables would effectively need to decrease to zero ""arbitrarily slowly"". Can any of you smart folks come up with a proof or counter example?","The following question occurred to me: Suppose is a sequence of positive random variables satisfying for all , . Is it true that there must exist a sequence so that ? My inclination is that this is false, but I cannot come up with a counter example. Such a counter example sequence of random variables would effectively need to decrease to zero ""arbitrarily slowly"". Can any of you smart folks come up with a proof or counter example?",X_n \delta>0 P(X_n < \delta) \to 1 a_n \to 0 X_n = O_P(a_n),"['real-analysis', 'probability', 'probability-theory']"
83,Probability of crossing between a line on a circle and a line segment inside the circle,Probability of crossing between a line on a circle and a line segment inside the circle,,"Say that we have a circle centered in $(0,0)$ with a radius $R$ . Inside the circle, we have a vertical line segment of length $2d$ in the center of the circle ( $x_1=-d,x_2=d,y_1=y_2=0$ ). Now let's take two points on the circumference of the circle with angle $\theta_1,\theta_2$ and draw a line between them. You can see it better by the figure below. My question will be what is the probability of having these two lines (the one at the origin and the random one). My first idea is to take $\theta_1,\theta_2$ from a uniform distribution and so I'll just need to find the condition for the crossing and I can then just integrate $\int\int d\theta_1 d\theta_2$ and this will be some function of $d/R$ . Starting from this I could write that for this crossing to happen we should have $-d<y(0)<d$ where $y(x)$ is the line equation for the random line. I can then rewrite this condition as: $|\cos(\theta_1) \cot(\frac{\theta_1 + \theta_2}{2}) + \sin(\theta_1) |\leq \frac{d}{R}$ . Numerically, I can find this probability (I did two things, first I would take a large amount of random line about 10 million and see how many cross on average and change $d/R$ and see how it changes and the other was just to check with the condition above for all values of $\theta_1,\theta_2 \in [0,2\pi]$ and also average and both methods gives the same results). But I'm trying to find an analytical expression and I'm stuck here. My idea is to first fix $\theta_1$ then find a condition for $\theta_2$ and then integrate $\theta_2$ and afterwards integrate $\theta_1$ between $0,2\pi$ and this should in principle give me the probability, but I can't seem to find a way to express the integration condition for $\theta_2$ , I tried doing it with Mathematica as well but it's not working out. Any help will be appreciated. Also, if needed, here's the results that I got from numerics for the probability.","Say that we have a circle centered in with a radius . Inside the circle, we have a vertical line segment of length in the center of the circle ( ). Now let's take two points on the circumference of the circle with angle and draw a line between them. You can see it better by the figure below. My question will be what is the probability of having these two lines (the one at the origin and the random one). My first idea is to take from a uniform distribution and so I'll just need to find the condition for the crossing and I can then just integrate and this will be some function of . Starting from this I could write that for this crossing to happen we should have where is the line equation for the random line. I can then rewrite this condition as: . Numerically, I can find this probability (I did two things, first I would take a large amount of random line about 10 million and see how many cross on average and change and see how it changes and the other was just to check with the condition above for all values of and also average and both methods gives the same results). But I'm trying to find an analytical expression and I'm stuck here. My idea is to first fix then find a condition for and then integrate and afterwards integrate between and this should in principle give me the probability, but I can't seem to find a way to express the integration condition for , I tried doing it with Mathematica as well but it's not working out. Any help will be appreciated. Also, if needed, here's the results that I got from numerics for the probability.","(0,0) R 2d x_1=-d,x_2=d,y_1=y_2=0 \theta_1,\theta_2 \theta_1,\theta_2 \int\int d\theta_1 d\theta_2 d/R -d<y(0)<d y(x) |\cos(\theta_1) \cot(\frac{\theta_1 + \theta_2}{2}) + \sin(\theta_1) |\leq \frac{d}{R} d/R \theta_1,\theta_2 \in [0,2\pi] \theta_1 \theta_2 \theta_2 \theta_1 0,2\pi \theta_2","['probability', 'geometry', 'circles']"
84,Continuous bounded martingale of finite variation (ito lemma?),Continuous bounded martingale of finite variation (ito lemma?),,"The question: Suppose that $(M_t) $ $ : t \in [0,\infty)$ is a bounded continuous martingale with finite variation. Prove that $M_t^2  = M_0^2  + 2 \int_0^t  M_s dM_s,$ where the final integral is almost surely well-defined. (Hint: Cite here known results about one-dimensional functions of bounded variation.) Deduce that $M$ is almost surely constant My attempt Im fairly sure the last part is quite easy by taking the expected value of both sides and knowing that the stochastic integral is a martingale. My struggle lies within the first bit. Can I just use Itô formula using $f(x) = \frac{x^2}{2} $ ? That is to say: $f(M_t) -f(M_0) = \int_0^t f'(M_s)dM_s + \frac{1}{2}\int_0^tf''(M_s)ds$ This then gives me $\frac{M_t^2}{2} - \frac{M_0^2}{2} = \int_0^tM_sdM_s + t$ This is very nearly what I need but I have the annoying $+t$ on the end. Can I get rid of this somehow? I haven't at all used the continuity, boundedness or finite variation so i think I've done something wrong. What is the ""well known result"" the hint suggests I use? EDIT My textbook states: I do not understand how any of the equalities follow or hold? Is it that because the process is of finite variation we can just. use normal calculus? What is the formula being used here please","The question: Suppose that is a bounded continuous martingale with finite variation. Prove that where the final integral is almost surely well-defined. (Hint: Cite here known results about one-dimensional functions of bounded variation.) Deduce that is almost surely constant My attempt Im fairly sure the last part is quite easy by taking the expected value of both sides and knowing that the stochastic integral is a martingale. My struggle lies within the first bit. Can I just use Itô formula using ? That is to say: This then gives me This is very nearly what I need but I have the annoying on the end. Can I get rid of this somehow? I haven't at all used the continuity, boundedness or finite variation so i think I've done something wrong. What is the ""well known result"" the hint suggests I use? EDIT My textbook states: I do not understand how any of the equalities follow or hold? Is it that because the process is of finite variation we can just. use normal calculus? What is the formula being used here please","(M_t)   : t \in [0,\infty) M_t^2
 = M_0^2
 + 2 \int_0^t 
M_s dM_s, M f(x) = \frac{x^2}{2}  f(M_t) -f(M_0) = \int_0^t f'(M_s)dM_s + \frac{1}{2}\int_0^tf''(M_s)ds \frac{M_t^2}{2} - \frac{M_0^2}{2} = \int_0^tM_sdM_s + t +t","['probability', 'probability-theory', 'brownian-motion', 'martingales']"
85,Law of large numbers with incomplete observation,Law of large numbers with incomplete observation,,"I am currently reading the book Introduction to Reinforcement Learning by R. S. Sutton and A. G. Barto. The authors often reason with the LLN. In particular, at one point there is an expression like this (beginning of Section 2.2 - Action-value Methods) $$ 	\frac{\sum_{i = 1}^{t-1}R_i \mathbb{1}_{\{A_i = a\}}}{\sum_{i=1}^{t-1} \mathbb{1}_{\{A_i = a\}}}, 	$$ where $R_i$ are the rewards and $A_i$ are the actions taken at time $i$ . If I understand correctly, they claim that by the LLN, this expression converges to the mean of $R_i$ as long as Action $a$ is chosen infinitely often. Intuitively this of course makes sense, but I am not convinced. I am familiar with the LLN like this: Take $X_1,X_2,\dots$ iid, where $\mathbb{E}[|X_1|]$ exists. Then $$ 	\lim_{n \to \infty} \frac1n \sum_{i=1}^{n} X_i = \mathbb{E}[X_1] \hspace{20pt} 	$$ almost surely. I tried to recreate the situation from the book like this: We have two sequences $X_1,X_2,\dots$ iid and $C_1,C_2,\dots$ iid (if necessary, let the two sequences be independent), where $\mathbb{E}[|X_1|]$ and $\mathbb{E}[|C_1|]$ exist. Let $\mathbb{P}[C_i = \pm 1] = 1/2$ . Then intuitively the expression $$ 	\frac{\sum_{i = 1}^{n}X_i \mathbb{1}_{\{C_i = 1\}}}{\sum_{i=1}^{n} \mathbb{1}_{\{C_i = 1\}}} 	$$ should indeed converge almost surely to $\mathbb{E}[X_1]$ , since the probability of $\{C_i = 1\}$ only finitly many times is zero (i.e. you observe $X_i$ infinitely often almost surely). If this is correct, how can you argue this rigorously?","I am currently reading the book Introduction to Reinforcement Learning by R. S. Sutton and A. G. Barto. The authors often reason with the LLN. In particular, at one point there is an expression like this (beginning of Section 2.2 - Action-value Methods) where are the rewards and are the actions taken at time . If I understand correctly, they claim that by the LLN, this expression converges to the mean of as long as Action is chosen infinitely often. Intuitively this of course makes sense, but I am not convinced. I am familiar with the LLN like this: Take iid, where exists. Then almost surely. I tried to recreate the situation from the book like this: We have two sequences iid and iid (if necessary, let the two sequences be independent), where and exist. Let . Then intuitively the expression should indeed converge almost surely to , since the probability of only finitly many times is zero (i.e. you observe infinitely often almost surely). If this is correct, how can you argue this rigorously?","
	\frac{\sum_{i = 1}^{t-1}R_i \mathbb{1}_{\{A_i = a\}}}{\sum_{i=1}^{t-1} \mathbb{1}_{\{A_i = a\}}},
	 R_i A_i i R_i a X_1,X_2,\dots \mathbb{E}[|X_1|] 
	\lim_{n \to \infty} \frac1n \sum_{i=1}^{n} X_i = \mathbb{E}[X_1] \hspace{20pt}
	 X_1,X_2,\dots C_1,C_2,\dots \mathbb{E}[|X_1|] \mathbb{E}[|C_1|] \mathbb{P}[C_i = \pm 1] = 1/2 
	\frac{\sum_{i = 1}^{n}X_i \mathbb{1}_{\{C_i = 1\}}}{\sum_{i=1}^{n} \mathbb{1}_{\{C_i = 1\}}}
	 \mathbb{E}[X_1] \{C_i = 1\} X_i","['probability', 'statistics', 'law-of-large-numbers']"
86,Intuition on independence of two events.,Intuition on independence of two events.,,"The following question is taken from a textbook: Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 87-88) Please note that this is not a question on how to calculate independence, I am fully aware of this. Instead, the intuition is what I am looking for in the below confusing question. Consider the experiment of throwing a die twice. One should be clear from the context that the outcomes are in the form of a tuple $(\textbf{dice_1}, \textbf{dice_2})$ and the sample space is: $$ S = \left\{(1, 1), (1, 2), \ldots, (6, 6)\right\} $$ Define the three events below: $$ A = \{\textbf{1st dice is 3}\} \quad B = \{\textbf{sum of two die is 7}\} \quad C = \{\textbf{sum of two die is 8}\} $$ We want to find out if events $A$ and $B$ are independent? How about $A$ and $C$ ? Now the answer is easy to get if you just use the formula and show that if $P(A \cap B) = P(A)P(B)$ and in a similar vein for event $A$ and $C$ . However, I want to understand it more intuitively as my intuition failed me immediately, when I saw the question I thought that both should have similar answer since they are asked similarly. We focus on the independence of $A$ and $C$ first. The author said that intuitively, given that event $C$ has happened, will this affect the probability of $A$ happening? I assume that this means we do have to know the probability of event $A$ without $C$ first. We can enumerate and see that event $A$ has the following set representation: $$ A = \{(3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6)\} $$ which amounts to $P(A) = \frac{6}{36} = \frac{1}{6}$ . Now if $C$ happened, we know that the two rolls have a sum of $8$ , and we cannot construct a sum of $8$ with a roll of $1$ . To me, I immediately know that event $A$ cannot have the outcome that has a $1$ in the second roll, and thus the outcomes should only be limited to $5$ instead of $6$ and hence dependence is established. However, I believe somewhere my intuition is flawed, the author mentioned that: If you like a more intuitive argument, you can imagine that C has happened, i.e., the sum is 8. Then the probability for the first die to be 1 is 0 because there is no way to construct 8 when the first die is 1. As a result, we have eliminated one choice for the first die, leaving only five options. Therefore, since C has influenced the probability of A, they are dependent. I think I cannot understand why the author mentioned about ""first die"" when in event $A$ , the first die is already a $3$ . If we follow this line of logic, does this mean we do not actually need to know how event $A$ is defined? Is my interpretation wrong?","The following question is taken from a textbook: Stanley H. Chan: Introduction to Probability for Data Science, 2021. (pp. 87-88) Please note that this is not a question on how to calculate independence, I am fully aware of this. Instead, the intuition is what I am looking for in the below confusing question. Consider the experiment of throwing a die twice. One should be clear from the context that the outcomes are in the form of a tuple and the sample space is: Define the three events below: We want to find out if events and are independent? How about and ? Now the answer is easy to get if you just use the formula and show that if and in a similar vein for event and . However, I want to understand it more intuitively as my intuition failed me immediately, when I saw the question I thought that both should have similar answer since they are asked similarly. We focus on the independence of and first. The author said that intuitively, given that event has happened, will this affect the probability of happening? I assume that this means we do have to know the probability of event without first. We can enumerate and see that event has the following set representation: which amounts to . Now if happened, we know that the two rolls have a sum of , and we cannot construct a sum of with a roll of . To me, I immediately know that event cannot have the outcome that has a in the second roll, and thus the outcomes should only be limited to instead of and hence dependence is established. However, I believe somewhere my intuition is flawed, the author mentioned that: If you like a more intuitive argument, you can imagine that C has happened, i.e., the sum is 8. Then the probability for the first die to be 1 is 0 because there is no way to construct 8 when the first die is 1. As a result, we have eliminated one choice for the first die, leaving only five options. Therefore, since C has influenced the probability of A, they are dependent. I think I cannot understand why the author mentioned about ""first die"" when in event , the first die is already a . If we follow this line of logic, does this mean we do not actually need to know how event is defined? Is my interpretation wrong?","(\textbf{dice_1}, \textbf{dice_2}) 
S = \left\{(1, 1), (1, 2), \ldots, (6, 6)\right\}
 
A = \{\textbf{1st dice is 3}\} \quad B = \{\textbf{sum of two die is 7}\} \quad C = \{\textbf{sum of two die is 8}\}
 A B A C P(A \cap B) = P(A)P(B) A C A C C A A C A 
A = \{(3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6)\}
 P(A) = \frac{6}{36} = \frac{1}{6} C 8 8 1 A 1 5 6 A 3 A",['probability']
87,Why does the variance of the number of occurrences of a subsequence in a random sequence depend on the subsequence?,Why does the variance of the number of occurrences of a subsequence in a random sequence depend on the subsequence?,,"Question Why is the variance of the number of times we see the subsequences $[0, 0, 0, 1]$ and $[1, 0, 1, 0]$ in a random sequence of 1024 bits differ from one another and the binomial distribution $B(1021, 2^{-4})$ ? How can I calculate the probability and variance of seeing a particular subsequence? Background When looking at different ways of evaluating the output of a random number generator, I was looking at checking if the number of occurrences of a particular subsequence in a string of bits was within a confidence interval. As I played around with this method, I found some surprising results. I generated sequences of 1024 bits and counted the number of times a specific subsequence of length four occurred. I expected that out of the 1021 sliding window positions, the distribution of the number of matches would follow a binomial distribution of $B(1021,2^{-4})$ , which would have a mean of 63.8 and a variance of 59.8. However, the results I observed were quite different: Other Thoughts The differences in variance seem to be related to the fact that the subsequences are not independent, i.e., if you see the subsequence $[0, 0, 0, 1]$ then if you shift the sliding window over three places, you are guaranteed not to see that subsequence again no matter the next value. However, for the subsequence $[1, 0, 1, 0]$ you can shift over the window two times and have a chance of seeing the same subsequence again. But this would lead me to believe that the subsequence $[1, 0, 1, 0]$ is more likely as you would have more chances of seeing it in a sequence. But this is not the case. Code import matplotlib.pyplot as plt import seaborn as sns import numpy as np  # Generate 100,000 random 1024 bit sequences random_array = np.random.choice(a=[False, True], size=(100000, 1024))  # Generate a 4 element sliding window view sliding_window_view = np.lib.stride_tricks.sliding_window_view(     random_array, 4, axis=1 )  # requires np >= 1.20  # Count the number of sliding windows that equal [1, 0, 1, 0] number_of_1010 = np.all(sliding_window_view == [1, 0, 1, 0], axis=2).sum(axis=1) # Count the number of sliding windows that equal [0, 0, 0, 1] number_of_0001 = np.all(sliding_window_view == [0, 0, 0, 1], axis=2).sum(axis=1) # Generate my expected distribution expected = np.random.binomial(1021, 2**-4, size=100000)  # Show density plot sns.kdeplot(     number_of_1010,     bw=0.5,     label=(         f""[1, 0, 1, 0]; mean {np.mean(number_of_1010):.2f}; var""         f"" {np.var(number_of_1010):.2f}""     ), ) sns.kdeplot(     number_of_0001,     bw=0.5,     label=(         f""[0, 0, 0, 1]; mean {np.mean(number_of_0001):.2f}; var""         f"" {np.var(number_of_0001):.2f}""     ), ) sns.kdeplot(     expected,     bw=0.5,     label=(         f""B(1021, 2^-4); mean {np.mean(expected):.2f}; var""         f"" {np.var(expected):.2f}""     ), ) plt.legend() plt.show()","Question Why is the variance of the number of times we see the subsequences and in a random sequence of 1024 bits differ from one another and the binomial distribution ? How can I calculate the probability and variance of seeing a particular subsequence? Background When looking at different ways of evaluating the output of a random number generator, I was looking at checking if the number of occurrences of a particular subsequence in a string of bits was within a confidence interval. As I played around with this method, I found some surprising results. I generated sequences of 1024 bits and counted the number of times a specific subsequence of length four occurred. I expected that out of the 1021 sliding window positions, the distribution of the number of matches would follow a binomial distribution of , which would have a mean of 63.8 and a variance of 59.8. However, the results I observed were quite different: Other Thoughts The differences in variance seem to be related to the fact that the subsequences are not independent, i.e., if you see the subsequence then if you shift the sliding window over three places, you are guaranteed not to see that subsequence again no matter the next value. However, for the subsequence you can shift over the window two times and have a chance of seeing the same subsequence again. But this would lead me to believe that the subsequence is more likely as you would have more chances of seeing it in a sequence. But this is not the case. Code import matplotlib.pyplot as plt import seaborn as sns import numpy as np  # Generate 100,000 random 1024 bit sequences random_array = np.random.choice(a=[False, True], size=(100000, 1024))  # Generate a 4 element sliding window view sliding_window_view = np.lib.stride_tricks.sliding_window_view(     random_array, 4, axis=1 )  # requires np >= 1.20  # Count the number of sliding windows that equal [1, 0, 1, 0] number_of_1010 = np.all(sliding_window_view == [1, 0, 1, 0], axis=2).sum(axis=1) # Count the number of sliding windows that equal [0, 0, 0, 1] number_of_0001 = np.all(sliding_window_view == [0, 0, 0, 1], axis=2).sum(axis=1) # Generate my expected distribution expected = np.random.binomial(1021, 2**-4, size=100000)  # Show density plot sns.kdeplot(     number_of_1010,     bw=0.5,     label=(         f""[1, 0, 1, 0]; mean {np.mean(number_of_1010):.2f}; var""         f"" {np.var(number_of_1010):.2f}""     ), ) sns.kdeplot(     number_of_0001,     bw=0.5,     label=(         f""[0, 0, 0, 1]; mean {np.mean(number_of_0001):.2f}; var""         f"" {np.var(number_of_0001):.2f}""     ), ) sns.kdeplot(     expected,     bw=0.5,     label=(         f""B(1021, 2^-4); mean {np.mean(expected):.2f}; var""         f"" {np.var(expected):.2f}""     ), ) plt.legend() plt.show()","[0, 0, 0, 1] [1, 0, 1, 0] B(1021, 2^{-4}) B(1021,2^{-4}) [0, 0, 0, 1] [1, 0, 1, 0] [1, 0, 1, 0]","['probability', 'combinatorics', 'discrete-mathematics']"
88,Proving $\sum E\left[\frac{X_n^2}{1+|X_n|}\right] < \infty$. Then:$\sum X_n<\infty$ a.s.,Proving . Then: a.s.,\sum E\left[\frac{X_n^2}{1+|X_n|}\right] < \infty \sum X_n<\infty,"$\{X_n\}$ are independent variables, $EX_n=0, EX_n^2=1$ . $\sum E\left[\frac{X_n^2}{1+|X_n|}\right] < \infty$ . Then: $\sum X_n<\infty$ a.s. My ideas so far: I tried to use Kolmogorov three series theorem to prove the convergence of $\sum X_n<\infty$ . (1) $\sum p(|X_n|>1)<\infty$ (2) $\sum E(X_nI{_{|X_n|\leq1}})$ converges. (3) $\sum \operatorname{Var}(X_n^2I{_{|X_n|\leq1}}) \leq \sum E(X_n^2I{_{|X_n|\leq1}}) \leq\ \sum 2E\left(\frac{X_n^2}{1+|X_n|}I{_{|X_n|\leq1}}\right)\leq \sum 2E\left(\frac{X_n^2}{1+|X_n|}\right)<\infty$ . The convergence of series(3) is easy but I don't known how to prove the convergence of (1)(2) (For series (1), the Markov inequality seems not work. For series(2), Since $EX_n=0$ , then the convergence of $\sum E(X_nI{_{|X_n|\leq1}})$ is equivalent to the  convergence of $\sum E(X_nI{_{|X_n|>1}})$ , but I still cannot proof this). Thanks in advance for any tips or help in general.","are independent variables, . . Then: a.s. My ideas so far: I tried to use Kolmogorov three series theorem to prove the convergence of . (1) (2) converges. (3) . The convergence of series(3) is easy but I don't known how to prove the convergence of (1)(2) (For series (1), the Markov inequality seems not work. For series(2), Since , then the convergence of is equivalent to the  convergence of , but I still cannot proof this). Thanks in advance for any tips or help in general.","\{X_n\} EX_n=0, EX_n^2=1 \sum E\left[\frac{X_n^2}{1+|X_n|}\right] < \infty \sum X_n<\infty \sum X_n<\infty \sum p(|X_n|>1)<\infty \sum E(X_nI{_{|X_n|\leq1}}) \sum \operatorname{Var}(X_n^2I{_{|X_n|\leq1}}) \leq \sum E(X_n^2I{_{|X_n|\leq1}}) \leq\ \sum 2E\left(\frac{X_n^2}{1+|X_n|}I{_{|X_n|\leq1}}\right)\leq \sum 2E\left(\frac{X_n^2}{1+|X_n|}\right)<\infty EX_n=0 \sum E(X_nI{_{|X_n|\leq1}}) \sum E(X_nI{_{|X_n|>1}})","['probability', 'sequences-and-series', 'probability-theory', 'independence']"
89,Monty Hall Change in Problem Suggestion,Monty Hall Change in Problem Suggestion,,"So, Let's say we have three doors and three guests in our show. A car is behind one door. The other two doors have goats . Please note.. I am not asking about the original Monty Hall problem here. This is another problem (but eventually it might be equivalent to the original one). Each guest picks a different door. and the host opens one losing door and says goodbye to one contestant.Then He asks each of the remaining guests if they would like to switch. Q1 What is winning probability of each of the remaining guests if they decide to switch? Q2 If both have to switch doesn't that mean that the computed probabilities are useless? NOTE I am aware that we have two events which aren't disjoint here Event A : Car is behind the losing door or first remaining guest's choice Event B : Car is behind the losing door or second remaining guest's choice and each has 2/3 chance to win. So, the sum here isn't 1 So, eventually.. If the answer is to Switch or NOT , doesn't it mean that we have same probability for the remaining doors. Thanks.. please give time for discussion and don't down vote for the question if it's against your mathematical beliefs. I am suggesting a new problem here, so be open to other's ideas :)","So, Let's say we have three doors and three guests in our show. A car is behind one door. The other two doors have goats . Please note.. I am not asking about the original Monty Hall problem here. This is another problem (but eventually it might be equivalent to the original one). Each guest picks a different door. and the host opens one losing door and says goodbye to one contestant.Then He asks each of the remaining guests if they would like to switch. Q1 What is winning probability of each of the remaining guests if they decide to switch? Q2 If both have to switch doesn't that mean that the computed probabilities are useless? NOTE I am aware that we have two events which aren't disjoint here Event A : Car is behind the losing door or first remaining guest's choice Event B : Car is behind the losing door or second remaining guest's choice and each has 2/3 chance to win. So, the sum here isn't 1 So, eventually.. If the answer is to Switch or NOT , doesn't it mean that we have same probability for the remaining doors. Thanks.. please give time for discussion and don't down vote for the question if it's against your mathematical beliefs. I am suggesting a new problem here, so be open to other's ideas :)",,"['probability', 'probability-theory', 'conditional-probability', 'monty-hall']"
90,Game holder is always losing money in the St. Petersberg Paradox?,Game holder is always losing money in the St. Petersberg Paradox?,,"The St. Petersberg Paradox is described as follows: A gambler pays an entry fee $M$ dollar to play the following game: A fair coin is tossed repeated until the first head occurs and you win $2^{n-1}$ amount of money where $n$ is the total number of tosses. And the question is what is the fair amount of $M$ ? By some simple probability knowledge we can get the ""Expected Winning Money"" is $$E(2^{n-1})=\sum\limits_{k=1}^\infty 2^{k-1}\times\frac1{2^k}=\infty$$ But Bernoulli claims that $M$ is not worth infinity because of utility. And log-utility is considered here, which intuitively means that 1000 dollars are not equally significant to a pauper and a rich man. But I am confused that if so, then $M$ will be set to some finite amount. But if we only focus on the number itself, since the ""Expected Winning Money"" is infinity, then the game holder is 100% certain to lose money to hold this game(Or to be more precise, the game holder will definitely lose money when the number of people to play this game is large enough)? Can anyone help me? Thank you!!","The St. Petersberg Paradox is described as follows: A gambler pays an entry fee dollar to play the following game: A fair coin is tossed repeated until the first head occurs and you win amount of money where is the total number of tosses. And the question is what is the fair amount of ? By some simple probability knowledge we can get the ""Expected Winning Money"" is But Bernoulli claims that is not worth infinity because of utility. And log-utility is considered here, which intuitively means that 1000 dollars are not equally significant to a pauper and a rich man. But I am confused that if so, then will be set to some finite amount. But if we only focus on the number itself, since the ""Expected Winning Money"" is infinity, then the game holder is 100% certain to lose money to hold this game(Or to be more precise, the game holder will definitely lose money when the number of people to play this game is large enough)? Can anyone help me? Thank you!!",M 2^{n-1} n M E(2^{n-1})=\sum\limits_{k=1}^\infty 2^{k-1}\times\frac1{2^k}=\infty M M,"['probability', 'expected-value', 'economics', 'utility']"
91,What is the probability one man is chosen for treasurer and one woman for secretary?,What is the probability one man is chosen for treasurer and one woman for secretary?,,"So everyone, I have a simple probability question that I cannot wrap my head around. It go like this: There are $6$ men $9$ women on committee. $2$ people are chosen for treasurer and secretary. What is the probability one man is chosen for treasurer and one woman for secretary? My solution goes like this: $6$ men/ $15$ people $\cdot$ $9$ women/ $14$ people = $9/35$ but I was thinking, if we think that the denominator will be $15$ choose $2 = 105$ , then we get different answer of $6 \cdot 9/105 = 18/35$ ??? Now I'm confused on which one is the correct answer. Someone help clear the confusion for me.  Thanks.","So everyone, I have a simple probability question that I cannot wrap my head around. It go like this: There are men women on committee. people are chosen for treasurer and secretary. What is the probability one man is chosen for treasurer and one woman for secretary? My solution goes like this: men/ people women/ people = but I was thinking, if we think that the denominator will be choose , then we get different answer of ??? Now I'm confused on which one is the correct answer. Someone help clear the confusion for me.  Thanks.",6 9 2 6 15 \cdot 9 14 9/35 15 2 = 105 6 \cdot 9/105 = 18/35,['probability']
92,Measurability of the Wasserstein distance of a Markov kernel,Measurability of the Wasserstein distance of a Markov kernel,,"Consider two Polish metric spaces $(\mathcal{A}, \Sigma_\mathcal{A})$ and $(\mathcal{B}, \Sigma_\mathcal{B})$ endowed with their Borel $\sigma$ -algebras. Let $$a\mapsto \mu_a$$ be a Markov kernel, that is $\mu_a$ is a probability measure on $(\mathcal{B}, \Sigma_\mathcal{B})$ for all $a\in A$ , and for any measurable set $B\in\Sigma_\mathcal{B}$ we have that $a\mapsto \mu_A(B)$ is a measurable function from $\mathcal A$ to $[0, 1]$ . Let $\mathcal{P}_\mathcal{B}$ be the space of probability measures on $(\mathcal{B}, \Sigma_\mathcal{B})$ and fix $\nu\in\mathcal{P}_\mathcal{B}$ . Let $\mathcal{W}$ denote the $1$ -Wasserstein distance (wrt to the metric on $\mathcal{B}$ ) between probability measures in $\mathcal{P}_\mathcal{B}$ . Is the mapping $$a\mapsto \mathcal{W}(\mu_a, \nu)$$ a measurable map $\mathcal A\to \mathbb R$ ? I think that one way to prove the measurability would be to exploit Corollary 5.22 in [1], which essentially tells you that if $a\mapsto\mu_a$ is measurable wrt the Borel $\sigma$ -algebra induced on $\mathcal{P}_\mathcal{B}$ by the weak measure convergence, then $a\mapsto\pi_a$ is measurable, where $\pi_a$ is the optimal coupling between $\mu_a$ and $\nu$ . It would then follow that $a\mapsto \mathcal{W}(\mu_a, \nu) = \mathbb E_{(A,A')\sim\pi_a}[d(A, A')]$ is measurable. But is it actually true that $a\mapsto\mu_a$ is measurable? The main reason for the question is that I have often encounter expressions like $$\int_\mathcal A \mathcal{W}(\mathbb P_B, \mathbb P_{B|A=a})\,\mathrm d\mathbb P_A(a)$$ (where $A, B$ are coupled random variables, with marginals $\mathbb P_A$ and $\mathbb P_B$ , and $\mathbb P_{B|A=a}$ is a regular conditional probability) without any formal justification, see for instance [2] and the papers it builds on. But does this expression actually make sense? Is the integrand always measurable? [1] Villani, Optimal transport, old and new, 2008. [2] Rodríguez-Gálvez, Tighter expected generalization error bounds via Wasserstein Distance, 2021.","Consider two Polish metric spaces and endowed with their Borel -algebras. Let be a Markov kernel, that is is a probability measure on for all , and for any measurable set we have that is a measurable function from to . Let be the space of probability measures on and fix . Let denote the -Wasserstein distance (wrt to the metric on ) between probability measures in . Is the mapping a measurable map ? I think that one way to prove the measurability would be to exploit Corollary 5.22 in [1], which essentially tells you that if is measurable wrt the Borel -algebra induced on by the weak measure convergence, then is measurable, where is the optimal coupling between and . It would then follow that is measurable. But is it actually true that is measurable? The main reason for the question is that I have often encounter expressions like (where are coupled random variables, with marginals and , and is a regular conditional probability) without any formal justification, see for instance [2] and the papers it builds on. But does this expression actually make sense? Is the integrand always measurable? [1] Villani, Optimal transport, old and new, 2008. [2] Rodríguez-Gálvez, Tighter expected generalization error bounds via Wasserstein Distance, 2021.","(\mathcal{A}, \Sigma_\mathcal{A}) (\mathcal{B}, \Sigma_\mathcal{B}) \sigma a\mapsto \mu_a \mu_a (\mathcal{B}, \Sigma_\mathcal{B}) a\in A B\in\Sigma_\mathcal{B} a\mapsto \mu_A(B) \mathcal A [0, 1] \mathcal{P}_\mathcal{B} (\mathcal{B}, \Sigma_\mathcal{B}) \nu\in\mathcal{P}_\mathcal{B} \mathcal{W} 1 \mathcal{B} \mathcal{P}_\mathcal{B} a\mapsto \mathcal{W}(\mu_a, \nu) \mathcal A\to \mathbb R a\mapsto\mu_a \sigma \mathcal{P}_\mathcal{B} a\mapsto\pi_a \pi_a \mu_a \nu a\mapsto \mathcal{W}(\mu_a, \nu) = \mathbb E_{(A,A')\sim\pi_a}[d(A, A')] a\mapsto\mu_a \int_\mathcal A \mathcal{W}(\mathbb P_B, \mathbb P_{B|A=a})\,\mathrm d\mathbb P_A(a) A, B \mathbb P_A \mathbb P_B \mathbb P_{B|A=a}","['probability', 'probability-theory', 'measure-theory', 'measurable-functions']"
93,Stuck on proving a variation of the Central Limit Theorem.,Stuck on proving a variation of the Central Limit Theorem.,,"I'm trying to prove the following version of the central limit theorem. Let $$L^n = (L_1^n,...L_n^n) $$ such that the $L_i$ are i.i.d., there exists a sequence of constants such that $|L_i^n|\leq K^n$ for all $i$ and $K^n \rightarrow{0}$ , and it holds that for $Z_n= \sum_{i=1}^nL_i^n$ we have $\mathbb{E}[Z_n] \rightarrow{\mu}$ and $\operatorname{Var}(Z_n) \rightarrow \sigma^2$ . Then we have that $Z_n$ converges in distribution to $Z$ where $Z$ is normal with mean $\mu$ and variance $\sigma^2$ . I think it should be done with Characteristic functions + Levy's continuity theorem. The characterstic function will factor by the first hypothesis but I don't see how to incorporate the other two to arrive at the desired result.","I'm trying to prove the following version of the central limit theorem. Let such that the are i.i.d., there exists a sequence of constants such that for all and , and it holds that for we have and . Then we have that converges in distribution to where is normal with mean and variance . I think it should be done with Characteristic functions + Levy's continuity theorem. The characterstic function will factor by the first hypothesis but I don't see how to incorporate the other two to arrive at the desired result.","L^n = (L_1^n,...L_n^n)  L_i |L_i^n|\leq K^n i K^n \rightarrow{0} Z_n= \sum_{i=1}^nL_i^n \mathbb{E}[Z_n] \rightarrow{\mu} \operatorname{Var}(Z_n) \rightarrow \sigma^2 Z_n Z Z \mu \sigma^2","['probability', 'probability-theory', 'central-limit-theorem', 'probability-limit-theorems']"
94,Same distribution with different probability density function,Same distribution with different probability density function,,"Suppose $X$ is a random variable with probability density function: $$f_a(x)=\frac{1}{a}$$ With $0<x<a$ . I must find the Moment-generating function of $Y = -(\ln X - \ln a)$ . After calculation I've found that $M_Y(t)=\frac{1}{1-t}$ . So no matter what is the value of $a$ . For every $a$ , Moment-generating function is independent from $a$ . So every $Y$ with different values of $a$ have the same distribution? Even if their probability density functions are different? Or I've found the Moment-generating function wrong? $$M_Y(t)=E(e^{t(-(\ln X - \ln a)})=a^t\int_{0}^{a}x^{-t}\frac{1}{a}dx=\frac{1}{1-t}$$ So for every $t\in (-1,1)$ , we have $E(e^{tY})<\infty$ and so the Moment-generating function exists.","Suppose is a random variable with probability density function: With . I must find the Moment-generating function of . After calculation I've found that . So no matter what is the value of . For every , Moment-generating function is independent from . So every with different values of have the same distribution? Even if their probability density functions are different? Or I've found the Moment-generating function wrong? So for every , we have and so the Moment-generating function exists.","X f_a(x)=\frac{1}{a} 0<x<a Y = -(\ln X - \ln a) M_Y(t)=\frac{1}{1-t} a a a Y a M_Y(t)=E(e^{t(-(\ln X - \ln a)})=a^t\int_{0}^{a}x^{-t}\frac{1}{a}dx=\frac{1}{1-t} t\in (-1,1) E(e^{tY})<\infty","['probability', 'probability-distributions', 'moment-generating-functions']"
95,Prove: $P(X>a)\ge\frac{(1-a)^2}{b}$ for every $0<a<1$,Prove:  for every,P(X>a)\ge\frac{(1-a)^2}{b} 0<a<1,"I found this question and I have no idea how to solve it. I'll be glad if you can help me! $$$$ let $X>0$ be a random variable, such that: $E(X)=1,\quad E(X^2)=b$ Then, for every $0<a<1$ , prove that: $P(X>a)\ge\frac{(1-a)^2}{b}$ $$$$ If we were talking about upper bound, i would've start thinking about Markov or Chebyshev inequality, but it's not... So I'm out of ideas.","I found this question and I have no idea how to solve it. I'll be glad if you can help me! let be a random variable, such that: Then, for every , prove that: If we were talking about upper bound, i would've start thinking about Markov or Chebyshev inequality, but it's not... So I'm out of ideas."," X>0 E(X)=1,\quad E(X^2)=b 0<a<1 P(X>a)\ge\frac{(1-a)^2}{b} ","['probability', 'inequality', 'probability-distributions', 'random-variables']"
96,Probability question with a deck of cards,Probability question with a deck of cards,,"Just started to learn maths, so I'm sorry if this an elementary question. The question is: here is a deck with 40 cards ; 10 cards, each 10 with one of the 4 shapes (hearts, diamonds, clubs and spades). All the cards are numbered from 1 to 10. Every card has the same probability to be drawn. We start drawing cards from the deck. If the 11th card which was drawn is the first one with number 10 on it, what is the probability that the next card is a clubs? What I have tried: We need to find P(A|B), where A is the probability that the 12's card is a clubs, and B is the probability that the 11's card is a first ten. I chose the sample space to be picking 12 cards from 40. $P$ ( $\Omega$ ) = $\binom{40}{12}$ $P(B)$ = $\binom{36}{10}\binom{4}{1}\binom{29}{1}$ . Where in $P(B)$ , i chose 10 cards from 36 cards(without 10's), the picking 1 card from the the 10, the choosing from the rest. $P(A\cap B)$ = $\binom{9}{9}\binom{26}{1}(\binom{3}{1}\binom{1}{1} +\binom{1}{0})$ $+$ $\binom{9}{8}\binom{26}{2}(\binom{3}{1}\binom{2}{1}+\binom{1}{1})$ $+$ $\binom{9}{7}\binom{26}{3}(\binom{3}{1}\binom{3}{1} + \binom{2}{1})$ $+$ $\binom{9}{6}\binom{26}{4}(\binom{3}{1}\binom{4}{1}+\binom{3}{1})$ $+$ $\binom{9}{5}\binom{26}{5}(\binom{3}{1}\binom{5}{1}+\binom{4}{1})$ $+$ $\binom{9}{4}\binom{26}{6}(\binom{3}{1}\binom{6}{1}+\binom{5}{1})$$+$ $\binom{9}{3}\binom{26}{7}(\binom{3}{1}\binom{7}{1}+\binom{6}{1})$$+$ $\binom{9}{2}\binom{26}{8}(\binom{3}{1}\binom{8}{1}+\binom{7}{1})$$+$ $\binom{9}{1}\binom{26}{9}(\binom{3}{1}\binom{9}{1}+\binom{8}{1})$$+$ $\binom{9}{0}\binom{26}{10}(\binom{3}{1}\binom{10}{1}+\binom{9}{1})$ . Here, $\binom{9}{8}$ is the possibility that we choose 8 from 9 clubs ( we dont want to pick 10), $\binom{26}{2}$ is completing the picking of the rest 10 cards, $\binom{3}{1}\binom{3}{1}$ is picking 1 10 from 3 and picking a club from the 3 that left, $\binom{1}{1}$ is picking the ten of clubs and then picking the only left clubs. The rest of the calculations are the same. So, $P(A|B)  =  \frac {P(A\cap B)}{P(B)} = \frac {5271351254}{29485675300} $ $ \approx $ 0.178 The correct answer is $ \frac 14$ . My questions are: am I wrong, and, if so, is there a ""nicer"" way to compute $P(A\cap B)$ (or generally solving this exercise)? *Sorry if there are mistakes in grammar.","Just started to learn maths, so I'm sorry if this an elementary question. The question is: here is a deck with 40 cards ; 10 cards, each 10 with one of the 4 shapes (hearts, diamonds, clubs and spades). All the cards are numbered from 1 to 10. Every card has the same probability to be drawn. We start drawing cards from the deck. If the 11th card which was drawn is the first one with number 10 on it, what is the probability that the next card is a clubs? What I have tried: We need to find P(A|B), where A is the probability that the 12's card is a clubs, and B is the probability that the 11's card is a first ten. I chose the sample space to be picking 12 cards from 40. ( ) = = . Where in , i chose 10 cards from 36 cards(without 10's), the picking 1 card from the the 10, the choosing from the rest. = . Here, is the possibility that we choose 8 from 9 clubs ( we dont want to pick 10), is completing the picking of the rest 10 cards, is picking 1 10 from 3 and picking a club from the 3 that left, is picking the ten of clubs and then picking the only left clubs. The rest of the calculations are the same. So, 0.178 The correct answer is . My questions are: am I wrong, and, if so, is there a ""nicer"" way to compute (or generally solving this exercise)? *Sorry if there are mistakes in grammar.",P \Omega \binom{40}{12} P(B) \binom{36}{10}\binom{4}{1}\binom{29}{1} P(B) P(A\cap B) \binom{9}{9}\binom{26}{1}(\binom{3}{1}\binom{1}{1} +\binom{1}{0}) + \binom{9}{8}\binom{26}{2}(\binom{3}{1}\binom{2}{1}+\binom{1}{1}) + \binom{9}{7}\binom{26}{3}(\binom{3}{1}\binom{3}{1} + \binom{2}{1}) + \binom{9}{6}\binom{26}{4}(\binom{3}{1}\binom{4}{1}+\binom{3}{1}) + \binom{9}{5}\binom{26}{5}(\binom{3}{1}\binom{5}{1}+\binom{4}{1}) + \binom{9}{4}\binom{26}{6}(\binom{3}{1}\binom{6}{1}+\binom{5}{1})+ \binom{9}{3}\binom{26}{7}(\binom{3}{1}\binom{7}{1}+\binom{6}{1})+ \binom{9}{2}\binom{26}{8}(\binom{3}{1}\binom{8}{1}+\binom{7}{1})+ \binom{9}{1}\binom{26}{9}(\binom{3}{1}\binom{9}{1}+\binom{8}{1})+ \binom{9}{0}\binom{26}{10}(\binom{3}{1}\binom{10}{1}+\binom{9}{1}) \binom{9}{8} \binom{26}{2} \binom{3}{1}\binom{3}{1} \binom{1}{1} P(A|B)  =  \frac {P(A\cap B)}{P(B)} = \frac {5271351254}{29485675300}   \approx   \frac 14 P(A\cap B),['probability']
97,Going from 30 to 100 in a coin flip game.,Going from 30 to 100 in a coin flip game.,,"The question is this: Say you're playing a coin flip game, where you start with 30 dollars. If you flip heads, you win 1. If you get tails, you lose 1. You keep playing until you either run out of money or reach 100. What is the probability that you will reach 100. The coin is fair. I have seen many questions about expected number steps, expected earnings and so on. However I am having trouble with this question because the game need not even end for certain (I think). In such situation, how would we either get a probability, or explain why it can’t be arrived at, if that is the case?","The question is this: Say you're playing a coin flip game, where you start with 30 dollars. If you flip heads, you win 1. If you get tails, you lose 1. You keep playing until you either run out of money or reach 100. What is the probability that you will reach 100. The coin is fair. I have seen many questions about expected number steps, expected earnings and so on. However I am having trouble with this question because the game need not even end for certain (I think). In such situation, how would we either get a probability, or explain why it can’t be arrived at, if that is the case?",,"['probability', 'random-walk']"
98,Probability / Combinatoric of fair roulette question,Probability / Combinatoric of fair roulette question,,"In a fair roulette there are $4$ sections, numbered $1$ to $4$ . A player spins the roulette's pointer $10$ times independently. What is the chance that the pointer stops at each one of the $4$ sections at least one? My attempt: We have symmetric distribution here, so $|\Omega|=4^{10}$ . Define: $A_i$ = the pointer stops at each one of the sections exactly $i$ times, for $i=1,2$ . We want $P(A)$ , and note that $A=\cup_{i=1}^2 A_i$ Then: For $P(A_1)$ we choose 4 places for each section out of the 10 places, then we choose 3 sections out of the 4 and arrange them with the 6 places left, so: $$P(A_1)=\frac{\binom{10}{4}\binom{4}{3}6!}{10^4}$$ I do not know how to calculate $P(A_2)$ however, and I am not sure that what I did is correct, if not please explain me why. Thanks a lot!","In a fair roulette there are sections, numbered to . A player spins the roulette's pointer times independently. What is the chance that the pointer stops at each one of the sections at least one? My attempt: We have symmetric distribution here, so . Define: = the pointer stops at each one of the sections exactly times, for . We want , and note that Then: For we choose 4 places for each section out of the 10 places, then we choose 3 sections out of the 4 and arrange them with the 6 places left, so: I do not know how to calculate however, and I am not sure that what I did is correct, if not please explain me why. Thanks a lot!","4 1 4 10 4 |\Omega|=4^{10} A_i i i=1,2 P(A) A=\cup_{i=1}^2 A_i P(A_1) P(A_1)=\frac{\binom{10}{4}\binom{4}{3}6!}{10^4} P(A_2)","['real-analysis', 'probability', 'combinatorics', 'discrete-mathematics']"
99,A Markov Chain ($Y_n$) based on the stopping time of another Markov Chain $X_n$,A Markov Chain () based on the stopping time of another Markov Chain,Y_n X_n,"Problem Setting: If $(X_n)^{\infty}_{n=0}$ is a homogeneous Markov chain with state space $S$ and a transition matrix $P = (p_{ij})$ where $p_{ii} < 1$ for all $I \in S$ and consider $(Y_n)^{\infty}_{n=0}$ to be a sequence of new values for $X_n$ , then we let $\tau_m$ be the $m$ -th time where we see a new value of $X_n$ . For example, if $(X_0, X_1, ... , X_{10}) = (1,1,1,2,2,1,3,3,3,2,1)$ , then we will have $Y_0 = 1, Y_1 = 2, Y_2 = 1, Y_3 = 3, Y_4 = 2, Y_5 = 1$ and $\tau_1 = 3, \tau_2 = 5, \tau_3 = 6, \tau_4 = 9, \tau_5 = 10$ . Since we have known the t.p.m $P$ for $X_n$ , how can we find the transition probability matrix for $Y_n$ in terms of $P$ . Attempt: We have known that $\tau_m$ are stopping times with respect to $X_n$ . I think that $$ P(Y_n = j | Y_{n-1} = i) = P(X_{\tau_n} = j | X_{\tau_{n-1}} = i) = P_{ij}^{(\tau_n - \tau_{n-1})}, $$ since $Y_n$ and $X_n$ share the same state space and initial distribution. But I am not sure whether this is a correct case. This is because, by the definition, the diagonal of the transition probability matrix for $Y_n$ should be 0 ( $Y_n$ only records the new value in $X_n$ ). If I follow this thought, it seems that the $Y_n$ is not homogeneous. So I am wondering how can I find the t.p.m for $Y_n$ in terms of $P$ and what is the relationship between two M.C. $X_n$ and $Y_n$ ?","Problem Setting: If is a homogeneous Markov chain with state space and a transition matrix where for all and consider to be a sequence of new values for , then we let be the -th time where we see a new value of . For example, if , then we will have and . Since we have known the t.p.m for , how can we find the transition probability matrix for in terms of . Attempt: We have known that are stopping times with respect to . I think that since and share the same state space and initial distribution. But I am not sure whether this is a correct case. This is because, by the definition, the diagonal of the transition probability matrix for should be 0 ( only records the new value in ). If I follow this thought, it seems that the is not homogeneous. So I am wondering how can I find the t.p.m for in terms of and what is the relationship between two M.C. and ?","(X_n)^{\infty}_{n=0} S P = (p_{ij}) p_{ii} < 1 I \in S (Y_n)^{\infty}_{n=0} X_n \tau_m m X_n (X_0, X_1, ... , X_{10}) = (1,1,1,2,2,1,3,3,3,2,1) Y_0 = 1, Y_1 = 2, Y_2 = 1, Y_3 = 3, Y_4 = 2, Y_5 = 1 \tau_1 = 3, \tau_2 = 5, \tau_3 = 6, \tau_4 = 9, \tau_5 = 10 P X_n Y_n P \tau_m X_n 
P(Y_n = j | Y_{n-1} = i) = P(X_{\tau_n} = j | X_{\tau_{n-1}} = i) = P_{ij}^{(\tau_n - \tau_{n-1})},
 Y_n X_n Y_n Y_n X_n Y_n Y_n P X_n Y_n","['probability', 'statistics', 'stochastic-processes', 'markov-chains', 'stopping-times']"
