,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Classification of two dimensional algebras without unit.,Classification of two dimensional algebras without unit.,,"Let $A$ be a two dimensional commutative associative algebra over field $K$ of reals or complex numbers. Assume that $A$ has units $e$. Let $u \notin Ke$. Then $\{e,u\}$ is basis of $A$. In order to determine that algebra it suffices to know $u\cdot u$. Let $u=pu+qe$. Let's consider polynom $f(x)=x^2-px+q \in K[x]$. Three cases may occur: $f$ has two, one or none roots. In the first case putting $v=(y_2-y_1)^{-1}(u-y_1)$, where $y_1,y_2$ are roots of $f$, we have $v^2=v$ and $\{e,v\}$ is the basis of $A$. In the second putting $v=u-y_1e$, where $y_1$ is a root of $f$, we have $v^2=0$ and ${e,v}$ is the basis of $A$. In the third case $A$ is a field. How to determine all two dimensional commutative associative algebras without units? Thanks.","Let $A$ be a two dimensional commutative associative algebra over field $K$ of reals or complex numbers. Assume that $A$ has units $e$. Let $u \notin Ke$. Then $\{e,u\}$ is basis of $A$. In order to determine that algebra it suffices to know $u\cdot u$. Let $u=pu+qe$. Let's consider polynom $f(x)=x^2-px+q \in K[x]$. Three cases may occur: $f$ has two, one or none roots. In the first case putting $v=(y_2-y_1)^{-1}(u-y_1)$, where $y_1,y_2$ are roots of $f$, we have $v^2=v$ and $\{e,v\}$ is the basis of $A$. In the second putting $v=u-y_1e$, where $y_1$ is a root of $f$, we have $v^2=0$ and ${e,v}$ is the basis of $A$. In the third case $A$ is a field. How to determine all two dimensional commutative associative algebras without units? Thanks.",,['abstract-algebra']
1,Elementary Question About Hopf Algebras,Elementary Question About Hopf Algebras,,"Let $A$ be a smooth Hopf Algebra over a field $k$ with comultiplication map $\Delta$ and Augmentation Ideal $I$. Then I can regard the composition of $\Delta$ with the natural projection of $A \otimes A$ to the square of $I$, i.e. the map $A \rightarrow A \otimes_k A \rightarrow A/I^2 \otimes_k A/I^2$. Now my questions: (1) Can one say what this map does with an element $x$ of $A$ explicitly? In particular, what is it's kernel? I'm not quite sure if one can really say something in this general setting... (2) Is $A/I^2 \otimes_k A/I^2$ naturally isomorphic as $k-$algebra to something more familiar? Can it be that it is $(A\otimes_kA)/I\otimes_kI$? Or what else? And how does the above map then look like? Thanks a lot for your effort!","Let $A$ be a smooth Hopf Algebra over a field $k$ with comultiplication map $\Delta$ and Augmentation Ideal $I$. Then I can regard the composition of $\Delta$ with the natural projection of $A \otimes A$ to the square of $I$, i.e. the map $A \rightarrow A \otimes_k A \rightarrow A/I^2 \otimes_k A/I^2$. Now my questions: (1) Can one say what this map does with an element $x$ of $A$ explicitly? In particular, what is it's kernel? I'm not quite sure if one can really say something in this general setting... (2) Is $A/I^2 \otimes_k A/I^2$ naturally isomorphic as $k-$algebra to something more familiar? Can it be that it is $(A\otimes_kA)/I\otimes_kI$? Or what else? And how does the above map then look like? Thanks a lot for your effort!",,"['abstract-algebra', 'algebraic-geometry', 'commutative-algebra']"
2,Group theory applications along with a solved example,Group theory applications along with a solved example,,"As I asked in previous question , I am very curious about applying Group theory. Still I have doubts about how I can apply group theory. I know about formal definitions and I can able to solve and prove problems related to Group theory. But when comes to applications, I don't know where to start. I surfed the net, and I can get these links.... http://www.math.uconn.edu/~kconrad/math216/whygroups.html http://en.wikiversity.org/wiki/Topic:Group_theory http://ezinearticles.com/?Why-Study-Math?---Group-Theory-and-Subparticle-Physics&id=1456420 Those explanations are really good. But the real problem I face is,   all applications are of theoretical explanations, without a solved example which a beginner like me can understand. When I went to Wikipedia, I learned about the solution of the Rubik's cube in at most 20 steps posted in http://cube20.org/ What I can understand? Turning a cube upside down, it will still take the same number of moves to solve.(Symmetrical property). Where I need assistance? An example of showing how this symmetrical property of group theory works here. So, if someone could give an example of how group theory is applied (in this or some other instance) it will be useful to me....","As I asked in previous question , I am very curious about applying Group theory. Still I have doubts about how I can apply group theory. I know about formal definitions and I can able to solve and prove problems related to Group theory. But when comes to applications, I don't know where to start. I surfed the net, and I can get these links.... http://www.math.uconn.edu/~kconrad/math216/whygroups.html http://en.wikiversity.org/wiki/Topic:Group_theory http://ezinearticles.com/?Why-Study-Math?---Group-Theory-and-Subparticle-Physics&id=1456420 Those explanations are really good. But the real problem I face is,   all applications are of theoretical explanations, without a solved example which a beginner like me can understand. When I went to Wikipedia, I learned about the solution of the Rubik's cube in at most 20 steps posted in http://cube20.org/ What I can understand? Turning a cube upside down, it will still take the same number of moves to solve.(Symmetrical property). Where I need assistance? An example of showing how this symmetrical property of group theory works here. So, if someone could give an example of how group theory is applied (in this or some other instance) it will be useful to me....",,"['abstract-algebra', 'group-theory', 'big-list', 'applications']"
3,Tensor product of abelian group and a free abelian group,Tensor product of abelian group and a free abelian group,,"I am trying to show that if $F,H$ are abelian groups with $F$ free abelian, and if $a \in F$ and $h \in H$ are non-zero, then $a \otimes h \ne 0$ in $F \otimes H$. This is specifically in a section describing the derived functor Tor. Of course, that doesn't mean the solution has to involve that, but there is probably a way. I know that $F$ free abelian means that $F$ is torsion free and hence $\mbox{Tor}(F,A)=0$. I was trying to use a formulation of $\mbox{Tor}$ in terms of exact sequences. If: $$0 \to R \stackrel{i}{\hookrightarrow} F \to A \to 0$$ is an exact sequence then $\mbox{Tor}(A,B) =\mbox{ker}(i \otimes 1_b)$ Seemed to me if I picked the right sequence I could get that $\mbox{Tor}=0$ implies that the kernel is trivial, which would give the result, but I can't get this to work Edit It appears that this is false from the answers below. Here is a link to the question.","I am trying to show that if $F,H$ are abelian groups with $F$ free abelian, and if $a \in F$ and $h \in H$ are non-zero, then $a \otimes h \ne 0$ in $F \otimes H$. This is specifically in a section describing the derived functor Tor. Of course, that doesn't mean the solution has to involve that, but there is probably a way. I know that $F$ free abelian means that $F$ is torsion free and hence $\mbox{Tor}(F,A)=0$. I was trying to use a formulation of $\mbox{Tor}$ in terms of exact sequences. If: $$0 \to R \stackrel{i}{\hookrightarrow} F \to A \to 0$$ is an exact sequence then $\mbox{Tor}(A,B) =\mbox{ker}(i \otimes 1_b)$ Seemed to me if I picked the right sequence I could get that $\mbox{Tor}=0$ implies that the kernel is trivial, which would give the result, but I can't get this to work Edit It appears that this is false from the answers below. Here is a link to the question.",,"['abstract-algebra', 'homological-algebra']"
4,What is the pullback in the category of commutative algebras?,What is the pullback in the category of commutative algebras?,,The pullback is a subset of the cartesian product in the category of commutative rings with unit. What is the pullback in the category of commutative $k$-algebras? Is it the same set as in rings?,The pullback is a subset of the cartesian product in the category of commutative rings with unit. What is the pullback in the category of commutative $k$-algebras? Is it the same set as in rings?,,"['abstract-algebra', 'algebraic-geometry']"
5,morphism on the commutator subgroup of the free group/picture-hanging-puzzle,morphism on the commutator subgroup of the free group/picture-hanging-puzzle,,"Let $F_n=\langle x_1,\dots,x_n \rangle$ denote the free group on $n$ generators. Let \begin{align} \varphi:F_n\rightarrow \prod_{i=1}^n\langle x_1,\dots,x_n \mid x_i=e \rangle \end{align} be the canonic morphism making one of the generators trivial in each entry. I want to understand $\ker \varphi$ . Its clear that $\ker\varphi \subset [F_n,F_n]$ . Ultimately I am interested in finding the element in $\ker\varphi$ with the least symbols for each $n$ . Obviously when $n=2$ this is $[x_1,x_2]$ up to relabelling of the generators. In the case $n=3$ it probably is $[x_1,x_2]x_3[x_2,x_1]x_3^{-1}$ . Motivation for this is the picture-hanging-puzzle from topology where we you want to hang a picture on $n$ nails such that removing a nail makes the picture fall. It is known that there are solutions $\leq 2n^2$ symbols long, I'm just wondering if there is anything with less than $n^2$ symbols. Is there anything more known about this?","Let denote the free group on generators. Let be the canonic morphism making one of the generators trivial in each entry. I want to understand . Its clear that . Ultimately I am interested in finding the element in with the least symbols for each . Obviously when this is up to relabelling of the generators. In the case it probably is . Motivation for this is the picture-hanging-puzzle from topology where we you want to hang a picture on nails such that removing a nail makes the picture fall. It is known that there are solutions symbols long, I'm just wondering if there is anything with less than symbols. Is there anything more known about this?","F_n=\langle x_1,\dots,x_n \rangle n \begin{align}
\varphi:F_n\rightarrow \prod_{i=1}^n\langle x_1,\dots,x_n \mid x_i=e \rangle
\end{align} \ker \varphi \ker\varphi \subset [F_n,F_n] \ker\varphi n n=2 [x_1,x_2] n=3 [x_1,x_2]x_3[x_2,x_1]x_3^{-1} n \leq 2n^2 n^2","['abstract-algebra', 'group-theory', 'algebraic-topology']"
6,"Representations of semisimple lie algebras, the highest weight root strings spaces have dimension one","Representations of semisimple lie algebras, the highest weight root strings spaces have dimension one",,"This is exercise 22.1 in Humphreys Introduction to Lie Algebras and Representation Theory book. Let $\mathfrak{g}$ be a semisimple complex Lie Algebra and let $\lambda$ be a dominant weight also let $\alpha$ be a root of $\mathfrak{g}$ . Prove without using Freudenthal's formula, $V(\lambda)$ , the irreducible representation of highest weight $\lambda$ ,  the dimension of each component in of the $\alpha$ string though $\lambda$ is $1$ i.e. the dimension of the $\lambda- k \alpha$ weight space of $V(\lambda)$ is 1 for $0\leq k \leq <\lambda,\check{\alpha}>$ . My thoughts on this are that the fact that the Weyl group preserves the dimension of weight spaces we immediately have that the start (as its highest weight) and end of the string are dim 1. I am not sure how to proceed, I want to try use $\mathfrak{sl}_2$ theory but haven't thought of how. Up to this point we have covered the structure theory of lie algebras, abstract root systems and most recently the construction of the $V\lambda$ using Verma modules. Edit: Simple root $\alpha$","This is exercise 22.1 in Humphreys Introduction to Lie Algebras and Representation Theory book. Let be a semisimple complex Lie Algebra and let be a dominant weight also let be a root of . Prove without using Freudenthal's formula, , the irreducible representation of highest weight ,  the dimension of each component in of the string though is i.e. the dimension of the weight space of is 1 for . My thoughts on this are that the fact that the Weyl group preserves the dimension of weight spaces we immediately have that the start (as its highest weight) and end of the string are dim 1. I am not sure how to proceed, I want to try use theory but haven't thought of how. Up to this point we have covered the structure theory of lie algebras, abstract root systems and most recently the construction of the using Verma modules. Edit: Simple root","\mathfrak{g} \lambda \alpha \mathfrak{g} V(\lambda) \lambda \alpha \lambda 1 \lambda- k \alpha V(\lambda) 0\leq k \leq <\lambda,\check{\alpha}> \mathfrak{sl}_2 V\lambda \alpha","['abstract-algebra', 'representation-theory', 'lie-algebras']"
7,How to visualize the 6 roto-reflections in the group of symmetries of a tetrahedron $S_4$?,How to visualize the 6 roto-reflections in the group of symmetries of a tetrahedron ?,S_4,"I'm working on an applet that will calculate the product of two symmetries. (It's unfinished but here's a link to the project if you're curious.) I want the applet to show visuals to help the user understand what's happening for each symmetry action -- for example: for rotations, it displays the axis of rotation; for reflections, it displays the plane of reflection. There are six symmetries which I can't figure out a visualization for. I believe they're called ""roto-rotations"" or ""inversions,"" but I can't find much information online about them (in my applet they're currently labeled $φ_1$ through $φ_6$ ). They are the following elements of $S_4$ : (2341), (2413), (3142), (3421), (4123), (4312) Can anybody help me figure out how these elements can be visualized on the tetrahedron through axes of rotation/planes of reflection/some other visual?","I'm working on an applet that will calculate the product of two symmetries. (It's unfinished but here's a link to the project if you're curious.) I want the applet to show visuals to help the user understand what's happening for each symmetry action -- for example: for rotations, it displays the axis of rotation; for reflections, it displays the plane of reflection. There are six symmetries which I can't figure out a visualization for. I believe they're called ""roto-rotations"" or ""inversions,"" but I can't find much information online about them (in my applet they're currently labeled through ). They are the following elements of : (2341), (2413), (3142), (3421), (4123), (4312) Can anybody help me figure out how these elements can be visualized on the tetrahedron through axes of rotation/planes of reflection/some other visual?",φ_1 φ_6 S_4,"['abstract-algebra', 'group-theory', 'symmetric-groups', 'geometric-group-theory', 'platonic-solids']"
8,A Question on the Pedagogical Logic Behind the Order of Two Given Exercises,A Question on the Pedagogical Logic Behind the Order of Two Given Exercises,,"In Lang's Algebra, the following two exercises are presented to the reader in the following order: Groups Exercise 15: Let $G$ be a finite group acting on $S$ , a finite set of at least $2$ elements. Assume there is only one orbit. Prove there is at least one $g\in G$ with no fixed point, i.e. for all $s\in S$ , $g\cdot s\ne s$ . Groups Exercise 19b.: Let $G$ be a finite group action on a finite set $S$ . For each $g\in G$ , define ${\rm Stab}(g):=\{s\in S : gs = s\}$ . Prove the number of orbits of $S$ is equal to $$ \frac{1}{\#G}\sum_{g\in G}\#{\rm Stab}(g). $$ I can include the proofs I have for both of these if desired to assuage any concerns that I am fishing for the community to give me free proof(s). My question is as follows: The latter exercise appears to just be Burnside's Lemma, which I am all for having as an exercise. But the former exercise to me screams ""Hey, this is the type of problem where Burnside's Lemma does a lot of the heavy lifting."" Am I missing so obvious (or clever) approach to the former that allows one to circumvent using Burnside's Lemma, or should I chalk this up to the order of exercises not really mattering in the grand scheme of pedagogy? Thank you all for your help and insight :D","In Lang's Algebra, the following two exercises are presented to the reader in the following order: Groups Exercise 15: Let be a finite group acting on , a finite set of at least elements. Assume there is only one orbit. Prove there is at least one with no fixed point, i.e. for all , . Groups Exercise 19b.: Let be a finite group action on a finite set . For each , define . Prove the number of orbits of is equal to I can include the proofs I have for both of these if desired to assuage any concerns that I am fishing for the community to give me free proof(s). My question is as follows: The latter exercise appears to just be Burnside's Lemma, which I am all for having as an exercise. But the former exercise to me screams ""Hey, this is the type of problem where Burnside's Lemma does a lot of the heavy lifting."" Am I missing so obvious (or clever) approach to the former that allows one to circumvent using Burnside's Lemma, or should I chalk this up to the order of exercises not really mattering in the grand scheme of pedagogy? Thank you all for your help and insight :D","G S 2 g\in G s\in S g\cdot s\ne s G S g\in G {\rm Stab}(g):=\{s\in S : gs = s\} S 
\frac{1}{\#G}\sum_{g\in G}\#{\rm Stab}(g).
","['abstract-algebra', 'group-theory', 'education', 'group-actions', 'algebraic-combinatorics']"
9,"Affine Functions, Möbius and Hyperbolic","Affine Functions, Möbius and Hyperbolic",,"I haven't been able to figure out the relationship between objects in an Exercise of Do Carmo's book on Riemannian Geometry and this may be a bit vague, but I am posting out of despair. I want to understand how the hyperbolic metric arises on the upper half plane $\mathbb{H}$ , but struggle to understand why Do Carmo starts with $g(t) = yt +x$ . The following steps aim to make my question more precise, but not well defined: The functions $f(t) = yt +x$ ( $x,y \in \mathbb{R}, y>0$ ) define a group under composition, which can be understood as the upper half plane. Under composition, these functions define a group. We use this to define a left invariant metric, that at $e = (0,1)$ coincides with the usual scalar product on $\mathbb{R}^2$ ( $\langle u,v \rangle_{(f_2t+f_1)} = f_2^{-2}\langle u, v \rangle_e$ ). So far, we have $(G,\circ)$ and $\mathbb{R} \times \mathbb{R}_{>0}$ and our defined metric. Now, in part (b) of the Exercise, we add the complex upper half plane (which I write $\mathbb{H}$ ). It inherits complex multiplication and addition. We are asked to prove that $f_1 + if_2 = z \mapsto \frac{az + b}{cz + d}$ is an isometry of $G$ . Q: Why introduce the metric $g_{ij} = \delta_{ij}/y^2$ through these affine functions ( $G,\circ)$ ? It seems Do Carmo motivates the appearance of this metric as ""the one left-invariant under composition of real affine Transformations"" and then drops it and uses it on the complex upper half plane, which has a completely different structure to these affine transformations. Through my approaches so far: I've had the Idea of looking at the equivalence relation $(f,g) \sim (\lambda f, \lambda g), \lambda \in \mathbb{C}^\times$ . In this case: $(f_2t + f_1, g_2t + g_1) \sim (\frac{f_2t + f_1}{g_2t + g_1},1)$ which looks like a Möbius transformation, only $t \in \mathbb{R}$ in the Exercise. This didn't satisfy me but looks promising as $\mathrm{SL}_2(\mathbb{Z})$ is very close (acting on each component). If we add $z \mapsto -1/z$ we can then express the Möbius transformation as a composition of transformations of $G$ . But then, why start with $G$ first?  (random guess, Does adding this inversion correspond to adding a point at infinity?) In euclidian spaces, such affine transformations are our ""change of coordinates"", which leave the metric invariant. Here, we show that the Möbius transormations in a more general setting when we add that inversion. These actions seem to give us a way to ""straighten"" two points to a ""line"". Pointing in some direction for me to investigate would make me happy. The context is a talk that I will give on closed geodesics in $\mathbb{H}/\mathrm{SL}_2(\mathbb{Z})$ and their relationship to class Numbers. P.S. Having solved the Exercise, the discussion is not meant to be about a specific solution. Just the motivation behind the structure of the exercise.","I haven't been able to figure out the relationship between objects in an Exercise of Do Carmo's book on Riemannian Geometry and this may be a bit vague, but I am posting out of despair. I want to understand how the hyperbolic metric arises on the upper half plane , but struggle to understand why Do Carmo starts with . The following steps aim to make my question more precise, but not well defined: The functions ( ) define a group under composition, which can be understood as the upper half plane. Under composition, these functions define a group. We use this to define a left invariant metric, that at coincides with the usual scalar product on ( ). So far, we have and and our defined metric. Now, in part (b) of the Exercise, we add the complex upper half plane (which I write ). It inherits complex multiplication and addition. We are asked to prove that is an isometry of . Q: Why introduce the metric through these affine functions ( ? It seems Do Carmo motivates the appearance of this metric as ""the one left-invariant under composition of real affine Transformations"" and then drops it and uses it on the complex upper half plane, which has a completely different structure to these affine transformations. Through my approaches so far: I've had the Idea of looking at the equivalence relation . In this case: which looks like a Möbius transformation, only in the Exercise. This didn't satisfy me but looks promising as is very close (acting on each component). If we add we can then express the Möbius transformation as a composition of transformations of . But then, why start with first?  (random guess, Does adding this inversion correspond to adding a point at infinity?) In euclidian spaces, such affine transformations are our ""change of coordinates"", which leave the metric invariant. Here, we show that the Möbius transormations in a more general setting when we add that inversion. These actions seem to give us a way to ""straighten"" two points to a ""line"". Pointing in some direction for me to investigate would make me happy. The context is a talk that I will give on closed geodesics in and their relationship to class Numbers. P.S. Having solved the Exercise, the discussion is not meant to be about a specific solution. Just the motivation behind the structure of the exercise.","\mathbb{H} g(t) = yt +x f(t) = yt +x x,y \in \mathbb{R}, y>0 e = (0,1) \mathbb{R}^2 \langle u,v \rangle_{(f_2t+f_1)} = f_2^{-2}\langle u, v \rangle_e (G,\circ) \mathbb{R} \times \mathbb{R}_{>0} \mathbb{H} f_1 + if_2 = z \mapsto \frac{az + b}{cz + d} G g_{ij} = \delta_{ij}/y^2 G,\circ) (f,g) \sim (\lambda f, \lambda g), \lambda \in \mathbb{C}^\times (f_2t + f_1, g_2t + g_1) \sim (\frac{f_2t + f_1}{g_2t + g_1},1) t \in \mathbb{R} \mathrm{SL}_2(\mathbb{Z}) z \mapsto -1/z G G \mathbb{H}/\mathrm{SL}_2(\mathbb{Z})","['abstract-algebra', 'number-theory', 'differential-geometry', 'riemannian-geometry', 'hyperbolic-geometry']"
10,Centralizer of a Subgroup is a Subgroup,Centralizer of a Subgroup is a Subgroup,,"If $H$ is a subgroup of $G$ , then Gallian defines the centralizer $C(H)$ of $H$ as the set $$C(H) = \{g \in G : \text{$g h = h g$ for all $h \in H $}\} \,.$$ It’s easy to show that $C(H)$ is a subgroup of $G$ : Clearly $e h = h e = h$ for all $h \in H$ , so $C(H)$ is nonempty. Then if $g_0 \in C(H)$ and $g_1 \in C(H)$ , then $$(g_0 g_1) h = g_0 (g_1 h) = g_0 (h g_1) = (g_0 h) g_1 = h(g_0 g_1)$$ for all $h\in H$ , so $g_0g_1\in C(H)$ . Similarly, $$g_0 \in C(H) \iff g_0 h = h g_0 \iff g_0^{-1} (g_0 h) g_0^{-1} = g_0^{-1} (h g_0) g_0^{-1} \iff h g_0^{-1} = g_0^{-1} h$$ for all $h\in H$ , so we have $g_0^{-1}\in C(H)$ . Thus $C(H)$ is a subgroup of $G$ . I have two concerns about this proof. First, it is the exact same proof as for showing $C(h)$ is a subgroup of $G$ for any fixed $h \in G$ , except for adding the two “for all $h \in H$ ” clauses after each closure argument. Is anything else needed? Second, where does the condition that $H$ is a subgroup come into play? It seems one could take $H$ to be any subset of the group, not necessarily a subgroup. Thanks in advance!","If is a subgroup of , then Gallian defines the centralizer of as the set It’s easy to show that is a subgroup of : Clearly for all , so is nonempty. Then if and , then for all , so . Similarly, for all , so we have . Thus is a subgroup of . I have two concerns about this proof. First, it is the exact same proof as for showing is a subgroup of for any fixed , except for adding the two “for all ” clauses after each closure argument. Is anything else needed? Second, where does the condition that is a subgroup come into play? It seems one could take to be any subset of the group, not necessarily a subgroup. Thanks in advance!","H G C(H) H C(H) = \{g \in G : \text{g h = h g for all h \in H }\} \,. C(H) G e h = h e = h h \in H C(H) g_0 \in C(H) g_1 \in C(H) (g_0 g_1) h = g_0 (g_1 h) = g_0 (h g_1) = (g_0 h) g_1 = h(g_0 g_1) h\in H g_0g_1\in C(H) g_0 \in C(H) \iff g_0 h = h g_0 \iff g_0^{-1} (g_0 h) g_0^{-1} = g_0^{-1} (h g_0) g_0^{-1} \iff h g_0^{-1} = g_0^{-1} h h\in H g_0^{-1}\in C(H) C(H) G C(h) G h \in G h \in H H H",['abstract-algebra']
11,"Generating set of a ring and the ""empty product""","Generating set of a ring and the ""empty product""",,"Given some ring $R$ , a subset of elements $S$ is a ""generating set"" $R$ if every element in the ring can be written as a sum or difference of products of elements of $S$ . Or, borrowing the LaTeX from this answer , we have that a ring $R$ is generated by $S=\{s_1,\dots, s_n\}$ iff every element of $R$ can be written in the form $$ \pm(s_{i_{1,1}}s_{i_{1,2}}\dots s_{i_{2,1}})\pm(s_{i_{2,2}}\dots s_{i_{2,p_1}})\pm\dots\pm(s_{i_{n,1}}\dots s_{i_{n,p_n}}) $$ The question, which is also talked about in the comments of the above answer, is if the ""empty product"" of $1$ is allowed. If so, this would seem to suggest that $\Bbb Z$ is generated by the empty set, since everything is a sum or difference of empty products. This is kind of the ring-theoretic version of the idea that the trivial group is generated by the empty set. Similarly, the rings $\Bbb Z/n\Bbb Z$ would also appear to be generated by the empty set (as a subset of those rings). The ring $\Bbb Z[x]$ would be generated by only $\{x\}$ , as $1$ would still basically be generated as an empty product of no $x$ 's (i.e. as $x^0$ ). It all seems to make sense, and agrees with the alternative definition that $S$ generates $R$ iff $R$ is the smallest subring of itself (preserving $1$ ) that has all the elements of $S$ , which is (vacuously) true of the empty set in $\Bbb Z$ . Questions : Is this standard use of terminology when we talk about generating sets of rings? If we look at ""rng""s without $1$ , is it then standard to omit the empty product (equivalent to looking at the smallest ""subrng"" containing $S$ )?","Given some ring , a subset of elements is a ""generating set"" if every element in the ring can be written as a sum or difference of products of elements of . Or, borrowing the LaTeX from this answer , we have that a ring is generated by iff every element of can be written in the form The question, which is also talked about in the comments of the above answer, is if the ""empty product"" of is allowed. If so, this would seem to suggest that is generated by the empty set, since everything is a sum or difference of empty products. This is kind of the ring-theoretic version of the idea that the trivial group is generated by the empty set. Similarly, the rings would also appear to be generated by the empty set (as a subset of those rings). The ring would be generated by only , as would still basically be generated as an empty product of no 's (i.e. as ). It all seems to make sense, and agrees with the alternative definition that generates iff is the smallest subring of itself (preserving ) that has all the elements of , which is (vacuously) true of the empty set in . Questions : Is this standard use of terminology when we talk about generating sets of rings? If we look at ""rng""s without , is it then standard to omit the empty product (equivalent to looking at the smallest ""subrng"" containing )?","R S R S R S=\{s_1,\dots, s_n\} R 
\pm(s_{i_{1,1}}s_{i_{1,2}}\dots s_{i_{2,1}})\pm(s_{i_{2,2}}\dots s_{i_{2,p_1}})\pm\dots\pm(s_{i_{n,1}}\dots s_{i_{n,p_n}})
 1 \Bbb Z \Bbb Z/n\Bbb Z \Bbb Z[x] \{x\} 1 x x^0 S R R 1 S \Bbb Z 1 S","['abstract-algebra', 'ring-theory', 'terminology']"
12,What right triangles can be constructed using sides of three distinct regular polygons with the same circumradius?,What right triangles can be constructed using sides of three distinct regular polygons with the same circumradius?,,"I have been wondering if the following question requires advanced mathematics such as ring theory: What are the right triangles that we can construct using the side lengths of three distinct regular polygons having the same circumradius? An example would be the triangle constructed using an equilateral triangle, a square and a regular hexagon.","I have been wondering if the following question requires advanced mathematics such as ring theory: What are the right triangles that we can construct using the side lengths of three distinct regular polygons having the same circumradius? An example would be the triangle constructed using an equilateral triangle, a square and a regular hexagon.",,"['abstract-algebra', 'geometry', 'trigonometry']"
13,"Given a finitely generated, residually finite, non-cohopfian group $G$, can the following abelianizations ALL be finite?","Given a finitely generated, residually finite, non-cohopfian group , can the following abelianizations ALL be finite?",G,"Let $G$ be a finitely generated, residually finite, non-cohopfian group. Since $G$ is residually finite, we know that there exists a sequence of nested, normal, finite index subgroups $$G  = N_0 \rhd  N_1  \rhd N_2    \ldots $$ with the trivial intersection. Question : Is it possible that all $N_i$ have finite abelianization, i.e. the quotient group $N_i \big/ [N_i,N_i]$ is finite for every $i$ ? My thoughts so far : It is clear that $G$ can't be finite (finite implies cohopfian) or abelian or free (free groups have infinite abelianization). The closest group I was informed is $D_{\infty} = \; \left<r,s \;|\; srs=r^{-1}, s^2=1 \right>$ , which is finitely generated, residually finite and non-cohopfian. However, for any sequence of nested, normal, finite index subgroups with the trivial intersection $D_{\infty} = N_0 \rhd  N_1  \rhd N_2    \ldots $ , we eventually have $N_i$ contains only rotations, which means $N_i$ is infinite abelian, hence has infinite abelianization.","Let be a finitely generated, residually finite, non-cohopfian group. Since is residually finite, we know that there exists a sequence of nested, normal, finite index subgroups with the trivial intersection. Question : Is it possible that all have finite abelianization, i.e. the quotient group is finite for every ? My thoughts so far : It is clear that can't be finite (finite implies cohopfian) or abelian or free (free groups have infinite abelianization). The closest group I was informed is , which is finitely generated, residually finite and non-cohopfian. However, for any sequence of nested, normal, finite index subgroups with the trivial intersection , we eventually have contains only rotations, which means is infinite abelian, hence has infinite abelianization.","G G G  = N_0 \rhd  N_1  \rhd N_2    \ldots  N_i N_i \big/ [N_i,N_i] i G D_{\infty} = \; \left<r,s \;|\; srs=r^{-1}, s^2=1 \right> D_{\infty} = N_0 \rhd  N_1  \rhd N_2    \ldots  N_i N_i","['abstract-algebra', 'group-theory', 'geometric-group-theory', 'infinite-groups']"
14,Show the function between the dihedral groups is well defined,Show the function between the dihedral groups is well defined,,"Suppose that $n = dm$ where $d$ and $m$ are positive integers with $m\ge 3$ . Consider the dihedral group $D_n = \langle \{\mu, \rho\}\rangle,$ where $|\mu| = 2$ , $|\rho| = n$ and $\rho\mu = \mu\rho^{−1}$ , and the dihedral group $D_m = \langle \{s, r\}\rangle,$ where $|s| = 2$ , $|r| = m$ and $rs = sr^{−1}$ . Define $\psi : D_n \to D_m$ by $ψ(\mu^a\rho^b)=s^ar^b$ , for any integers $a,b$ . Show that $\psi$ is well-defined. Here's the stuff I noticed: different values of $a,b$ can give the same group element $\mu^a\rho^b$ , and I need to show that they also give the same $\psi(\mu^a\rho^b)$ . if $n$ is not a multiple of $m$ , then $\psi$ not well-defined. So here is what I did so far, (tried to make a proof sketch): from integer division, there exists unique integers $i, j, s, t$ with $0 \le i < 2$ and $0 \le j < n$ and $a = i + 2s$ and $b = j + nt$ . So, the group element $\mu^a\rho^b=\mu^{i+2s}\rho^{j+nt}$ uniquely determined by $i$ and $j$ , since changing $s$ and $t$ won't make a difference. So, I think I need to show that $\psi(\mu^a\rho^b)$ depends only on $i$ and $j$ , and not on $s$ or $t$ . (this is what I'm having a hard time doing.)","Suppose that where and are positive integers with . Consider the dihedral group where , and , and the dihedral group where , and . Define by , for any integers . Show that is well-defined. Here's the stuff I noticed: different values of can give the same group element , and I need to show that they also give the same . if is not a multiple of , then not well-defined. So here is what I did so far, (tried to make a proof sketch): from integer division, there exists unique integers with and and and . So, the group element uniquely determined by and , since changing and won't make a difference. So, I think I need to show that depends only on and , and not on or . (this is what I'm having a hard time doing.)","n = dm d m m\ge 3 D_n = \langle \{\mu, \rho\}\rangle, |\mu| = 2 |\rho| = n \rho\mu = \mu\rho^{−1} D_m = \langle \{s, r\}\rangle, |s| = 2 |r| = m rs = sr^{−1} \psi : D_n \to D_m ψ(\mu^a\rho^b)=s^ar^b a,b \psi a,b \mu^a\rho^b \psi(\mu^a\rho^b) n m \psi i, j, s, t 0 \le i < 2 0 \le j < n a = i + 2s b = j + nt \mu^a\rho^b=\mu^{i+2s}\rho^{j+nt} i j s t \psi(\mu^a\rho^b) i j s t","['abstract-algebra', 'group-theory', 'permutations', 'group-isomorphism', 'dihedral-groups']"
15,Is there a quadratically closed field strictly between the quadratic closures of $\mathbb{Q}$ and $\mathbb{Q}(\sqrt[3]{2})$?,Is there a quadratically closed field strictly between the quadratic closures of  and ?,\mathbb{Q} \mathbb{Q}(\sqrt[3]{2}),"Let $K$ be the quadratic closure of $\mathbb{Q}$ , and $K'$ the quadratic closure of $\mathbb{Q}(\sqrt[3]{2})$ . Is there a quadratically closed field $L$ strictly between $K$ and $K'$ , i.e. such that $K \subsetneq L \subsetneq K'$ ? It is a particular case of my previous question , so this is inspired by questions about ruler and compass constructions. If we could find some element $r \in K' \setminus K$ such that $\sqrt[3]{2}$ is of degree $3$ in $\mathbb{Q}(r)$ , then the quadratic closure of $\mathbb{Q}(r)$ would not contain $\sqrt[3]{2}$ , because the quadratic closure only adds elements whose degrees are powers of $2$ , and therefore we could define $L$ as this quadratic closure. The degree of $r$ over $\mathbb{Q}$ , if there is such a $r$ , is a power of $2$ , because we have $$ [\mathbb{Q}(\sqrt[3]{2},r) : \mathbb{Q}] = [\mathbb{Q}(\sqrt[3]{2},r) : \mathbb{Q}(\sqrt[3]{2})] \cdot [\mathbb{Q}(\sqrt[3]{2}) : \mathbb{Q}] = 2^n \cdot 3$$ so $$ [\mathbb{Q}(r) : \mathbb{Q}] = \frac{[\mathbb{Q}(\sqrt[3]{2},r) : \mathbb{Q}]}{[\mathbb{Q}(\sqrt[3]{2},r) : \mathbb{Q}(r)]} = \frac{2^n \cdot 3}{3} = 2^n.$$ We also have the reverse implication: if there is a quadratically closed field $L$ strictly between $K$ and $K'$ , then $\sqrt[3]{2}$ must be of degree $3$ over $L$ , otherwise it would be of degree smaller than $3$ , and there is no element of degree $2$ over $L$ , so it would be contained in $L$ , and for any element $r \in L \setminus K$ , $\sqrt[3]{2}$ would be of degree $3$ over $\mathbb{Q}(r)$ . To sum up, the question reduces to: is there an $r$ which is of degree a power of $2$ over $\mathbb{Q}$ and which is not polyquadratic over $\mathbb{Q}$ , but which is polyquadratic over $\mathbb{Q}(\sqrt[3]{2})$ ? You can find the formulas for the roots of a quartic polynomial here . We see that the solutions are contained in the quadratic closure of $\mathbb{Q}(\sqrt[3]{2})$ if the intermediate parameter $f$ is an integer or if it is equal to $\sqrt[3]{2}$ . So if we could find such an irreducible quartic over $\mathbb{Q}$ and such that its roots are not polyquadratic, we would conclude. But that becomes quite far fetched. Edit: Now cross-posted (not by me) on Mathoverflow .","Let be the quadratic closure of , and the quadratic closure of . Is there a quadratically closed field strictly between and , i.e. such that ? It is a particular case of my previous question , so this is inspired by questions about ruler and compass constructions. If we could find some element such that is of degree in , then the quadratic closure of would not contain , because the quadratic closure only adds elements whose degrees are powers of , and therefore we could define as this quadratic closure. The degree of over , if there is such a , is a power of , because we have so We also have the reverse implication: if there is a quadratically closed field strictly between and , then must be of degree over , otherwise it would be of degree smaller than , and there is no element of degree over , so it would be contained in , and for any element , would be of degree over . To sum up, the question reduces to: is there an which is of degree a power of over and which is not polyquadratic over , but which is polyquadratic over ? You can find the formulas for the roots of a quartic polynomial here . We see that the solutions are contained in the quadratic closure of if the intermediate parameter is an integer or if it is equal to . So if we could find such an irreducible quartic over and such that its roots are not polyquadratic, we would conclude. But that becomes quite far fetched. Edit: Now cross-posted (not by me) on Mathoverflow .","K \mathbb{Q} K' \mathbb{Q}(\sqrt[3]{2}) L K K' K \subsetneq L \subsetneq K' r \in K' \setminus K \sqrt[3]{2} 3 \mathbb{Q}(r) \mathbb{Q}(r) \sqrt[3]{2} 2 L r \mathbb{Q} r 2  [\mathbb{Q}(\sqrt[3]{2},r) : \mathbb{Q}] = [\mathbb{Q}(\sqrt[3]{2},r) : \mathbb{Q}(\sqrt[3]{2})] \cdot [\mathbb{Q}(\sqrt[3]{2}) : \mathbb{Q}] = 2^n \cdot 3  [\mathbb{Q}(r) : \mathbb{Q}] = \frac{[\mathbb{Q}(\sqrt[3]{2},r) : \mathbb{Q}]}{[\mathbb{Q}(\sqrt[3]{2},r) : \mathbb{Q}(r)]} = \frac{2^n \cdot 3}{3} = 2^n. L K K' \sqrt[3]{2} 3 L 3 2 L L r \in L \setminus K \sqrt[3]{2} 3 \mathbb{Q}(r) r 2 \mathbb{Q} \mathbb{Q} \mathbb{Q}(\sqrt[3]{2}) \mathbb{Q}(\sqrt[3]{2}) f \sqrt[3]{2} \mathbb{Q}","['abstract-algebra', 'field-theory', 'extension-field']"
16,"Let $G$ be a torsion-free abelian group, prove that for $g\neq h\in G$ there exists a homomorphism $\phi:G\to\Bbb{R}$ such that $\phi(g)\neq\phi(h)$","Let  be a torsion-free abelian group, prove that for  there exists a homomorphism  such that",G g\neq h\in G \phi:G\to\Bbb{R} \phi(g)\neq\phi(h),"I have the following question: Let $G$ be a torsion-free abelian group, prove that for every distinct elements $g, h \in G$ there exists a homomorphism $\phi: G \rightarrow \mathbb{R}$ such that $\phi(g)\neq \phi (h)$ . I have some observations, if I take $\phi(g)=a$ and $\phi(h)=b$ , for $a\neq  b\in \mathbb{R}$ and define $\phi(g^n h^m)= na + mb $ for every $m, n\in \mathbb{N}$ , then $\phi: \langle g, h\rangle\rightarrow \mathbb{R}$ is an homomorphism (it is well defined since $G$ is torsion free abelian). Therefore, if $G$ is finitely generated, by a similar agument I can conclude the problem. For the case where $G$ is not finitely generated I don't have any progress yet. I will appreciate any hint! thanks!","I have the following question: Let be a torsion-free abelian group, prove that for every distinct elements there exists a homomorphism such that . I have some observations, if I take and , for and define for every , then is an homomorphism (it is well defined since is torsion free abelian). Therefore, if is finitely generated, by a similar agument I can conclude the problem. For the case where is not finitely generated I don't have any progress yet. I will appreciate any hint! thanks!","G g, h \in G \phi: G \rightarrow \mathbb{R} \phi(g)\neq \phi (h) \phi(g)=a \phi(h)=b a\neq  b\in \mathbb{R} \phi(g^n h^m)= na + mb  m, n\in \mathbb{N} \phi: \langle g, h\rangle\rightarrow \mathbb{R} G G G","['abstract-algebra', 'group-theory', 'group-homomorphism', 'torsion-groups', 'free-abelian-group']"
17,"If $d$ is a gcd of $a$ and $b$, is $dx$ a gcd of $ax$ and $bx$?","If  is a gcd of  and , is  a gcd of  and ?",d a b dx ax bx,"Let $D$ be an integral domain and $a,b,x \in D$ . If $d$ is a greatest common divisor ( gcd ) of $a$ and $b$ , is it true that $dx$ is a gcd of $ax$ and $bx$ ? Note that $D$ is an integer domain, not a GCD domain. So this question is not the same as any of the following questions： 1 2 3 etc. More specifically, the existence of gcd of $ax$ and $bx$ is not guaranteed. Any insights are much appreciated. BTW: To avoid ambiguity , I haven't used notations such as $(a,b)$ or $(ax,bx)$ , which makes me verbose. You may use it at will.","Let be an integral domain and . If is a greatest common divisor ( gcd ) of and , is it true that is a gcd of and ? Note that is an integer domain, not a GCD domain. So this question is not the same as any of the following questions： 1 2 3 etc. More specifically, the existence of gcd of and is not guaranteed. Any insights are much appreciated. BTW: To avoid ambiguity , I haven't used notations such as or , which makes me verbose. You may use it at will.","D a,b,x \in D d a b dx ax bx D ax bx (a,b) (ax,bx)","['abstract-algebra', 'ring-theory', 'gcd-and-lcm', 'integral-domain']"
18,Central product isomorphism: $Z_4 * Q_8 \cong Z_4 * D_8$,Central product isomorphism:,Z_4 * Q_8 \cong Z_4 * D_8,"This problem is problem 5.1.12.b of Dummit and Foote and Ive been tearing my hair out. I managed to do 5.1.12.a and 5.1.13 which are related and were pretty simple but I can't for the life of me figure this one out. I tried to look up a solution online in the end but the solution was wrong so that didn't help either. Here is the problem: Let $Z_4=\left<x\right>$ . Let $D_8 = \left<r,s\right>$ and $Q_8=\left<i,j\right>$ be given by their usual generators and relations. Let $Z_4 * D_8$ be the central product of $Z_4$ and $D_8$ which identifies $x^2$ and $r^2$ (ie $Z_1=\left<x^2\right>, Z_2=\left<r^2\right>$ and the isomorphism is $x^2 \mapsto r^2$ ) and let $Z_4 * Q_8$ be the central product of $Z_4$ and $Q_8$ which identifies $x^2$ and $-1$ . Prove that $Z_4 * D_8 \cong Z_4 * Q_8$ . For reference of what the problem means by $Z_1$ and $Z_2$ here is the problem's definition of a central product: Let $A$ and $B$ be groups. Assume $Z(A)$ contains a subgroup $Z_1$ and $Z(B)$ contains a subgroup $Z_2$ with $Z_1\cong Z_2$ . Let this isomorphism be given by the map $x_i\mapsto y_i$ for all $x_i\in Z_1$ . A central product of $A$ and $B$ is a quotient $$\begin{equation} (A \times B)/Z \text{ where } Z=\{(x_i,y_i^{-1}) : x_i\in Z_1\}  \end{equation}$$ and is denoted by $A * B$ . I realize I could technically list out the elements of each set since it's only a total of 32 elements and then construct the first isomorphism that jumps out to me but that would not be interesting and very unsatisfying. Would love to hear if anyone has an elegant way to solve this.",This problem is problem 5.1.12.b of Dummit and Foote and Ive been tearing my hair out. I managed to do 5.1.12.a and 5.1.13 which are related and were pretty simple but I can't for the life of me figure this one out. I tried to look up a solution online in the end but the solution was wrong so that didn't help either. Here is the problem: Let . Let and be given by their usual generators and relations. Let be the central product of and which identifies and (ie and the isomorphism is ) and let be the central product of and which identifies and . Prove that . For reference of what the problem means by and here is the problem's definition of a central product: Let and be groups. Assume contains a subgroup and contains a subgroup with . Let this isomorphism be given by the map for all . A central product of and is a quotient and is denoted by . I realize I could technically list out the elements of each set since it's only a total of 32 elements and then construct the first isomorphism that jumps out to me but that would not be interesting and very unsatisfying. Would love to hear if anyone has an elegant way to solve this.,"Z_4=\left<x\right> D_8 = \left<r,s\right> Q_8=\left<i,j\right> Z_4 * D_8 Z_4 D_8 x^2 r^2 Z_1=\left<x^2\right>, Z_2=\left<r^2\right> x^2 \mapsto r^2 Z_4 * Q_8 Z_4 Q_8 x^2 -1 Z_4 * D_8 \cong Z_4 * Q_8 Z_1 Z_2 A B Z(A) Z_1 Z(B) Z_2 Z_1\cong Z_2 x_i\mapsto y_i x_i\in Z_1 A B \begin{equation}
(A \times B)/Z \text{ where } Z=\{(x_i,y_i^{-1}) : x_i\in Z_1\} 
\end{equation} A * B","['abstract-algebra', 'group-theory', 'group-isomorphism', 'quotient-group', 'direct-product']"
19,Proof Verification - Hungerford I.8.3,Proof Verification - Hungerford I.8.3,,"$\textbf{Hungerford I $\S$8, problem 3.}$ Let $G$ be an (additive) abelian group with subgroups $H$ and $K$ . Show that $G \cong H \oplus K$ iff there are homomorphisms $\pi_1:G\to H$ , $\pi_2:G\to K$ , $\iota_1: H\to G$ , and $\iota_2:K\to G$ such that $$\pi_1\iota_1 = 1_H,\ \pi_2\iota_2 = 1_K,\ \pi_1\iota_2 = 0 = \pi_2\iota_1$$ and $\iota_1\pi_1(x) + \iota_2\pi_2(x) = x$ for all $x \in G$ . My question is if the abelian assumption is needed at all. Here is a purposed proof of the $\Longleftarrow$ direction that does not use the fact that $G$ is abelian whatsoever: Consider $f :G \to H \oplus K$ with $f(g) := (\pi_1(g), \pi_2(g))$ for all $g\in G$ . Then $f$ is a homomorphism; $f$ is surjective since if $(h,k)\in H \oplus K$ , then by taking $g = \iota_1(h)\iota_2(k)$ , our assumption gives that $f(g) = (h,k)$ ; and $f$ is injective since if $g,g'\in G$ and $f(g) = f(g')$ , then $\pi_1(g) = \pi_1(g')$ and $\pi_2(g) = \pi_2(g')$ which (again by our assumption) yields that $$g = \iota_1(\pi_1(g)) \cdot \iota_2(\pi_2(g)) = \iota_1(\pi_1(g'))\cdot \iota_2(\pi_2(g')) = g'.$$ The other direction is somewhat obvious and I don't think uses the fact that $G$ is abelian at all either: Let $\phi: G\to H \oplus K$ be an isomorphism and for $i = 1,2$ let $\pi_i := p_i\phi$ and $\iota_i:=\phi^{-1}j_i$ , where $p_i$ and $j_i$ are canonical projections/inclusions. Yes, there is another post about this question but focuses on generalizing this problem in a completely different way and thus does not answer my question.","Let be an (additive) abelian group with subgroups and . Show that iff there are homomorphisms , , , and such that and for all . My question is if the abelian assumption is needed at all. Here is a purposed proof of the direction that does not use the fact that is abelian whatsoever: Consider with for all . Then is a homomorphism; is surjective since if , then by taking , our assumption gives that ; and is injective since if and , then and which (again by our assumption) yields that The other direction is somewhat obvious and I don't think uses the fact that is abelian at all either: Let be an isomorphism and for let and , where and are canonical projections/inclusions. Yes, there is another post about this question but focuses on generalizing this problem in a completely different way and thus does not answer my question.","\textbf{Hungerford I \S8, problem 3.} G H K G \cong H \oplus K \pi_1:G\to H \pi_2:G\to K \iota_1: H\to G \iota_2:K\to G \pi_1\iota_1 = 1_H,\ \pi_2\iota_2 = 1_K,\ \pi_1\iota_2 = 0 = \pi_2\iota_1 \iota_1\pi_1(x) + \iota_2\pi_2(x) = x x \in G \Longleftarrow G f :G \to H \oplus K f(g) := (\pi_1(g), \pi_2(g)) g\in G f f (h,k)\in H \oplus K g = \iota_1(h)\iota_2(k) f(g) = (h,k) f g,g'\in G f(g) = f(g') \pi_1(g) = \pi_1(g') \pi_2(g) = \pi_2(g') g = \iota_1(\pi_1(g)) \cdot \iota_2(\pi_2(g)) = \iota_1(\pi_1(g'))\cdot \iota_2(\pi_2(g')) = g'. G \phi: G\to H \oplus K i = 1,2 \pi_i := p_i\phi \iota_i:=\phi^{-1}j_i p_i j_i","['abstract-algebra', 'group-theory', 'solution-verification']"
20,Automorphism group of a non-abelian group is divisible by $p^2$.,Automorphism group of a non-abelian group is divisible by .,p^2,"Suppose $G$ is a finite non-abelian group, so that $|G|=p^n$ for some positive integer $n\ge 3$ (where $p$ is prime). How can we prove that $|{\rm Aut}(G)|$ is divisible by $p^2$ ? We know that $G/Z(G)\leq{\rm Aut}(G)$ by the inner automorphisms and the first isomorphism theorem. And because $G$ is non-abelian $Z(G)<G$ and by Lagrange's Theorem $|G/Z(G)|=\frac{p^n}{|Z(G)|}$ . But from here I'm stuck.","Suppose is a finite non-abelian group, so that for some positive integer (where is prime). How can we prove that is divisible by ? We know that by the inner automorphisms and the first isomorphism theorem. And because is non-abelian and by Lagrange's Theorem . But from here I'm stuck.",G |G|=p^n n\ge 3 p |{\rm Aut}(G)| p^2 G/Z(G)\leq{\rm Aut}(G) G Z(G)<G |G/Z(G)|=\frac{p^n}{|Z(G)|},"['abstract-algebra', 'group-theory', 'finite-groups', 'automorphism-group', 'p-groups']"
21,"When does a space admit a ""multiplication-defining"" metric?","When does a space admit a ""multiplication-defining"" metric?",,"Define a Thales space to be a topological space $\mathcal{X}=(X,\tau)$ such that there is some $d:X^2\rightarrow\mathbb{R}$ such that the following hold: The map $d$ is a metric and the topology it induces is $\tau$ . The map $\mathbb{R}^2\rightarrow\mathbb{R}: (x,y)\mapsto xy$ is (first-order, with parameters) definable in the two-sorted structure $$(X\sqcup \mathbb{R}; +,<,d).$$ For example, the usual metric witnesses that $\mathbb{R}^n$ is a Thales space for each $n>1$ as a consequence of Thales' intercept theorem (hence the name). [Stupid claims removed.] Ultimately I'd love an exact characterization of Thales spaces, but I think that's rather ambitious. An easier question would be something along the lines of, ""Is there a non-pathological Thales space which doesn't lean on the intersection theorem?"" I'll make that precise in the following way: Is there a Thales space which is separable and into which $\mathbb{R}^2$ does not continuously embed? (As Eric Wofsey's answer demonstrate separability doesn't actually rule out pathological examples, but it's what I asked.) I'd love to add ""connected"" but that might make the question too hard.","Define a Thales space to be a topological space such that there is some such that the following hold: The map is a metric and the topology it induces is . The map is (first-order, with parameters) definable in the two-sorted structure For example, the usual metric witnesses that is a Thales space for each as a consequence of Thales' intercept theorem (hence the name). [Stupid claims removed.] Ultimately I'd love an exact characterization of Thales spaces, but I think that's rather ambitious. An easier question would be something along the lines of, ""Is there a non-pathological Thales space which doesn't lean on the intersection theorem?"" I'll make that precise in the following way: Is there a Thales space which is separable and into which does not continuously embed? (As Eric Wofsey's answer demonstrate separability doesn't actually rule out pathological examples, but it's what I asked.) I'd love to add ""connected"" but that might make the question too hard.","\mathcal{X}=(X,\tau) d:X^2\rightarrow\mathbb{R} d \tau \mathbb{R}^2\rightarrow\mathbb{R}: (x,y)\mapsto xy (X\sqcup \mathbb{R}; +,<,d). \mathbb{R}^n n>1 \mathbb{R}^2","['abstract-algebra', 'general-topology', 'logic', 'metric-spaces', 'model-theory']"
22,An example about a non-commutative division ring with finite characteristic,An example about a non-commutative division ring with finite characteristic,,"After reading the proof of the theorem “For every central division $F$ -algebra $D$ with $D$ $\neq$ $F$ , $D$ contains a separable extension $K \supsetneqq F$ “, I have a question: dose there exist a non-commutative division ring $D$ with finite characteristic, which contains an $x\in D$ such that $x^n \not\in Z(D)$ for all positive integers n? First I tried quaternion algebra over  field $F_p(X)$ . Let $i^2= x$ , $j^2= y$ , $ij=k$ , $ji=-k$ where $x, y$ are any non-zero elements in $F_p(X)$ , the quaternion algebra $H(F_p(X))$ is a vector space over $F_p(X)$ with a basis $\{1,i ,j, k\}$ . Let $α =a+ib+jc+kd$ , $\bar{α}=a-ib-jc-kd$ , $α\bar{α}= \bar{α}α= a^2-xb^2-yc^2+xyd^2$ , then $H(F_p(X))$ is a division ring if and only if $α\bar{α}= 0$ implies $α= 0$ . After trying some examples, I find that the consequent processes are hard. Does there exist some good example that satisfies the property in the question?","After reading the proof of the theorem “For every central division -algebra with , contains a separable extension “, I have a question: dose there exist a non-commutative division ring with finite characteristic, which contains an such that for all positive integers n? First I tried quaternion algebra over  field . Let , , , where are any non-zero elements in , the quaternion algebra is a vector space over with a basis . Let , , , then is a division ring if and only if implies . After trying some examples, I find that the consequent processes are hard. Does there exist some good example that satisfies the property in the question?","F D D \neq F D K \supsetneqq F D x\in D x^n \not\in Z(D) F_p(X) i^2= x j^2= y ij=k ji=-k x, y F_p(X) H(F_p(X)) F_p(X) \{1,i ,j, k\} α =a+ib+jc+kd \bar{α}=a-ib-jc-kd α\bar{α}= \bar{α}α= a^2-xb^2-yc^2+xyd^2 H(F_p(X)) α\bar{α}= 0 α= 0","['abstract-algebra', 'modules', 'noncommutative-algebra']"
23,"Let $G$ be a finite abelian group, and let $n$ divide $|G|$. Let $m$ be the number of solutions of $x^n=1$. Prove that $n\mid m$.","Let  be a finite abelian group, and let  divide . Let  be the number of solutions of . Prove that .",G n |G| m x^n=1 n\mid m,"Let $G$ be a finite abelian group, and let $n$ divide $|G|$ .  Let $m$ be the number of solutions of $x^n=1$ .  Prove that $n\mid m$ . My attempt It's tempting to find a way to use Lagrange's theorem.  Maybe something here is a subgroup of something else?  We can fix $n$ and take the subgroup of $G$ of all elements which solve $x^n=1$ .  Proof that this is a subgroup:  Inverses of solutions are always solutions.  Because the group is abelian, products of solutions are solutions.  QED. Great, so it's a subgroup, so $m$ divides the order of $G$ .  So does $n$ .  I'm not sure that this really got me anywhere.  It'd be nice if there were some relevant subgroup of order $n$ . Being finite and abelian then it has a representation as $G\cong C_{p_1^{n_1}}\times\dots\times C_{p_k^{n_k}}$ , a product of cyclic groups of prime power order.  The solutions are exactly the product of solutions ""in each factor"", i.e. solutions of the form $\langle e, \dots, e, x, e, \dots, e\rangle$ where $x\in C_{p_i^{k_i}}$ for some $i$ .  So perhaps something comes from thinking about the number of solutions to $x^n=1$ where $x$ is taken from $C_{p_i^{k_i}}$ . Again this is a subgroup so the number of solutions divides $p_i^{k_i}$ , and $p_i^{k_i}$ divides $|G|$ . And $n$ divides the order of $G$ .  But at this point I'm not sure whether I'm on a productive path, since these facts don't seem to be enough to show that $n|m$ . In fact the more that I think about how $n$ is so-to-speak missing factors from $|G|$ the more I think that finding numbers which divide $|G|$ just isn't a productive path.","Let be a finite abelian group, and let divide .  Let be the number of solutions of .  Prove that . My attempt It's tempting to find a way to use Lagrange's theorem.  Maybe something here is a subgroup of something else?  We can fix and take the subgroup of of all elements which solve .  Proof that this is a subgroup:  Inverses of solutions are always solutions.  Because the group is abelian, products of solutions are solutions.  QED. Great, so it's a subgroup, so divides the order of .  So does .  I'm not sure that this really got me anywhere.  It'd be nice if there were some relevant subgroup of order . Being finite and abelian then it has a representation as , a product of cyclic groups of prime power order.  The solutions are exactly the product of solutions ""in each factor"", i.e. solutions of the form where for some .  So perhaps something comes from thinking about the number of solutions to where is taken from . Again this is a subgroup so the number of solutions divides , and divides . And divides the order of .  But at this point I'm not sure whether I'm on a productive path, since these facts don't seem to be enough to show that . In fact the more that I think about how is so-to-speak missing factors from the more I think that finding numbers which divide just isn't a productive path.","G n |G| m x^n=1 n\mid m n G x^n=1 m G n n G\cong C_{p_1^{n_1}}\times\dots\times C_{p_k^{n_k}} \langle e, \dots, e, x, e, \dots, e\rangle x\in C_{p_i^{k_i}} i x^n=1 x C_{p_i^{k_i}} p_i^{k_i} p_i^{k_i} |G| n G n|m n |G| |G|","['abstract-algebra', 'group-theory', 'finite-groups', 'abelian-groups']"
24,Most groups are noncommutative,Most groups are noncommutative,,"From page 41 of Evan Chen's napkin it states that most groups are noncommutative. This led me to think about an unconventional question: let $$C_n:=\text{number of nonisomorphic abelian groups of order }n$$ $$G_n:=\text{number of nonisomorphic groups of order }n.$$ Are there any known results on $\limsup_{n\rightarrow\infty}\frac{C_n}{G_n}$ or $\liminf_{n\rightarrow\infty}\frac{C_n}{G_n}$ ? Notice from here , for $p$ prime we have $C_{p^3}/G_{p^3}=3/5$ , so we can deduce $$\liminf_{n\rightarrow \infty}\frac{C_n}{G_n}\leq\frac{3}{5}$$ and also since $C_{p^2}/G_{p^2}=1$ , we have $$1\leq \limsup_{n\rightarrow \infty}\frac{C_n}{G_n}.$$ My question is, can these bounds be improved, and is determining the exact value possible? Edit: I realize that since $C_n/G_n\leq 1$ for all $n$ , we obviously have $\limsup_{n\rightarrow\infty}C_n/G_n=1$ . So forget about that.","From page 41 of Evan Chen's napkin it states that most groups are noncommutative. This led me to think about an unconventional question: let Are there any known results on or ? Notice from here , for prime we have , so we can deduce and also since , we have My question is, can these bounds be improved, and is determining the exact value possible? Edit: I realize that since for all , we obviously have . So forget about that.",C_n:=\text{number of nonisomorphic abelian groups of order }n G_n:=\text{number of nonisomorphic groups of order }n. \limsup_{n\rightarrow\infty}\frac{C_n}{G_n} \liminf_{n\rightarrow\infty}\frac{C_n}{G_n} p C_{p^3}/G_{p^3}=3/5 \liminf_{n\rightarrow \infty}\frac{C_n}{G_n}\leq\frac{3}{5} C_{p^2}/G_{p^2}=1 1\leq \limsup_{n\rightarrow \infty}\frac{C_n}{G_n}. C_n/G_n\leq 1 n \limsup_{n\rightarrow\infty}C_n/G_n=1,"['abstract-algebra', 'group-theory']"
25,Reference request for the Elimination Properties of Resultants,Reference request for the Elimination Properties of Resultants,,"Let $f,g$ be polynomials in $k[y_1,\dots,y_n][x]$ over a field $k$ . Assume that at least one of $f$ and $g$ is of positive degree in $x$ . Denote by $\operatorname{res}_x(f,g)$ the resultant of $f$ and $g$ with respect to $x$ . On the Wikipedia page for Resultants, under Elimination properties it is stated that if $R$ is a ring of polynomials, $f,g\in R[x]$ at least one of positive degree in $x$ and $I=(f,g)$ , then $I\cap R$ is a principal ideal of $R$ , generated by some $r\in R$ $\operatorname{res}_x(f,g)$ is in the principal ideal $(r)$ of $R$ There exists a positive integer $k$ such that $r^k$ is in the principal ideal $(\operatorname{res}_x(f,g))$ of $R$ . I am kindly asking for a reference on all three claims. I was not able to find any mention of these results in the refereces listed on the Wikipedia page (Gelfand Kapranov Zelevinski; Cox Little O'Shea; Macaulay; Salmon).","Let be polynomials in over a field . Assume that at least one of and is of positive degree in . Denote by the resultant of and with respect to . On the Wikipedia page for Resultants, under Elimination properties it is stated that if is a ring of polynomials, at least one of positive degree in and , then is a principal ideal of , generated by some is in the principal ideal of There exists a positive integer such that is in the principal ideal of . I am kindly asking for a reference on all three claims. I was not able to find any mention of these results in the refereces listed on the Wikipedia page (Gelfand Kapranov Zelevinski; Cox Little O'Shea; Macaulay; Salmon).","f,g k[y_1,\dots,y_n][x] k f g x \operatorname{res}_x(f,g) f g x R f,g\in R[x] x I=(f,g) I\cap R R r\in R \operatorname{res}_x(f,g) (r) R k r^k (\operatorname{res}_x(f,g)) R","['abstract-algebra', 'algebraic-geometry', 'reference-request', 'commutative-algebra', 'resultant']"
26,"If $ g_1, g_2, g_3 ,..., g_n$ are representatives of conjugacy classes of a group $G$ such that the elements pairwise commute, then $G$ is abelian.","If  are representatives of conjugacy classes of a group  such that the elements pairwise commute, then  is abelian."," g_1, g_2, g_3 ,..., g_n G G","The question says, Let $ g_1, g_2, g_3 ... g_n$ be representatives of all the distinct conjugacy classes of a finite group $G$ , such that these elements pairwise commute. Prove that $G$ is abelian. I just want my proof to get verified, as this is really simple, I'm a little sceptical about it. Proof: Let $C_G(g_i)$ be the centraliser of the element $g_i$ . Since it is given all the $g_i$ 's pairwise commute, we have $$  C_G(g_1) \cap C_G(g_2) \cap ... \cap C_G(g_n) \supset \{g_1, g_2, g_3 ... g_n\} $$ . Let us assume $|G|=N$ . Since we have $|C_G(g_i)| \geq n, \forall i \in \{1,2,...,n\}$ , from the class equation we have $$ |G| = \sum_{i=1}^n{|G : C_G(g_i)|} $$ or, $$ N \geq \left( \frac{N}{n}\right) .n$$ and the equality holds iff $|C_G(g_i)|=n \forall i \in \{1,2,...,n\}$ . Thus we have, $C_G(g_i)=\{g_1, g_2, g_3 ... g_n\}  \forall i \in \{1,2,...,n\}$ . However, from the class equation, we have $C_G(g_i)=G$ for at least one $g_i$ , which belongs to the centre of the group $Z(G)$ . Hence $G= \{g_1, g_2, g_3 ... g_n\}$ and the group is abelian ( Proved ). Is it all right or am I missing something?","The question says, Let be representatives of all the distinct conjugacy classes of a finite group , such that these elements pairwise commute. Prove that is abelian. I just want my proof to get verified, as this is really simple, I'm a little sceptical about it. Proof: Let be the centraliser of the element . Since it is given all the 's pairwise commute, we have . Let us assume . Since we have , from the class equation we have or, and the equality holds iff . Thus we have, . However, from the class equation, we have for at least one , which belongs to the centre of the group . Hence and the group is abelian ( Proved ). Is it all right or am I missing something?"," g_1, g_2, g_3 ... g_n G G C_G(g_i) g_i g_i   C_G(g_1) \cap C_G(g_2) \cap ... \cap C_G(g_n) \supset \{g_1, g_2, g_3 ... g_n\}  |G|=N |C_G(g_i)| \geq n, \forall i \in \{1,2,...,n\}  |G| = \sum_{i=1}^n{|G : C_G(g_i)|}   N \geq \left( \frac{N}{n}\right) .n |C_G(g_i)|=n \forall i \in \{1,2,...,n\} C_G(g_i)=\{g_1, g_2, g_3 ... g_n\}  \forall i \in \{1,2,...,n\} C_G(g_i)=G g_i Z(G) G= \{g_1, g_2, g_3 ... g_n\}","['abstract-algebra', 'group-theory', 'solution-verification']"
27,Chow group of a DVR,Chow group of a DVR,,"I need a sanity check on the following: If $A$ is a DVR then $CH_0(A) = 0$ . The proof is simple. A 0-dimensional cycle is of the form $Z= n \cdot [s]$ , where s is the closed point of $\operatorname{Spec} A$ . Let $\pi$ be a uniformizer of $A$ . Then $div(\pi^n) = length_A(A/(\pi^n))\cdot [s] = n \cdot [s]$ . Hence $CH_0(A) = Z_0(A)/R_0(A) = 0$ . Is this correct?","I need a sanity check on the following: If is a DVR then . The proof is simple. A 0-dimensional cycle is of the form , where s is the closed point of . Let be a uniformizer of . Then . Hence . Is this correct?",A CH_0(A) = 0 Z= n \cdot [s] \operatorname{Spec} A \pi A div(\pi^n) = length_A(A/(\pi^n))\cdot [s] = n \cdot [s] CH_0(A) = Z_0(A)/R_0(A) = 0,"['abstract-algebra', 'algebraic-geometry', 'commutative-algebra']"
28,Homomorphic image of an alternating group,Homomorphic image of an alternating group,,"I'm solving the following problem: If $f:S_n\rightarrow S_n$ is a group homomorphism, prove that $f(A_n)\subseteq A_n.$ (Here, $S_n$ is a symmetric group of degree $n$ , and $A_n$ is an alternating group of degree $n.$ ) For $n=2,$ it is trivial. Let $n\geq3.$ First we show that for any $3$ -cycle $(abc)\in S_n,$ its image $f((abc))$ is even . Suppose, on the contrary, that $f((abc))$ is odd . Since $(abc)^3=(1),$ $f((abc))^3=f((abc)^3)=f((1))=(1)$ . (Note that $f$ is a homomorphism). Thus, $f((abc))^3=(1).$ However, $(1)$ is $even$ and since we assumed that $f((abc))$ is odd , $f((abc))^3$ is odd . This is a contradiction! Thus $f((abc))$ is even . As every element $\sigma$ of $A_n$ (that is, all even permutations) is a product of $3$ -cycles ( Link ), we may write $\sigma = (a_1b_1c_1)\cdots(a_nb_nc_n).$ Then, $f(\sigma)=f((a_1b_1c_1)\cdots(a_nb_nc_n))=f((a_1b_1c_1))\cdots f((a_nb_nc_n)).$ As each $f((a_1b_1c_1)),\dots,f((a_nb_nc_n))$ is even , $f(\sigma)$ is also even . It follows that $f(A_n)\subseteq A_n$ ! Is my argument correct?","I'm solving the following problem: If is a group homomorphism, prove that (Here, is a symmetric group of degree , and is an alternating group of degree ) For it is trivial. Let First we show that for any -cycle its image is even . Suppose, on the contrary, that is odd . Since . (Note that is a homomorphism). Thus, However, is and since we assumed that is odd , is odd . This is a contradiction! Thus is even . As every element of (that is, all even permutations) is a product of -cycles ( Link ), we may write Then, As each is even , is also even . It follows that ! Is my argument correct?","f:S_n\rightarrow S_n f(A_n)\subseteq A_n. S_n n A_n n. n=2, n\geq3. 3 (abc)\in S_n, f((abc)) f((abc)) (abc)^3=(1), f((abc))^3=f((abc)^3)=f((1))=(1) f f((abc))^3=(1). (1) even f((abc)) f((abc))^3 f((abc)) \sigma A_n 3 \sigma = (a_1b_1c_1)\cdots(a_nb_nc_n). f(\sigma)=f((a_1b_1c_1)\cdots(a_nb_nc_n))=f((a_1b_1c_1))\cdots f((a_nb_nc_n)). f((a_1b_1c_1)),\dots,f((a_nb_nc_n)) f(\sigma) f(A_n)\subseteq A_n","['abstract-algebra', 'group-theory', 'solution-verification', 'symmetric-groups', 'group-homomorphism']"
29,Prove that this set is a ring,Prove that this set is a ring,,"Let $X$ be a set and $\mathcal{B}$ a subset of the set of maps from $X$ to $\mathbb{Z}_2$ . For any subset $A\subset X$ we define the characteristic mapping of A as the mapping $\chi_A:X\rightarrow \mathbb{Z}_2$ given by $\chi_A(x)=1$ if $x\in A$ and $\chi_A(x)=0$ if $x\notin A$ . Give $\mathcal{B}$ the operations: $\odot: \mathcal{B} \times \mathcal{B} \rightarrow \mathcal{B}$ given by $(\chi_A \odot \chi_B)(x)=\chi_A(x) \cdot \chi_B(x)$ and $\oplus : \mathcal{B} \times \mathcal{B} \rightarrow \mathcal{B}$ given by $(\chi_A \oplus \chi_B)(x)=\chi_A(x) + \chi_B(x) - \chi_A(x) \cdot \chi_B(x)$ . Show that $\mathcal{B}$ whith these operations is a ring . As a part of this exercise, we have to see that $(\mathcal{B},\oplus)$ is a group. I have considered the map $\chi_\emptyset$ as the neutral element for the addition $\oplus$ since $\chi_\emptyset (x)=0$ $\forall x \in X$ . But I have a problem when I try to find an opposite element because $\chi_A(x) + \chi_B(x) - \chi_A(x) \cdot \chi_B(x)$ has to be $0$ but it only happens if $x\in A^c \cap B^c$ . So, what is our candidate for be an opposite of $\chi_A$ and how can I denote it? Is it correct to consider the map $\chi_\emptyset$ as the neutral element?","Let be a set and a subset of the set of maps from to . For any subset we define the characteristic mapping of A as the mapping given by if and if . Give the operations: given by and given by . Show that whith these operations is a ring . As a part of this exercise, we have to see that is a group. I have considered the map as the neutral element for the addition since . But I have a problem when I try to find an opposite element because has to be but it only happens if . So, what is our candidate for be an opposite of and how can I denote it? Is it correct to consider the map as the neutral element?","X \mathcal{B} X \mathbb{Z}_2 A\subset X \chi_A:X\rightarrow \mathbb{Z}_2 \chi_A(x)=1 x\in A \chi_A(x)=0 x\notin A \mathcal{B} \odot: \mathcal{B} \times \mathcal{B} \rightarrow \mathcal{B} (\chi_A \odot \chi_B)(x)=\chi_A(x) \cdot \chi_B(x) \oplus : \mathcal{B} \times \mathcal{B} \rightarrow \mathcal{B} (\chi_A \oplus \chi_B)(x)=\chi_A(x) + \chi_B(x) - \chi_A(x) \cdot \chi_B(x) \mathcal{B} (\mathcal{B},\oplus) \chi_\emptyset \oplus \chi_\emptyset (x)=0 \forall x \in X \chi_A(x) + \chi_B(x) - \chi_A(x) \cdot \chi_B(x) 0 x\in A^c \cap B^c \chi_A \chi_\emptyset","['abstract-algebra', 'characteristic-functions']"
30,Octonion Algebras Over Number Fields,Octonion Algebras Over Number Fields,,Is there any textbook or paper about Arithmetic of Octonion Algebras or Octonion Algebras constructed over number fields? I know J. Voight book and K. Martin notes about quaternion algebras but I was thinking about a generalization using Octonions. More than that: Is it possible to define Orders and Maximal Orders over an octonion algebra? Or these concepts just make sense over associative algebras?,Is there any textbook or paper about Arithmetic of Octonion Algebras or Octonion Algebras constructed over number fields? I know J. Voight book and K. Martin notes about quaternion algebras but I was thinking about a generalization using Octonions. More than that: Is it possible to define Orders and Maximal Orders over an octonion algebra? Or these concepts just make sense over associative algebras?,,"['abstract-algebra', 'quaternions', 'octonions']"
31,No. of finite group (nonidentity)elements $x$ satisfying $x^5=e$ is a multiple of $4$,No. of finite group (nonidentity)elements  satisfying  is a multiple of,x x^5=e 4,"In a finite group $G$ with $e:=\text{id}_G$ , show that the number of nonidentity elements that satisfy the equation $x^5=e$ is a multiple of 4. This is number $50$ , Ch. $2$ from Gallian's text. I have seen two repeats of this question on MSE ( Show that number of solutions satisfying $x^5=e$ is a multiple of 4? , In a finite group, show that the number of nonidentity elements that satisfy the equation $x^5=e$ is a multiple of 4. ) but I still have questions about the question and my proof. My first question: Do we have to assume that $x^5=e$ for some $x\in G$ in the first place? My thinking is that this is a yes since in general a finite group may not have such an $x$ . Proof of claim : Suppose some $x\in G$ , $\space$$x\neq e$ satisfies the condition $x^5=e$ . Then note that $x^2\in G$ and $$(x^2)^5=(x^5)^2=e^2=e$$ so $x^2$ satisfies the condition. Similarly $x^3\in G$ and $x^4\in G$ . Observe that $$(x^3)^5=(x^5)^3=e^3=e$$ $$(x^4)^5=(x^5)^4=e^4=e$$ so that $x^3$ and $x^4$ also satisfy the condition. Once we verify that $x,x^2,x^3,x^4$ are distinct and that $x^i\neq e$ for $1\leq i \leq 4$ we will have proved the claim since for every $x$ that is a solution, so is $x^2$ , $x^3$ , and $x^4$ . Thus solutions come in multiples of $4$ . Note that we don't consider elements like $x^6$ or $x^7$ as solutions because $x^6=x$ and $x^7=x^2$ i.e. for $n>5$ , $x^n=x^i$ where $i\in\{1,2,3,4,5\}$ . So, considering powers of elements modulo $5$ is enough. To show each $x^i$ is distinct, we assume the contrary. That is, assume $$x^i=x^j$$ for some distinct $i,j\in\{1,2,3,4\}$ . Thus if we take $i$ to always be the greater of the two, $$x^i=x^j\iff x^{i-j}=e$$ so $$i-j=1,2\text{ or } 3$$ Note it is impossible $i-j=1$ by the assumption that $x\neq e$ . If $i-j=2$ or $i-j=3$ , then $$x^2=e\text{ and } x^3=e\implies x^3=x^2\cdot x=e\cdot x=x = e$$ but the latter shows $x=e$ if $x^3=e$ and $x^2=e$ ; this is a contradiciton. Thus it must be false that $x^i=x^j$ for some distinct $i,j\in\{1,2,3,4,5\}$ . In proving the above, we saw that the $x^2=e=x^3$ leads to a contradiction, so to show the last claim, namely that $x^i\neq e$ , we show that $x^4\neq e$ . Again assume that indeed $x^4=e$ . Then $$x^4=e=x^5\iff e=x\therefore\text{ contradiction }$$ $\blacksquare$ My second question: Is the above proof correct? By removing the condition that the group be finite, how could this change the conclusion about the number of solutions? I never really utilized that $G$ was finite above (maybe tacitly? I don't know) so I'm pretty stumped on this one.","In a finite group with , show that the number of nonidentity elements that satisfy the equation is a multiple of 4. This is number , Ch. from Gallian's text. I have seen two repeats of this question on MSE ( Show that number of solutions satisfying $x^5=e$ is a multiple of 4? , In a finite group, show that the number of nonidentity elements that satisfy the equation $x^5=e$ is a multiple of 4. ) but I still have questions about the question and my proof. My first question: Do we have to assume that for some in the first place? My thinking is that this is a yes since in general a finite group may not have such an . Proof of claim : Suppose some , satisfies the condition . Then note that and so satisfies the condition. Similarly and . Observe that so that and also satisfy the condition. Once we verify that are distinct and that for we will have proved the claim since for every that is a solution, so is , , and . Thus solutions come in multiples of . Note that we don't consider elements like or as solutions because and i.e. for , where . So, considering powers of elements modulo is enough. To show each is distinct, we assume the contrary. That is, assume for some distinct . Thus if we take to always be the greater of the two, so Note it is impossible by the assumption that . If or , then but the latter shows if and ; this is a contradiciton. Thus it must be false that for some distinct . In proving the above, we saw that the leads to a contradiction, so to show the last claim, namely that , we show that . Again assume that indeed . Then My second question: Is the above proof correct? By removing the condition that the group be finite, how could this change the conclusion about the number of solutions? I never really utilized that was finite above (maybe tacitly? I don't know) so I'm pretty stumped on this one.","G e:=\text{id}_G x^5=e 50 2 x^5=e x\in G x x\in G \spacex\neq e x^5=e x^2\in G (x^2)^5=(x^5)^2=e^2=e x^2 x^3\in G x^4\in G (x^3)^5=(x^5)^3=e^3=e (x^4)^5=(x^5)^4=e^4=e x^3 x^4 x,x^2,x^3,x^4 x^i\neq e 1\leq i \leq 4 x x^2 x^3 x^4 4 x^6 x^7 x^6=x x^7=x^2 n>5 x^n=x^i i\in\{1,2,3,4,5\} 5 x^i x^i=x^j i,j\in\{1,2,3,4\} i x^i=x^j\iff x^{i-j}=e i-j=1,2\text{ or } 3 i-j=1 x\neq e i-j=2 i-j=3 x^2=e\text{ and } x^3=e\implies x^3=x^2\cdot x=e\cdot x=x = e x=e x^3=e x^2=e x^i=x^j i,j\in\{1,2,3,4,5\} x^2=e=x^3 x^i\neq e x^4\neq e x^4=e x^4=e=x^5\iff e=x\therefore\text{ contradiction } \blacksquare G",['abstract-algebra']
32,Gelfand-Kolmogorov Theorem for the space $C(X)$ with compact $X$: ring vs algebra version.,Gelfand-Kolmogorov Theorem for the space  with compact : ring vs algebra version.,C(X) X,"A theorem by Gelfand and Kolmogorov comes in two different guises, depending on which structure we consider on $C(X)$ , namely if that of unital commutative ring or that of algebra. Ring version Let X and Y be compact spaces. Then, $C(X)$ and $C(Y)$ are isomorphic as rings if, and only if, $X$ and $Y$ are homeomorphic. Moreover, every rings isomorphism $T : C(Y)→ C(X)$ is of the form $Tf = f\circ h$ where $h:X →Y$ is a homeomorphism. Identically, we have: Algebra version Let X and Y be compact spaces. Then, $C(X)$ and $C(Y)$ are isomorphic as algebras if, and only if, $X$ and $Y$ are homeomorphic. Moreover, every algebra isomorphism $T : C(Y)→ C(X)$ is of the form $Tf = f\circ h$ where $h:X →Y$ is a homeomorphism. Now these two versions are claimed equivalent, but I cannot find an explicit proof of the fact, nonetheless I think the equivalence is based on the following Lemma : Each nonzero ring homomorphims $\omega:C(Y)\rightarrow \mathbb{R}$ is surjective and for each constant $c\in\mathbb{R}$ , letting $\delta\equiv 1$ ,    we have $\omega(c\delta)=c$ . Is this sufficient to prove that any ring homomorphism $\lambda: C(X)\rightarrow C(Y)$ is also an algebra homorphism? If not how to prove it? Morover, I think the two equivalent versions of the theorem have a categorical rephrasing: basically we have two contravariant functors: $C(−):Top→ComRing$ $C(−):Top→ComAlg $ Can we say something more about the categorical interpretation of this theorem? Has the Lemma or whatsoever the result needed to prove the equivalence, or the equivalence itself, a categorical interpretation too?","A theorem by Gelfand and Kolmogorov comes in two different guises, depending on which structure we consider on , namely if that of unital commutative ring or that of algebra. Ring version Let X and Y be compact spaces. Then, and are isomorphic as rings if, and only if, and are homeomorphic. Moreover, every rings isomorphism is of the form where is a homeomorphism. Identically, we have: Algebra version Let X and Y be compact spaces. Then, and are isomorphic as algebras if, and only if, and are homeomorphic. Moreover, every algebra isomorphism is of the form where is a homeomorphism. Now these two versions are claimed equivalent, but I cannot find an explicit proof of the fact, nonetheless I think the equivalence is based on the following Lemma : Each nonzero ring homomorphims is surjective and for each constant , letting ,    we have . Is this sufficient to prove that any ring homomorphism is also an algebra homorphism? If not how to prove it? Morover, I think the two equivalent versions of the theorem have a categorical rephrasing: basically we have two contravariant functors: Can we say something more about the categorical interpretation of this theorem? Has the Lemma or whatsoever the result needed to prove the equivalence, or the equivalence itself, a categorical interpretation too?",C(X) C(X) C(Y) X Y T : C(Y)→ C(X) Tf = f\circ h h:X →Y C(X) C(Y) X Y T : C(Y)→ C(X) Tf = f\circ h h:X →Y \omega:C(Y)\rightarrow \mathbb{R} c\in\mathbb{R} \delta\equiv 1 \omega(c\delta)=c \lambda: C(X)\rightarrow C(Y) C(−):Top→ComRing C(−):Top→ComAlg ,"['abstract-algebra', 'general-topology', 'functional-analysis', 'proof-verification', 'category-theory']"
33,"The field of fractions of $\mathbb{Z}[[X]]$ and $\mathbb{Q}[[X]]$, the power series rings, are different.","The field of fractions of  and , the power series rings, are different.",\mathbb{Z}[[X]] \mathbb{Q}[[X]],"It is not hard to see that the field of fractions of $\mathbb{Z}[X]$ is the same as the field of fractions of $\mathbb{Q}[X]$ ; so I wonder if the same is true for the respective power series rings. My attempt: Let $p(x) \in \mathbb{Z}[[X]]$ such that its constant term is nonzero. In $\mathbb{Q}[[X]]$ , $p(x)$ is a unit; consequently, $p(x)/1$ is an element of the field of fraction of $\mathbb{Q}[[X]]$ . On the other hand, $p(x)$ is not a unit of the integral domain $\mathbb{Z}[[X]]$ . Then $p(x)/1$ is not an element of the field of fractions of $\mathbb{Z}[X]$ . Am I right? Thanks in advance!","It is not hard to see that the field of fractions of is the same as the field of fractions of ; so I wonder if the same is true for the respective power series rings. My attempt: Let such that its constant term is nonzero. In , is a unit; consequently, is an element of the field of fraction of . On the other hand, is not a unit of the integral domain . Then is not an element of the field of fractions of . Am I right? Thanks in advance!",\mathbb{Z}[X] \mathbb{Q}[X] p(x) \in \mathbb{Z}[[X]] \mathbb{Q}[[X]] p(x) p(x)/1 \mathbb{Q}[[X]] p(x) \mathbb{Z}[[X]] p(x)/1 \mathbb{Z}[X],"['abstract-algebra', 'ring-theory']"
34,Which subfields of the Galois group of $x^4+8x^2+8x+4$ are Galois and find the splitting field polynomial,Which subfields of the Galois group of  are Galois and find the splitting field polynomial,x^4+8x^2+8x+4,"This question is an exercise in Dummit and Foote: 1)I want to find the Galois group of $f(x)=x^4+8x^2+8x+4$ . 2)Which subfields of the splitting field of $x^4+8x^2+8x+4$ are Galois over $\Bbb Q$ ? 3) For the subfields which are Galois over $\Bbb Q$ , find the polynomial $f(x) \in \Bbb Q[x]$ for which they are the splitting field over $\Bbb Q$ . My attempt: I have calculated that $f(x)$ is irreducible moreover, the resolvent cubic $h(x)=x^3-16x^2+48x+64$ is irreducible. Again the discriminant $315392$ is not a square so the Galois group has to $S_4$ . So part 1) is done. Now, the subfields of the Galois group of $x^4+8x^2+8x+4$ which are Galois correspond to the fixed field of a normal subgroup of $S_4$ which are $K_4$ and $A_4$ . So in some sense part 2) is solved. If I want to answer this question as a field $Fix(K_4)=\Bbb Q(a_1,\cdots,a_n)$ and $Fix(A_4)=\Bbb Q(b_1,\cdots,b_r)$ then what will be $a_i$ and $b_j$ . I am not getting any clue for part 3). Please help.","This question is an exercise in Dummit and Foote: 1)I want to find the Galois group of . 2)Which subfields of the splitting field of are Galois over ? 3) For the subfields which are Galois over , find the polynomial for which they are the splitting field over . My attempt: I have calculated that is irreducible moreover, the resolvent cubic is irreducible. Again the discriminant is not a square so the Galois group has to . So part 1) is done. Now, the subfields of the Galois group of which are Galois correspond to the fixed field of a normal subgroup of which are and . So in some sense part 2) is solved. If I want to answer this question as a field and then what will be and . I am not getting any clue for part 3). Please help.","f(x)=x^4+8x^2+8x+4 x^4+8x^2+8x+4 \Bbb Q \Bbb Q f(x) \in \Bbb Q[x] \Bbb Q f(x) h(x)=x^3-16x^2+48x+64 315392 S_4 x^4+8x^2+8x+4 S_4 K_4 A_4 Fix(K_4)=\Bbb Q(a_1,\cdots,a_n) Fix(A_4)=\Bbb Q(b_1,\cdots,b_r) a_i b_j","['abstract-algebra', 'field-theory', 'galois-theory', 'symmetric-groups', 'galois-extensions']"
35,$A\otimes \mathbf{Q}\cong B\otimes \mathbf{Q}$ implies $A$ and $B$ are $\mathcal{C}$-isomorphic,implies  and  are -isomorphic,A\otimes \mathbf{Q}\cong B\otimes \mathbf{Q} A B \mathcal{C},"I am trying to solve exercise 211 on Davis-Kirk : Let $\mathcal{C}$ be the class of torsion abelian groups. Show that for any abelian groups $A,~B$ , $A\otimes \mathbf{Q}\cong B\otimes \mathbf{Q}$ implies $A$ and $B$ are $\mathcal{C}$ -isomorphic, that is, there exists an abelian group $C$ and group homomorphisms $f:C\to A$ , $g:C\to B$ such that $\ker f,\mathrm{coker} f$ , $\ker g,\mathrm{coker} g$ are abelian torsion groups. My attempt: Consider the exact sequence $$0\to\mathbf{Z}\to \mathbf{Q}\to \mathbf{Q}/\mathbf{Z} \to 0   $$ and the indcued exact sequence $$0\to \mathrm{Tor}(\mathbf{Q}/\mathbf{Z},A)\to A\to \mathbf{Q}\otimes A \to \mathbf{Q}/\mathbf{Z} \otimes A \to 0 $$ It is tempting to take the map $A\to \mathbf{Q}\otimes A$ whose kernel and cokernel are all torsion groups. But the definition ask us to find a map whose target is $A$ , not the source. Moreover, we cannot conclude $\mathrm{Tor}(\mathbf{Q}/\mathbf{Z},A)\cong \mathrm{Tor}(\mathbf{Q}/\mathbf{Z},B)$ . Besides from this ""canonical map"", I have no idea how to construct those two maps. Any hints and answer are welcome!","I am trying to solve exercise 211 on Davis-Kirk : Let be the class of torsion abelian groups. Show that for any abelian groups , implies and are -isomorphic, that is, there exists an abelian group and group homomorphisms , such that , are abelian torsion groups. My attempt: Consider the exact sequence and the indcued exact sequence It is tempting to take the map whose kernel and cokernel are all torsion groups. But the definition ask us to find a map whose target is , not the source. Moreover, we cannot conclude . Besides from this ""canonical map"", I have no idea how to construct those two maps. Any hints and answer are welcome!","\mathcal{C} A,~B A\otimes \mathbf{Q}\cong B\otimes \mathbf{Q} A B \mathcal{C} C f:C\to A g:C\to B \ker f,\mathrm{coker} f \ker g,\mathrm{coker} g 0\to\mathbf{Z}\to \mathbf{Q}\to \mathbf{Q}/\mathbf{Z} \to 0    0\to \mathrm{Tor}(\mathbf{Q}/\mathbf{Z},A)\to A\to \mathbf{Q}\otimes A \to \mathbf{Q}/\mathbf{Z} \otimes A \to 0  A\to \mathbf{Q}\otimes A A \mathrm{Tor}(\mathbf{Q}/\mathbf{Z},A)\cong \mathrm{Tor}(\mathbf{Q}/\mathbf{Z},B)","['abstract-algebra', 'group-theory', 'algebraic-topology', 'commutative-algebra', 'homological-algebra']"
36,Is Kaplansky's radical same as Jacobson radical?,Is Kaplansky's radical same as Jacobson radical?,,"For a ring $R$ , Kaplansky defines $x\circ y= x+y+xy$ and an element $x$ is s.t.b. right quasi-regular (r.q.r) if $x\circ y=0$ for some element $y$ . He defines radical to be set theoretic join (sum) of all right quasi regular (r.q.r) ideals where an ideal is r.q.r if all its elements are r.q.r. Jacobson radical $J(R)$ is the intersection of maximal left (or right) ideals of a ring. Does either of these radical implies other or are they completely unrelated? I can't see any connection here.","For a ring , Kaplansky defines and an element is s.t.b. right quasi-regular (r.q.r) if for some element . He defines radical to be set theoretic join (sum) of all right quasi regular (r.q.r) ideals where an ideal is r.q.r if all its elements are r.q.r. Jacobson radical is the intersection of maximal left (or right) ideals of a ring. Does either of these radical implies other or are they completely unrelated? I can't see any connection here.",R x\circ y= x+y+xy x x\circ y=0 y J(R),"['abstract-algebra', 'ring-theory']"
37,Subsets of $\mathbb Z/n\mathbb Z$ disjoint with some of its shifts,Subsets of  disjoint with some of its shifts,\mathbb Z/n\mathbb Z,"Are there any descriptions of all subsets $X$ of $\mathbb Z/n\mathbb Z$ with the following property:  there exists $a\ne 0$ in $\mathbb Z/n\mathbb Z$ such that $X$ is disjoint with $X + a = \{x + a \pmod n\mid x \in X\}$ ? For example, for $n=5$ , any set with 1 or 2 elements satisfies this property. I used to believe that the same holds for any subsets of size less than or equal to $\frac{n}{2}$ , but for $n=6$ , a counterexample can be easily constructed. Probably there’s some well-known theorem about it?","Are there any descriptions of all subsets of with the following property:  there exists in such that is disjoint with ? For example, for , any set with 1 or 2 elements satisfies this property. I used to believe that the same holds for any subsets of size less than or equal to , but for , a counterexample can be easily constructed. Probably there’s some well-known theorem about it?",X \mathbb Z/n\mathbb Z a\ne 0 \mathbb Z/n\mathbb Z X X + a = \{x + a \pmod n\mid x \in X\} n=5 \frac{n}{2} n=6,"['abstract-algebra', 'group-theory', 'finite-groups', 'additive-combinatorics', 'sumset']"
38,f irreducible polynomial with $p-2$ real roots $\Rightarrow$ $Gal(\mathbb{Q}_{f}/\mathbb{Q}) \cong S_{p}$,f irreducible polynomial with  real roots,p-2 \Rightarrow Gal(\mathbb{Q}_{f}/\mathbb{Q}) \cong S_{p},I have no idea what to do to show the following Let $p\ge 5$ be a prime number 1) Let $H\subset S_{p}$ be a subgroup of the symmetric group. Assume that $p$ divides the order of $H$ and that $H$ contains a transposition. Show that $H=S_{p}$ . 2) Let $f(X)\in \mathbb{Q}[X]$ be an irreducible polynomial of degree $p$ with exactly $p-2$ real roots and $\mathbb{Q}_{f}$ is the splitting field of $f$ in an algebraic closure $\overline{\mathbb{Q}}$ of $\mathbb{Q}$ . Show that $Gal(\mathbb{Q}_{f}/\mathbb{Q})$ is isomorphic to $S_{p}$ . Thanks in advance for any help.,I have no idea what to do to show the following Let be a prime number 1) Let be a subgroup of the symmetric group. Assume that divides the order of and that contains a transposition. Show that . 2) Let be an irreducible polynomial of degree with exactly real roots and is the splitting field of in an algebraic closure of . Show that is isomorphic to . Thanks in advance for any help.,p\ge 5 H\subset S_{p} p H H H=S_{p} f(X)\in \mathbb{Q}[X] p p-2 \mathbb{Q}_{f} f \overline{\mathbb{Q}} \mathbb{Q} Gal(\mathbb{Q}_{f}/\mathbb{Q}) S_{p},['abstract-algebra']
39,The meaning of **homomorphic preimage **,The meaning of **homomorphic preimage **,,"We are working on commutative Ring Theory and their modules. While studying a paper, we saw the concept ""homomorphic preimage of an $R$ -module"". I want to know the meaning of this.","We are working on commutative Ring Theory and their modules. While studying a paper, we saw the concept ""homomorphic preimage of an -module"". I want to know the meaning of this.",R,"['abstract-algebra', 'modules']"
40,Physical dimensions in math,Physical dimensions in math,,"I was interested in the idea of of formalising the idea of physical dimensions with an algebraic structure containing ""all physical quantities of any type"". You'd need: Scalar multiplication over the reals (so you can get ""2 kg"" from ""2 * kg"") Addition within the same dimension (so you can have ""kg + kg = 2 kg"") Multiplication of any two elements (so you can have ""J = N m = N * m"") Inverses (so you can have ""m/s = m * s^(-1)"") A tensor algebra could formalise this system -- but then you'd get all sorts of objects like ""1 kg + 1 m"", which make no sense. A group would make sense -- with sub-groups like ""mass measurements"", ""time measurements"", ""real numbers"", ""units"" -- but then you can't have zero. Plus, I'd like to have some notion of units or ""unit vectors""/""unit tensors"". What's a good way to formalise this?","I was interested in the idea of of formalising the idea of physical dimensions with an algebraic structure containing ""all physical quantities of any type"". You'd need: Scalar multiplication over the reals (so you can get ""2 kg"" from ""2 * kg"") Addition within the same dimension (so you can have ""kg + kg = 2 kg"") Multiplication of any two elements (so you can have ""J = N m = N * m"") Inverses (so you can have ""m/s = m * s^(-1)"") A tensor algebra could formalise this system -- but then you'd get all sorts of objects like ""1 kg + 1 m"", which make no sense. A group would make sense -- with sub-groups like ""mass measurements"", ""time measurements"", ""real numbers"", ""units"" -- but then you can't have zero. Plus, I'd like to have some notion of units or ""unit vectors""/""unit tensors"". What's a good way to formalise this?",,"['abstract-algebra', 'group-theory', 'physics', 'tensor-products', 'dimensional-analysis']"
41,Is the $\mathbb{Z}$-grading of a Clifford algebra basis independent?,Is the -grading of a Clifford algebra basis independent?,\mathbb{Z},"Let $V$ be a finite dimensional vector space over a field $K$ of characteristic $\neq 2$, and let $q \colon V \to K$ be a quadratic form. One of the first things to show when learning the theory of Clifford algebras is that any orthogonal basis $\{ e_1, \dots, e_n \}$ of $V$ gives rise to a basis $\{ e_{i_1} \dots e_{i_k} : 1 \leq i_1 < i_2 < \dots < i_k \leq n \}$ of $\operatorname{C\ell}(V,q)$ as a $K$-vector space. In that way, we obtain a direct sum decomposition $$   \operatorname{C\ell}(V,q) = C_0 \oplus \dots \oplus C_n, $$ where each $C_k$ is generated by the $k$-products $e_{i_1} \dots e_{i_k}$. It is often regarded as a grading, although it is not a grading of a $K$-algebra in the strict sense. Question 1: By looking at simple examples, it appears to me that this grading is independent of the orthogonal basis of $V$ chosen. Is this true? Question 2: The Wikipedia article on Clifford algebras suggests that the map $\operatorname{C\ell}(V,q) \to K$ sending each element to its $C_0$-part is basis independent (of course this would be implied by a positive answer to the first question). Is this true? Is there some kind of basis independent formula? Thank you in advance!","Let $V$ be a finite dimensional vector space over a field $K$ of characteristic $\neq 2$, and let $q \colon V \to K$ be a quadratic form. One of the first things to show when learning the theory of Clifford algebras is that any orthogonal basis $\{ e_1, \dots, e_n \}$ of $V$ gives rise to a basis $\{ e_{i_1} \dots e_{i_k} : 1 \leq i_1 < i_2 < \dots < i_k \leq n \}$ of $\operatorname{C\ell}(V,q)$ as a $K$-vector space. In that way, we obtain a direct sum decomposition $$   \operatorname{C\ell}(V,q) = C_0 \oplus \dots \oplus C_n, $$ where each $C_k$ is generated by the $k$-products $e_{i_1} \dots e_{i_k}$. It is often regarded as a grading, although it is not a grading of a $K$-algebra in the strict sense. Question 1: By looking at simple examples, it appears to me that this grading is independent of the orthogonal basis of $V$ chosen. Is this true? Question 2: The Wikipedia article on Clifford algebras suggests that the map $\operatorname{C\ell}(V,q) \to K$ sending each element to its $C_0$-part is basis independent (of course this would be implied by a positive answer to the first question). Is this true? Is there some kind of basis independent formula? Thank you in advance!",,"['abstract-algebra', 'quadratic-forms', 'noncommutative-algebra', 'clifford-algebras']"
42,About corollary of sylow $p$-subgroup of finite group.,About corollary of sylow -subgroup of finite group.,p,"I am facing a problem in group theory question or better say a doubt. If anyone can help me then please do try to solve this question. A couple of days ago, we were discussing a corollary of Sylow’s theorem in group theory (Abstract algebra) lectures. In that corollary, our teacher proved that if a finite group G has order 30 then, It will have a normal subgroup of order $15$; Sylow $3$-subgroup and Sylow $5$-subgroup will be normal in $G$. If you’ll see that we can write the order of group as, $$   o(G) = 30 = 2 \cdot 3 \cdot 5 $$ and you can easily observe that $2,3,5$ are primes and $2 < 3 < 5$ also the difference of the first two primes is $1$ (i.e. $3-2$) and the last two primes are $2$ (i.e. $5-3$). Let us write this in quite an easy manner, $$  (2, 3, 5) ⇒ (1, 2) $$ where the product of primes in left side gives us the order of G and the right side’s no. are the differences between the first two and the last two primes respectively. Though I know that this is not the formal way of writing this, for the sake of convenience, I’m writing it in this way. Now my doubt is, are there infinitely many such combinations of three primes $(p, q, r)$ with $p < q < r$ such that the difference of first two and the last two primes can be written as $2^{k-1}$ (i.e. $q-p$) and $2^k$ (i.e. $r-q$), where $k \in \mathbb{N}$, i.e. $$  (p, q, r) ⇒ (2^{k-1}, 2^k) $$ such that $p \cdot q \cdot r$ is an order of a group $G$ such that, $G$ has a normal subgroup of order $q \cdot r$; Sylow $q$-subgroup and Sylow $r$-subgroup will be normal in $G$. Moreover, if we are able to find such combination $(p, q, r)$ for some $k \in \mathbb{N}$, then will it be a unique combination for that $k$ and if it is not unique i.e. if there is more than one such combination then how many combinations are possible for that particular $k$ and is there any relation between the combinations for that $k$?","I am facing a problem in group theory question or better say a doubt. If anyone can help me then please do try to solve this question. A couple of days ago, we were discussing a corollary of Sylow’s theorem in group theory (Abstract algebra) lectures. In that corollary, our teacher proved that if a finite group G has order 30 then, It will have a normal subgroup of order $15$; Sylow $3$-subgroup and Sylow $5$-subgroup will be normal in $G$. If you’ll see that we can write the order of group as, $$   o(G) = 30 = 2 \cdot 3 \cdot 5 $$ and you can easily observe that $2,3,5$ are primes and $2 < 3 < 5$ also the difference of the first two primes is $1$ (i.e. $3-2$) and the last two primes are $2$ (i.e. $5-3$). Let us write this in quite an easy manner, $$  (2, 3, 5) ⇒ (1, 2) $$ where the product of primes in left side gives us the order of G and the right side’s no. are the differences between the first two and the last two primes respectively. Though I know that this is not the formal way of writing this, for the sake of convenience, I’m writing it in this way. Now my doubt is, are there infinitely many such combinations of three primes $(p, q, r)$ with $p < q < r$ such that the difference of first two and the last two primes can be written as $2^{k-1}$ (i.e. $q-p$) and $2^k$ (i.e. $r-q$), where $k \in \mathbb{N}$, i.e. $$  (p, q, r) ⇒ (2^{k-1}, 2^k) $$ such that $p \cdot q \cdot r$ is an order of a group $G$ such that, $G$ has a normal subgroup of order $q \cdot r$; Sylow $q$-subgroup and Sylow $r$-subgroup will be normal in $G$. Moreover, if we are able to find such combination $(p, q, r)$ for some $k \in \mathbb{N}$, then will it be a unique combination for that $k$ and if it is not unique i.e. if there is more than one such combination then how many combinations are possible for that particular $k$ and is there any relation between the combinations for that $k$?",,"['abstract-algebra', 'group-theory', 'number-theory']"
43,Why does Lang describe a field as a union and compositum of its subfields in this manner?,Why does Lang describe a field as a union and compositum of its subfields in this manner?,,"I am reading Serge Lang's Algebra , revised 3rd edition, and on page 226, the author makes the following definitions and observations: If $E,F \subset L$ , the compositum of $E$ and $F$ in $L$ is defined to be the smallest subfield of $L$ containing both $E$ and $F$ . It is denoted $EF$ . If $k \subset E$ and $\alpha_1,\dots,\alpha_n \in E$ , then $k(\alpha_1,\dots,\alpha_n)$ is defined to be the smallest subfield of $E$ containing $k$ and $\alpha_1,\dots,\alpha_n$ . Observe that $$ E = \bigcup k(\alpha_1,\dots,\alpha_n), $$ where the union is taken over all finite families $\{ \alpha_1,\dots,\alpha_n \}$ of elements of $E$ . The compositum of an arbitrary family of subfields of a field $L$ is defined as the smallest subfield of $L$ containing all fields in the family. $E$ is finitely generated over $k$ if there is a finite family $\{ \alpha_1,\dots,\alpha_n \}$ of elements of $E$ such that $E = k(\alpha_1,\dots,\alpha_n)$ . Observe that $E$ is the compositum of all its finitely generated subfields over $k$ . My question is regarding the two observations (point nos. 3 and 6). It appears to me that it is enough to take union (and compositum) over all subfields generated by a single element. For example for point no. 3, I can write $$ E = \bigcup_{\alpha \in E} k(\alpha) $$ because $E$ is clearly contained in the RHS, and each $k(\alpha)$ is contained in $E$ and hence so is the union, implying that $E$ contains the RHS. Similarly for point no. 6. So, why does Lang emphasise to take the union and compositum over all finitely generated subfields? Is there some perspective that he wishes to emphasise that I am missing? Any help in understanding this will be appreciated.","I am reading Serge Lang's Algebra , revised 3rd edition, and on page 226, the author makes the following definitions and observations: If , the compositum of and in is defined to be the smallest subfield of containing both and . It is denoted . If and , then is defined to be the smallest subfield of containing and . Observe that where the union is taken over all finite families of elements of . The compositum of an arbitrary family of subfields of a field is defined as the smallest subfield of containing all fields in the family. is finitely generated over if there is a finite family of elements of such that . Observe that is the compositum of all its finitely generated subfields over . My question is regarding the two observations (point nos. 3 and 6). It appears to me that it is enough to take union (and compositum) over all subfields generated by a single element. For example for point no. 3, I can write because is clearly contained in the RHS, and each is contained in and hence so is the union, implying that contains the RHS. Similarly for point no. 6. So, why does Lang emphasise to take the union and compositum over all finitely generated subfields? Is there some perspective that he wishes to emphasise that I am missing? Any help in understanding this will be appreciated.","E,F \subset L E F L L E F EF k \subset E \alpha_1,\dots,\alpha_n \in E k(\alpha_1,\dots,\alpha_n) E k \alpha_1,\dots,\alpha_n  E = \bigcup k(\alpha_1,\dots,\alpha_n),  \{ \alpha_1,\dots,\alpha_n \} E L L E k \{ \alpha_1,\dots,\alpha_n \} E E = k(\alpha_1,\dots,\alpha_n) E k 
E = \bigcup_{\alpha \in E} k(\alpha)
 E k(\alpha) E E",['abstract-algebra']
44,How to see $x^3-17$ has a degree 2 irreducible factor in $Q_{3}[x]$?,How to see  has a degree 2 irreducible factor in ?,x^3-17 Q_{3}[x],"Consider $Q_3$ field which is rational number $Q$ completed at $p=3$.(In other words, $Q_3$ is $3-$adic rational numbers.) Let $f=x^3-17\in Q_3[x]$. Let $O$ be the complete DVR associated to $Q_3$. Clearly $f\in O[x]$. From Gauss lemma by $O$ PID, I see that if $f=gh,g,h\in Q_3[x]$,then $g,h\in O[x]$. Therefore, I can perform $3-$reduction by considering $\frac{O}{3}[x]$. Now $\bar{f}\in Z_3[x]$ has $x^3+1=(x+1)^3\in Z_3[x]$. So I cannot apply hensel lemma here to determine factor of $f$ in $Q_3[x]$. The book says it has a degree 2 irreducible factor in $Q_3[x]$. The other version of Hensel uses $f'(x)=3x^2$. And $x=-1$ yields $3^2\vert f(-1)$ and $3^2\not\vert f'(x)$ but $2=1+1$. The absolute value requires $|f(-1)|<|f'(-1)|^2$ where $|x|$ is the $\frac{1}{3^{v_3(x)}}$ and $v_3(x)$ is $3-$adic valuation of $x\in Q_3$. Both sides yields $\frac{1}{9}$ for absolute value. So I cannot apply this hensel lifting. $\textbf{Q:}$ Can someone kindly provide hints to methods to determine reducibility for local fields? If I am lucky, I can proceed by hensel lemma but it requires factors after prime reduction being coprime. Have I done something wrong above?","Consider $Q_3$ field which is rational number $Q$ completed at $p=3$.(In other words, $Q_3$ is $3-$adic rational numbers.) Let $f=x^3-17\in Q_3[x]$. Let $O$ be the complete DVR associated to $Q_3$. Clearly $f\in O[x]$. From Gauss lemma by $O$ PID, I see that if $f=gh,g,h\in Q_3[x]$,then $g,h\in O[x]$. Therefore, I can perform $3-$reduction by considering $\frac{O}{3}[x]$. Now $\bar{f}\in Z_3[x]$ has $x^3+1=(x+1)^3\in Z_3[x]$. So I cannot apply hensel lemma here to determine factor of $f$ in $Q_3[x]$. The book says it has a degree 2 irreducible factor in $Q_3[x]$. The other version of Hensel uses $f'(x)=3x^2$. And $x=-1$ yields $3^2\vert f(-1)$ and $3^2\not\vert f'(x)$ but $2=1+1$. The absolute value requires $|f(-1)|<|f'(-1)|^2$ where $|x|$ is the $\frac{1}{3^{v_3(x)}}$ and $v_3(x)$ is $3-$adic valuation of $x\in Q_3$. Both sides yields $\frac{1}{9}$ for absolute value. So I cannot apply this hensel lifting. $\textbf{Q:}$ Can someone kindly provide hints to methods to determine reducibility for local fields? If I am lucky, I can proceed by hensel lemma but it requires factors after prime reduction being coprime. Have I done something wrong above?",,"['abstract-algebra', 'number-theory', 'p-adic-number-theory']"
45,"Is it always true, that $\lim_{n \to \infty} \frac{|A_n \cap H|}{|A_n|} = \frac{1}{[G:H]}$?","Is it always true, that ?",\lim_{n \to \infty} \frac{|A_n \cap H|}{|A_n|} = \frac{1}{[G:H]},"Suppose, $G$ is a finitely generated group. Suppose $A_1$ is a finite symmetric generating set. (That means $A_1 \subset G$, $|A_1|$ is finite, $\langle A_1 \rangle = G$, $e \in A_1$, $\forall a \in A_1 (a^{-1} \in A_1)$.) Suppose the sequence $\{A_n\}_{n=1}^{\infty}$ of subsets of $G$ is defined by recurrent relation: $\forall n \in \mathbb{N} (A_{n+1} = A_nA_1)$, where $A_nA_1$ denotes subset product. Suppose $H$ is a subgroup of $G$ of finite index. Is it always true, that $\lim_{n \to \infty} \frac{|A_n \cap H|}{|A_n|} = \frac{1}{[G:H]}$? For finite groups the answer is obvious. However, I do not know how to deal with this problem in the case, when $G$ is infinite. Any help will be appreciated.","Suppose, $G$ is a finitely generated group. Suppose $A_1$ is a finite symmetric generating set. (That means $A_1 \subset G$, $|A_1|$ is finite, $\langle A_1 \rangle = G$, $e \in A_1$, $\forall a \in A_1 (a^{-1} \in A_1)$.) Suppose the sequence $\{A_n\}_{n=1}^{\infty}$ of subsets of $G$ is defined by recurrent relation: $\forall n \in \mathbb{N} (A_{n+1} = A_nA_1)$, where $A_nA_1$ denotes subset product. Suppose $H$ is a subgroup of $G$ of finite index. Is it always true, that $\lim_{n \to \infty} \frac{|A_n \cap H|}{|A_n|} = \frac{1}{[G:H]}$? For finite groups the answer is obvious. However, I do not know how to deal with this problem in the case, when $G$ is infinite. Any help will be appreciated.",,"['abstract-algebra', 'group-theory', 'limits', 'finitely-generated', 'additive-combinatorics']"
46,Equality of Hom groups via 5 lemma,Equality of Hom groups via 5 lemma,,"Reading a paper I found the following statement: given two spectra $A, B$ since multiplication by $p$ induces the same endomorphism in $[A,B]$ we have $[A \wedge M, B]\cong [A, \Sigma^{-1}M \wedge B]$, where $M$ is the mod $p$ Moore spectrum. I think the idea is simple: since the smash with $M$ is just taking the cone of the multiplication by $p$ we have exact triangles in the stable homotopy category $A \xrightarrow{p} A \rightarrow A \wedge M$ and $\Sigma^{-1}M \wedge B \rightarrow B \xrightarrow{p} B$. Thus applying respectively the functors $[-, B]$ and $[A,-]$ we get two long exact sequences in the form $[A,B]_{*+1} \xrightarrow{p} [A,B]_{*+1} \rightarrow Z \rightarrow [A,B]_{*} \xrightarrow{p}[A,B]_{*}$ where $Z$ is $[A \wedge M, B]_* $ or $[A, \Sigma^{-1}M \wedge B]_*$, so we should deduce that these two groups are isomorphic via the 5 lemma. The point of my question is that there is no canonical map between them, so I do not know if the 5 lemma can be applied. We have two maps $[A \wedge M, \Sigma^{-1} M \wedge B] \rightarrow [A \wedge M, B]$ and $[A \wedge M, B] \rightarrow [A,B]$ but I do not understand if I can obtain a map making the diagram of long exact sequences commute. The other option I see is that  we can produce a map between the two groups via diagram chase using the fact that the other morphisms are invertible: I tried to do this but I cannot conclude the result. Since this kind of proof is immediate I suppose that this claim is false: it would be like proving that in the 5 lemma the vertical map in the middle is not needed. Thanks in advance for any help.","Reading a paper I found the following statement: given two spectra $A, B$ since multiplication by $p$ induces the same endomorphism in $[A,B]$ we have $[A \wedge M, B]\cong [A, \Sigma^{-1}M \wedge B]$, where $M$ is the mod $p$ Moore spectrum. I think the idea is simple: since the smash with $M$ is just taking the cone of the multiplication by $p$ we have exact triangles in the stable homotopy category $A \xrightarrow{p} A \rightarrow A \wedge M$ and $\Sigma^{-1}M \wedge B \rightarrow B \xrightarrow{p} B$. Thus applying respectively the functors $[-, B]$ and $[A,-]$ we get two long exact sequences in the form $[A,B]_{*+1} \xrightarrow{p} [A,B]_{*+1} \rightarrow Z \rightarrow [A,B]_{*} \xrightarrow{p}[A,B]_{*}$ where $Z$ is $[A \wedge M, B]_* $ or $[A, \Sigma^{-1}M \wedge B]_*$, so we should deduce that these two groups are isomorphic via the 5 lemma. The point of my question is that there is no canonical map between them, so I do not know if the 5 lemma can be applied. We have two maps $[A \wedge M, \Sigma^{-1} M \wedge B] \rightarrow [A \wedge M, B]$ and $[A \wedge M, B] \rightarrow [A,B]$ but I do not understand if I can obtain a map making the diagram of long exact sequences commute. The other option I see is that  we can produce a map between the two groups via diagram chase using the fact that the other morphisms are invertible: I tried to do this but I cannot conclude the result. Since this kind of proof is immediate I suppose that this claim is false: it would be like proving that in the 5 lemma the vertical map in the middle is not needed. Thanks in advance for any help.",,"['abstract-algebra', 'exact-sequence', 'stable-homotopy-theory']"
47,Interpreting a chain map as a double complex (Weibel Exercise 1.2.8),Interpreting a chain map as a double complex (Weibel Exercise 1.2.8),,"I started reading Weibel’s An introduction to homological algebra but have trouble with the following exercise: Exercise 1.2.8 (Mapping cone)   Let $f \colon B \to C$ be a morphism of chain complexes.   Form a double chain complex $D$ out of $f$ by thinking of $f$ as a chain complex in $\mathbf{Ch}$ and using the sign trick, putting $B[-1]$ in the row $q = 1$ and $C$ in the row $q = 0$.   Thinking of $C$ and $B[-1]$ as double complexes in the obvious way, show that there exists a short exact sequence of double complexes   $$                         0   \to                   C   \to                   D   \xrightarrow{\,\delta\,}  B[-1]   \to                   0 \,. $$   The total complex of $D$ is $\operatorname{cone}(f')$, the mapping cone (see section 1.5) of the map $f'$, which differs from $f$ only by some $\pm$ signs and is isomorphic to $f$. [I have added a short summary of Weibel’s indexing and sign conventions at the end of the question.] My problem is that I don’t understand how we can interpret $f$ as a double complex in such a way that the shifted complex $B[-1]$ appears. So far I have tried the following: We can think of $f$ as a commutative square with $B$ sitting in the row $q = 1$ and $C$ sitting in the row $q = 0$. We can then use the sign trick to replace $f_p \colon B_p \to C_p$ by $(-1)^p f_p$, resulting in a double complex which looks like this: $$   \require{AMScd}   \begin{CD}     B_{p-1}     @<d<<     B_{p}     @.     \hspace{2em}(q=1)     \\     @V (-1)^{p-1} f VV     @VV (-1)^p f V     @.     \\     C_{p-1}     @<d<<     C_{p}     @.     \hspace{2em}(q = 0)   \end{CD} $$ (All other rows $q \neq 0, 1$ vanish.) But then the row $q = 1$ is not $B[-1]$ but $B$. We could also use the double complex which looks like this: $$   \require{AMScd}   \begin{CD}     B_{p-1}     @< -d <<     B_{p}     @.     (q=1)     \\     @V f VV     @V f VV     @.     \\     C_{p-1}     @<d<<     C_{p}     @.     (q = 0)   \end{CD} $$ But then the row $q = 1$ is still not $B[-1]$ because we only flipped the sign of the differential, but didn’t actually shift the degrees. Also, we didn’t use the sign trick. We could forcefully put $B[-1]$ in the row $q = 1$ and $C$ in the row $q = 0$, which results in the following diagram: $$   \require{AMScd}   \begin{CD}     B_{p-2}     @< -d <<     B_{p-1}     @.     (q=1)     \\     @V ? VV     @V ? VV     @.     \\     C_{p-1}     @<d<<     C_{p}     @.     (q = 0)   \end{CD} $$ But then I don’t understand how the vertical arrow are supposed to look like, and we didn’t use the sign trick. This option also doesn’t seem to give the desired mapping cone (up to sign) as its total complex. (What may be related to my problem is that I don’t know why Weibel labels the morphism $D \to B[-1]$ as $\delta$. As far as I can tell, this notational choice has not been explained, so I may be missing some subtlety here.) Any help is appreciated. Conventions : Weibel uses for a double complex $D = D_{\bullet,\bullet}$ the following indexing convention: $$   \require{AMScd}   \begin{CD}     D_{p-1,q}     @< d^h <<     D_{p,q}     \\     @V d^v VV     @V d^v VV     \\     D_{p-1,q-1}     @< d^h <<     D_{p,q-1}   \end{CD} $$ He requires the above square to be anti-commutative, i.e. that $d^h d^v + d^v d^h = 0$. He then defines the sign trick as associating to $d^v$ the chain morphisms $f_{\bullet,q} \colon D_{\bullet,q} \to D_{\bullet,q-1}$ given by $f_{p,q} = (-1)^p d^v_{p,q}$ (i.e. we flip the sign columnwise). The shift $B[p]$ of a chain complex $B = B_{\bullet}$ is defined by $B[p]_n = B_{n+p}$ and $d^{B[p]} = (-1)^p d^B$.","I started reading Weibel’s An introduction to homological algebra but have trouble with the following exercise: Exercise 1.2.8 (Mapping cone)   Let $f \colon B \to C$ be a morphism of chain complexes.   Form a double chain complex $D$ out of $f$ by thinking of $f$ as a chain complex in $\mathbf{Ch}$ and using the sign trick, putting $B[-1]$ in the row $q = 1$ and $C$ in the row $q = 0$.   Thinking of $C$ and $B[-1]$ as double complexes in the obvious way, show that there exists a short exact sequence of double complexes   $$                         0   \to                   C   \to                   D   \xrightarrow{\,\delta\,}  B[-1]   \to                   0 \,. $$   The total complex of $D$ is $\operatorname{cone}(f')$, the mapping cone (see section 1.5) of the map $f'$, which differs from $f$ only by some $\pm$ signs and is isomorphic to $f$. [I have added a short summary of Weibel’s indexing and sign conventions at the end of the question.] My problem is that I don’t understand how we can interpret $f$ as a double complex in such a way that the shifted complex $B[-1]$ appears. So far I have tried the following: We can think of $f$ as a commutative square with $B$ sitting in the row $q = 1$ and $C$ sitting in the row $q = 0$. We can then use the sign trick to replace $f_p \colon B_p \to C_p$ by $(-1)^p f_p$, resulting in a double complex which looks like this: $$   \require{AMScd}   \begin{CD}     B_{p-1}     @<d<<     B_{p}     @.     \hspace{2em}(q=1)     \\     @V (-1)^{p-1} f VV     @VV (-1)^p f V     @.     \\     C_{p-1}     @<d<<     C_{p}     @.     \hspace{2em}(q = 0)   \end{CD} $$ (All other rows $q \neq 0, 1$ vanish.) But then the row $q = 1$ is not $B[-1]$ but $B$. We could also use the double complex which looks like this: $$   \require{AMScd}   \begin{CD}     B_{p-1}     @< -d <<     B_{p}     @.     (q=1)     \\     @V f VV     @V f VV     @.     \\     C_{p-1}     @<d<<     C_{p}     @.     (q = 0)   \end{CD} $$ But then the row $q = 1$ is still not $B[-1]$ because we only flipped the sign of the differential, but didn’t actually shift the degrees. Also, we didn’t use the sign trick. We could forcefully put $B[-1]$ in the row $q = 1$ and $C$ in the row $q = 0$, which results in the following diagram: $$   \require{AMScd}   \begin{CD}     B_{p-2}     @< -d <<     B_{p-1}     @.     (q=1)     \\     @V ? VV     @V ? VV     @.     \\     C_{p-1}     @<d<<     C_{p}     @.     (q = 0)   \end{CD} $$ But then I don’t understand how the vertical arrow are supposed to look like, and we didn’t use the sign trick. This option also doesn’t seem to give the desired mapping cone (up to sign) as its total complex. (What may be related to my problem is that I don’t know why Weibel labels the morphism $D \to B[-1]$ as $\delta$. As far as I can tell, this notational choice has not been explained, so I may be missing some subtlety here.) Any help is appreciated. Conventions : Weibel uses for a double complex $D = D_{\bullet,\bullet}$ the following indexing convention: $$   \require{AMScd}   \begin{CD}     D_{p-1,q}     @< d^h <<     D_{p,q}     \\     @V d^v VV     @V d^v VV     \\     D_{p-1,q-1}     @< d^h <<     D_{p,q-1}   \end{CD} $$ He requires the above square to be anti-commutative, i.e. that $d^h d^v + d^v d^h = 0$. He then defines the sign trick as associating to $d^v$ the chain morphisms $f_{\bullet,q} \colon D_{\bullet,q} \to D_{\bullet,q-1}$ given by $f_{p,q} = (-1)^p d^v_{p,q}$ (i.e. we flip the sign columnwise). The shift $B[p]$ of a chain complex $B = B_{\bullet}$ is defined by $B[p]_n = B_{n+p}$ and $d^{B[p]} = (-1)^p d^B$.",,"['abstract-algebra', 'homological-algebra']"
48,discriminant of $x^p-1$,discriminant of,x^p-1,"I am attempting to solve Artin 16.10.9, part (b). I have already solved (a). Let $f(x)=(x-α_1) \cdots (x-α_n)$ . (a) Prove that the discriminant of $f$ is $\pm f'(α_1) \cdots f'(α_n)$ , where $f'$ is the derivative of $f$ , and determine the sign. (b) Use the formula to compute the discriminant of the polynomial $x^p-1$ , and use it to give another proof of Theorem 16.10.12. Here is Theorem 16.10.2, which we are asked to prove. Theorem: Let $p$ be a prime different from $2$ , and let $L$ be the unique quadratic extension of $\mathbb{Q}$ contained in the cyclotomic field $\mathbb{Q}(ζ_p)$ . If $p \equiv 1$ (mod 4), then $L=\mathbb{Q}(\sqrt p)$ , and if $p \equiv 3$ (mod 4), then $L=\mathbb{Q}(\sqrt{-p})$ . My progress so far I have shown, for part (a), that the discriminant of $f$ is $(-1)^{n \choose 2}f'(α_1) \cdots f'(α_n)$ . Then, using this result, I have shown that the discriminant of $x^p-1$ is $(-1)^{p \choose 2}p^p$ . If I have made a mistake, please correct me. Now, I want to use this formula to prove Theorem 16.10.2. So let $p\neq2$ and let $L$ be the unique quadratic extension contained in $\mathbb{Q}(ζ_p)$ . Write $L=\mathbb{Q}(\sqrt k)$ . For now, assume $p \equiv 1$ (mod 4). I see that $\mathbb{Q}(ζ_p)/ \mathbb{Q}$ is a Galois extension, with its Galois group isomorphic to $C_{p-1}$ . Additionally, I see that $\mathbb{Q}(ζ_p)/\mathbb{Q}(\sqrt k)$ is a Galois extension as well. I'm not sure how to show that $L=\mathbb{Q}(\sqrt p)$ though. How do it do it? Please help!","I am attempting to solve Artin 16.10.9, part (b). I have already solved (a). Let . (a) Prove that the discriminant of is , where is the derivative of , and determine the sign. (b) Use the formula to compute the discriminant of the polynomial , and use it to give another proof of Theorem 16.10.12. Here is Theorem 16.10.2, which we are asked to prove. Theorem: Let be a prime different from , and let be the unique quadratic extension of contained in the cyclotomic field . If (mod 4), then , and if (mod 4), then . My progress so far I have shown, for part (a), that the discriminant of is . Then, using this result, I have shown that the discriminant of is . If I have made a mistake, please correct me. Now, I want to use this formula to prove Theorem 16.10.2. So let and let be the unique quadratic extension contained in . Write . For now, assume (mod 4). I see that is a Galois extension, with its Galois group isomorphic to . Additionally, I see that is a Galois extension as well. I'm not sure how to show that though. How do it do it? Please help!",f(x)=(x-α_1) \cdots (x-α_n) f \pm f'(α_1) \cdots f'(α_n) f' f x^p-1 p 2 L \mathbb{Q} \mathbb{Q}(ζ_p) p \equiv 1 L=\mathbb{Q}(\sqrt p) p \equiv 3 L=\mathbb{Q}(\sqrt{-p}) f (-1)^{n \choose 2}f'(α_1) \cdots f'(α_n) x^p-1 (-1)^{p \choose 2}p^p p\neq2 L \mathbb{Q}(ζ_p) L=\mathbb{Q}(\sqrt k) p \equiv 1 \mathbb{Q}(ζ_p)/ \mathbb{Q} C_{p-1} \mathbb{Q}(ζ_p)/\mathbb{Q}(\sqrt k) L=\mathbb{Q}(\sqrt p),"['abstract-algebra', 'polynomials', 'galois-theory', 'roots-of-unity', 'discriminant']"
49,Is $\mathbb{Z}[\sqrt{29}] $ a PID,Is  a PID,\mathbb{Z}[\sqrt{29}] ,"Question as in title. I think that unique factorization fails, perhaps via either $ (\sqrt{29} - 1)(\sqrt{29} + 1) = 2^2 \cdot 7 $ or $ (\sqrt{29} - 5)(\sqrt{29} + 5) = 2^2 $, but I have trouble proving either of these two claims. How to solve this problem?","Question as in title. I think that unique factorization fails, perhaps via either $ (\sqrt{29} - 1)(\sqrt{29} + 1) = 2^2 \cdot 7 $ or $ (\sqrt{29} - 5)(\sqrt{29} + 5) = 2^2 $, but I have trouble proving either of these two claims. How to solve this problem?",,['abstract-algebra']
50,How to find all irreducible elements in $\mathbb{Z}[\sqrt{2}]$,How to find all irreducible elements in,\mathbb{Z}[\sqrt{2}],"I am trying to find all irreducible elements in $\mathbb{Z}[\sqrt{2}]$. So, all the elements of the form $(2bd+ac)+(bc+ad)\sqrt{2}$ such that either $(a+b\sqrt{2})$ or $(c+d\sqrt{2})$ is a unit. I know all the units in this ring  ( $U(\mathbb{Z}[\sqrt{2}]) = \{(1+\sqrt{2})^n | n \in \mathbb{N}\}$). So I suppose one thing I can do is just plug in a unit I know (e.g. $(1+\sqrt{2})$ or $(3+2\sqrt{2})$ and just know that any element of the form $(4d+3c+(2c+3d)\sqrt{2})$ where $c,d$ are integers is an irreducible (as long as it is not a unit itself, and of course we would get rid of all the ones that were associates of each other). Seems quite long-winded and inefficient, though. I'm still not seeing a pattern though for how I can find all the irreducible elements. Can someone help?","I am trying to find all irreducible elements in $\mathbb{Z}[\sqrt{2}]$. So, all the elements of the form $(2bd+ac)+(bc+ad)\sqrt{2}$ such that either $(a+b\sqrt{2})$ or $(c+d\sqrt{2})$ is a unit. I know all the units in this ring  ( $U(\mathbb{Z}[\sqrt{2}]) = \{(1+\sqrt{2})^n | n \in \mathbb{N}\}$). So I suppose one thing I can do is just plug in a unit I know (e.g. $(1+\sqrt{2})$ or $(3+2\sqrt{2})$ and just know that any element of the form $(4d+3c+(2c+3d)\sqrt{2})$ where $c,d$ are integers is an irreducible (as long as it is not a unit itself, and of course we would get rid of all the ones that were associates of each other). Seems quite long-winded and inefficient, though. I'm still not seeing a pattern though for how I can find all the irreducible elements. Can someone help?",,"['abstract-algebra', 'ring-theory']"
51,The Galois group is $\mathbb{Z_{4}}$ if and only if $\frac{\alpha}{\beta}-\frac{\beta}{\alpha}\in\mathbb{Q}$,The Galois group is  if and only if,\mathbb{Z_{4}} \frac{\alpha}{\beta}-\frac{\beta}{\alpha}\in\mathbb{Q},"This question is from Lang's Algebra Chapter VI Exercise Q8 Let $f(x)=x^4+ax^2+b$ be an irreducible polynomial over $\mathbb{Q}$, with roots $\pm\alpha$, $\pm\beta$ and splitting field $K$. I have shown that the Galois Group is either $\mathbb{Z_{4}}$ or $\mathbb{Z_{2}}\times\mathbb{Z_{2}}$ or $D_{8}$ The second part of this question asks me to show the Galois group is  $\mathbb{Z_{4}}$ if and only if $\frac{\alpha}{\beta}-\frac{\beta}{\alpha}\in\mathbb{Q}$ I have also shown that if the Galois group is $\mathbb{Z_{4}}$, then $\frac{\alpha}{\beta}-\frac{\beta}{\alpha}\in\mathbb{Q}$. However, I don't know how to show the opposite. I have tried that since there are only four possibilities of $\sigma(\alpha)$ and four possiblities for $\sigma(\beta)$, by $\sigma(\frac{\alpha}{\beta}-\frac{\beta}{\alpha})=\frac{\alpha}{\beta}-\frac{\beta}{\alpha}$ we can only have following three possibilities: 1) $\sigma(\alpha)=-\alpha$, $\sigma(\beta)=-\beta$ 2) $\sigma(\alpha)=\beta$, $\sigma(\beta)=-\alpha$ 3) $\sigma(\alpha)=-\beta$, $\sigma(\beta)=\alpha$ Clearly, the second case is what we want, but I don't know how to get rid of the case 1) and case 3). There is a similar post here Galois group of a biquadratic quartic , but I don't know how to connect this post to my question. Any hints or explanations are really appreciated!! EDIT 1: By the hints from Jyrki, I have shown that the case 1) and case 3) are actually the power of case 2), case 1) is the second power, and the case 3) is the third power. Moroever, in case 2), the order of $\sigma$ is $4$ so that we have the cyclic group of order $4$ Then, I found I skipped one step here. I have not shown that the extension degree is four. I think, to show this, I have to show that $K(\alpha, \beta)=K(\alpha)$ so that since $f(x)$ is irreducible with $\alpha$ being a root, the degree is $4$. However, I have no idea how to show this right now. Any ideas? Thank you! EDIT 2: The answer from Jyrki is definitely right, the reason of this edition here is to add one more little point in the whole proof. After all the arguments, we could only say that the Galois group has a cyclic subgroup, in our case, say $<\sigma_{2}>$ of order four, but it cannot conclude that the Galois group is $<\sigma_{2}>\cong \mathbb{Z_{4}}$. The reason behind is that the automorphism $\sigma_{2}$ was picked from the Galois group, and without knowing the degree of the splitting field over $\mathbb{Q}$, we cannot conclude the size of the Galois Group. In other words, if the splitting field is of degree $8$ over $\mathbb{Q}$, we could still get $<\sigma_{2}>$, but it is the subgroup of the Galois Group $\cong D_{8}$ Thus, the degree here is important. The splitting field is $\mathbb{Q}(\alpha,\beta)$, so the degree is $4$ if and only if $\mathbb{Q}(\alpha,\beta)=\mathbb{Q}(\alpha)$, since if you think about the intermediate field $\mathbb{Q}(\alpha)$ between $\mathbb{Q}(\alpha,\beta)$ and $\mathbb{Q}$, the degree between $\mathbb{Q}(\alpha)$ and $\mathbb{Q}(\alpha,\beta)$ can only be $1$ or $2$ (cannot be $3$ as the polynomial cannot only have one rational root, cannot be $4$ as otherwise the Galois group is of order $16$, which not divides $24=|S_{4}|$, but the Galois group should be a subgroup of $S_{4}$, as $f(x)$ irreducible). Then, if the degree between $\mathbb{Q}(\alpha)$ and $\mathbb{Q}(\alpha,\beta)$ is $2$, we get the Galois group to be $D_{8}$, if it is $1$, we get it to be $\mathbb{Z_{4}}$ or $\mathbb{Z_{2}\times Z_{2}}$. In current case it is $\mathbb{Z_{4}}$, but the point is that if the degree is $1$, $\mathbb{Q}(\alpha,\beta)=\mathbb{Q}(\alpha)$ (The ""only if"" part is really similar). Therefore, to prove the degree is $4$, we need to show $\mathbb{Q}(\alpha,\beta)=\mathbb{Q}(\alpha)$. To show this, we need to show that $\alpha$ generates $\beta$. First note that, since $\pm\alpha$, $\pm\beta$ are four roots of $f(x)=x^4+ax^2+b$. We could factor $f(x)$ into $f(x)=(x-\alpha)(x+\alpha)(x-\beta)(x+\beta)$, but it will finally give us $f(x)=x^{4}-(\alpha^{2}+\beta^{2})x^{2}+\alpha^{2} \beta^{2}$. Since $f(x)\in\mathbb{Q}[x]$, $-(\alpha^{2}+\beta^{2})=-\alpha^{2}-\beta^{2}\in\mathbb{Q}$. Thus, $-\alpha^{2}-\beta^{2}=d$ for some $d\in\mathbb{Q}$. Thus, $\beta^{2}=-d-\alpha^{2}$. Then, $\frac{\alpha}{\beta}-\frac{\beta}{\alpha}=\frac{\alpha^{2}-\beta^{2}}{\alpha \beta}=\frac{2\alpha^{2}+d}{\alpha \beta}$. Since $\frac{\alpha}{\beta}-\frac{\beta}{\alpha}\in\mathbb{Q}$, then $\frac{2\alpha^{2}+d}{\alpha \beta}\in\mathbb{Q}$, and thus $\frac{2\alpha^{2}+d}{\alpha \beta}=c$ for some $c\in\mathbb{Q}$. Thus, $\frac{2\alpha^{2}+d}{c\alpha}=\beta$. Thus, $\mathbb{Q}(\alpha,\beta)=\mathbb{Q}(\alpha)$, since $f(x)$ is irreducible of order $4$ with $\alpha$ as a root over $\mathbb{Q}$, then $\mathbb{Q}(\alpha,\beta)=\mathbb{Q}(\alpha)$ is of degree $4$ over $\mathbb{Q}$. Now, we finish the whole proof.","This question is from Lang's Algebra Chapter VI Exercise Q8 Let $f(x)=x^4+ax^2+b$ be an irreducible polynomial over $\mathbb{Q}$, with roots $\pm\alpha$, $\pm\beta$ and splitting field $K$. I have shown that the Galois Group is either $\mathbb{Z_{4}}$ or $\mathbb{Z_{2}}\times\mathbb{Z_{2}}$ or $D_{8}$ The second part of this question asks me to show the Galois group is  $\mathbb{Z_{4}}$ if and only if $\frac{\alpha}{\beta}-\frac{\beta}{\alpha}\in\mathbb{Q}$ I have also shown that if the Galois group is $\mathbb{Z_{4}}$, then $\frac{\alpha}{\beta}-\frac{\beta}{\alpha}\in\mathbb{Q}$. However, I don't know how to show the opposite. I have tried that since there are only four possibilities of $\sigma(\alpha)$ and four possiblities for $\sigma(\beta)$, by $\sigma(\frac{\alpha}{\beta}-\frac{\beta}{\alpha})=\frac{\alpha}{\beta}-\frac{\beta}{\alpha}$ we can only have following three possibilities: 1) $\sigma(\alpha)=-\alpha$, $\sigma(\beta)=-\beta$ 2) $\sigma(\alpha)=\beta$, $\sigma(\beta)=-\alpha$ 3) $\sigma(\alpha)=-\beta$, $\sigma(\beta)=\alpha$ Clearly, the second case is what we want, but I don't know how to get rid of the case 1) and case 3). There is a similar post here Galois group of a biquadratic quartic , but I don't know how to connect this post to my question. Any hints or explanations are really appreciated!! EDIT 1: By the hints from Jyrki, I have shown that the case 1) and case 3) are actually the power of case 2), case 1) is the second power, and the case 3) is the third power. Moroever, in case 2), the order of $\sigma$ is $4$ so that we have the cyclic group of order $4$ Then, I found I skipped one step here. I have not shown that the extension degree is four. I think, to show this, I have to show that $K(\alpha, \beta)=K(\alpha)$ so that since $f(x)$ is irreducible with $\alpha$ being a root, the degree is $4$. However, I have no idea how to show this right now. Any ideas? Thank you! EDIT 2: The answer from Jyrki is definitely right, the reason of this edition here is to add one more little point in the whole proof. After all the arguments, we could only say that the Galois group has a cyclic subgroup, in our case, say $<\sigma_{2}>$ of order four, but it cannot conclude that the Galois group is $<\sigma_{2}>\cong \mathbb{Z_{4}}$. The reason behind is that the automorphism $\sigma_{2}$ was picked from the Galois group, and without knowing the degree of the splitting field over $\mathbb{Q}$, we cannot conclude the size of the Galois Group. In other words, if the splitting field is of degree $8$ over $\mathbb{Q}$, we could still get $<\sigma_{2}>$, but it is the subgroup of the Galois Group $\cong D_{8}$ Thus, the degree here is important. The splitting field is $\mathbb{Q}(\alpha,\beta)$, so the degree is $4$ if and only if $\mathbb{Q}(\alpha,\beta)=\mathbb{Q}(\alpha)$, since if you think about the intermediate field $\mathbb{Q}(\alpha)$ between $\mathbb{Q}(\alpha,\beta)$ and $\mathbb{Q}$, the degree between $\mathbb{Q}(\alpha)$ and $\mathbb{Q}(\alpha,\beta)$ can only be $1$ or $2$ (cannot be $3$ as the polynomial cannot only have one rational root, cannot be $4$ as otherwise the Galois group is of order $16$, which not divides $24=|S_{4}|$, but the Galois group should be a subgroup of $S_{4}$, as $f(x)$ irreducible). Then, if the degree between $\mathbb{Q}(\alpha)$ and $\mathbb{Q}(\alpha,\beta)$ is $2$, we get the Galois group to be $D_{8}$, if it is $1$, we get it to be $\mathbb{Z_{4}}$ or $\mathbb{Z_{2}\times Z_{2}}$. In current case it is $\mathbb{Z_{4}}$, but the point is that if the degree is $1$, $\mathbb{Q}(\alpha,\beta)=\mathbb{Q}(\alpha)$ (The ""only if"" part is really similar). Therefore, to prove the degree is $4$, we need to show $\mathbb{Q}(\alpha,\beta)=\mathbb{Q}(\alpha)$. To show this, we need to show that $\alpha$ generates $\beta$. First note that, since $\pm\alpha$, $\pm\beta$ are four roots of $f(x)=x^4+ax^2+b$. We could factor $f(x)$ into $f(x)=(x-\alpha)(x+\alpha)(x-\beta)(x+\beta)$, but it will finally give us $f(x)=x^{4}-(\alpha^{2}+\beta^{2})x^{2}+\alpha^{2} \beta^{2}$. Since $f(x)\in\mathbb{Q}[x]$, $-(\alpha^{2}+\beta^{2})=-\alpha^{2}-\beta^{2}\in\mathbb{Q}$. Thus, $-\alpha^{2}-\beta^{2}=d$ for some $d\in\mathbb{Q}$. Thus, $\beta^{2}=-d-\alpha^{2}$. Then, $\frac{\alpha}{\beta}-\frac{\beta}{\alpha}=\frac{\alpha^{2}-\beta^{2}}{\alpha \beta}=\frac{2\alpha^{2}+d}{\alpha \beta}$. Since $\frac{\alpha}{\beta}-\frac{\beta}{\alpha}\in\mathbb{Q}$, then $\frac{2\alpha^{2}+d}{\alpha \beta}\in\mathbb{Q}$, and thus $\frac{2\alpha^{2}+d}{\alpha \beta}=c$ for some $c\in\mathbb{Q}$. Thus, $\frac{2\alpha^{2}+d}{c\alpha}=\beta$. Thus, $\mathbb{Q}(\alpha,\beta)=\mathbb{Q}(\alpha)$, since $f(x)$ is irreducible of order $4$ with $\alpha$ as a root over $\mathbb{Q}$, then $\mathbb{Q}(\alpha,\beta)=\mathbb{Q}(\alpha)$ is of degree $4$ over $\mathbb{Q}$. Now, we finish the whole proof.",,"['abstract-algebra', 'field-theory', 'galois-theory']"
52,"Expression of unitary group , the discrete subgroups and invariants","Expression of unitary group , the discrete subgroups and invariants",,"Let $$G=U(3),$$ be the unitary group. Here we consider $G$ in terms of the fundamental representation of U(3). Namely, all of $g \in G$ can be written as a rank-3 (3 by 3) matrices. What is the convenient way to parametrize the rank-3 matrix in terms of a 9 degrees of freedom (for 9 generators)? Can we find some subgroup of Lie group,  $$k \in K \subset G= U(3) $$  such that $$  k^T \{R_1, R_2\} k =\{R_1, R_2\} . $$   This means that set $\{R_1, R_2\}$ is invariant under the transformation by $k$. Namely, both cases are allowed:   $$  k^T R_1  k =R_1,\;\;\;  k^T R_2 k =R_2 . $$   $$  k^T R_1  k =R_2,\;\;\; k^T R_1 k =R_2 . $$ Here $k^T$ is the transpose of $k$. What is the full subset (or subgroup) of $K$? Here we define:  $$ R_1 = \left( \begin{array}{ccc}  0 & 1 & 0 \\  -1 & 0 & 0 \\  0 & 0 & 0 \\ \end{array} \right),\;\;\;\; R_2 =-R_1= -\left( \begin{array}{ccc}  0 & 1 & 0 \\  -1 & 0 & 0 \\  0 & 0 & 0 \\ \end{array} \right).$$ This means that $k^T R_a k=R_b$ which may transform $a$ to a different value $b$, where $a,b \in \{1,2 \}$. But overall the full set $ \{R_1, R_2\}$ is invariant under the transformation by $k$. There must be a trivial element $k=$ the rank-3 identity matrix. But what else can it allow? In particular, I can see an SU(2) and an additional $\mathbb{Z}_2 \times \mathbb{Z}_2$ structure in $K$. How could we determine the complete $K$? Edit: More clarifications. Simplified the problem.","Let $$G=U(3),$$ be the unitary group. Here we consider $G$ in terms of the fundamental representation of U(3). Namely, all of $g \in G$ can be written as a rank-3 (3 by 3) matrices. What is the convenient way to parametrize the rank-3 matrix in terms of a 9 degrees of freedom (for 9 generators)? Can we find some subgroup of Lie group,  $$k \in K \subset G= U(3) $$  such that $$  k^T \{R_1, R_2\} k =\{R_1, R_2\} . $$   This means that set $\{R_1, R_2\}$ is invariant under the transformation by $k$. Namely, both cases are allowed:   $$  k^T R_1  k =R_1,\;\;\;  k^T R_2 k =R_2 . $$   $$  k^T R_1  k =R_2,\;\;\; k^T R_1 k =R_2 . $$ Here $k^T$ is the transpose of $k$. What is the full subset (or subgroup) of $K$? Here we define:  $$ R_1 = \left( \begin{array}{ccc}  0 & 1 & 0 \\  -1 & 0 & 0 \\  0 & 0 & 0 \\ \end{array} \right),\;\;\;\; R_2 =-R_1= -\left( \begin{array}{ccc}  0 & 1 & 0 \\  -1 & 0 & 0 \\  0 & 0 & 0 \\ \end{array} \right).$$ This means that $k^T R_a k=R_b$ which may transform $a$ to a different value $b$, where $a,b \in \{1,2 \}$. But overall the full set $ \{R_1, R_2\}$ is invariant under the transformation by $k$. There must be a trivial element $k=$ the rank-3 identity matrix. But what else can it allow? In particular, I can see an SU(2) and an additional $\mathbb{Z}_2 \times \mathbb{Z}_2$ structure in $K$. How could we determine the complete $K$? Edit: More clarifications. Simplified the problem.",,"['abstract-algebra', 'algebraic-topology', 'finite-groups', 'lie-groups', 'lie-algebras']"
53,Explicit Formula for Cabling of Braids,Explicit Formula for Cabling of Braids,,"Given the Artin braid groups on $n$ and $m$ strands $Br_n$ and $Br_m$, there are cabling operations $\circ_k:Br_n\times Br_m\to Br_{n+m-1}$ that take a braid $\beta\in Br_m$ and replace the $k$th strand of a braid in $Br_n$ with $\beta$. See the following picture for the operation $\circ_2\colon Br_4\times Br_2\to  Br_5$: Does anyone know of an explicit description of these operations in terms of generators? Writing them down in low degrees, I seem to be able to work out a rough idea of how they should operate, but it seems likely to me that someone has already figured this out?","Given the Artin braid groups on $n$ and $m$ strands $Br_n$ and $Br_m$, there are cabling operations $\circ_k:Br_n\times Br_m\to Br_{n+m-1}$ that take a braid $\beta\in Br_m$ and replace the $k$th strand of a braid in $Br_n$ with $\beta$. See the following picture for the operation $\circ_2\colon Br_4\times Br_2\to  Br_5$: Does anyone know of an explicit description of these operations in terms of generators? Writing them down in low degrees, I seem to be able to work out a rough idea of how they should operate, but it seems likely to me that someone has already figured this out?",,"['abstract-algebra', 'group-theory', 'reference-request', 'braid-groups']"
54,Number of roots of a particular polynomial in $F_{121}$,Number of roots of a particular polynomial in,F_{121},"Question: Determine the number of roots of $f(x)=x^{12}+x^8+x^4+1$ in $\mathbb{F}_{121}$. I was told that a solution to this problem could, or perhaps should, use the fact that $\mathbb{F}_{121}^\times$ is cyclic, but I don't currently see how this helps. My attempt at a solution is written below, but I don't think it's the right approach. How does the fact that $\mathbb{F}_{121}^\times$ is cyclic play a part? My thoughts: First, notice that if $g(x)=x^3+x^2+x+1=(x^2+1)(x+1)$ then $g(x^4)=f(x),$ so $\beta\in  \mathbb{F}_{121}$ is a root of $f$ if and only if $\beta^4=\alpha$ for some $\alpha\in  \mathbb{F}_{121}$ that is a root of $g$. In particular, if $\alpha$ is a root of $g$ and $\alpha\in (\mathbb{F}_{121})^{\times 4}$ then $\alpha$ will correspond to a root of $f$ (the 'fourth root' of $\alpha$ in $\mathbb{F}_{121}$). Since $y^2+1\in\mathbb{F}_{11}[y]$ is irreducible, we know that  $$ \mathbb{F}_{121}\cong \frac{\mathbb{F}_{11}[y]}{(y^2+1)}\cong \mathbb{F}_{11}(i) $$ where $i^2=-1$. With this notation, we find that $g(x)=(x+1)(x+i)(x-i)\in \mathbb{F}_{11}(i)$. So we need to check whether $-1,\pm i$ are in $(\mathbb{F}_{121}^\times)^4$. At this point, I am not so sure how to proceed beyond checking for solutions to $(a+bi)^4=c$ for $a,b\in \mathbb{F}_{11}$ and $c\in \{-1,\pm i\}$, but I think there must be a better way... As a side note, I did a computation in PARI/GP and found that $x^{12}+x^8+x^4+1$ has $4$ roots, so we know how many there should be, but I'm at a loss as to how this can be computed nicely by hand.","Question: Determine the number of roots of $f(x)=x^{12}+x^8+x^4+1$ in $\mathbb{F}_{121}$. I was told that a solution to this problem could, or perhaps should, use the fact that $\mathbb{F}_{121}^\times$ is cyclic, but I don't currently see how this helps. My attempt at a solution is written below, but I don't think it's the right approach. How does the fact that $\mathbb{F}_{121}^\times$ is cyclic play a part? My thoughts: First, notice that if $g(x)=x^3+x^2+x+1=(x^2+1)(x+1)$ then $g(x^4)=f(x),$ so $\beta\in  \mathbb{F}_{121}$ is a root of $f$ if and only if $\beta^4=\alpha$ for some $\alpha\in  \mathbb{F}_{121}$ that is a root of $g$. In particular, if $\alpha$ is a root of $g$ and $\alpha\in (\mathbb{F}_{121})^{\times 4}$ then $\alpha$ will correspond to a root of $f$ (the 'fourth root' of $\alpha$ in $\mathbb{F}_{121}$). Since $y^2+1\in\mathbb{F}_{11}[y]$ is irreducible, we know that  $$ \mathbb{F}_{121}\cong \frac{\mathbb{F}_{11}[y]}{(y^2+1)}\cong \mathbb{F}_{11}(i) $$ where $i^2=-1$. With this notation, we find that $g(x)=(x+1)(x+i)(x-i)\in \mathbb{F}_{11}(i)$. So we need to check whether $-1,\pm i$ are in $(\mathbb{F}_{121}^\times)^4$. At this point, I am not so sure how to proceed beyond checking for solutions to $(a+bi)^4=c$ for $a,b\in \mathbb{F}_{11}$ and $c\in \{-1,\pm i\}$, but I think there must be a better way... As a side note, I did a computation in PARI/GP and found that $x^{12}+x^8+x^4+1$ has $4$ roots, so we know how many there should be, but I'm at a loss as to how this can be computed nicely by hand.",,"['abstract-algebra', 'number-theory', 'field-theory', 'finite-fields', 'factoring']"
55,Connecting conjugation in the symmetric group to a more general intuition of conjugation through Cayley's theorem,Connecting conjugation in the symmetric group to a more general intuition of conjugation through Cayley's theorem,,"I would like some feedback as to whether this intuition is correct. Conjugation in the symmetric group amounts to relabeling of the domain and codomain, preserving the cycle structure. For example, Conjugating sigma by tau, $\tau\sigma\tau^{-1},$ preserves the original cycle structure (in colors) of the $(153)(24)$ permutation in $S_5,$ which essentially is $\Big(\tau(1)\tau(5)\tau(3)\Big)\Big(\tau(2)\tau(4)\Big)=(123)(45):$ or the result of composing $\tau(\sigma(\tau^{-1})):$ -i.e. a 3-cycle / 2-cycle permutation. Since it is henceforth clear that conjugacy classes of $S_5$ will correspond to permutations that share the same cycle structure, and Cayley's theorem states that every group G is isomorphic to a subgroup of the symmetric group acting on G, what can we say that conjugacy preserves in a generic fashion for any type of (finite) group?","I would like some feedback as to whether this intuition is correct. Conjugation in the symmetric group amounts to relabeling of the domain and codomain, preserving the cycle structure. For example, Conjugating sigma by tau, $\tau\sigma\tau^{-1},$ preserves the original cycle structure (in colors) of the $(153)(24)$ permutation in $S_5,$ which essentially is $\Big(\tau(1)\tau(5)\tau(3)\Big)\Big(\tau(2)\tau(4)\Big)=(123)(45):$ or the result of composing $\tau(\sigma(\tau^{-1})):$ -i.e. a 3-cycle / 2-cycle permutation. Since it is henceforth clear that conjugacy classes of $S_5$ will correspond to permutations that share the same cycle structure, and Cayley's theorem states that every group G is isomorphic to a subgroup of the symmetric group acting on G, what can we say that conjugacy preserves in a generic fashion for any type of (finite) group?",,"['abstract-algebra', 'group-theory']"
56,Why these two definitions of induced representations are equivalent?,Why these two definitions of induced representations are equivalent?,,"Let $F$, $G$ and $H$ be respectively a field, a finite group and a subgroup of $G$. Problem. For a representation $(\sigma, W)$ of $H$, define an $F$-vector space $$\widetilde W=\{f\colon G\to W\mid f(hg)=\sigma(h)f(g),h\in H,g\in G\},$$ and the action of $G$ on $\widetilde W$ is given by $(g'f)(g)=f(gg')$. Then $\widetilde W$ is isomorphic to $F[G]\otimes_{F[H]}W$ (as $G$-representations, or in other words, as $F[G]$-modules). In my algebra lecture, the induced representation of $W$ from$H$ to $G$ is defined as the $F[G]$-module $\mathrm{Ind}_H^GW:=F[G]\otimes_{F[H]}W$, and this problem says that these two definitions are equivalent. However, although tried, I have no idea how to prove it. What I think may be helpful is a proposition which is stated as follows (Here $\mathrm{Res}_H^GV$ is the restriction of $V$ to $H$) Let $V$ be a representation of $G$ and $W$ be a subrepresentation of $\mathrm{Res}_H^GV$. Then $V\cong\mathrm{Ind}_H^GW$ if and only if $V$ is generated by $W$ as an $F[G]$-module and $\dim_FV=[G:H]\dim_FW$. Yet I do not know how to identify $W$ with an $F[H]$-submodule of $\mathrm{Res}_H^G\widetilde W$, let alone how to verify other conditions in this proposition. So I would like to ask if it is correct to prove it in this way, or there is any easier or more straightforward proof? Thanks in advance...","Let $F$, $G$ and $H$ be respectively a field, a finite group and a subgroup of $G$. Problem. For a representation $(\sigma, W)$ of $H$, define an $F$-vector space $$\widetilde W=\{f\colon G\to W\mid f(hg)=\sigma(h)f(g),h\in H,g\in G\},$$ and the action of $G$ on $\widetilde W$ is given by $(g'f)(g)=f(gg')$. Then $\widetilde W$ is isomorphic to $F[G]\otimes_{F[H]}W$ (as $G$-representations, or in other words, as $F[G]$-modules). In my algebra lecture, the induced representation of $W$ from$H$ to $G$ is defined as the $F[G]$-module $\mathrm{Ind}_H^GW:=F[G]\otimes_{F[H]}W$, and this problem says that these two definitions are equivalent. However, although tried, I have no idea how to prove it. What I think may be helpful is a proposition which is stated as follows (Here $\mathrm{Res}_H^GV$ is the restriction of $V$ to $H$) Let $V$ be a representation of $G$ and $W$ be a subrepresentation of $\mathrm{Res}_H^GV$. Then $V\cong\mathrm{Ind}_H^GW$ if and only if $V$ is generated by $W$ as an $F[G]$-module and $\dim_FV=[G:H]\dim_FW$. Yet I do not know how to identify $W$ with an $F[H]$-submodule of $\mathrm{Res}_H^G\widetilde W$, let alone how to verify other conditions in this proposition. So I would like to ask if it is correct to prove it in this way, or there is any easier or more straightforward proof? Thanks in advance...",,"['abstract-algebra', 'induction', 'representation-theory']"
57,Classifying finitely generated modules over complex quotient polynomial ring,Classifying finitely generated modules over complex quotient polynomial ring,,"Please help demystify the classification of finite modules over PIDs for me. I want to decompose a finitely generated module over a PID into its elementary divisors or its invariant factors (see Dummit & Foote, Theorems 12.5 and 12.6 if you're not familiar). Here's an example from Artin: Classify finitely generated modules over the ring $\mathbb{C}[\epsilon]$ where $\epsilon^2 = 0$. How does one start this process in the above simple case? I understand much of the proofs in the text, but can't seem to work out a simple example like this one. I see the same textbook problem here: Classify finitely generated modules over the ring $\mathbb{C}[\epsilon]$ where $\epsilon^2=0$ But don't believe they've completed the step of decomposing into its elementary divisors or invariant factors. Can someone help with this particular step?","Please help demystify the classification of finite modules over PIDs for me. I want to decompose a finitely generated module over a PID into its elementary divisors or its invariant factors (see Dummit & Foote, Theorems 12.5 and 12.6 if you're not familiar). Here's an example from Artin: Classify finitely generated modules over the ring $\mathbb{C}[\epsilon]$ where $\epsilon^2 = 0$. How does one start this process in the above simple case? I understand much of the proofs in the text, but can't seem to work out a simple example like this one. I see the same textbook problem here: Classify finitely generated modules over the ring $\mathbb{C}[\epsilon]$ where $\epsilon^2=0$ But don't believe they've completed the step of decomposing into its elementary divisors or invariant factors. Can someone help with this particular step?",,"['abstract-algebra', 'modules', 'principal-ideal-domains']"
58,Prove a group of order $28$ with a normal subgroup of order $4$ is abelian without Sylow Theorems,Prove a group of order  with a normal subgroup of order  is abelian without Sylow Theorems,28 4,"I have made some headway with the proof, but I can't quite finish it off. Please could I have some help? Please note that at no point are Sylow Theorems to be used during this proof. Let $G$ be a group such that $|G| =28$. We are given $H$, such that $|H|=4$, and $H$ is a normal subgroup of $G$. Previously, I have proven that $G$ must also contain a normal subgroup, $K$, where $|K|=7$. This was done without Sylow. I noticed that $H$ must be isomorphic to $C_4$ or $C_2\times C_2$ because these are the only groups of order 4, up to isomorphism. Since I'm trying to show $G$ is abelian, I guessed that $G$ will be $C_{28}$ or $C_2 \times C_{14}$. To try and show this, I started using the Direct Product Theorem. In either case of the identity of $H$, $H \cap K = e$, because $H$ will not contain any elements of order 7, and all the elements of $K$ are order 7 apart from the identity. Also, $H$ and $K$ are normal, so their elements commute with each other: For $h \in H$ and $k \in K$, $(khk^{-1})h^{-1} \in H$ and $k(hk^{-1}h^{-1}) \in K$ means $khk^{-1}h^{-1} = e$. But I cannot work out how to show any element of $G$ is the product of elements in $H$ and $K$. Should I perhaps consider the order of elements in $G$? When $H$ is $C_4$, $G$ will be $C_{28}$ and so must contain an element of order 28. Any help is very much appreciated.","I have made some headway with the proof, but I can't quite finish it off. Please could I have some help? Please note that at no point are Sylow Theorems to be used during this proof. Let $G$ be a group such that $|G| =28$. We are given $H$, such that $|H|=4$, and $H$ is a normal subgroup of $G$. Previously, I have proven that $G$ must also contain a normal subgroup, $K$, where $|K|=7$. This was done without Sylow. I noticed that $H$ must be isomorphic to $C_4$ or $C_2\times C_2$ because these are the only groups of order 4, up to isomorphism. Since I'm trying to show $G$ is abelian, I guessed that $G$ will be $C_{28}$ or $C_2 \times C_{14}$. To try and show this, I started using the Direct Product Theorem. In either case of the identity of $H$, $H \cap K = e$, because $H$ will not contain any elements of order 7, and all the elements of $K$ are order 7 apart from the identity. Also, $H$ and $K$ are normal, so their elements commute with each other: For $h \in H$ and $k \in K$, $(khk^{-1})h^{-1} \in H$ and $k(hk^{-1}h^{-1}) \in K$ means $khk^{-1}h^{-1} = e$. But I cannot work out how to show any element of $G$ is the product of elements in $H$ and $K$. Should I perhaps consider the order of elements in $G$? When $H$ is $C_4$, $G$ will be $C_{28}$ and so must contain an element of order 28. Any help is very much appreciated.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'abelian-groups']"
59,Minimal number of generators ideal in $\mathbb{Z}[x]$,Minimal number of generators ideal in,\mathbb{Z}[x],"Let $\mathfrak{a}=(x^n,\ldots,p^{n-1}x,p^n)$ ideal in $\mathbb{Z}[x]$.   Show that the minimal number of generators of $\mathfrak{a}$ is $n+1$. My strategy to prove this is to use one of the consequences of Nakayama Lemma; that is, to show that $\bar{x^n},\ldots,\bar{p^{n-1}x},\bar{p^n}$ is basis for the $\mathbb{Z}[x]/(x,p)\mathbb{Z}[x]$-module (vector space) $\mathfrak{a}/(x,p)\mathfrak{a}$. However, I was not able to show linear independence.","Let $\mathfrak{a}=(x^n,\ldots,p^{n-1}x,p^n)$ ideal in $\mathbb{Z}[x]$.   Show that the minimal number of generators of $\mathfrak{a}$ is $n+1$. My strategy to prove this is to use one of the consequences of Nakayama Lemma; that is, to show that $\bar{x^n},\ldots,\bar{p^{n-1}x},\bar{p^n}$ is basis for the $\mathbb{Z}[x]/(x,p)\mathbb{Z}[x]$-module (vector space) $\mathfrak{a}/(x,p)\mathfrak{a}$. However, I was not able to show linear independence.",,"['abstract-algebra', 'commutative-algebra']"
60,Singular $p$-subgroups of a finite group,Singular -subgroups of a finite group,p,"Let $G$ be a finite group and $p$ be a prime. Suppose that there is a $p$-subgroup $S$ of $G$ such that there is only one Sylow $p$-subgroup containing it. Let $N$ be a normal subgroup of $G$. Is it true that there is only one Sylow $p$-subgroup of $G/N$ containing $SN/N$? I think the answer is yes, but I cannot prove it; if so, can you give me any hint to prove it? I know that the Sylow $p$-subgroup of $G/N$ are of the type $QN/N$ where $Q$ is a Sylow $p$-subgroup of $G$, but how can one use this?","Let $G$ be a finite group and $p$ be a prime. Suppose that there is a $p$-subgroup $S$ of $G$ such that there is only one Sylow $p$-subgroup containing it. Let $N$ be a normal subgroup of $G$. Is it true that there is only one Sylow $p$-subgroup of $G/N$ containing $SN/N$? I think the answer is yes, but I cannot prove it; if so, can you give me any hint to prove it? I know that the Sylow $p$-subgroup of $G/N$ are of the type $QN/N$ where $Q$ is a Sylow $p$-subgroup of $G$, but how can one use this?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory']"
61,Let $p$ be an odd prime. Prove that if $P$ is a non-cyclic $p$-group then $P$ contains a normal subgroup $U$ with $U\cong\Bbb Z_p\times\Bbb Z_p$.,Let  be an odd prime. Prove that if  is a non-cyclic -group then  contains a normal subgroup  with .,p P p P U U\cong\Bbb Z_p\times\Bbb Z_p,"Let $p$ be an odd prime. Prove that if $P$ is a non-cyclic $p$-group then $P$ contains a normal subgroup $U$ with $U\cong\Bbb Z_p\times\Bbb Z_p$. (Abstract Algebra: Dummit & Foote, Semidirect Products) The authors provide us with some hints. So I may as well incorporate them in the following attempt: We proceed with induction on $|P|$. The cases are trivial for $|P|=p$ or $p^2$. If $|P|=p^3$, $P\cong\Bbb Z_{p^2}\times\Bbb Z_p,$ or $\cong\Bbb Z_p\times\Bbb Z_p\times\Bbb Z_p$, or $\cong\Bbb Z_{p^2}\rtimes\Bbb Z_p$, or $\cong(\Bbb Z_p\times\Bbb Z_p)\rtimes\Bbb Z_p$. For an abelian group, every subgroup is normal. Both $\Bbb Z_{p^2}\times\Bbb Z_p$ and $\Bbb Z_p\times\Bbb Z_p\times\Bbb Z_p$ obviously contain such subgroup $U$. If $P\cong(\Bbb Z_p\times\Bbb Z_p)\rtimes\Bbb Z_p=\langle a,b,c$ s.t. $a^p=b^p=c^p=1,ab=ba,cac^{-1}=ab,cbc^{-1}=b\rangle$, take $U=\langle a,b\rangle$. If $P\cong\Bbb Z_{p^2}\rtimes\Bbb Z_p=\langle d,e$ s.t. $d^{p^2}=e^p=1,ede^{-1}=d^{1+p}\rangle$, take $U=\langle d^p,e\rangle$. $d^p$ and $e$ commute because $ed^pe^{-1}=(ede^{-1})^p=(d^{1+p})^p=d^{p+p^2}=d^p$. Now we really actually proceed with induction. But before that, notice that the result is true if $P$ is an abelian group: every subgroup is normal and it's non-cyclic so it contains two elementary divisors anyway. Write $P\cong\Bbb Z_{p^{\beta_1}}\times\Bbb Z_{p^{\beta_2}}\times\dots$. Find an element of order $p$ in the first factor and another in the second factor, they generate the $U$ we want. Now the inductive hypothesis: suppose the result is true for any group with order $<|P|=p^\alpha$. Let $Z\le Z(P)$ with $|Z|=p$. Then we use this: Lemma. if $P/Z$ is cyclic, then $P$ is abelian. So Assume $P/Z$ is not cyclic. $|P/Z|<|P|$. Being a quotient of a $p$-group $P$, $P/Z$ is a $p$-group. By the inductive hypothesis, $P/Z$ contains a normal subgroup $H/Z\cong\Bbb Z_p\times\Bbb Z_p$. Let $\pi:P\rightarrow P/Z$ defined by $\pi:p\mapsto pZ$ be the natural projection homomorphism of the quotient. $\pi^{-1}(H/Z)=H$, the complete preimage of $H/Z$, is of order $p^3$. Let $kerf=\{h\in H$ s.t. $h^p=1\}$ be the kernel of the following $p$-th power map. I also show some established results: Let $p$ be an odd prime. $|H|=p^3$, the $p$-th power map of $H$, $f$, is defined as $f:h\mapsto h^p$. This is a homomorphism of $H$ into $Z(H)$. If $H$ is not cyclic, $|kerf|=p^2$ or $p^3$. $H$ is not cyclic, because its quotient $H/Z$ is not cyclic. Also, $kerf\unlhd^{char}H$. This is because $kerf$ contains the identity and all the elements of $H$ that are of order $p$, and if $\sigma\in\operatorname{Aut}(H)$, $\sigma$ preserves orders of elements, so it permutes the elements of order $p$. So $\sigma(kerf)=kerf$. We have $kerf\unlhd^{char}H\unlhd P$, i.e. $kerf\unlhd P$. And $kerf\cong\Bbb Z_p\times\Bbb Z_p$ (if so, then we're done), or $\cong\Bbb Z_p\times\Bbb Z_p\times\Bbb Z_p$, or $(\Bbb Z_p\times\Bbb Z_p)\rtimes\Bbb Z_p$. What if $kerf\cong\Bbb Z_p\times\Bbb Z_p\times\Bbb Z_p$, or $(\Bbb Z_p\times\Bbb Z_p)\rtimes\Bbb Z_p$? Surely for the former one, I cannot find characteristic subgroups of order $p^2$. There has to be some other way of constructing normal subgroup... For the latter one, is $\langle a,b\rangle$ characteristic? Why if it is?","Let $p$ be an odd prime. Prove that if $P$ is a non-cyclic $p$-group then $P$ contains a normal subgroup $U$ with $U\cong\Bbb Z_p\times\Bbb Z_p$. (Abstract Algebra: Dummit & Foote, Semidirect Products) The authors provide us with some hints. So I may as well incorporate them in the following attempt: We proceed with induction on $|P|$. The cases are trivial for $|P|=p$ or $p^2$. If $|P|=p^3$, $P\cong\Bbb Z_{p^2}\times\Bbb Z_p,$ or $\cong\Bbb Z_p\times\Bbb Z_p\times\Bbb Z_p$, or $\cong\Bbb Z_{p^2}\rtimes\Bbb Z_p$, or $\cong(\Bbb Z_p\times\Bbb Z_p)\rtimes\Bbb Z_p$. For an abelian group, every subgroup is normal. Both $\Bbb Z_{p^2}\times\Bbb Z_p$ and $\Bbb Z_p\times\Bbb Z_p\times\Bbb Z_p$ obviously contain such subgroup $U$. If $P\cong(\Bbb Z_p\times\Bbb Z_p)\rtimes\Bbb Z_p=\langle a,b,c$ s.t. $a^p=b^p=c^p=1,ab=ba,cac^{-1}=ab,cbc^{-1}=b\rangle$, take $U=\langle a,b\rangle$. If $P\cong\Bbb Z_{p^2}\rtimes\Bbb Z_p=\langle d,e$ s.t. $d^{p^2}=e^p=1,ede^{-1}=d^{1+p}\rangle$, take $U=\langle d^p,e\rangle$. $d^p$ and $e$ commute because $ed^pe^{-1}=(ede^{-1})^p=(d^{1+p})^p=d^{p+p^2}=d^p$. Now we really actually proceed with induction. But before that, notice that the result is true if $P$ is an abelian group: every subgroup is normal and it's non-cyclic so it contains two elementary divisors anyway. Write $P\cong\Bbb Z_{p^{\beta_1}}\times\Bbb Z_{p^{\beta_2}}\times\dots$. Find an element of order $p$ in the first factor and another in the second factor, they generate the $U$ we want. Now the inductive hypothesis: suppose the result is true for any group with order $<|P|=p^\alpha$. Let $Z\le Z(P)$ with $|Z|=p$. Then we use this: Lemma. if $P/Z$ is cyclic, then $P$ is abelian. So Assume $P/Z$ is not cyclic. $|P/Z|<|P|$. Being a quotient of a $p$-group $P$, $P/Z$ is a $p$-group. By the inductive hypothesis, $P/Z$ contains a normal subgroup $H/Z\cong\Bbb Z_p\times\Bbb Z_p$. Let $\pi:P\rightarrow P/Z$ defined by $\pi:p\mapsto pZ$ be the natural projection homomorphism of the quotient. $\pi^{-1}(H/Z)=H$, the complete preimage of $H/Z$, is of order $p^3$. Let $kerf=\{h\in H$ s.t. $h^p=1\}$ be the kernel of the following $p$-th power map. I also show some established results: Let $p$ be an odd prime. $|H|=p^3$, the $p$-th power map of $H$, $f$, is defined as $f:h\mapsto h^p$. This is a homomorphism of $H$ into $Z(H)$. If $H$ is not cyclic, $|kerf|=p^2$ or $p^3$. $H$ is not cyclic, because its quotient $H/Z$ is not cyclic. Also, $kerf\unlhd^{char}H$. This is because $kerf$ contains the identity and all the elements of $H$ that are of order $p$, and if $\sigma\in\operatorname{Aut}(H)$, $\sigma$ preserves orders of elements, so it permutes the elements of order $p$. So $\sigma(kerf)=kerf$. We have $kerf\unlhd^{char}H\unlhd P$, i.e. $kerf\unlhd P$. And $kerf\cong\Bbb Z_p\times\Bbb Z_p$ (if so, then we're done), or $\cong\Bbb Z_p\times\Bbb Z_p\times\Bbb Z_p$, or $(\Bbb Z_p\times\Bbb Z_p)\rtimes\Bbb Z_p$. What if $kerf\cong\Bbb Z_p\times\Bbb Z_p\times\Bbb Z_p$, or $(\Bbb Z_p\times\Bbb Z_p)\rtimes\Bbb Z_p$? Surely for the former one, I cannot find characteristic subgroups of order $p^2$. There has to be some other way of constructing normal subgroup... For the latter one, is $\langle a,b\rangle$ characteristic? Why if it is?",,"['abstract-algebra', 'group-theory']"
62,Ring of Witt vectors - Exercises in Neukirch's Algebraic Number Theory,Ring of Witt vectors - Exercises in Neukirch's Algebraic Number Theory,,"The following exercise is at the end of $\S4$ - Completions in Chapter II - The Theory of Valuations of the book Algebraic Number Theory by Neukirch: Exercise 2. Let $X_0, X_1, \ldots$ be an infinite sequence of unknowns, $p$ a fixed prime number and $W_n = X_0^{p^n} + pX_1^{p^{n-1}} + \ldots + p^nX_n, n \geq 0$. Show that there exist   polynomials $S_0, S_1, \ldots ; P_0, P_1, \ldots \in \mathbb{Z}[X_0, X_1, \ldots; Y_0, Y_1, \ldots]$ such that $$W_n(S_0, S_1, \ldots) = W_n(X_0, X_1, \ldots) + W_n(Y_0, Y_1, \ldots)$$   $$W_n(P_0, P_1, \ldots) = W_n(X_0, X_1, \ldots) \cdot W_n(Y_0, Y_1, \ldots)$$ After posting this question initially, I realized my work contained a trivial mistake (I assumed incorrectly that the identity $(X + Y)^{p^k} \equiv X^{p^k} + Y^{p^k} \pmod{p^k}$ holds for $k \gt 1$). But I am unable to show the existence of these polynomials in general. The first two cases are straightforward to compute (assuming $p = 3$): $$S_0 = X_0 + Y_0$$ $$S_1 = X_1 + Y_1 - X_0^2Y_0 - X_0Y_0^2$$ In general, I have the following relation: $$S_0^{p^n} + pS_1^{p^{n-1}} + \ldots + p^nS_n = X_0^{p^n} + Y_0^{p^n} + p\left(X_1^{p^{n-1}} + Y_1^{p^{n-1}}\right) + \ldots + p^n\left(X_n + Y_n\right)$$ which implies $$S_n = X_n + Y_n - \frac{S_0^{p^n} - X_0^{p^n} - Y_0^{p^n}}{p^n} - \frac{S_1^{p^{n-1}} - X_1^{p^{n-1}} - Y_1^{p^{n-1}}}{p^{n-1}} - \ldots - \frac{S_{n-1}^p - X_{n-1}^p - Y_{n-1}^p}{p}.$$ Unfortunately I am unable to prove that the coefficients are all integers. The individual terms in the subtractions do not have integer coefficients, because I have found that the $p$-valuation $v_p\left(\binom{p^r}{k}\right) = r - v_p(k)$ for $k \neq 0$. Of course, this does not mean $S_n \not\in \mathbb{Z}[X_0, X_1, \ldots; Y_0, Y_1, \ldots]$ since different terms may contain fractions adding up to integers for a given monomial of the $X_i, Y_i$.","The following exercise is at the end of $\S4$ - Completions in Chapter II - The Theory of Valuations of the book Algebraic Number Theory by Neukirch: Exercise 2. Let $X_0, X_1, \ldots$ be an infinite sequence of unknowns, $p$ a fixed prime number and $W_n = X_0^{p^n} + pX_1^{p^{n-1}} + \ldots + p^nX_n, n \geq 0$. Show that there exist   polynomials $S_0, S_1, \ldots ; P_0, P_1, \ldots \in \mathbb{Z}[X_0, X_1, \ldots; Y_0, Y_1, \ldots]$ such that $$W_n(S_0, S_1, \ldots) = W_n(X_0, X_1, \ldots) + W_n(Y_0, Y_1, \ldots)$$   $$W_n(P_0, P_1, \ldots) = W_n(X_0, X_1, \ldots) \cdot W_n(Y_0, Y_1, \ldots)$$ After posting this question initially, I realized my work contained a trivial mistake (I assumed incorrectly that the identity $(X + Y)^{p^k} \equiv X^{p^k} + Y^{p^k} \pmod{p^k}$ holds for $k \gt 1$). But I am unable to show the existence of these polynomials in general. The first two cases are straightforward to compute (assuming $p = 3$): $$S_0 = X_0 + Y_0$$ $$S_1 = X_1 + Y_1 - X_0^2Y_0 - X_0Y_0^2$$ In general, I have the following relation: $$S_0^{p^n} + pS_1^{p^{n-1}} + \ldots + p^nS_n = X_0^{p^n} + Y_0^{p^n} + p\left(X_1^{p^{n-1}} + Y_1^{p^{n-1}}\right) + \ldots + p^n\left(X_n + Y_n\right)$$ which implies $$S_n = X_n + Y_n - \frac{S_0^{p^n} - X_0^{p^n} - Y_0^{p^n}}{p^n} - \frac{S_1^{p^{n-1}} - X_1^{p^{n-1}} - Y_1^{p^{n-1}}}{p^{n-1}} - \ldots - \frac{S_{n-1}^p - X_{n-1}^p - Y_{n-1}^p}{p}.$$ Unfortunately I am unable to prove that the coefficients are all integers. The individual terms in the subtractions do not have integer coefficients, because I have found that the $p$-valuation $v_p\left(\binom{p^r}{k}\right) = r - v_p(k)$ for $k \neq 0$. Of course, this does not mean $S_n \not\in \mathbb{Z}[X_0, X_1, \ldots; Y_0, Y_1, \ldots]$ since different terms may contain fractions adding up to integers for a given monomial of the $X_i, Y_i$.",,"['abstract-algebra', 'algebraic-number-theory', 'p-adic-number-theory']"
63,"What is the Krull dimension of $C(X)$ for $X$ infinite, compact and Hausdorff?","What is the Krull dimension of  for  infinite, compact and Hausdorff?",C(X) X,"What is the Krull dimension of the ring of continuous real-valued functions on an infinite compact Hausdorff space? If the Krull dimension is not finite, we will say that it is infinite, and not try to define it as a cardinal or an ordinal. Of course the Krull dimension of $C(X)$ depends a priori on $X$, but I'd be very happy if it could be computed even in the most particular cases.","What is the Krull dimension of the ring of continuous real-valued functions on an infinite compact Hausdorff space? If the Krull dimension is not finite, we will say that it is infinite, and not try to define it as a cardinal or an ordinal. Of course the Krull dimension of $C(X)$ depends a priori on $X$, but I'd be very happy if it could be computed even in the most particular cases.",,"['abstract-algebra', 'functional-analysis', 'commutative-algebra']"
64,Generators of $GL_2(\mathbb{Q}_p)$,Generators of,GL_2(\mathbb{Q}_p),"A well known fact is that the  group $GL_2(\mathbb{Q}_p)$ is generated by the following matrices: $1) \text{ }     w=   \left( {\begin{array}{cc}    0 & 1 \\    1 & 0 \\   \end{array} } \right) $ $2) \text{ } \mathbb{Q}_p^{\star}  \left( {\begin{array}{cc}    1 & 0 \\    0 & 1 \\   \end{array} } \right) $ $3) \text{ }   \left( {\begin{array}{cc}    \mathbb{Z}_p^{\star} & 0 \\    0 & 1 \\   \end{array} } \right) $ $4) \text{ }   \left( {\begin{array}{cc}    p & 0 \\    0 & 1 \\   \end{array} } \right) $ $5) \text{ }   \left( {\begin{array}{cc}    1 & p\mathbb{Z}_p \\    0 & 1 \\   \end{array} } \right) $ I need a reference for the above fact. In particular, for $b \in \mathbb{Q}_p$, I am trying to write lower unipotent elements $  \left( {\begin{array}{cc}    1 & 0 \\    b & 1 \\   \end{array} } \right) $ in terms of the above matrices. Any help is welcome. Thanks.","A well known fact is that the  group $GL_2(\mathbb{Q}_p)$ is generated by the following matrices: $1) \text{ }     w=   \left( {\begin{array}{cc}    0 & 1 \\    1 & 0 \\   \end{array} } \right) $ $2) \text{ } \mathbb{Q}_p^{\star}  \left( {\begin{array}{cc}    1 & 0 \\    0 & 1 \\   \end{array} } \right) $ $3) \text{ }   \left( {\begin{array}{cc}    \mathbb{Z}_p^{\star} & 0 \\    0 & 1 \\   \end{array} } \right) $ $4) \text{ }   \left( {\begin{array}{cc}    p & 0 \\    0 & 1 \\   \end{array} } \right) $ $5) \text{ }   \left( {\begin{array}{cc}    1 & p\mathbb{Z}_p \\    0 & 1 \\   \end{array} } \right) $ I need a reference for the above fact. In particular, for $b \in \mathbb{Q}_p$, I am trying to write lower unipotent elements $  \left( {\begin{array}{cc}    1 & 0 \\    b & 1 \\   \end{array} } \right) $ in terms of the above matrices. Any help is welcome. Thanks.",,"['abstract-algebra', 'number-theory', 'algebraic-number-theory', 'matrix-decomposition', 'p-adic-number-theory']"
65,"Finding all non trivial congruence relations on (N, +)","Finding all non trivial congruence relations on (N, +)",,"I want to find all congruence relations on ($\mathbb{N}, +$). Clearly, we have $\bigtriangledown_\mathbb{N} = \mathbb{N} $ x $ \mathbb{N} $ and $\bigtriangleup_\mathbb{N}  = \{(x,x)| x \in \mathbb{N}\}$. How do I determine non-trivial ones? How can I prove that these, then, are all of them?","I want to find all congruence relations on ($\mathbb{N}, +$). Clearly, we have $\bigtriangledown_\mathbb{N} = \mathbb{N} $ x $ \mathbb{N} $ and $\bigtriangleup_\mathbb{N}  = \{(x,x)| x \in \mathbb{N}\}$. How do I determine non-trivial ones? How can I prove that these, then, are all of them?",,"['abstract-algebra', 'congruence-relations']"
66,Prove that a torsion module over a PID equals direct sum of its primary components,Prove that a torsion module over a PID equals direct sum of its primary components,,"Let $R$ be a P.I.D. with $1$ and $M$ be an $R$-module that is annihilated by the nonzero, proper ideal $(a)$. Let $a=p_1^{\alpha_1}p_2^{\alpha_2}\cdots p_k^{\alpha_k}$ be the unique factorization of $a$. Let $M_i$ be the submodule of $M$ annihilated by $p_i^{\alpha_i}$. Prove that $M=M_1\oplus M_2\oplus \cdots \oplus M_k$. My attempt so far: For each $1\leq j \leq k$ define $a_j = \prod_{i\ne j}  p_i^{\alpha_i}$. Let $\sum_{i=1}^{n} (a_jr_i)\cdot m_i$ be an   arbitrary element of the submodule $(a_j)M$. We have   $p_j^{\alpha_j}\cdot (\sum_{i=1}^{n} (a_jr_i)\cdot m_i) = (p_j^{\alpha_j}a_j(r_1 +\cdots + r_n))\cdot (m_1+\cdots +m_n) =(r_1  +\cdots +r_n)\cdot (a \cdot (m_1+\cdots +m_n)) =0$. So $\sum_{i=1}^{n} (a_jr_i)\cdot m_i \in M_j$, so that $(a_j)M\subset  M_j$. Next, let $m\in M_j$. Since $R$ is a P.I.D., we know $1= a_jx +  p_j^{\alpha_j}y$ for some $x, y \in R$. So $m= 1\cdot m = (a_jx +  p_j^{\alpha_j}y)\cdot m = xa_j \cdot m + yp_j^{\alpha_j} \cdot m =   xa_j \cdot m +0 \in (a_j)M$. Conclude that $(a_j)M = M_j$. Next, suppose $m\in (a_j)M\cap \sum_{t\ne j} (a_t)M$. We have $1\cdot m = xa_j \cdot m + yp_j^{\alpha_j} \cdot m= xa_j\cdot m  + 0$. But note that $xa_j\cdot ((\sum_{t\ne j}a_t)\cdot m) = wa\cdot m$ for some $w\in R$, so that $xa_j\cdot ((\sum_{t\ne j}a_t)\cdot m) = 0$. It follows that $xa_j = 0$, and $m=0+0=0$. Conclude that $ (a_j)M\cap \sum_{t\ne j} (a_t)M = (0)$. Thus, $\sum_{i=1}^{k} (a_i)M$ is a direct sum. At this point, I'm not sure how to actually show this direct sum is   equal to $M$. The only thing I tried is applying the Chinese Remainder   Theorem as follows, but it doesn't seem to work. We have that $(a)M=(0)$. And since $R$ is a PID, we know that since   $(p_i^{\alpha_i}, p_j^{\alpha_j})= (1) = R$ for any $i\ne j$,   $(p_i^{\alpha_i})$ and $(p_j^{\alpha_j})$ are comaximal ideals. So apply the Chinese Remainder Theorem to get $M\cong  M/(p_1^{\alpha_1})M \times \cdots \times M/(p_k^{\alpha_k})M$. I'd appreciate some help on finishing this.","Let $R$ be a P.I.D. with $1$ and $M$ be an $R$-module that is annihilated by the nonzero, proper ideal $(a)$. Let $a=p_1^{\alpha_1}p_2^{\alpha_2}\cdots p_k^{\alpha_k}$ be the unique factorization of $a$. Let $M_i$ be the submodule of $M$ annihilated by $p_i^{\alpha_i}$. Prove that $M=M_1\oplus M_2\oplus \cdots \oplus M_k$. My attempt so far: For each $1\leq j \leq k$ define $a_j = \prod_{i\ne j}  p_i^{\alpha_i}$. Let $\sum_{i=1}^{n} (a_jr_i)\cdot m_i$ be an   arbitrary element of the submodule $(a_j)M$. We have   $p_j^{\alpha_j}\cdot (\sum_{i=1}^{n} (a_jr_i)\cdot m_i) = (p_j^{\alpha_j}a_j(r_1 +\cdots + r_n))\cdot (m_1+\cdots +m_n) =(r_1  +\cdots +r_n)\cdot (a \cdot (m_1+\cdots +m_n)) =0$. So $\sum_{i=1}^{n} (a_jr_i)\cdot m_i \in M_j$, so that $(a_j)M\subset  M_j$. Next, let $m\in M_j$. Since $R$ is a P.I.D., we know $1= a_jx +  p_j^{\alpha_j}y$ for some $x, y \in R$. So $m= 1\cdot m = (a_jx +  p_j^{\alpha_j}y)\cdot m = xa_j \cdot m + yp_j^{\alpha_j} \cdot m =   xa_j \cdot m +0 \in (a_j)M$. Conclude that $(a_j)M = M_j$. Next, suppose $m\in (a_j)M\cap \sum_{t\ne j} (a_t)M$. We have $1\cdot m = xa_j \cdot m + yp_j^{\alpha_j} \cdot m= xa_j\cdot m  + 0$. But note that $xa_j\cdot ((\sum_{t\ne j}a_t)\cdot m) = wa\cdot m$ for some $w\in R$, so that $xa_j\cdot ((\sum_{t\ne j}a_t)\cdot m) = 0$. It follows that $xa_j = 0$, and $m=0+0=0$. Conclude that $ (a_j)M\cap \sum_{t\ne j} (a_t)M = (0)$. Thus, $\sum_{i=1}^{k} (a_i)M$ is a direct sum. At this point, I'm not sure how to actually show this direct sum is   equal to $M$. The only thing I tried is applying the Chinese Remainder   Theorem as follows, but it doesn't seem to work. We have that $(a)M=(0)$. And since $R$ is a PID, we know that since   $(p_i^{\alpha_i}, p_j^{\alpha_j})= (1) = R$ for any $i\ne j$,   $(p_i^{\alpha_i})$ and $(p_j^{\alpha_j})$ are comaximal ideals. So apply the Chinese Remainder Theorem to get $M\cong  M/(p_1^{\alpha_1})M \times \cdots \times M/(p_k^{\alpha_k})M$. I'd appreciate some help on finishing this.",,"['abstract-algebra', 'ring-theory', 'modules']"
67,Is $(11)$ a prime ideal of $\mathbb{Z}[\sqrt{-5}]$?,Is  a prime ideal of ?,(11) \mathbb{Z}[\sqrt{-5}],"Is $(11)$ a prime ideal of $\mathbb{Z}[\sqrt{-5}]$? I know that $11$ is an irreducible element in $\mathbb{Z}[\sqrt{-5}]$. Now to determine whether it is prime we can say $\mathbb{Z}[\sqrt{-5}]$ isomorphic to $\mathbb{Z}[x]/(x^2 + 5)$. So we get an isomorphism $$  \mathbb{Z}[\sqrt{-5}]/(11) \;\;\simeq\;\; \mathbb{Z}_{11}[x]/(x^2 + 5) \,.$$ Since $\mathbb{Z}_{11}$ is a field, $\mathbb{Z}_{11}[x]$ is a PID, and since $(x^2 + 5)$ is irreducible over $\mathbb{Z}_{11}[x]$, the ring $\mathbb{Z}_{11}[x]/(x^2 + 5)$ is a field. Hence $(11)$ can be treated as a maximal ideal as well as a prime ideal in the ring $\mathbb{Z}[\sqrt{-5}]$.","Is $(11)$ a prime ideal of $\mathbb{Z}[\sqrt{-5}]$? I know that $11$ is an irreducible element in $\mathbb{Z}[\sqrt{-5}]$. Now to determine whether it is prime we can say $\mathbb{Z}[\sqrt{-5}]$ isomorphic to $\mathbb{Z}[x]/(x^2 + 5)$. So we get an isomorphism $$  \mathbb{Z}[\sqrt{-5}]/(11) \;\;\simeq\;\; \mathbb{Z}_{11}[x]/(x^2 + 5) \,.$$ Since $\mathbb{Z}_{11}$ is a field, $\mathbb{Z}_{11}[x]$ is a PID, and since $(x^2 + 5)$ is irreducible over $\mathbb{Z}_{11}[x]$, the ring $\mathbb{Z}_{11}[x]/(x^2 + 5)$ is a field. Hence $(11)$ can be treated as a maximal ideal as well as a prime ideal in the ring $\mathbb{Z}[\sqrt{-5}]$.",,"['abstract-algebra', 'ring-theory', 'field-theory']"
68,Concrete Applications of Lattices to Algebra,Concrete Applications of Lattices to Algebra,,"The importance of lattices to algebra (or any field of mathematics really) should be fairly obvious. Specifically, we always have a complete lattice of subobjects (and a lattice of strong subobjects etc.) and a complete lattice of congruences. However, even though I like to claim this all the time I don't actually good way to illustrate the usefulness of this theory. What are some concrete application of lattices to algebra? This could be anything ranging from an alternate (better) proof of a classical theorem, to help in computing the subgroups of a finite group (if this is ever a thing, I'm only speculating here) or anything else, that you can hopefully motivate for a ""classical"" algebraist.","The importance of lattices to algebra (or any field of mathematics really) should be fairly obvious. Specifically, we always have a complete lattice of subobjects (and a lattice of strong subobjects etc.) and a complete lattice of congruences. However, even though I like to claim this all the time I don't actually good way to illustrate the usefulness of this theory. What are some concrete application of lattices to algebra? This could be anything ranging from an alternate (better) proof of a classical theorem, to help in computing the subgroups of a finite group (if this is ever a thing, I'm only speculating here) or anything else, that you can hopefully motivate for a ""classical"" algebraist.",,"['abstract-algebra', 'examples-counterexamples', 'applications', 'lattice-orders']"
69,Problem 4.4 in Isaacs (Algebra a graduate course),Problem 4.4 in Isaacs (Algebra a graduate course),,"I'm trying to prove this (problem 4.4 in Isaac's book) Le $\varphi:G\rightarrow H$ be a surjective homomorphism with $|G|$ finite and let $g \in G$. Show that \begin{equation}|C_{G}(g)|\geq|C_{H}(\varphi(g))|\end{equation} HINT: Show that the conjugacy class of $g$ in the inverse image in $G$ of $C_{H}(\varphi(g))$ has size $\leq|ker(\varphi)|$. I'm trying to interpret the hint but I'm stuck in it.  First, I think that it suggest to restrict the conjugacy class of $g$ (i.e., $\mathcal{O}_g$) to $C_{H}(\varphi(g))$, i.e., \begin{equation}\mathcal{O}^{restricted}_{g} = \{x^{-1}gx\,|\,x\in C_{H}(\varphi(g))\}\end{equation} Second, I think that it maybe suggest that I have to take the intersection between the conjugacy class of  $g$ and $C_{H}(\varphi(g))$, i.e., \begin{equation}\mathcal{O}_g\cap C_{H}(\varphi(g))\end{equation} Either way, I'm stuck. I just want help to interpret the hint. Thank you all.","I'm trying to prove this (problem 4.4 in Isaac's book) Le $\varphi:G\rightarrow H$ be a surjective homomorphism with $|G|$ finite and let $g \in G$. Show that \begin{equation}|C_{G}(g)|\geq|C_{H}(\varphi(g))|\end{equation} HINT: Show that the conjugacy class of $g$ in the inverse image in $G$ of $C_{H}(\varphi(g))$ has size $\leq|ker(\varphi)|$. I'm trying to interpret the hint but I'm stuck in it.  First, I think that it suggest to restrict the conjugacy class of $g$ (i.e., $\mathcal{O}_g$) to $C_{H}(\varphi(g))$, i.e., \begin{equation}\mathcal{O}^{restricted}_{g} = \{x^{-1}gx\,|\,x\in C_{H}(\varphi(g))\}\end{equation} Second, I think that it maybe suggest that I have to take the intersection between the conjugacy class of  $g$ and $C_{H}(\varphi(g))$, i.e., \begin{equation}\mathcal{O}_g\cap C_{H}(\varphi(g))\end{equation} Either way, I'm stuck. I just want help to interpret the hint. Thank you all.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
70,When irreducible elements of a UFD remain irreducible in a ring extension,When irreducible elements of a UFD remain irreducible in a ring extension,,"Let $U$ be a Noetherian UFD and let $D$ be a Noetherian integral domain (not known to be a UFD) such that $U \subseteq D$ . Further assume that $U$ and $D$ have the same finite Krull dimension. Of course, generally, an irreducible (=prime) element of $U$ may become reducible in $D$ . What can be said about such pairs of domains with the additional property that every irreducible element of $U$ remains irreducible in $D$ ? An example: $U=\mathbb{C}[x^2]$ , $D=\mathbb{C}[x^2][x^3]$ ; if I am not wrong, every irreducible element of $\mathbb{C}[x^2]$ remains irreducible in $D=\mathbb{C}[x^2][x^3]$ (though not prime). Edit: If my above question is too general, then I wish to ask the following question: Given an irreducible element $u \in U$ , can one find a ""nice"" criterion which guarantees that $u$ remains irreducible in $D$ ? New edit: Another question: If we further assume that $U \subseteq D$ is etale, then is it true that every irreducible element of $U$ remains irrdducible in $D$ ? or   is it true that every prime element of $U$ remains prime in $D$ ? Please see this recent question. Thank you very much!","Let be a Noetherian UFD and let be a Noetherian integral domain (not known to be a UFD) such that . Further assume that and have the same finite Krull dimension. Of course, generally, an irreducible (=prime) element of may become reducible in . What can be said about such pairs of domains with the additional property that every irreducible element of remains irreducible in ? An example: , ; if I am not wrong, every irreducible element of remains irreducible in (though not prime). Edit: If my above question is too general, then I wish to ask the following question: Given an irreducible element , can one find a ""nice"" criterion which guarantees that remains irreducible in ? New edit: Another question: If we further assume that is etale, then is it true that every irreducible element of remains irrdducible in ? or   is it true that every prime element of remains prime in ? Please see this recent question. Thank you very much!",U D U \subseteq D U D U D U D U=\mathbb{C}[x^2] D=\mathbb{C}[x^2][x^3] \mathbb{C}[x^2] D=\mathbb{C}[x^2][x^3] u \in U u D U \subseteq D U D U D,"['abstract-algebra', 'algebraic-geometry', 'ring-theory', 'commutative-algebra', 'unique-factorization-domains']"
71,"Describing ring properties in terms of infinitary sentences (Hodges, Model Theory, 2.2-9)","Describing ring properties in terms of infinitary sentences (Hodges, Model Theory, 2.2-9)",,"I'm self-studying Model Theory via Hodges' book Model Theory and got stuck in the following problem (see below for notation): Section 2.2, Problem 9 : For each of the following classes, show that it can be defined by a single sentence of $L_{\omega_1\omega}$. (a) Unique factorization domains. (b) Principal ideal domains. (c) Dedekind domains. (d) Semisimple rings. (e) Left coherent rings. (f) Left artinian rings. (g) Noetherian local commutative rings. (h) Groups $G$ such that if $H,K$ are any two isomorphic finitely generated subgroups of $G$ then $H$ is congruent to $K$ in $G$. The problem reduces to restate the properties in each item in a suitable manner, without dealing directly with ideals and subgroups but rather only with elements of the ring in question (finitely many of them at a time). See below for more details. My problem is: Problem: I don't know how to solve items (b), (c), (d), (f), and (g), because I don't know how to write conditions on ideals (and chains of these) in the given language. Some notation: The signature $L$ for rings is $\langle 0,1,+,-,\cdot\rangle$. Given an ordinal $\kappa$, we define the language $L_{\kappa\omega}$ in the usual manner, but we allow disjunctions and conjunction on sets of cardinality $<\kappa$, i.e., if $I$ is a set of formulas of $L_{\kappa\omega}$ with $|I|<\kappa$, then $\bigvee_{\phi\in I}\phi$ and $\bigwedge_{\phi\in I}\phi$ are formulas of $L_{\kappa\omega}$ (but we can only put quantifiers over finitely many variables: that's what the $\omega$ in $L_{\kappa\omega}$ means). For example, here's how we can do (h) (I believe the author meant ""conjugate"" instead of ""congruent""): We use variables $x_i,y_i,z_i,\ldots$. Moreover, if the variables $x_1,\ldots,x_k$ are bound, we write $\overline{x}=x_1\ldots x_k$. Given variables $x,y_1,\ldots,y_k$, let's write: $$x\in\langle \overline{y}\rangle:\bigvee_{n<\omega}\exists z_1\ldots z_n\left[\left[\bigwedge_{1\leq i\leq n}\bigvee_{1\leq j\leq k}(z_i=y_j)\lor (z_i=y_j^{-1})\right)\land x=z_1\cdots z_n\right]$$ which can be read, in the language of groups, as ""$x$ belongs to the subgroup generated by the $y_i$"". We can also write a formula for two finitely generated subgroups to be isomorphic: Consider variables $p_1,p_2,\ldots$, and all terms $t(\overline{p})$ in the language of groups which have only these variables. There are only countably many of these terms. Say we have variables $x_1\ldots x_k$ and $z_1\ldots z_k$. We write $$\langle\overline{x}\rangle\simeq\langle\overline{z}\rangle:\bigwedge_{t(\overline{p})}(t(\overline{x})=1\leftrightarrow t(\overline{z})=1),$$ where $t(\overline{x})$ means that we change each occurence of the variable $p_i$ by $x_{i\bmod k}$, and similarly for $t(\overline{z})$. The formula above states that the maps $x_i\mapsto z_i$ extends to an isomorphism of the generated subgroups. Finally, the condition in the exercise can be expressed by $$\bigwedge_{n<\omega}\forall x_1\ldots x_n,z_1\ldots,z_n\left[\langle\overline{x}\rangle\simeq\langle\overline{z}\rangle\rightarrow\exists g\left(\bigwedge_{1\leq i\leq k}gx_ig^{-1}\in\langle\overline{z}\rangle\land g^{-1}z_ig\in\langle\overline{x}\rangle\right)\right]$$ and the conjunction of this sentence with the usual group axioms is a formula in $L_{\omega_1\omega}$ which works. EDIT: Here are a few solutions for some of the items. Item (b): A ring is a PID iff every finitely generated ideal is principal, or equivalently iff every $2$-generated ideal is principal (Bézout domain), and it is a UFD (item (a)). All of these can be written in $L_{\omega_1\omega}$. Item (d): first recall given a ring $R$, the ideal generated by some $x\in R$ is $(x)=\left\{ax+xb+cxd:a,b,c,d\in R\right\}$, and $R$ is simple iff it is the ideal generated by any nonzero element. Thus a semisimple ring is one for which there are $n$ and $x_1,\ldots,x_n$, with $(x_i)\cap (x_j)=0$ if $i\neq j$, and for which $(x_i)=(x)$ for any $x\in (x_i)$. These can all be written in $L_{\omega_1\omega}$. Item (e): A ring $R$ is left coherent iff every finitely generated ideal is finitely presented. We can restate this as follows: For every $n$ and for every $a_1,\ldots,a_n$, there exist $m$ and terms $t_1(\overline{x}^1,\overline{p}),\ldots,t_m(\overline{x}^m,\overline{p})$, of the form $t_i(\overline{x}^i,\overline{p})=x^i_1p_1+\cdots+x^i_np_n$ (where $x^i_j$ and $p_j$ are variables) in the language of rings, and there exist $r^i_j\in R$, $1\leq i\leq m$, $1\leq j\leq n$, for which $t_i(\overline{r}^i,\overline{a})=0$ for all $i$, and such that for every $s_1,\ldots,s_n$, if $s_1a_1+\cdots+s_na_n=0$ then there are $q_1,\ldots,q_m$ such that for each $i$ $s_i=\sum_jq_jr_i^j$. This means that the relations $t_i(\overline{r},\overline{p})=0$, which make sense for left $R$-modules, are satisfies by the generators $a_i$, the map from the free module generated by $p_1,\ldots,p_n$, mapping $p_i\mapsto a_i$, has precisely the module generated by $t_i(\overline{r},\overline{p})$ as its kernel.","I'm self-studying Model Theory via Hodges' book Model Theory and got stuck in the following problem (see below for notation): Section 2.2, Problem 9 : For each of the following classes, show that it can be defined by a single sentence of $L_{\omega_1\omega}$. (a) Unique factorization domains. (b) Principal ideal domains. (c) Dedekind domains. (d) Semisimple rings. (e) Left coherent rings. (f) Left artinian rings. (g) Noetherian local commutative rings. (h) Groups $G$ such that if $H,K$ are any two isomorphic finitely generated subgroups of $G$ then $H$ is congruent to $K$ in $G$. The problem reduces to restate the properties in each item in a suitable manner, without dealing directly with ideals and subgroups but rather only with elements of the ring in question (finitely many of them at a time). See below for more details. My problem is: Problem: I don't know how to solve items (b), (c), (d), (f), and (g), because I don't know how to write conditions on ideals (and chains of these) in the given language. Some notation: The signature $L$ for rings is $\langle 0,1,+,-,\cdot\rangle$. Given an ordinal $\kappa$, we define the language $L_{\kappa\omega}$ in the usual manner, but we allow disjunctions and conjunction on sets of cardinality $<\kappa$, i.e., if $I$ is a set of formulas of $L_{\kappa\omega}$ with $|I|<\kappa$, then $\bigvee_{\phi\in I}\phi$ and $\bigwedge_{\phi\in I}\phi$ are formulas of $L_{\kappa\omega}$ (but we can only put quantifiers over finitely many variables: that's what the $\omega$ in $L_{\kappa\omega}$ means). For example, here's how we can do (h) (I believe the author meant ""conjugate"" instead of ""congruent""): We use variables $x_i,y_i,z_i,\ldots$. Moreover, if the variables $x_1,\ldots,x_k$ are bound, we write $\overline{x}=x_1\ldots x_k$. Given variables $x,y_1,\ldots,y_k$, let's write: $$x\in\langle \overline{y}\rangle:\bigvee_{n<\omega}\exists z_1\ldots z_n\left[\left[\bigwedge_{1\leq i\leq n}\bigvee_{1\leq j\leq k}(z_i=y_j)\lor (z_i=y_j^{-1})\right)\land x=z_1\cdots z_n\right]$$ which can be read, in the language of groups, as ""$x$ belongs to the subgroup generated by the $y_i$"". We can also write a formula for two finitely generated subgroups to be isomorphic: Consider variables $p_1,p_2,\ldots$, and all terms $t(\overline{p})$ in the language of groups which have only these variables. There are only countably many of these terms. Say we have variables $x_1\ldots x_k$ and $z_1\ldots z_k$. We write $$\langle\overline{x}\rangle\simeq\langle\overline{z}\rangle:\bigwedge_{t(\overline{p})}(t(\overline{x})=1\leftrightarrow t(\overline{z})=1),$$ where $t(\overline{x})$ means that we change each occurence of the variable $p_i$ by $x_{i\bmod k}$, and similarly for $t(\overline{z})$. The formula above states that the maps $x_i\mapsto z_i$ extends to an isomorphism of the generated subgroups. Finally, the condition in the exercise can be expressed by $$\bigwedge_{n<\omega}\forall x_1\ldots x_n,z_1\ldots,z_n\left[\langle\overline{x}\rangle\simeq\langle\overline{z}\rangle\rightarrow\exists g\left(\bigwedge_{1\leq i\leq k}gx_ig^{-1}\in\langle\overline{z}\rangle\land g^{-1}z_ig\in\langle\overline{x}\rangle\right)\right]$$ and the conjunction of this sentence with the usual group axioms is a formula in $L_{\omega_1\omega}$ which works. EDIT: Here are a few solutions for some of the items. Item (b): A ring is a PID iff every finitely generated ideal is principal, or equivalently iff every $2$-generated ideal is principal (Bézout domain), and it is a UFD (item (a)). All of these can be written in $L_{\omega_1\omega}$. Item (d): first recall given a ring $R$, the ideal generated by some $x\in R$ is $(x)=\left\{ax+xb+cxd:a,b,c,d\in R\right\}$, and $R$ is simple iff it is the ideal generated by any nonzero element. Thus a semisimple ring is one for which there are $n$ and $x_1,\ldots,x_n$, with $(x_i)\cap (x_j)=0$ if $i\neq j$, and for which $(x_i)=(x)$ for any $x\in (x_i)$. These can all be written in $L_{\omega_1\omega}$. Item (e): A ring $R$ is left coherent iff every finitely generated ideal is finitely presented. We can restate this as follows: For every $n$ and for every $a_1,\ldots,a_n$, there exist $m$ and terms $t_1(\overline{x}^1,\overline{p}),\ldots,t_m(\overline{x}^m,\overline{p})$, of the form $t_i(\overline{x}^i,\overline{p})=x^i_1p_1+\cdots+x^i_np_n$ (where $x^i_j$ and $p_j$ are variables) in the language of rings, and there exist $r^i_j\in R$, $1\leq i\leq m$, $1\leq j\leq n$, for which $t_i(\overline{r}^i,\overline{a})=0$ for all $i$, and such that for every $s_1,\ldots,s_n$, if $s_1a_1+\cdots+s_na_n=0$ then there are $q_1,\ldots,q_m$ such that for each $i$ $s_i=\sum_jq_jr_i^j$. This means that the relations $t_i(\overline{r},\overline{p})=0$, which make sense for left $R$-modules, are satisfies by the generators $a_i$, the map from the free module generated by $p_1,\ldots,p_n$, mapping $p_i\mapsto a_i$, has precisely the module generated by $t_i(\overline{r},\overline{p})$ as its kernel.",,['abstract-algebra']
72,$Q$ is an injective module iff injections from $Q$ always split,is an injective module iff injections from  always split,Q Q,"Clarification of terminology: We say an injection $A \xrightarrow{i} B$ splits iff the induced short exact sequence $0 \to A \xrightarrow{i} B \to B/i(A) \to 0$ splits. Similarly, we say a surjection $B \xrightarrow{p} C$ splits iff $0 \to \ker p \to B \xrightarrow{p} C \to 0$ splits. Here are the definitions of injective and projective modules I'm using: $Q$ is injective if, and only if, $\operatorname{Hom}(\ast, Q)$ takes injections to surjections ($0 \to A \to B$ exact implies $\operatorname{Hom}(B,Q) \to \operatorname{Hom}(A,Q) \to 0$ exact). $P$ is projective if and only if $\operatorname{Hom}(P, \ast)$ takes surjections to surjections. Want to show: $Q$ is injective if and only if injections from $Q$ always split. The $\Longrightarrow$ direction is straightforward. The $\Longleftarrow$ direction, not so much. (Dummit and Foote relegates this to the exercises and uses the nontrivial fact that every module is contained in an injective module. I imagine this is to parallel their proof that $P$ is projective iff surjections to $P$ always split, which uses the fact that every module is a quotient of a free, hence projective, module.) It bothered me that these dual concepts don't have ""dual"" proofs, so I came up with one using pushouts and pullbacks (D&F introduce these in exercise 27, if you have the book). The argument is rather straightforward, so I feel like something has to be wrong, but I can't figure out what it is. Here it is: Suppose injections from $Q$ always split, suppose $i: A \to B$ injects, and suppose $f \in \operatorname{Hom}(A,Q)$. Consider the pushout of $i$ and $f$: $$M = B \oplus Q/\{(i(a), -f(a)): a \in A\}.$$ Then we get the following maps ""for free"": $j: B \to M$ and $g: Q \to M$, with $ji = gf$. (At this point, we haven't used any of our hypotheses.) Now, it's straightforward to check that $g$ injects because $i$ does, hence $g$ splits and we get a map $h: M \to Q$ with $hg = 1$. Thus, $hj$ lifts $f$. Verification that $g$ injects because $i$ does: If $g(q) = 0$, then $(0,q) = (i(a), -f(a))$ for some $a$. But $i(a) = 0$ implies that $ a = 0$, and this in turn implies that $-f(a) = 0$, so that $q = 0$. (A completely analogous proof using the pullback shows that: projections to $P$ always split $\implies P$ is projective.) Where is the flaw in this proof?","Clarification of terminology: We say an injection $A \xrightarrow{i} B$ splits iff the induced short exact sequence $0 \to A \xrightarrow{i} B \to B/i(A) \to 0$ splits. Similarly, we say a surjection $B \xrightarrow{p} C$ splits iff $0 \to \ker p \to B \xrightarrow{p} C \to 0$ splits. Here are the definitions of injective and projective modules I'm using: $Q$ is injective if, and only if, $\operatorname{Hom}(\ast, Q)$ takes injections to surjections ($0 \to A \to B$ exact implies $\operatorname{Hom}(B,Q) \to \operatorname{Hom}(A,Q) \to 0$ exact). $P$ is projective if and only if $\operatorname{Hom}(P, \ast)$ takes surjections to surjections. Want to show: $Q$ is injective if and only if injections from $Q$ always split. The $\Longrightarrow$ direction is straightforward. The $\Longleftarrow$ direction, not so much. (Dummit and Foote relegates this to the exercises and uses the nontrivial fact that every module is contained in an injective module. I imagine this is to parallel their proof that $P$ is projective iff surjections to $P$ always split, which uses the fact that every module is a quotient of a free, hence projective, module.) It bothered me that these dual concepts don't have ""dual"" proofs, so I came up with one using pushouts and pullbacks (D&F introduce these in exercise 27, if you have the book). The argument is rather straightforward, so I feel like something has to be wrong, but I can't figure out what it is. Here it is: Suppose injections from $Q$ always split, suppose $i: A \to B$ injects, and suppose $f \in \operatorname{Hom}(A,Q)$. Consider the pushout of $i$ and $f$: $$M = B \oplus Q/\{(i(a), -f(a)): a \in A\}.$$ Then we get the following maps ""for free"": $j: B \to M$ and $g: Q \to M$, with $ji = gf$. (At this point, we haven't used any of our hypotheses.) Now, it's straightforward to check that $g$ injects because $i$ does, hence $g$ splits and we get a map $h: M \to Q$ with $hg = 1$. Thus, $hj$ lifts $f$. Verification that $g$ injects because $i$ does: If $g(q) = 0$, then $(0,q) = (i(a), -f(a))$ for some $a$. But $i(a) = 0$ implies that $ a = 0$, and this in turn implies that $-f(a) = 0$, so that $q = 0$. (A completely analogous proof using the pullback shows that: projections to $P$ always split $\implies P$ is projective.) Where is the flaw in this proof?",,"['abstract-algebra', 'proof-verification', 'homological-algebra', 'projective-module', 'injective-module']"
73,Equality of two definitions of the Drinfeld Double,Equality of two definitions of the Drinfeld Double,,"While studying the Drinfeld Double of a Hopf algebra, I came across two different definitions used for the multipliaction. For a finite dimensional Hopf algebra $H$ (over a field $K$) we define $D(H)=H^{*cop}\otimes H$ (the Drinfeld double of H) as a Hopf algebra with the following structure:     \begin{align*} 	&(\varphi \otimes g)(\psi \otimes h)= \psi_{(1)}(S^{-1}(g_{(3)}))\psi_{(3)}(g_{(1)})\varphi\psi_{(2)}\otimes g_{(2)}h		&& 1_{D(H)}=\varepsilon\otimes 1_H\\ 	& \Delta ( \varphi \otimes h)=(\varphi_{(2)}\otimes h_{(1)}) \otimes (\varphi_{(1)}\otimes h_{(2)}) && \varepsilon(\varphi \otimes h)=\varphi(1)\varepsilon(h) \\ 	& S(\varphi \otimes h)=(\varepsilon \otimes S(h))(S^{-1}(\varphi)\otimes 1). 	\end{align*} In addition I came across the following definition of the multiplication: $$ (\varphi \otimes g)(\psi \otimes h)=\varphi(g_{(1)} \rightharpoonup \psi \leftharpoonup S^{-1}(g_{(3)}))\otimes g_{(2)}h .$$ The notation we use here is defined like this: Let $A$ be an algebra. For $a \in A$, $\varphi \in A^*$ we define $a \rightharpoonup \varphi, \varphi \leftharpoonup a \in A^*$ with $(a \rightharpoonup \varphi)(b)=\varphi(ba)$ and $(\varphi \leftharpoonup a)(b)=\varphi(ab)$ for every $b \in A$. My goal is to show that both multiplications are equal. This is my approach: \begin{align*} (\varphi \otimes g)(\psi \otimes h) & = \psi_{(1)}(S^{-1}(g_{(3)}))\psi_{(3)}(g_{(1)})\varphi\psi_{(2)}\otimes g_{(2)}h \\ & = (\psi_{(1)} \leftharpoonup S^{-1}(g_{(3)}))(g_{(1)} \rightharpoonup \psi_{(3)})\varphi\psi_{(2)} \otimes g_{(2)}h \end{align*} On the other hand we have: \begin{align*} (\varphi \otimes g)(\psi \otimes h) & = \varphi(g_{(1)} \rightharpoonup \psi \leftharpoonup S^{-1}(g_{(3)}))\otimes g_{(2)}h  \\ & = \varphi(g_{(1)} \rightharpoonup \psi_{(2)})\psi_{(1)}(S^{-1}(g_{(3)})) \otimes g_{(2)}h \\ & = \varphi\psi_{(2)}(g_{(1)})\psi_{(1)}(S^{-1}(g_{(3)})) \otimes g_{(2)}h \\ & = \psi_{(1)}(S^{-1}(g_{(3)})) \psi_{(2)}(g_{(1)})  \varphi \otimes g_{(2)}h \end{align*} As you can see, I am trying to show the equality by starting from both sides. But with my attempt at the bottom I am still missing a $\psi$ and have to make sure while adding it that it gets the right index. On the upper attempt I have to remove $\psi_{(2)}$ but do not see how it is done.","While studying the Drinfeld Double of a Hopf algebra, I came across two different definitions used for the multipliaction. For a finite dimensional Hopf algebra $H$ (over a field $K$) we define $D(H)=H^{*cop}\otimes H$ (the Drinfeld double of H) as a Hopf algebra with the following structure:     \begin{align*} 	&(\varphi \otimes g)(\psi \otimes h)= \psi_{(1)}(S^{-1}(g_{(3)}))\psi_{(3)}(g_{(1)})\varphi\psi_{(2)}\otimes g_{(2)}h		&& 1_{D(H)}=\varepsilon\otimes 1_H\\ 	& \Delta ( \varphi \otimes h)=(\varphi_{(2)}\otimes h_{(1)}) \otimes (\varphi_{(1)}\otimes h_{(2)}) && \varepsilon(\varphi \otimes h)=\varphi(1)\varepsilon(h) \\ 	& S(\varphi \otimes h)=(\varepsilon \otimes S(h))(S^{-1}(\varphi)\otimes 1). 	\end{align*} In addition I came across the following definition of the multiplication: $$ (\varphi \otimes g)(\psi \otimes h)=\varphi(g_{(1)} \rightharpoonup \psi \leftharpoonup S^{-1}(g_{(3)}))\otimes g_{(2)}h .$$ The notation we use here is defined like this: Let $A$ be an algebra. For $a \in A$, $\varphi \in A^*$ we define $a \rightharpoonup \varphi, \varphi \leftharpoonup a \in A^*$ with $(a \rightharpoonup \varphi)(b)=\varphi(ba)$ and $(\varphi \leftharpoonup a)(b)=\varphi(ab)$ for every $b \in A$. My goal is to show that both multiplications are equal. This is my approach: \begin{align*} (\varphi \otimes g)(\psi \otimes h) & = \psi_{(1)}(S^{-1}(g_{(3)}))\psi_{(3)}(g_{(1)})\varphi\psi_{(2)}\otimes g_{(2)}h \\ & = (\psi_{(1)} \leftharpoonup S^{-1}(g_{(3)}))(g_{(1)} \rightharpoonup \psi_{(3)})\varphi\psi_{(2)} \otimes g_{(2)}h \end{align*} On the other hand we have: \begin{align*} (\varphi \otimes g)(\psi \otimes h) & = \varphi(g_{(1)} \rightharpoonup \psi \leftharpoonup S^{-1}(g_{(3)}))\otimes g_{(2)}h  \\ & = \varphi(g_{(1)} \rightharpoonup \psi_{(2)})\psi_{(1)}(S^{-1}(g_{(3)})) \otimes g_{(2)}h \\ & = \varphi\psi_{(2)}(g_{(1)})\psi_{(1)}(S^{-1}(g_{(3)})) \otimes g_{(2)}h \\ & = \psi_{(1)}(S^{-1}(g_{(3)})) \psi_{(2)}(g_{(1)})  \varphi \otimes g_{(2)}h \end{align*} As you can see, I am trying to show the equality by starting from both sides. But with my attempt at the bottom I am still missing a $\psi$ and have to make sure while adding it that it gets the right index. On the upper attempt I have to remove $\psi_{(2)}$ but do not see how it is done.",,"['abstract-algebra', 'hopf-algebras']"
74,Regarding the general method of the ''Classify groups of order $X$'' question.,Regarding the general method of the ''Classify groups of order '' question.,X,"Anyone who has had to prepare for an algebra qualifying exam is familiar with the ""Classify groups of order $X$"" question. To illustrate my general question, which I postpone until the end, consider the following simple example in which I classify groups $G$ of order $3 \cdot 7$.  Let $H$ and $K$ be the $7$- and $3$-Sylow subgroups, respectively.  By Sylow's theorems, we find easily that $H$ is normal and $K$ is either normal or one of seven conjugate copies.  Also $H \cong \mathbf{Z}_7$ and $K \cong \mathbf{Z}_3$.  Let $x$ be a generator of $\mathbf{Z}_3$ and let $y$ be a generator of $\mathbf{Z}_7$, both viewed multiplicatively.  Now $G$ is a semidirect product of $H$ and $K$, hence the possible structures of $G$ are determined by the possible group homomorphisms $$ \mathbf{Z}_3 \to \mathrm{Aut}(\mathbf{Z}_7) \cong \mathbf{Z}_6. $$  Such a group homomorphism is determined by the image of $x$; since the order of this image must divide the order of $x$, we see $x$ is either sent to the identity automorphism $\mathbf{1}$ or an automorphism of order three. We find that a generator of $\mathbf{Z}_6$ is the automorphism $\alpha \colon y \mapsto y^3$.  Therefore, there are three possible group homomorphisms, determined by sending $x$ to $\mathbf{1}$, to $\alpha^2 \colon y \mapsto y^2$, or to $\alpha^4 \colon y \mapsto y^4$.  It follows there are at most three possible groups of order $21$, generated by $x$ and $y$ and subject to the relations $x^3 = x^7 = 1$ as well as one of the following commutativity relations: $$xy = yx, \;\;\;\;\; xy = y^2 x, \;\;\;\;\; xy = y^4 x. $$  All such groups exist by employing the abstract construction of the semidirect product. What follows is always the most subtle part of the analysis. Which of these groups are duplicates? The first is the case $G \cong \mathbf{Z}_3 \times \mathbf{Z}_7$ which is clearly distinct from the remaining two.  Let the second group be denoted $G_2$ and the third $G_4$.  If $G_2$ were isomorphic to $G_4$, then there would have to exist $X, Y \in G_4$ of orders three and seven, respectively, and satisfying $XY = Y^2 X$ (or $X, Y \in G_2$ satisfying $XY = Y^4 X$).  And it is easy to see that, in fact, this condition is sufficient for $x \mapsto X$, $y \mapsto Y$ to determine an isomorphism $G_2 \cong G_4$.  Note that both $G_2$ and $G_4$ have seven $3$-Sylow subgroups (otherwise they would be Cartesian products).  So there are $14$ candidates for $X$ and $6$ candidates for $Y$. Morally, at least in my opinion, these groups should be isomorphic, because the only difference in their definition occurs when we chose between the two generators $\alpha^2$ and $\alpha^4$ of the cyclic subgroup $\mathbf{Z}_3 \subset \mathrm{Aut}(\mathbf{Z}_7) \cong \mathbf{Z}_6$, and these generators are 'essentially the same'. This is indeed the case, but the proof feels 'lucky'.  One finds by calculation that no map of the form $X = x$ and $Y = y^k$ satisfies $XY = Y^2 X \in G_4$.  But this is satisfied by taking $X = x^2$ and $Y = y$:  $$X Y = x^2 y = x y^4 x = y^{16} x^2 = y^2 x^2 = Y^2 X \in G_4. $$  We conclude there are two groups of order $21$ up to isomorphism. To give an example of how this problem becomes more complex, if instead one were computing groups of order $3 \cdot 7 \cdot 13$, then one must determine group homomorphisms $$\mathbf{Z}_3 \to \mathrm{Aut}(\mathbf{Z}_7 \times \mathbf{Z}_{13}) \cong \mathbf{Z}_6 \times \mathbf{Z}_{12}. $$  (Don't forget that the automorphisms of the direct product is the direct product of the automorphisms when the orders of the groups are coprime!)  If $\alpha$ generates $\mathbf{Z}_6$ and $\beta$ generates $\mathbf{Z}_{12}$, then there are nine possible semidirect structures, corresponding to $x$ being sent to to any of the following pairs: $$(\mathbf{1}, \mathbf{1}), \;\;\;\;\; (\alpha^2, \mathbf{1}), \\ (\alpha^4, \mathbf{1}), \;\;\;\;\; (\mathbf{1}, \beta^4), \\ (\mathbf{1}, \beta^8), \;\;\;\;\; (\alpha^2, \beta^4), \\ (\alpha^4, \beta^4), \;\;\;\;\; (\alpha^4, \beta^8), \;\;\;\;\; (\alpha^2, \beta^8). $$  Which of these are isomorphic? Hopefully at this point my general question is clear.  First, in words: In considering semidirect products $G \cong H \rtimes K$ is there a (natural?) proof that shows the choice of generator(s) of $\mathrm{Aut}(H)$ affects the resulting group only up to the choice of 'non-equivalent' generators? Here is a precise phrasing for which I would be thrilled to receive an answer: Question:  Prove or disprove. Let $p$ and $q$ be primes such that $q$ divides $p-1$.  Consider semidirect products $G_\rho = \mathbf{Z}_p \rtimes_\rho \mathbf{Z}_q$ determined by group homomorphisms $$ \rho \colon \mathbf{Z}_q \to \mathrm{Aut}(\mathbf{Z}_p) \cong \mathbf{Z}_{p-1}. $$  Let $x$ multiplicatively generate $\mathbf{Z}_q$ and let $\alpha$ multiplicatively generate $\mathbf{Z}_{p-1}$.  Setting $n = (p-1)/q$ the generators for $\mathbf{Z}_q \subset \mathbf{Z}_{p-1}$ are $\alpha^{nk}$ where $k = 1, \dots, q-1$.  Let $\rho_k$ denote the group homomorphism determined by $x \mapsto \alpha^{nk}$.  Then $G_{\rho_k} \cong G_{\rho_\ell}$ for all $1 \leq k, \ell \leq q-1$.","Anyone who has had to prepare for an algebra qualifying exam is familiar with the ""Classify groups of order $X$"" question. To illustrate my general question, which I postpone until the end, consider the following simple example in which I classify groups $G$ of order $3 \cdot 7$.  Let $H$ and $K$ be the $7$- and $3$-Sylow subgroups, respectively.  By Sylow's theorems, we find easily that $H$ is normal and $K$ is either normal or one of seven conjugate copies.  Also $H \cong \mathbf{Z}_7$ and $K \cong \mathbf{Z}_3$.  Let $x$ be a generator of $\mathbf{Z}_3$ and let $y$ be a generator of $\mathbf{Z}_7$, both viewed multiplicatively.  Now $G$ is a semidirect product of $H$ and $K$, hence the possible structures of $G$ are determined by the possible group homomorphisms $$ \mathbf{Z}_3 \to \mathrm{Aut}(\mathbf{Z}_7) \cong \mathbf{Z}_6. $$  Such a group homomorphism is determined by the image of $x$; since the order of this image must divide the order of $x$, we see $x$ is either sent to the identity automorphism $\mathbf{1}$ or an automorphism of order three. We find that a generator of $\mathbf{Z}_6$ is the automorphism $\alpha \colon y \mapsto y^3$.  Therefore, there are three possible group homomorphisms, determined by sending $x$ to $\mathbf{1}$, to $\alpha^2 \colon y \mapsto y^2$, or to $\alpha^4 \colon y \mapsto y^4$.  It follows there are at most three possible groups of order $21$, generated by $x$ and $y$ and subject to the relations $x^3 = x^7 = 1$ as well as one of the following commutativity relations: $$xy = yx, \;\;\;\;\; xy = y^2 x, \;\;\;\;\; xy = y^4 x. $$  All such groups exist by employing the abstract construction of the semidirect product. What follows is always the most subtle part of the analysis. Which of these groups are duplicates? The first is the case $G \cong \mathbf{Z}_3 \times \mathbf{Z}_7$ which is clearly distinct from the remaining two.  Let the second group be denoted $G_2$ and the third $G_4$.  If $G_2$ were isomorphic to $G_4$, then there would have to exist $X, Y \in G_4$ of orders three and seven, respectively, and satisfying $XY = Y^2 X$ (or $X, Y \in G_2$ satisfying $XY = Y^4 X$).  And it is easy to see that, in fact, this condition is sufficient for $x \mapsto X$, $y \mapsto Y$ to determine an isomorphism $G_2 \cong G_4$.  Note that both $G_2$ and $G_4$ have seven $3$-Sylow subgroups (otherwise they would be Cartesian products).  So there are $14$ candidates for $X$ and $6$ candidates for $Y$. Morally, at least in my opinion, these groups should be isomorphic, because the only difference in their definition occurs when we chose between the two generators $\alpha^2$ and $\alpha^4$ of the cyclic subgroup $\mathbf{Z}_3 \subset \mathrm{Aut}(\mathbf{Z}_7) \cong \mathbf{Z}_6$, and these generators are 'essentially the same'. This is indeed the case, but the proof feels 'lucky'.  One finds by calculation that no map of the form $X = x$ and $Y = y^k$ satisfies $XY = Y^2 X \in G_4$.  But this is satisfied by taking $X = x^2$ and $Y = y$:  $$X Y = x^2 y = x y^4 x = y^{16} x^2 = y^2 x^2 = Y^2 X \in G_4. $$  We conclude there are two groups of order $21$ up to isomorphism. To give an example of how this problem becomes more complex, if instead one were computing groups of order $3 \cdot 7 \cdot 13$, then one must determine group homomorphisms $$\mathbf{Z}_3 \to \mathrm{Aut}(\mathbf{Z}_7 \times \mathbf{Z}_{13}) \cong \mathbf{Z}_6 \times \mathbf{Z}_{12}. $$  (Don't forget that the automorphisms of the direct product is the direct product of the automorphisms when the orders of the groups are coprime!)  If $\alpha$ generates $\mathbf{Z}_6$ and $\beta$ generates $\mathbf{Z}_{12}$, then there are nine possible semidirect structures, corresponding to $x$ being sent to to any of the following pairs: $$(\mathbf{1}, \mathbf{1}), \;\;\;\;\; (\alpha^2, \mathbf{1}), \\ (\alpha^4, \mathbf{1}), \;\;\;\;\; (\mathbf{1}, \beta^4), \\ (\mathbf{1}, \beta^8), \;\;\;\;\; (\alpha^2, \beta^4), \\ (\alpha^4, \beta^4), \;\;\;\;\; (\alpha^4, \beta^8), \;\;\;\;\; (\alpha^2, \beta^8). $$  Which of these are isomorphic? Hopefully at this point my general question is clear.  First, in words: In considering semidirect products $G \cong H \rtimes K$ is there a (natural?) proof that shows the choice of generator(s) of $\mathrm{Aut}(H)$ affects the resulting group only up to the choice of 'non-equivalent' generators? Here is a precise phrasing for which I would be thrilled to receive an answer: Question:  Prove or disprove. Let $p$ and $q$ be primes such that $q$ divides $p-1$.  Consider semidirect products $G_\rho = \mathbf{Z}_p \rtimes_\rho \mathbf{Z}_q$ determined by group homomorphisms $$ \rho \colon \mathbf{Z}_q \to \mathrm{Aut}(\mathbf{Z}_p) \cong \mathbf{Z}_{p-1}. $$  Let $x$ multiplicatively generate $\mathbf{Z}_q$ and let $\alpha$ multiplicatively generate $\mathbf{Z}_{p-1}$.  Setting $n = (p-1)/q$ the generators for $\mathbf{Z}_q \subset \mathbf{Z}_{p-1}$ are $\alpha^{nk}$ where $k = 1, \dots, q-1$.  Let $\rho_k$ denote the group homomorphism determined by $x \mapsto \alpha^{nk}$.  Then $G_{\rho_k} \cong G_{\rho_\ell}$ for all $1 \leq k, \ell \leq q-1$.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'semidirect-product']"
75,Universal property of a monoid ring expressed as an adjunction?,Universal property of a monoid ring expressed as an adjunction?,,"Given a (not necessarily commutative) ring $R$ and a monoid $M$, we can form the monoid ring $R[M]$ in the same way as we form the group ring. I would expect the monoid ring construction to be left adjoint to some ""forgetful"" functor, probably sending a ring to its underlying multiplicative monoid, but the universal property given in the wikipedia article suggests that it is not so simple, since it involves a pair of homomorphisms and a commutativity condition. This suggests to me that maybe it involves functors (into or out of) a coslice category (perhaps rings under R?). What would be the correct way of stating this universal property as an adjunction? I am just curious.","Given a (not necessarily commutative) ring $R$ and a monoid $M$, we can form the monoid ring $R[M]$ in the same way as we form the group ring. I would expect the monoid ring construction to be left adjoint to some ""forgetful"" functor, probably sending a ring to its underlying multiplicative monoid, but the universal property given in the wikipedia article suggests that it is not so simple, since it involves a pair of homomorphisms and a commutativity condition. This suggests to me that maybe it involves functors (into or out of) a coslice category (perhaps rings under R?). What would be the correct way of stating this universal property as an adjunction? I am just curious.",,"['abstract-algebra', 'category-theory', 'monoid', 'adjoint-functors']"
76,Finding nilpotent elements in a quotient ring.,Finding nilpotent elements in a quotient ring.,,"Which are nilpotent elements of $\mathbb{Q}[x]/(x^5-3x^2)\times\mathbb{Z}/(12)$? I tried to decompose in this way: $$\mathbb{Q}[x]/(x^5-3x^2)\times\mathbb{Z}/(12)\cong\mathbb{Q}[x]/(x^2)\times\mathbb{Q}[x]/(x^3-3)\times\mathbb{Z}/(3)\times\mathbb{Z}/(4)$$ so i thought that nilpotent elements are only: $$(0,0,0,2), (x,0,0,2) \ \  \mbox{and} \ \  (x,0,0,0).$$ I don't know if I am right, because i tried another approach considering the intersetion of all prime ideals of that ring and i don't know to understand if the result is the same.","Which are nilpotent elements of $\mathbb{Q}[x]/(x^5-3x^2)\times\mathbb{Z}/(12)$? I tried to decompose in this way: $$\mathbb{Q}[x]/(x^5-3x^2)\times\mathbb{Z}/(12)\cong\mathbb{Q}[x]/(x^2)\times\mathbb{Q}[x]/(x^3-3)\times\mathbb{Z}/(3)\times\mathbb{Z}/(4)$$ so i thought that nilpotent elements are only: $$(0,0,0,2), (x,0,0,2) \ \  \mbox{and} \ \  (x,0,0,0).$$ I don't know if I am right, because i tried another approach considering the intersetion of all prime ideals of that ring and i don't know to understand if the result is the same.",,"['abstract-algebra', 'proof-verification', 'ideals', 'nilpotence']"
77,Affine scheme obtained from (commutative) group algebra,Affine scheme obtained from (commutative) group algebra,,"Let $G$ be a finite abelian group (written multiplicatively), $R$ a commutative ring and let $R [G]$ denote the set of all formal linear combinations of elements of $G$ with coefficients in $R$. Then $R[G]$ is an $R$-algebra and in particular a ring with multiplication of elements defined in the obvious way: $(\sum_{g\in G} a_g g)\cdot (\sum_{h\in G} b_h h) = \sum_{g\in G} \sum_{h\in G} a_g b_h (g h)$ where the product of group elements occurs in $G$. This object is called the group ring or the group algebra of $G$ (over $R$). This is just an idle speculative question which occurred to me during my representation theory class, but given that we've got a natural $R$-algebra $R[G]$ here, does the affine scheme $\text{Spec}R[G]$ carry any information about $G$? Particular cases of interest to me are when $R = \mathbb{C}$ (this most closely ties in with my representation theory course) and when $R$ is somehow ""arithmetic"" e.g. $\mathbb{Z}$ or $\mathbb{F}_p$ for a prime $p$.","Let $G$ be a finite abelian group (written multiplicatively), $R$ a commutative ring and let $R [G]$ denote the set of all formal linear combinations of elements of $G$ with coefficients in $R$. Then $R[G]$ is an $R$-algebra and in particular a ring with multiplication of elements defined in the obvious way: $(\sum_{g\in G} a_g g)\cdot (\sum_{h\in G} b_h h) = \sum_{g\in G} \sum_{h\in G} a_g b_h (g h)$ where the product of group elements occurs in $G$. This object is called the group ring or the group algebra of $G$ (over $R$). This is just an idle speculative question which occurred to me during my representation theory class, but given that we've got a natural $R$-algebra $R[G]$ here, does the affine scheme $\text{Spec}R[G]$ carry any information about $G$? Particular cases of interest to me are when $R = \mathbb{C}$ (this most closely ties in with my representation theory course) and when $R$ is somehow ""arithmetic"" e.g. $\mathbb{Z}$ or $\mathbb{F}_p$ for a prime $p$.",,"['abstract-algebra', 'algebraic-geometry', 'finite-groups', 'representation-theory', 'schemes']"
78,Find all ideals of ${\mathbb{Z}_n}$,Find all ideals of,{\mathbb{Z}_n},"The task is to find all ideals of ${\mathbb{Z}_n}$, where $n$ is   positive integer, greater than one. My effort Let $I$ be an ideal of ${\mathbb{Z}_n}$. It is obvious that $I$ is an additive subgroup of ${\mathbb{Z}_n}$. Consider $G$ as an additive subgroup of ${\mathbb{Z}_n}$. Then $G$ is a cyclic additive subgroup generated by $\left\langle d \right\rangle $, where $d \mid n$. We know that for a finite cyclic group of order $k$, every subgroup's order is a divisor of $k$, and there is exactly one subgroup for each divisor. It follows that all ideals of ${\mathbb{Z}_n}$ are of form $\left\langle {{d_1}} \right\rangle ,\left\langle {{d_2}} \right\rangle , \ldots \left\langle {{d_i}} \right\rangle $, where ${d_1},{d_2}, \ldots ,{d_i}$ are positive divisors or $n$. Questions Is my proof correct?","The task is to find all ideals of ${\mathbb{Z}_n}$, where $n$ is   positive integer, greater than one. My effort Let $I$ be an ideal of ${\mathbb{Z}_n}$. It is obvious that $I$ is an additive subgroup of ${\mathbb{Z}_n}$. Consider $G$ as an additive subgroup of ${\mathbb{Z}_n}$. Then $G$ is a cyclic additive subgroup generated by $\left\langle d \right\rangle $, where $d \mid n$. We know that for a finite cyclic group of order $k$, every subgroup's order is a divisor of $k$, and there is exactly one subgroup for each divisor. It follows that all ideals of ${\mathbb{Z}_n}$ are of form $\left\langle {{d_1}} \right\rangle ,\left\langle {{d_2}} \right\rangle , \ldots \left\langle {{d_i}} \right\rangle $, where ${d_1},{d_2}, \ldots ,{d_i}$ are positive divisors or $n$. Questions Is my proof correct?",,"['abstract-algebra', 'proof-verification']"
79,"Prove that $f = q_1 + Gq_2$ for some $q_1, q_2 \in \mathbb{k}_{sym}(x_1,\dots,x_n)$",Prove that  for some,"f = q_1 + Gq_2 q_1, q_2 \in \mathbb{k}_{sym}(x_1,\dots,x_n)","Suppose the orbit of the function $f \in \mathbb{k}(x_1,\dots,x_n)$ under the action of $\{\phi_\sigma\mid\sigma \in \mathfrak{S}_n\}$ has length $2$. Prove that $f = q_1 + Gq_2$ for some $q_1, q_2 \in \mathbb{k}_{\text{sym}}(x_1,\dots,x_n)$, where $G = W_n$ in case of $\mathrm{char}(\mathbb{k}) \neq 2$ and $G=F$ in case of  $\mathrm{char}(\mathbb{k}) = 2$. $$F(x_1, \dots, x_n) = \sum_{\sigma \in \mathfrak{A}_n} \prod_{i=1}^nx^{i-1}_{\sigma(i)}$$ $$W_n(x_1, \dots, x_n)= \prod_{1 \leq i < j \leq n}(x_i - x_j)$$ Honestly, i'm not really good at Galois theory, so i would be glad to hear any suggestions.","Suppose the orbit of the function $f \in \mathbb{k}(x_1,\dots,x_n)$ under the action of $\{\phi_\sigma\mid\sigma \in \mathfrak{S}_n\}$ has length $2$. Prove that $f = q_1 + Gq_2$ for some $q_1, q_2 \in \mathbb{k}_{\text{sym}}(x_1,\dots,x_n)$, where $G = W_n$ in case of $\mathrm{char}(\mathbb{k}) \neq 2$ and $G=F$ in case of  $\mathrm{char}(\mathbb{k}) = 2$. $$F(x_1, \dots, x_n) = \sum_{\sigma \in \mathfrak{A}_n} \prod_{i=1}^nx^{i-1}_{\sigma(i)}$$ $$W_n(x_1, \dots, x_n)= \prod_{1 \leq i < j \leq n}(x_i - x_j)$$ Honestly, i'm not really good at Galois theory, so i would be glad to hear any suggestions.",,"['abstract-algebra', 'galois-theory']"
80,"Determining the structure of the quotient ring $\mathbb{Z}[x]/(x^2+3,p)$",Determining the structure of the quotient ring,"\mathbb{Z}[x]/(x^2+3,p)","I'm interested in the following problem from Artin's Algebra text: Determine the structure of the ring $\mathbb Z[x]/(x^2 + 3,p)$, where (a) p = 3, (b) p = 5. I know that by the isomorphism theorems for rings we can take the quotients successively, and so $$\mathbb{Z}[x]/(p) \cong (\mathbb{Z}/p \mathbb{Z})[x] $$ as the map $\mathbb{Z}[x] \to (\mathbb{Z}/p \mathbb{Z})[x]$ defined by $\sum_{n} a_n x^n \mapsto \sum_{n} \overline{a_n} x^n$ is a surjective ring homomorphism with kernel $(p)$. Thus it remains to study the quotients $$(\mathbb{Z}/p \mathbb{Z})[x]/(x^2+3) $$ for $p \in \{3,5\}$. If $p=3$, $(x^2+3)=(x^2)$ in $(\mathbb{Z}/3 \mathbb{Z})[x]$, and by using polynomial division all distinct coset representatives can be reduced to the following list of 9 elements $$\{0,1,2,x,1+x,2+x,2x,1+2x,2+2x\}. $$ Moreover, it can shown that the list above gives 9 distinct cosets, as no difference of two distinct elements of the list is a multiple of $x^2$. Since $1$ and $x$ generate two distinct additive groups of order $3$, the additive group of our quotient ring is not cyclic. Elementary group theory then shows $$(\mathbb{Z}/3 \mathbb{Z})[x]/(x^2)^+ \cong (\mathbb{Z}/ 3 \mathbb{Z})^2 $$ as additive groups. I was then about to conclude that the multiplication on the quotient is then compatible with the usual one in $(\mathbb{Z}/3\mathbb{Z})^2$, but this is wrong! It can be seen that the quotient is not isomorphic to $(\mathbb{Z}/3\mathbb{Z})^2$ as a ring, because the former contains a nonzero element (represented by $x$) whose square is zero, while the latter contains no such elements. If $p=5$, a full list of coset representatives is of length 25 $$\{0,1,2,3,4,x,1+x,2+x,3+x,4+x,2x,1+2x,2+2x,3+2x,4+2x,3x,1+3x,2+3x,3+3x,4+3x,4x,1+4x,2+4x,3+4x,4+4x \} .$$ And once again, one can see that these represent 25 distinct cosets. Similarly to the $p=5$ case, I've managed to prove that the additive group of this ring is isomorphic to $(\mathbb{Z}/5 \mathbb{Z})^2$. My questions: Have I made any mistakes in my argument? What exactly am I supposed to do in this question? determine the number of elements? Write down the tables for addition and multiplication? Any further information about these quotients will be appreciated, thanks!","I'm interested in the following problem from Artin's Algebra text: Determine the structure of the ring $\mathbb Z[x]/(x^2 + 3,p)$, where (a) p = 3, (b) p = 5. I know that by the isomorphism theorems for rings we can take the quotients successively, and so $$\mathbb{Z}[x]/(p) \cong (\mathbb{Z}/p \mathbb{Z})[x] $$ as the map $\mathbb{Z}[x] \to (\mathbb{Z}/p \mathbb{Z})[x]$ defined by $\sum_{n} a_n x^n \mapsto \sum_{n} \overline{a_n} x^n$ is a surjective ring homomorphism with kernel $(p)$. Thus it remains to study the quotients $$(\mathbb{Z}/p \mathbb{Z})[x]/(x^2+3) $$ for $p \in \{3,5\}$. If $p=3$, $(x^2+3)=(x^2)$ in $(\mathbb{Z}/3 \mathbb{Z})[x]$, and by using polynomial division all distinct coset representatives can be reduced to the following list of 9 elements $$\{0,1,2,x,1+x,2+x,2x,1+2x,2+2x\}. $$ Moreover, it can shown that the list above gives 9 distinct cosets, as no difference of two distinct elements of the list is a multiple of $x^2$. Since $1$ and $x$ generate two distinct additive groups of order $3$, the additive group of our quotient ring is not cyclic. Elementary group theory then shows $$(\mathbb{Z}/3 \mathbb{Z})[x]/(x^2)^+ \cong (\mathbb{Z}/ 3 \mathbb{Z})^2 $$ as additive groups. I was then about to conclude that the multiplication on the quotient is then compatible with the usual one in $(\mathbb{Z}/3\mathbb{Z})^2$, but this is wrong! It can be seen that the quotient is not isomorphic to $(\mathbb{Z}/3\mathbb{Z})^2$ as a ring, because the former contains a nonzero element (represented by $x$) whose square is zero, while the latter contains no such elements. If $p=5$, a full list of coset representatives is of length 25 $$\{0,1,2,3,4,x,1+x,2+x,3+x,4+x,2x,1+2x,2+2x,3+2x,4+2x,3x,1+3x,2+3x,3+3x,4+3x,4x,1+4x,2+4x,3+4x,4+4x \} .$$ And once again, one can see that these represent 25 distinct cosets. Similarly to the $p=5$ case, I've managed to prove that the additive group of this ring is isomorphic to $(\mathbb{Z}/5 \mathbb{Z})^2$. My questions: Have I made any mistakes in my argument? What exactly am I supposed to do in this question? determine the number of elements? Write down the tables for addition and multiplication? Any further information about these quotients will be appreciated, thanks!",,"['abstract-algebra', 'ring-theory', 'ideals', 'quotient-spaces']"
81,$P(X) = X^6 - 11X^4 + 36X^2 - 36$ has a root in $\mathbb{Q}_p$ for every $p$,has a root in  for every,P(X) = X^6 - 11X^4 + 36X^2 - 36 \mathbb{Q}_p p,"Problem: Prove that $P(X) = X^6 - 11X^4 + 36X^2 - 36$ has a root in $\mathbb{R}$, has no roots in $\mathbb{Q}$, but has a root in $\mathbb{Q}_p$ for every $p$. What I have done: I think this is actually false. We can find this factorization: $P(X) = (X^2 - 2)(X^2 - 3)(X^2 - 6)$. So we deduce that there are 6 different roots in $\mathbb{R}$, and there are no roots in $\mathbb{Q}$. For $p \not= 2,3$ combining Hensel's Lemma and multiplicativity of Legendre Symbol we can say that there is a root in $\mathbb{Q}_p$. But for $p = 3$ we can't find $\sqrt{3}$ and $\sqrt{6}$ in $\mathbb{Q}_3$ beacuse they should have absolute value $|\sqrt{3}|_3 = |\sqrt{6}|_3 = 3^{-1/2}$ which is not possible cause, as sets, $|\mathbb{Q}_p|_p = |\mathbb{Q}|_p$. A root of $(X^2 - 2)$ in $\mathbb{Q}_3$ should be in $\mathbb{Z}_3$ because $\mathbb{Q}_3$ is the field of fractions of $\mathbb{Z}_3$ which is DVR and hence integrally closed (is that true?). But we can't solve $a_0^2 \equiv 2 \pmod 3$. $\mathbb{Q}_2$ is almost the same cause we must find a root for $(X^2 - 3)$ but $3 \not \equiv 1 \pmod  8$. Did I make any mistakes or is this problem  just wrong?","Problem: Prove that $P(X) = X^6 - 11X^4 + 36X^2 - 36$ has a root in $\mathbb{R}$, has no roots in $\mathbb{Q}$, but has a root in $\mathbb{Q}_p$ for every $p$. What I have done: I think this is actually false. We can find this factorization: $P(X) = (X^2 - 2)(X^2 - 3)(X^2 - 6)$. So we deduce that there are 6 different roots in $\mathbb{R}$, and there are no roots in $\mathbb{Q}$. For $p \not= 2,3$ combining Hensel's Lemma and multiplicativity of Legendre Symbol we can say that there is a root in $\mathbb{Q}_p$. But for $p = 3$ we can't find $\sqrt{3}$ and $\sqrt{6}$ in $\mathbb{Q}_3$ beacuse they should have absolute value $|\sqrt{3}|_3 = |\sqrt{6}|_3 = 3^{-1/2}$ which is not possible cause, as sets, $|\mathbb{Q}_p|_p = |\mathbb{Q}|_p$. A root of $(X^2 - 2)$ in $\mathbb{Q}_3$ should be in $\mathbb{Z}_3$ because $\mathbb{Q}_3$ is the field of fractions of $\mathbb{Z}_3$ which is DVR and hence integrally closed (is that true?). But we can't solve $a_0^2 \equiv 2 \pmod 3$. $\mathbb{Q}_2$ is almost the same cause we must find a root for $(X^2 - 3)$ but $3 \not \equiv 1 \pmod  8$. Did I make any mistakes or is this problem  just wrong?",,"['abstract-algebra', 'polynomials', 'ring-theory', 'irreducible-polynomials']"
82,About Abelian Finite Groups and Euler's Function,About Abelian Finite Groups and Euler's Function,,"Let $G$ be a finite group or $|G|=n$ and let $(\phi(n) ,n)=1$ (where $\phi(n) $ is Euler's function). Now prove $G$ is abelian.","Let $G$ be a finite group or $|G|=n$ and let $(\phi(n) ,n)=1$ (where $\phi(n) $ is Euler's function). Now prove $G$ is abelian.",,"['abstract-algebra', 'finite-groups', 'abelian-groups']"
83,Degree of splitting field of polynomial over a finite field,Degree of splitting field of polynomial over a finite field,,"Let $f$ be a polynomial over a finite field $F$ which decomposes into a product of irreducible factors $f=p_1...p_k$ of degree $n_1,...n_k$. How can I prove that the degree of splitting field of $f$ over $F$ is least common multiple of $n_1,...,n_k$?","Let $f$ be a polynomial over a finite field $F$ which decomposes into a product of irreducible factors $f=p_1...p_k$ of degree $n_1,...n_k$. How can I prove that the degree of splitting field of $f$ over $F$ is least common multiple of $n_1,...,n_k$?",,"['abstract-algebra', 'polynomials', 'finite-fields']"
84,Global Dimension of a Ring and its Localizations,Global Dimension of a Ring and its Localizations,,Why is the following true? The global dimension of a noetherian ring $A$ is the supremum of the global dimension of its localizations at its maximal ideals:   $$\operatorname{gldim}(A)=\sup_{\mathfrak m\in\operatorname{SpecMax}A} \operatorname{gldim}(A_{\mathfrak m}).$$ Could one approach by the definition of global dimension that is the supremum of projective dimensions of all $A$-modules? Thanks for any help!,Why is the following true? The global dimension of a noetherian ring $A$ is the supremum of the global dimension of its localizations at its maximal ideals:   $$\operatorname{gldim}(A)=\sup_{\mathfrak m\in\operatorname{SpecMax}A} \operatorname{gldim}(A_{\mathfrak m}).$$ Could one approach by the definition of global dimension that is the supremum of projective dimensions of all $A$-modules? Thanks for any help!,,"['abstract-algebra', 'commutative-algebra', 'homological-algebra', 'global-dimension']"
85,Discriminant of Polynomials (Galois Theory),Discriminant of Polynomials (Galois Theory),,"So I'm reading Dummit and Foote and they define the discriminant of $x_{1},...,x_{n}$ by $$D=\prod_{i<j}(x_{i}-x_{j})^2$$ and the discriminant of a polynomial to be the discriminant of the roots. They say that a permutation $\sigma \in S_{n}$ is in the alternating group $A_{n}$ iff $\sigma$ fixes the product $\sqrt{D}$. It follows by the Fundamental Theorem of Galois Theory that if $F$ has characterstic different from 2 then $\sqrt{D}$ generates the fixed field of $A_{n}$ and generates a quadratic extension of $K$. I am confused where characteristic $2$ comes into this.","So I'm reading Dummit and Foote and they define the discriminant of $x_{1},...,x_{n}$ by $$D=\prod_{i<j}(x_{i}-x_{j})^2$$ and the discriminant of a polynomial to be the discriminant of the roots. They say that a permutation $\sigma \in S_{n}$ is in the alternating group $A_{n}$ iff $\sigma$ fixes the product $\sqrt{D}$. It follows by the Fundamental Theorem of Galois Theory that if $F$ has characterstic different from 2 then $\sqrt{D}$ generates the fixed field of $A_{n}$ and generates a quadratic extension of $K$. I am confused where characteristic $2$ comes into this.",,"['abstract-algebra', 'polynomials', 'galois-theory', 'finite-fields', 'positive-characteristic']"
86,Calculating global sections of sheaves,Calculating global sections of sheaves,,"Consider the usual projective space $\mathbb{P}^{1} = \mathbb{C} \cup \{\infty\}$, and the Weil divisor $D = \{0\} \subset \mathbb{C} \subset \mathbb{P}^{1}$. Writing projective space as the union of the open sets, we obtain $\mathbb{P}^{1} = U_{0} \cup U_{1}$, using $U_{0} = Spec(\mathbb{C}[t]), U_{1} = Spec(\mathbb{C}[t^{-1}])$, we get $\mathbb{C}(\mathbb{P}^{1}) = \mathbb{C}(t)$. Defining $\Gamma(\mathbb{P}^{1},O_{\mathbb{P}^{1}}(D))=\{f\in \mathbb{C}(t)^{*} | div(f) + D \geq 0\} \cup \{0 \}$, it is then claimed that it follows easily that the global sections are $1,t^{-1} \in \Gamma(\mathbb{P}^{1},O_{\mathbb{P}^{1}} (D))$ (cf. Introduction to Toric Varieties Cox, Little, and Schenck p. 247). In addition, he further states that multiplying by $f$ gives a sheaf homomorphism $O_{\mathbb{P}^{1}}(-D) \to O_{\mathbb{P}^{1}}$ and that doing this for $1, t^{-1} \in \Gamma(\mathbb{P}^{1},O_{\mathbb{P}^{1}} (D))$ gives $$O_{\mathbb{P}^{1}}(-D) \oplus O_{\mathbb{P}^{1}}(-D) \to O_{\mathbb{P}^{1}}$$ Could someone please explain these implications in detail? I am rather new to sheaf theory and am having trouble following the arguments in this example. I know that we define $div(f) = \sum \nu_{D}(f) D_{f}$, where $\nu$ is the valuation, but I still fail to see above implication. Thanks","Consider the usual projective space $\mathbb{P}^{1} = \mathbb{C} \cup \{\infty\}$, and the Weil divisor $D = \{0\} \subset \mathbb{C} \subset \mathbb{P}^{1}$. Writing projective space as the union of the open sets, we obtain $\mathbb{P}^{1} = U_{0} \cup U_{1}$, using $U_{0} = Spec(\mathbb{C}[t]), U_{1} = Spec(\mathbb{C}[t^{-1}])$, we get $\mathbb{C}(\mathbb{P}^{1}) = \mathbb{C}(t)$. Defining $\Gamma(\mathbb{P}^{1},O_{\mathbb{P}^{1}}(D))=\{f\in \mathbb{C}(t)^{*} | div(f) + D \geq 0\} \cup \{0 \}$, it is then claimed that it follows easily that the global sections are $1,t^{-1} \in \Gamma(\mathbb{P}^{1},O_{\mathbb{P}^{1}} (D))$ (cf. Introduction to Toric Varieties Cox, Little, and Schenck p. 247). In addition, he further states that multiplying by $f$ gives a sheaf homomorphism $O_{\mathbb{P}^{1}}(-D) \to O_{\mathbb{P}^{1}}$ and that doing this for $1, t^{-1} \in \Gamma(\mathbb{P}^{1},O_{\mathbb{P}^{1}} (D))$ gives $$O_{\mathbb{P}^{1}}(-D) \oplus O_{\mathbb{P}^{1}}(-D) \to O_{\mathbb{P}^{1}}$$ Could someone please explain these implications in detail? I am rather new to sheaf theory and am having trouble following the arguments in this example. I know that we define $div(f) = \sum \nu_{D}(f) D_{f}$, where $\nu$ is the valuation, but I still fail to see above implication. Thanks",,"['abstract-algebra', 'algebraic-geometry', 'sheaf-theory', 'sheaf-cohomology']"
87,Nonspliting short exact sequence,Nonspliting short exact sequence,,"The short exact sequence $0\rightarrow \mathbb Z \stackrel{\alpha}{\longrightarrow} \mathbb Z \oplus \mathbb Q \stackrel{\beta} {\longrightarrow} \mathbb Q \rightarrow 0$ is splits because we have split map $\gamma: \mathbb Q\rightarrow \mathbb Z \oplus \mathbb Q$ defined by $\gamma(q) = (0,q)$ such that $\gamma\circ\beta$ is identity on $Q.$  My question here is if we have  $0\rightarrow \mathbb Z \stackrel{\alpha}{\longrightarrow} G \stackrel{\beta} {\longrightarrow} \mathbb Q \rightarrow 0,$ then what is $G$? One of the possibility is $\mathbb Z \oplus \mathbb Q.$ The sequence is not necessarily split because we do not know exactly whether $G$ has a copy of $\mathbb Q$ or copy of $\mathbb Z.$  Is there any source where I can get more information about it? Thank you.","The short exact sequence $0\rightarrow \mathbb Z \stackrel{\alpha}{\longrightarrow} \mathbb Z \oplus \mathbb Q \stackrel{\beta} {\longrightarrow} \mathbb Q \rightarrow 0$ is splits because we have split map $\gamma: \mathbb Q\rightarrow \mathbb Z \oplus \mathbb Q$ defined by $\gamma(q) = (0,q)$ such that $\gamma\circ\beta$ is identity on $Q.$  My question here is if we have  $0\rightarrow \mathbb Z \stackrel{\alpha}{\longrightarrow} G \stackrel{\beta} {\longrightarrow} \mathbb Q \rightarrow 0,$ then what is $G$? One of the possibility is $\mathbb Z \oplus \mathbb Q.$ The sequence is not necessarily split because we do not know exactly whether $G$ has a copy of $\mathbb Q$ or copy of $\mathbb Z.$  Is there any source where I can get more information about it? Thank you.",,"['abstract-algebra', 'homological-algebra']"
88,Proof that the set of intersection points is finite,Proof that the set of intersection points is finite,,"I am trying to understand the proof of the following theorem: Let $f,g\in K[x,y]$ without a common factor. Then $\#V(f,g)<\infty$. (Here $K$ is a field and $V(f,g):=\left\{(a,b):f(a,b)=g(a,b)=0\right\}$.) One step in this proof is not clear to me: We consider $f$ and $g$ as elements of $K(y)[x]$, where $K(y)$ is the field of all rational functions over $K$ in $y$. Then $\gcd(f,g)=1$ in $K(y)[x]$. My question: Why is this the case? It is clear to me that $K[x,y]\subset K(y)[x]$, but why can't $f$ and $g$ have a common factor in this larger set? I tried to assume the opposite that there is some common factor $h\in K(y)[x]$ such that $f=h\cdot h_1$ and $g=h\cdot h_2$ where $h_1,h_2\in K(y)[x]$. If I then take the least common multiple of the denominators of $h_1,h_2$ and $h$, i.e. some $b\in K[y]$, I obtain the equations $b\cdot f=\bar h_1\cdot\bar h$ and $b\cdot g=\bar h_2\cdot\bar h$ for some $\bar h,\bar h_1,\bar h_2\in K[x,y]\subset K(y)[x]$. Know I tried to use that $K(y)[x]$ admits a unique decomposition of each element in a product of irreducible elements...and got stuck. As I am not an algebraist, could someone please explain to me in simples words, how to prove this result without using too much theory from algebraic geometry (which I am not familiar with)? Thank you very much in advance!","I am trying to understand the proof of the following theorem: Let $f,g\in K[x,y]$ without a common factor. Then $\#V(f,g)<\infty$. (Here $K$ is a field and $V(f,g):=\left\{(a,b):f(a,b)=g(a,b)=0\right\}$.) One step in this proof is not clear to me: We consider $f$ and $g$ as elements of $K(y)[x]$, where $K(y)$ is the field of all rational functions over $K$ in $y$. Then $\gcd(f,g)=1$ in $K(y)[x]$. My question: Why is this the case? It is clear to me that $K[x,y]\subset K(y)[x]$, but why can't $f$ and $g$ have a common factor in this larger set? I tried to assume the opposite that there is some common factor $h\in K(y)[x]$ such that $f=h\cdot h_1$ and $g=h\cdot h_2$ where $h_1,h_2\in K(y)[x]$. If I then take the least common multiple of the denominators of $h_1,h_2$ and $h$, i.e. some $b\in K[y]$, I obtain the equations $b\cdot f=\bar h_1\cdot\bar h$ and $b\cdot g=\bar h_2\cdot\bar h$ for some $\bar h,\bar h_1,\bar h_2\in K[x,y]\subset K(y)[x]$. Know I tried to use that $K(y)[x]$ admits a unique decomposition of each element in a product of irreducible elements...and got stuck. As I am not an algebraist, could someone please explain to me in simples words, how to prove this result without using too much theory from algebraic geometry (which I am not familiar with)? Thank you very much in advance!",,"['abstract-algebra', 'algebraic-geometry']"
89,Structure of the group $\{1+p\mathbb Z_p \}$,Structure of the group,\{1+p\mathbb Z_p \},"In preparation for algebraic number theory I am reading Serre : A course in Arithmetic. I stuck in understanding a proof (p.17): Notation: $U_n=1+p^n\mathbb Z_p$ Actually there are many things which I don't understand... Why it holds that $(\alpha_n)^{p^{n-2}}\neq 1$ and $(\alpha_n)^{p^{n-1}}= 1$? Why $\phi_{n,\alpha}$ is an isomorphism? I see that is is an homomorphism, but  proving that its also bijective is not that easy for me, because its hard for me to imagine the group $U_1$/$U_n$ I also dont understand the last tree lines I know that I did understand only few things. In my opinion this book leaves out many arguments, so i hope that someone can make this clear for me. Thanks in advance!","In preparation for algebraic number theory I am reading Serre : A course in Arithmetic. I stuck in understanding a proof (p.17): Notation: $U_n=1+p^n\mathbb Z_p$ Actually there are many things which I don't understand... Why it holds that $(\alpha_n)^{p^{n-2}}\neq 1$ and $(\alpha_n)^{p^{n-1}}= 1$? Why $\phi_{n,\alpha}$ is an isomorphism? I see that is is an homomorphism, but  proving that its also bijective is not that easy for me, because its hard for me to imagine the group $U_1$/$U_n$ I also dont understand the last tree lines I know that I did understand only few things. In my opinion this book leaves out many arguments, so i hope that someone can make this clear for me. Thanks in advance!",,"['abstract-algebra', 'group-theory', 'p-adic-number-theory']"
90,"Proof that $\gcd(2^m-1,2^n+1)=1$ for odd $m$ using group theory",Proof that  for odd  using group theory,"\gcd(2^m-1,2^n+1)=1 m","Below is a perfectly fine proof using basic tools of number theory: Showing $\gcd(2^m-1,2^n+1)=1$ Could we prove this more quickly using group theory? I would be very interested in seeing an abstract algebra-flavored proof.","Below is a perfectly fine proof using basic tools of number theory: Showing $\gcd(2^m-1,2^n+1)=1$ Could we prove this more quickly using group theory? I would be very interested in seeing an abstract algebra-flavored proof.",,"['abstract-algebra', 'group-theory', 'elementary-number-theory', 'divisibility', 'gcd-and-lcm']"
91,If in a UFD every maximal ideal is principal then it is a PID,If in a UFD every maximal ideal is principal then it is a PID,,"I want to prove that if in a UFD every maximal ideal is principal then it is a PID. My line of attack is: If it is a field i.e. it has no non-zero proper ideal, then we are done. Otherwise consider a non-zero proper ideal. Then, by Zorn's lemma, it is contained in some maximal ideal, hence contained in a principal ideal which is not the whole ring. Now we know that if in a UFD every proper ideal is contained a proper principal ideal, then it is a PID, hence we are done. Is there any other solution without using Zorn's lemma?","I want to prove that if in a UFD every maximal ideal is principal then it is a PID. My line of attack is: If it is a field i.e. it has no non-zero proper ideal, then we are done. Otherwise consider a non-zero proper ideal. Then, by Zorn's lemma, it is contained in some maximal ideal, hence contained in a principal ideal which is not the whole ring. Now we know that if in a UFD every proper ideal is contained a proper principal ideal, then it is a PID, hence we are done. Is there any other solution without using Zorn's lemma?",,"['abstract-algebra', 'ring-theory']"
92,$x^p-x-1$ is irreducible over $\mathbb{Q}$[x],is irreducible over [x],x^p-x-1 \mathbb{Q},"For any prime  p, prove  that  $x^p-x-1$ is irreducible over $\mathbb{Q}$[x]. (In a field of characteristic p this is true). I asummed exist root in $\mathbb{Q}$, let's call $\frac{\alpha}{\beta} \in \mathbb{Q}$. Then following that  $\frac{\alpha ^p}{\beta ^p} - \frac{\alpha}{\beta}-1  = 0$ and then $\alpha ^p - \alpha \beta ^{p-1} - \beta ^p =0$. So $\alpha ^p = -\beta^p (1 + \alpha \beta ^{-1})$. But this only proves that $x^p -x -1$ don't have rational roots.","For any prime  p, prove  that  $x^p-x-1$ is irreducible over $\mathbb{Q}$[x]. (In a field of characteristic p this is true). I asummed exist root in $\mathbb{Q}$, let's call $\frac{\alpha}{\beta} \in \mathbb{Q}$. Then following that  $\frac{\alpha ^p}{\beta ^p} - \frac{\alpha}{\beta}-1  = 0$ and then $\alpha ^p - \alpha \beta ^{p-1} - \beta ^p =0$. So $\alpha ^p = -\beta^p (1 + \alpha \beta ^{-1})$. But this only proves that $x^p -x -1$ don't have rational roots.",,['abstract-algebra']
93,Show that every group G with |G|<6 is abelian.,Show that every group G with |G|<6 is abelian.,,"Show that every group G with |G|<6 is abelian. So I tried to prove this one by cases. Case 1: Suppose |G| = 1, then G is the trivial group, and is abelian. Case 2: |G| is prime, then |G| = 2, 3, or 5. Every group of order p, where p is prime is cyclic. Let g be a generator of any cyclic group G and let $a,b\in G$. Then, $\exists x,y \in \mathbb{Z}$ such that $a=g^x$ and $b=g^y$. Then we have that $$ab = g^x g^y = g^{x+y} = g^{y+x} = g^y g^x = ba$$ Hence, all cyclic groups are abelian. Case 3: |G| = 4 This one was kind of hard to wrap my head around until my professor told me that only two groups have order 4, $\mathbb{Z}_4$ and $\mathbb{V}$, the Klein group. So my proof of this case was sort of brute force, showing that each group was abelian. What if I was asked to prove that all groups of order less than 100 ( Note that I understand this is not true )? Brute force would not be the most efficient, as there are many groups of order less than 100. Is there a more efficient way of proving case 3?","Show that every group G with |G|<6 is abelian. So I tried to prove this one by cases. Case 1: Suppose |G| = 1, then G is the trivial group, and is abelian. Case 2: |G| is prime, then |G| = 2, 3, or 5. Every group of order p, where p is prime is cyclic. Let g be a generator of any cyclic group G and let $a,b\in G$. Then, $\exists x,y \in \mathbb{Z}$ such that $a=g^x$ and $b=g^y$. Then we have that $$ab = g^x g^y = g^{x+y} = g^{y+x} = g^y g^x = ba$$ Hence, all cyclic groups are abelian. Case 3: |G| = 4 This one was kind of hard to wrap my head around until my professor told me that only two groups have order 4, $\mathbb{Z}_4$ and $\mathbb{V}$, the Klein group. So my proof of this case was sort of brute force, showing that each group was abelian. What if I was asked to prove that all groups of order less than 100 ( Note that I understand this is not true )? Brute force would not be the most efficient, as there are many groups of order less than 100. Is there a more efficient way of proving case 3?",,"['abstract-algebra', 'group-theory']"
94,"$G$, $|G|=n$ is nilpotent $\iff$ $\forall m|n$, $G$ has a normal subgroup of order $m$.",",  is nilpotent  ,  has a normal subgroup of order .",G |G|=n \iff \forall m|n G m,"Prove $G$, $|G|=n$ is nilpotent $\iff$ $\forall m|n$, $G$ has a normal subgroup of order $m$. I got stuck in the second direction. One direction : $|G|=n=p_1^{s_1}\cdot ...\cdot p_k^{s_k}$ Where $p_i$ prime. Particularly, $\forall p_i^{s_i}, p_i^{s_i}|n$ and therefore the Sylow -$p_i$ subgroup is unique and normal. Therefore every Sylow -$p$ subgroup is normal and that means $G$ is nilpotent. (There is a theorem\corollary claiming that saying every Sylow -$p$ subgroup is normal is equivalent to saying $G$ is nilpotent. Other direction : Let $G$ be nilpotent. $|G|=n=p_1^{s_1}\cdot ...\cdot p_k1^{s_k}$ Where $p_i$ prime. Then, Sylow -$p_i$ subgroup is unique and normal. But what about the $p$- subgroups of order such as $p_i^{},p_i^{2},...,p_i^{s_i-1}$? They are subgroups contained in the Sylow -$p_i$ subgroup, and they all divide $n$, but are they normal? How can I show that?","Prove $G$, $|G|=n$ is nilpotent $\iff$ $\forall m|n$, $G$ has a normal subgroup of order $m$. I got stuck in the second direction. One direction : $|G|=n=p_1^{s_1}\cdot ...\cdot p_k^{s_k}$ Where $p_i$ prime. Particularly, $\forall p_i^{s_i}, p_i^{s_i}|n$ and therefore the Sylow -$p_i$ subgroup is unique and normal. Therefore every Sylow -$p$ subgroup is normal and that means $G$ is nilpotent. (There is a theorem\corollary claiming that saying every Sylow -$p$ subgroup is normal is equivalent to saying $G$ is nilpotent. Other direction : Let $G$ be nilpotent. $|G|=n=p_1^{s_1}\cdot ...\cdot p_k1^{s_k}$ Where $p_i$ prime. Then, Sylow -$p_i$ subgroup is unique and normal. But what about the $p$- subgroups of order such as $p_i^{},p_i^{2},...,p_i^{s_i-1}$? They are subgroups contained in the Sylow -$p_i$ subgroup, and they all divide $n$, but are they normal? How can I show that?",,"['abstract-algebra', 'group-theory', 'sylow-theory']"
95,The Underlying Manifolds of the Special Unitary Lie Groups SU(n),The Underlying Manifolds of the Special Unitary Lie Groups SU(n),,"I want to find the underlying manifolds of Lie Groups $\mbox{SU}(n)$ for general $n$. $$ \quad $$ My lecturer told us last year that the only n-spheres that admit a Lie group structure are $\mathbb{S}^1$ and $\mathbb{S}^3$. Moreover I see several question describing why this is so, such as here and here , and understand the arguments therein. However each Lie group must have some underlying manifold by definition. However I do not know how to find what the manifold is for any given Lie group. $$ \quad $$ My motivation for this question is to understand the Lie algebra relation $$ \mathfrak{su}(4) \simeq \mathfrak{so}(6) $$ and as such there is some relation between the Lie groups $\mbox{SU}(4)$ and $\mbox{SO}(6)$, with my neive guess being $$ \mbox{SU}(4) / \mathbb{Z}_2 \simeq \mbox{SO}(6) $$ I don't have any very good reason for this however, but it feels right. I note that $$ \mbox{dim}[\mbox{SU}(4)] = 15 \quad \mbox{ and } \quad \mbox{dim}[\mbox{SO}(6)] = 15$$ so we don't immediately think that no such relation should exist. Moreover, I'm encouraged by the relation $\mbox{SU}(2) / \mathbb{Z}_2 \simeq \mbox{SO}(3) $, which I understand and can calculate. Explicitly, one first notes that both $\mathfrak{su}(2)$ and $\mathfrak{so}(3)$ have the same Lie algebra, namely $$ [T_i, T_j ] = \varepsilon^{ijk} T_k $$ Then one shows that $\mbox{SU}(2)$ has the 3-sphere $\mathbb{S}^3$ as underlying manifold, since any $U \in \mbox{SU}(2)$ can be written like $$ U = a_0 I_2 + i \vec{a} \cdot \vec{\sigma} $$ with $$ a_0^2 + \vec{a} \cdot \vec{a} = 1 $$ and this is the equation for the unit 3-sphere $\mathbb{S}^3$, while it can be shown that $\mbox{SO}(3)$ has underlying manifold $\mathbb{RP}^3$, and it remains to note that $\mathbb{S}^3$ is a double cover of $\mathbb{RP}^3$, which motivates the quotient by $\mathbb{Z}_2$, leading to the result. Now, I have tried thinking about using this approach in my case of $\mbox{SU}(4)$ and $\mbox{SO}(6)$, but I make no progress. $$ \quad $$ Perhaps a related point, we can show that the action of $\mbox{SU}(2)$ on $\mathbb{C}^2 \simeq \mathbb{R}^4$ has as orbits 3-spheres $\mathbb{S}^3$ by considering the fact that that the action of $\mbox{SU}(2)$ on $\mathbb{C}^2$ preserves the Hilbert norm, giving a constraint $$ ||\vec{z}||^2 = |z_1|^2 + |z_2|^2 = x_1^2 +y_1^2 + x_2^2 +y_2^2 $$ for $\vec{z} = (z_1,z_2) = (x_1 + i y_1, x_2 + i y_2) \in \mathbb{C}^2$. Now this I have had success (I hope!) in generalising, and I find that the action of $\mbox{SU}(n)$ on $\mathbb{C}^n \simeq \mathbb{R}^{2n}$ should have as orbits (2n-1)-spheres $\mathbb{S}^{2n-1} \subset \mathbb{R}^{2n}$. I am unsure if this actually helps me with my original question however. $$ \quad $$ Finally, I'll note that my motivation for wanting to find a relation between $\mbox{SU}(4)$ and $\mbox{SO}(6)$ comes from studying the AdS/CFT correspondence (I'm a TP). In $\mathcal{N}=4$ Super-Yang-Mills theory we get one vector supermultiplet of states, which can be written as one $\mathcal{N}=1$ vector supermultiplet and three $\mathcal{N}=1$ chiral supermultiplet, consisting of a total of four gauge vector fields $A_{\mu}^i(x)$ and six scalar fields $\phi^{[ij]}(x)$ for $i = 1,2,3,4$ which then have an $\mbox{SU}(4)$ R-symmetry (an $\mathcal{N}=N$ supersymmetric field theory has an $\mbox{SU}(N)$ R-symmetry). However, in order to compare this to the type IIB superstring theory on $AdS_5 \times \mathbb{S}^5$ we need to match this $\mbox{SU}(4)$ R-symmetry with the $\mbox{SO}(6)$ rotation symmetry of the 5-sphere \mathbb{S}^5$. In the AdS/ CFT papers that I have read the TPs (who are not known for making accurate group theoretic statements! (See, for example, the top of page 30 and the bottom of page 72 of what is otherwise a brilliantly clear paper 0712.0689 ) ) simply write $\mbox{SU}(4) \simeq\mbox{SO}(6)$, which I know is deffinitely not correct! For starters, $\mbox{SU}(4)$ is simply connected, while $\mbox{SO}(6)$ is not (my thanks to QMechanic for pointing this nice quick check out to me many questions ago!). $$ \quad $$ To conlude, I want to find the relation between $\mbox{SU}(4)$ and $\mbox{SO}(6)$, and I think that not being able to find the underlying manifold of either $\mbox{SU}(4)$ or $\mbox{SO}(6)$ is what is stopping me (of course, perhaps I'm taking the complete incorrect approach...). Thank you to anyone who reads this and can help me. I'm sorry if it's a little long, but I wanted to let you know what I've tried thinking about, and what my motivation for the question is.","I want to find the underlying manifolds of Lie Groups $\mbox{SU}(n)$ for general $n$. $$ \quad $$ My lecturer told us last year that the only n-spheres that admit a Lie group structure are $\mathbb{S}^1$ and $\mathbb{S}^3$. Moreover I see several question describing why this is so, such as here and here , and understand the arguments therein. However each Lie group must have some underlying manifold by definition. However I do not know how to find what the manifold is for any given Lie group. $$ \quad $$ My motivation for this question is to understand the Lie algebra relation $$ \mathfrak{su}(4) \simeq \mathfrak{so}(6) $$ and as such there is some relation between the Lie groups $\mbox{SU}(4)$ and $\mbox{SO}(6)$, with my neive guess being $$ \mbox{SU}(4) / \mathbb{Z}_2 \simeq \mbox{SO}(6) $$ I don't have any very good reason for this however, but it feels right. I note that $$ \mbox{dim}[\mbox{SU}(4)] = 15 \quad \mbox{ and } \quad \mbox{dim}[\mbox{SO}(6)] = 15$$ so we don't immediately think that no such relation should exist. Moreover, I'm encouraged by the relation $\mbox{SU}(2) / \mathbb{Z}_2 \simeq \mbox{SO}(3) $, which I understand and can calculate. Explicitly, one first notes that both $\mathfrak{su}(2)$ and $\mathfrak{so}(3)$ have the same Lie algebra, namely $$ [T_i, T_j ] = \varepsilon^{ijk} T_k $$ Then one shows that $\mbox{SU}(2)$ has the 3-sphere $\mathbb{S}^3$ as underlying manifold, since any $U \in \mbox{SU}(2)$ can be written like $$ U = a_0 I_2 + i \vec{a} \cdot \vec{\sigma} $$ with $$ a_0^2 + \vec{a} \cdot \vec{a} = 1 $$ and this is the equation for the unit 3-sphere $\mathbb{S}^3$, while it can be shown that $\mbox{SO}(3)$ has underlying manifold $\mathbb{RP}^3$, and it remains to note that $\mathbb{S}^3$ is a double cover of $\mathbb{RP}^3$, which motivates the quotient by $\mathbb{Z}_2$, leading to the result. Now, I have tried thinking about using this approach in my case of $\mbox{SU}(4)$ and $\mbox{SO}(6)$, but I make no progress. $$ \quad $$ Perhaps a related point, we can show that the action of $\mbox{SU}(2)$ on $\mathbb{C}^2 \simeq \mathbb{R}^4$ has as orbits 3-spheres $\mathbb{S}^3$ by considering the fact that that the action of $\mbox{SU}(2)$ on $\mathbb{C}^2$ preserves the Hilbert norm, giving a constraint $$ ||\vec{z}||^2 = |z_1|^2 + |z_2|^2 = x_1^2 +y_1^2 + x_2^2 +y_2^2 $$ for $\vec{z} = (z_1,z_2) = (x_1 + i y_1, x_2 + i y_2) \in \mathbb{C}^2$. Now this I have had success (I hope!) in generalising, and I find that the action of $\mbox{SU}(n)$ on $\mathbb{C}^n \simeq \mathbb{R}^{2n}$ should have as orbits (2n-1)-spheres $\mathbb{S}^{2n-1} \subset \mathbb{R}^{2n}$. I am unsure if this actually helps me with my original question however. $$ \quad $$ Finally, I'll note that my motivation for wanting to find a relation between $\mbox{SU}(4)$ and $\mbox{SO}(6)$ comes from studying the AdS/CFT correspondence (I'm a TP). In $\mathcal{N}=4$ Super-Yang-Mills theory we get one vector supermultiplet of states, which can be written as one $\mathcal{N}=1$ vector supermultiplet and three $\mathcal{N}=1$ chiral supermultiplet, consisting of a total of four gauge vector fields $A_{\mu}^i(x)$ and six scalar fields $\phi^{[ij]}(x)$ for $i = 1,2,3,4$ which then have an $\mbox{SU}(4)$ R-symmetry (an $\mathcal{N}=N$ supersymmetric field theory has an $\mbox{SU}(N)$ R-symmetry). However, in order to compare this to the type IIB superstring theory on $AdS_5 \times \mathbb{S}^5$ we need to match this $\mbox{SU}(4)$ R-symmetry with the $\mbox{SO}(6)$ rotation symmetry of the 5-sphere \mathbb{S}^5$. In the AdS/ CFT papers that I have read the TPs (who are not known for making accurate group theoretic statements! (See, for example, the top of page 30 and the bottom of page 72 of what is otherwise a brilliantly clear paper 0712.0689 ) ) simply write $\mbox{SU}(4) \simeq\mbox{SO}(6)$, which I know is deffinitely not correct! For starters, $\mbox{SU}(4)$ is simply connected, while $\mbox{SO}(6)$ is not (my thanks to QMechanic for pointing this nice quick check out to me many questions ago!). $$ \quad $$ To conlude, I want to find the relation between $\mbox{SU}(4)$ and $\mbox{SO}(6)$, and I think that not being able to find the underlying manifold of either $\mbox{SU}(4)$ or $\mbox{SO}(6)$ is what is stopping me (of course, perhaps I'm taking the complete incorrect approach...). Thank you to anyone who reads this and can help me. I'm sorry if it's a little long, but I wanted to let you know what I've tried thinking about, and what my motivation for the question is.",,"['abstract-algebra', 'algebraic-topology', 'lie-groups', 'lie-algebras', 'mathematical-physics']"
96,Left invertible matrices over rings with some special property,Left invertible matrices over rings with some special property,,Suppose $R$ is a ring in which every left invertible element is invertible. Does this condition imply that every left invertible matrix in $\mathrm{M}_{n\times n}(R)$ is necessarily invertible?,Suppose $R$ is a ring in which every left invertible element is invertible. Does this condition imply that every left invertible matrix in $\mathrm{M}_{n\times n}(R)$ is necessarily invertible?,,"['abstract-algebra', 'matrices', 'ring-theory']"
97,Ways to find the order of an element in a group,Ways to find the order of an element in a group,,"Is there a better way of finding the order of an element in a group other than circling until the identity is reached? Is there or CAN there be a better general ways of finding orders of elements? (if no, please, explain why there can't be any ways) An example I have is a multiplicative group of elements $Z_{20}$ under modulo 20. Do I have to circle over every element to find orders?","Is there a better way of finding the order of an element in a group other than circling until the identity is reached? Is there or CAN there be a better general ways of finding orders of elements? (if no, please, explain why there can't be any ways) An example I have is a multiplicative group of elements $Z_{20}$ under modulo 20. Do I have to circle over every element to find orders?",,"['abstract-algebra', 'group-theory', 'finite-groups']"
98,Every finite dimensional representation of an algebra has an irreducible sub representation,Every finite dimensional representation of an algebra has an irreducible sub representation,,"Let $V$ be a nonzero finite dimensional representation, i.e we have a homomorphism $\rho\colon A\rightarrow \text{End}_k(V)$, of an algebra $A$. I have to show that there is an irreducible sub representation. This is how wanted to do that: Let $v\in V$ and look at $W=\text{span}\{\rho(a)(v)\colon a\in A\}$. This is a lineair subspace of $V$ and by construction it is a sub representation. But it is not irreducible yet. I thought I should continue this process, so take again another vector in $W$ and consider the same construction of a sub representation. I don't understand how I should continue this or if this is going to help me solve this problem. I should also use somewhere the finiteness of the representation as it does not hold for infinite dimensional representations. I need help. Thanks.","Let $V$ be a nonzero finite dimensional representation, i.e we have a homomorphism $\rho\colon A\rightarrow \text{End}_k(V)$, of an algebra $A$. I have to show that there is an irreducible sub representation. This is how wanted to do that: Let $v\in V$ and look at $W=\text{span}\{\rho(a)(v)\colon a\in A\}$. This is a lineair subspace of $V$ and by construction it is a sub representation. But it is not irreducible yet. I thought I should continue this process, so take again another vector in $W$ and consider the same construction of a sub representation. I don't understand how I should continue this or if this is going to help me solve this problem. I should also use somewhere the finiteness of the representation as it does not hold for infinite dimensional representations. I need help. Thanks.",,['abstract-algebra']
99,Groups - Prove that every element equals inverse of inverse of element,Groups - Prove that every element equals inverse of inverse of element,,"This is my first proof about groups. Please feed back and criticise in every way (including style & language). Axiom names ( see Wikipedia ) are italicised . We use $^{-1}$ to denote inverse elements; $e$ denotes the identity element. Let $(G, \cdot)$ be a group. By $\textit{identity element}$, $G \ne \emptyset$. Now, let $a \in G$. By $\textit{inverse element}$, $a^{-1} \in G$ and $(a^{-1})^{-1} \in G$. It remains to prove that $(a^{-1})^{-1} = a$. \begin{equation*} \begin{split} a &= a \cdot e && \text{by }\textit{identity element} \\   &= a \cdot \Big(a^{-1} \cdot (a^{-1})^{-1}\Big) && \text{by }\textit{inverse element} \\   &= (a \cdot a^{-1}) \cdot (a^{-1})^{-1} && \text{by }\textit{associativity} \\   &= e \cdot (a^{-1})^{-1} && \text{by }\textit{inverse element} \\   &= (a^{-1})^{-1} && \text{by }\textit{identity element} \end{split} \end{equation*} QED PS: What I do know is that I have a personal preference for details and explicitness :-(","This is my first proof about groups. Please feed back and criticise in every way (including style & language). Axiom names ( see Wikipedia ) are italicised . We use $^{-1}$ to denote inverse elements; $e$ denotes the identity element. Let $(G, \cdot)$ be a group. By $\textit{identity element}$, $G \ne \emptyset$. Now, let $a \in G$. By $\textit{inverse element}$, $a^{-1} \in G$ and $(a^{-1})^{-1} \in G$. It remains to prove that $(a^{-1})^{-1} = a$. \begin{equation*} \begin{split} a &= a \cdot e && \text{by }\textit{identity element} \\   &= a \cdot \Big(a^{-1} \cdot (a^{-1})^{-1}\Big) && \text{by }\textit{inverse element} \\   &= (a \cdot a^{-1}) \cdot (a^{-1})^{-1} && \text{by }\textit{associativity} \\   &= e \cdot (a^{-1})^{-1} && \text{by }\textit{inverse element} \\   &= (a^{-1})^{-1} && \text{by }\textit{identity element} \end{split} \end{equation*} QED PS: What I do know is that I have a personal preference for details and explicitness :-(",,"['abstract-algebra', 'group-theory', 'soft-question', 'proof-writing', 'proof-verification']"
