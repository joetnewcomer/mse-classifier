,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Directly Calculating Birthday Paradox Probabilites,Directly Calculating Birthday Paradox Probabilites,,"I am trying to calculate the probability of at least 2 people sharing a birthday in a group of 4 people. I understand that calculating it as 1-P(no shared birthdays) is simpler, but I would like to understand the counting method by doing it directly. My attempt for $n=4$ is P = P(2 people) + P(3 people) + P(4 people) = $\frac{1}{365}\binom{4}{2}+\frac{1}{365^2}\binom{4}{3}+\frac{1}{365^3}\binom{4}{4}=0.0164$ ... but this does not match up with P = $1-\frac{364}{365}\frac{363}{365}\frac{362}{365}=0.163...$ What am I doing wrong in the direct calculation?","I am trying to calculate the probability of at least 2 people sharing a birthday in a group of 4 people. I understand that calculating it as 1-P(no shared birthdays) is simpler, but I would like to understand the counting method by doing it directly. My attempt for is P = P(2 people) + P(3 people) + P(4 people) = ... but this does not match up with P = What am I doing wrong in the direct calculation?",n=4 \frac{1}{365}\binom{4}{2}+\frac{1}{365^2}\binom{4}{3}+\frac{1}{365^3}\binom{4}{4}=0.0164 1-\frac{364}{365}\frac{363}{365}\frac{362}{365}=0.163...,['probability']
1,"UMVUE for $P(X_1>t)$ for some fixed $t>\mu$ when $X_i \sim \operatorname{Exp}(\sigma, \mu)$",UMVUE for  for some fixed  when,"P(X_1>t) t>\mu X_i \sim \operatorname{Exp}(\sigma, \mu)","$X_1,\ldots,X_n$ is a sample from the density $$f_X(x)=\frac{1}{\sigma}e^{-\frac{x-\mu}{\sigma}}\quad,\,x>\mu$$ I know form a previous step that the UMVUE for $\sigma$ and $\mu$ is $\frac{1}{n-1}(\sum_iX_i-nX_{(1)})$ and $\frac{n}{n-1}X_{(1)}-\frac{1}{n-1}\bar{X}$ . Also, I know that $P(X_1>t) = e^{-\frac{(x-\mu)}{\sigma}}$ . My question is if there is a way I can use this information to find the UMVUE for $P(X_1>t)$ ? I tried to use the Rao-Blackwell theorem, with $h(X_1) = 1 \text{ if } X_1>t$ 0 OW unbiased estimator for $e^{-\frac{(x-\mu)}{\sigma}}$ . However, the computations for the estimator became tedious and couldn't get to a final answer.","is a sample from the density I know form a previous step that the UMVUE for and is and . Also, I know that . My question is if there is a way I can use this information to find the UMVUE for ? I tried to use the Rao-Blackwell theorem, with 0 OW unbiased estimator for . However, the computations for the estimator became tedious and couldn't get to a final answer.","X_1,\ldots,X_n f_X(x)=\frac{1}{\sigma}e^{-\frac{x-\mu}{\sigma}}\quad,\,x>\mu \sigma \mu \frac{1}{n-1}(\sum_iX_i-nX_{(1)}) \frac{n}{n-1}X_{(1)}-\frac{1}{n-1}\bar{X} P(X_1>t) = e^{-\frac{(x-\mu)}{\sigma}} P(X_1>t) h(X_1) = 1 \text{ if } X_1>t e^{-\frac{(x-\mu)}{\sigma}}","['probability', 'statistics', 'probability-distributions', 'statistical-inference', 'parameter-estimation']"
2,The probability of repeating a test with a 30% chance of being wrong.,The probability of repeating a test with a 30% chance of being wrong.,,"I got in a bit of an discussion with my dad about this and thought about it a lot. Would like some insight. So the question: if you have a test (ex: a virus antibody test) that returns positive or negative and has a 30% chance of having an incorrect result, how many tests would you need to make to have significant confidence (>99%) that the overall mode of all tests is correct? My dad argued that repeating tests does not increase confidence and I thought that it would.","I got in a bit of an discussion with my dad about this and thought about it a lot. Would like some insight. So the question: if you have a test (ex: a virus antibody test) that returns positive or negative and has a 30% chance of having an incorrect result, how many tests would you need to make to have significant confidence (>99%) that the overall mode of all tests is correct? My dad argued that repeating tests does not increase confidence and I thought that it would.",,['probability']
3,Solving a functional equation in CDF's of probability distributions,Solving a functional equation in CDF's of probability distributions,,"Reading a paper I've come across the following functional equation for unknown CDF's $F_1, F_2$ of centered probability distributions $\mu_1, \mu_2$ with variance $1$ : $$F^{-1}(G_2(x+y)) = F_1^{-1}(G_1(x))+ F_2^{-1}(G_1(y))\qquad \text{for all} \ (x,y) \in \mathbb{R}^2$$ where $G_i$ is the CDF of a centered gaussian with Variance $i$ and $F$ is the CDF of the convolution $\mu_1 \ast \mu_2$ . The unique solution is actually $F_1 = F_2 = G_1$ but I've not been able to proof that. I (think I) can show that $F_1 = F_2$ : $$F_1^{-1}(G_1(x))+ F_2^{-1}(G_1(y)) = F^{-1}(G_2(x+y)) = F^{-1}(G_2(y+x)) = F_1^{-1}(G_1(y))+ F_2^{-1}(G_1(x))$$ so $$F_1^{-1}(G_1(x)) - F_2^{-1}(G_1(x)) = F_1^{-1}(G_1(y)) - F_2^{-1}(G_1(y))$$ which means, that $F_1^{-1}(G_1(x)) - F_2^{-1}(G_1(x))$ is constant, since the right-hand side does not depend on $x$ . If the difference was not $0$ then either $\mu_1$ or $\mu_2$ is not centered since, $\mathbb{E}[\mu_i] = \int_0^1 F_i^{-1}(y)dy$ , so $F_1 = F_2$ . Is this argument correct? How can I proceed to show uniqueness of solution? You can find the paper here - the functional equation is part of the proof of Theorem 2 on page 49.","Reading a paper I've come across the following functional equation for unknown CDF's of centered probability distributions with variance : where is the CDF of a centered gaussian with Variance and is the CDF of the convolution . The unique solution is actually but I've not been able to proof that. I (think I) can show that : so which means, that is constant, since the right-hand side does not depend on . If the difference was not then either or is not centered since, , so . Is this argument correct? How can I proceed to show uniqueness of solution? You can find the paper here - the functional equation is part of the proof of Theorem 2 on page 49.","F_1, F_2 \mu_1, \mu_2 1 F^{-1}(G_2(x+y)) = F_1^{-1}(G_1(x))+ F_2^{-1}(G_1(y))\qquad \text{for all} \ (x,y) \in \mathbb{R}^2 G_i i F \mu_1 \ast \mu_2 F_1 = F_2 = G_1 F_1 = F_2 F_1^{-1}(G_1(x))+ F_2^{-1}(G_1(y)) = F^{-1}(G_2(x+y)) = F^{-1}(G_2(y+x)) = F_1^{-1}(G_1(y))+ F_2^{-1}(G_1(x)) F_1^{-1}(G_1(x)) - F_2^{-1}(G_1(x)) = F_1^{-1}(G_1(y)) - F_2^{-1}(G_1(y)) F_1^{-1}(G_1(x)) - F_2^{-1}(G_1(x)) x 0 \mu_1 \mu_2 \mathbb{E}[\mu_i] = \int_0^1 F_i^{-1}(y)dy F_1 = F_2","['probability', 'measure-theory', 'functional-equations']"
4,"Probability of $X > Y$ given that $X, Y$ are i.i.d. continuous r.v.s",Probability of  given that  are i.i.d. continuous r.v.s,"X > Y X, Y","Can someone please explain why is $P(X > Y) = \frac{1}{2}$ , when $X, Y$ are i.i.d. continuous random variables? I have seen people use the symmetry argument to justify this answer. The argument goes as follows: there are two ways of arranging two numbers $x$ and $y$ , and out of these arrangements only one has $x > y$ . So, the probability using symmetry is $0.5$ . I don't understand this conclusion. Doesn't this argument make an assumption that the values of $X$ and $Y$ that are drawn are not equal? To take a more concrete example, if we assume $X, Y$ are standard normal, wouldn't the sample space be divided into three events: $X > Y, X < Y, X = Y$ ? Based on this, we can say that $X > Y$ and $X < Y$ must be equal using symmetry, and let's call this value $\alpha$ . So, $2\alpha + P(X=Y) = 1$ . Clearly, $\alpha < 0.5$ , contrary to the first argument. So, which is the correct argument and why? Edit: based on the comments I am adding the calculations for $X=Y$ in case of normal distributions. Can someone point out the mistake? Thanks! $P(X=Y) = \int_{-\infty}^{\infty} P(X=Y|Y=y) P(Y=y) dy$ $P(X=Y) = \int_{-\infty}^{\infty} \frac{1}{2\pi} e^{-y^{2}} dy$ $P(X=Y) = \frac{1}{2\sqrt\pi}$ . Intuitively, the symmetry argument feels like an approximation (probably a very good one). Imagine we have a bivariate normal distribution, which is formed using $X$ and $Y$ . $P(X>Y)$ represents the region below the line $X=Y$ (in the 1st quadrant). Similarly, we can argue about the values in the other 3 quadrants. By geometry, the area of line is zero (because the line has no width?), and hence you arrive at the 1D analogy that the probability it takes a specific value is zero. Still not sure though why it doesn't show up in the calculations above. Edit: I realize the mistake I made in the above calculations. Going from step 1 to step 2, when I replaced $P(X=Y|Y=y)$ with $f_{X}(y)$ , this is wrong. As pointed out in the comments and answer below, this must be equal to zero. I confused (/abused) the notation for the discrete and continuous cases. Thanks everyone for an interesting discussion.","Can someone please explain why is , when are i.i.d. continuous random variables? I have seen people use the symmetry argument to justify this answer. The argument goes as follows: there are two ways of arranging two numbers and , and out of these arrangements only one has . So, the probability using symmetry is . I don't understand this conclusion. Doesn't this argument make an assumption that the values of and that are drawn are not equal? To take a more concrete example, if we assume are standard normal, wouldn't the sample space be divided into three events: ? Based on this, we can say that and must be equal using symmetry, and let's call this value . So, . Clearly, , contrary to the first argument. So, which is the correct argument and why? Edit: based on the comments I am adding the calculations for in case of normal distributions. Can someone point out the mistake? Thanks! . Intuitively, the symmetry argument feels like an approximation (probably a very good one). Imagine we have a bivariate normal distribution, which is formed using and . represents the region below the line (in the 1st quadrant). Similarly, we can argue about the values in the other 3 quadrants. By geometry, the area of line is zero (because the line has no width?), and hence you arrive at the 1D analogy that the probability it takes a specific value is zero. Still not sure though why it doesn't show up in the calculations above. Edit: I realize the mistake I made in the above calculations. Going from step 1 to step 2, when I replaced with , this is wrong. As pointed out in the comments and answer below, this must be equal to zero. I confused (/abused) the notation for the discrete and continuous cases. Thanks everyone for an interesting discussion.","P(X > Y) = \frac{1}{2} X, Y x y x > y 0.5 X Y X, Y X > Y, X < Y, X = Y X > Y X < Y \alpha 2\alpha + P(X=Y) = 1 \alpha < 0.5 X=Y P(X=Y) = \int_{-\infty}^{\infty} P(X=Y|Y=y) P(Y=y) dy P(X=Y) = \int_{-\infty}^{\infty} \frac{1}{2\pi} e^{-y^{2}} dy P(X=Y) = \frac{1}{2\sqrt\pi} X Y P(X>Y) X=Y P(X=Y|Y=y) f_{X}(y)","['probability', 'probability-distributions', 'normal-distribution']"
5,"Showing that $P (|X_1| < \Gamma , |X_2| < \Gamma)$ is increasing in $|\rho|$",Showing that  is increasing in,"P (|X_1| < \Gamma , |X_2| < \Gamma) |\rho|","Assume $(X_1,X_2 )^T$ is mean $0$ bivariate normal distributed with covariance matrix $\Sigma = \left (\begin{matrix} 1 & \rho \\ \rho & 1 \end{matrix} \right)$ and let $\Gamma > 0$ a positive constant. Then i would like to show that $P (|X_1| < \Gamma , |X_2| < \Gamma)$ is increasing in $|\rho|$ . Any tips? I already tried to simply use the integral representation of the probability, but could not show it.","Assume is mean bivariate normal distributed with covariance matrix and let a positive constant. Then i would like to show that is increasing in . Any tips? I already tried to simply use the integral representation of the probability, but could not show it.","(X_1,X_2 )^T 0 \Sigma = \left (\begin{matrix} 1 & \rho \\ \rho & 1 \end{matrix} \right) \Gamma > 0 P (|X_1| < \Gamma , |X_2| < \Gamma) |\rho|","['probability', 'normal-distribution', 'correlation']"
6,Conditional Probability: John and Mary's registration cards,Conditional Probability: John and Mary's registration cards,,"I am trying to solve a problem from a Dartmouth textbook ( https://math.dartmouth.edu/~prob/prob/prob.pdf ) Chapter 4.1 Ex 53. Disclaimer: I am not a student. I am just studying some probability questions from the text book. Here is the question: The registrar is carrying John and Mary’s registration cards and drops them in a puddle. When he pickes them up he cannot read the names but on the first card he picked up he can make out Mathematics 23 and Government 35, and on the second card he can make out only Mathematics 23. He asks you if you can help him decide which card belongs to Mary. You know that Mary likes government but does not like mathematics. You know nothing about John and assume that he is just a typical Dartmouth student. From this you estimate: P (Mary takes Government 35) = .5 P (Mary takes Mathematics 23) = .1 P (John takes Government 35) = .3 P (John takes Mathematics 23) = .2 Assume that their choices for courses are independent events. Show that the card with Mathematics 23 and Government 35 showing is more likely to be Mary’s than John’s. The conjunction fallacy referred to in the Linda problem would be to assume that the event “Mary takes Mathematics 23 and Government 35” is more likely than the event “Mary takes Mathematics 23.” Why are we not making this fallacy here? Here is the solution from the manual: We assume that John and Mary sign up for two courses. Their cards are dropped, one of the cards gets stepped on, and only one course can be read on this card. Call card I the card that was not stepped on and on which the registrar can read government 35 and mathematics 23; call card II the card that was stepped on and on which he can just read mathematics 23. There are four possibilities for these two cards. They are: Card I          Card II          Prob.  Cond. Prob. Mary(gov,math)  John(gov, math)  .0015  .224 Mary(gov,math)  John(other,math) .0025  .373 John(gov,math)  Mary(gov,math)   .0015  .224 John(gov,math)  Mary(other,math) .0012  .179 In the third column we have written the probability that each case will occur. For example, for the first one we compute the probability that the students will take the appropriate courses: .5 × .1 × .3 × .2 = .0030 and then we multiply by 1/2, the probability that it was John’s card that was stepped on. Now to get the conditional probabilities we must renormalize these probabilities so that they add up to one. In this way we obtain the results in the last column. From this we see that the probability that card I is Mary’s is .597 and that card I is John’s is .403, so it is more likely that that the card on which the registrar sees Mathematics 23 and Government 35 is Mary’s. My question: It seems like the solution calculates the Probability of ""Other"" by Prob(John takes other) = 1 - Prob(John takes gov) - Prob(John takes math) = 1 - 0.3 - 0.2 = 0.5 See row 2: Mary(gov,math)  John(other,math), this is calculated as 0.5*0.1*0.5*0.2 / 2 = 0.0025 This subtraction above implies ""John takes gov"" is exclusive from ""John takes math"". But later they are multiplying Prob(John takes gov)*Prob(John takes math) to get the joint probability. I find this problem/solution not making sense. What do you guys think? Alternatively, how would you best understand the solution to this question to make the most sense out of it?","I am trying to solve a problem from a Dartmouth textbook ( https://math.dartmouth.edu/~prob/prob/prob.pdf ) Chapter 4.1 Ex 53. Disclaimer: I am not a student. I am just studying some probability questions from the text book. Here is the question: The registrar is carrying John and Mary’s registration cards and drops them in a puddle. When he pickes them up he cannot read the names but on the first card he picked up he can make out Mathematics 23 and Government 35, and on the second card he can make out only Mathematics 23. He asks you if you can help him decide which card belongs to Mary. You know that Mary likes government but does not like mathematics. You know nothing about John and assume that he is just a typical Dartmouth student. From this you estimate: P (Mary takes Government 35) = .5 P (Mary takes Mathematics 23) = .1 P (John takes Government 35) = .3 P (John takes Mathematics 23) = .2 Assume that their choices for courses are independent events. Show that the card with Mathematics 23 and Government 35 showing is more likely to be Mary’s than John’s. The conjunction fallacy referred to in the Linda problem would be to assume that the event “Mary takes Mathematics 23 and Government 35” is more likely than the event “Mary takes Mathematics 23.” Why are we not making this fallacy here? Here is the solution from the manual: We assume that John and Mary sign up for two courses. Their cards are dropped, one of the cards gets stepped on, and only one course can be read on this card. Call card I the card that was not stepped on and on which the registrar can read government 35 and mathematics 23; call card II the card that was stepped on and on which he can just read mathematics 23. There are four possibilities for these two cards. They are: Card I          Card II          Prob.  Cond. Prob. Mary(gov,math)  John(gov, math)  .0015  .224 Mary(gov,math)  John(other,math) .0025  .373 John(gov,math)  Mary(gov,math)   .0015  .224 John(gov,math)  Mary(other,math) .0012  .179 In the third column we have written the probability that each case will occur. For example, for the first one we compute the probability that the students will take the appropriate courses: .5 × .1 × .3 × .2 = .0030 and then we multiply by 1/2, the probability that it was John’s card that was stepped on. Now to get the conditional probabilities we must renormalize these probabilities so that they add up to one. In this way we obtain the results in the last column. From this we see that the probability that card I is Mary’s is .597 and that card I is John’s is .403, so it is more likely that that the card on which the registrar sees Mathematics 23 and Government 35 is Mary’s. My question: It seems like the solution calculates the Probability of ""Other"" by Prob(John takes other) = 1 - Prob(John takes gov) - Prob(John takes math) = 1 - 0.3 - 0.2 = 0.5 See row 2: Mary(gov,math)  John(other,math), this is calculated as 0.5*0.1*0.5*0.2 / 2 = 0.0025 This subtraction above implies ""John takes gov"" is exclusive from ""John takes math"". But later they are multiplying Prob(John takes gov)*Prob(John takes math) to get the joint probability. I find this problem/solution not making sense. What do you guys think? Alternatively, how would you best understand the solution to this question to make the most sense out of it?",,['probability']
7,What is the stationary distribution of a bishop's legal moves in chess?,What is the stationary distribution of a bishop's legal moves in chess?,,"I have been asked to consider the following questions and I'm not sure what to do. Can anyone help out? Consider the random movement of a knight on a chessboard. At each time step, we pick one of the bishop’s legal moves at random. (1) What is the stationary distribution? (2) What is the expected number of moves to return to the corner (1,1) when we start there? Any help would be much appreciated!","I have been asked to consider the following questions and I'm not sure what to do. Can anyone help out? Consider the random movement of a knight on a chessboard. At each time step, we pick one of the bishop’s legal moves at random. (1) What is the stationary distribution? (2) What is the expected number of moves to return to the corner (1,1) when we start there? Any help would be much appreciated!",,"['probability', 'probability-theory']"
8,Probability concept that distinguishes likelihood of sequences 0110101011101... and 000000000000...?,Probability concept that distinguishes likelihood of sequences 0110101011101... and 000000000000...?,,"Say we have a coin and want to decide if it is fair or not. We flip it many times. Consider two cases. Say the result is a sequence like 0110101011101... The result is 000000000000... In the first case the assumption that the coin is fair sounds reasonable, while in the the second the coin is obviously completely biased. However, for a truly fair coin the probabilities of the two sequences are the identical. What is then the concept that distinguishes the first one as more likely? How does one quantify that? Consider also the third case The result is 010101010101010... This actually does not look like a coin at all, but it seems to pass naive tests which boil down to comparing number of zeros to number of ones. Is there a sense in which it is less random then (1)? Or I have to invent a new rule if somebody gives me a more cleverly crafted sequence?","Say we have a coin and want to decide if it is fair or not. We flip it many times. Consider two cases. Say the result is a sequence like 0110101011101... The result is 000000000000... In the first case the assumption that the coin is fair sounds reasonable, while in the the second the coin is obviously completely biased. However, for a truly fair coin the probabilities of the two sequences are the identical. What is then the concept that distinguishes the first one as more likely? How does one quantify that? Consider also the third case The result is 010101010101010... This actually does not look like a coin at all, but it seems to pass naive tests which boil down to comparing number of zeros to number of ones. Is there a sense in which it is less random then (1)? Or I have to invent a new rule if somebody gives me a more cleverly crafted sequence?",,['probability']
9,Expected value of number of steps until range reduced to a given fraction,Expected value of number of steps until range reduced to a given fraction,,"First time questioner here.  I'm working on a problem from a recreational math website, but trying to understand an easier version first.  Most such problems are discrete, and the continuous nature of this one is confusing me. The simpler problem: we start with the range $[0,1]$ .  Pick a random number uniformly from that range, and remove everything above your pick.  Do that repeatedly, picking a random number from the range that's left, until the remaining range drops below some fraction $1/x$ .  What's the average number of picks required? Consider a sequence of rvs $X_1, X_2, \dots$ , where $X_1 \sim U(0,1)$ and $X_i \sim U(0,X_{i-1})$ for $i \ge 2$ .  We want to know the expected number of steps it will take until an $X_n$ is picked below some fraction $1/x$ .  That is, given $1 \gt X_1 \gt X_2 \gt \dots \gt X_{n-1} \gt \frac 1 x \gt X_n$ , what's the expected value of $n$ ? I know the closed form for this simpler problem, thanks to Monte Carlo simulations.  Playing around with various $x$ and running for billions of simulations, the counts for each possible $n$ are easy to pick out in closed form, and shows (with Wolfram Alpha's help) that $$\mathbb{E}[n] = \sum_{n=1}^\infty n \frac{(\log x)^{n-1}} {(n-1)! x} = \log x + 1$$ So $P(n = 1) = \frac 1 x$ , which is obvious. $P(n = 2) = \frac {\log x} x$ , which I think I can get as follows.  The PDF for $X_2$ is $1/{X_1}$ , so the CDF is $P(X_2 \lt t) = t/X_1$ .  I want to know $P(X_2 \lt \frac 1 x)$ , so I need to integrate that over the range of possible $X_1$ : $$P(X_2 < 1/x < X_1) = \int_{1/x}^1 \frac{dX_1}{x X_1} = \frac{\log x} x$$ But now, how do I get that $P(X_3 < 1/x < X_2 < X_1 < 1) = (\log x)^2/(2x)$ ?  I suspect I need a double integral on $dX_2\ dX_1$ , but what?  The way the log appears in $\mathbb{E}[n]$ makes it look like the $\log x$ gets introduced via one of the integration bounds, but that can't be right, can it? My last college stats class was 40 years ago, and my knowledge since then is mostly driven by solving these website questions.  So that knowledge is really spotty.  The fact that $\mathbb{E}[n]$ looks like a power series suggests this has to do with moment generating functions, I guess, but I'm really out of my depths there. I've actually ""solved"" the full problem by using a discrete analogue, starting with $4\cdot 10^{10}$ stones and finding $\mathbb{E}[n]$ to reduce that to 1/40th the original count.  That used logic related to 2025645 , where harmonic numbers are in play.  But that took too long and was off by 8 in the required 10th decimal place.  A fast answer that doesn't involve guessing the final digits needs a continuous method, which is eluding me.","First time questioner here.  I'm working on a problem from a recreational math website, but trying to understand an easier version first.  Most such problems are discrete, and the continuous nature of this one is confusing me. The simpler problem: we start with the range .  Pick a random number uniformly from that range, and remove everything above your pick.  Do that repeatedly, picking a random number from the range that's left, until the remaining range drops below some fraction .  What's the average number of picks required? Consider a sequence of rvs , where and for .  We want to know the expected number of steps it will take until an is picked below some fraction .  That is, given , what's the expected value of ? I know the closed form for this simpler problem, thanks to Monte Carlo simulations.  Playing around with various and running for billions of simulations, the counts for each possible are easy to pick out in closed form, and shows (with Wolfram Alpha's help) that So , which is obvious. , which I think I can get as follows.  The PDF for is , so the CDF is .  I want to know , so I need to integrate that over the range of possible : But now, how do I get that ?  I suspect I need a double integral on , but what?  The way the log appears in makes it look like the gets introduced via one of the integration bounds, but that can't be right, can it? My last college stats class was 40 years ago, and my knowledge since then is mostly driven by solving these website questions.  So that knowledge is really spotty.  The fact that looks like a power series suggests this has to do with moment generating functions, I guess, but I'm really out of my depths there. I've actually ""solved"" the full problem by using a discrete analogue, starting with stones and finding to reduce that to 1/40th the original count.  That used logic related to 2025645 , where harmonic numbers are in play.  But that took too long and was off by 8 in the required 10th decimal place.  A fast answer that doesn't involve guessing the final digits needs a continuous method, which is eluding me.","[0,1] 1/x X_1, X_2, \dots X_1 \sim U(0,1) X_i \sim U(0,X_{i-1}) i \ge 2 X_n 1/x 1 \gt X_1 \gt X_2 \gt \dots \gt X_{n-1} \gt \frac 1 x \gt X_n n x n \mathbb{E}[n] = \sum_{n=1}^\infty n \frac{(\log x)^{n-1}} {(n-1)! x} = \log x + 1 P(n = 1) = \frac 1 x P(n = 2) = \frac {\log x} x X_2 1/{X_1} P(X_2 \lt t) = t/X_1 P(X_2 \lt \frac 1 x) X_1 P(X_2 < 1/x < X_1) = \int_{1/x}^1 \frac{dX_1}{x X_1} = \frac{\log x} x P(X_3 < 1/x < X_2 < X_1 < 1) = (\log x)^2/(2x) dX_2\ dX_1 \mathbb{E}[n] \log x \mathbb{E}[n] 4\cdot 10^{10} \mathbb{E}[n]","['probability', 'expected-value', 'uniform-distribution']"
10,supremum of expectation = expectation of supremum?,supremum of expectation = expectation of supremum?,,"In supremum of expectation $\le$ expectation of supremum? , can we have the reverse inequality up to a constant? Like $$ \underset{y\in \mathcal Y} \sup \mathbb E\big[f(X,y)\big] \ge C\mathbb E\big[\underset{y\in \mathcal Y} \sup f(X,y)\big] $$ for some $C>0?$ Or, having some conditions on $f$ , can we have $$ \underset{y\in \mathcal Y} \sup \mathbb E\big[f(X,y)\big] = \mathbb E\big[\underset{y\in \mathcal Y} \sup f(X,y)\big]? $$ Let us say $f(X,y)=X^Ty.$ Do we have an equality for this? Supremum of expectation equals expectation of supremum? : this post seems to be addressing this, but not sure if it's correct!","In supremum of expectation $\le$ expectation of supremum? , can we have the reverse inequality up to a constant? Like for some Or, having some conditions on , can we have Let us say Do we have an equality for this? Supremum of expectation equals expectation of supremum? : this post seems to be addressing this, but not sure if it's correct!"," \underset{y\in \mathcal Y} \sup \mathbb E\big[f(X,y)\big] \ge C\mathbb E\big[\underset{y\in \mathcal Y} \sup f(X,y)\big]  C>0? f  \underset{y\in \mathcal Y} \sup \mathbb E\big[f(X,y)\big] = \mathbb E\big[\underset{y\in \mathcal Y} \sup f(X,y)\big]?  f(X,y)=X^Ty.","['probability', 'supremum-and-infimum', 'expected-value']"
11,Proving $\frac1n\sum_{i=1}^na_i(B_i-\frac12)\stackrel{\text{a.s.}}\longrightarrow 0$ where $B_i$s are i.i.d Bernoulli$(\frac12)$,Proving  where s are i.i.d Bernoulli,\frac1n\sum_{i=1}^na_i(B_i-\frac12)\stackrel{\text{a.s.}}\longrightarrow 0 B_i (\frac12),"Problem: Let $\{B_n\}$ be a sequence of independent, identically distributed Bernoulli random variables of parameter $p=\frac12$ . Let $\{a_n\}$ be a non-negative, non-random sequence such that $\sup\limits_{n\geq0}\frac1n\sum\limits_{i=1}^na_i^2<\infty$ and $\frac1n\sum\limits_{i=1}^{n}a_i$ converges. Prove that $\frac1n\sum\limits_{i=1}^na_i(B_i-\frac12)$ converges to zero almost surely. This is an exercise in the section of ""strong law of large numbers"". But I only managed to prove the case when $\{a_n\}$ is bounded. Any help is appreciated!!","Problem: Let be a sequence of independent, identically distributed Bernoulli random variables of parameter . Let be a non-negative, non-random sequence such that and converges. Prove that converges to zero almost surely. This is an exercise in the section of ""strong law of large numbers"". But I only managed to prove the case when is bounded. Any help is appreciated!!",\{B_n\} p=\frac12 \{a_n\} \sup\limits_{n\geq0}\frac1n\sum\limits_{i=1}^na_i^2<\infty \frac1n\sum\limits_{i=1}^{n}a_i \frac1n\sum\limits_{i=1}^na_i(B_i-\frac12) \{a_n\},"['probability', 'probability-theory', 'law-of-large-numbers']"
12,Probability of euclidean distance between two random points inside a unit circle/sphere greater than 1,Probability of euclidean distance between two random points inside a unit circle/sphere greater than 1,,"Problem: Say there are two points inside the circle; A and B , and they are both randomly drawn according to a uniform distribution where the boundary is the circumference of the unit circle/the surface of the unit sphere. What's the probability that the euclidean distance between two randomly drawn points inside a unit circle/sphere greater than 1? This question has two versions; the 2D one and the 3D one. I have almost gotten down the expression of the integral in 2D one, but I still get stuck at the late stage of the problem, I haven't tried the 3-D version just yet, but I guess I will get stuck at a similar stage. The following is my attempt on the 2-D version of the problem: Phase 1: for the sake of simplicity, we can ""fix"" the angle θ of A to a particular fixed value θa and only vary its r value in the polar coordinate system, so A could be (0,θa), (0.2,θa), (1,θa) etc.   For B, we can vary everything including radius r and the angle θ of another point `B`. Phase2: The required probability should be equal to the sum of all of the conditional probability from r=0 to r= 1, where each increment of r is very very small: ΣP{|A - B| > 1 | A= (r, θa)  } Upon taking this limiting process to the sum, this becomes a definite integral over the conditional probability density function from r=0 to r=1. This is where I got stuck, I don't know how to transform the conditional probability to the conditional pdf inside the definite integral and possibly integrate it. And after this 2-D version, the 3-D version is gonna be another beast that I need help in order to deal with that. Note: These are the pictures of my drafts and my guesses, not sure whether they are helpful.","Problem: Say there are two points inside the circle; A and B , and they are both randomly drawn according to a uniform distribution where the boundary is the circumference of the unit circle/the surface of the unit sphere. What's the probability that the euclidean distance between two randomly drawn points inside a unit circle/sphere greater than 1? This question has two versions; the 2D one and the 3D one. I have almost gotten down the expression of the integral in 2D one, but I still get stuck at the late stage of the problem, I haven't tried the 3-D version just yet, but I guess I will get stuck at a similar stage. The following is my attempt on the 2-D version of the problem: Phase 1: for the sake of simplicity, we can ""fix"" the angle θ of A to a particular fixed value θa and only vary its r value in the polar coordinate system, so A could be (0,θa), (0.2,θa), (1,θa) etc.   For B, we can vary everything including radius r and the angle θ of another point `B`. Phase2: The required probability should be equal to the sum of all of the conditional probability from r=0 to r= 1, where each increment of r is very very small: ΣP{|A - B| > 1 | A= (r, θa)  } Upon taking this limiting process to the sum, this becomes a definite integral over the conditional probability density function from r=0 to r=1. This is where I got stuck, I don't know how to transform the conditional probability to the conditional pdf inside the definite integral and possibly integrate it. And after this 2-D version, the 3-D version is gonna be another beast that I need help in order to deal with that. Note: These are the pictures of my drafts and my guesses, not sure whether they are helpful.",,"['probability', 'probability-distributions', 'definite-integrals', 'conditional-probability', 'geometric-probability']"
13,Probability of hitting a four in cricket,Probability of hitting a four in cricket,,"Based on historical data, I calculated the probability of hitting a four (a type of shot) in cricket in one ball to be 0.114 (11.4%) [total number of fours / total number of balls]. In this case, how would I calculate the probability of a certain player hitting F fours in B balls? I tried simply multiplying the probability per ball by the number of balls, but this at times gives results far greater than 1 (when the number of fours is more than expected). Thanks for the help.","Based on historical data, I calculated the probability of hitting a four (a type of shot) in cricket in one ball to be 0.114 (11.4%) [total number of fours / total number of balls]. In this case, how would I calculate the probability of a certain player hitting F fours in B balls? I tried simply multiplying the probability per ball by the number of balls, but this at times gives results far greater than 1 (when the number of fours is more than expected). Thanks for the help.",,"['probability', 'statistics', 'data-analysis']"
14,Probability of getting a sufficiently long piece from multiple stick breaking,Probability of getting a sufficiently long piece from multiple stick breaking,,"This question asks: Start with a stick of length $1$ . Repeatedly remove some fraction $U$ of the remaining stick, where $U$ is uniform in $[0,1]$ . What is the probability that at least one of the removed pieces has length at least $\frac12$ ? Eventually I managed to solve it, but the result was not very enlightening. Thus I present here a generalisation of the question where $\frac12$ is replaced with an arbitrary $0\le x\le1$ . Let $f(x)$ be the probability that we eventually break off a stick of length at least $x$ ; it has been shown that for $\frac12\le x\le1$ , $f(x)=-\ln x$ . What, then, is $f(x)$ for $0\le x\le\frac12$ ? This generalisation is more difficult because now we can cut off more than one stick longer than $x$ . Let's use joriki's approach to the source question: when $x\le\frac12$ either we cut off a piece longer than $x$ at the start, with probability $1-x$ , or we leave a stick of length $t$ and replace $x$ with $x/t$ : $$f(x)=1-x+\int_{1-x}^1f(x/t)\,dt$$ This is the same formula as in joriki's answer except that the lower bound $x$ has become $1-x$ . We can make the same manipulations that follow there to  get $$f(x)=1-x+x\int_x^{x/(1-x)}\frac{f(u)}{u^2}\,du$$ $$1-f(x)=x\left(1-\int_x^{x/(1-x)}\frac{f(u)}{u^2}\,du\right)$$ and eventually the functional differential equation $$x(1-x)^2f''(x)=f'\left(\frac x{1-x}\right)-f'(x)(1-x)^2$$ but how would I proceed from here? I've determined the following approximate values for $f(x)$ with one million trials for each $x$ . .49 .712676 .48 .732251 .47 .751341 .46 .769896 .45 .787595 .44 .805675 .43 .822355 .42 .838964 .41 .854620 .40 .869991 .39 .883803 .38 .897808 .37 .910511 .36 .923427 .35 .934614 .34 .945107 .33 .954406 .32 .963026 .31 .969796 .30 .976313 .29 .981963 .28 .986094 .27 .989759 .26 .992816 .25 .995101 .24 .996743 .23 .997929 .22 .998779 .21 .999327 .20 .999609 .19 .999815 .18 .999924 .17 .999958 .16 .999990 .15 .999995 <=.14 1.000000","This question asks: Start with a stick of length . Repeatedly remove some fraction of the remaining stick, where is uniform in . What is the probability that at least one of the removed pieces has length at least ? Eventually I managed to solve it, but the result was not very enlightening. Thus I present here a generalisation of the question where is replaced with an arbitrary . Let be the probability that we eventually break off a stick of length at least ; it has been shown that for , . What, then, is for ? This generalisation is more difficult because now we can cut off more than one stick longer than . Let's use joriki's approach to the source question: when either we cut off a piece longer than at the start, with probability , or we leave a stick of length and replace with : This is the same formula as in joriki's answer except that the lower bound has become . We can make the same manipulations that follow there to  get and eventually the functional differential equation but how would I proceed from here? I've determined the following approximate values for with one million trials for each . .49 .712676 .48 .732251 .47 .751341 .46 .769896 .45 .787595 .44 .805675 .43 .822355 .42 .838964 .41 .854620 .40 .869991 .39 .883803 .38 .897808 .37 .910511 .36 .923427 .35 .934614 .34 .945107 .33 .954406 .32 .963026 .31 .969796 .30 .976313 .29 .981963 .28 .986094 .27 .989759 .26 .992816 .25 .995101 .24 .996743 .23 .997929 .22 .998779 .21 .999327 .20 .999609 .19 .999815 .18 .999924 .17 .999958 .16 .999990 .15 .999995 <=.14 1.000000","1 U U [0,1] \frac12 \frac12 0\le x\le1 f(x) x \frac12\le x\le1 f(x)=-\ln x f(x) 0\le x\le\frac12 x x\le\frac12 x 1-x t x x/t f(x)=1-x+\int_{1-x}^1f(x/t)\,dt x 1-x f(x)=1-x+x\int_x^{x/(1-x)}\frac{f(u)}{u^2}\,du 1-f(x)=x\left(1-\int_x^{x/(1-x)}\frac{f(u)}{u^2}\,du\right) x(1-x)^2f''(x)=f'\left(\frac x{1-x}\right)-f'(x)(1-x)^2 f(x) x","['probability', 'functional-equations']"
15,"A Stardew Valley tree has a $20\%$ chance of growing each day. What are the odds it will grow at least $2$, $3$, or $4$ times in $d$ days?","A Stardew Valley tree has a  chance of growing each day. What are the odds it will grow at least , , or  times in  days?",20\% 2 3 4 d,"I'm playing a game called Stardew Valley where each day, an ungrown tree has a $20\%$ chance of growing. So far I've figured out how to calculate what the odds of my tree growing at least once in d days is with the formula: $$1 - 0.8^d$$ So for example if $d = 5$ that's a probably of $0.672$ that my tree will grow at least once in that time. I want to be able to calculate the odds that it will grow at least $2, 3$ or $4$ times in d days.","I'm playing a game called Stardew Valley where each day, an ungrown tree has a chance of growing. So far I've figured out how to calculate what the odds of my tree growing at least once in d days is with the formula: So for example if that's a probably of that my tree will grow at least once in that time. I want to be able to calculate the odds that it will grow at least or times in d days.","20\% 1 - 0.8^d d = 5 0.672 2, 3 4",['probability']
16,Probability of correctly declaring number as prime,Probability of correctly declaring number as prime,,"It is known that a way to check whether a number $n$ is prime, is to check for divisors of $n$ from $2$ to $\lfloor\sqrt{n}\rfloor$ . If we find any divisor, then $n$ is not prime. If we don't, then we don't need to check for divisors bigger than $\sqrt{n}$ (and $n$ is prime). An ""approximation"" of this method would be to check for divisors the same way but from $2$ to $log_2n$ . If we find any divisor we declare that $n$ is not prime. If we don't find any divisor we declare that $n$ is prime. Of course this method will not always give the correct results. My question is: If the second algorithm declares a number to be prime, what is the probability that this number is actually prime?","It is known that a way to check whether a number is prime, is to check for divisors of from to . If we find any divisor, then is not prime. If we don't, then we don't need to check for divisors bigger than (and is prime). An ""approximation"" of this method would be to check for divisors the same way but from to . If we find any divisor we declare that is not prime. If we don't find any divisor we declare that is prime. Of course this method will not always give the correct results. My question is: If the second algorithm declares a number to be prime, what is the probability that this number is actually prime?",n n 2 \lfloor\sqrt{n}\rfloor n \sqrt{n} n 2 log_2n n n,"['probability', 'number-theory']"
17,"Suppose $E(X)=E(Y)$ and $\operatorname{Var}(X)>\operatorname{Var}(Y)$, do we have $E(f(X))>E(f(Y))$ for convex functions $f$?","Suppose  and , do we have  for convex functions ?",E(X)=E(Y) \operatorname{Var}(X)>\operatorname{Var}(Y) E(f(X))>E(f(Y)) f,"Suppose we have two random variables $X$ and $Y$ with the same mean but different variances, say $\operatorname{Var}(X) > \operatorname{Var}(Y)$ , and $f$ is a convex function. Is it possible to compare the expectations $E(f(X))$ and $E(f(Y))$ ? In the case $\operatorname{Var}(Y)=0$ , it reduces to Jensen's inequality. This is motivated by the following thought: if $f$ is convex increasing, we can interpret it as the utility function of a risk-loving individual, in which case $E(f(X)) > f(E(X))$ , i.e. facing a gamble $X$ the individual would prefer to play the gamble instead of taking the expected value. I'm wondering whether we can generalise it, so that if a gamble $X$ is riskier than a gamble $Y$ (in the sense that $\operatorname{Var}(X)>\operatorname{Var}(Y)$ , the risk-loving individual would prefer the riskier gamble (i.e. $E(f(X)) > E(f(Y))$ )? Thanks!","Suppose we have two random variables and with the same mean but different variances, say , and is a convex function. Is it possible to compare the expectations and ? In the case , it reduces to Jensen's inequality. This is motivated by the following thought: if is convex increasing, we can interpret it as the utility function of a risk-loving individual, in which case , i.e. facing a gamble the individual would prefer to play the gamble instead of taking the expected value. I'm wondering whether we can generalise it, so that if a gamble is riskier than a gamble (in the sense that , the risk-loving individual would prefer the riskier gamble (i.e. )? Thanks!",X Y \operatorname{Var}(X) > \operatorname{Var}(Y) f E(f(X)) E(f(Y)) \operatorname{Var}(Y)=0 f E(f(X)) > f(E(X)) X X Y \operatorname{Var}(X)>\operatorname{Var}(Y) E(f(X)) > E(f(Y)),"['real-analysis', 'probability', 'probability-theory', 'probability-distributions']"
18,Series Converging Almost Surely But Diverging in Mean,Series Converging Almost Surely But Diverging in Mean,,"I am looking for an example of independent, non-negative random variables $X_1, X_2, \dots$ such that $$ \sum_{n=1}^{\infty} X_n \, \lt \, \infty $$ almost surely but $$ \sum_{n=1}^{\infty} \mathbb{E}(X_n) \, = \, \infty $$ I can find examples of sequences which converge almost surely but diverge in mean, but can’t seem to be able to cook up an example with a series.","I am looking for an example of independent, non-negative random variables such that almost surely but I can find examples of sequences which converge almost surely but diverge in mean, but can’t seem to be able to cook up an example with a series.","X_1, X_2, \dots 
\sum_{n=1}^{\infty} X_n \, \lt \, \infty
 
\sum_{n=1}^{\infty} \mathbb{E}(X_n) \, = \, \infty
","['probability', 'probability-theory', 'convergence-divergence', 'expected-value', 'probability-limit-theorems']"
19,Probability random coins tossing,Probability random coins tossing,,"You are playing with a friend: You are tossing a (fair) coin. If it is a tail, you win. If not, then you are tossing 2 (fair) coins. If they are both tails, you win. If not, you are tossing 3 (fair) coins, if they are all tails you win. If not, you are tossing 4 (fair) coins and so on... What is the probability for you to win???  Is it a rational number? I came to this formula: $1-\Pi_{n=1}^{\infty}(1-(\frac{1}{2})^n)$","You are playing with a friend: You are tossing a (fair) coin. If it is a tail, you win. If not, then you are tossing 2 (fair) coins. If they are both tails, you win. If not, you are tossing 3 (fair) coins, if they are all tails you win. If not, you are tossing 4 (fair) coins and so on... What is the probability for you to win???  Is it a rational number? I came to this formula:",1-\Pi_{n=1}^{\infty}(1-(\frac{1}{2})^n),['probability']
20,A simple problem. What am I doing wrong?,A simple problem. What am I doing wrong?,,"I am totally new to probability and I am a little bit confused. I have the following homework: A large group of people are competing for all-expense-paid weekends in Philadelphia. The Master of Ceremonies gives each contestant a well-shuffled deck od cards. The contestant deals two cards off the top of the deck, and wins a weekend if the first card is the ace of hearts or the second card is the king of hearts. What is the probability of wining the weekend? I tried to solve this exercise in three ways: Using $P(A ∪ B) = P(A) + P(B) - P(A ∩ B)$ . I get: $$\frac{1}{52} + \frac{1}{52} - \frac{1}{52}×\frac{1}{51} = \frac{101}{51×52}.$$ Using $P(A ∪ B) = P(A) + P(B ∩ A^c)$ . I get: $$\frac{1}{52} + \frac{1}{52}×\frac{50}{51} = \frac{101}{51×52}.$$ Using formula $P(A) = 1 - P(A^c)$ where the opposite is not getting the ace of hearts as the first card and not getting the king of hearts as the second card. In this way I get: $$1 - \frac{51}{52}×\frac{50}{51} = \frac{2}{52} \ne \frac{101}{51×52}.$$ What am I doing wrong in the third way? Thank you in advance for your help.","I am totally new to probability and I am a little bit confused. I have the following homework: A large group of people are competing for all-expense-paid weekends in Philadelphia. The Master of Ceremonies gives each contestant a well-shuffled deck od cards. The contestant deals two cards off the top of the deck, and wins a weekend if the first card is the ace of hearts or the second card is the king of hearts. What is the probability of wining the weekend? I tried to solve this exercise in three ways: Using . I get: Using . I get: Using formula where the opposite is not getting the ace of hearts as the first card and not getting the king of hearts as the second card. In this way I get: What am I doing wrong in the third way? Thank you in advance for your help.",P(A ∪ B) = P(A) + P(B) - P(A ∩ B) \frac{1}{52} + \frac{1}{52} - \frac{1}{52}×\frac{1}{51} = \frac{101}{51×52}. P(A ∪ B) = P(A) + P(B ∩ A^c) \frac{1}{52} + \frac{1}{52}×\frac{50}{51} = \frac{101}{51×52}. P(A) = 1 - P(A^c) 1 - \frac{51}{52}×\frac{50}{51} = \frac{2}{52} \ne \frac{101}{51×52}.,['probability']
21,"Show that given n coins, if the probability of getting heads an even number of times is 1/2 then there is at least one fair coin","Show that given n coins, if the probability of getting heads an even number of times is 1/2 then there is at least one fair coin",,"So the set up is as follows: We have n coins being flipped independently, not necessarily all fair. I know that if there is at least one fair coin then the probability of getting an even number of heads after flipping is 1\2.  I want to show the converse, that if the probability is 1/2(of getting an even number of heads) then there is at least one fair coin.","So the set up is as follows: We have n coins being flipped independently, not necessarily all fair. I know that if there is at least one fair coin then the probability of getting an even number of heads after flipping is 1\2.  I want to show the converse, that if the probability is 1/2(of getting an even number of heads) then there is at least one fair coin.",,"['probability', 'conditional-probability']"
22,Difference between product distribution and joint distribution?,Difference between product distribution and joint distribution?,,What is the difference between an $n$ -fold product distribution and a joint distribution with $n$ random variables? Is it only defined for independent random variables? I am confused as to what is the definition of a product distribution. Context: I am reading class notes by John Duchi that say the $KL$ -Divergence of product distributions $P = P_1 \times P_2 \ldots P_n$ and $Q = Q_1 \times Q_2 \ldots Q_n$ given by $KL(P || Q)$ satisfies the decoupling equality of being $\sum_{i = 1}^{n}KL(P_i||Q_i)$ .,What is the difference between an -fold product distribution and a joint distribution with random variables? Is it only defined for independent random variables? I am confused as to what is the definition of a product distribution. Context: I am reading class notes by John Duchi that say the -Divergence of product distributions and given by satisfies the decoupling equality of being .,n n KL P = P_1 \times P_2 \ldots P_n Q = Q_1 \times Q_2 \ldots Q_n KL(P || Q) \sum_{i = 1}^{n}KL(P_i||Q_i),"['probability', 'probability-theory', 'measure-theory', 'probability-distributions', 'information-theory']"
23,Finding Coefficient of Term in Expansion (Multinomial/Binomial),Finding Coefficient of Term in Expansion (Multinomial/Binomial),,"I'm working on a proof of something and in the proof I need to find the coefficient of $s^{27}$ in $(\frac{1}{6}(s+s^{2}+s^{3}+s^{4}+s^{5}+s^{6}))^{10}$ . Wolfram Alpha gives the answer to be: I believe this is the correct answer, however, in my proof I don't want to say by Wolfram Alpha, the coefficient of $s^{27}$ in $(\frac{1}{6}(s+s^{2}+s^{3}+s^{4}+s^{5}+s^{6}))^{10}$ is $\frac{2665}{104976}$ . I think it is better that I solve for the coefficient of $s^{27}$ analytically or by hand. I wasn't sure, however what the best method to do this was. I was thinking maybe multinomial theorem (not binomial theorem since there are 6 terms)). However, there are many ways to combine powers of $s, s^2, s^3, s^4, s^5, \mbox{ and } s^6$ to get $s^{27}$ . Thus, I don't know the best way to find the coefficient of $s^{27}$ by hand or analytically. Any help would be much appreciated, thank you very much.","I'm working on a proof of something and in the proof I need to find the coefficient of in . Wolfram Alpha gives the answer to be: I believe this is the correct answer, however, in my proof I don't want to say by Wolfram Alpha, the coefficient of in is . I think it is better that I solve for the coefficient of analytically or by hand. I wasn't sure, however what the best method to do this was. I was thinking maybe multinomial theorem (not binomial theorem since there are 6 terms)). However, there are many ways to combine powers of to get . Thus, I don't know the best way to find the coefficient of by hand or analytically. Any help would be much appreciated, thank you very much.","s^{27} (\frac{1}{6}(s+s^{2}+s^{3}+s^{4}+s^{5}+s^{6}))^{10} s^{27} (\frac{1}{6}(s+s^{2}+s^{3}+s^{4}+s^{5}+s^{6}))^{10} \frac{2665}{104976} s^{27} s, s^2, s^3, s^4, s^5, \mbox{ and } s^6 s^{27} s^{27}","['calculus', 'probability', 'combinatorics', 'number-theory']"
24,Show that X is a sub-gaussian random vector with dependent sub-gaussian coordinates,Show that X is a sub-gaussian random vector with dependent sub-gaussian coordinates,,"Let $X \in R^n$ be a zero mean, random vector with sub-gaussian coordinates $X_i$ . prove that X is a sub-gaussian random vector no matter if coordinates are independent or dependent. It is easy to prove the result in the case of independent coordinates. When it comes to the case of dependent coordinates, I think of the definition of multivariate normal distribution but don't know if it works for sub-gaussian family. Assume a random vector Z $\in R^n$ has independent zero mean, unit variance, sub-gaussian coordinates and denote $\Sigma_X$ as the covariance matrix of X, we can find a Z such that $\Sigma_X^{1/2} Z$ has the same distribution as X. Because for $\forall a \in R^n$ $a^{T}\Sigma_X^{1/2} \in R^n$ , given the case of independent coordinates, we can say for $\forall a \in R^n, a^{T}\Sigma_X^{1/2}Z = a^{T}X$ is sub-gaussion distributed. So X is a sub-gaussian random vector. I am not sure if the proof is right for the whole sub-gaussian family, because I am not sure we can find a Z that $\Sigma_X^{1/2} Z$ is distributed same as X. Any suggestions and ideas?","Let be a zero mean, random vector with sub-gaussian coordinates . prove that X is a sub-gaussian random vector no matter if coordinates are independent or dependent. It is easy to prove the result in the case of independent coordinates. When it comes to the case of dependent coordinates, I think of the definition of multivariate normal distribution but don't know if it works for sub-gaussian family. Assume a random vector Z has independent zero mean, unit variance, sub-gaussian coordinates and denote as the covariance matrix of X, we can find a Z such that has the same distribution as X. Because for , given the case of independent coordinates, we can say for is sub-gaussion distributed. So X is a sub-gaussian random vector. I am not sure if the proof is right for the whole sub-gaussian family, because I am not sure we can find a Z that is distributed same as X. Any suggestions and ideas?","X \in R^n X_i \in R^n \Sigma_X \Sigma_X^{1/2} Z \forall a \in R^n a^{T}\Sigma_X^{1/2} \in R^n \forall a \in R^n, a^{T}\Sigma_X^{1/2}Z = a^{T}X \Sigma_X^{1/2} Z","['probability', 'statistics', 'normal-distribution']"
25,"Counting, Probability and Binomial Coefficients","Counting, Probability and Binomial Coefficients",,"If $$P_{2n+2}=\sum_{k=n+2}^{2n+2}{2n+2 \choose k}p^kq^{2n+2-k}$$ and, $$P_{2n}=\sum_{k=n+1}^{2n}{2n \choose k}p^kq^{2n-k}$$ where $0<p<q<1$ and $q=1-p$ Prove that $$P_{2n+2}=P_{2n}+{2n \choose n}p^{n+2}q^n-{2n \choose {n+1}}p^{n+1}q^{n+1}$$ $\mathbf {Inspiration:}$ A and B play a series of games where the probability of winning $\mathit p$ for A is kept less than 0.5. However A gets to choose in advance the total no. of plays. To win the game one must score more than half the games . If the total no. of games is to be even, How many plays should A choose? $\mathbf {Here}$ $P_{2n}$ and $P_{2n+2}$ represents the probability of A winning the play in $2n$ and $2n+2$ games where $2n$ is considered the optimum number of games","If and, where and Prove that A and B play a series of games where the probability of winning for A is kept less than 0.5. However A gets to choose in advance the total no. of plays. To win the game one must score more than half the games . If the total no. of games is to be even, How many plays should A choose? and represents the probability of A winning the play in and games where is considered the optimum number of games",P_{2n+2}=\sum_{k=n+2}^{2n+2}{2n+2 \choose k}p^kq^{2n+2-k} P_{2n}=\sum_{k=n+1}^{2n}{2n \choose k}p^kq^{2n-k} 0<p<q<1 q=1-p P_{2n+2}=P_{2n}+{2n \choose n}p^{n+2}q^n-{2n \choose {n+1}}p^{n+1}q^{n+1} \mathbf {Inspiration:} \mathit p \mathbf {Here} P_{2n} P_{2n+2} 2n 2n+2 2n,"['probability', 'sequences-and-series', 'combinatorics', 'probability-theory', 'binomial-coefficients']"
26,What is the difference between a weakly stationary process and strictly stationary process?,What is the difference between a weakly stationary process and strictly stationary process?,,In some lecture slides I read that the definition of a weakly stationary process is that The mean value is constant The covariance function is time-invariant The variance is constant and I read that the definition of a strictly stationary process is a process whose probability distribution does not change over time. What concrete properties of a strictly stationary process is not included in the definition of a weakly stationary process?,In some lecture slides I read that the definition of a weakly stationary process is that The mean value is constant The covariance function is time-invariant The variance is constant and I read that the definition of a strictly stationary process is a process whose probability distribution does not change over time. What concrete properties of a strictly stationary process is not included in the definition of a weakly stationary process?,,"['probability', 'probability-distributions', 'stochastic-processes', 'stationary-processes']"
27,Why don't we always consider complete measure spaces?,Why don't we always consider complete measure spaces?,,"Let $(\Omega ,\mathcal F,\mathbb P)$ a probability space and let $X=(X_t)$ and $Y=(Y_t)$ two stochastic processes. I know  for example that $X$ and $Y$ are indistinguishable if there is a set $N$ of measure $0$ s.t. for all $\omega \notin N$ we have $X_t=Y_t$ for all $t$ , but we can't write $\mathbb P\{\forall t, \ X_t=Y_t\}$ since $\{\forall t, X_t=Y_t\}$ may be not $\mathcal F-$ measurable. The thing is if $Y$ is a copy of $X$ and $(\Omega ,\mathcal F,\mathbb P)$ is complete, then $\{\forall t,X_t=Y_t\}$ is $\mathcal F-$ measurable. I also know that each measure space can be completed by adding sets of measure. Questions : So, why don't we always work with complete measure space (since they can be always completed), and avoid for example the problem of the measurability of $\{\forall t, X_t=Y_t\}$ if $Y$ is a copy of $X$ (or many other measurability problem) ? In what working in a non complete measure space can be interesting, or at least more interesting than to work with it's completion ? (since a non complete measure space can always be completed). Do you have an example where it's worth to work with the uncompleted measure space rather than with the completed space ?","Let a probability space and let and two stochastic processes. I know  for example that and are indistinguishable if there is a set of measure s.t. for all we have for all , but we can't write since may be not measurable. The thing is if is a copy of and is complete, then is measurable. I also know that each measure space can be completed by adding sets of measure. Questions : So, why don't we always work with complete measure space (since they can be always completed), and avoid for example the problem of the measurability of if is a copy of (or many other measurability problem) ? In what working in a non complete measure space can be interesting, or at least more interesting than to work with it's completion ? (since a non complete measure space can always be completed). Do you have an example where it's worth to work with the uncompleted measure space rather than with the completed space ?","(\Omega ,\mathcal F,\mathbb P) X=(X_t) Y=(Y_t) X Y N 0 \omega \notin N X_t=Y_t t \mathbb P\{\forall t, \ X_t=Y_t\} \{\forall t, X_t=Y_t\} \mathcal F- Y X (\Omega ,\mathcal F,\mathbb P) \{\forall t,X_t=Y_t\} \mathcal F- \{\forall t, X_t=Y_t\} Y X",['probability']
28,"How to calculate $\mathbb{P}(|U_{1} - U_{2}| < \frac{1}{12})$, where $U_{i} \sim \mathcal{U}(0, \frac{1}{2})$ and $U_{i}$ are independent.","How to calculate , where  and  are independent.","\mathbb{P}(|U_{1} - U_{2}| < \frac{1}{12}) U_{i} \sim \mathcal{U}(0, \frac{1}{2}) U_{i}","We have a Poisson process of intensity $\lambda = 4$ . We have the following event: $A$ : ""Two marks appear with a separation of $\frac{1}{12}$ or less"". We need to calculate the probability of exactly two ""marks"" appearing between $0$ and $\frac{1}{2}$ , and $A$ ocurring at the same time. That is, the probability of exactly two marks ocurring in $(0, \frac{1}{2})$ with a separation of $\frac{1}{12}$ or less. Here's how far I've gotten: Let $N$ : Number of marks between $0$ and $\frac{1}{2}$ . We want: $$\mathbb{P}(N=2, A) = \mathbb{P}(A|N=2)\mathbb{P}(N=2) $$ $N\sim Poi(\frac{1}{2}4)$ , so: $$\mathbb{P}(N=2) = \frac{2^2}{2!}e^{-2} = 2e^{-2}$$ The arrival times for a conditioned number of marks (in this case two) is $U_{1}$ , and $U_{2}$ , where $U_{i} \sim \mathcal{U}(0, \frac{1}{2})$ , and $U_{i}$ are independent, so: $$\mathbb{P}(A|N=2) = \mathbb{P}(\max(U_{1}, U_{2}) - \min(U_{1}, U_{2}) < \frac{1}{12}) = \mathbb{P}\left(|U_{1} - U_{2}| < \frac{1}{12}\right)$$ This is where I'm stuck. The answer is supposed to be $\frac{11}{18}e^{-2}$ , so $\mathbb{P}\left(|U_{1} - U_{2}| < \frac{1}{12}\right)$ should be $\frac{11}{36}$ . Thanks.","We have a Poisson process of intensity . We have the following event: : ""Two marks appear with a separation of or less"". We need to calculate the probability of exactly two ""marks"" appearing between and , and ocurring at the same time. That is, the probability of exactly two marks ocurring in with a separation of or less. Here's how far I've gotten: Let : Number of marks between and . We want: , so: The arrival times for a conditioned number of marks (in this case two) is , and , where , and are independent, so: This is where I'm stuck. The answer is supposed to be , so should be . Thanks.","\lambda = 4 A \frac{1}{12} 0 \frac{1}{2} A (0, \frac{1}{2}) \frac{1}{12} N 0 \frac{1}{2} \mathbb{P}(N=2, A) = \mathbb{P}(A|N=2)\mathbb{P}(N=2)  N\sim Poi(\frac{1}{2}4) \mathbb{P}(N=2) = \frac{2^2}{2!}e^{-2} = 2e^{-2} U_{1} U_{2} U_{i} \sim \mathcal{U}(0, \frac{1}{2}) U_{i} \mathbb{P}(A|N=2) = \mathbb{P}(\max(U_{1}, U_{2}) - \min(U_{1}, U_{2}) < \frac{1}{12}) = \mathbb{P}\left(|U_{1} - U_{2}| < \frac{1}{12}\right) \frac{11}{18}e^{-2} \mathbb{P}\left(|U_{1} - U_{2}| < \frac{1}{12}\right) \frac{11}{36}","['probability', 'probability-theory', 'probability-distributions', 'poisson-distribution']"
29,Question involving Characteristic Functions and the Existence of a Distribution,Question involving Characteristic Functions and the Existence of a Distribution,,"Question Is it possible for $X$ , $Y$ and $Z$ to have the same distribution and satisfy $X=U(Y+Z)$ where $U$ is uniform on $[0,1]$ and $Y$ , $Z$ are independent of $U$ and of one another? The above question is from Grimmett and Stirzaker. My attempt We translate the condition into characteristic functions. Let $\phi(t)=Ee^{it X}$ be the characteristic function of $X$ . Then $$ \phi(t)=Ee^{itUY}Ee^{itUZ}=(Ee^{itUX})^2=\left[\int_0^1 \int e^{itux}\,dF(x)\, du\right]^2=\left[\int_0^1 \phi(tu)\, du\right]^2  $$ using the independence and equality of distribution assumptions. We can write the above equation as $$ \phi (t)=\frac{1}{t^2}\left[\int_0^t \phi(y)\, dy\right]^2  $$ but I am not sure where to proceed from here. I guess we have to solve a differential equation. Put $\Phi(t)=\int_0^t \phi(y)\, dy$ . Then we have that $$ \Phi'(t)=\frac{1}{t^2}\Phi(t)^2 $$ but I am unable to solve this differential equation. Any help is appreciated.","Question Is it possible for , and to have the same distribution and satisfy where is uniform on and , are independent of and of one another? The above question is from Grimmett and Stirzaker. My attempt We translate the condition into characteristic functions. Let be the characteristic function of . Then using the independence and equality of distribution assumptions. We can write the above equation as but I am not sure where to proceed from here. I guess we have to solve a differential equation. Put . Then we have that but I am unable to solve this differential equation. Any help is appreciated.","X Y Z X=U(Y+Z) U [0,1] Y Z U \phi(t)=Ee^{it X} X 
\phi(t)=Ee^{itUY}Ee^{itUZ}=(Ee^{itUX})^2=\left[\int_0^1 \int e^{itux}\,dF(x)\, du\right]^2=\left[\int_0^1 \phi(tu)\, du\right]^2 
 
\phi (t)=\frac{1}{t^2}\left[\int_0^t \phi(y)\, dy\right]^2 
 \Phi(t)=\int_0^t \phi(y)\, dy 
\Phi'(t)=\frac{1}{t^2}\Phi(t)^2
","['real-analysis', 'probability', 'probability-theory', 'characteristic-functions']"
30,Every finite $\sigma$-algebra is of the form...?,Every finite -algebra is of the form...?,\sigma,"Let $\mathcal{F}$ be a finite $\sigma$ -algebra. The problem asks to show there exists a partition $G = \{ G_1,\dots,G_n \}$ of $\Omega$ such that for all $A \in \mathcal{F}$ , $A$ is the union of all or some $G_i$ : $$A = \bigcup_{i \in I} G_i$$ The existence of a partition is immediate from the definition of a $\sigma$ -algebra, but I'm not sure how to use the fact $\mathcal{F}$ is finite to construct the generating set $G$ . Specifically, to show that every member of $\mathcal{F}$ can be generated from a single partition using only union. Can someone give me a hint? Not a homework problem, I am working through a textbook for self-study.","Let be a finite -algebra. The problem asks to show there exists a partition of such that for all , is the union of all or some : The existence of a partition is immediate from the definition of a -algebra, but I'm not sure how to use the fact is finite to construct the generating set . Specifically, to show that every member of can be generated from a single partition using only union. Can someone give me a hint? Not a homework problem, I am working through a textbook for self-study.","\mathcal{F} \sigma G = \{ G_1,\dots,G_n \} \Omega A \in \mathcal{F} A G_i A = \bigcup_{i \in I} G_i \sigma \mathcal{F} G \mathcal{F}","['probability', 'measure-theory']"
31,Expected value of a card game with 6 cards,Expected value of a card game with 6 cards,,"A deck contains 3 cards with +1 value and 3 cards with -1 value. The dealer shuffles the cards and deals them face up one by one. After each card is dealt, you have the option of stopping the game. Once the game is stopped, you get paid according to the total value of the cards that were dealt. E.g. if you stop the game after +1, +1, +1, you get +3. What is the expected value of the optimal strategy for this game. My stab at it: Since the net sum of the cards is zero, you will never lose any points on each round. If your trailing score is negative, you can keep drawing to get to at least flat. Strategy: Draw until you get a cumulative score of +1 and stop. Since there are a total of 20 permutations 6!/(3!*3!) of this game, only 5 sequences will give you a trailing score of 0 or below. So the expected value of this strategy: .75*1 + .25*0 = .75 Strategy 2: Draw two cards, if you have a cumulative score that is greater than 1, stop. Otherwise draw until you get a score of 1 and stop. I was unable to figure out how to do the math for this strategy, but I did simulate it and apparently it has an expected value of .85. Can someone walk me through the math of the second strategy? If the second strategy is not the optimal one, what is a better strategy?","A deck contains 3 cards with +1 value and 3 cards with -1 value. The dealer shuffles the cards and deals them face up one by one. After each card is dealt, you have the option of stopping the game. Once the game is stopped, you get paid according to the total value of the cards that were dealt. E.g. if you stop the game after +1, +1, +1, you get +3. What is the expected value of the optimal strategy for this game. My stab at it: Since the net sum of the cards is zero, you will never lose any points on each round. If your trailing score is negative, you can keep drawing to get to at least flat. Strategy: Draw until you get a cumulative score of +1 and stop. Since there are a total of 20 permutations 6!/(3!*3!) of this game, only 5 sequences will give you a trailing score of 0 or below. So the expected value of this strategy: .75*1 + .25*0 = .75 Strategy 2: Draw two cards, if you have a cumulative score that is greater than 1, stop. Otherwise draw until you get a score of 1 and stop. I was unable to figure out how to do the math for this strategy, but I did simulate it and apparently it has an expected value of .85. Can someone walk me through the math of the second strategy? If the second strategy is not the optimal one, what is a better strategy?",,"['probability', 'optimization', 'game-theory', 'card-games']"
32,Applying the Pigeonhole Principle to a Set of Subsets,Applying the Pigeonhole Principle to a Set of Subsets,,"Let $A$ be a set of six positive integers each of which is less   than $15$ . Show that there must be two distinct subsets of $A$ whose elements when added up give the same sum. This is what I've tried so far. There are $2 ^ 6 = 64$ subsets of $A$ . We can also calculate the largest possible sum of a subset to be $14+13+12+11+10+9 = 69$ . The smallest possible sum for a subset is $0$ . Thus, there are $70$ possible sums, but only $63$ possible subsets $($ assuming we exclude the empty set $)$ . Is there something I am missing so that I can apply the pigeonhole principle?","Let be a set of six positive integers each of which is less   than . Show that there must be two distinct subsets of whose elements when added up give the same sum. This is what I've tried so far. There are subsets of . We can also calculate the largest possible sum of a subset to be . The smallest possible sum for a subset is . Thus, there are possible sums, but only possible subsets assuming we exclude the empty set . Is there something I am missing so that I can apply the pigeonhole principle?",A 15 A 2 ^ 6 = 64 A 14+13+12+11+10+9 = 69 0 70 63 ( ),"['probability', 'discrete-mathematics', 'pigeonhole-principle']"
33,"Math probability that ""5-out-of-36"" lottery draw has at least one pair of numbers with difference = 1.","Math probability that ""5-out-of-36"" lottery draw has at least one pair of numbers with difference = 1.",,"Given a $5$ out of $36$ lottery ( $5$ unique numbers out of pool of $36$ numbers ranging $[1,2,…,36]$ ). How to calculate probability that a draw has at least one pair of consecutive numbers (like $22, 23$ -a  pair of numbers whose difference $23-22 = 1$ )? Every draw ( $5$ numbers) has $10$ pairs. For dif 1 we have total of $35$ pairs ( $1$ and $2$ , $2$ and $3$ ... $34$ and $35$ ). There are total of $630$ pairs (binomial(35, 2)). Problem is I think cannot think like that: $1$ concrete pair out of $630$ appears with $1/630$ chances. Probability to have any of $35$ dif 1 pairs is $35/630$ (if I choose $2$ numbers randomly). But I choose $5$ numbers (which give $10$ pairs) - and it is not the same as just drawing $2$ pairs out of $630$ pairs. I cannot figure out how to reason in this case. The question is about not dif 1 but also dif 2 , dif 3 ... dif 35 (there is only single such pair!). How to mathematically calculate the probability? Can I think of a single 5-out-of-36 draw as an equivalent of 10 independent ""pick a pair out of all possible pairs""? It would give dif1 ( $35$ dif1 pairs out of $630$ all pairs) as $((35/630)+(34/629)+(33/628)+(32/627)+(31/626)+(30/625)+(29/624)+(28/623)+(27/622)+(26/621))$ . But it differs greatly from a real lottery, which makes me think that formula (and reasoning) above is not applicable! P.S. Stars and bars method is described here (wiki) , example how to use it is here","Given a out of lottery ( unique numbers out of pool of numbers ranging ). How to calculate probability that a draw has at least one pair of consecutive numbers (like -a  pair of numbers whose difference )? Every draw ( numbers) has pairs. For dif 1 we have total of pairs ( and , and ... and ). There are total of pairs (binomial(35, 2)). Problem is I think cannot think like that: concrete pair out of appears with chances. Probability to have any of dif 1 pairs is (if I choose numbers randomly). But I choose numbers (which give pairs) - and it is not the same as just drawing pairs out of pairs. I cannot figure out how to reason in this case. The question is about not dif 1 but also dif 2 , dif 3 ... dif 35 (there is only single such pair!). How to mathematically calculate the probability? Can I think of a single 5-out-of-36 draw as an equivalent of 10 independent ""pick a pair out of all possible pairs""? It would give dif1 ( dif1 pairs out of all pairs) as . But it differs greatly from a real lottery, which makes me think that formula (and reasoning) above is not applicable! P.S. Stars and bars method is described here (wiki) , example how to use it is here","5 36 5 36 [1,2,…,36] 22, 23 23-22 = 1 5 10 35 1 2 2 3 34 35 630 1 630 1/630 35 35/630 2 5 10 2 630 35 630 ((35/630)+(34/629)+(33/628)+(32/627)+(31/626)+(30/625)+(29/624)+(28/623)+(27/622)+(26/621))","['probability', 'probability-theory', 'lotteries']"
34,P value for a z-score of 4.9? Or am I doing this wrong?,P value for a z-score of 4.9? Or am I doing this wrong?,,"My question is as follows: A fair die is rolled $120$ times. Find the probability that $5$ is on the  top: a. between $30$ and $40$ times, b. between $18$ and $50$ times, c. more than $70$ times. Hint: Use the approximation of the Binomial distribution to the normal distribution. I am close to solving it. However, I am stuck, since I obtained a standard deviation value of $4.0825$ and therefore one of the $z$ -scores as $4.9$ . My solution is as follows: $x$ = event of having a $5$ shown on top $P(x) = 1/6$ This is a binomial probability experiment $np(1-p) \ge 10$ ? $120 * \frac{1}{6} ( 1 - \frac{1}{6}) = \frac{50}{3} > 10$ mean $= np = 120$ ; standard deviation $= \sqrt{\frac{50}{3}} = 4.0825.$ $X~N(\mu=20, \sigma=4.0825)$ a) $P(30\le x\le 40) =$ ? $z = \frac{x - \mu} {\sigma} $ $P\left(\frac{30 - 20}{4.0825} \le z \le \frac{40 - 20}{4.0825} \right)= P (2.45\le z\le4.9)$ At this point, I am stuck, since the $p$ -value for a $Z$ -score of $4.9$ is impossible to find (an online calculator gave me a value of $0.9999995$ ). Is my solution wrong or should I proceed with the given $p$ -value? Thank you all. : )","My question is as follows: A fair die is rolled times. Find the probability that is on the  top: a. between and times, b. between and times, c. more than times. Hint: Use the approximation of the Binomial distribution to the normal distribution. I am close to solving it. However, I am stuck, since I obtained a standard deviation value of and therefore one of the -scores as . My solution is as follows: = event of having a shown on top This is a binomial probability experiment ? mean ; standard deviation a) ? At this point, I am stuck, since the -value for a -score of is impossible to find (an online calculator gave me a value of ). Is my solution wrong or should I proceed with the given -value? Thank you all. : )","120 5 30 40 18 50 70 4.0825 z 4.9 x 5 P(x) = 1/6 np(1-p) \ge 10 120 * \frac{1}{6} ( 1 - \frac{1}{6}) = \frac{50}{3} > 10 = np = 120 = \sqrt{\frac{50}{3}} = 4.0825. X~N(\mu=20, \sigma=4.0825) P(30\le x\le 40) = z = \frac{x - \mu} {\sigma}  P\left(\frac{30 - 20}{4.0825} \le z \le \frac{40 - 20}{4.0825} \right)= P (2.45\le z\le4.9) p Z 4.9 0.9999995 p","['probability', 'normal-distribution', 'approximation', 'binomial-distribution']"
35,"Sum of Uniform(5,10) random variables to get more than 30","Sum of Uniform(5,10) random variables to get more than 30",,"Let $X_i$ be i.i.d. $Uniform(5,10)$ , and let $Y_t = \sum_{i=1}^t X_i$ . Let $T = \mbox{inf}\{t:Y_t \geq 30\}$ , what is $\mathbb{E}[T]$ ? At first I thought this was similar to Choose a random number between $0$ and $1$ and record its value. Keep doing it until the sum of the numbers exceeds $1$ . How many tries do we need? , but after trying some methods mentioned under that question, I still couldn't figure out a solution. I know $T$ can only be $4, 5, 6$ , but is it possible to compute each individual probability?","Let be i.i.d. , and let . Let , what is ? At first I thought this was similar to Choose a random number between and and record its value. Keep doing it until the sum of the numbers exceeds . How many tries do we need? , but after trying some methods mentioned under that question, I still couldn't figure out a solution. I know can only be , but is it possible to compute each individual probability?","X_i Uniform(5,10) Y_t = \sum_{i=1}^t X_i T = \mbox{inf}\{t:Y_t \geq 30\} \mathbb{E}[T] 0 1 1 T 4, 5, 6","['probability', 'random-variables', 'random', 'uniform-distribution']"
36,Beta distribution with parameters $\alpha = \beta \to 0$ is Bernoulli distribution,Beta distribution with parameters  is Bernoulli distribution,\alpha = \beta \to 0,"In the article https://en.wikipedia.org/wiki/Beta_distribution#Symmetric_(α_=_β) it is said that a Beta distribution with parameters $\alpha = \beta \to 0$ has a Bernoulli distribution with probability $p=0.5$ at $0$ and $1$. Formally, does this mean that the sequence $\text{Beta}(1/n, 1/n)$ with $n \in \mathbb{N}$ converge to $\text{Bernoulli}(0.5)$ and what kind of convergence it is (distribution, a. e.)? How to prove this fact? Beta density function when $\alpha = \beta$ is: $$f_X(x)=\frac{x^{\alpha -1} (1-x)^{\beta -1}}{B(\alpha, \beta)} = \frac{\Gamma(2\alpha)\;x^{\alpha -1} (1-x)^{\alpha -1}}{\Gamma(\alpha)^2}$$ then I need to find $$\lim_{\alpha^+ \to 0}\frac{\Gamma(2\alpha)\;x^{\alpha -1} (1-x)^{\alpha -1}}{\Gamma(\alpha)^2}$$ where $\lim_{\alpha^+ \to 0}$ is the limit from the right since the parameters for the Beta distribution are real positive numbers. We know that $\lim_{\alpha^+ \to 0} \Gamma(\alpha) = +\infty$ and for every $x \in \mathbb{R}$ $x^{-1}$ and $(1-x)^{-1}$ is another real number, then we have a limit of the form $\infty / \infty$ and we can use L'Hopital, but I dont know how to use it with the $\Gamma$ function and how to conclude that the new function is a density function of Bernoulli distribution.","In the article https://en.wikipedia.org/wiki/Beta_distribution#Symmetric_(α_=_β) it is said that a Beta distribution with parameters $\alpha = \beta \to 0$ has a Bernoulli distribution with probability $p=0.5$ at $0$ and $1$. Formally, does this mean that the sequence $\text{Beta}(1/n, 1/n)$ with $n \in \mathbb{N}$ converge to $\text{Bernoulli}(0.5)$ and what kind of convergence it is (distribution, a. e.)? How to prove this fact? Beta density function when $\alpha = \beta$ is: $$f_X(x)=\frac{x^{\alpha -1} (1-x)^{\beta -1}}{B(\alpha, \beta)} = \frac{\Gamma(2\alpha)\;x^{\alpha -1} (1-x)^{\alpha -1}}{\Gamma(\alpha)^2}$$ then I need to find $$\lim_{\alpha^+ \to 0}\frac{\Gamma(2\alpha)\;x^{\alpha -1} (1-x)^{\alpha -1}}{\Gamma(\alpha)^2}$$ where $\lim_{\alpha^+ \to 0}$ is the limit from the right since the parameters for the Beta distribution are real positive numbers. We know that $\lim_{\alpha^+ \to 0} \Gamma(\alpha) = +\infty$ and for every $x \in \mathbb{R}$ $x^{-1}$ and $(1-x)^{-1}$ is another real number, then we have a limit of the form $\infty / \infty$ and we can use L'Hopital, but I dont know how to use it with the $\Gamma$ function and how to conclude that the new function is a density function of Bernoulli distribution.",,"['probability', 'probability-distributions', 'gamma-function', 'beta-function']"
37,Expected number of students that don't have someone cheating from them.,Expected number of students that don't have someone cheating from them.,,"I recently watched this 3Blue1Brown video that has a small problem at the end (9:41) , which I haven't been able to solve. The problem is the following (my own phrasing): Suppose that you have $n$ students sitting in a circle taking a test. It's a hard test, so each student tries to cheat off of his neighbour, choosing randomly which neighbour to cheat from. What is the expected number of students that does not have a neighbour cheating from them? I am aware that it is stated in the video that a link to a solution can be found in the description. I have not been able to find a solution following this link, however. I have found the following values: $$\begin{array}{c|ccccc} n&3&4&5&6&7\\ \hline E(n)&\frac{3}{4}&\frac{4}{4}&\frac{5}{4}&\frac{6}{4}&\frac{7}{4} \end{array},$$ which suggests that $E(n)=\frac{n}{4}$ for $n>2$, but I do not see how to prove this. I keep on running into the problem of the probabilities not being independent. I've also tried to phrase the problem in terms of 'paths' formed by following which student is watching which, but this has not lead to anything so far. Any help or hint is welcome.","I recently watched this 3Blue1Brown video that has a small problem at the end (9:41) , which I haven't been able to solve. The problem is the following (my own phrasing): Suppose that you have $n$ students sitting in a circle taking a test. It's a hard test, so each student tries to cheat off of his neighbour, choosing randomly which neighbour to cheat from. What is the expected number of students that does not have a neighbour cheating from them? I am aware that it is stated in the video that a link to a solution can be found in the description. I have not been able to find a solution following this link, however. I have found the following values: $$\begin{array}{c|ccccc} n&3&4&5&6&7\\ \hline E(n)&\frac{3}{4}&\frac{4}{4}&\frac{5}{4}&\frac{6}{4}&\frac{7}{4} \end{array},$$ which suggests that $E(n)=\frac{n}{4}$ for $n>2$, but I do not see how to prove this. I keep on running into the problem of the probabilities not being independent. I've also tried to phrase the problem in terms of 'paths' formed by following which student is watching which, but this has not lead to anything so far. Any help or hint is welcome.",,"['probability', 'combinatorics', 'recreational-mathematics', 'expected-value']"
38,Intuition behind conditional probabilty: $P(A|B)=P(B\cap A)/P(B)$,Intuition behind conditional probabilty:,P(A|B)=P(B\cap A)/P(B),"I've struggled with probability for years. Even the most basic concepts. This is especially something I am not able to understand even after reading for the last 1.5 hours. Conditional probability is  $$ P(A|B)=\frac{P(B\cap A)}{P(B)}. $$ However, I fail to see why $P(A|B)=P(B \cap A)$ cannot be true in itself? Why do we have to divide by $P(B)$? A video online gave this example. The probability of being a male and an alcoholic is $\sim 2.25\%$. So what is the probability of being an alcoholic given that you are a male? I would say $2.25\%$ but in fact the answer is different. I cannot see how $P(A|B) \neq P(B \cap A)$. The intuition just isn't there. Is this something I am just supposed to accept and move on?","I've struggled with probability for years. Even the most basic concepts. This is especially something I am not able to understand even after reading for the last 1.5 hours. Conditional probability is  $$ P(A|B)=\frac{P(B\cap A)}{P(B)}. $$ However, I fail to see why $P(A|B)=P(B \cap A)$ cannot be true in itself? Why do we have to divide by $P(B)$? A video online gave this example. The probability of being a male and an alcoholic is $\sim 2.25\%$. So what is the probability of being an alcoholic given that you are a male? I would say $2.25\%$ but in fact the answer is different. I cannot see how $P(A|B) \neq P(B \cap A)$. The intuition just isn't there. Is this something I am just supposed to accept and move on?",,"['probability', 'intuition', 'conditional-probability']"
39,Game probability math question,Game probability math question,,"Hi I need help with problem related to probability. There is a game of basketball between you and one other person. (only   1 game). Both agree that the stake will be $\$10$ (winner gains $\$10$   more, loser loses $\$10$). At a random point in the game, the game is   interrupted, and you must make either one of the following choice: 1) Continue playing with a new stake of $\$20$ 2) Stop playing and lose $\$10$ What winning probability that you must/should have to choose option 1? And explain why? I have tried to list all cases that can happen, which are $3$: you keep playing and you win $\$20$, you keep playing and you lose $\$20$, you quit and you lose $\$10$. From there I don't know how to use the data to calculate the probability? Can someone give me some guidance?","Hi I need help with problem related to probability. There is a game of basketball between you and one other person. (only   1 game). Both agree that the stake will be $\$10$ (winner gains $\$10$   more, loser loses $\$10$). At a random point in the game, the game is   interrupted, and you must make either one of the following choice: 1) Continue playing with a new stake of $\$20$ 2) Stop playing and lose $\$10$ What winning probability that you must/should have to choose option 1? And explain why? I have tried to list all cases that can happen, which are $3$: you keep playing and you win $\$20$, you keep playing and you lose $\$20$, you quit and you lose $\$10$. From there I don't know how to use the data to calculate the probability? Can someone give me some guidance?",,['probability']
40,Which pattern comes before? - Tossing fair coins,Which pattern comes before? - Tossing fair coins,,"Suppose you are tossing a fair coin again and again. The problem is: If you choose one pattern among following 8 patterns of$$HHH, HHT, HTH, THH, HTT,THT,TTH,TTT$$ where H denotes head and T denotes tail, then I can always find another pattern such that my pattern comes before your pattern with probability strictly greater than 1/2. I could do it for $HHH$; if you choose $HHH$, then I choose $THH$. The probability of $THH$ coming before $HHH$ is greater than 1/2; unless the first three results are all $H$, which is of probability 1/8, $THH$ comes before $HHH$. By a similar argument, I could solve it for $TTT$. However, I find it puzzling when it comes to other cases. Any good idea? Thanks and regards. By the way, this problem is from Weighing the odds by David Williams.","Suppose you are tossing a fair coin again and again. The problem is: If you choose one pattern among following 8 patterns of$$HHH, HHT, HTH, THH, HTT,THT,TTH,TTT$$ where H denotes head and T denotes tail, then I can always find another pattern such that my pattern comes before your pattern with probability strictly greater than 1/2. I could do it for $HHH$; if you choose $HHH$, then I choose $THH$. The probability of $THH$ coming before $HHH$ is greater than 1/2; unless the first three results are all $H$, which is of probability 1/8, $THH$ comes before $HHH$. By a similar argument, I could solve it for $TTT$. However, I find it puzzling when it comes to other cases. Any good idea? Thanks and regards. By the way, this problem is from Weighing the odds by David Williams.",,"['probability', 'sequences-and-series', 'combinatorics', 'probability-theory']"
41,Estimating the smallest distance between $n$ points uniformly distributed on the unit circle.,Estimating the smallest distance between  points uniformly distributed on the unit circle.,n,"I'm working on the following question and would like some hints or solutions Let $n$ points be iid, uniformly distributed on the unit circle. Let   $\Delta_n$ be the smallest distance between any two of these points.    Show that $n^\theta \Delta_n\to 0$ in probability as $n\to \infty$, for all $0<\theta<2$. HINT: Divide the circle into small arcs and find the probability that at   least one arc contains 2 or more points So I tried following the hint, and I considered dividing up the circle into $n-1$ pieces that would give with probability 1, that two are in the same section.  However, $n^\theta/n-1$ does not go to zero.    The other things I tried were $n^2$ pieces and $n$ pieces, but the probability calculations are rather messy for these and I'd be dealing with factorials, which does not seem like it would go well with this problem. Source: Problem 2","I'm working on the following question and would like some hints or solutions Let $n$ points be iid, uniformly distributed on the unit circle. Let   $\Delta_n$ be the smallest distance between any two of these points.    Show that $n^\theta \Delta_n\to 0$ in probability as $n\to \infty$, for all $0<\theta<2$. HINT: Divide the circle into small arcs and find the probability that at   least one arc contains 2 or more points So I tried following the hint, and I considered dividing up the circle into $n-1$ pieces that would give with probability 1, that two are in the same section.  However, $n^\theta/n-1$ does not go to zero.    The other things I tried were $n^2$ pieces and $n$ pieces, but the probability calculations are rather messy for these and I'd be dealing with factorials, which does not seem like it would go well with this problem. Source: Problem 2",,"['probability', 'probability-theory']"
42,When to use the continuity correction for normal approximations of binomial probabilities.,When to use the continuity correction for normal approximations of binomial probabilities.,,"so I'm confused as to when you actually use continuity correction. If a problem deals with a binomial distribution and we are asked to find probabilities using normal approximation (provided np>5 and n(1-p)>5), I know we use continuity correction, but do we use continuity correction even for sampling distribution of sample means for said binomial distribution? In the problem below, in part b, do we use continuity correction? In general, do we use continuity correction if we know the identity of population distribution (namely if it's binomial)? What if we didn't know the problem below was a binomial distribution, how would we know we have to use continuity correction? In the next image, do we use continuity correction for part b. Based on the central limit theorem, I know if n>30 then the sampling distribution of sample means is approximately normal, but all this time I hadn't worried about continuity correction.","so I'm confused as to when you actually use continuity correction. If a problem deals with a binomial distribution and we are asked to find probabilities using normal approximation (provided np>5 and n(1-p)>5), I know we use continuity correction, but do we use continuity correction even for sampling distribution of sample means for said binomial distribution? In the problem below, in part b, do we use continuity correction? In general, do we use continuity correction if we know the identity of population distribution (namely if it's binomial)? What if we didn't know the problem below was a binomial distribution, how would we know we have to use continuity correction? In the next image, do we use continuity correction for part b. Based on the central limit theorem, I know if n>30 then the sampling distribution of sample means is approximately normal, but all this time I hadn't worried about continuity correction.",,"['probability', 'statistics', 'central-limit-theorem']"
43,"Calculate $E(\max (X,Y) \mid X) $ if $X$ and $Y$ are independent and exponential distributed",Calculate  if  and  are independent and exponential distributed,"E(\max (X,Y) \mid X)  X Y","Let $X,Y$ be independent and both $\text{Exp}(\lambda)$ distributed. How does one calculate $$E(\max (X,Y)\mid X)\,?$$ By independence  $\max (X,Y)$ is $\text{Exp}(2\lambda) $ distributed but I do not see how to continue. I am aware of memorylessness of exponential distribution. Help is welcome!","Let $X,Y$ be independent and both $\text{Exp}(\lambda)$ distributed. How does one calculate $$E(\max (X,Y)\mid X)\,?$$ By independence  $\max (X,Y)$ is $\text{Exp}(2\lambda) $ distributed but I do not see how to continue. I am aware of memorylessness of exponential distribution. Help is welcome!",,"['probability', 'probability-theory']"
44,What is the average product of the numbers drawn?,What is the average product of the numbers drawn?,,"There are 10 tickets in a box, each with a number on it. The average of those 10 numbers is zero. The average value of the squares of those numbers is 5. (a). If you pick two tickets at random, WITH replacement, what is the average product of the numbers drawn? (b). If you pick two tickets at random, WITHOUT replacement, what is the average product of the numbers drawn?","There are 10 tickets in a box, each with a number on it. The average of those 10 numbers is zero. The average value of the squares of those numbers is 5. (a). If you pick two tickets at random, WITH replacement, what is the average product of the numbers drawn? (b). If you pick two tickets at random, WITHOUT replacement, what is the average product of the numbers drawn?",,"['probability', 'average']"
45,Can someone explain to me how we derive the alternative form of Bayes theorem?,Can someone explain to me how we derive the alternative form of Bayes theorem?,,"I understand how we get this formula $$\Pr(H\mid E) = \frac{\Pr(H)\Pr(E\mid H)}{\Pr(E)}$$ from the fact that  $\Pr(H\cap E)$ is equal to both $\Pr(H)\Pr(E\mid H)$  and  $\Pr(E)\Pr(H\mid E),$ and solving for $\Pr(H\mid E).$ But how do we go from the denominator in the boldfaced formula to this new denominator below $$\Pr(E) =\Pr(H)\Pr(E\mid H)+\Pr(\bar H)\Pr(E\mid \bar H)$$ ? Please explain it to me like I'm ten years old.  I'm new to Bayes and learned the above after going over Venn diagrams several times, so break it down for me. Thanks so much.","I understand how we get this formula $$\Pr(H\mid E) = \frac{\Pr(H)\Pr(E\mid H)}{\Pr(E)}$$ from the fact that  $\Pr(H\cap E)$ is equal to both $\Pr(H)\Pr(E\mid H)$  and  $\Pr(E)\Pr(H\mid E),$ and solving for $\Pr(H\mid E).$ But how do we go from the denominator in the boldfaced formula to this new denominator below $$\Pr(E) =\Pr(H)\Pr(E\mid H)+\Pr(\bar H)\Pr(E\mid \bar H)$$ ? Please explain it to me like I'm ten years old.  I'm new to Bayes and learned the above after going over Venn diagrams several times, so break it down for me. Thanks so much.",,"['probability', 'bayes-theorem']"
46,log likelihood function and MLE for binomial sample,log likelihood function and MLE for binomial sample,,"Let $X_1,X_2,...;X_n$ be a random sample with $X_i$~$Binomial(m,p)$ for $i=1,...,n$ and $m=1,2,3,...$ and let $p\in (0,1)$. We assume $m$ is known and we are given the following data $x_1,...,x_n\in\{0,...,m\}$ Write up the log-likelihood function and find the MLE $\hat{P}ML$ for p I'm not quite sure how to approach this. This is what I've tried: I believe the likelihood function of a Binomial trial is given by $P_{X_i}(x;m)=$ ${m}\choose{x} $$p^x(1-p)^{m-x}$ From here I'm kind of stuck. I'm uncertain how I find/calculate the log likelihood function. I've understood the MLE as being taking the derivative with respect to m, setting the equation equal to zero and isolating m (like with most maximization problems). So finding the log likelihood function seems to be my problem Edit: I might be misunderstanding it but could the log likelihood function simple be log of the likelihood function? so $log(P_{X_i}(x;m))$","Let $X_1,X_2,...;X_n$ be a random sample with $X_i$~$Binomial(m,p)$ for $i=1,...,n$ and $m=1,2,3,...$ and let $p\in (0,1)$. We assume $m$ is known and we are given the following data $x_1,...,x_n\in\{0,...,m\}$ Write up the log-likelihood function and find the MLE $\hat{P}ML$ for p I'm not quite sure how to approach this. This is what I've tried: I believe the likelihood function of a Binomial trial is given by $P_{X_i}(x;m)=$ ${m}\choose{x} $$p^x(1-p)^{m-x}$ From here I'm kind of stuck. I'm uncertain how I find/calculate the log likelihood function. I've understood the MLE as being taking the derivative with respect to m, setting the equation equal to zero and isolating m (like with most maximization problems). So finding the log likelihood function seems to be my problem Edit: I might be misunderstanding it but could the log likelihood function simple be log of the likelihood function? so $log(P_{X_i}(x;m))$",,"['probability', 'proof-verification', 'maximum-likelihood', 'log-likelihood']"
47,"A bag contains 3 blue, 3 green and 3 red balls. You pick two balls at random","A bag contains 3 blue, 3 green and 3 red balls. You pick two balls at random",,"What is the probability that you have picked two balls with different colours? Initially I tried to solve this using sampling without replacement, although I wasn't entirely sure if replacement was a factor here as it wasn't explcitly stated. I didn't get very far, as I got confused with the number of combinations, how many balls were picked and how many would be left in each set etc. As is typical for me when I get confused with a probability question, I wrote out the tuples from the sample space and simply counted - this gave me 72 individual tuples, 18 of which were two balls that were the same colour leaving 54 combinations that would yield two different coloured balls. Thus the probability is $\frac{3}{4}$ I then thought to apply the same logic using combinations and tried to figure out what the probability would be of picking two of the same , event S, coloured balls which gave me $$\mathbb{P}(S)=\frac{{3 \choose 2}{3\choose1}}{9 \choose 2} =\frac{1}{4}$$  Thus the event D which is picking two different coloured balls is $$\mathbb{P}(D)=1-\frac{{3 \choose 2}{3\choose1}}{9 \choose 2}=\frac{3}{4}$$ Is this the correct answer? If it is (or even if it isn't) can someone please explain how one would go about doing this using combinations without having to find the probability of the compliment of the event first. Thanks!","What is the probability that you have picked two balls with different colours? Initially I tried to solve this using sampling without replacement, although I wasn't entirely sure if replacement was a factor here as it wasn't explcitly stated. I didn't get very far, as I got confused with the number of combinations, how many balls were picked and how many would be left in each set etc. As is typical for me when I get confused with a probability question, I wrote out the tuples from the sample space and simply counted - this gave me 72 individual tuples, 18 of which were two balls that were the same colour leaving 54 combinations that would yield two different coloured balls. Thus the probability is $\frac{3}{4}$ I then thought to apply the same logic using combinations and tried to figure out what the probability would be of picking two of the same , event S, coloured balls which gave me $$\mathbb{P}(S)=\frac{{3 \choose 2}{3\choose1}}{9 \choose 2} =\frac{1}{4}$$  Thus the event D which is picking two different coloured balls is $$\mathbb{P}(D)=1-\frac{{3 \choose 2}{3\choose1}}{9 \choose 2}=\frac{3}{4}$$ Is this the correct answer? If it is (or even if it isn't) can someone please explain how one would go about doing this using combinations without having to find the probability of the compliment of the event first. Thanks!",,"['probability', 'combinatorics']"
48,"Show that $n\sum_{k=1}^n\frac{1}{k}\sim n\log{n},$ Collector's problem.",Show that  Collector's problem.,"n\sum_{k=1}^n\frac{1}{k}\sim n\log{n},","Consider coupons numbered $1, 2, ..., n,$ which you collect until you   have all numbers. Each time you get a coupon, its number is   independent of previous numbers and all numbers are equally likely.   Let $N$ be the number of coupons you need, and show that (a) $\mathbb E[N] = n\sum^n_{k=1}\frac{1}{k} \sim n\log n$ for large $n$, (b) there is a constant c such that $\operatorname{Var}[N] \sim cn^2$ for large $n$. What is $c$? This is a famous problem called the collector's problem . Here follows one solution for part a) of the question: Let $N$ denote the (random) number of coupons that we need to purchase in order to complete our collection. We can write $N = X_1 + X_2 + . . . + X_n,$ where for any $k = 1, 2, . . . , n,$ $X_k$ denotes the additional number of coupons that we need to purchase to pass from $k − 1$ to $k$ different types of coupons in our collection. Trivially $X_1 = 1$ and, since we are considering the case of a uniform distribution, it follows that when $k$ distinct types of coupons have been collected, a new coupon purchased will be of a distinct type with probability equal to $\frac{n-k}{n}$. By the independence assumption, we get that the random variable $X_k$, for $k ∈ {2,...,N}$, is independent from the other variables and has a geometric law with parameter $\frac{n-k+1}{n}$. The expected number of coupons that we have to buy to complete the collection will be therefore $$\mathbb{E}[N]=\mathbb{E}[X_1]+\mathbb{E}[X_2]+...+\mathbb{E}[X_n] \tag{1}$$ $$=1+\frac{n}{n-1}+\frac{n}{n-2}+...+\frac{n}{2}+n \tag{2}$$ $$=n\sum_{k=1}^n\frac{1}{k}. \tag{3}$$ I don't understand this solution. I have the following questions: Can someone explain the problem statement? What collection is supposed to be completed? What do they mean by compeleted? Why is it trivial that $X_1=1?$ How can we conclude that there is a geometric distribution? First they say that they are considering the case of uniform distribution and then they switch to geometric. I don't see how the $X_k$'s can be independent. If I purchase a coupon, then I have less purchases to make, which changes my probability. How does one show that $(3)=n\log{n}$ as $n\rightarrow \infty?$","Consider coupons numbered $1, 2, ..., n,$ which you collect until you   have all numbers. Each time you get a coupon, its number is   independent of previous numbers and all numbers are equally likely.   Let $N$ be the number of coupons you need, and show that (a) $\mathbb E[N] = n\sum^n_{k=1}\frac{1}{k} \sim n\log n$ for large $n$, (b) there is a constant c such that $\operatorname{Var}[N] \sim cn^2$ for large $n$. What is $c$? This is a famous problem called the collector's problem . Here follows one solution for part a) of the question: Let $N$ denote the (random) number of coupons that we need to purchase in order to complete our collection. We can write $N = X_1 + X_2 + . . . + X_n,$ where for any $k = 1, 2, . . . , n,$ $X_k$ denotes the additional number of coupons that we need to purchase to pass from $k − 1$ to $k$ different types of coupons in our collection. Trivially $X_1 = 1$ and, since we are considering the case of a uniform distribution, it follows that when $k$ distinct types of coupons have been collected, a new coupon purchased will be of a distinct type with probability equal to $\frac{n-k}{n}$. By the independence assumption, we get that the random variable $X_k$, for $k ∈ {2,...,N}$, is independent from the other variables and has a geometric law with parameter $\frac{n-k+1}{n}$. The expected number of coupons that we have to buy to complete the collection will be therefore $$\mathbb{E}[N]=\mathbb{E}[X_1]+\mathbb{E}[X_2]+...+\mathbb{E}[X_n] \tag{1}$$ $$=1+\frac{n}{n-1}+\frac{n}{n-2}+...+\frac{n}{2}+n \tag{2}$$ $$=n\sum_{k=1}^n\frac{1}{k}. \tag{3}$$ I don't understand this solution. I have the following questions: Can someone explain the problem statement? What collection is supposed to be completed? What do they mean by compeleted? Why is it trivial that $X_1=1?$ How can we conclude that there is a geometric distribution? First they say that they are considering the case of uniform distribution and then they switch to geometric. I don't see how the $X_k$'s can be independent. If I purchase a coupon, then I have less purchases to make, which changes my probability. How does one show that $(3)=n\log{n}$ as $n\rightarrow \infty?$",,"['probability', 'probability-theory', 'probability-distributions', 'coupon-collector']"
49,"Show that random variables $X$ and $Y$ are not independent, but nevertheless Cov$[X,Y] = 0$","Show that random variables  and  are not independent, but nevertheless Cov","X Y [X,Y] = 0","Let $Z$ be a random uniformly distributed variable on $[0,1]$. Show that the random variables $X = \sin 2\pi Z$ and $Y = \cos 2\pi Z$ are not independent, but nevertheless Cov$[X,Y]=0$. This is a homework assignment, but I'm a bit stuck. My thoughts We can see that $X$ and $Y$ are not independent, since both depend on $Z$. If we want to show this explicitly, then we need to show that $$f_{X,Y}(a,b) \neq f_X(a)\;f_Y(b),$$ where $f_{X,Y}(a,b)$ is the joint probability distribution function. But how can I find the (joint) probability distribution function(s) $f_X, f_Y$ and $f_{X,Y}$? If I can find these functions, I can also solve the covariance problem. Is this the right way? Or is there a 'better' way to solve this problem?","Let $Z$ be a random uniformly distributed variable on $[0,1]$. Show that the random variables $X = \sin 2\pi Z$ and $Y = \cos 2\pi Z$ are not independent, but nevertheless Cov$[X,Y]=0$. This is a homework assignment, but I'm a bit stuck. My thoughts We can see that $X$ and $Y$ are not independent, since both depend on $Z$. If we want to show this explicitly, then we need to show that $$f_{X,Y}(a,b) \neq f_X(a)\;f_Y(b),$$ where $f_{X,Y}(a,b)$ is the joint probability distribution function. But how can I find the (joint) probability distribution function(s) $f_X, f_Y$ and $f_{X,Y}$? If I can find these functions, I can also solve the covariance problem. Is this the right way? Or is there a 'better' way to solve this problem?",,"['probability', 'random-variables', 'independence', 'correlation']"
50,"When variance is finite, is expectation value also finite?","When variance is finite, is expectation value also finite?",,"Let expectation value of $X$ be denoted as $E(X)$. Now we define the variance $V(X)$ as below. $V(X) \equiv E(X^2) - E(X)^2$ Now, if $V(X) < \infty$, is $E(X)$ also finite? My textbook says so but I don't understand the reason. Jensen's inequality states, for a convex function $h(x)$, $E(h(X)) \geq h(E(X))$ when $E(X)$ and $E(h(X))$ is both finite . For example, $h(x) = x^2$ is a convex function, so we can say $E(X^2) \geq E(X)^2$ but we can use this inequality only when $E(X)$ is finite. So, though Jensen's inequality may be a hint, I don't understand how to use this theorem. Could anyone give me a hint? Note: I've already read Does finite variance imply on a finite mean? , but didn't think the answers were correct because they used Jensen's inequality though whether or not the mean was finite was unknown.","Let expectation value of $X$ be denoted as $E(X)$. Now we define the variance $V(X)$ as below. $V(X) \equiv E(X^2) - E(X)^2$ Now, if $V(X) < \infty$, is $E(X)$ also finite? My textbook says so but I don't understand the reason. Jensen's inequality states, for a convex function $h(x)$, $E(h(X)) \geq h(E(X))$ when $E(X)$ and $E(h(X))$ is both finite . For example, $h(x) = x^2$ is a convex function, so we can say $E(X^2) \geq E(X)^2$ but we can use this inequality only when $E(X)$ is finite. So, though Jensen's inequality may be a hint, I don't understand how to use this theorem. Could anyone give me a hint? Note: I've already read Does finite variance imply on a finite mean? , but didn't think the answers were correct because they used Jensen's inequality though whether or not the mean was finite was unknown.",,"['probability', 'statistics']"
51,Probability Poisson Distribution 90 and 110 calls in a 100 second period,Probability Poisson Distribution 90 and 110 calls in a 100 second period,,"How can i get the probability using poisson distribution of this question: Telephone calls arrive at an exchange at an average rate of one every second. Find the probabilities of the following events, explaining briefly your assumptions. a) No calls arriving in a given five-second period. b) Between four and six calls arriving in the five-second period. c) Between $90$ and $110$ calls arriving in a 100-second period. (Give answer as a decimal.) I got a) and b) but i dont know the way to do c). I know I can use poisson distribution on $$P(X=90) + P(X=91) + \cdots + P(X=110)$$ but I feel like there is an easier way to do this. Thanks","How can i get the probability using poisson distribution of this question: Telephone calls arrive at an exchange at an average rate of one every second. Find the probabilities of the following events, explaining briefly your assumptions. a) No calls arriving in a given five-second period. b) Between four and six calls arriving in the five-second period. c) Between $90$ and $110$ calls arriving in a 100-second period. (Give answer as a decimal.) I got a) and b) but i dont know the way to do c). I know I can use poisson distribution on $$P(X=90) + P(X=91) + \cdots + P(X=110)$$ but I feel like there is an easier way to do this. Thanks",,"['probability', 'poisson-distribution', 'poisson-process']"
52,$X$ standard normal. $Y=X^2$. Find the pdf of $Y$ and covariance between $X$&$Y$,standard normal. . Find the pdf of  and covariance between &,X Y=X^2 Y X Y,"Let $X$ be standard normal random variable, i.e., $X ∼ N(0, 1)$. Consider transformed random variable: $Y = X^2$. (a) Find the probability density function of $Y$. (b) Find the covariance between $X$ and $Y$. I'm new to probability and don't really get yet transformation of random variables. If anyone could help me with this one I'd much appreciate. My work: $F_Y(y)=P(Y\leq y)=P(X^2\leq y)=P(X\leq\sqrt{y})=F_X(\sqrt{y})=\int_{-\infty}^\sqrt{y}\frac{1}{\sqrt{2\pi}}e^{-t^2/2}\,dt$ that's where I'm stuck. Edit: Is the correlation 0 because of the odd-moments popping in the equation?","Let $X$ be standard normal random variable, i.e., $X ∼ N(0, 1)$. Consider transformed random variable: $Y = X^2$. (a) Find the probability density function of $Y$. (b) Find the covariance between $X$ and $Y$. I'm new to probability and don't really get yet transformation of random variables. If anyone could help me with this one I'd much appreciate. My work: $F_Y(y)=P(Y\leq y)=P(X^2\leq y)=P(X\leq\sqrt{y})=F_X(\sqrt{y})=\int_{-\infty}^\sqrt{y}\frac{1}{\sqrt{2\pi}}e^{-t^2/2}\,dt$ that's where I'm stuck. Edit: Is the correlation 0 because of the odd-moments popping in the equation?",,"['probability', 'statistics']"
53,For what values of $k \in \mathbb{Z}\setminus\{0\}$ does there exist an unbiased estimator of $e^{k \lambda}$?,For what values of  does there exist an unbiased estimator of ?,k \in \mathbb{Z}\setminus\{0\} e^{k \lambda},"This is inspired by Finding an unbiased estimator of $e^{-2\lambda}$ for Poisson distribution , reminding me of a qualifying exam question that I was frustrated with. Suppose $X_1, \dots, X_n \overset{\text{iid}}{\sim}\text{Poisson}(\lambda)$. For some subset of size $k \leq n$, it can be seen that if $\mathbf{I}$ is the indicator function that $$\mathbf{I}(X_{i_1}+X_{i_2}+\cdots+X_{i_k}=0)$$ is an unbiased estimator of $e^{-k\lambda}$ for $k \geq 1$. The OP of the linked question above asked an interesting question: does there exist an unbiased estimator of $e^{2\lambda}$? More generally, Is there an unbiased estimator of $e^{k\lambda}$ for $k > 0$? In the comments to the link above, I told the OP I wouldn't know where to begin with this. My first thought was to try finding the distribution of the reciprocal of a Poisson distribution. Say $X \sim \text{Poisson}(\lambda)$, then $$f_{1/X}(y)=\dfrac{e^{-\lambda}\lambda^{1/y}}{(1/y)!}$$ (what is even the support of this thing?) and I suppose $(1/y)!$ would have to be extended in cases where $1/y$ isn't an integer... so basically, every case except $y = 1$, and then we'd have to use the Gamma function. But even with this, using indicator functions (as above) will still give $e^{-k \lambda}$ for $k \geq 1$; it doesn't help the problem much.","This is inspired by Finding an unbiased estimator of $e^{-2\lambda}$ for Poisson distribution , reminding me of a qualifying exam question that I was frustrated with. Suppose $X_1, \dots, X_n \overset{\text{iid}}{\sim}\text{Poisson}(\lambda)$. For some subset of size $k \leq n$, it can be seen that if $\mathbf{I}$ is the indicator function that $$\mathbf{I}(X_{i_1}+X_{i_2}+\cdots+X_{i_k}=0)$$ is an unbiased estimator of $e^{-k\lambda}$ for $k \geq 1$. The OP of the linked question above asked an interesting question: does there exist an unbiased estimator of $e^{2\lambda}$? More generally, Is there an unbiased estimator of $e^{k\lambda}$ for $k > 0$? In the comments to the link above, I told the OP I wouldn't know where to begin with this. My first thought was to try finding the distribution of the reciprocal of a Poisson distribution. Say $X \sim \text{Poisson}(\lambda)$, then $$f_{1/X}(y)=\dfrac{e^{-\lambda}\lambda^{1/y}}{(1/y)!}$$ (what is even the support of this thing?) and I suppose $(1/y)!$ would have to be extended in cases where $1/y$ isn't an integer... so basically, every case except $y = 1$, and then we'd have to use the Gamma function. But even with this, using indicator functions (as above) will still give $e^{-k \lambda}$ for $k \geq 1$; it doesn't help the problem much.",,"['probability', 'probability-distributions', 'poisson-distribution', 'parameter-estimation']"
54,Probability problem: $60$ workers in an industry,Probability problem:  workers in an industry,60,"Let's say there is an industry that employs $60$ workers, among these $60$ workers, $57$ are honest and the other $3$ are spies of another industry. Let's say that the industry starts a new project, so $4$ workers from the $60$ are randomly chosen (without replacement). We guess that the project will leak if among those $4$ workers selected, there is at least $1$ spy. i) What's the probability of choosing all $3$ spies? ii) What's the probability of project not to leak? iii) Taking as a fact that the project leaked, what's the probability of that all 3 spies are chosen? What I have achieved so far: i) There are $\binom{60}{4}$ ways to chose $4$ workers from $60$ . Chosing all the spies mean that the team created has $3$ spies and $1$ honest worker. So there are $\binom {3}{3}$ ways to chose $3$ spies and $\binom {57}{1}$ to choose $1$ honest worker. Let $A$ be the probability of chosing all spies, the answer is : $$P(A) = \frac{\binom {3}{3}\cdot\binom{57}{1}}{\binom {60}{4}}.$$ ii) If we want the project not to leak, we need to create a team with $4$ honest workers and $0$ spies. So, there are $\binom {57}{4}$ ways to chose $4$ workers from $57$ honest ones. Let $B$ be the probability of project not to leak, the answer is: $$P(B) = \frac{\binom {3}{0}\cdot\binom{57}{4}}{\binom {60}{4}}.$$ iii) Here we have conditional probability and we need to find $$P(A \mid B') = \dfrac{P(A\cap B')}{B'}.$$ Now I am not really sure what to do exactly. Any hint would be valueable.","Let's say there is an industry that employs workers, among these workers, are honest and the other are spies of another industry. Let's say that the industry starts a new project, so workers from the are randomly chosen (without replacement). We guess that the project will leak if among those workers selected, there is at least spy. i) What's the probability of choosing all spies? ii) What's the probability of project not to leak? iii) Taking as a fact that the project leaked, what's the probability of that all 3 spies are chosen? What I have achieved so far: i) There are ways to chose workers from . Chosing all the spies mean that the team created has spies and honest worker. So there are ways to chose spies and to choose honest worker. Let be the probability of chosing all spies, the answer is : ii) If we want the project not to leak, we need to create a team with honest workers and spies. So, there are ways to chose workers from honest ones. Let be the probability of project not to leak, the answer is: iii) Here we have conditional probability and we need to find Now I am not really sure what to do exactly. Any hint would be valueable.",60 60 57 3 4 60 4 1 3 \binom{60}{4} 4 60 3 1 \binom {3}{3} 3 \binom {57}{1} 1 A P(A) = \frac{\binom {3}{3}\cdot\binom{57}{1}}{\binom {60}{4}}. 4 0 \binom {57}{4} 4 57 B P(B) = \frac{\binom {3}{0}\cdot\binom{57}{4}}{\binom {60}{4}}. P(A \mid B') = \dfrac{P(A\cap B')}{B'}.,"['probability', 'combinatorics']"
55,On finding the asymptotic distribution of the coefficient of variation,On finding the asymptotic distribution of the coefficient of variation,,"Given an IID sample $X_1, \dots, X_n \sim N(\mu, \sigma^2)$ with $\mu \ne 0$ let $$(S_n)^2 = \frac{1}{n} \sum_{i = 1}^n ( X_i - \overline{X_n})^2$$ I want to find the distribution of the coefficient of variation $\frac{S_n}{\bar{X}_n}$ where $\bar{X}_n$ is the sample mean. I have come up with an entire solution but there appears to be an error I can't find. MY SOLUTION : $S_n$ is asymptotically consistent for $\sigma \implies \frac{S_n}{\sigma} \xrightarrow{p}1$ Since $ \sqrt{n}(\bar{X}_n - \mu)$ converges to a normal distribution (by the central limit theorem)  by the delta method we have that $\sqrt{n} \frac{\sigma}{\bar{X}_n}$ converges in distribution to $$  \frac{\sigma^2}{\mu^2}Z $$ where $Z \sim N\left(\frac{\sigma}{\mu}, 1\right) $ this is because we have chosen $\phi(x) = \frac{\sigma}{x} \implies \phi'(x) = -\frac{\sigma}{x^2} $. ($\phi$ is the function we are applying to the sequence of random variables). Now from Slutsky's theorem we have that $$\sqrt{n} \frac{S_n}{\bar{X}_n } = \sqrt{n}\frac{S_n/ \sigma}{\bar{X}_n / \sigma} \xrightarrow{d} N\left( \frac{\sigma}{\mu},\frac{\sigma^4}{\mu^4}\right)$$ Except the solution I am given has $N\left(\frac{\sigma}{\mu},\frac{\sigma^2}{2\mu^2}\right)$ Where is my mistake?","Given an IID sample $X_1, \dots, X_n \sim N(\mu, \sigma^2)$ with $\mu \ne 0$ let $$(S_n)^2 = \frac{1}{n} \sum_{i = 1}^n ( X_i - \overline{X_n})^2$$ I want to find the distribution of the coefficient of variation $\frac{S_n}{\bar{X}_n}$ where $\bar{X}_n$ is the sample mean. I have come up with an entire solution but there appears to be an error I can't find. MY SOLUTION : $S_n$ is asymptotically consistent for $\sigma \implies \frac{S_n}{\sigma} \xrightarrow{p}1$ Since $ \sqrt{n}(\bar{X}_n - \mu)$ converges to a normal distribution (by the central limit theorem)  by the delta method we have that $\sqrt{n} \frac{\sigma}{\bar{X}_n}$ converges in distribution to $$  \frac{\sigma^2}{\mu^2}Z $$ where $Z \sim N\left(\frac{\sigma}{\mu}, 1\right) $ this is because we have chosen $\phi(x) = \frac{\sigma}{x} \implies \phi'(x) = -\frac{\sigma}{x^2} $. ($\phi$ is the function we are applying to the sequence of random variables). Now from Slutsky's theorem we have that $$\sqrt{n} \frac{S_n}{\bar{X}_n } = \sqrt{n}\frac{S_n/ \sigma}{\bar{X}_n / \sigma} \xrightarrow{d} N\left( \frac{\sigma}{\mu},\frac{\sigma^4}{\mu^4}\right)$$ Except the solution I am given has $N\left(\frac{\sigma}{\mu},\frac{\sigma^2}{2\mu^2}\right)$ Where is my mistake?",,"['probability', 'probability-theory', 'asymptotics', 'normal-distribution']"
56,Does this probability density function have a name?,Does this probability density function have a name?,,I have a random variable distributed according to the density function $$P(x)=|x|e^{-x^2}$$ Does this pdf have a name?,I have a random variable distributed according to the density function $$P(x)=|x|e^{-x^2}$$ Does this pdf have a name?,,"['probability', 'statistics']"
57,The converse on the Central Limit Theorem,The converse on the Central Limit Theorem,,"The problem is the following: let $X_n$ be i.i.d r.v's and $\{b_n\}$ be a sequence of positive real numbers s.t. $b_n \longrightarrow \infty$ and $$ (I) \qquad \frac{\sum_{k=1}^n X_k }{b_n} \Rightarrow\mathcal{N}(0,1), $$ where $\Rightarrow$ denotes convergence in distribuition. Does this imply that $X_n$ has finite second moment? My intuition makes me think so, but I am not sure. I will show my idea in a very informal way, because I am actually struggling to prove a few passages, but at the end I will mention exactly what passages are being troublesome to me. First, for a $m \in \mathbb{N}$, we divide my sum in independent blocks that converge to the same distribution, $$ (II) \qquad  \frac{\sum_{k=1}^{mn} X_k }{b_{mn}} = \frac{b_{n}}{b_{mn}} \frac{\sum_{k=1}^{n} X_k }{b_{n}} + \cdots + \frac{b_{n}}{b_{mn}}\frac{\sum_{k=(m-1)n}^{mn} X_k }{b_{n}}.  $$ As those blocks are independent, I could write the limit in the RHS as  $$ \qquad\beta_m \xi_1+\cdots+ \beta_m \xi_m $$ where $\beta_k := \lim_{n \to \infty}\frac{b_{n}}{b_{mn}}$ and $\xi_i \sim \mathcal{N}(0,1)$. But evaluating the limit in the LHS of $(II)$, I have that $ \beta_m \xi_1+\cdots+ \beta_m \xi_m \sim \mathcal{N}(0,1)  $ hence the $\beta_m = m^{1/2}$. Therefore I would have that $$ (III)\qquad\lim_{n \to \infty}\frac{b_{n}}{b_{mn}} = \frac{1}{\sqrt{m}} $$ Which I believe that implies  $$ (IV)\qquad b_n = \sigma\sqrt{n}+o(1). $$ So finally, we are basically reduced to the the usual form $$ \frac{\sum_{k=1}^n X_k }{\sqrt{n}} \Rightarrow\mathcal{N}(0,\sigma ), $$ For $S_n\sum_{k=1}^n X_k$, we have that $$ E\Big[\frac{S^2_n}{n}\wedge M \Big] \longrightarrow E[\sigma \xi^2 \wedge M] \text{ as } n \longrightarrow \infty  $$ for all $M>0$, but the RHS is always smaller than $1$. And if $E[X_k^2]=\infty$, by monotone convergence  $$ E\Big[\frac{S^2_n}{n}\wedge M \Big] \longrightarrow E[X_k^2] \text{ as } M \longrightarrow \infty  $$ Which, with a bit of care can be show to be a contradiction, hence $E[X_k^2]<\infty$. So to the parts that I am finding difficult: Does the limit $(II)$ for $(I)$ to make sense? If not, does it exist in the case that $b_n e^{cn} \longrightarrow $ for all $c>0$? Does $(III)$ imply $(IV)$?","The problem is the following: let $X_n$ be i.i.d r.v's and $\{b_n\}$ be a sequence of positive real numbers s.t. $b_n \longrightarrow \infty$ and $$ (I) \qquad \frac{\sum_{k=1}^n X_k }{b_n} \Rightarrow\mathcal{N}(0,1), $$ where $\Rightarrow$ denotes convergence in distribuition. Does this imply that $X_n$ has finite second moment? My intuition makes me think so, but I am not sure. I will show my idea in a very informal way, because I am actually struggling to prove a few passages, but at the end I will mention exactly what passages are being troublesome to me. First, for a $m \in \mathbb{N}$, we divide my sum in independent blocks that converge to the same distribution, $$ (II) \qquad  \frac{\sum_{k=1}^{mn} X_k }{b_{mn}} = \frac{b_{n}}{b_{mn}} \frac{\sum_{k=1}^{n} X_k }{b_{n}} + \cdots + \frac{b_{n}}{b_{mn}}\frac{\sum_{k=(m-1)n}^{mn} X_k }{b_{n}}.  $$ As those blocks are independent, I could write the limit in the RHS as  $$ \qquad\beta_m \xi_1+\cdots+ \beta_m \xi_m $$ where $\beta_k := \lim_{n \to \infty}\frac{b_{n}}{b_{mn}}$ and $\xi_i \sim \mathcal{N}(0,1)$. But evaluating the limit in the LHS of $(II)$, I have that $ \beta_m \xi_1+\cdots+ \beta_m \xi_m \sim \mathcal{N}(0,1)  $ hence the $\beta_m = m^{1/2}$. Therefore I would have that $$ (III)\qquad\lim_{n \to \infty}\frac{b_{n}}{b_{mn}} = \frac{1}{\sqrt{m}} $$ Which I believe that implies  $$ (IV)\qquad b_n = \sigma\sqrt{n}+o(1). $$ So finally, we are basically reduced to the the usual form $$ \frac{\sum_{k=1}^n X_k }{\sqrt{n}} \Rightarrow\mathcal{N}(0,\sigma ), $$ For $S_n\sum_{k=1}^n X_k$, we have that $$ E\Big[\frac{S^2_n}{n}\wedge M \Big] \longrightarrow E[\sigma \xi^2 \wedge M] \text{ as } n \longrightarrow \infty  $$ for all $M>0$, but the RHS is always smaller than $1$. And if $E[X_k^2]=\infty$, by monotone convergence  $$ E\Big[\frac{S^2_n}{n}\wedge M \Big] \longrightarrow E[X_k^2] \text{ as } M \longrightarrow \infty  $$ Which, with a bit of care can be show to be a contradiction, hence $E[X_k^2]<\infty$. So to the parts that I am finding difficult: Does the limit $(II)$ for $(I)$ to make sense? If not, does it exist in the case that $b_n e^{cn} \longrightarrow $ for all $c>0$? Does $(III)$ imply $(IV)$?",,"['probability', 'probability-theory', 'random-variables', 'central-limit-theorem']"
58,What are the most fundamental applications of probability theory outside pure math?,What are the most fundamental applications of probability theory outside pure math?,,"What are the most important / fundamental / classical applications of probability theory outside of pure math? What were some of the original ""home runs"" of probability theory -- things that we could not do before, but which were very useful. Things that would make people say, ""Gosh, we've hit on a big idea here."" One example would be that probability is used in Quantum Mechanics. That's a good one, but I believe probability had already proved to be very useful even before QM came along.","What are the most important / fundamental / classical applications of probability theory outside of pure math? What were some of the original ""home runs"" of probability theory -- things that we could not do before, but which were very useful. Things that would make people say, ""Gosh, we've hit on a big idea here."" One example would be that probability is used in Quantum Mechanics. That's a good one, but I believe probability had already proved to be very useful even before QM came along.",,['probability']
59,Question in basic probability-coin tossing,Question in basic probability-coin tossing,,"Came across the following question: Given a coin with probability $0< p< 1$ to fall on ""head"". Tossing it independently. Given $n,m\in\mathbb{N}$ what is the probability to get $n$ ""head""s before $m$ ""tail""s? My approach was: the n heads need to occur in the $(n+m-1)$ first tosses. There're $n+m-1\choose n$ ways to pick $n$ elements from this group.   In each pick, we need to have $n$ heads meaning the probability is $p^n$. Summing all up I get ${n+m-1\choose n}\cdot p^n$. The result in the book is: $\sum_{k=n}^{m+n-1}{n+m-1\choose k}\cdot p^{k}\cdot (1-p)^{n+m-1-k}$ which I don't understand why.","Came across the following question: Given a coin with probability $0< p< 1$ to fall on ""head"". Tossing it independently. Given $n,m\in\mathbb{N}$ what is the probability to get $n$ ""head""s before $m$ ""tail""s? My approach was: the n heads need to occur in the $(n+m-1)$ first tosses. There're $n+m-1\choose n$ ways to pick $n$ elements from this group.   In each pick, we need to have $n$ heads meaning the probability is $p^n$. Summing all up I get ${n+m-1\choose n}\cdot p^n$. The result in the book is: $\sum_{k=n}^{m+n-1}{n+m-1\choose k}\cdot p^{k}\cdot (1-p)^{n+m-1-k}$ which I don't understand why.",,"['probability', 'probability-distributions']"
60,Basket with Lilies and Roses. Find the number of roses.,Basket with Lilies and Roses. Find the number of roses.,,"Ques: A covered basket of flowers has some lilies and roses. In search of rose, Sweety and Shweta alternately pick up a flower from the basket but put it back if it is not a rose. Sweety is 3 times more likely to be the first one to pick a rose. If sweety begin this 'rose hunt' and if there are 60 lilies in the basket, find the number of roses in the basket. Let the roses be x and lilies be y. Since they find all of the x roses finally $$ x!/(x+y)! + y/(x+y) * x!/(x+y)! \cdots = 1  $$ So to be straight forward, I do not have any good idea how to deal with this.","Ques: A covered basket of flowers has some lilies and roses. In search of rose, Sweety and Shweta alternately pick up a flower from the basket but put it back if it is not a rose. Sweety is 3 times more likely to be the first one to pick a rose. If sweety begin this 'rose hunt' and if there are 60 lilies in the basket, find the number of roses in the basket. Let the roses be x and lilies be y. Since they find all of the x roses finally $$ x!/(x+y)! + y/(x+y) * x!/(x+y)! \cdots = 1  $$ So to be straight forward, I do not have any good idea how to deal with this.",,"['probability', 'elementary-probability']"
61,Expected number of coin tosses before obtaining at least 1 head,Expected number of coin tosses before obtaining at least 1 head,,"We have covered conditional probabilities and law of total expectation so far but I have a very poor understanding of those concepts. I have absolutely no clue on how to proceed with this question: A fair die is thrown and a coin is tossed the number of times as the score shown on the die. If any heads are shown in the tosses of the coin, we stop, otherwise, we continue the experiment of throwing the die and coin toss until at least one head is shown. Find the expected number of coin tosses before we stop.","We have covered conditional probabilities and law of total expectation so far but I have a very poor understanding of those concepts. I have absolutely no clue on how to proceed with this question: A fair die is thrown and a coin is tossed the number of times as the score shown on the die. If any heads are shown in the tosses of the coin, we stop, otherwise, we continue the experiment of throwing the die and coin toss until at least one head is shown. Find the expected number of coin tosses before we stop.",,"['probability', 'expectation']"
62,Variance of $T_n = \min_i \{ X_i \} + \max_i \{ X_i \}$,Variance of,T_n = \min_i \{ X_i \} + \max_i \{ X_i \},"Let $X$ be a random variable with distribution $\operatorname{Unif}(0, \theta)$. Draw IID $X_1, X_2, \ldots, X_n$ and calculate the moment method estimator. Compare it with $T_n = \min_i \{ X_i \}   + \max_i \{ X_i \}$. Attempt : We easily find $$\theta' = \frac {2(X_1 + \cdots + X_n)}{n}. $$ I received the broad question as ""compare the variances of the two estimators"" at finite or at least asymptotically, but I can't compute $V(T_n)$. Is it possible? I can say $V(T_n) > V(\max_i \{ X_i \})$ because $\min_i \{ X_i \}$ and $\max_i \{ X_i \}$ should be positively correlated, and I'm able to find the distribution of $\max_i \{ X_i \}$ and compute its variance. Thanks!","Let $X$ be a random variable with distribution $\operatorname{Unif}(0, \theta)$. Draw IID $X_1, X_2, \ldots, X_n$ and calculate the moment method estimator. Compare it with $T_n = \min_i \{ X_i \}   + \max_i \{ X_i \}$. Attempt : We easily find $$\theta' = \frac {2(X_1 + \cdots + X_n)}{n}. $$ I received the broad question as ""compare the variances of the two estimators"" at finite or at least asymptotically, but I can't compute $V(T_n)$. Is it possible? I can say $V(T_n) > V(\max_i \{ X_i \})$ because $\min_i \{ X_i \}$ and $\max_i \{ X_i \}$ should be positively correlated, and I'm able to find the distribution of $\max_i \{ X_i \}$ and compute its variance. Thanks!",,"['probability', 'statistics', 'statistical-inference', 'uniform-distribution', 'variance']"
63,Is this a combinatorial identity: $ \sum_{k=1}^{n+1}\binom{n+1}{k} \sum_{i=0}^{k-1}\binom{n}{i} = 2^{2n} $?,Is this a combinatorial identity: ?, \sum_{k=1}^{n+1}\binom{n+1}{k} \sum_{i=0}^{k-1}\binom{n}{i} = 2^{2n} ,"$$ \sum_{k=1}^{n+1}\left(\binom{n+1}{k} \sum_{i=0}^{k-1}\binom{n}{i}\right) = 2^{2n} $$ This is my first question, please feel free to correct/guide me. While solving a probability problem from a text book l reduced the problem to the above LHS. I couldn't reduce it any further. I tried a few values of n and it holds. I gave a half hearted attempt at induction before I gave up. Does this hold? Is there a combinatorial proof to it(assuming it holds) i.e count something one way and count the same thing other way and then equate them. Is there a name to it? Most importantly how to Google such questions? To provide further context, the problem is as follows:- Alice and Bob have a total of $2n+1$ fair coins. Bob tosses $n+1$ coins while Alice tosses $n$ coins. Tosses are independent. What is the probability that Bob tossed more heads than Alice? It is from a standard textbook ""Introduction to Probability"" by Dmitri and N John.","$$ \sum_{k=1}^{n+1}\left(\binom{n+1}{k} \sum_{i=0}^{k-1}\binom{n}{i}\right) = 2^{2n} $$ This is my first question, please feel free to correct/guide me. While solving a probability problem from a text book l reduced the problem to the above LHS. I couldn't reduce it any further. I tried a few values of n and it holds. I gave a half hearted attempt at induction before I gave up. Does this hold? Is there a combinatorial proof to it(assuming it holds) i.e count something one way and count the same thing other way and then equate them. Is there a name to it? Most importantly how to Google such questions? To provide further context, the problem is as follows:- Alice and Bob have a total of $2n+1$ fair coins. Bob tosses $n+1$ coins while Alice tosses $n$ coins. Tosses are independent. What is the probability that Bob tossed more heads than Alice? It is from a standard textbook ""Introduction to Probability"" by Dmitri and N John.",,['probability']
64,Indicator variable with boxes and balls,Indicator variable with boxes and balls,,"We have 10 blue balls labeled from 1 to 10 and 10 red balls with same labels and we randomly put them into 10 boxes so that in each box is one blue and one red ball. Find the expected number of boxes, that have blue and red ball with same labels. In solution it says let indicator value have properties I(0) = 9/10 and I(1)=1/10. E(X)=10*1/10 = 1 Now I don't understand why, because I would say I(1) = 10*(2C2) / (20C2) since we have to pick 2 balls out of 20 and we have 10 pair of them ({1,1},{2,2},..). And E(X) 10*I(1). But is it 1/10 because we have to choose one pair out of 10? If that is true, why can we say that, since the number of all combinations is 20C2.","We have 10 blue balls labeled from 1 to 10 and 10 red balls with same labels and we randomly put them into 10 boxes so that in each box is one blue and one red ball. Find the expected number of boxes, that have blue and red ball with same labels. In solution it says let indicator value have properties I(0) = 9/10 and I(1)=1/10. E(X)=10*1/10 = 1 Now I don't understand why, because I would say I(1) = 10*(2C2) / (20C2) since we have to pick 2 balls out of 20 and we have 10 pair of them ({1,1},{2,2},..). And E(X) 10*I(1). But is it 1/10 because we have to choose one pair out of 10? If that is true, why can we say that, since the number of all combinations is 20C2.",,"['probability', 'combinatorics', 'random-variables', 'combinations', 'balls-in-bins']"
65,Probability of flipping at least 2 heads when flipping a coin 100 times,Probability of flipping at least 2 heads when flipping a coin 100 times,,"I tried using finding the contrary, that is the probability of getting 1 (100C1/2^100) heads and then 0 heads (100C0/2^100) and using the formula that P = 1 - P(b), where P(b) is the probability of the opposite. But when. I do P = 1 - ((100C1/2^100) + (100C0/2^100)), I get 1... which doesn't make any sense. So I'm not sure where I'm going wrong here.","I tried using finding the contrary, that is the probability of getting 1 (100C1/2^100) heads and then 0 heads (100C0/2^100) and using the formula that P = 1 - P(b), where P(b) is the probability of the opposite. But when. I do P = 1 - ((100C1/2^100) + (100C0/2^100)), I get 1... which doesn't make any sense. So I'm not sure where I'm going wrong here.",,"['probability', 'combinatorics', 'permutations']"
66,What is an unbiased estimator and utility of fisher information,What is an unbiased estimator and utility of fisher information,,"I am self learning estimation theory and finding it quite difficult to grasp the utility of Cramer Rao Lower bound. In text books and online tutorials always say that one should derive the CRLB of the estimator. If the variance of the estimator is greater than equal to the inverse of the Fisher information, then we say that no  other better estimator exists. The inverse of the Fisher information is the CRLB.  If the variance is equal to the CRLB, then the estimator is efficient. Intuitively, an estimator is nothing but a formula or an expression that is used to find an unknown value/ parameter. 1) Is there a better intuitive way to explain what CRLB bound tells us and why we need it? 2) What is meant by efficient estimator and efficiency to do what? With what do we compare the efficiency of an estimator. These questions may be trivial but I found very difficult to extract key information from highly mathematical heavy stuff. 3) Do we discard the estimator if inefficient? Please correct me if any information is wrong. Thank you.","I am self learning estimation theory and finding it quite difficult to grasp the utility of Cramer Rao Lower bound. In text books and online tutorials always say that one should derive the CRLB of the estimator. If the variance of the estimator is greater than equal to the inverse of the Fisher information, then we say that no  other better estimator exists. The inverse of the Fisher information is the CRLB.  If the variance is equal to the CRLB, then the estimator is efficient. Intuitively, an estimator is nothing but a formula or an expression that is used to find an unknown value/ parameter. 1) Is there a better intuitive way to explain what CRLB bound tells us and why we need it? 2) What is meant by efficient estimator and efficiency to do what? With what do we compare the efficiency of an estimator. These questions may be trivial but I found very difficult to extract key information from highly mathematical heavy stuff. 3) Do we discard the estimator if inefficient? Please correct me if any information is wrong. Thank you.",,"['probability', 'statistics', 'parameter-estimation']"
67,How to preserve ignorance in backpropagation learning?,How to preserve ignorance in backpropagation learning?,,"In machine learning it is important not only to correctly classify things based on observations that have been made, but also to know how unsure one is in an area where not many observations have been made. How can this be achieved? Which methods exist to avoid getting the network to extrapolate into areas we actually don't know much? (I am particularly interested in approaches for neural networks trained by error back propagation). Here is an example of what I want to achieve which I just accidentally accomplished in this case The training data are the cluster points and the colored image is the prediction map. Pure blue, red or green color means close to 100% confidence and in between colors like purple and yellow mean a large uncertainty between the classes of which colors are mixed :","In machine learning it is important not only to correctly classify things based on observations that have been made, but also to know how unsure one is in an area where not many observations have been made. How can this be achieved? Which methods exist to avoid getting the network to extrapolate into areas we actually don't know much? (I am particularly interested in approaches for neural networks trained by error back propagation). Here is an example of what I want to achieve which I just accidentally accomplished in this case The training data are the cluster points and the colored image is the prediction map. Pure blue, red or green color means close to 100% confidence and in between colors like purple and yellow mean a large uncertainty between the classes of which colors are mixed :",,"['calculus', 'probability', 'reference-request', 'machine-learning']"
68,Seven-sided dice from five-sided dice with finite rolls,Seven-sided dice from five-sided dice with finite rolls,,"I have a 5-sided dice, and I want to use it to simulate a 7-sided dice. Is there a way to do this with a finite number of rolls?","I have a 5-sided dice, and I want to use it to simulate a 7-sided dice. Is there a way to do this with a finite number of rolls?",,"['probability', 'dice', 'uniform-distribution']"
69,Answer verification for Binomial Distribution problem,Answer verification for Binomial Distribution problem,,Question: You buy a certain type of lottery ticket once a week for 4 weeks.  What's the probability you win a cash prize exactly twice? My attempt: P(Success) = $1/4 $ P(Not Successful) =$ 3/4$ $$4 \ _nC^r \ 2 \times \bigg(\frac{1}{4}\bigg)^2 \times \bigg(\frac{3}{4}\bigg)^2 = 0.2109375$$ Is my answer correct?,Question: You buy a certain type of lottery ticket once a week for 4 weeks.  What's the probability you win a cash prize exactly twice? My attempt: P(Success) = $1/4 $ P(Not Successful) =$ 3/4$ $$4 \ _nC^r \ 2 \times \bigg(\frac{1}{4}\bigg)^2 \times \bigg(\frac{3}{4}\bigg)^2 = 0.2109375$$ Is my answer correct?,,['probability']
70,Why mean independence does not imply independence?,Why mean independence does not imply independence?,,"Why mean independence does not imply independence? I considered $$ \mathbb{E}(X\mid Y=y) = \mathbb{E}(X) \text{ for all } y\in \mathcal{Y} $$ This implies that $$\int_\mathcal{X} x f_{X\mid Y} (x,y) \,dx = \int_{\mathcal{X}} x f_X (x) \,dx \text{ for all } y \in \mathcal{Y}$$ For the equality to hold, the left hand side cannot have any $y$ in it after we do the integration. This seems to suggest that $f_{X\mid Y} (x,y)$ has to be free of $y$. Then, if $f_{X\mid Y} (x,y)$ is free of $y$, and the equality holds, it seems that we must have $f_{X\mid Y} (x,y) = f_X (x)$. I think the last statement I made could have some problem because we probably only have $f_{X\mid Y} (x,y) = f_X (x)$ almost everywhere . But what would be an elementary counterexample?","Why mean independence does not imply independence? I considered $$ \mathbb{E}(X\mid Y=y) = \mathbb{E}(X) \text{ for all } y\in \mathcal{Y} $$ This implies that $$\int_\mathcal{X} x f_{X\mid Y} (x,y) \,dx = \int_{\mathcal{X}} x f_X (x) \,dx \text{ for all } y \in \mathcal{Y}$$ For the equality to hold, the left hand side cannot have any $y$ in it after we do the integration. This seems to suggest that $f_{X\mid Y} (x,y)$ has to be free of $y$. Then, if $f_{X\mid Y} (x,y)$ is free of $y$, and the equality holds, it seems that we must have $f_{X\mid Y} (x,y) = f_X (x)$. I think the last statement I made could have some problem because we probably only have $f_{X\mid Y} (x,y) = f_X (x)$ almost everywhere . But what would be an elementary counterexample?",,"['probability', 'analysis', 'probability-theory', 'examples-counterexamples']"
71,$\operatorname{P}$ vs. $P$ in probability,vs.  in probability,\operatorname{P} P,"Below are three separate notations my textbook uses: $\operatorname{P}(X)$: the probability that an event $X$, which is a subset of the sample space, occurs $\operatorname{P}(X=x)$: the probability the random variable $X$ assumes the specific numerical value $x$ $P(x)$: probability distribution function , where $P(x)=\operatorname{P}(X=x)$ I understand that it’s generally claimed that upright font is meant to indicate operators while slanted or italicizes font is meant to indicate variables and functions, but in reality, the conventions are much more nuanced than that. So, why the care to distinguish $\operatorname{P}$ from $P$? How important is it to do so? Is this simply a regional convention? I have noticed that Europeans use upright symbols more than do Americans (e.g., $\mathrm{d}x$ vs. $dx$), which could account for what I’m seeing. If you’re curious, my textbook is Mathematics for the International Student: Mathematics HL (Core) third edition by Haese et al. and is Australian in origin.","Below are three separate notations my textbook uses: $\operatorname{P}(X)$: the probability that an event $X$, which is a subset of the sample space, occurs $\operatorname{P}(X=x)$: the probability the random variable $X$ assumes the specific numerical value $x$ $P(x)$: probability distribution function , where $P(x)=\operatorname{P}(X=x)$ I understand that it’s generally claimed that upright font is meant to indicate operators while slanted or italicizes font is meant to indicate variables and functions, but in reality, the conventions are much more nuanced than that. So, why the care to distinguish $\operatorname{P}$ from $P$? How important is it to do so? Is this simply a regional convention? I have noticed that Europeans use upright symbols more than do Americans (e.g., $\mathrm{d}x$ vs. $dx$), which could account for what I’m seeing. If you’re curious, my textbook is Mathematics for the International Student: Mathematics HL (Core) third edition by Haese et al. and is Australian in origin.",,"['probability', 'notation', 'random-variables']"
72,Probability of rolling the same number twice in more than one round,Probability of rolling the same number twice in more than one round,,"If two people roll a die, the probability of rolling the same number is $1/6$. But what if they try it for example $3$ more times? How high is the probability that they will roll the same number at least once in $4$ rounds? I think that after the first round the probability is $1/6$ that the numbers are the same and $5/6$ that they are not. In a second round this continues like in the tree below: ___________    /           \   1/6          5/6  /   \        /   \ 1/6  5/6     5/6  1/6 Now to calculate the probability after the second round, that they have at least in one round the same answer is: $$(1/6 \cdot 1/6) + (1/6 \cdot 5/6) + (5/6 \cdot 1/6) =  11/36 \approx 30\%$$ Is that right?","If two people roll a die, the probability of rolling the same number is $1/6$. But what if they try it for example $3$ more times? How high is the probability that they will roll the same number at least once in $4$ rounds? I think that after the first round the probability is $1/6$ that the numbers are the same and $5/6$ that they are not. In a second round this continues like in the tree below: ___________    /           \   1/6          5/6  /   \        /   \ 1/6  5/6     5/6  1/6 Now to calculate the probability after the second round, that they have at least in one round the same answer is: $$(1/6 \cdot 1/6) + (1/6 \cdot 5/6) + (5/6 \cdot 1/6) =  11/36 \approx 30\%$$ Is that right?",,"['probability', 'dice']"
73,"Is this statement true: $\mathsf{Cov}(X,Y)\geq 0$, $\mathsf{P}(Y>0)=1$, show that $\mathsf{Cov}\Big(X,\dfrac{1}{Y}\Big)\leq 0$","Is this statement true: , , show that","\mathsf{Cov}(X,Y)\geq 0 \mathsf{P}(Y>0)=1 \mathsf{Cov}\Big(X,\dfrac{1}{Y}\Big)\leq 0","I was trying to prove a problem and I got stuck at a point. The problem leads to a point where I have to show: Let, $X$ and $Y$ are two r.v. If $\mathsf{Cov}(X,Y)\geq 0$ and $\mathsf{P}(Y>0)=1$, then show that $\mathsf{Cov}\Big(X,\dfrac{1}{Y}\Big)\leq 0$. But I could not find a way to go from $Y$ to $\dfrac{1}{Y}$, also I have a feeling that there may be a counterexample of the problem. Any help would be appreciated. Thanks to Einar Rødland , but in the problem I did not have $(X,Y)$ and $(X, 1/Y)$ same in distribution. The problem was to show if $\mathsf{E}\Big(\dfrac{Z_1-Z_2}{Z_1+Z_2}\Big)\geq 0$, then $\mathsf{E}(Z_1-Z_2)\geq 0$, where $Z_1$ and $Z_2$ are different positive r.v. and $\mathsf{Cov}(Z_1+Z_2,Z_1-Z_2)\geq 0$","I was trying to prove a problem and I got stuck at a point. The problem leads to a point where I have to show: Let, $X$ and $Y$ are two r.v. If $\mathsf{Cov}(X,Y)\geq 0$ and $\mathsf{P}(Y>0)=1$, then show that $\mathsf{Cov}\Big(X,\dfrac{1}{Y}\Big)\leq 0$. But I could not find a way to go from $Y$ to $\dfrac{1}{Y}$, also I have a feeling that there may be a counterexample of the problem. Any help would be appreciated. Thanks to Einar Rødland , but in the problem I did not have $(X,Y)$ and $(X, 1/Y)$ same in distribution. The problem was to show if $\mathsf{E}\Big(\dfrac{Z_1-Z_2}{Z_1+Z_2}\Big)\geq 0$, then $\mathsf{E}(Z_1-Z_2)\geq 0$, where $Z_1$ and $Z_2$ are different positive r.v. and $\mathsf{Cov}(Z_1+Z_2,Z_1-Z_2)\geq 0$",,"['probability', 'statistics', 'covariance']"
74,Derangement without replacement,Derangement without replacement,,"Each of $n \geq2$ people puts his or her name on a slip of paper (no two have the same   name). The slips of paper are shuffled in a hat, and then each person draws one (uniformly   at random at each stage, without replacement). Find the average number of   people who draw their own names. Does this match the pattern of derangements? I can't wrap my head around the fact that this does not allow replacement. EDIT 2: Adding to the comment of @drhab . The probability that the first person draws his own name is $\frac1n$ . By symmetry, anyone could be the first person. So, $$P[X_i] = \frac1n.$$ And summing over $n$ (linearity of expectation), I get $1$ . Is my approach correct? I am not super confident. I am trying to self-study probability using Blizstein's lectures and book, and I keep getting stuck in most of the questions.","Each of people puts his or her name on a slip of paper (no two have the same   name). The slips of paper are shuffled in a hat, and then each person draws one (uniformly   at random at each stage, without replacement). Find the average number of   people who draw their own names. Does this match the pattern of derangements? I can't wrap my head around the fact that this does not allow replacement. EDIT 2: Adding to the comment of @drhab . The probability that the first person draws his own name is . By symmetry, anyone could be the first person. So, And summing over (linearity of expectation), I get . Is my approach correct? I am not super confident. I am trying to self-study probability using Blizstein's lectures and book, and I keep getting stuck in most of the questions.",n \geq2 \frac1n P[X_i] = \frac1n. n 1,"['probability', 'derangements']"
75,The probability behind Bitcoin.,The probability behind Bitcoin.,,"I'm trying to understand the end of the foundational paper of Bitcoin In which the author plays a bit with probability to show how his system works. I'll try to explain the technicalities of bitcoin in exchange for some orientations in the probability calculations involved. We consider the scenario of an attacker trying to generate an   alternate chain faster than the honest chain. The race between the   honest chain and an attacker chain can be characterized as a Binomial   Random Walk. The success event is the honest chain being extended by   one block, increasing its lead by +1, and the failure event is the   attacker's chain being extended by one block, reducing the gap by -1.   The probability of an attacker catching up from a given deficit is   analogous to a Gambler's Ruin problem. Here I'm assuming we are talking about a binomial distribution not about a negative binomial distribution. Some people however consider it corresponds to a negative binomial. I'm not aware that stating that it is a random walk has special implications. Suppose a gambler with unlimited credit starts at a deficit and plays   potentially an infinite number of trials to try to reach break-even.   We can calculate the probability he ever reaches break-even, or that   an attacker ever catches up with the honest chain, as follows: p = probability an honest node finds the next block q = probability the attacker finds the next block $q_z$ = probability the attacker will   ever catch up from z blocks behind $q_z= 1 \;if p \leq q$ and $q_z = \big(\frac{q}{p}\big)^z \; if p > q$ Given our assumption that p > q, the probability drops exponentially   as the number of blocks the attacker has to catch up with increases.   With the odds against him, if he doesn't make a lucky lunge forward   early on, his chances become vanishingly small as he falls further   behind. This all makes sense to me. And maybe here is where one could say that $q_z$ follows a negative binomial distribution. However, I expect the number of failures in a negative binomial distribution to remain constant. However in this situation every time that we get a success the difference between the honest chain and the attacker's chain increases, so that the attacker needs more successes to reach the honest chain. Maybe you can clarify this point. We now consider how long the recipient of a new transaction needs to   wait before being sufficiently certain the sender can't change the   transaction. We assume the sender is an attacker who wants to make the   recipient believe he paid him for a while, then switch it to pay back   to himself after some time has passed. The receiver will be alerted   when that happens, but the sender hopes it will be too late. The receiver generates a new key pair and gives the public key to the   sender shortly before signing. This prevents the sender from preparing   a chain of blocks ahead of time by working on it continuously until he   is lucky enough to get far enough ahead, then executing the   transaction at that moment. Once the transaction is sent, the   dishonest sender starts working in secret on a  parallel chain   containing an alternate version of his transaction. The recipient waits until the transaction has been added to a block   and z blocks have been linked after it. He doesn't know the exact   amount of progress the attacker has made, but assuming the honest   blocks took the average expected time per block, the attacker's   potential progress will be a Poisson distribution with expected value $\lambda = z\frac{q}{p}$ Ok, so here definitely I think that we are using the fact that binomial negative or binomial distribution are related in the limit with Poisson's distribution, summarizing: $BN(n,p) \rightarrow_{n \rightarrow \infty, \lambda = n(1-p)} Poisson(\lambda)$ and $B(n,p) \rightarrow_{n \rightarrow \infty,\lambda = np}$ . Looking at the previous formulas I suspect that the author is going for the binomial one. But still I would need some clarification. To get the probability the attacker could still catch up now, we   multiply the Poisson density for each amount of progress he could have   made by the probability he could catch up from that point: $\sum_{k \geq 0} \frac{\lambda^ke^{-k}}{k!} \big(\frac{q}{p}\big)^{z-k}$ if $k \leq z$ and $\sum_{k \geq 0} \frac{\lambda^ke^{-k}}{k!} \cdot 1$ if $k > z$ Could you give me some insight to better understand this formula? What I ask for So, in summary I'm asking you to: Make an explicit statement of the random variable that is studied here, what is its distribution and to state whether random walks are important to understand the calculations that I showed. According to your answer to point one describe which of the limits I showed is used to derive the Poisson distribution and explain the idea of the last quotation. I don't really get what is being computed there. Please if you don't understand something about how bitcoin works comment.","I'm trying to understand the end of the foundational paper of Bitcoin In which the author plays a bit with probability to show how his system works. I'll try to explain the technicalities of bitcoin in exchange for some orientations in the probability calculations involved. We consider the scenario of an attacker trying to generate an   alternate chain faster than the honest chain. The race between the   honest chain and an attacker chain can be characterized as a Binomial   Random Walk. The success event is the honest chain being extended by   one block, increasing its lead by +1, and the failure event is the   attacker's chain being extended by one block, reducing the gap by -1.   The probability of an attacker catching up from a given deficit is   analogous to a Gambler's Ruin problem. Here I'm assuming we are talking about a binomial distribution not about a negative binomial distribution. Some people however consider it corresponds to a negative binomial. I'm not aware that stating that it is a random walk has special implications. Suppose a gambler with unlimited credit starts at a deficit and plays   potentially an infinite number of trials to try to reach break-even.   We can calculate the probability he ever reaches break-even, or that   an attacker ever catches up with the honest chain, as follows: p = probability an honest node finds the next block q = probability the attacker finds the next block = probability the attacker will   ever catch up from z blocks behind and Given our assumption that p > q, the probability drops exponentially   as the number of blocks the attacker has to catch up with increases.   With the odds against him, if he doesn't make a lucky lunge forward   early on, his chances become vanishingly small as he falls further   behind. This all makes sense to me. And maybe here is where one could say that follows a negative binomial distribution. However, I expect the number of failures in a negative binomial distribution to remain constant. However in this situation every time that we get a success the difference between the honest chain and the attacker's chain increases, so that the attacker needs more successes to reach the honest chain. Maybe you can clarify this point. We now consider how long the recipient of a new transaction needs to   wait before being sufficiently certain the sender can't change the   transaction. We assume the sender is an attacker who wants to make the   recipient believe he paid him for a while, then switch it to pay back   to himself after some time has passed. The receiver will be alerted   when that happens, but the sender hopes it will be too late. The receiver generates a new key pair and gives the public key to the   sender shortly before signing. This prevents the sender from preparing   a chain of blocks ahead of time by working on it continuously until he   is lucky enough to get far enough ahead, then executing the   transaction at that moment. Once the transaction is sent, the   dishonest sender starts working in secret on a  parallel chain   containing an alternate version of his transaction. The recipient waits until the transaction has been added to a block   and z blocks have been linked after it. He doesn't know the exact   amount of progress the attacker has made, but assuming the honest   blocks took the average expected time per block, the attacker's   potential progress will be a Poisson distribution with expected value Ok, so here definitely I think that we are using the fact that binomial negative or binomial distribution are related in the limit with Poisson's distribution, summarizing: and . Looking at the previous formulas I suspect that the author is going for the binomial one. But still I would need some clarification. To get the probability the attacker could still catch up now, we   multiply the Poisson density for each amount of progress he could have   made by the probability he could catch up from that point: if and if Could you give me some insight to better understand this formula? What I ask for So, in summary I'm asking you to: Make an explicit statement of the random variable that is studied here, what is its distribution and to state whether random walks are important to understand the calculations that I showed. According to your answer to point one describe which of the limits I showed is used to derive the Poisson distribution and explain the idea of the last quotation. I don't really get what is being computed there. Please if you don't understand something about how bitcoin works comment.","q_z q_z= 1 \;if p \leq q q_z = \big(\frac{q}{p}\big)^z \; if p > q q_z \lambda = z\frac{q}{p} BN(n,p) \rightarrow_{n \rightarrow \infty, \lambda = n(1-p)} Poisson(\lambda) B(n,p) \rightarrow_{n \rightarrow \infty,\lambda = np} \sum_{k \geq 0} \frac{\lambda^ke^{-k}}{k!} \big(\frac{q}{p}\big)^{z-k} k \leq z \sum_{k \geq 0} \frac{\lambda^ke^{-k}}{k!} \cdot 1 k > z","['probability', 'probability-distributions']"
76,"If $X \sim N(\mu, \sigma^2)$, and $Y$ is another random variable, is it an abuse of notation to write $p(X|Y, \mu, \sigma^2)$?","If , and  is another random variable, is it an abuse of notation to write ?","X \sim N(\mu, \sigma^2) Y p(X|Y, \mu, \sigma^2)","Suppose that $X$ is a Normal random variable such that: $$ X \sim N(\mu, \sigma^2) $$ Then, it is common to write: $$ p(x|\mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(\frac{-(x-\mu)^2}{2\sigma^2}\right) $$ Here, it seems that we are using a conditional notation, but we are conditioning on parameters. Now suppose that: $Y \sim N(\mu_y, \sigma_y^2)$. If we wrote: $$ p(X|Y,\mu,\sigma^2) $$ Would this still be valid? I have seen some books combine parameters and random variables in the conditional, but am not sure if this was an abuse of notation or something valid. What is the correct consensus here? Thanks.","Suppose that $X$ is a Normal random variable such that: $$ X \sim N(\mu, \sigma^2) $$ Then, it is common to write: $$ p(x|\mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(\frac{-(x-\mu)^2}{2\sigma^2}\right) $$ Here, it seems that we are using a conditional notation, but we are conditioning on parameters. Now suppose that: $Y \sim N(\mu_y, \sigma_y^2)$. If we wrote: $$ p(X|Y,\mu,\sigma^2) $$ Would this still be valid? I have seen some books combine parameters and random variables in the conditional, but am not sure if this was an abuse of notation or something valid. What is the correct consensus here? Thanks.",,"['probability', 'probability-theory']"
77,Probability of at least one die holding $6$ among $3$ dice,Probability of at least one die holding  among  dice,6 3,"When one throws three equal dice, how could we find what the probability that at least one die is holding the number 6 would be? Here’s my solution. The sample space is $$\mathbb C = \{(x,y,z)\mid x,y,z, \in \mathbb N\setminus\{0\}, 1\le x,y,z \le 6 \}.$$ Then, the event space is $$C = \{(x,y,z) \in \mathbb C \mid (x,y,z)  \in (6,y,z)\cup(x,6,z)\cup(x,y,6)\}.$$ Now, $|\mathbb C| = 6\cdot6\cdot6 = 216$ and $|C| = 36+36+36 - (6+6+6) + 1 =91$ . Thus the probability equals $\frac{91}{216}$ . Is this correct?","When one throws three equal dice, how could we find what the probability that at least one die is holding the number 6 would be? Here’s my solution. The sample space is Then, the event space is Now, and . Thus the probability equals . Is this correct?","\mathbb C = \{(x,y,z)\mid x,y,z, \in \mathbb N\setminus\{0\}, 1\le x,y,z \le 6 \}. C = \{(x,y,z) \in \mathbb C \mid (x,y,z)
 \in (6,y,z)\cup(x,6,z)\cup(x,y,6)\}. |\mathbb C| = 6\cdot6\cdot6 = 216 |C| = 36+36+36 - (6+6+6) + 1 =91 \frac{91}{216}","['probability', 'dice', 'solution-verification']"
78,Does this probability paradox have a name? [duplicate],Does this probability paradox have a name? [duplicate],,"This question already has answers here : Multiple-choice question about the probability of a random answer to itself being correct (6 answers) Closed 7 years ago . I stumbled over a probability paradox on the internet: If you choose an answer to this question at random, what is the chance that you will be correct? A) 25% B) 50% C) 60% D) 25% Given that ""at random"" means choosing each option with equal probability, each option had a chance of 25% to be correct. But since there are 2 options with 25% as the solution, we get 50% of being correct. In this case, B) would be correct. But then again, the probability of choosing B) at random would be 25%. And so on. Does this paradox have a name? Is there something I can read on it?","This question already has answers here : Multiple-choice question about the probability of a random answer to itself being correct (6 answers) Closed 7 years ago . I stumbled over a probability paradox on the internet: If you choose an answer to this question at random, what is the chance that you will be correct? A) 25% B) 50% C) 60% D) 25% Given that ""at random"" means choosing each option with equal probability, each option had a chance of 25% to be correct. But since there are 2 options with 25% as the solution, we get 50% of being correct. In this case, B) would be correct. But then again, the probability of choosing B) at random would be 25%. And so on. Does this paradox have a name? Is there something I can read on it?",,"['probability', 'paradoxes']"
79,Probability and counting assignment,Probability and counting assignment,,I have this assignment I am almost done but I am not sure if it is correct. As of right now I am a little second guessing myself on whether or not the Venn diagram is right. I also don't know what P( A union B) would be in part (c).,I have this assignment I am almost done but I am not sure if it is correct. As of right now I am a little second guessing myself on whether or not the Venn diagram is right. I also don't know what P( A union B) would be in part (c).,,"['probability', 'combinatorics']"
80,How to show a possion binomial random variable dominates another possion binomial random variable with a smaller probability value?,How to show a possion binomial random variable dominates another possion binomial random variable with a smaller probability value?,,"The definition of Poisson binomial distribution is shown as https://en.wikipedia.org/wiki/Poisson_binomial_distribution , where $n$ independent trails with success probabilities $p_1,p_2,\ldots,p_n$. (The binomial distribution is a special case of the Poisson binomial distribution that $p_1=p_2=\cdots=p_n$.) Let $X$ be a random variable following a Poisson binomial distribution, where $n$ independent trails with success probabilities $p_1,p_2,\ldots,p_i,\ldots,p_n$. Suppose that we arbitrarily reduce a probability $p_i$ to $p'_i$ ($p_i > p'_i$), and have another random variable $Y$, which follows a Poisson binomial distribution with success probabilities $p_1,p_2,\ldots,p'_i,\ldots,p_n$. Compared to the Poisson binomial distribution followed by $X$, the Poisson binomial distribution followed by $Y$ only has the same $p_1,\ldots,p_n$ except a lower $p'_i$. My goal is to show that $P(X\geq k) \geq P(Y \geq k)$, for any fixed $k \in \{1,\ldots,n\}$. In other words, I want to prove that $P(X\geq k)$ is a monotonic increasing function of $p_i$ for all $i = 1$ to $n$. The result looks simple, but I am struggling to prove that. Note that $P(X\geq k)  = \sum_{l=k}^n \sum_{A\in F_l} \prod_{i\in A} p_i \prod_{j\in A^c} (1-p_j) $ from Wikipedia. It is very hard to use an algebraic proof to show that $P(X\geq k) \geq P(Y \geq k)$. Can somebody give me a help?","The definition of Poisson binomial distribution is shown as https://en.wikipedia.org/wiki/Poisson_binomial_distribution , where $n$ independent trails with success probabilities $p_1,p_2,\ldots,p_n$. (The binomial distribution is a special case of the Poisson binomial distribution that $p_1=p_2=\cdots=p_n$.) Let $X$ be a random variable following a Poisson binomial distribution, where $n$ independent trails with success probabilities $p_1,p_2,\ldots,p_i,\ldots,p_n$. Suppose that we arbitrarily reduce a probability $p_i$ to $p'_i$ ($p_i > p'_i$), and have another random variable $Y$, which follows a Poisson binomial distribution with success probabilities $p_1,p_2,\ldots,p'_i,\ldots,p_n$. Compared to the Poisson binomial distribution followed by $X$, the Poisson binomial distribution followed by $Y$ only has the same $p_1,\ldots,p_n$ except a lower $p'_i$. My goal is to show that $P(X\geq k) \geq P(Y \geq k)$, for any fixed $k \in \{1,\ldots,n\}$. In other words, I want to prove that $P(X\geq k)$ is a monotonic increasing function of $p_i$ for all $i = 1$ to $n$. The result looks simple, but I am struggling to prove that. Note that $P(X\geq k)  = \sum_{l=k}^n \sum_{A\in F_l} \prod_{i\in A} p_i \prod_{j\in A^c} (1-p_j) $ from Wikipedia. It is very hard to use an algebraic proof to show that $P(X\geq k) \geq P(Y \geq k)$. Can somebody give me a help?",,"['probability', 'probability-distributions', 'binomial-distribution']"
81,combinatorics sum 2,combinatorics sum 2,,"Player 1 and Player 2 both start with 100 rupees. Each round of a game consists of the following: Both players choose a number randomly and independently from 1 to 5. If both players choose the same number, then Player 1 gives rupees 10 to Player 2. Otherwise, Player 2 gives rupees 10 to Player 1. Then the expected amount of money Player 1 will be left with after playing 10 rounds of this game is A. 120 B. 100 C. 50 D. 160 My Approach: Required expectation for 1 round= (1/5*1*(-10)+1/5*1/4*(10))=-1.5 rupees Therefore Expectation for 10 rounds = -1.5*10=-15 rupees So the player 1 will be left with 100-15= 85 rs. But this does not match any of the answer options.","Player 1 and Player 2 both start with 100 rupees. Each round of a game consists of the following: Both players choose a number randomly and independently from 1 to 5. If both players choose the same number, then Player 1 gives rupees 10 to Player 2. Otherwise, Player 2 gives rupees 10 to Player 1. Then the expected amount of money Player 1 will be left with after playing 10 rounds of this game is A. 120 B. 100 C. 50 D. 160 My Approach: Required expectation for 1 round= (1/5*1*(-10)+1/5*1/4*(10))=-1.5 rupees Therefore Expectation for 10 rounds = -1.5*10=-15 rupees So the player 1 will be left with 100-15= 85 rs. But this does not match any of the answer options.",,"['probability', 'combinatorics', 'expectation']"
82,"Isn't $\mathbb{E}[X^2|X\in[-b,b]]\leq \mathbb{E}[X^2]$ true?",Isn't  true?,"\mathbb{E}[X^2|X\in[-b,b]]\leq \mathbb{E}[X^2]","Let $X$ be a centered random variable such that $\mathrm{support}(X)\subseteq[-B,B]$, $B>0$, with discrete or continuous density $f$. Now, consider an event $\xi=\{X\in [-b,b]\}$, $b\in[0,B)$, with $\mathbb{P}(\xi)\in(0,1)$. Then we have $$\mathbb{E}[X^2|\xi]=\frac{1}{\mathbb{P}(\xi)}\int x^2\mathbb{1}_{[-b,b]}(x)f(x)\ \mathrm{d} x\leq \frac{1}{\mathbb{P}(\xi)}\int x^2f(x)\ \mathrm{d} x= \frac{1}{\mathbb{P}(\xi)}\mathbb{E}[X^2].$$ (Where the integral is meant in the Lebesgue- or Dirac- sense.) However, intuitively, in this setting I would expect $\mathbb{E}[X^2|\xi]\leq \mathbb{E}[X^2]$. So my questions are: If the latter result is true, how can it be proved? If it is wrong, can you provide a counter-example?","Let $X$ be a centered random variable such that $\mathrm{support}(X)\subseteq[-B,B]$, $B>0$, with discrete or continuous density $f$. Now, consider an event $\xi=\{X\in [-b,b]\}$, $b\in[0,B)$, with $\mathbb{P}(\xi)\in(0,1)$. Then we have $$\mathbb{E}[X^2|\xi]=\frac{1}{\mathbb{P}(\xi)}\int x^2\mathbb{1}_{[-b,b]}(x)f(x)\ \mathrm{d} x\leq \frac{1}{\mathbb{P}(\xi)}\int x^2f(x)\ \mathrm{d} x= \frac{1}{\mathbb{P}(\xi)}\mathbb{E}[X^2].$$ (Where the integral is meant in the Lebesgue- or Dirac- sense.) However, intuitively, in this setting I would expect $\mathbb{E}[X^2|\xi]\leq \mathbb{E}[X^2]$. So my questions are: If the latter result is true, how can it be proved? If it is wrong, can you provide a counter-example?",,"['probability', 'random-variables', 'conditional-expectation']"
83,Finding UMVUE of $p^s$ in Bernoulli distribution,Finding UMVUE of  in Bernoulli distribution,p^s,"Suppose that $X_1, \ldots, X_n$ follows Bernoulli distribution $B(1,p)$, then what is the UMVUE of $p^s$ and $p^s + (1-p)^{n-s}$? I suppose I should use the Lehmann–Scheffé theorem. Now $\overline{X}$ is a sufficient and complete statistic, I need to find a function of $\overline{X}$ whose expectation is $p^s$ and  $p^s + (1-p)^{n-1}$. But I don't know how to find such a function. Any hint would be welcome!","Suppose that $X_1, \ldots, X_n$ follows Bernoulli distribution $B(1,p)$, then what is the UMVUE of $p^s$ and $p^s + (1-p)^{n-s}$? I suppose I should use the Lehmann–Scheffé theorem. Now $\overline{X}$ is a sufficient and complete statistic, I need to find a function of $\overline{X}$ whose expectation is $p^s$ and  $p^s + (1-p)^{n-1}$. But I don't know how to find such a function. Any hint would be welcome!",,"['probability', 'statistics']"
84,Estimating the Length of a Coin Tossing Game,Estimating the Length of a Coin Tossing Game,,"I am looking to solve the following: A person plays a coin tossing game where he receives $1$ point for every heads and $5$ points for every tails.  The game stops when he receives $1,000$ points.  Estimate within $\pm{2}$ the expectation of the length of the coin tossing game. I know this is discrete martingale problem but I'm not sure how to approach it.","I am looking to solve the following: A person plays a coin tossing game where he receives $1$ point for every heads and $5$ points for every tails.  The game stops when he receives $1,000$ points.  Estimate within $\pm{2}$ the expectation of the length of the coin tossing game. I know this is discrete martingale problem but I'm not sure how to approach it.",,"['probability', 'probability-theory', 'martingales']"
85,Prove Chi-squared distribution by induction,Prove Chi-squared distribution by induction,,"$\forall n \in \mathbb{N}, {X_n\sim N(0,1)}$ independent. I wanna prove the pdf of $X=\sum_{k=1}^{n}X_k^2$ by induction : Define $$m_n=\int_0^\infty t^{n/2-1}exp(-t/2)dt$$ we have $$\forall t > 0, f_n(t)=\dfrac 1 {m_n} t^{n/2-1}exp(-t/2)$$ When $n=1$, it's easy to prove that $f_1(t)=\dfrac{exp(-\frac t 2)}{\sqrt{2\pi t}}$. Suppose the argument holds for $n$, when for $n+1$, I'm stuck at this step: $$f_{n+1}(t)=\int_0^tf_n(u)f_1(t-u)du=...=\dfrac{exp(-t/2)}{m_1\cdot m_n}t^{\frac{n-1}2}\int_0^1 \dfrac {v^{n/2-1}} {\sqrt{1-v}}dv$$ How could I simplify further this expression? Thanks a lot~","$\forall n \in \mathbb{N}, {X_n\sim N(0,1)}$ independent. I wanna prove the pdf of $X=\sum_{k=1}^{n}X_k^2$ by induction : Define $$m_n=\int_0^\infty t^{n/2-1}exp(-t/2)dt$$ we have $$\forall t > 0, f_n(t)=\dfrac 1 {m_n} t^{n/2-1}exp(-t/2)$$ When $n=1$, it's easy to prove that $f_1(t)=\dfrac{exp(-\frac t 2)}{\sqrt{2\pi t}}$. Suppose the argument holds for $n$, when for $n+1$, I'm stuck at this step: $$f_{n+1}(t)=\int_0^tf_n(u)f_1(t-u)du=...=\dfrac{exp(-t/2)}{m_1\cdot m_n}t^{\frac{n-1}2}\int_0^1 \dfrac {v^{n/2-1}} {\sqrt{1-v}}dv$$ How could I simplify further this expression? Thanks a lot~",,"['probability', 'chi-squared']"
86,rupee and paise coins probability question,rupee and paise coins probability question,,"Initially a bag was known to contain some one rupee ('0' or more) and some fifty paisa ('0' or more) coins. In all bag was known to have 4 coins. Two coins were randomly drawn from the bag and both found to be one rupee coin. If these coins are replaced, what is the probability that next drawn coin is fifty paisa coin ? (Assumption : Initially all number of rupee coins in the bag are equiprobable) My try : Let $P$ denotes $50 $ paise coin and $R$ represent $1$ rupee coin. So cases would be as follows $PPPP$ $PPPR$ $PPRR$ $PRRR$ $RRRR$ But as the question says there were $2$ $R$ coins so case $1.$ and $2$. get rejected.So remaining cases are $3$. So getting paise coin probabillity can be written as $\frac{1}{3}$.$\frac{2}{4}$ (case 3) + $\frac{1}{3}$.$\frac{1}{4}$ (case 4). i.e $\frac{1}{4}$ but answer is $\frac{1}{8}$ I think my method is wrong. Please help.","Initially a bag was known to contain some one rupee ('0' or more) and some fifty paisa ('0' or more) coins. In all bag was known to have 4 coins. Two coins were randomly drawn from the bag and both found to be one rupee coin. If these coins are replaced, what is the probability that next drawn coin is fifty paisa coin ? (Assumption : Initially all number of rupee coins in the bag are equiprobable) My try : Let $P$ denotes $50 $ paise coin and $R$ represent $1$ rupee coin. So cases would be as follows $PPPP$ $PPPR$ $PPRR$ $PRRR$ $RRRR$ But as the question says there were $2$ $R$ coins so case $1.$ and $2$. get rejected.So remaining cases are $3$. So getting paise coin probabillity can be written as $\frac{1}{3}$.$\frac{2}{4}$ (case 3) + $\frac{1}{3}$.$\frac{1}{4}$ (case 4). i.e $\frac{1}{4}$ but answer is $\frac{1}{8}$ I think my method is wrong. Please help.",,['probability']
87,How can I prove the following inequality for Ito-Integral,How can I prove the following inequality for Ito-Integral,,"I want to prove the following inequality: $$E\left[\left|\int_{t0}^t f(s,\omega)dW_s \right|^{2n}\right]\le (t-t_0)^{n-1}[n(2n-1)]^n\int_{t0}^tE[|f(s,\omega)|^{2n}]ds$$ I have been trying with Ito-Isometry and Cauchy Schwarz Inequality to get the Expectation under the integral. Where does the factor $[n(2n-1)]^n$ come from? Applying Ito Formula: $$E[\lvert\int_{t_0}^t f(s,\omega)dW_s\rvert^{2n}]=E[\int f^2(t,\omega)*n(2n-1)|\int f(s,\omega)dW_s|^{2n-2}dt]$$ Repeating the recursion n times we will get $$E[\lvert\int_{t0}^t f(s,\omega)dW_s \rvert^{2n}]= E[\int f^{2n}(t,\omega)*n(2n-1)*(n-1)*(2n-3)*.....*2 dt]\le E[\int f^{2n}(t,\omega)*n(2n-1)^n dt]\le n(2n-1)^nE[\int |f|^{2n}(t,\omega) dt]$$ Now how does the $(t-t_0)^{n-1}$ comes in?","I want to prove the following inequality: $$E\left[\left|\int_{t0}^t f(s,\omega)dW_s \right|^{2n}\right]\le (t-t_0)^{n-1}[n(2n-1)]^n\int_{t0}^tE[|f(s,\omega)|^{2n}]ds$$ I have been trying with Ito-Isometry and Cauchy Schwarz Inequality to get the Expectation under the integral. Where does the factor $[n(2n-1)]^n$ come from? Applying Ito Formula: $$E[\lvert\int_{t_0}^t f(s,\omega)dW_s\rvert^{2n}]=E[\int f^2(t,\omega)*n(2n-1)|\int f(s,\omega)dW_s|^{2n-2}dt]$$ Repeating the recursion n times we will get $$E[\lvert\int_{t0}^t f(s,\omega)dW_s \rvert^{2n}]= E[\int f^{2n}(t,\omega)*n(2n-1)*(n-1)*(2n-3)*.....*2 dt]\le E[\int f^{2n}(t,\omega)*n(2n-1)^n dt]\le n(2n-1)^nE[\int |f|^{2n}(t,\omega) dt]$$ Now how does the $(t-t_0)^{n-1}$ comes in?",,"['probability', 'probability-theory', 'stochastic-calculus', 'stochastic-integrals']"
88,"A deck of cards is well shuffled. The cards are dealt one by one, until the first time an ace appears","A deck of cards is well shuffled. The cards are dealt one by one, until the first time an ace appears",,"A deck of cards is well shuffled.  The cards are dealt one by one, until the first time an ace appears. Find the probability that no kings, queens or jacks appear before the first ace. Find the probability that exactly one king, exactly one queen and exactly one jack appear (in any order) before the ace first. Please review my methods and answers: One: Find the probability that no kings, queens or jacks appear before the first ace. Notation: Let b cards precede the first ace Let A be the first Ace Let a cards follow the first ace Conditions: b will range from 0 to 36 ($52 - (12 + 4)$) A will be one of four Ace cards a will range from 51 to 15 ($12 + 3$) In order to maintain equal likeliness of all configurations (an assumption), we will find the number of valid permutations and divide by the total number of permutations which will result in the probability of a valid configuration, denoted P(A). $$ P(A) = \frac{\textrm{number of valid permutations}}{\textrm{number of all permutations}} $$ $$P(A) = \frac{1}{52!}\sum_{i=0}^{36}\left(\frac{36!}{(36-i)!}\frac{4!}{(4-1)!}(51-i)!\right) $$ where within the summation, the first expression selects and permutes the number of cards preceding the first ace, the second expression selects the first ace, the third expression selects and permutes the cards which follow the first ace. The expression reduces to: $$ P(A)=\frac{4\times36!}{52!}\sum_{i=0}^{36} \frac{(51-i)!}{(36-i)!}$$ $$P(A) = 0.25$$ Two: Find the probability that exactly one king, exactly one queen and exactly one jack appear (in any order) before the ace first. There are $\frac{4!}{(4-1)!}$ ways to select one of four elements, be it an ace, jack, queen or king. Proceed in a similar fashion to part 1. by finding the quotient of the total number of permissible permutations and the total number of permutations, labelling it $P(B)$. $$P(B) = \frac{1}{52!} \sum_{i=0}^{36}\left(\frac{4!}{(4-1)!}\frac{4!}{(4-1)!}\frac{4!}{(4-1)!}\frac{1}{3!}\times\frac{36!}{(36-i)!}\frac{4!}{(4-1)!}(48-i)! \right)$$ Where the first three expressions in the summation are the selection of a king, queen and jack, the fourth expression allows these three cards to be chosen in any order.  The expressions following the multiplication symbol are: selection of a number of cards ( two, three, ... , ten) to follow the face cards and precede the first ace. selection of the first ace selection of the remaining cards The expression collapses to: $$ P(B) = \frac{4^4 \times 36!}{52!\times 3!} \sum_{i=0}^{36}\frac{(48-i)!}{(36-i)!} $$ $$P(B) = 2.4752\times{10}^{-5} $$ Thank you in advance","A deck of cards is well shuffled.  The cards are dealt one by one, until the first time an ace appears. Find the probability that no kings, queens or jacks appear before the first ace. Find the probability that exactly one king, exactly one queen and exactly one jack appear (in any order) before the ace first. Please review my methods and answers: One: Find the probability that no kings, queens or jacks appear before the first ace. Notation: Let b cards precede the first ace Let A be the first Ace Let a cards follow the first ace Conditions: b will range from 0 to 36 ($52 - (12 + 4)$) A will be one of four Ace cards a will range from 51 to 15 ($12 + 3$) In order to maintain equal likeliness of all configurations (an assumption), we will find the number of valid permutations and divide by the total number of permutations which will result in the probability of a valid configuration, denoted P(A). $$ P(A) = \frac{\textrm{number of valid permutations}}{\textrm{number of all permutations}} $$ $$P(A) = \frac{1}{52!}\sum_{i=0}^{36}\left(\frac{36!}{(36-i)!}\frac{4!}{(4-1)!}(51-i)!\right) $$ where within the summation, the first expression selects and permutes the number of cards preceding the first ace, the second expression selects the first ace, the third expression selects and permutes the cards which follow the first ace. The expression reduces to: $$ P(A)=\frac{4\times36!}{52!}\sum_{i=0}^{36} \frac{(51-i)!}{(36-i)!}$$ $$P(A) = 0.25$$ Two: Find the probability that exactly one king, exactly one queen and exactly one jack appear (in any order) before the ace first. There are $\frac{4!}{(4-1)!}$ ways to select one of four elements, be it an ace, jack, queen or king. Proceed in a similar fashion to part 1. by finding the quotient of the total number of permissible permutations and the total number of permutations, labelling it $P(B)$. $$P(B) = \frac{1}{52!} \sum_{i=0}^{36}\left(\frac{4!}{(4-1)!}\frac{4!}{(4-1)!}\frac{4!}{(4-1)!}\frac{1}{3!}\times\frac{36!}{(36-i)!}\frac{4!}{(4-1)!}(48-i)! \right)$$ Where the first three expressions in the summation are the selection of a king, queen and jack, the fourth expression allows these three cards to be chosen in any order.  The expressions following the multiplication symbol are: selection of a number of cards ( two, three, ... , ten) to follow the face cards and precede the first ace. selection of the first ace selection of the remaining cards The expression collapses to: $$ P(B) = \frac{4^4 \times 36!}{52!\times 3!} \sum_{i=0}^{36}\frac{(48-i)!}{(36-i)!} $$ $$P(B) = 2.4752\times{10}^{-5} $$ Thank you in advance",,"['probability', 'combinatorics', 'card-games']"
89,What is the probability that a coin is fair?,What is the probability that a coin is fair?,,"You paly a game with your friend Alice where you bet on the outcome of a coin toss. The coin has been provided by Alice. You think there is a 50% chance that she would have provided an unfair coin. If the coin is unfair then you believe that the probability that it will turn up heads is uniform in [0, 1]. The question is that, 1: You toss the coin and it comes up head. What is the probability that the coin is fair? 2: You toss the coin for the second time and it comes up head again. Now, what is the probability that the coin is fair? For me, I solve this problem through this way, P(fair|data) = $\frac{P(data|fair)P(fair)}{P(data|fair)P(fair)+P(data|unfair)P(unfair)}$ Where I know that P(fair)=0.5, P(data|fair)=$p^1(1-p)^0$=$p=0.5$ (as fair means P(head)=0.5=p), P(unfair)=0.5, So, the previous equation can be substitued as, P(fair|data) = $\frac{0.5*0.5}{0.5*0.5+P(data|unfair)*0.5}$ My question is how to express the term of P(data|unfair)? Thanks.","You paly a game with your friend Alice where you bet on the outcome of a coin toss. The coin has been provided by Alice. You think there is a 50% chance that she would have provided an unfair coin. If the coin is unfair then you believe that the probability that it will turn up heads is uniform in [0, 1]. The question is that, 1: You toss the coin and it comes up head. What is the probability that the coin is fair? 2: You toss the coin for the second time and it comes up head again. Now, what is the probability that the coin is fair? For me, I solve this problem through this way, P(fair|data) = $\frac{P(data|fair)P(fair)}{P(data|fair)P(fair)+P(data|unfair)P(unfair)}$ Where I know that P(fair)=0.5, P(data|fair)=$p^1(1-p)^0$=$p=0.5$ (as fair means P(head)=0.5=p), P(unfair)=0.5, So, the previous equation can be substitued as, P(fair|data) = $\frac{0.5*0.5}{0.5*0.5+P(data|unfair)*0.5}$ My question is how to express the term of P(data|unfair)? Thanks.",,"['probability', 'bayesian']"
90,How to come up with different ways to find the same solution?,How to come up with different ways to find the same solution?,,"A coin has probability $p$ of heads. Adam flips it first, then Becca, then Adam, etc., and the winner is the first to flip heads. Compute the probability that Adam wins. So I saw this problem this afternoon and I tried solving it on my own. I used the following reasoning to get to the solution: If $n$ denotes the number of tosses done in total. Then the only way Adam can win is if the head appears at an ""odd"" trial ($2n-1$). For the head to occur at the $2n - 1$ trial the first $(2n-1) - 1$ tosses must be equal to tails, so I expressed this as $$p\sum_{n=1}^\infty (1-p)^{2n - 2}$$ I then realized that this is a geometric series, which converges to the following value $$\frac{p}{1 - (1-p)^2} = \frac{1}{2 - p}$$ From my perspective I thought this was the only way you can get to this result, but the paper from which I got the question from used a very different approach ( recursion ). So I guess my question is, how can you train yourself to think about problems like this in more than one way?","A coin has probability $p$ of heads. Adam flips it first, then Becca, then Adam, etc., and the winner is the first to flip heads. Compute the probability that Adam wins. So I saw this problem this afternoon and I tried solving it on my own. I used the following reasoning to get to the solution: If $n$ denotes the number of tosses done in total. Then the only way Adam can win is if the head appears at an ""odd"" trial ($2n-1$). For the head to occur at the $2n - 1$ trial the first $(2n-1) - 1$ tosses must be equal to tails, so I expressed this as $$p\sum_{n=1}^\infty (1-p)^{2n - 2}$$ I then realized that this is a geometric series, which converges to the following value $$\frac{p}{1 - (1-p)^2} = \frac{1}{2 - p}$$ From my perspective I thought this was the only way you can get to this result, but the paper from which I got the question from used a very different approach ( recursion ). So I guess my question is, how can you train yourself to think about problems like this in more than one way?",,"['probability', 'recreational-mathematics', 'problem-solving']"
91,Maximizing Score in Dice Rolling Game,Maximizing Score in Dice Rolling Game,,"In a game I was playing, you roll two six-sided dice. If either of them rolls a one, your points for the turn become zero and your turn is ended. If you roll greater than one on both dice, the sum of the rolls add to your points and you can choose to roll again or choose to end your turn and add your points from the turn to your total score. I was wondering how many rolls per turn would give you the best possible score on average, so I programmed a simple simulation that tested rolling once, twice, three times, and four times in a turn. It turned out that the best score comes from rolling a pair three times, but I can't explain why. Can anyone explain this through a proof or some equations?","In a game I was playing, you roll two six-sided dice. If either of them rolls a one, your points for the turn become zero and your turn is ended. If you roll greater than one on both dice, the sum of the rolls add to your points and you can choose to roll again or choose to end your turn and add your points from the turn to your total score. I was wondering how many rolls per turn would give you the best possible score on average, so I programmed a simple simulation that tested rolling once, twice, three times, and four times in a turn. It turned out that the best score comes from rolling a pair three times, but I can't explain why. Can anyone explain this through a proof or some equations?",,"['probability', 'recreational-mathematics']"
92,"Swap sums, change of indices","Swap sums, change of indices",,"there are two equations I don't understand. (Probability Theory): $$\sum_{k=1}^{\infty} P(X \ge k) = \sum_{k=1}^{\infty} \sum_{n=k}^{\infty} P(X=n) = \sum_{n=1}^{\infty} \sum_{k=1}^{n} P(X=n) = \dots$$ I really don't get the second equation. I know that you can swap sums if all the addends are non-negative. But why do you change the indices like that? Markov Chains: $$\dots \sum_{n=1}^{\infty} \sum_{k=1}^{n} f_{ij}^{k} \Pi^{n-k}(j,j) = \sum_{k=1}^{\infty} \sum_{m=0}^{\infty} f_{ij}^{k} \Pi^m (j,j) = \dots $$ where $\Pi$ is the transition matrix. This time I know that you replace $n-k$ by $m$, but why is the first sum from 1 to infinity? Thank you for all your help.","there are two equations I don't understand. (Probability Theory): $$\sum_{k=1}^{\infty} P(X \ge k) = \sum_{k=1}^{\infty} \sum_{n=k}^{\infty} P(X=n) = \sum_{n=1}^{\infty} \sum_{k=1}^{n} P(X=n) = \dots$$ I really don't get the second equation. I know that you can swap sums if all the addends are non-negative. But why do you change the indices like that? Markov Chains: $$\dots \sum_{n=1}^{\infty} \sum_{k=1}^{n} f_{ij}^{k} \Pi^{n-k}(j,j) = \sum_{k=1}^{\infty} \sum_{m=0}^{\infty} f_{ij}^{k} \Pi^m (j,j) = \dots $$ where $\Pi$ is the transition matrix. This time I know that you replace $n-k$ by $m$, but why is the first sum from 1 to infinity? Thank you for all your help.",,"['probability', 'summation']"
93,An exercise about conditional expectation of Jean-François Le Gall's book,An exercise about conditional expectation of Jean-François Le Gall's book,,"Recently I've been studying Brownian Motion, Martingales, and Stochastic Calculus by Jean-François Le Gall. But I was stuck by this exercise (1.16 p.15): Consider a sequence of random variables $(X_n)$ and $(Y_n)$ defined recursively by   $$X_{n+1}=a_nX_n+\epsilon_{n+1}$$   and   $$Y_n=cX_n+\eta_n$$ where $a_n>0$, $c>0$ and $\epsilon_n\sim N(0,\sigma^2)$, $\eta_n\sim N(0,\delta^2)$ i.i.d.. Also, assume $(\epsilon_n)$ and $(\eta_n)$ is independent. Now define    $$\hat{X}_{n/m}=E[X_n|Y_0,\dots,Y_m].$$   Show that for $n\geq 1$,   $$\hat{X}_{n/n}=\hat{X}_{n/n-1}+\frac{E[X_nZ_n]}{E[Z_n^2]}Z_n.$$   where $Z_n:=Y_n-c\hat{X}_{n/n-1}$. I guess the solution involve some kind of inductive arguments, but I have no idea how to start... This would be nice for someone to offer me hints and ideas. Thanks!","Recently I've been studying Brownian Motion, Martingales, and Stochastic Calculus by Jean-François Le Gall. But I was stuck by this exercise (1.16 p.15): Consider a sequence of random variables $(X_n)$ and $(Y_n)$ defined recursively by   $$X_{n+1}=a_nX_n+\epsilon_{n+1}$$   and   $$Y_n=cX_n+\eta_n$$ where $a_n>0$, $c>0$ and $\epsilon_n\sim N(0,\sigma^2)$, $\eta_n\sim N(0,\delta^2)$ i.i.d.. Also, assume $(\epsilon_n)$ and $(\eta_n)$ is independent. Now define    $$\hat{X}_{n/m}=E[X_n|Y_0,\dots,Y_m].$$   Show that for $n\geq 1$,   $$\hat{X}_{n/n}=\hat{X}_{n/n-1}+\frac{E[X_nZ_n]}{E[Z_n^2]}Z_n.$$   where $Z_n:=Y_n-c\hat{X}_{n/n-1}$. I guess the solution involve some kind of inductive arguments, but I have no idea how to start... This would be nice for someone to offer me hints and ideas. Thanks!",,"['probability', 'probability-theory', 'conditional-expectation']"
94,Knock out tournament 2,Knock out tournament 2,,"$2^n$ players of equal strength are playing a knock out tournament. If they are paired randomly in all rounds, then what is the probability that out of two particular players $S_1$ and $S_2$, exactly one will reach the semi-finals of the tournament.","$2^n$ players of equal strength are playing a knock out tournament. If they are paired randomly in all rounds, then what is the probability that out of two particular players $S_1$ and $S_2$, exactly one will reach the semi-finals of the tournament.",,"['probability', 'combinatorics', 'combinations']"
95,Covariance matrix of multivariate Gaussian,Covariance matrix of multivariate Gaussian,,"I want to calculate the Covariance matrix of an n-dimensional normal distribution given by $Y=AX+a$ where $X=(X_1,...,X_n)$ with each $X_i$ a standard normal distribution. I have calculated the density of $Y$ as $$f(y)=\frac{1}{(2\pi)^{\frac{n}{2}}|det(A)|}e^{-\frac{1}{2}(y-a)^{T}(AA^{T})^{-1}(y-a)}$$ which according to my notes is correct. Wikipedia has as PDF $$f(y)=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^{-1/2}}e^{-\frac{1}{2}(y-a)^{T}\Sigma^{-1}(y-a)}$$ with covariance matrix $\Sigma$, from which I infer that I should have $\Sigma=AA^{T}$, i.e. my covariance matrix should be given by $AA^{T}$. But doing the actual calculation I get as Covariance of the components $Y_k,Y_l$, with expectations $a_k, a_l$ respectively: $$Cov(Y_k,Y_l)=\mathbb{E}[(Y_k-a_k)(Y_l-a_l)]=\mathbb{E}[Y_kY_l-a_kY_l-a_lY_k+a_ka_l]=\mathbb{E}[Y_kY_l]-a_ka_l=\mathbb{E}[(AX+a)_k(AX+a)_l]-a_ka_l=\mathbb{E}[(X_1\sum_{i=1}^na_{ki}+a_k])(X_1\sum_{i=1}^na_{li}+a_l)]-a_ka_l=\mathbb{E}[X_1^2(\sum_{i=1}^na_{ki})(\sum_{i=1}^na_{li})+X_1(\sum_{i=1}^na_{ki})+X_1(\sum_{i=1}^na_{li})+a_ka_l]-a_ka_l=\mathbb{E}[X_1^2](\sum_{i=1}^na_{ki})(\sum_{i=1}^na_{li})=(\sum_{i=1}^na_{ki})(\sum_{i=1}^na_{li})$$ where in the last two steps I have used linearity of expectation and the fact that the components are standard normally distributed, i.e. $\mathbb{E}[X_1]=0$ and $\mathbb{E}[X_1^2]=1$. However, this isn't equal to $(AA^{T})_{kl}=\sum_{i=1}^{n}a_{ki}a_{li}$. Does somebody see what I did wrong/what I am missing?","I want to calculate the Covariance matrix of an n-dimensional normal distribution given by $Y=AX+a$ where $X=(X_1,...,X_n)$ with each $X_i$ a standard normal distribution. I have calculated the density of $Y$ as $$f(y)=\frac{1}{(2\pi)^{\frac{n}{2}}|det(A)|}e^{-\frac{1}{2}(y-a)^{T}(AA^{T})^{-1}(y-a)}$$ which according to my notes is correct. Wikipedia has as PDF $$f(y)=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^{-1/2}}e^{-\frac{1}{2}(y-a)^{T}\Sigma^{-1}(y-a)}$$ with covariance matrix $\Sigma$, from which I infer that I should have $\Sigma=AA^{T}$, i.e. my covariance matrix should be given by $AA^{T}$. But doing the actual calculation I get as Covariance of the components $Y_k,Y_l$, with expectations $a_k, a_l$ respectively: $$Cov(Y_k,Y_l)=\mathbb{E}[(Y_k-a_k)(Y_l-a_l)]=\mathbb{E}[Y_kY_l-a_kY_l-a_lY_k+a_ka_l]=\mathbb{E}[Y_kY_l]-a_ka_l=\mathbb{E}[(AX+a)_k(AX+a)_l]-a_ka_l=\mathbb{E}[(X_1\sum_{i=1}^na_{ki}+a_k])(X_1\sum_{i=1}^na_{li}+a_l)]-a_ka_l=\mathbb{E}[X_1^2(\sum_{i=1}^na_{ki})(\sum_{i=1}^na_{li})+X_1(\sum_{i=1}^na_{ki})+X_1(\sum_{i=1}^na_{li})+a_ka_l]-a_ka_l=\mathbb{E}[X_1^2](\sum_{i=1}^na_{ki})(\sum_{i=1}^na_{li})=(\sum_{i=1}^na_{ki})(\sum_{i=1}^na_{li})$$ where in the last two steps I have used linearity of expectation and the fact that the components are standard normally distributed, i.e. $\mathbb{E}[X_1]=0$ and $\mathbb{E}[X_1^2]=1$. However, this isn't equal to $(AA^{T})_{kl}=\sum_{i=1}^{n}a_{ki}a_{li}$. Does somebody see what I did wrong/what I am missing?",,"['probability', 'probability-theory', 'probability-distributions', 'normal-distribution', 'expectation']"
96,Advantage of going first in a board game,Advantage of going first in a board game,,"I've been playing with my son a simple board game where you roll a regular 6 faced die and move as many positions as you roll. So nothing fancy, just pure luck game. Lately I've been trying to teach him that is not OK for him to always go first. It's not fair. Then he asked me a good question. ""WHY?"". The answer is obvious, because you get a better chance of reaching the end of the board first. You may have an extra roll to reach the end of the board. But I would like to see some numbers / probabilities. Not to explain my son, but for my inner peace. So my question is: Is there a formula that shows the chances of winning if you go first depending on the board length? For simplicity, let's say that there are 2 players only and the traps and bonuses from the board are ignored. I tried an incremental approach. board has the length 1 => Player 1 always wins. board has the length 2 => Player 2 wins only if P1 rolls a 1 and P2 rolls 2 or more so P2 wins with a probability of $\frac{1}{6} \times \frac{5}{6} = \frac{5}{36}$ and P1 with a probability of $\frac{31}{36}$. board has the lenght of 3 => I got lost in the math and my head hurts. Just for the record, my board has the length of 45. It seams logical that the bigger the board the closer the chances get to $\frac{1}{2}$ for each player. But is there a formula?","I've been playing with my son a simple board game where you roll a regular 6 faced die and move as many positions as you roll. So nothing fancy, just pure luck game. Lately I've been trying to teach him that is not OK for him to always go first. It's not fair. Then he asked me a good question. ""WHY?"". The answer is obvious, because you get a better chance of reaching the end of the board first. You may have an extra roll to reach the end of the board. But I would like to see some numbers / probabilities. Not to explain my son, but for my inner peace. So my question is: Is there a formula that shows the chances of winning if you go first depending on the board length? For simplicity, let's say that there are 2 players only and the traps and bonuses from the board are ignored. I tried an incremental approach. board has the length 1 => Player 1 always wins. board has the length 2 => Player 2 wins only if P1 rolls a 1 and P2 rolls 2 or more so P2 wins with a probability of $\frac{1}{6} \times \frac{5}{6} = \frac{5}{36}$ and P1 with a probability of $\frac{31}{36}$. board has the lenght of 3 => I got lost in the math and my head hurts. Just for the record, my board has the length of 45. It seams logical that the bigger the board the closer the chances get to $\frac{1}{2}$ for each player. But is there a formula?",,['probability']
97,Flipping Coins and Advantages,Flipping Coins and Advantages,,"You and I decide to play a game where we take turns flipping a coin.  The first player to flip 10 heads wins the game.  Naturally, there is an argument about who should go first. Simulations of this game show that the player to flips first wins 2% more than the player who flips second.  I'd like to make this more precise but have run into some problems. This isn't a binomial random variable, as there are no fixed number of trials (flip until someone gets 10 heads).  How can I model this?","You and I decide to play a game where we take turns flipping a coin.  The first player to flip 10 heads wins the game.  Naturally, there is an argument about who should go first. Simulations of this game show that the player to flips first wins 2% more than the player who flips second.  I'd like to make this more precise but have run into some problems. This isn't a binomial random variable, as there are no fixed number of trials (flip until someone gets 10 heads).  How can I model this?",,['probability']
98,"Average count of ""numbers bigger than it's predecessors"" on a random ordering of $ \left[ 1 ... n \right] $","Average count of ""numbers bigger than it's predecessors"" on a random ordering of", \left[ 1 ... n \right] ,"Note: Please refer me to other references of this problem in literature or web if you can. I did not find it in web myself, I don't know what keywords to use. I ""invented"" this problem myself. Problem: We have randomly ordered the numbers from 1 to N. A element of this list is called ""record"" (word i coined based on world record ) if it's bigger than the numbers before him on the list. Let's define the first number of the list as a record, so as to agree, this is not a important decision that affects the mechanics of the problem at all. Then, if we pick a random sequence, what is the expected value of the number of records? Example: The sequence 12354 has 4 records: 1,2,3,5, 4 is not because 5>4 and it's before 4.","Note: Please refer me to other references of this problem in literature or web if you can. I did not find it in web myself, I don't know what keywords to use. I ""invented"" this problem myself. Problem: We have randomly ordered the numbers from 1 to N. A element of this list is called ""record"" (word i coined based on world record ) if it's bigger than the numbers before him on the list. Let's define the first number of the list as a record, so as to agree, this is not a important decision that affects the mechanics of the problem at all. Then, if we pick a random sequence, what is the expected value of the number of records? Example: The sequence 12354 has 4 records: 1,2,3,5, 4 is not because 5>4 and it's before 4.",,"['probability', 'combinatorics', 'discrete-mathematics']"
99,Probability - mixing cards,Probability - mixing cards,,"The package contains 8 different cards, two of each color (that means 4 colors). We will mix the package. How likely we get combination in which no two cards of the same color are next to each other? There are $8!$ combinations how to mix the package. Now, I have to compute the number of combinations in which no two cards of the same color are next to each other. No idea how to do that. Maybe we place 4 cards of different color randomly (in $8*7*6*5$ ways) and then - I don't know. Maybe some Inclusion-Exclusion Principle?","The package contains 8 different cards, two of each color (that means 4 colors). We will mix the package. How likely we get combination in which no two cards of the same color are next to each other? There are $8!$ combinations how to mix the package. Now, I have to compute the number of combinations in which no two cards of the same color are next to each other. No idea how to do that. Maybe we place 4 cards of different color randomly (in $8*7*6*5$ ways) and then - I don't know. Maybe some Inclusion-Exclusion Principle?",,"['probability', 'combinatorics']"
