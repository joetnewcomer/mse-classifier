,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Let $Z$ be a standard normal random variable, prove the following","Let  be a standard normal random variable, prove the following",Z,"Let $Z$ be a standard normal random variable, prove: $P(Z > z) \leq \frac{e^{-\frac{z^2}{2}}}{2}$ How do I approach this question? Do I assume the moment generating function (in Chernoff Bounds) is $e^{-\frac{z^2}{2}}$ ? Does it even have anything to do with moment generating function or I can just simply use something like Markov's inequality or Chebyshev's inequality to solve this?","Let be a standard normal random variable, prove: How do I approach this question? Do I assume the moment generating function (in Chernoff Bounds) is ? Does it even have anything to do with moment generating function or I can just simply use something like Markov's inequality or Chebyshev's inequality to solve this?",Z P(Z > z) \leq \frac{e^{-\frac{z^2}{2}}}{2} e^{-\frac{z^2}{2}},['statistics']
1,Expected value of $\bar x^2$ shows different values when calculating through different equations.,Expected value of  shows different values when calculating through different equations.,\bar x^2,"Here are the basic notations: Population mean = $\mu$ Sample mean = $\bar x$ Population variance = $\sigma^2$ E = Estimator Assumption $E(x_i) = \mu$ $E(x_i)$ is any random variable within the population space. $$E(\bar x) = E(\frac{1}{n} \sum_{i=1}^n x_i)$$ $$E(\bar x) = \frac{1}{n} \sum_{i=1}^n E(x_i)$$ $$E(\bar x) = \frac{1}{n} \sum_{i=1}^n \mu$$ $$E(\bar x) = \frac{1}{n}. n. \mu$$ $$E(\bar x) = \mu$$ Now, $$Var(x_i) = E(x_i^2) - (E(x_i)^2)$$ $$\sigma^2 = E(x_i^2) - \mu^2$$ $$ E(x_i^2)= \mu^2 + \sigma^2 $$ $ E(x_i^2)= \mu^2 + \sigma^2 $ Let this be equation 1 Also, $$var(\bar x) = E(\bar x^2)-(E(\bar x))^2$$ $$E(\bar x^2) = \frac{\sigma^2}{n} + \mu^2$$ $E(\bar x^2) = \frac{\sigma^2}{n} + \mu^2$ Let this be equation 2 Also using the Estimator, $$E(\bar x^2) = E(\frac{1}{n} \sum_{i=1}^n x_i)^2$$ $$E(\bar x^2) = \frac{1}{n^2} \sum_{i=1}^n E(x_i)^2$$ From equation 1 we know that $ E(x_i^2)= \mu^2 + \sigma^2 $ Hence, $$E(\bar x^2) = \frac{1}{n^2} \sum_{i=1}^n (\sigma^2+\mu^2)$$ $$E(\bar x^2) = \frac{1}{n^2} \sum_{i=1}^n (\sigma^2+\mu^2)$$ $$E(\bar x^2) = \frac{1}{n^2} .n^2. (\sigma^2+\mu^2)$$ $$E(\bar x^2) = (\sigma^2+\mu^2)$$ How can $E(\bar x^2)$ have two values as shown above and equation 2 Where $E(\bar x^2) = \frac {\sigma^2}{n} + \mu^2$","Here are the basic notations: Population mean = Sample mean = Population variance = E = Estimator Assumption is any random variable within the population space. Now, Let this be equation 1 Also, Let this be equation 2 Also using the Estimator, From equation 1 we know that Hence, How can have two values as shown above and equation 2 Where",\mu \bar x \sigma^2 E(x_i) = \mu E(x_i) E(\bar x) = E(\frac{1}{n} \sum_{i=1}^n x_i) E(\bar x) = \frac{1}{n} \sum_{i=1}^n E(x_i) E(\bar x) = \frac{1}{n} \sum_{i=1}^n \mu E(\bar x) = \frac{1}{n}. n. \mu E(\bar x) = \mu Var(x_i) = E(x_i^2) - (E(x_i)^2) \sigma^2 = E(x_i^2) - \mu^2  E(x_i^2)= \mu^2 + \sigma^2   E(x_i^2)= \mu^2 + \sigma^2  var(\bar x) = E(\bar x^2)-(E(\bar x))^2 E(\bar x^2) = \frac{\sigma^2}{n} + \mu^2 E(\bar x^2) = \frac{\sigma^2}{n} + \mu^2 E(\bar x^2) = E(\frac{1}{n} \sum_{i=1}^n x_i)^2 E(\bar x^2) = \frac{1}{n^2} \sum_{i=1}^n E(x_i)^2  E(x_i^2)= \mu^2 + \sigma^2  E(\bar x^2) = \frac{1}{n^2} \sum_{i=1}^n (\sigma^2+\mu^2) E(\bar x^2) = \frac{1}{n^2} \sum_{i=1}^n (\sigma^2+\mu^2) E(\bar x^2) = \frac{1}{n^2} .n^2. (\sigma^2+\mu^2) E(\bar x^2) = (\sigma^2+\mu^2) E(\bar x^2) E(\bar x^2) = \frac {\sigma^2}{n} + \mu^2,"['statistics', 'variance', 'standard-deviation', 'data-analysis']"
2,Is Probability Mass Function essentially the same as a list of Probabilities?,Is Probability Mass Function essentially the same as a list of Probabilities?,,"For the most common example of tossing a coin two times. There are four outcomes. We know that range of X = Rx{0,1,2} Where X is the event of an outcome of heads at least once. Px(0) = 1/4 two tails and no heads Px(1) = 1/2 HT and TH Px(2) = 1/4 Two heads and no tails The limitations is that Px(k) > 0 and ΣPx = 1. Is there something more to PMF than being a list of probabilities? If no then why is there an entire equation making it such?","For the most common example of tossing a coin two times. There are four outcomes. We know that range of X = Rx{0,1,2} Where X is the event of an outcome of heads at least once. Px(0) = 1/4 two tails and no heads Px(1) = 1/2 HT and TH Px(2) = 1/4 Two heads and no tails The limitations is that Px(k) > 0 and ΣPx = 1. Is there something more to PMF than being a list of probabilities? If no then why is there an entire equation making it such?",,"['probability', 'statistics', 'permutations']"
3,$\int_0^1 |F_X^{-1}(q) - F_Y^{-1}(q)| dq = \int_\mathbb R |F_X(x) - F_Y(x)| dx$,,\int_0^1 |F_X^{-1}(q) - F_Y^{-1}(q)| dq = \int_\mathbb R |F_X(x) - F_Y(x)| dx,"Let X,Y be one-dimensional variables. I would like to prove that fact that $$\int_0^1 |F_X^{-1}(q) - F_Y^{-1}(q)| dq = \int_\mathbb R |F_X(x) - F_Y(x)| dx$$ where $F_X$ denotes cumulative distribution function of variable $X$ and $F_X^{-1}$ denotes quantile function. My work so far For sure this equality can be proven by only changing the variables in integrals. I tried to do $q = F_X(x)$ , then $dq = f(x) dx$ , where $f(x)$ is a probability density function. Therefore; $$\int_0^1 |F_X^{-1}(q) - F_Y^{-1}(q)| = \int_{\mathbb R}|(x - F_Y^{-1}(F_X(x)))|f(x)dx$$ which unforunetly is not exacly what I was looking for. Could you please give me a hand in proving this fact? EDIT I found out, that those integrals are equal to area between graphs $F_X$ and $F_Y$ , however I'm not sure how it can be proven.","Let X,Y be one-dimensional variables. I would like to prove that fact that where denotes cumulative distribution function of variable and denotes quantile function. My work so far For sure this equality can be proven by only changing the variables in integrals. I tried to do , then , where is a probability density function. Therefore; which unforunetly is not exacly what I was looking for. Could you please give me a hand in proving this fact? EDIT I found out, that those integrals are equal to area between graphs and , however I'm not sure how it can be proven.",\int_0^1 |F_X^{-1}(q) - F_Y^{-1}(q)| dq = \int_\mathbb R |F_X(x) - F_Y(x)| dx F_X X F_X^{-1} q = F_X(x) dq = f(x) dx f(x) \int_0^1 |F_X^{-1}(q) - F_Y^{-1}(q)| = \int_{\mathbb R}|(x - F_Y^{-1}(F_X(x)))|f(x)dx F_X F_Y,"['probability', 'probability-theory', 'statistics', 'probability-distributions']"
4,Expectation of the largest order statistic from uniform random variables [duplicate],Expectation of the largest order statistic from uniform random variables [duplicate],,"This question already has answers here : Expected value of $\max\{X_1,\ldots,X_n\}$ where $X_i$ are iid uniform. [duplicate] (2 answers) Closed 2 years ago . If $X_1, ..., X_n$ are iid random variables from the Uniform[ $0,\theta$ ] distribution, where $\theta >0$ , compute the expectation of the largest order statistic denoted $X_{(n)}$ . I am looking to test whether or not this statistic is an biased or unbiased estimator for $\theta$ , however I am struggling to test the bias as I am unable to compute its expectation. My initial thoughts with this question were that $E_{\theta}(X_{(n)})=\frac{\theta}2$ since this should be the expectation of any random variable from the uniform distribution on this interval. However, I can see that clearly this won't be the case in this situation since the expectation must (intuitively) depend upon $n$ in some way. I am wondering what the problem is with my initial thoughts. Edit: I have been informed in the comments of what the correct approach is, however, I am still unclear of the problem with my reasoning that $E_{\theta}(X_{(n)})=\frac{\theta}2$ since $E_{\theta}(X_i)=\frac{\theta}2$ for all possible values of $i$ . By definition, there exists some natural number $j$ such that $X_j=X_{(n)}$ so why is it that $X_j$ doesn't follow the uniform distribution when every $X_i$ does.","This question already has answers here : Expected value of $\max\{X_1,\ldots,X_n\}$ where $X_i$ are iid uniform. [duplicate] (2 answers) Closed 2 years ago . If are iid random variables from the Uniform[ ] distribution, where , compute the expectation of the largest order statistic denoted . I am looking to test whether or not this statistic is an biased or unbiased estimator for , however I am struggling to test the bias as I am unable to compute its expectation. My initial thoughts with this question were that since this should be the expectation of any random variable from the uniform distribution on this interval. However, I can see that clearly this won't be the case in this situation since the expectation must (intuitively) depend upon in some way. I am wondering what the problem is with my initial thoughts. Edit: I have been informed in the comments of what the correct approach is, however, I am still unclear of the problem with my reasoning that since for all possible values of . By definition, there exists some natural number such that so why is it that doesn't follow the uniform distribution when every does.","X_1, ..., X_n 0,\theta \theta >0 X_{(n)} \theta E_{\theta}(X_{(n)})=\frac{\theta}2 n E_{\theta}(X_{(n)})=\frac{\theta}2 E_{\theta}(X_i)=\frac{\theta}2 i j X_j=X_{(n)} X_j X_i","['probability', 'statistics', 'statistical-inference', 'uniform-distribution', 'order-statistics']"
5,Relationship Between Bayesian Optimization and Gaussian Process,Relationship Between Bayesian Optimization and Gaussian Process,,"In Bayesian Optimization , the function (i.e. objective function) that we are trying to optimize is modelled using some surrogate function - this surrogate function usually turns out to be a Gaussian Process. I am trying to better understand - in Bayesian Optimization, why exactly do we decide to model the objective function using a Gaussian Process? Could we have based the surrogate on some other class of functions instead? My guess is that perhaps Gaussian Processes have a certain type of ""mathematical flexibility"" which makes them an ideal choice for a surrogate models in the context of optimization. But in the end - is there some specific reason as to why Gaussian Processes are used in Bayesian Optimization (compared to some other class of surrogate function) ? Thanks!","In Bayesian Optimization , the function (i.e. objective function) that we are trying to optimize is modelled using some surrogate function - this surrogate function usually turns out to be a Gaussian Process. I am trying to better understand - in Bayesian Optimization, why exactly do we decide to model the objective function using a Gaussian Process? Could we have based the surrogate on some other class of functions instead? My guess is that perhaps Gaussian Processes have a certain type of ""mathematical flexibility"" which makes them an ideal choice for a surrogate models in the context of optimization. But in the end - is there some specific reason as to why Gaussian Processes are used in Bayesian Optimization (compared to some other class of surrogate function) ? Thanks!",,"['statistics', 'optimization', 'normal-distribution', 'machine-learning']"
6,Find the value of P[X>Y<Z>U] from a given joint distribution,Find the value of P[X>Y<Z>U] from a given joint distribution,,"Suppose the joint distribution is given by some function $f(x, y, z, u)$ . Then find the value of $P[X>Y<Z>U]$ assuming that $f$ is non-zero only for $x > 0, y>0, z>0, u>0$ My approach: Simply integrate the joint distribution function, taking care of appropriate limits for all the possible cases. However, I keep getting some form of "" circular limits "" on the integral. For example, one arrangement of the values for $x, y, z, u$ can be $y < u < x < z$ and the integral looks like $\int_{0}^{z}\int_{u}^{\infty}\int_{0}^{x}\int_{y}^{\infty}f(x, y, z, u)dx dy dz du$ Here, the limits for $z$ and $u$ are dependent on each other's value. Similarly for $x$ and $y$ . What is the way to deal with such integral limits? Forgive me if this a silly doubt, but I've been out of practice for a while. Please note that the RV are not independent. Thanks","Suppose the joint distribution is given by some function . Then find the value of assuming that is non-zero only for My approach: Simply integrate the joint distribution function, taking care of appropriate limits for all the possible cases. However, I keep getting some form of "" circular limits "" on the integral. For example, one arrangement of the values for can be and the integral looks like Here, the limits for and are dependent on each other's value. Similarly for and . What is the way to deal with such integral limits? Forgive me if this a silly doubt, but I've been out of practice for a while. Please note that the RV are not independent. Thanks","f(x, y, z, u) P[X>Y<Z>U] f x > 0, y>0, z>0, u>0 x, y, z, u y < u < x < z \int_{0}^{z}\int_{u}^{\infty}\int_{0}^{x}\int_{y}^{\infty}f(x, y, z, u)dx dy dz du z u x y","['probability', 'statistics', 'definite-integrals']"
7,How can we stay confidence replacing the population standard deviation by it's estimate?,How can we stay confidence replacing the population standard deviation by it's estimate?,,"So imagine we take $n$ random samples from a Bernoulli Trial. Thus our random samples are composed by binary random variables $X_1, X_2, ..., X_n$ . So by central limit theorem we know that the distribution of $Z=\frac{\overline{X}-p}{\sigma/\sqrt{n}}$ such that $\overline{X}=\frac{X_1+X_2+...+X_n}{n}$ approximates a standard normal pdf when $n$ is big enough. So finding the probability that $Z$ lies between $-1.96$ and $1.96$ is: $$P(-1.96\le Z\le 1.96)=P(-1.96\le \frac{\overline{X}-p}{\sigma/\sqrt{n}} \le 1.96) = 0.95$$ We also know that the standard deviation of our Binary Random Variable is $\sigma=\sqrt{p(1-p)}$ . Thus: $$P(-1.96\le \frac{\overline{X}-p}{\sqrt\frac{p(1-p)}{n}} \le 1.96) = 0.95$$ The book I'm using just replace $p$ by it's estimate $\overline{X}$ without further explanation. Why can we do that? Thus: $$P(-1.96\le \frac{\overline{X}-p}{\sqrt\frac{\overline{X}(1-\overline{X})}{n}} \le 1.96) = 0.95$$ So transforming a little we have that: $$P(\overline{X} -1.96\sqrt\frac{\overline{X}(1-\overline{X})}{n} \le p \le \overline{X} + 1.96 \sqrt\frac{\overline{X}(1-\overline{X})}{n}) = 0.95$$ How can we still saying that this is true with 95% of confidence? what justifies replacing $p$ by $\overline{X}$ ? I mean the 95% confidence interval is true when we use the population standard deviation and not some estimate. Using an unbiased estimator for the standard deviation population will only tells us that we are going to have a 95% confidence interval in the long run. So, it's the estimator $\overline{X}(1-\overline{X})$ for $\sigma^2$ even unbiased?","So imagine we take random samples from a Bernoulli Trial. Thus our random samples are composed by binary random variables . So by central limit theorem we know that the distribution of such that approximates a standard normal pdf when is big enough. So finding the probability that lies between and is: We also know that the standard deviation of our Binary Random Variable is . Thus: The book I'm using just replace by it's estimate without further explanation. Why can we do that? Thus: So transforming a little we have that: How can we still saying that this is true with 95% of confidence? what justifies replacing by ? I mean the 95% confidence interval is true when we use the population standard deviation and not some estimate. Using an unbiased estimator for the standard deviation population will only tells us that we are going to have a 95% confidence interval in the long run. So, it's the estimator for even unbiased?","n X_1, X_2, ..., X_n Z=\frac{\overline{X}-p}{\sigma/\sqrt{n}} \overline{X}=\frac{X_1+X_2+...+X_n}{n} n Z -1.96 1.96 P(-1.96\le Z\le 1.96)=P(-1.96\le \frac{\overline{X}-p}{\sigma/\sqrt{n}} \le 1.96) = 0.95 \sigma=\sqrt{p(1-p)} P(-1.96\le \frac{\overline{X}-p}{\sqrt\frac{p(1-p)}{n}} \le 1.96) = 0.95 p \overline{X} P(-1.96\le \frac{\overline{X}-p}{\sqrt\frac{\overline{X}(1-\overline{X})}{n}} \le 1.96) = 0.95 P(\overline{X} -1.96\sqrt\frac{\overline{X}(1-\overline{X})}{n} \le p \le \overline{X} + 1.96 \sqrt\frac{\overline{X}(1-\overline{X})}{n}) = 0.95 p \overline{X} \overline{X}(1-\overline{X}) \sigma^2","['statistics', 'proof-explanation', 'statistical-inference', 'estimation', 'central-limit-theorem']"
8,Relationship between definitions of Regular Conditional Distribution.,Relationship between definitions of Regular Conditional Distribution.,,"There seem to be two different definitions of a regular conditional distribution, but they seem to define a slightly different kernel function. How are they connected? Definition 1 and Definition 2 . Set Up Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $(\mathsf{E}, \mathcal{E})$ a measurable space, $X:\Omega\to\mathsf{E}$ a random variable with distribution $P_X = \mathbb{P}\circ X^{-1}$ , and $\mathcal{G}\subseteq \mathcal{F}$ be a sub-sigma algebra. Definitions Definition 1 : A kernel $k:\Omega\times \mathcal{E}\to [0, 1]$ that is a version of $\mathbb{E}[\mathbb{1}_{X\in A} \mid \mathcal{G}](\omega) = k(\omega, A)$ . Definition 2 : A kernel $k:\mathsf{E}\times\mathcal{F}\to[0, 1]$ satisfying $\mathbb{P}(A\cap X^{-1}(B)) = \int_B k(x, A) d P_X(x)$ . It almost seems that in the second definition one uses the inverse of $X$ as the random variable of interst, but this doesn't necessarily exist. MAJOR EDIT There is something really odd at play. I think there are actually many different definitions but people seem to not distinguish between them. Definition 1 is definitely a definition for a regular conditional distribution of a random variable given a sub-sigma algebra . That is $\mathbb{P}(X\in A \mid \mathcal{G})$ Definition 2 seems to be something like a regular conditional probability of a set given a random variable . That is $\mathbb{P}(A \mid X = x)$ .","There seem to be two different definitions of a regular conditional distribution, but they seem to define a slightly different kernel function. How are they connected? Definition 1 and Definition 2 . Set Up Let be a probability space, a measurable space, a random variable with distribution , and be a sub-sigma algebra. Definitions Definition 1 : A kernel that is a version of . Definition 2 : A kernel satisfying . It almost seems that in the second definition one uses the inverse of as the random variable of interst, but this doesn't necessarily exist. MAJOR EDIT There is something really odd at play. I think there are actually many different definitions but people seem to not distinguish between them. Definition 1 is definitely a definition for a regular conditional distribution of a random variable given a sub-sigma algebra . That is Definition 2 seems to be something like a regular conditional probability of a set given a random variable . That is .","(\Omega, \mathcal{F}, \mathbb{P}) (\mathsf{E}, \mathcal{E}) X:\Omega\to\mathsf{E} P_X = \mathbb{P}\circ X^{-1} \mathcal{G}\subseteq \mathcal{F} k:\Omega\times \mathcal{E}\to [0, 1] \mathbb{E}[\mathbb{1}_{X\in A} \mid \mathcal{G}](\omega) = k(\omega, A) k:\mathsf{E}\times\mathcal{F}\to[0, 1] \mathbb{P}(A\cap X^{-1}(B)) = \int_B k(x, A) d P_X(x) X \mathbb{P}(X\in A \mid \mathcal{G}) \mathbb{P}(A \mid X = x)","['probability-theory', 'measure-theory', 'statistics', 'probability-distributions', 'conditional-probability']"
9,Why arithmetic mean gives the closest number in a data set? [duplicate],Why arithmetic mean gives the closest number in a data set? [duplicate],,"This question already has answers here : Arithmetic mean. Why does it work? (6 answers) Closed 2 years ago . I just enrolled in AP Statistics course this week. And, one thing that popped up a lot in descriptive statistics is the idea of the mean. I understand mean as the closest data point to all of the data points. But, I simply don't understand the rationale behind it. How the one who made this formula come to think about it? What's intuition? Can anyone resolve that for me? Why mean = Sum of observations / Number of observations?","This question already has answers here : Arithmetic mean. Why does it work? (6 answers) Closed 2 years ago . I just enrolled in AP Statistics course this week. And, one thing that popped up a lot in descriptive statistics is the idea of the mean. I understand mean as the closest data point to all of the data points. But, I simply don't understand the rationale behind it. How the one who made this formula come to think about it? What's intuition? Can anyone resolve that for me? Why mean = Sum of observations / Number of observations?",,"['statistics', 'expected-value', 'average']"
10,summing over a new variable in joint distribution,summing over a new variable in joint distribution,,"I have noticed some examples when evaluating a joint probability they introduce a new variable by summing over it. For example: $P(A,B) = \sum_{C} P(A,B,C) = \sum_{C} P(A|B,C) P(B,C)= \sum_{C} P(A|B,C) P(B|C)$ What is the name of this approach ? and when do we use it ? My second question is that shouldn't the above equation be further factored to P(C)? like this: $P(A,B) = \sum_{C} P(A,B,C) = \sum_{C} P(A|B,C) P(B,C)= \sum_{C} P(A|B,C) P(B|C) P(C)$ Or is it ok to stop whenever we want ?",I have noticed some examples when evaluating a joint probability they introduce a new variable by summing over it. For example: What is the name of this approach ? and when do we use it ? My second question is that shouldn't the above equation be further factored to P(C)? like this: Or is it ok to stop whenever we want ?,"P(A,B) = \sum_{C} P(A,B,C) = \sum_{C} P(A|B,C) P(B,C)= \sum_{C} P(A|B,C) P(B|C) P(A,B) = \sum_{C} P(A,B,C) = \sum_{C} P(A|B,C) P(B,C)= \sum_{C} P(A|B,C) P(B|C) P(C)","['probability', 'statistics']"
11,Modelling difference in stock prices after a Brownian motion,Modelling difference in stock prices after a Brownian motion,,"Question Stocks $A$ and $B$ open on trading day at the same price. Let $X(t)$ denote the dollar amount by which stock $A$ 's price exceeds stock $B$ 's price when $100t\%$ of the trading day has elapsed. $X(t)\ \forall\ t \in [0, 1]$ is modelled as a Brownian motion process with $\mu = 0$ and $\sigma^2 = 0.3695$ . After $75\%$ of the trading day has elapsed, stock $A$ 's price is $39.75$ and stock $B$ 's price is $40.25$ . Find the probability that $X(1) \geq 0 $ . My working With $X(0) = 0$ and $\mu = 0$ , we have $$\begin{aligned} X(t) & = X(0) + \mu t + \sigma W_t\\ & = \sigma W_t, \end{aligned}$$ where $W_t \sim \mathcal{N}(0, t)$ . We can also obtain the following quantities: $$\begin{aligned} X(0.75) & = -\frac 1 2,\\ \mathbb{E}[X(0.75)] & = \mathbb{E}[X(1)]\\ & = 0,\\ Var[X(0.75)] & = 0.75\sigma^2,\\ Var[X(1)] & = \sigma^2,\\ \rho & = Corr[X(0.75), X(1)]\\ & = \frac {Cov[X(0.75), X(1)]} {\sqrt {\{Var[X(0.75)]\}\{Var[X(1)]\}}}\\ & = \frac {\sigma^2 Cov[W(0.75), W(1)]} {\sigma^2 \sqrt {0.75}}\\ & = \frac {\min\{0.75, 1\}} {\sqrt {0.75}}\\ & = \sqrt {0.75}. \end{aligned}$$ Now, let $$X(1) \mid X(0.75) = -\frac 1 2 \sim \mathcal{N}(s, t),$$ where $$\begin{aligned} s & = \mathbb{E}[X(1)] + \sqrt {\frac {Var[X(1)]} {Var[X(0.75)]}}(\rho)\{X(0.75) - \mathbb{E}[X(0.75)]\}\\ & = -\frac 1 2 \end{aligned}$$ and $$\begin{aligned} t & = (1 - \rho^2)Var[X(1)]\\ & = \frac 1 4 \sigma^2. \end{aligned}$$ With $\sigma^2 = 0.3695$ , $$X(1) \mid X(0.75) = -\frac 1 2 \sim \mathcal{N}\left(-\frac 1 2, \frac {739} {8000}\right).$$ $$\begin{aligned} \therefore \mathbb{P}[X(1) \geq 0] & = 1 - \mathbb{P}[X(1) < 0]\\ & = 1 - \mathbb{P}\left(Z < \sqrt {\frac {2000} {739}}\right)\\ & = 0.04997 \end{aligned}$$ As I have just covered Brownian motion in class, I am wondering whether my answer is correct and in particular, whether my working makes sense. Any comments will be greatly appreciated :)","Question Stocks and open on trading day at the same price. Let denote the dollar amount by which stock 's price exceeds stock 's price when of the trading day has elapsed. is modelled as a Brownian motion process with and . After of the trading day has elapsed, stock 's price is and stock 's price is . Find the probability that . My working With and , we have where . We can also obtain the following quantities: Now, let where and With , As I have just covered Brownian motion in class, I am wondering whether my answer is correct and in particular, whether my working makes sense. Any comments will be greatly appreciated :)","A B X(t) A B 100t\% X(t)\ \forall\ t \in [0, 1] \mu = 0 \sigma^2 = 0.3695 75\% A 39.75 B 40.25 X(1) \geq 0  X(0) = 0 \mu = 0 \begin{aligned}
X(t) & = X(0) + \mu t + \sigma W_t\\
& = \sigma W_t,
\end{aligned} W_t \sim \mathcal{N}(0, t) \begin{aligned}
X(0.75) & = -\frac 1 2,\\
\mathbb{E}[X(0.75)] & = \mathbb{E}[X(1)]\\
& = 0,\\
Var[X(0.75)] & = 0.75\sigma^2,\\
Var[X(1)] & = \sigma^2,\\
\rho & = Corr[X(0.75), X(1)]\\
& = \frac {Cov[X(0.75), X(1)]} {\sqrt {\{Var[X(0.75)]\}\{Var[X(1)]\}}}\\
& = \frac {\sigma^2 Cov[W(0.75), W(1)]} {\sigma^2 \sqrt {0.75}}\\
& = \frac {\min\{0.75, 1\}} {\sqrt {0.75}}\\
& = \sqrt {0.75}.
\end{aligned} X(1) \mid X(0.75) = -\frac 1 2 \sim \mathcal{N}(s, t), \begin{aligned}
s & = \mathbb{E}[X(1)] + \sqrt {\frac {Var[X(1)]} {Var[X(0.75)]}}(\rho)\{X(0.75) - \mathbb{E}[X(0.75)]\}\\
& = -\frac 1 2
\end{aligned} \begin{aligned}
t & = (1 - \rho^2)Var[X(1)]\\
& = \frac 1 4 \sigma^2.
\end{aligned} \sigma^2 = 0.3695 X(1) \mid X(0.75) = -\frac 1 2 \sim \mathcal{N}\left(-\frac 1 2, \frac {739} {8000}\right). \begin{aligned}
\therefore \mathbb{P}[X(1) \geq 0] & = 1 - \mathbb{P}[X(1) < 0]\\
& = 1 - \mathbb{P}\left(Z < \sqrt {\frac {2000} {739}}\right)\\
& = 0.04997
\end{aligned}","['probability', 'statistics', 'stochastic-processes', 'finance']"
12,Sum of independent continuous and discrete random variables,Sum of independent continuous and discrete random variables,,"I am trying to understand how to create a PDF from the sum of an independent continuous and discrete rv, Z = X + Y . I was wondering if anyone would be willing to provide an example of this. I have seen the equation FZ(z) = ∑ FY(z−x) . PX(x) , but I can't seem to make sense of how the z's and x's are taken as input into FY. Specifically I am working with a Bernoulli and Gaussian, but an example with any continuous and discrete random variables would be appreciated. Thanks.","I am trying to understand how to create a PDF from the sum of an independent continuous and discrete rv, Z = X + Y . I was wondering if anyone would be willing to provide an example of this. I have seen the equation FZ(z) = ∑ FY(z−x) . PX(x) , but I can't seem to make sense of how the z's and x's are taken as input into FY. Specifically I am working with a Bernoulli and Gaussian, but an example with any continuous and discrete random variables would be appreciated. Thanks.",,"['statistics', 'random-variables']"
13,"If the random variables $(v_k)$ are i.i.d, are the $(v_k-m_k)$ i.i.d. as well?","If the random variables  are i.i.d, are the  i.i.d. as well?",(v_k) (v_k-m_k),"This is my first time asking, so if my question is lacking, please let me know so I can edit it. $v_{k}$ is iid across $k$ where $k=1,....K$ and I can represent its CDF as $F(v)$ . ( Note : I have very large $K$ for sure ) I am creating a pseudo reservation value such that $\hat{v}_{k} = v_{k} - \max(0, \max_{k^{'}\neq k}(v_{k^{'}}-c_{k^{'}}))$ where $c_{k^{'}}$ is just constant unique to $k^{'}$ . Let's say $\hat{v}_{k}$ follows new CDF called $\hat{F}(\hat{v_{k}})$ . Goal : I want to show $\hat{F}(\hat{v_k})$ is iid across $k$ ( or at least for majority of $k$ ) Attempt is the following. Assume $v_{1}-c_{1} > v_{2}-c_{2} > v_{3}-c_{c} > ... > v_{K}-c_{K}$ . Then, we have the follwing. $$\hat{v}_{1} = v_{1} - \max(0, v_{2}-c_{2}) \quad k=1$$ $$\hat{v}_{k} = v_{k} - \max(0, v_{1}-c_{1}) \quad \text{for } k = 2,...,K$$ Current Conclusion : (1) $Pr(\hat{v}_{k}\leq x) = Pr(v_{k} \leq x+ \max(0, v_{1}-c_{1}))$ for $k=2,...K$ . Since I can treat $\max(0, v_{1}-c_{1})$ as some exogenous constant term, and $F(v_{k})$ are identically distributed, $\hat{F}(\hat{v_k})$ is identically distributed for at least $k=2,...,K$ . (2) For sets $A_{2},...,A_{K}$ of possible values of $v_{k}$ , $k=2,...,K$ , $$Pr(\hat{v}_{2} \in A_{2} \text{ & } ... \text{ & } \hat{v}_{K} \in A_{K})$$ $$=Pr(v_{k} \in \{ x+\max(0, v_{1}-c_{1}) \quad   x \in A_{k}\}) \text{   for } k= 2,...,K$$ $$ = \Pi_{k=2}^{K} Pr(v_{k} \in \{ x+\max(0, v_{1}-c_{1}) \quad   x \in A_{k}\}))  $$ because $v_{2}, ... v_{K}$ are independent and we have exogenous constant term $$=Pr(\hat{v}_{2} \in A_{2}) ... Pr(\hat{v}_{K} \in A_{K})$$ Thus , can I say that $\hat{F}(\hat{v}_{k})$ is iid for all $k$ except one?","This is my first time asking, so if my question is lacking, please let me know so I can edit it. is iid across where and I can represent its CDF as . ( Note : I have very large for sure ) I am creating a pseudo reservation value such that where is just constant unique to . Let's say follows new CDF called . Goal : I want to show is iid across ( or at least for majority of ) Attempt is the following. Assume . Then, we have the follwing. Current Conclusion : (1) for . Since I can treat as some exogenous constant term, and are identically distributed, is identically distributed for at least . (2) For sets of possible values of , , because are independent and we have exogenous constant term Thus , can I say that is iid for all except one?","v_{k} k k=1,....K F(v) K \hat{v}_{k} = v_{k} - \max(0, \max_{k^{'}\neq k}(v_{k^{'}}-c_{k^{'}})) c_{k^{'}} k^{'} \hat{v}_{k} \hat{F}(\hat{v_{k}}) \hat{F}(\hat{v_k}) k k v_{1}-c_{1} > v_{2}-c_{2} > v_{3}-c_{c} > ... > v_{K}-c_{K} \hat{v}_{1} = v_{1} - \max(0, v_{2}-c_{2}) \quad k=1 \hat{v}_{k} = v_{k} - \max(0, v_{1}-c_{1}) \quad \text{for } k = 2,...,K Pr(\hat{v}_{k}\leq x) = Pr(v_{k} \leq x+ \max(0, v_{1}-c_{1})) k=2,...K \max(0, v_{1}-c_{1}) F(v_{k}) \hat{F}(\hat{v_k}) k=2,...,K A_{2},...,A_{K} v_{k} k=2,...,K Pr(\hat{v}_{2} \in A_{2} \text{ & } ... \text{ & } \hat{v}_{K} \in A_{K}) =Pr(v_{k} \in \{ x+\max(0, v_{1}-c_{1}) \quad   x \in A_{k}\}) \text{   for } k= 2,...,K  = \Pi_{k=2}^{K} Pr(v_{k} \in \{ x+\max(0, v_{1}-c_{1}) \quad   x \in A_{k}\}))   v_{2}, ... v_{K} =Pr(\hat{v}_{2} \in A_{2}) ... Pr(\hat{v}_{K} \in A_{K}) \hat{F}(\hat{v}_{k}) k","['probability-theory', 'statistics', 'probability-distributions']"
14,Why Null Hypothesis for contingency tables is 'independent'?,Why Null Hypothesis for contingency tables is 'independent'?,,"For contingency tables I don't understand why the Null Hypothesis is 'independent'. We calculate Sum(Observed^2 / Expected) - N and compare this with the chi-squared distribution table. Let's say: Sum(Observed^2 / Expected) - N = 4 Chi-square value = 5.1 So 4 < 5.1 and we do NOT reject the Null Hypothesis, they are independent. But if 4 < 5.1, then the difference between all Observed and Expected is smaller than our Critical Value, so surely they are correlated and therefore not independent? ADDITIONAL INFORMATION I got confused because I was doing this question: and in the answer: they state the Null Hypothesis is ""no difference"", which read like they are not independent?","For contingency tables I don't understand why the Null Hypothesis is 'independent'. We calculate Sum(Observed^2 / Expected) - N and compare this with the chi-squared distribution table. Let's say: Sum(Observed^2 / Expected) - N = 4 Chi-square value = 5.1 So 4 < 5.1 and we do NOT reject the Null Hypothesis, they are independent. But if 4 < 5.1, then the difference between all Observed and Expected is smaller than our Critical Value, so surely they are correlated and therefore not independent? ADDITIONAL INFORMATION I got confused because I was doing this question: and in the answer: they state the Null Hypothesis is ""no difference"", which read like they are not independent?",,"['statistics', 'hypothesis-testing', 'correlation', 'chi-squared']"
15,Sample Pearson correlation coefficient,Sample Pearson correlation coefficient,,"Given paired data $\left\{(x_{1},y_{1}),\ldots ,(x_{n},y_{n})\right\}$ consisting of $n$ iid pairs ( $x_i$ and $y_i$ are indenpendent), $r_{xy}$ is defined as: $$ r_{xy}={\frac {\sum _{i=1}^{n}(x_{i}-{\bar {x}})(y_{i}-{\bar {y}})}{{\sqrt {\sum _{i=1}^{n}(x_{i}-{\bar {x}})^{2}}}{\sqrt {\sum _{i=1}^{n}(y_{i}-{\bar {y}})^{2}}}}}$$ where $Ex_1=\mu_1$ , $Ey_1=\mu_2$ , $Var [x_1]=\sigma_1^2$ , $Var [y_1]=\sigma_2^2$ . What is the limiting distribution of $\frac{\sqrt{n} \, r_{xy}}{\sqrt{1-r_{xy}^2}}$ .","Given paired data consisting of iid pairs ( and are indenpendent), is defined as: where , , , . What is the limiting distribution of .","\left\{(x_{1},y_{1}),\ldots ,(x_{n},y_{n})\right\} n x_i y_i r_{xy}  r_{xy}={\frac {\sum _{i=1}^{n}(x_{i}-{\bar {x}})(y_{i}-{\bar {y}})}{{\sqrt {\sum _{i=1}^{n}(x_{i}-{\bar {x}})^{2}}}{\sqrt {\sum _{i=1}^{n}(y_{i}-{\bar {y}})^{2}}}}} Ex_1=\mu_1 Ey_1=\mu_2 Var [x_1]=\sigma_1^2 Var [y_1]=\sigma_2^2 \frac{\sqrt{n} \, r_{xy}}{\sqrt{1-r_{xy}^2}}","['probability', 'analysis', 'statistics', 'statistical-inference', 'probability-limit-theorems']"
16,"Clarifying the rule: ""R-squared is invalid for nonlinear regression""","Clarifying the rule: ""R-squared is invalid for nonlinear regression""",,"I'm a novice trying to determine if the use of R-squared is valid for developing an exponential regression (of the form $y=a+b\,e^{cx}$ ). I've come across several articles online that say R-squared is invalid for nonlinear regression . That claim makes sense to me. But I've also noticed that lots of people still use R-squared for  nonlinear regression. Several of my statistics books suggest that R-squared can be used for all regression analysis, including nonlinear regression. Most statistics software produces a R-squared value for nonlinear regression. People that are far more educated than me continue to use R-squared for nonlinear regression. So, I can't help but think that something doesn't add up here. Why do so many people still do it? Are they really all wrong, and I'm right? My uneducated thoughts are: Sure, it's a common misconception that R-squared is valid for all types of regression, including nonlinear regression. But also, I'm wondering if the wording of ""R-squared is invalid for nonlinear regression"" might be an oversimplification . Does the rule need clarification? For example: R-squared can be used for some nonlinear regressions, such exponential regression, if the equation is first flattened by taking the natural logarithm of both sides. [removed - misleading] There are models that appear to be nonlinear, but in this context, they're actually considered to be linear. Examples: parabolic and polynomial. So using R-squared for them is valid. As mentioned, I'm a novice, I'm not a mathematician. Are clarifications 1-3 above correct? Or have I misunderstood? Note: I've intentionally posted this question on Math Stack Exchange, instead of on Cross Validated, because I find I get better answers here.","I'm a novice trying to determine if the use of R-squared is valid for developing an exponential regression (of the form ). I've come across several articles online that say R-squared is invalid for nonlinear regression . That claim makes sense to me. But I've also noticed that lots of people still use R-squared for  nonlinear regression. Several of my statistics books suggest that R-squared can be used for all regression analysis, including nonlinear regression. Most statistics software produces a R-squared value for nonlinear regression. People that are far more educated than me continue to use R-squared for nonlinear regression. So, I can't help but think that something doesn't add up here. Why do so many people still do it? Are they really all wrong, and I'm right? My uneducated thoughts are: Sure, it's a common misconception that R-squared is valid for all types of regression, including nonlinear regression. But also, I'm wondering if the wording of ""R-squared is invalid for nonlinear regression"" might be an oversimplification . Does the rule need clarification? For example: R-squared can be used for some nonlinear regressions, such exponential regression, if the equation is first flattened by taking the natural logarithm of both sides. [removed - misleading] There are models that appear to be nonlinear, but in this context, they're actually considered to be linear. Examples: parabolic and polynomial. So using R-squared for them is valid. As mentioned, I'm a novice, I'm not a mathematician. Are clarifications 1-3 above correct? Or have I misunderstood? Note: I've intentionally posted this question on Math Stack Exchange, instead of on Cross Validated, because I find I get better answers here.","y=a+b\,e^{cx}",['statistics']
17,Transition probability exponential in distance or difference,Transition probability exponential in distance or difference,,"Is there a situation, for example in physics or in dynamical systems, where we have a Markov chain where the transition probability between two states satisfies a law such as $$ p(y|x) = C e^{-d(x,y)} $$ where $d(x,y)$ is either a distance (as in a metric space), or a difference of some kind (for example, difference of energy density in physics)? The Boltzmann distribution has a similar law for the relative probabilities (the Boltzmann factor), but that's not quite the same as transition probabilities.","Is there a situation, for example in physics or in dynamical systems, where we have a Markov chain where the transition probability between two states satisfies a law such as where is either a distance (as in a metric space), or a difference of some kind (for example, difference of energy density in physics)? The Boltzmann distribution has a similar law for the relative probabilities (the Boltzmann factor), but that's not quite the same as transition probabilities.","
p(y|x) = C e^{-d(x,y)}
 d(x,y)","['statistics', 'dynamical-systems', 'markov-chains', 'statistical-mechanics']"
18,Minimiser of risk for linear-exponential error loss,Minimiser of risk for linear-exponential error loss,,"Question: Solve the following optimisation problem: $$\arg\min_{f} \mathbb{E} \left( \exp (-(Y- f(X))) + (Y - f(X)) - 1 \right)$$ Context: The linear-exponential loss function (LINEX loss for short) is given by $$L(\theta, \hat{\theta}) = \exp (-(\theta - \hat{\theta})) + (\theta - \hat{\theta}) - 1$$ The intuition behind this loss is that it is an asymmetric approximation to the usual quadratic loss function. This is a popular loss function in econometrics. Given two random $X$ and $Y$ , we may compute the loss of $Y$ relative to a measurable function of $X$ , $f(X)$ , simply by computing $L(Y, f(X))$ . A central problem in statistical decision theory is computing the minimiser of the risk of this loss; namely, we wish to solve the following optimisation problem: $$\arg\min_{f \in L^2} L(Y, f(X)) = \arg\min_{f \in L^2} \mathbb{E} \left( \exp (-(Y- f(X))) + (Y - f(X)) - 1 \right)$$ By considering some simpler cases (e.g. the case where $(X,Y)$ have a density ), one may conjecture that the minimiser is $\hat{f}(X) = - \log \mathbb{E}(e^{-Y}|X)$ . Indeed this paper derives the result in the setting of Bayes estimation. How may one arrive at this result in this setting? A similar problem: A related problem is computing the minimiser for the risk of squared-error loss: $$\arg\min_f \mathbb{E}[ (Y-f(X))^2 ] = \mathbb{E} (Y | X)$$ In this setting, one adds and subtracts $\mathbb{E}(Y|X)$ , expands, then uses properties of conditional expectation to conclude that $\mathbb{E}(Y|X)$ is indeed the minimiser. Indeed: $$\begin{align*} \mathbb{E}[(Y - f(X))^2] &= \mathbb{E}[(Y  - \mathbb{E}(Y|X) + \mathbb{E}(Y|X) - f(X))^2] \\ &= \mathbb{E}[(Y  - \mathbb{E}(Y|X))^2] + \mathbb{E}[(\mathbb{E}(Y|X) - f(X))^2] + 2 \mathbb{E}[(Y  - \mathbb{E}(Y|X))(\mathbb{E}(Y|X) - f(X))^2] \\ &= \mathbb{E}[(Y  - \mathbb{E}(Y|X))^2] + \mathbb{E}[(\mathbb{E}(Y|X) - f(X))^2] \end{align*}$$ where, in the last equality, we used the tower property with conditioning on $X$ to conclude the cross term is zero. At this point it is now evident that $f(X) = \mathbb{E}(Y|X)$ is a minimiser. Perhaps this idea could be extended to the loss function given above?","Question: Solve the following optimisation problem: Context: The linear-exponential loss function (LINEX loss for short) is given by The intuition behind this loss is that it is an asymmetric approximation to the usual quadratic loss function. This is a popular loss function in econometrics. Given two random and , we may compute the loss of relative to a measurable function of , , simply by computing . A central problem in statistical decision theory is computing the minimiser of the risk of this loss; namely, we wish to solve the following optimisation problem: By considering some simpler cases (e.g. the case where have a density ), one may conjecture that the minimiser is . Indeed this paper derives the result in the setting of Bayes estimation. How may one arrive at this result in this setting? A similar problem: A related problem is computing the minimiser for the risk of squared-error loss: In this setting, one adds and subtracts , expands, then uses properties of conditional expectation to conclude that is indeed the minimiser. Indeed: where, in the last equality, we used the tower property with conditioning on to conclude the cross term is zero. At this point it is now evident that is a minimiser. Perhaps this idea could be extended to the loss function given above?","\arg\min_{f} \mathbb{E} \left( \exp (-(Y- f(X))) + (Y - f(X)) - 1 \right) L(\theta, \hat{\theta}) = \exp (-(\theta - \hat{\theta})) + (\theta - \hat{\theta}) - 1 X Y Y X f(X) L(Y, f(X)) \arg\min_{f \in L^2} L(Y, f(X)) = \arg\min_{f \in L^2} \mathbb{E} \left( \exp (-(Y- f(X))) + (Y - f(X)) - 1 \right) (X,Y) \hat{f}(X) = - \log \mathbb{E}(e^{-Y}|X) \arg\min_f \mathbb{E}[ (Y-f(X))^2 ] = \mathbb{E} (Y | X) \mathbb{E}(Y|X) \mathbb{E}(Y|X) \begin{align*}
\mathbb{E}[(Y - f(X))^2] &= \mathbb{E}[(Y  - \mathbb{E}(Y|X) + \mathbb{E}(Y|X) - f(X))^2] \\
&= \mathbb{E}[(Y  - \mathbb{E}(Y|X))^2] + \mathbb{E}[(\mathbb{E}(Y|X) - f(X))^2] + 2 \mathbb{E}[(Y  - \mathbb{E}(Y|X))(\mathbb{E}(Y|X) - f(X))^2] \\
&= \mathbb{E}[(Y  - \mathbb{E}(Y|X))^2] + \mathbb{E}[(\mathbb{E}(Y|X) - f(X))^2]
\end{align*} X f(X) = \mathbb{E}(Y|X)","['statistics', 'optimization', 'statistical-inference', 'conditional-expectation', 'robust-statistics']"
19,Expected number of samples to estimate the mode of categorical distribution,Expected number of samples to estimate the mode of categorical distribution,,"Suppose I have a categorical distribution with pmf $(p_1, \dots, p_n)$ . What is the expected number of iid samples $\mathcal{S} = \{x_1, \dots, x_m\}$ I have to samples for the empirical mode to be equal to the actual mode $\mathrm{mode}(\mathcal{S}) = \arg\max_i p_i$ . That seems like a very standard question but I can't find anything about it online. Clearly, if the mode has probability 1 then the expected number of samples is 1 and when the mode goes to $0$ then the number of samples has to goes $\infty$ . Intuitively the number of samples is related $\frac{1}{\max_i p_i}$ , although the actual number probably depends on the pmf and not only on the probability of the mode. Has this expected number of samples been studied ? Is the intuition of the number of samples being related to $\frac{1}{\max_i p_i}$ true and if so what is the formal relation ?","Suppose I have a categorical distribution with pmf . What is the expected number of iid samples I have to samples for the empirical mode to be equal to the actual mode . That seems like a very standard question but I can't find anything about it online. Clearly, if the mode has probability 1 then the expected number of samples is 1 and when the mode goes to then the number of samples has to goes . Intuitively the number of samples is related , although the actual number probably depends on the pmf and not only on the probability of the mode. Has this expected number of samples been studied ? Is the intuition of the number of samples being related to true and if so what is the formal relation ?","(p_1, \dots, p_n) \mathcal{S} = \{x_1, \dots, x_m\} \mathrm{mode}(\mathcal{S}) = \arg\max_i p_i 0 \infty \frac{1}{\max_i p_i} \frac{1}{\max_i p_i}","['probability', 'statistics', 'expected-value', 'rate-of-convergence']"
20,"Let $X_n,Y_n$ be two sequences of random variable, where $0<X_n<Y_n$. Does $Y_n=O_p(1)$ imply $X_n=O_p(1)?$","Let  be two sequences of random variable, where . Does  imply","X_n,Y_n 0<X_n<Y_n Y_n=O_p(1) X_n=O_p(1)?","Let $X_n,Y_n$ be two sequences of random variable, where $0<X_n<Y_n$ . Does $Y_n=O_p(1)$ imply $X_n=O_p(1)?$ My proof Since $Y_n=O_p(1)$ , $$ (\forall \epsilon>0)(\exists k)\Big(P(|Y_n|>k)\leq \epsilon\Big)\ \  $$ Next, by law of total probability $$ P(|X_n|>k)=\underbrace{P(|Y_n|>k)}_{\leq \epsilon}\underbrace{P(|X_n|>k|\ |Y_n|>k)}_{<1}+\underbrace{P(|Y_n|\leq k)}_{\geq 1-\epsilon }\underbrace{P(|X_n|>k|\ |Y_n|\leq k)}_{0}\leq \epsilon $$ So the same $k$ works. Is my proof correct? I will also accept any alternative proof (or counter proof) as answer.","Let be two sequences of random variable, where . Does imply My proof Since , Next, by law of total probability So the same works. Is my proof correct? I will also accept any alternative proof (or counter proof) as answer.","X_n,Y_n 0<X_n<Y_n Y_n=O_p(1) X_n=O_p(1)? Y_n=O_p(1) 
(\forall \epsilon>0)(\exists k)\Big(P(|Y_n|>k)\leq \epsilon\Big)\ \ 
 
P(|X_n|>k)=\underbrace{P(|Y_n|>k)}_{\leq \epsilon}\underbrace{P(|X_n|>k|\ |Y_n|>k)}_{<1}+\underbrace{P(|Y_n|\leq k)}_{\geq 1-\epsilon }\underbrace{P(|X_n|>k|\ |Y_n|\leq k)}_{0}\leq \epsilon
 k","['real-analysis', 'probability-theory', 'statistics', 'solution-verification', 'conditional-probability']"
21,Confidence Interval for the product of heads and tails in 100 coin flips,Confidence Interval for the product of heads and tails in 100 coin flips,,"If I flip 100 fair coins and then multiply the number of heads by the number of tails. Can you give a double-sided 95% confidence interval on the product of the number of heads by the number of tails? Let $T$ denote the number of tails, and let $P$ denote the product. So $P = T(100-T)$ . I am trying to apply the central limit theorem. I already calculated that $E[P] = E[100T] - E[T^2] = 5000 - 2525 = 2475$ . Is there a faster way to calculate the variance of $P$ other than brute forcing the value of $E[T^3]$ and $E[T^4]$ ? I am on the wrong track?","If I flip 100 fair coins and then multiply the number of heads by the number of tails. Can you give a double-sided 95% confidence interval on the product of the number of heads by the number of tails? Let denote the number of tails, and let denote the product. So . I am trying to apply the central limit theorem. I already calculated that . Is there a faster way to calculate the variance of other than brute forcing the value of and ? I am on the wrong track?",T P P = T(100-T) E[P] = E[100T] - E[T^2] = 5000 - 2525 = 2475 P E[T^3] E[T^4],"['probability', 'combinatorics', 'statistics', 'binomial-distribution', 'confidence-interval']"
22,Conditional distribution function for two standard normal variables,Conditional distribution function for two standard normal variables,,"Let $U,V$ have a bivariate normal distribution with joint density $f_{u,v}(u,v)=\frac{1}{2\pi\sqrt{1-\rho^2}}\exp\left(-\frac{u^2+v^2-2\rho uv}{2(1-\rho^2)}\right)$ where $\rho\in(-1,1)$ is the correlation coefficient. I want to show that the conditional distribution of $U$ given $V=v$ is distributed as $N(\rho v,1-\rho^2)$ for all $v\in\mathbb{R}$ . We are allowed to assume $U,V$ are $N(0,1)$ variables. My attempt: By definition of the conditional density function we have $f_{u|v}(u|v)=\frac{f_{u,v}(u,v)}{f_v(v)}=\frac{\frac{1}{2\pi\sqrt{1-\rho^2}}\exp(-\frac{u^2+v^2-2\rho uv}{2(1-\rho^2)})}{\frac{1}{\sqrt{2\pi}}\exp(-\frac{v^2}{2})}$ $$=\frac{1}{\sqrt{1-\rho^2}}\exp\left(-\frac{(\rho v)^2+u^2-2\rho uv}{2(1-\rho^2)}\right)$$ I know I basically need to show this is the density function of a $N(\rho v,1-\rho^2)$ variable, but I am having problems with this - if we read off the mean and variance we should have $2\sigma^2=2(1-\rho^2)$ and so $\sigma^2=1-\rho^2$ , and the mean is $\rho v$ . But in the very first part before the exponent, surely we should have $\frac{1}{\sigma\sqrt{2\pi}}$ ? As the current form for my solution is incompatible with this. Any help would be really useful.","Let have a bivariate normal distribution with joint density where is the correlation coefficient. I want to show that the conditional distribution of given is distributed as for all . We are allowed to assume are variables. My attempt: By definition of the conditional density function we have I know I basically need to show this is the density function of a variable, but I am having problems with this - if we read off the mean and variance we should have and so , and the mean is . But in the very first part before the exponent, surely we should have ? As the current form for my solution is incompatible with this. Any help would be really useful.","U,V f_{u,v}(u,v)=\frac{1}{2\pi\sqrt{1-\rho^2}}\exp\left(-\frac{u^2+v^2-2\rho uv}{2(1-\rho^2)}\right) \rho\in(-1,1) U V=v N(\rho v,1-\rho^2) v\in\mathbb{R} U,V N(0,1) f_{u|v}(u|v)=\frac{f_{u,v}(u,v)}{f_v(v)}=\frac{\frac{1}{2\pi\sqrt{1-\rho^2}}\exp(-\frac{u^2+v^2-2\rho uv}{2(1-\rho^2)})}{\frac{1}{\sqrt{2\pi}}\exp(-\frac{v^2}{2})} =\frac{1}{\sqrt{1-\rho^2}}\exp\left(-\frac{(\rho v)^2+u^2-2\rho uv}{2(1-\rho^2)}\right) N(\rho v,1-\rho^2) 2\sigma^2=2(1-\rho^2) \sigma^2=1-\rho^2 \rho v \frac{1}{\sigma\sqrt{2\pi}}","['probability', 'probability-theory', 'statistics', 'solution-verification']"
23,asymptotic order in probability,asymptotic order in probability,,"Consider the definition of small o in probability . Let $X_n$ be a sequence of random variables and let $X_n=1+o_p(1)$ . That is, for any $\delta,\epsilon>0: P(\lvert X_n-1\rvert\geq \delta)\leq \epsilon$ for sufficiently large $n$ . The sequence converges in probability to one. This led me to conjecture that there should be a constant $1>M>0$ so that $P(\lvert X_n\rvert\geq M)\to1$ as $n\to+\infty$ . Or equivalently, $P(\lvert X_n\rvert < M)\to 0$ . Question . If it is true, then how to prove it?","Consider the definition of small o in probability . Let be a sequence of random variables and let . That is, for any for sufficiently large . The sequence converges in probability to one. This led me to conjecture that there should be a constant so that as . Or equivalently, . Question . If it is true, then how to prove it?","X_n X_n=1+o_p(1) \delta,\epsilon>0: P(\lvert X_n-1\rvert\geq \delta)\leq \epsilon n 1>M>0 P(\lvert X_n\rvert\geq M)\to1 n\to+\infty P(\lvert X_n\rvert < M)\to 0","['probability-theory', 'statistics', 'asymptotics']"
24,Random variable defined on the IID,Random variable defined on the IID,,"I understand that the mean and variance of the Cauchy distribution is undefined. I also understand that if we try to take independent and identically distributed random variable from the Cauchy distribution and attempt to use the Central Limit Theorem, it doesn't work. But what about the following case: Let $X_1,X_2,X_3$ be independent and identical random variables from the Cauchy distribution ( $x_0,\gamma$ ). Define $$Y=median(X_1,X_2,X_3)$$ Is it possible to find the expectation and variance of $Y$ ? If so, how? If not, is it because of the fundamental fact that the central limit theorem cannot be applied to the Cauchy distribution? Thanks for reading.","I understand that the mean and variance of the Cauchy distribution is undefined. I also understand that if we try to take independent and identically distributed random variable from the Cauchy distribution and attempt to use the Central Limit Theorem, it doesn't work. But what about the following case: Let be independent and identical random variables from the Cauchy distribution ( ). Define Is it possible to find the expectation and variance of ? If so, how? If not, is it because of the fundamental fact that the central limit theorem cannot be applied to the Cauchy distribution? Thanks for reading.","X_1,X_2,X_3 x_0,\gamma Y=median(X_1,X_2,X_3) Y","['probability', 'statistics', 'expected-value', 'variance', 'sampling']"
25,Least Square Estimation of Linear Regression,Least Square Estimation of Linear Regression,,"I have a linear regression model: $$y = \beta_0 + \beta_1x + \epsilon$$ with $\epsilon$ as a random noise. The least squares estimation is given by: $$S(\beta_0, \beta_1) = \sum^n_{i=1} (y_i - \beta_0 - \beta_1x_i)^2$$ By setting partial derivatives with respect to $\beta_0$ and $\beta_1$ , I obtained: $$\hat \beta_1 = \frac{\sum x_iy_i - \frac{\sum x_i \sum y_i}{n}}{\sum x_i^2 - \frac{(\sum x_i)^2}{n}} (1)$$ The final result for $\hat \beta_1$ is: $$\hat \beta_1 = \frac{\sum(x_i - \bar x)(y_i - \bar y)}{\sum (x_i - \bar x)^2} (2)$$ with $\bar x = \frac{\sum x_i}{n}$ and $\bar y = \frac{\sum y_i}{n}$ I am stuck at getting from (1) to (2), which is the final result. How should I proceed for this case?","I have a linear regression model: with as a random noise. The least squares estimation is given by: By setting partial derivatives with respect to and , I obtained: The final result for is: with and I am stuck at getting from (1) to (2), which is the final result. How should I proceed for this case?","y = \beta_0 + \beta_1x + \epsilon \epsilon S(\beta_0, \beta_1) = \sum^n_{i=1} (y_i - \beta_0 - \beta_1x_i)^2 \beta_0 \beta_1 \hat \beta_1 = \frac{\sum x_iy_i - \frac{\sum x_i \sum y_i}{n}}{\sum x_i^2 - \frac{(\sum x_i)^2}{n}} (1) \hat \beta_1 \hat \beta_1 = \frac{\sum(x_i - \bar x)(y_i - \bar y)}{\sum (x_i - \bar x)^2} (2) \bar x = \frac{\sum x_i}{n} \bar y = \frac{\sum y_i}{n}","['statistics', 'linear-regression']"
26,"What does this notation mean, concerning a vector?","What does this notation mean, concerning a vector?",,"I am currently reading a paper, in which the following system is defined: $$ \dot x(t) = f(x) + \varepsilon\sigma(x)\xi(t) \tag{1} $$ Where $x(t)$ is an $n$ -vector, $f(x)$ is some $n$ -vector transformation function, $\xi(t)$ us an $m$ -dimensional standard white Gaussian noise with parameters $\langle \xi(t)\rangle = 0,~\langle\xi(t)\xi^\mathsf{T}(\tau)\rangle = \delta(t-\tau)I$ , $\varepsilon$ is the scalar parameter of the noise intensity, and $\sigma(x)$ is an $n\times m$ -matrix-valued function of the random disturbances. And here, I do not understand, what does the notation $\langle\xi(t)\rangle$ mean, once $\xi(t)$ is a vector. I mean, I have already seen such notation, but its meaning was different, as for example, for some vectors $\boldsymbol{u}$ and $\boldsymbol{v}$ , $\langle \boldsymbol{u}, \boldsymbol{v}\rangle$ would be a dot-product of theirs, and $\langle\boldsymbol{u}, \boldsymbol{v}\rangle = 0$ only once $\boldsymbol{u} \perp \boldsymbol{v}$ . Or alternatively, as far as I know, in group theory, $\langle g \rangle$ where $g\in G$ , indicates the cyclic subgroup of $G$ , generated by its element of $g$ . In $(1)$ I completely fail to understand, what the notation means. I have rather a guess, that it may indicate ""kind-of"" expected value of a vector, since we assume the Gaussian white noise, but I have never seen such operations with vectors before, so that I cannot expand my thought on this any further.. I would be glad, if anyone could help me out with identifying, what such a notation may mean. Thank you in advance!","I am currently reading a paper, in which the following system is defined: Where is an -vector, is some -vector transformation function, us an -dimensional standard white Gaussian noise with parameters , is the scalar parameter of the noise intensity, and is an -matrix-valued function of the random disturbances. And here, I do not understand, what does the notation mean, once is a vector. I mean, I have already seen such notation, but its meaning was different, as for example, for some vectors and , would be a dot-product of theirs, and only once . Or alternatively, as far as I know, in group theory, where , indicates the cyclic subgroup of , generated by its element of . In I completely fail to understand, what the notation means. I have rather a guess, that it may indicate ""kind-of"" expected value of a vector, since we assume the Gaussian white noise, but I have never seen such operations with vectors before, so that I cannot expand my thought on this any further.. I would be glad, if anyone could help me out with identifying, what such a notation may mean. Thank you in advance!","
\dot x(t) = f(x) + \varepsilon\sigma(x)\xi(t) \tag{1}
 x(t) n f(x) n \xi(t) m \langle \xi(t)\rangle = 0,~\langle\xi(t)\xi^\mathsf{T}(\tau)\rangle = \delta(t-\tau)I \varepsilon \sigma(x) n\times m \langle\xi(t)\rangle \xi(t) \boldsymbol{u} \boldsymbol{v} \langle \boldsymbol{u}, \boldsymbol{v}\rangle \langle\boldsymbol{u}, \boldsymbol{v}\rangle = 0 \boldsymbol{u} \perp \boldsymbol{v} \langle g \rangle g\in G G g (1)","['statistics', 'notation', 'vectors', 'noise']"
27,Probability of exceeding a value with a given expectation and variance?,Probability of exceeding a value with a given expectation and variance?,,A factory produces $n$ items a week and is a random variable with expectation $50$ and variance $25$ what can be said about the probability that this weeks production will exceed $75$ ? The question then asks;  What can be said about the probability that this week’s production will be between $40$ and $60$ ? I understand the formulas for $E(x) = \frac { (n_1 + n_2 + n_3 + ... + n_m)} {m}$ and $ Var(x) = E(x^2) - E (x)^2 $ I just cant figure out how to use these two values to use them to answer the questions? Any help or explanations will be much appreciated,A factory produces items a week and is a random variable with expectation and variance what can be said about the probability that this weeks production will exceed ? The question then asks;  What can be said about the probability that this week’s production will be between and ? I understand the formulas for and I just cant figure out how to use these two values to use them to answer the questions? Any help or explanations will be much appreciated,n 50 25 75 40 60 E(x) = \frac { (n_1 + n_2 + n_3 + ... + n_m)} {m}  Var(x) = E(x^2) - E (x)^2 ,"['probability', 'statistics', 'random-variables', 'expected-value', 'variance']"
28,Finding a consistent estimator for area under simple regression line,Finding a consistent estimator for area under simple regression line,,"I am trying to solve the following problem: Take the following simple linear regression model, where $x_i \in \mathbb R$ : $y_i=\beta_0 + x_i \beta_1 + \epsilon_i$ Given that: $\mathbb E[\epsilon_i]=0$ $\mathbb E[\epsilon_i|x_i]=0$ $\beta_0 >0$ $\beta_1 <0$ Let $\theta_0$ represent the area under the regression line. Propose a consistent estimator of $\theta_0$ . I have began by finding the integral of $y_i$ with respect to $x_i$ . That is, $\theta_0= \int \beta_0 + x_i \beta_1 + \epsilon_i$ $dx_i=\beta_0x_i + {x_i^2\over{2}}{\beta_1} + \epsilon_ix_i$ I am considering proposing an MLE and proceeding to find the derivative of the log-likelihood of this expression. However, since this expression is rather complicated and I foresee the MLE computation turning incredibly thorny, I suspect I may be approaching this incorrectly. Any thoughts?","I am trying to solve the following problem: Take the following simple linear regression model, where : Given that: Let represent the area under the regression line. Propose a consistent estimator of . I have began by finding the integral of with respect to . That is, I am considering proposing an MLE and proceeding to find the derivative of the log-likelihood of this expression. However, since this expression is rather complicated and I foresee the MLE computation turning incredibly thorny, I suspect I may be approaching this incorrectly. Any thoughts?",x_i \in \mathbb R y_i=\beta_0 + x_i \beta_1 + \epsilon_i \mathbb E[\epsilon_i]=0 \mathbb E[\epsilon_i|x_i]=0 \beta_0 >0 \beta_1 <0 \theta_0 \theta_0 y_i x_i \theta_0= \int \beta_0 + x_i \beta_1 + \epsilon_i dx_i=\beta_0x_i + {x_i^2\over{2}}{\beta_1} + \epsilon_ix_i,"['statistics', 'regression', 'maximum-likelihood', 'parameter-estimation']"
29,My solution to compute type II error,My solution to compute type II error,,"Suppose there is a coin, we flipped it for 100 times and want to check if it is fair. Let $X_{1}, X_{2}, ..., X_{100}$ be the outcome of each experiment, which is a series of random variables following i.i.d. Bernoulli distributions with parameter p. For $i^{th}$ experiment, if we get a head, then $X_{i} = 1$ , otherwise $X_{i} = 0$ . Our hypothesis: $H_{0}: p = \frac{1}{2}$ against $H_{1}: p \neq \frac{1}{2}$ Let $X = \sum\limits^{100}_{i=1}X_{i}$ , if $40\leq X \leq 60$ then don't reject the null hypothesis $H_{0}$ , otherwise reject the null hypothesis. Obviously, $X \sim Bin(100, p)$ . $\mathbb{P}(40\leq X \leq 60) = \sum\limits^{60}_{x=40} \binom{100}{x}p^{x}(1-p)^{100-x}$ . Type II error is the probability that we can't reject the null hypothesis given that the alternative hypothesis is true. Suppose P is an uniform random variable defined on $(0,\frac{1}{2})\cup(\frac{1}{2}, 1)$ , we have: $\mathbb{P}(40\leq X \leq 60)\\ = \int^{1}_{0}\mathbb{P}(40\leq X \leq 60 | p \in (0,\frac{1}{2})\cup(\frac{1}{2}, 1))f_{P}(p)\, dp\\ = \int^{1}_{0}\mathbb{P}(40\leq X \leq 60 | p \in (0,\frac{1}{2})\cup(\frac{1}{2}, 1))\, dp\\ = \sum\limits^{60}_{x=40} \int^{1}_{0}\binom{100}{x}p^{x}(1-p)^{100-x}\, dp\\ = \sum\limits^{60}_{x=40}\int^{1}_{0}\frac{100!}{x!(100-x)!}p^{x}(1-p)^{100-x}\, dp\\ = \sum\limits^{60}_{x=40}\frac{100!}{101!}\int^{1}_{0}\frac{\Gamma(102)}{\Gamma(x+1)\Gamma(101-x)}p^{x}(1-p)^{100-x}\, dp\\ = \sum\limits^{60}_{x=40}\frac{100!}{101!} = \frac{21}{101}$ What's wrong with my solution?","Suppose there is a coin, we flipped it for 100 times and want to check if it is fair. Let be the outcome of each experiment, which is a series of random variables following i.i.d. Bernoulli distributions with parameter p. For experiment, if we get a head, then , otherwise . Our hypothesis: against Let , if then don't reject the null hypothesis , otherwise reject the null hypothesis. Obviously, . . Type II error is the probability that we can't reject the null hypothesis given that the alternative hypothesis is true. Suppose P is an uniform random variable defined on , we have: What's wrong with my solution?","X_{1}, X_{2}, ..., X_{100} i^{th} X_{i} = 1 X_{i} = 0 H_{0}: p = \frac{1}{2} H_{1}: p \neq \frac{1}{2} X = \sum\limits^{100}_{i=1}X_{i} 40\leq X \leq 60 H_{0} X \sim Bin(100, p) \mathbb{P}(40\leq X \leq 60) = \sum\limits^{60}_{x=40} \binom{100}{x}p^{x}(1-p)^{100-x} (0,\frac{1}{2})\cup(\frac{1}{2}, 1) \mathbb{P}(40\leq X \leq 60)\\
= \int^{1}_{0}\mathbb{P}(40\leq X \leq 60 | p \in (0,\frac{1}{2})\cup(\frac{1}{2}, 1))f_{P}(p)\, dp\\
= \int^{1}_{0}\mathbb{P}(40\leq X \leq 60 | p \in (0,\frac{1}{2})\cup(\frac{1}{2}, 1))\, dp\\
= \sum\limits^{60}_{x=40} \int^{1}_{0}\binom{100}{x}p^{x}(1-p)^{100-x}\, dp\\
= \sum\limits^{60}_{x=40}\int^{1}_{0}\frac{100!}{x!(100-x)!}p^{x}(1-p)^{100-x}\, dp\\
= \sum\limits^{60}_{x=40}\frac{100!}{101!}\int^{1}_{0}\frac{\Gamma(102)}{\Gamma(x+1)\Gamma(101-x)}p^{x}(1-p)^{100-x}\, dp\\
= \sum\limits^{60}_{x=40}\frac{100!}{101!} = \frac{21}{101}","['probability', 'probability-theory', 'statistics', 'probability-distributions', 'hypothesis-testing']"
30,Use of moore-penrose inverse when modeling PCA,Use of moore-penrose inverse when modeling PCA,,"In the derivation for principal component analysis we model our observed data points y as the result of a linear transformation restricted to being an axis change, W , applied to a set of uncorrelated variables x , where x lives in a lower dimensional space than y . Thus, we can represent our observations as y = Wx , and what we are trying to find as x = W'y , where W' is the pseudo-inverse of W . Is the reason we choose to model the mapping of y onto the pca axes with use of a pseudo-inverse due to the fact that we want to be able to use PCA on systems where y doesn't completely follow our assumptions? Where not all points in y are contained in the column space of W ?","In the derivation for principal component analysis we model our observed data points y as the result of a linear transformation restricted to being an axis change, W , applied to a set of uncorrelated variables x , where x lives in a lower dimensional space than y . Thus, we can represent our observations as y = Wx , and what we are trying to find as x = W'y , where W' is the pseudo-inverse of W . Is the reason we choose to model the mapping of y onto the pca axes with use of a pseudo-inverse due to the fact that we want to be able to use PCA on systems where y doesn't completely follow our assumptions? Where not all points in y are contained in the column space of W ?",,"['linear-algebra', 'statistics', 'linear-transformations']"
31,Find total number of bikes in the town,Find total number of bikes in the town,,"In a town, there are 33 families that own either 1, 2, or 3 bikes. The number of families that own 1 bike is equal to the number of families that own 3 bikes. What is the number of the bikes in the town? I know the answer is 66. If you test cases you will see that the number is always 66. FOr example: 15 own 1b, 15 own 3b, 3 own 2b = 66 10 own 1b, 10 own 3b, 13 own 2b = 66 My question is, how do you explain this result in a technical way, taking into consideration the mean?","In a town, there are 33 families that own either 1, 2, or 3 bikes. The number of families that own 1 bike is equal to the number of families that own 3 bikes. What is the number of the bikes in the town? I know the answer is 66. If you test cases you will see that the number is always 66. FOr example: 15 own 1b, 15 own 3b, 3 own 2b = 66 10 own 1b, 10 own 3b, 13 own 2b = 66 My question is, how do you explain this result in a technical way, taking into consideration the mean?",,"['statistics', 'puzzle', 'means']"
32,Upper bound on the expectation of the min max of gaussian random variables,Upper bound on the expectation of the min max of gaussian random variables,,"Define a random $n \times m$ matrix X , where each entry is independent and follows a standard gaussian distribution, i.e., $X_{ij} \sim N(0,1)$ , i.i.d., $\forall$ $i,j$ . My objective is to find an upper bound (as a function of m and n) for $$\mathbb{E}\left[\min_{1 \leq j \leq m} \max_{1 \leq i \leq n}X_{ij} \right ]$$ I know that the expectation of the maximum has an upper bound of order $\sqrt{\log n}$ , and in numerical simulations, I can see that when $m=n$ this expectation diverges to infinity as well, but I am struggling to find a sharp upper bound.","Define a random matrix X , where each entry is independent and follows a standard gaussian distribution, i.e., , i.i.d., . My objective is to find an upper bound (as a function of m and n) for I know that the expectation of the maximum has an upper bound of order , and in numerical simulations, I can see that when this expectation diverges to infinity as well, but I am struggling to find a sharp upper bound.","n \times m X_{ij} \sim N(0,1) \forall i,j \mathbb{E}\left[\min_{1 \leq j \leq m} \max_{1 \leq i \leq n}X_{ij} \right ] \sqrt{\log n} m=n","['probability', 'statistics', 'normal-distribution', 'expected-value', 'order-statistics']"
33,What can we conclude from the property $P(X<Y)=P(X>Y)=0.5$ of two random variables $X$ and $Y$?,What can we conclude from the property  of two random variables  and ?,P(X<Y)=P(X>Y)=0.5 X Y,"This is a similar question to Does the property $P(X<Y)=P(X>Y)=0.5$ imply equal expectations? I have a series of short questions related to: the medians of $X$ and $Y$ , the means, and the fact that $P(X>Y)=P(X<Y)=0.5$ . Let us introduce the following properties: \begin{align*} P_{\mbox{prob}}: \quad P(X>Y)&=P(X<Y)=0.5,\\ P_{\mbox{mean}}: \hspace{0.9cm}\quad E[X]&=E[Y],\\ P_{\mbox{median}}: \quad med[X]&=med[Y]. \end{align*} By the post in Does the property $P(X<Y)=P(X>Y)=0.5$ imply equal expectations? we know that $P_{\mbox{prob}} \nRightarrow P_{\mbox{mean}}$ , and obviously we now that $P_{\mbox{mean}}$ and $P_{\mbox{median}}$ do not imply each other. My questions are: $P_{\mbox{prob}} \Rightarrow P_{\mbox{median}}$ ? $P_{\mbox{mean}} \Rightarrow P_{\mbox{prob}}$ ? $P_{\mbox{median}} \Rightarrow P_{\mbox{prob}}$ ? I am not sure if the continuous and discrete cases differ here. The continuous case is maybe more interesting. I tried $X$ uniformly supported on $[a,b]$ and $Y$ on $[c,d]$ such that $a+b=c+d$ so that means are equal. But then I get $P(X<Y)=P(X>Y)$ which is then not a counterexample for question 2, or 1.","This is a similar question to Does the property $P(X<Y)=P(X>Y)=0.5$ imply equal expectations? I have a series of short questions related to: the medians of and , the means, and the fact that . Let us introduce the following properties: By the post in Does the property $P(X<Y)=P(X>Y)=0.5$ imply equal expectations? we know that , and obviously we now that and do not imply each other. My questions are: ? ? ? I am not sure if the continuous and discrete cases differ here. The continuous case is maybe more interesting. I tried uniformly supported on and on such that so that means are equal. But then I get which is then not a counterexample for question 2, or 1.","X Y P(X>Y)=P(X<Y)=0.5 \begin{align*}
P_{\mbox{prob}}: \quad P(X>Y)&=P(X<Y)=0.5,\\
P_{\mbox{mean}}: \hspace{0.9cm}\quad E[X]&=E[Y],\\
P_{\mbox{median}}: \quad med[X]&=med[Y].
\end{align*} P_{\mbox{prob}} \nRightarrow P_{\mbox{mean}} P_{\mbox{mean}} P_{\mbox{median}} P_{\mbox{prob}} \Rightarrow P_{\mbox{median}} P_{\mbox{mean}} \Rightarrow P_{\mbox{prob}} P_{\mbox{median}} \Rightarrow P_{\mbox{prob}} X [a,b] Y [c,d] a+b=c+d P(X<Y)=P(X>Y)","['probability', 'statistics', 'random-variables', 'expected-value', 'median']"
34,What is a reasonable bound for integrating the standard normal distribution with a single tail?,What is a reasonable bound for integrating the standard normal distribution with a single tail?,,This is a question I'm trying to figure out how to solve because my calculator does not allow me to evaluate improper integrals. I am trying to find the z that produces a small enough p to be negligible. In general I think I will need about 5 digits of accuracy maximum but I would also be interested in the general solution for some natural n. The problem boils down to solving this inequality: Find the least value of $a$ for which: $$\int_a^\infty \frac{\exp(-x^2/2)}{\sqrt{2\pi}} < 10^{-n}$$ Any insights on how I might go about this? This function doesn't even have an elementary antiderivative so this looks like a pretty tricky problem.,This is a question I'm trying to figure out how to solve because my calculator does not allow me to evaluate improper integrals. I am trying to find the z that produces a small enough p to be negligible. In general I think I will need about 5 digits of accuracy maximum but I would also be interested in the general solution for some natural n. The problem boils down to solving this inequality: Find the least value of for which: Any insights on how I might go about this? This function doesn't even have an elementary antiderivative so this looks like a pretty tricky problem.,a \int_a^\infty \frac{\exp(-x^2/2)}{\sqrt{2\pi}} < 10^{-n},['statistics']
35,Difference between EPE and MSE,Difference between EPE and MSE,,"In the book ESL ( Element of Statistical Learning ), the author introduces the EPE ( Expected prediction Error ) and the MSE ( Mean Squared Error ). I know that the EPE is defined as: $$EPE(f)=E(Y-f(X))^2$$ which is the expected value generated on all the different training data set. But what abount the MSE? The author defined the MSE like: $$MSE(x_0) = E_T[f(x_0)-\widehat{y_0})]^2$$ and i really don't get the difference... The question is: basically speaking, what's the difference between EPE and MSE?","In the book ESL ( Element of Statistical Learning ), the author introduces the EPE ( Expected prediction Error ) and the MSE ( Mean Squared Error ). I know that the EPE is defined as: which is the expected value generated on all the different training data set. But what abount the MSE? The author defined the MSE like: and i really don't get the difference... The question is: basically speaking, what's the difference between EPE and MSE?",EPE(f)=E(Y-f(X))^2 MSE(x_0) = E_T[f(x_0)-\widehat{y_0})]^2,"['statistics', 'machine-learning']"
36,What does this $\mathbb 1$ symbol in statistical learning theory mean?,What does this  symbol in statistical learning theory mean?,\mathbb 1,"Searching for something I do not know the name of is hard... Context is Statistical Learning Theory. Probably something basic, I do not remember from my boring statistics university lectures. Without knowing how the symbol is called, I can only provide an image:","Searching for something I do not know the name of is hard... Context is Statistical Learning Theory. Probably something basic, I do not remember from my boring statistics university lectures. Without knowing how the symbol is called, I can only provide an image:",,"['statistics', 'notation']"
37,Differentiation under expectation $f(x)=E[|x-Y|].$,Differentiation under expectation,f(x)=E[|x-Y|].,"Let $Y$ be a random variable with zero points mass which is integrable. Let x be in $[-M,M]$ for some $m\in\mathbb{r}$ . Consider $$f(x)=E[|x-Y|].$$ I want to take the derivative of $f(x)$ in a point $x_0\in(-M,M)$ . Here is my attempt of a solution. Using dominated convergence with majorant $|Y|+|M|$ , and that $Y$ has zero point mass in $x_0$ I obtain that $$f'(x_0)=\lim_{h\rightarrow 0}\frac{f(x_0)-f(x_0+h)}{h}=\lim_{h\rightarrow 0}E[\frac{|x_0-Y|-|x_0+h-Y|}{h}]=\lim_{h\rightarrow 0}E[\frac{|x_0-Y|-|x_0+h-Y|}{h}1_{Y\not=x_0}]=E[\lim_{h\rightarrow 0}\frac{|x_0-Y|-|x_0+h-Y|}{h}]=E[-1_{x_0-Y<0}+1_{x_0-Y>0}]=2P(Y\leq x_0)-1.$$ Is the above argument correct hence in the above setting it is correct that $f'(x_0)=2P(Y\leq x_0)-1$ ? And if it is correct doesn't it also hold in general that $f(x)$ is differentiable on $(-M,M)$ I have tried for $U$ uniform([0,1]) and $x_0\in(0,1)$ where i get $E[|x-U|]=x^2-x+1/2$ which differentiated is $2x-1$ which is equal to $2P(U\leq x)-1$ .","Let be a random variable with zero points mass which is integrable. Let x be in for some . Consider I want to take the derivative of in a point . Here is my attempt of a solution. Using dominated convergence with majorant , and that has zero point mass in I obtain that Is the above argument correct hence in the above setting it is correct that ? And if it is correct doesn't it also hold in general that is differentiable on I have tried for uniform([0,1]) and where i get which differentiated is which is equal to .","Y [-M,M] m\in\mathbb{r} f(x)=E[|x-Y|]. f(x) x_0\in(-M,M) |Y|+|M| Y x_0 f'(x_0)=\lim_{h\rightarrow 0}\frac{f(x_0)-f(x_0+h)}{h}=\lim_{h\rightarrow 0}E[\frac{|x_0-Y|-|x_0+h-Y|}{h}]=\lim_{h\rightarrow 0}E[\frac{|x_0-Y|-|x_0+h-Y|}{h}1_{Y\not=x_0}]=E[\lim_{h\rightarrow 0}\frac{|x_0-Y|-|x_0+h-Y|}{h}]=E[-1_{x_0-Y<0}+1_{x_0-Y>0}]=2P(Y\leq x_0)-1. f'(x_0)=2P(Y\leq x_0)-1 f(x) (-M,M) U x_0\in(0,1) E[|x-U|]=x^2-x+1/2 2x-1 2P(U\leq x)-1","['integration', 'statistics']"
38,Repeated convolution of a pdf of the product of two (independent?) random variables,Repeated convolution of a pdf of the product of two (independent?) random variables,,"Let $p\in \mathbb R$ and $k,n\in \mathbb N$ be fixed constants with $ k << n$ . Let $\bf A$ be a random vector of positive real numbers summing to $p$ , generated as follows: choose $n$ real numbers independently and uniformly between $0$ and $1$ to be the coordinates of $\bf A$ , then normalize so their sum is $p$ . Let $\bf x$ be a random ""mask"" vector of length $n$ , generated as follows. We choose a random subset of $k$ entries of $\bf x$ to be nonzero. Each of the nonzero entries is chosen uniformly in the range $(1,100)$ , independently of each other (and of $\bf A$ ). Question: How can we determine the cumulative distribution function of $\sum_{i=1}^{n} {\bf A}_i{\bf x}_i$ ? Edit: I did a bit of research and found out how to do steps 2 and 3 in the roadmap below ( I plan to do step 3 using Chernoff Bounds to approximate ). Thus, all that is left to do is find the PDF of $A_1$ , but this is really difficult, because I can’t find the point of intersection in order to integrate. Also, even I found the limits of integration, I’m not quite sure how I would take the derivative of such a complex function. I am currently trying to find a solution, but I welcome any input!","Let and be fixed constants with . Let be a random vector of positive real numbers summing to , generated as follows: choose real numbers independently and uniformly between and to be the coordinates of , then normalize so their sum is . Let be a random ""mask"" vector of length , generated as follows. We choose a random subset of entries of to be nonzero. Each of the nonzero entries is chosen uniformly in the range , independently of each other (and of ). Question: How can we determine the cumulative distribution function of ? Edit: I did a bit of research and found out how to do steps 2 and 3 in the roadmap below ( I plan to do step 3 using Chernoff Bounds to approximate ). Thus, all that is left to do is find the PDF of , but this is really difficult, because I can’t find the point of intersection in order to integrate. Also, even I found the limits of integration, I’m not quite sure how I would take the derivative of such a complex function. I am currently trying to find a solution, but I welcome any input!","p\in \mathbb R k,n\in \mathbb N  k << n \bf A p n 0 1 \bf A p \bf x n k \bf x (1,100) \bf A \sum_{i=1}^{n} {\bf A}_i{\bf x}_i A_1","['probability', 'combinatorics', 'statistics', 'convolution']"
39,"Calculate the standard deviation from confidence interval, sample size, and mean, when confidence interval is not symmetric around mean","Calculate the standard deviation from confidence interval, sample size, and mean, when confidence interval is not symmetric around mean",,"I have the following data: 300 customers were asked to participate in a survey, and each customer was able to submit his/her response within the first two weeks. The mean time to respond to the survey was 107 hours. Using this data, a statistician was able to conclude that the mean time to respond to the survey for future customers would be between 96.12 and 120.65 hours. Assuming that this is 95% confidence interval, how can we figure out the type of distribution and the standard deviation from this data? Thanks in advance for your help! PS: I tried to use t-statistic, but realized that the 95% confidence interval (96.12,120.65) is not symmetric by the mean (107). This means that the data is not normally distributed.","I have the following data: 300 customers were asked to participate in a survey, and each customer was able to submit his/her response within the first two weeks. The mean time to respond to the survey was 107 hours. Using this data, a statistician was able to conclude that the mean time to respond to the survey for future customers would be between 96.12 and 120.65 hours. Assuming that this is 95% confidence interval, how can we figure out the type of distribution and the standard deviation from this data? Thanks in advance for your help! PS: I tried to use t-statistic, but realized that the 95% confidence interval (96.12,120.65) is not symmetric by the mean (107). This means that the data is not normally distributed.",,"['statistics', 'statistical-inference', 'means', 'standard-deviation', 'confidence-interval']"
40,"If an event $A$ is independent of the event $B, B\cap C \text{ and } B \cup C.$ Then find $P(A \cap C)$",If an event  is independent of the event  Then find,"A B, B\cap C \text{ and } B \cup C. P(A \cap C)","If an event $A$ is independent of the event $B, B\cap C \text{ and } B  \cup C.$ Then find $P(A \cap C)$ . My attempt List item event $A$ is independent of the event $B.$ $\therefore P(A\cap B)=P(A)\cdot P(B)$ List item event $A$ is independent of the event $B\cap C.$ $\therefore P(A\cap (B \cap C))=P(A)\cdot P(B \cap C)$ List item event $A$ is independent of the event $B\cup C.$ $\therefore P(A\cap (B \cup C))=P(A)\cdot P(B \cup C)$ But I am not able to conclude the expression for $P(A \cap C).$",If an event is independent of the event Then find . My attempt List item event is independent of the event List item event is independent of the event List item event is independent of the event But I am not able to conclude the expression for,"A B, B\cap C \text{ and } B
 \cup C. P(A \cap C) A B. \therefore P(A\cap B)=P(A)\cdot P(B) A B\cap C. \therefore P(A\cap (B \cap C))=P(A)\cdot P(B \cap C) A B\cup C. \therefore P(A\cap (B \cup C))=P(A)\cdot P(B \cup C) P(A \cap C).","['probability', 'statistics', 'independence']"
41,$P(X_1 > X_2 + X_3 + 2)$ for a multivariate normal distribution,for a multivariate normal distribution,P(X_1 > X_2 + X_3 + 2),"I'm doing the next exercise by following the hints of the book but I don't get the final answer: Problem: Let $X=(X_1, X_2, X_3)$ have a multivariate normal distribution with mean vector 0 and variance-covariance matrix: ∑ = $ \begin{pmatrix} 1 & 0 & 0\\ 0 & 2 & 1\\  0 & 1 & 2 \end{pmatrix} $ Find: $P(X_1 > X_2 + X_3 + 2)$ My attempt: Let $Z = X_1 - X_2 - X_3$ . Note that $Z=p*X$ where $p= \begin{pmatrix} 1 & -1 & -1 \end{pmatrix}$ and $x =  \begin{pmatrix} X_1\\ X_2\\X_3 \end{pmatrix} $ Now I do the calculations: $E(Z)=p*E(X)=0$ , given p vector of constants and mean 0 by hypothesis. $Var(Z)=p*Var(X)*p=7$ , with one of the p's like row vector and the other one like column vector. The initial probability can be rewritten like: $P(X_1-X_2-X_3>2)=P(Z>2)$ . Someone told me a property that is like: $P\left(\frac{Z-mean}{\sqrt{var(Z)}}\right)>\frac{2- mean}{\sqrt{var(Z)}}$ but I'm not sure. The book gives a Hint that is: Find a vector a so that $aX= X_1 - X_2 - X_3$ and use the theorem: theorem 1 , but I'm not sure how to use it. Thanks in advance for the help. PD: sorry for not use very well HTML but I'm learning.","I'm doing the next exercise by following the hints of the book but I don't get the final answer: Problem: Let have a multivariate normal distribution with mean vector 0 and variance-covariance matrix: ∑ = Find: My attempt: Let . Note that where and Now I do the calculations: , given p vector of constants and mean 0 by hypothesis. , with one of the p's like row vector and the other one like column vector. The initial probability can be rewritten like: . Someone told me a property that is like: but I'm not sure. The book gives a Hint that is: Find a vector a so that and use the theorem: theorem 1 , but I'm not sure how to use it. Thanks in advance for the help. PD: sorry for not use very well HTML but I'm learning.","X=(X_1, X_2, X_3)  \begin{pmatrix} 1 & 0 & 0\\ 0 & 2 & 1\\  0 & 1 & 2 \end{pmatrix}  P(X_1 > X_2 + X_3 + 2) Z = X_1 - X_2 - X_3 Z=p*X p= \begin{pmatrix} 1 & -1 & -1 \end{pmatrix} x =  \begin{pmatrix} X_1\\ X_2\\X_3 \end{pmatrix}  E(Z)=p*E(X)=0 Var(Z)=p*Var(X)*p=7 P(X_1-X_2-X_3>2)=P(Z>2) P\left(\frac{Z-mean}{\sqrt{var(Z)}}\right)>\frac{2- mean}{\sqrt{var(Z)}} aX= X_1 - X_2 - X_3","['probability', 'probability-theory', 'statistics', 'probability-distributions', 'normal-distribution']"
42,"Given $\mathbb E[f(X^\top u)f(X^\top v)] \equiv h(u^\top v)$ for $X \sim N(0,I)$ and unit-vectors $u,v$, compute $h(1)$ and $h'(0)$ in terms of $f$","Given  for  and unit-vectors , compute  and  in terms of","\mathbb E[f(X^\top u)f(X^\top v)] \equiv h(u^\top v) X \sim N(0,I) u,v h(1) h'(0) f","Let $f:\mathbb R \to \mathbb R$ be a continuous function and define $F:S_{d-1} \times S_{d-1} \to \mathbb R$ by $F(u,v) := \mathbb E[f(X^\top u)f(X^\top v)]$ , where $S_{d-1}$ is the unit-sphere in $\mathbb R^d$ and $X \sim N(0,I_d)$ . Because of rotational invariance of the distribution of $X$ , it is clear that $F(u,v) \equiv h(u^\top v)$ for some continuous function $h:[-1,1] \to \mathbb R$ . Questions: (1) How smooth can the function $h$ be on the open interval $(-1,1)$ , especially around the point $0$ ? (2) In case $h$ is differentiable at $0$ , what is the value of $h'(0)$ in terms of $f$ ? Observation For computing the value of $h(0)$ , one can take any $a,b \in S_{d-1}$ such that $a^\top b = 0$ . Then $X^\top a$ and $X^\top b$ are independent random variables and so $$ h(0) = h(a^\top b) = \mathbb E[f(X^\top a)f(X^\top b)] = \mathbb E[f(X^\top a)]\mathbb E[f(X^\top b)] = \mathbb E[f(X_1)]^2 = \sigma_0(f)^2, $$ where $\sigma_k(f)$ is the $k$ th Hermite coefficient of $f$ , defined by $\sigma_k(f) = \mathbb E_{G \sim N(0,1)}[f(G)\operatorname{He}_k(G)]$ and $\operatorname{He}_k$ is the probabilist's $k$ th Hermite polynomial; in particular, $\mathrm{He}_0(z) = 1$ , $\mathrm{He}_1(z) := z$ , $\mathrm{He}_2(z) := z^2-1$ , $\mathrm{He}_3(z) := z^3-3z^2$ , etc. Similarly, for computing $h(1)$ one can take $a \in S_{d-1}$ and note that $$ h(1)=h(a^\top a) = \mathbb E[f(X^\top a)^2] = \mathbb E[f(X^\top a)^2] = \mathbb E[f(X_1)^2]=\sigma_0(f^2). $$","Let be a continuous function and define by , where is the unit-sphere in and . Because of rotational invariance of the distribution of , it is clear that for some continuous function . Questions: (1) How smooth can the function be on the open interval , especially around the point ? (2) In case is differentiable at , what is the value of in terms of ? Observation For computing the value of , one can take any such that . Then and are independent random variables and so where is the th Hermite coefficient of , defined by and is the probabilist's th Hermite polynomial; in particular, , , , , etc. Similarly, for computing one can take and note that","f:\mathbb R \to \mathbb R F:S_{d-1} \times S_{d-1} \to \mathbb R F(u,v) := \mathbb E[f(X^\top u)f(X^\top v)] S_{d-1} \mathbb R^d X \sim N(0,I_d) X F(u,v) \equiv h(u^\top v) h:[-1,1] \to \mathbb R h (-1,1) 0 h 0 h'(0) f h(0) a,b \in S_{d-1} a^\top b = 0 X^\top a X^\top b 
h(0) = h(a^\top b) = \mathbb E[f(X^\top a)f(X^\top b)] = \mathbb E[f(X^\top a)]\mathbb E[f(X^\top b)] = \mathbb E[f(X_1)]^2 = \sigma_0(f)^2,
 \sigma_k(f) k f \sigma_k(f) = \mathbb E_{G \sim N(0,1)}[f(G)\operatorname{He}_k(G)] \operatorname{He}_k k \mathrm{He}_0(z) = 1 \mathrm{He}_1(z) := z \mathrm{He}_2(z) := z^2-1 \mathrm{He}_3(z) := z^3-3z^2 h(1) a \in S_{d-1} 
h(1)=h(a^\top a) = \mathbb E[f(X^\top a)^2] = \mathbb E[f(X^\top a)^2] = \mathbb E[f(X_1)^2]=\sigma_0(f^2).
","['probability', 'statistics', 'taylor-expansion', 'gaussian-integral', 'hermite-polynomials']"
43,Baysian analysis of the Poisson distribution,Baysian analysis of the Poisson distribution,,"$ D = (x_i )_{i=1:n}$ is the training data, where $x_i$ follows a Poisson distribution of parameter $\lambda$ . The likelihood is $ p(D | \lambda) = \prod_{i=1}^n exp(-\lambda) \lambda^{x_i}/{x_i!} $ We assume that the prior distribution of $\lambda$ is $p(\lambda) = Ga(\lambda|a,b)$ ( gamma distribution ) The goal is to show that the posterior follows a gamma distribution. The demonstration that I found in a textbook is the following : $$ \begin{align} \mathsf p(\lambda|D) &\propto p (\lambda) p(D | \lambda) \\  &\propto  exp(-\lambda(b+n)) * \lambda^{a-1 + \sum x_i} \end{align} $$ and to conclude that $ p(\lambda|D) = Ga(a + \sum x_i, b+n )$ I don't understand how you can so easily ignore the constant term of the gamma distribution ( by that I mean $ \beta^\alpha / \Gamma (\alpha) $ ). Why is it only necessary to show that the distribution is proportional to these two terms to conclude that it's a gamma distribution ?","is the training data, where follows a Poisson distribution of parameter . The likelihood is We assume that the prior distribution of is ( gamma distribution ) The goal is to show that the posterior follows a gamma distribution. The demonstration that I found in a textbook is the following : and to conclude that I don't understand how you can so easily ignore the constant term of the gamma distribution ( by that I mean ). Why is it only necessary to show that the distribution is proportional to these two terms to conclude that it's a gamma distribution ?"," D = (x_i )_{i=1:n} x_i \lambda  p(D | \lambda) = \prod_{i=1}^n exp(-\lambda) \lambda^{x_i}/{x_i!}  \lambda p(\lambda) = Ga(\lambda|a,b) 
\begin{align}
\mathsf p(\lambda|D) &\propto p (\lambda) p(D | \lambda) \\
 &\propto  exp(-\lambda(b+n)) * \lambda^{a-1 + \sum x_i}
\end{align}
  p(\lambda|D) = Ga(a + \sum x_i, b+n )  \beta^\alpha / \Gamma (\alpha) ","['statistics', 'statistical-inference', 'bayesian', 'gamma-distribution']"
44,What does continuity of probability even mean intuitively?,What does continuity of probability even mean intuitively?,,"I'm reading ""All of Statistics A Concise Course in Statistical Inference"" by Larry Wassermann, and I came across a proof for continuity of probability like this : $\text{Theorem (1.8)(Continuity of Probabilities)}$ If $A_{n} \rightarrow A$ then $$ \lim_{n \rightarrow \infty} \big( \mathcal{P}(A_{n}) \big) \rightarrow \mathcal{P}(A)$$ Suppose that $A_{n}$ is monotone increasing so that $A_{1} \subset A_{2} \subset $ Then let $A = \lim_{n \rightarrow \infty} A_{n} = \bigcup_{i=1}^{\infty} A_{i}.$ Define $B_{1} = A_{1}$ ,and also define the set $B_{2} = \big\{ \omega \in \Omega: \omega \in A_{2} , \omega \notin A_{1}\big\} $ $B_{3} = \big\{ \omega \in \Omega: \, \omega \in A_{3}, \omega \notin A_{2}, \omega \notin A_{1} \big\}, ... $ It can be shown that $B_{1}$ , $B_{2}$ , … are disjoint, $A_{n} = \bigcup_{i=1}^{n}A_{i} = \bigcup_{i=1}^{n}B_{i}$ for each $n$ and $\bigcup_{i=1}^{\infty}B_{i} = \bigcup_{i=1}^{\infty} A_{i}$ $\big( \text{Exercise (1)} \big)$ From Axiom $(3)$ , one can say that $$\mathcal{P(A_{n})} = \mathcal{P} \bigg( \bigcup_{i = 1}^{n} B_{i} \bigg) = \sum_{i = 1} \mathcal{P}(B_{i}) $$ Using axiom $(3)$ again, $$\lim_{n \rightarrow \infty} \mathcal{P}(A_{n}) = \lim_{n \rightarrow \infty} \sum_{i = 1}^{n} \mathcal{P}(B_{i}) = \sum_{i = 1}^{ \infty} \mathcal{P}(B_{i}) = \mathcal{P} \bigg( \bigcup_{i=1}^{\infty} B_{i} \bigg) = \mathcal{P}(A).$$ So here I understand how the proof goes, as in various steps in the proof, but I don't get why and what are we trying to prove. Since I don't have a background in pure mathematics and measure theory and I'm having a hard time wrapping my head around this. I don't get what exactly are we trying to prove here : let's say $A_{n}$ is an event so are we trying to prove that as the event grows to infinity(since A is monotonically increasing) the probability of that event approaches the probability of sample space, which is essentially equal to $1$ ? What does this intuitively mean, or what kind of pre-requisites do I need for understand this text? EDIT : I would also appreciate if someone can point out some other text books which would help me understand these things better as someone with little knowledge in pure math.","I'm reading ""All of Statistics A Concise Course in Statistical Inference"" by Larry Wassermann, and I came across a proof for continuity of probability like this : If then Suppose that is monotone increasing so that Then let Define ,and also define the set It can be shown that , , … are disjoint, for each and From Axiom , one can say that Using axiom again, So here I understand how the proof goes, as in various steps in the proof, but I don't get why and what are we trying to prove. Since I don't have a background in pure mathematics and measure theory and I'm having a hard time wrapping my head around this. I don't get what exactly are we trying to prove here : let's say is an event so are we trying to prove that as the event grows to infinity(since A is monotonically increasing) the probability of that event approaches the probability of sample space, which is essentially equal to ? What does this intuitively mean, or what kind of pre-requisites do I need for understand this text? EDIT : I would also appreciate if someone can point out some other text books which would help me understand these things better as someone with little knowledge in pure math.","\text{Theorem (1.8)(Continuity of Probabilities)} A_{n} \rightarrow A  \lim_{n \rightarrow \infty} \big( \mathcal{P}(A_{n}) \big) \rightarrow \mathcal{P}(A) A_{n} A_{1} \subset A_{2} \subset  A = \lim_{n \rightarrow \infty} A_{n} = \bigcup_{i=1}^{\infty} A_{i}. B_{1} = A_{1} B_{2} = \big\{ \omega \in \Omega: \omega \in A_{2} , \omega \notin A_{1}\big\}  B_{3} = \big\{ \omega \in \Omega: \, \omega \in A_{3}, \omega \notin A_{2}, \omega \notin A_{1} \big\}, ...  B_{1} B_{2} A_{n} = \bigcup_{i=1}^{n}A_{i} = \bigcup_{i=1}^{n}B_{i} n \bigcup_{i=1}^{\infty}B_{i} = \bigcup_{i=1}^{\infty} A_{i} \big( \text{Exercise (1)} \big) (3) \mathcal{P(A_{n})} = \mathcal{P} \bigg( \bigcup_{i = 1}^{n} B_{i} \bigg) = \sum_{i = 1} \mathcal{P}(B_{i})  (3) \lim_{n \rightarrow \infty} \mathcal{P}(A_{n}) = \lim_{n \rightarrow \infty} \sum_{i = 1}^{n} \mathcal{P}(B_{i}) = \sum_{i = 1}^{ \infty} \mathcal{P}(B_{i}) = \mathcal{P} \bigg( \bigcup_{i=1}^{\infty} B_{i} \bigg) = \mathcal{P}(A). A_{n} 1","['probability', 'measure-theory', 'statistics', 'continuity']"
45,Linearity of Variance and Expected value,Linearity of Variance and Expected value,,"I know Expected value has the property of linearity $E(X+a)=E(X) + a$ , but it also seems to hold for $E(X^3+a)$ . But Variance also has the property $V(X+a)=V(X) + 0$ , but it does not hold for $V(X^3+a)=V(X^3) + 0$ . I discovered this from a question that asked to find the expected value adn variance for $Y = X^3 + 2$ given a distribution for $X$ . $$\begin{array}{|r|r|r|r|r|}\hline x&-1&0&1&2\\\hline p(x)&0.1&0.4&0.3&0.2\\\hline\end{array}$$ The table shows the distribution for $X$ , so I worked out $E(Y) = E(X^3 - 2) = 1.8 - 2 =-0.2$ . For variance I am thinking $V(Y) = V(X^3 - 2) = E(X^{3\times2}) - E(X^3)^2 - 0 =E(X^6)-0.2^2$ from which I get 11.16","I know Expected value has the property of linearity , but it also seems to hold for . But Variance also has the property , but it does not hold for . I discovered this from a question that asked to find the expected value adn variance for given a distribution for . The table shows the distribution for , so I worked out . For variance I am thinking from which I get 11.16",E(X+a)=E(X) + a E(X^3+a) V(X+a)=V(X) + 0 V(X^3+a)=V(X^3) + 0 Y = X^3 + 2 X \begin{array}{|r|r|r|r|r|}\hline x&-1&0&1&2\\\hline p(x)&0.1&0.4&0.3&0.2\\\hline\end{array} X E(Y) = E(X^3 - 2) = 1.8 - 2 =-0.2 V(Y) = V(X^3 - 2) = E(X^{3\times2}) - E(X^3)^2 - 0 =E(X^6)-0.2^2,"['statistics', 'expected-value', 'variance']"
46,Why does $E(E(Y-\gamma^TX|A)^2) = E[A(A^TA)^{-1}A^T(Y-\gamma^TX)^2]$,Why does,E(E(Y-\gamma^TX|A)^2) = E[A(A^TA)^{-1}A^T(Y-\gamma^TX)^2],"I am reading this paper , and in equation (7) on page 9, it's written that $$E(E(Y-\gamma^TX|A)^2) = E[P_A(Y-\gamma^TX)^2]$$ where $Y, X, A$ are random, $\gamma$ is fixed, $P_A$ is the linear $L_2$ projection onto the column space spanned by $A$ . I think $P_A = A(A^TA)^{-1}A^T$ . However, I'm still not quite sure why $$E(E(Y-\gamma^TX|A)^2) = E[A(A^TA)^{-1}A^T(Y-\gamma^TX)^2].$$","I am reading this paper , and in equation (7) on page 9, it's written that where are random, is fixed, is the linear projection onto the column space spanned by . I think . However, I'm still not quite sure why","E(E(Y-\gamma^TX|A)^2) = E[P_A(Y-\gamma^TX)^2] Y, X, A \gamma P_A L_2 A P_A = A(A^TA)^{-1}A^T E(E(Y-\gamma^TX|A)^2) = E[A(A^TA)^{-1}A^T(Y-\gamma^TX)^2].","['probability', 'statistics', 'expected-value', 'self-learning', 'conditional-expectation']"
47,Question About Central Limit Theorem,Question About Central Limit Theorem,,"When I google the central limit theorem it says the following: The central limit theorem states that if you have a population with mean $μ$ and standard deviation $σ$ and take sufficiently large random samples from the population with replacement, then the distribution of the sample means will be approximately normally distributed. My question is the following: does the central limit theorem only apply to sampling distributions of the sample mean? Or can it apply to any sampling distribution of any statistic? Such as sample variance, sample proportion, or difference between two sample means, etc.. Thank You For Your Time","When I google the central limit theorem it says the following: The central limit theorem states that if you have a population with mean and standard deviation and take sufficiently large random samples from the population with replacement, then the distribution of the sample means will be approximately normally distributed. My question is the following: does the central limit theorem only apply to sampling distributions of the sample mean? Or can it apply to any sampling distribution of any statistic? Such as sample variance, sample proportion, or difference between two sample means, etc.. Thank You For Your Time",μ σ,"['probability', 'statistics', 'central-limit-theorem']"
48,Method of Moments estimation,Method of Moments estimation,,"I am sorry in advance if this question seems like low effort, but I really do not know how to solve this problem. My understanding of method of moments estimation is bad. Here is the definition of method of moments estimation in my book: Let $\{X_1,X_2,...,X_n\}$ be a random sample from a population $F(x;\theta)$ . Suppose $\theta$ has $p$ components (for example, for a normal popoulation $N(\mu, \sigma^2),p=2$ ; for Poisson population with parameter $\lambda$ , $p=1$ ). Let $$\mu_k=\mu_k(\theta)=E(X^k)$$ denote the kth population moment, for k=1,2,... Therefore, $\mu_k$ depends on the unknown parapemter $\theta$ , as everything else about the distribution $F(x;\theta)$ is known. Denote the $k$ th sample moment by: $$M_k=\frac{1}{n}\sum^n_{i=1}X_i^k=\frac{X_1^k+X_2^k+...+X_n^k}{n}.$$ The MM estimator (MME) $\hat{\theta}$ of $\theta$ is the solution of the $p$ equations $$\mu_k(\hat{\theta})=M_k \text{ for } k=1,2,...,p$$ So my problem I am struggling to solve is the following: An economist decides to model the distribution of income in a  country with the probability density function: $$f_x(x;\alpha,k)=\frac{\alpha k^{\alpha}}{x^{\alpha+1}} \text{ for } x\geq k$$ and $0$ otherwise, where $k>0$ and $\alpha >2$ . Let $\{X_1,X_2,...,X_n\}$ be a random sample of size $n$ from this distribution. You may use the fact that: $$E(X)=\frac{\alpha k}{\alpha-1} \text{ and } E(X^2)=\frac{\alpha k^2}{\alpha-2}$$ Show that the method of moments estimators of $\alpha$ and $k$ are the solutions of: $$\frac{1}{\hat{\alpha}(\hat{\alpha}-2)}=\left(\frac{n-1}{n}\right)\frac{S^2}{\overline{X}^2} \text{ and } \hat{k}=\frac{(\hat{\alpha}-1)\overline{X}}{\hat{\alpha}}$$ where: $$\overline{X}=\frac{1}{n}\sum^n_{i=1}X_i\text{ and } S^2=\frac{1}{n-1}\sum^n_{i=1}(X_i-\overline{X})^2$$ My attempt to solve this: We have that $\mu_1(\alpha,k)=\frac{\alpha k}{\alpha-1}$ , $\mu_2(\alpha,k)=\frac{\alpha k^2}{\alpha - 2}$ So we have to solve the following equations: $$\mu_1(\alpha,k)=M_1 \text{ and } \mu_2(\alpha,k)=M_2$$ We have that $$\mu_1(\alpha,k)=M_1\Rightarrow \frac{\alpha k }{\alpha-1}=\overline{X}$$ Now, $$\mu_2(\alpha,k)=\frac{1}{n}\sum^n_{i=1}X^2_i\Rightarrow \frac{\alpha k^2}{\alpha-2}=\frac{1}{n}\sum^n_{i=1}X^2_i$$ So from the first equation we have that $$\frac{\alpha k}{\overline{X}}-1=\alpha-2$$ Plugging $\alpha-2$ into the first equation we get $$\frac{\alpha k^2}{\frac{\alpha k}{\overline{X}}}=\frac{1}{n}\sum^n_{i=1}X^2_i\Leftrightarrow k\overline{X}=\frac{1}{n}\sum^n_{i=1}X^2_i\Leftrightarrow \hat{k}=\frac{1}{\overline{X}}\sum^n_{i=1}X^2_i$$ Now I'd like to find $\hat{\alpha}$ . So for $k$ we plug in $\hat{k}$ (in equation $\mu_1(\alpha,k)=M_2$ ): $$\frac{\alpha k}{\alpha -1}=\overline{X}\Leftrightarrow \frac{alpha\frac{1}{n\overline{X}}\sum^n_{i=1}X^2_i}{\alpha-1}=\overline{X}\Leftrightarrow \frac{alpha \sum X^2_i}{n\overline{X}(\alpha-1)}=\overline{X}\Leftrightarrow \alpha = \frac{(\alpha-1)n\overline{X}^2}{\sum X_i^2}\text{ this is equation (1) }$$ Now we plug in $\hat{k}$ in the equation $\mu_2(\alpha,k)=M_2$ : $$\frac{\alpha k^2}{\alpha-2}=\sum X_i^2\Leftrightarrow \frac{\alpha\frac{1}{\left(n\overline{X}\right)^2}\left(\sum X^2_i\right)^2}{\alpha-2}=\sum X^2_i \Leftrightarrow \alpha = \frac{\left(n\overline{X}\right)^2(\alpha-2)}{\sum X^2_i} \text{ this is equation (2) for alpha }$$ Equating the 2 equations of $\alpha$ and solving for $\alpha$ : $$\frac{\left(n\overline{X}\right)^2(\alpha-2)}{\sum X_i^2}=\frac{(\alpha-1)n \overline{X}^2}{\sum X^2_i}$$ $$\Leftrightarrow (\left(n\overline{X}\right)^2(\alpha-2)=n\overline{X}^2(\alpha-1)\Leftrightarrow $$ $$\alpha\left(\left(n\overline{X}\right)^2-n\overline{X}^2\right)=2(n\overline{X}^2-n\overline{X}^2\Leftrightarrow \hat{\alpha}=\frac{2n-1}{n-1}$$ Well now that I have these, I don't know how they are the solutions of $$\frac{1}{\hat{\alpha}(\hat{\alpha}-2)}=\left(\frac{n-1}{n}\right)\frac{S^2}{\overline{X}^2} \text{ and } \hat{k}=\frac{(\hat{\alpha}-1)\overline{X}}{\hat{\alpha}}$$ Did I solve for the estimators correctly? How do I go on from here?","I am sorry in advance if this question seems like low effort, but I really do not know how to solve this problem. My understanding of method of moments estimation is bad. Here is the definition of method of moments estimation in my book: Let be a random sample from a population . Suppose has components (for example, for a normal popoulation ; for Poisson population with parameter , ). Let denote the kth population moment, for k=1,2,... Therefore, depends on the unknown parapemter , as everything else about the distribution is known. Denote the th sample moment by: The MM estimator (MME) of is the solution of the equations So my problem I am struggling to solve is the following: An economist decides to model the distribution of income in a  country with the probability density function: and otherwise, where and . Let be a random sample of size from this distribution. You may use the fact that: Show that the method of moments estimators of and are the solutions of: where: My attempt to solve this: We have that , So we have to solve the following equations: We have that Now, So from the first equation we have that Plugging into the first equation we get Now I'd like to find . So for we plug in (in equation ): Now we plug in in the equation : Equating the 2 equations of and solving for : Well now that I have these, I don't know how they are the solutions of Did I solve for the estimators correctly? How do I go on from here?","\{X_1,X_2,...,X_n\} F(x;\theta) \theta p N(\mu, \sigma^2),p=2 \lambda p=1 \mu_k=\mu_k(\theta)=E(X^k) \mu_k \theta F(x;\theta) k M_k=\frac{1}{n}\sum^n_{i=1}X_i^k=\frac{X_1^k+X_2^k+...+X_n^k}{n}. \hat{\theta} \theta p \mu_k(\hat{\theta})=M_k \text{ for } k=1,2,...,p f_x(x;\alpha,k)=\frac{\alpha k^{\alpha}}{x^{\alpha+1}} \text{ for } x\geq k 0 k>0 \alpha >2 \{X_1,X_2,...,X_n\} n E(X)=\frac{\alpha k}{\alpha-1} \text{ and } E(X^2)=\frac{\alpha k^2}{\alpha-2} \alpha k \frac{1}{\hat{\alpha}(\hat{\alpha}-2)}=\left(\frac{n-1}{n}\right)\frac{S^2}{\overline{X}^2} \text{ and } \hat{k}=\frac{(\hat{\alpha}-1)\overline{X}}{\hat{\alpha}} \overline{X}=\frac{1}{n}\sum^n_{i=1}X_i\text{ and } S^2=\frac{1}{n-1}\sum^n_{i=1}(X_i-\overline{X})^2 \mu_1(\alpha,k)=\frac{\alpha k}{\alpha-1} \mu_2(\alpha,k)=\frac{\alpha k^2}{\alpha - 2} \mu_1(\alpha,k)=M_1 \text{ and } \mu_2(\alpha,k)=M_2 \mu_1(\alpha,k)=M_1\Rightarrow \frac{\alpha k }{\alpha-1}=\overline{X} \mu_2(\alpha,k)=\frac{1}{n}\sum^n_{i=1}X^2_i\Rightarrow \frac{\alpha k^2}{\alpha-2}=\frac{1}{n}\sum^n_{i=1}X^2_i \frac{\alpha k}{\overline{X}}-1=\alpha-2 \alpha-2 \frac{\alpha k^2}{\frac{\alpha k}{\overline{X}}}=\frac{1}{n}\sum^n_{i=1}X^2_i\Leftrightarrow k\overline{X}=\frac{1}{n}\sum^n_{i=1}X^2_i\Leftrightarrow \hat{k}=\frac{1}{\overline{X}}\sum^n_{i=1}X^2_i \hat{\alpha} k \hat{k} \mu_1(\alpha,k)=M_2 \frac{\alpha k}{\alpha -1}=\overline{X}\Leftrightarrow \frac{alpha\frac{1}{n\overline{X}}\sum^n_{i=1}X^2_i}{\alpha-1}=\overline{X}\Leftrightarrow \frac{alpha \sum X^2_i}{n\overline{X}(\alpha-1)}=\overline{X}\Leftrightarrow \alpha = \frac{(\alpha-1)n\overline{X}^2}{\sum X_i^2}\text{ this is equation (1) } \hat{k} \mu_2(\alpha,k)=M_2 \frac{\alpha k^2}{\alpha-2}=\sum X_i^2\Leftrightarrow \frac{\alpha\frac{1}{\left(n\overline{X}\right)^2}\left(\sum X^2_i\right)^2}{\alpha-2}=\sum X^2_i \Leftrightarrow \alpha = \frac{\left(n\overline{X}\right)^2(\alpha-2)}{\sum X^2_i} \text{ this is equation (2) for alpha } \alpha \alpha \frac{\left(n\overline{X}\right)^2(\alpha-2)}{\sum X_i^2}=\frac{(\alpha-1)n \overline{X}^2}{\sum X^2_i} \Leftrightarrow (\left(n\overline{X}\right)^2(\alpha-2)=n\overline{X}^2(\alpha-1)\Leftrightarrow  \alpha\left(\left(n\overline{X}\right)^2-n\overline{X}^2\right)=2(n\overline{X}^2-n\overline{X}^2\Leftrightarrow \hat{\alpha}=\frac{2n-1}{n-1} \frac{1}{\hat{\alpha}(\hat{\alpha}-2)}=\left(\frac{n-1}{n}\right)\frac{S^2}{\overline{X}^2} \text{ and } \hat{k}=\frac{(\hat{\alpha}-1)\overline{X}}{\hat{\alpha}}","['probability', 'statistics']"
49,"A simpler way to minimize the mean of squares, given the mean?","A simpler way to minimize the mean of squares, given the mean?",,"Suppose I have $N$ real numbers and I already know their mean, $\bar{x}$ : $$ \bar{x}=\frac{1}{N}\sum_{i=1}^{N}x_i $$ (but I don't know the individual values $x_1,x_2,\dots,x_N)$ . I want to find the smallest possible value of the mean of the squares, $y$ : $$ y=\frac{1}{N}\sum_{i=1}^{N}x_i^2 $$ I thought a bit about the case where $N=2$ and it seemed like the answer should be $x_1=x_2=\bar{x}$ . For example, if $\bar{x}=5$ , then $5^2+5^2=50$ , but $4^2+6^2=52$ and $3^2+7^2=58$ , and so on. I feel like this should be a very simple thing to prove for any $N$ , but I had to dig into the back of an old (engineering) textbook to recall the method of Lagrange multipliers... which (unless I made a mistake) indeed gave me the answer $x_1=x_2=x_3=\dots=x_N=\bar{x}$ . Or, using the vector notation of the textbook: $\underline{x}=\bar{x}\underline{1}$ . I wrote my calculations below, just in case this result is wrong. My question is : Is there a ""simpler"" way to prove this result (e.g. using basic high school mathematics)? Is it over-complicated to view this as a constrained optimization problem? Many thanks for any help. My Calculations: Function to minimize (subject to constraint): $$f(\underline{x})=\frac{1}{N}\underline{1}^T\underline{x}^2$$ Constraint: $$c(\underline{x})=\frac{1}{N}\underline{1}^T\underline{x}-\bar{x}=0$$ Unconstrained function to minimize: $$h(\underline{x})=f(\underline{x})+\lambda c(\underline{x})$$ Minimize to get $\lambda$ : $$\frac{\partial f}{\partial \underline{x}} + \frac{\partial}{\partial \underline{x}}\left( \lambda c(\underline{x}) \right) = \underline{0}$$ $$\frac{2}{N}\underline{x} + \frac{\lambda}{N}\underline{1} = \underline{0}$$ $$\frac{2}{N}\underline{1}^T\underline{x} + \frac{\lambda}{N}\underline{1}^T\underline{1} = 0$$ $$\lambda = -2\bar{x}$$ Substitute $\lambda$ back in to solve for $x$ : $$\frac{2}{N}\underline{x} = \frac{2\bar{x}}{N}\underline{1}$$ $$\underline{x} = \bar{x}\underline{1}$$","Suppose I have real numbers and I already know their mean, : (but I don't know the individual values . I want to find the smallest possible value of the mean of the squares, : I thought a bit about the case where and it seemed like the answer should be . For example, if , then , but and , and so on. I feel like this should be a very simple thing to prove for any , but I had to dig into the back of an old (engineering) textbook to recall the method of Lagrange multipliers... which (unless I made a mistake) indeed gave me the answer . Or, using the vector notation of the textbook: . I wrote my calculations below, just in case this result is wrong. My question is : Is there a ""simpler"" way to prove this result (e.g. using basic high school mathematics)? Is it over-complicated to view this as a constrained optimization problem? Many thanks for any help. My Calculations: Function to minimize (subject to constraint): Constraint: Unconstrained function to minimize: Minimize to get : Substitute back in to solve for :","N \bar{x} 
\bar{x}=\frac{1}{N}\sum_{i=1}^{N}x_i
 x_1,x_2,\dots,x_N) y 
y=\frac{1}{N}\sum_{i=1}^{N}x_i^2
 N=2 x_1=x_2=\bar{x} \bar{x}=5 5^2+5^2=50 4^2+6^2=52 3^2+7^2=58 N x_1=x_2=x_3=\dots=x_N=\bar{x} \underline{x}=\bar{x}\underline{1} f(\underline{x})=\frac{1}{N}\underline{1}^T\underline{x}^2 c(\underline{x})=\frac{1}{N}\underline{1}^T\underline{x}-\bar{x}=0 h(\underline{x})=f(\underline{x})+\lambda c(\underline{x}) \lambda \frac{\partial f}{\partial \underline{x}} + \frac{\partial}{\partial \underline{x}}\left( \lambda c(\underline{x}) \right) = \underline{0} \frac{2}{N}\underline{x} + \frac{\lambda}{N}\underline{1} = \underline{0} \frac{2}{N}\underline{1}^T\underline{x} + \frac{\lambda}{N}\underline{1}^T\underline{1} = 0 \lambda = -2\bar{x} \lambda x \frac{2}{N}\underline{x} = \frac{2\bar{x}}{N}\underline{1} \underline{x} = \bar{x}\underline{1}","['calculus', 'statistics', 'optimization', 'lagrange-multiplier']"
50,How to perform Gibbs sampling for this distribution?,How to perform Gibbs sampling for this distribution?,,"I tried to sample this equation by Gibbs sampling. $ P\{X=i,y \le Y \le y+dy,N=n\}\propto C^n_iy^{i+\alpha-1}(1-y)^{n-i+\beta-1}e^{-\lambda}\frac{\lambda^n}{n!}dy $ I know I should generate X given $(y,n)$ , Y given $(x,n)$ and N given $(x,y)$ step by step. But I don't know how to generate them because I don't know the $\lambda$ and what $dy$ does mean. Please help me!!","I tried to sample this equation by Gibbs sampling. I know I should generate X given , Y given and N given step by step. But I don't know how to generate them because I don't know the and what does mean. Please help me!!","
P\{X=i,y \le Y \le y+dy,N=n\}\propto C^n_iy^{i+\alpha-1}(1-y)^{n-i+\beta-1}e^{-\lambda}\frac{\lambda^n}{n!}dy
 (y,n) (x,n) (x,y) \lambda dy","['probability', 'statistics', 'algorithms', 'computational-mathematics', 'sampling']"
51,Variance of a shifted exponential,Variance of a shifted exponential,,"I am having trouble finding the variance of this distribution. the mean is 2 $\lambda$ , but the variance is $\lambda^2$ ? In the solution, they say $\operatorname{Var}(\bar Y) =\lambda^2 $ , I'm really puzzled... Shifting a distribution will not really cause its variance to change right? Really appreciate any help! Thanks","I am having trouble finding the variance of this distribution. the mean is 2 , but the variance is ? In the solution, they say , I'm really puzzled... Shifting a distribution will not really cause its variance to change right? Really appreciate any help! Thanks",\lambda \lambda^2 \operatorname{Var}(\bar Y) =\lambda^2 ,"['statistics', 'probability-distributions', 'variance']"
52,Definition of Ergodicity in Theodoridis' Machine Learning,Definition of Ergodicity in Theodoridis' Machine Learning,,"This is related, but is not the same as https://stats.stackexchange.com/questions/319190/wide-sense-stationary-but-not-ergodic . Note that I am not assuming stationarity. Theodoridis, in his Machine Learning (2nd ed., p. 44), states the following: Definition 2.3 ( Ergodicity ). A stochastic process is said to be ergodic if the complete statistics can be determined by any one of the realizations. Theodoridis then goes on to state that ergodicity implies stationarity with a vague explanation that I can't seem to parse through: In other words, if a process is ergodic, every single realization carries identical statistical information and it can describe the entire random process. Since from a single sequence only one set of PDFs [probability density functions] can be obtained, we conclude that every ergodic process is necessarily stationary . What does ergodicity mean in this situation? In particular, the ""complete statistics"" phrase is throwing me off. I get the feeling that Theodoridis isn't referring to the $$\text{""}\mathbb{E}[g(T) \mid \theta] = 0 \implies \mathbb{P}(g(T) = 0 \mid \theta) = 1$$ for all $\theta$ "" definition of a complete statistic $T$ for $\theta$ . I recently completed a measure-theoretic probability sequence, so if this requires measure-theoretic probability tools to make precise, please use those tools in answering this question. Some searching talks about how a ""time-average is equal to the ensemble average,"" but I'm not really understanding this explanation and how it relates to the definition in Theodoridis' text. Sources that I can use to supplement this with a more detailed coverage of the theory would be appreciated as well. Hamilton's Time Series Analysis (as well as most of my other texts and most coverage I find online on this topic) only covers ergodicity with the assumption that we have stationarity to begin with. Robert and Casella's Monte Carlo Statistical Methods only discuss ergodicity in the context of Markov chains.","This is related, but is not the same as https://stats.stackexchange.com/questions/319190/wide-sense-stationary-but-not-ergodic . Note that I am not assuming stationarity. Theodoridis, in his Machine Learning (2nd ed., p. 44), states the following: Definition 2.3 ( Ergodicity ). A stochastic process is said to be ergodic if the complete statistics can be determined by any one of the realizations. Theodoridis then goes on to state that ergodicity implies stationarity with a vague explanation that I can't seem to parse through: In other words, if a process is ergodic, every single realization carries identical statistical information and it can describe the entire random process. Since from a single sequence only one set of PDFs [probability density functions] can be obtained, we conclude that every ergodic process is necessarily stationary . What does ergodicity mean in this situation? In particular, the ""complete statistics"" phrase is throwing me off. I get the feeling that Theodoridis isn't referring to the for all "" definition of a complete statistic for . I recently completed a measure-theoretic probability sequence, so if this requires measure-theoretic probability tools to make precise, please use those tools in answering this question. Some searching talks about how a ""time-average is equal to the ensemble average,"" but I'm not really understanding this explanation and how it relates to the definition in Theodoridis' text. Sources that I can use to supplement this with a more detailed coverage of the theory would be appreciated as well. Hamilton's Time Series Analysis (as well as most of my other texts and most coverage I find online on this topic) only covers ergodicity with the assumption that we have stationarity to begin with. Robert and Casella's Monte Carlo Statistical Methods only discuss ergodicity in the context of Markov chains.","\text{""}\mathbb{E}[g(T) \mid \theta] = 0 \implies \mathbb{P}(g(T) = 0 \mid \theta) = 1 \theta T \theta","['probability', 'statistics', 'stochastic-processes', 'machine-learning', 'ergodic-theory']"
53,"Let $X_1, ... , X_5$ be a random sample from $p(x;\theta)=(1-\theta)^{x-1}\theta$. Find the UMPT size $\alpha = 0.1$.",Let  be a random sample from . Find the UMPT size .,"X_1, ... , X_5 p(x;\theta)=(1-\theta)^{x-1}\theta \alpha = 0.1","Let $X_1, \ldots , X_5$ be a random sample from $p(x;\theta)=(1-\theta)^{x-1} \theta$ , for $x=1,2,3,\ldots$ . Consider $H_0:\theta \geq 0.7\text{ vs. } H_1:\theta<0.7$ . Find the UMPT size $\alpha = 0.1$ . My try: let $$H_0^{'}:\theta_0 = 0.7\text{ vs. } H_1^{'}:\theta=\theta_1 \quad(\theta_1<0.7)$$ Now, using the NP Lemma $$\frac{L(\theta_1)}{L(\theta_0)} = \frac{(1-\theta_0)\theta_1^n(1-\theta_1)^{\sum ^5_{i=1}x_i}}{(1-\theta_1)\theta_0^n(1-\theta_0)^{\sum ^5_{i=1}x_i}}\geq k$$ Then I end up with $$\sum ^5_{i=1}x_i\geq c$$ Then $$\Psi^*(x)= \begin{cases} 1&\sum ^5_{i=1}x_i\geq c\\ 0&\sum ^5_{i=1}x_i< c. \end{cases}$$ In order to find alpha, I need to know the probability distribution of $\sum ^5_{i=1}x_i$ but I'm not sure how to do this or if my method is correct. Any suggestions would be great!","Let be a random sample from , for . Consider . Find the UMPT size . My try: let Now, using the NP Lemma Then I end up with Then In order to find alpha, I need to know the probability distribution of but I'm not sure how to do this or if my method is correct. Any suggestions would be great!","X_1, \ldots , X_5 p(x;\theta)=(1-\theta)^{x-1} \theta x=1,2,3,\ldots H_0:\theta \geq 0.7\text{ vs. } H_1:\theta<0.7 \alpha = 0.1 H_0^{'}:\theta_0 = 0.7\text{ vs. } H_1^{'}:\theta=\theta_1 \quad(\theta_1<0.7) \frac{L(\theta_1)}{L(\theta_0)} = \frac{(1-\theta_0)\theta_1^n(1-\theta_1)^{\sum ^5_{i=1}x_i}}{(1-\theta_1)\theta_0^n(1-\theta_0)^{\sum ^5_{i=1}x_i}}\geq k \sum ^5_{i=1}x_i\geq c \Psi^*(x)=
\begin{cases}
1&\sum ^5_{i=1}x_i\geq c\\
0&\sum ^5_{i=1}x_i< c.
\end{cases} \sum ^5_{i=1}x_i","['probability', 'statistics', 'probability-distributions']"
54,Gamma-like distribution integral,Gamma-like distribution integral,,"Here I have an integral which is similar to gamma distribution, $$ \int_{0}^{\infty} \frac{e^{-\lambda x} \lambda^n x}{(n-1)!}dx $$ and how to compute its integral?","Here I have an integral which is similar to gamma distribution, and how to compute its integral?","
\int_{0}^{\infty} \frac{e^{-\lambda x} \lambda^n x}{(n-1)!}dx
","['calculus', 'probability', 'statistics']"
55,"Finding the MLE's when $X_i \sim N(\mu,\sigma^2)$",Finding the MLE's when,"X_i \sim N(\mu,\sigma^2)","We have a random sample of size $n$ from a normal distribution, $X_i \sim N(\mu,\sigma^2)$ . I have to find the MLE of the following: $P[X > c]$ for arbitrary $c$ The $95^\text{th}$ percentile of $X$ Could someone give me tips how to handle these kind of questions? I have solved MLE questions before, so I understand the idea behind it, however I couldn't answer these two unfortunately. So far, I have standardized the $P[X>c]$ and I know have $P[X>c] = 1 - F_X[\frac{c-\mu}{\sigma}]$ . I guess I can now conclude something, but I do not know what.","We have a random sample of size from a normal distribution, . I have to find the MLE of the following: for arbitrary The percentile of Could someone give me tips how to handle these kind of questions? I have solved MLE questions before, so I understand the idea behind it, however I couldn't answer these two unfortunately. So far, I have standardized the and I know have . I guess I can now conclude something, but I do not know what.","n X_i \sim N(\mu,\sigma^2) P[X > c] c 95^\text{th} X P[X>c] P[X>c] = 1 - F_X[\frac{c-\mu}{\sigma}]","['probability', 'statistics', 'normal-distribution', 'maximum-likelihood']"
56,On radially symmetric distributions,On radially symmetric distributions,,"Question Let $X_1, \ldots, X_n$ be independent and identically distributed continuous random variables with a positive continuous joint density function $f(x_1, \dots, x_n)$ . Suppose that the distribution of $X_1, \ldots, X_n$ is radially symmetric about the origin, which means that the joint probability density function $f$ satisfies $$f(x_1, \ldots, x_n) = f(y_1, \ldots, y_n)\quad \mathrm{whenever}\quad x_1^2 + \ldots + x_n^2 = y_1^2 + \ldots + y_n^2.$$ What are all possible distributions of $X_1$ ? My working The motivation here is to find a function that turns multiplication into addition, so the exponential function comes to mind. However, as the functions represent probability densities, they must also have finite area over the interval $(-\infty, \infty)$ . Thus, the inverse exponential function is required. $\implies f_{X_1}(x_1) = ce^{-x_1^2}$ , where $c$ is a constant. Is my reasoning for deducing the possible distributions of $X_1$ correct? If not, how should I approach the question and what should the possible distributions be? This is my first time encountering radially symmetric distributions, so any intuitive explanations will be greatly appreciated :)","Question Let be independent and identically distributed continuous random variables with a positive continuous joint density function . Suppose that the distribution of is radially symmetric about the origin, which means that the joint probability density function satisfies What are all possible distributions of ? My working The motivation here is to find a function that turns multiplication into addition, so the exponential function comes to mind. However, as the functions represent probability densities, they must also have finite area over the interval . Thus, the inverse exponential function is required. , where is a constant. Is my reasoning for deducing the possible distributions of correct? If not, how should I approach the question and what should the possible distributions be? This is my first time encountering radially symmetric distributions, so any intuitive explanations will be greatly appreciated :)","X_1, \ldots, X_n f(x_1, \dots, x_n) X_1, \ldots, X_n f f(x_1, \ldots, x_n) = f(y_1, \ldots, y_n)\quad \mathrm{whenever}\quad x_1^2 + \ldots + x_n^2 = y_1^2 + \ldots + y_n^2. X_1 (-\infty, \infty) \implies f_{X_1}(x_1) = ce^{-x_1^2} c X_1","['probability', 'statistics', 'probability-distributions', 'independence', 'symmetry']"
57,MLE of power $2$,MLE of power,2,"Suppose $X$ and $Y$ are random variables and let $x_1, ..., x_n$ be observed values from a random sample of $X$ . Assume that $Y_i = \alpha x_i^2 + \beta_i$ where $\alpha$ is unknown and $\beta_1, ..., \beta_n$ are iid. $N(0, \sigma^2)$ with $\sigma^2$ being unknown (Equivalently assume that the conditional expectation of $Y$ depends quadratically on $X$ and is $0$ when $X$ is $0$ ). (i) Determine the maximum likelihood estimators for $\alpha$ and $\sigma^2$ . (ii) Consider the diagrams below of the regression curve $y = x^2$ . Which set of data has a larger $\hat{\sigma}^2$ ? Why? My attempt: (i) I used this likelihood function $$L(\alpha, \sigma^2) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi \sigma^2}} exp(\sum_{i=1}^{n}\frac{-(y_i - \alpha x_i^2)^2}{2\sigma^2})$$ The negative of the natural log of this is $$-ln(L(\alpha, \sigma^2)) = \frac{n}{2}\ln(2\pi \sigma^2) + \sum_{i=1}^{n}\frac{(y_i - \alpha x_i^2)^2}{2\sigma^2}$$ We let the latter half of the RHS be another function $G$ so that: $$G(\alpha) = \sum_{i=1}^{n}\frac{(y_i - \alpha x_i^2)^2}{2\sigma^2}$$ Minimizing this w.r.t. $\alpha$ gives $$G' = \sum_{i=1}^{n} 2y_ix_i^2 + 2\alpha x_i^4 = 0$$ And so the MLE for $\alpha$ is $$\hat{\alpha} =  \frac{\sum_{i = 1}^{n}Y_ix_i^2}{\sum_{i = 1}^{n}x_i^4}$$ Now, minimizing $-\ln(L)$ w.r.t. $\sigma^2$ gives $$-ln(L(\alpha, \sigma^2))' = \frac{n}{2\sigma^2} - \frac{1}{2\sigma^4}\sum_{i=1}^{n}(y_i - \alpha x_i^2)^2 = 0$$ And so the MLE for $\sigma^2$ is $$\hat{\sigma}^2 =  \frac{1}{n}\sum_{i = 1}^{n} (y_i - \alpha x_i^2)^2$$ (ii) Clearly, diagram 2 has a more widespread set of data, which implies that it has a larger variance. My guess is that diagram 2 has a larger value for $\hat{\sigma}^2$ . Is what I have done correct? Is there any way to justify (ii)? Any assistance is appreciated.","Suppose and are random variables and let be observed values from a random sample of . Assume that where is unknown and are iid. with being unknown (Equivalently assume that the conditional expectation of depends quadratically on and is when is ). (i) Determine the maximum likelihood estimators for and . (ii) Consider the diagrams below of the regression curve . Which set of data has a larger ? Why? My attempt: (i) I used this likelihood function The negative of the natural log of this is We let the latter half of the RHS be another function so that: Minimizing this w.r.t. gives And so the MLE for is Now, minimizing w.r.t. gives And so the MLE for is (ii) Clearly, diagram 2 has a more widespread set of data, which implies that it has a larger variance. My guess is that diagram 2 has a larger value for . Is what I have done correct? Is there any way to justify (ii)? Any assistance is appreciated.","X Y x_1, ..., x_n X Y_i = \alpha x_i^2 + \beta_i \alpha \beta_1, ..., \beta_n N(0, \sigma^2) \sigma^2 Y X 0 X 0 \alpha \sigma^2 y = x^2 \hat{\sigma}^2 L(\alpha, \sigma^2) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi \sigma^2}} exp(\sum_{i=1}^{n}\frac{-(y_i - \alpha x_i^2)^2}{2\sigma^2}) -ln(L(\alpha, \sigma^2)) = \frac{n}{2}\ln(2\pi \sigma^2) + \sum_{i=1}^{n}\frac{(y_i - \alpha x_i^2)^2}{2\sigma^2} G G(\alpha) = \sum_{i=1}^{n}\frac{(y_i - \alpha x_i^2)^2}{2\sigma^2} \alpha G' = \sum_{i=1}^{n} 2y_ix_i^2 + 2\alpha x_i^4 = 0 \alpha \hat{\alpha} =  \frac{\sum_{i = 1}^{n}Y_ix_i^2}{\sum_{i = 1}^{n}x_i^4} -\ln(L) \sigma^2 -ln(L(\alpha, \sigma^2))' = \frac{n}{2\sigma^2} - \frac{1}{2\sigma^4}\sum_{i=1}^{n}(y_i - \alpha x_i^2)^2 = 0 \sigma^2 \hat{\sigma}^2 =  \frac{1}{n}\sum_{i = 1}^{n} (y_i - \alpha x_i^2)^2 \hat{\sigma}^2","['statistics', 'solution-verification', 'regression', 'maximum-likelihood', 'parameter-estimation']"
58,Conditional expectation of $X$ given $X+Y=5$ of a bivariate normal distribution,Conditional expectation of  given  of a bivariate normal distribution,X X+Y=5,"Random variables X and Y have a bivariate normal distribution. If the parameters are $\sigma_x,\sigma_y,\mu_x, \mu_y, \rho$ , how do we express $E(X|X+Y=5)$ using those parameters? The conditional expectation is given by $\mathbb{E}[X|Z=z]=\mu_X+\sigma_X\rho(\frac{\displaystyle z-\mu_Z}{\displaystyle \sigma_Z})$ . Maybe we can let $Z=X+Y$ but then our expression would not have the parameters in terms of Y.","Random variables X and Y have a bivariate normal distribution. If the parameters are , how do we express using those parameters? The conditional expectation is given by . Maybe we can let but then our expression would not have the parameters in terms of Y.","\sigma_x,\sigma_y,\mu_x, \mu_y, \rho E(X|X+Y=5) \mathbb{E}[X|Z=z]=\mu_X+\sigma_X\rho(\frac{\displaystyle z-\mu_Z}{\displaystyle \sigma_Z}) Z=X+Y","['probability', 'statistics', 'conditional-expectation', 'bivariate-distributions']"
59,Why normal equation can have infinite solutions?,Why normal equation can have infinite solutions?,,"The normal equation is $$ X^Ty = X^TX\hat{\beta}. $$ If $X^TX$ is invertible, then $\hat{\beta}$ has an unique solution which is $$ \hat{\beta} = (X^TX)^{-1}X^Ty. $$ However, if $X^TX$ is non-invertible, then $X^TX$ is a singular matrix, which means that $rank(X^TX) = r < p$ where $X$ is a $n \times p$ matrix. By the dimension theorem, we know that $$ rank(X^TX) = rank(X) = r < p. $$ And then we need to show that the $ker(X^TX) = ker(X)$ , and this can be proved by suppose $y \in ker(X^TX)$ $$ X^TXy = 0 \implies y^TX^TXy = 0 \implies ||Xy||^2 = 0 \implies Xy = 0. $$ Therefore, $ker(X^TX) = ker(X)$ . Then we know that there are $p-r$ linealy dependent columns in $X$ and $X$ and $X^TX$ can not span the whole column space of $X$ . However, I can't figure out that the above can finish the proof of why a normal equation can have infinite solutions?","The normal equation is If is invertible, then has an unique solution which is However, if is non-invertible, then is a singular matrix, which means that where is a matrix. By the dimension theorem, we know that And then we need to show that the , and this can be proved by suppose Therefore, . Then we know that there are linealy dependent columns in and and can not span the whole column space of . However, I can't figure out that the above can finish the proof of why a normal equation can have infinite solutions?","
X^Ty = X^TX\hat{\beta}.
 X^TX \hat{\beta} 
\hat{\beta} = (X^TX)^{-1}X^Ty.
 X^TX X^TX rank(X^TX) = r < p X n \times p 
rank(X^TX) = rank(X) = r < p.
 ker(X^TX) = ker(X) y \in ker(X^TX) 
X^TXy = 0 \implies y^TX^TXy = 0 \implies ||Xy||^2 = 0 \implies Xy = 0.
 ker(X^TX) = ker(X) p-r X X X^TX X","['linear-algebra', 'statistics']"
60,Quick Verification for Sufficient Statistic in Exponential Families!,Quick Verification for Sufficient Statistic in Exponential Families!,,"Problem: Prove that if the distribution of $X=(X_1,...,X_n)$ is in an exponential family, then $T(X)=(T_1(X),...,T_J(X))$ is sufficient for $\theta$ . Progress: Knowing that an exponential family can be written as $f(x;\theta)=1(x\in A)\exp\{\sum_{j=1}^J\gamma_j(\theta)T_j(x)+d(\theta)+S(x)\}$ , is this just the result of using the Neyman-Fisher Factorization Theorem? This seems too trivial so I must be missing something. Any help or verification would be appreciated!","Problem: Prove that if the distribution of is in an exponential family, then is sufficient for . Progress: Knowing that an exponential family can be written as , is this just the result of using the Neyman-Fisher Factorization Theorem? This seems too trivial so I must be missing something. Any help or verification would be appreciated!","X=(X_1,...,X_n) T(X)=(T_1(X),...,T_J(X)) \theta f(x;\theta)=1(x\in A)\exp\{\sum_{j=1}^J\gamma_j(\theta)T_j(x)+d(\theta)+S(x)\}","['statistics', 'probability-distributions', 'exponential-function', 'normal-distribution', 'statistical-inference']"
61,Optimal strategy to maximize the expected gains of a probability based game,Optimal strategy to maximize the expected gains of a probability based game,,"The game: you start with nothing, and you choose to roll a fair dice as many times as you want. Each of the 6 outcomes is attached with a certain $ value, except for one, where you will lose all that you gained and the game ends. My question: Mathmaitcally speaking, is there an optimal stopping rule that maximizes the expected gains of a single game? There are two possible kinds of strategies: 1- Stop after n rounds 2- Stop as soon as your balance exceed $k The latter makes more sense to me, as the former feels like I'm indulging in some kind of gambler's fallacy.","The game: you start with nothing, and you choose to roll a fair dice as many times as you want. Each of the 6 outcomes is attached with a certain $ value, except for one, where you will lose all that you gained and the game ends. My question: Mathmaitcally speaking, is there an optimal stopping rule that maximizes the expected gains of a single game? There are two possible kinds of strategies: 1- Stop after n rounds 2- Stop as soon as your balance exceed $k The latter makes more sense to me, as the former feels like I'm indulging in some kind of gambler's fallacy.",,"['probability', 'probability-theory', 'statistics', 'optimization', 'game-theory']"
62,What is the expectation of the largest eigenvalue of a Wishart distributed matrix?,What is the expectation of the largest eigenvalue of a Wishart distributed matrix?,,"Let $\mathcal{S}_{++}^d$ denote the space of (symmetric) positive definite matrices of size $d \times d$ , where $d\in \mathbb{N}$ is given. The density function of the $\mathrm{Wishart}_d(\nu,\mathbb{M})$ distribution is defined by \begin{equation}\label{eq:Wishart.density}     f_{\nu,\mathbb{M}}(\mathbb{X}) = \frac{|\mathbb{X}|^{\nu/2 - (d + 1)/2} \exp\big(-\frac{1}{2}\mathrm{tr}(\mathbb{M}^{-1} \mathbb{X})\big)}{|2 \, \mathbb{M}|^{\nu/2} \pi^{d(d-1)/4} \prod_{i=1}^d \Gamma\Big(\frac{\nu}{2} - \frac{i - 1}{2}\Big)}, \quad \mathbb{X}\in \mathcal{S}_{++}^d, \end{equation} where $\nu > d - 1$ is the number of degrees of freedom, and $\mathbb{M}\in \mathcal{S}_{++}^d$ is the scale matrix. If $\mathbb{S} \sim \mathrm{Wishart}_d(\nu,\mathbb{M})$ and $\lambda_{\mathrm{max}}(\mathbb{S})$ is the largest eigenvalue of $\mathbb{S}$ , then what is $\mathbb{E}[\lambda_{\mathrm{max}}(\mathbb{S})]$ ? I can't find any reference with a clear answer to this question.","Let denote the space of (symmetric) positive definite matrices of size , where is given. The density function of the distribution is defined by where is the number of degrees of freedom, and is the scale matrix. If and is the largest eigenvalue of , then what is ? I can't find any reference with a clear answer to this question.","\mathcal{S}_{++}^d d \times d d\in \mathbb{N} \mathrm{Wishart}_d(\nu,\mathbb{M}) \begin{equation}\label{eq:Wishart.density}
    f_{\nu,\mathbb{M}}(\mathbb{X}) = \frac{|\mathbb{X}|^{\nu/2 - (d + 1)/2} \exp\big(-\frac{1}{2}\mathrm{tr}(\mathbb{M}^{-1} \mathbb{X})\big)}{|2 \, \mathbb{M}|^{\nu/2} \pi^{d(d-1)/4} \prod_{i=1}^d \Gamma\Big(\frac{\nu}{2} - \frac{i - 1}{2}\Big)}, \quad \mathbb{X}\in \mathcal{S}_{++}^d,
\end{equation} \nu > d - 1 \mathbb{M}\in \mathcal{S}_{++}^d \mathbb{S} \sim \mathrm{Wishart}_d(\nu,\mathbb{M}) \lambda_{\mathrm{max}}(\mathbb{S}) \mathbb{S} \mathbb{E}[\lambda_{\mathrm{max}}(\mathbb{S})]","['probability', 'statistics']"
63,"$\sum_{j=1}^n|Z_1\cdots Z_j|$ converges in $L^1$ and a.s. for $Z_i\sim N(0,1)$",converges in  and a.s. for,"\sum_{j=1}^n|Z_1\cdots Z_j| L^1 Z_i\sim N(0,1)","I'm trying to prove that $\sum_{j=1}^n|Z_1\cdots Z_j|$ converges in $L^1$ and a.s. as $n\to\infty$ , for $Z_i\sim N(0,1)$ independently. I think I should use that I have a sum of nonnegative r.v.'s with expectation $\sqrt{\frac2{\pi}}^{\ n}$ , which converges to $0$ exponentially. Is there a theorem that gives both $L^1$ and a.s. convergence of a sum of nonnegative r.v.'s with expectations that tend to $0$ exponentially? If not, do you know another approach that can work here?","I'm trying to prove that converges in and a.s. as , for independently. I think I should use that I have a sum of nonnegative r.v.'s with expectation , which converges to exponentially. Is there a theorem that gives both and a.s. convergence of a sum of nonnegative r.v.'s with expectations that tend to exponentially? If not, do you know another approach that can work here?","\sum_{j=1}^n|Z_1\cdots Z_j| L^1 n\to\infty Z_i\sim N(0,1) \sqrt{\frac2{\pi}}^{\ n} 0 L^1 0","['probability-theory', 'statistics']"
64,Test if coin is fair with significance/confidence of 95%,Test if coin is fair with significance/confidence of 95%,,"Please take a look at the next $10$ mins of this lecture starting here: https://youtu.be/rYefUsYuEp0?t=1147 We are trying to find a number $\xi$ such that: $P(|S_n-n \cdot (1/2)| \le \xi) \approx 0.95$ The professor finds $\xi=31$ but he says that he ""pretends"" $S_n$ is approximately standard normal. Why $S_n$ ? I apply the CLT literally and so I ""pretend"" that $$Z_n = \frac{(S_n - n/2)}{(1/4)\cdot\sqrt{n}}$$ is standard normal. By ""pretend"" I just mean the usual i.e. I get the right to use the standard normal tables (as justified by the CLT). In the standard normal table I looked for $0.975$ and I found the Z-score number $1.96$ . When I did all the computations I got $\xi = 15.495$ which is twice less. Why? I am interpreting it this way: if I make 1000 coin tosses and if the number of heads I observe is no more than 15 away from 500, then I conclude with certainty of about 95% that my coin is fair. Am I incorrect conceptually? Or did I mess up the calculations? Or is there something else here which I am not taking into account? A deviation/difference of 31 given 1000 coin tosses seems too much to me just intuitively. But intuition can lie. Also, not sure why he says $S_n$ is approximately standard normal. It should be $Z_n$ , right? Maybe the lecturer is oversimplifying just for presentation purposes, and that's why he gets 31 and not 15.49. Is it indeed so?","Please take a look at the next mins of this lecture starting here: https://youtu.be/rYefUsYuEp0?t=1147 We are trying to find a number such that: The professor finds but he says that he ""pretends"" is approximately standard normal. Why ? I apply the CLT literally and so I ""pretend"" that is standard normal. By ""pretend"" I just mean the usual i.e. I get the right to use the standard normal tables (as justified by the CLT). In the standard normal table I looked for and I found the Z-score number . When I did all the computations I got which is twice less. Why? I am interpreting it this way: if I make 1000 coin tosses and if the number of heads I observe is no more than 15 away from 500, then I conclude with certainty of about 95% that my coin is fair. Am I incorrect conceptually? Or did I mess up the calculations? Or is there something else here which I am not taking into account? A deviation/difference of 31 given 1000 coin tosses seems too much to me just intuitively. But intuition can lie. Also, not sure why he says is approximately standard normal. It should be , right? Maybe the lecturer is oversimplifying just for presentation purposes, and that's why he gets 31 and not 15.49. Is it indeed so?",10 \xi P(|S_n-n \cdot (1/2)| \le \xi) \approx 0.95 \xi=31 S_n S_n Z_n = \frac{(S_n - n/2)}{(1/4)\cdot\sqrt{n}} 0.975 1.96 \xi = 15.495 S_n Z_n,"['probability', 'statistics', 'statistical-inference', 'central-limit-theorem']"
65,The sums of squares from standard deviation,The sums of squares from standard deviation,,"I am trying to figure out how to get a sum of squares from a standard deviation. The standard deviations I have are $11.04$ , $9.91$ and $9.43$ . How do I calculate the sum of squares associated with these standard deviation values? Thanks!","I am trying to figure out how to get a sum of squares from a standard deviation. The standard deviations I have are , and . How do I calculate the sum of squares associated with these standard deviation values? Thanks!",11.04 9.91 9.43,"['statistics', 'standard-deviation']"
66,How do I find $P(1< Z <2)$ for given problem?,How do I find  for given problem?,P(1< Z <2),"Suppose  a value z of the continuous random variable Z is generated as follows: First, a fair die is rolled.If the side of the die facing up has 1 or 2 dots, then z is drawn from a Unif(0,2) distribution;otherwise z is drawn from a Unif(1,4) distribution. Now for such random variable Z how can you find a P(1<Z<2)?? I am just unable to comprehend what the Z random variable would even look like.","Suppose  a value z of the continuous random variable Z is generated as follows: First, a fair die is rolled.If the side of the die facing up has 1 or 2 dots, then z is drawn from a Unif(0,2) distribution;otherwise z is drawn from a Unif(1,4) distribution. Now for such random variable Z how can you find a P(1<Z<2)?? I am just unable to comprehend what the Z random variable would even look like.",,"['statistics', 'random-variables', 'uniform-distribution']"
67,Method for estimating number of fish in my Aquarium,Method for estimating number of fish in my Aquarium,,"Context: I have an aquarium (50 Liters) with lots of fishes from the same specie (Guppy) and i have noticed that recently their number as grown exponentially due to their reproductive cycle. I would like to estimate their number. Problem: It's not possible for me to count them individually, and i cannot dry the aquarium due to the fact that the newborns are translucid and have sizes bellow 4 milimeters, it would be an impossible task to distinguish them from the grains of smalls rocks in my aquarium. Pre-Condition: Due to the fact that newborns stay relatively close to the ground and as they grow they will occupy (swim) in places increasingly closer to the surface level, we can consider that the fishes are uniformly distributed in the aquarium. Fish Tank Possible method: Take a cup of water (for example 150 milliliters) consistently from the same place of the aquarium, and count the number of fishes from inside the cup. By repeating this method multiple time i could in theory estimate the total number of fishes in my aquarium. Question: Is this a good method? Are there any big flaws in my lines of thinking? Could you think of a better, more pratical method? Thanks in advance for your help :)","Context: I have an aquarium (50 Liters) with lots of fishes from the same specie (Guppy) and i have noticed that recently their number as grown exponentially due to their reproductive cycle. I would like to estimate their number. Problem: It's not possible for me to count them individually, and i cannot dry the aquarium due to the fact that the newborns are translucid and have sizes bellow 4 milimeters, it would be an impossible task to distinguish them from the grains of smalls rocks in my aquarium. Pre-Condition: Due to the fact that newborns stay relatively close to the ground and as they grow they will occupy (swim) in places increasingly closer to the surface level, we can consider that the fishes are uniformly distributed in the aquarium. Fish Tank Possible method: Take a cup of water (for example 150 milliliters) consistently from the same place of the aquarium, and count the number of fishes from inside the cup. By repeating this method multiple time i could in theory estimate the total number of fishes in my aquarium. Question: Is this a good method? Are there any big flaws in my lines of thinking? Could you think of a better, more pratical method? Thanks in advance for your help :)",,"['statistics', 'numerical-methods', 'experimental-mathematics']"
68,How can it be derived? (Law of the unconscious statistician),How can it be derived? (Law of the unconscious statistician),,"On pg. 7 of Financial Calculus: An Introduction to Derivative Pricing by Martin Baxter & Andrew Rennie, it states: My Understanding I did try to derive this picture. But I don't understand how this outcome that is $S_0\exp(\mu -0.5\sigma^2)$ is derived. Could I get any hint of it?","On pg. 7 of Financial Calculus: An Introduction to Derivative Pricing by Martin Baxter & Andrew Rennie, it states: My Understanding I did try to derive this picture. But I don't understand how this outcome that is is derived. Could I get any hint of it?",S_0\exp(\mu -0.5\sigma^2),['statistics']
69,Probability of infection by staphylococcus aureus,Probability of infection by staphylococcus aureus,,"Please forgive my innumeracy, but I have a question with which I am hoping someone might be able to help me. Suppose the following be true. The chance of a prosthetic hip joint becoming infected by staphylococcus aureus is one per cent. The chance of a natural hip joint becoming infected by staphylococcus aureus is 0.1%. In other words (in case I am misusing the word 'chance'), one in one hundred people with prosthetic hip joints will become infected by staphylococcus aureus, whereas only one in one thousand people with natural hip joints will become so infected. Now suppose that X has a prosthetic hip joint and that X's hip joint becomes infected by staphylococcus aureus. Given only the information provided here, is it correct to say that X's hip joint probably would not have become infected but for the fact that X has a prosthetic hip joint (instead of a natural hip joint)? In other words (to make it clear what I mean by 'probably'), is it correct to say that there is a greater than 50 per cent chance that X's hip joint would not have become infected but for the fact that X has a prosthetic hip joint? Why or why not?","Please forgive my innumeracy, but I have a question with which I am hoping someone might be able to help me. Suppose the following be true. The chance of a prosthetic hip joint becoming infected by staphylococcus aureus is one per cent. The chance of a natural hip joint becoming infected by staphylococcus aureus is 0.1%. In other words (in case I am misusing the word 'chance'), one in one hundred people with prosthetic hip joints will become infected by staphylococcus aureus, whereas only one in one thousand people with natural hip joints will become so infected. Now suppose that X has a prosthetic hip joint and that X's hip joint becomes infected by staphylococcus aureus. Given only the information provided here, is it correct to say that X's hip joint probably would not have become infected but for the fact that X has a prosthetic hip joint (instead of a natural hip joint)? In other words (to make it clear what I mean by 'probably'), is it correct to say that there is a greater than 50 per cent chance that X's hip joint would not have become infected but for the fact that X has a prosthetic hip joint? Why or why not?",,"['probability', 'statistics']"
70,Intuition: Why do we divide by $\sqrt{n}$ instead of $n$ in the Central Limit Theorem?,Intuition: Why do we divide by  instead of  in the Central Limit Theorem?,\sqrt{n} n,"The law of large numbers for example is very straightforward to understand. You sum up the random variables, and divide them by their number. You take the almost sure limit of the arithmetic mean and end up with the expectation. What's not to love? Now for the Central Limit Theorem (CLT) we consider convergence in distribution so I realize the logic is different. Let me state a simple version for reference: Let $(X_n)_{n \in \mathbb{N}}$ be a sequence of i.i.d. random variables with $E[X_1]=0$ and > $Var(X_1) = \sigma^2$ where $0< \sigma <\infty$ . Then we have that $$ G_n := \frac{1}{\sqrt{n \sigma^2}} \sum_{k = 1}^{n} X_k  \overset{d}{\longrightarrow} G$$ where $G \sim N(0,1)$ I have seen more than one proof for the CLT but they are quite technical. For a long time I brushed this issue aside but it is repeating itself in several other theorems I encountered (e.g. Donsker's theorem for partial sum processes) so by now I really want to understand. Is there an intuition as to where the square root is coming from?","The law of large numbers for example is very straightforward to understand. You sum up the random variables, and divide them by their number. You take the almost sure limit of the arithmetic mean and end up with the expectation. What's not to love? Now for the Central Limit Theorem (CLT) we consider convergence in distribution so I realize the logic is different. Let me state a simple version for reference: Let be a sequence of i.i.d. random variables with and > where . Then we have that where I have seen more than one proof for the CLT but they are quite technical. For a long time I brushed this issue aside but it is repeating itself in several other theorems I encountered (e.g. Donsker's theorem for partial sum processes) so by now I really want to understand. Is there an intuition as to where the square root is coming from?","(X_n)_{n \in \mathbb{N}} E[X_1]=0 Var(X_1) = \sigma^2 0< \sigma <\infty  G_n := \frac{1}{\sqrt{n \sigma^2}} \sum_{k = 1}^{n} X_k  \overset{d}{\longrightarrow} G G \sim N(0,1)","['probability-theory', 'statistics', 'central-limit-theorem']"
71,MLE for $\mu$ for Normal distribution,MLE for  for Normal distribution,\mu,"I am doing some homework and have a little trouble with the following problem: Suppose the weight $X$ in pounds of a girl in a certain town is normally distributed with $N(\mu,15^2)$ while the weight $Y$ of a boy in this town is normally distributed $N(1.3 \mu, 20^2).$ The weights of randomly chosen girl and boy are $x = 95$ and $y = 130$ pounds respectively. Then I have to find the MLE of $\mu$ . However, I know that the MLE of $\mu$ for a normal distribution is simply the sample mean, thus $$MLE_{\mu} = \frac{1}{n} \sum_{i = 1}^n X_i = \frac{95 + 130}{2} = 112.5$$ Is this simply it? TIA for any help.","I am doing some homework and have a little trouble with the following problem: Suppose the weight in pounds of a girl in a certain town is normally distributed with while the weight of a boy in this town is normally distributed The weights of randomly chosen girl and boy are and pounds respectively. Then I have to find the MLE of . However, I know that the MLE of for a normal distribution is simply the sample mean, thus Is this simply it? TIA for any help.","X N(\mu,15^2) Y N(1.3 \mu, 20^2). x = 95 y = 130 \mu \mu MLE_{\mu} = \frac{1}{n} \sum_{i = 1}^n X_i = \frac{95 + 130}{2} = 112.5","['statistics', 'maximum-likelihood']"
72,"The sum of $2$ consecutive primes, Are there more $\mod 6=0$?","The sum of  consecutive primes, Are there more ?",2 \mod 6=0,"All prime numbers greater than $3$ take the form of either $6x+1$ or $6y-1$ . So the only options for the sums of $2$ consecutive primes are: $(6x+1 + 6y-1) \mod 6=0$ $(6x-1 + 6y+1) \mod 6=0$ $(6x+1 + 6y+1) \mod 6≠0$ $(6x-1 + 6y-1) \mod 6≠0$ According to the limited available options above, the chances for $(6x+1 + 6y-1) \mod 6=0$ or $(6x-1 + 6y+1) \mod 6=0$ to occur are only $50\%$ , However: Out of the first $200000$ prime numbers, when adding a prime number with the following prime number, $115141$ resulted in $\mod 6=0$ which is about $57.5705...\%$ When I mention ""following prime number"", I mean it as: $5+7$ ( $7$ is following $5$ ). another example: $31+37$ ( $37$ is following $31$ ),  another example: $43+47$ ( $47$ is following $43$ ). Why is it that there are more $\mod 6=0$ occurrences then $\mod 6≠0$ occurrences, when the probability shows that the chances for $\mod 6=0$ is just $50\%$ Am I expecting to see these kind of statistics (margins) continue infinitely? Can it be proven? Or maybe it is just that my sample test of 200000 is too small, and I should expect a correction in larger samples? Update: Per @Peter 's comment: A slight decrease if we continue until [ $3⋅10^9+19,3⋅10^9+37$ ] : [ $79805741,64643795,0.55248180928736247377077071400215505019$ ]","All prime numbers greater than take the form of either or . So the only options for the sums of consecutive primes are: According to the limited available options above, the chances for or to occur are only , However: Out of the first prime numbers, when adding a prime number with the following prime number, resulted in which is about When I mention ""following prime number"", I mean it as: ( is following ). another example: ( is following ),  another example: ( is following ). Why is it that there are more occurrences then occurrences, when the probability shows that the chances for is just Am I expecting to see these kind of statistics (margins) continue infinitely? Can it be proven? Or maybe it is just that my sample test of 200000 is too small, and I should expect a correction in larger samples? Update: Per @Peter 's comment: A slight decrease if we continue until [ ] : [ ]","3 6x+1 6y-1 2 (6x+1 + 6y-1) \mod 6=0 (6x-1 + 6y+1) \mod 6=0 (6x+1 + 6y+1) \mod 6≠0 (6x-1 + 6y-1) \mod 6≠0 (6x+1 + 6y-1) \mod 6=0 (6x-1 + 6y+1) \mod 6=0 50\% 200000 115141 \mod 6=0 57.5705...\% 5+7 7 5 31+37 37 31 43+47 47 43 \mod 6=0 \mod 6≠0 \mod 6=0 50\% 3⋅10^9+19,3⋅10^9+37 79805741,64643795,0.55248180928736247377077071400215505019","['probability', 'elementary-number-theory', 'statistics', 'prime-numbers', 'proof-explanation']"
73,Finding Variance from given table using formula,Finding Variance from given table using formula,,"Im having trouble calculating the variance for $X_m$ and $X_k$ for the following table: ""We now consider a random household and let the stochastic variables $X_k$ og $X_m$ be defined in the following way: $X_k$ : The woman's working hours measured in hours per. week $X_m$ : The man's working hours measured in hours per. week"" I calculated the marginal distribution for Xm: $$ P(X_m = 0) = 0.08$$ $$P(X_m = 20) = 0.12$$ $$P(X_m = 40) = 0.8$$ I've already calculated the mean for $X_m$ , which i did by using the marginal distribution values $$\text{mean} = 0.08 \cdot 0 +0.12 \cdot 20 +0.8 \cdot 40 =34.4$$ Now i am to calculate the Variance, however it seems as though there are multiple variance formulas available however im not sure which to use.","Im having trouble calculating the variance for and for the following table: ""We now consider a random household and let the stochastic variables og be defined in the following way: : The woman's working hours measured in hours per. week : The man's working hours measured in hours per. week"" I calculated the marginal distribution for Xm: I've already calculated the mean for , which i did by using the marginal distribution values Now i am to calculate the Variance, however it seems as though there are multiple variance formulas available however im not sure which to use.",X_m X_k X_k X_m X_k X_m  P(X_m = 0) = 0.08 P(X_m = 20) = 0.12 P(X_m = 40) = 0.8 X_m \text{mean} = 0.08 \cdot 0 +0.12 \cdot 20 +0.8 \cdot 40 =34.4,"['probability', 'statistics', 'expected-value', 'variance']"
74,"How can I evaluate average with negative values, given I will apply this weight for both negative and positive values","How can I evaluate average with negative values, given I will apply this weight for both negative and positive values",,"I am more a programming guy than math one, so please be easy on me with math expressions Before I start describing to make it clear: I have 2 types of scores: reddit score and sentiment score. Reddit score can be of any value. Sentiment score ranges between -1 and 1 So my task is to calculate weight for each sentiment score. Besides analyzing post for sentiments I want to give this post a weight to enhance evaluation of sentiment value it carries Basically it would look like this sentiment value = sentiment_analyzer(post) * weight I want to use average of reddit scores, which can be both negative and positive Then apply this average to calculate weight the following way: weight = reddit_score / average(reddit_scores) So here comes the problem, it is not typical but what happens if average will end up negative ? On one hand we can leave it as is, hoping this will never happen, but if it will it would ruin all scoring (I guess ?) , on the other we can't just make it positive and ignore that fact it was originally calculated with negative values. Maybe I am missing some basic Math concepts, but I really can remember this situation, when I studied Math. As for method itself I understand it far from accurate, but I am also limited on functions, so I would be grateful if you tell me whether this weight estimation method makes sense at all. And if there is a better simple method. (Even quartile formula not available)","I am more a programming guy than math one, so please be easy on me with math expressions Before I start describing to make it clear: I have 2 types of scores: reddit score and sentiment score. Reddit score can be of any value. Sentiment score ranges between -1 and 1 So my task is to calculate weight for each sentiment score. Besides analyzing post for sentiments I want to give this post a weight to enhance evaluation of sentiment value it carries Basically it would look like this sentiment value = sentiment_analyzer(post) * weight I want to use average of reddit scores, which can be both negative and positive Then apply this average to calculate weight the following way: weight = reddit_score / average(reddit_scores) So here comes the problem, it is not typical but what happens if average will end up negative ? On one hand we can leave it as is, hoping this will never happen, but if it will it would ruin all scoring (I guess ?) , on the other we can't just make it positive and ignore that fact it was originally calculated with negative values. Maybe I am missing some basic Math concepts, but I really can remember this situation, when I studied Math. As for method itself I understand it far from accurate, but I am also limited on functions, so I would be grateful if you tell me whether this weight estimation method makes sense at all. And if there is a better simple method. (Even quartile formula not available)",,['statistics']
75,Is there any specific meaning of the formula 2*(max-min)/(max+min)?,Is there any specific meaning of the formula 2*(max-min)/(max+min)?,,"I'm a student who studies machine learning. When I studied this paper( https://dl.acm.org/doi/pdf/10.1145/335191.335388 ), I saw the following formula and explanation. $$(direct_{max} - direct_{min})/direct_{mean} = (indirect_{max} - indirect_{min})/indirect_{mean}$$ The $direct_{mean}$ is the mean value of $direct_{max}$ and $direct_{min}$ . And $indirect_{mean}$ is also the mean value of $indirect_{max}$ and $indirect_{min}$ . In this case, that paper said the fluctuate amount is the same between direct and indirect. But I don't understand one thing. Is there any specific meaning of the below formula? $$2* (value_{max} - value_{min})/(value_{max} + value_{min})$$ I don't know why it has the meaning as the amount of fluctuating. Thank you for reading my question.","I'm a student who studies machine learning. When I studied this paper( https://dl.acm.org/doi/pdf/10.1145/335191.335388 ), I saw the following formula and explanation. The is the mean value of and . And is also the mean value of and . In this case, that paper said the fluctuate amount is the same between direct and indirect. But I don't understand one thing. Is there any specific meaning of the below formula? I don't know why it has the meaning as the amount of fluctuating. Thank you for reading my question.",(direct_{max} - direct_{min})/direct_{mean} = (indirect_{max} - indirect_{min})/indirect_{mean} direct_{mean} direct_{max} direct_{min} indirect_{mean} indirect_{max} indirect_{min} 2* (value_{max} - value_{min})/(value_{max} + value_{min}),['statistics']
76,Poisson distribution problem including cdf,Poisson distribution problem including cdf,,"The Question The number of cracks in a section of highway that is significant enough to require repair is assumed to follow a Poisson distribution. (a) Let $Y$ be the number of cracks in $4$ km, sketch the (CDF) Cumulative Distribution Function and graph up to $𝑦 = 4.5$ . (b) If we should order the material to fix the cracks beforehand, how many packages of the material (One package for one crack) shall we order to ensure that all the cracks in $4$ km can be fixed with at least $95\%$ chance? My Understanding For part (a), I tried to compute the probabilities of $Y=0, 1, 2, 3, 4, 5$ respectively, by using the formula of $Pr(X=k)=\frac{e^{-𝜇}\mu^k}{k!}$ however, when I tried to sum these probabilities together , $F(Y)$ turns out to exceed $1$ , where probability should not $\gt 1$ , what's wrong with that? What is the appropriate way to find the probabilities and thus I can graph up to $y=4.5$ ? For part (b), for my understanding, this Poisson distribution has infinite number of cracks, so I am quite doubt that how to ensure that all the cracks in $4$ km can be fixed with at least $95\%$ chance?","The Question The number of cracks in a section of highway that is significant enough to require repair is assumed to follow a Poisson distribution. (a) Let be the number of cracks in km, sketch the (CDF) Cumulative Distribution Function and graph up to . (b) If we should order the material to fix the cracks beforehand, how many packages of the material (One package for one crack) shall we order to ensure that all the cracks in km can be fixed with at least chance? My Understanding For part (a), I tried to compute the probabilities of respectively, by using the formula of however, when I tried to sum these probabilities together , turns out to exceed , where probability should not , what's wrong with that? What is the appropriate way to find the probabilities and thus I can graph up to ? For part (b), for my understanding, this Poisson distribution has infinite number of cracks, so I am quite doubt that how to ensure that all the cracks in km can be fixed with at least chance?","Y 4 𝑦 = 4.5 4 95\% Y=0, 1, 2, 3, 4, 5 Pr(X=k)=\frac{e^{-𝜇}\mu^k}{k!} F(Y) 1 \gt 1 y=4.5 4 95\%","['probability', 'statistics', 'probability-distributions']"
77,"Suppose $X_{1},...\sim U[0, 1]$. Let us define $X(n)$ = $\max_{1≤i≤n} X_i$ . Prove that $X(n)$ converges in probability to $1$.",Suppose . Let us define  =  . Prove that  converges in probability to .,"X_{1},...\sim U[0, 1] X(n) \max_{1≤i≤n} X_i X(n) 1","Suppose $X_{1},...\sim U[0, 1]$ . Let us define $X(n)$ = $\max_{1≤i≤n} X_i$ . Prove that $X(n)$ converges in probability to $1$ . Is this solution enough?... I cannot understand the solution provided in the below mentioned link: https://www.stat.cmu.edu/~larry/=stat705/Lecture4.pdf",Suppose . Let us define = . Prove that converges in probability to . Is this solution enough?... I cannot understand the solution provided in the below mentioned link: https://www.stat.cmu.edu/~larry/=stat705/Lecture4.pdf,"X_{1},...\sim U[0, 1] X(n) \max_{1≤i≤n} X_i X(n) 1","['probability', 'probability-theory', 'statistics', 'probability-distributions', 'problem-solving']"
78,"In Fisher’s discriminant for multiple classes, How do you manage when $(Sw)$ is singular matrix (so you cant get $(Sw)^{-1}$)?","In Fisher’s discriminant for multiple classes, How do you manage when  is singular matrix (so you cant get )?",(Sw) (Sw)^{-1},"I am trying to use Fisher’s discriminant for multiple classes to reduce the Dimension of the MNIST data set, similar to this post: https://towardsdatascience.com/an-illustrative-introduction-to-fishers-linear-discriminant-9484efee15ac But in my Implementation in Python, when I compute $Sw$ it is a singular matrix so I can not get $(Sw)^{-1}$ to obtain the eigenvectors from $(Sw)^{-1}Sb$ . Am I doing something wrong or what can I do to solve this problem? I am following the steps given in Pattern Recognition and Machine Learning By Bishop. Thanks.","I am trying to use Fisher’s discriminant for multiple classes to reduce the Dimension of the MNIST data set, similar to this post: https://towardsdatascience.com/an-illustrative-introduction-to-fishers-linear-discriminant-9484efee15ac But in my Implementation in Python, when I compute it is a singular matrix so I can not get to obtain the eigenvectors from . Am I doing something wrong or what can I do to solve this problem? I am following the steps given in Pattern Recognition and Machine Learning By Bishop. Thanks.",Sw (Sw)^{-1} (Sw)^{-1}Sb,"['probability', 'statistics', 'machine-learning', 'pattern-recognition', 'discriminant']"
79,Independence of two intertwined random variables,Independence of two intertwined random variables,,"Let $X_0$ , $X_1$ and $X_2$ be three mutually independent random variables. We define two more random variables $D_1$ and $D_2$ as follows: $$D_1 = X_1 + X_0\\[1ex] D_2 = X_2 + X_0$$ We're interested in arguing (in the most effective and simple way) if $D_1$ and $D_2$ are independent $D_1|X_0=x_0$ and $D_2|X_0=x_0$ are independent If $D_1$ and $D_2$ are independent, it must be $\text{Cov}(D_1,D_2)=0$ : $$\text{Cov}(D_1, D_2)=\mathbb{E}[D_1 D_2]-\mathbb{E}[D_1]\mathbb{E}[D_2] =\\ =\mathbb{E}\left[ (X_1+X_0)(X_2+X_0) \right] - \mathbb{E}\left[ X_1+X_0 \right]\mathbb{E}\left[ X_2+X_0 \right]=\\ =\mathbb{E}\left[ X_1 X_2 + X_1 X_0 + X_0 X_2 + X_0^2 \right] - \mathbb{E}\left[ X_1 \right]\mathbb{E}\left[ X_2 \right] - \mathbb{E}\left[ X_1 \right]\mathbb{E}\left[ X_0 \right] - \mathbb{E}\left[ X_0 \right]\mathbb{E}\left[ X_2 \right] - \left(\mathbb{E}\left[ X_0 \right]\right)^2=\\ =\mathbb{E}\left[ X_1 \right]\mathbb{E}\left[ X_2 \right] + \mathbb{E}\left[ X_1 \right]\mathbb{E}\left[ X_0 \right] + \mathbb{E}\left[ X_0 \right]\mathbb{E}\left[ X_2 \right] + \mathbb{E}\left[ X_0^2 \right] - \mathbb{E}\left[ X_1 \right]\mathbb{E}\left[ X_2 \right] - \mathbb{E}\left[ X_1 \right]\mathbb{E}\left[ X_0 \right] - \mathbb{E}\left[ X_0 \right]\mathbb{E}\left[ X_2 \right] - \left(\mathbb{E}\left[ X_0 \right]\right)^2=\\ =\mathbb{E}\left[ X_0^2 \right] - \left(\mathbb{E}\left[ X_0 \right]\right)^2 = \text{Var}(X_0)\neq 0$$ So, if not for the trivial case in which $X_0 = \text{constant}$ , $\mathbf{D_1}$ and $\mathbf{D_2}$ are not independent . 2. One could do the same thing of point 1. all over again or just notice that this case is exactly the trivial one in which $X_0 = x_0$ , a fixed ""constant"". So, $\mathbf{D_1|X_0 =x_0}$ and $\mathbf{D_2|X_0 =x_0}$ are independent . MY QUESTION Are my proofs correct? Is there a simpler way to prove the same thing or even just argument the same results in a better, more intuitive way? A BONUS QUESTION How can I test these theoretical results with the following example? (In order to really ""see"" what I found) $X_0$ is the outcome of the fair coin ""COIN"": $X_0=1$ if Heads , $X_0=0$ if Tails . $X_1$ is the outcome of the 6-faced fair dice ""DICE1"": $X_1=\{1,2,3,4,5,6\}$ $X_2$ is the outcome of the 6-faced fair dice ""DICE2"": $X_2=\{1,2,3,4,5,6\}$ SOMETHING THAT PERPLEXES ME Intuitively and ""constructively"", I would say that the event to observe $D_1=k$ is independent from that of observing $D_2 = h$ , infact the first is the event of obtaining $X_1 + X_0 = k$ with a throw of DICE1 and a toss of COIN while the second is the event of obtaining $X_2 + X_0 = k$ with a throw of DICE2 and a different toss of COIN: these two ""procedures"" are totally independent from each other and so should be their probabilities (?) But this contradicts my analytical results, doesn't it! Why is that?","Let , and be three mutually independent random variables. We define two more random variables and as follows: We're interested in arguing (in the most effective and simple way) if and are independent and are independent If and are independent, it must be : So, if not for the trivial case in which , and are not independent . 2. One could do the same thing of point 1. all over again or just notice that this case is exactly the trivial one in which , a fixed ""constant"". So, and are independent . MY QUESTION Are my proofs correct? Is there a simpler way to prove the same thing or even just argument the same results in a better, more intuitive way? A BONUS QUESTION How can I test these theoretical results with the following example? (In order to really ""see"" what I found) is the outcome of the fair coin ""COIN"": if Heads , if Tails . is the outcome of the 6-faced fair dice ""DICE1"": is the outcome of the 6-faced fair dice ""DICE2"": SOMETHING THAT PERPLEXES ME Intuitively and ""constructively"", I would say that the event to observe is independent from that of observing , infact the first is the event of obtaining with a throw of DICE1 and a toss of COIN while the second is the event of obtaining with a throw of DICE2 and a different toss of COIN: these two ""procedures"" are totally independent from each other and so should be their probabilities (?) But this contradicts my analytical results, doesn't it! Why is that?","X_0 X_1 X_2 D_1 D_2 D_1 = X_1 + X_0\\[1ex]
D_2 = X_2 + X_0 D_1 D_2 D_1|X_0=x_0 D_2|X_0=x_0 D_1 D_2 \text{Cov}(D_1,D_2)=0 \text{Cov}(D_1, D_2)=\mathbb{E}[D_1 D_2]-\mathbb{E}[D_1]\mathbb{E}[D_2] =\\
=\mathbb{E}\left[ (X_1+X_0)(X_2+X_0) \right] - \mathbb{E}\left[ X_1+X_0 \right]\mathbb{E}\left[ X_2+X_0 \right]=\\
=\mathbb{E}\left[ X_1 X_2 + X_1 X_0 + X_0 X_2 + X_0^2 \right] - \mathbb{E}\left[ X_1 \right]\mathbb{E}\left[ X_2 \right] - \mathbb{E}\left[ X_1 \right]\mathbb{E}\left[ X_0 \right] - \mathbb{E}\left[ X_0 \right]\mathbb{E}\left[ X_2 \right] - \left(\mathbb{E}\left[ X_0 \right]\right)^2=\\
=\mathbb{E}\left[ X_1 \right]\mathbb{E}\left[ X_2 \right] + \mathbb{E}\left[ X_1 \right]\mathbb{E}\left[ X_0 \right] + \mathbb{E}\left[ X_0 \right]\mathbb{E}\left[ X_2 \right] + \mathbb{E}\left[ X_0^2 \right] - \mathbb{E}\left[ X_1 \right]\mathbb{E}\left[ X_2 \right] - \mathbb{E}\left[ X_1 \right]\mathbb{E}\left[ X_0 \right] - \mathbb{E}\left[ X_0 \right]\mathbb{E}\left[ X_2 \right] - \left(\mathbb{E}\left[ X_0 \right]\right)^2=\\
=\mathbb{E}\left[ X_0^2 \right] - \left(\mathbb{E}\left[ X_0 \right]\right)^2 = \text{Var}(X_0)\neq 0 X_0 = \text{constant} \mathbf{D_1} \mathbf{D_2} X_0 = x_0 \mathbf{D_1|X_0 =x_0} \mathbf{D_2|X_0 =x_0} X_0 X_0=1 X_0=0 X_1 X_1=\{1,2,3,4,5,6\} X_2 X_2=\{1,2,3,4,5,6\} D_1=k D_2 = h X_1 + X_0 = k X_2 + X_0 = k","['probability', 'statistics', 'conditional-probability', 'variance', 'covariance']"
80,How to evaluate cumulative distribution function w/ sigma of given SRS?,How to evaluate cumulative distribution function w/ sigma of given SRS?,,"I have been given a set of 10 positive values that make up an SRS (Simple Random Sample) of a population, which has a normal distribution. I then am asked to evaluate $a = \sum_{i=1}^n\frac{(x_{i}-\mu)^2}{\sigma^2}$ and provide the distribution. Since it is a sum, I assumed a would simply be a number. Finally, I am asked to evaluate the following CDF: P ( $\sum_{i=1}^n\frac{(x_{i}-\mu)^2}{\sigma^2} \le a$ ). How should I interpret this? If the values in the SRS are all positive, then how could any subset less than the size of $n$ have the value of $a$ ? Wouldn't the probability of this just be $1$ ?","I have been given a set of 10 positive values that make up an SRS (Simple Random Sample) of a population, which has a normal distribution. I then am asked to evaluate and provide the distribution. Since it is a sum, I assumed a would simply be a number. Finally, I am asked to evaluate the following CDF: P ( ). How should I interpret this? If the values in the SRS are all positive, then how could any subset less than the size of have the value of ? Wouldn't the probability of this just be ?",a = \sum_{i=1}^n\frac{(x_{i}-\mu)^2}{\sigma^2} \sum_{i=1}^n\frac{(x_{i}-\mu)^2}{\sigma^2} \le a n a 1,['statistics']
81,"What does the term ""unbiased estimator"" mean?","What does the term ""unbiased estimator"" mean?",,"In my textbook for my statistics class, it says that $s^2$ , sample variance is a ""unbiased estimator"" for population variance, $\sigma^2$ . Does this mean that when we use $s^2$ as a point estimator for $\sigma^2$ , it precisely equals $\sigma^2$ ? So $s^2$ is not even an estimation/approximation for $\sigma^2$ ? What does unbiased estimator mean? Thank You!","In my textbook for my statistics class, it says that , sample variance is a ""unbiased estimator"" for population variance, . Does this mean that when we use as a point estimator for , it precisely equals ? So is not even an estimation/approximation for ? What does unbiased estimator mean? Thank You!",s^2 \sigma^2 s^2 \sigma^2 \sigma^2 s^2 \sigma^2,[]
82,What kind of distribution should I use to this question?,What kind of distribution should I use to this question?,,"From every 200 students in High School, 20 students failed. If we were to pick 40 students from the class. Calculate: (a) the probability of getting 8 failed students. (b) the expected value for the failed students out of 40 students. Should I use binomial distribution or hypergeometric?","From every 200 students in High School, 20 students failed. If we were to pick 40 students from the class. Calculate: (a) the probability of getting 8 failed students. (b) the expected value for the failed students out of 40 students. Should I use binomial distribution or hypergeometric?",,"['probability', 'statistics', 'statistical-inference', 'binomial-distribution']"
83,Why does calculating probabilities intuitively result in differences from Bayesian calculations?,Why does calculating probabilities intuitively result in differences from Bayesian calculations?,,"As an example, say you're asked to solve for the following problem: You have three bags, labeled A, B, and C. Bag A contains two red marbles and three blue marbles. Bag B contains five red marbles and one blue marble. Bag C contains three red marbles only. Suppose a bag is randomly selected (again, with equal probability), but you do not know which it is. You randomly draw a marble and observe that it is blue. What is the probability that the bag you selected this marble from is A? I understand that you can calculate P(A|blue) using Baye's Theorem which would ask me to solve for P(blue|A) * P(A) / P(blue) which comes out to be 0.78. However, if I were to be asked this question outside the context of a class on bayesian statistics, I would think that the probability would be 0.75 or 3/4 since there are 4 blue marbles between the three bags. Since there is an equal chance of drawing from either bag, couldn't we disregard the probability of drawing from a given bag and focus on the distribution of blue marbles between bags? What is the error in my thinking here?","As an example, say you're asked to solve for the following problem: You have three bags, labeled A, B, and C. Bag A contains two red marbles and three blue marbles. Bag B contains five red marbles and one blue marble. Bag C contains three red marbles only. Suppose a bag is randomly selected (again, with equal probability), but you do not know which it is. You randomly draw a marble and observe that it is blue. What is the probability that the bag you selected this marble from is A? I understand that you can calculate P(A|blue) using Baye's Theorem which would ask me to solve for P(blue|A) * P(A) / P(blue) which comes out to be 0.78. However, if I were to be asked this question outside the context of a class on bayesian statistics, I would think that the probability would be 0.75 or 3/4 since there are 4 blue marbles between the three bags. Since there is an equal chance of drawing from either bag, couldn't we disregard the probability of drawing from a given bag and focus on the distribution of blue marbles between bags? What is the error in my thinking here?",,"['statistics', 'bayesian']"
84,Calculating the Rolling Variance of a set of numbers,Calculating the Rolling Variance of a set of numbers,,"I would like to subscribe to a WebSocket stream which will supply me with many numbers per second. From this data, I would like to calculate the variance of say the last 1000 numbers. How can I do this in a rolling fashion? That is, I would like some computation comparable to this one for the mean of the last 1000 numbers: $$\rm{mean}_{i+1} = \rm{mean}_{i} + \frac{1}{1000}\left(x_{i+1}-x_{i-999}\right)$$ Thanks in advance for any help. Ben","I would like to subscribe to a WebSocket stream which will supply me with many numbers per second. From this data, I would like to calculate the variance of say the last 1000 numbers. How can I do this in a rolling fashion? That is, I would like some computation comparable to this one for the mean of the last 1000 numbers: Thanks in advance for any help. Ben",\rm{mean}_{i+1} = \rm{mean}_{i} + \frac{1}{1000}\left(x_{i+1}-x_{i-999}\right),['statistics']
85,Distribution of sum of product of normal random variables.,Distribution of sum of product of normal random variables.,,"The distribution of a product $Z=XY$ of two normally distributed random variables is given by the product distribution https://mathworld.wolfram.com/NormalProductDistribution.html . What is the distribution of $Q=\sum_{i=1}^n Z_i$ , where $Z_i= X_i Y_i$ , and $X_i,Y_i\sim \mathcal N(0,\sigma_i)$ ? A nice answer was given in: Distribution of sum of product-normal distributions. by @wolfies, for the case where $\sigma_i=1$ (that is, all the $X_i,Y_i$ are identically distributed standard normal). The distribution can be expressed in terms of the modified Bessel function of the second kind. And as $n\to\infty$ , the distribution approaches a normal distribution. But I am interested in the case where the $\sigma_i$ are different. If no-closed form solution can be found, I am curious about when $p(Q)$ will approach a normal distribution. Is there an ""effective"" $n$ in terms of the $\sigma_i$ ? My first guess was the participation ratio $n_\text{eff} = (\sum_{i=1}^n \sigma_i^2)^2/\sum_{i=1}^n \sigma_i^4$ . Here is how I've approached it so far. The characteristic function of each $Z_i$ is given, I believe, by $$\varphi_{Z_i}(t)=\frac{1}{\sqrt{t^2\sigma_i^2 + 1}}$$ So by independence the characteristic function of $Q$ is given by $$ \varphi_Q(t) = \prod_{i=1}^n\varphi_{Z_i}(t) = \prod_{i=1}^n \frac{1}{\sqrt{t^2\sigma_i^2 + 1}}$$ And $p(Q)$ should be given by the inverse Fourier transform of $\varphi_Q(t)$ . I am stuck trying to perform the inverse Fourier transform, and any help would be greatly appreciated! edit: @Henry gave a very nice answer regarding the asymptotic behavior of $p(Q)$ as $n\to\infty$ . but I am still curious about the behavior of $p(Q)$ for $n$ small. Can $p(Q)$ be computed exactly? If not, how large must $n$ be before $p(Q)$ is approximately normal, as a function of the $\{\sigma_i\}$ ?","The distribution of a product of two normally distributed random variables is given by the product distribution https://mathworld.wolfram.com/NormalProductDistribution.html . What is the distribution of , where , and ? A nice answer was given in: Distribution of sum of product-normal distributions. by @wolfies, for the case where (that is, all the are identically distributed standard normal). The distribution can be expressed in terms of the modified Bessel function of the second kind. And as , the distribution approaches a normal distribution. But I am interested in the case where the are different. If no-closed form solution can be found, I am curious about when will approach a normal distribution. Is there an ""effective"" in terms of the ? My first guess was the participation ratio . Here is how I've approached it so far. The characteristic function of each is given, I believe, by So by independence the characteristic function of is given by And should be given by the inverse Fourier transform of . I am stuck trying to perform the inverse Fourier transform, and any help would be greatly appreciated! edit: @Henry gave a very nice answer regarding the asymptotic behavior of as . but I am still curious about the behavior of for small. Can be computed exactly? If not, how large must be before is approximately normal, as a function of the ?","Z=XY Q=\sum_{i=1}^n Z_i Z_i= X_i Y_i X_i,Y_i\sim \mathcal N(0,\sigma_i) \sigma_i=1 X_i,Y_i n\to\infty \sigma_i p(Q) n \sigma_i n_\text{eff} = (\sum_{i=1}^n \sigma_i^2)^2/\sum_{i=1}^n \sigma_i^4 Z_i \varphi_{Z_i}(t)=\frac{1}{\sqrt{t^2\sigma_i^2 + 1}} Q  \varphi_Q(t) = \prod_{i=1}^n\varphi_{Z_i}(t) = \prod_{i=1}^n \frac{1}{\sqrt{t^2\sigma_i^2 + 1}} p(Q) \varphi_Q(t) p(Q) n\to\infty p(Q) n p(Q) n p(Q) \{\sigma_i\}","['statistics', 'probability-distributions', 'normal-distribution', 'central-limit-theorem', 'characteristic-functions']"
86,Is this a statistic?,Is this a statistic?,,"If I have $n$ random variables, $X_1,X_2,...,X_n$ . Is this a statistic: $$\Theta = 1/2(X_1+X_2)$$ I know the definition of statistic is the random variable represented by a function on my $n$ random variables, since I cannot think of a function on $n$ R.Vs that would yield this surely it is not a statistic?","If I have random variables, . Is this a statistic: I know the definition of statistic is the random variable represented by a function on my random variables, since I cannot think of a function on R.Vs that would yield this surely it is not a statistic?","n X_1,X_2,...,X_n \Theta = 1/2(X_1+X_2) n n","['statistics', 'random-variables']"
87,Why is the distribution of the x coordinate of a point randomly selected from the circumference the unit cricle not uniform?,Why is the distribution of the x coordinate of a point randomly selected from the circumference the unit cricle not uniform?,,"I am currently attempting to solve a question which deals with the distribution of the $x$ and $y$ coordinates of a randomly chosen point from the circumference  of the unit circle. When I first attempted the question I thought that since point is chosen at random, it would follow that it is uniformly distributed on the circumference of the circle, and moreover, its $x$ and $y$ coordinates will be uniformly distributed on the region $[-1,1]$ . However, this is wrong. I have found a couple of threads in regards to this issue, where the answers suggest one uses the fact that $x=\cos \theta$ and start from there. My issue is that this was not my original thought and that without going through the algebra with $x=\cos \theta$ I wouldn't be able to say why the distribution of $x$ (and $y$ for that mater) are not uniform. Could someone explain to me how can I intuitively rebutle the idea that $x$ (and $y$ ) are uniformly distributed, without involving calculation?","I am currently attempting to solve a question which deals with the distribution of the and coordinates of a randomly chosen point from the circumference  of the unit circle. When I first attempted the question I thought that since point is chosen at random, it would follow that it is uniformly distributed on the circumference of the circle, and moreover, its and coordinates will be uniformly distributed on the region . However, this is wrong. I have found a couple of threads in regards to this issue, where the answers suggest one uses the fact that and start from there. My issue is that this was not my original thought and that without going through the algebra with I wouldn't be able to say why the distribution of (and for that mater) are not uniform. Could someone explain to me how can I intuitively rebutle the idea that (and ) are uniformly distributed, without involving calculation?","x y x y [-1,1] x=\cos \theta x=\cos \theta x y x y","['probability', 'statistics', 'probability-distributions', 'uniform-distribution']"
88,The p-value of the test statistic in this problem is approximately equal to:,The p-value of the test statistic in this problem is approximately equal to:,,"A survey claims that more than 8 out of 10 doctors recommend aspirin for their patients with headaches. To test this claim, a random sample of 100 doctors’ results in 86 who indicate that they recommend aspirin. A. 0.0521 B. 0.0802 C. 0.1231 D. 0.0721 E. 0.0668 So far I got: Ho: P= 0.8 H1: P> 0.8 Z= (0.86-0.8)/0.4 = 1.50 If z= 1.50, cumulative probability is 0.9332 p-value= 2P(Z>zo) = 2(1-0.9332)=0.1336 Correct answer seems to be 0.0668, which is half of 0.1336. Not sure where I went wrong","A survey claims that more than 8 out of 10 doctors recommend aspirin for their patients with headaches. To test this claim, a random sample of 100 doctors’ results in 86 who indicate that they recommend aspirin. A. 0.0521 B. 0.0802 C. 0.1231 D. 0.0721 E. 0.0668 So far I got: Ho: P= 0.8 H1: P> 0.8 Z= (0.86-0.8)/0.4 = 1.50 If z= 1.50, cumulative probability is 0.9332 p-value= 2P(Z>zo) = 2(1-0.9332)=0.1336 Correct answer seems to be 0.0668, which is half of 0.1336. Not sure where I went wrong",,"['probability', 'statistics', 'probability-distributions', 'statistical-inference', 'hypothesis-testing']"
89,Find UMVU estimators for an exponential distribution,Find UMVU estimators for an exponential distribution,,"Let $X_1, \ldots,X_n$ be iid from an exponential distribution with density $$ f(x)=\begin{cases}\theta e^{-\theta x},&x>0, \\ 0,&\text{otherwise}.\end{cases}$$ Find UMVU estimators for $\theta$ and $\theta^2$ . $$f(\textbf x\mid\theta)=\displaystyle \prod\theta e^{-\theta x_i}1 \{x_i>0\} = \underbrace{\theta^ne^{-\theta\sum x_i}} \underbrace{1\{x_{(1)}>0\}}$$ so $\sum x_i$ is sufficient. But I do not know how to show it is complete. If this is the right way to find UMVU estimators, could someone teach me how to show if $\sum x_i$ is complete? And if it isn't how do you find an UMVU estimator?","Let be iid from an exponential distribution with density Find UMVU estimators for and . so is sufficient. But I do not know how to show it is complete. If this is the right way to find UMVU estimators, could someone teach me how to show if is complete? And if it isn't how do you find an UMVU estimator?","X_1, \ldots,X_n 
f(x)=\begin{cases}\theta e^{-\theta x},&x>0, \\ 0,&\text{otherwise}.\end{cases} \theta \theta^2 f(\textbf x\mid\theta)=\displaystyle \prod\theta e^{-\theta x_i}1 \{x_i>0\} = \underbrace{\theta^ne^{-\theta\sum x_i}} \underbrace{1\{x_{(1)}>0\}} \sum x_i \sum x_i",['statistics']
90,"Simplify $\sum_{i=1}^n\frac{a}{\theta-x_i}$ where $\{x_i\}\in(0,\theta)$ and $a\in(-1,0]$",Simplify  where  and,"\sum_{i=1}^n\frac{a}{\theta-x_i} \{x_i\}\in(0,\theta) a\in(-1,0]","I have this problem where I need to solve $-\frac{n(1+a)}{\theta}+\sum_{i=1}^n\frac{a}{\theta-x_i}=0 $ for $\theta$ (the solution is allowed to be in terms of the mean of $x_1,..., x_n$ ), provided  that $\{x_i\}\in(0,\theta)$ and $a\in(-1,0]$ . I really have no idea how to simplify the summation. Maybe I'm just missing something simple?","I have this problem where I need to solve for (the solution is allowed to be in terms of the mean of ), provided  that and . I really have no idea how to simplify the summation. Maybe I'm just missing something simple?","-\frac{n(1+a)}{\theta}+\sum_{i=1}^n\frac{a}{\theta-x_i}=0  \theta x_1,..., x_n \{x_i\}\in(0,\theta) a\in(-1,0]","['real-analysis', 'sequences-and-series', 'statistics', 'summation']"
91,"The PDF of $X$ is $\frac{1+\theta x}{2}$ for $x\in [-1,1], \theta \in[-1,1]$. Is the Method of Moments estimator of $\theta$ consistent?",The PDF of  is  for . Is the Method of Moments estimator of  consistent?,"X \frac{1+\theta x}{2} x\in [-1,1], \theta \in[-1,1] \theta","We know that the method of moments estimator, $\hat{\theta}_n(\textbf{X})$ , is consistent if $$\lim_{n\to \infty}\mathbb{P}(|\hat{\theta}_n(\textbf{X})-\theta|>\epsilon)=0$$ . We know that $\mathbb{E}(X;\theta)=\frac{1}{2}\int_{-1}^1(x+\theta x^2) dx=\frac{\theta}{3}$ , so $\hat{\theta}_n(\textbf{X})=3\bar{X}$ . Therefore $\lim_{n\to \infty}\mathbb{P}(|\hat{\theta}_n(\textbf{X})-\theta|>\epsilon)= \lim _{n\to \infty}\mathbb{P}(|3\bar{X}-\theta|>\epsilon) $ . At this point I'm not sure how to proceed? I've tried using Chebyshev's inequality but this doesn't lead anywhere. I know that if a sequence in random variables converges in distribution to a constant then that is equivalent to  a sequence in random variables converging in probability to that constant. Now $\lim_{n\to \infty}\mathbb{P}(\hat{\theta}_n(\textbf{X})\leq x)= \lim_{n\to \infty}\mathbb{P}(3\bar{X}\leq x)$ and I don't think this equals $\mathbb{P}(\theta\leq x)$ ? So would I be right in saying the method of moments estimator is not consistent?","We know that the method of moments estimator, , is consistent if . We know that , so . Therefore . At this point I'm not sure how to proceed? I've tried using Chebyshev's inequality but this doesn't lead anywhere. I know that if a sequence in random variables converges in distribution to a constant then that is equivalent to  a sequence in random variables converging in probability to that constant. Now and I don't think this equals ? So would I be right in saying the method of moments estimator is not consistent?",\hat{\theta}_n(\textbf{X}) \lim_{n\to \infty}\mathbb{P}(|\hat{\theta}_n(\textbf{X})-\theta|>\epsilon)=0 \mathbb{E}(X;\theta)=\frac{1}{2}\int_{-1}^1(x+\theta x^2) dx=\frac{\theta}{3} \hat{\theta}_n(\textbf{X})=3\bar{X} \lim_{n\to \infty}\mathbb{P}(|\hat{\theta}_n(\textbf{X})-\theta|>\epsilon)= \lim _{n\to \infty}\mathbb{P}(|3\bar{X}-\theta|>\epsilon)  \lim_{n\to \infty}\mathbb{P}(\hat{\theta}_n(\textbf{X})\leq x)= \lim_{n\to \infty}\mathbb{P}(3\bar{X}\leq x) \mathbb{P}(\theta\leq x),"['probability-theory', 'statistics', 'probability-distributions', 'statistical-inference']"
92,Find $E[Y\mid X=x]$,Find,E[Y\mid X=x],"Let $(X,Y)$ $$f(x,y)=\frac{x^2}{4}\hspace{1cm} 0\leq y\leq x\leq 2$$ Find $E[Y\mid X=x]$ I know $$\dfrac{f(x,y)}{f_X(x)}=\frac{x^2/4}{x^3/4}=\frac{1}{x}$$ My question is about the limits of integration, I don't know if they are $[0,2]$ $$E[Y\mid X=x]=\int_0^2y\cdot\frac{1}{x}\,dy$$ or $[0,x]$ $$E[Y\mid X=x]=\int_0^x y\cdot\frac{1}{x}\,dy$$","Let Find I know My question is about the limits of integration, I don't know if they are or","(X,Y) f(x,y)=\frac{x^2}{4}\hspace{1cm} 0\leq y\leq x\leq 2 E[Y\mid X=x] \dfrac{f(x,y)}{f_X(x)}=\frac{x^2/4}{x^3/4}=\frac{1}{x} [0,2] E[Y\mid X=x]=\int_0^2y\cdot\frac{1}{x}\,dy [0,x] E[Y\mid X=x]=\int_0^x y\cdot\frac{1}{x}\,dy","['probability', 'statistics', 'expected-value', 'conditional-expectation']"
93,Slutsky's theorem and the asymptotic normality of MLE,Slutsky's theorem and the asymptotic normality of MLE,,"I understand that $$\left[I(\theta_0)\right]^{1/2}(\hat{\theta}-\theta_0)\overset{d}{\rightarrow}N(0,1),$$ where $I(\theta_0)$ is the Fisher information at $\theta_0$ , $\hat{\theta}$ is a MLE of $\theta$ . My note says $I(\theta_0)$ can be replaced by $I(\hat{\theta})$ justified by Slutsky's theorem. Here is my proof: $$I(\hat{\theta})^{1/2}(\hat{\theta}-\theta_0)=I(\hat{\theta})^{1/2}I(\theta_0)^{-1/2}I(\theta_0)^{1/2}(\hat{\theta}-\theta_0)\overset{d}{\rightarrow}N(0,1),$$ since $I(\hat{\theta})^{1/2}I(\theta_0)^{-1/2}\overset{p}{\rightarrow}1$ , we have $$\left[I(\hat{\theta})\right]^{1/2}(\hat{\theta}-\theta_0)\overset{d}{\rightarrow}N(0,1)$$ Is this correct? If not, what part is wrong? In this proof, I used $I(\hat{\theta})^{1/2}I(\theta_0)^{-1/2}\overset{p}{\rightarrow}1$ . This hold when $\hat{\theta}\overset{p}{\rightarrow}\theta_0\implies I(\hat{\theta})^{1/2}\overset{p}{\rightarrow}I(\theta_0)^{1/2}$ . Is $I(\theta)$ always continuous for it to hold, or the continuity of $I(\theta)$ is an assumption we need to make?","I understand that where is the Fisher information at , is a MLE of . My note says can be replaced by justified by Slutsky's theorem. Here is my proof: since , we have Is this correct? If not, what part is wrong? In this proof, I used . This hold when . Is always continuous for it to hold, or the continuity of is an assumption we need to make?","\left[I(\theta_0)\right]^{1/2}(\hat{\theta}-\theta_0)\overset{d}{\rightarrow}N(0,1), I(\theta_0) \theta_0 \hat{\theta} \theta I(\theta_0) I(\hat{\theta}) I(\hat{\theta})^{1/2}(\hat{\theta}-\theta_0)=I(\hat{\theta})^{1/2}I(\theta_0)^{-1/2}I(\theta_0)^{1/2}(\hat{\theta}-\theta_0)\overset{d}{\rightarrow}N(0,1), I(\hat{\theta})^{1/2}I(\theta_0)^{-1/2}\overset{p}{\rightarrow}1 \left[I(\hat{\theta})\right]^{1/2}(\hat{\theta}-\theta_0)\overset{d}{\rightarrow}N(0,1) I(\hat{\theta})^{1/2}I(\theta_0)^{-1/2}\overset{p}{\rightarrow}1 \hat{\theta}\overset{p}{\rightarrow}\theta_0\implies I(\hat{\theta})^{1/2}\overset{p}{\rightarrow}I(\theta_0)^{1/2} I(\theta) I(\theta)","['probability-theory', 'statistics', 'asymptotics', 'maximum-likelihood', 'fisher-information']"
94,hint on a solved old exam question on probabilistic methods calcualation,hint on a solved old exam question on probabilistic methods calcualation,,"In my note I have some previous exam solved question as follows in Probabilistic methods section: Example: We have $k$ classes $C_1, C_2,...,C_k$ where each $C_i$ has uniform distribution over $-(2^{i-2})<x<2^{i-2}$ . by using maximum likelihood ratio test, then $ \lim_{k\rightarrow \infty} $ P $(error)= \frac{1}{2}$ $ \frac{1}{2}$ is Calculated by following idea: ** My challenge is I couldn't understand the logic of this answer. is there any intuitive idea to better understand here? **","In my note I have some previous exam solved question as follows in Probabilistic methods section: Example: We have classes where each has uniform distribution over . by using maximum likelihood ratio test, then P is Calculated by following idea: ** My challenge is I couldn't understand the logic of this answer. is there any intuitive idea to better understand here? **","k C_1, C_2,...,C_k C_i -(2^{i-2})<x<2^{i-2}  \lim_{k\rightarrow \infty}  (error)= \frac{1}{2}  \frac{1}{2}","['statistics', 'probability-distributions', 'computer-science', 'machine-learning', 'probabilistic-method']"
95,Convergence almost surely question,Convergence almost surely question,,"Suppose you have a sequence of independent random variables { $X_i, i\geq1$ }, such that $$\Bbb P(X_i=i^2 -1)=i^{-2},$$ $$ \Bbb P(X_i=-1)=1-i^{-2}.$$ Then, $\frac1n \sum_{i=1}^n X_i$ converges almost surely to a constant c. Find the value of c. For this question, I thought of applying the strong law of large numbers which says: $$ \frac1n \sum_{i=1}^n X_i$$ converges almost surely to $\mu$ , where { $X_i, i\geq1$ } is a sequence of IID random variables whose mean $\mu$ exists. However, for the question above, $\mu=0$ . But c is not equal to $0$ . c is, in fact, equal to -1. Any clarification on this would greatly be appreciated, as I'm not sure how $c=-1$ .","Suppose you have a sequence of independent random variables { }, such that Then, converges almost surely to a constant c. Find the value of c. For this question, I thought of applying the strong law of large numbers which says: converges almost surely to , where { } is a sequence of IID random variables whose mean exists. However, for the question above, . But c is not equal to . c is, in fact, equal to -1. Any clarification on this would greatly be appreciated, as I'm not sure how .","X_i, i\geq1 \Bbb P(X_i=i^2 -1)=i^{-2},  \Bbb P(X_i=-1)=1-i^{-2}. \frac1n \sum_{i=1}^n X_i  \frac1n \sum_{i=1}^n X_i \mu X_i, i\geq1 \mu \mu=0 0 c=-1","['probability-theory', 'statistics', 'convergence-divergence', 'borel-cantelli-lemmas']"
96,Calculating conditional variance using two different methods,Calculating conditional variance using two different methods,,"The stock prices of two companies at the end of any given year are modeled with random variables $X$ and $Y$ that follow a distribution with joint density function $f(x, y) = 2x$ for $0<x<1, x<y<x+1$ and $0$ otherwise. What is the conditional variance of $Y$ given $X=x$ ? My attempt : $$Var[Y|X=x] = E[Y^2|X=x] - (E[Y|X=x])^2$$ Now, $E[Y^2|X=x] = \int_0^2y^2\cdot f(y|X=x) \; dy$ . Note that $f(y|X=x) = \dfrac{f(x,y)}{f_X(x)} = \dfrac{2x}{\int_x^{x+1}2x \; dy} = 1$ . So, $E[Y^2|X=x] = \int_0^2y^2 \; dy = \dfrac{8}{3}$ . Next, $E[Y|X=x] = \int_0^2y\cdot f(y|X=x) \; dy = \int_0^2y\; dy = 2$ . So, $Var[Y|X=x] = \dfrac{8}{3} - 4 = \dfrac{-4}{3}$ which is not the correct answer. Where have I gone wrong? Alternatively, when I recognize that $f(y|X=x) = 1 \implies W \sim Unif[0, 2]$ where $W = Y|X=x$ , I can use the formula for the variance of a uniform distribution to calculate the conditional variance as follows: $$Var[W] = \frac{(2-0)^2}{12} = \frac{1}{3}$$ which is not the correct answer either. Where have I gone wrong with this approach? Thanks!","The stock prices of two companies at the end of any given year are modeled with random variables and that follow a distribution with joint density function for and otherwise. What is the conditional variance of given ? My attempt : Now, . Note that . So, . Next, . So, which is not the correct answer. Where have I gone wrong? Alternatively, when I recognize that where , I can use the formula for the variance of a uniform distribution to calculate the conditional variance as follows: which is not the correct answer either. Where have I gone wrong with this approach? Thanks!","X Y f(x, y) = 2x 0<x<1, x<y<x+1 0 Y X=x Var[Y|X=x] = E[Y^2|X=x] - (E[Y|X=x])^2 E[Y^2|X=x] = \int_0^2y^2\cdot f(y|X=x) \; dy f(y|X=x) = \dfrac{f(x,y)}{f_X(x)} = \dfrac{2x}{\int_x^{x+1}2x \; dy} = 1 E[Y^2|X=x] = \int_0^2y^2 \; dy = \dfrac{8}{3} E[Y|X=x] = \int_0^2y\cdot f(y|X=x) \; dy = \int_0^2y\; dy = 2 Var[Y|X=x] = \dfrac{8}{3} - 4 = \dfrac{-4}{3} f(y|X=x) = 1 \implies W \sim Unif[0, 2] W = Y|X=x Var[W] = \frac{(2-0)^2}{12} = \frac{1}{3}","['probability', 'statistics', 'solution-verification', 'variance', 'actuarial-science']"
97,"Getting Standard Deviation of Population from s. d. of individual samples. Given mean and standard deviation of samples, with no access to data.","Getting Standard Deviation of Population from s. d. of individual samples. Given mean and standard deviation of samples, with no access to data.",,"I know mean and standard deviation of individual samples (let say $10$ data points each, and no access to the underlying data); could I get the standard deviation of the population (let say $100$ samples) from the standard deviation of the individual samples? Which is the relationship? EDIT Thanks to BruceET's Answer . I've applied approach- $2$ to our data, and I'm just a little puzzled on results I get when calculating $S_{all}$ . I would expect that $S_{all}$ is greater than the average of the individual $S_{n}$ (since there is a spread as well of the mean of subsets); on the contrary I get an $S_{all}$ that is smaller. How this should be understood? Processed Data","I know mean and standard deviation of individual samples (let say data points each, and no access to the underlying data); could I get the standard deviation of the population (let say samples) from the standard deviation of the individual samples? Which is the relationship? EDIT Thanks to BruceET's Answer . I've applied approach- to our data, and I'm just a little puzzled on results I get when calculating . I would expect that is greater than the average of the individual (since there is a spread as well of the mean of subsets); on the contrary I get an that is smaller. How this should be understood? Processed Data",10 100 2 S_{all} S_{all} S_{n} S_{all},"['statistics', 'statistical-inference', 'means', 'standard-deviation']"
98,Problems to understand the definition of the level of significance $\alpha$,Problems to understand the definition of the level of significance,\alpha,"I'm having problems to understand the definition of the level of significance $\alpha$ . I thought I knew what $\alpha$ is but I realized I don't. When I stated to study statistics by myself I read this introductory book and everything was fine, the definition is very clear. He says on page 290: You’re probably wondering, how small does a p-value have to be for us to achieve statistical significance? If we agree that a p-value of $0.0001$ is clearly statistically significant and a p-value of $0.50$ is not, there must be some point between $0.0001$ and $0.50$ where we cross the threshold between statistical significance and random chance. That point, measuring when something becomes rare enough to be called “unusual,” might vary a lot from person to person. We should agree in advance on a reasonable cutoff point. Statisticians call this cutoff point the significance level of a test and usually denote it with the Greek letter $\alpha$ (alpha) . For example, if $\alpha = 0.05$ we say we are doing a $5\%$ test and will call the results statistically significant if the p-value for the sample is smaller than $0.05$ . Often, short hand notation such as $P < 0.05$ is used to indicate that the p-value is less than $0.05$ , which means the results are significant at a $5\%$ level. Now, I'm studying about statistical inference, a more advanced subject, and I realized there are some concepts that don't exactly have the same definition as I studied before. The level of significance is an example. I'm reading this book and on page 352 he introduces the Neyman-Pearson lemma as a method to find the UMP test . Example: On the basis of a random sample of size $1$ from the p.d.f. $f(x;  \theta)=\theta x^{\theta-1},\ 0 < x < 1\ (\theta > 1)$ : For $\theta_1>\theta_0$ , the cutoff point is calculated by: ... $C=(1−\alpha)^{\frac{1}{\theta_0}}$ For $\theta_1<\theta_0$ , we have: ... $C = \alpha^{\frac{1}{\theta_0}}$ So in this second book, the cutoff point is not necessarily $\alpha$ , I'm confused. MY ATTEMPT TO UNDERSTAND WITH THE HELP OF THE ANSWERS The alpha is predetermined, but it doesn't mean I can't have a smaller rejection region. Then I end up having a smaller rejection region using NP lemma with the same level of significance alpha. Some introductory books let the cutoff point to be $\alpha$ by standard (why?), that's the reason of my confusion, I can shrink the rejection region keeping the value of $\alpha$ . Can someone say if I'm right?","I'm having problems to understand the definition of the level of significance . I thought I knew what is but I realized I don't. When I stated to study statistics by myself I read this introductory book and everything was fine, the definition is very clear. He says on page 290: You’re probably wondering, how small does a p-value have to be for us to achieve statistical significance? If we agree that a p-value of is clearly statistically significant and a p-value of is not, there must be some point between and where we cross the threshold between statistical significance and random chance. That point, measuring when something becomes rare enough to be called “unusual,” might vary a lot from person to person. We should agree in advance on a reasonable cutoff point. Statisticians call this cutoff point the significance level of a test and usually denote it with the Greek letter (alpha) . For example, if we say we are doing a test and will call the results statistically significant if the p-value for the sample is smaller than . Often, short hand notation such as is used to indicate that the p-value is less than , which means the results are significant at a level. Now, I'm studying about statistical inference, a more advanced subject, and I realized there are some concepts that don't exactly have the same definition as I studied before. The level of significance is an example. I'm reading this book and on page 352 he introduces the Neyman-Pearson lemma as a method to find the UMP test . Example: On the basis of a random sample of size from the p.d.f. : For , the cutoff point is calculated by: ... For , we have: ... So in this second book, the cutoff point is not necessarily , I'm confused. MY ATTEMPT TO UNDERSTAND WITH THE HELP OF THE ANSWERS The alpha is predetermined, but it doesn't mean I can't have a smaller rejection region. Then I end up having a smaller rejection region using NP lemma with the same level of significance alpha. Some introductory books let the cutoff point to be by standard (why?), that's the reason of my confusion, I can shrink the rejection region keeping the value of . Can someone say if I'm right?","\alpha \alpha 0.0001 0.50 0.0001 0.50 \alpha \alpha = 0.05 5\% 0.05 P < 0.05 0.05 5\% 1 f(x;
 \theta)=\theta x^{\theta-1},\ 0 < x < 1\ (\theta > 1) \theta_1>\theta_0 C=(1−\alpha)^{\frac{1}{\theta_0}} \theta_1<\theta_0 C = \alpha^{\frac{1}{\theta_0}} \alpha \alpha \alpha","['statistics', 'statistical-inference', 'hypothesis-testing']"
99,Distribution of $8n\operatorname{ln}(\sqrt{0.2\hat{p}} + \sqrt{0.8(1-\hat{p})} )$,Distribution of,8n\operatorname{ln}(\sqrt{0.2\hat{p}} + \sqrt{0.8(1-\hat{p})} ),"Let $X_1, ..., X_n$ be a random sample taken from a Bernoulli $(p)$ distribution. Consider $\hat{p} = (1/n)\sum_i X_i = \bar{X}_n$ as the estimator of $p$ . We wish to test $H_0: p=0.2$ against $H_1: p\neq 0.2$ using the statistic $$ 8nB = - 8n\operatorname{ln}(\sqrt{0.2\hat{p}} + \sqrt{0.8(1-\hat{p})} ) $$ where $B = -\operatorname{ln}(\sqrt{0.2\hat{p}} + \sqrt{0.8(1-\hat{p})} )$ is the Bhattacharya's distance . The Problem: Determine the asymptotic distribution of $8nB$ . I haven't been able to create any analytical solution to the problem. I have verified that $\hat{p}$ satisfies the WLLN, that is, $\hat{p} \stackrel{P}{\longrightarrow} p$ . Simulation (using R) suggests that $8nB$ converges in distribution to a $\chi^2_1$ : N <- 10^4 n <- 10^4  B_distr <- c()  for(i in 1:N){   X <- sample(0:1, n, prob=c(0.8, 0.2),replace=TRUE)   p_hat <- mean(X)    B <- -8*n*log(sqrt(0.2*p_hat) + sqrt(0.8*(1 - p_hat)))   B_distr <- c(B_distr, B) }  hist(B_distr) psych::describe(B_distr) ks.test(B_distr, p=""pchisq"", 1)","Let be a random sample taken from a Bernoulli distribution. Consider as the estimator of . We wish to test against using the statistic where is the Bhattacharya's distance . The Problem: Determine the asymptotic distribution of . I haven't been able to create any analytical solution to the problem. I have verified that satisfies the WLLN, that is, . Simulation (using R) suggests that converges in distribution to a : N <- 10^4 n <- 10^4  B_distr <- c()  for(i in 1:N){   X <- sample(0:1, n, prob=c(0.8, 0.2),replace=TRUE)   p_hat <- mean(X)    B <- -8*n*log(sqrt(0.2*p_hat) + sqrt(0.8*(1 - p_hat)))   B_distr <- c(B_distr, B) }  hist(B_distr) psych::describe(B_distr) ks.test(B_distr, p=""pchisq"", 1)","X_1, ..., X_n (p) \hat{p} = (1/n)\sum_i X_i = \bar{X}_n p H_0: p=0.2 H_1: p\neq 0.2 
8nB = - 8n\operatorname{ln}(\sqrt{0.2\hat{p}} + \sqrt{0.8(1-\hat{p})} )
 B = -\operatorname{ln}(\sqrt{0.2\hat{p}} + \sqrt{0.8(1-\hat{p})} ) 8nB \hat{p} \hat{p} \stackrel{P}{\longrightarrow} p 8nB \chi^2_1","['probability', 'statistics', 'probability-distributions', 'probability-limit-theorems']"
