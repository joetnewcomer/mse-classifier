,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Is a dense set always infinite?,Is a dense set always infinite?,,"Learning about dense sets the classical example is that of $\mathbb Q$ , the rationals, in $\mathbb R$ .  The same interpretation is valid for irrationals in $\mathbb R$ . I was wondering if a dense set needs to be infinite, because this is what intuition would suggest. Moreover, are dense sets always countably infinite?","Learning about dense sets the classical example is that of , the rationals, in .  The same interpretation is valid for irrationals in . I was wondering if a dense set needs to be infinite, because this is what intuition would suggest. Moreover, are dense sets always countably infinite?",\mathbb Q \mathbb R \mathbb R,"['real-analysis', 'general-topology']"
1,But what is a continuous function?,But what is a continuous function?,,"I have a very basic problem. I am confused about ""continuous function"" term. What really is a continuous function? A function that is continuous for all of its domain or for all real numbers? Let's say: $\ln|x|$ - the graph clearly says it's continuous for all real numbers except for $0$ which is not part of the domain. So is this function continuous or not? I could say same about $\tan{x}$ or $\frac{x+1}{x}$ And also what about: $\ln{x}$ - the graph clearly says it's continuous for all of its domain: $(0; \infty)$ - so is this $f$ continuous or not? Thanks for clarification.","I have a very basic problem. I am confused about ""continuous function"" term. What really is a continuous function? A function that is continuous for all of its domain or for all real numbers? Let's say: - the graph clearly says it's continuous for all real numbers except for which is not part of the domain. So is this function continuous or not? I could say same about or And also what about: - the graph clearly says it's continuous for all of its domain: - so is this continuous or not? Thanks for clarification.",\ln|x| 0 \tan{x} \frac{x+1}{x} \ln{x} (0; \infty) f,"['real-analysis', 'limits', 'continuity']"
2,"How to construct a bijection from $(0, 1)$ to $[0, 1]$? [duplicate]",How to construct a bijection from  to ? [duplicate],"(0, 1) [0, 1]","This question already has answers here : Closed 11 years ago . Possible Duplicate: Bijection between an open and a closed interval How do I define a bijection between $(0,1)$ and $(0,1]$? I wonder if I can cut the interval $(0,1)$ into three pieces: $(0, \frac{1}{3})\cup(\frac{1}{3},\frac{2}{3})\cup(\frac{2}{3},1)$, in which I'm able to map point $\frac{1}{3}$ and $\frac{2}{3}$ to $0$ and $1$ respectively. Now the question remained is how to build a bijection mapping from those three intervels to $(0,1)$. Or, my method just goes in a wrong direction. Any correct approaches?","This question already has answers here : Closed 11 years ago . Possible Duplicate: Bijection between an open and a closed interval How do I define a bijection between $(0,1)$ and $(0,1]$? I wonder if I can cut the interval $(0,1)$ into three pieces: $(0, \frac{1}{3})\cup(\frac{1}{3},\frac{2}{3})\cup(\frac{2}{3},1)$, in which I'm able to map point $\frac{1}{3}$ and $\frac{2}{3}$ to $0$ and $1$ respectively. Now the question remained is how to build a bijection mapping from those three intervels to $(0,1)$. Or, my method just goes in a wrong direction. Any correct approaches?",,['real-analysis']
3,"Finding the value of $\lim_{a\to \infty}\int_0^1 a^x x^a \,dx$",Finding the value of,"\lim_{a\to \infty}\int_0^1 a^x x^a \,dx","I'm trying to find the value of $$\lim_{a\to \infty}\int_0^1 a^x x^a \,dx$$ My attempt: Let $\epsilon  >0$ be given. $ x\mapsto a^{x}$ is continuous at $ 1$ so there is a $d_a\in ( 0,1)$ such that $|a^{x} -a|< \epsilon $ for all $ x\in [d_a,1]$ . WLOG, let $d_a<1/2$ . $ |\int _{0}^{1} x^{a} a^{x} \ dx-\ \int _{0}^{1} \ ax^{a} |=|\int _{0}^{1}\left( a^{x} -a\right) x^{a} \ dx|\leq |\int _{0}^{d}\left( a^{x} -a\right) x^{a} \ dx|+|\int _{d}^{1}\left( a^{x} -a\right) x^{a} \ dx|$ \begin{align*} \left|\int _{0}^{1} x^{a} a^{x} \ dx-\ \int _{0}^{1} \ ax^{a} \right| & \leq \left|\int _{0}^{d_a}\left( a^{x} -a\right) x^{a} \ dx\right|+\left|\int _{d_a}^{1}\left( a^{x} -a\right) x^{a} \ dx\right|\\  & \leq \int _{0}^{d_a}\left( a -a^{x}\right) x^{a} \ dx+\epsilon \left|\int _{d_a}^{1} x^{a} \ dx\right|\\  & \leq \int _{0}^{d_a}\left( a -a^{x}\right) x^{a} \ dx+\epsilon \\  & \leq \int _{0}^{1/2} a(1/2)^{a} \ dx-a\int _{0}^{d_a} x^{a} dx+\epsilon \\  & \leq a(1/2)^{a}  +\epsilon  \end{align*} $0\leq \lim _{a\rightarrow \infty }\inf |\int _{0}^{1} x^{a} a^{x} \ dx-\ \int _{0}^{1} \ ax^{a} |\leq \lim _{a\rightarrow \infty }\sup |\int _{0}^{1} x^{a} a^{x} \ dx-\ \int _{0}^{1} \ ax^{a} |\leq \epsilon $ Since this is true for every $\epsilon  >0,$ it follows that $ \lim _{a\rightarrow \infty }\int _{0}^{1} x^{a} a^{x} \ dx-\ \int _{0}^{1} \ ax^{a} =0$ . Is my proof correct? Thanks.","I'm trying to find the value of My attempt: Let be given. is continuous at so there is a such that for all . WLOG, let . Since this is true for every it follows that . Is my proof correct? Thanks.","\lim_{a\to \infty}\int_0^1 a^x x^a \,dx \epsilon  >0  x\mapsto a^{x}  1 d_a\in ( 0,1) |a^{x} -a|< \epsilon   x\in [d_a,1] d_a<1/2  |\int _{0}^{1} x^{a} a^{x} \ dx-\ \int _{0}^{1} \ ax^{a} |=|\int _{0}^{1}\left( a^{x} -a\right) x^{a} \ dx|\leq |\int _{0}^{d}\left( a^{x} -a\right) x^{a} \ dx|+|\int _{d}^{1}\left( a^{x} -a\right) x^{a} \ dx| \begin{align*}
\left|\int _{0}^{1} x^{a} a^{x} \ dx-\ \int _{0}^{1} \ ax^{a} \right| & \leq \left|\int _{0}^{d_a}\left( a^{x} -a\right) x^{a} \ dx\right|+\left|\int _{d_a}^{1}\left( a^{x} -a\right) x^{a} \ dx\right|\\
 & \leq \int _{0}^{d_a}\left( a -a^{x}\right) x^{a} \ dx+\epsilon \left|\int _{d_a}^{1} x^{a} \ dx\right|\\
 & \leq \int _{0}^{d_a}\left( a -a^{x}\right) x^{a} \ dx+\epsilon \\
 & \leq \int _{0}^{1/2} a(1/2)^{a} \ dx-a\int _{0}^{d_a} x^{a} dx+\epsilon \\
 & \leq a(1/2)^{a}  +\epsilon 
\end{align*} 0\leq \lim _{a\rightarrow \infty }\inf |\int _{0}^{1} x^{a} a^{x} \ dx-\ \int _{0}^{1} \ ax^{a} |\leq \lim _{a\rightarrow \infty }\sup |\int _{0}^{1} x^{a} a^{x} \ dx-\ \int _{0}^{1} \ ax^{a} |\leq \epsilon  \epsilon  >0,  \lim _{a\rightarrow \infty }\int _{0}^{1} x^{a} a^{x} \ dx-\ \int _{0}^{1} \ ax^{a} =0","['real-analysis', 'limits', 'solution-verification']"
4,Prove the existence of the square root of $2$.,Prove the existence of the square root of .,2,"I am trying to prove the existence of the square root of $2$.  I have some steps with a very vague explanation and I would like to clarify. The proof: Let $$S=\{x\in\mathbb R\mid x\geqslant 0 \text{ and } x^2<2\}.$$ I understand the proof of LUB, ∝   and so I am at the step where $\alpha^2=2$. I know that we are to prove by contradiction so we state let $\alpha^2 <2$ and $\alpha^2 >2$.  Now my instructor wants us to use the Archimedean Axiom $1/n = \varepsilon$. $(\alpha^2 + 1/n)^2$  then what.....","I am trying to prove the existence of the square root of $2$.  I have some steps with a very vague explanation and I would like to clarify. The proof: Let $$S=\{x\in\mathbb R\mid x\geqslant 0 \text{ and } x^2<2\}.$$ I understand the proof of LUB, ∝   and so I am at the step where $\alpha^2=2$. I know that we are to prove by contradiction so we state let $\alpha^2 <2$ and $\alpha^2 >2$.  Now my instructor wants us to use the Archimedean Axiom $1/n = \varepsilon$. $(\alpha^2 + 1/n)^2$  then what.....",,"['real-analysis', 'radicals']"
5,$\lim_{x\to0}\frac{e^x-1-x}{x^2}$ using only rules of algebra of limits.,using only rules of algebra of limits.,\lim_{x\to0}\frac{e^x-1-x}{x^2},I would like to solve that limit  solved using only rules of algebra of limits . $$\lim_{x\to0}\frac{e^x-1-x}{x^2}$$ All the answers in How to find $\lim\limits_{x\to0}\frac{e^x-1-x}{x^2}$ without using l'Hopital's rule nor any series expansion? do not fully address my question. A challenging limit problem for the level of student who knows that: $$\begin{align*} \lim\limits_{x\to +\infty} e^x&=+\infty\tag1\\ \lim\limits_{x\to -\infty} e^x&=0\tag2\\ \lim\limits_{x\to +\infty} \frac{e^x}{x^n}&=+\infty\tag3\\ \lim\limits_{x\to -\infty} x^ne^x&=0\tag4\\ \lim\limits_{x\to 0} \frac{e^x-1}{x}&=1\tag5 \end{align*}$$,I would like to solve that limit  solved using only rules of algebra of limits . $$\lim_{x\to0}\frac{e^x-1-x}{x^2}$$ All the answers in How to find $\lim\limits_{x\to0}\frac{e^x-1-x}{x^2}$ without using l'Hopital's rule nor any series expansion? do not fully address my question. A challenging limit problem for the level of student who knows that: $$\begin{align*} \lim\limits_{x\to +\infty} e^x&=+\infty\tag1\\ \lim\limits_{x\to -\infty} e^x&=0\tag2\\ \lim\limits_{x\to +\infty} \frac{e^x}{x^n}&=+\infty\tag3\\ \lim\limits_{x\to -\infty} x^ne^x&=0\tag4\\ \lim\limits_{x\to 0} \frac{e^x-1}{x}&=1\tag5 \end{align*}$$,,"['calculus', 'real-analysis', 'limits', 'contest-math', 'limits-without-lhopital']"
6,Does there exist a continuous bijective function $ \displaystyle f : \Bbb R \rightarrow \Bbb R − \{1\}$?,Does there exist a continuous bijective function ?, \displaystyle f : \Bbb R \rightarrow \Bbb R − \{1\},"This is my first time posting on here :) My question is this: Does there exist a continuous bijective function $f :\Bbb R → \Bbb R − \{1\}$? Explain yes or no... My thoughts: Let $ \displaystyle f:  A \rightarrow  B$ be a function Okay for there to be a bijective function, for every element in A, there must be a unique element mapping $A$ to $B$. Right? Well if that is the case, then the answer to the question is FALSE. Why? Because the cadinality of the domain of $A$ (which in this case is R) is GREATER than the cardinality of the co-domain which is ($\Bbb R-\{1\}$). Because this is so, there must be some duplicates such that two different elements in $A$ map to the same element in $B$. Does this make sense? Unfortunately, I would be happy with this answer but another question pops up in my mind. I have read in my textbook that the cardinality of $\Bbb N$ is equal to the cardinality of $\mathbb Z$ But how? Since $\Bbb N$ represents all natural numbers ($0,1,2,3...$) and $\mathbb Z$ represents all the integers ($...-3,-2,-1,0,1,2,3...$). Clearly the cardinality of $\mathbb Z$ is greater than N but still the two have equal cardinality. So tying that in with the question, my answer doesn't seem right anymore. Any guidence or help would be greatly appreciated!!! Thanks :)","This is my first time posting on here :) My question is this: Does there exist a continuous bijective function $f :\Bbb R → \Bbb R − \{1\}$? Explain yes or no... My thoughts: Let $ \displaystyle f:  A \rightarrow  B$ be a function Okay for there to be a bijective function, for every element in A, there must be a unique element mapping $A$ to $B$. Right? Well if that is the case, then the answer to the question is FALSE. Why? Because the cadinality of the domain of $A$ (which in this case is R) is GREATER than the cardinality of the co-domain which is ($\Bbb R-\{1\}$). Because this is so, there must be some duplicates such that two different elements in $A$ map to the same element in $B$. Does this make sense? Unfortunately, I would be happy with this answer but another question pops up in my mind. I have read in my textbook that the cardinality of $\Bbb N$ is equal to the cardinality of $\mathbb Z$ But how? Since $\Bbb N$ represents all natural numbers ($0,1,2,3...$) and $\mathbb Z$ represents all the integers ($...-3,-2,-1,0,1,2,3...$). Clearly the cardinality of $\mathbb Z$ is greater than N but still the two have equal cardinality. So tying that in with the question, my answer doesn't seem right anymore. Any guidence or help would be greatly appreciated!!! Thanks :)",,"['real-analysis', 'general-topology']"
7,Calculate $\lim_{x\to 0}\frac{\ln(\cos(2x))}{x\sin x}$,Calculate,\lim_{x\to 0}\frac{\ln(\cos(2x))}{x\sin x},Problems with calculating $$\lim_{x\rightarrow0}\frac{\ln(\cos(2x))}{x\sin x}$$ $$\lim_{x\rightarrow0}\frac{\ln(\cos(2x))}{x\sin x}=\lim_{x\rightarrow0}\frac{\ln(2\cos^{2}(x)-1)}{(2\cos^{2}(x)-1)}\cdot \left(\frac{\sin x}{x}\right)^{-1}\cdot\frac{(2\cos^{2}(x)-1)}{x^{2}}=0$$ Correct answer is -2. Please show where this time I've error.  Thanks in advance!,Problems with calculating $$\lim_{x\rightarrow0}\frac{\ln(\cos(2x))}{x\sin x}$$ $$\lim_{x\rightarrow0}\frac{\ln(\cos(2x))}{x\sin x}=\lim_{x\rightarrow0}\frac{\ln(2\cos^{2}(x)-1)}{(2\cos^{2}(x)-1)}\cdot \left(\frac{\sin x}{x}\right)^{-1}\cdot\frac{(2\cos^{2}(x)-1)}{x^{2}}=0$$ Correct answer is -2. Please show where this time I've error.  Thanks in advance!,,"['real-analysis', 'limits']"
8,What do you get when you sum over the smaller half of the harmonic series? [duplicate],What do you get when you sum over the smaller half of the harmonic series? [duplicate],,"This question already has answers here : The limit of truncated sums of harmonic series, $\lim\limits_{k\to\infty}\sum_{n=k+1}^{2k}{\frac{1}{n}}$ (12 answers) Closed 4 years ago . More specifically, how would you evaluate the below formula? $$\lim_{n\to\infty}\sum_{k=n/2}^{n}\frac{1}{k}$$ I know that the harmonic series starting at any point diverges, but when we limit it in this way, does the series diverge or converge? If it diverges: How might you determine that? Is there some $d$ that we can replace with $2$ to make the sequence converge? If it converges: What does it converge to, and how might you determine that? The sequence must converge for any $d>2$ . Is there a formula for the series generalized for any $d$ ?","This question already has answers here : The limit of truncated sums of harmonic series, $\lim\limits_{k\to\infty}\sum_{n=k+1}^{2k}{\frac{1}{n}}$ (12 answers) Closed 4 years ago . More specifically, how would you evaluate the below formula? I know that the harmonic series starting at any point diverges, but when we limit it in this way, does the series diverge or converge? If it diverges: How might you determine that? Is there some that we can replace with to make the sequence converge? If it converges: What does it converge to, and how might you determine that? The sequence must converge for any . Is there a formula for the series generalized for any ?",\lim_{n\to\infty}\sum_{k=n/2}^{n}\frac{1}{k} d 2 d>2 d,"['real-analysis', 'sequences-and-series', 'harmonic-numbers']"
9,How to compare the values $\sqrt 2$ and $\ln(3).$,How to compare the values  and,\sqrt 2 \ln(3).,How to compare the values $\sqrt 2$ and $\ln(3)?$ I know only $\ln(x)<x$ and $\sqrt{x}<x$. Please help. Thanks.,How to compare the values $\sqrt 2$ and $\ln(3)?$ I know only $\ln(x)<x$ and $\sqrt{x}<x$. Please help. Thanks.,,"['real-analysis', 'real-numbers']"
10,"What is wrong with this argument that closed interval [0, 1] is not compact?","What is wrong with this argument that closed interval [0, 1] is not compact?",,"I am a student majoring engineering. I am studying real analysis with textbook 'Measure and Integral' by Wheeden and Zygmund. This book defined compact like the following: $E$ is compact if every open cover of $E$ has a finite subcover. By the definition $[0, 1]$ is not compact. However, by the Heine-Borel theorem, $[0, 1]$ is compact. Let me prove why $[0, 1]$ is not compact by the definition. According to the definition, it is enough to show an open cover of $E$ having infinite subcover. If $C=\{U_\alpha:\alpha\in \mathbb{N}\}$ is an indexed family of sets $\displaystyle U_\alpha=\left(-1+\frac{1}{n}, 2\right)$, then $C$ is a cover of $[0, 1]$ because $\displaystyle [0,1] \subseteq \bigcup\limits_{\alpha  \in \mathbb{N}} {\mathop U\nolimits_\alpha  }$. This $C$ has infinite subcovers like $C=\{U_{2\alpha}:\alpha\in \mathbb{N}\}$ Can someone teach me what is my fault?","I am a student majoring engineering. I am studying real analysis with textbook 'Measure and Integral' by Wheeden and Zygmund. This book defined compact like the following: $E$ is compact if every open cover of $E$ has a finite subcover. By the definition $[0, 1]$ is not compact. However, by the Heine-Borel theorem, $[0, 1]$ is compact. Let me prove why $[0, 1]$ is not compact by the definition. According to the definition, it is enough to show an open cover of $E$ having infinite subcover. If $C=\{U_\alpha:\alpha\in \mathbb{N}\}$ is an indexed family of sets $\displaystyle U_\alpha=\left(-1+\frac{1}{n}, 2\right)$, then $C$ is a cover of $[0, 1]$ because $\displaystyle [0,1] \subseteq \bigcup\limits_{\alpha  \in \mathbb{N}} {\mathop U\nolimits_\alpha  }$. This $C$ has infinite subcovers like $C=\{U_{2\alpha}:\alpha\in \mathbb{N}\}$ Can someone teach me what is my fault?",,"['real-analysis', 'general-topology', 'proof-verification', 'definition', 'compactness']"
11,Sequences of Rationals and Irrationals,Sequences of Rationals and Irrationals,,"Let $(x_n)$ be a sequence that converges to the irrational number $x$. Must it be the case that $x_1, x_2, \dots$ are all irrational? Let $(y_n)$ be a sequences that converges to the rational number $y$. Must $y_1, y_2, \dots$ all be rational? This was one of my midterm questions yesterday and I just wanted to clarify my responses. For (1), I said NO and as a counterexample, gave the sequence $$ (x_n) = (3, 3.1, 3.14, 3.141, 3.1415, \dots) $$ that converges to $\pi$ (note that each $x_j \in \mathbb{Q}$ since it is a finite decimal expansion). For (2), I said YES but was not sure how to prove it. Could anyone verify these responses and if I'm correct about (2), offer a proof for why it must be true.","Let $(x_n)$ be a sequence that converges to the irrational number $x$. Must it be the case that $x_1, x_2, \dots$ are all irrational? Let $(y_n)$ be a sequences that converges to the rational number $y$. Must $y_1, y_2, \dots$ all be rational? This was one of my midterm questions yesterday and I just wanted to clarify my responses. For (1), I said NO and as a counterexample, gave the sequence $$ (x_n) = (3, 3.1, 3.14, 3.141, 3.1415, \dots) $$ that converges to $\pi$ (note that each $x_j \in \mathbb{Q}$ since it is a finite decimal expansion). For (2), I said YES but was not sure how to prove it. Could anyone verify these responses and if I'm correct about (2), offer a proof for why it must be true.",,"['real-analysis', 'sequences-and-series', 'solution-verification', 'irrational-numbers', 'rational-numbers']"
12,How can I prove that $\int _{-1}^{1} \frac{1}{x} dx =0 $,How can I prove that,\int _{-1}^{1} \frac{1}{x} dx =0 ,"According to WolframAlpha $\int _{-1}^{1} \frac{1}{x} dx =0 $ . But how can this be proved rigorously? I know that the function is odd, but it's unbounded on $[-1;1]$ . Leibniz–Newton formula cannot be applied here either. I would really appreciate some help with this matter.","According to WolframAlpha . But how can this be proved rigorously? I know that the function is odd, but it's unbounded on . Leibniz–Newton formula cannot be applied here either. I would really appreciate some help with this matter.",\int _{-1}^{1} \frac{1}{x} dx =0  [-1;1],"['real-analysis', 'calculus', 'integration']"
13,The union of two open sets is open (In metric Spaces),The union of two open sets is open (In metric Spaces),,"Let $X$ a set not empty and $(X,d)$ a metric space. Prove he union of two open sets is open. My proof: Let $A_1,A_2$ open sets, we need to prove $A_1\cup A_2$ is open.   As $A_1,A_2$ are open set, then for all $a_1,a_2\in A_1,A_2$ respectively we have $r_1,r_2>0$ such that $B(a_1,r_1)\subset A_1$ and $B(a_2,r_2)\subset A_2$   Let $r=\frac{1}{2}min\{r_1,r_2\}$ and $x\in A_1\cup A_2$, then $x \in A_1$ or $x \in A_2$   This implies: $B(x,r)\subset A_1\cup A_2$   In conclusion, $A_1\cup A_2$  is open set. Note: My definition of Open is $\forall x\in A_1$ exists $r>0$ such that $B(x,r)\subset A$ What is your opinion about my proof? Do you think is a good proof? Is convincing?","Let $X$ a set not empty and $(X,d)$ a metric space. Prove he union of two open sets is open. My proof: Let $A_1,A_2$ open sets, we need to prove $A_1\cup A_2$ is open.   As $A_1,A_2$ are open set, then for all $a_1,a_2\in A_1,A_2$ respectively we have $r_1,r_2>0$ such that $B(a_1,r_1)\subset A_1$ and $B(a_2,r_2)\subset A_2$   Let $r=\frac{1}{2}min\{r_1,r_2\}$ and $x\in A_1\cup A_2$, then $x \in A_1$ or $x \in A_2$   This implies: $B(x,r)\subset A_1\cup A_2$   In conclusion, $A_1\cup A_2$  is open set. Note: My definition of Open is $\forall x\in A_1$ exists $r>0$ such that $B(x,r)\subset A$ What is your opinion about my proof? Do you think is a good proof? Is convincing?",,"['real-analysis', 'proof-verification']"
14,Can I bring the variable of integration inside the integral?,Can I bring the variable of integration inside the integral?,,"$\def\d{\mathrm{d}}$ My problem So I have coefficient of a certain general solution of a PDE that turns out to be $$A_n  =\frac{\displaystyle \int_{0}^1 g(x)J_0(\lambda_mx)x\,\d x}{\displaystyle \int_0^1J^2_0(\lambda_m x)x\,\d x}.$$ Now the book says that when we replace $f(x)$ by $1$ we should get $$A_n=\frac{2}{\lambda_n J_1(\lambda_n)},$$ however I couldn't get there so I thought that by plagging it in the solution $$Q(x,t)=\sum_{n=0}^\infty A_nJ_0(\lambda_n x)g(t),$$ where $g(t)$ is another function I just don't write. I could maybe bring the $J_0(x\lambda_n)$ inside the integral and use some sort of orthogonality or something else.","$\def\d{\mathrm{d}}$ My problem So I have coefficient of a certain general solution of a PDE that turns out to be $$A_n  =\frac{\displaystyle \int_{0}^1 g(x)J_0(\lambda_mx)x\,\d x}{\displaystyle \int_0^1J^2_0(\lambda_m x)x\,\d x}.$$ Now the book says that when we replace $f(x)$ by $1$ we should get $$A_n=\frac{2}{\lambda_n J_1(\lambda_n)},$$ however I couldn't get there so I thought that by plagging it in the solution $$Q(x,t)=\sum_{n=0}^\infty A_nJ_0(\lambda_n x)g(t),$$ where $g(t)$ is another function I just don't write. I could maybe bring the $J_0(x\lambda_n)$ inside the integral and use some sort of orthogonality or something else.",,"['calculus', 'real-analysis', 'integration']"
15,Why does a function has to be differentiable so many times to be considered smooth?,Why does a function has to be differentiable so many times to be considered smooth?,,"I'm studying ""Smoothness"". If a function is once differentiable for all x's, shouldn't it be considered smooth? Because it does ""look smooth"" for all f(x), there's no way it will have sharp corners or cusps because it's differentiable. Then why does it have to be differentiable way more times than once (and actually has to be differentiable infinite times) to be considered smooth? Or unless this is not about ""looking smooth"" but smooth in other meaning? Any help is greatly appreciated! Edit: Sorry. Please use a bit less formal math language so I can understand. I not very good at it.","I'm studying ""Smoothness"". If a function is once differentiable for all x's, shouldn't it be considered smooth? Because it does ""look smooth"" for all f(x), there's no way it will have sharp corners or cusps because it's differentiable. Then why does it have to be differentiable way more times than once (and actually has to be differentiable infinite times) to be considered smooth? Or unless this is not about ""looking smooth"" but smooth in other meaning? Any help is greatly appreciated! Edit: Sorry. Please use a bit less formal math language so I can understand. I not very good at it.",,"['real-analysis', 'calculus', 'smooth-functions']"
16,Every convergent sequence is bounded: what's wrong with this counterexample?,Every convergent sequence is bounded: what's wrong with this counterexample?,,"A basic result in analysis states that convergence of a sequence implies its boundedness. I was wondering: what's wrong with $x_n = 1/(n-a)$ for some $a \in N$? This sequence is convergent to $0$, but $x_a$ is unbounded. What am I missing here? Thanks!","A basic result in analysis states that convergence of a sequence implies its boundedness. I was wondering: what's wrong with $x_n = 1/(n-a)$ for some $a \in N$? This sequence is convergent to $0$, but $x_a$ is unbounded. What am I missing here? Thanks!",,"['real-analysis', 'sequences-and-series']"
17,How can the following be false based on the information about continuous functions?,How can the following be false based on the information about continuous functions?,,"Let $f\colon\mathbb{R}\to [0,\infty)$ be a continuous function. Then, what is the rationale behind saying that the following are false statements: There exists $x\in\mathbb{R}$ such that  $f(x)=\int_{-1}^{1}f(t)dt$. There exists $x\in\mathbb{R}$ such that  $f(x)=\frac{f(0)+f(1)}{2}$. I think the second statement should be true due to the intermediate value theorem but I am not certain about the first statement. But  my solution manual says both statements are false. What should be the rationale behind this reasoning?","Let $f\colon\mathbb{R}\to [0,\infty)$ be a continuous function. Then, what is the rationale behind saying that the following are false statements: There exists $x\in\mathbb{R}$ such that  $f(x)=\int_{-1}^{1}f(t)dt$. There exists $x\in\mathbb{R}$ such that  $f(x)=\frac{f(0)+f(1)}{2}$. I think the second statement should be true due to the intermediate value theorem but I am not certain about the first statement. But  my solution manual says both statements are false. What should be the rationale behind this reasoning?",,"['real-analysis', 'definite-integrals', 'continuity']"
18,Prove that $\sqrt{2}$ is a real number. [closed],Prove that  is a real number. [closed],\sqrt{2},"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question I remember I saw this question somewhere in Lang's undergraduate real analysis. Given any real number $\ge0$, show that it has a square root.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question I remember I saw this question somewhere in Lang's undergraduate real analysis. Given any real number $\ge0$, show that it has a square root.",,['real-analysis']
19,Product norm on infinite product space,Product norm on infinite product space,,"Today I proved that if $V$ is a normed space with norm $\|\cdot\|$ then I can define a norm on $V \times V$ that induces the same topology as the product topology as follows: $\| (v,w) \|_{V \times V} = \|v\| + \|w\|$. I think I can do the same for an infinite product $V^{\mathbb N}$ by defining $\|(v_n)\|_{\mathbb N} = \sum_{n=0}^\infty \frac{1}{2^n} \|v_n\|$ and I proved it using the proof of the case $V \times V$ and changing some minor things. Can you confirm that this result is correct? Thanks.","Today I proved that if $V$ is a normed space with norm $\|\cdot\|$ then I can define a norm on $V \times V$ that induces the same topology as the product topology as follows: $\| (v,w) \|_{V \times V} = \|v\| + \|w\|$. I think I can do the same for an infinite product $V^{\mathbb N}$ by defining $\|(v_n)\|_{\mathbb N} = \sum_{n=0}^\infty \frac{1}{2^n} \|v_n\|$ and I proved it using the proof of the case $V \times V$ and changing some minor things. Can you confirm that this result is correct? Thanks.",,"['real-analysis', 'normed-spaces']"
20,Gamma function proof of gamma $\;Γ(1/2) = \sqrt \pi\;$,Gamma function proof of gamma,\;Γ(1/2) = \sqrt \pi\;,So our teacher doesnt use the same demonstration as most other sites use for proving that gamma of a half is the square root of pi. I dont understand the demonstration from the first step because he uses the Wallis product but first he represents $Γ(1/2)$ as : $$Γ(n + 1/2) = 2^{-n}Γ(1/2)\prod_{k=1..n}(2k-1)$$ This is just the first step and i dont undderstand how they get that.. I understand the gamme function and that when you integrate it you get $Γ(x+1) = xΓ(x)$ and i know i need to somehow use this identity but i dunno how.,So our teacher doesnt use the same demonstration as most other sites use for proving that gamma of a half is the square root of pi. I dont understand the demonstration from the first step because he uses the Wallis product but first he represents $Γ(1/2)$ as : $$Γ(n + 1/2) = 2^{-n}Γ(1/2)\prod_{k=1..n}(2k-1)$$ This is just the first step and i dont undderstand how they get that.. I understand the gamme function and that when you integrate it you get $Γ(x+1) = xΓ(x)$ and i know i need to somehow use this identity but i dunno how.,,"['real-analysis', 'integration', 'analysis', 'factorial', 'gamma-function']"
21,"Continuous, bijective function from $f:[0,1)\to \mathbb{R}.$","Continuous, bijective function from","f:[0,1)\to \mathbb{R}.","Prove that there does not exist a continuous, bijective function $f:[0,1)\to \mathbb{R}.$ By contradiction I can assume a function exists, so that function is surjective, onto and continuous. And I know I need to use the intermediate value theorem but I can't create such a contradiction.","Prove that there does not exist a continuous, bijective function $f:[0,1)\to \mathbb{R}.$ By contradiction I can assume a function exists, so that function is surjective, onto and continuous. And I know I need to use the intermediate value theorem but I can't create such a contradiction.",,['real-analysis']
22,prove that the unit circle $x^2+y^2=1$ is a closed set,prove that the unit circle  is a closed set,x^2+y^2=1,I need to prove that the unit circle $x^2+y^2=1$ is a closed set in $\mathbb{R}^2$ is closed using convergent sequence method.,I need to prove that the unit circle $x^2+y^2=1$ is a closed set in $\mathbb{R}^2$ is closed using convergent sequence method.,,"['calculus', 'real-analysis', 'cauchy-sequences']"
23,Convergence of the sequence $(1+\frac{1}{n})(1+\frac{2}{n})\cdots(1+\frac{n}{n})$,Convergence of the sequence,(1+\frac{1}{n})(1+\frac{2}{n})\cdots(1+\frac{n}{n}),"I have a sequence $(a_n)$ where for each natural number $n$,   $$a_n = (1+\frac{1}{n})(1+\frac{2}{n})\cdots(1+\frac{n}{n})$$ and I want to find its limit as $n\to\infty$. I obviously couldn't prove it and after several futile attempts decided to post it here. Here is a list of a few observations which I got from those attempts: The sequence $(a_n)$ is a strictly increasing sequence. To prove this, I rewrote each element as $$a_n = (1+\frac{1}{n})(1+\frac{2}{n})\cdots(1+\frac{n}{n})= \frac{(n+1)\cdots(n+n)}{n^n}= \frac{(2n)!}{n!n^n}.$$ Then $$\frac{a_{n+1}}{a_n}= \frac{2(n+1)!}{(n+1)!(n+1)^{n+1}}\frac{n!n^n}{(2n)!}=\frac{(2n+1)(2n+2)}{(n+1)^2(1+\frac{1}{n})^n} \to \frac{4}{e}$$ as $n\to\infty$. Since $\frac{4}{e}>1$ we have $a_{n+1}>a_n$ eventually. The limit of this sequence is bounded below by $e$. By replacing $1,2, \ldots, n$ with $1$ in the expression of $a_n$, we get $a_n \geq (1+\frac{1}{n})^n$. And thus $\lim{(a_n)}\geq e$. $\lim{(a_n)}\geq e^2$ and $\lim{(a_n)}\geq e^3$. The first assertion follows from the fact that $$a_n\geq(1+\frac{1}{n})(1+\frac{2}{n})^{n-1}= \frac{(1+\frac{1}{n})(1+\frac{2}{n})^{n}}{(1+\frac{2}{n})} \to e^2.$$ And the last one follows the same way because $$a_n\geq (1+\frac{1}{n})(1+\frac{2}{n})(1+\frac{3}{n})^{n-2}.$$ Now I have a gut feeling that for any natural number $k$, one can show that for all sufficiently large natural number $n$, $$a_n\geq (1+\frac{1}{n})\cdots(1+\frac{k-1}{n})(1+\frac{k}{n})^{n-(k-1)}.$$ And therefore for all $k \in \mathbb{N}$, $\lim{(a_n)}\geq e^k$ making the sequence divergent. But I'm really not sure about this approach and I'll appreciate any help towards this end. Thank you. [Note: As this sequence is quite common, there may be other posts on math.SE asking the same question. I didn't search for them because I just don't know how to search for an expression this big. Though a link related to any previous question concerning this particular sequence will be good enough, I will greatly appreciate if someone takes the trouble to look into my approach/observations and point out where  I'm going wrong.]","I have a sequence $(a_n)$ where for each natural number $n$,   $$a_n = (1+\frac{1}{n})(1+\frac{2}{n})\cdots(1+\frac{n}{n})$$ and I want to find its limit as $n\to\infty$. I obviously couldn't prove it and after several futile attempts decided to post it here. Here is a list of a few observations which I got from those attempts: The sequence $(a_n)$ is a strictly increasing sequence. To prove this, I rewrote each element as $$a_n = (1+\frac{1}{n})(1+\frac{2}{n})\cdots(1+\frac{n}{n})= \frac{(n+1)\cdots(n+n)}{n^n}= \frac{(2n)!}{n!n^n}.$$ Then $$\frac{a_{n+1}}{a_n}= \frac{2(n+1)!}{(n+1)!(n+1)^{n+1}}\frac{n!n^n}{(2n)!}=\frac{(2n+1)(2n+2)}{(n+1)^2(1+\frac{1}{n})^n} \to \frac{4}{e}$$ as $n\to\infty$. Since $\frac{4}{e}>1$ we have $a_{n+1}>a_n$ eventually. The limit of this sequence is bounded below by $e$. By replacing $1,2, \ldots, n$ with $1$ in the expression of $a_n$, we get $a_n \geq (1+\frac{1}{n})^n$. And thus $\lim{(a_n)}\geq e$. $\lim{(a_n)}\geq e^2$ and $\lim{(a_n)}\geq e^3$. The first assertion follows from the fact that $$a_n\geq(1+\frac{1}{n})(1+\frac{2}{n})^{n-1}= \frac{(1+\frac{1}{n})(1+\frac{2}{n})^{n}}{(1+\frac{2}{n})} \to e^2.$$ And the last one follows the same way because $$a_n\geq (1+\frac{1}{n})(1+\frac{2}{n})(1+\frac{3}{n})^{n-2}.$$ Now I have a gut feeling that for any natural number $k$, one can show that for all sufficiently large natural number $n$, $$a_n\geq (1+\frac{1}{n})\cdots(1+\frac{k-1}{n})(1+\frac{k}{n})^{n-(k-1)}.$$ And therefore for all $k \in \mathbb{N}$, $\lim{(a_n)}\geq e^k$ making the sequence divergent. But I'm really not sure about this approach and I'll appreciate any help towards this end. Thank you. [Note: As this sequence is quite common, there may be other posts on math.SE asking the same question. I didn't search for them because I just don't know how to search for an expression this big. Though a link related to any previous question concerning this particular sequence will be good enough, I will greatly appreciate if someone takes the trouble to look into my approach/observations and point out where  I'm going wrong.]",,"['real-analysis', 'sequences-and-series', 'convergence-divergence']"
24,Does $\sum _{n=1}^{\infty }\frac{\left|\sin\left(n\right)\right|}{n}$ converge?,Does  converge?,\sum _{n=1}^{\infty }\frac{\left|\sin\left(n\right)\right|}{n},I'm not sure whether the following series converges or diverges: $$\sum _{n=1}^{\infty }\frac{\left|\sin (n)\right|}{n}$$ I proved that the series $\sum _{n=1}^{\infty }\frac{\sin^2 (n )}{n}$ converge. Is there a way I can use that? I've tried using Dirichlet series test with the latter but didn't got nowhere since $\frac{1}{\left|\sin x\right|}$ is not monotone decreasing.,I'm not sure whether the following series converges or diverges: $$\sum _{n=1}^{\infty }\frac{\left|\sin (n)\right|}{n}$$ I proved that the series $\sum _{n=1}^{\infty }\frac{\sin^2 (n )}{n}$ converge. Is there a way I can use that? I've tried using Dirichlet series test with the latter but didn't got nowhere since $\frac{1}{\left|\sin x\right|}$ is not monotone decreasing.,,"['real-analysis', 'sequences-and-series', 'convergence-divergence']"
25,"Why $\sin(nx)$ converges weakly in $L^2(-\pi,\pi)$?",Why  converges weakly in ?,"\sin(nx) L^2(-\pi,\pi)","Can anybody tell me why $\sin(nx)$ converges weakly in $L^2(-\pi,\pi)$. I can't see how $\sin(nx)$ can converge? Explanation with any other example will be nice as well.","Can anybody tell me why $\sin(nx)$ converges weakly in $L^2(-\pi,\pi)$. I can't see how $\sin(nx)$ can converge? Explanation with any other example will be nice as well.",,"['real-analysis', 'functional-analysis', 'hilbert-spaces', 'weak-convergence']"
26,Are balls around a point always symmetric about the axes?,Are balls around a point always symmetric about the axes?,,"I think they are. And I have sketched the following proof so far. Every ball around the origin is symmetric to the X-axis (generalize to all axis and around all points) Let $\| \cdot \|$ be any norm on $\mathbb{R}^n$ . Say the set $\{t \in \mathbb{R}^n : \|t\| \neq \|t_x\|\}$ is non-empty, where $t_x$ is the reflection of $t$ about the $X-$ axis. Let $r$ be ""a"" vector in the set with the smallest norm. Clearly, $r \neq \underline 0$ , so take the line joining $r$ and $\underline 0$ . The function $\|\cdot\|$ is continuous everywhere in the ball of radius $\|r\|$ , and this line is inside ball by its convexity. Therefore $\|\cdot \|$ is continious on this line , and assumes $0$ at $\underline 0$ and $\|r\|$ at $r$ . Therefore by $IVT$ , for every large enough $m$ there is a point $r_m$ on this line such that $\|r_m\| = \|r\| - \frac{1}{m}$ . By the collinearity of $r, r_m$ and $\underline 0$ , we have, $$\|r-r_m\| = \|r\|-\|r_m\| = \frac{1}{m} \implies r_m \rightarrow r $$ Also, by continuity of reflection, we have $r_{m_x} \rightarrow r_x$ , and by continuity of $\|\cdot\|$ , we have $\|r_m\| \rightarrow \|r\|$ , and $\|r_{m_x}\| \rightarrow \|r_x\|$ . Notice, by minimality of $r$ , $\|r_m\| = \|r_{m_x}\|$ ; that is they are the same sequence, and hence must have the same limit. Hence, $\|r_x\| = \|r\|$ . Contradiction! Or the set of assymetric vectors is non-empty. I have the following concerns. Does the fact really hold? If no, where did I go wrong, and what is a counterexample? Assuming it does, the ""lines"" between two points $x$ and $y$ induced by a norm and by convexity might be different. Particularly, the set $\{tx + (1-t)y: 0\leq t \leq 1\}$ is always the straight line joining $x$ and $y$ . However the set $\{z : \|y - z\| + \|z - x\| = \|y - x\|\}$ needn't always be a straight line. For example, it can be ""L"" shaped like in the case of $\|\cdot \|_1$ norm. Does this conflict affect the proof. Is there a simpler way to show this?","I think they are. And I have sketched the following proof so far. Every ball around the origin is symmetric to the X-axis (generalize to all axis and around all points) Let be any norm on . Say the set is non-empty, where is the reflection of about the axis. Let be ""a"" vector in the set with the smallest norm. Clearly, , so take the line joining and . The function is continuous everywhere in the ball of radius , and this line is inside ball by its convexity. Therefore is continious on this line , and assumes at and at . Therefore by , for every large enough there is a point on this line such that . By the collinearity of and , we have, Also, by continuity of reflection, we have , and by continuity of , we have , and . Notice, by minimality of , ; that is they are the same sequence, and hence must have the same limit. Hence, . Contradiction! Or the set of assymetric vectors is non-empty. I have the following concerns. Does the fact really hold? If no, where did I go wrong, and what is a counterexample? Assuming it does, the ""lines"" between two points and induced by a norm and by convexity might be different. Particularly, the set is always the straight line joining and . However the set needn't always be a straight line. For example, it can be ""L"" shaped like in the case of norm. Does this conflict affect the proof. Is there a simpler way to show this?","\| \cdot \| \mathbb{R}^n \{t \in \mathbb{R}^n : \|t\| \neq \|t_x\|\} t_x t X- r r \neq \underline 0 r \underline 0 \|\cdot\| \|r\| \|\cdot \| 0 \underline 0 \|r\| r IVT m r_m \|r_m\| = \|r\| - \frac{1}{m} r, r_m \underline 0 \|r-r_m\| = \|r\|-\|r_m\| = \frac{1}{m} \implies r_m \rightarrow r  r_{m_x} \rightarrow r_x \|\cdot\| \|r_m\| \rightarrow \|r\| \|r_{m_x}\| \rightarrow \|r_x\| r \|r_m\| = \|r_{m_x}\| \|r_x\| = \|r\| x y \{tx + (1-t)y: 0\leq t \leq 1\} x y \{z : \|y - z\| + \|z - x\| = \|y - x\|\} \|\cdot \|_1","['real-analysis', 'continuity', 'normed-spaces', 'symmetry', 'spheres']"
27,"Is there a bijective, monotonically increasing, strictly concave function from the reals, to the reals?","Is there a bijective, monotonically increasing, strictly concave function from the reals, to the reals?",,"I can't come up with a single one. The range should be the whole of the reals. The best I have is $\log(x)$ but that's only on the positive real line. And there's $f(x) = x$ , but this is not strictly concave. And $-e^{-x}$ only maps to half of the real line. Any ideas?","I can't come up with a single one. The range should be the whole of the reals. The best I have is but that's only on the positive real line. And there's , but this is not strictly concave. And only maps to half of the real line. Any ideas?",\log(x) f(x) = x -e^{-x},"['real-analysis', 'functions', 'recreational-mathematics', 'real-numbers']"
28,Find the largest term of the sequence $a_n=\sqrt[n]{n}$,Find the largest term of the sequence,a_n=\sqrt[n]{n},Find the largest term of the sequence $a_n=\sqrt[n]{n}$. By simple calculation: $$a_1= 1$$ $$a_2=1.41$$ $$a_3=1.44$$ $$a_4=1.41$$ $$a_5=1.37$$ $$a_6=1.348$$ $$\quad\vdots$$ After that the sequence seems to be pretty much decreasing and $$\lim_{n\to \infty}{\sqrt[n]{n}}=1$$ This way it looks like $a_3$ is the largest term however there is no official proof behind this. What's the usual way to approach such problems?,Find the largest term of the sequence $a_n=\sqrt[n]{n}$. By simple calculation: $$a_1= 1$$ $$a_2=1.41$$ $$a_3=1.44$$ $$a_4=1.41$$ $$a_5=1.37$$ $$a_6=1.348$$ $$\quad\vdots$$ After that the sequence seems to be pretty much decreasing and $$\lim_{n\to \infty}{\sqrt[n]{n}}=1$$ This way it looks like $a_3$ is the largest term however there is no official proof behind this. What's the usual way to approach such problems?,,"['real-analysis', 'sequences-and-series', 'optimization', 'logarithms', 'radicals']"
29,Prove that $\int_{0}^{1}f(x)^2dx\geq 4$,Prove that,\int_{0}^{1}f(x)^2dx\geq 4,"Let $f:[0,1]\to \mathbb{R} $ be an integrable function with $\int_{0}^{1}f(x)dx=\int_{0}^{1}xf(x)dx=1$ . Prove that $\int_{0}^{1}f(x)^2dx\geq 4$ . I got that $\int_{0}^{1}F(x)dx=F(0)$ , but I don't think it's useful at all.","Let be an integrable function with . Prove that . I got that , but I don't think it's useful at all.","f:[0,1]\to \mathbb{R}  \int_{0}^{1}f(x)dx=\int_{0}^{1}xf(x)dx=1 \int_{0}^{1}f(x)^2dx\geq 4 \int_{0}^{1}F(x)dx=F(0)","['real-analysis', 'calculus', 'integration', 'inequality', 'definite-integrals']"
30,Proof of the second symmetric derivative,Proof of the second symmetric derivative,,"Prove that if $f''(a)$ exists, then $$f''(a)=\lim_{h\to0}\frac{f(a+h)+f(a-h)-2f(a)}{h^{2}}.$$ I really have no idea on this one. Am I supposed to apply the mean value theorem?","Prove that if exists, then I really have no idea on this one. Am I supposed to apply the mean value theorem?",f''(a) f''(a)=\lim_{h\to0}\frac{f(a+h)+f(a-h)-2f(a)}{h^{2}}.,"['calculus', 'real-analysis', 'derivatives']"
31,Evaluating $\int_0^1 (1-x^2)^n dx$ [duplicate],Evaluating  [duplicate],\int_0^1 (1-x^2)^n dx,"This question already has answers here : Find the value of a given integral sequence: $I_n=\int_{0}^{1}(1-x^2)^ndx$ [duplicate] (3 answers) Closed 3 years ago . In an exercise I'm asked the following: a) Find a formula for $\int (1-x^2)^n dx$ , for any $n \in \mathbb N$ . b) Prove that, for all $n \in \mathbb N$ : $$\int_0^1(1-x^2)^n dx = \frac{2^{2n}(n!)^2}{(2n + 1)!}$$ I used the binomial theorem in $a$ and got: $$\int (1-x^2)^n dx = \sum_{k=0}^n \left( \begin{matrix} n \\ k \end{matrix} \right) (-1)^k \ \frac{x^{2k + 1}}{2k+1} \ \ \ + \ \ C$$ and so in part (b) i got: $$\int_0^1 (1-x^2)^n dx = \sum_{k=0}^n \left( \begin{matrix} n \\ k \end{matrix} \right) \ \frac{(-1)^k}{2k+1}$$ I have no clue on how to arrive at the expression that I'm supposed to arrive. How can I solve this?","This question already has answers here : Find the value of a given integral sequence: $I_n=\int_{0}^{1}(1-x^2)^ndx$ [duplicate] (3 answers) Closed 3 years ago . In an exercise I'm asked the following: a) Find a formula for , for any . b) Prove that, for all : I used the binomial theorem in and got: and so in part (b) i got: I have no clue on how to arrive at the expression that I'm supposed to arrive. How can I solve this?",\int (1-x^2)^n dx n \in \mathbb N n \in \mathbb N \int_0^1(1-x^2)^n dx = \frac{2^{2n}(n!)^2}{(2n + 1)!} a \int (1-x^2)^n dx = \sum_{k=0}^n \left( \begin{matrix} n \\ k \end{matrix} \right) (-1)^k \ \frac{x^{2k + 1}}{2k+1} \ \ \ + \ \ C \int_0^1 (1-x^2)^n dx = \sum_{k=0}^n \left( \begin{matrix} n \\ k \end{matrix} \right) \ \frac{(-1)^k}{2k+1},"['real-analysis', 'integration', 'definite-integrals']"
32,Prove $\lim\limits_{n\to \infty}\frac{1}{\sqrt n}\left|\sum\limits_{k=1}^n (-1)^k\sqrt k\right|= \frac{1}{2}$,Prove,\lim\limits_{n\to \infty}\frac{1}{\sqrt n}\left|\sum\limits_{k=1}^n (-1)^k\sqrt k\right|= \frac{1}{2},"I'm trying to show that $$\lim_{n\to \infty} x_n=\lim_{n\to \infty}\frac{1}{\sqrt n}\left|\sum_{k=1}^n (-1)^k\sqrt k\right|= \frac{1}{2}.$$ Assuming $\lim\limits_{n\to\infty} x_n=x$ exists, we have $$x_{2n}=\frac{\sqrt{2n-1}(-x_{2n-1})+\sqrt {2n}}{\sqrt {2n}}$$ Letting $n\to \infty$ , $$\quad \quad x=-x+1$$ $$x=\frac{1}{2}$$ But I'm stuck on proving the existence of $\lim x_n$ . Any idea? Update: I just solved the problem using sandwich theorem + integral test. Still, I would like to see a continuation of my initial idea, i.e. proving $\{x_{2n}\}$ is monotonically increasing (similarly, $\{x_{2n+1}\}$ is monotonically decreasing)","I'm trying to show that Assuming exists, we have Letting , But I'm stuck on proving the existence of . Any idea? Update: I just solved the problem using sandwich theorem + integral test. Still, I would like to see a continuation of my initial idea, i.e. proving is monotonically increasing (similarly, is monotonically decreasing)",\lim_{n\to \infty} x_n=\lim_{n\to \infty}\frac{1}{\sqrt n}\left|\sum_{k=1}^n (-1)^k\sqrt k\right|= \frac{1}{2}. \lim\limits_{n\to\infty} x_n=x x_{2n}=\frac{\sqrt{2n-1}(-x_{2n-1})+\sqrt {2n}}{\sqrt {2n}} n\to \infty \quad \quad x=-x+1 x=\frac{1}{2} \lim x_n \{x_{2n}\} \{x_{2n+1}\},"['real-analysis', 'sequences-and-series', 'limits']"
33,Does continuity always imply integrability?,Does continuity always imply integrability?,,"Please correct me if I'm wrong. In terms of Riemann integrability: If we are taking into consideration Riemann integrals on a closed interval, then any continuous function is integrable. In terms of improper integrals: continuity does not imply integrability.","Please correct me if I'm wrong. In terms of Riemann integrability: If we are taking into consideration Riemann integrals on a closed interval, then any continuous function is integrable. In terms of improper integrals: continuity does not imply integrability.",,"['real-analysis', 'integration', 'continuity']"
34,How can I show that $\left|\sum_{n=1}^\infty\frac{x}{n^2+x^2}\right|\leq\frac{\pi}{2}$ for any $x\in{\bf R}$?,How can I show that  for any ?,\left|\sum_{n=1}^\infty\frac{x}{n^2+x^2}\right|\leq\frac{\pi}{2} x\in{\bf R},"Show that   $$\left|\sum_{n=1}^\infty\frac{x}{n^2+x^2}\right|\leq\frac{\pi}{2}$$ It is true for $x=0$. But I don't see how it is true for any $x\in{\bf R}$. The identity $\frac{\pi}{2}=\int_0^\infty\frac{1}{1+x^2}dx$ may help, I think. But I don't know how to go on.","Show that   $$\left|\sum_{n=1}^\infty\frac{x}{n^2+x^2}\right|\leq\frac{\pi}{2}$$ It is true for $x=0$. But I don't see how it is true for any $x\in{\bf R}$. The identity $\frac{\pi}{2}=\int_0^\infty\frac{1}{1+x^2}dx$ may help, I think. But I don't know how to go on.",,['calculus']
35,Evaluate $\lim\limits_{n \to\infty} \left(\frac{n-1} {2n+2}\right)^n$,Evaluate,\lim\limits_{n \to\infty} \left(\frac{n-1} {2n+2}\right)^n,"What is the easiest way to evaluate this limit? $\displaystyle{\lim_{n \to\infty} \left(n-1 \over 2n+2\right)^n}$ $$ \text{Is this possible ?$\,$:}\quad \lim_{n \to\infty}\left(n/n - 1/n \over 2n/n + 2/n\right)^n = \lim_{n \to\infty}\left(1 - 1/n \over 2 + 2/n\right)^{n} = \lim_{n \to\infty} \left(1 \over 2\right)^{n} = 0 $$","What is the easiest way to evaluate this limit? $\displaystyle{\lim_{n \to\infty} \left(n-1 \over 2n+2\right)^n}$ $$ \text{Is this possible ?$\,$:}\quad \lim_{n \to\infty}\left(n/n - 1/n \over 2n/n + 2/n\right)^n = \lim_{n \to\infty}\left(1 - 1/n \over 2 + 2/n\right)^{n} = \lim_{n \to\infty} \left(1 \over 2\right)^{n} = 0 $$",,"['real-analysis', 'limits']"
36,Is this stronger statement of the squeeze theorem valid?,Is this stronger statement of the squeeze theorem valid?,,"The squeeze theorem formally states that if $f,g$ and $h$ are real functions defined on an interval $I$ containing $c$ as a limit point and satisfy $g(x) \leq f(x) \leq h(x)$ for all $x \in I$ except possibly $c$, and furthermore, $\lim_{x \to c} g(x) = \lim_{x \to c} h(x) = L$, then  $\lim_{x \to c} f(x) = L$. This is proven by choosing, for given $\epsilon$, the minimum of the two corresponding $\delta$s of $h$ and $g$ as the $\delta$ for $f$. This statement, however, isn't as strong as can be. In particular, suppose $g$ and $h$, about every neighbourhood of $c$, ""interchange"" roles of being the lower and upper bounds of $f$. A concrete example would be $f(x) = 0$, $h(x) = x^2\sin\frac{1}{x}$ and $g = -h$ as $x \to 0$. I think that the conclusion of the squeeze theorem should be valid in this case regardless, because so long as we choose $\delta$ such that $g,h$ are within $\epsilon$ of $L$, $f$ will be within $\epsilon$ of $L$. Essentially, I want to weaken the hypothesis so that rather than $\forall x \in I, c \neq x\left[g(x) \leq f(x) \leq h(x)\right]$, it states $\forall x \in I, c \neq x \left[g(x) \leq f(x) \leq h(x) \  \lor h(x) \leq f(x) \leq g(x)\right]$. Questions: Is my reasoning correct? If not, what mistake am I making? If so, why is the stronger statement not more common in calculus/analysis texts?","The squeeze theorem formally states that if $f,g$ and $h$ are real functions defined on an interval $I$ containing $c$ as a limit point and satisfy $g(x) \leq f(x) \leq h(x)$ for all $x \in I$ except possibly $c$, and furthermore, $\lim_{x \to c} g(x) = \lim_{x \to c} h(x) = L$, then  $\lim_{x \to c} f(x) = L$. This is proven by choosing, for given $\epsilon$, the minimum of the two corresponding $\delta$s of $h$ and $g$ as the $\delta$ for $f$. This statement, however, isn't as strong as can be. In particular, suppose $g$ and $h$, about every neighbourhood of $c$, ""interchange"" roles of being the lower and upper bounds of $f$. A concrete example would be $f(x) = 0$, $h(x) = x^2\sin\frac{1}{x}$ and $g = -h$ as $x \to 0$. I think that the conclusion of the squeeze theorem should be valid in this case regardless, because so long as we choose $\delta$ such that $g,h$ are within $\epsilon$ of $L$, $f$ will be within $\epsilon$ of $L$. Essentially, I want to weaken the hypothesis so that rather than $\forall x \in I, c \neq x\left[g(x) \leq f(x) \leq h(x)\right]$, it states $\forall x \in I, c \neq x \left[g(x) \leq f(x) \leq h(x) \  \lor h(x) \leq f(x) \leq g(x)\right]$. Questions: Is my reasoning correct? If not, what mistake am I making? If so, why is the stronger statement not more common in calculus/analysis texts?",,"['calculus', 'real-analysis', 'limits']"
37,What am I doing wrong in this proof?,What am I doing wrong in this proof?,,"The question is this: Let $f:\mathbb{R}\to\mathbb{R}$ be differentiable at $x=0$ and suppose that there is a number $L$ such that $$\lim_{x\rightarrow0}\frac{f(x)-f(x/2)}{x/2}=L.$$ Prove that $f'(0)=L$. Here's my answer with all theorems referenced being from Rudin: Let $a_n$ be a positive sequence converging to zero and  $$\varphi_n(x)=\frac{a_nf'(0)+2\big(f(x)-f(x/2)\big)}{x+a_n}.$$ Then  $$\lim_{n\rightarrow\infty}\lim_{x\rightarrow0}\varphi_n(x)=f'(0)$$ while $$\lim_{x\rightarrow0}\lim_{n\rightarrow\infty}\varphi_n(x)=L.$$ By theorem 7.11 then, if $\varphi_n(x)$ converges uniformly to $\varphi(x)=\frac{f(x)-f(x/2)}{x/2}$ over a set $E$ and $0$ is a limit point of $E$, then $L=f'(0)$. Let $E=[0,1]$. Then for $x\in E$, $$\big|\varphi_n(x)-\varphi(x)\big|=a_n\bigg|\frac{xf'(0)-2\big(f(x)-f(x/2)\big)}{x+a_n}\bigg|=a_n\big|f'(0)-\varphi_n(x)\big|\leq a_n\big(|f'(0)|+|\varphi_n(x)|\big)\leq a_n\bigg(|f'(0)|+\bigg|\frac{a_nf'(0)}{x+a_n}\bigg|+\bigg|\frac{2\big(f(x)-f(x/2)\big)}{x+a_n}\bigg|\bigg)< a_n\big(|2f'(0)|+|L|\big)\rightarrow0.$$ So by theorem 7.9, $\varphi_n(x)$ converges uniformly to $\varphi(x)$ over $E$ and therefore $f'(0)=L$. What I don't understand is that couldn't I have put basically anything, say $\pi$, in place of $f'(0)$ in $\varphi_n(x)$ and shown that in fact $L=\pi$? Not sure where I went wrong. Any help is greatly appreciated.","The question is this: Let $f:\mathbb{R}\to\mathbb{R}$ be differentiable at $x=0$ and suppose that there is a number $L$ such that $$\lim_{x\rightarrow0}\frac{f(x)-f(x/2)}{x/2}=L.$$ Prove that $f'(0)=L$. Here's my answer with all theorems referenced being from Rudin: Let $a_n$ be a positive sequence converging to zero and  $$\varphi_n(x)=\frac{a_nf'(0)+2\big(f(x)-f(x/2)\big)}{x+a_n}.$$ Then  $$\lim_{n\rightarrow\infty}\lim_{x\rightarrow0}\varphi_n(x)=f'(0)$$ while $$\lim_{x\rightarrow0}\lim_{n\rightarrow\infty}\varphi_n(x)=L.$$ By theorem 7.11 then, if $\varphi_n(x)$ converges uniformly to $\varphi(x)=\frac{f(x)-f(x/2)}{x/2}$ over a set $E$ and $0$ is a limit point of $E$, then $L=f'(0)$. Let $E=[0,1]$. Then for $x\in E$, $$\big|\varphi_n(x)-\varphi(x)\big|=a_n\bigg|\frac{xf'(0)-2\big(f(x)-f(x/2)\big)}{x+a_n}\bigg|=a_n\big|f'(0)-\varphi_n(x)\big|\leq a_n\big(|f'(0)|+|\varphi_n(x)|\big)\leq a_n\bigg(|f'(0)|+\bigg|\frac{a_nf'(0)}{x+a_n}\bigg|+\bigg|\frac{2\big(f(x)-f(x/2)\big)}{x+a_n}\bigg|\bigg)< a_n\big(|2f'(0)|+|L|\big)\rightarrow0.$$ So by theorem 7.9, $\varphi_n(x)$ converges uniformly to $\varphi(x)$ over $E$ and therefore $f'(0)=L$. What I don't understand is that couldn't I have put basically anything, say $\pi$, in place of $f'(0)$ in $\varphi_n(x)$ and shown that in fact $L=\pi$? Not sure where I went wrong. Any help is greatly appreciated.",,['real-analysis']
38,prove there is no rational r satisfying $2^r=3$,prove there is no rational r satisfying,2^r=3,I first assumed that there exists a rational $r=\frac{a}{b}$ such that $2^r=3$. ..and I can't make a progress after this. can anyone help me out?,I first assumed that there exists a rational $r=\frac{a}{b}$ such that $2^r=3$. ..and I can't make a progress after this. can anyone help me out?,,"['calculus', 'real-analysis']"
39,Finding a pair of functions with properties,Finding a pair of functions with properties,,"I need to find a pair of functions $f$, $g$ such that $f$ is not differentiable at  $x = 0$ $g$ is not differentiable at $f(0)$ $g \circ f$ is differentiable at $x = 0$ I've tried a lot of functions but just can't seem to find ones that work. Any help would be appreciated, thank you.","I need to find a pair of functions $f$, $g$ such that $f$ is not differentiable at  $x = 0$ $g$ is not differentiable at $f(0)$ $g \circ f$ is differentiable at $x = 0$ I've tried a lot of functions but just can't seem to find ones that work. Any help would be appreciated, thank you.",,"['real-analysis', 'functions', 'derivatives', 'examples-counterexamples']"
40,$f'(x)=f(x)$ and $f(0)=0$ implies that $f(x)=0$ formal proof,and  implies that  formal proof,f'(x)=f(x) f(0)=0 f(x)=0,"How can I prove that if a function is such that $f'(x)=f(x)$ and also $f(0)=0$ then $f(x)=0$ for every $x$. I have an idea but it's too long, I want to know if there is a simple way to do it. Thanks! Obviously in a formal way.","How can I prove that if a function is such that $f'(x)=f(x)$ and also $f(0)=0$ then $f(x)=0$ for every $x$. I have an idea but it's too long, I want to know if there is a simple way to do it. Thanks! Obviously in a formal way.",,['real-analysis']
41,Rolle's theorem: what's the right statement of the theorem?,Rolle's theorem: what's the right statement of the theorem?,,"In the fourth edition of ""Introduction to Real Analysis"" by Bartle and Sherbert, theorem 6.2.3 (Rolle's theorem) states, Suppose that f is continuous on a closed interval $I := [a, b]$, that   the derivative of $f$ exists at every point of the open interval $(a, b)$, and that $f(a) = f(b) = 0$.   Then there exists at least one point $c$ in $(a, b)$ such that the derivative of $f$ is zero at $c$. Now, why are we taking $f(a)=0=f(b)$? Is $f(a)=f(b)$ not sufficient?","In the fourth edition of ""Introduction to Real Analysis"" by Bartle and Sherbert, theorem 6.2.3 (Rolle's theorem) states, Suppose that f is continuous on a closed interval $I := [a, b]$, that   the derivative of $f$ exists at every point of the open interval $(a, b)$, and that $f(a) = f(b) = 0$.   Then there exists at least one point $c$ in $(a, b)$ such that the derivative of $f$ is zero at $c$. Now, why are we taking $f(a)=0=f(b)$? Is $f(a)=f(b)$ not sufficient?",,"['real-analysis', 'definition', 'rolles-theorem']"
42,Showing that $\sum_{k=N+1}^\infty \frac {1}{k!} < \frac {1}{N!}$ [duplicate],Showing that  [duplicate],\sum_{k=N+1}^\infty \frac {1}{k!} < \frac {1}{N!},"This question already has answers here : How to show $\sum_{k=n}^\infty{\frac{1}{k!}} \leq \frac{2}{n!}$ (3 answers) Closed 7 years ago . I was constructing a proof through inequalities, but I am having a bit of problem showing the following step:  $$\sum_{k=N+1}^\infty \frac {1}{k!} < \frac {1}{N!}$$ Is there any quick way to show this?","This question already has answers here : How to show $\sum_{k=n}^\infty{\frac{1}{k!}} \leq \frac{2}{n!}$ (3 answers) Closed 7 years ago . I was constructing a proof through inequalities, but I am having a bit of problem showing the following step:  $$\sum_{k=N+1}^\infty \frac {1}{k!} < \frac {1}{N!}$$ Is there any quick way to show this?",,"['real-analysis', 'sequences-and-series', 'inequality', 'summation', 'factorial']"
43,Prove that $\exp(x)>0$ using only formal definition of exp,Prove that  using only formal definition of exp,\exp(x)>0,"This problem would be easy if I could use the fact that $\exp(x)=e^x$, but I have to use the following definition: $$\exp(x)=\sum_{n=0}^{\infty}\frac{x^n}{n!}$$ I can also use the fact that $$\exp(x+y)=\exp(x)\exp(y)$$ So how do I prove, using those two equations, that $$\forall x\in \mathbb{R}:\exp(x)>0 $$ I mean, I can't just use the definition, because if $x<0$ then it isn't so obvious that $\exp(x)=\sum_{n=0}^{\infty}\frac{x^n}{n!}>0$. Can someone give me a hint or two? Thanks!","This problem would be easy if I could use the fact that $\exp(x)=e^x$, but I have to use the following definition: $$\exp(x)=\sum_{n=0}^{\infty}\frac{x^n}{n!}$$ I can also use the fact that $$\exp(x+y)=\exp(x)\exp(y)$$ So how do I prove, using those two equations, that $$\forall x\in \mathbb{R}:\exp(x)>0 $$ I mean, I can't just use the definition, because if $x<0$ then it isn't so obvious that $\exp(x)=\sum_{n=0}^{\infty}\frac{x^n}{n!}>0$. Can someone give me a hint or two? Thanks!",,['real-analysis']
44,Why is there Inequality in Fatou's Lemma?,Why is there Inequality in Fatou's Lemma?,,"I'm studying measure theory for the first time, and I just came across Fatou's Lemma. Why isn't it true that for any sequence of functions $\left\{ f_n \right\}$ in $L^+$ we always have that $$\int \displaystyle \liminf_{n\rightarrow \infty} f_n d\mu =\liminf_{n\rightarrow \infty} \int f_n d\mu\ ?$$","I'm studying measure theory for the first time, and I just came across Fatou's Lemma. Why isn't it true that for any sequence of functions $\left\{ f_n \right\}$ in $L^+$ we always have that $$\int \displaystyle \liminf_{n\rightarrow \infty} f_n d\mu =\liminf_{n\rightarrow \infty} \int f_n d\mu\ ?$$",,"['real-analysis', 'analysis', 'measure-theory', 'lebesgue-integral']"
45,Negation of uniform convergence,Negation of uniform convergence,,"Suppose $f_{n}$ is a sequence of functions which does not convergence uniformly to $f$. Does this mean that there exists an $\varepsilon_{0} > 0$, an $x_{0}$, and a sequence of integers $n_{k} \rightarrow \infty$ such that $|f_{n_{k}}(x_{0}) - f(x_{0})| \geq \varepsilon_{0}$?","Suppose $f_{n}$ is a sequence of functions which does not convergence uniformly to $f$. Does this mean that there exists an $\varepsilon_{0} > 0$, an $x_{0}$, and a sequence of integers $n_{k} \rightarrow \infty$ such that $|f_{n_{k}}(x_{0}) - f(x_{0})| \geq \varepsilon_{0}$?",,"['real-analysis', 'analysis', 'uniform-convergence']"
46,Test for convergence $\sum_{n=1}^{\infty} \frac{1}{2^\sqrt{n}}$ [duplicate],Test for convergence  [duplicate],\sum_{n=1}^{\infty} \frac{1}{2^\sqrt{n}},This question already has answers here : Closed 11 years ago . Possible Duplicate: convergence of a series involving $x^\sqrt{n}$ Test for convergence $$\sum_{n=1}^{\infty} \frac{1}{2^\sqrt{n}}$$ My first thought was to use the ratio test but it's inconclusive since it yields $1$. Are there some easy means to test the sum for convergence? Thanks!,This question already has answers here : Closed 11 years ago . Possible Duplicate: convergence of a series involving $x^\sqrt{n}$ Test for convergence $$\sum_{n=1}^{\infty} \frac{1}{2^\sqrt{n}}$$ My first thought was to use the ratio test but it's inconclusive since it yields $1$. Are there some easy means to test the sum for convergence? Thanks!,,"['calculus', 'real-analysis', 'sequences-and-series', 'convergence-divergence']"
47,Find $\lim_{n\to\infty} (1+\frac{1}{2}+...+\frac{1}{n})\frac{1}{n}$,Find,\lim_{n\to\infty} (1+\frac{1}{2}+...+\frac{1}{n})\frac{1}{n},"Find the following limit:   $$\lim_{n\to\infty} \left(1+\frac{1}{2}+...+\frac{1}{n}\right)\frac{1}{n}$$ My intuition says that this goes to zero, because $1/n$ goes much faster to zero than the harmonic series go to infinity, but how can I prove this?","Find the following limit:   $$\lim_{n\to\infty} \left(1+\frac{1}{2}+...+\frac{1}{n}\right)\frac{1}{n}$$ My intuition says that this goes to zero, because $1/n$ goes much faster to zero than the harmonic series go to infinity, but how can I prove this?",,"['real-analysis', 'limits', 'harmonic-numbers']"
48,The sum: $\sum_{k=1}^{n}(-1)^{k-1}~ [(H_k)^2+ H_k^{(2)}]~ {n \choose k}=\frac{2}{n^2}$,The sum:,\sum_{k=1}^{n}(-1)^{k-1}~ [(H_k)^2+ H_k^{(2)}]~ {n \choose k}=\frac{2}{n^2},"This attractive identity that $$\sum_{k=1}^{n}(-1)^{k-1}~ [(H_k)^2+ H_k^{(2)}]~ {n \choose k}=\frac{2}{n^2}~~~(*)$$ emerged while doing numerics at Mathematica with harmonic numbers, binomial coefficients  and sums involving them. Here $$H_k=1+\frac{1}{2}+\frac{1}{3}+...+\frac{1}{k},~~ H_k^{(2)}=1+\frac{1}{2^2}+\frac{1}{3^2}+...+\frac{1}{k^2}. $$ The question is: How to prove it $(*)$ by hand?","This attractive identity that emerged while doing numerics at Mathematica with harmonic numbers, binomial coefficients  and sums involving them. Here The question is: How to prove it by hand?","\sum_{k=1}^{n}(-1)^{k-1}~ [(H_k)^2+ H_k^{(2)}]~ {n \choose k}=\frac{2}{n^2}~~~(*) H_k=1+\frac{1}{2}+\frac{1}{3}+...+\frac{1}{k},~~ H_k^{(2)}=1+\frac{1}{2^2}+\frac{1}{3^2}+...+\frac{1}{k^2}.  (*)","['real-analysis', 'sequences-and-series', 'summation', 'binomial-coefficients', 'harmonic-numbers']"
49,Is $\sum_{n=1}^{+ \infty}\left(\frac {1}{n}-\frac{1}{p_n}\right)$ convergent?,Is  convergent?,\sum_{n=1}^{+ \infty}\left(\frac {1}{n}-\frac{1}{p_n}\right),"It is known that $$\sum_{n=1}^{+ \infty} \frac {1}{n}$$ is divergent. Also, it is known that $$\sum_{n=1}^{+ \infty} \frac {1}{p_n}$$ is divergent where $p_n$ is $n$ -th prime number. I was thinking what would happen (in the sense of convergence) if we termwise subtract these two series to obtain $$\sum_{n=1}^{+ \infty} \left(\frac {1}{n}-\frac{1}{p_n}\right)$$ Is $$\sum_{n=1}^{+ \infty} \left(\frac {1}{n}-\frac{1}{p_n}\right)$$ convergent?","It is known that is divergent. Also, it is known that is divergent where is -th prime number. I was thinking what would happen (in the sense of convergence) if we termwise subtract these two series to obtain Is convergent?",\sum_{n=1}^{+ \infty} \frac {1}{n} \sum_{n=1}^{+ \infty} \frac {1}{p_n} p_n n \sum_{n=1}^{+ \infty} \left(\frac {1}{n}-\frac{1}{p_n}\right) \sum_{n=1}^{+ \infty} \left(\frac {1}{n}-\frac{1}{p_n}\right),"['real-analysis', 'calculus']"
50,Proving $f'(1)$ exist for $f$ satisfying $f(xy)=xf(y)+yf(x)$,Proving  exist for  satisfying,f'(1) f f(xy)=xf(y)+yf(x),"The problem is: I have a continuous $f: \mathbb R_+ \to \mathbb R$ which satisfies $f(xy)=xf(y)+yf(x)$ for all $x,y \in \mathbb R_+$. I want to prove that $f$ is differentiable. The problem is equivalent to proving that $f'(1)$ exist. I have no idea how to go on.","The problem is: I have a continuous $f: \mathbb R_+ \to \mathbb R$ which satisfies $f(xy)=xf(y)+yf(x)$ for all $x,y \in \mathbb R_+$. I want to prove that $f$ is differentiable. The problem is equivalent to proving that $f'(1)$ exist. I have no idea how to go on.",,"['calculus', 'real-analysis', 'derivatives', 'functional-equations']"
51,A+B is closed if one of them is compact,A+B is closed if one of them is compact,,Q. Show that if A and B are closed subsets of $R^n$ and one of them is compact then A+B is closed. My doubt: A+B is not necessarily closed given A and B are closed. I need hints to start this question since it involves the concept of compactness.,Q. Show that if A and B are closed subsets of $R^n$ and one of them is compact then A+B is closed. My doubt: A+B is not necessarily closed given A and B are closed. I need hints to start this question since it involves the concept of compactness.,,['real-analysis']
52,"Let $f$ be a function such that $f'(x)=\frac{1}{x}$ and $f(1) = 0$ , show that $f(xy) = f(x) + f(y)$","Let  be a function such that  and  , show that",f f'(x)=\frac{1}{x} f(1) = 0 f(xy) = f(x) + f(y),"Let $f:\mathbb{R^+}\rightarrow \mathbb{R} $ a differentiable function such that $f'(x) = \frac{1}{x}$ and $f(1)=0$ . Show that $f(xy) = f(x) + f(y)$ for all $x,y \in \mathbb{R^+}$ It seems to be the logarithm function but I am unable to prove this statement without the fundamental theorem of calculus, is there any other way to prove this fact? Thanks for your help","Let $f:\mathbb{R^+}\rightarrow \mathbb{R} $ a differentiable function such that $f'(x) = \frac{1}{x}$ and $f(1)=0$ . Show that $f(xy) = f(x) + f(y)$ for all $x,y \in \mathbb{R^+}$ It seems to be the logarithm function but I am unable to prove this statement without the fundamental theorem of calculus, is there any other way to prove this fact? Thanks for your help",,"['real-analysis', 'derivatives']"
53,"""Length"" of rationals in an interval","""Length"" of rationals in an interval",,"For $x \in \mathbb{R}$, define $r(x)$ as follows: $$ r(x)= \begin{cases} 1 &\text{if $x$ is rational},\\ 0 &\text{if $x$ is irrational}. \end{cases} $$ Q. What is $\int_0^1 r(x) dx$ ? I know the rationals are dense in an interval, but countable, and so ""sparse."" My motivation is a desire to average over the rationals, and in some sense this integral would be the denominator. If the integral is zero, then I'll have to think of another route. Thanks!","For $x \in \mathbb{R}$, define $r(x)$ as follows: $$ r(x)= \begin{cases} 1 &\text{if $x$ is rational},\\ 0 &\text{if $x$ is irrational}. \end{cases} $$ Q. What is $\int_0^1 r(x) dx$ ? I know the rationals are dense in an interval, but countable, and so ""sparse."" My motivation is a desire to average over the rationals, and in some sense this integral would be the denominator. If the integral is zero, then I'll have to think of another route. Thanks!",,"['real-analysis', 'definite-integrals', 'irrational-numbers', 'rational-numbers']"
54,"Why differentiability implies continuity, but continuity does not imply differentiability?","Why differentiability implies continuity, but continuity does not imply differentiability?",,"Why does differentiability imply continuity, but continuity does not mean differentiability? I am more interested in the part about a continuous function not being differentiable. All I could find regarding why continuous functions can not be differentiable were counter-examples. I just wanted to know if there was a more detailed explanation.","Why does differentiability imply continuity, but continuity does not mean differentiability? I am more interested in the part about a continuous function not being differentiable. All I could find regarding why continuous functions can not be differentiable were counter-examples. I just wanted to know if there was a more detailed explanation.",,"['real-analysis', 'derivatives', 'continuity', 'examples-counterexamples']"
55,In what sense is a function on a circle the same as a $2 \pi$ periodic function on $\mathbb{R}$?,In what sense is a function on a circle the same as a  periodic function on ?,2 \pi \mathbb{R},I was reading the appendix of Elias M Stein's Fourier Analysis and before proving the approximation lemma the author mentions the following Recall that a function on a circle is the same as a $2 \pi$ periodic function on $\mathbb{R}$ Could someone explain me what this exactly means and how are the functions are the same?,I was reading the appendix of Elias M Stein's Fourier Analysis and before proving the approximation lemma the author mentions the following Recall that a function on a circle is the same as a $2 \pi$ periodic function on $\mathbb{R}$ Could someone explain me what this exactly means and how are the functions are the same?,,"['real-analysis', 'functions', 'circles', 'periodic-functions']"
56,Is it possible to have a convergent subsequence of a divergent sequence?,Is it possible to have a convergent subsequence of a divergent sequence?,,Is it possible to have a convergent subsequence of a divergent sequence? Thanks!,Is it possible to have a convergent subsequence of a divergent sequence? Thanks!,,['real-analysis']
57,function that is its own inverse,function that is its own inverse,,$f(f(x))=x \ \forall x \in \mathbb{R}$. I am trying to prove there exists an irrational $t$ such that $f(t)$ is also irrational. I have been trying things like assume $t$ irrational implies $f(t)$ is rational and then $f(f(t)+t)$ is rational but $f(f(f(t)+t))=f(t)+t$ but I can't come up with a contradiction. Is there a less mind-boggling approach?,$f(f(x))=x \ \forall x \in \mathbb{R}$. I am trying to prove there exists an irrational $t$ such that $f(t)$ is also irrational. I have been trying things like assume $t$ irrational implies $f(t)$ is rational and then $f(f(t)+t)$ is rational but $f(f(f(t)+t))=f(t)+t$ but I can't come up with a contradiction. Is there a less mind-boggling approach?,,"['real-analysis', 'elementary-set-theory']"
58,Find the exact value of $\int_{0}^{2}x[\frac{1}{x}]dx$.,Find the exact value of .,\int_{0}^{2}x[\frac{1}{x}]dx,"Find the exact value of $\int_{0}^{2}x\left[\frac{1}{x}\right]dx$ . Let $[x]$ denote $\lceil{x-\frac{1}{2}}\rceil$ . Using Desmos , I got $2.46736022133$ and WolframAlpha does not give me a solution. My intuition tells me that it might be possible to find an exact value using Trapezoidal Reimann Sums but I am not really sure how to go about doing it. After my attempt, I got stuck but I was at a point where I could plug it into WolframAlpha and it gave me $\frac{\pi^2}{4}$ . Why did it come out so nicely? My attempt: Where $A_n$ denotes the area of the $nth$ trapezoid from the right: $$A=\frac{h}{2}(a+b)$$ $$A_n=\frac{\frac{2}{2n-1}-\frac{2}{2n+1}}{2}(\frac{2n}{2n-1}+\frac{2n}{2n+1})$$ $$A_n=\frac{\frac{4n+2}{4n^{2}-1}-\frac{4n-2}{4n^{2}-1}}{2}\left(\frac{4n^{2}+2n}{4n^{2}-1}+\frac{4n^{2}-2n}{4n^{2}-1}\right)$$ $$A_n=\frac{2}{4n^{2}-1}\left(\frac{8n^{2}}{4n^{2}-1}\right)$$ $$A_n=\frac{16n^{2}}{\left(4n^{2}-1\right)^{2}}$$ Then: $$\int_{0}^{2}x\left[\frac{1}{x}\right]dx=\sum_{n=1}^{\infty}A_n=\sum_{n=1}^{\infty}\frac{16n^{2}}{\left(4n^{2}-1\right)^{2}}$$ I do not know how to solve this infinite summation so I plugged it into WolframAlpha and it gave me $\frac{\pi^2}{4}$ . How did it get to this conclusion? Is there a more efficient way to solve this?","Find the exact value of . Let denote . Using Desmos , I got and WolframAlpha does not give me a solution. My intuition tells me that it might be possible to find an exact value using Trapezoidal Reimann Sums but I am not really sure how to go about doing it. After my attempt, I got stuck but I was at a point where I could plug it into WolframAlpha and it gave me . Why did it come out so nicely? My attempt: Where denotes the area of the trapezoid from the right: Then: I do not know how to solve this infinite summation so I plugged it into WolframAlpha and it gave me . How did it get to this conclusion? Is there a more efficient way to solve this?",\int_{0}^{2}x\left[\frac{1}{x}\right]dx [x] \lceil{x-\frac{1}{2}}\rceil 2.46736022133 \frac{\pi^2}{4} A_n nth A=\frac{h}{2}(a+b) A_n=\frac{\frac{2}{2n-1}-\frac{2}{2n+1}}{2}(\frac{2n}{2n-1}+\frac{2n}{2n+1}) A_n=\frac{\frac{4n+2}{4n^{2}-1}-\frac{4n-2}{4n^{2}-1}}{2}\left(\frac{4n^{2}+2n}{4n^{2}-1}+\frac{4n^{2}-2n}{4n^{2}-1}\right) A_n=\frac{2}{4n^{2}-1}\left(\frac{8n^{2}}{4n^{2}-1}\right) A_n=\frac{16n^{2}}{\left(4n^{2}-1\right)^{2}} \int_{0}^{2}x\left[\frac{1}{x}\right]dx=\sum_{n=1}^{\infty}A_n=\sum_{n=1}^{\infty}\frac{16n^{2}}{\left(4n^{2}-1\right)^{2}} \frac{\pi^2}{4},"['real-analysis', 'definite-integrals']"
59,A limit involving $\frac{\pi^2}{6}$,A limit involving,\frac{\pi^2}{6},"Let $a_n=1+\frac{1}{2^2}+\dots+\frac{1}{n^2}$. Considering known that $\lim_{n\to\infty}a_n=\frac{\pi^2}{6}$, evaluate $$\lim_{n\to\infty}n\left( a_n-\frac{\pi^2}{6}\right)$$ My attempt: I first proved that $b_n=n\left( a_n-\frac{\pi^2}{6}\right)$ is decreasing , i.e. $b_{n+1}-b_n=a_n+\frac{1}{n+1}-\frac{\pi^2}{6} \leq 0$, which is true since $$\lim_{n\to\infty}\left(a_n+\frac{1}{n+1}\right)=\frac{\pi^2}{6}$$ and $a_n+\frac{1}{n+1}$ is an increasing sequence. Then I proved that $b_n$ is bounded by $0$ (obviously) and $-1$, the latter being true since it is equivalent to $a_n+\frac{1}{n}\geq \frac{\pi^2}{6}$, which can be proven as above. So $b_n$ is both decreasing and bounded, which means that it has a limit $l$ and I ended with Stolz-Cesaro: $$l=\lim_{n\to\infty}n\left( a_n-\frac{\pi^2}{6}\right)=\lim_{n\to\infty}\frac{n^2\left( a_n-\frac{\pi^2}{6}\right)}{n}=\lim_{n\to\infty}\left( (n+1)^2\left( a_{n+1}-\frac{\pi^2}{6}\right) -n^2\left( a_n-\frac{\pi^2}{6}\right)\right)=\lim_{n\to\infty}\left( \frac{n^2}{(n+1)^2}+a_{n+1}-\frac{\pi^2}{6}+2n\left( a_{n+1}-\frac{\pi^2}{6}\right)\right)=1+0+2l$$ so $l=-1$. Can anyone provide a shorter solution, if there is one, please?","Let $a_n=1+\frac{1}{2^2}+\dots+\frac{1}{n^2}$. Considering known that $\lim_{n\to\infty}a_n=\frac{\pi^2}{6}$, evaluate $$\lim_{n\to\infty}n\left( a_n-\frac{\pi^2}{6}\right)$$ My attempt: I first proved that $b_n=n\left( a_n-\frac{\pi^2}{6}\right)$ is decreasing , i.e. $b_{n+1}-b_n=a_n+\frac{1}{n+1}-\frac{\pi^2}{6} \leq 0$, which is true since $$\lim_{n\to\infty}\left(a_n+\frac{1}{n+1}\right)=\frac{\pi^2}{6}$$ and $a_n+\frac{1}{n+1}$ is an increasing sequence. Then I proved that $b_n$ is bounded by $0$ (obviously) and $-1$, the latter being true since it is equivalent to $a_n+\frac{1}{n}\geq \frac{\pi^2}{6}$, which can be proven as above. So $b_n$ is both decreasing and bounded, which means that it has a limit $l$ and I ended with Stolz-Cesaro: $$l=\lim_{n\to\infty}n\left( a_n-\frac{\pi^2}{6}\right)=\lim_{n\to\infty}\frac{n^2\left( a_n-\frac{\pi^2}{6}\right)}{n}=\lim_{n\to\infty}\left( (n+1)^2\left( a_{n+1}-\frac{\pi^2}{6}\right) -n^2\left( a_n-\frac{\pi^2}{6}\right)\right)=\lim_{n\to\infty}\left( \frac{n^2}{(n+1)^2}+a_{n+1}-\frac{\pi^2}{6}+2n\left( a_{n+1}-\frac{\pi^2}{6}\right)\right)=1+0+2l$$ so $l=-1$. Can anyone provide a shorter solution, if there is one, please?",,"['calculus', 'real-analysis', 'limits']"
60,Infinite Series $\sum_{m=0}^\infty\sum_{n=0}^\infty\frac{m!\:n!}{(m+n+2)!}$,Infinite Series,\sum_{m=0}^\infty\sum_{n=0}^\infty\frac{m!\:n!}{(m+n+2)!},Evaluating $$\sum_{m=0}^\infty \sum_{n=0}^\infty\frac{m!n!}{(m+n+2)!}$$ involving binomial coefficients. My attempt: $$\frac{1}{(m+1)(n+1)}\sum_{m=0}^\infty \sum_{n=0}^\infty\frac{(m+1)!(n+1)!}{(m+n+2)!}=\frac{1}{(m+1)(n+1)} \sum_{m=0}^\infty \sum_{n=0}^\infty\frac{1}{\binom{m+n+2}{m+1}}=?$$ Is there any closed form of this expression?,Evaluating $$\sum_{m=0}^\infty \sum_{n=0}^\infty\frac{m!n!}{(m+n+2)!}$$ involving binomial coefficients. My attempt: $$\frac{1}{(m+1)(n+1)}\sum_{m=0}^\infty \sum_{n=0}^\infty\frac{(m+1)!(n+1)!}{(m+n+2)!}=\frac{1}{(m+1)(n+1)} \sum_{m=0}^\infty \sum_{n=0}^\infty\frac{1}{\binom{m+n+2}{m+1}}=?$$ Is there any closed form of this expression?,,"['calculus', 'real-analysis', 'sequences-and-series', 'binomial-coefficients', 'closed-form']"
61,Using the definition of a limit to prove 1/n converges to zero.,Using the definition of a limit to prove 1/n converges to zero.,,"So we define a sequence as a sequence ${a_n}$ is said to converge to a number $\alpha$ provided that for every positive number $\epsilon$ there is a natural number N such that |${a_n}$ - $\alpha$| < $\epsilon$ for all integers n $\geq$ N. What I'm not understanding is what does this mean. For example, $\frac{1}{n}$ converges to 0. But I don't understand how I use this definition to prove that this converges to 0. It sounds trivial but how do I use the definition to prove that $\frac{1}{n}$ converges to 0. Can you also show the reasoning as to why you use certain steps?","So we define a sequence as a sequence ${a_n}$ is said to converge to a number $\alpha$ provided that for every positive number $\epsilon$ there is a natural number N such that |${a_n}$ - $\alpha$| < $\epsilon$ for all integers n $\geq$ N. What I'm not understanding is what does this mean. For example, $\frac{1}{n}$ converges to 0. But I don't understand how I use this definition to prove that this converges to 0. It sounds trivial but how do I use the definition to prove that $\frac{1}{n}$ converges to 0. Can you also show the reasoning as to why you use certain steps?",,"['real-analysis', 'sequences-and-series', 'limits', 'epsilon-delta']"
62,Deriving inverse matrix formula,Deriving inverse matrix formula,,"If matrix $A$ is given with dimensions $2 \times2 $ then, A is invertible if, and only, if $ad - bc \neq 0$: $$\begin{bmatrix}a & b\ \\c & d \ \end{bmatrix}^{-1} = \frac{1}{ad - bc}\begin{bmatrix}d & -b\ \\-c & a \ \end{bmatrix}$$ How can this be derived? I just need hints, I am not good at properties etc.. of matrices, please help!","If matrix $A$ is given with dimensions $2 \times2 $ then, A is invertible if, and only, if $ad - bc \neq 0$: $$\begin{bmatrix}a & b\ \\c & d \ \end{bmatrix}^{-1} = \frac{1}{ad - bc}\begin{bmatrix}d & -b\ \\-c & a \ \end{bmatrix}$$ How can this be derived? I just need hints, I am not good at properties etc.. of matrices, please help!",,"['real-analysis', 'linear-algebra', 'matrices', 'analysis']"
63,A difficult integral evaluation problem,A difficult integral evaluation problem,,"How do I compute the integration for $a>0$, $$ \int_0^\pi \frac{x\sin x}{1-2a\cos x+a^2}dx? $$ I want to find a complex function and integrate by the residue theorem .","How do I compute the integration for $a>0$, $$ \int_0^\pi \frac{x\sin x}{1-2a\cos x+a^2}dx? $$ I want to find a complex function and integrate by the residue theorem .",,"['calculus', 'real-analysis', 'complex-analysis', 'analysis', 'residue-calculus']"
64,Functional equations $f(x+y)= f(x) + f(y)$ and $f(xy)= f(x)f(y)$,Functional equations  and,f(x+y)= f(x) + f(y) f(xy)= f(x)f(y),"Let $f:\mathbb{R}\to \mathbb{R}$ is a function such that for all real $x$ and $y$, $f(x+y)= f(x) + f(y)$ and $f(xy)= f(x)f(y)$, then prove that $f$ must be one of the two following functions: $f:\mathbb{R}\to \mathbb{R}$ defined by $f(x)=0$ for all real $x$ OR $f:\mathbb{R}\to\mathbb{R}$ defined by $f(x)=x$ for all real $x$ I got to the point where putting the two equations together, you get $f(x+y)f(x)= f(xy) + f(x)^2$ and plugging in $f(x)=x$ checks with it. So am I going in the right direction or am I just doing some guess work? Is there a more elegant way of doing it? Thanks","Let $f:\mathbb{R}\to \mathbb{R}$ is a function such that for all real $x$ and $y$, $f(x+y)= f(x) + f(y)$ and $f(xy)= f(x)f(y)$, then prove that $f$ must be one of the two following functions: $f:\mathbb{R}\to \mathbb{R}$ defined by $f(x)=0$ for all real $x$ OR $f:\mathbb{R}\to\mathbb{R}$ defined by $f(x)=x$ for all real $x$ I got to the point where putting the two equations together, you get $f(x+y)f(x)= f(xy) + f(x)^2$ and plugging in $f(x)=x$ checks with it. So am I going in the right direction or am I just doing some guess work? Is there a more elegant way of doing it? Thanks",,"['real-analysis', 'functional-equations']"
65,Limits of sequences of sets,Limits of sequences of sets,,"I am starting to learn about the liminf and limsup of a sequence of sets. However, I do not understand the very basics, such as why $\lim\sup A_n=\bigcap_{n\in N}\bigcup_{k>n} A_k,$ and why $\lim\sup A_n=\bigcup_{n\in N}\bigcap_{k>n}A_k.$ Can someone break these definitions down for me? Also, why is $\lim\inf\subseteq\lim\sup$?","I am starting to learn about the liminf and limsup of a sequence of sets. However, I do not understand the very basics, such as why $\lim\sup A_n=\bigcap_{n\in N}\bigcup_{k>n} A_k,$ and why $\lim\sup A_n=\bigcup_{n\in N}\bigcap_{k>n}A_k.$ Can someone break these definitions down for me? Also, why is $\lim\inf\subseteq\lim\sup$?",,['real-analysis']
66,What is the Idea of a Relative Open Set?,What is the Idea of a Relative Open Set?,,"My real-analysis text gave the following defintion: Let U be a subset of E.  U is open relative to E if for $\forall t \in U$, $\exists \epsilon$ such that $N_\epsilon(t) \cap E \subset U$. Although the idea that U is open in $\mathbb R$ follows the definition, I normally do not think about the intersection of $N_\epsilon(t) \cap \mathbb R$. U is open if for $\forall t \in U$, $\exists \epsilon$ such that $N_\epsilon(t) \subset U$; every t is an interior point of U. Intuitively, each point, t, is contained in a ""bubble"". So, what is the significance of specifying the intersection? Apparently, I can't think of a relative open set in terms like interior points and ""bubbles"".","My real-analysis text gave the following defintion: Let U be a subset of E.  U is open relative to E if for $\forall t \in U$, $\exists \epsilon$ such that $N_\epsilon(t) \cap E \subset U$. Although the idea that U is open in $\mathbb R$ follows the definition, I normally do not think about the intersection of $N_\epsilon(t) \cap \mathbb R$. U is open if for $\forall t \in U$, $\exists \epsilon$ such that $N_\epsilon(t) \subset U$; every t is an interior point of U. Intuitively, each point, t, is contained in a ""bubble"". So, what is the significance of specifying the intersection? Apparently, I can't think of a relative open set in terms like interior points and ""bubbles"".",,"['real-analysis', 'general-topology']"
67,Continuous function that take irrationals to rationals and vice-versa. [duplicate],Continuous function that take irrationals to rationals and vice-versa. [duplicate],,This question already has answers here : No continuous function switches $\mathbb{Q}$ and the irrationals (4 answers) Closed 11 years ago . Can someone help me? How can I prove that there isn't an everywhere continuous function $f:\mathbb R \rightarrow \mathbb R$ that transforms every rational into an irrational and vice-versa?,This question already has answers here : No continuous function switches $\mathbb{Q}$ and the irrationals (4 answers) Closed 11 years ago . Can someone help me? How can I prove that there isn't an everywhere continuous function $f:\mathbb R \rightarrow \mathbb R$ that transforms every rational into an irrational and vice-versa?,,"['real-analysis', 'functions', 'continuity']"
68,"Is it true that |X| vanishes at infinity, then X is integrable?","Is it true that |X| vanishes at infinity, then X is integrable?",,"Suppose $X$ is a random variable on $(\Omega,\mathscr{F},\mathbb{P})$ . If there exists $M>0$ , such that for all $\lambda>0$ , we have $\mathbb{P}[|X|>\lambda]\le\frac{M}{\lambda}$ , then is it true that $X$ is integrable? This condition is weaker than the absolute continuty: Does absolute continuity of integral imply integrability on finite measure space , but compared to absolute continuity, the condition above gives a explicit inequality. So, I'm not sure if it is true. My attempt: $$\mathbb{E}[|X|]=\int_0^{+\infty}\mathbb{P}(|X|>\lambda) \ d\lambda\le M\int_0^{+\infty}\frac{1}{\lambda}\ d\lambda,$$ but the right side is infinite.","Suppose is a random variable on . If there exists , such that for all , we have , then is it true that is integrable? This condition is weaker than the absolute continuty: Does absolute continuity of integral imply integrability on finite measure space , but compared to absolute continuity, the condition above gives a explicit inequality. So, I'm not sure if it is true. My attempt: but the right side is infinite.","X (\Omega,\mathscr{F},\mathbb{P}) M>0 \lambda>0 \mathbb{P}[|X|>\lambda]\le\frac{M}{\lambda} X \mathbb{E}[|X|]=\int_0^{+\infty}\mathbb{P}(|X|>\lambda) \ d\lambda\le M\int_0^{+\infty}\frac{1}{\lambda}\ d\lambda,","['real-analysis', 'probability', 'measure-theory', 'statistics']"
69,Evaluating a rational function integral in a quick way,Evaluating a rational function integral in a quick way,,"In an recent test I was asked to evaluate the integral $$ \int_0^1 \frac{\sqrt[3]{x^2(1-x)}}{(1+x)^3} \text{d}x$$ in 8 minutes, but I didn't have a clue what to do with it. After the test, I tried the following approach: substituting $x=\frac{1}{t}, u=\sqrt[3]{t-1}$ gives $$ \int_0^1 \frac{\sqrt[3]{x^2(1-x)}}{(1+x)^3} \text{d}x=\int_1^\infty \frac{\sqrt[3]{t-1}}{(t+1)^3}\text{d}t=\int_0^\infty \frac{3u^3}{(u^3+2)^3}\text{d}u$$ then it becomes a problem of evaluating a rational function integral, but I still don't think it could be done in the time limit. Is there any quick method to evaluate this? Thanks for any help. (Note: 1. The integral is $\frac{\pi}{9\times 2^{2/3}\sqrt3}$ according to Wolfram Alpha. 2. It is best to solve it with first-year calculus, and I will understand more easily. Other solutions are also welcomed:)","In an recent test I was asked to evaluate the integral in 8 minutes, but I didn't have a clue what to do with it. After the test, I tried the following approach: substituting gives then it becomes a problem of evaluating a rational function integral, but I still don't think it could be done in the time limit. Is there any quick method to evaluate this? Thanks for any help. (Note: 1. The integral is according to Wolfram Alpha. 2. It is best to solve it with first-year calculus, and I will understand more easily. Other solutions are also welcomed:)"," \int_0^1 \frac{\sqrt[3]{x^2(1-x)}}{(1+x)^3} \text{d}x x=\frac{1}{t}, u=\sqrt[3]{t-1}  \int_0^1 \frac{\sqrt[3]{x^2(1-x)}}{(1+x)^3} \text{d}x=\int_1^\infty \frac{\sqrt[3]{t-1}}{(t+1)^3}\text{d}t=\int_0^\infty \frac{3u^3}{(u^3+2)^3}\text{d}u \frac{\pi}{9\times 2^{2/3}\sqrt3}","['real-analysis', 'calculus', 'integration', 'definite-integrals', 'rational-functions']"
70,compute $\int_0^1\sqrt{x(1-x)}dx$.,compute .,\int_0^1\sqrt{x(1-x)}dx,"My sister has a following integral to compute $$\int_0^1\sqrt{x(1-x)}dx.$$ I know how to compute it : doing the substitution $x=\sin^2(u)$ yields $$\int_0^{\pi/2}2\sin(x)^2\cos^2(x)dx=\frac{1}{2}\int_0^{\pi/2}\sin^2(2x)dx=\frac{1}{4}\int_0^{\pi/2}(1-\cos(4x))dx=\frac{\pi}{8}.$$ So I know how to do it. However, my sister is in high school, and they never saw substitution, so it's impossible that it's what her teacher expect. Is there an other way to compute it with more elementary tools ? I don't see it...","My sister has a following integral to compute I know how to compute it : doing the substitution yields So I know how to do it. However, my sister is in high school, and they never saw substitution, so it's impossible that it's what her teacher expect. Is there an other way to compute it with more elementary tools ? I don't see it...",\int_0^1\sqrt{x(1-x)}dx. x=\sin^2(u) \int_0^{\pi/2}2\sin(x)^2\cos^2(x)dx=\frac{1}{2}\int_0^{\pi/2}\sin^2(2x)dx=\frac{1}{4}\int_0^{\pi/2}(1-\cos(4x))dx=\frac{\pi}{8}.,"['real-analysis', 'integration']"
71,Continuity of a strange function,Continuity of a strange function,,"Let $f: [0,1)\to\mathbb{R}$ such that $f(x)=0.a_1a_3a_5\ldots$ where $x=0.a_1a_2a_3a_4\ldots$ , i.e, $f(x)$ skips the even digits of $x$ . Prove $f$ is continuous at $0$ , and find a point where $f$ is not continuous. Updated: If the expansion of $x$ could be finite, we adopt the finite expansion. As we can see, $f(0)=0$ and $f(x)\geq 0$ for all $x\in[0,1)$ . To prove $f$ is continuous, we want to estimate $f(x)$ less than some elementary function $g(x)$ . I tried to estimate it, but the function is so strange. Did anyone see the similar function before? Any hint would be highly appreciated.","Let such that where , i.e, skips the even digits of . Prove is continuous at , and find a point where is not continuous. Updated: If the expansion of could be finite, we adopt the finite expansion. As we can see, and for all . To prove is continuous, we want to estimate less than some elementary function . I tried to estimate it, but the function is so strange. Did anyone see the similar function before? Any hint would be highly appreciated.","f: [0,1)\to\mathbb{R} f(x)=0.a_1a_3a_5\ldots x=0.a_1a_2a_3a_4\ldots f(x) x f 0 f x f(0)=0 f(x)\geq 0 x\in[0,1) f f(x) g(x)","['real-analysis', 'calculus', 'continuity']"
72,What's the answer to $\int \frac{\cos^2x \sin x}{\sin x - \cos x} dx$?,What's the answer to ?,\int \frac{\cos^2x \sin x}{\sin x - \cos x} dx,"I tried solving the integral $$\int \frac{\cos^2x \sin x}{\sin x - \cos x}\, dx$$ the following ways: Expressing each function in the form of $\tan \left(\frac{x}{2}\right)$ , $\cos \left(\frac{x}{2}\right)\,$ and $\,\sin \left(\frac{x}{2}\right)\,$ independently, but that didn't go well for me. Multiplying and dividing by $\cos^2x$ or $\sin^2x$ . Expressing $\cos^2x$ as $1-\sin^2x$ and splitting the integral, and I was stuck with $\int \left(\frac{\sin^3x}{\sin x - \cos x}\right)\, dx$ which I rewrote as $\int \frac{\csc^2x}{\csc^4x (1-\cot x) } dx,\,$ and tried a whole range of substitutions only to fail. I tried to substitute $\frac{1}{ \sin x - \cos x}$ , $\frac{\sin x}{ \sin x - \cos x}$ , $\frac{\cos x \sin x}{ \sin x - \cos x}$ and $\frac{\cos^2x \sin x}{\sin x - \cos x},$ independently, none of which seemed to work  out. I expressed the denominator as $\sin\left(\frac{\pi}{4}-x\right)$ and tried multiplying and dividing by $\sin\left(\frac{\pi}{4}+x\right)$ , and carried out some substitutions. Then, I repeated the same with $\cos\left(\frac{\pi}{4}+x\right)$ . Neither of them worked.","I tried solving the integral the following ways: Expressing each function in the form of , and independently, but that didn't go well for me. Multiplying and dividing by or . Expressing as and splitting the integral, and I was stuck with which I rewrote as and tried a whole range of substitutions only to fail. I tried to substitute , , and independently, none of which seemed to work  out. I expressed the denominator as and tried multiplying and dividing by , and carried out some substitutions. Then, I repeated the same with . Neither of them worked.","\int \frac{\cos^2x \sin x}{\sin x - \cos x}\, dx \tan \left(\frac{x}{2}\right) \cos \left(\frac{x}{2}\right)\, \,\sin \left(\frac{x}{2}\right)\, \cos^2x \sin^2x \cos^2x 1-\sin^2x \int \left(\frac{\sin^3x}{\sin x - \cos x}\right)\, dx \int \frac{\csc^2x}{\csc^4x (1-\cot x) } dx,\, \frac{1}{ \sin x - \cos x} \frac{\sin x}{ \sin x - \cos x} \frac{\cos x \sin x}{ \sin x - \cos x} \frac{\cos^2x \sin x}{\sin x - \cos x}, \sin\left(\frac{\pi}{4}-x\right) \sin\left(\frac{\pi}{4}+x\right) \cos\left(\frac{\pi}{4}+x\right)","['real-analysis', 'integration', 'indefinite-integrals', 'substitution', 'trigonometric-integrals']"
73,Compact metric connected space,Compact metric connected space,,"If I have a compact metric space $X$ such that for all $a,b \in X$, there are points $a:=x_1,...x_n=:b$ such that $d(x_i,x_{i+1})< \varepsilon$, then this space is connected. Somehow, I don't see how to do this. Does anybody have an idea?","If I have a compact metric space $X$ such that for all $a,b \in X$, there are points $a:=x_1,...x_n=:b$ such that $d(x_i,x_{i+1})< \varepsilon$, then this space is connected. Somehow, I don't see how to do this. Does anybody have an idea?",,"['real-analysis', 'general-topology']"
74,How to evaluate $\sum\limits_{k=0}^{n} \sqrt{\binom{n}{k}} $,How to evaluate,\sum\limits_{k=0}^{n} \sqrt{\binom{n}{k}} ,"Can we find $$ \sum_{k=0}^{n} \sqrt{\binom{n}{k}} \quad$$ This problem asked me my friend about a year ago, but I didn't know how to attack problem. Now, I am interesting in solution. Any suggestion?","Can we find $$ \sum_{k=0}^{n} \sqrt{\binom{n}{k}} \quad$$ This problem asked me my friend about a year ago, but I didn't know how to attack problem. Now, I am interesting in solution. Any suggestion?",,"['real-analysis', 'summation', 'asymptotics', 'binomial-coefficients']"
75,"Relation between $T=0$ and $(Tx,x)=0$",Relation between  and,"T=0 (Tx,x)=0","Let $X$ be a vector space and (.,.) be an inner product on $X$ also if we have a linear operator $T:X\rightarrow X$, then in both cases real and complex for inner product what is the relation between $T=0$ and $(Tx,x)=0$?","Let $X$ be a vector space and (.,.) be an inner product on $X$ also if we have a linear operator $T:X\rightarrow X$, then in both cases real and complex for inner product what is the relation between $T=0$ and $(Tx,x)=0$?",,"['real-analysis', 'functional-analysis']"
76,"If the graph of a function $f: A \rightarrow \mathbb R$ is compact, is $f$ continuous where $A$ is a compact metric space?","If the graph of a function  is compact, is  continuous where  is a compact metric space?",f: A \rightarrow \mathbb R f A,"I have seen answers to this question, which go beyond my understanding of compactness and continuity. I was wondering whether we can cook up a proof using sequential compactness and certain equivalent definitions of continuity such as the inverse image of any closed set is closed. Here is what I have been able to conjure up so far. Assume that the graph of $f$ is compact. This means that it is also closed and bounded. The graph is a closed and bounded subset of $A \times f(A)$. All we need to show is that $f(A)$ is compact, and we are are home free, right? (since continuous functions take compact sets to compact sets). Question is: how do we show that $f(A)$ using the fact that the graph is compact. Can we claim that $f(A)$ is closed and bounded (since by Heine-Borel, any closed and bounded subset of $\mathbb R$ is compact)? I feel like I am really close. Can anyone help me out?","I have seen answers to this question, which go beyond my understanding of compactness and continuity. I was wondering whether we can cook up a proof using sequential compactness and certain equivalent definitions of continuity such as the inverse image of any closed set is closed. Here is what I have been able to conjure up so far. Assume that the graph of $f$ is compact. This means that it is also closed and bounded. The graph is a closed and bounded subset of $A \times f(A)$. All we need to show is that $f(A)$ is compact, and we are are home free, right? (since continuous functions take compact sets to compact sets). Question is: how do we show that $f(A)$ using the fact that the graph is compact. Can we claim that $f(A)$ is closed and bounded (since by Heine-Borel, any closed and bounded subset of $\mathbb R$ is compact)? I feel like I am really close. Can anyone help me out?",,"['real-analysis', 'general-topology', 'compactness']"
77,Does the improper integral $\int_0^\infty e^{-x^2}dx$ converge?,Does the improper integral  converge?,\int_0^\infty e^{-x^2}dx,"I want to show the convergence of the following improper integral $\int_0^\infty e^{-x^2}dx$. I try to use comparison test for integrals $x≥0$, $-x ≥0$, $-x^2≥0$ then $e^{-x^2}≤1$. So am ending with the fact that $\int_0^\infty e^{-x^2}dx$ converges if $\int_0^\infty dx$ converges but I don’t  appreciate this. Thanks","I want to show the convergence of the following improper integral $\int_0^\infty e^{-x^2}dx$. I try to use comparison test for integrals $x≥0$, $-x ≥0$, $-x^2≥0$ then $e^{-x^2}≤1$. So am ending with the fact that $\int_0^\infty e^{-x^2}dx$ converges if $\int_0^\infty dx$ converges but I don’t  appreciate this. Thanks",,"['real-analysis', 'integration']"
78,When can we plug in values in a limit?,When can we plug in values in a limit?,,"When is it that we can plug in the limit point into the function to evaluate a limit? I believe for real limit points, we can do this when the function is continuous at the point. But what about for limits at $ \infty $ and $ -\infty $? Is there a general statement that we can make about this? Example : It is easy to believe that the following limit evaluates to $ 0 $ $$ \lim_{n\to\infty}{\sqrt{n^2+n}-n} $$ How can we not fall into these traps? EDIT: Yes, the above limit is simple to evaluate correctly (it's $ 1/2 $). But what I'm asking is for a rigorous condition under which we can know whether or not we can naively plug in the value to get the correct answer.","When is it that we can plug in the limit point into the function to evaluate a limit? I believe for real limit points, we can do this when the function is continuous at the point. But what about for limits at $ \infty $ and $ -\infty $? Is there a general statement that we can make about this? Example : It is easy to believe that the following limit evaluates to $ 0 $ $$ \lim_{n\to\infty}{\sqrt{n^2+n}-n} $$ How can we not fall into these traps? EDIT: Yes, the above limit is simple to evaluate correctly (it's $ 1/2 $). But what I'm asking is for a rigorous condition under which we can know whether or not we can naively plug in the value to get the correct answer.",,"['calculus', 'real-analysis', 'limits']"
79,"Does real analysis have new theorems, or is it just a collection of proofs of old calculus theorems?","Does real analysis have new theorems, or is it just a collection of proofs of old calculus theorems?",,"I am trying to teach myself real analysis, but I was wondering if this subject is just a collection of proofs of calculus theorems. Aside from set theory, I haven’t learned anything new. By that, I mean I haven’t come across any new theorems that I didn’t already know from calculus. Also, in calculus, there are many difficult problems, including challenging integrals and limits. However, the problems I have faced so far in real analysis were hard because of my proof-writing skills, not because they were difficult problems like integrals. My second question is: If real analysis does not deal with hard integrals and if calculus books like Thomas' book don't have hard problems, then where does the insanely hard integrals that I see online came from ? something like nonelementary integrals or  nonelementary function like $\operatorname{Li}(x)$ . Where I can study them if not in real analysis or calculus   ?","I am trying to teach myself real analysis, but I was wondering if this subject is just a collection of proofs of calculus theorems. Aside from set theory, I haven’t learned anything new. By that, I mean I haven’t come across any new theorems that I didn’t already know from calculus. Also, in calculus, there are many difficult problems, including challenging integrals and limits. However, the problems I have faced so far in real analysis were hard because of my proof-writing skills, not because they were difficult problems like integrals. My second question is: If real analysis does not deal with hard integrals and if calculus books like Thomas' book don't have hard problems, then where does the insanely hard integrals that I see online came from ? something like nonelementary integrals or  nonelementary function like . Where I can study them if not in real analysis or calculus   ?",\operatorname{Li}(x),"['real-analysis', 'calculus', 'integration', 'book-recommendation']"
80,"Is $d(x,y)=(x-y)^2$ a valid metric in $\mathbb R$?",Is  a valid metric in ?,"d(x,y)=(x-y)^2 \mathbb R","Is $d(x,y)=(x-y)^2$ a valid metric in  $\mathbb R$? So obviously $d(x,y)=(x-y)^2\ge0$ for all $x,y \in \mathbb R$ and equality iff $x=y$, and is also symmetric $d(x,y)=d(y,x)$. But how do I check if $d(x,z)\le d(x,y)+d(y,z)$ ? I tried $d(x,z)=(x-z)^2=\lvert x-z\rvert ^2\le (\lvert x-y\rvert + \lvert y-z \rvert)^2$ but there is a leftover $2\lvert x-y \rvert \lvert y-z \rvert$ term","Is $d(x,y)=(x-y)^2$ a valid metric in  $\mathbb R$? So obviously $d(x,y)=(x-y)^2\ge0$ for all $x,y \in \mathbb R$ and equality iff $x=y$, and is also symmetric $d(x,y)=d(y,x)$. But how do I check if $d(x,z)\le d(x,y)+d(y,z)$ ? I tried $d(x,z)=(x-z)^2=\lvert x-z\rvert ^2\le (\lvert x-y\rvert + \lvert y-z \rvert)^2$ but there is a leftover $2\lvert x-y \rvert \lvert y-z \rvert$ term",,"['real-analysis', 'metric-spaces']"
81,A generalized derivative,A generalized derivative,,"Suppose that we define a ""derivative"" in the following way: $$\mathcal{D^{*^\alpha}}=\lim_{x\to x_0}\frac{f(x)^\alpha-f(x_0)^\alpha}{x-x_0}, $$ where $\alpha$ is a real number. What would be the rules of derivation of a function (product, sum, composition,...)? What could we say about a ""Taylor Polynomial"" using this kind of derivative? Is there any advantage in using this object?","Suppose that we define a ""derivative"" in the following way: $$\mathcal{D^{*^\alpha}}=\lim_{x\to x_0}\frac{f(x)^\alpha-f(x_0)^\alpha}{x-x_0}, $$ where $\alpha$ is a real number. What would be the rules of derivation of a function (product, sum, composition,...)? What could we say about a ""Taylor Polynomial"" using this kind of derivative? Is there any advantage in using this object?",,"['calculus', 'real-analysis', 'analysis']"
82,Evaluate $ \int_0^\pi \left( \frac{2 + 2\cos (x) - \cos((k-1)x) - 2\cos (kx) - \cos((k+1)x)}{1-\cos (2x)}\right) \mathrm{d}x $,Evaluate, \int_0^\pi \left( \frac{2 + 2\cos (x) - \cos((k-1)x) - 2\cos (kx) - \cos((k+1)x)}{1-\cos (2x)}\right) \mathrm{d}x ,"Evaluate the following definite integral: $$ \int_0^\pi  \left( \frac{2 + 2\cos (x) - \cos((k-1)x) - 2\cos (kx) - \cos((k+1)x)}{1-\cos(2x)}\right) \mathrm{d}x, $$ where $k \in \mathbb{N}_{>0}$.","Evaluate the following definite integral: $$ \int_0^\pi  \left( \frac{2 + 2\cos (x) - \cos((k-1)x) - 2\cos (kx) - \cos((k+1)x)}{1-\cos(2x)}\right) \mathrm{d}x, $$ where $k \in \mathbb{N}_{>0}$.",,"['calculus', 'real-analysis', 'integration', 'analysis', 'definite-integrals']"
83,What level of rigour is expected in Real Analysis?,What level of rigour is expected in Real Analysis?,,"I fail to find a duplicate. I am wondering what level of rigour is needed in a typical undergraduate course in Real Analysis. To clarify my question, I provide an exercise from Rudin and my proposed solution: (Exercise 5, Chapter 1) Let $A$ be a nonempty set of real numbers which is bounded below. Let $-A$ be the set of all numbers $-x$, where $x \in A$. Prove that $$\inf A = -\sup(-A)$$ My answer: $A$ is bounded below. As such, $-A$ must be bounded above. Suppose $\alpha$ is the greatest lower bound of $A$.  It follows that $-\alpha$ is the least upper bound of $-A$. As such, we arrive at the desired expression $$\inf A = -\sup(-A)$$ This, for instance, feels very short, but I also feel that there is not much more to be said here. While this task might possibly be a bad example, I dare to guess that the most common pitfall for young students entering higher mathematics is that they underestimate the rigour needed to solve seemingly trivial problems. As such, I ask for an elaboration on this. The provided example does not necessarily have to be used in your answer.","I fail to find a duplicate. I am wondering what level of rigour is needed in a typical undergraduate course in Real Analysis. To clarify my question, I provide an exercise from Rudin and my proposed solution: (Exercise 5, Chapter 1) Let $A$ be a nonempty set of real numbers which is bounded below. Let $-A$ be the set of all numbers $-x$, where $x \in A$. Prove that $$\inf A = -\sup(-A)$$ My answer: $A$ is bounded below. As such, $-A$ must be bounded above. Suppose $\alpha$ is the greatest lower bound of $A$.  It follows that $-\alpha$ is the least upper bound of $-A$. As such, we arrive at the desired expression $$\inf A = -\sup(-A)$$ This, for instance, feels very short, but I also feel that there is not much more to be said here. While this task might possibly be a bad example, I dare to guess that the most common pitfall for young students entering higher mathematics is that they underestimate the rigour needed to solve seemingly trivial problems. As such, I ask for an elaboration on this. The provided example does not necessarily have to be used in your answer.",,"['real-analysis', 'soft-question']"
84,Does there exist an unbounded function that is uniformly continuous?,Does there exist an unbounded function that is uniformly continuous?,,"I know that $1/x$ is unbounded on $(0,5)$ (for example) and that since it is unbounded, it is not uniformly continuous. Does a function have to be bounded to be uniformly continuous? I don't think one exists.","I know that $1/x$ is unbounded on $(0,5)$ (for example) and that since it is unbounded, it is not uniformly continuous. Does a function have to be bounded to be uniformly continuous? I don't think one exists.",,"['real-analysis', 'continuity', 'uniform-continuity']"
85,Why is $x\log(x)$ convex?,Why is  convex?,x\log(x),"Why is $x\log(x)$ convex? According to the definition it must hold: $(tx+(1-t)y)\log(tx+(1-t)y)\le tx\log(x)+(1-t)y\log(y)$ for all positive $x,y$ and $t\in[0,1]$ edit: It is allowed to derive, but i have to prove using the definition.","Why is $x\log(x)$ convex? According to the definition it must hold: $(tx+(1-t)y)\log(tx+(1-t)y)\le tx\log(x)+(1-t)y\log(y)$ for all positive $x,y$ and $t\in[0,1]$ edit: It is allowed to derive, but i have to prove using the definition.",,"['real-analysis', 'inequality', 'logarithms']"
86,Counterexample that the arbitrary union of compact sets is compact,Counterexample that the arbitrary union of compact sets is compact,,"I want to show that it is not true that for any metric space $(X,d)$ , the arbitrary union of compact subsets of $X$ is always compact. For this I use the following counterexample: Consider the metric space $(\mathbb{R},d)$ with $d$ being the euclidean metric. Let $\mathcal{A}=\left\{[a,a]:a\in\mathbb{R}\right\}$ , note that every element in $\mathcal{A}$ is a closed and bounded interval, then by the Heine-Borel theorem, each element of $\mathcal{A}$ is compact in this metric space. Note that $\cup\mathcal{A}=\bigcup_{a\in\mathbb{R}}[a,a]=\mathbb{R}$ , which is not compact. Then we found a metric space for which there is an arbitrary union of compact subsets that is not compact. Is this counterexample right? I'm a bit dubious about the use I'm making of the notion of ""arbitrary"" union, since I'm not positive that $\mathbb{R}$ is actually an arbitrary index set (since at the end I'm choosing the index set). In other words, I think I'm implying that ""arbitrary"" and ""uncountable"" are equivalent notions in this context, fact that I'm not sure of. Thank you!","I want to show that it is not true that for any metric space , the arbitrary union of compact subsets of is always compact. For this I use the following counterexample: Consider the metric space with being the euclidean metric. Let , note that every element in is a closed and bounded interval, then by the Heine-Borel theorem, each element of is compact in this metric space. Note that , which is not compact. Then we found a metric space for which there is an arbitrary union of compact subsets that is not compact. Is this counterexample right? I'm a bit dubious about the use I'm making of the notion of ""arbitrary"" union, since I'm not positive that is actually an arbitrary index set (since at the end I'm choosing the index set). In other words, I think I'm implying that ""arbitrary"" and ""uncountable"" are equivalent notions in this context, fact that I'm not sure of. Thank you!","(X,d) X (\mathbb{R},d) d \mathcal{A}=\left\{[a,a]:a\in\mathbb{R}\right\} \mathcal{A} \mathcal{A} \cup\mathcal{A}=\bigcup_{a\in\mathbb{R}}[a,a]=\mathbb{R} \mathbb{R}","['real-analysis', 'solution-verification', 'metric-spaces']"
87,"Do three distinct functions f, g and h exist such that f'=g, g'=h and h'=f?","Do three distinct functions f, g and h exist such that f'=g, g'=h and h'=f?",,"First year math student here taking Analysis II. Today we learned about sinh, cosh and tanh and how to take their derivatives. Our teacher, in his magnanimity, wrote on the board after fiddling with sinh and cosh that sinh'=cosh and cosh'=sinh. I noticed the oscillatory nature of this, and after commenting on it, quickly asked the question you see up above. He wasn't able to provide an answer; a friend of mine inquired on it and we ended up learning that functions whose nth derivative is itself have a special name. Yet we are no closer to finding three distinct functions that fit the bill. I would also kindly ask that if you are able to generalize this to the nth derivative please do so!","First year math student here taking Analysis II. Today we learned about sinh, cosh and tanh and how to take their derivatives. Our teacher, in his magnanimity, wrote on the board after fiddling with sinh and cosh that sinh'=cosh and cosh'=sinh. I noticed the oscillatory nature of this, and after commenting on it, quickly asked the question you see up above. He wasn't able to provide an answer; a friend of mine inquired on it and we ended up learning that functions whose nth derivative is itself have a special name. Yet we are no closer to finding three distinct functions that fit the bill. I would also kindly ask that if you are able to generalize this to the nth derivative please do so!",,"['real-analysis', 'derivatives']"
88,"If the sum of the tail of a series goes to $0$, must the series converge?","If the sum of the tail of a series goes to , must the series converge?",0,"Suppose $\{a_n\}$ is a sequence of positive terms. It is a well known result that if the series $\displaystyle \sum_{k=1}^{\infty} a_k$ converges then $\displaystyle \lim_{m \rightarrow \infty} \displaystyle \sum_{k=m}^{\infty} a_k=0 $. Is the converse true? That is, is it true that if the tail of a series goes to zero, then the series must converge? My thoughts: If we let $S_n=\displaystyle \sum_{k=1}^{n} a_k$, then clearly $S_n$ is an increasing sequence, and for $n > m$ , we have $S_n - S_m = \displaystyle \sum_{k=m+1}^{n} a_k $ Then we want to show that if $\displaystyle \lim_{m\rightarrow \infty} (\displaystyle \lim_{n\rightarrow \infty} S_n - S_m ) = 0$ (or just if it exists) then $\displaystyle \lim_{n\rightarrow \infty} S_n < \infty$. Note that since $S_n$ is increasing, it is enough to show that it is bounded. I tried to show this by definition, but my issue is that I am not sure how to deal with that double limit. Any help would be really appreciate it. Thanks!","Suppose $\{a_n\}$ is a sequence of positive terms. It is a well known result that if the series $\displaystyle \sum_{k=1}^{\infty} a_k$ converges then $\displaystyle \lim_{m \rightarrow \infty} \displaystyle \sum_{k=m}^{\infty} a_k=0 $. Is the converse true? That is, is it true that if the tail of a series goes to zero, then the series must converge? My thoughts: If we let $S_n=\displaystyle \sum_{k=1}^{n} a_k$, then clearly $S_n$ is an increasing sequence, and for $n > m$ , we have $S_n - S_m = \displaystyle \sum_{k=m+1}^{n} a_k $ Then we want to show that if $\displaystyle \lim_{m\rightarrow \infty} (\displaystyle \lim_{n\rightarrow \infty} S_n - S_m ) = 0$ (or just if it exists) then $\displaystyle \lim_{n\rightarrow \infty} S_n < \infty$. Note that since $S_n$ is increasing, it is enough to show that it is bounded. I tried to show this by definition, but my issue is that I am not sure how to deal with that double limit. Any help would be really appreciate it. Thanks!",,"['real-analysis', 'sequences-and-series']"
89,Are homeomorphisms convex-preserving?,Are homeomorphisms convex-preserving?,,"If $A\subset \mathbb R^n$ is a convex subset and $A$ is homeomorphic to a subset $B\subset R^n$, can I also say $B$ is convex? Any counterexamples?","If $A\subset \mathbb R^n$ is a convex subset and $A$ is homeomorphic to a subset $B\subset R^n$, can I also say $B$ is convex? Any counterexamples?",,"['real-analysis', 'general-topology', 'convex-analysis', 'examples-counterexamples']"
90,"Prove $(a^2+b^2)(c^2+d^2)\ge (ac+bd)^2$ for all $a,b,c,d\in\mathbb{R}$.",Prove  for all .,"(a^2+b^2)(c^2+d^2)\ge (ac+bd)^2 a,b,c,d\in\mathbb{R}","Prove $(a^2+b^2)(c^2+d^2)\ge (ac+bd)^2$ for all $a,b,c,d\in\mathbb{R}$. So $(a^2+b^2)(c^2+d^2) = a^2c^2+a^2d^2+b^2c^2+b^2d^2$ and $(ac+bd)^2 = a^2c^2+2acbd+b^2d^2$ So the problem is reduced to proving that $a^2d^2+b^2c^2\ge2acbd$ but I am not sure how to show that","Prove $(a^2+b^2)(c^2+d^2)\ge (ac+bd)^2$ for all $a,b,c,d\in\mathbb{R}$. So $(a^2+b^2)(c^2+d^2) = a^2c^2+a^2d^2+b^2c^2+b^2d^2$ and $(ac+bd)^2 = a^2c^2+2acbd+b^2d^2$ So the problem is reduced to proving that $a^2d^2+b^2c^2\ge2acbd$ but I am not sure how to show that",,['real-analysis']
91,"Is the set of natural numbers $\mathbb{N}$ Open, closed, or neither?","Is the set of natural numbers  Open, closed, or neither?",\mathbb{N},"I figured someone would have asked the question here, but I could not find it. I know it is not open, because  $ \forall n \in \mathbb{N}$, $V_\epsilon (n) \notin \mathbb{N}$. In other words, it is made up of a bunch of isolated points. But I keep reading that it is closed, and I'm having trouble thinking about why, except that perhaps the complement is open and thus $\mathbb{N}$ is closed? Or is it closed vacuously like $\mathbb{Z}$, it contains all its limit points because it has no limit points.","I figured someone would have asked the question here, but I could not find it. I know it is not open, because  $ \forall n \in \mathbb{N}$, $V_\epsilon (n) \notin \mathbb{N}$. In other words, it is made up of a bunch of isolated points. But I keep reading that it is closed, and I'm having trouble thinking about why, except that perhaps the complement is open and thus $\mathbb{N}$ is closed? Or is it closed vacuously like $\mathbb{Z}$, it contains all its limit points because it has no limit points.",,"['real-analysis', 'general-topology']"
92,If $f(2x)=2f(x)$ and $f'(0)=0$ then $f(x)=0$,If  and  then,f(2x)=2f(x) f'(0)=0 f(x)=0,"Recently, when I was working on a functional equation, I encountered something like an ordinary differential equation with boundary conditions! Theorem . If the following holds for all $x \in \mathbb R$    $$\begin{align} f(2x) &=2 f(x) \\ f'(0) &=0 \end{align}$$   then $f(x)=0$ on $\mathbb R$. Intuitively, it is evident for me that $f(x)=0$ but I cannot show this by a formal argument. In fact, I don't have any idea to work on it! :) I will be thankful if you provide me a hint or help to show this with a nice formal proof.","Recently, when I was working on a functional equation, I encountered something like an ordinary differential equation with boundary conditions! Theorem . If the following holds for all $x \in \mathbb R$    $$\begin{align} f(2x) &=2 f(x) \\ f'(0) &=0 \end{align}$$   then $f(x)=0$ on $\mathbb R$. Intuitively, it is evident for me that $f(x)=0$ but I cannot show this by a formal argument. In fact, I don't have any idea to work on it! :) I will be thankful if you provide me a hint or help to show this with a nice formal proof.",,"['calculus', 'real-analysis', 'functional-equations']"
93,My proof of divergence of $(-1)^n$,My proof of divergence of,(-1)^n,"Should I shorten my proof?   (Also, should I try to prove without contradiction?) We consider the sequence   $(x_n)_{n \in \mathbb{N}}$,   where   $x_n = (-1)^n$. $\textbf{Lemma.}$   For every element $x_n$ of the sequence $(x_n)$,   we have $|x_n| = 1$.   (We could prove this by induction on $n$.) $\textbf{Theorem.}$   $(x_n)$ diverges. $\textit{Proof.}$   We prove the theorem by contradiction.   To that end,   we assume that $(x_n)$ is not divergent, i.e. we assume that it is convergent.   With that said, we are done as soon as a contradiction is deduced.   By assumption, there is an $x \in \mathbb{R}$ such that   \begin{equation*}     \forall \varepsilon \in \mathbb{R}, \varepsilon > 0 :     \exists N           \in \mathbb{N}                  :     \forall n           \in \mathbb{N}, n > N           :     |x_n - x| < \varepsilon .   \end{equation*}   We choose $\varepsilon = 1$.   By assumption, there is an $N \in \mathbb{N}$ such that   \begin{equation*}     \forall n \in \mathbb{N}, n > N :     |x_n - x| < 1 .   \end{equation*}   We choose $n = N + 1$.   Hence, both $|x_n - x| < 1$ and $|x_{n + 1} - x| < 1$.   Thus,   \begin{equation*}     |x_{n + 1} - x| + |x_n - x| < 2 .   \end{equation*}   Moreover,   \begin{equation*}     \begin{split}       2 & =   |2| \\         & =   |2| \cdot  1  \\         & =   |2| \cdot |x_{n + 1}| && | \text{ by Lemma} \\         & =   |2 x_{n + 1}| && | \text{ by multiplicativeness of abs. val.} \\         & =   |x_{n + 1} + x_{n + 1}| \\         & =   |x_{n + 1} + (-1)x_{n}| \\         & =   |x_{n + 1} - x_{n}| \\         & =   |x_{n + 1} + 0 - x_{n}| \\         & =   |x_{n + 1} + (-x + x) - x_{n}| \\         & =   |(x_{n + 1} - x) + (x - x_{n})| \\         & \le |x_{n + 1} - x| + |x - x_{n}| && | \text{ by subadditivity of abs. val.} \\         & =   |x_{n + 1} - x| + |x_{n} - x| \qquad && | \text{ by evenness of abs. val.} \\     \end{split}   \end{equation*}   Hence, by transitivity, we have $2 < 2$.   Obviously, we deduced a contradiction. QED","Should I shorten my proof?   (Also, should I try to prove without contradiction?) We consider the sequence   $(x_n)_{n \in \mathbb{N}}$,   where   $x_n = (-1)^n$. $\textbf{Lemma.}$   For every element $x_n$ of the sequence $(x_n)$,   we have $|x_n| = 1$.   (We could prove this by induction on $n$.) $\textbf{Theorem.}$   $(x_n)$ diverges. $\textit{Proof.}$   We prove the theorem by contradiction.   To that end,   we assume that $(x_n)$ is not divergent, i.e. we assume that it is convergent.   With that said, we are done as soon as a contradiction is deduced.   By assumption, there is an $x \in \mathbb{R}$ such that   \begin{equation*}     \forall \varepsilon \in \mathbb{R}, \varepsilon > 0 :     \exists N           \in \mathbb{N}                  :     \forall n           \in \mathbb{N}, n > N           :     |x_n - x| < \varepsilon .   \end{equation*}   We choose $\varepsilon = 1$.   By assumption, there is an $N \in \mathbb{N}$ such that   \begin{equation*}     \forall n \in \mathbb{N}, n > N :     |x_n - x| < 1 .   \end{equation*}   We choose $n = N + 1$.   Hence, both $|x_n - x| < 1$ and $|x_{n + 1} - x| < 1$.   Thus,   \begin{equation*}     |x_{n + 1} - x| + |x_n - x| < 2 .   \end{equation*}   Moreover,   \begin{equation*}     \begin{split}       2 & =   |2| \\         & =   |2| \cdot  1  \\         & =   |2| \cdot |x_{n + 1}| && | \text{ by Lemma} \\         & =   |2 x_{n + 1}| && | \text{ by multiplicativeness of abs. val.} \\         & =   |x_{n + 1} + x_{n + 1}| \\         & =   |x_{n + 1} + (-1)x_{n}| \\         & =   |x_{n + 1} - x_{n}| \\         & =   |x_{n + 1} + 0 - x_{n}| \\         & =   |x_{n + 1} + (-x + x) - x_{n}| \\         & =   |(x_{n + 1} - x) + (x - x_{n})| \\         & \le |x_{n + 1} - x| + |x - x_{n}| && | \text{ by subadditivity of abs. val.} \\         & =   |x_{n + 1} - x| + |x_{n} - x| \qquad && | \text{ by evenness of abs. val.} \\     \end{split}   \end{equation*}   Hence, by transitivity, we have $2 < 2$.   Obviously, we deduced a contradiction. QED",,"['real-analysis', 'sequences-and-series', 'limits', 'proof-verification', 'epsilon-delta']"
94,Matrix characterization of surjective and injective linear functions,Matrix characterization of surjective and injective linear functions,,"I don't remember well of my Linear Algebra classes, looking the rank of a matrix $A\in M(n\times m)$ how can we say the application associated to this matrix is surjective or injective? For a matrix $A \in M(n\times n)$ is easy, $A$ is surjective (injective) iff $\text{rank} A=n$ . Thanks","I don't remember well of my Linear Algebra classes, looking the rank of a matrix $A\in M(n\times m)$ how can we say the application associated to this matrix is surjective or injective? For a matrix $A \in M(n\times n)$ is easy, $A$ is surjective (injective) iff $\text{rank} A=n$ . Thanks",,"['real-analysis', 'linear-algebra']"
95,About a specific argument purporting to show $0.999\dots = 1.0$.,About a specific argument purporting to show .,0.999\dots = 1.0,"I have read the proofs about why $0.9999.... = 1$, which are satisfying. But I can't get the following argument out of my head. Defining $0.9999....$ : Lets construct a non-terminating but recurring real number n such that all digits before decimal point are zero and all digits after decimal point are 9.  Comparing $1.0000$ with $0.99999...$ Digit at ones place in $1.0$ (i.e. 1) $\ne$ Digit at ones place in $0.99999$ (i.e. 0) Digit at tenths place in $1.0$ (i.e. 0) $\ne$ Digit at tenths place in $0.99999$ (i.e. 9). And so on.... Hence, $1.0 =0.9999...$ does not fit with our original definition of $0.9999...$ Can you find the mistake in the argument (other than saying that in-fact $1.0 = 0.9999...$)? Am I using a incorrect way to define (or perhaps compare) a number (with another)? Please help me. I am new to analysis. Thanks.","I have read the proofs about why $0.9999.... = 1$, which are satisfying. But I can't get the following argument out of my head. Defining $0.9999....$ : Lets construct a non-terminating but recurring real number n such that all digits before decimal point are zero and all digits after decimal point are 9.  Comparing $1.0000$ with $0.99999...$ Digit at ones place in $1.0$ (i.e. 1) $\ne$ Digit at ones place in $0.99999$ (i.e. 0) Digit at tenths place in $1.0$ (i.e. 0) $\ne$ Digit at tenths place in $0.99999$ (i.e. 9). And so on.... Hence, $1.0 =0.9999...$ does not fit with our original definition of $0.9999...$ Can you find the mistake in the argument (other than saying that in-fact $1.0 = 0.9999...$)? Am I using a incorrect way to define (or perhaps compare) a number (with another)? Please help me. I am new to analysis. Thanks.",,"['real-analysis', 'number-systems']"
96,Sum of infinite series with arctan: $\sum_{n=1}^{\infty}\left(\arctan\left(\frac{1}{4}-n\right)-\arctan\left(-\frac{1}{4}-n\right)\right)$,Sum of infinite series with arctan:,\sum_{n=1}^{\infty}\left(\arctan\left(\frac{1}{4}-n\right)-\arctan\left(-\frac{1}{4}-n\right)\right),"I'm trying to find the value of the following sum (if exist): $$\sum_{n=1}^{\infty}\left(\arctan\left(\frac{1}{4}-n\right)-\arctan\left(-\frac{1}{4}-n\right)\right)$$ where, $\arctan$ represent the inverse tangent function - $\tan^{-1}$. I tried to use the telescoping series idea and the sequence of partial sums but I couldn't cancel any terms!","I'm trying to find the value of the following sum (if exist): $$\sum_{n=1}^{\infty}\left(\arctan\left(\frac{1}{4}-n\right)-\arctan\left(-\frac{1}{4}-n\right)\right)$$ where, $\arctan$ represent the inverse tangent function - $\tan^{-1}$. I tried to use the telescoping series idea and the sequence of partial sums but I couldn't cancel any terms!",,"['calculus', 'real-analysis', 'sequences-and-series']"
97,Prove: $\lim\limits_{n \to \infty} \int_{0}^{\sqrt n}(1-\frac{x^2}{n})^ndx=\int_{0}^{\infty} e^{-x^2}dx$,Prove:,\lim\limits_{n \to \infty} \int_{0}^{\sqrt n}(1-\frac{x^2}{n})^ndx=\int_{0}^{\infty} e^{-x^2}dx,"I'd like your help with the following claim to prove: $$\lim_{n \to \infty} \int_{0}^{\sqrt n}\left(1-\frac{x^2}{n}\right)^ndx=\int_{0}^{\infty} e^{-x^2}dx.$$ I think I should use the claim: Let $a,b$ two real numbers and $\{f_n\}$ a sequence of continuous functions on $\left[a,b\right]$  which converges uniformly to $f$ on $[a,b]$. Then    $$\lim_{n\to\infty}\int_a^bf_n(t)dt=\int_a^bf(t)dt.$$ But for this, I must prove that $(1-\frac{x^2}{n})^n$ uniformly converges to $e^{-x^2}$.  How do I do that? One of the hardest and trickiest things to do is to prove this uniformly converges.. every function has its own way. I believe that the more examples I'll see the easiest it will be. Thanks again!","I'd like your help with the following claim to prove: $$\lim_{n \to \infty} \int_{0}^{\sqrt n}\left(1-\frac{x^2}{n}\right)^ndx=\int_{0}^{\infty} e^{-x^2}dx.$$ I think I should use the claim: Let $a,b$ two real numbers and $\{f_n\}$ a sequence of continuous functions on $\left[a,b\right]$  which converges uniformly to $f$ on $[a,b]$. Then    $$\lim_{n\to\infty}\int_a^bf_n(t)dt=\int_a^bf(t)dt.$$ But for this, I must prove that $(1-\frac{x^2}{n})^n$ uniformly converges to $e^{-x^2}$.  How do I do that? One of the hardest and trickiest things to do is to prove this uniformly converges.. every function has its own way. I believe that the more examples I'll see the easiest it will be. Thanks again!",,"['real-analysis', 'calculus', 'integration', 'limits', 'convergence-divergence']"
98,"Is it true that if $\limsup\limits_{n \to \infty}\left|\frac{a_{n+1}}{a_n}\right| > 1$, then $\sum a_n$ diverges?","Is it true that if , then  diverges?",\limsup\limits_{n \to \infty}\left|\frac{a_{n+1}}{a_n}\right| > 1 \sum a_n,"I am reading ""A Course in Analysis vol.2"" by Kazuo Matsuzaka. There is the following theorem (""ratio test"") in this book. Let $a_n \neq 0$ for all $n$ . (a) If $\limsup\limits_{n \to \infty}\left|\frac{a_{n+1}}{a_n}\right| < 1$ , then $\sum a_n$ converges absolutely. (b) If $\left|\frac{a_{n+1}}{a_n}\right| \geq 1$ for all $n \geq N$ for some $N$ , then $\sum a_n$ diverges. Is the following statement false? (b') If $\limsup\limits_{n \to \infty}\left|\frac{a_{n+1}}{a_n}\right| > 1$ , then $\sum a_n$ diverges.","I am reading ""A Course in Analysis vol.2"" by Kazuo Matsuzaka. There is the following theorem (""ratio test"") in this book. Let for all . (a) If , then converges absolutely. (b) If for all for some , then diverges. Is the following statement false? (b') If , then diverges.",a_n \neq 0 n \limsup\limits_{n \to \infty}\left|\frac{a_{n+1}}{a_n}\right| < 1 \sum a_n \left|\frac{a_{n+1}}{a_n}\right| \geq 1 n \geq N N \sum a_n \limsup\limits_{n \to \infty}\left|\frac{a_{n+1}}{a_n}\right| > 1 \sum a_n,"['real-analysis', 'calculus', 'sequences-and-series']"
99,How to define limit operations in general topological spaces? Are nets able to do this?,How to define limit operations in general topological spaces? Are nets able to do this?,,"I was always under the impression that in order to take a limit, I need to have a metric defined on my underlying space. For $f:\mathbb{R}\to \mathbb{R}$ , $ \lim_{x\to x_0}f(x)=a $ means that for all $\epsilon >0 $ there exists a $\delta(\epsilon)>0$ such that $|f(x)-a|<\epsilon$ whenever $0< |x-x_0|<\delta$ . The notion of a limit uses the underlying metric $|\cdot|$ of $\mathbb{R}$ . Is there a consistent way of dispensing with the metric and still define a limit operation in some topological space? Are nets able to do this?","I was always under the impression that in order to take a limit, I need to have a metric defined on my underlying space. For , means that for all there exists a such that whenever . The notion of a limit uses the underlying metric of . Is there a consistent way of dispensing with the metric and still define a limit operation in some topological space? Are nets able to do this?","f:\mathbb{R}\to \mathbb{R} 
\lim_{x\to x_0}f(x)=a
 \epsilon >0  \delta(\epsilon)>0 |f(x)-a|<\epsilon 0< |x-x_0|<\delta |\cdot| \mathbb{R}","['real-analysis', 'general-topology', 'limits']"
