,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Is the sequence of functions $f_n=\chi_{[n,n+1]}$ uniformly integrable?",Is the sequence of functions  uniformly integrable?,"f_n=\chi_{[n,n+1]}","I wish to prove or disprove that the sequence of functions $f_n=\chi_{[n,n+1]}$ is uniformly integrable? At a glance my judgement is YES, it is uniformly integrable. From the definition of Uniform integrability, that's A sequence ${f_n}$ is called uniformly integrable if $\forall \epsilon >0 \exists \delta > 0 $ such that if $E \subset X$, $E$ measurable and  $\mu (E)< \delta $ then $\forall n$ $\int_E |f_n| d\mu < \epsilon$. So I let $E \subset R$ such that $\mu (E)<\delta$ then $\int_E|f_n|=\int|f_n|\chi_E \leq \mu (E)<\delta$. So in this case $\epsilon =\delta$. Does this make sense?","I wish to prove or disprove that the sequence of functions $f_n=\chi_{[n,n+1]}$ is uniformly integrable? At a glance my judgement is YES, it is uniformly integrable. From the definition of Uniform integrability, that's A sequence ${f_n}$ is called uniformly integrable if $\forall \epsilon >0 \exists \delta > 0 $ such that if $E \subset X$, $E$ measurable and  $\mu (E)< \delta $ then $\forall n$ $\int_E |f_n| d\mu < \epsilon$. So I let $E \subset R$ such that $\mu (E)<\delta$ then $\int_E|f_n|=\int|f_n|\chi_E \leq \mu (E)<\delta$. So in this case $\epsilon =\delta$. Does this make sense?",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure', 'uniform-integrability']"
1,If a measure is a sum of finite measures then the underlying space must not necessarily be $\sigma$-finite,If a measure is a sum of finite measures then the underlying space must not necessarily be -finite,\sigma,"Give a counterexample. Let $(X,\mathcal{A})$ be a measurable space and $\mu$ a measure on $(X,\mathcal{A})$. If there are finite measures $(\mu_n)_{n \in \mathbb{N}}$ such that $\mu = \sum_{n \in \mathbb{N}}\mu_n$, then $\mu$ is $\sigma$-finite. Let $(x_n)_{n \in \mathbb{N}}$ be a real sequence. Then $$\mu := \sum_{n \in \mathbb{N}} \delta_{x_n}$$ is a measure on $(\mathbb{R},\mathcal{P}(\mathbb{R}))$, where $\delta_x$ is the Dirca-measure in $x$. Furthermore, we have that $\mu$ is $\sigma$-finite if and only if there exists no $x \in \mathbb{R}$ such that $x_n = x$ for infinitely many $n \in \mathbb{N}$. I wondered if there is any easier counterexample for the above statement since the one above is rather difficult to show. Any ideas?","Give a counterexample. Let $(X,\mathcal{A})$ be a measurable space and $\mu$ a measure on $(X,\mathcal{A})$. If there are finite measures $(\mu_n)_{n \in \mathbb{N}}$ such that $\mu = \sum_{n \in \mathbb{N}}\mu_n$, then $\mu$ is $\sigma$-finite. Let $(x_n)_{n \in \mathbb{N}}$ be a real sequence. Then $$\mu := \sum_{n \in \mathbb{N}} \delta_{x_n}$$ is a measure on $(\mathbb{R},\mathcal{P}(\mathbb{R}))$, where $\delta_x$ is the Dirca-measure in $x$. Furthermore, we have that $\mu$ is $\sigma$-finite if and only if there exists no $x \in \mathbb{R}$ such that $x_n = x$ for infinitely many $n \in \mathbb{N}$. I wondered if there is any easier counterexample for the above statement since the one above is rather difficult to show. Any ideas?",,"['measure-theory', 'examples-counterexamples']"
2,When does $f\in L^1$ vanish?,When does  vanish?,f\in L^1,"I am asking about the sort-of converse to this question : under what additional conditions on $f:\mathbb{R}_+\rightarrow\mathbb{R}$ does the following hold? $$ \int_{\mathbb{R}_+}f<\infty\implies \lim_{x\rightarrow\infty}f(x)=0 $$ Where the limit above is made in the topological sense: for every increasing diverging sequence $x_n$, $f(x_n)\rightarrow 0$. Surely, by the linked question, the set of such functions includes uniformly continuous ones, but can we expand the set and completely characterize it? Is it the set of BV functions? Absolutely continuous?","I am asking about the sort-of converse to this question : under what additional conditions on $f:\mathbb{R}_+\rightarrow\mathbb{R}$ does the following hold? $$ \int_{\mathbb{R}_+}f<\infty\implies \lim_{x\rightarrow\infty}f(x)=0 $$ Where the limit above is made in the topological sense: for every increasing diverging sequence $x_n$, $f(x_n)\rightarrow 0$. Surely, by the linked question, the set of such functions includes uniformly continuous ones, but can we expand the set and completely characterize it? Is it the set of BV functions? Absolutely continuous?",,"['measure-theory', 'lebesgue-integral']"
3,Standard notation or name for the measure defined by an integral over a function,Standard notation or name for the measure defined by an integral over a function,,"Let $(\Omega,\mathcal{F},\mu)$ be a measure space. For a measurable function $f \geq 0$ one can define a measure $\nu$ by $$ \nu(M) : = \int_M f d \mu = \int_{\Omega} f \mathbb{1}_{M} d \mu $$ for $M \in \mathcal{F}$. Is there a standard notation/name for the measure $\nu$? I think I saw something like $f \odot \mu$ but I am not sure.","Let $(\Omega,\mathcal{F},\mu)$ be a measure space. For a measurable function $f \geq 0$ one can define a measure $\nu$ by $$ \nu(M) : = \int_M f d \mu = \int_{\Omega} f \mathbb{1}_{M} d \mu $$ for $M \in \mathcal{F}$. Is there a standard notation/name for the measure $\nu$? I think I saw something like $f \odot \mu$ but I am not sure.",,"['probability', 'integration', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
4,Is the map $p\mapsto\int_X |f|^p d\mu$ differentiable when $\log|f|\notin L^1$?,Is the map  differentiable when ?,p\mapsto\int_X |f|^p d\mu \log|f|\notin L^1,"Let $(X,\mathscr{M},\mu)$ be a measure space and $f$ be a measurable function. Suppose $J$ is a nonempty open subinterval of $(0,\infty)$ such that $f\in L^p$ for all $p\in J$, and let $\varphi:J\rightarrow\mathbb{R}$ be the map given by $\varphi(p)=\int_X |f|^p d\mu$. My goal is to show that $\varphi$ is differentiable  on $J$, with the obvious derivative $\varphi'(p)=\int_X |f|^p\log|f| d\mu$. I have succeeded in proving this under the assumption that $\log|f|\in L^1$. My argument goes as follows: Let $p\in J$ and $(p_n)_{n\geq 1}$ be a sequence in $J$ converging to $p$ with $p_n\ne p$ for all $n\geq 1$. Choose a point $q\in J$ such that $p_n<q$ for all $n\geq 1$, a small $\epsilon>0$ such that $q+\epsilon\in J$, and a constant $C_{\epsilon}$ satisfying the inequality $\log t\leq C_{\epsilon}t^{\epsilon}$ for all $t\geq 1$. We have $$\frac{\varphi(p_n)-\varphi(p)}{p_n-p}=\int_{|f|>1}\frac{|f(x)|^{p_n}-|f(x)|^{p}}{p_n-p} d\mu+\int_{|f|\leq 1}\frac{|f(x)|^{p_n}-|f(x)|^{p}}{p_n-p} d\mu$$ and the mean value theorem gives (for each $x$) points $p'_n$ lying between $p_n$ and $p$ such that $\frac{|f(x)|^{p_n}-|f(x)|^{p}}{p_n-p}=|f(x)|^{p'_n} \log|f(x)|$. By our choice of $q$, we have $p'_n<q$ regardless of $x$ and $$\left|\frac{|f(x)|^{p_n}-|f(x)|^{p}}{p_n-p}\right|=|f(x)|^{p'_n}|\log|f(x)||\leq|f(x)|^q\log|f(x)|\leq C_{\epsilon}|f(x)|^{q+\epsilon}$$ whenever $|f(x)|>1$, and $$|f(x)|^{p'_n}|\log|f(x)||\leq|\log|f(x)||$$ whenever $|f(x)|\leq1$. Since $q+\epsilon\in J$, both the functions $|f|^{q+\epsilon}$ and $|\log|f||$ are in $L^1$ and the dominated convergence theorem applies. Hence we have $$\lim_{n\rightarrow\infty}\frac{\varphi(p_n)-\varphi(p)}{p_n-p}=\int_{|f|>1} |f|^p\log|f| d\mu+\int_{|f|\leq 1} |f|^p\log|f| d\mu=\int_X |f|^p\log|f| d\mu$$ and we conclude that $\varphi$ is differentiable at $p$ with the derivative $\int_X |f|^p\log|f| d\mu$. As above, I have used the additional assumption $\log|f|\in L^1$ in the argument. My questions are: Can this assumption be dropped? Does the expression $\int_X |f|^p\log|f| d\mu$ still make sense when $\log|f|\notin L^1$ ? When $\log|f|\notin L^1$, the integral $\int_X \log|f| d\mu$ exists but equals $-\infty$. In this case, if we further assume that $\mu(X)=1$, is it true that $\lim_{p\rightarrow 0}\Vert f\Vert_p=0$? Please enlighten me. Any advice on the questions or the argument I have made is welcome. Thank you in advance.","Let $(X,\mathscr{M},\mu)$ be a measure space and $f$ be a measurable function. Suppose $J$ is a nonempty open subinterval of $(0,\infty)$ such that $f\in L^p$ for all $p\in J$, and let $\varphi:J\rightarrow\mathbb{R}$ be the map given by $\varphi(p)=\int_X |f|^p d\mu$. My goal is to show that $\varphi$ is differentiable  on $J$, with the obvious derivative $\varphi'(p)=\int_X |f|^p\log|f| d\mu$. I have succeeded in proving this under the assumption that $\log|f|\in L^1$. My argument goes as follows: Let $p\in J$ and $(p_n)_{n\geq 1}$ be a sequence in $J$ converging to $p$ with $p_n\ne p$ for all $n\geq 1$. Choose a point $q\in J$ such that $p_n<q$ for all $n\geq 1$, a small $\epsilon>0$ such that $q+\epsilon\in J$, and a constant $C_{\epsilon}$ satisfying the inequality $\log t\leq C_{\epsilon}t^{\epsilon}$ for all $t\geq 1$. We have $$\frac{\varphi(p_n)-\varphi(p)}{p_n-p}=\int_{|f|>1}\frac{|f(x)|^{p_n}-|f(x)|^{p}}{p_n-p} d\mu+\int_{|f|\leq 1}\frac{|f(x)|^{p_n}-|f(x)|^{p}}{p_n-p} d\mu$$ and the mean value theorem gives (for each $x$) points $p'_n$ lying between $p_n$ and $p$ such that $\frac{|f(x)|^{p_n}-|f(x)|^{p}}{p_n-p}=|f(x)|^{p'_n} \log|f(x)|$. By our choice of $q$, we have $p'_n<q$ regardless of $x$ and $$\left|\frac{|f(x)|^{p_n}-|f(x)|^{p}}{p_n-p}\right|=|f(x)|^{p'_n}|\log|f(x)||\leq|f(x)|^q\log|f(x)|\leq C_{\epsilon}|f(x)|^{q+\epsilon}$$ whenever $|f(x)|>1$, and $$|f(x)|^{p'_n}|\log|f(x)||\leq|\log|f(x)||$$ whenever $|f(x)|\leq1$. Since $q+\epsilon\in J$, both the functions $|f|^{q+\epsilon}$ and $|\log|f||$ are in $L^1$ and the dominated convergence theorem applies. Hence we have $$\lim_{n\rightarrow\infty}\frac{\varphi(p_n)-\varphi(p)}{p_n-p}=\int_{|f|>1} |f|^p\log|f| d\mu+\int_{|f|\leq 1} |f|^p\log|f| d\mu=\int_X |f|^p\log|f| d\mu$$ and we conclude that $\varphi$ is differentiable at $p$ with the derivative $\int_X |f|^p\log|f| d\mu$. As above, I have used the additional assumption $\log|f|\in L^1$ in the argument. My questions are: Can this assumption be dropped? Does the expression $\int_X |f|^p\log|f| d\mu$ still make sense when $\log|f|\notin L^1$ ? When $\log|f|\notin L^1$, the integral $\int_X \log|f| d\mu$ exists but equals $-\infty$. In this case, if we further assume that $\mu(X)=1$, is it true that $\lim_{p\rightarrow 0}\Vert f\Vert_p=0$? Please enlighten me. Any advice on the questions or the argument I have made is welcome. Thank you in advance.",,"['real-analysis', 'functional-analysis', 'measure-theory', 'lebesgue-integral', 'lp-spaces']"
5,Cauchy in measure question,Cauchy in measure question,,"Let $w\in L^1(\mathbb{R}^d)$, where $w>0$. Let $\{f_n\}:\mathbb{R}^d\to\mathbb{R}$ be Lebesgue measurable functions such that $$\lim_{m,n\to\infty}\int_{|f_n-f_m|>t}w(x)\,dx=0$$ for any $t>0$. Prove that $\{f_n\}$ has a subsequence that converges almost everywhere to a measurable function $g$. Attempt: I am trying to show that $\{f_n\}$ is Cauchy in measure, and thus converges in measure, and thus has a convergent subsequence $f_{n_k}\to g$ a.e. We have $\lim_{m,n\to\infty}\int w(x)\chi_{\{|f_n-f_m|>t\}}(x)\,dx=0$. Since $|w(x)\chi_{\{|f_n-f_m|>t\}}(x)|\leq|w(x)|\in L^1$ so by Lebesgue's Dominated Convergence Theorem, $$\int w(x)\lim_{m,n\to\infty}\chi_{\{|f_n-f_m|>t\}(x)}=0$$ This means $w(x)\lim_{m,n\to\infty}\chi_{\{|f_n-f_m|>t\}}(x)=0$ almost everywhere on $\mathbb{R}$. Since $w>0$, so $\lim_{m,n\to\infty}\chi_{\{|f_n-f_m|>t\}}(x)=0$ a.e. However, I think we cannot conclude $\lim_{m,n\to\infty}|\{|f_n-f_m|>t\}|=0$ which is exactly what we need (Cauchy in measure). So close yet so far.. Thanks for any help.","Let $w\in L^1(\mathbb{R}^d)$, where $w>0$. Let $\{f_n\}:\mathbb{R}^d\to\mathbb{R}$ be Lebesgue measurable functions such that $$\lim_{m,n\to\infty}\int_{|f_n-f_m|>t}w(x)\,dx=0$$ for any $t>0$. Prove that $\{f_n\}$ has a subsequence that converges almost everywhere to a measurable function $g$. Attempt: I am trying to show that $\{f_n\}$ is Cauchy in measure, and thus converges in measure, and thus has a convergent subsequence $f_{n_k}\to g$ a.e. We have $\lim_{m,n\to\infty}\int w(x)\chi_{\{|f_n-f_m|>t\}}(x)\,dx=0$. Since $|w(x)\chi_{\{|f_n-f_m|>t\}}(x)|\leq|w(x)|\in L^1$ so by Lebesgue's Dominated Convergence Theorem, $$\int w(x)\lim_{m,n\to\infty}\chi_{\{|f_n-f_m|>t\}(x)}=0$$ This means $w(x)\lim_{m,n\to\infty}\chi_{\{|f_n-f_m|>t\}}(x)=0$ almost everywhere on $\mathbb{R}$. Since $w>0$, so $\lim_{m,n\to\infty}\chi_{\{|f_n-f_m|>t\}}(x)=0$ a.e. However, I think we cannot conclude $\lim_{m,n\to\infty}|\{|f_n-f_m|>t\}|=0$ which is exactly what we need (Cauchy in measure). So close yet so far.. Thanks for any help.",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
6,Proving that the function $f(x)=\sum_i|x-q_i|2^{-i}$ is not differentiable at any rational point,Proving that the function  is not differentiable at any rational point,f(x)=\sum_i|x-q_i|2^{-i},"Here,$\{q_i\}$ an enumeration of the rationals in the closed unit interval.Take $y=q_j\in \mathbb{Q}\cap [0,1]$. I tried to gleen something from the following manipulation \begin{align*} &\ \ \ \lim_{x\rightarrow q_j}\frac{1}{x-q_j}\sum_i 2^{-i}(|x-q_i|-|q_j-q_i|)\\ &=\lim_{x\rightarrow q_j}\frac{1}{x-q_j}(2^{-j}|x-q_{j}|+\sum_{i\ne j} 2^{-i}(|x-q_i|-|q_j-q_i|))\\ &=2^{-j}+\lim_{x\rightarrow q_j}\frac{1}{x-q_j}\sum_{i\ne j} 2^{-i}(|x-q_i|-|q_j-q_i|) \end{align*} Which I think will blow up, since the sum is some constant and the denominator blows up, with no chance of the differences in the numerator vanishing. Is my work correct? How can I show this a little more rigorously than just saying some words? For example, am I justified in commuting the limit and the sum?","Here,$\{q_i\}$ an enumeration of the rationals in the closed unit interval.Take $y=q_j\in \mathbb{Q}\cap [0,1]$. I tried to gleen something from the following manipulation \begin{align*} &\ \ \ \lim_{x\rightarrow q_j}\frac{1}{x-q_j}\sum_i 2^{-i}(|x-q_i|-|q_j-q_i|)\\ &=\lim_{x\rightarrow q_j}\frac{1}{x-q_j}(2^{-j}|x-q_{j}|+\sum_{i\ne j} 2^{-i}(|x-q_i|-|q_j-q_i|))\\ &=2^{-j}+\lim_{x\rightarrow q_j}\frac{1}{x-q_j}\sum_{i\ne j} 2^{-i}(|x-q_i|-|q_j-q_i|) \end{align*} Which I think will blow up, since the sum is some constant and the denominator blows up, with no chance of the differences in the numerator vanishing. Is my work correct? How can I show this a little more rigorously than just saying some words? For example, am I justified in commuting the limit and the sum?",,"['real-analysis', 'measure-theory', 'derivatives', 'lipschitz-functions', 'geometric-measure-theory']"
7,On a Clarkson-like inequality in $L^p$,On a Clarkson-like inequality in,L^p,"I'm currently reading the book ""Topics in Almost Everywhere Convergence"" by A. Garsia. At a certain point, he claims the validity of the following inequality, for $f, g \in L^p(X, \mathcal{A}, \mu)$, $\mu$ being a probability measure: \begin{equation*} \|  f - g \|^{p}_{p} \leq C_{p} \left[ \| f \|_{p}^{p} + \| g \|_{p}^{p} -2 \left\| \frac{f + g}{2} \right\|_{p}^{p} \right]^{\min \{1, p/2\}} \end{equation*} for any $p>1$, where $C_p$ is a constant and $f, g$ are on the unit ball. If $p\geq 2$, I see that this is Clarkson's inequality. However, for $1 < p <2$, it doesn't seem to be that simple. What bugs me the most is that this result is accompanied by the following footnote: This can be established by expressing $$|f|^p + |g|^p - 2 \left| \frac{f + g}{2} \right|^p$$ as an integral involving the second derivative of $|x|^p$. The constant $C_p$ tends to infinity as $p \to 1$. The above suggests that there is some unified approach for all values of $p$ and possibly elementary. Any hint on that direction would be appreciated.","I'm currently reading the book ""Topics in Almost Everywhere Convergence"" by A. Garsia. At a certain point, he claims the validity of the following inequality, for $f, g \in L^p(X, \mathcal{A}, \mu)$, $\mu$ being a probability measure: \begin{equation*} \|  f - g \|^{p}_{p} \leq C_{p} \left[ \| f \|_{p}^{p} + \| g \|_{p}^{p} -2 \left\| \frac{f + g}{2} \right\|_{p}^{p} \right]^{\min \{1, p/2\}} \end{equation*} for any $p>1$, where $C_p$ is a constant and $f, g$ are on the unit ball. If $p\geq 2$, I see that this is Clarkson's inequality. However, for $1 < p <2$, it doesn't seem to be that simple. What bugs me the most is that this result is accompanied by the following footnote: This can be established by expressing $$|f|^p + |g|^p - 2 \left| \frac{f + g}{2} \right|^p$$ as an integral involving the second derivative of $|x|^p$. The constant $C_p$ tends to infinity as $p \to 1$. The above suggests that there is some unified approach for all values of $p$ and possibly elementary. Any hint on that direction would be appreciated.",,"['functional-analysis', 'measure-theory', 'inequality', 'lp-spaces', 'integral-inequality']"
8,"$\int_{\mathbb{R}^n} \frac{1}{(\lVert x-y \rVert)^{n- \alpha}} d\mu (y) = (n-\alpha)\int _{[0,+\infty[} r^{\alpha - n -1} \mu(B(x,r)) d\lambda (r)$",,"\int_{\mathbb{R}^n} \frac{1}{(\lVert x-y \rVert)^{n- \alpha}} d\mu (y) = (n-\alpha)\int _{[0,+\infty[} r^{\alpha - n -1} \mu(B(x,r)) d\lambda (r)","Let $\mu$ be a Radon measure on $\mathbb{R}^n$, and $\alpha \in ]0,n[$. Show that : $\int_{\mathbb{R}^n} \frac{1}{(\lVert x-y \rVert)^{n- \alpha}} d\mu  (y) = (n-\alpha)\int _{[0,+\infty[} r^{\alpha - n -1} \mu(B(x,r))  d\lambda (r)$, where $B(x,r)$ is the open ball of center $x$ and radius $r$ in $\mathbb{R}^n$ and $\lambda$ is the Lebesgue measure on $\mathbb{R}$. I thought about using polar coordinates but I can't work it out. Moreover, I can't see why the condition of Radon measure is necessary here. Thanks in advance.","Let $\mu$ be a Radon measure on $\mathbb{R}^n$, and $\alpha \in ]0,n[$. Show that : $\int_{\mathbb{R}^n} \frac{1}{(\lVert x-y \rVert)^{n- \alpha}} d\mu  (y) = (n-\alpha)\int _{[0,+\infty[} r^{\alpha - n -1} \mu(B(x,r))  d\lambda (r)$, where $B(x,r)$ is the open ball of center $x$ and radius $r$ in $\mathbb{R}^n$ and $\lambda$ is the Lebesgue measure on $\mathbb{R}$. I thought about using polar coordinates but I can't work it out. Moreover, I can't see why the condition of Radon measure is necessary here. Thanks in advance.",,"['integration', 'measure-theory', 'lebesgue-integral']"
9,$\mathcal{L}_{\mathbb{R}} \otimes \mathcal{L}_{\mathbb{R}} \subset \mathcal{L}_{\mathbb{R}^2}$,,\mathcal{L}_{\mathbb{R}} \otimes \mathcal{L}_{\mathbb{R}} \subset \mathcal{L}_{\mathbb{R}^2},"The Borel $\sigma$ -algebra of $\mathbb{R}^n$ , $\mathcal{B}_{\mathbb{R}^n}$ , is defined as the smallest $\sigma$ -algebra of $\mathbb{R}^n$ containing the open sets of $\mathbb{R}^n$ for its usual topology. The Lebesgue $\sigma$ -algebra of $\mathbb{R}^n$ , $\mathcal{L}_{\mathbb{R}^n}$ , is characterized as the set of all subsets $A$ of $\mathbb{R}^n$ that can be written as $A = B \cup N$ , where $B$ is a Borel set and $N$ is a null-set (with respect to the Borel-Lebesgue measure). It is the completion of $\mathcal{B}_{\mathbb{R}^n}$ with respect to the Borel-Lebesgue measure : $\mathcal{L}_{\mathbb{R}^n} = \widehat{\mathcal{B}_{\mathbb{R}^n}}$ . I know that $\mathcal{B}_{\mathbb{R}^2} = \mathcal{B}_{\mathbb{R}} \otimes \mathcal{B}_{\mathbb{R}}$ . I want to show the following (clearly) equivalent assertions : $\mathcal{L}_{\mathbb{R}} \otimes \mathcal{L}_{\mathbb{R}} \subset  \mathcal{L}_{\mathbb{R}^2}$ $\widehat{\mathcal{B}_{\mathbb{R}}} \otimes  \widehat{\mathcal{B}_{\mathbb{R}}} \subset  \widehat{\mathcal{B}_{\mathbb{R}^2}}$ $\widehat{\mathcal{B}_{\mathbb{R}}} \otimes  \widehat{\mathcal{B}_{\mathbb{R}}} \subset  \widehat{\mathcal{B}_{\mathbb{R}} \otimes  \mathcal{B}_{\mathbb{R}}}$ . I think that what I need to show is that if $B_1$ , $B_2$ are Borel sets of $\mathbb{R}$ and $N_1$ , $N_2$ null sets of $\mathbb{R}$ , then $(B_1 \times N_2) \cup (N_1 \times B_2) \cup (N_1 \times N_2)$ is a null-set of $\mathbb{R}^2$ . Thanks. Edit : @G. Sassatelli : Thank you for pointing out this already existing topic . Nevertheless, they don't explain there why $(B_1 \times N_2) \cup (N_1 \times B_2) \cup (N_1 \times N_2)$ is a null-set of $\mathbb{R}^2$ . So here is my new question : Let $B_1$ , $B_2$ be Borel sets of $\mathbb{R}$ and $N_1$ , $N_2$ be   null sets of $\mathbb{R}$ . Why is $(B_1 \times N_2) \cup (N_1 \times B_2) \cup (N_1 \times N_2)$ a null-set of $\mathbb{R}^2$ ?","The Borel -algebra of , , is defined as the smallest -algebra of containing the open sets of for its usual topology. The Lebesgue -algebra of , , is characterized as the set of all subsets of that can be written as , where is a Borel set and is a null-set (with respect to the Borel-Lebesgue measure). It is the completion of with respect to the Borel-Lebesgue measure : . I know that . I want to show the following (clearly) equivalent assertions : . I think that what I need to show is that if , are Borel sets of and , null sets of , then is a null-set of . Thanks. Edit : @G. Sassatelli : Thank you for pointing out this already existing topic . Nevertheless, they don't explain there why is a null-set of . So here is my new question : Let , be Borel sets of and , be   null sets of . Why is a null-set of ?","\sigma \mathbb{R}^n \mathcal{B}_{\mathbb{R}^n} \sigma \mathbb{R}^n \mathbb{R}^n \sigma \mathbb{R}^n \mathcal{L}_{\mathbb{R}^n} A \mathbb{R}^n A = B \cup N B N \mathcal{B}_{\mathbb{R}^n} \mathcal{L}_{\mathbb{R}^n} = \widehat{\mathcal{B}_{\mathbb{R}^n}} \mathcal{B}_{\mathbb{R}^2} = \mathcal{B}_{\mathbb{R}} \otimes \mathcal{B}_{\mathbb{R}} \mathcal{L}_{\mathbb{R}} \otimes \mathcal{L}_{\mathbb{R}} \subset
 \mathcal{L}_{\mathbb{R}^2} \widehat{\mathcal{B}_{\mathbb{R}}} \otimes
 \widehat{\mathcal{B}_{\mathbb{R}}} \subset
 \widehat{\mathcal{B}_{\mathbb{R}^2}} \widehat{\mathcal{B}_{\mathbb{R}}} \otimes
 \widehat{\mathcal{B}_{\mathbb{R}}} \subset
 \widehat{\mathcal{B}_{\mathbb{R}} \otimes
 \mathcal{B}_{\mathbb{R}}} B_1 B_2 \mathbb{R} N_1 N_2 \mathbb{R} (B_1 \times N_2) \cup (N_1 \times B_2) \cup (N_1 \times N_2) \mathbb{R}^2 (B_1 \times N_2) \cup (N_1 \times B_2) \cup (N_1 \times N_2) \mathbb{R}^2 B_1 B_2 \mathbb{R} N_1 N_2 \mathbb{R} (B_1 \times N_2) \cup (N_1 \times B_2) \cup (N_1 \times N_2) \mathbb{R}^2","['measure-theory', 'lebesgue-measure']"
10,$\sigma$-algebra generated by a sum of functions,-algebra generated by a sum of functions,\sigma,"Is the $\sigma$-algebra generated by a finite sum of functions the same one as that generated by the set of those functions ? I'm trying to work it out but all I can get is stuff like $(X+Y)^{-1}(]-\infty,a[)=\displaystyle \cup_{t\in \mathbb{R}} (X^{-1}(\lbrace{t}\rbrace) \cap Y^{-1}(]-\infty, a-t[))$ which is already a bit of a mess since my reunion is uncountable.","Is the $\sigma$-algebra generated by a finite sum of functions the same one as that generated by the set of those functions ? I'm trying to work it out but all I can get is stuff like $(X+Y)^{-1}(]-\infty,a[)=\displaystyle \cup_{t\in \mathbb{R}} (X^{-1}(\lbrace{t}\rbrace) \cap Y^{-1}(]-\infty, a-t[))$ which is already a bit of a mess since my reunion is uncountable.",,['measure-theory']
11,Every discrete subgroup is unimodular,Every discrete subgroup is unimodular,,"Let $G$ be a locally-compact topological group. Let $\Gamma$ be a discrete subgroup [Perhaps $G$ is hausdorff in order for $\Gamma$ to be closed and therefore have a haar-measure, but It was not mentioned in the origin book]. A book I'm currently reading states trivially that $\Gamma$ must be unimodular, but I fail to understand it. It is clear to me that finite sets $E_{1,2}\subset\Gamma$ with $|E_1|=|E_2|$ must have the same measure (trivial for singletons by left-invariance of $\mu_\Gamma$, and by additivity also for finite sets). therefore $\mu_\Gamma(Eh)=\mu_\Gamma(E)$ for all finite $E\subset \Gamma$). Now, if $\Gamma$ is finite we are done. If it is countable, we will get by finiteness of haar measure that the measure must be the zero measure, which is a troubling result by itself. If it is more than countable, I don't know what to do but maybe follow the same argument for countable and get the same contradiction. p.s: I also tried using outer-regularity, but it seemed much less useful.","Let $G$ be a locally-compact topological group. Let $\Gamma$ be a discrete subgroup [Perhaps $G$ is hausdorff in order for $\Gamma$ to be closed and therefore have a haar-measure, but It was not mentioned in the origin book]. A book I'm currently reading states trivially that $\Gamma$ must be unimodular, but I fail to understand it. It is clear to me that finite sets $E_{1,2}\subset\Gamma$ with $|E_1|=|E_2|$ must have the same measure (trivial for singletons by left-invariance of $\mu_\Gamma$, and by additivity also for finite sets). therefore $\mu_\Gamma(Eh)=\mu_\Gamma(E)$ for all finite $E\subset \Gamma$). Now, if $\Gamma$ is finite we are done. If it is countable, we will get by finiteness of haar measure that the measure must be the zero measure, which is a troubling result by itself. If it is more than countable, I don't know what to do but maybe follow the same argument for countable and get the same contradiction. p.s: I also tried using outer-regularity, but it seemed much less useful.",,"['measure-theory', 'topological-groups', 'haar-measure']"
12,Series of $L^2$ functions converges pointwise almost everywhere,Series of  functions converges pointwise almost everywhere,L^2,"Let $\{f_n\}_{n=1}^\infty$ be a sequence of functions $f_n : \mathbb{R}^d \to \mathbb{C}$ in $L^2(\mathbb{R}^d)$ such that, for all $N \in \mathbb{N}$ $$\sum_{n = 1}^N \| f_n \|_{L^2}^2 \le C,$$ where $C$ is some positive constant independent of $N$. Furthermore, suppose there is some function $F \in L^2(\mathbb{R}^d)$ such that $$\| F - \sum_{n=1}^N f_n \|_{L^2}^2 \to 0$$ I would like to know if it is true that $\sum_{n=1}^\infty f_n$ converges pointwise almost everywhere to the function $F$. If we are dealing with functions in $L^1(\mathbb{R}^d)$ rather than $L^2(\mathbb{R}^d)$, then the answer to this question would be yes, and seen in this question here . However, in the $L^2$ case we are seemingly missing a step. We can of course start by applying monotone covergence: $$\int_{\mathbb{R}^n} \sum_{n=1}^\infty |f_n|^2 dx = \sum_{n =1}^\infty \int_{\mathbb{R}^n} |f_n|^2 dx \le C.$$ Hence $\sum_{n =1}^\infty |f_n|^2$ converges to a finite number almost everywhere. But this does not then imply that $\sum_{n=1}^\infty f_n$ converges almost everywhere (and we would have this implication in the $L^1$ case). Does the proof break down from here, or is there a way around this difficulty? Any hints or solutions are greatly appreciated.","Let $\{f_n\}_{n=1}^\infty$ be a sequence of functions $f_n : \mathbb{R}^d \to \mathbb{C}$ in $L^2(\mathbb{R}^d)$ such that, for all $N \in \mathbb{N}$ $$\sum_{n = 1}^N \| f_n \|_{L^2}^2 \le C,$$ where $C$ is some positive constant independent of $N$. Furthermore, suppose there is some function $F \in L^2(\mathbb{R}^d)$ such that $$\| F - \sum_{n=1}^N f_n \|_{L^2}^2 \to 0$$ I would like to know if it is true that $\sum_{n=1}^\infty f_n$ converges pointwise almost everywhere to the function $F$. If we are dealing with functions in $L^1(\mathbb{R}^d)$ rather than $L^2(\mathbb{R}^d)$, then the answer to this question would be yes, and seen in this question here . However, in the $L^2$ case we are seemingly missing a step. We can of course start by applying monotone covergence: $$\int_{\mathbb{R}^n} \sum_{n=1}^\infty |f_n|^2 dx = \sum_{n =1}^\infty \int_{\mathbb{R}^n} |f_n|^2 dx \le C.$$ Hence $\sum_{n =1}^\infty |f_n|^2$ converges to a finite number almost everywhere. But this does not then imply that $\sum_{n=1}^\infty f_n$ converges almost everywhere (and we would have this implication in the $L^1$ case). Does the proof break down from here, or is there a way around this difficulty? Any hints or solutions are greatly appreciated.",,"['measure-theory', 'lebesgue-integral', 'lp-spaces']"
13,Is the normed space of all bounded functions under the supremum norm isomorphic to $L^ \infty$?,Is the normed space of all bounded functions under the supremum norm isomorphic to ?,L^ \infty,"We are familiar with the space $L^ \infty$, i.e., the space of all essentially bounded measurable functions, i.e., $$L^ \infty(X,\mathcal{M},\mu)=\{f: X \rightarrow \mathbb{R}| f \text{ is measurable and } \exists M>0 \ni: \mu \{x \in \mathbb{R} | |f(x)> M\}=0 \}$$ under the essential supremum norm, $$||f||_ \infty=\text{esssup}_{x \in X} |f(x)|:= \inf \{M>0 |\text{ } \mu \{x \in X \text{ }|\text{ } |f(x)|> M\}=0\}$$ (i.e., the infimum of all essential  bounds). This is known to be a Banach space. This is also the natural analogue of the usual $L^p(X,\mathcal{M},\mu)$, $1\leq p<\infty$ for $p=\infty$, in the sense that $$\lim_{p \rightarrow \infty} ||f||_p =||f||_\infty $$ whenever there exist $q<\infty$ such that $f \in L^\infty(X,\mathcal{M},\mu) \bigcap L^q(X,\mathcal{M},\mu)$. What can also be considered, and in fact what is more natural in a sense, is the space of all (actually) bounded functions $$\mathscr{L}^\infty(X)=\{f: X \rightarrow \mathbb{R}| \exists M>0 \ni: |f(x)| \leq M \forall x \in X\}$$ under the (actual) supremum norm, $$||f||=\sup_{x \in X} |f(x)|$$ Unlike the analogous cases of $1\leq p<\infty$, it can easily be seen that $||.||$ itself is a norm (and not just a semi-norm) on $\mathscr{L}^\infty(X)$. As such there is no real necessity to go for equivalence classes here. It can also be seen that this is a Banach space (see Is the space of bounded functions with the Supremum norm a Banach Algebra ? for example). But is this different from our $L^\infty (X,\mathcal{M},\mu)$? The latter depends on the measure, while the former doesn't. On the one hand, there are more functions than there are measurable functions (w.r.t. any measure), while on the other, there are more essentially bounded functions than there are bounded functions. So, my questions are: Is $\mathscr{L}^\infty(X)$ isomorphic to $L^\infty (X,\mathcal{M},\mu)$ as vector spaces? Is $\mathscr{L}^\infty(X)$ under ||.|| isometric or isomorphic to $L^\infty (X,\mathcal{M},\mu)$ under $||.||_\infty$ as Banach spaces? If not, is there any interesting relation between them? We know that $$L^\infty (X,\mathcal{M},\mu)=\mathscr{L}^\infty(X)/\mathcal{N}(\mu)$$ as vector spaces, where $\mathcal{N}(\mu)=\ker(||.||_\infty)=\{f \in \mathscr{L}^\infty(X) | f=0 \text{ }\mu.a.e.\}$.","We are familiar with the space $L^ \infty$, i.e., the space of all essentially bounded measurable functions, i.e., $$L^ \infty(X,\mathcal{M},\mu)=\{f: X \rightarrow \mathbb{R}| f \text{ is measurable and } \exists M>0 \ni: \mu \{x \in \mathbb{R} | |f(x)> M\}=0 \}$$ under the essential supremum norm, $$||f||_ \infty=\text{esssup}_{x \in X} |f(x)|:= \inf \{M>0 |\text{ } \mu \{x \in X \text{ }|\text{ } |f(x)|> M\}=0\}$$ (i.e., the infimum of all essential  bounds). This is known to be a Banach space. This is also the natural analogue of the usual $L^p(X,\mathcal{M},\mu)$, $1\leq p<\infty$ for $p=\infty$, in the sense that $$\lim_{p \rightarrow \infty} ||f||_p =||f||_\infty $$ whenever there exist $q<\infty$ such that $f \in L^\infty(X,\mathcal{M},\mu) \bigcap L^q(X,\mathcal{M},\mu)$. What can also be considered, and in fact what is more natural in a sense, is the space of all (actually) bounded functions $$\mathscr{L}^\infty(X)=\{f: X \rightarrow \mathbb{R}| \exists M>0 \ni: |f(x)| \leq M \forall x \in X\}$$ under the (actual) supremum norm, $$||f||=\sup_{x \in X} |f(x)|$$ Unlike the analogous cases of $1\leq p<\infty$, it can easily be seen that $||.||$ itself is a norm (and not just a semi-norm) on $\mathscr{L}^\infty(X)$. As such there is no real necessity to go for equivalence classes here. It can also be seen that this is a Banach space (see Is the space of bounded functions with the Supremum norm a Banach Algebra ? for example). But is this different from our $L^\infty (X,\mathcal{M},\mu)$? The latter depends on the measure, while the former doesn't. On the one hand, there are more functions than there are measurable functions (w.r.t. any measure), while on the other, there are more essentially bounded functions than there are bounded functions. So, my questions are: Is $\mathscr{L}^\infty(X)$ isomorphic to $L^\infty (X,\mathcal{M},\mu)$ as vector spaces? Is $\mathscr{L}^\infty(X)$ under ||.|| isometric or isomorphic to $L^\infty (X,\mathcal{M},\mu)$ under $||.||_\infty$ as Banach spaces? If not, is there any interesting relation between them? We know that $$L^\infty (X,\mathcal{M},\mu)=\mathscr{L}^\infty(X)/\mathcal{N}(\mu)$$ as vector spaces, where $\mathcal{N}(\mu)=\ker(||.||_\infty)=\{f \in \mathscr{L}^\infty(X) | f=0 \text{ }\mu.a.e.\}$.",,"['functional-analysis', 'measure-theory', 'banach-spaces', 'lebesgue-measure', 'lp-spaces']"
14,Suprema and infima of measures,Suprema and infima of measures,,"Let $(E,\mathcal E)$ be a measurable space and $(\mu_i)_{i\in I}$ be a family of measures. Let: $$\sup_{i\in I} \mu_i : \mathcal E \to [0\, ..\infty], A \mapsto \sup_{i\in I} \mu_i(A)$$ $$\inf_{i\in I} \mu_i : \mathcal E \to [0\, ..\infty], A \mapsto \inf_{i\in I} \mu_i(A)$$ Is $\sup_{i\in I} \mu_i $ / $\inf_{i\in I} \mu_i $ a measure? If not generally what if $I = \mathbb{N}$ and / or  we require the $\mu_i$'s to be localizable, $\sigma$-finite or finite? If not, are there other ways to define suprema and infima in the lattice of measures (satisfying some property)?","Let $(E,\mathcal E)$ be a measurable space and $(\mu_i)_{i\in I}$ be a family of measures. Let: $$\sup_{i\in I} \mu_i : \mathcal E \to [0\, ..\infty], A \mapsto \sup_{i\in I} \mu_i(A)$$ $$\inf_{i\in I} \mu_i : \mathcal E \to [0\, ..\infty], A \mapsto \inf_{i\in I} \mu_i(A)$$ Is $\sup_{i\in I} \mu_i $ / $\inf_{i\in I} \mu_i $ a measure? If not generally what if $I = \mathbb{N}$ and / or  we require the $\mu_i$'s to be localizable, $\sigma$-finite or finite? If not, are there other ways to define suprema and infima in the lattice of measures (satisfying some property)?",,"['real-analysis', 'measure-theory']"
15,$\sigma$-additivity for measure of simple sets: $|\bigcup_{j=1}^{\infty}M_j|=\sum_{j=1}^{\infty}|M_j|$,-additivity for measure of simple sets:,\sigma |\bigcup_{j=1}^{\infty}M_j|=\sum_{j=1}^{\infty}|M_j|,"A hyperrectangle in $\mathbb{R}^d$ has the form $H = I_1 \times \ldots \times I_d$, where $I_1, \ldots, I_d$ are intervals. The natural volume $|H|$ is defined as $|H| : = |I_1| \cdot \ldots \cdot |I_d|$. A simple set $M \subset \mathbb{R}^d$ can be written as finite union $H_1 \cup \ldots \cup H_n$ of disjoint hyperrectangles and the natural measure of $M$ is defined as $|M| : = |H_1| + \ldots + |H_n|$. Now I want to prove the following theorem: Theorem. For disjoint simple sets $\{M_j\}_{j=1}^{\infty}$, where $\bigcup_{j=1}^{\infty} M_j$ is a simple set again, it holds that   $$ \left| \bigcup_{j=1}^{\infty} M_j \right| = \sum_{j=1}^{\infty} |M_j|.$$ By trying to prove this theorem I realised that the function $|\cdot|$ on simple sets has properties we are used from measures. For example we have $M_1 \subset M_2 \Rightarrow |M_1| \leq |M_2|$. It follows from the definition of $|\cdot|$ that we have $$ \left| \bigcup_{j=1}^{n} M_j \right| =\left| \bigcup_{j=1}^{n} \bigcup_{i=1}^{k_j}H_{i,j} \right|=  \sum_{j=1}^{n} \sum_{i=1}^{k_j}|H_{i,j}| = \sum_{j=1}^{n} |M_j|.$$ At this point I have no idea how to extend this property to countable unions.","A hyperrectangle in $\mathbb{R}^d$ has the form $H = I_1 \times \ldots \times I_d$, where $I_1, \ldots, I_d$ are intervals. The natural volume $|H|$ is defined as $|H| : = |I_1| \cdot \ldots \cdot |I_d|$. A simple set $M \subset \mathbb{R}^d$ can be written as finite union $H_1 \cup \ldots \cup H_n$ of disjoint hyperrectangles and the natural measure of $M$ is defined as $|M| : = |H_1| + \ldots + |H_n|$. Now I want to prove the following theorem: Theorem. For disjoint simple sets $\{M_j\}_{j=1}^{\infty}$, where $\bigcup_{j=1}^{\infty} M_j$ is a simple set again, it holds that   $$ \left| \bigcup_{j=1}^{\infty} M_j \right| = \sum_{j=1}^{\infty} |M_j|.$$ By trying to prove this theorem I realised that the function $|\cdot|$ on simple sets has properties we are used from measures. For example we have $M_1 \subset M_2 \Rightarrow |M_1| \leq |M_2|$. It follows from the definition of $|\cdot|$ that we have $$ \left| \bigcup_{j=1}^{n} M_j \right| =\left| \bigcup_{j=1}^{n} \bigcup_{i=1}^{k_j}H_{i,j} \right|=  \sum_{j=1}^{n} \sum_{i=1}^{k_j}|H_{i,j}| = \sum_{j=1}^{n} |M_j|.$$ At this point I have no idea how to extend this property to countable unions.",,"['measure-theory', 'elementary-set-theory', 'lebesgue-measure', 'volume']"
16,Show that if $E$ is Jordan measurable then $m(A-B) \leq \epsilon$,Show that if  is Jordan measurable then,E m(A-B) \leq \epsilon,"I want to show that if $E$ is Jordan measurable then for every $\epsilon > 0$ there exists $A \subset E \subset B$ such that $m(A-B) \leq \epsilon$. I think I have the right ideas but feel I am missing some details. I'd like some feedback for the following proof: Let $\epsilon>0$ be given. Suppose $E$ is Jordan measurable. Then there exists $A$ and $B$ elementary with $A \subset E \subset B$ such that $$ \sup m(A) = \inf m(B) $$ and thus $$ m(A) \leq m(B) $$ which implies $$ 0 \leq m(B) - m(A) $$ Now since $A \subset B$ we know $$ 0 \leq m(B) - m(A) = m(B-A) $$ and we can always choose $A,B$ such that $$ m(B-A) \leq \epsilon $$","I want to show that if $E$ is Jordan measurable then for every $\epsilon > 0$ there exists $A \subset E \subset B$ such that $m(A-B) \leq \epsilon$. I think I have the right ideas but feel I am missing some details. I'd like some feedback for the following proof: Let $\epsilon>0$ be given. Suppose $E$ is Jordan measurable. Then there exists $A$ and $B$ elementary with $A \subset E \subset B$ such that $$ \sup m(A) = \inf m(B) $$ and thus $$ m(A) \leq m(B) $$ which implies $$ 0 \leq m(B) - m(A) $$ Now since $A \subset B$ we know $$ 0 \leq m(B) - m(A) = m(B-A) $$ and we can always choose $A,B$ such that $$ m(B-A) \leq \epsilon $$",,"['real-analysis', 'measure-theory', 'proof-verification']"
17,"Limit of measures, two questions on limits of integrals","Limit of measures, two questions on limits of integrals",,"Suppose $\mu_n$ is a sequence of measures on $(X, \mathcal{A})$ such that $\mu_n(X) = 1$ for all $n$ and $\mu_n(A)$ converges as $n \to \infty$ for each $A \in \mathcal{A}$. Call the limit $\mu(A)$. I can show that $\mu$ is a measure. I have two questions. First question. Do we have necessarily have that $\int f\,d\mu_n \to \int f\,d\mu$ whenever $f$ is bounded and measurable? Second question. Do we have necessarily have that$$\int f\,d\mu \le \liminf_{n \to \infty} \int f\,d\mu_n$$whenever $f$ is nonnegative and measurable? Thanks in advance!","Suppose $\mu_n$ is a sequence of measures on $(X, \mathcal{A})$ such that $\mu_n(X) = 1$ for all $n$ and $\mu_n(A)$ converges as $n \to \infty$ for each $A \in \mathcal{A}$. Call the limit $\mu(A)$. I can show that $\mu$ is a measure. I have two questions. First question. Do we have necessarily have that $\int f\,d\mu_n \to \int f\,d\mu$ whenever $f$ is bounded and measurable? Second question. Do we have necessarily have that$$\int f\,d\mu \le \liminf_{n \to \infty} \int f\,d\mu_n$$whenever $f$ is nonnegative and measurable? Thanks in advance!",,['real-analysis']
18,"Real Analysis, Folland 3.25 Exampes Functions of Bounded Variation","Real Analysis, Folland 3.25 Exampes Functions of Bounded Variation",,"Background Information: Taking $a = -\infty$ and considering the total variation as a function of $b$ . To with $F:\mathbb{R}\rightarrow \mathbb{C}$ and $x\in\mathbb{R}$ , we define $$T_F(x) = \sup\{\sum_{1}^{n}|F(x_j) - F(x_{j-1}|:n\in\mathbb{N},-\infty < x_0 < \ldots < x_n = x\}$$ $T_F$ is called the total variation of $F$ . We observe that the sums in the definition of $T_F$ are made bigger if the additional subdivision points $x_j$ are added. Hence, if $a < b$ , the deinition of $T_F(b)$ is unaffected if we assume that $a$ is always one of the subdivision points. It follows that $$T_F(b) - T_F(a) = \sup\{\sum_{1}^{n}|F(x_j) - F(x_{j-1}|:n\in\mathbb{N},a = x_0 < \ldots < x_n = b\}$$ Thus $T_F$ is an increasing function with values in $[0,\infty]$ . If $T_F(\infty) = \lim_{x\rightarrow \infty}T_F(x)$ is finite, we say that $F$ is of bounded variation on $\mathbb{R}$ , and we denote the space of all such $F$ by $BV$ . More generally, the supremum on the right side is called the total variation of $F$ on $[a,b]$ . It depends only on the values of $F$ on $[a,b]$ , so we may define $BV([a,b])$ to be the set of all functions on $[a,b]$ whose total variation on $[a,b]$ is finite. Question: I have been working on these examples today and I am sort of stuck at for c,d,and e. I will provide the proofs I made for a and b just because. 3.25 Examples: a.) If $F:\mathbb{R}\rightarrow \mathbb{R}$ is bounded and increasing, then $F\in BV$ (in fact, $T_F(x) = F(x) - F(-\infty)$ ). b.) If $F,G\in BV$ and $a,b\in\mathbb{C}$ , then $aF + bG\in BV$ . c.) If $F$ is differentiable on $\mathbb{R}$ and $F'$ is bounded, then $F\in BV([a,b])$ for $-\infty < a < b < \infty$ (by MVT). d.) If $F(x) = \sin x$ , then $F\in BV([a,b])$ for $-\infty < a < b < \infty$ , but $F\notin BV$ . e.) If $F(x) = x\sin(x^-1)$ for $x\neq 0$ and $F(0) = 0$ , then $F\notin BV([a,b])$ for $a\leq 0 < b$ or $a < 0\leq b$ . Proof a.) - If $F:\mathbb{R} \rightarrow\mathbb{R}$ and $x\in\mathbb{R}$ , then $$T_F(x) = \sup\{\sum_{1}^{n}|F(x_j) - F(x_{j-1}|):n\in\mathbb{N}, -\infty < x_0 < \ldots < x_n = x \}$$ Since $F$ is increasing, the intervals $(F(x^-1),F(x^+) (x\in\mathbb{R})$ are disjoint, and for $|x| < N$ they lie in the interval $(F(-N),F(N))$ . Hence $$\sum_{|x| < N}|F(x^{+} - F(x^{-1}| \leq F(N) - F(-N) < \infty$$ so now we know $F$ is finite, therefore the total variation of $F$ is also finite, therefore $$\lim\limits_{x\rightarrow \infty}T_F(x) = T_F(\infty)\Rightarrow F\in BV$$ Proof b.) - Since $F,G\in BV \Rightarrow \lim_{x\rightarrow \infty}T_F(x) = T_F(\infty)$ and $\lim_{x\rightarrow \infty}T_G(x) = T_G(\infty)$ since $a,b$ are just scalars it follows that $$\lim_{x\rightarrow \infty} aT_F(x) + bT_G(x) = aT_F(\infty) + bT_G(\infty) \Rightarrow aF + bG\in BV$$ Questions for c.) Since we know $F$ is differentiable on $\mathbb{R}$ and $F'$ is bounded we can conclude that $F$ is uniformly continuous. Therefore, it seems to me to complete this proof we have to assume that $F$ is uniformly continuous on $[a,b]$ and differentiable on $(a,b)$ then we can apply the Mean Value theorem. But I am not sure how we show finiteness to conclude that $F\in BV([a,b])$ . Questions for d.) Since $F(x) = sin(x)$ we know that $F$ is then continuous and I guess based on c.) I need to show $F\in BV([a,b])$ but I am not sure how to show that $F\notin BV$ I am still thinking more about e.) and d.) I will re-edit if I get any further.","Background Information: Taking and considering the total variation as a function of . To with and , we define is called the total variation of . We observe that the sums in the definition of are made bigger if the additional subdivision points are added. Hence, if , the deinition of is unaffected if we assume that is always one of the subdivision points. It follows that Thus is an increasing function with values in . If is finite, we say that is of bounded variation on , and we denote the space of all such by . More generally, the supremum on the right side is called the total variation of on . It depends only on the values of on , so we may define to be the set of all functions on whose total variation on is finite. Question: I have been working on these examples today and I am sort of stuck at for c,d,and e. I will provide the proofs I made for a and b just because. 3.25 Examples: a.) If is bounded and increasing, then (in fact, ). b.) If and , then . c.) If is differentiable on and is bounded, then for (by MVT). d.) If , then for , but . e.) If for and , then for or . Proof a.) - If and , then Since is increasing, the intervals are disjoint, and for they lie in the interval . Hence so now we know is finite, therefore the total variation of is also finite, therefore Proof b.) - Since and since are just scalars it follows that Questions for c.) Since we know is differentiable on and is bounded we can conclude that is uniformly continuous. Therefore, it seems to me to complete this proof we have to assume that is uniformly continuous on and differentiable on then we can apply the Mean Value theorem. But I am not sure how we show finiteness to conclude that . Questions for d.) Since we know that is then continuous and I guess based on c.) I need to show but I am not sure how to show that I am still thinking more about e.) and d.) I will re-edit if I get any further.","a = -\infty b F:\mathbb{R}\rightarrow \mathbb{C} x\in\mathbb{R} T_F(x) = \sup\{\sum_{1}^{n}|F(x_j) - F(x_{j-1}|:n\in\mathbb{N},-\infty < x_0 < \ldots < x_n = x\} T_F F T_F x_j a < b T_F(b) a T_F(b) - T_F(a) = \sup\{\sum_{1}^{n}|F(x_j) - F(x_{j-1}|:n\in\mathbb{N},a = x_0 < \ldots < x_n = b\} T_F [0,\infty] T_F(\infty) = \lim_{x\rightarrow \infty}T_F(x) F \mathbb{R} F BV F [a,b] F [a,b] BV([a,b]) [a,b] [a,b] F:\mathbb{R}\rightarrow \mathbb{R} F\in BV T_F(x) = F(x) - F(-\infty) F,G\in BV a,b\in\mathbb{C} aF + bG\in BV F \mathbb{R} F' F\in BV([a,b]) -\infty < a < b < \infty F(x) = \sin x F\in BV([a,b]) -\infty < a < b < \infty F\notin BV F(x) = x\sin(x^-1) x\neq 0 F(0) = 0 F\notin BV([a,b]) a\leq 0 < b a < 0\leq b F:\mathbb{R} \rightarrow\mathbb{R} x\in\mathbb{R} T_F(x) = \sup\{\sum_{1}^{n}|F(x_j) - F(x_{j-1}|):n\in\mathbb{N}, -\infty < x_0 < \ldots < x_n = x \} F (F(x^-1),F(x^+) (x\in\mathbb{R}) |x| < N (F(-N),F(N)) \sum_{|x| < N}|F(x^{+} - F(x^{-1}| \leq F(N) - F(-N) < \infty F F \lim\limits_{x\rightarrow \infty}T_F(x) = T_F(\infty)\Rightarrow F\in BV F,G\in BV \Rightarrow \lim_{x\rightarrow \infty}T_F(x) = T_F(\infty) \lim_{x\rightarrow \infty}T_G(x) = T_G(\infty) a,b \lim_{x\rightarrow \infty} aT_F(x) + bT_G(x) = aT_F(\infty) + bT_G(\infty) \Rightarrow aF + bG\in BV F \mathbb{R} F' F F [a,b] (a,b) F\in BV([a,b]) F(x) = sin(x) F F\in BV([a,b]) F\notin BV","['real-analysis', 'measure-theory']"
19,"Let $f$ be a Lebesgue measurable function on $\Bbb{R}$ satisfying some properties, prove $f\equiv 0$ a.e.","Let  be a Lebesgue measurable function on  satisfying some properties, prove  a.e.",f \Bbb{R} f\equiv 0,"Let $f$ be a Lebesgue measurable function on $\Bbb{R}$ satisfying: i) there is $p\in (1,\infty)$ such that $f\in L^p(I)$ for any bounded interval $I$ . ii) there is some $\theta \in (0,1)$ such that: $$\left|\int_I f\ dx\right|^p\leq \theta (\mu(I))^{p-1}\int_I |f|^p\ dx$$ Prove that $f\equiv 0 $ a.e. This is a previous qual question (3, beware: PDF). My thoughts. We assume that there is some $E$ where without loss of generality $f>0$ on $E$ and $\mu(E)>0$ . Using regularity of Lebesgue measure, for all $\epsilon>0$ there is some open $G_{\epsilon}$ with $\mu(G_{\epsilon}\setminus E)<\epsilon$ and $E \subseteq G_{\epsilon}$ . We may decompose $G_{\epsilon}$ as a countable disjoint union $I_k$ . So we must only show that there is a contradiction if $f>0$ on some interval. I tried arguing like this: $$\begin{align*}\left|\int_I f\ dx\right|^p&\leq \theta (\mu(I))^{p-1}\int_I |f|^p\ dx\\ &\leq\theta (\mu(I))^{p-1} \mu(I) \operatorname{essup}(|f|^p)\\&=\theta(\mu(I))^p\operatorname{essup}_I(|f|^p)\end{align*}$$ I feel like there should be a general contradiction here (for example if $I=(0,1)$ and $f=1$ this inequality doesn't hold). Can someone help me? I would like hints only please.","Let be a Lebesgue measurable function on satisfying: i) there is such that for any bounded interval . ii) there is some such that: Prove that a.e. This is a previous qual question (3, beware: PDF). My thoughts. We assume that there is some where without loss of generality on and . Using regularity of Lebesgue measure, for all there is some open with and . We may decompose as a countable disjoint union . So we must only show that there is a contradiction if on some interval. I tried arguing like this: I feel like there should be a general contradiction here (for example if and this inequality doesn't hold). Can someone help me? I would like hints only please.","f \Bbb{R} p\in (1,\infty) f\in L^p(I) I \theta \in (0,1) \left|\int_I f\ dx\right|^p\leq \theta (\mu(I))^{p-1}\int_I |f|^p\ dx f\equiv 0  E f>0 E \mu(E)>0 \epsilon>0 G_{\epsilon} \mu(G_{\epsilon}\setminus E)<\epsilon E \subseteq G_{\epsilon} G_{\epsilon} I_k f>0 \begin{align*}\left|\int_I f\ dx\right|^p&\leq \theta (\mu(I))^{p-1}\int_I |f|^p\ dx\\ &\leq\theta (\mu(I))^{p-1} \mu(I) \operatorname{essup}(|f|^p)\\&=\theta(\mu(I))^p\operatorname{essup}_I(|f|^p)\end{align*} I=(0,1) f=1","['functional-analysis', 'measure-theory']"
20,"Real Analysis, Folland Corollary 3.10 The Lebesgue Radon Nikodym Theorem","Real Analysis, Folland Corollary 3.10 The Lebesgue Radon Nikodym Theorem",,"Background Information: Proposition 3.9 - Suppose that $\nu$ is a $\sigma$ -finite measure and $\lambda$ are $\sigma$ -finite measures on $(X,M)$ such that $\nu\ll \mu$ and $\mu\ll \lambda$ . a.) If $g\in L^1(\nu)$ , then $g(d\nu/d\mu)\in L^1(\nu)$ and $$\int g d\nu = \int g \frac{d\nu}{d\mu}d\mu$$ b.) We have that $\nu\ll \lambda$ , and $$\frac{d\nu}{d\lambda} = \frac{d\nu}{d\mu}\frac{d\mu}{d\lambda}  \quad \lambda-\text{a.e.}$$ Question: Corollary 3.10 - If $\mu \ll \lambda$ and $\lambda \ll \mu$ then $$\left(\frac{d\lambda}{d\mu}\right)\left(\frac{d\mu}{d\lambda}\right) = 1 \quad\text{a.e.}$$ with respect to either $\lambda$ or $\mu$ . Attempted proof - Suppose $\mu\ll\lambda$ then by proposition 3.9 b.) $$\frac{d\mu}{d\lambda} = \frac{d\mu}{d\nu}\frac{d\nu}{d\lambda} \quad \lambda- \text{a.e.}$$ Similarly if $\lambda \ll \mu$ then by proposition 3.9 b.) $$\frac{d\lambda}{d\mu} = \frac{d\lambda}{d\nu}\frac{d\nu}{d\mu} \quad \mu- \text{a.e.}$$ Then putting these two quantities together and using the result of proposition 3.9 we have that $$\left(\frac{d\mu}{d\lambda}\right)\left(\frac{d\lambda}{d\mu}\right) = 1 \quad\text{a.e.}$$ I am not sure if this is correct, any suggestions is greatly appreciated.","Background Information: Proposition 3.9 - Suppose that is a -finite measure and are -finite measures on such that and . a.) If , then and b.) We have that , and Question: Corollary 3.10 - If and then with respect to either or . Attempted proof - Suppose then by proposition 3.9 b.) Similarly if then by proposition 3.9 b.) Then putting these two quantities together and using the result of proposition 3.9 we have that I am not sure if this is correct, any suggestions is greatly appreciated.","\nu \sigma \lambda \sigma (X,M) \nu\ll \mu \mu\ll \lambda g\in L^1(\nu) g(d\nu/d\mu)\in L^1(\nu) \int g d\nu = \int g \frac{d\nu}{d\mu}d\mu \nu\ll \lambda \frac{d\nu}{d\lambda} = \frac{d\nu}{d\mu}\frac{d\mu}{d\lambda}  \quad \lambda-\text{a.e.} \mu \ll \lambda \lambda \ll \mu \left(\frac{d\lambda}{d\mu}\right)\left(\frac{d\mu}{d\lambda}\right) = 1 \quad\text{a.e.} \lambda \mu \mu\ll\lambda \frac{d\mu}{d\lambda} = \frac{d\mu}{d\nu}\frac{d\nu}{d\lambda} \quad \lambda- \text{a.e.} \lambda \ll \mu \frac{d\lambda}{d\mu} = \frac{d\lambda}{d\nu}\frac{d\nu}{d\mu} \quad \mu- \text{a.e.} \left(\frac{d\mu}{d\lambda}\right)\left(\frac{d\lambda}{d\mu}\right) = 1 \quad\text{a.e.}","['real-analysis', 'measure-theory', 'proof-verification']"
21,Integrals over subset of measure space,Integrals over subset of measure space,,"Let $(X, \mathcal{M}, \mu)$ be a measure space. Suppose $E \in \mathcal{M}$ and $f \in L^+$ where $L^+$ is a space of measurable functions from $X$ to $[0, \infty]$. $\int_E f$ is defined by $\int_X f\chi_E$ where $\chi_E$ is a characteristic function of $E$. Now every time we want to use some property that is true for integrals over whole space $X$, we have to do manipulations with $\chi_E$. For example, let $f_n$ be a sequence in $L^+$ such that $f_n(x) \nearrow f(x)$ for all $x \in E$. Suppose we know that monotone convergence theorem is true for integrals over $X$ and we want to prove $$\int_E f = \lim_{n\to\infty} \int_E f_n.$$ Since $f_n\chi_E \nearrow f\chi_E$ we have $$\int_E f = \int_X f\chi_E = \lim_{n\to\infty} \int_X f_n\chi_E = \lim_{n\to\infty} \int_E f_n.$$ I know it's easy but is there a way to avoid such manipulations? I want to know that equality above and many other statements about integrals are true because $E$ is a measure space in its own right (seems much more natural). More precisely, for $E \in \mathcal{M}$ define $$\mathcal{M}_E = \{ E \cap F \mid F \in \mathcal{M} \}.$$ It's easy to check that $\mathcal{M}_E$ is a $\sigma$-algebra. $(E, \mathcal{M}_E, \mu|_{\mathcal{M}_E})$ is a measure space and $\int_E f$ in space $(X, \mathcal{M}, \mu)$ is equal to $\int_E f|_E$ in space $(E, \mathcal{M}_E, \mu|_{\mathcal{M}_E})$ for every measurable $f$. Is this a commonly accepted way of handling integrals over subset of measure space? If not, do I really have to use $\chi_E$ every time or there is some other way?","Let $(X, \mathcal{M}, \mu)$ be a measure space. Suppose $E \in \mathcal{M}$ and $f \in L^+$ where $L^+$ is a space of measurable functions from $X$ to $[0, \infty]$. $\int_E f$ is defined by $\int_X f\chi_E$ where $\chi_E$ is a characteristic function of $E$. Now every time we want to use some property that is true for integrals over whole space $X$, we have to do manipulations with $\chi_E$. For example, let $f_n$ be a sequence in $L^+$ such that $f_n(x) \nearrow f(x)$ for all $x \in E$. Suppose we know that monotone convergence theorem is true for integrals over $X$ and we want to prove $$\int_E f = \lim_{n\to\infty} \int_E f_n.$$ Since $f_n\chi_E \nearrow f\chi_E$ we have $$\int_E f = \int_X f\chi_E = \lim_{n\to\infty} \int_X f_n\chi_E = \lim_{n\to\infty} \int_E f_n.$$ I know it's easy but is there a way to avoid such manipulations? I want to know that equality above and many other statements about integrals are true because $E$ is a measure space in its own right (seems much more natural). More precisely, for $E \in \mathcal{M}$ define $$\mathcal{M}_E = \{ E \cap F \mid F \in \mathcal{M} \}.$$ It's easy to check that $\mathcal{M}_E$ is a $\sigma$-algebra. $(E, \mathcal{M}_E, \mu|_{\mathcal{M}_E})$ is a measure space and $\int_E f$ in space $(X, \mathcal{M}, \mu)$ is equal to $\int_E f|_E$ in space $(E, \mathcal{M}_E, \mu|_{\mathcal{M}_E})$ for every measurable $f$. Is this a commonly accepted way of handling integrals over subset of measure space? If not, do I really have to use $\chi_E$ every time or there is some other way?",,"['integration', 'measure-theory', 'soft-question']"
22,"If $\{f_n\}\subset L_1([0,1])$, $f_n\to f$ pointwise, and $\sup_{n} \int_{0}^{1} |f_n|\max (0, \log |f_n|)<\infty$, then $f_n\to f$ in $L_1$","If ,  pointwise, and , then  in","\{f_n\}\subset L_1([0,1]) f_n\to f \sup_{n} \int_{0}^{1} |f_n|\max (0, \log |f_n|)<\infty f_n\to f L_1","I'm going through old analysis qualifying exams, and have come to a roadblock on the following problem: Suppose that $\{f_n\}\subset L_1([0,1])$, $f_n\to f$ pointwise, and $\sup_{n} \int_{0}^{1} |f_n|\max (0, \log |f_n|)<\infty$. Show that $f\in L_1([0,1])$ and $f_n\to f$ in $L_1$. Combining $\sup_{n} \int_{0}^{1} |f_n|\max (0, \log |f_n|)<\infty$ with Fatou's Lemma gives that $|f(x)|\max (0, \log |f(x)|) \in L_1$, and from here I can show that $f\in L_1$ by letting $A= \{x\mid |f(x)|>e\}$ and observing that $|f(x)|$ is bounded below $|f(x)|\max (0, \log |f(x)|)$ on $A$ and is bounded below $e$ on $A^c$. However, I got stuck here and am not sure how to proceed further. Hints or solutions are both welcome.","I'm going through old analysis qualifying exams, and have come to a roadblock on the following problem: Suppose that $\{f_n\}\subset L_1([0,1])$, $f_n\to f$ pointwise, and $\sup_{n} \int_{0}^{1} |f_n|\max (0, \log |f_n|)<\infty$. Show that $f\in L_1([0,1])$ and $f_n\to f$ in $L_1$. Combining $\sup_{n} \int_{0}^{1} |f_n|\max (0, \log |f_n|)<\infty$ with Fatou's Lemma gives that $|f(x)|\max (0, \log |f(x)|) \in L_1$, and from here I can show that $f\in L_1$ by letting $A= \{x\mid |f(x)|>e\}$ and observing that $|f(x)|$ is bounded below $|f(x)|\max (0, \log |f(x)|)$ on $A$ and is bounded below $e$ on $A^c$. However, I got stuck here and am not sure how to proceed further. Hints or solutions are both welcome.",,"['real-analysis', 'measure-theory', 'convergence-divergence', 'lebesgue-integral']"
23,"Real Analysis, Folland Problem 2.2.14 Integration of Nonnegative functions","Real Analysis, Folland Problem 2.2.14 Integration of Nonnegative functions",,"Problem 2.2.14 - If $f\in L^{+}$, let $\lambda(E) = \int_{E}f d\mu$ for $E\in M$. Then $\lambda$ is a measure on $M$, and for any $g\in L^{+}$, $\int g d\lambda = \int f g d\mu$.(First suppose that $g$ is simple) Attempted proof -  Observe that $\lambda(\emptyset) = \int_{\emptyset}f d\mu = \int 1_{\emptyset} f d\mu = \int 0 f d\mu = 0$. Let $\{E_n\}_{n\in\mathbb{N}}\subset M$ and let $F = \bigcup_{n=1}^{\infty}E_n$. Then $$\lambda(F) = \int_{F}f d\mu = \int 1_{F}f d\mu = \int \left(\sum_{n=1}^{\infty}1_{E_n}f\right)d\mu = \sum_{n=1}^{\infty}\int 1_{E_n}f d\mu \ \ \text{by proposition 2.15}\\ = \sum_{n=1}^{\infty}\int_{E_n}f d\mu = \sum_{n=1}^{\infty}\lambda(E_n)$$ Therefore $\lambda$ is a measure. Now, let $g\in L^{+}$, where $g$ is a simple with standard representation $g = \sum_{n=1}^{N}a_n 1_{E_n}$, then $$\int g d\lambda = \sum_{n=1}^{N}a_n\lambda(E_n) = \sum_{n=1}^{N}a_n\int_{E_n}f d\mu = \sum_{n=1}^{N}a_n\int f 1_{E_n}d\mu$$ $$=\int \sum_{n=1}^{N}a_n f 1_{E_n}d\mu = \int f g d\mu$$ Otherwise, there exists an increasing sequence $\{g_n \}_{n\in\mathbb{N}}\in L^{+}$ that converges to $g$, so that $\{fg_n\}_{n\in\mathbb{N}}$ converges to $fg$ and hence $$\int g d\lambda = \lim_{n\rightarrow \infty}\int g_n d\lambda = \lim_{n\rightarrow \infty}\int f g_n d\mu = \int f g d\mu$$ I am pretty sure this is correct, I just don't understand how $$\int f \chi_{F}d\mu = \int (\sum_{1}^{\infty}\chi_{E_n}f)d\mu$$ Also I do not understand the last part starting with otherwise that I found online.","Problem 2.2.14 - If $f\in L^{+}$, let $\lambda(E) = \int_{E}f d\mu$ for $E\in M$. Then $\lambda$ is a measure on $M$, and for any $g\in L^{+}$, $\int g d\lambda = \int f g d\mu$.(First suppose that $g$ is simple) Attempted proof -  Observe that $\lambda(\emptyset) = \int_{\emptyset}f d\mu = \int 1_{\emptyset} f d\mu = \int 0 f d\mu = 0$. Let $\{E_n\}_{n\in\mathbb{N}}\subset M$ and let $F = \bigcup_{n=1}^{\infty}E_n$. Then $$\lambda(F) = \int_{F}f d\mu = \int 1_{F}f d\mu = \int \left(\sum_{n=1}^{\infty}1_{E_n}f\right)d\mu = \sum_{n=1}^{\infty}\int 1_{E_n}f d\mu \ \ \text{by proposition 2.15}\\ = \sum_{n=1}^{\infty}\int_{E_n}f d\mu = \sum_{n=1}^{\infty}\lambda(E_n)$$ Therefore $\lambda$ is a measure. Now, let $g\in L^{+}$, where $g$ is a simple with standard representation $g = \sum_{n=1}^{N}a_n 1_{E_n}$, then $$\int g d\lambda = \sum_{n=1}^{N}a_n\lambda(E_n) = \sum_{n=1}^{N}a_n\int_{E_n}f d\mu = \sum_{n=1}^{N}a_n\int f 1_{E_n}d\mu$$ $$=\int \sum_{n=1}^{N}a_n f 1_{E_n}d\mu = \int f g d\mu$$ Otherwise, there exists an increasing sequence $\{g_n \}_{n\in\mathbb{N}}\in L^{+}$ that converges to $g$, so that $\{fg_n\}_{n\in\mathbb{N}}$ converges to $fg$ and hence $$\int g d\lambda = \lim_{n\rightarrow \infty}\int g_n d\lambda = \lim_{n\rightarrow \infty}\int f g_n d\mu = \int f g d\mu$$ I am pretty sure this is correct, I just don't understand how $$\int f \chi_{F}d\mu = \int (\sum_{1}^{\infty}\chi_{E_n}f)d\mu$$ Also I do not understand the last part starting with otherwise that I found online.",,"['real-analysis', 'measure-theory']"
24,$m_*(E)=m^*(E)\iff E$ Lebesgue measurable,Lebesgue measurable,m_*(E)=m^*(E)\iff E,"Let $E\subset [a,b]$. Show that $E$ is Lebesgue measurable if and only if the Lebesgue outer measure of $E$ is equal to the Lebesgue inner measure of $E$. I have seen the proof for this above statement for the Caratheodory definition of Lebesgue measurable, but I was wondering if someone could help me prove it for a different (but equivalent) definition of Lebesgue measurable set. The definition my book is using: $E\subset \mathbb{R}$ is said to be Lebesgue measurable if $E$ can be squeezed between an open set $G$ and a closed set $F$ where we have that $m^*(G\setminus F)<\varepsilon$ I need some help to start the problem please. Thanks! Just for completeness I provide the definitions of inner and outer lebesgue measure below: Lebesgue outer measure: For a subset $E$ of $\mathbb{R}$, we have that $m^*(E)=\inf\{\sum_{n=1}^{\infty}\ell(I_n):E\subset \cup_{n=1}^{\infty}I_n\}$ where $\ell(\cdot)$ denotes the length Lebesgue inner measure: For a subset $E$ of a bounded interval $[a,b]$, we have that $m_*(E)=b-a-m^*([a,b]\setminus E)$","Let $E\subset [a,b]$. Show that $E$ is Lebesgue measurable if and only if the Lebesgue outer measure of $E$ is equal to the Lebesgue inner measure of $E$. I have seen the proof for this above statement for the Caratheodory definition of Lebesgue measurable, but I was wondering if someone could help me prove it for a different (but equivalent) definition of Lebesgue measurable set. The definition my book is using: $E\subset \mathbb{R}$ is said to be Lebesgue measurable if $E$ can be squeezed between an open set $G$ and a closed set $F$ where we have that $m^*(G\setminus F)<\varepsilon$ I need some help to start the problem please. Thanks! Just for completeness I provide the definitions of inner and outer lebesgue measure below: Lebesgue outer measure: For a subset $E$ of $\mathbb{R}$, we have that $m^*(E)=\inf\{\sum_{n=1}^{\infty}\ell(I_n):E\subset \cup_{n=1}^{\infty}I_n\}$ where $\ell(\cdot)$ denotes the length Lebesgue inner measure: For a subset $E$ of a bounded interval $[a,b]$, we have that $m_*(E)=b-a-m^*([a,b]\setminus E)$",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
25,Radon Nikodym Thm: extending to $\sigma$-finite case,Radon Nikodym Thm: extending to -finite case,\sigma,"I am reading Bartle's ""Elements of Integration"". Radon-Nikodym Thm : Let $\lambda,\mu$ be $\sigma$-finite measures on a measurable space $(X,\textbf{X})$ and say $\lambda \ll \mu$.  Then $\exists$ unique $\mu$-a.e. measurable $f:X \to \bar{\mathbb{R}}_{\geq 0}$ (that's my notation for the nonnegative extended reals) s.t. $\lambda(E)= \int_E f \, d \mu$, $\forall E \in \textbf{X}$. From his pf, I'm comfortable with the case where $\lambda,\mu$ are finite (both existence and uniqueness). Here is how Bartle generalizes to the $\sigma$-finite case. Let $X_1 \subseteq X_2 \subseteq\cdots$ be s.t. $X= \bigcup_{n=1}^\infty X_n$, each $\lambda(X_n),\mu(X_n)< \infty$. $\exists$ fns $h_n: X \to \bar{\mathbb{R}}_{\geq 0}$ s.t. $h_n(x)=0$ for $x \notin X_n$ and $$\lambda(E)= \int_E h_n d \mu, \forall E \subseteq X_n \text{ measurable} \tag1$$ If $n \leq m$, then $X_n \subseteq X_m$ and $\int_E h_n d \mu = \int_E h_m d \mu$, $\forall E \in \textbf{X}$.  So $h_n 1_{X_n}= h_m 1_{X_n}$ $\mu$-a.e. Put $f_n:=\sup \{ h_1,\ldots,h_n\}$, so $(f_n)$ is a monotone seq.  Put $f:= \lim_{n \to \infty} f_n$.  Then $\lambda(E \cap X_n)= \int_E f_n \, d \mu$, so $\lambda(E)= \int_E f \, d \mu$, $\forall E \in \textbf{X}$, by the Monotone Conv Thm. Here are my questions regarding the proof: a) (2nd bullet point) I can see $\lambda_n (E):= \lambda(E \cap X_n)$ and $\mu_n (E):= \mu(E \cap X_n)$ are finite measures s.t. $\lambda_n \ll \mu_n$.  Thus, $\exists$ fns $h_n$ s.t. $\lambda(E)= \int_E h_n d \mu_n$, $\forall E \subseteq X_n$ measurable.  But why can we replace $\mu_n$ with $\mu$ to get (1)?  This seems intuitive but how do I make a rigorous argument?  Perhaps my attempt to define $\lambda_n, \mu_n$ was not helpful but it was the only way I could think of to use the result for finite measures. b) (4th bullet pt) Why does he define $f_n$ at all?  Why not just use $h_n$ in place of $f_n$?  It seems the $(h_n)$ are already an incr seq: for instance, $h_1=h_2$ $\mu$-a.e. on $X_1$ but $h_1=0$ on $X_1^c$ (while we know $h_2 \geq$0) so $h_1 \leq h_2$ $\mu$-a.e. I appreciate any help as I am new to measure theory and trying to understand how arguments are made.","I am reading Bartle's ""Elements of Integration"". Radon-Nikodym Thm : Let $\lambda,\mu$ be $\sigma$-finite measures on a measurable space $(X,\textbf{X})$ and say $\lambda \ll \mu$.  Then $\exists$ unique $\mu$-a.e. measurable $f:X \to \bar{\mathbb{R}}_{\geq 0}$ (that's my notation for the nonnegative extended reals) s.t. $\lambda(E)= \int_E f \, d \mu$, $\forall E \in \textbf{X}$. From his pf, I'm comfortable with the case where $\lambda,\mu$ are finite (both existence and uniqueness). Here is how Bartle generalizes to the $\sigma$-finite case. Let $X_1 \subseteq X_2 \subseteq\cdots$ be s.t. $X= \bigcup_{n=1}^\infty X_n$, each $\lambda(X_n),\mu(X_n)< \infty$. $\exists$ fns $h_n: X \to \bar{\mathbb{R}}_{\geq 0}$ s.t. $h_n(x)=0$ for $x \notin X_n$ and $$\lambda(E)= \int_E h_n d \mu, \forall E \subseteq X_n \text{ measurable} \tag1$$ If $n \leq m$, then $X_n \subseteq X_m$ and $\int_E h_n d \mu = \int_E h_m d \mu$, $\forall E \in \textbf{X}$.  So $h_n 1_{X_n}= h_m 1_{X_n}$ $\mu$-a.e. Put $f_n:=\sup \{ h_1,\ldots,h_n\}$, so $(f_n)$ is a monotone seq.  Put $f:= \lim_{n \to \infty} f_n$.  Then $\lambda(E \cap X_n)= \int_E f_n \, d \mu$, so $\lambda(E)= \int_E f \, d \mu$, $\forall E \in \textbf{X}$, by the Monotone Conv Thm. Here are my questions regarding the proof: a) (2nd bullet point) I can see $\lambda_n (E):= \lambda(E \cap X_n)$ and $\mu_n (E):= \mu(E \cap X_n)$ are finite measures s.t. $\lambda_n \ll \mu_n$.  Thus, $\exists$ fns $h_n$ s.t. $\lambda(E)= \int_E h_n d \mu_n$, $\forall E \subseteq X_n$ measurable.  But why can we replace $\mu_n$ with $\mu$ to get (1)?  This seems intuitive but how do I make a rigorous argument?  Perhaps my attempt to define $\lambda_n, \mu_n$ was not helpful but it was the only way I could think of to use the result for finite measures. b) (4th bullet pt) Why does he define $f_n$ at all?  Why not just use $h_n$ in place of $f_n$?  It seems the $(h_n)$ are already an incr seq: for instance, $h_1=h_2$ $\mu$-a.e. on $X_1$ but $h_1=0$ on $X_1^c$ (while we know $h_2 \geq$0) so $h_1 \leq h_2$ $\mu$-a.e. I appreciate any help as I am new to measure theory and trying to understand how arguments are made.",,"['real-analysis', 'measure-theory']"
26,Capacity of a set in $\mathbb{R}^n$,Capacity of a set in,\mathbb{R}^n,"The $2$-capacity of a set $\Omega$ sitting inside an open set $V \subset \mathbb{R}^n$ is given by $$\text{cap}_2(\Omega, V) = \inf_{u \in C^\infty_0(V), u|_\Omega \equiv 1} \int_V |\nabla u|^2 dx.$$ Now, if we assume that $\Omega$ is deep inside $V$, that is, suppose $\overline{\Omega} \subseteq V$, then do we have $\text{cap}_2(\Omega, V) = \text{cap}_2(\Omega, \mathbb{R}^n)$? Or at least $\text{cap}_2(\Omega, V) \leq C\text{cap}_2(\Omega, \mathbb{R}^n)$, where $C$ is a positive constant?","The $2$-capacity of a set $\Omega$ sitting inside an open set $V \subset \mathbb{R}^n$ is given by $$\text{cap}_2(\Omega, V) = \inf_{u \in C^\infty_0(V), u|_\Omega \equiv 1} \int_V |\nabla u|^2 dx.$$ Now, if we assume that $\Omega$ is deep inside $V$, that is, suppose $\overline{\Omega} \subseteq V$, then do we have $\text{cap}_2(\Omega, V) = \text{cap}_2(\Omega, \mathbb{R}^n)$? Or at least $\text{cap}_2(\Omega, V) \leq C\text{cap}_2(\Omega, \mathbb{R}^n)$, where $C$ is a positive constant?",,"['real-analysis', 'functional-analysis', 'measure-theory', 'reference-request', 'potential-theory']"
27,Showing that $f$ is not measurable,Showing that  is not measurable,f,"I'm learning about measure theory, specifically measurable functions, and need help with the following problem: Let $N$ be a non-measurable subset of $[0, 1]$ and define $$f(x) = \begin{cases} x, & x \in N  \\ -x, & x \in [0,1] \setminus N \end{cases}$$ $(1)$ Show that $f(x)$ is a non-measurable function. $(2)$ Show that $\forall a \in \mathbb R$ the set $\{f(x) = a\}$ is measurable. This problem looks rather simple but I think I'm missing some key points. I tried to prove $(1)$ by contradiction, that is assuming $f$ is measurable but I didn't get far. For $(2)$ my guess is that $m(\{f(x) = a\}) = 0$ (since by definition the Lebesgue measure of a single point is $0$ ) but I don't know how to show this properly.","I'm learning about measure theory, specifically measurable functions, and need help with the following problem: Let be a non-measurable subset of and define Show that is a non-measurable function. Show that the set is measurable. This problem looks rather simple but I think I'm missing some key points. I tried to prove by contradiction, that is assuming is measurable but I didn't get far. For my guess is that (since by definition the Lebesgue measure of a single point is ) but I don't know how to show this properly.","N [0, 1] f(x) = \begin{cases} x, & x \in N  \\ -x, & x \in [0,1] \setminus N \end{cases} (1) f(x) (2) \forall a \in \mathbb R \{f(x) = a\} (1) f (2) m(\{f(x) = a\}) = 0 0","['real-analysis', 'measure-theory', 'lebesgue-measure']"
28,"Let $\mu $ be a $\sigma $-finite measure. Show that for any $f\in L_p(\mu)$, $\|f\|_1=\sup\{ \int fg\, d\mu :\|g\|_\infty \leq 1\}$","Let  be a -finite measure. Show that for any ,","\mu  \sigma  f\in L_p(\mu) \|f\|_1=\sup\{ \int fg\, d\mu :\|g\|_\infty \leq 1\}","Let $\mu $ be a $\sigma $-finite measure. Show that for any $f\in L_p(\mu)$, $\|f\|_1=\sup\{ \int fg \, d\mu :\|g\|_\infty \leq 1\}$ I know that Holders inequality implies $\int fg \, d\mu \leq \|f\|_1 \|g\|_\infty$ and for all $\|g\|_\infty \leq 1$, $\int fg \, d\mu \leq \|f\|_1$. But how do I show it's the supremum? My intial idea was to show that there exists a $g$ so that it attains the supremum i.e. $fg=|f|$ but I can't seem to find one. Any hints please?","Let $\mu $ be a $\sigma $-finite measure. Show that for any $f\in L_p(\mu)$, $\|f\|_1=\sup\{ \int fg \, d\mu :\|g\|_\infty \leq 1\}$ I know that Holders inequality implies $\int fg \, d\mu \leq \|f\|_1 \|g\|_\infty$ and for all $\|g\|_\infty \leq 1$, $\int fg \, d\mu \leq \|f\|_1$. But how do I show it's the supremum? My intial idea was to show that there exists a $g$ so that it attains the supremum i.e. $fg=|f|$ but I can't seem to find one. Any hints please?",,"['measure-theory', 'lp-spaces']"
29,Martingale convergence for UI martingales,Martingale convergence for UI martingales,,"I started reading this paper (Lamb, Charles W..  Shorter Notes: A Short Proof of the Martingale Convergence Theorem . Proceedings of the American Mathematical Society 38.1 (1973): 215217) today. In paragraph 2 the author says The martingale $(X_n,\mathscr{F}_n:n\geq{0})$ is called    complete if there exists a random variable $X$ with $\mathbb{E}[X|\mathscr{F}_n] = X_n$ for $n\geq 0$.    There is no loss of generality in assuming that $X$ is $\mathscr{F}_\infty$-measurable where    $\mathscr{F}_\infty$ is the $\sigma$-field generated by $\bigcup \mathscr{F}_n$. It is an elementary exercise to show    that a martingale is complete if and only if it is uniformly integrable. We    remark only that the necessity is proved by defining a set function $\mu(A)=  \lim \mathbb{E}[X_n: A]$ on the field $\bigcup \mathscr{F}_n$, proving from the uniform integrability    that $\mu$ is a finite signed measure on $\bigcup \mathscr{F}_n$ [...] I can see why $\mu$ is a well defined set function and why it is finitely additive on $\bigcup \mathscr{F}_n$, but I didn't manage to prove countable additivity. This is my approach: let $(A_k)$ be a collection of disjoint elements of $\bigcup \mathscr{F}_n$ such that $A\equiv\bigcup_k A_k \in \bigcup_n \mathscr{F}_n$, then I can show by the Monotone Convergence Theorem that for all $m\geq 0$, $\mu(A)=\lim_{m\to \infty} \sum_k \mathbb{E}[X_m:A_k]$, but I don't see how to exchange the limit and the infinite sum. I guess this has to do with the fact that $X$ is uniformly integrable, but I don't understand how.","I started reading this paper (Lamb, Charles W..  Shorter Notes: A Short Proof of the Martingale Convergence Theorem . Proceedings of the American Mathematical Society 38.1 (1973): 215217) today. In paragraph 2 the author says The martingale $(X_n,\mathscr{F}_n:n\geq{0})$ is called    complete if there exists a random variable $X$ with $\mathbb{E}[X|\mathscr{F}_n] = X_n$ for $n\geq 0$.    There is no loss of generality in assuming that $X$ is $\mathscr{F}_\infty$-measurable where    $\mathscr{F}_\infty$ is the $\sigma$-field generated by $\bigcup \mathscr{F}_n$. It is an elementary exercise to show    that a martingale is complete if and only if it is uniformly integrable. We    remark only that the necessity is proved by defining a set function $\mu(A)=  \lim \mathbb{E}[X_n: A]$ on the field $\bigcup \mathscr{F}_n$, proving from the uniform integrability    that $\mu$ is a finite signed measure on $\bigcup \mathscr{F}_n$ [...] I can see why $\mu$ is a well defined set function and why it is finitely additive on $\bigcup \mathscr{F}_n$, but I didn't manage to prove countable additivity. This is my approach: let $(A_k)$ be a collection of disjoint elements of $\bigcup \mathscr{F}_n$ such that $A\equiv\bigcup_k A_k \in \bigcup_n \mathscr{F}_n$, then I can show by the Monotone Convergence Theorem that for all $m\geq 0$, $\mu(A)=\lim_{m\to \infty} \sum_k \mathbb{E}[X_m:A_k]$, but I don't see how to exchange the limit and the infinite sum. I guess this has to do with the fact that $X$ is uniformly integrable, but I don't understand how.",,"['measure-theory', 'martingales', 'uniform-integrability']"
30,Folland's Real Analysis 7.11,Folland's Real Analysis 7.11,,"Suppose $\mu$ is a Radon measure on $X$ such that $\mu(\left\lbrace x \right\rbrace)=0$ for all $x \in X$, and $A \in \mathbb{B}_X$ satisfies $0 < \mu(A) < \infty$. Then for any $\alpha$ such that $0 < \alpha < \mu(A)$ there is a Borel set $B \subset A$ such that $\mu(B) = \alpha$ I'm not even sure how to start this problem. It seems like a nice result, but any hints on how to start?","Suppose $\mu$ is a Radon measure on $X$ such that $\mu(\left\lbrace x \right\rbrace)=0$ for all $x \in X$, and $A \in \mathbb{B}_X$ satisfies $0 < \mu(A) < \infty$. Then for any $\alpha$ such that $0 < \alpha < \mu(A)$ there is a Borel set $B \subset A$ such that $\mu(B) = \alpha$ I'm not even sure how to start this problem. It seems like a nice result, but any hints on how to start?",,"['real-analysis', 'measure-theory']"
31,How to prove that Lebesgue measure is translation invariant,How to prove that Lebesgue measure is translation invariant,,"Can someone please explain: Assume for each $x \in \mathbb{R}$ and $A \subseteq \mathbb{R}$, that $x + A = \big\{ x + a \mid a \in A \big\}$. A and x + A are Borel sets for all $x \in \mathbb{R}$ Then, if  is the Lebesgue measure on B , how can it be proven to be a translation invariant? So far all I have gotten is that  (A) =  ( x + A ), for all Borel sets A and for all $x \in \mathbb{R}$.","Can someone please explain: Assume for each $x \in \mathbb{R}$ and $A \subseteq \mathbb{R}$, that $x + A = \big\{ x + a \mid a \in A \big\}$. A and x + A are Borel sets for all $x \in \mathbb{R}$ Then, if  is the Lebesgue measure on B , how can it be proven to be a translation invariant? So far all I have gotten is that  (A) =  ( x + A ), for all Borel sets A and for all $x \in \mathbb{R}$.",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
32,"Real Analysis, Folland Problem 5.3.29 The Baire Category Theorem","Real Analysis, Folland Problem 5.3.29 The Baire Category Theorem",,"The Baire Category Theorem - Let $X$ be a complete metric space a.) If $\{U_n\}_1^\infty$ is a sequence of open dense subsets of $X$, then $\bigcap_1^\infty U_n$ is dense in $X$. b.) $X$ is not a countable union of nowhere dense sets. The name for this theorem comes from Baire's terminology for sets: If $X$ is a topological space, a set $E\subset X$ if of the first category, or meager, according to Baire, if $E$ is a countable union of nowhere dense sets; otherwise $E$ is of the second category. Let $\mathscr{Y} = L^1(\mu)$ where $\mu$ is counting measure on $\mathbb{N}$, and let $\mathscr{X} = \{f\in \mathscr{Y}:\sum_{1}^{\infty}n|f(n)| < \infty \}$ equipped with the $L^1$ norm. a.) $X$ is a proper dense subset of $\mathscr{Y}$; hence $X$ is not complete. b.) Define $T:\mathscr{X}\rightarrow \mathscr{Y}$ by $Tf(n) = nf(n)$. Then $T$ is closed but not bounded. c.) Let $S = T^{-1}$. Then $S: \mathscr{Y}\rightarrow \mathscr{X}$ is bounded and surjective but not open. Proof of a.) Clearly $0\in \mathscr{X}$. If $f,g\in \mathscr{X}$ and $a\in K$ then $$\sum_{1}^{\infty}n|(f+ag)(n)| = \sum_{1}^{\infty}n|f(n) + ag(n)| \leq \sum_{1}^{\infty}n|f(n)| + \sum_{1}^{\infty}n|ag(n)| = \sum_{1}^{\infty}n|f(n)| + |a|\sum_{1}^{\infty}n|g(n)| < \infty$$ So $\mathscr{X}$ is a subspace of $\mathscr{Y}$. Since $\sum_{1}^{\infty}n^{-2}$ converges but $\sum_{1}^{\infty}n^{-1}$ does not, the map $n\rightarrow n^{-2}$ is in $\mathscr{Y}\setminus \mathscr{X}$. Let $f\in mathscr{Y}$ and $\epsilon\in (0,\infty)$. There exists $N\in\mathbb{N}$ such that $\sum_{n=N}^{\infty}|f(n)| < \epsilon$. It follows that $$\sum_{n=N}^{\infty}|f(n) - n^{-1}f(n)| = \sum_{n=N}^{\infty}(1 - n^{-1})|f(n)|\leq \sum_{n=N}^{\infty}|f(n)| < \epsilon$$ which implies that $\lVert f - g\rVert < \epsilon$, where $g\in \mathscr{X}$ is defined by $$g(n) := \begin{cases} f(n) & \text{if } n < N\\ n^{-1}f(n) & \text{if } n\geq N \end{cases}$$ This shows that $\mathscr{X}$ is a proper dense subset of $\mathscr{Y}$, so $\overline{\mathscr{X}} = \mathscr{Y}\neq \mathscr{X}$ and hence $\mathscr{X}$ is not complete. proof of b.) no idea proof of c.) Clearly $Sf(n) = n^{-1}f(n)$ for all $f\in \mathscr{Y}$ and $n\in \mathbb{N}$. It follows that $$\lVert S f\rVert = \sum_{1}^{\infty}|Sf(n)| = \sum_{1}^{\infty}|n^{-1}f(n)| = \sum_{1}^{\infty}n^{-1}|f(n)| \leq \sum_{1}^{\infty}|f(n)| = \lVert f\rVert$$ for all $f\in\mathscr{Y}$, so $S$ is bounded. Since $S = T^{-1}$, it is obvious that $S$ is surjective. If $S$ were open then $T$ would be continuous, which contradict b.). I know it may seem strange that I can prove a and c but not b but I am not exactly sure how to proceed with b, any suggestions is greatly appreciated.","The Baire Category Theorem - Let $X$ be a complete metric space a.) If $\{U_n\}_1^\infty$ is a sequence of open dense subsets of $X$, then $\bigcap_1^\infty U_n$ is dense in $X$. b.) $X$ is not a countable union of nowhere dense sets. The name for this theorem comes from Baire's terminology for sets: If $X$ is a topological space, a set $E\subset X$ if of the first category, or meager, according to Baire, if $E$ is a countable union of nowhere dense sets; otherwise $E$ is of the second category. Let $\mathscr{Y} = L^1(\mu)$ where $\mu$ is counting measure on $\mathbb{N}$, and let $\mathscr{X} = \{f\in \mathscr{Y}:\sum_{1}^{\infty}n|f(n)| < \infty \}$ equipped with the $L^1$ norm. a.) $X$ is a proper dense subset of $\mathscr{Y}$; hence $X$ is not complete. b.) Define $T:\mathscr{X}\rightarrow \mathscr{Y}$ by $Tf(n) = nf(n)$. Then $T$ is closed but not bounded. c.) Let $S = T^{-1}$. Then $S: \mathscr{Y}\rightarrow \mathscr{X}$ is bounded and surjective but not open. Proof of a.) Clearly $0\in \mathscr{X}$. If $f,g\in \mathscr{X}$ and $a\in K$ then $$\sum_{1}^{\infty}n|(f+ag)(n)| = \sum_{1}^{\infty}n|f(n) + ag(n)| \leq \sum_{1}^{\infty}n|f(n)| + \sum_{1}^{\infty}n|ag(n)| = \sum_{1}^{\infty}n|f(n)| + |a|\sum_{1}^{\infty}n|g(n)| < \infty$$ So $\mathscr{X}$ is a subspace of $\mathscr{Y}$. Since $\sum_{1}^{\infty}n^{-2}$ converges but $\sum_{1}^{\infty}n^{-1}$ does not, the map $n\rightarrow n^{-2}$ is in $\mathscr{Y}\setminus \mathscr{X}$. Let $f\in mathscr{Y}$ and $\epsilon\in (0,\infty)$. There exists $N\in\mathbb{N}$ such that $\sum_{n=N}^{\infty}|f(n)| < \epsilon$. It follows that $$\sum_{n=N}^{\infty}|f(n) - n^{-1}f(n)| = \sum_{n=N}^{\infty}(1 - n^{-1})|f(n)|\leq \sum_{n=N}^{\infty}|f(n)| < \epsilon$$ which implies that $\lVert f - g\rVert < \epsilon$, where $g\in \mathscr{X}$ is defined by $$g(n) := \begin{cases} f(n) & \text{if } n < N\\ n^{-1}f(n) & \text{if } n\geq N \end{cases}$$ This shows that $\mathscr{X}$ is a proper dense subset of $\mathscr{Y}$, so $\overline{\mathscr{X}} = \mathscr{Y}\neq \mathscr{X}$ and hence $\mathscr{X}$ is not complete. proof of b.) no idea proof of c.) Clearly $Sf(n) = n^{-1}f(n)$ for all $f\in \mathscr{Y}$ and $n\in \mathbb{N}$. It follows that $$\lVert S f\rVert = \sum_{1}^{\infty}|Sf(n)| = \sum_{1}^{\infty}|n^{-1}f(n)| = \sum_{1}^{\infty}n^{-1}|f(n)| \leq \sum_{1}^{\infty}|f(n)| = \lVert f\rVert$$ for all $f\in\mathscr{Y}$, so $S$ is bounded. Since $S = T^{-1}$, it is obvious that $S$ is surjective. If $S$ were open then $T$ would be continuous, which contradict b.). I know it may seem strange that I can prove a and c but not b but I am not exactly sure how to proceed with b, any suggestions is greatly appreciated.",,"['real-analysis', 'measure-theory']"
33,"Given measure, show that countable additivity implies countable subadditivity [duplicate]","Given measure, show that countable additivity implies countable subadditivity [duplicate]",,"This question already has an answer here : Countable additivity implies countable subadditivity? (1 answer) Closed 8 years ago . Let $m: \Sigma \mapsto \mathbb{R}_{\geq0}$, then I wish to show that $$m(\bigsqcup_{j = 1}^\infty A_j) = \sum\limits_{j=1}^\infty m(A_j) \implies m(\bigcup_{j = 1}^\infty A_j) \leq \sum\limits_{j=1}^\infty m(A_j)$$ Where ($\bigsqcup$ emphasizes disjoint union) (There is another post addressing this but it is neither instructive nor clear) Approach: Break things into disjoint unions $\displaystyle{\bigcup_{j = 1}^\infty A_j = \bigsqcup_{j=1}^\infty A_j \backslash (A_1\cup \ldots \cup A_{j-1}) = \bigsqcup_{j=1}^\infty A_j \cap (A_1\cup \ldots \cup A_{j-1})^c = A_1 \sqcup A_2 \cap A_1^c \sqcup A^3 \cap A_1^c \cap A_2^c \sqcup \ldots}$ Take measure of both sides $\displaystyle{m(\bigcup_{j = 1}^\infty A_j ) = m(A_1) + m( A_2 \cap A_1^c) + m( A^3 \cap A_1^c \cap A_2^c) + \ldots}$ At this point what can I do to conclude $$m(\bigcup_{j = 1}^\infty A_j) \leq \sum\limits_{j=1}^\infty m(A_j)?$$","This question already has an answer here : Countable additivity implies countable subadditivity? (1 answer) Closed 8 years ago . Let $m: \Sigma \mapsto \mathbb{R}_{\geq0}$, then I wish to show that $$m(\bigsqcup_{j = 1}^\infty A_j) = \sum\limits_{j=1}^\infty m(A_j) \implies m(\bigcup_{j = 1}^\infty A_j) \leq \sum\limits_{j=1}^\infty m(A_j)$$ Where ($\bigsqcup$ emphasizes disjoint union) (There is another post addressing this but it is neither instructive nor clear) Approach: Break things into disjoint unions $\displaystyle{\bigcup_{j = 1}^\infty A_j = \bigsqcup_{j=1}^\infty A_j \backslash (A_1\cup \ldots \cup A_{j-1}) = \bigsqcup_{j=1}^\infty A_j \cap (A_1\cup \ldots \cup A_{j-1})^c = A_1 \sqcup A_2 \cap A_1^c \sqcup A^3 \cap A_1^c \cap A_2^c \sqcup \ldots}$ Take measure of both sides $\displaystyle{m(\bigcup_{j = 1}^\infty A_j ) = m(A_1) + m( A_2 \cap A_1^c) + m( A^3 \cap A_1^c \cap A_2^c) + \ldots}$ At this point what can I do to conclude $$m(\bigcup_{j = 1}^\infty A_j) \leq \sum\limits_{j=1}^\infty m(A_j)?$$",,"['measure-theory', 'elementary-set-theory', 'proof-verification', 'lebesgue-measure']"
34,"Find $H\subset [0,1]$ of class $F_\sigma$",Find  of class,"H\subset [0,1] F_\sigma","Find $H\subset [0,1]$ of class $F_\sigma$ such that $m(H)=1$ and $H\cap\mathbb{Q}=\varnothing$. Here, $m(H)$ is the Lebesgue's measure. Any idea? Thanks!","Find $H\subset [0,1]$ of class $F_\sigma$ such that $m(H)=1$ and $H\cap\mathbb{Q}=\varnothing$. Here, $m(H)$ is the Lebesgue's measure. Any idea? Thanks!",,"['measure-theory', 'elementary-set-theory', 'lebesgue-measure', 'descriptive-set-theory']"
35,"prove $\mathscr{g}$ $\subset$ $\mathscr{g}_\delta$, a basic rule given in Measure Theory 2nd Edition written by Donald L. Cohn","prove   , a basic rule given in Measure Theory 2nd Edition written by Donald L. Cohn",\mathscr{g} \subset \mathscr{g}_\delta,"1, Let $\mathscr{g}$ be the family of all open subsets of $\mathbb{R}^d$ 2, Let $\mathscr{g}_\delta$ be the collection of all intersections of sequences of sets in $\mathscr{g}$ 3, And given that each closed subset of $\mathbb{R}^d$ is in $\mathscr{g}_\delta$ Then to prove $\mathscr{g}$ $\subset$ $\mathscr{g}_\delta$, and $\mathscr{g}_\delta$ $\subset$ $\mathscr{g}_{\delta\sigma}$ This is a rule I think is very basic in measure theory, It is given in the Proposition 1.1.6 of Measure Theory 2nd Edition written by Donald L. Cohn , however the book did not give a detail proof. As I think, because of line 3, then $\mathscr{g}_\delta$ contains all closed subsets of $\mathbb{R}^d$, then, if $\mathscr{g}$ $\subset$ $\mathscr{g}_\delta$, means $\mathscr{g}_\delta$ must also contain all open subsets of $\mathbb{R}^d$ because $\mathscr{g}$ contains all open subsets. If this is right, how could it be possible that $\mathscr{g}_{\delta\sigma}$ contains some additional subset of $\mathscr{R}^d$ that are not in $\mathscr{g}_\delta$ ?","1, Let $\mathscr{g}$ be the family of all open subsets of $\mathbb{R}^d$ 2, Let $\mathscr{g}_\delta$ be the collection of all intersections of sequences of sets in $\mathscr{g}$ 3, And given that each closed subset of $\mathbb{R}^d$ is in $\mathscr{g}_\delta$ Then to prove $\mathscr{g}$ $\subset$ $\mathscr{g}_\delta$, and $\mathscr{g}_\delta$ $\subset$ $\mathscr{g}_{\delta\sigma}$ This is a rule I think is very basic in measure theory, It is given in the Proposition 1.1.6 of Measure Theory 2nd Edition written by Donald L. Cohn , however the book did not give a detail proof. As I think, because of line 3, then $\mathscr{g}_\delta$ contains all closed subsets of $\mathbb{R}^d$, then, if $\mathscr{g}$ $\subset$ $\mathscr{g}_\delta$, means $\mathscr{g}_\delta$ must also contain all open subsets of $\mathbb{R}^d$ because $\mathscr{g}$ contains all open subsets. If this is right, how could it be possible that $\mathscr{g}_{\delta\sigma}$ contains some additional subset of $\mathscr{R}^d$ that are not in $\mathscr{g}_\delta$ ?",,['measure-theory']
36,"Measure theory problem involving metric density function $\rho(E, x)$",Measure theory problem involving metric density function,"\rho(E, x)","Working on the real line $(\mathbb{R})$, let $\mu : \mathscr{M} \rightarrow [0, +\infty]$ represent the Lebesgue measure ($\mathscr{M}$ is the set of measurable subsets of $\mathbb{R}$). For $E \in \mathscr{M}$ and $x \in \mathbb{R}$, we define $$\rho(E, x) = \lim_{\delta \to 0+} \frac{\mu(E \cap (x - \delta, x + \delta))}{2\delta},$$ if the limit exists. The above limit is called the metric density of $E$ at $x$. $(1)$ Given $E=(1,2)\cup(2,5]\cup\{6\}$, find the metric density of $E$ for all $x \in E$. $(2)$ Let $\alpha \in (0, 1)$. Construct a set $E\subset\mathbb{R}$ such that $\rho(E, 0) = \alpha$. My work and thoughts: $(1)$ Since $x$ can be any real number, the intersection $E \cap (x - \delta, x + \delta)$ can be empty. Also, if $(x - \delta, x + \delta) \subset E$, as $\delta \rightarrow 0+$ the intersection $E \cap (x - \delta, x + \delta) = x$. In either case the measure equals zero. Is this correct? For $(2)$ I have no idea.","Working on the real line $(\mathbb{R})$, let $\mu : \mathscr{M} \rightarrow [0, +\infty]$ represent the Lebesgue measure ($\mathscr{M}$ is the set of measurable subsets of $\mathbb{R}$). For $E \in \mathscr{M}$ and $x \in \mathbb{R}$, we define $$\rho(E, x) = \lim_{\delta \to 0+} \frac{\mu(E \cap (x - \delta, x + \delta))}{2\delta},$$ if the limit exists. The above limit is called the metric density of $E$ at $x$. $(1)$ Given $E=(1,2)\cup(2,5]\cup\{6\}$, find the metric density of $E$ for all $x \in E$. $(2)$ Let $\alpha \in (0, 1)$. Construct a set $E\subset\mathbb{R}$ such that $\rho(E, 0) = \alpha$. My work and thoughts: $(1)$ Since $x$ can be any real number, the intersection $E \cap (x - \delta, x + \delta)$ can be empty. Also, if $(x - \delta, x + \delta) \subset E$, as $\delta \rightarrow 0+$ the intersection $E \cap (x - \delta, x + \delta) = x$. In either case the measure equals zero. Is this correct? For $(2)$ I have no idea.",,"['real-analysis', 'measure-theory', 'proof-verification', 'lebesgue-measure']"
37,completion of a $\sigma$- algebra,completion of a - algebra,\sigma,"Let $(X,\textbf{X}, \mu)$ be a measure space, $\textbf{Z}=\{E\in \textbf{X}: \mu(E)=0\}$ and let $\textbf{X}'$ be the family of all subsets of $X$ of the form $(E\cup Z_1)-Z_2$, where $E\in \textbf{X}$, $Z_1$ and $Z_2$ are arbitrary subsets of sets belonging to $\textbf{Z}$. Show that a set is in $\textbf{X}'$ if and only if it has the form $E\cup Z$ where $E\in \textbf{X}$ and $Z$ is a subset of a set in $\textbf{Z}$. proof: Let $N=\{E\subseteq X: \exists M\in \textbf{Z}, E\subseteq M\}$. Suppose that $F\in \textbf{X}'$  then $F=(E\cup Z_1)-Z_2$, where $E\in \textbf{X}$ and $Z_1,Z_2 \in N$. Thus $F=(E-Z_2)\cup (Z_1-Z_2)$ I know that $Z_1-Z_2=Z_3\in N$ but I don't know why $E-Z_2\in \textbf{X}$.","Let $(X,\textbf{X}, \mu)$ be a measure space, $\textbf{Z}=\{E\in \textbf{X}: \mu(E)=0\}$ and let $\textbf{X}'$ be the family of all subsets of $X$ of the form $(E\cup Z_1)-Z_2$, where $E\in \textbf{X}$, $Z_1$ and $Z_2$ are arbitrary subsets of sets belonging to $\textbf{Z}$. Show that a set is in $\textbf{X}'$ if and only if it has the form $E\cup Z$ where $E\in \textbf{X}$ and $Z$ is a subset of a set in $\textbf{Z}$. proof: Let $N=\{E\subseteq X: \exists M\in \textbf{Z}, E\subseteq M\}$. Suppose that $F\in \textbf{X}'$  then $F=(E\cup Z_1)-Z_2$, where $E\in \textbf{X}$ and $Z_1,Z_2 \in N$. Thus $F=(E-Z_2)\cup (Z_1-Z_2)$ I know that $Z_1-Z_2=Z_3\in N$ but I don't know why $E-Z_2\in \textbf{X}$.",,['measure-theory']
38,Optimal Transport PDE formulation,Optimal Transport PDE formulation,,"Let $M^{\pm}$ be Polish spaces and $\mu^{\pm}$ be Borel probability measures on $M^+$ and $M^-$ respectively. If $G: M^+ \rightarrow M^-$ with the constraint $G_\#\mu^+ = \mu^-$, why does the following follow: ""Lets consider the constraint $G_\#\mu^+ = \mu^-$, assuming moreover that $\mu^{\pm} = f^{\pm}dVol^{\pm}$ on $\mathbb{R}^n$ or on Riemannian manifolds $M^{\pm}$. Then if $\phi \in C(M^-)$ is a test function, it follows that $$ \int_{M^+} \phi(G(x))f^+(x)dVol^+(x) = \int_{M^-} \phi(y)f^-(y)dVol^-(y).""$$ I've not come across test functions before so this isn't following for me. Many thanks. (Link: page 2:4 )","Let $M^{\pm}$ be Polish spaces and $\mu^{\pm}$ be Borel probability measures on $M^+$ and $M^-$ respectively. If $G: M^+ \rightarrow M^-$ with the constraint $G_\#\mu^+ = \mu^-$, why does the following follow: ""Lets consider the constraint $G_\#\mu^+ = \mu^-$, assuming moreover that $\mu^{\pm} = f^{\pm}dVol^{\pm}$ on $\mathbb{R}^n$ or on Riemannian manifolds $M^{\pm}$. Then if $\phi \in C(M^-)$ is a test function, it follows that $$ \int_{M^+} \phi(G(x))f^+(x)dVol^+(x) = \int_{M^-} \phi(y)f^-(y)dVol^-(y).""$$ I've not come across test functions before so this isn't following for me. Many thanks. (Link: page 2:4 )",,"['probability', 'measure-theory', 'partial-differential-equations', 'optimization', 'optimal-transport']"
39,A Lebesgue measure condition,A Lebesgue measure condition,,"Suppose that $\{B(x_j,r_j)\}_{j=1}^{n}$ is a finite collection of balls in $\mathbb{R}^d$. Show that there is a subcollection $\{B(x_{j_k},r_{j_k})\}_{k=1}^{l}$ of pairwise disjoint balls such that $$m\left(\bigcup_{k=1}^{l}B(x_{j_k},r_{j_k})\right) \geq 3^{-d} m\left(\bigcup_{j=1}^{n}B(x_{j},r_{j})\right)$$ where $m$ denotes Lebesgue measure. I want to constrain this problem by attempting to not trivialize it by applying a covering lemma. Attempted proof: Suppose that $\{B(x_j,r_j)\}_{j=1}^{n}$ is a finite collection of balls in $\mathbb{R}^d$ such that $$\{B(x_j,r_j)\}_{j=1}^{n} \rightarrow \{B(x,r)\} \ \ \text{as} \ \ n\rightarrow \infty$$ Then there exists a subsequence of balls $\{B(x_{j_k},r_{j_k})\}_{j=1}^{n}$ such that $$\{B(x_{j_k},r_{j_k})\}_{j=1}^{n}\rightarrow \{B(x,r)\} \ \ \text{as} \ \ n,k\rightarrow \infty $$ Let $\delta = 3^{d}$, then choose an $x_{j_k},r_{j_k}$ such that $$|x_{j_k} - r_{j_k}| \leq \frac{(b - a)}{\delta}$$ where the subsequence $\{B(x_{j_k},r_{j_k})\}$ lies in the interval $[a,b]$. Then let $$A = \bigcup_{1}^{l}B(x_{j_k},r_{j_k})$$ Since $\{B(x_{j_k},r_{j_k})\}$ is convergent and bounded, taking the Lebesgue measure it follows that $$m\left(\bigcup_{k=1}^{l}B(x_{j_k},r_{j_k})\right) \geq 3^{-d} m\left(\bigcup_{k=1}^{l}B(x_{j},r_{j})\right)$$ I am not sure if we can have balls just on some interval $[a,b]$ but I figured they could be on some place in $\mathbb{R}^d$. I am not sure if I can just conclude with that if I know it is convergent and bounded. Any suggestions is greatly appreciated.","Suppose that $\{B(x_j,r_j)\}_{j=1}^{n}$ is a finite collection of balls in $\mathbb{R}^d$. Show that there is a subcollection $\{B(x_{j_k},r_{j_k})\}_{k=1}^{l}$ of pairwise disjoint balls such that $$m\left(\bigcup_{k=1}^{l}B(x_{j_k},r_{j_k})\right) \geq 3^{-d} m\left(\bigcup_{j=1}^{n}B(x_{j},r_{j})\right)$$ where $m$ denotes Lebesgue measure. I want to constrain this problem by attempting to not trivialize it by applying a covering lemma. Attempted proof: Suppose that $\{B(x_j,r_j)\}_{j=1}^{n}$ is a finite collection of balls in $\mathbb{R}^d$ such that $$\{B(x_j,r_j)\}_{j=1}^{n} \rightarrow \{B(x,r)\} \ \ \text{as} \ \ n\rightarrow \infty$$ Then there exists a subsequence of balls $\{B(x_{j_k},r_{j_k})\}_{j=1}^{n}$ such that $$\{B(x_{j_k},r_{j_k})\}_{j=1}^{n}\rightarrow \{B(x,r)\} \ \ \text{as} \ \ n,k\rightarrow \infty $$ Let $\delta = 3^{d}$, then choose an $x_{j_k},r_{j_k}$ such that $$|x_{j_k} - r_{j_k}| \leq \frac{(b - a)}{\delta}$$ where the subsequence $\{B(x_{j_k},r_{j_k})\}$ lies in the interval $[a,b]$. Then let $$A = \bigcup_{1}^{l}B(x_{j_k},r_{j_k})$$ Since $\{B(x_{j_k},r_{j_k})\}$ is convergent and bounded, taking the Lebesgue measure it follows that $$m\left(\bigcup_{k=1}^{l}B(x_{j_k},r_{j_k})\right) \geq 3^{-d} m\left(\bigcup_{k=1}^{l}B(x_{j},r_{j})\right)$$ I am not sure if we can have balls just on some interval $[a,b]$ but I figured they could be on some place in $\mathbb{R}^d$. I am not sure if I can just conclude with that if I know it is convergent and bounded. Any suggestions is greatly appreciated.",,"['real-analysis', 'measure-theory']"
40,If $\mu(A)<\delta$ then $\sup_{f\in\mathcal{F}}\int_A|f|d\mu<\epsilon$,If  then,\mu(A)<\delta \sup_{f\in\mathcal{F}}\int_A|f|d\mu<\epsilon,"Let $(X,\Sigma,\mu)$ be a finite measure space. Let $\mathcal{F}$ be a family of measurable functions $f:X\to\mathbb{R}$ . Prove that if $$\lim_{t\to\infty}\left(\sup_{f\in\mathcal{F}}\int_{\{x\in X:|f(x)|\ge t\}}|f|d\mu \right)=0,$$ then $$\sup_{f\in\mathcal{F}}\int_X|f|d\mu<\infty,$$ and for all $\epsilon >0$ there exists $\delta >0$ such that: $$A\in\Sigma,\mu(A)<\delta\Longrightarrow \sup_{f\in\mathcal{F}}\int_A|f|d\mu<\epsilon.$$ For the first part. Let $t>0$ such that: $\displaystyle\sup_{f\in\mathcal{F}}\int_{\{x\in X:|f(x)|\ge t\}}|f|d\mu<1$ . Fix $f\in\mathcal{F}$ . Then $$\displaystyle\int_X|f|d\mu=\int_{\{|f|\ge t\}}|f|d\mu+\int_{\{|f|<t\}}|f|d\mu\le 1+t\mu(X)<\infty.$$ And $1+t\mu(X)$ does not depend of $f$ , so we get $\sup_{f\in\mathcal{F}}\int_X|f|d\mu<\infty$ . Is that correct? I don't know how to do the second part. Could it be true that $v(A):=\sup_{f\in\mathcal{F}}\int_A|f|d\mu$ is a finite measure? I wanted to try something similar to that known result when $\mathcal{F}$ is just one function (some call it absolutely continuous of the measure $v$ , I think). Any hint? Thank you.","Let be a finite measure space. Let be a family of measurable functions . Prove that if then and for all there exists such that: For the first part. Let such that: . Fix . Then And does not depend of , so we get . Is that correct? I don't know how to do the second part. Could it be true that is a finite measure? I wanted to try something similar to that known result when is just one function (some call it absolutely continuous of the measure , I think). Any hint? Thank you.","(X,\Sigma,\mu) \mathcal{F} f:X\to\mathbb{R} \lim_{t\to\infty}\left(\sup_{f\in\mathcal{F}}\int_{\{x\in X:|f(x)|\ge t\}}|f|d\mu \right)=0, \sup_{f\in\mathcal{F}}\int_X|f|d\mu<\infty, \epsilon >0 \delta >0 A\in\Sigma,\mu(A)<\delta\Longrightarrow \sup_{f\in\mathcal{F}}\int_A|f|d\mu<\epsilon. t>0 \displaystyle\sup_{f\in\mathcal{F}}\int_{\{x\in X:|f(x)|\ge t\}}|f|d\mu<1 f\in\mathcal{F} \displaystyle\int_X|f|d\mu=\int_{\{|f|\ge t\}}|f|d\mu+\int_{\{|f|<t\}}|f|d\mu\le 1+t\mu(X)<\infty. 1+t\mu(X) f \sup_{f\in\mathcal{F}}\int_X|f|d\mu<\infty v(A):=\sup_{f\in\mathcal{F}}\int_A|f|d\mu \mathcal{F} v",['measure-theory']
41,Probability density function: what's a measure $X_*P$?,Probability density function: what's a measure ?,X_*P,"The Wikipedia article on PDFs defines the probability distribution of a random variable $X$ in $(\mathcal{X},\mathcal{A})$ to be the measure $X_*P$ on $(\mathcal{X},\mathcal{A})$. I understand what a measure is, but what does the notation $X_*P$ mean? Also, the article then gives the equality $\int\limits_{X^{-1}A}dP=\int\limits_{A}fd\mu$ where $f=\frac{dX_*P}{d\mu}$. How did $dX_*P$ become $dP$, what what's the relation between $X_*$ and $X^{-1}$? What does it even mean to take the inverse of a variable?","The Wikipedia article on PDFs defines the probability distribution of a random variable $X$ in $(\mathcal{X},\mathcal{A})$ to be the measure $X_*P$ on $(\mathcal{X},\mathcal{A})$. I understand what a measure is, but what does the notation $X_*P$ mean? Also, the article then gives the equality $\int\limits_{X^{-1}A}dP=\int\limits_{A}fd\mu$ where $f=\frac{dX_*P}{d\mu}$. How did $dX_*P$ become $dP$, what what's the relation between $X_*$ and $X^{-1}$? What does it even mean to take the inverse of a variable?",,"['measure-theory', 'statistics', 'probability-distributions']"
42,"Lebesgue integral, Cavalieri's principle","Lebesgue integral, Cavalieri's principle",,"Merry Christmas, Can you prove my answer: Let $B_r^n (p):=\{x\in\mathbb R^n \mid |x-p|\le r\}$  be the Ball with radius $r\in\mathbb R_{+}$ and origin $p\in\mathbb R$ and dimension $n\in\mathbb N$. Evaluate $\lambda_3(B_1^3(0)\cap(B_r^2(0)\times\mathbb R))$, when $r\in (0,1)$ Answer: I evalute the internal term: $$B_1^3(0)\cap(B_r^2(0)\times\mathbb R) =\{(x,y,z)\in\mathbb R^3\mid x^2+y^2+z^2\le 1;x,y,z\in (-1,0)\cup (0,1)\}$$ And with the Principle of Cavalieri, I get following integral: $$\int_{-1}^1 \int_{-1}^1 \int_{-\sqrt{1-x^2-z^2}}^{\sqrt{1-x^2-z^2}} \, dy \, dx \, dz=\frac{4}{3}\pi$$ Do you agree?","Merry Christmas, Can you prove my answer: Let $B_r^n (p):=\{x\in\mathbb R^n \mid |x-p|\le r\}$  be the Ball with radius $r\in\mathbb R_{+}$ and origin $p\in\mathbb R$ and dimension $n\in\mathbb N$. Evaluate $\lambda_3(B_1^3(0)\cap(B_r^2(0)\times\mathbb R))$, when $r\in (0,1)$ Answer: I evalute the internal term: $$B_1^3(0)\cap(B_r^2(0)\times\mathbb R) =\{(x,y,z)\in\mathbb R^3\mid x^2+y^2+z^2\le 1;x,y,z\in (-1,0)\cup (0,1)\}$$ And with the Principle of Cavalieri, I get following integral: $$\int_{-1}^1 \int_{-1}^1 \int_{-\sqrt{1-x^2-z^2}}^{\sqrt{1-x^2-z^2}} \, dy \, dx \, dz=\frac{4}{3}\pi$$ Do you agree?",,"['real-analysis', 'measure-theory', 'lebesgue-integral']"
43,Union of neighborhoods of measurable set is measurable.,Union of neighborhoods of measurable set is measurable.,,"If $E\subseteq\mathbb{R}$ is Lebesgue measurable, show that $$F=\bigcup_{x\in E}[x-1,x+1]$$ is also Lebesgue measurable. My solution: the 'distance to E' function $$\rho(x) = \inf\limits_{y\in E}|x-y|$$ is continuous and therefore measurable, hence $\rho^{-1}([0,1))$ is measurable. The remaining points in $F$ (those with $\rho(x) = 1$) form a set of measure zero, because they are isolated. I am looking for alternative solutions and, of course, any corrections to my solution.","If $E\subseteq\mathbb{R}$ is Lebesgue measurable, show that $$F=\bigcup_{x\in E}[x-1,x+1]$$ is also Lebesgue measurable. My solution: the 'distance to E' function $$\rho(x) = \inf\limits_{y\in E}|x-y|$$ is continuous and therefore measurable, hence $\rho^{-1}([0,1))$ is measurable. The remaining points in $F$ (those with $\rho(x) = 1$) form a set of measure zero, because they are isolated. I am looking for alternative solutions and, of course, any corrections to my solution.",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
44,Why $\nu(E)=\int_E fd\mu$ is a signed measure.,Why  is a signed measure.,\nu(E)=\int_E fd\mu,"I don't understand a concept. A signed measure $\nu$ on a $\sigma -$\algebra is a mapping that satisfy 1) The set function $\nu$ is extended valued in the sense that $-\infty <\nu(E)\leq \infty $ for all $E\in\mathcal M$. 2) If $\{E_i\}_i$ are disjoint subset of $\mathcal M$, then $$\nu\left(\bigcup_{i=1}^\infty E_i\right)=\sum_{i=1}^\infty \nu(E_j).$$ Example If $f\geq 0$ and $f$ is $\mu-$measurable, then $$\nu(E)=\int_E f d\mu$$ where $(X,\mathcal M,\mu)$ is a measure space is a signed measure. Question How can $\int_E fd\mu <0$ if $f\geq 0$ ?","I don't understand a concept. A signed measure $\nu$ on a $\sigma -$\algebra is a mapping that satisfy 1) The set function $\nu$ is extended valued in the sense that $-\infty <\nu(E)\leq \infty $ for all $E\in\mathcal M$. 2) If $\{E_i\}_i$ are disjoint subset of $\mathcal M$, then $$\nu\left(\bigcup_{i=1}^\infty E_i\right)=\sum_{i=1}^\infty \nu(E_j).$$ Example If $f\geq 0$ and $f$ is $\mu-$measurable, then $$\nu(E)=\int_E f d\mu$$ where $(X,\mathcal M,\mu)$ is a measure space is a signed measure. Question How can $\int_E fd\mu <0$ if $f\geq 0$ ?",,['measure-theory']
45,Dominated convergence with $g$ depending on $n$,Dominated convergence with  depending on,g n,"I have a question about dominated convergence. Suppose I have a functions $f_n(x)$ which converge pointwise to $f(x)$. Furthermore, I know that $|f_n(x)|\leq g_n(x)$ for all $n$ and $x$, where $g_n(x)$ has limit $g(x)$.  If I also know that  $$\lim_{n\to\infty}\int g_n(x)dx=\int g(x)dx,$$ can I conclude that  $$\lim_{n\to\infty}\int f_n(x)dx=\int f(x)dx?$$ (This is basically the dominated convergence theorem, with $g$ replaced by $g_n$.)","I have a question about dominated convergence. Suppose I have a functions $f_n(x)$ which converge pointwise to $f(x)$. Furthermore, I know that $|f_n(x)|\leq g_n(x)$ for all $n$ and $x$, where $g_n(x)$ has limit $g(x)$.  If I also know that  $$\lim_{n\to\infty}\int g_n(x)dx=\int g(x)dx,$$ can I conclude that  $$\lim_{n\to\infty}\int f_n(x)dx=\int f(x)dx?$$ (This is basically the dominated convergence theorem, with $g$ replaced by $g_n$.)",,"['integration', 'measure-theory', 'convergence-divergence']"
46,Set of finite outer measure is contained in an open set of finite measure?,Set of finite outer measure is contained in an open set of finite measure?,,"In a proof I'm reading, the author remarks in the first line of the proof, with no justification whatsoever, that a set of finite outer measure is contained in an open set of finite measure. I have spent some time thinking about this and it is not obvious to me that this is the case. Can someone please explain why this should be obvious? Thank you.","In a proof I'm reading, the author remarks in the first line of the proof, with no justification whatsoever, that a set of finite outer measure is contained in an open set of finite measure. I have spent some time thinking about this and it is not obvious to me that this is the case. Can someone please explain why this should be obvious? Thank you.",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
47,Counting measure on the power set of N,Counting measure on the power set of N,,"I need to define a sequence of functions that converge to $f$ so that I can use the monotone convergence theorem to prove. Not sure how to define the sequence of functions. $$\int_{\mathbb{N}} f\,\text{d}\mu = \sum_{n=1}^\infty f(n)$$","I need to define a sequence of functions that converge to $f$ so that I can use the monotone convergence theorem to prove. Not sure how to define the sequence of functions. $$\int_{\mathbb{N}} f\,\text{d}\mu = \sum_{n=1}^\infty f(n)$$",,['measure-theory']
48,"Consider stopping times $S$ and $T$ for a filtration $(\mathcal{F}_n)$. Show that $\mathcal{F}_{\min(S,T)} = \mathcal{F}_{S}\cap \mathcal{F}_{T}$.",Consider stopping times  and  for a filtration . Show that .,"S T (\mathcal{F}_n) \mathcal{F}_{\min(S,T)} = \mathcal{F}_{S}\cap \mathcal{F}_{T}","I'm trying to solve this question but my argument works for $\mathcal{F}_{\max(S,T)} = \mathcal{F}_{S}\cap \mathcal{F}_{T}$. I'm wondering if anyone can confirm if this question is a typo and should be asking for $\max(S,T)$ instead of $\min(S,T)$.","I'm trying to solve this question but my argument works for $\mathcal{F}_{\max(S,T)} = \mathcal{F}_{S}\cap \mathcal{F}_{T}$. I'm wondering if anyone can confirm if this question is a typo and should be asking for $\max(S,T)$ instead of $\min(S,T)$.",,"['measure-theory', 'stopping-times']"
49,Prove that bounded $p$-norms and convergence a.e implies convergence in $L^1$,Prove that bounded -norms and convergence a.e implies convergence in,p L^1,"Suppose $\mu\left(X\right) < \infty$, $f_n \rightarrow f$ a.e and $p > 1$ is such that for some constant $C>0$, we have  $$ \|f_n\|_p \leq C,\ \ \text{for each} \ n $$ Prove that $f_n \rightarrow f$ in $L^1$. My attempt: I am trying to prove that $f_n \rightarrow f$ in $L^p$. Then the result is obvious from Holder's inequality. I am unable to use the given condition that $p$-norms are bounded. I need to apply Dominated convergence theorem, but I'm unable to see it.","Suppose $\mu\left(X\right) < \infty$, $f_n \rightarrow f$ a.e and $p > 1$ is such that for some constant $C>0$, we have  $$ \|f_n\|_p \leq C,\ \ \text{for each} \ n $$ Prove that $f_n \rightarrow f$ in $L^1$. My attempt: I am trying to prove that $f_n \rightarrow f$ in $L^p$. Then the result is obvious from Holder's inequality. I am unable to use the given condition that $p$-norms are bounded. I need to apply Dominated convergence theorem, but I'm unable to see it.",,['measure-theory']
50,A continuous function defined by Lebesgue measure,A continuous function defined by Lebesgue measure,,"Let $A,B\in\mathcal A_{\Bbb R}^*$ given with $\overline{\lambda}(A)<\infty$ and $\overline{\lambda}(B)<\infty$. Lets define $\; \overline{\lambda}_{A,B}:\Bbb R\to\Bbb R$ as follows: $$\overline{\lambda}_{A,B}(x)=\overline{\lambda}(A\cap(B+x))$$ where $B+x=\{b+x:b\in B\}$. So what I want to prove is that $\overline{\lambda}_{A,B}$ is continuous. Proof: Let $c\in\Bbb R$ fixed and let $x_n=c-\frac{1}{n}\;\forall n\in\Bbb N$. Clearly $x_n\in\Bbb R\;\forall n\in\Bbb N$. Then, let $B_n=B+x_n\;\forall n\in\Bbb N\Rightarrow\ B_n=\{b+c-\frac{1}{n}:b\in B\}\;\forall n\in\Bbb N$ Lemma 1 : $$B_n\subseteq B_{n+1}\;\forall n\in\Bbb N$$ Let $y\in B_n\Rightarrow\ y=b+c-\frac{1}{n}=b+c-\big(\frac{1}{n(n+1)}+\frac{1}{n+1}\big)=b+c-\frac{1}{n(n+1)}-\frac{1}{n+1}\;\forall n\in\Bbb N$. Thus $ y=b+c'-\frac{1}{n+1}\;\forall n\in\Bbb N$ with $c'=c-\frac{1}{n(n+1)}\Rightarrow\ y\in B_{n+1}$. Lemma 2 : $$\lim_{n\to\infty}(A\cap B_n)=A\cap (B+c)$$ Since $B_n\subseteq B_{n+1}\;\forall n\in\Bbb N$ by Lemma 1, the limit of $(B_n)_{n\in\Bbb N}$ exists and $\lim_{n\to\infty}(B_n)=\bigcup_{n=1}^\infty B_n,\ $but $\bigcup_{n=1}^\infty B_n=\bigcup_{n=1}^\infty \{b+c-\frac{1}{n}:b\in B\}=\{b+c:b\in B\}=B+c$. Now, clearly $A\cap B_n\subseteq A\cap B_{n+1}\;\forall n\in\Bbb N\Rightarrow\ \lim_{n\to\infty}(A\cap B_n)=\bigcup_{n=1}^\infty (A\cap B_n)=A\cap\bigcup_{n=1}^\infty B_n=A\cap (B+c)$. So by Lemma 2 we get that: $$\lim_{n\to\infty}\overline{\lambda}_{A,B}(x_n)=\lim_{n\to\infty}\overline{\lambda}(A\cap(B+x_n))=\lim_{n\to\infty}\overline{\lambda}(A\cap B_n)=\overline{\lambda}\big(\lim_{n\to\infty}(A\cap B_n)\big)=\overline{\lambda}(A\cap (B+c))=\overline{\lambda}_{A,B}(c)$$ And clearly $\lim_{n\to\infty}x_n=c$, thus $\overline{\lambda}_{A,B}$ is continuous. Did I miss something?","Let $A,B\in\mathcal A_{\Bbb R}^*$ given with $\overline{\lambda}(A)<\infty$ and $\overline{\lambda}(B)<\infty$. Lets define $\; \overline{\lambda}_{A,B}:\Bbb R\to\Bbb R$ as follows: $$\overline{\lambda}_{A,B}(x)=\overline{\lambda}(A\cap(B+x))$$ where $B+x=\{b+x:b\in B\}$. So what I want to prove is that $\overline{\lambda}_{A,B}$ is continuous. Proof: Let $c\in\Bbb R$ fixed and let $x_n=c-\frac{1}{n}\;\forall n\in\Bbb N$. Clearly $x_n\in\Bbb R\;\forall n\in\Bbb N$. Then, let $B_n=B+x_n\;\forall n\in\Bbb N\Rightarrow\ B_n=\{b+c-\frac{1}{n}:b\in B\}\;\forall n\in\Bbb N$ Lemma 1 : $$B_n\subseteq B_{n+1}\;\forall n\in\Bbb N$$ Let $y\in B_n\Rightarrow\ y=b+c-\frac{1}{n}=b+c-\big(\frac{1}{n(n+1)}+\frac{1}{n+1}\big)=b+c-\frac{1}{n(n+1)}-\frac{1}{n+1}\;\forall n\in\Bbb N$. Thus $ y=b+c'-\frac{1}{n+1}\;\forall n\in\Bbb N$ with $c'=c-\frac{1}{n(n+1)}\Rightarrow\ y\in B_{n+1}$. Lemma 2 : $$\lim_{n\to\infty}(A\cap B_n)=A\cap (B+c)$$ Since $B_n\subseteq B_{n+1}\;\forall n\in\Bbb N$ by Lemma 1, the limit of $(B_n)_{n\in\Bbb N}$ exists and $\lim_{n\to\infty}(B_n)=\bigcup_{n=1}^\infty B_n,\ $but $\bigcup_{n=1}^\infty B_n=\bigcup_{n=1}^\infty \{b+c-\frac{1}{n}:b\in B\}=\{b+c:b\in B\}=B+c$. Now, clearly $A\cap B_n\subseteq A\cap B_{n+1}\;\forall n\in\Bbb N\Rightarrow\ \lim_{n\to\infty}(A\cap B_n)=\bigcup_{n=1}^\infty (A\cap B_n)=A\cap\bigcup_{n=1}^\infty B_n=A\cap (B+c)$. So by Lemma 2 we get that: $$\lim_{n\to\infty}\overline{\lambda}_{A,B}(x_n)=\lim_{n\to\infty}\overline{\lambda}(A\cap(B+x_n))=\lim_{n\to\infty}\overline{\lambda}(A\cap B_n)=\overline{\lambda}\big(\lim_{n\to\infty}(A\cap B_n)\big)=\overline{\lambda}(A\cap (B+c))=\overline{\lambda}_{A,B}(c)$$ And clearly $\lim_{n\to\infty}x_n=c$, thus $\overline{\lambda}_{A,B}$ is continuous. Did I miss something?",,"['measure-theory', 'lebesgue-measure']"
51,$L^2(\Omega)/\Bbb{R}$ in cited reference?,in cited reference?,L^2(\Omega)/\Bbb{R},"The following is a theorem in the preliminary material section of Constantin and Foias's ""Navier-Stokes Equations"": Let $\Omega\subset\Bbb{R}^n$ be an open bounded set with locally   Lipschitz boundary. If a distribution $p\in D'(\Omega)$ has all its first derivatives $D_ip$ in $L^2(\Omega)$ then $p\in L^2(\Omega)$ and    $$  \|p\|_{L^2(\Omega)/\Bbb{R}}\leq C(\Omega)\|\nabla p\|_{L^2(\Omega)^n}  $$ If a distribution $p$ has all its first derivatives in    $H^{-1}(\Omega)$ then $p\in L^2(\Omega)$ and    $$     \|p\|_{L^2(\Omega)/\Bbb{R}}\leq C(\Omega)\|\nabla  p\|_{H^{-1}(\Omega)^n}    $$ In both cases, if no restriction is imposed on $\partial\Omega$ it   follows that $p\in L_{\hbox{loc}}^2(\Omega)$. By   $\|p\|_{L^2(\Omega)/\Bbb{R}}$ we mean $$  \inf_{c\in\Bbb{R}}\|p-c\|_{L^2(\Omega)}= \|p-\frac{\int_\Omega p \  dx}{|\Omega|}\cdot 1\|_{L^2(\Omega)}. $$ The space $L^2(\Omega)/\Bbb{R}$ defined in the theorem looks quite strange to me (since the notation usually suggests a quotient space).  Could anyone come up with a cited reference about this space?","The following is a theorem in the preliminary material section of Constantin and Foias's ""Navier-Stokes Equations"": Let $\Omega\subset\Bbb{R}^n$ be an open bounded set with locally   Lipschitz boundary. If a distribution $p\in D'(\Omega)$ has all its first derivatives $D_ip$ in $L^2(\Omega)$ then $p\in L^2(\Omega)$ and    $$  \|p\|_{L^2(\Omega)/\Bbb{R}}\leq C(\Omega)\|\nabla p\|_{L^2(\Omega)^n}  $$ If a distribution $p$ has all its first derivatives in    $H^{-1}(\Omega)$ then $p\in L^2(\Omega)$ and    $$     \|p\|_{L^2(\Omega)/\Bbb{R}}\leq C(\Omega)\|\nabla  p\|_{H^{-1}(\Omega)^n}    $$ In both cases, if no restriction is imposed on $\partial\Omega$ it   follows that $p\in L_{\hbox{loc}}^2(\Omega)$. By   $\|p\|_{L^2(\Omega)/\Bbb{R}}$ we mean $$  \inf_{c\in\Bbb{R}}\|p-c\|_{L^2(\Omega)}= \|p-\frac{\int_\Omega p \  dx}{|\Omega|}\cdot 1\|_{L^2(\Omega)}. $$ The space $L^2(\Omega)/\Bbb{R}$ defined in the theorem looks quite strange to me (since the notation usually suggests a quotient space).  Could anyone come up with a cited reference about this space?",,"['real-analysis', 'measure-theory']"
52,Dominated convergence theorem (computing limit),Dominated convergence theorem (computing limit),,"I need to compute $\displaystyle\lim_{n \rightarrow \infty} \int \frac{\sin (x^n)}{x^2} \, dx$ using Dominated Convergence theorem. I have taken the function $g$ such that $|f_n| \leq g$ , where $f_n =\dfrac{\sin (x^n)}{x^2} $ to be $\dfrac{1}{x^2}$. I am not sure how to proceed forward. Do I need to find another function $f$ s.t. $f_n \rightarrow f $ almost everywhere. If not then what should be my approach?","I need to compute $\displaystyle\lim_{n \rightarrow \infty} \int \frac{\sin (x^n)}{x^2} \, dx$ using Dominated Convergence theorem. I have taken the function $g$ such that $|f_n| \leq g$ , where $f_n =\dfrac{\sin (x^n)}{x^2} $ to be $\dfrac{1}{x^2}$. I am not sure how to proceed forward. Do I need to find another function $f$ s.t. $f_n \rightarrow f $ almost everywhere. If not then what should be my approach?",,"['real-analysis', 'measure-theory', 'lebesgue-integral']"
53,a set is invariant under translation for a certain measure,a set is invariant under translation for a certain measure,,"Assume $A\in\mathbb{R}^n$ is a Lebesgue null set and $\mu$ is a positive $\sigma$-finite measure living on $A$ (i.e. $\mu(A^c)=0$) such that  $$ \mu(A+r)=\mu(A),\forall r\in\mathbb{R}^n $$ does this imply that $\mu=0$? I think of this when I am learning the Lebesgue-Radon-Nikodym theorem and the invariant property under translation of Lebesgue measure. I think the answer is yes but still need more justification.  Any hint would be appreciated!","Assume $A\in\mathbb{R}^n$ is a Lebesgue null set and $\mu$ is a positive $\sigma$-finite measure living on $A$ (i.e. $\mu(A^c)=0$) such that  $$ \mu(A+r)=\mu(A),\forall r\in\mathbb{R}^n $$ does this imply that $\mu=0$? I think of this when I am learning the Lebesgue-Radon-Nikodym theorem and the invariant property under translation of Lebesgue measure. I think the answer is yes but still need more justification.  Any hint would be appreciated!",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
54,How to prove that $m\left(\lbrace f>\alpha\rbrace\right)$ is a right-continuous function of $\alpha$?,How to prove that  is a right-continuous function of ?,m\left(\lbrace f>\alpha\rbrace\right) \alpha,"Let $f$ be a Lebesgue measurable function that is finite almost everywhere on $\left[a,b\right]$. Prove that $m\left(\lbrace f>\alpha\rbrace\right)$ is a right-continuous function of $\alpha$, and that $m\left(\lbrace f\geq\alpha\rbrace\right)$ a left-continuous function of $\alpha$. I am really curious about how ''>'' and ''$\geq$'' make such a difference.","Let $f$ be a Lebesgue measurable function that is finite almost everywhere on $\left[a,b\right]$. Prove that $m\left(\lbrace f>\alpha\rbrace\right)$ is a right-continuous function of $\alpha$, and that $m\left(\lbrace f\geq\alpha\rbrace\right)$ a left-continuous function of $\alpha$. I am really curious about how ''>'' and ''$\geq$'' make such a difference.",,"['real-analysis', 'measure-theory']"
55,Is the pointwise limit of a uniformly bounded net of increasing positive continuous functions on a compact Hausdorff space Borel measurable?,Is the pointwise limit of a uniformly bounded net of increasing positive continuous functions on a compact Hausdorff space Borel measurable?,,Let $X$ be a compact and Hausdorff space. Let $\{f_i\}$ be a uniformly bounded net of increasing positive continuous functions on $X$. Let $f$ be the pointwise  limit of the net $\{f_i\}$. Is $f$ a Borel measurable function?,Let $X$ be a compact and Hausdorff space. Let $\{f_i\}$ be a uniformly bounded net of increasing positive continuous functions on $X$. Let $f$ be the pointwise  limit of the net $\{f_i\}$. Is $f$ a Borel measurable function?,,"['real-analysis', 'general-topology', 'measure-theory']"
56,Union of one set of outer measure zero and one set of outer measure $\geq 0$ has outer measure zer0.,Union of one set of outer measure zero and one set of outer measure  has outer measure zer0.,\geq 0,"Prove directly from the definition of Outer Measure $m^{*}$ that if $m^{*}(A) = 0$, then $m^{*}(A \cup B)=m^{*}(B)$ (this is actually an exercise from Royden, but our professor wants us to use the definition of Outer Measure (a function $m^{*}: \{\text{subsets of}\,\mathbb{R}\} \to \mathbb{R}_{\geq 0} \cup \{\infty \}$ defined as: $m^{*}(A) = \inf \left \{\displaystyle \sum_{k=1}^{\infty} l(I_{k})\, \vert I_{1},I_{2},\cdots \text{open bounded intervals such that}\, A \subseteq \cup_{k=1}^{\infty} I_{k} \right\}$ (where $l(I_{k})$ is the length of the $k$th interval)). Now, let $m^{*}(B) =  \inf \left \{\displaystyle \sum_{k=1}^{\infty} l(J_{k})\, \vert J_{1},J_{2},\cdots \text{open bounded intervals such that}\, B \subseteq \cup_{k=1}^{\infty} J_{k} \right\}$ and $m^{*}(A \cup B) = \inf \left \{\displaystyle \sum_{k=1}^{\infty} l(M_{k})\, \vert M_{1},M_{2},\cdots \text{open bounded intervals such that}\, A \cup B \subseteq \cup_{k=1}^{\infty} M_{k} \right\}$ The way I think the proof should go is the following: $m^{*}(A \cup B) = \inf \sum_{k=1}^{\infty} l(M_{k}) = \inf \sum_{k=1}^{\infty}l(I_{k}) + \inf \sum_{k=1}^{\infty}l(J_{k}) = 0 + m^{*}(B) = m^{*}(B)$. However, in order to do this, I would (1) need to show that $\cup_{k=1}^{\infty} M_{k} = (\cup_{k=1}^{\infty}I_{k})\cup (\cup_{k=1}^{\infty}J_{k})$ and (2) that this implies that $\inf \sum_{k=1}^{\infty} l(M_{k}) = \inf\sum_{k=1}^{\infty}l(I_{k}) + \inf\sum_{k=1}^{\infty}l(J_{k})$. It's frustrating, too, because this is supposed to be an easy exercise, and intuitively, it makes sense that the absolute minimum needed to cover $A \cup B$ should also be the absolute minimum needed to cover $A$ plus the absolute minimum needed to cover $B$, but I need to show this in a mathematically rigorous way, and can't just assert things without being able to mathematically explain them. If someone could please help me fill in the justification gaps in this proof and/or fix it if it's incorrect, it would be very much appreciated, and would definitely help me in my attempts to tackle the harder problems.","Prove directly from the definition of Outer Measure $m^{*}$ that if $m^{*}(A) = 0$, then $m^{*}(A \cup B)=m^{*}(B)$ (this is actually an exercise from Royden, but our professor wants us to use the definition of Outer Measure (a function $m^{*}: \{\text{subsets of}\,\mathbb{R}\} \to \mathbb{R}_{\geq 0} \cup \{\infty \}$ defined as: $m^{*}(A) = \inf \left \{\displaystyle \sum_{k=1}^{\infty} l(I_{k})\, \vert I_{1},I_{2},\cdots \text{open bounded intervals such that}\, A \subseteq \cup_{k=1}^{\infty} I_{k} \right\}$ (where $l(I_{k})$ is the length of the $k$th interval)). Now, let $m^{*}(B) =  \inf \left \{\displaystyle \sum_{k=1}^{\infty} l(J_{k})\, \vert J_{1},J_{2},\cdots \text{open bounded intervals such that}\, B \subseteq \cup_{k=1}^{\infty} J_{k} \right\}$ and $m^{*}(A \cup B) = \inf \left \{\displaystyle \sum_{k=1}^{\infty} l(M_{k})\, \vert M_{1},M_{2},\cdots \text{open bounded intervals such that}\, A \cup B \subseteq \cup_{k=1}^{\infty} M_{k} \right\}$ The way I think the proof should go is the following: $m^{*}(A \cup B) = \inf \sum_{k=1}^{\infty} l(M_{k}) = \inf \sum_{k=1}^{\infty}l(I_{k}) + \inf \sum_{k=1}^{\infty}l(J_{k}) = 0 + m^{*}(B) = m^{*}(B)$. However, in order to do this, I would (1) need to show that $\cup_{k=1}^{\infty} M_{k} = (\cup_{k=1}^{\infty}I_{k})\cup (\cup_{k=1}^{\infty}J_{k})$ and (2) that this implies that $\inf \sum_{k=1}^{\infty} l(M_{k}) = \inf\sum_{k=1}^{\infty}l(I_{k}) + \inf\sum_{k=1}^{\infty}l(J_{k})$. It's frustrating, too, because this is supposed to be an easy exercise, and intuitively, it makes sense that the absolute minimum needed to cover $A \cup B$ should also be the absolute minimum needed to cover $A$ plus the absolute minimum needed to cover $B$, but I need to show this in a mathematically rigorous way, and can't just assert things without being able to mathematically explain them. If someone could please help me fill in the justification gaps in this proof and/or fix it if it's incorrect, it would be very much appreciated, and would definitely help me in my attempts to tackle the harder problems.",,['real-analysis']
57,Convergence of Series of a.e. finite measurable functions,Convergence of Series of a.e. finite measurable functions,,"Let $(f_n)_{n\geq1}$ be a sequence of measurable almost everywhere finite real-valued functions on $(X,M,\mu)$, where $$ is a $$-finite measure. Prove that there exist constants $c_n > 0$ such that the series $\sum c_nf_n(x)$ converges for $\mu$-a.e. $x\in X$","Let $(f_n)_{n\geq1}$ be a sequence of measurable almost everywhere finite real-valued functions on $(X,M,\mu)$, where $$ is a $$-finite measure. Prove that there exist constants $c_n > 0$ such that the series $\sum c_nf_n(x)$ converges for $\mu$-a.e. $x\in X$",,"['real-analysis', 'measure-theory', 'convergence-divergence']"
58,Lebesgue Integral computation,Lebesgue Integral computation,,"Compute $\lim\limits_{n \to \infty} \int_0^n (1 - \frac{x}{n})^n e^{x/2} dx $, justify your calculation My Try: Use Lebesgue Dominance Convergence Theorem $f_n = (1 -\frac{x}{n})^n e^{x/2}$ and $|f_n| \leq g$ where $g = e^{-x} e^{x/2}$. If i do this i have to prove that $(1 -\frac{x}{n})^n <e^{-x}$ and i don't know how to prove it, any idea, any help, Thanks","Compute $\lim\limits_{n \to \infty} \int_0^n (1 - \frac{x}{n})^n e^{x/2} dx $, justify your calculation My Try: Use Lebesgue Dominance Convergence Theorem $f_n = (1 -\frac{x}{n})^n e^{x/2}$ and $|f_n| \leq g$ where $g = e^{-x} e^{x/2}$. If i do this i have to prove that $(1 -\frac{x}{n})^n <e^{-x}$ and i don't know how to prove it, any idea, any help, Thanks",,"['real-analysis', 'measure-theory', 'lebesgue-integral']"
59,Modifying definition of $\sigma$-algebra,Modifying definition of -algebra,\sigma,"Let's start with basic definitions. Def. Given a set $X$  we say that $\Sigma\subset 2^X$ is a $\sigma$-algebra , if $X\in\Sigma,$ $\Sigma$ is closed under complementation and countable unions. Def. Given a family $\mathcal A$ of subsets of $X,$  we say that $\sigma$-algebra $\sigma(\mathcal A)$ is the $\sigma$-algebra generated by $\mathcal A$ , if it is the smallest $\sigma$-algebra containing $\mathcal A.$ Asaf Karagila said in this answer , that $\sigma(\mathcal A)$ has descriptive, but transfinite form. It is $\Sigma^0_0=\Pi^0_0=$ finite intersections from $\mathcal{A}$ For countable ordinals $\alpha$ let: $$\Sigma^0_\alpha=\{\bigcup_{i\in\mathbb N} A_i\mid A_i\in\bigcup_{\beta<\alpha}\Pi^0_\beta\},\quad  \Pi^0_\alpha = \{X\setminus A\mid A\in\Sigma^0_\alpha\},\quad  \Delta^0_\alpha=\Sigma^0_\alpha\cap\Pi^0_\alpha$$ and then we define $\Delta=\bigcup_{\alpha<\omega_1} \Delta^0_\alpha.$ I heard of slightly different approach (I colored differences in $\color{green}{\text{green}}$), i.e. $\color{green}{\Delta_0=\mathcal{A}\cup\{\emptyset\}}$ For countable ordinals $\alpha$ let: $$\Sigma_\alpha=\{\bigcup_{i\in\mathbb N} A_i\mid A_i\in\bigcup_{\beta<\alpha}\color{green}{\Delta}_\beta\},\quad  \Pi_\alpha = \{X\setminus A\mid A\in\Sigma_\alpha\},\quad  \Delta_\alpha=\Sigma_\alpha\color{green}{\cup}\Pi_\alpha$$ and then we define $\Delta=\bigcup_{\alpha<\omega_1} \Delta_\alpha.$ In both cases the claim is that $\Delta=\sigma(\mathcal A).$ I have no clue how someone is able to proof that, particularly the inclusion $\Delta\subset\sigma(\mathcal A),$ but I believe it can be done and I am willing to assume that $\Delta=\sigma(\mathcal A)$ in both cases above. From now on, if I say transfinte induction, I mean the second one, i.e. the one with $\color{green}{\text{green}}$ elements. I would like to create a new object $\Gamma,$ which I get from transfinite induction, but restricted to the finite ordinals, i.e. I just simply do normal induction and define $\Gamma=\bigcup_{n<\infty}\Delta_n.$ To be even more explicite, let's actually define it using good old normal induction. So we set $\Delta_0=\mathcal{A}\cup\{\emptyset\}$ For every $n\in\mathbb{N}:$ $$\Sigma_n=\{\bigcup_{i\in\mathbb N} A_i\mid A_i\in\bigcup_{k<n}\Delta_k\},\quad \Pi_n = \{X\setminus A\mid A\in\Sigma_n\},\quad \Delta_n=\Sigma_n\cup\Pi_n$$ and then we define $\Gamma=\bigcup_{n<\infty}\Delta_n.$ For me $\Gamma$ is big enought. But since $\Delta=\sigma(\mathcal A)$ and $\Gamma$ looks smaller than $\Delta$ it is likely that $\Gamma\neq\sigma(\mathcal A).$ Unfortunetely $\Gamma$ seems not to be even a $\sigma$-algebra, for the same reason that $\Delta$ is in fact $\sigma$-algebra. (See Arturo Magidin's answer) It fails to be closed under countable unions. But it fails, due to considering diagonal-like elements (and actually this is the reason why I define $\Gamma$ in such way). What is the idea! (don't be scared in first reading) I would like to define two new objects called $\gamma$-algebra and $\gamma$-algebra generated by $\mathcal A.$ $\gamma$-algebra is defined similar to $\sigma$-algebra, but with $\color{blue}{\text{different (weaker) conditions}}$. $\gamma$-algebra generated by $\mathcal A$ is smallest such $\gamma$-algebra and it has descriptive form, which equals $\Gamma.$ In other words, I would like to end up with the following situation: Def. Given a set $X$  we say that $\Omega\subset 2^X$ is a $\gamma$-algebra , if $X\in\Omega,$ $\Omega$ is closed under complementation and $\color{blue}{\text{some conditions I ask you to invent}}$. Def. Given a family $\mathcal A$ of subsets of $X,$  we say that $\gamma$-algebra $\gamma(\mathcal A)$ is the $\gamma$-algebra generated by $\mathcal A$ , if it is the smallest $\gamma$-algebra containing $\mathcal A.$ Thm. Let $\mathcal A$ be a family of subsets of $X.$ If we define $\Gamma$ as above, then   $$\Gamma=\gamma(\mathcal A).$$ The question What conditions should be in $\color{blue}{\text{blue}}?$","Let's start with basic definitions. Def. Given a set $X$  we say that $\Sigma\subset 2^X$ is a $\sigma$-algebra , if $X\in\Sigma,$ $\Sigma$ is closed under complementation and countable unions. Def. Given a family $\mathcal A$ of subsets of $X,$  we say that $\sigma$-algebra $\sigma(\mathcal A)$ is the $\sigma$-algebra generated by $\mathcal A$ , if it is the smallest $\sigma$-algebra containing $\mathcal A.$ Asaf Karagila said in this answer , that $\sigma(\mathcal A)$ has descriptive, but transfinite form. It is $\Sigma^0_0=\Pi^0_0=$ finite intersections from $\mathcal{A}$ For countable ordinals $\alpha$ let: $$\Sigma^0_\alpha=\{\bigcup_{i\in\mathbb N} A_i\mid A_i\in\bigcup_{\beta<\alpha}\Pi^0_\beta\},\quad  \Pi^0_\alpha = \{X\setminus A\mid A\in\Sigma^0_\alpha\},\quad  \Delta^0_\alpha=\Sigma^0_\alpha\cap\Pi^0_\alpha$$ and then we define $\Delta=\bigcup_{\alpha<\omega_1} \Delta^0_\alpha.$ I heard of slightly different approach (I colored differences in $\color{green}{\text{green}}$), i.e. $\color{green}{\Delta_0=\mathcal{A}\cup\{\emptyset\}}$ For countable ordinals $\alpha$ let: $$\Sigma_\alpha=\{\bigcup_{i\in\mathbb N} A_i\mid A_i\in\bigcup_{\beta<\alpha}\color{green}{\Delta}_\beta\},\quad  \Pi_\alpha = \{X\setminus A\mid A\in\Sigma_\alpha\},\quad  \Delta_\alpha=\Sigma_\alpha\color{green}{\cup}\Pi_\alpha$$ and then we define $\Delta=\bigcup_{\alpha<\omega_1} \Delta_\alpha.$ In both cases the claim is that $\Delta=\sigma(\mathcal A).$ I have no clue how someone is able to proof that, particularly the inclusion $\Delta\subset\sigma(\mathcal A),$ but I believe it can be done and I am willing to assume that $\Delta=\sigma(\mathcal A)$ in both cases above. From now on, if I say transfinte induction, I mean the second one, i.e. the one with $\color{green}{\text{green}}$ elements. I would like to create a new object $\Gamma,$ which I get from transfinite induction, but restricted to the finite ordinals, i.e. I just simply do normal induction and define $\Gamma=\bigcup_{n<\infty}\Delta_n.$ To be even more explicite, let's actually define it using good old normal induction. So we set $\Delta_0=\mathcal{A}\cup\{\emptyset\}$ For every $n\in\mathbb{N}:$ $$\Sigma_n=\{\bigcup_{i\in\mathbb N} A_i\mid A_i\in\bigcup_{k<n}\Delta_k\},\quad \Pi_n = \{X\setminus A\mid A\in\Sigma_n\},\quad \Delta_n=\Sigma_n\cup\Pi_n$$ and then we define $\Gamma=\bigcup_{n<\infty}\Delta_n.$ For me $\Gamma$ is big enought. But since $\Delta=\sigma(\mathcal A)$ and $\Gamma$ looks smaller than $\Delta$ it is likely that $\Gamma\neq\sigma(\mathcal A).$ Unfortunetely $\Gamma$ seems not to be even a $\sigma$-algebra, for the same reason that $\Delta$ is in fact $\sigma$-algebra. (See Arturo Magidin's answer) It fails to be closed under countable unions. But it fails, due to considering diagonal-like elements (and actually this is the reason why I define $\Gamma$ in such way). What is the idea! (don't be scared in first reading) I would like to define two new objects called $\gamma$-algebra and $\gamma$-algebra generated by $\mathcal A.$ $\gamma$-algebra is defined similar to $\sigma$-algebra, but with $\color{blue}{\text{different (weaker) conditions}}$. $\gamma$-algebra generated by $\mathcal A$ is smallest such $\gamma$-algebra and it has descriptive form, which equals $\Gamma.$ In other words, I would like to end up with the following situation: Def. Given a set $X$  we say that $\Omega\subset 2^X$ is a $\gamma$-algebra , if $X\in\Omega,$ $\Omega$ is closed under complementation and $\color{blue}{\text{some conditions I ask you to invent}}$. Def. Given a family $\mathcal A$ of subsets of $X,$  we say that $\gamma$-algebra $\gamma(\mathcal A)$ is the $\gamma$-algebra generated by $\mathcal A$ , if it is the smallest $\gamma$-algebra containing $\mathcal A.$ Thm. Let $\mathcal A$ be a family of subsets of $X.$ If we define $\Gamma$ as above, then   $$\Gamma=\gamma(\mathcal A).$$ The question What conditions should be in $\color{blue}{\text{blue}}?$",,"['real-analysis', 'measure-theory', 'descriptive-set-theory']"
60,Example of the fact that outer measure is subadditive but not countably additive,Example of the fact that outer measure is subadditive but not countably additive,,I am looking for an explicit example of the fact that outer measure is sub-additive but not additive. Any help would be great,I am looking for an explicit example of the fact that outer measure is sub-additive but not additive. Any help would be great,,[]
61,Intersection of Borel subset with line,Intersection of Borel subset with line,,"Let $y \in \mathbb{R}$. If $A$ is a Borel subset of $\mathbb{R}^2$, then $$A(y) = \{x \in \mathbb{R}| (x,y) \in A\}$$ is a Borel subset of $\mathbb{R}$. I think that I have to show that $A(y)$ is in Borel-sigma algebra in $\mathbb{R}$. But the sigma algebra itself has no clear form, I mean I just know that it is the sigma algebra generated by all open sets, there is no clear form of its elements. Another thing is I am not sure if Borel ""subset"" means the same as Borel 'set' (which simply mean it is in the Borel sigma algebra). Any idea or hint about how to begin ? It is very good if anyone can list some important steps in proving this statement.","Let $y \in \mathbb{R}$. If $A$ is a Borel subset of $\mathbb{R}^2$, then $$A(y) = \{x \in \mathbb{R}| (x,y) \in A\}$$ is a Borel subset of $\mathbb{R}$. I think that I have to show that $A(y)$ is in Borel-sigma algebra in $\mathbb{R}$. But the sigma algebra itself has no clear form, I mean I just know that it is the sigma algebra generated by all open sets, there is no clear form of its elements. Another thing is I am not sure if Borel ""subset"" means the same as Borel 'set' (which simply mean it is in the Borel sigma algebra). Any idea or hint about how to begin ? It is very good if anyone can list some important steps in proving this statement.",,"['real-analysis', 'measure-theory', 'lebesgue-measure', 'descriptive-set-theory']"
62,"Dominated Convergence Theorem, Fourier tranform continuous proof","Dominated Convergence Theorem, Fourier tranform continuous proof",,"I am reading a proof that states that the Fourier transform $\hat{f}$ of a function $f\in L^1$ is continuous and bounded (here $f:\mathbb{R}^d\to \mathbb{R}$).  I am having trouble with understanding the use of dominated convergence theorem in the continuous part. Here is the proof, as appears in the notes: Let $(\zeta_n)$ be a sequence in $\mathbb{R}^d$ such that $\zeta_n\to\zeta\in\mathbb{R}^d$. Then $(\exp(i\langle x,\zeta\rangle)\exp(i\langle x,\zeta_n\rangle)f(x)\to 0$ as $n\to\infty$ for each $x\in\mathbb{R}^d$. Since $|\hat{f}(\zeta) \hat{f}(\zeta_n)|\leq 2\|f\|_1$, an application of the Dominated convergence theorem shows that $\hat{f}(\zeta_n)\to\hat{f}(\zeta)$. The trouble I am having is with the use of the DCT. Namely, isn't the goal to show $\exp(\langle x,\zeta_n\rangle)f(x)$ is dominated by some integrable function? How does $|\hat{f}(\zeta) \hat{f}(\zeta_n)|\leq 2\|f\|_1$ enable us to use the DCT? Thank you in advance. B. Edit: It appears $|\exp(\langle x,\zeta_n\rangle)f(x)|\leq |f(x)|$ which is integrable, so shouldn't this suffice?","I am reading a proof that states that the Fourier transform $\hat{f}$ of a function $f\in L^1$ is continuous and bounded (here $f:\mathbb{R}^d\to \mathbb{R}$).  I am having trouble with understanding the use of dominated convergence theorem in the continuous part. Here is the proof, as appears in the notes: Let $(\zeta_n)$ be a sequence in $\mathbb{R}^d$ such that $\zeta_n\to\zeta\in\mathbb{R}^d$. Then $(\exp(i\langle x,\zeta\rangle)\exp(i\langle x,\zeta_n\rangle)f(x)\to 0$ as $n\to\infty$ for each $x\in\mathbb{R}^d$. Since $|\hat{f}(\zeta) \hat{f}(\zeta_n)|\leq 2\|f\|_1$, an application of the Dominated convergence theorem shows that $\hat{f}(\zeta_n)\to\hat{f}(\zeta)$. The trouble I am having is with the use of the DCT. Namely, isn't the goal to show $\exp(\langle x,\zeta_n\rangle)f(x)$ is dominated by some integrable function? How does $|\hat{f}(\zeta) \hat{f}(\zeta_n)|\leq 2\|f\|_1$ enable us to use the DCT? Thank you in advance. B. Edit: It appears $|\exp(\langle x,\zeta_n\rangle)f(x)|\leq |f(x)|$ which is integrable, so shouldn't this suffice?",,"['measure-theory', 'fourier-analysis', 'lebesgue-integral']"
63,On the integration of a Lebesgue measurable function,On the integration of a Lebesgue measurable function,,"Consider a function $f$ defined as $f:[0,2\pi]\to \mathbb{R}$ such that  $\begin{equation} f(x)=\inf_{n\in \mathcal{N}} \sin^2 (2^n x) \end {equation}$ Is possible to give a decent bound of $\int_{0}^{2\pi} f(x) dx$ or directly get its value? We can prove that this function is measurable by prove the following lemma: Lemma: If $\mathcal{F}$ is a family of continuous functions on $[0, 2\pi]$. Then functon $\phi(x)$ defined as $\phi(x)=\inf_{f\in \mathcal{F}} f(x)$ is measurable on $[0, 2\pi]$. Hence, according to Lusin's theorem we can prove that this function is continuous a.e. on $[0,2\pi]$. Given all of these, can we get the exact value of the integration if it exists? Some of my own ideas: 1) I think one of the hard point is to determine the structure of sets $\mathbb{E}_{t}=f^{-1}(t)$ for any given $t$ in the range of $f$. 2) another interpretation on $f$: notice that if we denote $b_{k}= \sin^2 (2^{k} x)$ for fixed $x$ then it's not too hard to check that  $b_{k+1}=4b_{k}(1-b_{k})$. Hence sequence $\{b_{k}(x)\}$ could be regarded as obtained by starting at any point $b_{0}(x)=sin^2(x), x\in [0,2\pi]$ and conduct iteration with respect of $g(x)=4x(1-x)$. $f(x)$ actually measures the infimum of sequence $\{b_{k}(x)\}$ regarding different values of $b_{0}(x), x\in [0,2\pi]$.","Consider a function $f$ defined as $f:[0,2\pi]\to \mathbb{R}$ such that  $\begin{equation} f(x)=\inf_{n\in \mathcal{N}} \sin^2 (2^n x) \end {equation}$ Is possible to give a decent bound of $\int_{0}^{2\pi} f(x) dx$ or directly get its value? We can prove that this function is measurable by prove the following lemma: Lemma: If $\mathcal{F}$ is a family of continuous functions on $[0, 2\pi]$. Then functon $\phi(x)$ defined as $\phi(x)=\inf_{f\in \mathcal{F}} f(x)$ is measurable on $[0, 2\pi]$. Hence, according to Lusin's theorem we can prove that this function is continuous a.e. on $[0,2\pi]$. Given all of these, can we get the exact value of the integration if it exists? Some of my own ideas: 1) I think one of the hard point is to determine the structure of sets $\mathbb{E}_{t}=f^{-1}(t)$ for any given $t$ in the range of $f$. 2) another interpretation on $f$: notice that if we denote $b_{k}= \sin^2 (2^{k} x)$ for fixed $x$ then it's not too hard to check that  $b_{k+1}=4b_{k}(1-b_{k})$. Hence sequence $\{b_{k}(x)\}$ could be regarded as obtained by starting at any point $b_{0}(x)=sin^2(x), x\in [0,2\pi]$ and conduct iteration with respect of $g(x)=4x(1-x)$. $f(x)$ actually measures the infimum of sequence $\{b_{k}(x)\}$ regarding different values of $b_{0}(x), x\in [0,2\pi]$.",,"['real-analysis', 'integration', 'measure-theory', 'lebesgue-integral', 'supremum-and-infimum']"
64,Looking for a clarification of the Suslin $\mathcal{A}$-Operation with a (finite) example,Looking for a clarification of the Suslin -Operation with a (finite) example,\mathcal{A},"I have a problem concerning the output of (and the intuition behind) the Suslin $\mathcal{A}$-Operation . More specifically, I really don't see exactly what the output of it really is (even if I can actually use it to prove some very basic things), and I think this hampers my general understanding. In order to get some intuition, I decided to translate everything in terms of finite sets (this one should be an instantiation of the Alexandroff Operation). By doing this, I also added some numbered questions to emphasise my problems. This is the basic setting: $X = \{ a, b \}$ $A = \{0, 1 \}$ $A_e = \{ a, b \}$, $A_0 = \{ a \}$, $A_1 = \{ b \}$, $A_{00} = \varnothing = A_{10} = A_{01} = A_{11}$ where a Suslin scheme is a function of the form $A : A^{<\mathbb{N}} \to 2^X$. So, we have that $$ \mathcal{A}_2 ( \{ A_s \} ) = \bigcup_{\alpha \in A^{\mathbb{N}}} \bigcap_{n \in \mathbb{N}} A_{\alpha|n} \hspace{7cm} (\square),$$ where $\{ A_s \}$ denotes the family of all the $A$ sets previously considered (this is a Suslin scheme that is also regular), and $\alpha|n$ denotes the initial segment $\alpha = ( \alpha_0, \alpha_1 , \dots, \alpha_{n-1})$ of length $n$ of a $\alpha \in A^{\mathbb{N}}$. Hence we have that $$x \in \mathcal{A}_2 ( \{ A_s \} ) \Longleftrightarrow \exists \alpha \in A^{\mathbb{N}} : \forall n \in \mathbb{N} \ ( x \in A_{\alpha|n}) \hspace{3cm}(*).$$ Now, my problems start here. 1. Does this actually means that in this case, with finite $X$, the $\mathcal{A}$-Operation gives an empty result? This is my hypothesis because my intuition is the following. We are in a finite context, and no matter what $n \in \mathbb{N}$ we pick, still the process basically ends at the second digit (i.e. $A_{**}$) which is associated with the empty set, and hence there is no element that can fit the RHS of $(*)$. 2. Is this line of reasoning correct? If this is the case, then a natural consideration is that the power of the Suslin $\mathcal{A}$-Operation really comes from infinite spaces, where this process can go on indefinitely. 3. Again, is this correct? I am really looking forward to any feedback. Thank you in advance for your time. PS: The notation I used should be rather standard in set theory, but I will clarify if needed.","I have a problem concerning the output of (and the intuition behind) the Suslin $\mathcal{A}$-Operation . More specifically, I really don't see exactly what the output of it really is (even if I can actually use it to prove some very basic things), and I think this hampers my general understanding. In order to get some intuition, I decided to translate everything in terms of finite sets (this one should be an instantiation of the Alexandroff Operation). By doing this, I also added some numbered questions to emphasise my problems. This is the basic setting: $X = \{ a, b \}$ $A = \{0, 1 \}$ $A_e = \{ a, b \}$, $A_0 = \{ a \}$, $A_1 = \{ b \}$, $A_{00} = \varnothing = A_{10} = A_{01} = A_{11}$ where a Suslin scheme is a function of the form $A : A^{<\mathbb{N}} \to 2^X$. So, we have that $$ \mathcal{A}_2 ( \{ A_s \} ) = \bigcup_{\alpha \in A^{\mathbb{N}}} \bigcap_{n \in \mathbb{N}} A_{\alpha|n} \hspace{7cm} (\square),$$ where $\{ A_s \}$ denotes the family of all the $A$ sets previously considered (this is a Suslin scheme that is also regular), and $\alpha|n$ denotes the initial segment $\alpha = ( \alpha_0, \alpha_1 , \dots, \alpha_{n-1})$ of length $n$ of a $\alpha \in A^{\mathbb{N}}$. Hence we have that $$x \in \mathcal{A}_2 ( \{ A_s \} ) \Longleftrightarrow \exists \alpha \in A^{\mathbb{N}} : \forall n \in \mathbb{N} \ ( x \in A_{\alpha|n}) \hspace{3cm}(*).$$ Now, my problems start here. 1. Does this actually means that in this case, with finite $X$, the $\mathcal{A}$-Operation gives an empty result? This is my hypothesis because my intuition is the following. We are in a finite context, and no matter what $n \in \mathbb{N}$ we pick, still the process basically ends at the second digit (i.e. $A_{**}$) which is associated with the empty set, and hence there is no element that can fit the RHS of $(*)$. 2. Is this line of reasoning correct? If this is the case, then a natural consideration is that the power of the Suslin $\mathcal{A}$-Operation really comes from infinite spaces, where this process can go on indefinitely. 3. Again, is this correct? I am really looking forward to any feedback. Thank you in advance for your time. PS: The notation I used should be rather standard in set theory, but I will clarify if needed.",,"['general-topology', 'measure-theory', 'set-theory', 'self-learning', 'descriptive-set-theory']"
65,Property of a set of a positive Lebesgue measure,Property of a set of a positive Lebesgue measure,,"I am trying to see whether it is true that in any set of a positive Lebesgue measure in $R^2$ we can always find two points $(a_1,a_2)$ and $(b_1,b_2)$ such that the following hold: $a_1>b_1$ $a_2>b_2$ $a_1-2a_2>b_1-2b_2$. I think the starting point can be the fact that for any set $S$ of a positive Lebesgue measure in $R^2$ we can find a ball $B$ in $R^2$ such that $S\cap B$ has a positive Lebesgue measure in $R^2$ but not sure how to proceed with the proof from here. Any advice would be greatly appreciated!","I am trying to see whether it is true that in any set of a positive Lebesgue measure in $R^2$ we can always find two points $(a_1,a_2)$ and $(b_1,b_2)$ such that the following hold: $a_1>b_1$ $a_2>b_2$ $a_1-2a_2>b_1-2b_2$. I think the starting point can be the fact that for any set $S$ of a positive Lebesgue measure in $R^2$ we can find a ball $B$ in $R^2$ such that $S\cap B$ has a positive Lebesgue measure in $R^2$ but not sure how to proceed with the proof from here. Any advice would be greatly appreciated!",,"['measure-theory', 'lebesgue-measure']"
66,Show that $\mu(f)\mu(1/f)\geq\mu(\Omega)^2$,Show that,\mu(f)\mu(1/f)\geq\mu(\Omega)^2,"Prove that $\mu(\Omega)^2\leq\int f \,d\mu\int\frac{1}{f}\,d\mu$. I don't know if that what I did is correct or if it will help to solve the problem, but here it is: Using the Hlder inequality $\mu(\Omega)=\int_{\Omega} 1 \,d\mu=\int_{\Omega} |f.\frac{1}{f}|\,d\mu\leq (\int_{\Omega}|f|^1\, d\mu)^{\frac{1}{1}}(\int_{\Omega}|\frac{1}{f}|^1\, d\mu)^{\frac{1}{1}}= \int_{\Omega}f\, d\mu\int_{\Omega}\frac{1}{f}\, d\mu$. I stopped here.","Prove that $\mu(\Omega)^2\leq\int f \,d\mu\int\frac{1}{f}\,d\mu$. I don't know if that what I did is correct or if it will help to solve the problem, but here it is: Using the Hlder inequality $\mu(\Omega)=\int_{\Omega} 1 \,d\mu=\int_{\Omega} |f.\frac{1}{f}|\,d\mu\leq (\int_{\Omega}|f|^1\, d\mu)^{\frac{1}{1}}(\int_{\Omega}|\frac{1}{f}|^1\, d\mu)^{\frac{1}{1}}= \int_{\Omega}f\, d\mu\int_{\Omega}\frac{1}{f}\, d\mu$. I stopped here.",,"['integration', 'measure-theory', 'lebesgue-integral', 'lp-spaces']"
67,Measure spaces proof,Measure spaces proof,,"This theorem comes from the book Real Analysis by Folland Note: $M$ is a $\sigma$-algebra Suppose that $(X,M,\mu)$ is a measure space. Let $\mathcal{N} = \{N\in M: \mu(N) = 0\}$ and $\bar{M} = \{E\cup F: E\in M  \ \ \text{and} \ \ F\subset N \ \ \text{for some} \ \ N\in\mathcal{N}\}$. Then $\bar{M}$ is a $\sigma$-algebra, and there is a unique extention $\bar{\mu}$ of $\mu$ to a complete measure on $\bar{M}$ I believe I need to first show that since $M$ and $\mathcal{N}$ are closed under countable unions then so is $\bar{M}$, but I am not exactly sure how to show this. Then, once I have proven that $\bar{M}$ is a $\sigma$-algebra and given how they defined $\mathcal{N}$ then there must be a unique $\bar{\mu}$ that is a complete measure on $\bar{M}$. I am trying to not look at the proof in the book and do this on my own but I just need some help with the finer details, any suggestions would be greatly appreciated.","This theorem comes from the book Real Analysis by Folland Note: $M$ is a $\sigma$-algebra Suppose that $(X,M,\mu)$ is a measure space. Let $\mathcal{N} = \{N\in M: \mu(N) = 0\}$ and $\bar{M} = \{E\cup F: E\in M  \ \ \text{and} \ \ F\subset N \ \ \text{for some} \ \ N\in\mathcal{N}\}$. Then $\bar{M}$ is a $\sigma$-algebra, and there is a unique extention $\bar{\mu}$ of $\mu$ to a complete measure on $\bar{M}$ I believe I need to first show that since $M$ and $\mathcal{N}$ are closed under countable unions then so is $\bar{M}$, but I am not exactly sure how to show this. Then, once I have proven that $\bar{M}$ is a $\sigma$-algebra and given how they defined $\mathcal{N}$ then there must be a unique $\bar{\mu}$ that is a complete measure on $\bar{M}$. I am trying to not look at the proof in the book and do this on my own but I just need some help with the finer details, any suggestions would be greatly appreciated.",,"['real-analysis', 'measure-theory']"
68,Help with Rudin's proof of Riesz Representation Theorem,Help with Rudin's proof of Riesz Representation Theorem,,"I am having difficulty understanding a step in the proof of Riesz Representation Theorem, in Rudin's 'Real and Complex Analysis' (P.40, Theorem 2.14): Let $X$ be a locally compact Hausdorff space, and let $\Lambda$ be a positive linear functional on $C_c(X)$ (the set of all continuous functions on X with compact support) Rudin defines $$\mu(V)=sup\{\Lambda f:f\prec V\}$$ for every open set $V$ in $X$, where $f\prec V$ means $f$ is continuous and has compact support and $0\le f\le \chi_V$ He goes on to assert that $\mu(E)=inf\{ \mu(V): E\subseteq V, V \:open\}$ for every open set $E$ in $X$ But I have difficulty understanding why the above equality holds. I can prove $\mu(E)\leq inf\{ \mu(V): E\subseteq V, V \:open\}$ immediately from the definition of $\mu$ but the other side of the inequality is giving me trouble. Any help in elaborating Rudin's statement is very much appreciated.","I am having difficulty understanding a step in the proof of Riesz Representation Theorem, in Rudin's 'Real and Complex Analysis' (P.40, Theorem 2.14): Let $X$ be a locally compact Hausdorff space, and let $\Lambda$ be a positive linear functional on $C_c(X)$ (the set of all continuous functions on X with compact support) Rudin defines $$\mu(V)=sup\{\Lambda f:f\prec V\}$$ for every open set $V$ in $X$, where $f\prec V$ means $f$ is continuous and has compact support and $0\le f\le \chi_V$ He goes on to assert that $\mu(E)=inf\{ \mu(V): E\subseteq V, V \:open\}$ for every open set $E$ in $X$ But I have difficulty understanding why the above equality holds. I can prove $\mu(E)\leq inf\{ \mu(V): E\subseteq V, V \:open\}$ immediately from the definition of $\mu$ but the other side of the inequality is giving me trouble. Any help in elaborating Rudin's statement is very much appreciated.",,"['real-analysis', 'measure-theory', 'riesz-representation-theorem']"
69,A measure theory book with lots of examples,A measure theory book with lots of examples,,"I find that when learning more abstract concepts, it helps to have a 'simple' example tied to every theorem in order to fully appreciate the theorem or property. However, the course notes I am currently using for my studies of Measure Theory (this is a first course for me) do not have many examples. It is highly rigorous and detailed, but lacks examples. Are you aware of any introductory books on Measure Theory that has a good number of examples tied to each theorem? In other words I guess, do you know of very 'gentle' books on this topic?","I find that when learning more abstract concepts, it helps to have a 'simple' example tied to every theorem in order to fully appreciate the theorem or property. However, the course notes I am currently using for my studies of Measure Theory (this is a first course for me) do not have many examples. It is highly rigorous and detailed, but lacks examples. Are you aware of any introductory books on Measure Theory that has a good number of examples tied to each theorem? In other words I guess, do you know of very 'gentle' books on this topic?",,"['measure-theory', 'book-recommendation']"
70,Is the positive or negative variation of a signed measure finite?,Is the positive or negative variation of a signed measure finite?,,"I'm studying measure theory and read about signed measure. A signed measure is a function $\nu:\mathcal{A}\to \mathbb{R}\cup\{\pm\infty\}$, where $\mathcal A$ is a certain $\sigma-$algebra, such that $\nu(\varnothing)=0$ $\nu$ is $\sigma-$aditive $\nu$ can take the $\infty$ value or the $-\infty$ value, but not both. I manage the next definitions. The positive variation of $\nu$ is defined by $\nu^+(A):=\sup\{\nu(B): B\subseteq A,B\in\mathcal{A}\},\quad\forall A\in\mathcal A$, and the negative variation of $\nu$ is defined by $\nu^-:=(-\nu)^+$. I prove that both are positive measures, but I don't know if anyone of them is finite. I read on wikipedia ( https://en.wikipedia.org/wiki/Signed_measure , Properties section) that one of them is finite, but it uses Hahn decomposition theorem to define the positive and negative variations and I am not acquainted with that theorem.","I'm studying measure theory and read about signed measure. A signed measure is a function $\nu:\mathcal{A}\to \mathbb{R}\cup\{\pm\infty\}$, where $\mathcal A$ is a certain $\sigma-$algebra, such that $\nu(\varnothing)=0$ $\nu$ is $\sigma-$aditive $\nu$ can take the $\infty$ value or the $-\infty$ value, but not both. I manage the next definitions. The positive variation of $\nu$ is defined by $\nu^+(A):=\sup\{\nu(B): B\subseteq A,B\in\mathcal{A}\},\quad\forall A\in\mathcal A$, and the negative variation of $\nu$ is defined by $\nu^-:=(-\nu)^+$. I prove that both are positive measures, but I don't know if anyone of them is finite. I read on wikipedia ( https://en.wikipedia.org/wiki/Signed_measure , Properties section) that one of them is finite, but it uses Hahn decomposition theorem to define the positive and negative variations and I am not acquainted with that theorem.",,['measure-theory']
71,Bernoulli product measure,Bernoulli product measure,,"Let $\Omega=\{0,1\}^\mathbb{N}$ and $\mathcal{A}$ the sigma-algebra generated by the  cylinders sets $\{w\in\Omega\vert \forall s \in S, w_s=\epsilon_s\}$ with $S\subset\mathbb{N}$ finite and $\epsilon_s\in\{0,1\}$. Let $p\in(0,1)$. We take product measure with density $p$ on $(\Omega,\mathcal{A})$:$\mu=\prod_{n\in\mathbb{N}} \mu_n$ where $\mu_n$ is Bernoulli measure on $\{0,1\}$ given by $\mu_n(w_n=0)=1-p$, $\mu_n(w_n=1)=p$. I would like to prove that for all $\epsilon>0$ and $B\in\mathcal{A}$, there is a family of cylinders $(C_i)_{1\leq i \leq N}$ such as $\mu\left(B\Delta \bigcup_{1\leq i\leq N} C_i\right)<\epsilon$, where $\Delta$ is the symmetric difference. Actually, I'm also looking for a simple proof of the existence of the product measure. I would very much appreciate any help / references!","Let $\Omega=\{0,1\}^\mathbb{N}$ and $\mathcal{A}$ the sigma-algebra generated by the  cylinders sets $\{w\in\Omega\vert \forall s \in S, w_s=\epsilon_s\}$ with $S\subset\mathbb{N}$ finite and $\epsilon_s\in\{0,1\}$. Let $p\in(0,1)$. We take product measure with density $p$ on $(\Omega,\mathcal{A})$:$\mu=\prod_{n\in\mathbb{N}} \mu_n$ where $\mu_n$ is Bernoulli measure on $\{0,1\}$ given by $\mu_n(w_n=0)=1-p$, $\mu_n(w_n=1)=p$. I would like to prove that for all $\epsilon>0$ and $B\in\mathcal{A}$, there is a family of cylinders $(C_i)_{1\leq i \leq N}$ such as $\mu\left(B\Delta \bigcup_{1\leq i\leq N} C_i\right)<\epsilon$, where $\Delta$ is the symmetric difference. Actually, I'm also looking for a simple proof of the existence of the product measure. I would very much appreciate any help / references!",,"['measure-theory', 'ergodic-theory']"
72,Determine if $\left| {\mathop {\lim \sup }\limits_{n \to \infty } {A_n}\Delta \mathop {\lim \sup }\limits_{n \to \infty } {B_n}} \right| = 0$,Determine if,\left| {\mathop {\lim \sup }\limits_{n \to \infty } {A_n}\Delta \mathop {\lim \sup }\limits_{n \to \infty } {B_n}} \right| = 0,"The question is Is $\left| {\mathop {\lim \sup }\limits_{n \to \infty } {A_n}\Delta \mathop {\lim \sup }\limits_{n \to \infty } {B_n}} \right| = 0$ if given $\left| {{A_n}\Delta {B_n}} \right| = 0$ and $\left| {\bigcup\nolimits_{n = 1}^\infty  {{A_n}} \Delta  \cup \bigcup\nolimits_{n = 1}^\infty  {{B_n}} } \right| = 0$? Here $|*|$ means Lebesgue measure and $\Delta $ means symmetric difference, i.e. $A\Delta B = (A\backslash B) \cup (B\backslash A)$. Let $E_1={\bigcup\nolimits_{n = 1}^\infty  {{A_n}} \Delta  \cup \bigcup\nolimits_{n = 1}^\infty  {{B_n}} }$, $E_2={\mathop {\lim \sup }\limits_{n \to \infty } {A_n}\Delta \mathop {\lim \sup }\limits_{n \to \infty } {B_n}} $. I found neither $E_1\subseteq E_2$ nor $E_2\subseteq E_1$. If $x\in E_1$, then $x$ belongs to some $A_n$ but none of $B_n$ or vice versa. If $x\in E_2$, then $x$ belongs to infinite many $A_n$ but at most finite many $B_n$ or vise versa. Then $x\in E_1$ cannot imply $x\in E_2$ if $x$ only appears in finite many $A_n$ or $B_n$; $x\in E_2$ cannot imply $x\in E_1$ if $x$ appears if $x$ appears in both some $A_n$ and some $B_n$. But $E_1$ and $E_2$ has an intersection in which $x$ belongs to infinite many $A_n$ but none of $B_n$ or vise versa, and the measure of this intersection is zero since it is a subset of $E_1$. How do I go on from here to infer if $E_2$ has measure zero or not? Or there is other way to solve it? Thank you!","The question is Is $\left| {\mathop {\lim \sup }\limits_{n \to \infty } {A_n}\Delta \mathop {\lim \sup }\limits_{n \to \infty } {B_n}} \right| = 0$ if given $\left| {{A_n}\Delta {B_n}} \right| = 0$ and $\left| {\bigcup\nolimits_{n = 1}^\infty  {{A_n}} \Delta  \cup \bigcup\nolimits_{n = 1}^\infty  {{B_n}} } \right| = 0$? Here $|*|$ means Lebesgue measure and $\Delta $ means symmetric difference, i.e. $A\Delta B = (A\backslash B) \cup (B\backslash A)$. Let $E_1={\bigcup\nolimits_{n = 1}^\infty  {{A_n}} \Delta  \cup \bigcup\nolimits_{n = 1}^\infty  {{B_n}} }$, $E_2={\mathop {\lim \sup }\limits_{n \to \infty } {A_n}\Delta \mathop {\lim \sup }\limits_{n \to \infty } {B_n}} $. I found neither $E_1\subseteq E_2$ nor $E_2\subseteq E_1$. If $x\in E_1$, then $x$ belongs to some $A_n$ but none of $B_n$ or vice versa. If $x\in E_2$, then $x$ belongs to infinite many $A_n$ but at most finite many $B_n$ or vise versa. Then $x\in E_1$ cannot imply $x\in E_2$ if $x$ only appears in finite many $A_n$ or $B_n$; $x\in E_2$ cannot imply $x\in E_1$ if $x$ appears if $x$ appears in both some $A_n$ and some $B_n$. But $E_1$ and $E_2$ has an intersection in which $x$ belongs to infinite many $A_n$ but none of $B_n$ or vise versa, and the measure of this intersection is zero since it is a subset of $E_1$. How do I go on from here to infer if $E_2$ has measure zero or not? Or there is other way to solve it? Thank you!",,"['real-analysis', 'measure-theory']"
73,Construction of a set with density of half at $0$.,Construction of a set with density of half at .,0,"If we define for a given set $A \subset \Bbb{R}$ and $x\in \Bbb{R}$ the density of $A$ at $x$ being the limit as $[I]$ goes to zero of the ratio $[I \cap A]/[I]$ wherever the limit exists for intervals $I$ containing $x$ with $[.]$ denoting the Lebesgue outer measure, is it possible to construct an $A$ with density of $1/2$ at the point $0$,say?","If we define for a given set $A \subset \Bbb{R}$ and $x\in \Bbb{R}$ the density of $A$ at $x$ being the limit as $[I]$ goes to zero of the ratio $[I \cap A]/[I]$ wherever the limit exists for intervals $I$ containing $x$ with $[.]$ denoting the Lebesgue outer measure, is it possible to construct an $A$ with density of $1/2$ at the point $0$,say?",,"['measure-theory', 'lebesgue-measure']"
74,Proof that a random measure with orthogonal increments is a measure,Proof that a random measure with orthogonal increments is a measure,,"Let me first state what I mean by a random measure with orthogonal increments. Definition: A random measure with orthogonal increments $Z$ is a collection $\left(Z(B): B \in \mathcal{B}_{(-\pi,\pi]}\right)$  of zero-mean, complex random variables $Z(B)$ indexed by the Borel sets $\mathcal{B}_{(-\pi,\pi]}$ defined on some probability space $(\Omega,\mathcal{U},P)$ such that for some finite measure $\mu$ on $(-\pi,\pi]$   $$\mathrm{cov}(Z(B_1),Z(B_2))=\mu(B_1\cap B_2) \quad \forall{B_1,B_2}\in \mathcal{B}_{(-\pi,\pi]}$$ Honestly, I don't think I understand this definition. If $Z$ is a measure then it must be true that $Z(\emptyset) = 0$. How does this follow from the definition above exactly? Do I take $B_1 = B_2 = \emptyset$ and argue that given $\mathrm{cov}(Z(B_1),Z(B_2))=\mu(B_1\cap B_2) = 0$ and $E[Z(B)] = 0$ for any $B \in \mathcal{B}_{(-\pi,\pi]}$, $Z(\emptyset) = 0$ $\ P$-almost surely? Next I would like to show that $Z(\cup_j B_j) = \sum_jZ(B_j)$ in mean square whenever $B_1,B_2,\ldots$ is a sequence of pairwise disjoint Borel sets. I am not sure what the mathematical formulation of this result is. My guess is $$E[\lvert Z(\bigcup_j B_j) - \sum_jZ(B_j)\rvert^2] = 0$$ as this would imply  $Z(\cup_j B_j) = \sum_jZ(B_j)$ $\ P$-almost surely, which I think is the most you can expect from a random measure. (If it were an ordinary measure, we would insist on algebraic equality.) Assuming that my guess is right I proceed. From the definition I have (after a few steps) $$\mathrm{var}\left(Z\left(\bigcup_j B_j\right)\right) = \mathrm{var}\left(\sum_jZ(B_j)\right) $$ I don't know how to continue from this point on. I would really appreciate some help. Thanks.","Let me first state what I mean by a random measure with orthogonal increments. Definition: A random measure with orthogonal increments $Z$ is a collection $\left(Z(B): B \in \mathcal{B}_{(-\pi,\pi]}\right)$  of zero-mean, complex random variables $Z(B)$ indexed by the Borel sets $\mathcal{B}_{(-\pi,\pi]}$ defined on some probability space $(\Omega,\mathcal{U},P)$ such that for some finite measure $\mu$ on $(-\pi,\pi]$   $$\mathrm{cov}(Z(B_1),Z(B_2))=\mu(B_1\cap B_2) \quad \forall{B_1,B_2}\in \mathcal{B}_{(-\pi,\pi]}$$ Honestly, I don't think I understand this definition. If $Z$ is a measure then it must be true that $Z(\emptyset) = 0$. How does this follow from the definition above exactly? Do I take $B_1 = B_2 = \emptyset$ and argue that given $\mathrm{cov}(Z(B_1),Z(B_2))=\mu(B_1\cap B_2) = 0$ and $E[Z(B)] = 0$ for any $B \in \mathcal{B}_{(-\pi,\pi]}$, $Z(\emptyset) = 0$ $\ P$-almost surely? Next I would like to show that $Z(\cup_j B_j) = \sum_jZ(B_j)$ in mean square whenever $B_1,B_2,\ldots$ is a sequence of pairwise disjoint Borel sets. I am not sure what the mathematical formulation of this result is. My guess is $$E[\lvert Z(\bigcup_j B_j) - \sum_jZ(B_j)\rvert^2] = 0$$ as this would imply  $Z(\cup_j B_j) = \sum_jZ(B_j)$ $\ P$-almost surely, which I think is the most you can expect from a random measure. (If it were an ordinary measure, we would insist on algebraic equality.) Assuming that my guess is right I proceed. From the definition I have (after a few steps) $$\mathrm{var}\left(Z\left(\bigcup_j B_j\right)\right) = \mathrm{var}\left(\sum_jZ(B_j)\right) $$ I don't know how to continue from this point on. I would really appreciate some help. Thanks.",,"['measure-theory', 'spectral-theory']"
75,Prove continuity of averaging function for integrable $f$,Prove continuity of averaging function for integrable,f,"I want to prove the following statement which is part of a lemma in my textbook: Suppose $f$ is integrable on $\mathbb{R}^n$ and $x$ be a lebesgue point of $f$. Let $$M(r)=\frac{1}{r^d}\int_{|y|\le r} |f(x-y)-f(x)| \, dy$$ for $r>0$ Show $M(r)$ is a continuous function for $r>0$ My try: By changing of variable, $$M(r)=\frac{1}{r^d}\int_{|y|\le r} |f(x-y)-f(x)| \, dy=\int_{|z|\le 1} |f(x+rz)-f(x)| \, dz$$ Hence fixing $r_1>0$, I get $$ |M(r_2)-M(r_1)|\le \int_{|z|\le 1} |f(x+r_2z)-f(x+r_1z)| \, dz $$ If $f$ is continuous, let $r_2$ closed enough to $r_1$, I get uniform continuous then the conclusion follows. For integrable $f$ , I think I need to use Lusin theorem to approximate $f$ be a continuous function and use absolute continuity of $f$, which follows from the inegrability of $f$. But I am not sure how to argue it.","I want to prove the following statement which is part of a lemma in my textbook: Suppose $f$ is integrable on $\mathbb{R}^n$ and $x$ be a lebesgue point of $f$. Let $$M(r)=\frac{1}{r^d}\int_{|y|\le r} |f(x-y)-f(x)| \, dy$$ for $r>0$ Show $M(r)$ is a continuous function for $r>0$ My try: By changing of variable, $$M(r)=\frac{1}{r^d}\int_{|y|\le r} |f(x-y)-f(x)| \, dy=\int_{|z|\le 1} |f(x+rz)-f(x)| \, dz$$ Hence fixing $r_1>0$, I get $$ |M(r_2)-M(r_1)|\le \int_{|z|\le 1} |f(x+r_2z)-f(x+r_1z)| \, dz $$ If $f$ is continuous, let $r_2$ closed enough to $r_1$, I get uniform continuous then the conclusion follows. For integrable $f$ , I think I need to use Lusin theorem to approximate $f$ be a continuous function and use absolute continuity of $f$, which follows from the inegrability of $f$. But I am not sure how to argue it.",,"['real-analysis', 'measure-theory', 'continuity', 'lebesgue-integral', 'lebesgue-measure']"
76,The derivative of a measure,The derivative of a measure,,"Let $\mu$, $\nu$ be two Radon Measure on $\mathbb{R}^n$. How can I prove that $D_{\mu}{\nu}=\lim_{r \to 0} \frac{\nu(B(x,r)}{\mu(B(x,r))}$ is in $L^1_{loc}(\mathbb{R}^n,\mu)$?","Let $\mu$, $\nu$ be two Radon Measure on $\mathbb{R}^n$. How can I prove that $D_{\mu}{\nu}=\lim_{r \to 0} \frac{\nu(B(x,r)}{\mu(B(x,r))}$ is in $L^1_{loc}(\mathbb{R}^n,\mu)$?",,"['functional-analysis', 'measure-theory', 'geometric-measure-theory']"
77,"Are there two different notions of ""conditional probability""?","Are there two different notions of ""conditional probability""?",,"This question comes from reading the discussion here . (1) If one is given a ""probability measure"" $P : F \rightarrow [0,1]$ mapping a Borel $\sigma$-algebra $F$ to $[0,1]$ then for two ``random variables""/""probability distributions"",  $X: O \rightarrow S_1, Y: O \rightarrow S_2$  (mapping the underlying space to ""outcomes"" say $O$ to some set $S_1$ and $S_2$ respectively and $F$ is a $\sigma$-algebra over $O$) we can define the ""conditional probability"" as a quantity between the two random variables as the map, $$P(X\mid Y) :  S_1 \times S_2 \rightarrow [0,1]$$   $$(s_1,s_2) \rightarrow \frac { P ( X^{-1}(s_1) \cap Y^{-1}(s_2))  }{ P( Y^{-1}(s_2))}$$ (2) But if $X$ and $Y$ were two ""events"" i.e $X, Y \in F$  then its equally possible to define a conditional probability by the ``Kolmogorov definition""     $$P (X \mid Y ) = \frac { P(X \cap Y)  }{ P(Y) } $$ Are these two different notions of conditional probability?","This question comes from reading the discussion here . (1) If one is given a ""probability measure"" $P : F \rightarrow [0,1]$ mapping a Borel $\sigma$-algebra $F$ to $[0,1]$ then for two ``random variables""/""probability distributions"",  $X: O \rightarrow S_1, Y: O \rightarrow S_2$  (mapping the underlying space to ""outcomes"" say $O$ to some set $S_1$ and $S_2$ respectively and $F$ is a $\sigma$-algebra over $O$) we can define the ""conditional probability"" as a quantity between the two random variables as the map, $$P(X\mid Y) :  S_1 \times S_2 \rightarrow [0,1]$$   $$(s_1,s_2) \rightarrow \frac { P ( X^{-1}(s_1) \cap Y^{-1}(s_2))  }{ P( Y^{-1}(s_2))}$$ (2) But if $X$ and $Y$ were two ""events"" i.e $X, Y \in F$  then its equally possible to define a conditional probability by the ``Kolmogorov definition""     $$P (X \mid Y ) = \frac { P(X \cap Y)  }{ P(Y) } $$ Are these two different notions of conditional probability?",,"['probability', 'measure-theory', 'probability-distributions', 'lebesgue-measure']"
78,Radon measure and a non-L1 function,Radon measure and a non-L1 function,,"This is a part of the exercise 7.17 in Folland's Real Analysis: Suppose $\mu$ is a positive Radon measure on a locally compact Hausdorff space $X $ with $\mu (X)=\infty. $ Show that there exists $f\in C_0 (X) $ such that $\int_X f d\mu=\infty. $ I guess if we can choose a sequence of disjoint open sets having compact subsets such that the sum of measure of cpt subsets is $\infty $, then done. But the space is not normal in general.. I'm totally confused with it.","This is a part of the exercise 7.17 in Folland's Real Analysis: Suppose $\mu$ is a positive Radon measure on a locally compact Hausdorff space $X $ with $\mu (X)=\infty. $ Show that there exists $f\in C_0 (X) $ such that $\int_X f d\mu=\infty. $ I guess if we can choose a sequence of disjoint open sets having compact subsets such that the sum of measure of cpt subsets is $\infty $, then done. But the space is not normal in general.. I'm totally confused with it.",,"['real-analysis', 'measure-theory']"
79,Unable to understand what kind of pdf and its origin,Unable to understand what kind of pdf and its origin,,"I am facing difficulty in identifying how the formula given by Eq(2) in the paper Wen-Chi Tsai and Anirban DasGupta, On the Strong Consistency, Weak Limits and Practical Performance of the ML Estimate and Bayesian Estimates of a Symmetric Domain in $R^k$, Lecture Notes-Monograph Series Vol. 45, A Festschrift for Herman Rubin (2004), pp. 291-308 download link expressed as the log-likelihood $$L(p,r|x_1,\ldots,x_n) = \frac{1}{\lambda{(B_{p,r})}^n} \mathbf{1}_{(p,r):x_i \in B_{p,r}} \forall i =1,2,\ldots,n$$ comes.  In the expression $\lambda(B)$ is the Lebesgue measure of a ball $B_{p,r}$. $B_{p,r}$ denotes the centered $L_p$ ball with radius $r$ w.r.t the metric induced from $p$- norms in the $k$ -dimensional Euclidean space, $R^k$.  In general, the log-likelihood expression is expressed as the logarithm of the pdf. Here, where is the pdf and why the Lebesgue measure goes in the denominator and what is the numeral one ? I checked the references given below the formula Table of Integrals Series and Products pg 647 but could not find anything related to the pdf or the formula. Can somebody please explain what is the meaning of the expression and what is the pdf?","I am facing difficulty in identifying how the formula given by Eq(2) in the paper Wen-Chi Tsai and Anirban DasGupta, On the Strong Consistency, Weak Limits and Practical Performance of the ML Estimate and Bayesian Estimates of a Symmetric Domain in $R^k$, Lecture Notes-Monograph Series Vol. 45, A Festschrift for Herman Rubin (2004), pp. 291-308 download link expressed as the log-likelihood $$L(p,r|x_1,\ldots,x_n) = \frac{1}{\lambda{(B_{p,r})}^n} \mathbf{1}_{(p,r):x_i \in B_{p,r}} \forall i =1,2,\ldots,n$$ comes.  In the expression $\lambda(B)$ is the Lebesgue measure of a ball $B_{p,r}$. $B_{p,r}$ denotes the centered $L_p$ ball with radius $r$ w.r.t the metric induced from $p$- norms in the $k$ -dimensional Euclidean space, $R^k$.  In general, the log-likelihood expression is expressed as the logarithm of the pdf. Here, where is the pdf and why the Lebesgue measure goes in the denominator and what is the numeral one ? I checked the references given below the formula Table of Integrals Series and Products pg 647 but could not find anything related to the pdf or the formula. Can somebody please explain what is the meaning of the expression and what is the pdf?",,"['measure-theory', 'reference-request', 'probability-distributions', 'lebesgue-measure']"
80,Does $\left\|u_n-u\right\|_{L^2(\Omega)}\stackrel{n\to\infty}{\to}0$ imply $u\in L^2(\Omega)$?,Does  imply ?,\left\|u_n-u\right\|_{L^2(\Omega)}\stackrel{n\to\infty}{\to}0 u\in L^2(\Omega),"Let $\Omega\subseteq\mathbb{R}^n$ be bounded, $u\in C^0(\Omega)$ and $(u_n)_{n\in\mathbb{N}}\subseteq C_0^0(\Omega)$ with $$\left\|u_n-u\right\|_{L^2(\Omega)}\stackrel{n\to\infty}{\to}0\tag{1}$$ Can we conclude $u\in L^2(\Omega)$ from $(1)$? Note : $C_0(\Omega)$ is the set of all functions $\Omega\to\mathbb{R}$ that vanish at infinity .","Let $\Omega\subseteq\mathbb{R}^n$ be bounded, $u\in C^0(\Omega)$ and $(u_n)_{n\in\mathbb{N}}\subseteq C_0^0(\Omega)$ with $$\left\|u_n-u\right\|_{L^2(\Omega)}\stackrel{n\to\infty}{\to}0\tag{1}$$ Can we conclude $u\in L^2(\Omega)$ from $(1)$? Note : $C_0(\Omega)$ is the set of all functions $\Omega\to\mathbb{R}$ that vanish at infinity .",,"['real-analysis', 'measure-theory', 'convergence-divergence', 'lebesgue-integral']"
81,Steinhaus-like problem,Steinhaus-like problem,,"I know there are similar problems on here, but I believe this is not a duplicate. Let $E \subset \mathbb{R}$ be a measurable set of positive finite measure. Define $f:[0,\infty) \rightarrow \mathbb R$ by  $$f(t)= m(E \cap E_t),$$ where $E_t=\{t+x:x\in E\}$. Prove that $f$ is continuous on $[0,\infty)$. I wanted to rewrite $f$ as a convolution of two sufficiently nice functions (in this case $L^1$ and $L^\infty$) which we know to be continuous: $$f(t)=\int_{E\cap E_t}1 dx= \int_E 1_{E_t} dx= \int_E 1_{E}(x-t) dx=\int_{\mathbb R} 1_{-E}(t-x) 1_E dx= 1_{-E}*1_E(t), $$ and $1_{-E}$ is $L^1$ and $1_E$ is $L^\infty$. Alternative solutions (assuming this actually is one) are welcome, too. Also, a good reference for convolution results like the one used here would be much appreciated.","I know there are similar problems on here, but I believe this is not a duplicate. Let $E \subset \mathbb{R}$ be a measurable set of positive finite measure. Define $f:[0,\infty) \rightarrow \mathbb R$ by  $$f(t)= m(E \cap E_t),$$ where $E_t=\{t+x:x\in E\}$. Prove that $f$ is continuous on $[0,\infty)$. I wanted to rewrite $f$ as a convolution of two sufficiently nice functions (in this case $L^1$ and $L^\infty$) which we know to be continuous: $$f(t)=\int_{E\cap E_t}1 dx= \int_E 1_{E_t} dx= \int_E 1_{E}(x-t) dx=\int_{\mathbb R} 1_{-E}(t-x) 1_E dx= 1_{-E}*1_E(t), $$ and $1_{-E}$ is $L^1$ and $1_E$ is $L^\infty$. Alternative solutions (assuming this actually is one) are welcome, too. Also, a good reference for convolution results like the one used here would be much appreciated.",,"['real-analysis', 'measure-theory', 'convolution']"
82,"Prove $\int_X |f|^p=p\int^{\infty}_{0} t^{p-1}\mu({x: |f(x)>t}) dt\,$ [duplicate]",Prove  [duplicate],"\int_X |f|^p=p\int^{\infty}_{0} t^{p-1}\mu({x: |f(x)>t}) dt\,","This question already has answers here : Proof of $\int_{[0,\infty)}pt^{p-1}\mu(\{x:|f(x)|\geq t\})d\mu(t)=\int_{[0,\infty)}\mu(\{x:|f(x)|^p\geq s\})d\mu(s)$ (4 answers) Closed 6 years ago . Let $(X,\mathcal{M},\mu)$ be a measure space and $f$ be a nonnegative measurable function on $X$. Let $1\le p<\infty$. Show that, the function $|f|^p$ is integrable with respect to $\mu$ precisely when the function $$t\mapsto t^{p-1}\mu({x:|f(x)>t})$$ is integrable on $[0,\infty)$ with respect to Lebesgue measure. In addition prove that    $$\int_X |f|^p=p\int^{\infty}_{0} t^{p-1}\mu({x: |f(x)>t}) dt\,$$ I solved this problem for the case when space is sigma finite but don't know how to solve for general case.","This question already has answers here : Proof of $\int_{[0,\infty)}pt^{p-1}\mu(\{x:|f(x)|\geq t\})d\mu(t)=\int_{[0,\infty)}\mu(\{x:|f(x)|^p\geq s\})d\mu(s)$ (4 answers) Closed 6 years ago . Let $(X,\mathcal{M},\mu)$ be a measure space and $f$ be a nonnegative measurable function on $X$. Let $1\le p<\infty$. Show that, the function $|f|^p$ is integrable with respect to $\mu$ precisely when the function $$t\mapsto t^{p-1}\mu({x:|f(x)>t})$$ is integrable on $[0,\infty)$ with respect to Lebesgue measure. In addition prove that    $$\int_X |f|^p=p\int^{\infty}_{0} t^{p-1}\mu({x: |f(x)>t}) dt\,$$ I solved this problem for the case when space is sigma finite but don't know how to solve for general case.",,['measure-theory']
83,An example where Egorov's theorem fails,An example where Egorov's theorem fails,,"This is p.62 of Folland Real Analysis book. Here the measure of X is supposed to be finite. But, I want to know the case in which the theorem doesn't work if X is of infinite measure. I tried to think of one myself, but have failed.. Could anyone show me some example?","This is p.62 of Folland Real Analysis book. Here the measure of X is supposed to be finite. But, I want to know the case in which the theorem doesn't work if X is of infinite measure. I tried to think of one myself, but have failed.. Could anyone show me some example?",,"['real-analysis', 'measure-theory']"
84,A question about non-negative measurable function,A question about non-negative measurable function,,"Here is the proposition that I see in Rudin's Real and Complex analysis Suppose $f$ is a measurable function into $[0,\infty]$ and $E$ is a measurable set with respect to the measure $\mu$ Let $c$ be a constant, $0 \leq c < \infty$ Then, $\int_Ecfd\mu = c\int_Efd\mu$ I am wondering why we do not allow c to be $\infty$. If $c$ is allowed to be $\infty$, then $\int_Ecfd\mu = c\int_Efd\mu$  is not true anymore?","Here is the proposition that I see in Rudin's Real and Complex analysis Suppose $f$ is a measurable function into $[0,\infty]$ and $E$ is a measurable set with respect to the measure $\mu$ Let $c$ be a constant, $0 \leq c < \infty$ Then, $\int_Ecfd\mu = c\int_Efd\mu$ I am wondering why we do not allow c to be $\infty$. If $c$ is allowed to be $\infty$, then $\int_Ecfd\mu = c\int_Efd\mu$  is not true anymore?",,['measure-theory']
85,Proof of fractal dimension of Thomae's function,Proof of fractal dimension of Thomae's function,,"Thomae's function is defined to be $0$ if x is irrational. Its defined to be $1 \over q$ where $x={p \over q}$ in lowest terms and $q \gt 0$. Its measure is $0$ since the set of rational numbers is countable. However, it seems that this function might be a fractal and/or have fractal dimension. If it does, how does one find this fractal dimension? A proof or reference would be appreciated.","Thomae's function is defined to be $0$ if x is irrational. Its defined to be $1 \over q$ where $x={p \over q}$ in lowest terms and $q \gt 0$. Its measure is $0$ since the set of rational numbers is countable. However, it seems that this function might be a fractal and/or have fractal dimension. If it does, how does one find this fractal dimension? A proof or reference would be appreciated.",,"['measure-theory', 'fractals', 'dimension-theory-analysis']"
86,"Suppose $f$ is nonnegative and integrable on some measure space $(X, \mathcal{A}, \nu)$. Show $\lim_{t\to+\infty}t \cdot \nu(f \geq t) = 0$",Suppose  is nonnegative and integrable on some measure space . Show,"f (X, \mathcal{A}, \nu) \lim_{t\to+\infty}t \cdot \nu(f \geq t) = 0","Suppose $f$ is nonnegative and integrable on some measure space $(X, \mathcal{A}, \nu)$. Show $\lim_{t\to+\infty}t \cdot \nu(f \geq t) = 0$. My first attempt is to use Fubini to get $$ \int_X f \, d\nu = \int_0^\infty \nu( f\geq t ) \, dt \,\, . $$ Here $(f \geq t) = \big\{ x\in X \,:\, f(x) \geq t \big\}$. It is clear that  $\lim_{t\to+\infty} \nu(f \geq t) = 0$. And intuitively, the function $t\longmapsto \nu(f \geq t)$ is a decreasing integrable function, its tail may behave like $t^{-\beta}$ with $\beta > 1$, in this case the desired result follows. More work is needed and any comment is highly appreciated. THANKS!","Suppose $f$ is nonnegative and integrable on some measure space $(X, \mathcal{A}, \nu)$. Show $\lim_{t\to+\infty}t \cdot \nu(f \geq t) = 0$. My first attempt is to use Fubini to get $$ \int_X f \, d\nu = \int_0^\infty \nu( f\geq t ) \, dt \,\, . $$ Here $(f \geq t) = \big\{ x\in X \,:\, f(x) \geq t \big\}$. It is clear that  $\lim_{t\to+\infty} \nu(f \geq t) = 0$. And intuitively, the function $t\longmapsto \nu(f \geq t)$ is a decreasing integrable function, its tail may behave like $t^{-\beta}$ with $\beta > 1$, in this case the desired result follows. More work is needed and any comment is highly appreciated. THANKS!",,"['integration', 'measure-theory']"
87,Questions regarding the Proof of Egorov's Theorem (Carothers),Questions regarding the Proof of Egorov's Theorem (Carothers),,"Egorov's Theorem Let $(f_n)$ be a sequence of measurable functions converging pointwise almost everywhere to a real-valued function $f$ on a measurable set $D$ of finite measure. Then for $\epsilon>0$, there is a measurable set $E\subset D$ such that $m(E)<\epsilon$ and such that $(f_n)$ converges uniformly to $f$ on $D\setminus E$. Proof given in Carother's Real Analysis Suppose $f_n\to f$ everywhere on $D$. For each $n,k$, consider $$E(n,k)=\bigcup_{m=n}^{\infty}\left\{x\in D: |f_m(x)-f(x)|\geq \frac{1}{k}\right\}$$ If $k$ is fixed and $n\to\infty$, these sets $E(n,k)$ decrease. $\color{blue}{\text{In fact, $\cap_{n=1}^{\infty}=\emptyset$, since $f_n\to f$ everywhere on $D$.}} $   Since $m(D)<\infty$, we have $m(E(n,k))\to 0$ as $n\to \infty$. $\color{blue}{\text{Then we may choose a subsequence $(n_k)$ for which $m(E(n_k,k))<\frac{\epsilon}{2^k}$.}}$ Now if we set $E=\cup_{k=1}^{\infty}E(n_k,k)$, $\color{blue}{\text{then $m(E)<\epsilon$}}$. What's more, for $x\notin E$, we have $x\notin E(n_k,k)$ for all $k$. In particular $|f_m(x)-f(x)|<\frac{1}{k}$ for all $m\geq n_k$. $\color{blue}{\text{Hence $f_n$ converges uniformly to $f$ on $D\setminus E$.}}$ The parts in blue are the parts where I have some questions about. Questions: Why does $f_n\to f$ make the infinite intersection of the $E(n,k)$ have to be empty? How are we guaranteed the existence of a subsequence (does this follow from the fact that $f_n\to f$?) Why is $m(E)<\epsilon$? (Is this because  $E(n,k)$ is decreasing?) Why is the convergence uniform? Isn't it just pointwise? The proof still hasn't shown that $\sup_{x\in E}|f_m(x)-f(x)|<\frac{1}{k}$, has it?","Egorov's Theorem Let $(f_n)$ be a sequence of measurable functions converging pointwise almost everywhere to a real-valued function $f$ on a measurable set $D$ of finite measure. Then for $\epsilon>0$, there is a measurable set $E\subset D$ such that $m(E)<\epsilon$ and such that $(f_n)$ converges uniformly to $f$ on $D\setminus E$. Proof given in Carother's Real Analysis Suppose $f_n\to f$ everywhere on $D$. For each $n,k$, consider $$E(n,k)=\bigcup_{m=n}^{\infty}\left\{x\in D: |f_m(x)-f(x)|\geq \frac{1}{k}\right\}$$ If $k$ is fixed and $n\to\infty$, these sets $E(n,k)$ decrease. $\color{blue}{\text{In fact, $\cap_{n=1}^{\infty}=\emptyset$, since $f_n\to f$ everywhere on $D$.}} $   Since $m(D)<\infty$, we have $m(E(n,k))\to 0$ as $n\to \infty$. $\color{blue}{\text{Then we may choose a subsequence $(n_k)$ for which $m(E(n_k,k))<\frac{\epsilon}{2^k}$.}}$ Now if we set $E=\cup_{k=1}^{\infty}E(n_k,k)$, $\color{blue}{\text{then $m(E)<\epsilon$}}$. What's more, for $x\notin E$, we have $x\notin E(n_k,k)$ for all $k$. In particular $|f_m(x)-f(x)|<\frac{1}{k}$ for all $m\geq n_k$. $\color{blue}{\text{Hence $f_n$ converges uniformly to $f$ on $D\setminus E$.}}$ The parts in blue are the parts where I have some questions about. Questions: Why does $f_n\to f$ make the infinite intersection of the $E(n,k)$ have to be empty? How are we guaranteed the existence of a subsequence (does this follow from the fact that $f_n\to f$?) Why is $m(E)<\epsilon$? (Is this because  $E(n,k)$ is decreasing?) Why is the convergence uniform? Isn't it just pointwise? The proof still hasn't shown that $\sup_{x\in E}|f_m(x)-f(x)|<\frac{1}{k}$, has it?",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
88,"If $f$ is measurable and $\int f < \infty$, then $f(x) < \infty$ a.e.","If  is measurable and , then  a.e.",f \int f < \infty f(x) < \infty,"I am looking for a hint for what should be a simple proof, but once again I am missing the key connection. Please don't provide a complete solution, nudge me to discover what I am missing. If $f$ is a measurable non-negative function and $\int f < \infty$, then $\{x : f(x) = \infty \}$ is a null set. What I am attempting: Define a function $g(x)$ as follows: $$g(x) = \left\{\begin{array}{ll} a, & \textrm{if} f(x) = \infty, \\ f(x), & \textrm{otherwise}.\end{array}\right.$$ Then, we have a proposition that states that for measurable $h$, $\int h = 0 \iff h = 0$ a.e. So what I'm trying to do is set $h = f-g$ and show that $\int h = \int f-g = 0$. This would complete the proof. If $A = \{x : f(x) = \infty\}$, then I have $\int g = \int_{A^C} g + \int_A g = \int_{A^C} f+ a\mu(A)$. I want to use this in some way to conclude that $\mu(A) = 0$ necessarily. The only hypothesis I have to work with is $\int f < \infty$. I'm not sure if this is the right approach. Intuitively, I know exactly what the statement means. I just can't identify the machinery needed to get to the conclusion.","I am looking for a hint for what should be a simple proof, but once again I am missing the key connection. Please don't provide a complete solution, nudge me to discover what I am missing. If $f$ is a measurable non-negative function and $\int f < \infty$, then $\{x : f(x) = \infty \}$ is a null set. What I am attempting: Define a function $g(x)$ as follows: $$g(x) = \left\{\begin{array}{ll} a, & \textrm{if} f(x) = \infty, \\ f(x), & \textrm{otherwise}.\end{array}\right.$$ Then, we have a proposition that states that for measurable $h$, $\int h = 0 \iff h = 0$ a.e. So what I'm trying to do is set $h = f-g$ and show that $\int h = \int f-g = 0$. This would complete the proof. If $A = \{x : f(x) = \infty\}$, then I have $\int g = \int_{A^C} g + \int_A g = \int_{A^C} f+ a\mu(A)$. I want to use this in some way to conclude that $\mu(A) = 0$ necessarily. The only hypothesis I have to work with is $\int f < \infty$. I'm not sure if this is the right approach. Intuitively, I know exactly what the statement means. I just can't identify the machinery needed to get to the conclusion.",,"['integration', 'measure-theory']"
89,Almost every $x$ is a cluster point of its own trajectory.,Almost every  is a cluster point of its own trajectory.,x,"The following problem appears in [1]: 2.3.2(a) Let $(X, d)$ be a compact metric space and let $T:X \rightarrow X$ be a continuous map. Suppose that $\mu$ is a $T$-invariant probability measure defined on the Borel subsets of $X$. Prove that for $\mu$-almost every $x \in X$ there is a sequence $n_k \rightarrow \infty$ with $T^{n_k}(x) \rightarrow x$ as $k \rightarrow \infty$. (b) Prove that the same conclusion holds under the assumption that $X$ is a metric space, $T:X \rightarrow X$ is Borel measurable, and $\mu$ is a $T$-invariant probability measure. This question appears in the section on Poincar recurrence. Intuitively, it makes sense and should obviously be true. However, I am having difficulty writing a nice proof, mainly from the fact that $x$ is a specific point in its own neighborhood, and I cannot be certain when changing neighborhoods that the collection of almost every point returning is the same. My intuition is telling me that I might be able to use the Lebesgue number of an open cover of $\varepsilon$-balls to simplify the argument. However, part (b) does not assume compactness (or even completeness). What I want to say is: Let $A_k = \{x \in X : \exists n_k \in \mathbb{N}, T^{n_k}(x) \in B_k(x)\}$, where $B_k(x) = \{y \in X : d(x, y) < 1/k\}$, for all $k \in \mathbb{N}$. By Poincar recurrence, $\mu(A_k) = \mu(X) < \infty$. Let $B = \cap_{j=1}^\infty A_j$. Then, $B$ is precisely $\{x \in X : \exists n_k \rightarrow \infty, T^{n_k}(x) \rightarrow x \mathrm{\ as\ } k \rightarrow \infty\}$, and $\mu(B) = \mu(X)$. Question: How can I fix this to make a correct (and not ugly) proof? [1] Einsiedler, M., & Ward, T. (2011). Ergodic theory: With a view towards number theory . London: Springer-Verlag.","The following problem appears in [1]: 2.3.2(a) Let $(X, d)$ be a compact metric space and let $T:X \rightarrow X$ be a continuous map. Suppose that $\mu$ is a $T$-invariant probability measure defined on the Borel subsets of $X$. Prove that for $\mu$-almost every $x \in X$ there is a sequence $n_k \rightarrow \infty$ with $T^{n_k}(x) \rightarrow x$ as $k \rightarrow \infty$. (b) Prove that the same conclusion holds under the assumption that $X$ is a metric space, $T:X \rightarrow X$ is Borel measurable, and $\mu$ is a $T$-invariant probability measure. This question appears in the section on Poincar recurrence. Intuitively, it makes sense and should obviously be true. However, I am having difficulty writing a nice proof, mainly from the fact that $x$ is a specific point in its own neighborhood, and I cannot be certain when changing neighborhoods that the collection of almost every point returning is the same. My intuition is telling me that I might be able to use the Lebesgue number of an open cover of $\varepsilon$-balls to simplify the argument. However, part (b) does not assume compactness (or even completeness). What I want to say is: Let $A_k = \{x \in X : \exists n_k \in \mathbb{N}, T^{n_k}(x) \in B_k(x)\}$, where $B_k(x) = \{y \in X : d(x, y) < 1/k\}$, for all $k \in \mathbb{N}$. By Poincar recurrence, $\mu(A_k) = \mu(X) < \infty$. Let $B = \cap_{j=1}^\infty A_j$. Then, $B$ is precisely $\{x \in X : \exists n_k \rightarrow \infty, T^{n_k}(x) \rightarrow x \mathrm{\ as\ } k \rightarrow \infty\}$, and $\mu(B) = \mu(X)$. Question: How can I fix this to make a correct (and not ugly) proof? [1] Einsiedler, M., & Ward, T. (2011). Ergodic theory: With a view towards number theory . London: Springer-Verlag.",,['measure-theory']
90,Proving set of density points is an open set,Proving set of density points is an open set,,"Let $A\subset\mathbb{R}$ measurable and denote the set of density points $$\tilde{A}:=\{x\in\mathbb{R}\mid \lim_{\epsilon\to 0}\frac{m([x-\epsilon,x+\epsilon]\cap A)}{2\epsilon}=1\}$$Porve/Dsiprove this set is open. I thought building a set $A$ which it's density points are a finite number of singletons (or countable) and then it'll contradict the claim above. My question is how can I build a set based on number of density points? More specific: Does exist a set $A\subset \mathbb{R}$ with finitely number of density points or s.t $|\tilde{A}|<\infty$?","Let $A\subset\mathbb{R}$ measurable and denote the set of density points $$\tilde{A}:=\{x\in\mathbb{R}\mid \lim_{\epsilon\to 0}\frac{m([x-\epsilon,x+\epsilon]\cap A)}{2\epsilon}=1\}$$Porve/Dsiprove this set is open. I thought building a set $A$ which it's density points are a finite number of singletons (or countable) and then it'll contradict the claim above. My question is how can I build a set based on number of density points? More specific: Does exist a set $A\subset \mathbb{R}$ with finitely number of density points or s.t $|\tilde{A}|<\infty$?",,"['real-analysis', 'measure-theory']"
91,An exercise on an integral inequality,An exercise on an integral inequality,,"I need help with this exercise: let   $f,g,h : [0,1]  \to  [0,\infty] $ integrable functions. Prove that the following statements are equivalent: i) $(f(x))^2 \leq g(x)h(x) $ almost everywhere. ii) For every measurable set $E \subset [0,1] $ we have: $$\left(\displaystyle\int_E f(x)dx\right)^2 \leq \displaystyle\int_E g(x)dx\displaystyle\int_E h(x)dx.$$ I proved that $ i) \Rightarrow ii) $ with Holder inequality, but i have some problems with the other implication.","I need help with this exercise: let   $f,g,h : [0,1]  \to  [0,\infty] $ integrable functions. Prove that the following statements are equivalent: i) $(f(x))^2 \leq g(x)h(x) $ almost everywhere. ii) For every measurable set $E \subset [0,1] $ we have: $$\left(\displaystyle\int_E f(x)dx\right)^2 \leq \displaystyle\int_E g(x)dx\displaystyle\int_E h(x)dx.$$ I proved that $ i) \Rightarrow ii) $ with Holder inequality, but i have some problems with the other implication.",,"['measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
92,"If $\lim_{n \to \infty} \int f^{2n} \, d\mu$ exists, then $|f| \leq 1$ $\mu$-almost everywhere.","If  exists, then  -almost everywhere.","\lim_{n \to \infty} \int f^{2n} \, d\mu |f| \leq 1 \mu","Let $(X,A,\mu)$ be a finite measure space and $f\in M(A)$ (so $f$ is measurable) en $f^n \in L^1(\mu)$ (Lebesgue integrable) for all $n\geq 1$. Show that if $\lim_{n \to \infty} \int f^n \, d \mu$ exists and is finite than $|f(x)|\leq$ 1 $\mu$ a.e","Let $(X,A,\mu)$ be a finite measure space and $f\in M(A)$ (so $f$ is measurable) en $f^n \in L^1(\mu)$ (Lebesgue integrable) for all $n\geq 1$. Show that if $\lim_{n \to \infty} \int f^n \, d \mu$ exists and is finite than $|f(x)|\leq$ 1 $\mu$ a.e",,['measure-theory']
93,Measure theory exercise,Measure theory exercise,,"From measure theory volume 1 by Fremlin, exercise 111Xf: Let $X$ be a set, $\mathcal{A}$ a family of subsets of $X$, and $\Sigma$ the $\sigma$-algebra of subsets of $X$ generated by $\mathcal{A}$. Suppose that $Y\subset X$. Show that  ${\{E \cap Y : E \in \Sigma}\}$  is the -algebra of subsets of $Y$ generated by ${\{A \cap Y : A \in \mathcal{A}}\}$. I'm able to show that it's a $\sigma$-algebra, and clearly it contains the $\sigma$-algebra generated by ${\{A \cap Y : A \in \mathcal{A}}\}$, but I don't know how to show ${\{E \cap Y : E \in \Sigma}\}$ $\subseteq\sigma (\{{A \cap Y : A \in \mathcal{A}}\})$.","From measure theory volume 1 by Fremlin, exercise 111Xf: Let $X$ be a set, $\mathcal{A}$ a family of subsets of $X$, and $\Sigma$ the $\sigma$-algebra of subsets of $X$ generated by $\mathcal{A}$. Suppose that $Y\subset X$. Show that  ${\{E \cap Y : E \in \Sigma}\}$  is the -algebra of subsets of $Y$ generated by ${\{A \cap Y : A \in \mathcal{A}}\}$. I'm able to show that it's a $\sigma$-algebra, and clearly it contains the $\sigma$-algebra generated by ${\{A \cap Y : A \in \mathcal{A}}\}$, but I don't know how to show ${\{E \cap Y : E \in \Sigma}\}$ $\subseteq\sigma (\{{A \cap Y : A \in \mathcal{A}}\})$.",,['measure-theory']
94,Prove or disprove $\nu(E)=\lambda(f(E))$ is a measure provided that $f$ is nondecreasing and satisfies the N-condition.,Prove or disprove  is a measure provided that  is nondecreasing and satisfies the N-condition.,\nu(E)=\lambda(f(E)) f,"Suppose $f$ is a non-decreasing continuous function from $[a,b]$ to $\mathbb{R}$, and $\lambda$ is the Lebesgue measure in $\mathbb{R^1}$. Also, $f$ satisfies the property that $f$ maps Lebesgue measurable set to Lebesgue measurable set. Prove or disprove $\nu(E)=\lambda(f(E))$ is a measure. Based on the hypothesis above, if $f$ also maps zero measurable set to zero measurable set, prove or disprove $\nu(E)=\lambda(f(E))$ is a measure. For the first question, I don't believe $\nu$ is a measure, but I don't have a good example at hand. For the second question, I learned from somewhere that $f$ is actually absolutely continuous, thus $\nu$ has to be a measure. But I don't know how to prove this directly without proving $f$ is absolutely continous. Any ideas would be appreciated.","Suppose $f$ is a non-decreasing continuous function from $[a,b]$ to $\mathbb{R}$, and $\lambda$ is the Lebesgue measure in $\mathbb{R^1}$. Also, $f$ satisfies the property that $f$ maps Lebesgue measurable set to Lebesgue measurable set. Prove or disprove $\nu(E)=\lambda(f(E))$ is a measure. Based on the hypothesis above, if $f$ also maps zero measurable set to zero measurable set, prove or disprove $\nu(E)=\lambda(f(E))$ is a measure. For the first question, I don't believe $\nu$ is a measure, but I don't have a good example at hand. For the second question, I learned from somewhere that $f$ is actually absolutely continuous, thus $\nu$ has to be a measure. But I don't know how to prove this directly without proving $f$ is absolutely continous. Any ideas would be appreciated.",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
95,limsup of measurable functions is not measurable?,limsup of measurable functions is not measurable?,,"Suppose $f_r(x)$ is measurable for any fixed $r>0$, I was wondering whether $\limsup_{r\to 0^+}f_r(x)$ is measurable. I know the limsup of sequence of measurable functions is measurable, and I also know for each $x$, $\limsup f_r(x)$ will be achieved by a sequence of $\big(f_{r_i}(x)\big)_i$, with $r_i\to 0$, but the problem is that I still don't know how to write $\{x|\limsup_{r\to 0^+}f_r(x)\le a\}$ as a countable union of measurable sets since it seems the sup is taken in an uncountable set. I know if $f_r(x)$ is continuous, then we have $$\{x|\limsup_{r\to 0^+}f_r(x)\le a\}=\{x|\lim_{k\to \infty}\sup_{0<r<\frac{1}{k},r\in \mathbb{Q}}f_r(x)\le a\}$$ which is countable, hence $\limsup_{r\to 0^+}f_r(x)$ is measurable. Is it hold for general $f_r$? How about $f_r$ be semi-continuous?","Suppose $f_r(x)$ is measurable for any fixed $r>0$, I was wondering whether $\limsup_{r\to 0^+}f_r(x)$ is measurable. I know the limsup of sequence of measurable functions is measurable, and I also know for each $x$, $\limsup f_r(x)$ will be achieved by a sequence of $\big(f_{r_i}(x)\big)_i$, with $r_i\to 0$, but the problem is that I still don't know how to write $\{x|\limsup_{r\to 0^+}f_r(x)\le a\}$ as a countable union of measurable sets since it seems the sup is taken in an uncountable set. I know if $f_r(x)$ is continuous, then we have $$\{x|\limsup_{r\to 0^+}f_r(x)\le a\}=\{x|\lim_{k\to \infty}\sup_{0<r<\frac{1}{k},r\in \mathbb{Q}}f_r(x)\le a\}$$ which is countable, hence $\limsup_{r\to 0^+}f_r(x)$ is measurable. Is it hold for general $f_r$? How about $f_r$ be semi-continuous?",,"['real-analysis', 'measure-theory']"
96,Convolution of two indicator functions can't be constant,Convolution of two indicator functions can't be constant,,"Let $A,B \subset S^1$ be measurable sets (considering $S^1$ with say the lebesgue measure). I'm trying to prove that if the convolution $1_A*1_B$ is constant then one of $A$ or $B$ is a full measure set or one of them is of measure zero. I didn't make much progress but i'm pretty sure that the measure of the intersection of two sets can't be invariant to translation of one of the sets. It's just too pathological. Thank you for the help.","Let $A,B \subset S^1$ be measurable sets (considering $S^1$ with say the lebesgue measure). I'm trying to prove that if the convolution $1_A*1_B$ is constant then one of $A$ or $B$ is a full measure set or one of them is of measure zero. I didn't make much progress but i'm pretty sure that the measure of the intersection of two sets can't be invariant to translation of one of the sets. It's just too pathological. Thank you for the help.",,"['measure-theory', 'convolution']"
97,Convergence of $f_n(x) = 2^n \cdot F(2^n (x-a_n))$ with $F(x) = e^{-x^2}$ with different notions of convergence.,Convergence of  with  with different notions of convergence.,f_n(x) = 2^n \cdot F(2^n (x-a_n)) F(x) = e^{-x^2},"I had my measure theory exam this morning, and one exercise was the following: I really can't see a solution. During the semester, we talked about almost everywhere convergence, almost uniform convergence, convergence in measure an convergence in $L^p$. The problem is as follows: Let be $(a_n)_n$ be a real sequence and let $F(x)=e^{-x^2}$. Define $$f_n(x)=2^nF(2^n(x-a_n))$$ for all $x\in \Bbb{R}$ and all $n \in \Bbb{N}$. Show if and in which meaning of convergence $F_n(x)$ converges to (some) $f$ and in that case if $$\int f=\lim_{n \to +\infty} \int f_n.$$ This is my first post, I hope I did not miss anything. My attempt: I noticed that $$\int f_n=\sqrt{\pi}$$ (it's quite trivial to prove this, just some substitution) and so I think that $f_n$ can converge to $F$ in $L^p$, the proof will be easy if I find a way to show that $f_n<F$ or $F<f_n$ but I can't show that (if it's possible).","I had my measure theory exam this morning, and one exercise was the following: I really can't see a solution. During the semester, we talked about almost everywhere convergence, almost uniform convergence, convergence in measure an convergence in $L^p$. The problem is as follows: Let be $(a_n)_n$ be a real sequence and let $F(x)=e^{-x^2}$. Define $$f_n(x)=2^nF(2^n(x-a_n))$$ for all $x\in \Bbb{R}$ and all $n \in \Bbb{N}$. Show if and in which meaning of convergence $F_n(x)$ converges to (some) $f$ and in that case if $$\int f=\lim_{n \to +\infty} \int f_n.$$ This is my first post, I hope I did not miss anything. My attempt: I noticed that $$\int f_n=\sqrt{\pi}$$ (it's quite trivial to prove this, just some substitution) and so I think that $f_n$ can converge to $F$ in $L^p$, the proof will be easy if I find a way to show that $f_n<F$ or $F<f_n$ but I can't show that (if it's possible).",,"['measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
98,Dominated convergence theorem for finitely additive measures.,Dominated convergence theorem for finitely additive measures.,,"Let $\Omega\subset\mathbb{R}^N$ be a bounded domain and $\mu$ a finitely additive, finite signed measure, which is absolutely continuous with respect to the Lebesgue measure in $\Omega$. Let $\phi_n\in L^\infty(\Omega)$, $\phi\in L^\infty(\Omega)$. Assume that $\phi_n(x)\to \phi(x)$ for a.e. (Lebesgue measure) $x\in \overline{\Omega}$, $\|\phi_n\|_\infty <M$. May I conclude that $$\int_\Omega \phi_nd\mu\to\int_\Omega \phi d\mu. \tag{1}$$ Once $\mu$ is only finitely additive, the Dominated Convergence Theorem does not work, however, as we have that $\mu$ is absolutely continuous with respect to the Lebesgue measure in $\Omega$, maybe we can use this fact to prove the result, or maybe there is also a counter example. If we can prove that $\phi_n\to \phi$ in $\mu$-measure, we are done, however I could not prove it also. This problem comes from my answer here . In that answer, I used Dominated Convergence Theorem (which is not immediately true) to prove the limit $$\int_\Omega \frac{\partial (u\gamma_n-u)}{\partial x_i}d\mu_i\to 0.$$ I think that this limit is really zero and that I can save the answer. Remark: If necessary, we can assume that the support of $\phi_n$ is contained in the set $$\{x\in \Omega:\ \operatorname{dist}(x,\partial\Omega)<1/n\}.$$","Let $\Omega\subset\mathbb{R}^N$ be a bounded domain and $\mu$ a finitely additive, finite signed measure, which is absolutely continuous with respect to the Lebesgue measure in $\Omega$. Let $\phi_n\in L^\infty(\Omega)$, $\phi\in L^\infty(\Omega)$. Assume that $\phi_n(x)\to \phi(x)$ for a.e. (Lebesgue measure) $x\in \overline{\Omega}$, $\|\phi_n\|_\infty <M$. May I conclude that $$\int_\Omega \phi_nd\mu\to\int_\Omega \phi d\mu. \tag{1}$$ Once $\mu$ is only finitely additive, the Dominated Convergence Theorem does not work, however, as we have that $\mu$ is absolutely continuous with respect to the Lebesgue measure in $\Omega$, maybe we can use this fact to prove the result, or maybe there is also a counter example. If we can prove that $\phi_n\to \phi$ in $\mu$-measure, we are done, however I could not prove it also. This problem comes from my answer here . In that answer, I used Dominated Convergence Theorem (which is not immediately true) to prove the limit $$\int_\Omega \frac{\partial (u\gamma_n-u)}{\partial x_i}d\mu_i\to 0.$$ I think that this limit is really zero and that I can save the answer. Remark: If necessary, we can assume that the support of $\phi_n$ is contained in the set $$\{x\in \Omega:\ \operatorname{dist}(x,\partial\Omega)<1/n\}.$$",,['measure-theory']
99,Conditions on integration by parts with unbounded endpoint,Conditions on integration by parts with unbounded endpoint,,"I have the following theorem for integration by parts when both endpoints are finite: (Lebesgue integrals are used throughout) Let $a\le b$ be real numbers, and $f,g$ be functions continuous on $[a,b]$ and differentiable on $(a,b)$, such that $f\cdot g'$ and $f'\cdot g$ are Lebesgue integrable on $(a,b)$. Then:   $$\int_{(a,b)}f\cdot g'=(f(b)g(b)-f(a)g(a))-\int_{(a,b)}f'\cdot g.$$ I would like to extend this theorem to the case when the interval of integration is right-unbounded. What is the most natural statement for this case? I don't think that continuous on $[a,\infty)$ and differentiable on $(a,\infty)$ is sufficient, since the direct analogue would be ""continuous on $[a,\infty]$"" which suggests that the behavior at $\infty$ needs to be controlled in some way - I suspect that it should be sufficient to require that the real limit of the function exist. That said, how is something like this proven? In principle I should just be able to take a limit as $b\to\infty$ in the above theorem, but what is the appropriate theorem for taking the limit of a sequence of base sets in an integral? Something like: If $A_n$ is a sequence of subsets of $\Bbb R$ satisfying <condition> and $f:\bigcup_n A_n\to\Bbb C$ is Lebesgue integrable on each $A_n$, and $A=\lim_n A_n$ (whatever that means), then $f$ is integrable on $A$ and $$\int_A f=\lim_n\int_{A_n}f.$$","I have the following theorem for integration by parts when both endpoints are finite: (Lebesgue integrals are used throughout) Let $a\le b$ be real numbers, and $f,g$ be functions continuous on $[a,b]$ and differentiable on $(a,b)$, such that $f\cdot g'$ and $f'\cdot g$ are Lebesgue integrable on $(a,b)$. Then:   $$\int_{(a,b)}f\cdot g'=(f(b)g(b)-f(a)g(a))-\int_{(a,b)}f'\cdot g.$$ I would like to extend this theorem to the case when the interval of integration is right-unbounded. What is the most natural statement for this case? I don't think that continuous on $[a,\infty)$ and differentiable on $(a,\infty)$ is sufficient, since the direct analogue would be ""continuous on $[a,\infty]$"" which suggests that the behavior at $\infty$ needs to be controlled in some way - I suspect that it should be sufficient to require that the real limit of the function exist. That said, how is something like this proven? In principle I should just be able to take a limit as $b\to\infty$ in the above theorem, but what is the appropriate theorem for taking the limit of a sequence of base sets in an integral? Something like: If $A_n$ is a sequence of subsets of $\Bbb R$ satisfying <condition> and $f:\bigcup_n A_n\to\Bbb C$ is Lebesgue integrable on each $A_n$, and $A=\lim_n A_n$ (whatever that means), then $f$ is integrable on $A$ and $$\int_A f=\lim_n\int_{A_n}f.$$",,"['real-analysis', 'integration', 'measure-theory', 'lebesgue-integral']"
