,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Given a set of N resistors, not guaranteed identical, how many different arrangements using k resistors can be made?","Given a set of N resistors, not guaranteed identical, how many different arrangements using k resistors can be made?",,"I'm trying to develop a program that evaluates all possible arrangements (combinations of series and parallel) of k resistors from a set. From what I've read, if the resistors were identical values, then this would just be a permutation formula. But what if the k resistors have different values? Say I don't care if any arrangements end up having the same net resistance as each other, I just want to know the total number of ways I can arrange R1, R2, ... Rk. Ignoring the set for the moment (or setting N = k), I get that when k =1, there's only one arrangement (obviously). When k=2, there are 2 (both in series, both in parallel). When k = 3, I get 8: 1 x all three in series 1 x all three in parallel 3 x 1 in parallel with 2 in series, and 3 x 1 in series with 2 in parallel When k becomes 4 or above, this becomes a lot more complicated. 3 series resistors can be parallel with 1, or 1 can be in series with 3 parallel, or 2 parallel resistors can be in series with 2 other parallel resistors, or 2 series can be in series with 2 parallel, etc. Does anybody have a solution for this problem, or know of any statistical formula that would help me? EDIT : after a quick and dirty attempt to sketch out all possible arrangements for 4 resistors, I counted 52 different arrangements. As best as I can explain: 1 x all 4 in series 1 x all 4 in parallel 4 x 1 in series with 3 in parallel 12 x 1 in series with 1 resistor in parallel with 2 others in series 6 x 2 in series, in series with 2 in parallel 3 x 2 in parallel in series with 2 in parallel 3 x 2 in series parallel with 2 in series 6 x 2 in series in parallel with 2 in parallel 4 x 1 in parallel with 3 in series 12 x 1 in parallel with (1 in series with 2 in parallel) That's probably not very easy to follow, but I'm pretty sure I'm correct. So now I have for N=k, k = 1: y = 1 k = 2: y = 2 k = 3: y = 8 k = 4: y = 52 k = 5: y = ??","I'm trying to develop a program that evaluates all possible arrangements (combinations of series and parallel) of k resistors from a set. From what I've read, if the resistors were identical values, then this would just be a permutation formula. But what if the k resistors have different values? Say I don't care if any arrangements end up having the same net resistance as each other, I just want to know the total number of ways I can arrange R1, R2, ... Rk. Ignoring the set for the moment (or setting N = k), I get that when k =1, there's only one arrangement (obviously). When k=2, there are 2 (both in series, both in parallel). When k = 3, I get 8: 1 x all three in series 1 x all three in parallel 3 x 1 in parallel with 2 in series, and 3 x 1 in series with 2 in parallel When k becomes 4 or above, this becomes a lot more complicated. 3 series resistors can be parallel with 1, or 1 can be in series with 3 parallel, or 2 parallel resistors can be in series with 2 other parallel resistors, or 2 series can be in series with 2 parallel, etc. Does anybody have a solution for this problem, or know of any statistical formula that would help me? EDIT : after a quick and dirty attempt to sketch out all possible arrangements for 4 resistors, I counted 52 different arrangements. As best as I can explain: 1 x all 4 in series 1 x all 4 in parallel 4 x 1 in series with 3 in parallel 12 x 1 in series with 1 resistor in parallel with 2 others in series 6 x 2 in series, in series with 2 in parallel 3 x 2 in parallel in series with 2 in parallel 3 x 2 in series parallel with 2 in series 6 x 2 in series in parallel with 2 in parallel 4 x 1 in parallel with 3 in series 12 x 1 in parallel with (1 in series with 2 in parallel) That's probably not very easy to follow, but I'm pretty sure I'm correct. So now I have for N=k, k = 1: y = 1 k = 2: y = 2 k = 3: y = 8 k = 4: y = 52 k = 5: y = ??",,"['statistics', 'graph-theory', 'permutations', 'combinations']"
1,Probability someone never gets promoted?,Probability someone never gets promoted?,,"I was doing some simulations on societal structures. For example, given a population, with a heirachy of N levels. e.g. one prime-minister, 10 cabinet members, 100 MPs, and so on. Let $P$ be the number of people that a person on a higher level has under their control. (In this case P=10). And assuming that everyone starts their carreer on the bottom of the heirachy. And that everyone retires at a specified age. When someone retires, one person on the level below randomly gets promoted (and someone moves up to replace them and so on) and one new person starts at the bottom level. (We can assume some steady birth rate so the working population stays constant.) Then I asked questions such as how long will the person at the top stay in power? Let $L$ be the length of anyone's career before retirement. (e.g. 50 years). I found that the average length of time the top person will stay in their job will be $L/N$ years. In other words for a flatter heirachy the ruler will stay in basically half their life. Whereas for a tall heirachy the ruler will usually be very old by the time they get to the top and only stay there for a short time. (Think of the case where $N\approx 1$ and the case where $P\approx 1$ ). In fact I compared this with the UK heirachical structure (I set $P=30$ and $N\approx 5.3$ ) and I get the length of time for a prime minister to be roughly the right 10 years. Which is kind of right. But I also wanted to calculate the probability that someone in the lowest heirachichy will never get promoted and stay on the bottom rung all their life? Or to be more general the probability that someone will reach level $M$ before retirement.","I was doing some simulations on societal structures. For example, given a population, with a heirachy of N levels. e.g. one prime-minister, 10 cabinet members, 100 MPs, and so on. Let be the number of people that a person on a higher level has under their control. (In this case P=10). And assuming that everyone starts their carreer on the bottom of the heirachy. And that everyone retires at a specified age. When someone retires, one person on the level below randomly gets promoted (and someone moves up to replace them and so on) and one new person starts at the bottom level. (We can assume some steady birth rate so the working population stays constant.) Then I asked questions such as how long will the person at the top stay in power? Let be the length of anyone's career before retirement. (e.g. 50 years). I found that the average length of time the top person will stay in their job will be years. In other words for a flatter heirachy the ruler will stay in basically half their life. Whereas for a tall heirachy the ruler will usually be very old by the time they get to the top and only stay there for a short time. (Think of the case where and the case where ). In fact I compared this with the UK heirachical structure (I set and ) and I get the length of time for a prime minister to be roughly the right 10 years. Which is kind of right. But I also wanted to calculate the probability that someone in the lowest heirachichy will never get promoted and stay on the bottom rung all their life? Or to be more general the probability that someone will reach level before retirement.",P L L/N N\approx 1 P\approx 1 P=30 N\approx 5.3 M,"['probability', 'statistics', 'applications']"
2,Grouping of combinations with elements in common,Grouping of combinations with elements in common,,"Consider all the $\left(\begin{array}{c} n\\k\end{array}\right)$ possible combinations of $k$ elements from a fixed set of $n$ elements. Let’s now form groups of these combinations with the following property: In each group there exist at least one combination with at least $s<k$ elements in common with all other combinations of the group. Is it possible to find the minimum number of groups that cover all the $\left(\begin{array}{c} n\\k\end{array}\right)$ combinations, as a function of $n$ , $k$ and $s$ ? The exact number would be great, but some (sharp) upper limit would also be very useful. In other words, I would like to find the $s$ -net covering number of the set of all $\left(\begin{array}{c} n\\k\end{array}\right)$ possible combinations, with respect to the distance metric corresponding to the number of non-overlapping elements.","Consider all the possible combinations of elements from a fixed set of elements. Let’s now form groups of these combinations with the following property: In each group there exist at least one combination with at least elements in common with all other combinations of the group. Is it possible to find the minimum number of groups that cover all the combinations, as a function of , and ? The exact number would be great, but some (sharp) upper limit would also be very useful. In other words, I would like to find the -net covering number of the set of all possible combinations, with respect to the distance metric corresponding to the number of non-overlapping elements.",\left(\begin{array}{c} n\\k\end{array}\right) k n s<k \left(\begin{array}{c} n\\k\end{array}\right) n k s s \left(\begin{array}{c} n\\k\end{array}\right),"['combinatorics', 'statistics', 'elementary-set-theory', 'clustering']"
3,Does the symmetricity hold for paired data drawn from symmetric sample data without replacement?,Does the symmetricity hold for paired data drawn from symmetric sample data without replacement?,,"If the distribution of $X_1 ,\dots, X_n$ are symmetric about a common median $\theta$ , which means for every $X_i$ , $$\Pr(X_i \leq \theta-x) = \Pr(X_i \geq \theta +x),$$ where $i = 1, 2,\dots, n$ . May I get the equation $$\Pr(W+Y \leq 2*(\theta - x)) = \Pr(W+Y \geq 2*(\theta + x))$$ if $W$ and $Y$ are drawn from $X_1$ , ..., $X_n$ without replacemnt? Any suggestion will help! Thank you in advance :)","If the distribution of are symmetric about a common median , which means for every , where . May I get the equation if and are drawn from , ..., without replacemnt? Any suggestion will help! Thank you in advance :)","X_1 ,\dots, X_n \theta X_i \Pr(X_i \leq \theta-x) = \Pr(X_i \geq \theta +x), i = 1, 2,\dots, n \Pr(W+Y \leq 2*(\theta - x)) = \Pr(W+Y \geq 2*(\theta + x)) W Y X_1 X_n","['probability', 'probability-theory', 'statistics', 'median']"
4,Kiefer bound on variance of unbiased estimator,Kiefer bound on variance of unbiased estimator,,"I am trying to work through the very short paper entitled ""On Minimium Variance Estimators"" by J. Kiefer (1952). In this work he gives two explicit examples on calculating the lower bound on the variance of the two random variables. In both cases, he calculates the bound two different ways, using equation (3) and (4) of his paper. Eq. 4 of his paper is the Chapman-Robbins bound, whereas Eq. 3 is a more general Barankin type bound. I think I understand how he got his Chapman-Robbins result, but I am confused as to how he calculates the more general bound. Ill now paraphrase his first example: For n observations on a uniform distribution from $0$ to $\theta$ , $(\Omega =\{\theta|\theta>0\})$ , the random variable Y is the maximum of those observations with pdf $f(y;\theta)=ny^{n-1}/\theta^{n}$ for $0\leq y\leq \theta$ and is $0$ elsewhere. The Chapman Robbins bound on a pdf $f(y;\theta)$ is given by \begin{align} E_{\theta}(t-\theta)^2\geq[\inf_h\frac{1}{h^2}(\int_{\chi}\frac{(f(y;\theta+h))^2}{f(y;\theta)}\text{d}\mu-1)]^{-1} \end{align} , for any $t(y)$ such that $E_{\theta}t=\theta$ . Kiefer finds that for $n=1$ , $[(\int_{\chi}\frac{(f(y;\theta+h))^2}{f(y;\theta)}\text{d}\mu-1)]=-\frac{1}{h(\theta+h)}$ , which in turn yields a bound of $\theta^2/4$ . Lets start by deriving this result in more detail. We have that $\frac{(f(y;\theta+h))^2}{f(y;\theta)}=\frac{\theta}{(\theta+h)^2}$ , and $\chi$ has support from $0$ to $\theta+h$ (note that $-\theta<h<0$ ), so $\int_{\chi}\frac{(f(y;\theta+h))^2}{f(y;\theta)}\text{d}\mu=\int_{0}^{\theta+h}\frac{\theta}{(\theta+h)^2}\text{d}y=\frac{\theta}{(\theta+h)}$ , and so we have that $[\inf_h\frac{1}{h^2}(\frac{\theta}{(\theta+h)}-1)]=\inf_h(-\frac{1}{h(\theta+h)})$ as desired. This term obtains its minimum at $h=-\theta/2$ , and is $4/\theta^2$ . The Chapman-Robbins bound is the inverse of this term, $\theta^2/4$ . This coincides with what Kiefer found in his paper. Now for the more general Barankin type bound, which Kiefer gives as \begin{align} E_{\theta}(t-\theta)^2\geq\sup_{\lambda_1}\left[(E_1(h))^2\left(\int_{\chi}\frac{[\int_{\Omega_{\theta}}f(y;\theta+h)\text{d}\lambda_{1}(h)]^{2}}{f(y;\theta)}\text{d}\mu-1\right)^{-1}\right] \end{align} where $E_{1}(h)=\int_{\Omega_{\theta}}h\text{d}\lambda_{1}(h)$ , Kiefer claims the ideal measure $\text{d}\lambda_{1}(h)=\frac{n+1}{\theta}(h/\theta+1)^n\text{d}h$ . Proceeding now for general $n$ , we have that $E_{1}(h)=\int_{\Omega_{\theta}}h\frac{n+1}{\theta}(h/\theta+1)^n\text{d}h=\int_{\Omega_{\theta}}(h+\theta-\theta)\frac{n+1}{\theta^{n+1}}(h+\theta)^n\text{d}h=\int_{-\theta}^{0}\frac{n+1}{\theta^{n+1}}(h+\theta)^{n+1}\text{d}h-\int_{-\theta}^{0}\frac{n+1}{\theta^{n}}(h+\theta)^{n}\text{d}h=\frac{n+1}{n+2}\theta-\theta=-\frac{1}{n+2}\theta$ . We now calculate the integral \begin{align} \int_{\Omega_{\theta}}f(y;\theta+h)\text{d}\lambda_{1}(h) = \int_{-\theta}^{0}\frac{n y^{n-1}}{(\theta+h)^n}\frac{n+1}{\theta^{n+1}}(\theta+h)^{n}\text{d}h = \frac{n(n+1)y^{n-1}}{\theta^{n}} \end{align} This means that \begin{align} \int_{\chi}\frac{[\int_{\Omega_{\theta}}f(y;\theta+h)\text{d}\lambda_{1}(h)]^{2}}{f(y;\theta)}\text{d}\mu = \int_{\chi}(n+1)^2 f(y;\theta) \text{d}\mu = (n+1)^2 \end{align} Since $(n+1)^2-1=n(n+2)$ we can combine our earlier results to find \begin{align} \left[(E_1(h))^2\left(\int_{\chi}\frac{[\int_{\Omega_{\theta}}f(y;\theta+h)\text{d}\lambda_{1}(h)]^{2}}{f(y;\theta)}\text{d}\mu-1\right)^{-1}\right] = \frac{1}{n(n+2)^3}\theta^{2}. \end{align} However, Kiefer finds the variance to be bounded by $\frac{1}{n(n+2)}\theta^{2}$ , which equals $\frac{n+1}{n}Y$ , so their is an unbiased estimator that reaches this bound (and clearly the answer I derived is wrong). My questions are: where did I go wrong in my derivation? Also, is there an easy way to see how Kiefer knew to choose $\text{d}\lambda_{1}(h)$ the way that he did, other than the obvious answer that this gives the best bound? Also, if anyone has general advice on calculation of tight bounds beyond Chapman-Robbins bound, I would be interested in hearing their strategies. Hopefully I have included enough notation to make the problem palatable, but if not I can copy more from the paper. edit: fixed incorrect mathematical symbol.","I am trying to work through the very short paper entitled ""On Minimium Variance Estimators"" by J. Kiefer (1952). In this work he gives two explicit examples on calculating the lower bound on the variance of the two random variables. In both cases, he calculates the bound two different ways, using equation (3) and (4) of his paper. Eq. 4 of his paper is the Chapman-Robbins bound, whereas Eq. 3 is a more general Barankin type bound. I think I understand how he got his Chapman-Robbins result, but I am confused as to how he calculates the more general bound. Ill now paraphrase his first example: For n observations on a uniform distribution from to , , the random variable Y is the maximum of those observations with pdf for and is elsewhere. The Chapman Robbins bound on a pdf is given by , for any such that . Kiefer finds that for , , which in turn yields a bound of . Lets start by deriving this result in more detail. We have that , and has support from to (note that ), so , and so we have that as desired. This term obtains its minimum at , and is . The Chapman-Robbins bound is the inverse of this term, . This coincides with what Kiefer found in his paper. Now for the more general Barankin type bound, which Kiefer gives as where , Kiefer claims the ideal measure . Proceeding now for general , we have that . We now calculate the integral This means that Since we can combine our earlier results to find However, Kiefer finds the variance to be bounded by , which equals , so their is an unbiased estimator that reaches this bound (and clearly the answer I derived is wrong). My questions are: where did I go wrong in my derivation? Also, is there an easy way to see how Kiefer knew to choose the way that he did, other than the obvious answer that this gives the best bound? Also, if anyone has general advice on calculation of tight bounds beyond Chapman-Robbins bound, I would be interested in hearing their strategies. Hopefully I have included enough notation to make the problem palatable, but if not I can copy more from the paper. edit: fixed incorrect mathematical symbol.","0 \theta (\Omega =\{\theta|\theta>0\}) f(y;\theta)=ny^{n-1}/\theta^{n} 0\leq y\leq \theta 0 f(y;\theta) \begin{align}
E_{\theta}(t-\theta)^2\geq[\inf_h\frac{1}{h^2}(\int_{\chi}\frac{(f(y;\theta+h))^2}{f(y;\theta)}\text{d}\mu-1)]^{-1}
\end{align} t(y) E_{\theta}t=\theta n=1 [(\int_{\chi}\frac{(f(y;\theta+h))^2}{f(y;\theta)}\text{d}\mu-1)]=-\frac{1}{h(\theta+h)} \theta^2/4 \frac{(f(y;\theta+h))^2}{f(y;\theta)}=\frac{\theta}{(\theta+h)^2} \chi 0 \theta+h -\theta<h<0 \int_{\chi}\frac{(f(y;\theta+h))^2}{f(y;\theta)}\text{d}\mu=\int_{0}^{\theta+h}\frac{\theta}{(\theta+h)^2}\text{d}y=\frac{\theta}{(\theta+h)} [\inf_h\frac{1}{h^2}(\frac{\theta}{(\theta+h)}-1)]=\inf_h(-\frac{1}{h(\theta+h)}) h=-\theta/2 4/\theta^2 \theta^2/4 \begin{align}
E_{\theta}(t-\theta)^2\geq\sup_{\lambda_1}\left[(E_1(h))^2\left(\int_{\chi}\frac{[\int_{\Omega_{\theta}}f(y;\theta+h)\text{d}\lambda_{1}(h)]^{2}}{f(y;\theta)}\text{d}\mu-1\right)^{-1}\right]
\end{align} E_{1}(h)=\int_{\Omega_{\theta}}h\text{d}\lambda_{1}(h) \text{d}\lambda_{1}(h)=\frac{n+1}{\theta}(h/\theta+1)^n\text{d}h n E_{1}(h)=\int_{\Omega_{\theta}}h\frac{n+1}{\theta}(h/\theta+1)^n\text{d}h=\int_{\Omega_{\theta}}(h+\theta-\theta)\frac{n+1}{\theta^{n+1}}(h+\theta)^n\text{d}h=\int_{-\theta}^{0}\frac{n+1}{\theta^{n+1}}(h+\theta)^{n+1}\text{d}h-\int_{-\theta}^{0}\frac{n+1}{\theta^{n}}(h+\theta)^{n}\text{d}h=\frac{n+1}{n+2}\theta-\theta=-\frac{1}{n+2}\theta \begin{align}
\int_{\Omega_{\theta}}f(y;\theta+h)\text{d}\lambda_{1}(h) = \int_{-\theta}^{0}\frac{n y^{n-1}}{(\theta+h)^n}\frac{n+1}{\theta^{n+1}}(\theta+h)^{n}\text{d}h = \frac{n(n+1)y^{n-1}}{\theta^{n}}
\end{align} \begin{align}
\int_{\chi}\frac{[\int_{\Omega_{\theta}}f(y;\theta+h)\text{d}\lambda_{1}(h)]^{2}}{f(y;\theta)}\text{d}\mu = \int_{\chi}(n+1)^2 f(y;\theta) \text{d}\mu = (n+1)^2
\end{align} (n+1)^2-1=n(n+2) \begin{align}
\left[(E_1(h))^2\left(\int_{\chi}\frac{[\int_{\Omega_{\theta}}f(y;\theta+h)\text{d}\lambda_{1}(h)]^{2}}{f(y;\theta)}\text{d}\mu-1\right)^{-1}\right] = \frac{1}{n(n+2)^3}\theta^{2}.
\end{align} \frac{1}{n(n+2)}\theta^{2} \frac{n+1}{n}Y \text{d}\lambda_{1}(h)","['probability', 'statistics', 'estimation', 'parameter-estimation']"
5,Finding design matrix $X$ in the linear model,Finding design matrix  in the linear model,X,"$y=Xb+e$ is a (General) linear model with $n=p=3$ . Given that $b_3$ is non estimable, and $b_1+ 2b_2 + 2b_3$ is estimable. How can I find an $X$ which is consistent with the above? I think I have a partial solution to it but I do not understand the methodology of solving it. My questions 1) How can we show/prove that $\lambda_1\notin  C(X^T)$ but $\lambda_2 \in  C(X^T)$ ? and lastly, 2) How does the design matrix $X$ looks and why ? So I know $$b = \begin{bmatrix} b_1\\  b_2\\ b_3 \end{bmatrix}$$ Now since $b_3$ is non estimable : $b_3 = λ_1^T b$ $\lambda_1 = \begin{bmatrix} 0\\  0\\ 1 \end{bmatrix}$ and $\lambda_1\notin C(X^T)$ (the column space of $X^T$ ). and since $b_1 +2b_2 + 2b_3$ is estimable then $$b_1 +2b_2 + 2b_3 = \lambda_2^T b$$ $\lambda_2 = \begin{bmatrix} 1\\  2\\ 2 \end{bmatrix}$ and $\lambda_2$ is  in $C(X^T)$ . We know probably that $X$ is not full column rank. I was thinking to use $X^T b = \lambda_1$ , $X^T b = \lambda_2 $ to find $X$ matrix but I am not sure how to proceed.","is a (General) linear model with . Given that is non estimable, and is estimable. How can I find an which is consistent with the above? I think I have a partial solution to it but I do not understand the methodology of solving it. My questions 1) How can we show/prove that but ? and lastly, 2) How does the design matrix looks and why ? So I know Now since is non estimable : and (the column space of ). and since is estimable then and is  in . We know probably that is not full column rank. I was thinking to use , to find matrix but I am not sure how to proceed.","y=Xb+e n=p=3 b_3 b_1+ 2b_2 + 2b_3 X \lambda_1\notin  C(X^T) \lambda_2 \in  C(X^T) X b = \begin{bmatrix}
b_1\\ 
b_2\\
b_3
\end{bmatrix} b_3 b_3 = λ_1^T b \lambda_1 = \begin{bmatrix}
0\\ 
0\\
1
\end{bmatrix} \lambda_1\notin C(X^T) X^T b_1 +2b_2 + 2b_3 b_1 +2b_2 + 2b_3 = \lambda_2^T b \lambda_2 = \begin{bmatrix}
1\\ 
2\\
2
\end{bmatrix} \lambda_2 C(X^T) X X^T b = \lambda_1 X^T b = \lambda_2  X","['linear-algebra', 'matrices', 'statistics', 'systems-of-equations', 'linear-regression']"
6,Intuition behind defining the information of a random variable as being additive for independent events,Intuition behind defining the information of a random variable as being additive for independent events,,"I'm recently studying the concepts of entropy and I've a fundamental question regarding the conceptual formulation of information content of a random variable $X$ , or equivalently, the uncertaintly of a system/probabilistic experiments with $n$ possible outcomes. In either cases, I'm trying to understand why the information content, or, the uncertainty has to be an additive function in the formulation process itself? Of course, $f(p) :=k log p$ satisfies the $f(pq)= f(p) + f(q)$ . But my question is before defining the information content or uncertaintly as a log function. More precisely: (1) Information content ( https://en.wikipedia.org/wiki/Entropy_(information_theory) ): Consider a probability space $(\Omega, \mathcal{F}, P)$ where the three notations in the parentheses denote respectiveky the sample space, a sigma algebra of $P$ -measurable sets (""events""), and $P$ is the probability measure on $\Omega$ . Now, we don't quite need a random variable to formulate the information content $I$ , i.e. $I$ is just a function defined on the ""events"", $I : \mathcal{F} \to [0, \infty]$ , so that: (1) $I(\Omega)=0$ (This is intutively clear, as the full event doesn't bring us any information), (2) $I(A) \leq I(B)$ if $P(A) \geq P(B)$ (intuitively clear, as rarer events are more informative), and (3) $I(AB)=I(A) + I(B)$ , where $A,B$ are independent. Now, this is the part I fail to have an intuition: why is it assumed that $I(AB)=I(A) + I(B)$ , where $A,B$ are independent? Let's try to examine some counter examples here. If we'd have assumed $I(AB)=I(A)I(B)$ , where $A,B$ are independent, then it'd not necessaily satisfy (2), as there're events $A,B$ with one of $I(A), I(B)$ is less than $1$ , and then $I(A) \leq I(AB) = I(A)I(B) > I(A)$ , contradintion. So this doesn't work. What if, we'd have defined $I(AB) = I(A) + I(B) + \phi(I(A), I(B))$ , where $\phi(.,.)$ satisfies: i) $\phi(p, 1) = 0 \forall p, \phi(1, q)=0 \forall q, ii) \phi(p,q) = \phi(q, p) \forall p, q $ . What'd be the problem if the information content were defined like this? I understand the last definition looks unnecessarily complicated, so perhaps counterintuitive, and also, perhaps Shannon was inspired by the idea of entropy in thermodynamics, but still I wonder!","I'm recently studying the concepts of entropy and I've a fundamental question regarding the conceptual formulation of information content of a random variable , or equivalently, the uncertaintly of a system/probabilistic experiments with possible outcomes. In either cases, I'm trying to understand why the information content, or, the uncertainty has to be an additive function in the formulation process itself? Of course, satisfies the . But my question is before defining the information content or uncertaintly as a log function. More precisely: (1) Information content ( https://en.wikipedia.org/wiki/Entropy_(information_theory) ): Consider a probability space where the three notations in the parentheses denote respectiveky the sample space, a sigma algebra of -measurable sets (""events""), and is the probability measure on . Now, we don't quite need a random variable to formulate the information content , i.e. is just a function defined on the ""events"", , so that: (1) (This is intutively clear, as the full event doesn't bring us any information), (2) if (intuitively clear, as rarer events are more informative), and (3) , where are independent. Now, this is the part I fail to have an intuition: why is it assumed that , where are independent? Let's try to examine some counter examples here. If we'd have assumed , where are independent, then it'd not necessaily satisfy (2), as there're events with one of is less than , and then , contradintion. So this doesn't work. What if, we'd have defined , where satisfies: i) . What'd be the problem if the information content were defined like this? I understand the last definition looks unnecessarily complicated, so perhaps counterintuitive, and also, perhaps Shannon was inspired by the idea of entropy in thermodynamics, but still I wonder!","X n f(p) :=k log p f(pq)= f(p) + f(q) (\Omega, \mathcal{F}, P) P P \Omega I I I : \mathcal{F} \to [0, \infty] I(\Omega)=0 I(A) \leq I(B) P(A) \geq P(B) I(AB)=I(A) + I(B) A,B I(AB)=I(A) + I(B) A,B I(AB)=I(A)I(B) A,B A,B I(A), I(B) 1 I(A) \leq I(AB) = I(A)I(B) > I(A) I(AB) = I(A) + I(B) + \phi(I(A), I(B)) \phi(.,.) \phi(p, 1) = 0 \forall p, \phi(1, q)=0 \forall q, ii) \phi(p,q) = \phi(q, p) \forall p, q ","['statistics', 'information-theory', 'statistical-mechanics', 'fisher-information', 'information-geometry']"
7,Is normal the only rotation-invariant distribution whose marginals are normal?,Is normal the only rotation-invariant distribution whose marginals are normal?,,"From Maxwell's theorem, standard normal distribution is the only rotation-invariant distribution with fully-factorized marginals. What if we do not ask the marginals to be independent, but instead require them to be univariate standard normal? Will multivariate standard Gaussian distribution still be the only rotation-invariant distribution?","From Maxwell's theorem, standard normal distribution is the only rotation-invariant distribution with fully-factorized marginals. What if we do not ask the marginals to be independent, but instead require them to be univariate standard normal? Will multivariate standard Gaussian distribution still be the only rotation-invariant distribution?",,"['probability', 'statistics', 'probability-distributions']"
8,Population Estimation using Power-Law Inter-arrival Times,Population Estimation using Power-Law Inter-arrival Times,,"I am wondering if the community could give me some pointers on how to solve the following problem. I feel as if I am missing a key link and so I am having some challenges making some headway. Any Assistance would be greatly appreciated. Here we go! There are $N$ fishermen on a lake with a fixed, yet unknown, number of fish in the lake. Each fisherman fishes at the same time and for a length of time $T$ . When a fisherman catches a fish, the fisherman annotates the time when the fish was caught. There is no catch and release. At the end of the fishing period, a person collects all times, sorts them and computes the inter-catch (inter-arrival) times. He notes that they are power-law distributed according to \begin{equation} \frac{\beta \alpha^\beta}{x^{1+\alpha}} I_{[\alpha,\infty)}(x) \end{equation} where $I_{[\alpha,\infty)}(x)$ represents that indicator function, or domain, where the distribution is defined. With this setup, is it possible to estimate the population of fish within the lake?","I am wondering if the community could give me some pointers on how to solve the following problem. I feel as if I am missing a key link and so I am having some challenges making some headway. Any Assistance would be greatly appreciated. Here we go! There are fishermen on a lake with a fixed, yet unknown, number of fish in the lake. Each fisherman fishes at the same time and for a length of time . When a fisherman catches a fish, the fisherman annotates the time when the fish was caught. There is no catch and release. At the end of the fishing period, a person collects all times, sorts them and computes the inter-catch (inter-arrival) times. He notes that they are power-law distributed according to where represents that indicator function, or domain, where the distribution is defined. With this setup, is it possible to estimate the population of fish within the lake?","N T \begin{equation}
\frac{\beta \alpha^\beta}{x^{1+\alpha}} I_{[\alpha,\infty)}(x)
\end{equation} I_{[\alpha,\infty)}(x)","['probability', 'statistics', 'queueing-theory']"
9,Proving a stochastic process is almost surely continuous.,Proving a stochastic process is almost surely continuous.,,"Let $f:[0,\infty) \times\mathbb{R}$ be  bounded and continuous. If we let $(X_t)$ be an adapted process such that $X_0=0$ and $X_t = \int_0^tf(s,X_s)ds \forall t \geq 0$ Show that $X_t$ is almost surely continuous. We know that almost surely continuous means $ P(X_n \to X)=1 $ iff $$ \lim_{n \to \infty}P(\sup_{m \ge n} |X_m -X|>\epsilon) \to 0  $$ I feel like this would not be true. Counter example: Take f to be the constant function f = 1. Then $X_t = \int_0^t1ds = t$ and the limit X= $\infty$ So $$ \lim_{n \to \infty}P(\sup_{t \ge n} |X_t -X|>\epsilon)  $$ $$ =\lim_{n \to \infty}P(\sup_{t \ge n} |t -\infty|>\epsilon) $$ $$ =\lim_{n \to \infty}P(\infty>\epsilon) =1$$ So why is $X_t$ almost surely continuous and what is wrong with my counter example?",Let be  bounded and continuous. If we let be an adapted process such that and Show that is almost surely continuous. We know that almost surely continuous means iff I feel like this would not be true. Counter example: Take f to be the constant function f = 1. Then and the limit X= So So why is almost surely continuous and what is wrong with my counter example?,"f:[0,\infty) \times\mathbb{R} (X_t) X_0=0 X_t = \int_0^tf(s,X_s)ds \forall t \geq 0 X_t  P(X_n \to X)=1   \lim_{n \to \infty}P(\sup_{m \ge n} |X_m -X|>\epsilon) \to 0   X_t = \int_0^t1ds = t \infty  \lim_{n \to \infty}P(\sup_{t \ge n} |X_t -X|>\epsilon)    =\lim_{n \to \infty}P(\sup_{t \ge n} |t -\infty|>\epsilon)   =\lim_{n \to \infty}P(\infty>\epsilon) =1 X_t","['probability', 'limits', 'probability-theory', 'statistics', 'stochastic-processes']"
10,Estimating population size from capture recapture metho,Estimating population size from capture recapture metho,,"Given a population of unknown size, with k tagged individuals, we sample n of them and find m to be tagged. We would like an estimate for the size of the population N If we assume equal likelyhood of capture throughout and constant population size, we can apply the Lincoln-Petersen method and estimate N using the ratio: $kn/m$ , I would like to formally derive this ratio by maximizing the discrete probability function of tagged indvidualsin the sample. i.e. find N such that the probability of having m tagged individuals in our sample of size n is maximized. We know that P(m out of n individuals are tagged)= ${k\choose m}{N-k\choose n-n}/{N\choose n}$ . I would like to show that the ratio 𝑘𝑛/𝑚 is the value of N that maximizes this function but I/m getting stuck in the computation.","Given a population of unknown size, with k tagged individuals, we sample n of them and find m to be tagged. We would like an estimate for the size of the population N If we assume equal likelyhood of capture throughout and constant population size, we can apply the Lincoln-Petersen method and estimate N using the ratio: , I would like to formally derive this ratio by maximizing the discrete probability function of tagged indvidualsin the sample. i.e. find N such that the probability of having m tagged individuals in our sample of size n is maximized. We know that P(m out of n individuals are tagged)= . I would like to show that the ratio 𝑘𝑛/𝑚 is the value of N that maximizes this function but I/m getting stuck in the computation.",kn/m {k\choose m}{N-k\choose n-n}/{N\choose n},"['probability', 'statistics', 'sampling']"
11,The fitted values of a simple linear regression are linear combinations of the observed,The fitted values of a simple linear regression are linear combinations of the observed,,"I have notes which say that the i th fitted value $\hat{Y}_i$ is a linear combination of the response values $$\hat{Y}_i = \sum_{j=1}h_{ij}Y_j$$ where $$h_{ij} = \frac 1 n + \frac{(x_i-\overline{x})(x_j - \overline{x})}{S_{xx}} $$ First I'm a little unclear on the exact meanings of the variables.  In a linear regression, I thought there was an infinity of fitted values along the line of best fit.  Are these just the fitted values at the observed $x_i$ values?  And are the observed responses $Y_j$ all observed responses or just those at $x_i$ ? Second, I've searched for a proof of this but I can't find one.  I have a textbook showing that the coefficients of the regression are linear combinations of response variables (which if these are normal then the coefficient is normal), but that's not this.  Can anyone either direct me to one or give the proof?","I have notes which say that the i th fitted value is a linear combination of the response values where First I'm a little unclear on the exact meanings of the variables.  In a linear regression, I thought there was an infinity of fitted values along the line of best fit.  Are these just the fitted values at the observed values?  And are the observed responses all observed responses or just those at ? Second, I've searched for a proof of this but I can't find one.  I have a textbook showing that the coefficients of the regression are linear combinations of response variables (which if these are normal then the coefficient is normal), but that's not this.  Can anyone either direct me to one or give the proof?",\hat{Y}_i \hat{Y}_i = \sum_{j=1}h_{ij}Y_j h_{ij} = \frac 1 n + \frac{(x_i-\overline{x})(x_j - \overline{x})}{S_{xx}}  x_i Y_j x_i,"['statistics', 'linear-regression']"
12,expected value of sum over sum of squares,expected value of sum over sum of squares,,"I was trying to compute the expectation of something where something of the form $$\mathbb{E}\left[\frac{\sum_i X_i}{\sum_i X_i^2}\right]$$ appears multiple times, where $X_i \sim \mathcal{N}(\mu_x, \sigma_x^2)$ is normally distributed. Now, I have this feeling that this form should be something that could be known in statistics. After all this looks very much like the quotient of empirical mean and (uncorrected) variance, but I don't seem to find anything on what this could be distributed like or what this expectation is. I am aware that this form looks very similar to the t-distribution, but since the step from variance to standard deviation is non-linear, I am not sure whether this relation would help me in any way. Is there anybody out there who could give me some pointer(s) what distribution this is or at least how I could compute the expectation of something like this?","I was trying to compute the expectation of something where something of the form appears multiple times, where is normally distributed. Now, I have this feeling that this form should be something that could be known in statistics. After all this looks very much like the quotient of empirical mean and (uncorrected) variance, but I don't seem to find anything on what this could be distributed like or what this expectation is. I am aware that this form looks very similar to the t-distribution, but since the step from variance to standard deviation is non-linear, I am not sure whether this relation would help me in any way. Is there anybody out there who could give me some pointer(s) what distribution this is or at least how I could compute the expectation of something like this?","\mathbb{E}\left[\frac{\sum_i X_i}{\sum_i X_i^2}\right] X_i \sim \mathcal{N}(\mu_x, \sigma_x^2)","['statistics', 'probability-distributions', 'normal-distribution', 'expected-value']"
13,Autocorrelation function of a wide-sense cyclostationary process,Autocorrelation function of a wide-sense cyclostationary process,,"I came across a question in which the following figure was given and the question was: ""The autocorrelation function RXX[k1,k2] of a zero-mean random process X[k] is depicted below. Which of the following properties are fulﬁlled?"". The answer is: it's a wide-sense cyclostationary with period 2. How can we conclude this based on the autocorrelation function? In general, if the autocorrelation matrix is diagonal, what can we conclude about the underlying process?","I came across a question in which the following figure was given and the question was: ""The autocorrelation function RXX[k1,k2] of a zero-mean random process X[k] is depicted below. Which of the following properties are fulﬁlled?"". The answer is: it's a wide-sense cyclostationary with period 2. How can we conclude this based on the autocorrelation function? In general, if the autocorrelation matrix is diagonal, what can we conclude about the underlying process?",,"['statistics', 'correlation', 'stationary-processes']"
14,Finding the UMVUE of $\lambda^2$ for $X \sim Pois(\lambda)$,Finding the UMVUE of  for,\lambda^2 X \sim Pois(\lambda),"Hello, I am trying to work on this problem and the following is what I know so far. Usually the steps that I take to solve these problms are 1), Find the MLE 2), Find its Bias.  If biased, adjust it. 3), Show completeness of the distribution. Once these steps are taken then the Lehman-Scheffe theorem will let us know that the unbiased estimator is the UMVUE. However, this is what I got so far. a), $\hat{\lambda}_{MLE} = \bar{X}$ so $\hat{\lambda^2}_{MLE}=\bar{X}^2$ The problem with this is that $$E[\bar{X}^2]=\frac{\lambda}{n}+\lambda^2$$ so I do not know a simple way to adjust this to make it into an unbiased estimator. For $(\lambda-1)^2$ I get the same problem with $(\bar{X}-1)^2$ where $$E[(\bar{X}-1)^2]=\frac{\lambda}{n}+(\lambda-1)^2$$ . Poisson is a regular exponential class so it is simple to show completeness. I am just having problem with the algebraic manipulation . . . I would appreciate your help.","Hello, I am trying to work on this problem and the following is what I know so far. Usually the steps that I take to solve these problms are 1), Find the MLE 2), Find its Bias.  If biased, adjust it. 3), Show completeness of the distribution. Once these steps are taken then the Lehman-Scheffe theorem will let us know that the unbiased estimator is the UMVUE. However, this is what I got so far. a), so The problem with this is that so I do not know a simple way to adjust this to make it into an unbiased estimator. For I get the same problem with where . Poisson is a regular exponential class so it is simple to show completeness. I am just having problem with the algebraic manipulation . . . I would appreciate your help.",\hat{\lambda}_{MLE} = \bar{X} \hat{\lambda^2}_{MLE}=\bar{X}^2 E[\bar{X}^2]=\frac{\lambda}{n}+\lambda^2 (\lambda-1)^2 (\bar{X}-1)^2 E[(\bar{X}-1)^2]=\frac{\lambda}{n}+(\lambda-1)^2,"['statistics', 'maximum-likelihood', 'parameter-estimation']"
15,Show convergence in probability of the reciprocal,Show convergence in probability of the reciprocal,,"I have the following problem- If $Y_n$ converges in probability to $Y$ then show that $\frac{1}{Y_n}$ converges in probability to $\frac{1}{Y}$ . Also $P(Y_n=0) = 0$ for all $n$ and $P(Y = 0) = 0$ My attempt - Since $Y_n$ converges in probability to $Y$ then we know that $Y_n$ is bounded in probability and $Y$ is also bounded in probability , so I can get $M$ s.t. $$P(|Y_nY| > M) < \eta$$ then $P(|\frac{1}{Y_n} - \frac{1}{Y}| > \epsilon) = P(\frac{|Y_n-Y|}{|Y_nY|} > \epsilon) \leq  P(\frac{|Y_n-Y|}{|Y_nY|}>\epsilon,|Y_nY| > M) +P(\frac{|Y_n-Y|}{|Y_nY|}>\epsilon,|Y_nY| \leq M) \leq P(|Y_nY| > M) + P(\frac{|Y_n-Y|}{|Y_nY|}>\epsilon,|Y_nY| \leq M)  $ I don't know how to go ahead from here,  basically the problem is the second term in the last expression,  if I can somehow manipulate that to use the convergence of $Y_n$ I'd be done. So can someone please provide me with the solution to this problem Edit: I have made the correction and now it says bounded in probability not just bounded.","I have the following problem- If converges in probability to then show that converges in probability to . Also for all and My attempt - Since converges in probability to then we know that is bounded in probability and is also bounded in probability , so I can get s.t. then I don't know how to go ahead from here,  basically the problem is the second term in the last expression,  if I can somehow manipulate that to use the convergence of I'd be done. So can someone please provide me with the solution to this problem Edit: I have made the correction and now it says bounded in probability not just bounded.","Y_n Y \frac{1}{Y_n} \frac{1}{Y} P(Y_n=0) = 0 n P(Y = 0) = 0 Y_n Y Y_n Y M P(|Y_nY| > M) < \eta P(|\frac{1}{Y_n} - \frac{1}{Y}| > \epsilon) = P(\frac{|Y_n-Y|}{|Y_nY|} > \epsilon) \leq  P(\frac{|Y_n-Y|}{|Y_nY|}>\epsilon,|Y_nY| > M) +P(\frac{|Y_n-Y|}{|Y_nY|}>\epsilon,|Y_nY| \leq M) \leq P(|Y_nY| > M) + P(\frac{|Y_n-Y|}{|Y_nY|}>\epsilon,|Y_nY| \leq M)   Y_n","['probability-theory', 'statistics', 'convergence-divergence']"
16,Covariance matrix of a stationary random process,Covariance matrix of a stationary random process,,"Cxx is the covariance matrix of a stationary random process X[k]. Assume we create X0 by subtracting the nonzero mean mx from X, consisting of samples of X[k]. Then, the covariance matrix for X0 is different from Cxx? What if X[k] is wide-sense-stationary or not stationary?","Cxx is the covariance matrix of a stationary random process X[k]. Assume we create X0 by subtracting the nonzero mean mx from X, consisting of samples of X[k]. Then, the covariance matrix for X0 is different from Cxx? What if X[k] is wide-sense-stationary or not stationary?",,"['statistics', 'covariance', 'stationary-processes']"
17,"$P(\mu \in (\bar{X} - 1/2, \bar{X} + 1/2))$ for Gauss distribution",for Gauss distribution,"P(\mu \in (\bar{X} - 1/2, \bar{X} + 1/2))","Let $\bar{X}$ be the mean of a random sample of size $n$ from $N(\mu=u, \sigma^2 = 10)$ Find $n$ so that the probability is a approximately $0.954$ that the random interval $(\bar{X} - 1/2, \bar{X} + 1/2)$ includes $\mu$ . I began with $P(\bar{X} - 1/2 < u < \bar{X} + 1/2) = 0.954$ then I'm not sure as to where to go from there.",Let be the mean of a random sample of size from Find so that the probability is a approximately that the random interval includes . I began with then I'm not sure as to where to go from there.,"\bar{X} n N(\mu=u, \sigma^2 = 10) n 0.954 (\bar{X} - 1/2, \bar{X} + 1/2) \mu P(\bar{X} - 1/2 < u < \bar{X} + 1/2) = 0.954","['statistics', 'normal-distribution']"
18,Rubik's cube problem - Combinatorics required [closed],Rubik's cube problem - Combinatorics required [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question There are $4.3\times 10^{19}$ combinations possible with a standard $3\times 3\times 3$ Rubick's cube. My question is, if you would take 2 cubes and scramble them randomly, what are the odds of perfectly matching a single side on both cubes?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question There are combinations possible with a standard Rubick's cube. My question is, if you would take 2 cubes and scramble them randomly, what are the odds of perfectly matching a single side on both cubes?",4.3\times 10^{19} 3\times 3\times 3,"['combinatorics', 'statistics']"
19,Is MLE of multinominal distribution almost surely convergence?,Is MLE of multinominal distribution almost surely convergence?,,"I know MLE converges in probability to its parameters. However, I am not sure if MLE of multinominal distribution has stronger convergence, i.e., almost surely convergence.","I know MLE converges in probability to its parameters. However, I am not sure if MLE of multinominal distribution has stronger convergence, i.e., almost surely convergence.",,"['probability', 'statistics', 'convergence-divergence']"
20,Hotel Key Card Recognition,Hotel Key Card Recognition,,"Another problem from  BadCamp Puzzles: http://www-scf.usc.edu/~mearnest/puzzles_by_genre.php Here is the question: A hotel key card has two ways it can inserted it into the lock. However, it is so poorly labeled that as far you can tell, either way is equally likely to be the correct one. Even worse, the card reader is finicky, so even when you insert it on the correct side, the lock only opens with a known probability, p. Trying the current side takes one seconds, and flipping takes half a second. What strategy minimizes the expected time it will take to open the lock? Personally, I think I should change the side after inserting side A or B specific times in a row. And I got the probability than side A is correct given $k_1$ times failure of A and $k_2$ times failure of B: $$P(side\ A\ is\ right | A\ failed\ k_1\ times\ and B\ failed\ k_2\ times)=\frac{(1-p)^{k_1}}{(1-p)^{k_1}+(1-p)^{k_2}}$$ But here flipping will always take half a second. So I got the equations intuitively: $$\frac{(1-p)^{k_2}}{(1-p)^{k_1}+(1-p)^{k_2}}*\frac{1}{p}+0.5=\frac{(1-p)^{k_1}}{(1-p)^{k_1}+(1-p)^{k_2}}*\frac{1}{p}$$ LHS means expectation time it will take to open if we flip, RHS means that of keeping flipping. If LHS side less than RHS, then we should flip from side A to side B. V.V. But I am not sure if this is right. Any suggestion or idea will be appreciated. Thanks a lot!","Another problem from  BadCamp Puzzles: http://www-scf.usc.edu/~mearnest/puzzles_by_genre.php Here is the question: A hotel key card has two ways it can inserted it into the lock. However, it is so poorly labeled that as far you can tell, either way is equally likely to be the correct one. Even worse, the card reader is finicky, so even when you insert it on the correct side, the lock only opens with a known probability, p. Trying the current side takes one seconds, and flipping takes half a second. What strategy minimizes the expected time it will take to open the lock? Personally, I think I should change the side after inserting side A or B specific times in a row. And I got the probability than side A is correct given times failure of A and times failure of B: But here flipping will always take half a second. So I got the equations intuitively: LHS means expectation time it will take to open if we flip, RHS means that of keeping flipping. If LHS side less than RHS, then we should flip from side A to side B. V.V. But I am not sure if this is right. Any suggestion or idea will be appreciated. Thanks a lot!",k_1 k_2 P(side\ A\ is\ right | A\ failed\ k_1\ times\ and B\ failed\ k_2\ times)=\frac{(1-p)^{k_1}}{(1-p)^{k_1}+(1-p)^{k_2}} \frac{(1-p)^{k_2}}{(1-p)^{k_1}+(1-p)^{k_2}}*\frac{1}{p}+0.5=\frac{(1-p)^{k_1}}{(1-p)^{k_1}+(1-p)^{k_2}}*\frac{1}{p},"['probability', 'statistics']"
21,Statistical tests on correlation coefficients,Statistical tests on correlation coefficients,,"I ran an experiment with $n$ subjects. For each subject, I measured the correlation  ( $\rho$ ) between two variables. Thus, I ended up with $n$ correlation coefficients $\rho$ . I wanted to test whether the population correlation coefficient is different from zero. What statistical test should I perform? I had tried Fisher transformation on each subject's $\rho$ , but not sure how to proceed.","I ran an experiment with subjects. For each subject, I measured the correlation  ( ) between two variables. Thus, I ended up with correlation coefficients . I wanted to test whether the population correlation coefficient is different from zero. What statistical test should I perform? I had tried Fisher transformation on each subject's , but not sure how to proceed.",n \rho n \rho \rho,"['statistics', 'statistical-inference', 'hypothesis-testing', 'correlation']"
22,Drawing causal relationship from an observational study?,Drawing causal relationship from an observational study?,,"I am reading OpenIntro's Statistics and came across this problem: In part b) I don't believe one can establish causal relationships because the research is an observational study (I think). After reading through the study itself, it seems that its authors do draw a causal relationship. Any help explaining as to why this is would be greatly appreciated. Thank you.","I am reading OpenIntro's Statistics and came across this problem: In part b) I don't believe one can establish causal relationships because the research is an observational study (I think). After reading through the study itself, it seems that its authors do draw a causal relationship. Any help explaining as to why this is would be greatly appreciated. Thank you.",,"['statistics', 'definition', 'statistical-inference']"
23,How to calculate probability of a cell containing mine in minesweeper?,How to calculate probability of a cell containing mine in minesweeper?,,In Minesweeper: If we just investigate 1 specific cell and 8 unrevealed cells surrounding it. I know that the chance of a cell is mine = number of mines (the center number) / number of hidden cells. But what if we have one more cell is revealed? Can someone please show me the way to calculate the probability of the rest of them containing mines? Thank you.,In Minesweeper: If we just investigate 1 specific cell and 8 unrevealed cells surrounding it. I know that the chance of a cell is mine = number of mines (the center number) / number of hidden cells. But what if we have one more cell is revealed? Can someone please show me the way to calculate the probability of the rest of them containing mines? Thank you.,,"['probability', 'statistics', 'discrete-mathematics']"
24,On confidence sets and linear regression,On confidence sets and linear regression,,"I'm working on Exercise 3.2 from Elements of Statistical Learning . It asks to find a $95\%$ confidence interval for a linear regression prediction (ordinary least squares are used) using two different methods. In the first part we're looking for the confidence interval for a single prediction $x_0^T \hat{\beta}$ , as far as I understand it's basically $$x_0^T \hat{\beta} \pm z_{0.975} \cdot \hat{\sigma} \sqrt{x_0^T \left(\mathbf{X}^T \mathbf{X}\right) x_0},$$ where $\mathbf{X} \in \mathbb{R}^{N \times (p + 1)}$ - design matrix, $z_{0.975} \approx 1.96$ quantile of standard normal distribution and $$\hat{\sigma} = \frac{1}{N - p - 1} \sum_{i = 1}^N \left( y_i - \hat{y}_i \right)^2$$ In the second part, we're looking for a confidence interval generated by a confidence set for the whole vector $\beta$ : $$C_\beta = \left\{ \beta: \; f(\beta) = (\beta - \hat{\beta})^T \mathbf{X}^T \mathbf{X} (\beta - \hat{\beta}) \leq \hat{\sigma} \chi_{p+1}^{2 \; (0.975)}\right\},$$ where $\chi_{p+1}^{2 \; (0.975)}$ is a $0.975$ quantile of $\chi_{p + 1}^2$ . Here I'm having troubles. First of all, how to calculate confidence interval based on $C_\beta$ ? My guess was that it's equivalent to finding the following: $$\min_{\beta \in C_\beta} x_0^T \beta \quad \text{and} \quad \min_{\beta \in C_\beta} x_0^T \beta$$ which at the same time is equivalent to $$\begin{cases} \alpha x_0 = \nabla f (\beta) \\ \beta \in \partial C_\beta \end{cases}$$ for a fixed $x_0$ (here I used Lagrange multipliers method for solving an optimization problem). I've solved this and got the following confidence interval for $x_0^T \hat{\beta}$ : $$x_0^T \hat{\beta} \pm \hat{\sigma} \sqrt{\chi_{p+1}^{2 \; (0.975)}  x_0^T \left(\mathbf{X}^T \mathbf{X}\right) x_0}$$ Is this right? My main concern is that it's just a $\chi^2$ correction of the first confidence interval, where we used estimate of $\sigma$ but not its true value, though is it indeed a confidence interval generated by $C_\beta$ ? And if it's not, could someone help with understanding what it actually is? Thanks!","I'm working on Exercise 3.2 from Elements of Statistical Learning . It asks to find a confidence interval for a linear regression prediction (ordinary least squares are used) using two different methods. In the first part we're looking for the confidence interval for a single prediction , as far as I understand it's basically where - design matrix, quantile of standard normal distribution and In the second part, we're looking for a confidence interval generated by a confidence set for the whole vector : where is a quantile of . Here I'm having troubles. First of all, how to calculate confidence interval based on ? My guess was that it's equivalent to finding the following: which at the same time is equivalent to for a fixed (here I used Lagrange multipliers method for solving an optimization problem). I've solved this and got the following confidence interval for : Is this right? My main concern is that it's just a correction of the first confidence interval, where we used estimate of but not its true value, though is it indeed a confidence interval generated by ? And if it's not, could someone help with understanding what it actually is? Thanks!","95\% x_0^T \hat{\beta} x_0^T \hat{\beta} \pm z_{0.975} \cdot \hat{\sigma}
\sqrt{x_0^T \left(\mathbf{X}^T \mathbf{X}\right) x_0}, \mathbf{X} \in \mathbb{R}^{N \times (p + 1)} z_{0.975} \approx 1.96 \hat{\sigma} = \frac{1}{N - p - 1} \sum_{i = 1}^N \left( y_i - \hat{y}_i \right)^2 \beta C_\beta = \left\{ \beta: \; f(\beta) = (\beta - \hat{\beta})^T \mathbf{X}^T \mathbf{X} (\beta - \hat{\beta}) \leq \hat{\sigma} \chi_{p+1}^{2 \; (0.975)}\right\}, \chi_{p+1}^{2 \; (0.975)} 0.975 \chi_{p + 1}^2 C_\beta \min_{\beta \in C_\beta} x_0^T \beta \quad \text{and} \quad
\min_{\beta \in C_\beta} x_0^T \beta \begin{cases}
\alpha x_0 = \nabla f (\beta) \\
\beta \in \partial C_\beta
\end{cases} x_0 x_0^T \hat{\beta} x_0^T \hat{\beta} \pm \hat{\sigma} \sqrt{\chi_{p+1}^{2 \; (0.975)} 
x_0^T \left(\mathbf{X}^T \mathbf{X}\right) x_0} \chi^2 \sigma C_\beta","['statistics', 'least-squares', 'linear-regression']"
25,"Is there a ""Riemann-Stieltjes integral"" for discrete 2D functions?","Is there a ""Riemann-Stieltjes integral"" for discrete 2D functions?",,"I was wondering if Riemann-Stieltjes integral still works when both of the functions $f$ and $g$ are discrete and two dimensional? Something like below: $$\int f(x,y) dg(x,y)$$ By using the parametric formula of the curve I would be able to write $x$ and $y$ in terms of one variable like angle $\alpha$ but I don't know how that would help me solve this integral which is actually a summation on discrete 2D signals. Any Suggestions?",I was wondering if Riemann-Stieltjes integral still works when both of the functions and are discrete and two dimensional? Something like below: By using the parametric formula of the curve I would be able to write and in terms of one variable like angle but I don't know how that would help me solve this integral which is actually a summation on discrete 2D signals. Any Suggestions?,"f g \int f(x,y) dg(x,y) x y \alpha","['probability', 'statistics', 'discrete-mathematics', 'probability-distributions', 'discrete-calculus']"
26,drawing marbles with different probabilities,drawing marbles with different probabilities,,"Suppose I have $N$ marbles ( $m_1$ to $m_N$ ). The chance that I take the $i$ -th marble $m_i$ is $p(0,i)$ (adding up to $1$ ). If I now take a marble (say the marble with number $M_1$ ) out and want to take a second one, the chances, for all $i<>M_1$ , have changed to $p(1,i)=\frac{p(0,i)}{1-p(0,M_1)}$ , again adding up to 1 (and $p(1,M_1)=0$ ).  If I want to take a third one, again the chances will have chanced, depending on the first 2 I took out. Now my question is: what is the chance, when I take $K$ marbles out of a bag containing $N$ marbles, that marble $m_1$ is not taken? I'm looking for a result in terms of the original chances $p(0,i)$ . For $p(0,i)=\frac{1}{N}$ this is the traditional problem. Just so that you don't wonder about the marbles having different probabilities: the question comes from a different perspective: I'm trowing darts at balloons of different lengths hanging in line and have therefor different chances of hitting them. When one is hit, it will disappear and the other balloons will again form a line (so no gaps). Thanks in advance","Suppose I have marbles ( to ). The chance that I take the -th marble is (adding up to ). If I now take a marble (say the marble with number ) out and want to take a second one, the chances, for all , have changed to , again adding up to 1 (and ).  If I want to take a third one, again the chances will have chanced, depending on the first 2 I took out. Now my question is: what is the chance, when I take marbles out of a bag containing marbles, that marble is not taken? I'm looking for a result in terms of the original chances . For this is the traditional problem. Just so that you don't wonder about the marbles having different probabilities: the question comes from a different perspective: I'm trowing darts at balloons of different lengths hanging in line and have therefor different chances of hitting them. When one is hit, it will disappear and the other balloons will again form a line (so no gaps). Thanks in advance","N m_1 m_N i m_i p(0,i) 1 M_1 i<>M_1 p(1,i)=\frac{p(0,i)}{1-p(0,M_1)} p(1,M_1)=0 K N m_1 p(0,i) p(0,i)=\frac{1}{N}","['probability', 'statistics']"
27,Some distributions / auto-correlations associated with irrational numbers,Some distributions / auto-correlations associated with irrational numbers,,"Given a number $x\in [0, 1]$ , let us consider the sequence $z_n=\{b^n x\}$ where the curly brackets represent the fractional part function, and $b>1$ is an integer. In particular, $\lfloor b z_n\rfloor$ is the $n$ -digit of $x$ in base $b$ . The following property is true for most real numbers $x\in [0, 1]$ , for all positive integers $k$ , though there are infinitely many exceptions (all rational numbers are exceptions): $c(x,k) = \mbox{Correl}(z_n,z_{n+k}) = b^{-k}$ . The correlation here is an empirical auto-correlation of lag $k$ computed on the observed values in the sequence $z_n$ . This result is true for all numbers $x$ but a set of Lebesgue measure zero. Not sure if it is a well known result or not, but I formally proved it, and this is not the object of this question. Empirical evidence also suggests it is correct. This result is true only for normal numbers, that is, in a nutshell, numbers having a uniform distribution on $[0, 1]$ for $z_n$ (the vast majority of numbers.) Not all irrational numbers are normal, for instance $0.101001000100001...$ is irrational but not normal in base $2$ . The contants $\pi,\log(2), e, \sqrt 2, \sin(1)$ are believed to be normal, after extensive statistical testing up to 22 trillions of digits, though there is no proof. Now is the interesting part of the discussion. I am doing some tests, computing the following correlations for some number $x$ , with $b=2$ and $f(n)=n$ : $g(x,k) =\mbox{Correl}\Big(\{xf(n)\},\{b^k xf(n)\}\Big), k=0, 1, 2 \cdots.$ You would also expect, if $f(n)$ is a well behaved sequence of integers, say $f(n) = n$ , that $g(x,k) = c(x, k)$ . My question is whether you can find an irrational number $x$ that is non-normal, for which $g(x,k) \neq b^{-k}$ for at least some values of $k$ , say $k=1, 2, 3$ or $4$ . Here we can use $b=2$ for simplicity. All the irrational numbers that I tested so far (even weird ones) seem to satisfy $g(x,k) = b^{-k}$ , and none of the rational numbers I tested do. I am very interested in finding an irrational number (obviously it would be a non-normal one) for which this equality is NOT satisfied. A positive answer to my question may lead to new criteria to characterize normal numbers.","Given a number , let us consider the sequence where the curly brackets represent the fractional part function, and is an integer. In particular, is the -digit of in base . The following property is true for most real numbers , for all positive integers , though there are infinitely many exceptions (all rational numbers are exceptions): . The correlation here is an empirical auto-correlation of lag computed on the observed values in the sequence . This result is true for all numbers but a set of Lebesgue measure zero. Not sure if it is a well known result or not, but I formally proved it, and this is not the object of this question. Empirical evidence also suggests it is correct. This result is true only for normal numbers, that is, in a nutshell, numbers having a uniform distribution on for (the vast majority of numbers.) Not all irrational numbers are normal, for instance is irrational but not normal in base . The contants are believed to be normal, after extensive statistical testing up to 22 trillions of digits, though there is no proof. Now is the interesting part of the discussion. I am doing some tests, computing the following correlations for some number , with and : You would also expect, if is a well behaved sequence of integers, say , that . My question is whether you can find an irrational number that is non-normal, for which for at least some values of , say or . Here we can use for simplicity. All the irrational numbers that I tested so far (even weird ones) seem to satisfy , and none of the rational numbers I tested do. I am very interested in finding an irrational number (obviously it would be a non-normal one) for which this equality is NOT satisfied. A positive answer to my question may lead to new criteria to characterize normal numbers.","x\in [0, 1] z_n=\{b^n x\} b>1 \lfloor b z_n\rfloor n x b x\in [0, 1] k c(x,k) = \mbox{Correl}(z_n,z_{n+k}) = b^{-k} k z_n x [0, 1] z_n 0.101001000100001... 2 \pi,\log(2), e, \sqrt 2, \sin(1) x b=2 f(n)=n g(x,k) =\mbox{Correl}\Big(\{xf(n)\},\{b^k xf(n)\}\Big), k=0, 1, 2 \cdots. f(n) f(n) = n g(x,k) = c(x, k) x g(x,k) \neq b^{-k} k k=1, 2, 3 4 b=2 g(x,k) = b^{-k}","['sequences-and-series', 'number-theory', 'statistics', 'stochastic-processes', 'irrational-numbers']"
28,"Two random variables $U$, $V$ such that the conditional distribution of $U$ given $V = v$ is $ve^{-u}$ for $u > ln(v)$. Prove the following:","Two random variables ,  such that the conditional distribution of  given  is  for . Prove the following:",U V U V = v ve^{-u} u > ln(v),"Given two random variables $U$ and $V$ such that the conditional PDF of $U$ given $V = v$ is $ve^{-u}$ for $u > ln(v)$ , prove $U - V$ conditional on $V = v$ follows $Exp(1)$ . Intuitively, why is this true? My attempt: Let $Z = U - V$ . $P(Z <= z | V = v) = P(U - v <= z | V = v) = P(U <= z + v | V = v)$ Differentiating with respect to $z$ , we see that the desired PDF is $ve^{-(z+v)}$ . But this is not an exponential distribution with parameter $1$ .. what have I done wrong?","Given two random variables and such that the conditional PDF of given is for , prove conditional on follows . Intuitively, why is this true? My attempt: Let . Differentiating with respect to , we see that the desired PDF is . But this is not an exponential distribution with parameter .. what have I done wrong?",U V U V = v ve^{-u} u > ln(v) U - V V = v Exp(1) Z = U - V P(Z <= z | V = v) = P(U - v <= z | V = v) = P(U <= z + v | V = v) z ve^{-(z+v)} 1,"['statistics', 'proof-verification', 'probability-distributions', 'conditional-probability']"
29,Limit distribution of Bernoulli variance,Limit distribution of Bernoulli variance,,"Let $X_1 \dots X_n \sim B(1, p)$ be i.i.d. random variables. Then the variance of $X_i$ can be approximated through $Y_n = \bar{X}_n(1 - \bar{X}_n)$ . What is the limit distribution of $Y_n$ as $n \to \infty$ ? I tried to solve this as follows. Let $q = 1 - p$ , then from the CLT follows $$\sqrt{\frac{n}{pq}}(\bar{X}_n - p) \to Z \sim \text{N}(0, 1) \text{ as } n \to \infty$$ Through the delta method with $g(x) = x(1 - x)$ , we can conclude that $$ \sqrt{\frac{n}{pq}}(g(\bar{X}_n) - g(p)) \to g'(p) \cdot Z $$ or equivalently $$\sqrt{n}(Y_n - pq) \to \sqrt{pq}(q - p) \cdot Z \sim \text{N}(0, pq(q - p)^2) \text{ as } n \to \infty$$ And then I was unsure on how to proceed finding the limit distribution of $Y_n$ . The big problem, at least to me, seems to be how to eliminate the occurrence of $\sqrt{n}$ on the left. I had a bit of an ad-hoc idea but I'm not sure if it's justifiable. It goes as follows: Let $F_n : \mathbb{R} \to \mathbb{R}$ be the cdf and $P_n : \mathbb{R} \to \mathbb{R}$ the probability function of $Y_n$ , and $\phi : \mathbb{R} \to \mathbb{R}$ be the cdf of $Z \sim N(0, 1)$ . Then, using the definition of convergence by distribution, the previous result can be rewritten as follows. $$ \lim_{n \to \infty} P_n(\sqrt{n}(Y_n - pq) \le x) = \phi\left(\frac{x}{\sqrt{pq}(q-p)}\right)$$ or equivalently $$ \lim_{n \to \infty} P_n(Y_n \le \frac{x}{\sqrt{n}} + pq) = \phi\left(\frac{x}{\sqrt{pq}(q-p)}\right)$$ Letting $y = \frac{x}{\sqrt{n}} + pq$ we can conclude that \begin{align} \lim_{n \to \infty} F_n(y) &= \lim_{n \to \infty} P_n(Y_n \le y) \\ &= \lim_{n \to \infty}\phi\left(\frac{\sqrt{n}y - pq}{\sqrt{pq}(q-p)}\right) \end{align} If we denote the unknown limit distribution as $F : \mathbb{R} \to \mathbb{R}$ , then this means we can define it as $$ F(y) = \left\{\begin{array}{ll} 0 \quad &\text{ if } \frac{y}{p - q} < 0 \\ \phi\left(\frac{\sqrt{pq}}{p - q}\right) \quad &\text{ if } y = 0 \\ 1 \quad &\text{ if } \frac{y}{p - q} > 0 \end{array}\right. $$ I can already tell this argument fails specifically in the case when $p = 1/2$ , but disregarding that, does this argument make any sense?","Let be i.i.d. random variables. Then the variance of can be approximated through . What is the limit distribution of as ? I tried to solve this as follows. Let , then from the CLT follows Through the delta method with , we can conclude that or equivalently And then I was unsure on how to proceed finding the limit distribution of . The big problem, at least to me, seems to be how to eliminate the occurrence of on the left. I had a bit of an ad-hoc idea but I'm not sure if it's justifiable. It goes as follows: Let be the cdf and the probability function of , and be the cdf of . Then, using the definition of convergence by distribution, the previous result can be rewritten as follows. or equivalently Letting we can conclude that If we denote the unknown limit distribution as , then this means we can define it as I can already tell this argument fails specifically in the case when , but disregarding that, does this argument make any sense?","X_1 \dots X_n \sim B(1, p) X_i Y_n = \bar{X}_n(1 - \bar{X}_n) Y_n n \to \infty q = 1 - p \sqrt{\frac{n}{pq}}(\bar{X}_n - p) \to Z \sim \text{N}(0, 1) \text{ as } n \to \infty g(x) = x(1 - x)  \sqrt{\frac{n}{pq}}(g(\bar{X}_n) - g(p)) \to g'(p) \cdot Z  \sqrt{n}(Y_n - pq) \to \sqrt{pq}(q - p) \cdot Z \sim \text{N}(0, pq(q - p)^2) \text{ as } n \to \infty Y_n \sqrt{n} F_n : \mathbb{R} \to \mathbb{R} P_n : \mathbb{R} \to \mathbb{R} Y_n \phi : \mathbb{R} \to \mathbb{R} Z \sim N(0, 1)  \lim_{n \to \infty} P_n(\sqrt{n}(Y_n - pq) \le x) = \phi\left(\frac{x}{\sqrt{pq}(q-p)}\right)  \lim_{n \to \infty} P_n(Y_n \le \frac{x}{\sqrt{n}} + pq) = \phi\left(\frac{x}{\sqrt{pq}(q-p)}\right) y = \frac{x}{\sqrt{n}} + pq \begin{align}
\lim_{n \to \infty} F_n(y) &= \lim_{n \to \infty} P_n(Y_n \le y) \\
&= \lim_{n \to \infty}\phi\left(\frac{\sqrt{n}y - pq}{\sqrt{pq}(q-p)}\right)
\end{align} F : \mathbb{R} \to \mathbb{R} 
F(y) = \left\{\begin{array}{ll}
0 \quad &\text{ if } \frac{y}{p - q} < 0 \\
\phi\left(\frac{\sqrt{pq}}{p - q}\right) \quad &\text{ if } y = 0 \\
1 \quad &\text{ if } \frac{y}{p - q} > 0
\end{array}\right.
 p = 1/2","['statistics', 'probability-distributions', 'random-variables', 'central-limit-theorem', 'delta-method']"
30,incremental computation of standard deviation (batch by batch),incremental computation of standard deviation (batch by batch),,"I found this link to compute standard deviation when we add samples one by one. If we add samples batch by batch ( $N_B$ ), how could we incrementally calculate the variance?","I found this link to compute standard deviation when we add samples one by one. If we add samples batch by batch ( ), how could we incrementally calculate the variance?",N_B,"['statistics', 'algorithms', 'computational-mathematics', 'variance']"
31,How many times should I perform an experiment to get a high level of accuracy?,How many times should I perform an experiment to get a high level of accuracy?,,"I have an experiment with 4 factors (independent variables). The first and second variable have 8 levels, the third 5 and the fourth only 3 levels. Theres one dependent variable. How many times should I perform the experiment in order to get a high level of accuracy? For instance a 95%. I would appreciate the mathematical procedure behind this calculation. Thank you.","I have an experiment with 4 factors (independent variables). The first and second variable have 8 levels, the third 5 and the fourth only 3 levels. Theres one dependent variable. How many times should I perform the experiment in order to get a high level of accuracy? For instance a 95%. I would appreciate the mathematical procedure behind this calculation. Thank you.",,"['statistics', 'statistical-inference', 'mathematical-modeling', 'experimental-mathematics']"
32,How to perform updates on multivariate normals?,How to perform updates on multivariate normals?,,"Suppose I have the following model: $$\begin{aligned} \mathcal L &\sim \mathcal N \left(\vec {\mu_L}, \mathbf \Sigma_L \right) \\ \mathcal X &\sim \mathcal N \left(\vec 0, \mathbf \Sigma_X \right) \\ \mathcal P &= \mathcal L + \mathcal X \\ \\ \end{aligned}$$ Or, equivalently: $$\begin{aligned} \mathcal L &\sim \mathcal N \left(\vec {\mu_L}, \mathbf \Sigma_L \right) \\ \mathcal P | \mathcal L = \vec l &\sim \mathcal N \left(\vec {l}, \mathbf \Sigma_X \right)  \end{aligned}$$ What's $\mathcal L | \mathcal P = \vec p$ distributed as, in general? In the one-dimensional case, it is very easy to see through straightforward algebraic manipulation that: $$\mathcal L | \mathcal P = p \sim \mathcal N \left( \frac{\frac 1 {\sigma_L^{2}} \mu_L + \frac 1 {\sigma_X^{2}} p}{\frac 1 {\sigma_L^{2}} + \frac 1 {\sigma_X^{2}}}, \left(\frac 1 {\sigma_L^{2}} + \frac 1 {\sigma_X^{2}}\right)^{-1} \right)$$ That is, the posterior mean is the average between $\mu_L$ and $p$ weighted by the precisions of each distribution, and the posterior precision is the sum of the precisions of each distribution (so the posterior variance is its inverse). Algebraic manipulation seems like it shouldn't be the only way to get to this result, though. What other way is there? And how do I use it to generalise this result to higher dimensions? It seems to me that the result should be something like: $$\mathcal L | \mathcal P = \vec p \sim \mathcal N \left( \frac{\mathbf\Sigma_L^{-1}\vec{\mu_L} + \mathbf\Sigma_X^{-1}\vec p}{|\mathbf\Sigma_L^{-1}| + |\mathbf\Sigma_X^{-1}|}, \left(\mathbf\Sigma_L^{-1} + \mathbf\Sigma_X^{-1}\right)^{-1} \right)$$ But I have no idea if that's actually the case or how to prove it if so.","Suppose I have the following model: Or, equivalently: What's distributed as, in general? In the one-dimensional case, it is very easy to see through straightforward algebraic manipulation that: That is, the posterior mean is the average between and weighted by the precisions of each distribution, and the posterior precision is the sum of the precisions of each distribution (so the posterior variance is its inverse). Algebraic manipulation seems like it shouldn't be the only way to get to this result, though. What other way is there? And how do I use it to generalise this result to higher dimensions? It seems to me that the result should be something like: But I have no idea if that's actually the case or how to prove it if so.","\begin{aligned}
\mathcal L &\sim \mathcal N \left(\vec {\mu_L}, \mathbf \Sigma_L \right) \\
\mathcal X &\sim \mathcal N \left(\vec 0, \mathbf \Sigma_X \right) \\
\mathcal P &= \mathcal L + \mathcal X \\ \\
\end{aligned} \begin{aligned}
\mathcal L &\sim \mathcal N \left(\vec {\mu_L}, \mathbf \Sigma_L \right) \\
\mathcal P | \mathcal L = \vec l &\sim \mathcal N \left(\vec {l}, \mathbf \Sigma_X \right) 
\end{aligned} \mathcal L | \mathcal P = \vec p \mathcal L | \mathcal P = p \sim \mathcal N \left(
\frac{\frac 1 {\sigma_L^{2}} \mu_L + \frac 1 {\sigma_X^{2}} p}{\frac 1 {\sigma_L^{2}} + \frac 1 {\sigma_X^{2}}}, \left(\frac 1 {\sigma_L^{2}} + \frac 1 {\sigma_X^{2}}\right)^{-1}
\right) \mu_L p \mathcal L | \mathcal P = \vec p \sim \mathcal N \left(
\frac{\mathbf\Sigma_L^{-1}\vec{\mu_L} + \mathbf\Sigma_X^{-1}\vec p}{|\mathbf\Sigma_L^{-1}| + |\mathbf\Sigma_X^{-1}|}, \left(\mathbf\Sigma_L^{-1} + \mathbf\Sigma_X^{-1}\right)^{-1}
\right)","['probability', 'statistics', 'probability-distributions', 'normal-distribution', 'bayesian']"
33,"Binary classification, Bayes classifier, Bayes decision boundary","Binary classification, Bayes classifier, Bayes decision boundary",,"I have recently come across this problem from a friend I help with stats occasionally. This however stumped me completely. I have looked online on basically every single website you can find but what I did find either I did not fully understand or I didn't fully understand well enough to explain to my friend. In my last resort I have made an account here hoping for some help. From what I have read and understood I know the Bayes boundary is a kind of squiggly line you find which separates between classifying an observation on either end. However I don't understand how one comes to finding how to get one. Furthermore, bayesian stats is very new to me so I am struggling and therefore my friend is too. Thank you for reading and I hope someone who understands this well can explain it to me in a simple concise and easy way Consider a binary classification problem $Y \in \{0, 1\}$ with one predictor $X$ . The prior probability of being in class 0 is $Pr(Y = 0) = \pi_0= 0.69$ and the density function for $X$ in class 0 is a standard normal $$f_0(x) = Normal(0, 1) = (1/\sqrt{2\pi})\exp(-0.5x^2).$$ The density function for $X$ in class 1 is also normal, but with $\mu = 1$ and $\sigma^2 = 0.5$ , i.e. $$f_1(x) = Normal(0, 1) = (1/\sqrt{\pi})\exp(-(x-1)^2).$$ (a) Plot $\pi_0f_0(x)$ and $\pi_1f_1(x)$ in the same figure. (b) Find the Bayes decision boundary. (c) Using Bayes classifier, classify the observation $X = 3$ . Justify your prediction. (d) What is the probability that an observation with $X = 2$ is in class 1? Any help at all would be greatly appreciated!","I have recently come across this problem from a friend I help with stats occasionally. This however stumped me completely. I have looked online on basically every single website you can find but what I did find either I did not fully understand or I didn't fully understand well enough to explain to my friend. In my last resort I have made an account here hoping for some help. From what I have read and understood I know the Bayes boundary is a kind of squiggly line you find which separates between classifying an observation on either end. However I don't understand how one comes to finding how to get one. Furthermore, bayesian stats is very new to me so I am struggling and therefore my friend is too. Thank you for reading and I hope someone who understands this well can explain it to me in a simple concise and easy way Consider a binary classification problem with one predictor . The prior probability of being in class 0 is and the density function for in class 0 is a standard normal The density function for in class 1 is also normal, but with and , i.e. (a) Plot and in the same figure. (b) Find the Bayes decision boundary. (c) Using Bayes classifier, classify the observation . Justify your prediction. (d) What is the probability that an observation with is in class 1? Any help at all would be greatly appreciated!","Y \in \{0, 1\} X Pr(Y = 0) = \pi_0= 0.69 X f_0(x) = Normal(0, 1) = (1/\sqrt{2\pi})\exp(-0.5x^2). X \mu = 1 \sigma^2 = 0.5 f_1(x) = Normal(0, 1) = (1/\sqrt{\pi})\exp(-(x-1)^2). \pi_0f_0(x) \pi_1f_1(x) X = 3 X = 2","['probability', 'statistics', 'bayesian', 'empirical-bayes']"
34,A version of PCA which chooses regressors based on covariance between responses and X,A version of PCA which chooses regressors based on covariance between responses and X,,"The PCA I've seen is to achieve dimensionality reduction by choosing the desired number of principal components in direction which maximizes the total variance of our design matrix $X$ , or the direction which maximizes $X^TX$ . I'm thinking of a way to choose regressors that have the most significance by incorporating the response vector $y$ . So let $x_{(.),1},\dots x_{(.),p}$ be the columns of $X$ , and $\bar{x}_{(.),1},\dots \bar{x}_{(.),p}$ be their centered (mean $0$ ) versions. So I would want to do something like choose a first principal component $v_1$ such that $v_1$ is in the colspace of $X$ and maximizes $$v_1^T \frac{ \sum_{j=1}^p (y - \hat y)\bar x_{(.),j}^T }{\sum_{j=1}^p \| \bar x_{(.),j}\|} v_1~.$$ The reason that I would want something like this is so that I can find a linear transformation of the data such that the probability of my regressors $\beta_1 \dots \beta_p$ under the transformation is in order of significance. In other words, $\mathbb{P}(\beta_1 = 0) \leq \mathbb{P}(\beta_2 = 0) \leq \dots \leq \mathbb{P}(\beta_p) = 0$ . I don't know if something like this exists, or if this is a wrong angle to approach dimensionality reduction from.","The PCA I've seen is to achieve dimensionality reduction by choosing the desired number of principal components in direction which maximizes the total variance of our design matrix , or the direction which maximizes . I'm thinking of a way to choose regressors that have the most significance by incorporating the response vector . So let be the columns of , and be their centered (mean ) versions. So I would want to do something like choose a first principal component such that is in the colspace of and maximizes The reason that I would want something like this is so that I can find a linear transformation of the data such that the probability of my regressors under the transformation is in order of significance. In other words, . I don't know if something like this exists, or if this is a wrong angle to approach dimensionality reduction from.","X X^TX y x_{(.),1},\dots x_{(.),p} X \bar{x}_{(.),1},\dots \bar{x}_{(.),p} 0 v_1 v_1 X v_1^T \frac{ \sum_{j=1}^p (y - \hat y)\bar x_{(.),j}^T }{\sum_{j=1}^p \| \bar x_{(.),j}\|} v_1~. \beta_1 \dots \beta_p \mathbb{P}(\beta_1 = 0) \leq \mathbb{P}(\beta_2 = 0) \leq \dots \leq \mathbb{P}(\beta_p) = 0","['linear-algebra', 'statistics', 'covariance']"
35,Any higher mathematical relationship between these survival analysis entities?,Any higher mathematical relationship between these survival analysis entities?,,"For part of some software documentation, I created this image of the relationships between survival analysis entities: survival, CDF, PDF, hazard and cumulative hazard (see image below). There is an obvious horizontal ""symmetry"" in the image. Is this a consequence of some higher mathematics? Or is this a consequence of mathematicians are humans and like things to look and feel alike? Or neither, and it's just by chance.","For part of some software documentation, I created this image of the relationships between survival analysis entities: survival, CDF, PDF, hazard and cumulative hazard (see image below). There is an obvious horizontal ""symmetry"" in the image. Is this a consequence of some higher mathematics? Or is this a consequence of mathematicians are humans and like things to look and feel alike? Or neither, and it's just by chance.",,['statistics']
36,"Final Questions - Part 3 (Birth and Death Process) - (hardest and nastiest B&D question I have encountered, ever)","Final Questions - Part 3 (Birth and Death Process) - (hardest and nastiest B&D question I have encountered, ever)",,"There is a selective group that people can join. Arrival of people who want to join the group is Poisson Process with parameter $\lambda$ . The person who arrive at the group can join the group only if he/she gets approval from all existing members. Each member will say 'yes' with probability 1/2 and 'no' with probability 1/2. Also, each member of the group leaves the group independently at a Exponential distribution of time $\mu$ . The number of members of this group defines a birth and death process. What is the limiting probability? My attempt: I came up with a very nasty answer. $\alpha_i = \frac{1}{i!}(\frac{1}{2})^{\sum_0^{i-1}i}(\frac{\lambda}{\mu})^i\alpha_0 \ $ for $i = 1,2,3,...$ $\alpha_0 = (1 + \sum_{1}^{\infty}\frac{1}{i!}(\frac{1}{2})^{\sum_0^{i-1}i}(\frac{\lambda}{\mu})^i\alpha_0 )^{-1}$ Does anyone has any idea if this is correct?","There is a selective group that people can join. Arrival of people who want to join the group is Poisson Process with parameter . The person who arrive at the group can join the group only if he/she gets approval from all existing members. Each member will say 'yes' with probability 1/2 and 'no' with probability 1/2. Also, each member of the group leaves the group independently at a Exponential distribution of time . The number of members of this group defines a birth and death process. What is the limiting probability? My attempt: I came up with a very nasty answer. for Does anyone has any idea if this is correct?","\lambda \mu \alpha_i = \frac{1}{i!}(\frac{1}{2})^{\sum_0^{i-1}i}(\frac{\lambda}{\mu})^i\alpha_0 \  i = 1,2,3,... \alpha_0 = (1 + \sum_{1}^{\infty}\frac{1}{i!}(\frac{1}{2})^{\sum_0^{i-1}i}(\frac{\lambda}{\mu})^i\alpha_0 )^{-1}","['probability', 'statistics', 'stochastic-processes', 'markov-chains', 'birth-death-process']"
37,Final Questions - Part 1 (Poisson Process),Final Questions - Part 1 (Poisson Process),,"After owing a lot to you guys on this website, I finally took my exam on Stochastic Process today! There were some questions in this exam that I was not sure about. I want to share it with you guys and see what you guys think. This is from my recollection of the exam that I took few hours ago so might not be 100% rigorous. Please understand and let me know if I am missing some details necessary. Of course, for legal issue, this is not completely the same as the exam itself. Black birds arrive at the John's office at the according to Poisson Process with parameter $\alpha$ . Independently of the black birds, yellow birds arrive at the office according to Poisson Process with parameter $\beta$ . Starting from 9:00AM until 10:AM, given that there were 3 black birds and 5 yellow birds arrived at the office, what is the probability that all 3 black birds arrived before 5 yellow birds? My answer : Unfortunately, I could not solve this question. But I tried my best to guess and gave two solutions: [Solution 1] Let $X_i$ ~ Unif( $0,1$ ), $i = 1,2,3$ be the arrival time of the black birds and $Y_k$ ~ Unif( $0,1$ ), $k = 1,2,3,4,5$ be the arrival time of the yellow birds. Therefore, we calculate: $\int^{1}_{0} P(max{X_i}<t) \cdot P(min{Y_k}>t) \ dt$ = $\int^{1}_{0} t^3(1-t)^5 \ dt$ Then I could not solve this integral by substitution or integration by parts. [Solution 2] $P$ ( $3$ black birds arrived before all $5$ yellow birds) = $P$ (first arrival was black bird) + $P$ (second arrival was black bird) + $P$ (third arrival was black bird)  = $\ {3 \choose 1}\frac{\alpha}{3\alpha + 5 \beta} + {2 \choose 1}\frac{\alpha}{2\alpha + 5 \beta} + {1 \choose 1}\frac{\alpha}{\alpha + 5 \beta} $ Is any of the solutions correct? Haha :')","After owing a lot to you guys on this website, I finally took my exam on Stochastic Process today! There were some questions in this exam that I was not sure about. I want to share it with you guys and see what you guys think. This is from my recollection of the exam that I took few hours ago so might not be 100% rigorous. Please understand and let me know if I am missing some details necessary. Of course, for legal issue, this is not completely the same as the exam itself. Black birds arrive at the John's office at the according to Poisson Process with parameter . Independently of the black birds, yellow birds arrive at the office according to Poisson Process with parameter . Starting from 9:00AM until 10:AM, given that there were 3 black birds and 5 yellow birds arrived at the office, what is the probability that all 3 black birds arrived before 5 yellow birds? My answer : Unfortunately, I could not solve this question. But I tried my best to guess and gave two solutions: [Solution 1] Let ~ Unif( ), be the arrival time of the black birds and ~ Unif( ), be the arrival time of the yellow birds. Therefore, we calculate: = Then I could not solve this integral by substitution or integration by parts. [Solution 2] ( black birds arrived before all yellow birds) = (first arrival was black bird) + (second arrival was black bird) + (third arrival was black bird)  = Is any of the solutions correct? Haha :')","\alpha \beta X_i 0,1 i = 1,2,3 Y_k 0,1 k = 1,2,3,4,5 \int^{1}_{0} P(max{X_i}<t) \cdot P(min{Y_k}>t) \ dt \int^{1}_{0} t^3(1-t)^5 \ dt P 3 5 P P P \ {3 \choose 1}\frac{\alpha}{3\alpha + 5 \beta} + {2 \choose 1}\frac{\alpha}{2\alpha + 5 \beta} + {1 \choose 1}\frac{\alpha}{\alpha + 5 \beta} ","['probability', 'statistics', 'stochastic-processes', 'markov-chains', 'poisson-process']"
38,Probability of Collision [binary vector],Probability of Collision [binary vector],,"Given a collection of nonzero distinct binary vectors $x_1,..., x_m \in {0,1}^n$ . To make look up faster, we hash them to vectors of length $p<n$ by means of a lienar mapping $x_i \rightarrow Ax_i$ where $A$ is a $p\times n$ matrix with 0-1 entries, and all computations are performed modulo 2. Suppose the entries of the matrix are picked uniformly at random (each independent coin toss)... 1- If we were to pick any $1 \leq i < j \leq m $ what is the prob. that $x_i$ and $x_j$ hash to the same vector and we have a collision? My attempt: I think that this is similar to the birthday problem from https://preshing.com/20110504/hash-collision-probabilities/ but I'm really unsure that we are bringing in an exponential 'e'. I'd guess from that link that the probability of collision = 1 - prob(no collision). So P(collision )= $1- e^{-p*(p-1)/2m}$ = $1- e^{-2*(2-1)/2m}$ = $1- e^{-1/m}$ . Is that correct or completely the wrong? ... or would you leave the answer in terms of p (I think we only pick one i and j so we can simplify here? 2- Prove that if $p \geq 2log_2 m$ , then with probability atleast $\frac{1}{2}$ there are no collisions among the $x_i$ . My attempt: I'd say I need the answer to above (which is why I was concerned) .... but we would need $\frac{1}{2} =$ P(No Collision) = $e^{-p*(p-1)/2m}$ ... but this is not simplifying to $log_2$ and instead would mean $2mln(\frac{1}{2})= -p^{2}-p$ . which is wrong b/c I will have that ln follow around ...","Given a collection of nonzero distinct binary vectors . To make look up faster, we hash them to vectors of length by means of a lienar mapping where is a matrix with 0-1 entries, and all computations are performed modulo 2. Suppose the entries of the matrix are picked uniformly at random (each independent coin toss)... 1- If we were to pick any what is the prob. that and hash to the same vector and we have a collision? My attempt: I think that this is similar to the birthday problem from https://preshing.com/20110504/hash-collision-probabilities/ but I'm really unsure that we are bringing in an exponential 'e'. I'd guess from that link that the probability of collision = 1 - prob(no collision). So P(collision )= = = . Is that correct or completely the wrong? ... or would you leave the answer in terms of p (I think we only pick one i and j so we can simplify here? 2- Prove that if , then with probability atleast there are no collisions among the . My attempt: I'd say I need the answer to above (which is why I was concerned) .... but we would need P(No Collision) = ... but this is not simplifying to and instead would mean . which is wrong b/c I will have that ln follow around ...","x_1,..., x_m \in {0,1}^n p<n x_i \rightarrow Ax_i A p\times n 1 \leq i < j \leq m  x_i x_j 1- e^{-p*(p-1)/2m} 1- e^{-2*(2-1)/2m} 1- e^{-1/m} p \geq 2log_2 m \frac{1}{2} x_i \frac{1}{2} = e^{-p*(p-1)/2m} log_2 2mln(\frac{1}{2})= -p^{2}-p","['probability', 'statistics', 'proof-verification', 'logic', 'problem-solving']"
39,chi-squared test statistic implementation in python,chi-squared test statistic implementation in python,,"I am tasked with creating a script version of a spreadsheet which does overall model testing of satellite measurements for land subsidence. In one particular cell of this spreadsheet, I see a formula as follows. Although it is not explicitly stated, I suspect that the cell is calculating a chi-squared test statistic: $$\chi^2 = \sum_{i=1}^n \frac{(z_i-z_{regr,i})^2}{\sigma_{assumed}^2}$$ I have done a bit of research into python libraries from which to generate this result because the idea of the script is to code as little as possible from scratch. Unfortunately, all online resources show that the test statistic is calculated as follows: $$\chi^2 = \sum_{i=1}^n \frac{(z_i-z_{regr,i})^2}{z_{regr, i}}$$ Part of the idea of this spreadsheet is that the standard deviation must be a user-defined input, and I cannot reconciliate that with the above formula. Furthermore, common python methods such as scipy.stats.chisquare only have the following mathematical inputs: f_obs : array_like     Observed frequencies in each category. f_exp : array_like, optional     Expected frequencies in each category.  By default the categories are     assumed to be equally likely. ddof : int, optional     ""Delta degrees of freedom"": adjustment to the degrees of freedom     for the p-value.  The p-value is computed using a chi-squared     distribution with ``k - 1 - ddof`` degrees of freedom, where `k`     is the number of observed frequencies.  The default value of `ddof`     is 0. And the following outputs: chisq : float or ndarray     The chi-squared test statistic.  The value is a float if `axis` is     None or `f_obs` and `f_exp` are 1-D. p : float or ndarray     The p-value of the test.  The value is a float if `ddof` and the     return value `chisq` are scalars. And never require standard deviation as input. My question is twofold: Is the first equation that I am showing correct? Why then is it different than the chi-squared test statistic provided in literature? If the first equation is correct, how can I use functions such as scipy.stats.chisquare to evaluate it, namely with an assumed $\sigma$ ? Thanks","I am tasked with creating a script version of a spreadsheet which does overall model testing of satellite measurements for land subsidence. In one particular cell of this spreadsheet, I see a formula as follows. Although it is not explicitly stated, I suspect that the cell is calculating a chi-squared test statistic: I have done a bit of research into python libraries from which to generate this result because the idea of the script is to code as little as possible from scratch. Unfortunately, all online resources show that the test statistic is calculated as follows: Part of the idea of this spreadsheet is that the standard deviation must be a user-defined input, and I cannot reconciliate that with the above formula. Furthermore, common python methods such as scipy.stats.chisquare only have the following mathematical inputs: f_obs : array_like     Observed frequencies in each category. f_exp : array_like, optional     Expected frequencies in each category.  By default the categories are     assumed to be equally likely. ddof : int, optional     ""Delta degrees of freedom"": adjustment to the degrees of freedom     for the p-value.  The p-value is computed using a chi-squared     distribution with ``k - 1 - ddof`` degrees of freedom, where `k`     is the number of observed frequencies.  The default value of `ddof`     is 0. And the following outputs: chisq : float or ndarray     The chi-squared test statistic.  The value is a float if `axis` is     None or `f_obs` and `f_exp` are 1-D. p : float or ndarray     The p-value of the test.  The value is a float if `ddof` and the     return value `chisq` are scalars. And never require standard deviation as input. My question is twofold: Is the first equation that I am showing correct? Why then is it different than the chi-squared test statistic provided in literature? If the first equation is correct, how can I use functions such as scipy.stats.chisquare to evaluate it, namely with an assumed ? Thanks","\chi^2 = \sum_{i=1}^n \frac{(z_i-z_{regr,i})^2}{\sigma_{assumed}^2} \chi^2 = \sum_{i=1}^n \frac{(z_i-z_{regr,i})^2}{z_{regr, i}} \sigma","['probability', 'statistics', 'python']"
40,Can we join CDF and Survival function in Copula,Can we join CDF and Survival function in Copula,,"Can we join CDF(cumulative density function) and Survival function like this in copula construction $$ H\left(x_1,x_2,x_3\right)=Pr\left(X_1<x_1,X_2>x_2,X_3<x_3\right) $$ or $$ H\left(x_1,x_2,x_3\right)=C\left(F_1\left(x_1\right), 1-F_2\left(x_2\right),F_3\left(x_3\right)\right)$$ or $$H\left(x_1,x_2,x_3\right)=C\left(F_1\left(x_1\right), S_2\left(x_2\right),F_3\left(x_3\right)\right) $$",Can we join CDF(cumulative density function) and Survival function like this in copula construction or or,"
H\left(x_1,x_2,x_3\right)=Pr\left(X_1<x_1,X_2>x_2,X_3<x_3\right)
 
H\left(x_1,x_2,x_3\right)=C\left(F_1\left(x_1\right), 1-F_2\left(x_2\right),F_3\left(x_3\right)\right) H\left(x_1,x_2,x_3\right)=C\left(F_1\left(x_1\right), S_2\left(x_2\right),F_3\left(x_3\right)\right) ",['statistics']
41,Gradient operator of the log multivariate Gaussian density,Gradient operator of the log multivariate Gaussian density,,"I'm trying to analytically find the gradient the log a multivariate Gaussian density, which is given by $$ f(x_{1}, \dots, x_{p}) = f(\vec{x}) = \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}} \exp \Bigg(-\frac{1}{2}(\vec{x} - \vec{\mu})^{T}\Sigma^{-1}(\vec{x} - \vec{\mu})\Bigg) \sim \mathcal{N}(\vec{\mu}, \Sigma) $$ where $\vec{x}, \vec{\mu} \in \mathbb{R}^{p}$ , and $\Sigma \in \mathbb{R}^{p \times p}$ . I want to find the analytical expression for $\nabla f$ , where $\nabla$ is the gradient operator defined as $$ \nabla f(\vec{x}) = \Bigg[ \frac{\partial f(\vec{x})}{\partial x_{1}}, \dots, \frac{\partial f(\vec{x})}{\partial x_{p}} \Bigg] $$ My vector calculus is very rusty and not sure how to take partial derivatives with respect to $x_{1}, \dots, x_{p}$ . Any help is much appreciated!","I'm trying to analytically find the gradient the log a multivariate Gaussian density, which is given by where , and . I want to find the analytical expression for , where is the gradient operator defined as My vector calculus is very rusty and not sure how to take partial derivatives with respect to . Any help is much appreciated!","
f(x_{1}, \dots, x_{p}) = f(\vec{x}) = \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}} \exp \Bigg(-\frac{1}{2}(\vec{x} - \vec{\mu})^{T}\Sigma^{-1}(\vec{x} - \vec{\mu})\Bigg) \sim \mathcal{N}(\vec{\mu}, \Sigma)
 \vec{x}, \vec{\mu} \in \mathbb{R}^{p} \Sigma \in \mathbb{R}^{p \times p} \nabla f \nabla 
\nabla f(\vec{x}) = \Bigg[ \frac{\partial f(\vec{x})}{\partial x_{1}}, \dots, \frac{\partial f(\vec{x})}{\partial x_{p}} \Bigg]
 x_{1}, \dots, x_{p}","['linear-algebra', 'statistics', 'multivariable-calculus', 'vectors', 'normal-distribution']"
42,How do you estimate the mean of a Poisson distribution from data?,How do you estimate the mean of a Poisson distribution from data?,,"I have thought of three different approaches for estimating the mean for a Poisson, but I am not sure which one is the correct method to estimate it (the third one is documented separately at the end of the question). For the sake of a concrete example, say that we want to find the Poisson distribution for the number of cars passing by in an hour (in front of our house or whatever). Say that we want to estimate this by standing outside of hours house for $t$ hours and counting the number $n$ of cars we saw. Then we could approximate the mean $\lambda$ as: $$\lambda \approx \frac{n}{t}$$ where $\lambda$ is the mean number of cars that we see per hour. That is first approach (which is the one I believe is the correct one). (note: that I know the first one is easier to do in real life for the specific example, but I am not concerned with that, I am concerned with the mathematical correctness) The second approach is the following approach. Instead imagine that for some reason we are only allowed to record how long it takes us to see 1 single specific car. We record how long it took to see car i as $\tau_i$ (hours). Now we could estimate how many cars we see expect to see in 1 hour by doing: $$ \lambda_i \approx \frac{1}{\tau_i}$$ [note that if $\tau_i < 1$, then we can have an mean value of seeing a car for an hour to be > 1] So now, say that instead we choose to do this on independent days and we took k of these time periods $\tau_i$ and instead we estimated the ""global"" mean by doing a average of the means: $$\lambda = \frac{1}{k}\sum^{k}_{i=1} \lambda_i = \frac{1}{k}\sum^{k}_{i=1} \frac{1}{\tau_i}$$ The second method might seem a little strange, but I was wondering if the two method where actually equivalent somehow, or if the second one was completely wrong and I why. The first one seems to be the correct one but I can't seem to ""prove"" to myself why my intuition says that. [notice that the second method has an interesting property where we can instead of weighting all of them equally, we can do a weighted average to maybe insert the intuitive concept of which $\tau_i$ we trust more for our certain application. A little tangential to my original question, but an interesting thought...] Bounty Section I forgot to add this the first time I asked the question and thought it was important to add it now (since this was the reason my question came up in the first place!). I have a different method for estimating the mean and was wondering if it was correct. Instead of waiting outside for t minutes, what if you did the following. You waited outside and recored how much time it took to see 1 car. Let $\tau_i$ be amount of time you waited to see the ith car. However, notice that after you see a car, you stop your stop-watch and later (maybe on another day), you restart your watch waiting to see the next occurrence of a single car (otherwise, if you you just stop your stop-watch and re-start it immediately, its just the same as the original MLE estimator I was asking about), and you obviously repeat this a but of times. In fact, assume you do this $n$ times (i.e. you see n cars and record how long it took to see each one). Then instead of doing my previous method of $\frac{1}{\tau_i}$, you instead try to do something similar to the first maximum likelihood method by doing the following: $$\lambda \approx \frac{n}{t} = \frac{n}{\sum^{n}_{i=1} \tau_i}$$ where t is the total time it took you to see n cars. But this time these cars were seen by n independent ""samples"". It feels that this method might not be correct but I was not sure. Is there something about necessarily having the total time interval t happen in one consecutive time interval?","I have thought of three different approaches for estimating the mean for a Poisson, but I am not sure which one is the correct method to estimate it (the third one is documented separately at the end of the question). For the sake of a concrete example, say that we want to find the Poisson distribution for the number of cars passing by in an hour (in front of our house or whatever). Say that we want to estimate this by standing outside of hours house for $t$ hours and counting the number $n$ of cars we saw. Then we could approximate the mean $\lambda$ as: $$\lambda \approx \frac{n}{t}$$ where $\lambda$ is the mean number of cars that we see per hour. That is first approach (which is the one I believe is the correct one). (note: that I know the first one is easier to do in real life for the specific example, but I am not concerned with that, I am concerned with the mathematical correctness) The second approach is the following approach. Instead imagine that for some reason we are only allowed to record how long it takes us to see 1 single specific car. We record how long it took to see car i as $\tau_i$ (hours). Now we could estimate how many cars we see expect to see in 1 hour by doing: $$ \lambda_i \approx \frac{1}{\tau_i}$$ [note that if $\tau_i < 1$, then we can have an mean value of seeing a car for an hour to be > 1] So now, say that instead we choose to do this on independent days and we took k of these time periods $\tau_i$ and instead we estimated the ""global"" mean by doing a average of the means: $$\lambda = \frac{1}{k}\sum^{k}_{i=1} \lambda_i = \frac{1}{k}\sum^{k}_{i=1} \frac{1}{\tau_i}$$ The second method might seem a little strange, but I was wondering if the two method where actually equivalent somehow, or if the second one was completely wrong and I why. The first one seems to be the correct one but I can't seem to ""prove"" to myself why my intuition says that. [notice that the second method has an interesting property where we can instead of weighting all of them equally, we can do a weighted average to maybe insert the intuitive concept of which $\tau_i$ we trust more for our certain application. A little tangential to my original question, but an interesting thought...] Bounty Section I forgot to add this the first time I asked the question and thought it was important to add it now (since this was the reason my question came up in the first place!). I have a different method for estimating the mean and was wondering if it was correct. Instead of waiting outside for t minutes, what if you did the following. You waited outside and recored how much time it took to see 1 car. Let $\tau_i$ be amount of time you waited to see the ith car. However, notice that after you see a car, you stop your stop-watch and later (maybe on another day), you restart your watch waiting to see the next occurrence of a single car (otherwise, if you you just stop your stop-watch and re-start it immediately, its just the same as the original MLE estimator I was asking about), and you obviously repeat this a but of times. In fact, assume you do this $n$ times (i.e. you see n cars and record how long it took to see each one). Then instead of doing my previous method of $\frac{1}{\tau_i}$, you instead try to do something similar to the first maximum likelihood method by doing the following: $$\lambda \approx \frac{n}{t} = \frac{n}{\sum^{n}_{i=1} \tau_i}$$ where t is the total time it took you to see n cars. But this time these cars were seen by n independent ""samples"". It feels that this method might not be correct but I was not sure. Is there something about necessarily having the total time interval t happen in one consecutive time interval?",,"['probability', 'statistics', 'probability-distributions']"
43,Kernel Density Estimation intuition,Kernel Density Estimation intuition,,"I just read this article about the motivation for KDE. From what I understand, you are using Gaussian probability density distributions for each datapoint and then, depending on the selected kernel width, you get a KDE curve. I had a few questions: What is the kernel width defined as, for these Gaussian distributions? Is it just the variance? From what I understand, you add the probability densities corresponding to each point to get the full KDE. What does the resulting value curve physically mean? Is it some sort of cumulative probability density?","I just read this article about the motivation for KDE. From what I understand, you are using Gaussian probability density distributions for each datapoint and then, depending on the selected kernel width, you get a KDE curve. I had a few questions: What is the kernel width defined as, for these Gaussian distributions? Is it just the variance? From what I understand, you add the probability densities corresponding to each point to get the full KDE. What does the resulting value curve physically mean? Is it some sort of cumulative probability density?",,"['statistics', 'data-analysis']"
44,Statistical Hypothesis Testing for $f(x)p(x)+g(y)q(y) \equiv C$,Statistical Hypothesis Testing for,f(x)p(x)+g(y)q(y) \equiv C,"$f(x)$ , $p(x)$ , $g(y)$ and $q(y)$ are four functions, where $f(x)$ and $g(y)$ are probability density functions. $C$ is a constant. Now I have some statistics $x_1,...,x_n$ and $y_1,...,y_n$ , where $x_i \sim f(x)$ and $y_i \sim g(x)$ . $p(x_i)$ and $q(y_i)$ are known for all $i$ . Is there any statistical hypothesis testing method for the hypothesis $f(x)p(x)+g(y)q(y) \equiv C$ ? If not, what about a simplified problem where $p(x) \equiv q(y) \equiv 1$ ?",", , and are four functions, where and are probability density functions. is a constant. Now I have some statistics and , where and . and are known for all . Is there any statistical hypothesis testing method for the hypothesis ? If not, what about a simplified problem where ?","f(x) p(x) g(y) q(y) f(x) g(y) C x_1,...,x_n y_1,...,y_n x_i \sim f(x) y_i \sim g(x) p(x_i) q(y_i) i f(x)p(x)+g(y)q(y) \equiv C p(x) \equiv q(y) \equiv 1","['statistics', 'hypothesis-testing']"
45,How to get the sample number?,How to get the sample number?,,"I have this statement: The weights of a school are distributed in a normal way $\sim N(85, > 8)$ If a sampling is done. what should be the size of this sample, so that   the probability of the mean of this sample is less than $87$ , is $0.977$ ? My attempt: I need a sample $K$ of the weights, of size $n$ , such that $P(\overline K<87) = 0.977$ . So $n$ need to be $> 30$ (according to central limit theorem) and thus $\overline K \sim N(85, \frac{8}{\sqrt{n}})$ . Now I standardize the normal distribution. $P(\overline K<87) = P(Z < \frac{\sqrt{n}}{4})$ , where $Z$ is a random var $\sim N(0,1)$ . So i have: $P(Z < \frac{\sqrt{n}}{4}) = 0.977$ But from here, I do not know how to calculate $n$ . Any hint is appreciated. PD: I must not use the formula or calculus, and the answer must be $64$","I have this statement: The weights of a school are distributed in a normal way If a sampling is done. what should be the size of this sample, so that   the probability of the mean of this sample is less than , is ? My attempt: I need a sample of the weights, of size , such that . So need to be (according to central limit theorem) and thus . Now I standardize the normal distribution. , where is a random var . So i have: But from here, I do not know how to calculate . Any hint is appreciated. PD: I must not use the formula or calculus, and the answer must be","\sim N(85,
> 8) 87 0.977 K n P(\overline K<87) = 0.977 n > 30 \overline K \sim N(85, \frac{8}{\sqrt{n}}) P(\overline K<87) = P(Z < \frac{\sqrt{n}}{4}) Z \sim N(0,1) P(Z < \frac{\sqrt{n}}{4}) = 0.977 n 64",['statistics']
46,Comparing the marks of students from different universities,Comparing the marks of students from different universities,,"The standard deviation of first year statistics exam marks is known to be $14$ . A sample of $50$ first year statistics students from University A had a mean exam mark of $75$ , while a sample of $36$ University B students had a sample mean of $80$ . Test at the $10$ % level of significance whether the marks for University B are significantly better than A. I want to know if a one-sided ( $\mu_{A}<\mu_{B}$ ) hypothesis test is appropriate for this question and if the critical value $z$ is $-1.28$ (very important!) and the test statistic $Z$ is $-1.634$ .","The standard deviation of first year statistics exam marks is known to be . A sample of first year statistics students from University A had a mean exam mark of , while a sample of University B students had a sample mean of . Test at the % level of significance whether the marks for University B are significantly better than A. I want to know if a one-sided ( ) hypothesis test is appropriate for this question and if the critical value is (very important!) and the test statistic is .",14 50 75 36 80 10 \mu_{A}<\mu_{B} z -1.28 Z -1.634,"['statistics', 'hypothesis-testing']"
47,Pdf of joint independent random variables yield strange results,Pdf of joint independent random variables yield strange results,,"I have the following problem: I want to compute the value of $<P_T>$ as a function of $P_L$ meaning $$ <P_T> = f(P_L) $$ Where $P_T = Psin(\theta)$ and $P_L = Pcos(\theta)$ .  P has a uniform distribution in [0, 10] and so do $\theta$ in [0, 2 $\pi$ ]. For simplicity let's call $P\rightarrow x$ : $$f_X(x) = \begin{cases}\frac{1}{10} & x \in [0, 10] \\ 0 & otherwise \end{cases} $$ Now: $$f_\theta(\Theta) = \begin{cases}\frac{1}{2\pi} & \Theta \in [0, 2\pi] \\ 0 & otherwise \end{cases} $$ Let's now call $sin(\theta) \rightarrow y$ then, thanks to Jacobian formula: $$f_Y(y) = \begin{cases}\frac{1}{\pi\sqrt{(1-y^2)}} & y \in [-1,1] \\ 0 & otherwise \end{cases} $$ I want to compute the pdf of $P_T \rightarrow z = xy$ using the formula: $$f_Z(z) = \int_{-\infty}^{\infty} f_X(x)f_Y(\frac{z}{x})\frac{1}{|x|}dx $$ This means to me: $$f_Z(z) = \int_{0}^{10} \frac{1}{10\pi}\frac{1}{\sqrt{(1-\frac{z^2}{x^2}})}\frac{1}{|x|}dx = \frac{1}{10\pi} \big[log(\sqrt{x^2-z^2} + x)\big]_{x = 0}^{x = 10}$$ Now I have a problem meaning that for $x = 0$ the right hand side of the previous equation evaluates to: $$log(\sqrt{x^2-z^2} + x) |_{x=0} = log(\sqrt{-z^2}) $$ As $z=P_T$ takes real values in the range [0,10] I think that the formula is wrong but I can't find a way to make it right. Can someone spot the error? BTW to compute $<z>$ I thought of doing $<z> = \int zf_Z(z)dz$ hoping to find some dependence only on $P_L$ . That's why, with this reasoning I need the pdf of $z$ . Thank you everyone for your help.","I have the following problem: I want to compute the value of as a function of meaning Where and .  P has a uniform distribution in [0, 10] and so do in [0, 2 ]. For simplicity let's call : Now: Let's now call then, thanks to Jacobian formula: I want to compute the pdf of using the formula: This means to me: Now I have a problem meaning that for the right hand side of the previous equation evaluates to: As takes real values in the range [0,10] I think that the formula is wrong but I can't find a way to make it right. Can someone spot the error? BTW to compute I thought of doing hoping to find some dependence only on . That's why, with this reasoning I need the pdf of . Thank you everyone for your help.","<P_T> P_L  <P_T> = f(P_L)  P_T = Psin(\theta) P_L = Pcos(\theta) \theta \pi P\rightarrow x f_X(x) = \begin{cases}\frac{1}{10} & x \in [0, 10] \\ 0 & otherwise \end{cases}  f_\theta(\Theta) = \begin{cases}\frac{1}{2\pi} & \Theta \in [0, 2\pi] \\ 0 & otherwise \end{cases}  sin(\theta) \rightarrow y f_Y(y) = \begin{cases}\frac{1}{\pi\sqrt{(1-y^2)}} & y \in [-1,1] \\ 0 & otherwise \end{cases}  P_T \rightarrow z = xy f_Z(z) = \int_{-\infty}^{\infty} f_X(x)f_Y(\frac{z}{x})\frac{1}{|x|}dx  f_Z(z) = \int_{0}^{10} \frac{1}{10\pi}\frac{1}{\sqrt{(1-\frac{z^2}{x^2}})}\frac{1}{|x|}dx = \frac{1}{10\pi} \big[log(\sqrt{x^2-z^2} + x)\big]_{x = 0}^{x = 10} x = 0 log(\sqrt{x^2-z^2} + x) |_{x=0} = log(\sqrt{-z^2})  z=P_T <z> <z> = \int zf_Z(z)dz P_L z","['probability', 'statistics', 'probability-distributions', 'physics', 'mathematical-physics']"
48,Kullback-Leibler divergence from mixture distribution to its components,Kullback-Leibler divergence from mixture distribution to its components,,"Suppose $f$ is the density of a mixture distribution with half the weight on a standard normal distribution and half the weight on a logistic distribution rescaled to have standard deviation $1$ . Now let $g$ be the density of the standard normal distribution and $h$ the distribution of this rescaled logistic distribution. Then $$g(x) = \frac{1}{\sqrt{2\pi}}e^{-x^2/2}$$ $$h(x) = \frac{\pi}{\sqrt{3}} \frac{e^{-\pi x/\sqrt{3}}}{(1+e^{-\pi x/\sqrt{3}})^2}$$ $$f(x) = \frac{1}{2}g(x) + \frac{1}{2}h(x).$$ I am wondering about the Kullback-Leibler divergences $KL(f, g)$ and $KL(f, h)$ . In particular, I'd like to know which one is smaller. I have simulated a time series from this mixture distribution and performed Bayesian model averaging on it, where I also included Gaussian and logistic models. In theory, I should end up with the posterior of the distribution with smallest divergence converging to 1, but it seems that the posteriors do not actually converge, even after a sample of $7500$ observations. Hence, this made me want to attack this problem analytically. Could it perhaps be that the divergences are equal or at least very close? I am struggling to calculate the divergences myself, since I either end up with a very nasty integral or a very nasty expectation. Could someone help me figure this out?","Suppose is the density of a mixture distribution with half the weight on a standard normal distribution and half the weight on a logistic distribution rescaled to have standard deviation . Now let be the density of the standard normal distribution and the distribution of this rescaled logistic distribution. Then I am wondering about the Kullback-Leibler divergences and . In particular, I'd like to know which one is smaller. I have simulated a time series from this mixture distribution and performed Bayesian model averaging on it, where I also included Gaussian and logistic models. In theory, I should end up with the posterior of the distribution with smallest divergence converging to 1, but it seems that the posteriors do not actually converge, even after a sample of observations. Hence, this made me want to attack this problem analytically. Could it perhaps be that the divergences are equal or at least very close? I am struggling to calculate the divergences myself, since I either end up with a very nasty integral or a very nasty expectation. Could someone help me figure this out?","f 1 g h g(x) = \frac{1}{\sqrt{2\pi}}e^{-x^2/2} h(x) = \frac{\pi}{\sqrt{3}} \frac{e^{-\pi x/\sqrt{3}}}{(1+e^{-\pi x/\sqrt{3}})^2} f(x) = \frac{1}{2}g(x) + \frac{1}{2}h(x). KL(f, g) KL(f, h) 7500","['probability', 'statistics', 'bayesian']"
49,Calculation of alarm level for a signal detection in Poisson distributed noise,Calculation of alarm level for a signal detection in Poisson distributed noise,,"I am trying out my luck with the first post here... Well, to start off I have a problem, and I am not really sure about the solution. I hope that someone might chime in with suggestions.. We have an ionizing radiation detector. It is sampling the radiation induced counts each second. The counts in the detector are Poisson distributed. Then, a source might pass the detector giving rise to the number of counts in the detector for some time. We want to have a threshold for counts in the detector, which when passed would indicate that there is a source nearby. The question is whether we are correctly estimating the threshold for a certain detection criteria set for a given number of false alarms. For example, given, that the total survey time is one hour there are 3600 individual measurements in total. We want to set the threshold of detection to 1 false alarm per hour or 1 in every 3600 measurements. Due to the fact, that the counts in the detector are Poisson distributed around the mean of $\lambda_\text{bkg}$ , we can estimate the threshold level $N_\text{alarm}$ using Poisson CDF for a probability of $P_\text{alarm}=1-\frac{1}{3600}$ .  To do that, I am using qpois(lambda,p) function in R. As far as I understand it should yield correct alarm level. Testing the results using a number of simulated one-hour measurements yields average probability of any number of alarms of around 25% for a given one-hour survey. For a number of alarms greater than one, the probability is around 3%. Is this correct? Or maybe I missing something?","I am trying out my luck with the first post here... Well, to start off I have a problem, and I am not really sure about the solution. I hope that someone might chime in with suggestions.. We have an ionizing radiation detector. It is sampling the radiation induced counts each second. The counts in the detector are Poisson distributed. Then, a source might pass the detector giving rise to the number of counts in the detector for some time. We want to have a threshold for counts in the detector, which when passed would indicate that there is a source nearby. The question is whether we are correctly estimating the threshold for a certain detection criteria set for a given number of false alarms. For example, given, that the total survey time is one hour there are 3600 individual measurements in total. We want to set the threshold of detection to 1 false alarm per hour or 1 in every 3600 measurements. Due to the fact, that the counts in the detector are Poisson distributed around the mean of , we can estimate the threshold level using Poisson CDF for a probability of .  To do that, I am using qpois(lambda,p) function in R. As far as I understand it should yield correct alarm level. Testing the results using a number of simulated one-hour measurements yields average probability of any number of alarms of around 25% for a given one-hour survey. For a number of alarms greater than one, the probability is around 3%. Is this correct? Or maybe I missing something?",\lambda_\text{bkg} N_\text{alarm} P_\text{alarm}=1-\frac{1}{3600},"['statistics', 'physics', 'signal-processing', 'poisson-distribution', 'poisson-process']"
50,Conditional expectation calculation: $E[\frac{\sum_{i=1}^n \Bbb{I}_{X_i \le 2}}{n}| \sum_{i=1}^n X_i]$,Conditional expectation calculation:,E[\frac{\sum_{i=1}^n \Bbb{I}_{X_i \le 2}}{n}| \sum_{i=1}^n X_i],"I am trying to calculate the UMVUE for $Pr[X_1\le 2]$ where $X_1,...X_n \sim_{iid} Exp(\theta) $ . I know that the average number of incidents where the random variable is less than or equal to $2$ is an unbiased estimator of $Pr[X_1\le2]$ .  Thus, $$E \left[\frac{\sum_{i=1}^n\Bbb{I}_{X_i \le 2}}{n} \right] = Pr[X_1\le2]$$ The problem that I have is here. Utilizing Lehmann-Scheffe's Theorem I want to evaluate $$E \left[\frac{\sum_{i=1}^n\Bbb{I}_{X_i \le 2}}{n} | \sum_{i=1}^nX_i \right] $$ but I am not sure how to procede from here. Letting $Y=\sum_{i=1}^nX_i$ I know that $Y \sim \Gamma(n,\theta)$ so I know its distribution and I have $$nE \left[\sum_{i=1}^n \Bbb X_i\le 2 | Y \right]$$","I am trying to calculate the UMVUE for where . I know that the average number of incidents where the random variable is less than or equal to is an unbiased estimator of .  Thus, The problem that I have is here. Utilizing Lehmann-Scheffe's Theorem I want to evaluate but I am not sure how to procede from here. Letting I know that so I know its distribution and I have","Pr[X_1\le 2] X_1,...X_n \sim_{iid} Exp(\theta)  2 Pr[X_1\le2] E \left[\frac{\sum_{i=1}^n\Bbb{I}_{X_i \le 2}}{n} \right] = Pr[X_1\le2] E \left[\frac{\sum_{i=1}^n\Bbb{I}_{X_i \le 2}}{n} | \sum_{i=1}^nX_i \right]  Y=\sum_{i=1}^nX_i Y \sim \Gamma(n,\theta) nE \left[\sum_{i=1}^n \Bbb X_i\le 2 | Y \right]","['probability', 'statistics', 'conditional-expectation']"
51,"Why does $E[X^ku(X)]=0, \space \forall k \in \Bbb{N}$ imply $u(X)=0$?",Why does  imply ?,"E[X^ku(X)]=0, \space \forall k \in \Bbb{N} u(X)=0","I am given a situation where $X_1,X_2,...X_n \sim_{iid} X$ with pdf $f_X(x;\theta)$ and $u(X)$ is an unbiased and sufficient estimator of $\theta$ . I am working on proofs where I am trying to find if $X$ is complete and it seems that as long as $E[u(X)]=0$ is given and you can show that $E[X^ku(X)]=0$ for any natural number $k$ then you can show $u(X)=0$ . I do not know why the last logic works. May I have some help please?",I am given a situation where with pdf and is an unbiased and sufficient estimator of . I am working on proofs where I am trying to find if is complete and it seems that as long as is given and you can show that for any natural number then you can show . I do not know why the last logic works. May I have some help please?,"X_1,X_2,...X_n \sim_{iid} X f_X(x;\theta) u(X) \theta X E[u(X)]=0 E[X^ku(X)]=0 k u(X)=0","['probability', 'statistics', 'parameter-estimation']"
52,Moment Matching Distributions,Moment Matching Distributions,,"I have to estimate the coefficients $c_1,...,c_n$ of the relationship $$ Y = c_1X_1+c_2X_2+\cdots + c_nX_n $$ So the distribution of $Y$ is given through a linear combination of other random variables. Further there is the fact that for any sample of $X_1,...,X_n$ it holds that $$ 0\leq\sum_{i=1}^nX_i<1 $$ I have ways to generate samples for $Y,X_1,...,X_n$ , giving me a linear system of equations. One way to estimate the coefficients $c_1,...,c_n$ in that case would be through least squares. But I'd like to do better than that. Another alternative would be to use moment matching (with centralized moments), e.g., $$ E[(Y-E[Y])^m] = E[(c_1X_1+c_2X_2+\cdots + c_nX_n-E[c_1X_1+c_2X_2+\cdots + c_nX_n])^m] $$ which would add further equations for higher moments with $m>1$ . This however leads to a system of equations which is non-linear in the parameters $c_1,...,c_n$ . Are there any principled ways to solve such non-linear systems? The best idea I had so far (for $m=1,...,N$ ) is to find a numerical solution through optimizing the squared loss of the LHS and the RHS of the equation through gradient descent. Do you have any better ideas or principled approaches to suggest?","I have to estimate the coefficients of the relationship So the distribution of is given through a linear combination of other random variables. Further there is the fact that for any sample of it holds that I have ways to generate samples for , giving me a linear system of equations. One way to estimate the coefficients in that case would be through least squares. But I'd like to do better than that. Another alternative would be to use moment matching (with centralized moments), e.g., which would add further equations for higher moments with . This however leads to a system of equations which is non-linear in the parameters . Are there any principled ways to solve such non-linear systems? The best idea I had so far (for ) is to find a numerical solution through optimizing the squared loss of the LHS and the RHS of the equation through gradient descent. Do you have any better ideas or principled approaches to suggest?","c_1,...,c_n 
Y = c_1X_1+c_2X_2+\cdots + c_nX_n
 Y X_1,...,X_n 
0\leq\sum_{i=1}^nX_i<1
 Y,X_1,...,X_n c_1,...,c_n 
E[(Y-E[Y])^m] = E[(c_1X_1+c_2X_2+\cdots + c_nX_n-E[c_1X_1+c_2X_2+\cdots + c_nX_n])^m]
 m>1 c_1,...,c_n m=1,...,N","['statistics', 'numerical-methods', 'maximum-likelihood']"
53,Non-parametric confidence interval (Chebyshev inequality),Non-parametric confidence interval (Chebyshev inequality),,"I want to solve the following exercise: Given is an expected value of random variable X, E(X) = 200 at time point t and a standard deviation of 50. (a) Find the 95% confidence interval of the random variable at this time point t. (b) What is the probability that the value of the Random Variable is at least 300? There is no probability distribution and no further data given. My approach: As one of the comments points out, I am using Chebyshev's theorem: $$P(|X-\mu|\ge k\sigma)\le\frac{1}{k^2}$$ I find the following results - are these correct? (a) For $1 - \frac{1}{k^2}$ = 0.95 I find k = 4.4721 and hence with $k\sigma-\mu \leq X \leq k\sigma+\mu$ I find the lower bound of 23.6 and the upper bound of 423.6068 for the 95% confidence interval. (b) Not quite sure here, but my approach would be using $$|X-200|\ge 100$$ with $\sigma = 50$ we get $\frac{1}{2^2}$ and hence a probability of 25% for a value of X being at least 300. Is that correct?","I want to solve the following exercise: Given is an expected value of random variable X, E(X) = 200 at time point t and a standard deviation of 50. (a) Find the 95% confidence interval of the random variable at this time point t. (b) What is the probability that the value of the Random Variable is at least 300? There is no probability distribution and no further data given. My approach: As one of the comments points out, I am using Chebyshev's theorem: I find the following results - are these correct? (a) For = 0.95 I find k = 4.4721 and hence with I find the lower bound of 23.6 and the upper bound of 423.6068 for the 95% confidence interval. (b) Not quite sure here, but my approach would be using with we get and hence a probability of 25% for a value of X being at least 300. Is that correct?",P(|X-\mu|\ge k\sigma)\le\frac{1}{k^2} 1 - \frac{1}{k^2} k\sigma-\mu \leq X \leq k\sigma+\mu |X-200|\ge 100 \sigma = 50 \frac{1}{2^2},"['probability', 'statistics', 'confidence-interval']"
54,Why can't I calculate the $R^2$ in some regression models if I use the method of maximum likelihood estimation?,Why can't I calculate the  in some regression models if I use the method of maximum likelihood estimation?,R^2,"I've modeled two regression models the first is a multiple linear regression (OLS) $$Y=\beta_0+\beta_1X_1+...+\beta_nX_n+e$$ and I can get its $R^2$ . The second model is a spatial autoregressive model (SAR) $$Y=\rho W+\beta_0+\beta_1X_1+...+\beta_nX_n+e$$ where W is the contiguity matrix and $\rho$ is an unknown parameter. This model is estimated by the method of maximum likelihood but I cannot calculate its $R^2$ and rather I have to use the $R^2$ Nalgerkerke. I've found this ""There is no direct equivalent to the OLS R-squared, these models are fitted by maximum likelihood."" from http://r-sig-geo.2731867.n2.nabble.com/How-to-calculate-squared-R-of-spatial-autoregressive-models-td5762576.html but I'd like to know why I cannot calculate $R^2$ for this model if the formula is just $$R^2=1-\frac{\sum(y_i-\hat{y_i})^2}{\sum(y_i-\overline{y})^2}$$","I've modeled two regression models the first is a multiple linear regression (OLS) and I can get its . The second model is a spatial autoregressive model (SAR) where W is the contiguity matrix and is an unknown parameter. This model is estimated by the method of maximum likelihood but I cannot calculate its and rather I have to use the Nalgerkerke. I've found this ""There is no direct equivalent to the OLS R-squared, these models are fitted by maximum likelihood."" from http://r-sig-geo.2731867.n2.nabble.com/How-to-calculate-squared-R-of-spatial-autoregressive-models-td5762576.html but I'd like to know why I cannot calculate for this model if the formula is just",Y=\beta_0+\beta_1X_1+...+\beta_nX_n+e R^2 Y=\rho W+\beta_0+\beta_1X_1+...+\beta_nX_n+e \rho R^2 R^2 R^2 R^2=1-\frac{\sum(y_i-\hat{y_i})^2}{\sum(y_i-\overline{y})^2},"['statistics', 'maximum-likelihood', 'linear-regression']"
55,UMP test for testing $f=f_0$ vs $f=f_1$ where $f$ is discrete,UMP test for testing  vs  where  is discrete,f=f_0 f=f_1 f,"As I was studying for my exam I came across the following problem: Let $X$ be a discrete random variable with probability mass function (pmf) given by $f(x) = P(X = x)$ . Further, consider the situation in which $f(x)$ can take on one of two forms which are given in the following table: Determine the uniformly most powerful (UMP) test for $H_0 : f = f_0$ vs. $H_1 : f = f_1$ at the $\alpha = 0.3$ level. I know that to find the UMP of a test you must start by setting up the likelihood ratio. However, I am not sure how to do so in this case. Any suggestions are appreciated. After receiving a hint from @StubbornAtom and doing some more reading, here my attempt to solve this problem. Since our hypothesis test is a simple hypothesis test we can use Neymann-Pearson Lemma, which states the LRT is the UMP of such hypothesis tests. We let $\lambda(x)=\frac{f_1(x)}{f_0(x)}$ and we reject $H_0$ if $\lambda(x)>k$ . In our case the LRT is as follows: $\frac{f_1(1)}{f_0(1)}=3/2$ , $\frac{f_1(2)}{f_0(2)}=1/3$ , $\frac{f_1(3)}{f_0(3)}=3$ , $\frac{f_1(5)}{f_0(5)}=2/3$ , $\frac{f_1(7)}{f_0(7)}=1$ . From here we see that the greatest value of the LRT is $3$ and it happens when $x=3$ . Therefore, our critical region is $\{x=3\}$ . Thus, we reject $H_0$ if $X = 3$ . The significance of this test $\alpha=P(\text{reject } H_0\mid H_0)=P(X=3\mid f_0)=0.1$ . But we need it to be 0.3 I would appreciate a thumbs up or down for my attempt to solve this problem. Thank you!","As I was studying for my exam I came across the following problem: Let be a discrete random variable with probability mass function (pmf) given by . Further, consider the situation in which can take on one of two forms which are given in the following table: Determine the uniformly most powerful (UMP) test for vs. at the level. I know that to find the UMP of a test you must start by setting up the likelihood ratio. However, I am not sure how to do so in this case. Any suggestions are appreciated. After receiving a hint from @StubbornAtom and doing some more reading, here my attempt to solve this problem. Since our hypothesis test is a simple hypothesis test we can use Neymann-Pearson Lemma, which states the LRT is the UMP of such hypothesis tests. We let and we reject if . In our case the LRT is as follows: , , , , . From here we see that the greatest value of the LRT is and it happens when . Therefore, our critical region is . Thus, we reject if . The significance of this test . But we need it to be 0.3 I would appreciate a thumbs up or down for my attempt to solve this problem. Thank you!",X f(x) = P(X = x) f(x) H_0 : f = f_0 H_1 : f = f_1 \alpha = 0.3 \lambda(x)=\frac{f_1(x)}{f_0(x)} H_0 \lambda(x)>k \frac{f_1(1)}{f_0(1)}=3/2 \frac{f_1(2)}{f_0(2)}=1/3 \frac{f_1(3)}{f_0(3)}=3 \frac{f_1(5)}{f_0(5)}=2/3 \frac{f_1(7)}{f_0(7)}=1 3 x=3 \{x=3\} H_0 X = 3 \alpha=P(\text{reject } H_0\mid H_0)=P(X=3\mid f_0)=0.1,"['statistics', 'statistical-inference', 'hypothesis-testing']"
56,Equivalent to Tao's Analysis 1 Book for Statistics,Equivalent to Tao's Analysis 1 Book for Statistics,,"I am looking a book recommendation that is equivalent to Tao's Analysis I for Statistics. Would you share your recommendations? In particular, it would be ideal to find a book that starts with a measure-theoretic probability set-up and takes off from there, published primarily aiming for advanced undergrad or first-year Ph.D. student readers. Note I am not looking for a probability book, but a statistics book. Thanks in advance!","I am looking a book recommendation that is equivalent to Tao's Analysis I for Statistics. Would you share your recommendations? In particular, it would be ideal to find a book that starts with a measure-theoretic probability set-up and takes off from there, published primarily aiming for advanced undergrad or first-year Ph.D. student readers. Note I am not looking for a probability book, but a statistics book. Thanks in advance!",,"['statistics', 'reference-request', 'book-recommendation']"
57,why is the population standard deviation approximated as the sample standard deviation [closed],why is the population standard deviation approximated as the sample standard deviation [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 5 years ago . Improve this question This question addresses calculating a p value from the mean and standard deviation statistics of a sample.  I understand that the -general- philosophy is to divide the sample standard deviation by the root of the population size to get the standard deviation of the sampling distribution, using the assumption that the standard deviation of the sample is roughly equal to the standard deviation of the hypothetical larger population.  Then one calculates a z-score from the number of standard deviations of the sampling distribution to calculate what percent of the time the observed result would have occurred by random chance.  I understand that the particular formula for the sampling distribution standard deviation depends on the particular statistic, say difference of means is a different formula. The texts and videos that I've looked at use language like ""the sample standard deviation is the best number we have available to estimate the population standard deviation.""  I just don't find that explanation satisfying. This approach hinges on the validity of estimating the standard deviation of the entire population as being approximately equal to the standard deviation of the representative sample.  However, we don't make the same assumption that the mean of the population is the approximately equal to the mean of the sample.  At some level, it feels like the final result of significance or non-significance is only self-validating or checking for self-consistency of an assumption that is baked into the methodology. So to restate, why is the sample standard deviation a good approximation of the populatoin standard deviation, but the sample mean is not a good approximation of the population mean?  I found online an equation for standard deviation of the sampling distribution of standard deviations: standard error of standard deviation = .71 sample standard deviation / root N. Does the relative narrowness of the standard error compared to standard deviation play a role in justifying the approximation? Thank you","Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 5 years ago . Improve this question This question addresses calculating a p value from the mean and standard deviation statistics of a sample.  I understand that the -general- philosophy is to divide the sample standard deviation by the root of the population size to get the standard deviation of the sampling distribution, using the assumption that the standard deviation of the sample is roughly equal to the standard deviation of the hypothetical larger population.  Then one calculates a z-score from the number of standard deviations of the sampling distribution to calculate what percent of the time the observed result would have occurred by random chance.  I understand that the particular formula for the sampling distribution standard deviation depends on the particular statistic, say difference of means is a different formula. The texts and videos that I've looked at use language like ""the sample standard deviation is the best number we have available to estimate the population standard deviation.""  I just don't find that explanation satisfying. This approach hinges on the validity of estimating the standard deviation of the entire population as being approximately equal to the standard deviation of the representative sample.  However, we don't make the same assumption that the mean of the population is the approximately equal to the mean of the sample.  At some level, it feels like the final result of significance or non-significance is only self-validating or checking for self-consistency of an assumption that is baked into the methodology. So to restate, why is the sample standard deviation a good approximation of the populatoin standard deviation, but the sample mean is not a good approximation of the population mean?  I found online an equation for standard deviation of the sampling distribution of standard deviations: standard error of standard deviation = .71 sample standard deviation / root N. Does the relative narrowness of the standard error compared to standard deviation play a role in justifying the approximation? Thank you",,"['probability', 'statistics']"
58,What is the large-n limit of a distribution of the following sample statistic:,What is the large-n limit of a distribution of the following sample statistic:,,"What is the large-n limit of a distribution of the following sample statistic: $$\displaystyle\frac{\sum^{n}X_{i}}{\,\sqrt{\,\sum^{n}X_{i}^{2}\,}\,}$$ when sampling the Cauchy(0,1) distribution? Monte Carlo simulation indicates that convergence to this limit is quite fast, and that the resulting (symmetric) PDF has very sharp cusps at -1 and +1, but of course does not yield an analytic expression for this PDF - would anyone be able to find it? The following graph indicates how the positive half of the PDF looks like:","What is the large-n limit of a distribution of the following sample statistic: when sampling the Cauchy(0,1) distribution? Monte Carlo simulation indicates that convergence to this limit is quite fast, and that the resulting (symmetric) PDF has very sharp cusps at -1 and +1, but of course does not yield an analytic expression for this PDF - would anyone be able to find it? The following graph indicates how the positive half of the PDF looks like:","\displaystyle\frac{\sum^{n}X_{i}}{\,\sqrt{\,\sum^{n}X_{i}^{2}\,}\,}","['probability', 'statistics', 'probability-distributions', 'probability-limit-theorems']"
59,Calculate Earth Movers Distance on samples,Calculate Earth Movers Distance on samples,,"I understand how to calculate the Earth Movers Distance Earth Movers Distance of discrete distributions. However, how would I calculate it if I only have sets of samples $\in \mathbb{R}^N$ from two different distributions? (I assume that one uses every sample as its own cluster and move it to a partner sample of the other distribution?). If that is correct, how is it with different amount of samples in the two sets from the two distributions?","I understand how to calculate the Earth Movers Distance Earth Movers Distance of discrete distributions. However, how would I calculate it if I only have sets of samples from two different distributions? (I assume that one uses every sample as its own cluster and move it to a partner sample of the other distribution?). If that is correct, how is it with different amount of samples in the two sets from the two distributions?",\in \mathbb{R}^N,"['probability-theory', 'statistics']"
60,How to calculate reletive weights (alpha) in Principal Component Analysis,How to calculate reletive weights (alpha) in Principal Component Analysis,,"I am trying to work through the method described in this paper of calculating a normalcy index using principal component analysis. I understand steps 1-5, except for the equation for eigenvectors which is $\mathbf e_i = \sum_{j=1}^N \alpha_j^ix_j$ where $\alpha_j^i$ are ""relative weights determined solely by the orthonormality constraint."" The matrix containing $\mathbf x_j$ is a 10x8 matrix but the eigenvectors ( $\mathbf e_i$ ) are from the covariance matrix which is 8x8 (I did that part in MATLAB). Because there is a difference in matrix dimensions I can't divide $\mathbf e_i$ by $\mathbf x_j$ to find $\mathbf \alpha_j^i$ . I need $\mathbf \alpha_j^i$ to complete the next steps (as far as I can tell) including mutiplying it by another 10x8 matrix $\mathbf z_j$ . Please help me understand how I'm supposed to calculate $\mathbf \alpha_j^i$","I am trying to work through the method described in this paper of calculating a normalcy index using principal component analysis. I understand steps 1-5, except for the equation for eigenvectors which is where are ""relative weights determined solely by the orthonormality constraint."" The matrix containing is a 10x8 matrix but the eigenvectors ( ) are from the covariance matrix which is 8x8 (I did that part in MATLAB). Because there is a difference in matrix dimensions I can't divide by to find . I need to complete the next steps (as far as I can tell) including mutiplying it by another 10x8 matrix . Please help me understand how I'm supposed to calculate",\mathbf e_i = \sum_{j=1}^N \alpha_j^ix_j \alpha_j^i \mathbf x_j \mathbf e_i \mathbf e_i \mathbf x_j \mathbf \alpha_j^i \mathbf \alpha_j^i \mathbf z_j \mathbf \alpha_j^i,"['linear-algebra', 'matrices', 'statistics', 'matlab', 'machine-learning']"
61,prove that a process is an MA(q),prove that a process is an MA(q),,"We are given the following polynomial : $$\Theta(z) = 1 + \theta_1 z + ...+ \theta_q z^q  $$ and we suppose that $(z_t)_{t \in \mathbb{Z}}$ is weakly stationnary and its spectral measure is given by : $$ \mu_z(d\omega) = |\Theta(e^{i\omega})|^2\sigma^2/2\pi d\omega$$ and that $\Theta$ has no root in the unit circle. We want to prove that $(z_t)$ is an $MA(q)$ . I used the inverse filtering theorem to show that there exists $(\epsilon_t)_t$ weakly stationnary such that $z_t = \Theta(L) \epsilon_t $ where L is the backward shift operator. Indeed $\sum_{-\infty}^{\infty} |\theta_i| \lt \infty $ and $\int_{-\pi}^{\pi}\frac{1}{|\Theta(e^{-i\omega})|^2}\mu_z(d\omega) < \infty$ . Furthermore, $\gamma_{\epsilon}(h) = \sigma^2 \mathbb{1}_{h=0}$ but i have yet to prove that the expectation of $(\epsilon_t)$ is null, and i have no clue on how to do it. Also, i don't see where we use the hypothesis that $\Theta$ has no root in the unit circle since $|\Theta(e^{-i\omega})|^2$ is contained in the spectral measure of $z_t$ and it simplifies inside the integral which makes it converge. So it seems to me that this hypothesis is not necessary. Thank you for your help","We are given the following polynomial : and we suppose that is weakly stationnary and its spectral measure is given by : and that has no root in the unit circle. We want to prove that is an . I used the inverse filtering theorem to show that there exists weakly stationnary such that where L is the backward shift operator. Indeed and . Furthermore, but i have yet to prove that the expectation of is null, and i have no clue on how to do it. Also, i don't see where we use the hypothesis that has no root in the unit circle since is contained in the spectral measure of and it simplifies inside the integral which makes it converge. So it seems to me that this hypothesis is not necessary. Thank you for your help",\Theta(z) = 1 + \theta_1 z + ...+ \theta_q z^q   (z_t)_{t \in \mathbb{Z}}  \mu_z(d\omega) = |\Theta(e^{i\omega})|^2\sigma^2/2\pi d\omega \Theta (z_t) MA(q) (\epsilon_t)_t z_t = \Theta(L) \epsilon_t  \sum_{-\infty}^{\infty} |\theta_i| \lt \infty  \int_{-\pi}^{\pi}\frac{1}{|\Theta(e^{-i\omega})|^2}\mu_z(d\omega) < \infty \gamma_{\epsilon}(h) = \sigma^2 \mathbb{1}_{h=0} (\epsilon_t) \Theta |\Theta(e^{-i\omega})|^2 z_t,"['statistics', 'stochastic-processes', 'time-series']"
62,Probability of Random Item Selection,Probability of Random Item Selection,,"In a 15-piece batch there are 5 black balls and the 10 remaining balls are white. 3 balls are selected randomly. The batch is discarded if among the chosen ones at least one selected ball is white. What is the probability of this? I assume the random selection is based upon no replacements, as 3 balls are taken at one go. Formula: $P(X=x) = C(n,x) p^x (1–p)^{n-x}$ The probability of selecting a white ball is given by $\tfrac{10}{15}$ , hence $\tfrac{2}{3}$ should be white. But how about the probability distribution for at least one single white ball selected out of 3? Thanks to @lulu: $1 - (\tfrac{5}{15} * \tfrac{4}{14} * \tfrac{3}{13}$ ) or just $1 - \binom 53 \Big / \binom {15}3$","In a 15-piece batch there are 5 black balls and the 10 remaining balls are white. 3 balls are selected randomly. The batch is discarded if among the chosen ones at least one selected ball is white. What is the probability of this? I assume the random selection is based upon no replacements, as 3 balls are taken at one go. Formula: The probability of selecting a white ball is given by , hence should be white. But how about the probability distribution for at least one single white ball selected out of 3? Thanks to @lulu: ) or just","P(X=x) = C(n,x) p^x (1–p)^{n-x} \tfrac{10}{15} \tfrac{2}{3} 1 - (\tfrac{5}{15} * \tfrac{4}{14} * \tfrac{3}{13} 1 - \binom 53 \Big / \binom {15}3","['probability', 'statistics']"
63,Find $\lim_{n \rightarrow \infty} P(n[Y_n]=k)$,Find,\lim_{n \rightarrow \infty} P(n[Y_n]=k),"Suppose $X_1,X_2,...,X_n$ is a random sample from $U(0,\theta)$ for some unknown $\theta>0$ .Let $Y_n$ be the minimum of $X_1,X_2,..,X_n$ . Find $\lim_{n \rightarrow \infty} P(n[Y_n]=k)$ for $k=0,1,2,...$ where $[x]$ denotes the largest integer less than or equal to $x$ . My approach : We first write down the pdf of $Y_{n}$ : $f(y)=\frac{n}{\theta}(1-\frac{y}{\theta})^{n-1}$ Now, let $Z=[Y_n]$ $P(Z=z)=P([Y_n]=z)=P(z \le Y_n < z+1)=\int_{z}^{z+1} \frac{n}{\theta}(1-\frac{y}{\theta})^{n-1} dy=(1-\frac{z}{\theta})^n-(1-\frac{z+1}{\theta})^n$ Now, plugging in $\frac{k}{n}$ for $z$ ,we have $P(Z=\frac{k}{n})=(1-\frac{k}{n \theta})^n-(1-\frac{k+n}{n \theta})^n$ , but I cannot find the limit . Perhaps, I have made a mistake somewhere. Please help!!","Suppose is a random sample from for some unknown .Let be the minimum of . Find for where denotes the largest integer less than or equal to . My approach : We first write down the pdf of : Now, let Now, plugging in for ,we have , but I cannot find the limit . Perhaps, I have made a mistake somewhere. Please help!!","X_1,X_2,...,X_n U(0,\theta) \theta>0 Y_n X_1,X_2,..,X_n \lim_{n \rightarrow \infty} P(n[Y_n]=k) k=0,1,2,... [x] x Y_{n} f(y)=\frac{n}{\theta}(1-\frac{y}{\theta})^{n-1} Z=[Y_n] P(Z=z)=P([Y_n]=z)=P(z \le Y_n < z+1)=\int_{z}^{z+1} \frac{n}{\theta}(1-\frac{y}{\theta})^{n-1} dy=(1-\frac{z}{\theta})^n-(1-\frac{z+1}{\theta})^n \frac{k}{n} z P(Z=\frac{k}{n})=(1-\frac{k}{n \theta})^n-(1-\frac{k+n}{n \theta})^n","['probability', 'probability-theory']"
64,Find standard deviation of x,Find standard deviation of x,,I have a sample size of n=175 and mean of μ =6.78 hours. What is the standard deviation of X̄ do you need that 95% of all samples will have to mean within 5 minutes of μ I used the equation m(margin of error) = (Z*)(σ / √n) so my solution when I plug in the variables and solve is as followed .08=(1.96)(σ /13.229) which gives me 0.58 but the correct answer is 0.041 What am I doing wrong?,I have a sample size of n=175 and mean of μ =6.78 hours. What is the standard deviation of X̄ do you need that 95% of all samples will have to mean within 5 minutes of μ I used the equation m(margin of error) = (Z*)(σ / √n) so my solution when I plug in the variables and solve is as followed .08=(1.96)(σ /13.229) which gives me 0.58 but the correct answer is 0.041 What am I doing wrong?,,"['statistics', 'standard-deviation', 'confidence-interval']"
65,consistency of Neyman Pearson lemma in the case simple vs simple test for exponential families,consistency of Neyman Pearson lemma in the case simple vs simple test for exponential families,,"Basics, jump to section 2 for the question : I know that in the case of an exponential family with 1 parameter, meaning the distribution function of the sample variables can be written like : $$ f_X(t) = \exp( \eta( \theta) T(t) - d( \theta) + S( x) ) $$ if we compare two hypothesis like those : $$ H_0 : \theta = \theta_0 \text{ vs }  H_1 :\theta = \theta_1$$ Neyman-Pearson lemma tells us that : if $\eta$ is increasing we get this test : $$ \mathbb{1}_{ \sum t_i \geq q_{1 - \alpha}} $$ if $\eta$ is decreasing we get this test : $$ \mathbb{1}_{ \sum t_i \leq q_{\alpha}} $$ where $q_{\lambda }$ is the solution of this equation  ( $\alpha$ -quantiles ): $$ P( \sum t_i \leq q_{\alpha} | H_0 ) = \alpha $$ When I first started doing exercices using this formula, i didn't know if I should put constants in the $\eta$ or in the $T$ function. I've succesfully proven that whether you put a positive multiplicative constant in one of those, you get the same result, meaning the two tests functions are the same if you multiply one function by $a$ and the other by $1/a$ . However, i can't do it for $ a = -1$ . I got to this point : How do you prove the equality of the two following tests : if I'm applying formulas : $$ \mathbb{1}_{ \sum t_i \geq q_{1 - \alpha}} $$ $$ P( \sum t_i \leq q_{1 -\alpha} | H_0 ) = 1 - \alpha $$ if I write $-\eta( \theta) \times - T(t)$ instead : $$ \mathbb{1}_{ \sum t_i \geq - q_{\alpha}} $$ $$ P( \sum t_i \geq - q_{\alpha} | H_0 ) = \alpha $$ I've succesfully done that for a gaussian distribution, but I can't do the general case. disclaimer : I'm still learning basics of statistics. So sorry for the possible trivialness of the questions. Moreover, i don't yet get everything and maybe, I ve set some hypothesis or constants as obviously shared ideas whereas it wasn't. So please free to ask if i forgot anything. Thank you.","Basics, jump to section 2 for the question : I know that in the case of an exponential family with 1 parameter, meaning the distribution function of the sample variables can be written like : if we compare two hypothesis like those : Neyman-Pearson lemma tells us that : if is increasing we get this test : if is decreasing we get this test : where is the solution of this equation  ( -quantiles ): When I first started doing exercices using this formula, i didn't know if I should put constants in the or in the function. I've succesfully proven that whether you put a positive multiplicative constant in one of those, you get the same result, meaning the two tests functions are the same if you multiply one function by and the other by . However, i can't do it for . I got to this point : How do you prove the equality of the two following tests : if I'm applying formulas : if I write instead : I've succesfully done that for a gaussian distribution, but I can't do the general case. disclaimer : I'm still learning basics of statistics. So sorry for the possible trivialness of the questions. Moreover, i don't yet get everything and maybe, I ve set some hypothesis or constants as obviously shared ideas whereas it wasn't. So please free to ask if i forgot anything. Thank you.", f_X(t) = \exp( \eta( \theta) T(t) - d( \theta) + S( x) )   H_0 : \theta = \theta_0 \text{ vs }  H_1 :\theta = \theta_1 \eta  \mathbb{1}_{ \sum t_i \geq q_{1 - \alpha}}  \eta  \mathbb{1}_{ \sum t_i \leq q_{\alpha}}  q_{\lambda } \alpha  P( \sum t_i \leq q_{\alpha} | H_0 ) = \alpha  \eta T a 1/a  a = -1  \mathbb{1}_{ \sum t_i \geq q_{1 - \alpha}}   P( \sum t_i \leq q_{1 -\alpha} | H_0 ) = 1 - \alpha  -\eta( \theta) \times - T(t)  \mathbb{1}_{ \sum t_i \geq - q_{\alpha}}   P( \sum t_i \geq - q_{\alpha} | H_0 ) = \alpha ,"['statistics', 'statistical-inference', 'hypothesis-testing']"
66,what is pilot estimator?,what is pilot estimator?,,"I have met with a term ""pilot estimator"" in some papers .I have no idea what it is and I have searched the website like wiki but in vain. Can anybody tell me what it is ? Thanks in advance.","I have met with a term ""pilot estimator"" in some papers .I have no idea what it is and I have searched the website like wiki but in vain. Can anybody tell me what it is ? Thanks in advance.",,"['statistics', 'estimation']"
67,Find a suitable ARMA model,Find a suitable ARMA model,,I know that the ACF and PACF shown below is either of a MA(2) or AR(2) process. How can I decide which one it is by just looking at the plots?,I know that the ACF and PACF shown below is either of a MA(2) or AR(2) process. How can I decide which one it is by just looking at the plots?,,"['statistics', 'time-series']"
68,"Definition of Covariance Matrix, to divide by $n$ or not.","Definition of Covariance Matrix, to divide by  or not.",n,"In most sources, the covariance of matrix of observations $X \in (n,p)$ is usually defined as $$cov(X) = \frac{\hat X^T \hat X}{n-1}$$ where $\hat X = X - \mu (X)$ . However, after reading the definition of Wikipedia , it is not divided by the $(n-1)$ term. Why? I'm not talking about bias, since they don't divide by $n$ either.","In most sources, the covariance of matrix of observations is usually defined as where . However, after reading the definition of Wikipedia , it is not divided by the term. Why? I'm not talking about bias, since they don't divide by either.","X \in (n,p) cov(X) = \frac{\hat X^T \hat X}{n-1} \hat X = X - \mu (X) (n-1) n","['statistics', 'covariance']"
69,Puzzling random number property,Puzzling random number property,,"For a series of values $A_{\text{peak}}\geqslant 0$ , I generated a large number ( $n$ ) of random values $A_{\text{noise}}$ (using the Mersenne Twister algorithm in PHP) within $[-A_{\text{peak}},+A_{\text{peak}}]$ , and from these calculated the average root-mean-square value : $\displaystyle\overline{\text{RMS}}_{\text{noise}}=\sqrt{\frac{1}{n}\cdot\sum_{1}^{n}A_{\text{noise}}^{2}}$ . Using regression analysis it then turns out that, with high accuracy : $A_{\text{peak}}=\sqrt{3}\cdot\overline{\text{RMS}}_{\text{noise}}$ . How can this $\sqrt{3}$ constant be derived mathematically ?","For a series of values , I generated a large number ( ) of random values (using the Mersenne Twister algorithm in PHP) within , and from these calculated the average root-mean-square value : . Using regression analysis it then turns out that, with high accuracy : . How can this constant be derived mathematically ?","A_{\text{peak}}\geqslant 0 n A_{\text{noise}} [-A_{\text{peak}},+A_{\text{peak}}] \displaystyle\overline{\text{RMS}}_{\text{noise}}=\sqrt{\frac{1}{n}\cdot\sum_{1}^{n}A_{\text{noise}}^{2}} A_{\text{peak}}=\sqrt{3}\cdot\overline{\text{RMS}}_{\text{noise}} \sqrt{3}","['statistics', 'random']"
70,How to calculate weighted average of hourly sales in a day,How to calculate weighted average of hourly sales in a day,,"I have hourly sales data & want to aggregate it to a day level. Out of $24$ hours, we are classifying $6$ hrs as peak hours and $18$ hrs as non-peak. Assume peak hr sales for a day as: $X_1, X_2,..., X_6$ Non-peak hr sales for a day as: $Y_1, Y_2,..., Y_{18}$ How can we take a weighted average of peak hr and non-peak hrs to get the data to a day level?","I have hourly sales data & want to aggregate it to a day level. Out of hours, we are classifying hrs as peak hours and hrs as non-peak. Assume peak hr sales for a day as: Non-peak hr sales for a day as: How can we take a weighted average of peak hr and non-peak hrs to get the data to a day level?","24 6 18 X_1, X_2,..., X_6 Y_1, Y_2,..., Y_{18}","['statistics', 'average', 'means', 'descriptive-statistics']"
71,About two events being mutually exclusive and independent give that one of the event's probability is zero.,About two events being mutually exclusive and independent give that one of the event's probability is zero.,,"I'm studying statistics and probability using an introductory textbook and it had this question: 108.The events “Other” and “Up for reelection in November 2016” are ________  a. mutually exclusive.  b. independent.  c. both mutually exclusive and independent.  d. neither mutually exclusive nor independent. The answer key says that the correct answer is letter a , but shouldn't it be letter c as the P(""Other"" $\cap$ ""Up for reelection in November 2016"") = 0 meaning that the two events are mutually exclusive and that the P(""Other""|""Up for reelection in November 2016"") = P(Other), therefore also being independent?","I'm studying statistics and probability using an introductory textbook and it had this question: 108.The events “Other” and “Up for reelection in November 2016” are ________  a. mutually exclusive.  b. independent.  c. both mutually exclusive and independent.  d. neither mutually exclusive nor independent. The answer key says that the correct answer is letter a , but shouldn't it be letter c as the P(""Other"" ""Up for reelection in November 2016"") = 0 meaning that the two events are mutually exclusive and that the P(""Other""|""Up for reelection in November 2016"") = P(Other), therefore also being independent?",\cap,"['probability', 'statistics']"
72,Why is the KL divergence the number of bits required to represent the error of an estimator?,Why is the KL divergence the number of bits required to represent the error of an estimator?,,"I am familiar with several interpretations of the KL divergence, last week I heard of a new one, mentioned in a lecture on probabilistic graphical models. It was stated kind of offhandedly, so I hope I'm getting the gist, but I seem to remember something like ""The KL divergence between a distribution $\mathcal{D}$ and an empirical distribution $\mathcal{D}_{emp}$ based on a sample $\mathcal{X}\sim\mathcal{D}$ is the number of bits required to represent the error of a MLE which is based on $\mathcal{X}$ "" (I know this sounds weird, MLE for what parameter? Maybe for any parameter? I'm honestly not sure) Is anyone familiar with such a result?","I am familiar with several interpretations of the KL divergence, last week I heard of a new one, mentioned in a lecture on probabilistic graphical models. It was stated kind of offhandedly, so I hope I'm getting the gist, but I seem to remember something like ""The KL divergence between a distribution and an empirical distribution based on a sample is the number of bits required to represent the error of a MLE which is based on "" (I know this sounds weird, MLE for what parameter? Maybe for any parameter? I'm honestly not sure) Is anyone familiar with such a result?",\mathcal{D} \mathcal{D}_{emp} \mathcal{X}\sim\mathcal{D} \mathcal{X},"['statistics', 'statistical-inference', 'information-theory']"
73,Variance of the range for the exponential distribution,Variance of the range for the exponential distribution,,"If $n$ random variables are independently distributed with an exponential distribution $f_X(x) =\lambda e^{-\lambda x} (x\geq 0)$ , the range $R_n = \max(X_1,\cdots,X_n) - \min(X_1,\cdots,X_n)$ has the following expectation: $\mbox{E}[R_n] = \frac{1}{\lambda}\Big(1+\frac{1}{2}+\frac{1}{3}+\cdots + \frac{1}{n-1}\Big)$ . This result is well known, see here for some context. However, I could not find a formula for the variance, in the literature. So I decided to do the computations myself and came up with a spectacular formula. I am wondering if the following  formula for the variance is original: $\mbox{Var}[R_n]= \frac{1}{\lambda^2}\Big(1+\frac{1}{2^2}+\frac{1}{3^2}+\cdots + \frac{1}{(n-1)^2}\Big)$ . As a result, the limit as $n\rightarrow\infty$ is $\pi^2/(6\lambda^2)$ . I have a hard time believing that this is a new result. Could someone provide a reference? I plan on including it in an upcoming article. This result is pretty deep, though not that hard to prove. It is almost like the range, for the exponential distribution, is made up of a weighted sum of independent exponential variables with same parameter $\lambda$ , each new one added into the sum contributing with a weight equal to $1/k, k=1, 2$ and so on.","If random variables are independently distributed with an exponential distribution , the range has the following expectation: . This result is well known, see here for some context. However, I could not find a formula for the variance, in the literature. So I decided to do the computations myself and came up with a spectacular formula. I am wondering if the following  formula for the variance is original: . As a result, the limit as is . I have a hard time believing that this is a new result. Could someone provide a reference? I plan on including it in an upcoming article. This result is pretty deep, though not that hard to prove. It is almost like the range, for the exponential distribution, is made up of a weighted sum of independent exponential variables with same parameter , each new one added into the sum contributing with a weight equal to and so on.","n f_X(x) =\lambda e^{-\lambda x} (x\geq 0) R_n = \max(X_1,\cdots,X_n) - \min(X_1,\cdots,X_n) \mbox{E}[R_n] = \frac{1}{\lambda}\Big(1+\frac{1}{2}+\frac{1}{3}+\cdots + \frac{1}{n-1}\Big) \mbox{Var}[R_n]= \frac{1}{\lambda^2}\Big(1+\frac{1}{2^2}+\frac{1}{3^2}+\cdots + \frac{1}{(n-1)^2}\Big) n\rightarrow\infty \pi^2/(6\lambda^2) \lambda 1/k, k=1, 2","['probability', 'statistics', 'probability-distributions', 'exponential-distribution', 'order-statistics']"
74,Draw multiple elements from set: overlap,Draw multiple elements from set: overlap,,"Assume I have a finite set of $N$ elements. Now assume that $k$ elements will be drawn randomly from the set (without replacement). These $k$ draws will in total be repeated $I$ times, but between each draw $i\in I$ , there is replacement. How many unique elements $n\in N$ can I expect to draw as a function of $I$ , $N$ , and $k$ if I assume that each $n$ is equally likely to be chosen? What if each $n$ is not equally likely (because e.g. the likelihood approximates a normal distribution)? I believe that for the case of equal probability to be chosen, $I\cdot k-\frac{I(I-1)}{2}\cdot\left(\frac{k}{N}\right)^{2}\cdot k$ should do the trick. Am I right?","Assume I have a finite set of elements. Now assume that elements will be drawn randomly from the set (without replacement). These draws will in total be repeated times, but between each draw , there is replacement. How many unique elements can I expect to draw as a function of , , and if I assume that each is equally likely to be chosen? What if each is not equally likely (because e.g. the likelihood approximates a normal distribution)? I believe that for the case of equal probability to be chosen, should do the trick. Am I right?",N k k I i\in I n\in N I N k n n I\cdot k-\frac{I(I-1)}{2}\cdot\left(\frac{k}{N}\right)^{2}\cdot k,"['probability', 'statistics']"
75,Probability of population parameter to be contained in confidence interval,Probability of population parameter to be contained in confidence interval,,"First of all, I have found this question: Interpretation of confidence interval which might seem as a duplicate. As well as this explanation http://onlinestatbook.com/2/estimation/confidence.html within it -- but I find it hard to understand. In the second link it is stated that: Confidence intervals for means are intervals constructed using a   procedure that will contain the population mean a specified proportion of the time, typically either   95% or 99% of the time. An example of a 95% confidence   interval is shown below: 72.85 < μ < 107.15 There is good reason to believe that the population mean lies between   these two bounds of 72.85 and 107.15 since 95% of the time confidence   intervals contain the true mean. But also: It is natural to interpret a 95% confidence interval as an interval   with a 0.95 probability of containing the population mean. However,   the proper interpretation is not that simple. One problem is that the   computation of a confidence interval does not take into account any   other information you might have about the value of the population   mean. For example, if numerous prior studies had all found sample   means above 110, it would not make sense to conclude that there is a   0.95 probability that the population mean is between 72.85 and 107.15. What about situations in which there is no prior information about the   value of the population mean? Even here the interpretation is complex.   The problem is that there can be more than one procedure that produces   intervals that contain the population parameter 95% of the time. Which   procedure produces the ""true"" 95% confidence interval? For the sake of the discussion I rather refer to a situation in which one can have huge amount of data, and the confidence level can be extremely high. My questions are: If one can't say it is as likely for the population parameter to be inside the interval as the confidence level, why does the author write ""There is good reason to believe that the population mean lies between these two bounds (...)"" in the first paragraph? In the second quoted paragraph the author refers to a situation in which there was a prior information. I don't see how that is relevant. If your confidence level is, say $1-2^{-30}$ , it is indeed very unlikely you get an interval which contradicts previous studies. If it indeed happens, one must conclude that one of you had a mistake. You, or the previous studies. Where am I wrong? Also in the second paragraph the author writes: ... there can be more than one procedure that produces intervals that contain the population parameter 95% of the time. Which procedure produces the ""true"" 95% confidence interval? I didn't understand this line, what is he trying to say? To summarize, I'll try to compare it to null hypothesis rejecting, which I understand better: If I randomly pick a confidence interval from a set of confidence intervals, of which $1-2^{-30}$ contain the true population parameter, why can't I say it is as likely I have picked a good interval, as it is likely the null hypothesis should be rejected when $p\leq2^{-30}$ ? Note: I am a beginning math student. I have taken with passion some basic math classes such as Linear Algebra 101, and Calculus, but nothing more. In statistics I have a reasonable understanding of basic hypothesis testing (null hypothesis, statistical significance, p-values).","First of all, I have found this question: Interpretation of confidence interval which might seem as a duplicate. As well as this explanation http://onlinestatbook.com/2/estimation/confidence.html within it -- but I find it hard to understand. In the second link it is stated that: Confidence intervals for means are intervals constructed using a   procedure that will contain the population mean a specified proportion of the time, typically either   95% or 99% of the time. An example of a 95% confidence   interval is shown below: 72.85 < μ < 107.15 There is good reason to believe that the population mean lies between   these two bounds of 72.85 and 107.15 since 95% of the time confidence   intervals contain the true mean. But also: It is natural to interpret a 95% confidence interval as an interval   with a 0.95 probability of containing the population mean. However,   the proper interpretation is not that simple. One problem is that the   computation of a confidence interval does not take into account any   other information you might have about the value of the population   mean. For example, if numerous prior studies had all found sample   means above 110, it would not make sense to conclude that there is a   0.95 probability that the population mean is between 72.85 and 107.15. What about situations in which there is no prior information about the   value of the population mean? Even here the interpretation is complex.   The problem is that there can be more than one procedure that produces   intervals that contain the population parameter 95% of the time. Which   procedure produces the ""true"" 95% confidence interval? For the sake of the discussion I rather refer to a situation in which one can have huge amount of data, and the confidence level can be extremely high. My questions are: If one can't say it is as likely for the population parameter to be inside the interval as the confidence level, why does the author write ""There is good reason to believe that the population mean lies between these two bounds (...)"" in the first paragraph? In the second quoted paragraph the author refers to a situation in which there was a prior information. I don't see how that is relevant. If your confidence level is, say , it is indeed very unlikely you get an interval which contradicts previous studies. If it indeed happens, one must conclude that one of you had a mistake. You, or the previous studies. Where am I wrong? Also in the second paragraph the author writes: ... there can be more than one procedure that produces intervals that contain the population parameter 95% of the time. Which procedure produces the ""true"" 95% confidence interval? I didn't understand this line, what is he trying to say? To summarize, I'll try to compare it to null hypothesis rejecting, which I understand better: If I randomly pick a confidence interval from a set of confidence intervals, of which contain the true population parameter, why can't I say it is as likely I have picked a good interval, as it is likely the null hypothesis should be rejected when ? Note: I am a beginning math student. I have taken with passion some basic math classes such as Linear Algebra 101, and Calculus, but nothing more. In statistics I have a reasonable understanding of basic hypothesis testing (null hypothesis, statistical significance, p-values).",1-2^{-30} 1-2^{-30} p\leq2^{-30},"['statistics', 'confidence-interval']"
76,FIFA19 - overall rating is higher for specific country? [closed],FIFA19 - overall rating is higher for specific country? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 5 years ago . Improve this question Hy, I was studying this data set on Kaggle ( https://www.kaggle.com/karangadiya/fifa19 ) for my machine learning problem. Idea is to from features of player to count overall rating. Ok, first we need a little bit of feature engineering to see what feature will be significant. One of this is country of player such as Croatia or Brasil. Main idea is that country of player wouldn't have much impact on overall rating, but what if developer with intention give Brasil player much higher rating than Croatia player.The same idea can be used in club(Maybe equal player in Real Madrid and Dinamo Zagreb have higher rating if he play in RM). So the problem is to show that country of player has no connection to overall. To try to solve this problem I use all Croatia and Brasil player and use T-test on their overall rating. The test show that Brasil player have higher rating, but this can be also reason that Brasil have better players. Another idea was also use T-test again but overall / value for Croatia and Brasil but I didn't get any clear answer. Can you give idea how to approach the problem?","Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 5 years ago . Improve this question Hy, I was studying this data set on Kaggle ( https://www.kaggle.com/karangadiya/fifa19 ) for my machine learning problem. Idea is to from features of player to count overall rating. Ok, first we need a little bit of feature engineering to see what feature will be significant. One of this is country of player such as Croatia or Brasil. Main idea is that country of player wouldn't have much impact on overall rating, but what if developer with intention give Brasil player much higher rating than Croatia player.The same idea can be used in club(Maybe equal player in Real Madrid and Dinamo Zagreb have higher rating if he play in RM). So the problem is to show that country of player has no connection to overall. To try to solve this problem I use all Croatia and Brasil player and use T-test on their overall rating. The test show that Brasil player have higher rating, but this can be also reason that Brasil have better players. Another idea was also use T-test again but overall / value for Croatia and Brasil but I didn't get any clear answer. Can you give idea how to approach the problem?",,"['statistics', 'machine-learning', 'means', 'anova']"
77,Some questions on the nature of statistical/probabilistic deduction,Some questions on the nature of statistical/probabilistic deduction,,"I have been doing some reading and thinking on the nature of statistical inference and the way formal statistics models an event seems a bit strange to me. Here is how I like to think about it: In the deterministic world, the most basic way of trying to model something is to try to fit a function $y=f(x)$ that models input x to output y. The way this is usually is done is that either you have some theoretical calculations that suggests you the form of $f(x)$ or you look at many data and make a guess (or some computational fitting procedure). In the first case you simply test your guess function against your data by calculating mean absolute error between observed results $y_{obs}$ and the calculated ones $y_{calc}$ via the function $f$ given the inputs $x$ . In the second case when you are training your $f(x)$ based on data then you train on some training subset and test it on some validation subset, but again using mean absolute error. On the other hand when you want to model your data probabilistically, i,e it is too hard or impossible to build $f(x)$ , you try to come up with a probability distribution $p(x)$ that tells you how likely it is to get some set of outcomes each time you make an experiment. In this case you have to test your error on the level of the probability distribution. The way I would naturally do is as follows: I assume that you have some guess $p_0(x)$ about what the probability would be like. Then I take set of experimental outcomes $\{x_i\}_{i=1}^N$ and look at the measure $p^N(x)= \frac{1}{N}\sum_{i=1}^N \delta_{x_i}(x)$ .  One can calculate the difference between $p^N$ and $p_0$ using a norm defined on the space of probability measures. If my guess $p_0$ is really good and $p^N$ converges to $p_0$ strongly then anyways the norm measured in any of these will tend to $0$ as $N$ goes to $\infty$ . You can probably only spot differences for low number of data but then again with low number of data modeling your data because more of a choice as there is too much flexibility in what you can fit. Below is an example where I model data points drawn from a normal distribution (their variance is denoted in the titles as data sigma and all has mean 0). Once I construct $p_N$ from data, I iterate over different values of variance and determine $p_0$ based on which variance gives the less distance to $p_N$ ( I fix mean=0 but that can be varied too). The distance I use is the mean absolute distance between cumulative distribution functions of $p_0$ and $p^N(x)= \frac{1}{N}\sum_{i=1}^N \delta_{x_i}(x)$ .  (a modified version of Kolmogorov distance). I also compare it to the normal distribution which has the variance and mean of the data which I call the unbiased and denote by $\hat{p}$ . In the first figure I compare $p_0$ and $\hat{p}$ with the data on the x-axis. In the second figure I plot cdfs for $p_0$ , $\hat{p}$ , $p^N$ . As can be seen for the cases when there is a lot of data they are almost identical and they are only noticably different for low number of data points. In the first figure the sigma calculated for the $p_0$ is denoted in the titles as Min Dist Gaussian sigma. The distances of $p_0$ and $\hat{p}$ to data are given in the legends. To me this seems like the only sane way of thinking about modelling probabilistic phenomenon. On the other hand in the statistics domain what people do is they first guess a $p_0$ and then an alternate not $p_0$ which I denote as $p_1$ . Looking at $p_0$ and $p_1$ you can somehow determine a region which if most of the data falls then $p_0$ is rejected. This should be somehow a region which is more towards the ""high concentration regions"" of $p_1$ and ""low concentration regions"" of $p_0$ so that you are more confident in your prediction. This just seems to me like a very round about way of measuring some sort of distance between the probability measures $p_0,p_1$ and the experimental measure $ \frac{1}{N}\sum_{i=1}^N \delta_{x_i}(x)$ . However I was not able to formalise this. So my questions are: 1- Is it possible to see this as some sort of norm comparison between these probability measures? 2- If so, what is the reason this particular comparison is used? 3- And finally if we are looking at distance, why do we not try to find some $p(x)$ which minimises the distance rather and rather just compare one $p_1$ and its negatition?","I have been doing some reading and thinking on the nature of statistical inference and the way formal statistics models an event seems a bit strange to me. Here is how I like to think about it: In the deterministic world, the most basic way of trying to model something is to try to fit a function that models input x to output y. The way this is usually is done is that either you have some theoretical calculations that suggests you the form of or you look at many data and make a guess (or some computational fitting procedure). In the first case you simply test your guess function against your data by calculating mean absolute error between observed results and the calculated ones via the function given the inputs . In the second case when you are training your based on data then you train on some training subset and test it on some validation subset, but again using mean absolute error. On the other hand when you want to model your data probabilistically, i,e it is too hard or impossible to build , you try to come up with a probability distribution that tells you how likely it is to get some set of outcomes each time you make an experiment. In this case you have to test your error on the level of the probability distribution. The way I would naturally do is as follows: I assume that you have some guess about what the probability would be like. Then I take set of experimental outcomes and look at the measure .  One can calculate the difference between and using a norm defined on the space of probability measures. If my guess is really good and converges to strongly then anyways the norm measured in any of these will tend to as goes to . You can probably only spot differences for low number of data but then again with low number of data modeling your data because more of a choice as there is too much flexibility in what you can fit. Below is an example where I model data points drawn from a normal distribution (their variance is denoted in the titles as data sigma and all has mean 0). Once I construct from data, I iterate over different values of variance and determine based on which variance gives the less distance to ( I fix mean=0 but that can be varied too). The distance I use is the mean absolute distance between cumulative distribution functions of and .  (a modified version of Kolmogorov distance). I also compare it to the normal distribution which has the variance and mean of the data which I call the unbiased and denote by . In the first figure I compare and with the data on the x-axis. In the second figure I plot cdfs for , , . As can be seen for the cases when there is a lot of data they are almost identical and they are only noticably different for low number of data points. In the first figure the sigma calculated for the is denoted in the titles as Min Dist Gaussian sigma. The distances of and to data are given in the legends. To me this seems like the only sane way of thinking about modelling probabilistic phenomenon. On the other hand in the statistics domain what people do is they first guess a and then an alternate not which I denote as . Looking at and you can somehow determine a region which if most of the data falls then is rejected. This should be somehow a region which is more towards the ""high concentration regions"" of and ""low concentration regions"" of so that you are more confident in your prediction. This just seems to me like a very round about way of measuring some sort of distance between the probability measures and the experimental measure . However I was not able to formalise this. So my questions are: 1- Is it possible to see this as some sort of norm comparison between these probability measures? 2- If so, what is the reason this particular comparison is used? 3- And finally if we are looking at distance, why do we not try to find some which minimises the distance rather and rather just compare one and its negatition?","y=f(x) f(x) y_{obs} y_{calc} f x f(x) f(x) p(x) p_0(x) \{x_i\}_{i=1}^N p^N(x)= \frac{1}{N}\sum_{i=1}^N \delta_{x_i}(x) p^N p_0 p_0 p^N p_0 0 N \infty p_N p_0 p_N p_0 p^N(x)= \frac{1}{N}\sum_{i=1}^N \delta_{x_i}(x) \hat{p} p_0 \hat{p} p_0 \hat{p} p^N p_0 p_0 \hat{p} p_0 p_0 p_1 p_0 p_1 p_0 p_1 p_0 p_0,p_1  \frac{1}{N}\sum_{i=1}^N \delta_{x_i}(x) p(x) p_1","['statistics', 'probability-distributions', 'statistical-inference']"
78,"How to properly represent a conditional expectation $E(Y\mid X,Z)$ if there are values of $X$ and $Z$ that cannot simultaneously exist?",How to properly represent a conditional expectation  if there are values of  and  that cannot simultaneously exist?,"E(Y\mid X,Z) X Z","Suppose $Y, X, Z$ are all discrete random variables. Then the conditional mean of $Y$ on levels of $X=x$ and $Z=Z$ is represented by $E(Y\mid X=x,Z=z)$ now suppose that there are values of $x_1 \in X$ and $z_1 \in Z$ such that both cannot simultaneously exist. An example might be if $Y, X, Z$ were vectors of observations corresponding to people, and so such person had $x_1, z_1$ simultaneously. In such a case, $E(Y\mid X=x_1,Z=z_1)$ is undefined. Is there a way define the conditional expectation in a notationally correct way? One thought is using the indicator function $\mathbb{1}(X=x_1,Z=z_1)E(Y\mid X=x_1,Z=z_1)$ but $E(Y\mid X=x_1,Z=z_1)$ is still undefined and multiplying by zero seems to be a hacky fix. Example: For an example, consider $Y$ to be mortality, where $Y=1$ is death, $Y=0$ is living. Then, suppose $X$ is gender, such that $X=1$ is female, $X=0$ male and that $Z$ is whether one had ovarian cancer before ( $Z=1$ ). Then, $$ E(Y\mid X=0, Z=1) $$ can't be computed because to have ovarian cancer implies one is female, therefore we cannot compute it since $X=0$ is male (making the assumption only females can get ovarian cancer). Further Motivation: I am also motivated by how the law of total probability might work under such cases. For example, suppose we wanted to find $E(Y\mid X) but only had information at the level of $ X $ and $ Z$. We can therefore use the law of total probability to have: $$ E(Y\mid X) = \sum_z E(Y\mid X,Z=z)P(Z=z\mid X) $$ However, in such cases, sometimes, like the example above, $E(Y\mid X,Z=z)$ is undefined at certain values. How might the law of total probability work in this case? I would appreciate any insights. Thanks!","Suppose are all discrete random variables. Then the conditional mean of on levels of and is represented by now suppose that there are values of and such that both cannot simultaneously exist. An example might be if were vectors of observations corresponding to people, and so such person had simultaneously. In such a case, is undefined. Is there a way define the conditional expectation in a notationally correct way? One thought is using the indicator function but is still undefined and multiplying by zero seems to be a hacky fix. Example: For an example, consider to be mortality, where is death, is living. Then, suppose is gender, such that is female, male and that is whether one had ovarian cancer before ( ). Then, can't be computed because to have ovarian cancer implies one is female, therefore we cannot compute it since is male (making the assumption only females can get ovarian cancer). Further Motivation: I am also motivated by how the law of total probability might work under such cases. For example, suppose we wanted to find X Z$. We can therefore use the law of total probability to have: However, in such cases, sometimes, like the example above, is undefined at certain values. How might the law of total probability work in this case? I would appreciate any insights. Thanks!","Y, X, Z Y X=x Z=Z E(Y\mid X=x,Z=z) x_1 \in X z_1 \in Z Y, X, Z x_1, z_1 E(Y\mid X=x_1,Z=z_1) \mathbb{1}(X=x_1,Z=z_1)E(Y\mid X=x_1,Z=z_1) E(Y\mid X=x_1,Z=z_1) Y Y=1 Y=0 X X=1 X=0 Z Z=1 
E(Y\mid X=0, Z=1)
 X=0 E(Y\mid X) but only had information at the level of   and  
E(Y\mid X) = \sum_z E(Y\mid X,Z=z)P(Z=z\mid X)
 E(Y\mid X,Z=z)","['probability', 'statistics']"
79,Covariance of sum of two dependent random vectors,Covariance of sum of two dependent random vectors,,"$\newcommand{\cov}{\operatorname{cov}}\newcommand{\corr}{\operatorname{corr}}$ I have two dependent multivariate random variables, or random vectors, $X$ and $Y$ , their respective covariance matrices $\Sigma_X = \cov(X,X)$ , $\Sigma_Y = \cov(Y,Y)$ and a non-zero correlation matrix $P_{XY} = \corr(X, Y)$ . I would like to compute the covariance matrix of the sum of the two random vectors: \begin{align} Z {}={}& X + Y \\ \Sigma_Z {}={}& \Sigma_X + \Sigma_Y + 2 \cov(X, Y) \end{align} Intuitively, I would assume the cross-covariance can be computed as follows: $$\cov(X, Y) = P_{XY} \sqrt{\Sigma_X} \sqrt{\Sigma_Y}$$ But I can see that this matrix is not necessarily symmetric, and therefore the resulting $\Sigma_Z$ wouldn't be either. Am I wrong? Is it at all possible to compute $\Sigma_Z$ from the information I have? If not, is there some way to approximate it? EDIT: I think it isn't correct to write: $$ \Sigma_Z = \Sigma_X + \Sigma_Y + 2 \cov(X, Y) $$ as $\cov(X,Y) \ne \cov(Y,X)$ , but instead $\cov(X,Y) = \cov(Y,X)^T$ . Rewriting the equation for $\Sigma_Z$ to: \begin{align} \Sigma_Z {}={}& \Sigma_X + \Sigma_Y + \cov(X, Y) + \cov(Y, X) \\ {}={}& \Sigma_X + \Sigma_Y + \cov(X, Y) + \cov(X, Y)^T \end{align} I can now prove that indeed $\Sigma_Z$ is guaranteed to be symmetric. As antkam points out in the chat below, it isn't necessary that $\cov(X, Y) + \cov(X, Y)^T$ be positive semi-definite for $\Sigma_Z$ to be positive semi-definite.","I have two dependent multivariate random variables, or random vectors, and , their respective covariance matrices , and a non-zero correlation matrix . I would like to compute the covariance matrix of the sum of the two random vectors: Intuitively, I would assume the cross-covariance can be computed as follows: But I can see that this matrix is not necessarily symmetric, and therefore the resulting wouldn't be either. Am I wrong? Is it at all possible to compute from the information I have? If not, is there some way to approximate it? EDIT: I think it isn't correct to write: as , but instead . Rewriting the equation for to: I can now prove that indeed is guaranteed to be symmetric. As antkam points out in the chat below, it isn't necessary that be positive semi-definite for to be positive semi-definite.","\newcommand{\cov}{\operatorname{cov}}\newcommand{\corr}{\operatorname{corr}} X Y \Sigma_X = \cov(X,X) \Sigma_Y = \cov(Y,Y) P_{XY} = \corr(X, Y) \begin{align}
Z {}={}& X + Y
\\
\Sigma_Z {}={}& \Sigma_X + \Sigma_Y + 2 \cov(X, Y)
\end{align} \cov(X, Y) = P_{XY} \sqrt{\Sigma_X} \sqrt{\Sigma_Y} \Sigma_Z \Sigma_Z  \Sigma_Z = \Sigma_X + \Sigma_Y + 2 \cov(X, Y)  \cov(X,Y) \ne \cov(Y,X) \cov(X,Y) = \cov(Y,X)^T \Sigma_Z \begin{align}
\Sigma_Z {}={}& \Sigma_X + \Sigma_Y + \cov(X, Y) + \cov(Y, X)
\\
{}={}& \Sigma_X + \Sigma_Y + \cov(X, Y) + \cov(X, Y)^T
\end{align} \Sigma_Z \cov(X, Y) + \cov(X, Y)^T \Sigma_Z","['probability', 'probability-theory', 'statistics', 'random-variables', 'covariance']"
80,Round number problem involving CLT.,Round number problem involving CLT.,,"Every time Jim uses his credit card, he rounds the amount he was charged to the nearest dollar in his records. Assume the number of cents involved in each purchase is a uniformly distributed whole number between 0 and 99. He has used the credit card a total of 150 times. (a) If the total amount in Jim's records differs from the actual total by \$10, what is the mean error (difference between amount charged and amount recorded) per purchase? (b) Find the probability that the total amount in Jim's records differs from the actual total by more than \$10. (Hint: The Central Limit Theorem implies the distribution of the mean error per purchase in a random sample of 150 purchases is normal) a) I think the answer should be $\frac{10}{150} \approx \$0.07$ per purchase. b) I do not know how to solve this problem. Here is what I have done so far: Let $X$ be the random variable for the error in total. Since the number in cents is selected in the discrete interval $[0,99]$ randomly, the probability for rounding any price amount is $p = 0.5$ because for the first 50 digits [0 , 49], we don't round, but we round for [50 , 99]. Then... $\bar X = 0.005{}\cdot{}150 = \$0.75$ $ \mu  = \$10 $ ? I don't really know what to put here. I guess it is given by the problem. $\sigma^2 = E[(X-\mu)^2] = \frac {1}{100} 2(0^2 +0.1^2 +...+0.50^2)= 0.4583 $ $  \frac{\sigma}{\sqrt{n}} = \frac{\sigma}{\sqrt{150}} = 0.05528$ $P( Z > \frac{\bar X-\mu}{\frac{\sigma}{\sqrt{n}}}) = 1- P( Z < \frac{0.75-10}{0.05528}) = 1 - P( Z < -167.33)$ ... whose z value is too big to be on the z-table. Where is my mistake?","Every time Jim uses his credit card, he rounds the amount he was charged to the nearest dollar in his records. Assume the number of cents involved in each purchase is a uniformly distributed whole number between 0 and 99. He has used the credit card a total of 150 times. (a) If the total amount in Jim's records differs from the actual total by \$10, what is the mean error (difference between amount charged and amount recorded) per purchase? (b) Find the probability that the total amount in Jim's records differs from the actual total by more than \$10. (Hint: The Central Limit Theorem implies the distribution of the mean error per purchase in a random sample of 150 purchases is normal) a) I think the answer should be per purchase. b) I do not know how to solve this problem. Here is what I have done so far: Let be the random variable for the error in total. Since the number in cents is selected in the discrete interval randomly, the probability for rounding any price amount is because for the first 50 digits [0 , 49], we don't round, but we round for [50 , 99]. Then... ? I don't really know what to put here. I guess it is given by the problem. ... whose z value is too big to be on the z-table. Where is my mistake?","\frac{10}{150} \approx \0.07 X [0,99] p = 0.5 \bar X = 0.005{}\cdot{}150 = \0.75  \mu  = \10  \sigma^2 = E[(X-\mu)^2] = \frac {1}{100} 2(0^2 +0.1^2 +...+0.50^2)= 0.4583    \frac{\sigma}{\sqrt{n}} = \frac{\sigma}{\sqrt{150}} = 0.05528 P( Z > \frac{\bar X-\mu}{\frac{\sigma}{\sqrt{n}}}) = 1- P( Z < \frac{0.75-10}{0.05528}) = 1 - P( Z < -167.33)","['probability', 'statistics']"
81,B-Splines and sum of uniform variables,B-Splines and sum of uniform variables,,"Exercise 5.2 in Elements of Statistical Learning Goal is to show that an order $M$ B-Spline basis function is the density function of a convolution of $M$ uniform random variables. Although I feel the idea, I am looking for an elegant exhaustive solution. Below my attempts. We denote $B_{i,m}(x)$ the $i$ -th B-Spline basis function of order $m$ for the knot-sequence $\tau$ , $m<M$ , defined as $$B_{i,1}(x)=\begin{cases}                1 & \text{if } \: \: \: \tau_{i} \leq x \leq \tau_{i+1}\\                0 & \text{otherwise}             \end{cases}$$ for $i=1,\dotsc ,K+2M-1$ $$B_{i,m}(x)= \frac{x-\tau_{i}}{\tau_{i+m-1}-\tau_{i}} B_{i,m-1}(x) + \frac{\tau_{i+m}-x}{\tau_{i+m}-\tau_{i+1}} B_{i+1,m-1}(x)$$ for $i-1, \dotsc ,K+2M-m$ . The distribution for the sum of $M$ uniform RVs is the convolution of density functions. I read the exercise as ""show that the $i$ -th B-Spline of order $M$ is the density function for the sum of $M$ uniform RVs"". Using the characteristic function, we can write $$P_{ X_1 + \dotsb +X_M }(u)=\mathcal{F}^{-1}\!\!\left[ \left( \frac{i(1-e^{it}) }t \right)^M \right]\!\!(u)$$ ( Elaboration on how to obtain this last result is welcome. ) After calculation, $$P_{ X_1 + \dotsb +X_M }(u) = \frac{1}{2(n-1)!}\sum^{M}_{k=0}(-1)^{k}\binom{n}{k}(u-k)^{M-1} \mathrm{sgn}(u-k)  \tag{*}$$ I propose to proceed by induction. $$M=2: \qquad P_{X_{1}+X_{2}}(x)=\begin{cases}                x & \text{if } \: \: \: 0 \leq x \leq 1\\ x-2 & \text{if } \: \: \: 1 \leq x \leq 2\\                0 & \text{otherwise}             \end{cases}$$ while $$B_{i,2}(x)=\begin{cases}                \dfrac{x-\tau_{i}}{\tau_{i+1}-\tau_{i}} & \text{if } \: \: \: \tau_{i} \leq x \leq \tau_{i+1}\\\\ \dfrac{\tau_{i+2}-x}{\tau_{i+2}-\tau_{i+1}} & \text{if } \: \: \: \tau_{i+1} \leq x \leq \tau_{i+2}\\\\                0 & \text{otherwise}             \end{cases}$$ Which is the same as $P_{X_{1}+X_{2}}$ up to a change in variable, approximately $X = \dfrac{x-\tau_{i}}{\tau_{i+1}-\tau_{i}}$ . More rigorous elaboration on this change in variable or an argument to show the equivalence or both expressions is welcome. Induction. We assume property true at order $M$ . $$B_{i,M+1}(x)= \frac{x-\tau_{i}}{\tau_{i+M}-\tau_{i}} B_{i,M}(x) + \frac{\tau_{i+M+1}-x}{\tau_{i+M+1}-\tau_{i+1}} B_{i+1,M}(x)$$ How to properly show that $B_{i,M+1}(x)$ expresses as $(*)$ where $M+1$ uniform RVs are added ? One idea would be to express by induction the density of the sum of $M+1$ RVs in $(*)$ as a function of the density of the sum of $M$ RVs. How to write it properly ?","Exercise 5.2 in Elements of Statistical Learning Goal is to show that an order B-Spline basis function is the density function of a convolution of uniform random variables. Although I feel the idea, I am looking for an elegant exhaustive solution. Below my attempts. We denote the -th B-Spline basis function of order for the knot-sequence , , defined as for for . The distribution for the sum of uniform RVs is the convolution of density functions. I read the exercise as ""show that the -th B-Spline of order is the density function for the sum of uniform RVs"". Using the characteristic function, we can write ( Elaboration on how to obtain this last result is welcome. ) After calculation, I propose to proceed by induction. while Which is the same as up to a change in variable, approximately . More rigorous elaboration on this change in variable or an argument to show the equivalence or both expressions is welcome. Induction. We assume property true at order . How to properly show that expresses as where uniform RVs are added ? One idea would be to express by induction the density of the sum of RVs in as a function of the density of the sum of RVs. How to write it properly ?","M M B_{i,m}(x) i m \tau m<M B_{i,1}(x)=\begin{cases}
               1 & \text{if } \: \: \: \tau_{i} \leq x \leq \tau_{i+1}\\
               0 & \text{otherwise}
            \end{cases} i=1,\dotsc ,K+2M-1 B_{i,m}(x)= \frac{x-\tau_{i}}{\tau_{i+m-1}-\tau_{i}} B_{i,m-1}(x) + \frac{\tau_{i+m}-x}{\tau_{i+m}-\tau_{i+1}} B_{i+1,m-1}(x) i-1, \dotsc ,K+2M-m M i M M P_{ X_1 + \dotsb +X_M }(u)=\mathcal{F}^{-1}\!\!\left[ \left( \frac{i(1-e^{it}) }t \right)^M \right]\!\!(u) P_{ X_1 + \dotsb +X_M }(u) = \frac{1}{2(n-1)!}\sum^{M}_{k=0}(-1)^{k}\binom{n}{k}(u-k)^{M-1} \mathrm{sgn}(u-k)  \tag{*} M=2: \qquad P_{X_{1}+X_{2}}(x)=\begin{cases}
               x & \text{if } \: \: \: 0 \leq x \leq 1\\
x-2 & \text{if } \: \: \: 1 \leq x \leq 2\\
               0 & \text{otherwise}
            \end{cases} B_{i,2}(x)=\begin{cases}
               \dfrac{x-\tau_{i}}{\tau_{i+1}-\tau_{i}} & \text{if } \: \: \: \tau_{i} \leq x \leq \tau_{i+1}\\\\
\dfrac{\tau_{i+2}-x}{\tau_{i+2}-\tau_{i+1}} & \text{if } \: \: \: \tau_{i+1} \leq x \leq \tau_{i+2}\\\\
               0 & \text{otherwise}
            \end{cases} P_{X_{1}+X_{2}} X = \dfrac{x-\tau_{i}}{\tau_{i+1}-\tau_{i}} M B_{i,M+1}(x)= \frac{x-\tau_{i}}{\tau_{i+M}-\tau_{i}} B_{i,M}(x) + \frac{\tau_{i+M+1}-x}{\tau_{i+M+1}-\tau_{i+1}} B_{i+1,M}(x) B_{i,M+1}(x) (*) M+1 M+1 (*) M","['probability', 'statistics', 'probability-distributions', 'statistical-inference']"
82,Hanson-Wright Inequality for Symmetric Matrices,Hanson-Wright Inequality for Symmetric Matrices,,"The Hanson-Wright inequality for arbitrary $n \times n$ matrix A, and $X$ a random vector with subgaussian coordinates (of norm 1) is $$ Pr(|X^TAX-\mathbb{E}X^TAX| \geq t) \leq 2\exp \left(-c \min\left(\frac{t^2}{\|A\|_F}, \frac{t}{\|A\|} \right)\right) $$ A proof of this follows first by decoupling and showing that equivalently we may consider $$ Pr(|X^TAX' - \mathbb{E}X^TAX'| \geq t) $$ for i.i.d. $X,X'$ . We then establish in the case where $X,X'$ are gaussian the bound $$ \mathbb{E}\exp(\lambda X^TAX') \leq \exp(C\lambda^2\|A\|_F^2) $$ Finally, one shows that we can replace arbitrary $X,X'$ with normally distributed counterparts while only paying a constant cost (see page 140 of Vershynin High Dimensional Probability). In particular, for $X,X'$ with subgaussian entries of norm 1, and with $g,g' \sim \mathcal{N}(0,I_n)$ , we have the bound \begin{equation} \mathbb{E}\exp(\lambda X^TAX') \leq\mathbb{E}\exp(C\lambda g^TAg')  \end{equation} for some constant $C$ . I'm interested in the case where $A$ is a symmetric matrix. When $X$ are gaussian, we can already assume that $A$ in $X^TAX$ is diagonal. Crucially (or so it seems to me), we don't need to decouple here. This lets one bound the moment generating function of $X^TAX$ like \begin{align*} \mathbb{E}\exp(\lambda X^TAX) &= \prod_{i=1}^n \mathbb{E} \exp(\lambda a_iX_i^2)\\ &= \prod_{i=1}^n (1-2\lambda a_i)^{-1/2} \\ &= \prod_{i=1}^n \exp(2\lambda a_i) \end{align*} if $\lambda < \frac{1}{4}$ , using the identity $(1-t)^{-1/2} < e^{t}$ for $t < 1/2$ . So one can replace $\|A\|_F$ with $tr(A)$ , which should give a better bound. If we want to get this result in general though, we need some result along the lines of \begin{equation} \mathbb{E}\exp(\lambda X^TAX) \leq\mathbb{E}\exp(C\lambda g^TAg)  \end{equation} Does such a bound hold? (I am sourcing this material from chapter 6 of Vershynin's High Dimensional Probability)","The Hanson-Wright inequality for arbitrary matrix A, and a random vector with subgaussian coordinates (of norm 1) is A proof of this follows first by decoupling and showing that equivalently we may consider for i.i.d. . We then establish in the case where are gaussian the bound Finally, one shows that we can replace arbitrary with normally distributed counterparts while only paying a constant cost (see page 140 of Vershynin High Dimensional Probability). In particular, for with subgaussian entries of norm 1, and with , we have the bound for some constant . I'm interested in the case where is a symmetric matrix. When are gaussian, we can already assume that in is diagonal. Crucially (or so it seems to me), we don't need to decouple here. This lets one bound the moment generating function of like if , using the identity for . So one can replace with , which should give a better bound. If we want to get this result in general though, we need some result along the lines of Does such a bound hold? (I am sourcing this material from chapter 6 of Vershynin's High Dimensional Probability)","n \times n X 
Pr(|X^TAX-\mathbb{E}X^TAX| \geq t) \leq 2\exp \left(-c \min\left(\frac{t^2}{\|A\|_F}, \frac{t}{\|A\|} \right)\right)
 
Pr(|X^TAX' - \mathbb{E}X^TAX'| \geq t)
 X,X' X,X' 
\mathbb{E}\exp(\lambda X^TAX') \leq \exp(C\lambda^2\|A\|_F^2)
 X,X' X,X' g,g' \sim \mathcal{N}(0,I_n) \begin{equation}
\mathbb{E}\exp(\lambda X^TAX') \leq\mathbb{E}\exp(C\lambda g^TAg') 
\end{equation} C A X A X^TAX X^TAX \begin{align*}
\mathbb{E}\exp(\lambda X^TAX) &= \prod_{i=1}^n \mathbb{E} \exp(\lambda a_iX_i^2)\\
&= \prod_{i=1}^n (1-2\lambda a_i)^{-1/2} \\
&= \prod_{i=1}^n \exp(2\lambda a_i)
\end{align*} \lambda < \frac{1}{4} (1-t)^{-1/2} < e^{t} t < 1/2 \|A\|_F tr(A) \begin{equation}
\mathbb{E}\exp(\lambda X^TAX) \leq\mathbb{E}\exp(C\lambda g^TAg) 
\end{equation}","['probability', 'probability-theory', 'statistics']"
83,How do you compare data values that come from different data sets using standard deviation?,How do you compare data values that come from different data sets using standard deviation?,,"My textbook had this question: ""Two swimmers, Angie and Beth, from different teams, wanted to find out who had the fastest time for the 50 meter freestyle when compared to her team. Which swimmer had the fastest time when compared to her team?"" \begin{array}{|c|c|c|c|} \hline Swimmer& Time (seconds) & Team Mean Time & Team Standard Deviation \\ \hline  Angie& 26.2& 27.2& 0.8\\ \hline  Beth&  27.3& 30.1& 1.4\\ \hline \end{array} Now my textbook's answer was this: ""From the above scores, it is clear that Angie's time of -1.25 is smaller than Beth's time of -2. And for swimming, lower time is better. Therefore, Angie has a better swimming time as compared to her team."" What I did: I calculate the number of standard deviations for both of them using the formula: z = $\frac{x - μ}{ σ}$ . I then got  Angie's z-score to be -1.25 and Beth's z-score to be -2. Now since Beth has a more negative z-score, doesn't that mean that she's deviating from her team's mean time, therefore having a faster time when compared to her team? I don't get why the textbook's answer is saying that Angela had the fastest time when compared to her team or did I do something wrong?","My textbook had this question: ""Two swimmers, Angie and Beth, from different teams, wanted to find out who had the fastest time for the 50 meter freestyle when compared to her team. Which swimmer had the fastest time when compared to her team?"" Now my textbook's answer was this: ""From the above scores, it is clear that Angie's time of -1.25 is smaller than Beth's time of -2. And for swimming, lower time is better. Therefore, Angie has a better swimming time as compared to her team."" What I did: I calculate the number of standard deviations for both of them using the formula: z = . I then got  Angie's z-score to be -1.25 and Beth's z-score to be -2. Now since Beth has a more negative z-score, doesn't that mean that she's deviating from her team's mean time, therefore having a faster time when compared to her team? I don't get why the textbook's answer is saying that Angela had the fastest time when compared to her team or did I do something wrong?","\begin{array}{|c|c|c|c|}
\hline
Swimmer& Time (seconds) & Team Mean Time & Team Standard Deviation \\ \hline
 Angie& 26.2& 27.2& 0.8\\ \hline
 Beth&  27.3& 30.1& 1.4\\ \hline
\end{array} \frac{x - μ}{ σ}",['statistics']
84,Wasserstein distance between $X$ and $X+N$,Wasserstein distance between  and,X X+N,"Is there a way to calculate the Wasserstein distance (or any other distance) between the distribution of a random variable $X \in \mathbb{R}^d$ and the distribution of $X+N$ where $N \sim \mathcal{N}(0,\sigma^2\mathbb{I}_d)$ is small perturbation along the dimensions ?",Is there a way to calculate the Wasserstein distance (or any other distance) between the distribution of a random variable and the distribution of where is small perturbation along the dimensions ?,"X \in \mathbb{R}^d X+N N \sim \mathcal{N}(0,\sigma^2\mathbb{I}_d)","['probability-theory', 'statistics', 'probability-distributions', 'random-variables', 'signal-processing']"
85,Show identity for Stable distributions,Show identity for Stable distributions,,"let $X_1,X_2,X$ be i.i.d (idenpendant, identically distributed) with stable probability density function $l_\alpha(x)$ . For $\forall A>0,B>0$ find $C$ such that $AX_1 + BX_2 \overset{d}{=}CX \qquad (1)$ where $\overset{d}{=}$ means equal in distribution. $\textrm{My Idea}$ : In the lecture we showed that the characteristic function $\hat{l}_\alpha$ is given by $\hat{l}_\alpha(k) = <e^{ikx}>:= \int_{-\infty}^\infty e^{ikx}l_\alpha(x)dx=e^{-\sigma^\alpha|k|^\alpha} \quad \sigma>0$ . Using this result i get the following relation: $(1) \quad \Rightarrow \quad  <e^{i(AX_1 +BX_2)k}>=<e^{ikAX_1}><e^{ikBX_2}>=<e^{ikCX}>$ which should be equivalent to $e^{-\sigma^\alpha|k|^\alpha A^\alpha}  e^{-\sigma^\alpha|k|^\alpha B^\alpha} = e^{-\sigma^\alpha|k|^\alpha C^\alpha} \Rightarrow A+B=C$ Is this the correct solution?","let be i.i.d (idenpendant, identically distributed) with stable probability density function . For find such that where means equal in distribution. : In the lecture we showed that the characteristic function is given by . Using this result i get the following relation: which should be equivalent to Is this the correct solution?","X_1,X_2,X l_\alpha(x) \forall A>0,B>0 C AX_1 + BX_2 \overset{d}{=}CX \qquad (1) \overset{d}{=} \textrm{My Idea} \hat{l}_\alpha \hat{l}_\alpha(k) = <e^{ikx}>:= \int_{-\infty}^\infty e^{ikx}l_\alpha(x)dx=e^{-\sigma^\alpha|k|^\alpha} \quad \sigma>0 (1) \quad \Rightarrow \quad  <e^{i(AX_1 +BX_2)k}>=<e^{ikAX_1}><e^{ikBX_2}>=<e^{ikCX}> e^{-\sigma^\alpha|k|^\alpha A^\alpha}  e^{-\sigma^\alpha|k|^\alpha B^\alpha} = e^{-\sigma^\alpha|k|^\alpha C^\alpha} \Rightarrow A+B=C","['statistics', 'probability-distributions']"
86,Does the binomial CDF decrease with the number of trials?,Does the binomial CDF decrease with the number of trials?,,"When we fix the probability of success, does the binomial CDF decrease with the number of trials? I thought so, but I cannot prove it. It would be appreciated if someone could let me know whether it is true and if so, how to prove it. Thanks!","When we fix the probability of success, does the binomial CDF decrease with the number of trials? I thought so, but I cannot prove it. It would be appreciated if someone could let me know whether it is true and if so, how to prove it. Thanks!",,"['probability', 'statistics']"
87,Why can we use a consistent variance matrix estimator when finding the asymptotic distribution,Why can we use a consistent variance matrix estimator when finding the asymptotic distribution,,"So I am pretty sure that in a one-dimensional case, we would just say $x \overset{d}{\to} N(0,\sigma^2)$ and $s^2 \overset{p}{\to} \sigma^2$ so $\frac{s}{\sigma} \frac{x}{s} \overset{d}{\to} N(0,1)$ and the first fraction converges to 1 so $x \overset{d}{\to} N(0,s^2)$ from Cramer Slutsky theorem. Trying to do this with a multivariate distribution, I used the Cholesky decomposition to say the variance matrix has a ""square root"" (because a variance matrix by definition has to be positive semidefinite) and applied the same principle: $X \overset{d}{\to} N(0,\Sigma)$ and $S \overset{p}{\to} \Sigma$ , we get $\Sigma^{1/2} X \overset{d}{\to} N(0,I)$ and $S^{1/2} S^{-1/2} \Sigma^{1/2} X \overset{d}{\to} N(0,I)$ . My issue, however, is I don't actually know if $S^{-1/2} \Sigma^{1/2} \overset{p}{\to} I$ necessarily holds. So is this true? If not, how else could I show that asymptotic distribution holds when we use the consistent variance estimator?","So I am pretty sure that in a one-dimensional case, we would just say and so and the first fraction converges to 1 so from Cramer Slutsky theorem. Trying to do this with a multivariate distribution, I used the Cholesky decomposition to say the variance matrix has a ""square root"" (because a variance matrix by definition has to be positive semidefinite) and applied the same principle: and , we get and . My issue, however, is I don't actually know if necessarily holds. So is this true? If not, how else could I show that asymptotic distribution holds when we use the consistent variance estimator?","x \overset{d}{\to} N(0,\sigma^2) s^2 \overset{p}{\to} \sigma^2 \frac{s}{\sigma} \frac{x}{s} \overset{d}{\to} N(0,1) x \overset{d}{\to} N(0,s^2) X \overset{d}{\to} N(0,\Sigma) S \overset{p}{\to} \Sigma \Sigma^{1/2} X \overset{d}{\to} N(0,I) S^{1/2} S^{-1/2} \Sigma^{1/2} X \overset{d}{\to} N(0,I) S^{-1/2} \Sigma^{1/2} \overset{p}{\to} I","['probability', 'matrices', 'statistics', 'variance']"
88,hazard increase,hazard increase,,I had a question regarding this proof. The hazard function is being defined as $\frac{\phi(x)}{1-F(x)}$ with $\phi(x)$ as the density function and $F(x)$ the CDF. How can I prove that this is increasing in $x$ if we’re dealing with a normal distribution?,I had a question regarding this proof. The hazard function is being defined as with as the density function and the CDF. How can I prove that this is increasing in if we’re dealing with a normal distribution?,\frac{\phi(x)}{1-F(x)} \phi(x) F(x) x,"['probability', 'probability-theory', 'statistics', 'probability-distributions']"
89,Find supremum of Type II error in Neyman-Pearson framework,Find supremum of Type II error in Neyman-Pearson framework,,"Let $X_1,\dots,X_n$ be an iid sample from an $N(\theta,1)$ distribution. We want to test $H_0:\:\theta=0$ against the alternative $H_1\:\theta \neq 0$ using the test statistic $$T_n(X_1,\dots,X_n) = \bar{X}_n$$ and the corresponding test function $$\delta(X_1,\dots,X_n) = \begin{cases} 1, & \text{if } |T_n(X_1,\dots,X_n| \geq Q, \\ 0, & \mbox{otherwise}\end{cases}$$ where $Q\geq0$ . The goal is now to find the smallest value of $Q$ for which the significance level is $\alpha = 0.05$ and then to find the supremum over the paramater space of the probability of type II error for that value of $Q$ . For the Type I error, I got $$\mathbb{P}_\theta(\delta = 1) = 2\cdot\Phi(-\sqrt{n}\cdot Q), \quad \theta \in \Theta_0$$ In order to fix this error at level $\alpha = 0.05$ , we need $2\cdot\Phi(-\sqrt{n}\cdot Q) = 0.05$ , i.e. $Q=1.96/\sqrt{n}$ , since $2\cdot\Phi(1.96)=2\cdot 0.025 = 0.05$ For the Type II error, I got $$\mathbb{P}_\theta(\delta = 0) = \Phi(\sqrt{n}\cdot (Q-\theta))-\Phi(-\sqrt{n} \cdot (Q+\theta)), \quad \theta \in \Theta_1$$ I now need to find the supremum of this error over the parameter space. Intuitively, the Type II error should increase the closer $\theta$ gets to 0, since that is the $\theta$ -value of $H_0$ . This would mean that $$\text{sup}_\theta \mathbb{P}_\theta(\delta = 0) = \Phi(\sqrt{n}\cdot Q)-\Phi(-\sqrt{n} \cdot Q), \quad \theta \in \Theta_1$$ Is this correct?","Let be an iid sample from an distribution. We want to test against the alternative using the test statistic and the corresponding test function where . The goal is now to find the smallest value of for which the significance level is and then to find the supremum over the paramater space of the probability of type II error for that value of . For the Type I error, I got In order to fix this error at level , we need , i.e. , since For the Type II error, I got I now need to find the supremum of this error over the parameter space. Intuitively, the Type II error should increase the closer gets to 0, since that is the -value of . This would mean that Is this correct?","X_1,\dots,X_n N(\theta,1) H_0:\:\theta=0 H_1\:\theta \neq 0 T_n(X_1,\dots,X_n) = \bar{X}_n \delta(X_1,\dots,X_n) = \begin{cases} 1, & \text{if } |T_n(X_1,\dots,X_n| \geq Q, \\ 0, & \mbox{otherwise}\end{cases} Q\geq0 Q \alpha = 0.05 Q \mathbb{P}_\theta(\delta = 1) = 2\cdot\Phi(-\sqrt{n}\cdot Q), \quad \theta \in \Theta_0 \alpha = 0.05 2\cdot\Phi(-\sqrt{n}\cdot Q) = 0.05 Q=1.96/\sqrt{n} 2\cdot\Phi(1.96)=2\cdot 0.025 = 0.05 \mathbb{P}_\theta(\delta = 0) = \Phi(\sqrt{n}\cdot (Q-\theta))-\Phi(-\sqrt{n} \cdot (Q+\theta)), \quad \theta \in \Theta_1 \theta \theta H_0 \text{sup}_\theta \mathbb{P}_\theta(\delta = 0) = \Phi(\sqrt{n}\cdot Q)-\Phi(-\sqrt{n} \cdot Q), \quad \theta \in \Theta_1","['statistics', 'normal-distribution', 'statistical-inference', 'hypothesis-testing']"
90,Birth/Death Processes with constant departure rate,Birth/Death Processes with constant departure rate,,"So, I'm looking at a Birth/Death process $Z$ with an arrival rate of $\frac{1}{n+1}$ and a departure rate of $1$ . I'm trying to show that this process is positive recurrent and find the stationary distribution. My understanding of positive recurrent is that if there is a non-zero probability that the markov chain will not return to a state. Additionally, it is a class property, and there only seems to be one communication class as you can access every state from any other state. Since the departure rate is greater than 0, isn't there always a probability that the markov chain will return to any initial starting state? So, if we take state 1, there is always a non-zero probability that the markov chain will return back to state 1 as the departure rate is nonzero? I'm a bit confused on how to answer the question (and show that this chain is positive recurrent) since I don't agree with the assumption the question is making (that this process is positive recurrent). I'd appreciate any help! Thank you so much!","So, I'm looking at a Birth/Death process with an arrival rate of and a departure rate of . I'm trying to show that this process is positive recurrent and find the stationary distribution. My understanding of positive recurrent is that if there is a non-zero probability that the markov chain will not return to a state. Additionally, it is a class property, and there only seems to be one communication class as you can access every state from any other state. Since the departure rate is greater than 0, isn't there always a probability that the markov chain will return to any initial starting state? So, if we take state 1, there is always a non-zero probability that the markov chain will return back to state 1 as the departure rate is nonzero? I'm a bit confused on how to answer the question (and show that this chain is positive recurrent) since I don't agree with the assumption the question is making (that this process is positive recurrent). I'd appreciate any help! Thank you so much!",Z \frac{1}{n+1} 1,"['probability', 'statistics', 'stochastic-processes']"
91,Representation of Generalized Quadratic Form of Random Variables,Representation of Generalized Quadratic Form of Random Variables,,"I am interested in finding/understanding a ""good"" $L^2$ -orthogonal (i.e. uncorrelated) decomposition of a matrix-valued quadratic form. The setup is as follows: Given a random matrix $X$ (tall, of size $n\times N$ ), with mean zero rows $X_i$ consider $$Q(X) = X'AX.$$ The covariance structure of $X$ can be encoded in a block matrix $\Sigma>0$ given as $$ \Sigma = \begin{bmatrix} \Sigma_{11} & \Sigma_{12} & \dots& \Sigma_{1N}\\ \Sigma_{12} & \Sigma_{22} & \dots&\\ \vdots & \ddots& \ddots \end{bmatrix}. $$ The blocks are of size $n$ corresponding to the length of the vectors $X_i$ . Ideally, I would like to represent $Q$ as $$ Q(X) = X'AX = \sum U'_i\Lambda_iU_i $$ Where the covariance structure of the $U_i$ is at least block-diagonal: $$ \Lambda = \begin{bmatrix} \Lambda_1 & 0 & 0&\dots\\ 0 & \Lambda_2 & 0 &\dots\\ 0 & 0 & \ddots & \ddots \end{bmatrix}. $$ Is this possible? Also, and if so, I am interested in the relationship between the singular values of the blocks of $\Sigma$ and $\Lambda$ . I suspect something like this to be acheivable given that we can do it ordinary quadratic forms: sum of squares of dependent gaussian random variables I guess maybe one could use a vectorized version of the argument presented there, but I am not entirely sure how to procede?","I am interested in finding/understanding a ""good"" -orthogonal (i.e. uncorrelated) decomposition of a matrix-valued quadratic form. The setup is as follows: Given a random matrix (tall, of size ), with mean zero rows consider The covariance structure of can be encoded in a block matrix given as The blocks are of size corresponding to the length of the vectors . Ideally, I would like to represent as Where the covariance structure of the is at least block-diagonal: Is this possible? Also, and if so, I am interested in the relationship between the singular values of the blocks of and . I suspect something like this to be acheivable given that we can do it ordinary quadratic forms: sum of squares of dependent gaussian random variables I guess maybe one could use a vectorized version of the argument presented there, but I am not entirely sure how to procede?","L^2 X n\times N X_i Q(X) = X'AX. X \Sigma>0 
\Sigma = \begin{bmatrix}
\Sigma_{11} & \Sigma_{12} & \dots& \Sigma_{1N}\\
\Sigma_{12} & \Sigma_{22} & \dots&\\
\vdots & \ddots& \ddots
\end{bmatrix}.
 n X_i Q 
Q(X) = X'AX = \sum U'_i\Lambda_iU_i
 U_i 
\Lambda = \begin{bmatrix}
\Lambda_1 & 0 & 0&\dots\\
0 & \Lambda_2 & 0 &\dots\\
0 & 0 & \ddots & \ddots
\end{bmatrix}.
 \Sigma \Lambda","['probability', 'matrices', 'statistics', 'quadratic-forms']"
92,Convergence of quantiles based on estimates,Convergence of quantiles based on estimates,,"Let $D_\theta$ denote a distribution with parameter $\theta$ , that has density wrt. Lebesgue measure. Let $X$ have distribution $D_\theta$ and let $\hat{\theta}_n$ be a sequence of estimates of $\theta$ , converging to $\theta$ in probability (or almost surely if that is required). Let $Q_\theta(p)$ denote the quantile function of $D_\theta$ . Do we have $$ P(X \in [Q_{\hat{\theta}_n}(p_1), Q_{\hat{\theta}_n}(p_2)]) \to P(X \in [Q_\theta(p_1), Q_\theta(p_2)]) $$ for every $p_1 \leq p_2$ ? If not, what further assumptions do we need? Continuity of $Q$ in $\theta$ seems like it might do the trick but can we infer that from simply knowing that $D_\theta$ is absolutely continuous wrt. Lebesgue measure? Any ideas?","Let denote a distribution with parameter , that has density wrt. Lebesgue measure. Let have distribution and let be a sequence of estimates of , converging to in probability (or almost surely if that is required). Let denote the quantile function of . Do we have for every ? If not, what further assumptions do we need? Continuity of in seems like it might do the trick but can we infer that from simply knowing that is absolutely continuous wrt. Lebesgue measure? Any ideas?","D_\theta \theta X D_\theta \hat{\theta}_n \theta \theta Q_\theta(p) D_\theta 
P(X \in [Q_{\hat{\theta}_n}(p_1), Q_{\hat{\theta}_n}(p_2)]) \to P(X \in [Q_\theta(p_1), Q_\theta(p_2)])
 p_1 \leq p_2 Q \theta D_\theta","['probability', 'statistics']"
93,"Why is $X_{n-k,n}$ a good estimator for $U(\frac{n}{k})$?",Why is  a good estimator for ?,"X_{n-k,n} U(\frac{n}{k})","I'm learning about Extreme Value Theory. In my class we're discussing the $U(t)$ -tail quantile which has the following definition: For a distribution function $F$ , the tail quantile function $U(t)$ is defined such that $$ P(X> U(t) ) = 1 - F(U(t)) = \frac{1}{t}, \,t\geq 1 $$ Suppose that you have a sample $X_1,\ldots, X_n$ from distribution function $F$ . Estimation of $U(\frac{1}{p})$ is based on the following result: For $F\in D(G_\gamma)$ , for $\gamma>0$ , iff $$ \lim_{t\to\infty}\dfrac{U(tx)}{U(t)} = x^\gamma, $$ $U(tx)\approx U(t)x^\gamma$ . Now let $tx = \frac{1}{p}$ , and $t = \frac{n}{k}$ , where $k$ is a large integer but much smaller than $n$ . We then have $$ U\bigl(\frac1p \bigr) \approx U\bigl(\frac{n}{k} \bigr)\bigl( \frac{k}{np}\bigr)^\gamma $$ I think that I understand all this. Now comes the part that I'm having trouble with to grasp: Let $X_{1,n}, \ldots, X_{n,n}$ be the order statistics of the sample $X_1, \ldots, X_n$ . $U(\frac{n}{k})$ can be estimated by the empirical quantile $X_{n-k,n}$ . (Why is this a good estimator? Think about the empirical distribution function $\hat{F}(x) = \frac{1}{n}\sum_{i = 1}^n I(X_i\leq x).)$ Question: Why is $X_{n-k,n}$ a good estimator for $U(\frac{n}{k})$ ? Intuitively I understand that it might would be a good estimator, since $P\bigl( X > U(\frac1p) \bigr) = p$ so that $U\bigl(\frac1p \bigr) = x_{1 -p}$ . Hence you would get that $P\bigl( X > U(\frac{n}{k}) \bigr) = \frac{k}{n}$ and $U(\frac{n}{k}) = x_{1 - k/n}$ . A sensible estimator for $x_{1 - k/n}$ would then be $X_{n-k, n}$ . I don't find this satisfying though, especially since I supposedly have to think about the empirical distribution function to understand why this would be a good estimator.","I'm learning about Extreme Value Theory. In my class we're discussing the -tail quantile which has the following definition: For a distribution function , the tail quantile function is defined such that Suppose that you have a sample from distribution function . Estimation of is based on the following result: For , for , iff . Now let , and , where is a large integer but much smaller than . We then have I think that I understand all this. Now comes the part that I'm having trouble with to grasp: Let be the order statistics of the sample . can be estimated by the empirical quantile . (Why is this a good estimator? Think about the empirical distribution function Question: Why is a good estimator for ? Intuitively I understand that it might would be a good estimator, since so that . Hence you would get that and . A sensible estimator for would then be . I don't find this satisfying though, especially since I supposedly have to think about the empirical distribution function to understand why this would be a good estimator.","U(t) F U(t) 
P(X> U(t) ) = 1 - F(U(t)) = \frac{1}{t}, \,t\geq 1
 X_1,\ldots, X_n F U(\frac{1}{p}) F\in D(G_\gamma) \gamma>0 
\lim_{t\to\infty}\dfrac{U(tx)}{U(t)} = x^\gamma,
 U(tx)\approx U(t)x^\gamma tx = \frac{1}{p} t = \frac{n}{k} k n 
U\bigl(\frac1p \bigr) \approx U\bigl(\frac{n}{k} \bigr)\bigl( \frac{k}{np}\bigr)^\gamma
 X_{1,n}, \ldots, X_{n,n} X_1, \ldots, X_n U(\frac{n}{k}) X_{n-k,n} \hat{F}(x) = \frac{1}{n}\sum_{i = 1}^n I(X_i\leq x).) X_{n-k,n} U(\frac{n}{k}) P\bigl( X > U(\frac1p) \bigr) = p U\bigl(\frac1p \bigr) = x_{1 -p} P\bigl( X > U(\frac{n}{k}) \bigr) = \frac{k}{n} U(\frac{n}{k}) = x_{1 - k/n} x_{1 - k/n} X_{n-k, n}","['probability', 'probability-theory', 'statistics', 'probability-distributions']"
94,The probability of double chance being a good or bad virus when killing a virus and automatically double itself every time,The probability of double chance being a good or bad virus when killing a virus and automatically double itself every time,,"This is a question I read somewhere else and think so much about getting an answer, but still struggling. Here is the problem: I have 9 virus which is 5 of them are good, and 4 of them are bad. Every time I kill a virus, it dies, and 2 viruses will be born from its body which is having 50-50 chances to be a good or bad virus. What is the probability that after 100 times I kill a virus randomly and the amount of bad virus is zero? Which probability formula or theory should I learn to solve this one? Thanks.","This is a question I read somewhere else and think so much about getting an answer, but still struggling. Here is the problem: I have 9 virus which is 5 of them are good, and 4 of them are bad. Every time I kill a virus, it dies, and 2 viruses will be born from its body which is having 50-50 chances to be a good or bad virus. What is the probability that after 100 times I kill a virus randomly and the amount of bad virus is zero? Which probability formula or theory should I learn to solve this one? Thanks.",,"['probability', 'probability-theory', 'statistics', 'probability-distributions', 'conditional-probability']"
95,how to show the K-nearest-neighbor density model is an improper distribution: Bishops 2.61,how to show the K-nearest-neighbor density model is an improper distribution: Bishops 2.61,,"In Bishop's pattern recognition and machine learning, KNN is defined from a starting distribution: $$p(x) = \frac{K}{NV}$$ where K is the number of observed points in a region of measure V, out of a total of N observations. The KNN model is defined by allowing a sphere to expand around a given point x until it contains exactly K other points. exercise 2.61 in the text is where I'm stuck: show that the K-nearest-neighbor density model defines an improper distribution whose integral over all space is divergent. I'm not sure how to set up the integral to show that the distribution is improper... I suspect it's a simple solution, but I'm having trouble figuring out how to get traction on it. Any help would be greatly appreciated. Edit: for K=k you've got the region split into a kth order Voronoi tessellation, which leaves the full normalizing integral as a sum of integrals across each disjoint region. Setting K=1 and N=1 (for the simplest case) you've got $$ \int p(x) = \int dx/V(x) = \int \frac{\Gamma(D/2)D\,dx}{2\pi^{D/2}\parallel x - p_c \parallel^D} = \int_0^{\infty} \frac{D\,dr}{r^D}$$ , where $p_c$ is the closest point (our one observed point in my simple case). I might have made a mistake above, but intuitively, I take this to mean that the distribution p(x) is ill-defined for the points in the observed dataset (since the volume of the sphere centered on $p_c$ with $p_c$ on the boundary is zero, so p(x) explodes to infinity at those points). That gives one possible reason why this is an improper distribution for K=1, but look at K=2 in the case of N=2: The sphere is defined by the radius needed to enclose the farthest point, meaning there's a boundary surface dividing the feature space in half, where every point on that surface has the same distance to both points. Our integral then for one side of that surface involves integrating with the volume coming from the distance to the far point on the other side of the surface, and then the integral on the other side is identical since the space is symmetrically split. I have no idea how to even approximate that integral, but it at least doesn't have the singularity issue that comes up with K=1. No idea how to proceed from here.","In Bishop's pattern recognition and machine learning, KNN is defined from a starting distribution: where K is the number of observed points in a region of measure V, out of a total of N observations. The KNN model is defined by allowing a sphere to expand around a given point x until it contains exactly K other points. exercise 2.61 in the text is where I'm stuck: show that the K-nearest-neighbor density model defines an improper distribution whose integral over all space is divergent. I'm not sure how to set up the integral to show that the distribution is improper... I suspect it's a simple solution, but I'm having trouble figuring out how to get traction on it. Any help would be greatly appreciated. Edit: for K=k you've got the region split into a kth order Voronoi tessellation, which leaves the full normalizing integral as a sum of integrals across each disjoint region. Setting K=1 and N=1 (for the simplest case) you've got , where is the closest point (our one observed point in my simple case). I might have made a mistake above, but intuitively, I take this to mean that the distribution p(x) is ill-defined for the points in the observed dataset (since the volume of the sphere centered on with on the boundary is zero, so p(x) explodes to infinity at those points). That gives one possible reason why this is an improper distribution for K=1, but look at K=2 in the case of N=2: The sphere is defined by the radius needed to enclose the farthest point, meaning there's a boundary surface dividing the feature space in half, where every point on that surface has the same distance to both points. Our integral then for one side of that surface involves integrating with the volume coming from the distance to the far point on the other side of the surface, and then the integral on the other side is identical since the space is symmetrically split. I have no idea how to even approximate that integral, but it at least doesn't have the singularity issue that comes up with K=1. No idea how to proceed from here.","p(x) = \frac{K}{NV}  \int p(x) = \int dx/V(x) = \int \frac{\Gamma(D/2)D\,dx}{2\pi^{D/2}\parallel x - p_c \parallel^D} = \int_0^{\infty} \frac{D\,dr}{r^D} p_c p_c p_c","['statistics', 'machine-learning']"
96,Is it appropriate to use clustering to partition the dependent variable into separate datasets for a home price prediction model?,Is it appropriate to use clustering to partition the dependent variable into separate datasets for a home price prediction model?,,"I'm struggling to decide how to deal with a heteroskedasticity problem in a home price prediction model I'm developing. The training set residuals are normally distributed around zero, but they have an average absolute error of nearly 20%. As expected, there is lower variability among the observations with low sale values and higher variability among the observations with higher sale values. Something we are trying to achieve is equity - that is to say, lower value homes are predicted approximately as accurately as higher value homes. Because our current model doesn't do that so well, we are looking for a solution. One thing I though might help would be to use a k-means clustering algorithm on the dependent variable to partition the dataset based on home value - so, we would have three datasets, one each for low, medium, and high values. I was first (and still am) wondering if this algorithm should be applied on the whole dataset before defining training and test sets, or if we should define training and test sets before clustering and then create additional training and test sets based on those clusters. However, now I'm moreso wondering if there are bias issues we need to worry about, and if this is generally an appropriate way to do this, or if there are better ways to address this problem. For context, this model is a hedonic model using OLS. We've already used spatial clustering to define geographic areas within a broader study area and partitioned the dataset accordingly (our reasoning for doing this as opposed to using indicator variables for the geographic clusters is that the variability in the independent variables with respect to the geographic clusters couldn't possibly be captured using a single binary for each). We are going to also run spatial lag/error models and random forest models to see how they perform, but it's doubtful they'll reduce the absolute error as drastically as we need (we want prediction accuracy of under 10%).","I'm struggling to decide how to deal with a heteroskedasticity problem in a home price prediction model I'm developing. The training set residuals are normally distributed around zero, but they have an average absolute error of nearly 20%. As expected, there is lower variability among the observations with low sale values and higher variability among the observations with higher sale values. Something we are trying to achieve is equity - that is to say, lower value homes are predicted approximately as accurately as higher value homes. Because our current model doesn't do that so well, we are looking for a solution. One thing I though might help would be to use a k-means clustering algorithm on the dependent variable to partition the dataset based on home value - so, we would have three datasets, one each for low, medium, and high values. I was first (and still am) wondering if this algorithm should be applied on the whole dataset before defining training and test sets, or if we should define training and test sets before clustering and then create additional training and test sets based on those clusters. However, now I'm moreso wondering if there are bias issues we need to worry about, and if this is generally an appropriate way to do this, or if there are better ways to address this problem. For context, this model is a hedonic model using OLS. We've already used spatial clustering to define geographic areas within a broader study area and partitioned the dataset accordingly (our reasoning for doing this as opposed to using indicator variables for the geographic clusters is that the variability in the independent variables with respect to the geographic clusters couldn't possibly be captured using a single binary for each). We are going to also run spatial lag/error models and random forest models to see how they perform, but it's doubtful they'll reduce the absolute error as drastically as we need (we want prediction accuracy of under 10%).",,"['statistics', 'regression', 'machine-learning', 'data-analysis', 'clustering']"
97,How do we obtain an estimate for $\textbf{P}(X\geq 1)$ where $X\sim\text{Exp}(\lambda)$?,How do we obtain an estimate for  where ?,\textbf{P}(X\geq 1) X\sim\text{Exp}(\lambda),"Consider a simple sample $X_{1},X_{2},\ldots,X_{n}$ whose distribution is given by $X\sim Exp(\lambda)$ . (a) Determine an estimator for $\lambda$ according to the method of moments. (b) Determine another estimator for $\lambda$ different from the previous one. (c) Determine an estimate of $\textbf{P}(X\geq 1)$ in accordance to the method of moments. MY ATTEMPT As to the first case, we have \begin{align*} \frac{1}{\lambda} = \textbf{E}(X) \Rightarrow \hat{\lambda} = \frac{n}{\displaystyle\sum_{k=1}^{n}X_{k}} \end{align*} As to the second case, we have \begin{align*} \frac{1}{\lambda^{2}} = \textbf{Var}(X) = \textbf{E}(X^{2}) - \textbf{E}(X)^{2} \Rightarrow \hat{\lambda} = \left[\frac{1}{n}\sum_{k=1}^{n}X^{2}_{k} - \left(\frac{1}{n}\sum_{k=1}^{n}X_{k}\right)^{2}\right]^{-1/2} \end{align*} EDIT In the third case, we have \begin{align*} \textbf{P}(X\geq 1) = 1 - \textbf{P}(X < 1) = 1 - \exp(-1\times\lambda) = 1 - \exp(-\lambda) \end{align*} Now it suffices to substitute $\lambda$ for any of the above expressions. Could someone double-check my reasoning? Thanks in advance!","Consider a simple sample whose distribution is given by . (a) Determine an estimator for according to the method of moments. (b) Determine another estimator for different from the previous one. (c) Determine an estimate of in accordance to the method of moments. MY ATTEMPT As to the first case, we have As to the second case, we have EDIT In the third case, we have Now it suffices to substitute for any of the above expressions. Could someone double-check my reasoning? Thanks in advance!","X_{1},X_{2},\ldots,X_{n} X\sim Exp(\lambda) \lambda \lambda \textbf{P}(X\geq 1) \begin{align*}
\frac{1}{\lambda} = \textbf{E}(X) \Rightarrow \hat{\lambda} = \frac{n}{\displaystyle\sum_{k=1}^{n}X_{k}}
\end{align*} \begin{align*}
\frac{1}{\lambda^{2}} = \textbf{Var}(X) = \textbf{E}(X^{2}) - \textbf{E}(X)^{2} \Rightarrow \hat{\lambda} = \left[\frac{1}{n}\sum_{k=1}^{n}X^{2}_{k} - \left(\frac{1}{n}\sum_{k=1}^{n}X_{k}\right)^{2}\right]^{-1/2}
\end{align*} \begin{align*}
\textbf{P}(X\geq 1) = 1 - \textbf{P}(X < 1) = 1 - \exp(-1\times\lambda) = 1 - \exp(-\lambda)
\end{align*} \lambda","['statistics', 'exponential-distribution']"
98,The limit distribution of Wilcoxon signed rank statistic?,The limit distribution of Wilcoxon signed rank statistic?,,"An alternative representation of the Wilcoxon signed rank statistic $V$ is $V=\sum_{i\le j}\mathbb{I}_{\{X_i+X_j>0\}}=\sum_i\mathbb{I}_{\{X_i>0\}}+\sum_{i<j}\mathbb{I}_{\{X_i+X_j>0\}}$ where $X_1,\cdots, X_n$ are i.i.d. . How to find the limiting distribution of $V$ without requiring that $X_i$ has a symmetric distribution? I know it can be solved by projection method. But I don't know exactly how it works. Who can help me write down the details of the proof? Thanks a lot.",An alternative representation of the Wilcoxon signed rank statistic is where are i.i.d. . How to find the limiting distribution of without requiring that has a symmetric distribution? I know it can be solved by projection method. But I don't know exactly how it works. Who can help me write down the details of the proof? Thanks a lot.,"V V=\sum_{i\le j}\mathbb{I}_{\{X_i+X_j>0\}}=\sum_i\mathbb{I}_{\{X_i>0\}}+\sum_{i<j}\mathbb{I}_{\{X_i+X_j>0\}} X_1,\cdots, X_n V X_i","['statistics', 'asymptotics', 'weak-convergence']"
99,Is a rolling $z$-score a good proxy for a derivative?,Is a rolling -score a good proxy for a derivative?,z,"Given a time series $\{V_t\}_{t=1}^{n}$ , where $t \mapsto V_t \in \mathbb{R}$ , I want to have some smoothed notion of the ""derivative"" of this time series. It was recommended that I look at $$\tilde{V}_t = \frac{V_t - \text{$k$-step moving average of } V_t}{\text{$k$-step std dev of $V_t$}}.$$ The $k$ -step moving average of $V_t$ is $\frac{1}{k} \sum_{i=0}^{k-1}V_{t-i}$ . This quantity, empirically, seems to act something like derivative. (For a line it is constant, for a sine curve it is almost a cosine curve, etc.) Can someone explain why, mathematically, this would be a heuristic for a derivative? Thanks.","Given a time series , where , I want to have some smoothed notion of the ""derivative"" of this time series. It was recommended that I look at The -step moving average of is . This quantity, empirically, seems to act something like derivative. (For a line it is constant, for a sine curve it is almost a cosine curve, etc.) Can someone explain why, mathematically, this would be a heuristic for a derivative? Thanks.",\{V_t\}_{t=1}^{n} t \mapsto V_t \in \mathbb{R} \tilde{V}_t = \frac{V_t - \text{k-step moving average of } V_t}{\text{k-step std dev of V_t}}. k V_t \frac{1}{k} \sum_{i=0}^{k-1}V_{t-i},"['real-analysis', 'statistics', 'discrete-mathematics', 'time-series']"
