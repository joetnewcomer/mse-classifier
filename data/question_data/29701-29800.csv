,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Uniform distribution on $\ell_1$ ball,Uniform distribution on  ball,\ell_1,"I am trying to show that a random vector that is uniformly distributed on the $\ell_1$ ball (or a scaled version of the $\ell_1$ ball) in $\mathbb{R}^n$ is isotropic (i.e. $\mathbb{E}X X^T = Id$ ).  I can show that the off-diagonal terms are zero since $(x_1, \cdots, x_i, \dots, x_n)$ and $(x_1, \cdots, -x_i, \dots, x_n)$ are identically distributed so $\mathbb{E} x_i x_j  = - \mathbb{E} x_i x_j$ implies that $\mathbb{E} x_i x_j = 0$ for $i \neq j$ . Additionally, I would like to show that $X$ is not subgaussian where we define subgaussian to mean there exists a constant $C$ such that $\mathbb{E} e^{X^2/C^2} \leq 2$ . Source : Vershynin, High Dimensional Probability , Exercise 3.4.9.","I am trying to show that a random vector that is uniformly distributed on the ball (or a scaled version of the ball) in is isotropic (i.e. ).  I can show that the off-diagonal terms are zero since and are identically distributed so implies that for . Additionally, I would like to show that is not subgaussian where we define subgaussian to mean there exists a constant such that . Source : Vershynin, High Dimensional Probability , Exercise 3.4.9.","\ell_1 \ell_1 \mathbb{R}^n \mathbb{E}X X^T = Id (x_1, \cdots, x_i, \dots, x_n) (x_1, \cdots, -x_i, \dots, x_n) \mathbb{E} x_i x_j  = - \mathbb{E} x_i x_j \mathbb{E} x_i x_j = 0 i \neq j X C \mathbb{E} e^{X^2/C^2} \leq 2","['probability', 'probability-distributions']"
1,Variance converging to zero implies weak convergence to delta measure?,Variance converging to zero implies weak convergence to delta measure?,,"I have the following question: Suppose that I have a sequence of random variables $X_n$ such that all moments exists and are finite. I have that $E[X_n]\to a$, where $a$ is a finite number and also $\text{Var}(X)\to 0$. We may also assume that a density with respect to the Lebesgue measure exists. Does this imply that $X_n\to_w \delta_a$? weakly? Thanks a lot, any ideas on conditions are welcomed! This is true for the Gaussian distribution, but I wondered to what extend we can transfer it. Literature is also welcomed!","I have the following question: Suppose that I have a sequence of random variables $X_n$ such that all moments exists and are finite. I have that $E[X_n]\to a$, where $a$ is a finite number and also $\text{Var}(X)\to 0$. We may also assume that a density with respect to the Lebesgue measure exists. Does this imply that $X_n\to_w \delta_a$? weakly? Thanks a lot, any ideas on conditions are welcomed! This is true for the Gaussian distribution, but I wondered to what extend we can transfer it. Literature is also welcomed!",,"['probability', 'probability-distributions', 'weak-convergence', 'stochastic-approximation']"
2,Derivation of the third moment of Poisson distribution using Stein-Chen identity,Derivation of the third moment of Poisson distribution using Stein-Chen identity,,"(a) Use LOTUS to show that for $X \sim \operatorname{Pois}(\lambda)$ and any function g, $E(Xg(X)) = λE(g(X + 1))$.   This is called the Stein-Chen identity for the Poisson. (b) Find the third moment $E(X^3)$ for $X \sim \operatorname{Pois}(\lambda)$ by using the identity from (a) and a   bit of algebra to reduce the calculation to the fact that $X$ has mean $\lambda$ and variance $\lambda$. Only part b) is concerned. My solution Let $g(X) = X^2$, then \begin{align} E(X^3) &= \lambda E(g(X+1)) \\ &= \lambda E((X+1)^2) \\ &= \lambda (E(X^2) + 2E(X) + 1) \\ &= \lambda (\lambda+\lambda^2 + 2\lambda + 1)\\ &= \lambda^3 + 3\lambda^2 + \lambda \end{align} However, from litarature I know that the third moment should be $\lambda$. What went wrong?","(a) Use LOTUS to show that for $X \sim \operatorname{Pois}(\lambda)$ and any function g, $E(Xg(X)) = λE(g(X + 1))$.   This is called the Stein-Chen identity for the Poisson. (b) Find the third moment $E(X^3)$ for $X \sim \operatorname{Pois}(\lambda)$ by using the identity from (a) and a   bit of algebra to reduce the calculation to the fact that $X$ has mean $\lambda$ and variance $\lambda$. Only part b) is concerned. My solution Let $g(X) = X^2$, then \begin{align} E(X^3) &= \lambda E(g(X+1)) \\ &= \lambda E((X+1)^2) \\ &= \lambda (E(X^2) + 2E(X) + 1) \\ &= \lambda (\lambda+\lambda^2 + 2\lambda + 1)\\ &= \lambda^3 + 3\lambda^2 + \lambda \end{align} However, from litarature I know that the third moment should be $\lambda$. What went wrong?",,['probability']
3,Bound the variance of the product of two random varables.,Bound the variance of the product of two random varables.,,For two random variables $X$ and $Y$ show that the following inequality holds $$\mathrm{Var}(XY)\leq 2\|Y\|_{\infty}^{2}\mathrm{Var}(X)+2\|X\|_{\infty}^{2}\mathrm{Var}(Y).$$ Well first I tried to show it for just indicators functions by I couldn't even show that.  Any tips?,For two random variables $X$ and $Y$ show that the following inequality holds $$\mathrm{Var}(XY)\leq 2\|Y\|_{\infty}^{2}\mathrm{Var}(X)+2\|X\|_{\infty}^{2}\mathrm{Var}(Y).$$ Well first I tried to show it for just indicators functions by I couldn't even show that.  Any tips?,,"['probability', 'probability-theory', 'inequality', 'random-variables', 'covariance']"
4,Expected value equals sum of probabilities [duplicate],Expected value equals sum of probabilities [duplicate],,"This question already has answers here : Find the Mean for Non-Negative Integer-Valued Random Variable (3 answers) Closed 9 years ago . Let $X$ be a random variable that takes non-negative integer values. Show that,  $$E[X] = \sum^{\infty}_{k=1}P(X \geq k)$$ I'm having trouble following the solution. Could someone help clarify some steps? Thanks. By definition, $$P(X \geq k) = \sum^{\infty}_{i=k}p_{X}(i)$$ Therefore, we substitute to get  $$\sum^{\infty}_{k=1}P(X \geq k) = \sum_{k=1}^{\infty}\sum_{i=k}^{\infty}p_{X}(i)$$ Now here is where I'm confused. $$\sum_{k=1}^{\infty}\sum_{i=k}^{\infty}p_{X}(i) = \sum_{i=1}^{\infty}\sum_{k=1}^{i}p_{X}(i) = \sum^{\infty}_{i=1}ip_{X}(i)$$ I don't understand how we are manipulating the summations in the first equality and how we derive $ip_{X}(i)$ in the second equality.","This question already has answers here : Find the Mean for Non-Negative Integer-Valued Random Variable (3 answers) Closed 9 years ago . Let $X$ be a random variable that takes non-negative integer values. Show that,  $$E[X] = \sum^{\infty}_{k=1}P(X \geq k)$$ I'm having trouble following the solution. Could someone help clarify some steps? Thanks. By definition, $$P(X \geq k) = \sum^{\infty}_{i=k}p_{X}(i)$$ Therefore, we substitute to get  $$\sum^{\infty}_{k=1}P(X \geq k) = \sum_{k=1}^{\infty}\sum_{i=k}^{\infty}p_{X}(i)$$ Now here is where I'm confused. $$\sum_{k=1}^{\infty}\sum_{i=k}^{\infty}p_{X}(i) = \sum_{i=1}^{\infty}\sum_{k=1}^{i}p_{X}(i) = \sum^{\infty}_{i=1}ip_{X}(i)$$ I don't understand how we are manipulating the summations in the first equality and how we derive $ip_{X}(i)$ in the second equality.",,['probability']
5,Variance of a sum of complex independent random variables,Variance of a sum of complex independent random variables,,"$\newcommand{\Var}{\operatorname{Var}}$Consider the zero mean independent complex random variables $X_1,\dots,X_n$ and the complex constants $a_1,\dots,a_n$. Does the formula for real valued independent random variables carry over to complex case as: $$\Var[a_1X_1+\dots +a_nX_n] = | a_1 | ^2\Var(X_1)+\dots+ | a_n |^2\Var(X_n)$$","$\newcommand{\Var}{\operatorname{Var}}$Consider the zero mean independent complex random variables $X_1,\dots,X_n$ and the complex constants $a_1,\dots,a_n$. Does the formula for real valued independent random variables carry over to complex case as: $$\Var[a_1X_1+\dots +a_nX_n] = | a_1 | ^2\Var(X_1)+\dots+ | a_n |^2\Var(X_n)$$",,['probability']
6,"Given every horse's chance of winning a race, what is the probability that a specific horse will finish in nth place?","Given every horse's chance of winning a race, what is the probability that a specific horse will finish in nth place?",,"I have been interested in calculating a specific horse's chance of finishing in nth place given every horse's chance of winning in a particular race. i.e. Given the following: Horse    Chance of winning A        0.35 B        0.25 C        0.15 D        0.10 E        0.09 F        0.05 G        0.01 Calculate for any horse it's chance of finishing in nth place. For instance, calculate the chance of HorseC finishing in 2nd place, or calculate the chance of HorseB finishing in 3rd place. I thought that this is something I could get help with online. All of the journal articles I found discuss chances of a pair of horses winning, i.e. the chance of horse A winning and horse B coming second, which is obviously different to this question. This: http://forum.sbrforum.com/handicapper-think-tank/526381-win-v-place-odds-value-math-question.html#post5076725 is the closest thing I have found to what I am looking for, but I believe he assumes that given one horse wins, the others have an equal chance of placing second, which is clearly not the case. UPDATE I just had time to have a go at this and I am trying to come up with a formula for P(i, n) as @ThanosDarkadakis suggested. I am unsure of whether the odds of HorseZ finishing 3rd is: sum of HorseXWin * HorseY2nd * (HorseZWin/(1-HorseXWin-HorseY2nd)), for each X/Y or sum of HorseXWin * HorseY2nd * (HorseZWin/(sum of remaining win probabilities)), for each X/Y or sum of HorseXWin * HorseYWin * (HorseZWin/(1-HorseXWin-HorseYWin)), for each X/Y Where HorseX is the winner of the race, HorseY comes 2nd and HorseZ comes 3rd (for each X/Y). I'm sure that with a formula for P(i, 3) it would be trivial to write a formula for P(i, n). Any suggestions are greatly appreciated.","I have been interested in calculating a specific horse's chance of finishing in nth place given every horse's chance of winning in a particular race. i.e. Given the following: Horse    Chance of winning A        0.35 B        0.25 C        0.15 D        0.10 E        0.09 F        0.05 G        0.01 Calculate for any horse it's chance of finishing in nth place. For instance, calculate the chance of HorseC finishing in 2nd place, or calculate the chance of HorseB finishing in 3rd place. I thought that this is something I could get help with online. All of the journal articles I found discuss chances of a pair of horses winning, i.e. the chance of horse A winning and horse B coming second, which is obviously different to this question. This: http://forum.sbrforum.com/handicapper-think-tank/526381-win-v-place-odds-value-math-question.html#post5076725 is the closest thing I have found to what I am looking for, but I believe he assumes that given one horse wins, the others have an equal chance of placing second, which is clearly not the case. UPDATE I just had time to have a go at this and I am trying to come up with a formula for P(i, n) as @ThanosDarkadakis suggested. I am unsure of whether the odds of HorseZ finishing 3rd is: sum of HorseXWin * HorseY2nd * (HorseZWin/(1-HorseXWin-HorseY2nd)), for each X/Y or sum of HorseXWin * HorseY2nd * (HorseZWin/(sum of remaining win probabilities)), for each X/Y or sum of HorseXWin * HorseYWin * (HorseZWin/(1-HorseXWin-HorseYWin)), for each X/Y Where HorseX is the winner of the race, HorseY comes 2nd and HorseZ comes 3rd (for each X/Y). I'm sure that with a formula for P(i, 3) it would be trivial to write a formula for P(i, n). Any suggestions are greatly appreciated.",,"['probability', 'statistics', 'conditional-probability']"
7,Why aren't the strong LLNs and CLT contradicting each other?,Why aren't the strong LLNs and CLT contradicting each other?,,"Given $n$ i.i.d. random variables $\{X_1, X_2, \dots , X_n\}$, each with mean $M$ and variance $V$, both strong and week LLNs seem to say that the average of the $n$ random variables, $S_n = \frac{X_1 + X_2 + \dots + X_n }{n}$, approaches $M$, as $n \to \infty$. The CLT seems to say that, as $n \to \infty$, the distribution of this average $S_n$ approaches a normal distribution with mean $M$ and variance $V$. The problem I'm having is that it seems like the distribution of the average should converge to something like a discrete variable with a PMF like $1$ at $M$ and $0$ everywhere else. This is because the strong LLN says the average must be $M$, as $n$ approaches infinity. Instead, the normal distribution given by the CLT seems to say that there's a chance of the average not being $M$, as $n$ approaches infinity, which seems to contradict the strong LLN. Where's the flaw in my reasoning?","Given $n$ i.i.d. random variables $\{X_1, X_2, \dots , X_n\}$, each with mean $M$ and variance $V$, both strong and week LLNs seem to say that the average of the $n$ random variables, $S_n = \frac{X_1 + X_2 + \dots + X_n }{n}$, approaches $M$, as $n \to \infty$. The CLT seems to say that, as $n \to \infty$, the distribution of this average $S_n$ approaches a normal distribution with mean $M$ and variance $V$. The problem I'm having is that it seems like the distribution of the average should converge to something like a discrete variable with a PMF like $1$ at $M$ and $0$ everywhere else. This is because the strong LLN says the average must be $M$, as $n$ approaches infinity. Instead, the normal distribution given by the CLT seems to say that there's a chance of the average not being $M$, as $n$ approaches infinity, which seems to contradict the strong LLN. Where's the flaw in my reasoning?",,"['probability', 'probability-theory', 'central-limit-theorem', 'law-of-large-numbers']"
8,"the following inequality is true, but I can't prove it","the following inequality is true, but I can't prove it",,"The inequality $$\sum_{k=1}^{2d}\left(1-\frac{1}{2d+2-k}\right)\frac{d^k}{k!}>e^d\left(1-\frac{1}{d}\right)$$ holds for all integer $d\geq 1$. I use computer to verify it for $d\leq 50$, and find it is true, but I can't prove it.  Thanks for your answer.","The inequality $$\sum_{k=1}^{2d}\left(1-\frac{1}{2d+2-k}\right)\frac{d^k}{k!}>e^d\left(1-\frac{1}{d}\right)$$ holds for all integer $d\geq 1$. I use computer to verify it for $d\leq 50$, and find it is true, but I can't prove it.  Thanks for your answer.",,"['probability', 'inequality', 'asymptotics', 'approximation']"
9,Dice throwing probability of three different faces.,Dice throwing probability of three different faces.,,A standard six side die is rolled three times. Find the chance that three different faces appear? My thoughts: Probability p(same face pops up is)= $1- P$. You roll first one and record what you get. The probability of next (2) two rolls give you same face is...? My chances of rolling any given face is $1/6$. It does not matter what you get first role the next two rows have to the same as the first one role. Therefore$= (1-(1/6)^2)= 1-(1/6^2)=1-(1/36)$,A standard six side die is rolled three times. Find the chance that three different faces appear? My thoughts: Probability p(same face pops up is)= $1- P$. You roll first one and record what you get. The probability of next (2) two rolls give you same face is...? My chances of rolling any given face is $1/6$. It does not matter what you get first role the next two rows have to the same as the first one role. Therefore$= (1-(1/6)^2)= 1-(1/6^2)=1-(1/36)$,,['probability']
10,Expectation and variance of this stochastic process,Expectation and variance of this stochastic process,,"I am trying to compute the expectation and variance of the following stochastic process: $$ Z_t = \exp \left( \frac{1}{2} \int_0^t W_s \, dW_s   \right) $$ where $W_t$ is a standard Brownian motion. I have tried the following to compute the expectation: Let $Y_t = \int_0^t W_s \, dW_s$, then $dY_t = W_t \ dW_t$, and applying the Ito formula to $Z_t = \exp\left( \frac{1}{2} Y_t  \right) $ I get $$ dZ_t = \frac{1}{2} Z_t W_t \, dW_t + \frac{1}{8} Z_t W_t^2 \, dt $$ Writing this in integral form and taking expectations, the $dW_t$ integral vanishes and I find that $$ \mathbb{E}(Z_t) = 1 + \frac{1}{8} \int_0^t \mathbb{E}(Z_s W_s^2) \, ds $$ So it seems like in order to compute $ \mathbb{E}(Z_t) $, I need to compute $ \mathbb{E}(Z_t W_t^2)$. That involves expressing $ Z_t W_t^2$ as an Ito process, which in turn involves expressing $Z_t W_t^n$ as an Ito process for some higher power of $n$, and this process does not seem to terminate. Is there some trick I can use to simplify the computation of this expectation? I am running into the same issues when computing $\mathbb{E}(Z_t^2) $ to find the variance as well, so suggestions for that computation would also be very welcome.","I am trying to compute the expectation and variance of the following stochastic process: $$ Z_t = \exp \left( \frac{1}{2} \int_0^t W_s \, dW_s   \right) $$ where $W_t$ is a standard Brownian motion. I have tried the following to compute the expectation: Let $Y_t = \int_0^t W_s \, dW_s$, then $dY_t = W_t \ dW_t$, and applying the Ito formula to $Z_t = \exp\left( \frac{1}{2} Y_t  \right) $ I get $$ dZ_t = \frac{1}{2} Z_t W_t \, dW_t + \frac{1}{8} Z_t W_t^2 \, dt $$ Writing this in integral form and taking expectations, the $dW_t$ integral vanishes and I find that $$ \mathbb{E}(Z_t) = 1 + \frac{1}{8} \int_0^t \mathbb{E}(Z_s W_s^2) \, ds $$ So it seems like in order to compute $ \mathbb{E}(Z_t) $, I need to compute $ \mathbb{E}(Z_t W_t^2)$. That involves expressing $ Z_t W_t^2$ as an Ito process, which in turn involves expressing $Z_t W_t^n$ as an Ito process for some higher power of $n$, and this process does not seem to terminate. Is there some trick I can use to simplify the computation of this expectation? I am running into the same issues when computing $\mathbb{E}(Z_t^2) $ to find the variance as well, so suggestions for that computation would also be very welcome.",,"['probability', 'stochastic-calculus', 'stochastic-integrals']"
11,Evaluation of probability related integral,Evaluation of probability related integral,,"I have encountered the following integral in my research which does not give-in to my attempts: $$ \int_\mathbb{R} x \left( \frac{1}{\sigma_1} \phi\left(\frac{x}{\sigma_1}\right) \Phi\left(\frac{x-\mu}{\sigma_2}\right) + \frac{1}{\sigma_2} \phi\left(\frac{x-\mu}{\sigma_2}\right) \Phi\left(\frac{x}{\sigma_1}\right) \right) dx $$ where $\phi(x)$ denote probability density function and $\Phi(x)$ a cumulative density function of the standard normal distribution. $\sigma_1$ and $\sigma_2$ are positive, and $\mu$ is real. I would appreciate hints on how to evaluate it. Thank you!","I have encountered the following integral in my research which does not give-in to my attempts: $$ \int_\mathbb{R} x \left( \frac{1}{\sigma_1} \phi\left(\frac{x}{\sigma_1}\right) \Phi\left(\frac{x-\mu}{\sigma_2}\right) + \frac{1}{\sigma_2} \phi\left(\frac{x-\mu}{\sigma_2}\right) \Phi\left(\frac{x}{\sigma_1}\right) \right) dx $$ where $\phi(x)$ denote probability density function and $\Phi(x)$ a cumulative density function of the standard normal distribution. $\sigma_1$ and $\sigma_2$ are positive, and $\mu$ is real. I would appreciate hints on how to evaluate it. Thank you!",,"['probability', 'integration']"
12,expected number of balls withdrawn to get equal numbers of black and white balls,expected number of balls withdrawn to get equal numbers of black and white balls,,"There are $n$ black balls and $n$ white balls in a bin.  I withdraw the balls one at a time without replacement until I have an equal number of white and black balls.  What is the expected number of balls that I have to withdraw? It appears that the answer should be $4^n\left/{2n \choose n}\right.$. So for $n = 3$ it would be: $$4^3\left/{6 \choose 3}\right. =  \frac{64}{20} = \frac{16}{5}$$ I have verified the answers for $n = 2$ and $n = 3$, but I am not able to prove the general result.","There are $n$ black balls and $n$ white balls in a bin.  I withdraw the balls one at a time without replacement until I have an equal number of white and black balls.  What is the expected number of balls that I have to withdraw? It appears that the answer should be $4^n\left/{2n \choose n}\right.$. So for $n = 3$ it would be: $$4^3\left/{6 \choose 3}\right. =  \frac{64}{20} = \frac{16}{5}$$ I have verified the answers for $n = 2$ and $n = 3$, but I am not able to prove the general result.",,['probability']
13,"What is the expected number of dice one needs to roll to get 1,2,3,4,5,6 in order?","What is the expected number of dice one needs to roll to get 1,2,3,4,5,6 in order?",,"If I have a fair die and throw it until I get a run of 1,2,3,4,5,6 in order, how many times on average must I throw the dice?","If I have a fair die and throw it until I get a run of 1,2,3,4,5,6 in order, how many times on average must I throw the dice?",,"['probability', 'statistics', 'dice']"
14,Probability: People sitting in a row (linear arrangement),Probability: People sitting in a row (linear arrangement),,"Question: Ten persons are seated at random in a row. What is the probability that a particular couple will be seated together? My attempt: 9! 2!/ 10! = $\dfrac{1}{5}$ , since there are 9! ways of sitting in pairs and 2! ways to arrange a couple. The solution I'm given is $\dfrac{1}{63}$. Can someone point out what I'm doing wrong?","Question: Ten persons are seated at random in a row. What is the probability that a particular couple will be seated together? My attempt: 9! 2!/ 10! = $\dfrac{1}{5}$ , since there are 9! ways of sitting in pairs and 2! ways to arrange a couple. The solution I'm given is $\dfrac{1}{63}$. Can someone point out what I'm doing wrong?",,['probability']
15,Central Limit Theorem and sum of squared random variables,Central Limit Theorem and sum of squared random variables,,"This is a two-part question. Suppose I am drawing random variables $X_i\sim A$, $1\leq i \leq n$ where $A$ is a zero-mean, finite variance $\sigma_A^2$, symmetric probability distribution having finite fourth moment $\mathbb{E}(X^4)$ over the support of real number line.  Assume that for all $(i,j)$, $X_i$ and $X_j$ are independent.  I am interested in approximating the distribution of the sum of squares $\sum_{i=1}^nX_i^2$ with the normal distribution, for very large $n$.  In the second part of the question I relax the assumption that $X_i$'s are identically-distributed, but keep same conditions on each $A_i$. By Central Limit Theorem (CLT), the sum of these i.i.d. random variables, the random variable  $$\frac{\sum_{i=1}^nX_i}{\sqrt{n\sigma_A^2}}\xrightarrow{D}\mathcal{N}(0,1)$$ where $\xrightarrow{D}$ denotes convergence in distribution. Thus, I can approximate the distribution of the sum by $\mathcal{N}(0,n\sigma_A^2)$ for large enough $n$. The first part of my question is: what distribution can I use to approximate the sum of the squares of a large number of these i.i.d. random variables $\sum_{i=1}^n X^2_i$?  Do a function of it converge to a standard Gaussian in distribution (i.e. given large enough, possibly infinite $n$)?  I understand that if $A$ is a Gaussian, then $\frac{1}{\sigma_A^2}\sum_{i=1}^n X^2_i\sim\chi^2(n)$, which can be approximated by $\mathcal{N}(n\sigma_A^2,2n\sigma_A^4)$ for very large $n$ using the asymptotic properties of chi-squared distribution (where $\sigma_A^4$ denotes squared variance.)  But what happens when $A$ has the nice properties described above, but is not necessarily Gaussian? My intuition tells me that that it should converge to a Gaussian, since we are still dealing with a sum of random variables with finite mean and variance.  But I'm not sure how to prove that or characterize the distribution in terms of $n$ and $\sigma_A^2$. Second part of the question is a further generalization on this topic.  Now suppose $X_i\sim A_i$ are non-identically distributed.  They are all still independent, and $A_i$ are still zero-mean and symmetric, but they all have different finite variances $\sigma_i^2$, and may have a different form.  Since the means and variances are finite, Lindeberg's condition is met, which assures us that CLT holds for the $\frac{\sum_{i=1}^n X_i}{\sqrt{\sum_{i=1}^n\sigma_i^2}}\xrightarrow{D}\mathcal{N}(0,1)$.  However, again, I am wondering what happens with the sum of squares $\sum_{i=1}^n X_i^2$.  Is there a function of it that converges to a nice random variable such as Gaussian in distribution (i.e. for an appropriately large $n$, possibly infinite, does it look Gaussian) If so, to what distribution does it converge to and how can one characterize both the distribution and the function of $\sum_{i=1}^n X_i$ in terms of $n$ and $\sigma_i^2$, and possibly $\mathbb{E}(X_i^4)$?  Is the result more attainable if each $A_i$ is a zero-mean Gaussian with variance $\sigma_i^2$? Again, my intuition tells me that a function of $\sum_{i=1}^n X_i^2$ should converge to a Gaussian, since again we are dealing with the sum of random variables with finite means and variances, which should meet Lindeberg's condition...  but is there a proof and how to characterization of this distribution in terms of $n$ and $\sigma_i^2$? EDITS : I have changed the question after @Michael Hardy answered the first part for me.  The second part is still open...","This is a two-part question. Suppose I am drawing random variables $X_i\sim A$, $1\leq i \leq n$ where $A$ is a zero-mean, finite variance $\sigma_A^2$, symmetric probability distribution having finite fourth moment $\mathbb{E}(X^4)$ over the support of real number line.  Assume that for all $(i,j)$, $X_i$ and $X_j$ are independent.  I am interested in approximating the distribution of the sum of squares $\sum_{i=1}^nX_i^2$ with the normal distribution, for very large $n$.  In the second part of the question I relax the assumption that $X_i$'s are identically-distributed, but keep same conditions on each $A_i$. By Central Limit Theorem (CLT), the sum of these i.i.d. random variables, the random variable  $$\frac{\sum_{i=1}^nX_i}{\sqrt{n\sigma_A^2}}\xrightarrow{D}\mathcal{N}(0,1)$$ where $\xrightarrow{D}$ denotes convergence in distribution. Thus, I can approximate the distribution of the sum by $\mathcal{N}(0,n\sigma_A^2)$ for large enough $n$. The first part of my question is: what distribution can I use to approximate the sum of the squares of a large number of these i.i.d. random variables $\sum_{i=1}^n X^2_i$?  Do a function of it converge to a standard Gaussian in distribution (i.e. given large enough, possibly infinite $n$)?  I understand that if $A$ is a Gaussian, then $\frac{1}{\sigma_A^2}\sum_{i=1}^n X^2_i\sim\chi^2(n)$, which can be approximated by $\mathcal{N}(n\sigma_A^2,2n\sigma_A^4)$ for very large $n$ using the asymptotic properties of chi-squared distribution (where $\sigma_A^4$ denotes squared variance.)  But what happens when $A$ has the nice properties described above, but is not necessarily Gaussian? My intuition tells me that that it should converge to a Gaussian, since we are still dealing with a sum of random variables with finite mean and variance.  But I'm not sure how to prove that or characterize the distribution in terms of $n$ and $\sigma_A^2$. Second part of the question is a further generalization on this topic.  Now suppose $X_i\sim A_i$ are non-identically distributed.  They are all still independent, and $A_i$ are still zero-mean and symmetric, but they all have different finite variances $\sigma_i^2$, and may have a different form.  Since the means and variances are finite, Lindeberg's condition is met, which assures us that CLT holds for the $\frac{\sum_{i=1}^n X_i}{\sqrt{\sum_{i=1}^n\sigma_i^2}}\xrightarrow{D}\mathcal{N}(0,1)$.  However, again, I am wondering what happens with the sum of squares $\sum_{i=1}^n X_i^2$.  Is there a function of it that converges to a nice random variable such as Gaussian in distribution (i.e. for an appropriately large $n$, possibly infinite, does it look Gaussian) If so, to what distribution does it converge to and how can one characterize both the distribution and the function of $\sum_{i=1}^n X_i$ in terms of $n$ and $\sigma_i^2$, and possibly $\mathbb{E}(X_i^4)$?  Is the result more attainable if each $A_i$ is a zero-mean Gaussian with variance $\sigma_i^2$? Again, my intuition tells me that a function of $\sum_{i=1}^n X_i^2$ should converge to a Gaussian, since again we are dealing with the sum of random variables with finite means and variances, which should meet Lindeberg's condition...  but is there a proof and how to characterization of this distribution in terms of $n$ and $\sigma_i^2$? EDITS : I have changed the question after @Michael Hardy answered the first part for me.  The second part is still open...",,"['probability', 'probability-theory', 'asymptotics']"
16,Probability of cumulative dice rolls hitting a number,Probability of cumulative dice rolls hitting a number,,"Is there a general formula to determine the probability of unbounded, cumulative dice rolls hitting a specified number? For Example, with a D6 and 14: 5 + 2 + 3 + 4 = 14 : success 1 + 1 + 1 + 6 + 5 + 4 = 17 : failure","Is there a general formula to determine the probability of unbounded, cumulative dice rolls hitting a specified number? For Example, with a D6 and 14: 5 + 2 + 3 + 4 = 14 : success 1 + 1 + 1 + 6 + 5 + 4 = 17 : failure",,['number-theory']
17,Taking the Limit of Stars and Bars,Taking the Limit of Stars and Bars,,"I'm current working on the following question from Chapter 1 of Theory of Probability and Random Processes by Koralov and Sinai: For integers $n$ and $r$ , find the number of solutions of the equation $$x_1 + \ldots + x_r = n,$$ where $x_i \geq 0$ are integers. Assuming the uniform distribution on the space of the solutions, find $P(x_1=a)$ and its limit as $r\to \infty$ , $n\to\infty$ , $n/r\to\rho > 0$ . So, the first part is just a simple stars and bars and we get $\binom{n+r-1}{r-1}$ . However, it's the second part, taking the limit, that I'm struggling with. Essentially, I'm trying to evaluate the following limit $$\lim_{n\to\infty\,r\to\infty\\n/r\to\rho} \binom{n-a+r-2}{r-2}\big/\binom{n+r-1}{r-1}.$$ Intuitively, I expect the limit to converge to some Poisson Distribution parameterized by $\rho$ and evaluated at $a$ . I've attempted this by applying Stirling's Approximation, but have no idea how to proceed: \begin{align}P(x_1=a)&=\binom{n-a+r-2}{r-2}\big/\binom{n+r-1}{r-1} \\ &= \frac{(n-a+r-2)!(r-1)!n!}{(r-2)!(n-a)!(n+r-1)!} \\  &= \frac{(r-1)n!(n-a+r-2)!}{(n+r-1)!(n-a)!} \\ &\approx \frac{(r-1)\sqrt{2\pi n}(n/e)^n\sqrt{2\pi (n-a+r-2)}\left(\frac{n-a+r-2}{e}\right)^{n-a+r-2}}{\sqrt{2\pi(n+r-1)}\left(\frac{n+r-1}{e}\right)^{n+r-1}\sqrt{2\pi (n-a)}\left(\frac{n-a}{e}\right)^{n-a}} \\ &\,\,\vdots \\ &= (r-1)n^n (e^{r-1})(n-a+r-2)^{n-a+r-2}(e^{2-r})\left(\frac{1}{n-a}\right)^{n-a}\left(\frac{1}{n+r-1}\right)^{n+r-1} \\ &\,\,\vdots \\ &= (r-1)e\left(\frac{n}{n+r}\right)^a \\ P(x_1=a)&= (r-1)e\left(\frac{n/r}{n/r+1}\right)^a. \end{align} Then, taking the limit of the last expression we get $(r-1)e(\rho/(\rho+1))^a$ , which then goes to infinity. But this result makes no sense...","I'm current working on the following question from Chapter 1 of Theory of Probability and Random Processes by Koralov and Sinai: For integers and , find the number of solutions of the equation where are integers. Assuming the uniform distribution on the space of the solutions, find and its limit as , , . So, the first part is just a simple stars and bars and we get . However, it's the second part, taking the limit, that I'm struggling with. Essentially, I'm trying to evaluate the following limit Intuitively, I expect the limit to converge to some Poisson Distribution parameterized by and evaluated at . I've attempted this by applying Stirling's Approximation, but have no idea how to proceed: Then, taking the limit of the last expression we get , which then goes to infinity. But this result makes no sense...","n r x_1 + \ldots + x_r = n, x_i \geq 0 P(x_1=a) r\to \infty n\to\infty n/r\to\rho > 0 \binom{n+r-1}{r-1} \lim_{n\to\infty\,r\to\infty\\n/r\to\rho} \binom{n-a+r-2}{r-2}\big/\binom{n+r-1}{r-1}. \rho a \begin{align}P(x_1=a)&=\binom{n-a+r-2}{r-2}\big/\binom{n+r-1}{r-1} \\ &= \frac{(n-a+r-2)!(r-1)!n!}{(r-2)!(n-a)!(n+r-1)!} \\ 
&= \frac{(r-1)n!(n-a+r-2)!}{(n+r-1)!(n-a)!} \\
&\approx \frac{(r-1)\sqrt{2\pi n}(n/e)^n\sqrt{2\pi (n-a+r-2)}\left(\frac{n-a+r-2}{e}\right)^{n-a+r-2}}{\sqrt{2\pi(n+r-1)}\left(\frac{n+r-1}{e}\right)^{n+r-1}\sqrt{2\pi (n-a)}\left(\frac{n-a}{e}\right)^{n-a}} \\
&\,\,\vdots \\
&= (r-1)n^n (e^{r-1})(n-a+r-2)^{n-a+r-2}(e^{2-r})\left(\frac{1}{n-a}\right)^{n-a}\left(\frac{1}{n+r-1}\right)^{n+r-1} \\
&\,\,\vdots \\
&= (r-1)e\left(\frac{n}{n+r}\right)^a \\
P(x_1=a)&= (r-1)e\left(\frac{n/r}{n/r+1}\right)^a.
\end{align} (r-1)e(\rho/(\rho+1))^a","['probability', 'combinatorics', 'limits', 'solution-verification']"
18,Why Doesn't the St Petersburg Paradox Happen All the Time?,Why Doesn't the St Petersburg Paradox Happen All the Time?,,"I am learning about the St Petersburg Paradox https://en.wikipedia.org/wiki/St._Petersburg_paradox - here is my attempt to summarize it: A fair coin is tossed at each stage. The initial stake begins at 2 dollars and is doubled every time tails appears. The first time heads appears, the game ends and the player wins whatever is the current stake As we can see, this game will have an expected reward of infinite dollars: $$E(X) = \sum_{i=1}^{\infty} x_i \cdot p_i$$ $$E  = \sum_{n=1}^{\infty} \frac{1}{2^n} \cdot 2^n = \frac{1}{2} \cdot 2 + \frac{1}{4} \cdot 4 + \frac{1}{8} \cdot 8 + \frac{1}{16} \cdot 16 + ...  = 1 + 1 + 1 + 1 + ...  = \sum_{n=1}^{\infty} 1  =  \infty$$ The paradox is that even though the game has an infinite reward, in real life simulations, the game usually ends up with a finite reward. Although seemingly counterintuitive, this does seem logical. Even more, we can write computer simulations to see that large number of games will have finite rewards. My question is about applying the insights of the St Petersburg Paradox to the first passage/first hitting times of Brownian Motions . For example, consider the generic Brownian Motion: $$Y_t = y_0 + \mu t + \sigma W_t$$ $Y_t$ is the value of the process at time $t$ . $y_0$ is the initial value of the process at time $t=0$ . $\mu$ is the drift rate, representing the deterministic trend. $\sigma$ is the diffusion coefficient, scaling the Brownian motion $W_t$ . $W_t$ is a standard Brownian motion. Now, consider the following situations (all with 1 dimensional continuous Brownian Motions): Situation 1: An unconstrained Brownian Motion without Drift starting at $y=1$ at time $t=0$ : When will it be expected to first reach the point $y=5$ ? Situation 2: A Brownian Motion without Drift starting at $y=1$ at time $t=0$ : If the stopping condition is when it reaches the point $y=5$ or $y=-5$ for the first time - when will it be expected to stop? Situation 3: A Brownian Motion without Drift starting at $y=1$ at time $t=0$ : If it can only go between the points $y=5$ or $y=-5$ ,  when will it be expected to first reach the point $y=3$ ? (i.e. if it reaches $y=-5$ , it ""bounces back"" - however I am not sure how to mathematically encapsulate this ""bouncing back"" behavior) Situation 4: How will the first passage times for Situations 1,2,3 change if we use Brownian Motions with Drift? (i.e. I know that the Inverse Gaussian Distribution is used here) Situation 5: How will the first passage times for Situations 1,2,3,4 change if the Brownian Motion can only take discrete values? (i.e. a random walk) Naively, using the logic from the St Petersburg Paradox, I could argue that the expected stopping times for the above 5 questions will all be infinite. That is, technically, there are very small probabilities that all these Brownian Motions can get stuck in an infinite loop of going back and forth, and never reach their stopping conditions. Thus, each of these infinitely long paths are weighted with infinitely small probabilities - and since there are an infinite number of these paths : the expected value would be infinite. Is the St Petersburg Paradox fundamentally at odds with the concept of First Passage/Hitting Times? Yet this is clearly not the case. I can repeatedly simulate any of the above situations and see that all of them have finite stopping times (even though some of them might be long). However, now it seems to me that in theory, the more simulations you do, the probability of encountering a very long simulation increases, thus the average stopping time would statistically increase as the number of simulations increase? Can someone please help me understand how to mathematically analyze the probability distributions and expected first passage/hitting times of the above situations? Why will some of them be finite and some of them be infinite? In situations where there is an infinite answer - is it wrong to just simulate the situation many times and take the expectation of the empirical distribution of these simulations as the average hitting time? It seems to me that by virtue of the St Petersburg Paradox, all hitting time distributions should be infinite - yet this is clearly not the case? Note: Why is the Brownian Motion related to the Normal Distribution?","I am learning about the St Petersburg Paradox https://en.wikipedia.org/wiki/St._Petersburg_paradox - here is my attempt to summarize it: A fair coin is tossed at each stage. The initial stake begins at 2 dollars and is doubled every time tails appears. The first time heads appears, the game ends and the player wins whatever is the current stake As we can see, this game will have an expected reward of infinite dollars: The paradox is that even though the game has an infinite reward, in real life simulations, the game usually ends up with a finite reward. Although seemingly counterintuitive, this does seem logical. Even more, we can write computer simulations to see that large number of games will have finite rewards. My question is about applying the insights of the St Petersburg Paradox to the first passage/first hitting times of Brownian Motions . For example, consider the generic Brownian Motion: is the value of the process at time . is the initial value of the process at time . is the drift rate, representing the deterministic trend. is the diffusion coefficient, scaling the Brownian motion . is a standard Brownian motion. Now, consider the following situations (all with 1 dimensional continuous Brownian Motions): Situation 1: An unconstrained Brownian Motion without Drift starting at at time : When will it be expected to first reach the point ? Situation 2: A Brownian Motion without Drift starting at at time : If the stopping condition is when it reaches the point or for the first time - when will it be expected to stop? Situation 3: A Brownian Motion without Drift starting at at time : If it can only go between the points or ,  when will it be expected to first reach the point ? (i.e. if it reaches , it ""bounces back"" - however I am not sure how to mathematically encapsulate this ""bouncing back"" behavior) Situation 4: How will the first passage times for Situations 1,2,3 change if we use Brownian Motions with Drift? (i.e. I know that the Inverse Gaussian Distribution is used here) Situation 5: How will the first passage times for Situations 1,2,3,4 change if the Brownian Motion can only take discrete values? (i.e. a random walk) Naively, using the logic from the St Petersburg Paradox, I could argue that the expected stopping times for the above 5 questions will all be infinite. That is, technically, there are very small probabilities that all these Brownian Motions can get stuck in an infinite loop of going back and forth, and never reach their stopping conditions. Thus, each of these infinitely long paths are weighted with infinitely small probabilities - and since there are an infinite number of these paths : the expected value would be infinite. Is the St Petersburg Paradox fundamentally at odds with the concept of First Passage/Hitting Times? Yet this is clearly not the case. I can repeatedly simulate any of the above situations and see that all of them have finite stopping times (even though some of them might be long). However, now it seems to me that in theory, the more simulations you do, the probability of encountering a very long simulation increases, thus the average stopping time would statistically increase as the number of simulations increase? Can someone please help me understand how to mathematically analyze the probability distributions and expected first passage/hitting times of the above situations? Why will some of them be finite and some of them be infinite? In situations where there is an infinite answer - is it wrong to just simulate the situation many times and take the expectation of the empirical distribution of these simulations as the average hitting time? It seems to me that by virtue of the St Petersburg Paradox, all hitting time distributions should be infinite - yet this is clearly not the case? Note: Why is the Brownian Motion related to the Normal Distribution?",E(X) = \sum_{i=1}^{\infty} x_i \cdot p_i E  = \sum_{n=1}^{\infty} \frac{1}{2^n} \cdot 2^n = \frac{1}{2} \cdot 2 + \frac{1}{4} \cdot 4 + \frac{1}{8} \cdot 8 + \frac{1}{16} \cdot 16 + ...  = 1 + 1 + 1 + 1 + ...  = \sum_{n=1}^{\infty} 1  =  \infty Y_t = y_0 + \mu t + \sigma W_t Y_t t y_0 t=0 \mu \sigma W_t W_t y=1 t=0 y=5 y=1 t=0 y=5 y=-5 y=1 t=0 y=5 y=-5 y=3 y=-5,"['probability', 'brownian-motion', 'paradoxes']"
19,Probability that my set of dice 'wins',Probability that my set of dice 'wins',,"My question is about probabilities. Given are two sets of regular, 6-sided, fair dice of at least one die (but no upper bound on the number of dice). Now, 1 of the sets is considered to be 'the winner'. This is determined with the following method: Sort both sets on the number of eyes. Compare the dice of both sets 1-by-1 starting at the highest by pairing up the dice from both sets (compare 1st with 1st, 2nd with 2nd etc.). As soon as 1 die is higher than the other, then the respective set is the winner and the other dice are ignored. If both sets have an equal number of dice and all dice are equal, then it's a tie. If it's a tie except that one set still has dice left (is a bigger set), then that set is the winner. Examples: A: 6 5 5 (winner) B: 6 5 4  A: 4 (winner) B: 1 1 1  A: 6 5 2 2 B: 6 5 2 2 (tie)  A: 6 5 1 (winner) B: 6 5 Question: How can I calculate the probability that a certain set wins after you throw all dice, given only the sizes of both sets? Edit: The answer can either be a function with 2 inputs, or if this is not possible, an algorithm that calculates this. In practice, the number of dice will be very small (usually smaller than 5). Edit 2: Context : These are the rules for resolving a speed roll to determine initiative in a fight between gladiators in the board game called Spartacus. I'm programming a hobby project where I'm simulating such fights and I want to use the probability of either gladiator winning initiative. The probability is used in a Minimax algorithm to generate child positions of the starting position. Disclaimer: I'm not a mathematician and I have little mathematical knowledge but I do know algebra etc. I'm looking for an answer in the form of an equation with 2 unknowns: sizes of both sets or an algoritm that accepts those inputs","My question is about probabilities. Given are two sets of regular, 6-sided, fair dice of at least one die (but no upper bound on the number of dice). Now, 1 of the sets is considered to be 'the winner'. This is determined with the following method: Sort both sets on the number of eyes. Compare the dice of both sets 1-by-1 starting at the highest by pairing up the dice from both sets (compare 1st with 1st, 2nd with 2nd etc.). As soon as 1 die is higher than the other, then the respective set is the winner and the other dice are ignored. If both sets have an equal number of dice and all dice are equal, then it's a tie. If it's a tie except that one set still has dice left (is a bigger set), then that set is the winner. Examples: A: 6 5 5 (winner) B: 6 5 4  A: 4 (winner) B: 1 1 1  A: 6 5 2 2 B: 6 5 2 2 (tie)  A: 6 5 1 (winner) B: 6 5 Question: How can I calculate the probability that a certain set wins after you throw all dice, given only the sizes of both sets? Edit: The answer can either be a function with 2 inputs, or if this is not possible, an algorithm that calculates this. In practice, the number of dice will be very small (usually smaller than 5). Edit 2: Context : These are the rules for resolving a speed roll to determine initiative in a fight between gladiators in the board game called Spartacus. I'm programming a hobby project where I'm simulating such fights and I want to use the probability of either gladiator winning initiative. The probability is used in a Minimax algorithm to generate child positions of the starting position. Disclaimer: I'm not a mathematician and I have little mathematical knowledge but I do know algebra etc. I'm looking for an answer in the form of an equation with 2 unknowns: sizes of both sets or an algoritm that accepts those inputs",,"['probability', 'dice']"
20,Why is it necessary for density functions to be absolutely continuous with respect to a measure in order for the cross entropy to be defined?,Why is it necessary for density functions to be absolutely continuous with respect to a measure in order for the cross entropy to be defined?,,"In the Wikipedia page describing cross entropy, the following expression is written down to denote the cross entropy $H$ between two densities $p(x)$ and $q(x)$ : $H(p,q) = - \int_\mathcal{X}p(x)\log q(x)dr(x)$ The page mentions that "" $p$ and $q$ must be absolutely continuous with respect to some measure $r$ (usually $r$ is a Lebesgue measure on a Borel $\sigma$ -algebra)"". The definition of absolute continuity is this: Let $I$ be an interval on the real line; let $(x_k, y_k)$ be a finite sequence of pairwise disjoint sub-intervals of $I$ where $x_k < y_k \in I$ ;  a function $f$ is absolutely continuous with respect to $I$ if $\forall \epsilon > 0$ there exists $\delta >0$ such that    we have $\sum_k (y_k - x_k) < \delta \implies \sum_k|f(y_k) - f(x_k)|<\epsilon$ I have some intuition for what absolute continuity with respect to $I$ might mean - if I want the output to change by a tiny amount $\epsilon$ from $f(x_k)$ to $f(y_k)$ , an absolutely continuous function on $I$ guarantees that I only need to push $x_k$ by a tiny amount that is upper bounded by $\delta$ . But why is this an important assumption to make in order for the cross entropy to be defined? I just don't see the link at all, and I am looking for some intuition.","In the Wikipedia page describing cross entropy, the following expression is written down to denote the cross entropy between two densities and : The page mentions that "" and must be absolutely continuous with respect to some measure (usually is a Lebesgue measure on a Borel -algebra)"". The definition of absolute continuity is this: Let be an interval on the real line; let be a finite sequence of pairwise disjoint sub-intervals of where ;  a function is absolutely continuous with respect to if there exists such that    we have I have some intuition for what absolute continuity with respect to might mean - if I want the output to change by a tiny amount from to , an absolutely continuous function on guarantees that I only need to push by a tiny amount that is upper bounded by . But why is this an important assumption to make in order for the cross entropy to be defined? I just don't see the link at all, and I am looking for some intuition.","H p(x) q(x) H(p,q) = - \int_\mathcal{X}p(x)\log q(x)dr(x) p q r r \sigma I (x_k, y_k) I x_k < y_k \in I f I \forall \epsilon > 0 \delta >0 \sum_k (y_k - x_k) < \delta \implies \sum_k|f(y_k) - f(x_k)|<\epsilon I \epsilon f(x_k) f(y_k) I x_k \delta","['probability', 'probability-theory', 'absolute-continuity']"
21,The time it takes for a candle having a lifetime that follows an exponential distribution to go off,The time it takes for a candle having a lifetime that follows an exponential distribution to go off,,"We have $5$ candles each having a lifetime which follows an exponential distribution with parameter $\lambda$ . We light up each candle at time $t=0$ . Assume that $Y$ is the time that it takes for the third candle to go off. What is the expectation and variance of $Y$ ? My try : First of all, I believe having $5$ candles is irrelevant. We only need to consider one random variable following the exponential distribution, like $X\sim \exp(\lambda)$ . It means that on average, it takes $\frac{1}{\lambda}$ for the candle to go off. However, this does not seem like a random variable. It seems like it is a constant. Then, it won't be meaningful to calculate the expectation and variance. Am I right? Also, we know that at some point, the candle ""will"" go off. So, does this mean that we cannot predict at which time it will? I am totally confused thinking about these concepts. I appreciate if someone enlightens me. Note: There is a similar question here . However, the question has not been answered due to the lack of attemps provided by the OP.","We have candles each having a lifetime which follows an exponential distribution with parameter . We light up each candle at time . Assume that is the time that it takes for the third candle to go off. What is the expectation and variance of ? My try : First of all, I believe having candles is irrelevant. We only need to consider one random variable following the exponential distribution, like . It means that on average, it takes for the candle to go off. However, this does not seem like a random variable. It seems like it is a constant. Then, it won't be meaningful to calculate the expectation and variance. Am I right? Also, we know that at some point, the candle ""will"" go off. So, does this mean that we cannot predict at which time it will? I am totally confused thinking about these concepts. I appreciate if someone enlightens me. Note: There is a similar question here . However, the question has not been answered due to the lack of attemps provided by the OP.",5 \lambda t=0 Y Y 5 X\sim \exp(\lambda) \frac{1}{\lambda},"['probability', 'random-variables', 'exponential-distribution']"
22,"Minesweeper odds for this scenario, 2 different calculations","Minesweeper odds for this scenario, 2 different calculations",,"I am trying to calculate the odds, for every square (Except M or Q) of a mine being there, without knowing the total mines on the board. I've found 2 different formulas online, which are similar except for one portion & although produce the same number for some sections, a very different answer is given for sections of the board. For example, the blue section I have 2 different answers for. As you can see I've split up the squares into logical sections, where the probability will be the same. For better explanation, the board looks like this: ABCDE F3G1H IJ1KL MNOPQ The sections, broken up by the number they 'touch': Section           # of bombs in section: -------           ---------------------- (A+B+C+F+G+I+J) = 3 (C+D+E+G+H+K+L) = 1 (G+J+K+N+O+P)   = 1 Note: that I am using the # of bombs to mean the number of bombs contained inside the squares. For example, The green section (A+B+F+I) are 4 squares. At most 4 squares can have 4 mines (1 mine per square). In our case green cannot contain 4 mines though, because of the '3'. Further broken up, Here we get the sections you see in the image. By breaking up sections when we know which squares will give the same odds. I will call these the 'known solutions', or 'absolute solutions' (The right column is the # of bombs inside all of the squares combined): (A+B+F+I) + (C) + (G) + (J) = 3 (G) + (C) + (D+E+H+L) + (K) = 1 (J) + (N+O+P) + (K) + (G) = 1 Here we calculate all of the possible solutions. We do this by making assumptions. First we assume (C) has 1 bomb. In other words, the 'C' square is a bomb. (C is chosen at random, but I prefer to start with a small section). I'll call the first solution 'A1-1': (C) = 1 Since (C) = 1, and ((G) + (C) + (D+E+H+L) + (K)) = 1, we know that (G), (K) and (DEHL) are must be 0: (G) = 0 (D+E+H+L) = 0 (K) = 0 But now we need to make another assumption. I chose (J) = 1. Again, I prefer starting with small sections. This gives us an entire solution (A1-1): Grouping   # of bombs --------   ----------- (C)       = 1 (D+E+H+L) = 0 (K)       = 0 (G)       = 0 (J)       = 1 (N+O+P)   = 0 (A+F+I+B) = 1 I'll keep assuming (C) is 1 until we've come up with every solution (Note the 'absolute solutions' must always hold true, since that's how Minesweeper works, and we want to utilize what we know: (a1-2)      # of bombs ----        ---------- (C)       = 1 (D+E+H+L) = 0 (K)       = 0 (G)       = 0 (J)       = 0 (N+O+P)   = 1 (A+F+I+B) = 2 That's all for C = 1, so next we assume G=1: a2-1        # of bombs ----        ---------- (C)       = 0 (G)       = 1 (D+E+H+L) = 0 (K)       = 0 (N+O+P)   = 0 (J)       = 0 (A+F+I+B) = 2  a2-2 ---- (C)       = 0 (G)       = 0 (J)       = 1 (A+F+I+B) = 2 (N+O+P)   = 0 (D+E+H+L) = 1 (K)       = 0  a2-3 ---- (C)       = 0 (G)       = 0 (J)       = 0 (K)       = 1 (D+E+H+L) = 0 (A+F+I+B) = 3 (N+O+P)   = 0  a2-4 ---- (C)       = 0 (G)       = 0 (J)       = 0 (K)       = 0 (D+E+H+L) = 1 (A+F+I+B) = 3 (N+O+P)   = 1 That gives us every solution. Now we list the number of bombs in every possible solution : Note that:  (A+F+I+B) is Green,  (C)       is Pink,  (D+E+H+L) is orange,  (G)       is brown,  (J)       is Yellow,  (K)       is Purple (N+O+P)   is blue: #:      A1  A12 A21 A22 A23 A24 GREEN:  1   2   2   2   3   3 PINK:   1   1   0   0   0   0    ORANGE: 0   0   0   1   0   1 BROWN:  0   0   1   0   0   0 YELLOW: 1   0   0   1   0   0 PURPLE: 0   0   0   0   1   0 BLUE:   0   1   0   0   0   1 Now we calculate the combinations possible for every solution. This is done by using nCr ( Binomial coefficient ). Where N = Number of Squares and B = numberOfBombs. Combinations = N NCR B. For the first solution (A1-1) these are the combinations: (GREEN)   = 4 NCR 1 = 4 (PINK)    = 1 NCR 1 = 1 (ORANGE)  = 4 NCR 0 = 1 (BROWN)   = 1 NCR 0 = 1 (YELLOW)  = 1 NCR 1 = 1 (PURPLE)  = 0 NCR 1 = 1 (BLUE)    = 3 NCR 0 = 1 Multiplying these combinations we get: 4*1*1*1*1*1*1 = 4 combinations for this solution (A1-1). Doing the same for all solutions we get: #:      A1  A12 A21 A22 A23 A24 GREEN:  4   6   6   6   4   4 PINK:   1   1   1   1   1   1    ORANGE: 1   1   1   4   1   4 BROWN:  1   1   1   1   1   1 YELLOW: 1   1   1   1   1   1 PURPLE: 1   1   1   1   1   1 BLUE:   1   3   1   1   1   3 TOTALS: 4   18  6   24  4   48  Total combinations = 104 Note: In the above table, to get 'TOTALS' we multiply all combinations to get the total combinations for that solution. Now for the part that I am conflicted on. I choose 'Blue' to demonstrate, since I am getting a different answer using either method. Method 1: For each solution take the number of mines divided by the number of squares (3) and multiply by the combinations: A1-1      A1-2      A2-1    A2-2     A2-3    A2-4 (0/3*4)   (1/3*18)  (0/3*6) (0/3*24) (0/3*4) (1/3*48) Adding those numbers up (Taking away the 0's to make it easier): (1/3*18) + (1/3*48) = 22. Now divide by the total combinations (104): 22/104 = 0.212. However there are 3 squares, so we can divide by 3 if we want the odds of a single square in the section: 0.212/3 = 0.0705 Method 2 Multiply the total combinations for the non-zero values (48 + 18), divide by the total combinations (104): 1*66/104 = .635. Again we can divide by 3 if we want the odds of a single square: .635/3 = .212 So, are my odds for hitting a mine on any given blue square .212% , .0705% , or something else?","I am trying to calculate the odds, for every square (Except M or Q) of a mine being there, without knowing the total mines on the board. I've found 2 different formulas online, which are similar except for one portion & although produce the same number for some sections, a very different answer is given for sections of the board. For example, the blue section I have 2 different answers for. As you can see I've split up the squares into logical sections, where the probability will be the same. For better explanation, the board looks like this: ABCDE F3G1H IJ1KL MNOPQ The sections, broken up by the number they 'touch': Section           # of bombs in section: -------           ---------------------- (A+B+C+F+G+I+J) = 3 (C+D+E+G+H+K+L) = 1 (G+J+K+N+O+P)   = 1 Note: that I am using the # of bombs to mean the number of bombs contained inside the squares. For example, The green section (A+B+F+I) are 4 squares. At most 4 squares can have 4 mines (1 mine per square). In our case green cannot contain 4 mines though, because of the '3'. Further broken up, Here we get the sections you see in the image. By breaking up sections when we know which squares will give the same odds. I will call these the 'known solutions', or 'absolute solutions' (The right column is the # of bombs inside all of the squares combined): (A+B+F+I) + (C) + (G) + (J) = 3 (G) + (C) + (D+E+H+L) + (K) = 1 (J) + (N+O+P) + (K) + (G) = 1 Here we calculate all of the possible solutions. We do this by making assumptions. First we assume (C) has 1 bomb. In other words, the 'C' square is a bomb. (C is chosen at random, but I prefer to start with a small section). I'll call the first solution 'A1-1': (C) = 1 Since (C) = 1, and ((G) + (C) + (D+E+H+L) + (K)) = 1, we know that (G), (K) and (DEHL) are must be 0: (G) = 0 (D+E+H+L) = 0 (K) = 0 But now we need to make another assumption. I chose (J) = 1. Again, I prefer starting with small sections. This gives us an entire solution (A1-1): Grouping   # of bombs --------   ----------- (C)       = 1 (D+E+H+L) = 0 (K)       = 0 (G)       = 0 (J)       = 1 (N+O+P)   = 0 (A+F+I+B) = 1 I'll keep assuming (C) is 1 until we've come up with every solution (Note the 'absolute solutions' must always hold true, since that's how Minesweeper works, and we want to utilize what we know: (a1-2)      # of bombs ----        ---------- (C)       = 1 (D+E+H+L) = 0 (K)       = 0 (G)       = 0 (J)       = 0 (N+O+P)   = 1 (A+F+I+B) = 2 That's all for C = 1, so next we assume G=1: a2-1        # of bombs ----        ---------- (C)       = 0 (G)       = 1 (D+E+H+L) = 0 (K)       = 0 (N+O+P)   = 0 (J)       = 0 (A+F+I+B) = 2  a2-2 ---- (C)       = 0 (G)       = 0 (J)       = 1 (A+F+I+B) = 2 (N+O+P)   = 0 (D+E+H+L) = 1 (K)       = 0  a2-3 ---- (C)       = 0 (G)       = 0 (J)       = 0 (K)       = 1 (D+E+H+L) = 0 (A+F+I+B) = 3 (N+O+P)   = 0  a2-4 ---- (C)       = 0 (G)       = 0 (J)       = 0 (K)       = 0 (D+E+H+L) = 1 (A+F+I+B) = 3 (N+O+P)   = 1 That gives us every solution. Now we list the number of bombs in every possible solution : Note that:  (A+F+I+B) is Green,  (C)       is Pink,  (D+E+H+L) is orange,  (G)       is brown,  (J)       is Yellow,  (K)       is Purple (N+O+P)   is blue: #:      A1  A12 A21 A22 A23 A24 GREEN:  1   2   2   2   3   3 PINK:   1   1   0   0   0   0    ORANGE: 0   0   0   1   0   1 BROWN:  0   0   1   0   0   0 YELLOW: 1   0   0   1   0   0 PURPLE: 0   0   0   0   1   0 BLUE:   0   1   0   0   0   1 Now we calculate the combinations possible for every solution. This is done by using nCr ( Binomial coefficient ). Where N = Number of Squares and B = numberOfBombs. Combinations = N NCR B. For the first solution (A1-1) these are the combinations: (GREEN)   = 4 NCR 1 = 4 (PINK)    = 1 NCR 1 = 1 (ORANGE)  = 4 NCR 0 = 1 (BROWN)   = 1 NCR 0 = 1 (YELLOW)  = 1 NCR 1 = 1 (PURPLE)  = 0 NCR 1 = 1 (BLUE)    = 3 NCR 0 = 1 Multiplying these combinations we get: 4*1*1*1*1*1*1 = 4 combinations for this solution (A1-1). Doing the same for all solutions we get: #:      A1  A12 A21 A22 A23 A24 GREEN:  4   6   6   6   4   4 PINK:   1   1   1   1   1   1    ORANGE: 1   1   1   4   1   4 BROWN:  1   1   1   1   1   1 YELLOW: 1   1   1   1   1   1 PURPLE: 1   1   1   1   1   1 BLUE:   1   3   1   1   1   3 TOTALS: 4   18  6   24  4   48  Total combinations = 104 Note: In the above table, to get 'TOTALS' we multiply all combinations to get the total combinations for that solution. Now for the part that I am conflicted on. I choose 'Blue' to demonstrate, since I am getting a different answer using either method. Method 1: For each solution take the number of mines divided by the number of squares (3) and multiply by the combinations: A1-1      A1-2      A2-1    A2-2     A2-3    A2-4 (0/3*4)   (1/3*18)  (0/3*6) (0/3*24) (0/3*4) (1/3*48) Adding those numbers up (Taking away the 0's to make it easier): (1/3*18) + (1/3*48) = 22. Now divide by the total combinations (104): 22/104 = 0.212. However there are 3 squares, so we can divide by 3 if we want the odds of a single square in the section: 0.212/3 = 0.0705 Method 2 Multiply the total combinations for the non-zero values (48 + 18), divide by the total combinations (104): 1*66/104 = .635. Again we can divide by 3 if we want the odds of a single square: .635/3 = .212 So, are my odds for hitting a mine on any given blue square .212% , .0705% , or something else?",,"['probability', 'combinations']"
23,Probability of three sequential events,Probability of three sequential events,,"A smuggler wants to transfer his smuggled goods from city A to city B. There are three police check posts between these two cities. Assume that there is no communication among the check posts. The probabilities of him being caught at these three stops are $0.7, 0.5$ and $0.3$ respectively. What is the probability that he successfully transfers his goods? A] $0.105$ B] $0.5$ C] $0.245$ D] $0.045$ Is it as simple as calculating success in all three scenarios: $0.3 * 0.5 * 0.7 = 0.105$ . Is A correct answer ?",A smuggler wants to transfer his smuggled goods from city A to city B. There are three police check posts between these two cities. Assume that there is no communication among the check posts. The probabilities of him being caught at these three stops are and respectively. What is the probability that he successfully transfers his goods? A] B] C] D] Is it as simple as calculating success in all three scenarios: . Is A correct answer ?,"0.7, 0.5 0.3 0.105 0.5 0.245 0.045 0.3 * 0.5 * 0.7 = 0.105","['probability', 'proof-verification']"
24,Charged particles,Charged particles,,"We are creating a circular hub consisting of charged 0 and 1 particles next to each other, beginning with four of them: 0, 1, -0 and -1 in this order. Every 1 sec we randomly select one of each kind and add it next to the last one. Whenever a 0 particle finds itself next to a -0 or a 1 particle next to a -1, they both vanish. Assuming it is equally likely to select each of the 4 kinds, what is the probability that at some point the hub vanishes completely? I assume it is not as easy as $\frac {1}{4}.\frac {1}{3}.\frac {1}{2}$, right? I can't figure out of anything else... Any help?","We are creating a circular hub consisting of charged 0 and 1 particles next to each other, beginning with four of them: 0, 1, -0 and -1 in this order. Every 1 sec we randomly select one of each kind and add it next to the last one. Whenever a 0 particle finds itself next to a -0 or a 1 particle next to a -1, they both vanish. Assuming it is equally likely to select each of the 4 kinds, what is the probability that at some point the hub vanishes completely? I assume it is not as easy as $\frac {1}{4}.\frac {1}{3}.\frac {1}{2}$, right? I can't figure out of anything else... Any help?",,['probability']
25,Derive the probability that Tom W is a computer scientist.,Derive the probability that Tom W is a computer scientist.,,"I'm reading Thinking, Fast and Slow by Daniel Kahneman and I came across the following text: The following is a personality sketch of Tom W written during Tom's senior year in high school by a psychologist, on the basis of psychological tests of uncertain validity: Tom W is of high intelligence, although lacking in true creativity. He has a need for order and clarity, and for neat and tidy systems in which every detail finds its appropriate place. His writing is rather dull and mechanical, occasionally enlivened by somewhat corny puns and flashes of imagination of the sci-fi type. He has a strong drive for competence. He seems to have little feel and little sympathy for other people, and does not enjoy interacting with others. Self-centered, he nonetheless has a deep moral sense. The book then goes on to show that most people, when asked to estimate the probability that Tom W is enrolled in computer science and not some other field, only consider the above description in their judgment, and completely ignore the fact that there are far less students in computer science than there are in social studies. In order to give arrive at a better estimate, Kahneman proposes the use of Bayesian statistics: The relevant ""rules"" for cases such as the Tom W problem are provided by Bayesian statistics. This influential modern approach to statistics is named after an English minister of the eighteenth century, the Reverend Thomas Bayes, who is credited with the first major contribution to a large problem: the logic of how people should change their mind in the light of evidence. Bayes' rule specifies how prior beliefs (in the examples of this chapter, base rates) should be combined with the diagnosticity of the evidence, the degree to which it favors the hypothesis over the alternative. For example, if you believe that $3\%$ of graduate students are enrolled in computer science (the base rate), and you also believe that the description of Tom W is $4$ times more likely for a graduate student in that field than in other fields, then Bayes' rule says you must believe that the probability that Tom W is a computer scientist is now $11\%$ . Question: Why would the posterior probability equal $11\%$ ? If $A$ is the event that Tom is a computer scientist, and $B$ is the event that a CS student has a description like Tom, Bayes' theorem says that $$P(A\mid B) = \dfrac{P(B\mid A)P(A)}{P(B)}$$ If we assume that the base rate is $0.03$ we have that $P(A) = 0.03$ , and if we assume that the given description is four times as likely for a student enrolled in computer science than a student enrolled in any other field, we have that $$\dfrac{P(B\mid A)}{P(B)} = \dfrac{4P(B\mid C)}{5P(B\mid C)} = \dfrac{4}{5}$$ where $C$ is the event that Tom  is not enrolled in computer science and using the fact that $P(B) = P(B\mid A) + P(B\mid C)$ . Combining the prior and the likelihood we get that $$P(A\mid B) = \dfrac{4}{5}*0.03 = 0.024$$ What am I doing wrong? EDIT: I know what I did wrong. It was incorrect for me to say that $P(B) = P(B\mid A) + P(B\mid C)$ . It's supposed to be: $P(B) = P(B\mid A)P(A) + P(B\mid C)P(C),$ and this solves the problem. What should I do now? Answer the question myself, or edit it even more?","I'm reading Thinking, Fast and Slow by Daniel Kahneman and I came across the following text: The following is a personality sketch of Tom W written during Tom's senior year in high school by a psychologist, on the basis of psychological tests of uncertain validity: Tom W is of high intelligence, although lacking in true creativity. He has a need for order and clarity, and for neat and tidy systems in which every detail finds its appropriate place. His writing is rather dull and mechanical, occasionally enlivened by somewhat corny puns and flashes of imagination of the sci-fi type. He has a strong drive for competence. He seems to have little feel and little sympathy for other people, and does not enjoy interacting with others. Self-centered, he nonetheless has a deep moral sense. The book then goes on to show that most people, when asked to estimate the probability that Tom W is enrolled in computer science and not some other field, only consider the above description in their judgment, and completely ignore the fact that there are far less students in computer science than there are in social studies. In order to give arrive at a better estimate, Kahneman proposes the use of Bayesian statistics: The relevant ""rules"" for cases such as the Tom W problem are provided by Bayesian statistics. This influential modern approach to statistics is named after an English minister of the eighteenth century, the Reverend Thomas Bayes, who is credited with the first major contribution to a large problem: the logic of how people should change their mind in the light of evidence. Bayes' rule specifies how prior beliefs (in the examples of this chapter, base rates) should be combined with the diagnosticity of the evidence, the degree to which it favors the hypothesis over the alternative. For example, if you believe that of graduate students are enrolled in computer science (the base rate), and you also believe that the description of Tom W is times more likely for a graduate student in that field than in other fields, then Bayes' rule says you must believe that the probability that Tom W is a computer scientist is now . Question: Why would the posterior probability equal ? If is the event that Tom is a computer scientist, and is the event that a CS student has a description like Tom, Bayes' theorem says that If we assume that the base rate is we have that , and if we assume that the given description is four times as likely for a student enrolled in computer science than a student enrolled in any other field, we have that where is the event that Tom  is not enrolled in computer science and using the fact that . Combining the prior and the likelihood we get that What am I doing wrong? EDIT: I know what I did wrong. It was incorrect for me to say that . It's supposed to be: and this solves the problem. What should I do now? Answer the question myself, or edit it even more?","3\% 4 11\% 11\% A B P(A\mid B) = \dfrac{P(B\mid A)P(A)}{P(B)} 0.03 P(A) = 0.03 \dfrac{P(B\mid A)}{P(B)} = \dfrac{4P(B\mid C)}{5P(B\mid C)} = \dfrac{4}{5} C P(B) = P(B\mid A) + P(B\mid C) P(A\mid B) = \dfrac{4}{5}*0.03 = 0.024 P(B) = P(B\mid A) + P(B\mid C) P(B) = P(B\mid A)P(A) + P(B\mid C)P(C),","['probability', 'probability-theory', 'bayesian', 'bayes-theorem']"
26,Bayes rule for two conditioned events,Bayes rule for two conditioned events,,"I only saw Bayes rule with one conditioned event and now I need to work with two events and I am not sure if this is a right way to do it: $$ p(A \mid B, C) = \frac{p(B \mid A, C)\ p(A \mid C)}{p(B \mid C)} = \frac{p(B, A \mid C)}{p(B\mid C)}$$ I honestly do not know if this makes sense, but I needed to have $p(B\mid C)$ in denominator for the problem that I am solving, so I thought this might be the way to do it. Why is the above true or false?","I only saw Bayes rule with one conditioned event and now I need to work with two events and I am not sure if this is a right way to do it: I honestly do not know if this makes sense, but I needed to have in denominator for the problem that I am solving, so I thought this might be the way to do it. Why is the above true or false?"," p(A \mid B, C) = \frac{p(B \mid A, C)\ p(A \mid C)}{p(B \mid C)} = \frac{p(B, A \mid C)}{p(B\mid C)} p(B\mid C)","['probability', 'conditional-probability', 'bayes-theorem']"
27,An application of Hall's marriage theorem.,An application of Hall's marriage theorem.,,"I am reading the Wikipedia article entitled Hall's marriage theorem.  It states we can use the theorem to prove the following: ""Take a standard deck of cards, and deal them out into 13 piles of 4 cards each. Then, using the marriage theorem, we can show that it is always possible to select exactly 1 card from each pile, such that the 13 selected cards contain exactly one card of each rank (Ace, 2, 3, ..., Queen, King)."" The article doesn't say HOW Hall's theorem can be used to prove this. I think we could create a bipartite graph with one partite set consisting of each of the 13 ranks and the other partite set consisting of the 13 piles. An edge joins a rank to a pile if that rank is in the pile.  Each rank would be joined to at least one pile and at most 4 piles.  This is as far as I have gotten.","I am reading the Wikipedia article entitled Hall's marriage theorem.  It states we can use the theorem to prove the following: ""Take a standard deck of cards, and deal them out into 13 piles of 4 cards each. Then, using the marriage theorem, we can show that it is always possible to select exactly 1 card from each pile, such that the 13 selected cards contain exactly one card of each rank (Ace, 2, 3, ..., Queen, King)."" The article doesn't say HOW Hall's theorem can be used to prove this. I think we could create a bipartite graph with one partite set consisting of each of the 13 ranks and the other partite set consisting of the 13 piles. An edge joins a rank to a pile if that rank is in the pile.  Each rank would be joined to at least one pile and at most 4 piles.  This is as far as I have gotten.",,"['probability', 'combinatorics', 'graph-theory']"
28,Why is my Monty Hall answer wrong using Bayes Rule?,Why is my Monty Hall answer wrong using Bayes Rule?,,"The Monty Hall problem is described this way: Suppose you're on a game show, and you're given the choice of three   doors: Behind one door is a car; behind the others, goats. You pick a   door, say No. 1, and the host, who knows what's behind the doors,   opens another door, say No. 3, which has a goat. He then says to you,   ""Do you want to pick door No. 2?"" Is it to your advantage to switch   your choice? I am interested in finding the probability of winning when you switch. I already know it's $2/3$ but I want to show it with Bayes Rule. I tried this: $A$ = car behind door $1$ $B$ = goat is behind door $3$ $$P(A|B) = \frac{P(B|A)P(A)}{P(B)} = \frac{1 \cdot 1/3}{1-1/3} = \frac{1}{2}$$ $P(B|A)$ = the probability that a goat is behind door $3$ given that the car is behind door $1$. This is equal to $1$ because if we know where the car is, then any other door must have a goat. $P(A)$ = the probability of the car being behind door $1$. Assuming any door is equally likely to contain a car before we open any doors, this is $1/3$. $P(B)$ = the probability of a goat behind behind door $3$. This is equal to $1$ minus the probability that the car is behind door $3$, so $1-1/3$. Where is my mistake?","The Monty Hall problem is described this way: Suppose you're on a game show, and you're given the choice of three   doors: Behind one door is a car; behind the others, goats. You pick a   door, say No. 1, and the host, who knows what's behind the doors,   opens another door, say No. 3, which has a goat. He then says to you,   ""Do you want to pick door No. 2?"" Is it to your advantage to switch   your choice? I am interested in finding the probability of winning when you switch. I already know it's $2/3$ but I want to show it with Bayes Rule. I tried this: $A$ = car behind door $1$ $B$ = goat is behind door $3$ $$P(A|B) = \frac{P(B|A)P(A)}{P(B)} = \frac{1 \cdot 1/3}{1-1/3} = \frac{1}{2}$$ $P(B|A)$ = the probability that a goat is behind door $3$ given that the car is behind door $1$. This is equal to $1$ because if we know where the car is, then any other door must have a goat. $P(A)$ = the probability of the car being behind door $1$. Assuming any door is equally likely to contain a car before we open any doors, this is $1/3$. $P(B)$ = the probability of a goat behind behind door $3$. This is equal to $1$ minus the probability that the car is behind door $3$, so $1-1/3$. Where is my mistake?",,"['probability', 'number-theory', 'bayesian', 'bayes-theorem', 'monty-hall']"
29,Determine the Size of a Test Bank,Determine the Size of a Test Bank,,"Suppose you have two people take an exam which is composed of 30 questions which are randomly chosen from a test bank of n questions. Person A and Person B both take different randomly generated instances of the exam, and then compare the question sets they were given. Person B notices that 7 of their 30 questions were repeated from Person A's question set. Is there anyway to deduce the likely total number of questions in the test bank given you know 7/30 of them were repeated in a second instance of the exam? Obviously you would not get an exact value, but could you determine a range of probabilities for each different size of the test bank? How you would you go about solving this? Thank you!","Suppose you have two people take an exam which is composed of 30 questions which are randomly chosen from a test bank of n questions. Person A and Person B both take different randomly generated instances of the exam, and then compare the question sets they were given. Person B notices that 7 of their 30 questions were repeated from Person A's question set. Is there anyway to deduce the likely total number of questions in the test bank given you know 7/30 of them were repeated in a second instance of the exam? Obviously you would not get an exact value, but could you determine a range of probabilities for each different size of the test bank? How you would you go about solving this? Thank you!",,"['probability', 'combinatorics', 'statistics']"
30,Density of a Normal RV whose mean is drawn from a Normal Distribution (Compound Distribution),Density of a Normal RV whose mean is drawn from a Normal Distribution (Compound Distribution),,"I am trying to compute the density of a random variable that is normal distributed, where the mean of the distribution is itself drawn from a normal distribution. I would like to find the best estimate of $\mu$ given $c$, where $\mu, c$ are defined: \begin{align*} c \sim N(\lambda, 1)\\  \lambda \sim N(\mu,1) \end{align*} Given that we have no prior on $\mu$ I assume the maximum likelihood is the best approach to this question. Wikipedia says  ""Compounding a Gaussian distribution with mean distributed according to another Gaussian distribution yields a Gaussian distribution."" but offers no reference for this. I cannot work this out myself and have no clue where to look for lecture notes or textbooks on this.","I am trying to compute the density of a random variable that is normal distributed, where the mean of the distribution is itself drawn from a normal distribution. I would like to find the best estimate of $\mu$ given $c$, where $\mu, c$ are defined: \begin{align*} c \sim N(\lambda, 1)\\  \lambda \sim N(\mu,1) \end{align*} Given that we have no prior on $\mu$ I assume the maximum likelihood is the best approach to this question. Wikipedia says  ""Compounding a Gaussian distribution with mean distributed according to another Gaussian distribution yields a Gaussian distribution."" but offers no reference for this. I cannot work this out myself and have no clue where to look for lecture notes or textbooks on this.",,"['probability', 'probability-distributions']"
31,Proof: Product of Expectation of two independent random variables!,Proof: Product of Expectation of two independent random variables!,,"Consider two independent Random variables A, and B, now I know that, E[A+B] = E[A] + E[B] , E[AB] = E[A] * E[B] . I am looking for a prove of these properties, I am successful in proving the first one, but I am unable to prove the 2nd property. Can anyone throw some guideline, or a starting point for the second proof? Regards,","Consider two independent Random variables A, and B, now I know that, E[A+B] = E[A] + E[B] , E[AB] = E[A] * E[B] . I am looking for a prove of these properties, I am successful in proving the first one, but I am unable to prove the 2nd property. Can anyone throw some guideline, or a starting point for the second proof? Regards,",,"['probability', 'random-variables', 'expectation']"
32,"Two chess players, A and B, are going to play 7 games. There are three possible outcomes for each game, A wins, A loses, or Tie","Two chess players, A and B, are going to play 7 games. There are three possible outcomes for each game, A wins, A loses, or Tie",,"Two chess players, A and B, are going to play 7 games. There are three possible outcomes for each game, A wins, A loses, or Tie Addtionally, a win is worth 1 point, draw 0.5 points and loss 0 points. (a) How many possibilities for the games are there such that player A ends up with 3 wins, 2 draws and 2 losses? (b) How many possible outcomes for the games are there such that A ends with four points and B ends with 3 points. (c) Now, assume the first player to 4 points wins and no further matches are played. How many outcomes are there such that the match lasts 7 games and A wins with a score of 4 to 3? (a) There are $3^7$ total possibilities for a string of 7 games. 3 of the 7 games need to be wins for A ${7 \choose 3}$, then 4 of the remaining games need to be draws ${4 \choose 2}$ and then the other two games are losses for B ${2 \choose 2}$. The total is then ${7 \choose 3}{4 \choose 2}{2 \choose 2}=210$ for part a. (b) This should be the sum of the previous answer (210) and the total number of outcomes where A wins 4 games, ${7 \choose 4}$= 35. So, 245. (c) For this one, I guess I just have to subtract from the answer for (b) because this includes the matches that go 7 games. I think there are two terms that need to be subtracted, ${6 \choose 4}{3 \choose 3}$, which denotes all outcomes where A wins four of the first 6 games and B wins the other 3. The other term ${6 \choose 3}{3 \choose 2}$, which is the result where A wins 3 of the first 6 and draws 2 of the remaining 3 games. So, the final answer would be $245-{6 \choose 4}{3 \choose 3}-{6 \choose 3}{3 \choose 2}=170$ Is it okay to subsume ${4 \choose 4}$ and ${5 \choose 4}$ in ${6 \choose 4}$? It seems like if I added these terms, I would be counting different outcomes two or three times.","Two chess players, A and B, are going to play 7 games. There are three possible outcomes for each game, A wins, A loses, or Tie Addtionally, a win is worth 1 point, draw 0.5 points and loss 0 points. (a) How many possibilities for the games are there such that player A ends up with 3 wins, 2 draws and 2 losses? (b) How many possible outcomes for the games are there such that A ends with four points and B ends with 3 points. (c) Now, assume the first player to 4 points wins and no further matches are played. How many outcomes are there such that the match lasts 7 games and A wins with a score of 4 to 3? (a) There are $3^7$ total possibilities for a string of 7 games. 3 of the 7 games need to be wins for A ${7 \choose 3}$, then 4 of the remaining games need to be draws ${4 \choose 2}$ and then the other two games are losses for B ${2 \choose 2}$. The total is then ${7 \choose 3}{4 \choose 2}{2 \choose 2}=210$ for part a. (b) This should be the sum of the previous answer (210) and the total number of outcomes where A wins 4 games, ${7 \choose 4}$= 35. So, 245. (c) For this one, I guess I just have to subtract from the answer for (b) because this includes the matches that go 7 games. I think there are two terms that need to be subtracted, ${6 \choose 4}{3 \choose 3}$, which denotes all outcomes where A wins four of the first 6 games and B wins the other 3. The other term ${6 \choose 3}{3 \choose 2}$, which is the result where A wins 3 of the first 6 and draws 2 of the remaining 3 games. So, the final answer would be $245-{6 \choose 4}{3 \choose 3}-{6 \choose 3}{3 \choose 2}=170$ Is it okay to subsume ${4 \choose 4}$ and ${5 \choose 4}$ in ${6 \choose 4}$? It seems like if I added these terms, I would be counting different outcomes two or three times.",,"['probability', 'combinatorics', 'solution-verification']"
33,What is the value of $\prod_{i=1}^\infty \left(1-\frac{1}{2^i}\right)$? [duplicate],What is the value of ? [duplicate],\prod_{i=1}^\infty \left(1-\frac{1}{2^i}\right),"This question already has an answer here : How to solve the limit $\lim\limits_{n\to \infty}(1-a)(1-a^2)\cdots(1-a^n)$? (1 answer) Closed 4 years ago . Also, what about in general, for some value p , which has the value 2 in the given formula? MOTIVATION: I was wondering the probability of never getting tails if one forever flipped a coin whose probability of landing tails decreased (in this case, geometrically) each flip. The probability of tails on flip i is $\frac{1}{2^i}$ , and the probability of heads on flip i is $1-\frac{1}{2^i}$ . So, first flip the coin is 50-50, next it is 75-25, etc. And the probability of never landing tails is equal to the probability of always landing heads , which is the infinite product of the heads probabilities, yielding $\prod_{i=1}^\infty \left(1-\frac{1}{2^i}\right)$ . => ( $\frac{1}{2} * \frac{3}{4} * \frac{7}{8} ...$ )","This question already has an answer here : How to solve the limit $\lim\limits_{n\to \infty}(1-a)(1-a^2)\cdots(1-a^n)$? (1 answer) Closed 4 years ago . Also, what about in general, for some value p , which has the value 2 in the given formula? MOTIVATION: I was wondering the probability of never getting tails if one forever flipped a coin whose probability of landing tails decreased (in this case, geometrically) each flip. The probability of tails on flip i is , and the probability of heads on flip i is . So, first flip the coin is 50-50, next it is 75-25, etc. And the probability of never landing tails is equal to the probability of always landing heads , which is the infinite product of the heads probabilities, yielding . => ( )",\frac{1}{2^i} 1-\frac{1}{2^i} \prod_{i=1}^\infty \left(1-\frac{1}{2^i}\right) \frac{1}{2} * \frac{3}{4} * \frac{7}{8} ...,"['probability', 'sequences-and-series', 'infinite-product']"
34,When to use Binomial Distribution vs. Poisson Distribution?,When to use Binomial Distribution vs. Poisson Distribution?,,"A bike has probability of breaking down $p$, on any given day. In this case, to determine the number of times that a bike breaks down in a year, I have been told that it would be best modelled with a Poisson distribution, with $\lambda = 365\,p$. I am wondering why it would be incorrect to use a binomial distribution, with $n=365$. After all, isn't Poisson really an approximation of a sum of Bernoulli random variables? Thanks!","A bike has probability of breaking down $p$, on any given day. In this case, to determine the number of times that a bike breaks down in a year, I have been told that it would be best modelled with a Poisson distribution, with $\lambda = 365\,p$. I am wondering why it would be incorrect to use a binomial distribution, with $n=365$. After all, isn't Poisson really an approximation of a sum of Bernoulli random variables? Thanks!",,"['probability', 'probability-distributions', 'poisson-distribution']"
35,"Birthday ""Paradox"" - another, different, version!","Birthday ""Paradox"" - another, different, version!",,"Background Many people are familiar with the so-called Birthday ""Paradox"" that, in a room of $23$ people, there is a better than $50/50$ chance that two of them will share the same birthday. In its more general form for $n$ people, the probability of no two people sharing the same birthday is $p(n) = \large\frac{365!}{365^n(365-n)!}$ . Similar calculations are used for understanding hash-space sizes, cryptographic attacks, etc. Motivation The reason for asking the following question is actually related to understanding a specific financial market behavior. However, a variant on the ""Birthday Paradox"" problem fits perfectly as an analogy and is likely to be of wider interest to more people with different backgrounds. My question is therefore framed along the lines of the  familiar ""Birthday Paradox"", but with a difference, as follows. Situation There are a total of $60$ people in a room. Of these, it turns out that there are $11$ pairs of people who share the same birthday, and two triples (i.e. groups of $3$ people) who have the same birthday. The remaining $60 - 11\cdot2 - 2\cdot3 = 32$ people have different birthdays. Assuming a population in which any day is equally likely for a birthday (i.e. ignore Feb 29th & possible seasonal effects) and, given the specified distribution of birthdays mentioned above, the questioner would actually like to understand how likely (or unlikely) it is that these $60$ people were really chosen randomly. However, I am not sure if the question posed in that way is actually answerable at all. When I posed this question on another site (where it was left unanswered), I was at least advised to re-state the question in a slightly different way, as follows below. Question If $60$ people are chosen at random from a population in which any day is equally likely to be a person's birthday, what is the probability that there are $11$ days on which exactly $2$ people share a birthday, two days on which exactly $3$ of them share a birthday, and no days on which $4$ or more of them share a birthday?","Background Many people are familiar with the so-called Birthday ""Paradox"" that, in a room of people, there is a better than chance that two of them will share the same birthday. In its more general form for people, the probability of no two people sharing the same birthday is . Similar calculations are used for understanding hash-space sizes, cryptographic attacks, etc. Motivation The reason for asking the following question is actually related to understanding a specific financial market behavior. However, a variant on the ""Birthday Paradox"" problem fits perfectly as an analogy and is likely to be of wider interest to more people with different backgrounds. My question is therefore framed along the lines of the  familiar ""Birthday Paradox"", but with a difference, as follows. Situation There are a total of people in a room. Of these, it turns out that there are pairs of people who share the same birthday, and two triples (i.e. groups of people) who have the same birthday. The remaining people have different birthdays. Assuming a population in which any day is equally likely for a birthday (i.e. ignore Feb 29th & possible seasonal effects) and, given the specified distribution of birthdays mentioned above, the questioner would actually like to understand how likely (or unlikely) it is that these people were really chosen randomly. However, I am not sure if the question posed in that way is actually answerable at all. When I posed this question on another site (where it was left unanswered), I was at least advised to re-state the question in a slightly different way, as follows below. Question If people are chosen at random from a population in which any day is equally likely to be a person's birthday, what is the probability that there are days on which exactly people share a birthday, two days on which exactly of them share a birthday, and no days on which or more of them share a birthday?",23 50/50 n p(n) = \large\frac{365!}{365^n(365-n)!} 60 11 3 60 - 11\cdot2 - 2\cdot3 = 32 60 60 11 2 3 4,"['probability', 'probability-theory', 'statistics', 'combinations', 'birthday']"
36,pairwise disjoint events example,pairwise disjoint events example,,"Can someone please give me an example of a pairwise disjoint event? Let $S = \{1,2,3,4,5,6,7,8,9\}.$ Will pairwise disjoint events be: $\{1\},\{2\},\{3,4\},\{5,6,7,8,9\}$? In order to be pairwise disjoint event does it just mean that for all $A_i$ inside $S$ the intersection between $A_i$ and $A_j$ ($j$ not equal $i$) is the empty set?","Can someone please give me an example of a pairwise disjoint event? Let $S = \{1,2,3,4,5,6,7,8,9\}.$ Will pairwise disjoint events be: $\{1\},\{2\},\{3,4\},\{5,6,7,8,9\}$? In order to be pairwise disjoint event does it just mean that for all $A_i$ inside $S$ the intersection between $A_i$ and $A_j$ ($j$ not equal $i$) is the empty set?",,['probability']
37,Odds of being correct X times in a row,Odds of being correct X times in a row,,Is there a simple way to know what the chances are of being correct for a given number of opportunities? To keep this simple: I am either right or wrong with a 50/50 chance. What are the odds that I'll be correct 7 times in a row or 20 or simply X times? ... and can the answer be put in simple terms ;),Is there a simple way to know what the chances are of being correct for a given number of opportunities? To keep this simple: I am either right or wrong with a 50/50 chance. What are the odds that I'll be correct 7 times in a row or 20 or simply X times? ... and can the answer be put in simple terms ;),,['probability']
38,Intuition for scale of the largest eigenvalue of symmetric Gaussian matrix,Intuition for scale of the largest eigenvalue of symmetric Gaussian matrix,,"Let $X$ be $n \times n$ matrix whose matrix elements are independent identically distributed normal variables with zero mean and variance of $\frac{1}{2}$. Then $$      A = \frac{1}{2} \left(X + X^\top\right) $$ is a random matrix from GOE ensemble with weight $\exp(-\operatorname{Tr}(A^2))$. Let $\lambda_\max(n)$ denote its largest eigenvalue. The soft edge limit asserts convergence of $\left(\lambda_\max(n)-\sqrt{n}\right) n^{1/6}$ in distribution as $n$ increases. Q: I am seeking to get an intuition (or better yet, a simple argument) for why the largest eigenvalue scales like $\sqrt{n}$.","Let $X$ be $n \times n$ matrix whose matrix elements are independent identically distributed normal variables with zero mean and variance of $\frac{1}{2}$. Then $$      A = \frac{1}{2} \left(X + X^\top\right) $$ is a random matrix from GOE ensemble with weight $\exp(-\operatorname{Tr}(A^2))$. Let $\lambda_\max(n)$ denote its largest eigenvalue. The soft edge limit asserts convergence of $\left(\lambda_\max(n)-\sqrt{n}\right) n^{1/6}$ in distribution as $n$ increases. Q: I am seeking to get an intuition (or better yet, a simple argument) for why the largest eigenvalue scales like $\sqrt{n}$.",,"['probability', 'intuition']"
39,The exact probability of observing $x$ unique elements after sampling with replacement from a set with $N$ elements,The exact probability of observing  unique elements after sampling with replacement from a set with  elements,x N,"Say I sample with replacement from a set of $N$ unique elements s.t. elements are selected with uniform probability.  If I sample with replacement $M$ times from this set, what is the exact probability $P(x)$ that I have observed at least $x$ unique elements? I believe different variants of this question have been asked on this site, however, I haven't seen a form that asks for an explicit probability $P(x)$? For example, Ross Rogers asks a variant of this question here: probability distribution of coverage of a set after `X` independently, randomly selected members of the set , and Henry calculates the mean number of unique elements, $x$, and variance for the coverage of a set of $N$ elements after sampling with replacement $M$ times (we switch $M$ and $x$ here to fit with our variable specification). Reproducing Henry's derivation here: Mean[x] = $N * (1 - (1 - \frac{1}{N})^M)$ Var[x] = $N\left(1-\dfrac{1}{N}\right)^M  + N^2 \left(1-\dfrac{1}{N}\right)\left(1-\dfrac{2}{N}\right)^M - N^2\left(1-\dfrac{1}{N}\right)^{2M}$ (I'll note that I don't quite understand the derivation for Var[x]...) How can we translate this variance into our $P(x)$?","Say I sample with replacement from a set of $N$ unique elements s.t. elements are selected with uniform probability.  If I sample with replacement $M$ times from this set, what is the exact probability $P(x)$ that I have observed at least $x$ unique elements? I believe different variants of this question have been asked on this site, however, I haven't seen a form that asks for an explicit probability $P(x)$? For example, Ross Rogers asks a variant of this question here: probability distribution of coverage of a set after `X` independently, randomly selected members of the set , and Henry calculates the mean number of unique elements, $x$, and variance for the coverage of a set of $N$ elements after sampling with replacement $M$ times (we switch $M$ and $x$ here to fit with our variable specification). Reproducing Henry's derivation here: Mean[x] = $N * (1 - (1 - \frac{1}{N})^M)$ Var[x] = $N\left(1-\dfrac{1}{N}\right)^M  + N^2 \left(1-\dfrac{1}{N}\right)\left(1-\dfrac{2}{N}\right)^M - N^2\left(1-\dfrac{1}{N}\right)^{2M}$ (I'll note that I don't quite understand the derivation for Var[x]...) How can we translate this variance into our $P(x)$?",,['probability']
40,Is the metric induced by convergence in probability (Ky Fan metric) complete?,Is the metric induced by convergence in probability (Ky Fan metric) complete?,,"My question is as the following: Let $X_1,X_2,\cdots$ be independent random variables and $S_n=\sum\limits_{k=0}^n X_k$. Suppose that $\sum\limits_{k=n}^m X_k$ converges in probability to $0$ when $n,m$ go to $\infty$. Does $S_n$ converge also in probability to a certain limit? It is known that convergence in probability defines a topology on the space of random variables over a fixed probability space. This topology is metrizable by the Ky Fan metric, which is caracterized by: $d(X,Y)=\inf\{\epsilon>0: P(|X-Y|>\epsilon)\le\epsilon\}$, or $d(X,Y)=E[\min(|X-Y|,1)]$. If the Ky Fan metric is complete, then $S_n$ would converge to a limit. So is the Ky Fan metric complete?","My question is as the following: Let $X_1,X_2,\cdots$ be independent random variables and $S_n=\sum\limits_{k=0}^n X_k$. Suppose that $\sum\limits_{k=n}^m X_k$ converges in probability to $0$ when $n,m$ go to $\infty$. Does $S_n$ converge also in probability to a certain limit? It is known that convergence in probability defines a topology on the space of random variables over a fixed probability space. This topology is metrizable by the Ky Fan metric, which is caracterized by: $d(X,Y)=\inf\{\epsilon>0: P(|X-Y|>\epsilon)\le\epsilon\}$, or $d(X,Y)=E[\min(|X-Y|,1)]$. If the Ky Fan metric is complete, then $S_n$ would converge to a limit. So is the Ky Fan metric complete?",,"['probability', 'convergence-divergence']"
41,On the number of consecutive tails when flipping a biased coin,On the number of consecutive tails when flipping a biased coin,,Say we flip a biased coin such that the probability of getting the same outcome in a row (head-head or tail-tail) is $p$. What is the probability of getting three or more tails consecutively out of $n$ flips (and alternatively out of infinite number of flips). For example: TTT-H-TTT-HH-TTTT... I am looking for: The fraction of tails that are in sections of size three or more. The expected size of sections with tails.,Say we flip a biased coin such that the probability of getting the same outcome in a row (head-head or tail-tail) is $p$. What is the probability of getting three or more tails consecutively out of $n$ flips (and alternatively out of infinite number of flips). For example: TTT-H-TTT-HH-TTTT... I am looking for: The fraction of tails that are in sections of size three or more. The expected size of sections with tails.,,['probability']
42,exponential bank waiting times,exponential bank waiting times,,"I have a question about expected waiting times at a bank. Consider a bank with two tellers. Three people, A, B and C enter the bank at almost the same time and in that order. A and B go directly into service while C waits for the first avaliable teller. Suppose that the service time for teller one is exponentially distributed with mean 3 and teller two with mean 6. a) What is the expected total amount of time for C to complete her business? b) What is the expected total time until the last of the three customers leaves? c) What is the probability C is the last one to leave?","I have a question about expected waiting times at a bank. Consider a bank with two tellers. Three people, A, B and C enter the bank at almost the same time and in that order. A and B go directly into service while C waits for the first avaliable teller. Suppose that the service time for teller one is exponentially distributed with mean 3 and teller two with mean 6. a) What is the expected total amount of time for C to complete her business? b) What is the expected total time until the last of the three customers leaves? c) What is the probability C is the last one to leave?",,"['probability', 'probability-distributions']"
43,Probability of Random number repeating,Probability of Random number repeating,,"In the situation of having a high entropy random number generator, that generates numbers in the range of 0 and 2,147,000,000. If i have a list of 1,000,000 integer values, what are the chances that a random number will already be on my list?","In the situation of having a high entropy random number generator, that generates numbers in the range of 0 and 2,147,000,000. If i have a list of 1,000,000 integer values, what are the chances that a random number will already be on my list?",,"['probability', 'random']"
44,"Lipschitzness of $f$ on a high-probabilty subset from $\|f(X)-f(Y)\|\le \|X-Y\|$ with high probability for iid $(X,Y)$",Lipschitzness of  on a high-probabilty subset from  with high probability for iid,"f \|f(X)-f(Y)\|\le \|X-Y\| (X,Y)","Consider two iid random vectors $(X,Y)$ both in $R^k$ and $f:R^k\to R^m$ . Assume that for some $\epsilon>0$ (that may be assumed small if necessary, say, $\epsilon<0.01$ ), it holds that $$P \Big( \|f(X)-f(Y)\| \le \|X-Y\|\Big) \ge 1-\epsilon.$$ The norm is the Euclidean norm. The goal is to derive from this high-probabilty bound on the product measure some Lipschitzness condition on $f$ . I am looking of a reverse, in some sense, of the simple observation that if the restriction of $f$ to some $A$ is 1-Lipschitz and $P(X\in A)\ge1-\epsilon/2$ then the above probability bound is true. Question: Assuming $P ( \|f(X)-f(Y)\| \le \|X-Y\|) \ge 1-\epsilon$ , Is it always true that there exists a measurable $A\subset R^k$ such that the restriction of $f$ to $A$ is 1-Lipschitz (or C-Lipschitz for some C) and such that $P(X\in A)\ge 1-g(\epsilon)$ for some $g$ with $g(\epsilon)\to_{\epsilon\to0}0$ ? An answer would still be of interest to me if $k=m=1$ and $X,Y\sim$ Uniform $[0,1]$ .","Consider two iid random vectors both in and . Assume that for some (that may be assumed small if necessary, say, ), it holds that The norm is the Euclidean norm. The goal is to derive from this high-probabilty bound on the product measure some Lipschitzness condition on . I am looking of a reverse, in some sense, of the simple observation that if the restriction of to some is 1-Lipschitz and then the above probability bound is true. Question: Assuming , Is it always true that there exists a measurable such that the restriction of to is 1-Lipschitz (or C-Lipschitz for some C) and such that for some with ? An answer would still be of interest to me if and Uniform .","(X,Y) R^k f:R^k\to R^m \epsilon>0 \epsilon<0.01 P \Big( \|f(X)-f(Y)\| \le \|X-Y\|\Big) \ge 1-\epsilon. f f A P(X\in A)\ge1-\epsilon/2 P ( \|f(X)-f(Y)\| \le \|X-Y\|) \ge 1-\epsilon A\subset R^k f A P(X\in A)\ge 1-g(\epsilon) g g(\epsilon)\to_{\epsilon\to0}0 k=m=1 X,Y\sim [0,1]","['probability', 'functional-analysis', 'independence', 'lipschitz-functions', 'product-measure']"
45,Is it true that if $P(\int_0^T f^2(s) ds<\infty)=1$ then the exponential defines a density?,Is it true that if  then the exponential defines a density?,P(\int_0^T f^2(s) ds<\infty)=1,Let $f(t)$ be a progressively measurable process wrt Brownian motion $B(t)$ so that $$P\left(\int_0^Tf^2(s)ds<\infty\right)=1$$ Is it true then that the exponential $$\exp\left(\int_0^T f(s)dB(s)-\frac12\int_0^Tf^2(s)ds\right)$$ defines a density on Wiener space? I know the Novikov condition $$E\left[\exp\left(\int_0^Tf^2(s)ds\right)\right]<\infty$$ implies that the exponential defines a density. But what is you just have a.s. $L^2$ ?,Let be a progressively measurable process wrt Brownian motion so that Is it true then that the exponential defines a density on Wiener space? I know the Novikov condition implies that the exponential defines a density. But what is you just have a.s. ?,f(t) B(t) P\left(\int_0^Tf^2(s)ds<\infty\right)=1 \exp\left(\int_0^T f(s)dB(s)-\frac12\int_0^Tf^2(s)ds\right) E\left[\exp\left(\int_0^Tf^2(s)ds\right)\right]<\infty L^2,"['probability', 'stochastic-processes']"
46,Probability of different winners in a two candidate election (range voting vs majority),Probability of different winners in a two candidate election (range voting vs majority),,"I was clicking through the xkcd comics, and I came upon xkcd 2225 . I didn't know about "" Range Voting "", so decided to read about this voting system. I came up with the following problem based off it: Let there be $2$ candidates in an election, $C_1$ and $C_2$ . Each voter will randomly assign both candidates a score, choosing from the standard uniform distribution, $U(0, 1)$ . The winner, counting by range voting, will be the candidate who got the greater sum of scores. The winner, counting by majority voting, will be the candidate who got the greater number of high scores. What is the probability that the two winners are different as the number of voters approaches $\infty$ ? I fear that explanation was unclear, so let me illustrate an example: Let there be $5$ voters. Then the scores could be $$[0.1, 0.2]$$ $$[0.6, 0.7]$$ $$[0.9, 0.1]$$ $$[0.4, 0.5]$$ $$[0.8, 0.9]$$ Then $C_1$ would be the winner by range voting since $0.1 + 0.6 + 0.9 + 0.4 + 0.8 = 2.8 > 2.4=0.2+0.7+0.1+0.5+0.9$ . $C_2$ would be the winner by majority because they secured voters $1, 2, 4, 5$ , whereas $C_1$ only secured voter $3$ . I can rewrite the problem as $$2 \mathbb{P}(C_1 \text{ winning range} \cap C_2 \text{ winning majority})$$ This can in turn be written as $$2 \sum_{k=1}^{n/2}\mathbb{P}(C_1 \text{ winning range} \cap C_1 \text{ getting exactly k in majority vote})$$ Let $s_i$ be the value of the vote cast by the $i$ th voter for $C_1$ minus the value of the vote cast for $C_2$ . The values of $s_i$ will follow the distribution of $1 - |x|$ with $-1 < x < 1$ . The inner probability can be written in terms of integrals, although it is very ugly, to get $$2\sum_{k = 1}^{n/2}\binom{n}{k} \int_0^1 ... \int_0^1 \int_{-1}^0 ... \int_{-1}^0 \prod_{i=1}^{k}(1-s_i) \prod_{i=k+1}^n (1+s_i) \left[\sum_{i=1}^n s_i > 0\right] ds_n...ds_{k+1} ds_k...ds_1$$ where $[$ $]$ denotes the Iverson bracket . From here, the integral can be rewritten to get $$2\sum_{k = 1}^{n/2}\binom{n}{k} \underbrace{\int_0^1 ... \int_{0}^1 \prod_{i=1}^{n}s_i \left[\sum_{i=k+1}^n s_i - \sum_{i=1}^k s_i > n-2k \right] ds_n...ds_1}_{I_{n, k}}$$ Using Mathematica, I found that $I_{2, 1} = \frac{1}{8}, I_{3, 1} = \frac{19}{720}, I_{4, 1} = \frac{191}{40320}, I_{5, 1} = \frac{887}{1209600}, I_{6, 1} = \frac{6797}{68428800}, I_{5, 2} = \frac{10117}{1209600}, I_{6, 2} = \frac{467009}{239500800}$ . However, I wasn't able to simplify the sum any further. I found that the approximation for $n = 3$ is $\frac{19}{120}$ , for $n = 5$ it is $\frac{21121}{120960}$ , and for $n = 7$ , it is $\frac{56332921}{311351040} \approx 0.181$ . I didn't include results about even $n$ because of possible ambiguity with the $k = n/2$ case. It seems that $I_{2k, k} = \frac{1}{2^{2k+1}}$ , and $$\lim_{k \to \infty} \frac{\binom{2k}{k}}{2^{2k+1}} = 0$$ so this would confirm that ignoring the $k = n/2$ case would have no impact as $n \to \infty$ . My questions: Would it be possible to find a closed form for $I_{n, k}$ ? If so, what is it? What is the closed form for the limit of the probability as $n$ approaches $\infty$ ? Edit: I can instead use the sums of the integral as the bounds. I get $$I_{n, k} = \int_0^k \int_{n-2k+S_1}^{n-k} P_{k}(S_1)P_{n-k}(S_2)dS_2 dS_1$$ where $P_m(x) = \int_0^1 ... \int_0^1 \prod_{i=1}^m s_i \left[\sum s_i = x\right]ds_m ... ds_1$ $P_m(x)$ can be rewritten as $$\int_{x-1}^{x} (x-t) P_{m-1}(t) dt $$ with $P_m(x) = 0$ for $x < 0$ and $x > m$ . I found that $P_1(x) = x$ for $0 \le x \le 1$ , $$P_2(x) = \left\{\begin{array}{ll} \frac{1}{3!}x^{3} & : 0 \le x \le 1\\ \frac{1}{3!}(-x^3 + 6x - 4) & : 1 \le x \le 2 \end{array} \right.$$ $$P_3(x) = \left\{\begin{array}{ll} \frac{1}{5!}x^{5} & : 0 \le x \le 1\\ \frac{1}{5!}(-2x^5 + 30x^3 - 60x^2 + 45x-12) & : 1 \le x \le 2 \\ \frac{1}{5!}(x^5 - 30x^3 + 60x^2 + 45x-108) & : 2 \le x \le 3 \end{array} \right.$$ $$P_4(x) = \left\{ \begin{array}{ll}  \frac{1}{7!}x^7 &: 0 \le x \le 1 \\ \frac{1}{7!}\left(-3x^{7}+84x^{5}-280x^{4}+420x^{3}-336x^{2}+140x-24\right) &: 1 \le x \le 2 \\ \frac{1}{7!}\left(3x^{7}-168x^{5}+560x^{4}+420x^{3}-4368x^{2}+6860x-3480\right) &: 2 \le x \le 3 \\ \frac{1}{7!}(-x^{7}+84x^{5}-280x^{4}-840x^{3}+4704x^{2}-4480x-1536) &: 3 \le x \le 4 \end{array} \right.$$ I wasn't able to find a closed form for $P_m(x)$ , but I suspect that it might be related to the Irwin-Hall distribution . Here is what I found so far for $P_m(x)$ : $$\left\{ \begin{array}{ll}  \frac{1}{(2m-1)!}x^{2m-1} &: 0 \le x \le 1 \\ \frac{1}{(2m-1)!}\left(x^{2m-1}-\left(2m-1\right)\cdot m\left(x-1\right)^{2m-2}-m\left(x-1\right)^{2m-1}\right) &: 1 \le x \le 2 \end{array} \right.$$ Edit $2$ : Letting $P_{m, k}(x)$ be $P_m(x)$ for $k \le x \le k+1$ and repeatedly using the recurrence relation, I found that $$P_{m, k}(x) = \int_{x-1}^{k}\left(x-x_{1}\right)P_{m-1,k-1}\left(x_{1}\right)dx_{1}+\sum_{t=1}^{m-k-1}\frac{1}{\left(2t+1\right)!}\left(\left(x-k\right)^{2t}\int_{k-1}^{k}P_{m-t-1,k-1}\left(x_{2}\right)\left(2kt+x-\left(1+2t\right)x_{2}\right)dx_{2}+\int_{k-1}^{x-1}P_{m-t-1,k-1}\left(x_{2}\right)\left(1-x+x_{2}\right)^{2t}\left(-2t-x+x_{2}\right)dx_{2}\right)$$ However, when I try to use this for $P_{m, 2}(x)$ , I get a really long and nasty function with hypergeometric functions. Edit $3$ : I was able to get that $$P_{m, m-1}(x) = (-1)^{m+1} \sum_{n=m-1}^{2m-1} \frac{\binom{m}{n-m+1}}{n!}(x-m)^n = \frac{(m-x)^{m-1}\ _1F_1(-m; m; m-x)}{(m-1)!}$$","I was clicking through the xkcd comics, and I came upon xkcd 2225 . I didn't know about "" Range Voting "", so decided to read about this voting system. I came up with the following problem based off it: Let there be candidates in an election, and . Each voter will randomly assign both candidates a score, choosing from the standard uniform distribution, . The winner, counting by range voting, will be the candidate who got the greater sum of scores. The winner, counting by majority voting, will be the candidate who got the greater number of high scores. What is the probability that the two winners are different as the number of voters approaches ? I fear that explanation was unclear, so let me illustrate an example: Let there be voters. Then the scores could be Then would be the winner by range voting since . would be the winner by majority because they secured voters , whereas only secured voter . I can rewrite the problem as This can in turn be written as Let be the value of the vote cast by the th voter for minus the value of the vote cast for . The values of will follow the distribution of with . The inner probability can be written in terms of integrals, although it is very ugly, to get where denotes the Iverson bracket . From here, the integral can be rewritten to get Using Mathematica, I found that . However, I wasn't able to simplify the sum any further. I found that the approximation for is , for it is , and for , it is . I didn't include results about even because of possible ambiguity with the case. It seems that , and so this would confirm that ignoring the case would have no impact as . My questions: Would it be possible to find a closed form for ? If so, what is it? What is the closed form for the limit of the probability as approaches ? Edit: I can instead use the sums of the integral as the bounds. I get where can be rewritten as with for and . I found that for , I wasn't able to find a closed form for , but I suspect that it might be related to the Irwin-Hall distribution . Here is what I found so far for : Edit : Letting be for and repeatedly using the recurrence relation, I found that However, when I try to use this for , I get a really long and nasty function with hypergeometric functions. Edit : I was able to get that","2 C_1 C_2 U(0, 1) \infty 5 [0.1, 0.2] [0.6, 0.7] [0.9, 0.1] [0.4, 0.5] [0.8, 0.9] C_1 0.1 + 0.6 + 0.9 + 0.4 + 0.8 = 2.8 > 2.4=0.2+0.7+0.1+0.5+0.9 C_2 1, 2, 4, 5 C_1 3 2 \mathbb{P}(C_1 \text{ winning range} \cap C_2 \text{ winning majority}) 2 \sum_{k=1}^{n/2}\mathbb{P}(C_1 \text{ winning range} \cap C_1 \text{ getting exactly k in majority vote}) s_i i C_1 C_2 s_i 1 - |x| -1 < x < 1 2\sum_{k = 1}^{n/2}\binom{n}{k} \int_0^1 ... \int_0^1 \int_{-1}^0 ... \int_{-1}^0 \prod_{i=1}^{k}(1-s_i) \prod_{i=k+1}^n (1+s_i) \left[\sum_{i=1}^n s_i > 0\right] ds_n...ds_{k+1} ds_k...ds_1 [ ] 2\sum_{k = 1}^{n/2}\binom{n}{k} \underbrace{\int_0^1 ... \int_{0}^1 \prod_{i=1}^{n}s_i \left[\sum_{i=k+1}^n s_i - \sum_{i=1}^k s_i > n-2k \right] ds_n...ds_1}_{I_{n, k}} I_{2, 1} = \frac{1}{8}, I_{3, 1} = \frac{19}{720}, I_{4, 1} = \frac{191}{40320}, I_{5, 1} = \frac{887}{1209600}, I_{6, 1} = \frac{6797}{68428800}, I_{5, 2} = \frac{10117}{1209600}, I_{6, 2} = \frac{467009}{239500800} n = 3 \frac{19}{120} n = 5 \frac{21121}{120960} n = 7 \frac{56332921}{311351040} \approx 0.181 n k = n/2 I_{2k, k} = \frac{1}{2^{2k+1}} \lim_{k \to \infty} \frac{\binom{2k}{k}}{2^{2k+1}} = 0 k = n/2 n \to \infty I_{n, k} n \infty I_{n, k} = \int_0^k \int_{n-2k+S_1}^{n-k} P_{k}(S_1)P_{n-k}(S_2)dS_2 dS_1 P_m(x) = \int_0^1 ... \int_0^1 \prod_{i=1}^m s_i \left[\sum s_i = x\right]ds_m ... ds_1 P_m(x) \int_{x-1}^{x} (x-t) P_{m-1}(t) dt  P_m(x) = 0 x < 0 x > m P_1(x) = x 0 \le x \le 1 P_2(x) = \left\{\begin{array}{ll} \frac{1}{3!}x^{3} & : 0 \le x \le 1\\ \frac{1}{3!}(-x^3 + 6x - 4) & : 1 \le x \le 2 \end{array} \right. P_3(x) = \left\{\begin{array}{ll} \frac{1}{5!}x^{5} & : 0 \le x \le 1\\ \frac{1}{5!}(-2x^5 + 30x^3 - 60x^2 + 45x-12) & : 1 \le x \le 2 \\ \frac{1}{5!}(x^5 - 30x^3 + 60x^2 + 45x-108) & : 2 \le x \le 3 \end{array} \right. P_4(x) = \left\{ \begin{array}{ll} 
\frac{1}{7!}x^7 &: 0 \le x \le 1
\\ \frac{1}{7!}\left(-3x^{7}+84x^{5}-280x^{4}+420x^{3}-336x^{2}+140x-24\right) &: 1 \le x \le 2
\\ \frac{1}{7!}\left(3x^{7}-168x^{5}+560x^{4}+420x^{3}-4368x^{2}+6860x-3480\right) &: 2 \le x \le 3
\\ \frac{1}{7!}(-x^{7}+84x^{5}-280x^{4}-840x^{3}+4704x^{2}-4480x-1536) &: 3 \le x \le 4
\end{array} \right. P_m(x) P_m(x) \left\{ \begin{array}{ll} 
\frac{1}{(2m-1)!}x^{2m-1} &: 0 \le x \le 1
\\ \frac{1}{(2m-1)!}\left(x^{2m-1}-\left(2m-1\right)\cdot m\left(x-1\right)^{2m-2}-m\left(x-1\right)^{2m-1}\right) &: 1 \le x \le 2
\end{array} \right. 2 P_{m, k}(x) P_m(x) k \le x \le k+1 P_{m, k}(x) = \int_{x-1}^{k}\left(x-x_{1}\right)P_{m-1,k-1}\left(x_{1}\right)dx_{1}+\sum_{t=1}^{m-k-1}\frac{1}{\left(2t+1\right)!}\left(\left(x-k\right)^{2t}\int_{k-1}^{k}P_{m-t-1,k-1}\left(x_{2}\right)\left(2kt+x-\left(1+2t\right)x_{2}\right)dx_{2}+\int_{k-1}^{x-1}P_{m-t-1,k-1}\left(x_{2}\right)\left(1-x+x_{2}\right)^{2t}\left(-2t-x+x_{2}\right)dx_{2}\right) P_{m, 2}(x) 3 P_{m, m-1}(x) = (-1)^{m+1} \sum_{n=m-1}^{2m-1} \frac{\binom{m}{n-m+1}}{n!}(x-m)^n = \frac{(m-x)^{m-1}\ _1F_1(-m; m; m-x)}{(m-1)!}","['probability', 'integration', 'summation', 'voting-theory']"
47,Why does the order matter when I throw differently colored balls into bins? (with limited bin capacity),Why does the order matter when I throw differently colored balls into bins? (with limited bin capacity),,"I have $n$ bins, $n$ red balls, and $n$ green balls. I throw the balls into randomly selected bins one at a time. Once a bin has $2$ balls in it, I close the bin. It matters to me how many bins will have two red balls at the end. Does the order I throw the balls matter? The answer is yes, which I've verified through simulation and looking at the $n=2$ case, but I'm wondering whether there is a powerful conceptual explanation. This could take the form of calculating the expected number of red/red bins for any $n$ in ordered vs randomized sets of balls and noting the difference in the process, or it could take some other form.","I have bins, red balls, and green balls. I throw the balls into randomly selected bins one at a time. Once a bin has balls in it, I close the bin. It matters to me how many bins will have two red balls at the end. Does the order I throw the balls matter? The answer is yes, which I've verified through simulation and looking at the case, but I'm wondering whether there is a powerful conceptual explanation. This could take the form of calculating the expected number of red/red bins for any in ordered vs randomized sets of balls and noting the difference in the process, or it could take some other form.",n n n 2 n=2 n,"['probability', 'balls-in-bins']"
48,A plague spreading on a graph,A plague spreading on a graph,,"This is a problem I heard from a friend. I didn't figure it out, so I want to post it here because it's quite an interesting problem. The island pictured below is made up of nine towns. One day, a plague arrives at $G$. Though the citizens do their best to contain the plague, each road between an infected and uninfected village has a $10\%$ chance every day to spread it to the uninfected one. How long do we expect it to take until the whole population is infected?"" My attempt: Probability is not my strong suit, so I couldn't get very far with this problem. The naive way to go about it is to build a probability tree, but I feel like there has to be a simpler way to do with the degrees of the vertices. The problem I keep running into, though, is that you can easily calculate probabilities for the first day - 10% to each neighboring town, 20% overall, but past that you have too many possible infection maps to do any meaningful calculations. I also just noticed that the last node to be infected (in terms of probability) will be the farthest from $G$, which is $A$ - 4 edges away. Because each day there is a 10% chance of one of those edges being infected, we have an average time of $10*4$=40 days to get to $A$. Is this a correct solution? If not, what is the solution to this problem? EDIT: The answers posted thus far have been amazing, but this problem was given to mathematically talented high school students so there has to be a simple solution (in terms of math used, not the argument itself). I'll be offering a bounty for such an answer when it's available.","This is a problem I heard from a friend. I didn't figure it out, so I want to post it here because it's quite an interesting problem. The island pictured below is made up of nine towns. One day, a plague arrives at $G$. Though the citizens do their best to contain the plague, each road between an infected and uninfected village has a $10\%$ chance every day to spread it to the uninfected one. How long do we expect it to take until the whole population is infected?"" My attempt: Probability is not my strong suit, so I couldn't get very far with this problem. The naive way to go about it is to build a probability tree, but I feel like there has to be a simpler way to do with the degrees of the vertices. The problem I keep running into, though, is that you can easily calculate probabilities for the first day - 10% to each neighboring town, 20% overall, but past that you have too many possible infection maps to do any meaningful calculations. I also just noticed that the last node to be infected (in terms of probability) will be the farthest from $G$, which is $A$ - 4 edges away. Because each day there is a 10% chance of one of those edges being infected, we have an average time of $10*4$=40 days to get to $A$. Is this a correct solution? If not, what is the solution to this problem? EDIT: The answers posted thus far have been amazing, but this problem was given to mathematically talented high school students so there has to be a simple solution (in terms of math used, not the argument itself). I'll be offering a bounty for such an answer when it's available.",,"['probability', 'graph-theory']"
49,Is this a known formula? $ \prod_{k=0}^n \left(1 - \frac{a_k}{N}\right)$,Is this a known formula?, \prod_{k=0}^n \left(1 - \frac{a_k}{N}\right),"I try to quantify a partition, are there any known indicators/caracteristic numbers? Something which came to my mind was $$ \prod_{k=0}^n \left(1 - \frac{a_k}{N}\right), $$ with the following condition $$ \sum_{k=0}^n a_k = N .$$ Is this a known formula? I'd like to have an indicator which tells me if the partition is well spread or concentrated on some few numbers. I hope my question is clear as I know not a lot about partitions. Thank you for your help. Edit: If $a_0=N$ and all others $a_k$ are 0 this formula gives 0. If all $a_k$ are 1 and $n=N$ tends to infinity this formula goes to $\frac{1}{e}$. So I am wondering too if $\frac{1}{e}$ is the upper bound for a finite $N$ for all partitions. Edit2: Thanks a lot for different proofs that $\frac{1}{e}$ is the upper bound. I still like to know if someone knows something more about this formula. If someone has an interessing fact, that would be nice.","I try to quantify a partition, are there any known indicators/caracteristic numbers? Something which came to my mind was $$ \prod_{k=0}^n \left(1 - \frac{a_k}{N}\right), $$ with the following condition $$ \sum_{k=0}^n a_k = N .$$ Is this a known formula? I'd like to have an indicator which tells me if the partition is well spread or concentrated on some few numbers. I hope my question is clear as I know not a lot about partitions. Thank you for your help. Edit: If $a_0=N$ and all others $a_k$ are 0 this formula gives 0. If all $a_k$ are 1 and $n=N$ tends to infinity this formula goes to $\frac{1}{e}$. So I am wondering too if $\frac{1}{e}$ is the upper bound for a finite $N$ for all partitions. Edit2: Thanks a lot for different proofs that $\frac{1}{e}$ is the upper bound. I still like to know if someone knows something more about this formula. If someone has an interessing fact, that would be nice.",,"['probability', 'number-theory']"
50,How to model the probability of this gift exchange?,How to model the probability of this gift exchange?,,"There is a gift exchange with $N$ people using the following rules: Everyone starts with a randomly selected wrapped gift. The people take turns rolling a 6-sided die to determine what action to take. Rolling a 1 or a 2 means that person gets to open the gift in front of them - and that person is taken out of the rotation. Rolling a 3, 4, 5, or 6 causes other events that shift around the wrapped gifts (i.e. that person cannot open their gift yet). The game ends once every gift has been opened. I wanted to know how many turns this gift exchange should go on until completion but I couldn't figure out how to model that. I try restructuring it as ""What is the probability it will end in $X$ turns?"" but still didn't get far. Any ideas? I know the probability of opening a gift on any given turn is $\frac{2}{6} = \frac{1}{3}$. So I could calculate the probability of the gift exchange ending as fast as possible ($N$ turns for $N$ people), which would be $\left(\frac{1}{3}\right)^N$. How can I expand on this to compute the probability of the exchange ending in $X$ turns, where each turn has a $\frac{2}{3}$ chance of ""no gifts opened""?","There is a gift exchange with $N$ people using the following rules: Everyone starts with a randomly selected wrapped gift. The people take turns rolling a 6-sided die to determine what action to take. Rolling a 1 or a 2 means that person gets to open the gift in front of them - and that person is taken out of the rotation. Rolling a 3, 4, 5, or 6 causes other events that shift around the wrapped gifts (i.e. that person cannot open their gift yet). The game ends once every gift has been opened. I wanted to know how many turns this gift exchange should go on until completion but I couldn't figure out how to model that. I try restructuring it as ""What is the probability it will end in $X$ turns?"" but still didn't get far. Any ideas? I know the probability of opening a gift on any given turn is $\frac{2}{6} = \frac{1}{3}$. So I could calculate the probability of the gift exchange ending as fast as possible ($N$ turns for $N$ people), which would be $\left(\frac{1}{3}\right)^N$. How can I expand on this to compute the probability of the exchange ending in $X$ turns, where each turn has a $\frac{2}{3}$ chance of ""no gifts opened""?",,"['probability', 'combinatorics']"
51,Probability of an event occurring within a smaller time interval if one knows the probability of occurrence over a larger time interval,Probability of an event occurring within a smaller time interval if one knows the probability of occurrence over a larger time interval,,"The following threads are related to my question, but since I have minimal confidence around probability & math, I'm not sure how to interpret some of this and whether the answers apply to my situation (I think I'm dealing with a binomial process and most of the relevant material I've found describes Poisson processes): What is the probability of an event happening in some interval given probability of it in x interval? Probability of an event that has happened, to have happened in a specific time range? Calculate probability of an event occurring exactly once in an arbitrarily selected year, given mean annual occurrences over a century Suppose I take ""samples"" of the environment in hopes of detecting something. I have a model that tells me the probability an event will occur at least once sometime between 7:00am and 8:00am. Suppose this probability is 0.25, and is based on an hourly weather prediction -- so my predictive model is only good to the hour. However, I can only take samples in scheduled chunks of one minute. Assuming perfect detection, what's my probability of detecting the event of interest if I sample any SINGLE random minute out of the hour? What is my probability of detecting this event if I can randomly sample 2,3,4,5... or any N <= 60 minutes out of this hour? I was thinking it would make sense for my problem to spread this 0.25 probability uniformly between the 60 minutes since I only have hourly resolution. So if I can only sample 1 minute out of the hour, probability of the event occurring at least once in THAT minute is 0.25*1/60. If I can sample 2 minutes out of the hour, total probability of the event occurring at least once during those minutes is 0.25*2/60. Three minutes would be 0.25*3/60 and so on. Alternatively, I know it might be more conventional to say: 1-((1-0.25/60)^N) for calculating the probability of this event happening at least once across N sampled minutes, but this feels less intuitive for me within the context of a disconnect between the time scales. Perhaps either approach is fine depending on the system assumptions. Regardless,  is it okay to divvy up that 0.25 hourly probability among the 60 minutes the way I have done, or does this violate something basic in probability theory? (If it helps provide context, the events I'm trying to detect are bird songs! I don't care about rates (Poisson), I just care about presence or absence of singing in a given sampled minute.)","The following threads are related to my question, but since I have minimal confidence around probability & math, I'm not sure how to interpret some of this and whether the answers apply to my situation (I think I'm dealing with a binomial process and most of the relevant material I've found describes Poisson processes): What is the probability of an event happening in some interval given probability of it in x interval? Probability of an event that has happened, to have happened in a specific time range? Calculate probability of an event occurring exactly once in an arbitrarily selected year, given mean annual occurrences over a century Suppose I take ""samples"" of the environment in hopes of detecting something. I have a model that tells me the probability an event will occur at least once sometime between 7:00am and 8:00am. Suppose this probability is 0.25, and is based on an hourly weather prediction -- so my predictive model is only good to the hour. However, I can only take samples in scheduled chunks of one minute. Assuming perfect detection, what's my probability of detecting the event of interest if I sample any SINGLE random minute out of the hour? What is my probability of detecting this event if I can randomly sample 2,3,4,5... or any N <= 60 minutes out of this hour? I was thinking it would make sense for my problem to spread this 0.25 probability uniformly between the 60 minutes since I only have hourly resolution. So if I can only sample 1 minute out of the hour, probability of the event occurring at least once in THAT minute is 0.25*1/60. If I can sample 2 minutes out of the hour, total probability of the event occurring at least once during those minutes is 0.25*2/60. Three minutes would be 0.25*3/60 and so on. Alternatively, I know it might be more conventional to say: 1-((1-0.25/60)^N) for calculating the probability of this event happening at least once across N sampled minutes, but this feels less intuitive for me within the context of a disconnect between the time scales. Perhaps either approach is fine depending on the system assumptions. Regardless,  is it okay to divvy up that 0.25 hourly probability among the 60 minutes the way I have done, or does this violate something basic in probability theory? (If it helps provide context, the events I'm trying to detect are bird songs! I don't care about rates (Poisson), I just care about presence or absence of singing in a given sampled minute.)",,['probability']
52,Definition of Tail-index of a probability distribution,Definition of Tail-index of a probability distribution,,What is a valid definition of Tail-index of a probability distribution? I understand that it is something to do with the rate of convergence of the density function $f(x)$ $($to $0)$ as $x \to \infty$. I tried searching google and I do find a lot of articles/papers on the topic but nowhere I can find a specific definition of the term. Any help would be much appreciated! Thanks.,What is a valid definition of Tail-index of a probability distribution? I understand that it is something to do with the rate of convergence of the density function $f(x)$ $($to $0)$ as $x \to \infty$. I tried searching google and I do find a lot of articles/papers on the topic but nowhere I can find a specific definition of the term. Any help would be much appreciated! Thanks.,,"['probability', 'probability-theory']"
53,Showing $\limsup \frac{S_n}{\sqrt{n}} = \infty$,Showing,\limsup \frac{S_n}{\sqrt{n}} = \infty,"Let $X_1, X_2, \dots$ be i.i.d random variables with $\mathbb{E}(X_i) = 0$ and $0 < Var(X_i) < \infty$ . Use the Central Limit Theorem and Kolmogorov’s 0-1 Law to conclude that $\limsup \frac{Sn}{\sqrt{n}} = \infty$ a.s.. Kolmogorov's 0-1 Law: If $X_1, X_2, \dots$ are independent and $A \in \mathcal{T}$ , then $\mathbb{P}(A) = 0$ or $\mathbb{P}(A) = 1$ . Let $A_x = \{{\limsup \frac{S_n}{\sqrt{n}}} > x\}$ . Then $A_x \in \mathcal{T}$ , so I just need to show that $\mathbb{P}(A_x) > 0$ , because $\mathbb{P}( \limsup \frac{S_n}{\sqrt{n}} > x \ \text{i.o.}) \geq \mathbb{P}({\limsup \frac{S_n}{\sqrt{n}} > x}) = 1$ . I'm having some trouble to show that $\mathbb{P}(A_x) > 0$","Let be i.i.d random variables with and . Use the Central Limit Theorem and Kolmogorov’s 0-1 Law to conclude that a.s.. Kolmogorov's 0-1 Law: If are independent and , then or . Let . Then , so I just need to show that , because . I'm having some trouble to show that","X_1, X_2, \dots \mathbb{E}(X_i) = 0 0 < Var(X_i) < \infty \limsup \frac{Sn}{\sqrt{n}} = \infty X_1, X_2, \dots A \in \mathcal{T} \mathbb{P}(A) = 0 \mathbb{P}(A) = 1 A_x = \{{\limsup \frac{S_n}{\sqrt{n}}} > x\} A_x \in \mathcal{T} \mathbb{P}(A_x) > 0 \mathbb{P}( \limsup \frac{S_n}{\sqrt{n}} > x \ \text{i.o.}) \geq \mathbb{P}({\limsup \frac{S_n}{\sqrt{n}} > x}) = 1 \mathbb{P}(A_x) > 0","['probability', 'probability-theory']"
54,Probabilistic classical algorithm on Deutsch-Jozsa problem,Probabilistic classical algorithm on Deutsch-Jozsa problem,,"Here is the description of Deutsch-Jozsa problem: Let $f: \{0,1\}^n \mapsto \{0,1\}$ be a function promised to be either constant or balanced ('balanced' means that $f$ outputs as many 0's as 1's). I need to show that a probabilistic classical algorithm making two evaluations of $f$ can with probability at least 2/3 correctly determine whether $f$ is constant or balanced. There is also a hint: Your guess does not need to be a deterministic function of the results of the two queries. Your result should not assume any particular a priori probabilities of having a constant or balanced function. I'm a bit lost here.  My thinking is that if the two evaluations are the different, then $f$ is definitely balanced.  Otherwise, $f$ could be either constant or balanced.  But the chance of success would be depending on the probability of $f$ being constant, which is against the given hint. How should I approach this problem?","Here is the description of Deutsch-Jozsa problem: Let $f: \{0,1\}^n \mapsto \{0,1\}$ be a function promised to be either constant or balanced ('balanced' means that $f$ outputs as many 0's as 1's). I need to show that a probabilistic classical algorithm making two evaluations of $f$ can with probability at least 2/3 correctly determine whether $f$ is constant or balanced. There is also a hint: Your guess does not need to be a deterministic function of the results of the two queries. Your result should not assume any particular a priori probabilities of having a constant or balanced function. I'm a bit lost here.  My thinking is that if the two evaluations are the different, then $f$ is definitely balanced.  Otherwise, $f$ could be either constant or balanced.  But the chance of success would be depending on the probability of $f$ being constant, which is against the given hint. How should I approach this problem?",,"['probability', 'algorithms', 'quantum-computation']"
55,"Have I found an error in Williams' ""Martingales"" exercises?","Have I found an error in Williams' ""Martingales"" exercises?",,"I want to solve Problem EG.2. from Probability with Martingales : Planet X is a ball with centre O. Three spaceships A, B and C land at random on its surface, their positions being independent and each uniformly distributed on the surface. Spaceships A and B can communicate directly by radio if $\measuredangle AOB < 90^\circ$. Show that the probability that they can keep in touch (with, for example, A communicating with B via C if necessary) is $(\pi + 2)/(4\pi)$. I believe I have shown that the probability is in fact $(2 \pi + 1) / (4 \pi)$. To begin, we denote by $AB$ (resp. $AC$, $BC$) the event that $A$ and $B$ are within $90^\circ$ of each other. We then observe that the probability that communication is possible is given by: $$P(comms) = P(AB \cup (AC \cap BC)),$$ which after some basic manipulation may be re-written as $$P(comms) = P(AB) + P(AC \cap BC) - P(AB \cap AC \cap BC).$$ We then proceed by computing each term on the right-hand side. (A warning that my argument and notation is somewhat loose, and I would appreciate any ideas about tightening it.) For $P(AB)$, we have $$P(AB) = \iint_S P(AB | A = x) \frac{1}{|S|} dS(x),$$ where $S$ denotes the planet's surface and $|S|$ its surface area. By symmetry, we see $P(AB|A) = 1/2$, so that $P(AB) = (1/2)(1/|S|)|S|=1/2$. Next, $$P(AC \cap BC) = \iint_S P(AC|C = x) P(BC|C = x) \frac{1}{|S|} dS(x).$$ By the same argument as above, $P(AC|C) = P(BC|C) = 1/2$, and hence $P(AC \cap BC) = 1/4$. Finally, we have $$P(AB \cap AC \cap BC | A=x) = \iint_{S/x} P(AC \cap BC | A = x, B = y) \frac{1}{2|S|} dS(y),$$ where $S/x$ denotes the hemisphere of $S$ centred on $x$. Now, $P(AC \cap BC|A=x,B=y)$ corresponds to the fraction of $S$ covered by the intersection of $S/x$ and $S/y$. If we define a spherical coordinate system on $S$ with $x$ corresponding to polar angle $\theta = 0$, then this fraction is given by $1/2 - \theta(y)/(2 \pi)$ for $0 \leq \theta(y) \leq \pi/2$ (i.e. $\theta(y)$ in $S/x$), and hence $$P(AB \cap AC \cap BC | A=x) = \frac{1}{4} - \frac{1}{4\pi}$$ (where I skip performing the double integral above here explicitly for brevity). All up, we then obtain $$P(comms) = \frac{2 \pi + 1}{4 \pi},$$ as stated above, which disagrees with Williams' stated result, although no mistake is obvious to me. Moreover, I have written a Monte Carlo simulator in Python that seems to confirm my result (and which I can provide if anyone would find it useful). In summary, I ask the following: (1) Is Williams correct, or am I?; and (2) How can my argument be made tighter, more rigorous, or more elegant?","I want to solve Problem EG.2. from Probability with Martingales : Planet X is a ball with centre O. Three spaceships A, B and C land at random on its surface, their positions being independent and each uniformly distributed on the surface. Spaceships A and B can communicate directly by radio if $\measuredangle AOB < 90^\circ$. Show that the probability that they can keep in touch (with, for example, A communicating with B via C if necessary) is $(\pi + 2)/(4\pi)$. I believe I have shown that the probability is in fact $(2 \pi + 1) / (4 \pi)$. To begin, we denote by $AB$ (resp. $AC$, $BC$) the event that $A$ and $B$ are within $90^\circ$ of each other. We then observe that the probability that communication is possible is given by: $$P(comms) = P(AB \cup (AC \cap BC)),$$ which after some basic manipulation may be re-written as $$P(comms) = P(AB) + P(AC \cap BC) - P(AB \cap AC \cap BC).$$ We then proceed by computing each term on the right-hand side. (A warning that my argument and notation is somewhat loose, and I would appreciate any ideas about tightening it.) For $P(AB)$, we have $$P(AB) = \iint_S P(AB | A = x) \frac{1}{|S|} dS(x),$$ where $S$ denotes the planet's surface and $|S|$ its surface area. By symmetry, we see $P(AB|A) = 1/2$, so that $P(AB) = (1/2)(1/|S|)|S|=1/2$. Next, $$P(AC \cap BC) = \iint_S P(AC|C = x) P(BC|C = x) \frac{1}{|S|} dS(x).$$ By the same argument as above, $P(AC|C) = P(BC|C) = 1/2$, and hence $P(AC \cap BC) = 1/4$. Finally, we have $$P(AB \cap AC \cap BC | A=x) = \iint_{S/x} P(AC \cap BC | A = x, B = y) \frac{1}{2|S|} dS(y),$$ where $S/x$ denotes the hemisphere of $S$ centred on $x$. Now, $P(AC \cap BC|A=x,B=y)$ corresponds to the fraction of $S$ covered by the intersection of $S/x$ and $S/y$. If we define a spherical coordinate system on $S$ with $x$ corresponding to polar angle $\theta = 0$, then this fraction is given by $1/2 - \theta(y)/(2 \pi)$ for $0 \leq \theta(y) \leq \pi/2$ (i.e. $\theta(y)$ in $S/x$), and hence $$P(AB \cap AC \cap BC | A=x) = \frac{1}{4} - \frac{1}{4\pi}$$ (where I skip performing the double integral above here explicitly for brevity). All up, we then obtain $$P(comms) = \frac{2 \pi + 1}{4 \pi},$$ as stated above, which disagrees with Williams' stated result, although no mistake is obvious to me. Moreover, I have written a Monte Carlo simulator in Python that seems to confirm my result (and which I can provide if anyone would find it useful). In summary, I ask the following: (1) Is Williams correct, or am I?; and (2) How can my argument be made tighter, more rigorous, or more elegant?",,"['probability', 'geometric-probability']"
56,"Probability of choosing $n$ numbers from $\{1, \dots, 2n\}$ so that $n$ is 3rd in size",Probability of choosing  numbers from  so that  is 3rd in size,"n \{1, \dots, 2n\} n","We uniformly randomly choose $n$ numbers out of $2n$ numbers from the group $\{1, \dots, 2n\}$ so that order matters and repetitions are allowed. What is the probability that $n$ is the $3^{\text{rd}}$ number in size in the chosen series? (= there are only two bigger than $n$) Note that if a number that is bigger than $n$ was chosen more than once, we still count it as one number bigger than $n$. Example: $n = 5, \{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\}$ $7, 1, 5, 9, 9$ - ok $2, 2, 10, 5, 7$ - ok $6, 6, 3, 5, 5$ - not ok, 5 is $2^{\text{nd}}$ in size My lead was to first choose 2 numbers that are bigger than $n$ out of the n numbers that are bigger than $n$ in the group $\{1, \dots, 2n\}$. Then in order to complete a series of $n$ numbers I need to choose $n-3$ more from the numbers that are equal or smaller than $n$, but then I figured this is not right as a series could be formed from the 2 numbers bigger than $n$ and $n$ itself without any additional numbers. At this point I have no additional leads and could very much use your assistance and guidance.","We uniformly randomly choose $n$ numbers out of $2n$ numbers from the group $\{1, \dots, 2n\}$ so that order matters and repetitions are allowed. What is the probability that $n$ is the $3^{\text{rd}}$ number in size in the chosen series? (= there are only two bigger than $n$) Note that if a number that is bigger than $n$ was chosen more than once, we still count it as one number bigger than $n$. Example: $n = 5, \{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\}$ $7, 1, 5, 9, 9$ - ok $2, 2, 10, 5, 7$ - ok $6, 6, 3, 5, 5$ - not ok, 5 is $2^{\text{nd}}$ in size My lead was to first choose 2 numbers that are bigger than $n$ out of the n numbers that are bigger than $n$ in the group $\{1, \dots, 2n\}$. Then in order to complete a series of $n$ numbers I need to choose $n-3$ more from the numbers that are equal or smaller than $n$, but then I figured this is not right as a series could be formed from the 2 numbers bigger than $n$ and $n$ itself without any additional numbers. At this point I have no additional leads and could very much use your assistance and guidance.",,"['probability', 'combinatorics', 'discrete-mathematics', 'inclusion-exclusion']"
57,Multivariate Normal Distribution: Relationship between two conditional probabilities.,Multivariate Normal Distribution: Relationship between two conditional probabilities.,,"Suppose I have a multivariate normal random variable $Z$ which has $n$ dimensions.  Suppose I have a vector $x$. Set $i$ as a number between $1$ and $n$ and $k$ as a number between $1$ and $n-1$.  Can I say the following about the relationship between the following two probabilities? \begin{align} & P(Z_i>x_i \mid Z_j>x_j \text{ for exactly $k$ components $j$}) \\[10pt] < {} & P(Z_i>x_i \mid Z_j>x_j \text{ for exactly $k+1$ components $j$}) \end{align} This seems logical to me. Essentially we are saying that the fact $k+1$ components cross the threshold as opposed to just $k$ components increases the probability that a specific one crossed its threshold.  However, I have no idea why this has to be true just why I think it should be true.  I would really appreciate a formal explanation or counterproof.Thanks!","Suppose I have a multivariate normal random variable $Z$ which has $n$ dimensions.  Suppose I have a vector $x$. Set $i$ as a number between $1$ and $n$ and $k$ as a number between $1$ and $n-1$.  Can I say the following about the relationship between the following two probabilities? \begin{align} & P(Z_i>x_i \mid Z_j>x_j \text{ for exactly $k$ components $j$}) \\[10pt] < {} & P(Z_i>x_i \mid Z_j>x_j \text{ for exactly $k+1$ components $j$}) \end{align} This seems logical to me. Essentially we are saying that the fact $k+1$ components cross the threshold as opposed to just $k$ components increases the probability that a specific one crossed its threshold.  However, I have no idea why this has to be true just why I think it should be true.  I would really appreciate a formal explanation or counterproof.Thanks!",,"['probability', 'multivariable-calculus', 'normal-distribution']"
58,Throwing dice 10 times,Throwing dice 10 times,,"A fair dice was thrown 10 times, and it's been registered that all numbers 1-6 have appeared at least once. If this is true, what's the probability that at least 2 sixes have appeared? At first I thought I should calculate the amount of combinations of die throws that the 6 numbers that have definitely appeared as $\binom{10}{6}$, then dividing it by the amount of all possible outcomes, $6^{10}$, and then multiply it with the probability of throwing at least 1 six in the remaining 4 throws, since one has already been registered, $P(A)= 1-\left(\frac56\right)^4$. Then I began to have serious doubts, as $6^{10}$ is an insanely large number, and whether I'd even need the possible outcomes of the 6 numbers that were thrown, and the only solution I could think of is that the all that matters would be the 4 throws we don't know about, regardless of in which throw we got one of the numbers 1-6, and that the answer would be the already mentioned: $$P(A)= 1-\left(\frac56\right)^4$$ Now I'm having minor doubts about this approach, and don't have a solution to this problem, so I would really appreciate if someone could tell me if this way of thinking is right or wrong.","A fair dice was thrown 10 times, and it's been registered that all numbers 1-6 have appeared at least once. If this is true, what's the probability that at least 2 sixes have appeared? At first I thought I should calculate the amount of combinations of die throws that the 6 numbers that have definitely appeared as $\binom{10}{6}$, then dividing it by the amount of all possible outcomes, $6^{10}$, and then multiply it with the probability of throwing at least 1 six in the remaining 4 throws, since one has already been registered, $P(A)= 1-\left(\frac56\right)^4$. Then I began to have serious doubts, as $6^{10}$ is an insanely large number, and whether I'd even need the possible outcomes of the 6 numbers that were thrown, and the only solution I could think of is that the all that matters would be the 4 throws we don't know about, regardless of in which throw we got one of the numbers 1-6, and that the answer would be the already mentioned: $$P(A)= 1-\left(\frac56\right)^4$$ Now I'm having minor doubts about this approach, and don't have a solution to this problem, so I would really appreciate if someone could tell me if this way of thinking is right or wrong.",,"['probability', 'combinatorics', 'dice']"
59,Conditional probability given multiple independent events,Conditional probability given multiple independent events,,"I am interested in finding the conditional probability $P(A|E_1,E_2,...,E_n)$ where the $E_i$ are mutually independent events. I know only $P(A)$ and $P(A|E_i)$. Is this possible? If so, how? If not, what information is missing?","I am interested in finding the conditional probability $P(A|E_1,E_2,...,E_n)$ where the $E_i$ are mutually independent events. I know only $P(A)$ and $P(A|E_i)$. Is this possible? If so, how? If not, what information is missing?",,['probability']
60,Probability of a double-headed coin,Probability of a double-headed coin,,"Here are three related problems from Blitzstein and Hwang's Introduction to Probability . Curious if my approach is sound. I'm reasonably confident in the first result, but not so much in the other two, particularly the last one. 1:: A hat contains 100 coins, of which 99 are fair but one is double-headed. A coin is chosen uniformly at random. The chosen coin is flipped 7 times, and it lands heads on all 7. What is the probability that the chosen coin is double-headed? My answer With all of these, I'm using naive probability, in which the numerator is my desired outcome(s) and the denominator my possible outcomes given the result. In this case, my desired outcome is double-headed, and my possible outcomes are double-headed or not double-headed and seven straight heads. This gives me $$\frac{\frac{1}{100}*1}{\frac{1}{100}*1 + \frac{99}{100}*\frac{1}{128}} \approx .5639$$ 2:: A hat contains 100 coins, of which at least 99 are fair, but there may be one that is double-headed. (If there are no such coins, all 100 are fair.) There is a 1/2 chance that one of the coins is double-headed. A coin is chosen uniformly at random, is flipped 7 times, and lands heads each time. (a) What is the probability that one of the coins is double-headed? My answer My desired outcomes are there is a double-headed coin and this coin is double-headed or there is a double-headed coin and this coin is not double-headed and this coin comes up heads seven times. My possible outcomes are the two above, and also there is no double-headed coin and this coin has come up heads seven times. This gives me: $$\frac{\frac{1}{2}*\frac{1}{100}*1 + \frac{1}{2}*\frac{99}{100}*\frac{1}{128}}{\frac{1}{2}*\frac{1}{100}*1 + \frac{1}{2}*\frac{99}{100}*\frac{1}{128} + \frac{1}{2}*\frac{1}{128}} \approx .6942$$ (b) What is the probability that the chosen coin is double-headed? Similar to the above, but now $$\frac{\frac{1}{2}*\frac{1}{100}*1}{\frac{1}{2}*\frac{1}{100}*1 + \frac{1}{2}*\frac{99}{100}*\frac{1}{128} + \frac{1}{2}*\frac{1}{128}} \approx .3914$$ Addendum: I'm a dolt - there was no reason for me to be less confident in the last answer than in the second one. (I should be equally (un)confident in both.) If the probability of selecting the double-headed coin, when present, is ≈.5639, Answer(2b) is just ≈.5639 * Answer(2a).","Here are three related problems from Blitzstein and Hwang's Introduction to Probability . Curious if my approach is sound. I'm reasonably confident in the first result, but not so much in the other two, particularly the last one. 1:: A hat contains 100 coins, of which 99 are fair but one is double-headed. A coin is chosen uniformly at random. The chosen coin is flipped 7 times, and it lands heads on all 7. What is the probability that the chosen coin is double-headed? My answer With all of these, I'm using naive probability, in which the numerator is my desired outcome(s) and the denominator my possible outcomes given the result. In this case, my desired outcome is double-headed, and my possible outcomes are double-headed or not double-headed and seven straight heads. This gives me $$\frac{\frac{1}{100}*1}{\frac{1}{100}*1 + \frac{99}{100}*\frac{1}{128}} \approx .5639$$ 2:: A hat contains 100 coins, of which at least 99 are fair, but there may be one that is double-headed. (If there are no such coins, all 100 are fair.) There is a 1/2 chance that one of the coins is double-headed. A coin is chosen uniformly at random, is flipped 7 times, and lands heads each time. (a) What is the probability that one of the coins is double-headed? My answer My desired outcomes are there is a double-headed coin and this coin is double-headed or there is a double-headed coin and this coin is not double-headed and this coin comes up heads seven times. My possible outcomes are the two above, and also there is no double-headed coin and this coin has come up heads seven times. This gives me: $$\frac{\frac{1}{2}*\frac{1}{100}*1 + \frac{1}{2}*\frac{99}{100}*\frac{1}{128}}{\frac{1}{2}*\frac{1}{100}*1 + \frac{1}{2}*\frac{99}{100}*\frac{1}{128} + \frac{1}{2}*\frac{1}{128}} \approx .6942$$ (b) What is the probability that the chosen coin is double-headed? Similar to the above, but now $$\frac{\frac{1}{2}*\frac{1}{100}*1}{\frac{1}{2}*\frac{1}{100}*1 + \frac{1}{2}*\frac{99}{100}*\frac{1}{128} + \frac{1}{2}*\frac{1}{128}} \approx .3914$$ Addendum: I'm a dolt - there was no reason for me to be less confident in the last answer than in the second one. (I should be equally (un)confident in both.) If the probability of selecting the double-headed coin, when present, is ≈.5639, Answer(2b) is just ≈.5639 * Answer(2a).",,['probability']
61,"Extended Bayes' theorem: p(A | B, C, D) - Constructing a Bayesian Network","Extended Bayes' theorem: p(A | B, C, D) - Constructing a Bayesian Network",,"I'm having some difficulty understanding Bayes' theorem with multiple events. I'm trying to put together a Bayesian network.  I have four independent probabilities but I have found that A, B and C can affect the probability of D, so my question is: how do I write the formula for $p(D | B, C, A)$? As an example, suppose I was given: p(A) = 31.6% , p(B) = 71% , p(C) = 4.5% , and p(D) = 22% , how would I get $p(D|B,C,A)$?","I'm having some difficulty understanding Bayes' theorem with multiple events. I'm trying to put together a Bayesian network.  I have four independent probabilities but I have found that A, B and C can affect the probability of D, so my question is: how do I write the formula for $p(D | B, C, A)$? As an example, suppose I was given: p(A) = 31.6% , p(B) = 71% , p(C) = 4.5% , and p(D) = 22% , how would I get $p(D|B,C,A)$?",,"['probability', 'bayes-theorem', 'bayesian-network']"
62,Lindeberg's condition vs Lyapunov's condition,Lindeberg's condition vs Lyapunov's condition,,Can someone construct an example where Lindeberg's condition holds but Lyapunov's condition does not? This is a problem from Billingsley's/Chung's book.,Can someone construct an example where Lindeberg's condition holds but Lyapunov's condition does not? This is a problem from Billingsley's/Chung's book.,,['probability']
63,What is probability? [closed],What is probability? [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 years ago . Improve this question I tried to understand the most fundamental foundation of the mathematical definition of probability in the most natural/human way. (At first, I thought I may have found a proper understanding like this:) First, we need to abstract the events as set . And we assign some real number to the set by measuring these sets. We assign number because it is human nature to quantify things. Let's denote the measure as m . Then it is    also instinct/natural for human to   use the ratio of m(part for E) / m(total) to measure the probability of event E. In short, probability is nothing but the ratio of the measurement between part and total. With this sense, probability is only meaningful in a relative context . We can use arbitrary m as it fits. And the P(S) is always 1 since m(S)/m(S) is always 1. And also, it's easy to understand why we use division to define the conditional probability as below. P(A|B)=P(AB)/P(B), because it is actually this: $$ P(A\mid B) = \frac{m(AB)}{m(B)} = \frac{m(AB)/m(S)}{m(B)/m(S)} = \frac{P(AB)}{P(B)} $$ I really want to know if there's any flaw of this understanding. (But after having discussions here, I came to the following ADDs which is specific to the Mathematical Theory of Probability .) ADD 1 Is there any authoritative definition of what probability is ? I found almost all books define the probability based on the 3 famous axioms . But those axioms don't define what probability is. They merely say how probability should behave. ADD 2 On a second thought, I think I need to add some clarification. We must differentiate between mathematical probability and the interpretation of natural probability .  What I mentioned above is my attempt to explain the rational behind the mathematical probability . The natural probability is just a vague concept without precise quantification. In order to make it mathematically operational , we have to do some construction . And the above is what we have done. ADD 3 As I read the book "" Probability and Statistics "". It says: ...Almost all work in the mathematical theory of probability...has   been related to the following two problems: (i) methods for   determining the probabilities of certain events from the specified probabilities of each possible outcome of an experiment and (ii) methods for revising the probabilities of events when   additional relevant information is obtained. So, it occurs to me that ""mathematical theory of probability"" cannot provide us with the initial probabilities of all outcomes, these initial probabilities have to be specified in some other ways which may come from different interpretations of probability or practical choice or even subjective initiatives . They are represented as various p.d.f/p.f, some of which are quite obscure. What ""mathematical theory of probability"" can provide is just methods to calculate the probability of events of interest based on the foundation of those initial probabilities. So it is once again proved the ideology of mathematics that it doesn't care about what a mathematical object is . But cares about how to manipulate it. But, despite that the concept of probability is highly controversial and there're so many in-compatible operational interpretations for it, it is very interesting why all authorities agree on a single mathematical theory of probability as the method of mathematical manipulation . Are they out of options? Here 's another question about the justification of mathematical theory of probability.","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 years ago . Improve this question I tried to understand the most fundamental foundation of the mathematical definition of probability in the most natural/human way. (At first, I thought I may have found a proper understanding like this:) First, we need to abstract the events as set . And we assign some real number to the set by measuring these sets. We assign number because it is human nature to quantify things. Let's denote the measure as m . Then it is    also instinct/natural for human to   use the ratio of m(part for E) / m(total) to measure the probability of event E. In short, probability is nothing but the ratio of the measurement between part and total. With this sense, probability is only meaningful in a relative context . We can use arbitrary m as it fits. And the P(S) is always 1 since m(S)/m(S) is always 1. And also, it's easy to understand why we use division to define the conditional probability as below. P(A|B)=P(AB)/P(B), because it is actually this: $$ P(A\mid B) = \frac{m(AB)}{m(B)} = \frac{m(AB)/m(S)}{m(B)/m(S)} = \frac{P(AB)}{P(B)} $$ I really want to know if there's any flaw of this understanding. (But after having discussions here, I came to the following ADDs which is specific to the Mathematical Theory of Probability .) ADD 1 Is there any authoritative definition of what probability is ? I found almost all books define the probability based on the 3 famous axioms . But those axioms don't define what probability is. They merely say how probability should behave. ADD 2 On a second thought, I think I need to add some clarification. We must differentiate between mathematical probability and the interpretation of natural probability .  What I mentioned above is my attempt to explain the rational behind the mathematical probability . The natural probability is just a vague concept without precise quantification. In order to make it mathematically operational , we have to do some construction . And the above is what we have done. ADD 3 As I read the book "" Probability and Statistics "". It says: ...Almost all work in the mathematical theory of probability...has   been related to the following two problems: (i) methods for   determining the probabilities of certain events from the specified probabilities of each possible outcome of an experiment and (ii) methods for revising the probabilities of events when   additional relevant information is obtained. So, it occurs to me that ""mathematical theory of probability"" cannot provide us with the initial probabilities of all outcomes, these initial probabilities have to be specified in some other ways which may come from different interpretations of probability or practical choice or even subjective initiatives . They are represented as various p.d.f/p.f, some of which are quite obscure. What ""mathematical theory of probability"" can provide is just methods to calculate the probability of events of interest based on the foundation of those initial probabilities. So it is once again proved the ideology of mathematics that it doesn't care about what a mathematical object is . But cares about how to manipulate it. But, despite that the concept of probability is highly controversial and there're so many in-compatible operational interpretations for it, it is very interesting why all authorities agree on a single mathematical theory of probability as the method of mathematical manipulation . Are they out of options? Here 's another question about the justification of mathematical theory of probability.",,"['probability', 'probability-theory']"
64,"If the coefficients of the quadratic equation $ax^2+bx +c$ are u.i.i.d ran variates in $(0,1)$ what is the probability of roots being real? [duplicate]",If the coefficients of the quadratic equation  are u.i.i.d ran variates in  what is the probability of roots being real? [duplicate],"ax^2+bx +c (0,1)","This question already has answers here : Probability that a quadratic polynomial with random coefficients has real roots (6 answers) Closed 5 years ago . If the coefficients a,b,c(taken in order ,c being the constant term) of a quadratic equation are randomly and independenly chosen in the open interval(0,1) what is the probability that both the roots are real?","This question already has answers here : Probability that a quadratic polynomial with random coefficients has real roots (6 answers) Closed 5 years ago . If the coefficients a,b,c(taken in order ,c being the constant term) of a quadratic equation are randomly and independenly chosen in the open interval(0,1) what is the probability that both the roots are real?",,['probability']
65,"relative size of most factors of semiprimes, close?","relative size of most factors of semiprimes, close?",,"when chatting about RSA a cohort just asserted something like ""most prime factors of semiprimes are roughly the same size"" measured in bits. ie ""bits"" is the number of digits in the base2 representations of the two primes. am skeptical myself. in other words, eg if a program filters the semiprimes from $1..n$ and then looks at the size of factors, the assertion is most will be approximately equal. his ""proof"" sketch was brief/hazy and unconvincing. am skeptical. have a different picture of this. (think it might be closer to ""many"" ...) is this true? what is a proof sketch? is this connected to any number theory or area of study? if incorrect is there some other similar assertion that is correct?","when chatting about RSA a cohort just asserted something like ""most prime factors of semiprimes are roughly the same size"" measured in bits. ie ""bits"" is the number of digits in the base2 representations of the two primes. am skeptical myself. in other words, eg if a program filters the semiprimes from $1..n$ and then looks at the size of factors, the assertion is most will be approximately equal. his ""proof"" sketch was brief/hazy and unconvincing. am skeptical. have a different picture of this. (think it might be closer to ""many"" ...) is this true? what is a proof sketch? is this connected to any number theory or area of study? if incorrect is there some other similar assertion that is correct?",,"['probability', 'number-theory', 'statistics', 'prime-numbers', 'semiprimes']"
66,Find distribution when given Moment generating function,Find distribution when given Moment generating function,,"I am trying to find the distribution that corresponds to this moment-generating function. $$ M(t) =\frac{1}{3e^{-t}-2} , \quad t < \ln \frac 3 2 $$ I can not even consider where to start. Any push in the right direction would be appreciated!  Thanks:)","I am trying to find the distribution that corresponds to this moment-generating function. $$ M(t) =\frac{1}{3e^{-t}-2} , \quad t < \ln \frac 3 2 $$ I can not even consider where to start. Any push in the right direction would be appreciated!  Thanks:)",,['probability']
67,prove the way to generate geometrically distributed random numbers,prove the way to generate geometrically distributed random numbers,,"The way to generate geometrically distributed random numbers is the following $$\lfloor{\ln(u)/\ln(1-p)}\rfloor$$ where $u$ is uniformly distributed in $[0,1]$ and $p$ is the parameter in the geometric distribution. But can anybody help provide a rigorous proof? I only see that $\ln(u)/\ln(1-p)$ is exponentially distributed, but how to get the geometric distribution?","The way to generate geometrically distributed random numbers is the following $$\lfloor{\ln(u)/\ln(1-p)}\rfloor$$ where $u$ is uniformly distributed in $[0,1]$ and $p$ is the parameter in the geometric distribution. But can anybody help provide a rigorous proof? I only see that $\ln(u)/\ln(1-p)$ is exponentially distributed, but how to get the geometric distribution?",,['probability']
68,How to compute the expected distance to a nearest neighbor in an array of random vectors?,How to compute the expected distance to a nearest neighbor in an array of random vectors?,,"Let us have $k$ independent random vectors $x_1, x_2, \dots, x_k$ with uniform distribution over $ \left[0;1 \right]^n $. Then the distance (preferrably Manhattan) between an arbitrary vector $x_a$ and its nearest neighbor among these vectors is a well defined random variable. How can we estimate its momenta? Especially the expected value ? Since I have no idea how to start let us begin with the case of two vectors $a$ and $b$ in two dimensions: In this case one is the nearest neighbor to the other, so their distance is: $$ d \left(a, b\right) = \left | a_1 - b_1 \right | + \left | a_2 - b_2 \right |  $$  Where $a_1, a_2, b_1, b_2 \sim  U \left[0;1 \right]$ and are independent. In this case we can compute the expected value as a double integral: $$ I := \iint_{\left[0;1 \right]^2}^{} \left | x - y \right | + \left | x - y \right | dxdy $$ Since the integrand is symmetric along $x = y$: $$ I = 2 \iint_{\left[0;1 \right]^2}^{} \left | x - y \right | dxdy = 4 \int_{0}^{1} \left ( \int_{0}^{x} x - y  dy \right ) dx = 4 \int_{0}^{1} \frac{x^2}{2} dx = \frac{2}{3} $$ It would probably not be so hard to extend this result to $n$ dimensions. The real challenge is to add other vectors to the picture. If we have three vectors $a,b,c$, then both $b$ and $c$ have equal probability of being the closest individual to $a$. We can then compute the expected distance as the weighted sum of conditional expected values. $$ \frac{1}{2} E \left [ d \left( a, b \right) | b \text{ is closer}  \right] + \frac{1}{2} E \left [ d \left( a, c \right) | c \text{ is closer}  \right] $$ Both $E \left [ d \left( a, b \right) | b \text{ is closer}  \right]$ and $E \left [ d \left( a, c \right) | c \text{ is closer}  \right]$ could be computed as integrals in 6 dimensions somehow.","Let us have $k$ independent random vectors $x_1, x_2, \dots, x_k$ with uniform distribution over $ \left[0;1 \right]^n $. Then the distance (preferrably Manhattan) between an arbitrary vector $x_a$ and its nearest neighbor among these vectors is a well defined random variable. How can we estimate its momenta? Especially the expected value ? Since I have no idea how to start let us begin with the case of two vectors $a$ and $b$ in two dimensions: In this case one is the nearest neighbor to the other, so their distance is: $$ d \left(a, b\right) = \left | a_1 - b_1 \right | + \left | a_2 - b_2 \right |  $$  Where $a_1, a_2, b_1, b_2 \sim  U \left[0;1 \right]$ and are independent. In this case we can compute the expected value as a double integral: $$ I := \iint_{\left[0;1 \right]^2}^{} \left | x - y \right | + \left | x - y \right | dxdy $$ Since the integrand is symmetric along $x = y$: $$ I = 2 \iint_{\left[0;1 \right]^2}^{} \left | x - y \right | dxdy = 4 \int_{0}^{1} \left ( \int_{0}^{x} x - y  dy \right ) dx = 4 \int_{0}^{1} \frac{x^2}{2} dx = \frac{2}{3} $$ It would probably not be so hard to extend this result to $n$ dimensions. The real challenge is to add other vectors to the picture. If we have three vectors $a,b,c$, then both $b$ and $c$ have equal probability of being the closest individual to $a$. We can then compute the expected distance as the weighted sum of conditional expected values. $$ \frac{1}{2} E \left [ d \left( a, b \right) | b \text{ is closer}  \right] + \frac{1}{2} E \left [ d \left( a, c \right) | c \text{ is closer}  \right] $$ Both $E \left [ d \left( a, b \right) | b \text{ is closer}  \right]$ and $E \left [ d \left( a, c \right) | c \text{ is closer}  \right]$ could be computed as integrals in 6 dimensions somehow.",,"['probability', 'geometry']"
69,Convergence of binomial to normal,Convergence of binomial to normal,,"Problem: Let $X_n \sim \operatorname{Bin}(n,p_n) $ where $p_n \xrightarrow{} 0$ and $np_n \xrightarrow{} \infty$. What I need to show is that $$\frac{X_n - np_n}{\sqrt{np_n}} \xrightarrow{d} N(0,1) \text{ as } n\xrightarrow{} \infty.$$ My thoughts: My first thought was to set  $$Y_n=\frac{X_n - np_n}{\sqrt{np_n}}$$ and investigate $P(Y_n=k) = p_{X_n}(\sqrt{np_n}k + np_n) $ as $n$ goes to infinity, but this led to very messy calculations so I don't know if it is the right approach. My second attempt was with Central Limit Theorem, rewriting $X_n$ as a sum of Bernoulli random variables, $X_n = Z_1 + \dots + Z_n$, $Z_n \sim \operatorname{Be}(p_n)$. The expectation and variance of each $Z_i$ is dependent on $n$ in that case. Will that violate any assumptions in CLT? I prefer working out these kind of questions from definition rather than using a theorem and previous results, so if anyone can show me that I would be very grateful! Thanks.","Problem: Let $X_n \sim \operatorname{Bin}(n,p_n) $ where $p_n \xrightarrow{} 0$ and $np_n \xrightarrow{} \infty$. What I need to show is that $$\frac{X_n - np_n}{\sqrt{np_n}} \xrightarrow{d} N(0,1) \text{ as } n\xrightarrow{} \infty.$$ My thoughts: My first thought was to set  $$Y_n=\frac{X_n - np_n}{\sqrt{np_n}}$$ and investigate $P(Y_n=k) = p_{X_n}(\sqrt{np_n}k + np_n) $ as $n$ goes to infinity, but this led to very messy calculations so I don't know if it is the right approach. My second attempt was with Central Limit Theorem, rewriting $X_n$ as a sum of Bernoulli random variables, $X_n = Z_1 + \dots + Z_n$, $Z_n \sim \operatorname{Be}(p_n)$. The expectation and variance of each $Z_i$ is dependent on $n$ in that case. Will that violate any assumptions in CLT? I prefer working out these kind of questions from definition rather than using a theorem and previous results, so if anyone can show me that I would be very grateful! Thanks.",,"['probability', 'convergence-divergence', 'normal-distribution', 'weak-convergence', 'probability-limit-theorems']"
70,Bound on expectation of absolute value in terms of variance,Bound on expectation of absolute value in terms of variance,,"In my book it says that a white noise process $\{Z_t\}$ with mean zero and variance $\sigma^2$ has the following property: E$|Z_t| \leq \sigma$. This had me thinking of Jensen's inequality, that $\text{E}(g(X)) \geq g(\text{E}(X))$, for convex functions g. Since we have that $\text{E}(Z^2_t) = \sigma^2$ and $\text{E}(Z_t) = 0$, we could apply this inequality to to  $\text{E}(Z_t)$ and obtain $\text{E}(|Z_t|) \geq |\text{E}(Z_t)| = 0$, since the absolute value is a convex function.  But we need the upper bound, and the inequality is only for convex functions, so we can't use $\text{E}(Z^2_t) = \sigma^2$ and take square roots on both sides..","In my book it says that a white noise process $\{Z_t\}$ with mean zero and variance $\sigma^2$ has the following property: E$|Z_t| \leq \sigma$. This had me thinking of Jensen's inequality, that $\text{E}(g(X)) \geq g(\text{E}(X))$, for convex functions g. Since we have that $\text{E}(Z^2_t) = \sigma^2$ and $\text{E}(Z_t) = 0$, we could apply this inequality to to  $\text{E}(Z_t)$ and obtain $\text{E}(|Z_t|) \geq |\text{E}(Z_t)| = 0$, since the absolute value is a convex function.  But we need the upper bound, and the inequality is only for convex functions, so we can't use $\text{E}(Z^2_t) = \sigma^2$ and take square roots on both sides..",,"['probability', 'time-series']"
71,Randomly selecting a natural number,Randomly selecting a natural number,,"In the answer to these questions: Probability of picking a random natural number , Given two randomly chosen natural numbers, what is the probability that the second is greater than the first? it is stated that one cannot pick a natural number randomly. However, in this question: What is the probability of randomly selecting $ n $ natural numbers, all pairwise coprime? it is assumed that we can pick $n$ natural numbers randomly. A description is given in the last question as to how these numbers are randomly selected, to which there seems to be no objection (although the accepted answer is given by one of the people explaining that one cannot pick a random number in the first question). I know one can't pick a natural number randomly, so how come there doesn't seem to be a problem with randomly picking a number in the last question? NB: I am happy with some sort of measure-theoretic answer, hence the probability-theory tag, but I think for accessibility to other people a more basic description would be preferable.","In the answer to these questions: Probability of picking a random natural number , Given two randomly chosen natural numbers, what is the probability that the second is greater than the first? it is stated that one cannot pick a natural number randomly. However, in this question: What is the probability of randomly selecting $ n $ natural numbers, all pairwise coprime? it is assumed that we can pick $n$ natural numbers randomly. A description is given in the last question as to how these numbers are randomly selected, to which there seems to be no objection (although the accepted answer is given by one of the people explaining that one cannot pick a random number in the first question). I know one can't pick a natural number randomly, so how come there doesn't seem to be a problem with randomly picking a number in the last question? NB: I am happy with some sort of measure-theoretic answer, hence the probability-theory tag, but I think for accessibility to other people a more basic description would be preferable.",,"['probability', 'probability-theory']"
72,"Probability of a number appearing in another number , like 31 in 2315?","Probability of a number appearing in another number , like 31 in 2315?",,"How likely is it that a number of consisting of n digits, contains a number consisting of n digits or less? I though that perhaps I could multiply the number of permutations by the chance of such a permutation occuring (as displayed below), but some permutations allow for others to occur simultaneously. Doesn't that make my calculation invalid? Please note: I only want to calculate the chances of a number appearing at all, doesn't matter  if that is once, twice or more.","How likely is it that a number of consisting of n digits, contains a number consisting of n digits or less? I though that perhaps I could multiply the number of permutations by the chance of such a permutation occuring (as displayed below), but some permutations allow for others to occur simultaneously. Doesn't that make my calculation invalid? Please note: I only want to calculate the chances of a number appearing at all, doesn't matter  if that is once, twice or more.",,"['probability', 'combinatorics']"
73,"""Paradox"" of a Poisson process on $\mathbb R$","""Paradox"" of a Poisson process on",\mathbb R,"This question concerns the apparently peculiar behavior around zero of the Poisson process defined over the entire real line $\mathbb R$. A Poisson process $N(A)$ with mean measure $\mu$ on a general topological measure space $(\Omega, \mathcal B, \mathbb P)$ is defined such that for all $A \in \mathcal B$ satisfying $\mu(A) < \infty$, $$ \mathbb P(N(A) = n) = e^{-\mu(A)} \frac{(\mu(A))^n}{n!} $$ and for disjoint $A_1,\ldots,A_k$, the $N(A_i)$ are mutually independent. If $\Omega = [0,\infty)$ and $\mu$ is proportional to Lebesgue measure, then we can construct the process $N$ via a sequence $\{T_i\}$ of iid $\mathrm{Exp}(\lambda)$ random variables with $X_n = T_1 + \cdots + T_n$ and $N(t) = \#\{n: X_n \leq t\}$. If $\Omega = (-\infty,\infty)$, a simple modification of the above construction works. We take a second iid $\mathrm{Exp}(\lambda)$ sequence $\{U_i\}$ independent of the first and place points at $X_{-n} = -(U_1 + \cdots + U_n)$. It seems easy to see that this satisfies the general definition of a Poisson process. We only really need to worry if $A$ contains points on both sides of zero. So, if $A$ is any Borel set on $\mathbb R$, we decompose it as $A = (A \cap (-\infty,0)) \cup (A \cap [0,\infty))$ and then use the fact that the construction on each half-line was independent of one another and that sums of independent Poissons are Poisson. "" Paradox "": Every interarrival time is $\mathrm{Exp}(\lambda)$ independently of each other except for the interarrival time that straddles zero, namely $X_1 - X_{-1}$, which is still independent of all other interarrival times, but is $\Gamma(2,\lambda)$ since it is the sum of two independent $\mathrm{Exp}(\lambda)$ random variables. How do we explain away this peculiar behavior of the process around zero? (I realize this is not a proper paradox, which explains the quotation marks.)","This question concerns the apparently peculiar behavior around zero of the Poisson process defined over the entire real line $\mathbb R$. A Poisson process $N(A)$ with mean measure $\mu$ on a general topological measure space $(\Omega, \mathcal B, \mathbb P)$ is defined such that for all $A \in \mathcal B$ satisfying $\mu(A) < \infty$, $$ \mathbb P(N(A) = n) = e^{-\mu(A)} \frac{(\mu(A))^n}{n!} $$ and for disjoint $A_1,\ldots,A_k$, the $N(A_i)$ are mutually independent. If $\Omega = [0,\infty)$ and $\mu$ is proportional to Lebesgue measure, then we can construct the process $N$ via a sequence $\{T_i\}$ of iid $\mathrm{Exp}(\lambda)$ random variables with $X_n = T_1 + \cdots + T_n$ and $N(t) = \#\{n: X_n \leq t\}$. If $\Omega = (-\infty,\infty)$, a simple modification of the above construction works. We take a second iid $\mathrm{Exp}(\lambda)$ sequence $\{U_i\}$ independent of the first and place points at $X_{-n} = -(U_1 + \cdots + U_n)$. It seems easy to see that this satisfies the general definition of a Poisson process. We only really need to worry if $A$ contains points on both sides of zero. So, if $A$ is any Borel set on $\mathbb R$, we decompose it as $A = (A \cap (-\infty,0)) \cup (A \cap [0,\infty))$ and then use the fact that the construction on each half-line was independent of one another and that sums of independent Poissons are Poisson. "" Paradox "": Every interarrival time is $\mathrm{Exp}(\lambda)$ independently of each other except for the interarrival time that straddles zero, namely $X_1 - X_{-1}$, which is still independent of all other interarrival times, but is $\Gamma(2,\lambda)$ since it is the sum of two independent $\mathrm{Exp}(\lambda)$ random variables. How do we explain away this peculiar behavior of the process around zero? (I realize this is not a proper paradox, which explains the quotation marks.)",,"['probability', 'probability-theory', 'stochastic-processes']"
74,Simulation of Brownian Motion,Simulation of Brownian Motion,,If I want to simulate Brownian motion in the Euclidean space I can simulate it by a point that is moving a distance $\epsilon$ in an arbitrary direction then it randomly choose a new direction and moves a distance $\epsilon$ again and so on. The smaller the $\epsilon$ the closer the simulation will be to the real Brownian motion. How can I simulate Brownian motion in the hyperbolic space (Poincare Disk model for instance)? Does the same work here where I replace the Euclidean distance by the hyperbolic distance? My intuition is yes but when I did the simulation the random walk do not seem to be transient but it should be!,If I want to simulate Brownian motion in the Euclidean space I can simulate it by a point that is moving a distance $\epsilon$ in an arbitrary direction then it randomly choose a new direction and moves a distance $\epsilon$ again and so on. The smaller the $\epsilon$ the closer the simulation will be to the real Brownian motion. How can I simulate Brownian motion in the hyperbolic space (Poincare Disk model for instance)? Does the same work here where I replace the Euclidean distance by the hyperbolic distance? My intuition is yes but when I did the simulation the random walk do not seem to be transient but it should be!,,['probability']
75,Asymptotic behavior of the first step in a best strategy,Asymptotic behavior of the first step in a best strategy,,"Consider the game described here , but for a sequence $X_1,\ldots,X_n$ of i.i.d. uniform rv's on $\lbrace 1,\ldots,n \rbrace$ (in the original game $n=6$). Using the original notation, let $a_n$ denote the first element in the best strategy $a_n,\ldots,a_2$. We saw that for $n=6$, $a_n = n$. Can you provide a heuristic explanation as to why $a_n < n$ for all sufficiently large $n$ (this is indicated by numerical results), or even much better, can you determine the behavior of $n - a_n$ as $n \to \infty$? No rigorous proof is required, only heuristic ideas.","Consider the game described here , but for a sequence $X_1,\ldots,X_n$ of i.i.d. uniform rv's on $\lbrace 1,\ldots,n \rbrace$ (in the original game $n=6$). Using the original notation, let $a_n$ denote the first element in the best strategy $a_n,\ldots,a_2$. We saw that for $n=6$, $a_n = n$. Can you provide a heuristic explanation as to why $a_n < n$ for all sufficiently large $n$ (this is indicated by numerical results), or even much better, can you determine the behavior of $n - a_n$ as $n \to \infty$? No rigorous proof is required, only heuristic ideas.",,"['probability', 'sequences-and-series', 'asymptotics']"
76,A probability involving side lengths of a random triangle on a disk: Is it really $\frac37$?,A probability involving side lengths of a random triangle on a disk: Is it really ?,\frac37,"Choose three uniformly random points on a disk, and let them be the vertices of a triangle. Call the side lengths, in random order, $a,b,c$ . What is $P(a^2<bc)$ ? A simulation with $10^7$ such random triangles yielded a proportion of $0.4285833\approx1.00003\times\frac{3}{7}$ satisfying $a^2<bc$ , leading me to believe that the probability is $\frac37$ . I find this alleged probability interesting because it seems that the number $7$ rarely appears in the answers to natural geometry or probability questions. Context Recently I have learned that some probabilities related to circles, of the form $P(x^2<yz)$ , have simple rational values (for example, a probability about a random triangle inscribed in a circle, and a probability about a random pentagram inscribed in a circle). So I wondered if there is a probability like this related to a disk. I may have found one. My attempt Let the boundary of the disk be $x^2+y^2=1$ . Using disk point picking , let the three points be $C\left(\sqrt{r_1}\cos\theta_1,\sqrt{r_1}\sin\theta_1\right)$ $B\left(\sqrt{r_2}\cos\theta_2,\sqrt{r_2}\sin\theta_2\right)$ $A\left(\sqrt{r_3},0\right)$ where each $r$ is a uniformly random real number from $0$ to $1$ , and each $\theta$ is a uniformly random real number from $0$ to $2\pi$ . Let $a=BC$ , $b=AC$ , $c=AB$ . This gives: $$P(a^2<bc)=P\left(r_1+r_2-2\sqrt{r_1r_2}\cos(\theta_1-\theta_2)<\sqrt{\left(r_1-2\sqrt{r_1r_3}\cos\theta_1+r_3\right)\left(r_2-2\sqrt{r_2r_3}\cos\theta_2+r_3\right)}\right)$$ I do not know how to set up an integral, nor any other way to calculate the probability. Apparently, after the dust settles, we should be left with $\frac37$ .","Choose three uniformly random points on a disk, and let them be the vertices of a triangle. Call the side lengths, in random order, . What is ? A simulation with such random triangles yielded a proportion of satisfying , leading me to believe that the probability is . I find this alleged probability interesting because it seems that the number rarely appears in the answers to natural geometry or probability questions. Context Recently I have learned that some probabilities related to circles, of the form , have simple rational values (for example, a probability about a random triangle inscribed in a circle, and a probability about a random pentagram inscribed in a circle). So I wondered if there is a probability like this related to a disk. I may have found one. My attempt Let the boundary of the disk be . Using disk point picking , let the three points be where each is a uniformly random real number from to , and each is a uniformly random real number from to . Let , , . This gives: I do not know how to set up an integral, nor any other way to calculate the probability. Apparently, after the dust settles, we should be left with .","a,b,c P(a^2<bc) 10^7 0.4285833\approx1.00003\times\frac{3}{7} a^2<bc \frac37 7 P(x^2<yz) x^2+y^2=1 C\left(\sqrt{r_1}\cos\theta_1,\sqrt{r_1}\sin\theta_1\right) B\left(\sqrt{r_2}\cos\theta_2,\sqrt{r_2}\sin\theta_2\right) A\left(\sqrt{r_3},0\right) r 0 1 \theta 0 2\pi a=BC b=AC c=AB P(a^2<bc)=P\left(r_1+r_2-2\sqrt{r_1r_2}\cos(\theta_1-\theta_2)<\sqrt{\left(r_1-2\sqrt{r_1r_3}\cos\theta_1+r_3\right)\left(r_2-2\sqrt{r_2r_3}\cos\theta_2+r_3\right)}\right) \frac37","['probability', 'integration', 'geometry', 'conjectures', 'geometric-probability']"
77,Probability of each type of inscribed octahedron,Probability of each type of inscribed octahedron,,"Fix a $V\in\mathbb{N}$ with $V\ge 4$ . Randomly pick $V$ points on a sphere (independently and uniformly with respect to the surface area measure). You may think of the convex hull of these $V$ points. With probability 1, this constitutes a nondegenerate convex polyhedron. In fact, all faces would be triangles (probability 1)(*), so this should be a $(2V-4)$ -hedron (from Euler's $F-E+V=2$ when $3F=2E$ ). But what is the probability for each topological type? I think(**) the first ""interesting"" case is for $V=6$ random points on the sphere, so random octahedra, so let me ask about that. What is the probability that 6 randomly chosen points on a sphere span an octahedron which is topologically like a regular octahedron (so all 6 vertices have same vertex order). Both an exact answer and an approximate value from simulating the random process would be interesting. Notes: (*) I learn that a polyhedron all of whose faces are triangles can be called a simplicial polyhedron . (**) A bit more research leads to the beautiful table Counting Polyhedra which confirms that out of the 257 distinct octahedra, there are 2 distinct ones with $V=6$ . One is the regular octahedron. The other one seems to be called the biaugmented tetrahedron or bicapped tetrahedron although I am not sure if it has other names.","Fix a with . Randomly pick points on a sphere (independently and uniformly with respect to the surface area measure). You may think of the convex hull of these points. With probability 1, this constitutes a nondegenerate convex polyhedron. In fact, all faces would be triangles (probability 1)(*), so this should be a -hedron (from Euler's when ). But what is the probability for each topological type? I think(**) the first ""interesting"" case is for random points on the sphere, so random octahedra, so let me ask about that. What is the probability that 6 randomly chosen points on a sphere span an octahedron which is topologically like a regular octahedron (so all 6 vertices have same vertex order). Both an exact answer and an approximate value from simulating the random process would be interesting. Notes: (*) I learn that a polyhedron all of whose faces are triangles can be called a simplicial polyhedron . (**) A bit more research leads to the beautiful table Counting Polyhedra which confirms that out of the 257 distinct octahedra, there are 2 distinct ones with . One is the regular octahedron. The other one seems to be called the biaugmented tetrahedron or bicapped tetrahedron although I am not sure if it has other names.",V\in\mathbb{N} V\ge 4 V V (2V-4) F-E+V=2 3F=2E V=6 V=6,"['probability', 'polyhedra', 'solid-geometry', 'geometric-probability']"
78,Expected number of tosses under a moving-window-based stopping condition,Expected number of tosses under a moving-window-based stopping condition,,"Given two integers $N \geq M \gt 0$ and $0<p<1$ . Suppose I keep tossing a coin with a head probability $p$ until I get $M$ heads in the most recent $N$ tosses. What is the expected number of tosses? The game is stopped immediately if $M$ heads are reached before $N$ tosses are attempted. The question is not from my class or exercise; It just appears in various occasions in my everyday life that pique my curiosity. An example is the ""mastery"" in Minesweeper online , which is defined to be the number of wins out of consecutive 100 games. In the case of a global quest, players are asked to reach certain mastery from scratch, e.g., to win 70 out of 100 consecutive intermediate games. A skilled player with a winning probability of 0.8 is likely to finish the quest in less than 100 games, while a newbie with a winning probability of 0.6 is likely to make hundreds or thousands of attempts to complete the quest. Some players would like to estimate the expected number of games they need to play, hence it comes the above question. Intuitively, when $M\ll pN$ , the expected number of games should be very close to $M/p$ . As $M$ approaches or exceeds $pN$ , the expected number of games grows very quickly. So far I haven't find a way to solve the question for a general $M$ . But the question does reduce to some well-known problems for some specific $M$ . Let $E(M, N)$ denote the expectation: first head $$ E(1,N) = \frac{1}{p}$$ first N-consecutive heads $$E(N, N) = \frac{p^{-N}-1}{1-p}$$ $M=2$ seems to be another case where a relation can be built without too much effort. Let $X_{M,N}$ denote the number of tosses to stop the game and $Y$ denote the number of tosses to reach the first head, then $$E(2,N) = \sum_{y} E(X_{2,N}|Y=y) P(Y=y)$$ The conditional probability can be calculated by considering the next $N-1$ tosses. Let $q=1-p$ , \begin{align} E(X_{2,N}|Y=y) &= p\sum_{k=0}^{N-2} q^k (y+k+1) + q^{N-1} [y+N-1+E(2,N)] \\  & = y + \frac{1-q^{N-1}}{p} + q^{N-1}E(2,N) \end{align} which yields $$ E(2,N) = \frac{2-q^{N-1}}{p(1-q^{N-1})} $$ But I don't think the above approach for $M=2$ can be generalized to $M\geq 3$ . $M=N-1$ is another case where we only need to consider a state with $N$ possibilities, instead of $2^N$ . Let $Z_{r}^{N}$ denote the rest number of tosses to finish the game of $M=N-1$ with a most recent history of tail-( $r$ consecutive heads)-tail: $$ T\underbrace{H...H}_{r}T | (Z_{r}^N ~ \text{tosses to finish}) $$ We have $$ E(Z_{r}^{N}) = p^{N-r-1}(N-r-1) + q\sum_{k=0}^{N-r-2}p^k\left[k+1+E(Z_{k}^{N})\right] $$ Note that $E(Z_{0}^{N})=E(N-1, N)$ is the quantity we are looking for. Unfortunately I haven't found an explicit expression, though it's just  a system of $N-1$ linear equations: $$ (I - qA) \pmb{E} = \pmb{b}  $$ where, for $i,j=0,\ldots,N-2$ , $$ A_{ij} = \left\{\begin{matrix} p^j & i+j\leq N-2 \\ 0 & i+j\gt N-2 \end{matrix} \right. $$ and $$b_i = \frac{1-p^{N-1-i}}{q} $$ With the help of sympy I got the following results for $p=2/3$ : \begin{align} E(2,3) &= 51/16 & \approx 3.19 \\ E(3,4) &= 1551/296 & \approx 5.24\\ E(4,5) &= 156615/19936 & \approx 7.86\\ E(5,6) &= 38234649/3388448 & \approx 11.28 \\ E(6,7) &= 31121052081/1963106560 & \approx 15.85 \end{align} As pointed out by @VarunVejalla, a small reduction from $2^N$ can be achieved by considering where the heads are in the sequence of the last $N$ flips. This can be done by generalizing the method for $M=N-1$ . Let $Z_{r_1 \ldots r_{N-M}}^{N}$ denote the rest number of tosses to stop the game with a most recent history of $r_i$ consecutive heads separated apart by a tail each, i.e., $$ T\underbrace{H...H}_{r_1}T\underbrace{H...H}_{r_2}T\ldots T \underbrace{H...H}_{r_{N-M}}T | (Z_{r_1\ldots r_{N-M}}^{N} ~ \text{tosses to finish}) $$ where $0\leq r_i\leq M-1$ and $\sum_{i=1}^{N-M}r_i\leq M-1$ . We have $$E(Z_{r_1\ldots r_{N-M}}^{N}) - q\sum_{k=0}^{M-1-\sum r_i} p^k E(Z_{r_2\ldots r_{N-M}k}^{N}) = \frac{1-p^{M-\sum r_i}}{q} $$ The above system of linear equations works for any $M<N$ , but its size equals the number of non-negative integer solutions to $\sum_{i=1}^{N-M}r_i\leq M-1$ , which roughly scales as $O(N^{\textrm{min}(M, N-M)})$ . Does anyone have any thoughts on its closed-form solution (if it exists)?","Given two integers and . Suppose I keep tossing a coin with a head probability until I get heads in the most recent tosses. What is the expected number of tosses? The game is stopped immediately if heads are reached before tosses are attempted. The question is not from my class or exercise; It just appears in various occasions in my everyday life that pique my curiosity. An example is the ""mastery"" in Minesweeper online , which is defined to be the number of wins out of consecutive 100 games. In the case of a global quest, players are asked to reach certain mastery from scratch, e.g., to win 70 out of 100 consecutive intermediate games. A skilled player with a winning probability of 0.8 is likely to finish the quest in less than 100 games, while a newbie with a winning probability of 0.6 is likely to make hundreds or thousands of attempts to complete the quest. Some players would like to estimate the expected number of games they need to play, hence it comes the above question. Intuitively, when , the expected number of games should be very close to . As approaches or exceeds , the expected number of games grows very quickly. So far I haven't find a way to solve the question for a general . But the question does reduce to some well-known problems for some specific . Let denote the expectation: first head first N-consecutive heads seems to be another case where a relation can be built without too much effort. Let denote the number of tosses to stop the game and denote the number of tosses to reach the first head, then The conditional probability can be calculated by considering the next tosses. Let , which yields But I don't think the above approach for can be generalized to . is another case where we only need to consider a state with possibilities, instead of . Let denote the rest number of tosses to finish the game of with a most recent history of tail-( consecutive heads)-tail: We have Note that is the quantity we are looking for. Unfortunately I haven't found an explicit expression, though it's just  a system of linear equations: where, for , and With the help of sympy I got the following results for : As pointed out by @VarunVejalla, a small reduction from can be achieved by considering where the heads are in the sequence of the last flips. This can be done by generalizing the method for . Let denote the rest number of tosses to stop the game with a most recent history of consecutive heads separated apart by a tail each, i.e., where and . We have The above system of linear equations works for any , but its size equals the number of non-negative integer solutions to , which roughly scales as . Does anyone have any thoughts on its closed-form solution (if it exists)?","N \geq M \gt 0 0<p<1 p M N M N M\ll pN M/p M pN M M E(M, N)  E(1,N) = \frac{1}{p} E(N, N) = \frac{p^{-N}-1}{1-p} M=2 X_{M,N} Y E(2,N) = \sum_{y} E(X_{2,N}|Y=y) P(Y=y) N-1 q=1-p \begin{align}
E(X_{2,N}|Y=y) &= p\sum_{k=0}^{N-2} q^k (y+k+1) + q^{N-1} [y+N-1+E(2,N)] \\ 
& = y + \frac{1-q^{N-1}}{p} + q^{N-1}E(2,N)
\end{align}  E(2,N) = \frac{2-q^{N-1}}{p(1-q^{N-1})}  M=2 M\geq 3 M=N-1 N 2^N Z_{r}^{N} M=N-1 r  T\underbrace{H...H}_{r}T | (Z_{r}^N ~ \text{tosses to finish})   E(Z_{r}^{N}) = p^{N-r-1}(N-r-1) + q\sum_{k=0}^{N-r-2}p^k\left[k+1+E(Z_{k}^{N})\right]  E(Z_{0}^{N})=E(N-1, N) N-1  (I - qA) \pmb{E} = \pmb{b}   i,j=0,\ldots,N-2  A_{ij} = \left\{\begin{matrix}
p^j & i+j\leq N-2 \\
0 & i+j\gt N-2
\end{matrix} \right.
 b_i = \frac{1-p^{N-1-i}}{q}  p=2/3 \begin{align}
E(2,3) &= 51/16 & \approx 3.19 \\
E(3,4) &= 1551/296 & \approx 5.24\\
E(4,5) &= 156615/19936 & \approx 7.86\\
E(5,6) &= 38234649/3388448 & \approx 11.28 \\
E(6,7) &= 31121052081/1963106560 & \approx 15.85
\end{align} 2^N N M=N-1 Z_{r_1 \ldots r_{N-M}}^{N} r_i  T\underbrace{H...H}_{r_1}T\underbrace{H...H}_{r_2}T\ldots T \underbrace{H...H}_{r_{N-M}}T | (Z_{r_1\ldots r_{N-M}}^{N} ~ \text{tosses to finish})  0\leq r_i\leq M-1 \sum_{i=1}^{N-M}r_i\leq M-1 E(Z_{r_1\ldots r_{N-M}}^{N}) - q\sum_{k=0}^{M-1-\sum r_i} p^k E(Z_{r_2\ldots r_{N-M}k}^{N}) = \frac{1-p^{M-\sum r_i}}{q}  M<N \sum_{i=1}^{N-M}r_i\leq M-1 O(N^{\textrm{min}(M, N-M)})","['probability', 'probability-distributions']"
79,Using Mantel's theorem to prove a probabilistic inequality,Using Mantel's theorem to prove a probabilistic inequality,,"I'm self-learning Yufei Zhao's ""Graph Theorey and Additive Combinatorics"" , one problem I encounter is the following: The next exercise can be solved by a neat application of Mantel's theorem. Exercise 1.1.10. Let $X$ and $Y$ be independent and identically distributed random vectors in $\mathbb{R}^{d}$ according to some arbitrary probability distribution. Prove that $$ \mathbb{P}(|X+Y| \geq 1) \geq \frac{1}{2} \mathbb{P}(|X| \geq 1)^{2} . $$ Mantel's theorem . Every $n$ -vertex triangle-free graph has at most $\left\lfloor n^{2} / 4\right\rfloor$ edges. AKA $$ \operatorname{ex}(n, H)=\left\lfloor\frac{n^{2}}{4}\right\rfloor \text {. } $$ I have no clue how this inequality of integral is connected with graph theorey, please at least give me a hint. Proof not using Mantel's theorem is also welcome.","I'm self-learning Yufei Zhao's ""Graph Theorey and Additive Combinatorics"" , one problem I encounter is the following: The next exercise can be solved by a neat application of Mantel's theorem. Exercise 1.1.10. Let and be independent and identically distributed random vectors in according to some arbitrary probability distribution. Prove that Mantel's theorem . Every -vertex triangle-free graph has at most edges. AKA I have no clue how this inequality of integral is connected with graph theorey, please at least give me a hint. Proof not using Mantel's theorem is also welcome.","X Y \mathbb{R}^{d} 
\mathbb{P}(|X+Y| \geq 1) \geq \frac{1}{2} \mathbb{P}(|X| \geq 1)^{2} .
 n \left\lfloor n^{2} / 4\right\rfloor 
\operatorname{ex}(n, H)=\left\lfloor\frac{n^{2}}{4}\right\rfloor \text {. }
","['probability', 'geometry', 'graph-theory', 'integral-inequality', 'extremal-graph-theory']"
80,Chance letter a next to b in circle with whole alphabet such that no vowels next to each other,Chance letter a next to b in circle with whole alphabet such that no vowels next to each other,,"Here's a question from a book on probability I'm working through: If the $26$ letters of the alphabet are written down in a ring so that no two vowels come together, what is the chance that a is next to b ? Here's what I did. Let's fix a . Since b can be immediately to the left or right of a , there's $2$ choices for b . Without loss of generality let's say we have ab , and so we have $4$ vowels remaining and $20$ consonants remaining. With the condition that no $2$ vowels come together: We want to find the number of possible places where we can place a vowel, which is in between consonants. With the $20$ consonants, there's $19$ possible ""gaps"" between, plus the $2$ on the end, for a total of $21$ . However, because our b already occupies one of them, we have to subtract $1$ , getting us $20$ . So out of these $20$ places we're choosing $4$ , so there's $\binom{20}{4}$ ways to place our $4$ vowels among the $20$ consonants subject to the condition no $2$ vowels come together. There's $4!$ ways to order the remaining vowels and $20!$ ways to order the remaining consonants. So our numerator is $${{2 \binom{20}{4} 20!4!}}$$ Now let's calculate the denominator. Fix a again. This time we have $21$ consonants and $4$ vowels remaining, but only the $20$ possible ""gaps"" between the consonants to places our $4$ vowels (there's no $2$ at the end this time around), so our numerator is $$\binom{20}{4}21!4!$$ Therefore the chance that a is next to b is $${2\over{21}}$$ However, the answer in the back of my book (which is known to be wrong in many places in the answers in the back section) is ${1\over{10}}$ . So who's correct? And if I'm wrong, where did I specifically go wrong?","Here's a question from a book on probability I'm working through: If the letters of the alphabet are written down in a ring so that no two vowels come together, what is the chance that a is next to b ? Here's what I did. Let's fix a . Since b can be immediately to the left or right of a , there's choices for b . Without loss of generality let's say we have ab , and so we have vowels remaining and consonants remaining. With the condition that no vowels come together: We want to find the number of possible places where we can place a vowel, which is in between consonants. With the consonants, there's possible ""gaps"" between, plus the on the end, for a total of . However, because our b already occupies one of them, we have to subtract , getting us . So out of these places we're choosing , so there's ways to place our vowels among the consonants subject to the condition no vowels come together. There's ways to order the remaining vowels and ways to order the remaining consonants. So our numerator is Now let's calculate the denominator. Fix a again. This time we have consonants and vowels remaining, but only the possible ""gaps"" between the consonants to places our vowels (there's no at the end this time around), so our numerator is Therefore the chance that a is next to b is However, the answer in the back of my book (which is known to be wrong in many places in the answers in the back section) is . So who's correct? And if I'm wrong, where did I specifically go wrong?",26 2 4 20 2 20 19 2 21 1 20 20 4 \binom{20}{4} 4 20 2 4! 20! {{2 \binom{20}{4} 20!4!}} 21 4 20 4 2 \binom{20}{4}21!4! {2\over{21}} {1\over{10}},"['probability', 'combinatorics', 'combinatorics-on-words']"
81,The expectation of $e^X \left(1-(1-e^{-X}\right)^n)$ when $X$ has Exponential Distribution,The expectation of  when  has Exponential Distribution,e^X \left(1-(1-e^{-X}\right)^n) X,"To my surprise, I was able to evaluate the following expression in Mathematica: $$E\left[e^X \left(1-(1-e^{-X}\right)^n) \right] = \frac{y}{y-1} \left(1-\frac{1}{\binom{n+y-1}{y-1}}\right)\quad X\sim\text{Exp}(y)$$ with the right hand side being equal to $\text{HarmonicNumber}(n)$ in the particular case $y=1$ , and equal to $n$ when $y=0$ . If we define $\binom{n}{k} = \frac{\Gamma(n+1)}{\Gamma(n-k+1)\Gamma(k+1)}$ the results seems to hold for all $x,y\in\mathbb R$ , though I mostly care about $n$ and $y$ as positive integers. I have no idea how to prove this by hand. I tried a series expansion of the exponentials without realizing much. I also tried rewriting in terms of the uniform distribution, since $e^{-X}$ has the same distribution as $U^{1/y}$ for $U\sim\text{Uniform}(0,1)$ . Are there any tricks or properties I'm missing?","To my surprise, I was able to evaluate the following expression in Mathematica: with the right hand side being equal to in the particular case , and equal to when . If we define the results seems to hold for all , though I mostly care about and as positive integers. I have no idea how to prove this by hand. I tried a series expansion of the exponentials without realizing much. I also tried rewriting in terms of the uniform distribution, since has the same distribution as for . Are there any tricks or properties I'm missing?","E\left[e^X \left(1-(1-e^{-X}\right)^n) \right] = \frac{y}{y-1} \left(1-\frac{1}{\binom{n+y-1}{y-1}}\right)\quad X\sim\text{Exp}(y) \text{HarmonicNumber}(n) y=1 n y=0 \binom{n}{k} = \frac{\Gamma(n+1)}{\Gamma(n-k+1)\Gamma(k+1)} x,y\in\mathbb R n y e^{-X} U^{1/y} U\sim\text{Uniform}(0,1)","['probability', 'expected-value', 'uniform-distribution', 'exponential-distribution', 'harmonic-numbers']"
82,Expected time until random walk on hexagonal grid exceeds distance N from start,Expected time until random walk on hexagonal grid exceeds distance N from start,,"A particle starts in a cell in an infinite hexagonal grid, and every second, jumps to an adjacent cell uniformly randomly. What is the expected amount of time until the particle is $N$ cell-jumps away from its starting point? With some linear algebra, for example, one finds values of $1$ , then $10/3$ , then $213/29$ , for cases $N=1,2,3$ respectively. Computer simulation shows growth is approximately $4N^2/5$ . I expected to be able to solve this problem with similar methods (using polynomials in barycentric coordinates, constrained by dihedral symmetries) as to my recent Puzzling question , but to no avail so far. Curiously, by a coupling argument, this problem is equivalent to computing the expected value of the variable $\text{min}\{X_1,X_2\}$ where $X_i$ are iid variables representing the escape time of the honeybee from the center of its triangle in the linked problem, but that observation doesn't seem to help much. Some rambling about my current attempts: In barycentric coordinates $(\alpha, \beta, \gamma)$ whereby we always have $\alpha + \beta + \gamma = 3N$ , it would seem reasonable to demand that—in order to find the average escape time at $(\alpha, \beta, \gamma)$ from the $N-1$ -hexagon centered at $(N,N,N)$ —we find a function $H(\alpha, \beta, \gamma)$ algebraically satisfying the ""average-of-6-neighbors-plus-1"" property everywhere, which also satisfies $H = 0$ whenever $\alpha = 0, 2N$ or $\beta = 0, 2N$ or $\gamma = 0, 2N$ . After all, this approach is exactly how the triangular escape time problem is solved, just leaving out the $2N$ constraints. In that case, we think of the elementary symmetric polynomials in $\alpha, \beta, \gamma$ , and realize $\alpha\beta\gamma$ is a good candidate. It doesn't quite satisfy the averaging-plus-one law—its difference from its nearby-average function is $3N$ and not $1$ —so we tweak it to $\frac{3\alpha\beta\gamma}{\alpha+\beta+\gamma}$ to solve the problem. So that is how I proceeded here, examining the obvious candidate $H=\alpha \beta \gamma (\alpha-2\beta-2\gamma)(\beta-2\alpha-2\gamma)(\gamma-2\alpha-2\beta)$ . But its difference from its nearby-average function is gnarly, and not susceptible to obvious tweaks. With some thought, one realizes the field of rational functions invariant up to angular and mirror symmetry are generated by $H$ as well as $e_1 = \alpha+\beta+\gamma$ and $e_2 = \alpha \beta + \alpha \gamma + \beta\gamma$ . Especially considering the empirical evidence that our formula will be of degree $2$ , one might try candidate tweaks like $\frac{H}{e_1^4}$ or $\frac{H}{e_1^2 e_2}$ or $\frac{H}{e_2^2}$ or $\frac{H^2}{e_1^4 e_2^3}$ ... but some time spent in Mathematica proved fruitless. It's become clear to me now that no rational function of the form $\frac{F}{e_1^n e_2^m}$ will satisfy the criteria of the first paragraph , because such a function will still be defined on and inside the full triangular region, thus restricting to a solution of the honeybee escape time problem. By standard Markov chain reasoning, this solution is unique, and obviously not the solution to the problem at hand. So, either an even more complicated denominator is needed (one giving poles outside the hexagon but inside the triangle), or we need to allow possibilities like $H \neq 0$ even if $\alpha = 0$ as long as we're outside the hexagonal boundary, or we need some even more radical change to our techniques.","A particle starts in a cell in an infinite hexagonal grid, and every second, jumps to an adjacent cell uniformly randomly. What is the expected amount of time until the particle is cell-jumps away from its starting point? With some linear algebra, for example, one finds values of , then , then , for cases respectively. Computer simulation shows growth is approximately . I expected to be able to solve this problem with similar methods (using polynomials in barycentric coordinates, constrained by dihedral symmetries) as to my recent Puzzling question , but to no avail so far. Curiously, by a coupling argument, this problem is equivalent to computing the expected value of the variable where are iid variables representing the escape time of the honeybee from the center of its triangle in the linked problem, but that observation doesn't seem to help much. Some rambling about my current attempts: In barycentric coordinates whereby we always have , it would seem reasonable to demand that—in order to find the average escape time at from the -hexagon centered at —we find a function algebraically satisfying the ""average-of-6-neighbors-plus-1"" property everywhere, which also satisfies whenever or or . After all, this approach is exactly how the triangular escape time problem is solved, just leaving out the constraints. In that case, we think of the elementary symmetric polynomials in , and realize is a good candidate. It doesn't quite satisfy the averaging-plus-one law—its difference from its nearby-average function is and not —so we tweak it to to solve the problem. So that is how I proceeded here, examining the obvious candidate . But its difference from its nearby-average function is gnarly, and not susceptible to obvious tweaks. With some thought, one realizes the field of rational functions invariant up to angular and mirror symmetry are generated by as well as and . Especially considering the empirical evidence that our formula will be of degree , one might try candidate tweaks like or or or ... but some time spent in Mathematica proved fruitless. It's become clear to me now that no rational function of the form will satisfy the criteria of the first paragraph , because such a function will still be defined on and inside the full triangular region, thus restricting to a solution of the honeybee escape time problem. By standard Markov chain reasoning, this solution is unique, and obviously not the solution to the problem at hand. So, either an even more complicated denominator is needed (one giving poles outside the hexagon but inside the triangle), or we need to allow possibilities like even if as long as we're outside the hexagonal boundary, or we need some even more radical change to our techniques.","N 1 10/3 213/29 N=1,2,3 4N^2/5 \text{min}\{X_1,X_2\} X_i (\alpha, \beta, \gamma) \alpha + \beta + \gamma = 3N (\alpha, \beta, \gamma) N-1 (N,N,N) H(\alpha, \beta, \gamma) H = 0 \alpha = 0, 2N \beta = 0, 2N \gamma = 0, 2N 2N \alpha, \beta, \gamma \alpha\beta\gamma 3N 1 \frac{3\alpha\beta\gamma}{\alpha+\beta+\gamma} H=\alpha \beta \gamma (\alpha-2\beta-2\gamma)(\beta-2\alpha-2\gamma)(\gamma-2\alpha-2\beta) H e_1 = \alpha+\beta+\gamma e_2 = \alpha \beta + \alpha \gamma + \beta\gamma 2 \frac{H}{e_1^4} \frac{H}{e_1^2 e_2} \frac{H}{e_2^2} \frac{H^2}{e_1^4 e_2^3} \frac{F}{e_1^n e_2^m} H \neq 0 \alpha = 0","['probability', 'statistics', 'markov-chains', 'random-walk']"
83,when is a longer series BAD for the better team?,when is a longer series BAD for the better team?,,"This question is inspired by: A longer series is better for a better team: Can you see this at a glance? Also obviously inspired by the NBA playoffs happening right now.  :) Suppose two teams are playing a series of $2k-1$ games, and the first team to win $k$ games wins the overall series.  (No game can end in a tie.)  Moreover, team A is ""better"" than team B. Let $A_i$ denote the event that team A wins game $i$. Let $A_{series}$ denote the event that team A wins the series, i.e., A wins $k$ or more games. If the game results are i.i.d., and $P(A_i) = p > 1/2$ for any game $i$, then a longer series (larger $k$) increases A's chance of winning the series, i.e. $P(A_{series})$ is an increasing function in $k$.  This is intuitively obvious, and a proof can be found in the link above (although that post asks an excellent question re: why such an ""obvious"" result requires an algebraically convoluted proof). I wanna know under what conditions, i.e. under what probability model, would a longer match be BAD for the better team A.  Perhaps some dependence that encodes ""reversion to the mean"" and/or (opposite of) ""momentum""? What I tried My $0$-th attempt: If we allow ""fatigue"" in the form of decreasing $P(A_i),$ then a longer series can be bad for A, even when all $P(A_i) > 1/2.$  A simple 3-game example: if $P(A_1) = 1, P(A_2) = P(A_3) = 0.51$, then A always wins in a 1-game ""series"" ($k=1$) but B has a chance ($0.49^2$) in a 3-game series ($k=2$).  @Henry in his answer gave an infinite length example. So I'm looking for something where the marginal probabilities $P(A_i)$ are constant (i.e. no fatigue). My 1st attempt: let $P(A_1) = p > 1/2$, and thereafter every game $i$ result = game 1 result.  This means: (1) $P(A_i) = p > 1/2$ (even though they are dependent), and yet (2) a longer series would give no advantage (nor disadvantage) to team A, because $P(A_{series}) = p$ regardless of $k$.  However, I want a scenario where a longer series actually decreases $P(A_{series})$. My 2nd attempt is something convoluted: the first 7 games ($k=4$) are played ""normally"" (i.i.d.) but then games 8 and 9 are always won by the loser of the best-of-first-7 series.  I have not worked this out fully, but while this may give an example where $P(A_{series} | k = 4) > P(A_{series} | k = 5)$, I think this also implies the marginal probabilities $P(A_8), P(A_9) < 1/2$.  So this isn't satisfying as a counterexample, since not only $P(A_i)$ are non-constant, team A actually becomes the worse team in a sense. My 3rd attempt is a ""surgical tweak"" to the 2nd attempt: (1) if the first 7 games include exactly 4 wins by A, then games 8 & 9 are won by team B (therefore making B the overall winner), but (2) if the first 7 games have any other result, then games 8 & 9 are played i.i.d. but with an enhanced $P(A_8)=P(A_9) = p' > p$.  By restricting the special dependence to an event of small enough probability, and balancing it out with $p' > p$ in the case (2), I think I can manage $P(A_8) = P(A_9) =p $.  I have not worked out whether $P(A_{series} | k = 4) > P(A_{series} | k = 5)$ for some choice of $p, p'$.   Also, this counterexample is too ""artificial"" for my taste. What I seek is a probability model where: For every game $i$, the marginal probability $P(A_i)$ is the same, i.e. $\forall i: P(A_i) = p > 1/2$. There exists $k_0$ s.t. $P(A_{series} | k = k_0) > P(A_{series} | k = k_0 + 1)$. Bonus if this is true for all $k_0$, or all sufficiently large $k_0$. Aesthetic requirement :) - Any dependence is as ""simple"" as possible, i.e. I prefer not to have something like my 3rd attempt (or even more convoluted).  I know this isn't a math requirement, and people can have different tastes...  comments on this point are welcome.","This question is inspired by: A longer series is better for a better team: Can you see this at a glance? Also obviously inspired by the NBA playoffs happening right now.  :) Suppose two teams are playing a series of $2k-1$ games, and the first team to win $k$ games wins the overall series.  (No game can end in a tie.)  Moreover, team A is ""better"" than team B. Let $A_i$ denote the event that team A wins game $i$. Let $A_{series}$ denote the event that team A wins the series, i.e., A wins $k$ or more games. If the game results are i.i.d., and $P(A_i) = p > 1/2$ for any game $i$, then a longer series (larger $k$) increases A's chance of winning the series, i.e. $P(A_{series})$ is an increasing function in $k$.  This is intuitively obvious, and a proof can be found in the link above (although that post asks an excellent question re: why such an ""obvious"" result requires an algebraically convoluted proof). I wanna know under what conditions, i.e. under what probability model, would a longer match be BAD for the better team A.  Perhaps some dependence that encodes ""reversion to the mean"" and/or (opposite of) ""momentum""? What I tried My $0$-th attempt: If we allow ""fatigue"" in the form of decreasing $P(A_i),$ then a longer series can be bad for A, even when all $P(A_i) > 1/2.$  A simple 3-game example: if $P(A_1) = 1, P(A_2) = P(A_3) = 0.51$, then A always wins in a 1-game ""series"" ($k=1$) but B has a chance ($0.49^2$) in a 3-game series ($k=2$).  @Henry in his answer gave an infinite length example. So I'm looking for something where the marginal probabilities $P(A_i)$ are constant (i.e. no fatigue). My 1st attempt: let $P(A_1) = p > 1/2$, and thereafter every game $i$ result = game 1 result.  This means: (1) $P(A_i) = p > 1/2$ (even though they are dependent), and yet (2) a longer series would give no advantage (nor disadvantage) to team A, because $P(A_{series}) = p$ regardless of $k$.  However, I want a scenario where a longer series actually decreases $P(A_{series})$. My 2nd attempt is something convoluted: the first 7 games ($k=4$) are played ""normally"" (i.i.d.) but then games 8 and 9 are always won by the loser of the best-of-first-7 series.  I have not worked this out fully, but while this may give an example where $P(A_{series} | k = 4) > P(A_{series} | k = 5)$, I think this also implies the marginal probabilities $P(A_8), P(A_9) < 1/2$.  So this isn't satisfying as a counterexample, since not only $P(A_i)$ are non-constant, team A actually becomes the worse team in a sense. My 3rd attempt is a ""surgical tweak"" to the 2nd attempt: (1) if the first 7 games include exactly 4 wins by A, then games 8 & 9 are won by team B (therefore making B the overall winner), but (2) if the first 7 games have any other result, then games 8 & 9 are played i.i.d. but with an enhanced $P(A_8)=P(A_9) = p' > p$.  By restricting the special dependence to an event of small enough probability, and balancing it out with $p' > p$ in the case (2), I think I can manage $P(A_8) = P(A_9) =p $.  I have not worked out whether $P(A_{series} | k = 4) > P(A_{series} | k = 5)$ for some choice of $p, p'$.   Also, this counterexample is too ""artificial"" for my taste. What I seek is a probability model where: For every game $i$, the marginal probability $P(A_i)$ is the same, i.e. $\forall i: P(A_i) = p > 1/2$. There exists $k_0$ s.t. $P(A_{series} | k = k_0) > P(A_{series} | k = k_0 + 1)$. Bonus if this is true for all $k_0$, or all sufficiently large $k_0$. Aesthetic requirement :) - Any dependence is as ""simple"" as possible, i.e. I prefer not to have something like my 3rd attempt (or even more convoluted).  I know this isn't a math requirement, and people can have different tastes...  comments on this point are welcome.",,['probability']
84,Tail Value at Risk of Normal Distribution,Tail Value at Risk of Normal Distribution,,"For a random variable $X$, Tail-value-at-risk is denoted as $\operatorname{TVaR}_p(X) = \operatorname E(X \mid X>\pi_p) = \dfrac{ \int_{\pi_p}^\infty xf(x) \, dx}{1-F(\pi_p)}$, where $\pi_p=\operatorname{VaR}_p=$ the value-at-risk $=$ the value such that $P(X>\pi_p)=1-p$. While I was reading through my book, I stumbled upon this page: But I struggle to see how the second result was proved.  I'm either not sure how to do the calculus or I don't know what tricks they used to get there, but I can't figure it out.  Do you understand how they got there?","For a random variable $X$, Tail-value-at-risk is denoted as $\operatorname{TVaR}_p(X) = \operatorname E(X \mid X>\pi_p) = \dfrac{ \int_{\pi_p}^\infty xf(x) \, dx}{1-F(\pi_p)}$, where $\pi_p=\operatorname{VaR}_p=$ the value-at-risk $=$ the value such that $P(X>\pi_p)=1-p$. While I was reading through my book, I stumbled upon this page: But I struggle to see how the second result was proved.  I'm either not sure how to do the calculus or I don't know what tricks they used to get there, but I can't figure it out.  Do you understand how they got there?",,"['probability', 'probability-distributions', 'normal-distribution', 'actuarial-science', 'distribution-tails']"
85,Correct probability calculation for Minesweeper,Correct probability calculation for Minesweeper,,"When I play Minesweeper, every now and then I reach a point where I have to make a guess. I then try to calculate the probability for every option to be a mine in order to choose the safest move. But sometimes I find that different calculations result in different probabilities, which means I'm doing it wrong in some sense, and this is what I want to clarify. Below is an example of such a dilemma. Notice the green mark in the upper-left region. I have two choices next to the 4-mark, each with a probability of $\frac{1}{2}$. On the other hand, from the 5-mark point of view, we need to select 2 squares out of 3, suggesting a $\frac{2}{3}$ probability for each square. We can also follow a third calculation, by starting from the 2-mark on the rightmost square on this remaining ""island"": if the upper square is a mine, it can be easily seen that the upper square of the 4-mark must also be a mine; if not- it can be shown that both 4-mark squares have equal probability to be mines. This implies that the upper 4-mark square has probability of $\frac{3}{4}$ to be a mine - again a contradiction. A more ""desperate"" attempt would be to say that all three ""calculation trajectories"" are equally likely, thus we need to add the calculated probabilities and sum them up with a factor of $\frac{1}{3}$. But that is quite awkward, and I'm sure there is more solid reasoning here, but I wasn't able to prove it myself. So... what is the correct way to calculate the probability? As a last remark - I assume here that the remaining island is large enough such that no further meaningful information can be extracted from the remaining squares, such as the number of remaining mines, or a direct enumeration of all possible mine distributions. Thanks, and I hope you find this intriguing as I do. :)","When I play Minesweeper, every now and then I reach a point where I have to make a guess. I then try to calculate the probability for every option to be a mine in order to choose the safest move. But sometimes I find that different calculations result in different probabilities, which means I'm doing it wrong in some sense, and this is what I want to clarify. Below is an example of such a dilemma. Notice the green mark in the upper-left region. I have two choices next to the 4-mark, each with a probability of $\frac{1}{2}$. On the other hand, from the 5-mark point of view, we need to select 2 squares out of 3, suggesting a $\frac{2}{3}$ probability for each square. We can also follow a third calculation, by starting from the 2-mark on the rightmost square on this remaining ""island"": if the upper square is a mine, it can be easily seen that the upper square of the 4-mark must also be a mine; if not- it can be shown that both 4-mark squares have equal probability to be mines. This implies that the upper 4-mark square has probability of $\frac{3}{4}$ to be a mine - again a contradiction. A more ""desperate"" attempt would be to say that all three ""calculation trajectories"" are equally likely, thus we need to add the calculated probabilities and sum them up with a factor of $\frac{1}{3}$. But that is quite awkward, and I'm sure there is more solid reasoning here, but I wasn't able to prove it myself. So... what is the correct way to calculate the probability? As a last remark - I assume here that the remaining island is large enough such that no further meaningful information can be extracted from the remaining squares, such as the number of remaining mines, or a direct enumeration of all possible mine distributions. Thanks, and I hope you find this intriguing as I do. :)",,"['probability', 'combinatorics', 'recreational-mathematics']"
86,Condition on sigma algebra,Condition on sigma algebra,,"Say I toss two distinct coins. Let A be event: there are two heads, $\{HH\}$ Let $\sigma$ be a sigma algebra $\big\{\emptyset,\Omega,\{HH,HT\},\{TT,TH\}\big\}$ How does one understand $P(A|\sigma)$, $E(A|\sigma)$?  How does the meaning differ if sigma algebra is chosen differently, say trivial, or full algebra?","Say I toss two distinct coins. Let A be event: there are two heads, $\{HH\}$ Let $\sigma$ be a sigma algebra $\big\{\emptyset,\Omega,\{HH,HT\},\{TT,TH\}\big\}$ How does one understand $P(A|\sigma)$, $E(A|\sigma)$?  How does the meaning differ if sigma algebra is chosen differently, say trivial, or full algebra?",,"['probability', 'probability-theory', 'measure-theory']"
87,Find independent $X$ and $Y$ that are not normally distributed s.t. $X+Y$ is normally distributed. [duplicate],Find independent  and  that are not normally distributed s.t.  is normally distributed. [duplicate],X Y X+Y,"This question already has answers here : If the sum of two i.i.d. random variables is normal, must the variables themselves be normal? (2 answers) Closed 2 months ago . It's a rather elementary fact that a sum of two independent normally distributed random variables $X$ and $Y$ is normally distributed (or, if you will, the convolution of two normal densities is a normal density). To what extent does this go the other way around? It seems that is $X$ and $Y$ are independent and $X$ is normally distributed, then $Y$ is normally distributed or constant. If you drop both independence of $X$ and $Y$ and $X$ being normally distributed, it's pretty easy to e.g. take $X \sim \mathcal{N}(0,1)$, $Y = 1(X \geq 0)$ and consider $U=XY$, $V=X \,1(Y = 0)$. Now neither $U$ or $V$ are normally distributed but $U+V = X$. However, if you require $X$ and $Y$ to be independent, but drop the requirement of $X$ being normally distributed, it's seems more difficult. Is there a counterexample in that case, where $X$ and $Y$ are not normally distributed but $X+Y$ is?","This question already has answers here : If the sum of two i.i.d. random variables is normal, must the variables themselves be normal? (2 answers) Closed 2 months ago . It's a rather elementary fact that a sum of two independent normally distributed random variables $X$ and $Y$ is normally distributed (or, if you will, the convolution of two normal densities is a normal density). To what extent does this go the other way around? It seems that is $X$ and $Y$ are independent and $X$ is normally distributed, then $Y$ is normally distributed or constant. If you drop both independence of $X$ and $Y$ and $X$ being normally distributed, it's pretty easy to e.g. take $X \sim \mathcal{N}(0,1)$, $Y = 1(X \geq 0)$ and consider $U=XY$, $V=X \,1(Y = 0)$. Now neither $U$ or $V$ are normally distributed but $U+V = X$. However, if you require $X$ and $Y$ to be independent, but drop the requirement of $X$ being normally distributed, it's seems more difficult. Is there a counterexample in that case, where $X$ and $Y$ are not normally distributed but $X+Y$ is?",,"['probability', 'probability-distributions', 'normal-distribution']"
88,Applications of the law of the iterated logarithm,Applications of the law of the iterated logarithm,,"The law of the iterated logarithm says that if $X_n$ is a sequence of iid random variables with zero expectation and unit variance, then the partial sums sequence $S_n = \sum_{i = 1}^n X_i$ satisfies almost surely that $\limsup_{n \rightarrow \infty} \frac{S_n}{\sqrt{2 n \log{\log\ n}}} = 1$. What are the applications of this result? Why is it considered important or even useful? I looked at the wikipedia article . It doesn't explain to me in detail where is this result applied. What major results are built from it or what major areas of applications are. What I am looking for is something like a list of major applications of that theorem. Like how is it used to proved other stuff.","The law of the iterated logarithm says that if $X_n$ is a sequence of iid random variables with zero expectation and unit variance, then the partial sums sequence $S_n = \sum_{i = 1}^n X_i$ satisfies almost surely that $\limsup_{n \rightarrow \infty} \frac{S_n}{\sqrt{2 n \log{\log\ n}}} = 1$. What are the applications of this result? Why is it considered important or even useful? I looked at the wikipedia article . It doesn't explain to me in detail where is this result applied. What major results are built from it or what major areas of applications are. What I am looking for is something like a list of major applications of that theorem. Like how is it used to proved other stuff.",,"['probability', 'probability-theory', 'statistics', 'probability-limit-theorems']"
89,What does actually probability mean?,What does actually probability mean?,,I am a beginner in quantum information. Reading about it has made me question the definition of probability. If the probability of an outcome $m$ in an experiment is $p(m)$ then it means that if I perform the experiment $n$ times ( $n \to \infty$ ) then $p(m)*n$ times I will get the outcome as $m$ . But probability of an outcome by intuition also means how certain we are that we will get that outcome as a result when we perform the experiment. But according to the first definition  probability of an outcome makes sense when we perform the same experiment a very large number of times. Whereas according to the second definition we are just performing the experiment once and rather express probability as a measure of certainty. sorry for asking  a trivial question like this.,I am a beginner in quantum information. Reading about it has made me question the definition of probability. If the probability of an outcome in an experiment is then it means that if I perform the experiment times ( ) then times I will get the outcome as . But probability of an outcome by intuition also means how certain we are that we will get that outcome as a result when we perform the experiment. But according to the first definition  probability of an outcome makes sense when we perform the same experiment a very large number of times. Whereas according to the second definition we are just performing the experiment once and rather express probability as a measure of certainty. sorry for asking  a trivial question like this.,m p(m) n n \to \infty p(m)*n m,"['probability', 'probability-theory']"
90,The Matching Problem/Derangements - n letters to n people,The Matching Problem/Derangements - n letters to n people,,"There are n letters addressed to n eople at different addresses. The n addresses are typed on n envelopes.  A disgruntled secretary shuffles the letters and puts them in the envelopes in random order, one letter per envelope. Find the probability that at least one letter is put in a correctly addressed envelope. [Hint: use the inclusion-exclusion formula.] What is the probability approximately, for large n ? My attempt at a solution: $P(\text{all correct}) = \frac{1}{n!}$ $P(\text{$n-1$ correct}) = {n \choose n-1} \frac{1}{n!} = \frac{1}{1!(n-1)!}$ , since ${n \choose n-1}$ ways of selecting n-1 correct letters. $P(\text{$n-2$ correct}) = {n \choose n-2} \frac{1}{n!} = \frac{1}{2!(n-2)!}$ $\ldots$ $P(\text{$n-n$ correct}) = {n \choose n-n} \frac{1}{n!} = \frac{1}{n!(n-n)!} = \frac{1}{n!}$ This all looks ok to me, but I tested this for a case of 4 people, (I think the theoretical value should be $\frac{9}{24}$ but obviously that is not what I got. Can someone correct my logic please? Also, with regards to the hint about inclusion/exclusion - where would that come in? I read about derangements on Wikipedia but it did not make total sense to me (the derivation). I would appreciate any advice whatsoever including references to other material.","There are n letters addressed to n eople at different addresses. The n addresses are typed on n envelopes.  A disgruntled secretary shuffles the letters and puts them in the envelopes in random order, one letter per envelope. Find the probability that at least one letter is put in a correctly addressed envelope. [Hint: use the inclusion-exclusion formula.] What is the probability approximately, for large n ? My attempt at a solution: , since ways of selecting n-1 correct letters. This all looks ok to me, but I tested this for a case of 4 people, (I think the theoretical value should be but obviously that is not what I got. Can someone correct my logic please? Also, with regards to the hint about inclusion/exclusion - where would that come in? I read about derangements on Wikipedia but it did not make total sense to me (the derivation). I would appreciate any advice whatsoever including references to other material.",P(\text{all correct}) = \frac{1}{n!} P(\text{n-1 correct}) = {n \choose n-1} \frac{1}{n!} = \frac{1}{1!(n-1)!} {n \choose n-1} P(\text{n-2 correct}) = {n \choose n-2} \frac{1}{n!} = \frac{1}{2!(n-2)!} \ldots P(\text{n-n correct}) = {n \choose n-n} \frac{1}{n!} = \frac{1}{n!(n-n)!} = \frac{1}{n!} \frac{9}{24},"['probability', 'combinatorics', 'inclusion-exclusion']"
91,Probability of an integer being a prime,Probability of an integer being a prime,,"$\Omega=\mathbb{N}^*,P(\omega=n)=\dfrac{1}{2^n}$, let $A_k$ be the event $k\mid\omega$. 1) Find $P(A_k)$ 2) Let B be the event ""$\omega$ is prime"", show that $\frac{13}{32}<P(B)<\frac{209}{504}$ One can see easily that $P(A_k)=\dfrac{1}{2^k-1}$ To find $P(B)$, I did the following : $$\begin{align} P(B)&=\displaystyle\sum_{n\in\mathbb{N}^*}P(\omega=n)P\left(\bigcap_{k=2}^{\lfloor\sqrt{n}\rfloor}\overline{A_k}\right) \\&=\sum_{n\in\mathbb{N}^*}\dfrac{1}{2^n}\left(1-P\left(\bigcup_{k=2}^{‌​\lfloor\sqrt{n}\rfloor}{A_k}\right)\right) \\&\le\sum_{n\in\mathbb{N}^*}\dfrac{1}{2^n}\left(1-\sum_{k=2}^{\lfloor\sqrt{n}\rfloor}P\left(A_k\right)‌​\right) \\&=\sum_{n\in\mathbb{N}^*}\dfrac{1}{2^n}\left(1-\sum_{k=2}^{\lfloor\sqrt{n}\rfloor}\dfrac{1}{2^k-1}\right)\end{align}$$ However, I cannot find a good simplification of that bound.","$\Omega=\mathbb{N}^*,P(\omega=n)=\dfrac{1}{2^n}$, let $A_k$ be the event $k\mid\omega$. 1) Find $P(A_k)$ 2) Let B be the event ""$\omega$ is prime"", show that $\frac{13}{32}<P(B)<\frac{209}{504}$ One can see easily that $P(A_k)=\dfrac{1}{2^k-1}$ To find $P(B)$, I did the following : $$\begin{align} P(B)&=\displaystyle\sum_{n\in\mathbb{N}^*}P(\omega=n)P\left(\bigcap_{k=2}^{\lfloor\sqrt{n}\rfloor}\overline{A_k}\right) \\&=\sum_{n\in\mathbb{N}^*}\dfrac{1}{2^n}\left(1-P\left(\bigcup_{k=2}^{‌​\lfloor\sqrt{n}\rfloor}{A_k}\right)\right) \\&\le\sum_{n\in\mathbb{N}^*}\dfrac{1}{2^n}\left(1-\sum_{k=2}^{\lfloor\sqrt{n}\rfloor}P\left(A_k\right)‌​\right) \\&=\sum_{n\in\mathbb{N}^*}\dfrac{1}{2^n}\left(1-\sum_{k=2}^{\lfloor\sqrt{n}\rfloor}\dfrac{1}{2^k-1}\right)\end{align}$$ However, I cannot find a good simplification of that bound.",,"['probability', 'prime-numbers']"
92,Finding tight upper/lower bounds for $\mathbb{E}[\frac{1}{1+X^{2}}]$ where $X$ is a RV with $\mathbb{E}[X]=0$ and $\mbox{Var}(X)=\nu<\infty $,Finding tight upper/lower bounds for  where  is a RV with  and,\mathbb{E}[\frac{1}{1+X^{2}}] X \mathbb{E}[X]=0 \mbox{Var}(X)=\nu<\infty ,"The question is pretty much in the title. My first thought was using Jensen's inquality to get some sort of lower bound. Since $\frac{1}{1+x^{2}}$   is convex on $\mathbb{R}\backslash\left[-\frac{1}{2},\frac{1}{2}\right]$   I think by Jensen's inequality I get a lower bound of the form: $$\frac{1}{1+\nu}\leq\frac{1}{1+\mathbb{E}\left[\left(X\cdot1_{\left\{ X>\frac{1}{2}\right\} }\right)^{2}\right]}\leq\mathbb{E}\left[\frac{1}{1+\left(X\cdot1_{\left\{ X>\frac{1}{2}\right\} }\right)^{2}}\right]\leq\mathbb{E}\left[\frac{1}{1+X^{2}}\right]  $$  I'm not sure if it's even correct to use Jensen's inequality in this manner, the formulation of the inequality I'm familiar with is for an integrable RV and a convex function over an interval of the form $\left(a,b\right)$   with $a,b$   possibly being $\pm\infty$. EDIT : like a comment suggested it's not hard to apply Jensen's Inequality correctly to obtain the second inequality. Unfortunately I just noticed the third inequality is incorrect since $$\frac{1}{1+\left(X\cdot1_{\left\{ X\geq\frac{1}{2}\right\} }\right)^{2}}\geq\frac{1}{1+X^{2}} $$ Yet the bound itself still feels like it should be correct. I also verified you can approach it as desired with a uniform RV defined on the interval $\left(-\varepsilon,\varepsilon\right)$ as $\varepsilon$ tends to $0$. As can be seen: $$\mathbb{E}\left[\frac{1}{1+X^{2}}\right]=\int\limits _{-\varepsilon}^{\varepsilon}\frac{1}{2\varepsilon}\cdot\frac{1}{1+x^{2}}dx=\frac{\tan^{-1}\left(\varepsilon\right)}{\varepsilon}\overset{\varepsilon\to0}{\longrightarrow}1$$ $$\frac{1}{1+\mathbb{E}\left[X^{2}\right]}=\frac{1}{1+\frac{\varepsilon^{2}}{3}}\overset{\varepsilon\to0}{\longrightarrow}1$$ I'd appreciate help showing a bound of the form $\frac{1}{1+\nu}\leq\mathbb{E}\left[\frac{1}{1+X^{2}}\right]$ indeed holds (or a contradicting example and an alternative bound).","The question is pretty much in the title. My first thought was using Jensen's inquality to get some sort of lower bound. Since $\frac{1}{1+x^{2}}$   is convex on $\mathbb{R}\backslash\left[-\frac{1}{2},\frac{1}{2}\right]$   I think by Jensen's inequality I get a lower bound of the form: $$\frac{1}{1+\nu}\leq\frac{1}{1+\mathbb{E}\left[\left(X\cdot1_{\left\{ X>\frac{1}{2}\right\} }\right)^{2}\right]}\leq\mathbb{E}\left[\frac{1}{1+\left(X\cdot1_{\left\{ X>\frac{1}{2}\right\} }\right)^{2}}\right]\leq\mathbb{E}\left[\frac{1}{1+X^{2}}\right]  $$  I'm not sure if it's even correct to use Jensen's inequality in this manner, the formulation of the inequality I'm familiar with is for an integrable RV and a convex function over an interval of the form $\left(a,b\right)$   with $a,b$   possibly being $\pm\infty$. EDIT : like a comment suggested it's not hard to apply Jensen's Inequality correctly to obtain the second inequality. Unfortunately I just noticed the third inequality is incorrect since $$\frac{1}{1+\left(X\cdot1_{\left\{ X\geq\frac{1}{2}\right\} }\right)^{2}}\geq\frac{1}{1+X^{2}} $$ Yet the bound itself still feels like it should be correct. I also verified you can approach it as desired with a uniform RV defined on the interval $\left(-\varepsilon,\varepsilon\right)$ as $\varepsilon$ tends to $0$. As can be seen: $$\mathbb{E}\left[\frac{1}{1+X^{2}}\right]=\int\limits _{-\varepsilon}^{\varepsilon}\frac{1}{2\varepsilon}\cdot\frac{1}{1+x^{2}}dx=\frac{\tan^{-1}\left(\varepsilon\right)}{\varepsilon}\overset{\varepsilon\to0}{\longrightarrow}1$$ $$\frac{1}{1+\mathbb{E}\left[X^{2}\right]}=\frac{1}{1+\frac{\varepsilon^{2}}{3}}\overset{\varepsilon\to0}{\longrightarrow}1$$ I'd appreciate help showing a bound of the form $\frac{1}{1+\nu}\leq\mathbb{E}\left[\frac{1}{1+X^{2}}\right]$ indeed holds (or a contradicting example and an alternative bound).",,"['probability', 'probability-theory', 'random-variables', 'expectation']"
93,Deriving joint CDF from joint PDF,Deriving joint CDF from joint PDF,,"The joint probability function of $(X,Y)$ is given by: $$f_{(X,Y)}(x,y) = e^{-x}$$  Which is defined for the values: $$ 0 \le y\le x<\infty$$ $$0\text{ elsewhere}$$ How would I find the cumulative distribution function of $(X,Y)$? I know that the area that I am integrating in is a infinite triangle(if drawn in a 2d plane) so I set up my integration as: $$\int_0^\infty \int_y^\infty e^{-x}\,dx\,dy$$ After the inside integral is evaluated I get: $$\int_0^\infty e^{-y}dy$$ Which then evaluates to 1. But the answer is supposed to be: $$ 0,\quad x<0 \quad \text{or} \quad \ y\ <0$$ $$1-e^{-y}-ye^{-x},\quad 0\le y\le x$$ $$1-e^{-x}-xe^{-x},\quad y>x\ge0$$ I have completely no idea how the answer came about and also why are these instances where y is greater than x even though the values specifically state that y is less than x?","The joint probability function of $(X,Y)$ is given by: $$f_{(X,Y)}(x,y) = e^{-x}$$  Which is defined for the values: $$ 0 \le y\le x<\infty$$ $$0\text{ elsewhere}$$ How would I find the cumulative distribution function of $(X,Y)$? I know that the area that I am integrating in is a infinite triangle(if drawn in a 2d plane) so I set up my integration as: $$\int_0^\infty \int_y^\infty e^{-x}\,dx\,dy$$ After the inside integral is evaluated I get: $$\int_0^\infty e^{-y}dy$$ Which then evaluates to 1. But the answer is supposed to be: $$ 0,\quad x<0 \quad \text{or} \quad \ y\ <0$$ $$1-e^{-y}-ye^{-x},\quad 0\le y\le x$$ $$1-e^{-x}-xe^{-x},\quad y>x\ge0$$ I have completely no idea how the answer came about and also why are these instances where y is greater than x even though the values specifically state that y is less than x?",,['probability']
94,Markov Chain Initial Distribution,Markov Chain Initial Distribution,,"Suppose $\{X_0,X_1,X_2,\dots\}$ is a discrete-time Markov chain taking values in a finite set $\{1,\dots,N\}$ with initial distribution $p_i(0) = P(X_0 = i)$ for $i\in\{1,\dots,N\}$ and transition probability matrix P where the $ij$-th entry $p_{ij} = P(X_k = j \mid X_{k-1} = i)$ for $k\geq 1$ and $i,j\in\{1,\dots,N\}$. In order for the Markov chain to be well-defined, must we have that $P(X_0 = i)>0$ for all $i\in\{1,\dots,N\}$? If this were not true, then some elements of matrix $P$ would be undefined since the following definition is only valid for $P(X_0 = i)>0$. $$ p_{ij}=P(X_1 = j \mid X_0 = i) = \frac{ P(X_1 = j, X_0 = i) }{ P(X_0 = i) } $$ In some books dealing with discrete-time Markov chains, I have seen the author set the initial distribution to something like $p_i(0) = 1$ if $i=1$ and $p_i(0)=0$ if $i\neq 1$ to signify that the initial condition is known. Doesn't this cause the transition probability matrix $P$ to be invalid and the underlying probability space ill-defined?","Suppose $\{X_0,X_1,X_2,\dots\}$ is a discrete-time Markov chain taking values in a finite set $\{1,\dots,N\}$ with initial distribution $p_i(0) = P(X_0 = i)$ for $i\in\{1,\dots,N\}$ and transition probability matrix P where the $ij$-th entry $p_{ij} = P(X_k = j \mid X_{k-1} = i)$ for $k\geq 1$ and $i,j\in\{1,\dots,N\}$. In order for the Markov chain to be well-defined, must we have that $P(X_0 = i)>0$ for all $i\in\{1,\dots,N\}$? If this were not true, then some elements of matrix $P$ would be undefined since the following definition is only valid for $P(X_0 = i)>0$. $$ p_{ij}=P(X_1 = j \mid X_0 = i) = \frac{ P(X_1 = j, X_0 = i) }{ P(X_0 = i) } $$ In some books dealing with discrete-time Markov chains, I have seen the author set the initial distribution to something like $p_i(0) = 1$ if $i=1$ and $p_i(0)=0$ if $i\neq 1$ to signify that the initial condition is known. Doesn't this cause the transition probability matrix $P$ to be invalid and the underlying probability space ill-defined?",,"['probability', 'probability-theory', 'stochastic-processes', 'random-variables', 'markov-chains']"
95,Why can't all subsets of sample space be considered as events?,Why can't all subsets of sample space be considered as events?,,"My textbook is Probability and random processes by Grimmett & Stirzaker and the first chapter does not explain this,"" for reasons beyond the scope of the book"". The authors introduce the reader to sample spaces and to events and then go on to say that events are subsets of sample space. Then they ask, ""Need all subsets of sample space be events ?"" and then they say no. But I don't see why not. Can anyone give mean an intuitive explanation for this?","My textbook is Probability and random processes by Grimmett & Stirzaker and the first chapter does not explain this,"" for reasons beyond the scope of the book"". The authors introduce the reader to sample spaces and to events and then go on to say that events are subsets of sample space. Then they ask, ""Need all subsets of sample space be events ?"" and then they say no. But I don't see why not. Can anyone give mean an intuitive explanation for this?",,['probability']
96,Intuition of law of iterated logarithm,Intuition of law of iterated logarithm,,"Let $X_i$ be iid random variables with $EX_i = 0$ and $Var X_i=1$ and $S_n=X_1+\cdots+X_n$. Then the law of the iterated logarithm says almost everywhere we have $$\limsup_{n\to\infty}\frac{S_n}{\sqrt{n\log{\log{n}}}} = \sqrt{2}$$ On the other hand the central limit theorem says $$\frac{S_n}{\sqrt{n}} \to N(0,1)$$ Can anyone explain why dividing by an extra $\sqrt{\log{\log{n}}}$ should go from giving $N(0,1)$ to something bounded by the constant $\sqrt{2}$? To try to understand I considered the simple case when each $X_n$ is $N(0,1)$ so that $S_n/\sqrt{n}$ is also normally distributed as $N(0,1)$. Then $S_n/\sqrt{n\log{\log{n}}}$ is distributed as $N(0,1/\log{\log{n}})$. Then it would seem to me that to even have just $\limsup_{n\to\infty}\frac{S_n}{\sqrt{n\log{\log{n}}}} \le \sqrt{2}$ requires either $$\sum_{n=3}^\infty P\left(\frac{S_n}{\sqrt{n\log{\log{n}}}} > \sqrt{2}\right) < \infty$$ or if $$\sum_{n=3}^\infty P\left(\frac{S_n}{\sqrt{n\log{\log{n}}}} > \sqrt{2}\right) = \infty$$ then to achieve $\limsup_{n\to\infty}\frac{S_n}{\sqrt{n\log{\log{n}}}} \le \sqrt{2}$ the sets {$ \omega : \frac{S_n}{\sqrt{n\log{\log{n}}}} > \sqrt{2}$} cannot for example cover the probability space over and over infinitely forever. I don't know the value of $\sum_{n=3}^\infty P\left(\frac{S_n}{\sqrt{n\log{\log{n}}}} > \sqrt{2}\right)$ but since it is the sum of the probability of the tail ends of a bunch of normal distributions you would expect there to be no closed form even for partial sums. In the other direction for $\limsup_{n\to\infty}\frac{S_n}{\sqrt{n\log{\log{n}}}}$ to not have a value lower than $\sqrt{2}$ isn't it necessary that something like the following holds $$\sum_{n=3}^\infty P\left(\sqrt{2}-\epsilon < \frac{S_n}{\sqrt{n\log{\log{n}}}} \le \sqrt{2}\right) = \infty$$ Can anyone explain why this number $\sqrt{2}$ should pop up?","Let $X_i$ be iid random variables with $EX_i = 0$ and $Var X_i=1$ and $S_n=X_1+\cdots+X_n$. Then the law of the iterated logarithm says almost everywhere we have $$\limsup_{n\to\infty}\frac{S_n}{\sqrt{n\log{\log{n}}}} = \sqrt{2}$$ On the other hand the central limit theorem says $$\frac{S_n}{\sqrt{n}} \to N(0,1)$$ Can anyone explain why dividing by an extra $\sqrt{\log{\log{n}}}$ should go from giving $N(0,1)$ to something bounded by the constant $\sqrt{2}$? To try to understand I considered the simple case when each $X_n$ is $N(0,1)$ so that $S_n/\sqrt{n}$ is also normally distributed as $N(0,1)$. Then $S_n/\sqrt{n\log{\log{n}}}$ is distributed as $N(0,1/\log{\log{n}})$. Then it would seem to me that to even have just $\limsup_{n\to\infty}\frac{S_n}{\sqrt{n\log{\log{n}}}} \le \sqrt{2}$ requires either $$\sum_{n=3}^\infty P\left(\frac{S_n}{\sqrt{n\log{\log{n}}}} > \sqrt{2}\right) < \infty$$ or if $$\sum_{n=3}^\infty P\left(\frac{S_n}{\sqrt{n\log{\log{n}}}} > \sqrt{2}\right) = \infty$$ then to achieve $\limsup_{n\to\infty}\frac{S_n}{\sqrt{n\log{\log{n}}}} \le \sqrt{2}$ the sets {$ \omega : \frac{S_n}{\sqrt{n\log{\log{n}}}} > \sqrt{2}$} cannot for example cover the probability space over and over infinitely forever. I don't know the value of $\sum_{n=3}^\infty P\left(\frac{S_n}{\sqrt{n\log{\log{n}}}} > \sqrt{2}\right)$ but since it is the sum of the probability of the tail ends of a bunch of normal distributions you would expect there to be no closed form even for partial sums. In the other direction for $\limsup_{n\to\infty}\frac{S_n}{\sqrt{n\log{\log{n}}}}$ to not have a value lower than $\sqrt{2}$ isn't it necessary that something like the following holds $$\sum_{n=3}^\infty P\left(\sqrt{2}-\epsilon < \frac{S_n}{\sqrt{n\log{\log{n}}}} \le \sqrt{2}\right) = \infty$$ Can anyone explain why this number $\sqrt{2}$ should pop up?",,"['probability', 'probability-theory', 'intuition']"
97,Expected length of a sequence that contains all words of a given length.,Expected length of a sequence that contains all words of a given length.,,"Fix some alphabet $\Sigma$ and a positive integer $n$.  What is the expected number of random letters drawn from $\Sigma$ until all length-$n$ words are present? For example, let $\Sigma = \{0,1\}.$  Then the string ""10"" contains all possible 1-letter words, ie ""0"" and ""1"".  The expected length for a random string is simply the coupon-collector problem with 2 cards... so the expected length is 3. But it's more complicated when words can overlap.  For the same alphabet and $n=2$ we can see that the string ""00110"" has all 2-letter words, and I claim that's the shortest string that does. But what's the expected length of a random string that contains all four strings ""00"", ""01"", ""10"", and ""11""?  The usual coupon-collector approach doesn't seem to work.","Fix some alphabet $\Sigma$ and a positive integer $n$.  What is the expected number of random letters drawn from $\Sigma$ until all length-$n$ words are present? For example, let $\Sigma = \{0,1\}.$  Then the string ""10"" contains all possible 1-letter words, ie ""0"" and ""1"".  The expected length for a random string is simply the coupon-collector problem with 2 cards... so the expected length is 3. But it's more complicated when words can overlap.  For the same alphabet and $n=2$ we can see that the string ""00110"" has all 2-letter words, and I claim that's the shortest string that does. But what's the expected length of a random string that contains all four strings ""00"", ""01"", ""10"", and ""11""?  The usual coupon-collector approach doesn't seem to work.",,['probability']
98,Martingale preservation under independent enlargement of filtration,Martingale preservation under independent enlargement of filtration,,"I think this is probably a very easy question but I haven't worked with $\sigma$-algebras in depth for a long time now so am finding myself a little rusty. Would be very grateful if someone could give me a (careful) proof of the following (I'm pretty sure it's true!). I guess I'm missing the right way of characterising the elements of the join of two $\sigma$-algebras appropriately. Let $M_t$ be a martingale with respect to the filtration $\mathcal{F}_t$ on some probability space $(\Omega, \mathcal{F}, P)$. Assume that $\mathcal{G}_t \subseteq \mathcal{F}$ where for each $t \geq 0$, $\mathcal{G}_t$ is independent of $\mathcal{F}_t$ and let $\mathcal{H}_t := \mathcal{F}_t \vee \mathcal{G}_t$. Then $M_t$ is also a martingale with respect to $\mathcal{H}_t$. Thanks!","I think this is probably a very easy question but I haven't worked with $\sigma$-algebras in depth for a long time now so am finding myself a little rusty. Would be very grateful if someone could give me a (careful) proof of the following (I'm pretty sure it's true!). I guess I'm missing the right way of characterising the elements of the join of two $\sigma$-algebras appropriately. Let $M_t$ be a martingale with respect to the filtration $\mathcal{F}_t$ on some probability space $(\Omega, \mathcal{F}, P)$. Assume that $\mathcal{G}_t \subseteq \mathcal{F}$ where for each $t \geq 0$, $\mathcal{G}_t$ is independent of $\mathcal{F}_t$ and let $\mathcal{H}_t := \mathcal{F}_t \vee \mathcal{G}_t$. Then $M_t$ is also a martingale with respect to $\mathcal{H}_t$. Thanks!",,"['probability', 'measure-theory', 'probability-theory', 'martingales']"
99,Proof to motivate the need for measure theoretic probability,Proof to motivate the need for measure theoretic probability,,"Im using Billingsley's Probability and Measure.  In lecture the instructor motivated the need for measure theory in probability by providing a solution to the following problem : Show that a discrete probability space cannot contain an infinite sequence $A_1, A_2,...$ of independent events, each of probability $\frac{1}{2}$.  This is exercise 1.1a in the text. My thought is that such a sequence may be interpreted as a dyadic expansion of some real number in the unit interval, thus the probability space must be unaccountably infinite.  Of course this is not rigorous and it differs from the approach suggested by the author.  The problem notes give the following hint: ""Each point lies in one of the four sets $A_1 \cap A_2$, $A_1^c \cap A_2$, $A_1 \cap A_2^c$, $A_1^c \cap A_2^c$ and hence would have probability at most $2^{-2}$; continue."" I'm not sure I see where he is going with this.  Of course as the sequence goes infinite, the probability of any set goes to zero, but how does this prove the space cannot be discrete?","Im using Billingsley's Probability and Measure.  In lecture the instructor motivated the need for measure theory in probability by providing a solution to the following problem : Show that a discrete probability space cannot contain an infinite sequence $A_1, A_2,...$ of independent events, each of probability $\frac{1}{2}$.  This is exercise 1.1a in the text. My thought is that such a sequence may be interpreted as a dyadic expansion of some real number in the unit interval, thus the probability space must be unaccountably infinite.  Of course this is not rigorous and it differs from the approach suggested by the author.  The problem notes give the following hint: ""Each point lies in one of the four sets $A_1 \cap A_2$, $A_1^c \cap A_2$, $A_1 \cap A_2^c$, $A_1^c \cap A_2^c$ and hence would have probability at most $2^{-2}$; continue."" I'm not sure I see where he is going with this.  Of course as the sequence goes infinite, the probability of any set goes to zero, but how does this prove the space cannot be discrete?",,"['probability', 'measure-theory', 'probability-theory']"
