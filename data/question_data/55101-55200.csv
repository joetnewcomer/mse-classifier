,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Evaluating a series with the Möbius function and greatest common divisor.,Evaluating a series with the Möbius function and greatest common divisor.,,"Problem: Let $\gcd(a,b,c,d)$ refer to the largest integer $r$ such that $r$ divides each of $a,b,c,d$.  Evaluate the series $$\sum_{a=1}^{\infty}\sum_{b=1}^{\infty}\sum_{c=1}^{\infty}\sum_{d=1}^{\infty}\frac{\mu(a)\mu(b)\mu(c)\mu(d)}{a^{2}b^{2}c^{2}d^{2}}\gcd(a,b,c,d)^{4},$$ where $\mu(n)$ is the Möbius function. I tried several tricks, but I eventually got stuck.  I think it should be possible to rewrite the entire thing as an Euler Product. It looks very similar to  the double series $$\sum_{a=1}^{\infty}\sum_{b=1}^{\infty}\frac{\mu(a)\mu(b)}{a^{2}b^{2}}\gcd(a,b)^{2}=\frac{6}{\pi^2}.$$ Any help is appreciated.","Problem: Let $\gcd(a,b,c,d)$ refer to the largest integer $r$ such that $r$ divides each of $a,b,c,d$.  Evaluate the series $$\sum_{a=1}^{\infty}\sum_{b=1}^{\infty}\sum_{c=1}^{\infty}\sum_{d=1}^{\infty}\frac{\mu(a)\mu(b)\mu(c)\mu(d)}{a^{2}b^{2}c^{2}d^{2}}\gcd(a,b,c,d)^{4},$$ where $\mu(n)$ is the Möbius function. I tried several tricks, but I eventually got stuck.  I think it should be possible to rewrite the entire thing as an Euler Product. It looks very similar to  the double series $$\sum_{a=1}^{\infty}\sum_{b=1}^{\infty}\frac{\mu(a)\mu(b)}{a^{2}b^{2}}\gcd(a,b)^{2}=\frac{6}{\pi^2}.$$ Any help is appreciated.",,"['number-theory', 'sequences-and-series', 'analytic-number-theory', 'euler-product']"
1,Pete L. Clark's Convergence Notes,Pete L. Clark's Convergence Notes,,"I had initially sought out a better understanding of filters and nets, and a few quick google searches showed this document as highly recommended.  (And they are excellent!) I'm having a bit of trouble verifying one of the facts which is stated on page 6: fact 2. Link: http://alpha.math.uga.edu/~pete/convergence.pdf It says that $X$ is Frechet if and only if every subspace $Y$ of $X$ is sequential. It is a few lines to show the $(\Rightarrow)$ direction, but I'm really stuck on the $(\Leftarrow)$ direction.  In fact, I'm actually not able to find the difference between a sequential space (one where sequentially closed subsets are closed) and a Frechet space (one where the sequential closure of subsets coincides with the topological closure). It seems that the definitions are the same if $sc(sc(A)) = sc(A)$ for all subsets $A$ of some topological space.  I can't prove this fact, but cannot come up with a counter-example either. Of course Frechet implies sequential: If $A\subset X$ is sequentially closed, then $sc(A) = A$ .  Since $X$ is Frechet, $sc(A) = \overline{A}$ .  So $A = \overline{A}$ .","I had initially sought out a better understanding of filters and nets, and a few quick google searches showed this document as highly recommended.  (And they are excellent!) I'm having a bit of trouble verifying one of the facts which is stated on page 6: fact 2. Link: http://alpha.math.uga.edu/~pete/convergence.pdf It says that is Frechet if and only if every subspace of is sequential. It is a few lines to show the direction, but I'm really stuck on the direction.  In fact, I'm actually not able to find the difference between a sequential space (one where sequentially closed subsets are closed) and a Frechet space (one where the sequential closure of subsets coincides with the topological closure). It seems that the definitions are the same if for all subsets of some topological space.  I can't prove this fact, but cannot come up with a counter-example either. Of course Frechet implies sequential: If is sequentially closed, then .  Since is Frechet, .  So .",X Y X (\Rightarrow) (\Leftarrow) sc(sc(A)) = sc(A) A A\subset X sc(A) = A X sc(A) = \overline{A} A = \overline{A},"['general-topology', 'sequences-and-series', 'metric-spaces']"
2,Accelerating Convergence of a Sequence,Accelerating Convergence of a Sequence,,"Suppose I had a monotonically increasing sequence $\{d_{n}\}$ which is also bounded above. The $d_{n}$'s satisfy a given recurrence, however computationally they tend very slowly to the limit. What are some ways which I can use to speed up the convergence of this sequence computationally? I am computing these $d_{n}$ in PARI/GP if that is useful information.","Suppose I had a monotonically increasing sequence $\{d_{n}\}$ which is also bounded above. The $d_{n}$'s satisfy a given recurrence, however computationally they tend very slowly to the limit. What are some ways which I can use to speed up the convergence of this sequence computationally? I am computing these $d_{n}$ in PARI/GP if that is useful information.",,"['sequences-and-series', 'algorithms', 'numerical-methods', 'computational-mathematics']"
3,The sum $s(k)=\sum_{n=1}^\infty\frac{\Gamma(\frac{1}{2^n}+1)}{\Gamma(\frac{1}{2^n}-k)}$ gives weird fractions,The sum  gives weird fractions,s(k)=\sum_{n=1}^\infty\frac{\Gamma(\frac{1}{2^n}+1)}{\Gamma(\frac{1}{2^n}-k)},"I stumbled across a series while playing around with a functional equation, it looks like this: $$s(k)=\sum_{n=1}^\infty\frac{\Gamma(\frac{1}{2^n}+1)}{\Gamma(\frac{1}{2^n}-k)}$$ Mathematica gives interesting fractions for the first couple of values of $k$ . Starting with $k=0$ and incrementing by $1$ , they are: $$1, -\frac{2}{3},\frac{8}{7}, -\frac{328}{105}, \frac{1088}{93}, -\frac{108608}{1953}, \dots$$ But Mathematica wasn't able to evaluate the sum for a generic positive integer $k$ . So, can you $\Gamma$ -wizards tell me if there's a way of getting those fractions without numerically evaluating the sum? EDIT: I should say where I got that sum from! I was thinking about a series $$f(x)=\sum_{n=1}^\infty(x^{1/2^n}-1)$$ which satisfied the equation $f(x^2)=f(x)+x-1$ . I noticed that this is similar to $\ln(x^2)=\ln(x)+\ln(x)$ , expecially because $\ln(x) \approx x - 1$ near $1$ . So this function $f(x)$ is kind of like a undercooked logarithm or something. So I wanted to find a Taylor series of $f(x)$ near $x = 1$ and after a some algebra I got: $$f(x)=\sum_{k=0}^\infty\sum_{n=1}^\infty\frac{\Gamma(\frac{1}{2^n}+1)}{(k+1)!\cdot\Gamma(\frac{1}{2^n}-k)}(x-1)^{k+1}$$ which is how I got to the sum","I stumbled across a series while playing around with a functional equation, it looks like this: Mathematica gives interesting fractions for the first couple of values of . Starting with and incrementing by , they are: But Mathematica wasn't able to evaluate the sum for a generic positive integer . So, can you -wizards tell me if there's a way of getting those fractions without numerically evaluating the sum? EDIT: I should say where I got that sum from! I was thinking about a series which satisfied the equation . I noticed that this is similar to , expecially because near . So this function is kind of like a undercooked logarithm or something. So I wanted to find a Taylor series of near and after a some algebra I got: which is how I got to the sum","s(k)=\sum_{n=1}^\infty\frac{\Gamma(\frac{1}{2^n}+1)}{\Gamma(\frac{1}{2^n}-k)} k k=0 1 1, -\frac{2}{3},\frac{8}{7}, -\frac{328}{105}, \frac{1088}{93}, -\frac{108608}{1953}, \dots k \Gamma f(x)=\sum_{n=1}^\infty(x^{1/2^n}-1) f(x^2)=f(x)+x-1 \ln(x^2)=\ln(x)+\ln(x) \ln(x) \approx x - 1 1 f(x) f(x) x = 1 f(x)=\sum_{k=0}^\infty\sum_{n=1}^\infty\frac{\Gamma(\frac{1}{2^n}+1)}{(k+1)!\cdot\Gamma(\frac{1}{2^n}-k)}(x-1)^{k+1}","['sequences-and-series', 'gamma-function']"
4,Exact solution to Dirac delta perturbation for particle in a box,Exact solution to Dirac delta perturbation for particle in a box,,"Using diagrammatic perturbation theory the energy of a particle in a box with a Dirac delta potential can be closely approximated. The following energy correction terms to the ground state energy ( $\mathscr{E}_1$ ) up to 5th order are found. The question is if anybody recognizes some series or easy way to extend to higher orders. \begin{align*}     E^{(0)}_1 = \langle 1|\mathscr{H}_0|1\rangle &= \frac{\pi^2}{2}& \\     E^{(1)}_1 = \langle 1|\mathscr{V}|1\rangle &= 2&\\     E^{(2)}_1 = \langle 1|\mathscr{V}|\Psi_1^{(1)}\rangle &= -\frac{2}{\pi^2}& \\     E^{(3)}_1 = \langle 1|\mathscr{V}|\Psi_1^{(2)}\rangle &= -\frac{2}{3\pi^2} + \frac{8}{\pi^4} \\     E^{(4)}_1 = \langle 1|\mathscr{V}|\Psi_1^{(3)}\rangle &= \frac{4}{\pi^4} - \frac{40}{\pi^6} \\     E^{(5)}_1 = \langle 1|\mathscr{V}|\Psi_1^{(4)}\rangle &= \frac{2}{5\pi^4} - \frac{80}{3\pi^6}+ \frac{224}{\pi^8}\\ \end{align*} $$\mathscr{E}_1=E^{(0)}_1 + E^{(1)}_1 + E^{(2)}_1 + E^{(3)}_1 + E^{(4)}_1 + E^{(5)}_1 + ...$$ I also found a source stating $E^{(5)}_1 = \frac{8}{45\pi^4}-\frac{22}{\pi^6}+\frac{200}{\pi^8}$ , the difference is probably caused by human error, I am not sure who is wrong though. (I got it from a Master's student report, which I am not sure if they want to share it publically) System description For a particle in an infinite square well (""particle in a box""), the solutions to the one-dimensional Schrödinger equation are known. In a box with length $a$ (for simplicity $a=1$ ), the particle has a wavefunction/eigenfunction $\psi_n$ with corresponding energy/eigenvalue $E_n$ , where $n$ refers to the state, with $n=1$ being the ground state. $$ \left(-\frac{1}{2}\frac{d^2}{dx^2}\right)|\psi\rangle = E|\psi\rangle\\ \psi_n = \sqrt{\frac{2}{a}}\sin\left(\frac{n\pi}{a}x\right)\\ E_n = \frac{n^2\pi^2}{2a} $$ A perturbation can be made, specifically a Dirac potential in the middle of the well. This means that the energies and wavefunctions are no longer known. Perturbation theory can approximate the perturbed system using solutions of the unperturbed system. Look at Physics Exchange , which discusses the same problem. However, they did not state any closed form of the different correction terms. Perturbation theory The repulsive Dirac potential will change the Schrödinger Equation. $$ \left(-\frac{1}{2}\frac{d^2}{dx^2}+\delta\left(x-\frac{1}{2}\right)\right)|\psi\rangle = E|\psi\rangle. $$ Perturbation theory , says that the Hamiltonian $\mathscr{H}$ can be split in the unperturbed Hamiltonian $\mathscr{H}_0$ and the perturbation $\mathscr{V}$ . Some shorthand notation can be set up. $$ V_{ij} = \langle i|\mathscr{V}|j\rangle = \langle i|\delta\left(x-\frac{a}{2}\right)|j\rangle = 2\sin\left(\frac{i\pi}{2}\right)\sin\left(\frac{j\pi}{2}\right)\\ E_i^{(0)} = E_i = \frac{i^2\pi^2}{2}. $$ This shows that $V_{ij}=V_{ji}$ and note that $a=1$ was used. Using the unperturbed wavefunctions and energies, the ground state energy of the perturbed system ( $\mathscr{E}_1$ ) can be approximated. For the first few terms a closed form can be found, could this be extended to arbitrary order? $$\mathscr{E}_1=E^{(0)}_1 + E^{(1)}_1 + E^{(2)}_1 + E^{(3)}_1 + E^{(4)}_1 + E^{(5)}_1 + ...$$ Diagrammatic perturbation theory One way of finding the energy corrections is called diagrammatic perturbation theory . ""Modern Quantum Chemistry"" by Szabo and Ostlund has a chapter on this [1]. It comes down to the fact that diagrams can represent parts of the energy correction terms. The rules for drawing the diagrams are as follows: Draw $n$ dots vertically, in order. Connect all $n$ dots together with a continuous line, so that each dot has one line passing through it. Do this in all possible distinct ways. diagrams are equivalent if each and every dot is connected to an identical pair of dots. Then arrows can be added to the lines, lines going down are ""hole lines"" and lines going up are called ""particle lines"". The perturbation ( $\mathscr{V}$ ) is represented by the dots. The rules to translate the diagrams into expressions are as follows: Each dot contributes a factor $\langle\psi_{\text{label line in}}|\mathscr{V}|\psi_{\text{label line out}}\rangle$ , to the numerator. Each pair of adjacent dots contributes to the denominator factor $\sum E^{(0)}_{\text{hole}}-E^{(0)}_{\text{particle}}$ , this sum runs over all lines crossing a (imaginary) horizontal line separating two adjacent dots The overall sign of the expression is $(-)^{h+l}$ , $h$ is the number of hole lines and $l$ is the number of closed loops (which is 1 in this system). Below the diagrams representing the first four corrections to the energy are shown. Below that their corresponding expressions are given. \begin{align}     E^{(1)}_1 = V_{11}&\\     E^{(2)}_1 = \sum_{n\neq1}& \frac{V_{1n}^2}{\left(E_1-E_n\right)}\\     E^{(3)}_1 = \sum_{nm\neq1}& \frac{V_{1n}V_{nm}V_{m1}}{\left(E_1-E_n\right)\left(E_1-E_m\right)}-V_{11}\frac{V_{1n}^2}{\left(E_1-E_n\right)^2}\\     E^{(4)}_1 = \sum_{nmk\neq1}& \frac{V_{1n}V_{nm}V_{mk}V_{k1}}{\left(E_1-E_n\right)\left(E_1-E_m\right)\left(E_1-E_k\right)} + V_{11}^2\frac{V_{1n}^2}{\left(E_1-E_n\right)^3} \\&- V_{11}\frac{V_{1n}V_{nm}V_{m1}}{\left(E_1-E_n\right)^2\left(E_1-E_m\right)}- V_{11}\frac{V_{1n}V_{nm}V_{m1}}{\left(E_1-E_n\right)\left(E_1-E_m\right)^2} \\&- \frac{V_{1n}^2V_{1m}^2}{\left(E_1-E_n\right)\left(2E_1-E_n-E_n\right)\left(E_1-E_m\right)} - \frac{V_{1n}^2V_{1m}^2}{\left(E_1-E_n\right)^2\left(2E_1-E_n-E_n\right)} \end{align} One can see that there would be 24 distinct diagrams for the 5th order and 120 for the 6th order. Using Mathematica the infinite sums are then evaluated, and the energies at the top of this post are found. Concluding, is there a series or an easy way to go to higher orders? Possibly is there even an exact solution when going to infinite order? References: [1]: Szabo, A., & Ostlund, N. S. (1996). Modern Quantum Chemistry: Introduction to Advanced Electronic Structure Theory. Courier Corporation.","Using diagrammatic perturbation theory the energy of a particle in a box with a Dirac delta potential can be closely approximated. The following energy correction terms to the ground state energy ( ) up to 5th order are found. The question is if anybody recognizes some series or easy way to extend to higher orders. I also found a source stating , the difference is probably caused by human error, I am not sure who is wrong though. (I got it from a Master's student report, which I am not sure if they want to share it publically) System description For a particle in an infinite square well (""particle in a box""), the solutions to the one-dimensional Schrödinger equation are known. In a box with length (for simplicity ), the particle has a wavefunction/eigenfunction with corresponding energy/eigenvalue , where refers to the state, with being the ground state. A perturbation can be made, specifically a Dirac potential in the middle of the well. This means that the energies and wavefunctions are no longer known. Perturbation theory can approximate the perturbed system using solutions of the unperturbed system. Look at Physics Exchange , which discusses the same problem. However, they did not state any closed form of the different correction terms. Perturbation theory The repulsive Dirac potential will change the Schrödinger Equation. Perturbation theory , says that the Hamiltonian can be split in the unperturbed Hamiltonian and the perturbation . Some shorthand notation can be set up. This shows that and note that was used. Using the unperturbed wavefunctions and energies, the ground state energy of the perturbed system ( ) can be approximated. For the first few terms a closed form can be found, could this be extended to arbitrary order? Diagrammatic perturbation theory One way of finding the energy corrections is called diagrammatic perturbation theory . ""Modern Quantum Chemistry"" by Szabo and Ostlund has a chapter on this [1]. It comes down to the fact that diagrams can represent parts of the energy correction terms. The rules for drawing the diagrams are as follows: Draw dots vertically, in order. Connect all dots together with a continuous line, so that each dot has one line passing through it. Do this in all possible distinct ways. diagrams are equivalent if each and every dot is connected to an identical pair of dots. Then arrows can be added to the lines, lines going down are ""hole lines"" and lines going up are called ""particle lines"". The perturbation ( ) is represented by the dots. The rules to translate the diagrams into expressions are as follows: Each dot contributes a factor , to the numerator. Each pair of adjacent dots contributes to the denominator factor , this sum runs over all lines crossing a (imaginary) horizontal line separating two adjacent dots The overall sign of the expression is , is the number of hole lines and is the number of closed loops (which is 1 in this system). Below the diagrams representing the first four corrections to the energy are shown. Below that their corresponding expressions are given. One can see that there would be 24 distinct diagrams for the 5th order and 120 for the 6th order. Using Mathematica the infinite sums are then evaluated, and the energies at the top of this post are found. Concluding, is there a series or an easy way to go to higher orders? Possibly is there even an exact solution when going to infinite order? References: [1]: Szabo, A., & Ostlund, N. S. (1996). Modern Quantum Chemistry: Introduction to Advanced Electronic Structure Theory. Courier Corporation.","\mathscr{E}_1 \begin{align*}
    E^{(0)}_1 = \langle 1|\mathscr{H}_0|1\rangle &= \frac{\pi^2}{2}& \\
    E^{(1)}_1 = \langle 1|\mathscr{V}|1\rangle &= 2&\\
    E^{(2)}_1 = \langle 1|\mathscr{V}|\Psi_1^{(1)}\rangle &= -\frac{2}{\pi^2}& \\
    E^{(3)}_1 = \langle 1|\mathscr{V}|\Psi_1^{(2)}\rangle &= -\frac{2}{3\pi^2} + \frac{8}{\pi^4} \\
    E^{(4)}_1 = \langle 1|\mathscr{V}|\Psi_1^{(3)}\rangle &= \frac{4}{\pi^4} - \frac{40}{\pi^6} \\
    E^{(5)}_1 = \langle 1|\mathscr{V}|\Psi_1^{(4)}\rangle &= \frac{2}{5\pi^4} - \frac{80}{3\pi^6}+ \frac{224}{\pi^8}\\
\end{align*} \mathscr{E}_1=E^{(0)}_1 + E^{(1)}_1 + E^{(2)}_1 + E^{(3)}_1 + E^{(4)}_1 + E^{(5)}_1 + ... E^{(5)}_1 = \frac{8}{45\pi^4}-\frac{22}{\pi^6}+\frac{200}{\pi^8} a a=1 \psi_n E_n n n=1 
\left(-\frac{1}{2}\frac{d^2}{dx^2}\right)|\psi\rangle = E|\psi\rangle\\
\psi_n = \sqrt{\frac{2}{a}}\sin\left(\frac{n\pi}{a}x\right)\\
E_n = \frac{n^2\pi^2}{2a}
 
\left(-\frac{1}{2}\frac{d^2}{dx^2}+\delta\left(x-\frac{1}{2}\right)\right)|\psi\rangle = E|\psi\rangle.
 \mathscr{H} \mathscr{H}_0 \mathscr{V} 
V_{ij} = \langle i|\mathscr{V}|j\rangle = \langle i|\delta\left(x-\frac{a}{2}\right)|j\rangle = 2\sin\left(\frac{i\pi}{2}\right)\sin\left(\frac{j\pi}{2}\right)\\
E_i^{(0)} = E_i = \frac{i^2\pi^2}{2}.
 V_{ij}=V_{ji} a=1 \mathscr{E}_1 \mathscr{E}_1=E^{(0)}_1 + E^{(1)}_1 + E^{(2)}_1 + E^{(3)}_1 + E^{(4)}_1 + E^{(5)}_1 + ... n n \mathscr{V} \langle\psi_{\text{label line in}}|\mathscr{V}|\psi_{\text{label line out}}\rangle \sum E^{(0)}_{\text{hole}}-E^{(0)}_{\text{particle}} (-)^{h+l} h l \begin{align}
    E^{(1)}_1 = V_{11}&\\
    E^{(2)}_1 = \sum_{n\neq1}& \frac{V_{1n}^2}{\left(E_1-E_n\right)}\\
    E^{(3)}_1 = \sum_{nm\neq1}& \frac{V_{1n}V_{nm}V_{m1}}{\left(E_1-E_n\right)\left(E_1-E_m\right)}-V_{11}\frac{V_{1n}^2}{\left(E_1-E_n\right)^2}\\
    E^{(4)}_1 = \sum_{nmk\neq1}& \frac{V_{1n}V_{nm}V_{mk}V_{k1}}{\left(E_1-E_n\right)\left(E_1-E_m\right)\left(E_1-E_k\right)} + V_{11}^2\frac{V_{1n}^2}{\left(E_1-E_n\right)^3} \\&- V_{11}\frac{V_{1n}V_{nm}V_{m1}}{\left(E_1-E_n\right)^2\left(E_1-E_m\right)}- V_{11}\frac{V_{1n}V_{nm}V_{m1}}{\left(E_1-E_n\right)\left(E_1-E_m\right)^2} \\&- \frac{V_{1n}^2V_{1m}^2}{\left(E_1-E_n\right)\left(2E_1-E_n-E_n\right)\left(E_1-E_m\right)} - \frac{V_{1n}^2V_{1m}^2}{\left(E_1-E_n\right)^2\left(2E_1-E_n-E_n\right)}
\end{align}","['sequences-and-series', 'physics', 'mathematical-physics', 'perturbation-theory', 'causal-diagrams']"
5,Trying to find a NICE form of : $\sum_{m=1}^{n}\lfloor\log_2m\rfloor$ [ Mathematical Gazette 2002 ],Trying to find a NICE form of :  [ Mathematical Gazette 2002 ],\sum_{m=1}^{n}\lfloor\log_2m\rfloor,"$Q.$ Find a NICE form of : $$\sum_{m=1}^{p}\lfloor\log_2m\rfloor$$ APPROACH : We have , $$\lfloor\log_21\rfloor⠀\color{red}{\lfloor\log_22\rfloor}⠀\lfloor\log_23\rfloor⠀\color{red}{\lfloor\log_24\rfloor}⠀\lfloor\log_25\rfloor⠀\lfloor\log_26\rfloor⠀\lfloor\log_27\rfloor⠀\color{red}{\lfloor\log_28\rfloor}⠀........⠀\lfloor\log_2n\rfloor$$ $$0⠀⠀⠀⠀⠀⠀\color{red}1⠀⠀⠀⠀⠀⠀1⠀⠀⠀⠀⠀⠀\color{red}2⠀⠀⠀⠀⠀⠀2⠀⠀⠀⠀⠀2⠀⠀⠀⠀⠀⠀2⠀⠀⠀⠀⠀⠀\color{red}3⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀$$ We know that : $$\lfloor\log_22^k\rfloor=k$$ STEP 1 : Sum of terms b/w $\lfloor\log_22^{k-1}\rfloor\to\lfloor\log_22^k\rfloor$ . Number of terms b/w $2^{k-1}\to2^k$ is $2^{k-1}$ . Hence the  sum upto $\underline{\lfloor\log_22^{k-1}\rfloor\to\lfloor\log_22^k\rfloor}$ will be : $$S_{2^{k-1}\to2^k}=\lfloor\log_22^{k-1}\rfloor2^{k-1}+\lfloor\log_22^{k}\rfloor$$ $$S_{2^{k-1}\to2^k}=(k-1)2^{k-1}+k$$ Now sum upto $\underline{\lfloor\log_21\rfloor\to\lfloor\log_22^k\rfloor}$ : $$S_{ \lfloor\log_22^k\rfloor}=k+\underbrace{\sum_{r=1}^{k}(k-1)2^{k-1}}_\phi$$ $\Rightarrow$ Now we'll solve for $\phi$ , $$\phi=0.2^0+1.2^1+2.2^2+3.2^3+.......+(k-1)2^{k-1}$$ $$\phi=2+2.2^2+3.2^3+.......+(k-1)2^{k-1}⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀(1)$$ $$\frac{\phi}{2}=1+2.2+3.2^2+.......+(k-1)2^{k-2}⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀(2)$$ Substracting $eq^n(1)$ from $eq^n(2)$ $$-\frac{\phi}{2}=\underbrace{1+2+2^2+2^3+.......+2^{k-2}}_{n-1⠀terms⠀(GP)}-(k-1)2^{k-1}$$ $$-\frac{\phi}{2}=(2^{k-1}-1)-(k-1)2^{k-1}$$ $$\phi=2((k-1)2^{k-1}-2^{k-1}+1)$$ $$\phi=2^k(k-2)+2$$ $\Rightarrow$ Using the value of $\phi$ in $S_{ \lfloor\log_22^k\rfloor}$ : $$S_{ \lfloor\log_22^k\rfloor}=k+2^k(k-2)+2$$ STEP 2 : Let there be a term $\lfloor\log_2p\rfloor$ b/w $\lfloor\log_22^{k-1}\rfloor\to\lfloor\log_22^k\rfloor$ : $$S_{\lfloor\log_2p\rfloor}=S_{ \lfloor\log_22^k\rfloor}-\lfloor\log_22^k\rfloor-\delta$$ Here $\delta$ is the sum of terms b/w $\lfloor\log_2p\rfloor$ and $\lfloor\log_22^k\rfloor$ . Number of terms b/w $\lfloor\log_2p\rfloor$ and $\lfloor\log_22^k\rfloor$ is $(2^k-p)-1$ Hence $\delta$ : $$\delta=(2^k-p-1)\lfloor\log_2p\rfloor$$ Now , $$S_{\lfloor\log_2p\rfloor}=k+2^k(k-2)+2-\lfloor\log_22^k\rfloor-(2^k-p-1)\lfloor\log_2p\rfloor$$ Here are some important conditions : $$ \lfloor\log_22^k\rfloor=k$$ $$\lfloor\log_22^{k-1}\rfloor=\lfloor\log_2p\rfloor$$ $$\lfloor\log_22^k\rfloor=\lfloor\log_22^{k-1}\rfloor+1=\lfloor\log_2p\rfloor+1$$ FINALLY : after further simplifying , I got  : $$\sum_{m=1}^{p}\lfloor\log_2m\rfloor=\lfloor\log_2p\rfloor(p+1)-2^{\lfloor\log_2p\rfloor+1}+2$$ DOUBT : Is there a simpler OR better approach than this ?","Find a NICE form of : APPROACH : We have , We know that : STEP 1 : Sum of terms b/w . Number of terms b/w is . Hence the  sum upto will be : Now sum upto : Now we'll solve for , Substracting from Using the value of in : STEP 2 : Let there be a term b/w : Here is the sum of terms b/w and . Number of terms b/w and is Hence : Now , Here are some important conditions : FINALLY : after further simplifying , I got  : DOUBT : Is there a simpler OR better approach than this ?",Q. \sum_{m=1}^{p}\lfloor\log_2m\rfloor \lfloor\log_21\rfloor⠀\color{red}{\lfloor\log_22\rfloor}⠀\lfloor\log_23\rfloor⠀\color{red}{\lfloor\log_24\rfloor}⠀\lfloor\log_25\rfloor⠀\lfloor\log_26\rfloor⠀\lfloor\log_27\rfloor⠀\color{red}{\lfloor\log_28\rfloor}⠀........⠀\lfloor\log_2n\rfloor 0⠀⠀⠀⠀⠀⠀\color{red}1⠀⠀⠀⠀⠀⠀1⠀⠀⠀⠀⠀⠀\color{red}2⠀⠀⠀⠀⠀⠀2⠀⠀⠀⠀⠀2⠀⠀⠀⠀⠀⠀2⠀⠀⠀⠀⠀⠀\color{red}3⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ \lfloor\log_22^k\rfloor=k \lfloor\log_22^{k-1}\rfloor\to\lfloor\log_22^k\rfloor 2^{k-1}\to2^k 2^{k-1} \underline{\lfloor\log_22^{k-1}\rfloor\to\lfloor\log_22^k\rfloor} S_{2^{k-1}\to2^k}=\lfloor\log_22^{k-1}\rfloor2^{k-1}+\lfloor\log_22^{k}\rfloor S_{2^{k-1}\to2^k}=(k-1)2^{k-1}+k \underline{\lfloor\log_21\rfloor\to\lfloor\log_22^k\rfloor} S_{ \lfloor\log_22^k\rfloor}=k+\underbrace{\sum_{r=1}^{k}(k-1)2^{k-1}}_\phi \Rightarrow \phi \phi=0.2^0+1.2^1+2.2^2+3.2^3+.......+(k-1)2^{k-1} \phi=2+2.2^2+3.2^3+.......+(k-1)2^{k-1}⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀(1) \frac{\phi}{2}=1+2.2+3.2^2+.......+(k-1)2^{k-2}⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀(2) eq^n(1) eq^n(2) -\frac{\phi}{2}=\underbrace{1+2+2^2+2^3+.......+2^{k-2}}_{n-1⠀terms⠀(GP)}-(k-1)2^{k-1} -\frac{\phi}{2}=(2^{k-1}-1)-(k-1)2^{k-1} \phi=2((k-1)2^{k-1}-2^{k-1}+1) \phi=2^k(k-2)+2 \Rightarrow \phi S_{ \lfloor\log_22^k\rfloor} S_{ \lfloor\log_22^k\rfloor}=k+2^k(k-2)+2 \lfloor\log_2p\rfloor \lfloor\log_22^{k-1}\rfloor\to\lfloor\log_22^k\rfloor S_{\lfloor\log_2p\rfloor}=S_{ \lfloor\log_22^k\rfloor}-\lfloor\log_22^k\rfloor-\delta \delta \lfloor\log_2p\rfloor \lfloor\log_22^k\rfloor \lfloor\log_2p\rfloor \lfloor\log_22^k\rfloor (2^k-p)-1 \delta \delta=(2^k-p-1)\lfloor\log_2p\rfloor S_{\lfloor\log_2p\rfloor}=k+2^k(k-2)+2-\lfloor\log_22^k\rfloor-(2^k-p-1)\lfloor\log_2p\rfloor  \lfloor\log_22^k\rfloor=k \lfloor\log_22^{k-1}\rfloor=\lfloor\log_2p\rfloor \lfloor\log_22^k\rfloor=\lfloor\log_22^{k-1}\rfloor+1=\lfloor\log_2p\rfloor+1 \sum_{m=1}^{p}\lfloor\log_2m\rfloor=\lfloor\log_2p\rfloor(p+1)-2^{\lfloor\log_2p\rfloor+1}+2,"['sequences-and-series', 'algebra-precalculus', 'summation', 'logarithms', 'ceiling-and-floor-functions']"
6,Generalizing Catalan numbers: number of ways where we cross the diagonal $k$ times.,Generalizing Catalan numbers: number of ways where we cross the diagonal  times.,k,"Let's say we have a square grid with n steps each. One starts at the lower left corner, takes $2n$ steps; $n$ of them to the right and $n$ of them to the upwards and ends up at the upper right corner. If we want to count the number of paths that don't cross the main diagonal and stay on a particular side of it, we get the Catalan numbers, $C_n=\frac{2n \choose n}{(n+1)}$ . Accounting for both sides, the total paths that don't cross the main diagonal then become $2 C_n$ . A natural question to ask is: how many paths cross the main diagonal exactly $k$ times? Let's call this number $R_{k,n}$ . I want to find a closed-form expression for $R_{k,n}$ . Obviously, $R_{0,n}=2C_n$ My attempt and some thoughts The question here: Using the Catalan numbers provides a warm-up. Both @joriki and @robjohn calculate the number of paths that have a segment that is positive (possibly empty) followed by a segment that is negative (possibly empty). Let's denote this sequence, $G_n$ as joriki does. They do this by noting that conditional on some cut-off point, we simply get two Catalan sequences. Hence, the number of such paths becomes the convolution of the Catalan numbers with themselves. joriki notes that this sequence will have a generating function that is the square of the generating function of the Catalan numbers. He uses this to determine that it is simply the $n+1$ th Catalan number. Another way to go about finding this would have been to use the general formula here: Proof of identity about generalized binomial sequences. with $k=2$ . The two yield the same answer. This can be used to get $R_{1,n}$ per the following equation (we divide $R_{1,n}$ by 2 because the sequence only considers paths which were negative first and then positive while $R_{1,n}$ includes sequences that were positive first): $$G_n=C_{n+1}=2C_n+\frac{R_{1,n}}{2}$$ $$=> R_{1,n}=2C_{n+1}-4C_n$$ Now, can we apply this ""convolution trick"" to get $R_{k,n}$ ? One way is to consider paths that have three sections. They start off with a section (possibly empty) below the main diagonal. Then, they cross it and there is a section (possibly empty) above the main diagonal. Then, they cross it again and there is a third section (possibly empty) that stays below the main diagonal. Unlike before, there are two cut-off points and it seems we have a three-way convolution of the Catalan numbers with themselves. The first thought is that the number of such paths (say $H_n$ ) will have a generating function that is the cube of that of the Catalan numbers. And if we increase the number of segments further, we get higher and higher powers of the generating function. But this can't be right since as we keep increasing the number of such segments, the number of paths should keep increasing per equation (5.70) here: Proof of identity about generalized binomial sequences. . In reality, we'll reach an upper bound at some point when we simply cover all ${2n \choose n}$ paths. So, what is the error in the ""three way convolution leading to a generating function becoming the cube of the Catalan number generating function"" argument? One resolution might be that the argument is fine, but increasing the cut-off points starts double and triple counting the paths.","Let's say we have a square grid with n steps each. One starts at the lower left corner, takes steps; of them to the right and of them to the upwards and ends up at the upper right corner. If we want to count the number of paths that don't cross the main diagonal and stay on a particular side of it, we get the Catalan numbers, . Accounting for both sides, the total paths that don't cross the main diagonal then become . A natural question to ask is: how many paths cross the main diagonal exactly times? Let's call this number . I want to find a closed-form expression for . Obviously, My attempt and some thoughts The question here: Using the Catalan numbers provides a warm-up. Both @joriki and @robjohn calculate the number of paths that have a segment that is positive (possibly empty) followed by a segment that is negative (possibly empty). Let's denote this sequence, as joriki does. They do this by noting that conditional on some cut-off point, we simply get two Catalan sequences. Hence, the number of such paths becomes the convolution of the Catalan numbers with themselves. joriki notes that this sequence will have a generating function that is the square of the generating function of the Catalan numbers. He uses this to determine that it is simply the th Catalan number. Another way to go about finding this would have been to use the general formula here: Proof of identity about generalized binomial sequences. with . The two yield the same answer. This can be used to get per the following equation (we divide by 2 because the sequence only considers paths which were negative first and then positive while includes sequences that were positive first): Now, can we apply this ""convolution trick"" to get ? One way is to consider paths that have three sections. They start off with a section (possibly empty) below the main diagonal. Then, they cross it and there is a section (possibly empty) above the main diagonal. Then, they cross it again and there is a third section (possibly empty) that stays below the main diagonal. Unlike before, there are two cut-off points and it seems we have a three-way convolution of the Catalan numbers with themselves. The first thought is that the number of such paths (say ) will have a generating function that is the cube of that of the Catalan numbers. And if we increase the number of segments further, we get higher and higher powers of the generating function. But this can't be right since as we keep increasing the number of such segments, the number of paths should keep increasing per equation (5.70) here: Proof of identity about generalized binomial sequences. . In reality, we'll reach an upper bound at some point when we simply cover all paths. So, what is the error in the ""three way convolution leading to a generating function becoming the cube of the Catalan number generating function"" argument? One resolution might be that the argument is fine, but increasing the cut-off points starts double and triple counting the paths.","2n n n C_n=\frac{2n \choose n}{(n+1)} 2 C_n k R_{k,n} R_{k,n} R_{0,n}=2C_n G_n n+1 k=2 R_{1,n} R_{1,n} R_{1,n} G_n=C_{n+1}=2C_n+\frac{R_{1,n}}{2} => R_{1,n}=2C_{n+1}-4C_n R_{k,n} H_n {2n \choose n}","['sequences-and-series', 'combinatorics', 'binomial-coefficients', 'catalan-numbers']"
7,A formula for Ramanujan's tau function,A formula for Ramanujan's tau function,,"In his paper On certain Arithmetical Functions published in Transactions of the Cambridge Philosophical Society , XXII, No. 9, 1916, 159-184, Ramanujan makes some bold claims about the tau function defined as follows: $$\sum_{n=1}^{\infty} \tau(n) q^n=q\prod_{n=1}^{\infty} (1-q^n)^{24}\tag{1}$$ To quote him It appears that $$\sum_{n=1}^{\infty} \frac{\tau(n)} {n^s} =\prod_{p} \frac{1}{1-\tau(p)p^{-s} +p^{11-2s}}\tag{2}$$ This assertion is equivalent to the assertion that, if $$n=p_1^{a_1}p_2^{a_2}\dots p_r^{a_r} $$ where $p_1,p_2,\dots,p_r$ are the prime divisors of $n$ , then $$n^{-11/2}\tau(n)=\frac{\sin((1+a_1)\theta_{p_1})}{\sin\theta_{p_1}}\cdot\frac{\sin((1+a_2)\theta_{p_2})}{\sin\theta_{p_2}}\dots\frac{\sin((1+a_r)\theta_{p_r})}{\sin\theta_{p_r}}\tag{3}$$ where $\cos\theta_p=\frac{1}{2}p^{-11/2}\tau(p)$ . It would follow that, if $n$ and $n'$ are prime to each other, we must have $$\tau(nn') =\tau(n) \tau(n') \tag{4}$$ Let us suppose that $(3)$ is true, and also that (as appears to be highly probable) $$\{2\tau(p)\}^2\leq p^{11}\text{ (see note at the end)} \tag{5}$$ so that $\theta_p$ is real. It is rather very remarkable that Ramanujan starts with a proposed equation $(2)$ without any proof (only God knows how he guessed it) and then draws conclusions like $(3),(4)$ . IMHO Ramanujan uses empirical evidence and his hope that $\theta_p$ should be real to make the bold conjecture $(5)$ which was finally proved by Deligne using very sophisticated tools (of which I have no inkling). Identity $(4)$ was proved by Mordell and his proof is replicated here . Based on these ideas one can prove the identity $(2)$ . My question is regarding equation $(3)$ . It appears that Ramanujan uses some general theory of Dirichlet series and their expression into infinite products to derive $(3)$ and he has used that approach to derive many similar identities based on Dirichlet series in the same paper. Is there any general theory which which allows us to deduce $(3)$ from $(2)$ ? I am hoping that this is the easy part in whatever is presented above and expect some sort of a general proof here which can work of other Dirichlet series and its corresponding infinite product representation. Note : Equation $(5)$ has a typo in the original paper also (or perhaps in my copy of Collected Papers of Ramanujan). It should be fixed as $$\{\tau(p) \} ^{2}\leq 4p^{11}\tag{6}$$","In his paper On certain Arithmetical Functions published in Transactions of the Cambridge Philosophical Society , XXII, No. 9, 1916, 159-184, Ramanujan makes some bold claims about the tau function defined as follows: To quote him It appears that This assertion is equivalent to the assertion that, if where are the prime divisors of , then where . It would follow that, if and are prime to each other, we must have Let us suppose that is true, and also that (as appears to be highly probable) so that is real. It is rather very remarkable that Ramanujan starts with a proposed equation without any proof (only God knows how he guessed it) and then draws conclusions like . IMHO Ramanujan uses empirical evidence and his hope that should be real to make the bold conjecture which was finally proved by Deligne using very sophisticated tools (of which I have no inkling). Identity was proved by Mordell and his proof is replicated here . Based on these ideas one can prove the identity . My question is regarding equation . It appears that Ramanujan uses some general theory of Dirichlet series and their expression into infinite products to derive and he has used that approach to derive many similar identities based on Dirichlet series in the same paper. Is there any general theory which which allows us to deduce from ? I am hoping that this is the easy part in whatever is presented above and expect some sort of a general proof here which can work of other Dirichlet series and its corresponding infinite product representation. Note : Equation has a typo in the original paper also (or perhaps in my copy of Collected Papers of Ramanujan). It should be fixed as","\sum_{n=1}^{\infty} \tau(n) q^n=q\prod_{n=1}^{\infty} (1-q^n)^{24}\tag{1} \sum_{n=1}^{\infty} \frac{\tau(n)} {n^s} =\prod_{p} \frac{1}{1-\tau(p)p^{-s} +p^{11-2s}}\tag{2} n=p_1^{a_1}p_2^{a_2}\dots p_r^{a_r}  p_1,p_2,\dots,p_r n n^{-11/2}\tau(n)=\frac{\sin((1+a_1)\theta_{p_1})}{\sin\theta_{p_1}}\cdot\frac{\sin((1+a_2)\theta_{p_2})}{\sin\theta_{p_2}}\dots\frac{\sin((1+a_r)\theta_{p_r})}{\sin\theta_{p_r}}\tag{3} \cos\theta_p=\frac{1}{2}p^{-11/2}\tau(p) n n' \tau(nn') =\tau(n) \tau(n') \tag{4} (3) \{2\tau(p)\}^2\leq p^{11}\text{ (see note at the end)} \tag{5} \theta_p (2) (3),(4) \theta_p (5) (4) (2) (3) (3) (3) (2) (5) \{\tau(p) \} ^{2}\leq 4p^{11}\tag{6}","['sequences-and-series', 'infinite-product', 'dirichlet-series']"
8,A sum of partitions,A sum of partitions,,"A friend of mine presented a problem I found interesting: Compute the following: $$\sum_{n=0}^\infty\left(\prod_{k=1}^j(1+x^k)\right)[x^{mn}]$$ where $P(x)[x^n]$ denotes the $x^n$ coefficient of $P$ . This problem is meant to be solved with the assistance of a program for large $j$ (larger than 1000) and $m\ll j$ . I'm interested in general, but if the case of $m~|~j$ is special, then that suffices for me. My first thought was to brute force compute all of the coefficients, but this takes $\mathcal O(j^3)$ time, which is too slow. My second thought was that this is essentially searching for distinct partitions . The issue is the finite upper bound, meaning that this becomes inaccurate after than $x^{j+1}$ coefficient. I'm not super familiar with partitions to know how to adjust for this without brute force like above. My third thought was to tackle this more generally with: $$\sum_{n=0}^\infty P(x)[x^{mn}]=\frac1m\sum_{n=0}^{m-1}P(e^{2\pi in/m})$$ But this almost completely ignores the form of $P$ , so I don't feel like this is how the problem should be tackled. How can I tackle this problem? Update: I just realized that when $m~|~j$ we have $$\sum_{n=0}^\infty\left(\prod_{k=1}^j(1+x^k)\right)[x^{mn}]=\frac1m\sum_{n=0}^{m-1}\left[\prod_{k=0}^{m-1}(1+e^{2\pi ink/m})\right]^{j/m}$$ which is far fewer computations. Ruby code . Still interested in alternative solutions.","A friend of mine presented a problem I found interesting: Compute the following: where denotes the coefficient of . This problem is meant to be solved with the assistance of a program for large (larger than 1000) and . I'm interested in general, but if the case of is special, then that suffices for me. My first thought was to brute force compute all of the coefficients, but this takes time, which is too slow. My second thought was that this is essentially searching for distinct partitions . The issue is the finite upper bound, meaning that this becomes inaccurate after than coefficient. I'm not super familiar with partitions to know how to adjust for this without brute force like above. My third thought was to tackle this more generally with: But this almost completely ignores the form of , so I don't feel like this is how the problem should be tackled. How can I tackle this problem? Update: I just realized that when we have which is far fewer computations. Ruby code . Still interested in alternative solutions.",\sum_{n=0}^\infty\left(\prod_{k=1}^j(1+x^k)\right)[x^{mn}] P(x)[x^n] x^n P j m\ll j m~|~j \mathcal O(j^3) x^{j+1} \sum_{n=0}^\infty P(x)[x^{mn}]=\frac1m\sum_{n=0}^{m-1}P(e^{2\pi in/m}) P m~|~j \sum_{n=0}^\infty\left(\prod_{k=1}^j(1+x^k)\right)[x^{mn}]=\frac1m\sum_{n=0}^{m-1}\left[\prod_{k=0}^{m-1}(1+e^{2\pi ink/m})\right]^{j/m},"['sequences-and-series', 'combinatorics', 'algorithms', 'integer-partitions']"
9,Does equidistribution imply convergence,Does equidistribution imply convergence,,"The following is an interesting problem presented to this site which has yet to bet solved : Does $$\sum_{n=1}^\infty \frac{\sin(n!)}{n}$$ converge. While attempting this problem, I thought that proving the equidistribution of $n!$ modulo $2\pi$ would be sufficient for the original conjecture. For those who do not know, an sequence $a_n$ is said to be equidistributed on a non-degenerate interval $[a,b]$ if $$\lim_{n\to \infty}\frac{|\{a_1,a_2,\cdots,a_n\}\cap [c,d]|}{n}=\frac{d-c}{b-a}$$ for all subintervals $[c,d]\subseteq [a,b]$ . My thoughts then turned to the more general question: If $a_n$ is any sequence of real numbers such that $\mod(a_n,2\pi)$ is equidistributed over $[0,2\pi]$ , does $$\sum_{n=1}^\infty \frac{\sin(a_n)}{n^\beta}$$ necessarily converge for $\beta>0$ . Obviously, if $\beta>1$ then the series converges absolutely, so the interesting cases are $0<\beta<1$ and $\beta=1$ (although they might be the same case overall). One possible way forward is using Weyl's criterion : we know that if $a_n$ is equidistributed over $[0,2\pi]$ , then $$\lim_{n\to\infty} \sum_{j=1}^n\frac{\sin(q a_j)}{n}=0$$ for all $q\in\mathbb{N}$ . I'm not sure how this could be useful but it seems pretty close to the original sum. One result in favor of this conjecture is discussed on this mathoverflow post. That is, if $p(n)$ is any polynomial with rational coefficients, then $$\sum_{n=1}^\infty \frac{\sin(p(n))}{n}$$ converges.","The following is an interesting problem presented to this site which has yet to bet solved : Does converge. While attempting this problem, I thought that proving the equidistribution of modulo would be sufficient for the original conjecture. For those who do not know, an sequence is said to be equidistributed on a non-degenerate interval if for all subintervals . My thoughts then turned to the more general question: If is any sequence of real numbers such that is equidistributed over , does necessarily converge for . Obviously, if then the series converges absolutely, so the interesting cases are and (although they might be the same case overall). One possible way forward is using Weyl's criterion : we know that if is equidistributed over , then for all . I'm not sure how this could be useful but it seems pretty close to the original sum. One result in favor of this conjecture is discussed on this mathoverflow post. That is, if is any polynomial with rational coefficients, then converges.","\sum_{n=1}^\infty \frac{\sin(n!)}{n} n! 2\pi a_n [a,b] \lim_{n\to \infty}\frac{|\{a_1,a_2,\cdots,a_n\}\cap [c,d]|}{n}=\frac{d-c}{b-a} [c,d]\subseteq [a,b] a_n \mod(a_n,2\pi) [0,2\pi] \sum_{n=1}^\infty \frac{\sin(a_n)}{n^\beta} \beta>0 \beta>1 0<\beta<1 \beta=1 a_n [0,2\pi] \lim_{n\to\infty} \sum_{j=1}^n\frac{\sin(q a_j)}{n}=0 q\in\mathbb{N} p(n) \sum_{n=1}^\infty \frac{\sin(p(n))}{n}","['sequences-and-series', 'ergodic-theory', 'equidistribution']"
10,cauchy's first theorem on limits of sequences,cauchy's first theorem on limits of sequences,,"Cauchy's first theorem on limits goes like this If $\ <f_n> $ be a sequence of positive terms and $$ \lim_{\ n\to\infty}\ f_n=l$$ Then $$ \lim_{ n\to\infty}\ [\ \frac{f_1+f_2+\dots+f_n}{n}]=l$$ Now this is an example of its application. $Q)$ Find the value of $$ \lim_{\ n \to \infty}\frac{1}{n}[1+\frac{1}{2}+\frac{1}{3}\dots+\frac{1}{n}] $$ $A)$ By cauchy's theorem if $$ f_n=\frac{1}{n} \ and \lim_{\ n\to\infty}\frac{1}{n}=0 $$ Then $$ \lim_{\ n\to\infty}\frac{1}{n}[1+\frac{1}{2}+\frac{1}{3}\dots+\frac{1}{n}]=0$$ I understand this example. Now here is another example and its solution which I found in various texts but I don't understand how can we apply cauchy's theorem to it $Q)$ Find the value of $$ \lim_{\ n\to\infty}[\frac{1}{(n+1)^2}+\frac{1}{(n+2)^2}+\dots+\frac{1}{2n^2}] $$ $A)$ Multiply and divide by n $$ \lim_{\ n\to\infty}\frac{1}{n}[\frac{n}{(n+1)^2}+\frac{n}{(n+2)^2}+\dots+\frac{n}{2n^2}] $$ Let $$ <f_n>=\frac{n}{(n+n)^2}=\frac{n}{4n^2}$$ Then, $$ \lim_{\ n\to\infty}f_n=\lim_{n\to\infty}\frac{1}{4n}=0$$ By cauchy's theorem $$ \lim_{\ n\to\infty}[\frac{1}{(n+1)^2}+\frac{1}{(n+2)^2}+\dots+\frac{1}{2n^2}]=0 $$ As you can see there is clearly a distinction between the first and second question In th first we have $ 1+\frac{1}{2}+\frac{1}{3}+\dots+\frac{1}{n}$ while in the second one we have $\frac{n}{(n+1)^2}+\frac{n}{(n+2)^2}+\dots+\frac{n}{(2n)^2} $ I see how the first one can be written as the sum of sequence $\frac{1}{n}$ But how can the second one written as the sum of the sequence $\frac{n}{(2n)^2}$ Please help....","Cauchy's first theorem on limits goes like this If be a sequence of positive terms and Then Now this is an example of its application. Find the value of By cauchy's theorem if Then I understand this example. Now here is another example and its solution which I found in various texts but I don't understand how can we apply cauchy's theorem to it Find the value of Multiply and divide by n Let Then, By cauchy's theorem As you can see there is clearly a distinction between the first and second question In th first we have while in the second one we have I see how the first one can be written as the sum of sequence But how can the second one written as the sum of the sequence Please help....",\ <f_n>   \lim_{\ n\to\infty}\ f_n=l  \lim_{ n\to\infty}\ [\ \frac{f_1+f_2+\dots+f_n}{n}]=l Q)  \lim_{\ n \to \infty}\frac{1}{n}[1+\frac{1}{2}+\frac{1}{3}\dots+\frac{1}{n}]  A)  f_n=\frac{1}{n} \ and \lim_{\ n\to\infty}\frac{1}{n}=0   \lim_{\ n\to\infty}\frac{1}{n}[1+\frac{1}{2}+\frac{1}{3}\dots+\frac{1}{n}]=0 Q)  \lim_{\ n\to\infty}[\frac{1}{(n+1)^2}+\frac{1}{(n+2)^2}+\dots+\frac{1}{2n^2}]  A)  \lim_{\ n\to\infty}\frac{1}{n}[\frac{n}{(n+1)^2}+\frac{n}{(n+2)^2}+\dots+\frac{n}{2n^2}]   <f_n>=\frac{n}{(n+n)^2}=\frac{n}{4n^2}  \lim_{\ n\to\infty}f_n=\lim_{n\to\infty}\frac{1}{4n}=0  \lim_{\ n\to\infty}[\frac{1}{(n+1)^2}+\frac{1}{(n+2)^2}+\dots+\frac{1}{2n^2}]=0   1+\frac{1}{2}+\frac{1}{3}+\dots+\frac{1}{n} \frac{n}{(n+1)^2}+\frac{n}{(n+2)^2}+\dots+\frac{n}{(2n)^2}  \frac{1}{n} \frac{n}{(2n)^2},"['sequences-and-series', 'limits']"
11,What is $\sum_{n=1}^{\infty}a_1 a_2...a_n$?,What is ?,\sum_{n=1}^{\infty}a_1 a_2...a_n,"Let $\{a_n\}$ be defined as follows: $a_1>0, a_{n+1}=\ln \dfrac{e^{a_n}-1}{a_n}$ for $n \geq 1.$ Then find the sum $\displaystyle \sum_{n=1}^{\infty}a_1a_2...a_n.$ Please give some hints to solve this. At the question it was also given that $\{a_n\}$ is a decreasing sequence of positive terms converging to 0.",Let be defined as follows: for Then find the sum Please give some hints to solve this. At the question it was also given that is a decreasing sequence of positive terms converging to 0.,"\{a_n\} a_1>0, a_{n+1}=\ln \dfrac{e^{a_n}-1}{a_n} n \geq 1. \displaystyle \sum_{n=1}^{\infty}a_1a_2...a_n. \{a_n\}","['sequences-and-series', 'analysis']"
12,Sum of square of binomial coeffcient with positive and negative terms,Sum of square of binomial coeffcient with positive and negative terms,,Finding $\displaystyle \binom{2n}{1}^2-2\binom{2n}{2}^2+3\binom{2n}{3}^2-\cdots \cdots -2n\binom{2n}{2n}^2.$ What I've tried: $$(1-x)^{2n}=\binom{2n}{0}-\binom{2n}{1}x+\binom{2n}{2}x^2+\cdots \cdots +\binom{2n}{2n}x^{2n}$$ $$-2n(1-x)^{2n-1}=-\binom{2n}{1}+2\binom{2n}{2}x-3\binom{2n}{3}x^2+\cdots +n\binom{2n}{2n}x^{2n-1}$$ Sum notation: $$\sum_{k=0}^{2n} (-1)^{k-1}k\binom{2n}{k}^2$$,Finding What I've tried: Sum notation:,\displaystyle \binom{2n}{1}^2-2\binom{2n}{2}^2+3\binom{2n}{3}^2-\cdots \cdots -2n\binom{2n}{2n}^2. (1-x)^{2n}=\binom{2n}{0}-\binom{2n}{1}x+\binom{2n}{2}x^2+\cdots \cdots +\binom{2n}{2n}x^{2n} -2n(1-x)^{2n-1}=-\binom{2n}{1}+2\binom{2n}{2}x-3\binom{2n}{3}x^2+\cdots +n\binom{2n}{2n}x^{2n-1} \sum_{k=0}^{2n} (-1)^{k-1}k\binom{2n}{k}^2,['sequences-and-series']
13,How to calculate $\sum\limits_{n=1}^{\infty}\frac{1}{3^n - 2^n}$,How to calculate,\sum\limits_{n=1}^{\infty}\frac{1}{3^n - 2^n},"By the test of reason, this series converges.  The problem is figuring out which technique to use to calculate your sum. Thanks for any help.","By the test of reason, this series converges.  The problem is figuring out which technique to use to calculate your sum. Thanks for any help.",,['sequences-and-series']
14,$\sum\limits_{m\geq1}\sum\limits_{n\geq1}\frac{(-1)^n}{n^3}\sin\left(\frac{n}{m^2}\right)=\frac{\pi^6}{11340}-\frac{\pi^4}{72}$ Numerical evidence,Numerical evidence,\sum\limits_{m\geq1}\sum\limits_{n\geq1}\frac{(-1)^n}{n^3}\sin\left(\frac{n}{m^2}\right)=\frac{\pi^6}{11340}-\frac{\pi^4}{72},"I am looking for numerical evidence that $$\sum_{m\geq1}\sum_{n\geq1}\frac{(-1)^n}{n^3}\sin\left(\frac{n}{m^2}\right)=\frac{\pi^6}{11340}-\frac{\pi^4}{72}$$ I have proven it, but I just want to be extra sure. Desmos only gives me accuracy to the third decimal place, but I know that some of you (@Claude Leibovici) are able to give me extremely high decimal accuracy. Proof: We know that for $|t|\leq\pi$ , $$t^2=\frac{\pi^2}3+4\sum_{n\geq1}\frac{(-1)^n}{n^2}\cos nt$$ Solving for the sum then integrating both sides from $0$ to $x$ , $$\sum_{n\geq1}\frac{(-1)^n}{n^3}\sin(nx)=\frac{x^3}{12}-\frac{\pi^2x}{12}$$ Then plugging in $x=\frac1{m^2}$ for integer $m\geq1$ , $$\sum_{n\geq1}\frac{(-1)^n}{n^3}\sin\bigg(\frac{n}{m^2}\bigg)=\frac{1}{12m^6}-\frac{\pi^2}{12m^2}$$ then applying $\sum_{m\geq1}$ on both sides, $$\sum_{m\geq1}\sum_{n\geq1}\frac{(-1)^n}{n^3}\sin\bigg(\frac{n}{m^2}\bigg)=\frac1{12}\zeta(6)-\frac{\pi^2}{12}\zeta(2)$$ We simplify to reach our conclusion $$\sum_{m\geq1}\sum_{n\geq1}\frac{(-1)^n}{n^3}\sin\bigg(\frac{n}{m^2}\bigg)=\frac{\pi^6}{11340}-\frac{\pi^4}{72}$$","I am looking for numerical evidence that I have proven it, but I just want to be extra sure. Desmos only gives me accuracy to the third decimal place, but I know that some of you (@Claude Leibovici) are able to give me extremely high decimal accuracy. Proof: We know that for , Solving for the sum then integrating both sides from to , Then plugging in for integer , then applying on both sides, We simplify to reach our conclusion",\sum_{m\geq1}\sum_{n\geq1}\frac{(-1)^n}{n^3}\sin\left(\frac{n}{m^2}\right)=\frac{\pi^6}{11340}-\frac{\pi^4}{72} |t|\leq\pi t^2=\frac{\pi^2}3+4\sum_{n\geq1}\frac{(-1)^n}{n^2}\cos nt 0 x \sum_{n\geq1}\frac{(-1)^n}{n^3}\sin(nx)=\frac{x^3}{12}-\frac{\pi^2x}{12} x=\frac1{m^2} m\geq1 \sum_{n\geq1}\frac{(-1)^n}{n^3}\sin\bigg(\frac{n}{m^2}\bigg)=\frac{1}{12m^6}-\frac{\pi^2}{12m^2} \sum_{m\geq1} \sum_{m\geq1}\sum_{n\geq1}\frac{(-1)^n}{n^3}\sin\bigg(\frac{n}{m^2}\bigg)=\frac1{12}\zeta(6)-\frac{\pi^2}{12}\zeta(2) \sum_{m\geq1}\sum_{n\geq1}\frac{(-1)^n}{n^3}\sin\bigg(\frac{n}{m^2}\bigg)=\frac{\pi^6}{11340}-\frac{\pi^4}{72},"['sequences-and-series', 'proof-verification', 'fourier-series', 'decimal-expansion']"
15,Calculating the $\sum_{x=1}^\infty\left[\prod_{k=0}^s{s\choose k}x^k\right]^{-1}$,Calculating the,\sum_{x=1}^\infty\left[\prod_{k=0}^s{s\choose k}x^k\right]^{-1},"Question: If $s \in \mathbb{N}$ is it true: $\sum_{x=1}^\infty\left[\prod_{k=0}^s{s\choose k}x^k\right]^{-1}={\zeta\left[{s+1 \choose 2}\right] \above 1.5pt \prod_{k=1}^s{s \choose k}};$ where $\zeta\left[{s+1 \choose 2}\right]$ is the Riemann zeta function $^1$ evaluated at the triangular numbers $^2$ ? I believe I can show the answer to the question is yes by way of inspection. I cannot get an actual explicit calculation that answers the question affirmatively - that is what I am asking for ! Solution to question by inspection: For short handedness I write $$\zeta_{\times}(s)=\sum_{x=1}^\infty\Bigg[\prod_{k=0}^s{s\choose k}x^k\Bigg]^{-1}$$ I computed a small list of values of $\zeta_{\times}(s)$ for small $s$ : \begin{array}{ l | l } s & 2 & 3 & 4 & 5 & 6 & 7\\ \hline \zeta_{\times}(s) & \frac{\zeta(3)}{2} & \frac{\zeta(6)}{9} & \frac{\zeta(10)}{96} & \frac{\zeta(15)}{2500} & \frac{\zeta(21)}{162000}& \frac{\zeta(28)}{26471025}\\  \end{array} Inspection suggests that $\zeta_{\times}(s)$ has numerator equal to the Riemann zeta function at ${s+1 \choose 2}.$ The denominators of $\zeta_{\times}(s)$ can be written explicitly as $2,9,96,2500,162000,\ldots$ ; which appear to be the integer sequence A001142 $^3$ . Listed in the reference section is the following paper by Lagarias: Products of Binomial Coefficients and Unreduced Farey Fractions . $^4$ . Lagarias defines the unreduced Farey fractions $^5$ to be the ordered sequence of all reduced and unreduced fractions between $0$ and $1$ with denominator of size at most $s.$ Following Lagarias' notation: I write $G_s$ for the set of unreduced Farey fractions and let $|G_s|$ and $G_s^*$ denote the cardinality and the product of all elements of $G_s$ respectively. Lagarias shows the following results: $|G_s|={s+1 \choose 2}$ and $G_s^*=\prod_{k=1}^s{s \choose k}.$ I put everything together and get $$\zeta_{\times}(s)={\zeta\big(|G_s|\big) \above 1.5pt G_s^*}$$ and I am done. $\blacksquare$ Source and motivation of the problem: Curiosity is the main driving source of the problem. Here it goes: If $x$ and $s$ are positive numbers I write $\zeta(s)$ for the Riemann zeta function evaluated at the number $s.$ For ease of typing  I write Pascal's Triangle $^{6}$ like this: $$\text{ }\begin{matrix} 1&&&&\\ 1&1&&&\\ \color{red}{1}&\color{red}{2}&\color{red}{1}&&\\ \color{blue}{1}&\color{blue}{3}&\color{blue}{3}&\color{blue}{1}&\\ 1&4&6&4&1\\ \vdots \end{matrix}$$ and recall that the first row in Pascal's triangle is numbered at $0$ .  Now look at the second and third rows of the triangle, highlighted in red and blue respectively and observe: $\sum_{x=0}^\infty{ 1 \above 1.5pt \color{red}{1}+\color{red}{2}x+\color{red}{1}x^2}=\zeta(2)$ and $\sum_{x=0}^\infty{ 1 \above 1.5pt \color{blue}{1}+\color{blue}{3}x+\color{blue}{3}x^2+\color{blue}{1}x^3}=\zeta(3).$ This observation shows that $\zeta(s)$ can be recovered from the rows of Pascal's triangle - in particular I can write $\sum_{x=0}^\infty\frac{1}{(1+x)^s}=\zeta(s).$ On the other hand using the binomial theorem $^{7}$ allows me to compute $(1+n)^s$ explicitly with the formula: $\sum_{k=0}^s{s\choose k}x^k$ in which case after substitution: $$\zeta(s)=\sum_{x=0}^\infty\bigg[\sum_{k=0}^s{s\choose k}x^k\bigg]^{-1}$$ Now out of total curiosity I decided to swap the inner summation inside the big brackets and swap it out with a product, noting carefully that if I do that I need to shift the starting point in the outer summation to $1$ otherwise I would be dividing by zero. For short handedness I wrote $$\zeta_{\times}(s)=\sum_{x=1}^\infty\Bigg[\prod_{k=0}^s{s\choose k}x^k\Bigg]^{-1}$$ Numerical inspection suggested $$\zeta_{\times}(s) ={\zeta\left[{s+1 \choose 2}\right] \above 1.5pt \prod_{k=1}^s{s \choose k}}$$ I double checked my numerical hunch against Sloan's Database and encountered the paper by Lagarias. In Lieu of the fact that Lagarias has an explicit formulae for $\log G_s^*$ (see Lagarias paper or reference above for notation) I primarily became interested in computing $\log \zeta_{\times}(s).$ If I could answer the question affirmatively then I would know that $$\log \zeta_{\times}(s)=\log \zeta(|G_s|)-\log(G_s^*)$$","Question: If is it true: where is the Riemann zeta function evaluated at the triangular numbers ? I believe I can show the answer to the question is yes by way of inspection. I cannot get an actual explicit calculation that answers the question affirmatively - that is what I am asking for ! Solution to question by inspection: For short handedness I write I computed a small list of values of for small : Inspection suggests that has numerator equal to the Riemann zeta function at The denominators of can be written explicitly as ; which appear to be the integer sequence A001142 . Listed in the reference section is the following paper by Lagarias: Products of Binomial Coefficients and Unreduced Farey Fractions . . Lagarias defines the unreduced Farey fractions to be the ordered sequence of all reduced and unreduced fractions between and with denominator of size at most Following Lagarias' notation: I write for the set of unreduced Farey fractions and let and denote the cardinality and the product of all elements of respectively. Lagarias shows the following results: and I put everything together and get and I am done. Source and motivation of the problem: Curiosity is the main driving source of the problem. Here it goes: If and are positive numbers I write for the Riemann zeta function evaluated at the number For ease of typing  I write Pascal's Triangle like this: and recall that the first row in Pascal's triangle is numbered at .  Now look at the second and third rows of the triangle, highlighted in red and blue respectively and observe: and This observation shows that can be recovered from the rows of Pascal's triangle - in particular I can write On the other hand using the binomial theorem allows me to compute explicitly with the formula: in which case after substitution: Now out of total curiosity I decided to swap the inner summation inside the big brackets and swap it out with a product, noting carefully that if I do that I need to shift the starting point in the outer summation to otherwise I would be dividing by zero. For short handedness I wrote Numerical inspection suggested I double checked my numerical hunch against Sloan's Database and encountered the paper by Lagarias. In Lieu of the fact that Lagarias has an explicit formulae for (see Lagarias paper or reference above for notation) I primarily became interested in computing If I could answer the question affirmatively then I would know that","s \in \mathbb{N} \sum_{x=1}^\infty\left[\prod_{k=0}^s{s\choose k}x^k\right]^{-1}={\zeta\left[{s+1 \choose 2}\right] \above 1.5pt \prod_{k=1}^s{s \choose k}}; \zeta\left[{s+1 \choose 2}\right] ^1 ^2 \zeta_{\times}(s)=\sum_{x=1}^\infty\Bigg[\prod_{k=0}^s{s\choose k}x^k\Bigg]^{-1} \zeta_{\times}(s) s \begin{array}{ l | l }
s & 2 & 3 & 4 & 5 & 6 & 7\\ \hline
\zeta_{\times}(s) & \frac{\zeta(3)}{2} & \frac{\zeta(6)}{9} & \frac{\zeta(10)}{96} & \frac{\zeta(15)}{2500} & \frac{\zeta(21)}{162000}& \frac{\zeta(28)}{26471025}\\ 
\end{array} \zeta_{\times}(s) {s+1 \choose 2}. \zeta_{\times}(s) 2,9,96,2500,162000,\ldots ^3 ^4 ^5 0 1 s. G_s |G_s| G_s^* G_s |G_s|={s+1 \choose 2} G_s^*=\prod_{k=1}^s{s \choose k}. \zeta_{\times}(s)={\zeta\big(|G_s|\big) \above 1.5pt G_s^*} \blacksquare x s \zeta(s) s. ^{6} \text{ }\begin{matrix}
1&&&&\\
1&1&&&\\
\color{red}{1}&\color{red}{2}&\color{red}{1}&&\\
\color{blue}{1}&\color{blue}{3}&\color{blue}{3}&\color{blue}{1}&\\
1&4&6&4&1\\
\vdots
\end{matrix} 0 \sum_{x=0}^\infty{ 1 \above 1.5pt \color{red}{1}+\color{red}{2}x+\color{red}{1}x^2}=\zeta(2) \sum_{x=0}^\infty{ 1 \above 1.5pt \color{blue}{1}+\color{blue}{3}x+\color{blue}{3}x^2+\color{blue}{1}x^3}=\zeta(3). \zeta(s) \sum_{x=0}^\infty\frac{1}{(1+x)^s}=\zeta(s). ^{7} (1+n)^s \sum_{k=0}^s{s\choose k}x^k \zeta(s)=\sum_{x=0}^\infty\bigg[\sum_{k=0}^s{s\choose k}x^k\bigg]^{-1} 1 \zeta_{\times}(s)=\sum_{x=1}^\infty\Bigg[\prod_{k=0}^s{s\choose k}x^k\Bigg]^{-1} \zeta_{\times}(s) ={\zeta\left[{s+1 \choose 2}\right] \above 1.5pt \prod_{k=1}^s{s \choose k}} \log G_s^* \log \zeta_{\times}(s). \log \zeta_{\times}(s)=\log \zeta(|G_s|)-\log(G_s^*)","['sequences-and-series', 'binomial-coefficients', 'riemann-zeta', 'conjectures']"
16,How is the sequence $x_{n+1} = \frac{(x_n)^{2} + 5}{ 6}$ going to converge to 1,How is the sequence  going to converge to 1,x_{n+1} = \frac{(x_n)^{2} + 5}{ 6},"Having some trouble understanding that if $x_{1} = 4$ and the sequence where n is defined as $x_{n+1} = \frac{(x_n)^{2} + 5}{ 6}$ how is it going to converge to 1. I have solved using the L as limit and using the quadratic i get two possibilites that are 5, or 1.","Having some trouble understanding that if and the sequence where n is defined as how is it going to converge to 1. I have solved using the L as limit and using the quadratic i get two possibilites that are 5, or 1.",x_{1} = 4 x_{n+1} = \frac{(x_n)^{2} + 5}{ 6},"['sequences-and-series', 'limits', 'convergence-divergence']"
17,Closed form sum for the following series on the euclidean grid.,Closed form sum for the following series on the euclidean grid.,,"I am trying to find a closed form solution for the following series. The $\sqrt{i^2 + j^2}$ in the exponent comes from distances on the euclidean grid from the origin. $x = \sum_{i,j} e^{-\sqrt{i^2 + j^2}}$ where $i,j$ range from $0$ to infinity. It appears this expression is not a geometric series, so I have trouble analyzing it. I did some quick simulations to realize that the value converges quickly. For $i,j$ in range (0,40), and using double-precision floating point, the value converges to $2.95878712840391$ . Altering the range of $i,j$ no longer changes the sum because the incremental values are beyond the precision of the floating point decimal. I would greatly appreciate some help in approaching this series, and if there is a way to represent it in a closed form. Or if there is a way to approximate the answer to a desired precision.","I am trying to find a closed form solution for the following series. The in the exponent comes from distances on the euclidean grid from the origin. where range from to infinity. It appears this expression is not a geometric series, so I have trouble analyzing it. I did some quick simulations to realize that the value converges quickly. For in range (0,40), and using double-precision floating point, the value converges to . Altering the range of no longer changes the sum because the incremental values are beyond the precision of the floating point decimal. I would greatly appreciate some help in approaching this series, and if there is a way to represent it in a closed form. Or if there is a way to approximate the answer to a desired precision.","\sqrt{i^2 + j^2} x = \sum_{i,j} e^{-\sqrt{i^2 + j^2}} i,j 0 i,j 2.95878712840391 i,j","['sequences-and-series', 'power-series']"
18,"If $|a_1|>1$, then the series $\sum\frac{a_1^n+\cdots+a_k^n}{n}$ diverges","If , then the series  diverges",|a_1|>1 \sum\frac{a_1^n+\cdots+a_k^n}{n},"Let $a_1,...,a_k$ be complex numbers different from $1$. I am trying to prove that if at least one of them has a module strictly greater than $1$, say $|a_1|>1$, then the series $\displaystyle\sum\frac{a_1^n+\cdots+a_k^n}{n}$ diverges. I have tried to prove that $\dfrac{a_1^n+\cdots+a_k^n}{n}$ doesn't converge to $0$ as it should for the series to converge, and for that I've rewritten it as: $$ \frac{|a_1^k+\cdots+a_n^k|}{k}= \frac{|a_1|^k}{k}\Big|1+\Big(\frac{a_2}{a_1}\Big)^k +\cdots+\Big(\frac{a_n}{a_1}\Big)^k\Big| $$ I thus have to prove that the sum after the $1+\cdots,\,$ doesn't converge to $-1$, but I can't seem to do it.","Let $a_1,...,a_k$ be complex numbers different from $1$. I am trying to prove that if at least one of them has a module strictly greater than $1$, say $|a_1|>1$, then the series $\displaystyle\sum\frac{a_1^n+\cdots+a_k^n}{n}$ diverges. I have tried to prove that $\dfrac{a_1^n+\cdots+a_k^n}{n}$ doesn't converge to $0$ as it should for the series to converge, and for that I've rewritten it as: $$ \frac{|a_1^k+\cdots+a_n^k|}{k}= \frac{|a_1|^k}{k}\Big|1+\Big(\frac{a_2}{a_1}\Big)^k +\cdots+\Big(\frac{a_n}{a_1}\Big)^k\Big| $$ I thus have to prove that the sum after the $1+\cdots,\,$ doesn't converge to $-1$, but I can't seem to do it.",,"['sequences-and-series', 'complex-analysis', 'convergence-divergence']"
19,"If $\sum\limits_{i=1}^na_i=\prod\limits_{i=1}^na_i$ for every $n$, identify $\lim\limits_{n\to \infty}a_n$","If  for every , identify",\sum\limits_{i=1}^na_i=\prod\limits_{i=1}^na_i n \lim\limits_{n\to \infty}a_n,"Let $\left(a_n\right)_{n \in\mathbb{N}} $ denote a sequence of real numbers such that, for every $n\geqslant1$, $$\sum_{i=1}^na_i=\prod_{i=1}^na_i$$ Identify the limit $$\lim_{n\to \infty}a_n$$ What I have done: $$a_1-a_1=0 \\a_1+a_2-(a_1a_2)=0 \to  a_1\cdot a_2(\dfrac{a_1}{a_2}+\dfrac{a_2}{a_1}-1)=0\\.\\.\\.\\a_1\cdot a_2\cdot \cdot \cdot a_n(\dfrac{a_1}{a_2\cdot \cdot \cdot a_n}+\dfrac{a_2}{a_1\cdot \cdot \cdot a_n}+...+\dfrac{a_n}{a_2\cdot \cdot \cdot a_{n-1}}-1)=0$$ Now what do I do ?","Let $\left(a_n\right)_{n \in\mathbb{N}} $ denote a sequence of real numbers such that, for every $n\geqslant1$, $$\sum_{i=1}^na_i=\prod_{i=1}^na_i$$ Identify the limit $$\lim_{n\to \infty}a_n$$ What I have done: $$a_1-a_1=0 \\a_1+a_2-(a_1a_2)=0 \to  a_1\cdot a_2(\dfrac{a_1}{a_2}+\dfrac{a_2}{a_1}-1)=0\\.\\.\\.\\a_1\cdot a_2\cdot \cdot \cdot a_n(\dfrac{a_1}{a_2\cdot \cdot \cdot a_n}+\dfrac{a_2}{a_1\cdot \cdot \cdot a_n}+...+\dfrac{a_n}{a_2\cdot \cdot \cdot a_{n-1}}-1)=0$$ Now what do I do ?",,['sequences-and-series']
20,Use Fourier series of odd function to evaluate $1-\frac15+\frac17-\frac1{11}+\cdots$,Use Fourier series of odd function to evaluate,1-\frac15+\frac17-\frac1{11}+\cdots,"Show that the Fourier series expansion for $f(x)$ is   $$\frac2{\sqrt3}\left(\cos x-\frac{\cos5x}5+\frac{\cos7x}7-\frac{\cos11x}{11}+\cdots\right)$$   where   $$f(x)=\begin{cases}\dfrac\pi3&\text{for }x\in\left[0,\dfrac\pi3\right)\\[1ex]0&\text{for }x\in\left[\dfrac\pi3,\dfrac{2\pi}3\right)\\[1ex]-\dfrac\pi3&\text{for }x\in\left[\dfrac{2\pi}3,\pi\right)\end{cases}$$   and $f(x)=f(x+\pi)$ for all $x\in\mathbb R$. Attempt : $$f(x)=\frac{a_0}2+\sum_{n\ge1}(a_n\cos2nx+b_n\sin2nx)$$ where $$a_0=\frac2\pi\int_0^\pi f(x)\,\mathrm dx$$ $$a_n=\frac2\pi\int_0^\pi f(x)\cos2nx\,\mathrm dx$$ $$b_n=\frac2\pi\int_0^\pi f(x)\sin2nx\,\mathrm dx$$ I know that $f(x)$ is odd, so $a_0=0$ and $a_n=0$ for all $n\in\mathbb N$. For the sine series, I end up with, among several equivalent expressions, $$b_n=\frac1{3n}\left(2-\cos\frac{2n\pi}3-\cos\frac{4n\pi}3\right)$$ $$b_n=\frac2{3n}\left(\sin^2\frac{2n\pi}3+\sin^2\frac{4n\pi}3\right)$$ which gives me (using $g$ to distinguish my result from the expected $f$) $$g(x)=\sum_{n\ge1}\frac{c_n\sin2nx}n=\sin2x+\frac{\sin4x}2+\frac{\sin8x}4+\frac{\sin10x}5+\frac{\sin14x}7+\cdots$$ where $c_n=1$ if $n$ is not a multiple of $3$, and $0$ otherwise. Plotting the first few partial sums suggests that this answer is just as valid as the suggested one. Is there some manipulation I can do to my result in order to get the solution to match? Or is there another way of finding the series expansion to arrive at the cosine series directly? There is also a second part to the problem, which is to Show that   $$\frac\pi{2\sqrt3}=1-\frac15+\frac17-\frac1{11}+\cdots$$ which I can easily get from evaluating $f(x)$ and the given expansion at $x=0$: $$\frac\pi3=\frac2{\sqrt3}\left(1-\frac15+\frac17-\frac1{11}+\frac1{13}-\frac1{17}+\frac1{19}-\frac1{23}+\cdots\right)$$ but I don't immediately see a way to use $g(x)$. At first glance, choosing $x=\dfrac\pi4$ seems to be the right thing to do, but this yields $$\frac\pi3=1+\frac15-\frac17-\frac1{11}+\frac1{13}+\frac1{17}-\frac1{19}-\frac1{23}+\cdots$$","Show that the Fourier series expansion for $f(x)$ is   $$\frac2{\sqrt3}\left(\cos x-\frac{\cos5x}5+\frac{\cos7x}7-\frac{\cos11x}{11}+\cdots\right)$$   where   $$f(x)=\begin{cases}\dfrac\pi3&\text{for }x\in\left[0,\dfrac\pi3\right)\\[1ex]0&\text{for }x\in\left[\dfrac\pi3,\dfrac{2\pi}3\right)\\[1ex]-\dfrac\pi3&\text{for }x\in\left[\dfrac{2\pi}3,\pi\right)\end{cases}$$   and $f(x)=f(x+\pi)$ for all $x\in\mathbb R$. Attempt : $$f(x)=\frac{a_0}2+\sum_{n\ge1}(a_n\cos2nx+b_n\sin2nx)$$ where $$a_0=\frac2\pi\int_0^\pi f(x)\,\mathrm dx$$ $$a_n=\frac2\pi\int_0^\pi f(x)\cos2nx\,\mathrm dx$$ $$b_n=\frac2\pi\int_0^\pi f(x)\sin2nx\,\mathrm dx$$ I know that $f(x)$ is odd, so $a_0=0$ and $a_n=0$ for all $n\in\mathbb N$. For the sine series, I end up with, among several equivalent expressions, $$b_n=\frac1{3n}\left(2-\cos\frac{2n\pi}3-\cos\frac{4n\pi}3\right)$$ $$b_n=\frac2{3n}\left(\sin^2\frac{2n\pi}3+\sin^2\frac{4n\pi}3\right)$$ which gives me (using $g$ to distinguish my result from the expected $f$) $$g(x)=\sum_{n\ge1}\frac{c_n\sin2nx}n=\sin2x+\frac{\sin4x}2+\frac{\sin8x}4+\frac{\sin10x}5+\frac{\sin14x}7+\cdots$$ where $c_n=1$ if $n$ is not a multiple of $3$, and $0$ otherwise. Plotting the first few partial sums suggests that this answer is just as valid as the suggested one. Is there some manipulation I can do to my result in order to get the solution to match? Or is there another way of finding the series expansion to arrive at the cosine series directly? There is also a second part to the problem, which is to Show that   $$\frac\pi{2\sqrt3}=1-\frac15+\frac17-\frac1{11}+\cdots$$ which I can easily get from evaluating $f(x)$ and the given expansion at $x=0$: $$\frac\pi3=\frac2{\sqrt3}\left(1-\frac15+\frac17-\frac1{11}+\frac1{13}-\frac1{17}+\frac1{19}-\frac1{23}+\cdots\right)$$ but I don't immediately see a way to use $g(x)$. At first glance, choosing $x=\dfrac\pi4$ seems to be the right thing to do, but this yields $$\frac\pi3=1+\frac15-\frac17-\frac1{11}+\frac1{13}+\frac1{17}-\frac1{19}-\frac1{23}+\cdots$$",,"['sequences-and-series', 'fourier-series']"
21,Prove that for the series $\sum_{n \in \mathbb{N}}|\zeta_n\mu_n|$ to be convergent for all $\zeta \in l^p \implies \mu \in l^q$,Prove that for the series  to be convergent for all,\sum_{n \in \mathbb{N}}|\zeta_n\mu_n| \zeta \in l^p \implies \mu \in l^q,"Prove that for the series $$\sum_{n \in \mathbb{N}}|\zeta_n\mu_n|$$ to be convergent for all $$\zeta \in l^p \implies \mu \in l^q$$ I used Holder's inequality to prove that $$\sum_{n \in \mathbb{N}}|\zeta_n\mu_n| \leq \|\zeta\|_p \|\mu\|_q $$ But I cannot find a $\zeta= (\zeta_1, \zeta_2,....)$ such that $A(\zeta)=\sum_{n \in \mathbb{N}}|\zeta_n\mu_n|=(\sum_{n \in \mathbb{N}} |\mu_n|^q)^{\frac{1}{q}}$. $ \zeta=??$","Prove that for the series $$\sum_{n \in \mathbb{N}}|\zeta_n\mu_n|$$ to be convergent for all $$\zeta \in l^p \implies \mu \in l^q$$ I used Holder's inequality to prove that $$\sum_{n \in \mathbb{N}}|\zeta_n\mu_n| \leq \|\zeta\|_p \|\mu\|_q $$ But I cannot find a $\zeta= (\zeta_1, \zeta_2,....)$ such that $A(\zeta)=\sum_{n \in \mathbb{N}}|\zeta_n\mu_n|=(\sum_{n \in \mathbb{N}} |\mu_n|^q)^{\frac{1}{q}}$. $ \zeta=??$",,"['sequences-and-series', 'functional-analysis', 'operator-theory']"
22,The Perfect Sharing Algorithm (ABBABAAB...),The Perfect Sharing Algorithm (ABBABAAB...),,"Less of a question and more of an exercise, it has to do with something I found while doing some programming and being unable to find things. Basically I wanted a formula for the perfect sharing algorithm as I call it,(ABBABAABBAABABBA...), I don't know the proper name of the sequence but it's used for truly fair sharing between 2 people. I couldn't find a formula so I figured this out after a while. Start with AB Every A turns into an AB and every B turns into a BA. AB -> ABBA -> ABBABAAB ... This allowed me to get a computer to achieve the algorithm in many ways, but it also raised some questions. Question 1: Can I repeat this forever and have it properly generate the algorithm? The algorithm is normally created by taking AB, then inverting each 2-state 'digit' and sticking it on the end (ABBA). You then take this entire sequence and repeat the process (ABBABAAB). This is an infinite sequence. Is what I'm doing going to generate the same sequence as the second method? Question 2. 2 people decide they want to share a task, so they use this algorithm. a) If they know how many turns have occurred but forget who's turn it is, can they generate an equation that tells them who's turn it is given the number of turns that have passed? b) The 2 people forget where they are in the sequence, but they know who's turn it is right now. How many previous turns will they need to remember in order to find their place again under the worse possible scenario?","Less of a question and more of an exercise, it has to do with something I found while doing some programming and being unable to find things. Basically I wanted a formula for the perfect sharing algorithm as I call it,(ABBABAABBAABABBA...), I don't know the proper name of the sequence but it's used for truly fair sharing between 2 people. I couldn't find a formula so I figured this out after a while. Start with AB Every A turns into an AB and every B turns into a BA. AB -> ABBA -> ABBABAAB ... This allowed me to get a computer to achieve the algorithm in many ways, but it also raised some questions. Question 1: Can I repeat this forever and have it properly generate the algorithm? The algorithm is normally created by taking AB, then inverting each 2-state 'digit' and sticking it on the end (ABBA). You then take this entire sequence and repeat the process (ABBABAAB). This is an infinite sequence. Is what I'm doing going to generate the same sequence as the second method? Question 2. 2 people decide they want to share a task, so they use this algorithm. a) If they know how many turns have occurred but forget who's turn it is, can they generate an equation that tells them who's turn it is given the number of turns that have passed? b) The 2 people forget where they are in the sequence, but they know who's turn it is right now. How many previous turns will they need to remember in order to find their place again under the worse possible scenario?",,"['sequences-and-series', 'recurrence-relations', 'fractals', 'infinite-groups']"
23,Prove $\int_0^{\pi/2} J_0 (\cos x) dx=\frac{\pi}{2} \left(J_0 \left(\frac{1}{2} \right)\right)^2$,Prove,\int_0^{\pi/2} J_0 (\cos x) dx=\frac{\pi}{2} \left(J_0 \left(\frac{1}{2} \right)\right)^2,"I got curious about this integral because we have the following identity: $$\frac{2}{\pi}\int_0^{\pi/2} \cos (x\cos t) dt=J_0(x)$$ So we have an interesting (if useless) symmetry: $$\int_0^{\pi/2} J_0 (\cos x) dx=\frac{2}{\pi}\int_0^{\pi/2}\int_0^{\pi/2} \cos (\cos x \cos t) ~dt~dx=\int_0^{\pi/2} J_0 (\cos t) dt$$ Wolfram Alpha doesn't show a closed form for this integral. However, if we use the series for the Bessel function: $$J_0(x)=\sum_{k=0}^\infty \frac{(-1)^k x^{2k}}{4^kk!^2}$$ And the known closed form for the family of integrals: $$\int_0^{\pi/2} \cos^{2k} (x) dx=\frac{\sqrt{\pi}}{2}\frac{\Gamma \left(k+\frac{1}{2} \right)}{k!}$$ We obtain: $$\int_0^{\pi/2} J_0 (\cos x) dx=\frac{\sqrt{\pi}}{2} \sum_{k=0}^\infty \frac{(-1)^k \Gamma \left(k+\frac{1}{2} \right)}{4^kk!^3}$$ Wolfram Alpha evaluates this series, giving a closed form for the integral: $$\int_0^{\pi/2} J_0 (\cos x) dx=\frac{\pi}{2} \left(J_0 \left(\frac{1}{2} \right)\right)^2=1.3834405\dots$$ This agrees with the numerical value. However, I have not been able to show this myself. How do we prove this closed form? Is there a more general case, involving Bessel functions of order $n$?","I got curious about this integral because we have the following identity: $$\frac{2}{\pi}\int_0^{\pi/2} \cos (x\cos t) dt=J_0(x)$$ So we have an interesting (if useless) symmetry: $$\int_0^{\pi/2} J_0 (\cos x) dx=\frac{2}{\pi}\int_0^{\pi/2}\int_0^{\pi/2} \cos (\cos x \cos t) ~dt~dx=\int_0^{\pi/2} J_0 (\cos t) dt$$ Wolfram Alpha doesn't show a closed form for this integral. However, if we use the series for the Bessel function: $$J_0(x)=\sum_{k=0}^\infty \frac{(-1)^k x^{2k}}{4^kk!^2}$$ And the known closed form for the family of integrals: $$\int_0^{\pi/2} \cos^{2k} (x) dx=\frac{\sqrt{\pi}}{2}\frac{\Gamma \left(k+\frac{1}{2} \right)}{k!}$$ We obtain: $$\int_0^{\pi/2} J_0 (\cos x) dx=\frac{\sqrt{\pi}}{2} \sum_{k=0}^\infty \frac{(-1)^k \Gamma \left(k+\frac{1}{2} \right)}{4^kk!^3}$$ Wolfram Alpha evaluates this series, giving a closed form for the integral: $$\int_0^{\pi/2} J_0 (\cos x) dx=\frac{\pi}{2} \left(J_0 \left(\frac{1}{2} \right)\right)^2=1.3834405\dots$$ This agrees with the numerical value. However, I have not been able to show this myself. How do we prove this closed form? Is there a more general case, involving Bessel functions of order $n$?",,"['sequences-and-series', 'definite-integrals', 'special-functions', 'bessel-functions']"
24,Computing alternating sum using contour integration,Computing alternating sum using contour integration,,"By considering the integral of: $$\left(\frac{\sin\alpha z}{\alpha z}\right)^2 \frac{\pi}{\sin \pi z},\quad \alpha<\frac{\pi}{2}$$ around a circle of large radius, prove that: $$\sum\limits_{n=1}^\infty (-1)^{m-1} \frac{\sin ^2 m\alpha}{(m \alpha)^2} = \frac{1}{2}$$ Attempt at answer: I can see that I have poles at $z=n$ , and a double pole at $z=0$ . So in order to perform the contour integration, I first find the residues for $z=n$ : $$\frac{\pi}{\sin\pi z} = \frac{1}{z} \left( 1 + \frac{(\pi z)^2}{3!} + ...\right)$$ the $1/z$ part is equal to $1$ , so the residues are $$\sum\limits_{n=-N}^N \frac{\sin ^2 n\alpha}{(n \alpha)^2}$$ Next, finding the residue at $z=0$ : I found it to be $=1$ , by series expansion. I know that if I let my function tend to zero as the contour encloses all the poles, I have that: $$2\pi i \left(2 \sum\limits_{n=1}^\infty \frac{\sin ^2 n\alpha}{(n \alpha)^2} + 1\right) = 0$$ So I'm very almost there - but I have no idea where the $(-1)^{m-1}$ factor comes from, and also - if I rearrange the last equation, I get that the sum is $-\frac{1}{2}$ (i.e. not positive). If anyone could help find where I'm going wrong, that would be great!","By considering the integral of: around a circle of large radius, prove that: Attempt at answer: I can see that I have poles at , and a double pole at . So in order to perform the contour integration, I first find the residues for : the part is equal to , so the residues are Next, finding the residue at : I found it to be , by series expansion. I know that if I let my function tend to zero as the contour encloses all the poles, I have that: So I'm very almost there - but I have no idea where the factor comes from, and also - if I rearrange the last equation, I get that the sum is (i.e. not positive). If anyone could help find where I'm going wrong, that would be great!","\left(\frac{\sin\alpha z}{\alpha z}\right)^2 \frac{\pi}{\sin \pi z},\quad \alpha<\frac{\pi}{2} \sum\limits_{n=1}^\infty (-1)^{m-1} \frac{\sin ^2 m\alpha}{(m \alpha)^2} = \frac{1}{2} z=n z=0 z=n \frac{\pi}{\sin\pi z} = \frac{1}{z} \left( 1 + \frac{(\pi z)^2}{3!} + ...\right) 1/z 1 \sum\limits_{n=-N}^N \frac{\sin ^2 n\alpha}{(n \alpha)^2} z=0 =1 2\pi i \left(2 \sum\limits_{n=1}^\infty \frac{\sin ^2 n\alpha}{(n \alpha)^2} + 1\right) = 0 (-1)^{m-1} -\frac{1}{2}","['sequences-and-series', 'complex-analysis', 'contour-integration', 'complex-integration']"
25,What do we know about $\sum_\limits{n=0}^{\infty} \frac{(-1)^n}{kn+1}$?,What do we know about ?,\sum_\limits{n=0}^{\infty} \frac{(-1)^n}{kn+1},"Let define, for $k \ge 1$ : $$ f(k) = \sum_\limits{n=0}^{\infty} \frac{(-1)^n}{kn+1}. $$ It is well-known that $f(1) = \ln(2), f(2) = \pi/4$. Some computations on WolframAlpha led me to $f(3) =1/9 (\sqrt3 \pi+\ln(8))$, $f(4) = (\pi+2 \ln(1+\sqrt2))/(4 \sqrt2)$ and also (if I'm not mistaken) : $$ f(5) = 1/b \cdot \Big(\frac{8\sqrt2}{\sqrt a} \;\pi \;-\; 6 (\sqrt5 - 1)\ln(2) \;+\; 2 (3-\sqrt5)\ln(\sqrt 5 + 1)\\ - 4 \ln(\sqrt5 - 1) \;+\; (\sqrt5 - 5)\ln\Big( \frac{\bar a}{a} \Big) \Big)$$ with $a = 5+\sqrt5, \bar a = 5-\sqrt5,b=20(\sqrt 5 - 1)$. Then, I would like to ask the following : is it true that (for general $k \geq 1$) $f(k) \in \overline{ \mathbb Q} (A)$ where $A = \{ \pi \} \cup \{ \ln(x) \mid x \in \overline{ \mathbb Q} \cap \mathbb R \}$, as it seems to be the case for small values of $k$ ? Are there some available results on these series? I looked at some special functions : this result on the digamma function is related to my question. I don't know if it is possible to use this result in order to compute $f(k)$. Any comment or answer would be appreciated!","Let define, for $k \ge 1$ : $$ f(k) = \sum_\limits{n=0}^{\infty} \frac{(-1)^n}{kn+1}. $$ It is well-known that $f(1) = \ln(2), f(2) = \pi/4$. Some computations on WolframAlpha led me to $f(3) =1/9 (\sqrt3 \pi+\ln(8))$, $f(4) = (\pi+2 \ln(1+\sqrt2))/(4 \sqrt2)$ and also (if I'm not mistaken) : $$ f(5) = 1/b \cdot \Big(\frac{8\sqrt2}{\sqrt a} \;\pi \;-\; 6 (\sqrt5 - 1)\ln(2) \;+\; 2 (3-\sqrt5)\ln(\sqrt 5 + 1)\\ - 4 \ln(\sqrt5 - 1) \;+\; (\sqrt5 - 5)\ln\Big( \frac{\bar a}{a} \Big) \Big)$$ with $a = 5+\sqrt5, \bar a = 5-\sqrt5,b=20(\sqrt 5 - 1)$. Then, I would like to ask the following : is it true that (for general $k \geq 1$) $f(k) \in \overline{ \mathbb Q} (A)$ where $A = \{ \pi \} \cup \{ \ln(x) \mid x \in \overline{ \mathbb Q} \cap \mathbb R \}$, as it seems to be the case for small values of $k$ ? Are there some available results on these series? I looked at some special functions : this result on the digamma function is related to my question. I don't know if it is possible to use this result in order to compute $f(k)$. Any comment or answer would be appreciated!",,"['sequences-and-series', 'reference-request', 'digamma-function']"
26,how do I find the general term here?,how do I find the general term here?,,I am getting crazy on this series! I found this in a handwritten old book without a reference. I could not figure out how it is built but the series numerically seems to converge to $\pi$. \begin{align} a_1&=\frac{16}{3}\\ a_2&=\frac{56}{15}\\ a_3&=\frac{362}{105}\\ a_4&=\frac{1051}{315}\\ a_5&=\frac{90913}{27720}\\ a_6&=\frac{2339483}{720720}\\ a_7&=\frac{9294869}{2882880}\\ a_8&=\frac{314539061}{98017920}\\ a_9&=\frac{95291361359}{29797447680}\\ a_{10}&=\frac{27155335099}{8513556480}\\ a_{11}&=\frac{2493237983453}{783247196160}\\ a_{12}&=\frac{24892232679053}{7832471961600}\\ a_{13}&=\frac{596632945162997}{187979327078400}\\ a_{14}&=\frac{34567420288501151}{10902800970547200}\\ a_{15}&=\frac{4282497882211187099}{1351947320347852800}\\ a_{16}&=\frac{8558465078579558323}{2703894640695705600}\\ ...\\ a_{\infty}&=\pi \end{align} I have observed that the denominators include multiplication of odd numbers while $2^j$ is also always around. Sometimes the odd numbers appear in a row sometimes they are not in order. For the numerator I do not see much of a pattern!,I am getting crazy on this series! I found this in a handwritten old book without a reference. I could not figure out how it is built but the series numerically seems to converge to $\pi$. \begin{align} a_1&=\frac{16}{3}\\ a_2&=\frac{56}{15}\\ a_3&=\frac{362}{105}\\ a_4&=\frac{1051}{315}\\ a_5&=\frac{90913}{27720}\\ a_6&=\frac{2339483}{720720}\\ a_7&=\frac{9294869}{2882880}\\ a_8&=\frac{314539061}{98017920}\\ a_9&=\frac{95291361359}{29797447680}\\ a_{10}&=\frac{27155335099}{8513556480}\\ a_{11}&=\frac{2493237983453}{783247196160}\\ a_{12}&=\frac{24892232679053}{7832471961600}\\ a_{13}&=\frac{596632945162997}{187979327078400}\\ a_{14}&=\frac{34567420288501151}{10902800970547200}\\ a_{15}&=\frac{4282497882211187099}{1351947320347852800}\\ a_{16}&=\frac{8558465078579558323}{2703894640695705600}\\ ...\\ a_{\infty}&=\pi \end{align} I have observed that the denominators include multiplication of odd numbers while $2^j$ is also always around. Sometimes the odd numbers appear in a row sometimes they are not in order. For the numerator I do not see much of a pattern!,,['sequences-and-series']
27,Proving that $\sum_{i=1}^n\frac{a_i}{1-a_i}\leq\sum_{i=1}^n\frac{b_i}{1-b_i}$,Proving that,\sum_{i=1}^n\frac{a_i}{1-a_i}\leq\sum_{i=1}^n\frac{b_i}{1-b_i},"Suppose $a_1,a_2,...,a_n>0$ and $\sum_{i=1}^na_i=1$.  Define $b_1,b_2,...,b_n$ by     $b_i=\frac{a_i^2}{\sum_{j=1}^n(a_j^2)}$.  Show that $$\sum_{i=1}^n\frac{a_i}{1-a_i}\leq\sum_{i=1}^n\frac{b_i}{1-b_i}$$. I have been unable to make any substantial progress. I've noticed that $\sum b_i=1$ also. Letting $A_n=\sum_{i=1}^n\frac{a_i}{1-a_i}$, $B_n=\sum_{i=1}^n\frac{b_i}{1-b_i}$,  both $A_n$ and $B_n$ are greater than one, and more precisely $B_n\geq\frac{n}{n-1}$. But nothing I've found seems particularly useful. I found that the problem simplifies to $\sum_{i=1}^n\frac{1}{1-a_i}\leq\sum_{i=1}^n\frac{1}{1-b_i}$, but without further progression. Can anyone help me solve this question? Question comes from 2014 Irish Mathematical Olympiad","Suppose $a_1,a_2,...,a_n>0$ and $\sum_{i=1}^na_i=1$.  Define $b_1,b_2,...,b_n$ by     $b_i=\frac{a_i^2}{\sum_{j=1}^n(a_j^2)}$.  Show that $$\sum_{i=1}^n\frac{a_i}{1-a_i}\leq\sum_{i=1}^n\frac{b_i}{1-b_i}$$. I have been unable to make any substantial progress. I've noticed that $\sum b_i=1$ also. Letting $A_n=\sum_{i=1}^n\frac{a_i}{1-a_i}$, $B_n=\sum_{i=1}^n\frac{b_i}{1-b_i}$,  both $A_n$ and $B_n$ are greater than one, and more precisely $B_n\geq\frac{n}{n-1}$. But nothing I've found seems particularly useful. I found that the problem simplifies to $\sum_{i=1}^n\frac{1}{1-a_i}\leq\sum_{i=1}^n\frac{1}{1-b_i}$, but without further progression. Can anyone help me solve this question? Question comes from 2014 Irish Mathematical Olympiad",,"['sequences-and-series', 'inequality', 'contest-math']"
28,"Exploring $ \sum_{n=0}^\infty \frac{n^p}{n!} = B_pe$, particularly $p = 2$.","Exploring , particularly .", \sum_{n=0}^\infty \frac{n^p}{n!} = B_pe p = 2,"I was exploring the fact that $$ \sum_{n=0}^\infty \frac{n^p}{n!} = B_pe,$$ where $B_n$ is the $n$th Bell number. I found this result by exploring the series on wolframalpha and looking up the sequence of numbers generated. I have no experience with Bell numbers other than knowing that they represent the number of ways of partitioning a set. What I tried Looking at the base case we can verify $$\sum_{n=0}^\infty \frac{n}{n!} = \sum_{n=1}^\infty \frac{1}{(n-1)!} = e. $$ But then I realize that $n^2$ is going to be difficult. Specifically what I want I am doing this for fun, so I just want to glean some sort of lesson out of this. Resources that let me learn for myself are just as good! An accepted answer will have any one of the following: A proof that $\sum_{n = 0}^{\infty} \frac{n^2}{n!} = 2e$ (this interests me a lot) A description of why this series is related to Bell numbers and the number of partitions of a set A link to some resource that introduces Bell numbers and/or their connection to this series.","I was exploring the fact that $$ \sum_{n=0}^\infty \frac{n^p}{n!} = B_pe,$$ where $B_n$ is the $n$th Bell number. I found this result by exploring the series on wolframalpha and looking up the sequence of numbers generated. I have no experience with Bell numbers other than knowing that they represent the number of ways of partitioning a set. What I tried Looking at the base case we can verify $$\sum_{n=0}^\infty \frac{n}{n!} = \sum_{n=1}^\infty \frac{1}{(n-1)!} = e. $$ But then I realize that $n^2$ is going to be difficult. Specifically what I want I am doing this for fun, so I just want to glean some sort of lesson out of this. Resources that let me learn for myself are just as good! An accepted answer will have any one of the following: A proof that $\sum_{n = 0}^{\infty} \frac{n^2}{n!} = 2e$ (this interests me a lot) A description of why this series is related to Bell numbers and the number of partitions of a set A link to some resource that introduces Bell numbers and/or their connection to this series.",,"['sequences-and-series', 'combinatorics']"
29,An alternating series identity with a hidden hyperbolic tangent,An alternating series identity with a hidden hyperbolic tangent,,"How does one use the inverse Mellin transform to prove that the following identity holds? $$\sum_{n=1}^{\infty}\frac{(-1)^n}{n(e^{n\pi} + 1)} = \frac{1}{8}(\pi - 5\log(2))$$ The identity follows from MO189199 and the penultimate identity on this page (for $x=\frac{1}{2}$). Scratch-work: I computed the Mellin transform of $$f(x) = \frac{(-1)^x}{x(e^{x\pi} + 1)}$$ and re-wrote the function in terms of its inverse Mellin Transform as (substituting $x = n$) $$\sum_{n=1}^{\infty}\frac{(-1)^n}{n(e^{n\pi} + 1)} = \frac{1}{2\pi i}\int_{C} (2 \pi)^{1-s} \Gamma(s-1)\big(\zeta(s-1, \frac{1}{2} - \frac{i}{2}) - \zeta(s-1, 1-\frac{i}{2})\big)\zeta(s)ds$$ But I am not altogether confident that this has been computed correctly, and I am still not sure how to find the poles and compute the residues. For example, checking for a residue at $s=0$ gives $$\frac{1}{8}(\pi - 2\pi i)$$ There seems to be a nontrivial contribution at $s = 1$ and $s = -1$ as well, but already the mathematics has exceeded what I understand; I am especially unclear with regard to how one accounts for residues with respect to the generalized Riemann zeta function $\zeta(s,a)$. Clarity on using this approach or another to demonstrate the main identity would be appreciated!","How does one use the inverse Mellin transform to prove that the following identity holds? $$\sum_{n=1}^{\infty}\frac{(-1)^n}{n(e^{n\pi} + 1)} = \frac{1}{8}(\pi - 5\log(2))$$ The identity follows from MO189199 and the penultimate identity on this page (for $x=\frac{1}{2}$). Scratch-work: I computed the Mellin transform of $$f(x) = \frac{(-1)^x}{x(e^{x\pi} + 1)}$$ and re-wrote the function in terms of its inverse Mellin Transform as (substituting $x = n$) $$\sum_{n=1}^{\infty}\frac{(-1)^n}{n(e^{n\pi} + 1)} = \frac{1}{2\pi i}\int_{C} (2 \pi)^{1-s} \Gamma(s-1)\big(\zeta(s-1, \frac{1}{2} - \frac{i}{2}) - \zeta(s-1, 1-\frac{i}{2})\big)\zeta(s)ds$$ But I am not altogether confident that this has been computed correctly, and I am still not sure how to find the poles and compute the residues. For example, checking for a residue at $s=0$ gives $$\frac{1}{8}(\pi - 2\pi i)$$ There seems to be a nontrivial contribution at $s = 1$ and $s = -1$ as well, but already the mathematics has exceeded what I understand; I am especially unclear with regard to how one accounts for residues with respect to the generalized Riemann zeta function $\zeta(s,a)$. Clarity on using this approach or another to demonstrate the main identity would be appreciated!",,"['sequences-and-series', 'integral-transforms', 'hyperbolic-functions', 'exponential-sum']"
30,Evaluting sum $\sum \limits_{n=0}^\infty\frac{n^k}{n!}$,Evaluting sum,\sum \limits_{n=0}^\infty\frac{n^k}{n!},"Inspired by this question ,I was interested if the following sum has a closed form.Looking for $k$ integer I found the Dobinski's formula so that the sum when $k$ is natural number is $e\cdot B_k$ where $B_k$ is the $k$-th Bell number.I am interested if it's known whether the sum $$\sum_{n=0}^\infty\frac{n^k}{n!}$$ has a closed form for some other values of $k$.","Inspired by this question ,I was interested if the following sum has a closed form.Looking for $k$ integer I found the Dobinski's formula so that the sum when $k$ is natural number is $e\cdot B_k$ where $B_k$ is the $k$-th Bell number.I am interested if it's known whether the sum $$\sum_{n=0}^\infty\frac{n^k}{n!}$$ has a closed form for some other values of $k$.",,"['sequences-and-series', 'closed-form']"
31,Prove Divisibility In Fibonacci Sequence Over A Prime Number,Prove Divisibility In Fibonacci Sequence Over A Prime Number,,"In The Fibonacci sequence which is defined as $$ F_n=F_{n-1}+F_{n-2}, $$ lets say we have the number $p$ which is an odd prime. Prove that: $F_{p-1} + F_{p+1} -1$ Is divisible by $p$. Prove that for any given $n$ real positive integer: $F_{p^{n+1}-1} + F_{p^{n+1}+1} -(F_{p^{n}-1} + F_{p^{n}+1})$ Is divisible by $p^{n+1}$ How to prove this?","In The Fibonacci sequence which is defined as $$ F_n=F_{n-1}+F_{n-2}, $$ lets say we have the number $p$ which is an odd prime. Prove that: $F_{p-1} + F_{p+1} -1$ Is divisible by $p$. Prove that for any given $n$ real positive integer: $F_{p^{n+1}-1} + F_{p^{n+1}+1} -(F_{p^{n}-1} + F_{p^{n}+1})$ Is divisible by $p^{n+1}$ How to prove this?",,"['sequences-and-series', 'number-theory', 'divisibility', 'problem-solving', 'fibonacci-numbers']"
32,Infinite sequence of $3$ numbers with nonrepeated parts.,Infinite sequence of  numbers with nonrepeated parts.,3,I am thinking about this problem. Can we construct infinite sequence with $3$ numbers so that no repeated parts exist in it? There should not be subsequence with $2k$ numbers so that its left and right parts are the same. This is such a sequence $1 0 1 2 0 2 1 0 2 0 1 0 2 1 0 1 2 0 2 1 $. The question is can we give a algorithm to continue it infinity. It is clear that we can't do it if there are only $2$ numbers.,I am thinking about this problem. Can we construct infinite sequence with $3$ numbers so that no repeated parts exist in it? There should not be subsequence with $2k$ numbers so that its left and right parts are the same. This is such a sequence $1 0 1 2 0 2 1 0 2 0 1 0 2 1 0 1 2 0 2 1 $. The question is can we give a algorithm to continue it infinity. It is clear that we can't do it if there are only $2$ numbers.,,"['sequences-and-series', 'algorithms']"
33,Sums $\sum_{k = 0}^n k^t {n \choose k}$ where $t$ is a positive integer,Sums  where  is a positive integer,\sum_{k = 0}^n k^t {n \choose k} t,"I recently came across the problem of finding out the sum $\sum_{k = 0}^n k^2 {n \choose k}$. The solution that I've found goes something like this: $\sum_{k = 0}^n k^2 {n \choose k}=\sum_{k = 0}^n k(k-1) {n \choose k} + \sum_{k = 0}^n k {n \choose k}$. Using the fact that $\sum_{k = 0}^n k {n \choose k}=n2^{n-1}$ and that $\sum_{k = 0}^n k(k-1) {n \choose k}  =[\sum_{k = 0}^n (x^k)'' {n \choose k}]|_{x=1}=[\sum_{k = 0}^n (x^k) {n \choose k}]'' |_{x=1}=[(x+1)^n]'' |_{x=1} = n(n-1)2^{n-2}$ (where we use the binomial expansion $(x+1)^n=\sum_{k = 0}^n x^k {n \choose k}$), one can easily evaluate the desired sum as being equal to $n(n+1)2^{n-3}$. Clearly, one can continue this method to find (recursively) formulas for the sums $\sum_{k = 0}^n k^t {n \choose k}$ where $t$ is a positive integer. For example, one more iteration gives $\sum_{k = 0}^n k^3 {n \choose k}=n^2(n+3)2^{n-3}$ (if I did not made any calculation error). So, if we define $F(t)$ to be the polynomial such that $\sum_{k = 0}^n k^t {n \choose k} = 2^{n-t} F(t)$, my question is simply: Is there a closed formula for $F(t)$? Also, I would be happy with any reference on this kind of sums. Thank you!","I recently came across the problem of finding out the sum $\sum_{k = 0}^n k^2 {n \choose k}$. The solution that I've found goes something like this: $\sum_{k = 0}^n k^2 {n \choose k}=\sum_{k = 0}^n k(k-1) {n \choose k} + \sum_{k = 0}^n k {n \choose k}$. Using the fact that $\sum_{k = 0}^n k {n \choose k}=n2^{n-1}$ and that $\sum_{k = 0}^n k(k-1) {n \choose k}  =[\sum_{k = 0}^n (x^k)'' {n \choose k}]|_{x=1}=[\sum_{k = 0}^n (x^k) {n \choose k}]'' |_{x=1}=[(x+1)^n]'' |_{x=1} = n(n-1)2^{n-2}$ (where we use the binomial expansion $(x+1)^n=\sum_{k = 0}^n x^k {n \choose k}$), one can easily evaluate the desired sum as being equal to $n(n+1)2^{n-3}$. Clearly, one can continue this method to find (recursively) formulas for the sums $\sum_{k = 0}^n k^t {n \choose k}$ where $t$ is a positive integer. For example, one more iteration gives $\sum_{k = 0}^n k^3 {n \choose k}=n^2(n+3)2^{n-3}$ (if I did not made any calculation error). So, if we define $F(t)$ to be the polynomial such that $\sum_{k = 0}^n k^t {n \choose k} = 2^{n-t} F(t)$, my question is simply: Is there a closed formula for $F(t)$? Also, I would be happy with any reference on this kind of sums. Thank you!",,"['sequences-and-series', 'combinatorics', 'summation', 'binomial-coefficients']"
34,How to simplify this summation: $\sum\limits_{k=0}^\infty \frac1{4!} \cdot \frac{k^7}{2^k}$,How to simplify this summation:,\sum\limits_{k=0}^\infty \frac1{4!} \cdot \frac{k^7}{2^k},"I was wondering how to solve this infinite sum. $$\sum_{k=0}^\infty {1\over 4!} \cdot {k^7\over2^k}$$ I know roughly that for $$\sum_{k=0}^\infty {k \over 2^k}$$ the sum takes advantage of the derivative of $(1-x)^{-1}$ to get the result, but I'm not full clear on that as well as how to extend it to the $k^7$ properly.  Or is there a better way to go about this problem?","I was wondering how to solve this infinite sum. $$\sum_{k=0}^\infty {1\over 4!} \cdot {k^7\over2^k}$$ I know roughly that for $$\sum_{k=0}^\infty {k \over 2^k}$$ the sum takes advantage of the derivative of $(1-x)^{-1}$ to get the result, but I'm not full clear on that as well as how to extend it to the $k^7$ properly.  Or is there a better way to go about this problem?",,['sequences-and-series']
35,Convergence of differentiated power series,Convergence of differentiated power series,,"Consider $\displaystyle f(z)=\sum_{k=0}^\infty a_k z^k$ and suppose that $\displaystyle\sum_{n=0}^\infty f^{(n)}(0)$ converges. Prove that $\forall z \in \mathbb C, \displaystyle\sum_{n=0}^\infty f^{(n)}(z)$ converges. I'm pretty stumped on this one. The convergence $\displaystyle\sum_{n=0}^\infty f^{(n)}(0)$ indicates that $\displaystyle\sum_{n=0}^\infty n! a_n$ converges. What then ? Any hint is appreciated.",Consider and suppose that converges. Prove that converges. I'm pretty stumped on this one. The convergence indicates that converges. What then ? Any hint is appreciated.,"\displaystyle f(z)=\sum_{k=0}^\infty a_k z^k \displaystyle\sum_{n=0}^\infty f^{(n)}(0) \forall z \in \mathbb C, \displaystyle\sum_{n=0}^\infty f^{(n)}(z) \displaystyle\sum_{n=0}^\infty f^{(n)}(0) \displaystyle\sum_{n=0}^\infty n! a_n","['sequences-and-series', 'power-series']"
36,$u_{n+1}-u_n-u_n^2\to 0$ implies $u_n$ goes either to $0$ or to $+\infty$,implies  goes either to  or to,u_{n+1}-u_n-u_n^2\to 0 u_n 0 +\infty,"Let $u_n$ be a real sequence such that $\displaystyle u_{n+1}-u_n-u_n^2\to_{\infty} 0$ . Prove that either $u_n\to 0$ or $u_n \to +\infty$ Progress If $u_n$ is bounded, it has a convergent subsequence $u_{n_k}$ that goes to $\beta$ . By assumption, $\displaystyle u_{n_k+1}\to \beta^2+\beta$ This proves that if $\beta$ is an accumulation point of $u_n$ , then $\beta^2+\beta$ also is. This forces $\beta \in (-2,0]$ (otherwise the sequence is not bounded) And in this case, iterating and using the closedness of the set of accumulation points yields that $0$ is an accumulation point of $u_n$ . I should prove next that $\beta=0$ , but I can't. EDIT : the crucial point that I missed is going backward (rewriting $u_n-u_{n-1}-u_{n-1}^2\to 0$ ), as Krokop did in his answer. If $u_n$ is unbounded, $u_n$ has a subsequence that goes to $+|-\infty$ . EDIT : this part still lacks a slick and elegant proof","Let be a real sequence such that . Prove that either or Progress If is bounded, it has a convergent subsequence that goes to . By assumption, This proves that if is an accumulation point of , then also is. This forces (otherwise the sequence is not bounded) And in this case, iterating and using the closedness of the set of accumulation points yields that is an accumulation point of . I should prove next that , but I can't. EDIT : the crucial point that I missed is going backward (rewriting ), as Krokop did in his answer. If is unbounded, has a subsequence that goes to . EDIT : this part still lacks a slick and elegant proof","u_n \displaystyle u_{n+1}-u_n-u_n^2\to_{\infty} 0 u_n\to 0 u_n \to +\infty u_n u_{n_k} \beta \displaystyle u_{n_k+1}\to \beta^2+\beta \beta u_n \beta^2+\beta \beta \in (-2,0] 0 u_n \beta=0 u_n-u_{n-1}-u_{n-1}^2\to 0 u_n u_n +|-\infty",['sequences-and-series']
37,How prove $a_{n}=[\sqrt{2}n]+[\sqrt{5}n]$ Contains infinitely even numbers.,How prove  Contains infinitely even numbers.,a_{n}=[\sqrt{2}n]+[\sqrt{5}n],"let sequence $$a_{n}=[\sqrt{2}n]+[\sqrt{5}n]$$ where $[x]$  is  the largest integer not greater than $x$ show that  $\{a_{n}\}$  Contains infinitely   even numbers. also I guess contains infinitely odd numbers. before I have ask this How prove this sequence $S_{n}=[2^n\cdot \sqrt{2}],n\in N$ contains infinitely many composite numbers I found :  $$a_{2}=[2\sqrt{2}]+[2\sqrt{5}]=2+4=6$$ $$a_{3}=[3\sqrt{2}]+[3\sqrt{5}]=4+6=10$$ $$a_{5}=[5\sqrt{2}]+[5\sqrt{5}]=7+11=18$$ $$a_{7}=[7\sqrt{2}]+[7\sqrt{5}]=9+15=24$$ $$a_{8}=[8\sqrt{2}]+[8\sqrt{5}]=11+17=28$$ $$a_{9}=[9\sqrt{2}]+[9\sqrt{5}]=12+20=32$$ $$a_{10}=[10\sqrt{2}]+[10\sqrt{5}]=14+22=36$$ $$a_{12}=[12\sqrt{2}]+[12\sqrt{5}]=16+26=42$$ $$a_{14}=[14\sqrt{2}]+[14\sqrt{5}]=19+31=50$$ $$a_{15}=[15\sqrt{2}]+[15\sqrt{5}]=21+33=54$$ and so on  this problem is my found it. It seem this is interesting problem,and How prove it? Thank you","let sequence $$a_{n}=[\sqrt{2}n]+[\sqrt{5}n]$$ where $[x]$  is  the largest integer not greater than $x$ show that  $\{a_{n}\}$  Contains infinitely   even numbers. also I guess contains infinitely odd numbers. before I have ask this How prove this sequence $S_{n}=[2^n\cdot \sqrt{2}],n\in N$ contains infinitely many composite numbers I found :  $$a_{2}=[2\sqrt{2}]+[2\sqrt{5}]=2+4=6$$ $$a_{3}=[3\sqrt{2}]+[3\sqrt{5}]=4+6=10$$ $$a_{5}=[5\sqrt{2}]+[5\sqrt{5}]=7+11=18$$ $$a_{7}=[7\sqrt{2}]+[7\sqrt{5}]=9+15=24$$ $$a_{8}=[8\sqrt{2}]+[8\sqrt{5}]=11+17=28$$ $$a_{9}=[9\sqrt{2}]+[9\sqrt{5}]=12+20=32$$ $$a_{10}=[10\sqrt{2}]+[10\sqrt{5}]=14+22=36$$ $$a_{12}=[12\sqrt{2}]+[12\sqrt{5}]=16+26=42$$ $$a_{14}=[14\sqrt{2}]+[14\sqrt{5}]=19+31=50$$ $$a_{15}=[15\sqrt{2}]+[15\sqrt{5}]=21+33=54$$ and so on  this problem is my found it. It seem this is interesting problem,and How prove it? Thank you",,"['sequences-and-series', 'number-theory']"
38,How to find the sum of $i(i+1)\cdots(i+k)$ for fixed $k$ between $i = 1$ and $n$? [duplicate],How to find the sum of  for fixed  between  and ? [duplicate],i(i+1)\cdots(i+k) k i = 1 n,"This question already has answers here : Finding a closed formula for $1\cdot2\cdot3\cdots k +\dots + n(n+1)(n+2)\cdots(k+n-1)$ (5 answers) Closed 8 years ago . I learned that $$\sum \limits_{i=1}^n i(i+1) = \frac{n(n+1)(n+2)}{3}$$ or in general $$\sum \limits_{i = 1}^n i(i+1)(i+2) \dots (i + k) = \frac{n(n+1)\dots (n+k+1)}{k+2}$$ From a mathematical standpoint why is this true? I'm not asking for inductive proof. I am asking if you only given the left hand side, how would you go about writing a closed form expression for the sum?","This question already has answers here : Finding a closed formula for $1\cdot2\cdot3\cdots k +\dots + n(n+1)(n+2)\cdots(k+n-1)$ (5 answers) Closed 8 years ago . I learned that $$\sum \limits_{i=1}^n i(i+1) = \frac{n(n+1)(n+2)}{3}$$ or in general $$\sum \limits_{i = 1}^n i(i+1)(i+2) \dots (i + k) = \frac{n(n+1)\dots (n+k+1)}{k+2}$$ From a mathematical standpoint why is this true? I'm not asking for inductive proof. I am asking if you only given the left hand side, how would you go about writing a closed form expression for the sum?",,"['sequences-and-series', 'summation']"
39,Borel sum of $ 1!+2!+3!+.... $,Borel sum of, 1!+2!+3!+.... ,I know that the Borel sum of $ \sum_{n=0}^{\infty}(-1)^{n}n! $ is $ \int_{0}^{\infty} dx \frac{e^{-x}}{1+x} $ but what happens with the sum $  \sum_{n=0}^{\infty}n! $ the Borel sum should be $ \int_{0}^{\infty} dx \frac{e^{-x}}{1-x} $ which has a pole at $ x=1 $  using Shothotsky's formula I get $$ PV  \int_{0}^{\infty} dx \frac{e^{-x}}{1-x}-i\pi e^{-1} $$ however this is a complex number.,I know that the Borel sum of $ \sum_{n=0}^{\infty}(-1)^{n}n! $ is $ \int_{0}^{\infty} dx \frac{e^{-x}}{1+x} $ but what happens with the sum $  \sum_{n=0}^{\infty}n! $ the Borel sum should be $ \int_{0}^{\infty} dx \frac{e^{-x}}{1-x} $ which has a pole at $ x=1 $  using Shothotsky's formula I get $$ PV  \int_{0}^{\infty} dx \frac{e^{-x}}{1-x}-i\pi e^{-1} $$ however this is a complex number.,,"['sequences-and-series', 'divergent-series']"
40,Does the series $\sum_{n=1}^{\infty}|x|^\sqrt n$ converge pointwise? If it then what would be the sum?,Does the series  converge pointwise? If it then what would be the sum?,\sum_{n=1}^{\infty}|x|^\sqrt n,Does the series $\sum_{n=1}^{\infty}|x|^\sqrt n$ converge pointwise?,Does the series $\sum_{n=1}^{\infty}|x|^\sqrt n$ converge pointwise?,,['sequences-and-series']
41,Closed Bounded but not compact Subset of a Normed Vector Space,Closed Bounded but not compact Subset of a Normed Vector Space,,"Consider $\ell^\infty $ the vector space of real bounded sequences endowed with the sup norm, that is  $||x|| = \sup_n |x_n|$ where $x = (x_n)_{n \in \Bbb N}$. Prove that $B'(0,1) = \{x \in l^\infty : ||x|| \le 1\} $ is not compact. Now, we are given a hint that we can use the equivalence of sequential compactness and compactness without proof. However, I don't understand how sequences of sequences work? Do I need to find a set of sequences and order them such that they do not converge to the same sequence? Does the sequence $(y_n)$ where $y_n$ is the sequence such that $y_n = 0$ at all but the nth term where $y_n =1$ satisfy the requirement that it does not have a convergent subsequence? I think I have probably just confused myself with this sequence of sequences lark. Sorry and thanks.","Consider $\ell^\infty $ the vector space of real bounded sequences endowed with the sup norm, that is  $||x|| = \sup_n |x_n|$ where $x = (x_n)_{n \in \Bbb N}$. Prove that $B'(0,1) = \{x \in l^\infty : ||x|| \le 1\} $ is not compact. Now, we are given a hint that we can use the equivalence of sequential compactness and compactness without proof. However, I don't understand how sequences of sequences work? Do I need to find a set of sequences and order them such that they do not converge to the same sequence? Does the sequence $(y_n)$ where $y_n$ is the sequence such that $y_n = 0$ at all but the nth term where $y_n =1$ satisfy the requirement that it does not have a convergent subsequence? I think I have probably just confused myself with this sequence of sequences lark. Sorry and thanks.",,"['general-topology', 'sequences-and-series', 'compactness', 'topological-vector-spaces']"
42,Property of $\frac{\sum a_i}{\sum b_i}$ when $\frac{a_i}{b_i}$ is increasing,Property of  when  is increasing,\frac{\sum a_i}{\sum b_i} \frac{a_i}{b_i},"Can you prove the following property? Let $a_i,b_i$ be real positive numbers for $i=1,2,\dots$ , such that $\dfrac{a_i}{b_i}$ is an increasing sequence. Then: 1) The sequence $s_n=\dfrac{\sum_{i=1}^n a_i}{\sum_{i=1}^n b_i}$ is increasing. 2) Furthermore, for $0<r<k<n$ we have: $$\dfrac{\sum_{i=1}^r a_i}{\sum_{i=1}^r b_i}<\dfrac{\sum_{i=1}^n a_i}{\sum_{i=1}^n b_i}<\dfrac{\sum_{i=k}^n a_i}{\sum_{i=k}^n b_i}$$","Can you prove the following property? Let $a_i,b_i$ be real positive numbers for $i=1,2,\dots$ , such that $\dfrac{a_i}{b_i}$ is an increasing sequence. Then: 1) The sequence $s_n=\dfrac{\sum_{i=1}^n a_i}{\sum_{i=1}^n b_i}$ is increasing. 2) Furthermore, for $0<r<k<n$ we have: $$\dfrac{\sum_{i=1}^r a_i}{\sum_{i=1}^r b_i}<\dfrac{\sum_{i=1}^n a_i}{\sum_{i=1}^n b_i}<\dfrac{\sum_{i=k}^n a_i}{\sum_{i=k}^n b_i}$$",,"['sequences-and-series', 'inequality']"
43,Offset Alternating Series,Offset Alternating Series,,"I have the following alternating series that I would like to determine whether it is absolutely convergent, conditionally convergent, or divergent: $$  \sum\limits^{\infty}_{n=1} \frac{1+2(-1)^n}{n} $$ I have applied some tests and I find it reasonable to conclude that it is divergent. As a sum of two series: $$  \sum\limits^{\infty}_{n=1} \frac{1}{n} + \sum\limits^{\infty}_{n=1} \frac{2(-1)^n}{n} $$ I believe a convergent series when added to a divergent series, results in a divergent series.  If this isn't a fact then I would still be left to say that it is inconclusive. Using the Alternating Series Test, with: $$ a_n = \frac{1+2(-1)^n}{n} $$ although this isn't of 'proper form' $  \sum\limits^{\infty}_{n=1} (-1)^n a_n $ the limit of $a_n $ does approach zero as $ n \rightarrow \infty $.  As for monotonically decreasing, the limit of the ratio of absolute terms is divergent for $ n $ even and inconclusive for $ n $ odd, which has me concluding divergent by The Ratio Test as well as not monotonically decreasing, where: $$ \lim\limits_{n \rightarrow \infty} \left\lvert \frac{2(-1)^n + 1}{2(-1)^n - 1} \frac{n}{n+1} \right\rvert $$ Am I on the right track here?  Am I making any really improper assumptions?  Was there a better way to go about with the proof? Thanks!","I have the following alternating series that I would like to determine whether it is absolutely convergent, conditionally convergent, or divergent: $$  \sum\limits^{\infty}_{n=1} \frac{1+2(-1)^n}{n} $$ I have applied some tests and I find it reasonable to conclude that it is divergent. As a sum of two series: $$  \sum\limits^{\infty}_{n=1} \frac{1}{n} + \sum\limits^{\infty}_{n=1} \frac{2(-1)^n}{n} $$ I believe a convergent series when added to a divergent series, results in a divergent series.  If this isn't a fact then I would still be left to say that it is inconclusive. Using the Alternating Series Test, with: $$ a_n = \frac{1+2(-1)^n}{n} $$ although this isn't of 'proper form' $  \sum\limits^{\infty}_{n=1} (-1)^n a_n $ the limit of $a_n $ does approach zero as $ n \rightarrow \infty $.  As for monotonically decreasing, the limit of the ratio of absolute terms is divergent for $ n $ even and inconclusive for $ n $ odd, which has me concluding divergent by The Ratio Test as well as not monotonically decreasing, where: $$ \lim\limits_{n \rightarrow \infty} \left\lvert \frac{2(-1)^n + 1}{2(-1)^n - 1} \frac{n}{n+1} \right\rvert $$ Am I on the right track here?  Am I making any really improper assumptions?  Was there a better way to go about with the proof? Thanks!",,['sequences-and-series']
44,Hard recursion involving sums,Hard recursion involving sums,,"Let $n$ be an arbitrary integer. Define: $$\begin{align} c_0 &= 1;\\ c_m &= \frac1m \sum_{k = 1}^m (k n - m + k) \frac{(-1)^k}{(2k)!} c_{m - k}. \end{align}$$ This recursion turns up in my quest of computing integrals of functions of Bessel functions. Instead of solving this recursion, I'm also satisfied with the power series of $\cos^n \alpha$. I have tried solving that recursion using generating functions and then find some way to see this as the product of two series, however the $m^{-1}$ messes that up! Any suggestions?","Let $n$ be an arbitrary integer. Define: $$\begin{align} c_0 &= 1;\\ c_m &= \frac1m \sum_{k = 1}^m (k n - m + k) \frac{(-1)^k}{(2k)!} c_{m - k}. \end{align}$$ This recursion turns up in my quest of computing integrals of functions of Bessel functions. Instead of solving this recursion, I'm also satisfied with the power series of $\cos^n \alpha$. I have tried solving that recursion using generating functions and then find some way to see this as the product of two series, however the $m^{-1}$ messes that up! Any suggestions?",,['sequences-and-series']
45,How can one prove that $\sum_{k=1}^{\infty}\prod_{m=1}^{2k}\text{ctg}\frac{m\pi}{2k+1}=\frac{\pi}{4}-1$?,How can one prove that ?,\sum_{k=1}^{\infty}\prod_{m=1}^{2k}\text{ctg}\frac{m\pi}{2k+1}=\frac{\pi}{4}-1,"A question from some Russian book, about different summations an integrals, by Prudnikhov, Brichkhov and Marichev. Page 746, 20, they write: $$ \sum_{k=1}^{\infty}\prod_{m=1}^{2k}\text{ctg}\frac{m\pi}{2k+1}=\frac{\pi}{4}-1 $$ Without proof, actually the whole book is with no single proof. How could I start proving that, what is product of $\prod_{m=1}^{2k}\text{ctg}\frac{m\pi}{2k+1}$? Thanks!","A question from some Russian book, about different summations an integrals, by Prudnikhov, Brichkhov and Marichev. Page 746, 20, they write: $$ \sum_{k=1}^{\infty}\prod_{m=1}^{2k}\text{ctg}\frac{m\pi}{2k+1}=\frac{\pi}{4}-1 $$ Without proof, actually the whole book is with no single proof. How could I start proving that, what is product of $\prod_{m=1}^{2k}\text{ctg}\frac{m\pi}{2k+1}$? Thanks!",,"['sequences-and-series', 'analysis']"
46,Evaluating a limit of the truncated exponential series motivated by the prime number theorem for $k$ distinct prime factors.,Evaluating a limit of the truncated exponential series motivated by the prime number theorem for  distinct prime factors.,k,"If $\pi_k(n)$ is the cardinality of numbers with k factors (repetitions included) less than or equal n, the generalized Prime Number Theorem is: $$\pi_k(n)\sim \frac{n}{\ln n} \frac{(\ln \ln n)^{k-1}}{(k-1)!}.$$ I noticed it appears true that $$\lim_{n \to\infty}\ \sum_{k=1}^{n}\frac{2^n}{\ln 2^n} \frac{(\ln\ln 2^n)^{k-1}}{(k-1)!} = 2^n ,$$ which makes sense to me. In my attempts to prove this I could only get a few steps along.  How can this be done? Edit: Looking through Ramanjuan's Collected Papers in the 32d paper I notice he has the following: $$[x] = \{\pi_1(x) + \pi_2(x)+\pi_3(x)...\}.......(1)$$ and $$x = \frac{x}{\ln x}\{1 + \ln\ln x + \frac{(\ln\ln x)^2}{2!}...\}....(2)$$ He says that (1) and (2) are ""obvious."" The second was not obvious to me, but can be found by letting y = $\ln\ln x$ and using the Taylor series for e. I'm including this for completeness because (1) above is the idea behind the original question.","If $\pi_k(n)$ is the cardinality of numbers with k factors (repetitions included) less than or equal n, the generalized Prime Number Theorem is: $$\pi_k(n)\sim \frac{n}{\ln n} \frac{(\ln \ln n)^{k-1}}{(k-1)!}.$$ I noticed it appears true that $$\lim_{n \to\infty}\ \sum_{k=1}^{n}\frac{2^n}{\ln 2^n} \frac{(\ln\ln 2^n)^{k-1}}{(k-1)!} = 2^n ,$$ which makes sense to me. In my attempts to prove this I could only get a few steps along.  How can this be done? Edit: Looking through Ramanjuan's Collected Papers in the 32d paper I notice he has the following: $$[x] = \{\pi_1(x) + \pi_2(x)+\pi_3(x)...\}.......(1)$$ and $$x = \frac{x}{\ln x}\{1 + \ln\ln x + \frac{(\ln\ln x)^2}{2!}...\}....(2)$$ He says that (1) and (2) are ""obvious."" The second was not obvious to me, but can be found by letting y = $\ln\ln x$ and using the Taylor series for e. I'm including this for completeness because (1) above is the idea behind the original question.",,"['sequences-and-series', 'analysis', 'limits', 'asymptotics', 'analytic-number-theory']"
47,Divergence of Dirichlet series,Divergence of Dirichlet series,,"Suppose $s$ is a complex number with $\Re(s) \in (0,1]$ and $\{a_n\}$ is a complex sequence converging to $a \neq 0$. Must the Dirichlet series $$\sum_{n=1}^\infty\frac{a_n}{n^s}$$ diverge?","Suppose $s$ is a complex number with $\Re(s) \in (0,1]$ and $\{a_n\}$ is a complex sequence converging to $a \neq 0$. Must the Dirichlet series $$\sum_{n=1}^\infty\frac{a_n}{n^s}$$ diverge?",,"['sequences-and-series', 'dirichlet-series']"
48,Series expansion for iterated function,Series expansion for iterated function,,"I would like to find the MacLaurin expansion of an iterated function.  Finding the first few terms is not hard, but it doesn't take long before Mathematica runs out of memory using the straightforward program. Is there some good way to find terms with reasonable time and space? My problem allows some flexibility with the number of iterations and terms—but obviously more of both would be better.  The goal is to be able to compute the terms at some high precision without loosing precision.  This will only work when the input happens to be small, of course.  The more iterations the more work is done per iteration but the smaller the range to which it applies; the more terms the larger the range. At the moment I'm using 100 iterations and 150 terms (though this function is odd so it's only half that many coefficients).  The eventual precision will be tens of thousands of digits, which causes some difficulties since the coefficients are large (on the order of $10^{133}$) even out to $x^{149}.$","I would like to find the MacLaurin expansion of an iterated function.  Finding the first few terms is not hard, but it doesn't take long before Mathematica runs out of memory using the straightforward program. Is there some good way to find terms with reasonable time and space? My problem allows some flexibility with the number of iterations and terms—but obviously more of both would be better.  The goal is to be able to compute the terms at some high precision without loosing precision.  This will only work when the input happens to be small, of course.  The more iterations the more work is done per iteration but the smaller the range to which it applies; the more terms the larger the range. At the moment I'm using 100 iterations and 150 terms (though this function is odd so it's only half that many coefficients).  The eventual precision will be tens of thousands of digits, which causes some difficulties since the coefficients are large (on the order of $10^{133}$) even out to $x^{149}.$",,"['sequences-and-series', 'analysis', 'numerical-methods', 'fixed-point-theorems', 'symbolic-computation']"
49,Method to obtain values of Gauss hypergeometric function.,Method to obtain values of Gauss hypergeometric function.,,"Context: Reading this interesting paper: ( https://arxiv.org/pdf/1607.04742.pdf ) (""Special values of Gauss’s hypergeometric series derived from Appell’s series F1 with closed forms"" by Akihito Ebisu). We find that the author obtains a lot of values of Gauss Hypergeometric function with a new approach. In particular we have: $$\sum_{n=0}^{\infty}\frac{(3n)!(2n)!(-1)^n}{n!^5}\left(\frac{1}{8640} \right)^n=\frac{9\cdot 5^{2/3}\cdot\Gamma(1/3)^6}{100\pi^4},\tag{1}$$ $$\sum_{n=0}^{\infty}\frac{(4n)!(-1)^n}{n!^4}\left(\frac{1}{6635520} \right)^n=\frac{3\cdot 5^{1/4}\cdot\Gamma(1/4)^4}{25 \pi^3}.\tag{2}$$ Guillera obtains values of Gauss Hypergeometric function with the WZ method: ( https://arxiv.org/pdf/2001.08104.pdf ), and then with Clausen's formula deduces some Ramanujan series for $1/\pi$ . Updated Level 3: From the comments of Tito Piezas III we are going to give the transformation that allows us to obtain (1) using Ebisu's values. We take this version of Clausen's formula: $$\left(\sum_{n=0}^{\infty}\frac{f(a)f(b)}{f(2b)n!}x^n\right)^2=(1-x)^{-a}\sum_{n=0}^{\infty}\frac{f(a)f(b)f(2b-a)}{f(b+1/2)f(2b)n!}\left(\frac{x^2}{4(x-1)} \right)^n\tag{3}.$$ Where $f(x)=\frac{\Gamma{(x+n)}}{\Gamma{(x)}}=(x)_{n},$ is the Pochhammer symbol. Setting $a=1/3$ and $b=1/2$ in $(3)$ we have: $$_2F_1(\frac{1}{3},\frac{1}{2};1;x)^2=\frac{1}{(1-x)^{1/3}}\sum_{n=0}^{\infty}\frac{(2n)!(3n)!}{n!^5}\left(\frac{x^2}{432(x-1)}\right)^{n}\tag{4}.$$ Now using value $(E′′.1)$ (page 11 from Ebisu's paper) and setting in $(4)$ $x=\frac{1}{5}$ we have $(1)$ which is the second formula of level 3 listed by Tito. Concerning the second series of level 3 we find that solutions to $\frac{x^2}{432(x-1)}=-\frac{1}{8640}$ are $x=1/5$ and $x=-1/4$ so setting in $(4)$ $x=-1/4$ gives also: $$_2F_1(\frac{1}{3},\frac{1}{2};1;-\frac{1}{4})=\frac{3\cdot 20^{1/6}\Gamma{(\frac{1}{3})}^3}{10\pi^2}\tag{5}.$$ Concerning the third series of level 3 we find that solutions to $\frac{x^2}{432(x-1)}=-\frac{1}{326592}$ are $x=1/28$ and $x=-1/27$ so setting in $(4)$ $x=1/28$ gives: $$_2F_1(\frac{1}{3},\frac{1}{2};1;\frac{1}{28})=\frac{3\cdot 14^{1/3}\Gamma{(\frac{1}{3})}^3}{14\pi^2}\tag{6}.$$ Setting in $(4)$ $x=-1/27$ gives also: $$_2F_1(\frac{1}{3},\frac{1}{2};1;-\frac{1}{27})=\frac{9\cdot 2^{2/3}\Gamma{(\frac{1}{3})}^3}{28\pi^2}\tag{7}.$$ Updated Level 2: To obtain $(2)$ there is not explicit value listed in Ebisu's paper but using formula (B'.1) from page 8 and setting $a=1/4$ implies: $$_2F_1(\frac{1}{4},\frac{1}{2};1;-\frac{1}{80})=\frac{20^{1/4}\Gamma{(1/4)}^2}{5\pi^{3/2}}.\tag{8}$$ Now using $(3)$ and setting $a=1/4$ and $b=1/2$ we have: $$_2F_1(\frac{1}{4},\frac{1}{2};1;x)^2=\frac{1}{(1-x)^{1/4}}\sum_{n=0}^{\infty}\frac{(4n)!}{n!^4}\left(\frac{x^2}{1024(x-1)}\right)^{n}.\tag{9}$$ Then using $(8)$ and $(9)$ we recover $(2)$ which is the second series of level 2 given by Tito. Also solutions to $\frac{x^2}{1024(x-1)}=-\frac{1}{6635520}$ are $x=-1/80$ and $x=1/81$ so putting $x=1/81$ in $(9)$ we get also: $$_2F_1(\frac{1}{4},\frac{1}{2};1;\frac{1}{81})=\frac{3\sqrt{2}\Gamma{(1/4)}^2}{10\pi^{3/2}}.\tag{10}$$ Concerning the first series of level 2 given by Tito we see that solutions to: $\frac{x^2}{1024(x-1)}=-\frac{1}{12288}$ are $x=-1/3$ and $x=1/4$ so using $(9)$ when $x=-1/3$ gives: $$_2F_1(\frac{1}{4},\frac{1}{2};1;-\frac{1}{3})=\frac{\sqrt{6}\Gamma{(1/4)}^2}{6\pi^{3/2}}.\tag{11}$$ And setting $x=1/4$ also: $$_2F_1(\frac{1}{4},\frac{1}{2};1;\frac{1}{4})=\frac{3^{1/4}\Gamma{(1/4)}^2}{3\pi^{3/2}}.\tag{12}$$ Updated Level 2': Also: $$_2F_1(\frac{1}{4},\frac{1}{2};1;-\frac{32}{49})=\frac{28^{1/4}\Gamma{(1/7)}\Gamma{(2/7)}\Gamma{(4/7)}}{8\pi^2}\tag{13},$$ and $$_2F_1(\frac{1}{4},\frac{1}{2};1;\frac{32}{81})=\frac{3\cdot 1372^{1/4}\Gamma{(1/7)}\Gamma{(2/7)}\Gamma{(4/7)}}{56\pi^2}\tag{14}.$$ So the $_3F_2$ series: $$\sum_{n=0}^{\infty}\frac{(-1)^n(4n)!}{63^{2n}n!^{4}}=\frac{3\cdot\Gamma{(1/7)}^2\Gamma{(2/7)}^2\Gamma{(4/7)}^2}{32\pi^{4}}\tag{15}.$$ With some effor one can shows the Ramanujan's series: $$\sum_{n=0}^{\infty}\frac{(-1)^n(65n+8)(4n)!}{63^{2n}n!^{4}}=\frac{9\sqrt{7}}{\pi}.\tag{16}$$ Question: So Akihito's method is less opaque than WZ method. Do you think that we can use his method and prove all the rational series known for $1/\pi$ ? Reflections: This question can be misunderstood as to what the WZ method refers. I think this method is revolutionary and brilliant because it's ""trivial"" except for the fact when Carlson's theorem is needed. Also as Tito Piezas III has pointed, Jesús Guillera has proved series for $1/\pi^2$ using it and no other proofs are known till today. This method goes far beyond and deals with any hypergeometric series so you can see how magnificent it is.","Context: Reading this interesting paper: ( https://arxiv.org/pdf/1607.04742.pdf ) (""Special values of Gauss’s hypergeometric series derived from Appell’s series F1 with closed forms"" by Akihito Ebisu). We find that the author obtains a lot of values of Gauss Hypergeometric function with a new approach. In particular we have: Guillera obtains values of Gauss Hypergeometric function with the WZ method: ( https://arxiv.org/pdf/2001.08104.pdf ), and then with Clausen's formula deduces some Ramanujan series for . Updated Level 3: From the comments of Tito Piezas III we are going to give the transformation that allows us to obtain (1) using Ebisu's values. We take this version of Clausen's formula: Where is the Pochhammer symbol. Setting and in we have: Now using value (page 11 from Ebisu's paper) and setting in we have which is the second formula of level 3 listed by Tito. Concerning the second series of level 3 we find that solutions to are and so setting in gives also: Concerning the third series of level 3 we find that solutions to are and so setting in gives: Setting in gives also: Updated Level 2: To obtain there is not explicit value listed in Ebisu's paper but using formula (B'.1) from page 8 and setting implies: Now using and setting and we have: Then using and we recover which is the second series of level 2 given by Tito. Also solutions to are and so putting in we get also: Concerning the first series of level 2 given by Tito we see that solutions to: are and so using when gives: And setting also: Updated Level 2': Also: and So the series: With some effor one can shows the Ramanujan's series: Question: So Akihito's method is less opaque than WZ method. Do you think that we can use his method and prove all the rational series known for ? Reflections: This question can be misunderstood as to what the WZ method refers. I think this method is revolutionary and brilliant because it's ""trivial"" except for the fact when Carlson's theorem is needed. Also as Tito Piezas III has pointed, Jesús Guillera has proved series for using it and no other proofs are known till today. This method goes far beyond and deals with any hypergeometric series so you can see how magnificent it is.","\sum_{n=0}^{\infty}\frac{(3n)!(2n)!(-1)^n}{n!^5}\left(\frac{1}{8640} \right)^n=\frac{9\cdot 5^{2/3}\cdot\Gamma(1/3)^6}{100\pi^4},\tag{1} \sum_{n=0}^{\infty}\frac{(4n)!(-1)^n}{n!^4}\left(\frac{1}{6635520} \right)^n=\frac{3\cdot 5^{1/4}\cdot\Gamma(1/4)^4}{25 \pi^3}.\tag{2} 1/\pi \left(\sum_{n=0}^{\infty}\frac{f(a)f(b)}{f(2b)n!}x^n\right)^2=(1-x)^{-a}\sum_{n=0}^{\infty}\frac{f(a)f(b)f(2b-a)}{f(b+1/2)f(2b)n!}\left(\frac{x^2}{4(x-1)} \right)^n\tag{3}. f(x)=\frac{\Gamma{(x+n)}}{\Gamma{(x)}}=(x)_{n}, a=1/3 b=1/2 (3) _2F_1(\frac{1}{3},\frac{1}{2};1;x)^2=\frac{1}{(1-x)^{1/3}}\sum_{n=0}^{\infty}\frac{(2n)!(3n)!}{n!^5}\left(\frac{x^2}{432(x-1)}\right)^{n}\tag{4}. (E′′.1) (4) x=\frac{1}{5} (1) \frac{x^2}{432(x-1)}=-\frac{1}{8640} x=1/5 x=-1/4 (4) x=-1/4 _2F_1(\frac{1}{3},\frac{1}{2};1;-\frac{1}{4})=\frac{3\cdot 20^{1/6}\Gamma{(\frac{1}{3})}^3}{10\pi^2}\tag{5}. \frac{x^2}{432(x-1)}=-\frac{1}{326592} x=1/28 x=-1/27 (4) x=1/28 _2F_1(\frac{1}{3},\frac{1}{2};1;\frac{1}{28})=\frac{3\cdot 14^{1/3}\Gamma{(\frac{1}{3})}^3}{14\pi^2}\tag{6}. (4) x=-1/27 _2F_1(\frac{1}{3},\frac{1}{2};1;-\frac{1}{27})=\frac{9\cdot 2^{2/3}\Gamma{(\frac{1}{3})}^3}{28\pi^2}\tag{7}. (2) a=1/4 _2F_1(\frac{1}{4},\frac{1}{2};1;-\frac{1}{80})=\frac{20^{1/4}\Gamma{(1/4)}^2}{5\pi^{3/2}}.\tag{8} (3) a=1/4 b=1/2 _2F_1(\frac{1}{4},\frac{1}{2};1;x)^2=\frac{1}{(1-x)^{1/4}}\sum_{n=0}^{\infty}\frac{(4n)!}{n!^4}\left(\frac{x^2}{1024(x-1)}\right)^{n}.\tag{9} (8) (9) (2) \frac{x^2}{1024(x-1)}=-\frac{1}{6635520} x=-1/80 x=1/81 x=1/81 (9) _2F_1(\frac{1}{4},\frac{1}{2};1;\frac{1}{81})=\frac{3\sqrt{2}\Gamma{(1/4)}^2}{10\pi^{3/2}}.\tag{10} \frac{x^2}{1024(x-1)}=-\frac{1}{12288} x=-1/3 x=1/4 (9) x=-1/3 _2F_1(\frac{1}{4},\frac{1}{2};1;-\frac{1}{3})=\frac{\sqrt{6}\Gamma{(1/4)}^2}{6\pi^{3/2}}.\tag{11} x=1/4 _2F_1(\frac{1}{4},\frac{1}{2};1;\frac{1}{4})=\frac{3^{1/4}\Gamma{(1/4)}^2}{3\pi^{3/2}}.\tag{12} _2F_1(\frac{1}{4},\frac{1}{2};1;-\frac{32}{49})=\frac{28^{1/4}\Gamma{(1/7)}\Gamma{(2/7)}\Gamma{(4/7)}}{8\pi^2}\tag{13}, _2F_1(\frac{1}{4},\frac{1}{2};1;\frac{32}{81})=\frac{3\cdot 1372^{1/4}\Gamma{(1/7)}\Gamma{(2/7)}\Gamma{(4/7)}}{56\pi^2}\tag{14}. _3F_2 \sum_{n=0}^{\infty}\frac{(-1)^n(4n)!}{63^{2n}n!^{4}}=\frac{3\cdot\Gamma{(1/7)}^2\Gamma{(2/7)}^2\Gamma{(4/7)}^2}{32\pi^{4}}\tag{15}. \sum_{n=0}^{\infty}\frac{(-1)^n(65n+8)(4n)!}{63^{2n}n!^{4}}=\frac{9\sqrt{7}}{\pi}.\tag{16} 1/\pi 1/\pi^2","['sequences-and-series', 'closed-form', 'hypergeometric-function']"
50,What is $x^\bot$? Is $\zeta(\bot)=\bot$ for Riemann's zeta function $\zeta$ and wheel theory's $\bot$?,What is ? Is  for Riemann's zeta function  and wheel theory's ?,x^\bot \zeta(\bot)=\bot \zeta \bot,"Background: A wheel is an algebraic structure $(W,0,1,+,\cdot, /)$ where: $W$ is a set, $0,1\in W,$ $+$ and $\cdot$ are binary operations, $/$ is a unary operation, and $+,\cdot$ are associative, commutative, and with identities $0$ and $1$ , respectively, $//x=x$ , $/(xy)=/x/y$ , $xz+yz=(x+y)z+0z$ , $(x+yz)=x/y+z+0y$ , $0\cdot 0=0$ , $(x+0y)z=xz+0y$ , $/(x+0y)=/x+0y$ , $0/0+x=0/0$ . We denote $0/0$ by $\bot$ . The final axiom can be written as $$\bot+x=\bot.$$ See What are the mathematical properties of ⊥ in wheel theory? Therefore, $$\sum_{i=1}^\infty a_i=\bot\tag{$\Sigma$}$$ is $\bot$ whenever $a_i=\bot$ for at least one $i\in\Bbb N$ . The Question: Can we go any further than $(\Sigma)$ ? What is $x^\bot$ ? In particular, is $$\zeta(\bot)=\bot$$ for Riemann's zeta function? Thoughts: Due to the argument in the question linked to, my intuition is that, yes, we can go further; for instance, $$\prod_{i=1}^\infty a_i=\bot\tag{$\Pi$}$$ whenever $a_i=\bot$ for at least one $i\in\Bbb N$ , where $\Pi$ is defined in the obvious manner; but $$ \zeta(\bot) :=\sum_{n=1}^\infty 1\cdot/(n^\bot) $$ requires some notion of what $n^\bot$ means. I guess it should be $$x^\bot=\bot.\tag{$\bot$}$$ But breaking this down: $$ x^\bot =x^{0/0} =x^{0\cdot /0} =(x^0)^{/0} =1^{/0},$$ which has me stumped. Should we define $$1^{/0}:=\bot?\tag{1}$$ Further Context: This is just for fun. I don't think anything deep is going on here. I have no formal training in wheel theory. Please help :)","Background: A wheel is an algebraic structure where: is a set, and are binary operations, is a unary operation, and are associative, commutative, and with identities and , respectively, , , , , , , , . We denote by . The final axiom can be written as See What are the mathematical properties of ⊥ in wheel theory? Therefore, is whenever for at least one . The Question: Can we go any further than ? What is ? In particular, is for Riemann's zeta function? Thoughts: Due to the argument in the question linked to, my intuition is that, yes, we can go further; for instance, whenever for at least one , where is defined in the obvious manner; but requires some notion of what means. I guess it should be But breaking this down: which has me stumped. Should we define Further Context: This is just for fun. I don't think anything deep is going on here. I have no formal training in wheel theory. Please help :)","(W,0,1,+,\cdot, /) W 0,1\in W, + \cdot / +,\cdot 0 1 //x=x /(xy)=/x/y xz+yz=(x+y)z+0z (x+yz)=x/y+z+0y 0\cdot 0=0 (x+0y)z=xz+0y /(x+0y)=/x+0y 0/0+x=0/0 0/0 \bot \bot+x=\bot. \sum_{i=1}^\infty a_i=\bot\tag{\Sigma} \bot a_i=\bot i\in\Bbb N (\Sigma) x^\bot \zeta(\bot)=\bot \prod_{i=1}^\infty a_i=\bot\tag{\Pi} a_i=\bot i\in\Bbb N \Pi 
\zeta(\bot)
:=\sum_{n=1}^\infty 1\cdot/(n^\bot)
 n^\bot x^\bot=\bot.\tag{\bot} 
x^\bot =x^{0/0}
=x^{0\cdot /0}
=(x^0)^{/0}
=1^{/0}, 1^{/0}:=\bot?\tag{1}","['sequences-and-series', 'exponentiation', 'riemann-zeta', 'infinite-product', 'wheel-theory']"
51,Better upper bound for $ \sum_{k=2}^{\infty} \frac{1}{2^{k-1}} \sum_{n=1}^{\infty} (n! \: \text{mod} \: k) $,Better upper bound for, \sum_{k=2}^{\infty} \frac{1}{2^{k-1}} \sum_{n=1}^{\infty} (n! \: \text{mod} \: k) ,"Since the sum $\sum_{n=1}^{\infty} (n! \: \text{mod} \: k)$ will be zero beyond $k-1$ , the series could be interpreted as an finite sum of length $k-1$ . Also, the max value of $n! \: \text{mod} \: k$ is naturally $k-1$ . Taken together one has a max value of: $$ \sum_{k=2}^{\infty} \frac{(k-1)^2}{2^{k-1}} = 6 $$ Mathematica gives the value of $$ \sum_{k=2}^{\infty} \frac{1}{2^{k-1}} \sum_{n=1}^{\infty} (n! \: \text{mod} \: k) \approx 3.005674093 $$ so my upper bound is clearly quite crude. What would be a better upper bound? Edit: To be clear my upper bound is $\frac{x (x+1)}{(1-x)^3}$ for $ \sum_{k=2}^{\infty} x^{k-1} \sum_{n=1}^{\infty} (n! \: \text{mod} \: k)$ .","Since the sum will be zero beyond , the series could be interpreted as an finite sum of length . Also, the max value of is naturally . Taken together one has a max value of: Mathematica gives the value of so my upper bound is clearly quite crude. What would be a better upper bound? Edit: To be clear my upper bound is for .",\sum_{n=1}^{\infty} (n! \: \text{mod} \: k) k-1 k-1 n! \: \text{mod} \: k k-1  \sum_{k=2}^{\infty} \frac{(k-1)^2}{2^{k-1}} = 6   \sum_{k=2}^{\infty} \frac{1}{2^{k-1}} \sum_{n=1}^{\infty} (n! \: \text{mod} \: k) \approx 3.005674093  \frac{x (x+1)}{(1-x)^3}  \sum_{k=2}^{\infty} x^{k-1} \sum_{n=1}^{\infty} (n! \: \text{mod} \: k),['sequences-and-series']
52,Alternate forms of $ \sum\limits_{n=2}^\infty \text P(n)=\sum\limits_{p\text{ prime}}\frac1{p(p-1)} $ with the prime zeta function.,Alternate forms of  with the prime zeta function., \sum\limits_{n=2}^\infty \text P(n)=\sum\limits_{p\text{ prime}}\frac1{p(p-1)} ,"We know that: $$\sum_{n=2}^\infty (\zeta(n)-1)=1$$ but what about with the Prime Zeta function $\text P(s)$ ?: $$\sum_{n=2}^\infty \text P(n)=0.77315666904979…$$ Now interchange the sum with the prime numbers $ p_k$ $$\sum_{n=2}^\infty \sum_{m=1}^\infty \frac1{p_m^n}= \sum_{m=1}^\infty\sum_{n=2}^\infty \frac1{p_m^n}=\sum_{n=1}^\infty \frac1{p_n(p_n-1)}$$ which gives the same decimal. There are also many prime-related constants . Another form given by @reuns is with the Euler Phi and Mobius functions : $$\sum_{n=2}^\infty \text P(n)=\sum_{n=2}^\infty \frac{\phi(n)\ln(\zeta(n))}n-\sum_{n=2}^\infty \frac{\mu(n)\ln(\zeta(n))}n= \sum_{n=2}^\infty \frac{\phi(n)\ln(\zeta(n))}n-\text C= \gamma-\text B_1+ \sum_{n=2}^\infty \frac{\phi(n)\ln(\zeta(n))}n $$ where $\text P(s)=-\ln(\epsilon)+\text C+O(\epsilon),\epsilon>0$ as seen in Formulas 3 throught 5 here on MathWorld and $\text C=\text B_1-\gamma$ with the Merten’s constant $\text B_1$ and Euler Mascheroni constant . It also gives the same decimal. The Euler phi sum is similar to @Steven Clark’s formula ( $14$ ) here . If one read further in the Merten’s constant article , then the amount of prime factors average deviation constant $\text B_2$ appears giving: $$\sum_{n=2}^\infty \text P(n)=\sum_{p\text{ prime}}\frac1{p(p-1)}=\text B_2-\text B_1= 0.77315666904979… $$ Now that a “closed form” has been found, are there any alternate forms of the $0.77315666904979…\,$ constant in terms of special functions, integrals, manipulated sums et cetera?","We know that: but what about with the Prime Zeta function ?: Now interchange the sum with the prime numbers which gives the same decimal. There are also many prime-related constants . Another form given by @reuns is with the Euler Phi and Mobius functions : where as seen in Formulas 3 throught 5 here on MathWorld and with the Merten’s constant and Euler Mascheroni constant . It also gives the same decimal. The Euler phi sum is similar to @Steven Clark’s formula ( ) here . If one read further in the Merten’s constant article , then the amount of prime factors average deviation constant appears giving: Now that a “closed form” has been found, are there any alternate forms of the constant in terms of special functions, integrals, manipulated sums et cetera?","\sum_{n=2}^\infty (\zeta(n)-1)=1 \text P(s) \sum_{n=2}^\infty \text P(n)=0.77315666904979…  p_k \sum_{n=2}^\infty \sum_{m=1}^\infty \frac1{p_m^n}= \sum_{m=1}^\infty\sum_{n=2}^\infty \frac1{p_m^n}=\sum_{n=1}^\infty \frac1{p_n(p_n-1)} \sum_{n=2}^\infty \text P(n)=\sum_{n=2}^\infty \frac{\phi(n)\ln(\zeta(n))}n-\sum_{n=2}^\infty \frac{\mu(n)\ln(\zeta(n))}n= \sum_{n=2}^\infty \frac{\phi(n)\ln(\zeta(n))}n-\text C= \gamma-\text B_1+ \sum_{n=2}^\infty \frac{\phi(n)\ln(\zeta(n))}n  \text P(s)=-\ln(\epsilon)+\text C+O(\epsilon),\epsilon>0 \text C=\text B_1-\gamma \text B_1 14 \text B_2 \sum_{n=2}^\infty \text P(n)=\sum_{p\text{ prime}}\frac1{p(p-1)}=\text B_2-\text B_1= 0.77315666904979…  0.77315666904979…\,","['sequences-and-series', 'prime-numbers', 'closed-form', 'zeta-functions', 'constants']"
53,$(\frac1a+\frac12\frac{x}{a+2}+\frac{1\cdot3}{2\cdot4}\frac{x^2}{a+4}+...)(1+\frac12x+\frac{1\cdot3}{2\cdot4}x^2+...)=\frac1a(1+\frac{a+1}{a+2}x+...)$,,(\frac1a+\frac12\frac{x}{a+2}+\frac{1\cdot3}{2\cdot4}\frac{x^2}{a+4}+...)(1+\frac12x+\frac{1\cdot3}{2\cdot4}x^2+...)=\frac1a(1+\frac{a+1}{a+2}x+...),"For $a>0$ , prove $$\left(\frac{1}{a}+\frac{1}{2}\cdot\frac{x}{a+2}+\frac{1\cdot 3}{2\cdot 4}\cdot \frac{x^2}{a+4}+\cdots\right) \cdot  \left( 1+\frac{1}{2}\cdot x+\frac{1\cdot 3}{2\cdot 4}\cdot  x^2 +\cdots \right) = \frac{1}{a} \left[ 1+\frac{a+1}{a+2}x+\frac{(a+1)(a+3)}{(a+2)(a+4)} x^2 +\cdots \right]$$ I'm a bit lost on how to prove it. First I tried to prove it by induction but the expansion of $x^n$ 's coefficient on the left side is complex. Then I tried to simplify it. Call it $S_1 S_2 = S_3$ , apparently $S_2 = \sum_{n\ge 0} 4^{-n}{2n \choose n} x^n  = \frac{1}{\sqrt{1-x}}$ , but I got problem in $S_1$ . What I have done is: Denote $c_n = 4^{-n} {2n \choose n}$ , then $$\left( \sum_{n\ge 1} \frac{c_n}{n} x^n \right)' = \sum_{n\ge 1} c_n x^{n-1} = \frac1x \left( \sum_{n\ge 0} c_n x^n - 1 \right) = \frac1x\left(\frac{1}{\sqrt{1-x}}-1\right) $$ Let $f(x) = -2 \ln (1+\sqrt{1-x})$ , then $f' = \frac1x\left(\frac{1}{\sqrt{1-x}}-1\right)$ . Integral from $0$ to $x$ leads to $$\sum_{n\ge 1} \frac{c_n}{n} x^n  = \int_0^x \frac1x\left(\frac{1}{\sqrt{1-x}}-1\right) dx = f(x) |_0^x =\ln 4 - 2 \ln (1+\sqrt{1-x})$$ To work out $S_1=\sum_{n\ge 1} \frac{c_n}{2n+a} x^n = \frac12 \sum_{n\ge 1} \frac{c_n}{n+b} x^n$ , where $b = a/2$ , define $g(x) = 2S_1 = \sum_{n\ge 1} \frac{c_n}{n+b} x^n $ . Then we have $$ \frac{(x^b g)'}{x^b} = g' + \frac{b}{x}g = \frac1x\left(\frac{1}{\sqrt{1-x}}-1\right) $$ So $$g = \frac{1}{x^b} \left( \int_0^x \frac{x^{b-1}}{\sqrt{1-x}} dx - \frac{x^b}{b} + c  \right) $$ , where $c$ is a constant. But then I'm stuck at the ​ $ \int_0^x \frac{x^{b-1}}{\sqrt{1-x}} dx$ integral.","For , prove I'm a bit lost on how to prove it. First I tried to prove it by induction but the expansion of 's coefficient on the left side is complex. Then I tried to simplify it. Call it , apparently , but I got problem in . What I have done is: Denote , then Let , then . Integral from to leads to To work out , where , define . Then we have So , where is a constant. But then I'm stuck at the ​ integral.","a>0 \left(\frac{1}{a}+\frac{1}{2}\cdot\frac{x}{a+2}+\frac{1\cdot 3}{2\cdot 4}\cdot \frac{x^2}{a+4}+\cdots\right) \cdot 
\left( 1+\frac{1}{2}\cdot x+\frac{1\cdot 3}{2\cdot 4}\cdot  x^2 +\cdots \right)
= \frac{1}{a} \left[
1+\frac{a+1}{a+2}x+\frac{(a+1)(a+3)}{(a+2)(a+4)} x^2 +\cdots
\right] x^n S_1 S_2 = S_3 S_2 = \sum_{n\ge 0} 4^{-n}{2n \choose n} x^n  = \frac{1}{\sqrt{1-x}} S_1 c_n = 4^{-n} {2n \choose n} \left( \sum_{n\ge 1} \frac{c_n}{n} x^n \right)' = \sum_{n\ge 1} c_n x^{n-1} = \frac1x \left( \sum_{n\ge 0} c_n x^n - 1 \right) = \frac1x\left(\frac{1}{\sqrt{1-x}}-1\right)  f(x) = -2 \ln (1+\sqrt{1-x}) f' = \frac1x\left(\frac{1}{\sqrt{1-x}}-1\right) 0 x \sum_{n\ge 1} \frac{c_n}{n} x^n  = \int_0^x \frac1x\left(\frac{1}{\sqrt{1-x}}-1\right) dx = f(x) |_0^x =\ln 4 - 2 \ln (1+\sqrt{1-x}) S_1=\sum_{n\ge 1} \frac{c_n}{2n+a} x^n = \frac12 \sum_{n\ge 1} \frac{c_n}{n+b} x^n b = a/2 g(x) = 2S_1 = \sum_{n\ge 1} \frac{c_n}{n+b} x^n   \frac{(x^b g)'}{x^b} = g' + \frac{b}{x}g = \frac1x\left(\frac{1}{\sqrt{1-x}}-1\right)  g = \frac{1}{x^b} \left( \int_0^x \frac{x^{b-1}}{\sqrt{1-x}} dx - \frac{x^b}{b} + c  \right)  c  \int_0^x \frac{x^{b-1}}{\sqrt{1-x}} dx",['sequences-and-series']
54,Can a series $\sum_{n=1}^{\infty} (\frac{1}2)^n=1$ be infinitely substituted into itself?,Can a series  be infinitely substituted into itself?,\sum_{n=1}^{\infty} (\frac{1}2)^n=1,"Example $$\Large\sum_{n=1}^{\infty} \left(\frac{\sum_{n=1}^{\infty} \left(\frac{\sum_{n=1}^{\infty} \left(\frac{\sum_{n=1}^{\infty} \left(\frac{\sum_{n=1}^{\infty} \left(\frac{...}2\right)^n}2\right)^n}2\right)^n}2\right)^n}2\right)^n$$ Motivation Recently did a screen share on gather.town with itself and was greeted with this image below. The idea popped into my head, ""What if this infinite mirror concept was applied to an infinite series, would it be possible to create a series that has a known result but is not calculable?""","Example Motivation Recently did a screen share on gather.town with itself and was greeted with this image below. The idea popped into my head, ""What if this infinite mirror concept was applied to an infinite series, would it be possible to create a series that has a known result but is not calculable?""",\Large\sum_{n=1}^{\infty} \left(\frac{\sum_{n=1}^{\infty} \left(\frac{\sum_{n=1}^{\infty} \left(\frac{\sum_{n=1}^{\infty} \left(\frac{\sum_{n=1}^{\infty} \left(\frac{...}2\right)^n}2\right)^n}2\right)^n}2\right)^n}2\right)^n,"['sequences-and-series', 'algebra-precalculus']"
55,"If the complex sequence $u_{n+1}=f(u_n)$ has only one limit point, then it converges","If the complex sequence  has only one limit point, then it converges",u_{n+1}=f(u_n),"I would like to prove that if $f:\mathbb{C}\to\mathbb{C}$ is continuous and if a sequence $u$ defined by : $\forall n\in\mathbb{N},\,u_{n+1}=f(u_n)$ has only one limit point (not sure of the translation of ""valeur d'adhérence"" in french), then this sequence does converge. I guess that it's wise to look after a proof that $u$ is a bounded sequence (it is well known that any bounded complex sequence possessing only one limit point is indeed convergent). EDIT : we suppose, that for some $u_0\in\mathbb{C}$ - (and not for all of them) - the sequence $(u_n)$ has exactly one limit point.","I would like to prove that if is continuous and if a sequence defined by : has only one limit point (not sure of the translation of ""valeur d'adhérence"" in french), then this sequence does converge. I guess that it's wise to look after a proof that is a bounded sequence (it is well known that any bounded complex sequence possessing only one limit point is indeed convergent). EDIT : we suppose, that for some - (and not for all of them) - the sequence has exactly one limit point.","f:\mathbb{C}\to\mathbb{C} u \forall n\in\mathbb{N},\,u_{n+1}=f(u_n) u u_0\in\mathbb{C} (u_n)","['sequences-and-series', 'convergence-divergence', 'complex-numbers', 'dynamical-systems', 'fixed-point-theorems']"
56,"Questions regarding $\ln(x) = \sum_{n=1}^{\infty}\frac{(-1)^{n}}{n}(\zeta(n,x)-\zeta(n))$. Have I found something ""new""?","Questions regarding . Have I found something ""new""?","\ln(x) = \sum_{n=1}^{\infty}\frac{(-1)^{n}}{n}(\zeta(n,x)-\zeta(n))","Introduction TL;DR I was messing around with the Taylor series for $\ln(x)$ when I ended up with the formula \begin{align} \ln(x) &= \sum_{n=1}^{\infty}\frac{(-1)^{n}}{n}(\zeta(n,x)-\zeta(n)) \\\\ & =\sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n}H_{x-1}^{(n)}\end{align} (Here $\zeta(n,x)$ is Hurwit's Zeta function and $H_{x-1}^{(n)}$ is the $(x-1)$ -th Harmonic number of order $n$ (Generalized Harmonic numbers)) I claim that this formula works for all $x > 0$ (only $x\in\mathbb{R}$ for now). My questions are at the bottom of the post. Here are some numerical examples (using WolframAlpha): $\ln(2)$ $\ln(3)$ $\ln(0.5)$ $\ln(69)$ $\ln(1000)$ Derivation My derivation of the formula bases on the taylor series for $\ln(x+1)$ shown below $${\displaystyle \ln(1+x)=\sum _{n=1}^{\infty}{\frac{(-1)^{n-1}}{n}}x^{n}}$$ which is valid for $|x|\leq1$ . We can clearly see that we could get a infinite series for $\ln(2)$ by plugging in $1$ . But how would we get a series for $\ln(3)$ ? Well, one could plug in $\frac{1}{2}$ to get that $${\displaystyle \ln(1+\frac{1}{2})=\sum _{n=1}^{\infty}{\frac{(-1)^{n-1}}{n2^n}}}$$ By adding the inside of the natural logarithm on the LHS, and then using basic logarithm properties we get: $${\displaystyle \ln(3)=\ln(2) + \sum _{n=1}^{\infty}{\frac{(-1)^{n-1}}{n2^n}}}$$ Then, using the infinite series from earlier for $\ln(2)$ we get \begin{align} \ln(3) & =\sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n} + \sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n2^n} \\\\ & = \sum_{n=1}^{\infty}\frac{(2^n+1)(-1)^{n+1}}{n2^n}\end{align} Do you get the point? Now, in general, plugging in $\frac{1}{x}$ , we would get: \begin{align} \ln(x+1) & = \ln(x) + \sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{nx^n}\end{align} Now what's $\ln(x)$ ? Well, one could do the exact same thing (the process I described above) for first $x$ , then $x-1$ , then $x-2$ and so on, all the way until $1$ since $\ln(1) = 0$ . So doing this we get: \begin{align} \ln(x+1) & = \sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n} + \sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n2^n} \cdots + \sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{nx^n} \\\\ & = \sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n} + \frac{(-1)^{n+1}}{n2^n} \cdots + \frac{(-1)^{n+1}}{nx^n} \\\\ & = \sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n}\left(1+\frac{1}{2^n}+\frac{1}{3^n}\cdots+\frac{1}{x^n}\right) \\\\ & = \sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n}\sum_{k=1}^x \frac{1}{k^n}\\\\ & =\sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n}H_{x}^{(n)} \\\\  &= \sum_{n=1}^{\infty}\frac{(-1)^{n}}{n}(\zeta(n,x+1)-\zeta(n))\end{align} Then plugging in $x-1$ we get: $$\boxed{\ln(x) = \sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n}H_{x-1}^{(n)} = \sum_{n=1}^{\infty}\frac{(-1)^{n}}{n}(\zeta(n,x)-\zeta(n))}$$ Questions First of all, is my derivation correct? (I believe so, since I have tested the formula numerically a lot now, and it has worked) The title is a bit misleading; me finding something new about something elementary as natural logarithms is pretty much impossible, but I couldn't find this series listed anywhere, so if anyone recognizes this series please link some reference? Does this series work for all $x>0$ and $x\in\mathbb{R}$ ? Maybe even complex numbers? Does this series converge quickly? Can something else be said about the series? (Cool things to note, possible simplifications... whatever)","Introduction TL;DR I was messing around with the Taylor series for when I ended up with the formula (Here is Hurwit's Zeta function and is the -th Harmonic number of order (Generalized Harmonic numbers)) I claim that this formula works for all (only for now). My questions are at the bottom of the post. Here are some numerical examples (using WolframAlpha): Derivation My derivation of the formula bases on the taylor series for shown below which is valid for . We can clearly see that we could get a infinite series for by plugging in . But how would we get a series for ? Well, one could plug in to get that By adding the inside of the natural logarithm on the LHS, and then using basic logarithm properties we get: Then, using the infinite series from earlier for we get Do you get the point? Now, in general, plugging in , we would get: Now what's ? Well, one could do the exact same thing (the process I described above) for first , then , then and so on, all the way until since . So doing this we get: Then plugging in we get: Questions First of all, is my derivation correct? (I believe so, since I have tested the formula numerically a lot now, and it has worked) The title is a bit misleading; me finding something new about something elementary as natural logarithms is pretty much impossible, but I couldn't find this series listed anywhere, so if anyone recognizes this series please link some reference? Does this series work for all and ? Maybe even complex numbers? Does this series converge quickly? Can something else be said about the series? (Cool things to note, possible simplifications... whatever)","\ln(x) \begin{align} \ln(x) &= \sum_{n=1}^{\infty}\frac{(-1)^{n}}{n}(\zeta(n,x)-\zeta(n)) \\\\ & =\sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n}H_{x-1}^{(n)}\end{align} \zeta(n,x) H_{x-1}^{(n)} (x-1) n x > 0 x\in\mathbb{R} \ln(2) \ln(3) \ln(0.5) \ln(69) \ln(1000) \ln(x+1) {\displaystyle \ln(1+x)=\sum _{n=1}^{\infty}{\frac{(-1)^{n-1}}{n}}x^{n}} |x|\leq1 \ln(2) 1 \ln(3) \frac{1}{2} {\displaystyle \ln(1+\frac{1}{2})=\sum _{n=1}^{\infty}{\frac{(-1)^{n-1}}{n2^n}}} {\displaystyle \ln(3)=\ln(2) + \sum _{n=1}^{\infty}{\frac{(-1)^{n-1}}{n2^n}}} \ln(2) \begin{align} \ln(3) & =\sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n} + \sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n2^n} \\\\ & = \sum_{n=1}^{\infty}\frac{(2^n+1)(-1)^{n+1}}{n2^n}\end{align} \frac{1}{x} \begin{align} \ln(x+1) & = \ln(x) + \sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{nx^n}\end{align} \ln(x) x x-1 x-2 1 \ln(1) = 0 \begin{align} \ln(x+1) & = \sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n} + \sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n2^n} \cdots + \sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{nx^n} \\\\ & = \sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n} + \frac{(-1)^{n+1}}{n2^n} \cdots + \frac{(-1)^{n+1}}{nx^n} \\\\ & = \sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n}\left(1+\frac{1}{2^n}+\frac{1}{3^n}\cdots+\frac{1}{x^n}\right) \\\\ & = \sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n}\sum_{k=1}^x \frac{1}{k^n}\\\\ & =\sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n}H_{x}^{(n)} \\\\  &= \sum_{n=1}^{\infty}\frac{(-1)^{n}}{n}(\zeta(n,x+1)-\zeta(n))\end{align} x-1 \boxed{\ln(x) = \sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n}H_{x-1}^{(n)} = \sum_{n=1}^{\infty}\frac{(-1)^{n}}{n}(\zeta(n,x)-\zeta(n))} x>0 x\in\mathbb{R}","['sequences-and-series', 'logarithms', 'riemann-zeta', 'harmonic-numbers']"
57,Prouhet-Thue-Morse sequence and Arithmetic Progressions,Prouhet-Thue-Morse sequence and Arithmetic Progressions,,"This question is a fragment from a question posted by @Mathphile for which the link will be provided below. Let $(x_i)$ be an arithmetic progression of length $M$ . Let $(t_i)$ be the $i$ th element in the Prouhet-Thue-Morse sequence where we have: $$t_0=0$$ $$t_{2n}=t_n \quad (n \in \mathbb{N}_0)$$ $$t_{2n+1}=1-t_n \quad (n \in \mathbb{N}_0)$$ If all the elements of $(t_{x_i})$ are to be $0$ 's, can the value of $M$ be arbitrarily large? Link for Prouhet-Thue-Morse Sequence Link for @Mathphile problem","This question is a fragment from a question posted by @Mathphile for which the link will be provided below. Let be an arithmetic progression of length . Let be the th element in the Prouhet-Thue-Morse sequence where we have: If all the elements of are to be 's, can the value of be arbitrarily large? Link for Prouhet-Thue-Morse Sequence Link for @Mathphile problem",(x_i) M (t_i) i t_0=0 t_{2n}=t_n \quad (n \in \mathbb{N}_0) t_{2n+1}=1-t_n \quad (n \in \mathbb{N}_0) (t_{x_i}) 0 M,"['sequences-and-series', 'number-theory', 'arithmetic-progressions']"
58,Proof of a bizarre identity,Proof of a bizarre identity,,"Prove That $$ \prod_{r=1}^{n} (1-x^r) = 1 - \sum_{r=1}^{n} (1-x)\cdot(1-x^2)\cdot \ldots\cdot(1-x^{r-1})x^r $$ I found this identity through experimentation with Wolfram Alpha while trying to find a formula for the product on the LHS. I have been able to prove it using induction, but I'm interested in how one would derive such identities. I'm seeking a direct proof without induction. Any help will be appreciated. Thanks.","Prove That I found this identity through experimentation with Wolfram Alpha while trying to find a formula for the product on the LHS. I have been able to prove it using induction, but I'm interested in how one would derive such identities. I'm seeking a direct proof without induction. Any help will be appreciated. Thanks.", \prod_{r=1}^{n} (1-x^r) = 1 - \sum_{r=1}^{n} (1-x)\cdot(1-x^2)\cdot \ldots\cdot(1-x^{r-1})x^r ,"['sequences-and-series', 'combinatorics', 'products']"
59,Curious ODE with Dirac comb,Curious ODE with Dirac comb,,"I got stuck in my calculations trying to solve the following problem: Given the ODE $$\dot{x} = -\alpha x + a\sum_{n=0}^\infty\delta(t-n\tau)$$ where $\alpha \gt 0$ , define $$x_k = x(k\tau +0 )$$ and find $x_k$ as a function of $x_{k-1}$ . What is the value of the following limit $$\lim_{k\rightarrow \infty}x_k?$$ My attempt First of all we define the following function $$f(t) = a\sum_{n=0}^\infty\delta(t-n\tau)$$ then the ODE becomes pretty much standard $$\dot{x}(t) = -\alpha x(t) + f(t)$$ for which the general solution is $$x(t) = e^{-\alpha t} x(0)+\int_0^t e^{-\alpha(t-t')}f(t')\,dt'\\ x(t) = e^{-\alpha t} x(0)+\int_0^t e^{-\alpha(t-t')}a\sum_{n=0}^\infty\delta(t'-n\tau)\,dt'.$$ Now we interchange the sum with the integral (being a physicist I impudently change them without checking uniform convergence!) and get $$x(t)= e^{-\alpha t} x(0)+\sum_{n=0}^\infty a\int_0^t e^{-\alpha(t-t')}\delta(t'-n\tau)\,dt'$$ By the definition of $x_k$ $$\begin{align}x_k = x(k\tau+0) &=  e^{-\alpha k\tau} x(0)+\sum_{n=0}^\infty a\int_0^{k\tau} e^{-\alpha(k\tau-t')}\delta(t'-n\tau)\,dt'\\&=\underbrace{e^{-\alpha k\tau}x(0)}_{\text{first term}}+\underbrace{\sum_{n=0}^kae^{-\alpha(k\tau-n\tau)}}_{\text{second term}}\end{align}$$ We can easily calculate $x_{k-1}$ from the value of $x_k$ $$ x_{k-1} =  \underbrace{e^{-\alpha(k-1)\tau}x(0)}_{\text{first term}}+\underbrace{a\sum_{n=0}^{k-1}e^{-\alpha(k\tau-n\tau)}}_{\text{second term}}.$$ It is clear that is we want to make a relation between $x_k$ and $x_{k-1}$ , the first terms of both can be written as $$e^{-\alpha k\tau}x(0) = e^{-\alpha\tau}e^{-\alpha(k-1)\tau}x(0)$$ so I'm bound to say that, at list for the first terms $$x_k = e^{-\alpha\tau}x_{k-1}\tag2$$ The real problem arises when we try to make adjustments to $(2)$ to make the second terms equal, mainly from definition $(2)$ we get $$x_k = e^{-\alpha\tau}e^{-\alpha(k-1)\tau}x(0) + \color{red}{e^{-\alpha\tau}a\sum_{n=0}^{k-1}e^{-\alpha(k-n)\tau}}$$ My questions now are Question 1: How can I adjust that second term to get $x_k$ as a function of $x_{k-1}$ ? Question 2: Is there an easier way to solve this problem?","I got stuck in my calculations trying to solve the following problem: Given the ODE where , define and find as a function of . What is the value of the following limit My attempt First of all we define the following function then the ODE becomes pretty much standard for which the general solution is Now we interchange the sum with the integral (being a physicist I impudently change them without checking uniform convergence!) and get By the definition of We can easily calculate from the value of It is clear that is we want to make a relation between and , the first terms of both can be written as so I'm bound to say that, at list for the first terms The real problem arises when we try to make adjustments to to make the second terms equal, mainly from definition we get My questions now are Question 1: How can I adjust that second term to get as a function of ? Question 2: Is there an easier way to solve this problem?","\dot{x} = -\alpha x + a\sum_{n=0}^\infty\delta(t-n\tau) \alpha \gt 0 x_k = x(k\tau +0 ) x_k x_{k-1} \lim_{k\rightarrow \infty}x_k? f(t) = a\sum_{n=0}^\infty\delta(t-n\tau) \dot{x}(t) = -\alpha x(t) + f(t) x(t) = e^{-\alpha t} x(0)+\int_0^t e^{-\alpha(t-t')}f(t')\,dt'\\ x(t) = e^{-\alpha t} x(0)+\int_0^t e^{-\alpha(t-t')}a\sum_{n=0}^\infty\delta(t'-n\tau)\,dt'. x(t)= e^{-\alpha t} x(0)+\sum_{n=0}^\infty a\int_0^t e^{-\alpha(t-t')}\delta(t'-n\tau)\,dt' x_k \begin{align}x_k = x(k\tau+0) &=  e^{-\alpha k\tau} x(0)+\sum_{n=0}^\infty a\int_0^{k\tau} e^{-\alpha(k\tau-t')}\delta(t'-n\tau)\,dt'\\&=\underbrace{e^{-\alpha k\tau}x(0)}_{\text{first term}}+\underbrace{\sum_{n=0}^kae^{-\alpha(k\tau-n\tau)}}_{\text{second term}}\end{align} x_{k-1} x_k  x_{k-1} =  \underbrace{e^{-\alpha(k-1)\tau}x(0)}_{\text{first term}}+\underbrace{a\sum_{n=0}^{k-1}e^{-\alpha(k\tau-n\tau)}}_{\text{second term}}. x_k x_{k-1} e^{-\alpha k\tau}x(0) = e^{-\alpha\tau}e^{-\alpha(k-1)\tau}x(0) x_k = e^{-\alpha\tau}x_{k-1}\tag2 (2) (2) x_k = e^{-\alpha\tau}e^{-\alpha(k-1)\tau}x(0) + \color{red}{e^{-\alpha\tau}a\sum_{n=0}^{k-1}e^{-\alpha(k-n)\tau}} x_k x_{k-1}","['sequences-and-series', 'ordinary-differential-equations', 'limits', 'dirac-delta']"
60,Weird sum that is almost definitely not $\sqrt 2$,Weird sum that is almost definitely not,\sqrt 2,I have not the ability to compute more than four digits of $$\sum_{n=1}^\infty \frac{1}{n^2 H_n^{(\ln n)}}$$ $H_n^{(m)} = \sum_{k=1}^n \frac{1}{k^m}$ is the generalized harmonic number . I know this is the weirdest sum and it offers me no actual interest.  All I know is that the decimal number starts off as $1.414...$ and I want to settle my mind that it is not actually $\sqrt 2$. That would be crazy. I have no reason to expect it. I just want some confirmation. My calculations were from Desmos here https://www.desmos.com/calculator/helb1dgf1g .,I have not the ability to compute more than four digits of $$\sum_{n=1}^\infty \frac{1}{n^2 H_n^{(\ln n)}}$$ $H_n^{(m)} = \sum_{k=1}^n \frac{1}{k^m}$ is the generalized harmonic number . I know this is the weirdest sum and it offers me no actual interest.  All I know is that the decimal number starts off as $1.414...$ and I want to settle my mind that it is not actually $\sqrt 2$. That would be crazy. I have no reason to expect it. I just want some confirmation. My calculations were from Desmos here https://www.desmos.com/calculator/helb1dgf1g .,,"['sequences-and-series', 'decimal-expansion']"
61,End behavior of $(\sin k)^k$ where $k \in \mathbb{N}$,End behavior of  where,(\sin k)^k k \in \mathbb{N},"It's clear that the set $\{\sin k \mid k \in \mathbb{N}\}$ is dense in $[0, 1)$. What I'm having trouble determining is how the sequence $\{(\sin k)^k \mid k \in \mathbb{N}\}$ behaves for large $k$. My main question is: does there exist $N \in \mathbb{N}$ and $\epsilon \in \mathbb{R}, 0 \leq \epsilon < 1$ such that for all $k \geq N, k \in \mathbb{N}$, $(\sin k)^k \leq \epsilon$? Or equivalently, does there exist $N \in \mathbb{N}$ such that $\sup(\{(\sin k)^k \mid k \in \mathbb{N}, k \geq N\}) \neq 1$?","It's clear that the set $\{\sin k \mid k \in \mathbb{N}\}$ is dense in $[0, 1)$. What I'm having trouble determining is how the sequence $\{(\sin k)^k \mid k \in \mathbb{N}\}$ behaves for large $k$. My main question is: does there exist $N \in \mathbb{N}$ and $\epsilon \in \mathbb{R}, 0 \leq \epsilon < 1$ such that for all $k \geq N, k \in \mathbb{N}$, $(\sin k)^k \leq \epsilon$? Or equivalently, does there exist $N \in \mathbb{N}$ such that $\sup(\{(\sin k)^k \mid k \in \mathbb{N}, k \geq N\}) \neq 1$?",,"['sequences-and-series', 'analytic-number-theory']"
62,Does the series admit a limit as $\alpha\to 0$?,Does the series admit a limit as ?,\alpha\to 0,"I have the following problem: Let $\{x_n\}_{n\geq 1}$ be a bounded sequence of real numbers and let $\sigma_n=\sigma_n(\alpha)$ be a sequence of weights, depending on a real parameter $\alpha>0$, such that $\sigma_n>0$, $$\sum_{n\geq 1} \sigma_n<\infty$$ for all $\alpha>0$ and $\sigma_n\to 1$ as $\alpha\to 0$. To fix ideas, consider $$ \sigma_n = \frac{1}{1+\alpha n^2},$$ but I would like to know if there are results more in general, for $\sigma_n$ satisfying the properties above. Now, by the hypothesis we know that $$\sum_{n\geq 1} \sigma_n x_n$$ is absolutely convergent for any $\alpha>0$. What I'm interested in is understanding if the following rescaled series admits limit as $\alpha\to 0$: $$\lim_{\alpha\to 0} \frac{\displaystyle \sum_{n\geq 1} \sigma_n x_n}{\displaystyle \sum_{n\geq 1} \sigma_n}.$$ My intuition tells me that, since $\sigma_n\to 1$ as $\alpha\to 0$, it will tend to some sort of uniform distribution, i.e. $$\lim_{\alpha\to 0} \frac{\displaystyle \sum_{n\geq 1} \sigma_n x_n}{\displaystyle \sum_{n\geq 1} \sigma_n}  = \lim_{N\to\infty} \frac{1}{N} \sum_{n=1}^N x_n,$$ assuming the RHS is well defined. So the question is: is my intuition correct? Or is it correct under suitable assumptions on $\{x_n\}_n$ or $\{\sigma_n(\alpha)\}$? This is not an exercise, it's something that has come up in a project I'm working on, and usually I don't deal with this type of problems so I don't know how to approach it. Any help is appreciated! EDIT: when I talk about assumptions on $\sigma_n$ I mean possiblle assumptions in addition to the ones I'm already imposing. Moreover, I'm more interested in understanding if the limit exists and what it looks like, rather then force the assumptions in order to make it become what my intuition tells me it should be. To make it clear: I'm mainly interested in the case $$\sigma_n=\frac{1}{1+\alpha n^2}$$ but there are lots of other choices of $\sigma_n$ which satisfy the assumptions, as for example $$\sigma_n=\frac{1}{1+\alpha n^c}\ \text{ for some } c>1$$ but also things like $$\sigma_n=\frac{1}{1+\alpha n!}$$ with the latter example decaying much faster then the others. So I'm trying to understand what would be the limit of the ratio in the first example, and if it would change taking the other choices or it would be still the same.","I have the following problem: Let $\{x_n\}_{n\geq 1}$ be a bounded sequence of real numbers and let $\sigma_n=\sigma_n(\alpha)$ be a sequence of weights, depending on a real parameter $\alpha>0$, such that $\sigma_n>0$, $$\sum_{n\geq 1} \sigma_n<\infty$$ for all $\alpha>0$ and $\sigma_n\to 1$ as $\alpha\to 0$. To fix ideas, consider $$ \sigma_n = \frac{1}{1+\alpha n^2},$$ but I would like to know if there are results more in general, for $\sigma_n$ satisfying the properties above. Now, by the hypothesis we know that $$\sum_{n\geq 1} \sigma_n x_n$$ is absolutely convergent for any $\alpha>0$. What I'm interested in is understanding if the following rescaled series admits limit as $\alpha\to 0$: $$\lim_{\alpha\to 0} \frac{\displaystyle \sum_{n\geq 1} \sigma_n x_n}{\displaystyle \sum_{n\geq 1} \sigma_n}.$$ My intuition tells me that, since $\sigma_n\to 1$ as $\alpha\to 0$, it will tend to some sort of uniform distribution, i.e. $$\lim_{\alpha\to 0} \frac{\displaystyle \sum_{n\geq 1} \sigma_n x_n}{\displaystyle \sum_{n\geq 1} \sigma_n}  = \lim_{N\to\infty} \frac{1}{N} \sum_{n=1}^N x_n,$$ assuming the RHS is well defined. So the question is: is my intuition correct? Or is it correct under suitable assumptions on $\{x_n\}_n$ or $\{\sigma_n(\alpha)\}$? This is not an exercise, it's something that has come up in a project I'm working on, and usually I don't deal with this type of problems so I don't know how to approach it. Any help is appreciated! EDIT: when I talk about assumptions on $\sigma_n$ I mean possiblle assumptions in addition to the ones I'm already imposing. Moreover, I'm more interested in understanding if the limit exists and what it looks like, rather then force the assumptions in order to make it become what my intuition tells me it should be. To make it clear: I'm mainly interested in the case $$\sigma_n=\frac{1}{1+\alpha n^2}$$ but there are lots of other choices of $\sigma_n$ which satisfy the assumptions, as for example $$\sigma_n=\frac{1}{1+\alpha n^c}\ \text{ for some } c>1$$ but also things like $$\sigma_n=\frac{1}{1+\alpha n!}$$ with the latter example decaying much faster then the others. So I'm trying to understand what would be the limit of the ratio in the first example, and if it would change taking the other choices or it would be still the same.",,"['sequences-and-series', 'limits']"
63,Recurrence Relation involving Fractional Part,Recurrence Relation involving Fractional Part,,"I am considering the following sequence: $$a_0=\sqrt 2$$ $$a_{n+1}=a_n+\{a_n\}$$ where $\{x\}:= x-\lfloor x\rfloor$ denotes the fractional part function. Since I have observed that the sequence exhibits almost-linear growth, I am trying to find the value of the limit $$\lim_{n\to\infty} \frac{a_n}{n}$$ This is by no means rigorous, but I believe that the value is $1/2$, because the $\{a_n\}$ seems to behave somewhat like a random variable, and if we instead considered the sequence $$b_{n+1}=b_n+X_n$$ where each $X_n$ is a random variable uniformly distributed in $(0,1)$, the expected value of $\Delta b_n=X_n$ is $1/2$. Any ideas about how to prove this more rigorously? Is my reasoning even correct?","I am considering the following sequence: $$a_0=\sqrt 2$$ $$a_{n+1}=a_n+\{a_n\}$$ where $\{x\}:= x-\lfloor x\rfloor$ denotes the fractional part function. Since I have observed that the sequence exhibits almost-linear growth, I am trying to find the value of the limit $$\lim_{n\to\infty} \frac{a_n}{n}$$ This is by no means rigorous, but I believe that the value is $1/2$, because the $\{a_n\}$ seems to behave somewhat like a random variable, and if we instead considered the sequence $$b_{n+1}=b_n+X_n$$ where each $X_n$ is a random variable uniformly distributed in $(0,1)$, the expected value of $\Delta b_n=X_n$ is $1/2$. Any ideas about how to prove this more rigorously? Is my reasoning even correct?",,"['sequences-and-series', 'recurrence-relations', 'fractional-part']"
64,Sums of the form $S_k=\sum_{n\geq 1}\frac{1}{\sinh^{2k}(n \pi)}$ and the residue theorem.,Sums of the form  and the residue theorem.,S_k=\sum_{n\geq 1}\frac{1}{\sinh^{2k}(n \pi)},"Let us define the sums $$S_k=\sum_{n\geq 1}\frac{1}{\sinh^{2k}(n \pi)}$$ A few days ago, i was able to give a surprisingly simple derivation of the fact that $$ S_1=\sum_{n\geq 1}\frac{1}{\sinh^2(\pi n)}=\frac{1}{6}-\frac{1}{2\pi} $$ as an answer to this nice old question in terms of contour integration. Being curious i immediatly tried to generalize this result to higher orders of $\sinh$, which as it turned out will not work that easily. For example, considering the case of $k=2$ it turns out that $$\text{Res}\left(\frac{ \cot(\pi z)}{ \sinh^4(\pi z)},z=z_k\right)= \begin{cases} \frac{1}{\pi\sinh^4(\pi k)} \quad\text {if}\,\,k \in \mathbb{Z}/0,\\ -\frac{1}{\pi\sinh^4(\pi k)} -\frac{4}{3\pi\sinh^2(\pi k)} \quad\text {if}\,\,ik \in \mathbb{Z}/0 \end{cases} $$ So integrating over a large quadratic contour gives us absolutly no information about $S_2$, since the residues cancel (For details of the exact procedure please have a look at the post linked above). This is in fact a simple consequence of the transformation properties of $\sinh^{2k}(z)$ along the imaginary axis: $\sinh^{2k}(i y)=(-1)^k\sin^{2k}(y)$ Looking at $S_3$ with the same approach, it turns out that it contains $S_2$ as well as $S_1$ so it is clear that we need this value to make any progress in a generalization at all. I also want to mention that a Laplace/Mellintransform approach seem to suffer from the same cancellations then what i tried above, so this  is maybe also not the way to go...:/ My questions are 1.) Is there any chance to proof the result for $S_2$ (and $S_k$ in general if possible) using an an approach which is close to the one i used to calculate $S_1$ ? 2.) What is a general approach to derive calculate such sums using a minimum of knowledge about the realm of elliptic integrals, Jacobi theta functions etc. (where i'm sure they can be derived but i have far too less knowledge in this field to do this by my own) PS: It turns out that a closed form is, according to mathematica, given by $$ S_2=-\frac{11}{90}+\frac{1}{3\pi}+\frac{\bar{\omega}^4}{7680 \pi^4} $$ where $\bar{\omega}$ is the Lemniscate constant .","Let us define the sums $$S_k=\sum_{n\geq 1}\frac{1}{\sinh^{2k}(n \pi)}$$ A few days ago, i was able to give a surprisingly simple derivation of the fact that $$ S_1=\sum_{n\geq 1}\frac{1}{\sinh^2(\pi n)}=\frac{1}{6}-\frac{1}{2\pi} $$ as an answer to this nice old question in terms of contour integration. Being curious i immediatly tried to generalize this result to higher orders of $\sinh$, which as it turned out will not work that easily. For example, considering the case of $k=2$ it turns out that $$\text{Res}\left(\frac{ \cot(\pi z)}{ \sinh^4(\pi z)},z=z_k\right)= \begin{cases} \frac{1}{\pi\sinh^4(\pi k)} \quad\text {if}\,\,k \in \mathbb{Z}/0,\\ -\frac{1}{\pi\sinh^4(\pi k)} -\frac{4}{3\pi\sinh^2(\pi k)} \quad\text {if}\,\,ik \in \mathbb{Z}/0 \end{cases} $$ So integrating over a large quadratic contour gives us absolutly no information about $S_2$, since the residues cancel (For details of the exact procedure please have a look at the post linked above). This is in fact a simple consequence of the transformation properties of $\sinh^{2k}(z)$ along the imaginary axis: $\sinh^{2k}(i y)=(-1)^k\sin^{2k}(y)$ Looking at $S_3$ with the same approach, it turns out that it contains $S_2$ as well as $S_1$ so it is clear that we need this value to make any progress in a generalization at all. I also want to mention that a Laplace/Mellintransform approach seem to suffer from the same cancellations then what i tried above, so this  is maybe also not the way to go...:/ My questions are 1.) Is there any chance to proof the result for $S_2$ (and $S_k$ in general if possible) using an an approach which is close to the one i used to calculate $S_1$ ? 2.) What is a general approach to derive calculate such sums using a minimum of knowledge about the realm of elliptic integrals, Jacobi theta functions etc. (where i'm sure they can be derived but i have far too less knowledge in this field to do this by my own) PS: It turns out that a closed form is, according to mathematica, given by $$ S_2=-\frac{11}{90}+\frac{1}{3\pi}+\frac{\bar{\omega}^4}{7680 \pi^4} $$ where $\bar{\omega}$ is the Lemniscate constant .",,"['sequences-and-series', 'complex-analysis', 'contour-integration', 'modular-forms', 'elliptic-integrals']"
65,Convergence of a monotonic sequence,Convergence of a monotonic sequence,,"Assume $a_n\geq 0$ is a sequence of positive real numbers which satisfy the following inequality: for each $n,m\in\mathbb{N}$, we have $$(n+m)a_{n+m}\leq na_n+ma_m.$$ I can't show the convergence of this seemingly well-behaved sequence (I am guessing it does converge, and that one should use a monotonic trick?). Any hint is appreciated. I found this in a list of exercises in sequences and convergence, and I believe it should be elementary because so are the rest of the problems in that list. Thanks in advance! For completeness, my -failed- attempts so far: Using induction, one proves esily that for any $p,n\in\mathbb{N}$ the inequality $$a_{pn}\leq a_n.$$ From here one might conclude convergence of subsequences of the form $\{a_{{p^k}n}\}_k$ for any $p,n\in\mathbb{N}$. But unfortunately, I can't get an argument from here. Another promising-looking inequality is $$a_{n+1}\leq \frac{n}{n+1}a_n+\frac{a_1}{n},$$ but again this does not suffice. Finally, I tried playing with the sequence (for some $r$ fixed) $$A_n=\min\left\{\frac{nx_n+x_1}{n+1},\frac{(n-1)x_{n-1}+x_2}{n+1},\dots,\frac{(n-1)x_{n-r}+x_{r+1}}{n+1}\right\},$$ becase its a trick I have seen elsewhere when solving exercises on convergence of bounded sequences. I don't think this is the way, because I believe this would only work if you had an estimate of $a_{n+1}$ as a ""convex"" combination of the $r$-tail. EDIT: It seems like everyone can prove this result one way or another. A friend of mine immediately suggested to apply Fekete's Subadditive Lemma here to the sequence $b_n=n a_n$.","Assume $a_n\geq 0$ is a sequence of positive real numbers which satisfy the following inequality: for each $n,m\in\mathbb{N}$, we have $$(n+m)a_{n+m}\leq na_n+ma_m.$$ I can't show the convergence of this seemingly well-behaved sequence (I am guessing it does converge, and that one should use a monotonic trick?). Any hint is appreciated. I found this in a list of exercises in sequences and convergence, and I believe it should be elementary because so are the rest of the problems in that list. Thanks in advance! For completeness, my -failed- attempts so far: Using induction, one proves esily that for any $p,n\in\mathbb{N}$ the inequality $$a_{pn}\leq a_n.$$ From here one might conclude convergence of subsequences of the form $\{a_{{p^k}n}\}_k$ for any $p,n\in\mathbb{N}$. But unfortunately, I can't get an argument from here. Another promising-looking inequality is $$a_{n+1}\leq \frac{n}{n+1}a_n+\frac{a_1}{n},$$ but again this does not suffice. Finally, I tried playing with the sequence (for some $r$ fixed) $$A_n=\min\left\{\frac{nx_n+x_1}{n+1},\frac{(n-1)x_{n-1}+x_2}{n+1},\dots,\frac{(n-1)x_{n-r}+x_{r+1}}{n+1}\right\},$$ becase its a trick I have seen elsewhere when solving exercises on convergence of bounded sequences. I don't think this is the way, because I believe this would only work if you had an estimate of $a_{n+1}$ as a ""convex"" combination of the $r$-tail. EDIT: It seems like everyone can prove this result one way or another. A friend of mine immediately suggested to apply Fekete's Subadditive Lemma here to the sequence $b_n=n a_n$.",,['sequences-and-series']
66,Closed form for the series $\sum_{k=1}^\infty (-1)^k \ln \left( \tanh \frac{\pi k x}{2} \right)$,Closed form for the series,\sum_{k=1}^\infty (-1)^k \ln \left( \tanh \frac{\pi k x}{2} \right),"Is there a closed form for: $$f(x)=\sum_{k=1}^\infty (-1)^k \ln \left( \tanh \frac{\pi k x}{2} \right)=2\sum_{n=0}^\infty \frac{1}{2n+1}\frac{1}{e^{\pi (2n+1) x}+1}$$ This sum originated from a recent question , where we have: $$f(1)= -\frac{1}{\pi}\int_0^1 \ln \left( \ln \frac{1}{x} \right) \frac{dx}{1+x^2}=\ln \frac{\Gamma (3/4)}{\pi^{1/4}}$$ If we differentiate w.r.t. $x$, we obtain: $$f'(x)=\sum_{k=1}^\infty (-1)^k \frac{\pi k}{\sinh \pi k x}$$ There is again a closed form for $x=1$ (obtained numerically): $$f'(1)=-\frac{1}{4}$$ So, is there a closed form or at least an integral definition for arbitrary $x>0$? The series converges absolutely (numerically at least): $$\sum_{k=1}^\infty \ln \left( \tanh \frac{\pi k x}{2} \right)< \infty$$ Thus, this series can also be expressed as a logarithm of an infinite product: $$f(x)=\ln \prod_{k=1}^\infty \tanh (\pi k x) - \ln \prod_{k=1}^\infty \tanh  \left( \pi (k-1/2) x \right)$$ $$e^{f(x)}=  \prod_{k=1}^\infty \frac{\tanh (\pi k x)}{\tanh  \left( \pi (k-1/2) x \right)}$$ This by the way leads to: $$\prod_{k=1}^\infty \frac{\tanh (\pi k)}{\tanh  \left( \pi (k-1/2) \right)}=\frac{\pi^{1/4}}{\Gamma(3/4)}$$ I feel like there is a way to use the infinite product form for $\sinh$ and $\cosh$: $$\sinh (\pi x)=\pi x \prod_{n=1}^\infty \left(1+\frac{x^2}{n^2} \right)$$ $$\cosh (\pi x)=\prod_{n=1}^\infty \left(1+\frac{x^2}{(n-1/2)^2} \right)$$","Is there a closed form for: $$f(x)=\sum_{k=1}^\infty (-1)^k \ln \left( \tanh \frac{\pi k x}{2} \right)=2\sum_{n=0}^\infty \frac{1}{2n+1}\frac{1}{e^{\pi (2n+1) x}+1}$$ This sum originated from a recent question , where we have: $$f(1)= -\frac{1}{\pi}\int_0^1 \ln \left( \ln \frac{1}{x} \right) \frac{dx}{1+x^2}=\ln \frac{\Gamma (3/4)}{\pi^{1/4}}$$ If we differentiate w.r.t. $x$, we obtain: $$f'(x)=\sum_{k=1}^\infty (-1)^k \frac{\pi k}{\sinh \pi k x}$$ There is again a closed form for $x=1$ (obtained numerically): $$f'(1)=-\frac{1}{4}$$ So, is there a closed form or at least an integral definition for arbitrary $x>0$? The series converges absolutely (numerically at least): $$\sum_{k=1}^\infty \ln \left( \tanh \frac{\pi k x}{2} \right)< \infty$$ Thus, this series can also be expressed as a logarithm of an infinite product: $$f(x)=\ln \prod_{k=1}^\infty \tanh (\pi k x) - \ln \prod_{k=1}^\infty \tanh  \left( \pi (k-1/2) x \right)$$ $$e^{f(x)}=  \prod_{k=1}^\infty \frac{\tanh (\pi k x)}{\tanh  \left( \pi (k-1/2) x \right)}$$ This by the way leads to: $$\prod_{k=1}^\infty \frac{\tanh (\pi k)}{\tanh  \left( \pi (k-1/2) \right)}=\frac{\pi^{1/4}}{\Gamma(3/4)}$$ I feel like there is a way to use the infinite product form for $\sinh$ and $\cosh$: $$\sinh (\pi x)=\pi x \prod_{n=1}^\infty \left(1+\frac{x^2}{n^2} \right)$$ $$\cosh (\pi x)=\prod_{n=1}^\infty \left(1+\frac{x^2}{(n-1/2)^2} \right)$$",,"['sequences-and-series', 'definite-integrals', 'closed-form', 'infinite-product']"
67,Asymptotic value of a sequence,Asymptotic value of a sequence,,"Assume a real sequence $1=a_1\leq a_2\le \cdots \leq a_n$, and $a_{i+1}-a_i\leq \sqrt{a_i}$. Does this hold: $$\sum_{i=1}^{n-1} \frac{a_{i+1}-a_i}{a_i} \in O(\log n)$$","Assume a real sequence $1=a_1\leq a_2\le \cdots \leq a_n$, and $a_{i+1}-a_i\leq \sqrt{a_i}$. Does this hold: $$\sum_{i=1}^{n-1} \frac{a_{i+1}-a_i}{a_i} \in O(\log n)$$",,"['sequences-and-series', 'discrete-mathematics', 'asymptotics']"
68,Examine convergence of $\sum_{n=1}^{\infty}(\sqrt[n]{a} - \frac{\sqrt[n]{b}+\sqrt[n]{c}}{2})$,Examine convergence of,\sum_{n=1}^{\infty}(\sqrt[n]{a} - \frac{\sqrt[n]{b}+\sqrt[n]{c}}{2}),"How to examine convergence of $\sum_{n=1}^{\infty}(\sqrt[n]{a} - \frac{\sqrt[n]{b}+\sqrt[n]{c}}{2})$ for $a, b, c> 0$ using Taylor's theorem?","How to examine convergence of $\sum_{n=1}^{\infty}(\sqrt[n]{a} - \frac{\sqrt[n]{b}+\sqrt[n]{c}}{2})$ for $a, b, c> 0$ using Taylor's theorem?",,"['sequences-and-series', 'derivatives', 'taylor-expansion', 'divergent-series']"
69,Is it correct to say that ($\color{red}{(} \limsup |W_k|/k\color{red}{)} \le 1) \supseteq \limsup \color{red}{(}|W_k|/k \le 1\color{red}{)}$?,Is it correct to say that (?,\color{red}{(} \limsup |W_k|/k\color{red}{)} \le 1) \supseteq \limsup \color{red}{(}|W_k|/k \le 1\color{red}{)},"Let $W_0, W_1, W_2, \dots$ be random variables on a probability space   $(\Omega, \mathscr{F}, \mathbb{P})$ where $$\sum_{k=0}^{\infty}P(|W_k|>k) <\infty$$ Prove that $$\limsup \frac{|W_k|}{k} \le 1 \ \text{a.s.} $$ I initially thought the conclusion meant $(**)$ when it really means $(*)$: $$P(\color{red}{(} \limsup |W_k|/k\color{red}{)} \le 1) = 1 \ \text{(*)}$$ $$P(\limsup \color{red}{(}|W_k|/k \le 1\color{red}{)}) = 1 \ \text{(**)}$$ What I tried: By the first Borel-Cantelli Lemma, we have $P(\limsup (|W_k| > k)) = 0$ $\to P(\limsup (|W_k|/k > 1)) = 0$ $\to P(\liminf (|W_k|/k > 1)) = 0$ $\to P([\liminf (|W_k|/k > 1)]^C) = 1$ $\to P(\limsup \color{red}{(}|W_k|/k \le 1\color{red}{)}) = 1$ $\to P(\color{red}{(} \limsup |W_k|/k\color{red}{)} \le 1) = 1$ QED assuming $(**)$ implies $(*)$. Is it really the case that $(**)$ implies $(*)$? Here is why I think such: $\forall \omega \in \Omega, \omega \in (\limsup \color{red}{(}|W_k|/k \le 1\color{red}{)})$ Then $\forall m \ge 1, \exists n \ge m$ s.t. $\omega \in (\frac{|W_n(\omega)|}{n} \le 1)$ $\to \omega \in (\limsup \frac{|W_n(\omega)|}{n} \le \limsup 1 = 1)$ Now if $(\color{red}{(} \limsup |W_k|/k\color{red}{)} \le 1) \supseteq \limsup \color{red}{(}|W_k|/k \le 1\color{red}{)}$, then it follows by monotonicity that $(**)$ implies $(*)$ QED. However $(*)$ does not imply $(**)$ because it does not hold that $(\color{red}{(} \limsup |W_k|/k\color{red}{)} \le 1) \subseteq \limsup \color{red}{(}|W_k|/k \le 1\color{red}{)}$. Counterexample given in comments below. I guess the intuitive explanation is that $\limsup \frac{|W_n(\omega)|}{n} \le \limsup 1$ --/--> $\frac{|W_n(\omega)|}{n} \le 1$ for similar reasons that $x_n \le y_n \to \lim x_n \le \lim y_n$, if those limits exist (1) but $\lim x_n \le \lim y_n$ --/--> $x_n \le y_n$ (2), which makes sense: (1) has an infinite number of statements which imply 3 statements (limsup, liminf, limsup=liminf) (2) has 3 statements that claims to imply an infinite number of statements Is that right? Edit based on what Daniel Fischer said: To prove $$\liminf \{\frac{W_k(\omega)}{k} \le 1\} \subseteq \{\limsup \frac{W_k(\omega)}{k} \le 1\}:$$ Suppose $$\omega \in \liminf \{\frac{W_k(\omega)}{k} \le 1\}$$ Then $\exists m \ge 1$ s.t. $\forall k \ge m$, $$\omega \in \{\frac{|W_k(\omega)|}{k} \le 1\}$$ Since $\frac{|W_k(\omega)|}{k} \le 1 \to \limsup \frac{|W_k(\omega)|}{k} \le \limsup 1 = 1$ , we have $$\to \omega \in \{\limsup \frac{|W_k(\omega)|}{k} \le 1\}$$","Let $W_0, W_1, W_2, \dots$ be random variables on a probability space   $(\Omega, \mathscr{F}, \mathbb{P})$ where $$\sum_{k=0}^{\infty}P(|W_k|>k) <\infty$$ Prove that $$\limsup \frac{|W_k|}{k} \le 1 \ \text{a.s.} $$ I initially thought the conclusion meant $(**)$ when it really means $(*)$: $$P(\color{red}{(} \limsup |W_k|/k\color{red}{)} \le 1) = 1 \ \text{(*)}$$ $$P(\limsup \color{red}{(}|W_k|/k \le 1\color{red}{)}) = 1 \ \text{(**)}$$ What I tried: By the first Borel-Cantelli Lemma, we have $P(\limsup (|W_k| > k)) = 0$ $\to P(\limsup (|W_k|/k > 1)) = 0$ $\to P(\liminf (|W_k|/k > 1)) = 0$ $\to P([\liminf (|W_k|/k > 1)]^C) = 1$ $\to P(\limsup \color{red}{(}|W_k|/k \le 1\color{red}{)}) = 1$ $\to P(\color{red}{(} \limsup |W_k|/k\color{red}{)} \le 1) = 1$ QED assuming $(**)$ implies $(*)$. Is it really the case that $(**)$ implies $(*)$? Here is why I think such: $\forall \omega \in \Omega, \omega \in (\limsup \color{red}{(}|W_k|/k \le 1\color{red}{)})$ Then $\forall m \ge 1, \exists n \ge m$ s.t. $\omega \in (\frac{|W_n(\omega)|}{n} \le 1)$ $\to \omega \in (\limsup \frac{|W_n(\omega)|}{n} \le \limsup 1 = 1)$ Now if $(\color{red}{(} \limsup |W_k|/k\color{red}{)} \le 1) \supseteq \limsup \color{red}{(}|W_k|/k \le 1\color{red}{)}$, then it follows by monotonicity that $(**)$ implies $(*)$ QED. However $(*)$ does not imply $(**)$ because it does not hold that $(\color{red}{(} \limsup |W_k|/k\color{red}{)} \le 1) \subseteq \limsup \color{red}{(}|W_k|/k \le 1\color{red}{)}$. Counterexample given in comments below. I guess the intuitive explanation is that $\limsup \frac{|W_n(\omega)|}{n} \le \limsup 1$ --/--> $\frac{|W_n(\omega)|}{n} \le 1$ for similar reasons that $x_n \le y_n \to \lim x_n \le \lim y_n$, if those limits exist (1) but $\lim x_n \le \lim y_n$ --/--> $x_n \le y_n$ (2), which makes sense: (1) has an infinite number of statements which imply 3 statements (limsup, liminf, limsup=liminf) (2) has 3 statements that claims to imply an infinite number of statements Is that right? Edit based on what Daniel Fischer said: To prove $$\liminf \{\frac{W_k(\omega)}{k} \le 1\} \subseteq \{\limsup \frac{W_k(\omega)}{k} \le 1\}:$$ Suppose $$\omega \in \liminf \{\frac{W_k(\omega)}{k} \le 1\}$$ Then $\exists m \ge 1$ s.t. $\forall k \ge m$, $$\omega \in \{\frac{|W_k(\omega)|}{k} \le 1\}$$ Since $\frac{|W_k(\omega)|}{k} \le 1 \to \limsup \frac{|W_k(\omega)|}{k} \le \limsup 1 = 1$ , we have $$\to \omega \in \{\limsup \frac{|W_k(\omega)|}{k} \le 1\}$$",,"['sequences-and-series', 'probability-theory', 'random-variables', 'limsup-and-liminf', 'borel-cantelli-lemmas']"
70,Is there a closed form for the infinite product $\prod_{n=0}^{\infty}\bigl(1+{x \over 2^n} \bigr)$,Is there a closed form for the infinite product,\prod_{n=0}^{\infty}\bigl(1+{x \over 2^n} \bigr),"It has been a long time ago since I first encountered the following infinite product : $$ \prod_{n=0}^{\infty}\bigl(1+{x \over 2^n} \bigr) = (1 + x) \bigl(1 + {x \over 2}\bigr)\bigl(1 + {x \over 4}\bigr)\bigl(1 + {x \over 8}\bigr)  \cdots  $$ to my knowledge I haven't seen a closed form, but I would appreciate if gathering some information about this product. Does it relate to any known functions?","It has been a long time ago since I first encountered the following infinite product : $$ \prod_{n=0}^{\infty}\bigl(1+{x \over 2^n} \bigr) = (1 + x) \bigl(1 + {x \over 2}\bigr)\bigl(1 + {x \over 4}\bigr)\bigl(1 + {x \over 8}\bigr)  \cdots  $$ to my knowledge I haven't seen a closed form, but I would appreciate if gathering some information about this product. Does it relate to any known functions?",,"['sequences-and-series', 'infinite-product']"
71,Proving that $\sum_{k=0}^\infty\frac{2^{-5k}(6k+1)((2k-1)!!)^3}{4(k!)^3} = {1\over\pi}$,Proving that,\sum_{k=0}^\infty\frac{2^{-5k}(6k+1)((2k-1)!!)^3}{4(k!)^3} = {1\over\pi},"While trying to prove that $$(1)\qquad x\sum_{k=0}^\infty\frac{2^{-5k}(6k+1)((2k-1)!!)^3}{4(k!)^3} = 1 \implies x=\pi$$ I got to a point, using W|A, where I have to prove that $$\color{red}{(2)\qquad \pi = -\frac{8 \left (\sqrt{16-3 K\left ({1\over4} (2-\sqrt{3})\right )^2\, _3 F_2\left ({3\over2}, {3\over2}, {3\over2};\,2, 2;{1\over4}\right )}-4\right )}{\left (3\, _3 F_2\left ({3\over2}, {3\over2}, {3\over2};\,2, 2;\,{1\over4}\right )\right )}}$$ Where $K(x)$ is the complete elliptic K function, and $_xF_y(a_1 ... a_p;b_1 ... b_q; z)$ is the generalized hypergeometric function. IMPORTANT: As user153012 pointed out, there is likely an error in $(2)$, as I translated it from mathematica to Latex by hand, so I'll just post the mathematica query so that there is no misunderstanding: -8 (-4 + Sqrt[16 - 3 EllipticK[(2 - Sqrt[3])/4]^2 HypergeometricPFQ[{3/2, 3/2, 3/2}, {2, 2}, 1/4]]))/(3 HypergeometricPFQ[{3/2, 3/2, 3/2}, {2, 2}, 1/4]) Here's a LINK to the query ( If W|A show a message similar to ""Wolfram|Alpha doesn't know how to interpret your input"", just recompute the query by either refreshig the page or pressing the orange and white $=$ sign ). I will be correcting this error asap. Is there a way to prove $(2)$ to be true, or another way to prove $(1)$ to be true (by eliminating the double factorial? I haven't had any success in doing this myself.)? Thanks.","While trying to prove that $$(1)\qquad x\sum_{k=0}^\infty\frac{2^{-5k}(6k+1)((2k-1)!!)^3}{4(k!)^3} = 1 \implies x=\pi$$ I got to a point, using W|A, where I have to prove that $$\color{red}{(2)\qquad \pi = -\frac{8 \left (\sqrt{16-3 K\left ({1\over4} (2-\sqrt{3})\right )^2\, _3 F_2\left ({3\over2}, {3\over2}, {3\over2};\,2, 2;{1\over4}\right )}-4\right )}{\left (3\, _3 F_2\left ({3\over2}, {3\over2}, {3\over2};\,2, 2;\,{1\over4}\right )\right )}}$$ Where $K(x)$ is the complete elliptic K function, and $_xF_y(a_1 ... a_p;b_1 ... b_q; z)$ is the generalized hypergeometric function. IMPORTANT: As user153012 pointed out, there is likely an error in $(2)$, as I translated it from mathematica to Latex by hand, so I'll just post the mathematica query so that there is no misunderstanding: -8 (-4 + Sqrt[16 - 3 EllipticK[(2 - Sqrt[3])/4]^2 HypergeometricPFQ[{3/2, 3/2, 3/2}, {2, 2}, 1/4]]))/(3 HypergeometricPFQ[{3/2, 3/2, 3/2}, {2, 2}, 1/4]) Here's a LINK to the query ( If W|A show a message similar to ""Wolfram|Alpha doesn't know how to interpret your input"", just recompute the query by either refreshig the page or pressing the orange and white $=$ sign ). I will be correcting this error asap. Is there a way to prove $(2)$ to be true, or another way to prove $(1)$ to be true (by eliminating the double factorial? I haven't had any success in doing this myself.)? Thanks.",,"['sequences-and-series', 'factorial', 'pi', 'hypergeometric-function', 'elliptic-integrals']"
72,On the numbers divisible by all the Integers not exceeding their $r^{th}$ roots.,On the numbers divisible by all the Integers not exceeding their  roots.,r^{th},"Consider the set of all numbers which are divisible by all natural numbers not exceeding their square root, and denote this set by $S_2=\{1,2,3,4,6,8,12,24\}$ (Here the subscript indicates that we're taking the 2nd root of the numbers). Thus $|S_2|=8$. Similarly, the set of all numbers which are divisible by all natural numbers not exceeding the cube root is $S_3 = \{1,2,3,4,5,6,7,8,10,12,14,16,18,20,22,24,26,30,36,42,48,54,60,72,84,96,108,120,‌​180,240,300,420\}$, with $|S_3|=32$. Now define $S_r$ similarly as the set of all positive numbers divisible by all the naturals not exceeding their $r^{th}$ roots.  Then I have the folowing questions: Q-1 What is the general formula for finding $|S_r|$ (ie. Cardinality of $S_r$)? Q-2 Is there an expression for the greatest element of $S_r$? Asymptotics will also be encouraged.","Consider the set of all numbers which are divisible by all natural numbers not exceeding their square root, and denote this set by $S_2=\{1,2,3,4,6,8,12,24\}$ (Here the subscript indicates that we're taking the 2nd root of the numbers). Thus $|S_2|=8$. Similarly, the set of all numbers which are divisible by all natural numbers not exceeding the cube root is $S_3 = \{1,2,3,4,5,6,7,8,10,12,14,16,18,20,22,24,26,30,36,42,48,54,60,72,84,96,108,120,‌​180,240,300,420\}$, with $|S_3|=32$. Now define $S_r$ similarly as the set of all positive numbers divisible by all the naturals not exceeding their $r^{th}$ roots.  Then I have the folowing questions: Q-1 What is the general formula for finding $|S_r|$ (ie. Cardinality of $S_r$)? Q-2 Is there an expression for the greatest element of $S_r$? Asymptotics will also be encouraged.",,"['sequences-and-series', 'number-theory', 'inequality']"
73,"If $f(x)=x$ for $0 \leq x \leq e$ and $f(x)=xf(\ln(x))$ for $x>e$, then does the series $\sum\limits_n\frac1{f(n)}$ converge?","If  for  and  for , then does the series  converge?",f(x)=x 0 \leq x \leq e f(x)=xf(\ln(x)) x>e \sum\limits_n\frac1{f(n)},"Let $f(x)=x$ if $0 \leq x \leq e$, $f(x)=xf(\ln(x))$ if $x>e$.    Does the series $\sum\limits_{n\geq1}{\frac{1}{f(n)}}$ converge? My attempt : One can note that for all  $n\geq 3$, there exist $k\geq 1$ such that $$f(n)=n\ln(n)\ln(\ln(n))\cdots\ln^{(k)}(n)$$ where  $\ln^{(k)}$ refers to the function $\ln$ composed by itself $k$ times. Then, consider $$ I_k=\int_{\exp^{(k)}(1)}^{+\infty}\frac{1}{t\ln(t)\dots\ln^{(k)}(t)}dt. $$ By substituting  $t=e^u$, we have $$ I_k=\int_{exp^{(k-1)}(1)}^{+\infty}\frac{1}{e^uu\ln(u)\dots\ln^{(k-1)}(u)}e^udu=I_{k-1}, $$ Since $I_1=\int_e^{+\infty}\frac{1}{t\ln(t)}dt$ diverges then $I_k$ diverges too. Then, I would like to do an integral test, unfortunately $k$ is $n$-dependent. So, I think the trick is to choose a good interval. Any ideas for this ?","Let $f(x)=x$ if $0 \leq x \leq e$, $f(x)=xf(\ln(x))$ if $x>e$.    Does the series $\sum\limits_{n\geq1}{\frac{1}{f(n)}}$ converge? My attempt : One can note that for all  $n\geq 3$, there exist $k\geq 1$ such that $$f(n)=n\ln(n)\ln(\ln(n))\cdots\ln^{(k)}(n)$$ where  $\ln^{(k)}$ refers to the function $\ln$ composed by itself $k$ times. Then, consider $$ I_k=\int_{\exp^{(k)}(1)}^{+\infty}\frac{1}{t\ln(t)\dots\ln^{(k)}(t)}dt. $$ By substituting  $t=e^u$, we have $$ I_k=\int_{exp^{(k-1)}(1)}^{+\infty}\frac{1}{e^uu\ln(u)\dots\ln^{(k-1)}(u)}e^udu=I_{k-1}, $$ Since $I_1=\int_e^{+\infty}\frac{1}{t\ln(t)}dt$ diverges then $I_k$ diverges too. Then, I would like to do an integral test, unfortunately $k$ is $n$-dependent. So, I think the trick is to choose a good interval. Any ideas for this ?",,['sequences-and-series']
74,Elementary proof of prime number theorem?,Elementary proof of prime number theorem?,,"From Wikipedia : ""The prime number theorem is also equivalent to: $$\lim_{x \rightarrow \infty} \frac{\psi(x)}{x}=1$$ where $$\psi(x) = \sum\limits_{n \leq x} \Lambda(n)$$ is the Chebyshev function . and where: $$\Lambda(n) = \begin{cases} \log p & \text{if }n=p^k \text{ for some prime } p \text{ and integer } k \ge 1, \\ 0 & \text{otherwise.} \end{cases}$$ is the von Mangoldt function . The von Mangoldt function can be calculated as . Edit 27.1.2018 , I rewrote the whole question from here on, trying to use more conventional notation. $n$ stands for row index, and $k$ stands for column index. Mathematica knows that: $$\log(n)=\lim\limits_{s \rightarrow 1}\zeta(s)\left(1-\frac{1}{n^{s-1}}\right) \; \; \; \; \; \; (1)$$ and it has been proven that for $n>1$ the von Mangoldt function is: $$\Lambda(n)=\lim\limits_{s \rightarrow 1}\zeta(s)\sum\limits_{d|n} \frac{\mu(d)}{d^{s-1}} \; \; \; \; \; \; (2)$$ The Dirichlet series associated with the von Mangoldt function defined in such away  as above, is the infinite symmetric square matrix $T_1$: $$T_1=a(GCD(n,k)) \; \; \; \; \; \; (3)$$ which starts: $$T_1 = \left(   \begin{array}{ccccccc}   +1&+1&+1&+1&+1&+1&+1&\cdots \\ +1&-1&+1&-1&+1&-1&+1 \\ +1&+1&-2&+1&+1&-2&+1 \\ +1&-1&+1&-1&+1&-1&+1 \\ +1&+1&+1&+1&-4&+1&+1 \\ +1&-1&-2&-1&+1&+2&+1 \\ +1&+1&+1&+1&+1&+1&-6 \\ \vdots&&&&&&&\ddots \end{array}   \right)$$ where: $$a(n) = \sum\limits_{d|n} d \cdot \mu(d) \; \; \; \; \; \; (4)$$ (better known as the Dirichlet inverse of the Euler totient.) Now by periodicity of the entries in the columns for $m=0,1,2,3,4,5,...$ or $m \in \mathcal ℕ_0$, the column sums satisfy: $$\sum\limits_{n=1+m}^{n=k+m} T_1(n,k)=\begin{cases}1 & \mbox{ if } k=1\\ 0&\mbox{ if } k>1.\end{cases}  \; \; \; \; \; \; (5)$$ and by periodicity of the entries in the rows, the row sums satisfy: $$\sum\limits_{k=1+m}^{k=n+m} T_1(n,k)=\begin{cases}1 & \mbox{ if } n=1\\ 0&\mbox{ if } n>1.\end{cases} \; \; \; \; \; \; (6)$$ by symmetry. Since from $(2)$ for $n>1$: $$\Lambda(n)=\sum\limits_{k=1}^{k=\infty}\frac{T_1(n,k)}{k} \; \; \; \; \; \; (7)$$ and: $$\sum\limits_{n=1+m}^{n=k+m} \frac{T_1(n,k)}{k} =\begin{cases}1 & \mbox{ if } k=1\\ 0&\mbox{ if } k>1.\end{cases}  \; \; \; \; \; \; (8)$$ and since the denominator is $k$ in $(8)$ and the length of the period in the $k$-the column is also $k$, we can say that the average contribution to $\Lambda(n)$ from an entry $T_1(n,k)$ for $k>1$ in matrix $T_1$ must be: $$\sum\limits_{n=1+m}^{n=k+m} \frac{T_1(n,k)}{k} =\begin{cases}1 & \mbox{ if } k=1\\ 0&\mbox{ if } k>1.\end{cases}  \; \; \; \; \; \; (9)$$ Writing: $$\sum_{n \leq x} \Lambda(n)=\sum_{n \leq x} \sum\limits_{k=1}^{k=\infty}\frac{T_1(n,k)}{k} \; \; \; \; \; \; (10)$$ Combining $(9)$ with the right hand side of $(10)$ and multiplying the denominators $k \cdot k = k^2$ we get: $$\sum_{n \leq x} \Lambda(n)=\sum_{n \leq x} \sum\limits_{k=1}^{k=\infty}\sum\limits_{n=1+m}^{n=k+m} \frac{T_1(n,k)}{k^2} =\begin{cases} (1+o(1))x & \mbox{ if } k=1\\ (0+o(1))x &\mbox{ if } k>1.\end{cases}  \; \; \; \; \; \; (11)$$ and thereby at least heuristically: $$\sum_{n \leq x} \Lambda(n) = (1+o(1)) x  \; \; \; \; \; \; (12)$$ $\square$ Associated Mathematica 8 code: nn = 7 a[n_] := If[n < 1, 0, Sum[d MoebiusMu@d, {d, Divisors[n]}]]  MatrixForm[  Table[Table[If[k == 1, 0, a[GCD[n, k]]], {k, 1, nn}], {n, 1, nn}]] MatrixForm[  Table[Table[    Sum[If[k == 1, 0, a[GCD[n, k]]], {k, 1, x}], {x, 1, nn}], {n, 1,     nn}]] MatrixForm[  Table[Table[    Sum[If[k == 1, 0, a[GCD[n, k]]], {k, 1, x}]/x, {x, 1, nn}], {n, 1,     nn}]] Edit 18.2.2018: I will try to add some details. Starting with matrix $T_1$ defined above, we form the matrix $T_2$, but before that we state again the property of matrix $T_1$, namely: $$\Lambda(k) = \sum\limits_{n=1}^{n=\infty}\frac{T_1(n,k)}{n}$$ and then matrix $T_2$: $$T_2(n,k)=\sum\limits_{k=1}^{k=g}T_1(n,k)$$ where: $$g=1,2,3,4,5,...$$ and: $$n=1,2,3,4,5,...$$ Matrix $T_2$ in turn has the property: $$\psi(x)=\sum\limits_{k \leq x} \Lambda(k) = \sum\limits_{n=1}^{n=\infty}\frac{T_2(n,k)}{n}$$ We then form matrix $T_3$: $$T_3(n,k)=\frac{T_2(n,k)}{n \cdot k}$$ Since for $n>1$: $$\lim\limits_{k \rightarrow \infty} T_3(n,k) = 0$$ and since: $$\lim\limits_{k \rightarrow \infty} T_3(1,k) = 1$$ the prime number theorem is true/follows. $\square$ In case I did not get it entirely right I attach this second program in Mathematica as a verification: (*start*) nn = 12; TableForm[   A = Table[Table[If[Mod[n, k] == 0, 1, 0], {k, 1, nn}], {n, 1, nn}]]; TableForm[   B = Table[     Table[If[Mod[k, n] == 0, MoebiusMu[n]*n, 0], {k, 1, nn}], {n, 1,       nn}]]; TableForm[T1 = (A.B)]; TableForm[  T2 = Table[Table[Sum[T1[[n, k]], {k, 1, g}], {g, 1, nn}], {n, 1, nn}]] TableForm[T3 = Table[Table[T2[[n, k]]/n/k, {k, 1, nn}], {n, 1, nn}]] (*end*)","From Wikipedia : ""The prime number theorem is also equivalent to: $$\lim_{x \rightarrow \infty} \frac{\psi(x)}{x}=1$$ where $$\psi(x) = \sum\limits_{n \leq x} \Lambda(n)$$ is the Chebyshev function . and where: $$\Lambda(n) = \begin{cases} \log p & \text{if }n=p^k \text{ for some prime } p \text{ and integer } k \ge 1, \\ 0 & \text{otherwise.} \end{cases}$$ is the von Mangoldt function . The von Mangoldt function can be calculated as . Edit 27.1.2018 , I rewrote the whole question from here on, trying to use more conventional notation. $n$ stands for row index, and $k$ stands for column index. Mathematica knows that: $$\log(n)=\lim\limits_{s \rightarrow 1}\zeta(s)\left(1-\frac{1}{n^{s-1}}\right) \; \; \; \; \; \; (1)$$ and it has been proven that for $n>1$ the von Mangoldt function is: $$\Lambda(n)=\lim\limits_{s \rightarrow 1}\zeta(s)\sum\limits_{d|n} \frac{\mu(d)}{d^{s-1}} \; \; \; \; \; \; (2)$$ The Dirichlet series associated with the von Mangoldt function defined in such away  as above, is the infinite symmetric square matrix $T_1$: $$T_1=a(GCD(n,k)) \; \; \; \; \; \; (3)$$ which starts: $$T_1 = \left(   \begin{array}{ccccccc}   +1&+1&+1&+1&+1&+1&+1&\cdots \\ +1&-1&+1&-1&+1&-1&+1 \\ +1&+1&-2&+1&+1&-2&+1 \\ +1&-1&+1&-1&+1&-1&+1 \\ +1&+1&+1&+1&-4&+1&+1 \\ +1&-1&-2&-1&+1&+2&+1 \\ +1&+1&+1&+1&+1&+1&-6 \\ \vdots&&&&&&&\ddots \end{array}   \right)$$ where: $$a(n) = \sum\limits_{d|n} d \cdot \mu(d) \; \; \; \; \; \; (4)$$ (better known as the Dirichlet inverse of the Euler totient.) Now by periodicity of the entries in the columns for $m=0,1,2,3,4,5,...$ or $m \in \mathcal ℕ_0$, the column sums satisfy: $$\sum\limits_{n=1+m}^{n=k+m} T_1(n,k)=\begin{cases}1 & \mbox{ if } k=1\\ 0&\mbox{ if } k>1.\end{cases}  \; \; \; \; \; \; (5)$$ and by periodicity of the entries in the rows, the row sums satisfy: $$\sum\limits_{k=1+m}^{k=n+m} T_1(n,k)=\begin{cases}1 & \mbox{ if } n=1\\ 0&\mbox{ if } n>1.\end{cases} \; \; \; \; \; \; (6)$$ by symmetry. Since from $(2)$ for $n>1$: $$\Lambda(n)=\sum\limits_{k=1}^{k=\infty}\frac{T_1(n,k)}{k} \; \; \; \; \; \; (7)$$ and: $$\sum\limits_{n=1+m}^{n=k+m} \frac{T_1(n,k)}{k} =\begin{cases}1 & \mbox{ if } k=1\\ 0&\mbox{ if } k>1.\end{cases}  \; \; \; \; \; \; (8)$$ and since the denominator is $k$ in $(8)$ and the length of the period in the $k$-the column is also $k$, we can say that the average contribution to $\Lambda(n)$ from an entry $T_1(n,k)$ for $k>1$ in matrix $T_1$ must be: $$\sum\limits_{n=1+m}^{n=k+m} \frac{T_1(n,k)}{k} =\begin{cases}1 & \mbox{ if } k=1\\ 0&\mbox{ if } k>1.\end{cases}  \; \; \; \; \; \; (9)$$ Writing: $$\sum_{n \leq x} \Lambda(n)=\sum_{n \leq x} \sum\limits_{k=1}^{k=\infty}\frac{T_1(n,k)}{k} \; \; \; \; \; \; (10)$$ Combining $(9)$ with the right hand side of $(10)$ and multiplying the denominators $k \cdot k = k^2$ we get: $$\sum_{n \leq x} \Lambda(n)=\sum_{n \leq x} \sum\limits_{k=1}^{k=\infty}\sum\limits_{n=1+m}^{n=k+m} \frac{T_1(n,k)}{k^2} =\begin{cases} (1+o(1))x & \mbox{ if } k=1\\ (0+o(1))x &\mbox{ if } k>1.\end{cases}  \; \; \; \; \; \; (11)$$ and thereby at least heuristically: $$\sum_{n \leq x} \Lambda(n) = (1+o(1)) x  \; \; \; \; \; \; (12)$$ $\square$ Associated Mathematica 8 code: nn = 7 a[n_] := If[n < 1, 0, Sum[d MoebiusMu@d, {d, Divisors[n]}]]  MatrixForm[  Table[Table[If[k == 1, 0, a[GCD[n, k]]], {k, 1, nn}], {n, 1, nn}]] MatrixForm[  Table[Table[    Sum[If[k == 1, 0, a[GCD[n, k]]], {k, 1, x}], {x, 1, nn}], {n, 1,     nn}]] MatrixForm[  Table[Table[    Sum[If[k == 1, 0, a[GCD[n, k]]], {k, 1, x}]/x, {x, 1, nn}], {n, 1,     nn}]] Edit 18.2.2018: I will try to add some details. Starting with matrix $T_1$ defined above, we form the matrix $T_2$, but before that we state again the property of matrix $T_1$, namely: $$\Lambda(k) = \sum\limits_{n=1}^{n=\infty}\frac{T_1(n,k)}{n}$$ and then matrix $T_2$: $$T_2(n,k)=\sum\limits_{k=1}^{k=g}T_1(n,k)$$ where: $$g=1,2,3,4,5,...$$ and: $$n=1,2,3,4,5,...$$ Matrix $T_2$ in turn has the property: $$\psi(x)=\sum\limits_{k \leq x} \Lambda(k) = \sum\limits_{n=1}^{n=\infty}\frac{T_2(n,k)}{n}$$ We then form matrix $T_3$: $$T_3(n,k)=\frac{T_2(n,k)}{n \cdot k}$$ Since for $n>1$: $$\lim\limits_{k \rightarrow \infty} T_3(n,k) = 0$$ and since: $$\lim\limits_{k \rightarrow \infty} T_3(1,k) = 1$$ the prime number theorem is true/follows. $\square$ In case I did not get it entirely right I attach this second program in Mathematica as a verification: (*start*) nn = 12; TableForm[   A = Table[Table[If[Mod[n, k] == 0, 1, 0], {k, 1, nn}], {n, 1, nn}]]; TableForm[   B = Table[     Table[If[Mod[k, n] == 0, MoebiusMu[n]*n, 0], {k, 1, nn}], {n, 1,       nn}]]; TableForm[T1 = (A.B)]; TableForm[  T2 = Table[Table[Sum[T1[[n, k]], {k, 1, g}], {g, 1, nn}], {n, 1, nn}]] TableForm[T3 = Table[Table[T2[[n, k]]/n/k, {k, 1, nn}], {n, 1, nn}]] (*end*)",,"['sequences-and-series', 'elementary-number-theory', 'proof-verification']"
75,percentage of numbers starting with $2$ in $\{2^n\}$,percentage of numbers starting with  in,2 \{2^n\},"I have once heard a professor telling (during a course on Fourier theory) that there is a way to determine the numbers starting with a $2$ in the sequence $\{2^n\colon n\in\mathbb{N}\}$. I asked him about it, but he could not remember how. The proof involved the theory of equidistributed sequences the Weyl criterion . Is there someone who knows how to prove this? Or is there a nice reference (preferably a book)?","I have once heard a professor telling (during a course on Fourier theory) that there is a way to determine the numbers starting with a $2$ in the sequence $\{2^n\colon n\in\mathbb{N}\}$. I asked him about it, but he could not remember how. The proof involved the theory of equidistributed sequences the Weyl criterion . Is there someone who knows how to prove this? Or is there a nice reference (preferably a book)?",,"['sequences-and-series', 'number-theory', 'reference-request', 'fourier-analysis']"
76,What should a 21st century Euler attempt?,What should a 21st century Euler attempt?,,"Euler at the start of his career found the exact sum of the series $\sum_{n=1}^{\infty}\frac{1}{n^2}=\frac{\pi^2}{6}$. My question is: What could a 21st century Euler possibly attempt to solve? Are there any similar ""elementary"" problems which a mature mathematician in his late teens/early twenties could attempt to solve? By ""elementary"" I'm referring to problems whose intuitive solution could possibly be understood by a high school student. This might sound like a stupid question but I'm just curious. Thanks in advance for trying to help!","Euler at the start of his career found the exact sum of the series $\sum_{n=1}^{\infty}\frac{1}{n^2}=\frac{\pi^2}{6}$. My question is: What could a 21st century Euler possibly attempt to solve? Are there any similar ""elementary"" problems which a mature mathematician in his late teens/early twenties could attempt to solve? By ""elementary"" I'm referring to problems whose intuitive solution could possibly be understood by a high school student. This might sound like a stupid question but I'm just curious. Thanks in advance for trying to help!",,['sequences-and-series']
77,Convergence of $\prod_{n=1}^\infty(1+a_n)$,Convergence of,\prod_{n=1}^\infty(1+a_n),"The question is motivated by the following exercise in complex analysis: Let $\{a_n\}\subset{\Bbb C}$ such that $a_n\neq-1$ for all $n$. Show that if $\sum_{n=1}^\infty |a_n|^2$ converges, then the product $\prod_{n=1}^\infty(1+a_n)$ converges to a non-zero limit if and only if $\sum_{n=1}^\infty a_n$ converges. One can get a proof by using $|a_n|^2$ to bound $|\log(1+a_n)-a_n|$. Here is my question : is the converse of this statement also true? If ""the product $\prod_{n=1}^\infty(1+a_n)$ converges to a non-zero limit if and only if $\sum_{n=1}^\infty a_n$ converges"", then $\sum_{n=1}^\infty |a_n|^2$ converges.","The question is motivated by the following exercise in complex analysis: Let $\{a_n\}\subset{\Bbb C}$ such that $a_n\neq-1$ for all $n$. Show that if $\sum_{n=1}^\infty |a_n|^2$ converges, then the product $\prod_{n=1}^\infty(1+a_n)$ converges to a non-zero limit if and only if $\sum_{n=1}^\infty a_n$ converges. One can get a proof by using $|a_n|^2$ to bound $|\log(1+a_n)-a_n|$. Here is my question : is the converse of this statement also true? If ""the product $\prod_{n=1}^\infty(1+a_n)$ converges to a non-zero limit if and only if $\sum_{n=1}^\infty a_n$ converges"", then $\sum_{n=1}^\infty |a_n|^2$ converges.",,['sequences-and-series']
78,"$\sin n>0$, $a_n=1/n \, ,\sin n<0$, $a_n=-1/n \, , \sum_{n=1}^{\infty} a_n$ converge?",", ,  converge?","\sin n>0 a_n=1/n \, ,\sin n<0 a_n=-1/n \, , \sum_{n=1}^{\infty} a_n","Define sequence $a_n$ as: If $\sin n>0$, $a_n=1/n$, and if $\sin n<0$, $a_n=-1/n$. Does the series $\displaystyle \sum_{n=1}^{\infty} a_n$ converge?","Define sequence $a_n$ as: If $\sin n>0$, $a_n=1/n$, and if $\sin n<0$, $a_n=-1/n$. Does the series $\displaystyle \sum_{n=1}^{\infty} a_n$ converge?",,['sequences-and-series']
79,What functions satisfy $\sum _{n=1} ^{\infty} x_n < \infty \ \Rightarrow \sum _{n=1} ^{\infty} f(x_n) < \infty $ [duplicate],What functions satisfy  [duplicate],\sum _{n=1} ^{\infty} x_n < \infty \ \Rightarrow \sum _{n=1} ^{\infty} f(x_n) < \infty ,This question already has answers here : The set of functions which map convergent series to convergent series (3 answers) Closed 11 years ago . Could you help me with this problem? What functions $f: \mathbb{R} \rightarrow \mathbb{R}$ satisfy the following implication? $\sum _{n=1} ^{\infty} x_n < \infty \ \Rightarrow  \sum _{n=1} ^{\infty} f(x_n) < \infty $ The necessary condition for convergence of series $\sum _{n=1} ^{\infty} a_n $ is that $\lim a_n =0$. So I think that $f$ should be decreasing. Series is convergent $\iff$ $\forall \epsilon>0 \ \ \exists N\in \mathbb{N} \ : \ \forall q \ge p \ge k \ : \ |\sum _{n=p} ^q a_n|< \epsilon$. But I don't know how to use it. Could you help me? Thank you.,This question already has answers here : The set of functions which map convergent series to convergent series (3 answers) Closed 11 years ago . Could you help me with this problem? What functions $f: \mathbb{R} \rightarrow \mathbb{R}$ satisfy the following implication? $\sum _{n=1} ^{\infty} x_n < \infty \ \Rightarrow  \sum _{n=1} ^{\infty} f(x_n) < \infty $ The necessary condition for convergence of series $\sum _{n=1} ^{\infty} a_n $ is that $\lim a_n =0$. So I think that $f$ should be decreasing. Series is convergent $\iff$ $\forall \epsilon>0 \ \ \exists N\in \mathbb{N} \ : \ \forall q \ge p \ge k \ : \ |\sum _{n=p} ^q a_n|< \epsilon$. But I don't know how to use it. Could you help me? Thank you.,,"['sequences-and-series', 'convergence-divergence']"
80,Kind of counter intuitive sum of log gamma,Kind of counter intuitive sum of log gamma,,"I came across an infinite series that appears to be rather counter intuitive. Show that $\displaystyle \sum_{k=1}^{\infty}(-1)^{k+1}\ln(\Gamma(k+1))=\frac{-1}{4}\ln\left (\frac{\pi}{2}\right)$ At first glance, it obviously diverges.  I ran this through Mathematica for a check and that is what it said, ""sum does not converge"". But, I ran it through Maple as $\displaystyle \sum_{k=1}^{\infty}(-1)^{k+1}\ln(k!)$ and it actually returned the above result.  Mathematica still would not. If I entered it in using the Gamma function instead of its equivalent factorial, it would not return the result. What is going on here?.  I presume this has something to do with analytic continuation of some sort?. Since $k!=\Gamma(k+1)$,  why would Maple return the result for the factorial but would not for the Gamma even though they are essentially the same thing?. It reminds me of $\zeta(0)=\frac{-1}{2}$. If we just let $s=0$ in $\displaystyle\sum_{k=1}^{\infty}\frac{1}{k^{s}}$ we get an infinite string of 1's.  But, using the functional equation, it can be shown to converge to -1/2. How can the above sum be shown to equal $\frac{-1}{4}\ln\left (\frac{\pi}{2}\right)$?. I searched all around for something on this, but could find nothing. Thanks all.  I hope you find this as interesting as I have.","I came across an infinite series that appears to be rather counter intuitive. Show that $\displaystyle \sum_{k=1}^{\infty}(-1)^{k+1}\ln(\Gamma(k+1))=\frac{-1}{4}\ln\left (\frac{\pi}{2}\right)$ At first glance, it obviously diverges.  I ran this through Mathematica for a check and that is what it said, ""sum does not converge"". But, I ran it through Maple as $\displaystyle \sum_{k=1}^{\infty}(-1)^{k+1}\ln(k!)$ and it actually returned the above result.  Mathematica still would not. If I entered it in using the Gamma function instead of its equivalent factorial, it would not return the result. What is going on here?.  I presume this has something to do with analytic continuation of some sort?. Since $k!=\Gamma(k+1)$,  why would Maple return the result for the factorial but would not for the Gamma even though they are essentially the same thing?. It reminds me of $\zeta(0)=\frac{-1}{2}$. If we just let $s=0$ in $\displaystyle\sum_{k=1}^{\infty}\frac{1}{k^{s}}$ we get an infinite string of 1's.  But, using the functional equation, it can be shown to converge to -1/2. How can the above sum be shown to equal $\frac{-1}{4}\ln\left (\frac{\pi}{2}\right)$?. I searched all around for something on this, but could find nothing. Thanks all.  I hope you find this as interesting as I have.",,['sequences-and-series']
81,"How to find convergence region of $\sum_{n\geqslant 0, m \geqslant 0} x^n y^m \binom{n+m}{n}^2$",How to find convergence region of,"\sum_{n\geqslant 0, m \geqslant 0} x^n y^m \binom{n+m}{n}^2","The following two series are special cases of Appell $F_3$ and $F_4$, namely: $$   \mathcal{S}_1 = \sum_{n \geqslant 0, m \geqslant 0} \frac{x^n y^m}{\binom{n+m}{n}} $$ and $$   \mathcal{S}_2 = \sum_{n \geqslant 0, m \geqslant 0} \binom{n+m}{n}^2 x^n y^m $$ How would one establish that $\mathcal{S}_1$ converges for $\{ (x,y)\colon -1<x<1, -1<y<1 \}$, and $\mathcal{S}_2$ converges for $\{ (x,y) \colon \sqrt{|x|} + \sqrt{|y|} < 1\}$.","The following two series are special cases of Appell $F_3$ and $F_4$, namely: $$   \mathcal{S}_1 = \sum_{n \geqslant 0, m \geqslant 0} \frac{x^n y^m}{\binom{n+m}{n}} $$ and $$   \mathcal{S}_2 = \sum_{n \geqslant 0, m \geqslant 0} \binom{n+m}{n}^2 x^n y^m $$ How would one establish that $\mathcal{S}_1$ converges for $\{ (x,y)\colon -1<x<1, -1<y<1 \}$, and $\mathcal{S}_2$ converges for $\{ (x,y) \colon \sqrt{|x|} + \sqrt{|y|} < 1\}$.",,"['sequences-and-series', 'reference-request']"
82,Tricky radius of convergence: $\sum\limits_{n=0}^\infty\cos\left(\alpha\sqrt{1+n^2}\right)z^n$,Tricky radius of convergence:,\sum\limits_{n=0}^\infty\cos\left(\alpha\sqrt{1+n^2}\right)z^n,"I encountered the following power series, and while I know a couple of ways to determine radius of convergence, I wasn't able to figure out how to evaluate the appropriate limit to get said radius. Can anyone help? What is the radius of convergence of the power series $$\sum_{n=0}^\infty\cos\left(\alpha\sqrt{1+n^2}\right)z^n,$$ where $\alpha$ is any real number? What if $\alpha$ is a complex number?","I encountered the following power series, and while I know a couple of ways to determine radius of convergence, I wasn't able to figure out how to evaluate the appropriate limit to get said radius. Can anyone help? What is the radius of convergence of the power series $$\sum_{n=0}^\infty\cos\left(\alpha\sqrt{1+n^2}\right)z^n,$$ where $\alpha$ is any real number? What if $\alpha$ is a complex number?",,"['sequences-and-series', 'complex-analysis', 'power-series']"
83,Cauchy-Product of non-absolutely convergent series,Cauchy-Product of non-absolutely convergent series,,"While grading some basic coursework on analysis, I read an argument, that a Cauchy product of two series that converge but not absolutely can never converge i.e. if $\sum a_n$, $\sum b_n$ converge but not absolutely, the series $\sum c_n$ with $$c_n= \sum_{k=0}^n a_{n-k}b_k$$ diverges. Although we didn't have any theorem in the course stating something like this, it made me wonder if it was true.","While grading some basic coursework on analysis, I read an argument, that a Cauchy product of two series that converge but not absolutely can never converge i.e. if $\sum a_n$, $\sum b_n$ converge but not absolutely, the series $\sum c_n$ with $$c_n= \sum_{k=0}^n a_{n-k}b_k$$ diverges. Although we didn't have any theorem in the course stating something like this, it made me wonder if it was true.",,"['sequences-and-series', 'analysis', 'convergence-divergence']"
84,Limit of the sequence $u_{n+1}=2^{n+1}\arctan \left(\frac{u_{n}}{2^{n+1}}\right)$,Limit of the sequence,u_{n+1}=2^{n+1}\arctan \left(\frac{u_{n}}{2^{n+1}}\right),"I am interested in calculating the limit of the sequence $$ u_{n + 1} = 2^{n + 1} \arctan\left(\dfrac{u_{n}}{2^{n + 1}}\right) \,,\qquad\left(\ u_{0} > 0\,\right) $$ By the inequality $\arctan\left(x\right) < x,\ \mbox{if}\quad x > 0\ ,$ we can see that: $u_{n}$ is strictly decreasing and $0 < u_{n} < u_{0}$ , thus the sequence converges. As $\arctan\left(x\right) \approx x$ ( if $x$ approaches to $0$ ) and thus $u_{n+1}\approx u_{n}$ ( if $n$ is big ), it converges very slowly. ( a $\tt Python$ script shows that we get a decrease of $0.01$ in $1000$ steps ! ). By the fixed point theorem, we can show that $$ \dfrac{u_{n}}{2^{n}} \to 0 $$ But it is too little to infer that the limit of $u_{n}$ is zero $\ldots$ Can anyone have an idea, how to prove it ?.","I am interested in calculating the limit of the sequence By the inequality we can see that: is strictly decreasing and , thus the sequence converges. As ( if approaches to ) and thus ( if is big ), it converges very slowly. ( a script shows that we get a decrease of in steps ! ). By the fixed point theorem, we can show that But it is too little to infer that the limit of is zero Can anyone have an idea, how to prove it ?.","
u_{n + 1} = 2^{n + 1}
\arctan\left(\dfrac{u_{n}}{2^{n + 1}}\right)
\,,\qquad\left(\ u_{0} > 0\,\right)
 \arctan\left(x\right) < x,\ \mbox{if}\quad x > 0\ , u_{n} 0 < u_{n} < u_{0} \arctan\left(x\right) \approx x x 0 u_{n+1}\approx u_{n} n \tt Python 0.01 1000 
\dfrac{u_{n}}{2^{n}} \to 0
 u_{n} \ldots","['sequences-and-series', 'limits']"
85,A sequence derived from $\lceil \sin (2n) \rceil$ with some interesting features,A sequence derived from  with some interesting features,\lceil \sin (2n) \rceil,"I was playing with Excel and created a sequence with some interesting features. In column A, list the sequence $\color{red}{a_n=\lceil \sin (2n) \rceil}$ (using the ceiling function ). In column B, list the sequence of gaps between the terms of the previous sequence. In column C, list the sequence of gaps between the terms of the previous sequence. And so on. Let $b_n$ be the sequence in the top diagonal (highlighted). Behold the graph of $|b_n/2^n|$ against $n$ : The terms on the approximate horizontal line are very close to $1/44$ . What's going on here? More specifically: Why does dividing the terms of $|b_n|$ by $2^n$ yield such stability (as opposed to making the terms go toward $0$ or infinity)? Why are there long strings of values that are very close to $1/44$ ? Why does the graph dip to $0$ at $n=698$ and then go back up? How does the graph behave for $n>1000$ ? I only have a fuzzy notion that the last three questions may be related to rational approximations for $\pi$ . For comparison purposes only: graphs derived from other starting sequences If $a_n=\lceil \sin (\color{red}{1}n) \rceil$ , here is the graph of $|b_n/2^n|$ against $n$ : If $a_n=\lceil \sin (\color{red}{3}n) \rceil$ , here is the graph of $|b_n/2^n|$ against $n$ : If $a_n=\lceil \sin (\color{red}{4}n) \rceil$ , here is the graph of $|b_n/2^n|$ against $n$ : If $a_n$ is a random binary sequence with $0$ and $1$ equally likely, here is one possible graph of $|b_n/2^n|$ against $n$ : If $a_n$ is the sequence of prime numbers, here is the graph of $|b_n/2^n|$ against $n$ : (Incidentally, the last two graphs resemble "" Mountains of Guilin "" functions, i.e. $f_{p_j,n}(x)=|\sin (p_1x)+\sin (p_2x)+\dots+\sin (p_nx)|$ where $p_j$ are linearly independent over $\mathbb{Q}$ .) (The answers to this question might resolve an earlier question of mine: Strange dips in sequence $u_n=\log{|(n-1)^{\text{st}}\text{ difference of first $n$ primes}|}$ .)","I was playing with Excel and created a sequence with some interesting features. In column A, list the sequence (using the ceiling function ). In column B, list the sequence of gaps between the terms of the previous sequence. In column C, list the sequence of gaps between the terms of the previous sequence. And so on. Let be the sequence in the top diagonal (highlighted). Behold the graph of against : The terms on the approximate horizontal line are very close to . What's going on here? More specifically: Why does dividing the terms of by yield such stability (as opposed to making the terms go toward or infinity)? Why are there long strings of values that are very close to ? Why does the graph dip to at and then go back up? How does the graph behave for ? I only have a fuzzy notion that the last three questions may be related to rational approximations for . For comparison purposes only: graphs derived from other starting sequences If , here is the graph of against : If , here is the graph of against : If , here is the graph of against : If is a random binary sequence with and equally likely, here is one possible graph of against : If is the sequence of prime numbers, here is the graph of against : (Incidentally, the last two graphs resemble "" Mountains of Guilin "" functions, i.e. where are linearly independent over .) (The answers to this question might resolve an earlier question of mine: Strange dips in sequence .)","\color{red}{a_n=\lceil \sin (2n) \rceil} b_n |b_n/2^n| n 1/44 |b_n| 2^n 0 1/44 0 n=698 n>1000 \pi a_n=\lceil \sin (\color{red}{1}n) \rceil |b_n/2^n| n a_n=\lceil \sin (\color{red}{3}n) \rceil |b_n/2^n| n a_n=\lceil \sin (\color{red}{4}n) \rceil |b_n/2^n| n a_n 0 1 |b_n/2^n| n a_n |b_n/2^n| n f_{p_j,n}(x)=|\sin (p_1x)+\sin (p_2x)+\dots+\sin (p_nx)| p_j \mathbb{Q} u_n=\log{|(n-1)^{\text{st}}\text{ difference of first n primes}|}","['sequences-and-series', 'number-theory', 'trigonometry', 'graphing-functions', 'pi']"
86,Factorial-like product where the factors are offset,Factorial-like product where the factors are offset,,"Does this ""factorial-like"" product have a name? $ (1 + t) \cdot (2 + t) \cdot (3 + t) \cdot \ldots \cdot (n + t) $ where $n \in \mathbb{N}$ and $0 < t < 1$ ? So it's like a factorial in the sense that the factors differ by 1, but the factors are integers offset by a fixed real number $t$ . And is there a known way to numerically approximate the logarithm of such a product for large $n$ where an iterative approach would be too slow? (just like the logarithm of the Gamma function can be approximated well)","Does this ""factorial-like"" product have a name? where and ? So it's like a factorial in the sense that the factors differ by 1, but the factors are integers offset by a fixed real number . And is there a known way to numerically approximate the logarithm of such a product for large where an iterative approach would be too slow? (just like the logarithm of the Gamma function can be approximated well)", (1 + t) \cdot (2 + t) \cdot (3 + t) \cdot \ldots \cdot (n + t)  n \in \mathbb{N} 0 < t < 1 t n,"['sequences-and-series', 'numerical-methods', 'approximation', 'factorial', 'gamma-function']"
87,Determining convergence of sequence $a_n=a_{n-1}^{-1}+a_{n-2}^{-1}$ [duplicate],Determining convergence of sequence  [duplicate],a_n=a_{n-1}^{-1}+a_{n-2}^{-1},"This question already has answers here : Proof of existence of a limit for the sequence recursively-defined with $a_1=1$, $a_2=1$ and $a_n=\frac{1}{a_{n-1}}+\frac{1}{a_{n-2}}$ for $n\ge2$ (5 answers) Closed 2 years ago . I'm trying to prove convergence for the sequence $$a_n=\frac{1}{a_{n-1}}+\frac{1}{a_{n-2}}$$ with $a_0=a_1=1$ . If it does converge then it converges to $\sqrt{2}$ , which agrees with numerical tests. $$$$ I've managed to prove two facts about the sequence, although I'm not sure they're relevant to the question or not. Firstly, for every set of three consecutive terms in the sequence, at least one is bigger than $\sqrt{2}$ and at least one is smaller than $\sqrt{2}$ . Secondly, if two consecutive terms are in the interval $(\alpha,\,2\alpha^{-1})$ for some $\alpha\in[1,\,\sqrt{2})$ , then all terms that follow are in this interval as well. $$$$ Does anyone have an idea for how to prove convergence, with or without these facts?","This question already has answers here : Proof of existence of a limit for the sequence recursively-defined with $a_1=1$, $a_2=1$ and $a_n=\frac{1}{a_{n-1}}+\frac{1}{a_{n-2}}$ for $n\ge2$ (5 answers) Closed 2 years ago . I'm trying to prove convergence for the sequence with . If it does converge then it converges to , which agrees with numerical tests. I've managed to prove two facts about the sequence, although I'm not sure they're relevant to the question or not. Firstly, for every set of three consecutive terms in the sequence, at least one is bigger than and at least one is smaller than . Secondly, if two consecutive terms are in the interval for some , then all terms that follow are in this interval as well. Does anyone have an idea for how to prove convergence, with or without these facts?","a_n=\frac{1}{a_{n-1}}+\frac{1}{a_{n-2}} a_0=a_1=1 \sqrt{2}  \sqrt{2} \sqrt{2} (\alpha,\,2\alpha^{-1}) \alpha\in[1,\,\sqrt{2}) ","['sequences-and-series', 'recursion']"
88,Evaluate the series $ \sum_{n=1}^{\infty} \frac{1}{n(e^{2\pi n}-1)} $.,Evaluate the series ., \sum_{n=1}^{\infty} \frac{1}{n(e^{2\pi n}-1)} ,"In Ramanujan's Notebooks Volume 2 by B.C. Berndt I came across the formula $$ \sum_{n=1}^{\infty} \frac{1}{n(e^{2\pi n}-1)} = \log 2 + \frac{3}{4} \log \pi - \frac{\pi}{12} -\log \Gamma \left(\frac{1}{4} \right). $$ The proof provided uses some special values from the theory of elliptic functions, but I am unfamiliar with the subject. Does there exist a different evaluation of the series? I tried contour integration, cotangent partial fraction, and applying Poisson summation or converting to an integral but so far no success. Any help is appreciated!","In Ramanujan's Notebooks Volume 2 by B.C. Berndt I came across the formula The proof provided uses some special values from the theory of elliptic functions, but I am unfamiliar with the subject. Does there exist a different evaluation of the series? I tried contour integration, cotangent partial fraction, and applying Poisson summation or converting to an integral but so far no success. Any help is appreciated!", \sum_{n=1}^{\infty} \frac{1}{n(e^{2\pi n}-1)} = \log 2 + \frac{3}{4} \log \pi - \frac{\pi}{12} -\log \Gamma \left(\frac{1}{4} \right). ,"['sequences-and-series', 'hyperbolic-functions']"
89,$\sum _{n=0}^{\infty} \frac{1}{(n+1) (n+2)} \left(\frac{1}{\lfloor n \phi \rfloor +2}+\frac{1}{\lfloor n \phi ^{-1} \rfloor +2}\right)$,,\sum _{n=0}^{\infty} \frac{1}{(n+1) (n+2)} \left(\frac{1}{\lfloor n \phi \rfloor +2}+\frac{1}{\lfloor n \phi ^{-1} \rfloor +2}\right),"How to prove: $$\sum _{n=0}^{\infty} \frac{1}{(n+1) (n+2)} \left(\frac{1}{\lfloor n \phi \rfloor +2}+\frac{1}{\lfloor n \phi ^{-1} \rfloor +2}\right)=\frac{3}{4}$$ Here $\phi=\frac{1+\sqrt 5}{2}$ and $\lfloor \cdot \rfloor$ the floor function. I suspect this is related to number theory (continued fractions) which I'm not familiar with. Any help will be appreciated. Update: Here is a related problem, solved by similar techniques.","How to prove: Here and the floor function. I suspect this is related to number theory (continued fractions) which I'm not familiar with. Any help will be appreciated. Update: Here is a related problem, solved by similar techniques.",\sum _{n=0}^{\infty} \frac{1}{(n+1) (n+2)} \left(\frac{1}{\lfloor n \phi \rfloor +2}+\frac{1}{\lfloor n \phi ^{-1} \rfloor +2}\right)=\frac{3}{4} \phi=\frac{1+\sqrt 5}{2} \lfloor \cdot \rfloor,"['sequences-and-series', 'number-theory', 'golden-ratio']"
90,Evaluate $\lim\limits_{n\rightarrow\infty} \mathrm{srt}_n\left({^{n+1}}2\right)$,Evaluate,\lim\limits_{n\rightarrow\infty} \mathrm{srt}_n\left({^{n+1}}2\right),"Notation: ${^n}x = x^{x^{\cdots^x}}$ is tetration , i.e. $x$ to the power of itself $n$ times. $\mathrm{srt}_n(x)$ is the super $n$ -th root, or the inverse function of ${^n}x$ , which is well defined for $x\ge 1$ . I can prove that $$ \lim\limits_{n\rightarrow\infty} \mathrm{srt}_n\left({^{n+1}}2\right) $$ converges to some value between about $\mathrm{srt}_3(256)\approx 2.2915$ and about $2.6$ , but it is computationally intractable even for relatively small $n$ . For example $^5 2\approx 2\times 10^{19728}$ . For ease of notation, we let $s_n = \mathrm{srt}_n(^{n+1}2)$ . I would be very surprised if there's a nice closed form of $\lim\limits_{n\rightarrow\infty} s_n$ , so I'm mostly interested here in how to approximate it other than a direct computation of the definition, which really isn't all that viable. As noted above, even computing $s_4$ is tough to do from the formula, though taking some logarithms can get you a bit further, it doesn't help much since tetration is much faster than exponentiation. Is there some trick that convert the formula to $s_n$ into something more tractable? I can see how you could use the same approach as the one I used (see below) to get better lower bounds than $2.29$ , but I suspect that would also become extremely difficult to use if you wanted any sort of precision (even one decimal place might be hard). Proof of convergence: Clearly $s_n > 2$ for all $n$ , so it suffices to show $s_n$ is decreasing. Observe: \begin{eqnarray} ^n s_n &=& 2^{\left(^n2\right)} = 2^{\left(^{n-1}s_{n-1}\right)}<(s_{n-1})^{\left(^{n-1}s_{n-1}\right)} = {^n}(s_{n-1}) \end{eqnarray} since $x\to {^n}x$ is increasing, this implies $s_n$ decreases. Proof of lower bound: We prove that $s_n > c = \mathrm{srt}_3(256)$ for all $n$ by proving inductively ${^n} c \le\frac{\ln 2}{2\ln(c)} \left({^{n+1}}2\right)$ . Since $\frac{\ln 2}{2\ln(c)} <1$ , this means ${^n}c<{^{n+1}}2$ . Taking $\mathrm{srt}_n$ of both sides shows $s_n>c$ . For the base case, we take $n=2$ : \begin{eqnarray} c^{c^c} &=& 256 = 2^8\\ c^c \ln c &=& 8(\ln 2)\\ c^c \ln c &=& \frac12 (\ln 2) 16\\ c^c&=&\frac{\ln 2}{2\ln(c)} \left({^{3}}2\right) \end{eqnarray} Now, for the inductive step. Suppose ${^n} c \le\frac{\ln 2}{2\ln(c)} \left({^{n+1}}2\right)$ for some $n\ge 2$ . Observe that for $x > 4$ (this is not a tight bound): $$ \frac{\ln 2}{2\ln(c)} x < \frac1{\ln c}\ln\left(\frac{\ln 2}{2\ln(c)}\right) + \frac{\ln 2}{\ln c}x $$ Since ${^{n+1}2} > 4$ , we therefore have \begin{eqnarray} {^n} c &\le&\frac{\ln 2}{2\ln(c)} \left({^{n+1}}2\right)\\ &<&\frac1{\ln c}\ln\left(\frac{\ln 2}{2\ln(c)}\right) + \frac{\ln 2}{\ln c}\left({^{n+1}2}\right) \end{eqnarray} Taking the $c$ th power of both sides yields $$ {^{n+1}} c < \frac{\ln 2}{2\ln(c)} \left(^{n+2}2\right) $$ as desired. Hence we have inductively $$ {^{n}} c < \frac{\ln 2}{2\ln(c)} \left(^{n+1}2\right) $$ for all $n\ge 2$ . Therefore $s_n > c$ for all $n$ . Computed with WolframAlpha, the first three terms of $s$ are \begin{eqnarray} s_1 &=& 4\\ s_2 &\approx& 2.74537...\\ s_3 &\approx& 2.58611...\\ s_4 &\approx& 2.57406... \end{eqnarray} Search query used for $s_2$ , $s_3$ , and $s_4$ .","Notation: is tetration , i.e. to the power of itself times. is the super -th root, or the inverse function of , which is well defined for . I can prove that converges to some value between about and about , but it is computationally intractable even for relatively small . For example . For ease of notation, we let . I would be very surprised if there's a nice closed form of , so I'm mostly interested here in how to approximate it other than a direct computation of the definition, which really isn't all that viable. As noted above, even computing is tough to do from the formula, though taking some logarithms can get you a bit further, it doesn't help much since tetration is much faster than exponentiation. Is there some trick that convert the formula to into something more tractable? I can see how you could use the same approach as the one I used (see below) to get better lower bounds than , but I suspect that would also become extremely difficult to use if you wanted any sort of precision (even one decimal place might be hard). Proof of convergence: Clearly for all , so it suffices to show is decreasing. Observe: since is increasing, this implies decreases. Proof of lower bound: We prove that for all by proving inductively . Since , this means . Taking of both sides shows . For the base case, we take : Now, for the inductive step. Suppose for some . Observe that for (this is not a tight bound): Since , we therefore have Taking the th power of both sides yields as desired. Hence we have inductively for all . Therefore for all . Computed with WolframAlpha, the first three terms of are Search query used for , , and .","{^n}x = x^{x^{\cdots^x}} x n \mathrm{srt}_n(x) n {^n}x x\ge 1 
\lim\limits_{n\rightarrow\infty} \mathrm{srt}_n\left({^{n+1}}2\right)
 \mathrm{srt}_3(256)\approx 2.2915 2.6 n ^5 2\approx 2\times 10^{19728} s_n = \mathrm{srt}_n(^{n+1}2) \lim\limits_{n\rightarrow\infty} s_n s_4 s_n 2.29 s_n > 2 n s_n \begin{eqnarray}
^n s_n &=& 2^{\left(^n2\right)} = 2^{\left(^{n-1}s_{n-1}\right)}<(s_{n-1})^{\left(^{n-1}s_{n-1}\right)} = {^n}(s_{n-1})
\end{eqnarray} x\to {^n}x s_n s_n > c = \mathrm{srt}_3(256) n {^n} c \le\frac{\ln 2}{2\ln(c)} \left({^{n+1}}2\right) \frac{\ln 2}{2\ln(c)} <1 {^n}c<{^{n+1}}2 \mathrm{srt}_n s_n>c n=2 \begin{eqnarray}
c^{c^c} &=& 256 = 2^8\\
c^c \ln c &=& 8(\ln 2)\\
c^c \ln c &=& \frac12 (\ln 2) 16\\
c^c&=&\frac{\ln 2}{2\ln(c)} \left({^{3}}2\right)
\end{eqnarray} {^n} c \le\frac{\ln 2}{2\ln(c)} \left({^{n+1}}2\right) n\ge 2 x > 4 
\frac{\ln 2}{2\ln(c)} x < \frac1{\ln c}\ln\left(\frac{\ln 2}{2\ln(c)}\right) + \frac{\ln 2}{\ln c}x
 {^{n+1}2} > 4 \begin{eqnarray}
{^n} c &\le&\frac{\ln 2}{2\ln(c)} \left({^{n+1}}2\right)\\
&<&\frac1{\ln c}\ln\left(\frac{\ln 2}{2\ln(c)}\right) + \frac{\ln 2}{\ln c}\left({^{n+1}2}\right)
\end{eqnarray} c 
{^{n+1}} c < \frac{\ln 2}{2\ln(c)} \left(^{n+2}2\right)
 
{^{n}} c < \frac{\ln 2}{2\ln(c)} \left(^{n+1}2\right)
 n\ge 2 s_n > c n s \begin{eqnarray}
s_1 &=& 4\\
s_2 &\approx& 2.74537...\\
s_3 &\approx& 2.58611...\\
s_4 &\approx& 2.57406...
\end{eqnarray} s_2 s_3 s_4","['sequences-and-series', 'limits', 'approximation', 'tetration']"
91,How to proceed with this Sequence question,How to proceed with this Sequence question,,"Let $a,b$ be given positive integers such that $a<b$ . Let $M(a,b)$ be   defined as $$ \frac{\sum_{k=a}^b     \sqrt{k^2+3k+3}}{b-a+1}. $$ Evaluate $[M(a,b)]$ where $[.]$ represents greatest integer function. I have tried to factorise the term inside the square root however I believe it was pretty useless. I have a feeling that it might(?) telescope but I have no clue what to do here. Any help will be appreciated",Let be given positive integers such that . Let be   defined as Evaluate where represents greatest integer function. I have tried to factorise the term inside the square root however I believe it was pretty useless. I have a feeling that it might(?) telescope but I have no clue what to do here. Any help will be appreciated,"a,b a<b M(a,b)  \frac{\sum_{k=a}^b     \sqrt{k^2+3k+3}}{b-a+1}.  [M(a,b)] [.]","['sequences-and-series', 'algebra-precalculus']"
92,Binary weight of OEIS sequence A308092.,Binary weight of OEIS sequence A308092.,,"Preliminaries OEIS sequence A308092 is defined as: The sum of the first $n$ terms of the sequence is the concatenation of the first $n$ bits of the sequence read as binary, with $a(1) = 1$ . And it begins 1, 2, 3, 7, 14, 28, 56, 112, 224, 448, 896, 1791, 3583, 7166, ... which in binary is $$ 1_2, 10_2, 11_2, 111_2, 1110_2, 11100_2, 111000_2, 1110000_2, 11100000_2, 111000000_2, 1110000000_2, 11011111111_2, 110111111111_2, 1101111111110_2. $$ Example To be explicit, for $n = 5$ , $$   \begin{align*}   1 + 2 + 3 + 7 + 14  &= 1_2 + 10_2 + 11_2 + 111_2 + 1110_2 \\ &= 11011_2,   \end{align*} $$ that is, the sum of the first five terms is the first five bits of the sequence. An equivalent definition is $a(n) = c(n) - c(n-1)$ for $n > 2$ , where $c(n)$ is the concatenation of the first $n$ bits of the sequence. Question It appears that the number of ones in the binary representation of $A308092(n)$ is weakly increasing as a function of $n$ . The number of ones is listed here: 1, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 10, 11, 11, 11, 13, 13, 14, 14, 14, 16, 16, 16, 17, 17, 17, 19, 19, 19, 19, 20, 20, 20, 22, 22, 22, 22, 22, 23, 23, 23, 25, 25, 25, 25, 25, 25, 26, 26, 26, 28, 28, 28, 28, 28, 28, 28, 29, 29, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 40, 41, 41, 41, ... I've checked that this claim is true for the first 5000 terms, but I don't know how to prove it. Why is this true? Or is there some large counterexample? Note At first, it appears that the run-lengths of bits in A308092 matches the run-lengths in the ""number of ones"" sequence, but this fails at the $51$ st term. However, they both begin 2, 1, 8, 1, 3, 2, 3, 3, 3, 4, 3, 5, 3, 6, 3, 7, 2, 1, 10, 1, 11, 1, 9, 1, 2, 1, 9, 2, 2, 1, 8, 1, 5, 1, 8, 1, 3, 1, 2, 1, 8, 1, 3, 1, 3, 1, 8, 1, 3, 1, ... two 1s, one 0, eight 1s, one 0, three 1s, two 0s, ... (bits in sequence) (two 1s, one 2, eight 3s, one 10, three 11s, two 13s, ... (""number of ones"" sequence)","Preliminaries OEIS sequence A308092 is defined as: The sum of the first terms of the sequence is the concatenation of the first bits of the sequence read as binary, with . And it begins 1, 2, 3, 7, 14, 28, 56, 112, 224, 448, 896, 1791, 3583, 7166, ... which in binary is Example To be explicit, for , that is, the sum of the first five terms is the first five bits of the sequence. An equivalent definition is for , where is the concatenation of the first bits of the sequence. Question It appears that the number of ones in the binary representation of is weakly increasing as a function of . The number of ones is listed here: 1, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 10, 11, 11, 11, 13, 13, 14, 14, 14, 16, 16, 16, 17, 17, 17, 19, 19, 19, 19, 20, 20, 20, 22, 22, 22, 22, 22, 23, 23, 23, 25, 25, 25, 25, 25, 25, 26, 26, 26, 28, 28, 28, 28, 28, 28, 28, 29, 29, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 40, 41, 41, 41, ... I've checked that this claim is true for the first 5000 terms, but I don't know how to prove it. Why is this true? Or is there some large counterexample? Note At first, it appears that the run-lengths of bits in A308092 matches the run-lengths in the ""number of ones"" sequence, but this fails at the st term. However, they both begin 2, 1, 8, 1, 3, 2, 3, 3, 3, 4, 3, 5, 3, 6, 3, 7, 2, 1, 10, 1, 11, 1, 9, 1, 2, 1, 9, 2, 2, 1, 8, 1, 5, 1, 8, 1, 3, 1, 2, 1, 8, 1, 3, 1, 3, 1, 8, 1, 3, 1, ... two 1s, one 0, eight 1s, one 0, three 1s, two 0s, ... (bits in sequence) (two 1s, one 2, eight 3s, one 10, three 11s, two 13s, ... (""number of ones"" sequence)","n n a(1) = 1 
1_2, 10_2, 11_2, 111_2, 1110_2, 11100_2, 111000_2, 1110000_2, 11100000_2, 111000000_2, 1110000000_2, 11011111111_2, 110111111111_2, 1101111111110_2.
 n = 5 
  \begin{align*}
  1 + 2 + 3 + 7 + 14 
&= 1_2 + 10_2 + 11_2 + 111_2 + 1110_2 \\
&= 11011_2,
  \end{align*}
 a(n) = c(n) - c(n-1) n > 2 c(n) n A308092(n) n 51","['sequences-and-series', 'binary', 'oeis']"
93,An entrance exam problem relating to sequences and limits,An entrance exam problem relating to sequences and limits,,"this is a problem from the entrance exam of the University of Tokyo and unfortunately, the official doesn't offer solutions. 1) Using mathematical induction. Assume $f_{n}(x)=c_{n} x^{a_{n}}$ holds for $n$ , and by $f_{n+1}(x)=p \int_{0}^{x}\left(f_{n}(t)\right)^{1 / q} \mathrm{d} t$ we can get $f_{n+1}(x)$ . Then comparing the coeffient and the exponent will show that it holds for $n+1$ too. 2) 3) 4) 5) 6) I've no idea. I tried to calc the derivatives of $g_n$ , but I don't know what to do next. I can get $a_{n+1}$ from the recursive formula, but the form of it is kinda complex which makes it hard to get $c_{n+1}$ . So I guess the rest questions could be done without knowing what actually $a_n$ and $c_n$ are. But I don't know how to do that. Also, $1 / p+1 / q=1$ seems a frequent condition, how is it usually used in solutions?","this is a problem from the entrance exam of the University of Tokyo and unfortunately, the official doesn't offer solutions. 1) Using mathematical induction. Assume holds for , and by we can get . Then comparing the coeffient and the exponent will show that it holds for too. 2) 3) 4) 5) 6) I've no idea. I tried to calc the derivatives of , but I don't know what to do next. I can get from the recursive formula, but the form of it is kinda complex which makes it hard to get . So I guess the rest questions could be done without knowing what actually and are. But I don't know how to do that. Also, seems a frequent condition, how is it usually used in solutions?",f_{n}(x)=c_{n} x^{a_{n}} n f_{n+1}(x)=p \int_{0}^{x}\left(f_{n}(t)\right)^{1 / q} \mathrm{d} t f_{n+1}(x) n+1 g_n a_{n+1} c_{n+1} a_n c_n 1 / p+1 / q=1,"['sequences-and-series', 'limits', 'analysis']"
94,Are there integral solutions for $(2a-1)(2^{(b+c)}-3^c )=2^b-1$?,Are there integral solutions for ?,(2a-1)(2^{(b+c)}-3^c )=2^b-1,"Can anyone prove this assertion?  Or at least suggest a method of attack?  It has come up in my research. There do not exist $a,b$ and $c$ such that$$  (2a-1)(2^{(b+c)}-3^c )=2^b-1 $$where $a>0,b>1,c>1$ and $a,b,c ∈ Z$ This question came up as I was comparing 2 types of sums: $S1=x+(3/2)x+(3/2)^2x+...+(3/2)^cx, S2=y+2y+2^2y+...+2^by$ to see if they could ever equal one another, given specific constraints on the relationship between x and y - specifically that $y=2x−1$ and $x=2^c(2a−1) $","Can anyone prove this assertion?  Or at least suggest a method of attack?  It has come up in my research. There do not exist $a,b$ and $c$ such that$$  (2a-1)(2^{(b+c)}-3^c )=2^b-1 $$where $a>0,b>1,c>1$ and $a,b,c ∈ Z$ This question came up as I was comparing 2 types of sums: $S1=x+(3/2)x+(3/2)^2x+...+(3/2)^cx, S2=y+2y+2^2y+...+2^by$ to see if they could ever equal one another, given specific constraints on the relationship between x and y - specifically that $y=2x−1$ and $x=2^c(2a−1) $",,"['sequences-and-series', 'number-theory', 'collatz-conjecture']"
95,What is $\sum\limits_{m=1}^\infty \frac{H_m}{m^6} \cdot (\frac{1}{2})^m$?,What is ?,\sum\limits_{m=1}^\infty \frac{H_m}{m^6} \cdot (\frac{1}{2})^m,"We consider a following class of Euler sums: \begin{equation} {\bf H}^{(1)}_p(\frac{1}{2}) := \sum\limits_{m=1}^\infty \frac{H_m}{m^p} \cdot \frac{1}{2^m} \end{equation} Now by using the following integral representation: \begin{equation} {\bf H}^{(1)}_p(\frac{1}{2}) = \int\limits_0^{1/2} \frac{[\log(\frac{1/2}{x})]^{p-1}}{(p-1)!} \cdot \frac{Li_1(x)}{x(1-x)} dx \end{equation} and then by integration by parts we computed those sums for $p\le 5$. We have: \begin{eqnarray} {\bf H}^{(1)}_1(1/2) &=& \frac{\pi ^2}{12}\\ {\bf H}^{(1)}_2(1/2) &=& \zeta (3)-\frac{1}{12} \pi ^2 \log (2)\\ {\bf H}^{(1)}_3(1/2) &=& \text{Li}_4\left(\frac{1}{2}\right)-\frac{1}{8} \zeta (3) \log (2)+\frac{\pi ^4}{720}+\frac{\log ^4(2)}{24}\\ {\bf H}^{(1)}_4(1/2) &=& 2 \text{Li}_5\left(\frac{1}{2}\right)+\text{Li}_4\left(\frac{1}{2}\right) \log (2)-\frac{\pi ^2 \zeta (3)}{12}+\frac{\zeta (5)}{32}+\frac{1}{2} \zeta (3) \log ^2(2)+\frac{\log ^5(2)}{40}-\frac{1}{36} \pi ^2 \log    ^3(2)-\frac{1}{720} \pi ^4 \log (2)\\ {\bf H}^{(1)}_5(1/2) &=& 3 \text{Li}_6\left(\frac{1}{2}\right)+\text{Li}_5\left(\frac{1}{2}\right) \log (2)-\frac{\zeta (3)^2}{4}-\frac{1}{6} \zeta (3) \log ^3(2)+\frac{1}{12} \pi ^2 \zeta (3) \log (2)-\frac{1}{32} \zeta (5) \log (2)-\frac{19 \pi    ^6}{8640}-\frac{\log ^6(2)}{240}+\frac{1}{144} \pi ^2 \log ^4(2)+\frac{\pi ^4 \log ^2(2)}{1440}-\frac{1}{2} {\bf H}^{(1)}_5(-1) \end{eqnarray} Note that the last case above involves a new quantity ${\bf H}^{(1)}_5(-1) = \zeta(-5,1)+Li_6(-1)$ a quantity which is not expressible via poly-logarithms. Now, my question is here quite humble. Can we push this thread up one step further and compute the result for $p=6$? Is the quantity in question also ""new"" or can it be reduced to the univariate zeta functions only? I have used the following code to check in http://wayback.cecm.sfu.ca/cgi-bin/EZFace/zetaform.cgi for possible linear dependencies between the quantity in question and zeta functions. lindep([zp(2,6,1)+zp(2,7), z(7), z(2)^3*log(2), z(3)^2*log(2), z(5)*log(2)^2, z(5)*z(2), z(2)^2*z(3), z(2)^2*log(2)^3, z(3)*log(2)^4, z(2)*log(2)^5, log(2)^7, zp(2,4)*log(2)^3, zp(2,5)*log(2)^2, zp(2,6)*log(2), zp(2,7), zp(2,5,1)*log(2)]) Unfortunately I couldn't find any results.","We consider a following class of Euler sums: \begin{equation} {\bf H}^{(1)}_p(\frac{1}{2}) := \sum\limits_{m=1}^\infty \frac{H_m}{m^p} \cdot \frac{1}{2^m} \end{equation} Now by using the following integral representation: \begin{equation} {\bf H}^{(1)}_p(\frac{1}{2}) = \int\limits_0^{1/2} \frac{[\log(\frac{1/2}{x})]^{p-1}}{(p-1)!} \cdot \frac{Li_1(x)}{x(1-x)} dx \end{equation} and then by integration by parts we computed those sums for $p\le 5$. We have: \begin{eqnarray} {\bf H}^{(1)}_1(1/2) &=& \frac{\pi ^2}{12}\\ {\bf H}^{(1)}_2(1/2) &=& \zeta (3)-\frac{1}{12} \pi ^2 \log (2)\\ {\bf H}^{(1)}_3(1/2) &=& \text{Li}_4\left(\frac{1}{2}\right)-\frac{1}{8} \zeta (3) \log (2)+\frac{\pi ^4}{720}+\frac{\log ^4(2)}{24}\\ {\bf H}^{(1)}_4(1/2) &=& 2 \text{Li}_5\left(\frac{1}{2}\right)+\text{Li}_4\left(\frac{1}{2}\right) \log (2)-\frac{\pi ^2 \zeta (3)}{12}+\frac{\zeta (5)}{32}+\frac{1}{2} \zeta (3) \log ^2(2)+\frac{\log ^5(2)}{40}-\frac{1}{36} \pi ^2 \log    ^3(2)-\frac{1}{720} \pi ^4 \log (2)\\ {\bf H}^{(1)}_5(1/2) &=& 3 \text{Li}_6\left(\frac{1}{2}\right)+\text{Li}_5\left(\frac{1}{2}\right) \log (2)-\frac{\zeta (3)^2}{4}-\frac{1}{6} \zeta (3) \log ^3(2)+\frac{1}{12} \pi ^2 \zeta (3) \log (2)-\frac{1}{32} \zeta (5) \log (2)-\frac{19 \pi    ^6}{8640}-\frac{\log ^6(2)}{240}+\frac{1}{144} \pi ^2 \log ^4(2)+\frac{\pi ^4 \log ^2(2)}{1440}-\frac{1}{2} {\bf H}^{(1)}_5(-1) \end{eqnarray} Note that the last case above involves a new quantity ${\bf H}^{(1)}_5(-1) = \zeta(-5,1)+Li_6(-1)$ a quantity which is not expressible via poly-logarithms. Now, my question is here quite humble. Can we push this thread up one step further and compute the result for $p=6$? Is the quantity in question also ""new"" or can it be reduced to the univariate zeta functions only? I have used the following code to check in http://wayback.cecm.sfu.ca/cgi-bin/EZFace/zetaform.cgi for possible linear dependencies between the quantity in question and zeta functions. lindep([zp(2,6,1)+zp(2,7), z(7), z(2)^3*log(2), z(3)^2*log(2), z(5)*log(2)^2, z(5)*z(2), z(2)^2*z(3), z(2)^2*log(2)^3, z(3)*log(2)^4, z(2)*log(2)^5, log(2)^7, zp(2,4)*log(2)^3, zp(2,5)*log(2)^2, zp(2,6)*log(2), zp(2,7), zp(2,5,1)*log(2)]) Unfortunately I couldn't find any results.",,"['sequences-and-series', 'special-functions', 'euler-sums']"
96,Primes of Atlantis: a definition and a problem,Primes of Atlantis: a definition and a problem,,"We denote the floor function as $\lfloor x\rfloor$, and for integers $k\geq 1$ we consider the following sum of the areas of three consecutive circles $$\pi  k^2+\pi(k+1)^2+\pi(k+2)^2=\pi  \left( 3k^2+6k+5\right). $$ Definition. When for an integer $n\geq 1$ the integer    $$\mathcal{A}(n)=\lfloor  \pi\left( 3n^2+6n+5\right) \rfloor$$ is a prime number, I say that it's a prime of Atlantis. Our sequence of prime of Atlantis starts as $$43, 157, 241, 769, 4567, 11551, 14341, 16631, 19949\ldots$$ corresponding to the indexes $n's:1, 3, 4, 8, 21, 34, 38, 41, 45, \ldots$ as you can see with these codes using Wolfram Alpha online calculator: Table IsPrime(floor(pi (n^2+(n+1)^2+(n+2)^2))), for n=1 to 100 Table floor(pi (n^2+(n+1)^2+(n+2)^2)), for n=1 to 100 Question. I would like to know if we can deduce if there are infinitely many primes of Atlantis. Many thanks. If you can't solve the problem, but you can provide us useful reasonings or calculations about the Question, please share your knowledges.","We denote the floor function as $\lfloor x\rfloor$, and for integers $k\geq 1$ we consider the following sum of the areas of three consecutive circles $$\pi  k^2+\pi(k+1)^2+\pi(k+2)^2=\pi  \left( 3k^2+6k+5\right). $$ Definition. When for an integer $n\geq 1$ the integer    $$\mathcal{A}(n)=\lfloor  \pi\left( 3n^2+6n+5\right) \rfloor$$ is a prime number, I say that it's a prime of Atlantis. Our sequence of prime of Atlantis starts as $$43, 157, 241, 769, 4567, 11551, 14341, 16631, 19949\ldots$$ corresponding to the indexes $n's:1, 3, 4, 8, 21, 34, 38, 41, 45, \ldots$ as you can see with these codes using Wolfram Alpha online calculator: Table IsPrime(floor(pi (n^2+(n+1)^2+(n+2)^2))), for n=1 to 100 Table floor(pi (n^2+(n+1)^2+(n+2)^2)), for n=1 to 100 Question. I would like to know if we can deduce if there are infinitely many primes of Atlantis. Many thanks. If you can't solve the problem, but you can provide us useful reasonings or calculations about the Question, please share your knowledges.",,"['sequences-and-series', 'elementary-number-theory']"
97,"Size of Terms in ""Solid"" Sequences","Size of Terms in ""Solid"" Sequences",,"Call a finite sequence $\{a_1,a_2,..,a_n\}\in \mathbb{N}_{≥1}$ solid if, for all contiguous subsequences $S=\{a_i,a_{i+1},\dots,a_{i+j}\}$, there does not exist an adjacent contiguous subsequence  $S'=\{a_{(i+j)+1},a_{(i+j)+2},\dots,a_{(i+j)+k}\}$ such that $$\sum_{a\in S}a=\sum_{b\in S'}b$$ For example, the sequences $\{1,3,2,3,4,2,4\}$ and $\{1,3,2,3,1,3,2,8\}$ are solid. However, $\{1,2,1,3,2\}$ and $\{1,3,2,3,5\}$ are not. Here is what I am trying to show... Claim : If for some solid sequence $\{a_1,a_2,..,a_n\}$ we have $n\geq2^m$ for some positive integer $m$, then there exits $i\leq n$ such that $a_i\geq2^{m-1}$ This feels like it should have a neat inductive proof. The base case is clear (as any four term sequence must include a $3$). I just can't seem to see the trick for the induction (though it is possible that the proof may not even involve the technique at all). So, first of all, is this claim correct? And, if so, what's the proof? Can a stronger lower bound than $2^{m-1}$ be demonstrated? If the claim is not correct, what bounds can we put on the greatest term of a solid sequence of length $n$? Update :It seems like a bound of $2^{m-1}$ is indeed quite weak. What better (possibly asymptotic) bound could be proved?","Call a finite sequence $\{a_1,a_2,..,a_n\}\in \mathbb{N}_{≥1}$ solid if, for all contiguous subsequences $S=\{a_i,a_{i+1},\dots,a_{i+j}\}$, there does not exist an adjacent contiguous subsequence  $S'=\{a_{(i+j)+1},a_{(i+j)+2},\dots,a_{(i+j)+k}\}$ such that $$\sum_{a\in S}a=\sum_{b\in S'}b$$ For example, the sequences $\{1,3,2,3,4,2,4\}$ and $\{1,3,2,3,1,3,2,8\}$ are solid. However, $\{1,2,1,3,2\}$ and $\{1,3,2,3,5\}$ are not. Here is what I am trying to show... Claim : If for some solid sequence $\{a_1,a_2,..,a_n\}$ we have $n\geq2^m$ for some positive integer $m$, then there exits $i\leq n$ such that $a_i\geq2^{m-1}$ This feels like it should have a neat inductive proof. The base case is clear (as any four term sequence must include a $3$). I just can't seem to see the trick for the induction (though it is possible that the proof may not even involve the technique at all). So, first of all, is this claim correct? And, if so, what's the proof? Can a stronger lower bound than $2^{m-1}$ be demonstrated? If the claim is not correct, what bounds can we put on the greatest term of a solid sequence of length $n$? Update :It seems like a bound of $2^{m-1}$ is indeed quite weak. What better (possibly asymptotic) bound could be proved?",,"['sequences-and-series', 'combinatorics', 'number-theory', 'elementary-number-theory', 'summation']"
98,"Does $\sum_{n=1}^\infty \frac{1}{n!}{n\brace \varphi(n)}$ converge, where ${n\brace m}$ are Stirling numbers of second kind?","Does  converge, where  are Stirling numbers of second kind?",\sum_{n=1}^\infty \frac{1}{n!}{n\brace \varphi(n)} {n\brace m},"When I was playing with the function StirlingS2[n, m] in Wolfram Alpha online calculator, that corresponds with the implementation of Stirling numbers of the second kind (see the definition in this MathWorld ), I've thought about doing experiments with number-theoretic functions like the Euler's totient function $\varphi(n)$ , the prime counting function $\pi(n)$ or the sum of divisor function $\sigma(n)$ . With the purpose of  ensuring the convergence of the series in my experiements I've multiplied by a factor $\frac{1}{n!}$ (and after I did my experiments I've seen that some series seems convergent, but other seems divergent). I don't know if these kind of questions were in the literature, I am saying deduce the convergence of series with same form of next question (with $0<a_n<b_n$ two arithmetic functions as inputs of the function StirlingS2[n, m] ). Question. Let $\varphi(n)$ the Euler's totient function and we denote with ${n\brace m}$ our Stirling numbers of second kind. Do you know how deduce the convergence of $$\sum_{n=1}^\infty \frac{1}{n!}{n\brace \varphi(n)}?$$ Thanks in advance.","When I was playing with the function StirlingS2[n, m] in Wolfram Alpha online calculator, that corresponds with the implementation of Stirling numbers of the second kind (see the definition in this MathWorld ), I've thought about doing experiments with number-theoretic functions like the Euler's totient function , the prime counting function or the sum of divisor function . With the purpose of  ensuring the convergence of the series in my experiements I've multiplied by a factor (and after I did my experiments I've seen that some series seems convergent, but other seems divergent). I don't know if these kind of questions were in the literature, I am saying deduce the convergence of series with same form of next question (with two arithmetic functions as inputs of the function StirlingS2[n, m] ). Question. Let the Euler's totient function and we denote with our Stirling numbers of second kind. Do you know how deduce the convergence of Thanks in advance.",\varphi(n) \pi(n) \sigma(n) \frac{1}{n!} 0<a_n<b_n \varphi(n) {n\brace m} \sum_{n=1}^\infty \frac{1}{n!}{n\brace \varphi(n)}?,"['sequences-and-series', 'convergence-divergence']"
99,Find the sum of the infinite series $\frac{1}{1\cdot 2}+\frac{1\cdot3}{1\cdot2\cdot3\cdot4}+\frac{1\cdot3\cdot5}{1\cdot2\cdot3\cdot4\cdot5\cdot6}+...$ [duplicate],Find the sum of the infinite series  [duplicate],\frac{1}{1\cdot 2}+\frac{1\cdot3}{1\cdot2\cdot3\cdot4}+\frac{1\cdot3\cdot5}{1\cdot2\cdot3\cdot4\cdot5\cdot6}+...,This question already has answers here : Sum of the series:$\frac{1}{1\cdot 2}+\frac{1\cdot3}{1\cdot2\cdot3\cdot4}+\cdots$ (2 answers) Closed 3 years ago . Find the sum of the series $\frac{1}{1\cdot 2}+\frac{1\cdot3}{1\cdot2\cdot3\cdot4}+\frac{1\cdot3\cdot5}{1\cdot2\cdot3\cdot4\cdot5\cdot6}+...$. This type of questions generally require a trick or something and i am not able to figure that out. My guess is that it has something to do with exponential series or binomial series. Any help?,This question already has answers here : Sum of the series:$\frac{1}{1\cdot 2}+\frac{1\cdot3}{1\cdot2\cdot3\cdot4}+\cdots$ (2 answers) Closed 3 years ago . Find the sum of the series $\frac{1}{1\cdot 2}+\frac{1\cdot3}{1\cdot2\cdot3\cdot4}+\frac{1\cdot3\cdot5}{1\cdot2\cdot3\cdot4\cdot5\cdot6}+...$. This type of questions generally require a trick or something and i am not able to figure that out. My guess is that it has something to do with exponential series or binomial series. Any help?,,['sequences-and-series']
