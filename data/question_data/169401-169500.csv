,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Intuitive meaning of Pearson Product-moment correlation coefficient Formula,Intuitive meaning of Pearson Product-moment correlation coefficient Formula,,"I can't understand the intuition behind Pearson Product-moment correlation coefficient Formula for bivariate data. The formula is : $$\rho = \frac{\mathrm{cov}(X,Y)}{S_x \cdot S_y} $$ where cov is covariance, $S_x$ and $S_y$ are standard deviations of $x$ and $y$ . I want to know how that formula come. I searched on net but couldn't find how that formula came.","I can't understand the intuition behind Pearson Product-moment correlation coefficient Formula for bivariate data. The formula is : where cov is covariance, and are standard deviations of and . I want to know how that formula come. I searched on net but couldn't find how that formula came.","\rho = \frac{\mathrm{cov}(X,Y)}{S_x \cdot S_y}  S_x S_y x y","['statistics', 'intuition', 'correlation']"
1,Is there a mathematical name given to the count of negative and positive numbers in a set,Is there a mathematical name given to the count of negative and positive numbers in a set,,"If I have a set of numbers {-1, 2, 3, 4, -8, 2, 0, 44} and I make the statement that there are: 2 negative numbers 5 positive numbers and one signless number Is there a mathematical concept used to name this count? Thanks","If I have a set of numbers {-1, 2, 3, 4, -8, 2, 0, 44} and I make the statement that there are: 2 negative numbers 5 positive numbers and one signless number Is there a mathematical concept used to name this count? Thanks",,"['statistics', 'terminology']"
2,Interpolation needed,Interpolation needed,,"I have a series of datasets which I need to interpolate, I did this once in uni but that was a long time ago. I could use any pointers I can get. So I have put the data up here in the hope that someone might be able to explain to me how I may resolve this. I realise that by posting my data here someone might do the interpolation for me and suck all the fun out of the exercise but I suppose this is a risk I am willing to take (wink, wink) The data represents the ""Power Curve"" of some wind turbines, and is given by the respective manufacturers. A continuous function to represent this data would allow us to compute the power output for a given windspeed and vica-versa. In each case x represents wind speed measured in m/s and y represents power in kW. Leading to something like this: Series 1            Series 2          Series 3     Series 4       Series 5 x    y            x      y           x   y        x      y       x      y  0    0            0      0           0   0        0      0       0      0 1    0            2.5    0           1   0        1.5    0       1      0 2    2            3.5    22          2   0        2.5    0       2      2 3    18           4.5    62          3   1,5      3.5    23      3      18 4    56           5.5    120         4   17       4.5    78      4      56 5    127          6.5    195         5   44,5     5.5    160     5      127 6    240          7.5    298         6   72       6.5    285     6      240 7    400          8.5    443         7   123,7    7.5    456     7      400 8    626          9.5    614         8   197      8.5    679     8      626 9    892          10.5   792         9   277      9.5    953     9      892 10  1223         11.5   962         10  364      10.5   1255    10     1223 11  1590         12.5   1093        11  445      11.5   1543    11     1590 12  1830         13.5   1190        12  533      12.5   1638    12     1900 13  1950         14.5   1253        13  583      13.5   1670    13     2310 14  2050         15.5   1284        14  618      14.5   1670    14     2310 15  2050         16.5   1298        15  620      15.5   1670    15     2310 16  2050         17.5   1295        16  618      16.5   1670    16     2310 17  2050         18.5   1276        17  580      17.5   1670    17     2310 18  2050         19.5   1245                     18.5   1670    18     2310 19  2050         20.5   1211                     19.5   1670    19     2310 20  2050         21.5   1174                     20.5   1670    20     2310 21  2050         22.5   1148                     21.5   1670    21     2310 22  2050         23.5   1128                     22.5   1670    22     2310 23  2050         24.5   1118                     23.5   1670    23     2310 24  2050                                         24.5   1670    24     2310 25  2050                                         24.5   1670    25     2310","I have a series of datasets which I need to interpolate, I did this once in uni but that was a long time ago. I could use any pointers I can get. So I have put the data up here in the hope that someone might be able to explain to me how I may resolve this. I realise that by posting my data here someone might do the interpolation for me and suck all the fun out of the exercise but I suppose this is a risk I am willing to take (wink, wink) The data represents the ""Power Curve"" of some wind turbines, and is given by the respective manufacturers. A continuous function to represent this data would allow us to compute the power output for a given windspeed and vica-versa. In each case x represents wind speed measured in m/s and y represents power in kW. Leading to something like this: Series 1            Series 2          Series 3     Series 4       Series 5 x    y            x      y           x   y        x      y       x      y  0    0            0      0           0   0        0      0       0      0 1    0            2.5    0           1   0        1.5    0       1      0 2    2            3.5    22          2   0        2.5    0       2      2 3    18           4.5    62          3   1,5      3.5    23      3      18 4    56           5.5    120         4   17       4.5    78      4      56 5    127          6.5    195         5   44,5     5.5    160     5      127 6    240          7.5    298         6   72       6.5    285     6      240 7    400          8.5    443         7   123,7    7.5    456     7      400 8    626          9.5    614         8   197      8.5    679     8      626 9    892          10.5   792         9   277      9.5    953     9      892 10  1223         11.5   962         10  364      10.5   1255    10     1223 11  1590         12.5   1093        11  445      11.5   1543    11     1590 12  1830         13.5   1190        12  533      12.5   1638    12     1900 13  1950         14.5   1253        13  583      13.5   1670    13     2310 14  2050         15.5   1284        14  618      14.5   1670    14     2310 15  2050         16.5   1298        15  620      15.5   1670    15     2310 16  2050         17.5   1295        16  618      16.5   1670    16     2310 17  2050         18.5   1276        17  580      17.5   1670    17     2310 18  2050         19.5   1245                     18.5   1670    18     2310 19  2050         20.5   1211                     19.5   1670    19     2310 20  2050         21.5   1174                     20.5   1670    20     2310 21  2050         22.5   1148                     21.5   1670    21     2310 22  2050         23.5   1128                     22.5   1670    22     2310 23  2050         24.5   1118                     23.5   1670    23     2310 24  2050                                         24.5   1670    24     2310 25  2050                                         24.5   1670    25     2310",,['statistics']
3,What is the difference between $\mathbf X\mathbf X^\prime$ and $(\mathbf X-\mu)(\mathbf X-\mu)^\prime$?,What is the difference between  and ?,\mathbf X\mathbf X^\prime (\mathbf X-\mu)(\mathbf X-\mu)^\prime,"In $\mathbf X\mathbf X^\prime$, $\mathbf X$ is a matrix contains data points in column fashion, $\mathbf X^\prime$ is its transpose, this looks like a covariance matrix, but does not subtract mean, so what is the different meaning of subtract mean or not subtract it?","In $\mathbf X\mathbf X^\prime$, $\mathbf X$ is a matrix contains data points in column fashion, $\mathbf X^\prime$ is its transpose, this looks like a covariance matrix, but does not subtract mean, so what is the different meaning of subtract mean or not subtract it?",,"['linear-algebra', 'statistics', 'matrices']"
4,Finding joint sufficient statistics [closed],Finding joint sufficient statistics [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I'm trying to find two statistics $T_1$ , $T_2$ such that $(T_1, T_2)$ is jointly sufficient for $(\lambda, \theta)$ for a random sample $X_1, \dots, X_n$ from a two parameter exponential distribution. $f(x) = \begin{cases} \lambda e^{-\lambda (x-\theta)}, & \theta < x < \infty, \\ 0, & \text{elsewhere}. \end{cases}$ Thanks.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I'm trying to find two statistics , such that is jointly sufficient for for a random sample from a two parameter exponential distribution. Thanks.","T_1 T_2 (T_1, T_2) (\lambda, \theta) X_1, \dots, X_n f(x) = \begin{cases}
\lambda e^{-\lambda (x-\theta)}, & \theta < x < \infty, \\
0, & \text{elsewhere}.
\end{cases}","['statistics', 'probability-distributions']"
5,"How do you find the number that corresponds to Quartile 1, when given an even number of scores?","How do you find the number that corresponds to Quartile 1, when given an even number of scores?",,"If you have an odd number of data values {39, 40, 42, 44, 47, 48, 49, 51, 53}, what is the score that value that corresponds to Quartile 1?  In general, I would like to know if you include the median's value (47) in figuring the position of quartile 1.","If you have an odd number of data values {39, 40, 42, 44, 47, 48, 49, 51, 53}, what is the score that value that corresponds to Quartile 1?  In general, I would like to know if you include the median's value (47) in figuring the position of quartile 1.",,['statistics']
6,Finding the change point in data from a piecewise linear function,Finding the change point in data from a piecewise linear function,,"Greetings, I'm performing research that will help determine the size of observed space and the time elapsed since the big bang. Hopefully you can help! I have data conforming to a piecewise linear function on which I want to perform two linear regressions. There is a point at which the slope and intercept change, and I need to (write a program to) find this point. Thoughts?","Greetings, I'm performing research that will help determine the size of observed space and the time elapsed since the big bang. Hopefully you can help! I have data conforming to a piecewise linear function on which I want to perform two linear regressions. There is a point at which the slope and intercept change, and I need to (write a program to) find this point. Thoughts?",,['statistics']
7,can I get an upper bound on the tail of a binomial variable?,can I get an upper bound on the tail of a binomial variable?,,"I have $X_1,...$ Bernoulli variables with probability $p$ of success. I want to get an $n$ such that with probability $\delta$ $P(\sum_{i=1}^n X_i \ge k) \ge \delta$ This $n$ would of course depend on $k$, $p$ and $\delta$. Can I get an upper bound for that $n(k,\delta,p)$? (meaning, I want some $n(k,\delta,p)$ for which the above holds, the smaller $n$ is, the better.) Thanks.","I have $X_1,...$ Bernoulli variables with probability $p$ of success. I want to get an $n$ such that with probability $\delta$ $P(\sum_{i=1}^n X_i \ge k) \ge \delta$ This $n$ would of course depend on $k$, $p$ and $\delta$. Can I get an upper bound for that $n(k,\delta,p)$? (meaning, I want some $n(k,\delta,p)$ for which the above holds, the smaller $n$ is, the better.) Thanks.",,"['probability', 'statistics']"
8,Conjugate priors and Bayesian updates,Conjugate priors and Bayesian updates,,"In a paper by Cyert and Degroot (1974) ( Rational Expectations and Bayesian Analysis , in Journal of Political Economy), authors use Bayesian update for an uncertain parameter. They have a model for pricing as follows $$p_{t+1}=ap_{t}+v_{t+1}$$ where $v_1$ , $v_2$ ,... form a sequence of iid error terms. The parameter on which there is a Bayesian update is $a$ . $r$ is the known precision of the signal (from the pricing equation). They find the following updating rule for the mean and the variance for $a$ $$m_{t+1}=\frac{h_{t}m_{t}+rp_{t}p_{t+1}}{h_{t}+r\left(p_{t}\right)^{2}}$$ and $$h_{t+1}=h_{t}+r\left(p_{t}\right)^{2}$$ I have some trouble to find these values. Here is what I have tried ; They say they use prior conjugates to find these updating rules. So,the posterior $$p\left(a\mid p_{t+1}\right)\propto p\left(a\right)p\left(p_{t+1}\mid a\right)$$ $ $ where $$p\left(a\right)=\left(2\pi\sigma_{0}^{2}\right)^{-\frac{1}{2}}\text{exp}\left(-\frac{1}{2\sigma_{0}^{2}}\left(a-a_{0}\right)^{2}\right)$$ and $$p\left(p_{t+1}\mid a\right)=\left(2\pi\sigma_{c}^{2}\right)^{-\frac{1}{2}}\text{exp}\left(-\frac{1}{2\sigma_{c}^{2}}\left(p_{t+1}-a\right)^{2}\right)$$ So by using these last two expressions, I write $$p\left(a\right)p\left(p_{t+1}\mid a\right)\propto exp\left(-\frac{1}{2\sigma_{0}^{2}}\left(a-a_{0}\right)^{2}-\frac{1}{2\sigma_{c}^{2}}\left(p_{t+1}-a\right)^{2}\right)$$ where the known and constant precision $\frac{1}{\sigma_{c}^{2}}=r$ and the time varying precision $\frac{1}{\sigma_{0}^{2}}=h_{0}$ and I end up with this $$p\left(a\right)p\left(p_{t+1}\mid a\right)\propto exp\left(-\frac{h_{0}}{2}\left(a^{2}-2aa_{0}+a_{0}^{2}\right)-\frac{r}{2}\left(p_{t+1}^{2}-2p_{t+1}a+a^{2}\right)\right) \overset{\text{def}}{=}\text{exp}\left(-\frac{h_{1}}{2}\left(a-a_{1}\right)^{2}\right)$$ I cannot end up with terms like $p_t^2$ and $p_t p_t+1$ . What do I miss? Any hints/suggestions or solution is appreciated, thanks!","In a paper by Cyert and Degroot (1974) ( Rational Expectations and Bayesian Analysis , in Journal of Political Economy), authors use Bayesian update for an uncertain parameter. They have a model for pricing as follows where , ,... form a sequence of iid error terms. The parameter on which there is a Bayesian update is . is the known precision of the signal (from the pricing equation). They find the following updating rule for the mean and the variance for and I have some trouble to find these values. Here is what I have tried ; They say they use prior conjugates to find these updating rules. So,the posterior where and So by using these last two expressions, I write where the known and constant precision and the time varying precision and I end up with this I cannot end up with terms like and . What do I miss? Any hints/suggestions or solution is appreciated, thanks!","p_{t+1}=ap_{t}+v_{t+1} v_1 v_2 a r a m_{t+1}=\frac{h_{t}m_{t}+rp_{t}p_{t+1}}{h_{t}+r\left(p_{t}\right)^{2}} h_{t+1}=h_{t}+r\left(p_{t}\right)^{2} p\left(a\mid p_{t+1}\right)\propto p\left(a\right)p\left(p_{t+1}\mid a\right) 
 p\left(a\right)=\left(2\pi\sigma_{0}^{2}\right)^{-\frac{1}{2}}\text{exp}\left(-\frac{1}{2\sigma_{0}^{2}}\left(a-a_{0}\right)^{2}\right) p\left(p_{t+1}\mid a\right)=\left(2\pi\sigma_{c}^{2}\right)^{-\frac{1}{2}}\text{exp}\left(-\frac{1}{2\sigma_{c}^{2}}\left(p_{t+1}-a\right)^{2}\right) p\left(a\right)p\left(p_{t+1}\mid a\right)\propto exp\left(-\frac{1}{2\sigma_{0}^{2}}\left(a-a_{0}\right)^{2}-\frac{1}{2\sigma_{c}^{2}}\left(p_{t+1}-a\right)^{2}\right) \frac{1}{\sigma_{c}^{2}}=r \frac{1}{\sigma_{0}^{2}}=h_{0} p\left(a\right)p\left(p_{t+1}\mid a\right)\propto exp\left(-\frac{h_{0}}{2}\left(a^{2}-2aa_{0}+a_{0}^{2}\right)-\frac{r}{2}\left(p_{t+1}^{2}-2p_{t+1}a+a^{2}\right)\right) \overset{\text{def}}{=}\text{exp}\left(-\frac{h_{1}}{2}\left(a-a_{1}\right)^{2}\right) p_t^2 p_t p_t+1","['statistics', 'bayesian']"
9,Expected value of 1/X^2 when X follows an inversed gamma distribution,Expected value of 1/X^2 when X follows an inversed gamma distribution,,"I am working on calculating the expected value of the reciprocal of the square of a variable $X$ that follows an Inverse Gaussian distribution with parameters $\mu$ (mean) and $\lambda$ (shape). The probability density function (PDF) of the Inverse Gaussian distribution is given by: $f(x; \mu, \lambda) = \left(\frac{\lambda}{2\pi x^3}\right)^{\frac{1}{2}} \exp\left(-\frac{\lambda (x-\mu)^2}{2\mu^2 x}\right) $ for $x > 0$ . I am trying to find: $ E\left[\frac{1}{X^2}\right] = \int_{0}^{\infty} \frac{1}{x^2} f(x; \mu, \lambda) \, dx $ which simplifies to: $ E\left[\frac{1}{X^2}\right] = \left(\frac{\lambda}{2\pi}\right)^{\frac{1}{2}} \int_{0}^{\infty} x^{-\frac{7}{2}} \exp\left(-\frac{\lambda (x-\mu)^2}{2\mu^2 x}\right) \, dx $ I am unsure how to approach solving this integral and am wondering if there is a known closed-form solution or if it generally requires numerical methods for evaluation. Insights or references to relevant techniques or literature would be greatly appreciated.",I am working on calculating the expected value of the reciprocal of the square of a variable that follows an Inverse Gaussian distribution with parameters (mean) and (shape). The probability density function (PDF) of the Inverse Gaussian distribution is given by: for . I am trying to find: which simplifies to: I am unsure how to approach solving this integral and am wondering if there is a known closed-form solution or if it generally requires numerical methods for evaluation. Insights or references to relevant techniques or literature would be greatly appreciated.,"X \mu \lambda f(x; \mu, \lambda) = \left(\frac{\lambda}{2\pi x^3}\right)^{\frac{1}{2}} \exp\left(-\frac{\lambda (x-\mu)^2}{2\mu^2 x}\right)
 x > 0 
E\left[\frac{1}{X^2}\right] = \int_{0}^{\infty} \frac{1}{x^2} f(x; \mu, \lambda) \, dx
 
E\left[\frac{1}{X^2}\right] = \left(\frac{\lambda}{2\pi}\right)^{\frac{1}{2}} \int_{0}^{\infty} x^{-\frac{7}{2}} \exp\left(-\frac{\lambda (x-\mu)^2}{2\mu^2 x}\right) \, dx
","['statistics', 'probability-distributions']"
10,"Generalization of Geometric Mean, Standard Deviation, etc.","Generalization of Geometric Mean, Standard Deviation, etc.",,"The geometric mean can be thought of as the exponential of the arithmetic mean of the logarithms of your dataset $\{a_i\}_{i=1}^n$ : $$GM = \exp\left(\dfrac{1}{n}\sum_{i=1}^{n}\ln(a_i)\right)$$ Similarly, the standard deviation of a dataset is the square root of the arithmetic mean of the squares of your errors $\{e_i\}_{i=1}^{n}$ : $$SD = \sqrt{\dfrac{1}{n}\sum_{i=1}^{n}(e_i)^2}$$ I find it interesting that both of these ideas seems to follow of more general pattern: $$f^{-1}\left( \dfrac{1}{n} \sum_{i=1}^{n} f(x_i) \right),$$ where the function in question is $f(x) = x^2$ for the standard deviation, and $f(x) = \ln x$ for the geometric mean. Even the arithmetic mean is trivially of this form, just with $f(x)= x$ as the identity function. Are there other widely-used variations of these kinds of ""functional"" averages? And is there anything we can say, more universally, about these kinds of averages as a whole? In particular, I find it interesting that all three of the averages I mentioned above (when applied to two values) all give values that are between the two data points. What would have to be true about a function $f(x)$ for this ""midpoint"" property to hold? For example, $\arcsin\left( \frac{1}{2} (\sin a + \sin b)\right)$ is most certainly not between $a$ and $b$ in most cases.","The geometric mean can be thought of as the exponential of the arithmetic mean of the logarithms of your dataset : Similarly, the standard deviation of a dataset is the square root of the arithmetic mean of the squares of your errors : I find it interesting that both of these ideas seems to follow of more general pattern: where the function in question is for the standard deviation, and for the geometric mean. Even the arithmetic mean is trivially of this form, just with as the identity function. Are there other widely-used variations of these kinds of ""functional"" averages? And is there anything we can say, more universally, about these kinds of averages as a whole? In particular, I find it interesting that all three of the averages I mentioned above (when applied to two values) all give values that are between the two data points. What would have to be true about a function for this ""midpoint"" property to hold? For example, is most certainly not between and in most cases.","\{a_i\}_{i=1}^n GM = \exp\left(\dfrac{1}{n}\sum_{i=1}^{n}\ln(a_i)\right) \{e_i\}_{i=1}^{n} SD = \sqrt{\dfrac{1}{n}\sum_{i=1}^{n}(e_i)^2} f^{-1}\left( \dfrac{1}{n} \sum_{i=1}^{n} f(x_i) \right), f(x) = x^2 f(x) = \ln x f(x)= x f(x) \arcsin\left( \frac{1}{2} (\sin a + \sin b)\right) a b","['statistics', 'functions', 'average', 'standard-deviation']"
11,"Finding $x$ and $y$ with the information that ""On exactly half of the days,No more than one student was absent"". [closed]","Finding  and  with the information that ""On exactly half of the days,No more than one student was absent"". [closed]",x y,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 months ago . Improve this question Henry recorded the number of students present everyday for a total of $40$ days. Also there are a total of $29$ students. Here is the frequency table: Also it is given that,on exactly half of the days, No more than one student was absent. Find the values of $x,y$ . My try: Obviously $1+2+x+10+y+12=40 \Rightarrow x+y=15$ . But I am unable to frame other equation. I found cumulative frequencies as: $1,3,x+3,x+13,28,40.$ But not sure how to proceed?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 months ago . Improve this question Henry recorded the number of students present everyday for a total of days. Also there are a total of students. Here is the frequency table: Also it is given that,on exactly half of the days, No more than one student was absent. Find the values of . My try: Obviously . But I am unable to frame other equation. I found cumulative frequencies as: But not sure how to proceed?","40 29 x,y 1+2+x+10+y+12=40 \Rightarrow x+y=15 1,3,x+3,x+13,28,40.","['probability', 'statistics', 'cumulative-distribution-functions']"
12,Distribution of a combination of four uniformly distributed variables: $ X_1+X_2 +\sqrt{(X_2 - X_1)^2 + (Y_2 - Y_1)^2}$,Distribution of a combination of four uniformly distributed variables:, X_1+X_2 +\sqrt{(X_2 - X_1)^2 + (Y_2 - Y_1)^2},"My problem involves four random variables $X_1, Y_1, X_2, Y_2 \sim U(0,1)$ in the expression $Z = X_1 + X_2 + \sqrt{(X_2 - X_1)^2 + (Y_2 - Y_1)^2}$ . From what I understand so far, I need to find the PDF of the overall distribution to be able to find $P(Z>z)$ . Attempts I first thought that finding the expected value of $\sqrt{(X_2 - X_1)^2 + (Y_2 - Y_1)^2}$ by quad-integrating from 0 to 1 would greatly simplify the problem. This led to attempts using geometric probability. Then I realized that the presence of the $X_1$ and $X_2$ outside of this term complicates things. I have come across a lot of posts addressing the simple combination of uniformly distributed variables, such as $X + Y$ and $X - Y$ . Again, the expression this problem involves is much more complicated, which is why I am asking this question. I have also used simulation to plot what the distribution looks like, which assures me there is an answer (whether it is closed-form, I do not know) but gives me no clue how to get there. Photo of Simulated Distribution So - how do I go about finding the PDF of $Z = X_1 + X_2 + \sqrt{(X_2 - X_1)^2 + (Y_2 - Y_1)^2}$ ? I need the exact distribution because I am looking for the closed-form probability that the expression is greater than 2 . Thanks in advance!","My problem involves four random variables in the expression . From what I understand so far, I need to find the PDF of the overall distribution to be able to find . Attempts I first thought that finding the expected value of by quad-integrating from 0 to 1 would greatly simplify the problem. This led to attempts using geometric probability. Then I realized that the presence of the and outside of this term complicates things. I have come across a lot of posts addressing the simple combination of uniformly distributed variables, such as and . Again, the expression this problem involves is much more complicated, which is why I am asking this question. I have also used simulation to plot what the distribution looks like, which assures me there is an answer (whether it is closed-form, I do not know) but gives me no clue how to get there. Photo of Simulated Distribution So - how do I go about finding the PDF of ? I need the exact distribution because I am looking for the closed-form probability that the expression is greater than 2 . Thanks in advance!","X_1, Y_1, X_2, Y_2 \sim U(0,1) Z = X_1 + X_2 + \sqrt{(X_2 - X_1)^2 + (Y_2 - Y_1)^2} P(Z>z) \sqrt{(X_2 - X_1)^2 + (Y_2 - Y_1)^2} X_1 X_2 X + Y X - Y Z = X_1 + X_2 + \sqrt{(X_2 - X_1)^2 + (Y_2 - Y_1)^2}","['probability', 'statistics', 'geometric-probability']"
13,"How Can We Study the Possibility of Uniform ""Distribuitons"" on Countable Sets Like $\mathbb{N}$ or $\mathbb{Q}$?","How Can We Study the Possibility of Uniform ""Distribuitons"" on Countable Sets Like  or ?",\mathbb{N} \mathbb{Q},"I wonder if there exist ways to deal with infinitely coutable sets with a probability in the  ""uniform"" sense. In the basic Probability Theory, as far as I know, we usually study two kinds of probability most of the time that is compatible with our sense of probability: 1- First one is the discrete probability which uses convergent sums and mass functions defined on a finite outcome space $\Omega$ and finite $\sigma$ -algebra $\mathcal{F} \subset 2^{\Omega}$ such that $\mathbb{P}(\Omega) = 1$ . We consider $\sigma$ -algebras to generalize the concept but things are simpler here and all can be induced to positive sums and series. In this version, uniform distributions corresponds to the case that the mass function is constant and $f({x}) = 1/n$ for each outcome $x\in\Omega$ where $|\Omega| = n$ where $\mathcal{F}$ is just the entire power set $2^{\Omega}$ since it should contain all singletons and all sets are finite. Then, for any event $E\in \mathcal{F} = 2^{\Omega}$ where $|F| = k \leq n$ , it produces $f(E) = k/n$ by finite additivity of the (probability) measure. Other than the uniform distribution, we can consider any countable $\Omega$ where $\mathbb{P}(\Omega) = 1$ is still satisfied which means that any non-negative function $f$ satisfying $\sum_{x\in \Omega} \mathbb{P}({x}) = 1$ can be considered as a mass function. Then, the sense for uniform distribution does not work here as a probability mass function because countable infinite set causes the mass function $f(x)$ to be zero if $E$ is finite or undefined caused by indeterminate quotient $\infty/\infty$ if $E$ is infinite. 2- However, there is the second kind of the theory, the continuous probability on, for example, real numbers $\mathbb{R}$ using Lebesgue Integration . In this case, probability is not considered as the sum of singleton outcomes, i.e. $\sum f(x)$ , but the integral of the density function of an event $E\in \mathcal{F}\subset 2^{\Omega}$ as the integral $\int_E fd\lambda$ in general. So we can use the similar set-up here where the only change is to use integration instead of sums and series. Now the sense for uniform density here is just a constant function again: Given a bounded measurable set E which is not null, e. g. intervals. Then $c := m(E) \in (0, \infty)$ and we can use the uniform distribution on this bounded set as $f(x) = 1/c > 0$ . Then we simply have the total probability as the integral $\int_E f dm = (1/c)c = 1$ which makes it a distribution for real. Unfortunately, there are things we are missing here, too : None of the null sets are covered by the continous probability as well as sets with measure $\infty$ : The latter is similar to the problem we encountered in discrete case since it causes the uniform distribution on the set to be 0 and then the probibility, which means the integral of the zero distribution here, becomes 0, not 1 . On the other hand the former is caused by the fact that integrals over null sets are zero automatically, not 1 . Thus no function $f$ can be a density function for a null set like countable infinite sets $\mathbb{N}$ or $\mathbb{Q}$ if they are null in the given measure, for example Lebesgue Measure or Borel measure . Finally, I think that using a measure where the set $\mathbb{N}$ is not null (consider a measure where every natural number is an atom that of equal measure) coincides with the discrete probability with some editing since the integration on $\mathbb{N}$ becomes the limit of the finite sum by the definition of the integral via simple functions. QUESTION : We have the sense that choosing a random natural number should be considered in some sort of ""uniform"" way . How can we describe that uniformity and study it in a natural sense? Which tools do we have to examine them? After my surfing on that topic I realized that the discrete way cannot handle some of infinite quantities includig uniform ones and continous way cannot handle null-sets including countable ones. So I believe that there should be a middle-way or a completely different approach to study (infinitely) countable uniformity.","I wonder if there exist ways to deal with infinitely coutable sets with a probability in the  ""uniform"" sense. In the basic Probability Theory, as far as I know, we usually study two kinds of probability most of the time that is compatible with our sense of probability: 1- First one is the discrete probability which uses convergent sums and mass functions defined on a finite outcome space and finite -algebra such that . We consider -algebras to generalize the concept but things are simpler here and all can be induced to positive sums and series. In this version, uniform distributions corresponds to the case that the mass function is constant and for each outcome where where is just the entire power set since it should contain all singletons and all sets are finite. Then, for any event where , it produces by finite additivity of the (probability) measure. Other than the uniform distribution, we can consider any countable where is still satisfied which means that any non-negative function satisfying can be considered as a mass function. Then, the sense for uniform distribution does not work here as a probability mass function because countable infinite set causes the mass function to be zero if is finite or undefined caused by indeterminate quotient if is infinite. 2- However, there is the second kind of the theory, the continuous probability on, for example, real numbers using Lebesgue Integration . In this case, probability is not considered as the sum of singleton outcomes, i.e. , but the integral of the density function of an event as the integral in general. So we can use the similar set-up here where the only change is to use integration instead of sums and series. Now the sense for uniform density here is just a constant function again: Given a bounded measurable set E which is not null, e. g. intervals. Then and we can use the uniform distribution on this bounded set as . Then we simply have the total probability as the integral which makes it a distribution for real. Unfortunately, there are things we are missing here, too : None of the null sets are covered by the continous probability as well as sets with measure : The latter is similar to the problem we encountered in discrete case since it causes the uniform distribution on the set to be 0 and then the probibility, which means the integral of the zero distribution here, becomes 0, not 1 . On the other hand the former is caused by the fact that integrals over null sets are zero automatically, not 1 . Thus no function can be a density function for a null set like countable infinite sets or if they are null in the given measure, for example Lebesgue Measure or Borel measure . Finally, I think that using a measure where the set is not null (consider a measure where every natural number is an atom that of equal measure) coincides with the discrete probability with some editing since the integration on becomes the limit of the finite sum by the definition of the integral via simple functions. QUESTION : We have the sense that choosing a random natural number should be considered in some sort of ""uniform"" way . How can we describe that uniformity and study it in a natural sense? Which tools do we have to examine them? After my surfing on that topic I realized that the discrete way cannot handle some of infinite quantities includig uniform ones and continous way cannot handle null-sets including countable ones. So I believe that there should be a middle-way or a completely different approach to study (infinitely) countable uniformity.","\Omega \sigma \mathcal{F} \subset 2^{\Omega} \mathbb{P}(\Omega) = 1 \sigma f({x}) = 1/n x\in\Omega |\Omega| = n \mathcal{F} 2^{\Omega} E\in \mathcal{F} = 2^{\Omega} |F| = k \leq n f(E) = k/n \Omega \mathbb{P}(\Omega) = 1 f \sum_{x\in \Omega} \mathbb{P}({x}) = 1 f(x) E \infty/\infty E \mathbb{R} \sum f(x) E\in \mathcal{F}\subset 2^{\Omega} \int_E fd\lambda c := m(E) \in (0, \infty) f(x) = 1/c > 0 \int_E f dm = (1/c)c = 1 \infty f \mathbb{N} \mathbb{Q} \mathbb{N} \mathbb{N}","['probability', 'probability-theory', 'statistics', 'conditional-probability', 'uniform-distribution']"
14,Finding $E[Z^2\Phi(Z)]$ using law of the unconscious statistician,Finding  using law of the unconscious statistician,E[Z^2\Phi(Z)],"Question: Random Variable $Z$ follows a standard normal distribution with c.d.f. $\Phi$ . Find $E[Z^2\Phi(Z)]$ using the law of the unconscious statistician. I am thinking of using some substitution to work it out, for example, using $\phi'(z)=-z\phi(z)$ can help to solve $E[Z\Phi(Z)]$ , but I don’t know how to apply this trick for finding out $E[Z^2\Phi(Z)]$ .","Question: Random Variable follows a standard normal distribution with c.d.f. . Find using the law of the unconscious statistician. I am thinking of using some substitution to work it out, for example, using can help to solve , but I don’t know how to apply this trick for finding out .",Z \Phi E[Z^2\Phi(Z)] \phi'(z)=-z\phi(z) E[Z\Phi(Z)] E[Z^2\Phi(Z)],"['statistics', 'expected-value']"
15,Fisher Information Matrix for Weibull Distribution...,Fisher Information Matrix for Weibull Distribution...,,"I wish to find the Fisher Information Matrix for the Weibull Distribution... I face two difficulties, I can't find any sufficient guide in internet to lead me to derive the Fisher Information Matrix... if have, could you share it to me... I not able to ensure that everything I have proved below is valid or not... but the below are my workings.. Given that the pdf of Weibull Distribution is $$f(x;k,\lambda)=\frac{k}{\lambda}\left(\frac{x}{\lambda}\right)^{k-1}e^{-\left(\frac{x}{\lambda}\right)^k} $$ Likelihood function : $$ L(k,\lambda|x_i)=k^n\lambda^{-nk}\,\text{exp}\left[(k-1)\sum_{i=1}^n \text{ln}(x_i)-\sum_{i=1}^n \left(\frac{x_i}{\lambda}\right)^k\right]$$ Log-likelhood function : $$\frac{\delta L}{\delta k}=\frac{n}{\lambda}-n\text{ln}\lambda+\sum_{i=1}^n \text{ln}\left(x_i\right)-\sum_{i=1}^n \left( \frac{x_i}{\lambda}\right)^k$$ $$\frac{\delta L}{\delta \lambda}=-\frac{nk}{\lambda}+\frac{k}{\lambda^{k+1}}\sum_{i=1}^n \left(x_i\right)^k$$ Second Difference... $$\frac{\delta^2 L}{\delta k^2}=-\frac{n}{k^2}-\sum_{i=1}^{n}\left(\frac{x_i}{\lambda}\right)^k \left( \text{ln}\left( \frac{x_i}{\lambda}   \right)\right)^2$$ $$\frac{\delta^2 L}{\delta \lambda^2}=\frac{nk}{\lambda^2}+ \frac{k(k+1)}{\lambda^{k+2}} \sum_{i=1}^n \left(x_i \right)^k$$ $$ \frac{\delta^2 L}{\delta k \delta \lambda}=\frac{\delta^2 L}{\delta \lambda \delta k}=-\frac{n}{\lambda}+\frac{1}{\lambda} \sum_{i=1}^n \left[ \left(\frac{x_i}{\lambda}\right)^k  \left( 1+k\, \text{ln}\left( \frac{x_i}{\lambda}  \right)  \right)  \right]  $$ Given that the Fisher Information Matrix have to be in the form of $$ I(k,\lambda) = -E \begin{bmatrix} \frac{\delta^2 L}{\delta k^2} & \frac{\delta^2 L}{\delta k \delta \lambda}\\ \frac{\delta^2 L}{\delta \lambda \delta k} & \frac{\delta^2 L}{\delta \lambda^2} \end{bmatrix}$$ Next, $$E\left(\frac{\delta^2L}{\delta k^2}  \right)\\=E\left(-\frac{n}{k^2}-\sum_{i=1}^{n}\left(\frac{x_i}{\lambda}\right)^k \left( \text{ln}\left( \frac{x_i}{\lambda}   \right)\right)^2 \right) \\=E\left(-\frac{n}{k^2}\right) - E\left( \sum_{i=1}^{n}\left(\frac{x_i}{\lambda}\right)^k \left( \text{ln}\left( \frac{x_i}{\lambda} \right)\right)^2\right)\\=-\frac{n}{k^2} - \frac{1}{\lambda^k} \sum_{i=1}^nE\left( (x_i)^k \left( \text{ln}\frac{x_i}{\lambda}  \right)^2 \right)\\=...$$ And I am stuck for $E\left(\frac{\delta^2 L}{\delta \lambda^2}\right)$ and $E\left(\frac{\delta^2 L}{\delta \lambda \delta k}\right)$ as well... Should I find the derivation for $E\left[X^{p}\left( \text{ln}\frac{X_i}{\lambda}\right)^q  \right]$ ? Which lead to $\int_0^\infty X^{p}\left( \text{ln}\frac{X_i}{\lambda}\right)^q \frac{k}{\lambda}\left(\frac{x}{\lambda}\right)^{k-1}e^{-\left(\frac{x}{\lambda}\right)^k} $ ? Need your help as I have tried my very best to figure it out for weeks... or does it have a better approach for everything...","I wish to find the Fisher Information Matrix for the Weibull Distribution... I face two difficulties, I can't find any sufficient guide in internet to lead me to derive the Fisher Information Matrix... if have, could you share it to me... I not able to ensure that everything I have proved below is valid or not... but the below are my workings.. Given that the pdf of Weibull Distribution is Likelihood function : Log-likelhood function : Second Difference... Given that the Fisher Information Matrix have to be in the form of Next, And I am stuck for and as well... Should I find the derivation for ? Which lead to ? Need your help as I have tried my very best to figure it out for weeks... or does it have a better approach for everything...","f(x;k,\lambda)=\frac{k}{\lambda}\left(\frac{x}{\lambda}\right)^{k-1}e^{-\left(\frac{x}{\lambda}\right)^k}   L(k,\lambda|x_i)=k^n\lambda^{-nk}\,\text{exp}\left[(k-1)\sum_{i=1}^n \text{ln}(x_i)-\sum_{i=1}^n \left(\frac{x_i}{\lambda}\right)^k\right] \frac{\delta L}{\delta k}=\frac{n}{\lambda}-n\text{ln}\lambda+\sum_{i=1}^n \text{ln}\left(x_i\right)-\sum_{i=1}^n \left( \frac{x_i}{\lambda}\right)^k \frac{\delta L}{\delta \lambda}=-\frac{nk}{\lambda}+\frac{k}{\lambda^{k+1}}\sum_{i=1}^n \left(x_i\right)^k \frac{\delta^2 L}{\delta k^2}=-\frac{n}{k^2}-\sum_{i=1}^{n}\left(\frac{x_i}{\lambda}\right)^k \left( \text{ln}\left( \frac{x_i}{\lambda}   \right)\right)^2 \frac{\delta^2 L}{\delta \lambda^2}=\frac{nk}{\lambda^2}+ \frac{k(k+1)}{\lambda^{k+2}} \sum_{i=1}^n \left(x_i \right)^k  \frac{\delta^2 L}{\delta k \delta \lambda}=\frac{\delta^2 L}{\delta \lambda \delta k}=-\frac{n}{\lambda}+\frac{1}{\lambda} \sum_{i=1}^n \left[ \left(\frac{x_i}{\lambda}\right)^k  \left( 1+k\, \text{ln}\left( \frac{x_i}{\lambda}  \right)  \right)  \right]    I(k,\lambda) = -E \begin{bmatrix}
\frac{\delta^2 L}{\delta k^2} & \frac{\delta^2 L}{\delta k \delta \lambda}\\
\frac{\delta^2 L}{\delta \lambda \delta k} & \frac{\delta^2 L}{\delta \lambda^2}
\end{bmatrix} E\left(\frac{\delta^2L}{\delta k^2}  \right)\\=E\left(-\frac{n}{k^2}-\sum_{i=1}^{n}\left(\frac{x_i}{\lambda}\right)^k \left( \text{ln}\left( \frac{x_i}{\lambda}   \right)\right)^2 \right)
\\=E\left(-\frac{n}{k^2}\right) - E\left( \sum_{i=1}^{n}\left(\frac{x_i}{\lambda}\right)^k \left( \text{ln}\left( \frac{x_i}{\lambda} \right)\right)^2\right)\\=-\frac{n}{k^2} - \frac{1}{\lambda^k} \sum_{i=1}^nE\left( (x_i)^k \left( \text{ln}\frac{x_i}{\lambda}  \right)^2
\right)\\=... E\left(\frac{\delta^2 L}{\delta \lambda^2}\right) E\left(\frac{\delta^2 L}{\delta \lambda \delta k}\right) E\left[X^{p}\left( \text{ln}\frac{X_i}{\lambda}\right)^q  \right] \int_0^\infty X^{p}\left( \text{ln}\frac{X_i}{\lambda}\right)^q \frac{k}{\lambda}\left(\frac{x}{\lambda}\right)^{k-1}e^{-\left(\frac{x}{\lambda}\right)^k} ","['statistics', 'probability-distributions', 'log-likelihood', 'fisher-information']"
16,Nonincreasing cdf? Potential error in my textbook..,Nonincreasing cdf? Potential error in my textbook..,,"Image from Introduction to Mathematical Statistics (7th edition) by Hogg, McKean & Craig: I hope I'm not missing something obvious here, but isn't a cdf supposed to be non decreasing ? If $F$ is a cdf of a random variable $X$ and $x \leq y$ then it must be that $F(x) = P(X \leq x) = P(X \leq y) - P(x < X \leq y) \leq P(X \leq y) = F(y)$ .","Image from Introduction to Mathematical Statistics (7th edition) by Hogg, McKean & Craig: I hope I'm not missing something obvious here, but isn't a cdf supposed to be non decreasing ? If is a cdf of a random variable and then it must be that .",F X x \leq y F(x) = P(X \leq x) = P(X \leq y) - P(x < X \leq y) \leq P(X \leq y) = F(y),"['probability', 'probability-theory', 'statistics']"
17,A fair six-sided die is rolled repeatedly until the product of the rolls is square.,A fair six-sided die is rolled repeatedly until the product of the rolls is square.,,"I'm stuck on this problem. A fair six-sided die is rolled repeatedly. On average how long does it take until the first time that the product of the numbers rolled is a square? (For example, if the first roll is 1 or 4, it takes just one roll; if the sequence begins 3, 2, 6, then it takes three rolls.) I'm trying to use prime factors to get a solution, for instance if we don't roll a 1 or 4 first, rolling it again will not affect the chance of the next throw giving our product as a square, and we need an even number of 5s, the number of 2s + number of 6s to be even, and the number of 3s + number of 6s to be even. I know I need to relate this to Markov chains somehow, but I'm stuck as to how.","I'm stuck on this problem. A fair six-sided die is rolled repeatedly. On average how long does it take until the first time that the product of the numbers rolled is a square? (For example, if the first roll is 1 or 4, it takes just one roll; if the sequence begins 3, 2, 6, then it takes three rolls.) I'm trying to use prime factors to get a solution, for instance if we don't roll a 1 or 4 first, rolling it again will not affect the chance of the next throw giving our product as a square, and we need an even number of 5s, the number of 2s + number of 6s to be even, and the number of 3s + number of 6s to be even. I know I need to relate this to Markov chains somehow, but I'm stuck as to how.",,"['probability', 'statistics', 'markov-chains', 'dice']"
18,Please help me determine the boundedness of a function.,Please help me determine the boundedness of a function.,,"Assumption Suppose the function $K: \mathbb R \to \mathbb R_{\geq 0}$ is symmetric about $0$ and the following holds \begin{align} \int_{-\infty}^\infty K(z)dz &= 1,\\ \int_{-\infty}^\infty K^2(z)dz &< \infty,\\ \int_{-\infty}^\infty z^2 K(z)dz &< \infty,\\ \int_{-\infty}^\infty |z|^3 K(z)dz &< \infty. \end{align} Problem Can we show that the following is true in this case? \begin{align} \int_{-\infty}^\infty z^2 K^2(z)dz < \infty \end{align} Intuitively it seems correct, but I have no idea how to show it mathematically.","Assumption Suppose the function is symmetric about and the following holds Problem Can we show that the following is true in this case? Intuitively it seems correct, but I have no idea how to show it mathematically.","K: \mathbb R \to \mathbb R_{\geq 0} 0 \begin{align}
\int_{-\infty}^\infty K(z)dz &= 1,\\
\int_{-\infty}^\infty K^2(z)dz &< \infty,\\
\int_{-\infty}^\infty z^2 K(z)dz &< \infty,\\
\int_{-\infty}^\infty |z|^3 K(z)dz &< \infty.
\end{align} \begin{align}
\int_{-\infty}^\infty z^2 K^2(z)dz < \infty
\end{align}","['real-analysis', 'analysis', 'statistics']"
19,"$X_i\sim \mathrm{UNIF}(0,\theta)$. Show that $S=X_{n:n}$ is sufficient for $\theta$ by the factorization criterion.",. Show that  is sufficient for  by the factorization criterion.,"X_i\sim \mathrm{UNIF}(0,\theta) S=X_{n:n} \theta","Consider a random sample from a uniform distribution $X_i\sim \mathrm{UNIF}(0,\theta)$ , where $\theta$ is unknown. Show that $S=X_{n:n}$ is sufficient for $\theta$ by the factorization criterion. Factorization Criterion : if $X_1,...,X_n$ have joint pdf $f(x_1,...,x_n;\theta)$ and if $S=(S_1,...,S_k)$ , then $S_1,...,S_k$ are jointly sufficient for $\theta$ if and only if $f(x_1,...,x_n;\theta)=g(s;\theta)h(x_1,...x_n)$ based on the questions, it is known that $X_i\sim \mathrm{UNIF}(0,\theta)$ so the pdf is $f(x) = 1/\theta$ , $0<=x<=\theta$ and the CDF is $F(x) = x/\theta$ so, the joint pdf is $f(x_1,...,x_n;\theta)=f(x_1;\theta)...f(x_n;\theta)$ $=(1/\theta)^n$ $=1/\theta^n$ $=g(x_{n:n};\theta)h(x_1,...,x_n)$ where $=g(x_{n:n};\theta) =  g(s;\theta) =1/\theta^n$ if $s<\theta$ and zero otherwise, and $h(x_1,...,x_n) = 1$ if $0<x_{1:n}$ and zero otherwise. So, $S=X_{n:n}$ is sufficient for $\theta$ But I don't understand why $g(x_{n:n};\theta) =  g(s;\theta) =1/\theta^n$ ?","Consider a random sample from a uniform distribution , where is unknown. Show that is sufficient for by the factorization criterion. Factorization Criterion : if have joint pdf and if , then are jointly sufficient for if and only if based on the questions, it is known that so the pdf is , and the CDF is so, the joint pdf is where if and zero otherwise, and if and zero otherwise. So, is sufficient for But I don't understand why ?","X_i\sim \mathrm{UNIF}(0,\theta) \theta S=X_{n:n} \theta X_1,...,X_n f(x_1,...,x_n;\theta) S=(S_1,...,S_k) S_1,...,S_k \theta f(x_1,...,x_n;\theta)=g(s;\theta)h(x_1,...x_n) X_i\sim \mathrm{UNIF}(0,\theta) f(x) = 1/\theta 0<=x<=\theta F(x) = x/\theta f(x_1,...,x_n;\theta)=f(x_1;\theta)...f(x_n;\theta) =(1/\theta)^n =1/\theta^n =g(x_{n:n};\theta)h(x_1,...,x_n) =g(x_{n:n};\theta) =  g(s;\theta) =1/\theta^n s<\theta h(x_1,...,x_n) = 1 0<x_{1:n} S=X_{n:n} \theta g(x_{n:n};\theta) =  g(s;\theta) =1/\theta^n","['statistics', 'uniform-distribution', 'order-statistics', 'sufficient-statistics']"
20,Find the UMVUE of $P(X \leq c)$ in exponential distribution?,Find the UMVUE of  in exponential distribution?,P(X \leq c),"Given iid observations $X_1,...,X_n$ on X with the pdf $f_\theta (x)=e^{-(x-\theta)} I(x > \theta)$ , find the UMVUE of $P(X \leq c)$ , for fixed $c>0$ . My attempt: I find $P(X \leq c)= 1-e^{-(c-\theta)}$ First, I find $T(X)=X_{(1)}$ is a complete and sufficient statistic for $\theta$ . The any UMVUE should be based on $T(X)=X_{(1)}$ . I compute $E(T(X))=\frac{\theta n+1}{n}$ . Thus, $T(X)=X_{(1)}$ is the UMVUE of $\frac{\theta n+1}{n}$ . Now there's still one step away. How to get the UMVUE of $1-e^{-(c-\theta)}$ . My idea is to compute $E[  1(X_1 \leq c)  |T]$ . But I don't know how to compute that. Or there exists other ideas, such as some transformation of the density $X_{(1)}$ and we can get the expectation directly to the $e^{\theta}$ .","Given iid observations on X with the pdf , find the UMVUE of , for fixed . My attempt: I find First, I find is a complete and sufficient statistic for . The any UMVUE should be based on . I compute . Thus, is the UMVUE of . Now there's still one step away. How to get the UMVUE of . My idea is to compute . But I don't know how to compute that. Or there exists other ideas, such as some transformation of the density and we can get the expectation directly to the .","X_1,...,X_n f_\theta (x)=e^{-(x-\theta)} I(x > \theta) P(X \leq c) c>0 P(X \leq c)= 1-e^{-(c-\theta)} T(X)=X_{(1)} \theta T(X)=X_{(1)} E(T(X))=\frac{\theta n+1}{n} T(X)=X_{(1)} \frac{\theta n+1}{n} 1-e^{-(c-\theta)} E[  1(X_1 \leq c)  |T] X_{(1)} e^{\theta}","['probability', 'statistics', 'statistical-inference', 'parameter-estimation', 'exponential-distribution']"
21,Some general question about statistics,Some general question about statistics,,"Consider an experiment of picking a real number between 0 and 1. Let's say I picked 0.5. Two interpretations are possible: Something extraordinary has happened, because the probability of picking 0.5 from the interval $[0,1]$ is zero. Nothing extraordinary has happened, because the probability that the number you picked is between 0 and 1 is 1. Both interpretations seem reasonable, but they have completely different conclusions. What is going on?","Consider an experiment of picking a real number between 0 and 1. Let's say I picked 0.5. Two interpretations are possible: Something extraordinary has happened, because the probability of picking 0.5 from the interval is zero. Nothing extraordinary has happened, because the probability that the number you picked is between 0 and 1 is 1. Both interpretations seem reasonable, but they have completely different conclusions. What is going on?","[0,1]","['statistics', 'statistical-inference']"
22,What is the probability that a matrix with i.i.d. normal entries is stable?,What is the probability that a matrix with i.i.d. normal entries is stable?,,"Let $A$ be an $n \times n$ random matrix, such that the entries $a_{ij}$ are i.i.d. from the standard normal distribution. I'm curious on the probability that $A$ is Schur stable. That is, $$P(\rho(A) < 1),$$ where $\rho(A)=\max\{|\lambda|:\lambda \in spec(A)\}$ . Are there practical lower bounds (i.e. something other than insanely tiny values)? The best I was able to figure out was $P(\rho(A)<1)=\sum_{j=1}^nP(|\lambda_j(A)|<1)$ , where $\lambda_j$ is the $j$ th eigenvalue of $A$ .","Let be an random matrix, such that the entries are i.i.d. from the standard normal distribution. I'm curious on the probability that is Schur stable. That is, where . Are there practical lower bounds (i.e. something other than insanely tiny values)? The best I was able to figure out was , where is the th eigenvalue of .","A n \times n a_{ij} A P(\rho(A) < 1), \rho(A)=\max\{|\lambda|:\lambda \in spec(A)\} P(\rho(A)<1)=\sum_{j=1}^nP(|\lambda_j(A)|<1) \lambda_j j A","['linear-algebra', 'probability', 'statistics', 'eigenvalues-eigenvectors', 'stability-theory']"
23,the probability of that the winning combinations have at least two consecutive numbers,the probability of that the winning combinations have at least two consecutive numbers,,"suppose that we have a game in which there are 40 balls numbered 1 to 40 and six are drawn without replacement to determine the winning combination.we want to find the probability of  that the winning combinations have at least two consecutive numbers my attempt: using numbers from 1 to 40,the number of  the possible pairs are ${40 \choose 2}$ ,from those pairs there is 39 pairs of consecutive numbers. now let's take $B$ the set of all pairs of  consecutive numbers ,i.e B is the union of those 39 pairs. $B=A_{1,2} \cup A_{2,3}\cup ......\cup A_{38,39} \cup A_{39,40}$ ( $A_{i,j}$ is the pair $(i,j)$ where i and j are consecutive numbers) let's calculate the probability of the event $B$ using ""The Union of a Finite Number of Events"" theorem $P(B=A_{1,2} \cup A_{2,3}\cup ......\cup A_{38,39} \cup A_{39,40})=$ $\sum_{i=1}^{39}P(A_{i,i+1})-\sum_{}^{}P(A_{i,i+1} \cap A_{j,j+1})+\sum_{}^{}P(A_{i,i+1} \cap A_{j,j+1}\cap A_{w,w+1})+_-.....-P(A_{1,2} \cap A_{2,3}\cap .....\cap A_{39,40})$ the first term $\sum_{i=1}^{39}P(A_{i,i+1})$ :the probability of each pair is just $\frac{1}{{40 \choose 2}}$ ,and we have 39 pairs so the first term equal $\frac{39}{{40 \choose 2}}$ the Second term $\sum_{}^{}P(A_{i,i+1} \cap A_{j,j+1})=P(A_{1,2} \cap A_{2,3})+...$ : here in each term the first pair have the propability of $\frac{1}{{40 \choose 2}}$ and the second pair have the propability of $\frac{1}{{40 \choose 2}-1}$ and we have ${39 \choose 2}$ terms,so the Second term equal $\frac{{39 \choose 2}}{({40 \choose 2}-1){40 \choose 2}}$ . i know that the attempt is not applicable because of such large amount of terms to deal with .anyway i have two questions:does  my approach is Right?,what is other approach to deal with this problem?.(i  started studying probability  in this  week  so please don't use advanced stuff )","suppose that we have a game in which there are 40 balls numbered 1 to 40 and six are drawn without replacement to determine the winning combination.we want to find the probability of  that the winning combinations have at least two consecutive numbers my attempt: using numbers from 1 to 40,the number of  the possible pairs are ,from those pairs there is 39 pairs of consecutive numbers. now let's take the set of all pairs of  consecutive numbers ,i.e B is the union of those 39 pairs. ( is the pair where i and j are consecutive numbers) let's calculate the probability of the event using ""The Union of a Finite Number of Events"" theorem the first term :the probability of each pair is just ,and we have 39 pairs so the first term equal the Second term : here in each term the first pair have the propability of and the second pair have the propability of and we have terms,so the Second term equal . i know that the attempt is not applicable because of such large amount of terms to deal with .anyway i have two questions:does  my approach is Right?,what is other approach to deal with this problem?.(i  started studying probability  in this  week  so please don't use advanced stuff )","{40 \choose 2} B B=A_{1,2} \cup A_{2,3}\cup ......\cup A_{38,39} \cup A_{39,40} A_{i,j} (i,j) B P(B=A_{1,2} \cup A_{2,3}\cup ......\cup A_{38,39} \cup A_{39,40})= \sum_{i=1}^{39}P(A_{i,i+1})-\sum_{}^{}P(A_{i,i+1} \cap A_{j,j+1})+\sum_{}^{}P(A_{i,i+1} \cap A_{j,j+1}\cap A_{w,w+1})+_-.....-P(A_{1,2} \cap A_{2,3}\cap .....\cap A_{39,40}) \sum_{i=1}^{39}P(A_{i,i+1}) \frac{1}{{40 \choose 2}} \frac{39}{{40 \choose 2}} \sum_{}^{}P(A_{i,i+1} \cap A_{j,j+1})=P(A_{1,2} \cap A_{2,3})+... \frac{1}{{40 \choose 2}} \frac{1}{{40 \choose 2}-1} {39 \choose 2} \frac{{39 \choose 2}}{({40 \choose 2}-1){40 \choose 2}}","['probability', 'combinatorics', 'probability-theory', 'statistics']"
24,Geometric random variable and its expectation,Geometric random variable and its expectation,,"Let X be a geometric random variable with p = 1/2. Compute E(X^3). I got the value of 26 as my answer. Is my approach correct? Firstly let's establish q = 1 - p for the sake of simplicity. Secondly, I have already calculated that: $$E({X^2}) = {q+1\over p^2} , E({X}) =  {1\over p}$$ Thus: $$E({X^3}) = \sum_{i=1}^\infty i^3q^{i-1}p = \sum_{i=1}^\infty ({i-1})^3q^{i-1}p + 3\sum_{i=1}^\infty ({i-1})^2q^{i-1}p + 3\sum_{i=1}^\infty ({i-1})q^{i-1}p + \sum_{i=1}^\infty q^{i-1}p$$ $$= \sum_{j=0}^\infty j^3q^{j}p + 3\sum_{j=0}^\infty j^2q^{j}p + 3\sum_{j=0}^\infty jq^{j}p + 1$$ $$= qE({X^3}) + 3qE({X^2}) + 3qE({X}) + 1$$ Rearranging these equations; $$({1-q})E({X^3}) = 3qE({X^2}) + 3qE({X}) + 1$$ $${p}E({X^3}) = 3qE({X^2}) + 3qE({X}) + 1$$ $${p}E({X^3}) = {(3q)}{q+1\over p^2} + {(3q)}{1\over p} + 1$$ $$E({X^3}) = {{(3q)}{q+1\over p^2} + {(3q)}{1\over p} + 1\over p}$$ substitute $$p = {1\over 2} ,q = {1\over 2}$$ and we get $$E({X^3}) = 26$$","Let X be a geometric random variable with p = 1/2. Compute E(X^3). I got the value of 26 as my answer. Is my approach correct? Firstly let's establish q = 1 - p for the sake of simplicity. Secondly, I have already calculated that: Thus: Rearranging these equations; substitute and we get","E({X^2}) = {q+1\over p^2} , E({X}) =  {1\over p} E({X^3}) = \sum_{i=1}^\infty i^3q^{i-1}p = \sum_{i=1}^\infty ({i-1})^3q^{i-1}p + 3\sum_{i=1}^\infty ({i-1})^2q^{i-1}p + 3\sum_{i=1}^\infty ({i-1})q^{i-1}p + \sum_{i=1}^\infty q^{i-1}p = \sum_{j=0}^\infty j^3q^{j}p + 3\sum_{j=0}^\infty j^2q^{j}p + 3\sum_{j=0}^\infty jq^{j}p + 1 = qE({X^3}) + 3qE({X^2}) + 3qE({X}) + 1 ({1-q})E({X^3}) = 3qE({X^2}) + 3qE({X}) + 1 {p}E({X^3}) = 3qE({X^2}) + 3qE({X}) + 1 {p}E({X^3}) = {(3q)}{q+1\over p^2} + {(3q)}{1\over p} + 1 E({X^3}) = {{(3q)}{q+1\over p^2} + {(3q)}{1\over p} + 1\over p} p = {1\over 2} ,q = {1\over 2} E({X^3}) = 26","['probability', 'statistics']"
25,Marginal Posterior Distribution for Multinomial/Dirichlet Variables,Marginal Posterior Distribution for Multinomial/Dirichlet Variables,,"Suppose that some data $(y_{1},\ldots,y_{J})$ are distributed multinomially with parameters $(\theta_{1},\ldots,\theta_{J})$ and that $\theta = (\theta_{1},\ldots,\theta_{J})$ has Dirichlet prior distribution: \begin{equation*} p(y_{1},\ldots,y_{J}|\theta_{1},\ldots,\theta_{J}) \propto \prod_{i=1}^{J}{\theta_{i}^{y_{i}}} \end{equation*} and \begin{equation*} p(\theta_{1},\ldots,\theta_{j}) \propto \prod_{i=1}^{J}{\theta_{i}^{\alpha_{i}-1}} \end{equation*} such that the $\theta_{i}$ sum to unity. I want to determine the distribution of $\theta_{1},\theta_{2}|y_{1},\ldots,y_{J}$ . It is clear that the posterior distribution of $\theta$ given $y$ also has a Dirichlet distribution \begin{equation*} p(\theta_{1},\ldots,\theta_{J}|y_{1},\ldots,y_{J}) \propto \prod_{i=1}^{J}{\theta_{i}^{\alpha_{i}+y_{i}-1}}. \end{equation*} The answer, I think, is that \begin{equation*} p(\theta_{1},\theta_{2}|y_{1},\ldots,y_{J}) \propto \theta_{1}^{y_{1}+\alpha_{1}-1}\theta_{2}^{y_{2}+\alpha_{2}-1}\left(1-\theta_{1}-\theta_{2}\right)^{-1+\sum_{i=3}^{J}{(y_{i}+\alpha_{i})}}. \end{equation*} I'm not clear, though, on how to obtain this result. I know that under the assumptions of the problem, \begin{equation*} p(\theta_{1},\theta_{2},1-\theta_{1}-\theta_{2})\propto \theta_{1}^{\alpha_{1}-1}\theta_{2}^{\alpha_{2}-1}(1-\theta_{1}-\theta_{2})^{1-\alpha_{1}-\alpha_{2}}, \end{equation*} but I haven't found how to incorporate this into my thinking. My instinct is to say that \begin{equation*} p(\theta_{1},\theta_{2}|y_{1},\ldots,y_{J}) = \int{p(\theta_{1},\ldots,\theta_{J}|y_{1},\ldots,y_{J})\,\mathrm{d}\theta_{3}\cdots\mathrm{d}\theta_{J}}, \end{equation*} but I'm not sure what the limits of integration should be. The $\theta_{i}$ are non-negative by assumption and sum to $1$ , so the bounds need to be subsets of $[0,1]$ in every case, but it's not clear to me how to restrict them (inductively?).","Suppose that some data are distributed multinomially with parameters and that has Dirichlet prior distribution: and such that the sum to unity. I want to determine the distribution of . It is clear that the posterior distribution of given also has a Dirichlet distribution The answer, I think, is that I'm not clear, though, on how to obtain this result. I know that under the assumptions of the problem, but I haven't found how to incorporate this into my thinking. My instinct is to say that but I'm not sure what the limits of integration should be. The are non-negative by assumption and sum to , so the bounds need to be subsets of in every case, but it's not clear to me how to restrict them (inductively?).","(y_{1},\ldots,y_{J}) (\theta_{1},\ldots,\theta_{J}) \theta = (\theta_{1},\ldots,\theta_{J}) \begin{equation*}
p(y_{1},\ldots,y_{J}|\theta_{1},\ldots,\theta_{J}) \propto \prod_{i=1}^{J}{\theta_{i}^{y_{i}}}
\end{equation*} \begin{equation*}
p(\theta_{1},\ldots,\theta_{j}) \propto \prod_{i=1}^{J}{\theta_{i}^{\alpha_{i}-1}}
\end{equation*} \theta_{i} \theta_{1},\theta_{2}|y_{1},\ldots,y_{J} \theta y \begin{equation*}
p(\theta_{1},\ldots,\theta_{J}|y_{1},\ldots,y_{J}) \propto \prod_{i=1}^{J}{\theta_{i}^{\alpha_{i}+y_{i}-1}}.
\end{equation*} \begin{equation*}
p(\theta_{1},\theta_{2}|y_{1},\ldots,y_{J}) \propto \theta_{1}^{y_{1}+\alpha_{1}-1}\theta_{2}^{y_{2}+\alpha_{2}-1}\left(1-\theta_{1}-\theta_{2}\right)^{-1+\sum_{i=3}^{J}{(y_{i}+\alpha_{i})}}.
\end{equation*} \begin{equation*}
p(\theta_{1},\theta_{2},1-\theta_{1}-\theta_{2})\propto \theta_{1}^{\alpha_{1}-1}\theta_{2}^{\alpha_{2}-1}(1-\theta_{1}-\theta_{2})^{1-\alpha_{1}-\alpha_{2}},
\end{equation*} \begin{equation*}
p(\theta_{1},\theta_{2}|y_{1},\ldots,y_{J}) = \int{p(\theta_{1},\ldots,\theta_{J}|y_{1},\ldots,y_{J})\,\mathrm{d}\theta_{3}\cdots\mathrm{d}\theta_{J}},
\end{equation*} \theta_{i} 1 [0,1]","['statistics', 'problem-solving', 'bayesian', 'multinomial-distribution']"
26,"Probability distributions for sorted observations of a random variable, such as the nth-highest roll from k dice.","Probability distributions for sorted observations of a random variable, such as the nth-highest roll from k dice.",,"This seems to be a bit of an unorthodox question since I haven't been able to find any questions quite like it on this site. The closest I can find are those pertaining specifically to the scenarios of rolling dice and ignoring some number of either only the lowest or only the highest. So, I'll first describe a more general case of the problem for anyone else who might need to know how the distribution of ordered observations of a random variable works. Note on notation: As per Wikipedia , I'm using $\left[ a .. b \right]$ to mean the set of integers between $a$ and $b$ —that is, $\left[ a .. b \right] = \left[ a,b \right] \cap \mathbb{N}$ General Case Take $k$ observations, $a_1$ through $a_k$ , of some random variable $A$ with distribution $\mathcal{A}$ . Put them in a list $b$ , ordered from smallest to largest, so that $b_n$ is the $n$ th-smallest value of $\{ a_i \mid i \in [1 .. k]\}$ . What is the probability distribution of $b_n$ ? I will refer to this distribution as $\Omega(\mathcal{A}, k, n)$ . Example Let's say $k$ = 5 and $A$ is a standard uniform random variable . That is, $A \sim \mathcal{U}(0,1)$ . We obtain five observations of $\mathcal{U}(0,1)$ : $a = ( .376, .531, .826, .896, .166 )$ and then we sort them: $b = ( .166, .376, .531, .826, .896 )$ Each $b_n$ is an observation of $\Omega(\mathcal{U}(0,1), 5, n)$ . For example, 0.531 is an observation of $\Omega(\mathcal{U}(0,1), 5, 3)$ . Specific Case The particular reason I came across this problem is for tabletop role-playing games, which typically use dice for determining random outcomes. A common method for modifying the shape of probability distributions without changing the minimum and maximum possible values is to have players perform one or more extra rolls and then discard the highest or lowest results before summing the remaining values. For example, roll a 20-sided dice twice and discard the highest, or roll a 6-sided dice four times and discard the lowest. When designing new game mechanics that use this type of random selection, it would be good to know what the actual probability distributions are. To determine the probability distribution of a sum of certain rolls in a sorted set, you need to know the probability distribution of each die after sorting. So, my specific case is a subset of the general case for a discrete uniform distribution with domain $[1..s]$ , where s is the number of sides on the die. I will call this distribution $D(s)$ . It has the following probability mass function and cumulative distribution function: $p(x; s) = \left\{\begin{array}{ll}\frac{1}{s} & \quad x \in [1 .. s] \\ 0 & \quad \text{otherwise} \end{array}\right.$ $F(x; s) = \left\{\begin{array}{ll} 0 & \quad x \lt 1 \\ \frac{\lfloor x \rfloor}{s} & \quad 1 \leq x \leq s \\ 1 & \quad x \gt s \end{array}\right.$ What I'm looking for is a way to get the probability distribution for the $n$ th-smallest value from rolling an $s$ -sided die $k$ times. Formally, I want to find the probability mass function $p(x; s, k, n)$ and/or the cumulative distribution function $F(x; s, k, n)$ of $\Omega(D(s), k, n)$ . Example Let's say $k$ = 4 and $A$ is a random variable that represents the outcome of rolling a 20-sided die. That is, $A \sim D(20)$ . We obtain four observations of $D(20)$ : $a = ( 19, 10, 10, 13)$ and then we sort them: $b = ( 10, 10, 13, 19 )$ Each $b_n$ is an observation of $\Omega(D(20), 4, n)$ . For example, the second 10 is an observation of $\Omega(D(20), 4, 2)$ . What I am personally looking for is just a solution to the dice problem. However, out of curiosity as to whether it is even possible, I do wonder if it is possible to come up with a more general composite function that handles the general case for any random variable. I'm sure there are use cases for needing to know the distribution of things like the middle half of observations from a normal distribution, or the tenth-highest outcome out of a hundred from a geometric distribution.","This seems to be a bit of an unorthodox question since I haven't been able to find any questions quite like it on this site. The closest I can find are those pertaining specifically to the scenarios of rolling dice and ignoring some number of either only the lowest or only the highest. So, I'll first describe a more general case of the problem for anyone else who might need to know how the distribution of ordered observations of a random variable works. Note on notation: As per Wikipedia , I'm using to mean the set of integers between and —that is, General Case Take observations, through , of some random variable with distribution . Put them in a list , ordered from smallest to largest, so that is the th-smallest value of . What is the probability distribution of ? I will refer to this distribution as . Example Let's say = 5 and is a standard uniform random variable . That is, . We obtain five observations of : and then we sort them: Each is an observation of . For example, 0.531 is an observation of . Specific Case The particular reason I came across this problem is for tabletop role-playing games, which typically use dice for determining random outcomes. A common method for modifying the shape of probability distributions without changing the minimum and maximum possible values is to have players perform one or more extra rolls and then discard the highest or lowest results before summing the remaining values. For example, roll a 20-sided dice twice and discard the highest, or roll a 6-sided dice four times and discard the lowest. When designing new game mechanics that use this type of random selection, it would be good to know what the actual probability distributions are. To determine the probability distribution of a sum of certain rolls in a sorted set, you need to know the probability distribution of each die after sorting. So, my specific case is a subset of the general case for a discrete uniform distribution with domain , where s is the number of sides on the die. I will call this distribution . It has the following probability mass function and cumulative distribution function: What I'm looking for is a way to get the probability distribution for the th-smallest value from rolling an -sided die times. Formally, I want to find the probability mass function and/or the cumulative distribution function of . Example Let's say = 4 and is a random variable that represents the outcome of rolling a 20-sided die. That is, . We obtain four observations of : and then we sort them: Each is an observation of . For example, the second 10 is an observation of . What I am personally looking for is just a solution to the dice problem. However, out of curiosity as to whether it is even possible, I do wonder if it is possible to come up with a more general composite function that handles the general case for any random variable. I'm sure there are use cases for needing to know the distribution of things like the middle half of observations from a normal distribution, or the tenth-highest outcome out of a hundred from a geometric distribution.","\left[ a .. b \right] a b \left[ a .. b \right] = \left[ a,b \right] \cap \mathbb{N} k a_1 a_k A \mathcal{A} b b_n n \{ a_i \mid i \in [1 .. k]\} b_n \Omega(\mathcal{A}, k, n) k A A \sim \mathcal{U}(0,1) \mathcal{U}(0,1) a = ( .376, .531, .826, .896, .166 ) b = ( .166, .376, .531, .826, .896 ) b_n \Omega(\mathcal{U}(0,1), 5, n) \Omega(\mathcal{U}(0,1), 5, 3) [1..s] D(s) p(x; s) = \left\{\begin{array}{ll}\frac{1}{s} & \quad x \in [1 .. s] \\ 0 & \quad \text{otherwise} \end{array}\right. F(x; s) = \left\{\begin{array}{ll} 0 & \quad x \lt 1 \\ \frac{\lfloor x \rfloor}{s} & \quad 1 \leq x \leq s \\ 1 & \quad x \gt s \end{array}\right. n s k p(x; s, k, n) F(x; s, k, n) \Omega(D(s), k, n) k A A \sim D(20) D(20) a = ( 19, 10, 10, 13) b = ( 10, 10, 13, 19 ) b_n \Omega(D(20), 4, n) \Omega(D(20), 4, 2)","['statistics', 'probability-distributions', 'random-variables', 'dice']"
27,When can standard deviation be equal to range,When can standard deviation be equal to range,,I was learning basic statistics and I read a proof that the standard deviation is always less than or equal to the range.  I don't understand how range can ever be equal to the standard deviation. I could only think of one case: when all data points have the same value. Is there any other case possible in which the equality holds?,I was learning basic statistics and I read a proof that the standard deviation is always less than or equal to the range.  I don't understand how range can ever be equal to the standard deviation. I could only think of one case: when all data points have the same value. Is there any other case possible in which the equality holds?,,['statistics']
28,Are Bernoulli distributions log-concave?,Are Bernoulli distributions log-concave?,,"Question: I am aware that the common continuous distributions (like Gaussian, Uniform, Gamma) are log-concave. I am wondering if Bernoulli distributions (a discrete distribution) is log-concave? If so, then does this extend to the Categorical distribution ? My attempt: For a Bernoulli( $p$ ) distribution $$ f(k)=p^k(1-p)^{1-k} \text{ for } k\in\{0,1\}, $$ we need to show that for some $\theta\in(0,1)$ , we have $$ f\Big(\theta k_1+(1-\theta) k_2\Big)\geq f(k_1)^\theta f(k_2)^{1-\theta}. $$ I can show this by considering two cases (i) $\theta k_1+(1-\theta) k_2=0$ and $\theta k_1+(1-\theta) k_2=1$ . Case (i) leads to $k_1,k_2=0$ which leads to equality in the log-concave inequality. Case (ii) leads to either $k_1,k_2=1$ which leads to equality in the log-concave inequality, or $k_1,k_2\notin\{0,1\}$ which leads to strict inequality in the log-concave inequality.","Question: I am aware that the common continuous distributions (like Gaussian, Uniform, Gamma) are log-concave. I am wondering if Bernoulli distributions (a discrete distribution) is log-concave? If so, then does this extend to the Categorical distribution ? My attempt: For a Bernoulli( ) distribution we need to show that for some , we have I can show this by considering two cases (i) and . Case (i) leads to which leads to equality in the log-concave inequality. Case (ii) leads to either which leads to equality in the log-concave inequality, or which leads to strict inequality in the log-concave inequality.","p 
f(k)=p^k(1-p)^{1-k} \text{ for } k\in\{0,1\},
 \theta\in(0,1) 
f\Big(\theta k_1+(1-\theta) k_2\Big)\geq f(k_1)^\theta f(k_2)^{1-\theta}.
 \theta k_1+(1-\theta) k_2=0 \theta k_1+(1-\theta) k_2=1 k_1,k_2=0 k_1,k_2=1 k_1,k_2\notin\{0,1\}","['probability', 'statistics', 'inequality', 'probability-distributions', 'bernoulli-distribution']"
29,Estimation of exponential distribution parameter from smallest $n$ out of N observations,Estimation of exponential distribution parameter from smallest  out of N observations,n,"I am interested in estimating the parameter $\lambda$ of an exponential distribution based on the smallest $n$ out of a total of $N$ observations. In mathematical terms: let $X$ be distributed according to $\text{Exp}(\lambda)$ and $x_1, \dots, x_N$ be random samples of X ordered, wlog, such that $x_1 < x_2 < \dots < x_N$ . How can I estimate the parameter $\lambda$ if I know the first $n$ observations $x_1, \dots, x_n$ and the total number of observations $N$ ? I thought I could write down a likelihood function by considering that the first observation is coming from the minimum of a sequence of $N$ i.i.d.r.v. and writing the corresponding probability, then the second from the minimum of the remaining $N-1$ and so on and so forth, but this approach seems pretty cumbersome and impractical if $n$ and $N$ are relatively large. Is there any other way I could approach this problem?","I am interested in estimating the parameter of an exponential distribution based on the smallest out of a total of observations. In mathematical terms: let be distributed according to and be random samples of X ordered, wlog, such that . How can I estimate the parameter if I know the first observations and the total number of observations ? I thought I could write down a likelihood function by considering that the first observation is coming from the minimum of a sequence of i.i.d.r.v. and writing the corresponding probability, then the second from the minimum of the remaining and so on and so forth, but this approach seems pretty cumbersome and impractical if and are relatively large. Is there any other way I could approach this problem?","\lambda n N X \text{Exp}(\lambda) x_1, \dots, x_N x_1 < x_2 < \dots < x_N \lambda n x_1, \dots, x_n N N N-1 n N","['statistics', 'probability-distributions', 'parameter-estimation', 'exponential-distribution', 'maximum-likelihood']"
30,"Generating random, non-negative unit weight vectors.","Generating random, non-negative unit weight vectors.",,"Put it simply, how do I generate uniformly randomly a vector $w = (w_1,w_2,w_3)$ such that $w_1+w_2+w_3 = 1$ and $w_i\geq 0$ ? Essentially, I want the same thing as in Uniform distribution on the surface of unit sphere , except in the $L_1$ norm and also in the positive quadrant. Note I need this for a simulation, so a direct reference to a python library would work. Also, I decided it's better to post it here after searching on stackoverflow - even the more natural $L^2$ norm version of the question was better answered here. I am tempted to do the naive $X_1,X_2,X_3\sim Unif[0,1]$ i.i.d and then normalize by the $L^1$ norm, but the above answer for $L^2$ says this only works for $L^2$ if I do normal random variables, so I am a bit unsure.","Put it simply, how do I generate uniformly randomly a vector such that and ? Essentially, I want the same thing as in Uniform distribution on the surface of unit sphere , except in the norm and also in the positive quadrant. Note I need this for a simulation, so a direct reference to a python library would work. Also, I decided it's better to post it here after searching on stackoverflow - even the more natural norm version of the question was better answered here. I am tempted to do the naive i.i.d and then normalize by the norm, but the above answer for says this only works for if I do normal random variables, so I am a bit unsure.","w = (w_1,w_2,w_3) w_1+w_2+w_3 = 1 w_i\geq 0 L_1 L^2 X_1,X_2,X_3\sim Unif[0,1] L^1 L^2 L^2","['probability', 'statistics', 'probability-distributions', 'uniform-distribution']"
31,Probability density of two random variables using characteristic function,Probability density of two random variables using characteristic function,,"I've been trying to solve the following question : $X$ and $Y$ are two real random variables with a probability density of : $$f(x,y) = e^{-y} *\mathscr{1}_{0<x<y}(x,y)$$ where $\mathscr{1}$ is the characteristic function. Verify that $f$ is a probability density. Give the marginal probability $f_1$ of $X$ and $f_2$ of $Y$ . Are $X$ and $Y$ independent? Determine $\mathbb P{\left\{\frac{X}{Y}\le z  \mbox{ and } Y \le y \right\}}$ for $z \in [0,1]$ . Give then the law of $\frac{X}{Y}$ . Are the $\frac{X}{Y}$ and $Y$ independent variables? For the first question I tried checking the condition of normalization : $\int_{R^2} f(x,y)dxdy = 1$ so I did : $\int_{-\infty}^{\infty}\int_{-\infty}^{\infty} e^{-y} *\mathscr{1}_{0<x<y}(x,y)dxdy$ $\int_{0}^{\infty}\int_{x}^{\infty} e^{-y} dydx = \int_{0}^{\infty} e^{-x} dx = 1$ But I'm not sure of this manipulation. For the second question I did : $$f_{1}(x) = \int_{-\infty}^{\infty} f(x,y) dy = \int_{-\infty}^{\infty} e^{-y} *\mathscr{1}_{0<x<y}(x,y)dy = \int_{x}^{\infty} e^{-y} dy = e^{-x}$$ $$f_{2}(y) = \int_{-\infty}^{\infty} f(x,y) dx = \int_{-\infty}^{\infty} e^{-y} *\mathscr{1}_{0<x<y}(x,y)dx = \int_{0}^{y} e^{-y} dx = ye^{-y}$$ But I'm also not sure. For the third question I think I should try to check if $f(x,y) = f_1(x)f_2(y)$ but I don't know how to handle out the characteristic function in the equality. For question 4 I tried the following : $P{\left\{\frac{X}{Y}\le z  \mbox{ and } Y \le y \right\}}$ for $z \in [0,1]$ = $P$ { ${\frac{X}{Y}\le z}$ } * $P$ { ${Y\le y}$ } $P$ { ${X{\le}Y}$ } $= \int_{-\infty}^{\infty} \int_{-\infty}^{y} f(x,y) dxdy = \int_{-\infty}^{\infty} \int_{-\infty}^{y} e^{-y} *\mathscr{1}_{0<x<y}(x,y)dxdy = \int_{0}^{\infty} \int_{0}^{y} e^{-y}dxdy = \int_{0}^{\infty}e^{-y} \int_{0}^{y} dxdy = \int_{-\infty}^{\infty}ye^{-y}dy = 1$ and $P$ { ${Y{\le}y}$ } = 1 Thus, the answer is 1*1=1 and the law of the fraction is yexp(-y). For the rest sincerely I have no clue. Thank you for any advice !","I've been trying to solve the following question : and are two real random variables with a probability density of : where is the characteristic function. Verify that is a probability density. Give the marginal probability of and of . Are and independent? Determine for . Give then the law of . Are the and independent variables? For the first question I tried checking the condition of normalization : so I did : But I'm not sure of this manipulation. For the second question I did : But I'm also not sure. For the third question I think I should try to check if but I don't know how to handle out the characteristic function in the equality. For question 4 I tried the following : for = { } * { } { } and { } = 1 Thus, the answer is 1*1=1 and the law of the fraction is yexp(-y). For the rest sincerely I have no clue. Thank you for any advice !","X Y f(x,y) = e^{-y} *\mathscr{1}_{0<x<y}(x,y) \mathscr{1} f f_1 X f_2 Y X Y \mathbb P{\left\{\frac{X}{Y}\le z  \mbox{ and } Y \le y \right\}} z \in [0,1] \frac{X}{Y} \frac{X}{Y} Y \int_{R^2} f(x,y)dxdy = 1 \int_{-\infty}^{\infty}\int_{-\infty}^{\infty} e^{-y} *\mathscr{1}_{0<x<y}(x,y)dxdy \int_{0}^{\infty}\int_{x}^{\infty} e^{-y} dydx = \int_{0}^{\infty} e^{-x} dx = 1 f_{1}(x) = \int_{-\infty}^{\infty} f(x,y) dy = \int_{-\infty}^{\infty} e^{-y} *\mathscr{1}_{0<x<y}(x,y)dy = \int_{x}^{\infty} e^{-y} dy = e^{-x} f_{2}(y) = \int_{-\infty}^{\infty} f(x,y) dx = \int_{-\infty}^{\infty} e^{-y} *\mathscr{1}_{0<x<y}(x,y)dx = \int_{0}^{y} e^{-y} dx = ye^{-y} f(x,y) = f_1(x)f_2(y) P{\left\{\frac{X}{Y}\le z  \mbox{ and } Y \le y \right\}} z \in [0,1] P {\frac{X}{Y}\le z} P {Y\le y} P {X{\le}Y} = \int_{-\infty}^{\infty} \int_{-\infty}^{y} f(x,y) dxdy = \int_{-\infty}^{\infty} \int_{-\infty}^{y} e^{-y} *\mathscr{1}_{0<x<y}(x,y)dxdy = \int_{0}^{\infty} \int_{0}^{y} e^{-y}dxdy = \int_{0}^{\infty}e^{-y} \int_{0}^{y} dxdy = \int_{-\infty}^{\infty}ye^{-y}dy = 1 P {Y{\le}y}","['statistics', 'probability-distributions', 'random-variables', 'characteristic-functions', 'marginal-probability']"
32,Expected Tosses To Get THH sequence [duplicate],Expected Tosses To Get THH sequence [duplicate],,"This question already has answers here : Stuck on a probability problem/Expectation of coin toss (2 answers) Closed 10 months ago . What is the expected number of tosses of a fair coin to see a $THH$ sequence? Here is my approach: Here are the different cases: We get $THH$ straight away in $3$ throws (probability $\frac{1}{8}$ ). We first get $H$ (probability $\frac{1}{2}$ ), in which case we restart and number of tosses is $\mathbb{E}(X+1)$ We get $TT$ (probability $\frac{1}{4}$ ). In this case we need $\mathbb{E}(X ~|~ T)$ as first toss is a $T$ . We get $THT$ (probability $\frac{1}{8}$ ). Once again, in this case we need $\mathbb{E}(X~|~T)$ as first toss is a $T$ . Thus, putting this together: $$\mathbb{E}(X) = 3\cdot\frac{1}{8} + \mathbb{E}(X+1)\cdot\frac{1}{2} + \mathbb{E}(X~|~T)(\frac{1}{4}+ \frac{1}{8})$$ Now, let's find $\mathbb{E}(X~|~T) = \mathbb{E}(THH~|~T) = \mathbb{E}(Y)$ : We flip two $H$ immediately after the first $T$ (probability $\frac{1}{4}$ ) We flip a $T$ after the first $T$ (probability $\frac{1}{2}$ ), so we restart and the new expectation is $\mathbb{E}(Y)+1$ We flip a $H$ and then $T$ after the first $T$ to get $THT$ (probability $\frac{1}{4}$ ), and so we restart with expectation $\mathbb{E}(Y)+2$ Solving for $\mathbb{E}(Y)$ : $$\mathbb{E}(Y) = 2\cdot\frac{1}{4} + (\mathbb{E}(Y)+1)\cdot\frac{1}{2} + (\mathbb{E}(Y)+2)\cdot\frac{1}{4}       = 6$$ Plugging this back into the original equation for $\mathbb{E}(X)$ and solving we get $\mathbb{E}(X)= 6.25$ when the answer is $8$ . Can someone please explain where I went wrong?","This question already has answers here : Stuck on a probability problem/Expectation of coin toss (2 answers) Closed 10 months ago . What is the expected number of tosses of a fair coin to see a sequence? Here is my approach: Here are the different cases: We get straight away in throws (probability ). We first get (probability ), in which case we restart and number of tosses is We get (probability ). In this case we need as first toss is a . We get (probability ). Once again, in this case we need as first toss is a . Thus, putting this together: Now, let's find : We flip two immediately after the first (probability ) We flip a after the first (probability ), so we restart and the new expectation is We flip a and then after the first to get (probability ), and so we restart with expectation Solving for : Plugging this back into the original equation for and solving we get when the answer is . Can someone please explain where I went wrong?","THH THH 3 \frac{1}{8} H \frac{1}{2} \mathbb{E}(X+1) TT \frac{1}{4} \mathbb{E}(X ~|~ T) T THT \frac{1}{8} \mathbb{E}(X~|~T) T \mathbb{E}(X) = 3\cdot\frac{1}{8} + \mathbb{E}(X+1)\cdot\frac{1}{2} + \mathbb{E}(X~|~T)(\frac{1}{4}+ \frac{1}{8}) \mathbb{E}(X~|~T) = \mathbb{E}(THH~|~T) = \mathbb{E}(Y) H T \frac{1}{4} T T \frac{1}{2} \mathbb{E}(Y)+1 H T T THT \frac{1}{4} \mathbb{E}(Y)+2 \mathbb{E}(Y) \mathbb{E}(Y) = 2\cdot\frac{1}{4} + (\mathbb{E}(Y)+1)\cdot\frac{1}{2} + (\mathbb{E}(Y)+2)\cdot\frac{1}{4} 
     = 6 \mathbb{E}(X) \mathbb{E}(X)= 6.25 8","['probability', 'statistics']"
33,PDF of product of power law distributed variables,PDF of product of power law distributed variables,,"Consider $X_1 \sim f_1 = ax^{a-1}$ , $X_2 \sim f_2 = bx^{b-1}$ , both independent and defined over the positive domain. I am interested in the PDF of the product $Z = X_1X_2$ . The know expression of the product distribution is $$ f_Z(z) = \int_{-\infty}^{\infty}f_1(x)f_2(z/x)\frac{1}{|x|} dx\\ =\int_{0}^{1}ax^{a-1} b(z/x)^{b-1}\frac{1}{|x|} dx\\ =ab z^{b-1}\int_{0}^{1}x^{a-b-1} dx\\ \propto z^{b-1} $$ What I am worried about is the asymmetry: clearly $f_Z(z)$ cannot depend on $b$ alone. More specifically, because of commutativity of product one can also compute the distribution of $X_2X_1$ to be $\propto z^{a-1}$ which is a contraddiction. What is going wrong here?","Consider , , both independent and defined over the positive domain. I am interested in the PDF of the product . The know expression of the product distribution is What I am worried about is the asymmetry: clearly cannot depend on alone. More specifically, because of commutativity of product one can also compute the distribution of to be which is a contraddiction. What is going wrong here?","X_1 \sim f_1 = ax^{a-1} X_2 \sim f_2 = bx^{b-1} Z = X_1X_2 
f_Z(z) = \int_{-\infty}^{\infty}f_1(x)f_2(z/x)\frac{1}{|x|} dx\\
=\int_{0}^{1}ax^{a-1} b(z/x)^{b-1}\frac{1}{|x|} dx\\
=ab z^{b-1}\int_{0}^{1}x^{a-b-1} dx\\
\propto z^{b-1}
 f_Z(z) b X_2X_1 \propto z^{a-1}","['probability', 'statistics']"
34,"Is (X,Y) bivariate normal in this case?","Is (X,Y) bivariate normal in this case?",,"Let (X, Y) be a bivariate random variable. It is known that $X|Y \sim N(\phi Y, \sigma^2)$ and $Y|X \sim N(\phi X, \sigma^2)$ , for some known $\phi, \sigma^2, −1 < \phi < 1$ .  Is (X,Y) bivariate normal? I want to say they are bivariate normal, but I don't know how to conclude. I like this definition:  (X,Y) being bivariate normal is ""any linear combination of X and Y "" is normal.","Let (X, Y) be a bivariate random variable. It is known that and , for some known .  Is (X,Y) bivariate normal? I want to say they are bivariate normal, but I don't know how to conclude. I like this definition:  (X,Y) being bivariate normal is ""any linear combination of X and Y "" is normal.","X|Y \sim N(\phi Y, \sigma^2) Y|X \sim N(\phi X, \sigma^2) \phi, \sigma^2, −1 < \phi < 1","['probability', 'statistics']"
35,Uniformly Sampling from a High-Dimensional Unit Sphere [duplicate],Uniformly Sampling from a High-Dimensional Unit Sphere [duplicate],,"This question already has answers here : Algorithm to generate an uniform distribution of points in the volume of an hypersphere/on the surface of an hypersphere. (3 answers) Closed last year . The community reviewed whether to reopen this question last year and left it closed: Original close reason(s) were not resolved This Question is supposed to gather techniques on how to uniformly sample points on $\mathbb S^{d-1}$ for large $d$ . There are a few things to keep in mind for this problem, mainly as the dimension $d$ increases: The computation of the norm of vectors in $\mathbb R^d$ becomes increasingly expensive. Hence methods relying on normalization of vectors become less efficient. The volume of the $d$ -ball in relation to larger sets containing the $d$ -ball decreases. As a consequence, acceptance-rejection sampling methods become less efficient as we reject too many samples. To give two examples of ""naive"" methods one might try, which do work well in low dimensions but not in large dimensions, consider the following: Normalizing a symmetric distribution: First, sample a random vector $X\in\mathbb R^d$ from a distribution which is invariant under symmetry transformations of $\mathbb S^{d-1}$ , then normalize $X$ , i.e. compute $X/\Vert X\Vert$ . This normalized vector will be uniformly distributed on $\mathbb S^{d-1}$ . This method suffers from Problem 1. Rejecting points from the unit cube: Sample a random vector $X$ uniformly in $[-1,1]^d$ . If the random vector lies inside the $d$ -ball, keep the sample, if not, discard the sample. This will generate a uniform distribution on the $d$ -ball. A uniform distribution on $\mathbb S^{d-1}$ can then be achieved by normalizing the samples. This acceptance-rejection method suffers from Problem 2, since as $d$ increases, fewer points in the unit cube are located in the unit $d$ -ball and hence we will reject a lot of samples. (This method also suffers from Problem 1, but that's beside the point.) Question: What are sampling techniques that achieve a uniform distribution on $\mathbb S^{d-1}$ but avoid Problems 1 and 2 for large $d$ ?","This question already has answers here : Algorithm to generate an uniform distribution of points in the volume of an hypersphere/on the surface of an hypersphere. (3 answers) Closed last year . The community reviewed whether to reopen this question last year and left it closed: Original close reason(s) were not resolved This Question is supposed to gather techniques on how to uniformly sample points on for large . There are a few things to keep in mind for this problem, mainly as the dimension increases: The computation of the norm of vectors in becomes increasingly expensive. Hence methods relying on normalization of vectors become less efficient. The volume of the -ball in relation to larger sets containing the -ball decreases. As a consequence, acceptance-rejection sampling methods become less efficient as we reject too many samples. To give two examples of ""naive"" methods one might try, which do work well in low dimensions but not in large dimensions, consider the following: Normalizing a symmetric distribution: First, sample a random vector from a distribution which is invariant under symmetry transformations of , then normalize , i.e. compute . This normalized vector will be uniformly distributed on . This method suffers from Problem 1. Rejecting points from the unit cube: Sample a random vector uniformly in . If the random vector lies inside the -ball, keep the sample, if not, discard the sample. This will generate a uniform distribution on the -ball. A uniform distribution on can then be achieved by normalizing the samples. This acceptance-rejection method suffers from Problem 2, since as increases, fewer points in the unit cube are located in the unit -ball and hence we will reject a lot of samples. (This method also suffers from Problem 1, but that's beside the point.) Question: What are sampling techniques that achieve a uniform distribution on but avoid Problems 1 and 2 for large ?","\mathbb S^{d-1} d d \mathbb R^d d d X\in\mathbb R^d \mathbb S^{d-1} X X/\Vert X\Vert \mathbb S^{d-1} X [-1,1]^d d d \mathbb S^{d-1} d d \mathbb S^{d-1} d","['probability', 'statistics', 'uniform-distribution', 'sampling']"
36,Finding the density of a function of a distribution,Finding the density of a function of a distribution,,"I came across a question that defined the R.V $X$ to be uniformly distributed on the interval $[-2,1]$ and we are asked to find the density of $U=X^2$ . Since the function being applied to X is not injective, I opted for the method of distribution functions, thus: $$P(U\le u)$$ $$= P(X^2 \le u)$$ $$=P(-\sqrt{u} \le X \le \sqrt{u}) $$ It is clear by substitution that the bounds for $U$ are from $[0,4]$ So all that is left is to solve for: $$ \ \int_{-\sqrt{u}}^{\sqrt{u}} \frac{1}{3} \ dx \ $$ $$ = 2\frac{\sqrt{u}}{3} $$ This gives me my distribution function but after deriving to obtain the density: $$ f(u) = \frac{1}{3\sqrt{u}} $$ This does not give a valid density for the bounds $[0,4]$ . I assume my error lies in the initial bounds for the derivation of the distribution function but after a little messing around I still cannot pinpoint where the mistake lies. And clues would be greatly appreciated!","I came across a question that defined the R.V to be uniformly distributed on the interval and we are asked to find the density of . Since the function being applied to X is not injective, I opted for the method of distribution functions, thus: It is clear by substitution that the bounds for are from So all that is left is to solve for: This gives me my distribution function but after deriving to obtain the density: This does not give a valid density for the bounds . I assume my error lies in the initial bounds for the derivation of the distribution function but after a little messing around I still cannot pinpoint where the mistake lies. And clues would be greatly appreciated!","X [-2,1] U=X^2 P(U\le u) = P(X^2 \le u) =P(-\sqrt{u} \le X \le \sqrt{u})  U [0,4]  \ \int_{-\sqrt{u}}^{\sqrt{u}} \frac{1}{3} \ dx \   = 2\frac{\sqrt{u}}{3}   f(u) = \frac{1}{3\sqrt{u}}  [0,4]","['probability', 'statistics', 'probability-distributions']"
37,The complete sufficient statistics for uniform distribution [closed],The complete sufficient statistics for uniform distribution [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed last year . Improve this question Given uniform distribution $(0, \theta)$ , we know the complete sufficient statistics is $X_{(n)}$ . We can show it is complete by definition of the completeness. Another uniform distribution is $(\theta, 2\theta)$ . Now the  sufficient statistics is $(X_{(1)}, X_{(n)})$ . It is not complete, however. The uniform $(\theta, 2\theta)$ is a scale family, with standard pdf f(z) ~ uniform (1,2). So if $z_1,...,z_n$ is a random sample from a uniform $(1,2)$ , then $x_1=\theta z_1,..., x_n = \theta z_n$ . So the distribution of $(X_{(1)}, X_{(n)})$ does not depend on $\theta$ . It is thus not complete. My question: why we cannot say uniform distribution $(0, \theta)$ is a scalar distribution with Uniform (0,1)?","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed last year . Improve this question Given uniform distribution , we know the complete sufficient statistics is . We can show it is complete by definition of the completeness. Another uniform distribution is . Now the  sufficient statistics is . It is not complete, however. The uniform is a scale family, with standard pdf f(z) ~ uniform (1,2). So if is a random sample from a uniform , then . So the distribution of does not depend on . It is thus not complete. My question: why we cannot say uniform distribution is a scalar distribution with Uniform (0,1)?","(0, \theta) X_{(n)} (\theta, 2\theta) (X_{(1)}, X_{(n)}) (\theta, 2\theta) z_1,...,z_n (1,2) x_1=\theta z_1,..., x_n = \theta z_n (X_{(1)}, X_{(n)}) \theta (0, \theta)","['statistics', 'statistical-inference']"
38,Prove that $J=JH=HJ$,Prove that,J=JH=HJ,"The question asks for the idempotency of \begin{align*} H-\frac{1}{n}J \end{align*} where $H$ is the hat matrix for multilinear regression, $H = X(X'X)^{-1}X'$ , and $J$ is the matrix of all 1's. I proceeded by definition, i.e., wanting to show that $(H-\frac{1}{n}J)(H-\frac{1}{n}J)= H-\frac{1}{n}J$ , expanding it I got: \begin{align*} H-\frac{1}{n}(HJ+JH)+\frac{1}{n}J \end{align*} where we can find that $HJ=JH$ , knowing that any element of the i-th row of $HJ$ is the sum of i-th row of $H$ ; any element of j-th column of $JH$ is the sum of j-th column of $H$ , combining with the fact that $H$ is symmetric. How can I proceed from up here? It seems necessary that $HJ=J$ , but how do we prove it?","The question asks for the idempotency of where is the hat matrix for multilinear regression, , and is the matrix of all 1's. I proceeded by definition, i.e., wanting to show that , expanding it I got: where we can find that , knowing that any element of the i-th row of is the sum of i-th row of ; any element of j-th column of is the sum of j-th column of , combining with the fact that is symmetric. How can I proceed from up here? It seems necessary that , but how do we prove it?","\begin{align*}
H-\frac{1}{n}J
\end{align*} H H = X(X'X)^{-1}X' J (H-\frac{1}{n}J)(H-\frac{1}{n}J)= H-\frac{1}{n}J \begin{align*}
H-\frac{1}{n}(HJ+JH)+\frac{1}{n}J
\end{align*} HJ=JH HJ H JH H H HJ=J","['matrices', 'statistics', 'linear-regression']"
39,Probability of sum of random variables,Probability of sum of random variables,,"I am trying to compute $P(X_1=x_1,\ldots,X_n=x_n\mid X_1+\cdots+X_n=x_1+\cdots+x_n)$ , where $X_i$ are independent samples from a Poisson distribution with mean $\lambda>0$ and $x_i$ are nonnegative values. $$P(X_1=x_1,\ldots,X_n=x_n\mid X_1+\cdots+X_n=x_1+....+x_n)=\frac{P(X_1=x_1,\ldots,X_n=x_n)}{P(X_1+\cdots+X_n=x_1+\cdots+x_n)}\;,$$ the numerator part is simple, but I have no idea for the denominator part; it looks like a sample mean to me, but I still do not know how to proceed further.","I am trying to compute , where are independent samples from a Poisson distribution with mean and are nonnegative values. the numerator part is simple, but I have no idea for the denominator part; it looks like a sample mean to me, but I still do not know how to proceed further.","P(X_1=x_1,\ldots,X_n=x_n\mid X_1+\cdots+X_n=x_1+\cdots+x_n) X_i \lambda>0 x_i P(X_1=x_1,\ldots,X_n=x_n\mid X_1+\cdots+X_n=x_1+....+x_n)=\frac{P(X_1=x_1,\ldots,X_n=x_n)}{P(X_1+\cdots+X_n=x_1+\cdots+x_n)}\;,","['probability', 'statistics']"
40,"Estimator for $\theta$ on $U[0,\theta]$",Estimator for  on,"\theta U[0,\theta]","Consider $\theta^\ast = X_{(1)}+X_{(n)}$ . I have the following questions: Is $\theta^\ast$ unbiased? I would say so. I need to show that $\mathbb E[\theta^\ast] = \mathbb E[X_{(1)}+X_{(n)}] = \theta$ . The expectation of $\mathbb E[X_{(n)}]$ is \begin{align*} F_{X_{n}}(x) &= \mathbb P(X_{(n)}\leqslant x)\\ &= \mathbb P(X_{(1)}\leqslant x,\dots, X_{(n)}\leqslant x)\\ &= \left(\frac x\theta\right)^n\\ f_{X_{(n)}}(x) &= F'_{X_{(n)}}(x)\\ &=n\theta^{n-1}x^{n-1}\\ \mathbb E[X_{(n)}] &= \int\limits_0^\theta xf_{X_{(n)}}(x)\\ &=\frac {n}{n+1}\theta. \end{align*} The expectation of $\mathbb E[X_{(1)}]$ is \begin{align*} F_{X_{(1)}}(x) &= 1-[1-F_{X}]^n\\ &=1-[1-\frac x\theta ]^n\\ f_{X_{(1)}}(x)&= F'_{X_{(1)}}(x)\\ &=n\theta^{-1} \left(1-\frac x \theta\right)^{n-1}\\ \mathbb E[X_{(1)}] &= \int\limits_{0}^\theta xf_{X_{(1)}}(x)\\ &=\frac 1{n+1}\theta. \end{align*} And therefore we have $$\mathbb E[X_{(1)}+X_{(n)}] = \frac{n}{n+1}\theta + \frac1 {n+1}\theta = \theta.$$ Is $\theta^\ast$ unbiased consistent? I need to show that $\mathbb P(|\theta-\theta^\ast|\geqslant \varepsilon)\to0$ for all $\varepsilon >0, n\to\infty$ . I am not sure how to do this or even if it is true. I believe I have to use some central limit theorem .",Consider . I have the following questions: Is unbiased? I would say so. I need to show that . The expectation of is The expectation of is And therefore we have Is unbiased consistent? I need to show that for all . I am not sure how to do this or even if it is true. I believe I have to use some central limit theorem .,"\theta^\ast = X_{(1)}+X_{(n)} \theta^\ast \mathbb E[\theta^\ast] = \mathbb E[X_{(1)}+X_{(n)}] = \theta \mathbb E[X_{(n)}] \begin{align*}
F_{X_{n}}(x) &= \mathbb P(X_{(n)}\leqslant x)\\
&= \mathbb P(X_{(1)}\leqslant x,\dots, X_{(n)}\leqslant x)\\
&= \left(\frac x\theta\right)^n\\
f_{X_{(n)}}(x) &= F'_{X_{(n)}}(x)\\
&=n\theta^{n-1}x^{n-1}\\
\mathbb E[X_{(n)}] &= \int\limits_0^\theta xf_{X_{(n)}}(x)\\
&=\frac {n}{n+1}\theta.
\end{align*} \mathbb E[X_{(1)}] \begin{align*}
F_{X_{(1)}}(x) &= 1-[1-F_{X}]^n\\
&=1-[1-\frac x\theta ]^n\\
f_{X_{(1)}}(x)&= F'_{X_{(1)}}(x)\\
&=n\theta^{-1} \left(1-\frac x \theta\right)^{n-1}\\
\mathbb E[X_{(1)}] &= \int\limits_{0}^\theta xf_{X_{(1)}}(x)\\
&=\frac 1{n+1}\theta.
\end{align*} \mathbb E[X_{(1)}+X_{(n)}] = \frac{n}{n+1}\theta + \frac1 {n+1}\theta = \theta. \theta^\ast \mathbb P(|\theta-\theta^\ast|\geqslant \varepsilon)\to0 \varepsilon >0, n\to\infty","['probability-theory', 'statistics', 'parameter-estimation']"
41,Swapping unknown number of balls from two drawers based on a coin toss [closed],Swapping unknown number of balls from two drawers based on a coin toss [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question There are n balls labeled with at least one person's name. The balls are distributed in two drawers, with drawer 1 containing more balls. Each person tosses a fair coin, if the outcome is heads, the person must put all the balls with their name from drawer 1 into drawer 2 and put the balls with their name from drawer 2 into drawer 1. Basically the balls are taken from both drawers and placed in the respective other one. Show that after each person tosses a coin, there is a positive probability that there are more balls in drawer 2 than in drawer 1. I encountered this problem in my textbook and don't know how to approach this question.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question There are n balls labeled with at least one person's name. The balls are distributed in two drawers, with drawer 1 containing more balls. Each person tosses a fair coin, if the outcome is heads, the person must put all the balls with their name from drawer 1 into drawer 2 and put the balls with their name from drawer 2 into drawer 1. Basically the balls are taken from both drawers and placed in the respective other one. Show that after each person tosses a coin, there is a positive probability that there are more balls in drawer 2 than in drawer 1. I encountered this problem in my textbook and don't know how to approach this question.",,"['probability', 'statistics']"
42,How to elegantly predict average number of zero crossings for cumulative sum plot for N flips of a coin where heads is +1 and tails is -1,How to elegantly predict average number of zero crossings for cumulative sum plot for N flips of a coin where heads is +1 and tails is -1,,"I believe the same question was asked in question 1338097, but I think the answer might be flawed. However, I'm not familiar with the terms and have only the most basic understanding of probability theory. I know that if you create a sequence of +1s and -1s by flipping a fair coin N times (e.g. heads for +1, tails for -1) the number of possible sequences, ranging from all +1s to all -1s is 2^N. And assuming the sequence is truly random, each of the possible sequences will have the same probability of occurring. Therefore, if you generated each of the 2^N possible sequences, performing the cumulative summation process for each and counting the number of times the sum crosses 0 (i.e. 1 -> 0 -> -1 or -1 -> 0 -> 1), then dividing that count by 2^N gives the answer I'm looking for. And for N = 5 or less, you could even figure it out on a piece of paper in a few minutes if you weren't a computer programmer or didn't have a computer. But I wrote a program to do it and here's my table of answers for N = 2 to 10: N    average 0 crossings  2    none (takes at least 3 moves to cross 0)  3    .25   4    .25  5    .4375  6    .4375  7    .59375  8    .59375  9    .730469  10   .730469 And since the process to come up with these answers involves nothing more than simple arithmetic, I believe these answers are as exact as single-precision floating point operations can give. Of course, the problem with this method is that the computer is brought to its knees for values of N higher than about 30. But I don't care about being that exact. Approximations to, say, 5 decimal places would be fine. Is there an elegant solution that would have my computer spitting out the answer for values of N greater than 100 or even 1000?","I believe the same question was asked in question 1338097, but I think the answer might be flawed. However, I'm not familiar with the terms and have only the most basic understanding of probability theory. I know that if you create a sequence of +1s and -1s by flipping a fair coin N times (e.g. heads for +1, tails for -1) the number of possible sequences, ranging from all +1s to all -1s is 2^N. And assuming the sequence is truly random, each of the possible sequences will have the same probability of occurring. Therefore, if you generated each of the 2^N possible sequences, performing the cumulative summation process for each and counting the number of times the sum crosses 0 (i.e. 1 -> 0 -> -1 or -1 -> 0 -> 1), then dividing that count by 2^N gives the answer I'm looking for. And for N = 5 or less, you could even figure it out on a piece of paper in a few minutes if you weren't a computer programmer or didn't have a computer. But I wrote a program to do it and here's my table of answers for N = 2 to 10: N    average 0 crossings  2    none (takes at least 3 moves to cross 0)  3    .25   4    .25  5    .4375  6    .4375  7    .59375  8    .59375  9    .730469  10   .730469 And since the process to come up with these answers involves nothing more than simple arithmetic, I believe these answers are as exact as single-precision floating point operations can give. Of course, the problem with this method is that the computer is brought to its knees for values of N higher than about 30. But I don't care about being that exact. Approximations to, say, 5 decimal places would be fine. Is there an elegant solution that would have my computer spitting out the answer for values of N greater than 100 or even 1000?",,"['probability', 'statistics']"
43,"Maximum likelihoof estimator of $\mu$ if $X_1\sim N(\mu,1)$",Maximum likelihoof estimator of  if,"\mu X_1\sim N(\mu,1)","Question: Let $X_1, . . . , X_n$ be a random sample with $X_1 \sim N(\mu, 1)$ where $\mu \geq 0$ . Derive the maximum likelihood estimator of $\mu$ . I have some difficulties understanding the question. I already calculated the MLE of $\mu$ when $X_1,...,X_n$ are a random sample from $N(\mu,\sigma^2)$ . In that case the MLE of $\mu$ is $\hat{\mu} = \bar{X}$ . Is it the same case here? Or does the $\mu\geq 0$ changes anything? Or maybe the question states that $X_2,...,X_n\sim N(\mu, \sigma^2)$ ? I'm not that familiar with statistic jargon.",Question: Let be a random sample with where . Derive the maximum likelihood estimator of . I have some difficulties understanding the question. I already calculated the MLE of when are a random sample from . In that case the MLE of is . Is it the same case here? Or does the changes anything? Or maybe the question states that ? I'm not that familiar with statistic jargon.,"X_1, . . . , X_n X_1 \sim N(\mu, 1) \mu \geq 0 \mu \mu X_1,...,X_n N(\mu,\sigma^2) \mu \hat{\mu} = \bar{X} \mu\geq 0 X_2,...,X_n\sim N(\mu, \sigma^2)","['statistics', 'maximum-likelihood']"
44,Sequence of random variables and limit theorems,Sequence of random variables and limit theorems,,"Let $\{X_{n}\}_{n}$ be a sequence of random variables independent and iddentically distributed with distribution $P$ and defined in the same probability space $(\Omega,\sigma,\mathbb{P})$ . Let $A$ be a Borel-set such that $P(A) > 0$ . We want to show that $$ \mathbb{P}(\{\omega\in\Omega : \#(\{n\in\mathbb{N} : X_{n}(\omega)\in A\}) = \infty\}) = 1 $$ I'm stuck in this result. I think that the proof is based in the fact that the set $A$ has positive measure, but I'm not able to related with the probability.","Let be a sequence of random variables independent and iddentically distributed with distribution and defined in the same probability space . Let be a Borel-set such that . We want to show that I'm stuck in this result. I think that the proof is based in the fact that the set has positive measure, but I'm not able to related with the probability.","\{X_{n}\}_{n} P (\Omega,\sigma,\mathbb{P}) A P(A) > 0 
\mathbb{P}(\{\omega\in\Omega : \#(\{n\in\mathbb{N} : X_{n}(\omega)\in A\}) = \infty\}) = 1
 A","['probability', 'statistics', 'borel-sets']"
45,Properties and Applications of Probability Distributions,Properties and Applications of Probability Distributions,,"I am an MBA Student taking courses in Statistics. Our prof gave us a data manipulation assignment in which we have a column that contains a single weather measurement over a period of 100 days. For example, the weather can be either Sunny, Rainy, Cloudy, Snowy or Windy. Based on this data, we have to calculate the probability of ""two consecutive days of any weather combination"". For example, what is the probability of a Sunny day followed by another Sunny day - or what is the probability of a Cloudy day followed by a Windy day? As such, I think there are 25 possible combinations - I made a 5 x 5 contingency table in which each entry consists of a possible weather combination. Using the data, I calculated the probability of each possible weather combination and populated the entries within the table. As a logical check, I ensured that the sum of probabilities in any given row always add up to 1. Although this was all the assignment was asking us for, I thought of the following idea: What if these actually aren't the ""true"" probabilities? By this I mean, what if this weather over these 100 days was unusual - is it possible to place a ""range"" on these probabilities ? For example, the probability of two consecutive Sunny days is 0.13, but in reality this probability could be anywhere between 0.11 and 0.15. Or, given that today is Snowy, there is a 0.3 ± 0.05 probability that it will be Sunny tomorrow This way, given the current weather, I could compare the probabilities and ranges for all possible weather combinations and find out the most likely weather for tomorrow. I spent the day thinking about this question, and it sounds that maybe a ""confidence interval"" might be the answer I am looking for. Now, the question becomes how to calculate the confidence interval for these 25 probabilities. I kept thinking about this question and thought that this question is like rolling a 5 sided dice. We learned that flipping a two sided coin is a Binomial Probability Distribution whereas anything with more than two sides is a Multinomial Probability Distribution ( https://en.wikipedia.org/wiki/Multinomial_distribution ). I know that the general formula of a 95% confidence interval (based on the standard deviation of the Binomial Distribution ) for a proportion can be given by : Estimated Proportion ± 1.96 sqrt[ (Estimated Proportion * (1 - Estimated Proportion)) / sqrt(n) ]. In the case of the Multinomial Probability Distribution - could I say that the 95% confidence interval: Estimated Proportion ± sqrt[n * Estimated Proportion * (1-Estimated Proportion)]? In the above formula, ""n"" would be the total number of points (i.e. 100) and I would repeat this formula for each of the 25 probabilities. This formula is based on the Standard Deviation of the Multinomial Distribution. Is my understanding of this correct?","I am an MBA Student taking courses in Statistics. Our prof gave us a data manipulation assignment in which we have a column that contains a single weather measurement over a period of 100 days. For example, the weather can be either Sunny, Rainy, Cloudy, Snowy or Windy. Based on this data, we have to calculate the probability of ""two consecutive days of any weather combination"". For example, what is the probability of a Sunny day followed by another Sunny day - or what is the probability of a Cloudy day followed by a Windy day? As such, I think there are 25 possible combinations - I made a 5 x 5 contingency table in which each entry consists of a possible weather combination. Using the data, I calculated the probability of each possible weather combination and populated the entries within the table. As a logical check, I ensured that the sum of probabilities in any given row always add up to 1. Although this was all the assignment was asking us for, I thought of the following idea: What if these actually aren't the ""true"" probabilities? By this I mean, what if this weather over these 100 days was unusual - is it possible to place a ""range"" on these probabilities ? For example, the probability of two consecutive Sunny days is 0.13, but in reality this probability could be anywhere between 0.11 and 0.15. Or, given that today is Snowy, there is a 0.3 ± 0.05 probability that it will be Sunny tomorrow This way, given the current weather, I could compare the probabilities and ranges for all possible weather combinations and find out the most likely weather for tomorrow. I spent the day thinking about this question, and it sounds that maybe a ""confidence interval"" might be the answer I am looking for. Now, the question becomes how to calculate the confidence interval for these 25 probabilities. I kept thinking about this question and thought that this question is like rolling a 5 sided dice. We learned that flipping a two sided coin is a Binomial Probability Distribution whereas anything with more than two sides is a Multinomial Probability Distribution ( https://en.wikipedia.org/wiki/Multinomial_distribution ). I know that the general formula of a 95% confidence interval (based on the standard deviation of the Binomial Distribution ) for a proportion can be given by : Estimated Proportion ± 1.96 sqrt[ (Estimated Proportion * (1 - Estimated Proportion)) / sqrt(n) ]. In the case of the Multinomial Probability Distribution - could I say that the 95% confidence interval: Estimated Proportion ± sqrt[n * Estimated Proportion * (1-Estimated Proportion)]? In the above formula, ""n"" would be the total number of points (i.e. 100) and I would repeat this formula for each of the 25 probabilities. This formula is based on the Standard Deviation of the Multinomial Distribution. Is my understanding of this correct?",,"['probability', 'statistics']"
46,Why do we have that $u\cdot v$ converges weakly to a standard Gaussian random variables as $n\to \infty$?,Why do we have that  converges weakly to a standard Gaussian random variables as ?,u\cdot v n\to \infty,"Following this question: Can we get the concentration inequality of the inner product of two unit vectors distributed on the sphere? . Let $u$ and $v$ be two random vectors on $R^n$ that are independent and uniformly distributed on the unit sphere. That means we can represent it as Gaussian random vectors $g\sim N(0, I_n)$ , $$u=\frac{g}{\|g\|_2}. $$ Why do we have that $u\cdot v$ (may be with some orders?) converges weakly to a standard Gaussian random variables as $n\to \infty$ ? That means $u\cdot v=O_p(1)$ .","Following this question: Can we get the concentration inequality of the inner product of two unit vectors distributed on the sphere? . Let and be two random vectors on that are independent and uniformly distributed on the unit sphere. That means we can represent it as Gaussian random vectors , Why do we have that (may be with some orders?) converges weakly to a standard Gaussian random variables as ? That means .","u v R^n g\sim N(0, I_n) u=\frac{g}{\|g\|_2}.
 u\cdot v n\to \infty u\cdot v=O_p(1)","['real-analysis', 'probability', 'statistics']"
47,"If $X$ and $Y$ are negatively correlated and $Y,Z$ are negatively correlated, does that mean $X,Z$ are positively correlated?","If  and  are negatively correlated and  are negatively correlated, does that mean  are positively correlated?","X Y Y,Z X,Z","If $Cov(X,Y)<0$ and $Cov(Y,Z)<0$ does that necessarily mean $Cov(X,Z)>0$ ? Intuitively I'm thinking yes, but I'm trying to prove it.  My thoughts were to look at $E(XZ)$ and condition that on $X$ to see if that helps somehow. I was also thinking that you could consider covariance to be like the angle between two random variables and relate that to cosine somehow but in this case we're not assuming the random variables are centered either.","If and does that necessarily mean ? Intuitively I'm thinking yes, but I'm trying to prove it.  My thoughts were to look at and condition that on to see if that helps somehow. I was also thinking that you could consider covariance to be like the angle between two random variables and relate that to cosine somehow but in this case we're not assuming the random variables are centered either.","Cov(X,Y)<0 Cov(Y,Z)<0 Cov(X,Z)>0 E(XZ) X","['probability-theory', 'statistics', 'correlation']"
48,Compute the MLE of variance for $f(x) = 3x^3 /\theta^3$,Compute the MLE of variance for,f(x) = 3x^3 /\theta^3,"We are given $X_1, X_2,\dots, X_n$ that are independent and with the same disturbution function $f(x) = 3x^2 /\theta^3$ for $ 0 \leq x \leq \theta$ , where $\theta$ is an unknown positive variable. Using the maximum likelyhood method find : An MLE for $\theta$ An MLE for the variance of Xi's My answer to 1 is the well -known method : $L(\theta) = \prod_{i=1}^nf(X_i:\theta) \implies $ $$ L(\theta) = (\frac{3}{\theta^3})^n\prod_{i=1}^{n}x_i^3 $$ Now this has a well-known answer : $\hat \theta = \max_{1\leq i\leq n}x_i$ My problem is question 2 : I haven't got the concept of MLE quite well . I computed $\sigma^2 = Var(Xi) = \frac{3\theta^2}{5}$ . When we are trying to find an MLE for $Var(X_i)$ is it like we are trying to find an MLE for $\theta^2$ ? And if we already have an MLE for $\theta$ can't we just say that the MLE for $\theta^2$ is $\hat \theta^2$ ? So I would answer something like : $\hat Var(X_i) =\frac{3}{5}\hat \theta^2 $ but I am not sure at all . Even if question 1) wasn't present , the only way I know to use this method is to -blindly - take the definition of maximum likelyhood function (which hopefully will be a function  of the parameter I want to estimate) $L(\theta) = \prod_{i=1}^nf(X_i:\theta) $ . So I thought I could maybe write $f(x) $ as a function of $3/5 \theta^2$ : $$f(x:\frac{3}{5}\theta^2) = \sqrt{\frac{3}{5}}\frac{3x^3}{\sqrt{\frac{3}{5}\theta^2}^3}$$ Then I would have : $$L(\frac{3}{5}\theta^2) = (\sqrt{\frac{3}{5}}\frac{3}{\sqrt{\frac{3}{5}\theta^2}^3})^n\prod_{i=1}^{n}x_i^3 \implies $$ $$L(\sigma^2) = \Big(\sqrt{\frac{3}{5} }\frac{3}{\sigma^2}\Big)^n\prod_{i=1}^{n}x_i^3  $$ So then the answer would be just $\hat {\sigma^2} = \max\limits_{1 \leq i \leq n}{x_i}$ ?","We are given that are independent and with the same disturbution function for , where is an unknown positive variable. Using the maximum likelyhood method find : An MLE for An MLE for the variance of Xi's My answer to 1 is the well -known method : Now this has a well-known answer : My problem is question 2 : I haven't got the concept of MLE quite well . I computed . When we are trying to find an MLE for is it like we are trying to find an MLE for ? And if we already have an MLE for can't we just say that the MLE for is ? So I would answer something like : but I am not sure at all . Even if question 1) wasn't present , the only way I know to use this method is to -blindly - take the definition of maximum likelyhood function (which hopefully will be a function  of the parameter I want to estimate) . So I thought I could maybe write as a function of : Then I would have : So then the answer would be just ?","X_1, X_2,\dots, X_n f(x) = 3x^2 /\theta^3  0 \leq x \leq \theta \theta \theta L(\theta) = \prod_{i=1}^nf(X_i:\theta) \implies  
L(\theta) = (\frac{3}{\theta^3})^n\prod_{i=1}^{n}x_i^3
 \hat \theta = \max_{1\leq i\leq n}x_i \sigma^2 = Var(Xi) = \frac{3\theta^2}{5} Var(X_i) \theta^2 \theta \theta^2 \hat \theta^2 \hat Var(X_i) =\frac{3}{5}\hat \theta^2  L(\theta) = \prod_{i=1}^nf(X_i:\theta)  f(x)  3/5 \theta^2 f(x:\frac{3}{5}\theta^2) = \sqrt{\frac{3}{5}}\frac{3x^3}{\sqrt{\frac{3}{5}\theta^2}^3} L(\frac{3}{5}\theta^2) = (\sqrt{\frac{3}{5}}\frac{3}{\sqrt{\frac{3}{5}\theta^2}^3})^n\prod_{i=1}^{n}x_i^3 \implies  L(\sigma^2) = \Big(\sqrt{\frac{3}{5} }\frac{3}{\sigma^2}\Big)^n\prod_{i=1}^{n}x_i^3   \hat {\sigma^2} = \max\limits_{1 \leq i \leq n}{x_i}","['probability-theory', 'statistics', 'parameter-estimation', 'maximum-likelihood']"
49,What is the probability that this happen P(A)+P(B)−2P(A ∩B),What is the probability that this happen P(A)+P(B)−2P(A ∩B),,"I think that my question has a bad structured, but my question is in base the next. Let A and B be any sets. Show that the probability that exactly one of the events A or B occurs is: $$P(A)+P(B)−2P(A\cap B)$$ I thought that this is possible with The inclusion-exclusion principle, is it right or I need other thing?","I think that my question has a bad structured, but my question is in base the next. Let A and B be any sets. Show that the probability that exactly one of the events A or B occurs is: I thought that this is possible with The inclusion-exclusion principle, is it right or I need other thing?",P(A)+P(B)−2P(A\cap B),"['probability', 'probability-theory', 'statistics', 'inclusion-exclusion']"
50,What does this math notation mean? $\min_{i} \|x_{i}\|$ [closed],What does this math notation mean?  [closed],\min_{i} \|x_{i}\|,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question $\qquad\min_{i} \|x_{i}\|$ I'm doing some machine learning problems and I ran into this notation. I don't understand what "" min i "" means in this case. Is it the smallest element in the norm of $x$ ? Any help would be appreciated.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question I'm doing some machine learning problems and I ran into this notation. I don't understand what "" min i "" means in this case. Is it the smallest element in the norm of ? Any help would be appreciated.",\qquad\min_{i} \|x_{i}\| x,"['statistics', 'notation', 'machine-learning']"
51,Convergence almost surely of the sample mean,Convergence almost surely of the sample mean,,"In a probability textbook I have been working through, I came across the following exercise involving almost sure convergence for the sample mean of a given sequence of random variables and was unsure how to proceed with the problem. For an independent sequence of random variables, for each value of $i\geq 1$ , $\mathbb{P}(X_i=i^2-1)=i^{-2}$ and $\mathbb{P}(X_i=-1)=1-i^{-2}$ . The sequence of random variables $\displaystyle \frac{1}{n}\sum \limits _{i=1}^nX_i$ converges almost surely to a constant. Find this constant. The progress that I have made on the problem is that we know that $$\sum \limits _{i=1}^\infty \mathbb{P}(X_i\neq -1)=\sum \limits _{i=1}^\infty i^{-2}<\infty .$$ And so by the first Borel-Cantelli Lemma, the probability of this event occurring infinitely often is equal to $0$ . For almost sure convergence, we need to show that $$\mathbb{P}\left (\left \{\left |\overline X_n-\overline X\right |\geq \varepsilon \right \}_{\text{io}}\right )=0$$ (where $\text{io}$ refers to an event that occurs “infinitely often”) However, it is unclear to me how the progress I have made helps us in this particular instance and would be grateful for any additional guidance.","In a probability textbook I have been working through, I came across the following exercise involving almost sure convergence for the sample mean of a given sequence of random variables and was unsure how to proceed with the problem. For an independent sequence of random variables, for each value of , and . The sequence of random variables converges almost surely to a constant. Find this constant. The progress that I have made on the problem is that we know that And so by the first Borel-Cantelli Lemma, the probability of this event occurring infinitely often is equal to . For almost sure convergence, we need to show that (where refers to an event that occurs “infinitely often”) However, it is unclear to me how the progress I have made helps us in this particular instance and would be grateful for any additional guidance.",i\geq 1 \mathbb{P}(X_i=i^2-1)=i^{-2} \mathbb{P}(X_i=-1)=1-i^{-2} \displaystyle \frac{1}{n}\sum \limits _{i=1}^nX_i \sum \limits _{i=1}^\infty \mathbb{P}(X_i\neq -1)=\sum \limits _{i=1}^\infty i^{-2}<\infty . 0 \mathbb{P}\left (\left \{\left |\overline X_n-\overline X\right |\geq \varepsilon \right \}_{\text{io}}\right )=0 \text{io},"['probability', 'statistics', 'convergence-divergence', 'random-variables', 'almost-everywhere']"
52,Simplifying the double summation $\sum_{m=0}^{\infty}\sum_{n=0}^{\infty} \alpha \frac{2m+n}{m!n!} (p)^{m+n} =1$ to find alpha,Simplifying the double summation  to find alpha,\sum_{m=0}^{\infty}\sum_{n=0}^{\infty} \alpha \frac{2m+n}{m!n!} (p)^{m+n} =1,"Background In studying probability, I came across a question asking to find a constant of proportionality alpha that determines a discrete joint probability distribution. The exercise has a solution, however, there is little explanation provided which has made it quite hard to follow. I’ve detailed my progress and also what parts I am stuck with below. The Question Find the value of $\alpha > 0$ such that, for all $m,n \in \{0,1,2,3$ … $\}$ : $$P(X=m, Y=n) = \alpha \frac{2m+n}{m!n!} (p)^{m+n}$$ My Attempt It is clear that if we sum over all values of $m$ and $n$ , then this should be equal to $1$ by the properties of the joint density density function - i.e. $$\sum_{m=0}^{\infty}\sum_{n=0}^{\infty} \alpha \frac{2m+n}{m!n!} (p)^{m+n} =1$$ By splitting up the fraction, we see that this is equivalent to: $$\sum_{m=0}^{\infty}\sum_{n=0}^{\infty} \frac{2m}{m!n!} (p)^{m+n} + \frac{n}{m!n!} (p)^{m+n} =\frac{1}{\alpha}$$ However, I am unsure of how to proceed from here. The model solution says that this can be rewritten as: $$3\sum_{m=0}^{\infty}\sum_{n=0}^{\infty} \alpha \frac{1}{m!n!} (p)^{m+1+n} =1$$ It’s both parts of this line that are unclear to me. I don’t understand how the expression on the left hand side is arrived at. And I also don’t see how this simplifies to give us the required result to solve for alpha. I would be grateful for any help in understanding this.","Background In studying probability, I came across a question asking to find a constant of proportionality alpha that determines a discrete joint probability distribution. The exercise has a solution, however, there is little explanation provided which has made it quite hard to follow. I’ve detailed my progress and also what parts I am stuck with below. The Question Find the value of such that, for all … : My Attempt It is clear that if we sum over all values of and , then this should be equal to by the properties of the joint density density function - i.e. By splitting up the fraction, we see that this is equivalent to: However, I am unsure of how to proceed from here. The model solution says that this can be rewritten as: It’s both parts of this line that are unclear to me. I don’t understand how the expression on the left hand side is arrived at. And I also don’t see how this simplifies to give us the required result to solve for alpha. I would be grateful for any help in understanding this.","\alpha > 0 m,n \in \{0,1,2,3 \} P(X=m, Y=n) = \alpha \frac{2m+n}{m!n!} (p)^{m+n} m n 1 \sum_{m=0}^{\infty}\sum_{n=0}^{\infty} \alpha \frac{2m+n}{m!n!} (p)^{m+n} =1 \sum_{m=0}^{\infty}\sum_{n=0}^{\infty} \frac{2m}{m!n!} (p)^{m+n} + \frac{n}{m!n!} (p)^{m+n} =\frac{1}{\alpha} 3\sum_{m=0}^{\infty}\sum_{n=0}^{\infty} \alpha \frac{1}{m!n!} (p)^{m+1+n} =1","['probability', 'statistics', 'discrete-mathematics', 'probability-distributions', 'summation']"
53,How do you prove the mean is the best estimator?,How do you prove the mean is the best estimator?,,"sorry if this wastes your time but I am not a mathematician. I do like numbers though. After reading a problem where you were shown a set of X numbers, and asked how would you predict the next one, I learnt about the average. By plotting I realize that the average is a number that will always be between the max and the min but also that is the number whose differences to all the sample will by smallest possible (at least in the case of picking up a single number). I tried to write some math representing this but I have no real idea how to prove it. I imagine that this could be proved by contradiction: any other number gives rise to a larger difference. But I couldnt get anywhere. Would you give me some hints, or pointers as to what kind of ideas do you need to prove it?","sorry if this wastes your time but I am not a mathematician. I do like numbers though. After reading a problem where you were shown a set of X numbers, and asked how would you predict the next one, I learnt about the average. By plotting I realize that the average is a number that will always be between the max and the min but also that is the number whose differences to all the sample will by smallest possible (at least in the case of picking up a single number). I tried to write some math representing this but I have no real idea how to prove it. I imagine that this could be proved by contradiction: any other number gives rise to a larger difference. But I couldnt get anywhere. Would you give me some hints, or pointers as to what kind of ideas do you need to prove it?",,"['statistics', 'parameter-estimation', 'average', 'means']"
54,"How do a create a population given the mean, size and standard deviation?","How do a create a population given the mean, size and standard deviation?",,"How do I create a population (set of positive integers) given the size, mean and standard deviation? Like, if N = 7, mean is 50 and the standard deviation is 20, can I generate a population that fits that criteria?","How do I create a population (set of positive integers) given the size, mean and standard deviation? Like, if N = 7, mean is 50 and the standard deviation is 20, can I generate a population that fits that criteria?",,['statistics']
55,N-length string loop cut N times: piece length as N $\to \infty$?,N-length string loop cut N times: piece length as N ?,\to \infty,"Suppose I take a loop of string of length N units, and mark N points on it at independant and uniformly random (not necessarily integral) points along its length. (So for example suppose I have a 3 inch string:  I might make marks at 0.425 inches, 0.924 inches and 2.4155 inches clockwise from some arbitrary origin point on the loop.) Then lets say I cut the string loop at each of the N points.  I will be left with N pieces of string.  The average length of these pieces of string will be 1 unit (as their total length is N units, and there are N of them: $N/N = 1$ ). As N approaches infinity, what is the distribution of the length of these pieces of string? I think the answer is a probability density function with center of mass at 1, and total integral 1. What is this function?  Does it have a name?","Suppose I take a loop of string of length N units, and mark N points on it at independant and uniformly random (not necessarily integral) points along its length. (So for example suppose I have a 3 inch string:  I might make marks at 0.425 inches, 0.924 inches and 2.4155 inches clockwise from some arbitrary origin point on the loop.) Then lets say I cut the string loop at each of the N points.  I will be left with N pieces of string.  The average length of these pieces of string will be 1 unit (as their total length is N units, and there are N of them: ). As N approaches infinity, what is the distribution of the length of these pieces of string? I think the answer is a probability density function with center of mass at 1, and total integral 1. What is this function?  Does it have a name?",N/N = 1,"['calculus', 'probability', 'probability-theory', 'statistics', 'probability-distributions']"
56,Average of ratios compared to ratio of averages,Average of ratios compared to ratio of averages,,How to formalize (in simple terms) when average of ratios would be  greater than ratio of averages? I found that sometimes the former is greater than the latter and sometimes the latter is greater than the former. I want to understand in what cases one would be greater than the other. What happens at asymptotic? And what happens in day to day calculations? Which should I expect to be greater?,How to formalize (in simple terms) when average of ratios would be  greater than ratio of averages? I found that sometimes the former is greater than the latter and sometimes the latter is greater than the former. I want to understand in what cases one would be greater than the other. What happens at asymptotic? And what happens in day to day calculations? Which should I expect to be greater?,,"['statistics', 'intuition', 'average', 'ratio']"
57,A uniform bound of Hölder class-like densities.,A uniform bound of Hölder class-like densities.,,"Let $f(x)$ satisfies $f\geq 0$ and $\int_R f(x)dx = 1$ , suppose it also in the so-called H $\ddot o$ lder class, i.e. $\mid f(x)^{(l)}-f(y)^{(l)}\mid \leq L\mid x-y \mid^{\alpha}$ for all $x, y \in R$ , where $f(x)^{(l)}$ is the $l-$ order derivative of $f$ , $l$ is a positive integer, $0<\alpha<1$ and $L$ is a positive number. The question is to show that such class of $f$ is uniform bounded, i.e., $f(x)\leq M$ for all $x$ and all $f$ satisfies the conditions, where $M$ is a constant only depends on $l,\alpha, L$ . It seems like a mathematical analysis problem with a quite simple form. A proof or any references and directions are appreciated.","Let satisfies and , suppose it also in the so-called H lder class, i.e. for all , where is the order derivative of , is a positive integer, and is a positive number. The question is to show that such class of is uniform bounded, i.e., for all and all satisfies the conditions, where is a constant only depends on . It seems like a mathematical analysis problem with a quite simple form. A proof or any references and directions are appreciated.","f(x) f\geq 0 \int_R f(x)dx = 1 \ddot o \mid f(x)^{(l)}-f(y)^{(l)}\mid \leq L\mid x-y \mid^{\alpha} x, y \in R f(x)^{(l)} l- f l 0<\alpha<1 L f f(x)\leq M x f M l,\alpha, L","['real-analysis', 'probability-theory', 'analysis', 'statistics', 'density-function']"
58,Summability Condition for Linear Process,Summability Condition for Linear Process,,"I have been studying linear processes in time series of the following form: $X_t= \sum_{j=0}^{\infty}c_j\epsilon_{t-j}$ In this case, the following implication (about the covariance function) holds: $ \sum_{j=1}^{\infty} j|c_i| < \infty \Rightarrow \sum_{j=0}^{\infty} j|\gamma_i|   < \infty $ However, I have some trouble understanding the proof which runs us follows: $ \sum_{j=0}^{\infty} j^p|\gamma_i| \leq \sigma^2 \sum_{i=0}^{\infty} |c_i|\sum_{j=0}^{\infty} j^p|c_{i+j}| \leq  \sigma^2 \sum_{i=0}^{\infty} |c_i|\sum_{j=0}^{\infty} (i+j)^p |c_{i+j}| \leq \sigma^2 \sum_{i=0}^{\infty} |c_i|\sum_{j=0}^{\infty} j^p |c_{j}| < \infty$ I do not understand the following part (the last inequality): $ \sigma^2 \sum_{i=0}^{\infty} |c_i|\sum_{j=0}^{\infty} (i+j)^p |c_{i+j}| \leq \sigma^2 \sum_{i=0}^{\infty} |c_i|\sum_{j=0}^{\infty} j^p |c_{j}| < \infty$ Can anyone please help me out and explain why it holds?","I have been studying linear processes in time series of the following form: In this case, the following implication (about the covariance function) holds: However, I have some trouble understanding the proof which runs us follows: I do not understand the following part (the last inequality): Can anyone please help me out and explain why it holds?",X_t= \sum_{j=0}^{\infty}c_j\epsilon_{t-j}  \sum_{j=1}^{\infty} j|c_i| < \infty \Rightarrow \sum_{j=0}^{\infty} j|\gamma_i|   < \infty   \sum_{j=0}^{\infty} j^p|\gamma_i| \leq \sigma^2 \sum_{i=0}^{\infty} |c_i|\sum_{j=0}^{\infty} j^p|c_{i+j}| \leq  \sigma^2 \sum_{i=0}^{\infty} |c_i|\sum_{j=0}^{\infty} (i+j)^p |c_{i+j}| \leq \sigma^2 \sum_{i=0}^{\infty} |c_i|\sum_{j=0}^{\infty} j^p |c_{j}| < \infty  \sigma^2 \sum_{i=0}^{\infty} |c_i|\sum_{j=0}^{\infty} (i+j)^p |c_{i+j}| \leq \sigma^2 \sum_{i=0}^{\infty} |c_i|\sum_{j=0}^{\infty} j^p |c_{j}| < \infty,"['statistics', 'variance', 'time-series']"
59,Can reparameterization make Cramer-Rao bounds tight?,Can reparameterization make Cramer-Rao bounds tight?,,"Given a family of distributions parametrized by $\theta$ for which Cramer-Rao bounds on variance for a (biased or unbiased) estimator of $\theta$ exist, these bounds may be unattainable. In the proof for the 1D case, the looseness is introduced by applying the Cauchy-Schwarz inequality on the covariance between the score and the statistic. Is there a “onto” map $\phi\mapsto\theta$ for which CRLBs for $\phi$ are tight?","Given a family of distributions parametrized by for which Cramer-Rao bounds on variance for a (biased or unbiased) estimator of exist, these bounds may be unattainable. In the proof for the 1D case, the looseness is introduced by applying the Cauchy-Schwarz inequality on the covariance between the score and the statistic. Is there a “onto” map for which CRLBs for are tight?",\theta \theta \phi\mapsto\theta \phi,"['real-analysis', 'statistics', 'reference-request', 'change-of-variable', 'parameter-estimation']"
60,What does a.s.P. mean in this context?,What does a.s.P. mean in this context?,,"I am reading a statistics book, ""Sufficient Dimension Reduction"" by Bing Li. In Chapter 2, it says: We say that $\mathcal{G}_1$ and $\mathcal{G}_2$ are conditional independent given $\mathcal{G}_3$ , ...,if for every $A \in \mathcal{G}_1$ and $B \in \mathcal{G}_2$ , we have $P(A \cap B | \mathcal{G}_3)=P(A|\mathcal{G}_3) P(B | \mathcal{G}_3), a.s.P.$ What does a.s.P. mean in this context? I didn't find clues in previous texts, so I guess this should be a pretty common symbol.","I am reading a statistics book, ""Sufficient Dimension Reduction"" by Bing Li. In Chapter 2, it says: We say that and are conditional independent given , ...,if for every and , we have What does a.s.P. mean in this context? I didn't find clues in previous texts, so I guess this should be a pretty common symbol.","\mathcal{G}_1 \mathcal{G}_2 \mathcal{G}_3 A \in \mathcal{G}_1 B \in \mathcal{G}_2 P(A \cap B | \mathcal{G}_3)=P(A|\mathcal{G}_3) P(B | \mathcal{G}_3), a.s.P.","['probability-theory', 'measure-theory', 'statistics', 'terminology', 'independence']"
61,logic and application to a combinatorics question (Two chess players),logic and application to a combinatorics question (Two chess players),,"I have a logic question regarding the approach of a combinatorics problem: ""Two chess players, 𝐴 and 𝐵, are going to play 7 games. Each game has three possible outcomes: a win for 𝐴 (which is a loss for 𝐵), a draw (tie), and a loss for 𝐴 (which is a win for 𝐵). A win is worth 1 point, a draw is worth 0.5 points, and a loss is worth 0 points. Assume that they are playing a best-of-7 match, where the match will end when either player has 4 points or when 7 games have been played, whichever is first. For example, if after 6 games the score is 4 to 2 in favor of 𝐴, then 𝐴 wins the match and they don’t play a 7th game. How many possible outcomes for the individual games are there, such that the match lasts for 7 games and 𝐴 wins by a score of 4 to 3?"" This question has being asked and answered here original question Since the original answer is rather long, hence, I am using only part of the answer: Player $A$ wins 3 games, draws 1 game and loses 2 games gives $\binom{6}{3} \binom{3}{1} \binom{2}{2}$ ; for my question. The logic from the posted answer is that player $A$ plans out his game 3 wins, 1 draw, 2 loses and winning the last game, hence, $n$ is adjusted after a grouped outcome. However, in real life situation shouldn't it be $\binom{7}{1} \binom{6}{1} \cdots \binom{1}{1}$ where the outcome is adjusted after every game and player $A$ is only able to do $n-1$ ""choose"" 1 till the 7th game? For clarity $n$ is from $\binom{n}{k}$ , and my question is not about questioning the correctness of the answer from the original post but the approach and logic in live settings. Kindly advise Added info for clarity; Sorry for the lack of vocabulary, there are probably better words/phases than my choice of ""sequential choices"". I'll try to express it in my best effort. $\require{cancel}$ There are 7 games of which the players are to play in sequence, one game after another till the game ends at the 7th game. Therefore, shouldn't it be $\cancel {\binom{7}{1} \binom{6}{1}\binom{5}{1}\binom{4}{1}\binom{3}{1}\binom{2}{1}\binom{1}{1}}$ when the choices are not determined until the current game ends. The logic  from Joffan and user2661923 answers makes sense to me where the 7 games are played simultaneously. Added info after seeing @user2661923's Addendum : Thanks to user2661923's Addendum, I realized that my alternate view of updating after each game should be using win,lose, and tie(WLT) instead(my original intuition = ""strike-thru""). And is very tedious and risk over and under count.","I have a logic question regarding the approach of a combinatorics problem: ""Two chess players, 𝐴 and 𝐵, are going to play 7 games. Each game has three possible outcomes: a win for 𝐴 (which is a loss for 𝐵), a draw (tie), and a loss for 𝐴 (which is a win for 𝐵). A win is worth 1 point, a draw is worth 0.5 points, and a loss is worth 0 points. Assume that they are playing a best-of-7 match, where the match will end when either player has 4 points or when 7 games have been played, whichever is first. For example, if after 6 games the score is 4 to 2 in favor of 𝐴, then 𝐴 wins the match and they don’t play a 7th game. How many possible outcomes for the individual games are there, such that the match lasts for 7 games and 𝐴 wins by a score of 4 to 3?"" This question has being asked and answered here original question Since the original answer is rather long, hence, I am using only part of the answer: Player wins 3 games, draws 1 game and loses 2 games gives ; for my question. The logic from the posted answer is that player plans out his game 3 wins, 1 draw, 2 loses and winning the last game, hence, is adjusted after a grouped outcome. However, in real life situation shouldn't it be where the outcome is adjusted after every game and player is only able to do ""choose"" 1 till the 7th game? For clarity is from , and my question is not about questioning the correctness of the answer from the original post but the approach and logic in live settings. Kindly advise Added info for clarity; Sorry for the lack of vocabulary, there are probably better words/phases than my choice of ""sequential choices"". I'll try to express it in my best effort. There are 7 games of which the players are to play in sequence, one game after another till the game ends at the 7th game. Therefore, shouldn't it be when the choices are not determined until the current game ends. The logic  from Joffan and user2661923 answers makes sense to me where the 7 games are played simultaneously. Added info after seeing @user2661923's Addendum : Thanks to user2661923's Addendum, I realized that my alternate view of updating after each game should be using win,lose, and tie(WLT) instead(my original intuition = ""strike-thru""). And is very tedious and risk over and under count.",A \binom{6}{3} \binom{3}{1} \binom{2}{2} A n \binom{7}{1} \binom{6}{1} \cdots \binom{1}{1} A n-1 n \binom{n}{k} \require{cancel} \cancel {\binom{7}{1} \binom{6}{1}\binom{5}{1}\binom{4}{1}\binom{3}{1}\binom{2}{1}\binom{1}{1}},"['combinatorics', 'statistics', 'elementary-set-theory']"
62,"How to prove $Cov(E(X_1|X_2), X_1 - $ $E(X_1|X_2))$ $= 0$",How to prove,"Cov(E(X_1|X_2), X_1 -  E(X_1|X_2)) = 0","Question Determine whether or not the following result is True or False: $$Cov(E(X_1|X_2), X_1 - E(X_1|X_2)) = 0$$ Attempt I tried at first: $=E[((X_1|X_2)(X_1-E(X_1|X_2)) - E(X_1|X_2)E(X_1-E(X_1|X_2))]$ $E[(X_1(X_1|X_2) - (X_1|X_2)E(X_1|X_2)+E(X_1|X_2)^2-E(X_1|X_2)E(X_1)]$ $E(X_1)^2 - E(X_1|X_2)E(X_1) + E(E(X_1|X_2)^2) - E(X_1)^2$ $-E(X_1|X_2)E(X_1) + E(E(X_1|X_2)^2)$ From here I am lost. Further Comments I know $E(E(X_1|X_2)^2) = E(X_1)^2$ But what about $E(X_1|X_2)E(X_1)$ ? Is there way to simplify it?",Question Determine whether or not the following result is True or False: Attempt I tried at first: From here I am lost. Further Comments I know But what about ? Is there way to simplify it?,"Cov(E(X_1|X_2), X_1 - E(X_1|X_2)) = 0 =E[((X_1|X_2)(X_1-E(X_1|X_2)) - E(X_1|X_2)E(X_1-E(X_1|X_2))] E[(X_1(X_1|X_2) - (X_1|X_2)E(X_1|X_2)+E(X_1|X_2)^2-E(X_1|X_2)E(X_1)] E(X_1)^2 - E(X_1|X_2)E(X_1) + E(E(X_1|X_2)^2) - E(X_1)^2 -E(X_1|X_2)E(X_1) + E(E(X_1|X_2)^2) E(E(X_1|X_2)^2) = E(X_1)^2 E(X_1|X_2)E(X_1)","['probability', 'statistics', 'expected-value', 'covariance']"
63,Is nearest point to $\mu$ also nearest to all other points?,Is nearest point to  also nearest to all other points?,\mu,"Suppose a set of points $\mathcal{X} = \{ x_1, …, x_n\} \subset \mathbb{R}^p$ . Define $$\mu = \frac1n \sum_i x_i$$ We know that $\mu$ is the point which minimizes (over $\mathbb{R}^p$ ) the sum of squared distances between it and all other points in $\mathcal{X}$ . Is it true that the point in $\mathcal{X}$ that is closest to $\mu$ is also the point in $\mathcal{X}$ that is closest to all other points in $\mathcal{X}$ ? In other words what I am asking is whether the following equality holds: $$\arg\min_{x_i \in \mathcal{X}} \| \mu - x_i \|_2^2 = \arg\min_{x_j \in \mathcal{X}} \sum_i \| x_j - x_i \|_2^2$$ How can this be shown? I’m finding it difficult to write a proof due to the fact that $\mathcal{X}$ is a set of points (non-convex, disconnected, countable, etc) If yes, does this still hold when we use other $p$ -norms in place of $\ell_2$ to compute distance?","Suppose a set of points . Define We know that is the point which minimizes (over ) the sum of squared distances between it and all other points in . Is it true that the point in that is closest to is also the point in that is closest to all other points in ? In other words what I am asking is whether the following equality holds: How can this be shown? I’m finding it difficult to write a proof due to the fact that is a set of points (non-convex, disconnected, countable, etc) If yes, does this still hold when we use other -norms in place of to compute distance?","\mathcal{X} = \{ x_1, …, x_n\} \subset \mathbb{R}^p \mu = \frac1n \sum_i x_i \mu \mathbb{R}^p \mathcal{X} \mathcal{X} \mu \mathcal{X} \mathcal{X} \arg\min_{x_i \in \mathcal{X}} \| \mu - x_i \|_2^2 = \arg\min_{x_j \in \mathcal{X}} \sum_i \| x_j - x_i \|_2^2 \mathcal{X} p \ell_2","['real-analysis', 'analysis', 'statistics', 'optimization', 'algorithms']"
64,Gradient descent inside the expectation-maximization (EM) algorithm,Gradient descent inside the expectation-maximization (EM) algorithm,,"I am feeling super uncertain about how much I can play around with the EM algorithm. Here is my question: In the EM algorithm, during the M-step, one attempts to find a parameter value, $\theta$ , that maximizes $Q$ . Sometimes the function of $Q$ with respect to that parameter value is continuous, differentiable and concave, but does not have a closed form solution for the stationary points and requires some form of numerical techniques, like gradient descent or Newton-Raphson method, to find the stationary points. Am I correct to conclude that one does not break the convergences of the EM algorithm if you use these numerical methods to optimize $Q$ with respect to some parameter value $\theta$ . In fact, am I correct to conclude that one could use any optimization technique in the E step for all the parameters we wish to optimize for?","I am feeling super uncertain about how much I can play around with the EM algorithm. Here is my question: In the EM algorithm, during the M-step, one attempts to find a parameter value, , that maximizes . Sometimes the function of with respect to that parameter value is continuous, differentiable and concave, but does not have a closed form solution for the stationary points and requires some form of numerical techniques, like gradient descent or Newton-Raphson method, to find the stationary points. Am I correct to conclude that one does not break the convergences of the EM algorithm if you use these numerical methods to optimize with respect to some parameter value . In fact, am I correct to conclude that one could use any optimization technique in the E step for all the parameters we wish to optimize for?",\theta Q Q Q \theta,"['statistics', 'optimization', 'numerical-optimization', 'gradient-descent']"
65,Computation of maximum likelihood estimates,Computation of maximum likelihood estimates,,"Question Solve for the maximum likelihood estimates of the distribution with parameters $\alpha$ and $\beta$ and the following pdf , where $x > 0$ : $$f(x; \alpha, \beta) = \frac {\alpha} {\sqrt {2\pi \beta}} x^{-\frac 3 2} \exp\left[-\frac {(\alpha - \beta x)^2} {2\beta x}\right].$$ Hint: You should be able to write the parameter estimates in terms of $\overline{x}$ and $\overline{1/x}$ , where $\overline{1/x} = \frac 1 n \sum^n_{i = 1} \frac 1 {x_i}$ . My working $$\begin{aligned} l(\alpha, \beta) & = n\ln\frac {\alpha} {\sqrt{2\pi \beta}} - \frac 3 2 \sum^n_{i = 1} \ln x_i - \sum^n_{i = 1} \frac {(\alpha - \beta x_i)^2} {2\beta x_i}\\ & = n\ln \alpha - \frac 1 2 n \ln(2\pi) - \frac 1 2 n \ln \beta - \frac 3 2 \sum^n_{i = 1} \ln x_i - \sum^n_{i = 1} \frac {(\alpha - \beta x_i)^2} {2\beta x_i}\\ \implies \frac {\mathrm{d}l} {\mathrm{d}\alpha} & = \frac n {\alpha} - \sum^n_{i = 1} \frac {2(\alpha - \beta x_i)} {2\beta x_i}\\ & = n \left(\frac 1 {\alpha} + 1\right) - \sum^n_{i = 1} \frac {\alpha} {\beta x_i}\\ & = n \left(\frac 1 {\alpha} + 1\right) - \frac {n\alpha} {\beta} \overline{1/x}\\ & = n\left(\frac 1 {\alpha} + 1 - \frac {\alpha} {\beta} \overline{1/x}\right)\\ \frac {\mathrm{d}l} {\mathrm{d}\beta} & = -\frac n {2\beta} - \sum^n_{i = 1} \frac {2(\alpha - \beta x_i)(-x_i)(2\beta x_i) - (\alpha - \beta x_i)^2(2x_i)} {4\beta^2 x^2_i}\\ & = -\frac n {2\beta} + \sum^n_{i = 1} \frac {(\alpha - \beta x_i)(2\beta x_i) + (\alpha - \beta x_i)^2} {2\beta^2 x_i}\\ & = -\frac n {2\beta} + \sum^n_{i = 1} \frac {(\alpha - \beta x_i)(\alpha + \beta x_i)} {2\beta^2 x_i}\\ & = -\frac n {2\beta} + \sum^n_{i = 1} \frac {(\alpha^2 - \beta^2 x^2_i)} {2\beta^2 x_i}\\ & = -\frac n {2\beta} + \frac {n\alpha^2} {2\beta^2} \overline{1/x} - \frac n 2 \overline{x}\\ & = \frac n 2 \left(\frac {\alpha^2} {\beta^2} \overline{1/x} - \frac 1 {\beta} - \overline{x}\right) \end{aligned}$$ When $$\begin{aligned} \frac {\mathrm{d}l} {\mathrm{d}\alpha} & = 0,\\ \frac {\beta(\alpha + 1)} {\alpha^2} & = \overline{1/x}. \end{aligned}$$ When $$\begin{aligned} \frac {\mathrm{d}l} {\mathrm{d}\beta} & = 0,\\ \alpha^2 \overline{1/x} - \beta & = \beta^2 \overline{x}. \end{aligned}$$ Assuming my score equations are correct and I have not gone wrong anywhere, I am now stuck here. In particular, I am unable to see how I can further manipulate the two equations above to return just $\alpha$ and $\beta$ . Any intuitive explanations will be greatly appreciated :)","Question Solve for the maximum likelihood estimates of the distribution with parameters and and the following pdf , where : Hint: You should be able to write the parameter estimates in terms of and , where . My working When When Assuming my score equations are correct and I have not gone wrong anywhere, I am now stuck here. In particular, I am unable to see how I can further manipulate the two equations above to return just and . Any intuitive explanations will be greatly appreciated :)","\alpha \beta x > 0 f(x; \alpha, \beta) = \frac {\alpha} {\sqrt {2\pi \beta}} x^{-\frac 3 2} \exp\left[-\frac {(\alpha - \beta x)^2} {2\beta x}\right]. \overline{x} \overline{1/x} \overline{1/x} = \frac 1 n \sum^n_{i = 1} \frac 1 {x_i} \begin{aligned}
l(\alpha, \beta) & = n\ln\frac {\alpha} {\sqrt{2\pi \beta}} - \frac 3 2 \sum^n_{i = 1} \ln x_i - \sum^n_{i = 1} \frac {(\alpha - \beta x_i)^2} {2\beta x_i}\\
& = n\ln \alpha - \frac 1 2 n \ln(2\pi) - \frac 1 2 n \ln \beta - \frac 3 2 \sum^n_{i = 1} \ln x_i - \sum^n_{i = 1} \frac {(\alpha - \beta x_i)^2} {2\beta x_i}\\
\implies \frac {\mathrm{d}l} {\mathrm{d}\alpha} & = \frac n {\alpha} - \sum^n_{i = 1} \frac {2(\alpha - \beta x_i)} {2\beta x_i}\\
& = n \left(\frac 1 {\alpha} + 1\right) - \sum^n_{i = 1} \frac {\alpha} {\beta x_i}\\
& = n \left(\frac 1 {\alpha} + 1\right) - \frac {n\alpha} {\beta} \overline{1/x}\\
& = n\left(\frac 1 {\alpha} + 1 - \frac {\alpha} {\beta} \overline{1/x}\right)\\
\frac {\mathrm{d}l} {\mathrm{d}\beta} & = -\frac n {2\beta} - \sum^n_{i = 1} \frac {2(\alpha - \beta x_i)(-x_i)(2\beta x_i) - (\alpha - \beta x_i)^2(2x_i)} {4\beta^2 x^2_i}\\
& = -\frac n {2\beta} + \sum^n_{i = 1} \frac {(\alpha - \beta x_i)(2\beta x_i) + (\alpha - \beta x_i)^2} {2\beta^2 x_i}\\
& = -\frac n {2\beta} + \sum^n_{i = 1} \frac {(\alpha - \beta x_i)(\alpha + \beta x_i)} {2\beta^2 x_i}\\
& = -\frac n {2\beta} + \sum^n_{i = 1} \frac {(\alpha^2 - \beta^2 x^2_i)} {2\beta^2 x_i}\\
& = -\frac n {2\beta} + \frac {n\alpha^2} {2\beta^2} \overline{1/x} - \frac n 2 \overline{x}\\
& = \frac n 2 \left(\frac {\alpha^2} {\beta^2} \overline{1/x} - \frac 1 {\beta} - \overline{x}\right)
\end{aligned} \begin{aligned}
\frac {\mathrm{d}l} {\mathrm{d}\alpha} & = 0,\\
\frac {\beta(\alpha + 1)} {\alpha^2} & = \overline{1/x}.
\end{aligned} \begin{aligned}
\frac {\mathrm{d}l} {\mathrm{d}\beta} & = 0,\\
\alpha^2 \overline{1/x} - \beta & = \beta^2 \overline{x}.
\end{aligned} \alpha \beta","['statistics', 'optimization', 'partial-derivative', 'maximum-likelihood']"
66,Optimal strategy for getting the larger envelope of two envelopes,Optimal strategy for getting the larger envelope of two envelopes,,"I encountered a problem similar to the two envelope paradox: Two envelopes with amounts $x$ and $2x$ , where $x$ is uniformly distributed in $[0,100]$ . Randomly shuffle the two envelopes, and you pick one and observe the amount. You can choose to switch or stay. What is the optimal strategy to get the envelope with the larger amount? An intuitive strategy is to switch if the envelope has less than 100. But I am not sure how to show this strategy in fact maximizes the probability of getting the envelope with the larger amount. Here is what I tried: \begin{align*} P(\text{getting large envelop}) &= P(\text{getting large envelop } | \text{ observed <100})P(\text{ observed <100})\\  &+ P(\text{getting large envelop } | \text{ observed >100})P(\text{ observed >100})\\ &= P(\text{getting large envelop} | \text{ observed <100}) \cdot \frac{3}{4} + 1 \cdot \frac{1}{4} \\ \end{align*} but how can I show that the strategy maximizes $P(\text{getting large envelop} | \text{ observed <100})$ ? Thanks.","I encountered a problem similar to the two envelope paradox: Two envelopes with amounts and , where is uniformly distributed in . Randomly shuffle the two envelopes, and you pick one and observe the amount. You can choose to switch or stay. What is the optimal strategy to get the envelope with the larger amount? An intuitive strategy is to switch if the envelope has less than 100. But I am not sure how to show this strategy in fact maximizes the probability of getting the envelope with the larger amount. Here is what I tried: but how can I show that the strategy maximizes ? Thanks.","x 2x x [0,100] \begin{align*}
P(\text{getting large envelop}) &= P(\text{getting large envelop } | \text{ observed <100})P(\text{ observed <100})\\ 
&+ P(\text{getting large envelop } | \text{ observed >100})P(\text{ observed >100})\\
&= P(\text{getting large envelop} | \text{ observed <100}) \cdot \frac{3}{4} + 1 \cdot \frac{1}{4} \\
\end{align*} P(\text{getting large envelop} | \text{ observed <100})","['probability', 'statistics', 'game-theory']"
67,Intuition for the variables $x_i$ that minimise $\sum_i a_i x_i^2$ with constraint $\sum_i x_i = 1$,Intuition for the variables  that minimise  with constraint,x_i \sum_i a_i x_i^2 \sum_i x_i = 1,"Given $a_1, \dots, a_n \in \mathbb R_{\geq0}$ , we wish to choose $x_1, \dots, x_n \in \mathbb R_{\geq 0}$ that minimise $\sum_i a_ix_i^2$ with the constraint $\sum_i x_i = 1$ . This can be solved with Lagrange multipliers the tedious way. But it turns out that the optimal set of $x_i$ s satisfies $a_1x_1 = \dots = a_nx_n$ . Is there an intuitive justification (perhaps statistical or geometric) for why this holds? If so, the problem could be solved by simply observing that the minimum should satisfy $a_1x_1 = \dots = a_nx_n$ , from which the solution falls out trivially. (This problem arises when constructing a minimum variance fully-invested portfolio where all assets are uncorrelated, for example.)","Given , we wish to choose that minimise with the constraint . This can be solved with Lagrange multipliers the tedious way. But it turns out that the optimal set of s satisfies . Is there an intuitive justification (perhaps statistical or geometric) for why this holds? If so, the problem could be solved by simply observing that the minimum should satisfy , from which the solution falls out trivially. (This problem arises when constructing a minimum variance fully-invested portfolio where all assets are uncorrelated, for example.)","a_1, \dots, a_n \in \mathbb R_{\geq0} x_1, \dots, x_n \in \mathbb R_{\geq 0} \sum_i a_ix_i^2 \sum_i x_i = 1 x_i a_1x_1 = \dots = a_nx_n a_1x_1 = \dots = a_nx_n","['statistics', 'optimization', 'maxima-minima', 'lagrange-multiplier', 'finance']"
68,Intuition and Proof of Confidence Interval for Sample Variation,Intuition and Proof of Confidence Interval for Sample Variation,,"Let $X_1, ..., X_n$ be a random sample from a normal distribution with an unknown $\mu$ and unknown $\sigma$ . The sample mean of this sample is $\bar{X}$ . The following graph shows the density curve of the sampling distribution of the sample mean: The yellow shaded region represents where 95% of random sample means would fall and has an interval of $(\mu - L, \mu + L)$ . Since there is a 95% chance that any random sample mean would fall in that interval, we can also say with 95% confidence that a given sample mean would contain the population mean within its confidence interval (CI). Finding the CI then for a sample mean simply requires centering the interval around the sample mean: $$(\mu - L + (\bar{X} - \mu), \mu + L + (\bar{X} - \mu)) = (\bar{X} - L, \bar{X} + L)$$ where $L = t_{\alpha/2} * \frac{s}{\sqrt(n)}$ . Unfortunately, this approach seems to fall apart when I try to apply it to finding the confidence interval for the sample variance. The sample variance has a sampling distribution of $\chi^2$ with $n - 1$ degrees of freedom. We can convert a sample variance to its corresponding $\chi^2$ value with the following formula: $$\chi^2 = \frac{(n - 1)s^2}{\sigma^2}$$ Here is a plot of a chi-square distribution with $df = 4$ . It can represent the distribution of the ""chi-transformed"" sample variances. The red line is the mean of the distribution, the blue lines represent the $\chi^2$ values below which and above which lie 5% of the data. And the dotted green line represents the ""chi-transformed"" value of our theoretical sample variance. I can no longer apply my ""shift the interval"" strategy because the distribution is skewed and also cannot go below 0. How do I intuit (mathematically and visually) the 90% confidence interval of the sample variance?","Let be a random sample from a normal distribution with an unknown and unknown . The sample mean of this sample is . The following graph shows the density curve of the sampling distribution of the sample mean: The yellow shaded region represents where 95% of random sample means would fall and has an interval of . Since there is a 95% chance that any random sample mean would fall in that interval, we can also say with 95% confidence that a given sample mean would contain the population mean within its confidence interval (CI). Finding the CI then for a sample mean simply requires centering the interval around the sample mean: where . Unfortunately, this approach seems to fall apart when I try to apply it to finding the confidence interval for the sample variance. The sample variance has a sampling distribution of with degrees of freedom. We can convert a sample variance to its corresponding value with the following formula: Here is a plot of a chi-square distribution with . It can represent the distribution of the ""chi-transformed"" sample variances. The red line is the mean of the distribution, the blue lines represent the values below which and above which lie 5% of the data. And the dotted green line represents the ""chi-transformed"" value of our theoretical sample variance. I can no longer apply my ""shift the interval"" strategy because the distribution is skewed and also cannot go below 0. How do I intuit (mathematically and visually) the 90% confidence interval of the sample variance?","X_1, ..., X_n \mu \sigma \bar{X} (\mu - L, \mu + L) (\mu - L + (\bar{X} - \mu), \mu + L + (\bar{X} - \mu)) = (\bar{X} - L, \bar{X} + L) L = t_{\alpha/2} * \frac{s}{\sqrt(n)} \chi^2 n - 1 \chi^2 \chi^2 = \frac{(n - 1)s^2}{\sigma^2} df = 4 \chi^2","['probability', 'statistics', 'probability-distributions', 'variance', 'confidence-interval']"
69,Compute $Var[\frac{1}{n}\sum_{i=1}^n (X_i-E[X])^2]$,Compute,Var[\frac{1}{n}\sum_{i=1}^n (X_i-E[X])^2],"Let $X_1,\ldots, X_n$ be positive random variables in the range $[a, b]$ and $\sum_i^n X_i = 1$ . I want to compute \begin{eqnarray} Var[\frac{1}{n}\sum_{i=1}^n (X_i-E[X])^2]  &=& \frac{1}{n^2}Var[\sum_{i=1}^n (X_i-E[X])^2]\\ &=& \frac{1}{n^2}\sum_{i=1}^n Var[X_i^2] - 4Var[X_i E[X]] + Var[E[X]^2]\\ \end{eqnarray} Here I got stuck. Are there any approximations I can use to go further or to at least estimate an upper bound for the variance?",Let be positive random variables in the range and . I want to compute Here I got stuck. Are there any approximations I can use to go further or to at least estimate an upper bound for the variance?,"X_1,\ldots, X_n [a, b] \sum_i^n X_i = 1 \begin{eqnarray}
Var[\frac{1}{n}\sum_{i=1}^n (X_i-E[X])^2] 
&=& \frac{1}{n^2}Var[\sum_{i=1}^n (X_i-E[X])^2]\\
&=& \frac{1}{n^2}\sum_{i=1}^n Var[X_i^2] - 4Var[X_i E[X]] + Var[E[X]^2]\\
\end{eqnarray}","['probability', 'probability-theory', 'statistics', 'statistical-inference', 'descriptive-statistics']"
70,How is the t-distribution a statistic considering it is dependent on parameter mu?,How is the t-distribution a statistic considering it is dependent on parameter mu?,,"Casella and Berger textbook teaches that a statistic is only the function of a random sample and never its unknown population parameter(s). In the case of Student's t-distribution, while it utilizes the sample variance in place of the unknown variance population parameter, its distribution still relies on the mean mu population parameter. Shouldn't this disqualify Student's t-distribution as being a statistic? Thanks for any information","Casella and Berger textbook teaches that a statistic is only the function of a random sample and never its unknown population parameter(s). In the case of Student's t-distribution, while it utilizes the sample variance in place of the unknown variance population parameter, its distribution still relies on the mean mu population parameter. Shouldn't this disqualify Student's t-distribution as being a statistic? Thanks for any information",,"['probability', 'probability-theory', 'statistics', 'normal-distribution', 'statistical-inference']"
71,Meaning of $\frac{P(X\cap Y)}{P(X)P(Y)}$,Meaning of,\frac{P(X\cap Y)}{P(X)P(Y)},"Imagine that we have a set $\Omega$ and $X$ and $Y$ are events that can happen, I mean, $P(X),P(Y)>0$ . Then, what does it mean the ratio $\frac{P(X\cap Y)}{P(X)P(Y)}$ ? I know that $\frac{P(X\cap Y)}{P(X)P(Y)}=\frac{P(X|Y)}{P(X)}=\frac{P(Y|X)}{P(Y)}$ and if that ratio is equal to 1 then $X,Y$ are independent events, but I can't figure out what exactly it means... please give simple examples. I found this when reading about lift-data mining.","Imagine that we have a set and and are events that can happen, I mean, . Then, what does it mean the ratio ? I know that and if that ratio is equal to 1 then are independent events, but I can't figure out what exactly it means... please give simple examples. I found this when reading about lift-data mining.","\Omega X Y P(X),P(Y)>0 \frac{P(X\cap Y)}{P(X)P(Y)} \frac{P(X\cap Y)}{P(X)P(Y)}=\frac{P(X|Y)}{P(X)}=\frac{P(Y|X)}{P(Y)} X,Y","['probability', 'statistics']"
72,What is the correct standard deviation when splitting a sample?,What is the correct standard deviation when splitting a sample?,,"I roll a four-faced die 1000 times, but I have 100 dies, so I seperate into 10 rolls of 100 each and tally the result. I want to calculate the standard deviation of the 0 count. As an example, here's a result: {0: 251, 1: 254, 2: 271, 3: 224} , $\mu = \frac{251}{1000} = 0.251$ {0: 30, 1: 24, 2: 26, 3: 20} {0: 25, 1: 25, 2: 26, 3: 24} {0: 22, 1: 22, 2: 27, 3: 29} {0: 23, 1: 26, 2: 30, 3: 21} {0: 24, 1: 20, 2: 30, 3: 26} {0: 26, 1: 31, 2: 26, 3: 17} {0: 22, 1: 23, 2: 32, 3: 23} {0: 23, 1: 32, 2: 23, 3: 22} {0: 27, 1: 28, 2: 22, 3: 23} {0: 29, 1: 23, 2: 29, 3: 19} The first way I do it is by using the normal approximation: $$\sigma_1 = \sqrt{\frac{0.251*(1-0.251)}{1000}} = 0.0137$$ . The second way is to calculate the deviation of the 10 rolls, which gives: $$\sigma_2 = \sqrt{\frac{(0.3-0.251)^2+(0.25-0.251)^2+\cdots+(0.29-0.251)^2}{10}}=0.027$$ I tried changing and increasing both the total size and the size of the tally, but the results never approach each other. I think they are both consequences of the central limit theorem, and the discrepancy is due to sampling technique? Which is more correct, or are they both wrong? What's the right way to find $\sigma$ of 0 , or 1 , etc.? Thank you! Here's the Python code I used to generate the problem: import numpy as np import collections  small = 100 big = 1000  die = np.random.randint(0,4,big) diedict = collections.Counter(die) print(dict(sorted(diedict.items()))) #the total tally std1 = np.sqrt(diedict[0]/big*(1-diedict[0]/big)/big)  sumsquare=0 for i in range(0,big,small):     print(dict(sorted(collections.Counter(die[i:i+small]).items()))) #the seperate rolls     sumsquare += (collections.Counter(die[i:i+small])[0]/small-diedict[0]/big)**2  std2 = np.sqrt(sumsquare/(big/small)) print(std1,std2)  plot_histogram(diedict)","I roll a four-faced die 1000 times, but I have 100 dies, so I seperate into 10 rolls of 100 each and tally the result. I want to calculate the standard deviation of the 0 count. As an example, here's a result: {0: 251, 1: 254, 2: 271, 3: 224} , {0: 30, 1: 24, 2: 26, 3: 20} {0: 25, 1: 25, 2: 26, 3: 24} {0: 22, 1: 22, 2: 27, 3: 29} {0: 23, 1: 26, 2: 30, 3: 21} {0: 24, 1: 20, 2: 30, 3: 26} {0: 26, 1: 31, 2: 26, 3: 17} {0: 22, 1: 23, 2: 32, 3: 23} {0: 23, 1: 32, 2: 23, 3: 22} {0: 27, 1: 28, 2: 22, 3: 23} {0: 29, 1: 23, 2: 29, 3: 19} The first way I do it is by using the normal approximation: . The second way is to calculate the deviation of the 10 rolls, which gives: I tried changing and increasing both the total size and the size of the tally, but the results never approach each other. I think they are both consequences of the central limit theorem, and the discrepancy is due to sampling technique? Which is more correct, or are they both wrong? What's the right way to find of 0 , or 1 , etc.? Thank you! Here's the Python code I used to generate the problem: import numpy as np import collections  small = 100 big = 1000  die = np.random.randint(0,4,big) diedict = collections.Counter(die) print(dict(sorted(diedict.items()))) #the total tally std1 = np.sqrt(diedict[0]/big*(1-diedict[0]/big)/big)  sumsquare=0 for i in range(0,big,small):     print(dict(sorted(collections.Counter(die[i:i+small]).items()))) #the seperate rolls     sumsquare += (collections.Counter(die[i:i+small])[0]/small-diedict[0]/big)**2  std2 = np.sqrt(sumsquare/(big/small)) print(std1,std2)  plot_histogram(diedict)",\mu = \frac{251}{1000} = 0.251 \sigma_1 = \sqrt{\frac{0.251*(1-0.251)}{1000}} = 0.0137 \sigma_2 = \sqrt{\frac{(0.3-0.251)^2+(0.25-0.251)^2+\cdots+(0.29-0.251)^2}{10}}=0.027 \sigma,"['probability', 'statistics', 'central-limit-theorem', 'sampling']"
73,Finding the covariance matrix of $Y=AX$ where $X$ is a known multivariate gaussian random variable,Finding the covariance matrix of  where  is a known multivariate gaussian random variable,Y=AX X,"For $X=(X_1,X_2,X_3)$ with Gaussian distribution, covariance matrix $2I_3$ ( $2$ multiplied by the identity matrix), and mean vector $\mu$ = $(3,3,3)^T$ , I want to find the covariance matrix of $Y=(Y_1,Y_2,Y_3)^T$ where $$Y=\begin{pmatrix}1/\sqrt 2 & 0 & -1/\sqrt 2 \\1/\sqrt 3 & 1/\sqrt 3 & 1/\sqrt 3\\ 1/\sqrt 6 & -2/\sqrt 6 & 1/\sqrt 6\\ \end{pmatrix}X$$ I know that when I use the definition of the covariance matrix in terms of expectations, my answer is $2I$ (which is the correct answer). However when I substitute in $Y=AX=A(2Z+\mu)=2AZ+A\mu$ , the covariance matrix of Y is $(2A)(2A)^T$ which simplifies to $4I_3$ . However, this contradicts the correct answer $2I_3$ . I hope someone could clarify this for me.","For with Gaussian distribution, covariance matrix ( multiplied by the identity matrix), and mean vector = , I want to find the covariance matrix of where I know that when I use the definition of the covariance matrix in terms of expectations, my answer is (which is the correct answer). However when I substitute in , the covariance matrix of Y is which simplifies to . However, this contradicts the correct answer . I hope someone could clarify this for me.","X=(X_1,X_2,X_3) 2I_3 2 \mu (3,3,3)^T Y=(Y_1,Y_2,Y_3)^T Y=\begin{pmatrix}1/\sqrt 2 & 0 & -1/\sqrt 2 \\1/\sqrt 3 & 1/\sqrt 3 & 1/\sqrt 3\\ 1/\sqrt 6 & -2/\sqrt 6 & 1/\sqrt 6\\
\end{pmatrix}X 2I Y=AX=A(2Z+\mu)=2AZ+A\mu (2A)(2A)^T 4I_3 2I_3","['probability', 'statistics', 'normal-distribution', 'covariance', 'multivariate-statistical-analysis']"
74,Is the unbiased test always uniformly most powerful? [closed],Is the unbiased test always uniformly most powerful? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I know that the uniformly most powerful test is always unbiased, if it exists, but is the unbiased test always UMP?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I know that the uniformly most powerful test is always unbiased, if it exists, but is the unbiased test always UMP?",,"['probability', 'statistics', 'hypothesis-testing']"
75,Simulating Coin Flips vs Probability of Coin Flips,Simulating Coin Flips vs Probability of Coin Flips,,"Is there a standard formula for calculating the maximum, minimum and average number of times you need to flip a coin before observing a desired sequence? Suppose you have a coin that has a 95% chance of landing on HEADS and a 5% chance of landing on TAILS. Suppose you are interested in knowing the maximum, minimum and average number of times you need to flip a coin before observing HEADS, TAILS, HEADS. It is straightforward to find out the probability of this sequence : P(H,T,H) = 0.95 * 0.05 * 0.95 = 0.045. But for some reason, I don't think that this means that :if you were to consider 3 flips as a ""run"" - in 100 ""runs"", on average 4.5 of these runs would result in HEADS, TAILS, HEADS My question: Is there an exact formula that can answer these kinds of questions? The maximum number of ""runs"" before observing HEADS, TAILS, HEADS The minimum number of ""runs"" before observing HEADS, TAILS, HEADS The average number of ""runs"" before observing HEADS, TAILS, HEADS Or can such a question only be solved using simulation methods? (e.g. program a computer to simulate many such ""runs"" and answer the above questions through simulation) Thanks!","Is there a standard formula for calculating the maximum, minimum and average number of times you need to flip a coin before observing a desired sequence? Suppose you have a coin that has a 95% chance of landing on HEADS and a 5% chance of landing on TAILS. Suppose you are interested in knowing the maximum, minimum and average number of times you need to flip a coin before observing HEADS, TAILS, HEADS. It is straightforward to find out the probability of this sequence : P(H,T,H) = 0.95 * 0.05 * 0.95 = 0.045. But for some reason, I don't think that this means that :if you were to consider 3 flips as a ""run"" - in 100 ""runs"", on average 4.5 of these runs would result in HEADS, TAILS, HEADS My question: Is there an exact formula that can answer these kinds of questions? The maximum number of ""runs"" before observing HEADS, TAILS, HEADS The minimum number of ""runs"" before observing HEADS, TAILS, HEADS The average number of ""runs"" before observing HEADS, TAILS, HEADS Or can such a question only be solved using simulation methods? (e.g. program a computer to simulate many such ""runs"" and answer the above questions through simulation) Thanks!",,"['probability', 'statistics', 'simulation']"
76,Derivation involving taking moment of Navier Stokes equation,Derivation involving taking moment of Navier Stokes equation,,"The article under concern is: Germano, M. (1992). Turbulence: The filtering approach. Journal of Fluid Mechanics, 238, 325-336. doi:10.1017/S0022112092001733 On page 328, Germano considers the Navier-Stokes equation (equation 17) written in Einstein notation: $u_{i, t}+\left(u_{i} u_{k}\right)_{, k}=-p_{, i}+\sigma_{i k, k}$ and states that 'by taking a moment of (17) with $u_j$ and adding this to another moment of the same equation but with the indices interchanged', the following equation can be achieved: $\left(u_{i} u_{j}\right)_{, t}+\left(u_{i} u_{j} u_{k}\right)_{, k}=-\left[p u_{i} \delta_{j k}+p u_{j} \delta_{i k}-\nu\left(u_{i} u_{j}\right)_{, k}\right]_{,k}+2 p s_{i j}-2 v u_{i, k} u_{j, k}$ where $\sigma_{i j}=2 \nu s_{i j} ; \quad s_{i j}=\frac{1}{2}\left(u_{i, j}+u_{j, i}\right)$ . The derivation is made with the following commuting properties of the moment operator: $\left( f_{, t}\right)=(f)_{, t} ; \quad\left( f_{, k}\right)=( f)_{, k}$ After hours of attempts, I got nowhere near the final derivation. One of the significant issues I am facing is how $p$ , without the derivative (so $p_{,i}$ ), is achieved as well as where the $\delta_{jk}$ and $\delta_{ik}$ come from. Also, regarding the 'indices interchanged' part, is the author referring to equation (17) itself or after taking the moment of it with $u_j$ ? I would really appreciate if someone could shed some light on how I should go about deriving this.","The article under concern is: Germano, M. (1992). Turbulence: The filtering approach. Journal of Fluid Mechanics, 238, 325-336. doi:10.1017/S0022112092001733 On page 328, Germano considers the Navier-Stokes equation (equation 17) written in Einstein notation: and states that 'by taking a moment of (17) with and adding this to another moment of the same equation but with the indices interchanged', the following equation can be achieved: where . The derivation is made with the following commuting properties of the moment operator: After hours of attempts, I got nowhere near the final derivation. One of the significant issues I am facing is how , without the derivative (so ), is achieved as well as where the and come from. Also, regarding the 'indices interchanged' part, is the author referring to equation (17) itself or after taking the moment of it with ? I would really appreciate if someone could shed some light on how I should go about deriving this.","u_{i, t}+\left(u_{i} u_{k}\right)_{, k}=-p_{, i}+\sigma_{i k, k} u_j \left(u_{i} u_{j}\right)_{, t}+\left(u_{i} u_{j} u_{k}\right)_{, k}=-\left[p u_{i} \delta_{j k}+p u_{j} \delta_{i k}-\nu\left(u_{i} u_{j}\right)_{, k}\right]_{,k}+2 p s_{i j}-2 v u_{i, k} u_{j, k} \sigma_{i j}=2 \nu s_{i j} ; \quad s_{i j}=\frac{1}{2}\left(u_{i, j}+u_{j, i}\right) \left( f_{, t}\right)=(f)_{, t} ; \quad\left( f_{, k}\right)=( f)_{, k} p p_{,i} \delta_{jk} \delta_{ik} u_j","['statistics', 'partial-differential-equations', 'fluid-dynamics']"
77,"If $Y=\min\{ X_{1},X_{2} \}$ and $X_{i} \sim N(0,1)$ then $Y^{2} \sim \chi ^{2}_{(1)}$",If  and  then,"Y=\min\{ X_{1},X_{2} \} X_{i} \sim N(0,1) Y^{2} \sim \chi ^{2}_{(1)}","If $Y=\min\{ X_{1},X_{2} \}$ and $X_{i} \sim N(0,1)$ then $Y^{2} \sim \chi ^{2}_{(1)}$ If $X \sim  N(0,1) \implies X^{2} \sim \chi ^{2}_{1}$ What about the square? If we suppose that $X_{1} < X_{2}$ we have the previous proposition and is the same for $X_{2} < X_{1}$ .",If and then If What about the square? If we suppose that we have the previous proposition and is the same for .,"Y=\min\{ X_{1},X_{2} \} X_{i} \sim N(0,1) Y^{2} \sim \chi ^{2}_{(1)} X \sim  N(0,1) \implies X^{2} \sim \chi ^{2}_{1} X_{1} < X_{2} X_{2} < X_{1}","['probability', 'statistics', 'probability-distributions', 'normal-distribution']"
78,Identifying null and alternative hypothesis,Identifying null and alternative hypothesis,,"I need help with an exercise. It says: The president of a university claims that the mean time spent partying by all students at this university is not more than 7 hours per week. A random sample of 40 students taken from this university showed that they spent an average of 9.50 hours partying the previous week with a standard deviation of 2.3 hours. Test at the 2.5% significance level whether the president’s claim is true. I understand that the null hypothesis is basically what the researcher is claiming. So here I'm stating the null and the alternative hypothesis as: $H_0: \mu=7$ $H_1:\mu\leq7$ I checked the solution for this exercise online and I'm getting: I have a Statistics book that always states the null hypothesis as $\mu$ equals a value and the alternative hypothesis, depending on the claim, as $\mu$ less, greater or different that value. So I'm now confused because in the solution I found they put the in the null hypothesis the claim rather than in the alternative and then in the alternative that $\mu>7$ when that's is not the claim. I know what I have to do after that, but I'm stuck with that because if it is a lower tail then I do not reject the null hypothesis but if it is a right tail I do reject the null hypothesis, so the conclusion would be different.","I need help with an exercise. It says: The president of a university claims that the mean time spent partying by all students at this university is not more than 7 hours per week. A random sample of 40 students taken from this university showed that they spent an average of 9.50 hours partying the previous week with a standard deviation of 2.3 hours. Test at the 2.5% significance level whether the president’s claim is true. I understand that the null hypothesis is basically what the researcher is claiming. So here I'm stating the null and the alternative hypothesis as: I checked the solution for this exercise online and I'm getting: I have a Statistics book that always states the null hypothesis as equals a value and the alternative hypothesis, depending on the claim, as less, greater or different that value. So I'm now confused because in the solution I found they put the in the null hypothesis the claim rather than in the alternative and then in the alternative that when that's is not the claim. I know what I have to do after that, but I'm stuck with that because if it is a lower tail then I do not reject the null hypothesis but if it is a right tail I do reject the null hypothesis, so the conclusion would be different.",H_0: \mu=7 H_1:\mu\leq7 \mu \mu \mu>7,"['statistics', 'statistical-inference', 'hypothesis-testing']"
79,Conditioned Normal Distributions and joint PDF's,Conditioned Normal Distributions and joint PDF's,,"Let X, Y, Z be r.v.s such that X ⇠ N (0, 1) and conditional on X = x, Y and Z are i.i.d. N (x, 1). (a) Find the joint PDF of X, Y, Z. (b) Find the joint PDF of Y and Z. You can leave your answer as an integral, though the integral can be done with some algebra (such as completing the square) and facts about the Normal distribution. Is my reasoning correct? I did the following: a) $f(X=x,Y=y,Z=z)=f(X=x)f(Y=y|X=x)f(Z=z|X=x,Y=y)=f(X=x)f(Y=y|X=x)f(Z=z|X=x)=$ $$\frac{1}{2\sqrt \pi} e^{-x^2/2} \,  \frac{1}{2\sqrt \pi} e^{-(y-x)^2/2} \,   \frac{1}{2\sqrt \pi} e^{-(z-x)^2/2} \,$$ b) $$f(Y,Z)=\int_{-\infty}^{\infty}( \frac{1}{2\sqrt \pi} e^{-x^2/2} \,   \frac{1}{2\sqrt \pi} e^{-(y-x)^2/2} \,  \frac{1}{2\sqrt \pi} e^{-(z-x)^2/2} \, dx)$$","Let X, Y, Z be r.v.s such that X ⇠ N (0, 1) and conditional on X = x, Y and Z are i.i.d. N (x, 1). (a) Find the joint PDF of X, Y, Z. (b) Find the joint PDF of Y and Z. You can leave your answer as an integral, though the integral can be done with some algebra (such as completing the square) and facts about the Normal distribution. Is my reasoning correct? I did the following: a) b)","f(X=x,Y=y,Z=z)=f(X=x)f(Y=y|X=x)f(Z=z|X=x,Y=y)=f(X=x)f(Y=y|X=x)f(Z=z|X=x)= \frac{1}{2\sqrt \pi} e^{-x^2/2} \,  \frac{1}{2\sqrt \pi} e^{-(y-x)^2/2} \,   \frac{1}{2\sqrt \pi} e^{-(z-x)^2/2} \, f(Y,Z)=\int_{-\infty}^{\infty}( \frac{1}{2\sqrt \pi} e^{-x^2/2} \,   \frac{1}{2\sqrt \pi} e^{-(y-x)^2/2} \,  \frac{1}{2\sqrt \pi} e^{-(z-x)^2/2} \, dx)","['probability', 'statistics', 'conditional-probability', 'density-function']"
80,Inequality related to standard normal distribution function,Inequality related to standard normal distribution function,,"I want to show that $$ 2\Phi(x)^2 - \Phi(2x) \geq 0 $$ for all $x<0$ , where $\Phi$ is a cumulative distribution function of $N(0,1)$ . I am pretty sure that this holds since I've checked it with numerous $x$ 's, but I am struggling to prove it. I tried differentiating it, but it seems not working at least within my abilities. Could somebody help me with it? Thank you.","I want to show that for all , where is a cumulative distribution function of . I am pretty sure that this holds since I've checked it with numerous 's, but I am struggling to prove it. I tried differentiating it, but it seems not working at least within my abilities. Could somebody help me with it? Thank you.","
2\Phi(x)^2 - \Phi(2x) \geq 0
 x<0 \Phi N(0,1) x","['statistics', 'inequality', 'probability-distributions', 'normal-distribution', 'cumulative-distribution-functions']"
81,Prove $\frac{S_{n}}{n} \overset{p}{\rightarrow} p$ where $S_n$ is a binomial random variable.,Prove  where  is a binomial random variable.,\frac{S_{n}}{n} \overset{p}{\rightarrow} p S_n,"I want to prove that $\frac{1}{n}S_{n} \overset{p}{\longrightarrow} p\:$ as $\:n \longrightarrow \infty$ from first principles, where $S_{n}$ denotes the number of successes in $n$ binomial trials with success probability $p$ . From the definition of convergence in probability. A random sequence $Y_{n}$ converges in probability to $c$ if: $$P(|Y_{n} - c| < \epsilon) \longrightarrow 1\text{ as } n \longrightarrow \infty$$ For every $\epsilon > 0$ . We can do the following: $$\begin{align}P\left(\left|\frac{S_{n}}{n} - p\right| < \epsilon\right) &= P\left(\frac{S_{n}}{n} - p < \epsilon\right) - P\left(\frac{S_{n}}{n} - p < -\epsilon\right) \\&= P(S_{n} < n(p + \epsilon)) - P(S_{n} < n(p - \epsilon))\end{align}$$ I assume that the result follows the binomial cdf. But im not sure how to proceed.","I want to prove that as from first principles, where denotes the number of successes in binomial trials with success probability . From the definition of convergence in probability. A random sequence converges in probability to if: For every . We can do the following: I assume that the result follows the binomial cdf. But im not sure how to proceed.",\frac{1}{n}S_{n} \overset{p}{\longrightarrow} p\: \:n \longrightarrow \infty S_{n} n p Y_{n} c P(|Y_{n} - c| < \epsilon) \longrightarrow 1\text{ as } n \longrightarrow \infty \epsilon > 0 \begin{align}P\left(\left|\frac{S_{n}}{n} - p\right| < \epsilon\right) &= P\left(\frac{S_{n}}{n} - p < \epsilon\right) - P\left(\frac{S_{n}}{n} - p < -\epsilon\right) \\&= P(S_{n} < n(p + \epsilon)) - P(S_{n} < n(p - \epsilon))\end{align},"['probability-theory', 'statistics', 'convergence-divergence', 'binomial-distribution']"
82,Urn with $4$ Different Colored Balls that is Drawn $4$ Times with Replacement,Urn with  Different Colored Balls that is Drawn  Times with Replacement,4 4,"There is an urn that contains $1$ Green ball, $1$ Red ball, $1$ White ball, and $1$ Yellow ball. The urn is drawn 4 times with replacement. So I am trying to calculate: the probability of the the 4 draws yielding exactly 2 pairs of colors (e.g. GGRR) and the probability of the 4 draws yielding 1 single pair of color and 2 single / different colors (e.g. GGRW) For the 2 pairs, my thinking is such that ${4\choose2}$ represents the numbers of ways a paired color combo can be drawn / arranged ${4\choose1}$ is for the 1st color of the paired color combo ${3\choose1}$ is for the 2nd color of the paired color combo ${16\choose4}$ is for the total number of possible slots (_ _ _ _, each _ being a possible of 4 colors) $$\frac{{4\choose2}{4\choose1}{3\choose1}}{16\choose4}$$ I am not sure if this is right, but I think I am at least somewhat on the right track For the 1 pair + 2 singles, in all honesty, I am bit lost about how to begin. I am not sure whether I should use the nCk formula or go by counting and then adjust for slot placement. Thank you in advance","There is an urn that contains Green ball, Red ball, White ball, and Yellow ball. The urn is drawn 4 times with replacement. So I am trying to calculate: the probability of the the 4 draws yielding exactly 2 pairs of colors (e.g. GGRR) and the probability of the 4 draws yielding 1 single pair of color and 2 single / different colors (e.g. GGRW) For the 2 pairs, my thinking is such that represents the numbers of ways a paired color combo can be drawn / arranged is for the 1st color of the paired color combo is for the 2nd color of the paired color combo is for the total number of possible slots (_ _ _ _, each _ being a possible of 4 colors) I am not sure if this is right, but I think I am at least somewhat on the right track For the 1 pair + 2 singles, in all honesty, I am bit lost about how to begin. I am not sure whether I should use the nCk formula or go by counting and then adjust for slot placement. Thank you in advance",1 1 1 1 {4\choose2} {4\choose1} {3\choose1} {16\choose4} \frac{{4\choose2}{4\choose1}{3\choose1}}{16\choose4},"['probability', 'combinatorics', 'statistics']"
83,Compute or approximate the mode of a normal distribution with skew parameter $\lambda$. How about for Ashour 2010's approximation?,Compute or approximate the mode of a normal distribution with skew parameter . How about for Ashour 2010's approximation?,\lambda,"I'd like to compute the mode for a normal distribution with skew parameter λ . I assume I can just differentiate, but is there a shortcut or approximation? I'd like to learn how to do this generally, for my own statistical knowledge. But, more pressingly, I'm a developer and I'm writing a program that uses the approximation in Ashour and Abdul-hameed (2010) of a skewed normal. I need to at least approximate the mode for the distribution therein. How could I compute or approximate the mode for an Ashour 2010's approximation?","I'd like to compute the mode for a normal distribution with skew parameter λ . I assume I can just differentiate, but is there a shortcut or approximation? I'd like to learn how to do this generally, for my own statistical knowledge. But, more pressingly, I'm a developer and I'm writing a program that uses the approximation in Ashour and Abdul-hameed (2010) of a skewed normal. I need to at least approximate the mode for the distribution therein. How could I compute or approximate the mode for an Ashour 2010's approximation?",,"['statistics', 'normal-distribution']"
84,Two types of averages for ratios of two things,Two types of averages for ratios of two things,,"It was brought to my attention in this video that, where you have some attribute of your data that is the ratio of two other attributes, there are two ways of generating the mean ""average"" of this ratio. Taking the example from the beginning of the video, suppose that $x_i$ is the total sales (in \$) for a given line item, and $k_i$ is the quantity sold: Item ID Sales Qty sold Accessory #1 $x_1$ $k_1$ Accessory #2 $x_2$ $k_2$ Accessory #3 $x_3$ $k_3$ For each individual line item, you might define ""Sales per unit"" as $u_i=\frac{x_i}{k_i}$ . However, as the video points out, there are two ways one might then define the average Sales per unit for an Accessory. Using the video's terminology: $$\text{AGG}=\frac{x_1+x_2+x_3}{k_1+k_2+k_3}$$ $$\text{AVG}=\frac{1}{3}\left(\frac{x_1}{k_1}+\frac{x_2}{k_2}+\frac{x_3}{k_3}\right)$$ So $\text{AVG}$ is just $\bar{u}$ , whereas $\text{AGG}$ creates a composite Accessory item $\left(X, K\right)$ , whose sales and quantity are the sum of the individual line items', and calculates $U=\frac{X}{K}$ for that composite item. Plugging in example numbers for the $x_i$ and $k_i$ suggests that $\text{AGG}$ and $\text{AVG}$ do not in general give the same value. My question is: what are the qualitative differences in what $\text{AGG}$ and $\text{AVG}$ are doing? Which provides the better view of what average sales per unit for an Accessory are?","It was brought to my attention in this video that, where you have some attribute of your data that is the ratio of two other attributes, there are two ways of generating the mean ""average"" of this ratio. Taking the example from the beginning of the video, suppose that is the total sales (in \$) for a given line item, and is the quantity sold: Item ID Sales Qty sold Accessory #1 Accessory #2 Accessory #3 For each individual line item, you might define ""Sales per unit"" as . However, as the video points out, there are two ways one might then define the average Sales per unit for an Accessory. Using the video's terminology: So is just , whereas creates a composite Accessory item , whose sales and quantity are the sum of the individual line items', and calculates for that composite item. Plugging in example numbers for the and suggests that and do not in general give the same value. My question is: what are the qualitative differences in what and are doing? Which provides the better view of what average sales per unit for an Accessory are?","x_i k_i x_1 k_1 x_2 k_2 x_3 k_3 u_i=\frac{x_i}{k_i} \text{AGG}=\frac{x_1+x_2+x_3}{k_1+k_2+k_3} \text{AVG}=\frac{1}{3}\left(\frac{x_1}{k_1}+\frac{x_2}{k_2}+\frac{x_3}{k_3}\right) \text{AVG} \bar{u} \text{AGG} \left(X, K\right) U=\frac{X}{K} x_i k_i \text{AGG} \text{AVG} \text{AGG} \text{AVG}","['statistics', 'descriptive-statistics']"
85,Probability of Rain Question,Probability of Rain Question,,"This is the question: Most mornings, Victor checks the weather report before deciding whether to carry an umbrella. If the forecast is “rain,” the probability of actually having rain that day is 80%. On the other hand, if the forecast is “no rain,” the probability of it actually raining is equal to 10%. During fall and winter the forecast is “rain” 70% of the time and during summer and spring it is 20%. (a) One day, Victor missed the forecast and it rained. What is the probability that the forecast was “rain” if it was during the winter? What is the probability that the forecast was “rain” if it was during the summer? ==================================================================================== I've figured out the numerator for both winter and summer but I'm having issues coming up with the denominator. Any help is appreciated. So far I have: Let A be the event that the forecast was rain. Let B be the event that it rained. Let p be the probability that the forecast says rain. So, P(A|B) = P(B|A)P(A)","This is the question: Most mornings, Victor checks the weather report before deciding whether to carry an umbrella. If the forecast is “rain,” the probability of actually having rain that day is 80%. On the other hand, if the forecast is “no rain,” the probability of it actually raining is equal to 10%. During fall and winter the forecast is “rain” 70% of the time and during summer and spring it is 20%. (a) One day, Victor missed the forecast and it rained. What is the probability that the forecast was “rain” if it was during the winter? What is the probability that the forecast was “rain” if it was during the summer? ==================================================================================== I've figured out the numerator for both winter and summer but I'm having issues coming up with the denominator. Any help is appreciated. So far I have: Let A be the event that the forecast was rain. Let B be the event that it rained. Let p be the probability that the forecast says rain. So, P(A|B) = P(B|A)P(A)",,"['probability', 'statistics']"
86,Probability distribution function and distribution function,Probability distribution function and distribution function,,Is there a difference between the two? For discrete variables: PMF and CDF exists. The CDF is what we call the distribution function For continuous variables: PDF and CDF exist. The CDF is what we call the distribution function. What is the probability distribution function then?,Is there a difference between the two? For discrete variables: PMF and CDF exists. The CDF is what we call the distribution function For continuous variables: PDF and CDF exist. The CDF is what we call the distribution function. What is the probability distribution function then?,,"['probability', 'statistics']"
87,Sensitivity of geometric median to moving one point,Sensitivity of geometric median to moving one point,,"The geometric median of a finite set $S$ of points in the Euclidean plane is defined as the point $m$ for which $\sum_{s\in S} d(m,s)$ is minimized, where $d(x,y)$ is the Euclidean distance between $x$ and $y$ . As long as $S$ is not colinear, the geometric median is unique. My question is this; if you replace a point $s\in S$ with some $s'$ for which $d(s,s')<\epsilon$ , will the geometric median of the new set be at most $\epsilon$ away from the geometric median of the original? The reason I want to know is that I could use this result in order to solve the puzzle here: Algorithm for people to congregate with limited relative location information . I have verified this is true when $|S|=3$ and $|S|=4$ , where the geometric median can be described explicitly. For example, when $S$ is the set of vertices of a convex quadrilateral, it can be shown the median of $S$ is the intersection of the diagonals. This intersection moves by less than $\epsilon$ when any vertex moves by $\epsilon$ .","The geometric median of a finite set of points in the Euclidean plane is defined as the point for which is minimized, where is the Euclidean distance between and . As long as is not colinear, the geometric median is unique. My question is this; if you replace a point with some for which , will the geometric median of the new set be at most away from the geometric median of the original? The reason I want to know is that I could use this result in order to solve the puzzle here: Algorithm for people to congregate with limited relative location information . I have verified this is true when and , where the geometric median can be described explicitly. For example, when is the set of vertices of a convex quadrilateral, it can be shown the median of is the intersection of the diagonals. This intersection moves by less than when any vertex moves by .","S m \sum_{s\in S} d(m,s) d(x,y) x y S s\in S s' d(s,s')<\epsilon \epsilon |S|=3 |S|=4 S S \epsilon \epsilon","['geometry', 'statistics', 'convex-optimization']"
88,mean and variance formula for negative binomial distribution,mean and variance formula for negative binomial distribution,,"The equation below indicates expected value of negative binomial distribution. I need a derivation for this formula. I have searched a lot but can't find any solution. Thanks for helping :) $$ E(X)=\sum_{x=r}^\infty x\cdot \binom {x-1}{r-1} \cdot p^r \cdot (1-p)^{x-r} =\frac{r}{p} $$ I have tried: \begin{align} E(X) & =\sum _{x=r} x\cdot \binom{x-1}{r-1} \cdot p^r \cdot (1-p)^{x-r} \\[8pt] & = \sum_{x=r}^\infty x \cdot \frac{(x-1)!}{(r-1)! \cdot ((x-1-(r-1))!} \cdot p^r \cdot (1-p)^{x-r} \\[8pt] & = \sum_{x=r}^\infty \frac{x!}{(r-1)!\cdot ((x-r)!} \cdot p^r \cdot (1-p)^{x-r} \\[8pt] \Longrightarrow & \phantom{={}} \sum_{x=r}^\infty r\cdot \frac{x!}{r!\cdot (x-r)!}\cdot p^r \cdot (1-p{)}^{x-r} \\[8pt] & = \frac{r}{p} \cdot \sum_{x=r}^\infty \frac{x!}{r!\cdot (x-r)!}\cdot p^{r+1}\cdot (1-p)^{x-r} \end{align} If the power of $p$ in the last equation were not $r + 1,$ I can implement Newton Binomial. So It will be true. But I am stuck here.",The equation below indicates expected value of negative binomial distribution. I need a derivation for this formula. I have searched a lot but can't find any solution. Thanks for helping :) I have tried: If the power of in the last equation were not I can implement Newton Binomial. So It will be true. But I am stuck here.,"
E(X)=\sum_{x=r}^\infty x\cdot \binom {x-1}{r-1} \cdot p^r \cdot (1-p)^{x-r} =\frac{r}{p}
 \begin{align}
E(X) & =\sum _{x=r} x\cdot \binom{x-1}{r-1} \cdot p^r \cdot (1-p)^{x-r} \\[8pt]
& = \sum_{x=r}^\infty x \cdot \frac{(x-1)!}{(r-1)! \cdot ((x-1-(r-1))!} \cdot p^r \cdot (1-p)^{x-r} \\[8pt]
& = \sum_{x=r}^\infty \frac{x!}{(r-1)!\cdot ((x-r)!} \cdot p^r \cdot (1-p)^{x-r} \\[8pt]
\Longrightarrow & \phantom{={}} \sum_{x=r}^\infty r\cdot \frac{x!}{r!\cdot (x-r)!}\cdot p^r \cdot (1-p{)}^{x-r} \\[8pt]
& = \frac{r}{p} \cdot \sum_{x=r}^\infty \frac{x!}{r!\cdot (x-r)!}\cdot p^{r+1}\cdot (1-p)^{x-r}
\end{align} p r + 1,","['statistics', 'probability-distributions', 'self-learning', 'negative-binomial']"
89,Is it more likely to get $450-550$ or $379-479$ blue marbles in $1000$ draws?,Is it more likely to get  or  blue marbles in  draws?,450-550 379-479 1000,"This is a follow up question to this: An urn contains $4$ blue and $4$ red marbles. What is $P(A\vert B)$? An urn contains $4$ blue and $4$ red marbles. At first a marble is drawn (without looking) and removed from the urn. Then, a marble is drawn from the urn, its color recorded and put back in the urn. This process is repeated $1000$ times. Let $D$ be the event that between $450$ and $550$ blue marbles are drawn and let $E$ be the event that between $379$ and $479$ blue marbles are drawn. Which event is more likely? Intuitively I would say that event $D$ is more likely. This is because on average I would expect around $500$ blue marbles drawn. Since the event $D$ is centered around this average it seems more likely to me than event $E$ that is centered around a value of $429$ . Is there a nice way to show this mathematically by maybe using some sort of approximation?","This is a follow up question to this: An urn contains $4$ blue and $4$ red marbles. What is $P(A\vert B)$? An urn contains blue and red marbles. At first a marble is drawn (without looking) and removed from the urn. Then, a marble is drawn from the urn, its color recorded and put back in the urn. This process is repeated times. Let be the event that between and blue marbles are drawn and let be the event that between and blue marbles are drawn. Which event is more likely? Intuitively I would say that event is more likely. This is because on average I would expect around blue marbles drawn. Since the event is centered around this average it seems more likely to me than event that is centered around a value of . Is there a nice way to show this mathematically by maybe using some sort of approximation?",4 4 1000 D 450 550 E 379 479 D 500 D E 429,"['probability', 'combinatorics', 'statistics']"
90,Comparing mean squared errors for estimators,Comparing mean squared errors for estimators,,"Let random sample $(X_{1},...X_{n})$ is taken from a population with mean $\mu $ and variance $\sigma ^{2}$ . Compare suggesting estimators for $\mu $ according to mean squared error. Suggesting estimators are , $T_{1}=\frac{3X_{1}-X_{2}-X_{3}+4X_{n}}{5}$ and $T_{2}=\frac{X_{1}}{2}-\frac{X_{2}}{3}+\frac{X_{n}}{6}$ Here is my solution : $E(X)=\mu $ and $var(X)=\sigma ^{2}$ $E(T_{1})=E(\frac{3X_{1}-X_{2}-X_{3}+4X_{n}}{5})=\frac{5\mu }{5}=\mu $ and $var(T_{1})=var(\frac{3X_{1}-X_{2}-X_{3}+4X_{n}}{5})=\frac{27}{25}\sigma ^{2}$ $MSE(T_{1};\mu )=Var(T_{1})+(E(T_{1})-\mu ))^{2}=\frac{27}{25}\sigma ^{2}$ $E(T_{2})=E(\frac{X_{1}}{2}-\frac{X_{2}}{3}+\frac{X_{n}}{6})=\frac{1}{3}\mu $ and $var(T_{2})=var(\frac{X_{1}}{2}-\frac{X_{2}}{3}+\frac{X_{n}}{6})=\frac{7}{18}\sigma ^{2}$ $MSE(T_{2};\mu )=Var(T_{2})+(E(T_{2})-\mu ))^{2}=\frac{7}{18}\sigma ^{2}+\frac{4}{9}\mu ^{2}$ But how can I compare these two mean squared error. I do not know the value of $\mu ^{2}$ $MSE(T_{1};\mu )<MSE(T_{2};\mu )$ or $MSE(T_{2};\mu )<MSE(T_{1};\mu )$ ?","Let random sample is taken from a population with mean and variance . Compare suggesting estimators for according to mean squared error. Suggesting estimators are , and Here is my solution : and and and But how can I compare these two mean squared error. I do not know the value of or ?","(X_{1},...X_{n}) \mu  \sigma ^{2} \mu  T_{1}=\frac{3X_{1}-X_{2}-X_{3}+4X_{n}}{5} T_{2}=\frac{X_{1}}{2}-\frac{X_{2}}{3}+\frac{X_{n}}{6} E(X)=\mu  var(X)=\sigma ^{2} E(T_{1})=E(\frac{3X_{1}-X_{2}-X_{3}+4X_{n}}{5})=\frac{5\mu }{5}=\mu  var(T_{1})=var(\frac{3X_{1}-X_{2}-X_{3}+4X_{n}}{5})=\frac{27}{25}\sigma ^{2} MSE(T_{1};\mu )=Var(T_{1})+(E(T_{1})-\mu ))^{2}=\frac{27}{25}\sigma ^{2} E(T_{2})=E(\frac{X_{1}}{2}-\frac{X_{2}}{3}+\frac{X_{n}}{6})=\frac{1}{3}\mu  var(T_{2})=var(\frac{X_{1}}{2}-\frac{X_{2}}{3}+\frac{X_{n}}{6})=\frac{7}{18}\sigma ^{2} MSE(T_{2};\mu )=Var(T_{2})+(E(T_{2})-\mu ))^{2}=\frac{7}{18}\sigma ^{2}+\frac{4}{9}\mu ^{2} \mu ^{2} MSE(T_{1};\mu )<MSE(T_{2};\mu ) MSE(T_{2};\mu )<MSE(T_{1};\mu )","['probability', 'statistics', 'variance', 'means', 'mean-square-error']"
91,Student's t-distribution calculation,Student's t-distribution calculation,,"How to calculate this Student's t-distribution? $X $ ~ $ t(17)$ I have to find $P(X>8)$ and $a$ where $P(X>a)=0.1$ . I used standardizing for calculating similar probability for normal distribution $X $ ~ $ N(18,3)$ . How can I do that kind of thing here in Student's? I know there exists the formula of $Z$ but don't know how to use it. $\frac{\bar X-\mu}{S/\sqrt n}$ Thanks.",How to calculate this Student's t-distribution? ~ I have to find and where . I used standardizing for calculating similar probability for normal distribution ~ . How can I do that kind of thing here in Student's? I know there exists the formula of but don't know how to use it. Thanks.,"X   t(17) P(X>8) a P(X>a)=0.1 X   N(18,3) Z \frac{\bar X-\mu}{S/\sqrt n}",['probability']
92,What is the probability that 83% or more of this sample...?,What is the probability that 83% or more of this sample...?,,"This equation comes from Edgenuity's course of Statistics, and I am taking the course as a high school senior. I understand how to find the z-score and, in this case, not the standard deviation. A cell phone provider has 85% of its customers rank their service as ""satisfactory.” Nico takes a random sample of 75 customers from this cell phone provider. What is the probability that 83% or more of this sample ranks the provider’s service as ""satisfactory”? A. 0.314 B. 0.485 C. 0.562 D. 0.686 My guess with the observed value and mean value for the $z$ -score equation would be to substitute $0.83$ for the former and 0.85 for the latter. For the standard deviation, I believe I use the equation $\sqrt{np (1-p)}$ , substituting $0.85$ for $p$ and $75$ for $n$ . However, when I found the calculation to be $\approx 3.0923$ , I thought it was higher than what I'm normally used to. And sure enough, when it was substituted into the $z$ -score equation, the z-score was far too small. How do I find the correct answer? What methods were incorrect?","This equation comes from Edgenuity's course of Statistics, and I am taking the course as a high school senior. I understand how to find the z-score and, in this case, not the standard deviation. A cell phone provider has 85% of its customers rank their service as ""satisfactory.” Nico takes a random sample of 75 customers from this cell phone provider. What is the probability that 83% or more of this sample ranks the provider’s service as ""satisfactory”? A. 0.314 B. 0.485 C. 0.562 D. 0.686 My guess with the observed value and mean value for the -score equation would be to substitute for the former and 0.85 for the latter. For the standard deviation, I believe I use the equation , substituting for and for . However, when I found the calculation to be , I thought it was higher than what I'm normally used to. And sure enough, when it was substituted into the -score equation, the z-score was far too small. How do I find the correct answer? What methods were incorrect?",z 0.83 \sqrt{np (1-p)} 0.85 p 75 n \approx 3.0923 z,"['probability', 'statistics']"
93,"Confidence Interval for Normal$(\theta,\theta^2)$",Confidence Interval for Normal,"(\theta,\theta^2)","Let $X_1,X_2,\dots,X_n$ a simple random sample $$X_i\sim N(\theta,\theta^2)$$ I want to find a confidence interval for the mean using a pivotal quantity. I read this answer Confidence Intervals - distribution of a Pivot? and the pivotal quantity should be $$\frac{\bar{x}-\theta}{S/\sqrt{n}}$$ But I'm wondering if for this case I can use $$Y=\sum_{i=1}^nx_i\sim N(n\theta, n\theta^2)$$ Then my pivotal quantity will be $$\frac{Y-n\theta}{\theta\sqrt{n}}\sim N(0,1) $$ So $$P\left(-z_{\alpha/2}<\frac{y-n\theta}{\theta\sqrt{n}}<z_{\alpha/2}\right)=1-\alpha $$ $$P\left(\frac{Y}{n+\sqrt{n}z_{\alpha/2}}<\theta<\frac{Y}{n-\sqrt{n}z_{\alpha/2}}\right)=1-\alpha $$ Is this correct too?",Let a simple random sample I want to find a confidence interval for the mean using a pivotal quantity. I read this answer Confidence Intervals - distribution of a Pivot? and the pivotal quantity should be But I'm wondering if for this case I can use Then my pivotal quantity will be So Is this correct too?,"X_1,X_2,\dots,X_n X_i\sim N(\theta,\theta^2) \frac{\bar{x}-\theta}{S/\sqrt{n}} Y=\sum_{i=1}^nx_i\sim N(n\theta, n\theta^2) \frac{Y-n\theta}{\theta\sqrt{n}}\sim N(0,1)  P\left(-z_{\alpha/2}<\frac{y-n\theta}{\theta\sqrt{n}}<z_{\alpha/2}\right)=1-\alpha  P\left(\frac{Y}{n+\sqrt{n}z_{\alpha/2}}<\theta<\frac{Y}{n-\sqrt{n}z_{\alpha/2}}\right)=1-\alpha ","['statistics', 'statistical-inference', 'confidence-interval']"
94,Bayesian statistics to find a distribution,Bayesian statistics to find a distribution,,"Suppose that a random sample $X_1, ..., X_n$ is taken from a distribution where $X$ is a random variable that follows a Poisson distribution with mean $w$ . Furthermore, $w$ is modeled with a random variable $W$ that follows a chi-square distribution with $r = 4$ degrees of freedom. (i) Determine the posterior distribution of $W$ given that $X_1 = x_1, X_2 = x_2, ..., X_n = x_n$ (ii) Find the Bayesian estimator for $W$ that minimizes the mean-square error (iii) Before the sample was taken, Jack tells you that $w$ lies in $(0, 1)$ , however, no further information is provided about which values $w$ would most likely take in this interval. Do you pick a new prior pdf for $W$ ? Justify your answer, stating what new prior pdf you would take if so, or if not, why you would not pick a new prior pdf. Hint: Integration is unnecessary. The posterior distribution should be familiar if you use proportionality! You should use this posterior distribution to find the mean-square error. My attempt: (i) From chi-square with $r = 4$ , the prior pdf of $W$ is $$f_W(w) = \frac{we^{-w/2}}{4}$$ The pdf of a Poisson with mean $w$ is: $$f(x|w) = \frac{w^{x}e^{-w}}{x!}$$ The joint pdf of $X_1, X_2, ..., X_n$ is: $$F(x_1, ..., x_n|w) = \frac{w^{\sum{x_i}}e^{-nw}}{\prod{x_i!}}$$ The posterior probability density function (pdf) of $W$ given $X_1 = x_1, X_2 = x_2, ..., X_n = x_n$ is: $$f(w|x) = \frac{F(x_1, ..., x_n|w) \cdot f_W(w)}{f_X(x)} = \frac{F(x_1, ..., x_n|w) \cdot f_W(w)}{\int_{-\infty}^{\infty} F(x_1, ..., x_n|w) \cdot f_W(w) \,dw}$$ We apply proportionality: $$\frac{F(x_1, ..., x_n|w) \cdot f_W(w)}{\int_{-\infty}^{\infty} F(x_1, ..., x_n|w) \cdot f_W(w) \,dw} \propto F(x_1, ..., x_n|w) \cdot f_W(w) = \frac{w^{1+\sum{x_i}}e^{-nw-\frac{w}{2}}}{4\prod{x_i!}}$$ From here, there are a few possible posteriors to choose from: Chi-square, Exponential or Gamma. By mere inspection: If Chi-square, we have parameter $r = 4 + 2\sum{x_i}$ . If Exponential, we have parameter $\theta = \frac{-2}{w(2n+1)}$ or $\theta = \frac{1}{w^{1+\sum{x_i}}}$ . If Gamma, we have parameters $\alpha = 2 + \sum{x_i}$ and $\theta = \frac{2}{2n+1}$ . I am unsure which one is the correct posterior distribution as they all seem likely. (ii) Depends on (i) but am I supposed to use the fact that $E(W|X)$ is the least mean square here? (iii) Not sure. Any assistance especially with (i) and (iii) is much appreciated.","Suppose that a random sample is taken from a distribution where is a random variable that follows a Poisson distribution with mean . Furthermore, is modeled with a random variable that follows a chi-square distribution with degrees of freedom. (i) Determine the posterior distribution of given that (ii) Find the Bayesian estimator for that minimizes the mean-square error (iii) Before the sample was taken, Jack tells you that lies in , however, no further information is provided about which values would most likely take in this interval. Do you pick a new prior pdf for ? Justify your answer, stating what new prior pdf you would take if so, or if not, why you would not pick a new prior pdf. Hint: Integration is unnecessary. The posterior distribution should be familiar if you use proportionality! You should use this posterior distribution to find the mean-square error. My attempt: (i) From chi-square with , the prior pdf of is The pdf of a Poisson with mean is: The joint pdf of is: The posterior probability density function (pdf) of given is: We apply proportionality: From here, there are a few possible posteriors to choose from: Chi-square, Exponential or Gamma. By mere inspection: If Chi-square, we have parameter . If Exponential, we have parameter or . If Gamma, we have parameters and . I am unsure which one is the correct posterior distribution as they all seem likely. (ii) Depends on (i) but am I supposed to use the fact that is the least mean square here? (iii) Not sure. Any assistance especially with (i) and (iii) is much appreciated.","X_1, ..., X_n X w w W r = 4 W X_1 = x_1, X_2 = x_2, ..., X_n = x_n W w (0, 1) w W r = 4 W f_W(w) = \frac{we^{-w/2}}{4} w f(x|w) = \frac{w^{x}e^{-w}}{x!} X_1, X_2, ..., X_n F(x_1, ..., x_n|w) = \frac{w^{\sum{x_i}}e^{-nw}}{\prod{x_i!}} W X_1 = x_1, X_2 = x_2, ..., X_n = x_n f(w|x) = \frac{F(x_1, ..., x_n|w) \cdot f_W(w)}{f_X(x)} = \frac{F(x_1, ..., x_n|w) \cdot f_W(w)}{\int_{-\infty}^{\infty} F(x_1, ..., x_n|w) \cdot f_W(w) \,dw} \frac{F(x_1, ..., x_n|w) \cdot f_W(w)}{\int_{-\infty}^{\infty} F(x_1, ..., x_n|w) \cdot f_W(w) \,dw} \propto F(x_1, ..., x_n|w) \cdot f_W(w) = \frac{w^{1+\sum{x_i}}e^{-nw-\frac{w}{2}}}{4\prod{x_i!}} r = 4 + 2\sum{x_i} \theta = \frac{-2}{w(2n+1)} \theta = \frac{1}{w^{1+\sum{x_i}}} \alpha = 2 + \sum{x_i} \theta = \frac{2}{2n+1} E(W|X)","['statistics', 'probability-distributions', 'solution-verification', 'bayesian', 'parameter-estimation']"
95,Compute the expected number of dice that have been rolled at least once.,Compute the expected number of dice that have been rolled at least once.,,"I have been stuck forever on a homework problem. I thought I found the solution to the problem, but a friend simulated the setup with code and got a different final answer. I'm pretty sure his code is correct, but I also don't understand what could be wrong about my answer, so I was hoping you could enlighten me! Problem Definition: You have in total 5 dice. You select one of them at random and roll it. Then, you repeat this procedure 8 more times. Compute the expected number of dice that have been rolled at least once. My Solution: We can ignore the order of how we threw the dice. The total number of possibilities is \begin{equation}   N={9+5-1 \choose 9}={13 \choose 9}=715. \end{equation} For exactly $x$ different dice thrown at least once, we know that there are ${5 \choose x}$ amount of ways we can choose which dice to throw at least once. For each possible choice we for sure throw all $x$ dice once, after that we are free to do $9-x$ more throws. Every throw we get to choose any of the $x$ dice, thus \begin{equation}   n(x)={5 \choose x}{(9-x)+x-1 \choose 9-x}={5 \choose x}{8 \choose 9-x}, \end{equation} where $n(x)$ is the amount of ways we could have thrown exactly $x$ dice at least once. For the last step we just use a calculator, giving: \begin{equation}   \mathbb{E}(X)=\sum_{x=1}^5x\, \frac{n(x)}{N}=\frac{45}{13}. \end{equation}","I have been stuck forever on a homework problem. I thought I found the solution to the problem, but a friend simulated the setup with code and got a different final answer. I'm pretty sure his code is correct, but I also don't understand what could be wrong about my answer, so I was hoping you could enlighten me! Problem Definition: You have in total 5 dice. You select one of them at random and roll it. Then, you repeat this procedure 8 more times. Compute the expected number of dice that have been rolled at least once. My Solution: We can ignore the order of how we threw the dice. The total number of possibilities is For exactly different dice thrown at least once, we know that there are amount of ways we can choose which dice to throw at least once. For each possible choice we for sure throw all dice once, after that we are free to do more throws. Every throw we get to choose any of the dice, thus where is the amount of ways we could have thrown exactly dice at least once. For the last step we just use a calculator, giving:","\begin{equation}
  N={9+5-1 \choose 9}={13 \choose 9}=715.
\end{equation} x {5 \choose x} x 9-x x \begin{equation}
  n(x)={5 \choose x}{(9-x)+x-1 \choose 9-x}={5 \choose x}{8 \choose 9-x},
\end{equation} n(x) x \begin{equation}
  \mathbb{E}(X)=\sum_{x=1}^5x\, \frac{n(x)}{N}=\frac{45}{13}.
\end{equation}","['probability', 'probability-theory', 'statistics']"
96,Statistical survey of two genders in two cities,Statistical survey of two genders in two cities,,Suppose there are two cities. In the city A 52% of people are males and 48% are females. In the city B 47% of people are males and 53% are females. We conduct a survey: from each city a simple random sample of size 100 is taken. I need to find the probability that the survey will show greater percentage of males in city B than males in city A. What kind of statistical test should I use? $\chi^2$ or $t$ -test? And how can I find the asked probability?,Suppose there are two cities. In the city A 52% of people are males and 48% are females. In the city B 47% of people are males and 53% are females. We conduct a survey: from each city a simple random sample of size 100 is taken. I need to find the probability that the survey will show greater percentage of males in city B than males in city A. What kind of statistical test should I use? or -test? And how can I find the asked probability?,\chi^2 t,"['probability', 'statistics']"
97,Manipulation of Variance and quick way to show $\operatorname{Var}(X\mid X=x) = 0 $,Manipulation of Variance and quick way to show,\operatorname{Var}(X\mid X=x) = 0 ,"It is quite intuitive that $\operatorname{Var}(X\mid X=x) = 0 $ as the variable is no longer ""random"". It is also fairly simple to do this from the definition of Variance showing that $\mathbb{E}[X^2] = \mathbb{E}[X]^2 = x^2$ But I was wondering how in general we could manipulate conditioned variance and if there is another way to show this :) Thanks","It is quite intuitive that as the variable is no longer ""random"". It is also fairly simple to do this from the definition of Variance showing that But I was wondering how in general we could manipulate conditioned variance and if there is another way to show this :) Thanks",\operatorname{Var}(X\mid X=x) = 0  \mathbb{E}[X^2] = \mathbb{E}[X]^2 = x^2,"['probability', 'statistics', 'variance']"
98,MLE for mixed distribution,MLE for mixed distribution,,"Let $X\sim f(x)=\begin{cases}\lambda e^{-\lambda x},&x\in [0,5)\\e^{-5\lambda},&x=5\end{cases}$ How can I derive the MLE for this distribution? I know how to derive the MLE for $\lambda$ if $Y\sim\exp(\lambda)$ but I don't know how to work with this mixed distribution",Let How can I derive the MLE for this distribution? I know how to derive the MLE for if but I don't know how to work with this mixed distribution,"X\sim f(x)=\begin{cases}\lambda e^{-\lambda x},&x\in [0,5)\\e^{-5\lambda},&x=5\end{cases} \lambda Y\sim\exp(\lambda)","['statistics', 'probability-distributions', 'statistical-inference', 'maximum-likelihood']"
99,Ask George Casella textbook question 8.37 (a),Ask George Casella textbook question 8.37 (a),,"This is from George Casella textbook question 8.37 (a). Let $X_1,...,X_n$ be a random sample from a $n(\theta, \sigma^2)$ population. Consider testing $H_0:\theta\leq \theta_0$ versus $H_1:\theta> \theta_0$ .  If $\sigma^2$ is known, show that the test that rejects $H_0$ when $$\bar{X}>\theta_0+z_\alpha \sqrt{\sigma^2/n}$$ is a test of size $\alpha$ . Show that the test can be derived as an LRT. My understanding of this question is it contains 2 questions. First is to show the size of this test is $\alpha$ . The second question is to show this test can be derived as an LRT. I have both problems on these 2 questions. My attempt of the first question: to show the size is $\alpha$ . I show it based on the definition strictly. According to the definition 8.3.5, $\alpha=sup\beta(\theta)=supP(x\in R|H_0)=supP(x\in R|\theta\leq \theta_0)$ . Then I first get $P(x\in R)=P(\bar{X}>\theta_0+z_\alpha \sqrt{\sigma^2/n})=P(\bar{X}-\theta>\theta_0-\theta+z_\alpha \sqrt{\sigma^2/n})=P((\bar{X}-\theta)/\sqrt{\sigma^2/n}>(\theta_0-\theta)/\sqrt{\sigma^2/n}+z_\alpha)=P(Z>(\theta_0-\theta)/\sqrt{\sigma^2/n}+z_\alpha)$ . Then I find this probability is increasing in terms of $\theta$ , so the supremum under $H_0=\theta\leq \theta_0$ is reached at $\theta=\theta_0$ . So the above becomes $P(Z>z_\alpha)$ . It is exactly $\alpha$ . Then I finish my proof to show the size of this test is $\alpha$ . But the solution is very easy. I think the solution is wrong. Because it is not $Z=(\bar{X}-\theta_0)/\sqrt{\sigma^2/n}$ , it is $Z=(\bar{X}-\theta)/\sqrt{\sigma^2/n}$ . So I think the solution is wrong. But 8.37(a), 8.37(c) both use this solution. Am I correct? For the second question: to show this test can be derived as an LRT. Yes, I understand and get the step in the solution: it is equivalent  to rejecting if $(\bar{x}-\theta_0)/\sqrt{\sigma^2/n}>c'$ . Then we finished the proof? Shouldn't we derive the exact same form of $\bar{X}>\theta_0+z_\alpha \sqrt{\sigma^2/n}$ ? The solution is:","This is from George Casella textbook question 8.37 (a). Let be a random sample from a population. Consider testing versus .  If is known, show that the test that rejects when is a test of size . Show that the test can be derived as an LRT. My understanding of this question is it contains 2 questions. First is to show the size of this test is . The second question is to show this test can be derived as an LRT. I have both problems on these 2 questions. My attempt of the first question: to show the size is . I show it based on the definition strictly. According to the definition 8.3.5, . Then I first get . Then I find this probability is increasing in terms of , so the supremum under is reached at . So the above becomes . It is exactly . Then I finish my proof to show the size of this test is . But the solution is very easy. I think the solution is wrong. Because it is not , it is . So I think the solution is wrong. But 8.37(a), 8.37(c) both use this solution. Am I correct? For the second question: to show this test can be derived as an LRT. Yes, I understand and get the step in the solution: it is equivalent  to rejecting if . Then we finished the proof? Shouldn't we derive the exact same form of ? The solution is:","X_1,...,X_n n(\theta, \sigma^2) H_0:\theta\leq \theta_0 H_1:\theta> \theta_0 \sigma^2 H_0 \bar{X}>\theta_0+z_\alpha \sqrt{\sigma^2/n} \alpha \alpha \alpha \alpha=sup\beta(\theta)=supP(x\in R|H_0)=supP(x\in R|\theta\leq \theta_0) P(x\in R)=P(\bar{X}>\theta_0+z_\alpha \sqrt{\sigma^2/n})=P(\bar{X}-\theta>\theta_0-\theta+z_\alpha \sqrt{\sigma^2/n})=P((\bar{X}-\theta)/\sqrt{\sigma^2/n}>(\theta_0-\theta)/\sqrt{\sigma^2/n}+z_\alpha)=P(Z>(\theta_0-\theta)/\sqrt{\sigma^2/n}+z_\alpha) \theta H_0=\theta\leq \theta_0 \theta=\theta_0 P(Z>z_\alpha) \alpha \alpha Z=(\bar{X}-\theta_0)/\sqrt{\sigma^2/n} Z=(\bar{X}-\theta)/\sqrt{\sigma^2/n} (\bar{x}-\theta_0)/\sqrt{\sigma^2/n}>c' \bar{X}>\theta_0+z_\alpha \sqrt{\sigma^2/n}","['probability', 'statistics', 'statistical-inference']"
