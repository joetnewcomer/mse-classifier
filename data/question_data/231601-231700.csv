,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Restriction to equivalence relation is equivalence relation,Restriction to equivalence relation is equivalence relation,,"Let $\mathcal{R}$ be relation on $A$ and $A_0 \subseteq A$ . The $\mathbf{restriction}$ of $\mathcal{R}$ to $A_0$ is defined to be the relation $\mathcal{R} \cap (A_0 \times A_0) $ . $\mathbf{Homework \; Problem:}$ Please prove that that the restriction of equivalence relation is also an equivalence relation. Attempt: Let $\mathcal{R}$ be equivalence relation on set $A$ . Pick any point $x \in A_0$ . We have to show that $(x,x) \in \mathcal{R} \cap (A_0 \times A_0) $ . But, we are given that $x \in A$ as well, so $(x,x) \in \mathcal{R}$ . Since $x \in A_0$ , then $(x,x) \in A_0 \times A_0$ . therefore, $(x,x) \in \mathcal{R} \cap ( A_0 \times A_0) $ . Next, suppose $(x,y) \in \mathcal{R} \cap (A_0 \times A_0) $ and since $ \mathcal{R} \cap (A_0 \times A_0) \subseteq \mathcal{R} $ , then $(x,y) \in \mathcal{R}$ . so $(y,x) \in \mathcal{R}$ . Also, we know $(x,y) \in A_0 \times A_0$ . So by definition of product of a set with itself, then $(y,x)$ must be in $A_0 \times A_0$ as well. Therefore $(y,x) \in \mathcal{R} \cap ( A_0 \times A_0 )$ . So we have symmetry. Finally, say $(x,y)$ and $(y,z) $ are in $\mathcal{R} \cap (A_0 \times A_0) $ . First, we obtain $(x,z) \in \mathcal{R}$ by transitivity of $\mathcal{R}$ . since $x,y,z \in A_0$ , then $ (x,z)$ must be in $A_0 \times A_0$ and so $(x,z) \in \mathcal{R} \cap (A_0 \times A_0)$ and so we get transitivity. Is this a sufficient argument? Thanks.","Let be relation on and . The of to is defined to be the relation . Please prove that that the restriction of equivalence relation is also an equivalence relation. Attempt: Let be equivalence relation on set . Pick any point . We have to show that . But, we are given that as well, so . Since , then . therefore, . Next, suppose and since , then . so . Also, we know . So by definition of product of a set with itself, then must be in as well. Therefore . So we have symmetry. Finally, say and are in . First, we obtain by transitivity of . since , then must be in and so and so we get transitivity. Is this a sufficient argument? Thanks.","\mathcal{R} A A_0 \subseteq A \mathbf{restriction} \mathcal{R} A_0 \mathcal{R} \cap (A_0 \times A_0)  \mathbf{Homework \; Problem:} \mathcal{R} A x \in A_0 (x,x) \in \mathcal{R} \cap (A_0 \times A_0)  x \in A (x,x) \in \mathcal{R} x \in A_0 (x,x) \in A_0 \times A_0 (x,x) \in \mathcal{R} \cap ( A_0 \times A_0)  (x,y) \in \mathcal{R} \cap (A_0 \times A_0)   \mathcal{R} \cap (A_0 \times A_0) \subseteq \mathcal{R}  (x,y) \in \mathcal{R} (y,x) \in \mathcal{R} (x,y) \in A_0 \times A_0 (y,x) A_0 \times A_0 (y,x) \in \mathcal{R} \cap ( A_0 \times A_0 ) (x,y) (y,z)  \mathcal{R} \cap (A_0 \times A_0)  (x,z) \in \mathcal{R} \mathcal{R} x,y,z \in A_0  (x,z) A_0 \times A_0 (x,z) \in \mathcal{R} \cap (A_0 \times A_0)","['elementary-set-theory', 'proof-verification']"
1,"If $p_n$ is the $n^{th}$ prime, is it ever appropriate to speak of $p_{\aleph_0}$?","If  is the  prime, is it ever appropriate to speak of ?",p_n n^{th} p_{\aleph_0},"If $p_n$ is the $n^{th}$ prime, is it ever appropriate to speak of $p_{\aleph_0}$? I'm no math student.  Your pardon if this is just some clearly obvious and easy answer, I'm just not seeing it. When talking about a function such as $p_n$, where $p_n$ is the $n^{th}$ prime, and $n \in \mathbb{N}$, is it ever appropriate to talk of $p_{\aleph_0}$, since $\left|\mathbb{N}\right| = \aleph_0$? Further is there any proof that $p_n \in \mathbb{N}$ for all $n \in \mathbb{N}$?  The point isn't so much in using primes, they are merely convenient. My basic issue points to a fact discussed in this question, A ""number"" with an infinite number of digits is a natural number? , which states, ""By definition, a natural number has a finite number of digits..."" While it may not be as easily seen with base-10 numbers, I could easily construct a numbering system based on the primes themselves, such that each digit is mulitipled by $p_{digit}$, so that $p_n$ is always 1 followed by (n-1) zeros.  This numbering system, just to help see it, demonstrates that while $\mathbb{N}$ is an infinite set comprised of numbers with a finite number of digits, $\mathbb{P}$, constructed over the same range, grows one digit in length each time and so has one number of each count of digits, from 1 to $\aleph_0$, and thus would contain many numbers with an infinite number of digits.  But, I believe the numbering system is irrelevant, and just illustrates the point.  The real point is that over the range of $\mathbb{N}$, it seems like $p_n$ itself must become infinite in length, and thus no longer be in $\mathbb{N}$ (which, of course, makes no intuitive sense, that a prime not be an integer). What it seems like, thinking about it, I relate to the percentage of primes.  If one looks at the entire number line, there are effectively 0% primes across the whole of the number line, out to infinity.  Out at infinity, you have to go an appropriate ""infinite distance"" to find the next suitable prime, on average, which leaves you with a non-finite number of digits on your next $p_n$.  But, this is arrived at through an infinite set of finite-lengthed $n \in \mathbb{N}$. And, here's what I'm trying to wrap my head around.  This fact seems to indicate that you would run out of primes before you would natural numbers, except you can keep picking primes.  But, according to the illustration given above, $p_{\aleph_0} \notin \mathbb{N}$, or so it seems.. It seems I'm running into somekind of logical falacy here.  Is it just wrong to think of $p_{\aleph_0}$, which of needs must be of infinite length, and hence is not natural, or something else?  What am I missing?","If $p_n$ is the $n^{th}$ prime, is it ever appropriate to speak of $p_{\aleph_0}$? I'm no math student.  Your pardon if this is just some clearly obvious and easy answer, I'm just not seeing it. When talking about a function such as $p_n$, where $p_n$ is the $n^{th}$ prime, and $n \in \mathbb{N}$, is it ever appropriate to talk of $p_{\aleph_0}$, since $\left|\mathbb{N}\right| = \aleph_0$? Further is there any proof that $p_n \in \mathbb{N}$ for all $n \in \mathbb{N}$?  The point isn't so much in using primes, they are merely convenient. My basic issue points to a fact discussed in this question, A ""number"" with an infinite number of digits is a natural number? , which states, ""By definition, a natural number has a finite number of digits..."" While it may not be as easily seen with base-10 numbers, I could easily construct a numbering system based on the primes themselves, such that each digit is mulitipled by $p_{digit}$, so that $p_n$ is always 1 followed by (n-1) zeros.  This numbering system, just to help see it, demonstrates that while $\mathbb{N}$ is an infinite set comprised of numbers with a finite number of digits, $\mathbb{P}$, constructed over the same range, grows one digit in length each time and so has one number of each count of digits, from 1 to $\aleph_0$, and thus would contain many numbers with an infinite number of digits.  But, I believe the numbering system is irrelevant, and just illustrates the point.  The real point is that over the range of $\mathbb{N}$, it seems like $p_n$ itself must become infinite in length, and thus no longer be in $\mathbb{N}$ (which, of course, makes no intuitive sense, that a prime not be an integer). What it seems like, thinking about it, I relate to the percentage of primes.  If one looks at the entire number line, there are effectively 0% primes across the whole of the number line, out to infinity.  Out at infinity, you have to go an appropriate ""infinite distance"" to find the next suitable prime, on average, which leaves you with a non-finite number of digits on your next $p_n$.  But, this is arrived at through an infinite set of finite-lengthed $n \in \mathbb{N}$. And, here's what I'm trying to wrap my head around.  This fact seems to indicate that you would run out of primes before you would natural numbers, except you can keep picking primes.  But, according to the illustration given above, $p_{\aleph_0} \notin \mathbb{N}$, or so it seems.. It seems I'm running into somekind of logical falacy here.  Is it just wrong to think of $p_{\aleph_0}$, which of needs must be of infinite length, and hence is not natural, or something else?  What am I missing?",,"['elementary-set-theory', 'prime-numbers', 'cardinals']"
2,Definition of Ordered Pair,Definition of Ordered Pair,,"This is probably a more open ended question. Kuratowski's definition of ordered pair is that $(a,b) = \{\{a\},\{a,b\}\}$. This is basically just subset of a power set. But say we have a probability space that has events A = {a} and B = {a,b}, and we ask whether they're independent or not. Sometimes this is framed as asking whether the collection {A,B} is independent. But we've ended up asking if the ordered pair (a,b) is independent. Is this simply an artifact of the definition? Are there other situations where something just happens to also be something else that's irrelevant to the context? And, most importantly, does it even matter?","This is probably a more open ended question. Kuratowski's definition of ordered pair is that $(a,b) = \{\{a\},\{a,b\}\}$. This is basically just subset of a power set. But say we have a probability space that has events A = {a} and B = {a,b}, and we ask whether they're independent or not. Sometimes this is framed as asking whether the collection {A,B} is independent. But we've ended up asking if the ordered pair (a,b) is independent. Is this simply an artifact of the definition? Are there other situations where something just happens to also be something else that's irrelevant to the context? And, most importantly, does it even matter?",,['elementary-set-theory']
3,Notation for sets of unordered pairs,Notation for sets of unordered pairs,,"Let $A$ be a finite set of unordered pairs, e.g., $$A = \{\{1, 2\}, \{1, 3\}, \{2, 3\}\} \enspace .$$ Which of the following is proper notation for ""the element $\{1, 2\}$ belongs to $A$""? $\{1, 2\} \in A$ $\{1, 2\} \subsetneq A$ $\{\{1, 2\}\} \subsetneq A$ The second option makes no sense at all, but would the first and the third be equally appropriate?","Let $A$ be a finite set of unordered pairs, e.g., $$A = \{\{1, 2\}, \{1, 3\}, \{2, 3\}\} \enspace .$$ Which of the following is proper notation for ""the element $\{1, 2\}$ belongs to $A$""? $\{1, 2\} \in A$ $\{1, 2\} \subsetneq A$ $\{\{1, 2\}\} \subsetneq A$ The second option makes no sense at all, but would the first and the third be equally appropriate?",,"['elementary-set-theory', 'notation']"
4,Bijective continuous map between $\mathbb{R}$ and $\mathbb{R}^2$,Bijective continuous map between  and,\mathbb{R} \mathbb{R}^2,"I am currently attending a course on point-set topology and fundamental group. Today we proved in class that $\mathbb{R}$ and $\mathbb{R}^2$ are not homeomorphic with their normal Hausdorff topologies. I also learned from this question that there is in fact no continuous bijection between $\mathbb{R}$ and $\mathbb{R}^2$. I am wondering, what happens when we consider other topologies on $\mathbb{R}$ and $\mathbb{R}^2$? For example, in our course, we discussed cofinite and cocountable topologies, which I denote by $\tau_f$ and $\tau_c$ respectively. I am wondering, are there continuous bijections between $(\mathbb{R}, \tau_c)$ and $(\mathbb{R}^2, \tau_f)$? What about between $(\mathbb{R}^2, \tau_c)$ and $(\mathbb{R}, \tau_f)$?","I am currently attending a course on point-set topology and fundamental group. Today we proved in class that $\mathbb{R}$ and $\mathbb{R}^2$ are not homeomorphic with their normal Hausdorff topologies. I also learned from this question that there is in fact no continuous bijection between $\mathbb{R}$ and $\mathbb{R}^2$. I am wondering, what happens when we consider other topologies on $\mathbb{R}$ and $\mathbb{R}^2$? For example, in our course, we discussed cofinite and cocountable topologies, which I denote by $\tau_f$ and $\tau_c$ respectively. I am wondering, are there continuous bijections between $(\mathbb{R}, \tau_c)$ and $(\mathbb{R}^2, \tau_f)$? What about between $(\mathbb{R}^2, \tau_c)$ and $(\mathbb{R}, \tau_f)$?",,"['general-topology', 'elementary-set-theory', 'reference-request', 'continuity']"
5,Cartesian Product of a Union and an Intersection,Cartesian Product of a Union and an Intersection,,"I am given the Cartesian Product of an equation: $(A \cap C) \times (B \cup A)$ As being $\{(5,1),(5,4),(6,1),(6,4)\}$ And the sets: $B=\{1,9,4\}$ and $C=\{5,6,7,8\}$ And so I figure that $(A \cap C)=\{5,6\}$ and $(B \cup A)=\{1,4\}$ But regardless of the elements of the set $A$, surely $(B \cup A)$ must contain all three elements of $B$ and thusly $(B \cup A) \neq \{1,4\}$? I am supposed to give an example of the set $A$ with the maximum cardinality, but given my understanding of set notation this is not possible, is it?","I am given the Cartesian Product of an equation: $(A \cap C) \times (B \cup A)$ As being $\{(5,1),(5,4),(6,1),(6,4)\}$ And the sets: $B=\{1,9,4\}$ and $C=\{5,6,7,8\}$ And so I figure that $(A \cap C)=\{5,6\}$ and $(B \cup A)=\{1,4\}$ But regardless of the elements of the set $A$, surely $(B \cup A)$ must contain all three elements of $B$ and thusly $(B \cup A) \neq \{1,4\}$? I am supposed to give an example of the set $A$ with the maximum cardinality, but given my understanding of set notation this is not possible, is it?",,['elementary-set-theory']
6,Is it possible to work entirely with Axioms and Isomorphisms?,Is it possible to work entirely with Axioms and Isomorphisms?,,"I've been thinking a lot about foundations, again, and specifically how to make isomorphism invariance clearer - which seems to be one of the main purposes of alternative foundations such as Homotopy Type Theory. The problem seems to be that we often have different models of the same object which we would really like to identify with each other (as a simple example,  $\mathbb{N} = \{\varnothing, \{\varnothing\}, \{\varnothing, \{\varnothing\} \}, \dots\}$ is an entirely different set from the $X \subseteq \mathbb{Z}$ we tend to call $\mathbb{N}$) and  in ZFC, under the current definitions, we cannot formally do so. What we tend to do if we ever point this out at all is simply call it an abuse of notation, and justify it by claiming that the clear isomorphisms existing between the two models will preserve any theorems we want to invoke. Homotopy type theory claims to make this easier by making it so that if we have two isomorphic objects we can say they are equal (in some sense I'm not entirely clear on) and so carry across any theorems we like. The problem is that it seems we really need to leave our comfort zone to be able to do this. My question is...could this all be fixed by changing our point of view on some definitions? For instance, rather than saying ""The set of natural numbers is [some specific set]"", we could have the definition be phrased something like ""$(X, Succ, 0)$ is a natural numbers set if and only if [Peano Axioms]"", and then have as a theorem that $\{\varnothing, \{\varnothing\}, \{\varnothing, \{\varnothing\} \}, \dots\}$ is a natural numbers set. What I'm effectively suggesting is that we relegate the phrase ""set of natural numbers"" to the same level as ""group"", so that rather than proving that some statement is true of a particular set which we have called the set of natural numbers, we prove that the statement is true for any set of natural numbers. When we want to work with natural numbers, we simply say ""Let $\mathbb{N}$ be a set of natural numbers"" in the same way that we often say ""Let $G$ be a group"". What kind of problems arise from working in this way? If I'm not being clear enough please let me know, because I do have a few specific definitions in my head that I could give as examples which might clarify what I mean. EDIT: While structural set theory is effectively what I want, my question is whether or not this type of definition change would give us the benefits of structural set theory without leaving ZFC.","I've been thinking a lot about foundations, again, and specifically how to make isomorphism invariance clearer - which seems to be one of the main purposes of alternative foundations such as Homotopy Type Theory. The problem seems to be that we often have different models of the same object which we would really like to identify with each other (as a simple example,  $\mathbb{N} = \{\varnothing, \{\varnothing\}, \{\varnothing, \{\varnothing\} \}, \dots\}$ is an entirely different set from the $X \subseteq \mathbb{Z}$ we tend to call $\mathbb{N}$) and  in ZFC, under the current definitions, we cannot formally do so. What we tend to do if we ever point this out at all is simply call it an abuse of notation, and justify it by claiming that the clear isomorphisms existing between the two models will preserve any theorems we want to invoke. Homotopy type theory claims to make this easier by making it so that if we have two isomorphic objects we can say they are equal (in some sense I'm not entirely clear on) and so carry across any theorems we like. The problem is that it seems we really need to leave our comfort zone to be able to do this. My question is...could this all be fixed by changing our point of view on some definitions? For instance, rather than saying ""The set of natural numbers is [some specific set]"", we could have the definition be phrased something like ""$(X, Succ, 0)$ is a natural numbers set if and only if [Peano Axioms]"", and then have as a theorem that $\{\varnothing, \{\varnothing\}, \{\varnothing, \{\varnothing\} \}, \dots\}$ is a natural numbers set. What I'm effectively suggesting is that we relegate the phrase ""set of natural numbers"" to the same level as ""group"", so that rather than proving that some statement is true of a particular set which we have called the set of natural numbers, we prove that the statement is true for any set of natural numbers. When we want to work with natural numbers, we simply say ""Let $\mathbb{N}$ be a set of natural numbers"" in the same way that we often say ""Let $G$ be a group"". What kind of problems arise from working in this way? If I'm not being clear enough please let me know, because I do have a few specific definitions in my head that I could give as examples which might clarify what I mean. EDIT: While structural set theory is effectively what I want, my question is whether or not this type of definition change would give us the benefits of structural set theory without leaving ZFC.",,"['elementary-set-theory', 'foundations']"
7,Which of the following set inequalities are true? [closed],Which of the following set inequalities are true? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 8 years ago . Improve this question Let $G_1,G_2\subseteq \Bbb R^2$ .Let $f:\Bbb R^2\to \Bbb R^2$. Then which are correct? $f^{-1}(G_1\cup G_2)=f^{-1}(G_1)\cup f^{-1}(G_2)$ $f^{-1}(G_1^c)=(f^{-1}(G_1))^c$ $f(G_1\cap G_2)=f(G_1)\cap f(G_2)$ $G_1$ open and $G_2$ closed $\implies G_1+G_2 $ neither open nor closed. I am getting $1,2$ as true. $3$ is false. If $W$ is open $x+W$ is open for all $x$. Thus $4$ is false. Are these correct?","Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 8 years ago . Improve this question Let $G_1,G_2\subseteq \Bbb R^2$ .Let $f:\Bbb R^2\to \Bbb R^2$. Then which are correct? $f^{-1}(G_1\cup G_2)=f^{-1}(G_1)\cup f^{-1}(G_2)$ $f^{-1}(G_1^c)=(f^{-1}(G_1))^c$ $f(G_1\cap G_2)=f(G_1)\cap f(G_2)$ $G_1$ open and $G_2$ closed $\implies G_1+G_2 $ neither open nor closed. I am getting $1,2$ as true. $3$ is false. If $W$ is open $x+W$ is open for all $x$. Thus $4$ is false. Are these correct?",,"['general-topology', 'elementary-set-theory']"
8,What is the name of partition without pairwise disjoint property?,What is the name of partition without pairwise disjoint property?,,"Wiki definition of partition: Equivalently, a family of sets P is a partition of X if and only if all of the following conditions hold:[2] P does not contain the empty set. The union of the sets in P is equal to X. (The sets in P are said to cover X.) The intersection of any two distinct sets in P is empty. (We say the elements of P are pairwise disjoint.) If we remove the third condition, does the result sets have specific name in set theory?","Wiki definition of partition: Equivalently, a family of sets P is a partition of X if and only if all of the following conditions hold:[2] P does not contain the empty set. The union of the sets in P is equal to X. (The sets in P are said to cover X.) The intersection of any two distinct sets in P is empty. (We say the elements of P are pairwise disjoint.) If we remove the third condition, does the result sets have specific name in set theory?",,"['general-topology', 'elementary-set-theory', 'terminology']"
9,Clarification about a metric,Clarification about a metric,,"This is rather an easy question but I am a bit confused about the following metric $\rho(\mathcal{G},\mathcal{H})  := \sup_{A\in \mathcal{G}} \inf_{B\in \mathcal{H}} \mu(A \triangle B) + \sup_{B\in \mathcal{H}} \inf_{A\in \mathcal{G}} \mu(A \triangle B)$ where $A\Delta B$ is symmetric difference and $\mu$ is a measure for some underlying probability space. Now I want to understand what this implies for finite sets if we replace $\mu$ with cardinality of sets. Consider $\mathcal{G}=\{\left\{1,2,3,4 \right\}\}, \mathcal{H}=\{\{ 2\},\{1,3,4\}\}$ I found distance between these two sets as $4$ but I am not sure. Any confirmation and/or clarification is greatly appreciated. Many thanks!","This is rather an easy question but I am a bit confused about the following metric $\rho(\mathcal{G},\mathcal{H})  := \sup_{A\in \mathcal{G}} \inf_{B\in \mathcal{H}} \mu(A \triangle B) + \sup_{B\in \mathcal{H}} \inf_{A\in \mathcal{G}} \mu(A \triangle B)$ where $A\Delta B$ is symmetric difference and $\mu$ is a measure for some underlying probability space. Now I want to understand what this implies for finite sets if we replace $\mu$ with cardinality of sets. Consider $\mathcal{G}=\{\left\{1,2,3,4 \right\}\}, \mathcal{H}=\{\{ 2\},\{1,3,4\}\}$ I found distance between these two sets as $4$ but I am not sure. Any confirmation and/or clarification is greatly appreciated. Many thanks!",,"['elementary-set-theory', 'metric-spaces']"
10,Behavior of the null set?,Behavior of the null set?,,"I am trying to work out problems to understand the null set beyond the notion of, ""an empty box"". Therefore, I have tried to work out some problems concerning set operations involving the null set. I was wondering, is my logic correct here? $\emptyset$ $\in$ $\emptyset$ This is false because the empty set is defined as having no elements. This can be expressed via contradiction as $if \; empty \; \rightarrow \; no \; elements$, which yields as $T \rightarrow F$, which is false. $\{\{\emptyset\}\} \subseteq \{\emptyset,\{\emptyset,\{\emptyset\}\}\}$ This would be false because the two sets in $\{\emptyset,\{\emptyset,\{\emptyset\}\}\}$ are $\emptyset$ and $\{\{\emptyset,\{\emptyset\}\}\\$ $\{\emptyset\} \; \cap \{\emptyset,\{\{\emptyset\}\}\} = \emptyset$ This would be true, because the sets of $\{\emptyset,\{\{\emptyset\}\}\}$ include $\emptyset$ and $\{\{\emptyset\}\}$, which don't equal $\{\emptyset\}$. $\emptyset \subseteq \emptyset$ This would be true because the empty set is a subset of all sets.","I am trying to work out problems to understand the null set beyond the notion of, ""an empty box"". Therefore, I have tried to work out some problems concerning set operations involving the null set. I was wondering, is my logic correct here? $\emptyset$ $\in$ $\emptyset$ This is false because the empty set is defined as having no elements. This can be expressed via contradiction as $if \; empty \; \rightarrow \; no \; elements$, which yields as $T \rightarrow F$, which is false. $\{\{\emptyset\}\} \subseteq \{\emptyset,\{\emptyset,\{\emptyset\}\}\}$ This would be false because the two sets in $\{\emptyset,\{\emptyset,\{\emptyset\}\}\}$ are $\emptyset$ and $\{\{\emptyset,\{\emptyset\}\}\\$ $\{\emptyset\} \; \cap \{\emptyset,\{\{\emptyset\}\}\} = \emptyset$ This would be true, because the sets of $\{\emptyset,\{\{\emptyset\}\}\}$ include $\emptyset$ and $\{\{\emptyset\}\}$, which don't equal $\{\emptyset\}$. $\emptyset \subseteq \emptyset$ This would be true because the empty set is a subset of all sets.",,['elementary-set-theory']
11,Existence of a partition of a set $X$ which contains at least 2 subsets of $X$ with the same cardinality,Existence of a partition of a set  which contains at least 2 subsets of  with the same cardinality,X X,"If $X$ is a set s.t $|X|\geq \aleph _0$ then I want to prove that there exist $A,B\subset X$ s.t $A\cap B=\emptyset$, $A\cup B=X$ and $|A|=|B|=|X|$. How can I construct such subsets?","If $X$ is a set s.t $|X|\geq \aleph _0$ then I want to prove that there exist $A,B\subset X$ s.t $A\cap B=\emptyset$, $A\cup B=X$ and $|A|=|B|=|X|$. How can I construct such subsets?",,"['elementary-set-theory', 'cardinals']"
12,"Proving relationship between set complement, intersection and union","Proving relationship between set complement, intersection and union",,"Show that $S_1 \cup S_2 = \overline{\overline{S_1}\cap \overline{S_2}}$. So we want to show that the union of $S_1$ and $S_2$ is equal to the compliment of the intersection of the compliments of $S_1$ and $S_2$. I hope that makes sense! I created some finite sets with some random values. Here's what I have so far but I'm stuck! $$\begin{align*}     S_1  &= \{1, 2, 3, 4\}\\     S_2 &= \{2, 3, 4, 5, 6\}\\ 	S_1 \cup S_2 &= \{1, 2, 3, 4, 5, 6\}\\     \overline{S_1} &= \{5, 6\} &\text{(everything in $S_2$ but not in $S_1$)}\\     \overline{S_2} &= \{1\}    &\text{(everything in $S_1$ but not in $S_2$)} \end{align*}$$ I don't see a way to intersect $\overline{S_1}$ and $\overline{S_2}$, can someone point me in the right direction please? Am I on the right track, or way off?","Show that $S_1 \cup S_2 = \overline{\overline{S_1}\cap \overline{S_2}}$. So we want to show that the union of $S_1$ and $S_2$ is equal to the compliment of the intersection of the compliments of $S_1$ and $S_2$. I hope that makes sense! I created some finite sets with some random values. Here's what I have so far but I'm stuck! $$\begin{align*}     S_1  &= \{1, 2, 3, 4\}\\     S_2 &= \{2, 3, 4, 5, 6\}\\ 	S_1 \cup S_2 &= \{1, 2, 3, 4, 5, 6\}\\     \overline{S_1} &= \{5, 6\} &\text{(everything in $S_2$ but not in $S_1$)}\\     \overline{S_2} &= \{1\}    &\text{(everything in $S_1$ but not in $S_2$)} \end{align*}$$ I don't see a way to intersect $\overline{S_1}$ and $\overline{S_2}$, can someone point me in the right direction please? Am I on the right track, or way off?",,[]
13,Chance of Drawing All of a Subset,Chance of Drawing All of a Subset,,"I have a simple question but I can't seem to find the answer anywhere. Say that I have a set $\mathbb Z$ and a subset of that $\mathbb X$. I want to draw elements from $\mathbb Z$ until there is at least a 50% chance that I have drawn all the elements of $\mathbb X$. Clearly if $|\mathbb X| = 1$ then I just need to draw $\frac{|\mathbb Z|}{2}$. But how many will I need to draw if $|\mathbb X| > 1$? EDIT: GBQT made a good comment , I'm talking about drawing with replacement. Drawing element $e$ from $\mathbb Z$ does not preclude $e$ from being drawn again on subsequent draws. But $\mathbb X$ is finite, as in it has each element of $\mathbb X$ is unique.","I have a simple question but I can't seem to find the answer anywhere. Say that I have a set $\mathbb Z$ and a subset of that $\mathbb X$. I want to draw elements from $\mathbb Z$ until there is at least a 50% chance that I have drawn all the elements of $\mathbb X$. Clearly if $|\mathbb X| = 1$ then I just need to draw $\frac{|\mathbb Z|}{2}$. But how many will I need to draw if $|\mathbb X| > 1$? EDIT: GBQT made a good comment , I'm talking about drawing with replacement. Drawing element $e$ from $\mathbb Z$ does not preclude $e$ from being drawn again on subsequent draws. But $\mathbb X$ is finite, as in it has each element of $\mathbb X$ is unique.",,"['algebra-precalculus', 'elementary-set-theory', 'percentages']"
14,Examples of bijective map from $\mathbb{R}^3\rightarrow \mathbb{R}$,Examples of bijective map from,\mathbb{R}^3\rightarrow \mathbb{R},Could any one give an example of a bijective map from $\mathbb{R}^3\rightarrow \mathbb{R}$? Thank you.,Could any one give an example of a bijective map from $\mathbb{R}^3\rightarrow \mathbb{R}$? Thank you.,,"['real-analysis', 'elementary-set-theory', 'examples-counterexamples']"
15,The set $T=\{l\in\mathbb{N}: ml=nl \ \text{implies} \ m=n \}$ is inductive.,The set  is inductive.,T=\{l\in\mathbb{N}: ml=nl \ \text{implies} \ m=n \},"I'm trying to prove the following statement: $ml=nl$ implies $m=n$ for every $m,n,l\in \mathbb{N}$. So I defined the set  $T=\{l\in\mathbb{N}: ml=nl \  \text{implies} \ m=n \}$ and if I prove that $T$ is inductive, then I done. It is clear that $1\in T$. Suppose that $l\in T$, then I have that $ml=nl$ implies $m=n$. Now, if $m(l+1)=n(l+1)$ or $ml+m=nl+n$ how can one show that it implies $m=n$?","I'm trying to prove the following statement: $ml=nl$ implies $m=n$ for every $m,n,l\in \mathbb{N}$. So I defined the set  $T=\{l\in\mathbb{N}: ml=nl \  \text{implies} \ m=n \}$ and if I prove that $T$ is inductive, then I done. It is clear that $1\in T$. Suppose that $l\in T$, then I have that $ml=nl$ implies $m=n$. Now, if $m(l+1)=n(l+1)$ or $ml+m=nl+n$ how can one show that it implies $m=n$?",,"['elementary-set-theory', 'peano-axioms']"
16,The set is closed (resp. open) iff the complement set is open (resp. closed),The set is closed (resp. open) iff the complement set is open (resp. closed),,"There's a theorem in my small danish course book. Let $(M,d)$ be a metric space. Theorem : The concepts of open and closed are dual: A set $A\subseteq M$ is closed (resp. open) if and only if the complement set $\complement A$ is open (resp. closed). Proof : The formula $\complement \overline{A}=(\complement A)^{\circ}$ shows that $A=\overline{A}$ only if $(\complement A)^{\circ}=\complement A$, that is $A$ is closed, only if $\complement A$ is open. Using this on $\complement A$ insted of $A$, we get that $A$ is open only if $\complement  A$ is closed. I don't think the proof is useful. Here's what I want to prove; \begin{align*} \overline{A}=A\iff (\complement A)^{\circ}=\complement A\tag{1}\\ A^{\circ}=A\iff \overline{\complement A}=\complement A\tag{2}. \end{align*} Note this course book has some of few formulas without proofs added. Case $(1)$. $\implies:$ Assume that $\overline{A}=A$. We'll use the formula $\complement \overline{A}=(\complement A)^{\circ}$. Since $\complement \overline{A}= \complement A$, we have $\complement A=(\complement A)^{\circ}$. $\impliedby:$ Assume that $\complement A=(\complement A)^{\circ}$. We'll use the formula $\overline{A}=\complement((\complement A)^{\circ})$. We have $\overline{A}=\complement((\complement A)^{\circ})=\complement(\complement A)=A$. Case $(2)$. $\implies:$ Assume that $A^{\circ}=A$. We will use the formula $\overline{A}=A^{\circ}\cup \partial A$. We have $$\overline{\complement A}=(\complement A)^{\circ}\cup \partial(\complement A)=(\complement A)^{\circ}\cup \partial A=M\setminus A^{\circ}=M\setminus A=\complement A.$$ $\impliedby:$ This one I need help with. What do you think about my proof so far? I know that there are other proofs available in some websites but I would like to write it differently.","There's a theorem in my small danish course book. Let $(M,d)$ be a metric space. Theorem : The concepts of open and closed are dual: A set $A\subseteq M$ is closed (resp. open) if and only if the complement set $\complement A$ is open (resp. closed). Proof : The formula $\complement \overline{A}=(\complement A)^{\circ}$ shows that $A=\overline{A}$ only if $(\complement A)^{\circ}=\complement A$, that is $A$ is closed, only if $\complement A$ is open. Using this on $\complement A$ insted of $A$, we get that $A$ is open only if $\complement  A$ is closed. I don't think the proof is useful. Here's what I want to prove; \begin{align*} \overline{A}=A\iff (\complement A)^{\circ}=\complement A\tag{1}\\ A^{\circ}=A\iff \overline{\complement A}=\complement A\tag{2}. \end{align*} Note this course book has some of few formulas without proofs added. Case $(1)$. $\implies:$ Assume that $\overline{A}=A$. We'll use the formula $\complement \overline{A}=(\complement A)^{\circ}$. Since $\complement \overline{A}= \complement A$, we have $\complement A=(\complement A)^{\circ}$. $\impliedby:$ Assume that $\complement A=(\complement A)^{\circ}$. We'll use the formula $\overline{A}=\complement((\complement A)^{\circ})$. We have $\overline{A}=\complement((\complement A)^{\circ})=\complement(\complement A)=A$. Case $(2)$. $\implies:$ Assume that $A^{\circ}=A$. We will use the formula $\overline{A}=A^{\circ}\cup \partial A$. We have $$\overline{\complement A}=(\complement A)^{\circ}\cup \partial(\complement A)=(\complement A)^{\circ}\cup \partial A=M\setminus A^{\circ}=M\setminus A=\complement A.$$ $\impliedby:$ This one I need help with. What do you think about my proof so far? I know that there are other proofs available in some websites but I would like to write it differently.",,"['general-topology', 'elementary-set-theory', 'proof-verification']"
17,Order for sets in the real line,Order for sets in the real line,,"Consider the sets $[0,1]$ and $[1,2]$. I want to say that $[1,2]$ is greater than $[0,1]$. Is there a set order such that $$A \geq B \quad \text{if} \quad \inf A \geq \sup B.$$ What is the name of such order?","Consider the sets $[0,1]$ and $[1,2]$. I want to say that $[1,2]$ is greater than $[0,1]$. Is there a set order such that $$A \geq B \quad \text{if} \quad \inf A \geq \sup B.$$ What is the name of such order?",,"['elementary-set-theory', 'order-theory']"
18,Proof check:$ \left | \mathbb{R} \right |= 2^{\left|\mathbb{N} \right |}$,Proof check:, \left | \mathbb{R} \right |= 2^{\left|\mathbb{N} \right |},"This is my first time to post here. Sorry if this post is too simple or naive. Here I would like to prove that $\left | \mathbb{R} \right |= 2^{\left |\mathbb{N}  \right |}$ I would first construct a bijective mapping from $\mathbb{R}$ to [0,1) like this: $$f(x)=\begin{cases} \frac{1}{x-2}+\frac{1}{2}&\text{if } x<0\\  0&\text{if } x=0\\  \frac{1}{x+2} & \text{if } x>0 \end{cases}$$ Sorry this missed the $\frac{1}{2}$. I will fill this 'gap' by mapping $\frac{1}{4}$ to $\frac{1}{2}$, $\frac{1}{8}$ to $\frac{1}{4}$, etc... and the others just keep it. So now I have $\left | \mathbb{R} \right |= \left | [0,1) \right |$ Consider the binary representation of each element in $[0,1)$. If it has a finite representation, add zero's behind to make it infinite. As the cardinality of the length of each representation equals $\left|\mathbb{N}\right|$, I have $\left|\mathbb{R}\right|=2^{\left|\mathbb{N}\right|}$. Q.E.D. My question is: is the last part of my proof not clear or strict enough? How can I improve it? Any help or suggestion is appreciated. Thank you! :D","This is my first time to post here. Sorry if this post is too simple or naive. Here I would like to prove that $\left | \mathbb{R} \right |= 2^{\left |\mathbb{N}  \right |}$ I would first construct a bijective mapping from $\mathbb{R}$ to [0,1) like this: $$f(x)=\begin{cases} \frac{1}{x-2}+\frac{1}{2}&\text{if } x<0\\  0&\text{if } x=0\\  \frac{1}{x+2} & \text{if } x>0 \end{cases}$$ Sorry this missed the $\frac{1}{2}$. I will fill this 'gap' by mapping $\frac{1}{4}$ to $\frac{1}{2}$, $\frac{1}{8}$ to $\frac{1}{4}$, etc... and the others just keep it. So now I have $\left | \mathbb{R} \right |= \left | [0,1) \right |$ Consider the binary representation of each element in $[0,1)$. If it has a finite representation, add zero's behind to make it infinite. As the cardinality of the length of each representation equals $\left|\mathbb{N}\right|$, I have $\left|\mathbb{R}\right|=2^{\left|\mathbb{N}\right|}$. Q.E.D. My question is: is the last part of my proof not clear or strict enough? How can I improve it? Any help or suggestion is appreciated. Thank you! :D",,"['elementary-set-theory', 'proof-verification', 'cardinals']"
19,Why is this not a proof of Schroeder-Bernstein?,Why is this not a proof of Schroeder-Bernstein?,,"We can show that if $f: A \rightarrow B$ is injective then $|A| \leq |B|$ and if $g: B \rightarrow A$ is injective then $|B| \leq |A|$ so $|A| = |B|$. By the definition of having equal cardinality, there exists a bijection between $A$ and $B$. Whenever a textbook proves the theorem, however, a more complicated proof is shown. I must be missing something.","We can show that if $f: A \rightarrow B$ is injective then $|A| \leq |B|$ and if $g: B \rightarrow A$ is injective then $|B| \leq |A|$ so $|A| = |B|$. By the definition of having equal cardinality, there exists a bijection between $A$ and $B$. Whenever a textbook proves the theorem, however, a more complicated proof is shown. I must be missing something.",,['elementary-set-theory']
20,Computing the union and intersection of family of sets,Computing the union and intersection of family of sets,,"Suppose we are given for all $n \in \mathbb{N} $ $$ X_n = \{ (x,y) \in \mathbb{R} \times \mathbb{R} : n^2 \leq x^2 + y^2 \leq (n+1)^2 \} $$ I am trying to compute $\bigcup_{n \in \mathbb{N} } X_n $ and $\bigcap X_n $ My try: I was trying to draw the various annulus for varying values of $n$. Certainly, I find that $\bigcup X_n $ should be entire plane since this annulus keep expanding as $n$ grows. As for the intersection, it would just be the smallest annulus. That is  $ \bigcap X_n = \{ (x,y) : 1 \leq x^2 + y^2 \leq 4 \} $. My question is: How can I prove this rigorously? thanks","Suppose we are given for all $n \in \mathbb{N} $ $$ X_n = \{ (x,y) \in \mathbb{R} \times \mathbb{R} : n^2 \leq x^2 + y^2 \leq (n+1)^2 \} $$ I am trying to compute $\bigcup_{n \in \mathbb{N} } X_n $ and $\bigcap X_n $ My try: I was trying to draw the various annulus for varying values of $n$. Certainly, I find that $\bigcup X_n $ should be entire plane since this annulus keep expanding as $n$ grows. As for the intersection, it would just be the smallest annulus. That is  $ \bigcap X_n = \{ (x,y) : 1 \leq x^2 + y^2 \leq 4 \} $. My question is: How can I prove this rigorously? thanks",,[]
21,How to generate families of sets without replacement symmetry?,How to generate families of sets without replacement symmetry?,,"I need to generate a family of sets with as few symmetries as possible. If convenient, let the size of each elements of the family be a fixed $s$ and the number of elements in the family be a fixed $n$. For my purposes, the set $\{\{a,b\},\{a,c\}\}$ in universe $U=\{a,b,c,d\}$ is equivalent to $\{\{b,a\},\{b,c\}\}$ (with $a$ and $b$ swapped) and also $\{\{d,b\},\{d,c\}\}$ (with $a$ and $d$ swapped). If you swap the names of any two variables, it doesn't change the underlying structure. What are the formal names of this kind of equivalency? Given a universe set and size of the family how does one generate all possible families with no elements being equivalent under these conditions? I apologize if this is a well known problem. Searching hasn't really helped, I suspect because I'm using the wrong language to describe it.","I need to generate a family of sets with as few symmetries as possible. If convenient, let the size of each elements of the family be a fixed $s$ and the number of elements in the family be a fixed $n$. For my purposes, the set $\{\{a,b\},\{a,c\}\}$ in universe $U=\{a,b,c,d\}$ is equivalent to $\{\{b,a\},\{b,c\}\}$ (with $a$ and $b$ swapped) and also $\{\{d,b\},\{d,c\}\}$ (with $a$ and $d$ swapped). If you swap the names of any two variables, it doesn't change the underlying structure. What are the formal names of this kind of equivalency? Given a universe set and size of the family how does one generate all possible families with no elements being equivalent under these conditions? I apologize if this is a well known problem. Searching hasn't really helped, I suspect because I'm using the wrong language to describe it.",,['elementary-set-theory']
22,Writing some basic sentences in the language of set theory.,Writing some basic sentences in the language of set theory.,,"I am having some trouble proving that some basic sentences in the language $L_\in$ of first order set theory are $\Sigma_1$ or $\Pi_1$, the reason being that I do not know how exactly to write them. Unfortunately in most books dealing with ranks $\Sigma_n$ and $\Pi_n$ this knowledge is assumed which makes my life complicated. Now an introduction. Every quantifier free formula is $\Delta_0$. If $\phi$ and $\varphi$ are $\Delta_0$ then so is $\phi\wedge\varphi$ and $\neg\phi$ and finally if $\varphi$ is $\Delta_0$ then $(\exists x)(x\in y\wedge \phi)$ is also $\Delta_0$. A formula is $\Sigma_1$ if of the form $(\exists x)\phi$ for $\phi\in\Delta_0$ and in $\Pi_1$ if can we writen as $(\forall x)\phi$ for $\phi\in\Delta_0$. I would like to see that the following sentences are $\Sigma_1$ formulas: 1) $\alpha$ is not a cardinal (initial ordinal) 2) $cf(\alpha)\leq \beta$ 3) $\alpha$ is singular. 4) $|x|\leq |y|$ And the following are $\Pi_1$: 1) $\alpha$ is a cardinal. 2) $cf(\alpha)$ is regular. 3) $\alpha$ is weakly inaccessible 4) $y=P(x)$ The first one for example asks to write ""$\alpha$ is an ordinal and there is $\beta <\alpha$ and a surjection from $\beta$ to $\alpha$"". So it could be written as as ""exists $f$ function such that for some $\beta<\alpha$, $f$ is a surjection form $\beta$ to $\alpha$"". Now this I can see as $\Sigma_1$ formula, however I still doubt if the solution is correct. Other question arise like, given $x$ and $y$ fixed, if we range a variable among functions with domain in $x$ and range in $y$, is that not a bounded quantifier? That is, is the sentence ""$(\exists f)(f \text{ is a function } \wedge dom(f)\subset x \wedge rg(f)\subset y$)"" in $\Delta_0$?","I am having some trouble proving that some basic sentences in the language $L_\in$ of first order set theory are $\Sigma_1$ or $\Pi_1$, the reason being that I do not know how exactly to write them. Unfortunately in most books dealing with ranks $\Sigma_n$ and $\Pi_n$ this knowledge is assumed which makes my life complicated. Now an introduction. Every quantifier free formula is $\Delta_0$. If $\phi$ and $\varphi$ are $\Delta_0$ then so is $\phi\wedge\varphi$ and $\neg\phi$ and finally if $\varphi$ is $\Delta_0$ then $(\exists x)(x\in y\wedge \phi)$ is also $\Delta_0$. A formula is $\Sigma_1$ if of the form $(\exists x)\phi$ for $\phi\in\Delta_0$ and in $\Pi_1$ if can we writen as $(\forall x)\phi$ for $\phi\in\Delta_0$. I would like to see that the following sentences are $\Sigma_1$ formulas: 1) $\alpha$ is not a cardinal (initial ordinal) 2) $cf(\alpha)\leq \beta$ 3) $\alpha$ is singular. 4) $|x|\leq |y|$ And the following are $\Pi_1$: 1) $\alpha$ is a cardinal. 2) $cf(\alpha)$ is regular. 3) $\alpha$ is weakly inaccessible 4) $y=P(x)$ The first one for example asks to write ""$\alpha$ is an ordinal and there is $\beta <\alpha$ and a surjection from $\beta$ to $\alpha$"". So it could be written as as ""exists $f$ function such that for some $\beta<\alpha$, $f$ is a surjection form $\beta$ to $\alpha$"". Now this I can see as $\Sigma_1$ formula, however I still doubt if the solution is correct. Other question arise like, given $x$ and $y$ fixed, if we range a variable among functions with domain in $x$ and range in $y$, is that not a bounded quantifier? That is, is the sentence ""$(\exists f)(f \text{ is a function } \wedge dom(f)\subset x \wedge rg(f)\subset y$)"" in $\Delta_0$?",,['elementary-set-theory']
23,Looking for info on power set functor,Looking for info on power set functor,,"I was reading here about the various functors which take a set $S$ to its power set. In particular, there is the normal contravariant one, and two covariant ones, which the article calls $\exists$ and $\forall$. I'd like a little more information on these functors and their properties. In particular, I'm interested in how these might play in to proofs in point-set topology...for instance the relation between the fact that $\forall$ plays nice with intersections and the fact that the regular forward image plays nice with intersections as long as at most one of the sets fails to be saturated. I think these might provide a simple way to look at the rules we need to remember when we manipulate sets in point-set topology. (I previously wrote a poor version of this question here , and this is a new version.)","I was reading here about the various functors which take a set $S$ to its power set. In particular, there is the normal contravariant one, and two covariant ones, which the article calls $\exists$ and $\forall$. I'd like a little more information on these functors and their properties. In particular, I'm interested in how these might play in to proofs in point-set topology...for instance the relation between the fact that $\forall$ plays nice with intersections and the fact that the regular forward image plays nice with intersections as long as at most one of the sets fails to be saturated. I think these might provide a simple way to look at the rules we need to remember when we manipulate sets in point-set topology. (I previously wrote a poor version of this question here , and this is a new version.)",,"['general-topology', 'elementary-set-theory', 'category-theory']"
24,Prove $B ⊆ (C ∪ A) ⇔ (B \setminus A) ⊆ C$,Prove,B ⊆ (C ∪ A) ⇔ (B \setminus A) ⊆ C,"Prove the following: \begin{align} B ⊆ (C ∪ A) &⇒ (B\setminus A) ⊆ C \\ (B\setminus A) ⊆ C &⇒ B ⊆ (C ∪ A) \end{align} Using Eulerian circles I only understood that statements are true. Still have no idea how to prove. Any hints guys? (not asking for complete solution, need just an idea to start with). Would appreciate any help. :-)","Prove the following: \begin{align} B ⊆ (C ∪ A) &⇒ (B\setminus A) ⊆ C \\ (B\setminus A) ⊆ C &⇒ B ⊆ (C ∪ A) \end{align} Using Eulerian circles I only understood that statements are true. Still have no idea how to prove. Any hints guys? (not asking for complete solution, need just an idea to start with). Would appreciate any help. :-)",,[]
25,Disjoint subsets and Number of 1's in the binary representation,Disjoint subsets and Number of 1's in the binary representation,,"For a subset $S$ of $[n]$, let $\chi(S)$ denote the $n$ bit 'characterisitc vector' of $S$, i.e., $\chi(S)=(a_1, a_2, \ldots, a_n)$ where $a_i=1$ if $i \in S$ and $a_i=0 $ if $i \notin S$. Think of $\chi(S)$ as an $n$ bit binary number and let $D(\chi(S))$ denote the decimal representation of $\chi(S)$. Let $A, B \subseteq [n]$. The question is to show that $A \cap B = \varnothing$ if and only if the number of 1's in the binary representation of $D(\chi(A))+ D(\chi(B)) = |A|+|B|$. I could prove the forward direction: Observe that $D(\chi(S))= \sum_{i \in S} 2^{n-i}$ and the number of 1's in $\chi(S)= |S|$. Then if $A \cap B = \varnothing$, $$D(\chi(A))+ D(\chi(B)) = \sum_{i \in A} 2^{n-i} + \sum_{i \in B} 2^{n-i} = \sum_{i \in A \cup B} 2^{n-i} = D(\chi(A \cup B))$$ Then \begin{equation} \begin{split} \text{number of 1's in the binary representation of }\ D(\chi(A))+D(\chi(B)) \\ = \text{number of 1's in the binary representation of}\ D(\chi(A \cup B))  = \text{number of 1's in}\ \chi(A \cup B) = {|A \cup B|}  =|A|+|B| \end{split} \end{equation} To prove the converse, we have,  \begin{equation} \begin{split} D(\chi(A))+ D(\chi(B)) & = \sum_{i \in A} 2^{n-i} + \sum_{i \in B} 2^{n-i} \\  &= \sum_{i \in A \cup B} 2^{n-i} + \sum_{i \in A \cap B} 2^{n-i} \\  &= D(\chi(A \cup B))+ D(\chi(A \cap B)) \end{split} \end{equation} But I don't quite see how to reach the conclusion from here. Hints will be appreciated.","For a subset $S$ of $[n]$, let $\chi(S)$ denote the $n$ bit 'characterisitc vector' of $S$, i.e., $\chi(S)=(a_1, a_2, \ldots, a_n)$ where $a_i=1$ if $i \in S$ and $a_i=0 $ if $i \notin S$. Think of $\chi(S)$ as an $n$ bit binary number and let $D(\chi(S))$ denote the decimal representation of $\chi(S)$. Let $A, B \subseteq [n]$. The question is to show that $A \cap B = \varnothing$ if and only if the number of 1's in the binary representation of $D(\chi(A))+ D(\chi(B)) = |A|+|B|$. I could prove the forward direction: Observe that $D(\chi(S))= \sum_{i \in S} 2^{n-i}$ and the number of 1's in $\chi(S)= |S|$. Then if $A \cap B = \varnothing$, $$D(\chi(A))+ D(\chi(B)) = \sum_{i \in A} 2^{n-i} + \sum_{i \in B} 2^{n-i} = \sum_{i \in A \cup B} 2^{n-i} = D(\chi(A \cup B))$$ Then \begin{equation} \begin{split} \text{number of 1's in the binary representation of }\ D(\chi(A))+D(\chi(B)) \\ = \text{number of 1's in the binary representation of}\ D(\chi(A \cup B))  = \text{number of 1's in}\ \chi(A \cup B) = {|A \cup B|}  =|A|+|B| \end{split} \end{equation} To prove the converse, we have,  \begin{equation} \begin{split} D(\chi(A))+ D(\chi(B)) & = \sum_{i \in A} 2^{n-i} + \sum_{i \in B} 2^{n-i} \\  &= \sum_{i \in A \cup B} 2^{n-i} + \sum_{i \in A \cap B} 2^{n-i} \\  &= D(\chi(A \cup B))+ D(\chi(A \cap B)) \end{split} \end{equation} But I don't quite see how to reach the conclusion from here. Hints will be appreciated.",,"['combinatorics', 'elementary-set-theory']"
26,Basic question on application of Sunflower lemma,Basic question on application of Sunflower lemma,,"A sunflower or $\Delta$- system is a collection of sets $\mathscr{F}$ whose pairwise intersections are all the same set $S$, possibly empty.  Elements of the collection of sets $\mathscr{F}$ are called ""petals"". Sunflower lemma states that: Let $F$ be a family of sets each of cardinality $s$.    If $|F| > s! (k-1)^s$, then $F$ contains a sunflower with (at least) $k$ petals. This is an area I am not familiar with and this might be a bit silly question.  But I was just wondering, can I apply this result when $F$ is a family of sets of polynomials over a finite field? (Does it matter it is non-zero characteristic by any chance?)","A sunflower or $\Delta$- system is a collection of sets $\mathscr{F}$ whose pairwise intersections are all the same set $S$, possibly empty.  Elements of the collection of sets $\mathscr{F}$ are called ""petals"". Sunflower lemma states that: Let $F$ be a family of sets each of cardinality $s$.    If $|F| > s! (k-1)^s$, then $F$ contains a sunflower with (at least) $k$ petals. This is an area I am not familiar with and this might be a bit silly question.  But I was just wondering, can I apply this result when $F$ is a family of sets of polynomials over a finite field? (Does it matter it is non-zero characteristic by any chance?)",,"['combinatorics', 'elementary-set-theory']"
27,What are some examples of isotrophic sets?,What are some examples of isotrophic sets?,,"What are some examples of isotrophic sets? and is there a ""good"" way to describe them? Isotrophic meaning that a random vector X uniformly distributed in the set has the isotrophic property  for all $x \in  R^n $  expected value $ E(\langle x,X\rangle^2 )= ||x||_2 ^2$","What are some examples of isotrophic sets? and is there a ""good"" way to describe them? Isotrophic meaning that a random vector X uniformly distributed in the set has the isotrophic property  for all $x \in  R^n $  expected value $ E(\langle x,X\rangle^2 )= ||x||_2 ^2$",,"['probability', 'elementary-set-theory', 'convex-analysis', 'uniform-distribution']"
28,Clarification on the definition of $X^{\omega}$,Clarification on the definition of,X^{\omega},"I have never seen this notation before (graduated with a math degree a few months ago; not in school currently). Here's what I gather from Munkres' Topology : Given a set $X$, an $\mathbf{\omega}$ -tuple of elements of $X$   is a function \begin{equation*} \mathbf{x}: \mathbb{N} \to  X\text{.} \end{equation*} Such a function is called a sequence or infinite sequence of elements of $X$. The $i$th value of $\mathbf{x}$ at $i$ is $x_i$, known as the $i$ th coordinate of   $\mathbf{x}$ and denote \begin{equation*} \mathbf{x} =  \left(x_1, x_2, \dots\right) = \left(x_n\right)_{n \in  \mathbb{N}}\text{.} \end{equation*} As an example, Munkres mentions $X^{\omega}$, where $X = \{0, 1\}$. What is $X^{\omega}$ in this case? The set of all $\omega$-tuples where each coordinate can either be a $0$ or $1$? So am I correct in thinking that  $$X^{\omega} = \{(x_1, \dots, x_{\omega}): x_i = 0 \text{ or }1\}\text{?}$$ Can $\omega$ be finite, as well as infinite?","I have never seen this notation before (graduated with a math degree a few months ago; not in school currently). Here's what I gather from Munkres' Topology : Given a set $X$, an $\mathbf{\omega}$ -tuple of elements of $X$   is a function \begin{equation*} \mathbf{x}: \mathbb{N} \to  X\text{.} \end{equation*} Such a function is called a sequence or infinite sequence of elements of $X$. The $i$th value of $\mathbf{x}$ at $i$ is $x_i$, known as the $i$ th coordinate of   $\mathbf{x}$ and denote \begin{equation*} \mathbf{x} =  \left(x_1, x_2, \dots\right) = \left(x_n\right)_{n \in  \mathbb{N}}\text{.} \end{equation*} As an example, Munkres mentions $X^{\omega}$, where $X = \{0, 1\}$. What is $X^{\omega}$ in this case? The set of all $\omega$-tuples where each coordinate can either be a $0$ or $1$? So am I correct in thinking that  $$X^{\omega} = \{(x_1, \dots, x_{\omega}): x_i = 0 \text{ or }1\}\text{?}$$ Can $\omega$ be finite, as well as infinite?",,"['elementary-set-theory', 'notation']"
29,Existence of two unrelated pairs in a constrained relation,Existence of two unrelated pairs in a constrained relation,,"Given two sets $S, T$ and a relation defined by a set of pairs $R \subset S \times T$, such that: $$  \exists \, s_1, s_2  \in S : s_1 \neq s_2 \\  \exists \, t_1, t_2  \in T : t_1 \neq t_2 \\  \forall s \in S \, \exists \, t \in T : (s,t) \in R \\ \forall t \in T \, \exists \, s \in S : (s,t) \not \in R  $$ Show that  $$ \exists \, s, s' \in S : \exists\, t, t' \in T : \left[ (s,t) \in R \right] \wedge \left[ (s', t') \in R \right] \wedge \left[ (s,t') \not \in R \right]  \wedge \left[ (s',t) \not \in R \right]  $$ For $S$ and $T$ finite,  I can prove this by induction on the numbers of elements in $S$ and $T$. This is a statement of an old Putnam problem saying that if at a party every boy dances with at least one girl and no girl dances with every boy, then there exists a pair of couples such that $b$ danced with $g$ and $b'$ danced with $g'$ but $b$ did not dance with $g'$ nor $b'$ with $g$. Equivalent to the proof by induction, I think, is a proof by considering a minimal example of $S$ and $T$ which violates the proposition, and removing one member of $S$ or $T$, and looking at the properties of the remaining set, to show that then purported minimal violating set actually obeys the proposition.  (For example, a step in this proof would be to say that  the reduced sets cannot have a ""qualified"" duo of pairs since that would be qualified in the full sets; so either there is a universal $T$ or a no-relation $S$, and in either case adding back the removed element yields a qualified duo of pairs.) My question concerns proving the proposition when $S$ and $T$ may be infinite, and in particular, may be uncountably infinite.  It looks to me as if the same sort of proof requires at least the axiom of choice, but maybe it can be done with just transfinite induction. I'm shaky as to when a step in my proof implicitly assumes AC, so any help would be appreciated.","Given two sets $S, T$ and a relation defined by a set of pairs $R \subset S \times T$, such that: $$  \exists \, s_1, s_2  \in S : s_1 \neq s_2 \\  \exists \, t_1, t_2  \in T : t_1 \neq t_2 \\  \forall s \in S \, \exists \, t \in T : (s,t) \in R \\ \forall t \in T \, \exists \, s \in S : (s,t) \not \in R  $$ Show that  $$ \exists \, s, s' \in S : \exists\, t, t' \in T : \left[ (s,t) \in R \right] \wedge \left[ (s', t') \in R \right] \wedge \left[ (s,t') \not \in R \right]  \wedge \left[ (s',t) \not \in R \right]  $$ For $S$ and $T$ finite,  I can prove this by induction on the numbers of elements in $S$ and $T$. This is a statement of an old Putnam problem saying that if at a party every boy dances with at least one girl and no girl dances with every boy, then there exists a pair of couples such that $b$ danced with $g$ and $b'$ danced with $g'$ but $b$ did not dance with $g'$ nor $b'$ with $g$. Equivalent to the proof by induction, I think, is a proof by considering a minimal example of $S$ and $T$ which violates the proposition, and removing one member of $S$ or $T$, and looking at the properties of the remaining set, to show that then purported minimal violating set actually obeys the proposition.  (For example, a step in this proof would be to say that  the reduced sets cannot have a ""qualified"" duo of pairs since that would be qualified in the full sets; so either there is a universal $T$ or a no-relation $S$, and in either case adding back the removed element yields a qualified duo of pairs.) My question concerns proving the proposition when $S$ and $T$ may be infinite, and in particular, may be uncountably infinite.  It looks to me as if the same sort of proof requires at least the axiom of choice, but maybe it can be done with just transfinite induction. I'm shaky as to when a step in my proof implicitly assumes AC, so any help would be appreciated.",,"['elementary-set-theory', 'logic', 'induction']"
30,Rules for translating quantifiers to set operations?,Rules for translating quantifiers to set operations?,,I had this excercise in measure theory where I had to show that certain sets are measurable and I realized there was some mechanical procedure going on. Here is the question: Let $f_n:X\to \mathbb{R}$ be measurable functions. Show the   measurability of the following sets: $A = \{x:f_n(x)\to \infty\}$ $B = \{x:f_n(x)\to -\infty\}$ $C = \{x:f_n(x)\to \exists \lim_{n\to \infty}f_n \text{  finite > limit}\}$ Here's my solution: $A= \bigcap_{M>1} \bigcup_{N>1} \bigcap_{n>N}\{x:f_n(x)>M\} \implies$Measurable $B= \bigcap_{M>1} \bigcup_{N>1} \bigcap_{n>N}\{x:f_n(x)<-M\} \implies$Measurable $C= \bigcap_{M>1} \bigcup_{N>1} \bigcap_{n>m>N}\{x:|f_m(x)-f_n(x)|<\frac{1}{M}\} \implies$Measurable Is it generally true that you can translate anything defined by quantifiers to unions and intersection using the rules $\exists \to \bigcup$ and $\forall \to \bigcap$?,I had this excercise in measure theory where I had to show that certain sets are measurable and I realized there was some mechanical procedure going on. Here is the question: Let $f_n:X\to \mathbb{R}$ be measurable functions. Show the   measurability of the following sets: $A = \{x:f_n(x)\to \infty\}$ $B = \{x:f_n(x)\to -\infty\}$ $C = \{x:f_n(x)\to \exists \lim_{n\to \infty}f_n \text{  finite > limit}\}$ Here's my solution: $A= \bigcap_{M>1} \bigcup_{N>1} \bigcap_{n>N}\{x:f_n(x)>M\} \implies$Measurable $B= \bigcap_{M>1} \bigcup_{N>1} \bigcap_{n>N}\{x:f_n(x)<-M\} \implies$Measurable $C= \bigcap_{M>1} \bigcup_{N>1} \bigcap_{n>m>N}\{x:|f_m(x)-f_n(x)|<\frac{1}{M}\} \implies$Measurable Is it generally true that you can translate anything defined by quantifiers to unions and intersection using the rules $\exists \to \bigcup$ and $\forall \to \bigcap$?,,['measure-theory']
31,an introduction to axiomatic set theory that is not enderton,an introduction to axiomatic set theory that is not enderton,,"So I've been reading Endertons Elements of set theory which is easy to understand when it comes to the essential axioms, but there are a number of topics which seem to gloss over important information, as if the it were self explanatory. An example of one the confusing parts of the book which I am currently reading is the definition of the domain and range of a function; initially this makes sense, but then there is the use of a set with two consecutive arbitrary unions thrown in without any explanation. I don't know what this is, why its being used, or if this is some kind of error. Please correct me if I've made a mistake here but are there any more suitable books for introductory axiomatic set theory or is this the way I'm supposed to learn, by being exposed to ideas that are explained later on.","So I've been reading Endertons Elements of set theory which is easy to understand when it comes to the essential axioms, but there are a number of topics which seem to gloss over important information, as if the it were self explanatory. An example of one the confusing parts of the book which I am currently reading is the definition of the domain and range of a function; initially this makes sense, but then there is the use of a set with two consecutive arbitrary unions thrown in without any explanation. I don't know what this is, why its being used, or if this is some kind of error. Please correct me if I've made a mistake here but are there any more suitable books for introductory axiomatic set theory or is this the way I'm supposed to learn, by being exposed to ideas that are explained later on.",,[]
32,Topological proof for this set theory statement,Topological proof for this set theory statement,,"Let $\mathcal{A}$ be an algebra of set (in a space $X$), such that any subcollection of disjoint sets in $\mathcal{A}$ is finite. Prove that $\mathcal{A}$ is finite. I already found a boring brute force proof of this fact. But the finiteness property ""smell"" like a compactness argument of some sort - specifically, we seems to be lifting a local finiteness property to a global one. Hence I am looking for a slick purely topological proof of this fact. But for the life of me I can't figure out which topological structure to put on it to make the argument fall out. Anyone have any clues? Thank you.","Let $\mathcal{A}$ be an algebra of set (in a space $X$), such that any subcollection of disjoint sets in $\mathcal{A}$ is finite. Prove that $\mathcal{A}$ is finite. I already found a boring brute force proof of this fact. But the finiteness property ""smell"" like a compactness argument of some sort - specifically, we seems to be lifting a local finiteness property to a global one. Hence I am looking for a slick purely topological proof of this fact. But for the life of me I can't figure out which topological structure to put on it to make the argument fall out. Anyone have any clues? Thank you.",,"['general-topology', 'elementary-set-theory', 'alternative-proof']"
33,The cardinality of a union of two sets,The cardinality of a union of two sets,,"Assume that the cardinality of the union of two sets is continuum. How to prove that at least one of the sets has the cardinality of a continuum? I suppose that it's possible to cope with it, using the operations with cardinals (for example, something like $\mathfrak{c}+\mathfrak{c}=\mathfrak{c}$), but  i have no meaningful ideas. Could  you give me a hint, please? Thank you in advance.","Assume that the cardinality of the union of two sets is continuum. How to prove that at least one of the sets has the cardinality of a continuum? I suppose that it's possible to cope with it, using the operations with cardinals (for example, something like $\mathfrak{c}+\mathfrak{c}=\mathfrak{c}$), but  i have no meaningful ideas. Could  you give me a hint, please? Thank you in advance.",,"['elementary-set-theory', 'cardinals']"
34,Subsets of $ \mathbb Q $ of order type $ \omega^{\alpha}$ for each countable ordinal $\alpha $.,Subsets of  of order type  for each countable ordinal ., \mathbb Q   \omega^{\alpha} \alpha ,"My introductory text in Set Theory (Stillwell) includes an exercise (6.3.1) asking for an explicit example of a subset of $ \mathbb Q $ or order type $ \omega^2 $.  This seems straight forward enough.  I wish to generalize this, first by explicitly defining a sequence of sets $ A_n \subset \mathbb Q $ such that $ A_n $ has order type $ \omega^{n} $ and then seeing where we can go from there. (See Details below.) Taking the $limsup \{A_n\}$, I believe we get $A_{\omega} = \cup A_n$.  While my intuition carries me through $A_n$ for finite $n$, it is not entirely clear to me what $A_{\omega}$ looks like , or indeed if $A_{\omega}$ has order-type $\omega^{\omega}$.  I think it does.  If so, we should be able to carry on to generate $A_{\alpha}$ for each countable ordinal $\alpha$. Is this correct?  This is self-learning, so I don’t have anyone to refer to.  What is a better way of doing this so that intuition holds up past $\omega^{\omega}$? I am reading an introductory text but my question is more intermediate than introductory .  This is why I am unsure and seeking help.  For example, the text does not cover set-theoretic limits . DETAILS This is what I have done so far : First, let $A_1 = \mathbb N$. Clearly $A_1$ has order-type $\omega^1$. To make clear my approach I shall write $A_2$ in long hand .$$A_2 = \{ 1 - \frac12, 1 - \frac13, 1 - \frac14, \dots, 2 - \frac12, 2 - \frac13, \dots \} .$$ To generalise, given $A_n$, write $A_n = \{ a_1, a_2, \dots \}$, where $a_n \lt a_{n+1}$. Define $a_0 = 0$ and $d_i = a_i  - a_{i-1}$ for $i \gt 1$. Next, for each $i > 0$, let $$B_i = \{ a_i - (d_i \cdot \frac{1}{k}) : k \in \mathbb N \}.$$ Finally, we define $$A_{n+1} = \cup_i B_i$$ Defining our $A_n$ in this way should mean $A_n$ has order-type $\omega^n$.  Does this extend to infinite ordinals?","My introductory text in Set Theory (Stillwell) includes an exercise (6.3.1) asking for an explicit example of a subset of $ \mathbb Q $ or order type $ \omega^2 $.  This seems straight forward enough.  I wish to generalize this, first by explicitly defining a sequence of sets $ A_n \subset \mathbb Q $ such that $ A_n $ has order type $ \omega^{n} $ and then seeing where we can go from there. (See Details below.) Taking the $limsup \{A_n\}$, I believe we get $A_{\omega} = \cup A_n$.  While my intuition carries me through $A_n$ for finite $n$, it is not entirely clear to me what $A_{\omega}$ looks like , or indeed if $A_{\omega}$ has order-type $\omega^{\omega}$.  I think it does.  If so, we should be able to carry on to generate $A_{\alpha}$ for each countable ordinal $\alpha$. Is this correct?  This is self-learning, so I don’t have anyone to refer to.  What is a better way of doing this so that intuition holds up past $\omega^{\omega}$? I am reading an introductory text but my question is more intermediate than introductory .  This is why I am unsure and seeking help.  For example, the text does not cover set-theoretic limits . DETAILS This is what I have done so far : First, let $A_1 = \mathbb N$. Clearly $A_1$ has order-type $\omega^1$. To make clear my approach I shall write $A_2$ in long hand .$$A_2 = \{ 1 - \frac12, 1 - \frac13, 1 - \frac14, \dots, 2 - \frac12, 2 - \frac13, \dots \} .$$ To generalise, given $A_n$, write $A_n = \{ a_1, a_2, \dots \}$, where $a_n \lt a_{n+1}$. Define $a_0 = 0$ and $d_i = a_i  - a_{i-1}$ for $i \gt 1$. Next, for each $i > 0$, let $$B_i = \{ a_i - (d_i \cdot \frac{1}{k}) : k \in \mathbb N \}.$$ Finally, we define $$A_{n+1} = \cup_i B_i$$ Defining our $A_n$ in this way should mean $A_n$ has order-type $\omega^n$.  Does this extend to infinite ordinals?",,"['elementary-set-theory', 'self-learning', 'order-theory', 'ordinals']"
35,If $X$ is inductive then the set $\{ x \in X \mid x $ is transitive and $ x \notin x \}$ is inductive.,If  is inductive then the set  is transitive and  is inductive.,X \{ x \in X \mid x   x \notin x \},"Definition. We say that $A$ is an inductive set if $\varnothing\in A$, and whenever $x\in A$ then $x\cup\{x\}\in A$ as well. I am trying to prove the following exercise: If $X$ is inductive then the set $U = \{ x \in X \mid x $ is transitive and $ x \notin x \}$ is inductive. Proof: Let $\alpha \in U$, we have to show that $\alpha \cup \{ \alpha \} \in U$. But $\alpha \cup \{ \alpha \}$ is transitive since $(\beta \in \alpha \Rightarrow \beta \subseteq \alpha)$ and $(\alpha \subseteq \alpha \cup \{ \alpha \})$. Left to show: $\alpha \cup \{ \alpha \} \notin \alpha \cup \{ \alpha \}$. Suppose in contradiction that $\alpha \cup \{ \alpha \} \in \alpha \cup \{ \alpha \}$. This would imply $\alpha \cup \{ \alpha \} \in \alpha$ which implies $\alpha \in \alpha$ ($\alpha$ transitive). contradiction. Is my proof correct?","Definition. We say that $A$ is an inductive set if $\varnothing\in A$, and whenever $x\in A$ then $x\cup\{x\}\in A$ as well. I am trying to prove the following exercise: If $X$ is inductive then the set $U = \{ x \in X \mid x $ is transitive and $ x \notin x \}$ is inductive. Proof: Let $\alpha \in U$, we have to show that $\alpha \cup \{ \alpha \} \in U$. But $\alpha \cup \{ \alpha \}$ is transitive since $(\beta \in \alpha \Rightarrow \beta \subseteq \alpha)$ and $(\alpha \subseteq \alpha \cup \{ \alpha \})$. Left to show: $\alpha \cup \{ \alpha \} \notin \alpha \cup \{ \alpha \}$. Suppose in contradiction that $\alpha \cup \{ \alpha \} \in \alpha \cup \{ \alpha \}$. This would imply $\alpha \cup \{ \alpha \} \in \alpha$ which implies $\alpha \in \alpha$ ($\alpha$ transitive). contradiction. Is my proof correct?",,['elementary-set-theory']
36,Can $\mathbb A=\{f(x)\mid x\in\mathbb R\}$ be shortened as $\mathbb A=f(\mathbb R)$?,Can  be shortened as ?,\mathbb A=\{f(x)\mid x\in\mathbb R\} \mathbb A=f(\mathbb R),"Can $\mathbb A=\{f(x)\mid x\in\mathbb R\}$ be shortened as $\mathbb A=f(\mathbb R)$? I saw this notation in the IMO olympiad training materials (the solution to the Problem 16 (IMO 1999 Problem 6) here ). Because the source seems reliable, I believe the notation is correct, but can you confirm this?","Can $\mathbb A=\{f(x)\mid x\in\mathbb R\}$ be shortened as $\mathbb A=f(\mathbb R)$? I saw this notation in the IMO olympiad training materials (the solution to the Problem 16 (IMO 1999 Problem 6) here ). Because the source seems reliable, I believe the notation is correct, but can you confirm this?",,"['elementary-set-theory', 'notation']"
37,What does $F = 2^W$ mean?,What does  mean?,F = 2^W,I'm reading the book Reasoning about uncertainty and having some problems with the notation. $F = 2^W$ where $W$ is a set and $F$ an algebra. What this mean?,I'm reading the book Reasoning about uncertainty and having some problems with the notation. $F = 2^W$ where $W$ is a set and $F$ an algebra. What this mean?,,"['elementary-set-theory', 'notation']"
38,Cantor's theorem via non-injectivity.,Cantor's theorem via non-injectivity.,,"The usual proof of Cantor's theorem proceeds as follows. Let $X$ denote a set and consider a function $F : X \rightarrow \mathcal{P}(X)$. Then we define $D \in \mathcal{P}(X)$ by writing $D = \{x \in X \mid x \notin F(x)\}$, observe that $D$ is not in the image of $F$, and thereby conclude that $F$ is non-surjective. Question. Without using CBS , is there a proof of Cantor's theorem that proceeds by considering a function $f : \mathcal{P}(X) \rightarrow X,$ and finds distinct elements $C,D \in \mathcal{P}(X)$ such that $f(C) = f(D)$? Thereby showing that $f$ is non-injective.","The usual proof of Cantor's theorem proceeds as follows. Let $X$ denote a set and consider a function $F : X \rightarrow \mathcal{P}(X)$. Then we define $D \in \mathcal{P}(X)$ by writing $D = \{x \in X \mid x \notin F(x)\}$, observe that $D$ is not in the image of $F$, and thereby conclude that $F$ is non-surjective. Question. Without using CBS , is there a proof of Cantor's theorem that proceeds by considering a function $f : \mathcal{P}(X) \rightarrow X,$ and finds distinct elements $C,D \in \mathcal{P}(X)$ such that $f(C) = f(D)$? Thereby showing that $f$ is non-injective.",,['elementary-set-theory']
39,"Proof:""Infinite subset of $\mathbb N$ is countable [duplicate]","Proof:""Infinite subset of  is countable [duplicate]",\mathbb N,"This question already has an answer here : Help with a proof. Countable sets. (1 answer) Closed 9 years ago . I've read a proof of the statement :""An infinite subset of $\mathbb N$ is countable; that is, if $A \subset \mathbb N$ and if $A$ is infinite, then $A$ is equivalent to $\mathbb N$ ."" in Carothers' textbook and there is one part of the proof I don't understand. Proof Recall that $\mathbb N$ is well ordered. That is, each nonempty subset of $\mathbb N$ has a smallest element. Thus, since $A \ne \emptyset$ , there is a smallest element $x_1 \in A$ . Then $A \setminus \{x_1\} \ne \emptyset$ , and there must be a smallest $x_2 \in A \setminus \{x_1\}$ . But now $A \setminus \{x_1,x_2\} \ne \emptyset$ , and so we continue, setting $x_3=\min(A \setminus \{x_1,x_2\})$ . By induction, we can find $x_1,x_2,x_3,...,x_n,... \in A$ , where $x_n=\min(A \setminus \{x_1,...,x_{n-1}\})$ . How do we know that this process exhausts $A$ ? Well, suppose that $x \in A \setminus \{x_1,x_2,...\} \ne \emptyset$ . Then the set $\{k : x_k>x\}$ must be nonempty (otherwise we would have $x \in A$ and $x<x_1=\min A$ ) , and hence it has a least element. That is, there is some $n$ with $x_1<...<x_{n-1}<x<x_n$ . But this contradicts the choice of $x_n$ as the first element in $A \setminus \{x_1,...,x_{n-1}\}$ . Consequently, $A$ is countable. My questions It is affirmed that the set $\{k : x_k>x\}$ can't be empty (I don't get the reason Carothers gives for this being impossible). As I see it, if $\{k : x_k>x\}$ is empty, then $x_k \leq x$ for all $k$ . So the set $\{x_1,x_2,...\}$ obtained by the method of extracting the smallest element from each remaining nonempty subset of $\mathbb N$ is finite, but we've seen that the set constructed from choosing $x_n=\min(A \setminus \{x_1,...,x_{n-1}\})$ is infinite. So, wouldn't this be the reason why the set $\{k : x_k>x\}$ can't be empty rather than ""otherwise we would have $x \in A$ and $x<x_1=\min A$ ""?. I couldn't even understand why would $x$ be in $A$ instead of $x \in A \setminus \{x_1,x_2,...\}$ or why $x<x_1$ . I know it is a very small part of the proof but I would like to understand all the steps of it so I would appreciate if someone could clear up my doubt.","This question already has an answer here : Help with a proof. Countable sets. (1 answer) Closed 9 years ago . I've read a proof of the statement :""An infinite subset of is countable; that is, if and if is infinite, then is equivalent to ."" in Carothers' textbook and there is one part of the proof I don't understand. Proof Recall that is well ordered. That is, each nonempty subset of has a smallest element. Thus, since , there is a smallest element . Then , and there must be a smallest . But now , and so we continue, setting . By induction, we can find , where . How do we know that this process exhausts ? Well, suppose that . Then the set must be nonempty (otherwise we would have and ) , and hence it has a least element. That is, there is some with . But this contradicts the choice of as the first element in . Consequently, is countable. My questions It is affirmed that the set can't be empty (I don't get the reason Carothers gives for this being impossible). As I see it, if is empty, then for all . So the set obtained by the method of extracting the smallest element from each remaining nonempty subset of is finite, but we've seen that the set constructed from choosing is infinite. So, wouldn't this be the reason why the set can't be empty rather than ""otherwise we would have and ""?. I couldn't even understand why would be in instead of or why . I know it is a very small part of the proof but I would like to understand all the steps of it so I would appreciate if someone could clear up my doubt.","\mathbb N A \subset \mathbb N A A \mathbb N \mathbb N \mathbb N A \ne \emptyset x_1 \in A A \setminus \{x_1\} \ne \emptyset x_2 \in A \setminus \{x_1\} A \setminus \{x_1,x_2\} \ne \emptyset x_3=\min(A \setminus \{x_1,x_2\}) x_1,x_2,x_3,...,x_n,... \in A x_n=\min(A \setminus \{x_1,...,x_{n-1}\}) A x \in A \setminus \{x_1,x_2,...\} \ne \emptyset \{k : x_k>x\} x \in A x<x_1=\min A n x_1<...<x_{n-1}<x<x_n x_n A \setminus \{x_1,...,x_{n-1}\} A \{k : x_k>x\} \{k : x_k>x\} x_k \leq x k \{x_1,x_2,...\} \mathbb N x_n=\min(A \setminus \{x_1,...,x_{n-1}\}) \{k : x_k>x\} x \in A x<x_1=\min A x A x \in A \setminus \{x_1,x_2,...\} x<x_1","['elementary-set-theory', 'natural-numbers']"
40,Prove that $\operatorname{ran} f \subseteq \operatorname{dom} g \implies\operatorname{dom} (g \circ f)=\operatorname{dom} f$,Prove that,\operatorname{ran} f \subseteq \operatorname{dom} g \implies\operatorname{dom} (g \circ f)=\operatorname{dom} f,"Some preliminaries: A function $f$ is a binary relation such that $(x,y_1) \in f$ and $(x, y_2) \in f$ implies $y_1 = y_2$. $\operatorname{ran} f = \{y: \exists x$ such that $(x,y) \in f\}$ $\operatorname{dom} f = \{x: \exists y$ such that $(x, y) \in f\}$ $g \circ f = \{(x,y): \exists z$ such that $(x,z) \in f$ and $(z, y) \in g\}$ Can someone verify my proof? Prove that $\operatorname{ran} f \subseteq \operatorname{dom} g \implies\operatorname{dom} (g \circ f)=\operatorname{dom} f$ Let $x \in \operatorname{dom} f$. Then, $\exists y$ such that $(x,y) \in f$ Since $\operatorname{ran} f \subseteq \operatorname{dom} g$, we have $y \in \operatorname{dom} g$ But then, $\exists z$ such that $(y,z) \in g$ Since $(x,y) \in f$ and $y,z \in g$, $(x,z) \in g \circ f$ But then, $x \in \operatorname{dom} g \circ f$ So, $\operatorname{dom} f \subseteq \operatorname{dom} g \circ f$ Now, suppose $x \in \operatorname{dom} g \circ f$ Then, $\exists y$ such that $(x,y) \in g \circ f$. So, $\exists z$ such that $(x, z) \in f$ and $(z,y) \in g$ But then, $x \in \operatorname{dom} f$, since $(x,z) \in f$ So, $\operatorname{dom} g \circ f \subseteq \operatorname{dom} f$ Therefore, $\operatorname{dom} f = \operatorname{dom} g \circ f$","Some preliminaries: A function $f$ is a binary relation such that $(x,y_1) \in f$ and $(x, y_2) \in f$ implies $y_1 = y_2$. $\operatorname{ran} f = \{y: \exists x$ such that $(x,y) \in f\}$ $\operatorname{dom} f = \{x: \exists y$ such that $(x, y) \in f\}$ $g \circ f = \{(x,y): \exists z$ such that $(x,z) \in f$ and $(z, y) \in g\}$ Can someone verify my proof? Prove that $\operatorname{ran} f \subseteq \operatorname{dom} g \implies\operatorname{dom} (g \circ f)=\operatorname{dom} f$ Let $x \in \operatorname{dom} f$. Then, $\exists y$ such that $(x,y) \in f$ Since $\operatorname{ran} f \subseteq \operatorname{dom} g$, we have $y \in \operatorname{dom} g$ But then, $\exists z$ such that $(y,z) \in g$ Since $(x,y) \in f$ and $y,z \in g$, $(x,z) \in g \circ f$ But then, $x \in \operatorname{dom} g \circ f$ So, $\operatorname{dom} f \subseteq \operatorname{dom} g \circ f$ Now, suppose $x \in \operatorname{dom} g \circ f$ Then, $\exists y$ such that $(x,y) \in g \circ f$. So, $\exists z$ such that $(x, z) \in f$ and $(z,y) \in g$ But then, $x \in \operatorname{dom} f$, since $(x,z) \in f$ So, $\operatorname{dom} g \circ f \subseteq \operatorname{dom} f$ Therefore, $\operatorname{dom} f = \operatorname{dom} g \circ f$",,"['elementary-set-theory', 'proof-verification']"
41,Velleman's How to prove it. Partial order proof.,Velleman's How to prove it. Partial order proof.,,"Theorem: Suppose that $R$ is a partial order on $A$, $B_1 ⊆ A$, $B_2 ⊆ A$, $x_1$ is the least upper bound of $B_1$, and $x_2$ is the least upper bound of $B_2$. Prove that if $B_1 ⊆ B_2$ then $x_1Rx_2$. Analysis: The goal is to prove $(x_1,x_2)\in R$. This means $x_2$ is LARGER than $x_1$. The givens are: 1) $R$ is a partial order on $A$, $B_1 ⊆ A$, $B_2 ⊆ A$ 2)$x_1$ is the least upper bound of $B_1$($x_1$ is an upper bound of $B_1$ AND $x_1$ is the smallest element of $U_1$). Translated to logic symbols mean: $\forall b_1 \in B_1[(b_1,x_1)\in R]$ $\land$ $\forall a\in U_1[(x_1,a)\in R]$. Where $U_1$ is the set of all upper bounds of $B_1$. 3)$x_2$ is the least upper bound of $B_2$. Translated to logic symbols mean: $\forall b_2 \in B_2[(b_2,x_2)\in R]$ $\land$ $\forall c\in U_2[(x_2,c)\in R]$. Where $U_2$ is the set of all upper bounds of $B_2$. 4)$B_1 \subseteq B_2$ 5)Obviously $x_1\in U_1 \land x_2 \in U_2$.Both are also $\in A$. Am stuck at this point. I tried contrapositive, direct, contradiction but to no avail. I tried cases like $x_1=x_2 \lor x_1\neq x_2$ but to no avail. Some person wrote this proof: Suppose $B_1 \subseteq B_2$. Let $b_1$ be arbitrary element of $B_1$, then $(b_1 R x_1)$. It follows from our assumption that $b_1 \in B_2$. So $(b_1 R x_2)$, hence $x_2$ is also an upper bound of $B_1$. Since $x_1$ is least upper bound of $B_1$, so it is smaller than any other upper bound of $B_1$, hence $(x_1 R x_2)$. But I think it is wrong since the step ""Let $b_1$ be arbitrary element of $B_1$"" is unjustified(The only way to justify it is to have an existential quantifier[like $B_1$ is not a null set] in the givens which we don't have. Also the last part of it isn't justified(it assumes $x_1\in B_2$). Am I right ? Can someone lend a hand here ? It would be great if you just gave a hint then write the answer in a hidden box.","Theorem: Suppose that $R$ is a partial order on $A$, $B_1 ⊆ A$, $B_2 ⊆ A$, $x_1$ is the least upper bound of $B_1$, and $x_2$ is the least upper bound of $B_2$. Prove that if $B_1 ⊆ B_2$ then $x_1Rx_2$. Analysis: The goal is to prove $(x_1,x_2)\in R$. This means $x_2$ is LARGER than $x_1$. The givens are: 1) $R$ is a partial order on $A$, $B_1 ⊆ A$, $B_2 ⊆ A$ 2)$x_1$ is the least upper bound of $B_1$($x_1$ is an upper bound of $B_1$ AND $x_1$ is the smallest element of $U_1$). Translated to logic symbols mean: $\forall b_1 \in B_1[(b_1,x_1)\in R]$ $\land$ $\forall a\in U_1[(x_1,a)\in R]$. Where $U_1$ is the set of all upper bounds of $B_1$. 3)$x_2$ is the least upper bound of $B_2$. Translated to logic symbols mean: $\forall b_2 \in B_2[(b_2,x_2)\in R]$ $\land$ $\forall c\in U_2[(x_2,c)\in R]$. Where $U_2$ is the set of all upper bounds of $B_2$. 4)$B_1 \subseteq B_2$ 5)Obviously $x_1\in U_1 \land x_2 \in U_2$.Both are also $\in A$. Am stuck at this point. I tried contrapositive, direct, contradiction but to no avail. I tried cases like $x_1=x_2 \lor x_1\neq x_2$ but to no avail. Some person wrote this proof: Suppose $B_1 \subseteq B_2$. Let $b_1$ be arbitrary element of $B_1$, then $(b_1 R x_1)$. It follows from our assumption that $b_1 \in B_2$. So $(b_1 R x_2)$, hence $x_2$ is also an upper bound of $B_1$. Since $x_1$ is least upper bound of $B_1$, so it is smaller than any other upper bound of $B_1$, hence $(x_1 R x_2)$. But I think it is wrong since the step ""Let $b_1$ be arbitrary element of $B_1$"" is unjustified(The only way to justify it is to have an existential quantifier[like $B_1$ is not a null set] in the givens which we don't have. Also the last part of it isn't justified(it assumes $x_1\in B_2$). Am I right ? Can someone lend a hand here ? It would be great if you just gave a hint then write the answer in a hidden box.",,"['elementary-set-theory', 'proof-writing', 'proof-verification']"
42,Countably infinite set and uncountable collection of subsets,Countably infinite set and uncountable collection of subsets,,How can I Prove or disprove that every uncountable collection of subsets of a countably infinite set must have two members whose intersection has at least 2010 elements?,How can I Prove or disprove that every uncountable collection of subsets of a countably infinite set must have two members whose intersection has at least 2010 elements?,,['elementary-set-theory']
43,When can we have $(A+B)\cap C=A\cap C+B\cap C$?,When can we have ?,(A+B)\cap C=A\cap C+B\cap C,"With $A+B=\{a+b:a\in A, b\in B\}$ and any non-empty sets A,B,C. When can we have $(A+B)\cap C=A\cap C+B\cap C$? I am looking for the most general conditions (if any) such that the equality stands. Thanks Let's start by finding out what happens when $A,B,C\subset \mathbb{R}$.","With $A+B=\{a+b:a\in A, b\in B\}$ and any non-empty sets A,B,C. When can we have $(A+B)\cap C=A\cap C+B\cap C$? I am looking for the most general conditions (if any) such that the equality stands. Thanks Let's start by finding out what happens when $A,B,C\subset \mathbb{R}$.",,"['real-analysis', 'elementary-set-theory']"
44,"Prove that for every 2 elements in the set F of all functions from N to N, there's an element in F that's bigger than both","Prove that for every 2 elements in the set F of all functions from N to N, there's an element in F that's bigger than both",,"let there be $\ F$ the set of all functions from $\ N \rightarrow N$. K is a relation on F, for every f,g$\in$F , (f,g)$\in$K $\leftrightarrow$ for all $\ n\in N$, $\ f(n)\leq g(n)$ Prove that for every two elements in $\ F$, there exist an element that's bigger than both. in other words, given $\ f,g\in F$, proove that there's $\ h\in F$, that sustains $\ (g,h)\in K,(f,h)\in K$, $\ h$ is different from $\ f,g$. remark: h is not a constant element of F, it depends on f,g. my answer: for every $\ f,g\in F$, there's $\ h\in F$, such that $\ h(n)=f(n)+g(n)$ $\rightarrow f(n)\leq h(n), g(n)\leq h(n)\rightarrow (f,h)\in K,(g,h)\in K$ is it good?","let there be $\ F$ the set of all functions from $\ N \rightarrow N$. K is a relation on F, for every f,g$\in$F , (f,g)$\in$K $\leftrightarrow$ for all $\ n\in N$, $\ f(n)\leq g(n)$ Prove that for every two elements in $\ F$, there exist an element that's bigger than both. in other words, given $\ f,g\in F$, proove that there's $\ h\in F$, that sustains $\ (g,h)\in K,(f,h)\in K$, $\ h$ is different from $\ f,g$. remark: h is not a constant element of F, it depends on f,g. my answer: for every $\ f,g\in F$, there's $\ h\in F$, such that $\ h(n)=f(n)+g(n)$ $\rightarrow f(n)\leq h(n), g(n)\leq h(n)\rightarrow (f,h)\in K,(g,h)\in K$ is it good?",,"['elementary-set-theory', 'order-theory']"
45,Prove $f_\infty: A_\infty \rightarrow B_\infty$ is a bijection,Prove  is a bijection,f_\infty: A_\infty \rightarrow B_\infty,"Update: I was given some hints at how to approach this problem $A_\infty $ and $B_\infty$ are sets, not maps. (which is strange because there are function definitions coming into play here) The definition of $f_\infty$ is the restriction of $f$ with the domain and codomain restricted. 1.) Show that $f_\infty $is defined, i.e., if $a \in A_\infty$, then $f(a) \in B_\infty$. 2.) Show that $f_\infty$ is injective, clear because $f_\infty $ is a restriction of the      injective function f. 3.) Show that $f_\infty$ is onto, i.e., if $ b \in B_\infty$, then there is an $a \in A_\infty$      and $f(a) = b$. So, show that there is an appropriate element in $A$ that maps to      $b$, and then show that it even belong to $X_\infty.$ Original Attempt: I am using the Cantor-Schroder-Beenstein Theorem to prove $f_\infty: A_\infty \rightarrow B_\infty$ is a bijection. The cases of $f_+: A_+ \rightarrow B_+$ and $f_-: A_- \rightarrow B_-$  being bijections are already done. The theorem states that for any sets $A$ and $B$, if there exist injections from $A$ into $B$ and from $B$ to $A$, then $\mid A \mid = \mid B \mid$ From definition 5.4.5 A function $f: x \rightarrow y$ with the property $(\forall x_1, x_2 \in X)( x_1 \neq x_2 \rightarrow f(x_1) \neq f(x_2)$ is an injection of $X$ into $Y$. So, from $A $ into $B$ I have, $f: A \rightarrow B$ with the property $(\forall a_1, a_2 \in A)( a_1 \neq a_2 \rightarrow f(a_1) \neq f(a_2)$ and from $B$ into $A$, I have $f: B \rightarrow A$ with the property $(\forall b_1, b_2 \in B)( b_1 \neq b_2 \rightarrow f(b_1) \neq f(b_2)$ Anyway, For $A \in A_+$  the predecessor sequence terminates in A For $B \in B_+$  the predecessor sequence terminates in A The $f_+ $ is the restriction of $f$ to $A_+$, and $f_+$ is a function $A_+ \rightarrow B_+$ so the sequence is $(a \in A_+)$ is $(a,...x)$ Suppose $f_+$ is onto (surjection). The we pick $b \in B_+$ and our sequence is $(f(a),a,...x)$ Since  $b=f(a) $ and $a \in A_+$, $f_+ : A_+ \rightarrow B_+$ is a bijection. For $A \in A_-$  the predecessor sequence terminates in B For $B \in B_-$  the predecessor sequence terminates in B Suppose $g_: B_- \rightarrow A_-$ is well defined and a bijection. Then for $b \in B$, the sequence for $b$ is $(b,a,b_1,a_1...b_m)$. Now set $y_(b)=g(b)$. The sequence for $g(b)$ is $(g(b),b,...b_m)$, so $g(b) \in A$. Now suppose $g_-$ is is an injection. There is a restriction of an injective map $g$. For. $a \in A$ the sequence of $a$ will be $(a,b,...b_m)$ and $g(b_1) = a$ and $a \in A$. Therefore $g_: B_- \rightarrow A_-$ is a bijection For $A \in A_\infty$  the predecessor sequence doesn't terminate. For $B \in B_\infty$  the predecessor sequence doesn't terminate. So now I got to prove that  $f_\infty: A_\infty \rightarrow B_\infty$ is a bijection. So I already know that $A_\infty$ and $B_\infty$ are both going to be a surjection and an injection. But, since the predecessor sequence doesn't terminate, that means it could go on forever. I could have something like $(a,b,a_1,b_a,a_2,b_2,a_3,b_3,...) $ Maybe I think for $a \in A$ the sequence of $a$ is $(a,b,......b_m)$ so $g(b_1) = a $ and $a \in A_\infty$. and for $b \in B$, the sequence of $b$ will be $(b,a,b_1,a_1,...a_m$. Since $g(a_1) = b$ and $b \in B_\infty$, then $g: A_\infty \rightarrow B_\infty$ This is where I am kind of lost since I already mentioned that the $A_\infty$ and $B_\infty$ aren't going to terminate at all, so their sequence will continue, but how do I show that? Do I list a bunch of terms for $A$ and $B$ and then create a surjection and injection map? With the hints, would that mean that $A_\infty$ and $B_\infty$ are restricted in the domain and codomain as well, and the sequence or element belongs inside of $A_\infty$ and $B_\infty$ ?","Update: I was given some hints at how to approach this problem $A_\infty $ and $B_\infty$ are sets, not maps. (which is strange because there are function definitions coming into play here) The definition of $f_\infty$ is the restriction of $f$ with the domain and codomain restricted. 1.) Show that $f_\infty $is defined, i.e., if $a \in A_\infty$, then $f(a) \in B_\infty$. 2.) Show that $f_\infty$ is injective, clear because $f_\infty $ is a restriction of the      injective function f. 3.) Show that $f_\infty$ is onto, i.e., if $ b \in B_\infty$, then there is an $a \in A_\infty$      and $f(a) = b$. So, show that there is an appropriate element in $A$ that maps to      $b$, and then show that it even belong to $X_\infty.$ Original Attempt: I am using the Cantor-Schroder-Beenstein Theorem to prove $f_\infty: A_\infty \rightarrow B_\infty$ is a bijection. The cases of $f_+: A_+ \rightarrow B_+$ and $f_-: A_- \rightarrow B_-$  being bijections are already done. The theorem states that for any sets $A$ and $B$, if there exist injections from $A$ into $B$ and from $B$ to $A$, then $\mid A \mid = \mid B \mid$ From definition 5.4.5 A function $f: x \rightarrow y$ with the property $(\forall x_1, x_2 \in X)( x_1 \neq x_2 \rightarrow f(x_1) \neq f(x_2)$ is an injection of $X$ into $Y$. So, from $A $ into $B$ I have, $f: A \rightarrow B$ with the property $(\forall a_1, a_2 \in A)( a_1 \neq a_2 \rightarrow f(a_1) \neq f(a_2)$ and from $B$ into $A$, I have $f: B \rightarrow A$ with the property $(\forall b_1, b_2 \in B)( b_1 \neq b_2 \rightarrow f(b_1) \neq f(b_2)$ Anyway, For $A \in A_+$  the predecessor sequence terminates in A For $B \in B_+$  the predecessor sequence terminates in A The $f_+ $ is the restriction of $f$ to $A_+$, and $f_+$ is a function $A_+ \rightarrow B_+$ so the sequence is $(a \in A_+)$ is $(a,...x)$ Suppose $f_+$ is onto (surjection). The we pick $b \in B_+$ and our sequence is $(f(a),a,...x)$ Since  $b=f(a) $ and $a \in A_+$, $f_+ : A_+ \rightarrow B_+$ is a bijection. For $A \in A_-$  the predecessor sequence terminates in B For $B \in B_-$  the predecessor sequence terminates in B Suppose $g_: B_- \rightarrow A_-$ is well defined and a bijection. Then for $b \in B$, the sequence for $b$ is $(b,a,b_1,a_1...b_m)$. Now set $y_(b)=g(b)$. The sequence for $g(b)$ is $(g(b),b,...b_m)$, so $g(b) \in A$. Now suppose $g_-$ is is an injection. There is a restriction of an injective map $g$. For. $a \in A$ the sequence of $a$ will be $(a,b,...b_m)$ and $g(b_1) = a$ and $a \in A$. Therefore $g_: B_- \rightarrow A_-$ is a bijection For $A \in A_\infty$  the predecessor sequence doesn't terminate. For $B \in B_\infty$  the predecessor sequence doesn't terminate. So now I got to prove that  $f_\infty: A_\infty \rightarrow B_\infty$ is a bijection. So I already know that $A_\infty$ and $B_\infty$ are both going to be a surjection and an injection. But, since the predecessor sequence doesn't terminate, that means it could go on forever. I could have something like $(a,b,a_1,b_a,a_2,b_2,a_3,b_3,...) $ Maybe I think for $a \in A$ the sequence of $a$ is $(a,b,......b_m)$ so $g(b_1) = a $ and $a \in A_\infty$. and for $b \in B$, the sequence of $b$ will be $(b,a,b_1,a_1,...a_m$. Since $g(a_1) = b$ and $b \in B_\infty$, then $g: A_\infty \rightarrow B_\infty$ This is where I am kind of lost since I already mentioned that the $A_\infty$ and $B_\infty$ aren't going to terminate at all, so their sequence will continue, but how do I show that? Do I list a bunch of terms for $A$ and $B$ and then create a surjection and injection map? With the hints, would that mean that $A_\infty$ and $B_\infty$ are restricted in the domain and codomain as well, and the sequence or element belongs inside of $A_\infty$ and $B_\infty$ ?",,"['elementary-set-theory', 'proof-writing']"
46,Proving the inclusion exclusion principle from the definition of the cardinality,Proving the inclusion exclusion principle from the definition of the cardinality,,"I want to prove the inclusion exclusion principle:      $|A\cup B| = |A| + |B| - |A\cap B|$ where $A$ and $B$ are finite sets. I proved the addition rule by contructing a bijection to a subset of the natural numbers and want to do the same here... Can you give me a hint, I don't want a full solution :)","I want to prove the inclusion exclusion principle:      $|A\cup B| = |A| + |B| - |A\cap B|$ where $A$ and $B$ are finite sets. I proved the addition rule by contructing a bijection to a subset of the natural numbers and want to do the same here... Can you give me a hint, I don't want a full solution :)",,"['combinatorics', 'elementary-set-theory', 'inclusion-exclusion']"
47,"Given a family $\mathfrak{F}$ for sets, when are $\bigcup \mathfrak{F}$ and $\bigcap \mathfrak{F}$ empty?","Given a family  for sets, when are  and  empty?",\mathfrak{F} \bigcup \mathfrak{F} \bigcap \mathfrak{F},"Prove, disprove, or give a counterexample: Let $\mathfrak{F}$ be a family of sets. Then $\bigcup \mathfrak{F}=\varnothing$ iff $A=\varnothing$ for all $A \in \mathfrak{F}$ . Let $\mathfrak{F}$ be a family of sets. Then $\bigcap \mathfrak{F}=\varnothing$ iff $A=\varnothing$ for all $A \in \mathfrak{F}$ . I was thinking about using the following: $x \in\bigcup\mathfrak{F}$ if and only if $(\exists A\in\mathfrak{F})$$(x\in A)$ $x \in\bigcap\mathfrak{F}$ if and only if $(\forall A\in\mathfrak{F})$$(x\in A)$ Are these the correct definitions to apply? If so, how can I go about using them if these two can in fact be proved?","Prove, disprove, or give a counterexample: Let be a family of sets. Then iff for all . Let be a family of sets. Then iff for all . I was thinking about using the following: if and only if if and only if Are these the correct definitions to apply? If so, how can I go about using them if these two can in fact be proved?",\mathfrak{F} \bigcup \mathfrak{F}=\varnothing A=\varnothing A \in \mathfrak{F} \mathfrak{F} \bigcap \mathfrak{F}=\varnothing A=\varnothing A \in \mathfrak{F} x \in\bigcup\mathfrak{F} (\exists A\in\mathfrak{F})(x\in A) x \in\bigcap\mathfrak{F} (\forall A\in\mathfrak{F})(x\in A),['elementary-set-theory']
48,"Please clarify what is meant by ""arbitrarily large""","Please clarify what is meant by ""arbitrarily large""",,"My classmate and I are debating about a logic exercise. The exercise goes like this: Let $T$ be an incomplete countable theory. Prove or disprove: If $T$ has finite models and a denumerable model, then $T$ has arbitrarily large finite models. My friend thinks that a theory with the sentence $\exists x, y (x\ne y)$ should be a counterexample, as it has a finite model (of say size two), a denumerable model, but no ""arbitrarily finite model"" since he considers $1$ to be arbitrarily large, and there is no model of cardinality $1$ that models his theory. I disagree since I think that it is not enough that he chooses some number and says it is arbitrarily large; I think that for a given arbitarily large number, his theory should not have that model, if his theory is to suffice as a counterexample. Can someone clarify why and how either of us is wrong? Note that I do not need help with the problem itself (already solved it my way), just to settle this discussion.","My classmate and I are debating about a logic exercise. The exercise goes like this: Let $T$ be an incomplete countable theory. Prove or disprove: If $T$ has finite models and a denumerable model, then $T$ has arbitrarily large finite models. My friend thinks that a theory with the sentence $\exists x, y (x\ne y)$ should be a counterexample, as it has a finite model (of say size two), a denumerable model, but no ""arbitrarily finite model"" since he considers $1$ to be arbitrarily large, and there is no model of cardinality $1$ that models his theory. I disagree since I think that it is not enough that he chooses some number and says it is arbitrarily large; I think that for a given arbitarily large number, his theory should not have that model, if his theory is to suffice as a counterexample. Can someone clarify why and how either of us is wrong? Note that I do not need help with the problem itself (already solved it my way), just to settle this discussion.",,['elementary-set-theory']
49,Question about cardinals.,Question about cardinals.,,I have heard that $2^{\omega_1} = \omega_1^{\omega_1}$. Is that true? Why is that? I have tried to find a bijection between the set of all subsets of $\omega_1$ and the set of all functions $\alpha: \omega_1 \rightarrow \omega_1$ but I haven't found it. I have also tried to prove it with the definition with no success. Any help would be appreciated. Thank you ;),I have heard that $2^{\omega_1} = \omega_1^{\omega_1}$. Is that true? Why is that? I have tried to find a bijection between the set of all subsets of $\omega_1$ and the set of all functions $\alpha: \omega_1 \rightarrow \omega_1$ but I haven't found it. I have also tried to prove it with the definition with no success. Any help would be appreciated. Thank you ;),,"['elementary-set-theory', 'cardinals']"
50,"Given a subcollection of a powerset, do these ""separation"" relations have names?","Given a subcollection of a powerset, do these ""separation"" relations have names?",,"Let $X$ denote a set and $\mathcal{F}$ denote a subcollection of $\mathcal{P}(X).$ Do the following relations on $\mathcal{P}(X)$ have a name? For $A,B \subseteq X$, call $A$ partially separated from $B$ iff we can find $F \in \mathcal{F}$ such that $A \subseteq F$ and $B \subseteq F^c$. Call $A$ and $B$ totally separated iff each is partially separated from the other. Call $A$ and $B$ strongly separated by $\mathcal{F}$ if we can find disjoint $F,G \in \mathcal{F}$ with $A \subseteq F$ and $B \subseteq G.$","Let $X$ denote a set and $\mathcal{F}$ denote a subcollection of $\mathcal{P}(X).$ Do the following relations on $\mathcal{P}(X)$ have a name? For $A,B \subseteq X$, call $A$ partially separated from $B$ iff we can find $F \in \mathcal{F}$ such that $A \subseteq F$ and $B \subseteq F^c$. Call $A$ and $B$ totally separated iff each is partially separated from the other. Call $A$ and $B$ strongly separated by $\mathcal{F}$ if we can find disjoint $F,G \in \mathcal{F}$ with $A \subseteq F$ and $B \subseteq G.$",,"['elementary-set-theory', 'terminology']"
51,Find the cardinality of these sets,Find the cardinality of these sets,,"Question from my homework im struggling with Find the cardinality of these sets: 1) the set of all sequences of natural numbers 2) the set of all arithmetic series (difference between 2 numbers is the same,example 11,9,7 ...) 3) the set of all rising arithmetic series (difference between 2 numbers is positive, example 11 13 15...) My answers: 1) there are $2^{\aleph_0}$ sequences so the answer is $c$ 2) what determines a series is the first number, the difference between 2 numbers, and the last number, so you have 3 criteria, $\aleph_0$ options for each, overall - $3\cdot\aleph_0 = \aleph_0$ 3) this is a subset of the answer to question 2), so it is also $\aleph_0$. But I am wrong. I know I am wrong because the next question is ""Show that there is an isomorphism between the answer to question 1 and the answer to question 3"". Please help :)","Question from my homework im struggling with Find the cardinality of these sets: 1) the set of all sequences of natural numbers 2) the set of all arithmetic series (difference between 2 numbers is the same,example 11,9,7 ...) 3) the set of all rising arithmetic series (difference between 2 numbers is positive, example 11 13 15...) My answers: 1) there are $2^{\aleph_0}$ sequences so the answer is $c$ 2) what determines a series is the first number, the difference between 2 numbers, and the last number, so you have 3 criteria, $\aleph_0$ options for each, overall - $3\cdot\aleph_0 = \aleph_0$ 3) this is a subset of the answer to question 2), so it is also $\aleph_0$. But I am wrong. I know I am wrong because the next question is ""Show that there is an isomorphism between the answer to question 1 and the answer to question 3"". Please help :)",,"['elementary-set-theory', 'cardinals']"
52,Learning about maximal and minimal elements of a set...struggling a little bit with these questions.,Learning about maximal and minimal elements of a set...struggling a little bit with these questions.,,"Ok so I'm learning about partial orders, and I think I know the difference between a minimum/minimal & maximum/maximal element of a partially ordered set... but I just was wondering if someone could see if my examples are correct or incorrect and why. 1) For the power set of {1, 2, ..., n}, where n is a positive integer, under the empty relation, would the minimal and minimum element be 1? Would the maximal and maximum be n? (b.t.w what does ""under the empty relation"" even mean?) (In this case maximum = maximal and minimum = minimal, right?) 2) For the set of nonnegative integers under divisibility, would the minimum/minimal be 0 and there would be no maximal/maximum? (In this case maximum = maximal and minimum = minimal, right?) 3) Is it possible to have a set with no minimal element but a minimum element? Can you please give an example? This makes absolutely no sense to me. Thanks!","Ok so I'm learning about partial orders, and I think I know the difference between a minimum/minimal & maximum/maximal element of a partially ordered set... but I just was wondering if someone could see if my examples are correct or incorrect and why. 1) For the power set of {1, 2, ..., n}, where n is a positive integer, under the empty relation, would the minimal and minimum element be 1? Would the maximal and maximum be n? (b.t.w what does ""under the empty relation"" even mean?) (In this case maximum = maximal and minimum = minimal, right?) 2) For the set of nonnegative integers under divisibility, would the minimum/minimal be 0 and there would be no maximal/maximum? (In this case maximum = maximal and minimum = minimal, right?) 3) Is it possible to have a set with no minimal element but a minimum element? Can you please give an example? This makes absolutely no sense to me. Thanks!",,"['elementary-set-theory', 'elementary-functions']"
53,$\sigma$- ideal,- ideal,\sigma,"Let $(\Omega,\mathcal{A})$ be a measurable space. $\mathcal{N}\subset\mathcal{P}(\Omega)$ is called a $\sigma$ ideal, if     $$ (1)~\emptyset\in\mathcal{N},~~~~~(2) N\in\mathcal{N}, M\subset N\Rightarrow M\in\mathcal{N},~~~~~(3)(N_n)\in\mathcal{N}^{\mathbb{N}}\Rightarrow\bigcup_n N_n\in\mathcal{N} $$     Show that for every $\sigma$-ideal $\mathcal{N}$ it is     $$ \sigma(\mathcal{A}\cup\mathcal{N})=\left\{A\Delta N|A\in\mathcal{A},N\in\mathcal{N}\right\}. $$     Hint:      $$ \left\{A\Delta N|A\in\mathcal{A},N\in\mathcal{N}\right\}=\left\{B\subset\Omega|\exists A\in\mathcal{A},N\in\mathcal{N}: B\setminus N=A\setminus N\right\} $$ I do not have a special idea, to be honest. For the inclusion ""$\subseteq$ "" I thought that maybe this is a strategy: (1) Show that $\mathcal{S}:=\left\{A\Delta N|A\in\mathcal{A},N\in\mathcal{N}\right\}$ is a $\sigma$-algebra. (2) Show that $\mathcal{A}\cup\mathcal{N}\in\mathcal{S}$. Is that right or helpful? If yes: Which is the strategy for the other inclusion?","Let $(\Omega,\mathcal{A})$ be a measurable space. $\mathcal{N}\subset\mathcal{P}(\Omega)$ is called a $\sigma$ ideal, if     $$ (1)~\emptyset\in\mathcal{N},~~~~~(2) N\in\mathcal{N}, M\subset N\Rightarrow M\in\mathcal{N},~~~~~(3)(N_n)\in\mathcal{N}^{\mathbb{N}}\Rightarrow\bigcup_n N_n\in\mathcal{N} $$     Show that for every $\sigma$-ideal $\mathcal{N}$ it is     $$ \sigma(\mathcal{A}\cup\mathcal{N})=\left\{A\Delta N|A\in\mathcal{A},N\in\mathcal{N}\right\}. $$     Hint:      $$ \left\{A\Delta N|A\in\mathcal{A},N\in\mathcal{N}\right\}=\left\{B\subset\Omega|\exists A\in\mathcal{A},N\in\mathcal{N}: B\setminus N=A\setminus N\right\} $$ I do not have a special idea, to be honest. For the inclusion ""$\subseteq$ "" I thought that maybe this is a strategy: (1) Show that $\mathcal{S}:=\left\{A\Delta N|A\in\mathcal{A},N\in\mathcal{N}\right\}$ is a $\sigma$-algebra. (2) Show that $\mathcal{A}\cup\mathcal{N}\in\mathcal{S}$. Is that right or helpful? If yes: Which is the strategy for the other inclusion?",,['measure-theory']
54,What is the math behind the game Spot It?,What is the math behind the game Spot It?,,"I just purchased the game Spot It . As per this site , the structure of the game is as follows: Game has 55 round playing cards. Each card has eight randomly placed symbols. There are a total of 50 different symbols through the deck. The most fascinating feature of this game is any two cards selected will always have ONE (and only one) matching symbol to be found on both cards. Is there a formula you can use to create a derivative of this game with different numbers of symbols displayed on each card. Assuming the following variables: S = total number of symbols C = total number of cards N = number of symbols per card Can you mathematically demonstrate the minimum number of cards (C) and symbols (S) you need based on the number of symbols per card (N)?","I just purchased the game Spot It . As per this site , the structure of the game is as follows: Game has 55 round playing cards. Each card has eight randomly placed symbols. There are a total of 50 different symbols through the deck. The most fascinating feature of this game is any two cards selected will always have ONE (and only one) matching symbol to be found on both cards. Is there a formula you can use to create a derivative of this game with different numbers of symbols displayed on each card. Assuming the following variables: S = total number of symbols C = total number of cards N = number of symbols per card Can you mathematically demonstrate the minimum number of cards (C) and symbols (S) you need based on the number of symbols per card (N)?",,"['combinatorics', 'recreational-mathematics', 'card-games']"
55,Smallest ring containing collection of subsets,Smallest ring containing collection of subsets,,"Given any collection $C$ of subsets of a set $X$, show that there is a smallest ring of sets $R$ containing $C$. (That is, $R$ has the property that it contains $C$, and any ring that contains $C$ contains $R$.) Describe explicitly how to construct $R$ from $C$. We must take all finite unions and differences of the sets in $C$, call the new collection $C_1$. Then take all finite unions and differences of the sets in $C_1$, call the new collection $C_2$. And so on, to $C_3,C_4,\ldots$. Clearly any ring must contain $C,C_1,C_2,\ldots$. If we can show that the process stops at some $C_n$, we have our smallest ring of sets containing $C$. But why must it stop?","Given any collection $C$ of subsets of a set $X$, show that there is a smallest ring of sets $R$ containing $C$. (That is, $R$ has the property that it contains $C$, and any ring that contains $C$ contains $R$.) Describe explicitly how to construct $R$ from $C$. We must take all finite unions and differences of the sets in $C$, call the new collection $C_1$. Then take all finite unions and differences of the sets in $C_1$, call the new collection $C_2$. And so on, to $C_3,C_4,\ldots$. Clearly any ring must contain $C,C_1,C_2,\ldots$. If we can show that the process stops at some $C_n$, we have our smallest ring of sets containing $C$. But why must it stop?",,"['measure-theory', 'elementary-set-theory']"
56,Relation on countable sets,Relation on countable sets,,"Let $R$ be a relation on two countable sets $A$ and $B$, where $R\subset A\times B$, with the following properties: $\forall a\in A$ the set $\{b\in B: (a,b)\in R\}$ is finite. For any finite set $A_0$: $$|\{b\in B : \exists a_0\in A_0, \text{such that} \ \ (a_0,b)\in R  \}|\leq n|A_0|$$ where $n\in\mathbb{N}$. How can I show then, that there exist $n$ disjoint sets, $B_1,B_2,\dots, B_n$, where $B_i\subset B\ \ \ \ \ \ \forall \  \ 1 \leq i\leq n$, and there exists $n$ one to one and onto functions $f_1,f_2,\dots, f_n$ such that $f_i:B_i\to A \ \ \ \ \ \ \ \forall \  \ 1 \leq i\leq n $? Edited: $B_i\in B$ replaced with $B_i\subset B$","Let $R$ be a relation on two countable sets $A$ and $B$, where $R\subset A\times B$, with the following properties: $\forall a\in A$ the set $\{b\in B: (a,b)\in R\}$ is finite. For any finite set $A_0$: $$|\{b\in B : \exists a_0\in A_0, \text{such that} \ \ (a_0,b)\in R  \}|\leq n|A_0|$$ where $n\in\mathbb{N}$. How can I show then, that there exist $n$ disjoint sets, $B_1,B_2,\dots, B_n$, where $B_i\subset B\ \ \ \ \ \ \forall \  \ 1 \leq i\leq n$, and there exists $n$ one to one and onto functions $f_1,f_2,\dots, f_n$ such that $f_i:B_i\to A \ \ \ \ \ \ \ \forall \  \ 1 \leq i\leq n $? Edited: $B_i\in B$ replaced with $B_i\subset B$",,"['elementary-set-theory', 'relations']"
57,A function of the inverse function of a set contained in a set.,A function of the inverse function of a set contained in a set.,,"I'm doing an intro course on set theory and need to prove: Suppose that $$ f : X \rightarrow Y, A \subset X, B \subset Y $$ Prove that: a) $ f(f^{-1}(B)) \subset B $ and give an example where equality does not hold b) $ A \subset f^{-1}(f(A))  $ and give an example where equality does not hold. I have an idea that this has something to do with surjections, injections and bijections since the the function is not defined explicitly as any one, but I'm lost....","I'm doing an intro course on set theory and need to prove: Suppose that $$ f : X \rightarrow Y, A \subset X, B \subset Y $$ Prove that: a) $ f(f^{-1}(B)) \subset B $ and give an example where equality does not hold b) $ A \subset f^{-1}(f(A))  $ and give an example where equality does not hold. I have an idea that this has something to do with surjections, injections and bijections since the the function is not defined explicitly as any one, but I'm lost....",,['elementary-set-theory']
58,Can a countable set contain uncountably many infinite subsets such that the intersection of any two such distinct subsets is finite?,Can a countable set contain uncountably many infinite subsets such that the intersection of any two such distinct subsets is finite?,,Can a countable set contain uncountably many infinite subsets such that the intersection of any two such distinct subsets is finite?,Can a countable set contain uncountably many infinite subsets such that the intersection of any two such distinct subsets is finite?,,['elementary-set-theory']
59,How are algebras and rings of subsets generated in this paragraph?,How are algebras and rings of subsets generated in this paragraph?,,"From ncatlab What is missing is a simple description of the σ-algebra generated by ℬ. For a mere algebra, this is easy; any ℬ can be taken as a subbase of an algebra, the symmetric unions of finite families of elements of   ℬ form a base of the algebra, and the intersections of finite families   of elements of the base form an algebra. For a ring, the only difference is to use intersections only of inhabited families. But for anything from a δ-ring to a σ-algebra, nothing like this will work. According to the quote, which I don't quite understand, How is an algebra of subsets generated? In particular, how is symmetric union defined as a set operation? Union is always symmetric. I searched it on the internet, but the name seems to have a different meaning for relations. How is a ring of subsets generated? Thanks and regards!","From ncatlab What is missing is a simple description of the σ-algebra generated by ℬ. For a mere algebra, this is easy; any ℬ can be taken as a subbase of an algebra, the symmetric unions of finite families of elements of   ℬ form a base of the algebra, and the intersections of finite families   of elements of the base form an algebra. For a ring, the only difference is to use intersections only of inhabited families. But for anything from a δ-ring to a σ-algebra, nothing like this will work. According to the quote, which I don't quite understand, How is an algebra of subsets generated? In particular, how is symmetric union defined as a set operation? Union is always symmetric. I searched it on the internet, but the name seems to have a different meaning for relations. How is a ring of subsets generated? Thanks and regards!",,"['measure-theory', 'elementary-set-theory']"
60,Is the base case $m=0$ in this proof by induction correct?,Is the base case  in this proof by induction correct?,m=0,"Let $\Bbb J(n)$ the set of bounded intervals in $\Bbb R^n$ , that is, if $I\in\Bbb J(n)$ there are bounded intervals $I_k\in\Bbb R$ such that $I=\prod_{k=1}^n I_k$ , where the product is the cartesian product (we consider the empty set an interval in $\Bbb R$ and consequently also in $\Bbb J(n)$ ). Then let any finite collection $I,J_1,J_2,\ldots, J_m\in\Bbb J(n)$ , and I want to prove using strong induction that $$I\setminus\left(\bigcup_{k=1}^m J_k\right)\text{ can be written as a union of finite pairwise disjoint intervals}\tag1$$ If I choose the base case $m=1$ then the proof becomes messy, but if I choose the base case $m=0$ then I find that $(1)$ is just $I$ , so the base case holds trivially, and the rest of the proof is very simple. Proof: assume that a base case $m=0$ or $m=1$ holds, then we choose $(1)$ as hypothesis for all $1\le k\le m$ for some $m$ . Then the induction step gives $$I\setminus\left(\bigcup_{k=1}^{m+1}J_k\right)=\left(I\setminus\left(\bigcup_{k=1}^m J_k\right)\right)\setminus J_{m+1}\\=\left(\bigsqcup_{j=1}^r H_j\right)\setminus J_{m+1}=\left(\bigsqcup_{j=1}^r H_j\right)\cap J_{m+1}^\complement\\=\bigsqcup_{j=1}^r(H_j\cap J_{m+1}^\complement)=\bigsqcup_{j=1}^r(H_j\setminus J_{m+1})$$ for $H_j\in\Bbb J(n)$ , and using again the hypothesis we can write $H_j\setminus J_{m+1}$ as a union of disjoint intervals, so we are done. There is a huge difference in difficulty in this proof choosing $m=0$ or $m=1$ as the base case, so I'm not sure if the proof for $m=0$ is completely right. Can someone confirm that we can choose $m=0$ in this proof without harm? Also, I would like to know if someone knows how to handle easily the base case $m=1$ . I tried but I lost myself in a mountain of intersections, unions and abstract thinking. Of course, if someone knows how to prove $(1)$ in a different way I would like to know it. Equivalently $(1)$ can be stated as: for any finite collection $J_1,J_2,\ldots,J_m\in\Bbb J(n)$ then $\bigcup_{k=1}^m J_k$ can be written as a pairwise disjoint union of intervals. However, with this assertion, the induction step is as hard as the base case of the above when $m=1$ . EDIT: Amazingly it seems that the base case $m=0$ is valid. Observe what happens with this reformulation of $(1)$ : Let $I\in\Bbb J(n)$ and $\mathcal S\subset\Bbb J(n)$ finite. Then there is some finite $\mathcal B\subset\Bbb J(n)$ such that $$I\setminus\left(\bigcup\mathcal S\right)=\bigsqcup\mathcal B\tag2$$ Then from $(2)$ we can do induction over $|\mathcal S|$ and start with zero, so it seems that the base case of $m=0$ on $(1)$ is perfectly valid.","Let the set of bounded intervals in , that is, if there are bounded intervals such that , where the product is the cartesian product (we consider the empty set an interval in and consequently also in ). Then let any finite collection , and I want to prove using strong induction that If I choose the base case then the proof becomes messy, but if I choose the base case then I find that is just , so the base case holds trivially, and the rest of the proof is very simple. Proof: assume that a base case or holds, then we choose as hypothesis for all for some . Then the induction step gives for , and using again the hypothesis we can write as a union of disjoint intervals, so we are done. There is a huge difference in difficulty in this proof choosing or as the base case, so I'm not sure if the proof for is completely right. Can someone confirm that we can choose in this proof without harm? Also, I would like to know if someone knows how to handle easily the base case . I tried but I lost myself in a mountain of intersections, unions and abstract thinking. Of course, if someone knows how to prove in a different way I would like to know it. Equivalently can be stated as: for any finite collection then can be written as a pairwise disjoint union of intervals. However, with this assertion, the induction step is as hard as the base case of the above when . EDIT: Amazingly it seems that the base case is valid. Observe what happens with this reformulation of : Let and finite. Then there is some finite such that Then from we can do induction over and start with zero, so it seems that the base case of on is perfectly valid.","\Bbb J(n) \Bbb R^n I\in\Bbb J(n) I_k\in\Bbb R I=\prod_{k=1}^n I_k \Bbb R \Bbb J(n) I,J_1,J_2,\ldots, J_m\in\Bbb J(n) I\setminus\left(\bigcup_{k=1}^m J_k\right)\text{ can be written as a union of finite pairwise disjoint intervals}\tag1 m=1 m=0 (1) I m=0 m=1 (1) 1\le k\le m m I\setminus\left(\bigcup_{k=1}^{m+1}J_k\right)=\left(I\setminus\left(\bigcup_{k=1}^m J_k\right)\right)\setminus J_{m+1}\\=\left(\bigsqcup_{j=1}^r H_j\right)\setminus J_{m+1}=\left(\bigsqcup_{j=1}^r H_j\right)\cap J_{m+1}^\complement\\=\bigsqcup_{j=1}^r(H_j\cap J_{m+1}^\complement)=\bigsqcup_{j=1}^r(H_j\setminus J_{m+1}) H_j\in\Bbb J(n) H_j\setminus J_{m+1} m=0 m=1 m=0 m=0 m=1 (1) (1) J_1,J_2,\ldots,J_m\in\Bbb J(n) \bigcup_{k=1}^m J_k m=1 m=0 (1) I\in\Bbb J(n) \mathcal S\subset\Bbb J(n) \mathcal B\subset\Bbb J(n) I\setminus\left(\bigcup\mathcal S\right)=\bigsqcup\mathcal B\tag2 (2) |\mathcal S| m=0 (1)","['elementary-set-theory', 'proof-verification', 'induction', 'alternative-proof']"
61,"Power set of set containing empty set, sets of empty set, and mixes of the former","Power set of set containing empty set, sets of empty set, and mixes of the former",,"The title might be sort of confusing. The set is an infinite set like $$ A = \{ \emptyset, \{ \emptyset \}, \{ \{ \emptyset \} \}, ... \{ \emptyset, \{ \emptyset \} \}, \{ \{ \emptyset \}, \{ \{ \emptyset \} \} \}, ... ... \} $$ And it could be defined by the following rules #1: ∅ ∈ A #2: if a ∈ A, {a} ∈ A #3: if a ∈ A and b ∈ A, a ⋃ b ∈ A Consider a subset of 2 elements of A, like {x, y} ⊂ A, say, x ∈ A and y ∈ A, so {x} ∈ A and {y} ∈ A (#2), then {x} ⋃ {y} ∈ A (#3), as a result {x, y} is also an element of A. Similar deductions could be applied to subsets of 3 or even more elements. But that should have no chance according to Cantor's theorem . What mistakes I've made and what is the power set of A?","The title might be sort of confusing. The set is an infinite set like $$ A = \{ \emptyset, \{ \emptyset \}, \{ \{ \emptyset \} \}, ... \{ \emptyset, \{ \emptyset \} \}, \{ \{ \emptyset \}, \{ \{ \emptyset \} \} \}, ... ... \} $$ And it could be defined by the following rules #1: ∅ ∈ A #2: if a ∈ A, {a} ∈ A #3: if a ∈ A and b ∈ A, a ⋃ b ∈ A Consider a subset of 2 elements of A, like {x, y} ⊂ A, say, x ∈ A and y ∈ A, so {x} ∈ A and {y} ∈ A (#2), then {x} ⋃ {y} ∈ A (#3), as a result {x, y} is also an element of A. Similar deductions could be applied to subsets of 3 or even more elements. But that should have no chance according to Cantor's theorem . What mistakes I've made and what is the power set of A?",,['elementary-set-theory']
62,Proving : Every infinite subset of countable set is countable [duplicate],Proving : Every infinite subset of countable set is countable [duplicate],,"This question already has answers here : Closed 11 years ago . Possible Duplicate: An infinite subset of a countable set is countable I was going through rudin when I encountered the proof for ""Every infinite subset of a countable set is countable"". What he states is that we take a set $A$. Let $E \subset A$ be an infinite subset. We need to prove that $E$ is countable. The book states that we should pick the smallest number of A and then proceed picking smaller numbers and simultaneously indexing them with $J_n = \{1,2,3,\cdots,n\}$. What I don't understand is how can we pick a minimum out of countably infinite numbers? Suppose I define $A = \{ y | y =\dfrac{1}{n} \forall n\in\mathbb{N}\}$, we can never get a minimum. 0 can't be the minimum since the domain is assumed to be $[1,\infty)$. The logic of maximum also won't work because we can define the set $\mathbb{N}$ itself. We can't pick a maximum. Am I missing something?","This question already has answers here : Closed 11 years ago . Possible Duplicate: An infinite subset of a countable set is countable I was going through rudin when I encountered the proof for ""Every infinite subset of a countable set is countable"". What he states is that we take a set $A$. Let $E \subset A$ be an infinite subset. We need to prove that $E$ is countable. The book states that we should pick the smallest number of A and then proceed picking smaller numbers and simultaneously indexing them with $J_n = \{1,2,3,\cdots,n\}$. What I don't understand is how can we pick a minimum out of countably infinite numbers? Suppose I define $A = \{ y | y =\dfrac{1}{n} \forall n\in\mathbb{N}\}$, we can never get a minimum. 0 can't be the minimum since the domain is assumed to be $[1,\infty)$. The logic of maximum also won't work because we can define the set $\mathbb{N}$ itself. We can't pick a maximum. Am I missing something?",,"['calculus', 'real-analysis', 'elementary-set-theory', 'proof-writing']"
63,Unions and intersections: $(A \cup B = A ∪ C) \land (A \cap B = A ∩ C) \implies B = C.$,Unions and intersections:,(A \cup B = A ∪ C) \land (A \cap B = A ∩ C) \implies B = C.,"Prove or give a counterexample: $$(A ∪ B = A ∪ C) \land (A ∩ B = A ∩ C) \implies B = C.$$ I think this is true, but I am not sure how to show it. I don't know if there are any manipulations with unions and intersections that allows me to move things around. Thanks in advance for any hints.","Prove or give a counterexample: $$(A ∪ B = A ∪ C) \land (A ∩ B = A ∩ C) \implies B = C.$$ I think this is true, but I am not sure how to show it. I don't know if there are any manipulations with unions and intersections that allows me to move things around. Thanks in advance for any hints.",,['elementary-set-theory']
64,Proving $f(x)=|x|$ is onto,Proving  is onto,f(x)=|x|,"I've been working on proving that this is a onto function: $f$ : $\mathbb R$ $\to$ $\mathbb R^{\geq0}$ is defined by $f(x)=|x|$ My proof so far: Let $y\in\mathbb R$ . Rough work: $|x|=y \Rightarrow \sqrt {x^2}=y \Rightarrow n^2=y^2 \Rightarrow \pm x=\pm y$ Suppose $f(\pm y)=|\pm y|=y$ . I know that this function is definitely onto given the co-domain of $\mathbb R^{\geq0}$ , but I feel like my proof is flawed. Am I supposed to individually account for the $-x$ and the $+x$ from $\pm x=\pm y$ when trying to solve $f(x) = y$ ? Thanks!","I've been working on proving that this is a onto function: : is defined by My proof so far: Let . Rough work: Suppose . I know that this function is definitely onto given the co-domain of , but I feel like my proof is flawed. Am I supposed to individually account for the and the from when trying to solve ? Thanks!",f \mathbb R \to \mathbb R^{\geq0} f(x)=|x| y\in\mathbb R |x|=y \Rightarrow \sqrt {x^2}=y \Rightarrow n^2=y^2 \Rightarrow \pm x=\pm y f(\pm y)=|\pm y|=y \mathbb R^{\geq0} -x +x \pm x=\pm y f(x) = y,"['proof-verification', 'elementary-set-theory']"
65,Intuitive (combinatorial) proof of $2^n=\sum_{k=0}^n {n\choose k}$,Intuitive (combinatorial) proof of,2^n=\sum_{k=0}^n {n\choose k},"Why should we expect that $$2^n=\sum_{k=0}^n {n\choose k}$$ It is easily seen to be true, by the binomial theorem:  just set $x=y=1$ in $(x+y)^n$ . But what is an intuitive reason why it is true (in terms of subsets)?","Why should we expect that It is easily seen to be true, by the binomial theorem:  just set in . But what is an intuitive reason why it is true (in terms of subsets)?",2^n=\sum_{k=0}^n {n\choose k} x=y=1 (x+y)^n,['combinatorics']
66,"Is $ (A × B) ∪ (C × D) = (A ∪ C) × (B ∪ D)$ true for all sets $A, B, C$ and $D$?",Is  true for all sets  and ?," (A × B) ∪ (C × D) = (A ∪ C) × (B ∪ D) A, B, C D","Is $(A \times B) \cup (C \times D) = (A \cup C) \times (B \cup D)$ true for all sets $A, B, C$ and $ D?$ I tried to wrap my head around this, but I have absolutely no idea what is going on here. How could I possibly go about trying to prove this? Or disprove it? Any help or guidance would be appreciated.","Is $(A \times B) \cup (C \times D) = (A \cup C) \times (B \cup D)$ true for all sets $A, B, C$ and $ D?$ I tried to wrap my head around this, but I have absolutely no idea what is going on here. How could I possibly go about trying to prove this? Or disprove it? Any help or guidance would be appreciated.",,['elementary-set-theory']
67,Why does set-theoretic union and intersection operate on reverse logic?,Why does set-theoretic union and intersection operate on reverse logic?,,"In set theory, $A \cup B$ is logically defined as $\{x : x \in A \lor x \in B\}$ . In set theory, the result of unionizing A with B is a bigger set, but in logic, ""or"" is a softening operation. In set theory, $A \cap B$ is logically defined as $\{x : x \in A \land x \in B\}$ . In set theory, the result of intersecting A with B is a smaller set, but in logic, ""and"" is a strengthening operation. Why do the extensional results of union and intersection go in reverse from their logical definition?","In set theory, is logically defined as . In set theory, the result of unionizing A with B is a bigger set, but in logic, ""or"" is a softening operation. In set theory, is logically defined as . In set theory, the result of intersecting A with B is a smaller set, but in logic, ""and"" is a strengthening operation. Why do the extensional results of union and intersection go in reverse from their logical definition?",A \cup B \{x : x \in A \lor x \in B\} A \cap B \{x : x \in A \land x \in B\},"['elementary-set-theory', 'logic', 'soft-question', 'intuition']"
68,Proof: $A \neq \emptyset \implies A \nsubseteq \emptyset $,Proof:,A \neq \emptyset \implies A \nsubseteq \emptyset ,"I proof that, let $A$ a set and $A \neq \emptyset$, then $A \nsubseteq \emptyset$; Proof by contradiction: if $A \subseteq \emptyset$ then by property I have an absurd , in fact by hypothesis $A \neq \emptyset$, therefore $A \nsubseteq \emptyset$. Or, direct proof: by hypothesis $A \neq \emptyset$, then ""$A \nsubseteq \emptyset$ or $ \emptyset \nsubseteq A$"", but by property I have only case that $ A \nsubseteq \emptyset$... Is it correct? Thank you all in advance","I proof that, let $A$ a set and $A \neq \emptyset$, then $A \nsubseteq \emptyset$; Proof by contradiction: if $A \subseteq \emptyset$ then by property I have an absurd , in fact by hypothesis $A \neq \emptyset$, therefore $A \nsubseteq \emptyset$. Or, direct proof: by hypothesis $A \neq \emptyset$, then ""$A \nsubseteq \emptyset$ or $ \emptyset \nsubseteq A$"", but by property I have only case that $ A \nsubseteq \emptyset$... Is it correct? Thank you all in advance",,"['elementary-set-theory', 'proof-writing']"
69,When are quotient maps induced by equivalence relations surjective and injective?,When are quotient maps induced by equivalence relations surjective and injective?,,"Let $\sim$ be an equivalence relation on a set $X$.  Also, there is a natural function $p:X\to \tilde X$ where $\tilde X$ is a set of all equivalence classes. (Equivalence classes are defined as, $[x]=\{y \in X |x\sim y\}$ where the equivalence relation is reflexive, symmetric, and transitive $\forall (x,y)$).  This natural function $p$ is defined by $p(x)=[x]$.  When is this function surjective and when is it injective? My guess was that it was surjective from $x$ to some $k\in \mathbb{N}$ and injective in $\mathbb{N}$, but I am probably wrong.","Let $\sim$ be an equivalence relation on a set $X$.  Also, there is a natural function $p:X\to \tilde X$ where $\tilde X$ is a set of all equivalence classes. (Equivalence classes are defined as, $[x]=\{y \in X |x\sim y\}$ where the equivalence relation is reflexive, symmetric, and transitive $\forall (x,y)$).  This natural function $p$ is defined by $p(x)=[x]$.  When is this function surjective and when is it injective? My guess was that it was surjective from $x$ to some $k\in \mathbb{N}$ and injective in $\mathbb{N}$, but I am probably wrong.",,"['elementary-set-theory', 'ring-theory', 'field-theory', 'modular-arithmetic']"
70,How to intuitively understand the power set of $\emptyset$,How to intuitively understand the power set of,\emptyset,"We know that power set of $\{a\}$ is $\{\emptyset,\{a\}\}$. Similarly, I tried reasoning the fact that power set of $\{\emptyset\}$ should be $\{\emptyset,\{\emptyset\}\}$, but this doesn't give me any intuitive sense. Can someone help me to understand what exactly does it mean?","We know that power set of $\{a\}$ is $\{\emptyset,\{a\}\}$. Similarly, I tried reasoning the fact that power set of $\{\emptyset\}$ should be $\{\emptyset,\{\emptyset\}\}$, but this doesn't give me any intuitive sense. Can someone help me to understand what exactly does it mean?",,['elementary-set-theory']
71,"New, elegant proofs for $\varphi(p^{k})=p^{k}-p^{k-1}$","New, elegant proofs for",\varphi(p^{k})=p^{k}-p^{k-1},"Are there any short, elegant proofs known for the identity $\varphi(p^{k})=p^{k}-p^{k-1}$ ? (Here $\varphi$ is Euler's totient function and $p$ is a prime.) The standard combinatorial proof goes like this: In the set $\left\{ 1,2\ldots,p^{k}\right\} $ there in total $p^{k}$   number. Split this set into $p$ subsets $\left\{ 1,\ldots,p\right\} $,   $\left\{ p+1,\ldots,2p\right\} \ldots$ Then in each of these sets   there is only one number -- namely the one of the form $m\cdot p$ for   some suitable $m$, that divides $p^{k}$. There are in total   $\frac{p^{k}}{p}=p^{k-1}$ such sets, so in total $p^{k-1}$-many number from   $\left\{ 1,2\ldots,p^{k}\right\} $ divide $p^{k}$. Thus   $(p^{k}-p^{k-1})$-many numbers are coprime to $p^k$, which proves the identity. $\square$ (A different proof that is often encountered assumes that we know that  $\varphi(n)=n\prod_{p\mid n}(1-\frac{1}{p})$, from which our identity  follows immediately.  But this is actually a longer proof, since proving the auxiliary identity is longer.) Surprisingly, I would have imagined that there are tons of wildly different proofs of such a basic fact out there, but a preliminary internet seach as well as book skimming returned only (minor variations of) these two proofs. EDIT The present proofs are more or less reformulations (very polished with details hidden as good as possible - but still reformulations) of my first proofs. What I'm looking for are more radically different approaches (if these exist).","Are there any short, elegant proofs known for the identity $\varphi(p^{k})=p^{k}-p^{k-1}$ ? (Here $\varphi$ is Euler's totient function and $p$ is a prime.) The standard combinatorial proof goes like this: In the set $\left\{ 1,2\ldots,p^{k}\right\} $ there in total $p^{k}$   number. Split this set into $p$ subsets $\left\{ 1,\ldots,p\right\} $,   $\left\{ p+1,\ldots,2p\right\} \ldots$ Then in each of these sets   there is only one number -- namely the one of the form $m\cdot p$ for   some suitable $m$, that divides $p^{k}$. There are in total   $\frac{p^{k}}{p}=p^{k-1}$ such sets, so in total $p^{k-1}$-many number from   $\left\{ 1,2\ldots,p^{k}\right\} $ divide $p^{k}$. Thus   $(p^{k}-p^{k-1})$-many numbers are coprime to $p^k$, which proves the identity. $\square$ (A different proof that is often encountered assumes that we know that  $\varphi(n)=n\prod_{p\mid n}(1-\frac{1}{p})$, from which our identity  follows immediately.  But this is actually a longer proof, since proving the auxiliary identity is longer.) Surprisingly, I would have imagined that there are tons of wildly different proofs of such a basic fact out there, but a preliminary internet seach as well as book skimming returned only (minor variations of) these two proofs. EDIT The present proofs are more or less reformulations (very polished with details hidden as good as possible - but still reformulations) of my first proofs. What I'm looking for are more radically different approaches (if these exist).",,"['number-theory', 'elementary-set-theory', 'alternative-proof', 'totient-function']"
72,Set notation confusion (Empty Sets),Set notation confusion (Empty Sets),,"Could anyone explain the difference between the following: $\varnothing$ $\begin{Bmatrix} \varnothing  \end{Bmatrix}$ $\begin{Bmatrix} \varnothing & \begin{Bmatrix} \varnothing \end{Bmatrix} \end{Bmatrix}$ I know number 1 is an empty set. So if S is an empty set, can denote it like this: S = {}. Correct? Now, I'm having difficultly with perceiving what number 2 is. Well it looks like it's a set of an empty set. Confused with 3 as well. Could anyone explain to me the difference between the three? (Note: I've just started discrete maths this week.)","Could anyone explain the difference between the following: $\varnothing$ $\begin{Bmatrix} \varnothing  \end{Bmatrix}$ $\begin{Bmatrix} \varnothing & \begin{Bmatrix} \varnothing \end{Bmatrix} \end{Bmatrix}$ I know number 1 is an empty set. So if S is an empty set, can denote it like this: S = {}. Correct? Now, I'm having difficultly with perceiving what number 2 is. Well it looks like it's a set of an empty set. Confused with 3 as well. Could anyone explain to me the difference between the three? (Note: I've just started discrete maths this week.)",,"['elementary-set-theory', 'notation']"
73,Meaning of symbol $\mathcal{P}$ in set theory article?,Meaning of symbol  in set theory article?,\mathcal{P},"I am teaching myself real analysis, and in this particular set of lecture notes, the introductory chapter on set theory when explaining that not all sets are countable, states as follows: If $S$ is a set, $\operatorname{card}(S) < \operatorname{card}(\mathcal{P}(S))$. Can anyone tell me what this means? It is theorem 1.5.2 found on page 13 of the article.","I am teaching myself real analysis, and in this particular set of lecture notes, the introductory chapter on set theory when explaining that not all sets are countable, states as follows: If $S$ is a set, $\operatorname{card}(S) < \operatorname{card}(\mathcal{P}(S))$. Can anyone tell me what this means? It is theorem 1.5.2 found on page 13 of the article.",,"['elementary-set-theory', 'notation']"
74,Cardinality of all dense and countable sets of $\mathbb{R}$,Cardinality of all dense and countable sets of,\mathbb{R},What is the cardinality of the following set: $$\mathbb{A}:=\{A \ : A\subseteq\mathbb{R} \ \  \text{dense and countable}\}$$ (Is $\mathbb{A}$ a separable space ?) Thank You!,What is the cardinality of the following set: $$\mathbb{A}:=\{A \ : A\subseteq\mathbb{R} \ \  \text{dense and countable}\}$$ (Is $\mathbb{A}$ a separable space ?) Thank You!,,"['general-topology', 'elementary-set-theory']"
75,Set Theory Help [closed],Set Theory Help [closed],,"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 5 years ago . Improve this question I have a test coming up on set theory, so the basic definitions, set operations, relations and functions.  On the test I will have to do proofs involving all of these (subset, unions, intersections, relative complements, cartesian products, different kinds of relations, partial order/strict order, inverse, composition, fuctions, one-to-one functions, onto funtions, etc.) What I was wondering is if anyone has any tips for doing proofs. Usually I have a problem getting started with the proof...what rules to start with and what exactly I want to end up with. Then I think of using certain theorems but when I look at solutions from my teacher he uses different theorems. Any tips would be great","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 5 years ago . Improve this question I have a test coming up on set theory, so the basic definitions, set operations, relations and functions.  On the test I will have to do proofs involving all of these (subset, unions, intersections, relative complements, cartesian products, different kinds of relations, partial order/strict order, inverse, composition, fuctions, one-to-one functions, onto funtions, etc.) What I was wondering is if anyone has any tips for doing proofs. Usually I have a problem getting started with the proof...what rules to start with and what exactly I want to end up with. Then I think of using certain theorems but when I look at solutions from my teacher he uses different theorems. Any tips would be great",,"['elementary-set-theory', 'proof-writing']"
76,"Why is $\bigcup_{n\geq 1}[0,1-1/n] \neq [0,1]$?",Why is ?,"\bigcup_{n\geq 1}[0,1-1/n] \neq [0,1]","Sorry but aren't we taking limits $\lim_{m \to \infty} \cup_{n =1 }^{m}[0,1-1/n] = [0,1]$? Why is this supposed to be equal to $[0,1)$?","Sorry but aren't we taking limits $\lim_{m \to \infty} \cup_{n =1 }^{m}[0,1-1/n] = [0,1]$? Why is this supposed to be equal to $[0,1)$?",,['elementary-set-theory']
77,"Set theory. Is $\varnothing \in \{1,2,3\}$ true?",Set theory. Is  true?,"\varnothing \in \{1,2,3\}","Let $A = \{1, 2, 3\}$. Is the following expression true then? $\varnothing \in A$. I'm having issue understanding if the empty set is an element of $A$. Would love a brief explanation of why it is or isn't. Thanks a lot.","Let $A = \{1, 2, 3\}$. Is the following expression true then? $\varnothing \in A$. I'm having issue understanding if the empty set is an element of $A$. Would love a brief explanation of why it is or isn't. Thanks a lot.",,['elementary-set-theory']
78,Why is $ A^0 = \{ \emptyset \}$?,Why is ?, A^0 = \{ \emptyset \},Let $A$ be a set and denote $\underbrace{A \times A \times \cdots \times A}_\text{n times}$ by $A^n$. Why is it that $A^0 = \{ \emptyset \}$ ?,Let $A$ be a set and denote $\underbrace{A \times A \times \cdots \times A}_\text{n times}$ by $A^n$. Why is it that $A^0 = \{ \emptyset \}$ ?,,['elementary-set-theory']
79,Why vacuously true is defined for 'every' and is not defined for 'there exist',Why vacuously true is defined for 'every' and is not defined for 'there exist',,"When get general logic statements of vacuous truth, seems that the allowed forms are only for 'all ($\forall$)', and not for 'there exist ($\exists$)'. For example, in wiki , it shows the possible universally quantified statements are: $\forall x:P(x)\Rightarrow Q(x)$, where it is the case that $\forall x:\neg P(x)$. $\forall x\in A:Q(x)$, where the set $A$ is empty. $\forall \xi :Q(\xi )$, where the symbol $\xi$ is restricted to a type that has no representatives. I dont understand why there is no form constructed by $\exists$, for example: $\exists x\in A:Q(x)$, where the set $A$ is empty. In my understanding, this statement is equivalent to say: ""if there exist $x\in A$, then $Q(x)$ is true"". When $A$ is empty, that means the ""there exist $x\in A$"" is false, i.e. the $P$ of ""$P\Rightarrow Q$"" is false, then logically, the statement should be vacuously true. Could someone tell me where is wrong with this statement? (I know it's wrong as it is used to show ""$\varnothing\not\subset A$ is false instead of vacuous true"". See, for example, in discussion : ""$X$ is not a subset of $A$"", in symbols $X\not\subset A,$ means $\exists x(x\in X\text{ and }x\notin A).$ If $X$ has no elements, this existential statement is not true vacuously, it is simply false. ).","When get general logic statements of vacuous truth, seems that the allowed forms are only for 'all ($\forall$)', and not for 'there exist ($\exists$)'. For example, in wiki , it shows the possible universally quantified statements are: $\forall x:P(x)\Rightarrow Q(x)$, where it is the case that $\forall x:\neg P(x)$. $\forall x\in A:Q(x)$, where the set $A$ is empty. $\forall \xi :Q(\xi )$, where the symbol $\xi$ is restricted to a type that has no representatives. I dont understand why there is no form constructed by $\exists$, for example: $\exists x\in A:Q(x)$, where the set $A$ is empty. In my understanding, this statement is equivalent to say: ""if there exist $x\in A$, then $Q(x)$ is true"". When $A$ is empty, that means the ""there exist $x\in A$"" is false, i.e. the $P$ of ""$P\Rightarrow Q$"" is false, then logically, the statement should be vacuously true. Could someone tell me where is wrong with this statement? (I know it's wrong as it is used to show ""$\varnothing\not\subset A$ is false instead of vacuous true"". See, for example, in discussion : ""$X$ is not a subset of $A$"", in symbols $X\not\subset A,$ means $\exists x(x\in X\text{ and }x\notin A).$ If $X$ has no elements, this existential statement is not true vacuously, it is simply false. ).",,"['elementary-set-theory', 'logic']"
80,The Wikipedia definition of an Antisymmetric relation,The Wikipedia definition of an Antisymmetric relation,,"The Wikipedia definition of an Antisymmetric relation says : R is antisymmetric precisely if for all $a$ and  $b$ in $X$ \begin{align} \text{if } R(a,b) \text{ and } R(b,a) \text{ then } a=b. \end{align} or, equivalently \begin{align} \text{if } R(a,b) \text{ with } a\ne b  \text{ then } R(b,a) \text{ must not hold. } \end{align} My Question : Shouldn't the contrapositive of the first statement say \begin{align} \text{if } a\ne b \text{ then } R(a,b) \text{ or } R(b,a). \end{align} and in considering the mathematical sense of ""or"", it might as well happen that even if $R(a,b)$ holds ; nothing stops from $R(b,a)$ NOT being true. Please help me resolve this.","The Wikipedia definition of an Antisymmetric relation says : R is antisymmetric precisely if for all $a$ and  $b$ in $X$ \begin{align} \text{if } R(a,b) \text{ and } R(b,a) \text{ then } a=b. \end{align} or, equivalently \begin{align} \text{if } R(a,b) \text{ with } a\ne b  \text{ then } R(b,a) \text{ must not hold. } \end{align} My Question : Shouldn't the contrapositive of the first statement say \begin{align} \text{if } a\ne b \text{ then } R(a,b) \text{ or } R(b,a). \end{align} and in considering the mathematical sense of ""or"", it might as well happen that even if $R(a,b)$ holds ; nothing stops from $R(b,a)$ NOT being true. Please help me resolve this.",,"['elementary-set-theory', 'logic']"
81,Countability of a Totally Ordered Set [closed],Countability of a Totally Ordered Set [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Prove or disprove the following statement: If $X$ is a totally ordered set with the property that for every two elements $x$ and $y$ in $X$ such that $x<y$ , there exists another element $z$ such that $x<z<y$ , then $X$ is uncountable. What about the converse of the statement?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Prove or disprove the following statement: If is a totally ordered set with the property that for every two elements and in such that , there exists another element such that , then is uncountable. What about the converse of the statement?",X x y X x<y z x<z<y X,['elementary-set-theory']
82,The cardinality of the even numbers is half of the cardinality of the natural numbers? [duplicate],The cardinality of the even numbers is half of the cardinality of the natural numbers? [duplicate],,"This question already has answers here : What is larger -- the set of all positive even numbers, or the set of all positive integers? (9 answers) Closed 8 years ago . The following match-up makes it clear that the set of even integers and the set of positive integers have the same cardinality(size) since it establishes a one-to-one correspondence between them: but I could also show that the cardinality(size) of the set of even integers is just half of the cardinality of the natural numbers by establishing the correspondence like this (each even positive integer in the second set corresponds with itself in the first set): so is there something wrong here?","This question already has answers here : What is larger -- the set of all positive even numbers, or the set of all positive integers? (9 answers) Closed 8 years ago . The following match-up makes it clear that the set of even integers and the set of positive integers have the same cardinality(size) since it establishes a one-to-one correspondence between them: but I could also show that the cardinality(size) of the set of even integers is just half of the cardinality of the natural numbers by establishing the correspondence like this (each even positive integer in the second set corresponds with itself in the first set): so is there something wrong here?",,"['elementary-set-theory', 'infinity']"
83,Must an infinite intersection of infinite sets be infinite?,Must an infinite intersection of infinite sets be infinite?,,"If $A_2$ is a subset of $A_1$, $A_3$ is a subset of $A_2$, and this goes on infinitely and all contain an infinite number of elements, then is the intersection from $n=1$ to infinity, infinite as well? Prove if no.","If $A_2$ is a subset of $A_1$, $A_3$ is a subset of $A_2$, and this goes on infinitely and all contain an infinite number of elements, then is the intersection from $n=1$ to infinity, infinite as well? Prove if no.",,"['elementary-set-theory', 'infinity']"
84,Basic properties of symmetric difference in sets: $A \Delta B=A \Delta D$ implies $B=D$,Basic properties of symmetric difference in sets:  implies,A \Delta B=A \Delta D B=D,"How can I prove that for any sets $A,B,C,D$ if  $$A \Delta B = C  $$ and $$A \Delta D = C  $$ then $B=D$. Where $\Delta$ denotes symmetric difference.","How can I prove that for any sets $A,B,C,D$ if  $$A \Delta B = C  $$ and $$A \Delta D = C  $$ then $B=D$. Where $\Delta$ denotes symmetric difference.",,['elementary-set-theory']
85,Question about infinite intersection,Question about infinite intersection,,"Is  $\bigcap\limits_{n=1}^\infty (0, 1 + \frac{1}{n})$ equal to $(0, 1)$ or $(0,1]$?  Help is appreciated.","Is  $\bigcap\limits_{n=1}^\infty (0, 1 + \frac{1}{n})$ equal to $(0, 1)$ or $(0,1]$?  Help is appreciated.",,['elementary-set-theory']
86,What's the difference between a dense set and an uncountable set?,What's the difference between a dense set and an uncountable set?,,"I once called a dense set an uncountable set. I was told this was wrong, as the set was dense , and not uncountable . I didn't have the mathematical knowledge to find this confusing, and instead thought I was just mistaken. I still reckon I'm mistaken, but now I don't understand why. A set $X$ is dense iff $\forall x,z \in X$ where $x <z, \ \exists y \in X$ s.t. $x < y <z$ . A set is uncountable if you can't ever count the members in any subset of it. So, let's take the set of naturals. I of course can't count all of the members within the naturals, but I can count all the members in any finite subset of the naturals (of course, since the subset is finite). The problem with an uncountable set, like the set of real numbers, is that finite subsets (that include all members between the lower and upper limits) don't exist. $|[x,z]| = \infty \ \forall x,z \in \Bbb R$ There's an infinite number of members between any two members, and thus all subsets are infinite, which makes counting impossible (hence, uncountable ). Now, maybe there's  way to achieve this uncountability without the set being dense. I just don't see how. Surely, a dense set is an uncountable set and vice versa? EDIT: I took user Pilcrow's adivce, and looked at a proof of the countability of the rationals. If I understand correctly, a set being countable means that there is a formula or algorithm for the next member in line. So, for the rationals, that algorithm could be expressed like this: $\frac ab$ is a rational. $n(\frac ab)$ is the next rational ( next defined by an ordering not of the greatness kind). $$n(\frac ab) = \begin{cases} \frac{a+1}{b} & a+1 < b \\ \frac{1}{b+1} & a +1 = b \end{cases}$$ This would create a countable, ordered multiset, of which the rationals would be a subset. Thus, the rationals are countable (I assume it's impossible to have uncountable subsets of countable sets). From this, I gather that if a poset is dense, it just means that there is no formula/algorithm for the next member, if one is enumerating using the ordering of which the density arises from. To be concrete, $n(\frac ab)$ is undefined if its ordering is so that it is the next number greater than $\frac ab$ . There is no such number, because the rationals are dense when using the greatness ordering. So, now my question is, is this new understanding correct?","I once called a dense set an uncountable set. I was told this was wrong, as the set was dense , and not uncountable . I didn't have the mathematical knowledge to find this confusing, and instead thought I was just mistaken. I still reckon I'm mistaken, but now I don't understand why. A set is dense iff where s.t. . A set is uncountable if you can't ever count the members in any subset of it. So, let's take the set of naturals. I of course can't count all of the members within the naturals, but I can count all the members in any finite subset of the naturals (of course, since the subset is finite). The problem with an uncountable set, like the set of real numbers, is that finite subsets (that include all members between the lower and upper limits) don't exist. There's an infinite number of members between any two members, and thus all subsets are infinite, which makes counting impossible (hence, uncountable ). Now, maybe there's  way to achieve this uncountability without the set being dense. I just don't see how. Surely, a dense set is an uncountable set and vice versa? EDIT: I took user Pilcrow's adivce, and looked at a proof of the countability of the rationals. If I understand correctly, a set being countable means that there is a formula or algorithm for the next member in line. So, for the rationals, that algorithm could be expressed like this: is a rational. is the next rational ( next defined by an ordering not of the greatness kind). This would create a countable, ordered multiset, of which the rationals would be a subset. Thus, the rationals are countable (I assume it's impossible to have uncountable subsets of countable sets). From this, I gather that if a poset is dense, it just means that there is no formula/algorithm for the next member, if one is enumerating using the ordering of which the density arises from. To be concrete, is undefined if its ordering is so that it is the next number greater than . There is no such number, because the rationals are dense when using the greatness ordering. So, now my question is, is this new understanding correct?","X \forall x,z \in X x <z, \ \exists y \in X x < y <z |[x,z]| = \infty \ \forall x,z \in \Bbb R \frac ab n(\frac ab) n(\frac ab) = \begin{cases} \frac{a+1}{b} & a+1 < b \\ \frac{1}{b+1} & a +1 = b \end{cases} n(\frac ab) \frac ab","['elementary-set-theory', 'terminology', 'real-numbers', 'infinity']"
87,"if $\mathbb{S}$is any non empty set , why $ \varnothing- \mathbb{S} =\varnothing $ is true?","if is any non empty set , why  is true?",\mathbb{S}  \varnothing- \mathbb{S} =\varnothing ,"i can't understand why ? if   $\mathbb{S}$ is any set , why   $  \varnothing- \mathbb{S}   =\varnothing  $  is true . and does is hold for $  \varnothing- \varnothing   =\varnothing  $ ?? i know that for any two sets $ \mathbb{A,B}$ that $\mathbb{A-B}=  \begin{Bmatrix} x:x\in \mathbb{A}  , x   \notin \mathbb{B}   \end{Bmatrix}$ thanks for advance .","i can't understand why ? if   $\mathbb{S}$ is any set , why   $  \varnothing- \mathbb{S}   =\varnothing  $  is true . and does is hold for $  \varnothing- \varnothing   =\varnothing  $ ?? i know that for any two sets $ \mathbb{A,B}$ that $\mathbb{A-B}=  \begin{Bmatrix} x:x\in \mathbb{A}  , x   \notin \mathbb{B}   \end{Bmatrix}$ thanks for advance .",,['elementary-set-theory']
88,The number of odd size subsets is equal to the number of even size subsets [duplicate],The number of odd size subsets is equal to the number of even size subsets [duplicate],,"This question already has answers here : Exactly half of the elements of $\mathcal{P}(A)$ are odd-sized (8 answers) Closed 10 years ago . Prove that the number of subsets with odd number of elements is equal to the number of subsets with even number of elements. I'm not sure how to approach this problem.  Is this even true for me to prove.  For example, the set {null} contain only one subset, itself, which is even.  Thus, prove by contradiction?","This question already has answers here : Exactly half of the elements of $\mathcal{P}(A)$ are odd-sized (8 answers) Closed 10 years ago . Prove that the number of subsets with odd number of elements is equal to the number of subsets with even number of elements. I'm not sure how to approach this problem.  Is this even true for me to prove.  For example, the set {null} contain only one subset, itself, which is even.  Thus, prove by contradiction?",,"['combinatorics', 'elementary-set-theory']"
89,"How to show if $A \subseteq B$, then $A \cap B = A$?","How to show if , then ?",A \subseteq B A \cap B = A,"Hi I'm new to set theory. I need to prove that if $A \subseteq B$, then $A \cap B = A$. I would like to do this the formal way, without a Venn diagram. How should I proceed?","Hi I'm new to set theory. I need to prove that if $A \subseteq B$, then $A \cap B = A$. I would like to do this the formal way, without a Venn diagram. How should I proceed?",,[]
90,Proof $(A-\{a\}) \sim (B - \{b\}) $,Proof,(A-\{a\}) \sim (B - \{b\}) ,"I must prove the following: ""let $A$ and $B$ two set, with $A \neq \emptyset$ and $B \neq \emptyset$ and $A \sim B$, and $a \in A$ and $b \in B$, then $(A-\{a\}) \sim (B - \{b\})$ The symbol $\sim$ is used for ""equipotency""!! Thanks in advance!","I must prove the following: ""let $A$ and $B$ two set, with $A \neq \emptyset$ and $B \neq \emptyset$ and $A \sim B$, and $a \in A$ and $b \in B$, then $(A-\{a\}) \sim (B - \{b\})$ The symbol $\sim$ is used for ""equipotency""!! Thanks in advance!",,"['elementary-set-theory', 'cardinals']"
91,Prove $A\cup (A\cap B) = A$,Prove,A\cup (A\cap B) = A,"What I've done so far is stated that $(A \cup A) \cap (A \cup B)$  by distribution $A\cap (A\cup B)$        by 1, definition of $\cup$ $A\cap A$              by 2, definition of $\cup$ $A$                   by 3, definition of $\cap$ I'm not sure if I need to state that $A\cup B = \{x\mid x\in A\lor x\in B\}$ somewhere in there. I'd really appreciate some help on this one. Thank you!","What I've done so far is stated that $(A \cup A) \cap (A \cup B)$  by distribution $A\cap (A\cup B)$        by 1, definition of $\cup$ $A\cap A$              by 2, definition of $\cup$ $A$                   by 3, definition of $\cap$ I'm not sure if I need to state that $A\cup B = \{x\mid x\in A\lor x\in B\}$ somewhere in there. I'd really appreciate some help on this one. Thank you!",,['elementary-set-theory']
92,"Prove that if $f \circ g = f\circ h$, then $g = h$","Prove that if , then",f \circ g = f\circ h g = h,"Given three functions, $$f\colon A\to B, g\colon C\to A,h\colon C\to A$$ Prove or disprove that if  $f \circ g = f \circ h$, then $g = h$.","Given three functions, $$f\colon A\to B, g\colon C\to A,h\colon C\to A$$ Prove or disprove that if  $f \circ g = f \circ h$, then $g = h$.",,"['elementary-set-theory', 'function-and-relation-composition']"
93,on cardinality of a set,on cardinality of a set,,Set $S$ is a collection of disjoint sets each having cardinality of that of $\mathbb{R}$.The cardinality of set $S$ is also that of $\mathbb{R}$. $F$ is the set which is union of all the elements of $S$. Is the cardinality of set $F$ is equal to that of $\mathbb{R}$ ?,Set $S$ is a collection of disjoint sets each having cardinality of that of $\mathbb{R}$.The cardinality of set $S$ is also that of $\mathbb{R}$. $F$ is the set which is union of all the elements of $S$. Is the cardinality of set $F$ is equal to that of $\mathbb{R}$ ?,,['elementary-set-theory']
94,What is the meaning of ⊊?,What is the meaning of ⊊?,,"I have encountered this when referencing subsets and vector subspaces. For example, T ⊊ span(S) should mean that T is smaller than span(S)--at least from what I've gathered. Is ⊊ a sort of ≤ or < but for subsets? What would that little crossing line mean? I have tried looking it up on the net but could not find an answer. Thank you.","I have encountered this when referencing subsets and vector subspaces. For example, T ⊊ span(S) should mean that T is smaller than span(S)--at least from what I've gathered. Is ⊊ a sort of ≤ or < but for subsets? What would that little crossing line mean? I have tried looking it up on the net but could not find an answer. Thank you.",,"['linear-algebra', 'elementary-set-theory', 'notation']"
95,"My proof that if $P(A) \subseteq P(B)$, then $A \subseteq B$","My proof that if , then",P(A) \subseteq P(B) A \subseteq B,"I'm not sure if my proof is sound. Here it is: Assume that $P(A) \subseteq P(B)$, so any subset C of A is also a subset of B. Therefore, any element in C is also an element of A, and by the same reasoning is an element of B. Thus $A \subseteq B$, as all the elements in A are proven to be elements in B. I believe that I've covered that every single element in A must be an element in B, but for some reason I feel doubtful. Is my proof correct?","I'm not sure if my proof is sound. Here it is: Assume that $P(A) \subseteq P(B)$, so any subset C of A is also a subset of B. Therefore, any element in C is also an element of A, and by the same reasoning is an element of B. Thus $A \subseteq B$, as all the elements in A are proven to be elements in B. I believe that I've covered that every single element in A must be an element in B, but for some reason I feel doubtful. Is my proof correct?",,"['elementary-set-theory', 'proof-writing']"
96,Any hint in how to simplify a set theory expression: $(A \cap B) \cup (A \cap B \cap C' \cap D) \cup (A'\cap B)$,Any hint in how to simplify a set theory expression:,(A \cap B) \cup (A \cap B \cap C' \cap D) \cup (A'\cap B),"I'm having trouble simplifying this set theory expression $$\begin{align} (A \cap B) \cup (A \cap B \cap C' \cap D) \cup (A'\cap B) &  \end{align} $$ In the books says that absorption law can help, but I do not understand why $$\begin{align} (A \cup A') \cap B = U \cap B = B &  \end{align} $$ Can someone guide me in how do this please, just a hint please? I am stuck","I'm having trouble simplifying this set theory expression $$\begin{align} (A \cap B) \cup (A \cap B \cap C' \cap D) \cup (A'\cap B) &  \end{align} $$ In the books says that absorption law can help, but I do not understand why $$\begin{align} (A \cup A') \cap B = U \cap B = B &  \end{align} $$ Can someone guide me in how do this please, just a hint please? I am stuck",,['elementary-set-theory']
97,Show that if $\mathcal{P}(A) \subseteq A $ then $ \mathcal{P}(A) \in A $.,Show that if  then .,\mathcal{P}(A) \subseteq A   \mathcal{P}(A) \in A ,"I was working on a revision worksheet and I came across this question, and I was not sure to answer it. Can anyone help me out with this? Help will be much appreciated.","I was working on a revision worksheet and I came across this question, and I was not sure to answer it. Can anyone help me out with this? Help will be much appreciated.",,['elementary-set-theory']
98,"Why $A=\{1,2\}$ is different of $B=\{\{1,2\}\}$?",Why  is different of ?,"A=\{1,2\} B=\{\{1,2\}\}","If $A=\{1,2\}$ and $B=\{\{1,2\}\}$, why aren't they equals? I'm really confused with situations where sets are contained in itselves.","If $A=\{1,2\}$ and $B=\{\{1,2\}\}$, why aren't they equals? I'm really confused with situations where sets are contained in itselves.",,['elementary-set-theory']
99,Why it is always circle to represent a Set?,Why it is always circle to represent a Set?,,"When we draw a Venn diagram, we use circle to represent a Set. We can use any closed plane figure but most of the time it is a circle.  Why? are there any specialty about that?","When we draw a Venn diagram, we use circle to represent a Set. We can use any closed plane figure but most of the time it is a circle.  Why? are there any specialty about that?",,"['elementary-set-theory', 'education']"
