,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"If $f$ is twice differentiable and satisfies the following constraints, prove that $f'(0)\geq-\sqrt 2$.","If  is twice differentiable and satisfies the following constraints, prove that .",f f'(0)\geq-\sqrt 2,"Let $f$ be a twice differentiable function on the open interval $(-1,1) $such that $f(0)=1$. Suppose $f$ also satisfies $f(x) \ge 0, f'(x) \le 0 $and $f''(x) \le f(x)$, for all $ x\ge 0$. Show that $f'(0) \ge -\sqrt2.$ My attempt $ \rightarrow$  From Taylor's we see that $0 \leq f(x)=f(0)+f'(0)x+\frac{f''(\zeta)x^2}{2} $ for some $\zeta \in (0,x) .$ $f'(x)\leq 0$ and $  f'(x) \le 0 \implies$  $  f''(\zeta) \leq f(\zeta)\leq 1$ Thus $1+f'(0)x+\frac{x^2}{2} \geq 0 $. I'm stuck upto this,I can see that if the discriminant of the quadratic is less than $ 0$ we're done but how do I conclude that the discriminant would be $0$ ?","Let $f$ be a twice differentiable function on the open interval $(-1,1) $such that $f(0)=1$. Suppose $f$ also satisfies $f(x) \ge 0, f'(x) \le 0 $and $f''(x) \le f(x)$, for all $ x\ge 0$. Show that $f'(0) \ge -\sqrt2.$ My attempt $ \rightarrow$  From Taylor's we see that $0 \leq f(x)=f(0)+f'(0)x+\frac{f''(\zeta)x^2}{2} $ for some $\zeta \in (0,x) .$ $f'(x)\leq 0$ and $  f'(x) \le 0 \implies$  $  f''(\zeta) \leq f(\zeta)\leq 1$ Thus $1+f'(0)x+\frac{x^2}{2} \geq 0 $. I'm stuck upto this,I can see that if the discriminant of the quadratic is less than $ 0$ we're done but how do I conclude that the discriminant would be $0$ ?",,"['real-analysis', 'calculus', 'derivatives', 'mean-value-theorem']"
1,Computers can't deal with limit of $\Delta x \to 0$,Computers can't deal with limit of,\Delta x \to 0,"While I was studying about finite differences I came across an article that says ""computers can't deal with limit of $\Delta x \to 0$ "" in finite differences .But if computers can't deal with these equations does anybody know how they compute $ \frac {d}{dx}$ of $x^2$ and other such equations.Or whether these equations are pre-written.","While I was studying about finite differences I came across an article that says ""computers can't deal with limit of $\Delta x \to 0$ "" in finite differences .But if computers can't deal with these equations does anybody know how they compute $ \frac {d}{dx}$ of $x^2$ and other such equations.Or whether these equations are pre-written.",,"['calculus', 'derivatives', 'computer-science']"
2,What is the derivative of $\arccos(x^2)$?,What is the derivative of ?,\arccos(x^2),So I know that the derivative of arccos is:  $-dx/\sqrt{1-x^2}$ So how would I find the derivative of $\arccos(x^2)$? What does the $-dx$ mean in the above formula? Would it just be $-2x/\sqrt{1-x^2}$ ?,So I know that the derivative of arccos is:  $-dx/\sqrt{1-x^2}$ So how would I find the derivative of $\arccos(x^2)$? What does the $-dx$ mean in the above formula? Would it just be $-2x/\sqrt{1-x^2}$ ?,,"['calculus', 'derivatives']"
3,Second partial derivative test is inconclusive,Second partial derivative test is inconclusive,,"I am trying to find the critical points of the function: $f(x,y)=2x^4-3x^2y+y^2$ and find the Max, Min and saddle points. What I've done so far is: $f_x=8x^3-6xy=0  ,  f_y=-3x^2+2y=0  ,  f_{xx}=24x^2-6y  ,  f_{yy}=2  ,  f_{xy}=-6x$ So (0,0) is the only critical point. But using the second partial derivative test: $\Delta(0,0)=f_{xx} . f_{yy} - f^2_{xy}=0$ Which is inconclusive. Without using MATLAB or similar software and based on calculation, how can we determine whether (0,0) is Max, Min or saddle point? Or the general question is what to do when it's inconclusive (without using software)?","I am trying to find the critical points of the function: $f(x,y)=2x^4-3x^2y+y^2$ and find the Max, Min and saddle points. What I've done so far is: $f_x=8x^3-6xy=0  ,  f_y=-3x^2+2y=0  ,  f_{xx}=24x^2-6y  ,  f_{yy}=2  ,  f_{xy}=-6x$ So (0,0) is the only critical point. But using the second partial derivative test: $\Delta(0,0)=f_{xx} . f_{yy} - f^2_{xy}=0$ Which is inconclusive. Without using MATLAB or similar software and based on calculation, how can we determine whether (0,0) is Max, Min or saddle point? Or the general question is what to do when it's inconclusive (without using software)?",,"['derivatives', 'partial-derivative']"
4,Second derivative of a composite function,Second derivative of a composite function,,"Say, we have three Banach spaces $X, Y, Z$ and $g:X \to Y, \ \ f:Y \to Z$ are twice (Fréchet) differenciable. The question is: what is $(f \circ g)''$? Since $(f \circ g)'':X \to   \mathcal{L}^2(X,Z)$, I am interested in the most explicit form: $(f \circ g)''(a)[k, h]$ which would describe the entire action taking place. Let's pick some $a \in X$ and get started: \begin{align}  \\ (f \circ g)''(a)[k, h] &= D_{k}D_{h}(f \circ g)(a) \\  &= D_{k} \bigg( D_{h}(f \circ g)(a) \bigg) \\  &= D_{k} \bigg( (f \circ g)'(a)[h] \bigg)  \\  &= \bigg( D_{k} (f \circ g)'(a)\bigg) [h] \ \ \ \ \ \text{(by linearity)} \\  &= \bigg( D_{k} f'(g(a)) \circ g'(a)\bigg) [h] \ \ \ \ \ \text{(chain rule)} \\  &= \bigg( \frac{d}{dt} f'(g(a+tk)) \circ g'(a+tk)|_{t=0}\bigg) [h] \end{align} I’m really confused what to do next. It looks like we’d need to apply some sort of the product rule (but there is no product here: only compositions). And whatever I do next, I immediately lose track of how it all fits with $k$ and $h$. Any explanations (the more detailed the better) are hugely appreciated.","Say, we have three Banach spaces $X, Y, Z$ and $g:X \to Y, \ \ f:Y \to Z$ are twice (Fréchet) differenciable. The question is: what is $(f \circ g)''$? Since $(f \circ g)'':X \to   \mathcal{L}^2(X,Z)$, I am interested in the most explicit form: $(f \circ g)''(a)[k, h]$ which would describe the entire action taking place. Let's pick some $a \in X$ and get started: \begin{align}  \\ (f \circ g)''(a)[k, h] &= D_{k}D_{h}(f \circ g)(a) \\  &= D_{k} \bigg( D_{h}(f \circ g)(a) \bigg) \\  &= D_{k} \bigg( (f \circ g)'(a)[h] \bigg)  \\  &= \bigg( D_{k} (f \circ g)'(a)\bigg) [h] \ \ \ \ \ \text{(by linearity)} \\  &= \bigg( D_{k} f'(g(a)) \circ g'(a)\bigg) [h] \ \ \ \ \ \text{(chain rule)} \\  &= \bigg( \frac{d}{dt} f'(g(a+tk)) \circ g'(a+tk)|_{t=0}\bigg) [h] \end{align} I’m really confused what to do next. It looks like we’d need to apply some sort of the product rule (but there is no product here: only compositions). And whatever I do next, I immediately lose track of how it all fits with $k$ and $h$. Any explanations (the more detailed the better) are hugely appreciated.",,"['calculus', 'real-analysis', 'derivatives', 'banach-spaces']"
5,derivative with respect to $\log(x)$,derivative with respect to,\log(x),"I have a dynamic equation, $$ \frac{\dot{k}}{k} = s k^{\alpha - 1} + \delta + n$$ Where $\dot{k}/k$ is the capital growth rate as a function of savings $s$, capital $k$, capital depreciation rate $\delta$, and population growth rate $n$. I have been asked to find the change in the growth rate as $k$ increases. This is of course $$\frac{\partial \dot{k}/k}{\partial k} = (\alpha - 1) s k^{\alpha -2}$$ But what I want to find now is the change in growth rate as $k$ increases proportionately . This should be  $$\frac{\partial \dot{k}/k}{\partial \ln(k)} = ?$$ How do you calculate the partial derivative with respect to the logarithm of a variable? I'm sure the answer is simple, but my analytical calculus is pretty rusty.","I have a dynamic equation, $$ \frac{\dot{k}}{k} = s k^{\alpha - 1} + \delta + n$$ Where $\dot{k}/k$ is the capital growth rate as a function of savings $s$, capital $k$, capital depreciation rate $\delta$, and population growth rate $n$. I have been asked to find the change in the growth rate as $k$ increases. This is of course $$\frac{\partial \dot{k}/k}{\partial k} = (\alpha - 1) s k^{\alpha -2}$$ But what I want to find now is the change in growth rate as $k$ increases proportionately . This should be  $$\frac{\partial \dot{k}/k}{\partial \ln(k)} = ?$$ How do you calculate the partial derivative with respect to the logarithm of a variable? I'm sure the answer is simple, but my analytical calculus is pretty rusty.",,"['calculus', 'derivatives', 'economics']"
6,normalized Laplacian of Gaussian,normalized Laplacian of Gaussian,,"Laplacian of Gaussian formula for 2d case is $$\operatorname{LoG}(x,y) = \frac{1}{\pi\sigma^4}\left(\frac{x^2+y^2}{2\sigma^2} - 1\right)e^{-\frac{x^2+y^2}{2\sigma^2}},$$ in scale-space related processing of digital images, to make the Laplacian of Gaussian operator invariant to scales, it is always said to normalize $LoG$ by multiplying $\sigma^2$, that is $$\operatorname{LoG}_\text{normalized}(x,y) = \sigma^2\cdot \operatorname{LoG}(x,y) = \frac{1}{\pi\sigma^2}\left(\frac{x^2+y^2}{2\sigma^2} - 1\right)e^{-\frac{x^2+y^2}{2\sigma^2}}.$$ I wonder why multiply by $\sigma^2$ not $\sigma^4$ or anything else? UPDATE Thanks to comments from @achille. From the perspective of dimensional analysis , in the Laplacian of Gaussian operator $$LoG(x,y,\sigma)=\frac{\partial^2g}{\partial x^2} +\frac{\partial^2g}{\partial y^2}$$, I think $x,y$ are variables with dimension $L$, $\sigma$ is a parameter with dimension $L$. But what about $g$? Since $g$ is a function of $x,y,\sigma$, $$g(x,y,\sigma)=\frac{1}{2\pi \sigma^2}exp(-\frac{x^2+y^2}{2\sigma^2})$$, and $x,y,\sigma$ are of the same dimension $L$, so I guess in $g$, the term $exp(-\frac{x^2+y^2}{2\sigma^2})$ is dimensionless, isn't it? And the term $\frac{1}{2\pi \sigma^2}$ is of dimension $L^{-2}$, right? So $g$ is actually of dimension $L^{-2}$, isn't it? Now come back to $LoG$, it should have dimension $L^{-4}$? UPDATE 2 Laplacian operator is  $$\nabla^2 = \frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2}$$, and a Gaussian function's scale is $\sigma$, right? If I apply $\nabla^2$ on a Gaussian function $g(x,y,\sigma)$, what is difference of applying the dimensionless $\sigma^2*\nabla^2$?","Laplacian of Gaussian formula for 2d case is $$\operatorname{LoG}(x,y) = \frac{1}{\pi\sigma^4}\left(\frac{x^2+y^2}{2\sigma^2} - 1\right)e^{-\frac{x^2+y^2}{2\sigma^2}},$$ in scale-space related processing of digital images, to make the Laplacian of Gaussian operator invariant to scales, it is always said to normalize $LoG$ by multiplying $\sigma^2$, that is $$\operatorname{LoG}_\text{normalized}(x,y) = \sigma^2\cdot \operatorname{LoG}(x,y) = \frac{1}{\pi\sigma^2}\left(\frac{x^2+y^2}{2\sigma^2} - 1\right)e^{-\frac{x^2+y^2}{2\sigma^2}}.$$ I wonder why multiply by $\sigma^2$ not $\sigma^4$ or anything else? UPDATE Thanks to comments from @achille. From the perspective of dimensional analysis , in the Laplacian of Gaussian operator $$LoG(x,y,\sigma)=\frac{\partial^2g}{\partial x^2} +\frac{\partial^2g}{\partial y^2}$$, I think $x,y$ are variables with dimension $L$, $\sigma$ is a parameter with dimension $L$. But what about $g$? Since $g$ is a function of $x,y,\sigma$, $$g(x,y,\sigma)=\frac{1}{2\pi \sigma^2}exp(-\frac{x^2+y^2}{2\sigma^2})$$, and $x,y,\sigma$ are of the same dimension $L$, so I guess in $g$, the term $exp(-\frac{x^2+y^2}{2\sigma^2})$ is dimensionless, isn't it? And the term $\frac{1}{2\pi \sigma^2}$ is of dimension $L^{-2}$, right? So $g$ is actually of dimension $L^{-2}$, isn't it? Now come back to $LoG$, it should have dimension $L^{-4}$? UPDATE 2 Laplacian operator is  $$\nabla^2 = \frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2}$$, and a Gaussian function's scale is $\sigma$, right? If I apply $\nabla^2$ on a Gaussian function $g(x,y,\sigma)$, what is difference of applying the dimensionless $\sigma^2*\nabla^2$?",,"['derivatives', 'image-processing']"
7,Where is the tangent line to this curve horizontal?,Where is the tangent line to this curve horizontal?,,"Find the $x$-co-ordinate of the point where the tangent line to the curve $\ln(xy)=2.5x$ is horizontal. So, using implicit differentiation, I got $\frac{dy}{dx}$ to be $y(2.5 - \frac{1}{x})$. What do I do next? Thanks!","Find the $x$-co-ordinate of the point where the tangent line to the curve $\ln(xy)=2.5x$ is horizontal. So, using implicit differentiation, I got $\frac{dy}{dx}$ to be $y(2.5 - \frac{1}{x})$. What do I do next? Thanks!",,"['calculus', 'derivatives', 'implicit-differentiation']"
8,Using product and chain rule to find derivative.,Using product and chain rule to find derivative.,,Find the derivative of  $$y =(1+x^2)^4 (2-x^3)^5$$  To solve this I used the product rule and the chain rule. $$u = (1+x^2)^4$$ $$u' = 4 (1+x^2)^3(2x)$$ $$v= (2-x^3)^5$$ $$v' = 5(2-x^3)^4(3x^2)$$ $$uv'+vu'$$ $$((1+x^2)^4)(5(2-x^3)^4(3x^2)) + ((2-x^3)^5 )(4 (1+x^2)^3(2x))$$ The answer I got is: $$(15x^2)(1-x^2)^4(2-x^3)^4 + 8x(2-x^3)^5(1+x^2)^3$$. Why is the answer $$8x(x^2 +1)^3(2-x^3)^5-15x^2(x^2)(X^2+1)^4(2-x^3)4$$?  How did the $15x^2$ become negative?,Find the derivative of  $$y =(1+x^2)^4 (2-x^3)^5$$  To solve this I used the product rule and the chain rule. $$u = (1+x^2)^4$$ $$u' = 4 (1+x^2)^3(2x)$$ $$v= (2-x^3)^5$$ $$v' = 5(2-x^3)^4(3x^2)$$ $$uv'+vu'$$ $$((1+x^2)^4)(5(2-x^3)^4(3x^2)) + ((2-x^3)^5 )(4 (1+x^2)^3(2x))$$ The answer I got is: $$(15x^2)(1-x^2)^4(2-x^3)^4 + 8x(2-x^3)^5(1+x^2)^3$$. Why is the answer $$8x(x^2 +1)^3(2-x^3)^5-15x^2(x^2)(X^2+1)^4(2-x^3)4$$?  How did the $15x^2$ become negative?,,"['calculus', 'derivatives']"
9,"If $ \displaystyle F(x) = \int_{1}^{3 x} \frac{1}{t} ~ \mathrm{d}{t} $, find $ F'(x) $.","If , find .", \displaystyle F(x) = \int_{1}^{3 x} \frac{1}{t} ~ \mathrm{d}{t}   F'(x) ,Did I do the following correctly? \begin{align*}     F'(x) & = \frac{\mathrm{d}}{\mathrm{d}{x}}     \left[ \int_{1}^{3 x} \frac{1}{t} ~ \mathrm{d}{t} \right] \\ & = \frac{\mathrm{d}}{\mathrm{d}{x}} [\ln(3 x) - \ln(1)] \\ & = \frac{\mathrm{d}}{\mathrm{d}{x}} [\ln(3 x)] \\ & = \frac{1}{x}. \end{align*},Did I do the following correctly? \begin{align*}     F'(x) & = \frac{\mathrm{d}}{\mathrm{d}{x}}     \left[ \int_{1}^{3 x} \frac{1}{t} ~ \mathrm{d}{t} \right] \\ & = \frac{\mathrm{d}}{\mathrm{d}{x}} [\ln(3 x) - \ln(1)] \\ & = \frac{\mathrm{d}}{\mathrm{d}{x}} [\ln(3 x)] \\ & = \frac{1}{x}. \end{align*},,"['calculus', 'derivatives', 'logarithms']"
10,"Showing that if $f''(x) = 0$, $f(x) = ax+b$ without integrating","Showing that if ,  without integrating",f''(x) = 0 f(x) = ax+b,"Assume that $f : A \rightarrow \mathbb{R}$ is two times differentiable with $f''(x)=0$   for all $x \in A$, with $A$ an interval. Show, (not by integration), that $f$ is of the form $f(x) = ax + b$ for some constants $a, b$. My answer: I will use the Mean Value Theorem: Take $x,y \in A, x<y$. Applying the Mean Value Theorem on $[x,y]$ gives: $$f''(c)=\frac{f'(y)-f'(x)}{y-x}$$ for some $c \in A$. If $f''(x)=0 $ for all $x \in A$, then $f''(c)=0$, wich means that $f''(c)=\frac{f'(y)-f'(x)}{y-x}= 0$, which implies that $f'(y)-f'(x)=0$. So $f'(y)=f'(x)$. Set $k$ equal to this common value. Because x and y are arbitrary, it follows that $f'(x)=a$ for all $x \in A$ We are now given that $f'(x)=a$ for all $x \in A$. This means that, if we take $x,y \in A, x<y, $, by applying the Mean Value Theorem on [x,y],  $$f'(c)=\frac{f(y)-f(x)}{y-x}$$ for some $c \in A$. We know that $f'(x)=a$ for all $x \in A$, which means that $$f'(c)=\frac{f(y)-f(x)}{y-x}=a \implies f(y)-f(x)=a(y-x)$$ What's next? I could also use the definition of derivative, considering: $$f'(x)=a = \lim_{x \to c} \frac{f(x)-f(c)}{x-c}$$ How can I show that $f(x) = ax + b$ ?","Assume that $f : A \rightarrow \mathbb{R}$ is two times differentiable with $f''(x)=0$   for all $x \in A$, with $A$ an interval. Show, (not by integration), that $f$ is of the form $f(x) = ax + b$ for some constants $a, b$. My answer: I will use the Mean Value Theorem: Take $x,y \in A, x<y$. Applying the Mean Value Theorem on $[x,y]$ gives: $$f''(c)=\frac{f'(y)-f'(x)}{y-x}$$ for some $c \in A$. If $f''(x)=0 $ for all $x \in A$, then $f''(c)=0$, wich means that $f''(c)=\frac{f'(y)-f'(x)}{y-x}= 0$, which implies that $f'(y)-f'(x)=0$. So $f'(y)=f'(x)$. Set $k$ equal to this common value. Because x and y are arbitrary, it follows that $f'(x)=a$ for all $x \in A$ We are now given that $f'(x)=a$ for all $x \in A$. This means that, if we take $x,y \in A, x<y, $, by applying the Mean Value Theorem on [x,y],  $$f'(c)=\frac{f(y)-f(x)}{y-x}$$ for some $c \in A$. We know that $f'(x)=a$ for all $x \in A$, which means that $$f'(c)=\frac{f(y)-f(x)}{y-x}=a \implies f(y)-f(x)=a(y-x)$$ What's next? I could also use the definition of derivative, considering: $$f'(x)=a = \lim_{x \to c} \frac{f(x)-f(c)}{x-c}$$ How can I show that $f(x) = ax + b$ ?",,"['real-analysis', 'derivatives']"
11,Differentiation from first principles of specific form.,Differentiation from first principles of specific form.,,"I've been posed a question in which I'm to differentiate with respect to $x$ a function of the form $(x+a)^k$. I've successfully completed (matches the book's answer) the question by using the chain rule, however I cannot achieve the same result using the definition of the derivative. I would like a worked example of differentiation from first principles of a function of the form $(x+a)^k$.","I've been posed a question in which I'm to differentiate with respect to $x$ a function of the form $(x+a)^k$. I've successfully completed (matches the book's answer) the question by using the chain rule, however I cannot achieve the same result using the definition of the derivative. I would like a worked example of differentiation from first principles of a function of the form $(x+a)^k$.",,"['calculus', 'derivatives', 'self-learning']"
12,Derivative over variable vs. partial derivative over variable,Derivative over variable vs. partial derivative over variable,,"I was watching one of the Khan Academy videos on differential equations ("" Exact Equations Intuition 1 (proofy) "") and there's something that confused me. In the video, they use both the derivative of a function $\psi(x, y(x))$ with respect to $x$, $$\frac{d}{dx}\psi(x, y(x)),$$ as well as the partial derivative of the same function with respect to the same variable, $$\frac{\partial \psi}{\partial x}$$ (I think) I understand what a partial derivative of a function is (you consider its other arguments constants and you essentially turn it into a derivative of a single variable function), but I don't understand what a non-partial derivative with respect to one variable means. How is it different from a partial derivative?","I was watching one of the Khan Academy videos on differential equations ("" Exact Equations Intuition 1 (proofy) "") and there's something that confused me. In the video, they use both the derivative of a function $\psi(x, y(x))$ with respect to $x$, $$\frac{d}{dx}\psi(x, y(x)),$$ as well as the partial derivative of the same function with respect to the same variable, $$\frac{\partial \psi}{\partial x}$$ (I think) I understand what a partial derivative of a function is (you consider its other arguments constants and you essentially turn it into a derivative of a single variable function), but I don't understand what a non-partial derivative with respect to one variable means. How is it different from a partial derivative?",,"['calculus', 'derivatives']"
13,$x^5 = 9^x$ Solution by Derivatives (Where Did I Go Wrong)?,Solution by Derivatives (Where Did I Go Wrong)?,x^5 = 9^x,Where is my solution to the following problem wrong? Problem: $x^5 = 9^x$ Solve for x. $5x^4 = 9^x * \ln(9)$ d/dx both sides. $5x^4 = x^5 * \ln(9)$ As stated in the problem 9^x is equal to x^5 so substitute that in here. $5 = x * \ln(9)$ Divide x^5 by x^4 and get x. $5 / \ln(9) = x$ Isolate variables. But this is wrong! Where did I go wrong?  Was it in my derivation?  d/dx 9^x is 9^x * ln(9) so my derivative tables tell me. Was it in substituting x^5 for 9^x?  That seems allowed as long as the equation has a solution.  And it does.  It's just not x = 5/ln(9).,Where is my solution to the following problem wrong? Problem: Solve for x. d/dx both sides. As stated in the problem 9^x is equal to x^5 so substitute that in here. Divide x^5 by x^4 and get x. Isolate variables. But this is wrong! Where did I go wrong?  Was it in my derivation?  d/dx 9^x is 9^x * ln(9) so my derivative tables tell me. Was it in substituting x^5 for 9^x?  That seems allowed as long as the equation has a solution.  And it does.  It's just not x = 5/ln(9).,x^5 = 9^x 5x^4 = 9^x * \ln(9) 5x^4 = x^5 * \ln(9) 5 = x * \ln(9) 5 / \ln(9) = x,"['calculus', 'derivatives']"
14,Why is it possible to cancel a function in $\frac{\partial f}{\partial x}$?,Why is it possible to cancel a function in ?,\frac{\partial f}{\partial x},"I am a freshman engineering student. In my university, in the first semester we studied differentiation and continuity, infinite series and conic sections in mathematics and some thermodynamics in physics. In second term we study integration and Linear algebra in mathematics and Schrödinger equations in physics. I don’t know if this is standard or normal for other countries but all my friends in other universities have to take Schrödinger  in second semester. This seems like we are trying to run before learning how to walk. $\require{cancel}$ I want to ask how we can do this $\frac{ \partial w(x,t)}{ \partial x}= \frac{2i\pi w(x,t) P}{h} $ then $\frac{ \partial \cancel{ w(x,t)}}{ \partial x}= \frac{2i\pi \cancel{ w(x,t)} P}{h} $ in other words $\frac{ \partial}{ \partial x}= \frac{2i\pi  P}{h} $ I want to ask, how is it possible to cancel a function this way and what does $\frac{\partial }{\partial x}$ even mean without a function? When I tried to ask my professor, he told me something about linear operators and I didn’t understand a word from him. When I googled this, it was something related to linear algebra. Is it possible to explain this to someone who didn’t study multi variable calculus or linear algebra or ODE or PDE? Another question is: Is it normal to take Schrödinger equations in the second semester of the first year without proper mathematics?","I am a freshman engineering student. In my university, in the first semester we studied differentiation and continuity, infinite series and conic sections in mathematics and some thermodynamics in physics. In second term we study integration and Linear algebra in mathematics and Schrödinger equations in physics. I don’t know if this is standard or normal for other countries but all my friends in other universities have to take Schrödinger  in second semester. This seems like we are trying to run before learning how to walk. I want to ask how we can do this then in other words I want to ask, how is it possible to cancel a function this way and what does even mean without a function? When I tried to ask my professor, he told me something about linear operators and I didn’t understand a word from him. When I googled this, it was something related to linear algebra. Is it possible to explain this to someone who didn’t study multi variable calculus or linear algebra or ODE or PDE? Another question is: Is it normal to take Schrödinger equations in the second semester of the first year without proper mathematics?","\require{cancel} \frac{ \partial w(x,t)}{ \partial x}= \frac{2i\pi w(x,t) P}{h}  \frac{ \partial \cancel{ w(x,t)}}{ \partial x}= \frac{2i\pi \cancel{ w(x,t)} P}{h}  \frac{ \partial}{ \partial x}= \frac{2i\pi  P}{h}  \frac{\partial }{\partial x}","['calculus', 'derivatives', 'partial-differential-equations', 'partial-derivative']"
15,How to find the derivative of a piecewise function?,How to find the derivative of a piecewise function?,,"How to find the derivative of $\sqrt{x^{2}+4+3(x+\operatorname{sgn}(x))}$ . That is find $\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+4+3(x+\operatorname{sgn}(x))})$ . Now we clearly know that $\operatorname{sgn}(x)$ is a piecewise function. We know that $\operatorname{sgn}(x)=\frac{|x|}{x}$ when $x\neq0$ and $0$ when $x=0$ . Therefore when $x>0$ then the value of $\frac{|x|}{x}$ is $1$ . When $x<0$ then the value of $\frac{|x|}{x}$ is $-1$ . Now let's take cases. Case-1): When $\operatorname{sgn}(x)=1$ , then $\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+4+3x+3\operatorname{sgn}(x)})=\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+7+3x})=\frac{1}{2\sqrt{x^{2}+3x+7}}(2x+3)$ . Case-2): When $\operatorname{sgn}(x)=0$ , then $\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+4+3x+3\operatorname{sgn}(x)})=\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{4})=0$ . Case-3): When $\operatorname{sgn}(x)=-1$ , then $\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+4+3x+3\operatorname{sgn}(x)})=\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+3x+1})=\frac{1}{2\sqrt{x^{2}+3x+1}}(2x+3)$ . So, we can clearly see that $3$ different results are occuring for $\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+4+3(x+\operatorname{sgn}(x))}$ . But I want to know that is my process correct? Are $3$ different results possible? Please do let me know.","How to find the derivative of . That is find . Now we clearly know that is a piecewise function. We know that when and when . Therefore when then the value of is . When then the value of is . Now let's take cases. Case-1): When , then . Case-2): When , then . Case-3): When , then . So, we can clearly see that different results are occuring for . But I want to know that is my process correct? Are different results possible? Please do let me know.",\sqrt{x^{2}+4+3(x+\operatorname{sgn}(x))} \frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+4+3(x+\operatorname{sgn}(x))}) \operatorname{sgn}(x) \operatorname{sgn}(x)=\frac{|x|}{x} x\neq0 0 x=0 x>0 \frac{|x|}{x} 1 x<0 \frac{|x|}{x} -1 \operatorname{sgn}(x)=1 \frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+4+3x+3\operatorname{sgn}(x)})=\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+7+3x})=\frac{1}{2\sqrt{x^{2}+3x+7}}(2x+3) \operatorname{sgn}(x)=0 \frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+4+3x+3\operatorname{sgn}(x)})=\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{4})=0 \operatorname{sgn}(x)=-1 \frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+4+3x+3\operatorname{sgn}(x)})=\frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+3x+1})=\frac{1}{2\sqrt{x^{2}+3x+1}}(2x+3) 3 \frac{\mathrm{d}}{\mathrm{d}x}(\sqrt{x^{2}+4+3(x+\operatorname{sgn}(x))} 3,"['calculus', 'derivatives', 'derivatives-of-piecewise-functions']"
16,Maximize $x + y$ with constraint $y \cdot x^2=15$.,Maximize  with constraint .,x + y y \cdot x^2=15,"As the title says, I am asked to maximize the sum of two numbers $x + y$ when $x^2 \cdot y = 15$ . The thing is... I tried substitution but got nowhere, it seems $h(x) = x + \frac{15}{x^2}$ only has a minimum value, not a maximum. I've been starting to think there is an error in the excercise. I tried Lagrange multiplicators next, having: \begin{align} f(x,y) &= x+y\\ g(x,y) &= x^2\cdot y - 15 = 0 \end{align} Then: \begin{align} \nabla f = \lambda \nabla g \end{align} that gives: \begin{align} 2xy &= 1\\ 2x^2 &= 1\\ x^2\cdot y &= 15 \end{align} then we find \begin{align} 2xy &= 2x^2\\ x(2y - x) &= 0\\ x = 0 &\lor x = 2y \end{align} Now, from $x^2 \cdot y = 15$ we know $x,y>0$ , then we only have one solution $x=2y$ , applying that to $g(x)$ we get $x^2 \cdot \frac{x}{2} = 15 \implies x = \sqrt[3]{30}, y = \frac{\sqrt[3]{30}}{2}$ . Then the only point that I can use from Lagrange is $(\sqrt[3]{30}, \frac{\sqrt[3]{30}}{2})$ . But what guarantee do I have that said point is the maximum of the sum of $x + y$ ?. Doesn't Lagrange only find extremes? How do I check this result? As I said earlier, if I graph $h(x) = x + \frac{15}{x^2}$ in $R^2$ I find that $x=\sqrt[3]{30}$ is the value in the $x$ axis where the minimum value of $h(x)$ is, so this only feeds my suspicions about the problem having an error and the point needed being actually a minimum instead of a maximum. Can anyone shed some light into this?","As the title says, I am asked to maximize the sum of two numbers when . The thing is... I tried substitution but got nowhere, it seems only has a minimum value, not a maximum. I've been starting to think there is an error in the excercise. I tried Lagrange multiplicators next, having: Then: that gives: then we find Now, from we know , then we only have one solution , applying that to we get . Then the only point that I can use from Lagrange is . But what guarantee do I have that said point is the maximum of the sum of ?. Doesn't Lagrange only find extremes? How do I check this result? As I said earlier, if I graph in I find that is the value in the axis where the minimum value of is, so this only feeds my suspicions about the problem having an error and the point needed being actually a minimum instead of a maximum. Can anyone shed some light into this?","x + y x^2 \cdot y = 15 h(x) = x + \frac{15}{x^2} \begin{align}
f(x,y) &= x+y\\
g(x,y) &= x^2\cdot y - 15 = 0
\end{align} \begin{align}
\nabla f = \lambda \nabla g
\end{align} \begin{align}
2xy &= 1\\
2x^2 &= 1\\
x^2\cdot y &= 15
\end{align} \begin{align}
2xy &= 2x^2\\
x(2y - x) &= 0\\
x = 0 &\lor x = 2y
\end{align} x^2 \cdot y = 15 x,y>0 x=2y g(x) x^2 \cdot \frac{x}{2} = 15 \implies x = \sqrt[3]{30}, y = \frac{\sqrt[3]{30}}{2} (\sqrt[3]{30}, \frac{\sqrt[3]{30}}{2}) x + y h(x) = x + \frac{15}{x^2} R^2 x=\sqrt[3]{30} x h(x)","['calculus', 'derivatives']"
17,What's the derivative with respect to a constant?,What's the derivative with respect to a constant?,,"Suppose I have $f(x) = 5x$ . I know that $\frac{d\ f(x)}{dx} = 5$ . But what is $\frac{d f(x)}{d 5}$ , the derivative of the function $f$ with respect to the constant 5? The reason I ask is that I'm implementing software that computes auto-differentiation (a la TensorFlow). I want to know if I can treat a constant like a variable (as above) or if I have to do something else. This Stanford deep learning class webpage is what I'm referring to: $$ f(x) = c+x \\ f_a(x) = ax $$ Where the functions $f_c$ , $f_a$ translate the input by a constant of $c$ and scale the input by a constant of $a$ , respectively. These are technically special cases of addition and multiplication, but we introduce them as (new) unary gates here since we do not need the gradients for the constants $c$ , $a$ . That above statement implies that you could compute the derivative w.r.t. a constant, but they chose not to. This post did not answer my question: derivative with respect to constant. Thanks.","Suppose I have . I know that . But what is , the derivative of the function with respect to the constant 5? The reason I ask is that I'm implementing software that computes auto-differentiation (a la TensorFlow). I want to know if I can treat a constant like a variable (as above) or if I have to do something else. This Stanford deep learning class webpage is what I'm referring to: Where the functions , translate the input by a constant of and scale the input by a constant of , respectively. These are technically special cases of addition and multiplication, but we introduce them as (new) unary gates here since we do not need the gradients for the constants , . That above statement implies that you could compute the derivative w.r.t. a constant, but they chose not to. This post did not answer my question: derivative with respect to constant. Thanks.","f(x) = 5x \frac{d\ f(x)}{dx} = 5 \frac{d f(x)}{d 5} f 
f(x) = c+x \\
f_a(x) = ax
 f_c f_a c a c a","['calculus', 'derivatives']"
18,How to find $dT$? Thermodynamics (equation of state),How to find ? Thermodynamics (equation of state),dT,"I recently had my first lesson thermodynamics, and there is an exercises that I don't quite understand how you have to get the answer. It goes as follows: $$PV^{2}=nRe^{3T}$$ we are given that n en R are both constants. The question is what is $dT$ ? I don't think I have the right mathematical background to solve this question. I really would love to know where I could find the name of such kind problems. I now how to derive (and partial derivation), but I'm used to working with $\frac{dy}{dx}$ , but know it's only $dy$ or in my case $dT$ . If someone could help, solve this problem and where I can find theory to practice such mathematical problems that would be very helpful Thanks in advance","I recently had my first lesson thermodynamics, and there is an exercises that I don't quite understand how you have to get the answer. It goes as follows: we are given that n en R are both constants. The question is what is ? I don't think I have the right mathematical background to solve this question. I really would love to know where I could find the name of such kind problems. I now how to derive (and partial derivation), but I'm used to working with , but know it's only or in my case . If someone could help, solve this problem and where I can find theory to practice such mathematical problems that would be very helpful Thanks in advance",PV^{2}=nRe^{3T} dT \frac{dy}{dx} dy dT,"['derivatives', 'mathematical-physics']"
19,A problem on Rolle's theorem,A problem on Rolle's theorem,,"So there's this question that asks us to prove that, between any two roots of $\tan x=1$ there exists at least one root of $\tan x =-1$ . Suppose we assume that $a,b$ are two roots of $\tan x-1=0$ , then $f(a)=f(b)=0$ , where $f(x)= \tan x-1$ . According to the theorem, $f'(c)=0$ where $c \in (a,b)$ ,i.e., $\sec^2 c =0$ ....and this is not defined. Either there's something wrong with my understanding or with the problem. Please help.","So there's this question that asks us to prove that, between any two roots of there exists at least one root of . Suppose we assume that are two roots of , then , where . According to the theorem, where ,i.e., ....and this is not defined. Either there's something wrong with my understanding or with the problem. Please help.","\tan x=1 \tan x =-1 a,b \tan x-1=0 f(a)=f(b)=0 f(x)= \tan x-1 f'(c)=0 c \in (a,b) \sec^2 c =0","['derivatives', 'rolles-theorem']"
20,The differences between Lagrange and Leibniz's derivative notations,The differences between Lagrange and Leibniz's derivative notations,,"One problem I have found when learning calculus is that there are many different ways to denote the derivative. If $y=f(x)=x^2$ , then we could write \begin{align} f'(x)&=2x \\ y'&=2x \\ \frac{df}{dx}(x)&=2x \\ \frac{df(x)}{dx}&=2x \\ \frac{d}{dx}f(x)&=2x \\ \frac{dy}{dx}&=2x \end{align} And this is just Lagrange and Leibniz's notations alone. What I find troubling is that they all seem to be suggesting subtly different things about what the derivative actually is . Is it a function, a limit of a quotient, or both? In the interests of keeping my post brief, I'll focus my attention on $f'(x)=2x$ and $\frac{dy}{dx}=2x$ , as these seem to be the most common notations. $$ f'(x)=2x $$ It does make sense to think of the derivative as the gradient function: $$ f'\colon x\mapsto\lim_{\Delta x \to 0}\frac{f(x+\Delta x)-f(x)}{\Delta x} $$ In this case the limit expression is equal to $2x$ , and so we can write $$ f' \colon x \mapsto 2x $$ However, this notation seems a little counter-intuitive when we consider what it means to differentiate a function with respect to a variable other than $x$ . If I ask what is the derivative of $f(x)$ with respect to $\frac{x}{2}$ , does this question make sense? Is it simply $f'(\frac{x}{2})$ ? Or do we have to express $x^2$ in terms of $\frac{x}{2}$ ? And how can we can express this derivative using Lagrange's notation? $$ \frac{dy}{dx}=2x $$ There are many things which are nice about Leibniz's notation, including the fact that it is explicit which variable you are differentiating with respect to. However, in this case, it is unclear whether we are talking about a function, or something else entirely. There are other issues. Some people say they dislike the Leibniz formulation of the chain rule $$ \frac{dy}{dx}=\frac{dy}{du}\frac{du}{dx} $$ saying that they find it to be inaccurate. I don't really understand why this is the case. Could someone please elaborate?","One problem I have found when learning calculus is that there are many different ways to denote the derivative. If , then we could write And this is just Lagrange and Leibniz's notations alone. What I find troubling is that they all seem to be suggesting subtly different things about what the derivative actually is . Is it a function, a limit of a quotient, or both? In the interests of keeping my post brief, I'll focus my attention on and , as these seem to be the most common notations. It does make sense to think of the derivative as the gradient function: In this case the limit expression is equal to , and so we can write However, this notation seems a little counter-intuitive when we consider what it means to differentiate a function with respect to a variable other than . If I ask what is the derivative of with respect to , does this question make sense? Is it simply ? Or do we have to express in terms of ? And how can we can express this derivative using Lagrange's notation? There are many things which are nice about Leibniz's notation, including the fact that it is explicit which variable you are differentiating with respect to. However, in this case, it is unclear whether we are talking about a function, or something else entirely. There are other issues. Some people say they dislike the Leibniz formulation of the chain rule saying that they find it to be inaccurate. I don't really understand why this is the case. Could someone please elaborate?","y=f(x)=x^2 \begin{align}
f'(x)&=2x \\
y'&=2x \\
\frac{df}{dx}(x)&=2x \\
\frac{df(x)}{dx}&=2x \\
\frac{d}{dx}f(x)&=2x \\
\frac{dy}{dx}&=2x
\end{align} f'(x)=2x \frac{dy}{dx}=2x  f'(x)=2x  
f'\colon x\mapsto\lim_{\Delta x \to 0}\frac{f(x+\Delta x)-f(x)}{\Delta x}
 2x 
f' \colon x \mapsto 2x
 x f(x) \frac{x}{2} f'(\frac{x}{2}) x^2 \frac{x}{2}  \frac{dy}{dx}=2x  
\frac{dy}{dx}=\frac{dy}{du}\frac{du}{dx}
","['derivatives', 'notation', 'terminology']"
21,"Gradient of $\mbox{dist}\left(x, D \right)^2:= \left\| x - P_{D}(x)\right\|_2^2$, where $P_{D}(x)$ is a projection operator","Gradient of , where  is a projection operator","\mbox{dist}\left(x, D \right)^2:= \left\| x - P_{D}(x)\right\|_2^2 P_{D}(x)","Let $D \subset \mathbb{R}^{n}$ be a non empty convex closed set and: $$f:\mathbb{R}^{n}\rightarrow \mathbb{R}_{+}, f(x)=(\operatorname{dist}(x,D))^{2}$$ Prove that f is differentiable in $\mathbb{R}^{n}$ and $$f'(x)=2(x-P_{D}(x)), \forall x \in \mathbb{R}^{n},$$ where $\mbox{dist}(x,D)$ is the distance between a point $x$ and the set $D$ and $P_{D}(x)$ is the projection of $x$ in $D$ , i.e., \begin{align} \operatorname{dist}\left(x, D \right) := \left\| x -  P_{D}(x)\right\|_2. \end{align}","Let be a non empty convex closed set and: Prove that f is differentiable in and where is the distance between a point and the set and is the projection of in , i.e.,","D \subset \mathbb{R}^{n} f:\mathbb{R}^{n}\rightarrow \mathbb{R}_{+}, f(x)=(\operatorname{dist}(x,D))^{2} \mathbb{R}^{n} f'(x)=2(x-P_{D}(x)), \forall x \in \mathbb{R}^{n}, \mbox{dist}(x,D) x D P_{D}(x) x D \begin{align}
\operatorname{dist}\left(x, D \right) := \left\| x -  P_{D}(x)\right\|_2.
\end{align}","['derivatives', 'optimization', 'convex-analysis', 'convex-optimization', 'matrix-calculus']"
22,Is the derivative always nonnegative in a neighbourhood of a minimum?,Is the derivative always nonnegative in a neighbourhood of a minimum?,,"Let $f:[0,1] \to \mathbb R$ be a smooth function, and suppose that $f(x) > f(0)$ for every $0< x \le 1$ . Is it true that $f' \ge 0$ in some neighbourhood of $0$ ? $f'(0) \ge 0$ , and by the mean value theorem $$ f'(c(x))=\frac{f(x)-f(0)}{x-0}> 0,$$ where $0<c(x)<x$ . In particular, by taking $x$ to zero, we can construct a sequences $x_n \to 0$ satisfying $f'(x_n) >0$ . I am not sure how to proceed from here. Is there some pathological counter-example?","Let be a smooth function, and suppose that for every . Is it true that in some neighbourhood of ? , and by the mean value theorem where . In particular, by taking to zero, we can construct a sequences satisfying . I am not sure how to proceed from here. Is there some pathological counter-example?","f:[0,1] \to \mathbb R f(x) > f(0) 0< x \le 1 f' \ge 0 0 f'(0) \ge 0  f'(c(x))=\frac{f(x)-f(0)}{x-0}> 0, 0<c(x)<x x x_n \to 0 f'(x_n) >0","['real-analysis', 'calculus', 'derivatives', 'examples-counterexamples', 'monotone-functions']"
23,Power series differentiable at endpoints?,Power series differentiable at endpoints?,,"The usual theorem is something like this (please correct me if this is wrong): Let $R>0$ ( $R$ can be $+\infty$ ). Suppose $c_0+c_1x+c_2x^2+c_3x^3+\dots$ converges on $(-R,R)$ . Define $f:(-R,R)\rightarrow \mathbb R$ by $f(x)=c_0+c_1x+c_2x^2+c_3x^3+\dots$ . Then $f$ is differentiable on $(-R,R)$ , with $f'(x)=c_1+2c_2x+3c_3x^2+\dots$ . Here's my question: Now assume $R\neq+\infty$ . In the above theorem, replace each instance of $(-R,R)$ with (A) $(-R,R]$ ; (B) $[-R,R)$ ; or (C) $[-R,R]$ . to obtain new Theorems A, B, and C. Is each of these new Theorems true? If not, how can we strengthen the assumptions so that each new Theorem is true? (Added note: $R$ need not be the radius of convergence.)","The usual theorem is something like this (please correct me if this is wrong): Let ( can be ). Suppose converges on . Define by . Then is differentiable on , with . Here's my question: Now assume . In the above theorem, replace each instance of with (A) ; (B) ; or (C) . to obtain new Theorems A, B, and C. Is each of these new Theorems true? If not, how can we strengthen the assumptions so that each new Theorem is true? (Added note: need not be the radius of convergence.)","R>0 R +\infty c_0+c_1x+c_2x^2+c_3x^3+\dots (-R,R) f:(-R,R)\rightarrow \mathbb R f(x)=c_0+c_1x+c_2x^2+c_3x^3+\dots f (-R,R) f'(x)=c_1+2c_2x+3c_3x^2+\dots R\neq+\infty (-R,R) (-R,R] [-R,R) [-R,R] R","['real-analysis', 'calculus']"
24,"""Square root"" of a derivative operator?","""Square root"" of a derivative operator?",,"I have been studying derivatives as operators on a function. Specifically, how we may write, for a function $f(x)$ $$\frac{df}{dx}$$ as $$Df$$ where $D$ denotes $\frac{d}{dx}$ . I've seen how successive application of an operator is seen as multiplying the operators together to give rise to a new operator. For example $$\frac{d^2f}{dx^2}$$ can be written as $D^2f$ . What I have been pondering is this: Consider a certain operator $\Phi$ , which has the property that $$\Phi^2f=Df$$ i.e the $\Phi$ operator acts like a sort of ""square root"" of the derivative operator. This would imply that $$\Phi f = h$$ and $$\Phi h = g$$ where $g(x)$ and $h(x)$ are functions and that $$\frac{df}{dx}=g$$ My question is, has such an operator been studied before? Does it have a unique name? I do not necessarily belive $\Phi$ to be unique, perhaps many unique operators may fill the role of $\Phi$ . But can we determine if such an operator is unique or not?","I have been studying derivatives as operators on a function. Specifically, how we may write, for a function as where denotes . I've seen how successive application of an operator is seen as multiplying the operators together to give rise to a new operator. For example can be written as . What I have been pondering is this: Consider a certain operator , which has the property that i.e the operator acts like a sort of ""square root"" of the derivative operator. This would imply that and where and are functions and that My question is, has such an operator been studied before? Does it have a unique name? I do not necessarily belive to be unique, perhaps many unique operators may fill the role of . But can we determine if such an operator is unique or not?",f(x) \frac{df}{dx} Df D \frac{d}{dx} \frac{d^2f}{dx^2} D^2f \Phi \Phi^2f=Df \Phi \Phi f = h \Phi h = g g(x) h(x) \frac{df}{dx}=g \Phi \Phi,"['derivatives', 'differential-operators']"
25,"Prob. 5, Sec. 6.2, in Bartle & Sherbert's INTRO TO REAL ANALYSIS, 4th ed: How to show this function is strictly decreasing using derivative","Prob. 5, Sec. 6.2, in Bartle & Sherbert's INTRO TO REAL ANALYSIS, 4th ed: How to show this function is strictly decreasing using derivative",,"Here is Prob. 5, Sec. 6.2, in the book Introduction To Real Analysis by Robert G. Bartle & Donald R. Sherbert, 4th edition: Let $a > b > 0$ and let $n \in \mathbb{N}$ satisfy $n \geq 2$ . Prove that $a^{1/n} - b^{1/n} < (a-b)^{1/n}$ . [ Hint: Show that $f(x) \colon= x^{1/n} - (x-1)^{1/n}$ is decreasing for $x \geq 1$ , and evaluate $f$ at $1$ and $a/b$ .] My Attempt: We find that for $x > 1$ , $$ \begin{align}  f^\prime(x) &= \frac{1}{n}x^{\frac{1}{n} - 1} - \frac{1}{n}(x-1)^{\frac{1}{n} - 1} \\ &= \frac{1}{n} \left( \frac{x^{1/n}}{x} - \frac{(x-1)^{1/n}}{x-1} \right) \\ &= \frac{1}{nx(x-1)} \left( x^{1/n}(x-1) - x(x-1)^{1/n} \right) \\ &= \frac{x^{1/n}(x-1)^{1/n}}{nx(x-1)} \left( (x-1) - x \right) \\ &= -\frac{1}{nx^{1-\frac{1}{n}} (x-1)^{1-\frac{1}{n}} }.  \end{align} $$ PS (based on the answer by @auscrypt): We find that for $x > 1$ , $$ \begin{align}  f^\prime(x) &= \frac{1}{n}x^{\frac{1}{n} - 1} - \frac{1}{n}(x-1)^{\frac{1}{n} - 1} \\ &= \frac{1}{n} \left( \frac{x^{1/n}}{x} - \frac{(x-1)^{1/n}}{x-1} \right) \\ &= \frac{1}{nx(x-1)} \left( x^{1/n}(x-1) - x(x-1)^{1/n} \right) \\ &= \frac{x^{1/n}(x-1)^{1/n}}{nx(x-1)} \left( (x-1)^{1-1/n} - x^{1-1/n} \right) \\ &< 0.  \end{align} $$ because $1-1/n$ is positive for every $n \in \mathbb{N}$ such that $n \geq 2$ and because $0 < x-1< x$ , which implies that $$ 0 < (x-1)^{1-1/n} < x^{1-1/n},$$ and hence $$ (x-1)^{1-1/n} - x^{1-1/n} < 0.$$ Thus $f^\prime(x) < 0$ for all $x > 1$ . Therefore the function $f$ is strictly decreasing on the interval $[1, +\infty)$ . That is, for any $x > 1$ we have $f(x) < f(1)$ . Now if $a > b > 0$ , then $a/b > 1$ , and so we have $$ f(a/b) < f(1),$$ that is, $$ \left(\frac{a}{b}\right)^{\frac{1}{n}} - \left(\frac{a}{b} - 1\right)^{\frac{1}{n}} < 1,$$ which amounts to $$ \frac{a^{1/n} - (a-b)^{1/n} }{ b^{1/n} } < 1, $$ which implies $$ a^{1/n} - (a-b)^{1/n} < b^{1/n},$$ and hence $$ a^{1/n} - b^{1/n} < (a-b)^{1/n}, $$ as required. Are there any issues with this proof?","Here is Prob. 5, Sec. 6.2, in the book Introduction To Real Analysis by Robert G. Bartle & Donald R. Sherbert, 4th edition: Let and let satisfy . Prove that . [ Hint: Show that is decreasing for , and evaluate at and .] My Attempt: We find that for , PS (based on the answer by @auscrypt): We find that for , because is positive for every such that and because , which implies that and hence Thus for all . Therefore the function is strictly decreasing on the interval . That is, for any we have . Now if , then , and so we have that is, which amounts to which implies and hence as required. Are there any issues with this proof?","a > b > 0 n \in \mathbb{N} n \geq 2 a^{1/n} - b^{1/n} < (a-b)^{1/n} f(x) \colon= x^{1/n} - (x-1)^{1/n} x \geq 1 f 1 a/b x > 1 
\begin{align}
 f^\prime(x) &= \frac{1}{n}x^{\frac{1}{n} - 1} - \frac{1}{n}(x-1)^{\frac{1}{n} - 1} \\
&= \frac{1}{n} \left( \frac{x^{1/n}}{x} - \frac{(x-1)^{1/n}}{x-1} \right) \\
&= \frac{1}{nx(x-1)} \left( x^{1/n}(x-1) - x(x-1)^{1/n} \right) \\
&= \frac{x^{1/n}(x-1)^{1/n}}{nx(x-1)} \left( (x-1) - x \right) \\
&= -\frac{1}{nx^{1-\frac{1}{n}} (x-1)^{1-\frac{1}{n}} }. 
\end{align}
 x > 1 
\begin{align}
 f^\prime(x) &= \frac{1}{n}x^{\frac{1}{n} - 1} - \frac{1}{n}(x-1)^{\frac{1}{n} - 1} \\
&= \frac{1}{n} \left( \frac{x^{1/n}}{x} - \frac{(x-1)^{1/n}}{x-1} \right) \\
&= \frac{1}{nx(x-1)} \left( x^{1/n}(x-1) - x(x-1)^{1/n} \right) \\
&= \frac{x^{1/n}(x-1)^{1/n}}{nx(x-1)} \left( (x-1)^{1-1/n} - x^{1-1/n} \right) \\
&< 0. 
\end{align}
 1-1/n n \in \mathbb{N} n \geq 2 0 < x-1< x  0 < (x-1)^{1-1/n} < x^{1-1/n},  (x-1)^{1-1/n} - x^{1-1/n} < 0. f^\prime(x) < 0 x > 1 f [1, +\infty) x > 1 f(x) < f(1) a > b > 0 a/b > 1  f(a/b) < f(1),  \left(\frac{a}{b}\right)^{\frac{1}{n}} - \left(\frac{a}{b} - 1\right)^{\frac{1}{n}} < 1,  \frac{a^{1/n} - (a-b)^{1/n} }{ b^{1/n} } < 1,   a^{1/n} - (a-b)^{1/n} < b^{1/n},  a^{1/n} - b^{1/n} < (a-b)^{1/n}, ","['real-analysis', 'calculus', 'proof-verification', 'derivatives', 'inequality']"
26,Prove The Derivative Rules in the Ring of Polynomials. How to show Leibniz's rule?,Prove The Derivative Rules in the Ring of Polynomials. How to show Leibniz's rule?,,"Let $R$ be a commutative ring with unity element 1. Let $f(x)\in R[x]$ and define its derivative as $f'(x)=r_1 +2(r_2)x+...+n(r_n)x^{n-1}$ . Prove that $(f+g)'(x)=f'(x)+g'(x)$ and that $(fg)'(x)=f'(x)g(x)+f(x)g'(x)$ So im pretty sure I worked out the addition, but am struggling with the multiplication. Let $f(x),g(x)\in R[x]$ with $f(x)=r_0+r_1x+r_2x^2+...+r_nx^n$ and $g(x)=s_0+s_1x+s_2x^2+...+s_nx^n$ $$(f+g)'(x)=((r_0+s_0)+(r_1+s_1)x+...+(r_n+s_n)x^n)'(x)$$ $$=((r_1+s_1)+2(r_2+s_2)x+...n(r_n+s_n)^{n-1}$$ $$=((r_1+s_1)+(2r_2+2s_2)x+...+(nr_n+nr_n)x^{n-1}$$ $$=f'(x)+g'(x)$$ For the multiplication, this is what I've got so far... $$(fg)'(x)=((r_0s_0)+(r_0s_1+r_1s_0)x+...+(m_j)x^n)$$ where $$m_j=\sum_{i+k=j}^n r_is_k$$ for $j=0,1,2,...$ , $$(fg)'(x)=((r_0s_1+r_1s_0)+2(r_0s_2+r_1s_1+r_2s_0)x+...+n(m_j)x^{n-1}$$ $$=((r_0s_1+r_1s_0)+(2r_0s_2+2r_1s_1+2r_2s_0)x+...+nm_jx^{n-1}$$ This is where I lose it, if I'm even correct up to this point...","Let be a commutative ring with unity element 1. Let and define its derivative as . Prove that and that So im pretty sure I worked out the addition, but am struggling with the multiplication. Let with and For the multiplication, this is what I've got so far... where for , This is where I lose it, if I'm even correct up to this point...","R f(x)\in R[x] f'(x)=r_1 +2(r_2)x+...+n(r_n)x^{n-1} (f+g)'(x)=f'(x)+g'(x) (fg)'(x)=f'(x)g(x)+f(x)g'(x) f(x),g(x)\in R[x] f(x)=r_0+r_1x+r_2x^2+...+r_nx^n g(x)=s_0+s_1x+s_2x^2+...+s_nx^n (f+g)'(x)=((r_0+s_0)+(r_1+s_1)x+...+(r_n+s_n)x^n)'(x) =((r_1+s_1)+2(r_2+s_2)x+...n(r_n+s_n)^{n-1} =((r_1+s_1)+(2r_2+2s_2)x+...+(nr_n+nr_n)x^{n-1} =f'(x)+g'(x) (fg)'(x)=((r_0s_0)+(r_0s_1+r_1s_0)x+...+(m_j)x^n) m_j=\sum_{i+k=j}^n r_is_k j=0,1,2,... (fg)'(x)=((r_0s_1+r_1s_0)+2(r_0s_2+r_1s_1+r_2s_0)x+...+n(m_j)x^{n-1} =((r_0s_1+r_1s_0)+(2r_0s_2+2r_1s_1+2r_2s_0)x+...+nm_jx^{n-1}","['abstract-algebra', 'derivatives', 'polynomials', 'ring-theory']"
27,"Is there any function f which is only differentiable on $(0,\infty)$ and such that $f^{-1} = f'$?",Is there any function f which is only differentiable on  and such that ?,"(0,\infty) f^{-1} = f'","Is there any function f which is only differentiable on $(0,\infty)$ and such that $f^{-1} = f'$ ? I thinks  there exists no such function. I thought about  constant, exponential, trigonometric function, etc., but I didn't find any function which is only    differentiable on $(0,\infty)$ and such that $f^{-1} = f'$ . Is it true?","Is there any function f which is only differentiable on and such that ? I thinks  there exists no such function. I thought about  constant, exponential, trigonometric function, etc., but I didn't find any function which is only    differentiable on and such that . Is it true?","(0,\infty) f^{-1} = f' (0,\infty) f^{-1} = f'","['real-analysis', 'derivatives', 'inverse-function']"
28,Show $f:\mathbb R \to \mathbb R$ by $f(x)=\frac{x}{2}+x^2\sin\frac{1}{x}$ is not injective in any neighbourhood of $0$,Show  by  is not injective in any neighbourhood of,f:\mathbb R \to \mathbb R f(x)=\frac{x}{2}+x^2\sin\frac{1}{x} 0,"Define $f:\mathbb R \to \mathbb R$ by $f(x)=\frac{x}{2}+x^2\sin\frac{1}{x}$ if $x \neq 0$ and $f(0)=0$. Compute $f'(x)$ for all $x \in \mathbb R$. Show that $f'(0)>0$, yet $f$ is not injective in any neighbourhood of $0$. My idea: $f'(x)=\frac{1}{2}+2x\sin{\frac{1}{x}}-\cos{\frac{1}{x}}$ $f'(0)=\frac{1}{2}$ so $f'(0)>0$. (is this correct?) How would I prove non-injectivity?Would I show multiple values for $x$ which both equal the same $f(x_1)=f(x_2)$?","Define $f:\mathbb R \to \mathbb R$ by $f(x)=\frac{x}{2}+x^2\sin\frac{1}{x}$ if $x \neq 0$ and $f(0)=0$. Compute $f'(x)$ for all $x \in \mathbb R$. Show that $f'(0)>0$, yet $f$ is not injective in any neighbourhood of $0$. My idea: $f'(x)=\frac{1}{2}+2x\sin{\frac{1}{x}}-\cos{\frac{1}{x}}$ $f'(0)=\frac{1}{2}$ so $f'(0)>0$. (is this correct?) How would I prove non-injectivity?Would I show multiple values for $x$ which both equal the same $f(x_1)=f(x_2)$?",,['real-analysis']
29,"Continuity, partial derivatives and total differential","Continuity, partial derivatives and total differential",,"Is it true that if I have some function $f(x,y)$ , for which partial derivatives exist but it's not continuous, that this function cannot be differentiable (total differential doesn't exist)? But if my function is continuous and the partial derivatives do exist (and are also continuous), then it must be differentiable? I am confused, for a long time. I have found some examples but I just want to be clear.","Is it true that if I have some function , for which partial derivatives exist but it's not continuous, that this function cannot be differentiable (total differential doesn't exist)? But if my function is continuous and the partial derivatives do exist (and are also continuous), then it must be differentiable? I am confused, for a long time. I have found some examples but I just want to be clear.","f(x,y)","['calculus', 'derivatives', 'continuity', 'partial-derivative']"
30,Finding The Derivative Using $\frac{d}{dx}x^n=nx^{n-1}$,Finding The Derivative Using,\frac{d}{dx}x^n=nx^{n-1},"So I am learning how to differentiate now, and I came across this problem $$f(x)=\frac{1-x}{2+x}$$  We are wanted to find $f'(x)$. When I use $$\lim_{h\to0}\frac{f(x+h)-f(x)}{h}$$ I find that $f'(x)=\frac{-3}{(2+x)^2}$ but, when I try to find $f'(x)$ the easy way. i.e $\frac{d}{dx}x^=nx^{n-1}$. I cannot do it for some reason. Is it not possible to use that derivatives property when dealing with quotients? I know we can use it polynomial addition, subtraction and multiplication but I am struggling with quotients. Can someone please explain what it is I am not seeing? My Attempt: $$\frac{d}{dx}\frac{1-x}{2+x}=\frac{d}{dx}(1-x)(2+x)^{-1}=(1)(-1)(2+x)^{-2}$$ Which is obviously wrong so can someone please break this down for me.:)","So I am learning how to differentiate now, and I came across this problem $$f(x)=\frac{1-x}{2+x}$$  We are wanted to find $f'(x)$. When I use $$\lim_{h\to0}\frac{f(x+h)-f(x)}{h}$$ I find that $f'(x)=\frac{-3}{(2+x)^2}$ but, when I try to find $f'(x)$ the easy way. i.e $\frac{d}{dx}x^=nx^{n-1}$. I cannot do it for some reason. Is it not possible to use that derivatives property when dealing with quotients? I know we can use it polynomial addition, subtraction and multiplication but I am struggling with quotients. Can someone please explain what it is I am not seeing? My Attempt: $$\frac{d}{dx}\frac{1-x}{2+x}=\frac{d}{dx}(1-x)(2+x)^{-1}=(1)(-1)(2+x)^{-2}$$ Which is obviously wrong so can someone please break this down for me.:)",,"['calculus', 'derivatives']"
31,Derivative of $f(x)=x|x|$ at $x=0$,Derivative of  at,f(x)=x|x| x=0,I am trying to show that $f(x) = x|x|$ is differentiable for all $x \in \mathbb{R}$. By computing the prime derivative I get: $$f^\prime (x) = |x|+x(|x|)^\prime$$ I know that  $$(|x|)^\prime = \begin{cases}  1 & \text{for } x > 0 \\ -1 & \text{for } x < 0 \end{cases}$$ and it's undefined for $x = 0$.  Thus $$f^\prime (x) = \begin{cases}  2x & \text{for } x > 0 \\ -2x & \text{for } x < 0 \end{cases}$$ But what about $x = 0$?  Looking at the graph I can see $f^\prime (0) = 0$ but how can I get there? Thanks,I am trying to show that $f(x) = x|x|$ is differentiable for all $x \in \mathbb{R}$. By computing the prime derivative I get: $$f^\prime (x) = |x|+x(|x|)^\prime$$ I know that  $$(|x|)^\prime = \begin{cases}  1 & \text{for } x > 0 \\ -1 & \text{for } x < 0 \end{cases}$$ and it's undefined for $x = 0$.  Thus $$f^\prime (x) = \begin{cases}  2x & \text{for } x > 0 \\ -2x & \text{for } x < 0 \end{cases}$$ But what about $x = 0$?  Looking at the graph I can see $f^\prime (0) = 0$ but how can I get there? Thanks,,"['calculus', 'derivatives']"
32,Derivative of $x^x$ and the chain rule,Derivative of  and the chain rule,x^x,"Rewriting $x^x$ as $e^{x\ln{x}}$ we can then easily calculte the ${\frac{x}{dx}}$ derivative as ${x^x}(1 + \ln{x})$. We need to use chain rule in form $\frac{de^u}{du}\frac{du}{dx}$. The question is why cannot we use the chain rule skipping the 1st step of rewriting $x^x$ as $e^{xlnx}$? The idea would be to write $\frac{u^x}{du}\frac{du}{dx}$ which simply would be $x^x\ln{x} \cdot 1$? The answer is incorrect, here we are missing the $+x^x$ term.","Rewriting $x^x$ as $e^{x\ln{x}}$ we can then easily calculte the ${\frac{x}{dx}}$ derivative as ${x^x}(1 + \ln{x})$. We need to use chain rule in form $\frac{de^u}{du}\frac{du}{dx}$. The question is why cannot we use the chain rule skipping the 1st step of rewriting $x^x$ as $e^{xlnx}$? The idea would be to write $\frac{u^x}{du}\frac{du}{dx}$ which simply would be $x^x\ln{x} \cdot 1$? The answer is incorrect, here we are missing the $+x^x$ term.",,"['derivatives', 'chain-rule']"
33,$n$-th derivative of $f(\ln x)$,-th derivative of,n f(\ln x),"Find general formula for $n$-th derivative of $y = f(\ln x)$. To start with I found couple of derrivatives: \begin{align} y' &={1 \over x}f'(\ln x) \\ y''  &={1 \over x^2}(f''(\ln x)-f'(\ln x)) \\ y'''  &={1 \over x^3}(f'''(\ln x)-3f''(\ln x)+2f'(\ln x)) \\ y''''  &={1 \over x^4}(f''''(\ln x)-6f'''(\ln x)+11f''(\ln x)-6f'(\ln x)) \end{align} Thought it would be easy to notice a certain pattern and prove it by induction. But I can not observe anything useful. Maybe there is something like $n \choose k$ in general formula, if it exsists. I need a wise hint.","Find general formula for $n$-th derivative of $y = f(\ln x)$. To start with I found couple of derrivatives: \begin{align} y' &={1 \over x}f'(\ln x) \\ y''  &={1 \over x^2}(f''(\ln x)-f'(\ln x)) \\ y'''  &={1 \over x^3}(f'''(\ln x)-3f''(\ln x)+2f'(\ln x)) \\ y''''  &={1 \over x^4}(f''''(\ln x)-6f'''(\ln x)+11f''(\ln x)-6f'(\ln x)) \end{align} Thought it would be easy to notice a certain pattern and prove it by induction. But I can not observe anything useful. Maybe there is something like $n \choose k$ in general formula, if it exsists. I need a wise hint.",,"['calculus', 'derivatives', 'induction']"
34,Differentiate the Function: $y=2x \log_{10}\sqrt{x}$,Differentiate the Function:,y=2x \log_{10}\sqrt{x},$y=2x\log_{10}\sqrt{x}$ Solve using: Product Rule $\left(f(x)\cdot g(x)\right)'= f(x)\cdot\frac{d}{dx}g(x)+g(x)\cdot \frac{d}{dx}f(x)$ and $\frac{d}{dx}(\log_ax)= \frac{1}{x\ \ln\ a}$ $(2x)\cdot [\log_{10}\sqrt{x}]'+(\log_{10}\sqrt{x})\cdot [2x]'$ $y'=2x\frac{1}{\sqrt{x}\ln 10}+\log_{10}\sqrt{x}\cdot 2$ Answer in book is $y'= \frac{1}{\ln10}+\log_{10}x$,$y=2x\log_{10}\sqrt{x}$ Solve using: Product Rule $\left(f(x)\cdot g(x)\right)'= f(x)\cdot\frac{d}{dx}g(x)+g(x)\cdot \frac{d}{dx}f(x)$ and $\frac{d}{dx}(\log_ax)= \frac{1}{x\ \ln\ a}$ $(2x)\cdot [\log_{10}\sqrt{x}]'+(\log_{10}\sqrt{x})\cdot [2x]'$ $y'=2x\frac{1}{\sqrt{x}\ln 10}+\log_{10}\sqrt{x}\cdot 2$ Answer in book is $y'= \frac{1}{\ln10}+\log_{10}x$,,"['calculus', 'derivatives']"
35,How to compute the derivative of $x^x$ using the definition,How to compute the derivative of  using the definition,x^x,I want to prove that $\displaystyle\lim_{h\to 0}\frac{(x+h)^{x+h}-x^x}{h}=x^x(\ln(x)+1).$ If I write $x^x$ as $e^{x\ln(x)}$ I get: $\displaystyle\lim_{h\to0}\frac{e^{(x+h)\ln(x+h)}-e^{x\ln(x)}}{h}$ but then I'm stuck. What are the next steps? Thanks in advance.,I want to prove that $\displaystyle\lim_{h\to 0}\frac{(x+h)^{x+h}-x^x}{h}=x^x(\ln(x)+1).$ If I write $x^x$ as $e^{x\ln(x)}$ I get: $\displaystyle\lim_{h\to0}\frac{e^{(x+h)\ln(x+h)}-e^{x\ln(x)}}{h}$ but then I'm stuck. What are the next steps? Thanks in advance.,,"['derivatives', 'recreational-mathematics', 'limits-without-lhopital']"
36,A function with midpoint-linear derivative is a quadratic polynomial,A function with midpoint-linear derivative is a quadratic polynomial,,"Suppose $f:\mathbb{R}\to \mathbb{R}$ is a differentiable function such that $$f'\left(\frac{a+b}{2}\right) = \frac{f'(a)+f'(b)}2,\quad \forall a,b\in\mathbb{R}$$ Prove that $f$ is a polynomial of degree at most $2$ . In other words: if the derivative of a differentiable function is midpoint-linear, then it is linear. (In general, being midpoint-linear, i.e., $g((a+b)/2)=(g(a)+g(b))/2$ , is weaker ). I'm looking for a solution without Baire category tools, e.g., on the level of Rudin's Principles of Mathematical Analysis . Motivation The problem isn't hard to solve if one uses the fact that $f'$ , being a Baire- $1$ function, has a point of continuity. Then the rest is elementary: here's a proof that a midpoint-linear function $g$ with a point of continuity is linear: Subtract a  linear function to arrange $g(0)=g(1)=0$ . Apply the midpoint-linear property to conclude that $g=0$ at all dyadic rationals. If $g$ is continuous at $a$ , then $g(a)=0$ by above. For every $\epsilon>0$ there is a neighborhood of $a$ in which $|g|<\epsilon$ . From midpoint-linearity, and $g$ being $0$ on a dense set, it follows that $|g|<\epsilon$ everywhere. Thus, $g\equiv 0$ . But invoking that fact about Baire- $1$ function looks like using a sledgehammer and makes me think I'm missing some approach here.","Suppose is a differentiable function such that Prove that is a polynomial of degree at most . In other words: if the derivative of a differentiable function is midpoint-linear, then it is linear. (In general, being midpoint-linear, i.e., , is weaker ). I'm looking for a solution without Baire category tools, e.g., on the level of Rudin's Principles of Mathematical Analysis . Motivation The problem isn't hard to solve if one uses the fact that , being a Baire- function, has a point of continuity. Then the rest is elementary: here's a proof that a midpoint-linear function with a point of continuity is linear: Subtract a  linear function to arrange . Apply the midpoint-linear property to conclude that at all dyadic rationals. If is continuous at , then by above. For every there is a neighborhood of in which . From midpoint-linearity, and being on a dense set, it follows that everywhere. Thus, . But invoking that fact about Baire- function looks like using a sledgehammer and makes me think I'm missing some approach here.","f:\mathbb{R}\to \mathbb{R} f'\left(\frac{a+b}{2}\right) = \frac{f'(a)+f'(b)}2,\quad \forall a,b\in\mathbb{R} f 2 g((a+b)/2)=(g(a)+g(b))/2 f' 1 g g(0)=g(1)=0 g=0 g a g(a)=0 \epsilon>0 a |g|<\epsilon g 0 |g|<\epsilon g\equiv 0 1",['real-analysis']
37,Differentiation Tricks,Differentiation Tricks,,"Since most derivatives are trivial to take, it's understandable why integrals get most of the mathematical tricksters' attention. However, not all derivatives are trivial to take and I think it's good to have as many tricks up your sleeves as possible. I noticed the other day that $\left(\frac{dy}{dx}\right)^{-1}=\frac{dx}{dy}$ and that we can use this fact to differentiate functions like the inverse trig functions e.g. $y=\arcsin(x)$, $$\frac{d \sin(y)}{dy}=\cos(y)=\cos(\arcsin(x))=\sqrt{1-x^2}=\left(\frac{dy}{dx}\right)^{-1}$$ My question is, does anybody know of any similar tricks to differentiate those rare functions which are non-trivial?","Since most derivatives are trivial to take, it's understandable why integrals get most of the mathematical tricksters' attention. However, not all derivatives are trivial to take and I think it's good to have as many tricks up your sleeves as possible. I noticed the other day that $\left(\frac{dy}{dx}\right)^{-1}=\frac{dx}{dy}$ and that we can use this fact to differentiate functions like the inverse trig functions e.g. $y=\arcsin(x)$, $$\frac{d \sin(y)}{dy}=\cos(y)=\cos(\arcsin(x))=\sqrt{1-x^2}=\left(\frac{dy}{dx}\right)^{-1}$$ My question is, does anybody know of any similar tricks to differentiate those rare functions which are non-trivial?",,"['derivatives', 'differential-forms']"
38,"Show that between any two real roots of the equation $e^x \cos{x}+1=0$, there is a root of the equation $e^x \sin{x}+1=0$","Show that between any two real roots of the equation , there is a root of the equation",e^x \cos{x}+1=0 e^x \sin{x}+1=0,"My steps are the following: Suppose $f(a)=f(b)=0$ Since $f$ is differentiable on $[a,b]$ and continuous on $(a,b)$ By Rolle's Theorem $\exists c\in(a,b)$ such that $$f'(c)=e^c(-\sin{c})+e^c \cos{c}=0$$ So what I found is $\sin{c}=\cos{c}$","My steps are the following: Suppose $f(a)=f(b)=0$ Since $f$ is differentiable on $[a,b]$ and continuous on $(a,b)$ By Rolle's Theorem $\exists c\in(a,b)$ such that $$f'(c)=e^c(-\sin{c})+e^c \cos{c}=0$$ So what I found is $\sin{c}=\cos{c}$",,"['real-analysis', 'derivatives']"
39,How to differentiate this negative power? [duplicate],How to differentiate this negative power? [duplicate],,"This question already has answers here : Differentiation - simple case (2 answers) Closed 9 years ago . I'm reading the book ""Calculus made easy"" and I'm stuck with a step of a derivative with a negative power. Here is what is in the book: Case of a negative power. Let $y=x^{-2}$. Then proceed as before $$\eqalign{y+dy&=(x+dx)^{-2}\\&=x^{-2}\left(1+\dfrac{dx}x\right)^{-2}.}$$ I don't understand what I have to do to go from  $$ (x+dx)^{-2} $$ to $$ x^{-2} \cdot (1+dx/x)^{-2} $$ Any help will be much appreciated!","This question already has answers here : Differentiation - simple case (2 answers) Closed 9 years ago . I'm reading the book ""Calculus made easy"" and I'm stuck with a step of a derivative with a negative power. Here is what is in the book: Case of a negative power. Let $y=x^{-2}$. Then proceed as before $$\eqalign{y+dy&=(x+dx)^{-2}\\&=x^{-2}\left(1+\dfrac{dx}x\right)^{-2}.}$$ I don't understand what I have to do to go from  $$ (x+dx)^{-2} $$ to $$ x^{-2} \cdot (1+dx/x)^{-2} $$ Any help will be much appreciated!",,"['calculus', 'derivatives']"
40,Why does gradient descent make sense?,Why does gradient descent make sense?,,"Suppose I define two functions of $x$ in terms of a convex function $f$ with a unique minimum $x_0$: $$f_1(x) = 1 \times f(x)$$ $$f_2(x) = 2 \times f(x)$$ Suppose I wanted to minimize each of these functions numerically. Clearly, the minima of both occur at the same $x_0$. But if I tried to do gradient descent, I would be performing the updates $$x \gets x - \lambda \nabla f_k(x)$$ and therefore step sizes would be larger for $f_2$ than $f_1$. To me, this doesn't make sense. The step sizes should not depend on the scaling factor! It therefore seems to imply that gradient descent should be normalized such that the step sizes have constant magnitude regardless of the gradient's magnitude. So what justification is there for having the step size increase with the magnitude of the gradient when it's obvious that scaling the original function will change the gradient but not the location of its extrema?","Suppose I define two functions of $x$ in terms of a convex function $f$ with a unique minimum $x_0$: $$f_1(x) = 1 \times f(x)$$ $$f_2(x) = 2 \times f(x)$$ Suppose I wanted to minimize each of these functions numerically. Clearly, the minima of both occur at the same $x_0$. But if I tried to do gradient descent, I would be performing the updates $$x \gets x - \lambda \nabla f_k(x)$$ and therefore step sizes would be larger for $f_2$ than $f_1$. To me, this doesn't make sense. The step sizes should not depend on the scaling factor! It therefore seems to imply that gradient descent should be normalized such that the step sizes have constant magnitude regardless of the gradient's magnitude. So what justification is there for having the step size increase with the magnitude of the gradient when it's obvious that scaling the original function will change the gradient but not the location of its extrema?",,"['derivatives', 'optimization', 'convex-optimization', 'numerical-optimization', 'gradient-descent']"
41,Implicit Derivative approaches,Implicit Derivative approaches,,"Sorry for my excessive verboseness... Here's the equation as given: $$x = 10 + \sqrt{x^2 + y^2}$$ Here are my direct implicit steps without modifying original equation: $$\eqalign{ \dfrac{\mathrm d}{\mathrm dx}\left(x\right)& = \dfrac{\mathrm d}{\mathrm dx}\left(10 + \sqrt{x^2 + y^2}\right)\\ \dfrac{\mathrm dx}{\mathrm dx}& = \dfrac{\mathrm d}{\mathrm dx}\left(10 + \sqrt{x^2 + y^2}\right)\\ 1 &= \dfrac{\mathrm d}{\mathrm dx}\left(10 + \sqrt{x^2 + y^2}\right)\\ 1 &= \dfrac{\mathrm d}{\mathrm dx}\left(10\right) + \dfrac{\mathrm d}{\mathrm dx}\left(\sqrt{x^2 + y^2}\right)\\ 1& = 0 + \dfrac{\mathrm d}{\mathrm dx}\left(\sqrt{x^2 + y^2}\right)\\ 1 &= \dfrac{\mathrm d}{\mathrm dx}\left(\sqrt{x^2 + y^2}\right)\\ 1 &= \dfrac{\mathrm d}{\mathrm dx}\left(\left(x^2 + y^2\right)^{1/2}\right)\\ 1 &= \dfrac12 \left(x^2 + y^2\right)^{-1/2} \cdot\dfrac{\mathrm d}{\mathrm dx}\left(x^2 + y^2\right)\\ 1 &= \dfrac 1{2 \sqrt{x^2 + y^2}}\cdot\dfrac{\mathrm d}{\mathrm dx}\left(x^2 + y^2\right)\\ 1 &= \dfrac 1{2 \sqrt{x^2 + y^2}}\cdot\left(\dfrac{\mathrm d}{\mathrm dx}\left(x^2\right) + \dfrac{\mathrm d}{\mathrm dx}\left(y^2\right)\right)\\ 1 &= \dfrac 1{2 \sqrt{x^2 + y^2}}\cdot\left(2x\cdot\dfrac{\mathrm d}{\mathrm dx}\left(x\right) + 2y\cdot\dfrac{\mathrm d}{\mathrm dx}\left(y\right)\right)\\ 1 &= \dfrac 1{2 \sqrt{x^2 + y^2}}\cdot\left(2x\cdot\dfrac{\mathrm dx}{\mathrm dx} + 2y\cdot\dfrac{\mathrm dy}{\mathrm dx}\right)\\ 1 &= \dfrac 1{2 \sqrt{x^2 + y^2}}\cdot\left(2x + 2y\cdot\dfrac{\mathrm dy}{\mathrm dx}\right)\\ 1 &= \dfrac {2x}{2 \sqrt{x^2 + y^2}} + \dfrac {2y}{2 \sqrt{x^2 + y^2}}\cdot\dfrac{\mathrm dy}{\mathrm dx}\\ 1 &=\dfrac x{\sqrt{x^2 + y^2}}+ \dfrac{y}{\sqrt{x^2 + y^2}}\cdot\dfrac{\mathrm dy}{\mathrm dx}\\ 1 -\dfrac x{\sqrt{x^2 + y^2}} &= \dfrac{y}{\sqrt{x^2 + y^2}}\cdot\dfrac{\mathrm dy}{\mathrm dx}\\ \sqrt{x^2 + y^2}\cdot\left(1 - \dfrac x{\sqrt{x^2 + y^2}}\right) &= y\cdot\dfrac{\mathrm dy}{\mathrm dx}\\ \sqrt{x^2 + y^2} - \dfrac{x\cdot\sqrt{x^2 + y^2}}{\sqrt{x^2 + y^2}} &= y\cdot\dfrac{\mathrm dy}{\mathrm dx}\\ \sqrt{x^2 + y^2} - x &= y\cdot\dfrac{\mathrm dy}{\mathrm dx}\\ \left[\dfrac{\sqrt{x^2 + y^2} - x}y\right] &= \dfrac{\mathrm dy}{\mathrm dx}}$$ This result matches http://symbolab.com However, Wolfram gives: $$\frac{dy}{dx}= \frac{-10}y$$ In an effort to get to Wolfram's result, I tried isolating y first: $$\eqalign{ x &= 10 + \sqrt{x^2 + y^2}\\ 10 + \sqrt{x^2 + y^2} &= x\\ \sqrt{x^2 + y^2} &= x - 10\\ \sqrt{x^2 + y^2}^2 &= \left(x - 10\right)^2\\ \sqrt{x^2 + y^2}^2 &= \left(x - 10\right)\left(x - 10\right)\\ \sqrt{x^2 + y^2}^2 &= x^2 - 20x + 100\\ x^2 + y^2 &= x^2 - 20x + 100\\ y^2 &= x^2 - 20x + 100 - x^2\\ y^2 &= -20x + 100}$$ I'm guessing this next step could be problematic by not taking $\pm\sqrt n$ into account. $$\eqalign{y &= \sqrt{-20x + 100}\\ &= \left(-20x + 100\right)^{1/2}}$$ Proceeding to implicit derivative processing: $$\eqalign{ \dfrac{\mathrm d}{\mathrm dx}\left(y\right) &= \dfrac{\mathrm d}{\mathrm dx}\left(\left(-20x + 100\right)^{1/2}\right)\\ \dfrac{\mathrm dy}{\mathrm dx} &= \dfrac{\mathrm d}{\mathrm dx}\left(\left(-20x + 100\right)^{1/2}\right)\\ \dfrac{\mathrm dy}{\mathrm dx} &= \dfrac12 \cdot\left(-20x + 100\right)^{-1/2}\cdot\dfrac{\mathrm d}{\mathrm dx}\left(-20x + 100\right)\\ \dfrac{\mathrm dy}{\mathrm dx} &= \dfrac1{2\sqrt{-20x + 100}}\cdot\dfrac{\mathrm d}{\mathrm dx}\left(-20x + 100\right)\\ \dfrac{\mathrm dy}{\mathrm dx} &= \dfrac1{2\sqrt{-20x + 100}}\cdot\left(\dfrac{\mathrm d}{\mathrm dx}\left(-20x\right) + \dfrac{\mathrm d}{\mathrm dx}\left(100\right)\right)\\ \dfrac{\mathrm dy}{\mathrm dx} &= \dfrac1{2\sqrt{-20x + 100}}\cdot\left(20\dfrac{\mathrm d}{\mathrm dx}\left(x\right) + 0\right)\\ \dfrac{\mathrm dy}{\mathrm dx} &= \dfrac1{2\sqrt{-20x + 100}}\cdot\left(20\dfrac{\mathrm dx}{\mathrm dx}\right)\\ \dfrac{\mathrm dy}{\mathrm dx} &= \dfrac1{2\sqrt{-20x + 100}}\cdot20\\ \dfrac{\mathrm dy}{\mathrm dx} &= \dfrac{20}{2\sqrt{-20x + 100}}\\ \dfrac{\mathrm dy}{\mathrm dx} &= \dfrac{10}{\sqrt{-20x + 100}}}$$ I'm not sure if these next $\left(\dfrac{\mathrm dy}{\mathrm dx}\right)^2$ steps are allowed, but it did lead to a simpler result even though it never matched the Wolfram result: $$\eqalign{ \left(\dfrac{\mathrm dy}{\mathrm dx}\right)^2 &= \left(\dfrac{10}{\sqrt{-20x + 100}}\right)^2\\ \left(\dfrac{\mathrm dy}{\mathrm dx}\right)^2 &= \dfrac{10^2}{\sqrt{-20x + 100}^2}\\ \left(\dfrac{\mathrm dy}{\mathrm dx}\right)^2 &= \dfrac{100}{-20x + 100}\\ \left(\dfrac{\mathrm dy}{\mathrm dx}\right)^2 &= \dfrac{100}{-20\left(x + 5\right)}\\ \left(\dfrac{\mathrm dy}{\mathrm dx}\right)^2 &= -\dfrac5{x + 5}\\ \dfrac{\mathrm dy}{\mathrm dx} &= \sqrt{-\dfrac5{x + 5}}}$$ No matter what I try, I can't figure out at all how Wolfram got such a simple result. So which is the true derivative, and proper approach?","Sorry for my excessive verboseness... Here's the equation as given: $$x = 10 + \sqrt{x^2 + y^2}$$ Here are my direct implicit steps without modifying original equation: $$\eqalign{ \dfrac{\mathrm d}{\mathrm dx}\left(x\right)& = \dfrac{\mathrm d}{\mathrm dx}\left(10 + \sqrt{x^2 + y^2}\right)\\ \dfrac{\mathrm dx}{\mathrm dx}& = \dfrac{\mathrm d}{\mathrm dx}\left(10 + \sqrt{x^2 + y^2}\right)\\ 1 &= \dfrac{\mathrm d}{\mathrm dx}\left(10 + \sqrt{x^2 + y^2}\right)\\ 1 &= \dfrac{\mathrm d}{\mathrm dx}\left(10\right) + \dfrac{\mathrm d}{\mathrm dx}\left(\sqrt{x^2 + y^2}\right)\\ 1& = 0 + \dfrac{\mathrm d}{\mathrm dx}\left(\sqrt{x^2 + y^2}\right)\\ 1 &= \dfrac{\mathrm d}{\mathrm dx}\left(\sqrt{x^2 + y^2}\right)\\ 1 &= \dfrac{\mathrm d}{\mathrm dx}\left(\left(x^2 + y^2\right)^{1/2}\right)\\ 1 &= \dfrac12 \left(x^2 + y^2\right)^{-1/2} \cdot\dfrac{\mathrm d}{\mathrm dx}\left(x^2 + y^2\right)\\ 1 &= \dfrac 1{2 \sqrt{x^2 + y^2}}\cdot\dfrac{\mathrm d}{\mathrm dx}\left(x^2 + y^2\right)\\ 1 &= \dfrac 1{2 \sqrt{x^2 + y^2}}\cdot\left(\dfrac{\mathrm d}{\mathrm dx}\left(x^2\right) + \dfrac{\mathrm d}{\mathrm dx}\left(y^2\right)\right)\\ 1 &= \dfrac 1{2 \sqrt{x^2 + y^2}}\cdot\left(2x\cdot\dfrac{\mathrm d}{\mathrm dx}\left(x\right) + 2y\cdot\dfrac{\mathrm d}{\mathrm dx}\left(y\right)\right)\\ 1 &= \dfrac 1{2 \sqrt{x^2 + y^2}}\cdot\left(2x\cdot\dfrac{\mathrm dx}{\mathrm dx} + 2y\cdot\dfrac{\mathrm dy}{\mathrm dx}\right)\\ 1 &= \dfrac 1{2 \sqrt{x^2 + y^2}}\cdot\left(2x + 2y\cdot\dfrac{\mathrm dy}{\mathrm dx}\right)\\ 1 &= \dfrac {2x}{2 \sqrt{x^2 + y^2}} + \dfrac {2y}{2 \sqrt{x^2 + y^2}}\cdot\dfrac{\mathrm dy}{\mathrm dx}\\ 1 &=\dfrac x{\sqrt{x^2 + y^2}}+ \dfrac{y}{\sqrt{x^2 + y^2}}\cdot\dfrac{\mathrm dy}{\mathrm dx}\\ 1 -\dfrac x{\sqrt{x^2 + y^2}} &= \dfrac{y}{\sqrt{x^2 + y^2}}\cdot\dfrac{\mathrm dy}{\mathrm dx}\\ \sqrt{x^2 + y^2}\cdot\left(1 - \dfrac x{\sqrt{x^2 + y^2}}\right) &= y\cdot\dfrac{\mathrm dy}{\mathrm dx}\\ \sqrt{x^2 + y^2} - \dfrac{x\cdot\sqrt{x^2 + y^2}}{\sqrt{x^2 + y^2}} &= y\cdot\dfrac{\mathrm dy}{\mathrm dx}\\ \sqrt{x^2 + y^2} - x &= y\cdot\dfrac{\mathrm dy}{\mathrm dx}\\ \left[\dfrac{\sqrt{x^2 + y^2} - x}y\right] &= \dfrac{\mathrm dy}{\mathrm dx}}$$ This result matches http://symbolab.com However, Wolfram gives: $$\frac{dy}{dx}= \frac{-10}y$$ In an effort to get to Wolfram's result, I tried isolating y first: $$\eqalign{ x &= 10 + \sqrt{x^2 + y^2}\\ 10 + \sqrt{x^2 + y^2} &= x\\ \sqrt{x^2 + y^2} &= x - 10\\ \sqrt{x^2 + y^2}^2 &= \left(x - 10\right)^2\\ \sqrt{x^2 + y^2}^2 &= \left(x - 10\right)\left(x - 10\right)\\ \sqrt{x^2 + y^2}^2 &= x^2 - 20x + 100\\ x^2 + y^2 &= x^2 - 20x + 100\\ y^2 &= x^2 - 20x + 100 - x^2\\ y^2 &= -20x + 100}$$ I'm guessing this next step could be problematic by not taking $\pm\sqrt n$ into account. $$\eqalign{y &= \sqrt{-20x + 100}\\ &= \left(-20x + 100\right)^{1/2}}$$ Proceeding to implicit derivative processing: $$\eqalign{ \dfrac{\mathrm d}{\mathrm dx}\left(y\right) &= \dfrac{\mathrm d}{\mathrm dx}\left(\left(-20x + 100\right)^{1/2}\right)\\ \dfrac{\mathrm dy}{\mathrm dx} &= \dfrac{\mathrm d}{\mathrm dx}\left(\left(-20x + 100\right)^{1/2}\right)\\ \dfrac{\mathrm dy}{\mathrm dx} &= \dfrac12 \cdot\left(-20x + 100\right)^{-1/2}\cdot\dfrac{\mathrm d}{\mathrm dx}\left(-20x + 100\right)\\ \dfrac{\mathrm dy}{\mathrm dx} &= \dfrac1{2\sqrt{-20x + 100}}\cdot\dfrac{\mathrm d}{\mathrm dx}\left(-20x + 100\right)\\ \dfrac{\mathrm dy}{\mathrm dx} &= \dfrac1{2\sqrt{-20x + 100}}\cdot\left(\dfrac{\mathrm d}{\mathrm dx}\left(-20x\right) + \dfrac{\mathrm d}{\mathrm dx}\left(100\right)\right)\\ \dfrac{\mathrm dy}{\mathrm dx} &= \dfrac1{2\sqrt{-20x + 100}}\cdot\left(20\dfrac{\mathrm d}{\mathrm dx}\left(x\right) + 0\right)\\ \dfrac{\mathrm dy}{\mathrm dx} &= \dfrac1{2\sqrt{-20x + 100}}\cdot\left(20\dfrac{\mathrm dx}{\mathrm dx}\right)\\ \dfrac{\mathrm dy}{\mathrm dx} &= \dfrac1{2\sqrt{-20x + 100}}\cdot20\\ \dfrac{\mathrm dy}{\mathrm dx} &= \dfrac{20}{2\sqrt{-20x + 100}}\\ \dfrac{\mathrm dy}{\mathrm dx} &= \dfrac{10}{\sqrt{-20x + 100}}}$$ I'm not sure if these next $\left(\dfrac{\mathrm dy}{\mathrm dx}\right)^2$ steps are allowed, but it did lead to a simpler result even though it never matched the Wolfram result: $$\eqalign{ \left(\dfrac{\mathrm dy}{\mathrm dx}\right)^2 &= \left(\dfrac{10}{\sqrt{-20x + 100}}\right)^2\\ \left(\dfrac{\mathrm dy}{\mathrm dx}\right)^2 &= \dfrac{10^2}{\sqrt{-20x + 100}^2}\\ \left(\dfrac{\mathrm dy}{\mathrm dx}\right)^2 &= \dfrac{100}{-20x + 100}\\ \left(\dfrac{\mathrm dy}{\mathrm dx}\right)^2 &= \dfrac{100}{-20\left(x + 5\right)}\\ \left(\dfrac{\mathrm dy}{\mathrm dx}\right)^2 &= -\dfrac5{x + 5}\\ \dfrac{\mathrm dy}{\mathrm dx} &= \sqrt{-\dfrac5{x + 5}}}$$ No matter what I try, I can't figure out at all how Wolfram got such a simple result. So which is the true derivative, and proper approach?",,"['calculus', 'derivatives']"
42,Find $f'(0)$ given $f(x + y)$,Find  given,f'(0) f(x + y),"Let $f$ be a differentiable function satisfying $$f(x + y) = e^xf(y) + e^yf(x)$$ for all $x, y \in \mathbb{R}$. Find $f'(0)$. I tried to use the definition of $f'(0)$ to do this: $$f'(0) = \lim_{h \to 0} \frac{f(0 + h) - f(0)}{h} = \lim_{h \to 0}\frac{f(h)}{h}$$ The problem here is that I would have to apply L'Hopital's rule on the RHS , which would give me $$f'(0) = \frac{\lim_{h\to0}f'(h)}{\lim_{h\to0}1} = f'(0)$$ This doesn't really help much. Any ideas?","Let $f$ be a differentiable function satisfying $$f(x + y) = e^xf(y) + e^yf(x)$$ for all $x, y \in \mathbb{R}$. Find $f'(0)$. I tried to use the definition of $f'(0)$ to do this: $$f'(0) = \lim_{h \to 0} \frac{f(0 + h) - f(0)}{h} = \lim_{h \to 0}\frac{f(h)}{h}$$ The problem here is that I would have to apply L'Hopital's rule on the RHS , which would give me $$f'(0) = \frac{\lim_{h\to0}f'(h)}{\lim_{h\to0}1} = f'(0)$$ This doesn't really help much. Any ideas?",,"['calculus', 'derivatives']"
43,Prove an inequality (Using Taylor expansion),Prove an inequality (Using Taylor expansion),,"Prove: $\frac{x}{1+x} < \ln(1+x) < x$. I thought a good practice would be to prove it using Taylor Expansion. Here's my try: $$\ln(1+x) = x - \frac{x^2}{2} + \frac{x^3}{3}...$$ The n=1 Taylor polynomial is: $$T_1(x) = x$$ and  $$ ln(1+x) = T_1(x) +  R_1(x)$$ Lets evaluate $R_1(x)$ by Cauchy's remainder formula: $$R_1(x) = \frac{f^{(2)}(\xi)}{2!}\cdot x^2 = \frac{\frac{-1}{(\xi+1)^2}}{2!}\cdot x^2 = \frac{-x^2}{2(\xi+1)^2} < 0$$ Now, it does prove the right-hand side because $x + R_1(x) < x$ ($R_1(x)$ is negative). I'm not so sure what should I do for the left-hand side. I'd also like to get general critique for my current work. Thanks!","Prove: $\frac{x}{1+x} < \ln(1+x) < x$. I thought a good practice would be to prove it using Taylor Expansion. Here's my try: $$\ln(1+x) = x - \frac{x^2}{2} + \frac{x^3}{3}...$$ The n=1 Taylor polynomial is: $$T_1(x) = x$$ and  $$ ln(1+x) = T_1(x) +  R_1(x)$$ Lets evaluate $R_1(x)$ by Cauchy's remainder formula: $$R_1(x) = \frac{f^{(2)}(\xi)}{2!}\cdot x^2 = \frac{\frac{-1}{(\xi+1)^2}}{2!}\cdot x^2 = \frac{-x^2}{2(\xi+1)^2} < 0$$ Now, it does prove the right-hand side because $x + R_1(x) < x$ ($R_1(x)$ is negative). I'm not so sure what should I do for the left-hand side. I'd also like to get general critique for my current work. Thanks!",,"['calculus', 'real-analysis', 'polynomials', 'derivatives', 'taylor-expansion']"
44,How find this $\left(\frac{1}{x^2+a^2}\right)^{(n)}$,How find this,\left(\frac{1}{x^2+a^2}\right)^{(n)},"Prove that $$\left(\dfrac{1}{x^2+a^2}\right)^{(n)}=(-1)^{(n)}n!\dfrac{\sin{[(n+1)\cdot \mathrm{arccot}{(x/a)}]}}{a(x^2+a^2)^{(n+1)/2}}$$ my try: since $$\dfrac{1}{x^2+a^2}=\dfrac{1}{2ai}\left(\dfrac{1}{x-ai}-\dfrac{1}{x+ai}\right),i=\sqrt{-1}$$ so $$\left(\dfrac{1}{x^2+a^2}\right)^{(n)}=\dfrac{(-1)^nn!}{2ai}\left(\dfrac{1}{(x-ai)^{n+1}}-\dfrac{1}{(x+ai)^{n+1}}\right)$$ so let$$x=a\cot{\theta},0<\theta<\pi,$$ then $$x\pm ai=a(\cos{\theta}\pm i\sin{\theta})/\sin{\theta}$$ so $$\dfrac{1}{(x\pm ai)^{n+1}}=\dfrac{\sin^{n+1}{\theta}}{a^{n+1}}[\cos{(n+1)\theta}\mp i\sin{(n+1)\theta}]$$ so$$\left(\dfrac{1}{x^2+a^2}\right)^{(n)}=(-1)^{(n)}n!\dfrac{\sin{[(n+1)\cdot \mathrm{arccot}{(x/a)}]}}{a(x^2+a^2)^{(n+1)/2}}$$ Question: Have other methods? Because this is important reslut,so I think this have other methods?  Thank you","Prove that $$\left(\dfrac{1}{x^2+a^2}\right)^{(n)}=(-1)^{(n)}n!\dfrac{\sin{[(n+1)\cdot \mathrm{arccot}{(x/a)}]}}{a(x^2+a^2)^{(n+1)/2}}$$ my try: since $$\dfrac{1}{x^2+a^2}=\dfrac{1}{2ai}\left(\dfrac{1}{x-ai}-\dfrac{1}{x+ai}\right),i=\sqrt{-1}$$ so $$\left(\dfrac{1}{x^2+a^2}\right)^{(n)}=\dfrac{(-1)^nn!}{2ai}\left(\dfrac{1}{(x-ai)^{n+1}}-\dfrac{1}{(x+ai)^{n+1}}\right)$$ so let$$x=a\cot{\theta},0<\theta<\pi,$$ then $$x\pm ai=a(\cos{\theta}\pm i\sin{\theta})/\sin{\theta}$$ so $$\dfrac{1}{(x\pm ai)^{n+1}}=\dfrac{\sin^{n+1}{\theta}}{a^{n+1}}[\cos{(n+1)\theta}\mp i\sin{(n+1)\theta}]$$ so$$\left(\dfrac{1}{x^2+a^2}\right)^{(n)}=(-1)^{(n)}n!\dfrac{\sin{[(n+1)\cdot \mathrm{arccot}{(x/a)}]}}{a(x^2+a^2)^{(n+1)/2}}$$ Question: Have other methods? Because this is important reslut,so I think this have other methods?  Thank you",,"['calculus', 'derivatives']"
45,How do I solve a derivative that has an absolute value $x \times |x|$,How do I solve a derivative that has an absolute value,x \times |x|,"I have a function x * |x| To get the derivative I used the first principals: $$ f'(x) = ( (x-h) * | x + h | - (x * |x|) )/ h $$ So if x is + I got $$ x ^ 2 + xh - xh - h^2 - x^2 / h $$ $$ -h^2/h$$ $$ -h $$ $$ 0 $$ If x is negative: $$ x^2 - 2xh + h^2 - x^2$$ $$ -2xh+h^2 $$ $$ h (-2x + h)/h$$ $$ -2x + h $$ $$ -2x $$ So I checked with a derivative calculator and it says the answer is 2x.... So I'm not exactly sure why I got -2x, and why do we only used the negative part, why is the answer not -2x for negative x and 0 for positive x... why is only one chosen?","I have a function x * |x| To get the derivative I used the first principals: $$ f'(x) = ( (x-h) * | x + h | - (x * |x|) )/ h $$ So if x is + I got $$ x ^ 2 + xh - xh - h^2 - x^2 / h $$ $$ -h^2/h$$ $$ -h $$ $$ 0 $$ If x is negative: $$ x^2 - 2xh + h^2 - x^2$$ $$ -2xh+h^2 $$ $$ h (-2x + h)/h$$ $$ -2x + h $$ $$ -2x $$ So I checked with a derivative calculator and it says the answer is 2x.... So I'm not exactly sure why I got -2x, and why do we only used the negative part, why is the answer not -2x for negative x and 0 for positive x... why is only one chosen?",,"['calculus', 'derivatives']"
46,Trigonometric derivative?,Trigonometric derivative?,,Hello everyone how would I solve the following derivative. $f(x)=5x^3\tan(x)+\cot(2x)$ I know the derivative of $\tan(x)$ is $\sec^2(x)$ So would I do $15x^2\sec^2(x)-\csc(2x)$ As my derivative.,Hello everyone how would I solve the following derivative. $f(x)=5x^3\tan(x)+\cot(2x)$ I know the derivative of $\tan(x)$ is $\sec^2(x)$ So would I do $15x^2\sec^2(x)-\csc(2x)$ As my derivative.,,"['calculus', 'derivatives']"
47,Finding derivatives of Trigonometric Functions,Finding derivatives of Trigonometric Functions,,"I'm having a very difficult time understanding how find the derivative of trig functions. Here's one that I've been trying to crack for the half hour: $$y = \frac{11}{\sin x} + \frac{1}{\cot x}$$ I know that  $$\frac{d}{dx}(\sin x) = \cos x$$ and that $$\frac{d}{dx}(\cot x) = -\csc^2 x$$ I also know that the final answer is $$y' = -11\csc x\cot x+\sec^2 x$$ But no matter what I try I can't seem to come up with that answer. What I really need is systematic or step by step approcah that I could apply to these types of problems, no matter what format the're in. Because there's many more like this, except in different formats, that I have to solve.","I'm having a very difficult time understanding how find the derivative of trig functions. Here's one that I've been trying to crack for the half hour: $$y = \frac{11}{\sin x} + \frac{1}{\cot x}$$ I know that  $$\frac{d}{dx}(\sin x) = \cos x$$ and that $$\frac{d}{dx}(\cot x) = -\csc^2 x$$ I also know that the final answer is $$y' = -11\csc x\cot x+\sec^2 x$$ But no matter what I try I can't seem to come up with that answer. What I really need is systematic or step by step approcah that I could apply to these types of problems, no matter what format the're in. Because there's many more like this, except in different formats, that I have to solve.",,"['calculus', 'derivatives']"
48,Motivation for a new definition of the derivative using the concept of average velocity,Motivation for a new definition of the derivative using the concept of average velocity,,"As everyone knows, for a function $ f: \mathbb{R} \to \mathbb{R} $ and a point $ a \in \mathbb{R} $, we say that the derivative of $ f $ at $ a $ equals $ L $ if and only if $$ \lim_{x \to a} \frac{f(x) - f(a)}{x - a} = L. $$ Now, most textbooks on particle mechanics offer the following recipe for defining the instantaneous velocity of a particle traveling along a straight line. Let $ f: \mathbb{R} \to \mathbb{R} $ denote the displacement function of a particle traveling along the $ x $-axis, with respect to time. The goal is to define the instantaneous velocity of the particle at time $ t_{0} $. Pick a sequence of non-degenerate bounded closed intervals $ ([a_{n},b_{n}])_{n \in \mathbb{N}} $ such that $ t_{0} \in (a_{n},b_{n}) $ for all $ n \in \mathbb{N} $ and $ \displaystyle \lim_{n \to \infty} (b_{n} - a_{n}) = 0 $. Compute the sequence of average velocities $ (v_{\text{ave},n})_{n \in \mathbb{N}} $ of the particle over these closed intervals, i.e., $$ (v_{\text{ave},n})_{n \in \mathbb{N}} \stackrel{\text{def}}{=} \left( \frac{f(a_{n}) - f(b_{n})}{a_{n} - b_{n}} \right)_{n \in \mathbb{N}}. $$ Define the instantaneous velocity of the particle at time $ t_{0} $ as $ \displaystyle \lim_{n \to \infty} v_{\text{ave},n} $, if it exists. This recipe is somehow proposing a new definition of the derivative of a function. Let me describe it in precise mathematical terms. Consider $ f: \mathbb{R} \to \mathbb{R} $. Let $ a \in \mathbb{R} $, and let $ \Lambda $ be the set of non-degenerate bounded closed intervals $ I $ such that $ a \in I^{\circ} $. Define a partial ordering $ \preceq $ on $ \Lambda $ by $ I \preceq J \iff I \supseteq J $ for all $ I,J \in \Lambda $. One can easily verify that $ (\Lambda,\preceq) $ is a directed set. Next, define a net $ \lambda: \Lambda \to \mathbb{R} $ by   $$ \forall I \in \Lambda: \quad \lambda(I) \stackrel{\text{def}}{=} \frac{f({\frak{l}}(I)) - f({\frak{r}}(I))}{{\frak{l}}(I) - {\frak{r}}(I)}, $$   where $ {\frak{l}}(I) $ and $ {\frak{r}}(I) $ denote the left- and right-endpoints of $ I $ respectively. Then define   $$ f'(a) \stackrel{\text{def}}{=} \lim_{I \in \Lambda} \lambda(I), $$   if it exists. Question: How can we show that this new definition of the derivative agrees with the usual one?","As everyone knows, for a function $ f: \mathbb{R} \to \mathbb{R} $ and a point $ a \in \mathbb{R} $, we say that the derivative of $ f $ at $ a $ equals $ L $ if and only if $$ \lim_{x \to a} \frac{f(x) - f(a)}{x - a} = L. $$ Now, most textbooks on particle mechanics offer the following recipe for defining the instantaneous velocity of a particle traveling along a straight line. Let $ f: \mathbb{R} \to \mathbb{R} $ denote the displacement function of a particle traveling along the $ x $-axis, with respect to time. The goal is to define the instantaneous velocity of the particle at time $ t_{0} $. Pick a sequence of non-degenerate bounded closed intervals $ ([a_{n},b_{n}])_{n \in \mathbb{N}} $ such that $ t_{0} \in (a_{n},b_{n}) $ for all $ n \in \mathbb{N} $ and $ \displaystyle \lim_{n \to \infty} (b_{n} - a_{n}) = 0 $. Compute the sequence of average velocities $ (v_{\text{ave},n})_{n \in \mathbb{N}} $ of the particle over these closed intervals, i.e., $$ (v_{\text{ave},n})_{n \in \mathbb{N}} \stackrel{\text{def}}{=} \left( \frac{f(a_{n}) - f(b_{n})}{a_{n} - b_{n}} \right)_{n \in \mathbb{N}}. $$ Define the instantaneous velocity of the particle at time $ t_{0} $ as $ \displaystyle \lim_{n \to \infty} v_{\text{ave},n} $, if it exists. This recipe is somehow proposing a new definition of the derivative of a function. Let me describe it in precise mathematical terms. Consider $ f: \mathbb{R} \to \mathbb{R} $. Let $ a \in \mathbb{R} $, and let $ \Lambda $ be the set of non-degenerate bounded closed intervals $ I $ such that $ a \in I^{\circ} $. Define a partial ordering $ \preceq $ on $ \Lambda $ by $ I \preceq J \iff I \supseteq J $ for all $ I,J \in \Lambda $. One can easily verify that $ (\Lambda,\preceq) $ is a directed set. Next, define a net $ \lambda: \Lambda \to \mathbb{R} $ by   $$ \forall I \in \Lambda: \quad \lambda(I) \stackrel{\text{def}}{=} \frac{f({\frak{l}}(I)) - f({\frak{r}}(I))}{{\frak{l}}(I) - {\frak{r}}(I)}, $$   where $ {\frak{l}}(I) $ and $ {\frak{r}}(I) $ denote the left- and right-endpoints of $ I $ respectively. Then define   $$ f'(a) \stackrel{\text{def}}{=} \lim_{I \in \Lambda} \lambda(I), $$   if it exists. Question: How can we show that this new definition of the derivative agrees with the usual one?",,"['calculus', 'real-analysis', 'derivatives', 'definition', 'order-theory']"
49,How to prove $f(x)>g(x)$ by showing $f'(x)>g'(x)$ for some $x>x_0$,How to prove  by showing  for some,f(x)>g(x) f'(x)>g'(x) x>x_0,"Is it possible to show that some function $f(x)$ is larger than $g(x)$ if I can show that its derivative is larger for some $x>x_0$? As an example I can think of $f(x)=(1+x)^n , \ g(x)=1+nx+ \frac{n(n-1)x^2}{2}$, which derivatives are $n(1+x)^{n-1}$ and $n+n(n-1)x$ and the use Bernoulli inequality to show that $f'(x)>g'(x)$ for $x>0$.","Is it possible to show that some function $f(x)$ is larger than $g(x)$ if I can show that its derivative is larger for some $x>x_0$? As an example I can think of $f(x)=(1+x)^n , \ g(x)=1+nx+ \frac{n(n-1)x^2}{2}$, which derivatives are $n(1+x)^{n-1}$ and $n+n(n-1)x$ and the use Bernoulli inequality to show that $f'(x)>g'(x)$ for $x>0$.",,"['calculus', 'inequality', 'derivatives']"
50,Understanding $dx/df$ (not $df/dx$),Understanding  (not ),dx/df df/dx,"I have encountered here that sometimes people write $dx/df$ . For example, here , the author of the answer writes down the chain rule as $$\frac{dg}{df}=\frac{dg}{dx}\frac{dx}{df},$$ which seems to be an abuse of notation. And $dx/df$ is found to be just $\frac{1}{df/dx}$ . Here , I learned that when someone writes ""differentiate $f$ with respect to $g$ "", what they mean is to differentiate some hidden composition, which seems to rely upon an inverse of what is said to be a quantity with respect to which we want to differentiate (there, they have $\phi(t)=2t$ , whereas they differentiate $f(x)=x^2$ with respect to $x/2$ , and the composition is $f\circ\phi$ ), but I may be wrong here. So, if the goal is to ""differentiate $x$ with respect to $f$ "", do we actually have $$(x\circ h)'(u)=x'(h(u))h'(u),$$ where $h(u):=f^{-1}(u)$ and $x(u):=u$ ? This seems to agree with what $dx/df$ is to be found: $$(x\circ h)'(u)=\frac{1}{f'(f^{-1}(u))}=\frac{dx}{df}.$$","I have encountered here that sometimes people write . For example, here , the author of the answer writes down the chain rule as which seems to be an abuse of notation. And is found to be just . Here , I learned that when someone writes ""differentiate with respect to "", what they mean is to differentiate some hidden composition, which seems to rely upon an inverse of what is said to be a quantity with respect to which we want to differentiate (there, they have , whereas they differentiate with respect to , and the composition is ), but I may be wrong here. So, if the goal is to ""differentiate with respect to "", do we actually have where and ? This seems to agree with what is to be found:","dx/df \frac{dg}{df}=\frac{dg}{dx}\frac{dx}{df}, dx/df \frac{1}{df/dx} f g \phi(t)=2t f(x)=x^2 x/2 f\circ\phi x f (x\circ h)'(u)=x'(h(u))h'(u), h(u):=f^{-1}(u) x(u):=u dx/df (x\circ h)'(u)=\frac{1}{f'(f^{-1}(u))}=\frac{dx}{df}.","['calculus', 'derivatives']"
51,Possible values of c in the polynomial $x^3+ax^2+bx+c$.,Possible values of c in the polynomial .,x^3+ax^2+bx+c,"I'm studying for a GRE and this is a question from an old test: Let $p(x)$ be the polynomial $x^3+ax^2+bx+c$ , where $a,b,$ and $c$ are real constants. If $p(-3)=p(2)=0$ and $p'(-3)<0$ , which of the following is a possible value of $c$ ? Of the options given (-27, -18, -6, -3, -0.5), I have already solved the problem to see that -27 is the only possible value given, but my solution is lengthy, to say the least, and this is the GRE, so ideally problems should be solvable in approximately 2.5 minutes. I was wondering if anyone could think of faster ways to see how to solve this problem that avoids the copious amount of arithmetic I sort through to find the answer? Here's my solution: $$p(-3)=-27+9a-3b+c=0=8+4a+2b+c=p(2)$$ and so we may see that $a=b+7$ after several steps of time consuming arithmetic. Then, $$p'(x)=3x^2+2(7+b)x+b$$ $$\Rightarrow p'(-3)=27-6(7+b)+b<0 $$ and so we get that $b>-3$ after several more steps of arithmetic. Now, since $p$ has two real roots in $\mathbb{R}$ , it must split completely in $\mathbb{R}$ , and so $$p(x)=(x+3)(x-2)(x-\alpha)$$ for some $\alpha \in \mathbb{R}$ . Expanding this expression we get, $$x^3+x^2(1-\alpha)+x(-\alpha-6)+6\alpha $$ $$\Rightarrow a=1-\alpha\\ b=-\alpha-6\\c=6\alpha $$ And so, finally, since $b>-3 \Rightarrow \alpha<-3 \Rightarrow c<-18$ . And so we're done. This isn't a particularly challenging problem, in my opinion, but the solution is lengthy even without me including my actual arithmetic. Just writing it out takes longer that 3 minutes, let alone the time built in to actually thinking about the problem/ figuring out where to go next. So, I feel like there must be a simpler way to think about this problem and approach finding a solution, no?","I'm studying for a GRE and this is a question from an old test: Let be the polynomial , where and are real constants. If and , which of the following is a possible value of ? Of the options given (-27, -18, -6, -3, -0.5), I have already solved the problem to see that -27 is the only possible value given, but my solution is lengthy, to say the least, and this is the GRE, so ideally problems should be solvable in approximately 2.5 minutes. I was wondering if anyone could think of faster ways to see how to solve this problem that avoids the copious amount of arithmetic I sort through to find the answer? Here's my solution: and so we may see that after several steps of time consuming arithmetic. Then, and so we get that after several more steps of arithmetic. Now, since has two real roots in , it must split completely in , and so for some . Expanding this expression we get, And so, finally, since . And so we're done. This isn't a particularly challenging problem, in my opinion, but the solution is lengthy even without me including my actual arithmetic. Just writing it out takes longer that 3 minutes, let alone the time built in to actually thinking about the problem/ figuring out where to go next. So, I feel like there must be a simpler way to think about this problem and approach finding a solution, no?","p(x) x^3+ax^2+bx+c a,b, c p(-3)=p(2)=0 p'(-3)<0 c p(-3)=-27+9a-3b+c=0=8+4a+2b+c=p(2) a=b+7 p'(x)=3x^2+2(7+b)x+b \Rightarrow p'(-3)=27-6(7+b)+b<0  b>-3 p \mathbb{R} \mathbb{R} p(x)=(x+3)(x-2)(x-\alpha) \alpha \in \mathbb{R} x^3+x^2(1-\alpha)+x(-\alpha-6)+6\alpha  \Rightarrow a=1-\alpha\\ b=-\alpha-6\\c=6\alpha  b>-3 \Rightarrow \alpha<-3 \Rightarrow c<-18","['calculus', 'derivatives', 'polynomials', 'gre-exam']"
52,What did I do wrong in this simple related rates problem?,What did I do wrong in this simple related rates problem?,,"The question is A street light is mounted at the top of a 15-ft-tall pole. A man  6 ft tall walks away from the pole with a speed of 5 ftys along a straight path. How fast is the tip of his shadow moving when he is 40 ft from the pole? I drew a diagram like this to model the situation: Where $x$ is the distance between the pole and the man, and $y$ is the length of the shadow of the man. I'm pretty sure the question is asking to find $\frac{dy}{dt}$ when $x=40$ ,  so I expressed $y$ in terms of $x$ . $$ \frac{15}{6}=\frac{x+y}{y} \Rightarrow y=\frac{2}{3}x $$ I tried using the chain rule to find $\frac{dy}{dt}$ : $$ \frac{dy}{dt}=\frac{dy}{dx}\frac{dx}{dt} $$ We're given that the man is walking at $5 \text{ ft/s}$ so $x$ is increasing at a rate of $5 \text{ft/s}$ , therefore, $\frac{dx}{dt}=5$ . To find $\frac{dy}{dx}$ we simply differentiate both sides of the equation with respect to $x$ . $$ y=\frac{2}{3}x \Rightarrow \frac{dy}{dx}=\frac{2}{3} $$ So it follows that since $\frac{dx}{dt}=5$ and $\frac{dy}{dx}=\frac{2}{3}$ , $\frac{dy}{dt}$ must be $$ \frac{dy}{dt} = \frac{dy}{dx}\frac{dx}{dt} = 5\cdot \frac{2}{3} = \frac{10}{3} \text{ ft/s} $$ Except that it isn't. The correct answer in the textbook I'm using states that it is in fact $\frac{25}{3} \text{ ft/s}$ . I'm just confused about where I went wrong! This was my entire process to get to the incorrect answer.","The question is A street light is mounted at the top of a 15-ft-tall pole. A man  6 ft tall walks away from the pole with a speed of 5 ftys along a straight path. How fast is the tip of his shadow moving when he is 40 ft from the pole? I drew a diagram like this to model the situation: Where is the distance between the pole and the man, and is the length of the shadow of the man. I'm pretty sure the question is asking to find when ,  so I expressed in terms of . I tried using the chain rule to find : We're given that the man is walking at so is increasing at a rate of , therefore, . To find we simply differentiate both sides of the equation with respect to . So it follows that since and , must be Except that it isn't. The correct answer in the textbook I'm using states that it is in fact . I'm just confused about where I went wrong! This was my entire process to get to the incorrect answer.","x y \frac{dy}{dt} x=40 y x 
\frac{15}{6}=\frac{x+y}{y} \Rightarrow y=\frac{2}{3}x
 \frac{dy}{dt} 
\frac{dy}{dt}=\frac{dy}{dx}\frac{dx}{dt}
 5 \text{ ft/s} x 5 \text{ft/s} \frac{dx}{dt}=5 \frac{dy}{dx} x 
y=\frac{2}{3}x \Rightarrow \frac{dy}{dx}=\frac{2}{3}
 \frac{dx}{dt}=5 \frac{dy}{dx}=\frac{2}{3} \frac{dy}{dt} 
\frac{dy}{dt} = \frac{dy}{dx}\frac{dx}{dt} = 5\cdot \frac{2}{3} = \frac{10}{3} \text{ ft/s}
 \frac{25}{3} \text{ ft/s}","['calculus', 'derivatives', 'related-rates']"
53,"Derivative of ${g(x)=\int_0^1 \frac{e^{-x^2(t^2+1)}}{t^2+1}\,dt}$ respect to $x$.",Derivative of  respect to .,"{g(x)=\int_0^1 \frac{e^{-x^2(t^2+1)}}{t^2+1}\,dt} x","If $\displaystyle{g(x)=\int_0^1 \frac{e^{-x^2(t^2+1)}}{t^2+1}\,dt}$ , find $g'(x)$ . Any hint?","If , find . Any hint?","\displaystyle{g(x)=\int_0^1 \frac{e^{-x^2(t^2+1)}}{t^2+1}\,dt} g'(x)","['derivatives', 'definite-integrals']"
54,What is the derivative of binary cross entropy loss w.r.t to input of sigmoid function?,What is the derivative of binary cross entropy loss w.r.t to input of sigmoid function?,,"I want to compute the derivative of binary cross entropy loss w.r.t to the input of the sigmoid function and was wondering if there's a closed form expression? I've seen derivations of binary cross entropy loss with respect to model weights/parameters ( derivative of cost function for Logistic Regression ) as well as derivations of the sigmoid function w.r.t to its input ( Derivative of sigmoid function $\sigma (x) = \frac{1}{1+e^{-x}}$ ), but nothing that combines the two. I would greatly appreciate any help with this. There's also a post that computes the derivative of categorical cross entropy loss w.r.t to pre-softmax outputs ( Derivative of Softmax loss function ). I am looking for something similar in the binary case (perhaps this generalizes to the binary case, but not sure).","I want to compute the derivative of binary cross entropy loss w.r.t to the input of the sigmoid function and was wondering if there's a closed form expression? I've seen derivations of binary cross entropy loss with respect to model weights/parameters ( derivative of cost function for Logistic Regression ) as well as derivations of the sigmoid function w.r.t to its input ( Derivative of sigmoid function $\sigma (x) = \frac{1}{1+e^{-x}}$ ), but nothing that combines the two. I would greatly appreciate any help with this. There's also a post that computes the derivative of categorical cross entropy loss w.r.t to pre-softmax outputs ( Derivative of Softmax loss function ). I am looking for something similar in the binary case (perhaps this generalizes to the binary case, but not sure).",,"['calculus', 'derivatives', 'machine-learning', 'logistic-regression']"
55,Product rule for independent functions,Product rule for independent functions,,Suppose we have two independent functions $f(u)$ and $g(v)$ then (i) :- $$\frac {d \;(f(u)\cdot g(v))}{dx} = \frac {d (f(u)\cdot g(v))}{du}\cdot\frac{du}{dx} $$ Since $g(v)$ doesn't change with changing $u$ $$\frac {d (g(v))}{du} = 0$$ So the first equation becomes (ii) :- $$\frac {d \;(f(u)\cdot g(v))}{dx} = g(v) \cdot f'(u) \cdot\frac{du}{dx} $$ Similarly we can get this equation (iii) :- $$\frac {d \;(f(u)\cdot g(v))}{dx} = f(u)\cdot g'(v)\cdot \frac{dv}{dx} $$ Now if I add both the equations I will get $$ \frac {d \;(f(u)\cdot g(v))}{dx} = \left( \frac{1}{2} \right) \left(g(v)\cdot f'(u)\cdot\frac{du}{dx} + f(u)\cdot g'(v)\cdot\frac{dv}{dx}\right)$$ But this can't be right since it is half of what we get from the product rule. So where am I wrong ?,Suppose we have two independent functions and then (i) :- Since doesn't change with changing So the first equation becomes (ii) :- Similarly we can get this equation (iii) :- Now if I add both the equations I will get But this can't be right since it is half of what we get from the product rule. So where am I wrong ?,f(u) g(v) \frac {d \;(f(u)\cdot g(v))}{dx} = \frac {d (f(u)\cdot g(v))}{du}\cdot\frac{du}{dx}  g(v) u \frac {d (g(v))}{du} = 0 \frac {d \;(f(u)\cdot g(v))}{dx} = g(v) \cdot f'(u) \cdot\frac{du}{dx}  \frac {d \;(f(u)\cdot g(v))}{dx} = f(u)\cdot g'(v)\cdot \frac{dv}{dx}   \frac {d \;(f(u)\cdot g(v))}{dx} = \left( \frac{1}{2} \right) \left(g(v)\cdot f'(u)\cdot\frac{du}{dx} + f(u)\cdot g'(v)\cdot\frac{dv}{dx}\right),"['calculus', 'derivatives']"
56,Right derivative increasing implies convex,Right derivative increasing implies convex,,"I want to prove the following: If we have a function $f$ (not necessarily differentiable), but with right and left derivative $$f'_{\pm}(x) \equiv\lim_{y \rightarrow x^{\pm}} \frac{f(y)-f(x)}{y-x}$$ existing at all $x$ in $\mathbb{R}$ with $f'_+(x) \leq f'_+(y)$ $\forall x \leq y$ , then $f$ is convex. This is easily proven if $f$ is differentiable using the mean value theorem, but nothing like the same strategy (as far as I can see) works for this example.  Any help would be massively appreciated!","I want to prove the following: If we have a function (not necessarily differentiable), but with right and left derivative existing at all in with , then is convex. This is easily proven if is differentiable using the mean value theorem, but nothing like the same strategy (as far as I can see) works for this example.  Any help would be massively appreciated!",f f'_{\pm}(x) \equiv\lim_{y \rightarrow x^{\pm}} \frac{f(y)-f(x)}{y-x} x \mathbb{R} f'_+(x) \leq f'_+(y) \forall x \leq y f f,"['calculus', 'derivatives', 'convex-analysis']"
57,Differentiating the maximum?,Differentiating the maximum?,,"Consider a function $f(x,y) : \mathbb [0,1]^2 \to \mathbb R$ , smooth in both variables (very strong assumption for the purposes). Define $f_{X}(x) = \max_{y \in [0,1]} f(x,y)$ and $f_Y{(y)} = \max_{x \in [0,1]} f(x,y)$ , which are well-defined. Oftentimes, in optimization, it is a useful statement to say that $f_X$ and $f_Y$ have unique maxima/minima. For this purpose, it is convenient to see if they are differentiable , and set the derivative to zero. Under what sufficient conditions are $f_X$ and $f_Y$ differentiable (they are always continuous, as pointed out below)? Is the condition of ""f smooth"" acceptable? How can I study the derivative of $f_X$ and $f_Y$ , so that I can look at the maxima/minima of such functions? EDIT : Since we have come up with a counterexample to non-differentiability, given by $(x,y) \to 1-xy$ on $[-1,1]^2$ , I would like sufficient conditions under which this is true. One may use the language of sub-differentials etc. (from convex analysis) if required for this purpose.","Consider a function , smooth in both variables (very strong assumption for the purposes). Define and , which are well-defined. Oftentimes, in optimization, it is a useful statement to say that and have unique maxima/minima. For this purpose, it is convenient to see if they are differentiable , and set the derivative to zero. Under what sufficient conditions are and differentiable (they are always continuous, as pointed out below)? Is the condition of ""f smooth"" acceptable? How can I study the derivative of and , so that I can look at the maxima/minima of such functions? EDIT : Since we have come up with a counterexample to non-differentiability, given by on , I would like sufficient conditions under which this is true. One may use the language of sub-differentials etc. (from convex analysis) if required for this purpose.","f(x,y) : \mathbb [0,1]^2 \to \mathbb R f_{X}(x) = \max_{y \in [0,1]} f(x,y) f_Y{(y)} = \max_{x \in [0,1]} f(x,y) f_X f_Y f_X f_Y f_X f_Y (x,y) \to 1-xy [-1,1]^2","['real-analysis', 'calculus', 'derivatives', 'optimization']"
58,Let $f(x)=x+\frac{x^2}{2} + \frac{x^3}{3}+\frac{x^4}{4}+\frac{x^5}{5}$ and let $g(x)=f^{-1} (x)$. Find $g’’’(0)$,Let  and let . Find,f(x)=x+\frac{x^2}{2} + \frac{x^3}{3}+\frac{x^4}{4}+\frac{x^5}{5} g(x)=f^{-1} (x) g’’’(0),"My method is extremely inefficient, but here it is $$g(f(x))=x$$ $$g’(f(x)).f’(x)=1$$ Differentiating wrt x multiple times $$g’’’(f(x))(f’(x))^3 + (g’’(f(x)))(2f’(x))(f’’(x)) + g’’(f(x)).f’(x).f’’(x) + g’(f(x)).f’’’(x)=0$$ I may have made some computation errors in this, but I can’t seem to find any (I apologize if there are) $f(x)=0$ at $x=0$ $$g’’’(0) +2 g’’(0) + g’’(0) +2g’(0)=0$$ How do I proceed from here? Is there a better way to approach this ?","My method is extremely inefficient, but here it is Differentiating wrt x multiple times I may have made some computation errors in this, but I can’t seem to find any (I apologize if there are) at How do I proceed from here? Is there a better way to approach this ?",g(f(x))=x g’(f(x)).f’(x)=1 g’’’(f(x))(f’(x))^3 + (g’’(f(x)))(2f’(x))(f’’(x)) + g’’(f(x)).f’(x).f’’(x) + g’(f(x)).f’’’(x)=0 f(x)=0 x=0 g’’’(0) +2 g’’(0) + g’’(0) +2g’(0)=0,['derivatives']
59,Proof using Fundamental Theorem of Calculus (Showing RHS = LHS),Proof using Fundamental Theorem of Calculus (Showing RHS = LHS),,"Question: Prove that $\int^x_0\big[\int^u_0 f(t) dt\big] du = \int^x_0f(u)(x-u) du$ where $f$ is a continuous function. Attempt: My lecturer hinted that it'd be helpful to apply the fundamental theorem of calculus to $F(u) = u \int^u_0f(t) dt$ . I know that I can apply the FTC to $F(u)$ since $f$ is continuous, meaning it is also a Riemann integrable function and thus the conditions of the FTC are met. To find $F'(u)$ , I will let $G(u) = u$ and $H(u)=\int^u_0f(t) dt$ be functions such that $F(u)=G(u)H(u)$ .  Thus, $G'(u)=1$ and, applying the FTC, $H'(u)=f(u)$ . Using the product rule, $F'(u)=G(u)H'(u)+G'(u)H(u)=uf(u)+\int^u_0f(t) dt$ . However, this is where I get stuck and am not sure how to use this to prove the initial equation. Any help would be greatly appreciated.","Question: Prove that where is a continuous function. Attempt: My lecturer hinted that it'd be helpful to apply the fundamental theorem of calculus to . I know that I can apply the FTC to since is continuous, meaning it is also a Riemann integrable function and thus the conditions of the FTC are met. To find , I will let and be functions such that .  Thus, and, applying the FTC, . Using the product rule, . However, this is where I get stuck and am not sure how to use this to prove the initial equation. Any help would be greatly appreciated.",\int^x_0\big[\int^u_0 f(t) dt\big] du = \int^x_0f(u)(x-u) du f F(u) = u \int^u_0f(t) dt F(u) f F'(u) G(u) = u H(u)=\int^u_0f(t) dt F(u)=G(u)H(u) G'(u)=1 H'(u)=f(u) F'(u)=G(u)H'(u)+G'(u)H(u)=uf(u)+\int^u_0f(t) dt,"['real-analysis', 'calculus', 'integration', 'derivatives', 'proof-writing']"
60,Is there a relationship between the second derivative and the quadratic term of a cubic equation?,Is there a relationship between the second derivative and the quadratic term of a cubic equation?,,"I have been studying on cubic equations for a while and see that the cubic equation needs to be in the form of $mx^3+px+q=0$ so that we can find the roots easily. In order to obtain such an equation having no quadratic term for a cubic equation in the form of $x^3+ax^2+bx+c=0$ , $x$ value needs to be replaced with $t-\frac a{3}$ . I realised that the second derivative of any cubic equation in the form of $x^3+ax^2+bx+c=0$ is $y''=6x+2a$ , and when we equalize $y$ to $0$ , $x$ is equal to $-\frac a{3}$ . This had me thinking about any possible relation between the quadratic term and the second derivative. It is also sort of the same in quadratic functions in the form of $x^2+ax+b=0$ . When we replace $x$ with $-\frac a{2}$ , which is the first derivative of a quadratic function and the vertex point of it, we obtain the vertex form of the equation which does not have the linear term, $x^1$ . Is there a relation between the quadratic term and the second derivative of a cubic equation? If the answer is yes, what is it and how is it observed on graphs, in equations?","I have been studying on cubic equations for a while and see that the cubic equation needs to be in the form of so that we can find the roots easily. In order to obtain such an equation having no quadratic term for a cubic equation in the form of , value needs to be replaced with . I realised that the second derivative of any cubic equation in the form of is , and when we equalize to , is equal to . This had me thinking about any possible relation between the quadratic term and the second derivative. It is also sort of the same in quadratic functions in the form of . When we replace with , which is the first derivative of a quadratic function and the vertex point of it, we obtain the vertex form of the equation which does not have the linear term, . Is there a relation between the quadratic term and the second derivative of a cubic equation? If the answer is yes, what is it and how is it observed on graphs, in equations?",mx^3+px+q=0 x^3+ax^2+bx+c=0 x t-\frac a{3} x^3+ax^2+bx+c=0 y''=6x+2a y 0 x -\frac a{3} x^2+ax+b=0 x -\frac a{2} x^1,"['calculus', 'derivatives', 'roots', 'cubics']"
61,a function which is monotone in an open interval but it is not continuously differentiable at that interval.,a function which is monotone in an open interval but it is not continuously differentiable at that interval.,,Can you  give an example of a function $f(x)$ which is differentiable but not continuously differentiable  and there exists a nbd $N$ around a point $c$ such that $f'(x) >(<) 0   \forall x \in N $ and $f'(x)$ is not continuous at the point $c$ ? I am basically trying to search a function which is monotone in an open interval but it is not continuously differentiable at that interval. Can anyone please help me to find that kind of a function?,Can you  give an example of a function which is differentiable but not continuously differentiable  and there exists a nbd around a point such that and is not continuous at the point ? I am basically trying to search a function which is monotone in an open interval but it is not continuously differentiable at that interval. Can anyone please help me to find that kind of a function?,f(x) N c f'(x) >(<) 0   \forall x \in N  f'(x) c,"['real-analysis', 'calculus', 'derivatives']"
62,Prove $0.9999^{\!101}<0.99<0.9999^{\!100}$,Prove,0.9999^{\!101}<0.99<0.9999^{\!100},"Prove $$0.9999^{\!101}<0.99<0.9999^{\!100}$$ I think its original idea is $$(1-x)^{(1-\frac{1}{x})}<(1+x)^{(\frac{1}{x})} \tag{I can't prove!}$$ For $x=100^{\!-1}\,\therefore\,(1-x)^{(1-\frac{1}{x})}<(1+x)^{(\frac{1}{x})}\,\therefore\,0.99^{\!-99}<1.01^{\!100}$ . Furthermore $0.99^{\!-99}\times0.99^{\!100}=0.99<1.01^{\!100}\times0.99^{\!100}=0.9999^{\!100}$ . For $x=-100^{\!-1}\,\therefore\,(1-x)^{(1-\frac{1}{x})}<(1+x)^{(\frac{1}{x})}\,\therefore\,1.01^{\!101}<0.99^{\!-100}$ . Furthermore $1.01^{\!101}\times0.99^{\!101}=0.9999^{\!101}<0.99^{\!-100}\times0.99^{\!101}=0.99$ .",Prove I think its original idea is For . Furthermore . For . Furthermore .,"0.9999^{\!101}<0.99<0.9999^{\!100} (1-x)^{(1-\frac{1}{x})}<(1+x)^{(\frac{1}{x})} \tag{I can't prove!} x=100^{\!-1}\,\therefore\,(1-x)^{(1-\frac{1}{x})}<(1+x)^{(\frac{1}{x})}\,\therefore\,0.99^{\!-99}<1.01^{\!100} 0.99^{\!-99}\times0.99^{\!100}=0.99<1.01^{\!100}\times0.99^{\!100}=0.9999^{\!100} x=-100^{\!-1}\,\therefore\,(1-x)^{(1-\frac{1}{x})}<(1+x)^{(\frac{1}{x})}\,\therefore\,1.01^{\!101}<0.99^{\!-100} 1.01^{\!101}\times0.99^{\!101}=0.9999^{\!101}<0.99^{\!-100}\times0.99^{\!101}=0.99","['derivatives', 'inequality']"
63,What is the $n^{th}$ term derivative of $f(x) = (x^2-x-1)(\ln(1-x))$?,What is the  term derivative of ?,n^{th} f(x) = (x^2-x-1)(\ln(1-x)),I have the first three terms but am struggling with finding the $n^{th}$ term derivative of the function. Here is my work: $$\\$$ $$f(x) = (x^2-x-1)(\ln(1-x)) $$ $$f'(x) = (2x-1)(\ln(1-x))-\left(\dfrac{x^2-x-1}{1-x}\right)$$ $$f''(x) = \dfrac{3x^2-5x+2(x-1)^2 \ln(1-x)+3}{(1-x)^2}$$ $$f'''(x) = \dfrac{2x^2-5x+1}{(x-1)^3}$$ $$f^{(n)}(x) = \ ?$$,I have the first three terms but am struggling with finding the term derivative of the function. Here is my work:,n^{th} \\ f(x) = (x^2-x-1)(\ln(1-x))  f'(x) = (2x-1)(\ln(1-x))-\left(\dfrac{x^2-x-1}{1-x}\right) f''(x) = \dfrac{3x^2-5x+2(x-1)^2 \ln(1-x)+3}{(1-x)^2} f'''(x) = \dfrac{2x^2-5x+1}{(x-1)^3} f^{(n)}(x) = \ ?,"['calculus', 'derivatives']"
64,"If $|f'(x)| \leq c|f(x)|$ for all $x \in (0,1)$ then $f(x)=0$",If  for all  then,"|f'(x)| \leq c|f(x)| x \in (0,1) f(x)=0","Question:   Let $f:[0,1] \to \mathbb{R}$ be a real valued continuous function which is differentiable on $(0,1)$ , and satisfies $f(0)=0$ . Suppose there exists a $c \in (0,1)$ such that $|f'(x)| \leq c|f(x)|$ for all $x \in (0,1)$ . Show that $f(x)=0$ . Solution attempt: $f$ being continuous at $x=0$ , for a given $\epsilon >0$ $\exists$ a $\delta>0$ , such that $|f(x)|< \epsilon$ whenever $x \in [0, \delta) \cap [0,1]$ . Now, consider $|f'(h)|=|\lim_{k \to 0}\frac{f(h+k)-f(h)}{k} |\leq |cf(h)| \implies \lim_{ \ k \to 0} |f(2h)| \leq |f(h)|[1+ c|k|] $ Being continuous at $x=0$ , $\lim_{h \to 0} f(h) = f(0) = 0 \implies f(2h) = 0$ [by applying $|f(2h)| \leq |f(h)|(c|k|+1) \ $ ]. In this manner, let us partition the interval $[0,1)$ into $n$ subintervals of length $h$ each. As the length $h \to 0$ , $n \to \infty$ , and recursively, we get $|f(rh)| \leq |f(h)|(c|k|+1)^r \ $ . Hence, finally for all $r$ , we get $f(rh)=0$ . By continuity, we can safely say, for all $x$ in those respective subintervals, $f(x)=0$ . Again, by continuity, we have $\lim_{ x \to 1} f(x) = 0$ . Hence, $f(x)=0$ for all $x$ in $[0,1]$ .","Question:   Let be a real valued continuous function which is differentiable on , and satisfies . Suppose there exists a such that for all . Show that . Solution attempt: being continuous at , for a given a , such that whenever . Now, consider Being continuous at , [by applying ]. In this manner, let us partition the interval into subintervals of length each. As the length , , and recursively, we get . Hence, finally for all , we get . By continuity, we can safely say, for all in those respective subintervals, . Again, by continuity, we have . Hence, for all in .","f:[0,1] \to \mathbb{R} (0,1) f(0)=0 c \in (0,1) |f'(x)| \leq c|f(x)| x \in (0,1) f(x)=0 f x=0 \epsilon >0 \exists \delta>0 |f(x)|< \epsilon x \in [0, \delta) \cap [0,1] |f'(h)|=|\lim_{k \to 0}\frac{f(h+k)-f(h)}{k} |\leq |cf(h)| \implies \lim_{ \ k \to 0} |f(2h)| \leq |f(h)|[1+ c|k|]  x=0 \lim_{h \to 0} f(h) = f(0) = 0 \implies f(2h) = 0 |f(2h)| \leq |f(h)|(c|k|+1) \  [0,1) n h h \to 0 n \to \infty |f(rh)| \leq |f(h)|(c|k|+1)^r \  r f(rh)=0 x f(x)=0 \lim_{ x \to 1} f(x) = 0 f(x)=0 x [0,1]","['real-analysis', 'calculus', 'derivatives', 'proof-verification', 'continuity']"
65,Why can't I differentiate $ x^{\sin x} $ using the power rule?,Why can't I differentiate  using the power rule?, x^{\sin x} ,"I'm trying to differentiate $ x^{\sin x} $ , with respect to $ x $ and $x > 0 $ . My textbook initiates with $ y = x^{\sin x} $ , takes logarithms on both sides and arrives at the answer $$ x^{\sin x - 1}.\sin x + x^{\sin x}.\cos x \ \log x $$ Why can't I use the power rule to proceed like this: $ y' = (\sin x) \ x^{\sin x-1} \cos x $ . Here, I've first differentiated $ x $ with respect to $ \sin x $ and then I've differentiated $ \sin x $ with respect to $ x $ to get $ \cos x $ .","I'm trying to differentiate , with respect to and . My textbook initiates with , takes logarithms on both sides and arrives at the answer Why can't I use the power rule to proceed like this: . Here, I've first differentiated with respect to and then I've differentiated with respect to to get .", x^{\sin x}   x  x > 0   y = x^{\sin x}   x^{\sin x - 1}.\sin x + x^{\sin x}.\cos x \ \log x   y' = (\sin x) \ x^{\sin x-1} \cos x   x   \sin x   \sin x   x   \cos x ,['derivatives']
66,L'Hôpital's rule only applicable if right-hand limit exist?,L'Hôpital's rule only applicable if right-hand limit exist?,,"In a source I have been reading, this statement was made regarding L'Hôpital's rule: Why is it the case that L'Hôpital's rule is applicable only if the right-hand limit exists?  Why not the left-hand? Why not both?  I have read other sources on L'Hôpital's rule that do not mention it and would like clarification. Here is the text: L'Hôpital's Rule: Suppose that $f$ and $g$ are differentiable functions, and $f(a)=g(a)=0$ , and suppose that $g'(x)$ is nonzero in a neighborhood of $a$ (except maybe at $a$ itself).  Then $$\lim\limits_{x \to a} \ \frac{f(x)}{g(x)}=\lim\limits_{x \to a} \ \frac{f'(x)}{g'(x)}$$ if the limit on the right-hand side exists.","In a source I have been reading, this statement was made regarding L'Hôpital's rule: Why is it the case that L'Hôpital's rule is applicable only if the right-hand limit exists?  Why not the left-hand? Why not both?  I have read other sources on L'Hôpital's rule that do not mention it and would like clarification. Here is the text: L'Hôpital's Rule: Suppose that and are differentiable functions, and , and suppose that is nonzero in a neighborhood of (except maybe at itself).  Then if the limit on the right-hand side exists.",f g f(a)=g(a)=0 g'(x) a a \lim\limits_{x \to a} \ \frac{f(x)}{g(x)}=\lim\limits_{x \to a} \ \frac{f'(x)}{g'(x)},"['calculus', 'derivatives']"
67,Help with Calculus Optimization Problem!,Help with Calculus Optimization Problem!,,"We wish to construct a rectangular auditorium with a stage shaped as a semicircle of radius $r$, as shown in the diagram below (white is the stage and green is the seating area). For safety reasons, light strips must be placed on the perimeter of the seating area. If we have $45\pi + 60$ meters of light strips, what should $r$ be so that the seating area is maximized? So I first set the width of the seating area to 2r, and the depth to be x. The perimeter would then be  $2x + 2r + \pi r$ = $45\pi + 60$. The problem asks us to maximize the area, though, so it's $2rx - (\pi r^2)/2$. I can solve the equation in terms of x so that it becomes $x = (45\pi + 60 - r(\pi + 2))/2$. Unfortunately, I'm stuck from this point on, so any hint that you could give me would be great. Thanks!","We wish to construct a rectangular auditorium with a stage shaped as a semicircle of radius $r$, as shown in the diagram below (white is the stage and green is the seating area). For safety reasons, light strips must be placed on the perimeter of the seating area. If we have $45\pi + 60$ meters of light strips, what should $r$ be so that the seating area is maximized? So I first set the width of the seating area to 2r, and the depth to be x. The perimeter would then be  $2x + 2r + \pi r$ = $45\pi + 60$. The problem asks us to maximize the area, though, so it's $2rx - (\pi r^2)/2$. I can solve the equation in terms of x so that it becomes $x = (45\pi + 60 - r(\pi + 2))/2$. Unfortunately, I'm stuck from this point on, so any hint that you could give me would be great. Thanks!",,"['calculus', 'derivatives', 'optimization', 'circles', 'area']"
68,Connecting smooth functions in a smooth way,Connecting smooth functions in a smooth way,,"Let $a<b<c<d$ be real values, and let $f \in C^{\infty}([a,b])$ and $g \in C^{\infty}([c,d])$. Is there a way to ""connect"" these functions in a smooth way? That is, is there a function $h \in C^{\infty}([a,d])$ such that $h=f$ on $[a,b]$ and $h=g$ on $[c,d]$? If this is true, how is the proven? Is the proof non-constructive, or is there an explicit way to do it?","Let $a<b<c<d$ be real values, and let $f \in C^{\infty}([a,b])$ and $g \in C^{\infty}([c,d])$. Is there a way to ""connect"" these functions in a smooth way? That is, is there a function $h \in C^{\infty}([a,d])$ such that $h=f$ on $[a,b]$ and $h=g$ on $[c,d]$? If this is true, how is the proven? Is the proof non-constructive, or is there an explicit way to do it?",,"['calculus', 'derivatives', 'smooth-functions']"
69,Using taylor series expansion to approximate the derivative of a function,Using taylor series expansion to approximate the derivative of a function,,"I know that $f(x+h)=f(x)+hf'(x)+\frac{h^2}{2}f''(x)+\frac{h^3}{3!}f'''(x)$ but I do not know what to do to reach what is shown above, I would appreciate any collaboration.","I know that $f(x+h)=f(x)+hf'(x)+\frac{h^2}{2}f''(x)+\frac{h^3}{3!}f'''(x)$ but I do not know what to do to reach what is shown above, I would appreciate any collaboration.",,"['calculus', 'real-analysis', 'derivatives', 'numerical-methods', 'approximation']"
70,"Prove $f'(x) = 2 f(x)$ if $f(x+y) = f(x) f(y)$, $f(x) \ne 0$ and $f'(0) = 2$. [duplicate]","Prove  if ,  and . [duplicate]",f'(x) = 2 f(x) f(x+y) = f(x) f(y) f(x) \ne 0 f'(0) = 2,"This question already has answers here : Differentiable function, not constant, $f(x+y)=f(x)f(y)$, $f'(0)=2$ (2 answers) Closed 1 year ago . I'll state the question from my textbook below: A function $f: \mathbb{R} \to \mathbb{R}$ satisfies the equation $f(x+y) = f(x) f(y)$ for all $x,y \in \mathbb{R}, f(x) \ne 0$. Suppose that the function is differentiable at $x = 0$ and $f'(0) = 2$. Prove that $f'(x) = 2f(x)$. Firstly, I don't understand the first sentence completely. Does it mean that this equation holds true whenever $f(x) \ne 0$ or does it mean to say that $f(x) \ne 0, \forall x \in \mathbb{R}$. If it's the latter then $f(y) \ne 0$ too, right? And then I proceeded in many different ways to find $f'(x)$. I tried replacing $y$ by $0$ in the given equation and then differentiated it, first differentiated the equation and then replaced $y$ by $0$ and tried a few other things. None of these got me anywhere. Here's something I proved while trying to solve the question: Putting $x,y = 0$ in the given equation we have: $f(0) = f(0) f(0) \implies f(0)[f(0) - 1] = 0$ Since $f(x) \ne 0, \forall x \in \mathbb{R}$ (I'm not really sure if this is what the question meant, let's say it did), $f(0) - 1 =0 \implies f(0) = 1$ I don't know if this is even useful but it seems to be so, since we also have been given $f'(0) = 2$. Please help me prove the required equation. Any help would be appreciated.","This question already has answers here : Differentiable function, not constant, $f(x+y)=f(x)f(y)$, $f'(0)=2$ (2 answers) Closed 1 year ago . I'll state the question from my textbook below: A function $f: \mathbb{R} \to \mathbb{R}$ satisfies the equation $f(x+y) = f(x) f(y)$ for all $x,y \in \mathbb{R}, f(x) \ne 0$. Suppose that the function is differentiable at $x = 0$ and $f'(0) = 2$. Prove that $f'(x) = 2f(x)$. Firstly, I don't understand the first sentence completely. Does it mean that this equation holds true whenever $f(x) \ne 0$ or does it mean to say that $f(x) \ne 0, \forall x \in \mathbb{R}$. If it's the latter then $f(y) \ne 0$ too, right? And then I proceeded in many different ways to find $f'(x)$. I tried replacing $y$ by $0$ in the given equation and then differentiated it, first differentiated the equation and then replaced $y$ by $0$ and tried a few other things. None of these got me anywhere. Here's something I proved while trying to solve the question: Putting $x,y = 0$ in the given equation we have: $f(0) = f(0) f(0) \implies f(0)[f(0) - 1] = 0$ Since $f(x) \ne 0, \forall x \in \mathbb{R}$ (I'm not really sure if this is what the question meant, let's say it did), $f(0) - 1 =0 \implies f(0) = 1$ I don't know if this is even useful but it seems to be so, since we also have been given $f'(0) = 2$. Please help me prove the required equation. Any help would be appreciated.",,"['calculus', 'derivatives']"
71,"""$f^\prime (c) = \lim_{n \to \infty} f^\prime (x_n)$"" does not imply the continuity.",""""" does not imply the continuity.",f^\prime (c) = \lim_{n \to \infty} f^\prime (x_n),"Question: suppose $f : [a,b] \rightarrow R$ is a differentiable and $c \in [a,b]$. Then show there exists a sequence $\{x_n\}$ converging to $c$, $x_n \not = c$ for all $n$, such that $f^\prime (c) = \lim_{n \to \infty} f^\prime (x_n)$. Do note this does not imply that $f^\prime$ is continuous (why?). Attempt: Let $x_n \in [a,b]$ Then, $f(x_n)$ is differentiable.  Then, $f^\prime (c) = f^\prime(\lim_{n \to \infty}x_n)=\lim_{n \to \infty}f^\prime(x_n)$. I don't understand why this does not imply continuity because if $f(c)=\lim_{n \to \infty}f(x_n)$, $f$ is continuous at $c$. Isn't it the case for the derivative function? Thank you in advance. Edit: I agree that my attempt above assumes that $f^\prime$ is continuous, which might not be true. So, could you give me some hint to solve this problem without using that assumption? Let $x_n \in [a,b]$. Then, $f(x_n)$ is differentiable. Then, $\lim_{x_n \to c} \frac {f(x_n)-f(c)}{x_n-c}=f^\prime (c)$.I don't know how to proceed from here.","Question: suppose $f : [a,b] \rightarrow R$ is a differentiable and $c \in [a,b]$. Then show there exists a sequence $\{x_n\}$ converging to $c$, $x_n \not = c$ for all $n$, such that $f^\prime (c) = \lim_{n \to \infty} f^\prime (x_n)$. Do note this does not imply that $f^\prime$ is continuous (why?). Attempt: Let $x_n \in [a,b]$ Then, $f(x_n)$ is differentiable.  Then, $f^\prime (c) = f^\prime(\lim_{n \to \infty}x_n)=\lim_{n \to \infty}f^\prime(x_n)$. I don't understand why this does not imply continuity because if $f(c)=\lim_{n \to \infty}f(x_n)$, $f$ is continuous at $c$. Isn't it the case for the derivative function? Thank you in advance. Edit: I agree that my attempt above assumes that $f^\prime$ is continuous, which might not be true. So, could you give me some hint to solve this problem without using that assumption? Let $x_n \in [a,b]$. Then, $f(x_n)$ is differentiable. Then, $\lim_{x_n \to c} \frac {f(x_n)-f(c)}{x_n-c}=f^\prime (c)$.I don't know how to proceed from here.",,"['real-analysis', 'derivatives']"
72,"Apparently smooth function, discontinuous derivative","Apparently smooth function, discontinuous derivative",,"This question is about the existence of discontinuous derivatives, but it doesn't provide much examples except this one and $y = |x|$. The function $$f(x) = \left\{ \begin{array}{lr} \cos(ax) & 0 \leq x \leq c\\ \cos(ac) e^{-b (x - c)} & x > c \end{array} \right.$$ has $[0, +\infty)$ as its domain. $a, b, c \in \mathbb (0,+\infty)$ are real constants. Its first derivative is $$f'(x) = \left\{ \begin{array}{lr} -a \sin(ax) & 0 \leq x \leq c\\ - b \cos(ac) e^{-b (x - c)} & x > c \end{array} \right.$$ $f'(x)$ is continuous only when $a/b = \cot(ac)$ and not in general. $f(x)$ is a continuous function, without a vertical tangent, infinitely differentiable in its domain, and $a,b$ can be chosen such that the function doesn't have corners in $x = c$; despite this, it has a discontinuous derivative. 1) How can (even graphically) the derivative be not continuous where the function is so? 2) Are there any other similar examples that can be done?","This question is about the existence of discontinuous derivatives, but it doesn't provide much examples except this one and $y = |x|$. The function $$f(x) = \left\{ \begin{array}{lr} \cos(ax) & 0 \leq x \leq c\\ \cos(ac) e^{-b (x - c)} & x > c \end{array} \right.$$ has $[0, +\infty)$ as its domain. $a, b, c \in \mathbb (0,+\infty)$ are real constants. Its first derivative is $$f'(x) = \left\{ \begin{array}{lr} -a \sin(ax) & 0 \leq x \leq c\\ - b \cos(ac) e^{-b (x - c)} & x > c \end{array} \right.$$ $f'(x)$ is continuous only when $a/b = \cot(ac)$ and not in general. $f(x)$ is a continuous function, without a vertical tangent, infinitely differentiable in its domain, and $a,b$ can be chosen such that the function doesn't have corners in $x = c$; despite this, it has a discontinuous derivative. 1) How can (even graphically) the derivative be not continuous where the function is so? 2) Are there any other similar examples that can be done?",,"['calculus', 'real-analysis', 'derivatives', 'continuity']"
73,"Interesting math question motivated by physics -- if $\int_0^1f(x)\,dx=1$ and f(0)=f(1)=0 then find $\min f'(x)$",Interesting math question motivated by physics -- if  and f(0)=f(1)=0 then find,"\int_0^1f(x)\,dx=1 \min f'(x)","I saw a question in a physics textbook which was: A particle starts from rest at $t=0$ , $x=0$ , and comes again at rest on $x=1$ , $t=1$ . Let the instantaneous acceleration be $a$ . Then: (a) $a$ cannot be positive for all $t\in[0,1]$ . (b) $|a|$ cannot exceed 2 at any point. (c) $|a|$ must be $\geq 4$ at some point (d) $a$ must change sign but no other assertion can be made. The anwer was (a,c) which is easy to see intuitively but how to attack this problem rigorously? Translated into math the problem becomes $$\text{If }\int_0^1 f(x) \, dx = 1,\text{ and }f(0)=f(1)=0\text{ then find } \min f'(x).$$ Assuming $f(x)$ is continuous. At first I thought lets use some integral inequalities like Cauchy-Schwarz or something but then I realised it wont work. After that I thought that this is somewhat similar to calculus of variations but not quite. I have no idea how to approach this rigorously but I want to see how its done because this is like a ""simple problem"" but still I have no clue how to approach this. ... Its probably indicating some sort of gap in my knowledge or technique. So .. Please help!","I saw a question in a physics textbook which was: A particle starts from rest at , , and comes again at rest on , . Let the instantaneous acceleration be . Then: (a) cannot be positive for all . (b) cannot exceed 2 at any point. (c) must be at some point (d) must change sign but no other assertion can be made. The anwer was (a,c) which is easy to see intuitively but how to attack this problem rigorously? Translated into math the problem becomes Assuming is continuous. At first I thought lets use some integral inequalities like Cauchy-Schwarz or something but then I realised it wont work. After that I thought that this is somewhat similar to calculus of variations but not quite. I have no idea how to approach this rigorously but I want to see how its done because this is like a ""simple problem"" but still I have no clue how to approach this. ... Its probably indicating some sort of gap in my knowledge or technique. So .. Please help!","t=0 x=0 x=1 t=1 a a t\in[0,1] |a| |a| \geq 4 a \text{If }\int_0^1 f(x) \, dx = 1,\text{ and }f(0)=f(1)=0\text{ then find } \min f'(x). f(x)","['calculus', 'derivatives', 'inequality', 'definite-integrals', 'proof-writing']"
74,Smooth function with infinite oscillation,Smooth function with infinite oscillation,,"I'm curious to know if there's a function which: Has an infinite number of solutions for $f(x)=0$ on $x \in [-a,a]$ for an $a > 0$ (like $f(x) = \sin(\frac 1 x)$) Has an $n$th derivative for all $x\in[-a,a]$, for any $n$. There is no interval $[b,c]\subset[-a,a]$ ($b<c$) for which $f(x)=0$ on the whole interval Does such a function exist? If not, how could that be proven?","I'm curious to know if there's a function which: Has an infinite number of solutions for $f(x)=0$ on $x \in [-a,a]$ for an $a > 0$ (like $f(x) = \sin(\frac 1 x)$) Has an $n$th derivative for all $x\in[-a,a]$, for any $n$. There is no interval $[b,c]\subset[-a,a]$ ($b<c$) for which $f(x)=0$ on the whole interval Does such a function exist? If not, how could that be proven?",,['calculus']
75,Derivative of an ellipse,Derivative of an ellipse,,"I'm in my last year of high school and I'm currently studying on conics. Usually to get the centre of an ellipse for example I use the canonical form to get the following form $((x+k)/a)^2 + ((y+k)/b)^2=1$ then consider the $x+k$ and the $y+k$ at the coordinates of the centre. My Math teacher showed us a method to find this center without using the canonical form, just by using derivatives on the initial form which is: $ax^2 +by^2 + cx + dy + f = 0$. So his method consists of deriving this equation once with respect to $x$ and consider the $y$ a constant then have an equation which is $2ax + c = 0$ and the derive the same equation with respect to $y$ and considering $x$ a constant and having: $2by + d = 0$, and finally by solving these two equations he will have the center of the ellipse. Can I have an explanation on why he used this method? like what do the derivatives have to do with the ellipse, where did this method come from. Sorry for any English mistakes and for the wordiness, Thank you in advance.","I'm in my last year of high school and I'm currently studying on conics. Usually to get the centre of an ellipse for example I use the canonical form to get the following form $((x+k)/a)^2 + ((y+k)/b)^2=1$ then consider the $x+k$ and the $y+k$ at the coordinates of the centre. My Math teacher showed us a method to find this center without using the canonical form, just by using derivatives on the initial form which is: $ax^2 +by^2 + cx + dy + f = 0$. So his method consists of deriving this equation once with respect to $x$ and consider the $y$ a constant then have an equation which is $2ax + c = 0$ and the derive the same equation with respect to $y$ and considering $x$ a constant and having: $2by + d = 0$, and finally by solving these two equations he will have the center of the ellipse. Can I have an explanation on why he used this method? like what do the derivatives have to do with the ellipse, where did this method come from. Sorry for any English mistakes and for the wordiness, Thank you in advance.",,"['derivatives', 'conic-sections']"
76,Rewriting the time-independent Schrödinger equation for a simple harmonic oscillating potential in terms of new variables,Rewriting the time-independent Schrödinger equation for a simple harmonic oscillating potential in terms of new variables,,"Show that the time-independent Schrödinger equation for a simple harmonic oscillating potential  $$-\frac{\hbar^2}{2m}\frac{d^2 u}{dx^2}+\frac12 m\,\omega_0^2 x^2u=E\,u$$ can be written as  $$\frac{d^2u}{dy^2}+(\alpha - y^2)u=0\tag{1}$$ where $$y=\sqrt{\frac{m\,\omega_0}{\hbar}}x$$ and $$\alpha=\frac{2E}{\hbar\,\omega_0}$$ So by my logic $$\frac{dy}{dx}=\sqrt{\frac{m\,\omega_0}{\hbar}}$$ and  $$\frac{d^2y}{dx^2}=0$$ clearly something has gone wrong or I am going about this the wrong way. My lecturer mentioned in the lecture that: From $$y=\sqrt{\frac{m\,\omega_0}{\hbar}}x\tag{2}$$ it follows that $$\fbox{$\frac{d}{dx}=\sqrt{\frac{m\,\omega_0}{\hbar}}\frac{d}{dy}$}\tag{3}$$ But how does $(3)$ follow from $(2)$? I know that the boxed equation $(3)$ is correct as I have checked the printed notes for that lecture (for which the relevant parts are shown below): But that's just the first problem; even if I understood how obtain $(3)$, I still don't understand how to proceed to derive $(1)$. The only thing I could think to do is take the second derivative of $(3)$ with respect to $x$ such that $$\frac{d}{dx}\frac{d}{dx}=\frac{d^2}{dx^2}=\frac{d}{dx}\sqrt{\frac{m\,\omega_0}{\hbar}}\frac{d}{dy}$$ and once again I am left confused as this approach doesn't appear to be getting me any closer to deriving $(1)$. I don't doubt that I am likely missing something very simple here, but at the moment I have no idea what that is. Could someone please provide me with some hints or advice on how to derive $(1)$ and what operations where carried out to obtain $(3)$? Kindest regards.","Show that the time-independent Schrödinger equation for a simple harmonic oscillating potential  $$-\frac{\hbar^2}{2m}\frac{d^2 u}{dx^2}+\frac12 m\,\omega_0^2 x^2u=E\,u$$ can be written as  $$\frac{d^2u}{dy^2}+(\alpha - y^2)u=0\tag{1}$$ where $$y=\sqrt{\frac{m\,\omega_0}{\hbar}}x$$ and $$\alpha=\frac{2E}{\hbar\,\omega_0}$$ So by my logic $$\frac{dy}{dx}=\sqrt{\frac{m\,\omega_0}{\hbar}}$$ and  $$\frac{d^2y}{dx^2}=0$$ clearly something has gone wrong or I am going about this the wrong way. My lecturer mentioned in the lecture that: From $$y=\sqrt{\frac{m\,\omega_0}{\hbar}}x\tag{2}$$ it follows that $$\fbox{$\frac{d}{dx}=\sqrt{\frac{m\,\omega_0}{\hbar}}\frac{d}{dy}$}\tag{3}$$ But how does $(3)$ follow from $(2)$? I know that the boxed equation $(3)$ is correct as I have checked the printed notes for that lecture (for which the relevant parts are shown below): But that's just the first problem; even if I understood how obtain $(3)$, I still don't understand how to proceed to derive $(1)$. The only thing I could think to do is take the second derivative of $(3)$ with respect to $x$ such that $$\frac{d}{dx}\frac{d}{dx}=\frac{d^2}{dx^2}=\frac{d}{dx}\sqrt{\frac{m\,\omega_0}{\hbar}}\frac{d}{dy}$$ and once again I am left confused as this approach doesn't appear to be getting me any closer to deriving $(1)$. I don't doubt that I am likely missing something very simple here, but at the moment I have no idea what that is. Could someone please provide me with some hints or advice on how to derive $(1)$ and what operations where carried out to obtain $(3)$? Kindest regards.",,"['derivatives', 'proof-explanation', 'harmonic-functions', 'chain-rule']"
77,Rate of Evaporation of a Vase,Rate of Evaporation of a Vase,,"The base of a vase is created by rotating the curve $$f(x)=2.393794315((1.25916975182872)\left(\frac{x}{2.24581}\right)^4+(-4.29578020022745)(\frac{x}{2.24581})^3+(4.37766951188496)(\frac{x}{2.24581})^2+(-0.553610482668319)(\frac{x}{2.24581})+(-1.6343566433531))$$ ...defined in the domain { ${0.224581\le x\le 2.919553}$ }, rotated $2\pi$ radians about the x-axis. The units of the coordinate axes are in centimetres. My goal is to find the time it takes when the base of the vase is completely filled with water to evaporate. Through some basic evaporation equations from thermodynamics, I have discovered that: $$\frac{dV}{dt}=-2.55\cdot Exposed\ Surface\ Area$$ As the curve above is being revolved around the x-axis, it is obvious that: $$Exposed\ Surface\ Area=\pi \cdot (f(x))^2$$ However, this is as far as I've been able to go. In a worked example I saw, the rate of change in volume ( $\frac{dV}{dt}$ ) was linked to the volume in the container remaining, and then the total volume of the vase was plugged in to solve the differential equation for time. Here it is: SOLUTION Please help me proceed. Any help will be greatly appreciated, thank you in advance.","The base of a vase is created by rotating the curve ...defined in the domain { }, rotated radians about the x-axis. The units of the coordinate axes are in centimetres. My goal is to find the time it takes when the base of the vase is completely filled with water to evaporate. Through some basic evaporation equations from thermodynamics, I have discovered that: As the curve above is being revolved around the x-axis, it is obvious that: However, this is as far as I've been able to go. In a worked example I saw, the rate of change in volume ( ) was linked to the volume in the container remaining, and then the total volume of the vase was plugged in to solve the differential equation for time. Here it is: SOLUTION Please help me proceed. Any help will be greatly appreciated, thank you in advance.",f(x)=2.393794315((1.25916975182872)\left(\frac{x}{2.24581}\right)^4+(-4.29578020022745)(\frac{x}{2.24581})^3+(4.37766951188496)(\frac{x}{2.24581})^2+(-0.553610482668319)(\frac{x}{2.24581})+(-1.6343566433531)) {0.224581\le x\le 2.919553} 2\pi \frac{dV}{dt}=-2.55\cdot Exposed\ Surface\ Area Exposed\ Surface\ Area=\pi \cdot (f(x))^2 \frac{dV}{dt},"['integration', 'derivatives']"
78,"Let $n \in \mathbb N$ and $a,b \in \mathbb R$. Prove or disprove that $x^n+ax+b=0$ has no more than 3 solutions.",Let  and . Prove or disprove that  has no more than 3 solutions.,"n \in \mathbb N a,b \in \mathbb R x^n+ax+b=0","Let $n \in \mathbb N$ and $a,b \in \mathbb R$ . Prove or disprove that $x^n+ax+b=0$ has no more than 3 solutions. I believe this statement is true. Let's set $f(x)=x^n+ax+b$ and since it's a polynomial, it's continuous and differentiable. $$f'(x)=nx^{n-1}+a$$ $$f''(x)=n(n-1)x^{n-2}$$ My thoughts: I believe that if the polynomial has n solutions, then the first derivative has at most n-1 solutions, second has at most n-2 and so on. Since our second derivative has 1 solution, and our second derivative has 1 solution as well, then that means we have have at most 3 solutions. I feel that this train of thought isn't rigorous enough for a proof.","Let and . Prove or disprove that has no more than 3 solutions. I believe this statement is true. Let's set and since it's a polynomial, it's continuous and differentiable. My thoughts: I believe that if the polynomial has n solutions, then the first derivative has at most n-1 solutions, second has at most n-2 and so on. Since our second derivative has 1 solution, and our second derivative has 1 solution as well, then that means we have have at most 3 solutions. I feel that this train of thought isn't rigorous enough for a proof.","n \in \mathbb N a,b \in \mathbb R x^n+ax+b=0 f(x)=x^n+ax+b f'(x)=nx^{n-1}+a f''(x)=n(n-1)x^{n-2}","['calculus', 'derivatives', 'polynomials', 'roots']"
79,Compute $\frac{d^ny}{dx^n}$ if $y = \frac{7}{1-x}$,Compute  if,\frac{d^ny}{dx^n} y = \frac{7}{1-x},"I am wondering what is $\frac{d^n}{dx^n}$ if $y = \frac{7}{1-x}$ Basically, I understand that this asks for a formula to calculate any derivative of f(x) (correct me if I'm wrong). Is that related to Talylor's theory? How do I end up with such a formula? Thanks!","I am wondering what is $\frac{d^n}{dx^n}$ if $y = \frac{7}{1-x}$ Basically, I understand that this asks for a formula to calculate any derivative of f(x) (correct me if I'm wrong). Is that related to Talylor's theory? How do I end up with such a formula? Thanks!",,"['calculus', 'derivatives', 'taylor-expansion']"
80,Derivative definition,Derivative definition,,"Hey I have 2 derivative definition which were told in class. First one is  $ \underset{x\rightarrow a}{\lim}\frac{f(x)-f(a)}{x-a} = f'(a) $  This on is pretty straight forward for me. The second one is  $ \underset{h\rightarrow0}{\lim}\frac{f(x_{0}+h)-f(x_{0}-h)}{2h} = f'(x_0)$ this one however isn't clear enough. The explanation involved something like $\frac{f(x_{0}+h)-f(x_{0}-h)}{h}=\frac{f(x_{0}+h)-f(x_{0})}{h}+\frac{f(x_{0}-h)-f(x_{0})}{-h};$ And $\underset{h\rightarrow0}{\lim}\frac{f(x_{0}+h)-f(x_{0})}{h}=\underset{h\rightarrow0}{\lim}\frac{f(x_{0}-h)-f(x_{0})}{-h}=f'(x_{0});$  (this one is pretty clear to me it's like to substitute $h=x-x_{0}$ Then $\frac{f(x_{0}+h)-f(x_{0}-h)}{2h}=\frac{1}{2}\left(\frac{f(x_{0}+h)-f(x_{0})}{h}+\frac{f(x_{0}-h)-f(x_{0})}{-h}\right)=\frac{1}{2}(2f'(x_{0})=f'(x_{0})$ Now a question in my homework is to express the following expression in terms of $f'(x)$ The expression is : $$\underset{h\rightarrow0}{\lim}\frac{f(x_{0}-2h)-f(x_{0}+3h)}{h}$$ Then I try work the expression and get $\frac{f(x_{0}-2h)-f(x_{0}+3h)}{h}=\frac{f(x_{0}-2h)-f(x_{0})}{h}+\frac{f(x_{0}+3h)-f(x_{0})}{-h}$ Now, is it correct that  $\underset{h\rightarrow0}{\lim}\frac{f(x_{0}-2h)-f(x_{0})}{h}=\underset{h\rightarrow0}{\lim}\frac{f(x_{0}+3h)-f(x_{0})}{-h}=f'(x)  $   ? if yes my expression is simply  $2f'(x_0)$  however I am not sure and will appreciate some explanation.","Hey I have 2 derivative definition which were told in class. First one is  $ \underset{x\rightarrow a}{\lim}\frac{f(x)-f(a)}{x-a} = f'(a) $  This on is pretty straight forward for me. The second one is  $ \underset{h\rightarrow0}{\lim}\frac{f(x_{0}+h)-f(x_{0}-h)}{2h} = f'(x_0)$ this one however isn't clear enough. The explanation involved something like $\frac{f(x_{0}+h)-f(x_{0}-h)}{h}=\frac{f(x_{0}+h)-f(x_{0})}{h}+\frac{f(x_{0}-h)-f(x_{0})}{-h};$ And $\underset{h\rightarrow0}{\lim}\frac{f(x_{0}+h)-f(x_{0})}{h}=\underset{h\rightarrow0}{\lim}\frac{f(x_{0}-h)-f(x_{0})}{-h}=f'(x_{0});$  (this one is pretty clear to me it's like to substitute $h=x-x_{0}$ Then $\frac{f(x_{0}+h)-f(x_{0}-h)}{2h}=\frac{1}{2}\left(\frac{f(x_{0}+h)-f(x_{0})}{h}+\frac{f(x_{0}-h)-f(x_{0})}{-h}\right)=\frac{1}{2}(2f'(x_{0})=f'(x_{0})$ Now a question in my homework is to express the following expression in terms of $f'(x)$ The expression is : $$\underset{h\rightarrow0}{\lim}\frac{f(x_{0}-2h)-f(x_{0}+3h)}{h}$$ Then I try work the expression and get $\frac{f(x_{0}-2h)-f(x_{0}+3h)}{h}=\frac{f(x_{0}-2h)-f(x_{0})}{h}+\frac{f(x_{0}+3h)-f(x_{0})}{-h}$ Now, is it correct that  $\underset{h\rightarrow0}{\lim}\frac{f(x_{0}-2h)-f(x_{0})}{h}=\underset{h\rightarrow0}{\lim}\frac{f(x_{0}+3h)-f(x_{0})}{-h}=f'(x)  $   ? if yes my expression is simply  $2f'(x_0)$  however I am not sure and will appreciate some explanation.",,"['calculus', 'derivatives']"
81,Finding a derivative given certain conditions.,Finding a derivative given certain conditions.,,"Find $f'(0)$ if $f$ is a function such that $$1+f(x)+x^2(f(x))^3=11 \hspace{1cm}\text{and}\hspace{1cm}f(1)=2.$$ Here's what I've tried so far: If $f$ is differentiable around $0$, then the product $x^2f(x)^3$ is zero, such that differentiating, \begin{align*} 	1+f(x)+x^2(f(x))^3 &= 11\\ 	0 + f'(x)+[2xf(x)^3+3x^2f(x)^2f'(x)] &= 0\\ 	f'(x)[1+3x^2f(x)^2] &= -2xf(x)^3\\ 	f'(x) &= -\frac{2xf(x)^3}{1+3x^2f(x)^2} \end{align*}  so $f'(0) = -0/1$. I don't think this is correct though, I don't see why $f(1)=2$ is a relevant fact, or maybe I have to use some theorem instead of isolating $f'(x)$. Anyway, any help or maybe a hint would be greatly appreciated. Thanks.","Find $f'(0)$ if $f$ is a function such that $$1+f(x)+x^2(f(x))^3=11 \hspace{1cm}\text{and}\hspace{1cm}f(1)=2.$$ Here's what I've tried so far: If $f$ is differentiable around $0$, then the product $x^2f(x)^3$ is zero, such that differentiating, \begin{align*} 	1+f(x)+x^2(f(x))^3 &= 11\\ 	0 + f'(x)+[2xf(x)^3+3x^2f(x)^2f'(x)] &= 0\\ 	f'(x)[1+3x^2f(x)^2] &= -2xf(x)^3\\ 	f'(x) &= -\frac{2xf(x)^3}{1+3x^2f(x)^2} \end{align*}  so $f'(0) = -0/1$. I don't think this is correct though, I don't see why $f(1)=2$ is a relevant fact, or maybe I have to use some theorem instead of isolating $f'(x)$. Anyway, any help or maybe a hint would be greatly appreciated. Thanks.",,"['calculus', 'derivatives']"
82,"If $\sqrt{1-x^2}+\sqrt{1-y^2}=a(x-y)$, then what is $\frac{dy}{dx}$?","If , then what is ?",\sqrt{1-x^2}+\sqrt{1-y^2}=a(x-y) \frac{dy}{dx},"The question states: If $\sqrt{1-x^2}+\sqrt{1-y^2}=a(x-y)$, then what is $\frac{dy}{dx}$? The options are: $$\sqrt{\frac{1-x^2}{1-y^2}}$$ $$\sqrt{\frac{1-y^2}{1-x^2}}$$ $$\frac{1-x^2}{1-y^2}$$ $$\frac{1-y^2}{1-x^2}$$ I tried differentiating the entire expression: $$\begin{align} \frac{-2x}{2\sqrt{1-x^2}}+\frac{-2y}{2\sqrt{1-y^2}}\frac{dy}{dx} &= a(1-\frac{dy}{dx}) \\ a + \frac{x}{\sqrt{1-x^2}} &= \frac{dy}{dx}(a-\frac{y}{\sqrt{1-y^2}}) \\ \frac{dy}{dx} &= (a+\frac{x}{\sqrt{1-x^2}})(a-\frac{y}{\sqrt{1-y^2}})^{-1} \end{align}$$ I am not sure how to proceed now. Is there a better approach? Is it advisable to use my approach?","The question states: If $\sqrt{1-x^2}+\sqrt{1-y^2}=a(x-y)$, then what is $\frac{dy}{dx}$? The options are: $$\sqrt{\frac{1-x^2}{1-y^2}}$$ $$\sqrt{\frac{1-y^2}{1-x^2}}$$ $$\frac{1-x^2}{1-y^2}$$ $$\frac{1-y^2}{1-x^2}$$ I tried differentiating the entire expression: $$\begin{align} \frac{-2x}{2\sqrt{1-x^2}}+\frac{-2y}{2\sqrt{1-y^2}}\frac{dy}{dx} &= a(1-\frac{dy}{dx}) \\ a + \frac{x}{\sqrt{1-x^2}} &= \frac{dy}{dx}(a-\frac{y}{\sqrt{1-y^2}}) \\ \frac{dy}{dx} &= (a+\frac{x}{\sqrt{1-x^2}})(a-\frac{y}{\sqrt{1-y^2}})^{-1} \end{align}$$ I am not sure how to proceed now. Is there a better approach? Is it advisable to use my approach?",,"['calculus', 'derivatives']"
83,$n^{th}$ derivative of $y=x^2\cos x$,derivative of,n^{th} y=x^2\cos x,"I am stuck with Leibniz formula $$D^{n}y = \sum_{k=0}^{n} \binom{n}{k} \, x^{(2k)}\cos^{(n-k)}x$$ Could someone show how to do it?","I am stuck with Leibniz formula $$D^{n}y = \sum_{k=0}^{n} \binom{n}{k} \, x^{(2k)}\cos^{(n-k)}x$$ Could someone show how to do it?",,"['calculus', 'derivatives']"
84,"Let $f(x)$ be differentiable at $\mathbb R$, s.t $|f^\prime (x)| \le 6$ . Its given that $f(1)=20$, and $f(9)=68$ , prove that $f(7)=56$.","Let  be differentiable at , s.t  . Its given that , and  , prove that .",f(x) \mathbb R |f^\prime (x)| \le 6 f(1)=20 f(9)=68 f(7)=56,"Let $f(x)$ be differentiable ate $\mathbb R$, s.t $|f^\prime (x)| \le 6$ for every $x$ in $\mathbb R$. its given also that $f(1)=20$, and $f(9)=68$ , prove that $f(7)=56$. I'm thinking about applying  $\text{Mean Value theorem}$ and $\text{Intermediate Value theorem}$, in here but for some reason I miss something and I can't conclude that $f(7)=56$. any kind of help would be appreciated.","Let $f(x)$ be differentiable ate $\mathbb R$, s.t $|f^\prime (x)| \le 6$ for every $x$ in $\mathbb R$. its given also that $f(1)=20$, and $f(9)=68$ , prove that $f(7)=56$. I'm thinking about applying  $\text{Mean Value theorem}$ and $\text{Intermediate Value theorem}$, in here but for some reason I miss something and I can't conclude that $f(7)=56$. any kind of help would be appreciated.",,"['calculus', 'derivatives']"
85,In terms of units: is integration equal to multiplication and differentiation equal to division as a general rule?,In terms of units: is integration equal to multiplication and differentiation equal to division as a general rule?,,"The question From practical experience, I know that the unit of an integral - resulting from integration of an expression with respect to a variable with a unit (i.e. non-dimensionless variable) - is the same as if the expression and the variable were multiplied. Similarly, the unit of a derivative - resulting from differentiation of an expression with respect to a variable with a unit (i.e. non-dimensionless variable) - is the same as if the expression was divided by the variable. This makes sense to me, and I have never really thought about it before. The question is: can this fact be regarded as a general (mathematical) rule? If yes; is it possible to give a compelling, rigorous and yet simple argument for this fact? If not; are there any good examples to illustrate why this may not be a general fact? An example When calculating the distance travelled as an integral of velocity with respect to time, the units are the same as when multiplying the two quantities. $$ \int v \, \mathrm{d}t = s $$ $$ [\mathrm{m}/\mathrm{s}][\mathrm{s}] = [\mathrm{m}]$$ In thermodynamics, when calculating the entropy as a partial derivative of the internal energy with respect to temperature, the units are the same as when dividing the former quantity by the latter. $$ \left(\frac{\partial{U}}{\partial{T}}\right)_{V,\mathbf{n}} = S $$ $$ \frac{[\mathrm{J}]}{[\mathrm{K}]} = \frac{[\mathrm{J}]}{[\mathrm{K}]}$$ Disclaimer This is probably a rather trivial question, and a strongly suspect that the answer is yes based on the relationship between the operations. However, I would love to get a proper answer based on sound mathematical arguments. Any helpful suggestions or hints are greatly appreciated!","The question From practical experience, I know that the unit of an integral - resulting from integration of an expression with respect to a variable with a unit (i.e. non-dimensionless variable) - is the same as if the expression and the variable were multiplied. Similarly, the unit of a derivative - resulting from differentiation of an expression with respect to a variable with a unit (i.e. non-dimensionless variable) - is the same as if the expression was divided by the variable. This makes sense to me, and I have never really thought about it before. The question is: can this fact be regarded as a general (mathematical) rule? If yes; is it possible to give a compelling, rigorous and yet simple argument for this fact? If not; are there any good examples to illustrate why this may not be a general fact? An example When calculating the distance travelled as an integral of velocity with respect to time, the units are the same as when multiplying the two quantities. $$ \int v \, \mathrm{d}t = s $$ $$ [\mathrm{m}/\mathrm{s}][\mathrm{s}] = [\mathrm{m}]$$ In thermodynamics, when calculating the entropy as a partial derivative of the internal energy with respect to temperature, the units are the same as when dividing the former quantity by the latter. $$ \left(\frac{\partial{U}}{\partial{T}}\right)_{V,\mathbf{n}} = S $$ $$ \frac{[\mathrm{J}]}{[\mathrm{K}]} = \frac{[\mathrm{J}]}{[\mathrm{K}]}$$ Disclaimer This is probably a rather trivial question, and a strongly suspect that the answer is yes based on the relationship between the operations. However, I would love to get a proper answer based on sound mathematical arguments. Any helpful suggestions or hints are greatly appreciated!",,"['integration', 'derivatives', 'unit-of-measure']"
86,Does a bounded function converge if its derivative tends to zero?,Does a bounded function converge if its derivative tends to zero?,,Suppose we have function $f:\Bbb R^+\to\Bbb R$ that is bounded $|f(t)|<M$ and differentiable such that $\lim\limits_{t\to\infty}f'(t) = 0$ . Does this imply that $f(t)$ converges?,Suppose we have function that is bounded and differentiable such that . Does this imply that converges?,f:\Bbb R^+\to\Bbb R |f(t)|<M \lim\limits_{t\to\infty}f'(t) = 0 f(t),"['real-analysis', 'derivatives']"
87,Why is Implicit Differentiation needed for Derivative of $y = \arcsin (2x+1)$?,Why is Implicit Differentiation needed for Derivative of ?,y = \arcsin (2x+1),"my function is: $y = \arcsin (2x+1)$ and I want to find its derivative. My approach was to apply the chain rule: $$y' = \frac{dg}{du} \frac{du}{dx}$$ with $g = \arcsin(u)$ and $u = 2x+1$. $$g' = \frac{1}{\sqrt{1-u^2}}.$$ ${u}' = 2$. My solution therefore was $$\frac{1}{\sqrt{1-u^2}} \cdot 2 = \frac{2}{\sqrt{1-(2x+1)^2}}.$$ This seems to be wrong and the correct solution is given by:  $\frac{1}{\sqrt{-x^{2}-x}}$ I know that implicit differentiation should be used for this particular problem, but I do not really understand why. I appreciate any help!","my function is: $y = \arcsin (2x+1)$ and I want to find its derivative. My approach was to apply the chain rule: $$y' = \frac{dg}{du} \frac{du}{dx}$$ with $g = \arcsin(u)$ and $u = 2x+1$. $$g' = \frac{1}{\sqrt{1-u^2}}.$$ ${u}' = 2$. My solution therefore was $$\frac{1}{\sqrt{1-u^2}} \cdot 2 = \frac{2}{\sqrt{1-(2x+1)^2}}.$$ This seems to be wrong and the correct solution is given by:  $\frac{1}{\sqrt{-x^{2}-x}}$ I know that implicit differentiation should be used for this particular problem, but I do not really understand why. I appreciate any help!",,"['trigonometry', 'derivatives', 'implicit-differentiation']"
88,Prove that $f(c)=\frac12(c-a)(c-b)f''(\xi)$,Prove that,f(c)=\frac12(c-a)(c-b)f''(\xi),"A function $f:[a,b] \rightarrow \mathbb R$ is continuous on $[a,b]$ and $f''(x)$ exists $\forall x\in (a,b)$. If $a<c<b$ and $f(a)=f(b)=0$, prove that there exists a point $\xi$ in $(a,b)$ such that $f(c)=\frac12(c-a)(c-b)f''(\xi)$ My attempt: using Lagrange's Mean Value Theorem on $f$ in $[a,c]$ and $[c,b]$, $\exists \xi_1 \in (a,c)$ and $\exists \xi_2 \in (c,b)$ such that $f'(\xi_1)=\frac{f(c)-f(a)}{c-a}=\frac{f(c)}{c-a}$ and $f'(\xi_2)=\frac{f(b)-f(c)}{b-c}=\frac{-f(c)}{b-c}$ This is where I'm stuck. I tried applying MVT again, but it didn't lead me anywhere. I tried using Rolle's Theorem or Darboux Theorem but it only gave me a $f''(\xi_n)=0$. Can someone please tell me what to do next?","A function $f:[a,b] \rightarrow \mathbb R$ is continuous on $[a,b]$ and $f''(x)$ exists $\forall x\in (a,b)$. If $a<c<b$ and $f(a)=f(b)=0$, prove that there exists a point $\xi$ in $(a,b)$ such that $f(c)=\frac12(c-a)(c-b)f''(\xi)$ My attempt: using Lagrange's Mean Value Theorem on $f$ in $[a,c]$ and $[c,b]$, $\exists \xi_1 \in (a,c)$ and $\exists \xi_2 \in (c,b)$ such that $f'(\xi_1)=\frac{f(c)-f(a)}{c-a}=\frac{f(c)}{c-a}$ and $f'(\xi_2)=\frac{f(b)-f(c)}{b-c}=\frac{-f(c)}{b-c}$ This is where I'm stuck. I tried applying MVT again, but it didn't lead me anywhere. I tried using Rolle's Theorem or Darboux Theorem but it only gave me a $f''(\xi_n)=0$. Can someone please tell me what to do next?",,['derivatives']
89,Continuous function with continuous one-sided derivative,Continuous function with continuous one-sided derivative,,"Simple example of the absolute value function $x \mapsto |x|$ on $\mathbb{R}$ shows that it is possible for a continuous function to posses both the right-hand and the left-hand side derivatives and still not being differentiable on $\mathbb{R}$. I was wondering if it is possible to assume something about one of the one-hand side derivatives to obtain differentiability. The obvious came to my mind: Is it true that if a continuous function $f \in C(\mathbb{R})$ has left-hand-side derivative $f_{-}^{'}$ that is continuous on $\mathbb{R}$, then the function $f$ is differentiable?","Simple example of the absolute value function $x \mapsto |x|$ on $\mathbb{R}$ shows that it is possible for a continuous function to posses both the right-hand and the left-hand side derivatives and still not being differentiable on $\mathbb{R}$. I was wondering if it is possible to assume something about one of the one-hand side derivatives to obtain differentiability. The obvious came to my mind: Is it true that if a continuous function $f \in C(\mathbb{R})$ has left-hand-side derivative $f_{-}^{'}$ that is continuous on $\mathbb{R}$, then the function $f$ is differentiable?",,"['real-analysis', 'derivatives', 'continuity']"
90,Minimizing an error function by deriving a system of linear equations,Minimizing an error function by deriving a system of linear equations,,"Consider the following formula: $$E(\mathbf{w}) = \frac{1}{2}\sum_{n=1}^{N}\{y(x_n,\mathbf{w})-t_n\}^2$$ where $\mathbf{w}$ is a vector of weights; $x_n$ and $t_n$ come from two vectors of length $N$; and $y$ is a polynomial: $$y(x,\mathbf{w}) = \sum_{j=0}^M w_jx^j$$ My task is to show a system of equations which yield weights $\mathbf{w} = \{w_i\}$ that minimize E. I reckoned I should differentiate and set the derivative to 0: $$ \frac{dE}{dw} = \sum_{n=1}^{N}\{y(x_n,\mathbf{w})-t_n\}\times\frac{dy}{dw}$$ $$ \frac{dE}{dw} = \sum_{n=1}^{N}\{y(x_n,\mathbf{w})-t_n\}\times\sum_{i=0}^{M}x_n^j$$ $$\sum_{n=1}^{N}\{\sum_{j=0}^{M}w_jx_n^j-t_n\}\times\sum_{i=0}^{M}x_n^j = 0$$ The solution says to do what I did, except differentiate ""with respect to $w_i$"". It offers the following expression: $$\sum_{n=1}^{N}(\sum_{j=0}^{M}w_jx_n^j-t_n) x_n^i = 0$$ I take it that each $i$ yields another equation, hence this approach leading to a system of equations. There are two things I don't understand: Why is there not a summation over the $x_n^i$ values at the end? I thought differentiating $y$ would remove the weights but retain the summation. The inner summation uses a $j$ though the outer uses a $i$. Why are they not the same symbol? Though I know if they were both $j$ we would be left with just one equation, I don't understand how they can be different.","Consider the following formula: $$E(\mathbf{w}) = \frac{1}{2}\sum_{n=1}^{N}\{y(x_n,\mathbf{w})-t_n\}^2$$ where $\mathbf{w}$ is a vector of weights; $x_n$ and $t_n$ come from two vectors of length $N$; and $y$ is a polynomial: $$y(x,\mathbf{w}) = \sum_{j=0}^M w_jx^j$$ My task is to show a system of equations which yield weights $\mathbf{w} = \{w_i\}$ that minimize E. I reckoned I should differentiate and set the derivative to 0: $$ \frac{dE}{dw} = \sum_{n=1}^{N}\{y(x_n,\mathbf{w})-t_n\}\times\frac{dy}{dw}$$ $$ \frac{dE}{dw} = \sum_{n=1}^{N}\{y(x_n,\mathbf{w})-t_n\}\times\sum_{i=0}^{M}x_n^j$$ $$\sum_{n=1}^{N}\{\sum_{j=0}^{M}w_jx_n^j-t_n\}\times\sum_{i=0}^{M}x_n^j = 0$$ The solution says to do what I did, except differentiate ""with respect to $w_i$"". It offers the following expression: $$\sum_{n=1}^{N}(\sum_{j=0}^{M}w_jx_n^j-t_n) x_n^i = 0$$ I take it that each $i$ yields another equation, hence this approach leading to a system of equations. There are two things I don't understand: Why is there not a summation over the $x_n^i$ values at the end? I thought differentiating $y$ would remove the weights but retain the summation. The inner summation uses a $j$ though the outer uses a $i$. Why are they not the same symbol? Though I know if they were both $j$ we would be left with just one equation, I don't understand how they can be different.",,"['linear-algebra', 'derivatives', 'error-function']"
91,How do we know when two curves touch each other?,How do we know when two curves touch each other?,,"What are the conditions of two curves touching each other? A necessary condition for this is that the derivative for both the curves should be the same at the point of intersection. But that doesn't seem to be sufficient, as in the case of $y = x^3$ and $y=x^5$, both of which have the same derivative at x = 0, but they are intersecting or crossing each other. Does it have something to do with point of inflection? I'm unable to arrive at the conditions precisely.","What are the conditions of two curves touching each other? A necessary condition for this is that the derivative for both the curves should be the same at the point of intersection. But that doesn't seem to be sufficient, as in the case of $y = x^3$ and $y=x^5$, both of which have the same derivative at x = 0, but they are intersecting or crossing each other. Does it have something to do with point of inflection? I'm unable to arrive at the conditions precisely.",,['derivatives']
92,Worst case examples of non-differentiability of the Riemannian distance function,Worst case examples of non-differentiability of the Riemannian distance function,,"Let $g$ be a $C^\infty$ Riemannian metric on the plane, and let $p$ be a point on the plane. Let $X$ be the set of points $x$ at which the Riemannian distance $d(p,x)$ is not differentiable. How bad can $X$ be? Rademacher proved that a Lipschitz function is differentiable almost everywhere. So $X$ has to have measure zero. Can $\overline X$, the closure of $X$, have non-empty interior?","Let $g$ be a $C^\infty$ Riemannian metric on the plane, and let $p$ be a point on the plane. Let $X$ be the set of points $x$ at which the Riemannian distance $d(p,x)$ is not differentiable. How bad can $X$ be? Rademacher proved that a Lipschitz function is differentiable almost everywhere. So $X$ has to have measure zero. Can $\overline X$, the closure of $X$, have non-empty interior?",,"['derivatives', 'riemannian-geometry']"
93,"If $f$ and $g$ satisfy the sine/cosine addition formulae, then what is $g'(0)$?","If  and  satisfy the sine/cosine addition formulae, then what is ?",f g g'(0),"The question is: Question. Let $f,g:\mathbb R\to\mathbb R$ be two functions that satisfy $$f(x-y)=f(x)\cdot g(y)-f(y)\cdot g(x)$$ and $$g(x-y)=g(x)\cdot g(y)+f(x)\cdot f(y)$$ for all $x,y \in \mathbb{R} $ . If the right hand derivative at $x=0$ exists for $f(x)$ , then what is $g'(0)$ ? My try: By some simple substitutions I figured out that $f(0)=0$ and $g(0)=1$ . If in the second equation, we put $x=y$ , it will give $g(0)=(g(x))^2+(f(x))^2$ . If $g(0)=0$ , sum of the two squares becomes $0$ which implies the squares themselves are zero, I neglected $g(x)=f(x)=0$ as a trivial solution and hence took $g(0)=1$ . But how do I proceed after this?","The question is: Question. Let be two functions that satisfy and for all . If the right hand derivative at exists for , then what is ? My try: By some simple substitutions I figured out that and . If in the second equation, we put , it will give . If , sum of the two squares becomes which implies the squares themselves are zero, I neglected as a trivial solution and hence took . But how do I proceed after this?","f,g:\mathbb R\to\mathbb R f(x-y)=f(x)\cdot g(y)-f(y)\cdot g(x) g(x-y)=g(x)\cdot g(y)+f(x)\cdot f(y) x,y \in \mathbb{R}  x=0 f(x) g'(0) f(0)=0 g(0)=1 x=y g(0)=(g(x))^2+(f(x))^2 g(0)=0 0 g(x)=f(x)=0 g(0)=1","['derivatives', 'functional-equations']"
94,How to prove that f is one-to-one [duplicate],How to prove that f is one-to-one [duplicate],,This question already has answers here : For what values will f(x) be necessarily one-one? (3 answers) Closed 10 years ago . Let $g\colon \mathbb{R} → \mathbb{R}$ be differentiable with bounded derivative. i.e. $|g'(x)| < M$ for all $x ∈ \mathbb{R}$. Let $\epsilon$ be a positive number satisfying $0 < \epsilon < 1/M$. Let $f(x) = x+\epsilon g(x)$. How can I prove that $f$ is one-to-one (injective)? I really have no idea how to solve hint. Any hint would be appreciated. Thank you :),This question already has answers here : For what values will f(x) be necessarily one-one? (3 answers) Closed 10 years ago . Let $g\colon \mathbb{R} → \mathbb{R}$ be differentiable with bounded derivative. i.e. $|g'(x)| < M$ for all $x ∈ \mathbb{R}$. Let $\epsilon$ be a positive number satisfying $0 < \epsilon < 1/M$. Let $f(x) = x+\epsilon g(x)$. How can I prove that $f$ is one-to-one (injective)? I really have no idea how to solve hint. Any hint would be appreciated. Thank you :),,"['real-analysis', 'derivatives']"
95,Maple: assign derivative to function,Maple: assign derivative to function,,"This is probably a basic Maple question.  I'm trying to introduce $g$ as the derivative of $f$: Somewhat puzzling, Maple now says $g$ is two times the function $x()$. I've tried g := x -> diff(f(x),x) and g := diff(f,x) , but no luck. Google tells me I can use subs(x=3,g) to evaluate the derivative at $x=3$, but that's not very practical. Is there a way to define a Maple function as the derivative of another Maple function?","This is probably a basic Maple question.  I'm trying to introduce $g$ as the derivative of $f$: Somewhat puzzling, Maple now says $g$ is two times the function $x()$. I've tried g := x -> diff(f(x),x) and g := diff(f,x) , but no luck. Google tells me I can use subs(x=3,g) to evaluate the derivative at $x=3$, but that's not very practical. Is there a way to define a Maple function as the derivative of another Maple function?",,"['derivatives', 'maple']"
96,Why does substitution work in integrals,Why does substitution work in integrals,,"Let's say I have this integral: $$\int_0^\infty e^{-t} \, dt$$ And I make the substitution: $$t = nu$$ Then why I can say that: $$dt = n\,du$$ and then put this into my integral like this: $$\int_0^\infty e^{-nu}n\,du$$ What's happening in the background that allow this to be done? I'm asking this because I don't feel confortable threating diferencial operators as fractions and I don't know why this can be done.","Let's say I have this integral: $$\int_0^\infty e^{-t} \, dt$$ And I make the substitution: $$t = nu$$ Then why I can say that: $$dt = n\,du$$ and then put this into my integral like this: $$\int_0^\infty e^{-nu}n\,du$$ What's happening in the background that allow this to be done? I'm asking this because I don't feel confortable threating diferencial operators as fractions and I don't know why this can be done.",,"['calculus', 'integration', 'derivatives']"
97,Range of $f(x) = \sin(\cos x)$,Range of,f(x) = \sin(\cos x),Problem : Finding the maximum and minimum value of the function : $f(x) = \sin(\cos x)$ My approach :  We know that if $f'(x) > 0 $ function attain maximum value by putting $f'(x) = 0$ and taking the second derivative test ie. $f''(x) >0$ then function is minimum and if $f''(x) <0$ function is maximum this can be obtained by putting the value of $x$ (derived from $f'(x) =0$) Now the given function is : $f(x) = \sin(\cos x)$ $f'(x) = -\sin x \cos(\cos x) $ How can we do this with the help of calculus?,Problem : Finding the maximum and minimum value of the function : $f(x) = \sin(\cos x)$ My approach :  We know that if $f'(x) > 0 $ function attain maximum value by putting $f'(x) = 0$ and taking the second derivative test ie. $f''(x) >0$ then function is minimum and if $f''(x) <0$ function is maximum this can be obtained by putting the value of $x$ (derived from $f'(x) =0$) Now the given function is : $f(x) = \sin(\cos x)$ $f'(x) = -\sin x \cos(\cos x) $ How can we do this with the help of calculus?,,"['calculus', 'trigonometry', 'derivatives']"
98,Local Maxima in this function,Local Maxima in this function,,"I did the following problem in class $f(x)=x\sqrt{x+2}$ and I needed to find the local maxima. I said the domain was $[-2,\infty)$ and the left end point $(-2,0)$ on the graph is a local maxima because the graph has a negative derivative there, but my instructor said that it was wrong. Why is that end point not a local maxima? Thanks","I did the following problem in class $f(x)=x\sqrt{x+2}$ and I needed to find the local maxima. I said the domain was $[-2,\infty)$ and the left end point $(-2,0)$ on the graph is a local maxima because the graph has a negative derivative there, but my instructor said that it was wrong. Why is that end point not a local maxima? Thanks",,"['calculus', 'derivatives']"
99,The range of the derivative of a differentiable function,The range of the derivative of a differentiable function,,"I read somewhere that, given a function $f$ differentiable on $[a,b]$, the range of $f'$ can be (1) a closed interval or (2) an open interval or (3) a half-open interval or (4) an unbounded interval Can someone give an example for each one ?","I read somewhere that, given a function $f$ differentiable on $[a,b]$, the range of $f'$ can be (1) a closed interval or (2) an open interval or (3) a half-open interval or (4) an unbounded interval Can someone give an example for each one ?",,"['real-analysis', 'derivatives', 'examples-counterexamples']"
