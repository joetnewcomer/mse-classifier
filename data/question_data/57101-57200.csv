,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Finding the sum $f(x)=\sum_{n=2}^{\infty} \frac{x^n}{n(n-1)}$,Finding the sum,f(x)=\sum_{n=2}^{\infty} \frac{x^n}{n(n-1)},"I'm trying to find $$f(x)=\sum_{n=2}^{\infty} \frac{x^n}{n(n-1)}$$ I found the radius of convergence of the above series which is $R=1$. Checking $x=\pm 1$ also yields a convergent series. Therefore the above series converges for all $x\in [-1, 1]$. Using differentiation of the series term by term we get: $$f'(x)=\sum_{n=2}^{\infty} \frac{x^{n-1}}{n-1}=\sum_{n=1}^{\infty} \frac{x^{n}}{n}=-\log(1-x)$$ which also has $R=1$, and then, by integrating term by term we get: $$f(x)=\int_{0}^{x} f'(t)dt=-\int_{0}^{x} \log(1-t)dt=x-(x-1)\ln(1-x)$$ if I understand the theorems in my textbook correctly, the above formulas are true only for $x \in (-1, 1)$. It seems the above is correct since this is also what WolframAlpha says. I'm abit confused though. At first, it seemed the above series converges for all $x\in [-1, 1]$ but in the end I only got $f(x)$ for all $|x|\lt 1$, something seems to be missing. What can I say about $f(-1)$ and $f(1)$?","I'm trying to find $$f(x)=\sum_{n=2}^{\infty} \frac{x^n}{n(n-1)}$$ I found the radius of convergence of the above series which is $R=1$. Checking $x=\pm 1$ also yields a convergent series. Therefore the above series converges for all $x\in [-1, 1]$. Using differentiation of the series term by term we get: $$f'(x)=\sum_{n=2}^{\infty} \frac{x^{n-1}}{n-1}=\sum_{n=1}^{\infty} \frac{x^{n}}{n}=-\log(1-x)$$ which also has $R=1$, and then, by integrating term by term we get: $$f(x)=\int_{0}^{x} f'(t)dt=-\int_{0}^{x} \log(1-t)dt=x-(x-1)\ln(1-x)$$ if I understand the theorems in my textbook correctly, the above formulas are true only for $x \in (-1, 1)$. It seems the above is correct since this is also what WolframAlpha says. I'm abit confused though. At first, it seemed the above series converges for all $x\in [-1, 1]$ but in the end I only got $f(x)$ for all $|x|\lt 1$, something seems to be missing. What can I say about $f(-1)$ and $f(1)$?",,['calculus']
1,Is there an explanation for the patterns formed by the binomial coefficients $\binom{n+d-1}{d}\pmod{512}$?,Is there an explanation for the patterns formed by the binomial coefficients ?,\binom{n+d-1}{d}\pmod{512},"Simplicial sequences generalize the familiar ""linear"", ""triangular"", and ""tetrahedral"" number sequences. (A line segment is a $1$ -simplex, a triangle is a $2$ -simplex, a tetrahedron is a $3$ -simplex, and so on, so I'm calling these simplicial sequences.) In general, the $n$ -th $d$ -simplicial number is the binomial coefficient $\binom{n+d-1}{d}$ . The pictures below graphically show the $n$ -th element $\pmod{512}$ of $512$ simplicial sequences side by side. The white dots in a given frame have coordinates $(d,\binom{n+d-1}{d} \pmod {512})$ , where $d$ runs from $0$ through to $511$ , and the value of $n$ is displayed at the bottom of the diagram. Also, if you are using a ""modern browser"" (i.e. not IE6,7,8), you can see an animation running through all values of $n$ by following this link .  The animation allows you to start and stop, and even save individual frames. If you watch the animation, you'll see that binary visual patterns emerge, in ways that are threaded through the image and increase and decrease in strength.  The images below for $n=5$ and $n=256$ indicate the extremes .. for $n=5$ the points look randomly distributed, for $n=256$ they are strongly patterned. So my question is whether there are any explanations for the emergence and disappearance of visual binary patterns as we iterate through $n$ .","Simplicial sequences generalize the familiar ""linear"", ""triangular"", and ""tetrahedral"" number sequences. (A line segment is a -simplex, a triangle is a -simplex, a tetrahedron is a -simplex, and so on, so I'm calling these simplicial sequences.) In general, the -th -simplicial number is the binomial coefficient . The pictures below graphically show the -th element of simplicial sequences side by side. The white dots in a given frame have coordinates , where runs from through to , and the value of is displayed at the bottom of the diagram. Also, if you are using a ""modern browser"" (i.e. not IE6,7,8), you can see an animation running through all values of by following this link .  The animation allows you to start and stop, and even save individual frames. If you watch the animation, you'll see that binary visual patterns emerge, in ways that are threaded through the image and increase and decrease in strength.  The images below for and indicate the extremes .. for the points look randomly distributed, for they are strongly patterned. So my question is whether there are any explanations for the emergence and disappearance of visual binary patterns as we iterate through .","1 2 3 n d \binom{n+d-1}{d} n \pmod{512} 512 (d,\binom{n+d-1}{d} \pmod {512}) d 0 511 n n n=5 n=256 n=5 n=256 n","['sequences-and-series', 'binomial-coefficients', 'experimental-mathematics']"
2,Understanding the Series Summation: $\alpha+2\alpha^2+3\alpha^3+...=\frac{\alpha}{(\alpha-1)^2}$ [duplicate],Understanding the Series Summation:  [duplicate],\alpha+2\alpha^2+3\alpha^3+...=\frac{\alpha}{(\alpha-1)^2},"This question already has answers here : Formula for the summation of the series $a+2a^2+3a^3+...$ upto nth term? [duplicate] (4 answers) Closed 29 days ago . I've been working on understanding series and their summations, and I came across this particular series: $$\alpha+2\alpha^2+3\alpha^3+...$$ The solution provided states that the sum of this series is $$\frac{\alpha}{(\alpha-1)^2}$$ , but I'm having trouble understanding why this is the case. My Work: I tried to approach this problem by comparing it to the geometric series summation formula, which is $$\frac{a}{1-r}$$ where 'a' is the first term and 'r' is the common ratio. However, I'm not sure how to apply it here since the coefficients of $$\alpha$$ are increasing. Background: I'm currently an undergraduate student taking a course in Calculus II. We've covered sequences and series, including geometric series and the tests for convergence. Definitions: Here, $$\alpha$$ is a real number and the series is presumably infinite. I would appreciate any help or guidance on how to approach this problem. Thank you in advance!","This question already has answers here : Formula for the summation of the series $a+2a^2+3a^3+...$ upto nth term? [duplicate] (4 answers) Closed 29 days ago . I've been working on understanding series and their summations, and I came across this particular series: The solution provided states that the sum of this series is , but I'm having trouble understanding why this is the case. My Work: I tried to approach this problem by comparing it to the geometric series summation formula, which is where 'a' is the first term and 'r' is the common ratio. However, I'm not sure how to apply it here since the coefficients of are increasing. Background: I'm currently an undergraduate student taking a course in Calculus II. We've covered sequences and series, including geometric series and the tests for convergence. Definitions: Here, is a real number and the series is presumably infinite. I would appreciate any help or guidance on how to approach this problem. Thank you in advance!",\alpha+2\alpha^2+3\alpha^3+... \frac{\alpha}{(\alpha-1)^2} \frac{a}{1-r} \alpha \alpha,['sequences-and-series']
3,Asymptotic Behaviour of the Remainder of Certain Alternating Series,Asymptotic Behaviour of the Remainder of Certain Alternating Series,,"Let $a,b >0$ be real constants. Empirical observation (as in: asking WolframAlpha) suggests $$   \lim_{n\to \infty} n \cdot \sum_{k=0}^\infty (\frac{1}{n+ak} - \frac{1}{n+b+ak}) = \frac{b}{a} \tag{$*$}$$ Note that the series in question can be interpreted as the ""remainder"" / ""tail end"" of a (conditionally!) convergent alternating series. To see what is going on, confirm that e.g. ( $a=3, b=1, n=1000$ ) $$1000 \cdot (\frac{1}{1000}-\frac{1}{1001}+\frac{1}{1003}-\frac{1}{1004}+\frac{1}{1006}-\frac{1}{1007} + \dots) \approx \frac{1}{3}$$ Questions: Is there a better proof for $(*)$ than my attempt at the bottom of this question? What references treat estimates for the asymptotic behaviour of ""remainders"" like the above? Would there be finer estimates, after subtracting the above error ""of order $1/n$ "", of order $1/n^2$ , $1/n^3$ , ...? Context : A student challenged me to (show existence of, and) find $$\lim_{n\to \infty} n \cdot \int_0^{\frac{\pi}{4}}\tan^n(x) dx$$ Now the easy and well-known recursive formula $$\int \tan^{n}(x)dx = \frac{1}{n-1}\tan^{n-1}(x) - \int \tan^{n-2}(x) dx$$ gives $$\int_0^{\frac{\pi}{4}}\tan^n(x) dx = \begin{cases} \frac{1}{n-1}-\frac{1}{n-3}+\frac{1}{n-5} - \dots \pm 1\mp \frac{\pi}{4} \text{ if } n \text{ even}\\ \frac{1}{n-1}-\frac{1}{n-3}+\frac{1}{n-5} - \dots \pm \frac{1}{2}\mp \frac{\ln(2)}{2} \text{ if } n \text{ odd}\end{cases}$$ This is a funny case distinction because of course $\frac{\pi}{4} = 1-\frac{1}{3} +\frac{1}{5} \dots $ (Leibniz-Madhava) while $\frac{\ln(2)}{2} = \frac{1}{2}-\frac{1}{4}+\frac{1}{6} -\dots$ , so in both cases , the question becomes to estimate the "" $1/n$ -order"" growth of the ""tail end"" of the series, $$\lim_{n\to \infty} n \cdot (\frac{1}{n+1}-\frac{1}{n+3}+\frac{1}{n+5} \dots)$$ which by a slight adjustment of $(*)$ (for $b=2, a=4$ ) is $\dfrac{1}{2}$ . My own proof idea for $(*)$ : By a standard estimate for convergent alternating series, for $K$ big enough (e.g. $n+aK > n^2$ ) we have $$\sum_{k=0}^\infty (\frac{1}{n+ak} - \frac{1}{n+b+ak}) = \sum_{k=0}^K(\frac{1}{n+ak} - \frac{1}{n+b+ak}) + O \left(\frac{1}{n^2}\right)$$ and now that finite sum can be split up into its positive and negative terms, and we get $$\sum_{k=0}^K \frac{1}{n+ak} - \sum_{k=0}^K \frac{1}{n+b+ak}\\ =\frac{1}{a} \left(\sum_{k=0}^K \frac{1}{\frac{n}{a}+k} - \sum_{k=0}^K \frac{1}{\frac{n+b}{a}+k} \right)\\ \stackrel{**}\approx \frac{1}{a} \left((\ln (\frac{n}{a}+K) -\ln(\frac{n}{a})) - (\ln(\frac{n+b}{a}+K) - \ln(\frac{n+b}{a})) \right) \\ = \frac{1}{a}\ln(\frac{n+b}{n}) + \frac{1}{a}\ln(\dfrac{\frac{n}{a}+K}{\frac{n+b}{a}+K})$$ Since we can choose $K$ as big as we want, the second term becomes irrelevant. So when we take the limit $n\to \infty$ , the whole things behaves like $\frac{n}{a}\ln(\frac{n+b}{n}) = \frac{1}{a}\ln((1+\frac{b}{n})^n)$ which of course goes to $\frac{b}{a}$ . To justify $**$ up to $O(\frac{1}{n^2})$ : Taylor expansion says that for big enough $c$ (namely, $\frac{n}{a}+k$ and $\frac{n+b}{a}+k$ ), $$\ln(\frac{c+1}{c}) = \frac{1}{c} - \frac{1}{2c^2} + \frac{1}{3c^3} - \dots$$ so that $$(\ln (\frac{n}{a}+K) -\ln(\frac{n}{a})) - (\ln(\frac{n+b}{a}+K) - \ln(\frac{n+b}{a})) - \left(\sum_{k=0}^K \frac{1}{\frac{n}{a}+k} - \sum_{k=0}^K \frac{1}{\frac{n+b}{a}+k}\right) \\ = -\frac{1}{2} \underbrace{\left( \sum_{k=0}^K \frac{1}{(\frac{n}{a}+k)^2} - \sum_{k=0}^K \frac{1}{(\frac{n+b}{a}+k)^2}\right)}_{<\frac{1}{(\frac{n}{a}+K)^2} \in O(1/n^2)} + \frac{1}{3}\underbrace{\left( \sum_{k=0}^K \frac{1}{(\frac{n}{a}+k)^3} - \sum_{k=0}^K \frac{1}{(\frac{n+b}{a}+k)^3}\right)}_{<\frac{1}{(\frac{n}{a}+K)^3} \in O(1/n^3)} +\dots $$ with the estimates in the bottom again by interpreting these as alternating series.","Let be real constants. Empirical observation (as in: asking WolframAlpha) suggests Note that the series in question can be interpreted as the ""remainder"" / ""tail end"" of a (conditionally!) convergent alternating series. To see what is going on, confirm that e.g. ( ) Questions: Is there a better proof for than my attempt at the bottom of this question? What references treat estimates for the asymptotic behaviour of ""remainders"" like the above? Would there be finer estimates, after subtracting the above error ""of order "", of order , , ...? Context : A student challenged me to (show existence of, and) find Now the easy and well-known recursive formula gives This is a funny case distinction because of course (Leibniz-Madhava) while , so in both cases , the question becomes to estimate the "" -order"" growth of the ""tail end"" of the series, which by a slight adjustment of (for ) is . My own proof idea for : By a standard estimate for convergent alternating series, for big enough (e.g. ) we have and now that finite sum can be split up into its positive and negative terms, and we get Since we can choose as big as we want, the second term becomes irrelevant. So when we take the limit , the whole things behaves like which of course goes to . To justify up to : Taylor expansion says that for big enough (namely, and ), so that with the estimates in the bottom again by interpreting these as alternating series.","a,b >0    \lim_{n\to \infty} n \cdot \sum_{k=0}^\infty (\frac{1}{n+ak} - \frac{1}{n+b+ak}) = \frac{b}{a} \tag{*} a=3, b=1, n=1000 1000 \cdot (\frac{1}{1000}-\frac{1}{1001}+\frac{1}{1003}-\frac{1}{1004}+\frac{1}{1006}-\frac{1}{1007} + \dots) \approx \frac{1}{3} (*) 1/n 1/n^2 1/n^3 \lim_{n\to \infty} n \cdot \int_0^{\frac{\pi}{4}}\tan^n(x) dx \int \tan^{n}(x)dx = \frac{1}{n-1}\tan^{n-1}(x) - \int \tan^{n-2}(x) dx \int_0^{\frac{\pi}{4}}\tan^n(x) dx = \begin{cases} \frac{1}{n-1}-\frac{1}{n-3}+\frac{1}{n-5} - \dots \pm 1\mp \frac{\pi}{4} \text{ if } n \text{ even}\\ \frac{1}{n-1}-\frac{1}{n-3}+\frac{1}{n-5} - \dots \pm \frac{1}{2}\mp \frac{\ln(2)}{2} \text{ if } n \text{ odd}\end{cases} \frac{\pi}{4} = 1-\frac{1}{3} +\frac{1}{5} \dots  \frac{\ln(2)}{2} = \frac{1}{2}-\frac{1}{4}+\frac{1}{6} -\dots 1/n \lim_{n\to \infty} n \cdot (\frac{1}{n+1}-\frac{1}{n+3}+\frac{1}{n+5} \dots) (*) b=2, a=4 \dfrac{1}{2} (*) K n+aK > n^2 \sum_{k=0}^\infty (\frac{1}{n+ak} - \frac{1}{n+b+ak}) = \sum_{k=0}^K(\frac{1}{n+ak} - \frac{1}{n+b+ak}) + O \left(\frac{1}{n^2}\right) \sum_{k=0}^K \frac{1}{n+ak} - \sum_{k=0}^K \frac{1}{n+b+ak}\\ =\frac{1}{a} \left(\sum_{k=0}^K \frac{1}{\frac{n}{a}+k} - \sum_{k=0}^K \frac{1}{\frac{n+b}{a}+k} \right)\\ \stackrel{**}\approx \frac{1}{a} \left((\ln (\frac{n}{a}+K) -\ln(\frac{n}{a})) - (\ln(\frac{n+b}{a}+K) - \ln(\frac{n+b}{a})) \right) \\
= \frac{1}{a}\ln(\frac{n+b}{n}) + \frac{1}{a}\ln(\dfrac{\frac{n}{a}+K}{\frac{n+b}{a}+K}) K n\to \infty \frac{n}{a}\ln(\frac{n+b}{n}) = \frac{1}{a}\ln((1+\frac{b}{n})^n) \frac{b}{a} ** O(\frac{1}{n^2}) c \frac{n}{a}+k \frac{n+b}{a}+k \ln(\frac{c+1}{c}) = \frac{1}{c} - \frac{1}{2c^2} + \frac{1}{3c^3} - \dots (\ln (\frac{n}{a}+K) -\ln(\frac{n}{a})) - (\ln(\frac{n+b}{a}+K) - \ln(\frac{n+b}{a})) - \left(\sum_{k=0}^K \frac{1}{\frac{n}{a}+k} - \sum_{k=0}^K \frac{1}{\frac{n+b}{a}+k}\right) \\ = -\frac{1}{2} \underbrace{\left( \sum_{k=0}^K \frac{1}{(\frac{n}{a}+k)^2} - \sum_{k=0}^K \frac{1}{(\frac{n+b}{a}+k)^2}\right)}_{<\frac{1}{(\frac{n}{a}+K)^2} \in O(1/n^2)} + \frac{1}{3}\underbrace{\left( \sum_{k=0}^K \frac{1}{(\frac{n}{a}+k)^3} - \sum_{k=0}^K \frac{1}{(\frac{n+b}{a}+k)^3}\right)}_{<\frac{1}{(\frac{n}{a}+K)^3} \in O(1/n^3)} +\dots ","['real-analysis', 'sequences-and-series', 'reference-request', 'estimation', 'alternating-expression']"
4,Prove that the general formula for a sequence $a_n$ is $\frac{(-1)^n}{n!}$,Prove that the general formula for a sequence  is,a_n \frac{(-1)^n}{n!},"Here is a sequence $a_n$ where the first five $a_n$ are: $a_1=-\frac{1}{1!}$ $a_2=-\frac{1}{2!}+\frac{1}{1!\times1!}$ $a_3=-\frac{1}{3!}+\frac{2}{2!\times1!}-\frac{1}{1!\times1!\times1!}$ $a_4=-\frac{1}{4!}+\frac{2}{3!\times1!}+\frac{1}{2!\times2!}-\frac{3}{2!\times1!\times1!}+\frac{1}{1!\times1!\times1!\times1!}$ $a_5=-\frac{1}{5!}+\frac{2}{4!\times1!}+\frac{2}{3!\times2!}-\frac{3}{3!\times1!\times1!}-\frac{3}{2!\times2!\times1!}+\frac{4}{2!\times1!\times1!\times1!}-\frac{1}{1!\times1!\times1!\times1!\times1!}$ For each term in $a_n$ ​: 1.The denominator enumerates all combinations that sum to $n$ . 2.The numerator represents the number of permutations possible for that combination. 3.If the number of elements in the combination is odd, the term is negative. I have computed the first five $a_n$ mentioned above, and it appears that $a_n=\frac{(-1)^n}{n!}$ ​. However, I am struggling to provide a proof for this formula. Could someone please assist me?","Here is a sequence where the first five are: For each term in ​: 1.The denominator enumerates all combinations that sum to . 2.The numerator represents the number of permutations possible for that combination. 3.If the number of elements in the combination is odd, the term is negative. I have computed the first five mentioned above, and it appears that ​. However, I am struggling to provide a proof for this formula. Could someone please assist me?",a_n a_n a_1=-\frac{1}{1!} a_2=-\frac{1}{2!}+\frac{1}{1!\times1!} a_3=-\frac{1}{3!}+\frac{2}{2!\times1!}-\frac{1}{1!\times1!\times1!} a_4=-\frac{1}{4!}+\frac{2}{3!\times1!}+\frac{1}{2!\times2!}-\frac{3}{2!\times1!\times1!}+\frac{1}{1!\times1!\times1!\times1!} a_5=-\frac{1}{5!}+\frac{2}{4!\times1!}+\frac{2}{3!\times2!}-\frac{3}{3!\times1!\times1!}-\frac{3}{2!\times2!\times1!}+\frac{4}{2!\times1!\times1!\times1!}-\frac{1}{1!\times1!\times1!\times1!\times1!} a_n n a_n a_n=\frac{(-1)^n}{n!},"['sequences-and-series', 'combinatorics', 'integer-partitions']"
5,Does this serie converge ? $\sum_{n=1}^{\infty} \frac{1}{n^3 - 5n}$,Does this serie converge ?,\sum_{n=1}^{\infty} \frac{1}{n^3 - 5n},"Does this serie converge ? $$\sum_{n=1}^{\infty} \frac{1}{n^3 - 5n}$$ We have $$n^3 - 5n < n^3 \implies \frac{1}{n^3-5n} > \frac{1}{n^3}$$ We know $\frac{1}{n^3}$ converges because it's a p serie with $p > 1$ , but how does that help for determining the convergence of $\sum_{n=1}^{\infty} \frac{1}{n^3 - 5n}$ ? What should I do next ?","Does this serie converge ? We have We know converges because it's a p serie with , but how does that help for determining the convergence of ? What should I do next ?",\sum_{n=1}^{\infty} \frac{1}{n^3 - 5n} n^3 - 5n < n^3 \implies \frac{1}{n^3-5n} > \frac{1}{n^3} \frac{1}{n^3} p > 1 \sum_{n=1}^{\infty} \frac{1}{n^3 - 5n},"['real-analysis', 'sequences-and-series', 'analysis', 'convergence-divergence', 'summation']"
6,"Finding a closed form for the recursive sequence $a_n=\frac13(10-2a_{n-1})$, with $a_0=3$","Finding a closed form for the recursive sequence , with",a_n=\frac13(10-2a_{n-1}) a_0=3,I've got following recursive sequence: $$ a_n=\frac13(10-2a_{n-1}) $$ With $ a_0=3$ I have found following expression: $$ a_n=3+ \sum_{n=0}^n{2^{n-1}\cdot\frac{5}{3^n}\cdot (-1)^n} $$ Is there maybe a better form? Thank you for your help! I would appreciate hints,I've got following recursive sequence: With I have found following expression: Is there maybe a better form? Thank you for your help! I would appreciate hints,"
a_n=\frac13(10-2a_{n-1})
  a_0=3  a_n=3+ \sum_{n=0}^n{2^{n-1}\cdot\frac{5}{3^n}\cdot (-1)^n} ","['real-analysis', 'calculus', 'sequences-and-series']"
7,Understanding and verifying the formula for $\binom{T}{B}$,Understanding and verifying the formula for,\binom{T}{B},"I am studying a formula that I came across in my research, which is given by: $$\binom{T}{B}= \frac{1}{T-B}\sum_{\ell=1}^{\infty} \binom{T + \ell - 1}{B - 1} \left(1 - \frac{B}{T} \right)^\ell \cdot \ell$$ I have checked this equation numerically and found it to be accurate, and I want to clarify that the right-hand side of this formula is not an expectation with respect to $\ell$ , but I am having difficulty understanding its meaning and how it was derived. I have tried searching for possible generating functions or discrete probability distributions that might be related to this formula, but so far, I have not been successful. Any help or clarification would be greatly appreciated. Thank you.","I am studying a formula that I came across in my research, which is given by: I have checked this equation numerically and found it to be accurate, and I want to clarify that the right-hand side of this formula is not an expectation with respect to , but I am having difficulty understanding its meaning and how it was derived. I have tried searching for possible generating functions or discrete probability distributions that might be related to this formula, but so far, I have not been successful. Any help or clarification would be greatly appreciated. Thank you.",\binom{T}{B}= \frac{1}{T-B}\sum_{\ell=1}^{\infty} \binom{T + \ell - 1}{B - 1} \left(1 - \frac{B}{T} \right)^\ell \cdot \ell \ell,"['sequences-and-series', 'combinatorics', 'discrete-mathematics', 'probability-distributions', 'generating-functions']"
8,Show that a sequence is bounded.,Show that a sequence is bounded.,,"Let $f: \mathbb{R}_+ \to \mathbb{R}$ be a Lipschitz continuous function, i.e. there exits some $C > 0$ such that for all $x,y \in \mathbb{R}_+$ , we have $$ |f(x) - f(y)| \leq C|x-y|. $$ If $N \sim Poi(\lambda)$ , $\lambda>0$ , we can consider the random variable $f(N)$ . Assume that $\mathbb{E}[f(N)] = 0$ , i.e. $e^{-\lambda}\sum_{n=0}^\infty \frac{\lambda^n}{n!}f(n) = 0$ . Now, we consider the sequence $$ a_l := \frac{l!}{\lambda^{l+1}} \sum_{n=0}^l\frac{\lambda^n}{n!}f(n). $$ The goal is to show that $a_l$ is a bounded sequence. My thoughts: I was able to prove an equivalent representation of $a_l$ given by $$ a_l = \frac{\mathbb{E}[f(N)1_{\{N \leq l\}}]}{\lambda \mathbb{P}[N = l]}. $$ Since $$ a_l := \underbrace{\frac{l!}{\lambda^{l+1}}}_{\to \infty} \underbrace{{\sum_{n=0}^l\frac{\lambda^n}{n!}f(n)}}_{\to 0} $$ it would suffice that the partial sums on the RHS converge fast enough to 0. However, I am not sure how to proceed. It is not clear to me on how I can apply the Lipschitz condition in order to show boundedness. Some help or guidance into the right direction would be really appreciated. Thanks in advance!","Let be a Lipschitz continuous function, i.e. there exits some such that for all , we have If , , we can consider the random variable . Assume that , i.e. . Now, we consider the sequence The goal is to show that is a bounded sequence. My thoughts: I was able to prove an equivalent representation of given by Since it would suffice that the partial sums on the RHS converge fast enough to 0. However, I am not sure how to proceed. It is not clear to me on how I can apply the Lipschitz condition in order to show boundedness. Some help or guidance into the right direction would be really appreciated. Thanks in advance!","f: \mathbb{R}_+ \to \mathbb{R} C > 0 x,y \in \mathbb{R}_+ 
|f(x) - f(y)| \leq C|x-y|.
 N \sim Poi(\lambda) \lambda>0 f(N) \mathbb{E}[f(N)] = 0 e^{-\lambda}\sum_{n=0}^\infty \frac{\lambda^n}{n!}f(n) = 0 
a_l := \frac{l!}{\lambda^{l+1}} \sum_{n=0}^l\frac{\lambda^n}{n!}f(n).
 a_l a_l 
a_l = \frac{\mathbb{E}[f(N)1_{\{N \leq l\}}]}{\lambda \mathbb{P}[N = l]}.
 
a_l := \underbrace{\frac{l!}{\lambda^{l+1}}}_{\to \infty} \underbrace{{\sum_{n=0}^l\frac{\lambda^n}{n!}f(n)}}_{\to 0}
","['sequences-and-series', 'poisson-distribution', 'lipschitz-functions']"
9,How to prove that $\sum_{n=0}^{\infty}(-1)^{n}\frac{\Gamma(n+\frac{3}{4})}{\Gamma(n+\frac{5}{4})}=\frac{\sqrt{\pi}}{2}$ [closed],How to prove that  [closed],\sum_{n=0}^{\infty}(-1)^{n}\frac{\Gamma(n+\frac{3}{4})}{\Gamma(n+\frac{5}{4})}=\frac{\sqrt{\pi}}{2},"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question How can I prove that: $$\sum_{n=0}^{\infty}(-1)^{n}\frac{\Gamma(n+\frac{3}{4})}{\Gamma(n+\frac{5}{4})}=\frac{\sqrt{\pi}}{2}$$ The closest I've gotten is that if I call the sum S, then using the definition of the Beta function: $$\sqrt{\pi}S=\intop_0^1\frac{x^{-\frac{1}{4}}}{(1+x)\sqrt{1-x}}dx$$ But I don't really know where to go from here.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question How can I prove that: The closest I've gotten is that if I call the sum S, then using the definition of the Beta function: But I don't really know where to go from here.",\sum_{n=0}^{\infty}(-1)^{n}\frac{\Gamma(n+\frac{3}{4})}{\Gamma(n+\frac{5}{4})}=\frac{\sqrt{\pi}}{2} \sqrt{\pi}S=\intop_0^1\frac{x^{-\frac{1}{4}}}{(1+x)\sqrt{1-x}}dx,"['calculus', 'sequences-and-series', 'gamma-function']"
10,What is the result or equivalent order of this infinite sum?,What is the result or equivalent order of this infinite sum?,,"As described by the title, can we obtain an analytical result for the following infinite sum or provide an equivalent order as $p \rightarrow 1$ ? $$ \sum_{j=1}^{\infty} \left(\frac{p^j}{1-p^j}\right)^{i+1},i\ \text{is non-negative integer}. $$ Now, I only know that $$\sum_{j=1}^{\infty} \frac{p^j}{1-p^j}\approx \frac{1}{1-p}\ln\left(\frac{1}{1-p}\right).$$ I often have to compute the sum of infinite series in my research. I really appreciate if one can provide a textbook or useful handbook to reference.","As described by the title, can we obtain an analytical result for the following infinite sum or provide an equivalent order as ? Now, I only know that I often have to compute the sum of infinite series in my research. I really appreciate if one can provide a textbook or useful handbook to reference.","p \rightarrow 1 
\sum_{j=1}^{\infty} \left(\frac{p^j}{1-p^j}\right)^{i+1},i\ \text{is non-negative integer}.
 \sum_{j=1}^{\infty} \frac{p^j}{1-p^j}\approx \frac{1}{1-p}\ln\left(\frac{1}{1-p}\right).","['sequences-and-series', 'reference-request']"
11,sum of 100 terms of logarithmic expression,sum of 100 terms of logarithmic expression,,Calculate value of $\displaystyle \sum^{100}_{k=1}\ln\bigg(\frac{(2k+1)^4+\frac{1}{4}}{16k^4+\frac{1}{4}}\bigg)$ My try :: $\displaystyle x^4+4y^4$ $=(x^2+2xy+2y^2)(x^2-2xy+2y^2)$ So sum $\displaystyle \sum^{100}_{k=1}\ln\bigg(\frac{1+4(2k+1)^4}{1+4(2k)^4}\bigg)$ $\displaystyle =\sum^{100}_{k=1}\ln\bigg[\frac{(1+2(2k+1)+2(2k+1)^2)(1-2(2k+1)+2(2k+1)^2)}{(1+2(2k)+2(2k)^2)(1-2(2k)+2(2k)^2)}\bigg]$ How can I decompose that complex expression into partial fractions?,Calculate value of My try :: So sum How can I decompose that complex expression into partial fractions?,\displaystyle \sum^{100}_{k=1}\ln\bigg(\frac{(2k+1)^4+\frac{1}{4}}{16k^4+\frac{1}{4}}\bigg) \displaystyle x^4+4y^4 =(x^2+2xy+2y^2)(x^2-2xy+2y^2) \displaystyle \sum^{100}_{k=1}\ln\bigg(\frac{1+4(2k+1)^4}{1+4(2k)^4}\bigg) \displaystyle =\sum^{100}_{k=1}\ln\bigg[\frac{(1+2(2k+1)+2(2k+1)^2)(1-2(2k+1)+2(2k+1)^2)}{(1+2(2k)+2(2k)^2)(1-2(2k)+2(2k)^2)}\bigg],['sequences-and-series']
12,Proof of Bolzano Weierstrass Theorem in $\mathbb{R}^n$,Proof of Bolzano Weierstrass Theorem in,\mathbb{R}^n,"I would like to show the Bolzano-Weierstrass in $\mathbb{R}^n$ , I have seen this theorem in $\mathbb{R}$ and I know it can be shown by induction, something I will try now. Theorem : Every bounded sequence in $\mathbb{R}^n$ has a convergent subsequence in $\mathbb{R}^n$ Proof : By induction : we know that it is true for $n=1$ , we assume this holds for $p=k$ and we want to show this holds for $p=k+1$ . Consider $(x_n)$ a bounded sequence in $\mathbb{R}^{k+1}$ . For all $n\in\mathbb{N}$ we can write $x_n = (a_n, x_{n}^{k+1})$ where $a_n = (x_{n}^{1}, ..., x_{n}^{k})\in\mathbb{R}^{k}$ since $\mathbb{R}^{k+1}$ is isomorphic to $\mathbb{R}^{k}\times\mathbb{R}$ so this rewritting of $x_n$ , even if not exactly the same ""element"" as the initial $x_n$ , can be treated as the same. Clearly, for all $n\in\mathbb{N}, \exists M>0 : \lvert x_{n}^{k+1}\rvert\leq\lVert x_n\rVert_{2}\leq M$ and $\lVert a_n\rVert_{2}\leq\lVert x_n\rVert_{2}\leq M$ . Using the induction hypothesis, we know that $(a_n)$ has a convergent subsquence $(a_{n_j})$ , we denote $x\in\mathbb{R}^{k}$ its limit. Now, the sequence $(x_{n}^{k+1})$ has also a convergent subsequence in $\mathbb{R}$ by Bolzano-Weierstrass with limit $x^{k+1}\in\mathbb{R}$ . This shows that $x_n$ admits a convergent subsequence $(a_{n_j}, x_{n_j}^{k+1})$ whose limit is $(x,x^{k+1}) = (x^1, ..., x^{k+1})\in\mathbb{R}^{k+1}$ so the Bolzano-Weierstrass is true for $p=k+1$ , which concludes the proof. This seems correct to you? EDIT : My proof is false, we need to take another subsequence to be sure to have a vector with coordinate that have the same index ! Thanks to FShrike, Vercassivelaunos and egreg, you will find three very clear answers to this problem below.","I would like to show the Bolzano-Weierstrass in , I have seen this theorem in and I know it can be shown by induction, something I will try now. Theorem : Every bounded sequence in has a convergent subsequence in Proof : By induction : we know that it is true for , we assume this holds for and we want to show this holds for . Consider a bounded sequence in . For all we can write where since is isomorphic to so this rewritting of , even if not exactly the same ""element"" as the initial , can be treated as the same. Clearly, for all and . Using the induction hypothesis, we know that has a convergent subsquence , we denote its limit. Now, the sequence has also a convergent subsequence in by Bolzano-Weierstrass with limit . This shows that admits a convergent subsequence whose limit is so the Bolzano-Weierstrass is true for , which concludes the proof. This seems correct to you? EDIT : My proof is false, we need to take another subsequence to be sure to have a vector with coordinate that have the same index ! Thanks to FShrike, Vercassivelaunos and egreg, you will find three very clear answers to this problem below.","\mathbb{R}^n \mathbb{R} \mathbb{R}^n \mathbb{R}^n n=1 p=k p=k+1 (x_n) \mathbb{R}^{k+1} n\in\mathbb{N} x_n = (a_n, x_{n}^{k+1}) a_n = (x_{n}^{1}, ..., x_{n}^{k})\in\mathbb{R}^{k} \mathbb{R}^{k+1} \mathbb{R}^{k}\times\mathbb{R} x_n x_n n\in\mathbb{N}, \exists M>0 : \lvert x_{n}^{k+1}\rvert\leq\lVert x_n\rVert_{2}\leq M \lVert a_n\rVert_{2}\leq\lVert x_n\rVert_{2}\leq M (a_n) (a_{n_j}) x\in\mathbb{R}^{k} (x_{n}^{k+1}) \mathbb{R} x^{k+1}\in\mathbb{R} x_n (a_{n_j}, x_{n_j}^{k+1}) (x,x^{k+1}) = (x^1, ..., x^{k+1})\in\mathbb{R}^{k+1} p=k+1","['real-analysis', 'calculus', 'sequences-and-series', 'general-topology', 'analysis']"
13,Explicit formula for the $n^{th}$ positive integer of a $p$-rough sequence,Explicit formula for the  positive integer of a -rough sequence,n^{th} p,"A p -rough number , or p -jagged number , is an integer whose smallest prime factor is $p$ (Finch, 2001). The $3$ -rough numbers are the odd numbers. The $7$ -rough numbers are numbers not divisible by $2, 3,$ or $5,$ that is: $ \left \{1, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 49, 53, 59, 61, 67, 71, ...\right \} $ . I am struggling to find an explicit formula for the 7-rough numbers I also wonder whether there is some recurrence or other method that can be used to find the $n^{th}$ number of a $p$ -rough sequence for any possible $p$ . Thanks in advance! Edit I found on OEIS the following formula by Gary Detlefs (Sep 15, 2013) for the $7$ -rough numbers: $$a(n) = \frac{6f(n) - 3 + (-1)^{f(n)}}{2}$$ where $$f(n)= n + \lfloor\frac{n}{4}\rfloor + \lfloor\frac{(n+4) \mod 8}{6}\rfloor.$$ I wonder how it is derived and if it is possible to find an equivalent or alternative formula without the floor and mod operations in it.","A p -rough number , or p -jagged number , is an integer whose smallest prime factor is (Finch, 2001). The -rough numbers are the odd numbers. The -rough numbers are numbers not divisible by or that is: . I am struggling to find an explicit formula for the 7-rough numbers I also wonder whether there is some recurrence or other method that can be used to find the number of a -rough sequence for any possible . Thanks in advance! Edit I found on OEIS the following formula by Gary Detlefs (Sep 15, 2013) for the -rough numbers: where I wonder how it is derived and if it is possible to find an equivalent or alternative formula without the floor and mod operations in it.","p 3 7 2, 3, 5,  \left \{1, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 49, 53, 59, 61, 67, 71, ...\right \}  n^{th} p p 7 a(n) = \frac{6f(n) - 3 + (-1)^{f(n)}}{2} f(n)= n + \lfloor\frac{n}{4}\rfloor + \lfloor\frac{(n+4) \mod 8}{6}\rfloor.","['sequences-and-series', 'polynomials']"
14,Convergence of a series that is only known numerically,Convergence of a series that is only known numerically,,"I hope this is not a duplicate, this is quite a general question but I couldn't find the answer in any of the other posts. Suppose one has a power series $\sum_{n=0}^{\infty}c_n x^n$ whose coefficients $c_n$ can only be numerically computed (for example, in my particular case, the $c_n$ are obtained by inverting a matrix). The general question here would be how to implement the usual convergence tests (ratio test and root test specifically) to extract whether the series has a finite or inifite convergence radius in $x$ . To be more specific on the problem of having access to only the numeric values of $c_n$ , I'll show my attempts with the root and ratio tests. I compute the first 150 $c_n$ coefficients and plot $\vert c_n\vert^{1/n}$ as a function of $n$ : To me this picture does not make it clear whether or not the sequence approaches a finite value. With a little effort, I compute more coefficients, this time I go to 450. This is the result Which looks as inconclusive as the previous picture, as I cannot tell if the sequence approaches a value at around $2\pi$ or grows to infinity. Interestingly, the ratio test looks like this: Where the sequence that I plotted is $\vert c_{n+1}/c_n\vert$ . It seems that the ""sub-sequence"" given by odd n+1 and even n goes to zero while that given by even n+1 and odd n goes to infinity. I am unsure if the presence of the seemingly divergent contribution is a reason strong enough to claim the power series has zero radius of convergence. In sum, I am having trouble extracting strong conclusions about the convergence radius of the power series from this kind of analysis, and I was wondering if there are methods that can be applied other than plotting a few terms and trying to guess the general behavior. Edit : from the comments I see there is in principle no way of determining the convergence radius by looking at a finite number of terms. This is already an answer, but I'll leave here the specific problem that motivated the question. Let us consider the matrix $S$ , whose coefficients $s_{n,k}$ are \begin{equation} \begin{aligned} s_{n,k}&=0,\quad k<n,\\ s_{n,k}&=\frac{-i(-1)^{k+n} \Gamma (k)}{2^k(i\pi)^{n}\Gamma^2(n) \Gamma(k-n+2)}\frac{f(n,k)}{g(n)},\quad k\geq n, \end{aligned} \end{equation} where \begin{equation} \begin{aligned} f(n,k)&=(2i\pi)^n \Gamma(k+1,-2 i \pi ,2 i \pi )\\& +(2i\pi)^{k+1}[(-1)^{k+n} (\Gamma (n,-2 i \pi )-\Gamma (n))+\Gamma (n,2 i \pi )-\Gamma(n)],\\ g(n)&=2\pi(\tilde{\Gamma}(n,-2 i \pi )+\tilde{\Gamma}(n,2 i \pi)-2)+i n \tilde{\Gamma}(n+1,2 i \pi,-2i\pi). \end{aligned} \end{equation} In these expressions $i$ is the imaginary unit, $\Gamma(z,a,b)$ is the incomplete gamma function and $\tilde{\Gamma}(z,a,b)=\Gamma(z,a,b)/\Gamma(z)$ . The $S$ matrix is upper triangular, and all its diagonal elements are $1$ . Let us now consider the inverse matrix $T\equiv S^{-1}$ . Then the $c_n$ coefficients of the power series above are the elements of the first row of $T$ . In these conditions I have not been able to find a form for the entries $t_{n,k}$ of the $T$ matrix, and thus I've been forced to resort to generate $S$ numerically and invert it.","I hope this is not a duplicate, this is quite a general question but I couldn't find the answer in any of the other posts. Suppose one has a power series whose coefficients can only be numerically computed (for example, in my particular case, the are obtained by inverting a matrix). The general question here would be how to implement the usual convergence tests (ratio test and root test specifically) to extract whether the series has a finite or inifite convergence radius in . To be more specific on the problem of having access to only the numeric values of , I'll show my attempts with the root and ratio tests. I compute the first 150 coefficients and plot as a function of : To me this picture does not make it clear whether or not the sequence approaches a finite value. With a little effort, I compute more coefficients, this time I go to 450. This is the result Which looks as inconclusive as the previous picture, as I cannot tell if the sequence approaches a value at around or grows to infinity. Interestingly, the ratio test looks like this: Where the sequence that I plotted is . It seems that the ""sub-sequence"" given by odd n+1 and even n goes to zero while that given by even n+1 and odd n goes to infinity. I am unsure if the presence of the seemingly divergent contribution is a reason strong enough to claim the power series has zero radius of convergence. In sum, I am having trouble extracting strong conclusions about the convergence radius of the power series from this kind of analysis, and I was wondering if there are methods that can be applied other than plotting a few terms and trying to guess the general behavior. Edit : from the comments I see there is in principle no way of determining the convergence radius by looking at a finite number of terms. This is already an answer, but I'll leave here the specific problem that motivated the question. Let us consider the matrix , whose coefficients are where In these expressions is the imaginary unit, is the incomplete gamma function and . The matrix is upper triangular, and all its diagonal elements are . Let us now consider the inverse matrix . Then the coefficients of the power series above are the elements of the first row of . In these conditions I have not been able to find a form for the entries of the matrix, and thus I've been forced to resort to generate numerically and invert it.","\sum_{n=0}^{\infty}c_n x^n c_n c_n x c_n c_n \vert c_n\vert^{1/n} n 2\pi \vert c_{n+1}/c_n\vert S s_{n,k} \begin{equation}
\begin{aligned}
s_{n,k}&=0,\quad k<n,\\
s_{n,k}&=\frac{-i(-1)^{k+n} \Gamma (k)}{2^k(i\pi)^{n}\Gamma^2(n) \Gamma(k-n+2)}\frac{f(n,k)}{g(n)},\quad k\geq n,
\end{aligned}
\end{equation} \begin{equation}
\begin{aligned}
f(n,k)&=(2i\pi)^n \Gamma(k+1,-2 i \pi ,2 i \pi )\\&
+(2i\pi)^{k+1}[(-1)^{k+n} (\Gamma (n,-2 i \pi )-\Gamma (n))+\Gamma (n,2 i \pi )-\Gamma(n)],\\
g(n)&=2\pi(\tilde{\Gamma}(n,-2 i \pi )+\tilde{\Gamma}(n,2 i \pi)-2)+i n \tilde{\Gamma}(n+1,2 i \pi,-2i\pi).
\end{aligned}
\end{equation} i \Gamma(z,a,b) \tilde{\Gamma}(z,a,b)=\Gamma(z,a,b)/\Gamma(z) S 1 T\equiv S^{-1} c_n T t_{n,k} T S","['sequences-and-series', 'numerical-methods', 'power-series', 'numerical-calculus']"
15,Can we define addition of numbers which are **NOT** eventually all zero as we go to the left?,Can we define addition of numbers which are **NOT** eventually all zero as we go to the left?,,"I am struggling to define addition of objects which are similar to decimal-expansions. In this post, we refer to the decimal-expansion-like things as "" wumbers "". Our goal is to write something like: $\forall v,w \in \mathbb{W}$ , $\quad v + w = \text{<SOMETHING>}$ . For any natural numbers, you can pad the left of the associated string with any number of zeros you like. $582 = 000582 = 0000000000000000000582$ However, my wumbers never stop having non-zero digits as you go farther and farther to the left. This is because a wumber is simply a sign ( + or - ) and a function from $\mathbb{Z}$ to the symbols $\begin{Bmatrix} 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\end{Bmatrix}$ . I am most of the way to defining a reasonable form of addition, but I could use some help filling in the gaps. What is a "" Wumber ""? Definition of Wumber A wumber is an ordered pair $(F, S)$ such that $S$ is one of the symbols ""+"" or `""-"" and $F$ is a function from $\mathbb{Z}$ to the digits $\begin{Bmatrix} 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\end{Bmatrix}$ such that $\not\exists z \in \mathbb{Z}: \forall Z \geq z, F(Z) = 9 \text{ or } \forall Z \leq z, F(Z) = 9$ . Definition of $\mathbb{W}$ $\mathbb{W}$ denotes the set of all wumbers. Difference Between Wumbers and Decimal Expansions The primary difference between the decimal-expansion of a real-number and a wumber is that the digits of a wumber are not eventually all zero as you go to the left. There exists a wumber $W$ such that $\sum_{z \in \mathbb{Z}}^{\text{ }} 10^{z}*W(z)$ is not defined because the coefficient for very large powers of $10$ is not zero. Definition of the degree of a Wumber Let $\text{deg}$ be a mapping from the set of all wumbers $\mathbb{W}$ to the set $\mathbb{Z} \cup \begin{Bmatrix} \infty \end{Bmatrix}$ is defined as follows: $\forall W \in \mathbb{W}$ , $\qquad \text{deg}(W) = $ $\qquad \qquad \begin{cases} \infty,  & \text{if  } \forall n \in \mathbb{Z} \exists m \in \mathbb{Z}: W(m) \neq 0 \\ \text{min} \begin{Bmatrix} n \in \mathbb{Z}: \forall m \geq n, \quad W(m) = 0 \end{Bmatrix}  & \text{otherwise } \end{cases}$ Converting Wumbers to Real Numbers $(W^{\mathbb{R}})$ Let $W \in \mathbb{W}$ . If $\exists d \in \mathbb{Z}$ such that $d = \text{deg}(W)$ then $W^{\mathbb{R}} = \sum_{z \in \mathbb{Z}}^{\text{ }} 10^{z}*W(z)$ $W^{\mathbb{R}}$ is the sum of $10^{k}*W(k)$ taken over all $k \in \mathbb{Z}$ Also, wumber $W$ is said to be a real wumber . Converting Real Numbers to Wumbers $(x^{\mathbb{W}})$ For any real number $x$ , $x^{\mathbb{W}}$ is the unique wumber $W$ such that $W^{\mathbb{R}} = x$ Definition of "" Natural Wumber "" For any real wumber $W \in \mathbb{W}$ , $W$ is natural if and only if $W^{\mathbb{R}}$ is a natural number. How do we Add Wumbers? An answer to this question is a non-trivial definition of addition which extends addition of real-numbers to $\mathbb{W}$ . $\forall V, W \in \mathbb{W}$ if $V$ and $W$ are real, then $V + W = V^{\mathbb{R}} + W^{\mathbb{R}}$ Example $\qquad$ Let $W = (``+"", F)$ such that $F$ is a mapping from $\mathbb{Z}$ to the digits $\begin{Bmatrix} 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\end{Bmatrix}$ such that: $\qquad\qquad$ $F[0] = 5$ $\qquad\qquad$ $F[1] = 1$ $\qquad\qquad$ $F[-1] = 2$ $\qquad\qquad$ $F[a] = 0 \forall a \in \mathbb{Z}: \geq 2$ $\qquad\qquad$ $F[b] = 0 \forall b \in \mathbb{Z}b \leq -2$ Then, $F^{\mathbb{R}} = 15.2$ $\qquad$ Let $V = (""-"", G)$ such that $G$ is a mapping from $\mathbb{Z}$ to the digits $\begin{Bmatrix} 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\end{Bmatrix}$ such that: $\qquad\qquad$ $G[0] = 2$ $\qquad\qquad$ $G[1] = 4$ $\qquad\qquad$ $G[-1] = 6$ $\qquad\qquad$ $G[a] = 0$ $\forall a \in \mathbb{Z}: \geq 2$ $\qquad\qquad$ $G[b] = 0$ $\forall b \in \mathbb{Z}b \leq -2$ Then, $V^{\mathbb{R}} = 42.6$ So, $V + W = V^{\mathbb{R}} + W^{\mathbb{R}} = 42.6 + 15.2 = 57.8$ . The issue is when the co-efficient on large powers of $10$ are never eventually always zero... If you add a non-real wumber $V$ to a real wumber $W$ to produce non-real wumber $X$ then for all sufficiently large indices $k$ , the $X[k] = V[k]$ Suppose that we have $F$ from $\mathbb{Z}$ to the digits such that: $F(k) = 0$ for negative indices $k$ $F(k) = 0$ for odd positive indices $k > 0$ $F(k) = 1$ for even non-negative indices $k \geq 0$ Then $W = (""+"", F(k))$ is a non-real wumber . $W = \dots 101010101 \dots 10101.00000 \dots 0000 \dots$ You can add a number like $500$ or $\pi$ to a non-real wumber. $W + 500 + \pi = \dots 101010101 \dots 1010604.14519 \dots [\text{ more digits of } \pi] \dots$ After we define how to add a real number to a wumber we could define how to add any arbitrary pair of wumbers . If I ask you for the $k^{\text{th}}$ element of $V + W$ you should be able to: truncate $V$ at index $p$ truncate $W$ at index $p$ add the truncated wumbers together say that $\forall k, p \in \mathbb{Z}$ and $\forall V, W \in \mathbb{W}$ , $(V + W)[k] = T(V, p)[k] + T(W, p)[k]$ . The truncation $T$ of wumber $V$ at index $k$ has the properties: $T(V, k)[z] = V[z]$ for all $z \in \mathbb{Z}$ if $z \leq k$ $T(V, k)[z] = 0$ for all $z \in \mathbb{Z}$ if $z > k$ $T(V, k)$ is a real-wumber even if $V$ is a non-real wumber . Existence of a something we will call a "" Common Additive "" Instead of greatest-common-factor we could have a "" greatest-common-additive "". I am thinking that it is probably the case that $\forall V, W \in \mathbb{W}$ , if $V$ and $W$ are non-real then $\exists X \in \mathbb{W}$ such that: $X$ is a non-real wumber. $V = X + V^{\prime}$ $W = X + W^{\prime}$ $V^{\prime}$ is a real wumber $W^{\prime}$ is a real wumber Then, $V + W = (2*X) + (V^{\prime} + W^{\prime})$ $(2*X)$ is a non-real wumber. $(V^{\prime} + W^{\prime})$ is a real wumber. So, adding two non-real wumbers can be expressed as adding a real wumber to a non-real wumber . I am not sure how we would define $(2*X)$ for non-real $X$ . Maybe if $X$ was a ""binary wumber"" (a mapping from $\mathbb{Z}$ to $\begin{Bmatrix} 0, 1\end{Bmatrix}$ then $\forall k \in (2*X)(k) = X(k - 1)$ How can we define the addition of two non-real wumbers ? Was there a Question in There Somewhere ? An answer to this question is a non-trivial definition of addition which extends addition of real-numbers to $\mathbb{W}$ . How do you add two decimal expansions together when there exists non-zero co-efficient for $10^{k}$ where $k$ is very large.","I am struggling to define addition of objects which are similar to decimal-expansions. In this post, we refer to the decimal-expansion-like things as "" wumbers "". Our goal is to write something like: , . For any natural numbers, you can pad the left of the associated string with any number of zeros you like. However, my wumbers never stop having non-zero digits as you go farther and farther to the left. This is because a wumber is simply a sign ( + or - ) and a function from to the symbols . I am most of the way to defining a reasonable form of addition, but I could use some help filling in the gaps. What is a "" Wumber ""? Definition of Wumber A wumber is an ordered pair such that is one of the symbols ""+"" or `""-"" and is a function from to the digits such that . Definition of denotes the set of all wumbers. Difference Between Wumbers and Decimal Expansions The primary difference between the decimal-expansion of a real-number and a wumber is that the digits of a wumber are not eventually all zero as you go to the left. There exists a wumber such that is not defined because the coefficient for very large powers of is not zero. Definition of the degree of a Wumber Let be a mapping from the set of all wumbers to the set is defined as follows: , Converting Wumbers to Real Numbers Let . If such that then is the sum of taken over all Also, wumber is said to be a real wumber . Converting Real Numbers to Wumbers For any real number , is the unique wumber such that Definition of "" Natural Wumber "" For any real wumber , is natural if and only if is a natural number. How do we Add Wumbers? An answer to this question is a non-trivial definition of addition which extends addition of real-numbers to . if and are real, then Example Let such that is a mapping from to the digits such that: Then, Let such that is a mapping from to the digits such that: Then, So, . The issue is when the co-efficient on large powers of are never eventually always zero... If you add a non-real wumber to a real wumber to produce non-real wumber then for all sufficiently large indices , the Suppose that we have from to the digits such that: for negative indices for odd positive indices for even non-negative indices Then is a non-real wumber . You can add a number like or to a non-real wumber. After we define how to add a real number to a wumber we could define how to add any arbitrary pair of wumbers . If I ask you for the element of you should be able to: truncate at index truncate at index add the truncated wumbers together say that and , . The truncation of wumber at index has the properties: for all if for all if is a real-wumber even if is a non-real wumber . Existence of a something we will call a "" Common Additive "" Instead of greatest-common-factor we could have a "" greatest-common-additive "". I am thinking that it is probably the case that , if and are non-real then such that: is a non-real wumber. is a real wumber is a real wumber Then, is a non-real wumber. is a real wumber. So, adding two non-real wumbers can be expressed as adding a real wumber to a non-real wumber . I am not sure how we would define for non-real . Maybe if was a ""binary wumber"" (a mapping from to then How can we define the addition of two non-real wumbers ? Was there a Question in There Somewhere ? An answer to this question is a non-trivial definition of addition which extends addition of real-numbers to . How do you add two decimal expansions together when there exists non-zero co-efficient for where is very large.","\forall v,w \in \mathbb{W} \quad v + w = \text{<SOMETHING>} 582 = 000582 = 0000000000000000000582 \mathbb{Z} \begin{Bmatrix} 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\end{Bmatrix} (F, S) S F \mathbb{Z} \begin{Bmatrix} 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\end{Bmatrix} \not\exists z \in \mathbb{Z}: \forall Z \geq z, F(Z) = 9 \text{ or } \forall Z \leq z, F(Z) = 9 \mathbb{W} \mathbb{W} W \sum_{z \in \mathbb{Z}}^{\text{ }} 10^{z}*W(z) 10 \text{deg} \mathbb{W} \mathbb{Z} \cup \begin{Bmatrix} \infty \end{Bmatrix} \forall W \in \mathbb{W} \qquad \text{deg}(W) =  \qquad \qquad \begin{cases}
\infty,  & \text{if  } \forall n \in \mathbb{Z} \exists m \in \mathbb{Z}: W(m) \neq 0 \\
\text{min} \begin{Bmatrix} n \in \mathbb{Z}: \forall m \geq n, \quad W(m) = 0 \end{Bmatrix}  & \text{otherwise }
\end{cases} (W^{\mathbb{R}}) W \in \mathbb{W} \exists d \in \mathbb{Z} d = \text{deg}(W) W^{\mathbb{R}} = \sum_{z \in \mathbb{Z}}^{\text{ }} 10^{z}*W(z) W^{\mathbb{R}} 10^{k}*W(k) k \in \mathbb{Z} W (x^{\mathbb{W}}) x x^{\mathbb{W}} W W^{\mathbb{R}} = x W \in \mathbb{W} W W^{\mathbb{R}} \mathbb{W} \forall V, W \in \mathbb{W} V W V + W = V^{\mathbb{R}} + W^{\mathbb{R}} \qquad W = (``+"", F) F \mathbb{Z} \begin{Bmatrix} 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\end{Bmatrix} \qquad\qquad F[0] = 5 \qquad\qquad F[1] = 1 \qquad\qquad F[-1] = 2 \qquad\qquad F[a] = 0 \forall a \in \mathbb{Z}: \geq 2 \qquad\qquad F[b] = 0 \forall b \in \mathbb{Z}b \leq -2 F^{\mathbb{R}} = 15.2 \qquad V = (""-"", G) G \mathbb{Z} \begin{Bmatrix} 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\end{Bmatrix} \qquad\qquad G[0] = 2 \qquad\qquad G[1] = 4 \qquad\qquad G[-1] = 6 \qquad\qquad G[a] = 0 \forall a \in \mathbb{Z}: \geq 2 \qquad\qquad G[b] = 0 \forall b \in \mathbb{Z}b \leq -2 V^{\mathbb{R}} = 42.6 V + W = V^{\mathbb{R}} + W^{\mathbb{R}} = 42.6 + 15.2 = 57.8 10 V W X k X[k] = V[k] F \mathbb{Z} F(k) = 0 k F(k) = 0 k > 0 F(k) = 1 k \geq 0 W = (""+"", F(k)) W = \dots 101010101 \dots 10101.00000 \dots 0000 \dots 500 \pi W + 500 + \pi = \dots 101010101 \dots 1010604.14519 \dots [\text{ more digits of } \pi] \dots k^{\text{th}} V + W V p W p \forall k, p \in \mathbb{Z} \forall V, W \in \mathbb{W} (V + W)[k] = T(V, p)[k] + T(W, p)[k] T V k T(V, k)[z] = V[z] z \in \mathbb{Z} z \leq k T(V, k)[z] = 0 z \in \mathbb{Z} z > k T(V, k) V \forall V, W \in \mathbb{W} V W \exists X \in \mathbb{W} X V = X + V^{\prime} W = X + W^{\prime} V^{\prime} W^{\prime} V + W = (2*X) + (V^{\prime} + W^{\prime}) (2*X) (V^{\prime} + W^{\prime}) (2*X) X X \mathbb{Z} \begin{Bmatrix} 0, 1\end{Bmatrix} \forall k \in (2*X)(k) = X(k - 1) \mathbb{W} 10^{k} k","['sequences-and-series', 'number-theory', 'real-numbers', 'decimal-expansion', 'combinatorics-on-words']"
16,What are the possible values of $\lim\limits_{n\to\infty} \prod_{i=1}^n (1+ y_i^{\frac 1n}/n)$?,What are the possible values of ?,\lim\limits_{n\to\infty} \prod_{i=1}^n (1+ y_i^{\frac 1n}/n),"For any sequence $(y_i)_{i=1}^\infty$ of positive real numbers, let $(X_n)_{n=1}^\infty$ be another sequence defined by $$X_n = \prod_{i=1}^n \left(1+\frac{y_i^{\frac{1}{n}}}{n}\right).$$ It is clear that $X_n >1$ for all $n$ . Question: For any $c\ge 1$ , can one find a sequence $(y_i)$ of positive real numbers such that $\left(X_n\right)$ converges to $c$ as $n\to \infty$ ? In an answer to a previous question , it is shown that if $y_i, y_i^{-1}$ grows slower than polynomials, then the limit of $(X_n)$ is always $e$ . There are also simple examples $\left(y_i = \left(i^2\right)^i\right)$ which shows that $(X_n)$ might be unbounded. Some remarks: One can find $(y_i)$ such that $(X_n)$ is bounded, but has no limit (this can be done by choosing $y_i$ to be $1$ most of the time, and a huge number once in a while), Changing finitely many members of $(y_i)$ do not alter the limit of $(X_n)$ . Think of $(y_i)$ as a function $y: \mathbb N \to (0,\infty)$ . Then $f_n : \mathbb N \to (0,\infty)$ defined by $f_n(i) = y_i^{1/n}$ is a sequence of functions which converges pointwisely to the constant function $1$ . If the convergence is uniform, then limit of $(X_n)$ exists, but again the limit is $e$ .","For any sequence of positive real numbers, let be another sequence defined by It is clear that for all . Question: For any , can one find a sequence of positive real numbers such that converges to as ? In an answer to a previous question , it is shown that if grows slower than polynomials, then the limit of is always . There are also simple examples which shows that might be unbounded. Some remarks: One can find such that is bounded, but has no limit (this can be done by choosing to be most of the time, and a huge number once in a while), Changing finitely many members of do not alter the limit of . Think of as a function . Then defined by is a sequence of functions which converges pointwisely to the constant function . If the convergence is uniform, then limit of exists, but again the limit is .","(y_i)_{i=1}^\infty (X_n)_{n=1}^\infty X_n = \prod_{i=1}^n \left(1+\frac{y_i^{\frac{1}{n}}}{n}\right). X_n >1 n c\ge 1 (y_i) \left(X_n\right) c n\to \infty y_i, y_i^{-1} (X_n) e \left(y_i = \left(i^2\right)^i\right) (X_n) (y_i) (X_n) y_i 1 (y_i) (X_n) (y_i) y: \mathbb N \to (0,\infty) f_n : \mathbb N \to (0,\infty) f_n(i) = y_i^{1/n} 1 (X_n) e","['real-analysis', 'sequences-and-series', 'limits']"
17,Application of uniform bounded principle,Application of uniform bounded principle,,Let $(a_n)_{n∈N}$ be a sequence of real numbers. Show that the series $∑_{n=1} ^{\infty} |a_n− a_{n+1}|$ converges if and only if the series $∑_{n=1}^{\infty} a_nb_n$ converges for every convergent series $∑_{n=1}^{\infty}b_n$ in $\mathbb{R}$ . It is an application of uniform bounded principle. Can anyone give me some hint how to approach this problem.,Let be a sequence of real numbers. Show that the series converges if and only if the series converges for every convergent series in . It is an application of uniform bounded principle. Can anyone give me some hint how to approach this problem.,"(a_n)_{n∈N} ∑_{n=1}
^{\infty} |a_n−
a_{n+1}| ∑_{n=1}^{\infty} a_nb_n ∑_{n=1}^{\infty}b_n \mathbb{R}","['real-analysis', 'sequences-and-series', 'functional-analysis']"
18,"How to determine summability of ""nested series""","How to determine summability of ""nested series""",,"Consider some non-negative sequences $a_n, b_n, c_n,$ etc. Suppose I have a ""nested series"" (not sure proper terminology) $$\sum_{k = 1}^\infty a_k \sum_{j = 1}^k  b_j   \sum_{i = j}^k c_i$$ etc etc. How should I go about determining the summability of this series? Of course the first approach is to evaluate the inner term and work outwards...but is there a simpler way? Suppose I know the summability of $a_k, b_k, c_k$ (e.g., summable, non summable, summable or non-summable, summable, summable). Is there a fast way of determining if the overall series is summable? Any book that investigate these type of series would help :)","Consider some non-negative sequences etc. Suppose I have a ""nested series"" (not sure proper terminology) etc etc. How should I go about determining the summability of this series? Of course the first approach is to evaluate the inner term and work outwards...but is there a simpler way? Suppose I know the summability of (e.g., summable, non summable, summable or non-summable, summable, summable). Is there a fast way of determining if the overall series is summable? Any book that investigate these type of series would help :)","a_n, b_n, c_n, \sum_{k = 1}^\infty a_k \sum_{j = 1}^k  b_j   \sum_{i = j}^k c_i a_k, b_k, c_k","['real-analysis', 'sequences-and-series', 'reference-request', 'summation', 'terminology']"
19,Let $\sum_{n=1}^\infty a_n<\infty$. Then $\prod_{n=1}^\infty(1+a_n x)$ is subexponential in $x$.,Let . Then  is subexponential in .,\sum_{n=1}^\infty a_n<\infty \prod_{n=1}^\infty(1+a_n x) x,"In the process of trying to prove an estimate precluding blowup of a PDE, I have come across this problem. Suppose we are given an absolutely convergent sum, $\sum_{n=1}^\infty a_n<\infty$ , with $a_n\ge0$ . I claim that the function $$ F(x) = \prod_{n=1}^\infty (1+a_n x) $$ is sub-exponential in $x$ , that is, $$ \lim_{x\to+\infty} F(x) e^{-cx}=0 $$ for all $c>0$ . For $a_n$ non-terminating, $F(x)$ is of course super-polynomial. Furthermore, the bound $1+a_n x\le e^{a_n x}$ gives us $$ F(x) = \prod_{n=1}^\infty (1+a_n x)\le e^{\sum_{n=1}^\infty a_n x},\qquad x\ge0 $$ so $F(x)$ grows at most exponentially. However, I have yet to find a better bound on $F(x)$ . Can we prove that $F(x)$ is in fact sub-exponential? As an example of such an $F$ , we consider the identity $$ \prod_{n=1}^\infty \left( 1+\frac{x}{n^2} \right) = \frac{\sinh(\pi\sqrt x)}{\pi\sqrt x} $$ which can be derived from Euler's infinite product representation of the sine function .","In the process of trying to prove an estimate precluding blowup of a PDE, I have come across this problem. Suppose we are given an absolutely convergent sum, , with . I claim that the function is sub-exponential in , that is, for all . For non-terminating, is of course super-polynomial. Furthermore, the bound gives us so grows at most exponentially. However, I have yet to find a better bound on . Can we prove that is in fact sub-exponential? As an example of such an , we consider the identity which can be derived from Euler's infinite product representation of the sine function .","\sum_{n=1}^\infty a_n<\infty a_n\ge0 
F(x) = \prod_{n=1}^\infty (1+a_n x)
 x 
\lim_{x\to+\infty} F(x) e^{-cx}=0
 c>0 a_n F(x) 1+a_n x\le e^{a_n x} 
F(x) = \prod_{n=1}^\infty (1+a_n x)\le e^{\sum_{n=1}^\infty a_n x},\qquad x\ge0
 F(x) F(x) F(x) F 
\prod_{n=1}^\infty \left( 1+\frac{x}{n^2} \right) = \frac{\sinh(\pi\sqrt x)}{\pi\sqrt x}
","['real-analysis', 'sequences-and-series', 'partial-differential-equations', 'asymptotics']"
20,"If $\sin(n!\, x)\to 0$ as $n\to +\infty$, is then $x$ inevitably a rational multiple of $\pi$?","If  as , is then  inevitably a rational multiple of ?","\sin(n!\, x)\to 0 n\to +\infty x \pi","If $x$ is a rational multiple of $\pi$ , for a natural number $N$ big enough $\sin(n!\,x) = 0$ for all $n\geqslant N$ and then $\sin(n!\,x)\to 0$ as $n\to +\infty$ . However, I'm not so sure about the converse anymore: If it holds that $\sin(n!\,x)\to 0$ as $n\to +\infty$ , does it necessarily follow that $x$ belongs to $\pi\mathbf{Q}$ ?","If is a rational multiple of , for a natural number big enough for all and then as . However, I'm not so sure about the converse anymore: If it holds that as , does it necessarily follow that belongs to ?","x \pi N \sin(n!\,x) = 0 n\geqslant N \sin(n!\,x)\to 0 n\to +\infty \sin(n!\,x)\to 0 n\to +\infty x \pi\mathbf{Q}","['real-analysis', 'sequences-and-series', 'limits', 'trigonometric-series']"
21,Collatz conjecture but with $\ 3n-1\ $ instead of $\ 3n+1.\ $ Do any sequences go off to $\ +\infty\ $?,Collatz conjecture but with  instead of  Do any sequences go off to ?,\ 3n-1\  \ 3n+1.\  \ +\infty\ ,"Collatz conjecture but with $\ 3n-1\ $ instead of $\ 3n+1.\ $ Do any sequences go off to $\ +\infty\ $ ? $$$$ Background (not necessary to answer my question): Considering the following operation on an arbitrary positive integer: If the number is even, divide it by two. If the number is odd, triple it and add one. The Collatz conjecture is: This process will eventually reach the number $1$ , regardless of which positive integer is chosen initially. If the Collatz conjecture is false, then either there will be cycles that don't contain the number $\ 1,\ $ or there will be a (at least one) sequence that goes off to $\ +\infty.$ My question: Considering the following operation on an arbitrary positive integer: If the number is even, divide it by two. If the number is odd, triple it and take away one. An analogue to the Collatz conjecture with these rules fails, because $\ 5\to 14\to 7\to 20\to 10\to\ 5\ $ is a cycle that does not contain $\ 1.\ $ In fact, there are lots of cycles that don't contain $\ 1\ $ that I found with the Python code below. My question is do any sequences with this $\ 3n-1\ $ rule go off to $\ +\infty,\ $ or not? It seems ""less likely"" than the likelihood Collatz sequences will go off to $\ +\infty,\ $ but proving such a thing seems hard. Edit: I have checked all numbers up to $\ 5000\ $ using the code below and every sequence either goes to $\ 1\ $ or is in a loop. Also, there are no really long sequences (relative to number size) as opposed to some small starting numbers in the Collatz conjecture, like $\ n=27,\ $ which has $\ 111\ $ steps. This seems to suggest that no sequence goes off to infinity, and there should be some (relatively simple?) number theory proof for this. $$$$ def collatz2(n):     if n % 2 == 0: return int(n/2)     else:          return 3*n-1  def collatz_sequence2(n):     sequence = [n]     while n != 1:         n = collatz2(n)         sequence += [n]         if n in sequence[:-1]:             print(sequence[0], ""is in a loop not containing 1:"",)             break     return sequence  for i in range(1,100):     print(i, ':', collatz_sequence2(i))","Collatz conjecture but with instead of Do any sequences go off to ? Background (not necessary to answer my question): Considering the following operation on an arbitrary positive integer: If the number is even, divide it by two. If the number is odd, triple it and add one. The Collatz conjecture is: This process will eventually reach the number , regardless of which positive integer is chosen initially. If the Collatz conjecture is false, then either there will be cycles that don't contain the number or there will be a (at least one) sequence that goes off to My question: Considering the following operation on an arbitrary positive integer: If the number is even, divide it by two. If the number is odd, triple it and take away one. An analogue to the Collatz conjecture with these rules fails, because is a cycle that does not contain In fact, there are lots of cycles that don't contain that I found with the Python code below. My question is do any sequences with this rule go off to or not? It seems ""less likely"" than the likelihood Collatz sequences will go off to but proving such a thing seems hard. Edit: I have checked all numbers up to using the code below and every sequence either goes to or is in a loop. Also, there are no really long sequences (relative to number size) as opposed to some small starting numbers in the Collatz conjecture, like which has steps. This seems to suggest that no sequence goes off to infinity, and there should be some (relatively simple?) number theory proof for this. def collatz2(n):     if n % 2 == 0: return int(n/2)     else:          return 3*n-1  def collatz_sequence2(n):     sequence = [n]     while n != 1:         n = collatz2(n)         sequence += [n]         if n in sequence[:-1]:             print(sequence[0], ""is in a loop not containing 1:"",)             break     return sequence  for i in range(1,100):     print(i, ':', collatz_sequence2(i))","\ 3n-1\  \ 3n+1.\  \ +\infty\   1 \ 1,\  \ +\infty. \ 5\to 14\to 7\to 20\to 10\to\ 5\  \ 1.\  \ 1\  \ 3n-1\  \ +\infty,\  \ +\infty,\  \ 5000\  \ 1\  \ n=27,\  \ 111\  ","['sequences-and-series', 'number-theory', 'collatz-conjecture']"
22,"Convergence of a sequence in $(C[0,1])^*$",Convergence of a sequence in,"(C[0,1])^*","I would like to determine if the following sequence of linear functionals on $C[0,1]$ converges weakly (i.e. pointwise) and strongly (with respect to the norm) $$ \phi_n(f)=\int\limits_{0}^{1}(nt^2-[nt^2])f(t)dt,$$ where $[x]$ means greatest integer that is less than or equal to $x$ . I do not know how to investigate this question. Thanks in advance for your help.",I would like to determine if the following sequence of linear functionals on converges weakly (i.e. pointwise) and strongly (with respect to the norm) where means greatest integer that is less than or equal to . I do not know how to investigate this question. Thanks in advance for your help.,"C[0,1]  \phi_n(f)=\int\limits_{0}^{1}(nt^2-[nt^2])f(t)dt, [x] x","['sequences-and-series', 'functional-analysis', 'definite-integrals']"
23,A Fibonacci conjecture: $\frac{n-1}{n}<\log_{F_{n+1}}{F_n}<\frac{n}{n+1}$.,A Fibonacci conjecture: .,\frac{n-1}{n}<\log_{F_{n+1}}{F_n}<\frac{n}{n+1},"Given the Fibonacci sequence $F_n$ , that is $$ F_0=F_1=1,F_{n+2}=F_{n+1}+F_n. $$ Then we have the sequence $\{\log_{F_{n+1}}{F_n}\}$ is increasing. for any $n\geqslant2$ , $$ \frac{n-1}{n}<\log_{F_{n+1}}{F_n}<\frac{n}{n+1}. $$ In fact, I have tried to prove $(1)$ in a simple way, but failed. (See this previous question .) Because when $n$ is odd, the inequality $\frac{\ln F_n}{\ln F_{n+1}}<\frac{\ln F_{n+1}}{\ln F_{n+2}}\ $ is easy to get by using AM-GM inequality and Cassini's identity; when $n$ is even, things will be very different. As for $(2)$ , I have no idea how to prove it, except for using Binet's formula.","Given the Fibonacci sequence , that is Then we have the sequence is increasing. for any , In fact, I have tried to prove in a simple way, but failed. (See this previous question .) Because when is odd, the inequality is easy to get by using AM-GM inequality and Cassini's identity; when is even, things will be very different. As for , I have no idea how to prove it, except for using Binet's formula.","F_n 
F_0=F_1=1,F_{n+2}=F_{n+1}+F_n.
 \{\log_{F_{n+1}}{F_n}\} n\geqslant2 
\frac{n-1}{n}<\log_{F_{n+1}}{F_n}<\frac{n}{n+1}.
 (1) n \frac{\ln F_n}{\ln F_{n+1}}<\frac{\ln F_{n+1}}{\ln F_{n+2}}\  n (2)","['sequences-and-series', 'inequality', 'fibonacci-numbers']"
24,Limit of a real sequence [closed],Limit of a real sequence [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Let $$x_{n}=\frac{1}{n+2^{0}}+\frac{1}{n+2^{1}}+...+\frac{1}{n+2^{n}}\quad (n\in\mathbb{N}, \text{ }n\geq 1).$$ What is the limit of $x_n$ ? Attempt: Just the boundedness, $x_n∈(0,2)$ , $\forall n\geq 1$ . Can not even determine the monotonicity.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Let What is the limit of ? Attempt: Just the boundedness, , . Can not even determine the monotonicity.","x_{n}=\frac{1}{n+2^{0}}+\frac{1}{n+2^{1}}+...+\frac{1}{n+2^{n}}\quad (n\in\mathbb{N}, \text{ }n\geq 1). x_n x_n∈(0,2) \forall n\geq 1","['sequences-and-series', 'limits']"
25,How to find $\lim_{x\to 0^+}\sum_{n=1}^\infty\sin(\sqrt{n})e^{-nx}$,How to find,\lim_{x\to 0^+}\sum_{n=1}^\infty\sin(\sqrt{n})e^{-nx},"$$ \mbox{Let}\ \operatorname{S}\left(x\right) = \sum_{n = 1}^{\infty}\sin\left(\,\sqrt{\,{n}\,}\,\right) {\rm e}^{-nx},\quad \forall x > 0 $$ $\operatorname{S}\left(x\right)$ exists $\forall x > 0$ $\left(~\left\vert\,\sin\left(\sqrt{n}\right) {\rm e}^{-nx}\,\right\vert \leq {\rm e}^{-nx}\ \mbox{and}\ \sum{\rm e}^{-nx}\ \mbox{geometric series}~\right)$ I wonder if the limit $\displaystyle\lim_{x \to 0^{+}}\,\,\operatorname{S}\left(x\right)$ exists and how to calculate it. I don't see , if it's useful, how to use $\displaystyle\int_{0}^{\infty}\sin(\,\sqrt{\,{t}\,}\,){\rm e}^{-pt} \,{\rm d}t = \frac{{\rm e}^{-1/\left(4p\right)}}{2p}\,\sqrt{\frac{\pi}{p}}$","exists I wonder if the limit exists and how to calculate it. I don't see , if it's useful, how to use","
\mbox{Let}\ \operatorname{S}\left(x\right) =
\sum_{n = 1}^{\infty}\sin\left(\,\sqrt{\,{n}\,}\,\right)
{\rm e}^{-nx},\quad \forall x > 0
 \operatorname{S}\left(x\right) \forall x > 0 \left(~\left\vert\,\sin\left(\sqrt{n}\right)
{\rm e}^{-nx}\,\right\vert \leq {\rm e}^{-nx}\ \mbox{and}\ \sum{\rm e}^{-nx}\ \mbox{geometric series}~\right) \displaystyle\lim_{x \to 0^{+}}\,\,\operatorname{S}\left(x\right) \displaystyle\int_{0}^{\infty}\sin(\,\sqrt{\,{t}\,}\,){\rm e}^{-pt}
\,{\rm d}t =
\frac{{\rm e}^{-1/\left(4p\right)}}{2p}\,\sqrt{\frac{\pi}{p}}","['calculus', 'sequences-and-series', 'limits']"
26,Extending $\sum_{n=0}^\infty s^{n^2}$ beyond its natural boundary,Extending  beyond its natural boundary,\sum_{n=0}^\infty s^{n^2},"Let $\mathbb{D} = \{s \in \mathbb{C} : |s| < 1\}$ . Let $f : \mathbb{D} \rightarrow \mathbb{C}$ where $$ f(s) = \sum_{n=0}^\infty s^{n^2} $$ $f$ is analytic on $\mathbb{D}$ . This is what it looks like: $\partial \mathbb{D}$ is a natural boundary , so ordinary analytic continuation cannot extend $f$ beyond $\mathbb{D}$ . However, there might be another way to extend $f$ beyond $\mathbb{D}$ that is both aesthetically natural and yields a unique result. For example, see generalized analytic continuation and Continuation of functions beyond natural boundaries . Let $$ \Delta = \left\{\exp \left( 2\pi i \frac{2n + 1}{4m + 2} \right) : m, n \in \mathbb{Z}\right\} \subseteq \partial \mathbb{D} $$ Note that $\Delta$ is dense . It seems that \begin{align}     \lim_{\substack{s \rightarrow \omega \\ s \in \mathbb{D}}} f(s) &= \frac{1}{2} \\     \lim_{r \uparrow 1} \partial_r f(r \omega) &= 0 \end{align} for all $\omega \in \Delta$ . I have 2 questions: Are there other $\omega \in \partial \mathbb{D} \setminus \Delta$ for which the above limits exist? Is there an analytic (or meromorphic) $g : \mathbb{C} \setminus \overline{\mathbb{D}} \rightarrow \mathbb{C}$ such that \begin{align}     \lim_{\substack{s \rightarrow \omega \\ s \in \mathbb{C} \setminus \overline{\mathbb{D}}}} g(s) &= \lim_{\substack{s \rightarrow \omega \\ s \in \mathbb{D}}} f(s) \\     \lim_{r \downarrow 1} \partial_r g(r \omega) &= \lim_{r \uparrow 1} \partial_r f(r \omega) \end{align} for all $\omega \in \partial \mathbb{D}$ such that both sides are defined, and such that the LHS is undefined iff the RHS is undefined? That is, such that $g$ “matches” $f$ along $\partial \mathbb{D}$ , in some sense? If so, is it unique? If not, are there additional conditions, perhaps some analogue of the identity theorem , that can give us a unique extension?","Let . Let where is analytic on . This is what it looks like: is a natural boundary , so ordinary analytic continuation cannot extend beyond . However, there might be another way to extend beyond that is both aesthetically natural and yields a unique result. For example, see generalized analytic continuation and Continuation of functions beyond natural boundaries . Let Note that is dense . It seems that for all . I have 2 questions: Are there other for which the above limits exist? Is there an analytic (or meromorphic) such that for all such that both sides are defined, and such that the LHS is undefined iff the RHS is undefined? That is, such that “matches” along , in some sense? If so, is it unique? If not, are there additional conditions, perhaps some analogue of the identity theorem , that can give us a unique extension?","\mathbb{D} = \{s \in \mathbb{C} : |s| < 1\} f : \mathbb{D} \rightarrow \mathbb{C}  f(s) = \sum_{n=0}^\infty s^{n^2}  f \mathbb{D} \partial \mathbb{D} f \mathbb{D} f \mathbb{D}  \Delta = \left\{\exp \left( 2\pi i \frac{2n + 1}{4m + 2} \right) : m, n \in \mathbb{Z}\right\} \subseteq \partial \mathbb{D}  \Delta \begin{align}
    \lim_{\substack{s \rightarrow \omega \\ s \in \mathbb{D}}} f(s) &= \frac{1}{2} \\
    \lim_{r \uparrow 1} \partial_r f(r \omega) &= 0
\end{align} \omega \in \Delta \omega \in \partial \mathbb{D} \setminus \Delta g : \mathbb{C} \setminus \overline{\mathbb{D}} \rightarrow \mathbb{C} \begin{align}
    \lim_{\substack{s \rightarrow \omega \\ s \in \mathbb{C} \setminus \overline{\mathbb{D}}}} g(s) &= \lim_{\substack{s \rightarrow \omega \\ s \in \mathbb{D}}} f(s) \\
    \lim_{r \downarrow 1} \partial_r g(r \omega) &= \lim_{r \uparrow 1} \partial_r f(r \omega)
\end{align} \omega \in \partial \mathbb{D} g f \partial \mathbb{D}","['sequences-and-series', 'complex-analysis', 'power-series', 'analytic-continuation', 'lacunary-series']"
27,Polynomial such that $e^{2i\pi P(n)} \rightarrow 1$,Polynomial such that,e^{2i\pi P(n)} \rightarrow 1,"here is a  problem i’ve been having quite a lot of trouble with . Let $P$ be a polynomial such that the sequence $e^{2i\pi P(n)}$ converges to 1 $(i^2=-1).$ Show that $\forall n ,P(n)$ is an integer. Taking the imaginary part we are left with some $P$ polynomial such that $$\sin(2\pi P(n))\rightarrow0$$ But a half angle factorization also gives  that: $$\sin(\pi P(n))\rightarrow 0$$ And we wish to force P to , i guess even if it’s not equivalent, to have only integers coefficients. May you help me please.","here is a  problem i’ve been having quite a lot of trouble with . Let be a polynomial such that the sequence converges to 1 Show that is an integer. Taking the imaginary part we are left with some polynomial such that But a half angle factorization also gives  that: And we wish to force P to , i guess even if it’s not equivalent, to have only integers coefficients. May you help me please.","P e^{2i\pi P(n)} (i^2=-1). \forall n ,P(n) P \sin(2\pi P(n))\rightarrow0 \sin(\pi P(n))\rightarrow 0","['real-analysis', 'sequences-and-series', 'polynomials', 'integers', 'periodic-functions']"
28,Convergence of $\sum \frac{ \cos\sqrt n} {\sqrt n}$,Convergence of,\sum \frac{ \cos\sqrt n} {\sqrt n},"As you undestand from the topic title, I am wondering how to determine whether the series $$ \sum_{n=1}^{\infty} \frac{ \cos\sqrt n} {\sqrt n} $$ converges or not(it diverges actually). You know, the problem is, if it would be something like $$ \sum_{n=1}^{\infty} \frac{ \cos n} {\sqrt n} $$ Then the task can be easily solved using Dirichlet's test: we just need to show that $|\sum_{n=1}^{N} \cos n| \le K$ for all $N$ having fixed $K$ . This was described here Also, if it was like $$ \sum_{n=1}^{\infty} \frac{ \cos\sqrt n} {n} $$ then we are in much more complicated situation. Every reasonable solution I found on the internet involves approximating the series with an integral. This type of task implies very cute mathematical background(which I don't have:)) In my school we didn't study improper integrals(even just integrals). And actually our problem distincts from two others described above: $$ \sum_{n=1}^{\infty} \frac{ \cos\sqrt n} {\sqrt n} $$ This is why I believe there must be a solution which is simpler than using improper integrals. We studied lots of different convergence tests at school, but they seems useless here. Well, actually I think we should apply them, but after some mathematical magic. Also I tried to expand terms using Taylor's formula, but it didn't help. Any ideas?","As you undestand from the topic title, I am wondering how to determine whether the series converges or not(it diverges actually). You know, the problem is, if it would be something like Then the task can be easily solved using Dirichlet's test: we just need to show that for all having fixed . This was described here Also, if it was like then we are in much more complicated situation. Every reasonable solution I found on the internet involves approximating the series with an integral. This type of task implies very cute mathematical background(which I don't have:)) In my school we didn't study improper integrals(even just integrals). And actually our problem distincts from two others described above: This is why I believe there must be a solution which is simpler than using improper integrals. We studied lots of different convergence tests at school, but they seems useless here. Well, actually I think we should apply them, but after some mathematical magic. Also I tried to expand terms using Taylor's formula, but it didn't help. Any ideas?","
\sum_{n=1}^{\infty} \frac{ \cos\sqrt n} {\sqrt n}
 
\sum_{n=1}^{\infty} \frac{ \cos n} {\sqrt n}
 |\sum_{n=1}^{N} \cos n| \le K N K 
\sum_{n=1}^{\infty} \frac{ \cos\sqrt n} {n}
 
\sum_{n=1}^{\infty} \frac{ \cos\sqrt n} {\sqrt n}
","['real-analysis', 'calculus', 'sequences-and-series', 'convergence-divergence']"
29,How to calculate the limit of zeta function,How to calculate the limit of zeta function,,"Suppose $f(x)>0$ , $f''(x)\leqslant0$ ,and $\lim\limits_{x\to+\infty}f(x)=+\infty$ on $[0,+\infty)$ .prove that $$\lim\limits_{s\to0^+}\sum\limits_{n=0}^{\infty}\dfrac{(-1)^n}{f^s(n)}=\frac{1}{2}.$$ I tried to do it ,first of all we have $$\sum\limits_{n=0}^{\infty} \frac{(-1)^n}{f^s(n)}=\sum\limits_{n=0}^{\infty} \left( \frac{1}{f^s(2n)}-\frac{1}{f^s(2n+1)} \right).$$ Use MVT we have $$ \frac{1}{f^s(2n)}-\frac{1}{f^s(2n+1)}=-\frac{sf'(\xi_n)}{f^{s+1}(\xi_n)}(\xi_n\in(2n,2n+1)).$$ But next, I don't know how to deal with it. I want to ask that this problem can be solved by the property that the function is concave.","Suppose , ,and on .prove that I tried to do it ,first of all we have Use MVT we have But next, I don't know how to deal with it. I want to ask that this problem can be solved by the property that the function is concave.","f(x)>0 f''(x)\leqslant0 \lim\limits_{x\to+\infty}f(x)=+\infty [0,+\infty) \lim\limits_{s\to0^+}\sum\limits_{n=0}^{\infty}\dfrac{(-1)^n}{f^s(n)}=\frac{1}{2}. \sum\limits_{n=0}^{\infty} \frac{(-1)^n}{f^s(n)}=\sum\limits_{n=0}^{\infty} \left( \frac{1}{f^s(2n)}-\frac{1}{f^s(2n+1)} \right).  \frac{1}{f^s(2n)}-\frac{1}{f^s(2n+1)}=-\frac{sf'(\xi_n)}{f^{s+1}(\xi_n)}(\xi_n\in(2n,2n+1)).","['real-analysis', 'sequences-and-series', 'limits']"
30,Proving or disproving basic facts about infinite series,Proving or disproving basic facts about infinite series,,"I am self-learning Real Analysis from Understanding Analysis by Stephen Abott. I'd like to ask, if my proof to the below question on convergence of infinite series is rigorous and sufficient, and checks out. $\newcommand{\absval}[1]{\left\lvert #1 \right\rvert}$ Give an example of each or explain why the request is impossible referencing the proper theorem(s). (a) Two series $\sum {x_n}$ and $\sum{y_n}$ that both diverge but where $\sum x_n y_n$ converges. (b) A convergent series $\sum x_n$ and a bounded sequence $(y_n)$ such that $\sum x_n y_n$ diverges. (c) Two sequences $(x_n)$ and $(y_n)$ where $\sum x_n$ and $\sum (x_n + y_n)$ both converge but $\sum y_n$ diverges. (d) A sequence $(x_n)$ satisfying $0 \le x_n \le 1/n$ where $\sum (-1)^n x_n$ diverges. Proof. (a) The simplest examples I could come up with are: (i) $\sum x_n = \sum_{n=1}^{\infty}\frac{1}{n}$ and $\sum y_n = \sum_{n=1}^{\infty}\frac{1}{n}$ are both divergent sequences, but $\sum_{n=1}^{\infty}\frac{1}{n^2}$ is convergent. (ii) $\sum x_n = \sum_{n=1}^{\infty}\frac{1}{n}$ and $\sum y_n = \sum_{n=1}^{\infty}\frac{1}{n+1}$ are both divergent sequences, but $\sum_{n=1}^{\infty}\frac{1}{n(n+1)}$ is convergent. To see that $\sum_{n=1}^{\infty}\frac{1}{n(n+1)}$ is convergent, we simply note that $\sum_{n=1}^{\infty}\frac{1}{n^p}$ is convergent for $p > 1$ , so $\sum_{n=1}^{\infty}\frac{1}{n^2}$ is convergent. And $\frac{1}{n(n+1)} < \frac{1}{n^2}$ , so by the Comparison test, $\sum_{n=1}^{\infty}\frac{1}{n(n+1)}$ is convergent. (b) I think that this request is impossible. The series $\sum x_n$ is convergent. By the Cauchy Criterion, given any $\epsilon > 0$ , there exists $N \in\mathbf{N}$ , such that \begin{align*} 	\absval{x_{m+1} + x_{m+2} + \ldots + x_{n}} < \frac{\epsilon}{M} \end{align*} for $n > m \ge N$ . Also, the sequence $(y_n)$ is bounded, so $\absval{y_n} \le M$ for all $n\in\mathbf{N}$ . Consider the expression $\absval{x_{m+1}y_{m+1} + \ldots + x_{n}y_{n}}$ . We can write, \begin{align*} 	\absval{x_{m+1}y_{m+1} + \ldots + x_{n}y_{n}} &\le \absval{x_{m+1}\absval{y_{m+1}} + \ldots + x_{n}\absval{y_{n}}}\\ 	&\le \absval{x_{m+1}M + \ldots + x_{n}M}\\ 	&=M \absval{x_{m+1} + \ldots + x_{n}}\\ 	&<M \cdot \frac{\epsilon}{M} = \epsilon \end{align*} So, by the Cauchy criterion, $\sum x_n y_n$ is a convergent series. (c) This request is impossible. By the Algebraic Limit Theorem, if $\sum (x_n + y_n)$ converges and $\sum y_n$ converges, then $\sum (x_n + y_n) - \sum (y_n) = \sum x_n$ is also convergent. (d) I think that this request is impossible as well. We know that $\sum_{n=1}^{\infty} \frac{(-1)^n}{n}$ converges. I have a hunch, that the the alternating series $\sum_{n=1}^{\infty}(-1)^n x_n$ is always bound by $\sum_{n=1}^{\infty}(-1)^n /n$ . By the Algebraic Limit theorem, $\lim_{n \to \infty} 0 \le \lim_{n \to \infty} \le \lim_{n \to \infty} \frac{1}{n}$ , so $\lim_{n \to \infty}x_n = 0$ . I would like to show that $(x_n)$ is a decreasing sequence.","I am self-learning Real Analysis from Understanding Analysis by Stephen Abott. I'd like to ask, if my proof to the below question on convergence of infinite series is rigorous and sufficient, and checks out. Give an example of each or explain why the request is impossible referencing the proper theorem(s). (a) Two series and that both diverge but where converges. (b) A convergent series and a bounded sequence such that diverges. (c) Two sequences and where and both converge but diverges. (d) A sequence satisfying where diverges. Proof. (a) The simplest examples I could come up with are: (i) and are both divergent sequences, but is convergent. (ii) and are both divergent sequences, but is convergent. To see that is convergent, we simply note that is convergent for , so is convergent. And , so by the Comparison test, is convergent. (b) I think that this request is impossible. The series is convergent. By the Cauchy Criterion, given any , there exists , such that for . Also, the sequence is bounded, so for all . Consider the expression . We can write, So, by the Cauchy criterion, is a convergent series. (c) This request is impossible. By the Algebraic Limit Theorem, if converges and converges, then is also convergent. (d) I think that this request is impossible as well. We know that converges. I have a hunch, that the the alternating series is always bound by . By the Algebraic Limit theorem, , so . I would like to show that is a decreasing sequence.","\newcommand{\absval}[1]{\left\lvert #1 \right\rvert} \sum {x_n} \sum{y_n} \sum x_n y_n \sum x_n (y_n) \sum x_n y_n (x_n) (y_n) \sum x_n \sum (x_n + y_n) \sum y_n (x_n) 0 \le x_n \le 1/n \sum (-1)^n x_n \sum x_n = \sum_{n=1}^{\infty}\frac{1}{n} \sum y_n = \sum_{n=1}^{\infty}\frac{1}{n} \sum_{n=1}^{\infty}\frac{1}{n^2} \sum x_n = \sum_{n=1}^{\infty}\frac{1}{n} \sum y_n = \sum_{n=1}^{\infty}\frac{1}{n+1} \sum_{n=1}^{\infty}\frac{1}{n(n+1)} \sum_{n=1}^{\infty}\frac{1}{n(n+1)} \sum_{n=1}^{\infty}\frac{1}{n^p} p > 1 \sum_{n=1}^{\infty}\frac{1}{n^2} \frac{1}{n(n+1)} < \frac{1}{n^2} \sum_{n=1}^{\infty}\frac{1}{n(n+1)} \sum x_n \epsilon > 0 N \in\mathbf{N} \begin{align*}
	\absval{x_{m+1} + x_{m+2} + \ldots + x_{n}} < \frac{\epsilon}{M}
\end{align*} n > m \ge N (y_n) \absval{y_n} \le M n\in\mathbf{N} \absval{x_{m+1}y_{m+1} + \ldots + x_{n}y_{n}} \begin{align*}
	\absval{x_{m+1}y_{m+1} + \ldots + x_{n}y_{n}} &\le \absval{x_{m+1}\absval{y_{m+1}} + \ldots + x_{n}\absval{y_{n}}}\\
	&\le \absval{x_{m+1}M + \ldots + x_{n}M}\\
	&=M \absval{x_{m+1} + \ldots + x_{n}}\\
	&<M \cdot \frac{\epsilon}{M} = \epsilon
\end{align*} \sum x_n y_n \sum (x_n + y_n) \sum y_n \sum (x_n + y_n) - \sum (y_n) = \sum x_n \sum_{n=1}^{\infty} \frac{(-1)^n}{n} \sum_{n=1}^{\infty}(-1)^n x_n \sum_{n=1}^{\infty}(-1)^n /n \lim_{n \to \infty} 0 \le \lim_{n \to \infty} \le \lim_{n \to \infty} \frac{1}{n} \lim_{n \to \infty}x_n = 0 (x_n)","['real-analysis', 'sequences-and-series', 'convergence-divergence', 'solution-verification']"
31,Confused on what a series means.,Confused on what a series means.,,"I have been reading the book Relativity: The special & General Theory where in chapter XV, the author develops the expression of kinetic energy $$ \frac{1}{2} mv^2 $$ or $$ \text{ }m\frac{v^2}{2} $$ in the form of a series, $$ mc^2+\text{ }m\frac{v^2}{2}+\frac{3}{8}m\frac{v^4}{c^2}+... $$ Can someone explain to me what a series is? Or at the very least show me where I can find more information about this? Thank you.","I have been reading the book Relativity: The special & General Theory where in chapter XV, the author develops the expression of kinetic energy or in the form of a series, Can someone explain to me what a series is? Or at the very least show me where I can find more information about this? Thank you.","
\frac{1}{2} mv^2
 
\text{ }m\frac{v^2}{2}
 
mc^2+\text{ }m\frac{v^2}{2}+\frac{3}{8}m\frac{v^4}{c^2}+...
",[]
32,Proving $a_n = \sum_{k=1}^{n}\frac1{k}\sin(\frac{k\pi}{n+1})$ is increasing,Proving  is increasing,a_n = \sum_{k=1}^{n}\frac1{k}\sin(\frac{k\pi}{n+1}),"Is the sequence $a_n = \sum_{k=1}^{n}\frac1{k}\sin(\frac{k\pi}{n+1})$ increasing? Note that it converges to the integral $\int_0^\pi\frac{\sin x}{x} \,dx$ . I was plotting this sequence on Desmos and apparently it is monotone. But I'm having an hard time proving this. It seems that it's difficult to manipulate the sum: I don't think I can employ functions here and study some derivative; I used the sine sum-to-product formula while trying to show that $a_n < a_{n+1}$ , but it makes things more cumbersome. What could be a way to start? EDIT: for the sake of my problem, it suffices to show that the integral is un upper bound though. I'm not really interested whether it is increasing or not. As suggested by a user, this question was asked to complete the proof given in the answer to another question, which I posted here Bound the absolute value of the partial sums of $\sum \frac{\sin(nx)}{n}$ . Basically, what I'm trying to show is that the sequence of the maxima of the peaks of the partial sums of the Fourier series for the sawtooth wave is increasing to the integral given above (related to the Gibbs's phenomenon).","Is the sequence increasing? Note that it converges to the integral . I was plotting this sequence on Desmos and apparently it is monotone. But I'm having an hard time proving this. It seems that it's difficult to manipulate the sum: I don't think I can employ functions here and study some derivative; I used the sine sum-to-product formula while trying to show that , but it makes things more cumbersome. What could be a way to start? EDIT: for the sake of my problem, it suffices to show that the integral is un upper bound though. I'm not really interested whether it is increasing or not. As suggested by a user, this question was asked to complete the proof given in the answer to another question, which I posted here Bound the absolute value of the partial sums of $\sum \frac{\sin(nx)}{n}$ . Basically, what I'm trying to show is that the sequence of the maxima of the peaks of the partial sums of the Fourier series for the sawtooth wave is increasing to the integral given above (related to the Gibbs's phenomenon).","a_n = \sum_{k=1}^{n}\frac1{k}\sin(\frac{k\pi}{n+1}) \int_0^\pi\frac{\sin x}{x} \,dx a_n < a_{n+1}","['real-analysis', 'sequences-and-series']"
33,"Maple calls absolute convergent sum divergent, but why?","Maple calls absolute convergent sum divergent, but why?",,"Determine whether the sum is divergent, absolute convergent or conditionally convergent. First, I tried to solve this by hand. I tried to find a convergent majorant series for the series in question. $$\bigg|\cos(n^2+1) \frac{2+n^2}{1+n!} \bigg| \leq\frac{n^2}{n!}$$ It turns out that $\sum_{n=1}^{\infty}\frac{n^2}{n!}=2e$ , according to Maple that is. This result shows that the sum in the question is absolute convergent. I also tried to use Maple to double check my answer, and it gave me this. When Maple gives this sort of output, it usually means that the sum is not convergent. But didn't I just show that it was, or have I made a mistake? Can a ""Maple man"" tell me why Maple gives this result, and perhaps how I can avoid it?","Determine whether the sum is divergent, absolute convergent or conditionally convergent. First, I tried to solve this by hand. I tried to find a convergent majorant series for the series in question. It turns out that , according to Maple that is. This result shows that the sum in the question is absolute convergent. I also tried to use Maple to double check my answer, and it gave me this. When Maple gives this sort of output, it usually means that the sum is not convergent. But didn't I just show that it was, or have I made a mistake? Can a ""Maple man"" tell me why Maple gives this result, and perhaps how I can avoid it?",\bigg|\cos(n^2+1) \frac{2+n^2}{1+n!} \bigg| \leq\frac{n^2}{n!} \sum_{n=1}^{\infty}\frac{n^2}{n!}=2e,"['sequences-and-series', 'convergence-divergence', 'summation', 'maple']"
34,The Sum of Geometric-Factorial Series,The Sum of Geometric-Factorial Series,,"I was pondering over my Sequences & Series homework, when the following series struck my mind: $0!+1!x+2!x^{2}+3!x^{3}+.......+n!x^{n}$ And believe me, I am serious that I couldn't think of any approach, but it looked beautiful.I tried to look up all possible summation methods, but it seemed like they didn't offer a break to me.  So guys, any ideas or approach?","I was pondering over my Sequences & Series homework, when the following series struck my mind: And believe me, I am serious that I couldn't think of any approach, but it looked beautiful.I tried to look up all possible summation methods, but it seemed like they didn't offer a break to me.  So guys, any ideas or approach?",0!+1!x+2!x^{2}+3!x^{3}+.......+n!x^{n},"['sequences-and-series', 'summation']"
35,Is this alternating series divergent?,Is this alternating series divergent?,,"I have this series and I need to determine whether it is divergent or convergent, are my calculations correct and it is divergent or am I not seeing something $$ \sum_{n=2}^\infty (-1)^n \left( \frac{n}{2n+1}\right)^2  $$ since it is an alternating series I find the limit of  a_n $$ \lim_{n\to \infty}\left( \frac{n}{2n+1}\right)^2 = \frac{n^2}{(2n+1)^2} = \frac{n^2}{4n^2+4n+1} = \frac{1}{4} $$ and since it does not equal to 0 by the alternating divergence test it s divergent ??","I have this series and I need to determine whether it is divergent or convergent, are my calculations correct and it is divergent or am I not seeing something since it is an alternating series I find the limit of  a_n and since it does not equal to 0 by the alternating divergence test it s divergent ??","
\sum_{n=2}^\infty (-1)^n \left( \frac{n}{2n+1}\right)^2 
 
\lim_{n\to \infty}\left( \frac{n}{2n+1}\right)^2 = \frac{n^2}{(2n+1)^2} = \frac{n^2}{4n^2+4n+1} = \frac{1}{4}
","['sequences-and-series', 'divergent-series']"
36,Prove that $\sinh{2u}+2\sinh{4u}+3\sinh{6u}+...+n\sinh{2nu}=\frac{n\sinh{(2n+2)u-(n+1)\sinh{2nu}}}{4\sinh^2{u}}$,Prove that,\sinh{2u}+2\sinh{4u}+3\sinh{6u}+...+n\sinh{2nu}=\frac{n\sinh{(2n+2)u-(n+1)\sinh{2nu}}}{4\sinh^2{u}},"Prove that $$\sinh{2u}+2\sinh{4u}+3\sinh{6u}+...+n\sinh{2nu}=\frac{n\sinh{(2n+2)u-(n+1)\sinh{2nu}}}{4\sinh^2{u}}$$ My attempt at a solution: Let $$S=\sum_{r=1}^{n}\cosh{2ru}$$ then $$\frac{dS}{du}=\sum_{r=1}^{n}2r\sinh{2ru}\Rightarrow\sum_{r=1}^{n}{r\sinh{2ru}}=\frac{1}{2}\frac{dS}{du}$$ To evaluate $S$ , I used $\cosh{2ru}=\frac{1}{2}{(e^{2ru}+e^{-2ru})}$ , from which $$S=\frac{1}{2}\left\lbrace\sum_{r=1}^{n}e^{2ru}+\sum_{r=1}^n{e^{-2ru}}\right\rbrace =\frac{1}{2}\left\lbrace\frac{e^{2u}((e^{2u})^n-1)}{e^{2u}-1}+\frac{e^{-2u}(1-(e^{-2u})^n)}{1-e^{-2u}}\right\rbrace,$$ using the formula for the sum of the first $n$ terms of a geometric progression. After some algebra and cleaning up, I managed to obtain $$S=\frac{\sinh(2n+1)u}{2\sinh{u}}-\frac{1}{2}$$ and so $$\frac{dS}{du}=\frac{1}{2}\left[\frac{(\sinh{u})(2n+1)\cosh{(2n+1)u}-(\sinh{(2n+1)u})\cosh{u}}{\sinh^2{u}}\right]$$ but I struggle to spot the relevant hyperbolic identities (if needed) in order to proceed to the given result. Just curious, but is there an alternative method to reach the desired result?","Prove that My attempt at a solution: Let then To evaluate , I used , from which using the formula for the sum of the first terms of a geometric progression. After some algebra and cleaning up, I managed to obtain and so but I struggle to spot the relevant hyperbolic identities (if needed) in order to proceed to the given result. Just curious, but is there an alternative method to reach the desired result?","\sinh{2u}+2\sinh{4u}+3\sinh{6u}+...+n\sinh{2nu}=\frac{n\sinh{(2n+2)u-(n+1)\sinh{2nu}}}{4\sinh^2{u}} S=\sum_{r=1}^{n}\cosh{2ru} \frac{dS}{du}=\sum_{r=1}^{n}2r\sinh{2ru}\Rightarrow\sum_{r=1}^{n}{r\sinh{2ru}}=\frac{1}{2}\frac{dS}{du} S \cosh{2ru}=\frac{1}{2}{(e^{2ru}+e^{-2ru})} S=\frac{1}{2}\left\lbrace\sum_{r=1}^{n}e^{2ru}+\sum_{r=1}^n{e^{-2ru}}\right\rbrace
=\frac{1}{2}\left\lbrace\frac{e^{2u}((e^{2u})^n-1)}{e^{2u}-1}+\frac{e^{-2u}(1-(e^{-2u})^n)}{1-e^{-2u}}\right\rbrace, n S=\frac{\sinh(2n+1)u}{2\sinh{u}}-\frac{1}{2} \frac{dS}{du}=\frac{1}{2}\left[\frac{(\sinh{u})(2n+1)\cosh{(2n+1)u}-(\sinh{(2n+1)u})\cosh{u}}{\sinh^2{u}}\right]","['calculus', 'sequences-and-series', 'summation', 'hyperbolic-functions']"
37,Prove a series of a subsequence converges.,Prove a series of a subsequence converges.,,"Let $\sum_{n=1}^{\infty} a_n$ converge. Let $(n_k)_{k=1}^{\infty}$ be a subsequence of the sequence of positive integers. For each k, define: $$b_k = a_{n_{k-1}+1} + ...+ a_{n_k}$$ where $n_0 = 0$ . Prove $\sum_{n=1}^{\infty} b_k$ converges and that $\sum_{n=1}^{\infty} a_n = \sum_{k=1}^{\infty} b_k$ . This is the question I am looking at. I know that each subsequence of a convergent sequence also converges, and therefore because if a series converges, the sequence must also converge. I guess I'm just struggling notationally with this. I'm not really sure what $b_k$ is defining. I'm not looking for an answer (besides, this problem will not be graded, it is for practice), but a little help in the right direction would be greatly appreciated.","Let converge. Let be a subsequence of the sequence of positive integers. For each k, define: where . Prove converges and that . This is the question I am looking at. I know that each subsequence of a convergent sequence also converges, and therefore because if a series converges, the sequence must also converge. I guess I'm just struggling notationally with this. I'm not really sure what is defining. I'm not looking for an answer (besides, this problem will not be graded, it is for practice), but a little help in the right direction would be greatly appreciated.",\sum_{n=1}^{\infty} a_n (n_k)_{k=1}^{\infty} b_k = a_{n_{k-1}+1} + ...+ a_{n_k} n_0 = 0 \sum_{n=1}^{\infty} b_k \sum_{n=1}^{\infty} a_n = \sum_{k=1}^{\infty} b_k b_k,"['real-analysis', 'sequences-and-series', 'convergence-divergence']"
38,"What percentage of positive integers, written in base 10, are composite regardless of what base they are interpreted in?","What percentage of positive integers, written in base 10, are composite regardless of what base they are interpreted in?",,"There is a sequence of numbers (OEIS A121719 ) with the following defenition: If the string of base- $10$ digits corresponding to the positive integer $k$ is composite when interpreted in any possible base $b$ , then $k$ is in the sequence. After writing a program to find values of the sequence, I was curious whether the percentage of numbers $k<n$ in the sequence approaches a certain value as $n$ increases. I will now formally define my question: $A$ is the set of all positive integers in the sequence defined above. $$C(n)=1\:\text{if}\:n\in A,\:\text{otherwise}\:0$$ $$L=\lim_{n\to\infty}\frac{1}{n}\sum^n_{i=1} C(i)$$ I would like to know: Does the limit $L$ exist? Is $L>0$ ? Is there some method to find $L$ or the first $n$ digits of $L$ ?","There is a sequence of numbers (OEIS A121719 ) with the following defenition: If the string of base- digits corresponding to the positive integer is composite when interpreted in any possible base , then is in the sequence. After writing a program to find values of the sequence, I was curious whether the percentage of numbers in the sequence approaches a certain value as increases. I will now formally define my question: is the set of all positive integers in the sequence defined above. I would like to know: Does the limit exist? Is ? Is there some method to find or the first digits of ?","10 k b k k<n n A C(n)=1\:\text{if}\:n\in A,\:\text{otherwise}\:0 L=\lim_{n\to\infty}\frac{1}{n}\sum^n_{i=1} C(i) L L>0 L n L","['sequences-and-series', 'limits', 'prime-numbers', 'recreational-mathematics', 'decimal-expansion']"
39,Why is the Conway 'Look and Say' sequences constant defined by this polynom?,Why is the Conway 'Look and Say' sequences constant defined by this polynom?,,"In his work on 'Look and Say' sequences,for instance beginning with $1$ . $$1// 11// 21// 1211// 111221// 312212$$ If $L_n$ is the length of the $n-th$ sequences, then it follows from Conway work that : $$\lim_{n\to\infty} \ \frac{L_{n+1}}{L_n} =\lambda=1.303577269034... $$ where $\lambda$ is the unique real, stricly positive root of \begin{align}   x^{71} - x^{69}   - 2x^{68}  - x^{67}   + 2x^{66}  + 2x^{65}  + x^{64}   - x^{63} \\ - x^{62}  - x^{61}   - x^{60}   - x^{59}   + 2x^{58}  + 5x^{57}  + 3x^{56}  - 2x^{55}  - 10x^{54} \\ - 3x^{53}- 2x^{52}  + 6x^{51}  + 6x^{50}  + x^{49}   + 9x^{48}  - 3x^{47}  - 7x^{46}  - 8x^{45}  \\ - 8x^{44} + 10x^{43} + 6x^{42}  + 8x^{41}  - 5x^{40}  - 12x^{39} + 7x^{38}  - 7x^{37}  + 7x^{36}  \\ + x^{35}  - 3x^{34}  + 10x^{33} + x^{32}   - 6x^{31}  - 2x^{30}  - 10x^{29} - 3x^{28}  + 2x^{27}  \\ + 9x^{26} - 3x^{25}  + 14x^{24} - 8x^{23}   - 7x^{21} + 9x^{20}  -3x^{19} - 4x^{18}  \\ - 10x^{17} - 7x^{16} + 12x^{15} + 7x^{14}  + 2x^{13}  - 12x^{12} - 4x^{11}  - 2x^{10}  + 5x^9     \\ + x^7      - 7x^6    + 7x^5     - 4x^4     + 12x^3    - 6x^2     + 3x       - 6 \end{align} My question is: why that polynom? How did Conway manage to get it? Is it an approximation of the experimental values of $\lambda$ he got? If there exists any paper, I would appreciate to read it. Thanks for your help.","In his work on 'Look and Say' sequences,for instance beginning with . If is the length of the sequences, then it follows from Conway work that : where is the unique real, stricly positive root of My question is: why that polynom? How did Conway manage to get it? Is it an approximation of the experimental values of he got? If there exists any paper, I would appreciate to read it. Thanks for your help.","1 1//
11//
21//
1211//
111221//
312212 L_n n-th \lim_{n\to\infty} \
\frac{L_{n+1}}{L_n} =\lambda=1.303577269034...  \lambda \begin{align}
  x^{71} - x^{69}   - 2x^{68}  - x^{67}   + 2x^{66}  + 2x^{65}  + x^{64}   - x^{63} \\
- x^{62}  - x^{61}   - x^{60}   - x^{59}   + 2x^{58}  + 5x^{57}  + 3x^{56}  - 2x^{55}  - 10x^{54} \\
- 3x^{53}- 2x^{52}  + 6x^{51}  + 6x^{50}  + x^{49}   + 9x^{48}  - 3x^{47}  - 7x^{46}  - 8x^{45}  \\
- 8x^{44} + 10x^{43} + 6x^{42}  + 8x^{41}  - 5x^{40}  - 12x^{39} + 7x^{38}  - 7x^{37}  + 7x^{36}  \\
+ x^{35}  - 3x^{34}  + 10x^{33} + x^{32}   - 6x^{31}  - 2x^{30}  - 10x^{29} - 3x^{28}  + 2x^{27}  \\
+ 9x^{26} - 3x^{25}  + 14x^{24} - 8x^{23}   - 7x^{21} + 9x^{20}  -3x^{19} - 4x^{18}  \\
- 10x^{17} - 7x^{16} + 12x^{15} + 7x^{14}  + 2x^{13}  - 12x^{12} - 4x^{11}  - 2x^{10}  + 5x^9     \\
+ x^7      - 7x^6    + 7x^5     - 4x^4     + 12x^3    - 6x^2     + 3x       - 6
\end{align} \lambda","['sequences-and-series', 'polynomials', 'algebraic-number-theory']"
40,Examining cycles in a sequence,Examining cycles in a sequence,,"I am looking at a problem in Engel's problem solving strategies: Start with an $n$ -tuple $S=(a_0,a_1,\ldots, a_{n-1})$ of nonnegative integers. Define the operation $T(S):=(|a_0-a_1|, |a_1-a_2|,\ldots, |a_{n-1}-a_0|)$ . Now consider the sequence $S, T(S), T(T(S)),\ldots$ . For instance, if we take $n=4$ and $S=(0,3,10,13)$ , we get $(0,3,10,13)\mapsto (3,7,3,13)\mapsto (4,4,10,10)\mapsto(0,6,0,6)\mapsto(6,6,6,6)\mapsto(0,0,0,0)$ . Prove that, for $n\neq 2^r,$ we get (up to some exceptions) a cycle containing just two numbers: $0$ , and evenly often some number $a>0$ . Let $n\neq 2^r$ and let $c(n)$ be the cycle length. Prove that $c(2n)=2c(n)$ up to some exceptions. Prove that, for odd $n$ , $S=(0,0,\ldots,0,1,1)$ always lies on a cycle. The problem does not elaborate on what the 'exceptions' are. Some given hints/progress I've made: The sequences $S$ and $tS$ have the same 'life expectancy', where $tS$ denotes multiplication of each element by $t\in \mathbb{N}$ . This is because $T(tS)=tT(S)$ , so $T^k(tS)=0 \iff tT^k(S)=0 \iff T^k(S)=0$ . For $n=2^r$ , we always reach $(0,\ldots, 0)$ . Note that in mod 2, $|a-b|\equiv a+b$ . So $T(a_0,a_1,\ldots,a_{n-1})\equiv (a_0+a_1,a_1+a_2,\ldots,a_{n-1}+a_0)$ , and $T^2(S)\equiv (a_0+a_2,a_1+a_3,\ldots)$ etc. Continuing on, we see that these indices $a_i$ present in each slot has a structure identical to the parity of Pascal's triangle, where applying $T$ takes us to the next row in the triangle. So for $n=2^r$ , via the property of Pascal's triangle that the $2^r-1$ 'th row is entirely odd, we will reach $(\sum a_i, \sum a_i, \ldots, \sum a_i)$ , which then maps to $(0, 0,\ldots,0)$ in mod 2. Therefore after each $2^r$ steps we can extract a common factor of 2 from the $n$ -tuple. Further let $\max S$ denote the maximal element of $S$ . Observing that $\max S\geq\max T(S)$ , a descent argument will show that the eventually we must reach all $0$ 's. A suggestion from the book: given the sequence $(a_0,a_1,\ldots,a_{n-1})$ , assign the polynomial $p(x)=a_{n-1}+\ldots+a_0x^{n-1}$ with coefficients in mod 2, and $x^n=1$ . Then the polynomial $(1+x)p(x)$ belongs to $T(S)$ . EDIT: the book includes a table of $c(n)$ values, which were computer generated. The first few values on the table are: $c(3)=3, c(5)=15, c(7)=7, c(9)=63, c(11)=341, c(13)=819, c(15)=15, c(17)=255, c(19)=9709...$ . There seem to be various patterns in here, for instance, $c(2^k+1)=2^{2k}-1$ .","I am looking at a problem in Engel's problem solving strategies: Start with an -tuple of nonnegative integers. Define the operation . Now consider the sequence . For instance, if we take and , we get . Prove that, for we get (up to some exceptions) a cycle containing just two numbers: , and evenly often some number . Let and let be the cycle length. Prove that up to some exceptions. Prove that, for odd , always lies on a cycle. The problem does not elaborate on what the 'exceptions' are. Some given hints/progress I've made: The sequences and have the same 'life expectancy', where denotes multiplication of each element by . This is because , so . For , we always reach . Note that in mod 2, . So , and etc. Continuing on, we see that these indices present in each slot has a structure identical to the parity of Pascal's triangle, where applying takes us to the next row in the triangle. So for , via the property of Pascal's triangle that the 'th row is entirely odd, we will reach , which then maps to in mod 2. Therefore after each steps we can extract a common factor of 2 from the -tuple. Further let denote the maximal element of . Observing that , a descent argument will show that the eventually we must reach all 's. A suggestion from the book: given the sequence , assign the polynomial with coefficients in mod 2, and . Then the polynomial belongs to . EDIT: the book includes a table of values, which were computer generated. The first few values on the table are: . There seem to be various patterns in here, for instance, .","n S=(a_0,a_1,\ldots, a_{n-1}) T(S):=(|a_0-a_1|, |a_1-a_2|,\ldots, |a_{n-1}-a_0|) S, T(S), T(T(S)),\ldots n=4 S=(0,3,10,13) (0,3,10,13)\mapsto (3,7,3,13)\mapsto (4,4,10,10)\mapsto(0,6,0,6)\mapsto(6,6,6,6)\mapsto(0,0,0,0) n\neq 2^r, 0 a>0 n\neq 2^r c(n) c(2n)=2c(n) n S=(0,0,\ldots,0,1,1) S tS tS t\in \mathbb{N} T(tS)=tT(S) T^k(tS)=0 \iff tT^k(S)=0 \iff T^k(S)=0 n=2^r (0,\ldots, 0) |a-b|\equiv a+b T(a_0,a_1,\ldots,a_{n-1})\equiv (a_0+a_1,a_1+a_2,\ldots,a_{n-1}+a_0) T^2(S)\equiv (a_0+a_2,a_1+a_3,\ldots) a_i T n=2^r 2^r-1 (\sum a_i, \sum a_i, \ldots, \sum a_i) (0, 0,\ldots,0) 2^r n \max S S \max S\geq\max T(S) 0 (a_0,a_1,\ldots,a_{n-1}) p(x)=a_{n-1}+\ldots+a_0x^{n-1} x^n=1 (1+x)p(x) T(S) c(n) c(3)=3, c(5)=15, c(7)=7, c(9)=63, c(11)=341, c(13)=819, c(15)=15, c(17)=255, c(19)=9709... c(2^k+1)=2^{2k}-1","['sequences-and-series', 'problem-solving', 'absolute-value', 'invariance']"
41,Is there a convention to interpret equalities of functions as series?,Is there a convention to interpret equalities of functions as series?,,"I am wondering about whether there is a default or standard interpretation of statements such as $$\sum_{n=1}^\infty f_n(x) = f(x)$$ or equivalently $$\sum_{n=1}^\infty f_n = f$$ In some cases these statements can mean 'uniformly convergent to $f$ ' or just 'pointwise convergent to $f$ '. But sometimes I come across these equalities without the uniform or pointwise qualification, and thus in these situations I don't know whether as a default to interpret them as meaning pointwise or uniform convergence. For example, when I first learnt about power series, we had not yet met the notions of uniform convergence (or pointwise). We simply defined $f(x) = \sum_{n=1}^\infty a_nx^n$ . In hindsight, this equality really is equivalent to asserting the pointwise convergence of the series to $f$ over the radius of convergence. (Although it also turns out to be uniformly convergent within the radius) Another example comes from the second answer in this question: When can a sum and integral be interchanged? , from the user Jonas Teuwen. In particular, he states that $f = \sum_n f_n$ in his answer. How should these equalities be interpreted? Is there a default, e.g. just assume it means pointwise, or is it entirely context dependent? [Note: my current understanding is that when we deal with infinite series of functions, writing it as an equality is really a shorthand for some first order logic statement.  I.e. it is completely analogous to the fact that stating $\lim_{n \rightarrow \infty} a_n = l$ in the case of real sequences really means $\forall \epsilon >0 \exists N \forall n>N (|a_n - l|< \epsilon)$ . In this way I think of the equality symbol as just shorthand for a more verbose expression when it comes to series of functions, rather than meaning equality of mathematical objects so to say. In this sense, I don't know how to interpret the statements abut equality of series without any context.]","I am wondering about whether there is a default or standard interpretation of statements such as or equivalently In some cases these statements can mean 'uniformly convergent to ' or just 'pointwise convergent to '. But sometimes I come across these equalities without the uniform or pointwise qualification, and thus in these situations I don't know whether as a default to interpret them as meaning pointwise or uniform convergence. For example, when I first learnt about power series, we had not yet met the notions of uniform convergence (or pointwise). We simply defined . In hindsight, this equality really is equivalent to asserting the pointwise convergence of the series to over the radius of convergence. (Although it also turns out to be uniformly convergent within the radius) Another example comes from the second answer in this question: When can a sum and integral be interchanged? , from the user Jonas Teuwen. In particular, he states that in his answer. How should these equalities be interpreted? Is there a default, e.g. just assume it means pointwise, or is it entirely context dependent? [Note: my current understanding is that when we deal with infinite series of functions, writing it as an equality is really a shorthand for some first order logic statement.  I.e. it is completely analogous to the fact that stating in the case of real sequences really means . In this way I think of the equality symbol as just shorthand for a more verbose expression when it comes to series of functions, rather than meaning equality of mathematical objects so to say. In this sense, I don't know how to interpret the statements abut equality of series without any context.]",\sum_{n=1}^\infty f_n(x) = f(x) \sum_{n=1}^\infty f_n = f f f f(x) = \sum_{n=1}^\infty a_nx^n f f = \sum_n f_n \lim_{n \rightarrow \infty} a_n = l \forall \epsilon >0 \exists N \forall n>N (|a_n - l|< \epsilon),"['real-analysis', 'sequences-and-series']"
42,Fibonacci and the spreading of viruses,Fibonacci and the spreading of viruses,,"I tried to understand better the spreading of a virus on a case-by-case basis, not by differential or difference equations as in SIR and SEIR models with possibly non-integer rates and time constants. In the course of this, Fibonacci numbers showed up in a – for me – unexpected way. And a relation between Fibonacci numbers and powers of $2$ showed up that I'd like to understand better. This was my approach. Let $\lambda$ be the pre-infectious (or latent) period , and let $\lambda = 1$ (e.g. $1$ day). Let $\delta$ be the duration of infectiousness, e.g. $\delta = 4$ . After $\lambda + \delta$ days, an infected individual recovers. Finally let $\beta$ be the infection rate, i.e. the number of people an infectious individual infects per day. Let $\beta = 1$ . This choice of $\beta$ and $\delta$ corresponds to a basic reproduction number $R_0 = \beta\cdot\delta = 4$ . In a deterministic and idealized setup the number of infected indiviudals $I$ evolves like this starting with a single patient 0, neglecting the effect of the decreasing number of susceptible individuals: 1  1  1  1  1                        (patient 0)        1  1  1  1  1                     (patient 1)           2  2  2  2  2                  (patients 2 and 3)              4  4  4  4   4              (patients 4 to  7)                 8  8  8   8   8          (patients 8 to 15)                   15 15  15  15  15      ...                      29  29  29  29  29  ...                          56  56  56  56  ...                             108 108 108  ...                                 208 208  ... I = 1  2  4  8 16 30 58 112 216 416 ... ∆ =                2  6  16  40  96 ... Obviously, $I(t) = 2^t$ when $t < \lambda + \delta$ . For $t \ge \lambda + \delta$ , $I(t)$ deviates from $2^t$ , in this example by ∆ = 2, 6, 16, 40, 96, 222, 502, 1116, 2448, 5312, 11426, 24398, 51776, 109296, 229664, 480670 which is a sequence not to be found at OEIS , but I guess it's the number of binary strings of length $n$ having at least one run of length at least $5$ (see below). For the sake of comparison here for $\delta = 2$ 1  1  1                           1  1  1                               2  2  2                               3  3  3                               5  5  5                              8  8  8                      13 13  13                            21  21  21                                34  34 34                                 55 55 ... I = 1  2  4  6 10 16 26 42  68 110 ... ∆ =          2  6 16 38 86 188 402 ... [I(n) is obviously twice the $n$ -th Fibonacci number. The Fibonacci numbers come also as the numbers of newly infected individuals per day – but only in this very special case $\delta = 2$ . According to OEIS , the sequence $\Delta$ gives the number of $n$ -tosses having a run of $3$ or more heads or a run of $3$ or more tails for a fair coin resp. the difference between the number of branches of a complete binary tree of $n$ levels, and the number of recursive calls needed to compute the $(n+1)$ -th Fibonacci number .] And for $\delta = 3$ : 1  1  1  1                                 1  1  1  1                               2  2  2  2                                 4  4  4  4                                7  7  7  7                               13 13 13  13                              24 24  24  24                             44  44  44  44                              81  81  81 ...                                149 149 ... I = 1  2  4  8 14 26 48 88 162 298 ... ∆ =             2  6 16 40  94 214 ... [According to OEIS , the sequence $\Delta$ gives the number of binary strings of length n having at least one run of length at least 4 .] I am looking for a general formula $I_{\lambda\delta\beta}(t) = 2^t - \Delta_{\lambda\delta\beta}(t)$ relating in the special case of $\lambda = \beta = 1$ and $\delta =2$ the Fibonacci numbers with the powers of $2$ . A specific side question: What has the number of recursive calls needed to compute the $n$ -th Fibonacci number to do with the number of binary strings of length $n$ having at least one run of length at least $3$ ? (see above) For $\lambda = \beta = 1$ and large $\delta$ , e.g. $\delta =20$ , the first non-zero terms of $\Delta_{\lambda\delta\beta}$ are ∆ = 2, 6, 16, 40, 96, 224, 512, 1152, 2560, 5632, 12288, 26624, 57344, 122880, 262144, 557056, 1179648, 2490368, 5242880, 11010048 which is the initial part of the sequence $a(n) = n\cdot 2^{n-2}$ (see OEIS ). Edit 1 : The link , user @heropup provided, yields this insight: Edit 2 : There is a follow-up question to this one: Fibonacci and tossing coins .","I tried to understand better the spreading of a virus on a case-by-case basis, not by differential or difference equations as in SIR and SEIR models with possibly non-integer rates and time constants. In the course of this, Fibonacci numbers showed up in a – for me – unexpected way. And a relation between Fibonacci numbers and powers of showed up that I'd like to understand better. This was my approach. Let be the pre-infectious (or latent) period , and let (e.g. day). Let be the duration of infectiousness, e.g. . After days, an infected individual recovers. Finally let be the infection rate, i.e. the number of people an infectious individual infects per day. Let . This choice of and corresponds to a basic reproduction number . In a deterministic and idealized setup the number of infected indiviudals evolves like this starting with a single patient 0, neglecting the effect of the decreasing number of susceptible individuals: 1  1  1  1  1                        (patient 0)        1  1  1  1  1                     (patient 1)           2  2  2  2  2                  (patients 2 and 3)              4  4  4  4   4              (patients 4 to  7)                 8  8  8   8   8          (patients 8 to 15)                   15 15  15  15  15      ...                      29  29  29  29  29  ...                          56  56  56  56  ...                             108 108 108  ...                                 208 208  ... I = 1  2  4  8 16 30 58 112 216 416 ... ∆ =                2  6  16  40  96 ... Obviously, when . For , deviates from , in this example by ∆ = 2, 6, 16, 40, 96, 222, 502, 1116, 2448, 5312, 11426, 24398, 51776, 109296, 229664, 480670 which is a sequence not to be found at OEIS , but I guess it's the number of binary strings of length having at least one run of length at least (see below). For the sake of comparison here for 1  1  1                           1  1  1                               2  2  2                               3  3  3                               5  5  5                              8  8  8                      13 13  13                            21  21  21                                34  34 34                                 55 55 ... I = 1  2  4  6 10 16 26 42  68 110 ... ∆ =          2  6 16 38 86 188 402 ... [I(n) is obviously twice the -th Fibonacci number. The Fibonacci numbers come also as the numbers of newly infected individuals per day – but only in this very special case . According to OEIS , the sequence gives the number of -tosses having a run of or more heads or a run of or more tails for a fair coin resp. the difference between the number of branches of a complete binary tree of levels, and the number of recursive calls needed to compute the -th Fibonacci number .] And for : 1  1  1  1                                 1  1  1  1                               2  2  2  2                                 4  4  4  4                                7  7  7  7                               13 13 13  13                              24 24  24  24                             44  44  44  44                              81  81  81 ...                                149 149 ... I = 1  2  4  8 14 26 48 88 162 298 ... ∆ =             2  6 16 40  94 214 ... [According to OEIS , the sequence gives the number of binary strings of length n having at least one run of length at least 4 .] I am looking for a general formula relating in the special case of and the Fibonacci numbers with the powers of . A specific side question: What has the number of recursive calls needed to compute the -th Fibonacci number to do with the number of binary strings of length having at least one run of length at least ? (see above) For and large , e.g. , the first non-zero terms of are ∆ = 2, 6, 16, 40, 96, 224, 512, 1152, 2560, 5632, 12288, 26624, 57344, 122880, 262144, 557056, 1179648, 2490368, 5242880, 11010048 which is the initial part of the sequence (see OEIS ). Edit 1 : The link , user @heropup provided, yields this insight: Edit 2 : There is a follow-up question to this one: Fibonacci and tossing coins .",2 \lambda \lambda = 1 1 \delta \delta = 4 \lambda + \delta \beta \beta = 1 \beta \delta R_0 = \beta\cdot\delta = 4 I I(t) = 2^t t < \lambda + \delta t \ge \lambda + \delta I(t) 2^t n 5 \delta = 2 n \delta = 2 \Delta n 3 3 n (n+1) \delta = 3 \Delta I_{\lambda\delta\beta}(t) = 2^t - \Delta_{\lambda\delta\beta}(t) \lambda = \beta = 1 \delta =2 2 n n 3 \lambda = \beta = 1 \delta \delta =20 \Delta_{\lambda\delta\beta} a(n) = n\cdot 2^{n-2},"['sequences-and-series', 'exponential-function', 'mathematical-modeling', 'biology']"
43,General method for finding summation of series with $n^{th}$ term difference in AP,General method for finding summation of series with  term difference in AP,n^{th},"What is the method for finding the summation of a series whose $n^{th}$ difference between consecutive terms is in an AP? For example, $$2,12,36,80,150,252...$$ Taking the first term difference we get another series as such - $10,24,44,70,102...$ . Taking it's term difference we get the series $14,20,26,32$ which is in an Arithmetic Progression. Or, $$1,13,53,143,311,591,1023...$$ In this, the series formed by the $3^{rd}$ order difference is in AP.","What is the method for finding the summation of a series whose difference between consecutive terms is in an AP? For example, Taking the first term difference we get another series as such - . Taking it's term difference we get the series which is in an Arithmetic Progression. Or, In this, the series formed by the order difference is in AP.","n^{th} 2,12,36,80,150,252... 10,24,44,70,102... 14,20,26,32 1,13,53,143,311,591,1023... 3^{rd}","['sequences-and-series', 'algebra-precalculus', 'arithmetic-progressions']"
44,Periodic sequence problem,Periodic sequence problem,,"Given sequence $a_n$ defined such that $a_1=3$ , $a_{n+1}=\begin{cases}\frac{a_n}{2},\quad 2\mid a_n\\ \frac{a_n+1983}{2},\quad 2\nmid a_n\end{cases}$ . Then prove that the sequence $a_n$ is periodic and find the period. It's easy to prove that $0<a_n<1983$ by induction. By pigeonhole principle, there exist $i,j$ such that $a_i=a_j\implies a_{i+1}=a_{j+1}$ . By induction, we can prove $a_{i+k}=a_{j+k},\forall k\in\mathbb{N}$ . Otherwise, $a_n\begin{cases}2a_{n+1}, \quad a_{n+1}\le 991\\ 2a_{n+1}-1983, \quad a_{n+1}\ge 992\end{cases}$ . So we can prove also $a_{i-k}=a_{j-k} $ for $min(i,j)>k, \forall k\in\mathbb{N}$ . So it's periodic. But I can't find the period. In my opinion, the period is $660$ . Because $3\mid a_n$ and $0<a_n<1983$ . But I can't prove $\forall k, \exists i$ such that $a_i=3k$ , Can anyone help me?","Given sequence defined such that , . Then prove that the sequence is periodic and find the period. It's easy to prove that by induction. By pigeonhole principle, there exist such that . By induction, we can prove . Otherwise, . So we can prove also for . So it's periodic. But I can't find the period. In my opinion, the period is . Because and . But I can't prove such that , Can anyone help me?","a_n a_1=3 a_{n+1}=\begin{cases}\frac{a_n}{2},\quad 2\mid a_n\\ \frac{a_n+1983}{2},\quad 2\nmid a_n\end{cases} a_n 0<a_n<1983 i,j a_i=a_j\implies a_{i+1}=a_{j+1} a_{i+k}=a_{j+k},\forall k\in\mathbb{N} a_n\begin{cases}2a_{n+1}, \quad a_{n+1}\le 991\\ 2a_{n+1}-1983, \quad a_{n+1}\ge 992\end{cases} a_{i-k}=a_{j-k}  min(i,j)>k, \forall k\in\mathbb{N} 660 3\mid a_n 0<a_n<1983 \forall k, \exists i a_i=3k",['sequences-and-series']
45,Maximal extension of domain of $\Psi(x)=\sum_{n=1}^\infty e^{\frac{\log(n)}{\log(x)}}$ using analytic continuation,Maximal extension of domain of  using analytic continuation,\Psi(x)=\sum_{n=1}^\infty e^{\frac{\log(n)}{\log(x)}},Given $$ \Psi(x)=\sum_{n=1}^\infty e^{\frac{\ln(n)}{\ln(x)}}= \prod_{p~ \mathrm{prime}}\frac{1}{1-e^{\frac{\ln(p)}{\ln(x)}}}$$ What is the maximal extension of $\Psi$ ? I think that there is a barrier at $\Re(x)=0$ but don't know how to show that.,Given What is the maximal extension of ? I think that there is a barrier at but don't know how to show that., \Psi(x)=\sum_{n=1}^\infty e^{\frac{\ln(n)}{\ln(x)}}= \prod_{p~ \mathrm{prime}}\frac{1}{1-e^{\frac{\ln(p)}{\ln(x)}}} \Psi \Re(x)=0,"['sequences-and-series', 'logarithms', 'analytic-continuation', 'euler-product']"
46,Show that a sequence is convergent,Show that a sequence is convergent,,"I found this problem in real analysis and I have no idea how to start, I just need a hint let $x_n$ be a bounded sequence of real numbers, that satisfies: 1- $\lim_{n\to \infty} x_{n+1} - x_n = 0 $ 2- if $ A = \{x_n: \forall n\in \mathbb{N}\} $ then $A'$ is finite (This defines A as the range of $x_n$ and A' is the set of limit points of A) prove that $x_n$ is convergent for $x_n$ to converge it's enough to show that A' has only one element, that if $x \in A' $ and $y \in A'$ then $x = y$ I tried to deduce that from the definition of the set of limit points and no luck there. and since $x_n$ is bounded then it has a convergent subsequence, which converges to a point in A'. I don't know what to do next","I found this problem in real analysis and I have no idea how to start, I just need a hint let be a bounded sequence of real numbers, that satisfies: 1- 2- if then is finite (This defines A as the range of and A' is the set of limit points of A) prove that is convergent for to converge it's enough to show that A' has only one element, that if and then I tried to deduce that from the definition of the set of limit points and no luck there. and since is bounded then it has a convergent subsequence, which converges to a point in A'. I don't know what to do next",x_n \lim_{n\to \infty} x_{n+1} - x_n = 0   A = \{x_n: \forall n\in \mathbb{N}\}  A' x_n x_n x_n x \in A'  y \in A' x = y x_n,"['real-analysis', 'sequences-and-series', 'cauchy-sequences']"
47,"Unexpected result, does $\Big\lfloor\frac{n-1}{2}\Big\rfloor=\sum_{i=1}^\infty\bigg\lfloor\frac{n+2^i-1}{2^{i+1}}\bigg\rfloor $","Unexpected result, does",\Big\lfloor\frac{n-1}{2}\Big\rfloor=\sum_{i=1}^\infty\bigg\lfloor\frac{n+2^i-1}{2^{i+1}}\bigg\rfloor ,"While trying to prove something else, I arrived at the result that for $n\in\Bbb{Z}^+$ $$\Big\lfloor\frac{n-1}{2}\Big\rfloor=\Big\lfloor\frac{n+1}{4}\Big\rfloor+\Big\lfloor\frac{n+3}{8}\Big\rfloor+\Big\lfloor\frac{n+7}{16}\Big\rfloor+\cdots=\sum_{i=1}^\infty\bigg\lfloor\frac{n+2^i-1}{2^{i+1}}\bigg\rfloor$$ This result was quite spectacular to me and I want to know if it is true and if it is how I can prove it. For all cases I've tried it seems to hold true.","While trying to prove something else, I arrived at the result that for This result was quite spectacular to me and I want to know if it is true and if it is how I can prove it. For all cases I've tried it seems to hold true.",n\in\Bbb{Z}^+ \Big\lfloor\frac{n-1}{2}\Big\rfloor=\Big\lfloor\frac{n+1}{4}\Big\rfloor+\Big\lfloor\frac{n+3}{8}\Big\rfloor+\Big\lfloor\frac{n+7}{16}\Big\rfloor+\cdots=\sum_{i=1}^\infty\bigg\lfloor\frac{n+2^i-1}{2^{i+1}}\bigg\rfloor,"['sequences-and-series', 'combinatorics', 'ceiling-and-floor-functions', 'infinitary-combinatorics']"
48,"Does $\sum_{k=1}^∞ \frac1{\prod_{i=0}^{l(k)} (\ln^i k) · {(\ln^{l(k)} k)}^{l(k)}}$ converge, where $l(x) = \min \{ c\in\Bbb{N} : \ln^c x < e \}$?","Does  converge, where ?",\sum_{k=1}^∞ \frac1{\prod_{i=0}^{l(k)} (\ln^i k) · {(\ln^{l(k)} k)}^{l(k)}} l(x) = \min \{ c\in\Bbb{N} : \ln^c x < e \},"Define $\def\lnc{\operatorname{lnc}}$$\lnc x$ is the minimum natural $c$ such that $\ln^c x < e$ , for each real $x ≥ 1$ . Prove that $\displaystyle\sum_{k=1}^∞ \frac1{\prod_{i=0}^{\lnc k} (\ln^i k) · {(\ln^{\lnc k} k)}^{\lnc k}}$ diverges. Prove that $\displaystyle\sum_{k=1}^∞ \frac1{\prod_{i=0}^{\lnc k} (\ln^i k) · {(\ln^{\lnc k} k)}^{(\lnc k)^r}}$ converges for every $r > 1$ . I came up with this for fun, just to try to squeeze the gap between the well-known boundary: $\displaystyle\sum_{k=1}^∞ \frac1{\prod_{i=0}^p (\ln^i k)}$ diverges for every natural $p$ . $\displaystyle\sum_{k=1}^∞ \frac1{\prod_{i=0}^p (\ln^i k) · (\ln^p k)}$ converges for every natural $p$ . My proofs are below. Any comments are welcome! Downvoters should note that such questions are explicitly encouraged .","Define is the minimum natural such that , for each real . Prove that diverges. Prove that converges for every . I came up with this for fun, just to try to squeeze the gap between the well-known boundary: diverges for every natural . converges for every natural . My proofs are below. Any comments are welcome! Downvoters should note that such questions are explicitly encouraged .",\def\lnc{\operatorname{lnc}}\lnc x c \ln^c x < e x ≥ 1 \displaystyle\sum_{k=1}^∞ \frac1{\prod_{i=0}^{\lnc k} (\ln^i k) · {(\ln^{\lnc k} k)}^{\lnc k}} \displaystyle\sum_{k=1}^∞ \frac1{\prod_{i=0}^{\lnc k} (\ln^i k) · {(\ln^{\lnc k} k)}^{(\lnc k)^r}} r > 1 \displaystyle\sum_{k=1}^∞ \frac1{\prod_{i=0}^p (\ln^i k)} p \displaystyle\sum_{k=1}^∞ \frac1{\prod_{i=0}^p (\ln^i k) · (\ln^p k)} p,"['real-analysis', 'sequences-and-series', 'convergence-divergence', 'summation', 'logarithms']"
49,What is the probability that a prime is less than the number formed by reversing its digits?,What is the probability that a prime is less than the number formed by reversing its digits?,,"Let $p_n$ ne the $n$ -th prime and let $r_n$ be the number formed by reversing the digits of $p_n$ in base $10$ notation. All prime numbers greater than $5$ end in $1,3,7$ or $9$ . Take the first $n$ primes, count the number of primes $r(n)$ of them which are less than the number formed by their reverse. To what limiting value does $\dfrac{r(n)}{n}$ converge to as $n \to \infty$ or does it exist in the first place? It is easy to evaluate this for primes whose first and last digits are different. However when primes begin and end with the same digit then we have to consider all the intermediate digits. Experimental data shows that the limiting value may not exist and oscillate between $0.506$ and $0.707$ .","Let ne the -th prime and let be the number formed by reversing the digits of in base notation. All prime numbers greater than end in or . Take the first primes, count the number of primes of them which are less than the number formed by their reverse. To what limiting value does converge to as or does it exist in the first place? It is easy to evaluate this for primes whose first and last digits are different. However when primes begin and end with the same digit then we have to consider all the intermediate digits. Experimental data shows that the limiting value may not exist and oscillate between and .","p_n n r_n p_n 10 5 1,3,7 9 n r(n) \dfrac{r(n)}{n} n \to \infty 0.506 0.707","['sequences-and-series', 'number-theory', 'limits', 'elementary-number-theory', 'prime-numbers']"
50,Prove that : $\lim_{n\to +\infty}\left(x_{0}x_{1}...x_{n-1}\right)^{1/2^{n}}=\frac{3+\sqrt{5}}{2}$,Prove that :,\lim_{n\to +\infty}\left(x_{0}x_{1}...x_{n-1}\right)^{1/2^{n}}=\frac{3+\sqrt{5}}{2},Let sequence $x_{n+1}=x_{n}^{2}-2$ with $x_{0}=3$ Then prove that : $$\displaystyle\lim_{n\to +\infty}\left(x_{0}x_{1}...x_{n-1}\right)^{\frac{1}{2^{n}}}=\frac{3+\sqrt{5}}{2}$$ I don't know how I started but my result in try is : I see $\frac{3+\sqrt{5}}{2}+\frac{2}{3+\sqrt{5}}=3=x_{0}$ I don't know  where this can help me I have already to see your hints or ideas to approach it,Let sequence with Then prove that : I don't know how I started but my result in try is : I see I don't know  where this can help me I have already to see your hints or ideas to approach it,x_{n+1}=x_{n}^{2}-2 x_{0}=3 \displaystyle\lim_{n\to +\infty}\left(x_{0}x_{1}...x_{n-1}\right)^{\frac{1}{2^{n}}}=\frac{3+\sqrt{5}}{2} \frac{3+\sqrt{5}}{2}+\frac{2}{3+\sqrt{5}}=3=x_{0},"['calculus', 'sequences-and-series', 'limits']"
51,"If A entails B, and B entails C, does A entail C?","If A entails B, and B entails C, does A entail C?",,Or does C entail A? This is a most simple question that bothers me why I don't understand the answer. Propositional logic is very difficult for me. Could you please help me out?,Or does C entail A? This is a most simple question that bothers me why I don't understand the answer. Propositional logic is very difficult for me. Could you please help me out?,,"['sequences-and-series', 'logic']"
52,Does this system of infinite equations has an (almost) unique solution?,Does this system of infinite equations has an (almost) unique solution?,,"Let $a_1,\dots ,a_n \in \Bbb C$ , consider the following system of equations $$\begin{cases} x_1+ \cdots+ x_n=a_1 \\ {x_1}^2+\cdots+{x_n}^2=a_2 \\ \qquad \qquad \vdots \\ {x_1}^n+\cdots+{x_n}^n=a_n \end{cases}$$ Its ""easy"" to prove this system has a unique solution up to permutations. The reason is due to Newton identities that allow us to create an equivalent system $$\begin{cases} e_1(x_1,\dots,x_n)=b_1 \\ e_2(x_1,\dots,x_n)=b_2 \\ \qquad \qquad \vdots \\ e_n(x_1,\dots,x_n)=b_n \end{cases}$$ Where $e_1, \dots ,e_n$ are the elementary symmetric polynomials and $b_1, \dots ,b_n \in \Bbb C$ are numbers which can be calculated in terms of $a_1, \dots ,a_n$ . If we consider the polynomial $$P(X)=X^n-b_1 \cdot X^{n-1}+b_2 \cdot X^{n-2} + \cdots+(-1)^n \cdot b_0$$ Then, due to Vieta's Formulas, the solution to our system are precisely the  roots of $P$ (counted with multiplicity) which are unique up to permutations. My question is the following, let $(a_n)_{n\in \Bbb N}$ be complex numbers and consider the following system of infinite equations in $l^1(\Bbb C)$ $$\begin{cases} \sum_{n \in \Bbb N} x_n = a_1  \\ \sum_{n \in \Bbb N} {x_n}^2 = a_2 \\ \qquad \quad \vdots \\ \sum_{n \in \Bbb N} {x_n}^k = a_k \\ \qquad \quad \vdots \end{cases}$$ Are there any necessary/sufficienct conditions over $(a_n)_{n\in \Bbb N}$ for a solution to exist? If $(x_n)_{n\in \Bbb N}$ is a solution to our system and $\sigma : \Bbb N \rightarrow \Bbb N$ is a bijection then $(x_{\sigma (n)})_{n\in \Bbb N}$ is a solution to our system so any permutation of a solution is again a solution. Also, if we take a solution $(x_n)_{n\in \Bbb N}$ and we ""add"" zeros to our sequence then we get another solution, for example, the sequence $(y_n)_{n\in \Bbb N}$ defined as $$y_{2n}=0 \qquad ; \qquad y_{2n-1}=x_n \qquad \forall n \in \Bbb N$$ Is another solution to our system of equations. My second question would be the following. If our system of infinite equations has two solutions, $(x_n)_{n\in \Bbb N}$ and $(y_n)_{n\in \Bbb N}$ , is it true that I can get $(y_n)_{n\in \Bbb N}$ by taking $(x_n)_{n\in \Bbb N}$ and adding zeros and making permutations? Inspired by the finite case, I did the following approach. Its easy to prove (again, using Newton Identities) that if $(x_n)_{n\in \Bbb N} \in l^1(\Bbb C)$ then the following limit exists for every $k \in \Bbb N_0$ $$e_k(x):=\lim_{n \to \infty} e_k(x_1,\dots ,x_n) < \infty$$ And it can be calculated in terms of $\sum_{n \in \Bbb N} x_n , \dots , \sum_{n \in \Bbb N} {x_n}^k$ so we get the following (equivalent) system of equations $$\begin{cases} e_1(x) = b_1  \\ e_2(x) = b_2 \\ \qquad \vdots \\ e_k(x) = b_k \\ \qquad \vdots \end{cases}$$ Where $(b_n)_{n\in \Bbb N}$ are complex numbers which can be calculated in terms of $(a_n)_{n\in \Bbb N}$ . To reproduce the following step in the finite case, we will make some modifications in the approach. By Vieta's formulas, it's easy to check the following polynomial equality $$\prod_{k=1}^n (1-x_i \cdot X) = \sum_{k=0}^n (-1)^k \cdot e_k(x_1,\dots, x_n) \cdot X^k$$ With $x_1,\dots ,x_n \in \Bbb C$ . Note that the roots of this polynomial are ${x_i}^{-1}$ for every $x_i \not = 0$ . I would like to say (and have no idea how to prove) that if $(x_n)_{n \in \Bbb N} \in l^1(\Bbb C)$ then $$\prod_{k=1}^\infty (1-x_i \cdot z) = \sum_{k=0}^\infty (-1)^k \cdot e_k(x) \cdot z^k \qquad \forall \; z \in \Bbb C$$ If this is true, going back to our infinite system of equations, we could consider the series $$f(z)=1+ \sum_{k=1}^\infty (-1)^k \cdot b_k \cdot z^k$$ Wich is a function we can ""calculate"" since we know $(b_k)_{k \in \Bbb N}$ . We should ask some conditions over $(b_k)_{k \in \Bbb N}$ for this to be well defined over an open set around zero (or all over $\Bbb C$ ). Let $(r_n)_{n \in \Bbb N}$ be the roots of $f$ counted with multiplicity (Does this have a meaning???), let $x_n = {r_n}^{-1} \quad \forall n \in \Bbb N$ (Note $r_n \not = 0 \quad \forall n \in \Bbb N$ because $f(0)=1$ ), if $f$ has finite roots, we fill the sequence with zeros. I affirm that $(x_n)_{n \in \Bbb N}$ is a solution to our system. There are a LOT of gaps in my reasoning and Im not sure how to continue. My Complex analysis knowledge is really weak.","Let , consider the following system of equations Its ""easy"" to prove this system has a unique solution up to permutations. The reason is due to Newton identities that allow us to create an equivalent system Where are the elementary symmetric polynomials and are numbers which can be calculated in terms of . If we consider the polynomial Then, due to Vieta's Formulas, the solution to our system are precisely the  roots of (counted with multiplicity) which are unique up to permutations. My question is the following, let be complex numbers and consider the following system of infinite equations in Are there any necessary/sufficienct conditions over for a solution to exist? If is a solution to our system and is a bijection then is a solution to our system so any permutation of a solution is again a solution. Also, if we take a solution and we ""add"" zeros to our sequence then we get another solution, for example, the sequence defined as Is another solution to our system of equations. My second question would be the following. If our system of infinite equations has two solutions, and , is it true that I can get by taking and adding zeros and making permutations? Inspired by the finite case, I did the following approach. Its easy to prove (again, using Newton Identities) that if then the following limit exists for every And it can be calculated in terms of so we get the following (equivalent) system of equations Where are complex numbers which can be calculated in terms of . To reproduce the following step in the finite case, we will make some modifications in the approach. By Vieta's formulas, it's easy to check the following polynomial equality With . Note that the roots of this polynomial are for every . I would like to say (and have no idea how to prove) that if then If this is true, going back to our infinite system of equations, we could consider the series Wich is a function we can ""calculate"" since we know . We should ask some conditions over for this to be well defined over an open set around zero (or all over ). Let be the roots of counted with multiplicity (Does this have a meaning???), let (Note because ), if has finite roots, we fill the sequence with zeros. I affirm that is a solution to our system. There are a LOT of gaps in my reasoning and Im not sure how to continue. My Complex analysis knowledge is really weak.","a_1,\dots ,a_n \in \Bbb C \begin{cases} x_1+ \cdots+ x_n=a_1 \\ {x_1}^2+\cdots+{x_n}^2=a_2 \\ \qquad \qquad \vdots \\ {x_1}^n+\cdots+{x_n}^n=a_n \end{cases} \begin{cases} e_1(x_1,\dots,x_n)=b_1 \\ e_2(x_1,\dots,x_n)=b_2 \\ \qquad \qquad \vdots \\ e_n(x_1,\dots,x_n)=b_n \end{cases} e_1, \dots ,e_n b_1, \dots ,b_n \in \Bbb C a_1, \dots ,a_n P(X)=X^n-b_1 \cdot X^{n-1}+b_2 \cdot X^{n-2} + \cdots+(-1)^n \cdot b_0 P (a_n)_{n\in \Bbb N} l^1(\Bbb C) \begin{cases} \sum_{n \in \Bbb N} x_n = a_1
 \\ \sum_{n \in \Bbb N} {x_n}^2 = a_2 \\ \qquad \quad \vdots \\ \sum_{n \in \Bbb N} {x_n}^k = a_k \\ \qquad \quad \vdots \end{cases} (a_n)_{n\in \Bbb N} (x_n)_{n\in \Bbb N} \sigma : \Bbb N \rightarrow \Bbb N (x_{\sigma (n)})_{n\in \Bbb N} (x_n)_{n\in \Bbb N} (y_n)_{n\in \Bbb N} y_{2n}=0 \qquad ; \qquad y_{2n-1}=x_n \qquad \forall n \in \Bbb N (x_n)_{n\in \Bbb N} (y_n)_{n\in \Bbb N} (y_n)_{n\in \Bbb N} (x_n)_{n\in \Bbb N} (x_n)_{n\in \Bbb N} \in l^1(\Bbb C) k \in \Bbb N_0 e_k(x):=\lim_{n \to \infty} e_k(x_1,\dots ,x_n) < \infty \sum_{n \in \Bbb N} x_n , \dots , \sum_{n \in \Bbb N} {x_n}^k \begin{cases} e_1(x) = b_1
 \\ e_2(x) = b_2 \\ \qquad \vdots \\ e_k(x) = b_k \\ \qquad \vdots \end{cases} (b_n)_{n\in \Bbb N} (a_n)_{n\in \Bbb N} \prod_{k=1}^n (1-x_i \cdot X) = \sum_{k=0}^n (-1)^k \cdot e_k(x_1,\dots, x_n) \cdot X^k x_1,\dots ,x_n \in \Bbb C {x_i}^{-1} x_i \not = 0 (x_n)_{n \in \Bbb N} \in l^1(\Bbb C) \prod_{k=1}^\infty (1-x_i \cdot z) = \sum_{k=0}^\infty (-1)^k \cdot e_k(x) \cdot z^k \qquad \forall \; z \in \Bbb C f(z)=1+ \sum_{k=1}^\infty (-1)^k \cdot b_k \cdot z^k (b_k)_{k \in \Bbb N} (b_k)_{k \in \Bbb N} \Bbb C (r_n)_{n \in \Bbb N} f x_n = {r_n}^{-1} \quad \forall n \in \Bbb N r_n \not = 0 \quad \forall n \in \Bbb N f(0)=1 f (x_n)_{n \in \Bbb N}","['sequences-and-series', 'complex-analysis', 'polynomials', 'systems-of-equations', 'symmetric-polynomials']"
53,Closed form of asymptotic behaviour of $\sum_{k=1}^n \sin(\sqrt{k})$,Closed form of asymptotic behaviour of,\sum_{k=1}^n \sin(\sqrt{k}),"Motivated by the studies of convergence of various series of trigonometric fuctions with non trivial arguments which reached a peak in the sophisticated proof that $\sum_{k=1}^\infty \frac{\sin{n^k}}{n}$ is convergent for $k \gt 0$ ( Convergence of $\sum \limits_{n=1}^{\infty}\sin(n^k)/n$ ) I came up with the more general problem, valid also for divergent series : what is the asymptotic behaviour of the partial sums? And, more complicated, can closed forms be given? Here is a first example: Let $$f(k) = \sin(\sqrt{k}),s(n) = \sum_{k=0}^n f(k)$$ Problems: a) Show that for $n\to \infty$ we have $$s(n\to \infty) = 2 \sin \left(\sqrt{n}\right)-2 \sqrt{n} \cos \left(\sqrt{n}\right) + c + \frac{\sin \left(\sqrt{n}\right)}{2} + O\left (\frac{1}{\sqrt{n}}\right )$$ with come constant $c \simeq -0.203569...$ . b) find a possible closed form for $c$","Motivated by the studies of convergence of various series of trigonometric fuctions with non trivial arguments which reached a peak in the sophisticated proof that is convergent for ( Convergence of $\sum \limits_{n=1}^{\infty}\sin(n^k)/n$ ) I came up with the more general problem, valid also for divergent series : what is the asymptotic behaviour of the partial sums? And, more complicated, can closed forms be given? Here is a first example: Let Problems: a) Show that for we have with come constant . b) find a possible closed form for","\sum_{k=1}^\infty \frac{\sin{n^k}}{n} k \gt 0 f(k) = \sin(\sqrt{k}),s(n) = \sum_{k=0}^n f(k) n\to \infty s(n\to \infty) = 2 \sin \left(\sqrt{n}\right)-2 \sqrt{n} \cos \left(\sqrt{n}\right) + c + \frac{\sin \left(\sqrt{n}\right)}{2} + O\left (\frac{1}{\sqrt{n}}\right ) c \simeq -0.203569... c","['sequences-and-series', 'summation', 'asymptotics']"
54,Finding the geometric progression based on the given details,Finding the geometric progression based on the given details,,"The sum of infinite number of terms of a GP is 4, and the sum of their cubes is 192. Find the series. The following image is solution from my book. My doubt is why is $r=-2$ rejected? Is there any reason. If so please tell me.","The sum of infinite number of terms of a GP is 4, and the sum of their cubes is 192. Find the series. The following image is solution from my book. My doubt is why is rejected? Is there any reason. If so please tell me.",r=-2,[]
55,High precision evaluation of the series $\sum_{n=3}^\infty (-1)^n (1-n^{1/n})$,High precision evaluation of the series,\sum_{n=3}^\infty (-1)^n (1-n^{1/n}),"This series converges conditionally, but it's quite slow. I would like to find its value with high accuracy: $$S=\sum_{n=3}^\infty (-1)^n (1-n^{1/n})$$ Wolfram Alpha gives $S \approx 0.226354\ldots$ . Since the terms decrease monotonely in absolute value, we can apply an approximate estimation: $$S_N= \sum_{n=3}^{N-1} (-1)^n (1-n^{1/n})+ \frac{1}{2} (-1)^N (1-N^{1/N})$$ $$S_{100}=0.22644\ldots$$ $$S_{101}=0.22626\ldots$$ $$\frac{S_{100}+S_{101}}{2} =0.22635473854439942\ldots$$ Another way could be to transform the series, for example: $$n^{1/n}=\exp \frac{\log n}{n}=\sum_{k=0}^\infty \frac{\log^k n}{n^k k!}$$ Which gives us (assuming we are allowed to change the order of summation): $$S=\sum_{k=1}^\infty \frac{1}{k!} \sum_{n=3}^\infty (-1)^{n+1} \frac{\log^k n}{n^k}=\sum_{k=1}^\infty \frac{S_k}{k!}$$ The inner series $S_k>0$ can be expressed in terms of repeated derivatives of the zeta function, which don't have a closed form for $k \geq 2$ , but the series can still be evaluated numerically with high accuracy. Note $$S_1=\frac{\log 2}{2} (1+\log 2-2\gamma)$$ For $k \geq 2$ we can easily write: $$S_k=\sum_{q=1}^\infty \frac{\log^k (2q+1)}{(2q+1)^k}-\sum_{q=2}^\infty \frac{\log^k (2q)}{(2q)^k}$$ Both the series converge absolutely and can be easily approximated by Euler-Maclaurin summation with all the integrals and derivatives expressed in closed form (obviously for large $k$ it becomes unwieldy). Evaluating the series up to $S_6$ we obtain: $$S > 0.2263538 \ldots$$ Still not that good. Finally, we could use Euler-Maclaurin, but I'm not sure how to apply it in this case, especially how to deal with the integral.","This series converges conditionally, but it's quite slow. I would like to find its value with high accuracy: Wolfram Alpha gives . Since the terms decrease monotonely in absolute value, we can apply an approximate estimation: Another way could be to transform the series, for example: Which gives us (assuming we are allowed to change the order of summation): The inner series can be expressed in terms of repeated derivatives of the zeta function, which don't have a closed form for , but the series can still be evaluated numerically with high accuracy. Note For we can easily write: Both the series converge absolutely and can be easily approximated by Euler-Maclaurin summation with all the integrals and derivatives expressed in closed form (obviously for large it becomes unwieldy). Evaluating the series up to we obtain: Still not that good. Finally, we could use Euler-Maclaurin, but I'm not sure how to apply it in this case, especially how to deal with the integral.",S=\sum_{n=3}^\infty (-1)^n (1-n^{1/n}) S \approx 0.226354\ldots S_N= \sum_{n=3}^{N-1} (-1)^n (1-n^{1/n})+ \frac{1}{2} (-1)^N (1-N^{1/N}) S_{100}=0.22644\ldots S_{101}=0.22626\ldots \frac{S_{100}+S_{101}}{2} =0.22635473854439942\ldots n^{1/n}=\exp \frac{\log n}{n}=\sum_{k=0}^\infty \frac{\log^k n}{n^k k!} S=\sum_{k=1}^\infty \frac{1}{k!} \sum_{n=3}^\infty (-1)^{n+1} \frac{\log^k n}{n^k}=\sum_{k=1}^\infty \frac{S_k}{k!} S_k>0 k \geq 2 S_1=\frac{\log 2}{2} (1+\log 2-2\gamma) k \geq 2 S_k=\sum_{q=1}^\infty \frac{\log^k (2q+1)}{(2q+1)^k}-\sum_{q=2}^\infty \frac{\log^k (2q)}{(2q)^k} k S_6 S > 0.2263538 \ldots,"['sequences-and-series', 'approximation', 'euler-maclaurin']"
56,"A series such that $\sum {a_n}$ converges, but $\sum {a_{3n}}$ diverges.","A series such that  converges, but  diverges.",\sum {a_n} \sum {a_{3n}},"Give an example of a convergent series $\sum {a_n}$ such that the series $\sum {a_{3n}}$ is divergent. Give an example of a divergent series $\sum {b_n}$ such that the series $\sum {b_{3n}}$ is convergent. Attempt: I am not sure if this is a valid forumla for a sequence : $ a_{3n-2} = \frac{1}{1+4(n-1)} ,a_{3n-1} = \frac{1}{3+4(n-1)}, a_{3n} = -\frac{1}{2n}$ . This series converges to $\frac{3}{2} \log(2)$ . But, $\sum {a_{3n}}$ diverges. We define $b_{3n-2}=1 , b_{3n-1}=1, b_{3n} = \frac{1}{n^2}$ . The series diverges, but $\sum{b_{3n}}$ converges to $\frac{\pi^2}{6} $ The problem is, I am not sure if the this type of ""formula"" works [unlike the sequence defined by $1/n$ or something. Is this valid to define the sequence ""term-by-term"" (here, three different types of indices)?].","Give an example of a convergent series such that the series is divergent. Give an example of a divergent series such that the series is convergent. Attempt: I am not sure if this is a valid forumla for a sequence : . This series converges to . But, diverges. We define . The series diverges, but converges to The problem is, I am not sure if the this type of ""formula"" works [unlike the sequence defined by or something. Is this valid to define the sequence ""term-by-term"" (here, three different types of indices)?].","\sum {a_n} \sum {a_{3n}} \sum {b_n} \sum {b_{3n}}  a_{3n-2} = \frac{1}{1+4(n-1)} ,a_{3n-1} = \frac{1}{3+4(n-1)}, a_{3n} = -\frac{1}{2n} \frac{3}{2} \log(2) \sum {a_{3n}} b_{3n-2}=1 , b_{3n-1}=1, b_{3n} = \frac{1}{n^2} \sum{b_{3n}} \frac{\pi^2}{6}  1/n","['real-analysis', 'sequences-and-series', 'proof-verification', 'convergence-divergence', 'real-numbers']"
57,$|x_{n + 1} - x_n| < \frac{1}{2^n} \Rightarrow (x_n)$ is Cauchy [duplicate],is Cauchy [duplicate],|x_{n + 1} - x_n| < \frac{1}{2^n} \Rightarrow (x_n),"This question already has answers here : How to show if $|a_{n+1} - a_{n}| \le \frac{1}{2^n}$ then the sequence is Cauchy. (3 answers) Closed 5 years ago . Let $(x_n)$ be a real sequence with the property that for all $n \in \mathbb{N}$ , $$|x_{n + 1} - x_n| < \frac{1}{2^n}$$ I want to show, using the definition of a Cauchy sequence, that $(x_n)$ must be Cauchy. I have found that the property implies that for any $(m, n) \in \mathbb{R}^2$ , assuming without loss of generality that $m > n$ , it must be true that $$|x_n - x_m| \leq \sum\limits_{i = n}^m \frac{1}{2^i}$$ How can I proceed from there ? Is this even the right way to approach this problem?","This question already has answers here : How to show if $|a_{n+1} - a_{n}| \le \frac{1}{2^n}$ then the sequence is Cauchy. (3 answers) Closed 5 years ago . Let be a real sequence with the property that for all , I want to show, using the definition of a Cauchy sequence, that must be Cauchy. I have found that the property implies that for any , assuming without loss of generality that , it must be true that How can I proceed from there ? Is this even the right way to approach this problem?","(x_n) n \in \mathbb{N} |x_{n + 1} - x_n| < \frac{1}{2^n} (x_n) (m, n) \in \mathbb{R}^2 m > n |x_n - x_m| \leq \sum\limits_{i = n}^m \frac{1}{2^i}","['sequences-and-series', 'analysis', 'cauchy-sequences']"
58,Evaluate the limit: $\lim\limits_{n\to\infty} \frac{4^nn!}{(3n)^n}$,Evaluate the limit:,\lim\limits_{n\to\infty} \frac{4^nn!}{(3n)^n},"Evaluate the following limit $$ \lim_{n\to\infty} \frac{4^nn!}{(3n)^n} $$ I've shown the limit is equal to $0$ . One may for example use the ration test by which: $$ \begin{align} \frac{x_{n+1}}{x_n} &= \left({4\over 3}\right)^{n+1}\frac{(n+1)!}{(n+1)^{n+1}} \cdot \left({3\over 4}\right)^{n}\frac{n^n}{n!}\\ &= \frac{4}{3}\frac{n^n}{(n+1)^n} \end{align} $$ Now taking the limit of the fraction: $$ {4\over 3}\lim_{n\to\infty} \left(n\over n+1\right)^n = {4\over 3e} < 1 $$ By this the sequence is converging to $0$ . Another way could be Stirling's approximatiom, by which: $$ \frac{4^nn!}{(3n)^n} \sim \frac{4^n}{(3n)^n}\cdot \sqrt{2\pi n}\cdot\left({n\over e}\right)^n = \left({4\over 3e}\right)^n\sqrt{2\pi n} $$ Applying ration test after Stirling's approximation yields the same result. The problem is that Stirling's approximation has not been introduced yet. Also this limit comes right after the problems on proving some specific statements, among which are: $$ \begin{align*} \lim_{n\to\infty} x_n = x &\implies \lim_{n\to\infty}\frac{x_1 + x_2 + \cdots +x_n}{n} = x \tag 1\\ \lim_{n\to\infty} x_n = x &\implies \lim_{n\to\infty} \sqrt[n]{x_1x_2\dots x_n} = x\tag 2\\ \lim_{n\to\infty}\frac{x_{n+1}}{x_n} = x &\implies \lim_{n\to\infty} \sqrt[n]{x_n} = x\tag 3 \end{align*} $$ Right before the problem from question section the book is asking to find the limit of: $$ \lim_{n\to\infty} {1\over n}\sqrt[n]{(n+1)(n+2)\dots(2n)} $$ This may be easily handled by applying $(3)$ . My assumption is that the author expects me to use one of those proofs I've done before, however I don't see how any of them may be applied. Also please note that proving Cesaro-Stolz is following this limit. I would appreciate if someone could point me to a way to use $(1), (2)$ or $(3)$ for evaluating the limit. Or possibly suggest other approaches to find that limit from question section. Thank you!","Evaluate the following limit I've shown the limit is equal to . One may for example use the ration test by which: Now taking the limit of the fraction: By this the sequence is converging to . Another way could be Stirling's approximatiom, by which: Applying ration test after Stirling's approximation yields the same result. The problem is that Stirling's approximation has not been introduced yet. Also this limit comes right after the problems on proving some specific statements, among which are: Right before the problem from question section the book is asking to find the limit of: This may be easily handled by applying . My assumption is that the author expects me to use one of those proofs I've done before, however I don't see how any of them may be applied. Also please note that proving Cesaro-Stolz is following this limit. I would appreciate if someone could point me to a way to use or for evaluating the limit. Or possibly suggest other approaches to find that limit from question section. Thank you!","
\lim_{n\to\infty} \frac{4^nn!}{(3n)^n}
 0 
\begin{align}
\frac{x_{n+1}}{x_n} &= \left({4\over 3}\right)^{n+1}\frac{(n+1)!}{(n+1)^{n+1}} \cdot \left({3\over 4}\right)^{n}\frac{n^n}{n!}\\
&= \frac{4}{3}\frac{n^n}{(n+1)^n}
\end{align}
 
{4\over 3}\lim_{n\to\infty} \left(n\over n+1\right)^n = {4\over 3e} < 1
 0 
\frac{4^nn!}{(3n)^n} \sim \frac{4^n}{(3n)^n}\cdot \sqrt{2\pi n}\cdot\left({n\over e}\right)^n = \left({4\over 3e}\right)^n\sqrt{2\pi n}
 
\begin{align*}
\lim_{n\to\infty} x_n = x &\implies \lim_{n\to\infty}\frac{x_1 + x_2 + \cdots +x_n}{n} = x \tag 1\\
\lim_{n\to\infty} x_n = x &\implies \lim_{n\to\infty} \sqrt[n]{x_1x_2\dots x_n} = x\tag 2\\
\lim_{n\to\infty}\frac{x_{n+1}}{x_n} = x &\implies \lim_{n\to\infty} \sqrt[n]{x_n} = x\tag 3
\end{align*}
 
\lim_{n\to\infty} {1\over n}\sqrt[n]{(n+1)(n+2)\dots(2n)}
 (3) (1), (2) (3)","['real-analysis', 'sequences-and-series', 'limits']"
59,Simple example on uniformly convex spaces,Simple example on uniformly convex spaces,,"In the lectures we showed the following result: Theorem: Let $(E,\|\cdot\|_E)$ be a uniformly convex space. Consider a sequence $\{x_n \}\rvert_{n\in\mathbb{N}} \subset E$ and $x \in E$ such that it converges weakly to $x\in E$ $$ x_n\rightharpoonup x ,$$ and the sequence of the norms converges to the norm of $x\in E$ , i.e. $$\|x_n\|_E \longrightarrow \|x\|_E.$$ Then the sequence $\{x_n \}\rvert_{n\in\mathbb{N}} \subset E$ is strongly convergent $$x_n \longrightarrow x.$$ This means that weak convergence, together with the convergence of the norms imply strong converge in uniformly convex spaces. Question: Could you please provide a counterexample on a non uniformly convex space (maybe sequence space of bounded sequences $\ell^\infty$ ?) where this result does not hold? Concretely: A sequence on a non uniformly convex space such that it is weak convergent, and the sequence of the norms converges, but the sequence itself is not strongly convergent. I would be grateful to read any possible counterexample. Thanks!","In the lectures we showed the following result: Theorem: Let be a uniformly convex space. Consider a sequence and such that it converges weakly to and the sequence of the norms converges to the norm of , i.e. Then the sequence is strongly convergent This means that weak convergence, together with the convergence of the norms imply strong converge in uniformly convex spaces. Question: Could you please provide a counterexample on a non uniformly convex space (maybe sequence space of bounded sequences ?) where this result does not hold? Concretely: A sequence on a non uniformly convex space such that it is weak convergent, and the sequence of the norms converges, but the sequence itself is not strongly convergent. I would be grateful to read any possible counterexample. Thanks!","(E,\|\cdot\|_E) \{x_n \}\rvert_{n\in\mathbb{N}} \subset E x \in E x\in E  x_n\rightharpoonup x , x\in E \|x_n\|_E \longrightarrow \|x\|_E. \{x_n \}\rvert_{n\in\mathbb{N}} \subset E x_n \longrightarrow x. \ell^\infty","['sequences-and-series', 'functional-analysis', 'analysis', 'convergence-divergence', 'weak-convergence']"
60,Let $\sum_{k=1}^\infty a_n$ be convergent show that $\sum_{k=1}^\infty n(a_n-a_{n+1})$ converges,Let  be convergent show that  converges,\sum_{k=1}^\infty a_n \sum_{k=1}^\infty n(a_n-a_{n+1}),Let $\sum\limits_{k=1}^\infty a_n$ be a convergent series where $a_n\geq0$ and $(a_n)$ is a monotone decreasing sequence prove that the series $\sum\limits_{k=1}^\infty n(a_n-a_{n+1})$ also converges. What I tried : Let $(A_n)$ be the sequence of partial sums of the series $\sum\limits_{k=1}^\infty a_n$ and $(B_n)$ be the sequence of partial sums of the series $\sum\limits_{k=1}^\infty n(a_n-a_{n+1})$ . Since $A_n=\sum\limits_{k=1}^n a_k$ and $B_n=\sum\limits_{k=1}^n k(a_k-a_{k+1})$ we get that: \begin{align} B_n&=A_n-na_{n+1}\\ &=(a_1-a_{n+1})+(a_2-a_{n+1})+...+(a_n-a_{n+1})\\ &>(a_1-a_n)+(a_2-a_n)+...+(a_n-a_n)\\ &=B_{n-1} \end{align} we see that $(B_n)$ is a monotone increasing sequence $...(1)$ and $B_n=A_n-na_{n+1}<A_n$ this implies that the sequence $(B_n)$ is bounded above ...(2) Therefore (from (1) and (2)) the sequence $(B_n)$ converges so the series $\sum\limits_{k=1}^\infty n(a_n-a_{n+1})$ also converges Is my proof correct?,Let be a convergent series where and is a monotone decreasing sequence prove that the series also converges. What I tried : Let be the sequence of partial sums of the series and be the sequence of partial sums of the series . Since and we get that: we see that is a monotone increasing sequence and this implies that the sequence is bounded above ...(2) Therefore (from (1) and (2)) the sequence converges so the series also converges Is my proof correct?,"\sum\limits_{k=1}^\infty a_n a_n\geq0 (a_n) \sum\limits_{k=1}^\infty n(a_n-a_{n+1}) (A_n) \sum\limits_{k=1}^\infty a_n (B_n) \sum\limits_{k=1}^\infty n(a_n-a_{n+1}) A_n=\sum\limits_{k=1}^n a_k B_n=\sum\limits_{k=1}^n k(a_k-a_{k+1}) \begin{align}
B_n&=A_n-na_{n+1}\\
&=(a_1-a_{n+1})+(a_2-a_{n+1})+...+(a_n-a_{n+1})\\
&>(a_1-a_n)+(a_2-a_n)+...+(a_n-a_n)\\
&=B_{n-1}
\end{align} (B_n) ...(1) B_n=A_n-na_{n+1}<A_n (B_n) (B_n) \sum\limits_{k=1}^\infty n(a_n-a_{n+1})","['real-analysis', 'sequences-and-series', 'proof-verification', 'convergence-divergence']"
61,"Natural density of set $\{4^nk\}$, where $k$ is odd","Natural density of set , where  is odd",\{4^nk\} k,"A starting point is this problem: $P \subset Z_n = \{1, 2, \dots, n\}$ is binary , if there exists a number $k$ such that both $k \in P$ and $2k \in P$ , otherwise it is antibinary . One is supposed, for given $n$ , to show antibinary set with maximum amount of elements (there might be many sets satisfying this property). One can show that set $P_n = \{4^m(2k + 1) \mid m, k \in \mathbb{N}\} \cap Z_n$ is a proper solution. My question is: how big is this set? I'm looking for $\displaystyle\lim_{n \to \infty} p_n$ , where $p_n = \dfrac{|P_n|}{n}$ . Simple program I wrote in Python suggests that the answer is $\dfrac{2}{3}$ , but I don't know, how to prove it.","A starting point is this problem: is binary , if there exists a number such that both and , otherwise it is antibinary . One is supposed, for given , to show antibinary set with maximum amount of elements (there might be many sets satisfying this property). One can show that set is a proper solution. My question is: how big is this set? I'm looking for , where . Simple program I wrote in Python suggests that the answer is , but I don't know, how to prove it.","P \subset Z_n = \{1, 2, \dots, n\} k k \in P 2k \in P n P_n = \{4^m(2k + 1) \mid m, k \in \mathbb{N}\} \cap Z_n \displaystyle\lim_{n \to \infty} p_n p_n = \dfrac{|P_n|}{n} \dfrac{2}{3}","['sequences-and-series', 'elementary-number-theory']"
62,Then value of $\alpha^2 +4\alpha$ in Infinite series,Then value of  in Infinite series,\alpha^2 +4\alpha,"If $\displaystyle \alpha = \frac{5}{2!\cdot 3}+\frac{5\cdot 7}{3!\cdot 3^2}+\frac{5\cdot 7 \cdot 9}{4!\cdot 3^3}+\cdots \cdots \infty.$ Then value of $\alpha^2 +4\alpha$ is Try: Let $$S = \frac{5}{2!\cdot 3}+\frac{5\cdot 7}{3!\cdot 3^2}+\frac{5\cdot 7 \cdot 9}{4!\cdot 3^3}+\cdots \cdots $$ $$S+1 = 1+\frac{5}{2!\cdot 3}+\frac{5\cdot 7}{3!\cdot 3^2}+\frac{5\cdot 7 \cdot 9}{4!\cdot 3^3}+\cdots \cdots $$ Now camparing with $$(1+x)^n = 1+nx+\frac{n(n-1)x^2}{2!}+\frac{n(n-1)(n-2)x^3}{6\cdot 3!}+\cdots \cdots$$ So $\displaystyle nx=\frac{5}{6}$ and $\displaystyle \frac{n(n-1)x^2}{2}=\frac{35}{27}$ So $$\frac{nx(nx-x)}{2}=\frac{5}{12}\cdot \frac{5-6x}{6}=\frac{35}{27}$$ So $\displaystyle x=-\frac{41}{18}$ and $\displaystyle n=-\frac{15}{41}$ I am getting $\displaystyle S+1=\bigg(1-\frac{41}{18}\bigg)^{-\frac{15}{41}}$ but answer of $\alpha^2+4\alpha = 23$ which is not possible from my answer. could some help me how can i solve it, thanks","If Then value of is Try: Let Now camparing with So and So So and I am getting but answer of which is not possible from my answer. could some help me how can i solve it, thanks",\displaystyle \alpha = \frac{5}{2!\cdot 3}+\frac{5\cdot 7}{3!\cdot 3^2}+\frac{5\cdot 7 \cdot 9}{4!\cdot 3^3}+\cdots \cdots \infty. \alpha^2 +4\alpha S = \frac{5}{2!\cdot 3}+\frac{5\cdot 7}{3!\cdot 3^2}+\frac{5\cdot 7 \cdot 9}{4!\cdot 3^3}+\cdots \cdots  S+1 = 1+\frac{5}{2!\cdot 3}+\frac{5\cdot 7}{3!\cdot 3^2}+\frac{5\cdot 7 \cdot 9}{4!\cdot 3^3}+\cdots \cdots  (1+x)^n = 1+nx+\frac{n(n-1)x^2}{2!}+\frac{n(n-1)(n-2)x^3}{6\cdot 3!}+\cdots \cdots \displaystyle nx=\frac{5}{6} \displaystyle \frac{n(n-1)x^2}{2}=\frac{35}{27} \frac{nx(nx-x)}{2}=\frac{5}{12}\cdot \frac{5-6x}{6}=\frac{35}{27} \displaystyle x=-\frac{41}{18} \displaystyle n=-\frac{15}{41} \displaystyle S+1=\bigg(1-\frac{41}{18}\bigg)^{-\frac{15}{41}} \alpha^2+4\alpha = 23,['sequences-and-series']
63,$\sum a_n$ converges iff $\sum \frac{a_n}{1+a_n}$ converges.,converges iff  converges.,\sum a_n \sum \frac{a_n}{1+a_n},"This is a modification of a problem in Rudin. Let $(a_n)$ be a sequence of positive numbers (that is $a_n \geq 0)$. Then $\sum a_n$ converges iff $\sum \frac{a_n}{1+a_n}$ converges. My attempt : $\Rightarrow$ $$\frac{a_n}{1+a_n} \leq a_n$$ and this follows from comparison test. $\Leftarrow$ Since $$a_n = \frac{a_n}{1+a_n} (1+a_n) = \frac{a_n}{1+a_n} + \frac{a_n^2}{1+a_n}$$ it suffices to show that $\sum \frac{a_n^2}{1+a_n}$ converges. For this, it suffices to show that $(a_n)$ is bounded, because then the result follows from the comparison test. Indeed, let $M$ be an upperbound. Then $$\frac{a_n^2}{1+a_n} \leq \frac{Ma_n}{1+a_n}$$ We will prove that $a_n \to 0$, and this will prove the boundedness. Let $\epsilon > 0$. Choose $N$ such that $\frac{a_n}{1+a_n} < \frac{\epsilon}{1+ \epsilon}$ for $n \geq N$, which is possible since $\frac{a_n}{1+a_n} \to 0$ since the series converges. Then, $n \geq N$ implies that $a_n < \epsilon$ and the result follows. Is this correct? Is there an easier way?","This is a modification of a problem in Rudin. Let $(a_n)$ be a sequence of positive numbers (that is $a_n \geq 0)$. Then $\sum a_n$ converges iff $\sum \frac{a_n}{1+a_n}$ converges. My attempt : $\Rightarrow$ $$\frac{a_n}{1+a_n} \leq a_n$$ and this follows from comparison test. $\Leftarrow$ Since $$a_n = \frac{a_n}{1+a_n} (1+a_n) = \frac{a_n}{1+a_n} + \frac{a_n^2}{1+a_n}$$ it suffices to show that $\sum \frac{a_n^2}{1+a_n}$ converges. For this, it suffices to show that $(a_n)$ is bounded, because then the result follows from the comparison test. Indeed, let $M$ be an upperbound. Then $$\frac{a_n^2}{1+a_n} \leq \frac{Ma_n}{1+a_n}$$ We will prove that $a_n \to 0$, and this will prove the boundedness. Let $\epsilon > 0$. Choose $N$ such that $\frac{a_n}{1+a_n} < \frac{\epsilon}{1+ \epsilon}$ for $n \geq N$, which is possible since $\frac{a_n}{1+a_n} \to 0$ since the series converges. Then, $n \geq N$ implies that $a_n < \epsilon$ and the result follows. Is this correct? Is there an easier way?",,['real-analysis']
64,Proving a sequence with infinitely many zeros is not zero heavy?,Proving a sequence with infinitely many zeros is not zero heavy?,,"Is my counterexample correct? If a sequence contains an infinite number of zeroes, is it necessarily   zero-heavy? If not, provide a counterexample. Solution . Consider the sequence $(a_n)$ defined such that $a_n = 0$ whenever $n = 2^k$ for some $k\in\mathbf{N}$ and is $1$ otherwise, then given any $M\in\mathbf{N}$ we may choose a $k\in\mathbf{N}$ such that $2^{k+1}-(2^{k}+1)>M$ then given the construction of the sequence if $n\in\{2^{k}+1,2^{k+1}+2,\dots,(2^{k}+1)+M\}$ we have $a_n\neq 0$.The sequence in question then cannot possibly be zero heavy. NOTE: We define a sequence to be zero heavy if $$\exists M\in\mathbf{N}\forall N\in\mathbf{N}\exists n\in\{N,N+1,\dots,N+M\}(x_n=0)$$","Is my counterexample correct? If a sequence contains an infinite number of zeroes, is it necessarily   zero-heavy? If not, provide a counterexample. Solution . Consider the sequence $(a_n)$ defined such that $a_n = 0$ whenever $n = 2^k$ for some $k\in\mathbf{N}$ and is $1$ otherwise, then given any $M\in\mathbf{N}$ we may choose a $k\in\mathbf{N}$ such that $2^{k+1}-(2^{k}+1)>M$ then given the construction of the sequence if $n\in\{2^{k}+1,2^{k+1}+2,\dots,(2^{k}+1)+M\}$ we have $a_n\neq 0$.The sequence in question then cannot possibly be zero heavy. NOTE: We define a sequence to be zero heavy if $$\exists M\in\mathbf{N}\forall N\in\mathbf{N}\exists n\in\{N,N+1,\dots,N+M\}(x_n=0)$$",,"['real-analysis', 'sequences-and-series', 'proof-verification']"
65,"Prove the coefficients of $\prod_{k=2}^{n+1}(1-x^{a_k})$ are $0$, $1$, or $-1$ where $(a_k)$ are Fibonacci numbers.","Prove the coefficients of  are , , or  where  are Fibonacci numbers.",\prod_{k=2}^{n+1}(1-x^{a_k}) 0 1 -1 (a_k),"Given $a_1 =1,a_2=1, a_{n+2}=a_{n+1}+a_n$ , prove that for $n\geq 2$ , all coefficients of polynomial $$A(x)=\prod_{k=2}^{n+1}(1-x^{a_{k}})$$ are $0$ , $1$ , or $-1$ . I tried induction. I don't think it works. The hypothesis will be too weak. I think if we want to prove it by induction, we need to prove a stronger proposition, but I can't find it.","Given , prove that for , all coefficients of polynomial are , , or . I tried induction. I don't think it works. The hypothesis will be too weak. I think if we want to prove it by induction, we need to prove a stronger proposition, but I can't find it.","a_1 =1,a_2=1, a_{n+2}=a_{n+1}+a_n n\geq 2 A(x)=\prod_{k=2}^{n+1}(1-x^{a_{k}}) 0 1 -1","['sequences-and-series', 'polynomials', 'fibonacci-numbers']"
66,Uniform convergence of ${(1-\frac{x^2}{n})^n}$,Uniform convergence of,{(1-\frac{x^2}{n})^n},"Uniform convergence of: $$f_n(x):={(1-\frac{x^2}{n})^n}$$ (a) In a closed interval $[-L, L]$ as $L>0$ . (b) In $\mathbb{R}$ . My try: There is a pointwise convergence to $e^{-x^2}$ . Obviously, there is no uniform convergence in $\mathbb{R}$ as $\lim\limits _{x\to \infty }|f_n(x)|=\infty$ . $\;$ Thus, $\sup \limits _{x\in\mathbb{R}}|f_n(x)-e^{-x^2}|= \infty$ Can anyone give a direction for a closed interval?","Uniform convergence of: (a) In a closed interval as . (b) In . My try: There is a pointwise convergence to . Obviously, there is no uniform convergence in as . Thus, Can anyone give a direction for a closed interval?","f_n(x):={(1-\frac{x^2}{n})^n} [-L, L] L>0 \mathbb{R} e^{-x^2} \mathbb{R} \lim\limits _{x\to \infty }|f_n(x)|=\infty \; \sup \limits _{x\in\mathbb{R}}|f_n(x)-e^{-x^2}|= \infty","['real-analysis', 'calculus', 'sequences-and-series', 'uniform-convergence']"
67,"Show that $ \sum_{k=0}^{j} \binom{2j+1}{k+j+1} \ \frac{(-1)^k}{2k+1}=2^{2j-1}\ B(j+1,1/2)$.",Show that .," \sum_{k=0}^{j} \binom{2j+1}{k+j+1} \ \frac{(-1)^k}{2k+1}=2^{2j-1}\ B(j+1,1/2)","I want to prove that  $$ \sum_{k=0}^{j} \binom{2j+1}{k+j+1} \ \frac{(-1)^k}{2k+1}=2^{2j-1}\ B(j+1,1/2),$$ where $B(\cdot , \cdot)$ is the beta function . My idea was to change it to something like my previous question. Edit 1 .It follows from the absorption formula that  $$ \binom{2j+1}{k+j+1} = \frac{(2j+1)(2j) \ldots(j+2)(j+1)}{(k+j+1)(k+j) \ldots(k+2)(k+1)} \binom{j}{k}.$$  How can I go further with this binomial series? Edit 2 . This sum is going to diverge very fast as $j \to \infty,$ so I guess something like $\binom{2j}{j}$ inolves. Edit 3 . Due to $(-1)^k$, we have got lots of cancellations, which makes the series to be controlled. Edit 4 . The problem still open. Edit 5 . [Getting some progress] Consider two polynomials $$p_j(t):= \sum_{k=0}^{j} \binom{2j+1}{k+j+1}  (-t)^k \ \, \text{and} \ \ q_j(t):=4^j \ (1-t)^{j}.$$ To prove our guess, it suffices to show that  $$ \color{red}{\int_0^1 t^{-1/2} \, p_j(t) \, dt = \int_0^1 t^{-1/2} \, q_j(t) \, dt} \tag{*}$$ since  $$ \begin{align} \sum_{k=0}^{j} \binom{2j+1}{k+j+1} \ \frac{(-1)^k}{2k+1} & =  \sum_{k=0}^{j} \binom{2j+1}{k+j+1} (-1)^k \int_0^1 \frac{1}{2} t^{k-1/2} \, dt \\  & = \frac{1}{2} \int_0^1 t^{-1/2} \, p_j(t) \, dt \, , \end{align} $$ and $$ \frac{1}{2} \int_0^1 t^{-1/2} \, q_j(t) \, dt= 2^{2j-1}\ B(j+1,\frac{1}{2}).$$ I guess we can use induction since for $j=1$, we have  $$ \int_0^1 t^{-1/2} \, (3-t) \, dx = \int_0^1 t^{-1/2} \, 4(1-t) \, dt = 16/3.$$","I want to prove that  $$ \sum_{k=0}^{j} \binom{2j+1}{k+j+1} \ \frac{(-1)^k}{2k+1}=2^{2j-1}\ B(j+1,1/2),$$ where $B(\cdot , \cdot)$ is the beta function . My idea was to change it to something like my previous question. Edit 1 .It follows from the absorption formula that  $$ \binom{2j+1}{k+j+1} = \frac{(2j+1)(2j) \ldots(j+2)(j+1)}{(k+j+1)(k+j) \ldots(k+2)(k+1)} \binom{j}{k}.$$  How can I go further with this binomial series? Edit 2 . This sum is going to diverge very fast as $j \to \infty,$ so I guess something like $\binom{2j}{j}$ inolves. Edit 3 . Due to $(-1)^k$, we have got lots of cancellations, which makes the series to be controlled. Edit 4 . The problem still open. Edit 5 . [Getting some progress] Consider two polynomials $$p_j(t):= \sum_{k=0}^{j} \binom{2j+1}{k+j+1}  (-t)^k \ \, \text{and} \ \ q_j(t):=4^j \ (1-t)^{j}.$$ To prove our guess, it suffices to show that  $$ \color{red}{\int_0^1 t^{-1/2} \, p_j(t) \, dt = \int_0^1 t^{-1/2} \, q_j(t) \, dt} \tag{*}$$ since  $$ \begin{align} \sum_{k=0}^{j} \binom{2j+1}{k+j+1} \ \frac{(-1)^k}{2k+1} & =  \sum_{k=0}^{j} \binom{2j+1}{k+j+1} (-1)^k \int_0^1 \frac{1}{2} t^{k-1/2} \, dt \\  & = \frac{1}{2} \int_0^1 t^{-1/2} \, p_j(t) \, dt \, , \end{align} $$ and $$ \frac{1}{2} \int_0^1 t^{-1/2} \, q_j(t) \, dt= 2^{2j-1}\ B(j+1,\frac{1}{2}).$$ I guess we can use induction since for $j=1$, we have  $$ \int_0^1 t^{-1/2} \, (3-t) \, dx = \int_0^1 t^{-1/2} \, 4(1-t) \, dt = 16/3.$$",,"['sequences-and-series', 'binomial-coefficients', 'divergent-series', 'beta-function']"
68,Prove that $S_n\sim2^{n+1}$ where $S_n=\sum_{p=0}^n\sum_{q=0}^n\binom{n}{p}\binom{n}{q} e^{-pq}$.,Prove that  where .,S_n\sim2^{n+1} S_n=\sum_{p=0}^n\sum_{q=0}^n\binom{n}{p}\binom{n}{q} e^{-pq},"For $n\in\Bbb N$, define   $$S_n=\sum_{p=0}^n\sum_{q=0}^n\binom{n}{p}\binom{n}{q} e^{-pq}$$ I   want to prove that $$\lim_{n\to\infty}\frac{S_n}{2^{n+1}}=1$$ My attempts: For $n\in\Bbb N^*$, $$S_n=2^{n+1}-1+\sum_{p=1}^n\sum_{q=1}^n\binom{n}{p}\binom{n}{q} e^{-pq}$$ The role of $e$ is not important. In fact, we can replace $e$ with any constant $x\ge1$. I tried to use some similar methods (such as CLT) of the limit below but failed. $$\lim_{n\to\infty} e^{-n} \sum_{k=0}^{n} \frac{n^k}{k!}=\frac12$$ Summation of $q$ gives $$S_n=\sum_{p=0}^n\binom{n}{p}(1+e^{-p})^{n}$$ Some calculation results: $$\frac{S_{10}}{2^{11}}\simeq1.23\qquad\frac{S_{20}}{2^{21}}\simeq1.01\qquad\frac{S_{30}}{2^{31}}\simeq1.00035$$ The answer of the link in my comment is satisfied. However, it will also be appreciated if there are any other ideas.","For $n\in\Bbb N$, define   $$S_n=\sum_{p=0}^n\sum_{q=0}^n\binom{n}{p}\binom{n}{q} e^{-pq}$$ I   want to prove that $$\lim_{n\to\infty}\frac{S_n}{2^{n+1}}=1$$ My attempts: For $n\in\Bbb N^*$, $$S_n=2^{n+1}-1+\sum_{p=1}^n\sum_{q=1}^n\binom{n}{p}\binom{n}{q} e^{-pq}$$ The role of $e$ is not important. In fact, we can replace $e$ with any constant $x\ge1$. I tried to use some similar methods (such as CLT) of the limit below but failed. $$\lim_{n\to\infty} e^{-n} \sum_{k=0}^{n} \frac{n^k}{k!}=\frac12$$ Summation of $q$ gives $$S_n=\sum_{p=0}^n\binom{n}{p}(1+e^{-p})^{n}$$ Some calculation results: $$\frac{S_{10}}{2^{11}}\simeq1.23\qquad\frac{S_{20}}{2^{21}}\simeq1.01\qquad\frac{S_{30}}{2^{31}}\simeq1.00035$$ The answer of the link in my comment is satisfied. However, it will also be appreciated if there are any other ideas.",,"['sequences-and-series', 'analysis', 'limits', 'binomial-coefficients']"
69,"Assuming $\sum n a_n$ converges, does it follow that $\sum a_n$ converge? [duplicate]","Assuming  converges, does it follow that  converge? [duplicate]",\sum n a_n \sum a_n,"This question already has answers here : Is there a sequence such that $\sum{a_n}$ diverges but $\sum{na_n}$converges? (2 answers) Closed 6 years ago . Let us assume that the series  $$\sum n a_n$$ converges. Does it follow that the series $$\sum a_n$$ converge ? In case the series were positive, it's trivial using the comparison test. What can we say in the general case ?","This question already has answers here : Is there a sequence such that $\sum{a_n}$ diverges but $\sum{na_n}$converges? (2 answers) Closed 6 years ago . Let us assume that the series  $$\sum n a_n$$ converges. Does it follow that the series $$\sum a_n$$ converge ? In case the series were positive, it's trivial using the comparison test. What can we say in the general case ?",,"['sequences-and-series', 'convergence-divergence']"
70,Alternating harmonic series convergence $S_n = 1-\frac12 + \frac13 - \cdots + (-1)^n\frac1n$,Alternating harmonic series convergence,S_n = 1-\frac12 + \frac13 - \cdots + (-1)^n\frac1n,"Let's consider the alternating harmonic series  $S_n = 1-\frac12 + \frac13 - \cdots + (-1)^n\frac1n$. By rearranging its terms, we get  $S_n = (1-\frac12)-\frac14 + (\frac13-\frac16)-\frac18 + (\frac15-\frac1{10})-\cdots$. This equals to $S_n = \frac12-\frac14 + \frac16-\frac18 + \frac1{10}-\cdots$. By extracting $\frac12$ as common factor, we get: $S_n = \frac12(1-\frac12 + \frac13-\frac14 + \cdots)$. So in essence, $S_n = \frac12 S_n$, therefore $1=\frac12$. I have read the wikipedia article about Riemann series and roughly my understanding is that if the series converges, we can rearrange the terms and get any other number, or even to diverge. What could be an acceptable explanation of the paradox? Obviously 1 does not equal $\frac12$! In which of the above steps lies the error?","Let's consider the alternating harmonic series  $S_n = 1-\frac12 + \frac13 - \cdots + (-1)^n\frac1n$. By rearranging its terms, we get  $S_n = (1-\frac12)-\frac14 + (\frac13-\frac16)-\frac18 + (\frac15-\frac1{10})-\cdots$. This equals to $S_n = \frac12-\frac14 + \frac16-\frac18 + \frac1{10}-\cdots$. By extracting $\frac12$ as common factor, we get: $S_n = \frac12(1-\frac12 + \frac13-\frac14 + \cdots)$. So in essence, $S_n = \frac12 S_n$, therefore $1=\frac12$. I have read the wikipedia article about Riemann series and roughly my understanding is that if the series converges, we can rearrange the terms and get any other number, or even to diverge. What could be an acceptable explanation of the paradox? Obviously 1 does not equal $\frac12$! In which of the above steps lies the error?",,['sequences-and-series']
71,Infinite product of the form $2-2^{1/k}$,Infinite product of the form,2-2^{1/k},"How can I show that $$\lim_{n\to\infty} \prod_{k=2}^{n} (2-2^{1/k})=0$$ This is an exercise from a college admission exam, and the answer is given as 0.  I don't understand how infinitely many positive numbers can have a product equal to $0$.  I tried to take the logarithm of the product and use the fact that $$\lim_{x\to0} \frac{\ln(1+x)}{x}=1$$ and get rid of it, but I am left with $$\sum_{k=2}^{\infty} (1-2^{1/k})$$ Is it correct? Any other approaches would be appreciated.","How can I show that $$\lim_{n\to\infty} \prod_{k=2}^{n} (2-2^{1/k})=0$$ This is an exercise from a college admission exam, and the answer is given as 0.  I don't understand how infinitely many positive numbers can have a product equal to $0$.  I tried to take the logarithm of the product and use the fact that $$\lim_{x\to0} \frac{\ln(1+x)}{x}=1$$ and get rid of it, but I am left with $$\sum_{k=2}^{\infty} (1-2^{1/k})$$ Is it correct? Any other approaches would be appreciated.",,"['sequences-and-series', 'infinite-product']"
72,Find sum to infinite terms of the series $S=\frac{4}{5}+\frac{4.7}{5.8}+\frac{4.7.10}{5.8.11}+\cdots$,Find sum to infinite terms of the series,S=\frac{4}{5}+\frac{4.7}{5.8}+\frac{4.7.10}{5.8.11}+\cdots,Find sum to infinity terms of the series $$S=\frac{4}{5}+\frac{4.7}{5.8}+\frac{4.7.10}{5.8.11}+\cdots$$ My Try: we have $$1+S=1+\frac{4}{5}+\frac{4.7}{5.8}+\frac{4.7.10}{5.8.11}+\cdots$$ now $$(1+x)^n=1+nx+\frac{n(n-1)x^2}{2}+\cdots $$  So comparing we get $$nx=\frac{4}{5}$$ and $$\frac{n(n-1)x^2}{2}=\frac{7}{10}$$ solving for $x$ and $n$ we get $$n=\frac{-16}{19}$$ and $$x=\frac{-19}{20}$$ Hence $$1+S=(1+x)^n=20^{\frac{16}{19}}$$ $$S=20^{\frac{16}{19}}-1$$ Is this alright?,Find sum to infinity terms of the series $$S=\frac{4}{5}+\frac{4.7}{5.8}+\frac{4.7.10}{5.8.11}+\cdots$$ My Try: we have $$1+S=1+\frac{4}{5}+\frac{4.7}{5.8}+\frac{4.7.10}{5.8.11}+\cdots$$ now $$(1+x)^n=1+nx+\frac{n(n-1)x^2}{2}+\cdots $$  So comparing we get $$nx=\frac{4}{5}$$ and $$\frac{n(n-1)x^2}{2}=\frac{7}{10}$$ solving for $x$ and $n$ we get $$n=\frac{-16}{19}$$ and $$x=\frac{-19}{20}$$ Hence $$1+S=(1+x)^n=20^{\frac{16}{19}}$$ $$S=20^{\frac{16}{19}}-1$$ Is this alright?,,"['sequences-and-series', 'convergence-divergence', 'summation', 'binomial-coefficients', 'hypergeometric-function']"
73,Convergence of Sum of Reciprocal Palindromes,Convergence of Sum of Reciprocal Palindromes,,"Let $P_{b}(n)$ be the $n$th palindromic number in base $b$. I read on Wikipedia that the sum $$\sum_{n=1}^\infty \frac{1}{P_{10}(n)}$$ converges, but I have no idea how to prove it. I tried using combinatorics to count the ""density"" of the palindromes and establish an upper bound that was easy to prove was convergent, but my counting just got too complicated. How do I prove that this converges? Furthermore, how can I prove (or disprove) that it converges for any $b\ge 2, b\in \mathbb N$?","Let $P_{b}(n)$ be the $n$th palindromic number in base $b$. I read on Wikipedia that the sum $$\sum_{n=1}^\infty \frac{1}{P_{10}(n)}$$ converges, but I have no idea how to prove it. I tried using combinatorics to count the ""density"" of the palindromes and establish an upper bound that was easy to prove was convergent, but my counting just got too complicated. How do I prove that this converges? Furthermore, how can I prove (or disprove) that it converges for any $b\ge 2, b\in \mathbb N$?",,"['sequences-and-series', 'convergence-divergence', 'palindrome']"
74,Is the series convergent $x + x^{1+\frac{1}{2}}+x^{1+\frac{1}{2}+ \frac{1}{3}}+\cdots$,Is the series convergent,x + x^{1+\frac{1}{2}}+x^{1+\frac{1}{2}+ \frac{1}{3}}+\cdots,$$x + x^{1+\frac{1}{2}}+x^{1+\frac{1}{2}+ \frac{1}{3}}+\cdots$$ I know that $u_n = \lim_{n \to \infty}   x^ {\sum_{i=1}^n(1/i)}$ I used root test and ratio test but it isn't working.,I know that I used root test and ratio test but it isn't working.,x + x^{1+\frac{1}{2}}+x^{1+\frac{1}{2}+ \frac{1}{3}}+\cdots u_n = \lim_{n \to \infty}   x^ {\sum_{i=1}^n(1/i)},"['sequences-and-series', 'convergence-divergence']"
75,Find limit of sum,Find limit of sum,,I suspect that $\lim_{n \to \infty} \sum_{k = 0}^{n  - 1}\frac{k}{a^k(n - k)} = 0$ for $a > 1$. I know that this product represents the taylor coefficients of $\frac{-ax\ln(1 - x)}{(a - x)^2}$ by the Cauchy product. Unfortunately the limit as $x \to 1^{-1}$ is not defined so I can't use Abel's theorem. How can I prove this?,I suspect that $\lim_{n \to \infty} \sum_{k = 0}^{n  - 1}\frac{k}{a^k(n - k)} = 0$ for $a > 1$. I know that this product represents the taylor coefficients of $\frac{-ax\ln(1 - x)}{(a - x)^2}$ by the Cauchy product. Unfortunately the limit as $x \to 1^{-1}$ is not defined so I can't use Abel's theorem. How can I prove this?,,"['calculus', 'sequences-and-series', 'cauchy-product']"
76,On a certain sequence,On a certain sequence,,"Let $\{y_n\}$ be a sequence defined by $y_n=x_n-\ln n$ , where $\{x_n\}$ is defined by $x_1=1 ; x_{n+1}=x_n + e^{-x_n} , \forall n\in \mathbb N$ . Then is $\{y_n\} $ bounded ? Is $\{y_n\}$ convergent ? I know that $\{x_n\}$ is strictly increasing and unbounded ; but I am unable to say anything about $\{y_n\}$ . Please help  .Thanks in advance","Let $\{y_n\}$ be a sequence defined by $y_n=x_n-\ln n$ , where $\{x_n\}$ is defined by $x_1=1 ; x_{n+1}=x_n + e^{-x_n} , \forall n\in \mathbb N$ . Then is $\{y_n\} $ bounded ? Is $\{y_n\}$ convergent ? I know that $\{x_n\}$ is strictly increasing and unbounded ; but I am unable to say anything about $\{y_n\}$ . Please help  .Thanks in advance",,"['real-analysis', 'sequences-and-series']"
77,How are the Bell numbers related to this exponential series?,How are the Bell numbers related to this exponential series?,,"I recently started studying about the exponential series, and came across this infinite series $ {S}_{k}\mathrm{{=}}\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\frac{{n}^{k}}{n\mathrm{!}}} $ A few results that were given in my textbook were: $$ \begin{array}{l} {{S}_{0}\mathrm{{=}}{e}}\\ {{S}_{1}\mathrm{{=}}{e}}\\ {{S}_{2}\mathrm{{=}}{2}{e}}\\ {{S}_{3}\mathrm{{=}}{5}{e}}\\ {{S}_{4}\mathrm{{=}}{\mathrm{15}}{e}} \end{array} $$ The coefficients of $e$ piqued my interest, and so I used wolfram alpha to calculate $ {S}_{5} $, which came out to be equal to 52$e$. I looked up the sequence of coefficients of e on OEIS and it showed me a sequence of numbers known as the Bell numbers. I learned on Wikipedia that these numbers are used in Combinatorics, and give the maximum possible partitions of a set with given number of elements. Anyhow, I attempted to solve the above series for $k$=2 and 3 to see if I could find a pattern linking bell numbers to the series. Here's what I did: $$ \begin{array}{l} {\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\frac{{n}^{2}}{n\mathrm{!}}}\mathrm{{=}}\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\frac{{n}{\mathrm{(}}{n}\mathrm{{-}}{1}{\mathrm{)}}\mathrm{{+}}{n}}{n\mathrm{!}}}\mathrm{{=}}\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\mathrm{(}\frac{1}{{\mathrm{(}}{n}\mathrm{{-}}{2}{\mathrm{)!}}}}\mathrm{{+}}\frac{1}{{\mathrm{(}}{n}\mathrm{{-}}{1}{\mathrm{)!}}}{\mathrm{)}}\mathrm{{=}}{e}\mathrm{{+}}{e}\mathrm{{=}}{2}{e}}\\ {\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\frac{{n}^{3}}{n\mathrm{!}}}\mathrm{{=}}\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\frac{{n}{\mathrm{(}}{n}\mathrm{{-}}{1}{\mathrm{)}}{\mathrm{(}}{n}\mathrm{{-}}{2}{\mathrm{)}}\mathrm{{+}}{3}{n}^{2}\mathrm{{-}}{2}{n}}{n\mathrm{!}}}\mathrm{{=}}\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\mathrm{(}\frac{1}{{\mathrm{(}}{n}\mathrm{{-}}{3}{\mathrm{)!}}}}\mathrm{{+}}{3}\frac{{n}^{2}}{n\mathrm{!}}\mathrm{{-}}{2}\frac{n}{n\mathrm{!}}{\mathrm{)}}\mathrm{{=}}{e}\mathrm{{+}}{3}{\mathrm{(}}{2}{e}{\mathrm{)}}\mathrm{{-}}{2}{\mathrm{(}}{e}{\mathrm{)}}\mathrm{{=}}{5}{e}} \end{array} $$ This method could be extended for any $k$, I believe, but will become tedious to calculate for larger $k$. Needless to say, this didn't clear up any confusion for me. So could anyone please explain to me what's going on here? Any help regarding this will be much appreciated. Thanks","I recently started studying about the exponential series, and came across this infinite series $ {S}_{k}\mathrm{{=}}\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\frac{{n}^{k}}{n\mathrm{!}}} $ A few results that were given in my textbook were: $$ \begin{array}{l} {{S}_{0}\mathrm{{=}}{e}}\\ {{S}_{1}\mathrm{{=}}{e}}\\ {{S}_{2}\mathrm{{=}}{2}{e}}\\ {{S}_{3}\mathrm{{=}}{5}{e}}\\ {{S}_{4}\mathrm{{=}}{\mathrm{15}}{e}} \end{array} $$ The coefficients of $e$ piqued my interest, and so I used wolfram alpha to calculate $ {S}_{5} $, which came out to be equal to 52$e$. I looked up the sequence of coefficients of e on OEIS and it showed me a sequence of numbers known as the Bell numbers. I learned on Wikipedia that these numbers are used in Combinatorics, and give the maximum possible partitions of a set with given number of elements. Anyhow, I attempted to solve the above series for $k$=2 and 3 to see if I could find a pattern linking bell numbers to the series. Here's what I did: $$ \begin{array}{l} {\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\frac{{n}^{2}}{n\mathrm{!}}}\mathrm{{=}}\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\frac{{n}{\mathrm{(}}{n}\mathrm{{-}}{1}{\mathrm{)}}\mathrm{{+}}{n}}{n\mathrm{!}}}\mathrm{{=}}\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\mathrm{(}\frac{1}{{\mathrm{(}}{n}\mathrm{{-}}{2}{\mathrm{)!}}}}\mathrm{{+}}\frac{1}{{\mathrm{(}}{n}\mathrm{{-}}{1}{\mathrm{)!}}}{\mathrm{)}}\mathrm{{=}}{e}\mathrm{{+}}{e}\mathrm{{=}}{2}{e}}\\ {\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\frac{{n}^{3}}{n\mathrm{!}}}\mathrm{{=}}\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\frac{{n}{\mathrm{(}}{n}\mathrm{{-}}{1}{\mathrm{)}}{\mathrm{(}}{n}\mathrm{{-}}{2}{\mathrm{)}}\mathrm{{+}}{3}{n}^{2}\mathrm{{-}}{2}{n}}{n\mathrm{!}}}\mathrm{{=}}\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\mathrm{(}\frac{1}{{\mathrm{(}}{n}\mathrm{{-}}{3}{\mathrm{)!}}}}\mathrm{{+}}{3}\frac{{n}^{2}}{n\mathrm{!}}\mathrm{{-}}{2}\frac{n}{n\mathrm{!}}{\mathrm{)}}\mathrm{{=}}{e}\mathrm{{+}}{3}{\mathrm{(}}{2}{e}{\mathrm{)}}\mathrm{{-}}{2}{\mathrm{(}}{e}{\mathrm{)}}\mathrm{{=}}{5}{e}} \end{array} $$ This method could be extended for any $k$, I believe, but will become tedious to calculate for larger $k$. Needless to say, this didn't clear up any confusion for me. So could anyone please explain to me what's going on here? Any help regarding this will be much appreciated. Thanks",,"['sequences-and-series', 'combinatorics', 'summation', 'stirling-numbers', 'bell-numbers']"
78,Finding the row and column number of the number $20096$,Finding the row and column number of the number,20096,Consider the numbers arranged in the following way $$\begin{array}{ccccccc} 1 & 3 & 6 & 10 & 15 & 21 & \cdots \\ 2 & 5 & 9 & 14 & 20 & \cdots & \cdots \\ 4 & 8 & 13 & 19 & \cdots & \cdots & \cdots \\ 7 & 12 & 18 & \cdots & \cdots & \cdots & \cdots \\ 11 & 17 & \cdots & \cdots & \cdots & \cdots & \cdots \\ 16 & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots \end{array}$$The question is to find the row number and column number in which the number $20096$ occurs. I tried to find a general expression for the number in $k^{th}$ column and $n^{th}$ row.$$\frac{k(k-1)}{2}-(n-1)=20096$$and $$\frac{n(n-1)}{2}+k=20096$$But I am getting fractional value of row which is incorrect.Any ideas?Thanks.,Consider the numbers arranged in the following way $$\begin{array}{ccccccc} 1 & 3 & 6 & 10 & 15 & 21 & \cdots \\ 2 & 5 & 9 & 14 & 20 & \cdots & \cdots \\ 4 & 8 & 13 & 19 & \cdots & \cdots & \cdots \\ 7 & 12 & 18 & \cdots & \cdots & \cdots & \cdots \\ 11 & 17 & \cdots & \cdots & \cdots & \cdots & \cdots \\ 16 & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\ \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots \end{array}$$The question is to find the row number and column number in which the number $20096$ occurs. I tried to find a general expression for the number in $k^{th}$ column and $n^{th}$ row.$$\frac{k(k-1)}{2}-(n-1)=20096$$and $$\frac{n(n-1)}{2}+k=20096$$But I am getting fractional value of row which is incorrect.Any ideas?Thanks.,,['sequences-and-series']
79,Sum of all rationals between 0 and 1 squared,Sum of all rationals between 0 and 1 squared,,"Yesterday I came with a question: if rational numbers are countable, that means that all rational numbers between 0 and 1 can be listed in a sequence. Let be $Q(n)$ that sequence. It is pretty clear that $\sum_{n=1}^{\infty}Q(n) >\sum_{n=1}^{\infty}\frac{1}{n}$, it diverges. But what about $\sum_{n=1}^{\infty}Q(n)^2$? Does this serie converge? Is there even a way to define $Q(n)$ in a precise way? Many thanks in advance!!","Yesterday I came with a question: if rational numbers are countable, that means that all rational numbers between 0 and 1 can be listed in a sequence. Let be $Q(n)$ that sequence. It is pretty clear that $\sum_{n=1}^{\infty}Q(n) >\sum_{n=1}^{\infty}\frac{1}{n}$, it diverges. But what about $\sum_{n=1}^{\infty}Q(n)^2$? Does this serie converge? Is there even a way to define $Q(n)$ in a precise way? Many thanks in advance!!",,"['real-analysis', 'sequences-and-series', 'convergence-divergence', 'rational-numbers']"
80,Write $\sum\limits_{n=0}^\infty e^{-xn^3}$ in the form $\sum\limits_{n=-\infty}^\infty a_nx^n$,Write  in the form,\sum\limits_{n=0}^\infty e^{-xn^3} \sum\limits_{n=-\infty}^\infty a_nx^n,"This is a very simple question; I apologize if it has already been asked here. Define the following function (superficially similar to a theta function ): $$\varsigma(x)=\sum_{n=1}^\infty e^{-xn^3}$$ I am interested in knowing the Laurent series about $x=0$ of this series if it exists, i.e. I would like to know if there exist $\{a_n\}$ such that: $$\varsigma(x)=\sum_{n=-\infty}^\infty a_nx^n\tag{1}$$ for small enough $x>0$. I'm pretty sure that $\varsigma(x)$ diverges to infinity at $x=0$ so I assume that some of the $a_n$ for $n<0$ will be nonzero. Ideally I would love a closed form for the $a_n$ but I am especially interested for the moment in $a_1$. I have no idea how to find these terms, since this is not a Taylor series and since I do not know the complex behaviour of $\varsigma(z)$. Wolfram Alpha doesn't help me either. I am aware of the formula for Laurent series coefficients, and that for instance we will have: $$a_1=\frac{1}{2\pi i}\oint_C \frac{\varsigma(z)}{z^2}\;dz$$ where $C$ is a closed contour around $z=0$, but I am not sure how I should go about evaluating this; formally interchanging integral and sum only gives me a divergent sum : for instance making use of the fact that $e^{az}=\sum\limits_{n=0}^\infty \frac{a^nz^n}{n!}$ I formally get $a_1=-\sum\limits_{n=1}^\infty n^3$ but I don't know whether I can make this argument rigorous to get $a_1=-\zeta(-3)$. Background : This question arose from some recreational thoughts of mine on summing divergent series ; this answer used an $ne^{-\epsilon n}$ regularization rather than the usual $n^s$ to 'evaluate' $\sum\limits_{n=1}^\infty n$ and curiously obtained a constant term of $-\frac{1}{12}$ in the Laurent series in $\epsilon$; this interested me and made me wonder what an $n^3e^{-\epsilon n^3}$ regularization of $\sum\limits_{n=1}^\infty n^3$ would give. We have $\sum\limits_{n=1}^\infty n^3e^{-\epsilon n^3}=-\varsigma'(\epsilon)$ so the constant term in the Laurent series expansion of this function will be $-a_1$; thus I would conjecture that $a_1=-\frac{1}{120}$ (i.e. $-\zeta(-3)$; see here ). The above calculation supports this, but I don't know whether it can be made rigorous. Thus I have the following questions : Do there exist $a_n$ such that $(1)$ holds for small $x>0$? If so, does $a_1=-\frac{1}{120}$? Is it possible to write a closed form for the $a_n$?","This is a very simple question; I apologize if it has already been asked here. Define the following function (superficially similar to a theta function ): $$\varsigma(x)=\sum_{n=1}^\infty e^{-xn^3}$$ I am interested in knowing the Laurent series about $x=0$ of this series if it exists, i.e. I would like to know if there exist $\{a_n\}$ such that: $$\varsigma(x)=\sum_{n=-\infty}^\infty a_nx^n\tag{1}$$ for small enough $x>0$. I'm pretty sure that $\varsigma(x)$ diverges to infinity at $x=0$ so I assume that some of the $a_n$ for $n<0$ will be nonzero. Ideally I would love a closed form for the $a_n$ but I am especially interested for the moment in $a_1$. I have no idea how to find these terms, since this is not a Taylor series and since I do not know the complex behaviour of $\varsigma(z)$. Wolfram Alpha doesn't help me either. I am aware of the formula for Laurent series coefficients, and that for instance we will have: $$a_1=\frac{1}{2\pi i}\oint_C \frac{\varsigma(z)}{z^2}\;dz$$ where $C$ is a closed contour around $z=0$, but I am not sure how I should go about evaluating this; formally interchanging integral and sum only gives me a divergent sum : for instance making use of the fact that $e^{az}=\sum\limits_{n=0}^\infty \frac{a^nz^n}{n!}$ I formally get $a_1=-\sum\limits_{n=1}^\infty n^3$ but I don't know whether I can make this argument rigorous to get $a_1=-\zeta(-3)$. Background : This question arose from some recreational thoughts of mine on summing divergent series ; this answer used an $ne^{-\epsilon n}$ regularization rather than the usual $n^s$ to 'evaluate' $\sum\limits_{n=1}^\infty n$ and curiously obtained a constant term of $-\frac{1}{12}$ in the Laurent series in $\epsilon$; this interested me and made me wonder what an $n^3e^{-\epsilon n^3}$ regularization of $\sum\limits_{n=1}^\infty n^3$ would give. We have $\sum\limits_{n=1}^\infty n^3e^{-\epsilon n^3}=-\varsigma'(\epsilon)$ so the constant term in the Laurent series expansion of this function will be $-a_1$; thus I would conjecture that $a_1=-\frac{1}{120}$ (i.e. $-\zeta(-3)$; see here ). The above calculation supports this, but I don't know whether it can be made rigorous. Thus I have the following questions : Do there exist $a_n$ such that $(1)$ holds for small $x>0$? If so, does $a_1=-\frac{1}{120}$? Is it possible to write a closed form for the $a_n$?",,"['calculus', 'sequences-and-series', 'complex-analysis', 'recreational-mathematics', 'closed-form']"
81,problem on convergence of series $\sum_{n=1}^\infty\left(\frac1n-\tan^{-1} \frac1n\right)^a$,problem on convergence of series,\sum_{n=1}^\infty\left(\frac1n-\tan^{-1} \frac1n\right)^a,Finding the set of all positive values of $a$ for which the series $$ \sum_{n=1}^\infty\left(\frac1n-\tan^{-1} \frac1n\right)^a $$ converges. How will it depend on the the value of a that is its power of the term? After expanding the arc tan term I get the form of summation of $[ -1/n^3(1/3+1/n^2+......]^a $. now how does it depend on a ?,Finding the set of all positive values of $a$ for which the series $$ \sum_{n=1}^\infty\left(\frac1n-\tan^{-1} \frac1n\right)^a $$ converges. How will it depend on the the value of a that is its power of the term? After expanding the arc tan term I get the form of summation of $[ -1/n^3(1/3+1/n^2+......]^a $. now how does it depend on a ?,,"['calculus', 'sequences-and-series', 'convergence-divergence']"
82,"Find $\inf S$ and $\sup S$ for $S=\left\{\frac{12m-n-3mn+7}{5m-2n-2mn+5}: m,n\in \Bbb N\right\}$",Find  and  for,"\inf S \sup S S=\left\{\frac{12m-n-3mn+7}{5m-2n-2mn+5}: m,n\in \Bbb N\right\}","Find the infimum and supremum (if they exist) of the following set: $$S=\left\{\frac{12m-n-3mn+7}{5m-2n-2mn+5}: m,n\in \Bbb N\right\}$$ My attempt: $$\frac{12m-n-3mn+7}{5m-2n-2mn+5}=\frac{3m(4-n)-n+7}{5(m+1)-2n(m+1)}=$$ $$\frac{3m}{m+1}\cdot\frac{4-n}{5-2n}+\frac{7-n}{5-2n}\cdot\frac{1}{m+1}$$ $S:=A+B$ where $A:=\{\frac{3m}{m+1}\cdot\frac{4-n}{5-2n}: n\in\Bbb N\}$ and $B:=\{\frac{7-n}{5-2n}\cdot\frac{1}{m+1}:m\in\Bbb N\}$ $A:=X\cdot Y$ where $X:=\{\frac{3m}{m+1}:m\in\Bbb N\}$ and $Y=\{\frac{4-n}{5-2n}:n\in\Bbb N\}$ $X$ is strictly increasing(I proved it) so its first term is the infimum $$\Rightarrow \inf X=\frac{3}{2}$$ $$\lim_{m\to\infty}\frac{3m}{m+1}=3=\sup X$$ $$\sup Y=\lim_{n\to\infty}\frac{4-n}{5-2n}=\frac{1}{2}$$ I think $\inf Y=-4$ but I'm not sure how to prove it. $Y$ is increasing for $n>2.5$ or $n<1.5$ $n_1=2, n_3=-4 \Rightarrow \inf Y=-4$ After that I use the fact that $$\inf (X\cdot Y)=\min\{\sup X\cdot \sup Y, \sup X\cdot \inf Y, \inf X\cdot\sup B, \inf X\cdot \inf B\}$$ and $$\sup (X\cdot Y)=\max\{\sup X\cdot \sup Y, \sup X\cdot \inf Y, \inf X\cdot\sup B, \inf X\cdot \inf B\}$$ And then I find $\inf B$ and $\sup B$ in a similar way, and in the end I use the fact that $$\sup(A+B)=\sup A+\sup B$$ and $$\inf(A+B)=\inf A+\inf B.$$ Is there a better or faster way to solve this problem? Is what I did above correct? Thanks!","Find the infimum and supremum (if they exist) of the following set: $$S=\left\{\frac{12m-n-3mn+7}{5m-2n-2mn+5}: m,n\in \Bbb N\right\}$$ My attempt: $$\frac{12m-n-3mn+7}{5m-2n-2mn+5}=\frac{3m(4-n)-n+7}{5(m+1)-2n(m+1)}=$$ $$\frac{3m}{m+1}\cdot\frac{4-n}{5-2n}+\frac{7-n}{5-2n}\cdot\frac{1}{m+1}$$ $S:=A+B$ where $A:=\{\frac{3m}{m+1}\cdot\frac{4-n}{5-2n}: n\in\Bbb N\}$ and $B:=\{\frac{7-n}{5-2n}\cdot\frac{1}{m+1}:m\in\Bbb N\}$ $A:=X\cdot Y$ where $X:=\{\frac{3m}{m+1}:m\in\Bbb N\}$ and $Y=\{\frac{4-n}{5-2n}:n\in\Bbb N\}$ $X$ is strictly increasing(I proved it) so its first term is the infimum $$\Rightarrow \inf X=\frac{3}{2}$$ $$\lim_{m\to\infty}\frac{3m}{m+1}=3=\sup X$$ $$\sup Y=\lim_{n\to\infty}\frac{4-n}{5-2n}=\frac{1}{2}$$ I think $\inf Y=-4$ but I'm not sure how to prove it. $Y$ is increasing for $n>2.5$ or $n<1.5$ $n_1=2, n_3=-4 \Rightarrow \inf Y=-4$ After that I use the fact that $$\inf (X\cdot Y)=\min\{\sup X\cdot \sup Y, \sup X\cdot \inf Y, \inf X\cdot\sup B, \inf X\cdot \inf B\}$$ and $$\sup (X\cdot Y)=\max\{\sup X\cdot \sup Y, \sup X\cdot \inf Y, \inf X\cdot\sup B, \inf X\cdot \inf B\}$$ And then I find $\inf B$ and $\sup B$ in a similar way, and in the end I use the fact that $$\sup(A+B)=\sup A+\sup B$$ and $$\inf(A+B)=\inf A+\inf B.$$ Is there a better or faster way to solve this problem? Is what I did above correct? Thanks!",,"['calculus', 'real-analysis', 'sequences-and-series', 'supremum-and-infimum']"
83,the value of $\frac{100^2}{100!}+\sum^{100}_{k=1}|(k^2-3k+1)S_{k}|$ is,the value of  is,\frac{100^2}{100!}+\sum^{100}_{k=1}|(k^2-3k+1)S_{k}|,"Let $S_{k},$ where $k=1,2,3,\cdots \cdots ,100$ denote the sum of the infinite geometric series whose first term is $\displaystyle \frac{k-1}{k!}$ and the common ratio is $\displaystyle \frac{1}{k},$ then the value of $\displaystyle \frac{100^2}{100!}+\sum^{100}_{k=1}|(k^2-3k+1)S_{k}|$ is $\displaystyle S_{k} = \frac{a}{1-r} = \frac{(k-1)\cdot k}{k!\cdot (k-1)} = \frac{1}{(k-1)!}$ So  $\displaystyle \sum^{100}_{k=1}\bigg|(k^2-3k+1)S_{k}\bigg| = \sum^{100}_{k=1}\bigg|\frac{(k-1)^2-k}{(k-1)!}\bigg| = \sum^{100}_{k=1}\bigg|\frac{(k-1)}{(k-2)!}-\frac{k}{(k-1)!}\bigg| $ wan,t be able to go further, could some help me with this, thanks","Let $S_{k},$ where $k=1,2,3,\cdots \cdots ,100$ denote the sum of the infinite geometric series whose first term is $\displaystyle \frac{k-1}{k!}$ and the common ratio is $\displaystyle \frac{1}{k},$ then the value of $\displaystyle \frac{100^2}{100!}+\sum^{100}_{k=1}|(k^2-3k+1)S_{k}|$ is $\displaystyle S_{k} = \frac{a}{1-r} = \frac{(k-1)\cdot k}{k!\cdot (k-1)} = \frac{1}{(k-1)!}$ So  $\displaystyle \sum^{100}_{k=1}\bigg|(k^2-3k+1)S_{k}\bigg| = \sum^{100}_{k=1}\bigg|\frac{(k-1)^2-k}{(k-1)!}\bigg| = \sum^{100}_{k=1}\bigg|\frac{(k-1)}{(k-2)!}-\frac{k}{(k-1)!}\bigg| $ wan,t be able to go further, could some help me with this, thanks",,['sequences-and-series']
84,"Given $a_1=1, a_2=2, a_{n+1}=n(a_n+a_{n-1})$ find the general term [duplicate]",Given  find the general term [duplicate],"a_1=1, a_2=2, a_{n+1}=n(a_n+a_{n-1})","This question already has answers here : Finding $a_n$ if $a_0=a_1=1,a_{n+1}=n(a_n+a_{n-1})\ \ (n\ge 1).$ (2 answers) Closed 7 years ago . Given recursively defined sequence $(a_n)$: $$a_1=1$$ $$a_2=2$$ $$a_{n+1}=n(a_n+a_{n-1}), n\geq 2$$ Find the formula for the general term $a_n$. This is what I did: So the first few terms are: $a_1=1, a_2=2,a_3=6,a_4=24,a_5=120,...$  I guess the general term can be written as $n!$. Let's prove it by mathematical induction: Base case: $a_1=1!=1$ so it's true for $n=1$. Let's assume it's true for some $n$,i.e. $a_n=n!$. Then $$a_{n+1}=n(a_n+a_{n-1})=n(n!+(n-1)!)=n(n(n-1)!+(n-1)!)=n(n-1)!(n+1)=(n+1)n(n-1)!=(n+1)!$$ Using the principle of mathematical induction we've proved that the general term of this sequence is $n!$. Is this proof valid? I'm not sure whether it's allowed to put $a_{n-1}=(n-1)!$ here.","This question already has answers here : Finding $a_n$ if $a_0=a_1=1,a_{n+1}=n(a_n+a_{n-1})\ \ (n\ge 1).$ (2 answers) Closed 7 years ago . Given recursively defined sequence $(a_n)$: $$a_1=1$$ $$a_2=2$$ $$a_{n+1}=n(a_n+a_{n-1}), n\geq 2$$ Find the formula for the general term $a_n$. This is what I did: So the first few terms are: $a_1=1, a_2=2,a_3=6,a_4=24,a_5=120,...$  I guess the general term can be written as $n!$. Let's prove it by mathematical induction: Base case: $a_1=1!=1$ so it's true for $n=1$. Let's assume it's true for some $n$,i.e. $a_n=n!$. Then $$a_{n+1}=n(a_n+a_{n-1})=n(n!+(n-1)!)=n(n(n-1)!+(n-1)!)=n(n-1)!(n+1)=(n+1)n(n-1)!=(n+1)!$$ Using the principle of mathematical induction we've proved that the general term of this sequence is $n!$. Is this proof valid? I'm not sure whether it's allowed to put $a_{n-1}=(n-1)!$ here.",,"['sequences-and-series', 'proof-verification', 'induction', 'recurrence-relations']"
85,Show given property for a sequence $a_{n}$,Show given property for a sequence,a_{n},"The sequence $a_n$ is defined as  $ a_0$ is an arbitrary real number, $ a_{n+1}$ = $\lfloor a_{n}\rfloor$ ($a_{n} - \lfloor{a_{n}}\rfloor$) Show that for every $ a_0$: $$\exists m\geq0, \forall n \geq m, a_{n+2}= a_n$$ Floor function $\lfloor x \rfloor$, example, $\lfloor 3.2 \rfloor = 3$ and $\lfloor -3.2 \rfloor = -4$ Here is my attempt: [link] What I have noticed is that due to the floor function denoted as $\lfloor x \rfloor$ all of these sequences will approach zero. I am not sure if this sequences has a divergent property of periodically switching between a few particular elements, but maybe. Though why I think it approaches zero: Let $ a_0= 16.2 \Rightarrow  a_1 = 16 (16.2 - 16) = 16 \cdot 0.2 = 3.2 \Rightarrow  a_2 = 3 (3.2 - 3) = 3 \cdot 0.2 = 0.6 \Rightarrow  a_3 = 0 (0.6 \cdot 0) = 0$","The sequence $a_n$ is defined as  $ a_0$ is an arbitrary real number, $ a_{n+1}$ = $\lfloor a_{n}\rfloor$ ($a_{n} - \lfloor{a_{n}}\rfloor$) Show that for every $ a_0$: $$\exists m\geq0, \forall n \geq m, a_{n+2}= a_n$$ Floor function $\lfloor x \rfloor$, example, $\lfloor 3.2 \rfloor = 3$ and $\lfloor -3.2 \rfloor = -4$ Here is my attempt: [link] What I have noticed is that due to the floor function denoted as $\lfloor x \rfloor$ all of these sequences will approach zero. I am not sure if this sequences has a divergent property of periodically switching between a few particular elements, but maybe. Though why I think it approaches zero: Let $ a_0= 16.2 \Rightarrow  a_1 = 16 (16.2 - 16) = 16 \cdot 0.2 = 3.2 \Rightarrow  a_2 = 3 (3.2 - 3) = 3 \cdot 0.2 = 0.6 \Rightarrow  a_3 = 0 (0.6 \cdot 0) = 0$",,"['sequences-and-series', 'discrete-mathematics']"
86,Why is it so hard to find a closed form for $\sum_{n=1}^\infty \frac{1}{n^3}$?,Why is it so hard to find a closed form for ?,\sum_{n=1}^\infty \frac{1}{n^3},"The series $\sum_{n=1}^\infty \frac{1}{n^p}$ converges for $p>1$; I have known this result since I took calculus in my freshman year. It is also known that $$\sum_{n=1}^\infty \frac{1}{n^2}=\frac{\pi^2}{6} \text{ and } \sum_{n=1}^\infty \frac{1}{n^4}=\frac{\pi^4}{90}$$ I learned a few years later--while taking a history and philosophy of mathematics course of all places--that the precise value for which the series converges for $p=3$ is still unknown. Doing some brief investigation--using Wolfram|Alpha and Wikipedia--it appears that the result is defined in terms of the Riemann zeta function, i.e. $$\sum_{n=1}^\infty \frac{1}{n^3}=\zeta(3)\approx 1.2020569...$$ I have been told that a closed form has not been found. My question is why the mechanisms we have developed that enable us to find a closed form in the previous two cases fail in the third case? What it is that makes the $p=3$ case much more difficult? Is there even a closed form for the $p=3$ case, and for that matter, for all odd-numbered cases? I have attempted to ask one of my math professors this question, but I did not quite understand the explanation at the time. For added context, I am currently doing an undergraduate degree in statistics. As such, I have only taken two semesters of real analysis, and one semester of complex analysis. I also feel like this question might have been have been asked on this site before; if so, please point me in the right direction.","The series $\sum_{n=1}^\infty \frac{1}{n^p}$ converges for $p>1$; I have known this result since I took calculus in my freshman year. It is also known that $$\sum_{n=1}^\infty \frac{1}{n^2}=\frac{\pi^2}{6} \text{ and } \sum_{n=1}^\infty \frac{1}{n^4}=\frac{\pi^4}{90}$$ I learned a few years later--while taking a history and philosophy of mathematics course of all places--that the precise value for which the series converges for $p=3$ is still unknown. Doing some brief investigation--using Wolfram|Alpha and Wikipedia--it appears that the result is defined in terms of the Riemann zeta function, i.e. $$\sum_{n=1}^\infty \frac{1}{n^3}=\zeta(3)\approx 1.2020569...$$ I have been told that a closed form has not been found. My question is why the mechanisms we have developed that enable us to find a closed form in the previous two cases fail in the third case? What it is that makes the $p=3$ case much more difficult? Is there even a closed form for the $p=3$ case, and for that matter, for all odd-numbered cases? I have attempted to ask one of my math professors this question, but I did not quite understand the explanation at the time. For added context, I am currently doing an undergraduate degree in statistics. As such, I have only taken two semesters of real analysis, and one semester of complex analysis. I also feel like this question might have been have been asked on this site before; if so, please point me in the right direction.",,['calculus']
87,If series is divergent will a constant also keep it diverging?,If series is divergent will a constant also keep it diverging?,,"If $\sum_{n=0}^{\infty} b_n$ diverges, and $c \in \mathbb{R}$ then does $\sum_{n=0}^{\infty} cb_n$ diverge? My answer: NO. Let $c=0$, then the sum is $\sum_{n=0}^{\infty} 0 = 0$. True conclusion?","If $\sum_{n=0}^{\infty} b_n$ diverges, and $c \in \mathbb{R}$ then does $\sum_{n=0}^{\infty} cb_n$ diverge? My answer: NO. Let $c=0$, then the sum is $\sum_{n=0}^{\infty} 0 = 0$. True conclusion?",,"['calculus', 'sequences-and-series']"
88,Determine for which values the series $\sum_{k=1}^\infty \frac{b^{k^{2}}}{k!}$ is convergent.,Determine for which values the series  is convergent.,\sum_{k=1}^\infty \frac{b^{k^{2}}}{k!},"So I am trying to figure out for which positive real numbers b this series $$\sum_{k=1}^\infty \frac{b^{k^{2}}}{k!} $$ is convergent. Since it looks pretty hard to compare it with other series, I decided to use the ratio test. $$\lim_{k \to \infty} \left|\frac{b^{(k+1)^{2}}}{(k+1)!}\cdot{\frac{k!}{b^{k^{2}}}}\right| $$  $$=\lim_{k \to \infty} \left|\frac{b^{2k+1}}{k+1}\right| < 1 $$ But I am stuck here, this doesnt look too useful. Looking for some help.","So I am trying to figure out for which positive real numbers b this series $$\sum_{k=1}^\infty \frac{b^{k^{2}}}{k!} $$ is convergent. Since it looks pretty hard to compare it with other series, I decided to use the ratio test. $$\lim_{k \to \infty} \left|\frac{b^{(k+1)^{2}}}{(k+1)!}\cdot{\frac{k!}{b^{k^{2}}}}\right| $$  $$=\lim_{k \to \infty} \left|\frac{b^{2k+1}}{k+1}\right| < 1 $$ But I am stuck here, this doesnt look too useful. Looking for some help.",,"['calculus', 'sequences-and-series', 'analysis', 'convergence-divergence']"
89,"Given a finite sequence, can we always find a relation that generates that sequence?","Given a finite sequence, can we always find a relation that generates that sequence?",,"This is just something I've been wondering about, but I have no idea what the answer is. I suspect it's yes. Given an arbitrary finite sequence, can we always find a relation that generates that sequence? For example, given $4, 7, 10, 13$ we can find at least one relation that generates this sequence, $a_n=3n+1$. Is always it possible to find a relation for any arbitrary finite sequence? If so, how about an infinite sequence? (you would have to be given an infinite number of terms I guess.)","This is just something I've been wondering about, but I have no idea what the answer is. I suspect it's yes. Given an arbitrary finite sequence, can we always find a relation that generates that sequence? For example, given $4, 7, 10, 13$ we can find at least one relation that generates this sequence, $a_n=3n+1$. Is always it possible to find a relation for any arbitrary finite sequence? If so, how about an infinite sequence? (you would have to be given an infinite number of terms I guess.)",,"['calculus', 'sequences-and-series', 'algebra-precalculus']"
90,Show that $a(n) = (1/n)^{1+1/n}$ is monotonically decreasing,Show that  is monotonically decreasing,a(n) = (1/n)^{1+1/n},"$a(n)$ tends to $0$, as $n$ tends to $\infty$, but I am having trouble showing $a(n) > a(n+1)$.  I tried to use ln (n+1) - ln n >= 1/(n+1). so ln (n+1) >= ln n +1/(n+1) => 1/(e^(ln n + 1/(n+1)) >= 1/(e^ln (n+1)) => 1/(e^ln n)^(1+1/(n+1)) >= 1/(e^(ln n + 1/(n+1))^(1+1/(n+1)) >= 1/(e^ln (n+1))^(1+1/(n+1)). I think.  I tried some additional ideas like multiplying both sides by 1/(e^ln n)^(1/(n^2 + n))  but could not get the inequality I needed.","$a(n)$ tends to $0$, as $n$ tends to $\infty$, but I am having trouble showing $a(n) > a(n+1)$.  I tried to use ln (n+1) - ln n >= 1/(n+1). so ln (n+1) >= ln n +1/(n+1) => 1/(e^(ln n + 1/(n+1)) >= 1/(e^ln (n+1)) => 1/(e^ln n)^(1+1/(n+1)) >= 1/(e^(ln n + 1/(n+1))^(1+1/(n+1)) >= 1/(e^ln (n+1))^(1+1/(n+1)). I think.  I tried some additional ideas like multiplying both sides by 1/(e^ln n)^(1/(n^2 + n))  but could not get the inequality I needed.",,"['calculus', 'sequences-and-series']"
91,Conditional convergence of $\sum_{n=2}^{\infty} \frac{\cos(n)}{n}$,Conditional convergence of,\sum_{n=2}^{\infty} \frac{\cos(n)}{n},"Prove that the series $$\sum_{n=2}^{\infty} \frac{\cos(n)}{n}$$ is conditionally convergent? I tried to prove that it is not absolutely convergent series by trying to prove that $\sum_{n=2}^{\infty} \frac{\vert\cos(n)\vert}{n}$ is divergent, but I did not succeed. Is there another way?","Prove that the series is conditionally convergent? I tried to prove that it is not absolutely convergent series by trying to prove that is divergent, but I did not succeed. Is there another way?",\sum_{n=2}^{\infty} \frac{\cos(n)}{n} \sum_{n=2}^{\infty} \frac{\vert\cos(n)\vert}{n},"['calculus', 'sequences-and-series', 'convergence-divergence', 'conditional-convergence']"
92,Functional Equation of iterations,Functional Equation of iterations,,"Problem: Let $f : \mathbb{Q} \to \mathbb{Q}$ satisfy  $$f(f(f(x)))+2f(f(x))+f(x)=4x$$ and $$f^{2009}(x)=x$$ ($f$ iterated   $2009$ times). Prove that $f(x)=x$.    This is a contest type problem so it is supposed to have an elegant solution. My approach: I considered $f^{(k)}(x)=a_k$ then we get, $a_n+2a_{n-1}+a_{n-2}-4a_{n-3}=0$ with $f(a_{n-1})=a_n$ and we need to show that the sequence is constant, $a_i=a_0$.  The characteristic root of that recurrence are not good.  Also I observed that f must be a bijection Someone please help.","Problem: Let $f : \mathbb{Q} \to \mathbb{Q}$ satisfy  $$f(f(f(x)))+2f(f(x))+f(x)=4x$$ and $$f^{2009}(x)=x$$ ($f$ iterated   $2009$ times). Prove that $f(x)=x$.    This is a contest type problem so it is supposed to have an elegant solution. My approach: I considered $f^{(k)}(x)=a_k$ then we get, $a_n+2a_{n-1}+a_{n-2}-4a_{n-3}=0$ with $f(a_{n-1})=a_n$ and we need to show that the sequence is constant, $a_i=a_0$.  The characteristic root of that recurrence are not good.  Also I observed that f must be a bijection Someone please help.",,"['sequences-and-series', 'polynomials', 'recurrence-relations', 'contest-math', 'functional-equations']"
93,Any integral or series to prove $\frac{1}{\sqrt{3}}>\gamma$? [duplicate],Any integral or series to prove ? [duplicate],\frac{1}{\sqrt{3}}>\gamma,"This question already has answers here : Showing $\gamma < \sqrt{1/3}$ without a computer (2 answers) Closed 7 years ago . I recently noticed that these two numbers are remarkably close: $$\frac{1}{\sqrt{3}}-\gamma=0.000135\dots$$ Are there any integrals or series which can prove that $\frac{1}{\sqrt{3}}>\gamma$? Meaning that (as usual in such cases) the function under the integral has to be non-negative and the value should be proportional to the difference of these numbers. The same goes for the series (strictly non-negative terms). A good overview for the inequalities with $\pi$, like $\frac{22}{7}>\pi$, can be found in this question . A related question . But I don't consider my question a duplicate, because the linked question is more general.","This question already has answers here : Showing $\gamma < \sqrt{1/3}$ without a computer (2 answers) Closed 7 years ago . I recently noticed that these two numbers are remarkably close: $$\frac{1}{\sqrt{3}}-\gamma=0.000135\dots$$ Are there any integrals or series which can prove that $\frac{1}{\sqrt{3}}>\gamma$? Meaning that (as usual in such cases) the function under the integral has to be non-negative and the value should be proportional to the difference of these numbers. The same goes for the series (strictly non-negative terms). A good overview for the inequalities with $\pi$, like $\frac{22}{7}>\pi$, can be found in this question . A related question . But I don't consider my question a duplicate, because the linked question is more general.",,"['sequences-and-series', 'inequality', 'definite-integrals', 'euler-mascheroni-constant']"
94,Value of a trigonometric series [duplicate],Value of a trigonometric series [duplicate],,"This question already has an answer here : Find the sum : $\frac{1}{\cos0^\circ\cos1^\circ}+\frac{1}{\cos1^\circ \cos2^\circ} +\frac{1}{\cos2^\circ \cos3^\circ}+......+$ (1 answer) Closed 8 years ago . Question: If $x = \sin 1^\circ$, find the value of the expression:    $$\frac{1}{\cos0^\circ \cos1^\circ} + \frac{1}{\cos1^\circ\cos2^\circ} + ... + \frac{1}{\cos44^\circ\cos45^\circ}$$   in terms of $x$ I really can't see how I would simplify this expression in terms of $x$. Any hint would be appreciated.","This question already has an answer here : Find the sum : $\frac{1}{\cos0^\circ\cos1^\circ}+\frac{1}{\cos1^\circ \cos2^\circ} +\frac{1}{\cos2^\circ \cos3^\circ}+......+$ (1 answer) Closed 8 years ago . Question: If $x = \sin 1^\circ$, find the value of the expression:    $$\frac{1}{\cos0^\circ \cos1^\circ} + \frac{1}{\cos1^\circ\cos2^\circ} + ... + \frac{1}{\cos44^\circ\cos45^\circ}$$   in terms of $x$ I really can't see how I would simplify this expression in terms of $x$. Any hint would be appreciated.",,"['sequences-and-series', 'trigonometry']"
95,"Show that, $2\sum_{s=1}^{\infty}\frac{1-\beta(2s+1)}{2s+1}=\ln\left(\frac{\pi}{2}\right)-2+\frac{\pi}{2}$.","Show that, .",2\sum_{s=1}^{\infty}\frac{1-\beta(2s+1)}{2s+1}=\ln\left(\frac{\pi}{2}\right)-2+\frac{\pi}{2},"The Dirichlet beta function is defined as for Re(s)>0 $$\beta(s)=\sum_{n=0}^{\infty}\frac{(-1)^n}{(2n+1)^s}.$$ Show that, $$2\sum_{s=1}^{\infty}\frac{1-\beta(2s+1)}{2s+1}=\ln\left(\frac{\pi}{2}\right)-2+\frac{\pi}{2}.$$ Any hints where can we start to prove this identity? OR any authors would kindly prove it.","The Dirichlet beta function is defined as for Re(s)>0 $$\beta(s)=\sum_{n=0}^{\infty}\frac{(-1)^n}{(2n+1)^s}.$$ Show that, $$2\sum_{s=1}^{\infty}\frac{1-\beta(2s+1)}{2s+1}=\ln\left(\frac{\pi}{2}\right)-2+\frac{\pi}{2}.$$ Any hints where can we start to prove this identity? OR any authors would kindly prove it.",,[]
96,"Assuming $0 \leq a_{n+1} \leq c_n a_n + b_n$ (+ other conditions), show $a_n \to 0$","Assuming  (+ other conditions), show",0 \leq a_{n+1} \leq c_n a_n + b_n a_n \to 0,"In the paper ""A primal-dual splitting method for convex optimization ..."" (see here https://www.gipsa-lab.grenoble-inp.fr/~laurent.condat/publis/Condat-optim-JOTA-2013.pdf ), Lemma 4.6 states the following: Let $(a_n)_n, (b_n)_n, (c_n)_n$ be sequences of nonnegative real numbers such that $0 \leq c_n < 1$ for all $n$, $a_{n+1} \leq c_n a_n + b_n$ for all $n$, $\sum_n (1 - c_n) = \infty$, $b_n / (1-c_n) \to 0$. Then $a_n \to 0$. The paper cites the book ""Introduction to Optimization"" by Polyak as the source. It just quotes ""Lemma 3"" from that book, which is actually Lemma 3 of Section 2.2, page 45 (there are multiple Lemmas named ""Lemma 3""). Nevertheless, the book provides no proof . Does anyone see how this can be obtained? It seems to be a (more or less) well-known lemma, so I could also imagine that there is some other source where this is proved. As to my own input: A few lemmas before the current one are proved by considering a ""transformed"" sequence (something like $(u_k - \alpha_k /(1 - q_k))_k$ comes to mind) which then satisfy a more ""friendly"" estimate. However, I don't see which transformation would be helpful here.","In the paper ""A primal-dual splitting method for convex optimization ..."" (see here https://www.gipsa-lab.grenoble-inp.fr/~laurent.condat/publis/Condat-optim-JOTA-2013.pdf ), Lemma 4.6 states the following: Let $(a_n)_n, (b_n)_n, (c_n)_n$ be sequences of nonnegative real numbers such that $0 \leq c_n < 1$ for all $n$, $a_{n+1} \leq c_n a_n + b_n$ for all $n$, $\sum_n (1 - c_n) = \infty$, $b_n / (1-c_n) \to 0$. Then $a_n \to 0$. The paper cites the book ""Introduction to Optimization"" by Polyak as the source. It just quotes ""Lemma 3"" from that book, which is actually Lemma 3 of Section 2.2, page 45 (there are multiple Lemmas named ""Lemma 3""). Nevertheless, the book provides no proof . Does anyone see how this can be obtained? It seems to be a (more or less) well-known lemma, so I could also imagine that there is some other source where this is proved. As to my own input: A few lemmas before the current one are proved by considering a ""transformed"" sequence (something like $(u_k - \alpha_k /(1 - q_k))_k$ comes to mind) which then satisfy a more ""friendly"" estimate. However, I don't see which transformation would be helpful here.",,"['real-analysis', 'sequences-and-series', 'optimization', 'recurrence-relations']"
97,Nested logarithm series,Nested logarithm series,,"While working on problems from Spivak's Calculus, I came on one asking for the convergence/divergence of the series $$\sum_{n=1}^{\infty} \frac{1}{n^{1+\frac{1}{n}}}.$$ This is a straightforward comparison with the harmonic series to show divergence, but I ended up playing around with the idea a bit more and stumbling on the interesting fact that $$\sum_{n=2}^{\infty} \frac{1}{n^{1+\frac{1}{\log n}}}\,\,\text{diverges}\quad\text{and}\quad \sum_{n=2}^{\infty} \frac{1}{n^{1+\frac{1}{\log\log n}}}\,\,\text{converges}.$$ The first is another limit comparison with the harmonic series; the second I tried to do by looking at $$\int_2^{\infty} \frac{1}{n}\cdot \frac{1}{n^{\frac{1}{\log \log n}}}\, dn$$ and substituting $u=\log n$ to give $$\int_2^{\infty}e^{-\frac{u}{\log u}}\, du,$$ which seems more tractable. I have two questions: Can anyone show convergence of divergence of the second series by finishing up my attempt or through some other technique? More generally, for the series $$\sum_{n=1}^{\infty} \frac{1}{n^{1+\frac{1}{f(n)}}}$$ what can be said about the growth rates/other characterizations of the $f$ for which this converges? Any help would be much appreciated!","While working on problems from Spivak's Calculus, I came on one asking for the convergence/divergence of the series $$\sum_{n=1}^{\infty} \frac{1}{n^{1+\frac{1}{n}}}.$$ This is a straightforward comparison with the harmonic series to show divergence, but I ended up playing around with the idea a bit more and stumbling on the interesting fact that $$\sum_{n=2}^{\infty} \frac{1}{n^{1+\frac{1}{\log n}}}\,\,\text{diverges}\quad\text{and}\quad \sum_{n=2}^{\infty} \frac{1}{n^{1+\frac{1}{\log\log n}}}\,\,\text{converges}.$$ The first is another limit comparison with the harmonic series; the second I tried to do by looking at $$\int_2^{\infty} \frac{1}{n}\cdot \frac{1}{n^{\frac{1}{\log \log n}}}\, dn$$ and substituting $u=\log n$ to give $$\int_2^{\infty}e^{-\frac{u}{\log u}}\, du,$$ which seems more tractable. I have two questions: Can anyone show convergence of divergence of the second series by finishing up my attempt or through some other technique? More generally, for the series $$\sum_{n=1}^{\infty} \frac{1}{n^{1+\frac{1}{f(n)}}}$$ what can be said about the growth rates/other characterizations of the $f$ for which this converges? Any help would be much appreciated!",,"['sequences-and-series', 'convergence-divergence']"
98,How to determine if the following series converge or not?,How to determine if the following series converge or not?,,"$\Sigma_{n=1}^{\infty} a_n $ where: $ a_n = \frac{1}{\ln(n)^{\ln(n)}}$ $a_n = \frac{1}{n }-\ln\left( 1+\frac{1}{n}\right)$ in the first case, I really have no idea in the second case, is it correct to say that for $ \frac{1}{n }-\ln\left( 1+\frac{1}{n}\right)$ is (by taylor expansion) $\frac{1}{2n^2}+O(\frac{1}{n^3})$ and therefore, by the limit comparison test  converges?Is there any other way? Thanks in advance","$\Sigma_{n=1}^{\infty} a_n $ where: $ a_n = \frac{1}{\ln(n)^{\ln(n)}}$ $a_n = \frac{1}{n }-\ln\left( 1+\frac{1}{n}\right)$ in the first case, I really have no idea in the second case, is it correct to say that for $ \frac{1}{n }-\ln\left( 1+\frac{1}{n}\right)$ is (by taylor expansion) $\frac{1}{2n^2}+O(\frac{1}{n^3})$ and therefore, by the limit comparison test  converges?Is there any other way? Thanks in advance",,['sequences-and-series']
99,limit of $|n^t\sin n|$,limit of,|n^t\sin n|,"It is known that $\{\sin n : n\in\mathbb{N}\}$ is dense in $[-1,1]$, hence $\lim_{n\to\infty}\sin n$ doesn't exist and also $\lim_{n\to\infty} n^t\sin n$ doesn't exist for all $t>0$ (the reason is that the density implies that inequalities $\sin n>\frac{1}{2}$ and $\sin n<-\frac{1}{2}$ are satisfied infinitely many times, so there are subsequences tending to $+\infty$ and $-\infty$). What about $\lim_{n\to\infty} |n^t\sin n|$ ? The above argument shows that the limit - if exists - is infinite I dont't think it does converge, but I don't know how to prove it.","It is known that $\{\sin n : n\in\mathbb{N}\}$ is dense in $[-1,1]$, hence $\lim_{n\to\infty}\sin n$ doesn't exist and also $\lim_{n\to\infty} n^t\sin n$ doesn't exist for all $t>0$ (the reason is that the density implies that inequalities $\sin n>\frac{1}{2}$ and $\sin n<-\frac{1}{2}$ are satisfied infinitely many times, so there are subsequences tending to $+\infty$ and $-\infty$). What about $\lim_{n\to\infty} |n^t\sin n|$ ? The above argument shows that the limit - if exists - is infinite I dont't think it does converge, but I don't know how to prove it.",,"['sequences-and-series', 'limits']"
