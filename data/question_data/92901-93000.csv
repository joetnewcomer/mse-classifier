,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,why does $\frac{1}{z\cdot \sin{z}} $ only have pole when clearly its undefined at $n\pi$,why does  only have pole when clearly its undefined at,\frac{1}{z\cdot \sin{z}}  n\pi,"I am having trouble with a specific problem actually. I have a function $$f(z) = \frac{1}{z\cdot \sin{z}}$$ Now I want to find the residues of this. The Laurent series expanded about $0$ shows that $0$ is a pole of order $2$. The expansion looks something like this $$\frac{1}{z^2}+\frac{1}{6} + \frac{7z^2}{360} +  \cdots $$ so since the first coefficient of $z$ is just zero, the residue of this function is $0$. BUT I want to know why zero is the ONLY pole. Clearly $2\pi$ is a singularity point. Then when you expand about $2\pi$ you get the following expansion $$\frac{1}{2\pi (z - 2\pi)} - \frac{1}{4\pi^2} + \frac{(3+2\pi^2)(z-2\pi)}{24\pi^3} + \cdots $$ Again, it looks to me that the first negative power of $z$ has the coefficient $\frac{1}{2\pi}$. So why is it that when I type in ""poles of function 1/(z*sin(z))"" wolfram only identifies 0 as the pole. If I type in ""poles of function 1/(sin(z))"" then it identifies the poles as $n\pi$. Furthermore if you type in ""residues of 1/(z*sin(z))"" it only identifies 0 as a residue when we just saw above that $\frac{1}{2\pi}$ is also a residue. Whats even more weird is that if you type in ""residues of 1/(z*sin(z)) at 2pi"" it does give the right residue. Weird.","I am having trouble with a specific problem actually. I have a function $$f(z) = \frac{1}{z\cdot \sin{z}}$$ Now I want to find the residues of this. The Laurent series expanded about $0$ shows that $0$ is a pole of order $2$. The expansion looks something like this $$\frac{1}{z^2}+\frac{1}{6} + \frac{7z^2}{360} +  \cdots $$ so since the first coefficient of $z$ is just zero, the residue of this function is $0$. BUT I want to know why zero is the ONLY pole. Clearly $2\pi$ is a singularity point. Then when you expand about $2\pi$ you get the following expansion $$\frac{1}{2\pi (z - 2\pi)} - \frac{1}{4\pi^2} + \frac{(3+2\pi^2)(z-2\pi)}{24\pi^3} + \cdots $$ Again, it looks to me that the first negative power of $z$ has the coefficient $\frac{1}{2\pi}$. So why is it that when I type in ""poles of function 1/(z*sin(z))"" wolfram only identifies 0 as the pole. If I type in ""poles of function 1/(sin(z))"" then it identifies the poles as $n\pi$. Furthermore if you type in ""residues of 1/(z*sin(z))"" it only identifies 0 as a residue when we just saw above that $\frac{1}{2\pi}$ is also a residue. Whats even more weird is that if you type in ""residues of 1/(z*sin(z)) at 2pi"" it does give the right residue. Weird.",,['complex-analysis']
1,Examples of non-Riemann surfaces?,Examples of non-Riemann surfaces?,,"While studying Complex Analysis, I have come across Riemann Surfaces: http://mathworld.wolfram.com/RiemannSurface.html Can anyone please provide some examples of non-Riemannable surfaces? Thanks a lot!","While studying Complex Analysis, I have come across Riemann Surfaces: http://mathworld.wolfram.com/RiemannSurface.html Can anyone please provide some examples of non-Riemannable surfaces? Thanks a lot!",,"['complex-analysis', 'riemann-surfaces']"
2,"How to prove that $\cos^2(z)+\sin^2(z)=1$, where $z$ is a complex variable (if it is true)?","How to prove that , where  is a complex variable (if it is true)?",\cos^2(z)+\sin^2(z)=1 z,"Can someone show me: If $x$ is a real number, then $\cos^2(x)+\sin^2(x)= 1$. Is it true that $\cos^2(z)+\sin^2(z)=1$, where $z$ is a complex variable? Note :look [this  ] in wolfram alpha showed that's true !!!! Thank you for your help","Can someone show me: If $x$ is a real number, then $\cos^2(x)+\sin^2(x)= 1$. Is it true that $\cos^2(z)+\sin^2(z)=1$, where $z$ is a complex variable? Note :look [this  ] in wolfram alpha showed that's true !!!! Thank you for your help",,"['complex-analysis', 'trigonometry', 'complex-numbers']"
3,A Möbius transformation maps circles and lines to circles and lines. What exactly does that mean?,A Möbius transformation maps circles and lines to circles and lines. What exactly does that mean?,,"The title pretty much says it all. I am also looking for a concrete example if possible. I have looked at the proof, but I'm not exactly sure what it means because I am kind of confused on what the theorem actually says. Does it mean that if g(z) is a circle and f(z) is a Möbius transformation then f(g(z)) is a circle as well?","The title pretty much says it all. I am also looking for a concrete example if possible. I have looked at the proof, but I'm not exactly sure what it means because I am kind of confused on what the theorem actually says. Does it mean that if g(z) is a circle and f(z) is a Möbius transformation then f(g(z)) is a circle as well?",,"['complex-analysis', 'analysis', 'transformation']"
4,"If $f$ is holomorphic and $\,f'' = f$, then $f(z) = A \cosh z + B \sinh z$","If  is holomorphic and , then","f \,f'' = f f(z) = A \cosh z + B \sinh z","Suppose $f$ is holomorphic in a disk centered at the origin and $f$ satisfies the differential equation $$f'' = f.$$ Show that $f$ is of the form $$f(z)=A \sinh z + B \cosh z,$$ for suitable constants $A,B\in \mathbb C$. Of course if $f$ were a function of one real variable, usual techniques to solve linear homogeneous differential equations ( characteristic equations and so on) would quickly solve the problem. But using the same train of thought here, $f$ is a function of two real variables ($z = x + iy$), and so the same techniques cannot be applied directly. This is really a complex analysis problem.","Suppose $f$ is holomorphic in a disk centered at the origin and $f$ satisfies the differential equation $$f'' = f.$$ Show that $f$ is of the form $$f(z)=A \sinh z + B \cosh z,$$ for suitable constants $A,B\in \mathbb C$. Of course if $f$ were a function of one real variable, usual techniques to solve linear homogeneous differential equations ( characteristic equations and so on) would quickly solve the problem. But using the same train of thought here, $f$ is a function of two real variables ($z = x + iy$), and so the same techniques cannot be applied directly. This is really a complex analysis problem.",,"['complex-analysis', 'analysis', 'ordinary-differential-equations', 'analyticity', 'hyperbolic-functions']"
5,Symbolic definition for $i$?,Symbolic definition for ?,i,"Please help! I am trying to find a definition for $i$ that doesn't work for $-i$ . let $j$ be either $i$ or $-i$ . saying $j^2=-1$ doesn't help since $(i)^2=-1$ and $(-i)^2 = -1$ saying $j=\sqrt{-1}$ doesn't halp since $(-1)^{\frac{1}{2}}$ is multivalued $i$ and $-i$ saying $j=e^{i\pi/2}$ doesnt help since $e^{i\pi/2}=i$ but $e^{(-i)\pi/2}=-i$ too (yeah I know I said j= $e^{i\pi/2}$ and not $j=e^{j\pi/2}$ I did that to hopefully make it more intuitive) saying $j=ln(i)/(\pi/2)$ doesn't work since $i=ln(i)/(\pi/2)$ and $-i=ln(-i)/(pi/2)$ (check with a phase plotter, ln is multivalued but includes i and -i in their respective functions shown above http://davidbau.com/conformal/#log(z)%2F(pi%2F2)-z ) saying $Im(j) > 0$ doesn't work because $Im(z)=Re(z/i)$ and $Re(i/i)>0$ but $Re((-i)/(-i))>0$ Is this parity some sort of law? And yet $i\neq-i$ since $i=(-1)\cdot(-i)$ . Unless... Post Scriptum: Irionically, it is very easy to symbolically represent $1$ vs $-1$ even though $(1)^2=1$ and $(-1)^2=1$ , we can just say $x$ such that $x=x^2$ EDIT: can quaternions help? Is $i$ a set of 2 numbers? Are they always equal?","Please help! I am trying to find a definition for that doesn't work for . let be either or . saying doesn't help since and saying doesn't halp since is multivalued and saying doesnt help since but too (yeah I know I said j= and not I did that to hopefully make it more intuitive) saying doesn't work since and (check with a phase plotter, ln is multivalued but includes i and -i in their respective functions shown above http://davidbau.com/conformal/#log(z)%2F(pi%2F2)-z ) saying doesn't work because and but Is this parity some sort of law? And yet since . Unless... Post Scriptum: Irionically, it is very easy to symbolically represent vs even though and , we can just say such that EDIT: can quaternions help? Is a set of 2 numbers? Are they always equal?",i -i j i -i j^2=-1 (i)^2=-1 (-i)^2 = -1 j=\sqrt{-1} (-1)^{\frac{1}{2}} i -i j=e^{i\pi/2} e^{i\pi/2}=i e^{(-i)\pi/2}=-i e^{i\pi/2} j=e^{j\pi/2} j=ln(i)/(\pi/2) i=ln(i)/(\pi/2) -i=ln(-i)/(pi/2) Im(j) > 0 Im(z)=Re(z/i) Re(i/i)>0 Re((-i)/(-i))>0 i\neq-i i=(-1)\cdot(-i) 1 -1 (1)^2=1 (-1)^2=1 x x=x^2 i,"['complex-analysis', 'systems-of-equations', 'quaternions', 'parity']"
6,Can a holomorphic function of several variables have just one zero?,Can a holomorphic function of several variables have just one zero?,,Of course “several” in the title means $n$ strictly greater than 1 and the function is defined on some open subset of $\mathbb{C}^n$ . I tried to use the Weierstrass preparation theorem because it’s the only result on analysis of several variables I know but I couldn’t find a contradiction (I believe the answer is “no”).,Of course “several” in the title means strictly greater than 1 and the function is defined on some open subset of . I tried to use the Weierstrass preparation theorem because it’s the only result on analysis of several variables I know but I couldn’t find a contradiction (I believe the answer is “no”).,n \mathbb{C}^n,['complex-analysis']
7,Is there a trick to establish $z = \tan \left[ \frac{1}{i} \log \left( \sqrt{ \frac{1+iz}{1-iz} } \right) \right]$?,Is there a trick to establish ?,z = \tan \left[ \frac{1}{i} \log \left( \sqrt{ \frac{1+iz}{1-iz} } \right) \right],"Im trying to show that $$ z = \tan \left[ \frac{1}{i} \log \left( \sqrt{ \frac{1+iz}{1-iz} } \right) \right] $$ My first thought is to use the fact that $\sin x = \frac{ e^{ix} - e^{-ix} }{2i } $ and $\cos x = \frac{ e^{ix} + e^{-ix} }{2} $ to write $$ \tan x = \frac{ e^{ix } - e^{-ix} }{i( e^{ix} + e^{-ix} ) } $$ But using this, it looks like it will some very nasty calculations. Is there a trick to do this?","Im trying to show that $$ z = \tan \left[ \frac{1}{i} \log \left( \sqrt{ \frac{1+iz}{1-iz} } \right) \right] $$ My first thought is to use the fact that $\sin x = \frac{ e^{ix} - e^{-ix} }{2i } $ and $\cos x = \frac{ e^{ix} + e^{-ix} }{2} $ to write $$ \tan x = \frac{ e^{ix } - e^{-ix} }{i( e^{ix} + e^{-ix} ) } $$ But using this, it looks like it will some very nasty calculations. Is there a trick to do this?",,"['complex-analysis', 'algebra-precalculus']"
8,"If $f$ is an entire function that goes to infinity, $f$ is a polynomial","If  is an entire function that goes to infinity,  is a polynomial",f f,"I am asked to show that if $f$ is entire with the property that $\lim_{z\to\infty} f(z)=\infty$ , then $f$ must be a polynomial. However, I feel as if I am missing something. $e^z$ is entire (holomorphic at all finite $z$ ), and clearly $\lim_{z\to\infty} f(z)=\infty$ holds. However, $e^z$ is not a polynomial. This seems to be a disproof via counterexample. Is there something wrong with my reasoning, or with the problem?","I am asked to show that if is entire with the property that , then must be a polynomial. However, I feel as if I am missing something. is entire (holomorphic at all finite ), and clearly holds. However, is not a polynomial. This seems to be a disproof via counterexample. Is there something wrong with my reasoning, or with the problem?",f \lim_{z\to\infty} f(z)=\infty f e^z z \lim_{z\to\infty} f(z)=\infty e^z,"['complex-analysis', 'polynomials', 'entire-functions']"
9,Residues of Gamma Function at Poles,Residues of Gamma Function at Poles,,"I am struggling to understand the result that the analytic continuation of the Gamma function, $\Gamma(z)$ has poles at $C \setminus \{0,-1,-2,.....\}$ and residues of $(-1)^k/k!$ at pole $k$ . How may this be extended through the functional relation, to give the residuals of $\Gamma(z+1)$ or $z \Gamma(z)$ ?","I am struggling to understand the result that the analytic continuation of the Gamma function, has poles at and residues of at pole . How may this be extended through the functional relation, to give the residuals of or ?","\Gamma(z) C \setminus \{0,-1,-2,.....\} (-1)^k/k! k \Gamma(z+1) z \Gamma(z)",['complex-analysis']
10,Does Cauchy's theorem's hold if we only assume boundedness?,Does Cauchy's theorem's hold if we only assume boundedness?,,"Let $f$ be a function $\mathbb  C \to \mathbb C$ . I am not assuming $f$ is analytic on $\mathbb C$ , so Cauchy-Goursat does not apply. Suppose $\gamma$ is a simple closed contour, and suppose that the region $D = {\rm int}(\gamma) \cup \gamma$ can be approximated arbitrarily by little squares of arbitrarily small size. I would like to know whether $\oint_\gamma f = 0$ , under the assumption that $f$ is continuous and bounded on $D$ . I believe the answer is yes. Since the integral around $\gamma$ is equivalent to adding up the integrals from all the small squares, it is sufficient to show that the integral around the small squares approaches zero, which trivially follows from the Cauchy ML-inequality if $f$ is bounded on $D$ . Is this correct? So there is no need to assume analyticity if a continuous function is bounded?","Let be a function . I am not assuming is analytic on , so Cauchy-Goursat does not apply. Suppose is a simple closed contour, and suppose that the region can be approximated arbitrarily by little squares of arbitrarily small size. I would like to know whether , under the assumption that is continuous and bounded on . I believe the answer is yes. Since the integral around is equivalent to adding up the integrals from all the small squares, it is sufficient to show that the integral around the small squares approaches zero, which trivially follows from the Cauchy ML-inequality if is bounded on . Is this correct? So there is no need to assume analyticity if a continuous function is bounded?",f \mathbb  C \to \mathbb C f \mathbb C \gamma D = {\rm int}(\gamma) \cup \gamma \oint_\gamma f = 0 f D \gamma f D,['complex-analysis']
11,"A question in Complex Analysis $\int_0^{2\pi}\log(1-2r\cos x +r^2)\,dx$ [duplicate]",A question in Complex Analysis  [duplicate],"\int_0^{2\pi}\log(1-2r\cos x +r^2)\,dx","This question already has answers here : Computing $\int_{0}^{\pi}\ln\left(1-2a\cos x+a^2\right) \, dx$ (7 answers) Closed 3 years ago . My problem is to integrate this expression:  $$\int_0^{2\pi}\log(1-2r\cos x +r^2)dx.$$ where $r$ is any constant in $[0,1]$. I know the answer is zero. Can you explain you idea to me or just prove that? Maybe you will use the ""Cauchy integral theorem "".","This question already has answers here : Computing $\int_{0}^{\pi}\ln\left(1-2a\cos x+a^2\right) \, dx$ (7 answers) Closed 3 years ago . My problem is to integrate this expression:  $$\int_0^{2\pi}\log(1-2r\cos x +r^2)dx.$$ where $r$ is any constant in $[0,1]$. I know the answer is zero. Can you explain you idea to me or just prove that? Maybe you will use the ""Cauchy integral theorem "".",,"['complex-analysis', 'definite-integrals', 'harmonic-functions']"
12,Why the number of points where $f$ ramifies is finite?,Why the number of points where  ramifies is finite?,f,"I know roughly that there is a theorem in complex analysis saying that if $f$ has degree $e_x>1$ at point $x$, which is $f(z)=(x-z)^{e_x}g(z)$, then $f^{-1}(y)$ has $e_x$ different preimages in a neighborhood of $y$. In a complex Riemann surface, we have the same result considering $f$ in the local coordinates. We call that $f$ ramifies at point $x$ if $e_x>1$. I was told that the number of points where $e_x>1$ is finite. Can anyone tell me why? Is this result valid only in compact Riemann surface or generally? update: I realized that $f$ has digree $e_x$ at $x$ sould be $f(z)-f(x)=(z-x)^{e_x}g(z)$ rather than what I originally posted. Sorry for trouble..","I know roughly that there is a theorem in complex analysis saying that if $f$ has degree $e_x>1$ at point $x$, which is $f(z)=(x-z)^{e_x}g(z)$, then $f^{-1}(y)$ has $e_x$ different preimages in a neighborhood of $y$. In a complex Riemann surface, we have the same result considering $f$ in the local coordinates. We call that $f$ ramifies at point $x$ if $e_x>1$. I was told that the number of points where $e_x>1$ is finite. Can anyone tell me why? Is this result valid only in compact Riemann surface or generally? update: I realized that $f$ has digree $e_x$ at $x$ sould be $f(z)-f(x)=(z-x)^{e_x}g(z)$ rather than what I originally posted. Sorry for trouble..",,['complex-analysis']
13,Complex conjugate of $z$ without knowing $z=x+i y$,Complex conjugate of  without knowing,z z=x+i y,"Is it possible to determine (and if so, how) the complex conjugate $\bar{z}$ of $z$, if you don't already know that $z = x + i y$? I think you can use $\log(z)$ to get the angle, and therefore the ratio of $y$ and $x$. But how do you get $|z|$, the radius? How then to get $r$ (so that $x = {\rm Re}(z) = r \cos(\log(z))$ and $y = {\rm Im}(z) = r \sin(\log(z))$)? (this is related to How to express in closed form? , namely you can compute Re and Im using the conjugate, but then how do you reduce the conjugate itself fully to elementary functions (if at all))","Is it possible to determine (and if so, how) the complex conjugate $\bar{z}$ of $z$, if you don't already know that $z = x + i y$? I think you can use $\log(z)$ to get the angle, and therefore the ratio of $y$ and $x$. But how do you get $|z|$, the radius? How then to get $r$ (so that $x = {\rm Re}(z) = r \cos(\log(z))$ and $y = {\rm Im}(z) = r \sin(\log(z))$)? (this is related to How to express in closed form? , namely you can compute Re and Im using the conjugate, but then how do you reduce the conjugate itself fully to elementary functions (if at all))",,"['complex-analysis', 'complex-numbers']"
14,"If $|z|=1$, $z\neq-1$, show that $z$ may be expressed in the form $ z=\frac{1+it}{1-it}$ where $t\in \mathbb{R}$.","If , , show that  may be expressed in the form  where .",|z|=1 z\neq-1 z  z=\frac{1+it}{1-it} t\in \mathbb{R},"If $|z|=1$, $z\neq-1$, show that $z$ may be expressed in the form $$ z=\frac{1+it}{1-it},$$ where $t\in \mathbb{R}$. I don't know, how to begin. I started with the given conditions. Given that $|z|=1 \text{ and } z\neq-1\implies z=e^{it}, t\in[0,2\pi]/\{\pi\}.$","If $|z|=1$, $z\neq-1$, show that $z$ may be expressed in the form $$ z=\frac{1+it}{1-it},$$ where $t\in \mathbb{R}$. I don't know, how to begin. I started with the given conditions. Given that $|z|=1 \text{ and } z\neq-1\implies z=e^{it}, t\in[0,2\pi]/\{\pi\}.$",,['complex-analysis']
15,Computing the residues of $\dfrac{1}{\sin^2 z}$.,Computing the residues of .,\dfrac{1}{\sin^2 z},"I'm having a hard time correctly computing the residues of $\dfrac{1}{\sin^2 z}$. I  know the poles occur at $k\pi$, with order $2$. By a Taylor expansion I can rewrite $\sin z=\cos k\pi(z-k\pi)+f_2(z)(z-k\pi)^2$, and so  $$ \sin^2 z=(z-k\pi)^2(\cos k\pi+f_2(z)(z-k\pi))^2. $$ I want to calculate the residue with Cauchy's Integral Theorem, so  $$ \text{Res}(f,k\pi)=\frac{1}{2\pi i}\int_{|z-k\pi|=1}\frac{dz}{(z-k\pi)^2[\cos k\pi +f_2(z)(z-k\pi)]^2}. $$ This should equal the derivative of $(\cos k\pi+f_2(z)(z-k\pi))^{-2}$ evaluated at $k  \pi$. The derivative comes out to be $$ -2(\cos k\pi+f_2(z)(z-k\pi))^{-3}(f'_2(z)(z-k\pi)+f_2(z)) $$  and evaluates to $\dfrac{-2f_2(k\pi)}{(\cos k\pi)^3}$. Apparently the residue should  just be $0$, but I don't see how to conclude this. What am I missing to know $f_2(k\pi)=0$?","I'm having a hard time correctly computing the residues of $\dfrac{1}{\sin^2 z}$. I  know the poles occur at $k\pi$, with order $2$. By a Taylor expansion I can rewrite $\sin z=\cos k\pi(z-k\pi)+f_2(z)(z-k\pi)^2$, and so  $$ \sin^2 z=(z-k\pi)^2(\cos k\pi+f_2(z)(z-k\pi))^2. $$ I want to calculate the residue with Cauchy's Integral Theorem, so  $$ \text{Res}(f,k\pi)=\frac{1}{2\pi i}\int_{|z-k\pi|=1}\frac{dz}{(z-k\pi)^2[\cos k\pi +f_2(z)(z-k\pi)]^2}. $$ This should equal the derivative of $(\cos k\pi+f_2(z)(z-k\pi))^{-2}$ evaluated at $k  \pi$. The derivative comes out to be $$ -2(\cos k\pi+f_2(z)(z-k\pi))^{-3}(f'_2(z)(z-k\pi)+f_2(z)) $$  and evaluates to $\dfrac{-2f_2(k\pi)}{(\cos k\pi)^3}$. Apparently the residue should  just be $0$, but I don't see how to conclude this. What am I missing to know $f_2(k\pi)=0$?",,"['complex-analysis', 'residue-calculus']"
16,Complex cosine and sine,Complex cosine and sine,,"I would like to know what the mapping properties of the complex sine and cosine are. To start with one can say that $\sin(z)$ and $\cos(z)$ are conformal where their derivatives are nonzero, which means $\sin(z)$ preserves angles on $\mathbb{C}$ without $\frac{\pi}{2}+k\pi$ and $\cos(z)$ preserves angles on $\mathbb{C}$ without $\pi k$ for $\cos(z)$, with $k \in \mathbb{Z}$. What else can we say about these mappings? Thx.","I would like to know what the mapping properties of the complex sine and cosine are. To start with one can say that $\sin(z)$ and $\cos(z)$ are conformal where their derivatives are nonzero, which means $\sin(z)$ preserves angles on $\mathbb{C}$ without $\frac{\pi}{2}+k\pi$ and $\cos(z)$ preserves angles on $\mathbb{C}$ without $\pi k$ for $\cos(z)$, with $k \in \mathbb{Z}$. What else can we say about these mappings? Thx.",,['complex-analysis']
17,Applications of Complex Numbers,Applications of Complex Numbers,,"For my Complex Analysis course, we are to look up applications of Complex Numbers in the real world. The semester has just started and I am still new to the complex field. I want to get a head start on my research for the course. Anything I have seen on the complex field has only been in passing from my other course like ODE, Linear Algebra, and Abstract Algebra. I was wondering if someone can lead me into the right direction about what applications of complex numbers I can look into for my research topic. Recommended books I can refer to would also help. Thank you for your time and thanks in advanced for your feedback.","For my Complex Analysis course, we are to look up applications of Complex Numbers in the real world. The semester has just started and I am still new to the complex field. I want to get a head start on my research for the course. Anything I have seen on the complex field has only been in passing from my other course like ODE, Linear Algebra, and Abstract Algebra. I was wondering if someone can lead me into the right direction about what applications of complex numbers I can look into for my research topic. Recommended books I can refer to would also help. Thank you for your time and thanks in advanced for your feedback.",,"['complex-analysis', 'complex-numbers', 'soft-question', 'applications', 'advice']"
18,How to find a Laurent Series for this function,How to find a Laurent Series for this function,,How do I give a Laurent Series on various ranges of $|z|$ ? I need to find the Laurent series expansion for $$f(z)=\frac{1}{z(z-1)(z-2)}$$ for the following ranges of $|z|$ : $0<|z|<1$ $1<|z|<2$ $2<|z|$ I've calculated the partial fractions expansion of $f(z)$ to be $$f(z)=\frac{1}{2z}+\frac{1}{z-1}+\frac{1}{2(z-2)}$$,How do I give a Laurent Series on various ranges of ? I need to find the Laurent series expansion for for the following ranges of : I've calculated the partial fractions expansion of to be,|z| f(z)=\frac{1}{z(z-1)(z-2)} |z| 0<|z|<1 1<|z|<2 2<|z| f(z) f(z)=\frac{1}{2z}+\frac{1}{z-1}+\frac{1}{2(z-2)},"['complex-analysis', 'partial-fractions', 'laurent-series']"
19,Computing $\lim_{s \to 1} \Gamma \left(\frac{1-s}{2}\right) (s-1)$,Computing,\lim_{s \to 1} \Gamma \left(\frac{1-s}{2}\right) (s-1),"I want to evaluate the following limit: $$\lim_{s \to 1}\; \Gamma \left( \frac{1-s}{2} \right) (s-1).$$ I know that the gamma function has simple poles at $-n$ for $n \in \mathbb{N}_0$ with residue $\frac{(-1)^n}{n!}$. Also, I know that if a function $f$ has a simple pole at $a$, then $\operatorname{Res}_a f= \lim_{z \to a} (z-a) f(z)$. If $\Gamma(z)$ has a simple pole at $z=0$, then $\Gamma (\frac{1-s}{2})$ has a pole at $s=1$. If it was a simple pole, the limit would be $-1$, however, wolframalpha tells me the limit must be $-2$ and in the context I am using this limit, $-2$ must be the correct result. Where did I make a mistake? Thanks for any help in advance.","I want to evaluate the following limit: $$\lim_{s \to 1}\; \Gamma \left( \frac{1-s}{2} \right) (s-1).$$ I know that the gamma function has simple poles at $-n$ for $n \in \mathbb{N}_0$ with residue $\frac{(-1)^n}{n!}$. Also, I know that if a function $f$ has a simple pole at $a$, then $\operatorname{Res}_a f= \lim_{z \to a} (z-a) f(z)$. If $\Gamma(z)$ has a simple pole at $z=0$, then $\Gamma (\frac{1-s}{2})$ has a pole at $s=1$. If it was a simple pole, the limit would be $-1$, however, wolframalpha tells me the limit must be $-2$ and in the context I am using this limit, $-2$ must be the correct result. Where did I make a mistake? Thanks for any help in advance.",,"['complex-analysis', 'limits', 'gamma-function']"
20,Cauchy's Residue Theorem on a Singularity Outside a Contour,Cauchy's Residue Theorem on a Singularity Outside a Contour,,"I recently ran into the following exercise: Evaluate   $$\oint_\Gamma\frac{\cos z}{(z-\pi)^2}dz,$$where $\Gamma$ is a complete circuit of the circle $|z|=1$. Clearly, the singularity lies outside the contour: However, recall Cauchy's Residue Theorem : If $\Gamma$ is a simple closed positively oriented contour and $f$ is analytic inside and on $\Gamma$ except at the points $z_1$, $z_2$, ..., $z_n$, then   $$\int_\Gamma f(z)dz=2\pi i\sum_{j=1}^{n}\text{Res}(z_j),$$   where   $$\text{Res}(f;z_0)=\lim_{z\to z_0}\frac{1}{(m-1)!}\frac{d^{m-1}}{dz^{m-1}}[(z-z_0)^mf(z)].$$ If I use this to evaluate the integral, I will have that $$\text{Res}(f;\pi)=\lim_{z\to\pi}\frac{d}{dz}[\cos z]=0,$$and hence the value of the integral will evaluate to $0$, which is the correct answer. Is this purely coincidental? Because, as I understand it, for Cauchy's theorem to hold, the singularities must lie within the contour (or perhaps not?). Thanks in advance!","I recently ran into the following exercise: Evaluate   $$\oint_\Gamma\frac{\cos z}{(z-\pi)^2}dz,$$where $\Gamma$ is a complete circuit of the circle $|z|=1$. Clearly, the singularity lies outside the contour: However, recall Cauchy's Residue Theorem : If $\Gamma$ is a simple closed positively oriented contour and $f$ is analytic inside and on $\Gamma$ except at the points $z_1$, $z_2$, ..., $z_n$, then   $$\int_\Gamma f(z)dz=2\pi i\sum_{j=1}^{n}\text{Res}(z_j),$$   where   $$\text{Res}(f;z_0)=\lim_{z\to z_0}\frac{1}{(m-1)!}\frac{d^{m-1}}{dz^{m-1}}[(z-z_0)^mf(z)].$$ If I use this to evaluate the integral, I will have that $$\text{Res}(f;\pi)=\lim_{z\to\pi}\frac{d}{dz}[\cos z]=0,$$and hence the value of the integral will evaluate to $0$, which is the correct answer. Is this purely coincidental? Because, as I understand it, for Cauchy's theorem to hold, the singularities must lie within the contour (or perhaps not?). Thanks in advance!",,['complex-analysis']
21,When is composition of meromorphic functions meromorphic,When is composition of meromorphic functions meromorphic,,"When I compose a meromorphic and a holomorphic function, I get a meromorphic function. Are there other cases when a composition of two meromorphic functions is meromorphic? For example, if I compose a holomorphic and a meromorphic function? Or does it hold that the composition is meromorphic in general?","When I compose a meromorphic and a holomorphic function, I get a meromorphic function. Are there other cases when a composition of two meromorphic functions is meromorphic? For example, if I compose a holomorphic and a meromorphic function? Or does it hold that the composition is meromorphic in general?",,"['complex-analysis', 'function-and-relation-composition', 'holomorphic-functions', 'meromorphic-functions']"
22,Is this complex function differentiable at 0?,Is this complex function differentiable at 0?,,"I'm moving my first steps in Complex Analysis. I can't tell whether the function $$f(x+iy) = 2|xy|+i(y^2-x^2)$$ is differentiable at $0$ or not. I tried using the limit of the difference quotient : $$\lim_{z\to 0}\frac{2|xy|+i(y^2-x^2)}{x+iy}$$ The limit is $0$ when $xy>0$ because $x=-iy$ is a root of the numerator, but I can't compute the limit in general...","I'm moving my first steps in Complex Analysis. I can't tell whether the function $$f(x+iy) = 2|xy|+i(y^2-x^2)$$ is differentiable at $0$ or not. I tried using the limit of the difference quotient : $$\lim_{z\to 0}\frac{2|xy|+i(y^2-x^2)}{x+iy}$$ The limit is $0$ when $xy>0$ because $x=-iy$ is a root of the numerator, but I can't compute the limit in general...",,['complex-analysis']
23,Bolzano-Weierstrass theorem (complex case),Bolzano-Weierstrass theorem (complex case),,"I'm trying to prove Bolzano-Weierstrass Theorem to the complex case, i.e., if $(z_n)$ a complex sequence is bounded, then there is a subsequence of $z_n$ which converges. I'm trying to use the real case of the Bolzano-Weierstrass theorem to prove the complex case without success. I need help. Thanks","I'm trying to prove Bolzano-Weierstrass Theorem to the complex case, i.e., if $(z_n)$ a complex sequence is bounded, then there is a subsequence of $z_n$ which converges. I'm trying to use the real case of the Bolzano-Weierstrass theorem to prove the complex case without success. I need help. Thanks",,['complex-analysis']
24,What does the symbol $\subset\subset$ mean? [duplicate],What does the symbol  mean? [duplicate],\subset\subset,"This question already has an answer here : The meaning of notation $\subset\subset$ in complex analysis (1 answer) Closed 10 years ago . In some texts (mainly complex analysis or harmonic analysis) I sometimes see the following double subset symbol $\subset\subset$ for inclusion relation of two regions, e.g., $\Omega$ and $\Omega'$ are two regions in $\mathbb{C}$ such that $\Omega \subset\subset \Omega'$ . I never figured out what it means exactly; I always interpreted it as the closure $\overline{\Omega}$ is contained in $\Omega'$ (so that some nasty boundary effects can be avoided). Is that right? Or does $\subset\subset$ mean some other kind of inclusion? Thanks.","This question already has an answer here : The meaning of notation $\subset\subset$ in complex analysis (1 answer) Closed 10 years ago . In some texts (mainly complex analysis or harmonic analysis) I sometimes see the following double subset symbol for inclusion relation of two regions, e.g., and are two regions in such that . I never figured out what it means exactly; I always interpreted it as the closure is contained in (so that some nasty boundary effects can be avoided). Is that right? Or does mean some other kind of inclusion? Thanks.",\subset\subset \Omega \Omega' \mathbb{C} \Omega \subset\subset \Omega' \overline{\Omega} \Omega' \subset\subset,"['complex-analysis', 'notation', 'harmonic-analysis']"
25,Any linear fractional transformation transforming the real axis to itself can be written in terms of reals?,Any linear fractional transformation transforming the real axis to itself can be written in terms of reals?,,"I'm trying to teach myself complex analysis, and was reading about linear transformations. I would like to understand why any linear fractional transformation which transforms the real axis into itself can be written with real coefficients. I assume I have some linear fractional transformation $z\mapsto \frac{az+b}{cz+d}$, where $z\in\mathbb{C}$ and $a,b,c,d\in\mathbb{C}$ are the coefficients, and I think I would like to conclude $a,b,c,d\in\mathbb{R}$ actually. Choosing various reals, I get $$ 0\mapsto\frac{b}{d},\quad 1\mapsto\frac{a+b}{c+d},\quad -1\mapsto\frac{-a+b}{-c+d} $$ so I know all those images are again real. Is there someway to conclude that $a,b,c,d$ are individually real? Thank you.","I'm trying to teach myself complex analysis, and was reading about linear transformations. I would like to understand why any linear fractional transformation which transforms the real axis into itself can be written with real coefficients. I assume I have some linear fractional transformation $z\mapsto \frac{az+b}{cz+d}$, where $z\in\mathbb{C}$ and $a,b,c,d\in\mathbb{C}$ are the coefficients, and I think I would like to conclude $a,b,c,d\in\mathbb{R}$ actually. Choosing various reals, I get $$ 0\mapsto\frac{b}{d},\quad 1\mapsto\frac{a+b}{c+d},\quad -1\mapsto\frac{-a+b}{-c+d} $$ so I know all those images are again real. Is there someway to conclude that $a,b,c,d$ are individually real? Thank you.",,"['complex-analysis', 'transformation']"
26,"If $|z| < 1$, prove that $\Re \left(\frac{1}{1 - z} \right) > \frac{1}{2}$.","If , prove that .",|z| < 1 \Re \left(\frac{1}{1 - z} \right) > \frac{1}{2},"If $|z| < 1$ , prove that $\Re \left(\frac{1}{1 - z} \right) > \frac{1}{2}$ . My attempt: Consider $\frac{1}{1 - z}$ . Let $z = x + iy$ , we know that $|z| < 1 \implies x, y < 1$ . $$\frac{1}{1 - z} = \frac{1}{1 - x - iy} = \frac{1 - x + iy}{(1 - x)^2 + y^2}.$$ $$\Re \left(\frac{1}{1 - z} \right) = \frac{1 - x}{(1 - x)^2 + y^2}.$$ I got $$\frac{1}{(x-1)^2 + y^2} > \frac{1}{2}.$$ How do I manage the numerator? Can you help me? I welcome the alternative approaches.","If , prove that . My attempt: Consider . Let , we know that . I got How do I manage the numerator? Can you help me? I welcome the alternative approaches.","|z| < 1 \Re \left(\frac{1}{1 - z} \right) > \frac{1}{2} \frac{1}{1 - z} z = x + iy |z| < 1 \implies x, y < 1 \frac{1}{1 - z} = \frac{1}{1 - x - iy} = \frac{1 - x + iy}{(1 - x)^2 + y^2}. \Re \left(\frac{1}{1 - z} \right) = \frac{1 - x}{(1 - x)^2 + y^2}. \frac{1}{(x-1)^2 + y^2} > \frac{1}{2}.","['complex-analysis', 'algebra-precalculus']"
27,The complex version of the chain rule,The complex version of the chain rule,,"I want to prove the following equality: \begin{eqnarray} \frac{\partial}{\partial z} (g \circ f) = (\frac{\partial g}{\partial z} \frac{\partial f}{\partial z}) + (\frac{\partial g}{\partial \bar{z}} \frac{\partial \bar{f}}{\partial z}) \end{eqnarray} So I decide to do the following: \begin{eqnarray} \frac{\partial}{\partial z} (g \circ f) = \frac{1}{2}[(\frac{\partial g}{\partial x} \circ f)(\frac{\partial f}{\partial x}) + \frac{1}{i}(\frac{\partial g}{\partial y} \circ f)(\frac{\partial f}{\partial y})] \end{eqnarray} but the thing is that I am doing something wrong here since I don't get any conjugate function and any derivative with respect to $\bar{z}$ so Can someone help me to see where I am wrong and fix it please? In fact I don't see what to do next, so I appreciate your help. Thanks a lot in advance. Edition: What I've got so far is the following: $$\frac{1}{2}[(\frac{\partial g}{\partial x} \circ f + \frac{\partial g}{\partial y} \circ f)\frac{\partial f}{\partial z} ]$$ but I'm still stuck.","I want to prove the following equality: \begin{eqnarray} \frac{\partial}{\partial z} (g \circ f) = (\frac{\partial g}{\partial z} \frac{\partial f}{\partial z}) + (\frac{\partial g}{\partial \bar{z}} \frac{\partial \bar{f}}{\partial z}) \end{eqnarray} So I decide to do the following: \begin{eqnarray} \frac{\partial}{\partial z} (g \circ f) = \frac{1}{2}[(\frac{\partial g}{\partial x} \circ f)(\frac{\partial f}{\partial x}) + \frac{1}{i}(\frac{\partial g}{\partial y} \circ f)(\frac{\partial f}{\partial y})] \end{eqnarray} but the thing is that I am doing something wrong here since I don't get any conjugate function and any derivative with respect to $\bar{z}$ so Can someone help me to see where I am wrong and fix it please? In fact I don't see what to do next, so I appreciate your help. Thanks a lot in advance. Edition: What I've got so far is the following: $$\frac{1}{2}[(\frac{\partial g}{\partial x} \circ f + \frac{\partial g}{\partial y} \circ f)\frac{\partial f}{\partial z} ]$$ but I'm still stuck.",,['complex-analysis']
28,stein and shakarchi complex analysis exercise 3.15 (b),stein and shakarchi complex analysis exercise 3.15 (b),,"I can't solve this exercise from the book, can anyone give me a hint? Show that if $f$ is holomorphic in the unit disc, is bounded, and converges   uniformly to zero in the sector $\theta < \arg z < \varphi$ as $|z| \to 1$, then $f = 0$. (Use the Cauchy inequalities or the maximum modulus principle) My idea was to extend $f$ continuously to the border of the domain : $θ < \arg z < \varphi$ as $|z| = 1$ then since $f=0$ on the border, $f=0$ in the whole domain. However I can't show that $f$ is continuously extendable. thank you!","I can't solve this exercise from the book, can anyone give me a hint? Show that if $f$ is holomorphic in the unit disc, is bounded, and converges   uniformly to zero in the sector $\theta < \arg z < \varphi$ as $|z| \to 1$, then $f = 0$. (Use the Cauchy inequalities or the maximum modulus principle) My idea was to extend $f$ continuously to the border of the domain : $θ < \arg z < \varphi$ as $|z| = 1$ then since $f=0$ on the border, $f=0$ in the whole domain. However I can't show that $f$ is continuously extendable. thank you!",,['complex-analysis']
29,Do the polynomials $(1+z/n)^n$ converge compactly to $e^z$ on $\mathbb{C}$?,Do the polynomials  converge compactly to  on ?,(1+z/n)^n e^z \mathbb{C},"The question is Do the polynomials $p_n(x)=(1+z/n)^n$ converge compactly (or uniformly on compact subsets) to $e^z$ on $\mathbb{C}$? I thought about expanding $$p_n(z)=\sum_{k=0}^n a_k^{(n)}z^k$$ where $$a_k^{(n)}=\binom{n}{k}\frac{1}{n^k}=\frac{1}{k!}\prod_{j=0}^{k-1}\left(1-\frac{j}{n}\right)$$ and trying to show that $\frac{1}{k!}-a_k^{(n)}$ decreases sufficiently fast on any closed ball. That is, I tried to show $$\lim_{n\rightarrow\infty}\max_{z\in\overline{B_0(A)}}\left|\sum_{k=0}^n\frac{z^k}{k!}-p_n(z)\right|=0$$ for any fixed $A>0$, but I had difficulty with this approach. Any help is appreciated.","The question is Do the polynomials $p_n(x)=(1+z/n)^n$ converge compactly (or uniformly on compact subsets) to $e^z$ on $\mathbb{C}$? I thought about expanding $$p_n(z)=\sum_{k=0}^n a_k^{(n)}z^k$$ where $$a_k^{(n)}=\binom{n}{k}\frac{1}{n^k}=\frac{1}{k!}\prod_{j=0}^{k-1}\left(1-\frac{j}{n}\right)$$ and trying to show that $\frac{1}{k!}-a_k^{(n)}$ decreases sufficiently fast on any closed ball. That is, I tried to show $$\lim_{n\rightarrow\infty}\max_{z\in\overline{B_0(A)}}\left|\sum_{k=0}^n\frac{z^k}{k!}-p_n(z)\right|=0$$ for any fixed $A>0$, but I had difficulty with this approach. Any help is appreciated.",,"['complex-analysis', 'complex-numbers']"
30,Complex Analysis: Show that $Arg(z)$ is discontinuous at each point on the nonpositive real axis.,Complex Analysis: Show that  is discontinuous at each point on the nonpositive real axis.,Arg(z),"That's the question. I'm not entirely how to prove, per se, that $Arg(z)$ is discontinuous at every point on the nonpositive real axis. By definition, $- \pi < Arg(z) \leq \pi$, so I'm not sure what there is to show?","That's the question. I'm not entirely how to prove, per se, that $Arg(z)$ is discontinuous at every point on the nonpositive real axis. By definition, $- \pi < Arg(z) \leq \pi$, so I'm not sure what there is to show?",,['complex-analysis']
31,Showing that $f$ has exactly one fixed point,Showing that  has exactly one fixed point,f,"Let $\gamma$ be the circle $\{z \in \mathbb{C}: \lvert z\rvert=1  \}$. Suppose $f$ is a function analytic on an open set containing $\gamma$ and its interior and that $\lvert\, f(z)\rvert<1$ for each $z$ on $\gamma$. Show that $f$ has exactly one fixed point inside $\gamma$ That is, there is exactly one $z$ in the open unit disk with $f(z)=z$. Is this a result of Louville's theorem? I don't know how to approach it.","Let $\gamma$ be the circle $\{z \in \mathbb{C}: \lvert z\rvert=1  \}$. Suppose $f$ is a function analytic on an open set containing $\gamma$ and its interior and that $\lvert\, f(z)\rvert<1$ for each $z$ on $\gamma$. Show that $f$ has exactly one fixed point inside $\gamma$ That is, there is exactly one $z$ in the open unit disk with $f(z)=z$. Is this a result of Louville's theorem? I don't know how to approach it.",,"['complex-analysis', 'analysis', 'fixed-point-theorems']"
32,Where does complex exponential come from?,Where does complex exponential come from?,,The complex exponential function is defined as : $$e^{ix} = \cos x + i\sin x$$ It shares most of its properties with real exponential and it allows a lot of trigonometric calculations such as de Moivre's formula : $$(\cos x+i\sin x)^n = \cos{nx}+i\sin{nx}$$ But where does this definition come from and why does it work ?,The complex exponential function is defined as : $$e^{ix} = \cos x + i\sin x$$ It shares most of its properties with real exponential and it allows a lot of trigonometric calculations such as de Moivre's formula : $$(\cos x+i\sin x)^n = \cos{nx}+i\sin{nx}$$ But where does this definition come from and why does it work ?,,['complex-analysis']
33,Branch cut and $\log(z)$ derivative,Branch cut and  derivative,\log(z),"I'm a little confused about the branch cut thing. Given an entire functions $f(z),g(z),h(z)$, $z\in \mathbb C$, such that $f(x)=g(x)+h(x)$ for all $x\in \mathbb R$, $f$ and $g+h$ doesn't vanish on $\mathbb  R$ . I take the $\log$ for both sides then differentiate and get: $$\log f(x)=\log(g(x)+h(x))$$ $$\frac{f'(x)}{f(x)}=\frac{g'(x)+h'(x)}{g(x)+h(x)}$$ I thought this is correct, but I was asked about ""what is the branch cut I used here?"", and I don't know what does this mean, and what is the answer for this question! Any help!? Edit: I also have the same problem with the following case: If $f(x)=e^{g(x)}$ then $\log f(x)=g(x)$, and $\frac{f'(x)}{f(x)}=g'(x)$, also a branch cut issue!","I'm a little confused about the branch cut thing. Given an entire functions $f(z),g(z),h(z)$, $z\in \mathbb C$, such that $f(x)=g(x)+h(x)$ for all $x\in \mathbb R$, $f$ and $g+h$ doesn't vanish on $\mathbb  R$ . I take the $\log$ for both sides then differentiate and get: $$\log f(x)=\log(g(x)+h(x))$$ $$\frac{f'(x)}{f(x)}=\frac{g'(x)+h'(x)}{g(x)+h(x)}$$ I thought this is correct, but I was asked about ""what is the branch cut I used here?"", and I don't know what does this mean, and what is the answer for this question! Any help!? Edit: I also have the same problem with the following case: If $f(x)=e^{g(x)}$ then $\log f(x)=g(x)$, and $\frac{f'(x)}{f(x)}=g'(x)$, also a branch cut issue!",,['complex-analysis']
34,"For holomorphic $f$, $f(\frac{z}{2})= \frac{1}{2}f(z) \Longrightarrow f(z) = z$","For holomorphic ,",f f(\frac{z}{2})= \frac{1}{2}f(z) \Longrightarrow f(z) = z,"Let $f$ be a holomorphic function on the open unitary disk $\mathbb{D}$ and continuous on $\mathbb{\overline{D}}$. If $f(\frac{z}{2})= \frac{1}{2}f(z)$ for all $z\in \mathbb{\overline{D}}$ and $f(1)=1$, then $f(z)=z$ for all $z\in \mathbb{\overline{D}}$. Got this as homework. Any hints would be highly appreciated.","Let $f$ be a holomorphic function on the open unitary disk $\mathbb{D}$ and continuous on $\mathbb{\overline{D}}$. If $f(\frac{z}{2})= \frac{1}{2}f(z)$ for all $z\in \mathbb{\overline{D}}$ and $f(1)=1$, then $f(z)=z$ for all $z\in \mathbb{\overline{D}}$. Got this as homework. Any hints would be highly appreciated.",,['complex-analysis']
35,Integral using residue theorem complex analysis [closed],Integral using residue theorem complex analysis [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question How to solve this integral using residue theorem? $$\int_0^∞ \frac{x^{(a-1)}}{(x+b)(x+c)} \, dx $$ $0 < a < 1, \ \ \ b > 0, \ \ \ c > 0$","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question How to solve this integral using residue theorem? $$\int_0^∞ \frac{x^{(a-1)}}{(x+b)(x+c)} \, dx $$ $0 < a < 1, \ \ \ b > 0, \ \ \ c > 0$",,"['complex-analysis', 'residue-calculus']"
36,why can't we define a branch of $\log f(z)$ in the whole complex plane?,why can't we define a branch of  in the whole complex plane?,\log f(z),My question is really simple. The only problem to define a branch of $\log f(z)$ in the whole complex plane is because we can have $f(z)=0$ for some $z\in \mathbb C$? In fact I think I don't understand well what's the problem to define $\log f(z)$ in the whole complex plane. Could someone clarifies this for me?,My question is really simple. The only problem to define a branch of $\log f(z)$ in the whole complex plane is because we can have $f(z)=0$ for some $z\in \mathbb C$? In fact I think I don't understand well what's the problem to define $\log f(z)$ in the whole complex plane. Could someone clarifies this for me?,,['complex-analysis']
37,How to derive the value of $\log(-1)$?,How to derive the value of ?,\log(-1),"My book gives the following relation which I cannot derive myself. How to approach it? $$\log(-1)=(2n+1)\pi i, n=0,\pm1,... $$ The definition of logarithm I am using is, $\log z$ is any complex number  $ w$ such that $e^w=z$.","My book gives the following relation which I cannot derive myself. How to approach it? $$\log(-1)=(2n+1)\pi i, n=0,\pm1,... $$ The definition of logarithm I am using is, $\log z$ is any complex number  $ w$ such that $e^w=z$.",,"['complex-analysis', 'complex-numbers', 'logarithms']"
38,"$f(x)=x^3+ax^2+bx+c$ where $1\ge a\ge b\ge c\ge 0$. If $\lambda$ is any root of the polynomial, show that $|\lambda|\le 1$","where . If  is any root of the polynomial, show that",f(x)=x^3+ax^2+bx+c 1\ge a\ge b\ge c\ge 0 \lambda |\lambda|\le 1,"$f(x)=x^3+ax^2+bx+c$ where $1\ge a\ge b\ge c\ge 0$. If $\lambda$ is any root of the polynomial, show that $|\lambda|\le 1$. My attempt: As the polynomial is a cubic, it must have atleast one real root. So, I consider the $\mid\lambda\mid>1$ and $\lambda$ to be real and show that there arises a contradiction. Now, I differentiated the polynomial to see that $f'(x)>0$ from which I could conclude that if the roots are equal then I am done, but if roots are distinct then the other roots are imaginery. But, after several attempts, I could not show that $\mid\lambda\mid\le 1$. I considered using $\lambda\lambda'=\mid\lambda\mid^2$ where $\lambda'$ is the conjugate of the imaginery root, but that didn't seem to help. Please help. EDIT: Rouche's theorem is too advanced for me, please consider giving a more elementary solution. My level of knowledge should be near the undergraduate level.","$f(x)=x^3+ax^2+bx+c$ where $1\ge a\ge b\ge c\ge 0$. If $\lambda$ is any root of the polynomial, show that $|\lambda|\le 1$. My attempt: As the polynomial is a cubic, it must have atleast one real root. So, I consider the $\mid\lambda\mid>1$ and $\lambda$ to be real and show that there arises a contradiction. Now, I differentiated the polynomial to see that $f'(x)>0$ from which I could conclude that if the roots are equal then I am done, but if roots are distinct then the other roots are imaginery. But, after several attempts, I could not show that $\mid\lambda\mid\le 1$. I considered using $\lambda\lambda'=\mid\lambda\mid^2$ where $\lambda'$ is the conjugate of the imaginery root, but that didn't seem to help. Please help. EDIT: Rouche's theorem is too advanced for me, please consider giving a more elementary solution. My level of knowledge should be near the undergraduate level.",,"['complex-analysis', 'polynomials', 'complex-numbers', 'roots']"
39,Essential singularities of $\frac 1{e^z-1}$,Essential singularities of,\frac 1{e^z-1},"How do I show that $\frac 1{e^z-1}$ has essential singularities (instead of say, poles) at $z=2n\pi i(n\in \mathbb Z)$? I can't figure out how to show that the function does not go to infinity near $0$, or that it assumes every possible value near $0$. Exhibiting the laurent series around $0$ isn't general enough to show that essential singularities occur at all the stated points.","How do I show that $\frac 1{e^z-1}$ has essential singularities (instead of say, poles) at $z=2n\pi i(n\in \mathbb Z)$? I can't figure out how to show that the function does not go to infinity near $0$, or that it assumes every possible value near $0$. Exhibiting the laurent series around $0$ isn't general enough to show that essential singularities occur at all the stated points.",,"['complex-analysis', 'power-series']"
40,Computing the odd terms of the Taylor series of $\frac{z}{e^z-1}$,Computing the odd terms of the Taylor series of,\frac{z}{e^z-1},"I know that the terms are $0$ for odd $n > 1$, but I haven't had any luck proving this.  Computing them directly verifies this for small $n$; the function is also analytic, so I've tried taking the integrals $$f^{(n)}(0) = \frac{n!}{2\pi i}\oint_C \frac{f(t)\,\mathrm dt}{t^{n+1}},$$ but I haven't found a way to show that the answer is $0$ for odd $n$.","I know that the terms are $0$ for odd $n > 1$, but I haven't had any luck proving this.  Computing them directly verifies this for small $n$; the function is also analytic, so I've tried taking the integrals $$f^{(n)}(0) = \frac{n!}{2\pi i}\oint_C \frac{f(t)\,\mathrm dt}{t^{n+1}},$$ but I haven't found a way to show that the answer is $0$ for odd $n$.",,"['complex-analysis', 'taylor-expansion']"
41,"Entire function $f$ such that $f(z)=f(P(z))$, where $P$ is a polynomial of degree at least $2$.","Entire function  such that , where  is a polynomial of degree at least .",f f(z)=f(P(z)) P 2,"Let $f$ be a entire function and $P$ be a polynomial of degree at least $2$ . If $$f(z)=f(P(z)),\quad \forall z\in\mathbb C,$$ Is the entire function $f$ constant function? My thought: If $f$ is not constant, then $f$ must be transcendental entire function. If the sequence $\{z_n=P^n(z)\}$ iterated by $P$ has a limit point $w_0$ in $\mathbb C$ , then $$f(z)=f(z_1)=\cdots=f(z_n)=\cdots,\quad \lim_{n\to\infty}f(z_n)=f(w_0),$$ then $f(z)\equiv w_0$ by Identity theorem. But this is not always ture. For enample, if $P(z)=z^2+1$ , take $z=1$ , then $z_n\to\infty$ . Also if $$f(z)=f(e^z),\quad \forall z\in\mathbb C,$$ can we have $f$ is constant function? Any hints and help will welcome.","Let be a entire function and be a polynomial of degree at least . If Is the entire function constant function? My thought: If is not constant, then must be transcendental entire function. If the sequence iterated by has a limit point in , then then by Identity theorem. But this is not always ture. For enample, if , take , then . Also if can we have is constant function? Any hints and help will welcome.","f P 2 f(z)=f(P(z)),\quad \forall z\in\mathbb C, f f f \{z_n=P^n(z)\} P w_0 \mathbb C f(z)=f(z_1)=\cdots=f(z_n)=\cdots,\quad \lim_{n\to\infty}f(z_n)=f(w_0), f(z)\equiv w_0 P(z)=z^2+1 z=1 z_n\to\infty f(z)=f(e^z),\quad \forall z\in\mathbb C, f","['complex-analysis', 'limits', 'dynamical-systems']"
42,Evaluate the integral $\int_{-\infty}^{\infty} e^{-x^2} e^{ix} dx$,Evaluate the integral,\int_{-\infty}^{\infty} e^{-x^2} e^{ix} dx,I tried common techniques like integration by parts but did not succeed. The $e^{ix}$ also is causing some trouble. I'm guessing this is a Fourier transform in disguise but I'm not sure how the evaluate this. Any help will be appreciated!,I tried common techniques like integration by parts but did not succeed. The $e^{ix}$ also is causing some trouble. I'm guessing this is a Fourier transform in disguise but I'm not sure how the evaluate this. Any help will be appreciated!,,"['complex-analysis', 'analysis', 'fourier-analysis']"
43,Prove or disprove that every Holomorphic function preserving unboundedness is a polynomial.,Prove or disprove that every Holomorphic function preserving unboundedness is a polynomial.,,Roughly speaking as the title says: Prove or disprove that every holomorphic function preserving unboundedness is a polynomial. Let $f : \Bbb C \to \Bbb C$ be a holomorphic function such that for every unbounded set $ V \subset \Bbb C$ the image $f(V)$ is also unbounded. Prove or disprove that $f$ must be a polynomial.,Roughly speaking as the title says: Prove or disprove that every holomorphic function preserving unboundedness is a polynomial. Let $f : \Bbb C \to \Bbb C$ be a holomorphic function such that for every unbounded set $ V \subset \Bbb C$ the image $f(V)$ is also unbounded. Prove or disprove that $f$ must be a polynomial.,,"['complex-analysis', 'holomorphic-functions', 'analytic-functions']"
44,Suppose that for each $a\in \mathbb{C}$ at least one coefficient of the Taylor's series $f$ about $a$ is zero. Show that $f$ is a polynomial.,Suppose that for each  at least one coefficient of the Taylor's series  about  is zero. Show that  is a polynomial.,a\in \mathbb{C} f a f,Let $f:\mathbb{C}\rightarrow\mathbb{C}$ be a holomorphic function. Suppose that for each $a\in \mathbb{C}$ at least one coefficient of the Taylor's series $f$ about $a$ is zero. Show that $f$ is  a polynomial.,Let $f:\mathbb{C}\rightarrow\mathbb{C}$ be a holomorphic function. Suppose that for each $a\in \mathbb{C}$ at least one coefficient of the Taylor's series $f$ about $a$ is zero. Show that $f$ is  a polynomial.,,"['complex-analysis', 'complex-integration']"
45,Finding number of zero of $z^{10}+10z+9$ in the unit disc.,Finding number of zero of  in the unit disc.,z^{10}+10z+9,"I am trying to find the number of zero of the polynomial $f(z)=z^{10}+10z+9$ in the disc $D(0,1)$. So far I used Rouché's theorem with $g(z)=z^{10}$ to find that there are 10 zeroes in $D(0,2)$. However, as $-1$ is a zero of $f$ and is in $D(0,1)$, I think Rouché cannot be used directly. Could anyone give me a advice on how to proceed ? Thanks.","I am trying to find the number of zero of the polynomial $f(z)=z^{10}+10z+9$ in the disc $D(0,1)$. So far I used Rouché's theorem with $g(z)=z^{10}$ to find that there are 10 zeroes in $D(0,2)$. However, as $-1$ is a zero of $f$ and is in $D(0,1)$, I think Rouché cannot be used directly. Could anyone give me a advice on how to proceed ? Thanks.",,['complex-analysis']
46,How do I prove that $f'(z)=0$ implies $f$ is constant?,How do I prove that  implies  is constant?,f'(z)=0 f,"Let $V$ be an open connected subset of $\mathbb{C}$. Let $f:V\rightarrow\mathbb{C}$ be a function whose derivative is $0$ on $V$. How do I prove that $f$ is a constant on $V$? I know that $V$ is path-connected, but I don't know whether this helps.","Let $V$ be an open connected subset of $\mathbb{C}$. Let $f:V\rightarrow\mathbb{C}$ be a function whose derivative is $0$ on $V$. How do I prove that $f$ is a constant on $V$? I know that $V$ is path-connected, but I don't know whether this helps.",,['complex-analysis']
47,Are there two conventional definitions of “holomorphic”?,Are there two conventional definitions of “holomorphic”?,,"In Walter Rudin's Real and Complex Analysis , second edition, on page 213, two definitions are stated.  One of them says the derivative of $f$ at $z_0$ is $$f'(z_0)=\lim_{z\to z_0}\frac{f(z)-f(z_0)}{z-z_0}.\tag 1$$ The other says $f$ is holomorphic in an open set if $f'(z_0)$ exists at every value of $z_0$ in that set. By that definition, holomorphic doesn't just mean differentiable; it means differentiable at every point in some open set. He never defines “holomorphic at” a point, but only “holomorphic in” an open set. Before opening the book this afternoon, just remembering from years ago, I thought what it said was $f$ is differentiable at $z_0$ if $(1)$ holds; and $f$ is holomorphic at $z_0$ if the derivative exists at every point in some open neighborhood of $z_0$ . By that definition $f(z)=|z|^2$ would be differentiable at $0$ but not holomorphic at $0$ . Thus differentiability at an isolated point would be weaker than holomorphy at that point. QUESTION: Do both conventions exist? I take “ $f$ is analytic at $z_0$ ” to mean $f$ has a convergent power series expansion at $z_0$ , which actually converges to the right thing, the value of $f$ , in the interior of its circle of convergence. Differentiability at every point in some open neighborhood of $z_0$ is enough to prove analyticity, but differentiability at $z_0$ is not. By one of the conventions above, one can say a function holomorphic at a point is analytic at that point; by the other one cannot.","In Walter Rudin's Real and Complex Analysis , second edition, on page 213, two definitions are stated.  One of them says the derivative of at is The other says is holomorphic in an open set if exists at every value of in that set. By that definition, holomorphic doesn't just mean differentiable; it means differentiable at every point in some open set. He never defines “holomorphic at” a point, but only “holomorphic in” an open set. Before opening the book this afternoon, just remembering from years ago, I thought what it said was is differentiable at if holds; and is holomorphic at if the derivative exists at every point in some open neighborhood of . By that definition would be differentiable at but not holomorphic at . Thus differentiability at an isolated point would be weaker than holomorphy at that point. QUESTION: Do both conventions exist? I take “ is analytic at ” to mean has a convergent power series expansion at , which actually converges to the right thing, the value of , in the interior of its circle of convergence. Differentiability at every point in some open neighborhood of is enough to prove analyticity, but differentiability at is not. By one of the conventions above, one can say a function holomorphic at a point is analytic at that point; by the other one cannot.",f z_0 f'(z_0)=\lim_{z\to z_0}\frac{f(z)-f(z_0)}{z-z_0}.\tag 1 f f'(z_0) z_0 f z_0 (1) f z_0 z_0 f(z)=|z|^2 0 0 f z_0 f z_0 f z_0 z_0,"['complex-analysis', 'terminology', 'convention']"
48,"A complex map with ""bounded"" derivative is injective","A complex map with ""bounded"" derivative is injective",,"The exercise I try to solve states: ""Let $\,f\,$ be analytic in $\,D:=\{z\in\mathbb{C}\;|\;|z|<1\}\,$ , and such that $$|f'(z)-1|<\frac{1}{2}\,\,\,\forall\,z\in D$$ Prove that $\,f\,$ is $\,1-1\,$ in $\,D\,$. My thoughts: The condition $$|f'(z)-1|<\frac{1}{2}\,\,\,\forall\,z\in D$$ means the range of the analytic function $\,f'\,$ misses lots of points on the complex plane, so applying Picard's Theorem (or some extension of Liouville's) we get that $\,f'(z)=w=\,$ constant, from which it follows that $\,f\,$ is linear on $\,D\,$ and thus $\,1-1\,$ there. Doubts: $\,\,(i)\,\,$ This exercise is meant to be from an introductory first course in complex functions, so Picard's theorem seems overkill here...yet I can't see how to avoid it. $\,\,(ii)\,\,$ Even assuming we must use Picard's Theorem, the versions of it I know always talk of ""entire functions"", yet our function $\,f\,$ above is analytic only in the open unit disk. Is this a problem? Perhaps it is and thus something else must be used...? Any help will be much appreciated.","The exercise I try to solve states: ""Let $\,f\,$ be analytic in $\,D:=\{z\in\mathbb{C}\;|\;|z|<1\}\,$ , and such that $$|f'(z)-1|<\frac{1}{2}\,\,\,\forall\,z\in D$$ Prove that $\,f\,$ is $\,1-1\,$ in $\,D\,$. My thoughts: The condition $$|f'(z)-1|<\frac{1}{2}\,\,\,\forall\,z\in D$$ means the range of the analytic function $\,f'\,$ misses lots of points on the complex plane, so applying Picard's Theorem (or some extension of Liouville's) we get that $\,f'(z)=w=\,$ constant, from which it follows that $\,f\,$ is linear on $\,D\,$ and thus $\,1-1\,$ there. Doubts: $\,\,(i)\,\,$ This exercise is meant to be from an introductory first course in complex functions, so Picard's theorem seems overkill here...yet I can't see how to avoid it. $\,\,(ii)\,\,$ Even assuming we must use Picard's Theorem, the versions of it I know always talk of ""entire functions"", yet our function $\,f\,$ above is analytic only in the open unit disk. Is this a problem? Perhaps it is and thus something else must be used...? Any help will be much appreciated.",,['complex-analysis']
49,How to find all the solutions to cos$(z)=0$,How to find all the solutions to cos,(z)=0,"How would you go about finding all the solutions to $\cos(z)=0$, where $z\in \mathbb{C}$? I have $$\cos(z)=0 \implies (e^{iz})^2=-1 \implies \text{Log}(e^{iz})=\text{Log}(e^{i\pi(1/2+2k)})\qquad\text{ where }k\in \mathbb{Z}$$ $$\implies ie^{-y}x=i\pi(1/2+2k)$$ $$\implies z= e^{y}\pi(1/2+2k)+iy \qquad\forall k\in \mathbb{Z}\;\text{ and }\;\forall y\in \mathbb{R}$$ Is this correct? Thanks! EDIT: $e^{2iz}=e^{i\pi(1+2k)} \Rightarrow z=\pi/2+k\pi$ where $k\in \mathbb{Z}$","How would you go about finding all the solutions to $\cos(z)=0$, where $z\in \mathbb{C}$? I have $$\cos(z)=0 \implies (e^{iz})^2=-1 \implies \text{Log}(e^{iz})=\text{Log}(e^{i\pi(1/2+2k)})\qquad\text{ where }k\in \mathbb{Z}$$ $$\implies ie^{-y}x=i\pi(1/2+2k)$$ $$\implies z= e^{y}\pi(1/2+2k)+iy \qquad\forall k\in \mathbb{Z}\;\text{ and }\;\forall y\in \mathbb{R}$$ Is this correct? Thanks! EDIT: $e^{2iz}=e^{i\pi(1+2k)} \Rightarrow z=\pi/2+k\pi$ where $k\in \mathbb{Z}$",,"['complex-analysis', 'trigonometry']"
50,Why does the inverse of a mobius transform not get divided by the determinant?,Why does the inverse of a mobius transform not get divided by the determinant?,,for a mobius transform $\frac{az+b}{cz+d}$ it's inverse is given by $\frac{dw-b}{-cw+a}$ since this can be put into a matrix form why is there not a requirement for the inverse to be divided by the determinant?,for a mobius transform $\frac{az+b}{cz+d}$ it's inverse is given by $\frac{dw-b}{-cw+a}$ since this can be put into a matrix form why is there not a requirement for the inverse to be divided by the determinant?,,"['complex-analysis', 'mobius-transformation']"
51,Intuitive explanation why complex differentiation is not linear over real and imaginary part,Intuitive explanation why complex differentiation is not linear over real and imaginary part,,"Suppose we have a complex valued function $f = u + iv \colon U \to \mathbb C$ defined on an open subset $U$ of $\mathbb C$, which is holomorphic. I was asked why it is wrong to use the linearity of the differentiation operator to write $$ \frac{d}{dz} f(z) = \frac{d}{dz} (u(z) + iv(z)) = \frac{d}{dz} u(z) + i \frac{d}{dz} v(z). $$ I explained this by proving that a real - valued function that is holomorphic must be constant, and so for $\frac{d}{dz} u$ and $\frac{d}{dz} v$ to exist $u$ and $v$ must be constant in $z$. However $f$ is not necessarily constant so applying the linearity in this way is invalid. I also showed that the real - and imaginary part functions $\Re()$ and $\Im()$ are not holomorphic. Intuitively I think that real - valued and complex - valued functions are a different 'thing' and the $\frac{d}{dz}$ operator lives in the 'complex analysis world', so even though it is linear over complex functions it does not make sense to use it in the context of real - valued functions. However I was wondering whether there is a clearer or perhaps deeper explanation to this.","Suppose we have a complex valued function $f = u + iv \colon U \to \mathbb C$ defined on an open subset $U$ of $\mathbb C$, which is holomorphic. I was asked why it is wrong to use the linearity of the differentiation operator to write $$ \frac{d}{dz} f(z) = \frac{d}{dz} (u(z) + iv(z)) = \frac{d}{dz} u(z) + i \frac{d}{dz} v(z). $$ I explained this by proving that a real - valued function that is holomorphic must be constant, and so for $\frac{d}{dz} u$ and $\frac{d}{dz} v$ to exist $u$ and $v$ must be constant in $z$. However $f$ is not necessarily constant so applying the linearity in this way is invalid. I also showed that the real - and imaginary part functions $\Re()$ and $\Im()$ are not holomorphic. Intuitively I think that real - valued and complex - valued functions are a different 'thing' and the $\frac{d}{dz}$ operator lives in the 'complex analysis world', so even though it is linear over complex functions it does not make sense to use it in the context of real - valued functions. However I was wondering whether there is a clearer or perhaps deeper explanation to this.",,['complex-analysis']
52,Determine the complex function $f\left ( z \right )$,Determine the complex function,f\left ( z \right ),"The details provided are that the function is analytic and that its real part along the line $y=c x$ is constant. What conclusions can I draw from here? I think that this imposes $\frac{\partial u}{\partial x}=0 $ and $\frac{\partial u}{\partial y}=0 $ along the line, however I am unsure how to take it from here.","The details provided are that the function is analytic and that its real part along the line $y=c x$ is constant. What conclusions can I draw from here? I think that this imposes $\frac{\partial u}{\partial x}=0 $ and $\frac{\partial u}{\partial y}=0 $ along the line, however I am unsure how to take it from here.",,"['complex-analysis', 'analyticity']"
53,"Is it true that $ |\sin^2z+\cos^2z|=1, \forall z \in\Bbb C$?",Is it true that ?," |\sin^2z+\cos^2z|=1, \forall z \in\Bbb C","We know that equation $ \sin^2z+ \cos^2z=1$ which holds  $ \forall z \in\Bbb R$, actually holds $ \forall z \in\Bbb C$. Is it true that $ |\sin^2z+\cos^2z|=1, \forall z \in\Bbb C$? Thanks in advance.","We know that equation $ \sin^2z+ \cos^2z=1$ which holds  $ \forall z \in\Bbb R$, actually holds $ \forall z \in\Bbb C$. Is it true that $ |\sin^2z+\cos^2z|=1, \forall z \in\Bbb C$? Thanks in advance.",,"['complex-analysis', 'trigonometry', 'complex-numbers']"
54,"Proof that $g(z) = \int_0^1 f(t)e^{tz} \, dt$ is entire",Proof that  is entire,"g(z) = \int_0^1 f(t)e^{tz} \, dt","Let $f(z)$ be a complex and continuous function on $[0,1]$. We'll define $g(z) = \int_0^1 f(t)e^{tz} \, dt $. Prove that $g(z)$ is an entire function.","Let $f(z)$ be a complex and continuous function on $[0,1]$. We'll define $g(z) = \int_0^1 f(t)e^{tz} \, dt $. Prove that $g(z)$ is an entire function.",,['complex-analysis']
55,Why this determinant is conformally invariant?,Why this determinant is conformally invariant?,,"While I was reading a paper about random analytic function I found a statement that I was not able to prove and after try brute force and search for some references I decided to ask for a help here. The statement is the following: Denote by $\mathbb{D}$ the unit dic on the complex plane, and consider the function $p:\mathbb{D}^n\to\mathbb{C}$ given by $$ p(z_1,\dots,z_n)\, =\, 4^{-n}\, \det\left(\frac{(1-|z_i|^2)(1-|z_j|^2)}{|1-z_i\overline{z}_j|^2}\right)_{i,j=1}^{n}\, $$  then for any fixed $u\in\mathbb{D}$ the function $p$ is invariant for the Möbius transformation $$ \phi(u,z)=\frac{u+z}{1+\overline{u}z}, $$ in the sense that $$ p(z_1,\dots,z_n)\, = p(\phi(u,z_1),\ldots,\phi(u,z_n)). $$ I appreciate any reference or hint to prove this fact. Edition: The denominator was modified as point out for David and Anon.","While I was reading a paper about random analytic function I found a statement that I was not able to prove and after try brute force and search for some references I decided to ask for a help here. The statement is the following: Denote by $\mathbb{D}$ the unit dic on the complex plane, and consider the function $p:\mathbb{D}^n\to\mathbb{C}$ given by $$ p(z_1,\dots,z_n)\, =\, 4^{-n}\, \det\left(\frac{(1-|z_i|^2)(1-|z_j|^2)}{|1-z_i\overline{z}_j|^2}\right)_{i,j=1}^{n}\, $$  then for any fixed $u\in\mathbb{D}$ the function $p$ is invariant for the Möbius transformation $$ \phi(u,z)=\frac{u+z}{1+\overline{u}z}, $$ in the sense that $$ p(z_1,\dots,z_n)\, = p(\phi(u,z_1),\ldots,\phi(u,z_n)). $$ I appreciate any reference or hint to prove this fact. Edition: The denominator was modified as point out for David and Anon.",,"['complex-analysis', 'determinant']"
56,Approximating functions on compact sets by holomorphic or polynomial functions,Approximating functions on compact sets by holomorphic or polynomial functions,,"I'm studying for an exam and I'm stuck on the following problem: Does there exist a sequence of holomorphic functions $\{f_n(z)\}_{n=1}^{\infty}$ on the unit disc such that $f_n(z)\to1/z$ uniformly on $\{z\in\mathbb{C}\colon|z|=1/2\}$ as $n\to\infty$? What tools would I use if $1/z$ were replaced with another functions, or say the $f_n$'s were replaced by polynomials instead?","I'm studying for an exam and I'm stuck on the following problem: Does there exist a sequence of holomorphic functions $\{f_n(z)\}_{n=1}^{\infty}$ on the unit disc such that $f_n(z)\to1/z$ uniformly on $\{z\in\mathbb{C}\colon|z|=1/2\}$ as $n\to\infty$? What tools would I use if $1/z$ were replaced with another functions, or say the $f_n$'s were replaced by polynomials instead?",,['complex-analysis']
57,Can the limit of a complex number have multiple values?,Can the limit of a complex number have multiple values?,,"I have been studying ""Complex analysis"" for a while. In this ""limit of complex function"" question, I get an answer that's a $4$ th root of $-1.$ I change  that form to polar coordinate form and then see that there's more than one value. This is the work that I have done so far: So, Can the limit of a complex function has more than one value? If not, do I need to change an answer that's a fractional exponent to polar form?","I have been studying ""Complex analysis"" for a while. In this ""limit of complex function"" question, I get an answer that's a th root of I change  that form to polar coordinate form and then see that there's more than one value. This is the work that I have done so far: So, Can the limit of a complex function has more than one value? If not, do I need to change an answer that's a fractional exponent to polar form?",4 -1.,"['complex-analysis', 'limits']"
58,Complex Analysis: Showing analytic function is zero,Complex Analysis: Showing analytic function is zero,,"How I can solve this problem: Let $f: D \to D$ be an analytic function where $D$ is the unit open disc in $\mathbb C$ . Suppose there is a positive number $\delta > 0$ such that , $$\lim_{z \to e^{iθ}} ⁡f(z)= 0; \qquad \forall \ |\theta| < \delta.$$ Show that $f \equiv 0$ on $D$ . Thanks Note: An easier version of this Privalov's Theorem is an exercise problem from Stein and Shakarchi's Complex Analysis textbook which additionally assumes the holomorphic function converges uniformly to $0$ on the portion of the arc. See [1] , [2] , [3] . The absence of this 'uniform' non-tangential limit on the portion of the arc makes it a slightly more difficult problem.","How I can solve this problem: Let be an analytic function where is the unit open disc in . Suppose there is a positive number such that , Show that on . Thanks Note: An easier version of this Privalov's Theorem is an exercise problem from Stein and Shakarchi's Complex Analysis textbook which additionally assumes the holomorphic function converges uniformly to on the portion of the arc. See [1] , [2] , [3] . The absence of this 'uniform' non-tangential limit on the portion of the arc makes it a slightly more difficult problem.",f: D \to D D \mathbb C \delta > 0 \lim_{z \to e^{iθ}} ⁡f(z)= 0; \qquad \forall \ |\theta| < \delta. f \equiv 0 D 0,['complex-analysis']
59,Analytic continuation of Riemann zeta $\zeta(s)$ from the complex $\mathbb{C}$ to quaternion $\mathbb{H}$?,Analytic continuation of Riemann zeta  from the complex  to quaternion ?,\zeta(s) \mathbb{C} \mathbb{H},"One way to define  Riemann zeta function is by the analytic continuation of $$\zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s} = \frac{1}{1^s} + \frac{1}{2^s} + \frac{1}{3^s} + \cdots$$ for the domain $Re(s)>1$ to the full complex plane in $\mathbb{C}$ . Thus, Riemann zeta function is defined for $s \in \mathbb{C}$ and $\zeta(s)  \in  \mathbb{C}$ My question is that do we gain anything new to do analytic continuation of Riemann zeta function such that a ""modified Riemann zeta function"" so $s  \in  \mathbb{H}$ is in quaternion? and $\zeta(s)  \in  \mathbb{H}?$ Does this lead to any interesting result in the math literature? Edit: more precisely, according to the comment, we seek for an analytic continuation of $\zeta(s)$ from the complex $\mathbb{C}/\{1\}$ to quaternion $\mathbb{H}/\{1\}$ ?","One way to define  Riemann zeta function is by the analytic continuation of for the domain to the full complex plane in . Thus, Riemann zeta function is defined for and My question is that do we gain anything new to do analytic continuation of Riemann zeta function such that a ""modified Riemann zeta function"" so is in quaternion? and Does this lead to any interesting result in the math literature? Edit: more precisely, according to the comment, we seek for an analytic continuation of from the complex to quaternion ?",\zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s} = \frac{1}{1^s} + \frac{1}{2^s} + \frac{1}{3^s} + \cdots Re(s)>1 \mathbb{C} s \in \mathbb{C} \zeta(s)  \in  \mathbb{C} s  \in  \mathbb{H} \zeta(s)  \in  \mathbb{H}? \zeta(s) \mathbb{C}/\{1\} \mathbb{H}/\{1\},"['complex-analysis', 'riemann-zeta', 'quaternions']"
60,Defining $e^{i \theta}$,Defining,e^{i \theta},"I want to define $e^{i z}$ without using power series. My approach was as follows: Start with  $$\lim_{n \to \infty} \left(1+\frac{i}{n}\right)^{nz}$$ Then make the substitution $$\frac{1}{m} = \frac{i}{n},\ \text{ so } n=mi.$$ And we have $$\lim_{n \to \infty} \left(1+\frac{1}{m}\right)^{miz}$$ This almost works, but for $n \to \infty$ we have $m \to i \infty.$ So at this point we can't say $$\left[\lim_{m \to \infty} \left(1+\frac{1}{m}\right)^{m} \right]^{iz}=e^{iz}.$$ Because we don't have $m \to \infty.$ So my next idea was to try $$\lim_{x \to 0} \left(1+ ix\right)^{z/x}$$ Then make the substitution $y=ix.$ Then for $x \to 0$ we have $y \to 0.$ So we can say $$\lim_{y \to 0} (1+y)^{iz/y}$$ It is tempting now to write $$\left[\lim_{y \to 0} (1+y)^{1/y}\right]^{iz} = e^{iz}.$$ But we don't know that  $$e = \lim_{y \to 0} (1+y)^{1/y}.$$ We do know that $$e = \lim_{y \to 0+} (1+y)^{1/y}.$$ For $y \in \mathbb{R}.$ In other words, we know that the right limit of $(1+y)^{1/y}$ is $e$, but I wan't to be able to show that its true for all $y \in \mathbb{C}$ and for all ""paths"".","I want to define $e^{i z}$ without using power series. My approach was as follows: Start with  $$\lim_{n \to \infty} \left(1+\frac{i}{n}\right)^{nz}$$ Then make the substitution $$\frac{1}{m} = \frac{i}{n},\ \text{ so } n=mi.$$ And we have $$\lim_{n \to \infty} \left(1+\frac{1}{m}\right)^{miz}$$ This almost works, but for $n \to \infty$ we have $m \to i \infty.$ So at this point we can't say $$\left[\lim_{m \to \infty} \left(1+\frac{1}{m}\right)^{m} \right]^{iz}=e^{iz}.$$ Because we don't have $m \to \infty.$ So my next idea was to try $$\lim_{x \to 0} \left(1+ ix\right)^{z/x}$$ Then make the substitution $y=ix.$ Then for $x \to 0$ we have $y \to 0.$ So we can say $$\lim_{y \to 0} (1+y)^{iz/y}$$ It is tempting now to write $$\left[\lim_{y \to 0} (1+y)^{1/y}\right]^{iz} = e^{iz}.$$ But we don't know that  $$e = \lim_{y \to 0} (1+y)^{1/y}.$$ We do know that $$e = \lim_{y \to 0+} (1+y)^{1/y}.$$ For $y \in \mathbb{R}.$ In other words, we know that the right limit of $(1+y)^{1/y}$ is $e$, but I wan't to be able to show that its true for all $y \in \mathbb{C}$ and for all ""paths"".",,"['complex-analysis', 'analysis']"
61,Why is a holomorphic map between compact connected Riemann surfaces a branched covering?,Why is a holomorphic map between compact connected Riemann surfaces a branched covering?,,"I have seen it claimed that a non-constant holomorphic map $f:X \rightarrow Y$ between compact connected Riemann surfaces is a branched covering i.e. surjective and there is a finite set $\Sigma \subset Y$ and $r \in \mathbb{Z}_+$ such that $|f^{-1}(q)|=r$ for all $q \in Y \setminus \Sigma$. I can see why such a map is surjective, but I don't understand why the rest of the statement is true.","I have seen it claimed that a non-constant holomorphic map $f:X \rightarrow Y$ between compact connected Riemann surfaces is a branched covering i.e. surjective and there is a finite set $\Sigma \subset Y$ and $r \in \mathbb{Z}_+$ such that $|f^{-1}(q)|=r$ for all $q \in Y \setminus \Sigma$. I can see why such a map is surjective, but I don't understand why the rest of the statement is true.",,"['complex-analysis', 'riemann-surfaces']"
62,The value of $|z|^2+|z−3|^2+|z−i|^2$ is minimum when $z$ equals?,The value of  is minimum when  equals?,|z|^2+|z−3|^2+|z−i|^2 z,"The value of $|z|^2+|z−3|^2+|z−i|^2$ is minimum when $z$ equals? I thought probably the circumcentre of the triangle formed by $0,i,3$ should be the answer as in that case the distances would be equal.But the answer is different.Is there anyway to logically deduce the answer instead of the generic method that books follow (i.e. put $z=x+iy$ and then find minima).","The value of $|z|^2+|z−3|^2+|z−i|^2$ is minimum when $z$ equals? I thought probably the circumcentre of the triangle formed by $0,i,3$ should be the answer as in that case the distances would be equal.But the answer is different.Is there anyway to logically deduce the answer instead of the generic method that books follow (i.e. put $z=x+iy$ and then find minima).",,"['complex-analysis', 'optimization']"
63,Calculate $\int_0^{\infty}\frac{1}{(x+1)(x-2)}dx$ using residues,Calculate  using residues,\int_0^{\infty}\frac{1}{(x+1)(x-2)}dx,"I'm supposed to calculate $$\int_0^{\infty}\frac{1}{(x+1)(x-2)}dx$$ using residues. The typical procedure on a problem like this would be to integrate a contour going around an upper-half semicircle of radius $R$, and come back through the real axis, taking two indents on the path at the points $z=-1$, $z=2$, say of radius $\rho_1,\rho_2$ respectively. Then the total integral around the path is $0$ and I can calculate the limits as $\rho_1,\rho_2\to0$ and $R\to\infty$ using the known formulas/theorems. However, this leaves me with $\int_{-\infty}^{\infty}\frac{1}{(x+1)(x-2)}dx$, instead of $0$ to $\infty$. And the function is not even so I can't just take half of the whole integral. Does anybody know a way around this problem? Taking a path going a quarter around the circle and back down to the origin seems unnecessarily complicated, and I'm not even sure that would work here.","I'm supposed to calculate $$\int_0^{\infty}\frac{1}{(x+1)(x-2)}dx$$ using residues. The typical procedure on a problem like this would be to integrate a contour going around an upper-half semicircle of radius $R$, and come back through the real axis, taking two indents on the path at the points $z=-1$, $z=2$, say of radius $\rho_1,\rho_2$ respectively. Then the total integral around the path is $0$ and I can calculate the limits as $\rho_1,\rho_2\to0$ and $R\to\infty$ using the known formulas/theorems. However, this leaves me with $\int_{-\infty}^{\infty}\frac{1}{(x+1)(x-2)}dx$, instead of $0$ to $\infty$. And the function is not even so I can't just take half of the whole integral. Does anybody know a way around this problem? Taking a path going a quarter around the circle and back down to the origin seems unnecessarily complicated, and I'm not even sure that would work here.",,"['complex-analysis', 'contour-integration', 'residue-calculus']"
64,Principal branch of logarithm,Principal branch of logarithm,,"I need to compute $\log(1+i)$ and $\text{Log}(1+i)$, $\text{Log}$ meaning the principal branch. What I do is to express $(1+i)$ in polar coordinates, then equate it with $$\sqrt {2}(\cos \pi/4+ i\sin \pi/4)= \sqrt{2}\mathrm{e}^{\frac{\pi i}{4}}$$ Is this true? Can I now take $\log \sqrt{2}\mathrm{e}^{\frac{\pi i}{4}}=\frac{\sqrt{2}\pi i}{4}$? And now $\text{Log}(1+i)=\log|\sqrt{2}|+\frac {\pi i}{4}+ 2\pi k$? Can someone please tell what is wrong with my computation? What I am really confused about is how different it is to compute the principal brach and the other Help would be appreciated!","I need to compute $\log(1+i)$ and $\text{Log}(1+i)$, $\text{Log}$ meaning the principal branch. What I do is to express $(1+i)$ in polar coordinates, then equate it with $$\sqrt {2}(\cos \pi/4+ i\sin \pi/4)= \sqrt{2}\mathrm{e}^{\frac{\pi i}{4}}$$ Is this true? Can I now take $\log \sqrt{2}\mathrm{e}^{\frac{\pi i}{4}}=\frac{\sqrt{2}\pi i}{4}$? And now $\text{Log}(1+i)=\log|\sqrt{2}|+\frac {\pi i}{4}+ 2\pi k$? Can someone please tell what is wrong with my computation? What I am really confused about is how different it is to compute the principal brach and the other Help would be appreciated!",,"['complex-analysis', 'complex-numbers', 'logarithms']"
65,Showing that $e^z=z$ has infinitely many solutions [duplicate],Showing that  has infinitely many solutions [duplicate],e^z=z,"This question already has answers here : Are there any simple ways to see that $e^z-z=0$ has infinitely many solutions? (4 answers) Closed 4 years ago . One of our review problems for my complex analysis final is the following: Show that $e^z=z$ has infinitely many solutions in $\mathbb{C}$. I've seen a few solutions online, but none of them have used material that was covered in our introductory complex analysis course. Would anyone be able to provide a simple solution? I'm trying to think of ways to invoke bounding in some way but I can't seem to come up with anything.","This question already has answers here : Are there any simple ways to see that $e^z-z=0$ has infinitely many solutions? (4 answers) Closed 4 years ago . One of our review problems for my complex analysis final is the following: Show that $e^z=z$ has infinitely many solutions in $\mathbb{C}$. I've seen a few solutions online, but none of them have used material that was covered in our introductory complex analysis course. Would anyone be able to provide a simple solution? I'm trying to think of ways to invoke bounding in some way but I can't seem to come up with anything.",,['complex-analysis']
66,Do two distinct level sets determine a non-constant complex polynomial?,Do two distinct level sets determine a non-constant complex polynomial?,,"Let $f$ and $g$ be non-constant complex polynomials in one variable. Let $a\neq b$ be complex numbers and suppose $f^{-1}(a)=g^{-1}(a)$ and $f^{-1}(b)=g^{-1}(b)$. Does this imply $f=g$? If we think of entire functions instead of polynomials, the answer is negative: take $e^{-z}$ and $e^{z}$ and they share the same level sets for 0 and 1. More generally, Nevanlinna's 5-values theorem says that 5 level sets completely determine a non-constant meromorphic function. Can we lower this number when dealing with polynomials?","Let $f$ and $g$ be non-constant complex polynomials in one variable. Let $a\neq b$ be complex numbers and suppose $f^{-1}(a)=g^{-1}(a)$ and $f^{-1}(b)=g^{-1}(b)$. Does this imply $f=g$? If we think of entire functions instead of polynomials, the answer is negative: take $e^{-z}$ and $e^{z}$ and they share the same level sets for 0 and 1. More generally, Nevanlinna's 5-values theorem says that 5 level sets completely determine a non-constant meromorphic function. Can we lower this number when dealing with polynomials?",,"['complex-analysis', 'polynomials']"
67,Uniform convergence of Dirichlet series,Uniform convergence of Dirichlet series,,"Let $a_1,a_2,\ldots\in\mathbb{C}$ and consider the Dirichlet series $\sum_{n=1}^\infty \dfrac{a_n}{n^z}$. Suppose the series converges for some $z_0$. Then why does it converge uniformly on every closed disk in the half-space $\Re z>\Re z_0$, where $\Re$ denotes the real part of a complex number? I think it's reasonable that when the real part of $z$ increases, the denominator of $\dfrac{a_n}{n^z}$ increases (well, in some sense), so the convergence gets better. How can we actually prove it though?","Let $a_1,a_2,\ldots\in\mathbb{C}$ and consider the Dirichlet series $\sum_{n=1}^\infty \dfrac{a_n}{n^z}$. Suppose the series converges for some $z_0$. Then why does it converge uniformly on every closed disk in the half-space $\Re z>\Re z_0$, where $\Re$ denotes the real part of a complex number? I think it's reasonable that when the real part of $z$ increases, the denominator of $\dfrac{a_n}{n^z}$ increases (well, in some sense), so the convergence gets better. How can we actually prove it though?",,['complex-analysis']
68,How to solve a complex polynomial?,How to solve a complex polynomial?,,"Solve: $$ z^3 - 3z^2 + 6z - 4 = 0$$ How do I solve this? Can I do it by basically letting $ z = x + iy$ such that $ i = \sqrt{-1}$ and $ x, y \in \mathbf R $ and then substitute that into the equation and get a crazy long equation? If I did that I suspect I wouldn't be able to decipher the imaginary part of the equation. Or should I change it to one of the forms below: $$ z^n = r^n \mathbf{cis} n \theta $$ $$ z^n = r^n e^{n\theta i} $$ And then plug that into the equation? I did that. But it looked unsolvable. I'm so confused.","Solve: $$ z^3 - 3z^2 + 6z - 4 = 0$$ How do I solve this? Can I do it by basically letting $ z = x + iy$ such that $ i = \sqrt{-1}$ and $ x, y \in \mathbf R $ and then substitute that into the equation and get a crazy long equation? If I did that I suspect I wouldn't be able to decipher the imaginary part of the equation. Or should I change it to one of the forms below: $$ z^n = r^n \mathbf{cis} n \theta $$ $$ z^n = r^n e^{n\theta i} $$ And then plug that into the equation? I did that. But it looked unsolvable. I'm so confused.",,"['complex-analysis', 'complex-numbers', 'symbolic-computation']"
69,Find conformal mapping from sector to unit disc,Find conformal mapping from sector to unit disc,,"Find a conformal mapping between the sector $\{z\in\mathbb{C}  : -\pi/4<\arg(z) <\pi/4\}$ and the open unit disc $D$. I know that it should be a Möbius transformation, but other than that I am very stuck, any help would be much appreciated.","Find a conformal mapping between the sector $\{z\in\mathbb{C}  : -\pi/4<\arg(z) <\pi/4\}$ and the open unit disc $D$. I know that it should be a Möbius transformation, but other than that I am very stuck, any help would be much appreciated.",,['complex-analysis']
70,More Properties of Entire Functions,More Properties of Entire Functions,,"A couple more questions about entire functions that I'm having difficulty with: (1) Suppose $f$ is entire with $f(0)=0$ and $|f(z)|\leq e^{1/|z|}$ for all $z\neq0$.  Must $f$ be identically $0$? (2) Suppose that $g$ is entire with $g\circ g=g$.  If $g$ is not constant, must $g$ be the identity? Thanks again for any/all advice.","A couple more questions about entire functions that I'm having difficulty with: (1) Suppose $f$ is entire with $f(0)=0$ and $|f(z)|\leq e^{1/|z|}$ for all $z\neq0$.  Must $f$ be identically $0$? (2) Suppose that $g$ is entire with $g\circ g=g$.  If $g$ is not constant, must $g$ be the identity? Thanks again for any/all advice.",,['complex-analysis']
71,Proving $e^z$ is holomorphic,Proving  is holomorphic,e^z,"I read somewhere that $e^z$ is holomorphic function, but I can't think of an easy way to prove that. I thought of using Cauchy Riemann equations, but that's probably overkill. Is there a simple approach to show that this function is holomorphic?","I read somewhere that is holomorphic function, but I can't think of an easy way to prove that. I thought of using Cauchy Riemann equations, but that's probably overkill. Is there a simple approach to show that this function is holomorphic?",e^z,['complex-analysis']
72,How integrating over a branch cut is made rigorous?,How integrating over a branch cut is made rigorous?,,"This is from Ch. 7 of the book Complex Variables by J Brown and R Churchill 8th ed. In evaluation of the counter integration of $f(z)=\dfrac{z^{-a}}{z+1}$ the book first suggests the following : where $\mathbb{R^+} \cup {\{0}\}$ is the branch cut. Then it claim that integration over the branch cut is not allowed however we will make it rigorousin the exercise 8. Here it is: Well, the part (c) is where it's trying to make it 'rigorous' (part (a) and (b) are easy to understand). My questions: I can't understand part (c) about change of branches. In other words, how it integrates in other branches then sums them in another branch?! (esp. when still the legs from $\rho$ to $R$ both again relies over the branch cut $\mathbb{R^+} \cup {\{0}\}$ ). When in the text I read that it is going to become a rigorous treating, I was thinking about letting the branch cut $\mathbb{R^+} \cup {\{0}\}$ be, and limiting the legs to that branch cut (ie. limiting $\theta_1$ and $\theta_2$ to zero) like this : I tried it but I am not sure if the method is consistent with theorems.  Also I don't know if I can enter the limit $\theta_i \to 0$ inside integral. So how can I accomplish this method if it is allowed or is there any better (more acceptable) method alternative for the one presented in the exercise above? Edit: For question 2: How to prove that the following holds $$\lim_{\theta_1, \theta_2  \to 0} \int_{\rho}^{R} r^{-a} \Big( \dfrac{e^{-ai\theta_1}}{re^{\theta_1}+1} - \dfrac{e^{-2 \pi ai + ia\theta_2}}{re^{\theta_2}+1} \Big) dr = (1-e^{-2 \pi ai}) \int_{\rho}^{R} \dfrac{r^{-a}}{r+1} dr.$$ and can this be considered a rigorous-ization?","This is from Ch. 7 of the book Complex Variables by J Brown and R Churchill 8th ed. In evaluation of the counter integration of the book first suggests the following : where is the branch cut. Then it claim that integration over the branch cut is not allowed however we will make it rigorousin the exercise 8. Here it is: Well, the part (c) is where it's trying to make it 'rigorous' (part (a) and (b) are easy to understand). My questions: I can't understand part (c) about change of branches. In other words, how it integrates in other branches then sums them in another branch?! (esp. when still the legs from to both again relies over the branch cut ). When in the text I read that it is going to become a rigorous treating, I was thinking about letting the branch cut be, and limiting the legs to that branch cut (ie. limiting and to zero) like this : I tried it but I am not sure if the method is consistent with theorems.  Also I don't know if I can enter the limit inside integral. So how can I accomplish this method if it is allowed or is there any better (more acceptable) method alternative for the one presented in the exercise above? Edit: For question 2: How to prove that the following holds and can this be considered a rigorous-ization?","f(z)=\dfrac{z^{-a}}{z+1} \mathbb{R^+} \cup {\{0}\} \rho R \mathbb{R^+} \cup {\{0}\} \mathbb{R^+} \cup {\{0}\} \theta_1 \theta_2 \theta_i \to 0 \lim_{\theta_1, \theta_2  \to 0} \int_{\rho}^{R} r^{-a} \Big( \dfrac{e^{-ai\theta_1}}{re^{\theta_1}+1} - \dfrac{e^{-2 \pi ai + ia\theta_2}}{re^{\theta_2}+1} \Big) dr = (1-e^{-2 \pi ai}) \int_{\rho}^{R} \dfrac{r^{-a}}{r+1} dr.","['complex-analysis', 'proof-verification']"
73,Relation between signs of imaginary parts of $(x+iy)$ and $\sqrt{x+iy}$,Relation between signs of imaginary parts of  and,(x+iy) \sqrt{x+iy},"I am looking at the Harvard notes for the complex analysis, and I do not follow how they arrive at the circled: EDIT: Can also someone show me how to get to the last line? I am a bit confused about how the $\text{sgn}(b)$ emerges there.","I am looking at the Harvard notes for the complex analysis, and I do not follow how they arrive at the circled: EDIT: Can also someone show me how to get to the last line? I am a bit confused about how the $\text{sgn}(b)$ emerges there.",,"['complex-analysis', 'algebra-precalculus', 'radicals']"
74,Rules for exponential and logarithm with complex arguments,Rules for exponential and logarithm with complex arguments,,"Stackexchange community, i have a question concerning the rules for exponentials and logarithms with complex arguments. For real arguments we have: $$e^{a+b}=e^a\cdot e^b$$ $$e^{a-b}=e^{a}/e^{b}$$ $$e^{\ln a}=a$$ $$\ln(a\cdot b)=\ln a + \ln b$$ $$\ln(\frac{a}{b})=\ln a - \ln b$$ $$\ln(e^{a})=a$$ $$\log_a(b)=\frac{\log_c(b)}{\log_c(a)}$$ Can i use these laws also for complex numbers? I know I have to take care of periodicity and singularities.","Stackexchange community, i have a question concerning the rules for exponentials and logarithms with complex arguments. For real arguments we have: $$e^{a+b}=e^a\cdot e^b$$ $$e^{a-b}=e^{a}/e^{b}$$ $$e^{\ln a}=a$$ $$\ln(a\cdot b)=\ln a + \ln b$$ $$\ln(\frac{a}{b})=\ln a - \ln b$$ $$\ln(e^{a})=a$$ $$\log_a(b)=\frac{\log_c(b)}{\log_c(a)}$$ Can i use these laws also for complex numbers? I know I have to take care of periodicity and singularities.",,['complex-analysis']
75,what is the sup and inf of absolute value of $1+z+z^2+ ...+z^n$?,what is the sup and inf of absolute value of ?,1+z+z^2+ ...+z^n,"What is the supremum and the infimum of the absolute value of $1+z+z^2+ \dots+z^n$ when $z$ is a complex number and $z$ is inside the unit circle on the complex plane, which means $zz^*<1$? I tried such as when $z \geq 1$ on $\mathbb{R}$ it seems to have the supremum $n+1$ and when $z \geq 0$ it seems to have the infimum $1$, but I couldn't prove it.","What is the supremum and the infimum of the absolute value of $1+z+z^2+ \dots+z^n$ when $z$ is a complex number and $z$ is inside the unit circle on the complex plane, which means $zz^*<1$? I tried such as when $z \geq 1$ on $\mathbb{R}$ it seems to have the supremum $n+1$ and when $z \geq 0$ it seems to have the infimum $1$, but I couldn't prove it.",,"['complex-analysis', 'supremum-and-infimum']"
76,Residues and poles proof,Residues and poles proof,,"Let the degree of the polynomials $P(z)=a_0+a_1z+a_2z^2+\cdots+a_nz^n$   $a_n\neq0$ and $Q(z)=b_0+b_1z+b_2z^2+\cdots+b_mz^m$ $b_m\neq 0$ be such that $m\geq n+2$. Show that   if all the zeros of $Q(z)$ are interior to a simple closed contour C,   then $$\int_C\frac{P(z)}{Q(z)} \, dz=0$$ I am lost on how to show it $P(z)$ and $Q(z)$ are polynomials, then the ratio is analytic in all the points except where $Q(z)=0$. If $\frac{P(z)}{Q(z)}$ be analytical in all the points on the contour or inside, so I could tell straight that the integral is zero, but that is not the case.","Let the degree of the polynomials $P(z)=a_0+a_1z+a_2z^2+\cdots+a_nz^n$   $a_n\neq0$ and $Q(z)=b_0+b_1z+b_2z^2+\cdots+b_mz^m$ $b_m\neq 0$ be such that $m\geq n+2$. Show that   if all the zeros of $Q(z)$ are interior to a simple closed contour C,   then $$\int_C\frac{P(z)}{Q(z)} \, dz=0$$ I am lost on how to show it $P(z)$ and $Q(z)$ are polynomials, then the ratio is analytic in all the points except where $Q(z)=0$. If $\frac{P(z)}{Q(z)}$ be analytical in all the points on the contour or inside, so I could tell straight that the integral is zero, but that is not the case.",,"['complex-analysis', 'complex-numbers', 'residue-calculus', 'complex-integration']"
77,"There aren't non-holomorphic polynomials, right?","There aren't non-holomorphic polynomials, right?",,"Full disclosure: I'm taking my first complex analysis course as a graduate student and the title of my question looks like a dumb question to me. In any case, there's a problem in my book that deals with a sequence of ""holomorphic polynomials"" converging to a ""holomorphic polynomial"". Is this just a redundancy or is there some weird world where certain polynomials aren't (complex) differentiable?","Full disclosure: I'm taking my first complex analysis course as a graduate student and the title of my question looks like a dumb question to me. In any case, there's a problem in my book that deals with a sequence of ""holomorphic polynomials"" converging to a ""holomorphic polynomial"". Is this just a redundancy or is there some weird world where certain polynomials aren't (complex) differentiable?",,['complex-analysis']
78,Zeros set of analytic functions over complex plane with several variables,Zeros set of analytic functions over complex plane with several variables,,"I know that the zeros of analytic function (with one variable) over complex plane are isolated. However, I am not aware about the structure of the zeros set of analytic functions over complex plane with several variables . My question is: How I can understood this structure.","I know that the zeros of analytic function (with one variable) over complex plane are isolated. However, I am not aware about the structure of the zeros set of analytic functions over complex plane with several variables . My question is: How I can understood this structure.",,"['complex-analysis', 'roots', 'analyticity', 'several-complex-variables']"
79,Automorphism group any bounded domain of $\mathbb{C}$,Automorphism group any bounded domain of,\mathbb{C},"So far the automorphism group I have calculated for known domain is a Lie Group,so  Automorphism group any bounded domain of $\mathbb{C}$ is a lie group?","So far the automorphism group I have calculated for known domain is a Lie Group,so  Automorphism group any bounded domain of $\mathbb{C}$ is a lie group?",,"['complex-analysis', 'lie-groups', 'complex-geometry']"
80,"In the context of the fundamental theorem of algebra, why does $p(z)\overline{p(\bar z)}$ have only real coefficients?","In the context of the fundamental theorem of algebra, why does  have only real coefficients?",p(z)\overline{p(\bar z)},"I just read about a Wikipedia page on Fundamental Theorem of Algebra , and it says ""Some proofs of the theorem only prove that any non-constant polynomial with real coefficients has some complex root. This is enough to establish the theorem in the general case because, given a non-constant polynomial $p(z)$ with complex coefficients, the polynomial $$q(z)=p(z)\overline{p(\bar z)}$$ has only real coefficients and, if z is a zero of q(z), then either z or its conjugate is a root of p(z)."" I don't understand why $q(z)$ here has only real coefficients. Suppose $p(z)=\sum_{i=0}^na_iz^{i}\in\mathbb {C}[z].$ Then $\overline{p(\bar z)}=\sum_{j=0}^n\bar {a_j}z^j.$ (Right?) We have $$p(z)\bar{p(\bar z)}=\left(\sum_{i=0}^na_iz^{i}\right)\left(\sum_{j=0}^n\bar {a_j}z^j\right)=\sum_{k=0}^{2n}\left(\sum_{i+j=k}a_i\bar{a_j}\right)z^k.$$ However, it seems not true that $\sum_{i+j=k}a_i\bar{a_j}$ is always a real number, for some $k$ . What's wrong here? Moreover, I was wondering whether $p(z)p(\bar z)$ has only real coefficients. Why do people like choosing $p(z)\overline{p(\bar z)}$ ? Thanks in advance.","I just read about a Wikipedia page on Fundamental Theorem of Algebra , and it says ""Some proofs of the theorem only prove that any non-constant polynomial with real coefficients has some complex root. This is enough to establish the theorem in the general case because, given a non-constant polynomial with complex coefficients, the polynomial has only real coefficients and, if z is a zero of q(z), then either z or its conjugate is a root of p(z)."" I don't understand why here has only real coefficients. Suppose Then (Right?) We have However, it seems not true that is always a real number, for some . What's wrong here? Moreover, I was wondering whether has only real coefficients. Why do people like choosing ? Thanks in advance.",p(z) q(z)=p(z)\overline{p(\bar z)} q(z) p(z)=\sum_{i=0}^na_iz^{i}\in\mathbb {C}[z]. \overline{p(\bar z)}=\sum_{j=0}^n\bar {a_j}z^j. p(z)\bar{p(\bar z)}=\left(\sum_{i=0}^na_iz^{i}\right)\left(\sum_{j=0}^n\bar {a_j}z^j\right)=\sum_{k=0}^{2n}\left(\sum_{i+j=k}a_i\bar{a_j}\right)z^k. \sum_{i+j=k}a_i\bar{a_j} k p(z)p(\bar z) p(z)\overline{p(\bar z)},"['algebra-precalculus', 'complex-analysis', 'polynomials']"
81,Determine the set of values of $\exp(1/z)$ for $0<|z|<r$,Determine the set of values of  for,\exp(1/z) 0<|z|<r,"I can't do this exercise of Conway's Book: For $r>0$ let $A=\{w:w=\exp(1/z), 0<|z|<r\}$, determine the set $A$. Any hints?","I can't do this exercise of Conway's Book: For $r>0$ let $A=\{w:w=\exp(1/z), 0<|z|<r\}$, determine the set $A$. Any hints?",,['complex-numbers']
82,Why are the Fourier coefficients of a modular form constant?,Why are the Fourier coefficients of a modular form constant?,,"Let $f$ be a holomorphic modular form (of given weight and level one). Since it $1$ -périodic and of moderate growth, it has a Fourier expansion, but this one is a Fourier expansion in $x$ , that is $$f(z) = \sum_{n \geqslant 0} a_n(y) e(nx).$$ I would like to understand why $a_n(y)$ does not depend on $y$ . Many sources just state the holomorphicity, but I do not see the relation with this integral? Is that a question of contour integral expression?","Let be a holomorphic modular form (of given weight and level one). Since it -périodic and of moderate growth, it has a Fourier expansion, but this one is a Fourier expansion in , that is I would like to understand why does not depend on . Many sources just state the holomorphicity, but I do not see the relation with this integral? Is that a question of contour integral expression?",f 1 x f(z) = \sum_{n \geqslant 0} a_n(y) e(nx). a_n(y) y,"['complex-analysis', 'fourier-analysis', 'modular-forms']"
83,"Let $f$ be an entire function such that $f(1)=2f(0)$. Prove that $\forall\epsilon>0, \exists z\in\mathbb{C}$ such that $|f(z)|<\epsilon$",Let  be an entire function such that . Prove that  such that,"f f(1)=2f(0) \forall\epsilon>0, \exists z\in\mathbb{C} |f(z)|<\epsilon","I am asked to prove this: Let $f$ be an entire function such that $f(1)=2f(0)$ . Prove that $\forall\epsilon>0, \exists z\in\mathbb{C}$ such that $|f(z)|<\epsilon$ I considered a function $g(z)=f(z+1)-2f(z)$ , which is also entire and has a zero at $z=0$ , but I am not sure this is going to help me solve the problem.","I am asked to prove this: Let be an entire function such that . Prove that such that I considered a function , which is also entire and has a zero at , but I am not sure this is going to help me solve the problem.","f f(1)=2f(0) \forall\epsilon>0, \exists z\in\mathbb{C} |f(z)|<\epsilon g(z)=f(z+1)-2f(z) z=0",['complex-analysis']
84,Laurent series for $\cot (z)$,Laurent series for,\cot (z),"I'm looking for clarification on how to compute a Laurent series for $\cot z$ I started by trying to find the $\frac{1}{\sin z}$. I've found multiple references that go from an Taylor expansion for $\sin z$ directly to an expression for $\frac{1}{\sin z}$ but I am unable to follow how they got there. This thread Calculate Laurent series for $1/ \sin(z)$ started to answer my question but I do not understand how to use the given formulas to ""iteratively compute"" the coefficients, and the example given has several coefficients in place and I'm not sure how they were obtained.","I'm looking for clarification on how to compute a Laurent series for $\cot z$ I started by trying to find the $\frac{1}{\sin z}$. I've found multiple references that go from an Taylor expansion for $\sin z$ directly to an expression for $\frac{1}{\sin z}$ but I am unable to follow how they got there. This thread Calculate Laurent series for $1/ \sin(z)$ started to answer my question but I do not understand how to use the given formulas to ""iteratively compute"" the coefficients, and the example given has several coefficients in place and I'm not sure how they were obtained.",,"['complex-analysis', 'taylor-expansion', 'residue-calculus', 'laurent-series']"
85,Can a non-constant analytic function have infinitely many zeros on a closed disk?,Can a non-constant analytic function have infinitely many zeros on a closed disk?,,"I think not, however my proof is quite sketchy so far $...$ My attempt: Suppose an analytic function f has infinitely many zeros on some closed disk $D$ . Then there exists a sequence of zeros in $D$ with a limit point in $D$ . Thus by the identity theorem (Let $D$ be a domain and f analytic in D. If the set of zeros $Z(f)$ has a limit point in D, then $f ≡ 0$ in $D$ .), f is identically zero and thus constant. My main reasons for confusion (other than having a weak understanding of the identity theorem): Couldn't such a function $f$ have a finite number of distinct zeros, each with infinite multiplicity? in this case there wouldn't be a convergent sequence of zeros... What is the relevance of the fact that $D$ is closed? Any help in understanding this problem would be greatly appreciated! Thanks","I think not, however my proof is quite sketchy so far My attempt: Suppose an analytic function f has infinitely many zeros on some closed disk . Then there exists a sequence of zeros in with a limit point in . Thus by the identity theorem (Let be a domain and f analytic in D. If the set of zeros has a limit point in D, then in .), f is identically zero and thus constant. My main reasons for confusion (other than having a weak understanding of the identity theorem): Couldn't such a function have a finite number of distinct zeros, each with infinite multiplicity? in this case there wouldn't be a convergent sequence of zeros... What is the relevance of the fact that is closed? Any help in understanding this problem would be greatly appreciated! Thanks",... D D D D Z(f) f ≡ 0 D f D,['complex-analysis']
86,Proving $-\frac{1}{2}(z+\frac{1}{z})$ maps upper half disk onto upper half plane,Proving  maps upper half disk onto upper half plane,-\frac{1}{2}(z+\frac{1}{z}),"To prove $-\frac{1}{2}(z+\frac{1}{z})$ maps upper half disk onto upper half plane, I have been trying to find a formula for the  inverse. To this end, I chose $\omega$ in the upper half plane. $$\omega = -\frac{1}{2}(z+\frac{1}{z})$$ $$0 = z^2+2 \omega z +1$$ At this point I would prefer to use the quadratic formula because I want a formula for the inverse, but I was unable to prove that one of the two solutions given lie inside the unit disk. I have come up with an unsatisfactory existence proof below. There are two solutions for $z$, call them $z_1$ and $z_2$. By the form of the polynomial $z_1 z_2 = 1$ and $z_1 + z_2 = -2 \omega$. wlog let $|z_1| \lt 1$ and $|z_2| \gt 1$. Since $z_1$ and $z_2$ lie on opposite sides of the real line (because they are inverses), and their sum is in the lower half plane, the smaller one $z_1$ must lie in the upper half plane and hence the upper half disk. So there exists an inverse, but I don't have a closed form solution. (This is exercise 8.5 in Stein and Shakarchi Complex Analysis )","To prove $-\frac{1}{2}(z+\frac{1}{z})$ maps upper half disk onto upper half plane, I have been trying to find a formula for the  inverse. To this end, I chose $\omega$ in the upper half plane. $$\omega = -\frac{1}{2}(z+\frac{1}{z})$$ $$0 = z^2+2 \omega z +1$$ At this point I would prefer to use the quadratic formula because I want a formula for the inverse, but I was unable to prove that one of the two solutions given lie inside the unit disk. I have come up with an unsatisfactory existence proof below. There are two solutions for $z$, call them $z_1$ and $z_2$. By the form of the polynomial $z_1 z_2 = 1$ and $z_1 + z_2 = -2 \omega$. wlog let $|z_1| \lt 1$ and $|z_2| \gt 1$. Since $z_1$ and $z_2$ lie on opposite sides of the real line (because they are inverses), and their sum is in the lower half plane, the smaller one $z_1$ must lie in the upper half plane and hence the upper half disk. So there exists an inverse, but I don't have a closed form solution. (This is exercise 8.5 in Stein and Shakarchi Complex Analysis )",,['complex-analysis']
87,An exercise from Steins's complex analysis.,An exercise from Steins's complex analysis.,,"This is an exercise from Steins's complex analysis chapter $8$ : Suppose $F(z)$ is  holomorphic near $z=z_0$ and $F(z_0)=F'(z_0)=0$ , while $F''(z_0)\neq 0$ .show that there are two curves $\Gamma_1$ and $\Gamma_2$ that pass through $z_0$ , are orthogonal at $z_0$ ,and so that $F$ restricted to $\Gamma_1$ is real and has a minimum at $z_0$ ,while $F$ restricted to $\Gamma_2$ is also real but has a maximum at $z_0$ . This hint is also given: Write $F(z)=(g(z))^2$ for $z$ near $z_0$ , and consider the mapping $z \rightarrow g(z)$ and its inverse. I really have no idea. Thanks","This is an exercise from Steins's complex analysis chapter : Suppose is  holomorphic near and , while .show that there are two curves and that pass through , are orthogonal at ,and so that restricted to is real and has a minimum at ,while restricted to is also real but has a maximum at . This hint is also given: Write for near , and consider the mapping and its inverse. I really have no idea. Thanks",8 F(z) z=z_0 F(z_0)=F'(z_0)=0 F''(z_0)\neq 0 \Gamma_1 \Gamma_2 z_0 z_0 F \Gamma_1 z_0 F \Gamma_2 z_0 F(z)=(g(z))^2 z z_0 z \rightarrow g(z),['complex-analysis']
88,Crazy calculation for winding numbers,Crazy calculation for winding numbers,,"Find the winding number around $z=-i, z=-1, z=0$ in the following figure. The purpose of this exercise is to complete a complex integral with singularities at the stated points. My attempt is that the winding number around $z=0$ is $1$, and that the winding numbers around $z=-i$ is zero, and $z=-1$ is $-1$. The reason it is zero for $z=-i$ is because the curve winds around $-i$ clockwise once, and then winds around it counterclockwise once. The reason it is $-1$ for $z=-1$ is because the curve winds around that point clockwise once. My shakiest solution is the winding number for $z=-1$. For some reason, I have a competing thought that the winding number is in fact zero. In my head, I figure I'm free to ""move"" the knot around $z=-i$ and ""unfold"" it to get a figure that does not wind around $z=-1$ at all. Informally, I think of the curve as a rope where the intersections are actually a part of the rope lying on top of another part. I hope that is not too unclear.","Find the winding number around $z=-i, z=-1, z=0$ in the following figure. The purpose of this exercise is to complete a complex integral with singularities at the stated points. My attempt is that the winding number around $z=0$ is $1$, and that the winding numbers around $z=-i$ is zero, and $z=-1$ is $-1$. The reason it is zero for $z=-i$ is because the curve winds around $-i$ clockwise once, and then winds around it counterclockwise once. The reason it is $-1$ for $z=-1$ is because the curve winds around that point clockwise once. My shakiest solution is the winding number for $z=-1$. For some reason, I have a competing thought that the winding number is in fact zero. In my head, I figure I'm free to ""move"" the knot around $z=-i$ and ""unfold"" it to get a figure that does not wind around $z=-1$ at all. Informally, I think of the curve as a rope where the intersections are actually a part of the rope lying on top of another part. I hope that is not too unclear.",,['complex-analysis']
89,Weierstrass Approximation Theorem for $\Bbb C$,Weierstrass Approximation Theorem for,\Bbb C,"The Weierstrass approximation theorem states that any continuous function $ f : I \rightarrow \Bbb R $ on a closed, bounded, connected subset $ I \subseteq \Bbb R $ can be uniformly approximated by polynomials. Can any continuous function $ \phi : J \rightarrow \Bbb C $ on a closed, bounded, connected subset $ J \subseteq \Bbb C $ be uniformly approximated by polynomials? What I mean is, for which subsets $ J \subseteq \Bbb C $ can all functions be approximated uniformly by polynomials. This question is an example sheet question that I had (already supervised on $-$ non-examinable) but supervisor wasn't sure what the question meant exactly. There are some basic sets, such as closed, real intervals, that it clearly holds for, but others (such as closed unit ball) that it does not hold for. Is anyone able to shed any light on the answer. (Not just a few counter-examples, but some explanation as to why it does / does not hold on certain set (eg, because connected complement / similar).) Thanks very much!","The Weierstrass approximation theorem states that any continuous function $ f : I \rightarrow \Bbb R $ on a closed, bounded, connected subset $ I \subseteq \Bbb R $ can be uniformly approximated by polynomials. Can any continuous function $ \phi : J \rightarrow \Bbb C $ on a closed, bounded, connected subset $ J \subseteq \Bbb C $ be uniformly approximated by polynomials? What I mean is, for which subsets $ J \subseteq \Bbb C $ can all functions be approximated uniformly by polynomials. This question is an example sheet question that I had (already supervised on $-$ non-examinable) but supervisor wasn't sure what the question meant exactly. There are some basic sets, such as closed, real intervals, that it clearly holds for, but others (such as closed unit ball) that it does not hold for. Is anyone able to shed any light on the answer. (Not just a few counter-examples, but some explanation as to why it does / does not hold on certain set (eg, because connected complement / similar).) Thanks very much!",,"['complex-analysis', 'approximation']"
90,Radius of convergence for the exponential function,Radius of convergence for the exponential function,,"I'm studying physics and am currently following a course on complex analysis and in the section on analytic functions, the radius of convergence $R$ for power series was introduced. The Taylor expansion around $z_0=0$ for the exponential function was considered as an example of a power series with $R\rightarrow\infty$. The notes state this can be proved by using Weierstrass' Criterion for uniform convergence, which I'll state in my own words: Consider a series $\sum\limits_{k=0}^{\infty} f_k(z)$. If you know numbers $a_k$ for which $|f_k(z)| < a_k$ for all $z$, and $\sum\limits_{k=0}^{\infty} a_k$ converges uniformly, then also $\sum\limits_{k=0}^{\infty} f_k(z)$ converges uniformly. For the exponential, we have the power series $e^z = \sum\limits_{k=0}^{\infty}\dfrac{z^k}{k!}$. Now I've been thinking about this, but I can't seem to think of a uniformly converging series of $a_k$'s that bound the terms of this power series. Perhaps this is really straightforward and I wouldn't have any difficulties with it if I remembered my course on real analysis a bit better... It's not a homework problem and series convergence is not a main goal in this course, but it's been bugging me that I don't understand why Weierstrass's Criterion proves that the radius of convergence goes to infinity for the exponential, so I thought I'd ask here. Thanks in advance.","I'm studying physics and am currently following a course on complex analysis and in the section on analytic functions, the radius of convergence $R$ for power series was introduced. The Taylor expansion around $z_0=0$ for the exponential function was considered as an example of a power series with $R\rightarrow\infty$. The notes state this can be proved by using Weierstrass' Criterion for uniform convergence, which I'll state in my own words: Consider a series $\sum\limits_{k=0}^{\infty} f_k(z)$. If you know numbers $a_k$ for which $|f_k(z)| < a_k$ for all $z$, and $\sum\limits_{k=0}^{\infty} a_k$ converges uniformly, then also $\sum\limits_{k=0}^{\infty} f_k(z)$ converges uniformly. For the exponential, we have the power series $e^z = \sum\limits_{k=0}^{\infty}\dfrac{z^k}{k!}$. Now I've been thinking about this, but I can't seem to think of a uniformly converging series of $a_k$'s that bound the terms of this power series. Perhaps this is really straightforward and I wouldn't have any difficulties with it if I remembered my course on real analysis a bit better... It's not a homework problem and series convergence is not a main goal in this course, but it's been bugging me that I don't understand why Weierstrass's Criterion proves that the radius of convergence goes to infinity for the exponential, so I thought I'd ask here. Thanks in advance.",,"['complex-analysis', 'convergence-divergence', 'power-series', 'exponential-function']"
91,How to 'analyze' problems in analysis; Computing $\int_0^{2\pi}\frac{1}{(a+b\cos(\theta))^2}d\theta$,How to 'analyze' problems in analysis; Computing,\int_0^{2\pi}\frac{1}{(a+b\cos(\theta))^2}d\theta,"If $a, b \in \mathbb{R}$ with $a > b > 0$, compute this ungodly thing; $$\int_0^{2\pi}\frac{1}{(a+b\cos(\theta))^2}d\theta$$ I'm really not a fan of complex analysis... I can't visualize what's going on here. When I look at things from group/number/graph theory I see ideas. When I look at this... all I see a bunch of symbols. Where to begin with this? Maybe someone with analysis background can offer some intuition on 'analyzing' these things to better see whats going on.. Because right now, I'm lost looking at this. Thanks guys!","If $a, b \in \mathbb{R}$ with $a > b > 0$, compute this ungodly thing; $$\int_0^{2\pi}\frac{1}{(a+b\cos(\theta))^2}d\theta$$ I'm really not a fan of complex analysis... I can't visualize what's going on here. When I look at things from group/number/graph theory I see ideas. When I look at this... all I see a bunch of symbols. Where to begin with this? Maybe someone with analysis background can offer some intuition on 'analyzing' these things to better see whats going on.. Because right now, I'm lost looking at this. Thanks guys!",,"['complex-analysis', 'analysis', 'intuition', 'learning']"
92,Complex logarithm and derivatives,Complex logarithm and derivatives,,"c. Show that $e^{\mathrm{Log}(z)}=z$ and use this to evaluate the derivative of the function $\mathrm{Log}(z)$ . d. Is it true that $\log(e^z)=z$ for complex numbers $z$ ? Justify your answer. I don't know how to answer these questions, I get the concepts in my head but I don't know how to write it down on paper.","c. Show that and use this to evaluate the derivative of the function . d. Is it true that for complex numbers ? Justify your answer. I don't know how to answer these questions, I get the concepts in my head but I don't know how to write it down on paper.",e^{\mathrm{Log}(z)}=z \mathrm{Log}(z) \log(e^z)=z z,"['complex-analysis', 'logarithms']"
93,fractional linear transformations,fractional linear transformations,,"From my research, I have figured out that this is a Möbius transformation. The respective wiki page helped me understand a bit more, however I can't figure out how to obtain the image. So lets talk about what I do know. Well we are describing the set of all values $f(z)$ where $|z| < 1$. I also know that any three points. I also know that Given a set of three distinct points z1, z2, z3 on the Riemann sphere and a second set of distinct points w1, w2, w3, there exists precisely one Möbius transformation f(z) which maps the zs to the ws and from help from another forum I got the following: To decide which part is the image of the interior |z| < 1 of the disc,   figure out which point f sends to infinity.","From my research, I have figured out that this is a Möbius transformation. The respective wiki page helped me understand a bit more, however I can't figure out how to obtain the image. So lets talk about what I do know. Well we are describing the set of all values $f(z)$ where $|z| < 1$. I also know that any three points. I also know that Given a set of three distinct points z1, z2, z3 on the Riemann sphere and a second set of distinct points w1, w2, w3, there exists precisely one Möbius transformation f(z) which maps the zs to the ws and from help from another forum I got the following: To decide which part is the image of the interior |z| < 1 of the disc,   figure out which point f sends to infinity.",,['complex-analysis']
94,The Gamma function is holomorphic on V,The Gamma function is holomorphic on V,,"From the Weierstrass theorem we know that if $(f_n)$ is a sequence of holomorphic functions on an open set $V\subset\mathbb C$ such that $(f_n)$ uniformly converges to $f$ on every compact $K\subset V$ , then $f$ is holomorphic on $V.$ I am planing to use this idea to show that $$ \Gamma(z)=\int_0^{\infty}e^{-t}t^{z-1}\,\mathrm dt $$ is holomorphic on the open right half plane of $\mathbb{C.}$ Let's denote this set by $V.$ The following is the plan: Let $$\Gamma_n(z):=\int_{1/n}^ne^{-t}t^{z-1}\,\mathrm dt$$ for any $z \in V.$ Then I tried with DCT and spent my whole day to show that $\Gamma_n$ converges to $\Gamma,$ but I failed. Could you help me prove this uniform convergence? Also, on this site, a solution suggested by Disintegrating-By-Parts used Fubini's theorem. How do we actually know that $\Gamma_n$ is $L^1 ((0, \infty) \times V$ )?  Here V is the open right halfplane in $\mathbb{C}.$ NB: This problem was asked two/three times. Unfortunately, I do not completely understand any of the solutions. So, I am posting this question one more time. Thank you for your time.","From the Weierstrass theorem we know that if is a sequence of holomorphic functions on an open set such that uniformly converges to on every compact , then is holomorphic on I am planing to use this idea to show that is holomorphic on the open right half plane of Let's denote this set by The following is the plan: Let for any Then I tried with DCT and spent my whole day to show that converges to but I failed. Could you help me prove this uniform convergence? Also, on this site, a solution suggested by Disintegrating-By-Parts used Fubini's theorem. How do we actually know that is )?  Here V is the open right halfplane in NB: This problem was asked two/three times. Unfortunately, I do not completely understand any of the solutions. So, I am posting this question one more time. Thank you for your time.","(f_n) V\subset\mathbb C (f_n) f K\subset V f V.  \Gamma(z)=\int_0^{\infty}e^{-t}t^{z-1}\,\mathrm dt  \mathbb{C.} V. \Gamma_n(z):=\int_{1/n}^ne^{-t}t^{z-1}\,\mathrm dt z \in V. \Gamma_n \Gamma, \Gamma_n L^1 ((0, \infty) \times V \mathbb{C}.","['complex-analysis', 'gamma-function']"
95,Can derivatives have simple poles?,Can derivatives have simple poles?,,"Let $f$ be be holomorphic on the punctured disk $D'(z_0,r)$ with $z_0$ being an isolated singularity. Is it possible for $f'$ to have a simple pole at $z_0$ ? Just looking at the Laurent expansion of $f$ about $z_0$ I think the answer should be ""No"". I am somewhat unsure about this. Can anyone help me out?","Let be be holomorphic on the punctured disk with being an isolated singularity. Is it possible for to have a simple pole at ? Just looking at the Laurent expansion of about I think the answer should be ""No"". I am somewhat unsure about this. Can anyone help me out?","f D'(z_0,r) z_0 f' z_0 f z_0",['complex-analysis']
96,"Location of zeros of the ""real part"" of a polynomial","Location of zeros of the ""real part"" of a polynomial",,"I came across the following question on an old qualifying exam: Let $p$ be a polynomial, all of whose zeros lie in the lower half plane $\lbrace z : \text{Im}(z) < 0 \rbrace$ . Let $a$ and $b$ be the unique pair of polynomials with real coefficients such that $p(z) = a(z) + ib(z)$ . Prove that $a$ and $b$ have only real zeros. I tried to think of a creative way of using the argument principle to approach this, but my attempts so far have been unsuccessful. Does anyone have any insight into this problem? A solution or hint would be appreciated.","I came across the following question on an old qualifying exam: Let be a polynomial, all of whose zeros lie in the lower half plane . Let and be the unique pair of polynomials with real coefficients such that . Prove that and have only real zeros. I tried to think of a creative way of using the argument principle to approach this, but my attempts so far have been unsuccessful. Does anyone have any insight into this problem? A solution or hint would be appreciated.",p \lbrace z : \text{Im}(z) < 0 \rbrace a b p(z) = a(z) + ib(z) a b,"['complex-analysis', 'polynomials', 'roots']"
97,Why does $arg(z^{2})\neq 2arg(z)$?,Why does ?,arg(z^{2})\neq 2arg(z),"I was reading a text that i found about the argument of a complex number ( http://scipp.ucsc.edu/~haber/ph116A/arg_11.pdf ) but I dont truly understand the proof given in that text about why is it that $arg(z^{2})\neq 2arg(z)$, so if it is true, can you give me an idea of why does it happen, because most of the complex anaylisis textbooks say that this property is always true,$arg(z_{1}z_{2})=arg(z_{1})+arg(z_{2})$ if $z_{1},z_{2}$ are not zero, but if what I asked is true it means that it is false for $z_{1}=z_{2}$. I am really confused about this.","I was reading a text that i found about the argument of a complex number ( http://scipp.ucsc.edu/~haber/ph116A/arg_11.pdf ) but I dont truly understand the proof given in that text about why is it that $arg(z^{2})\neq 2arg(z)$, so if it is true, can you give me an idea of why does it happen, because most of the complex anaylisis textbooks say that this property is always true,$arg(z_{1}z_{2})=arg(z_{1})+arg(z_{2})$ if $z_{1},z_{2}$ are not zero, but if what I asked is true it means that it is false for $z_{1}=z_{2}$. I am really confused about this.",,"['complex-analysis', 'complex-numbers', 'proof-explanation']"
98,Is $z^{-1}(e^z-1)$ surjective?,Is  surjective?,z^{-1}(e^z-1),"Is the entire function $$    f(z)=\frac{1}{z}(e^z-1) $$ surjective? I tried to argue like in the question below, but it does not seem to work in a similar way. $z\exp(z)$ surjectivity with the Little Picard Theorem","Is the entire function $$    f(z)=\frac{1}{z}(e^z-1) $$ surjective? I tried to argue like in the question below, but it does not seem to work in a similar way. $z\exp(z)$ surjectivity with the Little Picard Theorem",,"['complex-analysis', 'complex-numbers']"
99,How to prove $f(z)=|z|$ is nowhere differentiable,How to prove  is nowhere differentiable,f(z)=|z|,Hi so i am trying to prove that the function is not  analytic but i am having trouble. I am supposed to use the definition $\frac{f(z+h)-f(z)}{h}$. I tried using the fact that $|z|=\sqrt{z\overline{z}}$ but I cannot see anything obvious. I know my aim is to show that if you approach $0$ at different angles you get different limits but to do so i have to somehow make the equation simpler.,Hi so i am trying to prove that the function is not  analytic but i am having trouble. I am supposed to use the definition $\frac{f(z+h)-f(z)}{h}$. I tried using the fact that $|z|=\sqrt{z\overline{z}}$ but I cannot see anything obvious. I know my aim is to show that if you approach $0$ at different angles you get different limits but to do so i have to somehow make the equation simpler.,,['complex-analysis']
