,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Prove that $f(z)=z^2$ is continuous.,Prove that  is continuous.,f(z)=z^2,"Prove that $f(z)=z^2$ is continuous for all complex and real values of $z$. What I've got so far is: Given $ \epsilon >0$ and $|z-z_0|<\delta$ after some calculations (which I've checked with the answer key) $$ |f(z)-f(z_0)|<\delta(\delta+2|z_0|) $$ Beyond this things get difficult when trying to create $\epsilon$ as a function of $\delta$, the answer reads: $$\delta(\delta+2|z_0|)\leq \frac{\epsilon}{3|z_0|}(|z_0|+2|z_0|)=\epsilon $$ and I have no clue how to get there.","Prove that $f(z)=z^2$ is continuous for all complex and real values of $z$. What I've got so far is: Given $ \epsilon >0$ and $|z-z_0|<\delta$ after some calculations (which I've checked with the answer key) $$ |f(z)-f(z_0)|<\delta(\delta+2|z_0|) $$ Beyond this things get difficult when trying to create $\epsilon$ as a function of $\delta$, the answer reads: $$\delta(\delta+2|z_0|)\leq \frac{\epsilon}{3|z_0|}(|z_0|+2|z_0|)=\epsilon $$ and I have no clue how to get there.",,"['complex-analysis', 'complex-numbers', 'continuity', 'epsilon-delta']"
1,"If $f(\mathbb{C})\subset \mathbb{C}-[0,1]$ then $f$ is constant [closed]",If  then  is constant [closed],"f(\mathbb{C})\subset \mathbb{C}-[0,1] f","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question If $f:\mathbb{C}\longrightarrow\mathbb{C}$ is an entire function such that $f(z)\neq w$ for all $z\in \mathbb{C}$ and for all $w\in [0,1]\subset \mathbb{R}$, how to prove that $f$ is constant (without using Picard's little theorem). Any hint would be appreciated.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question If $f:\mathbb{C}\longrightarrow\mathbb{C}$ is an entire function such that $f(z)\neq w$ for all $z\in \mathbb{C}$ and for all $w\in [0,1]\subset \mathbb{R}$, how to prove that $f$ is constant (without using Picard's little theorem). Any hint would be appreciated.",,['complex-analysis']
2,sequence uniformly convergent on the boundary of a bounded set in $\mathbb{C}$,sequence uniformly convergent on the boundary of a bounded set in,\mathbb{C},"Let $(f_n)$ be a sequence of functions which are  analytic on a bounded region $A\subset\mathbb{C}$ and continuous on the closure $Cl(A)$. Suppose that the sequence is uniformly convergent on the boundary $Bd(A)$. Prove that $(f_n)$ is uniformly convergent to a function on $A$. This is an exercise in the book Basic Complex Analysis by J.E. Marsden and M.J. Hoffman, and is not homework. I am just studying by myself. The book shows a hint: use the Maximum Modulus Theorem. I don't know how to approach the problem because I don't know how to construct the limit function. By hypothesis, there is a function $f$ defined on $Bd(A)$ such that $f_n\to f$ uniformly on $Bd(A)$ but How to extend this function to $A$? Using paths-connectedness of $A$? Do you have a solution for this problem?","Let $(f_n)$ be a sequence of functions which are  analytic on a bounded region $A\subset\mathbb{C}$ and continuous on the closure $Cl(A)$. Suppose that the sequence is uniformly convergent on the boundary $Bd(A)$. Prove that $(f_n)$ is uniformly convergent to a function on $A$. This is an exercise in the book Basic Complex Analysis by J.E. Marsden and M.J. Hoffman, and is not homework. I am just studying by myself. The book shows a hint: use the Maximum Modulus Theorem. I don't know how to approach the problem because I don't know how to construct the limit function. By hypothesis, there is a function $f$ defined on $Bd(A)$ such that $f_n\to f$ uniformly on $Bd(A)$ but How to extend this function to $A$? Using paths-connectedness of $A$? Do you have a solution for this problem?",,"['complex-analysis', 'convergence-divergence', 'uniform-convergence', 'maximum-principle']"
3,Deep reason why infinite sheet means logarithm while finite sheet means polynomial?,Deep reason why infinite sheet means logarithm while finite sheet means polynomial?,,"When reading the ""Lectures on Riemann Surfaces"" by Otto Forster on page 37, he claimed that Suppose $X$ is a Riemann surface and $f:X\to D^{*}$( $D^*$ is the punctured unit disk $\{z\in\mathbb{C}:0<|z|<1\}$) is an unbranched holomorphic covering map. Then one of the following holds: (i) If the covering has an infinite number of sheets, then there exists a biholomorphic mapping $\varphi:X\to H$ of $X$ onto the left half plane such that the following diagram commutes    $$ \require{AMScd} \begin{CD} X @>{\varphi}>> H\\ @V{f}VV @VV{\exp}V \\ D^* @>{id}>> D^* \end{CD} $$   (ii) If the covering is $k$-sheeted( $k<\infty$), then there exists a biholomorphic mapping $\varphi:X\to D^*$ such that following diagram commutes, where $p_k:D^*\to D^*$ is the mapping $z\to z^k$ .    $$ \require{AMScd} \begin{CD} X @>{\varphi}>> D^*\\ @V{f}VV @VV{p_k}V \\ D^* @>{id}>> D^* \end{CD} $$ My question is, are there any deep explanations for this theorem? Why $D^*$ has such a good property that infinite and finite sheet can both be turned into some function we are familiar with? Can other Riemann surface other than $D^*$ have the similar property? Thank you for your help!","When reading the ""Lectures on Riemann Surfaces"" by Otto Forster on page 37, he claimed that Suppose $X$ is a Riemann surface and $f:X\to D^{*}$( $D^*$ is the punctured unit disk $\{z\in\mathbb{C}:0<|z|<1\}$) is an unbranched holomorphic covering map. Then one of the following holds: (i) If the covering has an infinite number of sheets, then there exists a biholomorphic mapping $\varphi:X\to H$ of $X$ onto the left half plane such that the following diagram commutes    $$ \require{AMScd} \begin{CD} X @>{\varphi}>> H\\ @V{f}VV @VV{\exp}V \\ D^* @>{id}>> D^* \end{CD} $$   (ii) If the covering is $k$-sheeted( $k<\infty$), then there exists a biholomorphic mapping $\varphi:X\to D^*$ such that following diagram commutes, where $p_k:D^*\to D^*$ is the mapping $z\to z^k$ .    $$ \require{AMScd} \begin{CD} X @>{\varphi}>> D^*\\ @V{f}VV @VV{p_k}V \\ D^* @>{id}>> D^* \end{CD} $$ My question is, are there any deep explanations for this theorem? Why $D^*$ has such a good property that infinite and finite sheet can both be turned into some function we are familiar with? Can other Riemann surface other than $D^*$ have the similar property? Thank you for your help!",,"['complex-analysis', 'riemann-surfaces']"
4,Fourier transform of a complex exponential with quadratic argument,Fourier transform of a complex exponential with quadratic argument,,"I'm a PhD student who is starting to work right now in the well-established field of ultra-fast optics. The thing is that, in most of the papers I have been reading during the past few days, there is a Fourier transform pair that is normally taken for granted and serves as the basis for more complex calculations. However, and despite my efforts, I haven't been able to find any proof of such pair. In general, it is stated that: \begin{equation} \mathcal{F}\{e^{(jt^2)/(2\alpha)}\} \propto e^{(-j\alpha\omega^2)/2} \end{equation} where $j$ is the imaginary unit, as is the usual convention in engineering. To put it briefly, the Fourier transform of a complex exponential that depends quadratically with time is proportional to a complex eponential that depends quadratically with angular frequency. I know that this is in fact the case when a exponential with a REAL quadratic argument (i.e. a scaled version of the Normal distribution) is considered: \begin{equation} \mathcal{F}\{e^{-t^{2}/(2\alpha)} \} \propto  e^{-\sigma\omega^{2}/2} \end{equation} However, I don't see an easy way to extend that result to the case when the imaginary unit is included in the argument of the exponential. Any comments would be very much appreciated, thanks!","I'm a PhD student who is starting to work right now in the well-established field of ultra-fast optics. The thing is that, in most of the papers I have been reading during the past few days, there is a Fourier transform pair that is normally taken for granted and serves as the basis for more complex calculations. However, and despite my efforts, I haven't been able to find any proof of such pair. In general, it is stated that: \begin{equation} \mathcal{F}\{e^{(jt^2)/(2\alpha)}\} \propto e^{(-j\alpha\omega^2)/2} \end{equation} where $j$ is the imaginary unit, as is the usual convention in engineering. To put it briefly, the Fourier transform of a complex exponential that depends quadratically with time is proportional to a complex eponential that depends quadratically with angular frequency. I know that this is in fact the case when a exponential with a REAL quadratic argument (i.e. a scaled version of the Normal distribution) is considered: \begin{equation} \mathcal{F}\{e^{-t^{2}/(2\alpha)} \} \propto  e^{-\sigma\omega^{2}/2} \end{equation} However, I don't see an easy way to extend that result to the case when the imaginary unit is included in the argument of the exponential. Any comments would be very much appreciated, thanks!",,"['complex-analysis', 'fourier-analysis', 'normal-distribution']"
5,Laurent series expansion of 1/sin(z) - why is everything before residue 0?,Laurent series expansion of 1/sin(z) - why is everything before residue 0?,,"I seem to have taken some bad lecture notes about this... I have written (about $z = 0$ ) $$\frac{1}{\sin(z)} = \ldots +\frac{a_{-3}}{z^3}+\frac{a_{-1}}{z^{-1}}+{a_{1}}{z^1}+{a_{3}}{z^3}+\ldots   $$ Mentioned $\sin(z)$ being an odd function, and everything including and before the term $a_{-3}$ is $0$ . I don't understand that bit. Also, why isn't $a_{-1}=0$ as well? The next part is to evaluate $$\oint_{|z| = \frac{\pi}{2}} \frac{1}{\sin(z)}\ dz$$ Thanks","I seem to have taken some bad lecture notes about this... I have written (about ) Mentioned being an odd function, and everything including and before the term is . I don't understand that bit. Also, why isn't as well? The next part is to evaluate Thanks",z = 0 \frac{1}{\sin(z)} = \ldots +\frac{a_{-3}}{z^3}+\frac{a_{-1}}{z^{-1}}+{a_{1}}{z^1}+{a_{3}}{z^3}+\ldots    \sin(z) a_{-3} 0 a_{-1}=0 \oint_{|z| = \frac{\pi}{2}} \frac{1}{\sin(z)}\ dz,['complex-analysis']
6,Contour integral of $\sqrt{z^2-1}$ on $|z| = 2$,Contour integral of  on,\sqrt{z^2-1} |z| = 2,"I've been wrestling with this problem (available here ): Evaluate the integral of $f(z) = \sqrt{z^2-1}$ around the circle $\{z: |z| = 2\}$, where the branch of the square root function is chosen so that $\sqrt{2^2-1} > 0$. I came up with the answer $$\int\limits_{|z| = 2} \sqrt{z^2-1} dz = \pi i$$ using the following argument, which seems a little like voodoo to me. You notice that there are two points, at $z \pm 1$, where you might have to pick a branch of $log()$ to define the square root. Then, I convinced myself that as long as you exclude from your domain the real interval $-1 \le x \le 1$, the function $f(z)$ can be continuously defined (maybe the two branches somehow cancel?), and so is analytic on its domain. Therefore you can shrink the contour of integration continuously using the Cauchy Closed Curve Integral Theorem, so that you wind up reducing it to the real integral $$2\int_{-1}^1 \sqrt{x^2-1} dx = \pi i$$ I'm not really sure the answer is correct, and I'm even less certain about the way I got it. I had a hard time convincing myself that $\sqrt{z^2-1}$ was not multi-valued on the domain. To try to get at that I tried $\sqrt{z^2-1} = \sqrt{z+1} \sqrt{z-1}$ and reasoned that the product makes the discontinuity disappear, using $$e^{\frac{\pi}{2}i}\cdot e^{\frac{\pi}{2}i} = -1 = e^{-\frac{\pi}{2}i}\cdot e^{-\frac{\pi}{2}i} $$ for the different branches of $log()$ you can choose. I'd appreciate any input that would help me get a a better way to look at this. Thanks! EDIT An attempt to use the Residue at infinity: By substituting $z = 1/w$ you get \begin{eqnarray} \int\limits_{|z| = 2} \sqrt{z^2-1} dz &=& \int\limits_{|w| = 1/2} \frac{1}{w^2}\sqrt{\frac{1}{w^2}-1} dw \\ &=& \int\limits_{|w| = 1/2} \frac{1}{w^2}\sqrt{\frac{1-w^2}{w^2}} dw \\ &=& \int\limits_{|w| = 1/2} \frac{1}{w^3}\sqrt{1-w^2} dw \end{eqnarray} The integrand is analytic in $|w| \le 1/2$ except at $w = 0$, so we can apply the Residue Theorem. Near $w = 0$, $\sqrt{1-w^2} = 1 - \frac{1}{2}w^2 + \dots$, so the residue of $\frac{1}{w^3}\sqrt{1-w^2} $ at $w = 0$ is $-\frac{1}{2}$. Then the integral is $$\int\limits_{|z| = 2} \sqrt{z^2-1} dz = 2\pi i \cdot (-1/2) = -\pi i$$","I've been wrestling with this problem (available here ): Evaluate the integral of $f(z) = \sqrt{z^2-1}$ around the circle $\{z: |z| = 2\}$, where the branch of the square root function is chosen so that $\sqrt{2^2-1} > 0$. I came up with the answer $$\int\limits_{|z| = 2} \sqrt{z^2-1} dz = \pi i$$ using the following argument, which seems a little like voodoo to me. You notice that there are two points, at $z \pm 1$, where you might have to pick a branch of $log()$ to define the square root. Then, I convinced myself that as long as you exclude from your domain the real interval $-1 \le x \le 1$, the function $f(z)$ can be continuously defined (maybe the two branches somehow cancel?), and so is analytic on its domain. Therefore you can shrink the contour of integration continuously using the Cauchy Closed Curve Integral Theorem, so that you wind up reducing it to the real integral $$2\int_{-1}^1 \sqrt{x^2-1} dx = \pi i$$ I'm not really sure the answer is correct, and I'm even less certain about the way I got it. I had a hard time convincing myself that $\sqrt{z^2-1}$ was not multi-valued on the domain. To try to get at that I tried $\sqrt{z^2-1} = \sqrt{z+1} \sqrt{z-1}$ and reasoned that the product makes the discontinuity disappear, using $$e^{\frac{\pi}{2}i}\cdot e^{\frac{\pi}{2}i} = -1 = e^{-\frac{\pi}{2}i}\cdot e^{-\frac{\pi}{2}i} $$ for the different branches of $log()$ you can choose. I'd appreciate any input that would help me get a a better way to look at this. Thanks! EDIT An attempt to use the Residue at infinity: By substituting $z = 1/w$ you get \begin{eqnarray} \int\limits_{|z| = 2} \sqrt{z^2-1} dz &=& \int\limits_{|w| = 1/2} \frac{1}{w^2}\sqrt{\frac{1}{w^2}-1} dw \\ &=& \int\limits_{|w| = 1/2} \frac{1}{w^2}\sqrt{\frac{1-w^2}{w^2}} dw \\ &=& \int\limits_{|w| = 1/2} \frac{1}{w^3}\sqrt{1-w^2} dw \end{eqnarray} The integrand is analytic in $|w| \le 1/2$ except at $w = 0$, so we can apply the Residue Theorem. Near $w = 0$, $\sqrt{1-w^2} = 1 - \frac{1}{2}w^2 + \dots$, so the residue of $\frac{1}{w^3}\sqrt{1-w^2} $ at $w = 0$ is $-\frac{1}{2}$. Then the integral is $$\int\limits_{|z| = 2} \sqrt{z^2-1} dz = 2\pi i \cdot (-1/2) = -\pi i$$",,"['complex-analysis', 'contour-integration', 'branch-cuts']"
7,When Cauchy integral and when Cauchy residue..?,When Cauchy integral and when Cauchy residue..?,,$\int_C\tan(z)dz$ where $C$ is the circle $\vert z\vert=2$ What should be applied to evaluate the following solution? Is it Cauchy integral or residue?,$\int_C\tan(z)dz$ where $C$ is the circle $\vert z\vert=2$ What should be applied to evaluate the following solution? Is it Cauchy integral or residue?,,"['complex-analysis', 'contour-integration']"
8,Evaluate: $\int_{0}^{2\pi} e^{\cos \theta } \cos(\theta + \sin\theta) d\theta $,Evaluate:,\int_{0}^{2\pi} e^{\cos \theta } \cos(\theta + \sin\theta) d\theta ,Show that the following integral is equal to zero by evaluating $\oint_c e^{z} dz = 0$ $$\int_{0}^{2\pi} e^{\cos \theta } \cos(\theta + \sin\theta) d\theta = \int_{0}^{2\pi} e^{\cos \theta } \sin(\theta + \sin\theta) d\theta = 0$$ I think this is equivalent to showing $\oint_c e^{z + i \arg (z)} dz = 0$ but I don't know how :((,Show that the following integral is equal to zero by evaluating $\oint_c e^{z} dz = 0$ $$\int_{0}^{2\pi} e^{\cos \theta } \cos(\theta + \sin\theta) d\theta = \int_{0}^{2\pi} e^{\cos \theta } \sin(\theta + \sin\theta) d\theta = 0$$ I think this is equivalent to showing $\oint_c e^{z + i \arg (z)} dz = 0$ but I don't know how :((,,"['complex-analysis', 'contour-integration']"
9,Taylor series expansion of $\log[z]$ about $z=1$ (different branches),Taylor series expansion of  about  (different branches),\log[z] z=1,"I realize this is not the fastest way of getting a Taylor's series expansion of $f(z)=\log(z)$ about $z=1$. But here goes. I am assuming I am working on the principal branch of the logarithm ($-\pi<\theta<\pi$). I am assuming that $f(1)=\log(1)=0$. That's the branch I am on. Next, some derivatives: $f'(z)=1/z$ $f''(z)=-1/z^2$ $f'''(z)=2/z^3$ $f^{(4)}(z)=-6/z^4$ ... $f^{(n)}(z)=(-1)^{n+1}(n-1)!/z^n$ Hence, $$f(z)=\sum_{n=1}^{\infty}c_n(z-1)^n,$$ where $$c_n=\frac{f^{(n)}(1)}{n!}=\frac{(-1)^{n+1}(n-1)!}{n!(1)^n}=\frac{(-1)^{n+1}}{n}.$$ Thus: $$f(z)=(z-1)-\frac{(z-1)^2}{2}+\frac{(z-1)^3}{3}-\frac{(z-1)^4}{4}+\frac{(z-1)^5}{5}-\cdots$$ And checking, $f(1)=0$, which is my assumption above. Question: Now, suppose I start the problem again, only this time I assume I am a different branch of the logarithm. Let's assume that this time we are working on the branch $\pi<\theta<3\pi$, so that $f(1)=\log(1)=2\pi i$. If I repeat the calculations above, what would they now look like, and what would be the answer for my series?","I realize this is not the fastest way of getting a Taylor's series expansion of $f(z)=\log(z)$ about $z=1$. But here goes. I am assuming I am working on the principal branch of the logarithm ($-\pi<\theta<\pi$). I am assuming that $f(1)=\log(1)=0$. That's the branch I am on. Next, some derivatives: $f'(z)=1/z$ $f''(z)=-1/z^2$ $f'''(z)=2/z^3$ $f^{(4)}(z)=-6/z^4$ ... $f^{(n)}(z)=(-1)^{n+1}(n-1)!/z^n$ Hence, $$f(z)=\sum_{n=1}^{\infty}c_n(z-1)^n,$$ where $$c_n=\frac{f^{(n)}(1)}{n!}=\frac{(-1)^{n+1}(n-1)!}{n!(1)^n}=\frac{(-1)^{n+1}}{n}.$$ Thus: $$f(z)=(z-1)-\frac{(z-1)^2}{2}+\frac{(z-1)^3}{3}-\frac{(z-1)^4}{4}+\frac{(z-1)^5}{5}-\cdots$$ And checking, $f(1)=0$, which is my assumption above. Question: Now, suppose I start the problem again, only this time I assume I am a different branch of the logarithm. Let's assume that this time we are working on the branch $\pi<\theta<3\pi$, so that $f(1)=\log(1)=2\pi i$. If I repeat the calculations above, what would they now look like, and what would be the answer for my series?",,['complex-analysis']
10,"Integrating a function with 3 branch points: $\int_{C} z^{a-1} (z+z^{-1})^{b} \, \mathrm dz $",Integrating a function with 3 branch points:,"\int_{C} z^{a-1} (z+z^{-1})^{b} \, \mathrm dz ","I came across an exercise in a textbook that says to evaluate $$ \int_{\frac{-\pi}{2}}^{\frac{\pi}{2}} \cos (ax) \cos^{b} (x) \, dx  \, , \quad a > b > -1,$$ by integrating $f(z) = z^{a-1} (z+z^{-1})^{b}$ around a contour that consists of the line segment joining the points $i$ and $-i$ , along with the right half of the unit circle. It also says that the contour should be indented at the points $0, i$ , and $-i$ . But where should the branch cuts be placed?  Can we just use the principal branch of the logarithm?","I came across an exercise in a textbook that says to evaluate by integrating around a contour that consists of the line segment joining the points and , along with the right half of the unit circle. It also says that the contour should be indented at the points , and . But where should the branch cuts be placed?  Can we just use the principal branch of the logarithm?"," \int_{\frac{-\pi}{2}}^{\frac{\pi}{2}} \cos (ax) \cos^{b} (x) \, dx  \, , \quad a > b > -1, f(z) = z^{a-1} (z+z^{-1})^{b} i -i 0, i -i","['complex-analysis', 'contour-integration']"
11,"Entire function. Prove that $f(\bar{z})=\overline{f(z)}, \forall z\in C$",Entire function. Prove that,"f(\bar{z})=\overline{f(z)}, \forall z\in C","Let $f$ a entire function: $f(R)\subset R.\;$ Prove that $f(\bar{z})=\overline{f(z)}, \forall z\in C$","Let $f$ a entire function: $f(R)\subset R.\;$ Prove that $f(\bar{z})=\overline{f(z)}, \forall z\in C$",,['complex-analysis']
12,Must a meromorphic function on a compact set have same number of zeros and poles?,Must a meromorphic function on a compact set have same number of zeros and poles?,,Let $f:X\rightarrow\mathbb{C}\cup\{\infty\}$ be a meromorphic function while $X$ is compact. Must $f$ have same number of zeros and poles?,Let $f:X\rightarrow\mathbb{C}\cup\{\infty\}$ be a meromorphic function while $X$ is compact. Must $f$ have same number of zeros and poles?,,"['complex-analysis', 'meromorphic-functions']"
13,Proof for constant function without Picard's little theorem,Proof for constant function without Picard's little theorem,,I need to prove without using Picard's Little Theorem the following statement: Let $f(z)$ an entire function such that $f(z) \notin \mathbb R$  for every $z \in \mathbb C$. Prove that $f$ is constant. Do you have a way to do it? Thanks,I need to prove without using Picard's Little Theorem the following statement: Let $f(z)$ an entire function such that $f(z) \notin \mathbb R$  for every $z \in \mathbb C$. Prove that $f$ is constant. Do you have a way to do it? Thanks,,['complex-analysis']
14,How many roots of a polynomial have positive real part?,How many roots of a polynomial have positive real part?,,"I am given an exercise with three polynomials, and we have to find the number of roots of the first one that lie in the unit disk, the number of roots that lie in some region, e.g. those that lie in unit disk, or have $1<|root|<2$, etc. I succeeded with the first two, by Rouché's theorem (in short: if |f|>|g| on boundary of D, then f and f+g have same number of roots in D.). But now, the function in question is $z^4+8z^3+3z^2+8z+3$, and I shall find # of those roots that have positive real part. But I cannot find a way to divide the half-plane into appropriate regions, and then the function into a sum of appropriate functions to make this work. Does anybody have an idea?","I am given an exercise with three polynomials, and we have to find the number of roots of the first one that lie in the unit disk, the number of roots that lie in some region, e.g. those that lie in unit disk, or have $1<|root|<2$, etc. I succeeded with the first two, by Rouché's theorem (in short: if |f|>|g| on boundary of D, then f and f+g have same number of roots in D.). But now, the function in question is $z^4+8z^3+3z^2+8z+3$, and I shall find # of those roots that have positive real part. But I cannot find a way to divide the half-plane into appropriate regions, and then the function into a sum of appropriate functions to make this work. Does anybody have an idea?",,"['complex-analysis', 'polynomials', 'roots']"
15,Möbius transformations and concentric circles,Möbius transformations and concentric circles,,"Given a Möbius transformation that maps one pair of concentric circles to another pair of concentric circles, why is the ratio of the radii preserved through the map? I thought about how Möbius transformations are compositions of rotations, scaling, inversion, and translation, and that intuitively, these types of maps shouldn't change the ratio of radii between two circles. Would it be correct to just say that if $\frac{r_1}{r_2}$ is the ratio of radii between the two circles, then 1) The radii are invariant under translation, $z \mapsto z+a$, so $\frac{r_1}{r_2}$ stays the same 2) Under scaling by a factor $z \mapsto az$, $\frac{ar_1}{ar_2} = \frac{r_1}{r_2}$ 3) Under inversion, $z \mapsto \frac{1}{z}$, $\frac{1/r_1}{1/r_2} = \frac{r_2}{r_1}$ Or is there a different/better way to think about this problem?","Given a Möbius transformation that maps one pair of concentric circles to another pair of concentric circles, why is the ratio of the radii preserved through the map? I thought about how Möbius transformations are compositions of rotations, scaling, inversion, and translation, and that intuitively, these types of maps shouldn't change the ratio of radii between two circles. Would it be correct to just say that if $\frac{r_1}{r_2}$ is the ratio of radii between the two circles, then 1) The radii are invariant under translation, $z \mapsto z+a$, so $\frac{r_1}{r_2}$ stays the same 2) Under scaling by a factor $z \mapsto az$, $\frac{ar_1}{ar_2} = \frac{r_1}{r_2}$ 3) Under inversion, $z \mapsto \frac{1}{z}$, $\frac{1/r_1}{1/r_2} = \frac{r_2}{r_1}$ Or is there a different/better way to think about this problem?",,['complex-analysis']
16,Continuity of Rational Functions on the Riemann Sphere $\hat{\mathbb{C}}$,Continuity of Rational Functions on the Riemann Sphere,\hat{\mathbb{C}},"Let $\hat{\mathbb{C}} = \mathbb{C} \cup \{ \infty \}$ denote the Riemann Sphere . While reading the wikipedia article about it I found a passage that said that every rational function on the complex plane can be extended to a continuous function on the Riemann Sphere . The particular construction is as follows, let $R(z) = \frac{f(z)}{g(z)} \in \mathbb{C}(z)$ be a rational function. Lets assume for simplicity that $f(z)$ and $g(z)$ share no common factor. Then for any point $a \in \mathbb{C}$ such that $g(a) = 0$ but $f(a) \neq 0$ we define $R(a) = \infty$. Also we define $R(\infty) := \lim_{z \to \infty} R(z)$. So to quote wikipedia, with this definitions $R(z)$ becomes a continuous function from the Riemann Sphere to itself. The problem for me is that the article doesn't add any details as to how one may go about showing that in fact $R(z)$ is continuous. So my question is exactly that, to make it simple, if I have for instance $R(z) = \frac{z-1}{z+1}$ or even $R(z) = \frac{1}{z}$, how do I show that it is a continuous function on $\hat{\mathbb{C}}$? I think I can build up from an easy example such as this (assumming this is easy). Also, I'm a little bit confused about how to interpret this continuity, how should I see the continuity on the Riemann Sphere?, does it involve an argument with stereographic projection? I added in the Riemann Surface tag just in case they are involved, which I'm not sure. Thank you very much in advance.","Let $\hat{\mathbb{C}} = \mathbb{C} \cup \{ \infty \}$ denote the Riemann Sphere . While reading the wikipedia article about it I found a passage that said that every rational function on the complex plane can be extended to a continuous function on the Riemann Sphere . The particular construction is as follows, let $R(z) = \frac{f(z)}{g(z)} \in \mathbb{C}(z)$ be a rational function. Lets assume for simplicity that $f(z)$ and $g(z)$ share no common factor. Then for any point $a \in \mathbb{C}$ such that $g(a) = 0$ but $f(a) \neq 0$ we define $R(a) = \infty$. Also we define $R(\infty) := \lim_{z \to \infty} R(z)$. So to quote wikipedia, with this definitions $R(z)$ becomes a continuous function from the Riemann Sphere to itself. The problem for me is that the article doesn't add any details as to how one may go about showing that in fact $R(z)$ is continuous. So my question is exactly that, to make it simple, if I have for instance $R(z) = \frac{z-1}{z+1}$ or even $R(z) = \frac{1}{z}$, how do I show that it is a continuous function on $\hat{\mathbb{C}}$? I think I can build up from an easy example such as this (assumming this is easy). Also, I'm a little bit confused about how to interpret this continuity, how should I see the continuity on the Riemann Sphere?, does it involve an argument with stereographic projection? I added in the Riemann Surface tag just in case they are involved, which I'm not sure. Thank you very much in advance.",,"['complex-analysis', 'riemann-surfaces']"
17,Express Integer as Product Complex Number,Express Integer as Product Complex Number,,"Given positive integer $n$ . Find all integers can be expressed as $$S=\left (\sum_{k=1}^nz_k\right )\left (\sum_{k=1}^n \frac{1}{z_k}\right )$$ for some complex number $z_1,\cdots,z_n$ and $|z_1|=\cdots|z_n|=1$ . Here is my approach. For $n=1$ it's trivial. For $n\ge 2$ , let $z_k=e^{it_k}$ where $0<t_k\le 2\pi$ . I have prove that $0\le S\le n^2$ and $$S = \left (\sum_{k=1}^n \cos(t_k)\right )^2 + \left (\sum_{k=1}^n \sin(t_k)\right )^2.$$ I have found that for perfect square numbers. For example, if $n=2k$ for $k$ positive integer: $t_1=t_2=\cdots=t_n=0\implies S=4k^2.$ $t_1=t_2=\cdots=t_x=0$ and $t_{x+1}=\cdots=t_{2k}=\pi$ $\implies S=0$ . $t_1=t_2=\cdots=t_x=0$ and $t_{x+1}=\cdots=t_{2k}=\pi$ $\implies S=(2k-2x)^2$ . $t_1=t_2=\cdots=t_{2x}=0$ and $$\left (t_{2x+1},t_{2x+2},t_{2x+3},t_{2x+4},\cdots,t_{2k-1},t_{2k}\right )=\left (\frac{\pi}{2},-\frac{\pi}{2},\frac{\pi}{2},-\frac{\pi}{2},\cdots, \frac{\pi}{2},-\frac{\pi}{2}\right ),$$ we have $S=(2x-1)^2$ . For the rest number I don't have any clue to make construction.","Given positive integer . Find all integers can be expressed as for some complex number and . Here is my approach. For it's trivial. For , let where . I have prove that and I have found that for perfect square numbers. For example, if for positive integer: and . and . and we have . For the rest number I don't have any clue to make construction.","n S=\left (\sum_{k=1}^nz_k\right )\left (\sum_{k=1}^n \frac{1}{z_k}\right ) z_1,\cdots,z_n |z_1|=\cdots|z_n|=1 n=1 n\ge 2 z_k=e^{it_k} 0<t_k\le 2\pi 0\le S\le n^2 S = \left (\sum_{k=1}^n \cos(t_k)\right )^2 + \left (\sum_{k=1}^n \sin(t_k)\right )^2. n=2k k t_1=t_2=\cdots=t_n=0\implies S=4k^2. t_1=t_2=\cdots=t_x=0 t_{x+1}=\cdots=t_{2k}=\pi \implies S=0 t_1=t_2=\cdots=t_x=0 t_{x+1}=\cdots=t_{2k}=\pi \implies S=(2k-2x)^2 t_1=t_2=\cdots=t_{2x}=0 \left (t_{2x+1},t_{2x+2},t_{2x+3},t_{2x+4},\cdots,t_{2k-1},t_{2k}\right )=\left (\frac{\pi}{2},-\frac{\pi}{2},\frac{\pi}{2},-\frac{\pi}{2},\cdots, \frac{\pi}{2},-\frac{\pi}{2}\right ), S=(2x-1)^2","['complex-analysis', 'complex-numbers']"
18,If a holomorphic function $f$ from the open ball to the complex numbers have bounded derivative then $|\frac{f^{n}(0)}{n!}|\leq e$,If a holomorphic function  from the open ball to the complex numbers have bounded derivative then,f |\frac{f^{n}(0)}{n!}|\leq e,"The problem is the following. Let $B_1(0)=\lbrace z\in \mathbb{C}: |z|<1\rbrace$ and consider a holomorphic function $f:B_1(0)\to \mathbb{C}$ such that $|f^{\prime}(z)|\leq \frac{1}{1-|z|}$ for all $z\in B_1(0)$ . Show that $$|\frac{f^{n}(0)}{n!}|\leq e$$ where $f^n(0)$ denote the $n$ -th derivative of $f$ evaluated in $0$ . I already take arround four hours and don not get a good idea. Attempt . First of all I try join the information about each coefficient of the taylor series of $f$ . Since $B_1(0)$ is convex then it is simply connected and since $f$ is holomorphic we have by Cauchy integral Formula that for each $0<r<1$ and closed curve $\gamma:[0,2\pi]\to B_1(0)$ given by $\gamma(t)=re^{2\pi it}$ $$f^n(0)I(\gamma,0)=\frac{1}{2\pi i}\int_{\gamma}\frac{f(z)}{z^{n}}dz$$ and thus $$\left|\frac{f^{n}(0)}{n!}\right|\leq \frac{\operatorname{sup}_{z\in \gamma}|f(z)|}{r^{n}}$$ And this is all the information that I get from this. For other side, the bound in the derivative of $f$ tell me that for $z=0$ we have that $|f^{\prime}(0)|\leq 1$ . This lead me the possible intuition that I can also bound the other coefficients by $1$ . This is all the things that I have in mind, but I look myself too far of the solution. Any idea or hint is welcome. Update From the hints given in the comments. Let $g:B_1(0)\to \mathbb{C}$ given by $g(z)=f^{\prime}(z)$ and notice that since $f$ is holomorphic in a simply connected set, then all their derivatives exists and also are holomorphic in $B_1(0)$ . Thus we can also apply the Cauchy Integral formula to $g$ in the point $z_0=0$ to conclude that for each $n\in \mathbb{N}$ and closed curve $\gamma_n:[0,2\pi]\to \mathbb{C}$ given by $\gamma(t)=r_ne^{2\pi it}$ . we have $$\left| \frac{g^{n}(0)}{n!}\right|\leq \frac{1}{2\pi}\cdot |g(z)|\cdot 2\pi=\frac{\frac{1}{1-r_n}}{r_{n}^{n}}$$ And since $g=f^{\prime}$ we get $g^{n}(0)=f^{n+1}(0)$ . Moreover, since $|g(z)|\leq \frac{1}{1-|z|}$ for all $z\in B_1(0)$ we conclude $$ \left| \frac{f^{n+1}(0)}{n!}\right|\leq \frac{\frac{1}{1-r_n}}{r_{n}^{n}} $$ and if we multiply by $(n+1)^{-1}$ both sides, then $$ \left| \frac{f^{n+1}(0)}{(n+1)!}\right|\leq \frac{\frac{1}{1-r_n}}{r_{n}^{n}(n+1)}$$ for each $n\in \mathbb{N}$ Finally, is sufficient choose a correct sequence of radius. For this we  can choose for each $n\in \mathbb{N}$ the closed curve $\gamma_n:[0,2\pi]\to \mathbb{C}$ given by $\gamma(t)=(1-\frac{1}{n+1})e^{2\pi i t}$ for which we have $$\left| \frac{f^{n+1}(0)}{(n+1)!}\right|\leq \frac{1}{(1-\frac{1}{n+1})^{n}}$$ and taking $n\to \infty$ we have $$\left| \frac{f^{n+1}(0)}{(n+1)!}\right|\leq e$$ as desired. Thanks in advance to the community for their brilliant suggestions.","The problem is the following. Let and consider a holomorphic function such that for all . Show that where denote the -th derivative of evaluated in . I already take arround four hours and don not get a good idea. Attempt . First of all I try join the information about each coefficient of the taylor series of . Since is convex then it is simply connected and since is holomorphic we have by Cauchy integral Formula that for each and closed curve given by and thus And this is all the information that I get from this. For other side, the bound in the derivative of tell me that for we have that . This lead me the possible intuition that I can also bound the other coefficients by . This is all the things that I have in mind, but I look myself too far of the solution. Any idea or hint is welcome. Update From the hints given in the comments. Let given by and notice that since is holomorphic in a simply connected set, then all their derivatives exists and also are holomorphic in . Thus we can also apply the Cauchy Integral formula to in the point to conclude that for each and closed curve given by . we have And since we get . Moreover, since for all we conclude and if we multiply by both sides, then for each Finally, is sufficient choose a correct sequence of radius. For this we  can choose for each the closed curve given by for which we have and taking we have as desired. Thanks in advance to the community for their brilliant suggestions.","B_1(0)=\lbrace z\in \mathbb{C}: |z|<1\rbrace f:B_1(0)\to \mathbb{C} |f^{\prime}(z)|\leq \frac{1}{1-|z|} z\in B_1(0) |\frac{f^{n}(0)}{n!}|\leq e f^n(0) n f 0 f B_1(0) f 0<r<1 \gamma:[0,2\pi]\to B_1(0) \gamma(t)=re^{2\pi it} f^n(0)I(\gamma,0)=\frac{1}{2\pi i}\int_{\gamma}\frac{f(z)}{z^{n}}dz \left|\frac{f^{n}(0)}{n!}\right|\leq \frac{\operatorname{sup}_{z\in \gamma}|f(z)|}{r^{n}} f z=0 |f^{\prime}(0)|\leq 1 1 g:B_1(0)\to \mathbb{C} g(z)=f^{\prime}(z) f B_1(0) g z_0=0 n\in \mathbb{N} \gamma_n:[0,2\pi]\to \mathbb{C} \gamma(t)=r_ne^{2\pi it} \left| \frac{g^{n}(0)}{n!}\right|\leq \frac{1}{2\pi}\cdot |g(z)|\cdot 2\pi=\frac{\frac{1}{1-r_n}}{r_{n}^{n}} g=f^{\prime} g^{n}(0)=f^{n+1}(0) |g(z)|\leq \frac{1}{1-|z|} z\in B_1(0)  \left| \frac{f^{n+1}(0)}{n!}\right|\leq \frac{\frac{1}{1-r_n}}{r_{n}^{n}}  (n+1)^{-1}  \left| \frac{f^{n+1}(0)}{(n+1)!}\right|\leq \frac{\frac{1}{1-r_n}}{r_{n}^{n}(n+1)} n\in \mathbb{N} n\in \mathbb{N} \gamma_n:[0,2\pi]\to \mathbb{C} \gamma(t)=(1-\frac{1}{n+1})e^{2\pi i t} \left| \frac{f^{n+1}(0)}{(n+1)!}\right|\leq \frac{1}{(1-\frac{1}{n+1})^{n}} n\to \infty \left| \frac{f^{n+1}(0)}{(n+1)!}\right|\leq e","['complex-analysis', 'complex-numbers', 'complex-integration']"
19,Contour integral of $\frac{|x|^{\frac{1}{2}}}{(x-4i)(x+2i)}$,Contour integral of,\frac{|x|^{\frac{1}{2}}}{(x-4i)(x+2i)},"I am trying to solve the following integral: $$ \int_{-\infty}^{\infty}\frac{|x|^{\frac{1}{2}}}{(x-4i)(x+2i)}\,\mathrm dx. $$ There are poles at $4i$ , $-2i$ , and a semi-circle in upper half plane contour of radius $R$ will enclose $4i$ . However, the function is non-analytic in $x=0$ , so I assumed I needed to evade this point with my contour, by using a small semi-circle of radius r around $x=0$ in the upper half plane. Residue theorem then gives us: $$ I+I_r+I_R = 2\pi i \operatorname{Res}\left(4i,\frac{|x|^{\frac{1}{2}}}{(x-4i)(x+2i)}\right). $$ When taking the limit $R\rightarrow \infty$ , $I_R \rightarrow 0$ , and $I$ becomes the integral of interest. I am unsure if $I_r\rightarrow 0$ when $r\rightarrow 0$ , but I assumed this was the case. Calculating the residue gave me the result $-\frac{i}{3}$ , giving me the final result: $$ I = \int_{-\infty}^{\infty}\frac{|x|^{\frac{1}{2}}}{(x-4i)(x+2i)} dx = \frac{2\pi}{3}. $$ According to online calculators, this result is wrong, and would like any suggestions as to how this integral can be solved. Thanks in advance!","I am trying to solve the following integral: There are poles at , , and a semi-circle in upper half plane contour of radius will enclose . However, the function is non-analytic in , so I assumed I needed to evade this point with my contour, by using a small semi-circle of radius r around in the upper half plane. Residue theorem then gives us: When taking the limit , , and becomes the integral of interest. I am unsure if when , but I assumed this was the case. Calculating the residue gave me the result , giving me the final result: According to online calculators, this result is wrong, and would like any suggestions as to how this integral can be solved. Thanks in advance!","
\int_{-\infty}^{\infty}\frac{|x|^{\frac{1}{2}}}{(x-4i)(x+2i)}\,\mathrm dx.
 4i -2i R 4i x=0 x=0 
I+I_r+I_R = 2\pi i \operatorname{Res}\left(4i,\frac{|x|^{\frac{1}{2}}}{(x-4i)(x+2i)}\right).
 R\rightarrow \infty I_R \rightarrow 0 I I_r\rightarrow 0 r\rightarrow 0 -\frac{i}{3} 
I = \int_{-\infty}^{\infty}\frac{|x|^{\frac{1}{2}}}{(x-4i)(x+2i)} dx = \frac{2\pi}{3}.
","['complex-analysis', 'definite-integrals', 'contour-integration', 'residue-calculus']"
20,Show $2^{n-1} (z^n+1)-(z+1)^n=0$ for $n \geq 2$ implies $|z|=1$.,Show  for  implies .,2^{n-1} (z^n+1)-(z+1)^n=0 n \geq 2 |z|=1,"I've been trying to prove the following question: For $n \geq 2$ , if $z \in \mathbb{C}$ solves $2^{n-1} (z^n+1)-(z+1)^n=0$ , then $|z|=1$ . I rewrite the equation as $\frac{z^n+1}{2}=\left(\frac{z+1}{2}\right)^n$ . I don't know how to proceed from here. Any help would be appreciated! Thanks!","I've been trying to prove the following question: For , if solves , then . I rewrite the equation as . I don't know how to proceed from here. Any help would be appreciated! Thanks!",n \geq 2 z \in \mathbb{C} 2^{n-1} (z^n+1)-(z+1)^n=0 |z|=1 \frac{z^n+1}{2}=\left(\frac{z+1}{2}\right)^n,"['complex-analysis', 'complex-numbers']"
21,Using the Residue Theorem to Prove that $\int^{2\pi}_{0} \frac{1}{(a+\cos\theta)^{2}} d \theta=\frac{2\pi a}{(a^{2}-1)^{3/{2}}}.$,Using the Residue Theorem to Prove that,\int^{2\pi}_{0} \frac{1}{(a+\cos\theta)^{2}} d \theta=\frac{2\pi a}{(a^{2}-1)^{3/{2}}}.,"How do you evaluate the following integral? Here we take $a>1$ . $$\int^{2\pi}_{0} \frac{1}{(a+\cos\theta)^{2}} d \theta=\frac{2\pi a}{(a^{2}-1)^{\frac{3}{2}}}.$$ I know I have to use the Residue Theorem, however, I am stuck on which contour to use, and also how to find the pole of the function. Any hints are greatly appreciated.","How do you evaluate the following integral? Here we take . I know I have to use the Residue Theorem, however, I am stuck on which contour to use, and also how to find the pole of the function. Any hints are greatly appreciated.",a>1 \int^{2\pi}_{0} \frac{1}{(a+\cos\theta)^{2}} d \theta=\frac{2\pi a}{(a^{2}-1)^{\frac{3}{2}}}.,"['complex-analysis', 'residue-calculus']"
22,Question on evaluating $\int_{C}\frac{e^{iz}}{z(z-\pi)}dz$ without the residue theorem,Question on evaluating  without the residue theorem,\int_{C}\frac{e^{iz}}{z(z-\pi)}dz,"I am trying to figure out how to evaluate the integral $\int_{C}\frac{e^{iz}}{z(z-\pi)}dz$ where $C$ is any circle centered at the origin with radius greater than $\pi$.  I can see that $\frac{e^{iz}}{z(z-\pi)}$ is analytic everywhere except where $z=0$ and $z=\pi$, both of which are in the region bounded by $C$. I can also see that by using the Taylor expansion of $e^{iz}$ that $$\int_{C}\frac{e^{iz}}{z(z-\pi)}dz = \sum_{n=0}^{\infty}\frac{i^{n}}{n!}\int_{C}\frac{z^{n-1}}{z-\pi}dz$$ I'm supposed to apply Cauchy's Theorem or Cauchy's Integral Theorem to evaluate the integral along this curve but I am not sure how to do so.  I do not yet have the residue theorem in my tool box.","I am trying to figure out how to evaluate the integral $\int_{C}\frac{e^{iz}}{z(z-\pi)}dz$ where $C$ is any circle centered at the origin with radius greater than $\pi$.  I can see that $\frac{e^{iz}}{z(z-\pi)}$ is analytic everywhere except where $z=0$ and $z=\pi$, both of which are in the region bounded by $C$. I can also see that by using the Taylor expansion of $e^{iz}$ that $$\int_{C}\frac{e^{iz}}{z(z-\pi)}dz = \sum_{n=0}^{\infty}\frac{i^{n}}{n!}\int_{C}\frac{z^{n-1}}{z-\pi}dz$$ I'm supposed to apply Cauchy's Theorem or Cauchy's Integral Theorem to evaluate the integral along this curve but I am not sure how to do so.  I do not yet have the residue theorem in my tool box.",,"['complex-analysis', 'complex-integration', 'cauchy-integral-formula']"
23,What is the radius of convergence of the hypergeometric series?,What is the radius of convergence of the hypergeometric series?,,"Find the radius of convergence of    $$F(\alpha,\beta,\gamma,z)=1+\sum_\limits{n=1}^\infty\frac{\alpha(\alpha+1)\cdots(\alpha+n-1)\beta(\beta+1)\cdots(\beta+n-1)}{n!\gamma(\gamma+1)\cdots(\gamma+n-1)}z^n$$   Here $\alpha,\beta\in\mathbb{C}$ and $\gamma \neq 0,-1,-2,\cdots$. I set  $$c_n=\frac{\alpha(\alpha+1)\cdots(\alpha+n-1)\beta(\beta+1)\cdots(\beta+n-1)}{\gamma(\gamma+1)\cdots(\gamma+n-1)},\qquad a_n=\frac{c_n}{n!}$$ and  $$\color{red}{c_n\sim\left(\frac{\alpha\,\beta}{\gamma}\right)^n}, \qquad n\to\infty$$ Thus, the radius of convergence $R$ can be found using Cauchy-Hadamard's formula $$R=\frac{1}{\lim\sup|a_n|^{1/n}}=\left|\frac{\gamma}{\alpha\,\beta}\right|\cdot\lim_\limits{n\to\infty}\sqrt[n]{|n!|}=\left|\frac{\gamma}{\alpha\,\beta}\right|\cdot\infty=\infty.$$ This would conclude that $F(\alpha,\beta,\gamma,z)$ is an entire function, but I do not know if these steps are correct. I realized that the part in red is not true. What would be a better approximation?","Find the radius of convergence of    $$F(\alpha,\beta,\gamma,z)=1+\sum_\limits{n=1}^\infty\frac{\alpha(\alpha+1)\cdots(\alpha+n-1)\beta(\beta+1)\cdots(\beta+n-1)}{n!\gamma(\gamma+1)\cdots(\gamma+n-1)}z^n$$   Here $\alpha,\beta\in\mathbb{C}$ and $\gamma \neq 0,-1,-2,\cdots$. I set  $$c_n=\frac{\alpha(\alpha+1)\cdots(\alpha+n-1)\beta(\beta+1)\cdots(\beta+n-1)}{\gamma(\gamma+1)\cdots(\gamma+n-1)},\qquad a_n=\frac{c_n}{n!}$$ and  $$\color{red}{c_n\sim\left(\frac{\alpha\,\beta}{\gamma}\right)^n}, \qquad n\to\infty$$ Thus, the radius of convergence $R$ can be found using Cauchy-Hadamard's formula $$R=\frac{1}{\lim\sup|a_n|^{1/n}}=\left|\frac{\gamma}{\alpha\,\beta}\right|\cdot\lim_\limits{n\to\infty}\sqrt[n]{|n!|}=\left|\frac{\gamma}{\alpha\,\beta}\right|\cdot\infty=\infty.$$ This would conclude that $F(\alpha,\beta,\gamma,z)$ is an entire function, but I do not know if these steps are correct. I realized that the part in red is not true. What would be a better approximation?",,"['complex-analysis', 'power-series']"
24,Region of Convergence for Laurent Expansion,Region of Convergence for Laurent Expansion,,Find the Laurent expansion of $\frac{z}{(z+1)(z+2)}$ about the singularity $z=-2$. Specify the region of convergence and the nature of singularity at $z = -2$. The Laurent expansion I get is $1+(z+2)+(z+2)^2+ \ldots + \frac{2}{z+2}$ The singularity is a simple pole. But how to find the Region of Convergence.,Find the Laurent expansion of $\frac{z}{(z+1)(z+2)}$ about the singularity $z=-2$. Specify the region of convergence and the nature of singularity at $z = -2$. The Laurent expansion I get is $1+(z+2)+(z+2)^2+ \ldots + \frac{2}{z+2}$ The singularity is a simple pole. But how to find the Region of Convergence.,,"['complex-analysis', 'convergence-divergence', 'laurent-series']"
25,How does the derivative with respect to the complex conjugate even make sense?,How does the derivative with respect to the complex conjugate even make sense?,,"I came across this the other day: $$ \frac{\partial f}{\partial \bar{z}} = \frac12\left(\frac{\partial f}{\partial x}+i\frac{\partial f}{\partial y}\right) $$ I decided to attempt to work it out myself to better understand it. I know $2x = z + \bar{z}$, and $2iy = z - \bar{z}$, and using the total derivative we have $$ \frac{\partial f}{\partial \bar{z}} = \frac{\partial f}{\partial x}\frac{\partial x}{\partial \bar{z}} + \frac{\partial f}{\partial y}\frac{\partial y}{\partial \bar{z}} $$ and this is about where I got stuck. How exactly am I supposed to calculate $\frac{\partial x}{\partial \bar{z}}$? My confusion doesn't lie in the notation, but in the mechanics of the very thing I'm being asked to differentiate. Look at $x$: $$ x(\bar{z}) = \frac{\bar{z} + z}{2} = \frac{\bar{z}+\bar{\bar{z}}}{2} $$ if we label $Z = \bar{z}$, then $\frac{\partial x}{\partial \bar{z}} = \frac{\partial x}{\partial Z}$, and $x(Z) = \frac{Z+\bar{Z}}2$. However, as far as I can tell, $\frac{Z+\bar{Z}}{2}$ isn't even complex differentiable, because $\bar{Z}$ isn't complex differentiable with respect to $Z$. $x(Z)$ doesn't satisfy the CR equations: $$ x(X+iY) = X + i0 = u(X, Y) + iv(X, Y) \\ u_X = 1 \neq 0 = v_Y \\ v_X = 0 \neq -1 = -u_Y $$  so how could I possibly take the complex derivative of it? That doesn't make any sense. What exactly am I missing here? Is the derivative $\frac{\partial x}{\partial \bar{z}}$ a different kind of derivative? Are we not supposed to do the complex derivative but instead something else?","I came across this the other day: $$ \frac{\partial f}{\partial \bar{z}} = \frac12\left(\frac{\partial f}{\partial x}+i\frac{\partial f}{\partial y}\right) $$ I decided to attempt to work it out myself to better understand it. I know $2x = z + \bar{z}$, and $2iy = z - \bar{z}$, and using the total derivative we have $$ \frac{\partial f}{\partial \bar{z}} = \frac{\partial f}{\partial x}\frac{\partial x}{\partial \bar{z}} + \frac{\partial f}{\partial y}\frac{\partial y}{\partial \bar{z}} $$ and this is about where I got stuck. How exactly am I supposed to calculate $\frac{\partial x}{\partial \bar{z}}$? My confusion doesn't lie in the notation, but in the mechanics of the very thing I'm being asked to differentiate. Look at $x$: $$ x(\bar{z}) = \frac{\bar{z} + z}{2} = \frac{\bar{z}+\bar{\bar{z}}}{2} $$ if we label $Z = \bar{z}$, then $\frac{\partial x}{\partial \bar{z}} = \frac{\partial x}{\partial Z}$, and $x(Z) = \frac{Z+\bar{Z}}2$. However, as far as I can tell, $\frac{Z+\bar{Z}}{2}$ isn't even complex differentiable, because $\bar{Z}$ isn't complex differentiable with respect to $Z$. $x(Z)$ doesn't satisfy the CR equations: $$ x(X+iY) = X + i0 = u(X, Y) + iv(X, Y) \\ u_X = 1 \neq 0 = v_Y \\ v_X = 0 \neq -1 = -u_Y $$  so how could I possibly take the complex derivative of it? That doesn't make any sense. What exactly am I missing here? Is the derivative $\frac{\partial x}{\partial \bar{z}}$ a different kind of derivative? Are we not supposed to do the complex derivative but instead something else?",,"['complex-analysis', 'derivatives']"
26,Prove that a holomorphic function injective in an annulus is injective in the whole ball,Prove that a holomorphic function injective in an annulus is injective in the whole ball,,"Let $f: B(0,1) \rightarrow \mathbb{C}$ be holomorphic and suppose $\exists\ r \in (0,1)$ such that $f$ is injective in $A = \{z \in \mathbb{C} : r < |z| < 1\}$. Prove that $f$ is injective. I tried using Rouché theorem, or the identity theorem, but I don't know what to do. Any hints? :)","Let $f: B(0,1) \rightarrow \mathbb{C}$ be holomorphic and suppose $\exists\ r \in (0,1)$ such that $f$ is injective in $A = \{z \in \mathbb{C} : r < |z| < 1\}$. Prove that $f$ is injective. I tried using Rouché theorem, or the identity theorem, but I don't know what to do. Any hints? :)",,"['complex-analysis', 'holomorphic-functions']"
27,Choosing parametrization for complex integration with two branch cuts,Choosing parametrization for complex integration with two branch cuts,,"I am particularly interested in how Ron Gordon came up with the parametrization in his anser to this question: Inverse Laplace transform $\mathcal{L}^{-1}\left \{ \ln \left ( 1+\frac{w^{2}}{s^{2}}\right ) \right \}$ EDIT: Do we have to incorporate four  branch cuts, if for example we wanted to integrate the function $$f\left ( z \right )=\frac{\sqrt{z}}{\ln\left ( z^{4}+1 \right )}$$ Is there a generalization for choosing the parametrization for multiple branch cuts? EDIT #2: My understanding on how to approach integration of a complex function with one branch cut is clear, and I state this very boldly, I feel like I understand it intuitively(keeping the Riemann surfaces in mind). I am also very comfortable with recognizing when a function has multiple branch cuts, realizing why they are there, and that we must avoid them in order for the domain to stay simply connected. What I don't understand, is how to integrate along a branch cut which isn't necessarily along the real axis(e.g. along the line $\phi=\frac{\pi}{3}$. In the question linked, this paragraph confuses me : The reader should note that there is a fourfold split here: when $z$ is to the left or right of the imaginary axis, and when $z$ is above or below the real axis. In each of these cases, the log has a negative argument, but the log of the negative argument takes on a different value along each section of the dog-bone.   When $z$ is to the left and right of the imaginary axis we respectively parametrize $z=+iy$and $z=-iy$. However, we subtract $2i\pi$ from the log term upon crossing the imaginary axis and add $2i\pi$  upon crossing the real axis.","I am particularly interested in how Ron Gordon came up with the parametrization in his anser to this question: Inverse Laplace transform $\mathcal{L}^{-1}\left \{ \ln \left ( 1+\frac{w^{2}}{s^{2}}\right ) \right \}$ EDIT: Do we have to incorporate four  branch cuts, if for example we wanted to integrate the function $$f\left ( z \right )=\frac{\sqrt{z}}{\ln\left ( z^{4}+1 \right )}$$ Is there a generalization for choosing the parametrization for multiple branch cuts? EDIT #2: My understanding on how to approach integration of a complex function with one branch cut is clear, and I state this very boldly, I feel like I understand it intuitively(keeping the Riemann surfaces in mind). I am also very comfortable with recognizing when a function has multiple branch cuts, realizing why they are there, and that we must avoid them in order for the domain to stay simply connected. What I don't understand, is how to integrate along a branch cut which isn't necessarily along the real axis(e.g. along the line $\phi=\frac{\pi}{3}$. In the question linked, this paragraph confuses me : The reader should note that there is a fourfold split here: when $z$ is to the left or right of the imaginary axis, and when $z$ is above or below the real axis. In each of these cases, the log has a negative argument, but the log of the negative argument takes on a different value along each section of the dog-bone.   When $z$ is to the left and right of the imaginary axis we respectively parametrize $z=+iy$and $z=-iy$. However, we subtract $2i\pi$ from the log term upon crossing the imaginary axis and add $2i\pi$  upon crossing the real axis.",,"['complex-analysis', 'complex-integration', 'branch-cuts']"
28,Roots of Complex Polynomial in Disc,Roots of Complex Polynomial in Disc,,"This is a theorem that I have encountered before and proved using some homotopy-theoretic arguments, but I tried to prove this statement again without such tools and ended up failing.  It seems to be Rouche's Theorem, but I can't figure out how to jimmy it just right. The statement is very nice: All roots of $p(z) = z^n + a_{n-1}z^{n-1} + \cdots + a_0$ lie in the disc centered at zero with radius $R = \sqrt{1 + |a_{n-1}|^2 + |a_{n-2}|^2 + \cdots + |a_0|^2}$ I keep thinking I have done it correctly, only to find an error.  Does anyone have a slick proof of this that just uses complex-analytic techniques?  I would really like to see just a sketch, or just the first step to start it off, but hey, I won't stop you from finishing it up haha For those who would think it's useful to see the homotopy-theoretic version, check Munkres Topology, Ch. 9.56 and the first exercise, but it seems impossible to state this proof without using homotopy. Thanks a lot!","This is a theorem that I have encountered before and proved using some homotopy-theoretic arguments, but I tried to prove this statement again without such tools and ended up failing.  It seems to be Rouche's Theorem, but I can't figure out how to jimmy it just right. The statement is very nice: All roots of $p(z) = z^n + a_{n-1}z^{n-1} + \cdots + a_0$ lie in the disc centered at zero with radius $R = \sqrt{1 + |a_{n-1}|^2 + |a_{n-2}|^2 + \cdots + |a_0|^2}$ I keep thinking I have done it correctly, only to find an error.  Does anyone have a slick proof of this that just uses complex-analytic techniques?  I would really like to see just a sketch, or just the first step to start it off, but hey, I won't stop you from finishing it up haha For those who would think it's useful to see the homotopy-theoretic version, check Munkres Topology, Ch. 9.56 and the first exercise, but it seems impossible to state this proof without using homotopy. Thanks a lot!",,"['complex-analysis', 'polynomials']"
29,Showing that choice of point on a curve is irrelevant to finding $f(z_0)$ in the curve,Showing that choice of point on a curve is irrelevant to finding  in the curve,f(z_0),"Before I start I apologize for the horrible title but I have no idea how to title this. So the problem is as follows: Let $f(z)$ be analytic in and on a simple closed curve $\Gamma$, and let $f(z)$ have no zeros in or on $\Gamma$. Now let $z_0$ be a point in $\Gamma$, and $z_1$, $z_2$ be two points on $\Gamma$. Let $\gamma_1$ & $\gamma_2$ be the two curves connecting $z_1$ & $z_2$ to $z_0$ respectively.  Where the integraion is towards $z_0$ both times show that $$f(z_1)e^{\int_{\gamma_1}\frac{f'(x)}{f(x)}dx}=f(z_2)e^{\int_{\gamma_2}\frac{f'(x)}{f(x)}dx}$$ And then show that both sides are equal to $f(z_0)$. I'm given a hint to represent $f(z_2)/f(z_1)$ as an integral along the part of $\Gamma$ connecting these two points. This is where the problem begins and thats where I would start, but I'm struggling with that. One idea I had is that since $f(z_0)$ doesn't equal $0$, I could use that I could make a disk large enough centered at $z_0$ such that $e^{w(z)}=f(z)$, where $w(z)$ is essentially the two integral above, just flip the sign. Another idea I think is better.  If I solve the hint, then I could make a new curve $\gamma_3$ using the arc connecting $z_1$ and $z_2$ and $\gamma_1$ and $\gamma_2$, and then use Cauchy's theorem, so that $\int_{\gamma_3}f(z)=0$, and I would split this integral up into the three parts forming this curve if I could figure it out. Any help is appreciated, thanks in advance.","Before I start I apologize for the horrible title but I have no idea how to title this. So the problem is as follows: Let $f(z)$ be analytic in and on a simple closed curve $\Gamma$, and let $f(z)$ have no zeros in or on $\Gamma$. Now let $z_0$ be a point in $\Gamma$, and $z_1$, $z_2$ be two points on $\Gamma$. Let $\gamma_1$ & $\gamma_2$ be the two curves connecting $z_1$ & $z_2$ to $z_0$ respectively.  Where the integraion is towards $z_0$ both times show that $$f(z_1)e^{\int_{\gamma_1}\frac{f'(x)}{f(x)}dx}=f(z_2)e^{\int_{\gamma_2}\frac{f'(x)}{f(x)}dx}$$ And then show that both sides are equal to $f(z_0)$. I'm given a hint to represent $f(z_2)/f(z_1)$ as an integral along the part of $\Gamma$ connecting these two points. This is where the problem begins and thats where I would start, but I'm struggling with that. One idea I had is that since $f(z_0)$ doesn't equal $0$, I could use that I could make a disk large enough centered at $z_0$ such that $e^{w(z)}=f(z)$, where $w(z)$ is essentially the two integral above, just flip the sign. Another idea I think is better.  If I solve the hint, then I could make a new curve $\gamma_3$ using the arc connecting $z_1$ and $z_2$ and $\gamma_1$ and $\gamma_2$, and then use Cauchy's theorem, so that $\int_{\gamma_3}f(z)=0$, and I would split this integral up into the three parts forming this curve if I could figure it out. Any help is appreciated, thanks in advance.",,['complex-analysis']
30,Show that the set of zeros of $f$ is discrete,Show that the set of zeros of  is discrete,f,"Let $\Omega \subset \Bbb{C}$ a region. $f:\Omega \to \Bbb{C}$ holomorphic, $f\neq 0$ . Show that the set of zeros of $f$ is discrete. (That is, that it doesn't have any limit points.) This is the second part of an excercise in which I proved already that given $a \in \Omega$ such that $f(a)=0$ there exist $k \in \Bbb{N}$ such that $f(z)=(z-a)^kg(z)$ with $g:\Omega \to \Bbb{C}$ holomorphic and $g(a)\neq 0$ . However Im not being able to see how to show that the set of zeros is discrete. Any hint?","Let a region. holomorphic, . Show that the set of zeros of is discrete. (That is, that it doesn't have any limit points.) This is the second part of an excercise in which I proved already that given such that there exist such that with holomorphic and . However Im not being able to see how to show that the set of zeros is discrete. Any hint?",\Omega \subset \Bbb{C} f:\Omega \to \Bbb{C} f\neq 0 f a \in \Omega f(a)=0 k \in \Bbb{N} f(z)=(z-a)^kg(z) g:\Omega \to \Bbb{C} g(a)\neq 0,['complex-analysis']
31,Showing that a holomorphic function $f : \mathbb{C}\setminus\{0\} \to \mathbb{C}$ with $f(2z) = f(z)$ is constant,Showing that a holomorphic function  with  is constant,f : \mathbb{C}\setminus\{0\} \to \mathbb{C} f(2z) = f(z),"Let $f : \mathbb{C}\setminus\{0\} \to \mathbb{C}$ be a holomorphic function satisfying $f(2z) = f(z)$ for all $z \in \mathbb{C}\setminus\{0\}$. Show that $f$ is constant. Here $f$ is defined as a map $\mathbb{C}\setminus\{0\}\rightarrow \mathbb{C}$. If $0$ is a removable singularity, then it is clear to me that $f(z) = f(0)$ for all $z$. Further, I can rule out the possibility that $0$ is a pole since this would lead to a contradiction on the absolute value of $f$ as I take successive values of $z,z/2,z/4, z/8$, etc. However, I cannot currently rule out the possibility that such an $f$ exists which is non-constant and has an essential singularity at $0$. Can anybody suggest a way please?","Let $f : \mathbb{C}\setminus\{0\} \to \mathbb{C}$ be a holomorphic function satisfying $f(2z) = f(z)$ for all $z \in \mathbb{C}\setminus\{0\}$. Show that $f$ is constant. Here $f$ is defined as a map $\mathbb{C}\setminus\{0\}\rightarrow \mathbb{C}$. If $0$ is a removable singularity, then it is clear to me that $f(z) = f(0)$ for all $z$. Further, I can rule out the possibility that $0$ is a pole since this would lead to a contradiction on the absolute value of $f$ as I take successive values of $z,z/2,z/4, z/8$, etc. However, I cannot currently rule out the possibility that such an $f$ exists which is non-constant and has an essential singularity at $0$. Can anybody suggest a way please?",,['complex-analysis']
32,Proving or Disproving the Existence of a Function on the Unit Disc,Proving or Disproving the Existence of a Function on the Unit Disc,,"Let $f$ be holomorphic in the unit disc and continuous on its closure. Prove or disprove that there exists such $f$ so that $f(e^{i\theta})=e^{-i\theta}$ for $0<\theta<\frac{\pi}{4}$. I believe that there is no such function since on the boundary of the disc it acts as the map $z\mapsto \bar{z}$, which is not holomorphic. But I don't see how to prove this rigorously, nor do I see what known theorems could be applied. I am familiar with analytic continuation, but I am not sure if that applies since $f$ need not be holomorphic on the boundary. Any hints or insights would be greatly appreciated.","Let $f$ be holomorphic in the unit disc and continuous on its closure. Prove or disprove that there exists such $f$ so that $f(e^{i\theta})=e^{-i\theta}$ for $0<\theta<\frac{\pi}{4}$. I believe that there is no such function since on the boundary of the disc it acts as the map $z\mapsto \bar{z}$, which is not holomorphic. But I don't see how to prove this rigorously, nor do I see what known theorems could be applied. I am familiar with analytic continuation, but I am not sure if that applies since $f$ need not be holomorphic on the boundary. Any hints or insights would be greatly appreciated.",,['complex-analysis']
33,Non Existence of a proper holomorphic map from the unit disc onto the complex plane,Non Existence of a proper holomorphic map from the unit disc onto the complex plane,,It is well known that there is no proper holomorphic map from complex plane onto disc by Liouville's theorem.Does there exist a proper holomorphic map $f$ from the unit disc onto the complex plane?I believe that such map does not exists but I'm unable to prove this.Please Help! Def :A map $f:X \to Y$ is called a proper map if $f^{-1}(K)$ is compact in $X$ for every compact set $K$ in $Y$.,It is well known that there is no proper holomorphic map from complex plane onto disc by Liouville's theorem.Does there exist a proper holomorphic map $f$ from the unit disc onto the complex plane?I believe that such map does not exists but I'm unable to prove this.Please Help! Def :A map $f:X \to Y$ is called a proper map if $f^{-1}(K)$ is compact in $X$ for every compact set $K$ in $Y$.,,['complex-analysis']
34,Evaluate $\int_{|C|=2} \frac{dz}{z^2 + 2z + 2}$ using Cauchy-Goursat,Evaluate  using Cauchy-Goursat,\int_{|C|=2} \frac{dz}{z^2 + 2z + 2},"I've split the integral around $z_1 = 1 - i$ and $z_2 = 1+ i$ using the contours $C_1$ and $C_2$: $ \int_{|C|=2} g(z) dz = \int_{C_1} g(z) dz + \int_{C_2} g(z) dz$ In this case, $g(z)$ for $C_1$ is $\displaystyle \frac{\frac{1}{z-z_1}}{z-z_2}$ and $g(z)$ for $C_2$ is $\displaystyle \frac{\frac{1}{z-z_2}}{z-z_1}$. Using Cauchy's Thm I get $\displaystyle \frac{1}{z_2 - z_1}$ for the first one and $\displaystyle \frac{1}{z_1 - z_2}$ for the second. But evaluating $\displaystyle \int_{|C|=2} g(z) dz = 2\pi i \left(\frac{1}{z_2 - z_1} +  \frac{1}{z_1 - z_2} \right) = 0$ I'm not interested in other methods, just this particular version where you split the contour $C$ into $C_1$ and $C_2$ My issue with this answer is that it doesn't make sense.  When evaluating an integral like $\displaystyle \int_{\infty}^{-\infty} \frac{dx}{x^2 + 2x + 2}$ you must let $\displaystyle g(z) = \frac{1}{z^2 + 2z + 2}$ and then integrate over the contour $C$. I would've thought that the answer would be give me $\pi$","I've split the integral around $z_1 = 1 - i$ and $z_2 = 1+ i$ using the contours $C_1$ and $C_2$: $ \int_{|C|=2} g(z) dz = \int_{C_1} g(z) dz + \int_{C_2} g(z) dz$ In this case, $g(z)$ for $C_1$ is $\displaystyle \frac{\frac{1}{z-z_1}}{z-z_2}$ and $g(z)$ for $C_2$ is $\displaystyle \frac{\frac{1}{z-z_2}}{z-z_1}$. Using Cauchy's Thm I get $\displaystyle \frac{1}{z_2 - z_1}$ for the first one and $\displaystyle \frac{1}{z_1 - z_2}$ for the second. But evaluating $\displaystyle \int_{|C|=2} g(z) dz = 2\pi i \left(\frac{1}{z_2 - z_1} +  \frac{1}{z_1 - z_2} \right) = 0$ I'm not interested in other methods, just this particular version where you split the contour $C$ into $C_1$ and $C_2$ My issue with this answer is that it doesn't make sense.  When evaluating an integral like $\displaystyle \int_{\infty}^{-\infty} \frac{dx}{x^2 + 2x + 2}$ you must let $\displaystyle g(z) = \frac{1}{z^2 + 2z + 2}$ and then integrate over the contour $C$. I would've thought that the answer would be give me $\pi$",,"['complex-analysis', 'complex-integration']"
35,‘Integral’ of a Weierstrass $ \wp $-function.,‘Integral’ of a Weierstrass -function., \wp ,"I'm revising for my finals and I've seen a question which asks: Is there a meromorphic function $f: \mathbb{C}/\Lambda \to \mathbb{P}^1$ such that $f' = \wp$? There is a hint which says consider the poles of such a function, and I'm pretty sure no such function can exist, but if anyone could supply me with a proof or further hint I would be really grateful.","I'm revising for my finals and I've seen a question which asks: Is there a meromorphic function $f: \mathbb{C}/\Lambda \to \mathbb{P}^1$ such that $f' = \wp$? There is a hint which says consider the poles of such a function, and I'm pretty sure no such function can exist, but if anyone could supply me with a proof or further hint I would be really grateful.",,"['complex-analysis', 'algebraic-curves', 'complex-geometry']"
36,Limit with number $e$ and complex number,Limit with number  and complex number,e,"This is my first question here. I hope that I spend here a lot of fantastic time. How to proof that fact? $$\lim_{n\to\infty} \left(1+\frac{z}{n}\right)^{n}=e^{z}$$ where $z \in \mathbb{C}$ and $e^z$ is defined by its power series. I have one hint: find the limit of abs. value and arguments, but i don't know how to use it to solve that problem. Thank you for help. Before I try solve this problem, I proofed that $$e^z=e^{x}(\cos y + i \sin y)$$ where $z=x+yi$ ,maybe this help.","This is my first question here. I hope that I spend here a lot of fantastic time. How to proof that fact? $$\lim_{n\to\infty} \left(1+\frac{z}{n}\right)^{n}=e^{z}$$ where $z \in \mathbb{C}$ and $e^z$ is defined by its power series. I have one hint: find the limit of abs. value and arguments, but i don't know how to use it to solve that problem. Thank you for help. Before I try solve this problem, I proofed that $$e^z=e^{x}(\cos y + i \sin y)$$ where $z=x+yi$ ,maybe this help.",,"['complex-analysis', 'limits', 'exponential-function']"
37,finding the inverse Laplace transform of $\frac{1}{z\sqrt{z+1}}$,finding the inverse Laplace transform of,\frac{1}{z\sqrt{z+1}},i know that the inverse Laplace transform is given by $$2\pi i \left\{\sum\space\text{ of the residues at the poles of}\space e^{zt}f(z)\right\}- \frac{1}{2 \pi i}\int \text{ along the branch cut}$$ $$f(z) = \frac{1}{z\sqrt{z+1}}$$ there is a branch point at $z=-1$ and there is also a singularity at $z=-1$ and a pole at $z = 0$ i want to know if i include the residue at the pole $z=-1$ even though its the branch point or if i simply include the residue at the pole $z=0$ only and subtract it from the integral across the branch cut. i.e. $$\mathcal{L}^{-1}f(z) = 2\pi i(\operatorname{Res}(e^{zt}f(z);0)-\frac{1}{2\pi i}\int \text{ branch cut}$$,i know that the inverse Laplace transform is given by $$2\pi i \left\{\sum\space\text{ of the residues at the poles of}\space e^{zt}f(z)\right\}- \frac{1}{2 \pi i}\int \text{ along the branch cut}$$ $$f(z) = \frac{1}{z\sqrt{z+1}}$$ there is a branch point at $z=-1$ and there is also a singularity at $z=-1$ and a pole at $z = 0$ i want to know if i include the residue at the pole $z=-1$ even though its the branch point or if i simply include the residue at the pole $z=0$ only and subtract it from the integral across the branch cut. i.e. $$\mathcal{L}^{-1}f(z) = 2\pi i(\operatorname{Res}(e^{zt}f(z);0)-\frac{1}{2\pi i}\int \text{ branch cut}$$,,"['complex-analysis', 'laplace-transform', 'contour-integration']"
38,"Laurent series, integral over the annulus, radii","Laurent series, integral over the annulus, radii",,"We are given $$f = \sum_{n= - \infty} ^{\infty} a_n (z-z_0)^n \in \mathcal{O} ( \text{ann} (z_0, r, R)), \ \ 0<r<R< \infty. $$ Prove that $$\frac{1}{\pi} \int _{ann (z_0, r, R)} |f(z)|^2 d \lambda(z) = \sum _{n \neq -1} \frac{R^{2n+2} - r^{2n+2}}{n+1}|a_n|^2 + 2 \log \frac{R}{r}|a_{-1}|^2.$$ I know that $$a_n = \frac{1}{2 \pi i} \int_{\partial B(z_0, \rho)} \frac{f(s)}{(s-z_0)^{n+1}}ds, \ \ \rho \in (r,R), \ n \in \mathbb{Z}$$ We know that the series above is convergent, so $R = \frac{1}{\limsup_ {n \rightarrow \infty} \sqrt[n]{|a_n|}}$ and $r = \limsup_ {n \rightarrow \infty} \sqrt[n]{|a_{-n}|}$. In the series $$\sum _{n \neq -1} \frac{R^{2n+2}}{n+1}|a_n|^2, \ \ \sum _{n \neq -1} \frac{r^{2n+2}}{n+1}|a_n|^2$$ we have $b_n = \frac{|a_n|^2}{n+1}$ and radii of convergence are $$R'=\frac{1}{\limsup_ {n \rightarrow \infty} \sqrt[n]{\frac{|a_n|^2}{n+1}}} \ge \frac{1}{\limsup_ {n \rightarrow \infty} \sqrt[n]{|a_n|^2}} \ge \frac{1}{\limsup_ {n \rightarrow \infty} \sqrt[n]{|a_n|}}^2 = R^2,$$ so $R' \ge R^2$, and similarly, $$r' = \limsup_ {n \rightarrow \infty} \sqrt[n]{\frac{|a_{-n}|^2}{n+1}} \le \limsup_ {n \rightarrow \infty} \sqrt[n]{|a_{-n}|^2} \le r^2.$$ So the two series have radii of convergentce $R', r'$, assuming they have the form $\sum b_n (z-z_0)^n$ with $z=R^2$ or $-r^2$. Does that make sense? Could you tell me how to prove the equality of the integral and the series?","We are given $$f = \sum_{n= - \infty} ^{\infty} a_n (z-z_0)^n \in \mathcal{O} ( \text{ann} (z_0, r, R)), \ \ 0<r<R< \infty. $$ Prove that $$\frac{1}{\pi} \int _{ann (z_0, r, R)} |f(z)|^2 d \lambda(z) = \sum _{n \neq -1} \frac{R^{2n+2} - r^{2n+2}}{n+1}|a_n|^2 + 2 \log \frac{R}{r}|a_{-1}|^2.$$ I know that $$a_n = \frac{1}{2 \pi i} \int_{\partial B(z_0, \rho)} \frac{f(s)}{(s-z_0)^{n+1}}ds, \ \ \rho \in (r,R), \ n \in \mathbb{Z}$$ We know that the series above is convergent, so $R = \frac{1}{\limsup_ {n \rightarrow \infty} \sqrt[n]{|a_n|}}$ and $r = \limsup_ {n \rightarrow \infty} \sqrt[n]{|a_{-n}|}$. In the series $$\sum _{n \neq -1} \frac{R^{2n+2}}{n+1}|a_n|^2, \ \ \sum _{n \neq -1} \frac{r^{2n+2}}{n+1}|a_n|^2$$ we have $b_n = \frac{|a_n|^2}{n+1}$ and radii of convergence are $$R'=\frac{1}{\limsup_ {n \rightarrow \infty} \sqrt[n]{\frac{|a_n|^2}{n+1}}} \ge \frac{1}{\limsup_ {n \rightarrow \infty} \sqrt[n]{|a_n|^2}} \ge \frac{1}{\limsup_ {n \rightarrow \infty} \sqrt[n]{|a_n|}}^2 = R^2,$$ so $R' \ge R^2$, and similarly, $$r' = \limsup_ {n \rightarrow \infty} \sqrt[n]{\frac{|a_{-n}|^2}{n+1}} \le \limsup_ {n \rightarrow \infty} \sqrt[n]{|a_{-n}|^2} \le r^2.$$ So the two series have radii of convergentce $R', r'$, assuming they have the form $\sum b_n (z-z_0)^n$ with $z=R^2$ or $-r^2$. Does that make sense? Could you tell me how to prove the equality of the integral and the series?",,"['complex-analysis', 'analyticity', 'laurent-series']"
39,Showing that $z^3 e^z = 1$ has infinitely many solutions,Showing that  has infinitely many solutions,z^3 e^z = 1,"On an old complex analysis prelim, I encountered the following problem. Show that the equation $z^3 e^z =1$ has infinitely many solutions. How many are real? Well many sources in complex analysis utilize Picard's Big Theorem to show that $e^z -z =0$ has infinitely many solutions. Picard's Big Theorem states that if an analytic function $f$ has an essential singularity at a point $w$, then on any punctured neighborhood of $w$, $f(z)$ takes on every possible complex value, with at most one exception, infinitely often. Clearly, $f(z) = e^z -z$ has an essential singularity at $\infty$. Thus, $f$ takes on every value infinitely many times with at most one exception, at most one value can be achieved finitely often, and that value could possibly be $0$. But we recall that the exponential function is $2 \pi i$-periodic and so $f(z+ 2 \pi i)= f(z)- 2 \pi i$. So now $f$ takes on at least one value in $\{0,2 \pi i\}$ infinitely often. Applying Picard's Big Theorem to both these cases, implies that $e^z -z =0$ has infinitely many solutions. Can Picard's Big Theorem also be used to show that $z^3 e^z =1$ has infinitely many solutions? We can rewrite this equation as $e^z - z^{-3} =0$ so that we could let $f(z)= e^z - z^{-3}$ and see that it has an essential singularity at $\infty$, correct? If so, then I think that maybe Picard's Big Theorem might be OK here, though I'm not really sure. Now the second part of the problem is to find how many solutions are real; there is a hint (hardly expected on a prelim) that suggests using the Argument Principle. I'm familiar with how to find the number of zeros in a particular quadrant/half plane of a complex polynomial of finite degree through use of the Argument Principle, but don't know how to apply it here. I'd appreciate any help I can get.","On an old complex analysis prelim, I encountered the following problem. Show that the equation $z^3 e^z =1$ has infinitely many solutions. How many are real? Well many sources in complex analysis utilize Picard's Big Theorem to show that $e^z -z =0$ has infinitely many solutions. Picard's Big Theorem states that if an analytic function $f$ has an essential singularity at a point $w$, then on any punctured neighborhood of $w$, $f(z)$ takes on every possible complex value, with at most one exception, infinitely often. Clearly, $f(z) = e^z -z$ has an essential singularity at $\infty$. Thus, $f$ takes on every value infinitely many times with at most one exception, at most one value can be achieved finitely often, and that value could possibly be $0$. But we recall that the exponential function is $2 \pi i$-periodic and so $f(z+ 2 \pi i)= f(z)- 2 \pi i$. So now $f$ takes on at least one value in $\{0,2 \pi i\}$ infinitely often. Applying Picard's Big Theorem to both these cases, implies that $e^z -z =0$ has infinitely many solutions. Can Picard's Big Theorem also be used to show that $z^3 e^z =1$ has infinitely many solutions? We can rewrite this equation as $e^z - z^{-3} =0$ so that we could let $f(z)= e^z - z^{-3}$ and see that it has an essential singularity at $\infty$, correct? If so, then I think that maybe Picard's Big Theorem might be OK here, though I'm not really sure. Now the second part of the problem is to find how many solutions are real; there is a hint (hardly expected on a prelim) that suggests using the Argument Principle. I'm familiar with how to find the number of zeros in a particular quadrant/half plane of a complex polynomial of finite degree through use of the Argument Principle, but don't know how to apply it here. I'd appreciate any help I can get.",,['complex-analysis']
40,all complex solutions of $z\sin(z)=1$?,all complex solutions of ?,z\sin(z)=1,"A possibly easy question, Can we find all complex solutions of $z\sin(z)=1$ ? My try: Let $$\sin(z) = \frac{e^{iz} - e^{-iz}}{2i}$$ so we have  $$ z\frac{e^{iz} - e^{-iz}}{2i}=1 $$ Not sure how can I continue ? Thanks EDIT : I have posted a related question here .","A possibly easy question, Can we find all complex solutions of $z\sin(z)=1$ ? My try: Let $$\sin(z) = \frac{e^{iz} - e^{-iz}}{2i}$$ so we have  $$ z\frac{e^{iz} - e^{-iz}}{2i}=1 $$ Not sure how can I continue ? Thanks EDIT : I have posted a related question here .",,"['complex-analysis', 'trigonometry']"
41,"Ahlfors' extension of Riemann mapping function, proof clarification","Ahlfors' extension of Riemann mapping function, proof clarification",,"In the Ahlfors' Complex Analysis chapter about the Riemann Mapping Theorem section 6.1.3, page 233, he states and proves this theorem: Theorem 3. Suppose that the boundary of a simply connected region $\Omega$ contains a line segment $\gamma$ as a one-sided free boundary arc. Then the [Riemann mapping] function $f(z)$ which maps $\Omega$ onto the unit disk can be extended to a function which is analytic and one-to-one on $\Omega \cup \gamma$. The image of $\gamma$ is an arc $\gamma'$ on the unit circle. In this particular context by ""free boundary arc"" he means an open interval $a < x < b$ of the real line. I understand the proof of the existence of the extension: use the version of Schwarz reflection which only requires continuity of $\text{Re} \log f(z)$ at the boundary. What I don't understand is his argument that $f$ is injective on $\gamma$. Here's how it goes: We note further that $f'(z) \ne 0$ on $\gamma$. Indeed, $f'(x_0) = 0$ wold imply that $f(x_0)$ were a multiple value, in which case the two subarcs of $\gamma$ that meet at $x_0$ would be mapped on arcs that form an angle $\pi/n$ with $n \ge 2$; this is clearly impossible. If, for instance, the upper half disks are in $\Omega$, then   $$\partial \log |f| / \partial y = - \ \partial \arg f / \partial x < 0$$   on $\gamma$, and $\arg f$ moves constantly in the same direction. This proves that the mapping is one-to-one on $\gamma$. My attempt to clarify: In order to show that $f'(x_0)$ is not zero, I figured that if it were, we could factor $f(z)-f(x_0) = [(z-x_0)g(z)]^n$ where $g(x_0) \ne 0$. I think if you pick the right arc in the domain $\Omega \cup \gamma$, the image of that arc contains a point outside the closed unit disk. Even if $f'(x) \ne 0$ on $\gamma$, I still don't see why the image of $\gamma$ can't ""wrap all the way around the circle"" and come back to the same point, and so be locally injective without being globally one-to-one. Any help is greatly appreciated.","In the Ahlfors' Complex Analysis chapter about the Riemann Mapping Theorem section 6.1.3, page 233, he states and proves this theorem: Theorem 3. Suppose that the boundary of a simply connected region $\Omega$ contains a line segment $\gamma$ as a one-sided free boundary arc. Then the [Riemann mapping] function $f(z)$ which maps $\Omega$ onto the unit disk can be extended to a function which is analytic and one-to-one on $\Omega \cup \gamma$. The image of $\gamma$ is an arc $\gamma'$ on the unit circle. In this particular context by ""free boundary arc"" he means an open interval $a < x < b$ of the real line. I understand the proof of the existence of the extension: use the version of Schwarz reflection which only requires continuity of $\text{Re} \log f(z)$ at the boundary. What I don't understand is his argument that $f$ is injective on $\gamma$. Here's how it goes: We note further that $f'(z) \ne 0$ on $\gamma$. Indeed, $f'(x_0) = 0$ wold imply that $f(x_0)$ were a multiple value, in which case the two subarcs of $\gamma$ that meet at $x_0$ would be mapped on arcs that form an angle $\pi/n$ with $n \ge 2$; this is clearly impossible. If, for instance, the upper half disks are in $\Omega$, then   $$\partial \log |f| / \partial y = - \ \partial \arg f / \partial x < 0$$   on $\gamma$, and $\arg f$ moves constantly in the same direction. This proves that the mapping is one-to-one on $\gamma$. My attempt to clarify: In order to show that $f'(x_0)$ is not zero, I figured that if it were, we could factor $f(z)-f(x_0) = [(z-x_0)g(z)]^n$ where $g(x_0) \ne 0$. I think if you pick the right arc in the domain $\Omega \cup \gamma$, the image of that arc contains a point outside the closed unit disk. Even if $f'(x) \ne 0$ on $\gamma$, I still don't see why the image of $\gamma$ can't ""wrap all the way around the circle"" and come back to the same point, and so be locally injective without being globally one-to-one. Any help is greatly appreciated.",,['complex-analysis']
42,Meromorphic on unit disc with absolute value 1 on the circle is a rational function.,Meromorphic on unit disc with absolute value 1 on the circle is a rational function.,,Let $f$ be a meromorphic function on the open unit disk such that $f$ has a continuous extension to the boundary circle.Suppose $f$ has only poles in the open unit disc and suppose $|f(z)|=1$ for all $z$ with $|z|=1$.Prove that $f$ is a rational function.,Let $f$ be a meromorphic function on the open unit disk such that $f$ has a continuous extension to the boundary circle.Suppose $f$ has only poles in the open unit disc and suppose $|f(z)|=1$ for all $z$ with $|z|=1$.Prove that $f$ is a rational function.,,['complex-analysis']
43,Understanding Dogbone contour example,Understanding Dogbone contour example,,"I am trying to understand example $6$ on the Wikipedia page http://en.wikipedia.org/wiki/Methods_of_contour_integration , but one particular point has mystified me for hours. After it is shown that the line integral representing the left and right circles vanish as the radii get small, there is a skipped step that concludes that $$\oint_{C}\frac{f(z)}{5-z} dz = (1-i)\int_{0}^{3}\frac{x^\frac{3}{4}(3-x)^{\frac{1}{4}}}{5-x}dx.$$ I understand that this is related to the fact that as the radii approach zero, the horizontal curves approach the branch cut and takes on different values, but I do not understand how to arrive at $1$ and $-i$ respectively. I have read other examples of this such as the following link: Evaluating the integral $\int_{-1}^{1} \frac{\sqrt{1-x^{2}}}{1+x^{2}} \, dx$ using a dumbbell-shaped contour but there is consistently enough detail missing when discussing the branch point to leave me confused at my current level of knowledge in the subject.","I am trying to understand example on the Wikipedia page http://en.wikipedia.org/wiki/Methods_of_contour_integration , but one particular point has mystified me for hours. After it is shown that the line integral representing the left and right circles vanish as the radii get small, there is a skipped step that concludes that I understand that this is related to the fact that as the radii approach zero, the horizontal curves approach the branch cut and takes on different values, but I do not understand how to arrive at and respectively. I have read other examples of this such as the following link: Evaluating the integral $\int_{-1}^{1} \frac{\sqrt{1-x^{2}}}{1+x^{2}} \, dx$ using a dumbbell-shaped contour but there is consistently enough detail missing when discussing the branch point to leave me confused at my current level of knowledge in the subject.",6 \oint_{C}\frac{f(z)}{5-z} dz = (1-i)\int_{0}^{3}\frac{x^\frac{3}{4}(3-x)^{\frac{1}{4}}}{5-x}dx. 1 -i,"['complex-analysis', 'contour-integration', 'branch-cuts']"
44,Finding $\int_{0}^{2\pi} \frac {(1+2\cos\theta)^n\cos(n\theta)}{3+2\cos\theta} \operatorname{d}\theta$,Finding,\int_{0}^{2\pi} \frac {(1+2\cos\theta)^n\cos(n\theta)}{3+2\cos\theta} \operatorname{d}\theta,"If $n$ is a positive integer find $$ \int_{0}^{2\pi} \frac {(1+2\cos\theta)^n\cos(n\theta)}{3+2\cos\theta} \operatorname{d}\theta $$ I know that I have to use contour integral with a circle of radius 1 centered at the origin, but I am having trouble converting the integral into the form $\int_{|z|}$ $$\int_{|z| = 1} \frac{(1+z+1/z)^n\cos(n\theta)}{3+(z+1/z)} \frac{1}{iz} \operatorname{d}z$$ I cant seem to find a way to expand $\cos(n\theta)$ into a function of $z$. From the above equation, I can get that the poles of is at $z = -1.5 \pm \frac{\sqrt{5}}{2}$ and only the residual of $z = -1.5 + \frac{\sqrt{5}}{2}$ should be included.","If $n$ is a positive integer find $$ \int_{0}^{2\pi} \frac {(1+2\cos\theta)^n\cos(n\theta)}{3+2\cos\theta} \operatorname{d}\theta $$ I know that I have to use contour integral with a circle of radius 1 centered at the origin, but I am having trouble converting the integral into the form $\int_{|z|}$ $$\int_{|z| = 1} \frac{(1+z+1/z)^n\cos(n\theta)}{3+(z+1/z)} \frac{1}{iz} \operatorname{d}z$$ I cant seem to find a way to expand $\cos(n\theta)$ into a function of $z$. From the above equation, I can get that the poles of is at $z = -1.5 \pm \frac{\sqrt{5}}{2}$ and only the residual of $z = -1.5 + \frac{\sqrt{5}}{2}$ should be included.",,"['complex-analysis', 'contour-integration']"
45,Principal value of the singular integral $\int_0^\pi \frac{\cos nt}{\cos t - \cos A} dt$,Principal value of the singular integral,\int_0^\pi \frac{\cos nt}{\cos t - \cos A} dt,"For a constant $0<A<\pi$, and natural $n$ I want to find the principal value of the integral: $$\int_0^\pi \frac{\cos nt}{\cos t - \cos A} dt$$ First of all, I'm not certain what function in the complex plane I should look at. Using $$f(z) \equiv \frac{e^{inz}}{e^{iz}-\cos A}$$ or something similar doesn't work, because there is no obvious way to recover the original function from that (no simple relation of one being the imaginary part of the other etc). I tried expressing the difference of cosines as a product of sines, but I don't see how this gets me anywhere. So: what $f(z)$ should I choose? Then, I need to find an appropriate contour on the complex plane, and surround the singularity at $A$ with a (half?)circle of radius $\epsilon$, then take the limit $\epsilon \to 0$. I've tried a rectangle and a semicircle, but without an appropriate function to analyse, it's difficult to say what would work. In any case, for the function I tried (i.e. one with all the $t$'s replaced by $z$'s), I didn't get anywhere. I'm not looking for an answer, just a hint on what function to consider, and on what contour. Edit: Following Mhenni Benghorbal's hint, I arrive at: $$I=\frac{(-1)^{n+1}}{2i}\oint_{|z|=1} \frac{z^{2n}+1}{z^n (z+e^{iA})(z+e^{-iA})}dz$$ The problem is, the singularities are on the unit circle along which I'm integrating. I'm not sure how to deal with that.","For a constant $0<A<\pi$, and natural $n$ I want to find the principal value of the integral: $$\int_0^\pi \frac{\cos nt}{\cos t - \cos A} dt$$ First of all, I'm not certain what function in the complex plane I should look at. Using $$f(z) \equiv \frac{e^{inz}}{e^{iz}-\cos A}$$ or something similar doesn't work, because there is no obvious way to recover the original function from that (no simple relation of one being the imaginary part of the other etc). I tried expressing the difference of cosines as a product of sines, but I don't see how this gets me anywhere. So: what $f(z)$ should I choose? Then, I need to find an appropriate contour on the complex plane, and surround the singularity at $A$ with a (half?)circle of radius $\epsilon$, then take the limit $\epsilon \to 0$. I've tried a rectangle and a semicircle, but without an appropriate function to analyse, it's difficult to say what would work. In any case, for the function I tried (i.e. one with all the $t$'s replaced by $z$'s), I didn't get anywhere. I'm not looking for an answer, just a hint on what function to consider, and on what contour. Edit: Following Mhenni Benghorbal's hint, I arrive at: $$I=\frac{(-1)^{n+1}}{2i}\oint_{|z|=1} \frac{z^{2n}+1}{z^n (z+e^{iA})(z+e^{-iA})}dz$$ The problem is, the singularities are on the unit circle along which I'm integrating. I'm not sure how to deal with that.",,"['complex-analysis', 'improper-integrals']"
46,Diameter of a triangle?,Diameter of a triangle?,,"I've begun reading Stein's Complex Analysis book and found this in a proof of Goursat's theorem for a triangle. It mentions the 'diameter of a triangle' without explaining what is meant by that? Is it the diameter of the inscribed circle, or perhaps the superscribed circle? Or something else entirely? In case you're wondering, Figure 1 doesn't show this diameter.","I've begun reading Stein's Complex Analysis book and found this in a proof of Goursat's theorem for a triangle. It mentions the 'diameter of a triangle' without explaining what is meant by that? Is it the diameter of the inscribed circle, or perhaps the superscribed circle? Or something else entirely? In case you're wondering, Figure 1 doesn't show this diameter.",,"['geometry', 'complex-analysis']"
47,I need to find $\operatorname{Im} f$,I need to find,\operatorname{Im} f,"Let $f$ be analytic such that $\operatorname{Re} ( f'(z))=2y$ and $f(1+i)=2$.  I need to find $\operatorname{Im} f$. I took $f(z)=u(x,y)+i v(x,y)$ but I don't know $\frac{df(z)}{dz}=$ ? in terms of $u(x,y)$ and $v(x,y)$. Could any one help me in that step?","Let $f$ be analytic such that $\operatorname{Re} ( f'(z))=2y$ and $f(1+i)=2$.  I need to find $\operatorname{Im} f$. I took $f(z)=u(x,y)+i v(x,y)$ but I don't know $\frac{df(z)}{dz}=$ ? in terms of $u(x,y)$ and $v(x,y)$. Could any one help me in that step?",,['complex-analysis']
48,Describe all holomorphic functions.,Describe all holomorphic functions.,,"Problem: Describe the class of all holomorphic functions on $\mathbb{C}-\{0\}$ such that $$\sup_{(x,y)\neq (0,0)}\frac{|f(x+iy)|}{|\log(x^2+y^2)|}<\infty.$$ Attempt at a solution: Let $z=x+iy$, then we have: $$\frac{|f(z)|}{|\log|z|^2|}\leq c$$.  So, $|f(z)|\leq c|\log|z|^2|.$ For large enough $z$, we have $|\log|z|^2|\leq |z|^2$ so we get: $$|f(z)|\leq c|z|^2.$$ Now by extented Liouville's Theorem, $f(z)$ must reduce to a polynomial of degree at most two. Is this correct? Thanks!","Problem: Describe the class of all holomorphic functions on $\mathbb{C}-\{0\}$ such that $$\sup_{(x,y)\neq (0,0)}\frac{|f(x+iy)|}{|\log(x^2+y^2)|}<\infty.$$ Attempt at a solution: Let $z=x+iy$, then we have: $$\frac{|f(z)|}{|\log|z|^2|}\leq c$$.  So, $|f(z)|\leq c|\log|z|^2|.$ For large enough $z$, we have $|\log|z|^2|\leq |z|^2$ so we get: $$|f(z)|\leq c|z|^2.$$ Now by extented Liouville's Theorem, $f(z)$ must reduce to a polynomial of degree at most two. Is this correct? Thanks!",,"['complex-analysis', 'analysis']"
49,Modification of Schwarz-Christoffel integral,Modification of Schwarz-Christoffel integral,,"I found two different formulations of the Schwarz-Christoffel formula (e.g. Link1 , p.20 and Link2 , p. 9). The first is \begin{align*} z=w(\zeta)=&A+C\int\limits^{z}\prod\limits_{k=1}^n\left(\zeta-z_k\right)^{\alpha_k-1}d\zeta \end{align*} The second is \begin{align*} z=w(\zeta)=&A+C\int\limits^{z}\prod\limits_{k=1}^n\left(1-\frac{\zeta}{z_k}\right)^{\alpha_k-1}d\zeta \end{align*} In both equations $A$ and $C$ are complex constants, $z_k$ are the coordinates of point $k$ on the unit circle corresponding to the vertex $k$ of the rectangle, $\alpha_k$ are the interior angles of the vertices by means of multiples of $\pi$ and $\zeta$ is a point outside the unit circle such that $|\zeta| > 1$. In the second link on page 20 it is said that: ""Composing the first equation with standard conformal maps leads to variations of the Schwarz-Christoffel formula for mapping from other fundamental domains [...]. The simplest such modification has the unit disk as domain. The vertices then lie  in counterclockwise order on the unit circle and equation one can be transformed to equation two."" Why is this transformation possible for the upper complex half-plane and how is it carried out?","I found two different formulations of the Schwarz-Christoffel formula (e.g. Link1 , p.20 and Link2 , p. 9). The first is \begin{align*} z=w(\zeta)=&A+C\int\limits^{z}\prod\limits_{k=1}^n\left(\zeta-z_k\right)^{\alpha_k-1}d\zeta \end{align*} The second is \begin{align*} z=w(\zeta)=&A+C\int\limits^{z}\prod\limits_{k=1}^n\left(1-\frac{\zeta}{z_k}\right)^{\alpha_k-1}d\zeta \end{align*} In both equations $A$ and $C$ are complex constants, $z_k$ are the coordinates of point $k$ on the unit circle corresponding to the vertex $k$ of the rectangle, $\alpha_k$ are the interior angles of the vertices by means of multiples of $\pi$ and $\zeta$ is a point outside the unit circle such that $|\zeta| > 1$. In the second link on page 20 it is said that: ""Composing the first equation with standard conformal maps leads to variations of the Schwarz-Christoffel formula for mapping from other fundamental domains [...]. The simplest such modification has the unit disk as domain. The vertices then lie  in counterclockwise order on the unit circle and equation one can be transformed to equation two."" Why is this transformation possible for the upper complex half-plane and how is it carried out?",,"['complex-analysis', 'contour-integration', 'conformal-geometry']"
50,Recursion relation for Euler numbers,Recursion relation for Euler numbers,,"I am trying to solve the following: The Euler numbers $E_n$ are defined by the power series expansion $$\frac{1}{\cos z}=\sum_{n=0}^\infty \frac{E_n}{n!}z^n\text{ for }|z|<\pi/2$$ (a)  Show that $E_n=0$ when $n$ is an odd integer. (b) Establish a recursion relation for the sequence. Through research it seems that part a seems well established but I couldn't find a proof. Part (b) I found a formula, but couldn't find how to establish it. Any help appreciated.","I am trying to solve the following: The Euler numbers are defined by the power series expansion (a)  Show that when is an odd integer. (b) Establish a recursion relation for the sequence. Through research it seems that part a seems well established but I couldn't find a proof. Part (b) I found a formula, but couldn't find how to establish it. Any help appreciated.",E_n \frac{1}{\cos z}=\sum_{n=0}^\infty \frac{E_n}{n!}z^n\text{ for }|z|<\pi/2 E_n=0 n,['complex-analysis']
51,Contour integral with branch cut,Contour integral with branch cut,,"This is a question based on the method here: http://en.wikipedia.org/wiki/Methods_of_contour_integration#Example_.28V.29_.E2.80.93_the_square_of_the_logarithm The author chose a contour which requires a bit of a ""magical"" replacement of the original function $\displaystyle f(x)=\frac{\log(x)}{(1+x^2)^2}$ with analysis of $\displaystyle f(z)=\left(\frac{\log(z)}{(1+z^2)}\right)^2$, the need for which becomes apparent later I chose to instead pick a contour that only involves the upper half of the figure drawn, discarding the lower line N and cutting the curve through with the section of the real line $\mathbb R^+$ Numerically I obtain the same result: \begin{align} \int_\gamma f(z)dz &= \int_{\small M}+\int_{\small R^+} \\ &=\int_0^\infty\frac{\log(-x+i\epsilon)}{(1+(-x+i\epsilon)^2)^2}dx+\int_0^\infty f(x)dx \\ 2\pi i\cdot\operatorname{Res}[f(z),i]&=\int_0^\infty\frac{\log(x)+i\pi}{\left(1+x^2\right)^2}dx+\int_0^\infty f(x)dx&\epsilon\to0 \\ 2\pi i\cdot (\frac18(\pi+2i))&=\int_0^\infty\frac{i\pi}{\left(1+x^2\right)^2}dx+2\int_0^\infty f(x) dx\\ -\frac\pi2+\frac{i\pi^2}4&=\frac{i\pi^2}4+2\int_0^\infty f(x) dx\\ \int_0^\infty f(x)dx&=-\frac\pi4 \end{align} Is it just coincidence that I have the same result? Was there any flaw in my method? If not, why did the author pick a contour that requires a nonintuitive analysis which ""as it turns out ... is a multiple of the initial integral that we wish to calculate?""","This is a question based on the method here: http://en.wikipedia.org/wiki/Methods_of_contour_integration#Example_.28V.29_.E2.80.93_the_square_of_the_logarithm The author chose a contour which requires a bit of a ""magical"" replacement of the original function $\displaystyle f(x)=\frac{\log(x)}{(1+x^2)^2}$ with analysis of $\displaystyle f(z)=\left(\frac{\log(z)}{(1+z^2)}\right)^2$, the need for which becomes apparent later I chose to instead pick a contour that only involves the upper half of the figure drawn, discarding the lower line N and cutting the curve through with the section of the real line $\mathbb R^+$ Numerically I obtain the same result: \begin{align} \int_\gamma f(z)dz &= \int_{\small M}+\int_{\small R^+} \\ &=\int_0^\infty\frac{\log(-x+i\epsilon)}{(1+(-x+i\epsilon)^2)^2}dx+\int_0^\infty f(x)dx \\ 2\pi i\cdot\operatorname{Res}[f(z),i]&=\int_0^\infty\frac{\log(x)+i\pi}{\left(1+x^2\right)^2}dx+\int_0^\infty f(x)dx&\epsilon\to0 \\ 2\pi i\cdot (\frac18(\pi+2i))&=\int_0^\infty\frac{i\pi}{\left(1+x^2\right)^2}dx+2\int_0^\infty f(x) dx\\ -\frac\pi2+\frac{i\pi^2}4&=\frac{i\pi^2}4+2\int_0^\infty f(x) dx\\ \int_0^\infty f(x)dx&=-\frac\pi4 \end{align} Is it just coincidence that I have the same result? Was there any flaw in my method? If not, why did the author pick a contour that requires a nonintuitive analysis which ""as it turns out ... is a multiple of the initial integral that we wish to calculate?""",,"['complex-analysis', 'contour-integration']"
52,Is a meromorphic function on the Riemann Sphere completely determined modulo scalar by its zeroes and poles and their orders?,Is a meromorphic function on the Riemann Sphere completely determined modulo scalar by its zeroes and poles and their orders?,,"Let's say that all I know about a function $f$ is that it is meromorphic on $\mathbb{C}_\infty$, and that $\{z_i\}$ is the sets of zeroes of $f$, each one of order $n_i$ and $\{\lambda_j\}$ its set of poles, each one of order $m_i$. Does $f$ gets completely determined, modulo a constant scalar, with only this information? I think that I can show this as it follows: if $f$ is meromorphic on the Riemann Sphere, then it is a rational function. If $\alpha :\mathbb{C}_\infty\rightarrow\mathbb{C}$ is a holomorphic function, then it is constant. If $\alpha$ is not identically zero, then $\alpha f$ is a meromorphic function over $\mathbb{C}_\infty$ with the same set of zeroes and poles with the same orders. It could possibly be a trivial fact but I'm attending some Riemann Surfaces lectures without having a formal graduate course in Complex Analisys in one variable. Please criticize this!","Let's say that all I know about a function $f$ is that it is meromorphic on $\mathbb{C}_\infty$, and that $\{z_i\}$ is the sets of zeroes of $f$, each one of order $n_i$ and $\{\lambda_j\}$ its set of poles, each one of order $m_i$. Does $f$ gets completely determined, modulo a constant scalar, with only this information? I think that I can show this as it follows: if $f$ is meromorphic on the Riemann Sphere, then it is a rational function. If $\alpha :\mathbb{C}_\infty\rightarrow\mathbb{C}$ is a holomorphic function, then it is constant. If $\alpha$ is not identically zero, then $\alpha f$ is a meromorphic function over $\mathbb{C}_\infty$ with the same set of zeroes and poles with the same orders. It could possibly be a trivial fact but I'm attending some Riemann Surfaces lectures without having a formal graduate course in Complex Analisys in one variable. Please criticize this!",,"['complex-analysis', 'riemann-surfaces']"
53,product of harmonic functions,product of harmonic functions,,"""Let $u, v$ be harmonic functions on a region G. Prove that if the product $uv$ is identically zero, then either $u$ or $v$ must be identically zero."" Could sb. give me a hint for this question? I tried all the properties and theorems on harmonic functions (definition, poisson integral, max. principle, passed a holomorphic function,..), but could go nowhere. Thanks.","""Let $u, v$ be harmonic functions on a region G. Prove that if the product $uv$ is identically zero, then either $u$ or $v$ must be identically zero."" Could sb. give me a hint for this question? I tried all the properties and theorems on harmonic functions (definition, poisson integral, max. principle, passed a holomorphic function,..), but could go nowhere. Thanks.",,['complex-analysis']
54,"If $\operatorname{Re}f^\prime > 0$ on a convex domain, then $f$ is one-to-one.","If  on a convex domain, then  is one-to-one.",\operatorname{Re}f^\prime > 0 f,"Let $f(z)$ be analytic on a convex region $D \subset \mathbb{C}$. If $\mathrm{Re}f'(z)>0,\forall z\in D$, then show that $f(z)$ is a one-to-one function, that is, if $z_1\ne z_2,$ then $f(z_1)\ne f(z_2)$.","Let $f(z)$ be analytic on a convex region $D \subset \mathbb{C}$. If $\mathrm{Re}f'(z)>0,\forall z\in D$, then show that $f(z)$ is a one-to-one function, that is, if $z_1\ne z_2,$ then $f(z_1)\ne f(z_2)$.",,['complex-analysis']
55,Branch cut question,Branch cut question,,"I have a function $$f(z)=(z-1)^{3/5}(z+1)^{2/5}$$ and I have the branch of this function chosen such that $$-\pi<\arg(z\pm1)\leq\pi$$ How do I show that a branch cut is not required on the section $(-\infty,1)$ of the real axis? I have defined $(z-1)=r_1e^{i\theta_1}$ and $(z+1)=r_2e^{i\theta_2}$ and thus can get $f(z)$ into the form $$r_1^{3/5}r_2^{2/5}e^{i/5(3\theta_1+2\theta_2)}$$ Now here is where I get confused but I think I need to find $f(x\pm0i)$on the section $(\infty,1)$ of the real axis and determine continuity but I don't know how to do this for this specific example and would appreciate some help. Thank you.","I have a function $$f(z)=(z-1)^{3/5}(z+1)^{2/5}$$ and I have the branch of this function chosen such that $$-\pi<\arg(z\pm1)\leq\pi$$ How do I show that a branch cut is not required on the section $(-\infty,1)$ of the real axis? I have defined $(z-1)=r_1e^{i\theta_1}$ and $(z+1)=r_2e^{i\theta_2}$ and thus can get $f(z)$ into the form $$r_1^{3/5}r_2^{2/5}e^{i/5(3\theta_1+2\theta_2)}$$ Now here is where I get confused but I think I need to find $f(x\pm0i)$on the section $(\infty,1)$ of the real axis and determine continuity but I don't know how to do this for this specific example and would appreciate some help. Thank you.",,['complex-analysis']
56,$P(z)$ defines a polynomial,defines a polynomial,P(z),"Suppose that $f$ is analytic in a simply connected domain $D$ containing distinct points $z_1, z_2 ,\ldots,z_n $ and that $\gamma$ is simple closed curve  enclosing $z_1, z_2 ,\ldots,z_n $. Set $w(z)= \prod_{k=1}^n (z-z_k)$ . Prove that $$P(z) =\int_{\gamma}  \frac {f(\zeta)}{w(\zeta)} \frac{w(\zeta)-w(z)}{\zeta-z}d\zeta$$ defines a polynomial of degree $n-1$ satisfying $P(z_k) =f(z_k), k =1,2,3,\ldots,n.$ I don't know what thought I am suppose to present here. What I just know is to do the partial fraction of the $w(z)$. Then I just stuck not knowing the fact I am using here. This is actually a recent comprehensive exam question which I could not solve. My professor gave me some hint but that also did not help. The idea of partial fraction came out of his mouth. But I don't remember what he told me to do to complete the problem. I really wish to see the detail solution of the problem. Thanks in advance. Addendum Partial Fraction of $\frac{1}{w(\zeta)}= \frac {1}{\prod _{k=1}^n (\zeta-z_k)}$ is given by  $$\frac {A_1}{\zeta-z_1}+\frac {A_2}{\zeta-z_2}+\cdots+\frac {A_n}{\zeta-z_n}$$ Where each $A_i = \frac{1} {\prod_{j=1}^n z_i-z_j} , j \neq i$ Sorry I missed that not equal to part, I don't know how to accomodate that in the product, any edit appreciated.","Suppose that $f$ is analytic in a simply connected domain $D$ containing distinct points $z_1, z_2 ,\ldots,z_n $ and that $\gamma$ is simple closed curve  enclosing $z_1, z_2 ,\ldots,z_n $. Set $w(z)= \prod_{k=1}^n (z-z_k)$ . Prove that $$P(z) =\int_{\gamma}  \frac {f(\zeta)}{w(\zeta)} \frac{w(\zeta)-w(z)}{\zeta-z}d\zeta$$ defines a polynomial of degree $n-1$ satisfying $P(z_k) =f(z_k), k =1,2,3,\ldots,n.$ I don't know what thought I am suppose to present here. What I just know is to do the partial fraction of the $w(z)$. Then I just stuck not knowing the fact I am using here. This is actually a recent comprehensive exam question which I could not solve. My professor gave me some hint but that also did not help. The idea of partial fraction came out of his mouth. But I don't remember what he told me to do to complete the problem. I really wish to see the detail solution of the problem. Thanks in advance. Addendum Partial Fraction of $\frac{1}{w(\zeta)}= \frac {1}{\prod _{k=1}^n (\zeta-z_k)}$ is given by  $$\frac {A_1}{\zeta-z_1}+\frac {A_2}{\zeta-z_2}+\cdots+\frac {A_n}{\zeta-z_n}$$ Where each $A_i = \frac{1} {\prod_{j=1}^n z_i-z_j} , j \neq i$ Sorry I missed that not equal to part, I don't know how to accomodate that in the product, any edit appreciated.",,['complex-analysis']
57,integral of complex logarithm,integral of complex logarithm,,"Consider the integral $$I=\int_0^{2\pi}\log\left|re^{it}-a\right|\,dt$$ where $a$ is a complex number and $0<r<|a|$. We have $$I=\operatorname{Re}\left(\int_0^{2\pi}\log\left|re^{it}-a\right|\,dt\right)$$ Let $\gamma=\partial D(0,r)$. Then $$\begin{align}\int_\gamma\frac{\log(z-a)}{iz}\,dz&=\int_0^{2\pi}\frac{\log\left(re^{it}-a\right)} {ire^{it}}rie^{it}\,dt\\ &=\int_0^{2\pi}\log\left(re^{it}-a\right)\,dt\end{align}$$ Thus $$I=\operatorname{Re}\left(\int_{\gamma}\frac{\log(z-a)}{iz}\,dz\right)$$ Now my problem is that $\log(z-a)$ is not holomorphic in $D(0,r)$, so i can't use Cauchy's integral formula to compute $I$. How can I solve this?","Consider the integral $$I=\int_0^{2\pi}\log\left|re^{it}-a\right|\,dt$$ where $a$ is a complex number and $0<r<|a|$. We have $$I=\operatorname{Re}\left(\int_0^{2\pi}\log\left|re^{it}-a\right|\,dt\right)$$ Let $\gamma=\partial D(0,r)$. Then $$\begin{align}\int_\gamma\frac{\log(z-a)}{iz}\,dz&=\int_0^{2\pi}\frac{\log\left(re^{it}-a\right)} {ire^{it}}rie^{it}\,dt\\ &=\int_0^{2\pi}\log\left(re^{it}-a\right)\,dt\end{align}$$ Thus $$I=\operatorname{Re}\left(\int_{\gamma}\frac{\log(z-a)}{iz}\,dz\right)$$ Now my problem is that $\log(z-a)$ is not holomorphic in $D(0,r)$, so i can't use Cauchy's integral formula to compute $I$. How can I solve this?",,"['complex-analysis', 'complex-integration']"
58,Locus of $0<\arg(\frac{z+i}{z-i})<\pi/4$,Locus of,0<\arg(\frac{z+i}{z-i})<\pi/4,"I am studying Complex Analysis on my own and am having a bit of difficulty with finding the locus of $0<\arg(\frac{z+i}{z-i})<\pi/4$ rigorously. We can see geometrically (using Inscribed    Angle Property ) that the locus is the part of the plane that's to the right of the y-axis, minus a certain circle on the center (I calculated this circle to be $(x-1)^2+y^2=2$ specifically), but can this be calculated without this sort of geometrical intuition? ATTEMPT: I tried plugging $z=x+iy$. We get $$\Re(z)=\frac{x^2+y^2-1}{(x^2+(y-1)^2}$$ and $$\Im(z)=\frac{2x}{(x^2+(y-1)^2}$$ So my thought was to try and compare these two to $r\cos(t)$ and $r\sin(t)$ respectively, and then maybe use the formula $\sin^2(t)+\cos^2(t)=1$, but I didn't get very far.","I am studying Complex Analysis on my own and am having a bit of difficulty with finding the locus of $0<\arg(\frac{z+i}{z-i})<\pi/4$ rigorously. We can see geometrically (using Inscribed    Angle Property ) that the locus is the part of the plane that's to the right of the y-axis, minus a certain circle on the center (I calculated this circle to be $(x-1)^2+y^2=2$ specifically), but can this be calculated without this sort of geometrical intuition? ATTEMPT: I tried plugging $z=x+iy$. We get $$\Re(z)=\frac{x^2+y^2-1}{(x^2+(y-1)^2}$$ and $$\Im(z)=\frac{2x}{(x^2+(y-1)^2}$$ So my thought was to try and compare these two to $r\cos(t)$ and $r\sin(t)$ respectively, and then maybe use the formula $\sin^2(t)+\cos^2(t)=1$, but I didn't get very far.",,['complex-analysis']
59,Singularities of $e^{z - \frac{1}{z}}$,Singularities of,e^{z - \frac{1}{z}},I believe $e^{z - \frac{1}{z}}$ has essential singularities at $z = 0$ and $z = \infty$ (in both cases because of a $\frac{1}{z}$ in the exponent) but I'm having a hard time proving this. How can one show this?,I believe $e^{z - \frac{1}{z}}$ has essential singularities at $z = 0$ and $z = \infty$ (in both cases because of a $\frac{1}{z}$ in the exponent) but I'm having a hard time proving this. How can one show this?,,"['complex-analysis', 'power-series', 'singularity-theory']"
60,analytic extension,analytic extension,,Suppose that $f$ is analytic in the annulus $1<|z|<2$ and there exist a sequence of polynomials converging to $f$ uniformly on every compact subset of this annulus.  Show $f$ has an analytic extension to all of the disc $|z|<2$.,Suppose that $f$ is analytic in the annulus $1<|z|<2$ and there exist a sequence of polynomials converging to $f$ uniformly on every compact subset of this annulus.  Show $f$ has an analytic extension to all of the disc $|z|<2$.,,['complex-analysis']
61,Complex Analysis - Question about branch cuts,Complex Analysis - Question about branch cuts,,"I am having trouble understanding how branch cuts work. For example, the function $f(z)= \sqrt{z}$ has a branch cut where you reject the negative real axis. But how do you define the output so that the function is 1-1 and onto? For example what is $f(1 + i)$? And $f(1-i)$? Also does the function containing the branch cut have to be analytic?","I am having trouble understanding how branch cuts work. For example, the function $f(z)= \sqrt{z}$ has a branch cut where you reject the negative real axis. But how do you define the output so that the function is 1-1 and onto? For example what is $f(1 + i)$? And $f(1-i)$? Also does the function containing the branch cut have to be analytic?",,"['complex-analysis', 'branch-cuts']"
62,Continuous function on the unit circle must be $c\bar{z}$,Continuous function on the unit circle must be,c\bar{z},"This is a homework problem, so hints or rough outlines are strongly preferred to a full solution. Problem. Let $C$ be the unit circle.  Suppose the continuous function $f : C \rightarrow \mathbb{C}$ on the unit circle satisfies $|f(z)| \leq M$ and $\left|\int_{C} f(z)\;dz\right| = 2\pi M$.  Show that $f(z) = c\bar{z}$ for some constant $c$ with modulus $|c| = M$. I've been able to argue $|f(z)| = M$ for all $z \in C$ by assuming this is not the case and finding a contradiction using continuity, the given identity, and the $ML$-inequality.  This is clearly necessary, but may not be useful to solve the problem.","This is a homework problem, so hints or rough outlines are strongly preferred to a full solution. Problem. Let $C$ be the unit circle.  Suppose the continuous function $f : C \rightarrow \mathbb{C}$ on the unit circle satisfies $|f(z)| \leq M$ and $\left|\int_{C} f(z)\;dz\right| = 2\pi M$.  Show that $f(z) = c\bar{z}$ for some constant $c$ with modulus $|c| = M$. I've been able to argue $|f(z)| = M$ for all $z \in C$ by assuming this is not the case and finding a contradiction using continuity, the given identity, and the $ML$-inequality.  This is clearly necessary, but may not be useful to solve the problem.",,['complex-analysis']
63,"3 holomorphic functions, sum of absolute values does not have maximum","3 holomorphic functions, sum of absolute values does not have maximum",,"I have the following problem: Let $f,g,h$ be holomorphic functions (non-constant) in some domain $D$. Show that the function $F(z):=|f(z)|+|g(z)|+|h(z)|$ has no local maximum in this domain $D$. Can someone give a sketch of the proof?","I have the following problem: Let $f,g,h$ be holomorphic functions (non-constant) in some domain $D$. Show that the function $F(z):=|f(z)|+|g(z)|+|h(z)|$ has no local maximum in this domain $D$. Can someone give a sketch of the proof?",,['complex-analysis']
64,A tricky residue theorem problem,A tricky residue theorem problem,,"I thought I was fairly well-versed with using the residue theorem to evaluate improper integrals, but one problem has been giving me grief. How does one compute the integral $$\int_{-\infty}^{\infty}\frac{e^{\alpha+ix}}{(\alpha+ix)^\beta} dx$$ for real numbers $\alpha>1$, $\beta>0$? Note that $\beta$ is not necessarily an integer, which restricts the contours that can be used (ie. one needs to use contours on which a branch of logarithm can be defined).","I thought I was fairly well-versed with using the residue theorem to evaluate improper integrals, but one problem has been giving me grief. How does one compute the integral $$\int_{-\infty}^{\infty}\frac{e^{\alpha+ix}}{(\alpha+ix)^\beta} dx$$ for real numbers $\alpha>1$, $\beta>0$? Note that $\beta$ is not necessarily an integer, which restricts the contours that can be used (ie. one needs to use contours on which a branch of logarithm can be defined).",,['complex-analysis']
65,Showing the inequality $\frac{|f^{'}(z)|}{1-|f(z)|^{2}} \leq \frac{1}{1-|z|^{2}}$,Showing the inequality,\frac{|f^{'}(z)|}{1-|f(z)|^{2}} \leq \frac{1}{1-|z|^{2}},"I am trying to show if $|f(z)| \leq 1$, $|z| \leq 1$, then \begin{equation} \frac{|f^{'}(z)|}{1-|f(z)|^{2}} \leq \frac{1}{1-|z|^{2}} \end{equation}. I have used Cauchy's Inequality to derive $|f^{'}(z)| \leq \frac{1}{1-|z|}$ yet I still couldn't get the result I need. Also I am trying to find when equality would hold. Any tips or help would be much appreciated. Thanks!","I am trying to show if $|f(z)| \leq 1$, $|z| \leq 1$, then \begin{equation} \frac{|f^{'}(z)|}{1-|f(z)|^{2}} \leq \frac{1}{1-|z|^{2}} \end{equation}. I have used Cauchy's Inequality to derive $|f^{'}(z)| \leq \frac{1}{1-|z|}$ yet I still couldn't get the result I need. Also I am trying to find when equality would hold. Any tips or help would be much appreciated. Thanks!",,['complex-analysis']
66,Problem of Liouville's theorem,Problem of Liouville's theorem,,"Here is my problem: Let $f(z)$ be an entire function such that  $|f '(z)| < |f(z)|$ for all $z \in \mathbb{C}$, Show that there exists a constant A such that $|f(z)| < A*e^{|z|}$ for all $z \in \mathbb{C}$. I am trying to use Liouville's theorem  to prove and try to set $g(z)=|f '(z)|/|f(z)| < 1$ and then g(z) is constant. I am not sure if my thinking is right and how to prove this problem?  Thanks","Here is my problem: Let $f(z)$ be an entire function such that  $|f '(z)| < |f(z)|$ for all $z \in \mathbb{C}$, Show that there exists a constant A such that $|f(z)| < A*e^{|z|}$ for all $z \in \mathbb{C}$. I am trying to use Liouville's theorem  to prove and try to set $g(z)=|f '(z)|/|f(z)| < 1$ and then g(z) is constant. I am not sure if my thinking is right and how to prove this problem?  Thanks",,['complex-analysis']
67,"How to compute the infinite tower of the complex number $i$, that is$ ^{\infty}i$","How to compute the infinite tower of the complex number , that is",i  ^{\infty}i,Let $x = i^{i^{i^{i^{.^{.^{.{^ \infty}}}}}}}$. This is the solution of the equation $i^x - x = 0 $ . I used Euler's identity to find a solution. But I haven't yet found the real and imaginary parts of the solution. Are there more solutions? If so why did I miss them?,Let $x = i^{i^{i^{i^{.^{.^{.{^ \infty}}}}}}}$. This is the solution of the equation $i^x - x = 0 $ . I used Euler's identity to find a solution. But I haven't yet found the real and imaginary parts of the solution. Are there more solutions? If so why did I miss them?,,['complex-analysis']
68,Mapping that takes unit circle to unit circle,Mapping that takes unit circle to unit circle,,"Let $A \subset \mathbb{C} $ be an open set containing the closed unit disc. Let $f$ be an analytic function from $A$ to $\mathbb{C}$ such that $|f(z)|=1$ if $|z|=1$. Does it follow that $f(z) = a z^{n} \frac{cz^{m}-b}{1-cz^{m}\bar{b}} $ for some $a,b,c \in \mathbb{C}$ s.t. $|c|=1$ $|a|=1$, $|b|<1$ and some $n,m\ge 0 $?","Let $A \subset \mathbb{C} $ be an open set containing the closed unit disc. Let $f$ be an analytic function from $A$ to $\mathbb{C}$ such that $|f(z)|=1$ if $|z|=1$. Does it follow that $f(z) = a z^{n} \frac{cz^{m}-b}{1-cz^{m}\bar{b}} $ for some $a,b,c \in \mathbb{C}$ s.t. $|c|=1$ $|a|=1$, $|b|<1$ and some $n,m\ge 0 $?",,['complex-analysis']
69,What is the meaning of $z \to \infty $ when working with complex numbers?,What is the meaning of  when working with complex numbers?,z \to \infty ,"Let $z=x+iy$ .  If I am evaluating $f(z)$ as $z$ tends to infinity, I should assume this means $x$ tends to infinity and $y$ tends to infinity? I think this is the case but wanted to confirm.  I realized this when checking the solution to a problem asking for the limit of $f(z)=e^z$ as $z$ tends to infinity.  At first I simply thought infinity was the answer as I was ""thinking"" of $z$ as infinity $+ 0i$ , but I see that it's periodic when thinking of $x$ and $y$ both tending to infinity.  Obviously if it said the limit as $z$ tends to $5$ , the answer would be $e^5$ , but I suppose when thinking of infinity we consider both the real and imaginary parts to tend to infinity?","Let .  If I am evaluating as tends to infinity, I should assume this means tends to infinity and tends to infinity? I think this is the case but wanted to confirm.  I realized this when checking the solution to a problem asking for the limit of as tends to infinity.  At first I simply thought infinity was the answer as I was ""thinking"" of as infinity , but I see that it's periodic when thinking of and both tending to infinity.  Obviously if it said the limit as tends to , the answer would be , but I suppose when thinking of infinity we consider both the real and imaginary parts to tend to infinity?",z=x+iy f(z) z x y f(z)=e^z z z + 0i x y z 5 e^5,"['complex-analysis', 'functions', 'complex-numbers', 'infinity']"
70,Residue of $e^{\frac {1} {\sin z}}$ at $z = 0$,Residue of  at,e^{\frac {1} {\sin z}} z = 0,"I am a beginner in complex analysis. I have come across a problem that, in essence, asks me to find the residue of $e^{\frac{1}{\sin z}}$ at the isolated essential singularity $z=0$ . Until now, I have only seen problems where the sine is multiplied or divided to an analytic function, in which case it sufficed to expand the Taylor series of $\sin z$ , or even consider only the linear term of it. However, in this case, $\sin z$ is not only inverted but also exponentiated, which made it too difficult for me to directly write the Laurent series of the function. I briefly tried writing $$ \csc z = \sum_{n=-1}^{\infty} a_n z^n$$ because it has a simple pole at $z = 0$ , but exponentiating it lead to a representation of the residue as an infinite sum including $a_n$ , which I had no idea how to calculate using the inductive formlua for $a_n$ . I would like to ask what kind of techniques can be used in such problems, when complicated formulae are composed and inverted and such, making a direct derivation of Laurent series inapplicable. Thank you in advance.","I am a beginner in complex analysis. I have come across a problem that, in essence, asks me to find the residue of at the isolated essential singularity . Until now, I have only seen problems where the sine is multiplied or divided to an analytic function, in which case it sufficed to expand the Taylor series of , or even consider only the linear term of it. However, in this case, is not only inverted but also exponentiated, which made it too difficult for me to directly write the Laurent series of the function. I briefly tried writing because it has a simple pole at , but exponentiating it lead to a representation of the residue as an infinite sum including , which I had no idea how to calculate using the inductive formlua for . I would like to ask what kind of techniques can be used in such problems, when complicated formulae are composed and inverted and such, making a direct derivation of Laurent series inapplicable. Thank you in advance.",e^{\frac{1}{\sin z}} z=0 \sin z \sin z  \csc z = \sum_{n=-1}^{\infty} a_n z^n z = 0 a_n a_n,"['complex-analysis', 'residue-calculus']"
71,"Can we show: $\int_{-\pi/2}^{\pi/2}\sin\cos\tan x\cosh\sin\tan x\,\mathrm{d}x=\pi\sin(1/e)$ with contours?",Can we show:  with contours?,"\int_{-\pi/2}^{\pi/2}\sin\cos\tan x\cosh\sin\tan x\,\mathrm{d}x=\pi\sin(1/e)","$\newcommand{\d}{\,\mathrm{d}}$ By converting $\sin,\cos$ into their exponential forms and expanding the exponential into a series, it can be quickly shown using “normal” techniques that: $$\int_0^\infty\frac{\sin\cos x\cosh\sin x}{1+x^2}\,\mathrm{d}x=\frac{\pi}{2}\sin(1/e)$$ Which is equivalent to: $$\int_{-\pi/2}^{\pi/2}\sin\cos\tan(\vartheta)\cosh\sin\tan(\vartheta)\d\vartheta=\pi\cdot\sin(1/e)$$ This seems amenable to using contour integration (this approach is harder but of mathematical and - for me - educational interest). A notable complication is that this integral is improper. If we pass to $z=e^{it}$ , we must also take an improper contour integral, i.e: For $\varepsilon>0$ small, let $\gamma_{\varepsilon}$ be the contour $t\mapsto e^{it}$ restricted to $[\varepsilon-\pi/2,\pi/2-\varepsilon]$ . Then it suffices to show: $$2\pi i\cdot\sin(1/e)=\lim_{\varepsilon\to0^+}\oint_{\gamma_{\varepsilon}}2\sin\cosh\frac{z^2-1}{z^2+1}\cos\sinh\frac{z^2-1}{z^2+1}\cdot\frac{1}{z}\d z$$ We can use $\sin(a+b)+\sin(a-b)=2\sin(a)\cos(b)$ and $\cosh(x)+\sinh(x)=e^x,\,\cosh(x)-\sinh(x)=e^{-x}$ and instead ask to show: $$2\pi i\cdot\sin(1/e)=\lim_{\varepsilon\to0^+}\oint_{\gamma_{\varepsilon}}\frac{\sin(\exp(r(z)))+\sin(\exp(-r(z)))}{z}\d z=:\lim_{\varepsilon\to0^+}J_{\varepsilon}$$ Where $r(z)=1-2(1+z^2)^{-1}$ . What is promising about this: if one were to close the contour in such a way that it winds once around the origin, then the integral would evaluate to $2\pi i[\sin(e)+\sin(1/e)]$ by the residue theorem, $r(0)=-1$ . The standard thing to do here might be to add the contours $\gamma_{\pm}:[0,\pi]\to\Bbb C$ , $t\mapsto\pm i\mp\varepsilon e^{it}$ . Then: $$J_{\varepsilon}=2\pi i[\sin(1/e)+\sin(e)]+\oint_{\gamma_+\cup\,\gamma_-}$$ So we “just” need to show: $$\lim_{\varepsilon\to0^+}\oint_{\gamma_+\cup\,\gamma_-}\frac{\sin\exp(r(z))+\sin\exp(-r(z))}{z}\d z=-2\pi i\cdot\sin(e)$$ Furthermore, $r$ is even and $\gamma_+(t)=-\gamma_-(t)$ so  this symmetry allows us to instead show: $$\tag{$\ast$}\lim_{\varepsilon\to0+}\oint_{\gamma_+}\frac{\sin\exp(r(z))+\sin\exp(-r(z))}{z}\d z\overset{?}{=}-\pi i\cdot\sin(e)$$ But this is very difficult (for me). Substituting $z=\gamma_{\pm}(t)$ gives a very ugly mess. The asymptotics of the integrand are essentially $\sin\exp(O(\varepsilon^{-2}))$ and upon expansion into real and imaginary parts, we get a mess of $\sin(a)\cosh(b)+\cdots$ where $b=\sin(\sin(\sin(\cdot)))$ (more or less) and the asymptotics of that seem intractable. Equally, I might be overthinking this and getting lost in irrelevant details. A realised (?) version of our goal: $$\pi\cdot\sin(e)=\lim_{\varepsilon\to0^+}\varepsilon\cdot\int_0^\pi\frac{\sin\exp\left(1+\frac{2}{\varepsilon\cdot e^{it}(2i-\varepsilon\cdot e^{it})}\right)+\sin\exp\left(-1-\frac{2}{\varepsilon\cdot e^{it}(2i-\varepsilon\cdot e^{it})}\right)}{i\cdot e^{-it}-\varepsilon}\d t$$ The question: does anyone know how to continue, i.e. how to successfully show $(\ast)$ ? I’d really like to learn from this, as an example of more advanced asymptotic analysis than I’m used to. But perhaps it really is too difficult: in which case, I’d be happy to see alternative contour methods. Many thanks.","By converting into their exponential forms and expanding the exponential into a series, it can be quickly shown using “normal” techniques that: Which is equivalent to: This seems amenable to using contour integration (this approach is harder but of mathematical and - for me - educational interest). A notable complication is that this integral is improper. If we pass to , we must also take an improper contour integral, i.e: For small, let be the contour restricted to . Then it suffices to show: We can use and and instead ask to show: Where . What is promising about this: if one were to close the contour in such a way that it winds once around the origin, then the integral would evaluate to by the residue theorem, . The standard thing to do here might be to add the contours , . Then: So we “just” need to show: Furthermore, is even and so  this symmetry allows us to instead show: But this is very difficult (for me). Substituting gives a very ugly mess. The asymptotics of the integrand are essentially and upon expansion into real and imaginary parts, we get a mess of where (more or less) and the asymptotics of that seem intractable. Equally, I might be overthinking this and getting lost in irrelevant details. A realised (?) version of our goal: The question: does anyone know how to continue, i.e. how to successfully show ? I’d really like to learn from this, as an example of more advanced asymptotic analysis than I’m used to. But perhaps it really is too difficult: in which case, I’d be happy to see alternative contour methods. Many thanks.","\newcommand{\d}{\,\mathrm{d}} \sin,\cos \int_0^\infty\frac{\sin\cos x\cosh\sin x}{1+x^2}\,\mathrm{d}x=\frac{\pi}{2}\sin(1/e) \int_{-\pi/2}^{\pi/2}\sin\cos\tan(\vartheta)\cosh\sin\tan(\vartheta)\d\vartheta=\pi\cdot\sin(1/e) z=e^{it} \varepsilon>0 \gamma_{\varepsilon} t\mapsto e^{it} [\varepsilon-\pi/2,\pi/2-\varepsilon] 2\pi i\cdot\sin(1/e)=\lim_{\varepsilon\to0^+}\oint_{\gamma_{\varepsilon}}2\sin\cosh\frac{z^2-1}{z^2+1}\cos\sinh\frac{z^2-1}{z^2+1}\cdot\frac{1}{z}\d z \sin(a+b)+\sin(a-b)=2\sin(a)\cos(b) \cosh(x)+\sinh(x)=e^x,\,\cosh(x)-\sinh(x)=e^{-x} 2\pi i\cdot\sin(1/e)=\lim_{\varepsilon\to0^+}\oint_{\gamma_{\varepsilon}}\frac{\sin(\exp(r(z)))+\sin(\exp(-r(z)))}{z}\d z=:\lim_{\varepsilon\to0^+}J_{\varepsilon} r(z)=1-2(1+z^2)^{-1} 2\pi i[\sin(e)+\sin(1/e)] r(0)=-1 \gamma_{\pm}:[0,\pi]\to\Bbb C t\mapsto\pm i\mp\varepsilon e^{it} J_{\varepsilon}=2\pi i[\sin(1/e)+\sin(e)]+\oint_{\gamma_+\cup\,\gamma_-} \lim_{\varepsilon\to0^+}\oint_{\gamma_+\cup\,\gamma_-}\frac{\sin\exp(r(z))+\sin\exp(-r(z))}{z}\d z=-2\pi i\cdot\sin(e) r \gamma_+(t)=-\gamma_-(t) \tag{\ast}\lim_{\varepsilon\to0+}\oint_{\gamma_+}\frac{\sin\exp(r(z))+\sin\exp(-r(z))}{z}\d z\overset{?}{=}-\pi i\cdot\sin(e) z=\gamma_{\pm}(t) \sin\exp(O(\varepsilon^{-2})) \sin(a)\cosh(b)+\cdots b=\sin(\sin(\sin(\cdot))) \pi\cdot\sin(e)=\lim_{\varepsilon\to0^+}\varepsilon\cdot\int_0^\pi\frac{\sin\exp\left(1+\frac{2}{\varepsilon\cdot e^{it}(2i-\varepsilon\cdot e^{it})}\right)+\sin\exp\left(-1-\frac{2}{\varepsilon\cdot e^{it}(2i-\varepsilon\cdot e^{it})}\right)}{i\cdot e^{-it}-\varepsilon}\d t (\ast)","['complex-analysis', 'asymptotics', 'contour-integration']"
72,non negativity of Fourier coefficients of modular forms,non negativity of Fourier coefficients of modular forms,,"I would like to know if there exists some criteria to test whether a given modular form, of level N with integral or half-integral weight, has non negative coefficients. I am also interested in results saying when certain coefficients are necessarily non negative. Any research paper or reference is welcome !","I would like to know if there exists some criteria to test whether a given modular form, of level N with integral or half-integral weight, has non negative coefficients. I am also interested in results saying when certain coefficients are necessarily non negative. Any research paper or reference is welcome !",,"['complex-analysis', 'number-theory', 'modular-forms']"
73,Nice proof that an expectation vanishes?,Nice proof that an expectation vanishes?,,"Let $X$ and $Y$ be independent standard normal random variables. I have an ugly(ish) proof that for any $\epsilon>0$ , $ \mathbb E\log\|e_1+\epsilon(X,Y)\|=0 $ , where $e_1$ is the unit vector in the first coordinate direction (or more generally $\mathbb E\log\|v+\epsilon N\|=\log\|v\|$ for any non-zero vector (where $N=(X,Y)$ )). My proof is based on using polar coordinates to describe the distribution of $(X,Y)$ and then complex analysis for a fixed $r$ , taking care to deal with the branch cut of the logarithm in the case when $\epsilon r>1$ . It feels that the result should be well known and/or there should be a cleaner approach. Does anyone have either a reference for this fact or a nice proof? EDIT : In the light of the answer by angryavian below, it seems that my ""proof"" was over-optimistic. In the case when $\epsilon r>1$ , there is cancellation of one of the real and imaginary coordinates along the branch cut, but not the other one. I now think the expectation is not zero, but rather $\int_{1/\epsilon}^\infty 2\pi\log(r\epsilon)re^{-r^2/2}$ . This agrees nicely with angryavian's simulations in the case $\epsilon=1$ .","Let and be independent standard normal random variables. I have an ugly(ish) proof that for any , , where is the unit vector in the first coordinate direction (or more generally for any non-zero vector (where )). My proof is based on using polar coordinates to describe the distribution of and then complex analysis for a fixed , taking care to deal with the branch cut of the logarithm in the case when . It feels that the result should be well known and/or there should be a cleaner approach. Does anyone have either a reference for this fact or a nice proof? EDIT : In the light of the answer by angryavian below, it seems that my ""proof"" was over-optimistic. In the case when , there is cancellation of one of the real and imaginary coordinates along the branch cut, but not the other one. I now think the expectation is not zero, but rather . This agrees nicely with angryavian's simulations in the case .","X Y \epsilon>0 
\mathbb E\log\|e_1+\epsilon(X,Y)\|=0
 e_1 \mathbb E\log\|v+\epsilon N\|=\log\|v\| N=(X,Y) (X,Y) r \epsilon r>1 \epsilon r>1 \int_{1/\epsilon}^\infty 2\pi\log(r\epsilon)re^{-r^2/2} \epsilon=1","['complex-analysis', 'normal-distribution']"
74,Difference between the properties of differentiation in $\mathbb{C}$ and $\mathbb{R}^2$,Difference between the properties of differentiation in  and,\mathbb{C} \mathbb{R}^2,"I'm taking a course on Complex Calculus and I've been provided with the following definition for the derivative of a function: Definition : Let $f$ be a function whose domain contains a neighborhood of a point $z_0$ . The derivative of $f$ at $z_0$ is the limit $$f'(z_0) = \lim_{z\to z_0} \frac{f(z) - f(z_0)}{z - z_0}$$ But for a course on Multivariable Calculus, I was provided with the following definition (from Munkres' Analysis on Manifolds): Definition : Let $A \subset \mathbb{R}^m$ , let $f: A\to \mathbb{R}^n$ . Suppose $A$ contains a neighborhood of a . We say $f$ is differentiable at a if there is an n by m matrix B such that $$\frac{f(\mathbf{a + h})-f(\mathbf{a}) - B\cdot \mathbf{h}}{|\mathbf{h}|}\ \text{as}\ \mathbf{h}\to 0.$$ My problem here is that my instructor stated that any function $f:D\to \mathbb{C},\ D\subset \mathbb{C}$ that has continuous partial derivatives which satisfy the Cauchy-Riemann equations at some $z\in D$ is also differentiable at $z$ . But this was not the case for a function $g:D\to \mathbb{R}^2,\ D\in \mathbb{R}^2$ using the second definition for a derivative. To my knowledge, $\mathbb{C} \cong \mathbb{R}^2$ when viewed as $\mathbb{R}$ -modules, so I would expect the differential operator to behave the same as well. Why is it the case that these two definitions do not agree? Are these two definitions describing different things? Is any definition encapsulating the other? (If that makes any sense) Edit : Initially, I stated that my instructor specified that every complex function continuous at a point is also differentiable at that point. This was an error on my part, as I probably mixed up the statement. I rephrased my question, though the answers are still satisfactory and explanatory of the differences between these two definitions.","I'm taking a course on Complex Calculus and I've been provided with the following definition for the derivative of a function: Definition : Let be a function whose domain contains a neighborhood of a point . The derivative of at is the limit But for a course on Multivariable Calculus, I was provided with the following definition (from Munkres' Analysis on Manifolds): Definition : Let , let . Suppose contains a neighborhood of a . We say is differentiable at a if there is an n by m matrix B such that My problem here is that my instructor stated that any function that has continuous partial derivatives which satisfy the Cauchy-Riemann equations at some is also differentiable at . But this was not the case for a function using the second definition for a derivative. To my knowledge, when viewed as -modules, so I would expect the differential operator to behave the same as well. Why is it the case that these two definitions do not agree? Are these two definitions describing different things? Is any definition encapsulating the other? (If that makes any sense) Edit : Initially, I stated that my instructor specified that every complex function continuous at a point is also differentiable at that point. This was an error on my part, as I probably mixed up the statement. I rephrased my question, though the answers are still satisfactory and explanatory of the differences between these two definitions.","f z_0 f z_0 f'(z_0) = \lim_{z\to z_0} \frac{f(z) - f(z_0)}{z - z_0} A \subset \mathbb{R}^m f: A\to \mathbb{R}^n A f \frac{f(\mathbf{a + h})-f(\mathbf{a}) - B\cdot \mathbf{h}}{|\mathbf{h}|}\ \text{as}\ \mathbf{h}\to 0. f:D\to \mathbb{C},\ D\subset \mathbb{C} z\in D z g:D\to \mathbb{R}^2,\ D\in \mathbb{R}^2 \mathbb{C} \cong \mathbb{R}^2 \mathbb{R}","['complex-analysis', 'multivariable-calculus', 'derivatives']"
75,"Example of a complex function with ""essential singularity"" all along the unit circle","Example of a complex function with ""essential singularity"" all along the unit circle",,"I found myself curious whether there existed a complex function which is analytic on the interior of the unit disc, but such that there is no extension of the function to a holomorphic function on a strictly larger connected open set.  This was because all the typical examples I could think of with a finite radius of convergence of the Taylor series had natural analytic extensions near all but finitely many points of the boundary of the region of convergence. The example I came up with was: $$f(z) := \sum_{n=0}^\infty \frac{z^{2^n}}{2^n}.$$ This function has radius of convergence 1, and at every point of $|z| = 1$ it converges to a function whose imaginary part has $\Im f(e^{i \theta})$ equal to the Weierstrass function.  Therefore, the restriction to the unit circle is not differentiable (as a function on the real $C^\infty$ manifold $S^1$ ) at any point, which makes it impossible for any extension of $f$ to be holomorphic at any point on the unit circle (since Abel's theorem implies such an extension wouldn't have a pole at such a point). My question is: is this a valid example, or is there something I'm missing?  And also, is there a more natural example of such a function in terms of the usual examples of analytic functions?","I found myself curious whether there existed a complex function which is analytic on the interior of the unit disc, but such that there is no extension of the function to a holomorphic function on a strictly larger connected open set.  This was because all the typical examples I could think of with a finite radius of convergence of the Taylor series had natural analytic extensions near all but finitely many points of the boundary of the region of convergence. The example I came up with was: This function has radius of convergence 1, and at every point of it converges to a function whose imaginary part has equal to the Weierstrass function.  Therefore, the restriction to the unit circle is not differentiable (as a function on the real manifold ) at any point, which makes it impossible for any extension of to be holomorphic at any point on the unit circle (since Abel's theorem implies such an extension wouldn't have a pole at such a point). My question is: is this a valid example, or is there something I'm missing?  And also, is there a more natural example of such a function in terms of the usual examples of analytic functions?",f(z) := \sum_{n=0}^\infty \frac{z^{2^n}}{2^n}. |z| = 1 \Im f(e^{i \theta}) C^\infty S^1 f,['complex-analysis']
76,The Laplacian operator is invariant to $SL_2(\mathbb{R})$,The Laplacian operator is invariant to,SL_2(\mathbb{R}),"I am reading Iwaniec's book on the spectral analysis of automorphic forms, where I bumped into the following statement in p.20 section 1.6. Given a function $f:\mathbb{H}\longrightarrow \mathbb{C}$ , having continuous second derivatives, and some $g\in SL_2(\mathbb{R})$ , then $\Delta(f(gz)) = (\Delta f)(gz)$ . Note that the Laplacian operator we use on the hyperbolic plane $\mathbb{H}$ , is $$\Delta = y^2(\dfrac{\partial^2}{\partial x^2} + \dfrac{\partial^2}{\partial y^2})$$ My idea is that in order to prove such a statement, it is enough to prove it over the generators of $SL_2(\mathbb{R})$ , i.e., it is enough to check that the identity holds for $g_t(z) = z + t$ for $t\in\mathbb{R}$ , and $g^*(z) = -\dfrac{1}{z}$ . I found it easy proving the statement for $g=g_t$ , however for $g^*$ I didn't understand why it is true that: $$\Delta(f(-\dfrac{1}{z})) = (\Delta f)(-\dfrac{1}{z})$$ Writing down the formulas for the Laplacian, we get that the LHS is equal to: $$y^2(\dfrac{\partial^2 (f\circ\dfrac{-1}{z})}{\partial x^2} + \dfrac{\partial^2 (f\circ\dfrac{-1}{z})}{\partial y^2})$$ Whereas the RHS equals: $$\Im(-\dfrac{1}{z})^2(\dfrac{\partial^2 f}{\partial x^2}(\dfrac{-1}{z}) + \dfrac{\partial^2 f}{\partial y^2}(\dfrac{-1}{z}))$$ I could continue with the computation, however, simply analyzing the coefficient of $$\dfrac{\partial^2 f}{\partial x^2}(\dfrac{-1}{z})$$ on both sides seems to show me that I am on the wrong path. For the LHS: $$y^2\cdot\dfrac{\partial^2 f}{\partial x^2}(-\dfrac{1}{z})\dfrac{\partial^2 (-\dfrac{1}{z})}{\partial x^2}$$ For the RHS I obtain: $$\Im(-\dfrac{1}{z})^2\dfrac{\partial^2 f}{\partial x^2}(\dfrac{-1}{z})$$ Hence the identity could potentially be true if one has the equality: $$\Im(-\dfrac{1}{z})^2 = y^2\dfrac{\partial^2 (-\dfrac{1}{z})}{\partial x^2}$$ However, the RHS is $\dfrac{-2y^2}{z^3}$ , whereas the LHS is: $\dfrac{y^2}{(x^2+y^2)^2}$ , we cannot expect equality in the general case, so I am confused.","I am reading Iwaniec's book on the spectral analysis of automorphic forms, where I bumped into the following statement in p.20 section 1.6. Given a function , having continuous second derivatives, and some , then . Note that the Laplacian operator we use on the hyperbolic plane , is My idea is that in order to prove such a statement, it is enough to prove it over the generators of , i.e., it is enough to check that the identity holds for for , and . I found it easy proving the statement for , however for I didn't understand why it is true that: Writing down the formulas for the Laplacian, we get that the LHS is equal to: Whereas the RHS equals: I could continue with the computation, however, simply analyzing the coefficient of on both sides seems to show me that I am on the wrong path. For the LHS: For the RHS I obtain: Hence the identity could potentially be true if one has the equality: However, the RHS is , whereas the LHS is: , we cannot expect equality in the general case, so I am confused.",f:\mathbb{H}\longrightarrow \mathbb{C} g\in SL_2(\mathbb{R}) \Delta(f(gz)) = (\Delta f)(gz) \mathbb{H} \Delta = y^2(\dfrac{\partial^2}{\partial x^2} + \dfrac{\partial^2}{\partial y^2}) SL_2(\mathbb{R}) g_t(z) = z + t t\in\mathbb{R} g^*(z) = -\dfrac{1}{z} g=g_t g^* \Delta(f(-\dfrac{1}{z})) = (\Delta f)(-\dfrac{1}{z}) y^2(\dfrac{\partial^2 (f\circ\dfrac{-1}{z})}{\partial x^2} + \dfrac{\partial^2 (f\circ\dfrac{-1}{z})}{\partial y^2}) \Im(-\dfrac{1}{z})^2(\dfrac{\partial^2 f}{\partial x^2}(\dfrac{-1}{z}) + \dfrac{\partial^2 f}{\partial y^2}(\dfrac{-1}{z})) \dfrac{\partial^2 f}{\partial x^2}(\dfrac{-1}{z}) y^2\cdot\dfrac{\partial^2 f}{\partial x^2}(-\dfrac{1}{z})\dfrac{\partial^2 (-\dfrac{1}{z})}{\partial x^2} \Im(-\dfrac{1}{z})^2\dfrac{\partial^2 f}{\partial x^2}(\dfrac{-1}{z}) \Im(-\dfrac{1}{z})^2 = y^2\dfrac{\partial^2 (-\dfrac{1}{z})}{\partial x^2} \dfrac{-2y^2}{z^3} \dfrac{y^2}{(x^2+y^2)^2},"['complex-analysis', 'laplace-transform', 'automorphic-forms']"
77,"If $f: U \to V$ is holomorphic and injective , then $f'(z) \neq 0$ for all $z \in U$","If  is holomorphic and injective , then  for all",f: U \to V f'(z) \neq 0 z \in U,"Proposition : If $f: U \to V$ is holomorphic and injective , then $f'(z) \neq 0$ for all $z \in U$ . Proof : We argue by contradiction , and suppose that $f'(z_0) = 0$ for some $z_0 \in U$ . Then $$f(z)-f(z_0)=a(z-z_0)^k+G(z) \,\,\,\,\,\,\,\, \text{for all $z$ near $z_0$ ,}$$ with $a\neq 0 , k \ge 2$ and $G$ vanishing to order $k+1$ at $z_0$ . For sufficiently small $w$ , we write $$f(z)-f(z_0)-w=F(z)+G(z) \,\,\,\,\,\,\,\, \text{where $F(z)=a(z-z_0)^k-w$ .} $$ Since $|G(z)|\lt |F(z)|$ on a small circle centered at $z_0$ , and $F$ has at least two zeros inside that circle , Rouche's theorem implies that $f(z)-f(z_0)-w$ has at least two zeros there , a contradiction . My question : Why $F$ has at least two zeros inside that small circle ? We only know that $F$ has $k$ zeros in $C$ or for some large circle centered at $z_0$ . However , since $w$ is fixed , the radius $r$ of the small circle which satisfy $|G(z)|\lt |F(z)|$ can not be sufficiently large . So , how to deduce de desired conclusion by the proof given above ?","Proposition : If is holomorphic and injective , then for all . Proof : We argue by contradiction , and suppose that for some . Then with and vanishing to order at . For sufficiently small , we write Since on a small circle centered at , and has at least two zeros inside that circle , Rouche's theorem implies that has at least two zeros there , a contradiction . My question : Why has at least two zeros inside that small circle ? We only know that has zeros in or for some large circle centered at . However , since is fixed , the radius of the small circle which satisfy can not be sufficiently large . So , how to deduce de desired conclusion by the proof given above ?","f: U \to V f'(z) \neq 0 z \in U f'(z_0) = 0 z_0 \in U f(z)-f(z_0)=a(z-z_0)^k+G(z) \,\,\,\,\,\,\,\, \text{for all z near z_0 ,} a\neq 0 , k \ge 2 G k+1 z_0 w f(z)-f(z_0)-w=F(z)+G(z) \,\,\,\,\,\,\,\, \text{where F(z)=a(z-z_0)^k-w .}  |G(z)|\lt |F(z)| z_0 F f(z)-f(z_0)-w F F k C z_0 w r |G(z)|\lt |F(z)|","['complex-analysis', 'proof-explanation']"
78,Growth of Digamma function,Growth of Digamma function,,"For $1\le \sigma \le 2$ and $t\ge 2$ , $s=\sigma+it$ prove that $\displaystyle \frac{\Gamma'(s)}{\Gamma(s)}=O(\log t)$ . From Stirling's formula we have, $\displaystyle \Gamma(s)\approx \sqrt{2\pi}\exp\{s\log s-s-\frac 12 \log s\}$ . Then, $\displaystyle \frac{\Gamma'(s)}{\Gamma(s)}\approx\log s-\frac{1}{2s}$ . From here I'm unable to estimate !! Any hint. ? Where can I get rigorous proof ? Edit: Wikipedia links below the question are NOT clear enough to me.","For and , prove that . From Stirling's formula we have, . Then, . From here I'm unable to estimate !! Any hint. ? Where can I get rigorous proof ? Edit: Wikipedia links below the question are NOT clear enough to me.",1\le \sigma \le 2 t\ge 2 s=\sigma+it \displaystyle \frac{\Gamma'(s)}{\Gamma(s)}=O(\log t) \displaystyle \Gamma(s)\approx \sqrt{2\pi}\exp\{s\log s-s-\frac 12 \log s\} \displaystyle \frac{\Gamma'(s)}{\Gamma(s)}\approx\log s-\frac{1}{2s},"['complex-analysis', 'analytic-number-theory', 'gamma-function', 'riemann-zeta', 'digamma-function']"
79,Why do we want to consider the complexification of the tangent space in complex geometry?,Why do we want to consider the complexification of the tangent space in complex geometry?,,"Given a complex manifold $M$ , its complexified tangent bundle is $TM \otimes \mathbb C$ . It is quite confusing for me as to why we want to do this since at each point $TM$ can already be viewed as a complex vector space.","Given a complex manifold , its complexified tangent bundle is . It is quite confusing for me as to why we want to do this since at each point can already be viewed as a complex vector space.",M TM \otimes \mathbb C TM,"['complex-analysis', 'differential-geometry', 'differential-topology', 'complex-geometry']"
80,Where are the zeroes of complex exponential function?,Where are the zeroes of complex exponential function?,,"There is none because we have $e^z \neq 0$ for every $z \in \mathbb C$. But we have Taylor series that everywhere converges to $e^z$, it is $e^z = \displaystyle \sum_{k=0}^{+ \infty} \frac {z^k}{k!}$. If we truncate that series , say, at natural $m$, then we have Taylor polynomial $\displaystyle \sum_{k=0}^{m} \frac {z^k}{k!}$, which has, counted with maybe possible multiplicity, $m$ complex zeroes. So as the degree of Taylor polynomial grows the number of zeroes increases, but in the limit they all dissapear, why?","There is none because we have $e^z \neq 0$ for every $z \in \mathbb C$. But we have Taylor series that everywhere converges to $e^z$, it is $e^z = \displaystyle \sum_{k=0}^{+ \infty} \frac {z^k}{k!}$. If we truncate that series , say, at natural $m$, then we have Taylor polynomial $\displaystyle \sum_{k=0}^{m} \frac {z^k}{k!}$, which has, counted with maybe possible multiplicity, $m$ complex zeroes. So as the degree of Taylor polynomial grows the number of zeroes increases, but in the limit they all dissapear, why?",,"['complex-analysis', 'exponential-function', 'roots']"
81,A holomorphic function with infinitely many zeros in the unit disc,A holomorphic function with infinitely many zeros in the unit disc,,"Prove that if $f$ is holomorphic in the unit disc, bounded and not identically zero, and $z_1, z_2, z_3, \dotsc, z_n, \dotsc$ are its zeros ($\vert z_k \vert$ $\lt1$ ),then   $$\sum_{k=1}^\infty (1-\vert z_k \vert) \lt \infty$$   [Hint:Use Jensen's formula.] Since Jensen's formula can be used when $f$ vanishes nowhere on the circle $C_R$. I notice that there exist an increasing sequence $r_n$ for   $\lim_{n\to \infty} r_n = 1$, and $f$ vanishes nowhere on each $C_{r_n}$. Suppose $f(0) \neq 0$, then use Jensen's formula on each circle $C_r$ and get $$     \sum_{k=1}^{n_r} \log \vert z_k \vert   =   \log \vert f(0) \vert     + n_r \cdot \log r     - \frac{1}{2\pi}       \int_{0}^{2\pi}       \log \vert f(re^{i\theta}) \vert       \,\mathrm{d}\theta, $$ where $n_r$ denotes the numbers of zeros inside the disc $C_r$. But I don't know how to estimate the limit of $n_r \log r$ as $r$ tends to $1$.","Prove that if $f$ is holomorphic in the unit disc, bounded and not identically zero, and $z_1, z_2, z_3, \dotsc, z_n, \dotsc$ are its zeros ($\vert z_k \vert$ $\lt1$ ),then   $$\sum_{k=1}^\infty (1-\vert z_k \vert) \lt \infty$$   [Hint:Use Jensen's formula.] Since Jensen's formula can be used when $f$ vanishes nowhere on the circle $C_R$. I notice that there exist an increasing sequence $r_n$ for   $\lim_{n\to \infty} r_n = 1$, and $f$ vanishes nowhere on each $C_{r_n}$. Suppose $f(0) \neq 0$, then use Jensen's formula on each circle $C_r$ and get $$     \sum_{k=1}^{n_r} \log \vert z_k \vert   =   \log \vert f(0) \vert     + n_r \cdot \log r     - \frac{1}{2\pi}       \int_{0}^{2\pi}       \log \vert f(re^{i\theta}) \vert       \,\mathrm{d}\theta, $$ where $n_r$ denotes the numbers of zeros inside the disc $C_r$. But I don't know how to estimate the limit of $n_r \log r$ as $r$ tends to $1$.",,['complex-analysis']
82,An entire function whose integral is bounded is identically zero,An entire function whose integral is bounded is identically zero,,"Suppose $f$ has a power series at $0$ that converges in all of $\mathbb{C}$ and $$\int_{\mathbb{C}} |f(x+iy)|dxdy$$ Converges. Prove $f$ is identically zero. I don’t know Liouville’s theorem or any integral formulas yet, so I’m a bit stuck on this one. A hint is given: “Use polar coordinates to show $f(0)=0$” Edit: I am open to any suggestions, even those which use Liouville or Cauchy etc","Suppose $f$ has a power series at $0$ that converges in all of $\mathbb{C}$ and $$\int_{\mathbb{C}} |f(x+iy)|dxdy$$ Converges. Prove $f$ is identically zero. I don’t know Liouville’s theorem or any integral formulas yet, so I’m a bit stuck on this one. A hint is given: “Use polar coordinates to show $f(0)=0$” Edit: I am open to any suggestions, even those which use Liouville or Cauchy etc",,['complex-analysis']
83,Power series of a function related to Gamma function,Power series of a function related to Gamma function,,"I'm having trouble solving the following exercise: Let $\alpha \in \mathbb C$ fixed and $f: D \to \mathbb C$  defined by $$f(z) := \frac{1}{(1-z)^\alpha}.$$   Let $$f(z) = \sum_{n=0}^\infty a_n(\alpha) z^n $$   be the power series representation of $f$. Show that for the coefficients $a_n(\alpha)$ the following holds:   $$\lim_{n\to \infty}\frac{a_n(\alpha)}{n^{\alpha - 1}} = \frac{1}{\Gamma(\alpha)}$$ Where $D$ denotes the unit ball and $\Gamma$ the Gamma function. Attempt: I assume I need to find out explicit representation of the coefficients $a_n(\alpha)$ and then show the identity using the Gauß representation of the Gamma function: $$\Gamma(s) = \lim_{n\to \infty} \frac{n! n^s}{s(s+1) \cdot \cdot \cdot (s+n)}.$$ However, I was unable to find a useful one. Expanding the function $f$ into a Taylor series didn't work out (if I did not do it wrong). Is there an easier way to find out the coefficients?","I'm having trouble solving the following exercise: Let $\alpha \in \mathbb C$ fixed and $f: D \to \mathbb C$  defined by $$f(z) := \frac{1}{(1-z)^\alpha}.$$   Let $$f(z) = \sum_{n=0}^\infty a_n(\alpha) z^n $$   be the power series representation of $f$. Show that for the coefficients $a_n(\alpha)$ the following holds:   $$\lim_{n\to \infty}\frac{a_n(\alpha)}{n^{\alpha - 1}} = \frac{1}{\Gamma(\alpha)}$$ Where $D$ denotes the unit ball and $\Gamma$ the Gamma function. Attempt: I assume I need to find out explicit representation of the coefficients $a_n(\alpha)$ and then show the identity using the Gauß representation of the Gamma function: $$\Gamma(s) = \lim_{n\to \infty} \frac{n! n^s}{s(s+1) \cdot \cdot \cdot (s+n)}.$$ However, I was unable to find a useful one. Expanding the function $f$ into a Taylor series didn't work out (if I did not do it wrong). Is there an easier way to find out the coefficients?",,"['complex-analysis', 'analysis', 'power-series', 'gamma-function']"
84,Laplace Transform and Analytic continuation,Laplace Transform and Analytic continuation,,"I just started doing complex analysis and came across this notion of Analytic Continuation. Now I was thinking whether it is possible to analytically continue Laplace Transforms as well. What I mean is this: $$\mathcal{L}(\sin(at)) = \int_0^{\infty} e^{-st}\sin(at) \, dt $$ is only valid for $s>0$. BUT $$ \mathcal{L}(\sin(at)) = \frac{a}{s^2 + a^2}$$ is valid unless $s \neq ia$. So is it possible to use the above expression to find out the Laplace Transform for any other values for $s$ ? Thanks!","I just started doing complex analysis and came across this notion of Analytic Continuation. Now I was thinking whether it is possible to analytically continue Laplace Transforms as well. What I mean is this: $$\mathcal{L}(\sin(at)) = \int_0^{\infty} e^{-st}\sin(at) \, dt $$ is only valid for $s>0$. BUT $$ \mathcal{L}(\sin(at)) = \frac{a}{s^2 + a^2}$$ is valid unless $s \neq ia$. So is it possible to use the above expression to find out the Laplace Transform for any other values for $s$ ? Thanks!",,"['complex-analysis', 'laplace-transform']"
85,"If $|f|+|g|$ is constant on $D,$ prove that holomorphic functions $f,~g$ are constant on $D$.",If  is constant on  prove that holomorphic functions  are constant on .,"|f|+|g| D, f,~g D","Let $D\subseteq \mathbb{C}$ be open and connected and    $f,~g:D \rightarrow \mathbb{C}$ holomorphic functions such that    $|f|+|g|$ is constant on $D.$ Prove that $f,~g$ are constant on $D.$ Attempt. I noticed first that this problem is already set before, and is considered  to be duplicate ( If $|f|+|g|$ is constant then each of $f, g$ is constant ) and we are sent directly to problem sum of holomorphic functions . However, the last reference deals with the sum $|f|^2+|g|^2$, which I do not see how is connected to the sum $|f|+|g|$, as stated in our title (for example, the equality $|f|^2+|g|^2=(|f|+|g|)^2-2|f||g|$ is not helpful here). Thanks in advance!","Let $D\subseteq \mathbb{C}$ be open and connected and    $f,~g:D \rightarrow \mathbb{C}$ holomorphic functions such that    $|f|+|g|$ is constant on $D.$ Prove that $f,~g$ are constant on $D.$ Attempt. I noticed first that this problem is already set before, and is considered  to be duplicate ( If $|f|+|g|$ is constant then each of $f, g$ is constant ) and we are sent directly to problem sum of holomorphic functions . However, the last reference deals with the sum $|f|^2+|g|^2$, which I do not see how is connected to the sum $|f|+|g|$, as stated in our title (for example, the equality $|f|^2+|g|^2=(|f|+|g|)^2-2|f||g|$ is not helpful here). Thanks in advance!",,"['complex-analysis', 'complex-numbers', 'holomorphic-functions']"
86,Confusion about proving homotopy invariance of the contour integral,Confusion about proving homotopy invariance of the contour integral,,"This is a technical question about a certain proof of the following theorem. (I'm reading volume 2 of Stein and Shakarchi, pp. 93-95, but I imagine that any other complex analysis textbook has a similar proof.) Theorem: Let $f:\Omega\to\mathbb C$ be a holomorphic function on some domain $\Omega$ and let $\gamma_0,\gamma_1:[a,b]\to\mathbb C$ be closed, piecewise $C^1$ curves. If $\gamma_0$ and $\gamma_1$ are homotopic then    $$ \int_{\gamma_0} f(z)\,dz = \int_{\gamma_1} f(z)\,dz. $$ Here's a (very rough) sketch of the proof, for reference. I'm afraid that even this sketch is too detailed; you might just want to jump to the paragraph starting with ""The Problem"" if you're familiar with this standard proof. Proof: To begin, use a compactness argument to reduce to the case where  $\sup_{t\in[a,b]}|\gamma_0(t)-\gamma_1(t)|$ is small enough so that we can cover $\gamma_0$ and $\gamma_1$ with discs $D_1,D_2,\dots,D_n$ as in the picture below (except for my labeling being off by one). Specifically, the discs have the following property: there are times $a=t_0 < t_1 < \cdots < t_n = b$ such that if $t_{k-1} \leq t \leq t_k$ then $\gamma_0(t)$ and $\gamma_1(t)$ are contained in $D_k$. Also, choose points of the two arcs in each disc, $z_k=\gamma_0(t_k)$ and $w_k=\gamma_1(t_k)$. This has the effect of dividing both arcs into $n$ smaller arcs. (After this reduction, when I write $\gamma_0$ and $\gamma_1$ I really mean intermediate curves in the homotopy.) To finish, find a primitive (i.e., an antiderivative) $F_k$ of $f$ on each disc $D_k$. The integral of $f$ on each small arc is the difference of the values of $F_k$ on the endpoints of the arc . Now add up some equations, etc etc (omitted details). The Problem: The italicized line worries me. What happens if the intermediate arcs in the homotopy are not $C^1$? In order to use the relationship between primitives and contour integrals we need the contours to have some regularity properties, right? It seems like this proof should break if the homotopy passed through contours that were nowhere differentiable or had unbounded variation, for example. Do we need to assume that the homotopy is through $C^1$ curves? If so, it seems that we would have to also prove that homotopic curves are $C^1$ homotopic (like the proof of the De Rham theorem).","This is a technical question about a certain proof of the following theorem. (I'm reading volume 2 of Stein and Shakarchi, pp. 93-95, but I imagine that any other complex analysis textbook has a similar proof.) Theorem: Let $f:\Omega\to\mathbb C$ be a holomorphic function on some domain $\Omega$ and let $\gamma_0,\gamma_1:[a,b]\to\mathbb C$ be closed, piecewise $C^1$ curves. If $\gamma_0$ and $\gamma_1$ are homotopic then    $$ \int_{\gamma_0} f(z)\,dz = \int_{\gamma_1} f(z)\,dz. $$ Here's a (very rough) sketch of the proof, for reference. I'm afraid that even this sketch is too detailed; you might just want to jump to the paragraph starting with ""The Problem"" if you're familiar with this standard proof. Proof: To begin, use a compactness argument to reduce to the case where  $\sup_{t\in[a,b]}|\gamma_0(t)-\gamma_1(t)|$ is small enough so that we can cover $\gamma_0$ and $\gamma_1$ with discs $D_1,D_2,\dots,D_n$ as in the picture below (except for my labeling being off by one). Specifically, the discs have the following property: there are times $a=t_0 < t_1 < \cdots < t_n = b$ such that if $t_{k-1} \leq t \leq t_k$ then $\gamma_0(t)$ and $\gamma_1(t)$ are contained in $D_k$. Also, choose points of the two arcs in each disc, $z_k=\gamma_0(t_k)$ and $w_k=\gamma_1(t_k)$. This has the effect of dividing both arcs into $n$ smaller arcs. (After this reduction, when I write $\gamma_0$ and $\gamma_1$ I really mean intermediate curves in the homotopy.) To finish, find a primitive (i.e., an antiderivative) $F_k$ of $f$ on each disc $D_k$. The integral of $f$ on each small arc is the difference of the values of $F_k$ on the endpoints of the arc . Now add up some equations, etc etc (omitted details). The Problem: The italicized line worries me. What happens if the intermediate arcs in the homotopy are not $C^1$? In order to use the relationship between primitives and contour integrals we need the contours to have some regularity properties, right? It seems like this proof should break if the homotopy passed through contours that were nowhere differentiable or had unbounded variation, for example. Do we need to assume that the homotopy is through $C^1$ curves? If so, it seems that we would have to also prove that homotopic curves are $C^1$ homotopic (like the proof of the De Rham theorem).",,"['complex-analysis', 'proof-verification']"
87,Does the Fundamental Theorem of Algebra hold true for infinite polynomials?,Does the Fundamental Theorem of Algebra hold true for infinite polynomials?,,"I know that by the Fundamental Theorem of Algebra, every polynomial of positive degree has a zero in $\mathbb{C}$. Does this also hold for polynomials of infinite degree? Like, for example, the Taylor expansion of $e^z$ or $\cos z$?","I know that by the Fundamental Theorem of Algebra, every polynomial of positive degree has a zero in $\mathbb{C}$. Does this also hold for polynomials of infinite degree? Like, for example, the Taylor expansion of $e^z$ or $\cos z$?",,"['complex-analysis', 'complex-numbers', 'taylor-expansion']"
88,Product of two series to get a series decomposition of zeta in the critical strip,Product of two series to get a series decomposition of zeta in the critical strip,,"$\def\sfrac#1#2{%     \small#1%     \kern-.05em\lower0.1ex/\kern-.025em%     \lower0.4ex\small#2}$I've been working on gaining an intuitive understanding of the analytic continuation of the zeta function, but I've gotten stuck at this part where I have to multiply two very strange series together. The approach is quite simple: first start with the Dirichlet eta function, defined by $η(s) = \frac{1}{1^s} + \frac{-1}{2^s} + \frac{1}{3^s} + \frac{-1}{4^s} + ... $. Then the following relationship holds: $ζ(s) = η(s) · \frac{1}{1-\frac{2}{2^s}}$ If $\Re\{s\} > 1$, then the right factor can be expanded into a Taylor series, yielding $ζ(s) = \left(\frac{1}{1^s} + \frac{-1}{2^s} + \frac{1}{3^s} + \frac{-1}{4^s} + ... \right) \cdot \left(\frac{1}{1^s} + \frac{2}{2^s} + \frac{4}{4^s} + \frac{8}{8^s} + ... \right) \\ = \frac{1}{1^s} + \frac{1}{2^s} + \frac{1}{3^s} + \frac{1}{4^s} + ...$ where the product can be evaluated as a Dirichlet convolution. This is because the image of $\frac{2}{2^s}$ lies within the radius of convergence of the $1 + x + x^2 + x^3 + ...$ series expansion of $\frac{1}{1-x}$, so the Taylor expansion is valid. However, if $\Re\{s\} < 1$, then the image of $\frac{2}{2^s}$ lies outside the ROC, so that expansion doesn't work. Instead, we can take advantage of the functional equation $f(x) + f(\frac{1}{x}) = 1$ where $f(x) = \frac{1}{1-x}$. Substituting in $x=\frac{2}{2^s}$, and allowing that $\frac{1}{\left(\frac{2}{2^s}\right)} = \frac{\sfrac{1}{2}}{{\sfrac{1}{2}}^s}$, you get $\frac{1}{1-\frac{2}{2^s}} = 1 - \frac{1}{1-\frac{\sfrac{1}{2}}{{\sfrac{1}{2}}^s}}$ where $\frac{\sfrac{1}{2}}{{\sfrac{1}{2}}^s}$ now has an image lying within the ROC of the aforementioned series expansion for $\Re\{s\} < 1$. So we can expand the whole right side as $\frac{1}{1-\frac{2}{2^s}} = \frac{-\sfrac{1}{2}}{{\sfrac{1}{2}}^s} + \frac{-\sfrac{1}{4}}{{\sfrac{1}{4}}^s} + \frac{-\sfrac{1}{8}}{{\sfrac{1}{8}}^s} + \frac{-\sfrac{1}{16}}{{\sfrac{1}{16}}^s} + ...$ Finally, putting the whole thing together, we get $ζ(s) = \left(\frac{1}{1^s} + \frac{-1}{2^s} + \frac{1}{3^s} + \frac{-1}{4^s} + ... \right) \cdot \left(\frac{-\sfrac{1}{2}}{{\sfrac{1}{2}}^s} + \frac{-\sfrac{1}{4}}{{\sfrac{1}{4}}^s} + \frac{-\sfrac{1}{8}}{{\sfrac{1}{8}}^s} + \frac{-\sfrac{1}{16}}{{\sfrac{1}{16}}^s} + ...\right)$ Which, for $0 < \Re\{s\} < 1$, is the product of a conditionally convergent Dirichlet series, and an absolutely convergent ""fractional Dirichlet series."" And here I'm stumped. How can I expand this product? I understand the result should be some kind of ""fractional Dirichlet series"" where the denominators are dyadic rationals raised to the power of s, and I understand I basically want to perform some kind of Dirichlet convolution type thing here. But how do I actually do it? What does the resulting expression look like?","$\def\sfrac#1#2{%     \small#1%     \kern-.05em\lower0.1ex/\kern-.025em%     \lower0.4ex\small#2}$I've been working on gaining an intuitive understanding of the analytic continuation of the zeta function, but I've gotten stuck at this part where I have to multiply two very strange series together. The approach is quite simple: first start with the Dirichlet eta function, defined by $η(s) = \frac{1}{1^s} + \frac{-1}{2^s} + \frac{1}{3^s} + \frac{-1}{4^s} + ... $. Then the following relationship holds: $ζ(s) = η(s) · \frac{1}{1-\frac{2}{2^s}}$ If $\Re\{s\} > 1$, then the right factor can be expanded into a Taylor series, yielding $ζ(s) = \left(\frac{1}{1^s} + \frac{-1}{2^s} + \frac{1}{3^s} + \frac{-1}{4^s} + ... \right) \cdot \left(\frac{1}{1^s} + \frac{2}{2^s} + \frac{4}{4^s} + \frac{8}{8^s} + ... \right) \\ = \frac{1}{1^s} + \frac{1}{2^s} + \frac{1}{3^s} + \frac{1}{4^s} + ...$ where the product can be evaluated as a Dirichlet convolution. This is because the image of $\frac{2}{2^s}$ lies within the radius of convergence of the $1 + x + x^2 + x^3 + ...$ series expansion of $\frac{1}{1-x}$, so the Taylor expansion is valid. However, if $\Re\{s\} < 1$, then the image of $\frac{2}{2^s}$ lies outside the ROC, so that expansion doesn't work. Instead, we can take advantage of the functional equation $f(x) + f(\frac{1}{x}) = 1$ where $f(x) = \frac{1}{1-x}$. Substituting in $x=\frac{2}{2^s}$, and allowing that $\frac{1}{\left(\frac{2}{2^s}\right)} = \frac{\sfrac{1}{2}}{{\sfrac{1}{2}}^s}$, you get $\frac{1}{1-\frac{2}{2^s}} = 1 - \frac{1}{1-\frac{\sfrac{1}{2}}{{\sfrac{1}{2}}^s}}$ where $\frac{\sfrac{1}{2}}{{\sfrac{1}{2}}^s}$ now has an image lying within the ROC of the aforementioned series expansion for $\Re\{s\} < 1$. So we can expand the whole right side as $\frac{1}{1-\frac{2}{2^s}} = \frac{-\sfrac{1}{2}}{{\sfrac{1}{2}}^s} + \frac{-\sfrac{1}{4}}{{\sfrac{1}{4}}^s} + \frac{-\sfrac{1}{8}}{{\sfrac{1}{8}}^s} + \frac{-\sfrac{1}{16}}{{\sfrac{1}{16}}^s} + ...$ Finally, putting the whole thing together, we get $ζ(s) = \left(\frac{1}{1^s} + \frac{-1}{2^s} + \frac{1}{3^s} + \frac{-1}{4^s} + ... \right) \cdot \left(\frac{-\sfrac{1}{2}}{{\sfrac{1}{2}}^s} + \frac{-\sfrac{1}{4}}{{\sfrac{1}{4}}^s} + \frac{-\sfrac{1}{8}}{{\sfrac{1}{8}}^s} + \frac{-\sfrac{1}{16}}{{\sfrac{1}{16}}^s} + ...\right)$ Which, for $0 < \Re\{s\} < 1$, is the product of a conditionally convergent Dirichlet series, and an absolutely convergent ""fractional Dirichlet series."" And here I'm stumped. How can I expand this product? I understand the result should be some kind of ""fractional Dirichlet series"" where the denominators are dyadic rationals raised to the power of s, and I understand I basically want to perform some kind of Dirichlet convolution type thing here. But how do I actually do it? What does the resulting expression look like?",,"['complex-analysis', 'analytic-number-theory', 'riemann-zeta', 'dirichlet-series']"
89,The Multiplier Algebra of the Hardy Hilbert Space,The Multiplier Algebra of the Hardy Hilbert Space,,"Let $H$ be a Hilbert space of analytic functions. Define the multiplier algebra of H in the following manner: $M(H)=\{ \phi \in H  :  \phi h \in H, \forall h \in H \}$ It is mentioned in countless places that the multiplier algebra for $H^2=\{f \text{ analytic on the disk}, f= \sum a_nz^n : \sum |a_n|^2 < \infty \}$ is $H^\infty$, the space of bounded analytic functions on the unit disk. It is obvious that $H^\infty \subset M(H^2)$. My question is how does one prove the other inclusion?","Let $H$ be a Hilbert space of analytic functions. Define the multiplier algebra of H in the following manner: $M(H)=\{ \phi \in H  :  \phi h \in H, \forall h \in H \}$ It is mentioned in countless places that the multiplier algebra for $H^2=\{f \text{ analytic on the disk}, f= \sum a_nz^n : \sum |a_n|^2 < \infty \}$ is $H^\infty$, the space of bounded analytic functions on the unit disk. It is obvious that $H^\infty \subset M(H^2)$. My question is how does one prove the other inclusion?",,"['complex-analysis', 'operator-theory']"
90,Why is the Euclidian norm used to measure complex numbers?,Why is the Euclidian norm used to measure complex numbers?,,"Why is the Euclidian norm used to measure complex numbers? The complex numbers are numbers (or more precisely, pairs of numbers), and I can't see why are they essentially connected to the Euclidian geometry. As far as a I can see, the only connection between Euclidian plane and pairs of numbers is that the last can be conjugated to the plane in very ""neutral"" way. But as much as i understand, the euclidian plane is part of a more general notion of manifold, and you can conjugate pairs of numbers to any 2 dimensional manifold, including non euclidian planes. Are we using the euclidian norm (""modulus"") only because we want some kind of way to measure complex numbers that ""grows bigger as the complex numbers grows, no matter in what direction""? a way of measure which is ""free of direction"" (not taking into account the direction of which the quantity grows, but only its growth)? This is my way to understand it so far. If I am right, we can basically use any similar norm to measure complex numbers ""size"" (independent of direction), not only the Euclidian norm, and they'll do the same work and fulfill their destiny. Obviously there would be another but similar way to measure their ""direction"".. So, am I right, and its just an convention to use that way to measure ""size"" and ""direction"" of complex numbers by the so called modulus and argument? Or am I wrong? thx for answering! :)","Why is the Euclidian norm used to measure complex numbers? The complex numbers are numbers (or more precisely, pairs of numbers), and I can't see why are they essentially connected to the Euclidian geometry. As far as a I can see, the only connection between Euclidian plane and pairs of numbers is that the last can be conjugated to the plane in very ""neutral"" way. But as much as i understand, the euclidian plane is part of a more general notion of manifold, and you can conjugate pairs of numbers to any 2 dimensional manifold, including non euclidian planes. Are we using the euclidian norm (""modulus"") only because we want some kind of way to measure complex numbers that ""grows bigger as the complex numbers grows, no matter in what direction""? a way of measure which is ""free of direction"" (not taking into account the direction of which the quantity grows, but only its growth)? This is my way to understand it so far. If I am right, we can basically use any similar norm to measure complex numbers ""size"" (independent of direction), not only the Euclidian norm, and they'll do the same work and fulfill their destiny. Obviously there would be another but similar way to measure their ""direction"".. So, am I right, and its just an convention to use that way to measure ""size"" and ""direction"" of complex numbers by the so called modulus and argument? Or am I wrong? thx for answering! :)",,"['complex-analysis', 'complex-numbers', 'euclidean-geometry', 'normed-spaces']"
91,"Apply the Cauchy-Goursat theorem to show that $\int_C \operatorname{Log}(z+2)\, dz=0$ on a unit circle.",Apply the Cauchy-Goursat theorem to show that  on a unit circle.,"\int_C \operatorname{Log}(z+2)\, dz=0","Cauchy-Goursat theorem. If a function $f$ is analytic at all points interior to and on a simple closed contour $C$, then  $$\int_C f(z) \,dz=0.$$ This is a problem from Churchill's Complex Variables. Problem: Apply the Cauchy-Goursat theorem to show that $$\int_C f(z) \,dz=0$$ when the contour $C$ is the unit circle $|z|=1$, in either direction, and when $f(z)=\operatorname{Log}(z+2)$, where $\operatorname{Log}$ is the principal branch. I don't understand how I can apply the theorem in this case, since the branch of $f(z)$ is not defined on the ray $\theta=\pi$; hence does not satisfy the condition of analytic at all points interior to and on a simple closed contour $C$, of the theorem. How can I make sense of this problem? I would greatly appreciate any help.","Cauchy-Goursat theorem. If a function $f$ is analytic at all points interior to and on a simple closed contour $C$, then  $$\int_C f(z) \,dz=0.$$ This is a problem from Churchill's Complex Variables. Problem: Apply the Cauchy-Goursat theorem to show that $$\int_C f(z) \,dz=0$$ when the contour $C$ is the unit circle $|z|=1$, in either direction, and when $f(z)=\operatorname{Log}(z+2)$, where $\operatorname{Log}$ is the principal branch. I don't understand how I can apply the theorem in this case, since the branch of $f(z)$ is not defined on the ray $\theta=\pi$; hence does not satisfy the condition of analytic at all points interior to and on a simple closed contour $C$, of the theorem. How can I make sense of this problem? I would greatly appreciate any help.",,"['complex-analysis', 'complex-integration']"
92,Singular locus of analytic subvarieties,Singular locus of analytic subvarieties,,"In Griffiths and Harris page 21, it is proven that the singular locus, denoted $V_{s}$ is contained in an analytic subvariety of the complex manifold $M$ not equal to $V$ which is the analytic variety. We define $V_{s} = V - V^{*}$ where $V^{*}$ is the locus of smooth points of $V$. For $p \in V$ let k be the largest integer such that there exist k functions $f_{1},...,f_{k}$ in a neighborhood $U$ of $p$ vanishing on V and such that $J(f)$ has a $k\times k$ minor not everywhere singular on V; we may assume that $|(\frac{\partial f_{i}}{\partial z_{j}})_{1 \leq i,j \leq k}| \neq 0$ on V. Let $U' \subset U$ be the locus of $|(\frac{\partial f_{i}}{\partial z_{j}})_{1 \leq i,j \leq k}| \neq 0$ and $V'$ the locus $f_{1} = ... = f_{k} = 0$. Then $V' = V \cap U'$ is a complex submanifold of $U'$, and for any holomorphic function $f$ vanishing on V the differential $df = 0$ on $V'$, i.e., $f$ is constant on $V'$. It follows that for $q \in V'$ near $p$, $V=V'$ is a manifold in a neighborhood of q and so $V_{s} \subset |(\frac{\partial f_{i}}{\partial z_{j}})_{1 \leq i,j \leq k}| = 0$ I understand the proof up until the last statement. I believe that the holomorphic function $f$ vanishes because we stated that the integer $k$ was the largest integer and so any other such functions must have a singular $k \times k$ minor. However, I don't understand how it follows that $V=V'$ is a manifold near p and how it follows from this that $V_{s}$ is contained in the locus defined by the vanishing of the $k\times k$ minor. Thanks","In Griffiths and Harris page 21, it is proven that the singular locus, denoted $V_{s}$ is contained in an analytic subvariety of the complex manifold $M$ not equal to $V$ which is the analytic variety. We define $V_{s} = V - V^{*}$ where $V^{*}$ is the locus of smooth points of $V$. For $p \in V$ let k be the largest integer such that there exist k functions $f_{1},...,f_{k}$ in a neighborhood $U$ of $p$ vanishing on V and such that $J(f)$ has a $k\times k$ minor not everywhere singular on V; we may assume that $|(\frac{\partial f_{i}}{\partial z_{j}})_{1 \leq i,j \leq k}| \neq 0$ on V. Let $U' \subset U$ be the locus of $|(\frac{\partial f_{i}}{\partial z_{j}})_{1 \leq i,j \leq k}| \neq 0$ and $V'$ the locus $f_{1} = ... = f_{k} = 0$. Then $V' = V \cap U'$ is a complex submanifold of $U'$, and for any holomorphic function $f$ vanishing on V the differential $df = 0$ on $V'$, i.e., $f$ is constant on $V'$. It follows that for $q \in V'$ near $p$, $V=V'$ is a manifold in a neighborhood of q and so $V_{s} \subset |(\frac{\partial f_{i}}{\partial z_{j}})_{1 \leq i,j \leq k}| = 0$ I understand the proof up until the last statement. I believe that the holomorphic function $f$ vanishes because we stated that the integer $k$ was the largest integer and so any other such functions must have a singular $k \times k$ minor. However, I don't understand how it follows that $V=V'$ is a manifold near p and how it follows from this that $V_{s}$ is contained in the locus defined by the vanishing of the $k\times k$ minor. Thanks",,"['complex-analysis', 'algebraic-geometry', 'differential-geometry', 'complex-geometry']"
93,Regarding branch cuts and contour integration: $ \int_0^1 \frac{dx}{\sqrt{x^2-1}} $,Regarding branch cuts and contour integration:, \int_0^1 \frac{dx}{\sqrt{x^2-1}} ,"I am trying to compute the following integral through the use contour integration. $$ \int_0^1 \frac{dx}{\sqrt{x^2-1}} $$ So, I am considering the same integrand but from $-1$ to $1$, then doing the usual switch to a complex variable $z$.  The contour I am considering is a dumbbell type (please let me known if I need to elaborate on its shape) where the ""bells"" are centered around $-1$ and $1$, and the two horizontal contours are just above and below the real axis. I run into trouble when picking the branch cuts. What would be a good way to choose the branch in this case? A reasonable choice for me seems to be the cut $[-1,1]$, but when doing this I have trouble defining the argument on $z$.  If someone could enlighten me on this I would be very thankful.  The computation does not interest me as much as the intuition and method for defining the branch. Any help is appreciated.","I am trying to compute the following integral through the use contour integration. $$ \int_0^1 \frac{dx}{\sqrt{x^2-1}} $$ So, I am considering the same integrand but from $-1$ to $1$, then doing the usual switch to a complex variable $z$.  The contour I am considering is a dumbbell type (please let me known if I need to elaborate on its shape) where the ""bells"" are centered around $-1$ and $1$, and the two horizontal contours are just above and below the real axis. I run into trouble when picking the branch cuts. What would be a good way to choose the branch in this case? A reasonable choice for me seems to be the cut $[-1,1]$, but when doing this I have trouble defining the argument on $z$.  If someone could enlighten me on this I would be very thankful.  The computation does not interest me as much as the intuition and method for defining the branch. Any help is appreciated.",,"['complex-analysis', 'definite-integrals', 'contour-integration', 'branch-cuts']"
94,Biholomorphic map from a disk to its quarter,Biholomorphic map from a disk to its quarter,,"Could you tell me how to find a biholomorphic map from a unit disk $D$ to $\{ |z|<1 \ : \ \Re z >0, \ \Im z >0 \}$? I know that mapping of the form : $\frac{az+b}{cz+d}$ won't work. Also, we can map the quarter of the disk to upper half of the disk by $f(z) = z^2$. Then, using the map $g(z)= \frac{z-1}{z+1}$ we map  $Q:= \{ 0< \arg z < \frac{\pi}{2}\}$ to $D_+$ the  upper half of the unit disk. So $g^{-1}$ maps $D_+$ to $Q$ And $\varphi (z) = \frac{iz^2+1}{iz^2-1}: \ Q \rightarrow D$ Will this mapping work? $f^{-1} \circ g \circ \varphi ^{-1} (z)$","Could you tell me how to find a biholomorphic map from a unit disk $D$ to $\{ |z|<1 \ : \ \Re z >0, \ \Im z >0 \}$? I know that mapping of the form : $\frac{az+b}{cz+d}$ won't work. Also, we can map the quarter of the disk to upper half of the disk by $f(z) = z^2$. Then, using the map $g(z)= \frac{z-1}{z+1}$ we map  $Q:= \{ 0< \arg z < \frac{\pi}{2}\}$ to $D_+$ the  upper half of the unit disk. So $g^{-1}$ maps $D_+$ to $Q$ And $\varphi (z) = \frac{iz^2+1}{iz^2-1}: \ Q \rightarrow D$ Will this mapping work? $f^{-1} \circ g \circ \varphi ^{-1} (z)$",,"['complex-analysis', 'conformal-geometry']"
95,Cross ratio and symmetric points exercise,Cross ratio and symmetric points exercise,,"Problem Let $C$ be a circle or a line belonging to $\overline{\mathbb C}$ and let $z_2,z_3,z_4$. Two points $z$ and $z^*$ are said to be symmetric with respecto to $C$ if $\overline{(z,z_2,z_3,z_4)}=(z^*,z_2,z_3,z_4)$. $(i)$ Prove that the previous definition doesn't depend on the chosen points $z_2,z_3,z_4 \in C$ but of $C$. $(ii)$ Prove that for each $z \in \overline{\mathbb C}$ there is a unique symmetric point $z^*$ with respect to $C$. The function that assigns to each $z$ its correspondent $z^*$ with respect to $C$ is called symmetry with respect to $C$. Show that for each Möbius transformation $T$ which maps $\overline{\mathbb R}$ to $C$, the function $$T \circ \overline{T^{-1}}:\overline{\mathbb C} \to \overline{\mathbb C}$$ is the symmetry with respect to $C$. My attempt $(i)$ Let $C$ be a circle centered at $c$ of radius $R$ Using invariance of cross ratio under Möbius transformations, and using that $z_i-c=R$ for $i=2,3,4$ and $z\overline{z}=|z|^2$ we get $$\overline{(z,z_2,z_3,z_4)}=\overline{(z-c,z_2-c,z_3-c,z_4-c)}=(\overline{z}-\overline{c},\overline{z_2-c},\overline{z_3-c},\overline{z_4-c})=(\overline{z}-\overline{c},\dfrac{R^2}{z_2-c},\dfrac{R^2}{z_3-c},\dfrac{R^2}{z_4-c})=(\dfrac{R^2}{\overline{z}-\overline{c}},z_2-c,z_3-c,z_4-c)=(\dfrac{R^2}{\overline{z}-\overline{c}}+c,z_2,z_3,z_4)$$ So if $C$ is a circle, from this equation one deduces the dependence only on $C$. $(ii)$ If $C$ is a circle, from the formula $z^*=\dfrac{R^2}{\overline{z}-\overline{c}}+c$ it follows the uniqueness of $z^*$. I need help to show $(i)$ and uniqueness of $C$ if $C$ is a line. I also don't know what to do to show that $T \circ \overline{T^{-1}}:\overline{\mathbb C} \to \overline{\mathbb C}$ is the symmetry with respect to $C$, I would appreciate any suggestions.","Problem Let $C$ be a circle or a line belonging to $\overline{\mathbb C}$ and let $z_2,z_3,z_4$. Two points $z$ and $z^*$ are said to be symmetric with respecto to $C$ if $\overline{(z,z_2,z_3,z_4)}=(z^*,z_2,z_3,z_4)$. $(i)$ Prove that the previous definition doesn't depend on the chosen points $z_2,z_3,z_4 \in C$ but of $C$. $(ii)$ Prove that for each $z \in \overline{\mathbb C}$ there is a unique symmetric point $z^*$ with respect to $C$. The function that assigns to each $z$ its correspondent $z^*$ with respect to $C$ is called symmetry with respect to $C$. Show that for each Möbius transformation $T$ which maps $\overline{\mathbb R}$ to $C$, the function $$T \circ \overline{T^{-1}}:\overline{\mathbb C} \to \overline{\mathbb C}$$ is the symmetry with respect to $C$. My attempt $(i)$ Let $C$ be a circle centered at $c$ of radius $R$ Using invariance of cross ratio under Möbius transformations, and using that $z_i-c=R$ for $i=2,3,4$ and $z\overline{z}=|z|^2$ we get $$\overline{(z,z_2,z_3,z_4)}=\overline{(z-c,z_2-c,z_3-c,z_4-c)}=(\overline{z}-\overline{c},\overline{z_2-c},\overline{z_3-c},\overline{z_4-c})=(\overline{z}-\overline{c},\dfrac{R^2}{z_2-c},\dfrac{R^2}{z_3-c},\dfrac{R^2}{z_4-c})=(\dfrac{R^2}{\overline{z}-\overline{c}},z_2-c,z_3-c,z_4-c)=(\dfrac{R^2}{\overline{z}-\overline{c}}+c,z_2,z_3,z_4)$$ So if $C$ is a circle, from this equation one deduces the dependence only on $C$. $(ii)$ If $C$ is a circle, from the formula $z^*=\dfrac{R^2}{\overline{z}-\overline{c}}+c$ it follows the uniqueness of $z^*$. I need help to show $(i)$ and uniqueness of $C$ if $C$ is a line. I also don't know what to do to show that $T \circ \overline{T^{-1}}:\overline{\mathbb C} \to \overline{\mathbb C}$ is the symmetry with respect to $C$, I would appreciate any suggestions.",,"['complex-analysis', 'complex-numbers']"
96,Calculate $\int_{0}^{2\pi} \frac{\cos((2n+1)t)}{\cos(t)}dt$,Calculate,\int_{0}^{2\pi} \frac{\cos((2n+1)t)}{\cos(t)}dt,"Calculate the following integral for $n \in \mathbb{Z}$ with the   residue theorem $$\int_{0}^{2\pi} \frac{\cos((2n+1)t)}{\cos(t)}dt$$ So far I have tried two approaches. Firsty, for $n\geq 0$: $$\begin{align*}\int_{0}^{2\pi} \frac{\cos((2n+1)t)}{\cos(t)}dt &= \int_{C(0,1)^{+}} \frac{z^{2n+1}+z^{-(2n+1)}}{z+z^{-1}}\cdot \frac{1}{iz}dz \\ & = -i \int_{C(0,1)^{+}} \frac{z^{2n+1}+z^{-(2n+1)}}{z^2+1}dz \\ & = -i \int_{C(0,1)^{+}} \frac{z^{2(2n+1)}+1}{z^{2n+1}(z^2+1)}dz \\ & = -i \cdot 2\pi i \cdot Res_{z=0}\left(\frac{z^{2(2n+1)}+1}{z^{2n+1}(z^2+1)}\right) \\ & = \left.\frac{2\pi}{(2n)!} \left[ \frac{z^{2(2n+1)}+1}{z^2+1} \right]^{(2n)} \right\rvert_{z=0} \end{align*}$$ For the first equality I used the reversed parametrization  $z(t) = e^{it}$, with $0 \leq t \leq 2\pi$. The last equality follows from $Res_{z=a} \left( \frac{f(z)}{(z-a)^{n+1}}\right) = \frac{f^{(n)}(a)}{n!}$. However, I'm not sure how to calculate that derivative. Seconldy, I tried to integrate the function $f(z) = \frac{e^{i(2n+1)t}}{cos(t)}$. Using a similar technique this yields: $$\begin{align*} \int_{0}^{2\pi} \frac{e^{i(2n+1)t)}}{\cos(t)}dt &= \int_{C(0,1)^{+}} \frac{z^{2n+1}}{(z+z^{-1})/2}\cdot \frac{1}{iz}dz \\ & = -2i\int_{C(0,1)^+}\frac{z^{2n+1}}{z^2+1}dz \end{align*}$$ However, for $n \geq 1$, the singularities lie on my contour over which I integrate. How do I fix this? Can I just ignore that? Is this the right approach, or should I try differently? Thanks in advance.","Calculate the following integral for $n \in \mathbb{Z}$ with the   residue theorem $$\int_{0}^{2\pi} \frac{\cos((2n+1)t)}{\cos(t)}dt$$ So far I have tried two approaches. Firsty, for $n\geq 0$: $$\begin{align*}\int_{0}^{2\pi} \frac{\cos((2n+1)t)}{\cos(t)}dt &= \int_{C(0,1)^{+}} \frac{z^{2n+1}+z^{-(2n+1)}}{z+z^{-1}}\cdot \frac{1}{iz}dz \\ & = -i \int_{C(0,1)^{+}} \frac{z^{2n+1}+z^{-(2n+1)}}{z^2+1}dz \\ & = -i \int_{C(0,1)^{+}} \frac{z^{2(2n+1)}+1}{z^{2n+1}(z^2+1)}dz \\ & = -i \cdot 2\pi i \cdot Res_{z=0}\left(\frac{z^{2(2n+1)}+1}{z^{2n+1}(z^2+1)}\right) \\ & = \left.\frac{2\pi}{(2n)!} \left[ \frac{z^{2(2n+1)}+1}{z^2+1} \right]^{(2n)} \right\rvert_{z=0} \end{align*}$$ For the first equality I used the reversed parametrization  $z(t) = e^{it}$, with $0 \leq t \leq 2\pi$. The last equality follows from $Res_{z=a} \left( \frac{f(z)}{(z-a)^{n+1}}\right) = \frac{f^{(n)}(a)}{n!}$. However, I'm not sure how to calculate that derivative. Seconldy, I tried to integrate the function $f(z) = \frac{e^{i(2n+1)t}}{cos(t)}$. Using a similar technique this yields: $$\begin{align*} \int_{0}^{2\pi} \frac{e^{i(2n+1)t)}}{\cos(t)}dt &= \int_{C(0,1)^{+}} \frac{z^{2n+1}}{(z+z^{-1})/2}\cdot \frac{1}{iz}dz \\ & = -2i\int_{C(0,1)^+}\frac{z^{2n+1}}{z^2+1}dz \end{align*}$$ However, for $n \geq 1$, the singularities lie on my contour over which I integrate. How do I fix this? Can I just ignore that? Is this the right approach, or should I try differently? Thanks in advance.",,['complex-analysis']
97,Contour integration of a meromorphic function,Contour integration of a meromorphic function,,Given a meromorphic function $f$ which is uniformly bounded on the upper half plane. Assume that $\int_{-\infty}^{+\infty} f(x)dx$ is absolutely integrable. Then Cauchy's integral theorem suggests $\int_{-\infty}^{+\infty}f(x)dx=0$ except there is some tricky business around infinity. Can someone give me a counterexample or a supporting argument?,Given a meromorphic function $f$ which is uniformly bounded on the upper half plane. Assume that $\int_{-\infty}^{+\infty} f(x)dx$ is absolutely integrable. Then Cauchy's integral theorem suggests $\int_{-\infty}^{+\infty}f(x)dx=0$ except there is some tricky business around infinity. Can someone give me a counterexample or a supporting argument?,,"['complex-analysis', 'contour-integration']"
98,Uniform convergence of a sequence of functions,Uniform convergence of a sequence of functions,,"$f: D \rightarrow D$ is an analytic function on a bounded domain $D$ with $f(0)=0$ and $|f'(0)| < 1$. If $F_n(z) := f \circ \dots \circ f(z)$, show that $F_n(z) \rightarrow 0$ as $n \rightarrow \infty$ uniformly on compact subsets of $D$. My first instinct was to use Schwarz somehow, but turns out that $D$ is not necessarily simply connected, so I cannot use the Riemann mapping theorem to map $D$ to the unit disc. So, I was thinking about using Arzela-Ascoli somehow, but not sure how... There also is a suggestion to consider the behavior of $F_n$ on a small neighborhood of 0. In a neighborhood of 0, I assume that something similar to contraction mapping happens. Help!","$f: D \rightarrow D$ is an analytic function on a bounded domain $D$ with $f(0)=0$ and $|f'(0)| < 1$. If $F_n(z) := f \circ \dots \circ f(z)$, show that $F_n(z) \rightarrow 0$ as $n \rightarrow \infty$ uniformly on compact subsets of $D$. My first instinct was to use Schwarz somehow, but turns out that $D$ is not necessarily simply connected, so I cannot use the Riemann mapping theorem to map $D$ to the unit disc. So, I was thinking about using Arzela-Ascoli somehow, but not sure how... There also is a suggestion to consider the behavior of $F_n$ on a small neighborhood of 0. In a neighborhood of 0, I assume that something similar to contraction mapping happens. Help!",,['complex-analysis']
99,Multidimensional complex integral of a holomorphic function with no poles,Multidimensional complex integral of a holomorphic function with no poles,,"I am looking for a generalization of the Cauchy integral theorem. I know that there are generalizations of the Cauchy integral formula (eg the Bochner-Martinelli formula), but I do not know if this simplifies as I would hope. In single-variable complex analysis, we have the Cauchy integral theorem: $$ \oint_{\gamma}f(z) = 0 $$ if $f(z)$ is a holomorphic function with no poles within the region that $\gamma$ encloses. If $f(z_1\cdots,z_n)$ is a holomorphic function in $n$ complex variables with no poles within a domain $D$, is it true that $$ \oint_{\partial D}f(z_1,\cdots,z_n) = 0 $$","I am looking for a generalization of the Cauchy integral theorem. I know that there are generalizations of the Cauchy integral formula (eg the Bochner-Martinelli formula), but I do not know if this simplifies as I would hope. In single-variable complex analysis, we have the Cauchy integral theorem: $$ \oint_{\gamma}f(z) = 0 $$ if $f(z)$ is a holomorphic function with no poles within the region that $\gamma$ encloses. If $f(z_1\cdots,z_n)$ is a holomorphic function in $n$ complex variables with no poles within a domain $D$, is it true that $$ \oint_{\partial D}f(z_1,\cdots,z_n) = 0 $$",,"['complex-analysis', 'several-complex-variables']"
