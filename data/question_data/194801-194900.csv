,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,prove strictly convexity,prove strictly convexity,,"I wanna show $f(x)=-x^{\top}p+c\cdot\sqrt{x^\top\Sigma x}$ is strictly convex, where $p$ is a constant vector, $\Sigma$ is positive definite. I tried to show it by using $f''(x)$ is positive definite and I could obtain $$H(x)=c\cdot \frac{\Sigma -\frac{(\Sigma x)(\Sigma x)^{\top}}{x^\top\Sigma x}}{\sqrt{x^\top \Sigma x}}$$ yet I am stuck here. Could someone help me clarify it? Thanks in advance!","I wanna show $f(x)=-x^{\top}p+c\cdot\sqrt{x^\top\Sigma x}$ is strictly convex, where $p$ is a constant vector, $\Sigma$ is positive definite. I tried to show it by using $f''(x)$ is positive definite and I could obtain $$H(x)=c\cdot \frac{\Sigma -\frac{(\Sigma x)(\Sigma x)^{\top}}{x^\top\Sigma x}}{\sqrt{x^\top \Sigma x}}$$ yet I am stuck here. Could someone help me clarify it? Thanks in advance!",,"['calculus', 'derivatives', 'convex-analysis', 'positive-definite']"
1,Matrix trace derivatives,Matrix trace derivatives,,"Hi I am trying to take derivatives of the matrix trace. I do know that $$ \frac{d}{dx} Tr[A x]= A^\top $$ Now assuming $x$ is a complex square matrix, I am trying to calculate $$ \frac{d}{dx}Tr[x x^\top], \quad \frac{d}{dx} Tr[x x^\dagger] $$  Where $x^\top$ Is the matrix transpose and $x^\dagger$ is the hermitian transpose (complex transpose). How can I go about calculating these derivatives? Are the results the same? Does the transpose or complex transpose change anything? I am very bad with derivatives of matrix traces any help is greatly appreciated.  Thanks!","Hi I am trying to take derivatives of the matrix trace. I do know that $$ \frac{d}{dx} Tr[A x]= A^\top $$ Now assuming $x$ is a complex square matrix, I am trying to calculate $$ \frac{d}{dx}Tr[x x^\top], \quad \frac{d}{dx} Tr[x x^\dagger] $$  Where $x^\top$ Is the matrix transpose and $x^\dagger$ is the hermitian transpose (complex transpose). How can I go about calculating these derivatives? Are the results the same? Does the transpose or complex transpose change anything? I am very bad with derivatives of matrix traces any help is greatly appreciated.  Thanks!",,"['calculus', 'linear-algebra', 'matrices', 'derivatives']"
2,How important are differentiation and integration tricks and techniques to mathematicians? [closed],How important are differentiation and integration tricks and techniques to mathematicians? [closed],,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 7 years ago . Improve this question Having almost finished an honours calculus sequence, I'm now about to enroll in a real analysis course. I've been buying some interesting books lately on top of my required reading list (for example, I supplemented my Calculus book, which was Peter Lax' ""Calculus With Applications"" , with Mercer's ""More Calculus of a Single Variable"" ), and I'm now faced with the opportunity to buy a book on various Calculus techniques and tricks - Klambauer's ""Aspects of Calculus"" , to be precise - but I'm not sure if working through this book will be worth my time, or if I'd be better served spending my spare time working through some other topic. So, in trying to find an answer to this question, I think it's fair to generalize it and ask instead, how important are ""advanced"" differentiation and integration techniques and tricks to a mathematics major intending to work towards a PhD in mathematics - possibly aspiring to work in academia? I'd imagine such a question leads to different answers depending on what area of mathematics you decide to work in, so I'll leave the area unspecified. Also, I'm aware this question is somewhat similar to this one , but I'm specifically asking about the advanced techniques and tricks as discussed in Klambauer's book, not so much about calculus in general. Klambauer's book is quite particular about what it covers (difficult rational integration examples, hard derivatives, complicated series etc etc). Edit: again, allow me to emphasize that the answers will depend on what area of mathematics one decides to work in. I'm aware of that, and I knowingly and purposefully left the mathematical area unspecified so as to encourage open-ended answers that will end up painting a more complete picture than only focusing on the relevance of advanced differentiation tricks and techniques in just algebraic geometry, for example.","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 7 years ago . Improve this question Having almost finished an honours calculus sequence, I'm now about to enroll in a real analysis course. I've been buying some interesting books lately on top of my required reading list (for example, I supplemented my Calculus book, which was Peter Lax' ""Calculus With Applications"" , with Mercer's ""More Calculus of a Single Variable"" ), and I'm now faced with the opportunity to buy a book on various Calculus techniques and tricks - Klambauer's ""Aspects of Calculus"" , to be precise - but I'm not sure if working through this book will be worth my time, or if I'd be better served spending my spare time working through some other topic. So, in trying to find an answer to this question, I think it's fair to generalize it and ask instead, how important are ""advanced"" differentiation and integration techniques and tricks to a mathematics major intending to work towards a PhD in mathematics - possibly aspiring to work in academia? I'd imagine such a question leads to different answers depending on what area of mathematics you decide to work in, so I'll leave the area unspecified. Also, I'm aware this question is somewhat similar to this one , but I'm specifically asking about the advanced techniques and tricks as discussed in Klambauer's book, not so much about calculus in general. Klambauer's book is quite particular about what it covers (difficult rational integration examples, hard derivatives, complicated series etc etc). Edit: again, allow me to emphasize that the answers will depend on what area of mathematics one decides to work in. I'm aware of that, and I knowingly and purposefully left the mathematical area unspecified so as to encourage open-ended answers that will end up painting a more complete picture than only focusing on the relevance of advanced differentiation tricks and techniques in just algebraic geometry, for example.",,"['calculus', 'integration', 'derivatives', 'soft-question', 'education']"
3,Counterexample in a proof about $L^p$ spaces,Counterexample in a proof about  spaces,L^p,"I was reading a proof about the differentiability of the function: $N(\lambda) = \int_{x} | f + \lambda g|^p dm$ with $ \lambda \in [0,1]$. Where $(X, M, m)$ is a measure space and $f, g \in L^p(m)$ with $p>1$ In the proof it is said that the function defined by $F(\lambda, y) = | f(y) + \lambda g(y)|^p$ is $C^1$ with respect to $\lambda$ for almost every $y \in X$ I don't understand how one can see it. I tried to get a counterexample and I thought about: $X=[0,1]$ with lebesgue measure. $f,g:[0,1] \rightarrow \mathbb{R}$ defined by $f(x) = -1/2$ if $x \in \mathbb{R}-\mathbb{Q}$ and $f(x) =3$ if $x \in \mathbb{Q}$. And $g(x) = 1$ if $x \in \mathbb{R}-\mathbb{Q}$ and $g(x) = 0$ if $x \in \mathbb{Q}$. Thus I get: $F(\lambda, x)=|-1/2 + \lambda|^p$ if  $x \in \mathbb{R}-\mathbb{Q}$ and  $F(\lambda, x)=|3|^p$ if $x \in \mathbb{Q}$. Thus i get that $F$ is not differentiable in $\lambda = 1/2$ for every $x \in R-Q$. Is it a counterexample?","I was reading a proof about the differentiability of the function: $N(\lambda) = \int_{x} | f + \lambda g|^p dm$ with $ \lambda \in [0,1]$. Where $(X, M, m)$ is a measure space and $f, g \in L^p(m)$ with $p>1$ In the proof it is said that the function defined by $F(\lambda, y) = | f(y) + \lambda g(y)|^p$ is $C^1$ with respect to $\lambda$ for almost every $y \in X$ I don't understand how one can see it. I tried to get a counterexample and I thought about: $X=[0,1]$ with lebesgue measure. $f,g:[0,1] \rightarrow \mathbb{R}$ defined by $f(x) = -1/2$ if $x \in \mathbb{R}-\mathbb{Q}$ and $f(x) =3$ if $x \in \mathbb{Q}$. And $g(x) = 1$ if $x \in \mathbb{R}-\mathbb{Q}$ and $g(x) = 0$ if $x \in \mathbb{Q}$. Thus I get: $F(\lambda, x)=|-1/2 + \lambda|^p$ if  $x \in \mathbb{R}-\mathbb{Q}$ and  $F(\lambda, x)=|3|^p$ if $x \in \mathbb{Q}$. Thus i get that $F$ is not differentiable in $\lambda = 1/2$ for every $x \in R-Q$. Is it a counterexample?",,"['real-analysis', 'derivatives', 'lp-spaces']"
4,Why is ($dx)^2$ tiny quantity of $x^2$ and not of $x?$,Why is ( tiny quantity of  and not of,dx)^2 x^2 x?,When we say dx we are referring to a tiny quantity of $ x$ . And from literature the $(dx)^2$ is a tiny quantity of $x^2$ This is the part I am not clear about. A minute is $\frac{1}{60}$ of an hour so we could denote $\frac{1}{60}$ as $dx$ and the hour as $x$ Now a second $(\frac{1}{60})^2$ is a tiny quantity of a minute and therefore a tiny quantity of a tiny quantity of an hour. But I already said that hour is $x$. So how can we also say that it is a tiny quantity of $x^2$? (which is I guess $hour^2$?),When we say dx we are referring to a tiny quantity of $ x$ . And from literature the $(dx)^2$ is a tiny quantity of $x^2$ This is the part I am not clear about. A minute is $\frac{1}{60}$ of an hour so we could denote $\frac{1}{60}$ as $dx$ and the hour as $x$ Now a second $(\frac{1}{60})^2$ is a tiny quantity of a minute and therefore a tiny quantity of a tiny quantity of an hour. But I already said that hour is $x$. So how can we also say that it is a tiny quantity of $x^2$? (which is I guess $hour^2$?),,"['calculus', 'derivatives', 'terminology', 'math-history']"
5,What is the m-th derivative of $f(x)=a_{n}x^{n}+a_{n-1}x^{n-1}+a_{n-2}x^{n-2}+\ldots+a_{2}x^{2}+a_{1}x+a_{0}$?,What is the m-th derivative of ?,f(x)=a_{n}x^{n}+a_{n-1}x^{n-1}+a_{n-2}x^{n-2}+\ldots+a_{2}x^{2}+a_{1}x+a_{0},"Let there be an arbitrary polynomial of degree $n$: $$f(x)=a_{n}x^{n}+a_{n-1}x^{n-1}+a_{n-2}x^{n-2}+\ldots+a_{2}x^{2}+a_{1}x+a_{0}$$ where the $a_{i}$'s are constants. What would be the m-th derivative of f(x), i.e. $f^{(m)}(x)$? I figured out there would be 3 cases for $m$ and $n$. If $m=n$, then $$f^{(m)}(x)=n\cdot (n-1)\cdot (n-2)\cdot \ldots \cdot 1\cdot a_{n}\cdot x^{n-m}=n!\cdot a_{n}$$ If $m>n$, then $$f^{(m)}(x)=\frac{d^{m-n} \space f^{(n)}(x)}{dx^{m-n}}=\frac{d^{m-n} \space (n!\cdot a_{n})}{dx^{m-n}}=0$$ But what happens if $m<n$? I couldn't make any sense out of the expression I obtained. Any help would be appreciated. Thanks.","Let there be an arbitrary polynomial of degree $n$: $$f(x)=a_{n}x^{n}+a_{n-1}x^{n-1}+a_{n-2}x^{n-2}+\ldots+a_{2}x^{2}+a_{1}x+a_{0}$$ where the $a_{i}$'s are constants. What would be the m-th derivative of f(x), i.e. $f^{(m)}(x)$? I figured out there would be 3 cases for $m$ and $n$. If $m=n$, then $$f^{(m)}(x)=n\cdot (n-1)\cdot (n-2)\cdot \ldots \cdot 1\cdot a_{n}\cdot x^{n-m}=n!\cdot a_{n}$$ If $m>n$, then $$f^{(m)}(x)=\frac{d^{m-n} \space f^{(n)}(x)}{dx^{m-n}}=\frac{d^{m-n} \space (n!\cdot a_{n})}{dx^{m-n}}=0$$ But what happens if $m<n$? I couldn't make any sense out of the expression I obtained. Any help would be appreciated. Thanks.",,"['calculus', 'derivatives', 'polynomials']"
6,Inflection points with natural logs.,Inflection points with natural logs.,,"Where are the inflection points, if any exist, for $f(x)=10\frac{\ln(\ln(x))}{\ln(x)}$? I don't think any exist. But could use a little help. My guess would be that with the second derivative, if $x = e^{-2}$ you get 0, but this is not in the domain of the function. Is this correct, or completely off? Any help would be appreciated.","Where are the inflection points, if any exist, for $f(x)=10\frac{\ln(\ln(x))}{\ln(x)}$? I don't think any exist. But could use a little help. My guess would be that with the second derivative, if $x = e^{-2}$ you get 0, but this is not in the domain of the function. Is this correct, or completely off? Any help would be appreciated.",,['calculus']
7,Normal Derivative: Identity,Normal Derivative: Identity,,"I don't really get this identity : $$ \frac{\partial\Phi}{\partial n} = \vec n . \nabla \Phi $$ So gradient is: $$ \nabla \Phi = \frac{\partial\Phi}{\partial x}  \vec i +\frac{\partial\Phi}{\partial y} \vec j +\frac{\partial\Phi}{\partial z}  \vec k  $$ Normal vector is: $$ \vec n = n_x \vec i + n_y \vec j+ n_z \vec k $$ RHS of identity: $$\vec n . \nabla \Phi = n_x \frac{\partial\Phi}{\partial x} +  n_y \frac{\partial\Phi}{\partial y} +  n_z \frac{\partial\Phi}{\partial z} $$ So must be: $$ \frac{\partial\Phi}{\partial n} =  n_x \frac{\partial\Phi}{\partial x} +  n_y \frac{\partial\Phi}{\partial y} +  n_z \frac{\partial\Phi}{\partial z} $$ Now is my question, what is $n_x $ , so the components of the normal vector Can this be true: $$n_x = \frac{\partial x}{\partial n} $$","I don't really get this identity : $$ \frac{\partial\Phi}{\partial n} = \vec n . \nabla \Phi $$ So gradient is: $$ \nabla \Phi = \frac{\partial\Phi}{\partial x}  \vec i +\frac{\partial\Phi}{\partial y} \vec j +\frac{\partial\Phi}{\partial z}  \vec k  $$ Normal vector is: $$ \vec n = n_x \vec i + n_y \vec j+ n_z \vec k $$ RHS of identity: $$\vec n . \nabla \Phi = n_x \frac{\partial\Phi}{\partial x} +  n_y \frac{\partial\Phi}{\partial y} +  n_z \frac{\partial\Phi}{\partial z} $$ So must be: $$ \frac{\partial\Phi}{\partial n} =  n_x \frac{\partial\Phi}{\partial x} +  n_y \frac{\partial\Phi}{\partial y} +  n_z \frac{\partial\Phi}{\partial z} $$ Now is my question, what is $n_x $ , so the components of the normal vector Can this be true: $$n_x = \frac{\partial x}{\partial n} $$",,"['derivatives', 'partial-derivative', 'vector-analysis']"
8,Prove that a function containing $n!$ is decreasing,Prove that a function containing  is decreasing,n!,"Taking the derivative of the function $f(n)=n!$ with $n \in \mathbb{N}$ is not possible. But is there some alternative way to understand if a function with $n!$ is decreasing (besides the definition of decreasing, i.e. proving that $f(n+1)<f(n)$ directly, which is hard to do in some cases). For example: suppose that I need to use Leibniz rule of convergence for this series. $$\sum_{n \geq 1} (-1)^n \frac{\mathrm{sin}(n!)}{n^5}$$ Firstly I must prove that $ \frac{\mathrm{sin}(n!)}{n^5}$ is decreasing, but how can I do without taking the derivative?","Taking the derivative of the function $f(n)=n!$ with $n \in \mathbb{N}$ is not possible. But is there some alternative way to understand if a function with $n!$ is decreasing (besides the definition of decreasing, i.e. proving that $f(n+1)<f(n)$ directly, which is hard to do in some cases). For example: suppose that I need to use Leibniz rule of convergence for this series. $$\sum_{n \geq 1} (-1)^n \frac{\mathrm{sin}(n!)}{n^5}$$ Firstly I must prove that $ \frac{\mathrm{sin}(n!)}{n^5}$ is decreasing, but how can I do without taking the derivative?",,"['calculus', 'sequences-and-series', 'elementary-number-theory', 'derivatives', 'factorial']"
9,Prove if $|f|$ is differentiable at $a$ and $f$ is continuous at $a$ then $f$ is differentiable at $a$,Prove if  is differentiable at  and  is continuous at  then  is differentiable at,|f| a f a f a,"I have a problem Prove if $|f|$ is differentiable at $a$ and $f$ is continuous at $a$ then $f$ is differentiable at $a$ Hint: I need prove $|\lim_{x\rightarrow a}\frac{f(x)-f(a)}{x-a}|=\lim_{x\rightarrow a}|\frac{f(x)-f(a)}{x-a}|$ I try use this fact: $\lim_{x\rightarrow a}\frac{|f(x)|-|f(a)|}{x-a}$ Exist and $\lim_{x\rightarrow a}|f(x)|-|f(a)|=0$ But I'm stuck, please someone help me?","I have a problem Prove if $|f|$ is differentiable at $a$ and $f$ is continuous at $a$ then $f$ is differentiable at $a$ Hint: I need prove $|\lim_{x\rightarrow a}\frac{f(x)-f(a)}{x-a}|=\lim_{x\rightarrow a}|\frac{f(x)-f(a)}{x-a}|$ I try use this fact: $\lim_{x\rightarrow a}\frac{|f(x)|-|f(a)|}{x-a}$ Exist and $\lim_{x\rightarrow a}|f(x)|-|f(a)|=0$ But I'm stuck, please someone help me?",,"['real-analysis', 'derivatives']"
10,What is the derivative of the determinant of a symmetric positive definite matrix?,What is the derivative of the determinant of a symmetric positive definite matrix?,,"According to matrix cookbook $$\frac{\partial \det Y}{\partial x} = \det (Y) \text{Tr}\left( Y^{-1} \frac{\partial Y}{\partial x}\right) $$ Now assume $Y$ is a variance covariance matrix $\Sigma$, which is by definition symmetric and positive definite. Furthermore assume we derive for $x=\Sigma$. Does it follow that $$\frac{\partial \det \Sigma}{\partial \Sigma} = \det (\Sigma) \text{Tr}\left( \Sigma^{-1} \frac{\partial \Sigma}{\partial \Sigma}\right) = \det (\Sigma) \text{Tr}( \Sigma^{-1}) ?$$ In a related post I asked a similar question and a reply seems to suggest (and the reply seems to give the correct result) $$\frac{\partial \det \Sigma}{\partial \Sigma} = \det (\Sigma) \Sigma^{-1}.$$ So I wonder if I make a mistake in the second row of equations of if this is a special case due to the properties of $\Sigma$.","According to matrix cookbook $$\frac{\partial \det Y}{\partial x} = \det (Y) \text{Tr}\left( Y^{-1} \frac{\partial Y}{\partial x}\right) $$ Now assume $Y$ is a variance covariance matrix $\Sigma$, which is by definition symmetric and positive definite. Furthermore assume we derive for $x=\Sigma$. Does it follow that $$\frac{\partial \det \Sigma}{\partial \Sigma} = \det (\Sigma) \text{Tr}\left( \Sigma^{-1} \frac{\partial \Sigma}{\partial \Sigma}\right) = \det (\Sigma) \text{Tr}( \Sigma^{-1}) ?$$ In a related post I asked a similar question and a reply seems to suggest (and the reply seems to give the correct result) $$\frac{\partial \det \Sigma}{\partial \Sigma} = \det (\Sigma) \Sigma^{-1}.$$ So I wonder if I make a mistake in the second row of equations of if this is a special case due to the properties of $\Sigma$.",,"['derivatives', 'determinant', 'covariance']"
11,Is $f(x)= \frac{1}{x}-\frac{1}{e^{x}-1}$ increasing or decreasing?,Is  increasing or decreasing?,f(x)= \frac{1}{x}-\frac{1}{e^{x}-1},Is $f(x)= \frac{1}{x}-\frac{1}{e^{x}-1}$ increasing or decreasing? $$f(x)= \frac{1}{x}- (e^{x}-1)^{-1}$$ $$f'(x)=-\frac{1}{x^{2}}+(e^{x}-1)^{-2} \cdot e^{x}$$ $$f'(x)=-\frac{1}{x^{2}}+\frac{e^{x}}{(e^{x}-1)^{2}}$$ For all $x \geq 1$ we have that $f'(x) < 0$ $\Rightarrow$ monotonic decreasing function Is this correct?,Is $f(x)= \frac{1}{x}-\frac{1}{e^{x}-1}$ increasing or decreasing? $$f(x)= \frac{1}{x}- (e^{x}-1)^{-1}$$ $$f'(x)=-\frac{1}{x^{2}}+(e^{x}-1)^{-2} \cdot e^{x}$$ $$f'(x)=-\frac{1}{x^{2}}+\frac{e^{x}}{(e^{x}-1)^{2}}$$ For all $x \geq 1$ we have that $f'(x) < 0$ $\Rightarrow$ monotonic decreasing function Is this correct?,,"['calculus', 'real-analysis', 'derivatives', 'proof-verification']"
12,About the differentiability of a Weierstrass-like function,About the differentiability of a Weierstrass-like function,,"Let we consider: $$f(x)=\sum_{n=1}^{\infty}\frac{\sin(2^nx)}{n^2}$$ Since $\left|\sin x\right|\leq 1$ and $\sum_{n\geq 1}\frac{1}{n^2}<2$, the above series is uniformly convergent and $f(x)$ is a continuous function. The series associated with the formal derivative, $\sum_{n\geq 1}\frac{2^n\cos(2^n x)}{n^2}$, looks like it is not convergent for any $x\in\mathbb{R}$. Is it sufficient to prove this fact, to deduce that $f(x)$ is not differentiable at any $x\in\mathbb{R}$?","Let we consider: $$f(x)=\sum_{n=1}^{\infty}\frac{\sin(2^nx)}{n^2}$$ Since $\left|\sin x\right|\leq 1$ and $\sum_{n\geq 1}\frac{1}{n^2}<2$, the above series is uniformly convergent and $f(x)$ is a continuous function. The series associated with the formal derivative, $\sum_{n\geq 1}\frac{2^n\cos(2^n x)}{n^2}$, looks like it is not convergent for any $x\in\mathbb{R}$. Is it sufficient to prove this fact, to deduce that $f(x)$ is not differentiable at any $x\in\mathbb{R}$?",,"['real-analysis', 'derivatives']"
13,Exercise about limit.,Exercise about limit.,,"Let be $g(t)=t\ln t$, $t>0$. How to show that $\displaystyle\lim_{t\rightarrow \infty} \frac{g^{-1}(t)}{t} = 0$ ? I'm trying to do using the L'Hospital rule, but I can not justify that $\displaystyle\lim_{t\rightarrow \infty}g^{-1}(t)=\infty$.","Let be $g(t)=t\ln t$, $t>0$. How to show that $\displaystyle\lim_{t\rightarrow \infty} \frac{g^{-1}(t)}{t} = 0$ ? I'm trying to do using the L'Hospital rule, but I can not justify that $\displaystyle\lim_{t\rightarrow \infty}g^{-1}(t)=\infty$.",,['limits']
14,Implications of a Curve being Tangent to a Line,Implications of a Curve being Tangent to a Line,,"In my experience, I have usually dealt with finding or analyzing tangents to a curve. In this question I've encountered, I am asked to analyze a curve given it is a tangent to the line y=x . Here is the curve: $y=(x^3/3)+ax+b. $ I am tasked to prove that the above conditions imply that: $4(a-1)^3+9b^2=0$ I have deduced some things from the implication, but I feel that I have not deduced enough! Here is what I have understood so far: The slope of $y=x$ is 1. At the point the curve is tangent to this line, it's slope is 1. Therefore, I differentiated the equation of the curve with respect to $x$ and reached the following conclusion: $x^2+a=1$ so $x=\pm \sqrt(1-a) $ Substituting this result in the equation of the curve, I get $y=((\pm \sqrt(1-a))^3/3)+a(\pm \sqrt(1-a))+b. $ This is something, but does not seem to get me closer to deducing the required. At the point where the curve is tangent, we also have $y=x=\pm \sqrt(1-a)=((\pm \sqrt(1-a))^3/3)+a(\pm \sqrt(1-a))+b. $ My question is thus: Am I not considering an implication of the curve being a tangent to this line that will help me deduce the required?","In my experience, I have usually dealt with finding or analyzing tangents to a curve. In this question I've encountered, I am asked to analyze a curve given it is a tangent to the line y=x . Here is the curve: $y=(x^3/3)+ax+b. $ I am tasked to prove that the above conditions imply that: $4(a-1)^3+9b^2=0$ I have deduced some things from the implication, but I feel that I have not deduced enough! Here is what I have understood so far: The slope of $y=x$ is 1. At the point the curve is tangent to this line, it's slope is 1. Therefore, I differentiated the equation of the curve with respect to $x$ and reached the following conclusion: $x^2+a=1$ so $x=\pm \sqrt(1-a) $ Substituting this result in the equation of the curve, I get $y=((\pm \sqrt(1-a))^3/3)+a(\pm \sqrt(1-a))+b. $ This is something, but does not seem to get me closer to deducing the required. At the point where the curve is tangent, we also have $y=x=\pm \sqrt(1-a)=((\pm \sqrt(1-a))^3/3)+a(\pm \sqrt(1-a))+b. $ My question is thus: Am I not considering an implication of the curve being a tangent to this line that will help me deduce the required?",,"['calculus', 'derivatives', 'proof-verification', 'tangent-line']"
15,"Chain rule when $u$ is a fucntion of $x$ and $y$ and both $x$ , $y$ are fucntions of $u$ and $v$","Chain rule when  is a fucntion of  and  and both  ,  are fucntions of  and",u x y x y u v,"Find $\frac{\partial u}{\partial x}$ where $u$ and $v$ are functions of $x$ and $y$ $\bigg($ $u(x,y)$ and $v(x,y)$ $\bigg)$ and $x$ and $y$ is of the form, $x = f(u,v), y=g(u,v)$. This was in an exam and had multiple choices for answers. Some answers contained $\partial f$ and $\partial g$ terms.","Find $\frac{\partial u}{\partial x}$ where $u$ and $v$ are functions of $x$ and $y$ $\bigg($ $u(x,y)$ and $v(x,y)$ $\bigg)$ and $x$ and $y$ is of the form, $x = f(u,v), y=g(u,v)$. This was in an exam and had multiple choices for answers. Some answers contained $\partial f$ and $\partial g$ terms.",,"['real-analysis', 'derivatives', 'partial-derivative']"
16,"If the radius of a sphere is increased by $10\%$, by what percentage is its volume increased?","If the radius of a sphere is increased by , by what percentage is its volume increased?",10\%,"Question: If the radius of a sphere is increased by $10\%$ , by what percentage is its volume increased? Use Calculus. Answer: It increases by approximately $33.1\%$ . I did the above question using calculus but my answer came out to be 30%. Here's the solution. What is wrong in it? $V = \frac{4}{3} πr^3$ $dV = \frac 4 3  π \cdot 3  r^2 dr$ $dV  = 4 π r^2 dr$ since $dr = \frac{10}{100} r$ therefore $dV = 4  π  r^2 \cdot \frac{10}{100}  r$ $dV = \frac 4 {10} π r^3$ now $dV/V = [ \frac 4{10}  πr^3] / [ \frac 4 3  πr^3]$ $dV/V = 3/10$ and $100dV/V = \frac 3{10} \times 100 = 30\%  $","Question: If the radius of a sphere is increased by , by what percentage is its volume increased? Use Calculus. Answer: It increases by approximately . I did the above question using calculus but my answer came out to be 30%. Here's the solution. What is wrong in it? since therefore now and",10\% 33.1\% V = \frac{4}{3} πr^3 dV = \frac 4 3  π \cdot 3  r^2 dr dV  = 4 π r^2 dr dr = \frac{10}{100} r dV = 4  π  r^2 \cdot \frac{10}{100}  r dV = \frac 4 {10} π r^3 dV/V = [ \frac 4{10}  πr^3] / [ \frac 4 3  πr^3] dV/V = 3/10 100dV/V = \frac 3{10} \times 100 = 30\%  ,"['calculus', 'derivatives']"
17,"Which version of the total derivative formula is ""more correct""?","Which version of the total derivative formula is ""more correct""?",,"For $y=f(t,u_1,\ldots,u_m)$ with $u_i$ depending on $t$, i.e. $y$ not only directly but also indirectly depending on $t$: Wolfram says: $\frac{\partial y}{\partial t}=\frac{\partial f}{\partial t}+\frac{\partial f}{\partial u_1}\frac{\partial u_1}{\partial t}+ \ldots+\frac{\partial f}{\partial u_m}\frac{\partial u_m}{\partial t}$ while Wikipedia says: $\frac{df}{dt}=\frac{\partial f}{\partial t}+\frac{\partial f}{\partial u_1}\frac{du_1}{dt}+ \ldots+\frac{\partial f}{\partial u_m}\frac{du_m}{dt}$ Is it not unambiguous at Wolfram that partial and total derivative are used with the same symbols? From what I have read, total derivatives take into account the indirect effects of $t$, while partial derivatives do not. Even if the expression left to the equal sign here could be chosen freely (i.e. $\frac{df}{dt} \equiv \frac{\partial y}{\partial t}$): Does Wolfram not disregard that also $u_i$ could be some function that, again, depends indirectly on $t$? If I understand correctly, the partial derivative would neglect that, the total would not. Is this correct? Is Wolfram unprecise here because it uses $\frac{\partial u_1}{\partial t}$ instead of $\frac{du_1}{dt}$? Also, the Wolfram expression for the total derivative confuses me... Using the partial derivative on a variable that is the result of a function seems even more unprecise. $\frac{\partial y}{\partial t}$ is the total derivative and $\frac{\partial f}{\partial t}$ is the partial derivative... what is the intuition/reasoning for this?","For $y=f(t,u_1,\ldots,u_m)$ with $u_i$ depending on $t$, i.e. $y$ not only directly but also indirectly depending on $t$: Wolfram says: $\frac{\partial y}{\partial t}=\frac{\partial f}{\partial t}+\frac{\partial f}{\partial u_1}\frac{\partial u_1}{\partial t}+ \ldots+\frac{\partial f}{\partial u_m}\frac{\partial u_m}{\partial t}$ while Wikipedia says: $\frac{df}{dt}=\frac{\partial f}{\partial t}+\frac{\partial f}{\partial u_1}\frac{du_1}{dt}+ \ldots+\frac{\partial f}{\partial u_m}\frac{du_m}{dt}$ Is it not unambiguous at Wolfram that partial and total derivative are used with the same symbols? From what I have read, total derivatives take into account the indirect effects of $t$, while partial derivatives do not. Even if the expression left to the equal sign here could be chosen freely (i.e. $\frac{df}{dt} \equiv \frac{\partial y}{\partial t}$): Does Wolfram not disregard that also $u_i$ could be some function that, again, depends indirectly on $t$? If I understand correctly, the partial derivative would neglect that, the total would not. Is this correct? Is Wolfram unprecise here because it uses $\frac{\partial u_1}{\partial t}$ instead of $\frac{du_1}{dt}$? Also, the Wolfram expression for the total derivative confuses me... Using the partial derivative on a variable that is the result of a function seems even more unprecise. $\frac{\partial y}{\partial t}$ is the total derivative and $\frac{\partial f}{\partial t}$ is the partial derivative... what is the intuition/reasoning for this?",,"['derivatives', 'partial-derivative']"
18,Multiplicative Derivative,Multiplicative Derivative,,"I need a hint to recover the definition of the multiplicative derivative as $f^*(x)=e^{f'(x)/f(x)}$ starting from the definition with the limit $$f^*(x)=\lim_{h\to0}\Big(\frac{f(x+h)}{f(x)}\Big)^{\frac{1}{h}}.$$ I've tried to add and subtract $f(x)$ finding   $$f^*(x)=\lim_{h\to0}\Big(1+\frac{f(x+h)-f(x)}{f(x)}\Big)^{\frac{1}{h}}.$$ The next trick would be to rewrite $1/h$ as $$\frac{f(x)}{f(x+h)-f(x)}\frac{f(x+h)-f(x)}{h}\frac{1}{f(x)}$$ and calling $A(h)=\frac{f(x+h)-f(x)}{f(x)}$ one have   $$f^*(x)=\lim_{h\to0}\Big(1+A(h)\Big)^{\frac{1}{A(h)}\frac{f(x+h)-f(x)}{h}\frac{1}{f(x)}}.$$ I suspect that $$\lim_{h\to0}(1+h)^\frac{1}{h}=e,$$ $$\lim_{h\to0}A(h)=0$$ and $$f'(x)=\lim_{h\to0}\frac{f(x+h)-f(x)}{h}$$ must be used but I fail to see how.   What step one can do to recover the relation $f^*(x)=e^{f'(x)/f(x)}$?","I need a hint to recover the definition of the multiplicative derivative as $f^*(x)=e^{f'(x)/f(x)}$ starting from the definition with the limit $$f^*(x)=\lim_{h\to0}\Big(\frac{f(x+h)}{f(x)}\Big)^{\frac{1}{h}}.$$ I've tried to add and subtract $f(x)$ finding   $$f^*(x)=\lim_{h\to0}\Big(1+\frac{f(x+h)-f(x)}{f(x)}\Big)^{\frac{1}{h}}.$$ The next trick would be to rewrite $1/h$ as $$\frac{f(x)}{f(x+h)-f(x)}\frac{f(x+h)-f(x)}{h}\frac{1}{f(x)}$$ and calling $A(h)=\frac{f(x+h)-f(x)}{f(x)}$ one have   $$f^*(x)=\lim_{h\to0}\Big(1+A(h)\Big)^{\frac{1}{A(h)}\frac{f(x+h)-f(x)}{h}\frac{1}{f(x)}}.$$ I suspect that $$\lim_{h\to0}(1+h)^\frac{1}{h}=e,$$ $$\lim_{h\to0}A(h)=0$$ and $$f'(x)=\lim_{h\to0}\frac{f(x+h)-f(x)}{h}$$ must be used but I fail to see how.   What step one can do to recover the relation $f^*(x)=e^{f'(x)/f(x)}$?",,"['limits', 'derivatives', 'nonstandard-analysis']"
19,Tangent line intersections given the normal line equation for $(x-2)^2$,Tangent line intersections given the normal line equation for,(x-2)^2,"Sorry but I'm a bit stuck at this problem with derivatives and the tangent line, I'll be stating the problem then the steps I've done to try and solve it. The problem is stated like this: Find all points on the graph of $y = (x-2)^2$ at which the tangent line is perpendicular to the line with equation $2x - y + 2 = 0$ So I have the equation for the normal line: $y = 2(x + 1)$, so I think the  equation for the tangent line is $y = -\frac{1}{2}(x + 1)$. Since I need to get points of intersections with $(x-2)^2$, I need to get an equation for the tangent line based on it so I solve for derivatives. $$f(x) = (x - 2)^2$$ $$f'(x) = \frac{d}{dx} (x-2)^2$$ $$f'(x) = 2(x - 2)$$ So now given these, I have another equation for the tangent line at a given point of tangency $t$: $$y - f(t) = f'(t)(x - t)$$ $$y - (t - 2)^2 = 2(t - 2)(x - t)$$ $$y = 2(t - 2)(x - t) + (t - 2)^2$$ $$y = (t - 2)[2(x - t) + (t - 2)]$$ $$y = (t - 2)(2x - 2t + t - 2)$$ $$y = (t - 2)(2x -t - 2)$$ $$y = (t - 2)2(x - \frac{t}{2} - 1)$$ $$y = 2(t - 2)(x - \frac{t + 2}{2})$$ Now going back to the equation for the normal line, I now have two equations for the tangent line: $$y = -\frac{1}{2}(x + 1)$$ $$y = 2(t - 2)(x - \frac{t + 2}{2})$$ Now this is where I'm stuck. The two equations seem to imply that $2(t - 2) = -\frac{1}{2}$ and $\frac{t + 2}{2} = -1$, however solving for $t$ on the first equation gives me $\frac{7}{4}$ which seem to match what's in the answer key, but the other equation gives me $t = -4$. Why is that? Was I wrong in any of my assumptions? I know I must be missing something huge but I can't pinpoint it right now. Any help would be greatly appreciated. Thanks.","Sorry but I'm a bit stuck at this problem with derivatives and the tangent line, I'll be stating the problem then the steps I've done to try and solve it. The problem is stated like this: Find all points on the graph of $y = (x-2)^2$ at which the tangent line is perpendicular to the line with equation $2x - y + 2 = 0$ So I have the equation for the normal line: $y = 2(x + 1)$, so I think the  equation for the tangent line is $y = -\frac{1}{2}(x + 1)$. Since I need to get points of intersections with $(x-2)^2$, I need to get an equation for the tangent line based on it so I solve for derivatives. $$f(x) = (x - 2)^2$$ $$f'(x) = \frac{d}{dx} (x-2)^2$$ $$f'(x) = 2(x - 2)$$ So now given these, I have another equation for the tangent line at a given point of tangency $t$: $$y - f(t) = f'(t)(x - t)$$ $$y - (t - 2)^2 = 2(t - 2)(x - t)$$ $$y = 2(t - 2)(x - t) + (t - 2)^2$$ $$y = (t - 2)[2(x - t) + (t - 2)]$$ $$y = (t - 2)(2x - 2t + t - 2)$$ $$y = (t - 2)(2x -t - 2)$$ $$y = (t - 2)2(x - \frac{t}{2} - 1)$$ $$y = 2(t - 2)(x - \frac{t + 2}{2})$$ Now going back to the equation for the normal line, I now have two equations for the tangent line: $$y = -\frac{1}{2}(x + 1)$$ $$y = 2(t - 2)(x - \frac{t + 2}{2})$$ Now this is where I'm stuck. The two equations seem to imply that $2(t - 2) = -\frac{1}{2}$ and $\frac{t + 2}{2} = -1$, however solving for $t$ on the first equation gives me $\frac{7}{4}$ which seem to match what's in the answer key, but the other equation gives me $t = -4$. Why is that? Was I wrong in any of my assumptions? I know I must be missing something huge but I can't pinpoint it right now. Any help would be greatly appreciated. Thanks.",,"['calculus', 'algebra-precalculus', 'derivatives']"
20,Concept of the slope,Concept of the slope,,"Having difficulties understanding the concept of the slope: Suppose we have $f(x)=x^2$, its derivative $f'(x)=2x$ At $x=10$, $f(x)=100$ and $f'(x)=20$. So the rate of change of the function at $(x,y)=(10,100)$ is $20$, but what does that mean? If we take $x+1=11$, we get: $f(11)=121$ and not $120$. So what was the point of calculating the slope at (10,100)? What information did it provide us?","Having difficulties understanding the concept of the slope: Suppose we have $f(x)=x^2$, its derivative $f'(x)=2x$ At $x=10$, $f(x)=100$ and $f'(x)=20$. So the rate of change of the function at $(x,y)=(10,100)$ is $20$, but what does that mean? If we take $x+1=11$, we get: $f(11)=121$ and not $120$. So what was the point of calculating the slope at (10,100)? What information did it provide us?",,"['calculus', 'derivatives', 'soft-question', 'slope']"
21,$f$ ACL $\implies \exists \nabla f$ almost everywhere,ACL  almost everywhere,f \implies \exists \nabla f,"We have the following definition for an absolutely continuous function: Definition (absolutely continuous): A function $f:I\to \mathbb{R}^n$ , $I \subset \mathbb{R}$ interval, is said to be absolutely continuous if, $\forall \epsilon>0$ , $\exists \delta>0$ such that, $$[x_k,y_k]\subset I, k\in \{1,\dots,n\}\text{ pairwise disjoint intervals with }\sum_{k=1}^n|y_k-x_k|<\delta$$ $$\implies\sum_{k=1}^n|f(y_k)-f(x_k)|<\epsilon.$$ And then, we have the following proposition Proposition 1: If $f:I\longrightarrow\Bbb{R}^n$ is absolutely continuous, then $f$ is differentiable at almost everywhere in $I$ . Ok, now we give the definition of a absolutely continuous on lines (ACL) function. Definition (ACL): Let $\Omega\subset \Bbb{R}^n$ be a domain (open connected set) and $F:\Omega\longrightarrow \Bbb{R}^m$ a function. Given a $n$ -dimensional parallelepiped $P=[a_1,b_1]\times \dots \times [a_n,b_n]\subset \Omega$ and given a choice of $n-1$ fixed values $x_1\in [a_1,b_1],\dots,x_{i-1}\in[a_{i-1},b_{i-1}],x_{i+1}\in[a_{i+1},b_{i+1}],\dots,x_n\in[a_n,b_n]$ , we define the function $$\begin{array}{cccc}F^P_{x_1\dots x_{i-1}x_{i+1}\dots x_n}:&[a_i,b_i]&\longrightarrow &\Bbb{R}^m\\ &x_i&\mapsto& F(x_1,\dots,x_i,\dots,x_n)\end{array}$$ which ""fix"" the coordinates of $F$ at $P$ , except for $x_i$ . Then, we say $F$ is absolutely continuous on lines (or, simply, ACL), if, for every parallelepiped $P\in \Omega$ , $$F^P_{x_1\dots x_{i-1}x_{i+1}\dots x_n} \text{ is absolutely continuous for almost every ""$n-1$-choice"" as above.}$$ What I want to prove, maybe throughout Proposition 1, is Proposition 2: If $F:\Omega\subset \Bbb{R}^n\longrightarrow \Bbb{R}^m$ is ACL, then $\nabla F$ (or, partial derivatives) exists almost everywhere on $\Omega$ . ""Almost everywhere"" (:D) I've searched, books say ""it's easy to see"", ""easy to prove"", but I could not do it by myself. Can some one at least give me some insight of how to do it? I really need the case where $n=m=2$ . Fixing $x$ and looking to $F^R_x(y)=F(x,y)$ , I've tried to use that, at those points in which $F^R_y$ is NOT absolutely continuous is a set of measure zero, Proposition 1 holds. And, then, to look to the points where $F_x^R$ is NOT differentiable (which again has measure zero) and finally to make the union (in $x$ ) of all these sets, hoping that this had still measure zero. Done this, I would have taken out from $R$ a set of measure zero. Doing the same for fixed $y$ 's I would have reached the result. But my conjecture has prooved to be FALSE (in the sense that this set I'm looking at might NOT TO BE MEASURABLE), as we see here . THANK YOU, GUYS!","We have the following definition for an absolutely continuous function: Definition (absolutely continuous): A function , interval, is said to be absolutely continuous if, , such that, And then, we have the following proposition Proposition 1: If is absolutely continuous, then is differentiable at almost everywhere in . Ok, now we give the definition of a absolutely continuous on lines (ACL) function. Definition (ACL): Let be a domain (open connected set) and a function. Given a -dimensional parallelepiped and given a choice of fixed values , we define the function which ""fix"" the coordinates of at , except for . Then, we say is absolutely continuous on lines (or, simply, ACL), if, for every parallelepiped , What I want to prove, maybe throughout Proposition 1, is Proposition 2: If is ACL, then (or, partial derivatives) exists almost everywhere on . ""Almost everywhere"" (:D) I've searched, books say ""it's easy to see"", ""easy to prove"", but I could not do it by myself. Can some one at least give me some insight of how to do it? I really need the case where . Fixing and looking to , I've tried to use that, at those points in which is NOT absolutely continuous is a set of measure zero, Proposition 1 holds. And, then, to look to the points where is NOT differentiable (which again has measure zero) and finally to make the union (in ) of all these sets, hoping that this had still measure zero. Done this, I would have taken out from a set of measure zero. Doing the same for fixed 's I would have reached the result. But my conjecture has prooved to be FALSE (in the sense that this set I'm looking at might NOT TO BE MEASURABLE), as we see here . THANK YOU, GUYS!","f:I\to \mathbb{R}^n I \subset \mathbb{R} \forall \epsilon>0 \exists \delta>0 [x_k,y_k]\subset I, k\in \{1,\dots,n\}\text{ pairwise disjoint intervals with }\sum_{k=1}^n|y_k-x_k|<\delta \implies\sum_{k=1}^n|f(y_k)-f(x_k)|<\epsilon. f:I\longrightarrow\Bbb{R}^n f I \Omega\subset \Bbb{R}^n F:\Omega\longrightarrow \Bbb{R}^m n P=[a_1,b_1]\times \dots \times [a_n,b_n]\subset \Omega n-1 x_1\in [a_1,b_1],\dots,x_{i-1}\in[a_{i-1},b_{i-1}],x_{i+1}\in[a_{i+1},b_{i+1}],\dots,x_n\in[a_n,b_n] \begin{array}{cccc}F^P_{x_1\dots x_{i-1}x_{i+1}\dots x_n}:&[a_i,b_i]&\longrightarrow &\Bbb{R}^m\\ &x_i&\mapsto& F(x_1,\dots,x_i,\dots,x_n)\end{array} F P x_i F P\in \Omega F^P_{x_1\dots x_{i-1}x_{i+1}\dots x_n} \text{ is absolutely continuous for almost every ""n-1-choice"" as above.} F:\Omega\subset \Bbb{R}^n\longrightarrow \Bbb{R}^m \nabla F \Omega n=m=2 x F^R_x(y)=F(x,y) F^R_y F_x^R x R y","['measure-theory', 'derivatives', 'continuity', 'lebesgue-measure', 'almost-everywhere']"
22,When talking about gradient $\nabla f(x)$ are we assume $f(x)$ is scalar valued?,When talking about gradient  are we assume  is scalar valued?,\nabla f(x) f(x),Previously I always thought $\nabla f(x)$ is just the transpose of $Df(x)$. But recently I noticed that I wasn't able to find $\nabla f(x)$ where $f(x)$ is vector value function in my reference. Is it widely accepted that $\nabla f(x)$ should be scalar valued?,Previously I always thought $\nabla f(x)$ is just the transpose of $Df(x)$. But recently I noticed that I wasn't able to find $\nabla f(x)$ where $f(x)$ is vector value function in my reference. Is it widely accepted that $\nabla f(x)$ should be scalar valued?,,"['calculus', 'derivatives']"
23,"Applying MVT and IVT (?) to show something about f'''? (edit: actually, Taylor's Theorem using Lagrange remainder)","Applying MVT and IVT (?) to show something about f'''? (edit: actually, Taylor's Theorem using Lagrange remainder)",,"I believe that the correct answer to this question will involve applying both the Mean Value Theorem and the Intermediate Value Theorem, perhaps several times.  However, I can't see how to proceed.  I went down what I thought were the typical paths and just reached dead ends. Does someone maybe have a hint?  I think that with the appropriate nudge I should be able to solve this question.  If not, I'll edit and ask if someone knows how to solve the whole thing. Here's the question: Let $f: \mathbf R \to \mathbf R$ be such that $f$, $f'$, $f''$, and $f'''$ exist and are continuous on $\mathbf R$ and satisfying $f(-3)=-1$, $f(0)=0=f'(0)$, and $f(3)=8$.  Prove that there exists $\xi \in (-3, 3)$ such that $f'''(\xi) \ge 1$.","I believe that the correct answer to this question will involve applying both the Mean Value Theorem and the Intermediate Value Theorem, perhaps several times.  However, I can't see how to proceed.  I went down what I thought were the typical paths and just reached dead ends. Does someone maybe have a hint?  I think that with the appropriate nudge I should be able to solve this question.  If not, I'll edit and ask if someone knows how to solve the whole thing. Here's the question: Let $f: \mathbf R \to \mathbf R$ be such that $f$, $f'$, $f''$, and $f'''$ exist and are continuous on $\mathbf R$ and satisfying $f(-3)=-1$, $f(0)=0=f'(0)$, and $f(3)=8$.  Prove that there exists $\xi \in (-3, 3)$ such that $f'''(\xi) \ge 1$.",,"['calculus', 'real-analysis', 'derivatives', 'taylor-expansion']"
24,"How do I calculate $u(w)=\int_0^\infty \frac{1-\cos(wt)}{t}\,e^{-t}\,dt$?",How do I calculate ?,"u(w)=\int_0^\infty \frac{1-\cos(wt)}{t}\,e^{-t}\,dt","How do I calculate $$u(w)=\int_0^\infty \frac{1-\cos(wt)}{t}\,e^{-t}\,dt$$ I tried to do it, I use partial integration but I get lost. Is there any nice simple way to calculate it?","How do I calculate $$u(w)=\int_0^\infty \frac{1-\cos(wt)}{t}\,e^{-t}\,dt$$ I tried to do it, I use partial integration but I get lost. Is there any nice simple way to calculate it?",,"['calculus', 'integration', 'derivatives']"
25,Higher order derivatives of the binomial factor,Higher order derivatives of the binomial factor,,"Let $p$,$l$ be positive integers and $\theta$ be a parameter. The question is to compute the following quantity: \begin{equation} \kappa^{(p)}_l := \left. \frac{\partial^p}{\partial \theta^p} \binom{\theta}{l} \right|_{\theta=0} \end{equation} With the help of Mathematica we found the result for consecutive values of p. We have: \begin{equation} \kappa^{(p)}_l = \left\{ \begin{array}{rr} \delta_{l,0}           & \quad \mbox{if $p=0$} \\ \frac{(-1)^{l+1}}{l}   & \quad \mbox{if $p=1$} \\ 2 (-1)^l \cdot \frac{H_{l-1}}{l} & \quad \mbox{if $p=2$} \\ 3 (-1)^l \cdot \frac{H^{(2)}_{l-1} - H_{l-1}^2}{l} & \quad \mbox{if $p=3$} \\ 4 (-1)^l \cdot \frac{2 H^{(3)}_{l-1} - 3 H^{(2)}_{l-1} H_{l-1}+H_{l-1}^3}{l} & \quad \mbox{if $p=4$} \\ 5 (-1)^l \cdot \frac{6 H^{(4)}_{l-1} - 8 H^{(3)}_{l-1} H_{l-1}-3 H^{(2)}_{l-1} H^{(2)}_{l-1}+6 H^{(2)}_{l-1} H_{l-1}^2 - H_{l-1}^4}{l} & \quad \mbox{if $p=5$} \\ \end{array} \right. \end{equation} if $l\ge 1$ and $\kappa^{(p)}_0=\delta_{p,0}$. Here $H^{(p)}_l$ is the harmonic number of order $p$. Now, the obvious question would be to find the result for generic values of $p$.","Let $p$,$l$ be positive integers and $\theta$ be a parameter. The question is to compute the following quantity: \begin{equation} \kappa^{(p)}_l := \left. \frac{\partial^p}{\partial \theta^p} \binom{\theta}{l} \right|_{\theta=0} \end{equation} With the help of Mathematica we found the result for consecutive values of p. We have: \begin{equation} \kappa^{(p)}_l = \left\{ \begin{array}{rr} \delta_{l,0}           & \quad \mbox{if $p=0$} \\ \frac{(-1)^{l+1}}{l}   & \quad \mbox{if $p=1$} \\ 2 (-1)^l \cdot \frac{H_{l-1}}{l} & \quad \mbox{if $p=2$} \\ 3 (-1)^l \cdot \frac{H^{(2)}_{l-1} - H_{l-1}^2}{l} & \quad \mbox{if $p=3$} \\ 4 (-1)^l \cdot \frac{2 H^{(3)}_{l-1} - 3 H^{(2)}_{l-1} H_{l-1}+H_{l-1}^3}{l} & \quad \mbox{if $p=4$} \\ 5 (-1)^l \cdot \frac{6 H^{(4)}_{l-1} - 8 H^{(3)}_{l-1} H_{l-1}-3 H^{(2)}_{l-1} H^{(2)}_{l-1}+6 H^{(2)}_{l-1} H_{l-1}^2 - H_{l-1}^4}{l} & \quad \mbox{if $p=5$} \\ \end{array} \right. \end{equation} if $l\ge 1$ and $\kappa^{(p)}_0=\delta_{p,0}$. Here $H^{(p)}_l$ is the harmonic number of order $p$. Now, the obvious question would be to find the result for generic values of $p$.",,['derivatives']
26,Derivative of $\frac{\ln{x}}{\ln{a}}$,Derivative of,\frac{\ln{x}}{\ln{a}},I'm asked to prove that the derivative of $$\frac{\ln{x}}{\ln{a}}$$ is $$\frac{1}{x\cdot\ln{a}}$$ My attempt: $$\frac{d}{dx}(\frac{\ln{x}}{\ln{a}}) = \frac{\frac{1}{x}\cdot \ln{a} - \frac{1}{a}\cdot \ln{x}}{(\ln{a})^2}$$ which is  $$\frac{1}{x\cdot\ln{a}} - \frac{\ln{x}}{a\cdot (\ln{a})^2}$$ which is not equal to $$\frac{1}{x\cdot\ln{a}}$$ What am I doing wrong?,I'm asked to prove that the derivative of $$\frac{\ln{x}}{\ln{a}}$$ is $$\frac{1}{x\cdot\ln{a}}$$ My attempt: $$\frac{d}{dx}(\frac{\ln{x}}{\ln{a}}) = \frac{\frac{1}{x}\cdot \ln{a} - \frac{1}{a}\cdot \ln{x}}{(\ln{a})^2}$$ which is  $$\frac{1}{x\cdot\ln{a}} - \frac{\ln{x}}{a\cdot (\ln{a})^2}$$ which is not equal to $$\frac{1}{x\cdot\ln{a}}$$ What am I doing wrong?,,['derivatives']
27,Why does this optimization problem have a closed form solution that resembles least squares so much?,Why does this optimization problem have a closed form solution that resembles least squares so much?,,"Consider the following optimization problem $$\min_{\mathbf{Q}} \sum\limits_{i=1}^{n}{\|{{\mathbf{b}}_{i}}-{{\mathbf{Q}}^{T}}{{\mathbf{x}}_{i}}\|^2}+\lambda \|\mathbf{Q}\|^{2}$$ where $\mathbf{b_i}  $ is an $r$-dimensional vector, $\mathbf{Q}$ is an $n \times r$ matrix and $\mathbf{x_i} $ is an $n$-dimensional vector. The closed form solution is $$\mathbf{Q}={{(\mathbf{S}{{\mathbf{S}}^{T}}+\lambda \mathbf{I})}^{-1}}\mathbf{S}{{\mathbf{B}}^{T}}$$ Why does it resemble the least squares solution so much? How to conduct that?","Consider the following optimization problem $$\min_{\mathbf{Q}} \sum\limits_{i=1}^{n}{\|{{\mathbf{b}}_{i}}-{{\mathbf{Q}}^{T}}{{\mathbf{x}}_{i}}\|^2}+\lambda \|\mathbf{Q}\|^{2}$$ where $\mathbf{b_i}  $ is an $r$-dimensional vector, $\mathbf{Q}$ is an $n \times r$ matrix and $\mathbf{x_i} $ is an $n$-dimensional vector. The closed form solution is $$\mathbf{Q}={{(\mathbf{S}{{\mathbf{S}}^{T}}+\lambda \mathbf{I})}^{-1}}\mathbf{S}{{\mathbf{B}}^{T}}$$ Why does it resemble the least squares solution so much? How to conduct that?",,"['derivatives', 'optimization', 'matrix-calculus', 'least-squares', 'regularization']"
28,Finding the coefficient of $x^r$ in an expansion.,Finding the coefficient of  in an expansion.,x^r,Suppose that the summation of the infinite series $$1+nx+\frac{n(n-1)}{2} x^2+\cdots+\frac{n(n-1)\cdots(n-r+1)}{r}x^r+\cdots$$ is equal to $(1+x)^n$ for $|x|<1$. Show that the coefficient of $x^r$ in the expansion of $\frac{1+x+x^2}{(1-x)^2}$  is $3r $. Hence show that $(217)^\frac{1}{3} \simeq 6.0092$ My attempt : $$\frac{1+x+x^2}{(1-x)^2}=\frac{(1+x+x^2)(1-x)}{(1-x)^3}$$ $$\frac{1+x+x^2}{(1-x)^2}=\frac{1-x^3}{(1-x)^3}$$ $$=\frac{1}{(1-x)^3}-\frac{x^3}{(1-x)^3}$$ $$=\frac{1}{\left(1+(-x)\right)^3}+\frac{1}{\left(1+\left(-\frac{1}{x}\right)\right)^3}$$ $$=(1+(-x))^{-3}+\left(1+\left(-\frac{1}{x}\right)\right)^{-3}$$ How can I proceed after this ? Is there another method ? Is my method correct ?,Suppose that the summation of the infinite series $$1+nx+\frac{n(n-1)}{2} x^2+\cdots+\frac{n(n-1)\cdots(n-r+1)}{r}x^r+\cdots$$ is equal to $(1+x)^n$ for $|x|<1$. Show that the coefficient of $x^r$ in the expansion of $\frac{1+x+x^2}{(1-x)^2}$  is $3r $. Hence show that $(217)^\frac{1}{3} \simeq 6.0092$ My attempt : $$\frac{1+x+x^2}{(1-x)^2}=\frac{(1+x+x^2)(1-x)}{(1-x)^3}$$ $$\frac{1+x+x^2}{(1-x)^2}=\frac{1-x^3}{(1-x)^3}$$ $$=\frac{1}{(1-x)^3}-\frac{x^3}{(1-x)^3}$$ $$=\frac{1}{\left(1+(-x)\right)^3}+\frac{1}{\left(1+\left(-\frac{1}{x}\right)\right)^3}$$ $$=(1+(-x))^{-3}+\left(1+\left(-\frac{1}{x}\right)\right)^{-3}$$ How can I proceed after this ? Is there another method ? Is my method correct ?,,"['derivatives', 'binomial-coefficients', 'taylor-expansion']"
29,"When given a function of multiple variables, is it possible to differentiate all the variables simultaneously?","When given a function of multiple variables, is it possible to differentiate all the variables simultaneously?",,"I understand that when given a function of two variables, for example $f(x,y)=x^2y+xy^2$, you can perform partial differentiation on it to get $(2xy+y^2,y+2xy)$. However, to my understanding, this is essentially seeing how the function changes when moving either along the $x$-axis or the $y$-axis. One or the other, not both simultaneously. Just as when differentiating a function of one variable we can get a tangential line, is it possible to simultaneously differentiate both variables (instead of differentiating one and then the other) of a two-variable function to get a tangential surface? I apologize if my understanding of this concept is wrong, any help and/or corrections would be greatly appreciated. If my question seems confusing, please let me know. Thanks.","I understand that when given a function of two variables, for example $f(x,y)=x^2y+xy^2$, you can perform partial differentiation on it to get $(2xy+y^2,y+2xy)$. However, to my understanding, this is essentially seeing how the function changes when moving either along the $x$-axis or the $y$-axis. One or the other, not both simultaneously. Just as when differentiating a function of one variable we can get a tangential line, is it possible to simultaneously differentiate both variables (instead of differentiating one and then the other) of a two-variable function to get a tangential surface? I apologize if my understanding of this concept is wrong, any help and/or corrections would be greatly appreciated. If my question seems confusing, please let me know. Thanks.",,"['calculus', 'derivatives']"
30,Show that $\text{rank}(Df)(A) = \frac{n(n+1)}{2}$ for all $A$ such that $A^TA = I_n$,Show that  for all  such that,\text{rank}(Df)(A) = \frac{n(n+1)}{2} A A^TA = I_n,"We identify $\mathbb R^{n \times n}$ with $\mathbb R^{n^2}$ and define $f:\mathbb R^{n^2} \to \mathbb R^{n^2}, A \mapsto A^TA$. Show that $\text{rank}(Df)(A) = \frac{n(n+1)}{2}$ for all $A$ such that $A^TA = I_n$. The solution by Omnomnomnom written in a more accessible (for me) way: We firstly note that $$f(A+H)=(A + H)^T(A + H) = A^TA  + H^TA + A^TH +H^TH$$ Consider the following homomorphismus $\Phi:\mathbb R^{n^2} \to \mathbb R^{n^2}, H \mapsto H^TA + A^TH$ Thus the equation above can be written as: $$f(A+H)= f(A)  + \Phi(H) +H^TH$$ Remember that according to the definition $(Df)(A)$ is a homomorphismus from $\mathbb R^{n^2}$ to $\mathbb R^{n^2}$ such that $$\lim_{H\to 0, H \ne 0} \frac{f(A+H)-f(A)-(Df)(A)H}{\|H\|}=0$$ Because $\lim_{H\to 0, H \ne 0}\|\frac{H^TH}{\|H\|}\| \le \lim_{H\to 0, H \ne 0}\frac{\|H^T\|\|H\|}{\|H\|}=\lim_{H\to 0, H \ne 0}\|H^T\|=0$, it follows that: $$\lim_{H\to 0, H \ne 0} \frac{f(A+H)-f(A)-\Phi (H)}{\|H\|}=\lim_{H\to 0, H \ne 0} \frac{H^TH}{\|H\|}=0$$ and consequently  $Df(A)=\Phi$. Now we note that $\{\Phi(H):H \in \mathbb R^{n^2}\}=\{X\in \mathbb R^{n^2} : X^T = X\}$, because: 1) $(H^TA + A^TH)^T = A^TH^{TT} + H^TA^{TT} = H^TA + A^TH$ 2) $S$ is symmetric, then $\Phi(\frac{1}{2}AS)=\frac{1}{2}(SA^TA+A^TAS)=S$ Now it follows: $$\frac{n(n+1)}{2}=\dim \{X\in \mathbb R^{n^2} : X^T = X\}=\dim\{\Phi(H):H \in \mathbb R^{n^2}\}=\text{rank}\Phi=\text{rank}(Df)(A)$$","We identify $\mathbb R^{n \times n}$ with $\mathbb R^{n^2}$ and define $f:\mathbb R^{n^2} \to \mathbb R^{n^2}, A \mapsto A^TA$. Show that $\text{rank}(Df)(A) = \frac{n(n+1)}{2}$ for all $A$ such that $A^TA = I_n$. The solution by Omnomnomnom written in a more accessible (for me) way: We firstly note that $$f(A+H)=(A + H)^T(A + H) = A^TA  + H^TA + A^TH +H^TH$$ Consider the following homomorphismus $\Phi:\mathbb R^{n^2} \to \mathbb R^{n^2}, H \mapsto H^TA + A^TH$ Thus the equation above can be written as: $$f(A+H)= f(A)  + \Phi(H) +H^TH$$ Remember that according to the definition $(Df)(A)$ is a homomorphismus from $\mathbb R^{n^2}$ to $\mathbb R^{n^2}$ such that $$\lim_{H\to 0, H \ne 0} \frac{f(A+H)-f(A)-(Df)(A)H}{\|H\|}=0$$ Because $\lim_{H\to 0, H \ne 0}\|\frac{H^TH}{\|H\|}\| \le \lim_{H\to 0, H \ne 0}\frac{\|H^T\|\|H\|}{\|H\|}=\lim_{H\to 0, H \ne 0}\|H^T\|=0$, it follows that: $$\lim_{H\to 0, H \ne 0} \frac{f(A+H)-f(A)-\Phi (H)}{\|H\|}=\lim_{H\to 0, H \ne 0} \frac{H^TH}{\|H\|}=0$$ and consequently  $Df(A)=\Phi$. Now we note that $\{\Phi(H):H \in \mathbb R^{n^2}\}=\{X\in \mathbb R^{n^2} : X^T = X\}$, because: 1) $(H^TA + A^TH)^T = A^TH^{TT} + H^TA^{TT} = H^TA + A^TH$ 2) $S$ is symmetric, then $\Phi(\frac{1}{2}AS)=\frac{1}{2}(SA^TA+A^TAS)=S$ Now it follows: $$\frac{n(n+1)}{2}=\dim \{X\in \mathbb R^{n^2} : X^T = X\}=\dim\{\Phi(H):H \in \mathbb R^{n^2}\}=\text{rank}\Phi=\text{rank}(Df)(A)$$",,"['linear-algebra', 'derivatives', 'matrix-calculus', 'matrix-rank']"
31,"$f:\mathbb R \to \mathbb R$ be continuously differentiable function such that $f(x),f'(x)>0$ for all real $x$ , then $\lim _{x \to -\infty}f'(x)=0$?","be continuously differentiable function such that  for all real  , then ?","f:\mathbb R \to \mathbb R f(x),f'(x)>0 x \lim _{x \to -\infty}f'(x)=0","Let $f:\mathbb R \to \mathbb R$ be a continuously differentiable function such  that $f(x)>0 , f'(x)>0 , \forall x \in \mathbb R$ , then is it true that $\lim _{x \to -\infty}f'(x)=0$ ? I can only figure out that $\lim _{x \to -\infty} f(x)$ exists finitely as $f$ is increasing and bounded below . Please help . Thanks in advance","Let $f:\mathbb R \to \mathbb R$ be a continuously differentiable function such  that $f(x)>0 , f'(x)>0 , \forall x \in \mathbb R$ , then is it true that $\lim _{x \to -\infty}f'(x)=0$ ? I can only figure out that $\lim _{x \to -\infty} f(x)$ exists finitely as $f$ is increasing and bounded below . Please help . Thanks in advance",,"['real-analysis', 'limits']"
32,Sinc function derivative formula,Sinc function derivative formula,,"I was trying to find a formula for the derivative of the following function $$ f_{\alpha}(x) = \frac{\sin(\alpha x)}{x} $$ Since $$ \sin^{(k)}(\alpha x) = \alpha^k g_k(\alpha x), $$ where $$ g_k(\alpha x) = \left\{ \begin{array}{l} sin(\alpha x) & k \; mod \; 4 = 0 \\ cos(\alpha x) & k \; mod \; 4 = 1 \\ -sin(\alpha x) & k \; mod \; 4 = 2 \\ -cos(\alpha x) & k \; mod \; 4 = 3  \end{array} , \right. $$ and $$ \left( \frac{1}{x} \right) ^{(k)} = (-1)^k \frac{k!}{x^{k+1}} $$ by the Leibniz rule we have $$ f_{\alpha}(x)^{(k)} = \sum_{j=0}^k \binom{k}{j} \sin^{(j)}(\alpha x) \left(\frac{1}{x} \right)^{(k-j)} = \sum_{j=0}^k \binom{k}{j} \alpha^j g_j(\alpha x) (-1)^{k-j} \frac{(k-j)!}{x^{k-j+1}} $$ and assuming also I haven't done any mistake so far i have $$ \sum_{j=0}^k \binom{k}{j} \alpha^j g_j(\alpha x) (-1)^{k-j} \frac{(k-j)!}{x^{k-j+1}} = (-1)^k \frac{k!}{x^{k+1}}\sum_{j=0}^k \frac{1}{j!} \alpha^j g_j(\alpha x) (-1)^{j} x^j $$ which leads me at $$ f^{(k)}_{\alpha}(x) = \left( \frac{1}{x} \right)^{(k)} \sum_{j=0}^k \frac{(-1)^{j}}{j!} (\alpha x)^j g_j(\alpha x) $$ My question is, is there any mistake so far? If there's no mistake, is there a ""simpler expression"" than the one I'm proposing?","I was trying to find a formula for the derivative of the following function $$ f_{\alpha}(x) = \frac{\sin(\alpha x)}{x} $$ Since $$ \sin^{(k)}(\alpha x) = \alpha^k g_k(\alpha x), $$ where $$ g_k(\alpha x) = \left\{ \begin{array}{l} sin(\alpha x) & k \; mod \; 4 = 0 \\ cos(\alpha x) & k \; mod \; 4 = 1 \\ -sin(\alpha x) & k \; mod \; 4 = 2 \\ -cos(\alpha x) & k \; mod \; 4 = 3  \end{array} , \right. $$ and $$ \left( \frac{1}{x} \right) ^{(k)} = (-1)^k \frac{k!}{x^{k+1}} $$ by the Leibniz rule we have $$ f_{\alpha}(x)^{(k)} = \sum_{j=0}^k \binom{k}{j} \sin^{(j)}(\alpha x) \left(\frac{1}{x} \right)^{(k-j)} = \sum_{j=0}^k \binom{k}{j} \alpha^j g_j(\alpha x) (-1)^{k-j} \frac{(k-j)!}{x^{k-j+1}} $$ and assuming also I haven't done any mistake so far i have $$ \sum_{j=0}^k \binom{k}{j} \alpha^j g_j(\alpha x) (-1)^{k-j} \frac{(k-j)!}{x^{k-j+1}} = (-1)^k \frac{k!}{x^{k+1}}\sum_{j=0}^k \frac{1}{j!} \alpha^j g_j(\alpha x) (-1)^{j} x^j $$ which leads me at $$ f^{(k)}_{\alpha}(x) = \left( \frac{1}{x} \right)^{(k)} \sum_{j=0}^k \frac{(-1)^{j}}{j!} (\alpha x)^j g_j(\alpha x) $$ My question is, is there any mistake so far? If there's no mistake, is there a ""simpler expression"" than the one I'm proposing?",,"['calculus', 'derivatives']"
33,General guidelines to solve Mean Value Theorem problems,General guidelines to solve Mean Value Theorem problems,,"I am wondering if there is a general guideline to solve this specific type of MVT problem. For the teachers: how do you explain to the students how to apply MVT for these two questions below? Question #1 Using $MVT$ prove that $$ e^{x} > 1+x $$ for all $x > 0$ Question #2 Using $MVT$ prove that $$\ln (1+x) < x$$ for all $x > 0$ For example, when dealing with Show that $$  x^3+e^x=0 $$ cannot have two zeros I find helpful to Find values for the function where $f_{x_1} < 0$ and $f_{x_2} > 0$, in this case for example $x_1 = -2$ and $x_2 = 1$ Show using the derivative that f'(x) is always positive (or negative, in another case) Do you have guidelines for the first two questions introduced?","I am wondering if there is a general guideline to solve this specific type of MVT problem. For the teachers: how do you explain to the students how to apply MVT for these two questions below? Question #1 Using $MVT$ prove that $$ e^{x} > 1+x $$ for all $x > 0$ Question #2 Using $MVT$ prove that $$\ln (1+x) < x$$ for all $x > 0$ For example, when dealing with Show that $$  x^3+e^x=0 $$ cannot have two zeros I find helpful to Find values for the function where $f_{x_1} < 0$ and $f_{x_2} > 0$, in this case for example $x_1 = -2$ and $x_2 = 1$ Show using the derivative that f'(x) is always positive (or negative, in another case) Do you have guidelines for the first two questions introduced?",,"['calculus', 'derivatives']"
34,"Differentiation under the integral sign, where the partial derivative of the integrand is not bounded by a Lebesgue integrable function.","Differentiation under the integral sign, where the partial derivative of the integrand is not bounded by a Lebesgue integrable function.",,"Let $K(t)=\int_1^\infty u(t,x)\ \mathrm{d}x$, where $$u(t,x)=\frac{\cos{tx}}{x^2}\mathbb{1}_{[1,\infty)}(x).$$ I need to show that, for $t>0$, $$\frac{dK}{dt}(t)=\frac{1}{t}\left(K(t)-\cos{t}\right).$$ I have shown that $\int_1^\infty \frac{\partial}{\partial t}u(t,x)\ \mathrm{d}x$ is equal to the right-hand side of the above, but I cannot use the standard theorem for differentiation under the integral sign to establish that $$\int_1^\infty \frac{\partial}{\partial t}u(t,x)\ \mathrm{d}x=\frac{dK}{dt}(t),$$ since $$\frac{\partial}{\partial t}u(t,x)=\frac{-\sin{tx}}{x}$$ is not bounded above by a Lebesgue integral function. How do I therefore show that the equality still works?","Let $K(t)=\int_1^\infty u(t,x)\ \mathrm{d}x$, where $$u(t,x)=\frac{\cos{tx}}{x^2}\mathbb{1}_{[1,\infty)}(x).$$ I need to show that, for $t>0$, $$\frac{dK}{dt}(t)=\frac{1}{t}\left(K(t)-\cos{t}\right).$$ I have shown that $\int_1^\infty \frac{\partial}{\partial t}u(t,x)\ \mathrm{d}x$ is equal to the right-hand side of the above, but I cannot use the standard theorem for differentiation under the integral sign to establish that $$\int_1^\infty \frac{\partial}{\partial t}u(t,x)\ \mathrm{d}x=\frac{dK}{dt}(t),$$ since $$\frac{\partial}{\partial t}u(t,x)=\frac{-\sin{tx}}{x}$$ is not bounded above by a Lebesgue integral function. How do I therefore show that the equality still works?",,"['integration', 'derivatives', 'lebesgue-integral']"
35,What can we say about $\alpha$ if $\lim_{x\to \infty}f(x)=1$ and $\lim_{x\to \infty}f'(x)=\alpha$ for a differentiable function $f$ on $\mathbb{R}$? [duplicate],What can we say about  if  and  for a differentiable function  on ? [duplicate],\alpha \lim_{x\to \infty}f(x)=1 \lim_{x\to \infty}f'(x)=\alpha f \mathbb{R},This question already has answers here : Proving that $\lim\limits_{x\to\infty}f'(x) = 0$ when $\lim\limits_{x\to\infty}f(x)$ and $\lim\limits_{x\to\infty}f'(x)$ exist (6 answers) Closed 8 years ago . For what values of $\alpha$ would the given conditions hold? I don't know how to proceed.,This question already has answers here : Proving that $\lim\limits_{x\to\infty}f'(x) = 0$ when $\lim\limits_{x\to\infty}f(x)$ and $\lim\limits_{x\to\infty}f'(x)$ exist (6 answers) Closed 8 years ago . For what values of $\alpha$ would the given conditions hold? I don't know how to proceed.,,"['calculus', 'real-analysis', 'derivatives', 'continuity']"
36,The way of calculate $\frac{\partial}{\partial x} \ A^x $,The way of calculate,\frac{\partial}{\partial x} \ A^x ,"Problem: The square matrix $A\in\mathbf{R}^{n\times n}$ is not function of $x\in \mathbf{N}$. Then, how do to calculate the following matrix derivative?   $$\frac{\partial}{\partial x} \ A^x $$ I could not find such calculus on any website and materials as far as I know. Do you know any documents, papers or theorems which are related with this? Or how is derivation shown? My main interest: Furthermore, I have already shown a proof when the matrix $A$ is able to diagonalize. But, I cannot find how to approach in other cases or the general case.","Problem: The square matrix $A\in\mathbf{R}^{n\times n}$ is not function of $x\in \mathbf{N}$. Then, how do to calculate the following matrix derivative?   $$\frac{\partial}{\partial x} \ A^x $$ I could not find such calculus on any website and materials as far as I know. Do you know any documents, papers or theorems which are related with this? Or how is derivation shown? My main interest: Furthermore, I have already shown a proof when the matrix $A$ is able to diagonalize. But, I cannot find how to approach in other cases or the general case.",,"['linear-algebra', 'matrices', 'derivatives', 'matrix-calculus']"
37,Partial Derivative of Gaussian function: Matrix differentiation,Partial Derivative of Gaussian function: Matrix differentiation,,"I am interested in partial derivative of the following term w.r.t $x_1$ $$\mathbf g = \begin{bmatrix}x_1-k_1 ,& x_2-k_2, & x_3-k_3  \end{bmatrix} \begin{bmatrix}s_{11}& s_{12} & s_{13} \\ s_{21}& s_{22} & s_{23} \\s_{31}& s_{32} & s_{33}  \end{bmatrix}^{-1} \begin{bmatrix}x_1-k_1 \\ x_2-k_2 \\ x_3-k_3  \end{bmatrix}$$ My real problem is to partially differentiate Gaussian function w.r.t $\mathbf x$ which is defined as $$ f = \exp\left(-\frac{1}{2}({\mathbf x}-{\boldsymbol\mu})^\mathrm{T}{\boldsymbol\Sigma}^{-1}({\mathbf x}-{\boldsymbol\mu})\right)$$ $\Sigma$ is positive semidefinite symmetric matrix Here I am stuck with the derivative inside $\exp(.)$ term. For $\mathbf{x}\in \mathbb{R}^2$, I could solve it as follows $$\begin{align} \mathbf g &= \begin{bmatrix}x_1-k_1 ,& x_2-k_2 \end{bmatrix}\begin{bmatrix}\lambda_{11}& \lambda_{12} \\ \lambda_{21}& \lambda_{22}\end{bmatrix}\begin{bmatrix}x_1-k_1 \\ x_2-k_2\end{bmatrix} \\ & = \lambda_{11}(x_1-k_1)^2+(\lambda_{12}+\lambda_{21})(x_1-k_1)( x_2-k_2)+\lambda_{22}(x_2-k_2)^2 \\ \frac{\partial \mathbf g }{\partial x_1}  & = 2\lambda_{11}(x_1-k_1)+(\lambda_{12}+\lambda_{21})(x_2-k_2) \end{align} $$ where, $\begin{bmatrix}\lambda_{11}& \lambda_{12} \\ \lambda_{21}& \lambda_{22}\end{bmatrix} = \begin{bmatrix}s_{11}& s_{12}\\ s_{21}& s_{22} \end{bmatrix}^{-1} $ But as the dimension increases it becomes complicated. Can someone guide me how differentiation of matrices can be carried out . I am looking something of this sort and even before that I would like to know, is it possible?. $$\frac{\partial \mathbf g}{\partial x_1} = \frac{\partial}{\partial x_1} (\mathbf x - \mathbf k)^{\rm T}\Sigma^{-1}\mathbf x +  \mathbf x ^{\rm T}\Sigma^{-1}\frac{\partial}{\partial x_1}(\mathbf x - \mathbf k)$$","I am interested in partial derivative of the following term w.r.t $x_1$ $$\mathbf g = \begin{bmatrix}x_1-k_1 ,& x_2-k_2, & x_3-k_3  \end{bmatrix} \begin{bmatrix}s_{11}& s_{12} & s_{13} \\ s_{21}& s_{22} & s_{23} \\s_{31}& s_{32} & s_{33}  \end{bmatrix}^{-1} \begin{bmatrix}x_1-k_1 \\ x_2-k_2 \\ x_3-k_3  \end{bmatrix}$$ My real problem is to partially differentiate Gaussian function w.r.t $\mathbf x$ which is defined as $$ f = \exp\left(-\frac{1}{2}({\mathbf x}-{\boldsymbol\mu})^\mathrm{T}{\boldsymbol\Sigma}^{-1}({\mathbf x}-{\boldsymbol\mu})\right)$$ $\Sigma$ is positive semidefinite symmetric matrix Here I am stuck with the derivative inside $\exp(.)$ term. For $\mathbf{x}\in \mathbb{R}^2$, I could solve it as follows $$\begin{align} \mathbf g &= \begin{bmatrix}x_1-k_1 ,& x_2-k_2 \end{bmatrix}\begin{bmatrix}\lambda_{11}& \lambda_{12} \\ \lambda_{21}& \lambda_{22}\end{bmatrix}\begin{bmatrix}x_1-k_1 \\ x_2-k_2\end{bmatrix} \\ & = \lambda_{11}(x_1-k_1)^2+(\lambda_{12}+\lambda_{21})(x_1-k_1)( x_2-k_2)+\lambda_{22}(x_2-k_2)^2 \\ \frac{\partial \mathbf g }{\partial x_1}  & = 2\lambda_{11}(x_1-k_1)+(\lambda_{12}+\lambda_{21})(x_2-k_2) \end{align} $$ where, $\begin{bmatrix}\lambda_{11}& \lambda_{12} \\ \lambda_{21}& \lambda_{22}\end{bmatrix} = \begin{bmatrix}s_{11}& s_{12}\\ s_{21}& s_{22} \end{bmatrix}^{-1} $ But as the dimension increases it becomes complicated. Can someone guide me how differentiation of matrices can be carried out . I am looking something of this sort and even before that I would like to know, is it possible?. $$\frac{\partial \mathbf g}{\partial x_1} = \frac{\partial}{\partial x_1} (\mathbf x - \mathbf k)^{\rm T}\Sigma^{-1}\mathbf x +  \mathbf x ^{\rm T}\Sigma^{-1}\frac{\partial}{\partial x_1}(\mathbf x - \mathbf k)$$",,"['derivatives', 'partial-derivative', 'matrix-calculus']"
38,Sum of differentiable functions.,Sum of differentiable functions.,,"True/False Question :  suppose that $f+g$ is differentiable at point $x_0$ therefore $f$ and $g$ are differentiable at $x_0$ I think this statement is false and I got a counter example :  $f(x)=\begin{cases} 1 & \,\,x>0\\ x & \,\,x<0 \end{cases};   g(x)=\begin{cases} x\,\, & x-1>0\\ 0 & \leq0 \end{cases}$ $(f+g)(x)=\begin{cases} x\,\, & x>0\\ x\,\, & x<0\\ 0 & x=0 \end{cases}\rightarrow\forall x\in\mathbb{R}\,\,\left(f+g\right)(x)=x,  \left(f+g\right)'(0)=0$ Nor $f$ or $g$ are differentiable at $x_0=0$ but the sum is differentiable. However second True/false question got me very confused, it says : suppose that $f+g$ and $f$ is differentiable at point $x_0$ therefore $g$ are differentiable at $x_0$ and here I got confused, I can not find acounter example however I can not also find a proof","True/False Question :  suppose that $f+g$ is differentiable at point $x_0$ therefore $f$ and $g$ are differentiable at $x_0$ I think this statement is false and I got a counter example :  $f(x)=\begin{cases} 1 & \,\,x>0\\ x & \,\,x<0 \end{cases};   g(x)=\begin{cases} x\,\, & x-1>0\\ 0 & \leq0 \end{cases}$ $(f+g)(x)=\begin{cases} x\,\, & x>0\\ x\,\, & x<0\\ 0 & x=0 \end{cases}\rightarrow\forall x\in\mathbb{R}\,\,\left(f+g\right)(x)=x,  \left(f+g\right)'(0)=0$ Nor $f$ or $g$ are differentiable at $x_0=0$ but the sum is differentiable. However second True/false question got me very confused, it says : suppose that $f+g$ and $f$ is differentiable at point $x_0$ therefore $g$ are differentiable at $x_0$ and here I got confused, I can not find acounter example however I can not also find a proof",,"['calculus', 'limits', 'derivatives']"
39,"$f:[0,1] \to \mathbb{R}$ is differentiable and $|f'(x)|\le|f(x)|$ $\forall$ $x \in [0,1]$,$f(0)=0$.Show that $f(x)=0$ $\forall$ $x \in [0,1]$","is differentiable and   ,.Show that","f:[0,1] \to \mathbb{R} |f'(x)|\le|f(x)| \forall x \in [0,1] f(0)=0 f(x)=0 \forall x \in [0,1]","$f:[0,1] \to \mathbb{R}$ is differentiable and $|f'(x)|\le|f(x)|$ $\forall$ $x \in [0,1]$ , $f(0)=0$ .Show that $f(x)=0$ $\forall$ $x \in [0,1]$ I used the definition of derivative: $f'(x)=\left|\lim_{h \rightarrow 0} \frac{f(x+h)-f(x)}{h}\right| \le |f(x)|$ Now, checking differentiability at $x=0$ , $\left|\lim_{h \rightarrow 0} \frac{f(h)}{h}\right| \le 0$ which should give a contradiction as modulus of something is negative So, $|f(h)| \le 0 \implies f(x)=0$ But I am not confident and believe that something is wrong..please clarify","is differentiable and , .Show that I used the definition of derivative: Now, checking differentiability at , which should give a contradiction as modulus of something is negative So, But I am not confident and believe that something is wrong..please clarify","f:[0,1] \to \mathbb{R} |f'(x)|\le|f(x)| \forall x \in [0,1] f(0)=0 f(x)=0 \forall x \in [0,1] f'(x)=\left|\lim_{h \rightarrow 0} \frac{f(x+h)-f(x)}{h}\right| \le |f(x)| x=0 \left|\lim_{h \rightarrow 0} \frac{f(h)}{h}\right| \le 0 |f(h)| \le 0 \implies f(x)=0",['calculus']
40,Minor flaw in understanding of the proof of the derivative of exponential functions,Minor flaw in understanding of the proof of the derivative of exponential functions,,"I understand the majority of the proof of the derivative formula for exponential functions of the form: (full proof at bottom of post) $\frac{d}{dx}a^x$ but I have a little trouble with the last step which implies that the rate of change of any exponential function if proportional to both the function itself and the derivative of the function at zero. I fail to see how $\lim_{h\to 0}{\frac{a^h-1}{h}}=f'(0)$ *the limit is supposedly the value of the derivative of $a^x$ at $0$, but to me the limit seems only to be a simplified part of the whole definition of the derivative of the function! Where is the flaw in this line of reasoning? (to clarify my question: It seems like the $lim_{h\to 0}$ defines the derivative of $f$ with respect to $x$ anywhere, not just $0$.) Proof: $f(x)=a^x$ $f'(x)=\lim_{h\to 0}{\frac{f(x+h)-f(x)}{h}}$ $f'(x)=\lim_{h\to 0}{\frac{a^{x+h} -a^x}{h}}$ $=\lim_{h\to 0}{\frac{a^x(a^h-1)}{h}}$ $=a^x \cdot \lim_{h\to 0}{\frac{a^h-1}{h}}$ , and supposedly $f'(0)=\lim_{h\to 0}{\frac{a^h-1}{h}}$, so $f'(x)=f'(0)\cdot a^x$ $\square$ I also apologize to anyone who finds this question too basic; I just can't seem to break this mental block. Any help from a deeper understanding is greatly appreciated!","I understand the majority of the proof of the derivative formula for exponential functions of the form: (full proof at bottom of post) $\frac{d}{dx}a^x$ but I have a little trouble with the last step which implies that the rate of change of any exponential function if proportional to both the function itself and the derivative of the function at zero. I fail to see how $\lim_{h\to 0}{\frac{a^h-1}{h}}=f'(0)$ *the limit is supposedly the value of the derivative of $a^x$ at $0$, but to me the limit seems only to be a simplified part of the whole definition of the derivative of the function! Where is the flaw in this line of reasoning? (to clarify my question: It seems like the $lim_{h\to 0}$ defines the derivative of $f$ with respect to $x$ anywhere, not just $0$.) Proof: $f(x)=a^x$ $f'(x)=\lim_{h\to 0}{\frac{f(x+h)-f(x)}{h}}$ $f'(x)=\lim_{h\to 0}{\frac{a^{x+h} -a^x}{h}}$ $=\lim_{h\to 0}{\frac{a^x(a^h-1)}{h}}$ $=a^x \cdot \lim_{h\to 0}{\frac{a^h-1}{h}}$ , and supposedly $f'(0)=\lim_{h\to 0}{\frac{a^h-1}{h}}$, so $f'(x)=f'(0)\cdot a^x$ $\square$ I also apologize to anyone who finds this question too basic; I just can't seem to break this mental block. Any help from a deeper understanding is greatly appreciated!",,"['calculus', 'derivatives', 'exponential-function', 'proof-explanation']"
41,Suppose $f$ is differentiable at $a$. Evaluate $\lim\limits_{h\to0} \frac{f(a+16h) - f(a+15h)}h$,Suppose  is differentiable at . Evaluate,f a \lim\limits_{h\to0} \frac{f(a+16h) - f(a+15h)}h,Suppose $f$ is differentiable at $a$. Evaluate if possible $$\lim\limits_{h\to0} \frac{f(a+16h) - f(a+15h)}h$$ $$\lim\limits_{h\to0} \frac{f(a+15h)}h - \lim\limits_{h\to0} \frac{f(a+15h)}h$$ which to me is basically just $f'(a)- f'(a) = 0$ or I found $$\lim\limits_{h\to0} \frac{f(a) + f'(a)16h + r(16h) - f(a) - f'(a)15h - r(15h)}h$$ which equals to $\lim\limits_{h\to0} \frac{16hf'(a) - 15hf'(a)}h$ since $\lim\limits_{h\to0} r(16h)/h = 0$ which gives me $16f'(a) - 15f'(a) = f'(a)$ I end up with either $f'(a)$ or zero but I don't know which one is correct.,Suppose $f$ is differentiable at $a$. Evaluate if possible $$\lim\limits_{h\to0} \frac{f(a+16h) - f(a+15h)}h$$ $$\lim\limits_{h\to0} \frac{f(a+15h)}h - \lim\limits_{h\to0} \frac{f(a+15h)}h$$ which to me is basically just $f'(a)- f'(a) = 0$ or I found $$\lim\limits_{h\to0} \frac{f(a) + f'(a)16h + r(16h) - f(a) - f'(a)15h - r(15h)}h$$ which equals to $\lim\limits_{h\to0} \frac{16hf'(a) - 15hf'(a)}h$ since $\lim\limits_{h\to0} r(16h)/h = 0$ which gives me $16f'(a) - 15f'(a) = f'(a)$ I end up with either $f'(a)$ or zero but I don't know which one is correct.,,"['real-analysis', 'limits', 'derivatives']"
42,Function that is second differential continuous,Function that is second differential continuous,,"Let $f:[0,1]\rightarrow\mathbb{R}$ be a function whose second derivative $f''(x)$ is continuous on $[0,1]$. Suppose that f(0)=f(1)=0 and that $|f''(x)|<1$ for any $x\in [0,1]$. Then $$|f'(\frac{1}{2})|\leq\frac{1}{4}.$$ I tried to use mean value theorem to prove it, but I found no place to use condition of second derivative and I cannot prove this.","Let $f:[0,1]\rightarrow\mathbb{R}$ be a function whose second derivative $f''(x)$ is continuous on $[0,1]$. Suppose that f(0)=f(1)=0 and that $|f''(x)|<1$ for any $x\in [0,1]$. Then $$|f'(\frac{1}{2})|\leq\frac{1}{4}.$$ I tried to use mean value theorem to prove it, but I found no place to use condition of second derivative and I cannot prove this.",,"['real-analysis', 'analysis', 'derivatives', 'continuity']"
43,$f(x)=e^x -10x^2$ doesn't vanish in more than three points.,doesn't vanish in more than three points.,f(x)=e^x -10x^2,How can I prove that $f(x) = e^x - 10x^2$ doesn't vanish in more than three points. I stuck here I just computed the derivative that is $f'(x) = e^x - 20x$ and then $x= \log(20)+\log(x)$ when $f'(x)=0$. How can I prove this? Thanks for your help and time.,How can I prove that $f(x) = e^x - 10x^2$ doesn't vanish in more than three points. I stuck here I just computed the derivative that is $f'(x) = e^x - 20x$ and then $x= \log(20)+\log(x)$ when $f'(x)=0$. How can I prove this? Thanks for your help and time.,,"['calculus', 'algebra-precalculus', 'derivatives']"
44,Prove $\log u > \frac{u - 1}{u}$ for $u > 1$,Prove  for,\log u > \frac{u - 1}{u} u > 1,"How to prove that for $u > 1$ $$\log u > \frac{u - 1}{u}$$ without using integrals? I think I'm supposed to use derivatives or Taylor's theorem, as the exercise comes from a lecture about these subjects.","How to prove that for $u > 1$ $$\log u > \frac{u - 1}{u}$$ without using integrals? I think I'm supposed to use derivatives or Taylor's theorem, as the exercise comes from a lecture about these subjects.",,"['derivatives', 'logarithms', 'taylor-expansion']"
45,What is the second derivative of $Tr(A^T(\alpha)BA(\alpha))$?,What is the second derivative of ?,Tr(A^T(\alpha)BA(\alpha)),"What is the second derivative $\frac{d^2}{d\alpha}Tr(A^T(\alpha)BA(\alpha))$? Here, $B$ is square matrix and $A(\alpha)$ is a parameter dependent matrix that is rectangular. All entries of $B, A$ are always real.","What is the second derivative $\frac{d^2}{d\alpha}Tr(A^T(\alpha)BA(\alpha))$? Here, $B$ is square matrix and $A(\alpha)$ is a parameter dependent matrix that is rectangular. All entries of $B, A$ are always real.",,"['calculus', 'linear-algebra', 'derivatives', 'matrix-calculus', 'implicit-differentiation']"
46,Find all the parameters and such that the line $y = ax + \frac{1}{2}a - 2$ intersects the hyperbola $xy = 1$ at right angles in at least one point .,Find all the parameters and such that the line  intersects the hyperbola  at right angles in at least one point .,y = ax + \frac{1}{2}a - 2 xy = 1,Problem: Find all the parameters and such that the line $y = ax + \frac{1}{2}a - 2$ intersects the hyperbola $xy = 1$ at right angles in at least one point. My work: We try to find tangent to hyperbola such that tangent line intersects given line at rigth angle. We know that two line $y_1=ax+b$ and $y_2=cx+d$ intersects at right angle iff $a=-\frac{1}{c}$. So we need to find tangent to hyperbola. Let $t...y=kx+l$ be our tangent line. To find that first we will need $y'$ and we will find it by implicit differentiation. $$xy=1$$ $$y+xy'=0 \iff y'=\frac{-y}{x}$$ $$k=-\frac{y}{x}$$ But I haven't idea how to finish my work.,Problem: Find all the parameters and such that the line $y = ax + \frac{1}{2}a - 2$ intersects the hyperbola $xy = 1$ at right angles in at least one point. My work: We try to find tangent to hyperbola such that tangent line intersects given line at rigth angle. We know that two line $y_1=ax+b$ and $y_2=cx+d$ intersects at right angle iff $a=-\frac{1}{c}$. So we need to find tangent to hyperbola. Let $t...y=kx+l$ be our tangent line. To find that first we will need $y'$ and we will find it by implicit differentiation. $$xy=1$$ $$y+xy'=0 \iff y'=\frac{-y}{x}$$ $$k=-\frac{y}{x}$$ But I haven't idea how to finish my work.,,"['calculus', 'real-analysis', 'derivatives', 'implicit-differentiation', 'tangent-line']"
47,"Differentiate $v(x,y)=-\int_0^x u_y(t,0)dt+\int_0^y u_x (x,t) dt$ w.r.t. $x,y$ to prove complex differentiability",Differentiate  w.r.t.  to prove complex differentiability,"v(x,y)=-\int_0^x u_y(t,0)dt+\int_0^y u_x (x,t) dt x,y","The domain is an open unit box (if required) and $u$ is harmonic, $v$ is harmonic conjugate defined below. Prove Complex Differentiabilty Diffirentiate with respect to $x$ and $y$: $$v(x,y)=-\int_0^x u_y(t,0)dt+\int_0^y u_x (x,t) dt$$ I assumed the answer would be: $v_x=-u_y$ and $v_y=u_x$ (which would imply complex differentiability using Cauchy Riemann), but can somebody help me do the differentiation explicitly, with explanations? I tried using $dv/dx=dv/dt \times dt/dx$ If I'm correct $dv/dt=-u_y(x,0)+u_x(x,y)$","The domain is an open unit box (if required) and $u$ is harmonic, $v$ is harmonic conjugate defined below. Prove Complex Differentiabilty Diffirentiate with respect to $x$ and $y$: $$v(x,y)=-\int_0^x u_y(t,0)dt+\int_0^y u_x (x,t) dt$$ I assumed the answer would be: $v_x=-u_y$ and $v_y=u_x$ (which would imply complex differentiability using Cauchy Riemann), but can somebody help me do the differentiation explicitly, with explanations? I tried using $dv/dx=dv/dt \times dt/dx$ If I'm correct $dv/dt=-u_y(x,0)+u_x(x,y)$",,"['derivatives', 'partial-derivative', 'complex-integration']"
48,Show $f'(0)$ exists and is $L$,Show  exists and is,f'(0) L,"Our assumptions for this problem are: $f$ is continuous on an interval containing $0$ and differentiable for all $x$ not $0$. Moreover, $$\lim_{x \to 0} f'(x) = L.$$ We must show that $f'(0)$ exists and is $L$. My thoughts so far: I am able to produce a (somewhat drawn out) argument for the case in which $f'$ is differentiable at $0$ but cannot seem to account for when that is not necessarily the case. Any help in reducing this argument to that end is appreciated.","Our assumptions for this problem are: $f$ is continuous on an interval containing $0$ and differentiable for all $x$ not $0$. Moreover, $$\lim_{x \to 0} f'(x) = L.$$ We must show that $f'(0)$ exists and is $L$. My thoughts so far: I am able to produce a (somewhat drawn out) argument for the case in which $f'$ is differentiable at $0$ but cannot seem to account for when that is not necessarily the case. Any help in reducing this argument to that end is appreciated.",,['limits']
49,Show that the second derivative $\Gamma''(x)$ is positive when $x>0$,Show that the second derivative  is positive when,\Gamma''(x) x>0,"Let $\Gamma(x)=\int_0^{\infty}t^{z-1}e^{-t}dt$. I know that the first derivative is positive, since $\Gamma(x)$ is increasing when $x>0$, but I don't know how to show that the second derivative is positive without calculating it, something which we have not yet learned to do. Plotting out $x!$ shows that $\Gamma$ is concave up, and has a positive second derivative, but I don't know how to formulate a formal proof. Would it suffice to say $\Gamma(x+2)-\Gamma(x+1)>\Gamma(x+1)-\Gamma(x)$, $\forall x>0$, and $\Gamma$ is increasing at an increasing rate?","Let $\Gamma(x)=\int_0^{\infty}t^{z-1}e^{-t}dt$. I know that the first derivative is positive, since $\Gamma(x)$ is increasing when $x>0$, but I don't know how to show that the second derivative is positive without calculating it, something which we have not yet learned to do. Plotting out $x!$ shows that $\Gamma$ is concave up, and has a positive second derivative, but I don't know how to formulate a formal proof. Would it suffice to say $\Gamma(x+2)-\Gamma(x+1)>\Gamma(x+1)-\Gamma(x)$, $\forall x>0$, and $\Gamma$ is increasing at an increasing rate?",,"['derivatives', 'complex-numbers', 'gamma-function']"
50,Is it true that differentiable functions can have essential discontinuity,Is it true that differentiable functions can have essential discontinuity,,"I was reading wiki and found this statement. Quoting it: A function f is said to be continuously differentiable if the   derivative f'(x) exists and is itself a continuous function. Though   the derivative of a differentiable function never has a jump   discontinuity , it is possible for the derivative to have an essential   discontinuity . I am confused with this statement as we know : Function is differentiable in its domain -> continuous in that domain Not continuous -> Not differentiable How does a function still be differentiable even if it is not continuous ? How It can have essential discontinuity ? I did not get it from wiki example. Please clarify :)","I was reading wiki and found this statement. Quoting it: A function f is said to be continuously differentiable if the   derivative f'(x) exists and is itself a continuous function. Though   the derivative of a differentiable function never has a jump   discontinuity , it is possible for the derivative to have an essential   discontinuity . I am confused with this statement as we know : Function is differentiable in its domain -> continuous in that domain Not continuous -> Not differentiable How does a function still be differentiable even if it is not continuous ? How It can have essential discontinuity ? I did not get it from wiki example. Please clarify :)",,"['calculus', 'derivatives']"
51,"Number of values of $x\in [0,\pi]$ where $f(x)=\lfloor 4\sin x-7\rfloor$ is non derivable is?",Number of values of  where  is non derivable is?,"x\in [0,\pi] f(x)=\lfloor 4\sin x-7\rfloor","Number of values of $x\in [0,\pi]$ where $f(x)=\lfloor 4\sin x-7\rfloor$ is non derivable is? $f(x)=\lfloor 4\sin x-7\rfloor=\lfloor 4\sin x\rfloor-7$ I drew the graph of the $f(x)$ and see that there are six points in $x\in [0,\pi]$ where $f(x)$ is non-continuous and hence non derivable,but the answer given is $7$.","Number of values of $x\in [0,\pi]$ where $f(x)=\lfloor 4\sin x-7\rfloor$ is non derivable is? $f(x)=\lfloor 4\sin x-7\rfloor=\lfloor 4\sin x\rfloor-7$ I drew the graph of the $f(x)$ and see that there are six points in $x\in [0,\pi]$ where $f(x)$ is non-continuous and hence non derivable,but the answer given is $7$.",,"['calculus', 'derivatives', 'continuity', 'ceiling-and-floor-functions']"
52,Determining where the function $f(z) = \frac{y+ix}{x^2+y^2}$ is (complex-)differentiable,Determining where the function  is (complex-)differentiable,f(z) = \frac{y+ix}{x^2+y^2},"Determine at what points the function   $$f(z) = \frac{y+ix}{x^2+y^2}$$   is differentiable, and write the formula for $f'(z)$ at those points. Should I let $u = y+ix$ and $v = x^2 + y^2$ and then use the Cauchy-Riemann equation?","Determine at what points the function   $$f(z) = \frac{y+ix}{x^2+y^2}$$   is differentiable, and write the formula for $f'(z)$ at those points. Should I let $u = y+ix$ and $v = x^2 + y^2$ and then use the Cauchy-Riemann equation?",,"['complex-analysis', 'derivatives']"
53,differentiable function proofs,differentiable function proofs,,Im not sure if this appeared somewhere before but $f$ is a differentiable function and if $\lim_\limits{x\to \infty}f'(x)=l$ how to show that $\lim_\limits{x\to \infty} \frac {f(x)}{x} = l$ ?  Basically I used MVT and got stuck.. any clues? I think I need to work on this based on the epsilon definition of limits and combine it with the MVT.,Im not sure if this appeared somewhere before but $f$ is a differentiable function and if $\lim_\limits{x\to \infty}f'(x)=l$ how to show that $\lim_\limits{x\to \infty} \frac {f(x)}{x} = l$ ?  Basically I used MVT and got stuck.. any clues? I think I need to work on this based on the epsilon definition of limits and combine it with the MVT.,,"['calculus', 'limits', 'derivatives']"
54,Help with implicit differentiation problem [duplicate],Help with implicit differentiation problem [duplicate],,"This question already has answers here : The speed of the top of a sliding ladder (3 answers) A 6 meter ladder... (4 answers) Closed 8 years ago . Here is the problem: A ladder 15 metres high is propped up against a high wall. The bottom of the ladder slides away from the wall at a rate of $1\ {m/s}$. How fast is the top of the ladder sliding down the wall when in it is $12\ m$ off the ground? From this I can state the few things: \begin{equation} \text{Let}\ y(t) = \text{Height of wall at time}\: t \\ \text{Let}\ x(t) = \text{Distance between bottom of ladder and bottom of wall} \\ \text{We know}\ x'(t) = 1 \\ \text{We need to find}\ y'(t)\ \text{when}\ y(t) = 12 \end{equation} In order to find this, we need to get $y'(t)$ in terms of $x'(t)$ and $y(t)$. My first thought is that these form a right triangle, so I call upon Pythagoras: $$(y(t))^2 + (x(t))^2 = 15^2$$ Then implicitly differentiate with respect to $t$: \begin{align} & \frac{d}{dt}\bigg[(y(t))^2 + (x(t))^2\bigg] = \frac{d}{dt}\big[15^2\big] \\ \leadsto\quad & 2y'y + 2x'x = 0 \\ \leadsto\quad & y' = -{{x}\over{y}}x' \end{align} But here is where I reach a dead end. We have $y'$ in terms of $y$ and $x'$, but there's also a $x$ in there - the bottom of the triangle - that we don't know. How do I approach this? Thanks in advance!","This question already has answers here : The speed of the top of a sliding ladder (3 answers) A 6 meter ladder... (4 answers) Closed 8 years ago . Here is the problem: A ladder 15 metres high is propped up against a high wall. The bottom of the ladder slides away from the wall at a rate of $1\ {m/s}$. How fast is the top of the ladder sliding down the wall when in it is $12\ m$ off the ground? From this I can state the few things: \begin{equation} \text{Let}\ y(t) = \text{Height of wall at time}\: t \\ \text{Let}\ x(t) = \text{Distance between bottom of ladder and bottom of wall} \\ \text{We know}\ x'(t) = 1 \\ \text{We need to find}\ y'(t)\ \text{when}\ y(t) = 12 \end{equation} In order to find this, we need to get $y'(t)$ in terms of $x'(t)$ and $y(t)$. My first thought is that these form a right triangle, so I call upon Pythagoras: $$(y(t))^2 + (x(t))^2 = 15^2$$ Then implicitly differentiate with respect to $t$: \begin{align} & \frac{d}{dt}\bigg[(y(t))^2 + (x(t))^2\bigg] = \frac{d}{dt}\big[15^2\big] \\ \leadsto\quad & 2y'y + 2x'x = 0 \\ \leadsto\quad & y' = -{{x}\over{y}}x' \end{align} But here is where I reach a dead end. We have $y'$ in terms of $y$ and $x'$, but there's also a $x$ in there - the bottom of the triangle - that we don't know. How do I approach this? Thanks in advance!",,"['calculus', 'derivatives', 'implicit-differentiation']"
55,using L'Hospital solve $\lim_{x \to \infty} x - x^{2}\ln(1 + \frac{1}{x})$,using L'Hospital solve,\lim_{x \to \infty} x - x^{2}\ln(1 + \frac{1}{x}),I can't get this to $ = \frac{0}{0}$ form so I can use l'Hospital rule $$\lim_{x \to \infty} x - x^{2}\ln\left(1 + \frac{1}{x}\right)$$ tips? [EDIT] $$\lim_{x \to 0} \frac{1}{x} - \frac{\ln(1 + x)}{x^{2}}$$ second term $$\lim_{x \to 0} \frac{\ln(1 + x)}{x^{2}} =  \lim_{x \to 0}  \frac{\frac{1}{1 + x}}{2x} = 2\lim_{x \to 0}  \frac{x}{x+1} = 0$$ first term $$ \lim_{x \to 0}  \frac{1}{x} = \infty$$ is this okey?,I can't get this to $ = \frac{0}{0}$ form so I can use l'Hospital rule $$\lim_{x \to \infty} x - x^{2}\ln\left(1 + \frac{1}{x}\right)$$ tips? [EDIT] $$\lim_{x \to 0} \frac{1}{x} - \frac{\ln(1 + x)}{x^{2}}$$ second term $$\lim_{x \to 0} \frac{\ln(1 + x)}{x^{2}} =  \lim_{x \to 0}  \frac{\frac{1}{1 + x}}{2x} = 2\lim_{x \to 0}  \frac{x}{x+1} = 0$$ first term $$ \lim_{x \to 0}  \frac{1}{x} = \infty$$ is this okey?,,['derivatives']
56,Differentiability class of Matern function (based on Modified Bessel Function of second kind),Differentiability class of Matern function (based on Modified Bessel Function of second kind),,"I am working on some techniques using the Matérn covariance function: $h(r) = \frac{2^{1-\nu}}{\Gamma(\nu)}\Bigg(\sqrt{2\nu}\frac{r}{\rho}\Bigg)^\nu K_\nu\Bigg(\sqrt{2\nu}\frac{r}{\rho}\Bigg)$ with $r\in\mathbb{R}^+$ and $\nu\in\mathbb{R}^+$. For some reasons, I am looking at the continuity properties of this function wrt to $\nu$. By studying the first and second derivatives of it wrt $r$. I can show that  these derivatives are continuous on $\mathbb{R}^+$ if $\nu>1$. The idea now is to find the full continuity properties wrt to $\nu$. For doing this I am looking on some recurrence relations on the derivatives of $K_\nu(x)$ or $x^\nu K_\nu(x)$ wrt $r$.","I am working on some techniques using the Matérn covariance function: $h(r) = \frac{2^{1-\nu}}{\Gamma(\nu)}\Bigg(\sqrt{2\nu}\frac{r}{\rho}\Bigg)^\nu K_\nu\Bigg(\sqrt{2\nu}\frac{r}{\rho}\Bigg)$ with $r\in\mathbb{R}^+$ and $\nu\in\mathbb{R}^+$. For some reasons, I am looking at the continuity properties of this function wrt to $\nu$. By studying the first and second derivatives of it wrt $r$. I can show that  these derivatives are continuous on $\mathbb{R}^+$ if $\nu>1$. The idea now is to find the full continuity properties wrt to $\nu$. For doing this I am looking on some recurrence relations on the derivatives of $K_\nu(x)$ or $x^\nu K_\nu(x)$ wrt $r$.",,"['derivatives', 'continuity', 'bessel-functions']"
57,Understanding how this derivative was taken,Understanding how this derivative was taken,,"I am pouring water into a conical cup 8cm tall and 6cm across the top.   If the volume of the cup at time t is $V(t)$, how fast is the water   level ($h$) rising in terms of $V'(t)$? The solution in the book is: Take the water volume, given by $$\frac{1}{3}\pi(\frac{3}{8})^2h^3$$ Then differentiate with respect to $t$: $$V' = h'\pi(\frac{3}{8})^2h^2$$ Which gives $$h' = \frac{64V'}{9{\pi}h^2}$$ I did not understand how this differentiation happened, when there was no $t$ in the formula to differentiate ! If you differentiate with respect to $h$, though, you get something similar: $$\dfrac{9{\pi}h^2}{64}$$ But I'm not sure how $V'$ fits into this. Thanks in advance!","I am pouring water into a conical cup 8cm tall and 6cm across the top.   If the volume of the cup at time t is $V(t)$, how fast is the water   level ($h$) rising in terms of $V'(t)$? The solution in the book is: Take the water volume, given by $$\frac{1}{3}\pi(\frac{3}{8})^2h^3$$ Then differentiate with respect to $t$: $$V' = h'\pi(\frac{3}{8})^2h^2$$ Which gives $$h' = \frac{64V'}{9{\pi}h^2}$$ I did not understand how this differentiation happened, when there was no $t$ in the formula to differentiate ! If you differentiate with respect to $h$, though, you get something similar: $$\dfrac{9{\pi}h^2}{64}$$ But I'm not sure how $V'$ fits into this. Thanks in advance!",,['derivatives']
58,If $a+b+c = 0$ then the quadratic equation $3ax^{2}+2bx +c=0$ has atleast one root in _________?,If  then the quadratic equation  has atleast one root in _________?,a+b+c = 0 3ax^{2}+2bx +c=0,"If $a+b+c = 0$ then the quadratic equation $3ax^{2}+2bx +c=0$ has atleast one root in _________? Rolle's theorem states that if $f(a) = f(b)$ then there exists  a $p \in [a,b]$ such that : $f'(p) = \frac{f(b)-f(a)}{b-a} = 0$ So we have $f'(p) = 6ap + 2b \implies$ $p = \frac{-b}{3a}$ How to proceed next ?","If $a+b+c = 0$ then the quadratic equation $3ax^{2}+2bx +c=0$ has atleast one root in _________? Rolle's theorem states that if $f(a) = f(b)$ then there exists  a $p \in [a,b]$ such that : $f'(p) = \frac{f(b)-f(a)}{b-a} = 0$ So we have $f'(p) = 6ap + 2b \implies$ $p = \frac{-b}{3a}$ How to proceed next ?",,"['algebra-precalculus', 'derivatives', 'polynomials', 'quadratics']"
59,Which is correct to compute derivative of $\frac{d\left(x^{T}a\right)}{dx}$?,Which is correct to compute derivative of ?,\frac{d\left(x^{T}a\right)}{dx},"I have two vector $x$ and $a$ defined as:  $x= \left(\begin{array}{c} x_1\\ x_2\\ \vdots\\ x_n \end{array}\right) $; $a= \left(\begin{array}{c} a_1\\ a_2\\ \vdots\\ a_n \end{array}\right). $ Defined  that $$ x^{T}a=\sum_{i=1}^{n}x_{i}a_{i} $$ Which is correct solution of  $\frac{d\left(x^{T}a\right)}{dx}$? Solution 1: $$ \frac{d\left(x^{T}a\right)}{dx}=\left(\begin{array}{c} a_{1}\\ a_{2}\\ \vdots\\ a_{n} \end{array}\right)=a. $$ or Solution 2: $$ \frac{d\left(x^{T}a\right)}{dx}=a^T. $$ As my understand, I think the first solution is correct.","I have two vector $x$ and $a$ defined as:  $x= \left(\begin{array}{c} x_1\\ x_2\\ \vdots\\ x_n \end{array}\right) $; $a= \left(\begin{array}{c} a_1\\ a_2\\ \vdots\\ a_n \end{array}\right). $ Defined  that $$ x^{T}a=\sum_{i=1}^{n}x_{i}a_{i} $$ Which is correct solution of  $\frac{d\left(x^{T}a\right)}{dx}$? Solution 1: $$ \frac{d\left(x^{T}a\right)}{dx}=\left(\begin{array}{c} a_{1}\\ a_{2}\\ \vdots\\ a_{n} \end{array}\right)=a. $$ or Solution 2: $$ \frac{d\left(x^{T}a\right)}{dx}=a^T. $$ As my understand, I think the first solution is correct.",,"['calculus', 'linear-algebra', 'matrices', 'derivatives', 'partial-derivative']"
60,Evaluate a definite integral of a periodic function,Evaluate a definite integral of a periodic function,,"Suppose $\rho:R\rightarrow R^+$ is a $C^2$ periodic function with period $2\pi$, could you prove $$\int_0^{2\pi}\frac{(\rho'(\theta))^2-\rho(\theta)\rho''(\theta)}{\rho^2(\theta)+(\rho'(\theta))^2}d\theta=0?$$","Suppose $\rho:R\rightarrow R^+$ is a $C^2$ periodic function with period $2\pi$, could you prove $$\int_0^{2\pi}\frac{(\rho'(\theta))^2-\rho(\theta)\rho''(\theta)}{\rho^2(\theta)+(\rho'(\theta))^2}d\theta=0?$$",,"['calculus', 'integration', 'derivatives', 'definite-integrals']"
61,Chain rule for differentiation,Chain rule for differentiation,,I've been given this problem: $y= \sqrt{7+6x^3}$ Using the chain rule am I right in suggesting that $$u = 7+6x^3$$ $$y = \sqrt{u}$$,I've been given this problem: $y= \sqrt{7+6x^3}$ Using the chain rule am I right in suggesting that $$u = 7+6x^3$$ $$y = \sqrt{u}$$,,"['calculus', 'derivatives', 'chain-rule']"
62,N-th derivative of a product in binomial expansion?,N-th derivative of a product in binomial expansion?,,"I believe that the following is true: $$\frac{d^n}{dx^n}f(x)g(x)=\sum_{i=0}^{\infty}\frac{n!}{i!(n-i)!}f^{(n-m)}(x)g^{(m)}(x)$$ The rational part of the summation is binomial expansion constants and $f^{(n)}(x)=\frac{d^n}{dx^n}f(x)$ I have tested it for some values of $n$ where $f$ and $g$ are either polynomials or exponential functions and it appears to hold true. The question is whether or not the above is true with a proof. For those who concern, $n$ may or may not be a positive integer or even an integer at all because I wish to use this in Fractional Calculus allowing $n\in\mathbb{C}$.","I believe that the following is true: $$\frac{d^n}{dx^n}f(x)g(x)=\sum_{i=0}^{\infty}\frac{n!}{i!(n-i)!}f^{(n-m)}(x)g^{(m)}(x)$$ The rational part of the summation is binomial expansion constants and $f^{(n)}(x)=\frac{d^n}{dx^n}f(x)$ I have tested it for some values of $n$ where $f$ and $g$ are either polynomials or exponential functions and it appears to hold true. The question is whether or not the above is true with a proof. For those who concern, $n$ may or may not be a positive integer or even an integer at all because I wish to use this in Fractional Calculus allowing $n\in\mathbb{C}$.",,"['calculus', 'derivatives', 'binomial-theorem']"
63,"If $f\in C(\Bbb{R}^n) \cap C^1(\Bbb{R}^n\setminus\{0\})$ and $\nabla f(x) \to L$ as $x\to 0$, then $f\in C^1(\Bbb{R}^n)$","If  and  as , then",f\in C(\Bbb{R}^n) \cap C^1(\Bbb{R}^n\setminus\{0\}) \nabla f(x) \to L x\to 0 f\in C^1(\Bbb{R}^n),"Let $f:\Bbb{R}^n\to \Bbb{R}$ be continuous on $\Bbb{R}^n$ and continuously differentiable on $\Bbb{R}^n\setminus\{0\}$. Moreover, $\nabla f(x)\to L$ as $x\to 0$. Show $f$ is $C^1$ on $\Bbb{R}^n$ I tried to use the limit definition of derivative which relates to the gradient, but it gets mixed up and confusing, and I sense like I underuse the fact that $f$ is continuously differentiable, and not merely $C^1$. I would appreciate a aiding line.","Let $f:\Bbb{R}^n\to \Bbb{R}$ be continuous on $\Bbb{R}^n$ and continuously differentiable on $\Bbb{R}^n\setminus\{0\}$. Moreover, $\nabla f(x)\to L$ as $x\to 0$. Show $f$ is $C^1$ on $\Bbb{R}^n$ I tried to use the limit definition of derivative which relates to the gradient, but it gets mixed up and confusing, and I sense like I underuse the fact that $f$ is continuously differentiable, and not merely $C^1$. I would appreciate a aiding line.",,"['calculus', 'real-analysis', 'derivatives']"
64,Show that $fg$ is differentiable at $\hat{x}$ and that $(fg)'(\hat{x})= g(\hat{x})f'(\hat{x}) + f(\hat{x})g'(\hat{x})$,Show that  is differentiable at  and that,fg \hat{x} (fg)'(\hat{x})= g(\hat{x})f'(\hat{x}) + f(\hat{x})g'(\hat{x}),"Let $U$ an open set in $\mathbb{R^n}$, $\hat{x} \in U$ and let $f : U  \to \mathbb{R}$ and $g : U \to \mathbb{R}$ two different   differentiable functions at $\hat{x}$. Show that $fg$ is   differentiable at $\hat{x}$ and that $(fg)'(\hat{x})=  g(\hat{x})f'(\hat{x}) + f(\hat{x})g'(\hat{x})$. I know basically the proof for two functions at one variable. However, the problem seems to be different when we have two functions with strictly more than one variable. I don't know why but I tried different things and I don't have the flash to finish this problem. So that's what I've done so far: We have $$\lim_{x \to \hat{x}} \frac{f(x)-f(\hat{x})-f'(\hat{x})(x-\hat{x})}{||x-\hat{x}||}$$ and $$\lim_{x \to \hat{x}} \frac{g(x)-g(\hat{x})-g'(\hat{x})(x-\hat{x})}{||x-\hat{x}||}$$ Let $h(x)=(fg)(x)$ and taken $h'(\hat{x}) = g(\hat{x})f'(\hat{x}) + f(\hat{x})g'(\hat{x})$. Then $$\lim_{x \to \hat{x}} \frac{h(x)-h(\hat{x})-h'(\hat{x})(x-\hat{x})}{||x-\hat{x}||} = \lim_{x \to \hat{x}} \frac{(fg)(x)-(fg)(\hat{x})-(g(\hat{x})f'(\hat{x}) + f(\hat{x})g'(\hat{x}))(x-\hat{x})}{||x-\hat{x}||}$$ From this time, I tried differents factorizations, but it block; here one of them : $$(fg)(x)-(fg)(\hat{x}) = f(x)(g(x) - g(\hat{x})) + g(\hat{x})(f(x)-f(\hat{x}))$$ and $$g(\hat{x})f'(\hat{x}) + f(\hat{x})g'(\hat{x}) = f(\hat{x})(g(\hat{x})- g'(\hat{x})) + g'(\hat{x})(f(\hat{x}) + f'(\hat{x}))$$ Does someone could tell me where I could make a correction? Otherwise, is there an easier way to approach this type of question?","Let $U$ an open set in $\mathbb{R^n}$, $\hat{x} \in U$ and let $f : U  \to \mathbb{R}$ and $g : U \to \mathbb{R}$ two different   differentiable functions at $\hat{x}$. Show that $fg$ is   differentiable at $\hat{x}$ and that $(fg)'(\hat{x})=  g(\hat{x})f'(\hat{x}) + f(\hat{x})g'(\hat{x})$. I know basically the proof for two functions at one variable. However, the problem seems to be different when we have two functions with strictly more than one variable. I don't know why but I tried different things and I don't have the flash to finish this problem. So that's what I've done so far: We have $$\lim_{x \to \hat{x}} \frac{f(x)-f(\hat{x})-f'(\hat{x})(x-\hat{x})}{||x-\hat{x}||}$$ and $$\lim_{x \to \hat{x}} \frac{g(x)-g(\hat{x})-g'(\hat{x})(x-\hat{x})}{||x-\hat{x}||}$$ Let $h(x)=(fg)(x)$ and taken $h'(\hat{x}) = g(\hat{x})f'(\hat{x}) + f(\hat{x})g'(\hat{x})$. Then $$\lim_{x \to \hat{x}} \frac{h(x)-h(\hat{x})-h'(\hat{x})(x-\hat{x})}{||x-\hat{x}||} = \lim_{x \to \hat{x}} \frac{(fg)(x)-(fg)(\hat{x})-(g(\hat{x})f'(\hat{x}) + f(\hat{x})g'(\hat{x}))(x-\hat{x})}{||x-\hat{x}||}$$ From this time, I tried differents factorizations, but it block; here one of them : $$(fg)(x)-(fg)(\hat{x}) = f(x)(g(x) - g(\hat{x})) + g(\hat{x})(f(x)-f(\hat{x}))$$ and $$g(\hat{x})f'(\hat{x}) + f(\hat{x})g'(\hat{x}) = f(\hat{x})(g(\hat{x})- g'(\hat{x})) + g'(\hat{x})(f(\hat{x}) + f'(\hat{x}))$$ Does someone could tell me where I could make a correction? Otherwise, is there an easier way to approach this type of question?",,"['real-analysis', 'derivatives']"
65,"Which values of $p$, $f$ is it differentiable at the point $(0,0)$?","Which values of ,  is it differentiable at the point ?","p f (0,0)","Let $p \geq 1$ and $f: \mathbb{R^2} \to \mathbb{R}$ defined as $$f(x) =   \begin{cases}   (\sin \|x\|)^p \cos \frac{1}{\|x\|},       & \quad \text{if } \|x\| \not= 0  \\ 0,  & \quad \text{if } \|x\| = 0  \\    \end{cases} $$ (a) Show that $f$ is differentiable at point $x \not= (0,0)$ - (Done) (b) Which values of $p$, $f$ is it differentiable at the point $(0,0)$? We have seen in class that $f$ is differentiable at a point $\hat{x}$ is equivalent to find a function $f'(\hat{x}) \in \mathcal{L}(\mathbb{R}^n, \mathbb{R})$ such that $$\lim_{x \to \hat{x}} \frac{|f(x)-f(\hat{x})-f'(\hat{x})(x-\hat{x})|}{h}=0,$$ and we have discovered that $f'(\hat{x})(x-\hat{x}) = \nabla f(\hat{x}) \cdot (x-\hat{x})$. So far I tried to discover the partial derivatives of $f$ at $(0,0)$ : $$\frac{\partial f}{\partial x_1}(0,0) = \lim_{h \to 0} \frac{f(h,0)-f(0,0)}{h} = \lim_{h \to 0} \frac{(sin |h|)^pcos \frac{1}{|h|}}{h}$$ intuitively, I think $p$ has to be greater than $1$. We know that $(sin |h|)^pcos \frac{1}{|h|}$ is bounded between $-1$ and $1$. I am stucked at this point. Is anyone could help me to solve the problem? Is it a better way to find the values of $p$ for which $f$ is differentiable at the point $(0,0)$? A related question is this link . P.S. Please, don't try to use a very specific analysis theory; I am only an undergraduate student (bachelor).","Let $p \geq 1$ and $f: \mathbb{R^2} \to \mathbb{R}$ defined as $$f(x) =   \begin{cases}   (\sin \|x\|)^p \cos \frac{1}{\|x\|},       & \quad \text{if } \|x\| \not= 0  \\ 0,  & \quad \text{if } \|x\| = 0  \\    \end{cases} $$ (a) Show that $f$ is differentiable at point $x \not= (0,0)$ - (Done) (b) Which values of $p$, $f$ is it differentiable at the point $(0,0)$? We have seen in class that $f$ is differentiable at a point $\hat{x}$ is equivalent to find a function $f'(\hat{x}) \in \mathcal{L}(\mathbb{R}^n, \mathbb{R})$ such that $$\lim_{x \to \hat{x}} \frac{|f(x)-f(\hat{x})-f'(\hat{x})(x-\hat{x})|}{h}=0,$$ and we have discovered that $f'(\hat{x})(x-\hat{x}) = \nabla f(\hat{x}) \cdot (x-\hat{x})$. So far I tried to discover the partial derivatives of $f$ at $(0,0)$ : $$\frac{\partial f}{\partial x_1}(0,0) = \lim_{h \to 0} \frac{f(h,0)-f(0,0)}{h} = \lim_{h \to 0} \frac{(sin |h|)^pcos \frac{1}{|h|}}{h}$$ intuitively, I think $p$ has to be greater than $1$. We know that $(sin |h|)^pcos \frac{1}{|h|}$ is bounded between $-1$ and $1$. I am stucked at this point. Is anyone could help me to solve the problem? Is it a better way to find the values of $p$ for which $f$ is differentiable at the point $(0,0)$? A related question is this link . P.S. Please, don't try to use a very specific analysis theory; I am only an undergraduate student (bachelor).",,"['real-analysis', 'derivatives', 'partial-derivative']"
66,For every normed space the norm map is not Fréchet differentiable at $0$.,For every normed space the norm map is not Fréchet differentiable at .,0,Argue that for every normed space $\mathbb{X} \neq \{ 0 \}$ the norm map $\| \ldotp \|_\mathbb{X} : \mathbb{X} \to \mathbb{R}$ is not Fréchet differentiable at $0$. Not really sure where to start on this question. I know the absolute value function is not Fréchet differentiable at $0$.,Argue that for every normed space $\mathbb{X} \neq \{ 0 \}$ the norm map $\| \ldotp \|_\mathbb{X} : \mathbb{X} \to \mathbb{R}$ is not Fréchet differentiable at $0$. Not really sure where to start on this question. I know the absolute value function is not Fréchet differentiable at $0$.,,"['real-analysis', 'derivatives', 'normed-spaces']"
67,Numerical evaluation of first and second derivative,Numerical evaluation of first and second derivative,,"We start with the following function $g: (0,\infty)\rightarrow [0,\infty)$, $$ g(x)=x+2x^{-\frac{1}{2}}-3.$$ From this function we need a 'smooth' square-root. Thus, we check $g(1)=0$,  $$g'(x)=1-x^{-\frac{3}{2}},$$ $g'(1)=0$ and  $$g''(x)=\frac{3}{2}x^{-\frac{5}{2}}\geq 0.$$  Therefore, we can define the function $f: (0,\infty)\rightarrow \mathbb{R}$, $$f(x)=\operatorname{sign}(x-1)\sqrt{g(x)}.$$  We can compute the first derivatives as  $$ f'(x)=\frac{1}{2} \frac{g'(x)}{f(x)}=\frac{1}{2}\frac{1-x^{-\frac{3}{2}}}{\operatorname{sign}(x-1)\sqrt{x+2x^{-\frac{1}{2}}-3}} $$ and second derivatives as  $$ f''(x)=\frac{1}{2} \frac{g''(x)f(x)-g'(x)f'(x)}{\bigl(f(x)\bigr)^2}\\ =\frac{1}{2}\frac{g''(x)-\frac{\bigl(g'(x)\bigr)^2}{2g(x)}}{f(x)}\\ =\frac{1}{2}\frac{\frac{3}{2}x^{-\frac{5}{2}}-\frac{\bigl(1-x^{-\frac{3}{2}}\bigr)^2}{2\bigl(x+2x^{-\frac{1}{2}}-3\bigr)}}{\operatorname{sign}(x-1)\sqrt{x+2x^{-\frac{1}{2}}-3}} $$ where we used $f'(x)$ from above, reduced by $f(x)$ and used $f^2(x)=g(x)$. For $x=1$ the first and the second derivatives of $f$ are of the type $\frac{0}{0}$. I need a numerical stable evaluation of this derivatives.  But we have numerical cancellation especially in the nominators. A linear Taylor-polynomial at $x=1$ is possible for $f'(x)$ but the computation of $f'''(1)$ by hand is time-consuming. Is there a better formulation for $f(x)$? Is there an easy way to compute the coefficients of the Taylor-polynomials at $x=1$? (Edit 2:) How can I evaluate $f'(x)$ and $f''(x)$ numerically stable for $x\in (0,\infty)$? Edit 1: The Taylor-polynomial of degree 1 for $f'(x)$ at $x=1$ is  $$ f'(x)=\frac{\sqrt{3}}{2} - \frac{5}{4\sqrt{3}}(x-1)+\mathcal{O}\bigl(\lvert x-1\rvert^2\bigr) $$","We start with the following function $g: (0,\infty)\rightarrow [0,\infty)$, $$ g(x)=x+2x^{-\frac{1}{2}}-3.$$ From this function we need a 'smooth' square-root. Thus, we check $g(1)=0$,  $$g'(x)=1-x^{-\frac{3}{2}},$$ $g'(1)=0$ and  $$g''(x)=\frac{3}{2}x^{-\frac{5}{2}}\geq 0.$$  Therefore, we can define the function $f: (0,\infty)\rightarrow \mathbb{R}$, $$f(x)=\operatorname{sign}(x-1)\sqrt{g(x)}.$$  We can compute the first derivatives as  $$ f'(x)=\frac{1}{2} \frac{g'(x)}{f(x)}=\frac{1}{2}\frac{1-x^{-\frac{3}{2}}}{\operatorname{sign}(x-1)\sqrt{x+2x^{-\frac{1}{2}}-3}} $$ and second derivatives as  $$ f''(x)=\frac{1}{2} \frac{g''(x)f(x)-g'(x)f'(x)}{\bigl(f(x)\bigr)^2}\\ =\frac{1}{2}\frac{g''(x)-\frac{\bigl(g'(x)\bigr)^2}{2g(x)}}{f(x)}\\ =\frac{1}{2}\frac{\frac{3}{2}x^{-\frac{5}{2}}-\frac{\bigl(1-x^{-\frac{3}{2}}\bigr)^2}{2\bigl(x+2x^{-\frac{1}{2}}-3\bigr)}}{\operatorname{sign}(x-1)\sqrt{x+2x^{-\frac{1}{2}}-3}} $$ where we used $f'(x)$ from above, reduced by $f(x)$ and used $f^2(x)=g(x)$. For $x=1$ the first and the second derivatives of $f$ are of the type $\frac{0}{0}$. I need a numerical stable evaluation of this derivatives.  But we have numerical cancellation especially in the nominators. A linear Taylor-polynomial at $x=1$ is possible for $f'(x)$ but the computation of $f'''(1)$ by hand is time-consuming. Is there a better formulation for $f(x)$? Is there an easy way to compute the coefficients of the Taylor-polynomials at $x=1$? (Edit 2:) How can I evaluate $f'(x)$ and $f''(x)$ numerically stable for $x\in (0,\infty)$? Edit 1: The Taylor-polynomial of degree 1 for $f'(x)$ at $x=1$ is  $$ f'(x)=\frac{\sqrt{3}}{2} - \frac{5}{4\sqrt{3}}(x-1)+\mathcal{O}\bigl(\lvert x-1\rvert^2\bigr) $$",,"['real-analysis', 'derivatives']"
68,derivative of arctan(u),derivative of arctan(u),,Im trying to find the derivative of $\arctan(x-\sqrt{x^2+1})$ here are my steps if someone could point out where I went wrong. $$\begin{align} \frac{\mathrm d~\arctan(u)}{\mathrm d~x} \;& =\; {1\over{1+u^2}}\cdot \frac{\mathrm d~u}{\mathrm d~x} \\[1ex] & =\; {1-{x\over{\sqrt{x^2+1}}}\over{1+(x-\sqrt{x^2+1})^2}} \end{align}$$ Everything after this turns into a huge mess I don't know how to simplify. Is there a trick I missed or something I don't see?,Im trying to find the derivative of $\arctan(x-\sqrt{x^2+1})$ here are my steps if someone could point out where I went wrong. $$\begin{align} \frac{\mathrm d~\arctan(u)}{\mathrm d~x} \;& =\; {1\over{1+u^2}}\cdot \frac{\mathrm d~u}{\mathrm d~x} \\[1ex] & =\; {1-{x\over{\sqrt{x^2+1}}}\over{1+(x-\sqrt{x^2+1})^2}} \end{align}$$ Everything after this turns into a huge mess I don't know how to simplify. Is there a trick I missed or something I don't see?,,"['derivatives', 'inverse-function']"
69,How to find the surface area of a spherical cap by integration?,How to find the surface area of a spherical cap by integration?,,"I don't really understand how they derived the formula in the following picture. The aim is basically to find the formula for the surface area of a spherical cap.  Why do you differentiate the $x=\sqrt{r^2-y^2}$? how does that help to find the surface? What role does $ds$ play in here ?  How do you know that $S_y= 2\pi \int_c^d x\, ds$?","I don't really understand how they derived the formula in the following picture. The aim is basically to find the formula for the surface area of a spherical cap.  Why do you differentiate the $x=\sqrt{r^2-y^2}$? how does that help to find the surface? What role does $ds$ play in here ?  How do you know that $S_y= 2\pi \int_c^d x\, ds$?",,"['calculus', 'integration', 'derivatives', 'surfaces', 'spheres']"
70,Need help with notation for total derivatives,Need help with notation for total derivatives,,"consider the function $$f = f(x(t),y(t))$$ I know that its total derivative wrt t is $$\frac {df}{dt} = \frac {\partial f} {\partial x} \frac {dx}{dt} + \frac {\partial f}{\partial y} \frac {dy}{dt}$$ and that the total derivative wrt x is $$ \frac {df} {dx} = \frac {\partial f} {\partial x} \frac {dx}{dx} + \frac {\partial f} {\partial y} \frac {dy} {dx}$$ However I am not fully familiar with the notation and the forms in which it takes during more extreme conditions, such as the following, could anyone fill the blanks in for me? 1)$$f = f(x(t,w),y(t,w))$$ $$\frac {df}{dt} = ?$$ 2) $$f = f(x(g(t,w)),y(g(t,w)))$$ $$\frac {df}{dt} = ?$$ 3) $$f = f(x(g(t,w),z),y(g(t,w),z))$$ $$\frac {df}{dt} = ?$$ 4) $$f = f(x(g(t)),y(g(t)))$$ $$\frac {df}{dt} = ?$$ how would I go about writing these properly? Any answer will help illustrate the semantics in much greater detail","consider the function $$f = f(x(t),y(t))$$ I know that its total derivative wrt t is $$\frac {df}{dt} = \frac {\partial f} {\partial x} \frac {dx}{dt} + \frac {\partial f}{\partial y} \frac {dy}{dt}$$ and that the total derivative wrt x is $$ \frac {df} {dx} = \frac {\partial f} {\partial x} \frac {dx}{dx} + \frac {\partial f} {\partial y} \frac {dy} {dx}$$ However I am not fully familiar with the notation and the forms in which it takes during more extreme conditions, such as the following, could anyone fill the blanks in for me? 1)$$f = f(x(t,w),y(t,w))$$ $$\frac {df}{dt} = ?$$ 2) $$f = f(x(g(t,w)),y(g(t,w)))$$ $$\frac {df}{dt} = ?$$ 3) $$f = f(x(g(t,w),z),y(g(t,w),z))$$ $$\frac {df}{dt} = ?$$ 4) $$f = f(x(g(t)),y(g(t)))$$ $$\frac {df}{dt} = ?$$ how would I go about writing these properly? Any answer will help illustrate the semantics in much greater detail",,"['calculus', 'derivatives', 'partial-derivative', 'differential']"
71,Calculate the second-order derivative.,Calculate the second-order derivative.,,"Let $x \in \mathbb{R}^m$ be our variable. I would like to know what is: $$ \frac{\partial^2 \text{Tr}\big((A+B^\text{T}\textbf{diag}(x)B)^{-1}\big)}{\partial x_i \partial x_j}. $$ $A \in \mathbb{R}^{n\times n}$, $B \in \mathbb{R}^{m\times n} $ and $(A+B^\text{T}\textbf{diag}(x)B)$ is invertible. The $\textbf{diag}$ operator on a matrix results in a vector of diagonal elements and $\textbf{diag}$ on a vector results in a matrix with diagonal elements on the main diagonal and zero elsewhere. Hint: via matrixcookbook, I figured out that: $$ \frac{\partial \text{Tr}\big((A+B^\text{T}\textbf{diag}(x)B)^{-1}\big)}{\partial x} = \textbf{diag}(B(A+B^\text{T}\textbf{diag}(x)B)^{-2}B^{\text{T}}) $$","Let $x \in \mathbb{R}^m$ be our variable. I would like to know what is: $$ \frac{\partial^2 \text{Tr}\big((A+B^\text{T}\textbf{diag}(x)B)^{-1}\big)}{\partial x_i \partial x_j}. $$ $A \in \mathbb{R}^{n\times n}$, $B \in \mathbb{R}^{m\times n} $ and $(A+B^\text{T}\textbf{diag}(x)B)$ is invertible. The $\textbf{diag}$ operator on a matrix results in a vector of diagonal elements and $\textbf{diag}$ on a vector results in a matrix with diagonal elements on the main diagonal and zero elsewhere. Hint: via matrixcookbook, I figured out that: $$ \frac{\partial \text{Tr}\big((A+B^\text{T}\textbf{diag}(x)B)^{-1}\big)}{\partial x} = \textbf{diag}(B(A+B^\text{T}\textbf{diag}(x)B)^{-2}B^{\text{T}}) $$",,"['linear-algebra', 'derivatives', 'partial-derivative', 'matrix-calculus']"
72,elliptic PDE $\mathbf{u_{xx}+x^2u_{yy}=0}$ $\mathbf{u_{xx}}$ calculation using alternative coordinates $\xi$ and $\eta$.,elliptic PDE   calculation using alternative coordinates  and .,\mathbf{u_{xx}+x^2u_{yy}=0} \mathbf{u_{xx}} \xi \eta,"I am analysing an elliptic PDE $\mathbf{u_{xx}+x^2u_{yy}=0}$ and I don't understand how the below transitions  has been made. What rules have been used to get (2) and (3) $\\(1) \ \ \ \xi = \frac{1}{2} x^2, \ \eta =y \\ (2) \ \ \ \frac{\partial }{\partial x} =x \frac{\partial }{\partial \xi}; \ \ \  \frac{\partial }{\partial y} = \frac{\partial }{\partial \eta} \\ (3) \ \ \ u_{xx} = u_{\xi} + x \frac{\partial }{\partial \xi} u_{\xi} = u_{\xi} + x^2 u_{\xi \xi}$","I am analysing an elliptic PDE $\mathbf{u_{xx}+x^2u_{yy}=0}$ and I don't understand how the below transitions  has been made. What rules have been used to get (2) and (3) $\\(1) \ \ \ \xi = \frac{1}{2} x^2, \ \eta =y \\ (2) \ \ \ \frac{\partial }{\partial x} =x \frac{\partial }{\partial \xi}; \ \ \  \frac{\partial }{\partial y} = \frac{\partial }{\partial \eta} \\ (3) \ \ \ u_{xx} = u_{\xi} + x \frac{\partial }{\partial \xi} u_{\xi} = u_{\xi} + x^2 u_{\xi \xi}$",,"['derivatives', 'partial-differential-equations', 'partial-derivative']"
73,If $\sin y=a\sin(x+y)$ prove $\frac{\rm d y}{\rm d x}=\frac{\sin a}{1- 2x\cos a +x^2}$,If  prove,\sin y=a\sin(x+y) \frac{\rm d y}{\rm d x}=\frac{\sin a}{1- 2x\cos a +x^2},If $\sin y=a\sin(x+y)$ prove $\frac{\rm d y}{\rm d x}=\frac{\sin a}{1- 2x\cos a +x^2}$ I am not finding any proper way even to express $y$ only in terms of $x$ too which could reduce bit complexity. Any help in proving this or validating will be highly appreciated.,If $\sin y=a\sin(x+y)$ prove $\frac{\rm d y}{\rm d x}=\frac{\sin a}{1- 2x\cos a +x^2}$ I am not finding any proper way even to express $y$ only in terms of $x$ too which could reduce bit complexity. Any help in proving this or validating will be highly appreciated.,,"['trigonometry', 'derivatives', 'functional-equations']"
74,Where is the function series $f(x)=\sum\limits_{n=0}^\infty\frac{e^{-nx}}{n^2+1}$ differentiable?,Where is the function series  differentiable?,f(x)=\sum\limits_{n=0}^\infty\frac{e^{-nx}}{n^2+1},"I was asked to analyze the convergence, continuity and differentiability intervals of the next function series: $f(x)=\sum\limits_{n=0}^\infty\frac{e^{-nx}}{n^2+1}$ I already know that this series converge only for $x\geq0$ and that it is continuous in each of these points because of the Weierstrass M-test. However, I can't figure out how to analyze the differentiablity, so I'd appreciate some hints, or some sources regarding these kind of exercises. Thanks in advance.","I was asked to analyze the convergence, continuity and differentiability intervals of the next function series: $f(x)=\sum\limits_{n=0}^\infty\frac{e^{-nx}}{n^2+1}$ I already know that this series converge only for $x\geq0$ and that it is continuous in each of these points because of the Weierstrass M-test. However, I can't figure out how to analyze the differentiablity, so I'd appreciate some hints, or some sources regarding these kind of exercises. Thanks in advance.",,"['real-analysis', 'sequences-and-series', 'derivatives']"
75,Derivative of dot product vs derivative of scalars,Derivative of dot product vs derivative of scalars,,"Suppose $\vec{v}(t)$ is the velocity (vector) function. Then: $$\frac{\mathrm{d} (\vec{v}\cdot\vec{v})}{\mathrm{d} t}=2 \vec{v} \cdot \frac{\mathrm{d} \vec{v} }{\mathrm{d} t}=2 \vec{v} \cdot \vec{a}=2va \cos \varphi$$ where $\vec{a}$ is the acceleration vector and $\varphi$ - the angle between $\vec{a}$ and $\vec{v}$. On the other hand: $$\frac{\mathrm{d} (v\cdot v)}{\mathrm{d} t}=2 v \cdot \frac{\mathrm{d} v }{\mathrm{d} t}=2 v a \neq \frac{\mathrm{d} (\vec{v}\cdot\vec{v})}{\mathrm{d} t}$$ Although $\vec{v}\cdot\vec{v}=v\cdot v$ . Where is my mistake? I ask this because often times in physics I see the substitution $\vec{v} \cdot \vec{v}=v^2$ used in differentiation, although the results we get are different.","Suppose $\vec{v}(t)$ is the velocity (vector) function. Then: $$\frac{\mathrm{d} (\vec{v}\cdot\vec{v})}{\mathrm{d} t}=2 \vec{v} \cdot \frac{\mathrm{d} \vec{v} }{\mathrm{d} t}=2 \vec{v} \cdot \vec{a}=2va \cos \varphi$$ where $\vec{a}$ is the acceleration vector and $\varphi$ - the angle between $\vec{a}$ and $\vec{v}$. On the other hand: $$\frac{\mathrm{d} (v\cdot v)}{\mathrm{d} t}=2 v \cdot \frac{\mathrm{d} v }{\mathrm{d} t}=2 v a \neq \frac{\mathrm{d} (\vec{v}\cdot\vec{v})}{\mathrm{d} t}$$ Although $\vec{v}\cdot\vec{v}=v\cdot v$ . Where is my mistake? I ask this because often times in physics I see the substitution $\vec{v} \cdot \vec{v}=v^2$ used in differentiation, although the results we get are different.",,"['calculus', 'derivatives']"
76,Maths for economics: finding the level of production that minimises marginal cost [closed],Maths for economics: finding the level of production that minimises marginal cost [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let the total cost function of a firm be given by: $$TC(Q)= 16Q^3 - 72Q^2 + 446Q + 90$$ Find the level of production that minimises the marginal cost of production . (This is basically taking the first derivative of $TC$ then equating it to zero and finding the value of $Q$ - this is the part I can't do).","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let the total cost function of a firm be given by: $$TC(Q)= 16Q^3 - 72Q^2 + 446Q + 90$$ Find the level of production that minimises the marginal cost of production . (This is basically taking the first derivative of $TC$ then equating it to zero and finding the value of $Q$ - this is the part I can't do).",,"['calculus', 'derivatives', 'economics']"
77,"Is it true that $ \lim_{h \to 0} \frac{f(x_0 + h, y_0 + h) - f(x_0 + h, y_0)}{h} = \frac{\partial f}{\partial y}(x_0, y_0)?$",Is it true that," \lim_{h \to 0} \frac{f(x_0 + h, y_0 + h) - f(x_0 + h, y_0)}{h} = \frac{\partial f}{\partial y}(x_0, y_0)?","let $f: \mathbb{R}^2 \to \mathbb{C}$ be a continuous function. Let $(x_0,y_0) \in \mathbb{R}^2$ be a point in $\mathbb{R}^2$ such that both partial derivatives $\frac{\partial f}{\partial x}$ and $\frac{\partial f}{\partial y}$ exist at $(x_0,y_0)$ . Is is true that $$ \lim_{h \to 0} \frac{f(x_0 + h, y_0 + h) - f(x_0 + h, y_0)}{h} = \frac{\partial f}{\partial y}(x_0, y_0)?$$ I believe that this statement is true if we know that $f$ is $C^1$ in a neighborhood of $(x_0, y_0)$ , for then the mean value theorem tells us that $$\frac{f(x_0 + h, y_0 + h) - f(x_0 + h, y_0)}{h} = \frac{\partial f}{\partial y}(x_0+ h, \tilde{y}) $$ for some $\tilde{y}$ between $y_0$ and $y_0 + h$ , and this will converge to $\frac{\partial f}{\partial y}(x_0, y_0)$ as $h \to 0$ . But if $f$ is not $C^1$ then we don't have as much to work with. It seems that it may not be true in this case and we need to find a counterexample. Hints or solutions are greatly appreciated.","let be a continuous function. Let be a point in such that both partial derivatives and exist at . Is is true that I believe that this statement is true if we know that is in a neighborhood of , for then the mean value theorem tells us that for some between and , and this will converge to as . But if is not then we don't have as much to work with. It seems that it may not be true in this case and we need to find a counterexample. Hints or solutions are greatly appreciated.","f: \mathbb{R}^2 \to \mathbb{C} (x_0,y_0) \in \mathbb{R}^2 \mathbb{R}^2 \frac{\partial f}{\partial x} \frac{\partial f}{\partial y} (x_0,y_0)  \lim_{h \to 0} \frac{f(x_0 + h, y_0 + h) - f(x_0 + h, y_0)}{h} = \frac{\partial f}{\partial y}(x_0, y_0)? f C^1 (x_0, y_0) \frac{f(x_0 + h, y_0 + h) - f(x_0 + h, y_0)}{h} = \frac{\partial f}{\partial y}(x_0+ h, \tilde{y})  \tilde{y} y_0 y_0 + h \frac{\partial f}{\partial y}(x_0, y_0) h \to 0 f C^1","['real-analysis', 'derivatives', 'partial-derivative']"
78,Second Derivative Of A Parametric Function,Second Derivative Of A Parametric Function,,"If $ y = 2t^3 + t^2 + 3$ $ x = t^2 + 2t + 1 $ then what is $d^2y \over dx^2$ for t = 1? This is the question. What I tried is that, I first took the derivative using the rule $dy/dt \over dx/dt$, and then took the second derivative by taking the derivative of the result with respect to t. To formulate: $$\frac{d}{dt}(\frac{dy/dt}{dx/dt})$$ But in the end, the result didn't come out right. Is what I'm doing wrong? How to solve this question. Thanks in advance. The answer is $5\over8$ by the way, so you'll know when you get it right.","If $ y = 2t^3 + t^2 + 3$ $ x = t^2 + 2t + 1 $ then what is $d^2y \over dx^2$ for t = 1? This is the question. What I tried is that, I first took the derivative using the rule $dy/dt \over dx/dt$, and then took the second derivative by taking the derivative of the result with respect to t. To formulate: $$\frac{d}{dt}(\frac{dy/dt}{dx/dt})$$ But in the end, the result didn't come out right. Is what I'm doing wrong? How to solve this question. Thanks in advance. The answer is $5\over8$ by the way, so you'll know when you get it right.",,"['calculus', 'derivatives']"
79,Why does $\frac{d^2y}{dx^2}$ represent the second derivative? [duplicate],Why does  represent the second derivative? [duplicate],\frac{d^2y}{dx^2},"This question already has answers here : Why is $\frac{d^n}{dx^n}(y(x))$ the notation for the $n$th derivative of $y(x)$, instead of $\frac{d^n}{d^nx}(y(x))$? (5 answers) Closed 8 years ago . I know the second derivative of y wrt x: $\frac{d^2y}{dx^2}$ means  $\frac{d}{dx}(\frac{dy}{dx})$, but is there a mathematical reason you square the $d$ in the numerator but the $x$ in the denominator? I've wondered if it's because the $d$ in the denominator represents some arbitrary infinitely tiny amount, and the $d$ in the numerator is that same $d$, only squared to account for the second derivative. Does that make sense, and/or am I missing something significant about derivatives?","This question already has answers here : Why is $\frac{d^n}{dx^n}(y(x))$ the notation for the $n$th derivative of $y(x)$, instead of $\frac{d^n}{d^nx}(y(x))$? (5 answers) Closed 8 years ago . I know the second derivative of y wrt x: $\frac{d^2y}{dx^2}$ means  $\frac{d}{dx}(\frac{dy}{dx})$, but is there a mathematical reason you square the $d$ in the numerator but the $x$ in the denominator? I've wondered if it's because the $d$ in the denominator represents some arbitrary infinitely tiny amount, and the $d$ in the numerator is that same $d$, only squared to account for the second derivative. Does that make sense, and/or am I missing something significant about derivatives?",,"['calculus', 'derivatives']"
80,Weak Gâteaux Derivative,Weak Gâteaux Derivative,,"Suppose $X$ and $Y$ are Banach spaces. Let $F:X \rightarrow Y$ be a function and $U \subset X$ be an open set. The Gâteaux derivative of $F$ at $u \in U$ in the direction $\phi \in X$ is given by $$\lim_{t \rightarrow 0}\dfrac{F(u+t \phi) - F(u)}{t}.$$ In the Wikipedia article on the Gâteaux derivative , there is this sentence in the section 'definition' In some cases, a weak limit is taken instead of a strong limit, which leads to the notion of a weak Gâteaux derivative. Question: How should one write out the definition of the weak Gâteaux derivative? Since we are talking about weak limit, I suppose we need to talk about the weak topology. EDIT: Suppose $X$ is a Banach space and $\gamma$ is a Gaussian probability measure on $X$. Define a map $$(F * \gamma) (x) = \int \limits _X{F(x+t) \Bbb d\gamma(t)}$$ What is its weak Gâteaux derivative?","Suppose $X$ and $Y$ are Banach spaces. Let $F:X \rightarrow Y$ be a function and $U \subset X$ be an open set. The Gâteaux derivative of $F$ at $u \in U$ in the direction $\phi \in X$ is given by $$\lim_{t \rightarrow 0}\dfrac{F(u+t \phi) - F(u)}{t}.$$ In the Wikipedia article on the Gâteaux derivative , there is this sentence in the section 'definition' In some cases, a weak limit is taken instead of a strong limit, which leads to the notion of a weak Gâteaux derivative. Question: How should one write out the definition of the weak Gâteaux derivative? Since we are talking about weak limit, I suppose we need to talk about the weak topology. EDIT: Suppose $X$ is a Banach space and $\gamma$ is a Gaussian probability measure on $X$. Define a map $$(F * \gamma) (x) = \int \limits _X{F(x+t) \Bbb d\gamma(t)}$$ What is its weak Gâteaux derivative?",,"['functional-analysis', 'derivatives', 'definition']"
81,"is there a function f:R→R , differentiable on (a,b) but not on [a,b] ?(f is continuous on [a,b])","is there a function f:R→R , differentiable on (a,b) but not on [a,b] ?(f is continuous on [a,b])",,"is there a function like f:R→R such that : 1) f is continuous on [a,b] 2) f is differentiable on (a,b) 3) f(a)=f(b) but f is not differentiable on [a,b]??? (if the answer is no , then prove that f is also differentiable on [a,b]) this question came up in calculus 1 class and I think that f should be differentiable on [a,b] but can't prove it... I don't know what is the condition 3 for!!!","is there a function like f:R→R such that : 1) f is continuous on [a,b] 2) f is differentiable on (a,b) 3) f(a)=f(b) but f is not differentiable on [a,b]??? (if the answer is no , then prove that f is also differentiable on [a,b]) this question came up in calculus 1 class and I think that f should be differentiable on [a,b] but can't prove it... I don't know what is the condition 3 for!!!",,"['calculus', 'derivatives']"
82,Prove the inverse of a strictly increasing function is differentiable.,Prove the inverse of a strictly increasing function is differentiable.,,"So, I was given the following problem as part of a homework assignment. Suppose $f'(x) > 0$ in $(a,b)$. Prove that $f$ is strictly increasing in $(a,b)$, and let $g$ be its inverse function. Prove that $g$ is differentiable, and that   $$g'(f(x)) = \frac{1}{f'(x)}$$ I have proven that $f$ is strictly increasing in $(a,b)$, and I could prove that $g'(f(x)) = 1/f'(x)$ if I could prove that $g$ is differentiable. The problem is that I am having trouble with a proof of that. Any advice? Also, as a reference, this is exercise 5.2 from Baby Rudin.","So, I was given the following problem as part of a homework assignment. Suppose $f'(x) > 0$ in $(a,b)$. Prove that $f$ is strictly increasing in $(a,b)$, and let $g$ be its inverse function. Prove that $g$ is differentiable, and that   $$g'(f(x)) = \frac{1}{f'(x)}$$ I have proven that $f$ is strictly increasing in $(a,b)$, and I could prove that $g'(f(x)) = 1/f'(x)$ if I could prove that $g$ is differentiable. The problem is that I am having trouble with a proof of that. Any advice? Also, as a reference, this is exercise 5.2 from Baby Rudin.",,"['real-analysis', 'analysis', 'derivatives', 'monotone-functions']"
83,Use MVT to compare the value of two numbers,Use MVT to compare the value of two numbers,,"Use MVT to Prove that $.99^5>= .95$ I realize I should find a function before using MVT. However, the only function I can think about is $f(x)=x^5$, which doesn't work in this case. Any idea how about how to find a proper function?","Use MVT to Prove that $.99^5>= .95$ I realize I should find a function before using MVT. However, the only function I can think about is $f(x)=x^5$, which doesn't work in this case. Any idea how about how to find a proper function?",,['derivatives']
84,When there exists function $f$ such that for given $g$ we have $f'=g$?,When there exists function  such that for given  we have ?,f g f'=g,"I am looking for a theorem that states when function $g: \mathbb R \mapsto \mathbb R$ is a derrivative, i.e. there exists $f$ such that $f'=g$. What about if we just need this condition almost everywhere? I have looked at Lebesgue differentiation theorem but I either it is not the way to go or i can't extract it from there. I think I have seen such a theorem few years ago, but I can't recall it. Maybe I'll provide some background. I am considering the following integral: $$\int_{\mathbb R} \frac{ - g ( \bar x - y)}{|y|^{\alpha +1}} \phi (y/R) d y$$ Where $g$ is bounded function that is twice-differentiable everywhere except zero. At zero there may be some strange behaviour, not sure how strange. I assume  $\alpha \in (0,2)$ (it has to do with fractional laplacian) and that $\varphi$ is smooth cut-off function thtat is zero at a ball around orgin. I want to write the following: $$\int_{\mathbb R} \frac{ - g ( \bar x - y)}{|y|^{\alpha +1}} \phi (y/R) d y =  \int_{\mathbb R} \partial_k f(\bar x -y) \frac{\phi (y/R)}{|y|^{\alpha+1}} d y = \int_{\mathbb R}  f(\bar x -y) \partial_k \left[ \frac{\phi (y/R) }{|y|^{\alpha+1}} \right] d y$$ If I explicitly assume that $g$ is a derrivative of $f$ it works. I think I can also works when $g$ is Schwartz function. Am I right? But I want to obtain the most general result, hence my question.","I am looking for a theorem that states when function $g: \mathbb R \mapsto \mathbb R$ is a derrivative, i.e. there exists $f$ such that $f'=g$. What about if we just need this condition almost everywhere? I have looked at Lebesgue differentiation theorem but I either it is not the way to go or i can't extract it from there. I think I have seen such a theorem few years ago, but I can't recall it. Maybe I'll provide some background. I am considering the following integral: $$\int_{\mathbb R} \frac{ - g ( \bar x - y)}{|y|^{\alpha +1}} \phi (y/R) d y$$ Where $g$ is bounded function that is twice-differentiable everywhere except zero. At zero there may be some strange behaviour, not sure how strange. I assume  $\alpha \in (0,2)$ (it has to do with fractional laplacian) and that $\varphi$ is smooth cut-off function thtat is zero at a ball around orgin. I want to write the following: $$\int_{\mathbb R} \frac{ - g ( \bar x - y)}{|y|^{\alpha +1}} \phi (y/R) d y =  \int_{\mathbb R} \partial_k f(\bar x -y) \frac{\phi (y/R)}{|y|^{\alpha+1}} d y = \int_{\mathbb R}  f(\bar x -y) \partial_k \left[ \frac{\phi (y/R) }{|y|^{\alpha+1}} \right] d y$$ If I explicitly assume that $g$ is a derrivative of $f$ it works. I think I can also works when $g$ is Schwartz function. Am I right? But I want to obtain the most general result, hence my question.",,"['real-analysis', 'integration', 'derivatives']"
85,"Coordinate of $S(s,t)$ for Which Area of Quadrilateral is Maximum.",Coordinate of  for Which Area of Quadrilateral is Maximum.,"S(s,t)","Let $P(-2,3)\;\;,Q(-1,1)\;\;,R(s,t)$ and $S(2,7)$ be $4$ points in order on the parabola $y=ax^2+bx+c$ . Then the coordinates of $R(s,t)$ such that the area of Quadrilateral $PQRS$ is maximum. $\bf{My\; Try::}$ Here $P(-2,3)\;,Q(-1,1)\;\;,S(2,7)$ be the points lie on the parabola $y=ax^2+bx+c$ So Put $(x,y) = (-2,3)$ in $y=ax^2+bx+c\;,$ We get $4a-2b+c=3.................(1)$ Similarly  Put $(x,y) = (-1,1)$ in $y=ax^2+bx+c\;,$ We get $a-b+c=1...........(2)$ Similarly  Put $(x,y) = (2,7)$ in $y=ax^2+bx+c\;,$ We get $4a+2b+c=7...........(2)$ Now Solving These three equation , We get $a=1\;,b=1\;,c=1$ So we get equation of parabola be $y=x^2+x+1$ Now $\bf{Area\; of\; Quadrilateral\; PQRS = Area\; of \; \triangle PQR+Area\; of \; \triangle PRS}$ So  Area Of Quadrilateral $$A(s,t) = \begin{vmatrix}  -2& 3 & 1\\   -1& 1 & 1\\   s & t & 1 \end{vmatrix}+\begin{vmatrix}  -2& 3 & 1\\   s& t & 1\\   2 & 7 & 1 \end{vmatrix}$$ So $$A(s,t) = 2s+t+1+20+4s-4t = 6s-3t+21$$ Now $R(s,t)$ lie on $y=x^2+x+1.$ So we get $t=s^2+s+1$ So we get $$A(s) = 6s-3(s^2+s+1)+21 = -3s^2+3s+18$$ So using Derivative Test $A'(s)=-6s+3$ and $A''(s)=-6$ So for Max. or min., Put $\displaystyle -6s+3=0\Rightarrow s=\frac{1}{2}$ and $\displaystyle t=\frac{1}{4}+\frac{1}{2}+1 = \frac{7}{4}$ My Question is can we solve it any Shorter way, Means Maximise area using Inequality or Geometrically If yes Then plz explain here. Thanks","Let and be points in order on the parabola . Then the coordinates of such that the area of Quadrilateral is maximum. Here be the points lie on the parabola So Put in We get Similarly  Put in We get Similarly  Put in We get Now Solving These three equation , We get So we get equation of parabola be Now So  Area Of Quadrilateral So Now lie on So we get So we get So using Derivative Test and So for Max. or min., Put and My Question is can we solve it any Shorter way, Means Maximise area using Inequality or Geometrically If yes Then plz explain here. Thanks","P(-2,3)\;\;,Q(-1,1)\;\;,R(s,t) S(2,7) 4 y=ax^2+bx+c R(s,t) PQRS \bf{My\; Try::} P(-2,3)\;,Q(-1,1)\;\;,S(2,7) y=ax^2+bx+c (x,y) = (-2,3) y=ax^2+bx+c\;, 4a-2b+c=3.................(1) (x,y) = (-1,1) y=ax^2+bx+c\;, a-b+c=1...........(2) (x,y) = (2,7) y=ax^2+bx+c\;, 4a+2b+c=7...........(2) a=1\;,b=1\;,c=1 y=x^2+x+1 \bf{Area\; of\; Quadrilateral\; PQRS = Area\; of \; \triangle PQR+Area\; of \; \triangle PRS} A(s,t) = \begin{vmatrix}
 -2& 3 & 1\\ 
 -1& 1 & 1\\ 
 s & t & 1
\end{vmatrix}+\begin{vmatrix}
 -2& 3 & 1\\ 
 s& t & 1\\ 
 2 & 7 & 1
\end{vmatrix} A(s,t) = 2s+t+1+20+4s-4t = 6s-3t+21 R(s,t) y=x^2+x+1. t=s^2+s+1 A(s) = 6s-3(s^2+s+1)+21 = -3s^2+3s+18 A'(s)=-6s+3 A''(s)=-6 \displaystyle -6s+3=0\Rightarrow s=\frac{1}{2} \displaystyle t=\frac{1}{4}+\frac{1}{2}+1 = \frac{7}{4}","['geometry', 'derivatives', 'optimization', 'conic-sections']"
86,How would you differentiate this? I can't get anywhere,How would you differentiate this? I can't get anywhere,,"Let's say that $F$ is a nice well-behaved function. How would I compute the following derivative? $\frac{\partial}{\partial t} \left\{ \int_{0}^{t} \int_{x - t + \eta}^{x + t - \eta} F(\xi,\eta) d\xi d\eta \right\}$ I'm guessing I need the fundamental theorem of calculus, but the double integral is REALLY throwing me off - especially that the $t$ is contained in the limits of both integrals. Can someone help me out? EDIT: Given the problem that this came up in, I have hunch that the above derivative is zero.","Let's say that $F$ is a nice well-behaved function. How would I compute the following derivative? $\frac{\partial}{\partial t} \left\{ \int_{0}^{t} \int_{x - t + \eta}^{x + t - \eta} F(\xi,\eta) d\xi d\eta \right\}$ I'm guessing I need the fundamental theorem of calculus, but the double integral is REALLY throwing me off - especially that the $t$ is contained in the limits of both integrals. Can someone help me out? EDIT: Given the problem that this came up in, I have hunch that the above derivative is zero.",,"['calculus', 'integration', 'derivatives']"
87,is my answer correct? derivative of logarithmic functions,is my answer correct? derivative of logarithmic functions,,"I want to check my answer, pleas tell me if it's correct or not first problem $y=\left(\log _{\frac{1}{x}}\left(e\right)\right)$ my answer $y=\frac{lne}{ln_{\frac{1}{x}}}$ $y^|=lne\frac{d\left(\frac{1}{ln_{\frac{1}{x}}}\right)}{dx}=-\left(ln_{\frac{1}{x}}\right)^{-2}\frac{-x^{-2}}{\frac{1}{x}}=\left(lne\right)\left(\frac{-1}{\left(ln_{\frac{1}{x}}\right)^2}\right)\cdot \left(\frac{-1}{x}\right)$ $y^|=\frac{1}{x\left(ln_{\frac{1}{x}}\right)^2}$ second problem $y=\log _{lnx}\left(e\right)$ my answer $y=\frac{lne}{ln\left(lnx\right)}$ $y^|=y=lne\frac{d}{dx}\left(\frac{1}{ln\left(lnx\right)}\right)=\frac{\frac{-\frac{1}{xlnx}}{\left(ln\left(lnx\right)\right)^2}}{\left(ln\left(lnx\right)\right)^{-1}}=\frac{-\frac{1}{xlnx}}{ln\left(lnx\right)}$ $y^|==\frac{-1}{\left(xlnx\right)ln\left(lnx\right)}$","I want to check my answer, pleas tell me if it's correct or not first problem $y=\left(\log _{\frac{1}{x}}\left(e\right)\right)$ my answer $y=\frac{lne}{ln_{\frac{1}{x}}}$ $y^|=lne\frac{d\left(\frac{1}{ln_{\frac{1}{x}}}\right)}{dx}=-\left(ln_{\frac{1}{x}}\right)^{-2}\frac{-x^{-2}}{\frac{1}{x}}=\left(lne\right)\left(\frac{-1}{\left(ln_{\frac{1}{x}}\right)^2}\right)\cdot \left(\frac{-1}{x}\right)$ $y^|=\frac{1}{x\left(ln_{\frac{1}{x}}\right)^2}$ second problem $y=\log _{lnx}\left(e\right)$ my answer $y=\frac{lne}{ln\left(lnx\right)}$ $y^|=y=lne\frac{d}{dx}\left(\frac{1}{ln\left(lnx\right)}\right)=\frac{\frac{-\frac{1}{xlnx}}{\left(ln\left(lnx\right)\right)^2}}{\left(ln\left(lnx\right)\right)^{-1}}=\frac{-\frac{1}{xlnx}}{ln\left(lnx\right)}$ $y^|==\frac{-1}{\left(xlnx\right)ln\left(lnx\right)}$",,"['derivatives', 'logarithms']"
88,Minimizing $f(x)=A^{\frac{tx-1}{x-1}} \left( c^x \frac{\Gamma(0.5+x)}{\sqrt{\pi}} \right)^{\frac{1-t}{x-1}}$ subject to the constraint,Minimizing  subject to the constraint,f(x)=A^{\frac{tx-1}{x-1}} \left( c^x \frac{\Gamma(0.5+x)}{\sqrt{\pi}} \right)^{\frac{1-t}{x-1}},"Let $f(r)$ be a function defined as follows  \begin{align} f(x)=A^{\frac{tx-1}{x-1}} \left( c^x \frac{\Gamma(0.5+x)}{\sqrt{\pi}} \right)^{\frac{1-t}{x-1}} \end{align} where $0 < A,c$ and $ t\in (0,1)$. I want to solve  \begin{align} \min_{\frac{1}{t}<x}  f(x) \end{align} My approach: Let $g(x)=\ln(f(x))$ then both $g(x)$ and $f(x)$ have the same minimum where \begin{align} g(x)=\frac{tx-1}{x-1} \ln(A)+\frac{(1-t)x}{x-1} \ln(c)+\frac{1-t}{x-1} \ln \left(\Gamma(0.5+x) \right)-\frac{1-t}{2(x-1)}\ln(\pi) \end{align} and  \begin{align} &g'(x)=\\ &=\frac{1-t}{(x-1)^2} \ln(A)-\frac{1-t}{(x-1)^2} \ln(c)+(1-t)\frac{(x-1)\psi^{(0)}(x+0.5)-\log(\Gamma(x+0.5))}{(x-1)^2}+\frac{1-t}{2(x-1)^2}\ln(\pi)\\ &=\frac{1-t}{(x-1)^2} \left(\ln \left( \frac{ \sqrt{\pi} A}{c\Gamma(x+0.5)} \right)+ (x-1)\psi^{(0)}(x+0.5)\right) \end{align} where $\psi(x)$ is the so called digamma function. So, this means we have to focus on  \begin{align} h(x)=\ln \left( \frac{ \sqrt{\pi} A}{c\Gamma(x+0.5)} \right)+ (x-1)\psi^{(0)}(x+0.5) \end{align} for $\frac{1}{t} <x$. But how to solve $h(x)=0$ or say for what $x$ is $h(x)>0$ ??? If this impossible to do then the approximated solution is also fine? I also feel that there might be a simpler approach with out using derivative. Thank you for any help.","Let $f(r)$ be a function defined as follows  \begin{align} f(x)=A^{\frac{tx-1}{x-1}} \left( c^x \frac{\Gamma(0.5+x)}{\sqrt{\pi}} \right)^{\frac{1-t}{x-1}} \end{align} where $0 < A,c$ and $ t\in (0,1)$. I want to solve  \begin{align} \min_{\frac{1}{t}<x}  f(x) \end{align} My approach: Let $g(x)=\ln(f(x))$ then both $g(x)$ and $f(x)$ have the same minimum where \begin{align} g(x)=\frac{tx-1}{x-1} \ln(A)+\frac{(1-t)x}{x-1} \ln(c)+\frac{1-t}{x-1} \ln \left(\Gamma(0.5+x) \right)-\frac{1-t}{2(x-1)}\ln(\pi) \end{align} and  \begin{align} &g'(x)=\\ &=\frac{1-t}{(x-1)^2} \ln(A)-\frac{1-t}{(x-1)^2} \ln(c)+(1-t)\frac{(x-1)\psi^{(0)}(x+0.5)-\log(\Gamma(x+0.5))}{(x-1)^2}+\frac{1-t}{2(x-1)^2}\ln(\pi)\\ &=\frac{1-t}{(x-1)^2} \left(\ln \left( \frac{ \sqrt{\pi} A}{c\Gamma(x+0.5)} \right)+ (x-1)\psi^{(0)}(x+0.5)\right) \end{align} where $\psi(x)$ is the so called digamma function. So, this means we have to focus on  \begin{align} h(x)=\ln \left( \frac{ \sqrt{\pi} A}{c\Gamma(x+0.5)} \right)+ (x-1)\psi^{(0)}(x+0.5) \end{align} for $\frac{1}{t} <x$. But how to solve $h(x)=0$ or say for what $x$ is $h(x)>0$ ??? If this impossible to do then the approximated solution is also fine? I also feel that there might be a simpler approach with out using derivative. Thank you for any help.",,"['derivatives', 'optimization', 'gamma-function', 'polygamma', 'digamma-function']"
89,Tangent of Cubic Hermite curve,Tangent of Cubic Hermite curve,,"I have created cubic curve using CatmullRom Spline or Akima spline. From those, I obtain $a, b, c, d$ parameters. To get point on the curve, I do this $f(t) = a + bt + ct^2 + dt^3$ How to get tangent at $f(t)$? By just simply doing $ f´(t) = b + 2ct + 3dt^3$ or is this wrong and I have to calculate new $a, b, c, d$ as well? EDIT: For example, Catmull-Rom is calculated SplineSegment[] C = new SplineSegment[n]; for (all control points) {     C[i].a = 0.5f * (                 2 * cp[i]);     C[i].b = 0.5f * (   - cp[i - 1]             +     cp[i + 1]);     C[i].c = 0.5f * ( 2 * cp[i - 1] - 5 * cp[i] + 4 * cp[i + 1] - cp[i + 2]);     C[i].d = 0.5f * (   - cp[i - 1] + 3 * cp[i] - 3 * cp[i + 1] + cp[i + 2]);            } Natural cubic spline: SplineSegment[] C = new SplineSegment[n]; for (all control points) {     C[i].a = cp[i];     C[i].b = D[i];     C[i].c = 3 * (cp[i + 1] - cp[i]) - 2 * D[i] - D[i + 1];     C[i].d = 2 * (cp[i] - cp[i + 1]) + D[i] + D[i + 1]; }  //D is calculated from Cubic spline matrix","I have created cubic curve using CatmullRom Spline or Akima spline. From those, I obtain $a, b, c, d$ parameters. To get point on the curve, I do this $f(t) = a + bt + ct^2 + dt^3$ How to get tangent at $f(t)$? By just simply doing $ f´(t) = b + 2ct + 3dt^3$ or is this wrong and I have to calculate new $a, b, c, d$ as well? EDIT: For example, Catmull-Rom is calculated SplineSegment[] C = new SplineSegment[n]; for (all control points) {     C[i].a = 0.5f * (                 2 * cp[i]);     C[i].b = 0.5f * (   - cp[i - 1]             +     cp[i + 1]);     C[i].c = 0.5f * ( 2 * cp[i - 1] - 5 * cp[i] + 4 * cp[i + 1] - cp[i + 2]);     C[i].d = 0.5f * (   - cp[i - 1] + 3 * cp[i] - 3 * cp[i + 1] + cp[i + 2]);            } Natural cubic spline: SplineSegment[] C = new SplineSegment[n]; for (all control points) {     C[i].a = cp[i];     C[i].b = D[i];     C[i].c = 3 * (cp[i + 1] - cp[i]) - 2 * D[i] - D[i + 1];     C[i].d = 2 * (cp[i] - cp[i + 1]) + D[i] + D[i + 1]; }  //D is calculated from Cubic spline matrix",,"['derivatives', 'curves', 'spline']"
90,Where does $(a^2+2ab\cos(\theta)+b^2)^{p/2}+(a^2-2ab\cos(\theta)+b^2)^{p/2}$ have a Maximum?,Where does  have a Maximum?,(a^2+2ab\cos(\theta)+b^2)^{p/2}+(a^2-2ab\cos(\theta)+b^2)^{p/2},"Consider the real-valued function $$ \phi : [0,2 \pi) \rightarrow \mathbb{R} \\ \phi (\theta)=(a^2+2ab\cos(\theta)+b^2)^{p/2}+(a^2-2ab\cos(\theta)+b^2)^{p/2}$$ for $1<p$ and $a,b \in \mathbb{R}$. Where does this function attain its maximum/minimum? Does this depend on the choice of $a,b$ and $p$? If we compute the derivative we get: $$ \phi ' (\theta) = -abp \sin(\theta)((a^2+2ab\cos(\theta)+b^2)^{p/2-1}-(a^2-2ab\cos(\theta)+b^2)^{p/2-1})$$ The derivative vanishes at $0, \frac{\pi}{2}, \pi$ and $\frac{3 \pi}{2}$. So we have to inspect: $$ \phi(0)=\phi(\pi)=(a^2+2ab+b^2)^{p/2}+(a^2-2ab+b^2)^{p/2} = ((a+b)^2)^{p/2}+((a^2-b^2)^2)^{p/2}$$ and $$ \phi(\pi /2)=\phi(3\pi /2)=(a^2+b^2)^{p/2}+(a^2+b^2)^{p/2}$$ I can't really see which of the two is the max/min. How can we see which is?","Consider the real-valued function $$ \phi : [0,2 \pi) \rightarrow \mathbb{R} \\ \phi (\theta)=(a^2+2ab\cos(\theta)+b^2)^{p/2}+(a^2-2ab\cos(\theta)+b^2)^{p/2}$$ for $1<p$ and $a,b \in \mathbb{R}$. Where does this function attain its maximum/minimum? Does this depend on the choice of $a,b$ and $p$? If we compute the derivative we get: $$ \phi ' (\theta) = -abp \sin(\theta)((a^2+2ab\cos(\theta)+b^2)^{p/2-1}-(a^2-2ab\cos(\theta)+b^2)^{p/2-1})$$ The derivative vanishes at $0, \frac{\pi}{2}, \pi$ and $\frac{3 \pi}{2}$. So we have to inspect: $$ \phi(0)=\phi(\pi)=(a^2+2ab+b^2)^{p/2}+(a^2-2ab+b^2)^{p/2} = ((a+b)^2)^{p/2}+((a^2-b^2)^2)^{p/2}$$ and $$ \phi(\pi /2)=\phi(3\pi /2)=(a^2+b^2)^{p/2}+(a^2+b^2)^{p/2}$$ I can't really see which of the two is the max/min. How can we see which is?",,"['calculus', 'derivatives']"
91,"If $f,f',f''$ are bounded a.e., is $f'$ of bounded variation everywhere?","If  are bounded a.e., is  of bounded variation everywhere?","f,f',f'' f'","Assume the function $f$ is such that everywhere except in $0$: $f$ is bounded on $\mathbb{R}$ $f$ is twice differentiable everywhere except in $0$ $f'$ and $f''$ are bounded everywhere except in $0$ Question I the derivative of $f$, in the weak sense, of bounded variation? What I think $f'$ and $f''$ are not defined on $\mathbb{R}$ but by by extension, in the measure sense, $f'(t)=v(t)+\alpha H(t)$ where $v$ is differentiable on $\mathbb{R}$ and $H$ is the Heaviside function. Similarly, $f''(t)=a(t)+\alpha\delta(t)$ where $a=v'$ and $\delta$ is the Dirac function. $\alpha H$ is of bounded variation, $a$ is bounded on $\mathbb R$, so $v$ is Lipschitz hence of bounded variation, and so is their sum $f'$. Does it make sense?","Assume the function $f$ is such that everywhere except in $0$: $f$ is bounded on $\mathbb{R}$ $f$ is twice differentiable everywhere except in $0$ $f'$ and $f''$ are bounded everywhere except in $0$ Question I the derivative of $f$, in the weak sense, of bounded variation? What I think $f'$ and $f''$ are not defined on $\mathbb{R}$ but by by extension, in the measure sense, $f'(t)=v(t)+\alpha H(t)$ where $v$ is differentiable on $\mathbb{R}$ and $H$ is the Heaviside function. Similarly, $f''(t)=a(t)+\alpha\delta(t)$ where $a=v'$ and $\delta$ is the Dirac function. $\alpha H$ is of bounded variation, $a$ is bounded on $\mathbb R$, so $v$ is Lipschitz hence of bounded variation, and so is their sum $f'$. Does it make sense?",,"['measure-theory', 'derivatives', 'bounded-variation']"
92,"How to differentiate $x^4y^4$ with respect to $x$, if $y$ is a function of $x$?","How to differentiate  with respect to , if  is a function of ?",x^4y^4 x y x,"I have an online homework question that reads: differentiate the expression $x^4y^4$ with respect to $x$. The matching homework question in the textbook reads the same except the exponents are different: $x^2y^3$. For the textbook question I followed the product rule and got $(2xy^3)(3y^2)$. However, the answer key says the answer is $\frac{d}{dx}(x^2y^3)=3x^2y^2y'+2xy^3$. Can someone explain the methods to achieving this method and why it is correct. Also what exactly does $\frac{d}{dx}$ mean?","I have an online homework question that reads: differentiate the expression $x^4y^4$ with respect to $x$. The matching homework question in the textbook reads the same except the exponents are different: $x^2y^3$. For the textbook question I followed the product rule and got $(2xy^3)(3y^2)$. However, the answer key says the answer is $\frac{d}{dx}(x^2y^3)=3x^2y^2y'+2xy^3$. Can someone explain the methods to achieving this method and why it is correct. Also what exactly does $\frac{d}{dx}$ mean?",,"['calculus', 'derivatives', 'implicit-differentiation']"
93,Time derivative of the distance between 2 points moving over time,Time derivative of the distance between 2 points moving over time,,"let $d_{ij}$ the distance between 2 points in space $p_i$ and $p_j$. These 2 points are moving over time so it is more correct to write them as $p_i(t)$ and $p_j(t)$. $p_i$ and $p_j$ are, at every time, vectors in 3D to identify a point in 3D space. So $d_{ij}$ is : $d_{ij}=|| p_j - p_i ||$ I would like to know why, if it is correct, that: $\dot{d_{ij}}=\beta_{ij}^T(\dot{p_j}-\dot{p_i})$ where $\beta_{ij}$ is the bearing vector between point $i$ and point $j$. Which is defined as $\beta_{ij} = \frac{p_j-p_i}{d_{ij}}$ The $\beta_{ij}$ it is a unit vector which gives the direction between point $i$ and point $j$. I am working to understand this but until now I didn't succeded. Can someone help me please? Thanks a lot.","let $d_{ij}$ the distance between 2 points in space $p_i$ and $p_j$. These 2 points are moving over time so it is more correct to write them as $p_i(t)$ and $p_j(t)$. $p_i$ and $p_j$ are, at every time, vectors in 3D to identify a point in 3D space. So $d_{ij}$ is : $d_{ij}=|| p_j - p_i ||$ I would like to know why, if it is correct, that: $\dot{d_{ij}}=\beta_{ij}^T(\dot{p_j}-\dot{p_i})$ where $\beta_{ij}$ is the bearing vector between point $i$ and point $j$. Which is defined as $\beta_{ij} = \frac{p_j-p_i}{d_{ij}}$ The $\beta_{ij}$ it is a unit vector which gives the direction between point $i$ and point $j$. I am working to understand this but until now I didn't succeded. Can someone help me please? Thanks a lot.",,"['calculus', 'derivatives', 'normed-spaces', 'partial-derivative']"
94,A version of the product rule,A version of the product rule,,"Using the product rule we know that $$\frac{ {\rm d}\ln(fg)}{ {\rm d} x} = \frac{f'g+fg'}{fg}$$ Is there a function $K$ such that $$\frac{ {\rm d} K(f,g)}{ {\rm d} x} = \frac{f'g-fg'}{fg}$$ ...?","Using the product rule we know that $$\frac{ {\rm d}\ln(fg)}{ {\rm d} x} = \frac{f'g+fg'}{fg}$$ Is there a function $K$ such that $$\frac{ {\rm d} K(f,g)}{ {\rm d} x} = \frac{f'g-fg'}{fg}$$ ...?",,['derivatives']
95,What is a smooth function?,What is a smooth function?,,"According to Wikipedia , a smooth function is a function that has derivatives of all orders. I don't understand what this means if the case was for example the function $$f(x) = 1+2x$$  This can be differentiated only twice until it is zero. Is this considered a smooth function? I am confused about the definition.","According to Wikipedia , a smooth function is a function that has derivatives of all orders. I don't understand what this means if the case was for example the function $$f(x) = 1+2x$$  This can be differentiated only twice until it is zero. Is this considered a smooth function? I am confused about the definition.",,"['real-analysis', 'derivatives', 'terminology', 'definition']"
96,parametric equations of a curve,parametric equations of a curve,,"The parametric equations of a curve are $$x=2\theta-\sin 2\theta$$ $$y=2-\cos 2\theta$$ The question asks that ''For the part of the curve where $0<\theta<2\pi$, find the coordinates of the points where the tangent is parallel to the x-axis''. How can I solve this?","The parametric equations of a curve are $$x=2\theta-\sin 2\theta$$ $$y=2-\cos 2\theta$$ The question asks that ''For the part of the curve where $0<\theta<2\pi$, find the coordinates of the points where the tangent is parallel to the x-axis''. How can I solve this?",,"['calculus', 'derivatives', 'parametric']"
97,How to calculate the derivative of the pseudo-inverse matrix,How to calculate the derivative of the pseudo-inverse matrix,,I have the following equation: $$ \begin{equation}   x=(A^TA)^{-1}A^Tb \end{equation} $$ and I need to calculate the derivative of k-th entry of x with respect to A: $$ \begin{equation}  \frac{\partial x(k)}{\partial A} \end{equation} $$ I really don't know how to solve it! Can someone help me? Thank you!,I have the following equation: $$ \begin{equation}   x=(A^TA)^{-1}A^Tb \end{equation} $$ and I need to calculate the derivative of k-th entry of x with respect to A: $$ \begin{equation}  \frac{\partial x(k)}{\partial A} \end{equation} $$ I really don't know how to solve it! Can someone help me? Thank you!,,"['matrices', 'derivatives', 'pseudoinverse']"
98,Prove derivative with summation by induction,Prove derivative with summation by induction,,"I have this math question. That I am stuck on. If $f$ is a function, let $Df$ be its derivative.  For $n\in  \mathbb{Z}^+$ let $$ f^{(n)} = \underbrace{D \cdots D }_{n\mathrm{\  times}} f $$ be the $n^\mathrm{th}$ derivative of $f$.  In this    notation the usual product rule from calculus  says that   $$  (fg)^{(1)} = fg^{(1)} + f^{(1)} g. $$ Using the product rule, prove    the formula for the $n^\mathrm{th}$ derivative of a product  $$  (fg)^{(n)} = \sum_{k=0}^n \binom{n}{k} f^{(n-k)} g^{(k)}. $$ (Hint:     The proof in here is similar to the proof of the Binomial Theorem.) Here's my work for it so far: $$(fg)^{(1)} = \sum_{k=0}^{1}\binom{1}{k}f^{(1-k)}g^k=f^{(1)}g^{(0)}+f^{(0)}g^{(1)}$$ We assume $P(m)$ is true (induction assumption): $$(fg)^{(m)}=\sum_{k=0}^{m}\binom{m}{k}f^{(m-k)}g^k$$ We want to show that $P(m+1)$ is also true: $$(fg)^{(m+1)}=\sum_{k=0}^{m+1}\binom{m+1}{k}f^{(m+1-k)}g^k$$ I'm not sure how to connect the induction assumption with $P(m+1)$ thanks.","I have this math question. That I am stuck on. If $f$ is a function, let $Df$ be its derivative.  For $n\in  \mathbb{Z}^+$ let $$ f^{(n)} = \underbrace{D \cdots D }_{n\mathrm{\  times}} f $$ be the $n^\mathrm{th}$ derivative of $f$.  In this    notation the usual product rule from calculus  says that   $$  (fg)^{(1)} = fg^{(1)} + f^{(1)} g. $$ Using the product rule, prove    the formula for the $n^\mathrm{th}$ derivative of a product  $$  (fg)^{(n)} = \sum_{k=0}^n \binom{n}{k} f^{(n-k)} g^{(k)}. $$ (Hint:     The proof in here is similar to the proof of the Binomial Theorem.) Here's my work for it so far: $$(fg)^{(1)} = \sum_{k=0}^{1}\binom{1}{k}f^{(1-k)}g^k=f^{(1)}g^{(0)}+f^{(0)}g^{(1)}$$ We assume $P(m)$ is true (induction assumption): $$(fg)^{(m)}=\sum_{k=0}^{m}\binom{m}{k}f^{(m-k)}g^k$$ We want to show that $P(m+1)$ is also true: $$(fg)^{(m+1)}=\sum_{k=0}^{m+1}\binom{m+1}{k}f^{(m+1-k)}g^k$$ I'm not sure how to connect the induction assumption with $P(m+1)$ thanks.",,"['derivatives', 'summation', 'proof-writing', 'binomial-theorem']"
99,Differentiate a function with respect to a vector,Differentiate a function with respect to a vector,,"I'm reading my course on quantum mechanics and I just noticed something strange (or at least new to me) that I don't really understand : $$\psi(\vec{r},t) = \psi_0 e^{\frac{i}{\hbar}(\vec{p}.\vec{r} -Et)}$$ $$\frac{d\psi}{d\vec{r}} = \frac{i\vec{p}}{\hbar}\psi \hspace{5mm}, \hspace 5mm\frac{d\psi}{dt} = -\frac{iE}{\hbar}\psi$$ I'm confused. I've never seen this notation $\frac{d\psi}{d\vec{r}}$ before (with the vector at the bottom). Usually, when there are vectors, I see grad, div, etc... So what happened here ? Everything looks like the operation has been carried out by treating $\vec{r}$ like a simple variable and $\vec{p}$ like a simple constant, I didn't know that was possible. Exactly what rules have been applied here ? When can I do that ?","I'm reading my course on quantum mechanics and I just noticed something strange (or at least new to me) that I don't really understand : $$\psi(\vec{r},t) = \psi_0 e^{\frac{i}{\hbar}(\vec{p}.\vec{r} -Et)}$$ $$\frac{d\psi}{d\vec{r}} = \frac{i\vec{p}}{\hbar}\psi \hspace{5mm}, \hspace 5mm\frac{d\psi}{dt} = -\frac{iE}{\hbar}\psi$$ I'm confused. I've never seen this notation $\frac{d\psi}{d\vec{r}}$ before (with the vector at the bottom). Usually, when there are vectors, I see grad, div, etc... So what happened here ? Everything looks like the operation has been carried out by treating $\vec{r}$ like a simple variable and $\vec{p}$ like a simple constant, I didn't know that was possible. Exactly what rules have been applied here ? When can I do that ?",,"['derivatives', 'vector-analysis']"
