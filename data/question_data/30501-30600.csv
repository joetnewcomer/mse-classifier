,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Fubini-Tonelli theorem,Fubini-Tonelli theorem,,"I have the following question with me: Let $X, Y$ be independent real valued random variables and define $Z:=X+Y$ . Let $F_X, F_Y$ and $F_Z$ be the respective distribution functions of $X$ , $Y$ and $Z$ . Show that $$ F_Z(a)=\int F_X(a-y) P^Y(d y), \quad a \in \mathbb{R} . $$ If $X$ has continuous density $f_X$ , show that $$ f_Z(a):=\int f_X(a-y) P^Y(d y), \quad a \in \mathbb{R} $$ is the density of $Z$ . If $X$ has continuous density $f_X$ and $Y$ has continuous density $f_Y$ , show that $$ f_Z(a):=\int_{-\infty}^{\infty} f_X(a-y) f_Y(y) d y, \quad a \in \mathbb{R} $$ is the density of $Z$ . This is what I've tried: I can use the Fubini-Tonelli theorem to calculate $F_Z(a)$ . Also, integrating is easier than taking derivative. The following is the theorem:  Let $(E, \mathcal{E}, P)$ and $(F, \mathcal{F}, Q)$ be probability spaces. a) Define $R(A \times B)=P(A) Q(B)$ for $A \in \mathcal{E}, B \in \mathcal{F}$ . R extends uniquely to a probability measure $P \otimes Q$ on $\mathcal{E} \times \mathcal{F}$ (it is called the product measure). b) If $f$ is measurable and integrable (or positive) w.r.t. $\mathcal{E} \otimes \mathcal{F}$ , then the functions $$ \begin{aligned} x & \mapsto \int f(x, y) Q(d y), \\ y & \mapsto \int f(x, y) P(d x) \end{aligned} $$ are measurable and $$ \begin{aligned} \int f d P \otimes Q & =\int\left\{\int f(x, y) Q(d y)\right\} P(d x) \\ & =\int\left\{\int f(x, y) P(d x)\right\} Q(d y) \end{aligned} $$ But I'm not still not able to fully figure this out, and I would appreciate help. Thank you!!","I have the following question with me: Let be independent real valued random variables and define . Let and be the respective distribution functions of , and . Show that If has continuous density , show that is the density of . If has continuous density and has continuous density , show that is the density of . This is what I've tried: I can use the Fubini-Tonelli theorem to calculate . Also, integrating is easier than taking derivative. The following is the theorem:  Let and be probability spaces. a) Define for . R extends uniquely to a probability measure on (it is called the product measure). b) If is measurable and integrable (or positive) w.r.t. , then the functions are measurable and But I'm not still not able to fully figure this out, and I would appreciate help. Thank you!!","X, Y Z:=X+Y F_X, F_Y F_Z X Y Z 
F_Z(a)=\int F_X(a-y) P^Y(d y), \quad a \in \mathbb{R} .
 X f_X 
f_Z(a):=\int f_X(a-y) P^Y(d y), \quad a \in \mathbb{R}
 Z X f_X Y f_Y 
f_Z(a):=\int_{-\infty}^{\infty} f_X(a-y) f_Y(y) d y, \quad a \in \mathbb{R}
 Z F_Z(a) (E, \mathcal{E}, P) (F, \mathcal{F}, Q) R(A \times B)=P(A) Q(B) A \in \mathcal{E}, B \in \mathcal{F} P \otimes Q \mathcal{E} \times \mathcal{F} f \mathcal{E} \otimes \mathcal{F} 
\begin{aligned}
x & \mapsto \int f(x, y) Q(d y), \\
y & \mapsto \int f(x, y) P(d x)
\end{aligned}
 
\begin{aligned}
\int f d P \otimes Q & =\int\left\{\int f(x, y) Q(d y)\right\} P(d x) \\
& =\int\left\{\int f(x, y) P(d x)\right\} Q(d y)
\end{aligned}
","['probability', 'probability-theory', 'probability-distributions', 'fubini-tonelli-theorems']"
1,A stopping time problem for a random walk with transition probabilities dependent on states,A stopping time problem for a random walk with transition probabilities dependent on states,,"The Problem: In a one-dimensional random walk, at position $n > 0$ , the probability of moving to $(n-1)$ is $\frac{n+2}{2n+2}$ , and the probability of moving to $(n+1)$ is $\frac{n}{2n+2}$ . Starting at position $n$ , what is the average time to reach position $0$ ? Question 1: Let $v(n)$ be the expected time of moving from $n$ to $0$ . Then we have the following recursive equation: $$v(n) = 1 + \frac{n+2}{2n+2} v(n-1) + \frac{n}{2n+2} v(n+1)$$ And obviously $v(0) = 0$ , but to solve the equation we also need to know $v(1)$ , which I cannot compute. So my first question is: How to compute $v(1)$ ? p.s. Using random simulation on a computer, I have estimated that $v(1) = 3$ . Then the recursive equation can be solved to obtain $v(n) = n(n+2)$ . But I do not know how to compute $v(1)$ theoretically. Question 2: Another way to solve this problem is to use martingale. Let $X_t$ be the random position at time $t$ , and $X_0 = n$ . Let $$Y_t = (X_t+1)^2 + t$$ then $\{Y_t, t \ge 0\}$ is a martingale with respect to $\{X_t, t \ge 0\}$ . Let $T$ be the first visit time from $n$ to $0$ (stopping time). If the optional stopping theorem is applicable , then $$E(Y_T)= (0+1)^2+E(T) = E(Y_0) = (n+1)^2 + 0$$ So we have $$E(T) = n(n+2)$$ However, for the optional stopping theorem to be applicable, I have to firstly prove $E(T) < \infty$ . So my second question is: How to prove the expected stopping time $E(T) < \infty$ ? Thanks","The Problem: In a one-dimensional random walk, at position , the probability of moving to is , and the probability of moving to is . Starting at position , what is the average time to reach position ? Question 1: Let be the expected time of moving from to . Then we have the following recursive equation: And obviously , but to solve the equation we also need to know , which I cannot compute. So my first question is: How to compute ? p.s. Using random simulation on a computer, I have estimated that . Then the recursive equation can be solved to obtain . But I do not know how to compute theoretically. Question 2: Another way to solve this problem is to use martingale. Let be the random position at time , and . Let then is a martingale with respect to . Let be the first visit time from to (stopping time). If the optional stopping theorem is applicable , then So we have However, for the optional stopping theorem to be applicable, I have to firstly prove . So my second question is: How to prove the expected stopping time ? Thanks","n > 0 (n-1) \frac{n+2}{2n+2} (n+1) \frac{n}{2n+2} n 0 v(n) n 0 v(n) = 1 + \frac{n+2}{2n+2} v(n-1) + \frac{n}{2n+2} v(n+1) v(0) = 0 v(1) v(1) v(1) = 3 v(n) = n(n+2) v(1) X_t t X_0 = n Y_t = (X_t+1)^2 + t \{Y_t, t \ge 0\} \{X_t, t \ge 0\} T n 0 E(Y_T)= (0+1)^2+E(T) = E(Y_0) = (n+1)^2 + 0 E(T) = n(n+2) E(T) < \infty E(T) < \infty","['probability', 'martingales', 'markov-process', 'random-walk', 'stopping-times']"
2,"Definitions of the Stratonovich integral and why the ""average"" definition is arguably correct","Definitions of the Stratonovich integral and why the ""average"" definition is arguably correct",,"Notations: Herein: $\mathcal{B} := \{B(t)\}_{t \ge 0}$ denotes a standard Brownian motion, with $B(0) = 0$ . $P := \{x_i\}_{i=0}^n$ denotes a partition of the interval $[0,t]$ , with norm defined in the Riemannian sense. $\Delta B_i := B(x_i) - B(x_{i-1})$ . $\Delta x_i := x_i - x_{i-1}$ . $\mathcal{X} := \{X(t)\}_{t \ge 0}$ denotes a Stratonovich-integrable process, in whatever sense that is needed at the time. $\int_0^t X(s) \circ \mathrm{d} B(s)$ denotes the Stratonovich integral. The Conflicting Definitions: There are two conflicting definitions for the Stratonovich integral, which to my understanding are stated below: $$\begin{align*} \int_0^t X(s) \circ \mathrm{d}B(s) &:= \lim_{\|P\| \to 0} \sum_{i=1}^n \frac{X(x_i) + X(x_{i-1})}{2} \Delta B_i \tag{1} \\ \int_0^t X(s) \circ \mathrm{d}B(s) &:= \lim_{\|P\| \to 0} \sum_{i=1}^n X \left( \frac{x_i + x_{i-1}}{2} \right) \Delta B_i \tag{2} \end{align*}$$ The First Definition: Definition $(1)$ seems to be motivated by averaging $X(t)$ over each interval induced by $P$ . In fact we could have a ""more general"" integral by considering, for $\lambda \in [0,1]$ , $$\lim_{\|P\| \to 0} \sum_{i=1}^n \Big( (1-\lambda) X(x_i) + \lambda X(x_{i-1}) \Big)\Delta B_i \tag{1'}$$ where Itô integration arises from $\lambda = 0$ , as an example, and Stratonovich (in the sense of $(1)$ ) under $\lambda=1/2$ . In my reading, I've seen this used by The Wikipedia article on Stratonovich integrals (link) Apparently this is used in Ioannis Karatzas & Steven Shreve's Brownian Motion and Stochastic Calculus (Amazon link) The Encyclopedia of Math website (link) An article by Jonathan Mattingly on The Probability Workbook (link) The Second Definition: Definition $(2)$ seems to be inspired simply by the Riemann-Stieltjes formulation for deterministic functions: $$\int_0^t f(x) \, \mathrm{d} \varphi(x) = \lim_{\|P\| \to 0} \sum_{i=1}^n f(\xi_i) \Delta \varphi_i \tag{2'}$$ (for $\Delta \varphi_i$ defined similarly as for $\Delta B_i$ ). In this case, $\xi_i \in [x_{i-1},x_i]$ . This second definition of the Stratonovich integral seems to be inspired similarly: take $\xi_i$ to be the midpoints, $\varphi$ your Brownian motion, and $f$ comes from your stochastic process. In my reading, I've seen this definition used by: Bernt Øksendal in Stochastic Differential Equations: An Introduction with Applications (Amazon link) Dr. Peyam on YouTube (video link) Apparently, this arises in Steven Shreve's Stochastic Calculus for Finance (Amazon link) Lewis Smith on this webpage My Question: It does not seem obvious to me that these would be equivalent definitions. Moreover, I've several times seen on Math Stack Exchange (e.g. here ) the claim that $(1)$ is the ""correct"" definition, though seeing it used elsewhere (e.g. this Math Overflow post) no one objects (openly) to $(2)$ . Hence, I'm seeking a proper, definitive answer, because I am very confused: Which is ""correct"" to call the Stratonovich integral? Is it simply a matter of preference? Is there a particular reason to prefer one over the other if there is no definitive answer? Do any results for one definition break under the other? (Such as: does the conversion to an Itô integral break? What about properties like the chain rule?) ...or am I just totally missing something here?","Notations: Herein: denotes a standard Brownian motion, with . denotes a partition of the interval , with norm defined in the Riemannian sense. . . denotes a Stratonovich-integrable process, in whatever sense that is needed at the time. denotes the Stratonovich integral. The Conflicting Definitions: There are two conflicting definitions for the Stratonovich integral, which to my understanding are stated below: The First Definition: Definition seems to be motivated by averaging over each interval induced by . In fact we could have a ""more general"" integral by considering, for , where Itô integration arises from , as an example, and Stratonovich (in the sense of ) under . In my reading, I've seen this used by The Wikipedia article on Stratonovich integrals (link) Apparently this is used in Ioannis Karatzas & Steven Shreve's Brownian Motion and Stochastic Calculus (Amazon link) The Encyclopedia of Math website (link) An article by Jonathan Mattingly on The Probability Workbook (link) The Second Definition: Definition seems to be inspired simply by the Riemann-Stieltjes formulation for deterministic functions: (for defined similarly as for ). In this case, . This second definition of the Stratonovich integral seems to be inspired similarly: take to be the midpoints, your Brownian motion, and comes from your stochastic process. In my reading, I've seen this definition used by: Bernt Øksendal in Stochastic Differential Equations: An Introduction with Applications (Amazon link) Dr. Peyam on YouTube (video link) Apparently, this arises in Steven Shreve's Stochastic Calculus for Finance (Amazon link) Lewis Smith on this webpage My Question: It does not seem obvious to me that these would be equivalent definitions. Moreover, I've several times seen on Math Stack Exchange (e.g. here ) the claim that is the ""correct"" definition, though seeing it used elsewhere (e.g. this Math Overflow post) no one objects (openly) to . Hence, I'm seeking a proper, definitive answer, because I am very confused: Which is ""correct"" to call the Stratonovich integral? Is it simply a matter of preference? Is there a particular reason to prefer one over the other if there is no definitive answer? Do any results for one definition break under the other? (Such as: does the conversion to an Itô integral break? What about properties like the chain rule?) ...or am I just totally missing something here?","\mathcal{B} := \{B(t)\}_{t \ge 0} B(0) = 0 P := \{x_i\}_{i=0}^n [0,t] \Delta B_i := B(x_i) - B(x_{i-1}) \Delta x_i := x_i - x_{i-1} \mathcal{X} := \{X(t)\}_{t \ge 0} \int_0^t X(s) \circ \mathrm{d} B(s) \begin{align*}
\int_0^t X(s) \circ \mathrm{d}B(s) &:= \lim_{\|P\| \to 0} \sum_{i=1}^n \frac{X(x_i) + X(x_{i-1})}{2} \Delta B_i \tag{1} \\
\int_0^t X(s) \circ \mathrm{d}B(s) &:= \lim_{\|P\| \to 0} \sum_{i=1}^n X \left( \frac{x_i + x_{i-1}}{2} \right) \Delta B_i \tag{2}
\end{align*} (1) X(t) P \lambda \in [0,1] \lim_{\|P\| \to 0} \sum_{i=1}^n \Big( (1-\lambda) X(x_i) + \lambda X(x_{i-1}) \Big)\Delta B_i \tag{1'} \lambda = 0 (1) \lambda=1/2 (2) \int_0^t f(x) \, \mathrm{d} \varphi(x) = \lim_{\|P\| \to 0} \sum_{i=1}^n f(\xi_i) \Delta \varphi_i \tag{2'} \Delta \varphi_i \Delta B_i \xi_i \in [x_{i-1},x_i] \xi_i \varphi f (1) (2)","['probability', 'stochastic-processes', 'stochastic-calculus', 'brownian-motion', 'stochastic-integrals']"
3,"Is ""fattening"" countable sets a good way to compare their relative density within an uncountable set?","Is ""fattening"" countable sets a good way to compare their relative density within an uncountable set?",,"In a recent conversation, someone posed the following argument: The cardinality of the natural numbers and the rational numbers is the same, since they're both countable. So the probability of randomly selecting a natural number from the rational numbers is the same as selecting a non-natural number. This is obviously false for any finite interval (there are a finite number of natural numbers but an infinite number of rational numbers in that interval, after all), but it wasn't immediately clear to me how to properly extend to the entire real line. Cardinality is, of course, not a good way to think about probability on infinite sets, and ordinarily I would go to measure theory as the way to compare the sets' relative sizes (where, for the improper analogue of a uniform distribution, relative size is proportional to relative probability of selection). But the problem is that both sets are countable, and therefore both have measure zero using the usual measure on the real line. So I tried constructing something like a measure on the rationals, but a quick search of the literature suggested that such a thing wasn't possible, or at least wasn't likely to be at all well-behaved if it was. So, the solution I came upon was the following procedure: for any countable set $X$ , construct the ""fat"" version of $X$ , which we will call $X_d$ , by replacing each element of $x$ with an open* ball of some (small) radius $d$ , centered at $x$ ; then, $X_d$ is the union of all such open balls. In other words, we define: $$X_d=\bigcup_{x\in X}B(x,d)$$ where $B(x,d)$ is the open ball centered at $x$ of radius $d$ . This allows us to measure-theoretically compare the densities of countable subsets of an uncountable set. The set $\mathbb{Z}_d$ , or indeed the set $\mathbb{N}_d$ , has gaps for all $d<1$ . On the other hand, since the rationals are dense in the reals, we have that $\mathbb{Q}_d=\mathbb{R}$ for any $d$ . So the ratio of the sizes of $\mathbb{Z}_d$ and $\mathbb{Q}_d$ is roughly $d$ (""roughly"" because you could choose endpoints within a distance $d$ of an integer), regardless of the size of the interval. Sending $d$ to zero essentially recovers the original sets, along with the result that you will randomly select an integer from among the rationals with probability zero (thus, the same result holds for the natural numbers). Is this a reasonable way to get around the problems inherent in working with probability on the rationals? More generally, is it a reasonable way to compare the relative densities of countable subsets of uncountable sets? *As far as I can tell, the choice of open or closed ball doesn't matter for this procedure; I could be wrong on this, though.","In a recent conversation, someone posed the following argument: The cardinality of the natural numbers and the rational numbers is the same, since they're both countable. So the probability of randomly selecting a natural number from the rational numbers is the same as selecting a non-natural number. This is obviously false for any finite interval (there are a finite number of natural numbers but an infinite number of rational numbers in that interval, after all), but it wasn't immediately clear to me how to properly extend to the entire real line. Cardinality is, of course, not a good way to think about probability on infinite sets, and ordinarily I would go to measure theory as the way to compare the sets' relative sizes (where, for the improper analogue of a uniform distribution, relative size is proportional to relative probability of selection). But the problem is that both sets are countable, and therefore both have measure zero using the usual measure on the real line. So I tried constructing something like a measure on the rationals, but a quick search of the literature suggested that such a thing wasn't possible, or at least wasn't likely to be at all well-behaved if it was. So, the solution I came upon was the following procedure: for any countable set , construct the ""fat"" version of , which we will call , by replacing each element of with an open* ball of some (small) radius , centered at ; then, is the union of all such open balls. In other words, we define: where is the open ball centered at of radius . This allows us to measure-theoretically compare the densities of countable subsets of an uncountable set. The set , or indeed the set , has gaps for all . On the other hand, since the rationals are dense in the reals, we have that for any . So the ratio of the sizes of and is roughly (""roughly"" because you could choose endpoints within a distance of an integer), regardless of the size of the interval. Sending to zero essentially recovers the original sets, along with the result that you will randomly select an integer from among the rationals with probability zero (thus, the same result holds for the natural numbers). Is this a reasonable way to get around the problems inherent in working with probability on the rationals? More generally, is it a reasonable way to compare the relative densities of countable subsets of uncountable sets? *As far as I can tell, the choice of open or closed ball doesn't matter for this procedure; I could be wrong on this, though.","X X X_d x d x X_d X_d=\bigcup_{x\in X}B(x,d) B(x,d) x d \mathbb{Z}_d \mathbb{N}_d d<1 \mathbb{Q}_d=\mathbb{R} d \mathbb{Z}_d \mathbb{Q}_d d d d","['probability', 'measure-theory']"
4,Karhunen-Loeve expansion of non-centered processes,Karhunen-Loeve expansion of non-centered processes,,"The typical form of Karhunen-Loeve expansion is on a detrended stochastic process. E.g., let $Y(t)$ be a stochastic process on $[0,T]$ , and let $X(t) = Y(t)-\mathbb{E}Y(t)$ with a continuous covariance function $R_X(s,t)$ , then there exists a series of orthonormal functions $\phi_k(t)$ on $[0,T]$ and independent zero-mean and normalized random variables $Z_k$ such that $$ X(t) = \sum_{k=1}^{\infty} Z_k \sqrt{\lambda_k} \phi_k(t) $$ where $\lambda_k$ and $\phi_k(t)$ are the solutions of the following eigensystems equation: $$ \int_0^T R_X(s,t)\phi_k(t)dt=\lambda_k\phi_k(s) $$ My question is, if we do not subtract the mean from the process, and just focus on the raw autocorrelation function $R_Y(s,t)$ , as $R_Y(s,t)$ is also positive definite symmetric functions in $s,t$ , it has a spectral decomposition (Mercer's theorem) $$ R_Y(s,t) = \sum_k \mu_k \psi_k(s)\psi_k(t) $$ Can we expand the original process $Y(t)$ in $\psi(t)$ ? And does this decomposition enjoy some similar properties of the original K-L decomposition, such as the optimal compaction of energies of the signal in the eigenfunctions? $$ Y(t)=\sum_k \tilde{Z}_k \sqrt{\mu_k} \psi_k(t) $$ The empirical reason is that sometimes we are interested in the information contained in the mean as well, not only in the fluctuation around the mean. While the original K-L expansion optimally compacts the total variance into the first few eigenfunctions $\phi_k(t)$ , the direct decomposition of $Y(t)$ may optimally compact the total fluctuation around $0$ , i.e., the raw energy of the signal: $\mathbb{E}\int_0^T |Y(t)|^2dt$ into $\psi_k(t)$ . Has it been shown to be true? And if true, is the result trivial in the sense that $\psi_k(t)$ and $\phi_k(t)$ are connected in some simple way?","The typical form of Karhunen-Loeve expansion is on a detrended stochastic process. E.g., let be a stochastic process on , and let with a continuous covariance function , then there exists a series of orthonormal functions on and independent zero-mean and normalized random variables such that where and are the solutions of the following eigensystems equation: My question is, if we do not subtract the mean from the process, and just focus on the raw autocorrelation function , as is also positive definite symmetric functions in , it has a spectral decomposition (Mercer's theorem) Can we expand the original process in ? And does this decomposition enjoy some similar properties of the original K-L decomposition, such as the optimal compaction of energies of the signal in the eigenfunctions? The empirical reason is that sometimes we are interested in the information contained in the mean as well, not only in the fluctuation around the mean. While the original K-L expansion optimally compacts the total variance into the first few eigenfunctions , the direct decomposition of may optimally compact the total fluctuation around , i.e., the raw energy of the signal: into . Has it been shown to be true? And if true, is the result trivial in the sense that and are connected in some simple way?","Y(t) [0,T] X(t) = Y(t)-\mathbb{E}Y(t) R_X(s,t) \phi_k(t) [0,T] Z_k 
X(t) = \sum_{k=1}^{\infty} Z_k \sqrt{\lambda_k} \phi_k(t)
 \lambda_k \phi_k(t) 
\int_0^T R_X(s,t)\phi_k(t)dt=\lambda_k\phi_k(s)
 R_Y(s,t) R_Y(s,t) s,t 
R_Y(s,t) = \sum_k \mu_k \psi_k(s)\psi_k(t)
 Y(t) \psi(t) 
Y(t)=\sum_k \tilde{Z}_k \sqrt{\mu_k} \psi_k(t)
 \phi_k(t) Y(t) 0 \mathbb{E}\int_0^T |Y(t)|^2dt \psi_k(t) \psi_k(t) \phi_k(t)","['probability', 'stochastic-processes', 'spectral-theory', 'signal-processing']"
5,Finding the right conditions for a sequence to satisfy convergence in distribution then convergence in probability then convergence almost surely,Finding the right conditions for a sequence to satisfy convergence in distribution then convergence in probability then convergence almost surely,,"I couldn't solve this exercice so I could use some help. It goes like this : Let $(X_n)_{n \in\Bbb N^*}$ be a sequence of real independent random variable defined in some probability space. Let $F_{X_n}$ be the cumulutive distribution function such that $$F_{X_n}=\begin{cases} 1 & \quad   x > 1\\ a_n+(1-a_n)x^n & \quad x \in[0,1] \\  0 & \quad  x <0 \end{cases}$$ $a_n\in [0,1] $ Question : Find the right conditions for $a_n$ to have : 1/ Convergence in distribution. 2/ Convergence in probability. 3/Almost sure convergence. ( note that the questions are seperated so it needs to be solved one at a time ).",I couldn't solve this exercice so I could use some help. It goes like this : Let be a sequence of real independent random variable defined in some probability space. Let be the cumulutive distribution function such that Question : Find the right conditions for to have : 1/ Convergence in distribution. 2/ Convergence in probability. 3/Almost sure convergence. ( note that the questions are seperated so it needs to be solved one at a time ).,"(X_n)_{n \in\Bbb N^*} F_{X_n} F_{X_n}=\begin{cases}
1 & \quad   x > 1\\
a_n+(1-a_n)x^n & \quad x \in[0,1] \\ 
0 & \quad  x <0
\end{cases} a_n\in [0,1]  a_n","['probability', 'sequences-and-series', 'probability-theory', 'probability-distributions', 'convergence-divergence']"
6,What is the probability that an event will happen when the probability decreases exponentially?,What is the probability that an event will happen when the probability decreases exponentially?,,"So I am just a middle student who started studying probability in my stats class and I see the questions on this site are little advanced so I don't hope this one is too basic. Anyways lets say that the probability of an event happening was some number(like 1%), and each time a trial is run the of the event happening decreases by half(so 1% probability for the first trial, .5% probability for the second, .25% probability, and so on). What is the probability that the event will happen after 1 trial, 10 trials, 100 trials, and an infinite amount of trials?","So I am just a middle student who started studying probability in my stats class and I see the questions on this site are little advanced so I don't hope this one is too basic. Anyways lets say that the probability of an event happening was some number(like 1%), and each time a trial is run the of the event happening decreases by half(so 1% probability for the first trial, .5% probability for the second, .25% probability, and so on). What is the probability that the event will happen after 1 trial, 10 trials, 100 trials, and an infinite amount of trials?",,"['probability', 'infinity']"
7,Three way duel: which gun to choose?,Three way duel: which gun to choose?,,"Three shooters compete in three way duel game. Game 1 Rules: Shooters take turns to shoot. If it's your turn, you have to choose one other person to shoot, and cannot pass your turn or shoot in air, etc.. For the sake of fairness, shooters draw lots to decide who shoots first, second and third. They then fire in this order repeatedly until only one survives. Everyone is rational and calculates to maximize his survival probability. Before the game starts, there're three guns available to choose from, whose hitting probabilities are not revealed, but are known to have been drawn from $U[0,1]$ independently. The gun with the highest hitting probability is labeled ""1"", the one with the 2nd highest is labeled ""2"", and worst one is labeled ""3"". Shooters understand what the labels mean. After each chose his gun, the guns' exact hitting probabilities $g_1,g_2,g_3$ are reveal to all, and the game starts (aka Players draw lots and start shooting). Question: If you're the first one to choose a gun, which one should you choose to maximize your surviving probability? Which gun gives you the least surviving probability? Game 2 Rules: Each turn, a fair dice is flipped to decide who should shoot in this turn. If it's your turn, you have to choose one other person to shoot, and cannot pass your turn or shoot in air, etc.. Step 1 and 2 are repeated until only one survives. Everyone is rational and calculates to maximize his survival probability. Guns have to be chosen before the game starts as in Game 1. Question: If you're the first one to choose a gun, which one should you choose to maximize your surviving probability? Which gun gives you the least surviving probability? Game 0 This is an update. It just occurred to me that allowing the shooter with the worst gun to hold fire in Rule 2 Game 1 will not add much to the computation complexity. This is also more consistent with the spirit of the classical truel game, and is perhaps more reasonable. So while we're at game 1, might as well think about this case. Rules: Same as game 1 but with rule 2 changed, so that the shooter with the worst gun is allowed to hold fire/pass turns. Analysis for game 0: Holding fire can only happen when all 3 shooters are alive. If he should choose to hold fire, the worst shooter (call him #3) is essentially waiting to duel with the winner of the duel between #1 and #2. This gives $$P_{hold}(3,3\vert 3,2,1)=P(2,2\vert 2,1)P(3,3\vert 3,2)+P(1,2\vert 2,1)P(3,3\vert 3,1)$$ $$=\frac{g_2}{g_2+g_1-g_2g_1}\frac{g_3}{g_2+g_3-g_2g_3}+\frac{g_1(1-g_2)}{g_2+g_1-g_2g_1}\frac{g_3}{g_1+g_3-g_1g_3}$$ $$P_{hold}(3,3\vert 3,1,2)=P(1,1\vert 1,2)P(3,3\vert  3,1)+P(2,1\vert 1,2)P(3,3\vert 3,2)$$ $$=\frac{g_1}{g_2+g_1-g_2g_1}\frac{g_3}{g_1+g_3-g_1g_3}+\frac{g_2(1-g_1)}{g_2+g_1-g_2g_1}\frac{g_3}{g_2+g_3-g_2g_3}$$ where the notation $P(1,2\vert 2,1)$ means #1's survival probability when its #2's turn to shoot, given the current set of shooters are ordered in $\vert 2,1)$ , for instance.  To decide whether to hold or not, #3 only needs to compare $P_{hold}(3,3\vert 3,1,2)$ with $P_{shoot}(3,3\vert 3,1,2)$ , and $P_{hold}(3,3\vert 3,2,1)$ with $P_{shoot}(3,3\vert 3,2,1)$ , where $P_{shoot}$ is computed by game 1. This is the only additional computation you need to perform for game 0. Some motivations for formulating the games as such: In simpler versions of the classic three way duel game, hitting probabilities are given and you're asked to solve for surviving probabilities for the players. In the above games that goal is in some sense reversed, because I want to know how important is your accuracy (or hit probability) in a somewhat fair setting. Conclusions drawn from just one set of hit probabilities and one set of firing order don't tell much, because they are highly sensitive to those parameters. So you can think of the games as a kind of framework to answering the big picture question: overall, does a better shooter generally have higher survival rate? Unlike solving for instances of the game, questions like this are meta questions for the game, and actually give you more insights about the nature and structure of the game itself. (Meta questions are generally more interesting and challenging, I think. Think of the halting problem as a meta question about algorithms and Godel's incompleteness Theorems as meta questions about arithmetics! I'd better stop before I'm carried too far away by this :-p). The same question can even be asked for cases more than 3 players. For more than 3 players a closed form solution may be impractical to obtain, although simulations could always help. For game 1 for example, Simulation for 4 shooters with guns' hit probabilities $g_1\gt g_2\gt g_3\gt g_4$ randomly chosen shows that $P_{g_3}\gt P_{g_1}\gt P_{g_4}\gt P_{g_2}$ . For 5 shooters, $P_{g_4}\gt P_{g_3}\gt P_{g_1}\gt P_{g_5}\gt P_{g_2}$ . Not intuitive at all. Effective simulation of 6 shooters would take hours. So it seems small teens may be the most you can manage (if you have a super computer at hand). This means you can't go meta on the meta question again. Questions like ""If many shooters play game 1, choosing top notch guns never give you highest survival probability"" just rest safely beyond the ceiling of your computation power.","Three shooters compete in three way duel game. Game 1 Rules: Shooters take turns to shoot. If it's your turn, you have to choose one other person to shoot, and cannot pass your turn or shoot in air, etc.. For the sake of fairness, shooters draw lots to decide who shoots first, second and third. They then fire in this order repeatedly until only one survives. Everyone is rational and calculates to maximize his survival probability. Before the game starts, there're three guns available to choose from, whose hitting probabilities are not revealed, but are known to have been drawn from independently. The gun with the highest hitting probability is labeled ""1"", the one with the 2nd highest is labeled ""2"", and worst one is labeled ""3"". Shooters understand what the labels mean. After each chose his gun, the guns' exact hitting probabilities are reveal to all, and the game starts (aka Players draw lots and start shooting). Question: If you're the first one to choose a gun, which one should you choose to maximize your surviving probability? Which gun gives you the least surviving probability? Game 2 Rules: Each turn, a fair dice is flipped to decide who should shoot in this turn. If it's your turn, you have to choose one other person to shoot, and cannot pass your turn or shoot in air, etc.. Step 1 and 2 are repeated until only one survives. Everyone is rational and calculates to maximize his survival probability. Guns have to be chosen before the game starts as in Game 1. Question: If you're the first one to choose a gun, which one should you choose to maximize your surviving probability? Which gun gives you the least surviving probability? Game 0 This is an update. It just occurred to me that allowing the shooter with the worst gun to hold fire in Rule 2 Game 1 will not add much to the computation complexity. This is also more consistent with the spirit of the classical truel game, and is perhaps more reasonable. So while we're at game 1, might as well think about this case. Rules: Same as game 1 but with rule 2 changed, so that the shooter with the worst gun is allowed to hold fire/pass turns. Analysis for game 0: Holding fire can only happen when all 3 shooters are alive. If he should choose to hold fire, the worst shooter (call him #3) is essentially waiting to duel with the winner of the duel between #1 and #2. This gives where the notation means #1's survival probability when its #2's turn to shoot, given the current set of shooters are ordered in , for instance.  To decide whether to hold or not, #3 only needs to compare with , and with , where is computed by game 1. This is the only additional computation you need to perform for game 0. Some motivations for formulating the games as such: In simpler versions of the classic three way duel game, hitting probabilities are given and you're asked to solve for surviving probabilities for the players. In the above games that goal is in some sense reversed, because I want to know how important is your accuracy (or hit probability) in a somewhat fair setting. Conclusions drawn from just one set of hit probabilities and one set of firing order don't tell much, because they are highly sensitive to those parameters. So you can think of the games as a kind of framework to answering the big picture question: overall, does a better shooter generally have higher survival rate? Unlike solving for instances of the game, questions like this are meta questions for the game, and actually give you more insights about the nature and structure of the game itself. (Meta questions are generally more interesting and challenging, I think. Think of the halting problem as a meta question about algorithms and Godel's incompleteness Theorems as meta questions about arithmetics! I'd better stop before I'm carried too far away by this :-p). The same question can even be asked for cases more than 3 players. For more than 3 players a closed form solution may be impractical to obtain, although simulations could always help. For game 1 for example, Simulation for 4 shooters with guns' hit probabilities randomly chosen shows that . For 5 shooters, . Not intuitive at all. Effective simulation of 6 shooters would take hours. So it seems small teens may be the most you can manage (if you have a super computer at hand). This means you can't go meta on the meta question again. Questions like ""If many shooters play game 1, choosing top notch guns never give you highest survival probability"" just rest safely beyond the ceiling of your computation power.","U[0,1] g_1,g_2,g_3 P_{hold}(3,3\vert 3,2,1)=P(2,2\vert 2,1)P(3,3\vert 3,2)+P(1,2\vert 2,1)P(3,3\vert 3,1) =\frac{g_2}{g_2+g_1-g_2g_1}\frac{g_3}{g_2+g_3-g_2g_3}+\frac{g_1(1-g_2)}{g_2+g_1-g_2g_1}\frac{g_3}{g_1+g_3-g_1g_3} P_{hold}(3,3\vert 3,1,2)=P(1,1\vert 1,2)P(3,3\vert
 3,1)+P(2,1\vert 1,2)P(3,3\vert 3,2) =\frac{g_1}{g_2+g_1-g_2g_1}\frac{g_3}{g_1+g_3-g_1g_3}+\frac{g_2(1-g_1)}{g_2+g_1-g_2g_1}\frac{g_3}{g_2+g_3-g_2g_3} P(1,2\vert 2,1) \vert 2,1) P_{hold}(3,3\vert 3,1,2) P_{shoot}(3,3\vert 3,1,2) P_{hold}(3,3\vert 3,2,1) P_{shoot}(3,3\vert 3,2,1) P_{shoot} g_1\gt g_2\gt g_3\gt g_4 P_{g_3}\gt P_{g_1}\gt P_{g_4}\gt P_{g_2} P_{g_4}\gt P_{g_3}\gt P_{g_1}\gt P_{g_5}\gt P_{g_2}","['probability', 'integration', 'algorithms', 'recreational-mathematics', 'game-theory']"
8,Law of brownian hitting time uniquely determined by the barrier?,Law of brownian hitting time uniquely determined by the barrier?,,"We know that the law of $$\tau_b := \inf\{ t >0 : B_t \geq b\} ,$$ where $b>0$ and $B$ is a standard Brownian motion, is given by a certain computable density, which is uniquely determined  by $b$ . If we replace $b$ by a continuous function $b: [0,\infty) \to [0,\infty]$ and redefine $\tau_b$ as $$\tau_b := \inf\{ t >0 : B_t \geq b(t) \}$$ I would guess that $b$ also should uniquely determine the law  of $\tau_b$ . Edit: What I mean with uniquely determination is that I ask whether the implication $b_1 \neq b_2 \Rightarrow$ Law $(\tau_{b_1})$ $\neq$ Law $(\tau_{b_2})$ is true. So that ( $b$ $\mapsto$ law  of $\tau_b$ ) is injective I am not asking for a solution, I want to think about it by myself, but I don't know how to approach. Any hint, comment, idea or reference is appreciated. Edit2: The question from the first edit is called the inverse first-passage time problem for Brownian motion . These papers [ 1 ] [ 2 ] show indirectly that, if $b_1$ and $b_2$ are lower semicontinuous functions with $$\exists 0< t \leq \max (T^{b_1},T^{b_2}): b_1(t) \neq b_2 (t), $$ where $$T^{b_i} := \inf\{t> 0 : b_i(t) = -\infty \},$$ then Law $(\tau_{b_1})$ $\neq$ Law $(\tau_{b_2})$ .","We know that the law of where and is a standard Brownian motion, is given by a certain computable density, which is uniquely determined  by . If we replace by a continuous function and redefine as I would guess that also should uniquely determine the law  of . Edit: What I mean with uniquely determination is that I ask whether the implication Law Law is true. So that ( law  of ) is injective I am not asking for a solution, I want to think about it by myself, but I don't know how to approach. Any hint, comment, idea or reference is appreciated. Edit2: The question from the first edit is called the inverse first-passage time problem for Brownian motion . These papers [ 1 ] [ 2 ] show indirectly that, if and are lower semicontinuous functions with where then Law Law .","\tau_b := \inf\{ t >0 : B_t \geq b\} , b>0 B b b b: [0,\infty) \to [0,\infty] \tau_b \tau_b := \inf\{ t >0 : B_t \geq b(t) \} b \tau_b b_1 \neq b_2 \Rightarrow (\tau_{b_1}) \neq (\tau_{b_2}) b \mapsto \tau_b b_1 b_2 \exists 0< t \leq \max (T^{b_1},T^{b_2}): b_1(t) \neq b_2 (t),  T^{b_i} := \inf\{t> 0 : b_i(t) = -\infty \}, (\tau_{b_1}) \neq (\tau_{b_2})","['probability', 'probability-theory', 'brownian-motion']"
9,An application of Kolmogorov $0$-$1$ law,An application of Kolmogorov - law,0 1,"I need to approve or to disapprove the following statement : if $(X_n)_{n \in \mathbb{N}}$ is a sequence of independent random variables and identically distributed, and $(u_n)_{n \in \mathbb{N}}$ is a sequence of real numbers such that $$\mathbb{P}(\limsup_n|\frac{1}{n}\sum_{k=1}^nX_k-u_n|<+\infty)>0$$ then $\mathbb{P}(\limsup_n\frac{1}{n}|X_{2n+1}-X_{2n}|<+\infty)=1$ I know that by kolmogorov $0$ - $1$ law (since $(\frac{1}{n}|X_{2n+1}-X_{2n}|)_{n \in \mathbb{N}}$ is a sequence of independent random variable), we have $\mathbb{P}(\limsup_n\frac{1}{n}|X_{2n+1}-X_{2n}|<+\infty)=0 \ \ or \ \ 1,$ So which value does it take?","I need to approve or to disapprove the following statement : if is a sequence of independent random variables and identically distributed, and is a sequence of real numbers such that then I know that by kolmogorov - law (since is a sequence of independent random variable), we have So which value does it take?","(X_n)_{n \in \mathbb{N}} (u_n)_{n \in \mathbb{N}} \mathbb{P}(\limsup_n|\frac{1}{n}\sum_{k=1}^nX_k-u_n|<+\infty)>0 \mathbb{P}(\limsup_n\frac{1}{n}|X_{2n+1}-X_{2n}|<+\infty)=1 0 1 (\frac{1}{n}|X_{2n+1}-X_{2n}|)_{n \in \mathbb{N}} \mathbb{P}(\limsup_n\frac{1}{n}|X_{2n+1}-X_{2n}|<+\infty)=0 \ \ or \ \ 1,","['probability', 'probability-theory', 'measure-theory', 'borel-cantelli-lemmas']"
10,A coding theory/probability puzzle,A coding theory/probability puzzle,,"I thought of the following problem and I am stuck in solving it. Suppose there is a deck of 4 cards with 2 red and 2 blue. I pick 2 cards at random and choose 1 and show the other to my friend. With what probability can my friend find the color of my card if we have agreed on a good strategy in advance? If my friend always guesses the color red, we only fail in this game if I get 2 blue cards. That happens with probability 1/4 and it is the best I can achieve in this case. However, if the cards are numbered we can do even better, i.e. there is red card 1 and red card 2, blue card 1 and blue card 2. In this case, we can agree that my friend chooses the color of the card I gave him if the number is 1 and flips the color if it is 2. You can check that the only way we can fail is if I get both the red and the blue card of 1. (If I get both cards of the same color I show him the number 1 card. If I get two cards of different colors I show him the number 2 card and we win.) Since the probability of drawing two cards with the number 1 is 1/6, having numbers on the cards clearly helps. My question is what happens when there are $N$ cards of $N$ colors ( $N^2$ in total) and I draw $N$ cards, choose 1 and reveal $N-1$ cards to my friend ( in a random order , i.e. the order cannot encode information). What is the strategy that maximizes our probability of winning? How does this differ if cards are numbered or if they are not? I am interested both in optimal strategies for small $N$ , or with asymptotic bounds for large $N$ in both the numbered and unnumbered cases. Could it be that the probability in the numbered case goes to 1 and the unnumbered case is small? This would be very unintuitive!","I thought of the following problem and I am stuck in solving it. Suppose there is a deck of 4 cards with 2 red and 2 blue. I pick 2 cards at random and choose 1 and show the other to my friend. With what probability can my friend find the color of my card if we have agreed on a good strategy in advance? If my friend always guesses the color red, we only fail in this game if I get 2 blue cards. That happens with probability 1/4 and it is the best I can achieve in this case. However, if the cards are numbered we can do even better, i.e. there is red card 1 and red card 2, blue card 1 and blue card 2. In this case, we can agree that my friend chooses the color of the card I gave him if the number is 1 and flips the color if it is 2. You can check that the only way we can fail is if I get both the red and the blue card of 1. (If I get both cards of the same color I show him the number 1 card. If I get two cards of different colors I show him the number 2 card and we win.) Since the probability of drawing two cards with the number 1 is 1/6, having numbers on the cards clearly helps. My question is what happens when there are cards of colors ( in total) and I draw cards, choose 1 and reveal cards to my friend ( in a random order , i.e. the order cannot encode information). What is the strategy that maximizes our probability of winning? How does this differ if cards are numbered or if they are not? I am interested both in optimal strategies for small , or with asymptotic bounds for large in both the numbered and unnumbered cases. Could it be that the probability in the numbered case goes to 1 and the unnumbered case is small? This would be very unintuitive!",N N N^2 N N-1 N N,"['probability', 'puzzle', 'coding-theory']"
11,Prove that $P(A \cap B ) \geq 1 - P(\bar{A}) - P(\bar{B})$,Prove that,P(A \cap B ) \geq 1 - P(\bar{A}) - P(\bar{B}),"Prove that $P(A \cap B ) \geq 1 - P(\bar{A}) - P(\bar{B})$ This is what I got: So I know that $P(A \cup B) = P(A) + P(B) - P(A \cap B)$ Rearranging for $P(A \cap B)$ $P(A \cap B) = P(A) + P(B) - P(A \cup B)$ Substitute $P(A) = 1-P(\bar{A})$ and $P(B) = 1-P(\bar{B})$ $P(A \cap B) = 1 - P(\bar{A}) - P(\bar{B}) + 1 - P(A \cup B)$ Substitute $P(\overline{A \cup B}) = 1 - P(A \cup B)$ $P(A \cap B) = 1 - P(\bar{A}) - P(\bar{B}) + P(\overline{A \cup B})$ So $P(A \cap B) \geq 1 - P(\bar{A}) - P(\bar{B}) \enspace\enspace\enspace \text{ Since } P(\overline{A \cup B})\leq 1$ I'm not sure if my proof is correct or not and wanted to ask for some verification and correction if i'm wrong. Sorry if the structure is messy, I'm not that familiar with latex.","Prove that This is what I got: So I know that Rearranging for Substitute and Substitute So I'm not sure if my proof is correct or not and wanted to ask for some verification and correction if i'm wrong. Sorry if the structure is messy, I'm not that familiar with latex.",P(A \cap B ) \geq 1 - P(\bar{A}) - P(\bar{B}) P(A \cup B) = P(A) + P(B) - P(A \cap B) P(A \cap B) P(A \cap B) = P(A) + P(B) - P(A \cup B) P(A) = 1-P(\bar{A}) P(B) = 1-P(\bar{B}) P(A \cap B) = 1 - P(\bar{A}) - P(\bar{B}) + 1 - P(A \cup B) P(\overline{A \cup B}) = 1 - P(A \cup B) P(A \cap B) = 1 - P(\bar{A}) - P(\bar{B}) + P(\overline{A \cup B}) P(A \cap B) \geq 1 - P(\bar{A}) - P(\bar{B}) \enspace\enspace\enspace \text{ Since } P(\overline{A \cup B})\leq 1,"['probability', 'proof-verification']"
12,3 coins - 1 biased,3 coins - 1 biased,,"We have 3 coins, of which 2 are fair and the 3rd is biased (gives heads with probability 4/7). Two friends throw, in turn, all coins together, one time each, and the winner is the one who gets more heads. What is the probability of a draw? My first attempt: In order to have a draw, both flips must give the same output: Either TTT or HTT or THT or TTH or THH or HTH or HHT or HHH, where the first two letters correspond to the fair coins and the 3rd letter to the biased. So we have 8 possible outputs for EACH draw and we calculate the individual probability for each of them: 1st: 1/2*1/2*3/7=3/28 2nd, 3rd, 7th: same All the rest: 4/28 = 1/7.  All of them must add to 28/28, which indeed is OK. But then, in order to have a draw in both flips, we must have: TTT with TTT (zero heads) or HTT or THT or TTH with either of  HTT or THT or TTH or  THH or HTH or HHT with either of THH or HTH or HHT or HHH with HHH. Probability for first is 3/28 * 3/28 Same also for the last one, 4/28 * 4/28 I am a bit confused as regards the other two cases and also how to calculate the total probability for a draw. (Also, I am not sure for what I have done so far!) I am not at all familiar with probabilities and combinatorics :(","We have 3 coins, of which 2 are fair and the 3rd is biased (gives heads with probability 4/7). Two friends throw, in turn, all coins together, one time each, and the winner is the one who gets more heads. What is the probability of a draw? My first attempt: In order to have a draw, both flips must give the same output: Either TTT or HTT or THT or TTH or THH or HTH or HHT or HHH, where the first two letters correspond to the fair coins and the 3rd letter to the biased. So we have 8 possible outputs for EACH draw and we calculate the individual probability for each of them: 1st: 1/2*1/2*3/7=3/28 2nd, 3rd, 7th: same All the rest: 4/28 = 1/7.  All of them must add to 28/28, which indeed is OK. But then, in order to have a draw in both flips, we must have: TTT with TTT (zero heads) or HTT or THT or TTH with either of  HTT or THT or TTH or  THH or HTH or HHT with either of THH or HTH or HHT or HHH with HHH. Probability for first is 3/28 * 3/28 Same also for the last one, 4/28 * 4/28 I am a bit confused as regards the other two cases and also how to calculate the total probability for a draw. (Also, I am not sure for what I have done so far!) I am not at all familiar with probabilities and combinatorics :(",,['probability']
13,"The ""expected value"" in a heuristic argument about the Collatz conjecture","The ""expected value"" in a heuristic argument about the Collatz conjecture",,"In a popular heuristic argument in favor of the Collatz conjecture , one calculates a kind of ""geometric expected value"" for the ratio $C(x)/x$, where $x$ is odd, and \begin{align*} C(x) := \frac{3x+1}{2^{\upsilon_2 (3x+1) }}  \end{align*} is next odd number after $x$ in the sequence obtained by repeatedly applying the Collatz function \begin{align*} T(n) := \begin{cases} n/2 &\text{if $n$ is even,}\\ 3n+1 &\text{if $n$ is odd} \end{cases} \end{align*} to $x$. The argument is that the quantity \begin{align*} \frac{C(x)}{x} = \frac{3+\frac{1}{x}}{2^{\upsilon_2 (3x+1) }} \approx \frac{3}{2^{\upsilon_2 (3x+1)}} \end{align*} will equal $3/2$ with probability $1/2$, will equal $3/4$ with probability $1/4$, and will - generally - equal $3/2^k$ with probability $1/2^k$, and so the ""expected value"" of $C(x)/x$ is calculated as the following infinite product, which converges to $3/4 < 1$: \begin{align*} \prod_{k=1}^\infty \left(\frac{3}{2^k}\right)^{\frac{1}{2^k}}. \end{align*} My question : Why don't we calculate the expected value in the ""usual"" (ie. arithmetic , as opposed to geometric ) way, ie. as \begin{align*} \mathbb{E}\left(\frac{C(x)}{x}\right) = \sum \hspace{0.1cm} \text{""outcome""} \cdot \text{""probability of this outcome""} = \sum_{k=1}^\infty \frac{3}{2^k} \cdot \frac{1}{2^k}? \end{align*} If we did this, the expected value would be different, namely equal to $1$.","In a popular heuristic argument in favor of the Collatz conjecture , one calculates a kind of ""geometric expected value"" for the ratio $C(x)/x$, where $x$ is odd, and \begin{align*} C(x) := \frac{3x+1}{2^{\upsilon_2 (3x+1) }}  \end{align*} is next odd number after $x$ in the sequence obtained by repeatedly applying the Collatz function \begin{align*} T(n) := \begin{cases} n/2 &\text{if $n$ is even,}\\ 3n+1 &\text{if $n$ is odd} \end{cases} \end{align*} to $x$. The argument is that the quantity \begin{align*} \frac{C(x)}{x} = \frac{3+\frac{1}{x}}{2^{\upsilon_2 (3x+1) }} \approx \frac{3}{2^{\upsilon_2 (3x+1)}} \end{align*} will equal $3/2$ with probability $1/2$, will equal $3/4$ with probability $1/4$, and will - generally - equal $3/2^k$ with probability $1/2^k$, and so the ""expected value"" of $C(x)/x$ is calculated as the following infinite product, which converges to $3/4 < 1$: \begin{align*} \prod_{k=1}^\infty \left(\frac{3}{2^k}\right)^{\frac{1}{2^k}}. \end{align*} My question : Why don't we calculate the expected value in the ""usual"" (ie. arithmetic , as opposed to geometric ) way, ie. as \begin{align*} \mathbb{E}\left(\frac{C(x)}{x}\right) = \sum \hspace{0.1cm} \text{""outcome""} \cdot \text{""probability of this outcome""} = \sum_{k=1}^\infty \frac{3}{2^k} \cdot \frac{1}{2^k}? \end{align*} If we did this, the expected value would be different, namely equal to $1$.",,"['probability', 'number-theory', 'collatz-conjecture']"
14,Probability that no two people sit next to each other,Probability that no two people sit next to each other,,"Assume there are 10 people sitting around a circular table for lunch and those same 10 people meet again during dinner. I am interested in the probability no one sits next to the same person (I interpret ""sitting next to"" as being on left or right of the person). I ran a simulation and after 1 million randomizations comparing the lunch seating to the dinner seating, I got exactly 1 scenario that occurred where this happened. Is there a rigourous way to see if my simulation is correct?","Assume there are 10 people sitting around a circular table for lunch and those same 10 people meet again during dinner. I am interested in the probability no one sits next to the same person (I interpret ""sitting next to"" as being on left or right of the person). I ran a simulation and after 1 million randomizations comparing the lunch seating to the dinner seating, I got exactly 1 scenario that occurred where this happened. Is there a rigourous way to see if my simulation is correct?",,"['probability', 'combinatorics']"
15,Discrete math probability biased coin,Discrete math probability biased coin,,"If a biased coin flips heads with probability $\frac{3}{7}$ and tails with probability $\frac{4}{7}$ is flipped $80$ times, what is the probability that heads is flipped $30$ times? I used binomial distribution so I get $$ {80 \choose 30}\left(\frac{3}{7}\right)^{30}\left(\frac{4}{7}\right)^{50}\\ =\frac{80!}{30!50!}\left(\frac{3}{7}\right)^{30}\left(\frac{4}{7}\right)^{50} $$ Is this right?","If a biased coin flips heads with probability $\frac{3}{7}$ and tails with probability $\frac{4}{7}$ is flipped $80$ times, what is the probability that heads is flipped $30$ times? I used binomial distribution so I get $$ {80 \choose 30}\left(\frac{3}{7}\right)^{30}\left(\frac{4}{7}\right)^{50}\\ =\frac{80!}{30!50!}\left(\frac{3}{7}\right)^{30}\left(\frac{4}{7}\right)^{50} $$ Is this right?",,"['probability', 'combinatorics', 'discrete-mathematics', 'combinations', 'binomial-distribution']"
16,What is $P$ of either Heads or Tails having a lead $\geq 10$ at some point during game of $300$ flips?,What is  of either Heads or Tails having a lead  at some point during game of  flips?,P \geq 10 300,"Question refers to $P$ of getting lead of at least $10$ at any point during a game, with game lasting only $300$ flips. I tried to apply the formula given in an answer to a similar question here $P(X_n≥ (n+10/2))$ but that works out to summing $300 + 10$, and dividing by $2$ which = $155$. Following from that previous answer, it would seem that the $P$ of a lead of $10$ or greater at some point in a $300$ flip Game would be only $.155$ ...and that does not fit with the results when I simply use a simulator to repeatedly sample games of $300$ flips and count the times that a lead of at least 10 appears. Is there something wrong in the way I am applying this formula? or is wrong for the question I am asking?","Question refers to $P$ of getting lead of at least $10$ at any point during a game, with game lasting only $300$ flips. I tried to apply the formula given in an answer to a similar question here $P(X_n≥ (n+10/2))$ but that works out to summing $300 + 10$, and dividing by $2$ which = $155$. Following from that previous answer, it would seem that the $P$ of a lead of $10$ or greater at some point in a $300$ flip Game would be only $.155$ ...and that does not fit with the results when I simply use a simulator to repeatedly sample games of $300$ flips and count the times that a lead of at least 10 appears. Is there something wrong in the way I am applying this formula? or is wrong for the question I am asking?",,['probability']
17,Real life birthday paradox.,Real life birthday paradox.,,"This question is inspired by the Birthday paradox. Suppose we have a sample space $S$ of $n$ elements. Is there a probability distribution $\mu$ on $S$ so that $$P(\text{you pick $k$ elements of $S$, according to $\mu$, without repeating}) < P(\text{you pick $k$ elements of $S$ uniformly, without repeating})$$ To avoid triviality assume $1 < k < n$. (I assume the answer is no, I tried checking by hand, but I got stuck). The reason I ask, is that I am going to teach the Birthdng Paradox in class on Friday, and, of course, I'm going to assume that a person's birthday is uniformly distributed throughout the year. This is empirically false, and I guess that the fact that there is a bias towards certain days increases the likelihood of a shared birthday. I don't want to claim this in class without proof though.","This question is inspired by the Birthday paradox. Suppose we have a sample space $S$ of $n$ elements. Is there a probability distribution $\mu$ on $S$ so that $$P(\text{you pick $k$ elements of $S$, according to $\mu$, without repeating}) < P(\text{you pick $k$ elements of $S$ uniformly, without repeating})$$ To avoid triviality assume $1 < k < n$. (I assume the answer is no, I tried checking by hand, but I got stuck). The reason I ask, is that I am going to teach the Birthdng Paradox in class on Friday, and, of course, I'm going to assume that a person's birthday is uniformly distributed throughout the year. This is empirically false, and I guess that the fact that there is a bias towards certain days increases the likelihood of a shared birthday. I don't want to claim this in class without proof though.",,"['probability', 'birthday']"
18,Conditional distribution of random variable X given itself,Conditional distribution of random variable X given itself,,"I'm stuck with something that might seem trivial but gives me headache. What is the distribution of $X|X$, i.e. the conditional distribution of $X$ given $X$? I'm pretty confident that: $$\mathbb P(X\le t|X\le s)=\frac{\mathbb P(X\le t  \cap X\le s)}{\mathbb P(X\le s)}=\frac{\mathbb P(X\le t)}{\mathbb P(X\le s)}$$ if $t\le s$ and $$\mathbb P(X\le t|X\le s)=1$$ otherwise, $t>s$. However from this point onwards, I am confused. My intuitive answer would be that the conditional distribution $X|X$ is either the distribution of $X$ or $1$ (but a distribution equal to $1$ doesn't make any sense). P.S. I believe this is related to the question what is the joint distribution of X with itself, $f_{XX}(x,x)$, by $$f_{XX}(x,x)=f_{X|X}(x|x)\cdot f_{X}(x)$$ but I can't find $f_{XX}(x,x)$ either.","I'm stuck with something that might seem trivial but gives me headache. What is the distribution of $X|X$, i.e. the conditional distribution of $X$ given $X$? I'm pretty confident that: $$\mathbb P(X\le t|X\le s)=\frac{\mathbb P(X\le t  \cap X\le s)}{\mathbb P(X\le s)}=\frac{\mathbb P(X\le t)}{\mathbb P(X\le s)}$$ if $t\le s$ and $$\mathbb P(X\le t|X\le s)=1$$ otherwise, $t>s$. However from this point onwards, I am confused. My intuitive answer would be that the conditional distribution $X|X$ is either the distribution of $X$ or $1$ (but a distribution equal to $1$ doesn't make any sense). P.S. I believe this is related to the question what is the joint distribution of X with itself, $f_{XX}(x,x)$, by $$f_{XX}(x,x)=f_{X|X}(x|x)\cdot f_{X}(x)$$ but I can't find $f_{XX}(x,x)$ either.",,"['probability', 'probability-distributions', 'random-variables']"
19,conditional expectation given 2 random variables,conditional expectation given 2 random variables,,"Let's say there are random variables $A$ and $B$ being independent. And random variable $X$ . Are there any properties to simplify $\mathbb{E}(X \mid (A,B))$ : expectation of $X$ given $A$ and $B$ ? In particular, do we have a ""simplification"", like $\mathbb{E}(X \mid (A,B)) = \mathbb{E}( \mathbb{E}(X \mid A) \mid B)$ ? I think it's incorrect (take X = A*B) but it seems strange as intuitively this would seem to be correct, so I feel like there must be some formula linking $\mathbb{E}(X \mid (A,B))$ and the conditional expectations given a single variable thanks !","Let's say there are random variables and being independent. And random variable . Are there any properties to simplify : expectation of given and ? In particular, do we have a ""simplification"", like ? I think it's incorrect (take X = A*B) but it seems strange as intuitively this would seem to be correct, so I feel like there must be some formula linking and the conditional expectations given a single variable thanks !","A B X \mathbb{E}(X \mid (A,B)) X A B \mathbb{E}(X \mid (A,B)) = \mathbb{E}( \mathbb{E}(X \mid A) \mid B) \mathbb{E}(X \mid (A,B))","['probability', 'probability-theory', 'measure-theory', 'conditional-expectation']"
20,A riddle about a liar,A riddle about a liar,,Say Alice says:'the probability that I'm lying is greater than p.' What's the probability that Alice is lying?,Say Alice says:'the probability that I'm lying is greater than p.' What's the probability that Alice is lying?,,"['probability', 'puzzle']"
21,Why can't we combine events in a poisson distribution?,Why can't we combine events in a poisson distribution?,,"Let's say that babies in a hospital are delivered according to a Poisson distribution, where on average 1 baby is delivered every hour. Question 1 : What is the probability that at least 1 baby is delivered per hour? It is 1 - P(X = 0) for $\lambda = 1$, i.e. $1 - e^{-1} = 63\%$. Question 2 : What is the probability that at least 2 babies are delivered per 2 hours? It is 1 - P(X = 0) - P(X = 1) for $\lambda = 2$, i.e. $1 - e^{-2} - 2e^{-2} = 59\%$. To simplify the calculation of the question 2, let's combine 2 babies into one superbaby . We could then ask a question which seems (to me) to be identical to question 2: Question 3 :  What is the probability that at least 1 superbaby is delivered per 2 hours? It is 1 - P(X = 0) for $\lambda = 1$, i.e. $1 - e^{-1} = 63\%$. Here's what I don't understand: if a superbaby is simply 2 babies, Why is the probability that 1 superbaby is delivered per 2 hours not equal to the probability that 2 babies are delivered per 2 hours? My intuition tells me it has something to do with the assumption that events which follow a Poisson distribution are independent, but that's just a guess.","Let's say that babies in a hospital are delivered according to a Poisson distribution, where on average 1 baby is delivered every hour. Question 1 : What is the probability that at least 1 baby is delivered per hour? It is 1 - P(X = 0) for $\lambda = 1$, i.e. $1 - e^{-1} = 63\%$. Question 2 : What is the probability that at least 2 babies are delivered per 2 hours? It is 1 - P(X = 0) - P(X = 1) for $\lambda = 2$, i.e. $1 - e^{-2} - 2e^{-2} = 59\%$. To simplify the calculation of the question 2, let's combine 2 babies into one superbaby . We could then ask a question which seems (to me) to be identical to question 2: Question 3 :  What is the probability that at least 1 superbaby is delivered per 2 hours? It is 1 - P(X = 0) for $\lambda = 1$, i.e. $1 - e^{-1} = 63\%$. Here's what I don't understand: if a superbaby is simply 2 babies, Why is the probability that 1 superbaby is delivered per 2 hours not equal to the probability that 2 babies are delivered per 2 hours? My intuition tells me it has something to do with the assumption that events which follow a Poisson distribution are independent, but that's just a guess.",,['probability']
22,Inequality for conditional expectation,Inequality for conditional expectation,,"I have three random variables that are dependent, $\theta, Y,X$. Under which conditions on the distributions does the following implication hold: For a known function $g(.)$, two different realizations $Y=y$ and $Y=y'$ and the same realization $X=x$, $$E[g(\theta)|Y=y]\neq E[g(\theta)|Y=y']\implies E[g(\theta)|X=x,Y=y]\neq E[g(\theta)|X=x,Y=y']?$$ It seems to me this will boil down to finding conditions for the consequent to be true, i.e., $E[g(\theta)|X=x,Y=y]\neq E[g(\theta)|X=x,Y=y']$ for $y\neq y'$. My thoughts: \begin{equation} E[g(\theta)|X=x,Y=y]=\int g(\theta) f(\theta|X=x,Y=y) d\theta, \end{equation} so if $f(\theta|X=x,Y=y)$ first order stochastically dominates $f(\theta|X=x,Y=y')$ or vice versa, then $E[g(\theta)|X=x,Y=y]\neq E[g(\theta)|X=x,Y=y']$ (assuming $g$ is strictly increasing or decreasing). This is of course only a sufficient and not necessary condition, but still it is not clear to me when  first order stochastic dominance of $f(\theta|Y=y)$ in $y$ implies first order stochastic dominance of $f(\theta|X=x,Y=y)$. Any ideas on that are very much appreciated. Thanks!","I have three random variables that are dependent, $\theta, Y,X$. Under which conditions on the distributions does the following implication hold: For a known function $g(.)$, two different realizations $Y=y$ and $Y=y'$ and the same realization $X=x$, $$E[g(\theta)|Y=y]\neq E[g(\theta)|Y=y']\implies E[g(\theta)|X=x,Y=y]\neq E[g(\theta)|X=x,Y=y']?$$ It seems to me this will boil down to finding conditions for the consequent to be true, i.e., $E[g(\theta)|X=x,Y=y]\neq E[g(\theta)|X=x,Y=y']$ for $y\neq y'$. My thoughts: \begin{equation} E[g(\theta)|X=x,Y=y]=\int g(\theta) f(\theta|X=x,Y=y) d\theta, \end{equation} so if $f(\theta|X=x,Y=y)$ first order stochastically dominates $f(\theta|X=x,Y=y')$ or vice versa, then $E[g(\theta)|X=x,Y=y]\neq E[g(\theta)|X=x,Y=y']$ (assuming $g$ is strictly increasing or decreasing). This is of course only a sufficient and not necessary condition, but still it is not clear to me when  first order stochastic dominance of $f(\theta|Y=y)$ in $y$ implies first order stochastic dominance of $f(\theta|X=x,Y=y)$. Any ideas on that are very much appreciated. Thanks!",,"['probability', 'probability-distributions', 'conditional-expectation']"
23,Limit of median of uniform distribution,Limit of median of uniform distribution,,"Let $X_1,X_2,\ldots$ be a random sample from the uniform distribution on the interval $(0,1)$. Assuming that $n$ is odd, find the pdf of the sample median (say $M_n$). Does the pdf of the r.v. $(M_n-EM_n)/\sqrt{var(M_n)}$ converge to a limit as $n\rightarrow\infty$? My work: I find $M_n\sim Beta(\frac{n+1}{2},\frac{n+1}{2})$, $E M_n=1/2$, and $var(M_n)=\frac{1}{4(n+2)}$. I do not know use which theorem to solve the limit problem.","Let $X_1,X_2,\ldots$ be a random sample from the uniform distribution on the interval $(0,1)$. Assuming that $n$ is odd, find the pdf of the sample median (say $M_n$). Does the pdf of the r.v. $(M_n-EM_n)/\sqrt{var(M_n)}$ converge to a limit as $n\rightarrow\infty$? My work: I find $M_n\sim Beta(\frac{n+1}{2},\frac{n+1}{2})$, $E M_n=1/2$, and $var(M_n)=\frac{1}{4(n+2)}$. I do not know use which theorem to solve the limit problem.",,"['probability', 'statistics', 'statistical-inference', 'probability-limit-theorems']"
24,Gaussian distribution determined by first two moments,Gaussian distribution determined by first two moments,,"When said that Gaussian distribution is determined by it's mean and variance. How is that different of other distributions? Almost every distribution which I can think of has this property. For example if we know the mean of exponential, Poisson distribution then we know the whole distributions.","When said that Gaussian distribution is determined by it's mean and variance. How is that different of other distributions? Almost every distribution which I can think of has this property. For example if we know the mean of exponential, Poisson distribution then we know the whole distributions.",,"['probability', 'normal-distribution']"
25,"If I randomly generate a string of length N from an alphabet {A, B, C}, what's the likelihood that exactly k characters will be the same?","If I randomly generate a string of length N from an alphabet {A, B, C}, what's the likelihood that exactly k characters will be the same?",,"I have an alphabet: {A, B, C}. I'm randomly generating strings of length N from that alphabet. Examples: Examples: N=5, AACBC, AAAAA, BBCAA What is the likelihood that exactly k characters of that string are the same? (k <= N) (k corresponds to the maximum number of similar characters... Example: With string AABCAAA: N=7, k=5 because there are 5 A's. String AABBCC: N=6, k=2 because there are equally-sized groups of A's, B's, and C's.) Initially, my solution looked like this: P(k characters are the same) = $(\frac{1}{3})^k * (\frac{2}{3})^{n-k}$ Until I realized that this solution wasn't robust enough-- it doesn't matter WHICH characters are the same, only that k characters are the same. Thanks so much in advance for your help.","I have an alphabet: {A, B, C}. I'm randomly generating strings of length N from that alphabet. Examples: Examples: N=5, AACBC, AAAAA, BBCAA What is the likelihood that exactly k characters of that string are the same? (k <= N) (k corresponds to the maximum number of similar characters... Example: With string AABCAAA: N=7, k=5 because there are 5 A's. String AABBCC: N=6, k=2 because there are equally-sized groups of A's, B's, and C's.) Initially, my solution looked like this: P(k characters are the same) = $(\frac{1}{3})^k * (\frac{2}{3})^{n-k}$ Until I realized that this solution wasn't robust enough-- it doesn't matter WHICH characters are the same, only that k characters are the same. Thanks so much in advance for your help.",,"['probability', 'combinatorics', 'probability-theory']"
26,"You are making cookies and add N chips to dough randomly, and split it into 100 equal cookies, again at random. How many chips should go into dough?","You are making cookies and add N chips to dough randomly, and split it into 100 equal cookies, again at random. How many chips should go into dough?",,"Question: You are making chocolate chip cookies. You add N chips randomly to the dough and you randomly split the dough into 100 equal cookies. How many chips should go into the dough to give a probability of at least 90% that every cookie has at least one chip? I tried to attempt to solve this using IID random variables. I am not sure how to set the problem up. I know that there should at least be 100 chocolate chips or else the cookies will not meet the ""at least 1 chip per cookie"" requirement and that there is 10% chance that the cookies do not have a chip.","Question: You are making chocolate chip cookies. You add N chips randomly to the dough and you randomly split the dough into 100 equal cookies. How many chips should go into the dough to give a probability of at least 90% that every cookie has at least one chip? I tried to attempt to solve this using IID random variables. I am not sure how to set the problem up. I know that there should at least be 100 chocolate chips or else the cookies will not meet the ""at least 1 chip per cookie"" requirement and that there is 10% chance that the cookies do not have a chip.",,"['probability', 'statistics', 'probability-theory', 'discrete-mathematics']"
27,Expectation of hitting time for simple symmetric random walk,Expectation of hitting time for simple symmetric random walk,,"Assume there is a simple symmetric random walk $$S_n=X_1+...+X_n,\quad S_0=0$$ where $\mathbb P(X_i=\pm 1)=\frac{1}{2}$. Define $T=\inf\{n:S_n=1\}$. How to compute $\mathbb E(T)$? My idea: if $\mathbb E(T)<\infty$ then $$\mathbb E(S_T)=\mathbb E(T)\mathbb E(X_i)$$ where $\mathbb E(S_T)=1$, $\mathbb E(X_i)=0$  so there is a contradiction. Therefore, $\mathbb E(T)=\infty$. Is there something wrong?","Assume there is a simple symmetric random walk $$S_n=X_1+...+X_n,\quad S_0=0$$ where $\mathbb P(X_i=\pm 1)=\frac{1}{2}$. Define $T=\inf\{n:S_n=1\}$. How to compute $\mathbb E(T)$? My idea: if $\mathbb E(T)<\infty$ then $$\mathbb E(S_T)=\mathbb E(T)\mathbb E(X_i)$$ where $\mathbb E(S_T)=1$, $\mathbb E(X_i)=0$  so there is a contradiction. Therefore, $\mathbb E(T)=\infty$. Is there something wrong?",,"['probability', 'stochastic-processes', 'expectation', 'random-walk', 'stopping-times']"
28,What are some good references on how probability theory got mathematically rigorous?,What are some good references on how probability theory got mathematically rigorous?,,"I am working on a term paper for an analysis course and I thought it would be interesting to talk about the connection between analysis and probability theory. Honestly, it would also benefit me a lot as a student in statistics. Knowing the historical context of the things I'm learning about would help me better understand their significance. I vaguely remember from some of my probability courses that people have discovered the intuition of law of large numbers and central limit theorem very early, yet early attempts to put it on rigorous mathematical foundation failed, until the development of measure theory, Lebesgue integration, Fourier transformation, and so on. I am wondering whether there are some nice books/review papers that summarize this process. An ideal reference would include something like, someone tried to prove the law of large numbers, yet failed, since the integration theory back then wasn't adequate, someone tried doing the central limit theory and came up with the characteristic function idea, yet the one-to-one mapping between random variables and characteristic functions couldn't be established, due to some other lack of math tools back then. Finally Kolmogorov came into the picture, put together a complete set of tools and finished the job, by filling in something and something some earlier mathematicians missed.","I am working on a term paper for an analysis course and I thought it would be interesting to talk about the connection between analysis and probability theory. Honestly, it would also benefit me a lot as a student in statistics. Knowing the historical context of the things I'm learning about would help me better understand their significance. I vaguely remember from some of my probability courses that people have discovered the intuition of law of large numbers and central limit theorem very early, yet early attempts to put it on rigorous mathematical foundation failed, until the development of measure theory, Lebesgue integration, Fourier transformation, and so on. I am wondering whether there are some nice books/review papers that summarize this process. An ideal reference would include something like, someone tried to prove the law of large numbers, yet failed, since the integration theory back then wasn't adequate, someone tried doing the central limit theory and came up with the characteristic function idea, yet the one-to-one mapping between random variables and characteristic functions couldn't be established, due to some other lack of math tools back then. Finally Kolmogorov came into the picture, put together a complete set of tools and finished the job, by filling in something and something some earlier mathematicians missed.",,"['probability', 'statistics', 'probability-theory', 'soft-question', 'math-history']"
29,A short question about the convexity of a function,A short question about the convexity of a function,,"Let $x$ and $y$ be two numbers; $0\leq x \leq 1$ and $0\leq y \leq 1$ satisfying $$\mathcal{X}\times \mathcal{Y}=\left\{(x,y):\sum^{\lfloor k\rfloor}_{i=0}\binom{n}{i}(1-y)^{i} y^{n-i} +\sum^{\lfloor k\rfloor}_{i=0}\binom{n}{i}x^i (1-x)^{n-i}=1\right\}$$ Define a function $f^n_k:[0,1]\rightarrow [0,1]$ with the mapping $\mathcal{X} \overset{f^n_k}{\mapsto} \mathcal{Y}$ Prove that for every $k<n/2$, the function $f_k^n$ is concave (or similarly for every $k>n/2$ the function $f_k^n$ is convex). For simplicity, $n$ can be assumed odd. Summary of what I've found (for $k<n/2$): $f_k^n$ is obviously continous and passes through $(0,0)$ and $(1,1)$. $f_k^n$ passes through all pairs $(x,y)$ for which $y>x$ holds (except at $(0,0)$ and $(1,1)$, therefore $f_k^n$ lies above $y=x$ line on $[0,1]^2$. For every $f_k^n(x_0)=y_0$ there is an $\epsilon>0$ close point to $x_0$, namely $x_0+\epsilon$ such that $f_k^n(x_0+\epsilon)=y_0+\delta$ for some positive $\delta$. This proves that $f_k^n$ is increasing above $y=x$ line, but I dont think that it is enough for concavity. Here is the figure for $n=5$: Details of what I've done: The set defined above is the same with $$\mathcal{X}\times \mathcal{Y}=\left\{(x,y): B(k,n,1-y)=1-B(k,n,x)\right\}$$ where $B$ is the binomial c.d.f. Now let $h_0(x;n,k)=1-B(k,n,x)$ and $h_1(y;n,k)=B(k,n,1-y)$. I am able to prove that both $h_0$ and $h_1$ are increasing functions of $x$ and $y$ respectively. I know that in case $k=n/2$ then  $$h_0(x;n,n/2)=h_1(x;n,n/2)$$ One can see that we also have the following inequalities: $$h_0(x;n,n/2-1)>h_0(x;n,n/2)$$ and $$h_1(x;n,n/2-1)<h_1(x;n,n/2)$$ From this point i conclude that  $$h_0(x;n,n/2-1)>h_1(x;n,n/2-1)\quad\forall x\quad\quad (1)$$ BUT the condition of the set says that I need to find all $(x,y)$ such that $$h_0(x;n,n/2-1)=h_1(y;n,n/2-1)\quad\quad (2)$$ If $x=y$ or $x>y$ is assumed to satisfy $(2)$ then this is a contradiction for $(1)$. Accordingly I conclude that $y>x$ must be true for all pairs $(x,y)\in[0,1]^2$ except $(0,0)$ and $(1,1)$, which always satisfy the equality $(2)$. In the next step I assume the point $(x_0,y_0)$ is valid and satisfies $(2)$. Then II choose another point which is very close to $x_0$, i.e., $x_0+\epsilon$ for some $\epsilon>0$. Then since $h_0$ is an increasing function of $x$ then I will have $$h_0(x_0+\epsilon;n,n/2-1)>h_0(x_0;n,n/2-1)$$ this says that left hand side of $(2)$ increased with adding $\epsilon$ to $x_0$ and for $(2)$ to hold, right hand side must also increase. We are lucky because $h_1$ is also an increasing function of $y$ therefore if $(x_0,y_0)$ is a valid point satisfying $(2)$, then $(x_0+\epsilon,y_0+\delta)$ should also be valid for some positive $\delta$. I used $h_0(x;n,n/2-1)$ for the case $k<n/2$ but I could use $h_0(x;n,n/2-a)$ for some $a$. The conclusion would not change. Thanks: Could you please help me? Thanks in advance.","Let $x$ and $y$ be two numbers; $0\leq x \leq 1$ and $0\leq y \leq 1$ satisfying $$\mathcal{X}\times \mathcal{Y}=\left\{(x,y):\sum^{\lfloor k\rfloor}_{i=0}\binom{n}{i}(1-y)^{i} y^{n-i} +\sum^{\lfloor k\rfloor}_{i=0}\binom{n}{i}x^i (1-x)^{n-i}=1\right\}$$ Define a function $f^n_k:[0,1]\rightarrow [0,1]$ with the mapping $\mathcal{X} \overset{f^n_k}{\mapsto} \mathcal{Y}$ Prove that for every $k<n/2$, the function $f_k^n$ is concave (or similarly for every $k>n/2$ the function $f_k^n$ is convex). For simplicity, $n$ can be assumed odd. Summary of what I've found (for $k<n/2$): $f_k^n$ is obviously continous and passes through $(0,0)$ and $(1,1)$. $f_k^n$ passes through all pairs $(x,y)$ for which $y>x$ holds (except at $(0,0)$ and $(1,1)$, therefore $f_k^n$ lies above $y=x$ line on $[0,1]^2$. For every $f_k^n(x_0)=y_0$ there is an $\epsilon>0$ close point to $x_0$, namely $x_0+\epsilon$ such that $f_k^n(x_0+\epsilon)=y_0+\delta$ for some positive $\delta$. This proves that $f_k^n$ is increasing above $y=x$ line, but I dont think that it is enough for concavity. Here is the figure for $n=5$: Details of what I've done: The set defined above is the same with $$\mathcal{X}\times \mathcal{Y}=\left\{(x,y): B(k,n,1-y)=1-B(k,n,x)\right\}$$ where $B$ is the binomial c.d.f. Now let $h_0(x;n,k)=1-B(k,n,x)$ and $h_1(y;n,k)=B(k,n,1-y)$. I am able to prove that both $h_0$ and $h_1$ are increasing functions of $x$ and $y$ respectively. I know that in case $k=n/2$ then  $$h_0(x;n,n/2)=h_1(x;n,n/2)$$ One can see that we also have the following inequalities: $$h_0(x;n,n/2-1)>h_0(x;n,n/2)$$ and $$h_1(x;n,n/2-1)<h_1(x;n,n/2)$$ From this point i conclude that  $$h_0(x;n,n/2-1)>h_1(x;n,n/2-1)\quad\forall x\quad\quad (1)$$ BUT the condition of the set says that I need to find all $(x,y)$ such that $$h_0(x;n,n/2-1)=h_1(y;n,n/2-1)\quad\quad (2)$$ If $x=y$ or $x>y$ is assumed to satisfy $(2)$ then this is a contradiction for $(1)$. Accordingly I conclude that $y>x$ must be true for all pairs $(x,y)\in[0,1]^2$ except $(0,0)$ and $(1,1)$, which always satisfy the equality $(2)$. In the next step I assume the point $(x_0,y_0)$ is valid and satisfies $(2)$. Then II choose another point which is very close to $x_0$, i.e., $x_0+\epsilon$ for some $\epsilon>0$. Then since $h_0$ is an increasing function of $x$ then I will have $$h_0(x_0+\epsilon;n,n/2-1)>h_0(x_0;n,n/2-1)$$ this says that left hand side of $(2)$ increased with adding $\epsilon$ to $x_0$ and for $(2)$ to hold, right hand side must also increase. We are lucky because $h_1$ is also an increasing function of $y$ therefore if $(x_0,y_0)$ is a valid point satisfying $(2)$, then $(x_0+\epsilon,y_0+\delta)$ should also be valid for some positive $\delta$. I used $h_0(x;n,n/2-1)$ for the case $k<n/2$ but I could use $h_0(x;n,n/2-a)$ for some $a$. The conclusion would not change. Thanks: Could you please help me? Thanks in advance.",,"['probability', 'convex-analysis']"
30,The Day Camp Stacking Game,The Day Camp Stacking Game,,"My friend works at a day camp as a counselor and he told me about an interesting game he plays with his group of kids. You have a perfectly shuffled, regular $52$-card deck and a group of $2 \leq n < 52$ kids under your supervision. You ask the kids to sit in circle and randomly distribute a card to each one of them. Thus, each individual gets either a red or a black card (depending on the suit) that they stick on their forehead for everyone to see. The counselor then sits in the middle of the circle and passes through the remaining $52-n$ cards from top to bottom of the deck and show each card to the group. The rules are as follows: Each kid has an assigned chair to start the game. This chair can either be vacant or occupied during the game and cannot be moved. If a red (resp. black) card is shown, each kid with a red (resp. black) card sits on the chair to his/her left. If someone is already on the chair, the kid sits on him/her. If a kid has someone on top of him/her, he/she cannot move when his/her color is drawn, i.e. only kids on top of a stack can move. If two kids have the same color and this color is drawn, they rotate (shift) clockwise by $1$, $e.g.$ if $n=4$ and the colors are $RRBR$ and red is drawn, then the new configuration is $R \sharp (BR) R$, where $(BR)$ means black kid under red kid and $\sharp$ denotes an empty seat. It is possible that no kid moves on a card. The game ends when there are no more cards in the deck. Everybody wins in this game, like any day camp game. I found this game extremely fascinating due to its underlying mathematical structure. It gives rise to some deep mathematical problems which I am currently trying to understand. Let's assume the game does not stop when the deck of cards is empty, but instead after some multiple (called turn ) of the remaining cards are shown, i.e. after $(52-n)m$ cards are shown for some $m$. I wish to analyse two cases, namely cycling though the deck after each turn or shuffling the deck after each turn. By cycling , I mean that the first card that was shown in the first turn is the first card shown in the second turn and so on. In case of cycling, what is the probability that, at some point in the game, all $n$ children are stacked on top of each other? What about shuffling? In both cases, what happens when we let $m \to \infty$? I know very little about probabilities, let alone combinatorics, but I feel like these questions might be difficult to answer. This problem might even be undecidable. The game somewhat reminds me of an ""ordered"" version of the Tower of Hanoi with additional rules, which I know how to solve but I can't see how it could be useful in the current situation. One thing I noticed is that in either cases, the full stack $-$ if it ever happens $-$ will alternate in color as a direct corollary of rule 2. I had some ideas, for instance considering a graph with charges on each vertex and then realizing a stacking as an edge contraction and charge transfer, but this seems overly complicated. How would you go about this problem? Any help would be greatly appreciated.","My friend works at a day camp as a counselor and he told me about an interesting game he plays with his group of kids. You have a perfectly shuffled, regular $52$-card deck and a group of $2 \leq n < 52$ kids under your supervision. You ask the kids to sit in circle and randomly distribute a card to each one of them. Thus, each individual gets either a red or a black card (depending on the suit) that they stick on their forehead for everyone to see. The counselor then sits in the middle of the circle and passes through the remaining $52-n$ cards from top to bottom of the deck and show each card to the group. The rules are as follows: Each kid has an assigned chair to start the game. This chair can either be vacant or occupied during the game and cannot be moved. If a red (resp. black) card is shown, each kid with a red (resp. black) card sits on the chair to his/her left. If someone is already on the chair, the kid sits on him/her. If a kid has someone on top of him/her, he/she cannot move when his/her color is drawn, i.e. only kids on top of a stack can move. If two kids have the same color and this color is drawn, they rotate (shift) clockwise by $1$, $e.g.$ if $n=4$ and the colors are $RRBR$ and red is drawn, then the new configuration is $R \sharp (BR) R$, where $(BR)$ means black kid under red kid and $\sharp$ denotes an empty seat. It is possible that no kid moves on a card. The game ends when there are no more cards in the deck. Everybody wins in this game, like any day camp game. I found this game extremely fascinating due to its underlying mathematical structure. It gives rise to some deep mathematical problems which I am currently trying to understand. Let's assume the game does not stop when the deck of cards is empty, but instead after some multiple (called turn ) of the remaining cards are shown, i.e. after $(52-n)m$ cards are shown for some $m$. I wish to analyse two cases, namely cycling though the deck after each turn or shuffling the deck after each turn. By cycling , I mean that the first card that was shown in the first turn is the first card shown in the second turn and so on. In case of cycling, what is the probability that, at some point in the game, all $n$ children are stacked on top of each other? What about shuffling? In both cases, what happens when we let $m \to \infty$? I know very little about probabilities, let alone combinatorics, but I feel like these questions might be difficult to answer. This problem might even be undecidable. The game somewhat reminds me of an ""ordered"" version of the Tower of Hanoi with additional rules, which I know how to solve but I can't see how it could be useful in the current situation. One thing I noticed is that in either cases, the full stack $-$ if it ever happens $-$ will alternate in color as a direct corollary of rule 2. I had some ideas, for instance considering a graph with charges on each vertex and then realizing a stacking as an edge contraction and charge transfer, but this seems overly complicated. How would you go about this problem? Any help would be greatly appreciated.",,"['probability', 'combinatorics', 'card-games']"
31,Analysis of “Tiny Dice Dungeon” (I),Analysis of “Tiny Dice Dungeon” (I),,"Consider the following one-player game:  Initially, there is a pot of $\$0$. On each turn, the player may opt to end the game and collect the contents of the pot, or roll a single die.  In the latter case, if the roll is $1$, the game is over and the player collects nothing.  Otherwise, the amount of the die roll (from $\$2–\$6$) is added to the pot, and the player gets another move.  The player continues rolling until they either get a $1$, and collect nothing, or opt to collect the pot.  We would like to find the optimal strategy for this game, and the expected payoff under the optimal strategy. A simple (but not quite correct) analysis goes like this:  Any rational strategy must take the form “Stop if and only if the pot has value at least $\$S$.”  If the pot contains $\$P$, then the expected gain from the next die roll is $\frac16(-P+2+3+4+5+6 )$ dollars.  This is positive whenever $P\ge 20$, so the player should roll until the pot reaches $\$20$ or more, and then stop and collect it. This is in fact an optimal strategy, but the analysis is not exactly correct,  because it assumes, incorrectly, that the expected gain from a successful die roll is exactly $\$4$.  But actually the expectation is a little bit more than this, because a successful die roll not only adds $\$4$ to the pot, it enables further die rolls that may add more.  In fact strategies $S=20$ and $S=21$ yield identical expected payoffs of $\$8.141794893727$. A more careful analysis follows:  Let $X_S(P)$ be the expected amount won by following the stop-at-$S$ strategy when $\$P$ is already in the pot.  Then $X_S$ satisfies the following unusual recurrence: $$X_S(P) = \begin{cases} P & \text{if $P\ge S$} \\ \frac16\sum_{i=2}^6 X_S(P+i) & \text{otherwise} \end{cases} $$ We are interested in the behavior of $X_S(0)$, which we can calculate exactly using this recurrence.  This is tedious, so I had the computer do it.  $X_S(0)$ is maximized, as already mentioned, for $S=20$ and $S=21$. My questions are: Is there an easier method to calculate $X_S(0)$ without the help of the computer? Is there an argument that shows that $X_{20}(0) = X_{21}(0)$?","Consider the following one-player game:  Initially, there is a pot of $\$0$. On each turn, the player may opt to end the game and collect the contents of the pot, or roll a single die.  In the latter case, if the roll is $1$, the game is over and the player collects nothing.  Otherwise, the amount of the die roll (from $\$2–\$6$) is added to the pot, and the player gets another move.  The player continues rolling until they either get a $1$, and collect nothing, or opt to collect the pot.  We would like to find the optimal strategy for this game, and the expected payoff under the optimal strategy. A simple (but not quite correct) analysis goes like this:  Any rational strategy must take the form “Stop if and only if the pot has value at least $\$S$.”  If the pot contains $\$P$, then the expected gain from the next die roll is $\frac16(-P+2+3+4+5+6 )$ dollars.  This is positive whenever $P\ge 20$, so the player should roll until the pot reaches $\$20$ or more, and then stop and collect it. This is in fact an optimal strategy, but the analysis is not exactly correct,  because it assumes, incorrectly, that the expected gain from a successful die roll is exactly $\$4$.  But actually the expectation is a little bit more than this, because a successful die roll not only adds $\$4$ to the pot, it enables further die rolls that may add more.  In fact strategies $S=20$ and $S=21$ yield identical expected payoffs of $\$8.141794893727$. A more careful analysis follows:  Let $X_S(P)$ be the expected amount won by following the stop-at-$S$ strategy when $\$P$ is already in the pot.  Then $X_S$ satisfies the following unusual recurrence: $$X_S(P) = \begin{cases} P & \text{if $P\ge S$} \\ \frac16\sum_{i=2}^6 X_S(P+i) & \text{otherwise} \end{cases} $$ We are interested in the behavior of $X_S(0)$, which we can calculate exactly using this recurrence.  This is tedious, so I had the computer do it.  $X_S(0)$ is maximized, as already mentioned, for $S=20$ and $S=21$. My questions are: Is there an easier method to calculate $X_S(0)$ without the help of the computer? Is there an argument that shows that $X_{20}(0) = X_{21}(0)$?",,"['probability', 'expectation', 'dice']"
32,Finding Hitting probability from Markov Chain,Finding Hitting probability from Markov Chain,,"I have a Markov chain with states {1,2,3,4,5} which has the following transition matrix: $$P= \begin{bmatrix} 0.3 & 0 & 0.7 & 0 & 0\\ 0 & 1 & 0 & 0 & 0\\ 0.5 & 0 & 0.5 & 0 & 0\\ 0.2 & 0 & 0 & 0.5 & 0.3\\ 0 &1 & 0 & 0 & 0\\\end{bmatrix}$$ From here, I need to calculate the hitting time, $h_{42}$ , the probability that starting from state 4, the chain ever reaches state 2. My answer was: $h_{42}$ = $p_{45}$ $h_{52}$ + $p_{44}$ $h_{42}$ + $p_{41}$ $h_{12}$ $h_{42}$ = 0.3 $h_{52}$ + 0.5 $h_{42}$ + 0 from here, I calculated $h_{52}$ which, $h_{52}$ = 1 Finally, I got: 0.5 $h_{42}$ = 0.3 $h_{42}$ = 0.3/0.5 = 0.6 or 3/5 Could anyone please help me if I had find the solution correctly? (it was my first attempt trying to find the hitting time). Similarly, if I want to find $h_{41}$, is it: $h_{41}$ = 1 - $h_{42}$ = 2/5?","I have a Markov chain with states {1,2,3,4,5} which has the following transition matrix: $$P= \begin{bmatrix} 0.3 & 0 & 0.7 & 0 & 0\\ 0 & 1 & 0 & 0 & 0\\ 0.5 & 0 & 0.5 & 0 & 0\\ 0.2 & 0 & 0 & 0.5 & 0.3\\ 0 &1 & 0 & 0 & 0\\\end{bmatrix}$$ From here, I need to calculate the hitting time, $h_{42}$ , the probability that starting from state 4, the chain ever reaches state 2. My answer was: $h_{42}$ = $p_{45}$ $h_{52}$ + $p_{44}$ $h_{42}$ + $p_{41}$ $h_{12}$ $h_{42}$ = 0.3 $h_{52}$ + 0.5 $h_{42}$ + 0 from here, I calculated $h_{52}$ which, $h_{52}$ = 1 Finally, I got: 0.5 $h_{42}$ = 0.3 $h_{42}$ = 0.3/0.5 = 0.6 or 3/5 Could anyone please help me if I had find the solution correctly? (it was my first attempt trying to find the hitting time). Similarly, if I want to find $h_{41}$, is it: $h_{41}$ = 1 - $h_{42}$ = 2/5?",,"['probability', 'markov-chains']"
33,Why MLR (monotone likelihood ratio) implies stochastic increasing?,Why MLR (monotone likelihood ratio) implies stochastic increasing?,,"the following argument holds: for $\theta_1<\theta_2$, $\dfrac{f(x\mid\theta_2)}{f(x\mid\theta_1)}$ is increasing in $x$. Then, $F(x\mid\theta_2)\leq F(x\mid\theta_1)$ for all $x$. Intuitively, this seems to be natural but I could not find a way. Would you let me know this or have some hints?","the following argument holds: for $\theta_1<\theta_2$, $\dfrac{f(x\mid\theta_2)}{f(x\mid\theta_1)}$ is increasing in $x$. Then, $F(x\mid\theta_2)\leq F(x\mid\theta_1)$ for all $x$. Intuitively, this seems to be natural but I could not find a way. Would you let me know this or have some hints?",,"['probability', 'statistics']"
34,Probability that exists at least an edge in the configuration model,Probability that exists at least an edge in the configuration model,,"In this period, I am studying some topics on random networks to understand the modularity optimization used in community detection. In particular, I am trying to understand a model called configuration model, which represents a random graph with a given degree sequence. You can find some descriptions on the topic here: http://tuvalu.santafe.edu/~aaronc/courses/5352/fall2013/csci5352_2013_L11.pdf http://homepage.cs.uiowa.edu/~sriram/196/spring12/lectureNotes/Lecture11.pdf Now, my problem is that I don't understand why the probability $p_{ij}$ that exists at least an edge between two vertices $i$ and $j$ is evaluated as $p_{ij} = \frac{k_i k_j}{2m}$. I suppose that they are evaluating the probability as the edges were independent. Am i right? Are really the edges independent or is it supposed that they are in a large graph? I don't understand that very well because I have noticed that in some graphs the given probability is not a value between 0 and 1. It's confusing the fact that I have read on some articles that they call it as the ""expected number of edges between two vertex"" and on other ones that they call it as the ""probability that exists at least an edge between two vertex"", too. Is it the same thing? Could you help me understand the given probability? Thank you.","In this period, I am studying some topics on random networks to understand the modularity optimization used in community detection. In particular, I am trying to understand a model called configuration model, which represents a random graph with a given degree sequence. You can find some descriptions on the topic here: http://tuvalu.santafe.edu/~aaronc/courses/5352/fall2013/csci5352_2013_L11.pdf http://homepage.cs.uiowa.edu/~sriram/196/spring12/lectureNotes/Lecture11.pdf Now, my problem is that I don't understand why the probability $p_{ij}$ that exists at least an edge between two vertices $i$ and $j$ is evaluated as $p_{ij} = \frac{k_i k_j}{2m}$. I suppose that they are evaluating the probability as the edges were independent. Am i right? Are really the edges independent or is it supposed that they are in a large graph? I don't understand that very well because I have noticed that in some graphs the given probability is not a value between 0 and 1. It's confusing the fact that I have read on some articles that they call it as the ""expected number of edges between two vertex"" and on other ones that they call it as the ""probability that exists at least an edge between two vertex"", too. Is it the same thing? Could you help me understand the given probability? Thank you.",,"['probability', 'probability-theory', 'graph-theory', 'random-graphs', 'network']"
35,what the central limit theorem says,what the central limit theorem says,,"Asked what the central limit theorem says, a student replies, ""as you take larger and larger samples from a population, the histogram of the sample values looks more and more Normal"". Is the student right? Explain your answer. My answer is no, the student is wrong. My explanation is the histogram of the sample values will look like the population distribution, whatever it might happen to be. The central limit theorem says that the histogram of sample means (from many large samples) will look more and more Normal. Am I right about it? It is that simple? Is there anything more I can say about this?","Asked what the central limit theorem says, a student replies, ""as you take larger and larger samples from a population, the histogram of the sample values looks more and more Normal"". Is the student right? Explain your answer. My answer is no, the student is wrong. My explanation is the histogram of the sample values will look like the population distribution, whatever it might happen to be. The central limit theorem says that the histogram of sample means (from many large samples) will look more and more Normal. Am I right about it? It is that simple? Is there anything more I can say about this?",,"['probability', 'statistics', 'probability-theory', 'probability-distributions']"
36,Suppose that we flip a coin until either it comes up tails twice or we have flipped six times. What is the expected number of times we flip the coin?,Suppose that we flip a coin until either it comes up tails twice or we have flipped six times. What is the expected number of times we flip the coin?,,"So this is the answer that I got (where $N$ represents the number of coin flips after which you can stop) but can someone tell me if this looks right? $P(N=2) = P(TT) = \dfrac{1}{4} $ $P(N=3) = P(HTT , THT) = \dfrac{2}{8} $ $P(N=4) = P(HHTT;HTHT;THHT) = \dfrac{3}{16} $ $P(N=5) = \dfrac{4}{32} $ $P(N=6) = 1 - \dfrac{1}{4} - \dfrac{2}{8} - \dfrac{3}{16} - \dfrac{4}{32} = \dfrac{3}{16}$ $E(N) = 2\left(\dfrac{1}{4}\right) + 3\left(\dfrac{2}{8}\right) + 4\left(\dfrac{3}{16}\right) + 5\left(\dfrac{4}{32}\right) + 6\left(\dfrac{3}{16}\right) = \dfrac{15}{4} = 3.75$","So this is the answer that I got (where $N$ represents the number of coin flips after which you can stop) but can someone tell me if this looks right? $P(N=2) = P(TT) = \dfrac{1}{4} $ $P(N=3) = P(HTT , THT) = \dfrac{2}{8} $ $P(N=4) = P(HHTT;HTHT;THHT) = \dfrac{3}{16} $ $P(N=5) = \dfrac{4}{32} $ $P(N=6) = 1 - \dfrac{1}{4} - \dfrac{2}{8} - \dfrac{3}{16} - \dfrac{4}{32} = \dfrac{3}{16}$ $E(N) = 2\left(\dfrac{1}{4}\right) + 3\left(\dfrac{2}{8}\right) + 4\left(\dfrac{3}{16}\right) + 5\left(\dfrac{4}{32}\right) + 6\left(\dfrac{3}{16}\right) = \dfrac{15}{4} = 3.75$",,"['probability', 'discrete-mathematics']"
37,About a domain of random variable $S_n=X_1+X_2+...+X_n$,About a domain of random variable,S_n=X_1+X_2+...+X_n,"I have a question about a random variable $S_n=X_1+X_2+...+X_n$ in the probability theory. Assume that $X_k$ is a random variable on $\Omega$ for each $k$ and that each $X_k$ has the same distributions. In probability theory, we study a random variable $S_n=X_1+X_2+...+X_n$. Since this sum is just a addition of a functions, $S_n$ must have the domain $\Omega$. My question is the following: suppose we toss a coin $n$ times and let $X_k$ : $\Omega = \{H, T\} \to \mathbb{R}$ be random variables with $X_k(H)=1, X_k(T)=0$. Then $S_n=X_1+X_2+...+X_n=1+1+...+1=n$ and $S_n(T)=X_1(T)+X_2(T)+...+X_n(T)=0+0+...+0=0$. It does not mean anything that is useful! I know that $\frac{S_n}{n}$ must mean the average number of 'heads' in $n$ tosses of a coin. So I think the domain of $S_n$ should be the collection of n-tuples  $\omega=(\omega_1, \omega_2, ..., \omega_n) \in \Omega$, where $ω_k$ is either $H$ or $T$ and $S_n(\omega)=X_1(\omega_1)+X_2(\omega_2)+...+X_n(\omega_n)$. Can someone give me the right explanation about a domain of $S_n$?","I have a question about a random variable $S_n=X_1+X_2+...+X_n$ in the probability theory. Assume that $X_k$ is a random variable on $\Omega$ for each $k$ and that each $X_k$ has the same distributions. In probability theory, we study a random variable $S_n=X_1+X_2+...+X_n$. Since this sum is just a addition of a functions, $S_n$ must have the domain $\Omega$. My question is the following: suppose we toss a coin $n$ times and let $X_k$ : $\Omega = \{H, T\} \to \mathbb{R}$ be random variables with $X_k(H)=1, X_k(T)=0$. Then $S_n=X_1+X_2+...+X_n=1+1+...+1=n$ and $S_n(T)=X_1(T)+X_2(T)+...+X_n(T)=0+0+...+0=0$. It does not mean anything that is useful! I know that $\frac{S_n}{n}$ must mean the average number of 'heads' in $n$ tosses of a coin. So I think the domain of $S_n$ should be the collection of n-tuples  $\omega=(\omega_1, \omega_2, ..., \omega_n) \in \Omega$, where $ω_k$ is either $H$ or $T$ and $S_n(\omega)=X_1(\omega_1)+X_2(\omega_2)+...+X_n(\omega_n)$. Can someone give me the right explanation about a domain of $S_n$?",,"['probability', 'probability-theory', 'random-variables']"
38,Expected number of self loops.,Expected number of self loops.,,"You have 100 string in a bag and you randomly pull out one end of a string. You randomly pull out another end and tie them together. You do this until you have no more ends. The expected number of loops is $\sum_{i=1}^{n} \frac{1}{2n-1}$. What is the expected number of self loops? (Strings that are tied to its own end.) My take: The probability of having a self loop with the first string is 1/199. By linearity of expectation, each string has 1/199 chance of forming a self loop, so the expected number of self loops is $100/199$. Is this correct? Seems like a low number but then again you have many strings and it's unlikely to pull out your own end.","You have 100 string in a bag and you randomly pull out one end of a string. You randomly pull out another end and tie them together. You do this until you have no more ends. The expected number of loops is $\sum_{i=1}^{n} \frac{1}{2n-1}$. What is the expected number of self loops? (Strings that are tied to its own end.) My take: The probability of having a self loop with the first string is 1/199. By linearity of expectation, each string has 1/199 chance of forming a self loop, so the expected number of self loops is $100/199$. Is this correct? Seems like a low number but then again you have many strings and it's unlikely to pull out your own end.",,['probability']
39,Bridge HCP held by the best hand at the table?,Bridge HCP held by the best hand at the table?,,"In the game of Bridge, what is the expected number of high card points held by the player holding the most high card points at the table? $A=4$, $K=3$, $Q=2$, $J=1$.","In the game of Bridge, what is the expected number of high card points held by the player holding the most high card points at the table? $A=4$, $K=3$, $Q=2$, $J=1$.",,"['probability', 'combinatorics']"
40,"$X,Y$ i.i.d., $X$ and $(X+Y)/\sqrt{2}$ have the same dist., then show that $X$ has a normal distribution","i.i.d.,  and  have the same dist., then show that  has a normal distribution","X,Y X (X+Y)/\sqrt{2} X","I am trying to show that $X$ is a standard normal (in distribution) by applying the Lindberg's version of the central limit theorem to a sequence always equal to $X$. In order to do that, I need to show that Lindberg-Feller condition is satisfied, and, for that, I need $X$'s variance. Is there an easier way to do this? (without using CLT) Can anyone give me a hint on how to calculate that variance? Thanks a lot for reading!","I am trying to show that $X$ is a standard normal (in distribution) by applying the Lindberg's version of the central limit theorem to a sequence always equal to $X$. In order to do that, I need to show that Lindberg-Feller condition is satisfied, and, for that, I need $X$'s variance. Is there an easier way to do this? (without using CLT) Can anyone give me a hint on how to calculate that variance? Thanks a lot for reading!",,"['probability', 'normal-distribution']"
41,Different Perspectives of Multinomial Theorem & Partitions,Different Perspectives of Multinomial Theorem & Partitions,,"There are 2 important interpretations of the multinomial theorem and coefficients. 1:  Determining the number of ordered strings that can be formed using a set of letters.  For example, with 1 m , 4 i 's, 4 s 's , and 2 p 's, there are $\binom{11}{1,4,4,2}=34,650$ possible 11-letter strings that can be formed, of which mississippi is one specific example. 2: Partitioning a set of objects into several groupings where objects in each grouping are indistinguishable.  For example, in a group of 11 candidates, how many ways can we form 4 committees such that one committee has only 1 member, another has 4 members, another has 4 members, and the fourth committee has 2 members (assuming each person can serve in one committee)?  Again the answer is $\binom{11}{1,4,4,2}=34,650$.  I also understand that multinomial coefficients are a shortcut to partitioning.  We could have equivalently written:  $\binom{11}{1}\binom{10}{4}\binom{6}{4}\binom{2}{2}=34,650$. I did one problem the other day ( Probability/Combinatorics Question ), and answered it.  However, I am reviewing the material and seem to get the concepts confused.  In the following question: At a picnic, there was a bowl of chocolate candy that had 10 pieces of Milky Way, Almond Joy, Butterfinger, Nestle Crunch, Snickers, and Kit Kat. Jen grabbed six pieces at random from this bowl of 60 chocolate candies. (b) What is the probability that Jen grabs exactly five varieties? When calculating the numerator of the probability, sometimes I am tempted to write $\binom{6}{2,1,1,1,1,0}$ instead of the correct $\binom{6}{4,1}$.  Sometimes I want to view a type of candy as a committee group.  So since we have 5 varieties, we have 5 committees where one committee has 2 people (or candies), and the rest of the 4 committees have 1 person (or 1 candy). Can anyone please explain why this is the wrong view and how I can stop confusing myself? Thank you in advance.","There are 2 important interpretations of the multinomial theorem and coefficients. 1:  Determining the number of ordered strings that can be formed using a set of letters.  For example, with 1 m , 4 i 's, 4 s 's , and 2 p 's, there are $\binom{11}{1,4,4,2}=34,650$ possible 11-letter strings that can be formed, of which mississippi is one specific example. 2: Partitioning a set of objects into several groupings where objects in each grouping are indistinguishable.  For example, in a group of 11 candidates, how many ways can we form 4 committees such that one committee has only 1 member, another has 4 members, another has 4 members, and the fourth committee has 2 members (assuming each person can serve in one committee)?  Again the answer is $\binom{11}{1,4,4,2}=34,650$.  I also understand that multinomial coefficients are a shortcut to partitioning.  We could have equivalently written:  $\binom{11}{1}\binom{10}{4}\binom{6}{4}\binom{2}{2}=34,650$. I did one problem the other day ( Probability/Combinatorics Question ), and answered it.  However, I am reviewing the material and seem to get the concepts confused.  In the following question: At a picnic, there was a bowl of chocolate candy that had 10 pieces of Milky Way, Almond Joy, Butterfinger, Nestle Crunch, Snickers, and Kit Kat. Jen grabbed six pieces at random from this bowl of 60 chocolate candies. (b) What is the probability that Jen grabs exactly five varieties? When calculating the numerator of the probability, sometimes I am tempted to write $\binom{6}{2,1,1,1,1,0}$ instead of the correct $\binom{6}{4,1}$.  Sometimes I want to view a type of candy as a committee group.  So since we have 5 varieties, we have 5 committees where one committee has 2 people (or candies), and the rest of the 4 committees have 1 person (or 1 candy). Can anyone please explain why this is the wrong view and how I can stop confusing myself? Thank you in advance.",,"['probability', 'combinatorics', 'multinomial-coefficients']"
42,Unexpected hanging paradox maxmin strategies,Unexpected hanging paradox maxmin strategies,,"I have a question about strategies of the players of Unexpected hanging paradox (I am very sorry for a long topic,  topic exist already for a while, during this time I try to develop idea how to solve the problem, recently I decided to seek solution in the field of probability, therefore I ask for anyone who has experience in solving problems in probability to take a look. For understanding essential is reading the Version of the Paradox paradox, Question , and may be few last addendums). Version of the Paradox : Let's consider a slightly specific version of the paradox, where the players take actions in rounds (in terms of paradox rounds can be days). On every specific round (day) judges can take action $A$ - the prisoner will be hanged today, $B$ - the prisoner will not be hanged today, and the prisoner can have few guesses $A$ - I will be hanged today, $B$ - I will not be hanged today. The game is played simultaneously. If $A$ is played by one of the players then the judges win, if both players play $A$ simultaneously than  the prisoner win, and if both of them play $B$ game goes to the next round. If as a result of four rounds the prisoner is not hanged than the prisoner win. Question: what is max-min strategy for the judges and for the prisoner. If there are any solution concept (Nash equilibrium). The following is a few I hope useful ideas to approach the solution. The game should be represented in extensive from but with simultaneous play. Let's start from judges. There is no dominant strategy for the judges and it looks like there is no a pure Nash equlibrium. What it's known is that the chances to win when judges play $A$ is 50% and the chances to win when judges play B is $>50%$. But every next round the chances to win by choosing $B$ is getting lower, however the prisoner should prefer $B$ when the number of rounds is getting higher. In addition, we can try to do a backward induction, the last round is similar to the Matching pennies game , that has a mixed Nash equilibrium, with actions takes on probability of 50 %. On the second backward induction step (using the fact that on the last step the mixed Nash equilibrium is 50/50 between playing A and B for both players), therefore judges would prefer playing $B$ on the second step with probability 75 % and A with 25%, however the prisoner would prefer playing $A$ with 75% and B with 25%. Unfortunately I didn't get any closer to maxmin strategies, but at least I've shared few ideas. Addendum: Instead of playing 4 rounds, let's try to play 2 rounds, when the last round is similar to the matching pennies game, we can try to convert the 2 round game to normal form (4 by 4 actions for prisoner and judges of the form {AA,AB,BA,BB}) and it will be apparent that the most effective strategy for judges is two columns (judges is column player, at the same time is the worsen strategies for the prisoner ) - B(don't hang) -B(don't hang); B(don't hang)-A(hang) for the prisoner the win strategy is the strategy of the judges(BA when judges played BA, and BB when judges played BB), then maxmin of the prisoner is to play B for the tree rounds and on the last round play A or B with probability 50%. The worsen strategies for the judges is AA and AB (they actually don't yield the second turn because judges decide to hang on the first round, therefore consider only strategy A, in the normal form it's represent like AA and AB, maybe I get it wrong), therefore playing A is maxmin strategy of the judges. Addendum: we can try to looks at the problem from the probability point of view. Let's consider few ideas. Idea 1. Judges throughout the game should make five principal decisions, following is the decision with the probabilities. $Pr(j_1=$hand the prisoner on the first day$) = 0.2, ..., Pr(j_4=$hand the prisoner on the last (4'th) day$) = 0.2, Pr(j_5=$don't hang the prisoner at all$) = 0.2$ the same for the prisoner, $Pr(p_1=$I will be hanged on the first day$) = 0.2,..,Pr(p_4=$I will be hanged on the fourth day$) = 0.2, Pr(p_5=$I will not be hanged at all$) = 0.2$ $P($judges win$) = \sum_{1 \leq i \leq 4}^{} p_1(1-s_1)=0.8$ The above approach for me looks like not correct, just because taking an action on round $i$ depends on the decision on round $i-1$, therefore all the probabilities are not independent. Idea 2 We can try to represent all the probabilities of the game in this form $Pr(p_1=$prisoner wins on the first round$) = 0.5($prisoner:I will be hanged on the first day$) \cdot 0.5($judges : hang the prisoner on the first day$)$ $Pr(p_2=$prisoner wins on the second round$) = 0.5($prisoner:I will no be hanged on the first day$) \cdot 0.5($judges : don't hang the the prisoner on the first day$) \cdot 0.5($prisoner:I will be hanged on the second day$) \cdot 0.5($judges : hang the prisoner on the second day$).$ $Pr(p_4=$prisoner wins on the last round$) = (0.5 \cdot 0.5)^3 ($judges didn't hang the prisoner on the three previous round and the prisoner didn't make guess that he will be hanged during first three days$) \cdot (0.25($judges: hang on the last day, prisoner: I will be hanged today$) \cdot 0.25($judges: don't hang at all, prisoner: I will not be hanged at all$))$. $Pr($prisoner wins the game$) = p_1+p_2+p_3+p_4 =0.25+0.25^2+0.25^3+0.25^3 \cdot 0.5 = 0.3359375$ We get some result, I don't really know what to do with it, and don't know if it's correct, if we consider the probabilities for the victory like in Idea 2, it's obvious that the prisoner should make decision as soon as possible because on the first round he has the maximum probability to win and it goes less with every consecutive round. If we consider probability like in Idea 1 in independent manner, the maximal probability to win is on the round 4. What is the right way I still don't know.","I have a question about strategies of the players of Unexpected hanging paradox (I am very sorry for a long topic,  topic exist already for a while, during this time I try to develop idea how to solve the problem, recently I decided to seek solution in the field of probability, therefore I ask for anyone who has experience in solving problems in probability to take a look. For understanding essential is reading the Version of the Paradox paradox, Question , and may be few last addendums). Version of the Paradox : Let's consider a slightly specific version of the paradox, where the players take actions in rounds (in terms of paradox rounds can be days). On every specific round (day) judges can take action $A$ - the prisoner will be hanged today, $B$ - the prisoner will not be hanged today, and the prisoner can have few guesses $A$ - I will be hanged today, $B$ - I will not be hanged today. The game is played simultaneously. If $A$ is played by one of the players then the judges win, if both players play $A$ simultaneously than  the prisoner win, and if both of them play $B$ game goes to the next round. If as a result of four rounds the prisoner is not hanged than the prisoner win. Question: what is max-min strategy for the judges and for the prisoner. If there are any solution concept (Nash equilibrium). The following is a few I hope useful ideas to approach the solution. The game should be represented in extensive from but with simultaneous play. Let's start from judges. There is no dominant strategy for the judges and it looks like there is no a pure Nash equlibrium. What it's known is that the chances to win when judges play $A$ is 50% and the chances to win when judges play B is $>50%$. But every next round the chances to win by choosing $B$ is getting lower, however the prisoner should prefer $B$ when the number of rounds is getting higher. In addition, we can try to do a backward induction, the last round is similar to the Matching pennies game , that has a mixed Nash equilibrium, with actions takes on probability of 50 %. On the second backward induction step (using the fact that on the last step the mixed Nash equilibrium is 50/50 between playing A and B for both players), therefore judges would prefer playing $B$ on the second step with probability 75 % and A with 25%, however the prisoner would prefer playing $A$ with 75% and B with 25%. Unfortunately I didn't get any closer to maxmin strategies, but at least I've shared few ideas. Addendum: Instead of playing 4 rounds, let's try to play 2 rounds, when the last round is similar to the matching pennies game, we can try to convert the 2 round game to normal form (4 by 4 actions for prisoner and judges of the form {AA,AB,BA,BB}) and it will be apparent that the most effective strategy for judges is two columns (judges is column player, at the same time is the worsen strategies for the prisoner ) - B(don't hang) -B(don't hang); B(don't hang)-A(hang) for the prisoner the win strategy is the strategy of the judges(BA when judges played BA, and BB when judges played BB), then maxmin of the prisoner is to play B for the tree rounds and on the last round play A or B with probability 50%. The worsen strategies for the judges is AA and AB (they actually don't yield the second turn because judges decide to hang on the first round, therefore consider only strategy A, in the normal form it's represent like AA and AB, maybe I get it wrong), therefore playing A is maxmin strategy of the judges. Addendum: we can try to looks at the problem from the probability point of view. Let's consider few ideas. Idea 1. Judges throughout the game should make five principal decisions, following is the decision with the probabilities. $Pr(j_1=$hand the prisoner on the first day$) = 0.2, ..., Pr(j_4=$hand the prisoner on the last (4'th) day$) = 0.2, Pr(j_5=$don't hang the prisoner at all$) = 0.2$ the same for the prisoner, $Pr(p_1=$I will be hanged on the first day$) = 0.2,..,Pr(p_4=$I will be hanged on the fourth day$) = 0.2, Pr(p_5=$I will not be hanged at all$) = 0.2$ $P($judges win$) = \sum_{1 \leq i \leq 4}^{} p_1(1-s_1)=0.8$ The above approach for me looks like not correct, just because taking an action on round $i$ depends on the decision on round $i-1$, therefore all the probabilities are not independent. Idea 2 We can try to represent all the probabilities of the game in this form $Pr(p_1=$prisoner wins on the first round$) = 0.5($prisoner:I will be hanged on the first day$) \cdot 0.5($judges : hang the prisoner on the first day$)$ $Pr(p_2=$prisoner wins on the second round$) = 0.5($prisoner:I will no be hanged on the first day$) \cdot 0.5($judges : don't hang the the prisoner on the first day$) \cdot 0.5($prisoner:I will be hanged on the second day$) \cdot 0.5($judges : hang the prisoner on the second day$).$ $Pr(p_4=$prisoner wins on the last round$) = (0.5 \cdot 0.5)^3 ($judges didn't hang the prisoner on the three previous round and the prisoner didn't make guess that he will be hanged during first three days$) \cdot (0.25($judges: hang on the last day, prisoner: I will be hanged today$) \cdot 0.25($judges: don't hang at all, prisoner: I will not be hanged at all$))$. $Pr($prisoner wins the game$) = p_1+p_2+p_3+p_4 =0.25+0.25^2+0.25^3+0.25^3 \cdot 0.5 = 0.3359375$ We get some result, I don't really know what to do with it, and don't know if it's correct, if we consider the probabilities for the victory like in Idea 2, it's obvious that the prisoner should make decision as soon as possible because on the first round he has the maximum probability to win and it goes less with every consecutive round. If we consider probability like in Idea 1 in independent manner, the maximal probability to win is on the round 4. What is the right way I still don't know.",,"['probability', 'game-theory', 'nash-equilibrium', 'maximum-principle', 'algorithmic-game-theory']"
43,What are fair point values for Zombie dice?,What are fair point values for Zombie dice?,,"Described below is a modified version of Zombie dice ( http://www.sjgames.com/dice/zombiedice/ ) which the kids and I play. As in the original game, the idea is to sequentially roll sets of 3 specialty dice (described below and in the link above) until you either voluntarily stop rolling or bust. There are green, yellow an red dice whose faces show: Green: 3 brains, 1 shotgun blasts, 2 footsteps Yellow: 2 brains, 2 shogun blasts, 2 footsteps Red: 1 brain, 3 shotgun blats, 1 footsteps After each roll, you accumulate either brains (you ate your victim's brains) or shotgun blasts (victim shot you); footsteps are neutral (victim ran away). If you choose to stop rolling, you get 1 point for each accumulated brain. You bust when you accumulate 3 shotgun blasts and receive no points in that game. Instead of picking the dice blindly from a bag, as called for in the original version rules, we let the players pick which 3 dice to roll of any color available. Obviously, nobody in his right mind would roll anything other than the green dice, since they have the most brains and least shotgun blasts. We modified the rules by somewhat arbitrarily awarding 1 point for each green die, 2 points for a yellow die and 5 points for a red die. So, the riskier the dice you select to roll, the more points you stand to get. This introduces a nice risk/reward element to the game. Here is where you come in. I don't know whether our 1:2:5 point ratio is the fairest, that is, the one that balances the risk/reward of each die color. So: What should be the fair point value of each color die? I don't know whether one can calculate the desired values. Naturally, I could do a simulation by rolling, say, 1,000 games with each color dice and tallying the average number of brains accumulated right before the bust for each color; then, I would derive a factor by which to the yellow and red dice that equates the average outomes of the three colors. Also, I could but now don't have the tools (e.g., a BASIC interpreter) to write a simulation program, or the time to manually do the simulation. What say you is the right green:yellow:red ratio? BK asked: ""For one's turn must the same 3 dice be rolled each time or may one switch back and forth?"" LB says: No, you can switch dice. After each roll (except if you bust, of course) you: Keep the brains. Keep the shotguns. Return the footsteps to the dice cache. Pick any 3 dice from the dice cache, if you want to roll again, and roll. Note that as a game progresses and players accumulate brains and shotguns--depleting the dice cache--there will be times when a player's dice choice is limited by the dice then remaining in the cache. However, this does not happen often (we actually use 2 sets of Zombie dice and may even buy a couple more so there will always be plenty to pick from). Also, when there are fewer than 3 dice left in the cache, we replenish it by writing down on a Post-it the number of brains each player has and returning back to the cache their brain dice (could also do it for the shotguns be don't). So I think reasonable to disregard the dice depletion for our purposes. Dr. Tim Chow suggested I ask y'all. http://www.bgonline.org/forums/webbbs_config.pl?noframes;read=139865 I hope you find this problem interesting enough to give it a shot. Thanks in advance for taking the time to read this message and for hopefully figuring out the answer to the problem.","Described below is a modified version of Zombie dice ( http://www.sjgames.com/dice/zombiedice/ ) which the kids and I play. As in the original game, the idea is to sequentially roll sets of 3 specialty dice (described below and in the link above) until you either voluntarily stop rolling or bust. There are green, yellow an red dice whose faces show: Green: 3 brains, 1 shotgun blasts, 2 footsteps Yellow: 2 brains, 2 shogun blasts, 2 footsteps Red: 1 brain, 3 shotgun blats, 1 footsteps After each roll, you accumulate either brains (you ate your victim's brains) or shotgun blasts (victim shot you); footsteps are neutral (victim ran away). If you choose to stop rolling, you get 1 point for each accumulated brain. You bust when you accumulate 3 shotgun blasts and receive no points in that game. Instead of picking the dice blindly from a bag, as called for in the original version rules, we let the players pick which 3 dice to roll of any color available. Obviously, nobody in his right mind would roll anything other than the green dice, since they have the most brains and least shotgun blasts. We modified the rules by somewhat arbitrarily awarding 1 point for each green die, 2 points for a yellow die and 5 points for a red die. So, the riskier the dice you select to roll, the more points you stand to get. This introduces a nice risk/reward element to the game. Here is where you come in. I don't know whether our 1:2:5 point ratio is the fairest, that is, the one that balances the risk/reward of each die color. So: What should be the fair point value of each color die? I don't know whether one can calculate the desired values. Naturally, I could do a simulation by rolling, say, 1,000 games with each color dice and tallying the average number of brains accumulated right before the bust for each color; then, I would derive a factor by which to the yellow and red dice that equates the average outomes of the three colors. Also, I could but now don't have the tools (e.g., a BASIC interpreter) to write a simulation program, or the time to manually do the simulation. What say you is the right green:yellow:red ratio? BK asked: ""For one's turn must the same 3 dice be rolled each time or may one switch back and forth?"" LB says: No, you can switch dice. After each roll (except if you bust, of course) you: Keep the brains. Keep the shotguns. Return the footsteps to the dice cache. Pick any 3 dice from the dice cache, if you want to roll again, and roll. Note that as a game progresses and players accumulate brains and shotguns--depleting the dice cache--there will be times when a player's dice choice is limited by the dice then remaining in the cache. However, this does not happen often (we actually use 2 sets of Zombie dice and may even buy a couple more so there will always be plenty to pick from). Also, when there are fewer than 3 dice left in the cache, we replenish it by writing down on a Post-it the number of brains each player has and returning back to the cache their brain dice (could also do it for the shotguns be don't). So I think reasonable to disregard the dice depletion for our purposes. Dr. Tim Chow suggested I ask y'all. http://www.bgonline.org/forums/webbbs_config.pl?noframes;read=139865 I hope you find this problem interesting enough to give it a shot. Thanks in advance for taking the time to read this message and for hopefully figuring out the answer to the problem.",,"['probability', 'dice']"
44,Taylor series approximation statistics,Taylor series approximation statistics,,"how can I show the following: Let $X_1, X_2,\ldots, X_n$ be i.i.d Poisson with mean $\lambda$. Let $Y =  |\{i: X_i =0\}|$. Then $\lambda$ is estimated by $$\eta = - \log(Y/n)$$ Use Taylor series to find approximation for E($\eta$) and Var($\eta$) Thank you! I dont know around what point to take the Taylor series please help!","how can I show the following: Let $X_1, X_2,\ldots, X_n$ be i.i.d Poisson with mean $\lambda$. Let $Y =  |\{i: X_i =0\}|$. Then $\lambda$ is estimated by $$\eta = - \log(Y/n)$$ Use Taylor series to find approximation for E($\eta$) and Var($\eta$) Thank you! I dont know around what point to take the Taylor series please help!",,"['probability', 'statistics', 'probability-theory', 'statistical-inference']"
45,What are the probabilities of a tie when rolling to see who goes first in a board games for various numbers of dice and various numbers of players?,What are the probabilities of a tie when rolling to see who goes first in a board games for various numbers of dice and various numbers of players?,,"When playing many board games, the first step is to have everyone roll a die to see who goes first, with a roll off in the case of a tie.  While doing that over the Christmas break, my husband suggested that we roll two dice instead of one, with the assertion that this would make ties less likely.  My brother disagreed, claiming it wouldn't make any difference.  I'm interested in investigating this question. I've been able to calculate the probability of ties for the case of rolling one die for any number of players, and the case for rolling two dice with two players.  However, I haven't actually found a general solution in either case (I mostly used a brute force approach in the one die case).  Is anyone here aware of any sources that have investigated this issue? (For the record, I'm pretty sure both my husband and brother have forgotten the conversation, so you don't need to worry about hurting anyone's feelings.  :) )","When playing many board games, the first step is to have everyone roll a die to see who goes first, with a roll off in the case of a tie.  While doing that over the Christmas break, my husband suggested that we roll two dice instead of one, with the assertion that this would make ties less likely.  My brother disagreed, claiming it wouldn't make any difference.  I'm interested in investigating this question. I've been able to calculate the probability of ties for the case of rolling one die for any number of players, and the case for rolling two dice with two players.  However, I haven't actually found a general solution in either case (I mostly used a brute force approach in the one die case).  Is anyone here aware of any sources that have investigated this issue? (For the record, I'm pretty sure both my husband and brother have forgotten the conversation, so you don't need to worry about hurting anyone's feelings.  :) )",,"['probability', 'dice']"
46,Probability of duplicate free sample of iid discrete random sample,Probability of duplicate free sample of iid discrete random sample,,"Let $\{X_1,\ldots,X_n\}$ be independent identically distributed discrete random variables. I am interested in computing the probability of the event that the sample is duplicate free: $$      \mathbb{P}\left( \bigcap_{i<j} \{ X_i \not= X_j\}\right) $$ in terms of $p_2 = \mathbb{P}\left(X_1 = X_2\right)$, $p_3=\mathbb{P}\left(X_1 = X_2 = X_3\right)$, ..., $p_n = \mathbb{P}\left(X_1 = X_2 = X_3=\ldots=X_n\right)$. Special case If $X_k$ are uniformly distributed with the size of the sample space being $d$, this is a classic birthday problem with the answer: $$     \mathbb{P}\left( \bigcap_{i<j} \{ X_i \not= X_j\}\right) = \frac{n!}{d^n} \binom{d}{n} = \sum_{k=1}^n  \frac{s(n,k)}{d^{n-k}} $$ where $s(n,k)$ denotes the Stirling number of the first kind. Motivation Consider IEEE floating point number with mantissa $m$ encoded as $d$-tuple of significant binary digits (i.e. the first bit is always 1), and integer binary exponent $e$. For a random real $0<x<1$, bits are iid Bernoulli(1/2) random variables, and $-e$ is a Geometric(1/2) random variable. I am interested in computing the probability of the size $n$ sample having a duplicate. My approach Applying inclusion-exclusion principle, the complementary probability is  $$   \sum_{i<j} \mathbb{P}\left(X_i = X_j\right) - \sum_{i<j,i<p<q} \mathbb{P}\left(X_i = X_j, X_p=X_q\right)+\ldots = \\ \binom{n}{2} p_2 - 3 \binom{n}{4} p_2^2 - 2 \binom{n}{3} p_3 + \ldots $$ Solutions, ideas, references are welcome.","Let $\{X_1,\ldots,X_n\}$ be independent identically distributed discrete random variables. I am interested in computing the probability of the event that the sample is duplicate free: $$      \mathbb{P}\left( \bigcap_{i<j} \{ X_i \not= X_j\}\right) $$ in terms of $p_2 = \mathbb{P}\left(X_1 = X_2\right)$, $p_3=\mathbb{P}\left(X_1 = X_2 = X_3\right)$, ..., $p_n = \mathbb{P}\left(X_1 = X_2 = X_3=\ldots=X_n\right)$. Special case If $X_k$ are uniformly distributed with the size of the sample space being $d$, this is a classic birthday problem with the answer: $$     \mathbb{P}\left( \bigcap_{i<j} \{ X_i \not= X_j\}\right) = \frac{n!}{d^n} \binom{d}{n} = \sum_{k=1}^n  \frac{s(n,k)}{d^{n-k}} $$ where $s(n,k)$ denotes the Stirling number of the first kind. Motivation Consider IEEE floating point number with mantissa $m$ encoded as $d$-tuple of significant binary digits (i.e. the first bit is always 1), and integer binary exponent $e$. For a random real $0<x<1$, bits are iid Bernoulli(1/2) random variables, and $-e$ is a Geometric(1/2) random variable. I am interested in computing the probability of the size $n$ sample having a duplicate. My approach Applying inclusion-exclusion principle, the complementary probability is  $$   \sum_{i<j} \mathbb{P}\left(X_i = X_j\right) - \sum_{i<j,i<p<q} \mathbb{P}\left(X_i = X_j, X_p=X_q\right)+\ldots = \\ \binom{n}{2} p_2 - 3 \binom{n}{4} p_2^2 - 2 \binom{n}{3} p_3 + \ldots $$ Solutions, ideas, references are welcome.",,"['probability', 'combinatorics', 'reference-request']"
47,Lethal russian roulette (modifed),Lethal russian roulette (modifed),,$21$ players stand in the circle. Every player chooses aim for the shot - another player. No one can shoot themselves or into the air. What the probability that there are at least $2$ players that have taken aim at each other?,$21$ players stand in the circle. Every player chooses aim for the shot - another player. No one can shoot themselves or into the air. What the probability that there are at least $2$ players that have taken aim at each other?,,['probability']
48,Chances of avoiding the diagonal,Chances of avoiding the diagonal,,A circle of radius 1 is randomly placed in a rectangle $ABCD$ so that the circle lies completely inside the rectangle. Length and breadth of rectangles are 36 and 15 respectively. Let the probability that the circle will not touch diagonal $AC$ be $\dfrac mn$. Here $m$ and $n$ are relatively prime positive integers. Find the value of $m + n$. I think this can be done by calculating area .  But I am unable to get it how. Also the diagonal length will be 39 . How can I achieve this?,A circle of radius 1 is randomly placed in a rectangle $ABCD$ so that the circle lies completely inside the rectangle. Length and breadth of rectangles are 36 and 15 respectively. Let the probability that the circle will not touch diagonal $AC$ be $\dfrac mn$. Here $m$ and $n$ are relatively prime positive integers. Find the value of $m + n$. I think this can be done by calculating area .  But I am unable to get it how. Also the diagonal length will be 39 . How can I achieve this?,,"['probability', 'geometry', 'rational-numbers']"
49,"Given n raffles, what is the chance of winning k in a row?","Given n raffles, what is the chance of winning k in a row?",,"I was reading this interesting article about the probability of of tossing heads k times in a row out of n tosses . The final result was $$P = 1-\frac{\operatorname{fib}_k(n+2)}{2^n}\;,$$ where $\operatorname{fib}_k(n)$ is the $n$-th $k$-step Fibonacci number . However, I could not figure out how to adapt it to cases where the probability is not half but just some generic $p$. How do I approach that, and is there a generic solution for all $p$? To be clear, $n$ is the number of raffles, $p$ is the probability of winning a single one, and $k$ is the number of consecutive successes required. $P$ is the desired value.","I was reading this interesting article about the probability of of tossing heads k times in a row out of n tosses . The final result was $$P = 1-\frac{\operatorname{fib}_k(n+2)}{2^n}\;,$$ where $\operatorname{fib}_k(n)$ is the $n$-th $k$-step Fibonacci number . However, I could not figure out how to adapt it to cases where the probability is not half but just some generic $p$. How do I approach that, and is there a generic solution for all $p$? To be clear, $n$ is the number of raffles, $p$ is the probability of winning a single one, and $k$ is the number of consecutive successes required. $P$ is the desired value.",,['probability']
50,The definition of independent discrete random variables,The definition of independent discrete random variables,,"In probability books, the definition of independent discrete random variables are often given as The random variables $X$ and $Y$ are said to be independent if   $\mathbb P(X \leq x, Y \leq y) = \mathbb P(X \leq x) \mathbb P(Y \leq y)$   for any two real numbers $x$ and $y$, where $\mathbb P(X \leq x, Y \leq y)$ represents the   probability of occurrence of both event $\{X \leq x\}$ and event $\{Y \leq y\}$. or $\mathbb P(X \in A, Y \in B) = \mathbb P(X \in A) \mathbb P(Y \in B)$ And the 2 definitions are alleged to be identical.  But the proof is often omitted.  Although it's intuitively correct, I still want to see a proof.  Could anyone show me how to prove this?","In probability books, the definition of independent discrete random variables are often given as The random variables $X$ and $Y$ are said to be independent if   $\mathbb P(X \leq x, Y \leq y) = \mathbb P(X \leq x) \mathbb P(Y \leq y)$   for any two real numbers $x$ and $y$, where $\mathbb P(X \leq x, Y \leq y)$ represents the   probability of occurrence of both event $\{X \leq x\}$ and event $\{Y \leq y\}$. or $\mathbb P(X \in A, Y \in B) = \mathbb P(X \in A) \mathbb P(Y \in B)$ And the 2 definitions are alleged to be identical.  But the proof is often omitted.  Although it's intuitively correct, I still want to see a proof.  Could anyone show me how to prove this?",,['probability']
51,Expected travel time for regularly departing trains,Expected travel time for regularly departing trains,,"I'm going to ask a very simple practical question, but I believe it has some interesting mathematical properties. The simple variant is: trains depart every $x$ minutes and take $y$ minutes to arrive at the destination. How long should a rider expect his journey to take (waiting plus travel)? The more complex variant is: $n$ train lines service the stop. Each of the $i \in \{1, 2, ... n\}$ lines has trains departing every $x_{i}$ minutes and takes $y_{i}$ minutes to arrive at the destination. Assume arrival times are uncorrelated and random across lines. If the rider takes the first train on any line, what is the expected journey time? The final, most complex variant: it may be the case that taking the first train on any line is not optimal. (For example, if one of the train lines takes $y_{j} = 30$ minutes to arrive at the next stop while others take 20 minutes, and the waiting times are such that it doesn't make sense to take the slower train anyway.) Unfortunately I'm at a total loss for how to compute this, practically speaking. Mathematically it's minimizing the expectation over all subsets of $\{1, 2, ... n\}$, but I need to actually compute it so any tips would be helpful. This is more of a CS question so perhaps I'll cross-post to another site.","I'm going to ask a very simple practical question, but I believe it has some interesting mathematical properties. The simple variant is: trains depart every $x$ minutes and take $y$ minutes to arrive at the destination. How long should a rider expect his journey to take (waiting plus travel)? The more complex variant is: $n$ train lines service the stop. Each of the $i \in \{1, 2, ... n\}$ lines has trains departing every $x_{i}$ minutes and takes $y_{i}$ minutes to arrive at the destination. Assume arrival times are uncorrelated and random across lines. If the rider takes the first train on any line, what is the expected journey time? The final, most complex variant: it may be the case that taking the first train on any line is not optimal. (For example, if one of the train lines takes $y_{j} = 30$ minutes to arrive at the next stop while others take 20 minutes, and the waiting times are such that it doesn't make sense to take the slower train anyway.) Unfortunately I'm at a total loss for how to compute this, practically speaking. Mathematically it's minimizing the expectation over all subsets of $\{1, 2, ... n\}$, but I need to actually compute it so any tips would be helpful. This is more of a CS question so perhaps I'll cross-post to another site.",,"['probability', 'algorithms', 'stochastic-processes']"
52,How is a Halton sequence related to a Latin hypercube?,How is a Halton sequence related to a Latin hypercube?,,"I currently use a Halton sequence to choose parameter sets for a prognostic model (e.g. using metabolic rate and protein content parameters to predict growth rate). From my understanding, both a Halton sequence and a Latin Hypercube can be used to evenly sample parameter space. I am reviewing a paper where the author uses a Latin hypercube in the same context that I am using a Halton sequence. How are these approaches related? Are there conditions under which one would be more appropriate?","I currently use a Halton sequence to choose parameter sets for a prognostic model (e.g. using metabolic rate and protein content parameters to predict growth rate). From my understanding, both a Halton sequence and a Latin Hypercube can be used to evenly sample parameter space. I am reviewing a paper where the author uses a Latin hypercube in the same context that I am using a Halton sequence. How are these approaches related? Are there conditions under which one would be more appropriate?",,"['probability', 'algorithms', 'random', 'monte-carlo', 'sampling']"
53,What probability distribution function is this?,What probability distribution function is this?,,"This is sort of a followup to this question (I'll mention everything relevant in this post though so no need to click link). Main Question: I was trying to study a random variable $Y$ . I will describe it here: Suppose we flip a fair coin $L$ times. Then, we let the random variables $X_1, \ldots, X_s$ represent the counts of consecutive runs. For example, if $L = 5$ , and I flip $$HHTHH,$$ then $X_1 = 2$ (two heads), $X_2 = 1$ (followed by one tails), $X_3 = 2$ (followed by two heads). In this example, we let $s$ be the count of the number of consecutive runs (3 in this example). Now, I want to understand the behavior of $Y = \prod (X_i+1)$ as $L \to \infty$ . Specifically, I want to understand how the pdf/cdf of the limiting probability distribution looks like. Originally, I thought this would be a messy probability distribution with nothing interesting about it. However, when I graphed the pmf (histogram with about 200 bins for the log of the value of the RV) for $L = 17$ or $18$ , I got something cool (shown below). Can someone provide some insight into what $Y$ , or $Pr(Y < a)$ is? Thanks! 😁 Please explain this like I’m an undergrad who kinda paid attention in probability class for the first half of the semester. One suggestion for a possible answer (though I am slightly skeptical) : $$Pr(Y < a) \approx Pr\left(\log \prod_{i=1}^{\left\lfloor\frac{L}{2}\right\rfloor} 1 + Geo(1/2) < \log(a)\right)$$ One thing that was suggested was to model each $X_i$ as a geometric random variable $G_i$ . Then, if we let $Z_s = \prod\limits_{i=1}^{s}(G_i + 1)$ , then we take $\log(Z_s)$ , we can use the central limit theorem and send $s \to \infty$ . It was then suggested that since $s$ will be about $L/2$ , we can approximate the distribution (pdf/cdf) of $Y$ with $Z_{\lfloor L/2 \rfloor}$ . While this explains the lognormal shape, I would now like to know why it is this is the case. Specifically, why can we approximate the $X_i$ 's with i.i.d. geometric random variables as $L \to \infty$ (necessary for CLT) and why the ""distribution of $Y$ converges to the distribution of $Z_{\lfloor L/2 \rfloor}$ ."" Specifically, it was suggested that $\mathbb{P}(Y< a)=\mathbb{P}(\log Z_{L/2}< \log  a) =\mathbb{P}\left(\frac{\log Z_{L/2}-L\mu/2}{\sigma\sqrt{L/2}}< \frac{\log a-L\mu/2}{\sigma\sqrt{L/2}}\right)\asymp \Phi\left(\frac{\log a-L\mu/2}{\sigma\sqrt{L/2}}\right)$ This does explain the lognormal shape as expected. If this is the wrong way to approach this problem, please explain why and what I should do instead. And if it is correct, can someone work out the details of this (law of large numbers + CLT analysis details) and as a followup, when is it in general where we can make these approximations? Graph of pmf (looks like lognormal?) Below, I graphed a rough histogram of the distribution of the value of the random variable when $L$ is around 17. Some of the details might be off but theres is some lognormal shape to it and I wish to understand where this shape comes from and whether the random variable $Y$ tends to something nice like that below. THIS GRAPH IS WRONG, NEW GRAPH COMING SOON (BUT STILL LOGNORMAL)","This is sort of a followup to this question (I'll mention everything relevant in this post though so no need to click link). Main Question: I was trying to study a random variable . I will describe it here: Suppose we flip a fair coin times. Then, we let the random variables represent the counts of consecutive runs. For example, if , and I flip then (two heads), (followed by one tails), (followed by two heads). In this example, we let be the count of the number of consecutive runs (3 in this example). Now, I want to understand the behavior of as . Specifically, I want to understand how the pdf/cdf of the limiting probability distribution looks like. Originally, I thought this would be a messy probability distribution with nothing interesting about it. However, when I graphed the pmf (histogram with about 200 bins for the log of the value of the RV) for or , I got something cool (shown below). Can someone provide some insight into what , or is? Thanks! 😁 Please explain this like I’m an undergrad who kinda paid attention in probability class for the first half of the semester. One suggestion for a possible answer (though I am slightly skeptical) : One thing that was suggested was to model each as a geometric random variable . Then, if we let , then we take , we can use the central limit theorem and send . It was then suggested that since will be about , we can approximate the distribution (pdf/cdf) of with . While this explains the lognormal shape, I would now like to know why it is this is the case. Specifically, why can we approximate the 's with i.i.d. geometric random variables as (necessary for CLT) and why the ""distribution of converges to the distribution of ."" Specifically, it was suggested that This does explain the lognormal shape as expected. If this is the wrong way to approach this problem, please explain why and what I should do instead. And if it is correct, can someone work out the details of this (law of large numbers + CLT analysis details) and as a followup, when is it in general where we can make these approximations? Graph of pmf (looks like lognormal?) Below, I graphed a rough histogram of the distribution of the value of the random variable when is around 17. Some of the details might be off but theres is some lognormal shape to it and I wish to understand where this shape comes from and whether the random variable tends to something nice like that below. THIS GRAPH IS WRONG, NEW GRAPH COMING SOON (BUT STILL LOGNORMAL)","Y L X_1, \ldots, X_s L = 5 HHTHH, X_1 = 2 X_2 = 1 X_3 = 2 s Y = \prod (X_i+1) L \to \infty L = 17 18 Y Pr(Y < a) Pr(Y < a) \approx Pr\left(\log \prod_{i=1}^{\left\lfloor\frac{L}{2}\right\rfloor} 1 + Geo(1/2) < \log(a)\right) X_i G_i Z_s = \prod\limits_{i=1}^{s}(G_i + 1) \log(Z_s) s \to \infty s L/2 Y Z_{\lfloor L/2 \rfloor} X_i L \to \infty Y Z_{\lfloor L/2 \rfloor} \mathbb{P}(Y< a)=\mathbb{P}(\log Z_{L/2}< \log  a)
=\mathbb{P}\left(\frac{\log Z_{L/2}-L\mu/2}{\sigma\sqrt{L/2}}< \frac{\log a-L\mu/2}{\sigma\sqrt{L/2}}\right)\asymp \Phi\left(\frac{\log a-L\mu/2}{\sigma\sqrt{L/2}}\right) L Y","['probability', 'combinatorics', 'probability-distributions', 'random-variables', 'central-limit-theorem']"
54,Extreme value theory: asymptotic of the least-rolled number out of a series of rolls,Extreme value theory: asymptotic of the least-rolled number out of a series of rolls,,"Choose positive integers $D$ and $N$ . Roll a fair $D$ -sided die $N$ times, recording the number of times each of the $D$ outcomes are rolled, say $r_1, r_2, \ldots, r_D.$ What are the asymptotics of $\min(r_1, r_2, \ldots, r_D)$ ? They're not independent, so I can't directly apply the Fisher–Tippett–Gnedenko theorem but that's probably a good starting point. If it makes it easier you can assume $N \gg D.$ Of course the leading term is $N/D$ but what’s the second-order term? Maybe $\asymp \sqrt{N/D}$ ?","Choose positive integers and . Roll a fair -sided die times, recording the number of times each of the outcomes are rolled, say What are the asymptotics of ? They're not independent, so I can't directly apply the Fisher–Tippett–Gnedenko theorem but that's probably a good starting point. If it makes it easier you can assume Of course the leading term is but what’s the second-order term? Maybe ?","D N D N D r_1, r_2, \ldots, r_D. \min(r_1, r_2, \ldots, r_D) N \gg D. N/D \asymp \sqrt{N/D}","['probability', 'probability-distributions', 'asymptotics', 'dice', 'extreme-value-analysis']"
55,"Sum of Uniform([-1, 1]) random variables is dense in $\mathbb{R}$ [closed]","Sum of Uniform([-1, 1]) random variables is dense in  [closed]",\mathbb{R},"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 6 months ago . Improve this question Let $X_i, i \in \mathbb{N}$ be a sequence of i.i.d $\text{Uniform}([-1, 1])$ random variables. Let $S_n = X_1 + \cdots + X_n$ . Show that almost surely, the set $\{S_n: n \in \mathbb{N}\}$ is dense in $\mathbb{R}$ . I wonder if there is a way to approach this problem with the Kolmogorov's 0-1 law or the Hewitt-Savage 0-1 law? Besides, I think the Borel-Cantelli lemma could also be useful to solve this problem.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 6 months ago . Improve this question Let be a sequence of i.i.d random variables. Let . Show that almost surely, the set is dense in . I wonder if there is a way to approach this problem with the Kolmogorov's 0-1 law or the Hewitt-Savage 0-1 law? Besides, I think the Borel-Cantelli lemma could also be useful to solve this problem.","X_i, i \in \mathbb{N} \text{Uniform}([-1, 1]) S_n = X_1 + \cdots + X_n \{S_n: n \in \mathbb{N}\} \mathbb{R}","['probability', 'probability-theory']"
56,Bayes' theorem and card colors,Bayes' theorem and card colors,,"This is an expansion/generalization of a previous question I've asked here . Some of the simplifications I made in the original question turned out to be too simplifying, so I'm trying again. The most general case involves millions of cards and hundreds of front/back colors, if that's important for any reason. I have 10 cards. The color of the front of the card is either pink, yellow, or green. The color of the back of the card is orange, blue, or red. Here’s what I know: 5 of the cards have pink fronts, 3 have yellow fronts, and 2 have green fronts. 5 of the cards have orange backs, 1 has a blue back, and 4 have red backs Cards with an orange back can have either a yellow or pink front, but not green Cards with a red back can have either a green or pink front, but not yellow Cards with a blue back can have any color front If you're handed a new card with a pink/yellow/green front, what are the odds that the back is orange/blue/red given that the new card follows the same probability distribution as the 10 old cards? I've simulated the probabilities, and I'm reasonably confident the simulation is accurate, but I don't know how to get the closed-form solutions. The general idea is to create all possible decks that satisfy the constraints, and then count the number of occurrences of each card type in all decks. Simulation code (python): from itertools import permutations  fronts = [""pink""] * 5 + [""yellow""] * 3 + [""green""] * 2 backs = [""orange""] * 5 + [""blue""] * 1 + [""red""] * 4  decks = [list(zip(x, backs)) for x in permutations(fronts, len(backs))] permitted_decks = [d for d in decks if (""green"", ""orange"") not in d and (""yellow"", ""red"") not in d]  unique_decks = [] for deck in permitted_decks:     sorted_deck = sorted(deck)     if sorted_deck not in unique_decks:         unique_decks.append(sorted_deck) print(f""{len(unique_decks)} unique decks"")  counts = {f: {} for f in set(fronts)}  for deck in unique_decks:     for front, back in deck:         counts[front][back] = counts[front].get(back, 0) + 1  for front, back_counts in counts.items():     back_total = sum(back_counts.values())     for back_color, back_count in back_counts.items():         for quantity in [front, back_color, back_count, back_total, round(back_count/back_total, 10)]:             print(quantity, end=""\t"")         print("""")  >>> 3 unique decks >>> yellow  blue    1   9   0.1111111111     >>> yellow  orange  8   9   0.8888888889     >>> pink    orange  7   15  0.4666666667     >>> pink    red     7   15  0.4666666667     >>> pink    blue    1   15  0.0666666667     >>> green   red     5   6   0.8333333333     >>> green   blue    1   6   0.1666666667 Any help would be appreciated. Thanks! EDITED: If you run the simulation and do the counts for permitted_decks instead of unique_decks , by replacing for deck in unique_decks with for deck in permitted_decks , you get different numbers: yellow  orange  604800  691200  0.875   (7/8) yellow  blue    86400   691200  0.125   (1/8) pink    orange  547200  1152000 0.475   (19/40) pink    red     518400  1152000 0.45    (9/20) pink    blue    86400   1152000 0.075   (3/40) green   red     403200  460800  0.875   (7/8) green   blue    57600   460800  0.125   (1/8) So can I infer that even though there are three unique decks, the number of ways I can arrange the sides to create each unique deck is not the same for all decks, so the deck orientations are not equally likely? Here are the counts: 86400 [('green', 'red'), ('green', 'red'), ('pink', 'orange'), ('pink', 'orange'), ('pink', 'orange'), ('pink', 'red'), ('pink', 'red'), ('yellow', 'blue'), ('yellow', 'orange'), ('yellow', 'orange')] ******************** 86400 [('green', 'red'), ('green', 'red'), ('pink', 'blue'), ('pink', 'orange'), ('pink', 'orange'), ('pink', 'red'), ('pink', 'red'), ('yellow', 'orange'), ('yellow', 'orange'), ('yellow', 'orange')] ******************** 57600 [('green', 'blue'), ('green', 'red'), ('pink', 'orange'), ('pink', 'orange'), ('pink', 'red'), ('pink', 'red'), ('pink', 'red'), ('yellow', 'orange'), ('yellow', 'orange'), ('yellow', 'orange')]","This is an expansion/generalization of a previous question I've asked here . Some of the simplifications I made in the original question turned out to be too simplifying, so I'm trying again. The most general case involves millions of cards and hundreds of front/back colors, if that's important for any reason. I have 10 cards. The color of the front of the card is either pink, yellow, or green. The color of the back of the card is orange, blue, or red. Here’s what I know: 5 of the cards have pink fronts, 3 have yellow fronts, and 2 have green fronts. 5 of the cards have orange backs, 1 has a blue back, and 4 have red backs Cards with an orange back can have either a yellow or pink front, but not green Cards with a red back can have either a green or pink front, but not yellow Cards with a blue back can have any color front If you're handed a new card with a pink/yellow/green front, what are the odds that the back is orange/blue/red given that the new card follows the same probability distribution as the 10 old cards? I've simulated the probabilities, and I'm reasonably confident the simulation is accurate, but I don't know how to get the closed-form solutions. The general idea is to create all possible decks that satisfy the constraints, and then count the number of occurrences of each card type in all decks. Simulation code (python): from itertools import permutations  fronts = [""pink""] * 5 + [""yellow""] * 3 + [""green""] * 2 backs = [""orange""] * 5 + [""blue""] * 1 + [""red""] * 4  decks = [list(zip(x, backs)) for x in permutations(fronts, len(backs))] permitted_decks = [d for d in decks if (""green"", ""orange"") not in d and (""yellow"", ""red"") not in d]  unique_decks = [] for deck in permitted_decks:     sorted_deck = sorted(deck)     if sorted_deck not in unique_decks:         unique_decks.append(sorted_deck) print(f""{len(unique_decks)} unique decks"")  counts = {f: {} for f in set(fronts)}  for deck in unique_decks:     for front, back in deck:         counts[front][back] = counts[front].get(back, 0) + 1  for front, back_counts in counts.items():     back_total = sum(back_counts.values())     for back_color, back_count in back_counts.items():         for quantity in [front, back_color, back_count, back_total, round(back_count/back_total, 10)]:             print(quantity, end=""\t"")         print("""")  >>> 3 unique decks >>> yellow  blue    1   9   0.1111111111     >>> yellow  orange  8   9   0.8888888889     >>> pink    orange  7   15  0.4666666667     >>> pink    red     7   15  0.4666666667     >>> pink    blue    1   15  0.0666666667     >>> green   red     5   6   0.8333333333     >>> green   blue    1   6   0.1666666667 Any help would be appreciated. Thanks! EDITED: If you run the simulation and do the counts for permitted_decks instead of unique_decks , by replacing for deck in unique_decks with for deck in permitted_decks , you get different numbers: yellow  orange  604800  691200  0.875   (7/8) yellow  blue    86400   691200  0.125   (1/8) pink    orange  547200  1152000 0.475   (19/40) pink    red     518400  1152000 0.45    (9/20) pink    blue    86400   1152000 0.075   (3/40) green   red     403200  460800  0.875   (7/8) green   blue    57600   460800  0.125   (1/8) So can I infer that even though there are three unique decks, the number of ways I can arrange the sides to create each unique deck is not the same for all decks, so the deck orientations are not equally likely? Here are the counts: 86400 [('green', 'red'), ('green', 'red'), ('pink', 'orange'), ('pink', 'orange'), ('pink', 'orange'), ('pink', 'red'), ('pink', 'red'), ('yellow', 'blue'), ('yellow', 'orange'), ('yellow', 'orange')] ******************** 86400 [('green', 'red'), ('green', 'red'), ('pink', 'blue'), ('pink', 'orange'), ('pink', 'orange'), ('pink', 'red'), ('pink', 'red'), ('yellow', 'orange'), ('yellow', 'orange'), ('yellow', 'orange')] ******************** 57600 [('green', 'blue'), ('green', 'red'), ('pink', 'orange'), ('pink', 'orange'), ('pink', 'red'), ('pink', 'red'), ('pink', 'red'), ('yellow', 'orange'), ('yellow', 'orange'), ('yellow', 'orange')]",,"['probability', 'combinatorics', 'bayes-theorem']"
57,Game: $\frac{1}{3}$ winning probability vs. $\frac{2}{3}$ winning probability,Game:  winning probability vs.  winning probability,\frac{1}{3} \frac{2}{3},"$A$ and $B$ play a round-based game. Each round $A$ wins with probability $\frac{1}{3}$ and $B$ with probability $\frac{2}{3}$ . The loser of a round pays $1$ USD to the winner. The winner of the whole game is the one who wins all the USD from the other player. Now assume that $A$ starts with $n\geq 1$ USD and $B$ with $1$ USD. What is the winning probability of $B$ ? (Hint: Use recursion and the law of total probability) Let be $P(B)$ the probability that $B$ wins the game and $P(B|(k))$ the probability that $B$ wins the game if $B$ has $k\geq 1$ USD. So either one could understand the question in the sense that we must compute $P(B)$ or we must compute $P(B|(1))$ . However, in both cases we must apply law of total probability which requires us to find a disjoint decomposition of $B$ or $(B\cap (1))$ , respectively. As we don't know how the corresponding sets are defined we can't do this. Maybe someone can help me to disentangle this problem or show me how to set up a proper recursion without knowing how the sets look like.","and play a round-based game. Each round wins with probability and with probability . The loser of a round pays USD to the winner. The winner of the whole game is the one who wins all the USD from the other player. Now assume that starts with USD and with USD. What is the winning probability of ? (Hint: Use recursion and the law of total probability) Let be the probability that wins the game and the probability that wins the game if has USD. So either one could understand the question in the sense that we must compute or we must compute . However, in both cases we must apply law of total probability which requires us to find a disjoint decomposition of or , respectively. As we don't know how the corresponding sets are defined we can't do this. Maybe someone can help me to disentangle this problem or show me how to set up a proper recursion without knowing how the sets look like.",A B A \frac{1}{3} B \frac{2}{3} 1 A n\geq 1 B 1 B P(B) B P(B|(k)) B B k\geq 1 P(B) P(B|(1)) B (B\cap (1)),"['probability', 'conditional-probability', 'recursion', 'infinite-games']"
58,"If $(\gcd(a,b), \gcd(b,c), \gcd(c,a))$ form a triangle, what is the probability that $(a,b,c)$ also form a triangle?","If  form a triangle, what is the probability that  also form a triangle?","(\gcd(a,b), \gcd(b,c), \gcd(c,a)) (a,b,c)","Let $A_N$ be set of triplets $(\gcd(a,b), \gcd(b,c), \gcd(c,a))$ , $1\le a \le b \le c \le N$ such that $(\gcd(a,b), \gcd(b,c), \gcd(c,a))$ are the sides of a triangle. Let $B_N$ be the set of triplets $(a,b,c)$ , $1\le a \le b \le c \le N$ , $(\gcd(a,b), \gcd(b,c), \gcd(c,a)) \in A_N$ such that $(a,b,c)$ are the sides a triangle. Let $A(N)$ and $B(N)$ be the number of elements in $A_N$ and $B_N$ respectively. Is the following conjecture true? $$ \lim_{n \to \infty} \frac{A(N)}{B(N)} = \frac{1}{2} $$ Experimental evidence : Out the the first $1,012,270,546$ triplets where $(\gcd(a,b), \gcd(b,c), \gcd(c,a))$ formed a triangle, there were $505,222,520$ triplets of $(a,b,c)$ which also formed a triangle, giving a ratio of $0.499098$ . Increasing the range for the first $24,292,129,662$ triplets $(\gcd(a,b), \gcd(b,c), \gcd(c,a))$ increased the ratio only slightly to $0.499697$ .Thus experimental data indicates that the ratio is possibly $\displaystyle \frac{1}{2}$ . Can this be proved? Note : The converse is different i.e. if $(a,b,c)$ form a triangle then the probability that $(\gcd(a,b), \gcd(b,c), \gcd(c,a))$ also form a triangle is about $0.345$ (not sure if thi converges to a well known constant). Code import math as mt a = 1 t = tg = ttg = 0  while True:     b = 1     while b <= a:         c = 1         while c <= b:             ab = mt.gcd(a,b)             bc = mt.gcd(b,c)             ca = mt.gcd(c,a)                              if ab+bc>ca and bc+ca>ab and ca+ab>bc:                 tg = tg+1                 if a+b>c and b+c > a and c+a>b:                     t = t + 1             c = c + 1         b = b + 1          print(a,tg,t,t/tg)          a = a + 1","Let be set of triplets , such that are the sides of a triangle. Let be the set of triplets , , such that are the sides a triangle. Let and be the number of elements in and respectively. Is the following conjecture true? Experimental evidence : Out the the first triplets where formed a triangle, there were triplets of which also formed a triangle, giving a ratio of . Increasing the range for the first triplets increased the ratio only slightly to .Thus experimental data indicates that the ratio is possibly . Can this be proved? Note : The converse is different i.e. if form a triangle then the probability that also form a triangle is about (not sure if thi converges to a well known constant). Code import math as mt a = 1 t = tg = ttg = 0  while True:     b = 1     while b <= a:         c = 1         while c <= b:             ab = mt.gcd(a,b)             bc = mt.gcd(b,c)             ca = mt.gcd(c,a)                              if ab+bc>ca and bc+ca>ab and ca+ab>bc:                 tg = tg+1                 if a+b>c and b+c > a and c+a>b:                     t = t + 1             c = c + 1         b = b + 1          print(a,tg,t,t/tg)          a = a + 1","A_N (\gcd(a,b), \gcd(b,c), \gcd(c,a)) 1\le a \le b \le c \le N (\gcd(a,b), \gcd(b,c), \gcd(c,a)) B_N (a,b,c) 1\le a \le b \le c \le N (\gcd(a,b), \gcd(b,c), \gcd(c,a)) \in A_N (a,b,c) A(N) B(N) A_N B_N 
\lim_{n \to \infty} \frac{A(N)}{B(N)} = \frac{1}{2}
 1,012,270,546 (\gcd(a,b), \gcd(b,c), \gcd(c,a)) 505,222,520 (a,b,c) 0.499098 24,292,129,662 (\gcd(a,b), \gcd(b,c), \gcd(c,a)) 0.499697 \displaystyle \frac{1}{2} (a,b,c) (\gcd(a,b), \gcd(b,c), \gcd(c,a)) 0.345","['probability', 'number-theory', 'elementary-number-theory', 'triangles', 'divisibility']"
59,Is there a test for convexity?,Is there a test for convexity?,,"This is a very heterodox question. But here is the context. I'm programming a computational package, and the user may write/define a cost function freely, e.g. $$ cost(x,y) = e^{|x-y|} (x-y)^2. $$ Now, the algorithm programmed only works if the cost function is convex. Here is where my question comes in. Would there be some kind of test to verify if the function is indeed convex? Mathematically, we can try to manipulate the function in order to verify whether it satisfies the convexity definition, but this scenario does not allow for such approaches. I was thinking for something like ""sample some points, calculate the function and verify if the mid point is above the linear interpolation"". How many points would be necessary to correctly guess that the function is convex with a certain probability? Any references on this kind of odd question (the probability that a function is convex)?","This is a very heterodox question. But here is the context. I'm programming a computational package, and the user may write/define a cost function freely, e.g. Now, the algorithm programmed only works if the cost function is convex. Here is where my question comes in. Would there be some kind of test to verify if the function is indeed convex? Mathematically, we can try to manipulate the function in order to verify whether it satisfies the convexity definition, but this scenario does not allow for such approaches. I was thinking for something like ""sample some points, calculate the function and verify if the mid point is above the linear interpolation"". How many points would be necessary to correctly guess that the function is convex with a certain probability? Any references on this kind of odd question (the probability that a function is convex)?","
cost(x,y) = e^{|x-y|} (x-y)^2.
","['probability', 'convex-analysis', 'computability']"
60,"Size of an ""average"" $\epsilon$-net on the unit sphere","Size of an ""average"" -net on the unit sphere",\epsilon,"Let $\epsilon>0$ and consider constructing a set $S_\epsilon\subseteq S^{d-1}$ of points on the sphere $\{x\in\mathbb R^d \mid ||x||_2=1\}$ , such that $$ \mathbb E\left[\min_{y\in S_\epsilon}||x-y||_2^2\right]\le \epsilon, $$ where $x$ is a random point on the sphere and the expectation is with respect to the choice of $x$ . How big must $S_\epsilon$ be? I'm looking for a lower bound, although an upper bound may be interesting as well. The motivation for this problem comes from an attempt to prove a lower bound on the number of bits that are needed to send a real-valued vector $x\in\mathbb R^d$ such that the receiver can estimate $x$ to within an ( $\ell_2$ squared) error of $\epsilon||x||_2^2$ . The formulation requires a few extra steps (including Yao's Minimax principle), but this is the component I'm missing.","Let and consider constructing a set of points on the sphere , such that where is a random point on the sphere and the expectation is with respect to the choice of . How big must be? I'm looking for a lower bound, although an upper bound may be interesting as well. The motivation for this problem comes from an attempt to prove a lower bound on the number of bits that are needed to send a real-valued vector such that the receiver can estimate to within an ( squared) error of . The formulation requires a few extra steps (including Yao's Minimax principle), but this is the component I'm missing.","\epsilon>0 S_\epsilon\subseteq S^{d-1} \{x\in\mathbb R^d \mid ||x||_2=1\} 
\mathbb E\left[\min_{y\in S_\epsilon}||x-y||_2^2\right]\le \epsilon,
 x x S_\epsilon x\in\mathbb R^d x \ell_2 \epsilon||x||_2^2","['probability', 'combinatorics', 'geometry', 'expected-value', 'upper-lower-bounds']"
61,Can two random variables $X$ and $Y$ be identically distributed while satisfying $P(X<Y)=1$?,Can two random variables  and  be identically distributed while satisfying ?,X Y P(X<Y)=1,"I realise this is not possible if $X$ and $Y$ are discrete with a finite support and I think it is true in general, but I am having trouble with the continuous and discrete-with-infinite-support cases. Any help would be appreciated.","I realise this is not possible if and are discrete with a finite support and I think it is true in general, but I am having trouble with the continuous and discrete-with-infinite-support cases. Any help would be appreciated.",X Y,"['probability', 'random-variables']"
62,Cat and mouse question,Cat and mouse question,,"I got the following recurrence relations, letting $t_i$ be the expected number of mouse moves to get to room 6 from room $i$ : $$ t_6 = 0\\ t_5 = \frac{1}{2} + \frac{1}{2}(1+t_2)\\ t_4 = 1 + t_1\\ t_3 = 1 + t_2\\ t_2 = \frac{1}{3}(1 + t_5) + \frac{1}{3}(1 + t_1) + \frac{1}{3}(1 + t_3)\\ t_1 = \frac{1}{2}(1 + t_2) + \frac{1}{2}(1 + t_4) $$ which I solved to find $t_1 = 19$ . Does this seem right and does anyone have a quicker way to solve these kinds of questions?","I got the following recurrence relations, letting be the expected number of mouse moves to get to room 6 from room : which I solved to find . Does this seem right and does anyone have a quicker way to solve these kinds of questions?","t_i i 
t_6 = 0\\
t_5 = \frac{1}{2} + \frac{1}{2}(1+t_2)\\
t_4 = 1 + t_1\\
t_3 = 1 + t_2\\
t_2 = \frac{1}{3}(1 + t_5) + \frac{1}{3}(1 + t_1) + \frac{1}{3}(1 + t_3)\\
t_1 = \frac{1}{2}(1 + t_2) + \frac{1}{2}(1 + t_4)
 t_1 = 19","['probability', 'solution-verification', 'markov-chains']"
63,Probability of listening to a song in a shuffled playlist at time $t$?,Probability of listening to a song in a shuffled playlist at time ?,t,"Suppose we have a playlist of $N$ songs, with durations $\{t_1, t_2, \dots, t_N\}$ . The list is set to shuffle indefinitely. This means that, after each song is finished playing, the next song is chosen uniformly at random, so each song, including the one that just played, has an equal probability of playing, regardless of their duration. When the playlist is started, it chooses a song uniformly at random. Let $P_j(t)$ be the probability that the playlist would currently be playing song $j$ after time $t$ has passed since beginning the playlist. Intuitively, I'm sure that in the limit of large $t$ , $P_j(t)$ must converge towards $t_j/\sum_i t_i$ . But is that convergence asymptotic, or is there a hard cutoff time after which that is the distribution? For example, is this the distribution for all $t > \max(\{t_i\})$ ? If so, it's not obvious to me why this might be the case. Also I know that, for all $t < \min(\{t_i\})$ the probability distribution must be uniform. What is $P_j(t)$ in its general form? (Not just the above limits). Is there an analytic form? My attempt: Without loss of generality, order the songs in ascending duration, so $t_1 \le t_2 \le \dots \le t_N$ . But with some loss of generality, let's assume that no two songs have equal duration (a reasonable assumption for continuous time), so $t_1 < \dots < t_N$ . As we know, for $t<t_1$ , the probability distribution is uniform. For $t_1 < t < t_2$ , the only possible song that could have completed is the first song. Assuming $t < 2 t_1$ , $P_1(t) = 1/N^2$ . This is because the only way song $1$ can be playing is if song $1$ was rolled twice in a row. For $j \ne 1$ , $P_j(t) = \frac{N+1}{N^2}.$ That is, either they were rolled initially and are still playing, or song $1$ was rolled, and then song $j$ was rolled afterwards. Now, this doesn't cover the general case for $t_1 < t < t_2$ , only for $t < 2 t_1.$ However, $t_2$ can be any multiple of $t_1$ in principle. Suppose, for example, that $t_2 = 6.5 t_1$ , and $t = 5.5 t_1$ . Then the only way song $1$ can be playing at time $t$ is if it was rolled six times in a row. Thus $P_1(t) = 1/N^6.$ And $P_j(t) = \frac{N^5 + N^4 + N^3 + N^2 + N + 1}{N^6}$ for $j \ne 1$ . This can go on and on, for $t_2$ being any arbitrary multiple of $t_1$ . So it seems like that must be specified: For $(k-1) t_1 < t < k t_1 \le t_2$ , $$P_1(t) = 1/N^k$$ and $$P_j(t) = \frac{\sum_{i=0}^{k-1} N^i}{N^k}; \hspace{1mm} j \ne 1.$$ This approach shows why it's problematic to go anywhere beyond $t = t_2$ . For any interval $t_j < t < t_{j+1}$ , there will be a different discrete expression every time $t$ passes any sum of earlier times. For example, if we're evaluating the probability for $t_8 < t < t_9$ , and the sum $t_2 + 2 t_4 + t_7$ falls within this range, then there will be a different expression before and after that time, because there's a chance that the playlist just finished that sequence. Thus, I believe that a closed-form expression for $P_j(t)$ would take the form of an intractable number of disjoint expressions for different ranges, and for arbitrary $\{t_1, \dots, t_N\}$ it might be impossible to even show an expression, because this involves an arbitrary number of disjoint expressions. If that's true, though, then an answer may still be given for my question to the large- $t$ limit.","Suppose we have a playlist of songs, with durations . The list is set to shuffle indefinitely. This means that, after each song is finished playing, the next song is chosen uniformly at random, so each song, including the one that just played, has an equal probability of playing, regardless of their duration. When the playlist is started, it chooses a song uniformly at random. Let be the probability that the playlist would currently be playing song after time has passed since beginning the playlist. Intuitively, I'm sure that in the limit of large , must converge towards . But is that convergence asymptotic, or is there a hard cutoff time after which that is the distribution? For example, is this the distribution for all ? If so, it's not obvious to me why this might be the case. Also I know that, for all the probability distribution must be uniform. What is in its general form? (Not just the above limits). Is there an analytic form? My attempt: Without loss of generality, order the songs in ascending duration, so . But with some loss of generality, let's assume that no two songs have equal duration (a reasonable assumption for continuous time), so . As we know, for , the probability distribution is uniform. For , the only possible song that could have completed is the first song. Assuming , . This is because the only way song can be playing is if song was rolled twice in a row. For , That is, either they were rolled initially and are still playing, or song was rolled, and then song was rolled afterwards. Now, this doesn't cover the general case for , only for However, can be any multiple of in principle. Suppose, for example, that , and . Then the only way song can be playing at time is if it was rolled six times in a row. Thus And for . This can go on and on, for being any arbitrary multiple of . So it seems like that must be specified: For , and This approach shows why it's problematic to go anywhere beyond . For any interval , there will be a different discrete expression every time passes any sum of earlier times. For example, if we're evaluating the probability for , and the sum falls within this range, then there will be a different expression before and after that time, because there's a chance that the playlist just finished that sequence. Thus, I believe that a closed-form expression for would take the form of an intractable number of disjoint expressions for different ranges, and for arbitrary it might be impossible to even show an expression, because this involves an arbitrary number of disjoint expressions. If that's true, though, then an answer may still be given for my question to the large- limit.","N \{t_1, t_2, \dots, t_N\} P_j(t) j t t P_j(t) t_j/\sum_i t_i t > \max(\{t_i\}) t < \min(\{t_i\}) P_j(t) t_1 \le t_2 \le \dots \le t_N t_1 < \dots < t_N t<t_1 t_1 < t < t_2 t < 2 t_1 P_1(t) = 1/N^2 1 1 j \ne 1 P_j(t) = \frac{N+1}{N^2}. 1 j t_1 < t < t_2 t < 2 t_1. t_2 t_1 t_2 = 6.5 t_1 t = 5.5 t_1 1 t P_1(t) = 1/N^6. P_j(t) = \frac{N^5 + N^4 + N^3 + N^2 + N + 1}{N^6} j \ne 1 t_2 t_1 (k-1) t_1 < t < k t_1 \le t_2 P_1(t) = 1/N^k P_j(t) = \frac{\sum_{i=0}^{k-1} N^i}{N^k}; \hspace{1mm} j \ne 1. t = t_2 t_j < t < t_{j+1} t t_8 < t < t_9 t_2 + 2 t_4 + t_7 P_j(t) \{t_1, \dots, t_N\} t","['probability', 'markov-process']"
64,Prove that two random variables are independent distributed normally,Prove that two random variables are independent distributed normally,,"Let $M$ and $N$ are independent random variables distributed Uniform $[0, 1]$ . Define $(M_n)_{n\geq 1}$ and $(N_n)_{n\geq 1}$ which are two independent sequences of iid random variables distributed uniformly over $[−1, 1]$ . Let $Z = \inf \{ n ≥ 1, 0 < M^2_n + N^2_n< 1 \}$ and $X = M_Z \sqrt{\frac{-2 \log (M_Z^2 + N_Z^2)}{M_Z^2 + N_Z^2}}~~$ and $Y = N_Z \sqrt{\frac{-2 \log (M_Z^2 + N_Z^2)}{M_Z^2 + N_Z^2}}$ What is the distribution of $Z$ ? show that $X$ and $Y$ are two independant random variables distributed $N(0,1)$ . Addition A previous required question related to this exercise is asking to show that $X$ and $Y$ are independent random variables distributed $N(0, 1)$ , knowing that: $ X = \sqrt{-2 \log(M)} \cos(2 \pi N)$ and $Y = \sqrt{-2 \log(M)} \sin(2 \pi N)$ I already proved this part using the change of variables transformation. Then to show that they are independent, the joint density of $X,Y$ can factor into separate densities of $X$ and $Y$ .","Let and are independent random variables distributed Uniform . Define and which are two independent sequences of iid random variables distributed uniformly over . Let and and What is the distribution of ? show that and are two independant random variables distributed . Addition A previous required question related to this exercise is asking to show that and are independent random variables distributed , knowing that: and I already proved this part using the change of variables transformation. Then to show that they are independent, the joint density of can factor into separate densities of and .","M N [0, 1] (M_n)_{n\geq 1} (N_n)_{n\geq 1} [−1, 1] Z = \inf \{ n ≥ 1, 0 < M^2_n + N^2_n< 1 \} X = M_Z \sqrt{\frac{-2 \log (M_Z^2 + N_Z^2)}{M_Z^2 + N_Z^2}}~~ Y = N_Z \sqrt{\frac{-2 \log (M_Z^2 + N_Z^2)}{M_Z^2 + N_Z^2}} Z X Y N(0,1) X Y N(0, 1)  X = \sqrt{-2 \log(M)} \cos(2 \pi N) Y = \sqrt{-2 \log(M)} \sin(2 \pi N) X,Y X Y","['probability', 'probability-distributions', 'random-variables', 'independence']"
65,Please check my solution: probability that there is at least $2 \times 2$ square of just black squares,Please check my solution: probability that there is at least  square of just black squares,2 \times 2,"Suppose I had a $4\times4$ grid. Each square can be colored white, black, or gray. If a grid is colored at random, what is the probability that there is at least one $2\times2$ square of just black squares? Here's my attempt at a solution: There are a total of $3^{16}$ possible colorings. There are also 9 $2\times2$ squares in a $4\times4$ grid. Without loss of generality, assume that the top left square is black. Then there are $3^{12}$ ways that the other squares can be colored. Multiplying, we get $9*3^{12}$ possibilities. Thus, we get the probability $\frac{1}{9}$ . This solution seems too easy, and the probability seems a bit too high. Can someone please help?","Suppose I had a grid. Each square can be colored white, black, or gray. If a grid is colored at random, what is the probability that there is at least one square of just black squares? Here's my attempt at a solution: There are a total of possible colorings. There are also 9 squares in a grid. Without loss of generality, assume that the top left square is black. Then there are ways that the other squares can be colored. Multiplying, we get possibilities. Thus, we get the probability . This solution seems too easy, and the probability seems a bit too high. Can someone please help?",4\times4 2\times2 3^{16} 2\times2 4\times4 3^{12} 9*3^{12} \frac{1}{9},['probability']
66,Probability for a graph algorithm,Probability for a graph algorithm,,"Let $G = (V, E)$ a graph. A 'dominant set' $W ⊆ V$ is a set of nodes, so that for each node $v \in V$ holds that either $v$ itself or a neighbor of $v$ is contained in $W$ .  Assume that $G$ has minimum degree at least $d > 1$ , i.e. each node $v \in V$ has degree $deg(v) ≥ d$ . The algorithm consists of two rounds. In the first round we mark each node independently from the other nodes with probability $p$ . In the second round we look at each node $v \in V$ , if neither $v$ nor any of its neighbours were marked in the first lap, we mark $v$ . Let $X$ be the number of knots marked in the first round. So $E(X) = |V|*p$ , because $X \sim Bin(|V|,p)$ , right ? Let $v ∈ V $ any (but fixed) node. If think the probability that neither v nor one of the neighbors of v was marked in the first round would be $(1-p)^{deg(v)}$ right ? But how can i finde a upper bound  which is only dependent from $d$ and $p$ (and not from $v$ ). Let $Y$ be the number of knots marked in the second round. How can i finde a upper bound for $E(Y)$ .","Let a graph. A 'dominant set' is a set of nodes, so that for each node holds that either itself or a neighbor of is contained in .  Assume that has minimum degree at least , i.e. each node has degree . The algorithm consists of two rounds. In the first round we mark each node independently from the other nodes with probability . In the second round we look at each node , if neither nor any of its neighbours were marked in the first lap, we mark . Let be the number of knots marked in the first round. So , because , right ? Let any (but fixed) node. If think the probability that neither v nor one of the neighbors of v was marked in the first round would be right ? But how can i finde a upper bound  which is only dependent from and (and not from ). Let be the number of knots marked in the second round. How can i finde a upper bound for .","G = (V, E) W ⊆ V v \in V v v W G d > 1 v \in V deg(v) ≥ d p v \in V v v X E(X) = |V|*p X \sim Bin(|V|,p) v ∈ V  (1-p)^{deg(v)} d p v Y E(Y)","['probability', 'probability-theory', 'graph-theory', 'algorithms']"
67,Confidence two biased dice are the same?,Confidence two biased dice are the same?,,"I have 2 biased dice (die 1 and die 2) and I would like to calculate the % confidence they are the same (or different), given $n_1$ rolls of the first die and $n_2$ rolls of the second. Conceptually I'd expect that initially the confidence that they were the same (or different) would be $0$ , and as $n_1$ and $n_2$ increase towards $∞$ the confidence would approach $100\%$ that they are the same (or different). It's relatively trivial to generate a distribution curve of the probability of rolling a specific value on each die, but it's unclear to how how to compare 2 distribution curves (one from each die) to determine the confidence that they are the same or not.","I have 2 biased dice (die 1 and die 2) and I would like to calculate the % confidence they are the same (or different), given rolls of the first die and rolls of the second. Conceptually I'd expect that initially the confidence that they were the same (or different) would be , and as and increase towards the confidence would approach that they are the same (or different). It's relatively trivial to generate a distribution curve of the probability of rolling a specific value on each die, but it's unclear to how how to compare 2 distribution curves (one from each die) to determine the confidence that they are the same or not.",n_1 n_2 0 n_1 n_2 ∞ 100\%,"['probability', 'probability-distributions']"
68,Turning a Biased Coin into an Unbiased one Deterministically,Turning a Biased Coin into an Unbiased one Deterministically,,"Non-deterministic Exact Algorithm There is a simple algorithm to turn a biased coin into a fair one: Flip the coin twice. Identify HT with H and TH with T. Discard cases HH and TT. This algorithm produces a perfectly fair coin, but it is non-deterministic. Deterministic Approximation I also know it is possible to approximate a fair coin with a deterministic algorithm: Let $C_0$ be the biased coin and define $C_1$ by flipping $C_0$ twice. $C_1$ is H if $C_0$ was HH or TT, and $C_1$ is T if $C_0$ was HT or TH. We can see that if the probability that $C_0$ was heads is $p$ , then the probability that $C_1$ is heads is $p_1 = 1 - 2p(1 - p)$ . This is a parabola connecting $(0,1), (.5,.5)$ , and $(1,1)$ and we can see that if we assume $0<p<1$ then the function has a fixed point at $0.5$ . Since $0.5 < p_1 < p$ if $p>0.5$ and $0.5<p_1<1$ if $p<0.5$ , then we can see that a fixed point iteration with $0<p<1$ will always converge to $0.5$ . Therefore, we can find a deterministic $C_i$ that is arbitrarily fair (defined by flipping $C_{i-1}$ twice). My Problem I am trying to find out if, given some biased coin with rational probability of heads $p$ , we can construct an algorithm to solve this problem that is both deterministic and exact. Does anyone have any insights? (Note that the algorithm only has to work for a fixed probability $p$ , since as pointed out in the comments and answer, there are some $p$ , e.g., $p = 1/3$ for which there is no such algorithm.)","Non-deterministic Exact Algorithm There is a simple algorithm to turn a biased coin into a fair one: Flip the coin twice. Identify HT with H and TH with T. Discard cases HH and TT. This algorithm produces a perfectly fair coin, but it is non-deterministic. Deterministic Approximation I also know it is possible to approximate a fair coin with a deterministic algorithm: Let be the biased coin and define by flipping twice. is H if was HH or TT, and is T if was HT or TH. We can see that if the probability that was heads is , then the probability that is heads is . This is a parabola connecting , and and we can see that if we assume then the function has a fixed point at . Since if and if , then we can see that a fixed point iteration with will always converge to . Therefore, we can find a deterministic that is arbitrarily fair (defined by flipping twice). My Problem I am trying to find out if, given some biased coin with rational probability of heads , we can construct an algorithm to solve this problem that is both deterministic and exact. Does anyone have any insights? (Note that the algorithm only has to work for a fixed probability , since as pointed out in the comments and answer, there are some , e.g., for which there is no such algorithm.)","C_0 C_1 C_0 C_1 C_0 C_1 C_0 C_0 p C_1 p_1 = 1 - 2p(1 - p) (0,1), (.5,.5) (1,1) 0<p<1 0.5 0.5 < p_1 < p p>0.5 0.5<p_1<1 p<0.5 0<p<1 0.5 C_i C_{i-1} p p p p = 1/3","['probability', 'combinatorics', 'algorithms']"
69,Convergence of sample mean using CLT,Convergence of sample mean using CLT,,"Assume $X_i$ s are i.i.d. random variables with mean $\mu$ and variance $\sigma^2$ . Prove: $$\lim_{n\to\infty}n^2\mathbb{P}\left(\left|\frac{\sum_{i=1}^{n} X_i}{n}-\mu\right|>n^{-1/4}\right)=0.   \,\,\,\,\,\,\  (1)$$ My effort: I used Chebyshev inequality but did not work. Then, I thought about using the central limit theorem (CLT). By CLT: $$\lim_{n\to\infty}\mathbb{P}\left(\sqrt{n}\left|\frac{\sum_{i=1}^{n} X_i}{n}-\mu\right|>\gamma\right)=1-\mathrm{erf}\left(\frac{\gamma}{\sigma}\right).$$ The problem is that $\gamma$ cannot be a function of $n$ . Otherwise, I could let $\gamma=n^{1/4}$ and prove what I need. Is there a trick I can use here? How can I prove (1)? If (1) only holds for certain conditions, please let me know. Lastly, if we know $X_i=A_i^2 B_i^2$ where $A_i$ and $B_i$ are Gaussian random variables with non-zero means, can we prove (1)?","Assume s are i.i.d. random variables with mean and variance . Prove: My effort: I used Chebyshev inequality but did not work. Then, I thought about using the central limit theorem (CLT). By CLT: The problem is that cannot be a function of . Otherwise, I could let and prove what I need. Is there a trick I can use here? How can I prove (1)? If (1) only holds for certain conditions, please let me know. Lastly, if we know where and are Gaussian random variables with non-zero means, can we prove (1)?","X_i \mu \sigma^2 \lim_{n\to\infty}n^2\mathbb{P}\left(\left|\frac{\sum_{i=1}^{n} X_i}{n}-\mu\right|>n^{-1/4}\right)=0.   \,\,\,\,\,\,\  (1) \lim_{n\to\infty}\mathbb{P}\left(\sqrt{n}\left|\frac{\sum_{i=1}^{n} X_i}{n}-\mu\right|>\gamma\right)=1-\mathrm{erf}\left(\frac{\gamma}{\sigma}\right). \gamma n \gamma=n^{1/4} X_i=A_i^2 B_i^2 A_i B_i","['probability', 'probability-theory', 'convergence-divergence', 'central-limit-theorem', 'concentration-of-measure']"
70,$d_{TV}$ VS correlation coefficient.,VS correlation coefficient.,d_{TV},"Consider two RV $X,Y$. If $d_{TV}(X,Y)=0$ you may couple them in such a way that $$\rho_{XY}=\frac {\operatorname{COV}(X,Y) }{\sigma_X\sigma_Y}=1.$$ So, is there any formula to bound $d_{TV}$ in terms of $\rho$?","Consider two RV $X,Y$. If $d_{TV}(X,Y)=0$ you may couple them in such a way that $$\rho_{XY}=\frac {\operatorname{COV}(X,Y) }{\sigma_X\sigma_Y}=1.$$ So, is there any formula to bound $d_{TV}$ in terms of $\rho$?",,"['probability', 'statistics', 'inequality', 'correlation', 'total-variation']"
71,Computing the sum $\frac{1}{(\frac{1}{n}-p)^{2}}+\frac{1}{(\frac{2}{n}-p)^{2}}+\ldots+\frac{1}{(1-p)^{2}}$,Computing the sum,\frac{1}{(\frac{1}{n}-p)^{2}}+\frac{1}{(\frac{2}{n}-p)^{2}}+\ldots+\frac{1}{(1-p)^{2}},"Let $p\in(0,1)$ and $n$ be a finite positive integer. How to compute the following sum \begin{equation} \frac{1}{(\frac{1}{n}-p)^{2}}+\frac{1}{(\frac{2}{n}-p)^{2}}+\ldots+\frac{1}{(\frac{n-1}{n}-p)^{2}}+\frac{1}{(1-p)^{2}}? \end{equation} I tried substitution and expanding the denominator terms, but it doesn't seem to work. Any hints? Edit $1$: So here is why I want to compute this sum. Let $Z\sim\text{Bin}(n,p)$. I want to compute $\mathbb{E}|\frac{Z}{n}-p|$. Since $U:=|\frac{Z}{n}-p|$ is a non negative random variable taking values in $A:=\{p,|\frac{1}{n}-p|,\ldots,1-p\}$, I have \begin{align} \mathbb{E}|\frac{Z}{n}-p|&=\sum_{t\in A}\mathbb{P}(U>t)\\ &\le \text{var}(U)\sum_{t\in A}\frac{1}{t^{2}}\quad (\text{Chebyshev's inequality}) \end{align} This summation is what appears above. Another way could be to use an exponential bound in the second step. Edit $2$ So a simple upper bound is the following: \begin{align} \mathbb{E}|\frac{Z}{n}-p|&\le \frac{1}{n}\sqrt{\mathbb{E}(Z-np)^{2}}\\ &=\frac{\sqrt{p(1-p)}}{\sqrt{n}}, \end{align} which would be okay for my calculation. Any techniques to compute the sum in question are still welcome.","Let $p\in(0,1)$ and $n$ be a finite positive integer. How to compute the following sum \begin{equation} \frac{1}{(\frac{1}{n}-p)^{2}}+\frac{1}{(\frac{2}{n}-p)^{2}}+\ldots+\frac{1}{(\frac{n-1}{n}-p)^{2}}+\frac{1}{(1-p)^{2}}? \end{equation} I tried substitution and expanding the denominator terms, but it doesn't seem to work. Any hints? Edit $1$: So here is why I want to compute this sum. Let $Z\sim\text{Bin}(n,p)$. I want to compute $\mathbb{E}|\frac{Z}{n}-p|$. Since $U:=|\frac{Z}{n}-p|$ is a non negative random variable taking values in $A:=\{p,|\frac{1}{n}-p|,\ldots,1-p\}$, I have \begin{align} \mathbb{E}|\frac{Z}{n}-p|&=\sum_{t\in A}\mathbb{P}(U>t)\\ &\le \text{var}(U)\sum_{t\in A}\frac{1}{t^{2}}\quad (\text{Chebyshev's inequality}) \end{align} This summation is what appears above. Another way could be to use an exponential bound in the second step. Edit $2$ So a simple upper bound is the following: \begin{align} \mathbb{E}|\frac{Z}{n}-p|&\le \frac{1}{n}\sqrt{\mathbb{E}(Z-np)^{2}}\\ &=\frac{\sqrt{p(1-p)}}{\sqrt{n}}, \end{align} which would be okay for my calculation. Any techniques to compute the sum in question are still welcome.",,"['probability', 'sequences-and-series', 'algebra-precalculus', 'summation', 'expectation']"
72,Is this proof of indepencence of two events circular?,Is this proof of indepencence of two events circular?,,"Task (I freely admit it is from a former test): We choose a random person $X$ and it turns out that this person has three siblings, with at least one older sister among them. A) What is the probability that $X$ is a girl? B) What is the probability that the second oldest child of this familily is a girl? C) What is the probability that $X$ is the youngest child of this family? D) Let $A$, $B$, $C$ denote the above events. Which pairs are independent: $(A, B)$, $(A, C)$, $(B, C)$? Validate each answer. Note: Assume that, regarding each birth, the events: a boy is born and a girl is born have the same probability $p=\frac12$ (we do not take into account the possibility of twins being born, etc), and these events are independent from any former births. My solution attempt: A) $\frac12$, from the independence of birhts. Before we go to B), C), D), let's list all legal combinations: If $X$ is the second oldest kid: $b/g\quad b/g\quad X_{b/g}\quad g$ - this gives $8$ combinations If $X$ is the third oldest kid: $b/g \quad X_{b/g}\quad b/g \quad b/g$ - this would be $4\cdot 4$ combinations, but we must exclude the illegal combination that two oldest kids are all boys, so it's $4\cdot 3 = 12$ combinations If $X$ is the youngest kid: $X_{b/g} \quad b/g \quad b/g \quad b/g$ - Excluding the illegal combination that all older kids are all boys this gives us $2\cdot7=14$ combinations So we have a total of $34$ legal combinations. B) Let's list legal combinations: $b/g\quad b/g\quad X_g \quad g$ - $4$ combinations $b/g \quad X_{b/g} \quad g \quad b/g$ - $8$ combinations $X_{b/g} \quad b/g \quad g \quad b/g$ - $8$ combinations Thus the probability is $\frac{4+8+8}{34}=\frac{10}{17}$ C) Above we showed that there are $14$ legal combinations in such a case, so the answer is $\frac{14}{34}=\frac{7}{17}$ D) And here be dragons, I guess. This is how I'd tackle this: $(A, B)$: All legal combinations for the event $A\cap B$ are: $b/g\quad b/g \quad X_g \quad g$ - $4$ combinations $b/g \quad X_g \quad g \quad b/g$ - $4$ combinations $X_g\quad b/g\quad g\quad b/g$ - $4$ combinations $12$ combinations total, so $P(A\cap B) = \frac {12}{34} \neq \frac12\cdot \frac{20}{34} = P(A)\cdot P(B)$, so by definition $A$ and $B$ are not independent. $(A,C)$: There are $7$ legal combinations for the event $A\cap C$: $X_g\quad b/g \quad b/g \quad b/g$, this would be $8$ but we must exclude the illegal combination $X_g \quad b \quad b \quad b$ Therefore $P(A\cap C) = \frac7{34} = \frac12 \cdot \frac {14}{34} = P(A)\cdot P(B)$, so by definition these events are independent $(B, C)$: THere are $8$ legal combinations: $X_{b/g} \quad b/g \quad g \quad b/g$ So we have $P(B\cap C) = \frac8{34} = \frac 4{17}$ But $P(B)\cdot P(C) = \frac7{17}\cdot \frac{10}{17} \neq \frac 4{17}$ So by definition these events are not independent. My worry is: I used the classical definition of probability for each part of the task. But I can only use the classical definition if the permutation of children in this famility is independent of their sex; so, essentialy, I can only use the classical definition if $(A, C)$ are independent. However, it was my task to prove that $A$ and $C$ are really independent, and I used the classical definition to prove it... So, in the end, am I not guilty of circular reasoning here?","Task (I freely admit it is from a former test): We choose a random person $X$ and it turns out that this person has three siblings, with at least one older sister among them. A) What is the probability that $X$ is a girl? B) What is the probability that the second oldest child of this familily is a girl? C) What is the probability that $X$ is the youngest child of this family? D) Let $A$, $B$, $C$ denote the above events. Which pairs are independent: $(A, B)$, $(A, C)$, $(B, C)$? Validate each answer. Note: Assume that, regarding each birth, the events: a boy is born and a girl is born have the same probability $p=\frac12$ (we do not take into account the possibility of twins being born, etc), and these events are independent from any former births. My solution attempt: A) $\frac12$, from the independence of birhts. Before we go to B), C), D), let's list all legal combinations: If $X$ is the second oldest kid: $b/g\quad b/g\quad X_{b/g}\quad g$ - this gives $8$ combinations If $X$ is the third oldest kid: $b/g \quad X_{b/g}\quad b/g \quad b/g$ - this would be $4\cdot 4$ combinations, but we must exclude the illegal combination that two oldest kids are all boys, so it's $4\cdot 3 = 12$ combinations If $X$ is the youngest kid: $X_{b/g} \quad b/g \quad b/g \quad b/g$ - Excluding the illegal combination that all older kids are all boys this gives us $2\cdot7=14$ combinations So we have a total of $34$ legal combinations. B) Let's list legal combinations: $b/g\quad b/g\quad X_g \quad g$ - $4$ combinations $b/g \quad X_{b/g} \quad g \quad b/g$ - $8$ combinations $X_{b/g} \quad b/g \quad g \quad b/g$ - $8$ combinations Thus the probability is $\frac{4+8+8}{34}=\frac{10}{17}$ C) Above we showed that there are $14$ legal combinations in such a case, so the answer is $\frac{14}{34}=\frac{7}{17}$ D) And here be dragons, I guess. This is how I'd tackle this: $(A, B)$: All legal combinations for the event $A\cap B$ are: $b/g\quad b/g \quad X_g \quad g$ - $4$ combinations $b/g \quad X_g \quad g \quad b/g$ - $4$ combinations $X_g\quad b/g\quad g\quad b/g$ - $4$ combinations $12$ combinations total, so $P(A\cap B) = \frac {12}{34} \neq \frac12\cdot \frac{20}{34} = P(A)\cdot P(B)$, so by definition $A$ and $B$ are not independent. $(A,C)$: There are $7$ legal combinations for the event $A\cap C$: $X_g\quad b/g \quad b/g \quad b/g$, this would be $8$ but we must exclude the illegal combination $X_g \quad b \quad b \quad b$ Therefore $P(A\cap C) = \frac7{34} = \frac12 \cdot \frac {14}{34} = P(A)\cdot P(B)$, so by definition these events are independent $(B, C)$: THere are $8$ legal combinations: $X_{b/g} \quad b/g \quad g \quad b/g$ So we have $P(B\cap C) = \frac8{34} = \frac 4{17}$ But $P(B)\cdot P(C) = \frac7{17}\cdot \frac{10}{17} \neq \frac 4{17}$ So by definition these events are not independent. My worry is: I used the classical definition of probability for each part of the task. But I can only use the classical definition if the permutation of children in this famility is independent of their sex; so, essentialy, I can only use the classical definition if $(A, C)$ are independent. However, it was my task to prove that $A$ and $C$ are really independent, and I used the classical definition to prove it... So, in the end, am I not guilty of circular reasoning here?",,"['probability', 'proof-verification']"
73,"Mentally generating a (pseudo)random {0,1}-sequence with uniform distribution","Mentally generating a (pseudo)random {0,1}-sequence with uniform distribution",,"I want to learn of good ways by which to generate $\{0,1 \}$ -sequences in my head which are (pseudo)random with uniform distribution, so that I may simulate flipping a fair two-sided, standard coin. I want to do this because sometimes, I need to pick an option randomly, but I have no equipment (such as a coin or a random number generator) handy - and I am scared of having cognitive biases creep in. The trick/constraints in this challenge include(s): the fact that I am not an exceptionally skilled mental calculator and I may need to generate these numbers under pressure or quickly; I want the sequence (if it is pseudorandom) to have a fairly large period so that I can generate values many times in the same situation (say, in order to make several consecutive decisions over the course of a few seconds or minutes) without falling into an apparent pattern. I may add other constraints too. But the basic idea is that the method needs to be robust and versatile, but also reasonable in human situations. And, of course, it has to be free of cognitive biases or other failings, except for calculation accuracy and possibly choosing the initial values. Bonus points if it generalizes easily to $\{0, 1, \ldots, n \}$ -sequences for small $n$ , such that the method is still easy (etc.) to use Thank you very much","I want to learn of good ways by which to generate -sequences in my head which are (pseudo)random with uniform distribution, so that I may simulate flipping a fair two-sided, standard coin. I want to do this because sometimes, I need to pick an option randomly, but I have no equipment (such as a coin or a random number generator) handy - and I am scared of having cognitive biases creep in. The trick/constraints in this challenge include(s): the fact that I am not an exceptionally skilled mental calculator and I may need to generate these numbers under pressure or quickly; I want the sequence (if it is pseudorandom) to have a fairly large period so that I can generate values many times in the same situation (say, in order to make several consecutive decisions over the course of a few seconds or minutes) without falling into an apparent pattern. I may add other constraints too. But the basic idea is that the method needs to be robust and versatile, but also reasonable in human situations. And, of course, it has to be free of cognitive biases or other failings, except for calculation accuracy and possibly choosing the initial values. Bonus points if it generalizes easily to -sequences for small , such that the method is still easy (etc.) to use Thank you very much","\{0,1 \} \{0, 1, \ldots, n \} n","['probability', 'random-variables', 'random', 'mental-arithmetic']"
74,Expectation of Maximum Frequency,Expectation of Maximum Frequency,,I saw this question in a blog but do not know how to solve it. Question: There are K balls in a sack numbered 1 to K. Bob chooses a ball at random and notes down its number and then puts it back in sack. He does this process for N times. What is the expected value of the frequency of the most frequent element?,I saw this question in a blog but do not know how to solve it. Question: There are K balls in a sack numbered 1 to K. Bob chooses a ball at random and notes down its number and then puts it back in sack. He does this process for N times. What is the expected value of the frequency of the most frequent element?,,"['probability', 'combinatorics', 'random-variables', 'expectation', 'puzzle']"
75,Using Normal distribution for a random sample.,Using Normal distribution for a random sample.,,"The weights of a group of people are distributed on a normal curve with $\mu = 172$, $\sigma = 30$. What is the probability that the average weight of a sample of $9$ people is less than $177$? My attempt: Define $X_A = \frac{X_1+X_2+X_3+X_...+X_9}{9}$, where $X_i$ are random variables representing the weights of each man. Then $E[X_A] = 172$, and $Var[X_A] = \frac{30^2}{9}$. Then $Z = \frac{X_A-172}{10} $, The answer is the area to the left of $0.5$ in the standard normal curve, which is $0.6915$ (from a table). Is this right?","The weights of a group of people are distributed on a normal curve with $\mu = 172$, $\sigma = 30$. What is the probability that the average weight of a sample of $9$ people is less than $177$? My attempt: Define $X_A = \frac{X_1+X_2+X_3+X_...+X_9}{9}$, where $X_i$ are random variables representing the weights of each man. Then $E[X_A] = 172$, and $Var[X_A] = \frac{30^2}{9}$. Then $Z = \frac{X_A-172}{10} $, The answer is the area to the left of $0.5$ in the standard normal curve, which is $0.6915$ (from a table). Is this right?",,"['probability', 'statistics', 'probability-distributions']"
76,Conditional Expectation with elliptical random variables,Conditional Expectation with elliptical random variables,,"In a paper I am reading it is written the following: Let $X = (X_1, \dots, X_n) \sim E_n(\mu, \Sigma, \phi)$ be a   elliptical-distributed random vector; let $S = \sum_{i = 1}^n X_i$.   Then $$E[X_k \mid S=s] = \mu_k + \frac{\sigma_{k,S}}{\sigma_{S}^2}(s -  \mu_S)$$   where $\mu_k$ is the mean of $X_k$, $\mu_S, \sigma^2_S$ are the mean and variance of $S$, and $\sigma_{k,S}$ is the covariance between $X_k$ and $S$ I have tried to prove this but without luck. Can anybody help? Thoughts I tried the following: $$E[X_k \mid S=s] = \int xf_{X_k \mid S = s}(x) dx$$ Since $$f_{X_k \mid S = s}(x)  = \frac{f_{(X_k, S)}(x,s)}{f_S(s)}$$ I get $$E[X_k \mid S=s] = \frac 1{f_S(s)} \int x f_{(X_k, S)}(x,s) dx$$ I know the distribution of the vector $(X_k, S)$ (Since it is a linear transformation of the vector $X$, it is still elliptical distributed and I can compute it's mean and variance; the elliptical generator $\phi$  is still the same). But how to simplify it further to get to the result stated in the paper?","In a paper I am reading it is written the following: Let $X = (X_1, \dots, X_n) \sim E_n(\mu, \Sigma, \phi)$ be a   elliptical-distributed random vector; let $S = \sum_{i = 1}^n X_i$.   Then $$E[X_k \mid S=s] = \mu_k + \frac{\sigma_{k,S}}{\sigma_{S}^2}(s -  \mu_S)$$   where $\mu_k$ is the mean of $X_k$, $\mu_S, \sigma^2_S$ are the mean and variance of $S$, and $\sigma_{k,S}$ is the covariance between $X_k$ and $S$ I have tried to prove this but without luck. Can anybody help? Thoughts I tried the following: $$E[X_k \mid S=s] = \int xf_{X_k \mid S = s}(x) dx$$ Since $$f_{X_k \mid S = s}(x)  = \frac{f_{(X_k, S)}(x,s)}{f_S(s)}$$ I get $$E[X_k \mid S=s] = \frac 1{f_S(s)} \int x f_{(X_k, S)}(x,s) dx$$ I know the distribution of the vector $(X_k, S)$ (Since it is a linear transformation of the vector $X$, it is still elliptical distributed and I can compute it's mean and variance; the elliptical generator $\phi$  is still the same). But how to simplify it further to get to the result stated in the paper?",,"['probability', 'integration', 'probability-theory', 'expectation', 'conditional-expectation']"
77,Proof of Wald's second identity?,Proof of Wald's second identity?,,"I am very confused about the last step in the proof. If $\lim_{n\to\infty}ES_{\tau}^21_{\tau>n}=0$ then use the decomposition $S_{\tau}=S_n+(S_{\tau}-S_n)$, I get $\lim_{n\to\infty}E((S_{n}^2+2S_n(S_{\tau}-S_n)+(S_{\tau}-S_n)^2)1_{\tau>n})=0$, then we need $\lim_{n\to\infty}E((2S_n(S_{\tau}-S_n)+(S_{\tau}-S_n)^2)1_{\tau>n})=0$ to show $\lim_{n\to\infty}E((S_n)^21_{\tau>n})=0$. Then $S_n$ and $S_{\tau}-S_n$ are independent, so $\lim_{n\to\infty}E(2S_n(S_{\tau}-S_n)1_{\tau>n})=\lim_{n\to\infty}E(2S_n)E(S_{\tau}-S_n)=0$?(Not sure about this step since $\tau$ is unbounded.) Then we still need to show $\lim_{n\to\infty}E((S_{\tau}-S_n)^2)1_{\tau>n})=0$, why the lecture note says we need to show $\lim_{n\to\infty}E((S_{\tau}-S_n))1_{\tau>n}|\mathscr{F}_n)=0$?","I am very confused about the last step in the proof. If $\lim_{n\to\infty}ES_{\tau}^21_{\tau>n}=0$ then use the decomposition $S_{\tau}=S_n+(S_{\tau}-S_n)$, I get $\lim_{n\to\infty}E((S_{n}^2+2S_n(S_{\tau}-S_n)+(S_{\tau}-S_n)^2)1_{\tau>n})=0$, then we need $\lim_{n\to\infty}E((2S_n(S_{\tau}-S_n)+(S_{\tau}-S_n)^2)1_{\tau>n})=0$ to show $\lim_{n\to\infty}E((S_n)^21_{\tau>n})=0$. Then $S_n$ and $S_{\tau}-S_n$ are independent, so $\lim_{n\to\infty}E(2S_n(S_{\tau}-S_n)1_{\tau>n})=\lim_{n\to\infty}E(2S_n)E(S_{\tau}-S_n)=0$?(Not sure about this step since $\tau$ is unbounded.) Then we still need to show $\lim_{n\to\infty}E((S_{\tau}-S_n)^2)1_{\tau>n})=0$, why the lecture note says we need to show $\lim_{n\to\infty}E((S_{\tau}-S_n))1_{\tau>n}|\mathscr{F}_n)=0$?",,"['probability', 'probability-theory']"
78,A graph theoretical/combinatorial problem,A graph theoretical/combinatorial problem,,"I'll try to describe a problem that I am currently working on, hoping to get some direction out of anyone possibly interested in the problem. Let $G_1=([n],E_1), G_2=([n],E_2)$, such that $E_1\bigcup E_2 = {[n]\choose 2}, E_1\bigcap E_2 = \emptyset$. I.e. $E_1$ and $E_2$ form a partition of the complete graph. Observe the following process, consisting of two sides, god and the devil. At each step the devil chooses a graph, for example - $G_1$, and constructs a partition of its edges into two subsets, say $A, B$, i.e. $A\bigcup B = E_1$ and $A\bigcap B = \emptyset$. God, in his turn can choose either $A$ or $B$, say he chose $A$, now $G_1=([n],A)$. And they continue to another iteration. God's objective is to maximize the set of vertices $V:=\{i\in[n]|d_1(i),d_2(i) > 0\}$. I.e., to maximize the set of vertices with positive degree on both graphs, while the devil's goal is adverserial, he wishes to form partitions that would minimize the size $|V|$. I can prove that for all graphs $G_1,G_2$ such that all vertices have degree of $n/2(1\pm o(1))$, and for all adversarial strategies of the devil, there exists a strategy for god (a choice of partitions) such that after $k$ steps, $|V|\ge\dfrac{n}{2^k}$. My goal is to show that there exist graphs $G_1, G_2$ such that for all adversarial strategies, there exist counter strategies that would guaranty $|V|\ge\dfrac{n}{2^{k/2}}$. It can be shown using chernoff that the degree requirement holds for $G_1$ chosen according to $G(n,0.5)$ and $G_2$ being its complement with high probability. Some thoughts: I am convinced that with high probability choosing $G_1=G_{n,0.5}$ and $G_2$ to be its complement would be good candidates for the conjecture. Simply choosing the side with the larger cardinality at each step doesn't work. I have constructed a simple strategy that dictates god's choice at each step according to the following rule, that I suspect to be optimal strategy but I am short of proving it: Given a partition of $G_1$'s edges into two subsets $A$ and $B$, choose the set that maximizes $\Sigma_{(u,v)\in C}d_2(u) + d_2(v)$ for $C\in \{A,B\}$. The idea is defining a potential function $\Phi = \Sigma_{(u,v)\in E_1}d_2(u) + d_2(v)$ and taking notice that for a partition of $E_1$ into $A,B$ it holds that: $\Phi = \Sigma_{E_1} = \Sigma_A + \Sigma_B$, therefore there is a choice of either $A$ or $B$ that decreases $\Phi$ by a factor of at most $2$. $\Phi$ is also symmetric as it can be rewritten as $\Sigma_{i\in [n]}d_1(i)d_2(i)$. It can be (easily) shown that choosing according to this strategy guaranties $|V|\ge\dfrac{n}{2^k}$ for all graphs. I suspect that it is an optimal strategy that would also yield the conjectured lower bound for the random graph $G(n,0.5)$ and its complement. This is the problem, and those are some of my main thoughts. A simpler problem that I also can't solve would be to show that for 2 steps I can guaranty $|V|\ge n/2$. I hope I was clear, and will remain available to make any clarifications required. Edit: I am interested in proving that there exists a strategy for the case where $k\le c\log n$ for some $c\in (0,1)$ and in particular would be happy in showing, as stated above, the existence of such strategy in case $k=2$. Thanks! :)","I'll try to describe a problem that I am currently working on, hoping to get some direction out of anyone possibly interested in the problem. Let $G_1=([n],E_1), G_2=([n],E_2)$, such that $E_1\bigcup E_2 = {[n]\choose 2}, E_1\bigcap E_2 = \emptyset$. I.e. $E_1$ and $E_2$ form a partition of the complete graph. Observe the following process, consisting of two sides, god and the devil. At each step the devil chooses a graph, for example - $G_1$, and constructs a partition of its edges into two subsets, say $A, B$, i.e. $A\bigcup B = E_1$ and $A\bigcap B = \emptyset$. God, in his turn can choose either $A$ or $B$, say he chose $A$, now $G_1=([n],A)$. And they continue to another iteration. God's objective is to maximize the set of vertices $V:=\{i\in[n]|d_1(i),d_2(i) > 0\}$. I.e., to maximize the set of vertices with positive degree on both graphs, while the devil's goal is adverserial, he wishes to form partitions that would minimize the size $|V|$. I can prove that for all graphs $G_1,G_2$ such that all vertices have degree of $n/2(1\pm o(1))$, and for all adversarial strategies of the devil, there exists a strategy for god (a choice of partitions) such that after $k$ steps, $|V|\ge\dfrac{n}{2^k}$. My goal is to show that there exist graphs $G_1, G_2$ such that for all adversarial strategies, there exist counter strategies that would guaranty $|V|\ge\dfrac{n}{2^{k/2}}$. It can be shown using chernoff that the degree requirement holds for $G_1$ chosen according to $G(n,0.5)$ and $G_2$ being its complement with high probability. Some thoughts: I am convinced that with high probability choosing $G_1=G_{n,0.5}$ and $G_2$ to be its complement would be good candidates for the conjecture. Simply choosing the side with the larger cardinality at each step doesn't work. I have constructed a simple strategy that dictates god's choice at each step according to the following rule, that I suspect to be optimal strategy but I am short of proving it: Given a partition of $G_1$'s edges into two subsets $A$ and $B$, choose the set that maximizes $\Sigma_{(u,v)\in C}d_2(u) + d_2(v)$ for $C\in \{A,B\}$. The idea is defining a potential function $\Phi = \Sigma_{(u,v)\in E_1}d_2(u) + d_2(v)$ and taking notice that for a partition of $E_1$ into $A,B$ it holds that: $\Phi = \Sigma_{E_1} = \Sigma_A + \Sigma_B$, therefore there is a choice of either $A$ or $B$ that decreases $\Phi$ by a factor of at most $2$. $\Phi$ is also symmetric as it can be rewritten as $\Sigma_{i\in [n]}d_1(i)d_2(i)$. It can be (easily) shown that choosing according to this strategy guaranties $|V|\ge\dfrac{n}{2^k}$ for all graphs. I suspect that it is an optimal strategy that would also yield the conjectured lower bound for the random graph $G(n,0.5)$ and its complement. This is the problem, and those are some of my main thoughts. A simpler problem that I also can't solve would be to show that for 2 steps I can guaranty $|V|\ge n/2$. I hope I was clear, and will remain available to make any clarifications required. Edit: I am interested in proving that there exists a strategy for the case where $k\le c\log n$ for some $c\in (0,1)$ and in particular would be happy in showing, as stated above, the existence of such strategy in case $k=2$. Thanks! :)",,"['probability', 'combinatorics', 'graph-theory', 'random-graphs', 'research']"
79,Probability of Choosing an Item in Weighted Random Sampling Without Replacement,Probability of Choosing an Item in Weighted Random Sampling Without Replacement,,"Consider the problem of randomly sampling $k$ distinct items from a population of $n$ items without replacement. If all items have the same weight, then the probability that a specific item is among the $k$ selected items is $\binom{n-1}{k-1} / \binom{n}{k}$. Now suppose that items are weighted and the probability of each item being selected is determined by its relative weight: Input: Set $N=\{1,\dots,n\}$ items with weights $W=\{w_1,\dots,w_n\}$ Output: Set $S$ of $k$ randomly selected items without replacement Repeat k times probability of $i \in N \setminus S$ being selected = $\frac{w_i}{\sum_{j\in N \setminus S}w_j}$ randomly select an item from $N \setminus S$ and add it to $S$. What is the probability that a specific item is among the $k$ selected items in weighted random sampling without replacement?","Consider the problem of randomly sampling $k$ distinct items from a population of $n$ items without replacement. If all items have the same weight, then the probability that a specific item is among the $k$ selected items is $\binom{n-1}{k-1} / \binom{n}{k}$. Now suppose that items are weighted and the probability of each item being selected is determined by its relative weight: Input: Set $N=\{1,\dots,n\}$ items with weights $W=\{w_1,\dots,w_n\}$ Output: Set $S$ of $k$ randomly selected items without replacement Repeat k times probability of $i \in N \setminus S$ being selected = $\frac{w_i}{\sum_{j\in N \setminus S}w_j}$ randomly select an item from $N \setminus S$ and add it to $S$. What is the probability that a specific item is among the $k$ selected items in weighted random sampling without replacement?",,"['probability', 'statistics', 'sampling']"
80,Chance of flipping 50 heads over a span of 100 flips given more than 100 flips,Chance of flipping 50 heads over a span of 100 flips given more than 100 flips,,"So I found that the chance of flipping 50 heads out of a string of 100 flips is $$0.5^{50} (1-0.5)^{50} \binom{100}{50},$$ My question is, how do the chances of having at least 1 string of 100 flips, with heads resulting 50 times, change if I am allowed to flip the coin 101 times?  In other words, I could get 50 out of 100 in flips 1-100 OR 50 out of 100 in flips 2-101 or both. What about if I were allowed to flip the coin 200 times, but needed to get at least one string of 100 flips resulting in 50 heads? My thinking is that there are 101 different 100 flip sequences in a 200 flip sequence, and each of those 101 sequences should have $$0.5^{50} (1-0.5)^{50} \binom{100}{50},$$ probability of yielding heads exactly 50 times, which would multiply the probability by 101 times, but since the 101 different 100 flip sequences are overlapping, rather than being independent of each other, does it change the odds?","So I found that the chance of flipping 50 heads out of a string of 100 flips is $$0.5^{50} (1-0.5)^{50} \binom{100}{50},$$ My question is, how do the chances of having at least 1 string of 100 flips, with heads resulting 50 times, change if I am allowed to flip the coin 101 times?  In other words, I could get 50 out of 100 in flips 1-100 OR 50 out of 100 in flips 2-101 or both. What about if I were allowed to flip the coin 200 times, but needed to get at least one string of 100 flips resulting in 50 heads? My thinking is that there are 101 different 100 flip sequences in a 200 flip sequence, and each of those 101 sequences should have $$0.5^{50} (1-0.5)^{50} \binom{100}{50},$$ probability of yielding heads exactly 50 times, which would multiply the probability by 101 times, but since the 101 different 100 flip sequences are overlapping, rather than being independent of each other, does it change the odds?",,"['probability', 'sequences-and-series']"
81,Probability that the roots of a quadratic equation are real,Probability that the roots of a quadratic equation are real,,"Roots of the quadratic equation $x^2+5x+3=0$ are $4\sin^2\alpha+a$ and $4\cos^2\alpha+a$. Another quadratic equation is  $x^2+px+q=0$ where $p,q\in\mathbb{N}$ and $p,q\in[1,10]$. Find the probability that the roots of second  quadratic equation are real and that they are $4sin^4\alpha+b$ and $4\cos^4\alpha+b$. $$p^2-4q\ge 0$$ If $p=1$, then no possibilities. If $p=2$, then $q=1$. If $p=7,8,9,10$, then $q\in[1,10]$. But in this way there may be repetitions. I need to find the number quadratic equations first and then I can use the fact the difference in roots for both equations is same to reduce the total possibilities.","Roots of the quadratic equation $x^2+5x+3=0$ are $4\sin^2\alpha+a$ and $4\cos^2\alpha+a$. Another quadratic equation is  $x^2+px+q=0$ where $p,q\in\mathbb{N}$ and $p,q\in[1,10]$. Find the probability that the roots of second  quadratic equation are real and that they are $4sin^4\alpha+b$ and $4\cos^4\alpha+b$. $$p^2-4q\ge 0$$ If $p=1$, then no possibilities. If $p=2$, then $q=1$. If $p=7,8,9,10$, then $q\in[1,10]$. But in this way there may be repetitions. I need to find the number quadratic equations first and then I can use the fact the difference in roots for both equations is same to reduce the total possibilities.",,"['probability', 'algebra-precalculus', 'trigonometry', 'quadratics']"
82,Sum of matrix vector products,Sum of matrix vector products,,"Consider a sequence of fixed non-singular $n$ by $n$ matrices $A_i$ whose entries are chosen from $\{0,1\}$ and a sequence of independent random $n$ dimensional vectors $x_i$ whose entries are also chosen independently from $\{0,1\}$ . Assume $n$ is large. We know $H(A_ix_i) = n$. This is because $A_i$ is invertible and so $A_ix_i$ tells us precisely what the values of $x_i$ are. I am interested in $$y=H\left(\sum_{i=1}^{\ell} A_ix_i\right)$$ and in particular, under what circumstances is $y$ much larger than $n$? We know that if every $A_i$ is identical and each is simply the identity matrix then $y = nh_B(\ell)$ were $h_B(t) = H(B(t,1/2))$ .  Therefore, under these circumstances $y \approx C_1n\log_2{\ell}$ for some constant $C_1 >0$. What properties do the matrices $A_i$ have to have for $y$ to be of the form   $C_2n\ell$ for some constant $C_2>0$? It seems plausible that at the least the matrices $A_i$ should be dense to ensure that the range of values each entry of $A_ix_i$ can take is large enough. But is this sufficient?","Consider a sequence of fixed non-singular $n$ by $n$ matrices $A_i$ whose entries are chosen from $\{0,1\}$ and a sequence of independent random $n$ dimensional vectors $x_i$ whose entries are also chosen independently from $\{0,1\}$ . Assume $n$ is large. We know $H(A_ix_i) = n$. This is because $A_i$ is invertible and so $A_ix_i$ tells us precisely what the values of $x_i$ are. I am interested in $$y=H\left(\sum_{i=1}^{\ell} A_ix_i\right)$$ and in particular, under what circumstances is $y$ much larger than $n$? We know that if every $A_i$ is identical and each is simply the identity matrix then $y = nh_B(\ell)$ were $h_B(t) = H(B(t,1/2))$ .  Therefore, under these circumstances $y \approx C_1n\log_2{\ell}$ for some constant $C_1 >0$. What properties do the matrices $A_i$ have to have for $y$ to be of the form   $C_2n\ell$ for some constant $C_2>0$? It seems plausible that at the least the matrices $A_i$ should be dense to ensure that the range of values each entry of $A_ix_i$ can take is large enough. But is this sufficient?",,['probability']
83,Ratio between highest number among $n$ and $n+1$ samples,Ratio between highest number among  and  samples,n n+1,"When $n$ numbers are drawn independently and uniformly from $[0,1]$, the expected value of the highest number is $A=n/(n+1)$. When $n+1$ numbers are drawn under the same condition, the expected value of the highest number is $B=(n+1)/(n+2)$. The ratio is $\frac{A}{B}=\frac{n^2+2n}{n^2+2n+1}$. For fixed $n$ and any distribution $F$ with support $[0,1]$, let $A(F)$ denote the expected value of the highest of $n$ numbers drawn independently from this distribution, and $B(F)$ denote the expected value of the highest of $n+1$ numbers drawn independently from this distribution. What is the infimum of $\frac{A(F)}{B(F)}$ over all distributions $F$ with support $[0,1]$?","When $n$ numbers are drawn independently and uniformly from $[0,1]$, the expected value of the highest number is $A=n/(n+1)$. When $n+1$ numbers are drawn under the same condition, the expected value of the highest number is $B=(n+1)/(n+2)$. The ratio is $\frac{A}{B}=\frac{n^2+2n}{n^2+2n+1}$. For fixed $n$ and any distribution $F$ with support $[0,1]$, let $A(F)$ denote the expected value of the highest of $n$ numbers drawn independently from this distribution, and $B(F)$ denote the expected value of the highest of $n+1$ numbers drawn independently from this distribution. What is the infimum of $\frac{A(F)}{B(F)}$ over all distributions $F$ with support $[0,1]$?",,"['probability', 'probability-distributions']"
84,Crow probability question,Crow probability question,,"Twenty crows land randomly on a wire. Each crow is crowing at the nearest crow. What is the expected number of crows that are not crowed at? I truly have no idea how to approach this problem. I was thinking along the lines that the end crows each have probability $\frac12$ of not being crowed at. The penultimate crows on each end have $0$ probability of not being crowed at. For each ""interior"" crow, the probability of not being crowed at is $\frac14$. So the expected number of crows that are not crowed at is $2\cdot\frac12+16\cdot\frac14=5$.","Twenty crows land randomly on a wire. Each crow is crowing at the nearest crow. What is the expected number of crows that are not crowed at? I truly have no idea how to approach this problem. I was thinking along the lines that the end crows each have probability $\frac12$ of not being crowed at. The penultimate crows on each end have $0$ probability of not being crowed at. For each ""interior"" crow, the probability of not being crowed at is $\frac14$. So the expected number of crows that are not crowed at is $2\cdot\frac12+16\cdot\frac14=5$.",,"['probability', 'expectation']"
85,Probability of winning at Solitaire,Probability of winning at Solitaire,,"Using a standard deck of playing cards, how many ways of assembling (shuffling) them will result in a competent player always ""going out"" in a standard (seven initial columns, every remaining third card can be played) game of solitaire?  And what proportion / percentage of the total number of ways that a deck can be assembled does that number represent?","Using a standard deck of playing cards, how many ways of assembling (shuffling) them will result in a competent player always ""going out"" in a standard (seven initial columns, every remaining third card can be played) game of solitaire?  And what proportion / percentage of the total number of ways that a deck can be assembled does that number represent?",,"['probability', 'card-games']"
86,"If I bet half of my money each round in a fair gamble, what's the probability...","If I bet half of my money each round in a fair gamble, what's the probability...",,"that I can make 10 times of what I initially have? Here's the formal description. In a fair gamble, I lose or double my wager each with probability 1/2. No matter how much money I have, I always gamble half of my money (the money is infinitely divisible, so that I'm never ruined). If I start with 1 dollar, and I win once I own 10 dollars or more, what's the probability of winning? Let $X_n$ be the money I have after the nth round. Thus $X_{n+1} = 1.5X_n$ or $0.5X_n$ each with p = 1/2, and the process is a martingale. I tried to use the optional stopping theorem, by setting $\tau$ as the time that my money goes over 10 or goes below $\epsilon$ for the first time, and then let $\epsilon$ approach 0. The problem is, $X_{\tau}$ never actually equals 10. In fact it lies in the interval [10,15). So the theorem would only give a bound on the desired probability: $E[X_{\tau}] = E[X_{\tau}|X_{\tau} \geq 10] \Pr (X_{\tau} \geq 10) + E[X_{\tau}|X_{\tau} \leq \epsilon] \Pr (X_{\tau} \leq \epsilon) $ Next I take $y$ as the natural log of money and let $f(y)$ be the probability I can win with initial log-money $y$. The following formulas looked promising: $f(y) = 1, y \geq \ln 10$ $f(y) = 1/2 + f(y - \ln 2), \ln(20/3) \leq y < \ln 10$ $f(y) = f(y - \ln 2)/2 + f(y + \ln (3/2))/2, y < \ln(20/3)$ but still I can't find the right analytic expression of $f(y)$. I'm not even sure if $f$ is continuous at $y=\ln 10$ or $y = \ln (20/3)$. Any help is appreciated!","that I can make 10 times of what I initially have? Here's the formal description. In a fair gamble, I lose or double my wager each with probability 1/2. No matter how much money I have, I always gamble half of my money (the money is infinitely divisible, so that I'm never ruined). If I start with 1 dollar, and I win once I own 10 dollars or more, what's the probability of winning? Let $X_n$ be the money I have after the nth round. Thus $X_{n+1} = 1.5X_n$ or $0.5X_n$ each with p = 1/2, and the process is a martingale. I tried to use the optional stopping theorem, by setting $\tau$ as the time that my money goes over 10 or goes below $\epsilon$ for the first time, and then let $\epsilon$ approach 0. The problem is, $X_{\tau}$ never actually equals 10. In fact it lies in the interval [10,15). So the theorem would only give a bound on the desired probability: $E[X_{\tau}] = E[X_{\tau}|X_{\tau} \geq 10] \Pr (X_{\tau} \geq 10) + E[X_{\tau}|X_{\tau} \leq \epsilon] \Pr (X_{\tau} \leq \epsilon) $ Next I take $y$ as the natural log of money and let $f(y)$ be the probability I can win with initial log-money $y$. The following formulas looked promising: $f(y) = 1, y \geq \ln 10$ $f(y) = 1/2 + f(y - \ln 2), \ln(20/3) \leq y < \ln 10$ $f(y) = f(y - \ln 2)/2 + f(y + \ln (3/2))/2, y < \ln(20/3)$ but still I can't find the right analytic expression of $f(y)$. I'm not even sure if $f$ is continuous at $y=\ln 10$ or $y = \ln (20/3)$. Any help is appreciated!",,"['probability', 'martingales', 'gambling']"
87,Optimal elevator placement,Optimal elevator placement,,"I was thinking about this in my building today. Assume that the number of people trying to go up an elevator in a certain time period (say, an hour) is given by a Poisson distribution with mean $A$, and the number trying to go down is $B$. Assume the distribution of each passengers arrival time is uniform in the hour. Assume their are $n$ elevators. Assume that, when not in service, each elevator immediately returns to a floor which is a function $f$ of the current position of all other elevators. Assume that each elevator takes 15 sec between each floor and 30 sec each time it makes a stop. Which function f described earlier mimimizes expected wait time for a passenger?","I was thinking about this in my building today. Assume that the number of people trying to go up an elevator in a certain time period (say, an hour) is given by a Poisson distribution with mean $A$, and the number trying to go down is $B$. Assume the distribution of each passengers arrival time is uniform in the hour. Assume their are $n$ elevators. Assume that, when not in service, each elevator immediately returns to a floor which is a function $f$ of the current position of all other elevators. Assume that each elevator takes 15 sec between each floor and 30 sec each time it makes a stop. Which function f described earlier mimimizes expected wait time for a passenger?",,"['probability', 'optimization']"
88,Hoeffding inequality adapted to discrete random variables,Hoeffding inequality adapted to discrete random variables,,"Given $n$ (real-valued) random variables $X_1, X_2, ..., X_n \in [0, B]$, it can be derived from Hoeffding's Inequality that: $$\mathbb{P}^n\left[ \bar{X} - \mathbb{E}_n[ \bar{X} ] \geq t \right] \leq \exp \left( - \frac{2 n t^2}{B^2} \right) $$ where $\bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i$, and $\mathbb{P}^n$ is the product measure $\mathbb{P} \times \mathbb{P} \times \ldots \mathbb{P}$ ($n$ times). Is there a tighter bound if we have (integer-valued) random variables $X_1, X_2, ..., X_n \in \{0, 1, ..., B-1, B\}$? What similar inequalities are available for discrete, bounded, random variables?","Given $n$ (real-valued) random variables $X_1, X_2, ..., X_n \in [0, B]$, it can be derived from Hoeffding's Inequality that: $$\mathbb{P}^n\left[ \bar{X} - \mathbb{E}_n[ \bar{X} ] \geq t \right] \leq \exp \left( - \frac{2 n t^2}{B^2} \right) $$ where $\bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i$, and $\mathbb{P}^n$ is the product measure $\mathbb{P} \times \mathbb{P} \times \ldots \mathbb{P}$ ($n$ times). Is there a tighter bound if we have (integer-valued) random variables $X_1, X_2, ..., X_n \in \{0, 1, ..., B-1, B\}$? What similar inequalities are available for discrete, bounded, random variables?",,"['probability', 'probability-theory', 'inequality']"
89,Kalman filtering correlated measurements,Kalman filtering correlated measurements,,"I would like to run a Kalman filter over a set of measurements which may (will) be correlated.  Essentially, each new measurement contains (say) 90% of the same information from the previous measurement.  The measurements are made by integrating over time, and subsequent measurements are taken by overlapping integrations. For various reasons, I can't necessarily decimate the measurements so that they are independent of each other, but if I apply each measurement at its full weighting, the filter will become over confident and its covariance will shrink too quickly. My first thought is that there must be someway to increase the covariance from each measurement so that it doesn't overly affect the filter state, but I would like a rigorously correct solution, and I welcome any pointers. A least squares approach which allowed expressing the correlated measurements would also be welcome, but I kind of prefer the Kalman filter because it gives me a running covariance as well as the filtered result. Thank you in advance for any pointers!  Is there a better stack exchange for this question?","I would like to run a Kalman filter over a set of measurements which may (will) be correlated.  Essentially, each new measurement contains (say) 90% of the same information from the previous measurement.  The measurements are made by integrating over time, and subsequent measurements are taken by overlapping integrations. For various reasons, I can't necessarily decimate the measurements so that they are independent of each other, but if I apply each measurement at its full weighting, the filter will become over confident and its covariance will shrink too quickly. My first thought is that there must be someway to increase the covariance from each measurement so that it doesn't overly affect the filter state, but I would like a rigorously correct solution, and I welcome any pointers. A least squares approach which allowed expressing the correlated measurements would also be welcome, but I kind of prefer the Kalman filter because it gives me a running covariance as well as the filtered result. Thank you in advance for any pointers!  Is there a better stack exchange for this question?",,"['probability', 'statistics', 'bayesian-network', 'kalman-filter']"
90,Probability of Multiple Collisions in the Birthday Problem,Probability of Multiple Collisions in the Birthday Problem,,"I need help with an approximation concerning the birthday problem.  In a recent MAA Monthly (August-September 2013) article  ""Simple Approximation Formulas for the Birthday Problem"" by Matthias Arnold and Werner Glass, the authors claim the probability $p$ that out of $n$ people at least $k$ birthdays occur on a single day in a year with $c$ days  is approximately     $$p\approx1-\exp\,\left(\!n^k{\textrm{e}}^{-n/c}\left(\!\frac n{c(k+1)} -1\!\right)^{\!-1}c^{1-k}(k!)^{-1}\!\right).$$ The authors cite this formula from a 1989 paper  ""Methods for Studying Coincidences"" by Persi Diaconis and Frederick Mosteller.  Unfortunately, this reference only claims the formula comes from unpublished work and provides no further references. Can anyone provide  insight about how to obtain such a formula?","I need help with an approximation concerning the birthday problem.  In a recent MAA Monthly (August-September 2013) article  ""Simple Approximation Formulas for the Birthday Problem"" by Matthias Arnold and Werner Glass, the authors claim the probability $p$ that out of $n$ people at least $k$ birthdays occur on a single day in a year with $c$ days  is approximately     $$p\approx1-\exp\,\left(\!n^k{\textrm{e}}^{-n/c}\left(\!\frac n{c(k+1)} -1\!\right)^{\!-1}c^{1-k}(k!)^{-1}\!\right).$$ The authors cite this formula from a 1989 paper  ""Methods for Studying Coincidences"" by Persi Diaconis and Frederick Mosteller.  Unfortunately, this reference only claims the formula comes from unpublished work and provides no further references. Can anyone provide  insight about how to obtain such a formula?",,"['probability', 'birthday']"
91,Axiom of Choice and Probability,Axiom of Choice and Probability,,"let $\mathbb{N}=\{1,2,3,... \}$.  Set $\Omega = \mathbb{N}^\mathbb{N}$ and define for every $\omega \in  \Omega$ \begin{equation} Y_n (\omega) = \omega_n. \end{equation} Then Williams, Probability with Martingales, states without proof the following fact: if the axiom of choice holds, then there exists no probability measure defined on all the subsets of $\Omega$  such that the random variables $Y_n$ are IID. Do you have some idea of the proof? Any hint is well accepted. Thank you very much for your help. My best regards, Maurizio Barbato","let $\mathbb{N}=\{1,2,3,... \}$.  Set $\Omega = \mathbb{N}^\mathbb{N}$ and define for every $\omega \in  \Omega$ \begin{equation} Y_n (\omega) = \omega_n. \end{equation} Then Williams, Probability with Martingales, states without proof the following fact: if the axiom of choice holds, then there exists no probability measure defined on all the subsets of $\Omega$  such that the random variables $Y_n$ are IID. Do you have some idea of the proof? Any hint is well accepted. Thank you very much for your help. My best regards, Maurizio Barbato",,"['probability', 'elementary-set-theory']"
92,Why can't I use the variance of the sample average in the Central Limit Theorem for the weak-stationary process?,Why can't I use the variance of the sample average in the Central Limit Theorem for the weak-stationary process?,,"Under mild conditions $\dfrac{\bar{X}-\mu}{\sqrt{\sigma^2/n}}$ approaches the standard normal (where $\sigma^2$ is the process variance, not the marginal variance $\sigma^2_x$). Why is the denominator not the standard error for the sample mean of dependent data, specifically $\sqrt{\frac{\sigma_x^2}{n}\times [1 + 2*\sum_{i=1}^{n-1}(1-i/n)*\rho_i]}$ ? A high-level answer would be nice as I don't have a good background in mathematics. I didn't put this in CrossValidated because it deals with probability and stochastic processes.","Under mild conditions $\dfrac{\bar{X}-\mu}{\sqrt{\sigma^2/n}}$ approaches the standard normal (where $\sigma^2$ is the process variance, not the marginal variance $\sigma^2_x$). Why is the denominator not the standard error for the sample mean of dependent data, specifically $\sqrt{\frac{\sigma_x^2}{n}\times [1 + 2*\sum_{i=1}^{n-1}(1-i/n)*\rho_i]}$ ? A high-level answer would be nice as I don't have a good background in mathematics. I didn't put this in CrossValidated because it deals with probability and stochastic processes.",,"['probability', 'statistics', 'stochastic-processes']"
93,Microsoft Paint Spraypaint Tool,Microsoft Paint Spraypaint Tool,,"The following question is motivated by the spraypaint tool in Microsoft Paint.  In a sense, I'm asking how many clicks on average are necessary to fill each pixel within the range of the tool if we leave the cursor fixed.  The following is a more precise statement of the question: Consider $n$ dice, each with $k$ sides.  A roll consists of rolling all $n$ dice.  Determine $E(n,k)$, the expected number of rolls needed so that all numbers $1,\ldots,k$ have appeared on some roll. The translation to spraypaint can be seen by assuming the range of the spraypaint tool is $k$ pixels, and each click paints $n$ random pixels. I remember looking at this problem years ago, and only partially solving it.  I believe I worked on the case $n=1$: $$E(1,k)=kH_k=k\sum_{i=1}^k\frac{1}{i}$$ Here $H_k$ is the $k$th harmonic number.  I'm not entirely convinced of this result.  For $n=2$ I could only find a closed form for asymptotic behavior as $k$ got large.  My memory of the solution is a bit fuzzy though.","The following question is motivated by the spraypaint tool in Microsoft Paint.  In a sense, I'm asking how many clicks on average are necessary to fill each pixel within the range of the tool if we leave the cursor fixed.  The following is a more precise statement of the question: Consider $n$ dice, each with $k$ sides.  A roll consists of rolling all $n$ dice.  Determine $E(n,k)$, the expected number of rolls needed so that all numbers $1,\ldots,k$ have appeared on some roll. The translation to spraypaint can be seen by assuming the range of the spraypaint tool is $k$ pixels, and each click paints $n$ random pixels. I remember looking at this problem years ago, and only partially solving it.  I believe I worked on the case $n=1$: $$E(1,k)=kH_k=k\sum_{i=1}^k\frac{1}{i}$$ Here $H_k$ is the $k$th harmonic number.  I'm not entirely convinced of this result.  For $n=2$ I could only find a closed form for asymptotic behavior as $k$ got large.  My memory of the solution is a bit fuzzy though.",,"['probability', 'coupon-collector']"
94,Finding a probability distribution given the moment generating function,Finding a probability distribution given the moment generating function,,"The $n$-th moment ($n \geq 1$) of a random variable $X$ is given by: $m_n = \frac{2^n}{n+1}$. Find the probability distribution of $X$. Here's my attempt at a solution: I expand the moment generating function, $\psi (t) = E[e^{tX}]=\int_{-\infty}^{\infty}dxf(x)e^{tx}$, as a Taylor series about $0$: $$\psi (t) = 1+ \sum_{n=0}^{\infty}\frac{\psi^{(n)}(0)}{n!}t^n = 1 +\sum_{n=0}^{\infty}\frac{2 ^n}{(n+1)!}t^n = 1 + \frac{e^{2t}}{2t}.$$ Now, I have the identity $\psi (-t) = \int_{-\infty}^{\infty}dxf(x)e^{-tx}$ which is apparently a bilateral Laplace transform. So to find $f(x)$ I should invert it right? But the resulting integral seems not to converge at all. I haven't done Laplace transforms at all yet and I have no idea how to solve this problem. Is there perhaps a simpler way? In the lecture notes I couldn't see any formula relating the probability density function to the moment generating function.","The $n$-th moment ($n \geq 1$) of a random variable $X$ is given by: $m_n = \frac{2^n}{n+1}$. Find the probability distribution of $X$. Here's my attempt at a solution: I expand the moment generating function, $\psi (t) = E[e^{tX}]=\int_{-\infty}^{\infty}dxf(x)e^{tx}$, as a Taylor series about $0$: $$\psi (t) = 1+ \sum_{n=0}^{\infty}\frac{\psi^{(n)}(0)}{n!}t^n = 1 +\sum_{n=0}^{\infty}\frac{2 ^n}{(n+1)!}t^n = 1 + \frac{e^{2t}}{2t}.$$ Now, I have the identity $\psi (-t) = \int_{-\infty}^{\infty}dxf(x)e^{-tx}$ which is apparently a bilateral Laplace transform. So to find $f(x)$ I should invert it right? But the resulting integral seems not to converge at all. I haven't done Laplace transforms at all yet and I have no idea how to solve this problem. Is there perhaps a simpler way? In the lecture notes I couldn't see any formula relating the probability density function to the moment generating function.",,"['probability', 'generating-functions', 'moment-generating-functions']"
95,Probability question involving sets of cards,Probability question involving sets of cards,,"I have an infinite deck built out of sets of 10 cards (in other words 10*n cards). The sets are identical so one '2' is identical to another '2'. A player draws 6 cards. If he draws: any '1' AND a '2', or any '3' AND a '4', or any '5' AND a '6', or any '7' AND a '8', or any '9' AND a '10', he wins. In other words there are 5 pairs and if the player draws a complete pair he gets a point. What is the probability he won't win any points at all? To expand on the problem, if the player gets a point for every pair he completes in a hand, what is the probability he'll get 1, 2, or even 3 points? (3 points being 6 cards of 3 completed pairs) From what I know of Newton's Binomial, there are : $\binom{10}{6} = 210$ different hand combinations. To expand even further, how do the probabilities change if the source deck ceases to be infinite? From trial and error I can see that if the deck has only 10 cards then the player has to draw at least 1 complete pair. Example: For example, a hand of {1,1,3,5,5,9} will get no points. A hand of {1,1,2,3,4,5} will get 2. Script: I've made a simple js script to roughly calculate the probabilities of the infinite deck to verify if your mathematical answer is on track. I am yet to write a script which simulates a finite number of cards in a deck. http://jsfiddle.net/ch3shirecat/xZ8s5/ After azimut's answer: A slight explanation. If the deck has more than 10 cards (10*n with n>1) then any card can have more than 1 other card as a pair. For example, in a deck of 30 there'll be three '1' cards and three '2' cards with 9 possible pairings between them (with each giving a point). So the hand of {1,2,1,2,1,2} is possible and will give 3 pairings. Does it make sense? Thank you!","I have an infinite deck built out of sets of 10 cards (in other words 10*n cards). The sets are identical so one '2' is identical to another '2'. A player draws 6 cards. If he draws: any '1' AND a '2', or any '3' AND a '4', or any '5' AND a '6', or any '7' AND a '8', or any '9' AND a '10', he wins. In other words there are 5 pairs and if the player draws a complete pair he gets a point. What is the probability he won't win any points at all? To expand on the problem, if the player gets a point for every pair he completes in a hand, what is the probability he'll get 1, 2, or even 3 points? (3 points being 6 cards of 3 completed pairs) From what I know of Newton's Binomial, there are : $\binom{10}{6} = 210$ different hand combinations. To expand even further, how do the probabilities change if the source deck ceases to be infinite? From trial and error I can see that if the deck has only 10 cards then the player has to draw at least 1 complete pair. Example: For example, a hand of {1,1,3,5,5,9} will get no points. A hand of {1,1,2,3,4,5} will get 2. Script: I've made a simple js script to roughly calculate the probabilities of the infinite deck to verify if your mathematical answer is on track. I am yet to write a script which simulates a finite number of cards in a deck. http://jsfiddle.net/ch3shirecat/xZ8s5/ After azimut's answer: A slight explanation. If the deck has more than 10 cards (10*n with n>1) then any card can have more than 1 other card as a pair. For example, in a deck of 30 there'll be three '1' cards and three '2' cards with 9 possible pairings between them (with each giving a point). So the hand of {1,2,1,2,1,2} is possible and will give 3 pairings. Does it make sense? Thank you!",,"['probability', 'combinatorics', 'inclusion-exclusion', 'card-games']"
96,A coupling card trick in Durrett's book,A coupling card trick in Durrett's book,,"This is an example in Durrett's book ""Probability theory: theory and examples"", it's about the coupling time in Markov chains, but I can't see the reason behind it. The trick is played by two persons A and B. A writes 100 digits from 0-9 randomly, B choose one of the first 10 numbers and does not tell A. If B has chosen 7,say, he counts 7 places along the list, notes the digits at the location, and continue the process. If the digit is 0 he counts 10. A possible sequence is underlined in the list: $$ 3\  4\  \underline{7}\  8\  2\  3\  7\  5\  6\  \underline{1}\  \underline{6}\  4\  6\  5\  7\  8\  \underline{3}\  1\  5\  \underline{3}\  0\  7\  \underline{9} \ 2\  3\ ...$$ The trick is that, without knowing B's first digit, A can point to B's final stopping location. He just starts the process from any one of the first 10 places, and conclude that he's stopping location is the same as B's. The probability of making an error is less than 3%. I'm puzzled by the reasoning behind the example, can anyone explain it to me ?","This is an example in Durrett's book ""Probability theory: theory and examples"", it's about the coupling time in Markov chains, but I can't see the reason behind it. The trick is played by two persons A and B. A writes 100 digits from 0-9 randomly, B choose one of the first 10 numbers and does not tell A. If B has chosen 7,say, he counts 7 places along the list, notes the digits at the location, and continue the process. If the digit is 0 he counts 10. A possible sequence is underlined in the list: $$ 3\  4\  \underline{7}\  8\  2\  3\  7\  5\  6\  \underline{1}\  \underline{6}\  4\  6\  5\  7\  8\  \underline{3}\  1\  5\  \underline{3}\  0\  7\  \underline{9} \ 2\  3\ ...$$ The trick is that, without knowing B's first digit, A can point to B's final stopping location. He just starts the process from any one of the first 10 places, and conclude that he's stopping location is the same as B's. The probability of making an error is less than 3%. I'm puzzled by the reasoning behind the example, can anyone explain it to me ?",,['probability']
97,How to show that the push forward of a sigma algebra is a sigma algebra.,How to show that the push forward of a sigma algebra is a sigma algebra.,,"Let $\mathcal{M}$ be a sigma algebra on $X$. Let $f:X\to Y$. Define $$ \mathcal{A}=\{B\subset Y : f^{-1}(B)\in \mathcal{M}\}. $$ The problem is to show that $\mathcal{A}$ is a sigma algebra on $Y$. This is my attempt. Clearly, $\emptyset \in \mathcal{A}$. Let $\{B_k\}_{k=1}^\infty$ be a countable collection of sets such that $f^{-1}({B_k})\in \mathcal{M}$.  Then $f^{-1}(\cup B_k)=\cup f^{-1}(B_k)\in \mathcal{M}$. So $\cup B_k \subset Y$ and hence $\cup B_k\in\mathcal{A}$. Also, $f^{-1}(B^c)=(f^{-1}(B))^c\in \mathcal{M}$ and so $B^c\in \mathcal{A}$. Thus $\mathcal{A}$ is a sigma algebra on $Y$. Please, is what I have done right?","Let $\mathcal{M}$ be a sigma algebra on $X$. Let $f:X\to Y$. Define $$ \mathcal{A}=\{B\subset Y : f^{-1}(B)\in \mathcal{M}\}. $$ The problem is to show that $\mathcal{A}$ is a sigma algebra on $Y$. This is my attempt. Clearly, $\emptyset \in \mathcal{A}$. Let $\{B_k\}_{k=1}^\infty$ be a countable collection of sets such that $f^{-1}({B_k})\in \mathcal{M}$.  Then $f^{-1}(\cup B_k)=\cup f^{-1}(B_k)\in \mathcal{M}$. So $\cup B_k \subset Y$ and hence $\cup B_k\in\mathcal{A}$. Also, $f^{-1}(B^c)=(f^{-1}(B))^c\in \mathcal{M}$ and so $B^c\in \mathcal{A}$. Thus $\mathcal{A}$ is a sigma algebra on $Y$. Please, is what I have done right?",,"['probability', 'measure-theory']"
98,Does every continuous time minimal Markov chain have the Feller property?,Does every continuous time minimal Markov chain have the Feller property?,,"Consider a Q-matrix on a countable state space. (A Q-matrix is a matrix whose rows sum up to $0$, with nonpositive finite diagonal entries and nonnegative off-diagonal entries.) As explained for example in the book of Norris on Markov chains, every Q-matrix (without any further assumptions) defines a transition function (given by the minimal nonnegative solution of the corresponding backward equation). Is the  the semigroup associated to this minimal transition function always Feller? (definition of Feller: functions vanishing at infinity are mapped into functions vanishing at infinity). I know that in general, not every continuous time Markov chain is Feller, but I guess that for these minimal chains it is always true without further assumptions on $Q$.  Though I didn't find a statement like this in the books I consulted. Does anybody have a reference/proof/counterexample?","Consider a Q-matrix on a countable state space. (A Q-matrix is a matrix whose rows sum up to $0$, with nonpositive finite diagonal entries and nonnegative off-diagonal entries.) As explained for example in the book of Norris on Markov chains, every Q-matrix (without any further assumptions) defines a transition function (given by the minimal nonnegative solution of the corresponding backward equation). Is the  the semigroup associated to this minimal transition function always Feller? (definition of Feller: functions vanishing at infinity are mapped into functions vanishing at infinity). I know that in general, not every continuous time Markov chain is Feller, but I guess that for these minimal chains it is always true without further assumptions on $Q$.  Though I didn't find a statement like this in the books I consulted. Does anybody have a reference/proof/counterexample?",,"['probability', 'reference-request', 'stochastic-processes', 'markov-chains', 'semigroups']"
99,Showing a process is a martingale,Showing a process is a martingale,,"Let $\newcommand{\F}{\mathcal F} S_n=S_{n-1} +X_n $ where $S_0=0$ , and $X_k$ are iid, and let $\phi(t)=\mathbb{E}e^{itX_1}$ be the characteristic function of $X_k$. Consider a process $Y_n=e^{itS_n-n\log(\phi(t))}$. Show that the process $(Y_n, \F_n)$ is a martingale, where $\F_n=\sigma(X_1,...,X_n)$. I am not too sure about how to calculate the conditional expectation $\mathbb{E}[Y_n \mid \F_{n-1}]$. $\mathbb{E}[Y_n \mid \F_{n-1}]=\mathbb{E}[e^{itS_n-n\log\phi(t)}]=\mathbb{E}[e^{it(S_{n-1}+X_n)-n\log\phi(t)} \mid \F_{n-1}]=e^{itS_{n-1}}\mathbb{E}[e^{itX_n-n\log\phi(t)} \mid \F_{n-1}]$  $=e^{itS_{n-1}}\mathbb{E} [e^{itX_n} - \phi (t)^n \mid \F_{n-1}]$ At this point, I am stuck.","Let $\newcommand{\F}{\mathcal F} S_n=S_{n-1} +X_n $ where $S_0=0$ , and $X_k$ are iid, and let $\phi(t)=\mathbb{E}e^{itX_1}$ be the characteristic function of $X_k$. Consider a process $Y_n=e^{itS_n-n\log(\phi(t))}$. Show that the process $(Y_n, \F_n)$ is a martingale, where $\F_n=\sigma(X_1,...,X_n)$. I am not too sure about how to calculate the conditional expectation $\mathbb{E}[Y_n \mid \F_{n-1}]$. $\mathbb{E}[Y_n \mid \F_{n-1}]=\mathbb{E}[e^{itS_n-n\log\phi(t)}]=\mathbb{E}[e^{it(S_{n-1}+X_n)-n\log\phi(t)} \mid \F_{n-1}]=e^{itS_{n-1}}\mathbb{E}[e^{itX_n-n\log\phi(t)} \mid \F_{n-1}]$  $=e^{itS_{n-1}}\mathbb{E} [e^{itX_n} - \phi (t)^n \mid \F_{n-1}]$ At this point, I am stuck.",,"['probability', 'probability-theory', 'stochastic-processes', 'martingales']"
