,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,How to solve the limit $\lim\limits_{n\to \infty}(1-a)(1-a^2)\cdots(1-a^n)$?,How to solve the limit ?,\lim\limits_{n\to \infty}(1-a)(1-a^2)\cdots(1-a^n),Suppose $|a|<1$ be a real number. How to solve the following limit? $$\lim\limits_{n\to \infty}(1-a)(1-a^2)\cdots(1-a^n).$$,Suppose $|a|<1$ be a real number. How to solve the following limit? $$\lim\limits_{n\to \infty}(1-a)(1-a^2)\cdots(1-a^n).$$,,"['calculus', 'sequences-and-series', 'limits', 'infinite-product']"
1,Closed-form of $\sum_{k=1}^{\infty}\arctan(1/k^3)$,Closed-form of,\sum_{k=1}^{\infty}\arctan(1/k^3),Wolfram said that $$\sum_{k=1}^{\infty}\arctan\left(\frac{1}{k^2}\right)=\arctan\left(\frac{1-\cot\left(\frac{\pi}{\sqrt 2}\right)\tanh\left(\frac{\pi}{\sqrt 2}\right)}{1+\cot\left(\frac{\pi}{\sqrt 2}\right)\tanh\left(\frac{\pi}{\sqrt 2}\right)}\right).$$ I was wondering about a closed-form of $$S = \sum_{k=1}^{\infty}\arctan\left(\frac{1}{k^3}\right).$$ A numerical approximation of $S$ is $$S \approx 0.986791652613071125515794193830247643724471031136456434\dots$$ Is there a closed-form of $S$?,Wolfram said that $$\sum_{k=1}^{\infty}\arctan\left(\frac{1}{k^2}\right)=\arctan\left(\frac{1-\cot\left(\frac{\pi}{\sqrt 2}\right)\tanh\left(\frac{\pi}{\sqrt 2}\right)}{1+\cot\left(\frac{\pi}{\sqrt 2}\right)\tanh\left(\frac{\pi}{\sqrt 2}\right)}\right).$$ I was wondering about a closed-form of $$S = \sum_{k=1}^{\infty}\arctan\left(\frac{1}{k^3}\right).$$ A numerical approximation of $S$ is $$S \approx 0.986791652613071125515794193830247643724471031136456434\dots$$ Is there a closed-form of $S$?,,"['calculus', 'sequences-and-series', 'trigonometry', 'closed-form']"
2,Finding continuity and differentiability of a multivariate function,Finding continuity and differentiability of a multivariate function,,"Determine whether the following functions are differentiable, continuous, and whether its partial derivatives exists at point $(0,0)$: (a) $$f(x, y) = \sin x \sin(x + y) \sin(x − y)$$ (b)$$f(x,y)=\sqrt{|xy|}$$ (c)$$f(x, y) = 1 − \sin\sqrt{x^2 + y^2}$$ (d) $$f(x,y) = \begin{cases} \dfrac{xy}{x^2+y^2} & \text{if $x^2+y^2>0 $} \\ 0 & \text{if $x=y=0$} \end{cases}$$ (e) $$f(x,y) = \begin{cases} 1 & \text{if $x y \ne 0$} \\ 0  & \text{if $xy=0$} \end{cases}$$ (f)$$f(x,y) = \begin{cases} \dfrac{x^2-y^2}{x^2+y^2} & \text{if $x^2+y^2>0$} \\ 0 & \text{if $x=y=0$} \end{cases}$$ My try: For (a), using the definition of the derivative for a multivariate function, the limit tends to $0$, hence it's differentiable and its partial derivative exists and it's continuous. For (b) I mentioned that is not differentiable as using the definition of the derivative for a multivariate function, the limit does not tend to $0$. While it's continuous, as the limit of the function $f(x,y)$ tends to $0$. To determine whether its partial derivative exists, this part is tricky because of the modulus sign in the function hence I'm unsure whether a modulus is differentiable for this case. For part (c) it should be continuous but not differentiable at $(0,0)$ because its partial derivative does not exists at $(0,0)$. As to why its partial derivatives does not exists, lets say to find $$f_x$$, we let $y=0$, the expression $f(x,y)$ becomes $1-\sin(|x|)$ which is not differentable at $(0,0)$, hence partial derivatives cannot exists at $(0,0)$. For (d), this question is also tricky, as although initially I though its partial derivatives exists, now I think likewise. Because if I want to differentiate the function with respect to $x$ for example, I would sub in the value of $y=0$ making the numerator a zero and hence assume the derivative is $0$. However, on closer look, there is still the denominator of $x^2$ and if $x^2=0$ the denominator becomes $0$ and since $0/0$ is undefined, the partial derivatives do not exist. As for continuity, it is not continuous and hence not differentiable. For (e) Not differentiable, Discontinuous, Partial derivatives defined (because ""not continuous"" will mean it's not differentiable, but I'm unsure of the Partial derivatives portion though because it appears the the partial derivatives are $0$ but I also have the feeling that the partial derivatives do not exist.) For (f) Not differentiable, Continuous, Partial derivatives defined. This question appears to be similar to question (d) I have already attempted these questions many times, but I keep answering these questions incorrectly. I know that I must be missing out on some parts especially when these are tricky questions which are not as simple it might seem. Could anyone help me please? Thanks!","Determine whether the following functions are differentiable, continuous, and whether its partial derivatives exists at point $(0,0)$: (a) $$f(x, y) = \sin x \sin(x + y) \sin(x − y)$$ (b)$$f(x,y)=\sqrt{|xy|}$$ (c)$$f(x, y) = 1 − \sin\sqrt{x^2 + y^2}$$ (d) $$f(x,y) = \begin{cases} \dfrac{xy}{x^2+y^2} & \text{if $x^2+y^2>0 $} \\ 0 & \text{if $x=y=0$} \end{cases}$$ (e) $$f(x,y) = \begin{cases} 1 & \text{if $x y \ne 0$} \\ 0  & \text{if $xy=0$} \end{cases}$$ (f)$$f(x,y) = \begin{cases} \dfrac{x^2-y^2}{x^2+y^2} & \text{if $x^2+y^2>0$} \\ 0 & \text{if $x=y=0$} \end{cases}$$ My try: For (a), using the definition of the derivative for a multivariate function, the limit tends to $0$, hence it's differentiable and its partial derivative exists and it's continuous. For (b) I mentioned that is not differentiable as using the definition of the derivative for a multivariate function, the limit does not tend to $0$. While it's continuous, as the limit of the function $f(x,y)$ tends to $0$. To determine whether its partial derivative exists, this part is tricky because of the modulus sign in the function hence I'm unsure whether a modulus is differentiable for this case. For part (c) it should be continuous but not differentiable at $(0,0)$ because its partial derivative does not exists at $(0,0)$. As to why its partial derivatives does not exists, lets say to find $$f_x$$, we let $y=0$, the expression $f(x,y)$ becomes $1-\sin(|x|)$ which is not differentable at $(0,0)$, hence partial derivatives cannot exists at $(0,0)$. For (d), this question is also tricky, as although initially I though its partial derivatives exists, now I think likewise. Because if I want to differentiate the function with respect to $x$ for example, I would sub in the value of $y=0$ making the numerator a zero and hence assume the derivative is $0$. However, on closer look, there is still the denominator of $x^2$ and if $x^2=0$ the denominator becomes $0$ and since $0/0$ is undefined, the partial derivatives do not exist. As for continuity, it is not continuous and hence not differentiable. For (e) Not differentiable, Discontinuous, Partial derivatives defined (because ""not continuous"" will mean it's not differentiable, but I'm unsure of the Partial derivatives portion though because it appears the the partial derivatives are $0$ but I also have the feeling that the partial derivatives do not exist.) For (f) Not differentiable, Continuous, Partial derivatives defined. This question appears to be similar to question (d) I have already attempted these questions many times, but I keep answering these questions incorrectly. I know that I must be missing out on some parts especially when these are tricky questions which are not as simple it might seem. Could anyone help me please? Thanks!",,"['calculus', 'multivariable-calculus', 'derivatives', 'continuity', 'partial-derivative']"
3,"How to find the integral $\int_0^{70 \pi} |\cos^{2}x\sin x|\,dx$?",How to find the integral ?,"\int_0^{70 \pi} |\cos^{2}x\sin x|\,dx",I need help with this problem: $$\int_0^{70 \pi} \left|\cos^{2}\!\left(x\right)\sin\!\left(x\right)\right| dx$$ My friend says it's 140/3 but I don't see how.,I need help with this problem: $$\int_0^{70 \pi} \left|\cos^{2}\!\left(x\right)\sin\!\left(x\right)\right| dx$$ My friend says it's 140/3 but I don't see how.,,"['calculus', 'trigonometry', 'definite-integrals']"
4,Is this a valid proof of $\lim _{n\rightarrow \infty }(1+\frac{z}{n})^n=e^z$?,Is this a valid proof of ?,\lim _{n\rightarrow \infty }(1+\frac{z}{n})^n=e^z,"Define the function $g_n\left(z\right)=\left(1+\frac{z}{n}\right)^n$ for $\:n\in \mathbb{R^+}$. Then $$\frac{d}{dz}g_n\left(z\right)=n\left(1+\frac{z}{n}\right)^{n-1}\cdot\frac{1}{n}=\left(1+\frac{z}{n}\right)^{n-1}$$ Define $g_{\infty}\left(z\right)=\lim _{n\rightarrow \infty }g_n\left(x\right)=\lim_{n\rightarrow \infty }\left(1+\frac{z}{n}\right)^n$, then notice that $$\frac{d}{dz}g_{\infty}\left(z\right)=\frac{d}{dz}\left(\lim _{n\rightarrow \infty  }g_n\left(x\right)\right)=\lim _{n\rightarrow \infty }\frac{d}{dz}g_n\left(z\right)$$$$=\lim_{n\to  \infty}\left(1+\frac{z}{n}\right)^{n-1}=\lim_{n\to  \infty}\frac{\left(1+\frac{z}{n}\right)^n}{1+\frac{z}{n}}   =\lim _{n\rightarrow \infty }\left(1+\frac{z}{n}\right)^n=g_\infty\left(z\right)$$ By considering that $g_n\left(0\right)=1\: \forall\:n\in \mathbb{R^+}$, we have   the differential equation $$\frac{d}{dz}g_{\infty}\left(z\right)=g_\infty\left(z\right),\,g_\infty \left(0\right)=1$$ Which also has $e^z$ as a solution. However, the above differential   equation has a unique solution, so therefore    $$g_\infty \left(z\right)=\lim  _{n\rightarrow \infty }\left(1+\frac{z}{n}\right)^n=e^z\,\,\blacksquare$$ I came up with this proof myself, and I think it's quite elegant, but I'm unsure as to the validity of the proof. Something just doesn't seem right to me. Are there any invalid statements or loose ends to this proof? Also, how useful is this as a proof of the limit? You don't need to know  theory of differential equations, because you'd recognise easily that $e^z$ is its own derivative. Is there anything in it that might make it inaccessible, assuming you know that $\frac{d}{dz}e^z=e^z$?","Define the function $g_n\left(z\right)=\left(1+\frac{z}{n}\right)^n$ for $\:n\in \mathbb{R^+}$. Then $$\frac{d}{dz}g_n\left(z\right)=n\left(1+\frac{z}{n}\right)^{n-1}\cdot\frac{1}{n}=\left(1+\frac{z}{n}\right)^{n-1}$$ Define $g_{\infty}\left(z\right)=\lim _{n\rightarrow \infty }g_n\left(x\right)=\lim_{n\rightarrow \infty }\left(1+\frac{z}{n}\right)^n$, then notice that $$\frac{d}{dz}g_{\infty}\left(z\right)=\frac{d}{dz}\left(\lim _{n\rightarrow \infty  }g_n\left(x\right)\right)=\lim _{n\rightarrow \infty }\frac{d}{dz}g_n\left(z\right)$$$$=\lim_{n\to  \infty}\left(1+\frac{z}{n}\right)^{n-1}=\lim_{n\to  \infty}\frac{\left(1+\frac{z}{n}\right)^n}{1+\frac{z}{n}}   =\lim _{n\rightarrow \infty }\left(1+\frac{z}{n}\right)^n=g_\infty\left(z\right)$$ By considering that $g_n\left(0\right)=1\: \forall\:n\in \mathbb{R^+}$, we have   the differential equation $$\frac{d}{dz}g_{\infty}\left(z\right)=g_\infty\left(z\right),\,g_\infty \left(0\right)=1$$ Which also has $e^z$ as a solution. However, the above differential   equation has a unique solution, so therefore    $$g_\infty \left(z\right)=\lim  _{n\rightarrow \infty }\left(1+\frac{z}{n}\right)^n=e^z\,\,\blacksquare$$ I came up with this proof myself, and I think it's quite elegant, but I'm unsure as to the validity of the proof. Something just doesn't seem right to me. Are there any invalid statements or loose ends to this proof? Also, how useful is this as a proof of the limit? You don't need to know  theory of differential equations, because you'd recognise easily that $e^z$ is its own derivative. Is there anything in it that might make it inaccessible, assuming you know that $\frac{d}{dz}e^z=e^z$?",,"['calculus', 'limits', 'proof-verification', 'exponential-function']"
5,Multivariable calculus - find derivative using implicit differentiation,Multivariable calculus - find derivative using implicit differentiation,,"Short simple question which i managed to solve partially. we are given the equation $x^2+y^2-z^2+xz-yz-1=0$. Show using the implicit function theorem that this equation sets in the neighborhood of $(1,0,1)$ $z$ as a function of $x$ and $y$ and find: $\frac{dz}{dx},\frac{dz}{dy},\frac{d^2z}{dxdy}$ where $x=1$ and $y=0$ My answer: Define $F(x,y,z)=x^2+y^2-z^2+xz-yz-1$. Notice that $F(1,0,1)=0$. $F_x=2x+z$ , $F_y=2y-z$ , $F_z=-2z+x-y$ are all continouos functions, and $F$ itself is continuous as well, and as such $F \in C^1$. Also notice that $F_z(1,0,1)=-1 \neq 0$ and so $F_z$ is invertible at that point, and according to IFT, we can represent $z=z(x,y)$ as a function of $x$ and $y$ around that point. Now where I am having difficulties. if you look at an earlier question I asked Question about Implicit function theorem I tried deriving like I did then, and it does not work. If i was to do the same thing: $$\frac{dz}{dx} = -\frac{F_x}{F_z} = -\frac{2x+z}{x-y-2z}$$ I didn't get rid of the $z$. and the question only said $x=1$ and $y=0$. Is that because I must put $z=1$? or should the derivative be ""free"" of $z$?","Short simple question which i managed to solve partially. we are given the equation $x^2+y^2-z^2+xz-yz-1=0$. Show using the implicit function theorem that this equation sets in the neighborhood of $(1,0,1)$ $z$ as a function of $x$ and $y$ and find: $\frac{dz}{dx},\frac{dz}{dy},\frac{d^2z}{dxdy}$ where $x=1$ and $y=0$ My answer: Define $F(x,y,z)=x^2+y^2-z^2+xz-yz-1$. Notice that $F(1,0,1)=0$. $F_x=2x+z$ , $F_y=2y-z$ , $F_z=-2z+x-y$ are all continouos functions, and $F$ itself is continuous as well, and as such $F \in C^1$. Also notice that $F_z(1,0,1)=-1 \neq 0$ and so $F_z$ is invertible at that point, and according to IFT, we can represent $z=z(x,y)$ as a function of $x$ and $y$ around that point. Now where I am having difficulties. if you look at an earlier question I asked Question about Implicit function theorem I tried deriving like I did then, and it does not work. If i was to do the same thing: $$\frac{dz}{dx} = -\frac{F_x}{F_z} = -\frac{2x+z}{x-y-2z}$$ I didn't get rid of the $z$. and the question only said $x=1$ and $y=0$. Is that because I must put $z=1$? or should the derivative be ""free"" of $z$?",,"['calculus', 'multivariable-calculus', 'implicit-differentiation', 'implicit-function-theorem']"
6,Non-standard analysis way of proving that derivative of $e^x$ is $e^x$,Non-standard analysis way of proving that derivative of  is,e^x e^x,"What is the non-standard (infinitesimal) analysis way of proving that the derivative of $e^x$ is $e^x$? I tried to prove it myself, but I am having a hard time proving this without recourse to standard limit things.","What is the non-standard (infinitesimal) analysis way of proving that the derivative of $e^x$ is $e^x$? I tried to prove it myself, but I am having a hard time proving this without recourse to standard limit things.",,"['calculus', 'nonstandard-analysis', 'infinitesimals']"
7,A limit problem related to $\log \sec x$,A limit problem related to,\log \sec x,"If $$f(x) = \dfrac{{\displaystyle 3\int_{0}^{x}(1 + \sec t)\log\sec t\,dt}}{(\log\sec x)\{x + \log(\sec x + \tan x)\}}$$ then prove that $$\lim_{x \to {\pi/2}^{-}}f(x) = \frac{3}{2}$$ and $$\lim_{x \to 0}\frac{f(x) - 1}{x^{4}} = \frac{1}{420}$$ Looking at the integral sign in numerator I see that the best way to attack this problem is via L'Hospital Rule. But that requires to show that the integral diverges to $\infty$ as $x \to {\pi/2}^{-}$. Assuming that this is the case I solved the first limit by applying L'Hospital's rule twice. But for the second limit it seems hopeless to try L'Hospital because of denominator $x^{4}$ which might require 4 times its application. Looking at the functions involved it does not look easy to apply Taylor's series expansions. I am not sure if there is any elegant solution for the second problem. Please let me know any hints or a solution to the second limit. Update : I tried some simplification along with LHR for the second limit but still the final solution is eluding. Let $a(x), b(x)$ be the numerator and denominator of $f(x)$. Clearly we can see that \begin{align} B &= \lim_{x \to 0}\frac{b(x)}{x^{3}}\notag\\ &= \lim_{x \to 0}\frac{\log\sec x\{x + \log(\sec x + \tan x)\}}{x^{3}}\notag\\ &= -\lim_{x \to 0}\frac{\log\cos x\{x + \log(1 + \sin x) - \log \cos x\}}{x^{3}}\notag\\ &= -\lim_{x \to 0}\frac{\log\cos x}{x^{2}}\cdot\frac{x + \log(1 + \sin x) - \log \cos x}{x}\notag\\ &= -\lim_{x \to 0}\frac{\log(1 + \cos x - 1)}{\cos x - 1}\cdot\frac{\cos x - 1}{x^{2}}\cdot\frac{x + \log(1 + \sin x) - \log \cos x}{x}\notag\\ &= \frac{1}{2}\lim_{x \to 0}\frac{x + \log(1 + \sin x) - \log \cos x}{x}\notag\\ &= \frac{1}{2}\lim_{x \to 0}\left(1 + \frac{\log(1 + \sin x)}{\sin x}\cdot\frac{\sin x}{x} - \frac{\log (1 + \cos x - 1)}{\cos x - 1}\cdot x\cdot \frac{\cos x - 1}{x^{2}}\right)\notag\\ &= \frac{1}{2}\cdot 2 = 1\notag \end{align} Thus we can write \begin{align} L &= \lim_{x \to 0}\frac{f(x) - 1}{x^{4}}\notag\\ &= \lim_{x \to 0}\frac{a(x) - b(x)}{b(x)x^{4}}\notag\\ &= \lim_{x \to 0}\frac{a(x) - b(x)}{x^{7}}\cdot\frac{x^{3}}{b(x)}\notag\\ &= \lim_{x \to 0}\frac{a(x) - b(x)}{x^{7}}\notag\\ &= \frac{1}{7}\lim_{x \to 0}\frac{a'(x) - b'(x)}{x^{6}}\text{ (via L'Hospital's Rule)}\notag\\ &= \frac{1}{7}\lim_{x \to 0}\frac{3(1 + \sec x)\log\sec x - \tan x\{x + \log(\sec x + \tan x)\} -\log\sec x\{1 + \sec x\}}{x^{6}}\notag\\ &= \frac{1}{7}\lim_{x \to 0}\frac{2(1 + \sec x)\log\sec x - \tan x\{x + \log(\sec x + \tan x)\}}{x^{6}}\notag\\ &= \frac{1}{7}\lim_{x \to 0}\frac{2(1 + \cos x)\log\sec x - \sin x\{x + \log(\sec x + \tan x)\}}{x^{6}\cos x}\notag\\ &= \frac{1}{7}\lim_{x \to 0}\frac{2(1 + \cos x)\log\sec x - \sin x\{x + \log(\sec x + \tan x)\}}{x^{6}}\notag\\ \end{align} I wonder what could be done to go further.","If $$f(x) = \dfrac{{\displaystyle 3\int_{0}^{x}(1 + \sec t)\log\sec t\,dt}}{(\log\sec x)\{x + \log(\sec x + \tan x)\}}$$ then prove that $$\lim_{x \to {\pi/2}^{-}}f(x) = \frac{3}{2}$$ and $$\lim_{x \to 0}\frac{f(x) - 1}{x^{4}} = \frac{1}{420}$$ Looking at the integral sign in numerator I see that the best way to attack this problem is via L'Hospital Rule. But that requires to show that the integral diverges to $\infty$ as $x \to {\pi/2}^{-}$. Assuming that this is the case I solved the first limit by applying L'Hospital's rule twice. But for the second limit it seems hopeless to try L'Hospital because of denominator $x^{4}$ which might require 4 times its application. Looking at the functions involved it does not look easy to apply Taylor's series expansions. I am not sure if there is any elegant solution for the second problem. Please let me know any hints or a solution to the second limit. Update : I tried some simplification along with LHR for the second limit but still the final solution is eluding. Let $a(x), b(x)$ be the numerator and denominator of $f(x)$. Clearly we can see that \begin{align} B &= \lim_{x \to 0}\frac{b(x)}{x^{3}}\notag\\ &= \lim_{x \to 0}\frac{\log\sec x\{x + \log(\sec x + \tan x)\}}{x^{3}}\notag\\ &= -\lim_{x \to 0}\frac{\log\cos x\{x + \log(1 + \sin x) - \log \cos x\}}{x^{3}}\notag\\ &= -\lim_{x \to 0}\frac{\log\cos x}{x^{2}}\cdot\frac{x + \log(1 + \sin x) - \log \cos x}{x}\notag\\ &= -\lim_{x \to 0}\frac{\log(1 + \cos x - 1)}{\cos x - 1}\cdot\frac{\cos x - 1}{x^{2}}\cdot\frac{x + \log(1 + \sin x) - \log \cos x}{x}\notag\\ &= \frac{1}{2}\lim_{x \to 0}\frac{x + \log(1 + \sin x) - \log \cos x}{x}\notag\\ &= \frac{1}{2}\lim_{x \to 0}\left(1 + \frac{\log(1 + \sin x)}{\sin x}\cdot\frac{\sin x}{x} - \frac{\log (1 + \cos x - 1)}{\cos x - 1}\cdot x\cdot \frac{\cos x - 1}{x^{2}}\right)\notag\\ &= \frac{1}{2}\cdot 2 = 1\notag \end{align} Thus we can write \begin{align} L &= \lim_{x \to 0}\frac{f(x) - 1}{x^{4}}\notag\\ &= \lim_{x \to 0}\frac{a(x) - b(x)}{b(x)x^{4}}\notag\\ &= \lim_{x \to 0}\frac{a(x) - b(x)}{x^{7}}\cdot\frac{x^{3}}{b(x)}\notag\\ &= \lim_{x \to 0}\frac{a(x) - b(x)}{x^{7}}\notag\\ &= \frac{1}{7}\lim_{x \to 0}\frac{a'(x) - b'(x)}{x^{6}}\text{ (via L'Hospital's Rule)}\notag\\ &= \frac{1}{7}\lim_{x \to 0}\frac{3(1 + \sec x)\log\sec x - \tan x\{x + \log(\sec x + \tan x)\} -\log\sec x\{1 + \sec x\}}{x^{6}}\notag\\ &= \frac{1}{7}\lim_{x \to 0}\frac{2(1 + \sec x)\log\sec x - \tan x\{x + \log(\sec x + \tan x)\}}{x^{6}}\notag\\ &= \frac{1}{7}\lim_{x \to 0}\frac{2(1 + \cos x)\log\sec x - \sin x\{x + \log(\sec x + \tan x)\}}{x^{6}\cos x}\notag\\ &= \frac{1}{7}\lim_{x \to 0}\frac{2(1 + \cos x)\log\sec x - \sin x\{x + \log(\sec x + \tan x)\}}{x^{6}}\notag\\ \end{align} I wonder what could be done to go further.",,"['calculus', 'limits']"
8,Calculus in finitistic systems,Calculus in finitistic systems,,"I was just curious if there were some approaches to prove major theorems of calculus in finitistic systems like PRA ? Some related questions are, e.g., https://mathoverflow.net/questions/551/does-finite-math-need-the-axiom-of-infinity Math without infinity If all sets were finite, how could the real numbers be defined?","I was just curious if there were some approaches to prove major theorems of calculus in finitistic systems like PRA ? Some related questions are, e.g., https://mathoverflow.net/questions/551/does-finite-math-need-the-axiom-of-infinity Math without infinity If all sets were finite, how could the real numbers be defined?",,"['calculus', 'logic', 'constructive-mathematics', 'finitism']"
9,Complete and elementary proof that $(a^x - 1)/x $ converges as x goes to 0,Complete and elementary proof that  converges as x goes to 0,(a^x - 1)/x ,"Anybody who has taken a calculus course knows that $$\lim_{x \to 0} \frac{a^x - 1}{x}$$ exists for any positive real number $a$, simply because the limit is by definition the derivative of the function $a^x$ at $x = 0$.  However, for this argument to be non-circular one must have an independent technique for proving that $a^x$ is differentiable.  The standard approach involves the following two steps: 1) Calculate the derivative of $\log_a x$ by reducing it to the calculation of $$\lim_{h \to 0} (1 + h)^{\frac{1}{h}}$$ 2) Apply the inverse function theorem. I find this unsatisfying for two reasons.  First, the inverse function theorem is not entirely trivial, even in one variable.  Second, the limit in step 1 is quite difficult; in books it is often calculated along the sequence $h = \frac{1}{n}$ where $n$ runs over the positive integers, but doing the full calculation seems to be quite a bit more difficult (if one hopes to avoid circular reasoning). So I would like a different argument which uses only the elementary theory of limits and whatever algebra is needed.  For instance, I would like to avoid logarithms if their use involves an appeal to the inverse function theorem.  Is this possible?","Anybody who has taken a calculus course knows that $$\lim_{x \to 0} \frac{a^x - 1}{x}$$ exists for any positive real number $a$, simply because the limit is by definition the derivative of the function $a^x$ at $x = 0$.  However, for this argument to be non-circular one must have an independent technique for proving that $a^x$ is differentiable.  The standard approach involves the following two steps: 1) Calculate the derivative of $\log_a x$ by reducing it to the calculation of $$\lim_{h \to 0} (1 + h)^{\frac{1}{h}}$$ 2) Apply the inverse function theorem. I find this unsatisfying for two reasons.  First, the inverse function theorem is not entirely trivial, even in one variable.  Second, the limit in step 1 is quite difficult; in books it is often calculated along the sequence $h = \frac{1}{n}$ where $n$ runs over the positive integers, but doing the full calculation seems to be quite a bit more difficult (if one hopes to avoid circular reasoning). So I would like a different argument which uses only the elementary theory of limits and whatever algebra is needed.  For instance, I would like to avoid logarithms if their use involves an appeal to the inverse function theorem.  Is this possible?",,"['calculus', 'limits']"
10,Increasing and bounded sequence proof,Increasing and bounded sequence proof,,Prove that the sequence $a_n= 1+ \frac 12+ \frac 13+\cdots+ \frac 1n-\ln(⁡n)$ is increasing and bounded above. Conclude that it’s convergent. This what I got so far Proof: Part 1: Proving $a_n$ is increasing by induction. Base:  $a_1=1$ $a_2=1+\frac 12= \frac 32$ $a_1≤a_2$ So the base case is established. Induction step: We assume that $a_{n-1}≤a_n$. We will show that $a_n≤a_{n+1}$. Since $a_{n-1}≤a_n$ $$1+ \frac 12+ \frac 13+\cdots+ \frac{1}{(n-1)}-\ln(n-1) \leq 1+ \frac 12+ \frac 13+\cdots+ \frac 1n-\ln n$$ How should I continue?,Prove that the sequence $a_n= 1+ \frac 12+ \frac 13+\cdots+ \frac 1n-\ln(⁡n)$ is increasing and bounded above. Conclude that it’s convergent. This what I got so far Proof: Part 1: Proving $a_n$ is increasing by induction. Base:  $a_1=1$ $a_2=1+\frac 12= \frac 32$ $a_1≤a_2$ So the base case is established. Induction step: We assume that $a_{n-1}≤a_n$. We will show that $a_n≤a_{n+1}$. Since $a_{n-1}≤a_n$ $$1+ \frac 12+ \frac 13+\cdots+ \frac{1}{(n-1)}-\ln(n-1) \leq 1+ \frac 12+ \frac 13+\cdots+ \frac 1n-\ln n$$ How should I continue?,,"['calculus', 'proof-writing']"
11,Stuck on the integral $\int_0^{\infty}\frac{2+7\mathrm{cos}(x^\pi-e)-7\mathrm{sin}(1+x^8)}{1+x^2} \mathrm{d}x$,Stuck on the integral,\int_0^{\infty}\frac{2+7\mathrm{cos}(x^\pi-e)-7\mathrm{sin}(1+x^8)}{1+x^2} \mathrm{d}x,"Does anyone have any advice on how to evaluate the following integral? $$\int_0^{\infty}\frac{2+7\mathrm{cos}(x^\pi-e)-7\mathrm{sin}(1+x^8)}{1+x^2} \mathrm{d}x$$ It looks like it converges, but I have no idea where to even begin evaluating it. Any tips would be appreciated, thanks.","Does anyone have any advice on how to evaluate the following integral? $$\int_0^{\infty}\frac{2+7\mathrm{cos}(x^\pi-e)-7\mathrm{sin}(1+x^8)}{1+x^2} \mathrm{d}x$$ It looks like it converges, but I have no idea where to even begin evaluating it. Any tips would be appreciated, thanks.",,"['calculus', 'integration', 'improper-integrals']"
12,Alternative proof for differentiability of inverse function?,Alternative proof for differentiability of inverse function?,,"Problem Let $f$ be a continuous one-one function defined on an interval and suppose that $f$ is differentiable at $f^{-1}(b)$ with the derivative $f'(f^{-1}(x)) \neq 0$. Prove that $f^{-1}(x)$ is also differentiable at $b$. I read the proof in Spivak Calculus book, but it's quite confusing to me. Then I looked up online, and I saw exact the same proof everywhere. So I wonder is there an alternative proof to this problem that I'm not aware of? Here is the proof from Spivak book Theorem 5 (Calculus by Spivak 4th edition, page 237-238) Proof. Let $b = f(a)$. Then     $$\displaystyle\lim_{h\to 0} \dfrac{f^{-1}(b + h) - f^{-1}(b)}{h} = \displaystyle\lim_{h\to 0}  	\dfrac{f^{-1}(b + h) - a}{h}$$     Now every number $b + h$ in the domain of $f^{-1}$ can be written in the form     $$b + h = f(a + k)$$     for a unique $k$. Then     $$\displaystyle\lim_{h\to 0} \dfrac{f^{-1}(b + h) - a}{h}  	= \displaystyle\lim_{h\to 0}\dfrac{f^{-1}(f(a + k)) - a}{f(a + k) - b}  	= \displaystyle\lim_{h\to 0} \dfrac{k}{f(a + k) - f(a)}$$     We have     $$f^{-1}(b + h) = a + k \Leftrightarrow k = f^{-1}(b + h) - f^{-1}(b)$$     Since $f$ is continuous and one-one, $f^{-1}$ is also continuous at $b$. This means that $k$ approaches $0$ as $h$ approaches $0$. Since     $$\displaystyle\lim_{k\to 0} \dfrac{f(a + k) - f(a)}{k} = f'(a) = f'(f^{-1}(b)) \neq 0$$     this implies that     $$(f^{-1})'(b) = \dfrac{1}{f'(f^{-1}(b))}$$","Problem Let $f$ be a continuous one-one function defined on an interval and suppose that $f$ is differentiable at $f^{-1}(b)$ with the derivative $f'(f^{-1}(x)) \neq 0$. Prove that $f^{-1}(x)$ is also differentiable at $b$. I read the proof in Spivak Calculus book, but it's quite confusing to me. Then I looked up online, and I saw exact the same proof everywhere. So I wonder is there an alternative proof to this problem that I'm not aware of? Here is the proof from Spivak book Theorem 5 (Calculus by Spivak 4th edition, page 237-238) Proof. Let $b = f(a)$. Then     $$\displaystyle\lim_{h\to 0} \dfrac{f^{-1}(b + h) - f^{-1}(b)}{h} = \displaystyle\lim_{h\to 0}  	\dfrac{f^{-1}(b + h) - a}{h}$$     Now every number $b + h$ in the domain of $f^{-1}$ can be written in the form     $$b + h = f(a + k)$$     for a unique $k$. Then     $$\displaystyle\lim_{h\to 0} \dfrac{f^{-1}(b + h) - a}{h}  	= \displaystyle\lim_{h\to 0}\dfrac{f^{-1}(f(a + k)) - a}{f(a + k) - b}  	= \displaystyle\lim_{h\to 0} \dfrac{k}{f(a + k) - f(a)}$$     We have     $$f^{-1}(b + h) = a + k \Leftrightarrow k = f^{-1}(b + h) - f^{-1}(b)$$     Since $f$ is continuous and one-one, $f^{-1}$ is also continuous at $b$. This means that $k$ approaches $0$ as $h$ approaches $0$. Since     $$\displaystyle\lim_{k\to 0} \dfrac{f(a + k) - f(a)}{k} = f'(a) = f'(f^{-1}(b)) \neq 0$$     this implies that     $$(f^{-1})'(b) = \dfrac{1}{f'(f^{-1}(b))}$$",,"['calculus', 'derivatives']"
13,Area Bounded by Polar Curves,Area Bounded by Polar Curves,,"I am answering sample exams for my Calculus class and my attention was caught by the following item. Set-up the definite integral or sum of definite integrals equal to the area of the region above the polar axis, inside the limaçon $r = 3 + 2 \sin \theta$ and outside the lemniscate $r^2 = 32 \cos 2\theta$ given that the two curves intersect at $(4,\frac{\pi}{6})$. At first, I thought that the area is given by $$\dfrac{1}{2} \int_{\frac{\pi}{6}}^{\frac{5\pi}{6}}{[(3 + 2\sin \theta)^2 - (32 \cos 2\theta)] \mathrm{d}\theta}$$ but I know that the area of the lemniscate is tricky so I may have given a smaller area. My question is this: How do you know the limits of integration for lemniscates? (I know that the limits of integration for the area of the lemniscate alone is from $-\frac{\pi}{4}$ to $\frac{\pi}{4}$, but how about for small portions of the curve?) I'll appreciate any help. Thank you so much.","I am answering sample exams for my Calculus class and my attention was caught by the following item. Set-up the definite integral or sum of definite integrals equal to the area of the region above the polar axis, inside the limaçon $r = 3 + 2 \sin \theta$ and outside the lemniscate $r^2 = 32 \cos 2\theta$ given that the two curves intersect at $(4,\frac{\pi}{6})$. At first, I thought that the area is given by $$\dfrac{1}{2} \int_{\frac{\pi}{6}}^{\frac{5\pi}{6}}{[(3 + 2\sin \theta)^2 - (32 \cos 2\theta)] \mathrm{d}\theta}$$ but I know that the area of the lemniscate is tricky so I may have given a smaller area. My question is this: How do you know the limits of integration for lemniscates? (I know that the limits of integration for the area of the lemniscate alone is from $-\frac{\pi}{4}$ to $\frac{\pi}{4}$, but how about for small portions of the curve?) I'll appreciate any help. Thank you so much.",,"['calculus', 'polar-coordinates']"
14,Some basic practical applications of Calculus,Some basic practical applications of Calculus,,"I am currently studying Calculus on my own for fun.  I enjoy different components of math and how they can be used to solve so many problems. Many people, however, think I am crazy because I am studying mathematics in my spare time.  Many people ask me ""how will this ever be useful?"" and many times I cannot think of an answer.  Often, people do not understand the significance of certain things in math. For example, I would explain to someone how the Gamma function is like an extension of the factorial.  The usual response is ""Okay, how is that useful?""  When I attempt to explain, I then need to go into many other details about other concepts. What are some basic uses for Calculus and its functions?  I know that this is really vague, but I was hoping someone may help.","I am currently studying Calculus on my own for fun.  I enjoy different components of math and how they can be used to solve so many problems. Many people, however, think I am crazy because I am studying mathematics in my spare time.  Many people ask me ""how will this ever be useful?"" and many times I cannot think of an answer.  Often, people do not understand the significance of certain things in math. For example, I would explain to someone how the Gamma function is like an extension of the factorial.  The usual response is ""Okay, how is that useful?""  When I attempt to explain, I then need to go into many other details about other concepts. What are some basic uses for Calculus and its functions?  I know that this is really vague, but I was hoping someone may help.",,"['calculus', 'soft-question', 'learning']"
15,Find a closed form for :$\int_{0}^{1}\frac{x\log{x}\log^2{(1-x)}}{1+x^2}dx$,Find a closed form for :,\int_{0}^{1}\frac{x\log{x}\log^2{(1-x)}}{1+x^2}dx,"First of all, hello everyone, i am a new in  MSE community. I hope you guys all well. I found this integral on a web: $$\int_{0}^{1}\frac{x\log{x}\log^2{(1-x)}}{1+x^2}dx$$ I tried to IBP with $u=\log{x}\log^2{(1-x)}$ and $dv=\frac{x}{1+x^2}$ it to get: $$\int_{0}^{1}\frac{\log{x}\log{(1-x)}\log{(1+x^2)}}{1-x}dx-\frac{1}{2}\int_{0}^{1}\frac{\log{(x^2+1)}\log^2{(1-x)}}{x}dx$$ From here I got stuck, i know may be I misdirected. I tried to search our forum and found this link seems similar. The technique is unique, but I don't know how to apply it for my case. Can you guys give some advices or ideas? Thank you so much.","First of all, hello everyone, i am a new in  MSE community. I hope you guys all well. I found this integral on a web: I tried to IBP with and it to get: From here I got stuck, i know may be I misdirected. I tried to search our forum and found this link seems similar. The technique is unique, but I don't know how to apply it for my case. Can you guys give some advices or ideas? Thank you so much.",\int_{0}^{1}\frac{x\log{x}\log^2{(1-x)}}{1+x^2}dx u=\log{x}\log^2{(1-x)} dv=\frac{x}{1+x^2} \int_{0}^{1}\frac{\log{x}\log{(1-x)}\log{(1+x^2)}}{1-x}dx-\frac{1}{2}\int_{0}^{1}\frac{\log{(x^2+1)}\log^2{(1-x)}}{x}dx,"['calculus', 'integration']"
16,$\iint (x+y) dx dy $ What is my mistake?,What is my mistake?,\iint (x+y) dx dy ,"Question Solve the indefinite integral: $\iint (x+y) dx dy $ Attempt When calculating this indefinite double integral, I would first start with x and then y such that my solution would be: $\frac{1}2x^2 y + \frac{1}2y^2 x + c_1y + c_2$ But Wolfram Alpha's Solution is: $\frac{1}2x^2 y + \frac{1}2y^2 x + c_1x + c_2$ What am I doing wrong? Thanks in advance!","Question Solve the indefinite integral: Attempt When calculating this indefinite double integral, I would first start with x and then y such that my solution would be: But Wolfram Alpha's Solution is: What am I doing wrong? Thanks in advance!",\iint (x+y) dx dy  \frac{1}2x^2 y + \frac{1}2y^2 x + c_1y + c_2 \frac{1}2x^2 y + \frac{1}2y^2 x + c_1x + c_2,"['calculus', 'integration', 'analysis']"
17,Prove that the area of $M$ is bigger than the area of $\mathbb{S}^2$,Prove that the area of  is bigger than the area of,M \mathbb{S}^2,"Given $\mathbb{S}^2$ the unit sphere in $\mathbb{R}^3$ and let $f:\mathbb{S}^2\to \mathbb{R}$ be a $C^1$ function such that $f(x)\geq1$ for every $x\in\mathbb{S}^2$ and define $M=\{xf(x)|x\in\mathbb{S}^2\}$ 1.Prove that $M$ is smooth manifold with dimension of $2$ 2.Prove that the area of $M$ is bigger than the area of $\mathbb{S}^2$ Attempt: I proved it with composition of a map and f and showed that it is a regular parametrization. I've thought of doing the following $r:U\to\mathbb{S}^2$ map of the unit sphere $\int_M 1=\int_U \sqrt{\Gamma \left (\frac{d g}{dx_i} \right )}$ where $g(x_1,x_2)=r(x_1,x_2)f(r(x_1,x_2))$ but got stuck here and somehow to use the fact that $f(x)\geq1$ any hint?",Given the unit sphere in and let be a function such that for every and define 1.Prove that is smooth manifold with dimension of 2.Prove that the area of is bigger than the area of Attempt: I proved it with composition of a map and f and showed that it is a regular parametrization. I've thought of doing the following map of the unit sphere where but got stuck here and somehow to use the fact that any hint?,"\mathbb{S}^2 \mathbb{R}^3 f:\mathbb{S}^2\to \mathbb{R} C^1 f(x)\geq1 x\in\mathbb{S}^2 M=\{xf(x)|x\in\mathbb{S}^2\} M 2 M \mathbb{S}^2 r:U\to\mathbb{S}^2 \int_M 1=\int_U \sqrt{\Gamma \left (\frac{d g}{dx_i} \right )} g(x_1,x_2)=r(x_1,x_2)f(r(x_1,x_2)) f(x)\geq1","['calculus', 'integration', 'manifolds']"
18,If $u$ is a solution of $F(x) \cdot \nabla u = h(u) $ and $F(x) \cdot v(x)>0 \forall x \in \partial U$ then $u\equiv 0$,If  is a solution of  and  then,u F(x) \cdot \nabla u = h(u)  F(x) \cdot v(x)>0 \forall x \in \partial U u\equiv 0,"Let $U\subseteq \mathbb{R}^n$ open and bounded; $0 \in U $ and $\partial U$ is smooth. Let $u \in C^1(\bar{U})$ be a solution of the equation $$F(x) \cdot \nabla u = h(u),$$ with $F:\bar{U} \to \mathbb{R}^n$ continuous satisfying $F(x)\cdot v(x)>0, \forall x \in \partial U$ , where $v(x)$ is the normal unit vector exterior to $\partial U$ . If $h$ is a decreasing function and $h(0) = 0$ then $u \equiv 0$ . I have to solve this (yes, it is my homework, I signed up to some classes and I don't have the prerequisites and so I'm lost in almost everything I have to do. Please help me learn . I might need to know something very basic but I'm missing that piece of information). Now, given thet $\partial U$ is smooth I can use the divergence theorem on this. So far I have this: $$\int_U \nabla\cdot F(x) dx = \int_{\partial U} F(x) \cdot v(x) dx >0,$$ As $h$ is decreasing and $h(0)=0$ I know $h(x)\leq 0 \forall x \in \mathbb{R}$ and so $$0\geq\int_U h(u(x))dx = \int_U F(x)\cdot \nabla u(x) dx = \int_U \nabla\cdot [F(x)u(x)]dx - \int_U [\nabla\cdot F(x)]u(x)dx$$ So $$\int_U \nabla \cdot [F(x)u(x)]dx \leq \int_U[\nabla\cdot F(x)]u(x)dx$$ How do I carry on? I get that I should find something on the lines of: ""on one hand, on $\partial U$ we have that $F(x)\cdot v(x)$ is always positive, on the other $h(u(x))$ is never positive, so $u$ must be $0$ everyhere"". But I don't know how to do so. Thanks in advance. Tips provided by the professor today (haven't tried it yet, but I'll post it here already in case someone wants to give it a try as well). This is just my recollection of what he said in class, it is in no way formally written: The function u is $C^1(\bar{U})$ and therefore has a maximum (and minimum) value somewhere in $\bar{U}$ . Now we have two cases, either the maximum (and minimum) is inside $U$ or is in the boundary $\partial U$ . We'll talk about the maximum but the result follows similarly for the minimum. If u has it's maximum in $x \in U$ then we have that, at the maximum the gradient of $u$ is $0$ . and so $$h(u(x)) = F(x)\cdot \nabla u(x)  = F(x) \cdot 0 =0$$ as the function $h$ is decreasing, and $h(0) = 0$ , we have that $u(x)$ must be $0$ , as it is the only place where $h$ assumes the value $0$ . and so the maximum of the function $u(x)=0$ . Similarly we find that it's minimum is also $0$ , so $u \equiv 0$ . If on the other hand the maximum(and minimum) is on the boundary, then we have a problem. The professor sugested using ""Lagrange multiplier"" to solve this part. I have no clue what a lagrange multiplier is, but I'll read and after I learn it I believe I'll be able to solve the rest.","Let open and bounded; and is smooth. Let be a solution of the equation with continuous satisfying , where is the normal unit vector exterior to . If is a decreasing function and then . I have to solve this (yes, it is my homework, I signed up to some classes and I don't have the prerequisites and so I'm lost in almost everything I have to do. Please help me learn . I might need to know something very basic but I'm missing that piece of information). Now, given thet is smooth I can use the divergence theorem on this. So far I have this: As is decreasing and I know and so So How do I carry on? I get that I should find something on the lines of: ""on one hand, on we have that is always positive, on the other is never positive, so must be everyhere"". But I don't know how to do so. Thanks in advance. Tips provided by the professor today (haven't tried it yet, but I'll post it here already in case someone wants to give it a try as well). This is just my recollection of what he said in class, it is in no way formally written: The function u is and therefore has a maximum (and minimum) value somewhere in . Now we have two cases, either the maximum (and minimum) is inside or is in the boundary . We'll talk about the maximum but the result follows similarly for the minimum. If u has it's maximum in then we have that, at the maximum the gradient of is . and so as the function is decreasing, and , we have that must be , as it is the only place where assumes the value . and so the maximum of the function . Similarly we find that it's minimum is also , so . If on the other hand the maximum(and minimum) is on the boundary, then we have a problem. The professor sugested using ""Lagrange multiplier"" to solve this part. I have no clue what a lagrange multiplier is, but I'll read and after I learn it I believe I'll be able to solve the rest.","U\subseteq \mathbb{R}^n 0 \in U  \partial U u \in C^1(\bar{U}) F(x) \cdot \nabla u = h(u), F:\bar{U} \to \mathbb{R}^n F(x)\cdot v(x)>0, \forall x \in \partial U v(x) \partial U h h(0) = 0 u \equiv 0 \partial U \int_U \nabla\cdot F(x) dx = \int_{\partial U} F(x) \cdot v(x) dx >0, h h(0)=0 h(x)\leq 0 \forall x \in \mathbb{R} 0\geq\int_U h(u(x))dx = \int_U F(x)\cdot \nabla u(x) dx = \int_U \nabla\cdot [F(x)u(x)]dx - \int_U [\nabla\cdot F(x)]u(x)dx \int_U \nabla \cdot [F(x)u(x)]dx \leq \int_U[\nabla\cdot F(x)]u(x)dx \partial U F(x)\cdot v(x) h(u(x)) u 0 C^1(\bar{U}) \bar{U} U \partial U x \in U u 0 h(u(x)) = F(x)\cdot \nabla u(x)  = F(x) \cdot 0 =0 h h(0) = 0 u(x) 0 h 0 u(x)=0 0 u \equiv 0","['calculus', 'partial-differential-equations']"
19,Prove that the integral of a rapidly oscillating function is $0$,Prove that the integral of a rapidly oscillating function is,0,"Claim: If $n$ is a nonzero integer, then $$\int_{-\pi/2}^{\pi/2} \exp[{2in(x+\tan x)}] \ \mathrm{d}x = 0$$ Using Euler's identity $e^{ix}= \cos x + i \sin x$ , the fact that $\sin$ is an odd function so integrated over a symmetric integral gives $0$ , and the parity of $\cos$ , one gets $$\int_{0}^{\pi/2} \! \! \cos(2n(x+\tan x)) \ \mathrm{d}x$$ I tried using substitution, but it didn't get me anywhere. Is there maybe a general way to approach these rapidly oscillating integrals to show that the positive and negative areas cancel out?","Claim: If is a nonzero integer, then Using Euler's identity , the fact that is an odd function so integrated over a symmetric integral gives , and the parity of , one gets I tried using substitution, but it didn't get me anywhere. Is there maybe a general way to approach these rapidly oscillating integrals to show that the positive and negative areas cancel out?",n \int_{-\pi/2}^{\pi/2} \exp[{2in(x+\tan x)}] \ \mathrm{d}x = 0 e^{ix}= \cos x + i \sin x \sin 0 \cos \int_{0}^{\pi/2} \! \! \cos(2n(x+\tan x)) \ \mathrm{d}x,"['calculus', 'trigonometry', 'definite-integrals', 'oscillatory-integral']"
20,Non-numerical proof of an inequality,Non-numerical proof of an inequality,,"Let $ 0 < s < 1 $ be the unique solution to the equation $$ \frac{1}{2^s} + \frac{1}{6^s} + \frac{1}{12^s}=1, $$ and show that $$ \frac{1}{6^s}+\frac{1}{12^s} \geq \left(\frac{2}{7}\right)^s. $$ It is easy do this numerically; you can compute $ s \simeq 0.7584 $ with a calculator, and show that the desired inequality holds with this value plugged in. I'm looking for a more general proof, maybe geometric, using some calculus, or using concavity of the function $ x \mapsto x^s $ for $ 0 < s < 1 $ .","Let be the unique solution to the equation and show that It is easy do this numerically; you can compute with a calculator, and show that the desired inequality holds with this value plugged in. I'm looking for a more general proof, maybe geometric, using some calculus, or using concavity of the function for ."," 0 < s < 1   \frac{1}{2^s} + \frac{1}{6^s} + \frac{1}{12^s}=1,   \frac{1}{6^s}+\frac{1}{12^s} \geq \left(\frac{2}{7}\right)^s.   s \simeq 0.7584   x \mapsto x^s   0 < s < 1 ","['calculus', 'inequality', 'optimization', 'exponentiation', 'nonlinear-optimization']"
21,Maximum capacity of box without using Calculus?,Maximum capacity of box without using Calculus?,,"Lets use a square cardboard paper (side $s$ ) to make an open box. Remove four small squares from each corner and fold to make a rectangular box of height $x$ . To compute maximum possible volume, we can use AM-GM : $$ \sqrt[3]{(s-2x)(s-2x)\color{blue}{4}x} \le \dfrac{(s-2x)+(s-2x)+\color{blue}{4}x}{3} $$ $$ \Rightarrow V \le \dfrac{2}{27}s^3$$ Note : This matches the result obtained from calculus. Next take a rectangular paper ( $L \times B$ ) where $L > B$ . But AM-GM won't apply directly this time, since $L-2x > B-2x$ . This can be easily done by calculus. But I want to know if a valid solution using inequalities or other pre-Calculus methods exists? I tried : Let $(L-2x)=\lambda (B-2x)$ for maximum capacity. Then AM-GM, $$ \sqrt[3]{(L-2x)\lambda(B-2x)(2+2\lambda)x} \le \dfrac{(L-2x)+\lambda(B-2x)+(2+2\lambda)x}{3} $$ $$ \Rightarrow 2\lambda(1+\lambda)V \le \frac{1}{27}(L+\lambda B)^3$$ where $$ (L-2x)=\lambda(B-2x)=(2+2\lambda)x $$ gives a quadratic in $\lambda$ : $$\dfrac{\lambda (\lambda+2)}{2\lambda+1} = \dfrac{L}{B} = r$$ One obtains $$ V \le  \dfrac{(r+\lambda)^3}{\lambda (\lambda+1)} \dfrac{B^3}{54} $$ Is this correct? If it's incorrect, can this solution be improved? Or, does a different solution using pre-Calculus methods exist? Thank you for your time!","Lets use a square cardboard paper (side ) to make an open box. Remove four small squares from each corner and fold to make a rectangular box of height . To compute maximum possible volume, we can use AM-GM : Note : This matches the result obtained from calculus. Next take a rectangular paper ( ) where . But AM-GM won't apply directly this time, since . This can be easily done by calculus. But I want to know if a valid solution using inequalities or other pre-Calculus methods exists? I tried : Let for maximum capacity. Then AM-GM, where gives a quadratic in : One obtains Is this correct? If it's incorrect, can this solution be improved? Or, does a different solution using pre-Calculus methods exist? Thank you for your time!",s x  \sqrt[3]{(s-2x)(s-2x)\color{blue}{4}x} \le \dfrac{(s-2x)+(s-2x)+\color{blue}{4}x}{3}   \Rightarrow V \le \dfrac{2}{27}s^3 L \times B L > B L-2x > B-2x (L-2x)=\lambda (B-2x)  \sqrt[3]{(L-2x)\lambda(B-2x)(2+2\lambda)x} \le \dfrac{(L-2x)+\lambda(B-2x)+(2+2\lambda)x}{3}   \Rightarrow 2\lambda(1+\lambda)V \le \frac{1}{27}(L+\lambda B)^3  (L-2x)=\lambda(B-2x)=(2+2\lambda)x  \lambda \dfrac{\lambda (\lambda+2)}{2\lambda+1} = \dfrac{L}{B} = r  V \le  \dfrac{(r+\lambda)^3}{\lambda (\lambda+1)} \dfrac{B^3}{54} ,"['calculus', 'algebra-precalculus', 'inequality', 'maxima-minima', 'volume']"
22,"If $ f\geq0 $ and $ \intop_{0}^{\infty}f\left(x\right) $ converge, and $ \intop_{0}^{\infty}f'\left(x\right) $ converge, does it mean that:","If  and  converge, and  converge, does it mean that:", f\geq0   \intop_{0}^{\infty}f\left(x\right)   \intop_{0}^{\infty}f'\left(x\right) ,"Let $ f $ be non negative function, and differntiable such that $ f' $ is continious and $ \intop_{0}^{\infty}f\left(x\right),\intop_{0}^{\infty}f'\left(x\right) $ both converge. Is it true that $ \lim_{x\to\infty}f'\left(x\right)=0 $ ? I know that $ \lim_{x\to\infty}f\left(x\right)=0 $ for sure in this conditions. But Im not sure how to tell something about the limit of the deriviative. Thanks in advance","Let be non negative function, and differntiable such that is continious and both converge. Is it true that ? I know that for sure in this conditions. But Im not sure how to tell something about the limit of the deriviative. Thanks in advance"," f   f'   \intop_{0}^{\infty}f\left(x\right),\intop_{0}^{\infty}f'\left(x\right)   \lim_{x\to\infty}f'\left(x\right)=0   \lim_{x\to\infty}f\left(x\right)=0 ","['calculus', 'improper-integrals']"
23,Justifying $\sum_{n=0}^\infty\log(1+x^{2^n}) = -\log(1-x)$ for $0\le x<1$,Justifying  for,\sum_{n=0}^\infty\log(1+x^{2^n}) = -\log(1-x) 0\le x<1,"I studied the official solution to a Putnam competition problem and got stuck in a step, which is summarized as follows: For $0\le x<1$ , we have $$ \sum_{n=0}^\infty\log(1+x^{2^n}) = -\log(1-x)\tag{1} $$ My two closely related questions below are based on the justification of (1). The solution gave the following argument for justifying (1): Due to the uniqueness of binary expansions of nonnegative integers, we have the identity of formal power series $$ \frac{1}{1-x}=\prod_{n=0}^{\infty}\left(1+x^{2^{n}}\right)\,;\tag{2} $$ the product converges absolutely for $0\le x<1$ . But I don't understand what this means. Question 1 : In particular, how is ""the uniqueness of binary expansions of nonnegative integers"" used here? Naively, if we treat the infinite sum as a finite sum and apply (2), then we have $$ \sum_{n=0}^\infty\log(1+x^{2^n})  = \log \prod_{n=0}^{\infty}\left(1+x^{2^{n}}\right)  = \log \frac{1}{1-x} = -\log (1-x) \tag{3} $$ But Question 2 : how can one justify the first equal sign?","I studied the official solution to a Putnam competition problem and got stuck in a step, which is summarized as follows: For , we have My two closely related questions below are based on the justification of (1). The solution gave the following argument for justifying (1): Due to the uniqueness of binary expansions of nonnegative integers, we have the identity of formal power series the product converges absolutely for . But I don't understand what this means. Question 1 : In particular, how is ""the uniqueness of binary expansions of nonnegative integers"" used here? Naively, if we treat the infinite sum as a finite sum and apply (2), then we have But Question 2 : how can one justify the first equal sign?","0\le x<1 
\sum_{n=0}^\infty\log(1+x^{2^n}) = -\log(1-x)\tag{1}
 
\frac{1}{1-x}=\prod_{n=0}^{\infty}\left(1+x^{2^{n}}\right)\,;\tag{2}
 0\le x<1 
\sum_{n=0}^\infty\log(1+x^{2^n}) 
= \log \prod_{n=0}^{\infty}\left(1+x^{2^{n}}\right) 
= \log \frac{1}{1-x}
= -\log (1-x) \tag{3}
","['calculus', 'sequences-and-series']"
24,Proof regarding the minimum of a function,Proof regarding the minimum of a function,,"I want to show that the function $$f(x)= \frac{2x}{1+(\frac{1}{k-x})^a} +  \frac{k-2x}{1+2\cdot(\frac{1}{k-x})^a+ (\frac{1}{k-2x})^a}$$ with $$ x \in [0,\frac{k}{2}], a \in [0,\infty], k \in [0,1] $$ has the minimum $$min(f(x)) = \begin{cases} \frac{k}{1+3\cdot(\frac{1}{k})^a},\, a\leq \frac{log(3)}{log(2)} \\  \frac{k}{1+(\frac{1}{k/2})^a} ,\, else \end{cases}$$ for all permited values of the parameters $a,k$ . The minima can be obtained by setting either $x=0$ or $x=\frac{k}{2}$ . I checked that this is in fact the minimum by simulating the function for all permitted parameter values. My initial idea was to use the generalized version of the Binomial theorem  on the $1/(k-x)^a$ terms, but this only worked for $a\leq2$ because the elements of the series obtained from the theorem are not shrinking in absolute value. Another idea was to show that every critical point of the function is never a global minimum, but I cannot find a solution for $f'(x)=0$ . Any ideas would be greatly appreciated. Thanks in advance.","I want to show that the function with has the minimum for all permited values of the parameters . The minima can be obtained by setting either or . I checked that this is in fact the minimum by simulating the function for all permitted parameter values. My initial idea was to use the generalized version of the Binomial theorem  on the terms, but this only worked for because the elements of the series obtained from the theorem are not shrinking in absolute value. Another idea was to show that every critical point of the function is never a global minimum, but I cannot find a solution for . Any ideas would be greatly appreciated. Thanks in advance.","f(x)= \frac{2x}{1+(\frac{1}{k-x})^a} +  \frac{k-2x}{1+2\cdot(\frac{1}{k-x})^a+ (\frac{1}{k-2x})^a}  x \in [0,\frac{k}{2}], a \in [0,\infty], k \in [0,1]  min(f(x)) = \begin{cases}
\frac{k}{1+3\cdot(\frac{1}{k})^a},\, a\leq \frac{log(3)}{log(2)}
\\ 
\frac{k}{1+(\frac{1}{k/2})^a} ,\, else
\end{cases} a,k x=0 x=\frac{k}{2} 1/(k-x)^a a\leq2 f'(x)=0","['calculus', 'inequality', 'curves', 'maxima-minima']"
25,"If $\lim_{x \rightarrow 0}\frac{f(x)}{x^2} = 5$, then what is $\lim_{x \rightarrow 0}f(x)$?","If , then what is ?",\lim_{x \rightarrow 0}\frac{f(x)}{x^2} = 5 \lim_{x \rightarrow 0}f(x),"I know the answer to the above question, but I have a question on some of the reasoning. The way I know how to solve it is $$\lim_{x \rightarrow 0}f(x) = \lim_{x \rightarrow 0}\left(f(x)\cdot \frac{x^2}{x^2}\right) = \lim_{x \rightarrow 0}\left(\frac{f(x)}{x^2}\cdot x^2\right) = \left(\lim_{x \rightarrow 0}\frac{f(x)}{x^2}\right)\left(\lim_{x \rightarrow 0}x^2\right) = 5\cdot0 = 0.$$ I saw another solution elsewhere that gets the right answer, but I am unsure if the steps are actually correct. \begin{align*} &\lim_{x \rightarrow 0}\frac{f(x)}{x^2} = 5 \\ \Longrightarrow &\frac{\lim_{x \rightarrow 0}f(x)}{\lim_{x \rightarrow 0}x^2} = 5 \\  \Longrightarrow &\lim_{x \rightarrow 0}f(x) = 5\cdot \lim_{x \rightarrow 0}x^2\\ \Longrightarrow &\lim_{x \rightarrow 0}f(x) = 5\cdot 0 = 0. \end{align*} My issue is with that first step. I know that $\lim_{x \rightarrow a} \frac{f(x)}{g(x)} = \frac{\lim_{x \rightarrow a}f(x)}{\lim_{x \rightarrow a}g(x)}$ , but only when $\lim_{x \rightarrow a}g(x) \neq 0$ . Since $\lim_{x \rightarrow 0}x^2 = 0$ , wouldn't this invalidate the above work? However, it still got the same answer, so my real question is why did it work and when will it work in general? EDIT: Does anyone have a nice example for when the logic in the second method doesn't work?","I know the answer to the above question, but I have a question on some of the reasoning. The way I know how to solve it is I saw another solution elsewhere that gets the right answer, but I am unsure if the steps are actually correct. My issue is with that first step. I know that , but only when . Since , wouldn't this invalidate the above work? However, it still got the same answer, so my real question is why did it work and when will it work in general? EDIT: Does anyone have a nice example for when the logic in the second method doesn't work?","\lim_{x \rightarrow 0}f(x) = \lim_{x \rightarrow 0}\left(f(x)\cdot \frac{x^2}{x^2}\right) = \lim_{x \rightarrow 0}\left(\frac{f(x)}{x^2}\cdot x^2\right) = \left(\lim_{x \rightarrow 0}\frac{f(x)}{x^2}\right)\left(\lim_{x \rightarrow 0}x^2\right) = 5\cdot0 = 0. \begin{align*}
&\lim_{x \rightarrow 0}\frac{f(x)}{x^2} = 5 \\
\Longrightarrow &\frac{\lim_{x \rightarrow 0}f(x)}{\lim_{x \rightarrow 0}x^2} = 5 \\ 
\Longrightarrow &\lim_{x \rightarrow 0}f(x) = 5\cdot \lim_{x \rightarrow 0}x^2\\ \Longrightarrow &\lim_{x \rightarrow 0}f(x) = 5\cdot 0 = 0.
\end{align*} \lim_{x \rightarrow a} \frac{f(x)}{g(x)} = \frac{\lim_{x \rightarrow a}f(x)}{\lim_{x \rightarrow a}g(x)} \lim_{x \rightarrow a}g(x) \neq 0 \lim_{x \rightarrow 0}x^2 = 0",['calculus']
26,Volume of a tetrahedron whose 4 faces are congruent.,Volume of a tetrahedron whose 4 faces are congruent.,,"Suppose that I have a tetrahedron such that all four faces consist of congruent triangles, says with the lengths $a,b$ and $c$ for each side. Is there a beautiful method to compute its volume? PS. The reason for me tagging calculus and linear algebra is that I figured that the technique used to calculate such a problem may come from this areas.","Suppose that I have a tetrahedron such that all four faces consist of congruent triangles, says with the lengths $a,b$ and $c$ for each side. Is there a beautiful method to compute its volume? PS. The reason for me tagging calculus and linear algebra is that I figured that the technique used to calculate such a problem may come from this areas.",,"['calculus', 'linear-algebra', 'geometry', 'trigonometry']"
27,How much ketchup is on the table? (Ketchup flow rate problem),How much ketchup is on the table? (Ketchup flow rate problem),,"This is a question I came up with while watching my friend squirt ketchup onto his table. He was squirting the ketchup out of a bottle while moving the bottle upwards. A ketchup bottle starts upside down with the tip at the table. Ketchup is squirted out at a volume flow rate of $Q(t)$, in $\frac{m^3}{s}$, while the bottle itself is moving upwards at a rate of $v(t$), in $\frac{m}{s}$. When the ketchup comes out of the bottle it is always initially not moving, but immediately starts falling to the table due to gravity ($g = 10 \frac{m}{s^2}$ downwards). Find $V(t)$, the volume of ketchup on the table as a function of time. Edit 1: We can ignore the fact that in real life the accumulating ketchup on the table will, in some sense, increase the height of the table.","This is a question I came up with while watching my friend squirt ketchup onto his table. He was squirting the ketchup out of a bottle while moving the bottle upwards. A ketchup bottle starts upside down with the tip at the table. Ketchup is squirted out at a volume flow rate of $Q(t)$, in $\frac{m^3}{s}$, while the bottle itself is moving upwards at a rate of $v(t$), in $\frac{m}{s}$. When the ketchup comes out of the bottle it is always initially not moving, but immediately starts falling to the table due to gravity ($g = 10 \frac{m}{s^2}$ downwards). Find $V(t)$, the volume of ketchup on the table as a function of time. Edit 1: We can ignore the fact that in real life the accumulating ketchup on the table will, in some sense, increase the height of the table.",,"['calculus', 'integration', 'derivatives', 'physics', 'word-problem']"
28,How to find the indefinite integral of sin(sin(x))dx?,How to find the indefinite integral of sin(sin(x))dx?,,"(I got this function by mistake, when I miswrote other function. Now I'm curious how to find the antiderivative of what I miswrote) I have no a clue how to calculate it and neither does Wolfram Alpha or any other site that I tried. Trig formulas from school course don't seem to be useful too.","(I got this function by mistake, when I miswrote other function. Now I'm curious how to find the antiderivative of what I miswrote) I have no a clue how to calculate it and neither does Wolfram Alpha or any other site that I tried. Trig formulas from school course don't seem to be useful too.",,"['calculus', 'indefinite-integrals']"
29,Geometric (or Intuitive) proof of the improper integration of $\frac1x $,Geometric (or Intuitive) proof of the improper integration of,\frac1x ,"From a mathematical standpoint, I understand and I can solve the following: $$ \lim_{M\rightarrow\infty} \int_1^M \left({1 \over x}\right) \rightarrow \infty $$ Additionally, $$ \lim_{M\rightarrow\infty} \int_1^M \left({1 \over x^2}\right) \rightarrow 1 $$ This all makes mathematical sense to me. It's the geometric parts that confuse me.  The family of of $ 1/x^p $ graphs look very similar to me, so it makes me wonder why $ 1/x $ doesn't converge to some value as well. Especially considering the fact when you rotate $ 1/x $ and calculate the volume of that shape; it converges to some value. Again, mathematically, this makes sense because: $$ \lim_{M\rightarrow\infty}\int_1^M \left({1 \over x}\right) dx > \lim_{M\rightarrow\infty} \int_1^M \pi\left({1 \over x^2}\right) dx $$ But the geometric implications of this are that a cross-section of such an object has an infinite area but the volume is some finite value. My questions: Using an intuitive or geometric explanation, why doesn't $ 1\over x $ converge to some value? Why is the volume described above finite while the cross-section is infinite? Edit: Changed $[]$ to $()$","From a mathematical standpoint, I understand and I can solve the following: $$ \lim_{M\rightarrow\infty} \int_1^M \left({1 \over x}\right) \rightarrow \infty $$ Additionally, $$ \lim_{M\rightarrow\infty} \int_1^M \left({1 \over x^2}\right) \rightarrow 1 $$ This all makes mathematical sense to me. It's the geometric parts that confuse me.  The family of of $ 1/x^p $ graphs look very similar to me, so it makes me wonder why $ 1/x $ doesn't converge to some value as well. Especially considering the fact when you rotate $ 1/x $ and calculate the volume of that shape; it converges to some value. Again, mathematically, this makes sense because: $$ \lim_{M\rightarrow\infty}\int_1^M \left({1 \over x}\right) dx > \lim_{M\rightarrow\infty} \int_1^M \pi\left({1 \over x^2}\right) dx $$ But the geometric implications of this are that a cross-section of such an object has an infinite area but the volume is some finite value. My questions: Using an intuitive or geometric explanation, why doesn't $ 1\over x $ converge to some value? Why is the volume described above finite while the cross-section is infinite? Edit: Changed $[]$ to $()$",,"['calculus', 'integration', 'improper-integrals', 'volume']"
30,Prove $\lim_{n\to\infty} 2^n \sqrt{2-x_n} = \pi$,Prove,\lim_{n\to\infty} 2^n \sqrt{2-x_n} = \pi,"Given the sequence $x_1 = 0$, $x_{n+1} = \sqrt{2+x_n}$, proove: $$\lim_{n\to\infty} 2^n \sqrt{2-x_n} = \pi$$ I have used the relations $$2\cos({\frac x 2}) = \sqrt{2 + 2\cos(x)}$$ and $$2\sin({\frac x 2}) = \sqrt{2 - 2\cos(x)}$$ Observe: $x_1 = 0 = 2\cos(\alpha) \iff \alpha = \frac \pi 2$ I then hoped we can set $x_n = 2\cos(\frac{\alpha}{2^{n-1}})$ but if we can do this, why is that? I assummed we can, so: $\lim_{n\to\infty} 2^n \sqrt{2-x_n} = \lim_{n\to\infty} 2^n \sqrt{2-2\cos(\frac{\alpha}{2^{n-1}})} = \lim_{n\to\infty} 2^n \sqrt{4 \sin^2(\frac{\alpha}{2^n})}$ We know $$\alpha = \frac \pi 2$$ By substituting: $ = \lim_{n\to\infty} 2^{n+1} \sin(\frac{\pi}{2^{n+1}})$ Again, by substituting $$\frac{\pi}{2^{n+1}} = \frac 1 m$$ $= \lim_{m\to\infty} \pi m \sin(\frac 1 m)= \pi$ Is this proof correct, and if not, how to prove it? The even more important question is the why is that? part mentioned above.","Given the sequence $x_1 = 0$, $x_{n+1} = \sqrt{2+x_n}$, proove: $$\lim_{n\to\infty} 2^n \sqrt{2-x_n} = \pi$$ I have used the relations $$2\cos({\frac x 2}) = \sqrt{2 + 2\cos(x)}$$ and $$2\sin({\frac x 2}) = \sqrt{2 - 2\cos(x)}$$ Observe: $x_1 = 0 = 2\cos(\alpha) \iff \alpha = \frac \pi 2$ I then hoped we can set $x_n = 2\cos(\frac{\alpha}{2^{n-1}})$ but if we can do this, why is that? I assummed we can, so: $\lim_{n\to\infty} 2^n \sqrt{2-x_n} = \lim_{n\to\infty} 2^n \sqrt{2-2\cos(\frac{\alpha}{2^{n-1}})} = \lim_{n\to\infty} 2^n \sqrt{4 \sin^2(\frac{\alpha}{2^n})}$ We know $$\alpha = \frac \pi 2$$ By substituting: $ = \lim_{n\to\infty} 2^{n+1} \sin(\frac{\pi}{2^{n+1}})$ Again, by substituting $$\frac{\pi}{2^{n+1}} = \frac 1 m$$ $= \lim_{m\to\infty} \pi m \sin(\frac 1 m)= \pi$ Is this proof correct, and if not, how to prove it? The even more important question is the why is that? part mentioned above.",,"['calculus', 'algebra-precalculus']"
31,"how to $\int_0^{ +\infty} \frac{\sin(x)}{x+1}\, dx \leq \frac e5 \ln(\pi)$?",how to ?,"\int_0^{ +\infty} \frac{\sin(x)}{x+1}\, dx \leq \frac e5 \ln(\pi)","I need to prove irreproachably that $$\int_0^{ +\infty} \frac{\sin(x)}{x+1}\, dx \leq \frac e5 \ln(\pi)$$ . With an approximate calculation $\int_0^{ +\infty} \frac{\sin(x)}{x+1}\, dx\approx 0.62145$ and $\frac e5 \ln(\pi)\approx 0.62233$ We can see by Laplace transform that $$\int_{0}^{+\infty}\frac{\sin x}{1+x}\,dx = \int_{0}^{+\infty}\frac{e^{-s}}{1+s^2}\,ds $$ and deduce $$\int_{0}^{+\infty}\frac{\sin x}{1+x}\,dx = \int_{0}^{+\infty}\frac{e^{-s}}{1+s^2}\,ds\leq  \sqrt{\int_{0}^{+\infty}\frac{ds}{(1+s^2)^2 } } \sqrt{\int_{0}^{+\infty} e^{-2s}  ds} = \sqrt{\frac{\pi}{8}}.$$ But $\frac e5 \ln(\pi)< \sqrt{\frac{\pi}{8}}$","I need to prove irreproachably that $$\int_0^{ +\infty} \frac{\sin(x)}{x+1}\, dx \leq \frac e5 \ln(\pi)$$ . With an approximate calculation $\int_0^{ +\infty} \frac{\sin(x)}{x+1}\, dx\approx 0.62145$ and $\frac e5 \ln(\pi)\approx 0.62233$ We can see by Laplace transform that $$\int_{0}^{+\infty}\frac{\sin x}{1+x}\,dx = \int_{0}^{+\infty}\frac{e^{-s}}{1+s^2}\,ds $$ and deduce $$\int_{0}^{+\infty}\frac{\sin x}{1+x}\,dx = \int_{0}^{+\infty}\frac{e^{-s}}{1+s^2}\,ds\leq  \sqrt{\int_{0}^{+\infty}\frac{ds}{(1+s^2)^2 } } \sqrt{\int_{0}^{+\infty} e^{-2s}  ds} = \sqrt{\frac{\pi}{8}}.$$ But $\frac e5 \ln(\pi)< \sqrt{\frac{\pi}{8}}$",,"['calculus', 'inequality']"
32,Proof that $a^{\tan x} + a^{\cot x} \leq 2a$ where $\frac{1}{2} \leq a \leq 1$ and $0 \leq x \leq \frac{\pi}{4}$,Proof that  where  and,a^{\tan x} + a^{\cot x} \leq 2a \frac{1}{2} \leq a \leq 1 0 \leq x \leq \frac{\pi}{4},"$a^{\tan x}+a^{\cot x} \leq 2a$ where $\frac{1}{2} \leq a \leq 1$ and $0 \leq x \leq \frac{\pi}{4}$ I would like to prove the inequality which is given above. I spent all day thinking about it - I tried some inequalities like relation between exponential and linear or Jensen, but it doesn't work. I tried also by calculus - but when we calculate the derivative and assume it is equal to 0 we have an equality which isn't easy to solve. Maybe anyone has an idea, maybe it's easy and I don't know why I have a problem... I would be grateful if you gave me a hint, I don't want a full solution :)","$a^{\tan x}+a^{\cot x} \leq 2a$ where $\frac{1}{2} \leq a \leq 1$ and $0 \leq x \leq \frac{\pi}{4}$ I would like to prove the inequality which is given above. I spent all day thinking about it - I tried some inequalities like relation between exponential and linear or Jensen, but it doesn't work. I tried also by calculus - but when we calculate the derivative and assume it is equal to 0 we have an equality which isn't easy to solve. Maybe anyone has an idea, maybe it's easy and I don't know why I have a problem... I would be grateful if you gave me a hint, I don't want a full solution :)",,"['calculus', 'trigonometry', 'inequality', 'contest-math', 'exponential-function']"
33,Solving differential equation with two variables,Solving differential equation with two variables,,"How to solve a differential equation of the following form: $\dfrac{ax}{\dfrac{\partial{f(x,y)}}{\partial x}} + \dfrac{by}{\dfrac{\partial{f(x,y)}}{\partial y}}=-1 $ Where, $f(x_0,y_0)=c$.","How to solve a differential equation of the following form: $\dfrac{ax}{\dfrac{\partial{f(x,y)}}{\partial x}} + \dfrac{by}{\dfrac{\partial{f(x,y)}}{\partial y}}=-1 $ Where, $f(x_0,y_0)=c$.",,"['calculus', 'partial-differential-equations']"
34,Calculate return on investment (ROI),Calculate return on investment (ROI),,"Before coming to the question, I'll quickly explain how to calculate NPV (Net present value) with an example Information Available Equipment Cost - \$20,000 Annual Benefit - \$6,000 Scrap Value - \$2,000 Years in Service ($n$) - 4 Years Inflation Rate/Interest Rate ($r$) - 7% What is NPV Net Present Value is the amount of money we'll have from our investment in a particular product during the course of it's service. We calculate first the Present Value (PV) by $$\textrm{PV} = \sum_{k=1}^{n-1}\left(\frac{\textrm{Annual Benefit}}{(1+r)^k}\right)\quad + \quad \frac{\textrm{Annual Benefit}+\textrm{Scrap Value}}{(1+r)^n}$$ that is, the present value of each annual benefit over the lifetime, plus the present value of the final year benefit. For Final Year, we add the scrap value to annual benefit as well. For this case the values we get are Y1 = \$5,607 Y2 = \$5,240 Y3 = \$4,897 Y4 = \$6,103 Add them all together we get \$21,849. So at the end of 4 years we made \$21,849 on an investment of \$20000 in terms of today's money. $$\textrm{NPV} = 21,849 - 20,000 = \textbf{\$1,849}$$ ROI Now ROI is the value of r (Interest Rate) at which NPV comes out to be 0. At a certain value of r (for this case it's 11%), when you run the formula 4 times (for four years), the four values add up to 20,000 (the initial investment) Can you calculate it  with a formula? PS - Can someone suggest better tags?","Before coming to the question, I'll quickly explain how to calculate NPV (Net present value) with an example Information Available Equipment Cost - \$20,000 Annual Benefit - \$6,000 Scrap Value - \$2,000 Years in Service ($n$) - 4 Years Inflation Rate/Interest Rate ($r$) - 7% What is NPV Net Present Value is the amount of money we'll have from our investment in a particular product during the course of it's service. We calculate first the Present Value (PV) by $$\textrm{PV} = \sum_{k=1}^{n-1}\left(\frac{\textrm{Annual Benefit}}{(1+r)^k}\right)\quad + \quad \frac{\textrm{Annual Benefit}+\textrm{Scrap Value}}{(1+r)^n}$$ that is, the present value of each annual benefit over the lifetime, plus the present value of the final year benefit. For Final Year, we add the scrap value to annual benefit as well. For this case the values we get are Y1 = \$5,607 Y2 = \$5,240 Y3 = \$4,897 Y4 = \$6,103 Add them all together we get \$21,849. So at the end of 4 years we made \$21,849 on an investment of \$20000 in terms of today's money. $$\textrm{NPV} = 21,849 - 20,000 = \textbf{\$1,849}$$ ROI Now ROI is the value of r (Interest Rate) at which NPV comes out to be 0. At a certain value of r (for this case it's 11%), when you run the formula 4 times (for four years), the four values add up to 20,000 (the initial investment) Can you calculate it  with a formula? PS - Can someone suggest better tags?",,"['calculus', 'finance']"
35,What is the infinite dimensional counterpart of the Lie derivative?,What is the infinite dimensional counterpart of the Lie derivative?,,"In a finite dimensional space, one calculates the Lie derivative as $L_f(g)(x) = \langle \nabla g, f \rangle$ What is the equivalent in an infinite dimensional space? For example if $g$ takes as argument a function and $f$ is an infinite dimensional vector, how does one think about the Lie derivative? I am familiar with the Gateau derivative, so does one simply replace the gradient with this? Then we might have $L_f(g)(x) = \langle dg, f \rangle$ for some appropriate inner product? for instance $L^2$?","In a finite dimensional space, one calculates the Lie derivative as $L_f(g)(x) = \langle \nabla g, f \rangle$ What is the equivalent in an infinite dimensional space? For example if $g$ takes as argument a function and $f$ is an infinite dimensional vector, how does one think about the Lie derivative? I am familiar with the Gateau derivative, so does one simply replace the gradient with this? Then we might have $L_f(g)(x) = \langle dg, f \rangle$ for some appropriate inner product? for instance $L^2$?",,"['calculus', 'functional-analysis', 'lie-derivative', 'gateaux-derivative']"
36,"Taylor Series as a linear operator $T:C^{k} (\mathbb{R} , \mathbb{R}) \to C^{\infty} (\mathbb{R} , \mathbb{R})$?",Taylor Series as a linear operator ?,"T:C^{k} (\mathbb{R} , \mathbb{R}) \to C^{\infty} (\mathbb{R} , \mathbb{R})","Can the Taylor series be thought of as either a linear operator $T: C^{k} (\mathbb{R} , \mathbb{R}) \to C^{\infty} (\mathbb{R} , \mathbb{R})$  given by $$ Tf=\sum^{k}_{n=0} \frac{f^{(n)}(a)}{n!}(x-a)^{n}  $$ for $f \in C^{k} (\mathbb{R} , \mathbb{R})$ with the special case  $T:C^{\infty} (\mathbb{R} , \mathbb{R}) \to C^{\infty} (\mathbb{R} , \mathbb{R})$ given by  $$ Tf =\sum^{\infty}_{n=0} \frac{f^{(n)}(a)}{n!}(x-a)^{n}$$ for a function $f \in C^{\infty}(\mathbb{R} , \mathbb{R})$? The idea just popped into my head and I wanted to make sure I wasn't going down the rabbit hole.","Can the Taylor series be thought of as either a linear operator $T: C^{k} (\mathbb{R} , \mathbb{R}) \to C^{\infty} (\mathbb{R} , \mathbb{R})$  given by $$ Tf=\sum^{k}_{n=0} \frac{f^{(n)}(a)}{n!}(x-a)^{n}  $$ for $f \in C^{k} (\mathbb{R} , \mathbb{R})$ with the special case  $T:C^{\infty} (\mathbb{R} , \mathbb{R}) \to C^{\infty} (\mathbb{R} , \mathbb{R})$ given by  $$ Tf =\sum^{\infty}_{n=0} \frac{f^{(n)}(a)}{n!}(x-a)^{n}$$ for a function $f \in C^{\infty}(\mathbb{R} , \mathbb{R})$? The idea just popped into my head and I wanted to make sure I wasn't going down the rabbit hole.",,"['calculus', 'functional-analysis', 'taylor-expansion']"
37,Close approximation for absolute value function,Close approximation for absolute value function,,"I made a very acurate approximation function for $\sqrt{n^{2}+1}$ It is $\sqrt{n^{2}+1}\approx\frac{2n(n^{2}+1)}{2n^{2}+1}+\frac{2n^{2}+1}{n(4(2n^{2}+1)^{2}+1)}$ From this I can make a very close approximation of absolute value of n, $\mid n\mid\approx\frac{1}{\sqrt{n^{2}+1}}\left(\frac{2n^{2}(n^{2}+1)}{2n^{2}+1}+\frac{2n^{2}+1}{4(2n^{2}+1)^{2}+1}\right)$ My question is if this is interesting in any way to anybody? It doesn't look like it would make any integral easier. Except maybe the square root approximation may make some integrals for arc length easier to solve with great accuracy, because you could just enter the derivative of your function as n in the equation. Seems though it would be more complicated most of the time. Any thoughts? Note: I have provided a somewhat detailed explanation of how this formula was derived in an answer below.","I made a very acurate approximation function for It is From this I can make a very close approximation of absolute value of n, My question is if this is interesting in any way to anybody? It doesn't look like it would make any integral easier. Except maybe the square root approximation may make some integrals for arc length easier to solve with great accuracy, because you could just enter the derivative of your function as n in the equation. Seems though it would be more complicated most of the time. Any thoughts? Note: I have provided a somewhat detailed explanation of how this formula was derived in an answer below.",\sqrt{n^{2}+1} \sqrt{n^{2}+1}\approx\frac{2n(n^{2}+1)}{2n^{2}+1}+\frac{2n^{2}+1}{n(4(2n^{2}+1)^{2}+1)} \mid n\mid\approx\frac{1}{\sqrt{n^{2}+1}}\left(\frac{2n^{2}(n^{2}+1)}{2n^{2}+1}+\frac{2n^{2}+1}{4(2n^{2}+1)^{2}+1}\right),"['calculus', 'arithmetic', 'radicals', 'absolute-value', 'approximation-theory']"
38,Is the indefinite integral of a piecewise continuous function a continuous function?,Is the indefinite integral of a piecewise continuous function a continuous function?,,"I had looked around on the web and can't find much information related to the integration of piecewise continuous functions. Let's say we have a simple function $$f(x)= \begin{cases}        0 & x\leq 0 \\       x & 0\leq x\leq 1 \\       0 & x>1 \end{cases}$$ and we are looking to find the integral $\int f(x) dx$ WolframAlpha gives me the following result: $$\int f(x) dx= \begin{cases}        c & x\leq 0 \\       \frac{x^2}{2}+c & 0\leq x\leq 1 \\       \frac{1}{2}+c & x>1 \end{cases}$$ The cases $x\leq 0$ and $0\leq x\leq 1$ are clear. But why do we need the $\frac{1}{2}$ for the $x>1$ case? I see that this makes the integral continuous but is it necessary, i.e. is it wrong to have simply $c$ for the $x>1$ case for the integral?","I had looked around on the web and can't find much information related to the integration of piecewise continuous functions. Let's say we have a simple function $$f(x)= \begin{cases}        0 & x\leq 0 \\       x & 0\leq x\leq 1 \\       0 & x>1 \end{cases}$$ and we are looking to find the integral $\int f(x) dx$ WolframAlpha gives me the following result: $$\int f(x) dx= \begin{cases}        c & x\leq 0 \\       \frac{x^2}{2}+c & 0\leq x\leq 1 \\       \frac{1}{2}+c & x>1 \end{cases}$$ The cases $x\leq 0$ and $0\leq x\leq 1$ are clear. But why do we need the $\frac{1}{2}$ for the $x>1$ case? I see that this makes the integral continuous but is it necessary, i.e. is it wrong to have simply $c$ for the $x>1$ case for the integral?",,"['calculus', 'indefinite-integrals', 'piecewise-continuity']"
39,"Integration involving greatest integer function : $\int_0^{\pi} [\cot(x)] \, dx$",Integration involving greatest integer function :,"\int_0^{\pi} [\cot(x)] \, dx",What the integral of $$\int_0^{\pi} [\cot(x)]dx$$  where $[\cdot]$ represents greatest integer function. I know integral of $\cot$ is $|\log(\sin(x))|$ but $\log$ is not defined for $0$ or is there something else I'm forgetting?,What the integral of $$\int_0^{\pi} [\cot(x)]dx$$  where $[\cdot]$ represents greatest integer function. I know integral of $\cot$ is $|\log(\sin(x))|$ but $\log$ is not defined for $0$ or is there something else I'm forgetting?,,"['calculus', 'integration', 'algebra-precalculus', 'definite-integrals']"
40,Find the value of $\int_{0}^{\pi}e^{\cos\theta}\cos(\sin\theta)d\theta$.,Find the value of .,\int_{0}^{\pi}e^{\cos\theta}\cos(\sin\theta)d\theta,"Find the value of $\int_{0}^{\pi}e^{\cos\theta}\cos(\sin\theta)d\theta$. $e^{\cos\theta}\cos(\sin\theta)=Re(e^{e^{i\theta}})$,where $Re()$ represents real part of. So our integral becomes $$ \int_{0}^{\pi}Re(e^{e^{i\theta}})d\theta $$ Now by Cauchy integral formula, $$ \int_{0}^{2\pi}e^zdz=2\pi i $$ But in Cauchy formula, the limits of integration are from $0$ to $2\pi$ and in my question, limits of integration are from $0$ to $\pi$. So I think I cannot apply Cauchy formula as such. What should I do? Please help me, Thanks.","Find the value of $\int_{0}^{\pi}e^{\cos\theta}\cos(\sin\theta)d\theta$. $e^{\cos\theta}\cos(\sin\theta)=Re(e^{e^{i\theta}})$,where $Re()$ represents real part of. So our integral becomes $$ \int_{0}^{\pi}Re(e^{e^{i\theta}})d\theta $$ Now by Cauchy integral formula, $$ \int_{0}^{2\pi}e^zdz=2\pi i $$ But in Cauchy formula, the limits of integration are from $0$ to $2\pi$ and in my question, limits of integration are from $0$ to $\pi$. So I think I cannot apply Cauchy formula as such. What should I do? Please help me, Thanks.",,"['calculus', 'integration']"
41,How to prove this infinite product identity?,How to prove this infinite product identity?,,How can I prove the following identity? $$\large\prod_{k=1}^\infty\frac1{1-2^{1-2k}}=\sum_{m=0}^\infty\left(2^{-\frac{m^2+m}{2}}\prod_{n=1}^\infty\frac{1-2^{-m-n}}{1-2^{-n}}\right)$$ Numerically both sides evaluate to $$2.38423102903137172414989928867839723877...$$,How can I prove the following identity? $$\large\prod_{k=1}^\infty\frac1{1-2^{1-2k}}=\sum_{m=0}^\infty\left(2^{-\frac{m^2+m}{2}}\prod_{n=1}^\infty\frac{1-2^{-m-n}}{1-2^{-n}}\right)$$ Numerically both sides evaluate to $$2.38423102903137172414989928867839723877...$$,,"['calculus', 'sequences-and-series', 'infinite-product', 'arithmetic-progressions', 'geometric-progressions']"
42,Why is it wrong to derive the chain rule this way?,Why is it wrong to derive the chain rule this way?,,"My book says that the chain rule can stated as $$\dfrac{dy}{dx} = \dfrac{dy}{dt} \dfrac{dt}{dx}$$ However, it the book says that it is incorrect to reason that the chain rule is true because the $dt$'s cancel out. Why is it incorrect? I've heard people saying that differentials are not really numbers, but I don't know what to think because my book had just finished a section where it defined $dy$ and $dx$ as $(y-\Delta y)$ and $(x-\Delta x)$ respectively, and the book even used values such as .01 to substitute in place of these differentials.","My book says that the chain rule can stated as $$\dfrac{dy}{dx} = \dfrac{dy}{dt} \dfrac{dt}{dx}$$ However, it the book says that it is incorrect to reason that the chain rule is true because the $dt$'s cancel out. Why is it incorrect? I've heard people saying that differentials are not really numbers, but I don't know what to think because my book had just finished a section where it defined $dy$ and $dx$ as $(y-\Delta y)$ and $(x-\Delta x)$ respectively, and the book even used values such as .01 to substitute in place of these differentials.",,"['calculus', 'ordinary-differential-equations', 'multivariable-calculus', 'derivatives', 'chain-rule']"
43,"In the mean value theorem, we are guaranteed $c$ such that $f'(c) = (f(b)-f(a))/(b-a)$. Does $c$ have a name?","In the mean value theorem, we are guaranteed  such that . Does  have a name?",c f'(c) = (f(b)-f(a))/(b-a) c,"The Mean Value Theorem says approximately that for differentiable $f$, there is a $c \in (a,b)$ such that $$ f'(c) = \frac{f(b)-f(a)}{b - a}. $$ I presume that the number $f'(c)$ is the mean value . My question is very short, and very simple. Is there a name for the $c$ guaranteed by the Mean Value Theorem? If I had to name it now, I would call it the mean value abscissa? Many of these classical theorems were proved before the current language of calculus. This means it is possible, perhaps even likely, that such a $c$ was originally given a name.","The Mean Value Theorem says approximately that for differentiable $f$, there is a $c \in (a,b)$ such that $$ f'(c) = \frac{f(b)-f(a)}{b - a}. $$ I presume that the number $f'(c)$ is the mean value . My question is very short, and very simple. Is there a name for the $c$ guaranteed by the Mean Value Theorem? If I had to name it now, I would call it the mean value abscissa? Many of these classical theorems were proved before the current language of calculus. This means it is possible, perhaps even likely, that such a $c$ was originally given a name.",,"['calculus', 'terminology', 'math-history']"
44,"Polynomial maximization: If $x^4+ax^3+3x^2+bx+1 \ge 0$, find the maximum value of $a^2+b^2$","Polynomial maximization: If , find the maximum value of",x^4+ax^3+3x^2+bx+1 \ge 0 a^2+b^2,"If $x^4+ax^3+3x^2+bx+1 \ge 0$ for all real $x$ where $a,b \in R$. Find the maximum value of $(a^2+b^2)$.                                                                        I tried setting up inequalities in $a$ and $b$ but in the end had a hideous two variable expression whose maxima I had to calculate using Partial Derivatives. There must be a better way of doing it. Thanks!","If $x^4+ax^3+3x^2+bx+1 \ge 0$ for all real $x$ where $a,b \in R$. Find the maximum value of $(a^2+b^2)$.                                                                        I tried setting up inequalities in $a$ and $b$ but in the end had a hideous two variable expression whose maxima I had to calculate using Partial Derivatives. There must be a better way of doing it. Thanks!",,"['calculus', 'algebra-precalculus']"
45,Partial Fraction Decomposition with exponent in numerator,Partial Fraction Decomposition with exponent in numerator,,$$Y(s)=\frac{1-e^\frac{-\pi*s}{2}}{s^2[(s+\frac{1}{2})^2+1]}$$ This is actually a step in an differential equations problem. I need to decompose this so I can solve the ODE. I know how to solve the ODE. My only problem is dealing with this partial fraction - I've never encountered one that has an exponent in the numerator. Any ideas?,$$Y(s)=\frac{1-e^\frac{-\pi*s}{2}}{s^2[(s+\frac{1}{2})^2+1]}$$ This is actually a step in an differential equations problem. I need to decompose this so I can solve the ODE. I know how to solve the ODE. My only problem is dealing with this partial fraction - I've never encountered one that has an exponent in the numerator. Any ideas?,,"['calculus', 'ordinary-differential-equations', 'partial-fractions']"
46,Finding the volume of a cube using spherical coordinates,Finding the volume of a cube using spherical coordinates,,"Calculate the volume of a cube having edge length $a$ by integrating in spherical coordinates. Suppose that the cube have all the edges on the positive semi-axis. Let us divide it by the plane passing through the points $(0;0;0),(0;0;a),(a;a;0)$. We get two equivalent prism; now we divide the section again by the plane passing through the points $(a;0;a),(0;0;0),(a;a;a)$; So one may write:$$\frac{1}{2}V=(\int_{0}^{\pi/4}\,d\phi\int_{0}^{\pi/4}\,d\theta\int_{0}^{\frac{a}{\cos\phi}}r^2\sin\phi\,dr\quad+\quad\int_{\pi/4}^{\pi/2}\,d\phi\int_{0}^{\pi/4}\,d\theta\int_{0}^{\frac{a}{\sin\phi\cos\theta}}r^2\sin\phi\,dr)$$ So one should expect $V=a^3$ but the latter expression gives a different result. What is the correct way to calculate $V$ and why doesn't my reasoning work?","Calculate the volume of a cube having edge length $a$ by integrating in spherical coordinates. Suppose that the cube have all the edges on the positive semi-axis. Let us divide it by the plane passing through the points $(0;0;0),(0;0;a),(a;a;0)$. We get two equivalent prism; now we divide the section again by the plane passing through the points $(a;0;a),(0;0;0),(a;a;a)$; So one may write:$$\frac{1}{2}V=(\int_{0}^{\pi/4}\,d\phi\int_{0}^{\pi/4}\,d\theta\int_{0}^{\frac{a}{\cos\phi}}r^2\sin\phi\,dr\quad+\quad\int_{\pi/4}^{\pi/2}\,d\phi\int_{0}^{\pi/4}\,d\theta\int_{0}^{\frac{a}{\sin\phi\cos\theta}}r^2\sin\phi\,dr)$$ So one should expect $V=a^3$ but the latter expression gives a different result. What is the correct way to calculate $V$ and why doesn't my reasoning work?",,"['calculus', 'integration']"
47,Evaluating $\int_0^{\pi/3}\cosh^2\left(x/\sqrt{2}\right)\tan^3x \:dx$,Evaluating,\int_0^{\pi/3}\cosh^2\left(x/\sqrt{2}\right)\tan^3x \:dx,I've been told that this integral admits a closed form $$ \int_0^{\Large\pi/3}\cosh^2\left(x/\sqrt{2}\right)\tan^3x \:dx$$ But an integration by parts with $u'(x)=\cosh^2\left(x/\sqrt{2}\right)$ and $v(x)=\tan^3x$ produces the factor $\tan^2x\sec^2x$ in my new integral... The other integration by parts doesn't seem that useful... Thanks for your help.,I've been told that this integral admits a closed form $$ \int_0^{\Large\pi/3}\cosh^2\left(x/\sqrt{2}\right)\tan^3x \:dx$$ But an integration by parts with $u'(x)=\cosh^2\left(x/\sqrt{2}\right)$ and $v(x)=\tan^3x$ produces the factor $\tan^2x\sec^2x$ in my new integral... The other integration by parts doesn't seem that useful... Thanks for your help.,,"['calculus', 'integration', 'definite-integrals']"
48,limit of double binomial sum,limit of double binomial sum,,"Prove that $$\lim_{\max(M,N) \to \infty} \frac{\sum_{i=0}^{M-1} \sum_{j=0}^{N-1} p^{i} (1-p)^{j} {i+j \choose i}}{\min (\frac{M}{p}, \frac{N}{1-p})} = 1 $$ where $0<p<1$ and $M, N$ are positive integers. I did it for the case that one of $M, N$ is fixed by using the differentiation of power series representation of $\frac{1}{1-p}$, but I have no idea about the remaining case - both of $M, N$ go to infinity. My work - Proof for the special case where $N$ is finite: The original problem becomes $$\lim_{M \to \infty} \sum_{i=0}^{M-1} \sum_{j=0}^{N-1} p^{i} (1-p)^{j} {i+j \choose i} = \frac{N}{1-p}. $$ To see this, for each $j$, $$(1-p)^{j} \sum_{i=0}^{\infty} p^{i}  {i+j \choose i} = (1-p)^{j} \frac{1}{j!} \frac{d^{j}}{dp^{j}} \big( \frac{1}{1-p} \big) = \frac{(1-p)^{j}}{(1-p)^{j+1}} = \frac{1}{1-p}, $$ whence $$\lim_{M \to \infty} \sum_{i=0}^{M-1} \sum_{j=0}^{N-1} p^{i} (1-p)^{j} {i+j \choose i}  = N \cdot \frac{1}{1-p} = \frac{N}{1-p}. $$","Prove that $$\lim_{\max(M,N) \to \infty} \frac{\sum_{i=0}^{M-1} \sum_{j=0}^{N-1} p^{i} (1-p)^{j} {i+j \choose i}}{\min (\frac{M}{p}, \frac{N}{1-p})} = 1 $$ where $0<p<1$ and $M, N$ are positive integers. I did it for the case that one of $M, N$ is fixed by using the differentiation of power series representation of $\frac{1}{1-p}$, but I have no idea about the remaining case - both of $M, N$ go to infinity. My work - Proof for the special case where $N$ is finite: The original problem becomes $$\lim_{M \to \infty} \sum_{i=0}^{M-1} \sum_{j=0}^{N-1} p^{i} (1-p)^{j} {i+j \choose i} = \frac{N}{1-p}. $$ To see this, for each $j$, $$(1-p)^{j} \sum_{i=0}^{\infty} p^{i}  {i+j \choose i} = (1-p)^{j} \frac{1}{j!} \frac{d^{j}}{dp^{j}} \big( \frac{1}{1-p} \big) = \frac{(1-p)^{j}}{(1-p)^{j+1}} = \frac{1}{1-p}, $$ whence $$\lim_{M \to \infty} \sum_{i=0}^{M-1} \sum_{j=0}^{N-1} p^{i} (1-p)^{j} {i+j \choose i}  = N \cdot \frac{1}{1-p} = \frac{N}{1-p}. $$",,"['calculus', 'combinatorics']"
49,Area of the field that the cow can graze.,Area of the field that the cow can graze.,,How do we find the area that the cow can graze? The question goes as follows-- There is a circular barn house surrounded by a huge grazing field. A cow is tied to the rope ($AB$) at the end $A$ as shown. The length of the rope is half the circumference of the barn. Find the area that the cow can graze.  The left side of the area is obvious but i cannot get a hang of what is happening on the right side..all i can say is that the rope starts to wrap around the barn when the cow goes to the right. The length of the rope is $16\pi$ units.,How do we find the area that the cow can graze? The question goes as follows-- There is a circular barn house surrounded by a huge grazing field. A cow is tied to the rope ($AB$) at the end $A$ as shown. The length of the rope is half the circumference of the barn. Find the area that the cow can graze.  The left side of the area is obvious but i cannot get a hang of what is happening on the right side..all i can say is that the rope starts to wrap around the barn when the cow goes to the right. The length of the rope is $16\pi$ units.,,"['calculus', 'geometry', 'area']"
50,Show that $P$ is divided to simple roots knowing that $a_{k}^2-4a_{k-1}a_{k+1}>0$,Show that  is divided to simple roots knowing that,P a_{k}^2-4a_{k-1}a_{k+1}>0,"Let $P(X)=a_0+a_1X+..+a_nX^n\in R[X]$ Assume that  $\forall k, a_k>0$ and $a_{k}^2-4a_{k-1}a_{k+1}>0$ Show that $P$  is divided to simple roots in $R[X]$. i.e. $P(X)=C(X−\alpha_1)\cdots(x−\alpha_n)$, where $\alpha_i, \quad 1 \le i \leq n$ are distinct. I'm stuck wigh this problem, I cannot get any good idea for this. I tried to use the fact that,  $$ \sigma_{k}=(-1)^{k}\cdot\frac{a_{n-k}}{a_{n}} $$ where $\sigma_{k}$ are The elementary symmetric polynomials But it did not lead nowhere. In fact I do not see how to connect the fact that $a_{k}^2-4a_{k-1}a_{k+1}>0$ and the result I have to prove.","Let $P(X)=a_0+a_1X+..+a_nX^n\in R[X]$ Assume that  $\forall k, a_k>0$ and $a_{k}^2-4a_{k-1}a_{k+1}>0$ Show that $P$  is divided to simple roots in $R[X]$. i.e. $P(X)=C(X−\alpha_1)\cdots(x−\alpha_n)$, where $\alpha_i, \quad 1 \le i \leq n$ are distinct. I'm stuck wigh this problem, I cannot get any good idea for this. I tried to use the fact that,  $$ \sigma_{k}=(-1)^{k}\cdot\frac{a_{n-k}}{a_{n}} $$ where $\sigma_{k}$ are The elementary symmetric polynomials But it did not lead nowhere. In fact I do not see how to connect the fact that $a_{k}^2-4a_{k-1}a_{k+1}>0$ and the result I have to prove.",,['calculus']
51,"Indefinite Integral $\int\frac{1}{1+\tan^{-1}x}\,\text{d}x$",Indefinite Integral,"\int\frac{1}{1+\tan^{-1}x}\,\text{d}x","I tried to solve this indefinite integral, $$\int\frac{1}{1+\tan^{-1}x}\,\text{d}x.$$ I tried taking the change of variable $u=\tan^{-1}x$ but failed to reach a solution. Can anyone help me? Thanks in advance.","I tried to solve this indefinite integral, $$\int\frac{1}{1+\tan^{-1}x}\,\text{d}x.$$ I tried taking the change of variable $u=\tan^{-1}x$ but failed to reach a solution. Can anyone help me? Thanks in advance.",,"['calculus', 'integration', 'indefinite-integrals', 'substitution']"
52,How to integrate $e^{\sin x}(x \cos x - \tan x \sec x)$,How to integrate,e^{\sin x}(x \cos x - \tan x \sec x),"How would on find the indefinite integral $e^{\sin x}(x \cos x - \tan x \sec x)$ Our professor gave it to us as a review question. He told us it was from an exam several years ago as extra credit, however no one answered it correctly. I have been working on it for hours and cannot make a dent, I haven't made any progress! It isn't really important because there are no points awarded for it, however I would like to know how to do it Solution based on input from Doc: $\int e^{\sin x}(x \cos x -\tan x \sec x)\;dx$ $\int (e^{\sin x}\cos x)(x)\;dx - \int e^{\sin x}( \tan x \sec x)\;dx$ $\int (e^{\sin x})'(x)\;dx - \int e^{\sin x}(\sec x)'\;dx$ $ e^{\sin x}x-\int e^{\sin x}\;dx - (e^{\sin x}\sec x-\int \cos x e^{\sin x}\sec x\;dx)$ $ e^{\sin x}x-\int e^{\sin x}\;dx - e^{\sin x}\sec x+\int e^{\sin x}\;dx$ $ e^{\sin x}x - e^{\sin x}\sec x+C$ $ e^{\sin x}(x - \sec x)+C$","How would on find the indefinite integral $e^{\sin x}(x \cos x - \tan x \sec x)$ Our professor gave it to us as a review question. He told us it was from an exam several years ago as extra credit, however no one answered it correctly. I have been working on it for hours and cannot make a dent, I haven't made any progress! It isn't really important because there are no points awarded for it, however I would like to know how to do it Solution based on input from Doc: $\int e^{\sin x}(x \cos x -\tan x \sec x)\;dx$ $\int (e^{\sin x}\cos x)(x)\;dx - \int e^{\sin x}( \tan x \sec x)\;dx$ $\int (e^{\sin x})'(x)\;dx - \int e^{\sin x}(\sec x)'\;dx$ $ e^{\sin x}x-\int e^{\sin x}\;dx - (e^{\sin x}\sec x-\int \cos x e^{\sin x}\sec x\;dx)$ $ e^{\sin x}x-\int e^{\sin x}\;dx - e^{\sin x}\sec x+\int e^{\sin x}\;dx$ $ e^{\sin x}x - e^{\sin x}\sec x+C$ $ e^{\sin x}(x - \sec x)+C$",,"['calculus', 'integration', 'indefinite-integrals']"
53,Any continuous group homomorphism $\mathbb{R}\to \mathbb{R}^n$ is $C^\infty$,Any continuous group homomorphism  is,\mathbb{R}\to \mathbb{R}^n C^\infty,"Show that any continuous homomorphism $\mathbb{R}\to \mathbb{R}^n$, with respect to the usual abelian group structure, is actually $C^\infty$. My attempt: Let $\varphi$ be such a map. $$\lim_{h\to 0}\frac{\varphi(x+h) - \varphi(x)} {h} = \lim_{h \to 0} \frac{\varphi (h)}{h},$$ so if $\varphi'$ exists, it is constant on $\mathbb{R}$, and it is sufficient for it to exist at zero. Now note that $h\mapsto \frac{\varphi(h)}{h}$ is continuous for $h \neq 0$ since it is the product of a continuous scalar-valued function and a continuous vector-valued function. Now $$ \frac {\varphi \left(\frac{h}{m/n} \right ) } {\frac{h}{m/n}} = \frac{(n/m)\varphi(h)}{\frac{h}{m/n}} = \frac{\varphi(h)}{h}, \;\;\; m,n \in \mathbb{Z}$$ so $h\mapsto \frac{\varphi(h)}{h}$ is constant on $\mathbb{Q}$. Since it is continuous, it is constant on $\mathbb{R}$, and it has a limit at zero. I would appreciate it if you could let me know if there are parts of the argument I could explain better, or point out any errors.","Show that any continuous homomorphism $\mathbb{R}\to \mathbb{R}^n$, with respect to the usual abelian group structure, is actually $C^\infty$. My attempt: Let $\varphi$ be such a map. $$\lim_{h\to 0}\frac{\varphi(x+h) - \varphi(x)} {h} = \lim_{h \to 0} \frac{\varphi (h)}{h},$$ so if $\varphi'$ exists, it is constant on $\mathbb{R}$, and it is sufficient for it to exist at zero. Now note that $h\mapsto \frac{\varphi(h)}{h}$ is continuous for $h \neq 0$ since it is the product of a continuous scalar-valued function and a continuous vector-valued function. Now $$ \frac {\varphi \left(\frac{h}{m/n} \right ) } {\frac{h}{m/n}} = \frac{(n/m)\varphi(h)}{\frac{h}{m/n}} = \frac{\varphi(h)}{h}, \;\;\; m,n \in \mathbb{Z}$$ so $h\mapsto \frac{\varphi(h)}{h}$ is constant on $\mathbb{Q}$. Since it is continuous, it is constant on $\mathbb{R}$, and it has a limit at zero. I would appreciate it if you could let me know if there are parts of the argument I could explain better, or point out any errors.",,"['calculus', 'group-theory', 'proof-verification']"
54,Changing $|1-x|$ to $|x-1|$,Changing  to,|1-x| |x-1|,I'm trying to get the limit $$\displaystyle\lim_{x \rightarrow 1} \frac{(x-1)(x-1)}{|1-x|}.$$ I think what I need to do is change $|1-x|$ to $|x-1|$ so I can cancel out one of the terms... but how do I get there? Thanks so much.,I'm trying to get the limit $$\displaystyle\lim_{x \rightarrow 1} \frac{(x-1)(x-1)}{|1-x|}.$$ I think what I need to do is change $|1-x|$ to $|x-1|$ so I can cancel out one of the terms... but how do I get there? Thanks so much.,,"['calculus', 'algebra-precalculus']"
55,Hilarious Comic ... DiffyQ and infinity ensue...,Hilarious Comic ... DiffyQ and infinity ensue...,,"I ran across this comic, and it's gold.  It is orginially published here If I am correct, the first panel alone defines a self-referential loop if not a differential Equation: $X$: Amount of Black to fill text $Y$: Amount of ink to fill borderline $Z$: Amount of black ink in graph The amount of the image which would be black at first appears to be then $X+Y+Z$, but $Z$ also seems something as if bounded by $Z=X+Y+C+(\mathrm{something})Z$, where $A+B$ is that amount of black ink conveniently rendered outside of the graph, $C$ is an arbitrary amount of black ink added to the shaded part of the graph, and $Z$ is, of course, the amount of black required to draw this! See, when you are shading the amount of black ink in the graph in the first panel: you can add as much as you want, but it must be related to how much is in the comic alltogether! Though there are infinite amount of ways the graph could be shaded correctly, there is an infinite amount of ways the graph could be shaded incorrectly (here come the irrational numbers.) I'd like to try to prove this , but I have actual homework :P. The only way to resolve this is to explain how Z varies with itself! This creates a self-referential loop.  It thus smells like a differential equation but I can't find it! How do we resolve this? (Is it the same thing as the population equation:$$ \frac {dP}{dt} = kP \rightarrow P(t)=Ce^{kt}$$ where P (the dependent variable) is the amount of ink in the panel and $t$, the dependent variable, is the amount of ink in the Graph?  (Yes, I shamelessly ripped the population equation from my textbook and tried to applied it here. This is a question, not a statement.)  Is it true, then, that amount of black ink in the graph and/or panel overall is bound by this equation: $A+B+C+P(t)$? Also, if $X$,$Y$,and $C$ are allowed to vary does this not engender a 4-dimensional graph? (I told you this comic is gold.) That is just the first panel taken alone!  Now Let's take the THIRD panel into consideration! This panel looks a like Xeno's paradox in 2d, or a similar pattern to the horn of Gabriel! As a Tangent, let us describe Xeno's paradox as such (in one dimension): an arrow is fired, once it reaches the halfway point has halfway to go.  Once it reaches halfway of that halfway is has halfway to go again.  Thus, there are an infinite number of half-ways!  Just to be concise, let me express my opinion of something that at least kinda sorta reaches for its resolution: $$\int_1^\infty \frac{1}{x^2}\,dx = 1. $$ (Note this could also be discussed in terms of a similar series solution, such as $\sum_{i=1}^{n} \frac{1}{2^n} = \frac{\pi^2}{6}$, but actually trying to and resolving xeno's paradox is going way beyond the scope of this question.) But, the point of this is that an infinite pattern can lead to a finite result (such as the area under curve $1\over{X^2}$).  Now, look at the leftmost panel closely: If the third panel plots the location of Black ink in the image, as it says, it must plot itself in miniature.  This miniature, in turn, must include a plot of the comic; in this EXTRA-miniature plot, there must also be a plot of the comic, an infinite number of times. In other words, the third panel must plot itself and infinite number of times. Can it be shown that like the the amount of ink needed for these plots will so fast that a  thus that a finite amount of ink is needed to draw an infinite number of these ""reflected"" third panels? Let us try to compute the amount of ink recquired to draw this infinite number of self-mirrors. Amount of Ink $\bf \propto$ Surface  area of square We can assume this because the area covered by ink will be a fixed proportion of the squares area if the thickness of the the ink varies with the size of the square, which it obviously must or the image cannot be drawn! Let us say the sides of the small square are proportional (they must be if the plot is accurate) and that they are 1/5 the size of the first square.  Therefore both the surface area and the amount of ink used will be $\frac{1}{(5^n)^2}$ including the first square if n=0.  Now, let $A$ be the area of the first square.  We already know that $$\sum_{i=1}^{n} \frac{1}{(5^n)^2} < (\sum_{i=1}^{n} \frac{1}{2^n} = \frac{\pi^2}{6})$$ therefore $A*(1 + \lim_{n \to +\infty}\sum_{i=1}^{n} \frac{1}{(5^n)^2})$ must be a finite number. Thus an infinite number of panels can mathematically be drawn with a finite amount of ink! In other words, the added surface areas of a square, within a square, within a square, so on to infinity, is a finite combined area (remember the proof that the infinite series $\frac{1}{n^p}$ converges if $ p > 1$ - but I'll leave that to the reader.) Does this first differential equation still apply?  How would we unite these equations !? I will not comment on the second panel, but I think it may be similar to the first..... Thank you for reading all this!","I ran across this comic, and it's gold.  It is orginially published here If I am correct, the first panel alone defines a self-referential loop if not a differential Equation: $X$: Amount of Black to fill text $Y$: Amount of ink to fill borderline $Z$: Amount of black ink in graph The amount of the image which would be black at first appears to be then $X+Y+Z$, but $Z$ also seems something as if bounded by $Z=X+Y+C+(\mathrm{something})Z$, where $A+B$ is that amount of black ink conveniently rendered outside of the graph, $C$ is an arbitrary amount of black ink added to the shaded part of the graph, and $Z$ is, of course, the amount of black required to draw this! See, when you are shading the amount of black ink in the graph in the first panel: you can add as much as you want, but it must be related to how much is in the comic alltogether! Though there are infinite amount of ways the graph could be shaded correctly, there is an infinite amount of ways the graph could be shaded incorrectly (here come the irrational numbers.) I'd like to try to prove this , but I have actual homework :P. The only way to resolve this is to explain how Z varies with itself! This creates a self-referential loop.  It thus smells like a differential equation but I can't find it! How do we resolve this? (Is it the same thing as the population equation:$$ \frac {dP}{dt} = kP \rightarrow P(t)=Ce^{kt}$$ where P (the dependent variable) is the amount of ink in the panel and $t$, the dependent variable, is the amount of ink in the Graph?  (Yes, I shamelessly ripped the population equation from my textbook and tried to applied it here. This is a question, not a statement.)  Is it true, then, that amount of black ink in the graph and/or panel overall is bound by this equation: $A+B+C+P(t)$? Also, if $X$,$Y$,and $C$ are allowed to vary does this not engender a 4-dimensional graph? (I told you this comic is gold.) That is just the first panel taken alone!  Now Let's take the THIRD panel into consideration! This panel looks a like Xeno's paradox in 2d, or a similar pattern to the horn of Gabriel! As a Tangent, let us describe Xeno's paradox as such (in one dimension): an arrow is fired, once it reaches the halfway point has halfway to go.  Once it reaches halfway of that halfway is has halfway to go again.  Thus, there are an infinite number of half-ways!  Just to be concise, let me express my opinion of something that at least kinda sorta reaches for its resolution: $$\int_1^\infty \frac{1}{x^2}\,dx = 1. $$ (Note this could also be discussed in terms of a similar series solution, such as $\sum_{i=1}^{n} \frac{1}{2^n} = \frac{\pi^2}{6}$, but actually trying to and resolving xeno's paradox is going way beyond the scope of this question.) But, the point of this is that an infinite pattern can lead to a finite result (such as the area under curve $1\over{X^2}$).  Now, look at the leftmost panel closely: If the third panel plots the location of Black ink in the image, as it says, it must plot itself in miniature.  This miniature, in turn, must include a plot of the comic; in this EXTRA-miniature plot, there must also be a plot of the comic, an infinite number of times. In other words, the third panel must plot itself and infinite number of times. Can it be shown that like the the amount of ink needed for these plots will so fast that a  thus that a finite amount of ink is needed to draw an infinite number of these ""reflected"" third panels? Let us try to compute the amount of ink recquired to draw this infinite number of self-mirrors. Amount of Ink $\bf \propto$ Surface  area of square We can assume this because the area covered by ink will be a fixed proportion of the squares area if the thickness of the the ink varies with the size of the square, which it obviously must or the image cannot be drawn! Let us say the sides of the small square are proportional (they must be if the plot is accurate) and that they are 1/5 the size of the first square.  Therefore both the surface area and the amount of ink used will be $\frac{1}{(5^n)^2}$ including the first square if n=0.  Now, let $A$ be the area of the first square.  We already know that $$\sum_{i=1}^{n} \frac{1}{(5^n)^2} < (\sum_{i=1}^{n} \frac{1}{2^n} = \frac{\pi^2}{6})$$ therefore $A*(1 + \lim_{n \to +\infty}\sum_{i=1}^{n} \frac{1}{(5^n)^2})$ must be a finite number. Thus an infinite number of panels can mathematically be drawn with a finite amount of ink! In other words, the added surface areas of a square, within a square, within a square, so on to infinity, is a finite combined area (remember the proof that the infinite series $\frac{1}{n^p}$ converges if $ p > 1$ - but I'll leave that to the reader.) Does this first differential equation still apply?  How would we unite these equations !? I will not comment on the second panel, but I think it may be similar to the first..... Thank you for reading all this!",,"['calculus', 'sequences-and-series', 'recreational-mathematics', 'infinity']"
56,Fundamental Theorem of Calculus in Multivariate Case,Fundamental Theorem of Calculus in Multivariate Case,,"From the FTC we have, for continuously differentiable $f: \mathbb{R} \to \mathbb{R}$,  $$ f(a) - f(b) = \int_b^a \frac{d}{dx} f(x) dx $$ I'm trying to write the difference between a vector function in similar terms, that is, given $g : \mathbb{R}^d \to \mathbb{R}^d$, having known Jacobian $J_f(x)$, what can we say about $$ g(x_1) - g(x_2) = ?  $$","From the FTC we have, for continuously differentiable $f: \mathbb{R} \to \mathbb{R}$,  $$ f(a) - f(b) = \int_b^a \frac{d}{dx} f(x) dx $$ I'm trying to write the difference between a vector function in similar terms, that is, given $g : \mathbb{R}^d \to \mathbb{R}^d$, having known Jacobian $J_f(x)$, what can we say about $$ g(x_1) - g(x_2) = ?  $$",,"['calculus', 'integration', 'multivariable-calculus']"
57,Integral $\int \frac{\tan x}{x} dx$,Integral,\int \frac{\tan x}{x} dx,"Evaluate the integral:   $$\int \frac{\tan x}{x} dx$$ I tried integration by parts, got stuck. Ideas/ suggestions please.","Evaluate the integral:   $$\int \frac{\tan x}{x} dx$$ I tried integration by parts, got stuck. Ideas/ suggestions please.",,"['calculus', 'integration', 'trigonometry', 'indefinite-integrals']"
58,Proving that $\lim_{x\to\infty}f(x)=\lim_{x\to 0}f(\frac{1}{x})$ for any function $f$,Proving that  for any function,\lim_{x\to\infty}f(x)=\lim_{x\to 0}f(\frac{1}{x}) f,"Prove that for any $f(x)$,   $$\lim_{x\to\infty}f(x)=\lim_{x\to 0}f\left(\frac{1}{x}\right).$$ I don't know for sure if this is true, I just thought about it. It seems very intuitive for a simple $f(x)$, but for more complex ones (such as the definition of $e$, where this does work) I wouldn't be sure if it always worked. Thanks!","Prove that for any $f(x)$,   $$\lim_{x\to\infty}f(x)=\lim_{x\to 0}f\left(\frac{1}{x}\right).$$ I don't know for sure if this is true, I just thought about it. It seems very intuitive for a simple $f(x)$, but for more complex ones (such as the definition of $e$, where this does work) I wouldn't be sure if it always worked. Thanks!",,['calculus']
59,"bound for $a,b,c$ in $|ax^2+bx+c| \leq 1\;\forall x\in \left[0,1\right]$",bound for  in,"a,b,c |ax^2+bx+c| \leq 1\;\forall x\in \left[0,1\right]","Consider $a,b,c\in\mathbb{R}$ such that $|ax^2+bx+c|\leq 1\;\forall x\in \left[0,1\right]$ . Prove that $|a|\leq 8\;\;,|b| \leq 8$ and $|c| \leq 1$ . My Attempt: Set $x = 0$ in $|ax^2+bx+c|\leq 1$ to get $|c|  \leq 1$ . Similarly set $x = 1$ in $|ax^2+bx+c| \leq 1$ to get $|a+b+c|\leq 1$ . From here, how can I calculate bounds for $a$ and $b$ ?","Consider such that . Prove that and . My Attempt: Set in to get . Similarly set in to get . From here, how can I calculate bounds for and ?","a,b,c\in\mathbb{R} |ax^2+bx+c|\leq 1\;\forall x\in \left[0,1\right] |a|\leq 8\;\;,|b| \leq 8 |c| \leq 1 x = 0 |ax^2+bx+c|\leq 1 |c|  \leq 1 x = 1 |ax^2+bx+c| \leq 1 |a+b+c|\leq 1 a b","['calculus', 'inequality', 'systems-of-equations', 'absolute-value', 'substitution']"
60,Relative maximum and minimum of function of three variables,Relative maximum and minimum of function of three variables,,"I know that how to find relative maximum and minimum of function of two variables. How can I determine function when $f(x,y,z)=x^2+y^2-z^2 $ has relative maximum or relative minimum? Please give me hint. In general when does $f(x,y,z)$ have relative minimum or relative maximum? Thanks in advance.","I know that how to find relative maximum and minimum of function of two variables. How can I determine function when $f(x,y,z)=x^2+y^2-z^2 $ has relative maximum or relative minimum? Please give me hint. In general when does $f(x,y,z)$ have relative minimum or relative maximum? Thanks in advance.",,"['calculus', 'multivariable-calculus']"
61,$f'+\lambda f$ acts as $f'$ without integral,acts as  without integral,f'+\lambda f f',"Problem Suppose that $f(x)$ is a differentiable function and $f'(x)$ is the derivative of $f(x)$ . Without aids of integral, can we prove that $f'(x)+\lambda f(x)$ has intermediate property? Intermediate property A (real) function $f(x)$ having intermediate property means that if $a,b\in f(\Bbb R)$ and $a<c<b$ , then $c\in f(\Bbb R)$ , where $f(\Bbb R)=\{\;f(x):x\in\Bbb R\;\}$ With aids of integral Let $g(x)=f'(x)+\lambda f(x)$ . For $f(x)$ is continuous, we have $f(x)$ is Riemann-integrable. Let $G(x)=f(x)+\int_0^xf(t)dt$ , we have $G'(x)=g(x)$ ; therefore, we can apply Darboux's theorem to $G(x)$ , and we've done.","Problem Suppose that is a differentiable function and is the derivative of . Without aids of integral, can we prove that has intermediate property? Intermediate property A (real) function having intermediate property means that if and , then , where With aids of integral Let . For is continuous, we have is Riemann-integrable. Let , we have ; therefore, we can apply Darboux's theorem to , and we've done.","f(x) f'(x) f(x) f'(x)+\lambda f(x) f(x) a,b\in f(\Bbb R) a<c<b c\in f(\Bbb R) f(\Bbb R)=\{\;f(x):x\in\Bbb R\;\} g(x)=f'(x)+\lambda f(x) f(x) f(x) G(x)=f(x)+\int_0^xf(t)dt G'(x)=g(x) G(x)",['calculus']
62,Is this limit evaluation correct?,Is this limit evaluation correct?,,"In trying to give the OP an elementary answer to this question, I made some rather stupid mistakes. I feel terrible about giving a wrong answer (in lieu of a complicated but correct one). I devised a new proof, and wanted to check it before editing my answer. Does everyone like the following (well enough)? Assertion : $$\lim_{x \to 0^+} \frac{x^{x^x}}{x} = 1$$ Proof : We pass to the log of the limit. $$\log\left(\lim_{x \to 0^+} \frac{x^{x^x}}{x}\right) = \lim_{x \to 0^+} \log\left(\frac{x^{x^x}}{x}\right) = \lim_{x \to 0^+} \frac{\log(x)}{\frac{1}{x^x - 1}}$$ We use L'Hospital's rule, and rearrange: $$\lim_{x \to 0^+} \frac{\log(x)}{\frac{1}{x^x - 1}} = \lim_{x \to 0^+} \frac{\frac{1}{x}}{\frac{-x^x(\log(x) + 1)}{(x^x - 1)^2}} = \lim_{x \to 0^+} \frac{- (x^x - 1)^2}{x^{x}(x\log(x) + x)} = \left( \lim_{x \to 0^+} \frac{-(x^x - 1)}{x^x} \right) \left( \lim_{x \to 0^+} \frac{(x^x - 1)}{x\log(x) + x} \right) $$ provided that both of these last limits exist; but (again using L'Hospital in the 2nd limit) we see that $$\lim_{x \to 0^+} \frac{-(x^x - 1)}{x^x} = \frac{0}{1} = 0,$$ $$\lim_{x \to 0^+} \frac{(x^x - 1)}{x\log(x) + x} = \lim_{x \to 0^+} \frac{x^x(\log(x)+1)}{(1+ \log(x)) + (1)} = \left( \lim_{x \to 0^+} \frac{x^x(\log(x)+2)}{( \log(x)) + 2)} - \lim_{x \to 0^+} \frac{x^x}{(\log(x)) + 2)} \right) = 1,$$ and therefore $\displaystyle\log\left(\lim_{x \to 0^+} \frac{x^{x^x}}{x}\right) = 0$. Evaluating both sides by $\exp(x)$ therefore shows that $\displaystyle\lim_{x \to 0^+} \frac{x^{x^x}}{x} = 1$.","In trying to give the OP an elementary answer to this question, I made some rather stupid mistakes. I feel terrible about giving a wrong answer (in lieu of a complicated but correct one). I devised a new proof, and wanted to check it before editing my answer. Does everyone like the following (well enough)? Assertion : $$\lim_{x \to 0^+} \frac{x^{x^x}}{x} = 1$$ Proof : We pass to the log of the limit. $$\log\left(\lim_{x \to 0^+} \frac{x^{x^x}}{x}\right) = \lim_{x \to 0^+} \log\left(\frac{x^{x^x}}{x}\right) = \lim_{x \to 0^+} \frac{\log(x)}{\frac{1}{x^x - 1}}$$ We use L'Hospital's rule, and rearrange: $$\lim_{x \to 0^+} \frac{\log(x)}{\frac{1}{x^x - 1}} = \lim_{x \to 0^+} \frac{\frac{1}{x}}{\frac{-x^x(\log(x) + 1)}{(x^x - 1)^2}} = \lim_{x \to 0^+} \frac{- (x^x - 1)^2}{x^{x}(x\log(x) + x)} = \left( \lim_{x \to 0^+} \frac{-(x^x - 1)}{x^x} \right) \left( \lim_{x \to 0^+} \frac{(x^x - 1)}{x\log(x) + x} \right) $$ provided that both of these last limits exist; but (again using L'Hospital in the 2nd limit) we see that $$\lim_{x \to 0^+} \frac{-(x^x - 1)}{x^x} = \frac{0}{1} = 0,$$ $$\lim_{x \to 0^+} \frac{(x^x - 1)}{x\log(x) + x} = \lim_{x \to 0^+} \frac{x^x(\log(x)+1)}{(1+ \log(x)) + (1)} = \left( \lim_{x \to 0^+} \frac{x^x(\log(x)+2)}{( \log(x)) + 2)} - \lim_{x \to 0^+} \frac{x^x}{(\log(x)) + 2)} \right) = 1,$$ and therefore $\displaystyle\log\left(\lim_{x \to 0^+} \frac{x^{x^x}}{x}\right) = 0$. Evaluating both sides by $\exp(x)$ therefore shows that $\displaystyle\lim_{x \to 0^+} \frac{x^{x^x}}{x} = 1$.",,['calculus']
63,"Evaluating $ \int_{-\infty}^{\infty}x\exp\left(-b^{2}\left(x-c\right)^{2}\right)\mathrm{erf}^{2}\left(a\left(x-d\right)\right)\,\mathrm{d}x $",Evaluating," \int_{-\infty}^{\infty}x\exp\left(-b^{2}\left(x-c\right)^{2}\right)\mathrm{erf}^{2}\left(a\left(x-d\right)\right)\,\mathrm{d}x ","I have big difficulties solving the following integral: $$ \int_{-\infty}^{\infty}x\exp\left(-b^{2}\left(x-c\right)^{2}\right)\mathrm{erf}^{2}\left(a\left(x-d\right)\right)\,\mathrm{d}x $$ I tried to use integration by parts, and also tried to apply the technique called “differentiation under the integration sign” but with no results. I’m not very good at calculus so my question is if anyone could give me any hint of how to approach this integral. I would be ultimately thankful. If it could help at all, I know that $$  \int_{-\infty}^{\infty}x\exp\left(-b^{2}\left(x-c\right)^{2}\right)\mathrm{erf}\left(a\left(x-d\right)\right)\,\mathrm{d}x=\frac{a}{b^{2}\sqrt{a^{2}+b^{2}}}\exp\left(-\frac{a^{2}b^{2}\left(c-d\right)^{2}}{a^{2}+b^{2}}\right)+\frac{\sqrt{\pi}c}{b}\mathrm{erf}\left(\frac{ab\left(c-d\right)}{\sqrt{a^{2}+b^{2}}}\right), $$ for $b>0$.","I have big difficulties solving the following integral: $$ \int_{-\infty}^{\infty}x\exp\left(-b^{2}\left(x-c\right)^{2}\right)\mathrm{erf}^{2}\left(a\left(x-d\right)\right)\,\mathrm{d}x $$ I tried to use integration by parts, and also tried to apply the technique called “differentiation under the integration sign” but with no results. I’m not very good at calculus so my question is if anyone could give me any hint of how to approach this integral. I would be ultimately thankful. If it could help at all, I know that $$  \int_{-\infty}^{\infty}x\exp\left(-b^{2}\left(x-c\right)^{2}\right)\mathrm{erf}\left(a\left(x-d\right)\right)\,\mathrm{d}x=\frac{a}{b^{2}\sqrt{a^{2}+b^{2}}}\exp\left(-\frac{a^{2}b^{2}\left(c-d\right)^{2}}{a^{2}+b^{2}}\right)+\frac{\sqrt{\pi}c}{b}\mathrm{erf}\left(\frac{ab\left(c-d\right)}{\sqrt{a^{2}+b^{2}}}\right), $$ for $b>0$.",,"['calculus', 'definite-integrals', 'special-functions', 'error-function']"
64,Permutations don't affect summation in complex series implies absolute convergence?,Permutations don't affect summation in complex series implies absolute convergence?,,"Let $\sum a_{n}$ be a complex series that converges. Now let $\sum a'_{n}$ be a rearrangement of that series. If we have $$ \sum a_{n}=\sum a'_{n} $$ for all rearrangements, is it true that $\sum a_{n}$ converges absolutely? On a similar note, for all of you who own Rudin's Principles of Mathematical Analysis, can you check if there is a Theorem 3.56 in your book? Rudin cites it in Real and Complex Analysis, and I can't tell if it's a typo or was the theorem added in later printings.","Let $\sum a_{n}$ be a complex series that converges. Now let $\sum a'_{n}$ be a rearrangement of that series. If we have $$ \sum a_{n}=\sum a'_{n} $$ for all rearrangements, is it true that $\sum a_{n}$ converges absolutely? On a similar note, for all of you who own Rudin's Principles of Mathematical Analysis, can you check if there is a Theorem 3.56 in your book? Rudin cites it in Real and Complex Analysis, and I can't tell if it's a typo or was the theorem added in later printings.",,"['calculus', 'analysis', 'complex-analysis']"
65,"terminology: what is meant if someone writes ""calculus of ..""?","terminology: what is meant if someone writes ""calculus of ..""?",,"This question might be a little soft as it does not have a definite answer, so I hope I do not break the conventions of this forum by posting it here. I have now come across the term ""calculus of operators"" several times in various books, as well as the ""calculus of several variables"", ""calculus of variations"", calculus of residues"", ""calculus of pseudodifferential operators"", and so on. Each time I don't really understand what is meant by this - my guess is it involves an algebraic system that contains operations broadly to be understood as differentiation and integration - but I am not sure at all, in fact I don't think it fits the bill. I would be really grateful if I could get some better explanation than mine for the term ""calculus of [something]"". Many thanks !","This question might be a little soft as it does not have a definite answer, so I hope I do not break the conventions of this forum by posting it here. I have now come across the term ""calculus of operators"" several times in various books, as well as the ""calculus of several variables"", ""calculus of variations"", calculus of residues"", ""calculus of pseudodifferential operators"", and so on. Each time I don't really understand what is meant by this - my guess is it involves an algebraic system that contains operations broadly to be understood as differentiation and integration - but I am not sure at all, in fact I don't think it fits the bill. I would be really grateful if I could get some better explanation than mine for the term ""calculus of [something]"". Many thanks !",,"['calculus', 'soft-question', 'terminology']"
66,Evaluation of $\int_0^1\frac{\ln ^2\left( 1-x \right) \text{Li}_2\left( \dfrac{1+x}{2} \right)}{x}\text{d}x$,Evaluation of,\int_0^1\frac{\ln ^2\left( 1-x \right) \text{Li}_2\left( \dfrac{1+x}{2} \right)}{x}\text{d}x,"​show that \begin{align*} \int_0^1\frac{\ln ^2\left( 1-x \right) \text{Li}_2\left( \dfrac{1+x}{2} \right)}{x}\text{d}x&=\text{2Li}_5\left( \frac{1}{2} \right) +\text{2}\ln\text{2Li}_4\left( \frac{1}{2} \right) +\frac{81}{32}\zeta \left( 5 \right)\\ & -\frac{\ln ^22}{8}\zeta \left( 3 \right)+\frac{5\pi ^2}{16}\zeta \left( 3 \right) -\frac{\pi ^2\ln ^32}{18}-\frac{\pi ^4\ln 2}{15}\\ &+\frac{\ln ^52}{15} \end{align*} $$I = \int_0^1 \frac{\ln^2(1-x) \text{Li}_2\left(\frac{1+x}{2}\right)}{x} \, dx = -\int_0^1 \frac{\ln^2(1-x)}{x} \int_0^{\frac{1+x}{2}} \frac{\ln(1-y)}{y} \, dy \, dx$$ Swapping the order of integration, we get: \begin{align*} I = &-\int_0^{\frac{1}{2}} \frac{\ln(1-y)}{y} \int_0^1 \frac{\ln^2(1-x)}{x} \, dx \, dy \\ &- \int_{\frac{1}{2}}^1 \frac{\ln(1-y)}{y} \int_{2y-1}^1 \frac{\ln^2(1-x)}{x} \, dx \, dy \\ = &-\int_0^{\frac{1}{2}} \frac{\ln(1-y)}{y} \int_0^1 \frac{\ln^2(1-x)}{x} \, dx \, dy \\ &- 2\int_{\frac{1}{2}}^1 \frac{\ln(1-y) \text{Li}_3(2-2y)}{y} \, dy \\ &+ 2\int_{\frac{1}{2}}^1 \frac{\ln(1-y) \text{Li}_2(2-2y) \ln(2-2y)}{y} \, dy \\ &+ \int_{\frac{1}{2}}^1 \frac{\ln(1-y) \ln(2y-1) \ln^2(2-2y)}{y} \, dy \end{align*}","​show that Swapping the order of integration, we get:","\begin{align*} \int_0^1\frac{\ln ^2\left( 1-x \right) \text{Li}_2\left( \dfrac{1+x}{2} \right)}{x}\text{d}x&=\text{2Li}_5\left( \frac{1}{2} \right) +\text{2}\ln\text{2Li}_4\left( \frac{1}{2} \right) +\frac{81}{32}\zeta \left( 5 \right)\\ & -\frac{\ln ^22}{8}\zeta \left( 3 \right)+\frac{5\pi ^2}{16}\zeta \left( 3 \right) -\frac{\pi ^2\ln ^32}{18}-\frac{\pi ^4\ln 2}{15}\\ &+\frac{\ln ^52}{15} \end{align*} I = \int_0^1 \frac{\ln^2(1-x) \text{Li}_2\left(\frac{1+x}{2}\right)}{x} \, dx = -\int_0^1 \frac{\ln^2(1-x)}{x} \int_0^{\frac{1+x}{2}} \frac{\ln(1-y)}{y} \, dy \, dx \begin{align*}
I = &-\int_0^{\frac{1}{2}} \frac{\ln(1-y)}{y} \int_0^1 \frac{\ln^2(1-x)}{x} \, dx \, dy \\
&- \int_{\frac{1}{2}}^1 \frac{\ln(1-y)}{y} \int_{2y-1}^1 \frac{\ln^2(1-x)}{x} \, dx \, dy \\
= &-\int_0^{\frac{1}{2}} \frac{\ln(1-y)}{y} \int_0^1 \frac{\ln^2(1-x)}{x} \, dx \, dy \\
&- 2\int_{\frac{1}{2}}^1 \frac{\ln(1-y) \text{Li}_3(2-2y)}{y} \, dy \\
&+ 2\int_{\frac{1}{2}}^1 \frac{\ln(1-y) \text{Li}_2(2-2y) \ln(2-2y)}{y} \, dy \\
&+ \int_{\frac{1}{2}}^1 \frac{\ln(1-y) \ln(2y-1) \ln^2(2-2y)}{y} \, dy
\end{align*}","['calculus', 'integration']"
67,"Consider $A(3, 1)$ and $C(4, 3)$. There is a point $B(x, y)$ on the curve $y = x^2$. Minimise $|AB|^2 + |BC|^2$.",Consider  and . There is a point  on the curve . Minimise .,"A(3, 1) C(4, 3) B(x, y) y = x^2 |AB|^2 + |BC|^2","I took B as $B(x, x^2)$ . So far, I tried using the distance formula to get an expression for $|AB|^2 + |BC|^2$ . I got $(3 - x)^2 + (1 - x^2)^2 + (x - 4)^2 + (x^2 - 3)^2$ . Expanding this out gives $2x^4 - 6x^2 - 14x + 35$ . I defined a function $f(x) = 2x^4 - 6x^2 - 14x + 35$ . Then, $f'(x) = 8x^3 - 12x - 14$ . To get the minimum point of $f(x)$ , I tried finding the root of $8x^3 - 12x - 14 = 0$ . $4x^3 - 6x - 7 = 0$ , which gives $x = 1.609$ to 4.s.f. $2(1.609)^4 - 6(1.609)^2 - 14(1.609) + 35 = 10.345324$ I was wondering if there is a way to get an exact answer to this question instead of a decimal.","I took B as . So far, I tried using the distance formula to get an expression for . I got . Expanding this out gives . I defined a function . Then, . To get the minimum point of , I tried finding the root of . , which gives to 4.s.f. I was wondering if there is a way to get an exact answer to this question instead of a decimal.","B(x, x^2) |AB|^2 + |BC|^2 (3 - x)^2 + (1 - x^2)^2 + (x - 4)^2 + (x^2 - 3)^2 2x^4 - 6x^2 - 14x + 35 f(x) = 2x^4 - 6x^2 - 14x + 35 f'(x) = 8x^3 - 12x - 14 f(x) 8x^3 - 12x - 14 = 0 4x^3 - 6x - 7 = 0 x = 1.609 2(1.609)^4 - 6(1.609)^2 - 14(1.609) + 35 = 10.345324","['calculus', 'functions', 'derivatives', 'maxima-minima', 'coordinate-systems']"
68,A chain of circles of radius $1/n^p$ is tangent to the $x$-axis. What is the horizontal length of the chain?,A chain of circles of radius  is tangent to the -axis. What is the horizontal length of the chain?,1/n^p x,"I recently discovered that, if a chain of circles of radius $1/n^2$ , where $n\in\mathbb{N}$ , is tangent to the $x$ -axis, then the the horizontal length of the chain is exactly $2$ . This can be shown by the fact that a circle of radius $1$ is tangent to the other side of the chain (which can be proven by using Descartes' Circle Theorem to show that if three circles of radius $1/n^2, 1$ and $\infty$ are mutually tangent, then a circle of radius $1/(n+1)^2$ is tangent to all three circles). My question seeks to generalize this: If a chain of circles of radius $1/n^p$ , where $n\in\mathbb{N}$ and $p>2$ is an integer constant, is tangent to the $x$ -axis, what is the horizontal length of the chain? My attempt Descartes' Circle Theorem seems to only apply when $p=2$ . For other values of $p$ , I don't know what curve is tangent to the other side of the chain. Using the centres of two neighboring circles and Pythagorus' Theorem, the horizontal length of the chain is $$\sum\limits_{k=1}^\infty 2(k^2+k)^{-p/2}$$ but I don't know how to evaluate this series. To help you visualize, here is a chain of circles of radius $1/n^{3}$ .","I recently discovered that, if a chain of circles of radius , where , is tangent to the -axis, then the the horizontal length of the chain is exactly . This can be shown by the fact that a circle of radius is tangent to the other side of the chain (which can be proven by using Descartes' Circle Theorem to show that if three circles of radius and are mutually tangent, then a circle of radius is tangent to all three circles). My question seeks to generalize this: If a chain of circles of radius , where and is an integer constant, is tangent to the -axis, what is the horizontal length of the chain? My attempt Descartes' Circle Theorem seems to only apply when . For other values of , I don't know what curve is tangent to the other side of the chain. Using the centres of two neighboring circles and Pythagorus' Theorem, the horizontal length of the chain is but I don't know how to evaluate this series. To help you visualize, here is a chain of circles of radius .","1/n^2 n\in\mathbb{N} x 2 1 1/n^2, 1 \infty 1/(n+1)^2 1/n^p n\in\mathbb{N} p>2 x p=2 p \sum\limits_{k=1}^\infty 2(k^2+k)^{-p/2} 1/n^{3}","['calculus', 'geometry', 'circles', 'tangent-line']"
69,$\lim_{n\to\infty}\int_0^\infty \frac{f(x)}{x^2}\sin nx dx=\frac{\pi}{2}f'(0)$,,\lim_{n\to\infty}\int_0^\infty \frac{f(x)}{x^2}\sin nx dx=\frac{\pi}{2}f'(0),"Let $f$ be twice continuously differentiable on $[0,\infty)$ , and bounded, with $f(0)=0$ . Show that $\lim_{n\to\infty}\int_0^\infty \frac{f(x)}{x^2}\sin nxdx=\frac{\pi}{2}f'(0).$ My attempts: Using $\int_0^\infty \frac{\sin t}{t}dt=\frac{\pi}{2}$ to find $$\left|\int_0^\infty \frac{f(x)}{x^2}\sin nxdx-\frac{\pi}{2}f'(0)\right| =\left|\int_0^\infty \left[\frac{f(t/n)-f(0)}{t/n}-f'(0)\right]\frac{\sin t}{t}dt\right|$$ For the part $t\leq A$ for fixed $A>0$ it is OK, but for $t>A$ , any ideas? Another try is $$\left|\int_0^\infty \frac{f(x)}{x^2}\sin nxdx-\frac{\pi}{2}f'(0)\right| =\left|\int_0^\infty \frac{f(x)-xf'(0)}{x^2}\sin nxdx\right|$$ The function $\frac{f(x)-xf'(0)}{x^2}$ has limit $f''(0)/2$ as $x\to0^+$ . Oh, it seems that the assumptions are not sufficient, any help? What condition should we add to prove this above limit? And the proof?","Let be twice continuously differentiable on , and bounded, with . Show that My attempts: Using to find For the part for fixed it is OK, but for , any ideas? Another try is The function has limit as . Oh, it seems that the assumptions are not sufficient, any help? What condition should we add to prove this above limit? And the proof?","f [0,\infty) f(0)=0 \lim_{n\to\infty}\int_0^\infty \frac{f(x)}{x^2}\sin nxdx=\frac{\pi}{2}f'(0). \int_0^\infty \frac{\sin t}{t}dt=\frac{\pi}{2} \left|\int_0^\infty \frac{f(x)}{x^2}\sin nxdx-\frac{\pi}{2}f'(0)\right|
=\left|\int_0^\infty \left[\frac{f(t/n)-f(0)}{t/n}-f'(0)\right]\frac{\sin t}{t}dt\right| t\leq A A>0 t>A \left|\int_0^\infty \frac{f(x)}{x^2}\sin nxdx-\frac{\pi}{2}f'(0)\right|
=\left|\int_0^\infty \frac{f(x)-xf'(0)}{x^2}\sin nxdx\right| \frac{f(x)-xf'(0)}{x^2} f''(0)/2 x\to0^+","['calculus', 'integration', 'limits']"
70,Question regarding Solutions to the equation $y'' + y = y^3$,Question regarding Solutions to the equation,y'' + y = y^3,"A while ago I had a question given to me by a tutoring student that read as follows: A solution to the differential equation $y'' + y = y^3$ is: A) $y = \tanh(x/\sqrt{2})$ B) $y = \tanh(x\sqrt{2})$ C) $y = \coth(x/\sqrt{2})$ D) $y = \coth(x\sqrt{2})$ E) None of these. [3 Marks] Given the low marks available, I presumed that the desired method would be to simply 'plug-in' the given solutions to see which were satisfactory. Interestingly, I found that both A) and C) satisfied this equation. I was curious about this, since the formatting to me implied that only one of these should be correct... I decided to scout around online a bit to see if there was an actual method to solving a DE like this to see if I could narrow it down, or pull these solutions out directly (for my own interest). The results I obtained this way were interesting. My method is as below $$y''+y=y^3$$ $$y''y'+yy'=y^3y'$$ $$\frac{1}{2}((y')^2)'+\frac{1}{2}(y^2)'=\frac{1}{4}(y^4)'$$ $$(y')^2+y^2=\frac{1}{2}y^4$$ $$y'=\frac{1}{\sqrt{2}}\sqrt{y^4-2y^2}$$ Separating variables and integrating both sides: $$\int \frac{dy}{y\sqrt{y^2-2}} = \frac{x}{\sqrt{2}} + C$$ Answers I got from here then vary slightly; in my initial attempt I made the substitution $y = \sqrt{2}\cosh{u} \rightarrow dy=\sqrt{2}\sinh{u}du$ , leading to: $$\frac{1}{\sqrt{2}}\int{\frac{du}{\cosh{u}}} = \frac{x}{\sqrt{2}}+C$$ Using a further substitution of $v = e^u$ I finally arrived at a solution: $$\frac{2}{\sqrt{2}}\arctan{e^{\cosh^{-1}{\frac{y}{\sqrt{2}}}}} = \frac{x}{\sqrt{2}}+C$$ After doing some rearranging, I arrived at: $$y = \sqrt{2}\cosh{\left(\ln\left({\tan{\left(\frac{x}{2}+K_1\right)}}\right)\right)}$$ With $K_1 = C/\sqrt{2}$ Sticking this into wolfram alpha seems to show that this is another satisfactory solution to my original equation. Further; when I checked an integral calculator for the result of $$\int\frac{dy}{y\sqrt{y^2-2}}$$ I instead managed to acquire: $$\frac{1}{\sqrt{2}}\arctan{\left(\frac{1}{\sqrt{2}}\sqrt{y^2-2}\right)}=\frac{x}{\sqrt{2}}+C$$ leading to $$y = \sqrt{2}\sec(x+K_2)$$ where $K_2 = C\sqrt{2}$ Again, putting this into wolfram alpha seems to indicate that it is too another solution to the equation. What I'm wondering is How to extract the two solutions indicated in the question out of the DE, as I've clearly been unable to do so, What's the deal with the solutions I've found? I wouldn't be as surprised or intrigued if they both simplified to one (or both) of the results expected from the question, but plotting them indicates that they are not equivalent. Would be greatful to hear some insight from the wider community. Thanks!","A while ago I had a question given to me by a tutoring student that read as follows: A solution to the differential equation is: A) B) C) D) E) None of these. [3 Marks] Given the low marks available, I presumed that the desired method would be to simply 'plug-in' the given solutions to see which were satisfactory. Interestingly, I found that both A) and C) satisfied this equation. I was curious about this, since the formatting to me implied that only one of these should be correct... I decided to scout around online a bit to see if there was an actual method to solving a DE like this to see if I could narrow it down, or pull these solutions out directly (for my own interest). The results I obtained this way were interesting. My method is as below Separating variables and integrating both sides: Answers I got from here then vary slightly; in my initial attempt I made the substitution , leading to: Using a further substitution of I finally arrived at a solution: After doing some rearranging, I arrived at: With Sticking this into wolfram alpha seems to show that this is another satisfactory solution to my original equation. Further; when I checked an integral calculator for the result of I instead managed to acquire: leading to where Again, putting this into wolfram alpha seems to indicate that it is too another solution to the equation. What I'm wondering is How to extract the two solutions indicated in the question out of the DE, as I've clearly been unable to do so, What's the deal with the solutions I've found? I wouldn't be as surprised or intrigued if they both simplified to one (or both) of the results expected from the question, but plotting them indicates that they are not equivalent. Would be greatful to hear some insight from the wider community. Thanks!",y'' + y = y^3 y = \tanh(x/\sqrt{2}) y = \tanh(x\sqrt{2}) y = \coth(x/\sqrt{2}) y = \coth(x\sqrt{2}) y''+y=y^3 y''y'+yy'=y^3y' \frac{1}{2}((y')^2)'+\frac{1}{2}(y^2)'=\frac{1}{4}(y^4)' (y')^2+y^2=\frac{1}{2}y^4 y'=\frac{1}{\sqrt{2}}\sqrt{y^4-2y^2} \int \frac{dy}{y\sqrt{y^2-2}} = \frac{x}{\sqrt{2}} + C y = \sqrt{2}\cosh{u} \rightarrow dy=\sqrt{2}\sinh{u}du \frac{1}{\sqrt{2}}\int{\frac{du}{\cosh{u}}} = \frac{x}{\sqrt{2}}+C v = e^u \frac{2}{\sqrt{2}}\arctan{e^{\cosh^{-1}{\frac{y}{\sqrt{2}}}}} = \frac{x}{\sqrt{2}}+C y = \sqrt{2}\cosh{\left(\ln\left({\tan{\left(\frac{x}{2}+K_1\right)}}\right)\right)} K_1 = C/\sqrt{2} \int\frac{dy}{y\sqrt{y^2-2}} \frac{1}{\sqrt{2}}\arctan{\left(\frac{1}{\sqrt{2}}\sqrt{y^2-2}\right)}=\frac{x}{\sqrt{2}}+C y = \sqrt{2}\sec(x+K_2) K_2 = C\sqrt{2},"['calculus', 'ordinary-differential-equations', 'trigonometry', 'hyperbolic-functions']"
71,Number of real roots of polynomial and intermediate value theorem,Number of real roots of polynomial and intermediate value theorem,,"Let $p:\mathbb{R}\rightarrow\mathbb{R}$ be a polynomial function with real coefficients satisfying \begin{align} p(x_1)<0, p(x_2)>0, p(x_3)<0,\ldots \text{(sign flips in alternating manner)} \end{align} for $x_1<x_2<\ldots<x_n$ . Even without polynomial assumption, by virtue of intermediate value theorem (IVT), it is apparent that there are at least $n-1$ distinct real roots—precisely, at least one root in each interval $(x_k,x_{k+1}), k=1,\ldots,n-1$ . Replacing all strict inequalities with non-strict counterparts, that is, \begin{align} p(x_1)\leq0, p(x_2)\geq0, p(x_3)\leq0,\ldots \text{(sign flips in alternating manner)}, \end{align} we can again guarantee that there are at least $n-1$ real roots in $[x_1,x_n]$ when taking multiplicity into account. Let us commence (somehow dirty) derivation with strong induction on $n$ . Base case: The base case $n=2$ is trivial: if either $p(x_1)$ and $p(x_2)$ is zero, we are done; otherwise, applying IVT works out. Induction step: Assume that the claim holds for $n<m$ and consider the case $n=m$ . Let us divide and conquer the problem. i) $p(x_1)=0$ : $x_1$ is a root, and there are at least $m-2$ roots in $[x_2,x_m]$ from induction hypothesis. ii) $p(x_1)<0$ , $p(x_2)>0$ : There is at least one root in $(x_1,x_2)$ by IVT, and there are at least $m-2$ roots in $[x_2,x_m]$ from induction hypothesis. iii) $p(x_1)<0$ , $p(x_2)=0$ : We further divide into three cases: iii-a) $p'(x_2)=0$ : $x_2$ is a root with multiplicity 2, and there are at least $m-3$ roots in $[x_3,x_m]$ from induction hypothesis. iii-b) $p'(x_2)>0$ : We can find $x_2'\in(x_2,x_3)$ such that $p(x_2')>0$ . Applying the inductive hypothesis to $x_2',x_3,\ldots,x_m$ , there are at least $m-2$ roots in $[x_2',x_m]$ . Together with $x_2$ , there are at least $m-1$ roots in $[x_2,x_m]$ . iii-c) $p'(x_2)<0$ : We can find $x_2'\in(x_1,x_2)$ such that $p(x_2')>0$ . Therefore, there is at least one root in $(x_1,x_2')$ by IVT. Together with $m-2$ roots in $[x_2,x_m]$ where the existence is guaranteed by induction hypothesis, we have $m-1$ roots in $[x_1,x_m]$ . I reckon that the statement of the claim is intuitive whereas my proof described above is unnecessarily complicated. Hence, my question is twofold: Is there any simple and elegant proof of this claim? Is there any name referring to this claim? Any comments would be much appreciated.","Let be a polynomial function with real coefficients satisfying for . Even without polynomial assumption, by virtue of intermediate value theorem (IVT), it is apparent that there are at least distinct real roots—precisely, at least one root in each interval . Replacing all strict inequalities with non-strict counterparts, that is, we can again guarantee that there are at least real roots in when taking multiplicity into account. Let us commence (somehow dirty) derivation with strong induction on . Base case: The base case is trivial: if either and is zero, we are done; otherwise, applying IVT works out. Induction step: Assume that the claim holds for and consider the case . Let us divide and conquer the problem. i) : is a root, and there are at least roots in from induction hypothesis. ii) , : There is at least one root in by IVT, and there are at least roots in from induction hypothesis. iii) , : We further divide into three cases: iii-a) : is a root with multiplicity 2, and there are at least roots in from induction hypothesis. iii-b) : We can find such that . Applying the inductive hypothesis to , there are at least roots in . Together with , there are at least roots in . iii-c) : We can find such that . Therefore, there is at least one root in by IVT. Together with roots in where the existence is guaranteed by induction hypothesis, we have roots in . I reckon that the statement of the claim is intuitive whereas my proof described above is unnecessarily complicated. Hence, my question is twofold: Is there any simple and elegant proof of this claim? Is there any name referring to this claim? Any comments would be much appreciated.","p:\mathbb{R}\rightarrow\mathbb{R} \begin{align}
p(x_1)<0, p(x_2)>0, p(x_3)<0,\ldots \text{(sign flips in alternating manner)}
\end{align} x_1<x_2<\ldots<x_n n-1 (x_k,x_{k+1}), k=1,\ldots,n-1 \begin{align}
p(x_1)\leq0, p(x_2)\geq0, p(x_3)\leq0,\ldots \text{(sign flips in alternating manner)},
\end{align} n-1 [x_1,x_n] n n=2 p(x_1) p(x_2) n<m n=m p(x_1)=0 x_1 m-2 [x_2,x_m] p(x_1)<0 p(x_2)>0 (x_1,x_2) m-2 [x_2,x_m] p(x_1)<0 p(x_2)=0 p'(x_2)=0 x_2 m-3 [x_3,x_m] p'(x_2)>0 x_2'\in(x_2,x_3) p(x_2')>0 x_2',x_3,\ldots,x_m m-2 [x_2',x_m] x_2 m-1 [x_2,x_m] p'(x_2)<0 x_2'\in(x_1,x_2) p(x_2')>0 (x_1,x_2') m-2 [x_2,x_m] m-1 [x_1,x_m]",['calculus']
72,Is my Calculus Proof Correct?,Is my Calculus Proof Correct?,,"Question: A not uncommon calculus mistake is to believe that the product rule for derivatives says that $(fg)'=f'g'$ . If $f(x)=e^{x^2}$ , determine, with proof, whether there exists an open interval $(a,b)$ and a nonzero differentiable function $g$ defined on $(a,b)$ such that this wrong product rule is true for $x$ in $(a,b)$ . Is my solution correct? Is there anything I need to improve? My solution: We're trying to find a function $g$ such that $(fg)'=f'g'.$ Using the product rule, we get $$f'g + fg' =  f'g'.$$ Plugging in both $f(x)=e^{x^2}$ and $f'(x)=2xe^{x^2},$ we get $$2xe^{x^2}g + e^{x^2}g' = 2xe^{x^2}g'.$$ Simplifying and canceling $e^{x^2},$ we get $$\frac{g'}{g} = \frac{2x-1}{2x} = 1 +  \frac{1}{2x-1}.$$ Taking the integral of both sides, $$\int \frac{dg}g = \int 1+ \frac{1}{2x-1} \, dx.$$ $$\log|g| = \frac{\log|2x-1|}{2} + x + C.$$ $$|g| = e^{\frac{\log|2x-1|}{2}}e^xe^C.$$ Letting $e^C=K,$ we get $$\boxed{g = Ke^x\sqrt{|2x-1|}},$$ Where K is a constant greater than 0. Therefore, on any interval $(a,b)$ that does not contain the value of $\frac{1}{2},$ there exists nonzero differentiable function $g$ defined on $(a,b)$ such that $(fg)'=f'g'$ is true for $x$ in $(a,b)$ .","Question: A not uncommon calculus mistake is to believe that the product rule for derivatives says that . If , determine, with proof, whether there exists an open interval and a nonzero differentiable function defined on such that this wrong product rule is true for in . Is my solution correct? Is there anything I need to improve? My solution: We're trying to find a function such that Using the product rule, we get Plugging in both and we get Simplifying and canceling we get Taking the integral of both sides, Letting we get Where K is a constant greater than 0. Therefore, on any interval that does not contain the value of there exists nonzero differentiable function defined on such that is true for in .","(fg)'=f'g' f(x)=e^{x^2} (a,b) g (a,b) x (a,b) g (fg)'=f'g'. f'g + fg' =  f'g'. f(x)=e^{x^2} f'(x)=2xe^{x^2}, 2xe^{x^2}g + e^{x^2}g' = 2xe^{x^2}g'. e^{x^2}, \frac{g'}{g} = \frac{2x-1}{2x} = 1 +  \frac{1}{2x-1}. \int \frac{dg}g = \int 1+ \frac{1}{2x-1} \, dx. \log|g| = \frac{\log|2x-1|}{2} + x + C. |g| = e^{\frac{\log|2x-1|}{2}}e^xe^C. e^C=K, \boxed{g = Ke^x\sqrt{|2x-1|}}, (a,b) \frac{1}{2}, g (a,b) (fg)'=f'g' x (a,b)","['calculus', 'integration', 'derivatives', 'solution-verification']"
73,Find all polynomial functions,Find all polynomial functions,,"Find all polynomials $P(x)=a_0+a_1x+... a_nx^n; a_i \in Z$ such that $\forall x$ : $P(x)=(x-P(0))(x-P(1))...(x-P(n-1))$ I substituted some values like $0,1$ to get an idea of the polynomial coefficients and tried to see some pattern but it doesn't seem to be helping much. Also is it possible that calculus might play a role here since we have been given a polynomial function and not just a functional equation in general?",Find all polynomials such that : I substituted some values like to get an idea of the polynomial coefficients and tried to see some pattern but it doesn't seem to be helping much. Also is it possible that calculus might play a role here since we have been given a polynomial function and not just a functional equation in general?,"P(x)=a_0+a_1x+... a_nx^n; a_i \in Z \forall x P(x)=(x-P(0))(x-P(1))...(x-P(n-1)) 0,1","['calculus', 'polynomials', 'contest-math', 'functional-equations']"
74,"Evaluating $\int \sqrt{\frac{5-x}{x-2}}\,dx$ with two different methods and getting two different results [duplicate]",Evaluating  with two different methods and getting two different results [duplicate],"\int \sqrt{\frac{5-x}{x-2}}\,dx","This question already has an answer here : Getting different answers when integrating using different techniques (1 answer) Closed 4 years ago . I tried Evaluating $\int \sqrt{\dfrac{5-x}{x-2}}dx$ using two different methods and got two different results. Getting two different answers when tried using two different methods:- M- $1$ : $$\int \dfrac{5-x}{\sqrt{\left(5-x\right)\left(x-2\right)}}dx$$ $$\dfrac{1}{2}\int\dfrac{-2x+7}{\sqrt{\left(5-x\right)\left(x-2\right)}}dx+\dfrac{3}{2}\int\dfrac{dx}{\sqrt{\left(5-x\right)\left(x-2\right)}}$$ $$\sqrt{\left(5-x\right)\left(x-2\right)}+\dfrac{3}{2}\int\dfrac{dx}{\sqrt{-x^2+7x-10}}$$ $$\sqrt{\left(5-x\right)\left(x-2\right)}+\dfrac{3}{2}\int\dfrac{dx}{\sqrt{\left(\dfrac{3}{2}\right)^2-\left(x-\dfrac{7}{2}\right)^2}}$$ $$\sqrt{\left(5-x\right)\left(x-2\right)}+\dfrac{3}{2}\sin^{-1}\dfrac{x-\dfrac{7}{2}}{\dfrac{3}{2}}$$ $$\sqrt{\left(5-x\right)\left(x-2\right)}+\dfrac{3}{2}\sin^{-1}\dfrac{2x-7}{3}$$ M- $2$ : $$x=5\sin^2\theta+2\cos^2\theta$$ $$dx=\left(10\sin\theta\cos\theta-4\cos\theta\sin\theta\right) \, d\theta$$ $$\int \sqrt{\dfrac{5\cos^2\theta-2\cos^2\theta}{5\sin^2\theta-2\sin^2\theta}}\cdot6\sin\theta\cos\theta \,d\theta$$ $$6\int \cos^2\theta \,d\theta$$ $$\int 3\left(1+\cos2\theta\right) \,d\theta$$ $$3\left(\theta+\dfrac{\sin2\theta}{2}\right)$$ $$3\theta+\dfrac{3}{2}\sin2\theta$$ $$x=5\sin^2\theta+2-2\sin^2\theta$$ $$\sin^{-1}\sqrt{\dfrac{x-2}{3}}=\theta$$ $$\cos2\theta=1-2\sin^2\theta$$ $$\cos2\theta=1-2\cdot\dfrac{x-2}{3}$$ $$\cos2\theta=\dfrac{7-2x}{3}$$ $$3\sin^{-1}\sqrt{\dfrac{x-2}{3}}+\dfrac{3}{2}\cdot\dfrac{\sqrt{9-(49+4x^2-28x)}}{3}$$ $$3\sin^{-1}\sqrt{\dfrac{x-2}{3}}+\sqrt{\left(5-x\right)\left(x-2\right)}$$ In first and second method I am getting the different results of $\dfrac{3}{2}\sin^{-1}\dfrac{2x-7}{3}$ and $3\sin^{-1}\sqrt{\dfrac{x-2}{3}}$ respectively. I checked that these are not inter-convertible. Why am I getting this difference?",This question already has an answer here : Getting different answers when integrating using different techniques (1 answer) Closed 4 years ago . I tried Evaluating using two different methods and got two different results. Getting two different answers when tried using two different methods:- M- : M- : In first and second method I am getting the different results of and respectively. I checked that these are not inter-convertible. Why am I getting this difference?,"\int \sqrt{\dfrac{5-x}{x-2}}dx 1 \int \dfrac{5-x}{\sqrt{\left(5-x\right)\left(x-2\right)}}dx \dfrac{1}{2}\int\dfrac{-2x+7}{\sqrt{\left(5-x\right)\left(x-2\right)}}dx+\dfrac{3}{2}\int\dfrac{dx}{\sqrt{\left(5-x\right)\left(x-2\right)}} \sqrt{\left(5-x\right)\left(x-2\right)}+\dfrac{3}{2}\int\dfrac{dx}{\sqrt{-x^2+7x-10}} \sqrt{\left(5-x\right)\left(x-2\right)}+\dfrac{3}{2}\int\dfrac{dx}{\sqrt{\left(\dfrac{3}{2}\right)^2-\left(x-\dfrac{7}{2}\right)^2}} \sqrt{\left(5-x\right)\left(x-2\right)}+\dfrac{3}{2}\sin^{-1}\dfrac{x-\dfrac{7}{2}}{\dfrac{3}{2}} \sqrt{\left(5-x\right)\left(x-2\right)}+\dfrac{3}{2}\sin^{-1}\dfrac{2x-7}{3} 2 x=5\sin^2\theta+2\cos^2\theta dx=\left(10\sin\theta\cos\theta-4\cos\theta\sin\theta\right) \, d\theta \int \sqrt{\dfrac{5\cos^2\theta-2\cos^2\theta}{5\sin^2\theta-2\sin^2\theta}}\cdot6\sin\theta\cos\theta \,d\theta 6\int \cos^2\theta \,d\theta \int 3\left(1+\cos2\theta\right) \,d\theta 3\left(\theta+\dfrac{\sin2\theta}{2}\right) 3\theta+\dfrac{3}{2}\sin2\theta x=5\sin^2\theta+2-2\sin^2\theta \sin^{-1}\sqrt{\dfrac{x-2}{3}}=\theta \cos2\theta=1-2\sin^2\theta \cos2\theta=1-2\cdot\dfrac{x-2}{3} \cos2\theta=\dfrac{7-2x}{3} 3\sin^{-1}\sqrt{\dfrac{x-2}{3}}+\dfrac{3}{2}\cdot\dfrac{\sqrt{9-(49+4x^2-28x)}}{3} 3\sin^{-1}\sqrt{\dfrac{x-2}{3}}+\sqrt{\left(5-x\right)\left(x-2\right)} \dfrac{3}{2}\sin^{-1}\dfrac{2x-7}{3} 3\sin^{-1}\sqrt{\dfrac{x-2}{3}}","['calculus', 'integration']"
75,"The existence of $a,b$ such that $\int_a^b f(x)dx=\int_a^b g(x)dx=1/2$. [duplicate]",The existence of  such that . [duplicate],"a,b \int_a^b f(x)dx=\int_a^b g(x)dx=1/2","This question already has answers here : Show that there exist $[a,b]\subset [0,1]$, such that $\int_{a}^{b}f(x)dx$ = $\int_{a}^{b}g(x)dx$ = $\frac{1}{2}$ (4 answers) Closed 4 years ago . Let $f,g$ be Riemann integrable on $[0,1]$ such that $\int_0^1 f=\int_0^1 g=1$ . Show that there exists $0\leq a<b\leq 1$ such that $\int_a^b f=\int_a^b g=\frac{1}{2}$ . If there is only one function $f$ , it is easy. What about two functions?","This question already has answers here : Show that there exist $[a,b]\subset [0,1]$, such that $\int_{a}^{b}f(x)dx$ = $\int_{a}^{b}g(x)dx$ = $\frac{1}{2}$ (4 answers) Closed 4 years ago . Let be Riemann integrable on such that . Show that there exists such that . If there is only one function , it is easy. What about two functions?","f,g [0,1] \int_0^1 f=\int_0^1 g=1 0\leq a<b\leq 1 \int_a^b f=\int_a^b g=\frac{1}{2} f","['calculus', 'integration']"
76,Find $P(n+1)$ for a polynomial P,Find  for a polynomial P,P(n+1),"Fix a nonnegative integer $n$ . Let $P(x)$ be a polynomial of degree $n$ (over the real numbers) such that for all $k\in\left\{0,1,\ldots,n\right\}$ , we have $P(k)=\dfrac{k}{k+1}$ . Find $P(n+1)$ . My attempt: I consider a new polynomial $Q(x)=(x+1)P(x)-x$ . This $Q$ is a polynomial of degree $\leq n+1$ satisfying: $Q(k)=0\quad\forall k\in\{0,1,2,\ldots,n\}$ . Therefore $Q(x)=\lambda x(x-1)\cdots(x-n)$ for a certain real $\lambda$ . Hence, $Q(-1)=\lambda \cdot (-1)^{n+1}(n+1)!$ , but also $Q(-1)=(-1+1)P(-1)+1=1$ . Comparing these, we get $\lambda \cdot (-1)^{n+1} (n+1)! = 1$ , thus $\lambda=\dfrac{(-1)^{n+1}}{(n+1)!}$ . Since $Q(n+1)=\lambda(n+1)!$ then $Q(n+1)=(-1)^{n+1} $ , and from $P(x) = \dfrac{Q(x)+x}{x+1}$ we deduce: $$P(n+1)=\dfrac{(-1)^{n+1}+n+1}{n+2}.$$ I doubted that the answer were $P(n+1)=\frac{n+1}{n+2}$ but the term $(-1)^{n+1}$ wasn’t expected. Is there any mistake here? Does someone have an alternative proof?","Fix a nonnegative integer . Let be a polynomial of degree (over the real numbers) such that for all , we have . Find . My attempt: I consider a new polynomial . This is a polynomial of degree satisfying: . Therefore for a certain real . Hence, , but also . Comparing these, we get , thus . Since then , and from we deduce: I doubted that the answer were but the term wasn’t expected. Is there any mistake here? Does someone have an alternative proof?","n P(x) n k\in\left\{0,1,\ldots,n\right\} P(k)=\dfrac{k}{k+1} P(n+1) Q(x)=(x+1)P(x)-x Q \leq n+1 Q(k)=0\quad\forall k\in\{0,1,2,\ldots,n\} Q(x)=\lambda x(x-1)\cdots(x-n) \lambda Q(-1)=\lambda \cdot (-1)^{n+1}(n+1)! Q(-1)=(-1+1)P(-1)+1=1 \lambda \cdot (-1)^{n+1} (n+1)! = 1 \lambda=\dfrac{(-1)^{n+1}}{(n+1)!} Q(n+1)=\lambda(n+1)! Q(n+1)=(-1)^{n+1}  P(x) = \dfrac{Q(x)+x}{x+1} P(n+1)=\dfrac{(-1)^{n+1}+n+1}{n+2}. P(n+1)=\frac{n+1}{n+2} (-1)^{n+1}","['calculus', 'polynomials', 'alternative-proof']"
77,Confusion in this limits problem,Confusion in this limits problem,,"Evaluate $$\lim\limits_{n\to \infty} \frac{1^2 + 2^2 +...+n^2}{n^3}$$ This is the original method to solve this is: Taking summation of the square numbers $1^2 + 2^2 + 3^2 +...+n^2 = \frac{1}{6}n(n+1)(2n+1)$ $$\lim\limits_{n\to \infty} \frac{1^2 + 2^2 +...+n^2}{n^3} = \frac{\frac{1}{6}n(n+1)(2n+1)}{n^3}$$ $$=\lim\limits_{n \to \infty} \frac{(n+1)(2n+1)}{6n^2} = \lim\limits_{n\to \infty} \frac{1}{6}(1+\frac{1}{n})(2+\frac{1}{n})$$ $$=\frac{2}{6} = \frac{1}{3}$$ But when looking at the limit in a different angle I get a different answer, $$\lim\limits_{n\to \infty} \frac{1^2 + 2^2 +...+n^2}{n^3} = \lim\limits_{n\to \infty} \frac{1^2}{n^3}+\frac{2^2}{n^3}+...+\frac{1}{n}$$ $$=0+0+...+0 = 0$$ Both the method seem right to me, but why I am getting different answers? What have I done wrong? Please Explain. Thank you!","Evaluate This is the original method to solve this is: Taking summation of the square numbers But when looking at the limit in a different angle I get a different answer, Both the method seem right to me, but why I am getting different answers? What have I done wrong? Please Explain. Thank you!",\lim\limits_{n\to \infty} \frac{1^2 + 2^2 +...+n^2}{n^3} 1^2 + 2^2 + 3^2 +...+n^2 = \frac{1}{6}n(n+1)(2n+1) \lim\limits_{n\to \infty} \frac{1^2 + 2^2 +...+n^2}{n^3} = \frac{\frac{1}{6}n(n+1)(2n+1)}{n^3} =\lim\limits_{n \to \infty} \frac{(n+1)(2n+1)}{6n^2} = \lim\limits_{n\to \infty} \frac{1}{6}(1+\frac{1}{n})(2+\frac{1}{n}) =\frac{2}{6} = \frac{1}{3} \lim\limits_{n\to \infty} \frac{1^2 + 2^2 +...+n^2}{n^3} = \lim\limits_{n\to \infty} \frac{1^2}{n^3}+\frac{2^2}{n^3}+...+\frac{1}{n} =0+0+...+0 = 0,"['calculus', 'limits', 'summation']"
78,"A simple question about the proof of theorem 3.42 in Walter Rudin's ""Principles of Mathematical Analysis""","A simple question about the proof of theorem 3.42 in Walter Rudin's ""Principles of Mathematical Analysis""",,"I am reading ""Principles of Mathematical Analysis"" by Walter Rudin. I read the proof of theorem 3.42 on p.71. And I have a simple question about the following calculation: $$|\sum_{n=p}^{q} a_n b_n| = |\sum_{n=p}^{q-1} A_n (b_n - b_{n+1}) + A_q b_q - A_{p-1} b_p| \leq M |\sum_{n=p}^{q-1} (b_n - b_{n+1}) + b_q + b_p|.$$ My calculation is here: $$|\sum_{n=p}^{q} a_n b_n| = |\sum_{n=p}^{q-1} A_n (b_n - b_{n+1}) + A_q b_q - A_{p-1} b_p| \leq \\\sum_{n=p}^{q-1} |A_n| |(b_n - b_{n+1})| + |A_q| |b_q| + |A_{p-1} | |b_p| \leq \\\sum_{n=p}^{q-1} M |(b_n - b_{n+1})| + M |b_q| + M |b_p| = \\\sum_{n=p}^{q-1} M (b_n - b_{n+1}) + M b_q + M b_p = \\ M (\sum_{n=p}^{q-1}  (b_n - b_{n+1}) +  b_q +  b_p).$$ Of course, $$M |\sum_{n=p}^{q-1} (b_n - b_{n+1}) + b_q + b_p| = M (\sum_{n=p}^{q-1} (b_n - b_{n+1}) + b_q + b_p),$$ but why did Rudin write as follows? $$M |\sum_{n=p}^{q-1} (b_n - b_{n+1}) + b_q + b_p|.$$","I am reading ""Principles of Mathematical Analysis"" by Walter Rudin. I read the proof of theorem 3.42 on p.71. And I have a simple question about the following calculation: My calculation is here: Of course, but why did Rudin write as follows?","|\sum_{n=p}^{q} a_n b_n| = |\sum_{n=p}^{q-1} A_n (b_n - b_{n+1}) + A_q b_q - A_{p-1} b_p| \leq M |\sum_{n=p}^{q-1} (b_n - b_{n+1}) + b_q + b_p|. |\sum_{n=p}^{q} a_n b_n| = |\sum_{n=p}^{q-1} A_n (b_n - b_{n+1}) + A_q b_q - A_{p-1} b_p| \leq \\\sum_{n=p}^{q-1} |A_n| |(b_n - b_{n+1})| + |A_q| |b_q| + |A_{p-1} | |b_p| \leq \\\sum_{n=p}^{q-1} M |(b_n - b_{n+1})| + M |b_q| + M |b_p| = \\\sum_{n=p}^{q-1} M (b_n - b_{n+1}) + M b_q + M b_p = \\ M (\sum_{n=p}^{q-1}  (b_n - b_{n+1}) +  b_q +  b_p). M |\sum_{n=p}^{q-1} (b_n - b_{n+1}) + b_q + b_p| = M (\sum_{n=p}^{q-1} (b_n - b_{n+1}) + b_q + b_p), M |\sum_{n=p}^{q-1} (b_n - b_{n+1}) + b_q + b_p|.","['calculus', 'sequences-and-series', 'proof-verification']"
79,Calculating $\sum\limits_{n=1}^\infty\frac{{1}}{n+3^n} $,Calculating,\sum\limits_{n=1}^\infty\frac{{1}}{n+3^n} ,I was able to prove this sum $$\sum_{n=1}^\infty\frac{{1}}{n+3^n}$$ is convergent through the comparison test but I don't get how to find its sum.,I was able to prove this sum is convergent through the comparison test but I don't get how to find its sum.,\sum_{n=1}^\infty\frac{{1}}{n+3^n},"['calculus', 'sequences-and-series', 'convergence-divergence', 'summation']"
80,A nice expression for $\int_0^{\pi/2} \left[\frac{1}{x \sin(x)}-\frac{1}{x^2}\right] \mathrm{d} x$,A nice expression for,\int_0^{\pi/2} \left[\frac{1}{x \sin(x)}-\frac{1}{x^2}\right] \mathrm{d} x,"Motivated by the easier integral $$ \int \limits_0^\infty \left[\frac{1}{x^2} - \frac{1}{x \sinh(x)}\right] \mathrm{d} x = \ln(2) \, ,$$ I have been trying to compute $$ I \equiv \int \limits_0^{\pi/2} \left[\frac{1}{x \sin(x)} - \frac{1}{x^2} \right] \mathrm{d} x \approx 0.29172334953491321 \, .$$ I have not found a closed-form expression yet and inverse symbolic calculators do not give any results either. However, a few other representations for $I$ can be derived using the following methods: Laurent series The Laurent series of the cosecant function is given by $$\csc(x) = \frac{1}{x} + \sum \limits_{k=1}^\infty \frac{\lvert \mathrm{B}_{2k}\rvert (4^k - 2)}{(2k)!} x^{2k-1}$$ in terms of the Bernoulli numbers $(\mathrm{B}_n)_{n \in \mathbb{N}_0}$ and has radius of convergence $\pi$ , so we can integrate termwise to obtain $$ \tag{1} I = \sum \limits_{k=1}^\infty \frac{\lvert \mathrm{B}_{2k}\rvert  \left[2-4^{-(k-1)}\right] \pi^{2k-1}}{(2k-1)(2k)!} \, .$$ Pole expansion The series $$ \csc(x) = \frac{1}{x} + 2 x \sum \limits_{n=1}^\infty \frac{(-1)^{n-1}}{\pi^2 n^2 - x^2}$$ yields $$\tag{2} I = \frac{1}{\pi} \sum \limits_{n=1}^\infty \frac{(-1)^{n-1}}{n} \ln\left(\frac{2n+1}{2n-1}\right) \, .$$ Expanding the logarithm only leads to $$ \tag{3} I = \frac{1}{\pi} \sum \limits_{k=1}^\infty \frac{\eta(2k)}{(2k-1) 4^{k-1}} \, ,$$ which reduces to $(1)$ when the special values of the eta functions are used. Summation by parts turns $(2)$ into $$ \tag{4} I =  \frac{4}{\pi} \sum \limits_{n=1}^\infty \frac{(-1)^{n-1} (2n+1) \ln(2n+1)}{(2n+1)^2 -1} \, . $$ This can also be written as $$ \tag{5} I = \frac{4}{\pi} \beta'(1) + \frac{1}{\pi} \sum \limits_{n=1}^\infty \frac{(-1)^{n-1} \ln(2n+1)}{2n^3+3n^2+n} \, ,$$ where $\beta$ is the Dirichlet beta function (there is a reasonably nice expression for $\beta'(1)$). Integration by parts There are several possible ways to integrate by parts. One of them shows that $$ \tag{6} I = \frac{2}{\pi} \ln \left(\frac{4}{\pi}\right) + \frac{1}{2} \int \limits_0^{\pi/4} \frac{\ln[\tan(t)/t]}{t^2} \, \mathrm{d} t $$ holds. I am not sure how to proceed from here though. Plugging in the Maclaurin series of $\ln[\tan(t)/t]$ reproduces $(1)$ . Contour integration (due to eyeballfrog) As demonstrated in eyeballfrog's answer we also have $$ \tag{7} I = \frac{2}{\pi} - \int \limits_0^\infty \frac{t}{1+t^2} \, \operatorname{sech}\left(\frac{\pi}{2} t\right) \, \mathrm{d} t \, .$$ Using the pole expansion of $\operatorname{sech}$ yields $(4)$ again. That is all I have at the moment, so my question is: Is it possible to find a closed-form expression for the value of $I$ or can we at least rewrite any of the integral or series representation in terms of a suitable special function?","Motivated by the easier integral $$ \int \limits_0^\infty \left[\frac{1}{x^2} - \frac{1}{x \sinh(x)}\right] \mathrm{d} x = \ln(2) \, ,$$ I have been trying to compute $$ I \equiv \int \limits_0^{\pi/2} \left[\frac{1}{x \sin(x)} - \frac{1}{x^2} \right] \mathrm{d} x \approx 0.29172334953491321 \, .$$ I have not found a closed-form expression yet and inverse symbolic calculators do not give any results either. However, a few other representations for $I$ can be derived using the following methods: Laurent series The Laurent series of the cosecant function is given by $$\csc(x) = \frac{1}{x} + \sum \limits_{k=1}^\infty \frac{\lvert \mathrm{B}_{2k}\rvert (4^k - 2)}{(2k)!} x^{2k-1}$$ in terms of the Bernoulli numbers $(\mathrm{B}_n)_{n \in \mathbb{N}_0}$ and has radius of convergence $\pi$ , so we can integrate termwise to obtain $$ \tag{1} I = \sum \limits_{k=1}^\infty \frac{\lvert \mathrm{B}_{2k}\rvert  \left[2-4^{-(k-1)}\right] \pi^{2k-1}}{(2k-1)(2k)!} \, .$$ Pole expansion The series $$ \csc(x) = \frac{1}{x} + 2 x \sum \limits_{n=1}^\infty \frac{(-1)^{n-1}}{\pi^2 n^2 - x^2}$$ yields $$\tag{2} I = \frac{1}{\pi} \sum \limits_{n=1}^\infty \frac{(-1)^{n-1}}{n} \ln\left(\frac{2n+1}{2n-1}\right) \, .$$ Expanding the logarithm only leads to $$ \tag{3} I = \frac{1}{\pi} \sum \limits_{k=1}^\infty \frac{\eta(2k)}{(2k-1) 4^{k-1}} \, ,$$ which reduces to $(1)$ when the special values of the eta functions are used. Summation by parts turns $(2)$ into $$ \tag{4} I =  \frac{4}{\pi} \sum \limits_{n=1}^\infty \frac{(-1)^{n-1} (2n+1) \ln(2n+1)}{(2n+1)^2 -1} \, . $$ This can also be written as $$ \tag{5} I = \frac{4}{\pi} \beta'(1) + \frac{1}{\pi} \sum \limits_{n=1}^\infty \frac{(-1)^{n-1} \ln(2n+1)}{2n^3+3n^2+n} \, ,$$ where $\beta$ is the Dirichlet beta function (there is a reasonably nice expression for $\beta'(1)$). Integration by parts There are several possible ways to integrate by parts. One of them shows that $$ \tag{6} I = \frac{2}{\pi} \ln \left(\frac{4}{\pi}\right) + \frac{1}{2} \int \limits_0^{\pi/4} \frac{\ln[\tan(t)/t]}{t^2} \, \mathrm{d} t $$ holds. I am not sure how to proceed from here though. Plugging in the Maclaurin series of $\ln[\tan(t)/t]$ reproduces $(1)$ . Contour integration (due to eyeballfrog) As demonstrated in eyeballfrog's answer we also have $$ \tag{7} I = \frac{2}{\pi} - \int \limits_0^\infty \frac{t}{1+t^2} \, \operatorname{sech}\left(\frac{\pi}{2} t\right) \, \mathrm{d} t \, .$$ Using the pole expansion of $\operatorname{sech}$ yields $(4)$ again. That is all I have at the moment, so my question is: Is it possible to find a closed-form expression for the value of $I$ or can we at least rewrite any of the integral or series representation in terms of a suitable special function?",,"['calculus', 'integration', 'sequences-and-series', 'definite-integrals']"
81,Expressions for integrals of non-elementary integrals,Expressions for integrals of non-elementary integrals,,"Functions like $\frac1{\log x}$ have no elementary integrals in terms of standard functions; they are instead represented using special function notations, such as $\mathrm{li}(x)$. That's all and well, but how does one obtain an expression for the integral of these nonelementary integrals? I would expect that there would be "" no result found in terms of standard mathematical functions "", but WolframAlpha actually gives an expression for the logarithmic integral : $$\int \mathrm{li}(x)dx = x \, \mathrm{li}(x) - \mathrm{Ei}(2 \log x) + C.$$ (Or $x \, \mathrm{li}(x) - \mathrm{li}(x^2) + C$, for an appropriate choice of domain.) How does WolframAlpha obtain such a result? Is there a special technique that I am unaware of?","Functions like $\frac1{\log x}$ have no elementary integrals in terms of standard functions; they are instead represented using special function notations, such as $\mathrm{li}(x)$. That's all and well, but how does one obtain an expression for the integral of these nonelementary integrals? I would expect that there would be "" no result found in terms of standard mathematical functions "", but WolframAlpha actually gives an expression for the logarithmic integral : $$\int \mathrm{li}(x)dx = x \, \mathrm{li}(x) - \mathrm{Ei}(2 \log x) + C.$$ (Or $x \, \mathrm{li}(x) - \mathrm{li}(x^2) + C$, for an appropriate choice of domain.) How does WolframAlpha obtain such a result? Is there a special technique that I am unaware of?",,"['calculus', 'integration', 'indefinite-integrals']"
82,What does Infimum of Upper Sum and Supremum of Lower Sums mean?,What does Infimum of Upper Sum and Supremum of Lower Sums mean?,,"I'm trying to figure out the Darboux Integral definition as it states:  $f$ is integrable if $inf${U($f$,$P$)} = $sup${L($f$,$P$)}, where U($f$,$P$) is the upper sum, L($f$,$P$) is the lower sum of $f$ and $P$ is a parition of $f$. I'm not understanding what the $sup$/$inf$ of the sums mean. When calculating, they are a finite value (ie. L($f$,$P$) = $\sum_{i=1}^n m_i (x_i - x_{i-1})$) Consider: $$f(x) = 2x, x \in [0,1];~ P = \{0,\frac{1}{4},\frac{1}{2},1\}.$$ Since $P$ has 4 elements, n=3, thus 3 subintervals of $[0,1]$, can you definte these 3 subintervals however you want as long as they range [0,1]? ie. $$[0,\tfrac{1}{4}] \,\cup\, [\tfrac{1}{4},\tfrac{1}{2}] \,\cup\,[\tfrac{1}{2},1] \text{ or } [0,\tfrac{1}{3}] \,\cup\, [\tfrac{1}{3},\tfrac{2}{3}] \,\cup\,[\tfrac{2}{3},1] $$ So to calculate $U(f,P)$ for the first set of subintervals: $$U(f,P) = \sum_{i=1}^n M_i (x_i - x_{i-1})$$ $$ = f(\frac{1}{4})(\frac{1}{4} - 0)\;+ f(\frac{1}{2})(\frac{1}{2} - \frac{1}{4})\;+  f(1)(1 - \frac{1}{2})$$ $$ = \frac{1}{8} + \frac{1}{4} + 1= \frac{11}{8}$$ Calculate $L(f,P)$: $$L(f,P) = \sum_{i=1}^n m_i (x_i - x_{i-1})$$ $$ = f(0)(\frac{1}{4} - 0)\;+ f(\frac{1}{4})(\frac{1}{2} - \frac{1}{4})\;+  f(\frac{1}{2})(1 - \frac{1}{2})$$ $$ = 0 + \frac{1}{8} + \frac{1}{2}= \frac{5}{8}$$ First off, can someone confirm that my calculations for upper and lower sums are correct? Secondly, back to the main question, what is the $inf${U($f$,$P$)} and $sup${L($f$,$P$)} in this? as my $U$($f$,$P$) = $\frac{11}{8}$ and $L$($f$,$P$) = $\frac{5}{8}$. As I already know that $f$ is integrable, $U$($f$,$P$) = $L$($f$,$P$) only if $f$ is constant, but what is the set in which I'm supposed to take the $inf$ and $sup$ of? As per the Darboux Integral definition, $sup${$L(f,P)$} = $inf${$U(f,P)$} for this function.  . If someone could clear this up for me it would be greatly appreciated","I'm trying to figure out the Darboux Integral definition as it states:  $f$ is integrable if $inf${U($f$,$P$)} = $sup${L($f$,$P$)}, where U($f$,$P$) is the upper sum, L($f$,$P$) is the lower sum of $f$ and $P$ is a parition of $f$. I'm not understanding what the $sup$/$inf$ of the sums mean. When calculating, they are a finite value (ie. L($f$,$P$) = $\sum_{i=1}^n m_i (x_i - x_{i-1})$) Consider: $$f(x) = 2x, x \in [0,1];~ P = \{0,\frac{1}{4},\frac{1}{2},1\}.$$ Since $P$ has 4 elements, n=3, thus 3 subintervals of $[0,1]$, can you definte these 3 subintervals however you want as long as they range [0,1]? ie. $$[0,\tfrac{1}{4}] \,\cup\, [\tfrac{1}{4},\tfrac{1}{2}] \,\cup\,[\tfrac{1}{2},1] \text{ or } [0,\tfrac{1}{3}] \,\cup\, [\tfrac{1}{3},\tfrac{2}{3}] \,\cup\,[\tfrac{2}{3},1] $$ So to calculate $U(f,P)$ for the first set of subintervals: $$U(f,P) = \sum_{i=1}^n M_i (x_i - x_{i-1})$$ $$ = f(\frac{1}{4})(\frac{1}{4} - 0)\;+ f(\frac{1}{2})(\frac{1}{2} - \frac{1}{4})\;+  f(1)(1 - \frac{1}{2})$$ $$ = \frac{1}{8} + \frac{1}{4} + 1= \frac{11}{8}$$ Calculate $L(f,P)$: $$L(f,P) = \sum_{i=1}^n m_i (x_i - x_{i-1})$$ $$ = f(0)(\frac{1}{4} - 0)\;+ f(\frac{1}{4})(\frac{1}{2} - \frac{1}{4})\;+  f(\frac{1}{2})(1 - \frac{1}{2})$$ $$ = 0 + \frac{1}{8} + \frac{1}{2}= \frac{5}{8}$$ First off, can someone confirm that my calculations for upper and lower sums are correct? Secondly, back to the main question, what is the $inf${U($f$,$P$)} and $sup${L($f$,$P$)} in this? as my $U$($f$,$P$) = $\frac{11}{8}$ and $L$($f$,$P$) = $\frac{5}{8}$. As I already know that $f$ is integrable, $U$($f$,$P$) = $L$($f$,$P$) only if $f$ is constant, but what is the set in which I'm supposed to take the $inf$ and $sup$ of? As per the Darboux Integral definition, $sup${$L(f,P)$} = $inf${$U(f,P)$} for this function.  . If someone could clear this up for me it would be greatly appreciated",,"['calculus', 'integration', 'definite-integrals', 'supremum-and-infimum', 'riemann-integration']"
83,What is up with the antiderivative of $\arctan^2(x)$?,What is up with the antiderivative of ?,\arctan^2(x),"Integrating $\arctan^2(x)$ has been a mystery to me since I first learned to compute indefinite integrals. When I plug it into integral calculator or WolframAlpha, I get a primitive written in terms of complex numbers and polylogarythms; but $\arctan^2(x)$ is continuous and defined $\forall\space x\in\mathbb{R}$, the area under the curve $(x,\arctan^2(x))$ is well-defined and obvioulsy real. In fact, I can integrate that function numerically and get the area without using Barrow's Rule at all. I thought maybe the complex part of that expression is constant, therefore applying Barrow's Rule always yields a real number anyway, but then I could subtract a constant equal to its imaginary part times $i$ and get a real and still valid antiderivative. Anyway, I have no idea of how to compute that antiderivative in the first place, so I can't check for myself. Can a real, continuous function have a complex primitive but not a real primitive? And, can anyone give me a hint to help me compute its antiderivative by myself?","Integrating $\arctan^2(x)$ has been a mystery to me since I first learned to compute indefinite integrals. When I plug it into integral calculator or WolframAlpha, I get a primitive written in terms of complex numbers and polylogarythms; but $\arctan^2(x)$ is continuous and defined $\forall\space x\in\mathbb{R}$, the area under the curve $(x,\arctan^2(x))$ is well-defined and obvioulsy real. In fact, I can integrate that function numerically and get the area without using Barrow's Rule at all. I thought maybe the complex part of that expression is constant, therefore applying Barrow's Rule always yields a real number anyway, but then I could subtract a constant equal to its imaginary part times $i$ and get a real and still valid antiderivative. Anyway, I have no idea of how to compute that antiderivative in the first place, so I can't check for myself. Can a real, continuous function have a complex primitive but not a real primitive? And, can anyone give me a hint to help me compute its antiderivative by myself?",,"['calculus', 'integration', 'indefinite-integrals']"
84,Surface optimization for a volume,Surface optimization for a volume,,"One of my children received this homework and we are a bit disoriented by the way the questions are asked (more than the calculation actually). This is exactly the wording and layout of the homework: Consider an aluminum can: for example, a Coke can. Do such cans have   the right dimensions? What does ""right"" mean? Why do other products   come packed in containers of other shapes? Question: An ordinary can has a volume of 355 cm3. What shape will hold this volume of liquid using the least amount of aluminum (minimising   surface area)? Demonstrate your conclusion by comparing 2 different shapes in addition to a cylinder. Consider defining suitable variables and stating any and all assumptions you make. Use differentiation to find the value of your variable that minimizes the volume of metal used to make the container. Is there   another method you can use to justify your model? Are real containers this shape? Why or why not? Discuss which model best fits the actual container, giving reasons for any differences, if they exist. You are then informed that the circular top and bottom of your drink   can has thichtess 0.2mm but that the curved surface has thiclvtess   0.Imm. Nist Inc. would like to launch a new sized can that has a capacity of 200 ml. Using your model, find the dimensions of the can that would   minimize the volume of metal used to make the can. Do you think that Nist Inc. would use these dimensions? Why or why not? First, keep in mind that they have only seen derivatives so far (no integrals yet). Second, please understand that we are not native English speakers so decoding the sentences is part of the problem. Finding the optimal height and radius of the cylinder is quite trivial: Find the constraint equation (volume in terms of height) Find the optimizing equation (surface Area). Plug the height of the volume equation into the optimizing equation Derive that equation and make it equal to zero Solve it for the radius and plug the radius found in the height equation. The answer will provide you the ideal height and radius to optimize the surface area of the cylinder. So far so good, it seems that the actual cans are more or less optimal if simplified as pure cylinders (but the homework seems to consider there is another ""model"" that could be used. I went and check on the internet with no success. This model seems the obvious one). Now, does it have the ""right dimensions""? ""what does right mean""? and ""why do other products come packed in containers of other shapes""?  It seems to be anything but pure math questions and it seems to be dependent on how you see things (storage, drinking convenience,..). As I'm sure I'm wrong, I can't possibly understand what answers are expected here. Maybe I'm missing the point to make it all clear, at once. The ""right"" dimensions? For a soda can, it's pretty close to the ideal measures yes but is it the expected answer? No clue. ""What does right mean""? Well... I don't know what this question is really asking. In terms of Maths? In terms of storage issues? In terms of practicality? In terms of costs? ""why do other products come packed in containers of other shapes"" Same here? Cubes are easier to store I guess? Flat tops and bottoms allow a more convenient way to stack things? But I'm pretty sure I just don't get it. Moreover, this is an intro text and a series of questions are coming just after. I just don't know if these questions in the intro text are rhetorical or if they are already meant to be answered. Which would be strange as there is no constraining data yet. Now come the actual questions: ""What shape will hold this volume of liquid using the least amount of aluminum (minimising surface area)?"" That would be a sphere, with no doubt. But how to prove it in a trivial and absolute way? It's seems intense. ""Demonstrate your conclusion by comparing 2 different shapes in addition to a cylinder"". How a non comprehensive comparison would demonstrate anything? Here too, I don't get it. I could make the calculation for a cube and then a cylinder and then a sphere to show that it would decrease the surface area for a given volume but that wouldn't be a proof of anything, would it? All I would be able to say is that ""it seems"" that the more we go towards a shape with an infinite amount of sides (perfect curvature), the more we will optimize the surface area. But that doesn't demonstrate anything, especially if we just take 2 other shapes to get to that conclusion. ""Is there another method you can use to justify your model?"" Besides using the derivative to find the optimal height and radius? I can't seem to find another. Are we talking about the sphere model or the cylinder model now? ""Are real containers this shape? Why or why not?"" Sphere or cylinder? What shape are we talking about now? ""Discuss which model best fits the actual container, giving reasons for any differences, if they exist."" Which model is there that is obvious, besides the derivative? It feels like the questions are not specific enough. ""Do you think that Nist Inc. would use these dimensions? Why or why not?"" Here too, I'm lost. I can calculate the dimensions just fine but it seems that I have to go through the same reasoning than all the questions above...which are already confusing. My question is somewhere between a math question and an understanding question. But if I go and ask on another forum dedicated to English, they might be unhelpful because of the math aspect of that homework. So, all in all, it seems to be the best place to ask the question. I'm sure I just miss the point of that homework which makes all the questions quite obscure to me. Maybe some hint will help deblocking the situation at once. I feel like I'm missing something obvious. That's what I'm asking for. I'm probably sure this post will make some people laugh and make a clown out of me but be assured that the language barrier doesn't help. Thanks in advance.","One of my children received this homework and we are a bit disoriented by the way the questions are asked (more than the calculation actually). This is exactly the wording and layout of the homework: Consider an aluminum can: for example, a Coke can. Do such cans have   the right dimensions? What does ""right"" mean? Why do other products   come packed in containers of other shapes? Question: An ordinary can has a volume of 355 cm3. What shape will hold this volume of liquid using the least amount of aluminum (minimising   surface area)? Demonstrate your conclusion by comparing 2 different shapes in addition to a cylinder. Consider defining suitable variables and stating any and all assumptions you make. Use differentiation to find the value of your variable that minimizes the volume of metal used to make the container. Is there   another method you can use to justify your model? Are real containers this shape? Why or why not? Discuss which model best fits the actual container, giving reasons for any differences, if they exist. You are then informed that the circular top and bottom of your drink   can has thichtess 0.2mm but that the curved surface has thiclvtess   0.Imm. Nist Inc. would like to launch a new sized can that has a capacity of 200 ml. Using your model, find the dimensions of the can that would   minimize the volume of metal used to make the can. Do you think that Nist Inc. would use these dimensions? Why or why not? First, keep in mind that they have only seen derivatives so far (no integrals yet). Second, please understand that we are not native English speakers so decoding the sentences is part of the problem. Finding the optimal height and radius of the cylinder is quite trivial: Find the constraint equation (volume in terms of height) Find the optimizing equation (surface Area). Plug the height of the volume equation into the optimizing equation Derive that equation and make it equal to zero Solve it for the radius and plug the radius found in the height equation. The answer will provide you the ideal height and radius to optimize the surface area of the cylinder. So far so good, it seems that the actual cans are more or less optimal if simplified as pure cylinders (but the homework seems to consider there is another ""model"" that could be used. I went and check on the internet with no success. This model seems the obvious one). Now, does it have the ""right dimensions""? ""what does right mean""? and ""why do other products come packed in containers of other shapes""?  It seems to be anything but pure math questions and it seems to be dependent on how you see things (storage, drinking convenience,..). As I'm sure I'm wrong, I can't possibly understand what answers are expected here. Maybe I'm missing the point to make it all clear, at once. The ""right"" dimensions? For a soda can, it's pretty close to the ideal measures yes but is it the expected answer? No clue. ""What does right mean""? Well... I don't know what this question is really asking. In terms of Maths? In terms of storage issues? In terms of practicality? In terms of costs? ""why do other products come packed in containers of other shapes"" Same here? Cubes are easier to store I guess? Flat tops and bottoms allow a more convenient way to stack things? But I'm pretty sure I just don't get it. Moreover, this is an intro text and a series of questions are coming just after. I just don't know if these questions in the intro text are rhetorical or if they are already meant to be answered. Which would be strange as there is no constraining data yet. Now come the actual questions: ""What shape will hold this volume of liquid using the least amount of aluminum (minimising surface area)?"" That would be a sphere, with no doubt. But how to prove it in a trivial and absolute way? It's seems intense. ""Demonstrate your conclusion by comparing 2 different shapes in addition to a cylinder"". How a non comprehensive comparison would demonstrate anything? Here too, I don't get it. I could make the calculation for a cube and then a cylinder and then a sphere to show that it would decrease the surface area for a given volume but that wouldn't be a proof of anything, would it? All I would be able to say is that ""it seems"" that the more we go towards a shape with an infinite amount of sides (perfect curvature), the more we will optimize the surface area. But that doesn't demonstrate anything, especially if we just take 2 other shapes to get to that conclusion. ""Is there another method you can use to justify your model?"" Besides using the derivative to find the optimal height and radius? I can't seem to find another. Are we talking about the sphere model or the cylinder model now? ""Are real containers this shape? Why or why not?"" Sphere or cylinder? What shape are we talking about now? ""Discuss which model best fits the actual container, giving reasons for any differences, if they exist."" Which model is there that is obvious, besides the derivative? It feels like the questions are not specific enough. ""Do you think that Nist Inc. would use these dimensions? Why or why not?"" Here too, I'm lost. I can calculate the dimensions just fine but it seems that I have to go through the same reasoning than all the questions above...which are already confusing. My question is somewhere between a math question and an understanding question. But if I go and ask on another forum dedicated to English, they might be unhelpful because of the math aspect of that homework. So, all in all, it seems to be the best place to ask the question. I'm sure I just miss the point of that homework which makes all the questions quite obscure to me. Maybe some hint will help deblocking the situation at once. I feel like I'm missing something obvious. That's what I'm asking for. I'm probably sure this post will make some people laugh and make a clown out of me but be assured that the language barrier doesn't help. Thanks in advance.",,"['calculus', 'optimization', 'area', 'volume', 'spheres']"
85,Unsolved Elementary Integrals,Unsolved Elementary Integrals,,"I am currently in Integral Calculus, and I wondered if I could get a little creative with my practice. I was curious if there were any unsolved, but rather simple (solvable using methods taught in calc I/II), so that I could be practicing the integration tehniques I have learned while also solving a problem that hasn't been solved yet. I have consulted lists of integrals, but those are in a more general form (constants are represented by letters, etc.), and I was wondering if there was a place I could find lists of indefinite integrals that had never been calculated but weren't that difficult. Also, on a side note, if you happen to know any good resources for reading about more techniques of integration, I am currently looking to expand my ""toolbox"" of integration methods. Thank you all, and I hope each and every one of you is having a nice day.","I am currently in Integral Calculus, and I wondered if I could get a little creative with my practice. I was curious if there were any unsolved, but rather simple (solvable using methods taught in calc I/II), so that I could be practicing the integration tehniques I have learned while also solving a problem that hasn't been solved yet. I have consulted lists of integrals, but those are in a more general form (constants are represented by letters, etc.), and I was wondering if there was a place I could find lists of indefinite integrals that had never been calculated but weren't that difficult. Also, on a side note, if you happen to know any good resources for reading about more techniques of integration, I am currently looking to expand my ""toolbox"" of integration methods. Thank you all, and I hope each and every one of you is having a nice day.",,"['calculus', 'integration', 'soft-question']"
86,How prove $\cos 20^{\circ}$ is not rational?,How prove  is not rational?,\cos 20^{\circ},"How prove $\cos 20^{\circ}$ is not rational ? I tried something to make a proof .Let me show you my work . $$\cos 60^{\circ}=4\cos ^320^{\circ}-3\cos 20 ^{\circ}\\ \frac{1}{2}=4\cos ^320^{\circ}-3\cos 20 ^{\circ}\\\cos 20^{\circ}=x\\8x^3-6x-1=0$$ possible rational roots are $\in\{\pm 1,\pm \frac{1}2,\pm \frac 14,\pm\frac18\}$ but no one of them work in the equation ,so the equation has no rational root(s) ,hence $x \in \mathbb{Q^c}$ Is my trial true  ? Is there other idea(s) to show $\cos 20^{\circ}$ is not rational ?","How prove $\cos 20^{\circ}$ is not rational ? I tried something to make a proof .Let me show you my work . $$\cos 60^{\circ}=4\cos ^320^{\circ}-3\cos 20 ^{\circ}\\ \frac{1}{2}=4\cos ^320^{\circ}-3\cos 20 ^{\circ}\\\cos 20^{\circ}=x\\8x^3-6x-1=0$$ possible rational roots are $\in\{\pm 1,\pm \frac{1}2,\pm \frac 14,\pm\frac18\}$ but no one of them work in the equation ,so the equation has no rational root(s) ,hence $x \in \mathbb{Q^c}$ Is my trial true  ? Is there other idea(s) to show $\cos 20^{\circ}$ is not rational ?",,"['calculus', 'trigonometry', 'proof-verification', 'alternative-proof']"
87,Evaluate $\int_{x=0}^{2 \pi}\frac{dx}{(1+a \cos{x})^{b^2}}$,Evaluate,\int_{x=0}^{2 \pi}\frac{dx}{(1+a \cos{x})^{b^2}},"Evaluate:   $$\int_{0}^{2 \pi}\frac{dx}{(l^2+r^2+2 l r \cos{x})^{b^2}}$$   where $b^2$ is a real number, $r>0$, and $l \geq 0$. I can just simplify it to  $$c\int_{0}^{2 \pi}\frac{dx}{(1+a \cos{x})^{b^2}}$$ where $a>0$. Any ideas? simplifications? results?","Evaluate:   $$\int_{0}^{2 \pi}\frac{dx}{(l^2+r^2+2 l r \cos{x})^{b^2}}$$   where $b^2$ is a real number, $r>0$, and $l \geq 0$. I can just simplify it to  $$c\int_{0}^{2 \pi}\frac{dx}{(1+a \cos{x})^{b^2}}$$ where $a>0$. Any ideas? simplifications? results?",,"['calculus', 'integration', 'trigonometry', 'definite-integrals', 'trigonometric-integrals']"
88,How does one show that : $\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)^n\mathrm dx=f(n)?$,How does one show that :,\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)^n\mathrm dx=f(n)?,"Consider $$\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)^n\mathrm dx=f(n)\tag1$$   $n\ge0$ Using wolfram integrator, it gives us a closed form for $f(n)$, we managed to identify a pattern as shown below. setting $n=1,2,3,4$ and $5$ We notices the closed from has a pattern that involved binomial coefficents. $$\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)\mathrm dx=2!-1!\cdot{\pi\over 2}$$ $$\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)^2\mathrm dx=4!-3!\cdot{\pi\over 2}-1!\cdot{3\pi^2\over 4}$$ $$\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)^3\mathrm dx=6!-5!\cdot{3\pi\over 2}-4!\cdot{3\pi^2\over 4}+3!\cdot{\pi^3\over 8}$$ $$\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)^4\mathrm dx=8!-7!\cdot{4\pi\over 2}-6!\cdot{6\pi^2\over 4}+5!\cdot{4\pi^3\over 8}+4!\cdot{\pi^4\over 16}$$ $$\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)^5\mathrm dx=10!-9!\cdot{5\pi\over 2}-8!\cdot{10\pi^2\over 4}+7!\cdot{10\pi^3\over 8}+6!\cdot{5\pi^4\over 16}- 5!\cdot{\pi^5\over 32}$$ $$f(6)=12!-11!\cdot{6\pi\over 2}-10!\cdot{15\pi^2\over 4}+9!\cdot{20\pi^3\over 8}+8!\cdot{15\pi^4\over 16}- 7!\cdot{\pi^5\over 32}-6!\cdot{\pi^6\over 64}$$ We generalised $$f(n)=\sum_{k=0}^{n}(-1)^{\lceil {k/2}\rceil}(2n-k)!{n\choose k}\cdot{\pi^k\over2^k}\tag2$$ How does one prove (2)? An attempt: $I$ becomes $$\int_{0}^{1}\left[{\pi\over 2}\cos^{-1}x-(\cos^{-1}x)^2\right]^n\mathrm dx\tag3$$ probably using the binomial theorem to expand and integrate term by term, I guess I am stuck at this point, no sure what to do","Consider $$\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)^n\mathrm dx=f(n)\tag1$$   $n\ge0$ Using wolfram integrator, it gives us a closed form for $f(n)$, we managed to identify a pattern as shown below. setting $n=1,2,3,4$ and $5$ We notices the closed from has a pattern that involved binomial coefficents. $$\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)\mathrm dx=2!-1!\cdot{\pi\over 2}$$ $$\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)^2\mathrm dx=4!-3!\cdot{\pi\over 2}-1!\cdot{3\pi^2\over 4}$$ $$\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)^3\mathrm dx=6!-5!\cdot{3\pi\over 2}-4!\cdot{3\pi^2\over 4}+3!\cdot{\pi^3\over 8}$$ $$\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)^4\mathrm dx=8!-7!\cdot{4\pi\over 2}-6!\cdot{6\pi^2\over 4}+5!\cdot{4\pi^3\over 8}+4!\cdot{\pi^4\over 16}$$ $$\int_{0}^{1}(\sin^{-1}x \cos^{-1}x)^5\mathrm dx=10!-9!\cdot{5\pi\over 2}-8!\cdot{10\pi^2\over 4}+7!\cdot{10\pi^3\over 8}+6!\cdot{5\pi^4\over 16}- 5!\cdot{\pi^5\over 32}$$ $$f(6)=12!-11!\cdot{6\pi\over 2}-10!\cdot{15\pi^2\over 4}+9!\cdot{20\pi^3\over 8}+8!\cdot{15\pi^4\over 16}- 7!\cdot{\pi^5\over 32}-6!\cdot{\pi^6\over 64}$$ We generalised $$f(n)=\sum_{k=0}^{n}(-1)^{\lceil {k/2}\rceil}(2n-k)!{n\choose k}\cdot{\pi^k\over2^k}\tag2$$ How does one prove (2)? An attempt: $I$ becomes $$\int_{0}^{1}\left[{\pi\over 2}\cos^{-1}x-(\cos^{-1}x)^2\right]^n\mathrm dx\tag3$$ probably using the binomial theorem to expand and integrate term by term, I guess I am stuck at this point, no sure what to do",,"['calculus', 'integration', 'sequences-and-series', 'definite-integrals', 'binomial-coefficients']"
89,What is the meaning of a differential in terms of an exact differential?,What is the meaning of a differential in terms of an exact differential?,,"As I understand it a differential is an outdated concept from the time of Liebniz which was used to define derivatives and integrals before limits came along. As such $dy$ or $dx$ don't really have any meaning on their own. I have seen in multiple places that the idea of thinking of a derivative as a ratio of two infinitesimal change while intuitive is wrong. I understand this, and besides I am not even really sure if there is a rigorous way of saying when a quantity is infinitesimal. Now on the other hand, it have read that you can define these differentials as actual quantities that are approximations in the change of a function. For example for a function of one real variable the differential is the function $df$ of two independent real variables $x$ and $Δx$ given by: $df(x,Δx)=f'(x)Δx$ How this then reduces to $df = f'(x)dx$ and again what $dx$ means I dont understand. It seems to me that it is simply a linear approximation for the function at a point $x$. However there's no mention of how large or small $dx$ must be, it seems to be just as ill defined as before and I have still found other places referring to it as an infinitesimal even when it has been redefined as here. Anyway ignoring this, I can see how this could then be extended to functions of more than one independent variable $y = f(x_1,....,x_n)$ $dy = $$\frac{df}{dx_1}dx_1\ +\ .... \ +\frac{df}{dx_n}dx_n\ $ However then the notion of exact and inexact differentials are brought up. This seems like its unrelated but that raise the question of what a differential means in this case. All this comes from a course I am taking in Thermal Physics. ] 2 If anyone can enlighten me as to what the concept of differentials means or perhaps direct me towards a book or website where I can study it myself I would be very grateful. An explanation of Schwarz' Theorem in this context would be great too.","As I understand it a differential is an outdated concept from the time of Liebniz which was used to define derivatives and integrals before limits came along. As such $dy$ or $dx$ don't really have any meaning on their own. I have seen in multiple places that the idea of thinking of a derivative as a ratio of two infinitesimal change while intuitive is wrong. I understand this, and besides I am not even really sure if there is a rigorous way of saying when a quantity is infinitesimal. Now on the other hand, it have read that you can define these differentials as actual quantities that are approximations in the change of a function. For example for a function of one real variable the differential is the function $df$ of two independent real variables $x$ and $Δx$ given by: $df(x,Δx)=f'(x)Δx$ How this then reduces to $df = f'(x)dx$ and again what $dx$ means I dont understand. It seems to me that it is simply a linear approximation for the function at a point $x$. However there's no mention of how large or small $dx$ must be, it seems to be just as ill defined as before and I have still found other places referring to it as an infinitesimal even when it has been redefined as here. Anyway ignoring this, I can see how this could then be extended to functions of more than one independent variable $y = f(x_1,....,x_n)$ $dy = $$\frac{df}{dx_1}dx_1\ +\ .... \ +\frac{df}{dx_n}dx_n\ $ However then the notion of exact and inexact differentials are brought up. This seems like its unrelated but that raise the question of what a differential means in this case. All this comes from a course I am taking in Thermal Physics. ] 2 If anyone can enlighten me as to what the concept of differentials means or perhaps direct me towards a book or website where I can study it myself I would be very grateful. An explanation of Schwarz' Theorem in this context would be great too.",,"['calculus', 'multivariable-calculus', 'linear-approximation']"
90,Does the converse of the chain rule hold in general?,Does the converse of the chain rule hold in general?,,"I've found the following theorem for single variable real valued functions: The converse of the chain rule: Suppose that $f,g$ and $u$ are related so that $f(x)=g(u(x))$. If $u$ is continuous at $x_0$, $f'(x_0)$ exists and $g'(u(x_0))$ exists and is non-zero; then $u'(x_0)$ is defined and we have: $$f'(x_0)=g'(u(x_0))u'(x_0)$$ I'm interested in knowing if this ""other converse"" also holds: Suppose that $f,g$ and $u$ are related so that $f(x)=g(u(x))$. If $g$ is continuous at $u(x_0)$, $f'(x_0)$ exists and $u'(x_0)$ exists and is non-zero; then $g'(u(x_0))$ is defined and we have: $$f'(x_0)=g'(u(x_0))u'(x_0)$$ If anyone is interested here is the proof of the first one (page 12), I tryed to proved the second one in an analogous way but I didn't succeed. For my immediate purposes I would be happy with knowing it holds, and in case it doesn't some counterexample could be instructive. I'm also interested in knowing if those statements generalises in the obvious way to functions from $\mathbb{R}^n$ to $\mathbb{R}^m$. Thanks in advance","I've found the following theorem for single variable real valued functions: The converse of the chain rule: Suppose that $f,g$ and $u$ are related so that $f(x)=g(u(x))$. If $u$ is continuous at $x_0$, $f'(x_0)$ exists and $g'(u(x_0))$ exists and is non-zero; then $u'(x_0)$ is defined and we have: $$f'(x_0)=g'(u(x_0))u'(x_0)$$ I'm interested in knowing if this ""other converse"" also holds: Suppose that $f,g$ and $u$ are related so that $f(x)=g(u(x))$. If $g$ is continuous at $u(x_0)$, $f'(x_0)$ exists and $u'(x_0)$ exists and is non-zero; then $g'(u(x_0))$ is defined and we have: $$f'(x_0)=g'(u(x_0))u'(x_0)$$ If anyone is interested here is the proof of the first one (page 12), I tryed to proved the second one in an analogous way but I didn't succeed. For my immediate purposes I would be happy with knowing it holds, and in case it doesn't some counterexample could be instructive. I'm also interested in knowing if those statements generalises in the obvious way to functions from $\mathbb{R}^n$ to $\mathbb{R}^m$. Thanks in advance",,"['calculus', 'multivariable-calculus', 'chain-rule']"
91,Is there a closed-form for $\frac{d^ny}{dx^n}$?,Is there a closed-form for ?,\frac{d^ny}{dx^n},"I am dealing with this... #Question# Given $y$ is a function of $x$ , $x^n+y^n=1$ , where $n$ is a positive integer. Find $\displaystyle\frac{d^ny}{dx^n}$ in terms of $x$ , $y$ and $n$ . ###Example 1### For example, when $n=1$ , $x+y=1$ then $\displaystyle\frac{dy}{dx}=-1$ . ###Example 2### When $n=3$ , $x^3+y^3=1$ then $\displaystyle\frac{d^3y}{dx^3}=-\left(\frac{10x^6}{y^8}+\frac{12x^3}{y^5}+\frac{2}{y^2}\right)$ . ###Example 3### When $n=6$ , $x^6+y^6=1$ then $\displaystyle\frac{d^6y}{dx^6}=-\left(\frac{623645x^{30}}{y^{35}}+\frac{1612875x^{24}}{y^{29}}+\frac{1425875x^{18}}{y^{23}}+\frac{482625x^{12}}{y^{17}}+\frac{46100x^6}{y^{11}}+\frac{120}{y^5} \right)$ . ##Table of values## Below is a triangular array of values for the coefficient: \begin{array}{|c|c|c|c|} \hline n \backslash k& 1 & 2 & 3 & 4 & 5 & 6 &.\\ \hline 1 & 1\\ \hline 2 & 1 & 1&\\ \hline 3 &  10& 12&2&\\ \hline 4 & 231&378&153&6 &\\ \hline 5 & 9576&20160&12960&2400 & 24&\\ \hline 6 & 623645&1612875 & 1425875&482625&46100&120&\\ \hline. \end{array} Denote $a_{n,k}$ (where $k$ is a positive integer $\le n$ ) as the number in the $n$ -th row and the $k$ -th column. (e.g. $a_{3,2}=12$ ) Therefore, \begin{align} \displaystyle \frac{d^ny}{dx^n}=-\sum_{k=1}^n a_{n,k}\left(\frac{x^{n^2-kn}}{y^{n^2-kn+n-1}}\right).\end{align} I found that \begin{align}\boxed{\textbf{E1:} \quad \displaystyle \sum_{k \rm \ is \ odd} a_{n,k} =\sum_{k \rm \ is\  even} a_{n,k} \  \text{for}\  n>1\ \ \ },\end{align} (i.e. $a_{n,1}+a_{n,3}+a_{n,5}+...=a_{n,2}+a_{n,4}+a_{n,6}+...$ ) and \begin{align}\boxed{\textbf{E2:}\qquad \qquad \qquad  a_{n,n}=(n-1)! \qquad \quad \ }\end{align} related to the factorial. E1 and E2 are the two equalities I have discoverd. Moreover , \begin{align}\boxed{ \  a_{n,k}\  \text{is divisible by}\ (n-1) \text{.}\qquad \text{(i.e.}\ \  (n-1)|a_{n.k}\  \text{)}\  }\end{align} Someone has mentioned the generalized binomial theorem which can reduce $\displaystyle \frac{d^ny}{dx^n}$ to > \begin{align} \displaystyle \frac{d^ny}{dx^n}=\sum_{k=1}^{\infty} \binom{1/n}{k}  \frac{(kn)!}{\left(\left(k-1\right) n\right) !} x^{(k-1)n}\end{align} by rewriting $y=\left(1-x^n\right)^{1/n}$ for $|x|<1$ . It could be the answer, but now I'm more interested in finding the closed-form for $a_{n,k}$ . Is there a closed-form for $\displaystyle\frac{d^ny}{dx^n}$ (in terms of $a_{n,k}$ )? ###OR### Is there a closed-form for $a_{n,k}$ ?","I am dealing with this... #Question# Given is a function of , , where is a positive integer. Find in terms of , and . ###Example 1### For example, when , then . ###Example 2### When , then . ###Example 3### When , then . ##Table of values## Below is a triangular array of values for the coefficient: Denote (where is a positive integer ) as the number in the -th row and the -th column. (e.g. ) Therefore, I found that (i.e. ) and related to the factorial. E1 and E2 are the two equalities I have discoverd. Moreover , Someone has mentioned the generalized binomial theorem which can reduce to > by rewriting for . It could be the answer, but now I'm more interested in finding the closed-form for . Is there a closed-form for (in terms of )? ###OR### Is there a closed-form for ?","y x x^n+y^n=1 n \displaystyle\frac{d^ny}{dx^n} x y n n=1 x+y=1 \displaystyle\frac{dy}{dx}=-1 n=3 x^3+y^3=1 \displaystyle\frac{d^3y}{dx^3}=-\left(\frac{10x^6}{y^8}+\frac{12x^3}{y^5}+\frac{2}{y^2}\right) n=6 x^6+y^6=1 \displaystyle\frac{d^6y}{dx^6}=-\left(\frac{623645x^{30}}{y^{35}}+\frac{1612875x^{24}}{y^{29}}+\frac{1425875x^{18}}{y^{23}}+\frac{482625x^{12}}{y^{17}}+\frac{46100x^6}{y^{11}}+\frac{120}{y^5} \right) \begin{array}{|c|c|c|c|}
\hline
n \backslash k& 1 & 2 & 3 & 4 & 5 & 6 &.\\ \hline
1 & 1\\ \hline
2 & 1 & 1&\\ \hline
3 &  10& 12&2&\\ \hline
4 & 231&378&153&6 &\\ \hline
5 & 9576&20160&12960&2400 & 24&\\ \hline
6 & 623645&1612875 & 1425875&482625&46100&120&\\ \hline.
\end{array} a_{n,k} k \le n n k a_{3,2}=12 \begin{align} \displaystyle \frac{d^ny}{dx^n}=-\sum_{k=1}^n a_{n,k}\left(\frac{x^{n^2-kn}}{y^{n^2-kn+n-1}}\right).\end{align} \begin{align}\boxed{\textbf{E1:} \quad \displaystyle \sum_{k \rm \ is \ odd} a_{n,k} =\sum_{k \rm \ is\  even} a_{n,k} \  \text{for}\  n>1\ \ \ },\end{align} a_{n,1}+a_{n,3}+a_{n,5}+...=a_{n,2}+a_{n,4}+a_{n,6}+... \begin{align}\boxed{\textbf{E2:}\qquad \qquad \qquad  a_{n,n}=(n-1)! \qquad \quad \ }\end{align} \begin{align}\boxed{ \  a_{n,k}\  \text{is divisible by}\ (n-1) \text{.}\qquad \text{(i.e.}\ \  (n-1)|a_{n.k}\  \text{)}\  }\end{align} \displaystyle \frac{d^ny}{dx^n} \begin{align} \displaystyle \frac{d^ny}{dx^n}=\sum_{k=1}^{\infty} \binom{1/n}{k}  \frac{(kn)!}{\left(\left(k-1\right) n\right) !} x^{(k-1)n}\end{align} y=\left(1-x^n\right)^{1/n} |x|<1 a_{n,k} \displaystyle\frac{d^ny}{dx^n} a_{n,k} a_{n,k}","['calculus', 'functions', 'derivatives', 'closed-form', 'implicit-differentiation']"
92,Are telescoping sums related to the fundamental theorem of calculus?,Are telescoping sums related to the fundamental theorem of calculus?,,I just noticed that $$\sum_{i=1}^n (a_i - a_{i-1})=a_n-a_0$$ and $$\int_a^b f'(x)\mathrm{d}x=f(b)-f(a)$$ look really similar. We can consider $a_i-a_{i-1}$ a discrete analog to the derivative of continuous functions. Is there anything deep between those equations?,I just noticed that $$\sum_{i=1}^n (a_i - a_{i-1})=a_n-a_0$$ and $$\int_a^b f'(x)\mathrm{d}x=f(b)-f(a)$$ look really similar. We can consider $a_i-a_{i-1}$ a discrete analog to the derivative of continuous functions. Is there anything deep between those equations?,,"['calculus', 'algebra-precalculus']"
93,"$f(x)=\sin x$, $f$ polynomial",",  polynomial",f(x)=\sin x f,"$f$ is a polynomial and suppose that $f(x)=\sin x$ has infinitely many solutions. Prove that $f$ is a constant between -1 and 1. I get the problem intuitively, but how would I prove this formally? Can anyone give me any hints?","$f$ is a polynomial and suppose that $f(x)=\sin x$ has infinitely many solutions. Prove that $f$ is a constant between -1 and 1. I get the problem intuitively, but how would I prove this formally? Can anyone give me any hints?",,['calculus']
94,Solving the roots of Redlich Kwong Equation,Solving the roots of Redlich Kwong Equation,,"Good evening everyone. After studying some equations of state, I've read about the mathematical steps formulated to model some. In the particular case of Van der Waals, where $$P=\frac{RT}{v-b}-\frac{a}{v^2}$$ For those not familiar with this expression, this equation describes general characteristics of a real gas, P standing for pressure, R for the universal gas constant, T for temperature, v for molar volume (Yep, I know the little line is missing, sorry!), and a and b are characteristic constants for the gas . There are some special values for Temperature, Pressure and Molar volume. Finding them, apparently, helps me in my quest for a and b. I am told the following steps to do so in VdW equation: 1) Derive the function twice. 2) Solve RT for each derivative and make them equal to zero.Make an equation of of the derivative and the second derivative, then solve for v 3) Plug the value of V in the first derivative, and solve for T, now called critical temperature. 3 4) Plug the values of V and T in the original function, thus obtaining the critical pressure. 4 5) Solve ""a"" for critical T and critical P, then making the equation and obtaining ""b""[5] 6) Plug ""b"" in critical T, now obtaining ""a""[6] Now, back to my problem, I'm looking for ""a"" and ""b"" again, but now in the Redlich Kwong equation: $$P=\frac{RT}{v-b}-\frac{a}{\sqrt(T)*(v^2+vb)}$$ I've already derived the function twice and solved for RT: $$P'=\frac{-RT}{(v-b)^2}+\frac{a(2v+b)}{\sqrt(T)*((v^2+vb)^-2)}=0$$ $$RT=\frac{a(2v+b)*((v-b)^2}{\sqrt(T)*((v^2+vb)^-2)}$$ $$P''=\frac{2RT}{(v-b)^-3}+\frac{2a}{\sqrt(T)*((v^2+vb)^-2)}-\frac{2a*(2v+b)^2}{\sqrt(T)*((v^2+vb)^-3)}=0$$ $$RT=\frac{a}{\sqrt(T)}*((v-b)^3)*(\frac{(2v+b)^2}{((v^2)+vb)^3}-\frac{1}{(v^2)+vb)^2})$$ After putting the two =0, I've obtained this far: $$3v+2b=(v-b)*((2v+b)^2)((v^2)+vb)$$ As it isn't as simple as in the VdW case, I certainly don't know where to go now in order to obtain a value of v based on b. I would be so grateful if someone checked this, thank you!","Good evening everyone. After studying some equations of state, I've read about the mathematical steps formulated to model some. In the particular case of Van der Waals, where $$P=\frac{RT}{v-b}-\frac{a}{v^2}$$ For those not familiar with this expression, this equation describes general characteristics of a real gas, P standing for pressure, R for the universal gas constant, T for temperature, v for molar volume (Yep, I know the little line is missing, sorry!), and a and b are characteristic constants for the gas . There are some special values for Temperature, Pressure and Molar volume. Finding them, apparently, helps me in my quest for a and b. I am told the following steps to do so in VdW equation: 1) Derive the function twice. 2) Solve RT for each derivative and make them equal to zero.Make an equation of of the derivative and the second derivative, then solve for v 3) Plug the value of V in the first derivative, and solve for T, now called critical temperature. 3 4) Plug the values of V and T in the original function, thus obtaining the critical pressure. 4 5) Solve ""a"" for critical T and critical P, then making the equation and obtaining ""b""[5] 6) Plug ""b"" in critical T, now obtaining ""a""[6] Now, back to my problem, I'm looking for ""a"" and ""b"" again, but now in the Redlich Kwong equation: $$P=\frac{RT}{v-b}-\frac{a}{\sqrt(T)*(v^2+vb)}$$ I've already derived the function twice and solved for RT: $$P'=\frac{-RT}{(v-b)^2}+\frac{a(2v+b)}{\sqrt(T)*((v^2+vb)^-2)}=0$$ $$RT=\frac{a(2v+b)*((v-b)^2}{\sqrt(T)*((v^2+vb)^-2)}$$ $$P''=\frac{2RT}{(v-b)^-3}+\frac{2a}{\sqrt(T)*((v^2+vb)^-2)}-\frac{2a*(2v+b)^2}{\sqrt(T)*((v^2+vb)^-3)}=0$$ $$RT=\frac{a}{\sqrt(T)}*((v-b)^3)*(\frac{(2v+b)^2}{((v^2)+vb)^3}-\frac{1}{(v^2)+vb)^2})$$ After putting the two =0, I've obtained this far: $$3v+2b=(v-b)*((2v+b)^2)((v^2)+vb)$$ As it isn't as simple as in the VdW case, I certainly don't know where to go now in order to obtain a value of v based on b. I would be so grateful if someone checked this, thank you!",,"['calculus', 'algebra-precalculus']"
95,Curl of unit normal vector on a surface is zero?,Curl of unit normal vector on a surface is zero?,,"I have a scalar field $\phi$. From this field, I define an iso-surface $\phi=\phi_{iso}$. The unit normal vector on this surface is $\vec{n}=\left(\frac{\nabla\phi}{|\nabla\phi|}\right)_{\phi_{iso}}$ I have a book, where the author says: For any surface unit normal vector the following is true: $\nabla\times\vec{n}=0$ I found some other sources saying the same: rot(n)=0 (""since rot(n)=0"") curl(n)=0 on page 4 between eq. 20 and 21 Is this true for any surface? Because if I try to prove this myself, I get stuck really quick: $\nabla\times\vec{n}=\nabla\times\left(\frac{\nabla\phi}{|\nabla\phi|}\right)= \nabla\left(\frac{1}{|\nabla\phi|}\right)\times\nabla\phi+\frac{1}{|\nabla\phi|}\underbrace{\nabla\times\nabla\phi}_{=0}=\frac{1}{|\nabla\phi|^2}\nabla(|\nabla\phi|)\times\nabla\phi$ I can't see why this is supposed to be zero, since $|\nabla\phi|\ne\text{const}$ generally. Does anyone have an idea?","I have a scalar field $\phi$. From this field, I define an iso-surface $\phi=\phi_{iso}$. The unit normal vector on this surface is $\vec{n}=\left(\frac{\nabla\phi}{|\nabla\phi|}\right)_{\phi_{iso}}$ I have a book, where the author says: For any surface unit normal vector the following is true: $\nabla\times\vec{n}=0$ I found some other sources saying the same: rot(n)=0 (""since rot(n)=0"") curl(n)=0 on page 4 between eq. 20 and 21 Is this true for any surface? Because if I try to prove this myself, I get stuck really quick: $\nabla\times\vec{n}=\nabla\times\left(\frac{\nabla\phi}{|\nabla\phi|}\right)= \nabla\left(\frac{1}{|\nabla\phi|}\right)\times\nabla\phi+\frac{1}{|\nabla\phi|}\underbrace{\nabla\times\nabla\phi}_{=0}=\frac{1}{|\nabla\phi|^2}\nabla(|\nabla\phi|)\times\nabla\phi$ I can't see why this is supposed to be zero, since $|\nabla\phi|\ne\text{const}$ generally. Does anyone have an idea?",,"['calculus', 'differential-geometry', 'surfaces']"
96,Evaluate $\space\lim\limits_{n\to\infty}\sqrt{n}\int\limits_{-\infty}^{+\infty}\frac{\cos t}{\left(1+t^2\right)^n}dt$,Evaluate,\space\lim\limits_{n\to\infty}\sqrt{n}\int\limits_{-\infty}^{+\infty}\frac{\cos t}{\left(1+t^2\right)^n}dt,Find the limit $$ \large \space\lim\limits_{n\to\infty}\sqrt{n}\int\limits_{-\infty}^{+\infty}\frac{\cos t}{\left(1+t^2\right)^n}dt $$,Find the limit $$ \large \space\lim\limits_{n\to\infty}\sqrt{n}\int\limits_{-\infty}^{+\infty}\frac{\cos t}{\left(1+t^2\right)^n}dt $$,,['calculus']
97,Volumes + Surface Areas of Sphere with Calculus: Paradox?,Volumes + Surface Areas of Sphere with Calculus: Paradox?,,"I have an interesting observation, what appears to be an apparant contradiction. We calculate volume of sphere, we get it as $$\int_{-R}^R \pi (\sqrt{R^2-y^2})^2 dy$$ because we see it as, circular cylinder with height dy. We calculate surface area of sphere, we get it as $$\int_{-R}^R 2*\pi \sqrt{R^2-y^2} dy$$ because we see it as, circular cylinder outside with height dy. First integral, well I guess it is right. $\frac{4}{3} \pi R^3$. No problem there. But then, you look the second integral, you get, $\pi^2 R^2$! What is discrepancy here, and what is wrong.","I have an interesting observation, what appears to be an apparant contradiction. We calculate volume of sphere, we get it as $$\int_{-R}^R \pi (\sqrt{R^2-y^2})^2 dy$$ because we see it as, circular cylinder with height dy. We calculate surface area of sphere, we get it as $$\int_{-R}^R 2*\pi \sqrt{R^2-y^2} dy$$ because we see it as, circular cylinder outside with height dy. First integral, well I guess it is right. $\frac{4}{3} \pi R^3$. No problem there. But then, you look the second integral, you get, $\pi^2 R^2$! What is discrepancy here, and what is wrong.",,"['calculus', 'volume']"
98,How to compute the $n_{th}$ derivative of a composition: ${\left( {f \circ g} \right)^{(n)}}=?$,How to compute the  derivative of a composition:,n_{th} {\left( {f \circ g} \right)^{(n)}}=?,"I know that there is a general formula to compute the $n_{th}$ derivative of a product which is as follows $${\left( {fg} \right)^{(n)}} = \sum\limits_{k = 0}^n {\left( {\begin{array}{*{20}{c}} n\\ k \end{array}} \right){f^{(n - k)}}{g^{(k)}}}$$ I am wondering that if there exists such a general formula for the $n_{th}$ derivative of a composition. Specifically, how to find a general formula for the following: $${\left( {f \circ g} \right)^{(n)}}=?$$","I know that there is a general formula to compute the $n_{th}$ derivative of a product which is as follows $${\left( {fg} \right)^{(n)}} = \sum\limits_{k = 0}^n {\left( {\begin{array}{*{20}{c}} n\\ k \end{array}} \right){f^{(n - k)}}{g^{(k)}}}$$ I am wondering that if there exists such a general formula for the $n_{th}$ derivative of a composition. Specifically, how to find a general formula for the following: $${\left( {f \circ g} \right)^{(n)}}=?$$",,"['calculus', 'derivatives']"
99,$ \int_{0}^{2} (2x - x^2)^n dx $ recurrence relation,recurrence relation, \int_{0}^{2} (2x - x^2)^n dx ,Given $$ I_n =  \int_{0}^{2} (2x - x^2)^n dx $$ Compute $I_2$ I simply expanded it into $$ \int_0^2 4x^2 - 4x^3 + x^4 dx $$ and computed it. Show that $$ (2n+1)I_n = 2nI_{n-1} $$ I first tried doing integration by parts by writing it as $ \int_0^2 (x)' (2x-x^2)^n dx$ but that led nowhere and I also tried splitting it into $\int_0^2 (2x+x^2)^{n-1} (2x+x^2) dx$ and that didn't work either. How do I do this? Compute $$ \lim_{n \rightarrow \infty} I_n $$,Given $$ I_n =  \int_{0}^{2} (2x - x^2)^n dx $$ Compute $I_2$ I simply expanded it into $$ \int_0^2 4x^2 - 4x^3 + x^4 dx $$ and computed it. Show that $$ (2n+1)I_n = 2nI_{n-1} $$ I first tried doing integration by parts by writing it as $ \int_0^2 (x)' (2x-x^2)^n dx$ but that led nowhere and I also tried splitting it into $\int_0^2 (2x+x^2)^{n-1} (2x+x^2) dx$ and that didn't work either. How do I do this? Compute $$ \lim_{n \rightarrow \infty} I_n $$,,['calculus']
