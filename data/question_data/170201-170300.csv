,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Estimating mean from a biased sample,Estimating mean from a biased sample,,"Imagine that somebody had chosen $N$ numbers from a normal distribution with mean $\mu$ and variance $1$ ( $\mu$ is unknown to you) and only showed you all $n \le N$ numbers which are greater that $\mu$ . Is there a way to find an unbiased estimator of $\mu$ based on the given sample? This does not come from any textbook, I've came up with this problem recently (maybe it's even known but I haven't found anything), so feel free to play with the conditions (for example you may assume that $N$ is known or not or even assume an unknown variance). I found it interesting because in some situations you are presented with only one side of the coin and you somehow have to make a judgement out of the evidence you have. There are obviously some easy estimates (as for example a minimum which seems to be a $MLE$ ) but they are biased. Also I understand that since the mean of folded normal distribution has such a terribly looking formula the estimator might not be that pretty. And also what about other distributions? For example for uniform on $[0,\theta]$ the variable greater than the mean will have expectation $\frac{3}{4}\theta$ so the unbiased estimator will be $\hat{\theta}=\frac{4}{3}\overline{X}$ (or $\frac{2}{3}\overline{X}$ as an estimator for the mean).","Imagine that somebody had chosen numbers from a normal distribution with mean and variance ( is unknown to you) and only showed you all numbers which are greater that . Is there a way to find an unbiased estimator of based on the given sample? This does not come from any textbook, I've came up with this problem recently (maybe it's even known but I haven't found anything), so feel free to play with the conditions (for example you may assume that is known or not or even assume an unknown variance). I found it interesting because in some situations you are presented with only one side of the coin and you somehow have to make a judgement out of the evidence you have. There are obviously some easy estimates (as for example a minimum which seems to be a ) but they are biased. Also I understand that since the mean of folded normal distribution has such a terribly looking formula the estimator might not be that pretty. And also what about other distributions? For example for uniform on the variable greater than the mean will have expectation so the unbiased estimator will be (or as an estimator for the mean).","N \mu 1 \mu n \le N \mu \mu N MLE [0,\theta] \frac{3}{4}\theta \hat{\theta}=\frac{4}{3}\overline{X} \frac{2}{3}\overline{X}","['statistics', 'normal-distribution', 'parameter-estimation']"
1,Find $\lambda $ such that P(X=1)=$\frac{1}{2}$ where X is Poisson($\lambda$),Find  such that P(X=1)= where X is Poisson(),\lambda  \frac{1}{2} \lambda,"Find $\lambda $ such that P(X=1)= $\frac{1}{2}$ where X is Poisson( $\lambda$ ).  Using the formula $P\left(X=x\right)=\frac{\lambda^xe^{-\lambda}}{x!}$ and plugging in 1 for x I was able to simplify it down to $\lambda e^{-\lambda}=\frac{1}{2}$ . I was not too sure about how to solve this equation by hand, so I graphed the function of $\lambda e^{-\lambda}$ and y = $\frac{1}{2}$ , but these graphs never intersect which makes it seem that there is never a time that P(X=1)= $\frac{1}{2}$ because the max of the graph of $\lambda e^{-\lambda}$ is at 0.368. Is this a correct assumption that there is no solution to this problem, if not, how would you solve this equation the proper way?","Find such that P(X=1)= where X is Poisson( ).  Using the formula and plugging in 1 for x I was able to simplify it down to . I was not too sure about how to solve this equation by hand, so I graphed the function of and y = , but these graphs never intersect which makes it seem that there is never a time that P(X=1)= because the max of the graph of is at 0.368. Is this a correct assumption that there is no solution to this problem, if not, how would you solve this equation the proper way?",\lambda  \frac{1}{2} \lambda P\left(X=x\right)=\frac{\lambda^xe^{-\lambda}}{x!} \lambda e^{-\lambda}=\frac{1}{2} \lambda e^{-\lambda} \frac{1}{2} \frac{1}{2} \lambda e^{-\lambda},['statistics']
2,Cannot Find Parameter Estimation using Maximum Likelihood Estimation [duplicate],Cannot Find Parameter Estimation using Maximum Likelihood Estimation [duplicate],,"This question already has an answer here : Maximum likelihood when usual procedure doesn't work (1 answer) Closed 5 years ago . Given probability density function $$p(x|\phi)=\begin{cases}\dfrac{\phi}{x^2}&\phi<x<\infty\\0&\text{others}\end{cases}.$$ I want to find an estimation for the $\phi$ parameter with the maximum likelihood estimator. First, I find the likelihood function as below $$L(\phi)=\dfrac{\phi}{{x_1}^2}\dfrac{\phi}{{x_2}^2}\ldots\dfrac{\phi}{{x_n}^2}=\dfrac{\phi^n}{\prod\limits_{i=1}^n{x_i}^2}.$$ Then I determine the log likelihood $\ln L(\phi)$ , $$\ln L(\phi)=n\ln \phi-2\ln\prod\limits_{i=1}^n{x_i}.$$ Now, I try to find the maximum of the log likelihood, $$\dfrac{d}{d\phi} \ln L(\phi)=\dfrac{n}{\phi}=0.$$ Then I have $n=0$ . Problem : I can't find the $\hat\phi$ . How to find the parameter   estimation of $\phi$ using maximum likelihood estimator? Please help me. Thanks before.","This question already has an answer here : Maximum likelihood when usual procedure doesn't work (1 answer) Closed 5 years ago . Given probability density function I want to find an estimation for the parameter with the maximum likelihood estimator. First, I find the likelihood function as below Then I determine the log likelihood , Now, I try to find the maximum of the log likelihood, Then I have . Problem : I can't find the . How to find the parameter   estimation of using maximum likelihood estimator? Please help me. Thanks before.",p(x|\phi)=\begin{cases}\dfrac{\phi}{x^2}&\phi<x<\infty\\0&\text{others}\end{cases}. \phi L(\phi)=\dfrac{\phi}{{x_1}^2}\dfrac{\phi}{{x_2}^2}\ldots\dfrac{\phi}{{x_n}^2}=\dfrac{\phi^n}{\prod\limits_{i=1}^n{x_i}^2}. \ln L(\phi) \ln L(\phi)=n\ln \phi-2\ln\prod\limits_{i=1}^n{x_i}. \dfrac{d}{d\phi} \ln L(\phi)=\dfrac{n}{\phi}=0. n=0 \hat\phi \phi,"['statistics', 'maximum-likelihood', 'parameter-estimation']"
3,Finding the conditional expectation of independent exponential random variables,Finding the conditional expectation of independent exponential random variables,,"Let $X$ and $Y$ be independent exponential random variables with respective rates $\lambda$ and $\mu$ . Let $M = \text{min}(X,Y)$ . Find (a) $E(MX|M=X)$ (b) $E(MX|M=Y)$ (c) Cov $(X,M)$ (a) I first tried $\displaystyle E(MX|M=X) = E(X^2) = \int_{0}^{\infty} x^2 f(x) dx = \int_{0}^{\infty} x^2 \lambda e^{-\lambda x} \, dx = \frac{2}{\lambda ^2}$ , which does not agree with the textbook answer. I then tried $\displaystyle E(MX|M=X) = E(M^2) = \int_0^\infty m^2 f(m) \,dm $ , where $f(m)$ is the pdf of $M$ which I know from here is equal to $\displaystyle (\lambda + \mu) e^{-(\lambda + \mu)m}$ $$\therefore E(MX|M=X) = \int_{0}^{\infty} m^2 (\lambda + \mu) e^{-(\lambda + \mu)m} dm = \frac{2}{(\lambda+\mu)^2}, $$ which agrees with the textbook answer. Why is my first attempt not correct? \begin{align} \\[15pt] \end{align} (b) On this part I first tried $E(MX|M=Y) = E(XY)$ and using the fact that $$E(g(X,Y)) := \int_{-\infty}^{\infty}\int_{-\infty}^{\infty} g(x,y)f(x,y) \, dxdy \tag{*}$$ to write $$E(MX|M=Y) = E(XY) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} xy f(x,y) dx dy$$ but I was not able to find the joint pdf $f(x,y)$ . Alternatively, I tried $E(MX|M=Y) = E(MY|Y<X)$ , but couldn't figure out where to go from here. My guess is to use the memoryless property of exponentials, but I'm not sure how to apply that. \begin{align} \\[15pt] \end{align} (c) $ \;\text{Cov}(X,M) = E(MX)-E(X)E(M)$ , where $\displaystyle E(X) = \frac{1}{\lambda}$ and $ E(M) = \int_{0}^{\infty} m f(m) dm  = \frac{1}{\lambda + \mu}$ I'm not sure how to calculate $E(MX)$ . If I use equation (*), then I would again be stuck trying to find the joint pdf $f(x,m)$ like in part (b). Using a different approach: $M = \text{min}(X,Y) = \frac{X+Y-|X-Y|}{2}$ so that \begin{align} E(MX) &= E\left(\frac{ X^2 + XY - X(|X-Y|) }{2}\right) \\ &= \frac{1}{2} \left( E(X^2) + E(XY) - E \left( X\sqrt{(X-Y)^2} \right)\right) \\ &= \frac{1}{2} \left( E(X^2) + E(X)E(Y) - \iint_{0}^{\infty} x\sqrt{(x-y)^2} f(x,y) dxdy \right), \end{align} and again I'm stuck.","Let and be independent exponential random variables with respective rates and . Let . Find (a) (b) (c) Cov (a) I first tried , which does not agree with the textbook answer. I then tried , where is the pdf of which I know from here is equal to which agrees with the textbook answer. Why is my first attempt not correct? (b) On this part I first tried and using the fact that to write but I was not able to find the joint pdf . Alternatively, I tried , but couldn't figure out where to go from here. My guess is to use the memoryless property of exponentials, but I'm not sure how to apply that. (c) , where and I'm not sure how to calculate . If I use equation (*), then I would again be stuck trying to find the joint pdf like in part (b). Using a different approach: so that and again I'm stuck.","X Y \lambda \mu M = \text{min}(X,Y) E(MX|M=X) E(MX|M=Y) (X,M) \displaystyle E(MX|M=X) = E(X^2) = \int_{0}^{\infty} x^2 f(x) dx = \int_{0}^{\infty} x^2 \lambda e^{-\lambda x} \, dx = \frac{2}{\lambda ^2} \displaystyle E(MX|M=X) = E(M^2) = \int_0^\infty m^2 f(m) \,dm  f(m) M \displaystyle (\lambda + \mu) e^{-(\lambda + \mu)m} \therefore E(MX|M=X) = \int_{0}^{\infty} m^2 (\lambda + \mu) e^{-(\lambda + \mu)m} dm = \frac{2}{(\lambda+\mu)^2},  \begin{align}
\\[15pt]
\end{align} E(MX|M=Y) = E(XY) E(g(X,Y)) := \int_{-\infty}^{\infty}\int_{-\infty}^{\infty} g(x,y)f(x,y) \, dxdy \tag{*} E(MX|M=Y) = E(XY) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} xy f(x,y) dx dy f(x,y) E(MX|M=Y) = E(MY|Y<X) \begin{align}
\\[15pt]
\end{align}  \;\text{Cov}(X,M) = E(MX)-E(X)E(M) \displaystyle E(X) = \frac{1}{\lambda}  E(M) = \int_{0}^{\infty} m f(m) dm 
= \frac{1}{\lambda + \mu} E(MX) f(x,m) M = \text{min}(X,Y) = \frac{X+Y-|X-Y|}{2} \begin{align}
E(MX) &= E\left(\frac{ X^2 + XY - X(|X-Y|) }{2}\right) \\
&= \frac{1}{2} \left( E(X^2) + E(XY) - E \left( X\sqrt{(X-Y)^2} \right)\right) \\
&= \frac{1}{2} \left( E(X^2) + E(X)E(Y) - \iint_{0}^{\infty} x\sqrt{(x-y)^2} f(x,y) dxdy \right),
\end{align}","['probability-theory', 'statistics', 'probability-distributions', 'random-variables', 'conditional-expectation']"
4,Optimising unrounding using maximum likelihood,Optimising unrounding using maximum likelihood,,"I have a bunch of rounded random independent numbers. I want to replace them with unrounded numbers such that the unrounded numbers are 'most likely' to have been generated by some (continuous) distribution, eg, a lognormal distribution. What should be my objective function?","I have a bunch of rounded random independent numbers. I want to replace them with unrounded numbers such that the unrounded numbers are 'most likely' to have been generated by some (continuous) distribution, eg, a lognormal distribution. What should be my objective function?",,"['statistics', 'maximum-likelihood']"
5,Collisions during random insertion unto given domain,Collisions during random insertion unto given domain,,"Here's a satisfying one. Assume a list of maximum length L which starts out empty. For the first element we pick a random number within the domain [0 ... L ), we check if the list already contains it (it obviously doesn't when the list is empty), and if it's not already present then we populate the first empty element with that random number. If the number is present in the list (which will happen during later iterations) then we count a collision, we choose another random number, we check it again, and we try to populate the same position in the list. We iterate until the list is complete, counting collisions along the way. Counting the number of collisions for each element in the list, and graphing that against the list's occupation level, we end up with the following graph: The x axis represents the list's occupation degree, and the y axis represents the average number of collisions for each attempt to choose a collision-free number. Note that the y axis is logarithmic – an exponential trend line would be represented as a straight line. I find a lot of satisfying things in this graph: the shape of the curve, the symmetry of the y range (10E-3 ... 10E+3), and the fact that the sweet spot where there's one collision per number selection is at roughly 33%. Having said that, everything here is based on my empirical attempts to work out how this works – I averaged multiple iterations of computer-generated simulations to get to this graph. I have tested it with both [0...1000) and [1...10000), and the results were basically identical. I would appreciate a confirmation that my empirical results can be validated using a formal mathematical approach, rather than my naïve computer simulations.","Here's a satisfying one. Assume a list of maximum length L which starts out empty. For the first element we pick a random number within the domain [0 ... L ), we check if the list already contains it (it obviously doesn't when the list is empty), and if it's not already present then we populate the first empty element with that random number. If the number is present in the list (which will happen during later iterations) then we count a collision, we choose another random number, we check it again, and we try to populate the same position in the list. We iterate until the list is complete, counting collisions along the way. Counting the number of collisions for each element in the list, and graphing that against the list's occupation level, we end up with the following graph: The x axis represents the list's occupation degree, and the y axis represents the average number of collisions for each attempt to choose a collision-free number. Note that the y axis is logarithmic – an exponential trend line would be represented as a straight line. I find a lot of satisfying things in this graph: the shape of the curve, the symmetry of the y range (10E-3 ... 10E+3), and the fact that the sweet spot where there's one collision per number selection is at roughly 33%. Having said that, everything here is based on my empirical attempts to work out how this works – I averaged multiple iterations of computer-generated simulations to get to this graph. I have tested it with both [0...1000) and [1...10000), and the results were basically identical. I would appreciate a confirmation that my empirical results can be validated using a formal mathematical approach, rather than my naïve computer simulations.",,['statistics']
6,Find the percentile of random variable X with a normal distribution using standard normal distribution,Find the percentile of random variable X with a normal distribution using standard normal distribution,,"Need help finding the 80th percentile of random variable  X  with a normal distribution with $μ_X = 80, σ_X = 10,$ using standard normal distribution  and also the 90th percentile when $μ_X = 12, σ_X = 1.$ I get that you start off with $x = μ+zσ,$ but then I have no clue where to go with since I don't know what $X$ and $Z$ are.",Need help finding the 80th percentile of random variable  X  with a normal distribution with using standard normal distribution  and also the 90th percentile when I get that you start off with but then I have no clue where to go with since I don't know what and are.,"μ_X = 80, σ_X = 10, μ_X = 12, σ_X = 1. x = μ+zσ, X Z","['probability', 'statistics', 'normal-distribution']"
7,Confidence interval probability,Confidence interval probability,,I am struggling to even understand how to approach this problem Finding the probability of $$P(Z<z_a+z_{1-a})$$ Where Z is a standard normal variable and $$P(Z\leq z_a)=1-a$$ Is there manipulation rules for adding arguments in a normal distribution? How do I even start with this?,I am struggling to even understand how to approach this problem Finding the probability of Where Z is a standard normal variable and Is there manipulation rules for adding arguments in a normal distribution? How do I even start with this?,P(Z<z_a+z_{1-a}) P(Z\leq z_a)=1-a,"['probability', 'probability-theory', 'statistics', 'normal-distribution', 'statistical-inference']"
8,Conditional probability with MLE of Poisson variable,Conditional probability with MLE of Poisson variable,,"I'm having some trouble with this study question and would appreciate any help. This may be a duplicate but I have not been able to find any others. Question: Leaves of plants are examined for bugs. The number of bugs on a leaf follows a Poisson distribution with mean $\mu$ . However, many leaves have no bugs because they are unsuitable for feeding and not simply because of the chance variation allowed by the Poisson law. Therefore the empty leaves are not counted. a) Find the conditional probability that a leaf contains $x$ bugs, given that it contains at least one. b) Let $x_i$ be the number of bugs found on leaf $i$ (after the leaves with zero bugs are ignored). Show that the MLE of $\mu$ satisfies the equation $$\hat{\mu}=\bar{x}(1-e^{-\hat{\mu}}).$$ c) Determine $\hat{\mu}$ numerically for the case $\bar{x}=3.2.$ My attempt: a) If X is the number of bugs on a leaf and Y is the number of observed bugs on a leaf, then the probability is given by \begin{align} P(Y=x)&=P(X=x|X>0) \\ &=\frac{P(X=x)}{P(X>0)} \\ &=\frac{P(X=x)}{P(X>0)} \\ &=\frac{P(X=x)}{1-P(X=0)} \\ &=\frac{P(X=x)}{1-e^{-\mu}} \\ \end{align} b) Having some trouble with this. First I found the regular MLE of $\hat{\mu}$ for Poisson and got $\bar{x}=\hat{\mu}$ , so I'm assuming I need to use $$\frac{\mu}{1-e^{-\mu}}$$ in some way? Is this what my answer to a) is supposed to be? I tried finding the MLE of $\hat{\mu}$ again using this instead of $\mu$ but couldn't get the answer I needed. c) Not sure what to do here...","I'm having some trouble with this study question and would appreciate any help. This may be a duplicate but I have not been able to find any others. Question: Leaves of plants are examined for bugs. The number of bugs on a leaf follows a Poisson distribution with mean . However, many leaves have no bugs because they are unsuitable for feeding and not simply because of the chance variation allowed by the Poisson law. Therefore the empty leaves are not counted. a) Find the conditional probability that a leaf contains bugs, given that it contains at least one. b) Let be the number of bugs found on leaf (after the leaves with zero bugs are ignored). Show that the MLE of satisfies the equation c) Determine numerically for the case My attempt: a) If X is the number of bugs on a leaf and Y is the number of observed bugs on a leaf, then the probability is given by b) Having some trouble with this. First I found the regular MLE of for Poisson and got , so I'm assuming I need to use in some way? Is this what my answer to a) is supposed to be? I tried finding the MLE of again using this instead of but couldn't get the answer I needed. c) Not sure what to do here...","\mu x x_i i \mu \hat{\mu}=\bar{x}(1-e^{-\hat{\mu}}). \hat{\mu} \bar{x}=3.2. \begin{align}
P(Y=x)&=P(X=x|X>0) \\
&=\frac{P(X=x)}{P(X>0)} \\
&=\frac{P(X=x)}{P(X>0)} \\
&=\frac{P(X=x)}{1-P(X=0)} \\
&=\frac{P(X=x)}{1-e^{-\mu}} \\
\end{align} \hat{\mu} \bar{x}=\hat{\mu} \frac{\mu}{1-e^{-\mu}} \hat{\mu} \mu","['probability', 'statistics', 'estimation', 'maximum-likelihood']"
9,Understanding that a hypothesis test does not depend on a certain parameter,Understanding that a hypothesis test does not depend on a certain parameter,,"I have a very big doubt regarding a test not depending on $\theta_1$ . Suppose I have: $$(X_i)_{i=1}^{n}, X_i \stackrel{iid}{\sim} N(\theta, 1), \hbox{ that is } X_i \sim g(x_i, \theta) = (2\pi)^{-1/2} \exp[\frac{-1}{2}(x_i - \theta)^2]$$ The joint distribution is given by $f(x;\theta) = (2\pi)^{-n/2} \exp[\frac{-1}{2}\sum_{i = 1}^{n}(x_i - \theta)^2] $ Suppose I have the following hypothesis test with $0<\theta_1$ , where $\theta_1$ is fixed but arbitrary (remark: always positive) $$H_0: \theta = 0\quad \hbox{vs}\quad H_1: \theta = \theta_1$$ By Neyman–Pearson theorem, there is some $k>0$ such that $$\phi(x) = \left\{   \begin{array}{lr}     1 & : f(x;0)k  < f(x;\theta_1)  \\     0 & : f(x;0)k  > f(x;\theta_1)   \end{array} \right.$$ is a UMP test in the class of tests with size $\alpha = E_0[\phi(X)]$ . $$\hbox{I want to understand why this test does not depend on }\theta_1?$$ $remark:$ $\theta_1$ is positive and fixed but arbitrary. That is, I want to understand if I want to change the parameter $\theta_1$ , I will still get the same test exactly. Notice that: $$k < \frac{f(x;\theta_1)}{f(x;0)} \Longleftrightarrow \ln(k) < \frac{n}{2}(2 \theta_1 \bar{x} - \theta_1^{2}) $$ In addition, we can see that \begin{equation} \label{eq1} \begin{split} k < \frac{f(x;\theta_1)}{f(x;0)} & \Longleftrightarrow  \frac{\ln(k)}{n} < \frac{1}{2}(2 \theta_1 \bar{x} - \theta_1^{2}) = \theta_1\bar{x} - \frac{\theta_1^{2}}{2} \\  & \Longleftrightarrow \frac{\ln(k)}{n} + \frac{\theta_1^{2}}{2} < \theta_1\bar{x}\\ & \stackrel{\theta_1 > 0}{\Longleftrightarrow } \frac{\ln(k)}{n\theta_1} + \frac{\theta_1}{2} < \bar{x}\\ &\Longleftrightarrow \sqrt{n}\left[\frac{\ln(k)}{n\theta_1} + \frac{\theta_1}{2}\right] < \sqrt{n}\bar{x}\\ & \Longleftrightarrow \tilde{k}(\theta_1) < \sqrt{n}\bar{x} \end{split} \end{equation} Then $\phi(x) = \left\{   \begin{array}{lr}     1 & : \tilde{k}(\theta_1) < \sqrt{n}\bar{x}  \\     0 & : \tilde{k}(\theta_1) > \sqrt{n}\bar{x}   \end{array} \right.$ , with $\alpha = E_0[\phi(X)]$ . Notice that $Z = \sqrt{n} \bar{X} \sim N(0,1)$ . So, to determine the test well, we have to determine the constant $\tilde{k}(\theta_1)$ . We will determine the constant $\tilde{k}(\theta_1)$ forcing the test to be of size $\alpha$ . Under the null hypothesis, we have: \begin{equation}  \begin{split} \alpha = E_{0}[\phi(X)] & \Longleftrightarrow  P_{0}[\tilde{k}(\theta_1) < Z] = \alpha \\  & \Longleftrightarrow P_{0}[Z \leq \tilde{k}(\theta_1) ] = 1 -\alpha \\ & \Longleftrightarrow F_Z (\tilde{k}(\theta_1)| \theta = 0) = 1 -\alpha\\ & \Longleftrightarrow \tilde{k}(\theta_1) = F_{Z}^{-1} ( 1- \alpha| \theta = 0) \end{split} \end{equation} And here is my problem, because the $\tilde{k}(\theta_1)$ depends on the parameter $\theta_1$ . For example, suppose $\alpha = 0.01$ , we have $$\tilde{k}(\theta_1) = \sqrt{n}\left[\frac{\ln(k)}{n\theta_1} + \frac{\theta_1}{2}\right] = 2.33$$ In other words, if a take some other $\theta_1^{'}>0$ , we have other $\tilde{k}(\theta_1^{'})$ . And consequently, I will have another test $\phi^{'}(x) = \left\{   \begin{array}{lr}     1 & : \tilde{k}(\theta_1^{'}) < \sqrt{n}\bar{x}  \\     0 & : \tilde{k}(\theta_1^{'}) > \sqrt{n}\bar{x}   \end{array} \right.$ For this purpose, can I adjust the $\tilde{k}(\theta_1)$ by resizing the sample $n$ ? that is, if I want the $\tilde{k}(\theta_1)$ not to depend on the parameter $\theta_1$ , I should just change $n$ ? but this does not seem to make much sense. Why am I asking this? because in other problems, I really need to vary the parameter $\theta_1 > 0$ and ensure that the test does not depend on $\theta_1$ . For example: $$H_0: \theta \leq 0\quad \hbox{vs}\quad H_1: \theta > 0.$$","I have a very big doubt regarding a test not depending on . Suppose I have: The joint distribution is given by Suppose I have the following hypothesis test with , where is fixed but arbitrary (remark: always positive) By Neyman–Pearson theorem, there is some such that is a UMP test in the class of tests with size . is positive and fixed but arbitrary. That is, I want to understand if I want to change the parameter , I will still get the same test exactly. Notice that: In addition, we can see that Then , with . Notice that . So, to determine the test well, we have to determine the constant . We will determine the constant forcing the test to be of size . Under the null hypothesis, we have: And here is my problem, because the depends on the parameter . For example, suppose , we have In other words, if a take some other , we have other . And consequently, I will have another test For this purpose, can I adjust the by resizing the sample ? that is, if I want the not to depend on the parameter , I should just change ? but this does not seem to make much sense. Why am I asking this? because in other problems, I really need to vary the parameter and ensure that the test does not depend on . For example:","\theta_1 (X_i)_{i=1}^{n}, X_i \stackrel{iid}{\sim} N(\theta, 1), \hbox{ that is } X_i \sim g(x_i, \theta) = (2\pi)^{-1/2} \exp[\frac{-1}{2}(x_i - \theta)^2] f(x;\theta) = (2\pi)^{-n/2} \exp[\frac{-1}{2}\sum_{i = 1}^{n}(x_i - \theta)^2]  0<\theta_1 \theta_1 H_0: \theta = 0\quad \hbox{vs}\quad H_1: \theta = \theta_1 k>0 \phi(x) = \left\{
  \begin{array}{lr}
    1 & : f(x;0)k  < f(x;\theta_1)  \\
    0 & : f(x;0)k  > f(x;\theta_1)
  \end{array}
\right. \alpha = E_0[\phi(X)] \hbox{I want to understand why this test does not depend on }\theta_1? remark: \theta_1 \theta_1 k < \frac{f(x;\theta_1)}{f(x;0)} \Longleftrightarrow \ln(k) < \frac{n}{2}(2 \theta_1 \bar{x} - \theta_1^{2})  \begin{equation} \label{eq1}
\begin{split}
k < \frac{f(x;\theta_1)}{f(x;0)} & \Longleftrightarrow  \frac{\ln(k)}{n} < \frac{1}{2}(2 \theta_1 \bar{x} - \theta_1^{2}) = \theta_1\bar{x} - \frac{\theta_1^{2}}{2} \\
 & \Longleftrightarrow \frac{\ln(k)}{n} + \frac{\theta_1^{2}}{2} < \theta_1\bar{x}\\
& \stackrel{\theta_1 > 0}{\Longleftrightarrow } \frac{\ln(k)}{n\theta_1} + \frac{\theta_1}{2} < \bar{x}\\
&\Longleftrightarrow \sqrt{n}\left[\frac{\ln(k)}{n\theta_1} + \frac{\theta_1}{2}\right] < \sqrt{n}\bar{x}\\
& \Longleftrightarrow \tilde{k}(\theta_1) < \sqrt{n}\bar{x}
\end{split}
\end{equation} \phi(x) = \left\{
  \begin{array}{lr}
    1 & : \tilde{k}(\theta_1) < \sqrt{n}\bar{x}  \\
    0 & : \tilde{k}(\theta_1) > \sqrt{n}\bar{x}
  \end{array}
\right. \alpha = E_0[\phi(X)] Z = \sqrt{n} \bar{X} \sim N(0,1) \tilde{k}(\theta_1) \tilde{k}(\theta_1) \alpha \begin{equation} 
\begin{split}
\alpha = E_{0}[\phi(X)] & \Longleftrightarrow  P_{0}[\tilde{k}(\theta_1) < Z] = \alpha \\
 & \Longleftrightarrow P_{0}[Z \leq \tilde{k}(\theta_1) ] = 1 -\alpha \\
& \Longleftrightarrow F_Z (\tilde{k}(\theta_1)| \theta = 0) = 1 -\alpha\\
& \Longleftrightarrow \tilde{k}(\theta_1) = F_{Z}^{-1} ( 1- \alpha| \theta = 0)
\end{split}
\end{equation} \tilde{k}(\theta_1) \theta_1 \alpha = 0.01 \tilde{k}(\theta_1) = \sqrt{n}\left[\frac{\ln(k)}{n\theta_1} + \frac{\theta_1}{2}\right] = 2.33 \theta_1^{'}>0 \tilde{k}(\theta_1^{'}) \phi^{'}(x) = \left\{
  \begin{array}{lr}
    1 & : \tilde{k}(\theta_1^{'}) < \sqrt{n}\bar{x}  \\
    0 & : \tilde{k}(\theta_1^{'}) > \sqrt{n}\bar{x}
  \end{array}
\right. \tilde{k}(\theta_1) n \tilde{k}(\theta_1) \theta_1 n \theta_1 > 0 \theta_1 H_0: \theta \leq 0\quad \hbox{vs}\quad H_1: \theta > 0.","['statistics', 'hypothesis-testing']"
10,Do the boundary points matter when defining the PDF of a continuous RV?,Do the boundary points matter when defining the PDF of a continuous RV?,,"Lets say we are given the following definition of a CDF $F(x)$ . $$   F(x)=\begin{cases}        0,     && x        &\lt        &\sqrt{2} \\        x^2-2, && \sqrt{2} &\leq x \lt &\sqrt{3} \\        1,     && \sqrt{3} &\leq x        \end{cases} $$ Does it even matter whether we define the respective PDF $f(x)$ as $$   f(x)=\begin{cases}        2x,     && x \in [\sqrt{2}, \sqrt{3}] \\        0,      && \text {otherwise}        \end{cases} $$ versus the following $$   f(x)=\begin{cases}        2x,     && x \in [\sqrt{2}, \sqrt{3}) \\        0,      && \text {otherwise}        \end{cases} $$ Basically I am asking whether or not the brackets matter. Or are they all the same, and I can just play around with any combination I want $[] = () = [) = \ ...$ ?","Lets say we are given the following definition of a CDF . Does it even matter whether we define the respective PDF as versus the following Basically I am asking whether or not the brackets matter. Or are they all the same, and I can just play around with any combination I want ?","F(x) 
  F(x)=\begin{cases}
       0,     && x        &\lt        &\sqrt{2} \\
       x^2-2, && \sqrt{2} &\leq x \lt &\sqrt{3} \\
       1,     && \sqrt{3} &\leq x
       \end{cases}
 f(x) 
  f(x)=\begin{cases}
       2x,     && x \in [\sqrt{2}, \sqrt{3}] \\
       0,      && \text {otherwise}
       \end{cases}
 
  f(x)=\begin{cases}
       2x,     && x \in [\sqrt{2}, \sqrt{3}) \\
       0,      && \text {otherwise}
       \end{cases}
 [] = () = [) = \ ...","['probability', 'statistics', 'notation']"
11,Method for scoring a test in which participants may be able to give more answers than there are questions?,Method for scoring a test in which participants may be able to give more answers than there are questions?,,"I'm currently performing a study in which participants are being asked to listen to a continuous, changing musical tone and to answer when they detect a change and what they think that change correlates to (based off of prior training). The problem is that it's possible for them to answer more times than there are included changes in the sound clip. Is there an established method for scoring a test like this? Example: There are 20 changes in the tone and the participant selects that 24 changes happened, but they got 14/20 of them correct. I was arbitrarily thinking that their score should be #correct/20 if they provide 20 or less answers, but if they provide more than 20 answers, I was thinking it should be #correct/(20 + extra answers). Does this have any basis in research or should they be scored in a different manner?","I'm currently performing a study in which participants are being asked to listen to a continuous, changing musical tone and to answer when they detect a change and what they think that change correlates to (based off of prior training). The problem is that it's possible for them to answer more times than there are included changes in the sound clip. Is there an established method for scoring a test like this? Example: There are 20 changes in the tone and the participant selects that 24 changes happened, but they got 14/20 of them correct. I was arbitrarily thinking that their score should be #correct/20 if they provide 20 or less answers, but if they provide more than 20 answers, I was thinking it should be #correct/(20 + extra answers). Does this have any basis in research or should they be scored in a different manner?",,"['statistics', 'research', 'scoring-algorithm']"
12,If $X_1 + X_2 = z$ what is $E[X_1]$?,If  what is ?,X_1 + X_2 = z E[X_1],"With all variables iid, according to the following question the answer is $\frac{X_1 + X_2}{2}$ . However when I perform the following manipulations I get a different answer: $$E\big[X_1 | X_1 + X_2 = z\big] = \\ E\big[X_1|X_1 = z - X_2\big] = \\ E\big[z -X_2\big] = \\ z - E\big[X_2\big] $$ which is not the same thing. This also leads to some odd behavior, such as the expected value of the first of two dice when their sum is $2$ . The manipulations above suggest it would be negative.","With all variables iid, according to the following question the answer is . However when I perform the following manipulations I get a different answer: which is not the same thing. This also leads to some odd behavior, such as the expected value of the first of two dice when their sum is . The manipulations above suggest it would be negative.","\frac{X_1 + X_2}{2} E\big[X_1 | X_1 + X_2 = z\big] = \\ E\big[X_1|X_1 = z - X_2\big] =
\\ E\big[z -X_2\big] = \\
z - E\big[X_2\big]
 2","['probability', 'statistics']"
13,Degrees of freedom of the set of positive definitive matrices,Degrees of freedom of the set of positive definitive matrices,,"If I am not wrong, the set of definite positive matrices with real coefficients is a convex cone without the vertex, which is the null matrix. What is the number of degrees of freedom for this set of matrices? Please apologize me for not being formal. I will try to explain better my question. In statistics, a positive definite matrix has a special meaning, since it is a variance-covariance matrix. In statistical inference, we want to have a number of samples that it is at least equal to the number of degrees of freedom of the parameter space. Suppose to have a set of observation from a multivariate normal model $N(\mathbf{0}, \mathbf{V})$ , and that you want to do inference on $\mathbf{V}$ . You need a number of samples at least equal to the number of degrees of freedom for the matrix $\mathbf{V}$ . So, my question, how many degrees of freedom has the matrix $\mathbf{V}$ ? How to formalize this concept? Is ""number degrees of freedom"" a synonym for ""dimension of a manifold"" or something similar? Thank you for the clarification.","If I am not wrong, the set of definite positive matrices with real coefficients is a convex cone without the vertex, which is the null matrix. What is the number of degrees of freedom for this set of matrices? Please apologize me for not being formal. I will try to explain better my question. In statistics, a positive definite matrix has a special meaning, since it is a variance-covariance matrix. In statistical inference, we want to have a number of samples that it is at least equal to the number of degrees of freedom of the parameter space. Suppose to have a set of observation from a multivariate normal model , and that you want to do inference on . You need a number of samples at least equal to the number of degrees of freedom for the matrix . So, my question, how many degrees of freedom has the matrix ? How to formalize this concept? Is ""number degrees of freedom"" a synonym for ""dimension of a manifold"" or something similar? Thank you for the clarification.","N(\mathbf{0}, \mathbf{V}) \mathbf{V} \mathbf{V} \mathbf{V}","['statistics', 'positive-definite']"
14,$ES_X(p)$ of a Lognormal,of a Lognormal,ES_X(p),"I have been trying to find the expected shortfall for $X \sim Lognormal(\mu, \sigma^2)$ .  I have calculated the following; $$ ES_X(p)=\frac{1}{p}\exp\left(\mu+\frac{\sigma^2}{2}\right)\left[1-\Phi\left(\Phi^{-1}(1-p)-\sigma\right)\right] $$ However, when comparing my result to those I have found online it appears as though the expected shortfall is: $$ ES_X(\alpha)=\frac{1}{\alpha}\exp\left(\mu+\frac{\sigma^2}{2}\right)\left[\Phi\left(\Phi^{-1}(\alpha)-\sigma\right)\right], $$ where (I am fairly certain) $1-\alpha=p$ .  To me it appears as though these two answers are different, and if that is indeed the case does anyone happen to know where I went wrong in my calculations. I can't seem to figure out why these two answers do not correspond.  For the record, the formula I am using is; $$ ES_X(p)=\frac{E\left[X\mathbb{I}_{X>VaR_X(p)}\right]}{P(X>VaR_X(p))}=\frac{1}{p}\int\limits_{VaR_X(p)}^\infty xf(x;\mu,\sigma^2)dx $$ where $f(x;\mu,\sigma^2)$ is the probability density function of a Lognormal distribution.","I have been trying to find the expected shortfall for .  I have calculated the following; However, when comparing my result to those I have found online it appears as though the expected shortfall is: where (I am fairly certain) .  To me it appears as though these two answers are different, and if that is indeed the case does anyone happen to know where I went wrong in my calculations. I can't seem to figure out why these two answers do not correspond.  For the record, the formula I am using is; where is the probability density function of a Lognormal distribution.","X \sim Lognormal(\mu, \sigma^2) 
ES_X(p)=\frac{1}{p}\exp\left(\mu+\frac{\sigma^2}{2}\right)\left[1-\Phi\left(\Phi^{-1}(1-p)-\sigma\right)\right]
 
ES_X(\alpha)=\frac{1}{\alpha}\exp\left(\mu+\frac{\sigma^2}{2}\right)\left[\Phi\left(\Phi^{-1}(\alpha)-\sigma\right)\right],
 1-\alpha=p 
ES_X(p)=\frac{E\left[X\mathbb{I}_{X>VaR_X(p)}\right]}{P(X>VaR_X(p))}=\frac{1}{p}\int\limits_{VaR_X(p)}^\infty xf(x;\mu,\sigma^2)dx
 f(x;\mu,\sigma^2)","['statistics', 'actuarial-science', 'risk-assessment']"
15,Log det of covariance and entropy,Log det of covariance and entropy,,"I understand log of determinant of covariance matrix bounds entropy for gaussian distributed data. Is this the case for non gaussian data as well and if so, why? What does Determinant of Covariance Matrix give? and http://web.ntpu.edu.tw/~phwang/teaching/2012s/IT/slides/chap08.pdf show connection between 'differential entropy' and log of determinant of covariance matrix for Gaussian case. Eqn. 26 of https://arxiv.org/pdf/1604.03924.pdf?fbclid=IwAR1tDOzgZ2iXSo3lDbXnr8TUkxawCA8NikHFlfY4E5OWmbmJ3_WHeVPotFE has some relations (I guess for non-Gaussian case, but yet to check that)","I understand log of determinant of covariance matrix bounds entropy for gaussian distributed data. Is this the case for non gaussian data as well and if so, why? What does Determinant of Covariance Matrix give? and http://web.ntpu.edu.tw/~phwang/teaching/2012s/IT/slides/chap08.pdf show connection between 'differential entropy' and log of determinant of covariance matrix for Gaussian case. Eqn. 26 of https://arxiv.org/pdf/1604.03924.pdf?fbclid=IwAR1tDOzgZ2iXSo3lDbXnr8TUkxawCA8NikHFlfY4E5OWmbmJ3_WHeVPotFE has some relations (I guess for non-Gaussian case, but yet to check that)",,"['statistics', 'information-theory', 'covariance', 'entropy', 'upper-lower-bounds']"
16,"How does the formula of the correlation coefficient measures ""linear"" relationship?","How does the formula of the correlation coefficient measures ""linear"" relationship?",,"We do know that Pearson's correlation correlation coefficient measures the strength of the relationship (how much correlated) between two random variables , but then, what about $\textbf{linearity}$ , how does this very formula : $$r = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2\sum_{i=1}^{n}(y_i - \bar{y})^2}}$$ measures specifically a $\textbf{linear}$ relationship ? Is there an intuitive way to look at it that would explain why does it quantify a linear relationship ?","We do know that Pearson's correlation correlation coefficient measures the strength of the relationship (how much correlated) between two random variables , but then, what about , how does this very formula : measures specifically a relationship ? Is there an intuitive way to look at it that would explain why does it quantify a linear relationship ?",\textbf{linearity} r = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2\sum_{i=1}^{n}(y_i - \bar{y})^2}} \textbf{linear},"['probability', 'statistics']"
17,Find the probability that among seven persons no two were born on the same day of the week,Find the probability that among seven persons no two were born on the same day of the week,,"I Was initially thinking P(born on Monday) = 1/7 and P(Not Born on Monday) = 6/7 and then 1/7 * 6/7 = 6/42, but I don't know if that's the correct approach? In addition what is P(at least 2 were born on same day)  and P(two were born on a Saturday and 2 born on Tuesday) ?","I Was initially thinking P(born on Monday) = 1/7 and P(Not Born on Monday) = 6/7 and then 1/7 * 6/7 = 6/42, but I don't know if that's the correct approach? In addition what is P(at least 2 were born on same day)  and P(two were born on a Saturday and 2 born on Tuesday) ?",,"['probability', 'statistics']"
18,Definition: what is the difference between generating a random variable versus generating a random number?,Definition: what is the difference between generating a random variable versus generating a random number?,,"Can someone clarify to me the difference between: generating a random variable (according to a certain distribution) versus generating a random number (according to a certain distribution)? I am thoroughly confused by this concept, because my goal is simply to generate a set of data points according to a certain distribution, and every single reference out there is about generating random variables according to a certain distribution. Mathematically speaking, A random variable is a function. A random number is a scalar. Totally different thing. For example, this pdf ( http://opim.wharton.upenn.edu/~sok/papers/s/rv.pdf ) is titled ""Generating a random variable"" and starts an example with ""the most widely used method of generating pseudo-random numbers are the congruential generator"". But the notation for generating the pseudo-random number follows the convention of random variables. In this reference, it talks about generating random variables with the rejection-sampling method. http://www.columbia.edu/~ks20/4703-Sigman/4703-07-Notes-ARM.pdf But I thought this method was used for generating random numbers (which is the end-goal for everyone)? What is the distinction between these two concepts?","Can someone clarify to me the difference between: generating a random variable (according to a certain distribution) versus generating a random number (according to a certain distribution)? I am thoroughly confused by this concept, because my goal is simply to generate a set of data points according to a certain distribution, and every single reference out there is about generating random variables according to a certain distribution. Mathematically speaking, A random variable is a function. A random number is a scalar. Totally different thing. For example, this pdf ( http://opim.wharton.upenn.edu/~sok/papers/s/rv.pdf ) is titled ""Generating a random variable"" and starts an example with ""the most widely used method of generating pseudo-random numbers are the congruential generator"". But the notation for generating the pseudo-random number follows the convention of random variables. In this reference, it talks about generating random variables with the rejection-sampling method. http://www.columbia.edu/~ks20/4703-Sigman/4703-07-Notes-ARM.pdf But I thought this method was used for generating random numbers (which is the end-goal for everyone)? What is the distinction between these two concepts?",,"['probability', 'statistics', 'definition', 'statistical-inference', 'mathematical-modeling']"
19,How can I calculate the probability of two independent events with only the union and the intersection?,How can I calculate the probability of two independent events with only the union and the intersection?,,"Suppose two events A and B are two independent events with $P(A) > P(B)$ and $P(A ∪ B) = 0.626$ and $P(A ∩ B) = 0.144$ , determine the values of P(A) and P(B). So far I have: $$P(A ∩ B) = P(A) + P(B) - P(A U B)$$ $$0.144 = P(A) + P(B) - 0.626$$","Suppose two events A and B are two independent events with and and , determine the values of P(A) and P(B). So far I have:",P(A) > P(B) P(A ∪ B) = 0.626 P(A ∩ B) = 0.144 P(A ∩ B) = P(A) + P(B) - P(A U B) 0.144 = P(A) + P(B) - 0.626,"['probability', 'statistics']"
20,Investigate the significance level $α = 0.01$.,Investigate the significance level .,α = 0.01,"If you throw a coin in a vending machine, the coin is being weighed by the machine to determine its value. For statistical purposes, you decide to throw $4$ fifty-cent coins in this machine and let $\overline{X}_4$ be the estimator for the mean weight $μ$ of a fifty-cent coin. Assume that a single measurement has a normal distribution with expectation $μ$ and variance $σ^2 = 0.04$ . You find out that $\overline{x}_4 = 7.54$ . Investigate by using a statistical test whether $μ$ equals $7.5$ at significance level $α = 0.01$ . Solve: I assume $H_0:\mu=7.5$ and $H_1:\mu\neq7.5$ So it is a two-tailed problem and I have an $\alpha=0.005$ on the right and the same on the left. So from the table the critical values for these $\alpha$ are 2.57 and -2.57. So I can compute $Z=\frac{7.48-7.5}{\frac{\sqrt{0.004}}{\sqrt{4}}}=-0.63$ that is inside the region where we don't reject $H_0$ so we don't reject it. Is it correct? Can someone please help me? Or I should use the p-value?","If you throw a coin in a vending machine, the coin is being weighed by the machine to determine its value. For statistical purposes, you decide to throw fifty-cent coins in this machine and let be the estimator for the mean weight of a fifty-cent coin. Assume that a single measurement has a normal distribution with expectation and variance . You find out that . Investigate by using a statistical test whether equals at significance level . Solve: I assume and So it is a two-tailed problem and I have an on the right and the same on the left. So from the table the critical values for these are 2.57 and -2.57. So I can compute that is inside the region where we don't reject so we don't reject it. Is it correct? Can someone please help me? Or I should use the p-value?",4 \overline{X}_4 μ μ σ^2 = 0.04 \overline{x}_4 = 7.54 μ 7.5 α = 0.01 H_0:\mu=7.5 H_1:\mu\neq7.5 \alpha=0.005 \alpha Z=\frac{7.48-7.5}{\frac{\sqrt{0.004}}{\sqrt{4}}}=-0.63 H_0,"['probability', 'statistics']"
21,What makes statistical distributions so unique?,What makes statistical distributions so unique?,,"I am going to start this question with a definition. Definition:  If $Z\sim \mathcal{N}(0,1)$ and $U \sim \chi_{n}^2$ , and $Z$ and $U$ are independent, then the distribution of $$\frac{Z}{\sqrt{\frac{U}{n}}}$$ is called the $t$ distribution with $n$ degrees of freedom. My question , which may sound strange, is, why is this so special?  Why can't anyone just come up with a distribution which is some combination of other random variables and name it after themselves?","I am going to start this question with a definition. Definition:  If and , and and are independent, then the distribution of is called the distribution with degrees of freedom. My question , which may sound strange, is, why is this so special?  Why can't anyone just come up with a distribution which is some combination of other random variables and name it after themselves?","Z\sim \mathcal{N}(0,1) U \sim \chi_{n}^2 Z U \frac{Z}{\sqrt{\frac{U}{n}}} t n",['statistics']
22,"Coefficient of determination, why?","Coefficient of determination, why?",,"I mean it is written in a book ""Statistics for Management and Economics"", that coefficient of determination is coefficient of correlation squared. Well, am I the only one to whom this is surprising fact as he expected something more clear or natural?? I mean, if someone can present me the proof why, or why some other, more natural things do not work, like I don't know, absolute value of the coefficient of correlation or something similar to Chebyshev theorem ( $1-\text{coefficient of correlation}$ )?","I mean it is written in a book ""Statistics for Management and Economics"", that coefficient of determination is coefficient of correlation squared. Well, am I the only one to whom this is surprising fact as he expected something more clear or natural?? I mean, if someone can present me the proof why, or why some other, more natural things do not work, like I don't know, absolute value of the coefficient of correlation or something similar to Chebyshev theorem ( )?",1-\text{coefficient of correlation},['statistics']
23,"Zero conditional mean, and is regression estimating population regression function?","Zero conditional mean, and is regression estimating population regression function?",,"I am relearning econometrics to get a better understanding of it, and to clear the confusions when I had in college. Using the simple regression model, we have a population model equation as: $$ y = \beta_{0} + \beta_{1}x + u\tag{1}$$ In the SLR assumption 3, we have the zero conditional mean assumption . Are we assuming this statement because in reality, y can take many values given x taking a single value, so that we hope, given x, the expected value of y is center around E[y|x], is this understanding of SLR Assumption 3 correct ? This means, if we take the expected value of equation (1) conditioned on x: $$ E[y|x] = \beta_{0} + \beta_{1}x + E[u|x]\tag{2}$$ Because any deviation can be absorbed by the intercept item, we lose nothing by assuming E[u] = 0. By assuming SLR 3 E[u|x] = E[u] = 0, we are implying that: $$ E[u|x] =\sum{}u P_{u|x}(u) = \sum{}u\dfrac{P_{u,x}(u,x)}{P_{x}(x)}=\sum{}u\dfrac{P_{u}(u)P_{x}(x)}{P_{x}(x)} = \sum{}uP_{u}(u) = E[u]\tag{3}$$ In order to get the above equation, we are implying that x and u are independent of each other, so we are also implying that from the covariance formula of x and u, we can get the following equation E[ux] = E[u] = 0: $$ Cov(u, x) = E[ux] - E[u]E[x] = E[ux] - 0 = E[u]E[x] = 0 \tag{4}$$ Thus: $$ E[ux] = 0 \tag{5}$$ And, because of this implied uncorrelated relationship between u and x, the equation (2) above can be viewed as when E[u|x] = 0, so we have the population regression function by taking expectation conditioned on x for equation (1), as: $$ E[y|x] = \beta_{0} + \beta_{1}x \tag{6}$$ This is a linear relationship between x and expected value of y, by the change of 1 unit in x leads to beta1 unit change in y. And the distribution of y is centered at E[y|x]. So my question is that, when we are estimating using OLS, is the sample regression function estimating the population model equation (1) or estimating the population regression function equation (6) and why? Also, in multiple regression function, we also assume zero conditional mean as: $$ E[u|x_{1}, x_{2}, x_{3},...,x_{k}] = 0 $$ Here are we saying that u is uncorrelated with the group of (x1,...xk), or can we say that u is uncorrelated with each of xi respectively, for i = 1,...,k? Thank you for your help and time! Much obliged.","I am relearning econometrics to get a better understanding of it, and to clear the confusions when I had in college. Using the simple regression model, we have a population model equation as: In the SLR assumption 3, we have the zero conditional mean assumption . Are we assuming this statement because in reality, y can take many values given x taking a single value, so that we hope, given x, the expected value of y is center around E[y|x], is this understanding of SLR Assumption 3 correct ? This means, if we take the expected value of equation (1) conditioned on x: Because any deviation can be absorbed by the intercept item, we lose nothing by assuming E[u] = 0. By assuming SLR 3 E[u|x] = E[u] = 0, we are implying that: In order to get the above equation, we are implying that x and u are independent of each other, so we are also implying that from the covariance formula of x and u, we can get the following equation E[ux] = E[u] = 0: Thus: And, because of this implied uncorrelated relationship between u and x, the equation (2) above can be viewed as when E[u|x] = 0, so we have the population regression function by taking expectation conditioned on x for equation (1), as: This is a linear relationship between x and expected value of y, by the change of 1 unit in x leads to beta1 unit change in y. And the distribution of y is centered at E[y|x]. So my question is that, when we are estimating using OLS, is the sample regression function estimating the population model equation (1) or estimating the population regression function equation (6) and why? Also, in multiple regression function, we also assume zero conditional mean as: Here are we saying that u is uncorrelated with the group of (x1,...xk), or can we say that u is uncorrelated with each of xi respectively, for i = 1,...,k? Thank you for your help and time! Much obliged."," y = \beta_{0} + \beta_{1}x + u\tag{1}  E[y|x] = \beta_{0} + \beta_{1}x + E[u|x]\tag{2}  E[u|x] =\sum{}u P_{u|x}(u) = \sum{}u\dfrac{P_{u,x}(u,x)}{P_{x}(x)}=\sum{}u\dfrac{P_{u}(u)P_{x}(x)}{P_{x}(x)} = \sum{}uP_{u}(u) = E[u]\tag{3}  Cov(u, x) = E[ux] - E[u]E[x] = E[ux] - 0 = E[u]E[x] = 0 \tag{4}  E[ux] = 0 \tag{5}  E[y|x] = \beta_{0} + \beta_{1}x \tag{6}  E[u|x_{1}, x_{2}, x_{3},...,x_{k}] = 0 ","['statistics', 'regression']"
24,Inequality involving Monotone likelihood ratio and CDF ratio,Inequality involving Monotone likelihood ratio and CDF ratio,,"This problem has really been bothering me and I have no idea whether the statement is true or not. So any help is appreciated. Suppose $f(x)/g(x)$ satisfies monotone likelihood ratio property and have CDF $F$ and $G$ , respectively. Assume $f$ and $g$ have support in $[0,1]$ . Let $C \leq 1$ be a constant, and some $1 \geq x_1 \geq x_2\geq 0 $ , such that the following condition holds: $$ C\cdot \frac{f(x_1)}{g(x_1)} = \frac{f(x_2)}{g(x_2)}.$$ Prove or give a counterexample $$ C\cdot \frac{1-F(x_1)}{1-G(x_1)} \leq \frac{1-F(x_2)}{1-G(x_2)}$$ If false, is there a simple condition that could be added to $f$ and $g$ such that the statement is true? Attempt to showing proof : A natural place to start was using the inequality $$\frac{f}{g}(x) \leq \frac{1-F(x)}{1-G(x)}$$ but that ended up going nowhere. Attempt to construct counterexample If there is a counterexample, it could be that $1-F(x_2)$ is extremely close to $0$ . But that means $1-F(x_1)$ is also close to $0$ since $x_1 > x_2$ . It's also not immediately clear that the construction is valid. I also attempted a simple case of $F = x^2$ and $G = x$ but it was not a counterexample.","This problem has really been bothering me and I have no idea whether the statement is true or not. So any help is appreciated. Suppose satisfies monotone likelihood ratio property and have CDF and , respectively. Assume and have support in . Let be a constant, and some , such that the following condition holds: Prove or give a counterexample If false, is there a simple condition that could be added to and such that the statement is true? Attempt to showing proof : A natural place to start was using the inequality but that ended up going nowhere. Attempt to construct counterexample If there is a counterexample, it could be that is extremely close to . But that means is also close to since . It's also not immediately clear that the construction is valid. I also attempted a simple case of and but it was not a counterexample.","f(x)/g(x) F G f g [0,1] C \leq 1 1 \geq x_1 \geq x_2\geq 0   C\cdot \frac{f(x_1)}{g(x_1)} = \frac{f(x_2)}{g(x_2)}.  C\cdot \frac{1-F(x_1)}{1-G(x_1)} \leq \frac{1-F(x_2)}{1-G(x_2)} f g \frac{f}{g}(x) \leq \frac{1-F(x)}{1-G(x)} 1-F(x_2) 0 1-F(x_1) 0 x_1 > x_2 F = x^2 G = x","['statistics', 'density-function', 'ratio']"
25,"Expected value of $k$th ordered statistic in Uniform(0, r) for r<1","Expected value of th ordered statistic in Uniform(0, r) for r<1",k,"Suppose that we draw $X_1, \ldots, X_n$ independently and uniformly from $(0,r)$ and let $X_{(k)}$ denote the $k$ th smallest number drawn. Denoting the pdf of $X_{(k)}$ by function $f_k$ , I know that $$ f_{k}(x) = n \frac{1}{r} \binom{n-1}{k-1}(x/r)^{k-1}(1-x/r)^{n-k}. $$ Questions How can I find the expected value of $X_{(k)}$ ? I know that $\mathbb{E}[X_{(k)}] = \int_0^rf_k(x)xdx$ ; but I don't know how to solve it. Intuitively, I believe the answer should be $\mathbb{E}[X_{(k)}]=\frac{k}{n+1}r$ but I don't have any proofs for it. How concentrated is $X_{(k)}$ around its expectation? More precisely, I would like to know an upper bound on $\Pr[|X_{(k)}-\mathbb{E}[X_{(k)}]| > \epsilon]$ for given $\epsilon$ .","Suppose that we draw independently and uniformly from and let denote the th smallest number drawn. Denoting the pdf of by function , I know that Questions How can I find the expected value of ? I know that ; but I don't know how to solve it. Intuitively, I believe the answer should be but I don't have any proofs for it. How concentrated is around its expectation? More precisely, I would like to know an upper bound on for given .","X_1, \ldots, X_n (0,r) X_{(k)} k X_{(k)} f_k 
f_{k}(x) = n \frac{1}{r} \binom{n-1}{k-1}(x/r)^{k-1}(1-x/r)^{n-k}.
 X_{(k)} \mathbb{E}[X_{(k)}] = \int_0^rf_k(x)xdx \mathbb{E}[X_{(k)}]=\frac{k}{n+1}r X_{(k)} \Pr[|X_{(k)}-\mathbb{E}[X_{(k)}]| > \epsilon] \epsilon","['probability', 'statistics']"
26,Find UMVU estimator for $e^{-3 \theta}$ given a complete sufficient statistic $X \sim Pois(\theta)$ with $\theta>0$.,Find UMVU estimator for  given a complete sufficient statistic  with .,e^{-3 \theta} X \sim Pois(\theta) \theta>0,"My attempt: We know, since $X\sim Pois(\theta)$ that $\mathbb{P}_{\theta}(X=x)=e^{-\theta}\theta^{x}/x!$ . A given tip is that we must recall that $e^{x}=\sum^{\infty}_{k=0}\frac{x^{k}}{k!}$ . I know that once we find an unbiased estimator that is a function of our complete sufficient statistic $X$ , that this estimator must then automatically be UMVU. However, I'm not sure how to approach this question by even finding an expression for an unbiased estimator. Question: How to approach/solve this exercise? Thanks!","My attempt: We know, since that . A given tip is that we must recall that . I know that once we find an unbiased estimator that is a function of our complete sufficient statistic , that this estimator must then automatically be UMVU. However, I'm not sure how to approach this question by even finding an expression for an unbiased estimator. Question: How to approach/solve this exercise? Thanks!",X\sim Pois(\theta) \mathbb{P}_{\theta}(X=x)=e^{-\theta}\theta^{x}/x! e^{x}=\sum^{\infty}_{k=0}\frac{x^{k}}{k!} X,"['probability', 'probability-theory', 'statistics', 'statistical-inference', 'parameter-estimation']"
27,Buffon's needle: expected number of intersections & pmf when $l > d$,Buffon's needle: expected number of intersections & pmf when,l > d,"Earlier results have shown that when $l < d$ , the expected number of crossings of a needle of length $l$ with vertical lines spaced $d$ apart is $\frac{2l}{\pi d}$ , which is also the expression for the probability that a needle intersects a line. I'm looking for an intuitive explanation for why that is the case (is that even the case...?) when the needle is longer ie. $l > d$ (consider $l = 3, d = 1$ for example). This does not match the expression for the probability that a needle intersects a line when $l > d$ ; rather, it matches the expression for the probability that a needle intersects a line when $l < d$ . Is this just because the possible numbers of crossings are no longer restricted to $0$ and $1$ (ie. the $0$ term cancels out when computing the expected value)? And, how would one find the PMF of the number of crossings when $l > d$ (for a simpler case such as $l = 3, d = 1$ )? The possible values for the numbers of crossings are $0, 1, 2, 3, 4$ if I'm not mistaken. But I don't know where to go from there. edit: still looking for the PMF!","Earlier results have shown that when , the expected number of crossings of a needle of length with vertical lines spaced apart is , which is also the expression for the probability that a needle intersects a line. I'm looking for an intuitive explanation for why that is the case (is that even the case...?) when the needle is longer ie. (consider for example). This does not match the expression for the probability that a needle intersects a line when ; rather, it matches the expression for the probability that a needle intersects a line when . Is this just because the possible numbers of crossings are no longer restricted to and (ie. the term cancels out when computing the expected value)? And, how would one find the PMF of the number of crossings when (for a simpler case such as )? The possible values for the numbers of crossings are if I'm not mistaken. But I don't know where to go from there. edit: still looking for the PMF!","l < d l d \frac{2l}{\pi d} l > d l = 3, d = 1 l > d l < d 0 1 0 l > d l = 3, d = 1 0, 1, 2, 3, 4","['probability', 'probability-theory', 'statistics', 'probability-distributions']"
28,Expected number of a Poisson-distributed variable,Expected number of a Poisson-distributed variable,,"Fifty spotlights have just been installed in an outdoor security system. According to the manufacturer’s specifications, these particular lights are expected to burn out at the rate of 1.1 per one hundred hours. What is the expected number of bulbs that will fail to last for at least seventy-five hours? Here $\lambda=1.1/100$ hours. My first idea was to find the average burnout rate for $75$ hour interval, which equals $3/4 \cdot \lambda=0.825/75$ hours. However, I do not understand how it can help to find the expected number of bulbs that will burn out within $75$ hours.","Fifty spotlights have just been installed in an outdoor security system. According to the manufacturer’s specifications, these particular lights are expected to burn out at the rate of 1.1 per one hundred hours. What is the expected number of bulbs that will fail to last for at least seventy-five hours? Here hours. My first idea was to find the average burnout rate for hour interval, which equals hours. However, I do not understand how it can help to find the expected number of bulbs that will burn out within hours.",\lambda=1.1/100 75 3/4 \cdot \lambda=0.825/75 75,"['statistics', 'expected-value']"
29,"Probability theory - Logic, Notation, simulation","Probability theory - Logic, Notation, simulation",,"i need some help in probability theory. The thing is im not sure if im thinking about this correctly and if i express my thoughts correctly. I really got lost in all the dice examples of the internet. Let $\ X\ \in \{1,0\} $ a binary outcome. Eg. missing the train in the morning, or not. Let $\ p\ $ be the probability of missing the train. $$ P(X=1) = p $$ $$ P(X=0) = 1-p $$ Lets say we use the train $\ n$ times, where each event is independent and identically distributed. Then im pretty sure that the probability of missing the train at least 1 time is: $$ 1-[(1-p)^n] $$ What is the correct notation for this Probability? This cant be correct: $$ P(X>=1 |\ n\ ) $$ What about the probability of missing the train exactly one time in $n$ events? I would guess its just $$ P(X=1|\ n \ ) = (1-p)^n \ * \ p $$ Also is the notation correct here? Now how can i answer this question : ""For which n there is a 100% probability of missing the train?"" and should i use P(""at least one time"" | n ) or P(""exactly one time"" | n ) to answer this question ? Besides the questions above i have one more (less important) question : Is there some kind of distribution which describes this case, given $(p, n)$ and how to simulate a process like this in general. I am using numpy and python.","i need some help in probability theory. The thing is im not sure if im thinking about this correctly and if i express my thoughts correctly. I really got lost in all the dice examples of the internet. Let a binary outcome. Eg. missing the train in the morning, or not. Let be the probability of missing the train. Lets say we use the train times, where each event is independent and identically distributed. Then im pretty sure that the probability of missing the train at least 1 time is: What is the correct notation for this Probability? This cant be correct: What about the probability of missing the train exactly one time in events? I would guess its just Also is the notation correct here? Now how can i answer this question : ""For which n there is a 100% probability of missing the train?"" and should i use P(""at least one time"" | n ) or P(""exactly one time"" | n ) to answer this question ? Besides the questions above i have one more (less important) question : Is there some kind of distribution which describes this case, given and how to simulate a process like this in general. I am using numpy and python.","\ X\ \in \{1,0\}  \ p\  
P(X=1) = p
 
P(X=0) = 1-p
 \ n 
1-[(1-p)^n]
 
P(X>=1 |\ n\ )
 n 
P(X=1|\ n \ ) = (1-p)^n \ * \ p
 (p, n)","['probability', 'statistics', 'notation', 'conditional-probability']"
30,"Is $E(Y|X)=0, a.s.$ equivalent to $E[Y\cdot f(X)]=0, \forall f\in \mathscr{B}$?",Is  equivalent to ?,"E(Y|X)=0, a.s. E[Y\cdot f(X)]=0, \forall f\in \mathscr{B}","Is the statement below true? How to prove it? $$E(Y|X)=0, a.s.$$ is equivalent to $$E[Y\cdot f(X)]=0, \forall f\in \mathscr{B}$$ If $E(Y|X)=0, a.s.$ , then $E[Y\cdot f(X)]=E\{E[Y\cdot f(X)|X]\}=E[f(X)\cdot E(Y|X)]=0$ . How to prove the opposite part?","Is the statement below true? How to prove it? is equivalent to If , then . How to prove the opposite part?","E(Y|X)=0, a.s. E[Y\cdot f(X)]=0, \forall f\in \mathscr{B} E(Y|X)=0, a.s. E[Y\cdot f(X)]=E\{E[Y\cdot f(X)|X]\}=E[f(X)\cdot E(Y|X)]=0","['probability', 'probability-theory', 'statistics', 'measure-theory', 'conditional-expectation']"
31,Basic but illuminating examples of statistical modeling,Basic but illuminating examples of statistical modeling,,"I'd like to know the best examples that are simple and easy to understand, but which also capture the essence and the spirit of statistical modeling. What are some simple but also fundamental and illuminating examples of statistical modeling? Edit: Here is another way to phrase the question: If a student asked you what statistical modeling is, what examples would you tell them? You would want the examples to somehow capture the essence of the subject without being too complicated. Edit 2: I'll attempt to provide an example myself.  What fraction of the population is planning to vote for candidate A? We introduce a random variable $X$ that is the result of selecting a person at random from the population and checking whether or not the person is planning to vote for A. If the person is planning to vote for A then $X = 1$ , otherwise $X = 0$ . We make a modeling assumption that $X$ has a Bernoulli distribution with parameter $p$ . This is a simple but concrete and fundamental example of a statistical model. Suppose that we select $n$ people at random from the population (with replacement) and the random variable $X_i$ is $1$ if the $i$ th person is planning to vote for A, and zero otherwise. Then $$ \hat p = \frac{X_1 + \cdots + X_n}{n} $$ estimates the value of $p$ . When we estimate the parameter $p$ in this way we have performed statistical inference . I think this little example contains the key ideas of statistical modeling and statistical inference. A student can think of this example and say, ""Ah, now I know what statistical modeling and statistical inference are."" But please correct me if you have any disagreements, or if I've used any terms incorrectly, as I'm a bit of an outsider to the field of statistics. I'd be interested in hearing other examples like this that are basic but fundamental and illuminating.","I'd like to know the best examples that are simple and easy to understand, but which also capture the essence and the spirit of statistical modeling. What are some simple but also fundamental and illuminating examples of statistical modeling? Edit: Here is another way to phrase the question: If a student asked you what statistical modeling is, what examples would you tell them? You would want the examples to somehow capture the essence of the subject without being too complicated. Edit 2: I'll attempt to provide an example myself.  What fraction of the population is planning to vote for candidate A? We introduce a random variable that is the result of selecting a person at random from the population and checking whether or not the person is planning to vote for A. If the person is planning to vote for A then , otherwise . We make a modeling assumption that has a Bernoulli distribution with parameter . This is a simple but concrete and fundamental example of a statistical model. Suppose that we select people at random from the population (with replacement) and the random variable is if the th person is planning to vote for A, and zero otherwise. Then estimates the value of . When we estimate the parameter in this way we have performed statistical inference . I think this little example contains the key ideas of statistical modeling and statistical inference. A student can think of this example and say, ""Ah, now I know what statistical modeling and statistical inference are."" But please correct me if you have any disagreements, or if I've used any terms incorrectly, as I'm a bit of an outsider to the field of statistics. I'd be interested in hearing other examples like this that are basic but fundamental and illuminating.","X X = 1 X = 0 X p n X_i 1 i 
\hat p = \frac{X_1 + \cdots + X_n}{n}
 p p","['statistics', 'statistical-inference', 'p-value']"
32,What is the probability that a red ball will be selected?,What is the probability that a red ball will be selected?,,"What is the probability that a red ball will be selected? Suppose there are two jars, $A,B$ $A$ has $2$ red, $4$ green $B$ has $3$ red, $5$ green An urn is selected at random, giving each of the urns a probability of $1/2$ A random urn is selected, and one ball is selected from that urn. What is the probability that a $G$ ball is selected. I can use a tree diagram, in which my answer is very clear: We can see that the probability that a $R$ ball is selected is $(1/2)(2/6)+(1/2)(3/8)=17/48$ The way my textbook does it is using the theorem of total probability (conditional version). That is, $P(R)=P(R|A)P(A)+P(R|B)P(B)$ Thinking on pure intution, $P(R|A)$ is asking me ""what is the probability that you selected a red ball, knowing that you already selected A"". Well thats just $2/6$ . I can basically just look at everything after the $A$ in the diagram. So our equation ends up becoming the same as the thereom of probability. Here is where my question is: Using the formula, $P(R|A)=\dfrac{P(R\cap A)}{P(A)}$ But What is $P(R\cap A)$ ? If $P(A) = 1/2$ , then surely the numerator must be $1/6$ , since our intuitive approach told us that this conditional probability is $2/6$ . But I don't understand where this $1/6$ comes from. I can see that this is probably just $(1/2)(2/6)$ (basically we just multiply the entire branch), but why does this work? I know that you can multiple the probabilities of two independent events , but how is this independent? Selecting box A effected the number of red balls we had.","What is the probability that a red ball will be selected? Suppose there are two jars, has red, green has red, green An urn is selected at random, giving each of the urns a probability of A random urn is selected, and one ball is selected from that urn. What is the probability that a ball is selected. I can use a tree diagram, in which my answer is very clear: We can see that the probability that a ball is selected is The way my textbook does it is using the theorem of total probability (conditional version). That is, Thinking on pure intution, is asking me ""what is the probability that you selected a red ball, knowing that you already selected A"". Well thats just . I can basically just look at everything after the in the diagram. So our equation ends up becoming the same as the thereom of probability. Here is where my question is: Using the formula, But What is ? If , then surely the numerator must be , since our intuitive approach told us that this conditional probability is . But I don't understand where this comes from. I can see that this is probably just (basically we just multiply the entire branch), but why does this work? I know that you can multiple the probabilities of two independent events , but how is this independent? Selecting box A effected the number of red balls we had.","A,B A 2 4 B 3 5 1/2 G R (1/2)(2/6)+(1/2)(3/8)=17/48 P(R)=P(R|A)P(A)+P(R|B)P(B) P(R|A) 2/6 A P(R|A)=\dfrac{P(R\cap A)}{P(A)} P(R\cap A) P(A) = 1/2 1/6 2/6 1/6 (1/2)(2/6)","['probability', 'probability-theory', 'statistics']"
33,Prove $\operatorname{Var}(X+Y) \le 2\operatorname{Var}(X) + 2\operatorname{Var}(Y)$ where $X$ and $Y$ are not necessarily independent,Prove  where  and  are not necessarily independent,\operatorname{Var}(X+Y) \le 2\operatorname{Var}(X) + 2\operatorname{Var}(Y) X Y,"I know how to show that $\operatorname{Var}(X+Y) = \operatorname{Var}(X) + \operatorname{Var}(Y) + 2\operatorname{Cov}(X,Y)$ I was also given the hint that I should use the triangle inequality to get $|\operatorname{Var}(X) + \operatorname{Var}(Y) + 2\operatorname{Cov}(X,Y)| \le |\operatorname{Var}(x)| + |\operatorname{Var}(Y)| + |2\operatorname{Cov}(X,Y)|$ Honestly, I have no idea where to go from here.","I know how to show that I was also given the hint that I should use the triangle inequality to get Honestly, I have no idea where to go from here.","\operatorname{Var}(X+Y) = \operatorname{Var}(X) + \operatorname{Var}(Y) + 2\operatorname{Cov}(X,Y) |\operatorname{Var}(X) + \operatorname{Var}(Y) + 2\operatorname{Cov}(X,Y)| \le |\operatorname{Var}(x)| + |\operatorname{Var}(Y)| + |2\operatorname{Cov}(X,Y)|","['statistics', 'covariance', 'variance']"
34,"Showing $\sum a_iX_i$ and $\sum X_i$ are independent iff $\sum a_i=0$ where $X_i$'s are i.i.d $N(\theta,\sigma^2)$",Showing  and  are independent iff  where 's are i.i.d,"\sum a_iX_i \sum X_i \sum a_i=0 X_i N(\theta,\sigma^2)","Let $X_1, X_2,\ldots, X_n$ be iid with the distribution $N(\theta, \sigma^2),$ $-\infty < \theta < \infty$ . Prove that a necessary and sufficient condition that the statistics $Z =\sum a_iX_i$ and $Y=\sum X_i $ are independent is that $\sum a_i=0$ . My try: I have showed that $Y=\sum X_i$ is a complete sufficient statistic. To use Basu's theorem, since $Z$ is a linear combination of independent normal distribution then $$Z\sim N\left(\theta\sum a_i, \sigma^2\sum a_i^2\right)$$ then I said $Z$ is free of $\theta$ i.e ( an ancillary) iff $\sum a_i=0$ . Then by Basu's theorem they are independent. Is this a sufficient answer? Thank you","Let be iid with the distribution . Prove that a necessary and sufficient condition that the statistics and are independent is that . My try: I have showed that is a complete sufficient statistic. To use Basu's theorem, since is a linear combination of independent normal distribution then then I said is free of i.e ( an ancillary) iff . Then by Basu's theorem they are independent. Is this a sufficient answer? Thank you","X_1, X_2,\ldots, X_n N(\theta, \sigma^2), -\infty < \theta < \infty Z =\sum a_iX_i Y=\sum X_i  \sum a_i=0 Y=\sum X_i Z Z\sim N\left(\theta\sum a_i, \sigma^2\sum a_i^2\right) Z \theta \sum a_i=0","['statistics', 'probability-distributions']"
35,Find the marginal distribution given the mean and the covariance matrix,Find the marginal distribution given the mean and the covariance matrix,,"If we have a vector of normally distributed random variables $x^T = (x_1,x_2)$ with mean $\mathbf{\mu}^T = (10, 14)$ and a covariance matrix $$S_1 =\begin{bmatrix}13 & 12\\12 & 13\end{bmatrix}.$$ I would first like to calculate the marginal distribution My Thoughts The random variables are normally distributed, so the distributions are simply: $x_1 \sim N(10,13)$ and $x_2 \sim N(14, 13)$ ? Is this correct? It seems to simple, don't I need to use the covariance? Suppose now that we assume that $x_1$ and $x_2$ are returns to financial assets, we need to calculate the distribution of the portfolio that gives equal weight to both assets My thoughts I'm not quite sure what to do here? Any thoughts? Do they mean that for every $x_2$ we need $\frac{14}{10}$ assets of $x_2$ to get the same amount of money? Any help is must appreciated.","If we have a vector of normally distributed random variables with mean and a covariance matrix I would first like to calculate the marginal distribution My Thoughts The random variables are normally distributed, so the distributions are simply: and ? Is this correct? It seems to simple, don't I need to use the covariance? Suppose now that we assume that and are returns to financial assets, we need to calculate the distribution of the portfolio that gives equal weight to both assets My thoughts I'm not quite sure what to do here? Any thoughts? Do they mean that for every we need assets of to get the same amount of money? Any help is must appreciated.","x^T = (x_1,x_2) \mathbf{\mu}^T = (10, 14) S_1 =\begin{bmatrix}13 & 12\\12 & 13\end{bmatrix}. x_1 \sim N(10,13) x_2 \sim N(14, 13) x_1 x_2 x_2 \frac{14}{10} x_2","['statistics', 'normal-distribution', 'marginal-distribution']"
36,Upper bound of sub-gaussian norm of bounded random variable?,Upper bound of sub-gaussian norm of bounded random variable?,,"I am reading the High-Dimensional Probability by Dr.Roman Vershynin , where I stuck on some statement at page 28. where state as below: Any bounded random variable $X$ is sub-gaussian with: $$\newcommand\norm[1]{\left\lVert#1\right\rVert} \norm{X}_{\psi_2}\leq \frac{\norm{X}_{\infty}}{\sqrt{\log2}} $$ where $\newcommand\norm[1]{\left\lVert#1\right\rVert} \norm{X}_{\psi_2}$ is the sub-gaussian norm define as: $$\newcommand\norm[1]{\left\lVert#1\right\rVert} \norm{X}_{\psi_2} =\inf \left\{ t>0 : \mathbb{E} \left[\exp{\left(\frac{X^2}{t^2}\right)} \right]   \leq 2 \right\} $$ where $\newcommand\norm[1]{\left\lVert#1\right\rVert} \norm{X}_{\infty} :=( \mathbb{E} |X|^p)^{1/p}$ as $p \to \infty$ I can see how why the  bounded random variable is sub-gaussian (hoeffing lemma ),but How could I see this upper bound of sub-gaussian  norm?","I am reading the High-Dimensional Probability by Dr.Roman Vershynin , where I stuck on some statement at page 28. where state as below: Any bounded random variable is sub-gaussian with: where is the sub-gaussian norm define as: where as I can see how why the  bounded random variable is sub-gaussian (hoeffing lemma ),but How could I see this upper bound of sub-gaussian  norm?","X \newcommand\norm[1]{\left\lVert#1\right\rVert}
\norm{X}_{\psi_2}\leq \frac{\norm{X}_{\infty}}{\sqrt{\log2}}
 \newcommand\norm[1]{\left\lVert#1\right\rVert}
\norm{X}_{\psi_2} \newcommand\norm[1]{\left\lVert#1\right\rVert}
\norm{X}_{\psi_2} =\inf \left\{ t>0 : \mathbb{E} \left[\exp{\left(\frac{X^2}{t^2}\right)} \right]   \leq 2 \right\}
 \newcommand\norm[1]{\left\lVert#1\right\rVert}
\norm{X}_{\infty} :=( \mathbb{E} |X|^p)^{1/p} p \to \infty","['probability', 'statistics', 'random-variables']"
37,How to 'randomize' a given discrete probability distibution?,How to 'randomize' a given discrete probability distibution?,,"Given a discrete probability distribution, $\boldsymbol{\lambda} = (\lambda_1,\lambda_2, ..., \lambda_n)$, how can we construct a random distribution, $\boldsymbol{\Lambda} = (\Lambda_1, \Lambda_2, ..., \Lambda_n)$ such that $\mathbb{E}(\boldsymbol{\Lambda}) = \boldsymbol{\lambda}$? The goal is to generate random variations of the initial distribution, $\boldsymbol{\lambda}$, with the above property. If it is possible to do this and have some degree of control over the variance/spread of each $\lambda_i$, then even better! I suspect that there are many ways to achieve this, so any approaches/answers are appreciated. What I've tried: My initial thought was to let each $\Lambda_i \sim Beta(\alpha_i, \beta_i)$, with $\alpha_i$, $\beta_i$ chosen so that $\mathbb{E}(\Lambda_i) = \lambda_i$. By choosing larger $\alpha_i$, and $\beta_i$ values, we can also make the distributions tighter around the mean. However, this has the issue that, in general, $$ \sum_{i=1}^n \Lambda_i \ne 1 $$ We may work around this by normalizing $\boldsymbol{\Lambda}$ after evaluating each $\Lambda_i$ (by dividing through by sum). Unfortunately I think I am right in saying that, in general, this means that $\mathbb{E}(\boldsymbol{\Lambda}) = \boldsymbol{\lambda}$ no longer holds. Similarly, we could 'normalize' $\boldsymbol{\Lambda}$ by setting $$ \Lambda_n = 1 - \sum_{i=1}^{n-1} \Lambda_i $$ This preserves $\mathbb{E}(\boldsymbol{\Lambda}) = \boldsymbol{\lambda}$ (at the expense of the distribution of $\Lambda_n$ now being difficult to determine exactly, though we can approximate it ). The problem with this method is that $\Lambda_n$ could now be negative!","Given a discrete probability distribution, $\boldsymbol{\lambda} = (\lambda_1,\lambda_2, ..., \lambda_n)$, how can we construct a random distribution, $\boldsymbol{\Lambda} = (\Lambda_1, \Lambda_2, ..., \Lambda_n)$ such that $\mathbb{E}(\boldsymbol{\Lambda}) = \boldsymbol{\lambda}$? The goal is to generate random variations of the initial distribution, $\boldsymbol{\lambda}$, with the above property. If it is possible to do this and have some degree of control over the variance/spread of each $\lambda_i$, then even better! I suspect that there are many ways to achieve this, so any approaches/answers are appreciated. What I've tried: My initial thought was to let each $\Lambda_i \sim Beta(\alpha_i, \beta_i)$, with $\alpha_i$, $\beta_i$ chosen so that $\mathbb{E}(\Lambda_i) = \lambda_i$. By choosing larger $\alpha_i$, and $\beta_i$ values, we can also make the distributions tighter around the mean. However, this has the issue that, in general, $$ \sum_{i=1}^n \Lambda_i \ne 1 $$ We may work around this by normalizing $\boldsymbol{\Lambda}$ after evaluating each $\Lambda_i$ (by dividing through by sum). Unfortunately I think I am right in saying that, in general, this means that $\mathbb{E}(\boldsymbol{\Lambda}) = \boldsymbol{\lambda}$ no longer holds. Similarly, we could 'normalize' $\boldsymbol{\Lambda}$ by setting $$ \Lambda_n = 1 - \sum_{i=1}^{n-1} \Lambda_i $$ This preserves $\mathbb{E}(\boldsymbol{\Lambda}) = \boldsymbol{\lambda}$ (at the expense of the distribution of $\Lambda_n$ now being difficult to determine exactly, though we can approximate it ). The problem with this method is that $\Lambda_n$ could now be negative!",,"['probability', 'probability-theory', 'statistics', 'probability-distributions']"
38,"Let $X_1,X_2...X_n$ be a random sample from $N(\mu,\sigma^2)$. Find the umvue of $\mu^3$. [closed]",Let  be a random sample from . Find the umvue of . [closed],"X_1,X_2...X_n N(\mu,\sigma^2) \mu^3","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question Note: I know lehman scheffe theorem and that sample mean is umvue of $\mu$. But how can we find the UMVUE of hiher powers of $\mu $?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question Note: I know lehman scheffe theorem and that sample mean is umvue of $\mu$. But how can we find the UMVUE of hiher powers of $\mu $?",,"['statistics', 'normal-distribution', 'statistical-inference', 'parameter-estimation']"
39,Probability and Statistics Books for Distributions and Introduction to Data Mining/Machine Learning,Probability and Statistics Books for Distributions and Introduction to Data Mining/Machine Learning,,"In college, I took a probability class using Sheldon Ross' A First Course in Probability. It was not my best semester to say the least. However, I am returning back to probability and statistics as it relates to what I want to do later in life. Since then I have learned some basic data mining, regression modeling, more generalized statistics topics, but without any real theory. I would like to learn the theory because as the modeling gets more complicated, more theory comes into play and I would like to understand more than the general explanation. However, my foundation of probability is not well-rounded. I know of mean, standard deviation, variance, hypothesis testing, linear model assumptions, but there are not that complex. Specifically, I would like to explore more of the different types of distributions (gamma, poisson, etc), and explore topics related to modeling (logistic, support vectors, random forest, etc), but also topics in Data Mining and Machine Learning. I have a B.A. in Mathematics and Economics from an okay school, but have taken courses and understood topics in Linear Algebra, Multivariate Calculus, Econometrics, Statistics (for Economics), Mathematical Models (covered predator and prey, linear regression, differentiable equations), and Analysis (which I mostly understood). Based on the above, I am looking for books that would help me get to where I want to be with DETAILED examples and walkthroughs. I am not a big person on books that say this is trivial or make general assumptions without explaining the topic. I know it won't all be in one book. The two books I have are: An Introduction to Statistical Learning: with Application in R and R Data Mining: Implement data mining techniques through practical use cases and real world datasets . I am in the process of finishing the second book, but just encountered Maximum Likelihood and got thrown for a loop.  In case you can't tell by the titles, I am also learning R. Any advice would be well received as well as suggestions to free copies. Thank you.","In college, I took a probability class using Sheldon Ross' A First Course in Probability. It was not my best semester to say the least. However, I am returning back to probability and statistics as it relates to what I want to do later in life. Since then I have learned some basic data mining, regression modeling, more generalized statistics topics, but without any real theory. I would like to learn the theory because as the modeling gets more complicated, more theory comes into play and I would like to understand more than the general explanation. However, my foundation of probability is not well-rounded. I know of mean, standard deviation, variance, hypothesis testing, linear model assumptions, but there are not that complex. Specifically, I would like to explore more of the different types of distributions (gamma, poisson, etc), and explore topics related to modeling (logistic, support vectors, random forest, etc), but also topics in Data Mining and Machine Learning. I have a B.A. in Mathematics and Economics from an okay school, but have taken courses and understood topics in Linear Algebra, Multivariate Calculus, Econometrics, Statistics (for Economics), Mathematical Models (covered predator and prey, linear regression, differentiable equations), and Analysis (which I mostly understood). Based on the above, I am looking for books that would help me get to where I want to be with DETAILED examples and walkthroughs. I am not a big person on books that say this is trivial or make general assumptions without explaining the topic. I know it won't all be in one book. The two books I have are: An Introduction to Statistical Learning: with Application in R and R Data Mining: Implement data mining techniques through practical use cases and real world datasets . I am in the process of finishing the second book, but just encountered Maximum Likelihood and got thrown for a loop.  In case you can't tell by the titles, I am also learning R. Any advice would be well received as well as suggestions to free copies. Thank you.",,"['probability', 'statistics', 'book-recommendation', 'machine-learning', 'data-mining']"
40,How to calculate a Bernoulli Distribution problem,How to calculate a Bernoulli Distribution problem,,"I have my statistics exam quite soon and i came upon this question : At the last referendum, $40\%$ of the Italian population supported the constitutional reform. If a random sample of size $n = 200$ is drawn, which is the probability of observing at least $100$ people who voted YES? Searching through my online notes, i found out that the explanation that the professor gave is this: If $X$ is the random variable which is equal to one if the unit voted YES, then it has a Bernoulli distribution with success probability equal $0.40$. Due to the large sample size, the Normal approximation holds. Therefore, $\hat p \sim \mathcal N(0.40, 0.012)$ and $Pr(\hat p > 0.50) = Pr(Z > 0.1/0.0346) = Pr(Z > 2.89) = 1 − Pr(Z < 2.89) = 0.0019$. I do not understand how he went through this ... can somebody help me? Starting from the first part of the explanation , where he states: $\hat p\sim \mathcal N(0.40, 0.012)$. Where is the $0.012$ coming from ? Thanks!","I have my statistics exam quite soon and i came upon this question : At the last referendum, $40\%$ of the Italian population supported the constitutional reform. If a random sample of size $n = 200$ is drawn, which is the probability of observing at least $100$ people who voted YES? Searching through my online notes, i found out that the explanation that the professor gave is this: If $X$ is the random variable which is equal to one if the unit voted YES, then it has a Bernoulli distribution with success probability equal $0.40$. Due to the large sample size, the Normal approximation holds. Therefore, $\hat p \sim \mathcal N(0.40, 0.012)$ and $Pr(\hat p > 0.50) = Pr(Z > 0.1/0.0346) = Pr(Z > 2.89) = 1 − Pr(Z < 2.89) = 0.0019$. I do not understand how he went through this ... can somebody help me? Starting from the first part of the explanation , where he states: $\hat p\sim \mathcal N(0.40, 0.012)$. Where is the $0.012$ coming from ? Thanks!",,"['probability', 'statistics', 'statistical-inference', 'bernoulli-numbers']"
41,Expectation of a random variable as a random variable,Expectation of a random variable as a random variable,,"I am doing an exercise in inference theory which involves finding a confidence interval for a difference in expectations. I have two groups $A$ and $B$, of let's say patients, and we measure each groups blood sugar levels. We assume these groups each correspond to a random variable $X_A$ and $X_B$, distributed as $N(\mu_A, \sigma_A^2)$ and $N(\mu_B, \sigma_B^2)$ respectively. What we want is to find a confidence interval $I_{\mu}$ on significance level $\alpha$ for $\mu = \mu_A - \mu_B$, such that $$1-\alpha = P(h(\mu, \hat{\mu}) \in I) = P\left(h^{-1}_{\hat{\mu}}(h(\mu, \hat{\mu})) \in h^{-1}_{\hat{\mu}}(I)\right) = P(\mu \in I{\mu}).$$ I start by estimating $\mu$ by $\hat{\mu} = \hat{\mu_A} - \hat{\mu_B}$ and $\sigma^2$ by the pooled variance, $$\hat{\sigma}^2 = \frac{\hat{\sigma}^2_A(n_A-1)+\hat{\sigma}^2_B(n_B-1)}{(n_A-1)+(n_B-1)}=\frac{\sum_{i=1}^{n_A}(x_i-\bar{x})^2 \ +\sum_{j=1}^{n_B}(y_i-\bar{y})^2}{n_A + n_B - 2}$$ where there are $n_A$ and $n_B$ measurements from each group. Regarding the pivot random variable, I reasoned that $\hat{\mu}$ must have a normal distribution because a linear combination of normally distributed random variables is also normally distributed and the expectation, $E(\cdot)$, as an operator is linear. How do I formalize this? I read somewhere that this is $t$-distributed but don't know (yet) what a $t$-distribution. When I google on the $t$-distribution it looks like a normal distribution but with less variance. What is the connection? All the help is much appreciated, thank you in advance, Isak","I am doing an exercise in inference theory which involves finding a confidence interval for a difference in expectations. I have two groups $A$ and $B$, of let's say patients, and we measure each groups blood sugar levels. We assume these groups each correspond to a random variable $X_A$ and $X_B$, distributed as $N(\mu_A, \sigma_A^2)$ and $N(\mu_B, \sigma_B^2)$ respectively. What we want is to find a confidence interval $I_{\mu}$ on significance level $\alpha$ for $\mu = \mu_A - \mu_B$, such that $$1-\alpha = P(h(\mu, \hat{\mu}) \in I) = P\left(h^{-1}_{\hat{\mu}}(h(\mu, \hat{\mu})) \in h^{-1}_{\hat{\mu}}(I)\right) = P(\mu \in I{\mu}).$$ I start by estimating $\mu$ by $\hat{\mu} = \hat{\mu_A} - \hat{\mu_B}$ and $\sigma^2$ by the pooled variance, $$\hat{\sigma}^2 = \frac{\hat{\sigma}^2_A(n_A-1)+\hat{\sigma}^2_B(n_B-1)}{(n_A-1)+(n_B-1)}=\frac{\sum_{i=1}^{n_A}(x_i-\bar{x})^2 \ +\sum_{j=1}^{n_B}(y_i-\bar{y})^2}{n_A + n_B - 2}$$ where there are $n_A$ and $n_B$ measurements from each group. Regarding the pivot random variable, I reasoned that $\hat{\mu}$ must have a normal distribution because a linear combination of normally distributed random variables is also normally distributed and the expectation, $E(\cdot)$, as an operator is linear. How do I formalize this? I read somewhere that this is $t$-distributed but don't know (yet) what a $t$-distribution. When I google on the $t$-distribution it looks like a normal distribution but with less variance. What is the connection? All the help is much appreciated, thank you in advance, Isak",,"['statistics', 'normal-distribution', 'statistical-inference', 'confidence-interval', 'expected-value']"
42,"If $X$ is exponentially distributed with parameter $1$, prove that $\exp(-X)$ is uniformly distributed on $[0,1]$.","If  is exponentially distributed with parameter , prove that  is uniformly distributed on .","X 1 \exp(-X) [0,1]","This is what I have so far: The PDF of $X$ is  $$f_X(x)=e^{-x}$$ when $x\geq0$ and $0$ otherwise. The CDF of $X$ is $$P(X\leq x)=F_X(x)=1-e^{-x}$$ when $x\geq 0$ and $0$ otherwise. I know that I want to end up with the pdf of $Y=e^{-X}$ being $$f_Y=1$$ on $[0,1]$ and $0$ otherwise, hence a uniform distribution. So, \begin{align}F_Y(y)&=P(Y\leq y)\\ &=P(e^{-X}\leq y)\\ &=P(-\ln(y)\leq X) \end{align}  I don't know how to proceed from here. Also, I know that $X=-\ln(Y)$, but I am not sure how to use it/ if I need to.","This is what I have so far: The PDF of $X$ is  $$f_X(x)=e^{-x}$$ when $x\geq0$ and $0$ otherwise. The CDF of $X$ is $$P(X\leq x)=F_X(x)=1-e^{-x}$$ when $x\geq 0$ and $0$ otherwise. I know that I want to end up with the pdf of $Y=e^{-X}$ being $$f_Y=1$$ on $[0,1]$ and $0$ otherwise, hence a uniform distribution. So, \begin{align}F_Y(y)&=P(Y\leq y)\\ &=P(e^{-X}\leq y)\\ &=P(-\ln(y)\leq X) \end{align}  I don't know how to proceed from here. Also, I know that $X=-\ln(Y)$, but I am not sure how to use it/ if I need to.",,['statistics']
43,mean of a function on a topology other than R^n,mean of a function on a topology other than R^n,,"Sorry for the long post, the beginning part is mainly about the motivation for this question. At the end I give a specific problem I would like solved. I am plotting the angle of a complex function over a 2D space using colour to represent different angles. Most of my data is clustered together around a single angle with a relatively small variance. As a rough estimate, 90% of the data is within 15 degrees or so. For this reason I don't want to associate a unique colour to each of the angles in 360 degrees because most of the colours will go unused, I thus see it fit to find the ""mean"" (I concept I don't really know how to define on a circle) and then choose that angle to be associated with the colour in the middle of my colour wheel and then associate angles greater or less than the mean with colours varying on the colour wheel in such a way as to most efficiently use the colours. The main problem I have run into is calculating the mean. Imagine most of the data is clustered around 0 degrees. Then there will be about half the data just above 0 and the rest of it just below 360 because of the nature of angle. Thus the mean will be about 180. You could imagine shifting all the data points around the circle so as to cause the mean to not be near 0 degrees however this would require already knowing the mean. I have solved this problem. I imagine each data point as being a point in the plane like so. A point corresponding to the angle ø would be imagined as the point (cosø,sinø). I then take the mean of the data as it would be calculated for any data set in R 2 (I take the mean in the x and the mean in the y) then I take this new point of the form (x,y) and calculate its corresponding angle with ø = atan(y/x) there by projecting the point back into the original space. Of course this isn't perfect, say x=0, then you need to look at the sign of y and then pick 90 or 270 degrees accordingly. If y=x=0 then you can't get a value however in this case the notion of a mean doesn't really make sense in my opinion because the data is evenly spaced around the circle. Although this isn't perfect, it works for my application so I am going to leave it as it is. This now brings me to a more general question. Say you have some topology other than R n , with a distribution over it (like in my case above the topology S 1 ). How might one calculate/define the ""mean"". An easy generalization of what I did above can be done for a sphere, simply imagine the points as being in R 3 and then take the mean, then project the mean back onto the sphere. In general you could take a data set over a manifold, embed it in R n , and then project it back down onto the manifold and call that the mean. However this doesn't always work. Say you have a torus, if you embed this in R 3 you can find the mean however there is not a unique way to project a point in R 3 onto a torus. This is because if you draw a straight line through the origin and the mean it may cross the torus more than once, unlike with a sphere. I hope you found this problem interesting. Any links to resources discussing how this might be done would be greatly appreciated. Also any original ideas would be good too. Thanks","Sorry for the long post, the beginning part is mainly about the motivation for this question. At the end I give a specific problem I would like solved. I am plotting the angle of a complex function over a 2D space using colour to represent different angles. Most of my data is clustered together around a single angle with a relatively small variance. As a rough estimate, 90% of the data is within 15 degrees or so. For this reason I don't want to associate a unique colour to each of the angles in 360 degrees because most of the colours will go unused, I thus see it fit to find the ""mean"" (I concept I don't really know how to define on a circle) and then choose that angle to be associated with the colour in the middle of my colour wheel and then associate angles greater or less than the mean with colours varying on the colour wheel in such a way as to most efficiently use the colours. The main problem I have run into is calculating the mean. Imagine most of the data is clustered around 0 degrees. Then there will be about half the data just above 0 and the rest of it just below 360 because of the nature of angle. Thus the mean will be about 180. You could imagine shifting all the data points around the circle so as to cause the mean to not be near 0 degrees however this would require already knowing the mean. I have solved this problem. I imagine each data point as being a point in the plane like so. A point corresponding to the angle ø would be imagined as the point (cosø,sinø). I then take the mean of the data as it would be calculated for any data set in R 2 (I take the mean in the x and the mean in the y) then I take this new point of the form (x,y) and calculate its corresponding angle with ø = atan(y/x) there by projecting the point back into the original space. Of course this isn't perfect, say x=0, then you need to look at the sign of y and then pick 90 or 270 degrees accordingly. If y=x=0 then you can't get a value however in this case the notion of a mean doesn't really make sense in my opinion because the data is evenly spaced around the circle. Although this isn't perfect, it works for my application so I am going to leave it as it is. This now brings me to a more general question. Say you have some topology other than R n , with a distribution over it (like in my case above the topology S 1 ). How might one calculate/define the ""mean"". An easy generalization of what I did above can be done for a sphere, simply imagine the points as being in R 3 and then take the mean, then project the mean back onto the sphere. In general you could take a data set over a manifold, embed it in R n , and then project it back down onto the manifold and call that the mean. However this doesn't always work. Say you have a torus, if you embed this in R 3 you can find the mean however there is not a unique way to project a point in R 3 onto a torus. This is because if you draw a straight line through the origin and the mean it may cross the torus more than once, unlike with a sphere. I hope you found this problem interesting. Any links to resources discussing how this might be done would be greatly appreciated. Also any original ideas would be good too. Thanks",,"['general-topology', 'statistics', 'means']"
44,A Problem dealing with the Binomial Distribution,A Problem dealing with the Binomial Distribution,,"Below is my solution to a problem from a text book. I do not have confidence that my solution is right. I feel like I am missing something. Am I? Thanks, Bob Problem: An airline finds that $5$ percent of the persons making reservations on a certain flight will not show up for that flight. If the airline sells $160$ seats tickets for a fight with only $155$ seats, what is the probability that a seat will be available for every person holding a reservation and planning on flying. Answer: First realize that we have a binomial distribution with $n = 160$, $p = 0.95$ and $q = 0.05$. We are going to approximate that with a normal distribution. \begin{eqnarray*} u &=& np = 160(0.95) = 152 \\ \sigma^2 &=& npq = 0.95(0.05)(160) =7.6 \\ \sigma &=& 2.75681 \\ \end{eqnarray*} Observe that $155$ is $1.08821$ standard deviations above the mean. We then run the following command in R:  pnorm(1.08821) and got $0.8617488$. We conclude the probability that all the passengers will have seats is $0.8617488$. The book gets $0.8980$. We will now do the problem again using Yates's correction. This time we ask what is the probability that we have $155.5$ passengers or less. Now we are  $1.26991$ standard deviations above the mean.  We then run the following command in R:  pnorm(1.26991) and got $0.0.89794$ which matches the answer in the book.","Below is my solution to a problem from a text book. I do not have confidence that my solution is right. I feel like I am missing something. Am I? Thanks, Bob Problem: An airline finds that $5$ percent of the persons making reservations on a certain flight will not show up for that flight. If the airline sells $160$ seats tickets for a fight with only $155$ seats, what is the probability that a seat will be available for every person holding a reservation and planning on flying. Answer: First realize that we have a binomial distribution with $n = 160$, $p = 0.95$ and $q = 0.05$. We are going to approximate that with a normal distribution. \begin{eqnarray*} u &=& np = 160(0.95) = 152 \\ \sigma^2 &=& npq = 0.95(0.05)(160) =7.6 \\ \sigma &=& 2.75681 \\ \end{eqnarray*} Observe that $155$ is $1.08821$ standard deviations above the mean. We then run the following command in R:  pnorm(1.08821) and got $0.8617488$. We conclude the probability that all the passengers will have seats is $0.8617488$. The book gets $0.8980$. We will now do the problem again using Yates's correction. This time we ask what is the probability that we have $155.5$ passengers or less. Now we are  $1.26991$ standard deviations above the mean.  We then run the following command in R:  pnorm(1.26991) and got $0.0.89794$ which matches the answer in the book.",,"['probability', 'statistics']"
45,Chebyshev's inequality application and convergence - practical example,Chebyshev's inequality application and convergence - practical example,,"Let $W_n$ be a random variable with mean $\mu$ and variance $\frac{b^2}{n^{2p}}$ , with $p>0$ and $b$ and $\mu$ constants. Show that $$ \lim_{n\to\infty} P(|W_n-\mu| \leq \epsilon) = 1 $$ The solution applies Chebychevs: $$ P(|W_n-\mu| \leq \epsilon) = 1 - P(|W_n-\mu| > \epsilon) $$ $$ \geq 1 - P(|W_n-\mu| \geq \epsilon) $$ $$ = 1 - P(|W_n-\mu| \geq \frac{\epsilon n^p}{b} \frac{b}{n^p}) $$ $$ \geq 1 - \frac{1}{(\frac{\epsilon n^p}{b})^2}$$ and then taking the limit $n\to\infty$ . I do not understand the change of signs in the second line? Also where does $\frac{\epsilon n^p}{b} \frac{b}{n^p} $ in the third line come from? Does this imply $W_n$ converges in probability to $p$ ? $$ \lim_{n\to\infty} P(|W_n-\mu| \geq \epsilon) = 1 - \lim_{n\to\infty}P(|W_n-\mu| < \epsilon) \leq 1 - \lim_{n\to\infty} P(|W_n-\mu| \leq \epsilon) = 0$$ So, this i do not understand. An explanation in plain english of this. This is the first time i worked on exercises for convergence.","Let be a random variable with mean and variance , with and and constants. Show that The solution applies Chebychevs: and then taking the limit . I do not understand the change of signs in the second line? Also where does in the third line come from? Does this imply converges in probability to ? So, this i do not understand. An explanation in plain english of this. This is the first time i worked on exercises for convergence.",W_n \mu \frac{b^2}{n^{2p}} p>0 b \mu  \lim_{n\to\infty} P(|W_n-\mu| \leq \epsilon) = 1   P(|W_n-\mu| \leq \epsilon) = 1 - P(|W_n-\mu| > \epsilon)   \geq 1 - P(|W_n-\mu| \geq \epsilon)   = 1 - P(|W_n-\mu| \geq \frac{\epsilon n^p}{b} \frac{b}{n^p})   \geq 1 - \frac{1}{(\frac{\epsilon n^p}{b})^2} n\to\infty \frac{\epsilon n^p}{b} \frac{b}{n^p}  W_n p  \lim_{n\to\infty} P(|W_n-\mu| \geq \epsilon) = 1 - \lim_{n\to\infty}P(|W_n-\mu| < \epsilon) \leq 1 - \lim_{n\to\infty} P(|W_n-\mu| \leq \epsilon) = 0,"['probability-theory', 'statistics', 'convergence-divergence']"
46,Correlation between two linear combinations of random variables,Correlation between two linear combinations of random variables,,"Let $X_1, X_2, X_3, X_4$ be independent random variables with $\operatorname{var}(X_i)=1$, and $$U = 2X_1+X_2+X_3$$ $$ V = X_2+X_3 + 2X_4$$ Find $\operatorname{corr}(U, V)$ In general, how can I calculate the correlation between two linear combinations of independent $X_i$ such as $U$ and $V$ knowing only $\operatorname{var}(X_i)$? Or what if they weren't independent, but I had their covariance or correlation matrix?","Let $X_1, X_2, X_3, X_4$ be independent random variables with $\operatorname{var}(X_i)=1$, and $$U = 2X_1+X_2+X_3$$ $$ V = X_2+X_3 + 2X_4$$ Find $\operatorname{corr}(U, V)$ In general, how can I calculate the correlation between two linear combinations of independent $X_i$ such as $U$ and $V$ knowing only $\operatorname{var}(X_i)$? Or what if they weren't independent, but I had their covariance or correlation matrix?",,"['probability', 'statistics', 'random-variables', 'correlation']"
47,What is the second moment for a symmetric set of vectors?,What is the second moment for a symmetric set of vectors?,,"I am new to vector statistics and just wanted to check if I'm having a correct deduction here. I have a set of vectors from an $N$-dimensional space $$ v_k=\begin{bmatrix} v_{k_1} \\ v_{k_2} \\ \vdots \\ v_{k_N} \end{bmatrix} $$ which elements are either $-1$ or $1$. If this set of vectors is a complete combination of all possible vectors, which count would be $2^N$ I know the first moment of these vectors would be $0$ because of symmetry, can I say the second moment, the variance-covariance matrix is equal to a unitary $N\times N$ matrix? $$ \operatorname{cov}_{ij} = \frac{1}{N} \sum_{k=1}^{2^N} [(v_{k_i}-\mu_k)(v_{k_j}-\mu_k)] $$ where $\mu_k$ is the $k$th element of the first moment vector. Is there a algebraic proof for this?","I am new to vector statistics and just wanted to check if I'm having a correct deduction here. I have a set of vectors from an $N$-dimensional space $$ v_k=\begin{bmatrix} v_{k_1} \\ v_{k_2} \\ \vdots \\ v_{k_N} \end{bmatrix} $$ which elements are either $-1$ or $1$. If this set of vectors is a complete combination of all possible vectors, which count would be $2^N$ I know the first moment of these vectors would be $0$ because of symmetry, can I say the second moment, the variance-covariance matrix is equal to a unitary $N\times N$ matrix? $$ \operatorname{cov}_{ij} = \frac{1}{N} \sum_{k=1}^{2^N} [(v_{k_i}-\mu_k)(v_{k_j}-\mu_k)] $$ where $\mu_k$ is the $k$th element of the first moment vector. Is there a algebraic proof for this?",,"['linear-algebra', 'statistics', 'proof-verification']"
48,"Why are $\max(x_i)$ and $\min(x_i)$ sufficient statistics for $\operatorname{Unif}(a,b)$?",Why are  and  sufficient statistics for ?,"\max(x_i) \min(x_i) \operatorname{Unif}(a,b)","Suppose I have $X_i \sim \operatorname{Unif}(a,b)$. I have that the joint distribution is given by $$\frac{1}{\left(b-a\right)^n}\prod_{i=1}^n I(x_i \in (a,b)) = \frac{1}{\left(b-a\right)^n}I(\min(x_i) \in (a,b))I(\max(x_i)\in (a,b)).$$ Now, my question is why does this satisfy the factorization theorem? Don't $I(\min(x_i) \in (a,b))$ and $I(\max(x_i)\in (a,b))$ still depend on $a$ and $b$? If they don't, then don't we also have that $\prod_{i=1}^n I(x_i \in (a,b))$ doesn't depend on $a$ or $b$, and so, we can factor the original joint distribution as required, without any sufficient statistic. I think I am misunderstanding something about sufficiency here.","Suppose I have $X_i \sim \operatorname{Unif}(a,b)$. I have that the joint distribution is given by $$\frac{1}{\left(b-a\right)^n}\prod_{i=1}^n I(x_i \in (a,b)) = \frac{1}{\left(b-a\right)^n}I(\min(x_i) \in (a,b))I(\max(x_i)\in (a,b)).$$ Now, my question is why does this satisfy the factorization theorem? Don't $I(\min(x_i) \in (a,b))$ and $I(\max(x_i)\in (a,b))$ still depend on $a$ and $b$? If they don't, then don't we also have that $\prod_{i=1}^n I(x_i \in (a,b))$ doesn't depend on $a$ or $b$, and so, we can factor the original joint distribution as required, without any sufficient statistic. I think I am misunderstanding something about sufficiency here.",,"['probability', 'probability-theory', 'statistics', 'probability-distributions', 'statistical-inference']"
49,What is this curve called?,What is this curve called?,,"This curve can be easily generated with a spreadsheet. You can set cell A1 to be 100 and then B1 will be this formula =A1×(100+RAND()×10−5)÷100 And fill down about 150 or more cells. Then copy row B and paste formula result into column A. Repeat till you get bored. If you sort by size and graph, you will get a curve that looks like this. My question is, does this curve have a name and is there an equation that generates it? Edit to explain where this question comes from. If you choose a basket of stocks, like the S&P 500, and buy $1000 worth of each stock, then the values of the stocks will change and if you graph them they will form this curve.","This curve can be easily generated with a spreadsheet. You can set cell A1 to be 100 and then B1 will be this formula =A1×(100+RAND()×10−5)÷100 And fill down about 150 or more cells. Then copy row B and paste formula result into column A. Repeat till you get bored. If you sort by size and graph, you will get a curve that looks like this. My question is, does this curve have a name and is there an equation that generates it? Edit to explain where this question comes from. If you choose a basket of stocks, like the S&P 500, and buy $1000 worth of each stock, then the values of the stocks will change and if you graph them they will form this curve.",,"['probability', 'statistics', 'economics']"
50,Stuck in derivation of PCA,Stuck in derivation of PCA,,"I'm currently studying principal component analysis (PCA) from this lecture notes. I understand that we are trying to find the axis on which the variance of  projection of all the data points is maximum. Now where I'm stuck is in the formulation of PCA. In the above notes, on page number 5, our objective function is given as following. $$\frac{1}{m}\sum_{i=1}^{m}(x^{(i)^{T}}u)^2 = \frac{1}{m}\sum_{i=1}^{m}u^Tx^{(i)}x^{(i)^T}u$$ How this is derived? I can't find any explanation on this step anywhere. As per my understanding shouldn't it be: $$\frac{1}{m}\sum_{i=1}^{m}(x^{(i)^{T}}u)^2 = \frac{1}{m}\sum_{i=1}^{m}x^{(i)^T}ux^{(i)^T}u$$ Also in this question , the objective function is very different then the one mentioned above in the notes. (i.e from here and here it seems to be the distance between data point $x^{(i)}$ and the axis $w$ , but in the notes and video lectures, it's mentioned that it's distance between projection of point and the origin). What am I missing here? Any help would be appreciated","I'm currently studying principal component analysis (PCA) from this lecture notes. I understand that we are trying to find the axis on which the variance of  projection of all the data points is maximum. Now where I'm stuck is in the formulation of PCA. In the above notes, on page number 5, our objective function is given as following. How this is derived? I can't find any explanation on this step anywhere. As per my understanding shouldn't it be: Also in this question , the objective function is very different then the one mentioned above in the notes. (i.e from here and here it seems to be the distance between data point and the axis , but in the notes and video lectures, it's mentioned that it's distance between projection of point and the origin). What am I missing here? Any help would be appreciated",\frac{1}{m}\sum_{i=1}^{m}(x^{(i)^{T}}u)^2 = \frac{1}{m}\sum_{i=1}^{m}u^Tx^{(i)}x^{(i)^T}u \frac{1}{m}\sum_{i=1}^{m}(x^{(i)^{T}}u)^2 = \frac{1}{m}\sum_{i=1}^{m}x^{(i)^T}ux^{(i)^T}u x^{(i)} w,"['linear-algebra', 'statistics', 'machine-learning', 'principal-component-analysis']"
51,European Call Option - Expectation of Normal CDF,European Call Option - Expectation of Normal CDF,,"I'm trying to understand a paper of Sergii Kuchuk-Iatsenko and Yuliya Mishura, Pricing the European Call Option in the Model with Stochastic Volatility Driven by Ornstein-Uhlenbeck Process, Exact Formula, as its has similarity of what I am researching right now. So we know that European call option at $t=0$ is $$V_0=SN(d_1)+Ke^{-r(T-t)}N(d_2)$$ where $$d_1=\frac{ln(S/K)+(r+\frac{1}{2}\sigma^2)T}{\sigma\sqrt{T}}$$ $$d_2=d_1-\sigma\sqrt{T}$$ $S$ is price of underlying asset, $N(.)$ is standard normal CDF, $K$ is strike price, $r$ is risk-free rate, and $T$ is time to expiration. In Sergii Kuchuk paper, $N(d_1)$ can be stated into below equation $$N(d_1)=\frac{1}{2}+\frac{1}{\sqrt{2\pi}}I_{d_1\gt0}\int_{0}^{d_1}e^{-s^2/2}ds-\frac{1}{\sqrt{2\pi}}I_{d_1\lt0}\int_{d_1}^{0}e^{-s^2/2}ds$$ I already understand until this part. Then the paper stated that $$\mathbf{E}(N(d_1))=\frac{1}{2}+\frac{1}{\sqrt{2\pi}}\int_{0}^{\infty}\mathbf{Q}(S\lt{d_1})e^{-s^2/2}ds-\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{0}\mathbf{Q}(S\gt{d_1})e^{-s^2/2}ds$$ where $\mathbf{Q}$ is probability measure which is equivalent to objective measure $\mathbf{P}$. Which means $$\mathbf{E}(\frac{1}{\sqrt{2\pi}}I_{d_1\gt0}\int_{0}^{d_1}e^{-s^2/2}ds)=\frac{1}{\sqrt{2\pi}}\int_{0}^{\infty}\mathbf{Q}(S\lt{d_1})e^{-s^2/2}ds$$ I don't have a clue on this part.","I'm trying to understand a paper of Sergii Kuchuk-Iatsenko and Yuliya Mishura, Pricing the European Call Option in the Model with Stochastic Volatility Driven by Ornstein-Uhlenbeck Process, Exact Formula, as its has similarity of what I am researching right now. So we know that European call option at $t=0$ is $$V_0=SN(d_1)+Ke^{-r(T-t)}N(d_2)$$ where $$d_1=\frac{ln(S/K)+(r+\frac{1}{2}\sigma^2)T}{\sigma\sqrt{T}}$$ $$d_2=d_1-\sigma\sqrt{T}$$ $S$ is price of underlying asset, $N(.)$ is standard normal CDF, $K$ is strike price, $r$ is risk-free rate, and $T$ is time to expiration. In Sergii Kuchuk paper, $N(d_1)$ can be stated into below equation $$N(d_1)=\frac{1}{2}+\frac{1}{\sqrt{2\pi}}I_{d_1\gt0}\int_{0}^{d_1}e^{-s^2/2}ds-\frac{1}{\sqrt{2\pi}}I_{d_1\lt0}\int_{d_1}^{0}e^{-s^2/2}ds$$ I already understand until this part. Then the paper stated that $$\mathbf{E}(N(d_1))=\frac{1}{2}+\frac{1}{\sqrt{2\pi}}\int_{0}^{\infty}\mathbf{Q}(S\lt{d_1})e^{-s^2/2}ds-\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{0}\mathbf{Q}(S\gt{d_1})e^{-s^2/2}ds$$ where $\mathbf{Q}$ is probability measure which is equivalent to objective measure $\mathbf{P}$. Which means $$\mathbf{E}(\frac{1}{\sqrt{2\pi}}I_{d_1\gt0}\int_{0}^{d_1}e^{-s^2/2}ds)=\frac{1}{\sqrt{2\pi}}\int_{0}^{\infty}\mathbf{Q}(S\lt{d_1})e^{-s^2/2}ds$$ I don't have a clue on this part.",,"['statistics', 'stochastic-processes', 'stochastic-calculus', 'finance']"
52,Wrong proof for the variance of a sum of normally-distributed variables?,Wrong proof for the variance of a sum of normally-distributed variables?,,"I'm reading the book ""Introduction to Error Analysis"" by John R. Taylor. The author is discussing the probability distribution of a sum of two normally-distributed random variables, and wants to show that if $x \sim N(0,\sigma_x^2)$ and $y\sim N(0,\sigma_y^2)$, then $x+y \sim N(0, \sigma_x^2 + \sigma_y^2)$. He proceeds to prove this, but either there's something I'm seriously missing, or the proof is extremely hand-wavey (or just plain wrong). In particular, I don't see how you can take a term involving $x$ and $y$, call it $z$, and then conveniently integrate w.r.t. $z$ as if it were independent of $x$ and $y$. I'm quoting the proof below, with some slight formatting modifications to make typing it out easier. Thank you for your help. $\Pr(x,y) \propto \exp\left[-\frac{1}{2}\left(\frac{x^2}{\sigma_x^2} +  \frac{y^2}{\sigma_y^2}\right)\right]\quad\quad\quad$ (5.53) Knowing the probability of obtaining any $x$ and $y$, we can now   calculate the probability for any given value of $x+y$. The first step   is to rewrite the exponent in (5.53) in terms of the variable of   interest, $x+y$. This step can be done using the identity (which you   can easily verify) $ \frac{x^2}{A} + \frac{y^2}{B} = \frac{(x+y)^2}{A+B} + \frac{(Bx-Ay)^2}{AB(A+B)}  \quad\quad\quad$ (5.54) $= \frac{(x+y)^2}{A+B} + z^2 \quad\quad\quad (5.55) $ In the second line I have introduced the abbreviation $z^2$ for the   second term on the right of (5.54) because its value does not interest   us anyway. If we substitute (5.55) into (5.53), replacing $A$ with $\sigma_x^2$   and $B$ with $\sigma_y^2$, we obtain: $ \Pr(x,y) \propto  \exp\left[-\frac{1}{2}\left(\frac{(x+y)^2}{(\sigma_x^2 +  \sigma_y^2)}\right) - \frac{z^2}{2} \right]\quad\quad\quad$ (5.56) This probability for obtaining given values of $x$ and $y$ can just as   well be viewed as the probability of obtaining given values of $x+y$   and $z$. Thus, we can rewrite (5.56) as $ \Pr(x+y,z) \propto  \exp\left[-\frac{1}{2}\left(\frac{(x+y)^2}{(\sigma_x^2 +  \sigma_y^2)}\right)\right] \exp\left[- \frac{z^2}{2}\right]  \quad\quad\quad$ (5.57) Finally, what we want is the probability of obtaining a given value of   $x+y$ irrespective of the value of $z$. This probability is obtained   by summing, or rather integrating, (5.57) over all possible values of   $z$, that is, $ \Pr(x+y) = \int \limits_{-\infty}^{\infty} \Pr(x+y,z)\,dz  \quad\quad\quad (5.58) $ When we integrate (5.57) with respect to $z$, the factor   $\exp(-z^2/2)$ integrates to $\sqrt(2\pi)$, and we find $ \Pr(x+y) \propto \exp\left[-\frac{1}{2}\left(\frac{(x+y)^2}{(\sigma_x^2 + \sigma_y^2)}\right)\right] \quad\quad\quad $ (5.59)","I'm reading the book ""Introduction to Error Analysis"" by John R. Taylor. The author is discussing the probability distribution of a sum of two normally-distributed random variables, and wants to show that if $x \sim N(0,\sigma_x^2)$ and $y\sim N(0,\sigma_y^2)$, then $x+y \sim N(0, \sigma_x^2 + \sigma_y^2)$. He proceeds to prove this, but either there's something I'm seriously missing, or the proof is extremely hand-wavey (or just plain wrong). In particular, I don't see how you can take a term involving $x$ and $y$, call it $z$, and then conveniently integrate w.r.t. $z$ as if it were independent of $x$ and $y$. I'm quoting the proof below, with some slight formatting modifications to make typing it out easier. Thank you for your help. $\Pr(x,y) \propto \exp\left[-\frac{1}{2}\left(\frac{x^2}{\sigma_x^2} +  \frac{y^2}{\sigma_y^2}\right)\right]\quad\quad\quad$ (5.53) Knowing the probability of obtaining any $x$ and $y$, we can now   calculate the probability for any given value of $x+y$. The first step   is to rewrite the exponent in (5.53) in terms of the variable of   interest, $x+y$. This step can be done using the identity (which you   can easily verify) $ \frac{x^2}{A} + \frac{y^2}{B} = \frac{(x+y)^2}{A+B} + \frac{(Bx-Ay)^2}{AB(A+B)}  \quad\quad\quad$ (5.54) $= \frac{(x+y)^2}{A+B} + z^2 \quad\quad\quad (5.55) $ In the second line I have introduced the abbreviation $z^2$ for the   second term on the right of (5.54) because its value does not interest   us anyway. If we substitute (5.55) into (5.53), replacing $A$ with $\sigma_x^2$   and $B$ with $\sigma_y^2$, we obtain: $ \Pr(x,y) \propto  \exp\left[-\frac{1}{2}\left(\frac{(x+y)^2}{(\sigma_x^2 +  \sigma_y^2)}\right) - \frac{z^2}{2} \right]\quad\quad\quad$ (5.56) This probability for obtaining given values of $x$ and $y$ can just as   well be viewed as the probability of obtaining given values of $x+y$   and $z$. Thus, we can rewrite (5.56) as $ \Pr(x+y,z) \propto  \exp\left[-\frac{1}{2}\left(\frac{(x+y)^2}{(\sigma_x^2 +  \sigma_y^2)}\right)\right] \exp\left[- \frac{z^2}{2}\right]  \quad\quad\quad$ (5.57) Finally, what we want is the probability of obtaining a given value of   $x+y$ irrespective of the value of $z$. This probability is obtained   by summing, or rather integrating, (5.57) over all possible values of   $z$, that is, $ \Pr(x+y) = \int \limits_{-\infty}^{\infty} \Pr(x+y,z)\,dz  \quad\quad\quad (5.58) $ When we integrate (5.57) with respect to $z$, the factor   $\exp(-z^2/2)$ integrates to $\sqrt(2\pi)$, and we find $ \Pr(x+y) \propto \exp\left[-\frac{1}{2}\left(\frac{(x+y)^2}{(\sigma_x^2 + \sigma_y^2)}\right)\right] \quad\quad\quad $ (5.59)",,"['probability', 'statistics', 'proof-verification', 'normal-distribution', 'fake-proofs']"
53,finding the common variance of a die throw,finding the common variance of a die throw,,"would appreciate your help with this question: a regular die is being thrown 21 times. we define: $x_1$ - the number of throws we obtained 1 or 2. $x_2$ - the number of throws we obtained 3,4,5,6. $y_i = (-1)^{x_i}$ for i=1,2 how to calculate the covariance of $y_1$ and $y_2$? my attempt: we see that $y_1 = (-1)^{x_1}$ and $y_2 = (-1)^{x_2}$, which means that: $cov(y_1,y_2) = E[(y_1 -E[y_1])(y_2-E[y_2])]$. so when i plugged $y_1$ and $y_2$ into $E[X] = \sum_x x p_X(x)$ it becomes a huge mess and i'm no where near a solution. is there an elegeant way to solve it without getting to a huge mess? thank you very much for your help, really hoping to learn how to approach this kind of questions efficiently without getting into a huge mess. would really appreciate learning the correct way.","would appreciate your help with this question: a regular die is being thrown 21 times. we define: $x_1$ - the number of throws we obtained 1 or 2. $x_2$ - the number of throws we obtained 3,4,5,6. $y_i = (-1)^{x_i}$ for i=1,2 how to calculate the covariance of $y_1$ and $y_2$? my attempt: we see that $y_1 = (-1)^{x_1}$ and $y_2 = (-1)^{x_2}$, which means that: $cov(y_1,y_2) = E[(y_1 -E[y_1])(y_2-E[y_2])]$. so when i plugged $y_1$ and $y_2$ into $E[X] = \sum_x x p_X(x)$ it becomes a huge mess and i'm no where near a solution. is there an elegeant way to solve it without getting to a huge mess? thank you very much for your help, really hoping to learn how to approach this kind of questions efficiently without getting into a huge mess. would really appreciate learning the correct way.",,"['probability', 'statistics', 'discrete-mathematics', 'covariance']"
54,Scaling data sets to match each other with least error,Scaling data sets to match each other with least error,,"I have two data sets: A & B with values: $a_1,a_2...a_n$ and $b_1,b_2...b_n$ that represent the values for the same elements ($x_1,x_2...x_n$). For instance, $x_1 = a_1$ in the first data set and $x_1 = b_1$ in the second data set. These data sets have very different values, but its relative values should be the same ($\frac{a_i}{a_j}=\frac{b_i}{b_j}$). This is not the case because the data come from experiments. I would like to obtain a scaling constant to multiply data set B to match data set A with the least error. What is the best method to do this? Edit: Also, each value in B has an uncertainty measurement, how can I take into a account this effect? As I must be more focused on matching the values that have the least uncertainty.","I have two data sets: A & B with values: $a_1,a_2...a_n$ and $b_1,b_2...b_n$ that represent the values for the same elements ($x_1,x_2...x_n$). For instance, $x_1 = a_1$ in the first data set and $x_1 = b_1$ in the second data set. These data sets have very different values, but its relative values should be the same ($\frac{a_i}{a_j}=\frac{b_i}{b_j}$). This is not the case because the data come from experiments. I would like to obtain a scaling constant to multiply data set B to match data set A with the least error. What is the best method to do this? Edit: Also, each value in B has an uncertainty measurement, how can I take into a account this effect? As I must be more focused on matching the values that have the least uncertainty.",,"['statistics', 'statistical-inference', 'machine-learning']"
55,confusion in the combinatorial analysis in the game of baccarat,confusion in the combinatorial analysis in the game of baccarat,,"Update (14th Jun 18) My argument here is that if we assume all hands are 6-card hands, we have created a lot of extra invalid combinations to the ""total"". For example in this game, an extra of 37446746112/31=1207959552 combinations were created. Am I correct? OP Baccarat is a popular CASINO game played by a lot of people. One of my friend recently asked me a probability question and further brought my interest in this as I have a PhD in Statistics. I read on this page where Combinatorial Analysis is used. Looking at the example here, Player’s two cards: 1, 4 Banker’s two cards: 2, 4 Card 5: 2 (dealt to Player) Card 6: 7 (not used) I understand the method of working out the number 4030726144. But my question is Why would we consider the combinations of the SIX cards? As we only use FIVE card for this hand (according to the rules of this game). The answer for this hand would be 4030726144/32 = 125960192. It seems to me that the total 4,998,398,275,503,360 is an agreed number where it's been referred to on many sites, for example, the calculator seem to be using the same method. But none of which seem to explain why. As far as I am concerned, we should only consider VALID hands. So the example above should only be considered as a FIVE-card-hand Can someone help me understand this better?","Update (14th Jun 18) My argument here is that if we assume all hands are 6-card hands, we have created a lot of extra invalid combinations to the ""total"". For example in this game, an extra of 37446746112/31=1207959552 combinations were created. Am I correct? OP Baccarat is a popular CASINO game played by a lot of people. One of my friend recently asked me a probability question and further brought my interest in this as I have a PhD in Statistics. I read on this page where Combinatorial Analysis is used. Looking at the example here, Player’s two cards: 1, 4 Banker’s two cards: 2, 4 Card 5: 2 (dealt to Player) Card 6: 7 (not used) I understand the method of working out the number 4030726144. But my question is Why would we consider the combinations of the SIX cards? As we only use FIVE card for this hand (according to the rules of this game). The answer for this hand would be 4030726144/32 = 125960192. It seems to me that the total 4,998,398,275,503,360 is an agreed number where it's been referred to on many sites, for example, the calculator seem to be using the same method. But none of which seem to explain why. As far as I am concerned, we should only consider VALID hands. So the example above should only be considered as a FIVE-card-hand Can someone help me understand this better?",,"['probability', 'combinatorics', 'statistics', 'combinatorial-game-theory', 'card-games']"
56,$\alpha$-trimmed mean vs. sample mean (comprehension questions),-trimmed mean vs. sample mean (comprehension questions),\alpha,"Suppose that we have $n$ observations : $ x_1, ...,x_n$. ( sort them ). We get $ x_{(1)}, ...,x_{(n)}$ For $\alpha \in [0,\frac{1}{2}) $ we define the $\alpha$-trimmed mean : $$ T_{\alpha}=\frac{1}{n-2\lceil{\alpha n}\rceil}  \sum_{i=\lceil{\alpha n}\rceil +1}^{n-\lceil{\alpha n}\rceil} x_{(i)}$$ and the sample mean is : $$ S= \frac{1}{n}  \sum_{i=1}^{n} x_{(i)} $$ $1)$ What happens when a fraction of the observations, say $k$ observations, with $k < \alpha\cdot n$, is huge? Illustrate the effect for $k$ observations tending to infinity on the sample mean and on the $\alpha$-trimmed mean. Explain why the $\alpha$-trimmed mean may be problematic in real life applications   compared to the sample mean. $2)$ Suppose in the setting of part $1)$, that $k \geq 2n \cdot\alpha $. How does this affect the $\alpha$-trimmed mean? $3)$ Explain why the trimmed mean may be advantageous compared to the sample   mean in a real life application, with respect to its robustness. My idea: For $1)$ I've considered an example. If we have $n=9$ , $\alpha = 0.3$ ( $k$ has to be $2$ then) with: $x_{(1)}=4,x_{(2)}=7,x_{(3)}=8,x{(4)}_=10,x_{(5)}=12,x_{(6)}=23,x_{(7)}=231,x_{(8)}=323333,x_{(9)}=4567564$ Then: $S ≈ 543466$, while $T_{0.3}= 15$. If we now replace $x_{(8)}$ and $x_{(9)}$ by something higher [for example: $400.000$ and $987654321$] (because we want that the $k$ observations tends to infinity ) then we get $S ≈ 109783846$, while $T_{0.3}=15$. So my answer for $1)$ would be that $S$ tending to infinity, while the $k$ observations has no effect on $T_{0.3}$,right? Like you see I have used an example here. Can you help me with the illustration? for the second question of $1)$ I will consider the example above with $\alpha = 0,4$. Then only $x_{(5)}$ would be left. So $T_{0.4} =12 $.  So only one observation decides what the trimmed mean is. This is obviously not good, if you want to make a statement of a certain situation. Is this the answer, which is expected? $2)$ I would say that $T_{\alpha}$ tends to infinity? Because at least one of the observations, which tending to infinity is in $T_{\alpha}$. But my answer is really short? Did I really figure out what the exercise wants to show me? $3)$ So the trimmed mean is obviously less sensitive to outliers than the sample mean and still illustrates the central tendency. ( see that in $(1)$ ) But to be honest: I don't figured out which advantage ""hides"" in $(2)$. Can you help me here? Thank you for your help and correction.","Suppose that we have $n$ observations : $ x_1, ...,x_n$. ( sort them ). We get $ x_{(1)}, ...,x_{(n)}$ For $\alpha \in [0,\frac{1}{2}) $ we define the $\alpha$-trimmed mean : $$ T_{\alpha}=\frac{1}{n-2\lceil{\alpha n}\rceil}  \sum_{i=\lceil{\alpha n}\rceil +1}^{n-\lceil{\alpha n}\rceil} x_{(i)}$$ and the sample mean is : $$ S= \frac{1}{n}  \sum_{i=1}^{n} x_{(i)} $$ $1)$ What happens when a fraction of the observations, say $k$ observations, with $k < \alpha\cdot n$, is huge? Illustrate the effect for $k$ observations tending to infinity on the sample mean and on the $\alpha$-trimmed mean. Explain why the $\alpha$-trimmed mean may be problematic in real life applications   compared to the sample mean. $2)$ Suppose in the setting of part $1)$, that $k \geq 2n \cdot\alpha $. How does this affect the $\alpha$-trimmed mean? $3)$ Explain why the trimmed mean may be advantageous compared to the sample   mean in a real life application, with respect to its robustness. My idea: For $1)$ I've considered an example. If we have $n=9$ , $\alpha = 0.3$ ( $k$ has to be $2$ then) with: $x_{(1)}=4,x_{(2)}=7,x_{(3)}=8,x{(4)}_=10,x_{(5)}=12,x_{(6)}=23,x_{(7)}=231,x_{(8)}=323333,x_{(9)}=4567564$ Then: $S ≈ 543466$, while $T_{0.3}= 15$. If we now replace $x_{(8)}$ and $x_{(9)}$ by something higher [for example: $400.000$ and $987654321$] (because we want that the $k$ observations tends to infinity ) then we get $S ≈ 109783846$, while $T_{0.3}=15$. So my answer for $1)$ would be that $S$ tending to infinity, while the $k$ observations has no effect on $T_{0.3}$,right? Like you see I have used an example here. Can you help me with the illustration? for the second question of $1)$ I will consider the example above with $\alpha = 0,4$. Then only $x_{(5)}$ would be left. So $T_{0.4} =12 $.  So only one observation decides what the trimmed mean is. This is obviously not good, if you want to make a statement of a certain situation. Is this the answer, which is expected? $2)$ I would say that $T_{\alpha}$ tends to infinity? Because at least one of the observations, which tending to infinity is in $T_{\alpha}$. But my answer is really short? Did I really figure out what the exercise wants to show me? $3)$ So the trimmed mean is obviously less sensitive to outliers than the sample mean and still illustrates the central tendency. ( see that in $(1)$ ) But to be honest: I don't figured out which advantage ""hides"" in $(2)$. Can you help me here? Thank you for your help and correction.",,"['statistics', 'means']"
57,Which estimator is better here?,Which estimator is better here?,,"Let $X_1, X_2, \ldots, X_n$ be a random sample from a population with pmf $$P_\theta(X=x)=\theta^x(1-\theta)^{1-x}, \quad x=0,1; \qquad 0 \leq \theta \leq \frac{1}{2}$$ Compare the method of moment estimator (MME) and the maximun likelihood estimator (MLE), which one is preferred? Since $E(X)=\theta$, so $\hat{\theta}_\text{MME}=\bar{X}$ anyway (what if $\bar{X} > \frac{1}{2}$?). And by writing out the likelihood function and taking derivative I got $$\hat{\theta}_\text{MLE}=\begin{cases}\bar{X} & \text{ if }0\leq \bar{X} \leq \frac{1}{2}\\ \frac{1}{2} & \text{ if } \bar{X}>\frac{1}{2}\end{cases}$$ It seems the MLE is better, but is there a justification here?","Let $X_1, X_2, \ldots, X_n$ be a random sample from a population with pmf $$P_\theta(X=x)=\theta^x(1-\theta)^{1-x}, \quad x=0,1; \qquad 0 \leq \theta \leq \frac{1}{2}$$ Compare the method of moment estimator (MME) and the maximun likelihood estimator (MLE), which one is preferred? Since $E(X)=\theta$, so $\hat{\theta}_\text{MME}=\bar{X}$ anyway (what if $\bar{X} > \frac{1}{2}$?). And by writing out the likelihood function and taking derivative I got $$\hat{\theta}_\text{MLE}=\begin{cases}\bar{X} & \text{ if }0\leq \bar{X} \leq \frac{1}{2}\\ \frac{1}{2} & \text{ if } \bar{X}>\frac{1}{2}\end{cases}$$ It seems the MLE is better, but is there a justification here?",,"['statistics', 'statistical-inference', 'parameter-estimation', 'mean-square-error']"
58,Wilcoxon test statistic,Wilcoxon test statistic,,"I learned WSR (Wilcoxon signed rank test) several years ago, and today one of my friends suggest different test statistics on WSR. At first, I thought he was wrong; however, I did found some sources which were citing the positive rank sum as W test statistic. Such as these links suggests: http://courses.wcupa.edu/rbove/Berenson/CD-ROM%20Topics/topice-10_5.pdf http://www.stat.umn.edu/geyer/5601/notes/wilcox.pdf According to my undergrads stat, we choose the min(W+,W-) as the test statistic. for example: http://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Nonparametric/BS704_Nonparametric6.html On wiki, it suggest that W = abs(W+ minus W-) . https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test#Test_procedure Why does WSR test has so many ""alternative"" test statistics? Is there many versions of WSR? When to use which test statistics? I am confused now. Please share any insights with me, many thanks. # I would like to edit this question. I just tried to write functions to calculate z scores in r. using two equations below, I was able to get same absolute z-scores using Negative rank sum, Positive rank sum, or absolute rank sum: these data were replicates from an online source https://www.youtube.com/watch?v=TqCg2tb4wJ0 n =non-zero ranking sample size w+ = 75 w- = 16 |w| = 75-16=59 n = 13 for neg or pos z <- function(w,n){     (w-(n*(n+1)/4))/(sqrt((n*(n+1)*(2*n+1)/24))) } for absolute z1 <- function(w,n){     (w)/sqrt((n*(n+1)*(2*n+1))/6)   } z(75,13)   [1] 2.061627 z(16,13)   [1] -2.061627 z1(59,13)   [1] 2.061627 But I'm still confused with it... Should it considered to be irresponsible for articles and papers to use positive rank sum as w test statistics? Usually people use critical values sheet of w to determine the result right? http://users.stat.ufl.edu/~winner/tables/wilcox_signrank.pdf On the case above(the youtube link), if we use positive rank sum, the result would be completely opposite. Please let me know if I was thinking in the right direction.","I learned WSR (Wilcoxon signed rank test) several years ago, and today one of my friends suggest different test statistics on WSR. At first, I thought he was wrong; however, I did found some sources which were citing the positive rank sum as W test statistic. Such as these links suggests: http://courses.wcupa.edu/rbove/Berenson/CD-ROM%20Topics/topice-10_5.pdf http://www.stat.umn.edu/geyer/5601/notes/wilcox.pdf According to my undergrads stat, we choose the min(W+,W-) as the test statistic. for example: http://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Nonparametric/BS704_Nonparametric6.html On wiki, it suggest that W = abs(W+ minus W-) . https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test#Test_procedure Why does WSR test has so many ""alternative"" test statistics? Is there many versions of WSR? When to use which test statistics? I am confused now. Please share any insights with me, many thanks. # I would like to edit this question. I just tried to write functions to calculate z scores in r. using two equations below, I was able to get same absolute z-scores using Negative rank sum, Positive rank sum, or absolute rank sum: these data were replicates from an online source https://www.youtube.com/watch?v=TqCg2tb4wJ0 n =non-zero ranking sample size w+ = 75 w- = 16 |w| = 75-16=59 n = 13 for neg or pos z <- function(w,n){     (w-(n*(n+1)/4))/(sqrt((n*(n+1)*(2*n+1)/24))) } for absolute z1 <- function(w,n){     (w)/sqrt((n*(n+1)*(2*n+1))/6)   } z(75,13)   [1] 2.061627 z(16,13)   [1] -2.061627 z1(59,13)   [1] 2.061627 But I'm still confused with it... Should it considered to be irresponsible for articles and papers to use positive rank sum as w test statistics? Usually people use critical values sheet of w to determine the result right? http://users.stat.ufl.edu/~winner/tables/wilcox_signrank.pdf On the case above(the youtube link), if we use positive rank sum, the result would be completely opposite. Please let me know if I was thinking in the right direction.",,"['statistics', 'hypothesis-testing']"
59,"calculate $\operatorname{cov}(X,Y)$ from $f_{x,y}(x,y)$",calculate  from,"\operatorname{cov}(X,Y) f_{x,y}(x,y)","I have the following density function: $$f_{x, y}(x, y) = \begin{cases}2 & 0\leq x\leq y \leq 1\\ 0 & \text{otherwise}\end{cases}$$ We know that $\operatorname{cov}(X,Y) = E[(Y - EY)(X - EX)]$, therefore we need to calculate E[X] and E[Y]. $$f_x(x)=\int_x^1 2\,\mathrm dy = \big[2y\big]_x^1 = 2-x, \forall x\in[0, 1]$$ $$E[X] =  \int_0^1 x (2-x)\,\mathrm dx = \int_0^1 2x - x^2\,\mathrm dx= \left[\frac{2x^2}{2}-\frac{x^3}{3}\right]_0^1  = 1 - \frac{1}{3} = \frac23 $$ $$f_y(y) = \int_0^y\,\mathrm dx = \big[2x\big]_0^y = 2y, \forall y\in [0, 1]$$ $$E[Y] =  \int_0^1 y\cdot2y\,\mathrm dy= \int_0^1 2y^2\,\mathrm dy= \left[\frac{2y^3}{3}\right]_0^1 = \frac23$$ However, the provided solution states that $E[X]=\dfrac13$. Have I done a mistake or is the solution wrong? The continuation of the solution is: $$\mathrm{cov}(X,Y) = \int_0^1\int_x^1(x-\frac 13)(y- \frac 23) \times 2\,\mathrm dy\,\mathrm dx$$ Where does the $\underline{2\,\mathrm dy\,\mathrm dx}$ come from?","I have the following density function: $$f_{x, y}(x, y) = \begin{cases}2 & 0\leq x\leq y \leq 1\\ 0 & \text{otherwise}\end{cases}$$ We know that $\operatorname{cov}(X,Y) = E[(Y - EY)(X - EX)]$, therefore we need to calculate E[X] and E[Y]. $$f_x(x)=\int_x^1 2\,\mathrm dy = \big[2y\big]_x^1 = 2-x, \forall x\in[0, 1]$$ $$E[X] =  \int_0^1 x (2-x)\,\mathrm dx = \int_0^1 2x - x^2\,\mathrm dx= \left[\frac{2x^2}{2}-\frac{x^3}{3}\right]_0^1  = 1 - \frac{1}{3} = \frac23 $$ $$f_y(y) = \int_0^y\,\mathrm dx = \big[2x\big]_0^y = 2y, \forall y\in [0, 1]$$ $$E[Y] =  \int_0^1 y\cdot2y\,\mathrm dy= \int_0^1 2y^2\,\mathrm dy= \left[\frac{2y^3}{3}\right]_0^1 = \frac23$$ However, the provided solution states that $E[X]=\dfrac13$. Have I done a mistake or is the solution wrong? The continuation of the solution is: $$\mathrm{cov}(X,Y) = \int_0^1\int_x^1(x-\frac 13)(y- \frac 23) \times 2\,\mathrm dy\,\mathrm dx$$ Where does the $\underline{2\,\mathrm dy\,\mathrm dx}$ come from?",,"['probability', 'statistics', 'covariance', 'bivariate-distributions']"
60,Estimate of the speed of convergence to normal of the average of binomially distributioned variables,Estimate of the speed of convergence to normal of the average of binomially distributioned variables,,"Let us fix $n$, and consider a sequence of identical, independent random variables with binomial distributions with $n$ trials and probability of success $p=1/2$. Are there estimate on how fast the average of the sequence will converge to a normal distribution? (I mean, more accurate than application of the standard results.)","Let us fix $n$, and consider a sequence of identical, independent random variables with binomial distributions with $n$ trials and probability of success $p=1/2$. Are there estimate on how fast the average of the sequence will converge to a normal distribution? (I mean, more accurate than application of the standard results.)",,"['probability', 'statistics']"
61,Upper & Lower Bound on P-Value using printed t table,Upper & Lower Bound on P-Value using printed t table,,"Suppose we have a sample size of $n=25,$ and want to test $H_0 :\mu = 0$ against $H_A : \mu > 0$ using a t test at the 5% level of significance. The first question was Suppose the t-statistic were calculated to be $t = 1.972.$ What is the greatest upper & lower bound for the corresponding p-value that is implied by your critical value table? And my answer was $0.025 <$ p value $< 0.050.$ However, the next part ask Using a normal approximation to the null distribution of the t statistic, what is the greatest upper & lower bound for the p-value that is implied? I'm not sure how to do this? Do I use the z table but not quite sure how.","Suppose we have a sample size of $n=25,$ and want to test $H_0 :\mu = 0$ against $H_A : \mu > 0$ using a t test at the 5% level of significance. The first question was Suppose the t-statistic were calculated to be $t = 1.972.$ What is the greatest upper & lower bound for the corresponding p-value that is implied by your critical value table? And my answer was $0.025 <$ p value $< 0.050.$ However, the next part ask Using a normal approximation to the null distribution of the t statistic, what is the greatest upper & lower bound for the p-value that is implied? I'm not sure how to do this? Do I use the z table but not quite sure how.",,"['statistics', 'normal-distribution', 'hypothesis-testing']"
62,Clarification on Periodicity of Markov Chains,Clarification on Periodicity of Markov Chains,,"Given the Markov Chain:  \begin{bmatrix} 0 & 1 & 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 1 & 0 & 0\\ 0.3 & 0 & 0 & 0.7 & 0 & 0\\ 0 & 1 & 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 0.4 & 0 & 0.6\\ 0 & 0 & 0 & 0 & 1 & 0 \end{bmatrix} The question asks to find the periodicity of each class, and I figured out all the states except state 1 and 3. I believe the period of both of them are 0 i.e. no period since we can't return to either 1 or 3 if we start at these states.  However, since all states communicate with itself, does it mean the period of 1 and 3 is 1?","Given the Markov Chain:  \begin{bmatrix} 0 & 1 & 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 1 & 0 & 0\\ 0.3 & 0 & 0 & 0.7 & 0 & 0\\ 0 & 1 & 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 0.4 & 0 & 0.6\\ 0 & 0 & 0 & 0 & 1 & 0 \end{bmatrix} The question asks to find the periodicity of each class, and I figured out all the states except state 1 and 3. I believe the period of both of them are 0 i.e. no period since we can't return to either 1 or 3 if we start at these states.  However, since all states communicate with itself, does it mean the period of 1 and 3 is 1?",,"['statistics', 'stochastic-processes', 'markov-chains']"
63,"Find constant,PDF,mean value from CDF","Find constant,PDF,mean value from CDF",,"Let $F(x)$ be a cumulative distribution function where, $F(x) = \begin{cases} 0, & \mbox{if } x\leq\mbox{-1} \\ \frac{1}{2}(x+1)^2, & \mbox{if } -1<\mbox{x}\leq0 \\ 1-\frac{1}{2}(x-1)^2, & \mbox{if }  0<\mbox{x}\leq1 \\ c, & \mbox{if } 1<\mbox{x} \end{cases}$ I found by definition $c=1$ with the limits at $-\infty$ and $+\infty$. The excersice tells you that the PDF function is continuous so i took the derivative of CDF and found $f(x) = \begin{cases} 0, & \mbox{if } x\leq\mbox{-1} \\ x+1, & \mbox{if } -1<\mbox{x}\leq0 \\ 1-x, & \mbox{if }  0<\mbox{x}\leq1 \\ 0, & \mbox{if } 1<\mbox{x} \end{cases}$ Then it asks you to find the mean value $E[X]$. I took the integral and found $0$. I would appreciate it if someone wants to help me correct my solution if I am wrong.","Let $F(x)$ be a cumulative distribution function where, $F(x) = \begin{cases} 0, & \mbox{if } x\leq\mbox{-1} \\ \frac{1}{2}(x+1)^2, & \mbox{if } -1<\mbox{x}\leq0 \\ 1-\frac{1}{2}(x-1)^2, & \mbox{if }  0<\mbox{x}\leq1 \\ c, & \mbox{if } 1<\mbox{x} \end{cases}$ I found by definition $c=1$ with the limits at $-\infty$ and $+\infty$. The excersice tells you that the PDF function is continuous so i took the derivative of CDF and found $f(x) = \begin{cases} 0, & \mbox{if } x\leq\mbox{-1} \\ x+1, & \mbox{if } -1<\mbox{x}\leq0 \\ 1-x, & \mbox{if }  0<\mbox{x}\leq1 \\ 0, & \mbox{if } 1<\mbox{x} \end{cases}$ Then it asks you to find the mean value $E[X]$. I took the integral and found $0$. I would appreciate it if someone wants to help me correct my solution if I am wrong.",,"['integration', 'statistics']"
64,Proving that the variance of expectation is greater than the variance of sample mean.,Proving that the variance of expectation is greater than the variance of sample mean.,,"We have independent random variables $X_1,\cdots,X_n$, with $\mathbb{E}[X_i]=\mu$ and $Var[X_i]=\sigma^2$ $\forall i$ and the random variable $Z$ defined as $Z=\sum_{i=1}^{n}c_iX_i$ In the previous part of the question, we are asked to provide a condition on the constant $c_i$ that makes $Z$ and unbiased estimation of $\mu$ which I got as $\sum c_i=1$ The final part which I'm stuck on requires us to show that  $Var[Z]\geq Var[\bar{X}]$ where $\bar{X}$ is the sample mean. My suspicions are that the point of the question is to show that the variance of the expectation is always greater equal to the variance of the sample mean (Although I could be wrong). I tried starting with the Cauchy Schwarz inequality $|\sum X_ic_i|\leq \sqrt{\sum X_i^2}\sqrt{\sum c_i^2}$ $Z^2\leq \sum X_i^2\cdot\sum c_i^2$ but cant seem to get anywhere.","We have independent random variables $X_1,\cdots,X_n$, with $\mathbb{E}[X_i]=\mu$ and $Var[X_i]=\sigma^2$ $\forall i$ and the random variable $Z$ defined as $Z=\sum_{i=1}^{n}c_iX_i$ In the previous part of the question, we are asked to provide a condition on the constant $c_i$ that makes $Z$ and unbiased estimation of $\mu$ which I got as $\sum c_i=1$ The final part which I'm stuck on requires us to show that  $Var[Z]\geq Var[\bar{X}]$ where $\bar{X}$ is the sample mean. My suspicions are that the point of the question is to show that the variance of the expectation is always greater equal to the variance of the sample mean (Although I could be wrong). I tried starting with the Cauchy Schwarz inequality $|\sum X_ic_i|\leq \sqrt{\sum X_i^2}\sqrt{\sum c_i^2}$ $Z^2\leq \sum X_i^2\cdot\sum c_i^2$ but cant seem to get anywhere.",,"['statistics', 'expectation', 'parameter-estimation', 'cauchy-schwarz-inequality']"
65,"Show that MLE of $\alpha$ is unique when $X_i \sim \operatorname{Weibull}(\alpha,\theta)$",Show that MLE of  is unique when,"\alpha X_i \sim \operatorname{Weibull}(\alpha,\theta)","Let $X_1,\dots, X_n$ have Weibull distribution with pdf $f(x) = \frac{\alpha}{\theta}x^{\alpha-1}e^{-\frac{x^\alpha}{\theta}}$ . I'm trying to show that there is an unique solution for $\hat{\alpha}$ , the MLE of $\alpha$ . After deriving the likelihood equations,my problem is on showing that: $h'(\alpha) = \dfrac{\sum x_i^\alpha \, \sum x_i^\alpha (\log \, x_i)^2 -(\sum x_i^\alpha\log x_i)^2}{(\sum x_i^\alpha)^2}+\dfrac{1}{\alpha^2}>0$ so that I can argue, together with other conditions, that the root of likelihood equation is unique. My attempt was to rewrite $h'(\alpha) $ as: $h'(\alpha) = \sum(\log  x_i)^2 \dfrac{e^{\alpha \log x_i}}{\sum e^{\alpha \log  ,x_i}} - \left(\sum \log  x_i \dfrac{e^{\alpha \log  x_i}}{\sum e^{\alpha \log x_i}} \right)^2 + \dfrac{1}{\alpha^2}$ and use Cauchy-Schwarz on $\left(\sum \log   x_i \dfrac{e^{\alpha \log x_i}}{\sum e^{\alpha \log x_i}} \right)^2$ to argue that: $\sum (\log x_i)^2\sum\left(\dfrac{e^{\alpha\log x_i}}{\sum e^{\alpha\log x_i}}\right)^2  - \left(\sum\log x_i \dfrac{e^{\alpha\log x_i}}{\sum e^{\alpha \log x_i}}\right)^2\geq 0$ But then I could not show that $\sum(\log x_i)^2\dfrac{e^{\alpha\log  x_i}}{\sum e^{\alpha\log x_i}}\geq \sum(\log x_i)^2\sum\left(\dfrac{e^{\alpha\log x_i}}{\sum e^{\alpha\log x_i}}\right)^2 $ to argue that $h'(\alpha) > 0$ (since $\frac{1}{\alpha^2}>0$ , so that I don't have to worry about it). Any suggestions on how to tackle this problem? Obs: the book says that $h'(\alpha)>0$ , but it doesn't show how, it simple states that.","Let have Weibull distribution with pdf . I'm trying to show that there is an unique solution for , the MLE of . After deriving the likelihood equations,my problem is on showing that: so that I can argue, together with other conditions, that the root of likelihood equation is unique. My attempt was to rewrite as: and use Cauchy-Schwarz on to argue that: But then I could not show that to argue that (since , so that I don't have to worry about it). Any suggestions on how to tackle this problem? Obs: the book says that , but it doesn't show how, it simple states that.","X_1,\dots, X_n f(x) = \frac{\alpha}{\theta}x^{\alpha-1}e^{-\frac{x^\alpha}{\theta}} \hat{\alpha} \alpha h'(\alpha) = \dfrac{\sum x_i^\alpha \, \sum x_i^\alpha (\log \, x_i)^2 -(\sum x_i^\alpha\log x_i)^2}{(\sum x_i^\alpha)^2}+\dfrac{1}{\alpha^2}>0 h'(\alpha)  h'(\alpha) = \sum(\log  x_i)^2 \dfrac{e^{\alpha \log x_i}}{\sum e^{\alpha \log  ,x_i}} - \left(\sum \log  x_i \dfrac{e^{\alpha \log  x_i}}{\sum e^{\alpha \log x_i}} \right)^2 + \dfrac{1}{\alpha^2} \left(\sum \log   x_i \dfrac{e^{\alpha \log x_i}}{\sum e^{\alpha \log x_i}} \right)^2 \sum (\log x_i)^2\sum\left(\dfrac{e^{\alpha\log x_i}}{\sum e^{\alpha\log x_i}}\right)^2  - \left(\sum\log x_i \dfrac{e^{\alpha\log x_i}}{\sum e^{\alpha \log x_i}}\right)^2\geq 0 \sum(\log x_i)^2\dfrac{e^{\alpha\log  x_i}}{\sum e^{\alpha\log x_i}}\geq \sum(\log x_i)^2\sum\left(\dfrac{e^{\alpha\log x_i}}{\sum e^{\alpha\log x_i}}\right)^2  h'(\alpha) > 0 \frac{1}{\alpha^2}>0 h'(\alpha)>0","['calculus', 'real-analysis', 'statistics', 'maximum-likelihood', 'cauchy-schwarz-inequality']"
66,Normal distribution Questioning [closed],Normal distribution Questioning [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question The weights of a group of children are approximately normally distributed with mean 15kg and standard deviation=1.75 kg  What proportion of the children will weigh 13 of or more? Can someone help me solve it?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question The weights of a group of children are approximately normally distributed with mean 15kg and standard deviation=1.75 kg  What proportion of the children will weigh 13 of or more? Can someone help me solve it?",,['statistics']
67,"For a random sample from the distribution $f(x)=e^{-(x-\theta)} , x>\theta$ , show that $2n[X_{(1)}-\theta]\sim\chi^2_{2}$","For a random sample from the distribution  , show that","f(x)=e^{-(x-\theta)} , x>\theta 2n[X_{(1)}-\theta]\sim\chi^2_{2}","Show that for a random sample of size $n$ from the distribution $f(x)=e^{-(x-\theta)} , x>\theta$ , $2n[X_{(1)}-\theta] \sim \chi^2_{2}$ distribution and $2\sum_{i=2}^{n}[X_{(i)}-X_{(1)}]$ also has the $\chi^2_{2n-2}$ distribution and is independent of the first statistic.   Here, $X_{(i)}$ is defined as the $i$ th order statistic. My approach: I did the following series of transformations: $(X_1,X_2,..,X_n) \rightarrow (Y_1,Y_2,...,Y_n) \rightarrow (Y_{(1)},Y_{(2)},...,Y_{(n)}) \rightarrow (U_1,U_2,...U_n)$ where $Y_i=X_i-\theta$ , $U_1=2nY_{(1)}$ and $U_{i}=2(Y_{(i)}-Y_{(1)}) \ \text{for i =2,3,...n}$ SO, first the joint pdf of $X_1,X_2,...X_n$ is given by $f(x_1,x_2,...x_n)=e^{-\sum_{i=1}^{n}(x_i-\theta)} I_{x_i > \theta}$ Again, you can see $f(y_1,y_2,..,y_n)=e^{-\sum y_i} I_{y_i>0}$ Now, the joint pdf of order statistics $f_{1,2,...n}(y_1,..y_n)=n!e^{-\sum y_i} I_{y_1<y_2<...<y_n}$ Now transforming to $U$, the jacobian of transformation comes to be $\frac{1}{n2^n}$ Thus, $f(u_1,u_2,..u_n)=\frac{(n-1)!}{2^n}e^{\frac{-\sum u_i}{2}}$ From here I can deduce $u_1 \sim \chi^2_{2}$ But I cannot deduce anything from the remaining. Help!","Show that for a random sample of size $n$ from the distribution $f(x)=e^{-(x-\theta)} , x>\theta$ , $2n[X_{(1)}-\theta] \sim \chi^2_{2}$ distribution and $2\sum_{i=2}^{n}[X_{(i)}-X_{(1)}]$ also has the $\chi^2_{2n-2}$ distribution and is independent of the first statistic.   Here, $X_{(i)}$ is defined as the $i$ th order statistic. My approach: I did the following series of transformations: $(X_1,X_2,..,X_n) \rightarrow (Y_1,Y_2,...,Y_n) \rightarrow (Y_{(1)},Y_{(2)},...,Y_{(n)}) \rightarrow (U_1,U_2,...U_n)$ where $Y_i=X_i-\theta$ , $U_1=2nY_{(1)}$ and $U_{i}=2(Y_{(i)}-Y_{(1)}) \ \text{for i =2,3,...n}$ SO, first the joint pdf of $X_1,X_2,...X_n$ is given by $f(x_1,x_2,...x_n)=e^{-\sum_{i=1}^{n}(x_i-\theta)} I_{x_i > \theta}$ Again, you can see $f(y_1,y_2,..,y_n)=e^{-\sum y_i} I_{y_i>0}$ Now, the joint pdf of order statistics $f_{1,2,...n}(y_1,..y_n)=n!e^{-\sum y_i} I_{y_1<y_2<...<y_n}$ Now transforming to $U$, the jacobian of transformation comes to be $\frac{1}{n2^n}$ Thus, $f(u_1,u_2,..u_n)=\frac{(n-1)!}{2^n}e^{\frac{-\sum u_i}{2}}$ From here I can deduce $u_1 \sim \chi^2_{2}$ But I cannot deduce anything from the remaining. Help!",,"['probability', 'probability-theory']"
68,The probability that Student $1$ performs better than Student $2$ on an examination,The probability that Student  performs better than Student  on an examination,1 2,"Suppose there's a exam with 5 questions. If the probability that Student $1$ correctly answers question $i$ is $P_{1.i}$, then $P_{1.1} = 0.3$ , $P_{1.2} = 0.4$ , $P_{1.3} = 0.9$, $P_{1.4} = 0.7$ , $P_{1.5} = 0.1$ For Student $2$, $P_{2.1} = 0.4$ , $P_{2.2} = 0.5$ , $P_{2.3} = 0.2$, $P_{2.4} = 0.8$ , $P_{2.5} = 0.1$ What is the probability that Student $1$ performs better than Student $2$ ? How to solve something like that? I want an expression to do this.","Suppose there's a exam with 5 questions. If the probability that Student $1$ correctly answers question $i$ is $P_{1.i}$, then $P_{1.1} = 0.3$ , $P_{1.2} = 0.4$ , $P_{1.3} = 0.9$, $P_{1.4} = 0.7$ , $P_{1.5} = 0.1$ For Student $2$, $P_{2.1} = 0.4$ , $P_{2.2} = 0.5$ , $P_{2.3} = 0.2$, $P_{2.4} = 0.8$ , $P_{2.5} = 0.1$ What is the probability that Student $1$ performs better than Student $2$ ? How to solve something like that? I want an expression to do this.",,"['probability', 'statistics']"
69,Proving an inequality based on the sum of uniform random variables.,Proving an inequality based on the sum of uniform random variables.,,"Let we have $X_{1},.....,X_{100}$ be iid random variable from $U(-0.5,0.5)$. Then, prove using the chebychev inequality $P(T^2\geq25)\leq\frac{1}{3}$ Where $T = X_{1}+....+X_{100}$ My approach The inequality can be written as: $1-P(T^2\leq25)\leq\frac{1}{3}$ implies that $P(T^2\leq25)\geq\frac{2}{3}$ $P(-5\leq T\leq 5)\geq \frac{2}{3}$ I can make the T as sum of Uniform random variable with parameters $U(0,1)$. After that, we can use Irwin hall distribution of sum of iid $U(0,1)$ random variables. After adjusting terms, $P(-5-50\leq T-50\leq 5-50)\geq \frac{2}{3}$ $P(-55\leq T-50\leq -45)\geq \frac{2}{3}$ $T-50$ will be sum of 100 $U(0,1)$ iid random variables with mean $50$ and variance $\frac{100}{12}$. But now, chebychev inequality doesn't seems to be applicable. From here, I am not able to proceed. Any help?","Let we have $X_{1},.....,X_{100}$ be iid random variable from $U(-0.5,0.5)$. Then, prove using the chebychev inequality $P(T^2\geq25)\leq\frac{1}{3}$ Where $T = X_{1}+....+X_{100}$ My approach The inequality can be written as: $1-P(T^2\leq25)\leq\frac{1}{3}$ implies that $P(T^2\leq25)\geq\frac{2}{3}$ $P(-5\leq T\leq 5)\geq \frac{2}{3}$ I can make the T as sum of Uniform random variable with parameters $U(0,1)$. After that, we can use Irwin hall distribution of sum of iid $U(0,1)$ random variables. After adjusting terms, $P(-5-50\leq T-50\leq 5-50)\geq \frac{2}{3}$ $P(-55\leq T-50\leq -45)\geq \frac{2}{3}$ $T-50$ will be sum of 100 $U(0,1)$ iid random variables with mean $50$ and variance $\frac{100}{12}$. But now, chebychev inequality doesn't seems to be applicable. From here, I am not able to proceed. Any help?",,"['statistics', 'probability-distributions', 'distribution-theory']"
70,Why is a term that comes out of a variance bracket is squared?,Why is a term that comes out of a variance bracket is squared?,,I am in a course on data analysis. The following statement is made in the notes made available to us by our professor: $$ \text{Var}[a] = \text{Var}[\bar{y} -b\bar{x}] = \text{Var}[\bar{y}]  + \text{Var}[b\bar{x}] = \dfrac{\sigma^2}{n} + {\color{red}{(\bar{x}^2)}}\text{Var}[b]$$ I have marked the place where I have doubt in red. This is the expression to determine the variance of point estimates in a simple linear regression model. Thank you.,I am in a course on data analysis. The following statement is made in the notes made available to us by our professor: $$ \text{Var}[a] = \text{Var}[\bar{y} -b\bar{x}] = \text{Var}[\bar{y}]  + \text{Var}[b\bar{x}] = \dfrac{\sigma^2}{n} + {\color{red}{(\bar{x}^2)}}\text{Var}[b]$$ I have marked the place where I have doubt in red. This is the expression to determine the variance of point estimates in a simple linear regression model. Thank you.,,"['statistics', 'regression', 'linear-regression']"
71,Bus arrival probability...,Bus arrival probability...,,"This question has two parts, Question one A municipal bus system, when operating perfectly on time, provide at any given bus stop every 30 min. A person arrive at a random time at bus stop. What is the average waiting time until the next bus arrives? The Answer Since buses are following uniform distribution the average waiting time will be 15 min. Question two If the busses become totally disorganized and random following Poisson random process what will be the average waiting time given that number of buses remains content I know the answer is 1/lambda, but how to find the lambda, is it still 15 min since the same number of busses are running. Can someone explain this to me!!! Thanks","This question has two parts, Question one A municipal bus system, when operating perfectly on time, provide at any given bus stop every 30 min. A person arrive at a random time at bus stop. What is the average waiting time until the next bus arrives? The Answer Since buses are following uniform distribution the average waiting time will be 15 min. Question two If the busses become totally disorganized and random following Poisson random process what will be the average waiting time given that number of buses remains content I know the answer is 1/lambda, but how to find the lambda, is it still 15 min since the same number of busses are running. Can someone explain this to me!!! Thanks",,"['probability', 'statistics', 'descriptive-statistics']"
72,Hypotheses testing without a standard deviation,Hypotheses testing without a standard deviation,,"So, there seems to be a gap in my knowledge somewhere... here's the question A species of a common butterfly with a large population occurs in two different types, light (type $L$) and dark (type $D$). A naturalist observes 10 of the butterflies in a particular wood, $2$ of which are type $L$ and $8$ are type $D$. The naturalist wishes to decide whether this sample provides significant evidence that the proportion of type L butterflies differs from the proportion of type $D$ butterflies in this wood. Is there evidence to reject the null hypothesis at the $5\%$ level? So I believe this requires the T distribution due to the small sample size. So using $\frac{X-\mu}{\frac{\sigma}{\sqrt{10}}}$. I take $X$ as $=5$ as it's half the size as the proportion of both $L$ and $D$ should be $=$. Then $\mu=2$ as that was the actual value and $n$ as $10$. But what would $\sigma$ be? Or am I approaching this wrong? is there a way to find the standard deviation from this?","So, there seems to be a gap in my knowledge somewhere... here's the question A species of a common butterfly with a large population occurs in two different types, light (type $L$) and dark (type $D$). A naturalist observes 10 of the butterflies in a particular wood, $2$ of which are type $L$ and $8$ are type $D$. The naturalist wishes to decide whether this sample provides significant evidence that the proportion of type L butterflies differs from the proportion of type $D$ butterflies in this wood. Is there evidence to reject the null hypothesis at the $5\%$ level? So I believe this requires the T distribution due to the small sample size. So using $\frac{X-\mu}{\frac{\sigma}{\sqrt{10}}}$. I take $X$ as $=5$ as it's half the size as the proportion of both $L$ and $D$ should be $=$. Then $\mu=2$ as that was the actual value and $n$ as $10$. But what would $\sigma$ be? Or am I approaching this wrong? is there a way to find the standard deviation from this?",,"['probability', 'statistics', 'probability-distributions', 'hypothesis-testing']"
73,Expectation with time series model,Expectation with time series model,,"Consider the adapted ARCH model: $X_t^2 = \alpha_0 + \alpha_1X_{t-1}^2+\eta_t$, where $\eta_t=(\epsilon_t^2-1)(\alpha_0+\alpha_1X_{t-1}^2)$ and $\epsilon_t \sim \mathcal{N}(0,1)$. My question is, how can I calculate $\mathbb{E}(\eta_tX_{t-s}^2)?$ I have tried simplifying but can't get to the desired result which should be zero... e.g. $$ \mathbb{E}(\eta_tX^2_{t-s})=\mathbb{E}(\eta_t(\alpha_0 + \alpha_1X_{t-1-s}^2+\eta_{t-s}))=\mathbb{E}(((\epsilon_t^2-1)(\alpha_0+\alpha_1X_{t-1}^2))(\alpha_0 + \alpha_1X_{t-1-s}^2+\eta_{t-s}))$$ Not sure if i'm tackling this the wrong way, because this becomes quite messy, am i missing something ? Note I have calculated $\mathbb{E}(\eta_t)=0$.","Consider the adapted ARCH model: $X_t^2 = \alpha_0 + \alpha_1X_{t-1}^2+\eta_t$, where $\eta_t=(\epsilon_t^2-1)(\alpha_0+\alpha_1X_{t-1}^2)$ and $\epsilon_t \sim \mathcal{N}(0,1)$. My question is, how can I calculate $\mathbb{E}(\eta_tX_{t-s}^2)?$ I have tried simplifying but can't get to the desired result which should be zero... e.g. $$ \mathbb{E}(\eta_tX^2_{t-s})=\mathbb{E}(\eta_t(\alpha_0 + \alpha_1X_{t-1-s}^2+\eta_{t-s}))=\mathbb{E}(((\epsilon_t^2-1)(\alpha_0+\alpha_1X_{t-1}^2))(\alpha_0 + \alpha_1X_{t-1-s}^2+\eta_{t-s}))$$ Not sure if i'm tackling this the wrong way, because this becomes quite messy, am i missing something ? Note I have calculated $\mathbb{E}(\eta_t)=0$.",,"['statistics', 'stochastic-processes', 'expectation', 'time-series']"
74,"Computation of $P(3X+2Y < Z-W)$ when $W,X,Y,Z$ are independent normal variables",Computation of  when  are independent normal variables,"P(3X+2Y < Z-W) W,X,Y,Z","If you are given this following problem. $W,X,Y,Z$ are independent random variables with mean $= 1$ and standard deviation also equal to $1$. How would you compute this particular value: $P(3X+2Y < Z-W)$? Integration is easy, but I am having trouble setting up the computation.","If you are given this following problem. $W,X,Y,Z$ are independent random variables with mean $= 1$ and standard deviation also equal to $1$. How would you compute this particular value: $P(3X+2Y < Z-W)$? Integration is easy, but I am having trouble setting up the computation.",,"['probability', 'statistics', 'random-variables', 'normal-distribution']"
75,"CTMC: If the transition probability is >0 at one moment, then it is also >0 from that moment onwards","CTMC: If the transition probability is >0 at one moment, then it is also >0 from that moment onwards",,"Assume that $\{X_t:t\geq0\}$ is a continuous-time Markov chain with values on a discrete (countable, but possibly not finite) set $S$. Notation: for $i,j\in S$ and $t\geq0$, $p_{ij}(t):=\mathrm{P}\{X_t=j|X_0=i\}$. I want to prove that, for fixed $i$ and $j$ in $S$, the existence of a $s>0$ so that $p_{ij}(s)>0$ implies $\forall t>s, p_{ij}(t)>0$. I've tried lots of things (within my limited knowledge on the subject) and researched as far as I could, but I can't figure it out and I'm extremely frustrated because it seems really easy. I'll greatly appreciate detailed answers, since I'm afraid of not understanding the intermediate steps. EDIT: As I predicted, it's actually quite simple, but I still want to understand all the details (see comments below).","Assume that $\{X_t:t\geq0\}$ is a continuous-time Markov chain with values on a discrete (countable, but possibly not finite) set $S$. Notation: for $i,j\in S$ and $t\geq0$, $p_{ij}(t):=\mathrm{P}\{X_t=j|X_0=i\}$. I want to prove that, for fixed $i$ and $j$ in $S$, the existence of a $s>0$ so that $p_{ij}(s)>0$ implies $\forall t>s, p_{ij}(t)>0$. I've tried lots of things (within my limited knowledge on the subject) and researched as far as I could, but I can't figure it out and I'm extremely frustrated because it seems really easy. I'll greatly appreciate detailed answers, since I'm afraid of not understanding the intermediate steps. EDIT: As I predicted, it's actually quite simple, but I still want to understand all the details (see comments below).",,"['probability-theory', 'statistics', 'stochastic-processes', 'markov-chains', 'markov-process']"
76,Mean absorption time of a finite birth-death chain with two absorbing end-points,Mean absorption time of a finite birth-death chain with two absorbing end-points,,"I am attempting to understand the mean absorption time of a birth-death process (with non-constant birth and death probabilities) and with two absorbing end-points (i.e. probability of birth and death at x = 0 and x = n is equally 0). I am referring in particular to this online reference , however something is not bounds-checking. In particular, in the expression for $m_n(1)$, we see that $A_n$ (expressed here ) has a division by zero (in particular, p(0) = 0, and placed in the denominator, this is undefined). Am I missing something here? Or is this a typo? Is there another reference (maybe a book) that analyzes exactly such a chain?","I am attempting to understand the mean absorption time of a birth-death process (with non-constant birth and death probabilities) and with two absorbing end-points (i.e. probability of birth and death at x = 0 and x = n is equally 0). I am referring in particular to this online reference , however something is not bounds-checking. In particular, in the expression for $m_n(1)$, we see that $A_n$ (expressed here ) has a division by zero (in particular, p(0) = 0, and placed in the denominator, this is undefined). Am I missing something here? Or is this a typo? Is there another reference (maybe a book) that analyzes exactly such a chain?",,"['probability', 'statistics', 'markov-chains', 'markov-process']"
77,A random walk on the $n$-hypercube,A random walk on the -hypercube,n,"The stationary distribution for a simple random walk on a nonweighted graph gives $$\pi _{v}=\frac{deg(v)}{\sum_{z}^{}deg(z)} = \frac{deg(v)}{2e},$$ where $e$ denotes the number of edges of the graph. We can show this is stationary by proving that $\boldsymbol{\pi }=\boldsymbol{\pi }\boldsymbol{P}$. $$(\pi P)_{v}=\sum_{w}\pi _{w}P_{wv}= \sum_{w\sim v}\frac{deg(w)}{2e}\frac{1}{deg(w)}=\frac{1}{2e}\sum_{w\sim v}1=\frac{deg(v)}{2e}=\pi _{v}.$$ To make use of this, we can look at the hypercube. The $n$-hypercube graph has $2^{n}$ vertices.  The sum of the degrees of the vertices is $n2^{n}$.  So, $$\pi _{v}=\frac{n}{n2^{n}}=\frac{1}{2^{n}}.$$ The distribution is uniform.  This is because all of the vertex degrees are the same. How does this concept change when the graph is weighted?","The stationary distribution for a simple random walk on a nonweighted graph gives $$\pi _{v}=\frac{deg(v)}{\sum_{z}^{}deg(z)} = \frac{deg(v)}{2e},$$ where $e$ denotes the number of edges of the graph. We can show this is stationary by proving that $\boldsymbol{\pi }=\boldsymbol{\pi }\boldsymbol{P}$. $$(\pi P)_{v}=\sum_{w}\pi _{w}P_{wv}= \sum_{w\sim v}\frac{deg(w)}{2e}\frac{1}{deg(w)}=\frac{1}{2e}\sum_{w\sim v}1=\frac{deg(v)}{2e}=\pi _{v}.$$ To make use of this, we can look at the hypercube. The $n$-hypercube graph has $2^{n}$ vertices.  The sum of the degrees of the vertices is $n2^{n}$.  So, $$\pi _{v}=\frac{n}{n2^{n}}=\frac{1}{2^{n}}.$$ The distribution is uniform.  This is because all of the vertex degrees are the same. How does this concept change when the graph is weighted?",,"['geometry', 'statistics']"
78,"Exercise ""Mathematical Statistics - Jun Shao""","Exercise ""Mathematical Statistics - Jun Shao""",,"I'm trying to solve this problem: Let $X_1, ...,X_n, (n \ge 2)$ be i.i.d. random variables having the   normal distribution $N(\theta, 2)$ when $\theta=0$ and the normal   distribution $N(\theta, 1)$ when $\theta \in {\rm I\!R}-\{0\}$. Show that the sample mean $\bar{X}$ is not a sufficient   statistic for $\theta$. So, first I found the sample distributions,  $\bar{X} \sim N(0,2/n)$, when $\theta = 0$, and $\bar{X} \sim N(\theta,1/n)$, when $\theta \neq 0$. Then I wrote the function as \begin{align} f_{ \theta  }(x)={ \left[ { (4\pi ) }^{ -1/2 }\exp\{ \frac { -{ x }^{ 2 } }{ 4 } \}  \right]  }^{ I_{ \{ \theta =0\}  } }{ \left[ { (2\pi ) }^{ -1/2 }\exp\{ \frac { -{ (x-\theta ) }^{ 2 } }{ 2 } \}  \right]  }^{ I_{ \{ \theta \neq 0\}  } } \end{align} But I'm not sure how to procedure with that. I thought of using the factorization theorem, but I'm stuck in this density. Any hint?","I'm trying to solve this problem: Let $X_1, ...,X_n, (n \ge 2)$ be i.i.d. random variables having the   normal distribution $N(\theta, 2)$ when $\theta=0$ and the normal   distribution $N(\theta, 1)$ when $\theta \in {\rm I\!R}-\{0\}$. Show that the sample mean $\bar{X}$ is not a sufficient   statistic for $\theta$. So, first I found the sample distributions,  $\bar{X} \sim N(0,2/n)$, when $\theta = 0$, and $\bar{X} \sim N(\theta,1/n)$, when $\theta \neq 0$. Then I wrote the function as \begin{align} f_{ \theta  }(x)={ \left[ { (4\pi ) }^{ -1/2 }\exp\{ \frac { -{ x }^{ 2 } }{ 4 } \}  \right]  }^{ I_{ \{ \theta =0\}  } }{ \left[ { (2\pi ) }^{ -1/2 }\exp\{ \frac { -{ (x-\theta ) }^{ 2 } }{ 2 } \}  \right]  }^{ I_{ \{ \theta \neq 0\}  } } \end{align} But I'm not sure how to procedure with that. I thought of using the factorization theorem, but I'm stuck in this density. Any hint?",,"['statistics', 'probability-distributions', 'statistical-inference']"
79,An Example dealing with the Chi-Square Test,An Example dealing with the Chi-Square Test,,"Problem: In $60$ tosses of a coin, $37$ heads and $23$ tails were observed. Test the hypothesis that the coin is fair, using a significant level of (a) $0.05$, (b) $0.01$. Answer: \begin{eqnarray*} df &=& 2 - 1 = 1 \\ \chi^2 &=& \frac{(37-30)^2}{30} + \frac{(30-23)^2}{30} \\ \chi^2 &=& \frac{49}{30} + \frac{49}{30} = \frac{49}{15} \\ \chi^2 &=& 3.26667 \\ \end{eqnarray*} Using software I find that $P(\chi^2 < 3.26667) = 0.93$. Therefore, I reject the idea the coin is fair at both the $0.05$ and $0.01$ levels. The book's answer is: The hypothesis cannot be rejected at either level. What did I do wrong? Bob","Problem: In $60$ tosses of a coin, $37$ heads and $23$ tails were observed. Test the hypothesis that the coin is fair, using a significant level of (a) $0.05$, (b) $0.01$. Answer: \begin{eqnarray*} df &=& 2 - 1 = 1 \\ \chi^2 &=& \frac{(37-30)^2}{30} + \frac{(30-23)^2}{30} \\ \chi^2 &=& \frac{49}{30} + \frac{49}{30} = \frac{49}{15} \\ \chi^2 &=& 3.26667 \\ \end{eqnarray*} Using software I find that $P(\chi^2 < 3.26667) = 0.93$. Therefore, I reject the idea the coin is fair at both the $0.05$ and $0.01$ levels. The book's answer is: The hypothesis cannot be rejected at either level. What did I do wrong? Bob",,"['probability', 'statistics', 'probability-distributions']"
80,Basic question about significance of statistical tests,Basic question about significance of statistical tests,,"Apologies for the basic question this is really not my area at all but I’m trying to help a friend out. Whilst reading the Wikipedia page for the Shapiro-Wilk test I came across the following: “As with most statistical tests, the test may be statistically significant from a normal distribution in any large samples. Thus a Q–Q plot is useful for verification in addition to the test” I interpret this to mean that if we sampled a large amount of data from what was in fact a Normal population, the test may in fact reject the null hypothesis that the parent population was Normal. Is this interpretation correct? If so, why is this the case? I thought in general larger samples gave better testing?! Any intuition on this would be very much appreciated.","Apologies for the basic question this is really not my area at all but I’m trying to help a friend out. Whilst reading the Wikipedia page for the Shapiro-Wilk test I came across the following: “As with most statistical tests, the test may be statistically significant from a normal distribution in any large samples. Thus a Q–Q plot is useful for verification in addition to the test” I interpret this to mean that if we sampled a large amount of data from what was in fact a Normal population, the test may in fact reject the null hypothesis that the parent population was Normal. Is this interpretation correct? If so, why is this the case? I thought in general larger samples gave better testing?! Any intuition on this would be very much appreciated.",,"['statistics', 'statistical-inference', 'hypothesis-testing']"
81,Probability Density Function for Gamma Distributions,Probability Density Function for Gamma Distributions,,"Shouldn't probability density functions be in the form of $$P(X\in dx) = \cdots$$ Why does the one for gamma distributions divide by $dt$? $T_r =$ time of $r^\text{th}$ arrival after time $0$ in a poisson arrival process with rate $\lambda$. And if I multiply both sides by $dt$, how am I supposed to calculate $dt$ on the right side?","Shouldn't probability density functions be in the form of $$P(X\in dx) = \cdots$$ Why does the one for gamma distributions divide by $dt$? $T_r =$ time of $r^\text{th}$ arrival after time $0$ in a poisson arrival process with rate $\lambda$. And if I multiply both sides by $dt$, how am I supposed to calculate $dt$ on the right side?",,['statistics']
82,Finding the pdf of a random variable generating from another random variable with defined pdf,Finding the pdf of a random variable generating from another random variable with defined pdf,,"Initially, there is a random variable $X$ (non-negative) with distribution function: $$P(x) = \lambda e^{-\lambda x}$$ Now we randomly generate $X$ and, then, form sets of $N$ values of this variable: $(x_1,x_2,\ldots,x_N)$ And for each set, we define, for example, $$S = \frac{1}{N}\sum_{k=1}^N x_k^2$$ $S$ is then a new random variable. My question is: How to find the pdf of this new random variable ?","Initially, there is a random variable $X$ (non-negative) with distribution function: $$P(x) = \lambda e^{-\lambda x}$$ Now we randomly generate $X$ and, then, form sets of $N$ values of this variable: $(x_1,x_2,\ldots,x_N)$ And for each set, we define, for example, $$S = \frac{1}{N}\sum_{k=1}^N x_k^2$$ $S$ is then a new random variable. My question is: How to find the pdf of this new random variable ?",,"['statistics', 'probability-distributions', 'exponential-distribution', 'gamma-distribution']"
83,When to Use Normal Approximation?,When to Use Normal Approximation?,,"Do we use normal approximation when discrete distributions are hard to solve? For example, $P(X\ge 7000)$ where is $X\sim\operatorname{Binomial}(13000, 0.7)$. Obviously, summing each case manually cannot be done and the summation is difficult to solve (I assume)? In my textbook, sometimes when something is a dicrete distribution and I calculate it using discrete distribution, I flip to the answer and they used normal approximation to the discrete distribution. Example: ""Why are you choosing to use normal approximation?!""","Do we use normal approximation when discrete distributions are hard to solve? For example, $P(X\ge 7000)$ where is $X\sim\operatorname{Binomial}(13000, 0.7)$. Obviously, summing each case manually cannot be done and the summation is difficult to solve (I assume)? In my textbook, sometimes when something is a dicrete distribution and I calculate it using discrete distribution, I flip to the answer and they used normal approximation to the discrete distribution. Example: ""Why are you choosing to use normal approximation?!""",,['statistics']
84,Normal Approximation: Getting $E(X)$.,Normal Approximation: Getting .,E(X),"When we use normal approximation to a binomial distribution $Bin(n, p)$, do we assume it is a normal distribution and get $E(X)$ with $E(X)= \int_{-\infty}^{\infty}xf(x)dx$. Or get $E(X)$ as a binomial distribution first with  $E(X) = np$? What about when you're normal approximating a distribution that you have no idea what distribution it is?","When we use normal approximation to a binomial distribution $Bin(n, p)$, do we assume it is a normal distribution and get $E(X)$ with $E(X)= \int_{-\infty}^{\infty}xf(x)dx$. Or get $E(X)$ as a binomial distribution first with  $E(X) = np$? What about when you're normal approximating a distribution that you have no idea what distribution it is?",,['statistics']
85,"Find an unbiased estimator for $\alpha$, $\alpha^2$, and $\alpha^3$","Find an unbiased estimator for , , and",\alpha \alpha^2 \alpha^3,"$Y_1, Y_2,...,Y_n$ is a random sample drawn from Gamma($\alpha$, 2) (a) Find an unbiased estimator of 7 - 2$\alpha$. Verify your answer. Then find the mean square error of the estimator. Your estimator should depend on all data points. (b) Find an unbiased estimator of $\alpha^2$. Your estimator should depend on all data points. Verify your answer. (c)  Find an unbiased estimator of $\alpha^3$. Your estimator should depend on all data points. Verify your answer. What I have tried so far: First I calculated $E(Y_i) = \alpha\beta = 2\alpha$, $V(Y_i) = \alpha\beta^2 = 4\alpha$ Also following from that, $E(\overline{Y}) = 2\alpha$, and $V(\overline{Y}) = \frac{4\alpha}{n}$ (a) Since the estimator should depend on all data points, I used $\overline{Y}$. I used $E(7 - \overline{Y}) = E(Y) - E(\overline{Y}) = 7 - 2\alpha$ Since this estimator is unbiased, the MSE should be equal to just variance. So I got MSE = $V(7 - \overline{Y}) = V(\overline{Y}) = \frac{4\alpha}{n}$ (b) For this, I started with $E(\overline{Y}^2)$, which I tried to derive a formula, but I'm not sure I did this part correctly. I did this: $$E(\overline{Y}^2) = E[(\frac{1}{n}\sum_{i=0}^nY_i)^2] = \frac{1}{n^2}E[(\sum_{i=0}^nY_i)^2] = \frac{1}{n^2}\sum\sum_{i \ne j}E(Y_iY_j) = \frac{1}{n^2}[\sum_{i=0}^nE(Y_i^2) + \sum\sum_{i \ne j}E(Y_iY_j)]$$ From here, I used the identity $E(X^2) = V(X) + E(X)^2$, independence, and summation manipulation to arrive at: $$\frac{1}{n^2}[n(4\alpha + 4\alpha^2) + (n^2 -n)4\alpha^2]$$ After some simplification, I got  all of this equal to $4\alpha^2 + \frac{4\alpha}{n}$ Since this is biased with respect to $\alpha^2$, I adjusted my estimator to get $E(\frac{\overline{Y}^2}{4} - \frac{\overline{Y}}{2n})$ to get $\alpha^2$, which is unbiased. I'm not sure this part is correct, but it seemed to make sense. (c) This is where I ran into problems. I'm not sure how to approach this one. I tried looking in my text for some definitions and examples to help me, but I have no idea how to start. Any help would be greatly appreciated.","$Y_1, Y_2,...,Y_n$ is a random sample drawn from Gamma($\alpha$, 2) (a) Find an unbiased estimator of 7 - 2$\alpha$. Verify your answer. Then find the mean square error of the estimator. Your estimator should depend on all data points. (b) Find an unbiased estimator of $\alpha^2$. Your estimator should depend on all data points. Verify your answer. (c)  Find an unbiased estimator of $\alpha^3$. Your estimator should depend on all data points. Verify your answer. What I have tried so far: First I calculated $E(Y_i) = \alpha\beta = 2\alpha$, $V(Y_i) = \alpha\beta^2 = 4\alpha$ Also following from that, $E(\overline{Y}) = 2\alpha$, and $V(\overline{Y}) = \frac{4\alpha}{n}$ (a) Since the estimator should depend on all data points, I used $\overline{Y}$. I used $E(7 - \overline{Y}) = E(Y) - E(\overline{Y}) = 7 - 2\alpha$ Since this estimator is unbiased, the MSE should be equal to just variance. So I got MSE = $V(7 - \overline{Y}) = V(\overline{Y}) = \frac{4\alpha}{n}$ (b) For this, I started with $E(\overline{Y}^2)$, which I tried to derive a formula, but I'm not sure I did this part correctly. I did this: $$E(\overline{Y}^2) = E[(\frac{1}{n}\sum_{i=0}^nY_i)^2] = \frac{1}{n^2}E[(\sum_{i=0}^nY_i)^2] = \frac{1}{n^2}\sum\sum_{i \ne j}E(Y_iY_j) = \frac{1}{n^2}[\sum_{i=0}^nE(Y_i^2) + \sum\sum_{i \ne j}E(Y_iY_j)]$$ From here, I used the identity $E(X^2) = V(X) + E(X)^2$, independence, and summation manipulation to arrive at: $$\frac{1}{n^2}[n(4\alpha + 4\alpha^2) + (n^2 -n)4\alpha^2]$$ After some simplification, I got  all of this equal to $4\alpha^2 + \frac{4\alpha}{n}$ Since this is biased with respect to $\alpha^2$, I adjusted my estimator to get $E(\frac{\overline{Y}^2}{4} - \frac{\overline{Y}}{2n})$ to get $\alpha^2$, which is unbiased. I'm not sure this part is correct, but it seemed to make sense. (c) This is where I ran into problems. I'm not sure how to approach this one. I tried looking in my text for some definitions and examples to help me, but I have no idea how to start. Any help would be greatly appreciated.",,"['probability', 'probability-theory', 'statistics', 'probability-distributions']"
86,Probability - Statistics expected value [closed],Probability - Statistics expected value [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question A box contains $10$ red balls and $6$ blue balls, every time a ball is taken from the box it gets replaced with the same ball, from another unlimited supply of red and blue balls. What is the expected number of balls you will need to take to have at least $2$ of each colour? (at least $2$ red and at least $2$ blue balls). Any ideas how to tackle this problem? So far i have something along the lines of... Let X be the number of balls taken from the bag until 2 of each colours has been taken. a = red ball, b= blue ball.... P(a) = 10/16, P(b) = 6/16. minimum balls needed to be taken is 4, there are 4C2 different ways of choosing these balls","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question A box contains $10$ red balls and $6$ blue balls, every time a ball is taken from the box it gets replaced with the same ball, from another unlimited supply of red and blue balls. What is the expected number of balls you will need to take to have at least $2$ of each colour? (at least $2$ red and at least $2$ blue balls). Any ideas how to tackle this problem? So far i have something along the lines of... Let X be the number of balls taken from the bag until 2 of each colours has been taken. a = red ball, b= blue ball.... P(a) = 10/16, P(b) = 6/16. minimum balls needed to be taken is 4, there are 4C2 different ways of choosing these balls",,"['probability', 'statistics', 'expectation']"
87,Distribution of Conditional Bernoulli Random Variable,Distribution of Conditional Bernoulli Random Variable,,"Let $X_i\sim \mathcal{Poisson}(\lambda)$, where $X_i$ come from a random sample of size $n$ (so they're independent and identically distributed).  Let $T=I\lbrace X_1=0 \rbrace$ (indicator function); that is, $T\sim \mathcal{Bernoulli}(e^{-\lambda})$. Now define $B=\sum_{i=1}^nX_i$.  This implies $B\sim\mathcal{Poisson}(n\lambda)$.  Using this information, what is the distribution of the conditional random variable: $$T\mid_{B=b}$$ That is, what is the distribution of $T$ given that $B=b$?","Let $X_i\sim \mathcal{Poisson}(\lambda)$, where $X_i$ come from a random sample of size $n$ (so they're independent and identically distributed).  Let $T=I\lbrace X_1=0 \rbrace$ (indicator function); that is, $T\sim \mathcal{Bernoulli}(e^{-\lambda})$. Now define $B=\sum_{i=1}^nX_i$.  This implies $B\sim\mathcal{Poisson}(n\lambda)$.  Using this information, what is the distribution of the conditional random variable: $$T\mid_{B=b}$$ That is, what is the distribution of $T$ given that $B=b$?",,"['probability', 'probability-theory', 'statistics', 'probability-distributions']"
88,Standard Error of Median,Standard Error of Median,,"The following question is from Modern Mathematical Statistics (Devore). Consider the following observations: 0.83, 0.88, 0.88, 1.04, 1.09, 1.12, 1.29, 1.31, 1.48, 1.49, 1.59, 1.62, 1.65, 1.71, 1.76, 1.83 Assume that the distribution of the observations is normal. b. Calculate a point estimate of the median of the observations and state which estimator you used. e. What is the estimated standard error of the estimator that you used in part (b). Here are my responses: $$\\$$b. Given the assumption of normality, it is reasonable to use $\bar{x}$ as an estimate of the population median.In this case, $\bar{x}=1.3481$ $$\\$$e. Here I am unsure how to proceed. Is there a general formula for the standard error of a point estimate?","The following question is from Modern Mathematical Statistics (Devore). Consider the following observations: 0.83, 0.88, 0.88, 1.04, 1.09, 1.12, 1.29, 1.31, 1.48, 1.49, 1.59, 1.62, 1.65, 1.71, 1.76, 1.83 Assume that the distribution of the observations is normal. b. Calculate a point estimate of the median of the observations and state which estimator you used. e. What is the estimated standard error of the estimator that you used in part (b). Here are my responses: $$\\$$b. Given the assumption of normality, it is reasonable to use $\bar{x}$ as an estimate of the population median.In this case, $\bar{x}=1.3481$ $$\\$$e. Here I am unsure how to proceed. Is there a general formula for the standard error of a point estimate?",,['statistics']
89,"How to calculate standard deviation in case of known x values, assuming a normal distribution?","How to calculate standard deviation in case of known x values, assuming a normal distribution?",,"I have learned that 17% of the vehicles within a certain population drive less than 7. 500 km per year. On average, a given vehicle in that population will drive 13.300 km per year. Assuming a normal distribution, how (mathematically, using a graphic calculator, or using Excel) can I calculate the standard deviation for the population at hand 1 ?","I have learned that 17% of the vehicles within a certain population drive less than 7. 500 km per year. On average, a given vehicle in that population will drive 13.300 km per year. Assuming a normal distribution, how (mathematically, using a graphic calculator, or using Excel) can I calculate the standard deviation for the population at hand 1 ?",,"['statistics', 'normal-distribution', 'standard-deviation']"
90,Asymptotic Consistency of Estimator,Asymptotic Consistency of Estimator,,"Let $X_1,X_2,...,X_n$ be a random sample where $X_i$'s are i.i.d. and are from an Exponential distribution with mean $\theta$ and variance $\theta^2$. Define the following estimator of $\theta$: $$\hat\theta=\frac{n\bar X}{n+1}$$ What is the bias of $\hat\theta$?  Is $\hat\theta$ asymptotically consistent?  Is it mean square error (MSE) consistent? Here's my attempt at the solution, but I'm unsure: $Bias(\hat\theta)=E(\hat\theta)-\theta=\theta\left(\frac{n}{n+1}-1\right)=\frac{-\theta}{n+1}$ Here's the place that I'm not sure; does $\lim_{n \to \infty} Bias(\hat\theta)=0$ imply that $\hat\theta \rightarrow^P\theta$?  If so, is this alone enough to show that $\hat\theta$ is asymptotically consistent?  Unfortunatley, I haven't really been able to find a clear definition of ""asymptocially consistent,"" and this is just what I assume it means. Finally, for MSE consistency, I calculated that $\lim_{n \to \infty} V(\hat\theta)=\theta^2\ne 0$, which should imply that $\hat\theta$ is not MSE consistent.  But, once again, I also haven't found a clear definition for this terminology, so I'm not sure of it either. What do you think?","Let $X_1,X_2,...,X_n$ be a random sample where $X_i$'s are i.i.d. and are from an Exponential distribution with mean $\theta$ and variance $\theta^2$. Define the following estimator of $\theta$: $$\hat\theta=\frac{n\bar X}{n+1}$$ What is the bias of $\hat\theta$?  Is $\hat\theta$ asymptotically consistent?  Is it mean square error (MSE) consistent? Here's my attempt at the solution, but I'm unsure: $Bias(\hat\theta)=E(\hat\theta)-\theta=\theta\left(\frac{n}{n+1}-1\right)=\frac{-\theta}{n+1}$ Here's the place that I'm not sure; does $\lim_{n \to \infty} Bias(\hat\theta)=0$ imply that $\hat\theta \rightarrow^P\theta$?  If so, is this alone enough to show that $\hat\theta$ is asymptotically consistent?  Unfortunatley, I haven't really been able to find a clear definition of ""asymptocially consistent,"" and this is just what I assume it means. Finally, for MSE consistency, I calculated that $\lim_{n \to \infty} V(\hat\theta)=\theta^2\ne 0$, which should imply that $\hat\theta$ is not MSE consistent.  But, once again, I also haven't found a clear definition for this terminology, so I'm not sure of it either. What do you think?",,"['probability', 'probability-theory', 'statistics', 'random-variables', 'parameter-estimation']"
91,Averaged log-likelihood with a latent variable for mixture models,Averaged log-likelihood with a latent variable for mixture models,,"In class we've defined the following: $$Q(\theta; \theta^t) = \sum_z P(Z=z\mid X=x; \theta^t) \log P(X=x; Z=z;\theta)$$ It's part of the EM algorithm. Here, $\theta^t$ are the assumed parameters at time $t$. I just wonder, why wasn't it defined as conditional probability, like this: $$\log P(X=x \mid Z=z;\theta)$$ I'm looking for the intuition here, other than ""it's the definition"". Thanks","In class we've defined the following: $$Q(\theta; \theta^t) = \sum_z P(Z=z\mid X=x; \theta^t) \log P(X=x; Z=z;\theta)$$ It's part of the EM algorithm. Here, $\theta^t$ are the assumed parameters at time $t$. I just wonder, why wasn't it defined as conditional probability, like this: $$\log P(X=x \mid Z=z;\theta)$$ I'm looking for the intuition here, other than ""it's the definition"". Thanks",,"['statistics', 'machine-learning', 'maximum-likelihood', 'log-likelihood']"
92,Is there a name for the statement that the frequentist definition of probability follows from the Kolmogorov definition?,Is there a name for the statement that the frequentist definition of probability follows from the Kolmogorov definition?,,"From what I learned about the debate over definitions/interpretations of probability, it seems like that it doesn't mathematically make sense to define the probability in the frequentists way, but once probability is defined properly (axiomatically) the frequentists interpretation holds, when frequency is a well-defined concept (correct me if I am wrong). Is there a name for a theorem that states that frequency corresponds to probability in the Kolmogorov sense under certain conditions?","From what I learned about the debate over definitions/interpretations of probability, it seems like that it doesn't mathematically make sense to define the probability in the frequentists way, but once probability is defined properly (axiomatically) the frequentists interpretation holds, when frequency is a well-defined concept (correct me if I am wrong). Is there a name for a theorem that states that frequency corresponds to probability in the Kolmogorov sense under certain conditions?",,"['probability', 'probability-theory', 'statistics']"
93,Computing probabilities with the ${\chi}^{2}_{n}$ distribution,Computing probabilities with the  distribution,{\chi}^{2}_{n},"I have 2 questions. Here is background information to my questions, which involves showing that $\lbrace \sum_{i=1}^{n} x_{i} < \frac{\theta c_{1}}{2}\rbrace \cup \lbrace \sum_{i=1}^{n} x_{i} > \frac{\theta c_{2}}{2}\rbrace$ is the critical region for a UMPU level $\alpha$ test. The random sample is coming from a $\operatorname{Exp}(\theta)$ distribution, $\theta>0$. We can use the fact that if $X \sim \operatorname{Exp}(\theta)$ then $\frac{2X}{\theta} \sim \operatorname{Exp}(2) \sim {\chi}^{2}_{2}$. We can further use the fact that if $Y_{i} \sim {\chi}^{2}_{2}$ then $\sum_{i=1}^{n} Y_{i} \sim {\chi}^{2}_{2n}$. In this question, $f_{k}(x)$ is the pdf of a ${\chi}^{2}_{k}$ random variable. Okay, I was able to find the region $\lbrace \sum_{i=1}^n x_i < \frac{\theta c_1} 2 \rbrace \cup \lbrace \sum_{i=1}^n x_i > \frac{\theta c_2} 2 \rbrace$ using the fact that $\operatorname{Exp}(\theta)$ has a montone likelihood ratio in $\sum x_i$ and using a theorem in class. That’s fine. All that is left to show is that $P(\lbrace \sum_{i=1}^n X_i < \frac{\theta c_1}{2}\rbrace \cup \lbrace \sum_{i=1}^n X_i > \frac{\theta c_2} 2\rbrace)=\alpha$. My questions are: Are the following steps valid, for $c_1<c_2$: \begin{align} & P\left(\left\{ \sum_{i=1}^n X_i < \frac{\theta c_1} 2\right\} \cup \left\{ \sum_{i=1}^n X_i > \frac{\theta c_2} 2\right\}\right)=\alpha \\[10pt] \Longrightarrow & P(\chi^2_{2n}< c_1) + P(\chi^2_{2n}>c_2)=\alpha \\[10pt] \Longrightarrow & P(c_1<\chi^2_{2n}<c_2)=1-\alpha \\[10pt] \Longrightarrow & \int_{c_1}^{c_2} f_{2n}(x)dx=1-\alpha \\[10pt] \Longrightarrow & \int_{c_1}^{c_2} f_{2(n+1)}(x) \, dx=1-\alpha \end{align} The equality $\int_{c_1}^{c_2} f_{2n}(x)\,dx=\int_{c_1}^{c_2} f_{2(n+1)}(x) \, dx$ was given. Why is this true?","I have 2 questions. Here is background information to my questions, which involves showing that $\lbrace \sum_{i=1}^{n} x_{i} < \frac{\theta c_{1}}{2}\rbrace \cup \lbrace \sum_{i=1}^{n} x_{i} > \frac{\theta c_{2}}{2}\rbrace$ is the critical region for a UMPU level $\alpha$ test. The random sample is coming from a $\operatorname{Exp}(\theta)$ distribution, $\theta>0$. We can use the fact that if $X \sim \operatorname{Exp}(\theta)$ then $\frac{2X}{\theta} \sim \operatorname{Exp}(2) \sim {\chi}^{2}_{2}$. We can further use the fact that if $Y_{i} \sim {\chi}^{2}_{2}$ then $\sum_{i=1}^{n} Y_{i} \sim {\chi}^{2}_{2n}$. In this question, $f_{k}(x)$ is the pdf of a ${\chi}^{2}_{k}$ random variable. Okay, I was able to find the region $\lbrace \sum_{i=1}^n x_i < \frac{\theta c_1} 2 \rbrace \cup \lbrace \sum_{i=1}^n x_i > \frac{\theta c_2} 2 \rbrace$ using the fact that $\operatorname{Exp}(\theta)$ has a montone likelihood ratio in $\sum x_i$ and using a theorem in class. That’s fine. All that is left to show is that $P(\lbrace \sum_{i=1}^n X_i < \frac{\theta c_1}{2}\rbrace \cup \lbrace \sum_{i=1}^n X_i > \frac{\theta c_2} 2\rbrace)=\alpha$. My questions are: Are the following steps valid, for $c_1<c_2$: \begin{align} & P\left(\left\{ \sum_{i=1}^n X_i < \frac{\theta c_1} 2\right\} \cup \left\{ \sum_{i=1}^n X_i > \frac{\theta c_2} 2\right\}\right)=\alpha \\[10pt] \Longrightarrow & P(\chi^2_{2n}< c_1) + P(\chi^2_{2n}>c_2)=\alpha \\[10pt] \Longrightarrow & P(c_1<\chi^2_{2n}<c_2)=1-\alpha \\[10pt] \Longrightarrow & \int_{c_1}^{c_2} f_{2n}(x)dx=1-\alpha \\[10pt] \Longrightarrow & \int_{c_1}^{c_2} f_{2(n+1)}(x) \, dx=1-\alpha \end{align} The equality $\int_{c_1}^{c_2} f_{2n}(x)\,dx=\int_{c_1}^{c_2} f_{2(n+1)}(x) \, dx$ was given. Why is this true?",,"['statistics', 'probability-distributions', 'statistical-inference']"
94,Why is it so difficult to sample from a Boltzmann distribution?,Why is it so difficult to sample from a Boltzmann distribution?,,"I am studying simulated annealing, and simulated annealing involves a Boltzmann distribution. Typically I see the Boltzmann distribution written like: $P(E_i) = e^{-E_i/(kT)}/Z$ where $Z$ is the sum of all of the energy in all of the states, and $P(E_i)$ is the energy in just one of the states. The thing is in simulated annealing I see the pdf written with an integral: $P(x) = \frac{e^{-f(x)/T}}{\int_{S}e^{-f(z)/T}dz}$ I understand from many sources that the Boltzmann distribution is reportedly very difficult to sample from because it involves this $f(z)$ as you can see above.  I have two questions about that: 1) Why does the $f(z)$ not appear in the first equation I gave for the Boltzmann distribution?  (e.g., it does not appear here on wikipedia: https://en.wikipedia.org/wiki/Maxwell –Boltzmann_distribution) 2) I'm able to fire up python and use scipy to easily sample from a Boltzmann distribution just by doing import scipy from scipy import stats import numpy as np import matplotlib.pyplot as plt r = scipy.stats.boltzmann.rvs(lambda_=1.4, N=4, size=10) without trouble.  (source: https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.boltzmann.html#id23 ) So what is the big deal with sampling from a Boltzmann distribution?  There are all these fancy methods in Simulated Annealing like Hit and Run, Metropolis sampling, etc. Why are they necessary when I was able to sample from a Boltzmann distribution with ease?","I am studying simulated annealing, and simulated annealing involves a Boltzmann distribution. Typically I see the Boltzmann distribution written like: $P(E_i) = e^{-E_i/(kT)}/Z$ where $Z$ is the sum of all of the energy in all of the states, and $P(E_i)$ is the energy in just one of the states. The thing is in simulated annealing I see the pdf written with an integral: $P(x) = \frac{e^{-f(x)/T}}{\int_{S}e^{-f(z)/T}dz}$ I understand from many sources that the Boltzmann distribution is reportedly very difficult to sample from because it involves this $f(z)$ as you can see above.  I have two questions about that: 1) Why does the $f(z)$ not appear in the first equation I gave for the Boltzmann distribution?  (e.g., it does not appear here on wikipedia: https://en.wikipedia.org/wiki/Maxwell –Boltzmann_distribution) 2) I'm able to fire up python and use scipy to easily sample from a Boltzmann distribution just by doing import scipy from scipy import stats import numpy as np import matplotlib.pyplot as plt r = scipy.stats.boltzmann.rvs(lambda_=1.4, N=4, size=10) without trouble.  (source: https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.boltzmann.html#id23 ) So what is the big deal with sampling from a Boltzmann distribution?  There are all these fancy methods in Simulated Annealing like Hit and Run, Metropolis sampling, etc. Why are they necessary when I was able to sample from a Boltzmann distribution with ease?",,"['statistics', 'probability-distributions', 'mathematical-physics', 'sampling', 'statistical-mechanics']"
95,"Find $P(\max(X_1,X_2,X_3)=1)$ of Poisson random variable.",Find  of Poisson random variable.,"P(\max(X_1,X_2,X_3)=1)","Let $X_1 ,X_2,X_3$ be independent Poisson random variables with mean $1$  . Then $P(\max(X_1,X_2,X_3)=1)$  equals ? $(A)1-e^{-3}$ $(B) e^{-3}$ $(C)1-8e^{-3}$ $(D)7e^{-3}$ I usually solve these types of problem when we are given $P(\max(X_1,X_2,X_3)\leq1)$(say) then i proceed in this way if they are independent $P(X_1\leq1)P( X_2\leq1)P(X_3\leq 1)$. I have reasoning in my head behind this $P(\max(X_1,X_2,X_3)\leq1)$ is that if maximum order statistic is  $\leq1$ then other two random variables are also $\leq 1$ . Thus in this question $P(X_1\leq1)P( X_2\leq1)P(X_3\leq 1)$ changes as $P(X_1=1)P( X_2=1)P(X_3= 1)=e^{-3}$ Someone tell me if I am on right track and give me some more knowledge on this topic.","Let $X_1 ,X_2,X_3$ be independent Poisson random variables with mean $1$  . Then $P(\max(X_1,X_2,X_3)=1)$  equals ? $(A)1-e^{-3}$ $(B) e^{-3}$ $(C)1-8e^{-3}$ $(D)7e^{-3}$ I usually solve these types of problem when we are given $P(\max(X_1,X_2,X_3)\leq1)$(say) then i proceed in this way if they are independent $P(X_1\leq1)P( X_2\leq1)P(X_3\leq 1)$. I have reasoning in my head behind this $P(\max(X_1,X_2,X_3)\leq1)$ is that if maximum order statistic is  $\leq1$ then other two random variables are also $\leq 1$ . Thus in this question $P(X_1\leq1)P( X_2\leq1)P(X_3\leq 1)$ changes as $P(X_1=1)P( X_2=1)P(X_3= 1)=e^{-3}$ Someone tell me if I am on right track and give me some more knowledge on this topic.",,"['probability', 'statistics', 'probability-distributions', 'order-statistics']"
96,Statistics: Why are school grades qualitative variable?,Statistics: Why are school grades qualitative variable?,,"I am struggling to understand, why in descriptive statistics we say that school grades are a qualitative and not quantitative variable? I can understand why color of the hair is qualitative, but grades are numerical...","I am struggling to understand, why in descriptive statistics we say that school grades are a qualitative and not quantitative variable? I can understand why color of the hair is qualitative, but grades are numerical...",,"['statistics', 'descriptive-statistics']"
97,Conditional variance of joint density.,Conditional variance of joint density.,,"Joint density for X and Y is $f(x,y)=2e^{-x-2y} \ \ \ \ \ \ $for$ \ \ \ x>0,y>0 $ $0$ otherwise Calculate the variance of $Y$ given that $X>3$ and $Y>3$ Can we use this formula somehow here $V(Y)=E(V(X|Y))+V(E(X|Y))$? I thought that because joint density seems like product of two exponential distributions one can be conditional density and other can be marginal. Am i think totally wrong ? Bad way to deal this problem i guess. When i tried to solve this it was very laborious.","Joint density for X and Y is $f(x,y)=2e^{-x-2y} \ \ \ \ \ \ $for$ \ \ \ x>0,y>0 $ $0$ otherwise Calculate the variance of $Y$ given that $X>3$ and $Y>3$ Can we use this formula somehow here $V(Y)=E(V(X|Y))+V(E(X|Y))$? I thought that because joint density seems like product of two exponential distributions one can be conditional density and other can be marginal. Am i think totally wrong ? Bad way to deal this problem i guess. When i tried to solve this it was very laborious.",,"['probability', 'statistics', 'conditional-expectation']"
98,Method of moments estimator for $\theta$,Method of moments estimator for,\theta,"Let $ X_1,X_2,...,X_n $ be a random sample from a discrete distribution with probability mass function given by  $P(X=0)=\dfrac{1-\theta}{2};P(X=1)=\dfrac{1}{2};P(X=2)=\dfrac{\theta}{2}$;$0\leq\theta\leq1$ Find the method of moments estimator for $\theta$; I calculated $E(X)= 0 \cdot\dfrac{1-\theta}{2} + 1 \cdot\dfrac{1}{2}+ 2\cdot\dfrac{\theta}{2}=\theta+\dfrac{1}{2}$ $\bar x=\theta+\dfrac{1}{2}$ $\bar x+\dfrac{1}{2}= {\hat\theta } $ My solution doesnt matches up with my material. Did i do any mistake here? Please someone tell me.","Let $ X_1,X_2,...,X_n $ be a random sample from a discrete distribution with probability mass function given by  $P(X=0)=\dfrac{1-\theta}{2};P(X=1)=\dfrac{1}{2};P(X=2)=\dfrac{\theta}{2}$;$0\leq\theta\leq1$ Find the method of moments estimator for $\theta$; I calculated $E(X)= 0 \cdot\dfrac{1-\theta}{2} + 1 \cdot\dfrac{1}{2}+ 2\cdot\dfrac{\theta}{2}=\theta+\dfrac{1}{2}$ $\bar x=\theta+\dfrac{1}{2}$ $\bar x+\dfrac{1}{2}= {\hat\theta } $ My solution doesnt matches up with my material. Did i do any mistake here? Please someone tell me.",,"['statistics', 'statistical-inference', 'parameter-estimation']"
99,Determine the maximum-likelihood estimation for $\lambda$,Determine the maximum-likelihood estimation for,\lambda,"$X_1,\ldots,X_n$ are observations of a population with density   $f(x)=\frac{1}{2}\left\{\begin{matrix} \lambda e^{\lambda x} \;\,\text{ if } x<0\\  \lambda e^{-\lambda x} \text{ if } x \geq 0 \end{matrix}\right.$ where parameter $\lambda$ is unknown. Determine a maximum-likelihood estimation for $\lambda$. In my last question I try to solve the problem with another method (method of moment estimation: Given is a density.. Determine a method of moment for $\lambda$ ) I don't know if I do it correct but this time I like to know how can you do it correct with maximum-likelihood? Because I write test soon and I want use a reliable method but not sure how you use maximum-likelihood for this example? I think the method allow us to see the density as function of $\lambda$ which we are looking for, that why we can write as likelihood function $$L(\lambda) = \prod_{i=1}^{n}f_{X_i}(x_i;\lambda)$$ Now need to maximize this based on $\lambda$ so we get maximum-likelihood estimation for $\lambda$ if I understand wikipedia article correct till here. But I don't understand how we do this here and use the formula? We need derive for $\lambda$ and set it equal to zero but no idea how you can apply this here... : /","$X_1,\ldots,X_n$ are observations of a population with density   $f(x)=\frac{1}{2}\left\{\begin{matrix} \lambda e^{\lambda x} \;\,\text{ if } x<0\\  \lambda e^{-\lambda x} \text{ if } x \geq 0 \end{matrix}\right.$ where parameter $\lambda$ is unknown. Determine a maximum-likelihood estimation for $\lambda$. In my last question I try to solve the problem with another method (method of moment estimation: Given is a density.. Determine a method of moment for $\lambda$ ) I don't know if I do it correct but this time I like to know how can you do it correct with maximum-likelihood? Because I write test soon and I want use a reliable method but not sure how you use maximum-likelihood for this example? I think the method allow us to see the density as function of $\lambda$ which we are looking for, that why we can write as likelihood function $$L(\lambda) = \prod_{i=1}^{n}f_{X_i}(x_i;\lambda)$$ Now need to maximize this based on $\lambda$ so we get maximum-likelihood estimation for $\lambda$ if I understand wikipedia article correct till here. But I don't understand how we do this here and use the formula? We need derive for $\lambda$ and set it equal to zero but no idea how you can apply this here... : /",,"['probability', 'statistics']"
