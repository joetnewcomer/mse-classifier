,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Limit of $\frac{2^n}{n^{\sqrt{n}}}$,Limit of,\frac{2^n}{n^{\sqrt{n}}},"$$\lim_{n\to\infty}\frac{2^n}{n^{\sqrt{n}}}$$ The way I see it is that denominator is super-exponential and the numerator is only exponential, so this must be $0$ but wolfram is saying it is infinite. How do I evaluate this limit?","The way I see it is that denominator is super-exponential and the numerator is only exponential, so this must be but wolfram is saying it is infinite. How do I evaluate this limit?",\lim_{n\to\infty}\frac{2^n}{n^{\sqrt{n}}} 0,"['real-analysis', 'calculus', 'sequences-and-series', 'limits', 'analysis']"
1,"If a part of the series diverges, does the whole diverge?","If a part of the series diverges, does the whole diverge?",,I couldn't find an easy to way to check for the convergence of the series. The sum is supposed to be from 2 to infinity and there is a little mistake in the pic. Since $\frac1{n-1}$ diverges by comparison test with $\frac1n$ . Would it be right to say that the whole series is divergent because one of the part of the sum is divergent ?  Do l still need to prove that the other part diverges or not ?,I couldn't find an easy to way to check for the convergence of the series. The sum is supposed to be from 2 to infinity and there is a little mistake in the pic. Since diverges by comparison test with . Would it be right to say that the whole series is divergent because one of the part of the sum is divergent ?  Do l still need to prove that the other part diverges or not ?,\frac1{n-1} \frac1n,"['sequences-and-series', 'convergence-divergence']"
2,Why Abel-Plana formula does not work for exponent?,Why Abel-Plana formula does not work for exponent?,,"Abel-Plana formula : $$\sum _{n=0}^{\infty }f(n)=\int _{0}^{\infty }f(x)\,dx+{\frac {1}{2}}f(0)+i\int _{0}^{\infty }{\frac {f(it)-f(-it)}{e^{2\pi t}-1}}\,dt$$ If we take $f(x)=e^{-x}$ , the right-hand side is $3/2$ , the left-hand side is $\frac{e}{e-1}$ .","Abel-Plana formula : If we take , the right-hand side is , the left-hand side is .","\sum _{n=0}^{\infty }f(n)=\int _{0}^{\infty }f(x)\,dx+{\frac {1}{2}}f(0)+i\int _{0}^{\infty }{\frac {f(it)-f(-it)}{e^{2\pi t}-1}}\,dt f(x)=e^{-x} 3/2 \frac{e}{e-1}","['integration', 'sequences-and-series', 'complex-analysis']"
3,Use of Mellin transform for evaluation of a series,Use of Mellin transform for evaluation of a series,,"Show that $$\sum_{n=1}^\infty \frac{\sin an}{n}=\frac{\pi-a}{2} \ , \ 0<a<2\pi$$ I was asked to use Mellin transform to prove this result. So I used a formula related to the general series as follows $$\sum_{n=1}^\infty f(nx)=\mathcal{M}^{-1}\{F(s)\zeta(s);x\}$$ where $F(s)=\mathcal{M}\{f(x);s\}$ and $\zeta(s)$ is Riemann zeta function. Now taking $f(n)=\displaystyle\frac{\sin an}{n}$ we have $\displaystyle\mathcal{M}\bigg(\frac{\sin ax}{x}\bigg)=-\frac{\Gamma(s-1)\cos \frac{s\pi}{2}}{a^{s-1}}$ . Combining everything and using the  formula that $$\pi^s\zeta(1-s)=2^{1-s}\Gamma(s)\zeta(s)\cos \frac{s\pi}{2}$$ we have $$\sum_{n=1}^\infty \frac{\sin an}{n}=-\frac{a}{2}\mathcal{M}^{-1}\bigg\{\bigg(\frac{2\pi}{a}\bigg)^s\frac{\zeta(1-s)}{s-1};x=1\bigg\}$$ Now if we use calculus of residues to evaluate the expression at RHS, we see that we have singularity at $s=1$ . Using $\zeta(0)=-\frac{1}{2}$ we can easily calculate the residue at $s=1$ , which is $\displaystyle-\frac{\pi}{a}$ .  So I get the answer $$\sum_{n=1}^\infty \frac{\sin an}{n}=-\frac{a}{2}.\bigg(-\frac{\pi}{a}\bigg)=\frac{\pi}{2}$$ which is wrong of course as there should be an extra term $-\displaystyle\frac{a}{2}$ on RHS.  My doubt is I am missing a residue on the RHS while calculating the Mellin inverse, but I am unable to get that.  I need a help in this regard. Any help is appreciated.","Show that I was asked to use Mellin transform to prove this result. So I used a formula related to the general series as follows where and is Riemann zeta function. Now taking we have . Combining everything and using the  formula that we have Now if we use calculus of residues to evaluate the expression at RHS, we see that we have singularity at . Using we can easily calculate the residue at , which is .  So I get the answer which is wrong of course as there should be an extra term on RHS.  My doubt is I am missing a residue on the RHS while calculating the Mellin inverse, but I am unable to get that.  I need a help in this regard. Any help is appreciated.","\sum_{n=1}^\infty \frac{\sin an}{n}=\frac{\pi-a}{2} \ , \ 0<a<2\pi \sum_{n=1}^\infty f(nx)=\mathcal{M}^{-1}\{F(s)\zeta(s);x\} F(s)=\mathcal{M}\{f(x);s\} \zeta(s) f(n)=\displaystyle\frac{\sin an}{n} \displaystyle\mathcal{M}\bigg(\frac{\sin ax}{x}\bigg)=-\frac{\Gamma(s-1)\cos \frac{s\pi}{2}}{a^{s-1}} \pi^s\zeta(1-s)=2^{1-s}\Gamma(s)\zeta(s)\cos \frac{s\pi}{2} \sum_{n=1}^\infty \frac{\sin an}{n}=-\frac{a}{2}\mathcal{M}^{-1}\bigg\{\bigg(\frac{2\pi}{a}\bigg)^s\frac{\zeta(1-s)}{s-1};x=1\bigg\} s=1 \zeta(0)=-\frac{1}{2} s=1 \displaystyle-\frac{\pi}{a} \sum_{n=1}^\infty \frac{\sin an}{n}=-\frac{a}{2}.\bigg(-\frac{\pi}{a}\bigg)=\frac{\pi}{2} -\displaystyle\frac{a}{2}","['sequences-and-series', 'integral-transforms', 'mellin-transform']"
4,A question on convergence of real sequence,A question on convergence of real sequence,,Is there a sequence $\{x_n\}$ such that $\frac{x_n}{n}$ tends to $0$ but $\frac{x_n}{n^\alpha}$ does not tend to $0$ for any $0 < \alpha < 1$ ? More importantly is there a sequence of natural numbers with the above property?,Is there a sequence such that tends to but does not tend to for any ? More importantly is there a sequence of natural numbers with the above property?,\{x_n\} \frac{x_n}{n} 0 \frac{x_n}{n^\alpha} 0 0 < \alpha < 1,"['real-analysis', 'calculus', 'sequences-and-series']"
5,prove two dependent sequences converge,prove two dependent sequences converge,,"Please help with my homework question: Define $\{a_n\}_{n=1}^{\infty}$ , $\{b_n\}_{n=1}^{\infty}$ as: $b_{n+1}=\frac{a_n+b_n}{2}, a_{n+1}=\frac{a_n^2+b_n^2}{a_n+b_n}, 0<b_1<a_1$ Prove the limits converge and that $\lim \limits_{n \to \infty}a_n = \lim \limits_{n \to \infty}b_n $ . I have tried to show that they are monotone and bounded, tried looking for a property of arithmetic mean (related to $b_n$ ) but I'm completely stuck as none of these yielded anything useful. Any help would be appreciated","Please help with my homework question: Define , as: Prove the limits converge and that . I have tried to show that they are monotone and bounded, tried looking for a property of arithmetic mean (related to ) but I'm completely stuck as none of these yielded anything useful. Any help would be appreciated","\{a_n\}_{n=1}^{\infty} \{b_n\}_{n=1}^{\infty} b_{n+1}=\frac{a_n+b_n}{2}, a_{n+1}=\frac{a_n^2+b_n^2}{a_n+b_n}, 0<b_1<a_1 \lim \limits_{n \to \infty}a_n = \lim \limits_{n \to \infty}b_n  b_n","['sequences-and-series', 'convergence-divergence']"
6,"Is it possible to represent the natural number ""1"" as the sum of p-series in this way?","Is it possible to represent the natural number ""1"" as the sum of p-series in this way?",,"My argument: $$1=(\frac{1}{2})^2+(\frac{1}{3})^2+\cdots+(\frac{1}{2})^3+(\frac{1}{3})^3+\cdots=\sum_{k=2}^\infty (\frac{1}{k})^2+\sum_{k=2}^\infty (\frac{1}{k})^3+\cdots .$$ Explanation) First, for any natural number $n\geq2$ , the following holds: $$\sum_{k=1}^\infty (\frac{1}{n})^k=(\frac{1}{n})+(\frac{1}{n})^2+(\frac{1}{n})^3+\cdots= \frac{\frac{1}{n}}{1-\frac{1}{n}}=\frac{1}{n-1}.$$ (the infinite geometric series.) So, we obtain $$1=(\frac{1}{2})+(\frac{1}{2})^2+\cdots=\sum_{k=1}^\infty (\frac{1}{2})^k,$$ $$\frac{1}{2}=(\frac{1}{3})+(\frac{1}{3})^2+\cdots=\sum_{k=1}^\infty (\frac{1}{3})^k,$$ $$\frac{1}{3}=(\frac{1}{4})+(\frac{1}{4})^2+\cdots=\sum_{k=1}^\infty (\frac{1}{4})^k,$$ and so on. From above equalities, $$1=(\frac{1}{2})+(\frac{1}{2})^2+\cdots$$ $$=((\frac{1}{3})+(\frac{1}{3})^2+\cdots)+(\frac{1}{2})^2+(\frac{1}{2})^3+\cdots$$ $$=((\frac{1}{4})+(\frac{1}{4})^2+\cdots)+(\frac{1}{3})^2+(\frac{1}{3})^3+\cdots+(\frac{1}{2})^2+(\frac{1}{2})^3+\cdots$$ $$=\cdots .$$ If $p\ge2$ , then p-series absolutely converges. Hence we can change the order of terms in series as follows: $$1=(\frac{1}{2})^2+(\frac{1}{3})^2+(\frac{1}{4})^2+\cdots$$ $$+(\frac{1}{2})^3+(\frac{1}{3})^3+(\frac{1}{4})^3+\cdots$$ $$+(\frac{1}{2})^4+(\frac{1}{3})^4+(\frac{1}{4})^4+\cdots$$ $$=\sum_{k=2}^\infty (\frac{1}{k})^2+\sum_{k=2}^\infty (\frac{1}{k})^3+\sum_{k=2}^\infty (\frac{1}{k})^4+\cdots.$$ Thus, ""1"" becomes the sum of p-series(exactly from $k=2$ to infinity). Is this explanation correct?","My argument: Explanation) First, for any natural number , the following holds: (the infinite geometric series.) So, we obtain and so on. From above equalities, If , then p-series absolutely converges. Hence we can change the order of terms in series as follows: Thus, ""1"" becomes the sum of p-series(exactly from to infinity). Is this explanation correct?","1=(\frac{1}{2})^2+(\frac{1}{3})^2+\cdots+(\frac{1}{2})^3+(\frac{1}{3})^3+\cdots=\sum_{k=2}^\infty (\frac{1}{k})^2+\sum_{k=2}^\infty (\frac{1}{k})^3+\cdots . n\geq2 \sum_{k=1}^\infty (\frac{1}{n})^k=(\frac{1}{n})+(\frac{1}{n})^2+(\frac{1}{n})^3+\cdots= \frac{\frac{1}{n}}{1-\frac{1}{n}}=\frac{1}{n-1}. 1=(\frac{1}{2})+(\frac{1}{2})^2+\cdots=\sum_{k=1}^\infty (\frac{1}{2})^k, \frac{1}{2}=(\frac{1}{3})+(\frac{1}{3})^2+\cdots=\sum_{k=1}^\infty (\frac{1}{3})^k, \frac{1}{3}=(\frac{1}{4})+(\frac{1}{4})^2+\cdots=\sum_{k=1}^\infty (\frac{1}{4})^k, 1=(\frac{1}{2})+(\frac{1}{2})^2+\cdots =((\frac{1}{3})+(\frac{1}{3})^2+\cdots)+(\frac{1}{2})^2+(\frac{1}{2})^3+\cdots =((\frac{1}{4})+(\frac{1}{4})^2+\cdots)+(\frac{1}{3})^2+(\frac{1}{3})^3+\cdots+(\frac{1}{2})^2+(\frac{1}{2})^3+\cdots =\cdots . p\ge2 1=(\frac{1}{2})^2+(\frac{1}{3})^2+(\frac{1}{4})^2+\cdots +(\frac{1}{2})^3+(\frac{1}{3})^3+(\frac{1}{4})^3+\cdots +(\frac{1}{2})^4+(\frac{1}{3})^4+(\frac{1}{4})^4+\cdots =\sum_{k=2}^\infty (\frac{1}{k})^2+\sum_{k=2}^\infty (\frac{1}{k})^3+\sum_{k=2}^\infty (\frac{1}{k})^4+\cdots. k=2",['sequences-and-series']
7,To prove sum of A.P is greater than G.P,To prove sum of A.P is greater than G.P,,"Consider an Arithmetic Progression(A.P) with the first term $a$ , the commom difference $d$ and a Geometric Progression(G.P) with first term again as $a$ but common ratio $r$ such that $a,d,r>0$ and both these progressions have same number of terms and their last terms are also equal. Show that the sum of all the terms of A.P is greater than the sum of all the terms of the G.P. My Attempt: The terms between first and last terms are the $(n-2)$ Arithmetic Means(A.M's) or the Geometric Means(G.M's). Can it be proved that each of the A.M's is greater than the corresponding G.M's.","Consider an Arithmetic Progression(A.P) with the first term , the commom difference and a Geometric Progression(G.P) with first term again as but common ratio such that and both these progressions have same number of terms and their last terms are also equal. Show that the sum of all the terms of A.P is greater than the sum of all the terms of the G.P. My Attempt: The terms between first and last terms are the Arithmetic Means(A.M's) or the Geometric Means(G.M's). Can it be proved that each of the A.M's is greater than the corresponding G.M's.","a d a r a,d,r>0 (n-2)","['sequences-and-series', 'arithmetic-progressions', 'geometric-progressions']"
8,Find limit of recurrent sequence?,Find limit of recurrent sequence?,,"Let $ \forall n \in \mathbf{N}, ~ u_{n+1} = \frac{1}{\tanh^2(u_n)} - \frac{1}{u^2_n} $ with $ u_0 = a > 0 $ . What is the limit of $(u_n)$ ? I tried to find a fixed point of this sequence but the equation is impossible to solve algebraically.",Let with . What is the limit of ? I tried to find a fixed point of this sequence but the equation is impossible to solve algebraically.," \forall n \in \mathbf{N}, ~ u_{n+1} = \frac{1}{\tanh^2(u_n)} - \frac{1}{u^2_n}   u_0 = a > 0  (u_n)","['real-analysis', 'sequences-and-series', 'limits', 'recurrence-relations']"
9,Prove that $\exists c>0$ s.t $\sum_{n\geq x}\frac{1}{n^2}\leq \frac{c}{x}$ [duplicate],Prove that  s.t  [duplicate],\exists c>0 \sum_{n\geq x}\frac{1}{n^2}\leq \frac{c}{x},"This question already has answers here : Prove that there exists a constant $c>0$ such that the following happens (2 answers) Closed 4 years ago . $\mathbf{Question:}$ Prove that there exists a constant $c>0$ such that for all $x \in [1, \infty)$ , $\displaystyle\sum_{n \geq x}\frac{1}{n^2} \leq \frac{c}{x}$ $\mathbf{Attempt:}$ Evidently, $\displaystyle\bigg[\displaystyle\sum_{n =1}^\infty\frac{1}{n^2}-\sum_{j=1}^{\lfloor x \rfloor} \frac{1}{j^2}\bigg]{\lfloor x \rfloor}\leq x\displaystyle\sum_{n \geq x}\frac{1}{n^2} \leq \displaystyle\bigg[\sum_{n =1}^\infty\frac{1}{n^2}-\sum_{j=1}^{\lfloor x \rfloor} \frac{1}{j^2}\bigg]{\lceil x \rceil} $ . This inequality arises since, $\displaystyle\bigg[\sum_{n =1}^\infty\frac{1}{n^2}-\sum_{j=1}^{\lfloor x \rfloor} \frac{1}{j^2}\bigg]=\displaystyle\sum_{n \geq x}\frac{1}{n^2}$ . Now, let $\lfloor x\rfloor=m$ $\displaystyle\lim_{m \to \infty}\bigg[\sum_{n =1}^\infty\frac{1}{n^2}-\sum_{j=1}^m \frac{1}{j^2}\bigg]m$ $=\lim_{{m \to \infty},{r\to \infty}}\bigg[\frac{m}{(m+1)^2}+\frac{m}{(m+2)^2}+\frac{m}{(m+3)^2}+...+\frac{m}{(m+r)^2}+...\bigg]=$ $\lim_{{h \to 0},{r\to \infty}}h\bigg[\frac{1}{(1+h)^2}+\frac{1}{(1+2h)^2}+\frac{1}{(1+3h)^2}+...+\frac{1}{(1+rh)^2}+...\bigg]=\displaystyle\int_{x=0}^\infty\frac{1}{(1+x)^2}dx=1$ We have, $\lceil x\rceil=m+1$ and $\displaystyle\lim_{m \to \infty}\bigg[\sum_{n =1}^\infty\frac{1}{n^2}-\sum_{j=1}^m \frac{1}{j^2}\bigg](m+1)=\lim_{m \to \infty}\bigg[\sum_{n =1}^\infty\frac{1}{n^2}-\sum_{j=1}^m \frac{1}{j^2}\bigg]m$ Thereby, we conclude, $\displaystyle \lim_{x\to \infty}x\sum_{n \geq x}\frac{1}{n^2}=1 $ . Therefore, from the definition of limit, $\forall \varepsilon>0$ , $\exists G>0$ such that $\bigg|x\displaystyle\sum_{n \geq x}\frac{1}{n^2}-1\bigg|<\varepsilon$ $\forall x>G$ . Choosing $\varepsilon =1$ , we get $G=G_0$ such that $x\displaystyle\sum_{n \geq x}\frac{1}{n^2}<2$ , for any $x> G_0$ . We set $\displaystyle c=\max\bigg\{2, \sup_{x\in [1,G_0]}x\sum_{n \geq x}\frac{1}{n^2} \bigg\}$ Is this procedure valid? Kindly verify.","This question already has answers here : Prove that there exists a constant $c>0$ such that the following happens (2 answers) Closed 4 years ago . Prove that there exists a constant such that for all , Evidently, . This inequality arises since, . Now, let We have, and Thereby, we conclude, . Therefore, from the definition of limit, , such that . Choosing , we get such that , for any . We set Is this procedure valid? Kindly verify.","\mathbf{Question:} c>0 x \in [1, \infty) \displaystyle\sum_{n \geq x}\frac{1}{n^2} \leq \frac{c}{x} \mathbf{Attempt:} \displaystyle\bigg[\displaystyle\sum_{n =1}^\infty\frac{1}{n^2}-\sum_{j=1}^{\lfloor x \rfloor} \frac{1}{j^2}\bigg]{\lfloor x \rfloor}\leq x\displaystyle\sum_{n \geq x}\frac{1}{n^2} \leq \displaystyle\bigg[\sum_{n =1}^\infty\frac{1}{n^2}-\sum_{j=1}^{\lfloor x \rfloor} \frac{1}{j^2}\bigg]{\lceil x \rceil}  \displaystyle\bigg[\sum_{n =1}^\infty\frac{1}{n^2}-\sum_{j=1}^{\lfloor x \rfloor} \frac{1}{j^2}\bigg]=\displaystyle\sum_{n \geq x}\frac{1}{n^2} \lfloor x\rfloor=m \displaystyle\lim_{m \to \infty}\bigg[\sum_{n =1}^\infty\frac{1}{n^2}-\sum_{j=1}^m \frac{1}{j^2}\bigg]m =\lim_{{m \to \infty},{r\to \infty}}\bigg[\frac{m}{(m+1)^2}+\frac{m}{(m+2)^2}+\frac{m}{(m+3)^2}+...+\frac{m}{(m+r)^2}+...\bigg]= \lim_{{h \to 0},{r\to \infty}}h\bigg[\frac{1}{(1+h)^2}+\frac{1}{(1+2h)^2}+\frac{1}{(1+3h)^2}+...+\frac{1}{(1+rh)^2}+...\bigg]=\displaystyle\int_{x=0}^\infty\frac{1}{(1+x)^2}dx=1 \lceil x\rceil=m+1 \displaystyle\lim_{m \to \infty}\bigg[\sum_{n =1}^\infty\frac{1}{n^2}-\sum_{j=1}^m \frac{1}{j^2}\bigg](m+1)=\lim_{m \to \infty}\bigg[\sum_{n =1}^\infty\frac{1}{n^2}-\sum_{j=1}^m \frac{1}{j^2}\bigg]m \displaystyle \lim_{x\to \infty}x\sum_{n \geq x}\frac{1}{n^2}=1  \forall \varepsilon>0 \exists G>0 \bigg|x\displaystyle\sum_{n \geq x}\frac{1}{n^2}-1\bigg|<\varepsilon \forall x>G \varepsilon =1 G=G_0 x\displaystyle\sum_{n \geq x}\frac{1}{n^2}<2 x> G_0 \displaystyle c=\max\bigg\{2, \sup_{x\in [1,G_0]}x\sum_{n \geq x}\frac{1}{n^2} \bigg\}","['real-analysis', 'sequences-and-series', 'proof-verification', 'improper-integrals', 'ceiling-and-floor-functions']"
10,Alternating Fibonacci-like sequences are periodic?,Alternating Fibonacci-like sequences are periodic?,,"Define a Fibonacci-like sequence that depends on a parameter $k \in \mathbb{N}$ , and alternates $\pm$ : \begin{eqnarray} k=1 \;:\; f_1(n) &=& f_1(n-1)\\ k=2 \;:\; f_2(n) &=& f_2(n-1)-f_2(n-2)\\ k=3 \;:\; f_3(n) &=& f_3(n-1)-f_3(n-2)+f_3(n-3)\\ k=4 \;:\; f_4(n) &=& f_4(n-1)-f_4(n-2)+f_4(n-3)-f_4(n-4)\\ &\cdots&\\ k=k \;:\; f_k(n) &=& \Sigma_{i=1}^k (-1)^{i+1} f_k(n-i) \end{eqnarray} For any initial data specifying the values of $f_k(n)$ for $n=0,1,2,\ldots,k{-}1$ , I claim the sequence becomes periodic, with period $(k+1)$ if $k$ is odd, and $2(k+1)$ if $k$ is even.  For example, for $k=4$ , and initial values $$ \left(\; f_4(0),f_4(1),f_4(2),f_4(3) \;\right) = (1,2,3,4) \;, $$ then $f_4(n)$ , for $n=0,\ldots,20$ is: $$ 1, 2, 3, 4, 5, 2, -2, -3, -4, -5, -2, 2, 3, 4, 5, 2, -2, -3, -4, -5, -2 \;, $$ with period $2(k+1)=10$ . For example, \begin{eqnarray} f_4(5) &=& f_4(4)-f_4(3)+f_4(2)-f_4(1)\\ f_4(5) &=& 5-4+3-2\\ f_4(5) &=& 2 \;. \end{eqnarray} If instead we pin all initial values to $1$ , so that $$ \left( \; f_4(0),f_4(1),f_4(2),f_4(3) \; \right) = (1,1,1,1) \;, $$ the resulting sequence is: $$ 1, 1, 1, 1, 1, 0, -1, -1, -1, -1, 0, 1, 1, 1, 1, 0, -1, -1, -1, -1, 0 \;, $$ also period $10$ . My question: Q . What is a proof of the claim that such alternating   Fibonacci sequences $f_k(n)$ are periodic for any initial values? I can prove that, e.g., $f_4(n)$ is periodic with period $10$ , but only via induction for that specific $k{=}4$ , and initial conditions. But if my claim is true, there should be a way to see that all $f_k(n)$ , regardless of initial values, are periodic with those odd/even periods $(k+1)$ / $2(k+1)$ .","Define a Fibonacci-like sequence that depends on a parameter , and alternates : For any initial data specifying the values of for , I claim the sequence becomes periodic, with period if is odd, and if is even.  For example, for , and initial values then , for is: with period . For example, If instead we pin all initial values to , so that the resulting sequence is: also period . My question: Q . What is a proof of the claim that such alternating   Fibonacci sequences are periodic for any initial values? I can prove that, e.g., is periodic with period , but only via induction for that specific , and initial conditions. But if my claim is true, there should be a way to see that all , regardless of initial values, are periodic with those odd/even periods / .","k \in \mathbb{N} \pm \begin{eqnarray}
k=1 \;:\; f_1(n) &=& f_1(n-1)\\
k=2 \;:\; f_2(n) &=& f_2(n-1)-f_2(n-2)\\
k=3 \;:\; f_3(n) &=& f_3(n-1)-f_3(n-2)+f_3(n-3)\\
k=4 \;:\; f_4(n) &=& f_4(n-1)-f_4(n-2)+f_4(n-3)-f_4(n-4)\\
&\cdots&\\
k=k \;:\; f_k(n) &=& \Sigma_{i=1}^k (-1)^{i+1} f_k(n-i)
\end{eqnarray} f_k(n) n=0,1,2,\ldots,k{-}1 (k+1) k 2(k+1) k k=4 
\left(\; f_4(0),f_4(1),f_4(2),f_4(3) \;\right) = (1,2,3,4) \;,
 f_4(n) n=0,\ldots,20 
1, 2, 3, 4, 5, 2, -2, -3, -4, -5, -2, 2, 3, 4, 5, 2, -2, -3, -4, -5, -2 \;,
 2(k+1)=10 \begin{eqnarray}
f_4(5) &=& f_4(4)-f_4(3)+f_4(2)-f_4(1)\\
f_4(5) &=& 5-4+3-2\\
f_4(5) &=& 2 \;.
\end{eqnarray} 1 
\left( \; f_4(0),f_4(1),f_4(2),f_4(3) \; \right) = (1,1,1,1) \;,
 
1, 1, 1, 1, 1, 0, -1, -1, -1, -1, 0, 1, 1, 1, 1, 0, -1, -1, -1, -1, 0 \;,
 10 f_k(n) f_4(n) 10 k{=}4 f_k(n) (k+1) 2(k+1)","['sequences-and-series', 'recurrence-relations', 'fibonacci-numbers']"
11,Compute $\sum_{n=1}^\infty (-1)^{n-1}\frac{H_{2n+1}}{(2n+1)^3}$ and $\sum_{n=1}^\infty (-1)^{n-1}\frac{H_{2n+1}^{(2)}}{(2n+1)^2}$,Compute  and,\sum_{n=1}^\infty (-1)^{n-1}\frac{H_{2n+1}}{(2n+1)^3} \sum_{n=1}^\infty (-1)^{n-1}\frac{H_{2n+1}^{(2)}}{(2n+1)^2},"How to prove $$S_1=\sum_{n=1}^\infty (-1)^{n-1}\frac{H_{2n+1}}{(2n+1)^3}=1+\frac{35}{128}\pi\zeta(3)+\frac{1}{48}\zeta(4)-\frac1{384}\psi^{(3)}\left(\frac14\right)$$ $$S_2=\sum_{n=1}^\infty (-1)^{n-1}\frac{H_{2n+1}^{(2)}}{(2n+1)^2}=1+\frac18G\zeta(2)-\frac{35}{64}\pi\zeta(3)-\frac{15}{16}\zeta(4)+\frac1{768}\psi^{(3)}\left(\frac14\right)$$ where $H_n=\sum_{n=1}^\infty\frac1n$ is the $n$ th harmonic number, $G$ denotes the Catalan's constant, $\zeta$ denotes the Riemann Zeta function and $\psi^{(n)}$ designates the polygamma function. These two sums were proposed by Cornel and can be found here and here . My solution to $S_1$ can be found in the first link but its long, so can we find a better way to find $S_1$ and $S_2$ ? Thanks. Note: Using the generating function of $\ \sum_{n=1}^\infty x^n\frac{H_n}{n^3}$ to evaluate $S_1$ is not allowed.","How to prove where is the th harmonic number, denotes the Catalan's constant, denotes the Riemann Zeta function and designates the polygamma function. These two sums were proposed by Cornel and can be found here and here . My solution to can be found in the first link but its long, so can we find a better way to find and ? Thanks. Note: Using the generating function of to evaluate is not allowed.",S_1=\sum_{n=1}^\infty (-1)^{n-1}\frac{H_{2n+1}}{(2n+1)^3}=1+\frac{35}{128}\pi\zeta(3)+\frac{1}{48}\zeta(4)-\frac1{384}\psi^{(3)}\left(\frac14\right) S_2=\sum_{n=1}^\infty (-1)^{n-1}\frac{H_{2n+1}^{(2)}}{(2n+1)^2}=1+\frac18G\zeta(2)-\frac{35}{64}\pi\zeta(3)-\frac{15}{16}\zeta(4)+\frac1{768}\psi^{(3)}\left(\frac14\right) H_n=\sum_{n=1}^\infty\frac1n n G \zeta \psi^{(n)} S_1 S_1 S_2 \ \sum_{n=1}^\infty x^n\frac{H_n}{n^3} S_1,"['integration', 'sequences-and-series', 'definite-integrals', 'harmonic-analysis', 'polygamma']"
12,Does the series $\sum_{n=1}^{\infty}\frac{\cos(n+x)}{n}$ converge uniformly?,Does the series  converge uniformly?,\sum_{n=1}^{\infty}\frac{\cos(n+x)}{n},"Does the following series $$\sum_{n=1}^{\infty}\frac{\cos(n+x)}{n}$$ converge uniformly? I know the series converges pointwise since $\sum_{n}\frac{\cos n}{n}$ and $\sum_{n}\frac{\sin n}{n}$ converge. From desmos, it seems the series converges to some sort of sine wave and is infinitely differentiable. I have tried rewriting the series into $$\sum_{n=1}^{\infty}\frac{\cos n\cos x - \sin n\sin x}{n}$$ in order to use the Weierstrass M-Test. However, I'm not sure how to get a sequence of constants $C_{n}$ such that $$\sup_{x\in\mathbb{R}}\left|\frac{\cos n\cos x - \sin n\sin x}{n}\right|\leq C_{n}$$ and where $\sum_{n=1}^{\infty}C_{n}$ converges. I tried using the triangle inequality but this gives me something like $$\frac{|\cos n| + |\sin n|}{n}$$ This doesn't appear to help because it negates cancellation of positive and negative terms so my intuition tells me $\sum_{n=1}^{\infty}\frac{|\cos n| + |\sin n|}{n}$ would diverge as the harmonic series diverges. Is it possible to use the Weierstrass M-Test here to prove the series $\sum_{n=1}^{\infty}\frac{\cos(n+x)}{n}$ converges uniformly?","Does the following series converge uniformly? I know the series converges pointwise since and converge. From desmos, it seems the series converges to some sort of sine wave and is infinitely differentiable. I have tried rewriting the series into in order to use the Weierstrass M-Test. However, I'm not sure how to get a sequence of constants such that and where converges. I tried using the triangle inequality but this gives me something like This doesn't appear to help because it negates cancellation of positive and negative terms so my intuition tells me would diverge as the harmonic series diverges. Is it possible to use the Weierstrass M-Test here to prove the series converges uniformly?",\sum_{n=1}^{\infty}\frac{\cos(n+x)}{n} \sum_{n}\frac{\cos n}{n} \sum_{n}\frac{\sin n}{n} \sum_{n=1}^{\infty}\frac{\cos n\cos x - \sin n\sin x}{n} C_{n} \sup_{x\in\mathbb{R}}\left|\frac{\cos n\cos x - \sin n\sin x}{n}\right|\leq C_{n} \sum_{n=1}^{\infty}C_{n} \frac{|\cos n| + |\sin n|}{n} \sum_{n=1}^{\infty}\frac{|\cos n| + |\sin n|}{n} \sum_{n=1}^{\infty}\frac{\cos(n+x)}{n},"['sequences-and-series', 'convergence-divergence', 'uniform-convergence']"
13,$a+b+c=-3\sqrt{ac}$,,a+b+c=-3\sqrt{ac},"If $a,b,c$ be in Geometic Progression, and $b-c,c-a,a-b$ in Harmonic Progression then prove that $a+b+c=-3\sqrt{ac}$ . My attempt: $$c-a=\frac{2(b-c)(a-b)}{b-c+a-b}$$ $$(c-a)^2+2(b-c)(a-b)=0$$ $$c^2+a^2-2ac+2(ab-b^2-ac+bc)=0$$ $$a^2+c^2-2b^2-4ac+2ab+2bc=0$$ $$a^2+c^2-6ac+2b(a+c)=0(b^2=ac)$$ $$a^2+c^2+2ac+2b(a+c)=8ac$$ $$(a+c)(a+c+2b)=8ac$$ $$(a+c)(\sqrt{a}+\sqrt{c})^2=8(\sqrt{ac})^2(b=\sqrt{ac})$$","If be in Geometic Progression, and in Harmonic Progression then prove that . My attempt:","a,b,c b-c,c-a,a-b a+b+c=-3\sqrt{ac} c-a=\frac{2(b-c)(a-b)}{b-c+a-b} (c-a)^2+2(b-c)(a-b)=0 c^2+a^2-2ac+2(ab-b^2-ac+bc)=0 a^2+c^2-2b^2-4ac+2ab+2bc=0 a^2+c^2-6ac+2b(a+c)=0(b^2=ac) a^2+c^2+2ac+2b(a+c)=8ac (a+c)(a+c+2b)=8ac (a+c)(\sqrt{a}+\sqrt{c})^2=8(\sqrt{ac})^2(b=\sqrt{ac})",['sequences-and-series']
14,About the sequence $n^{\frac{1}{n}} -1$,About the sequence,n^{\frac{1}{n}} -1,"I am having trouble with this multiple-select mcq question: The value of $n^{\frac{1}{n}} -1$ tends to $0$ as $n\to \infty$ , is greater than $\frac{\log n}{n}$ for all $n\geq 3$ , is greater than $\log n$ for all $n\geq 3$ , is greater than $\frac{1}{\sqrt{n}}$ for all $n\geq 3$ . I know that option 1 is correct, because $\lim_{n\to \infty}n^{\frac{1}{n}} =1$ . Also, $$n^{\frac{1}{n}} -1=-1+ e^{\frac{\log n}{n}} =\frac{\log n}{n} + \frac{(\log n)^2}{n^2}/2! +...\geq \frac{\log n}{n},$$ meaning option 2 is also correct. But I don't see how to prove or disprove the other two options. Any help would be appreciated!","I am having trouble with this multiple-select mcq question: The value of tends to as , is greater than for all , is greater than for all , is greater than for all . I know that option 1 is correct, because . Also, meaning option 2 is also correct. But I don't see how to prove or disprove the other two options. Any help would be appreciated!","n^{\frac{1}{n}} -1 0 n\to \infty \frac{\log n}{n} n\geq 3 \log n n\geq 3 \frac{1}{\sqrt{n}} n\geq 3 \lim_{n\to \infty}n^{\frac{1}{n}} =1 n^{\frac{1}{n}} -1=-1+ e^{\frac{\log n}{n}} =\frac{\log n}{n} + \frac{(\log n)^2}{n^2}/2! +...\geq \frac{\log n}{n},","['real-analysis', 'sequences-and-series', 'limits']"
15,estimating the tail of $p$-series,estimating the tail of -series,p,"Let $  p >0 $ be a positive real. We consider the $p$ -series $$ \sum_{ n > N} \frac{1}{n^p} $$ where $ N \to \infty.$ An application of the integral test show that in the case where the series converges (namely for $ p > 1,$ then one has the estimate $$ \sum_{ n > N} \frac{1}{n^p} \ll N^{1-p},$$ as $ N \to \infty.$ My question is the following. Question 1: Under what assumptions one can obtain the tighter upper bound $$ \sum_{ n > N} \frac{1}{n^p} \ll N^{-p},$$ as $ N \to \infty?$ edit: After the comments of Sandeep Silwal , I have decided to change a bit the range of summation, hoping to get something better than $ \ll N^{1-p}.$ Here is the new question: Question 2: Let $ \delta \in (0,1).$ Under what assumptions on p, is it true that $$ \sum_{ n > N^\delta} \frac{1}{n^p} \ll N^{-p\delta} \quad ? $$ Finally, I think (if such an estimate is valid) that one could sum at the level $ n \geq h(N)$ where $h (N)$ is a positive slowly, increasing to infinity function, with $h(N) = o(N), \quad N \to \infty.$","Let be a positive real. We consider the -series where An application of the integral test show that in the case where the series converges (namely for then one has the estimate as My question is the following. Question 1: Under what assumptions one can obtain the tighter upper bound as edit: After the comments of Sandeep Silwal , I have decided to change a bit the range of summation, hoping to get something better than Here is the new question: Question 2: Let Under what assumptions on p, is it true that Finally, I think (if such an estimate is valid) that one could sum at the level where is a positive slowly, increasing to infinity function, with","  p >0  p  \sum_{ n > N} \frac{1}{n^p}   N \to \infty.  p > 1,  \sum_{ n > N} \frac{1}{n^p} \ll N^{1-p},  N \to \infty.  \sum_{ n > N} \frac{1}{n^p} \ll N^{-p},  N \to \infty?  \ll N^{1-p}.  \delta \in (0,1).  \sum_{ n > N^\delta} \frac{1}{n^p} \ll N^{-p\delta} \quad ?   n \geq h(N) h (N) h(N) = o(N), \quad N \to \infty.","['sequences-and-series', 'analysis', 'asymptotics', 'divergent-series']"
16,Showing $f(x) = \frac{x^2}{\sin(x)}$ is analytic near $0$,Showing  is analytic near,f(x) = \frac{x^2}{\sin(x)} 0,"Problem Show the function $$ f(x) = \frac{x^2}{\sin(x)} $$ is an analytic about $x=0$ . Try We have $$ f(x) = \frac{x^2}{x - x^3/3! + x^5/5! - \cdots } $$ Letting $f(x) = \sum_{n=0}^\infty a_n x^n $ , we have $$ a_0 = 0, a_1 = 1, a_2 = 0, a_3 = 1/6, a_4 = 0, a_5 = 7/360, \cdots $$ thus $f(x) = x - x^3/6 + \cdots$ . Now we have to decide if $\sum_{n=0}^\infty a_n x^n$ is convergent near zero. But I cannot see the rules of $a_0, a_1, a_2, \cdots$ , so how should I proceed? It is known that Assume $f: = \sum_{n=0}^\infty b_n x^n$ and $g:= \sum_{n=0}^\infty c_n x^n$ be convergent near zero with radius of convergence $\rho>0$ . If $g(0) \neq 0$ , we have $$ \frac{f}{g} = \sum_{n=0}^\infty d_n $$ for some radius of convergence $\le \rho$ . So relating this fact to my problem, $$ f(x) = \frac{x}{1 - x^2/3! + x^4/5! - \cdots } $$ may be convergent with radius of convergence $\le \infty$ , which is the radius of $x^2$ (poylnomial) and $\sin(x)$","Problem Show the function is an analytic about . Try We have Letting , we have thus . Now we have to decide if is convergent near zero. But I cannot see the rules of , so how should I proceed? It is known that Assume and be convergent near zero with radius of convergence . If , we have for some radius of convergence . So relating this fact to my problem, may be convergent with radius of convergence , which is the radius of (poylnomial) and","
f(x) = \frac{x^2}{\sin(x)}
 x=0 
f(x) = \frac{x^2}{x - x^3/3! + x^5/5! - \cdots }
 f(x) = \sum_{n=0}^\infty a_n x^n  
a_0 = 0, a_1 = 1, a_2 = 0, a_3 = 1/6, a_4 = 0, a_5 = 7/360, \cdots
 f(x) = x - x^3/6 + \cdots \sum_{n=0}^\infty a_n x^n a_0, a_1, a_2, \cdots f: = \sum_{n=0}^\infty b_n x^n g:= \sum_{n=0}^\infty c_n x^n \rho>0 g(0) \neq 0 
\frac{f}{g} = \sum_{n=0}^\infty d_n
 \le \rho 
f(x) = \frac{x}{1 - x^2/3! + x^4/5! - \cdots }
 \le \infty x^2 \sin(x)",['sequences-and-series']
17,Proving $ \sum_{n \in \mathbb{Z} } \left[\frac{\sin (n \alpha + \theta) }{ n \alpha + \theta} \right]^2 = \frac{\pi}{\alpha} $,Proving, \sum_{n \in \mathbb{Z} } \left[\frac{\sin (n \alpha + \theta) }{ n \alpha + \theta} \right]^2 = \frac{\pi}{\alpha} ,"Proving $$ \sum_{n \in \mathbb{Z} } \left[\frac{\sin (n \alpha + \theta)  }{ n \alpha + \theta} \right]^2 = \frac{\pi}{\alpha} \,\, \forall \alpha , \theta \in \mathbb{R} $$ My attempt It is known that $$\sum_{n\in\mathbb{Z}}\frac{1}{(n\pi+x)^2}=\csc^2(x)\tag{1}$$ which can be yielded from $$\sin(\pi x)=\pi x\prod_{n=1}^\infty\left(1-\frac{x^2}{n^2}\right)$$ Thus for the situation $\alpha = \pi$ we have $$ \sum_{n \in \mathbb{Z} } \left[\frac{\sin (n \pi + \theta)  }{ n \pi + \theta} \right]^2  =  \sum_{n \in \mathbb{Z} } \left(\frac{\sin\theta }{ n \pi + \theta} \right)^2  = 1 $$ But how to deal with the situation that $\alpha \ne \pi$ ? Since $$ \displaystyle\sum_{n \in \mathbb{Z} } \frac{1}{ (n \alpha + \theta)^2} = \frac{\pi^2 \csc^2 \frac{\pi\theta}{\alpha} }{\alpha^2} $$ is a corollary of $(1)$ , we only need to evaluate $ \displaystyle\sum_{n \in \mathbb{Z} } \frac{\cos (2n \alpha + 2\theta)  }{ (n \alpha + \theta)^2}   $ , which means to evaluate $$ \displaystyle\sum_{n \in \mathbb{Z} } \frac{\cos (2n \alpha ) }{ (n \alpha + \theta)^2} \tag{2} $$ and $$ \displaystyle\sum_{n \in \mathbb{Z} } \frac{\sin(2n \alpha ) }{ (n \alpha + \theta)^2} \tag{3} $$ In the post linked , we get a nice equation $$ \frac{\pi \cos(xy)}{\sin(\pi y)} =\sum_{n=-\infty}^\infty \frac{(-1)^n\cos(nx)}{y-n} $$ If there doesn't exist $(-1)^n$ , we can evaluate $(2)$ and $(3)$ by differentiating and selecting appropriate $x$ . But I got stuck on that. Any hints? Thanks in advance!","Proving My attempt It is known that which can be yielded from Thus for the situation we have But how to deal with the situation that ? Since is a corollary of , we only need to evaluate , which means to evaluate and In the post linked , we get a nice equation If there doesn't exist , we can evaluate and by differentiating and selecting appropriate . But I got stuck on that. Any hints? Thanks in advance!","
\sum_{n \in \mathbb{Z} } \left[\frac{\sin (n \alpha + \theta)  }{ n \alpha + \theta} \right]^2 = \frac{\pi}{\alpha} \,\, \forall \alpha , \theta \in \mathbb{R}
 \sum_{n\in\mathbb{Z}}\frac{1}{(n\pi+x)^2}=\csc^2(x)\tag{1} \sin(\pi x)=\pi x\prod_{n=1}^\infty\left(1-\frac{x^2}{n^2}\right) \alpha = \pi 
\sum_{n \in \mathbb{Z} } \left[\frac{\sin (n \pi + \theta)  }{ n \pi + \theta} \right]^2 
= 
\sum_{n \in \mathbb{Z} } \left(\frac{\sin\theta }{ n \pi + \theta} \right)^2 
= 1
 \alpha \ne \pi 
\displaystyle\sum_{n \in \mathbb{Z} } \frac{1}{ (n \alpha + \theta)^2} = \frac{\pi^2 \csc^2 \frac{\pi\theta}{\alpha} }{\alpha^2}
 (1) 
\displaystyle\sum_{n \in \mathbb{Z} } \frac{\cos (2n \alpha + 2\theta)  }{ (n \alpha + \theta)^2}  
 
\displaystyle\sum_{n \in \mathbb{Z} } \frac{\cos (2n \alpha ) }{ (n \alpha + \theta)^2} \tag{2}
 
\displaystyle\sum_{n \in \mathbb{Z} } \frac{\sin(2n \alpha ) }{ (n \alpha + \theta)^2} \tag{3}
 
\frac{\pi \cos(xy)}{\sin(\pi y)}
=\sum_{n=-\infty}^\infty \frac{(-1)^n\cos(nx)}{y-n}
 (-1)^n (2) (3) x","['real-analysis', 'sequences-and-series', 'complex-analysis', 'fourier-analysis']"
18,An unusal feature of a usual double sum of product of two binomial coefficiens,An unusal feature of a usual double sum of product of two binomial coefficiens,,"We know that $$\sum_{0 \le i \le j \le n}  A_i~ A_j= \frac{\left(\sum_{k=0}^{n} A_k\right) ^2+\sum_{k=0}^{n} A_k^2}{2}~~(1)$$ One can find $$ S= \sum_{0 \le i \le j < \infty} ~ 2^{-i-j}$$ using (1), we get $S=8/3$ . We can also find $S$ as below: $$S=\sum_{j=0}^{\infty} 2^{-j} \sum_{i=0}^{j} 2^{-i}= \sum_{j=0}^{\infty} 2^{-j} \frac{(2)^{-j-1}-1}{2^{-1}-1} =2\sum_{j=0}^{\infty}[2^{-j}-(2)^{-2j-1}]=8/3.$$ Using (1). we usually get $$T=\sum_{0 \le i \le j \le n}  {n \choose i} {n \choose j} = \frac{4^n+{2n \choose n}}{2}.$$ But we cannon get $T$ as $$ T =\sum_{j=0}^{n} {n \choose j} \sum_{i=0}^{j} {n \choose i},$$ because the second term is not doable in a closed form. Any help!","We know that One can find using (1), we get . We can also find as below: Using (1). we usually get But we cannon get as because the second term is not doable in a closed form. Any help!","\sum_{0 \le i \le j \le n}  A_i~ A_j= \frac{\left(\sum_{k=0}^{n} A_k\right) ^2+\sum_{k=0}^{n} A_k^2}{2}~~(1)  S= \sum_{0 \le i \le j < \infty} ~ 2^{-i-j} S=8/3 S S=\sum_{j=0}^{\infty} 2^{-j} \sum_{i=0}^{j} 2^{-i}= \sum_{j=0}^{\infty} 2^{-j} \frac{(2)^{-j-1}-1}{2^{-1}-1} =2\sum_{j=0}^{\infty}[2^{-j}-(2)^{-2j-1}]=8/3. T=\sum_{0 \le i \le j \le n}  {n \choose i} {n \choose j} = \frac{4^n+{2n \choose n}}{2}. T  T =\sum_{j=0}^{n} {n \choose j} \sum_{i=0}^{j} {n \choose i},","['sequences-and-series', 'combinations', 'binomial-coefficients']"
19,Is $\ell^1$ complete with this norm?,Is  complete with this norm?,\ell^1,"For $x \in \ell^1$ we set $\Vert x\Vert = \sup\limits_{N \in \mathbb{N}}|\sum\limits_{n=1}^{N}x_n|$ . One can easily see that this is a norm on $\ell^1$ . I was wondering if this space is now complete. I tried finding an absolutely convergent series that does not converge, but I did not find anything.","For we set . One can easily see that this is a norm on . I was wondering if this space is now complete. I tried finding an absolutely convergent series that does not converge, but I did not find anything.",x \in \ell^1 \Vert x\Vert = \sup\limits_{N \in \mathbb{N}}|\sum\limits_{n=1}^{N}x_n| \ell^1,"['sequences-and-series', 'functional-analysis', 'absolute-convergence']"
20,Show that $x\sin\frac{1}{x}$ has an unbounded 'length',Show that  has an unbounded 'length',x\sin\frac{1}{x},"This is problem 16 chapter 23 of 'Calculus-Spivak (3rd edition)' Consider the following 'length' describing set $$\ell(f,P)=\sum_{i=1}^{n}\sqrt{(t_{i}-t_{i-1})^2+[f(t_i)-f(t_{i-1})]^2}$$ Where $P=\{t_{1}<\dots<t_{n}\}$ is a partition of the interval being 'measured'. Let $f(x)=x  \cdot \sin( \frac{1}{x})$ for $0 < x \leq 1 $ and $f(0)=0$ . Show that $f$ has an 'infinite length'on $[0,1]$ by showing the unboundness of $\ell(f,P)$ by considering the partition $$P^*=\left\{ 0, \frac{2}{(2n+1)\pi},\dots,\frac{2}{5\pi},\frac{2}{3\pi},\frac{2}{\pi},1 \right\}$$ My attempt : Without loss of generality we can take $t_{i}$ and $t_{i-1}$ to be the terms $\frac{2}{(2k+1)\pi}$ and $\frac{2}{(2k-1)\pi}$ for some $k < n$ ( for a moment ignoring the 0 and 1 of the partition) . Then \begin{align*}f(t_{i})-f(t_{i-1}) &=t_{i} \sin\left(\frac{(2k-1)\pi}{2}\right)-t_{i-1} \sin\left(\frac{(2k+1)\pi}{2}\right) \\ &=t_{i}\sin\left(k\pi-\frac{\pi}{2}\right)-t_{i-1}\sin\left(k\pi+\frac{\pi}{2}\right) \\ &=-t_{i}-t_{i-1} \quad  \text{or} \quad t_{i}+t_{i-1} \end{align*} Now define $b_{i}=\frac{2}{(2n-2i+1)\pi}$ for $i$ in $\{0,\dots,n\}$ and let $0 < A_{n}=\sqrt{(1-\frac{2}{\pi})^2+(\sin(1)-1)^2}+\sqrt{\left(\frac{2}{(2n+1)\pi}\right)^2+\left(\frac{2}{(2n+1)\pi}\right)^2}$ then we can write \begin{align*} \ell\left(x\sin\frac{1}{x},P^*\right) &=A+\sum_{i=1}^{n+1}\sqrt{(b_{i}-b_{i-1})+[f(b_{i})-f(b_{i-1})]^2} \\ & \geq \sum_{i=1}^{n+1} \sqrt{(b_{i}-b_{i-1})^2+(b_{i}+b_{i-1})^2} \\ &= \sum_{i=1}^{n+1} \sqrt{2(b^2_{i}+b^2_{i-1})} \\ & \geq \sum_{i=0}^{n} b_i\end{align*} (According to the result preceeding the calculation). Since $$\sum_{i=0}^{n} b_{i}=\sum_{i=0}^{n} \frac{2}{(2i+1)\pi} \geq \sum_{i=1}^{n} \frac{1}{12i}$$ With the last sum diverging by the harmonic series convergence test, we have that the set $\ell(f,P^*)$ is unbounded and thus $f$ has 'infinite length' $\blacksquare$ My question is if my proof is correct? And also if there is something i can do to make my proof look more coherent? (in the sense that it looks too be a bit all over the place.)","This is problem 16 chapter 23 of 'Calculus-Spivak (3rd edition)' Consider the following 'length' describing set Where is a partition of the interval being 'measured'. Let for and . Show that has an 'infinite length'on by showing the unboundness of by considering the partition My attempt : Without loss of generality we can take and to be the terms and for some ( for a moment ignoring the 0 and 1 of the partition) . Then Now define for in and let then we can write (According to the result preceeding the calculation). Since With the last sum diverging by the harmonic series convergence test, we have that the set is unbounded and thus has 'infinite length' My question is if my proof is correct? And also if there is something i can do to make my proof look more coherent? (in the sense that it looks too be a bit all over the place.)","\ell(f,P)=\sum_{i=1}^{n}\sqrt{(t_{i}-t_{i-1})^2+[f(t_i)-f(t_{i-1})]^2} P=\{t_{1}<\dots<t_{n}\} f(x)=x  \cdot \sin( \frac{1}{x}) 0 < x \leq 1  f(0)=0 f [0,1] \ell(f,P) P^*=\left\{ 0, \frac{2}{(2n+1)\pi},\dots,\frac{2}{5\pi},\frac{2}{3\pi},\frac{2}{\pi},1 \right\} t_{i} t_{i-1} \frac{2}{(2k+1)\pi} \frac{2}{(2k-1)\pi} k < n \begin{align*}f(t_{i})-f(t_{i-1}) &=t_{i} \sin\left(\frac{(2k-1)\pi}{2}\right)-t_{i-1} \sin\left(\frac{(2k+1)\pi}{2}\right) \\
&=t_{i}\sin\left(k\pi-\frac{\pi}{2}\right)-t_{i-1}\sin\left(k\pi+\frac{\pi}{2}\right) \\
&=-t_{i}-t_{i-1} \quad  \text{or} \quad t_{i}+t_{i-1} \end{align*} b_{i}=\frac{2}{(2n-2i+1)\pi} i \{0,\dots,n\} 0 < A_{n}=\sqrt{(1-\frac{2}{\pi})^2+(\sin(1)-1)^2}+\sqrt{\left(\frac{2}{(2n+1)\pi}\right)^2+\left(\frac{2}{(2n+1)\pi}\right)^2} \begin{align*} \ell\left(x\sin\frac{1}{x},P^*\right) &=A+\sum_{i=1}^{n+1}\sqrt{(b_{i}-b_{i-1})+[f(b_{i})-f(b_{i-1})]^2} \\
& \geq \sum_{i=1}^{n+1} \sqrt{(b_{i}-b_{i-1})^2+(b_{i}+b_{i-1})^2} \\
&= \sum_{i=1}^{n+1} \sqrt{2(b^2_{i}+b^2_{i-1})} \\
& \geq \sum_{i=0}^{n} b_i\end{align*} \sum_{i=0}^{n} b_{i}=\sum_{i=0}^{n} \frac{2}{(2i+1)\pi} \geq \sum_{i=1}^{n} \frac{1}{12i} \ell(f,P^*) f \blacksquare",['real-analysis']
21,Infinite divergent series - does the convergence of quotient imply convergence of difference?,Infinite divergent series - does the convergence of quotient imply convergence of difference?,,"I have two series with all terms positive, $$\sum_{i=1}^{n}a_i \equiv A_n >0,\;\; \sum_{i=1}^{n}b_i\equiv B_n>0.$$ Each series diverge as $n\to \infty$ . We also have $A_n \leq B_n, \forall n$ . Assume that $$\lim_{n\to \infty}\frac{A_n}{B_n} \to 1$$ Does this imply that $$\lim_{n\to \infty}\left(B_n-A_n\right) \to 0,\;\;\;???$$ I suspect not, because, clumsily, $$B_n-A_n = B_n\cdot \left (1-\frac{A_n}{B_n}\right)$$ so it appears we are examining the limit $$\lim_{n\to \infty}\left[B_n\cdot \left (1-\frac{A_n}{B_n}\right)\right]$$ and one of the terms goes to infinity while the other goes to zero, so some condition related to the speed of convergence against the speed of divergence appears to be needed. Am I right in this?","I have two series with all terms positive, Each series diverge as . We also have . Assume that Does this imply that I suspect not, because, clumsily, so it appears we are examining the limit and one of the terms goes to infinity while the other goes to zero, so some condition related to the speed of convergence against the speed of divergence appears to be needed. Am I right in this?","\sum_{i=1}^{n}a_i \equiv A_n >0,\;\; \sum_{i=1}^{n}b_i\equiv B_n>0. n\to \infty A_n \leq B_n, \forall n \lim_{n\to \infty}\frac{A_n}{B_n} \to 1 \lim_{n\to \infty}\left(B_n-A_n\right) \to 0,\;\;\;??? B_n-A_n = B_n\cdot \left (1-\frac{A_n}{B_n}\right) \lim_{n\to \infty}\left[B_n\cdot \left (1-\frac{A_n}{B_n}\right)\right]","['sequences-and-series', 'divergent-series']"
22,$a_n > 0$ and $\sum_\limits{n=1}^{+\infty} \frac{1}{a_n}$ converges. Prove $\sum_\limits{n=1}^{+\infty} \frac{n}{a_1 + \cdots + a_n}$ is convergent. [duplicate],and  converges. Prove  is convergent. [duplicate],a_n > 0 \sum_\limits{n=1}^{+\infty} \frac{1}{a_n} \sum_\limits{n=1}^{+\infty} \frac{n}{a_1 + \cdots + a_n},"This question already has answers here : If $\sum_{n=1}^\infty \frac{1}{a_n}$ converges, must $\sum_{n=1}^\infty \frac{n}{a_1 + \dots + a_n}$ converge? (3 answers) Closed 5 years ago . $a_n > 0$ and $\sum_\limits{n=1}^{+\infty} \frac{1}{a_n}$ converges. Prove $\sum_\limits{n=1}^{+\infty} \frac{n}{a_1 + \cdots + a_n}$ is convergent. I find that this may have something to do with Stolz Theorem which says that if $\{\frac{1}{a_n}\}$ is convergent then $$\lim_{n \rightarrow +\infty} \frac{n}{a_1+\cdots +a_n} = \lim_{n \rightarrow +\infty} \frac{1}{a_n}$$ This may implies that $\frac{n}{a_1+\cdots +a_n}$ and $\frac{1}{a_n}$ have the same declining speed so leads to the answer of the question. However, I don't know how to turn this into correct proof.","This question already has answers here : If $\sum_{n=1}^\infty \frac{1}{a_n}$ converges, must $\sum_{n=1}^\infty \frac{n}{a_1 + \dots + a_n}$ converge? (3 answers) Closed 5 years ago . and converges. Prove is convergent. I find that this may have something to do with Stolz Theorem which says that if is convergent then This may implies that and have the same declining speed so leads to the answer of the question. However, I don't know how to turn this into correct proof.",a_n > 0 \sum_\limits{n=1}^{+\infty} \frac{1}{a_n} \sum_\limits{n=1}^{+\infty} \frac{n}{a_1 + \cdots + a_n} \{\frac{1}{a_n}\} \lim_{n \rightarrow +\infty} \frac{n}{a_1+\cdots +a_n} = \lim_{n \rightarrow +\infty} \frac{1}{a_n} \frac{n}{a_1+\cdots +a_n} \frac{1}{a_n},['sequences-and-series']
23,If $(a_n)\to A\neq 0$ and $(a_n b_n)\to AB$ then $(b_n)\to B$,If  and  then,(a_n)\to A\neq 0 (a_n b_n)\to AB (b_n)\to B,"Let $(a_n)$ and $(b_n)$ be sequences. If $(a_n) \to A\neq 0$ and $(a_n b_n)\to AB$ then $(b_n)\to B$ I know that we need to show this for both $A > 0$ and $A < 0$ . But I am having problems using the assumptions to deduce that $$|b_n - B| < \epsilon$$ I know that since $<a_n>\to A$ then there exists an $N_1\in \mathbb{N}$ such that for all $n > N_1$ $$|a_n - A| < \epsilon$$ Similarly, since $<a_n b_n>\to AB$ then there exists an $N_2\in\mathbb{N}$ such that for all $n > N_2$ $$|a_n b_n - AB| < \epsilon$$ Any help would be appreciated. Background information: Theorem 8.7 - If the sequence $(a_n)$ converges to $A$ and the sequence $(b_n)$ converges to $B$ then the sequence $(a_n b _n)$ converges to $AB$ Lemma 8.1 - If $a_n\neq 0$ for all $n\in\mathbb{N}$ and if $(a_n)$ converges to $A\neq 0$ then the sequence $(1/a_n)$ converges to $1/A$ Attempted proof - Using these two theorems above we can write $(a_n b_n/a_n) = (b_n)$ which converges to $B$ . I don't think this is complete can someone help me add details?","Let and be sequences. If and then I know that we need to show this for both and . But I am having problems using the assumptions to deduce that I know that since then there exists an such that for all Similarly, since then there exists an such that for all Any help would be appreciated. Background information: Theorem 8.7 - If the sequence converges to and the sequence converges to then the sequence converges to Lemma 8.1 - If for all and if converges to then the sequence converges to Attempted proof - Using these two theorems above we can write which converges to . I don't think this is complete can someone help me add details?",(a_n) (b_n) (a_n) \to A\neq 0 (a_n b_n)\to AB (b_n)\to B A > 0 A < 0 |b_n - B| < \epsilon <a_n>\to A N_1\in \mathbb{N} n > N_1 |a_n - A| < \epsilon <a_n b_n>\to AB N_2\in\mathbb{N} n > N_2 |a_n b_n - AB| < \epsilon (a_n) A (b_n) B (a_n b _n) AB a_n\neq 0 n\in\mathbb{N} (a_n) A\neq 0 (1/a_n) 1/A (a_n b_n/a_n) = (b_n) B,"['real-analysis', 'sequences-and-series', 'proof-writing']"
24,Find general term of $1+\frac{2!}{3}+\frac{3!}{11}+\frac{4!}{43}+\frac{5!}{171}+....$ [closed],Find general term of  [closed],1+\frac{2!}{3}+\frac{3!}{11}+\frac{4!}{43}+\frac{5!}{171}+....,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Find general term of $1+\frac{2!}{3}+\frac{3!}{11}+\frac{4!}{43}+\frac{5!}{171}+....$ However it has been ask to check convergence but how can i do that before knowing the general term. I can't see any pattern,comment quickly!","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Find general term of However it has been ask to check convergence but how can i do that before knowing the general term. I can't see any pattern,comment quickly!",1+\frac{2!}{3}+\frac{3!}{11}+\frac{4!}{43}+\frac{5!}{171}+....,"['sequences-and-series', 'pattern-recognition']"
25,Lower Bound on the Sum of Reciprocal of LCM,Lower Bound on the Sum of Reciprocal of LCM,,"While reading online, I encountered this post which the author claims that \begin{align} S(N, 1):=\sum_{1\le i, j \le N} \frac{1}{\text{lcm}(i, j)} \geq 3H_N-2 \end{align} and $S(N, 1) \geq H_N^2$ where $H_N$ is the partial harmonic sum . The prove of the latter inequality is already given in the post. For the former, we see that \begin{align} S(N, 1)  =&\ 2\sum^N_{j=2}\sum^{j-1}_{i=1}\frac{1}{\text{lcm}(i, j)} +H_N\\ \geq&\ 2\sum^N_{j=2} \frac{1}{\text{lcm}(1, j)}+H_N=\ 3H_N -2. \end{align} My question is whether there exists $C$ , independent of $N$ , such that the following bound holds \begin{align} s(N):=\sum_{N \leq i, j \leq 2N} \frac{1}{\text{lcm}(i, j)} \geq C \log N. \end{align} Actually, I know for a fact that this is true by $(1.7)$ in this paper but couldn't prove it. Another question: How does one show \begin{align} \sum_{N^2/4< k< N^2/3} (\#\left\{N/3<q<N/2 \big|\   q\mid k\right\})^2\sim  \sum_{N/3<q, q'<N/2} \frac{N^2}{\text{lcm}(q,q')}. \end{align} I started by \begin{align} \sum_{N^2/4< k< N^2/3} (\#\left\{N/3<q<N/2 \big|\   q\mid k\right\})^2 =&\ \sum_{N^2/4< k< N^2/3}\left( \sum_{\substack{N/3<q<N/2\\ q\mid k}}1  \right)^2\\ =&\ \sum_{N^2/4< k< N^2/3} \sum_{\substack{N/3<q,\ q'<N/2\\ q\mid k,\ q'\mid k}} 1. \end{align} Here I know I should interchange the order of summation, but I don't know how to get the lcm to show up. Any help/suggestion is highly welcome.","While reading online, I encountered this post which the author claims that and where is the partial harmonic sum . The prove of the latter inequality is already given in the post. For the former, we see that My question is whether there exists , independent of , such that the following bound holds Actually, I know for a fact that this is true by in this paper but couldn't prove it. Another question: How does one show I started by Here I know I should interchange the order of summation, but I don't know how to get the lcm to show up. Any help/suggestion is highly welcome.","\begin{align}
S(N, 1):=\sum_{1\le i, j \le N} \frac{1}{\text{lcm}(i, j)} \geq 3H_N-2
\end{align} S(N, 1) \geq H_N^2 H_N \begin{align}
S(N, 1) 
=&\ 2\sum^N_{j=2}\sum^{j-1}_{i=1}\frac{1}{\text{lcm}(i, j)} +H_N\\
\geq&\ 2\sum^N_{j=2} \frac{1}{\text{lcm}(1, j)}+H_N=\ 3H_N -2.
\end{align} C N \begin{align}
s(N):=\sum_{N \leq i, j \leq 2N} \frac{1}{\text{lcm}(i, j)} \geq C \log N.
\end{align} (1.7) \begin{align}
\sum_{N^2/4< k< N^2/3} (\#\left\{N/3<q<N/2 \big|\   q\mid k\right\})^2\sim  \sum_{N/3<q, q'<N/2} \frac{N^2}{\text{lcm}(q,q')}.
\end{align} \begin{align}
\sum_{N^2/4< k< N^2/3} (\#\left\{N/3<q<N/2 \big|\   q\mid k\right\})^2 =&\ \sum_{N^2/4< k< N^2/3}\left( \sum_{\substack{N/3<q<N/2\\ q\mid k}}1  \right)^2\\
=&\ \sum_{N^2/4< k< N^2/3} \sum_{\substack{N/3<q,\ q'<N/2\\ q\mid k,\ q'\mid k}} 1.
\end{align}","['sequences-and-series', 'analytic-number-theory', 'least-common-multiple']"
26,Proving convergence/divergence of this series? [closed],Proving convergence/divergence of this series? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question $$\sum_{k=0}^{\infty}\frac{(k!)}{(k+1)!+2^k}$$ Anyone know how to show that this series converges or diverges? I've tried multiple tests and nothing seems to be working. Any help would be amazing!","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Anyone know how to show that this series converges or diverges? I've tried multiple tests and nothing seems to be working. Any help would be amazing!",\sum_{k=0}^{\infty}\frac{(k!)}{(k+1)!+2^k},"['sequences-and-series', 'convergence-divergence']"
27,Is there a sequence of natural numbers with these properties?,Is there a sequence of natural numbers with these properties?,,Is there a sequence of natural numbers (except 1) which every consecutive term is $\textbf{not}$ relatively prime and each natural number appears $\textbf{exactly once}$ ?,Is there a sequence of natural numbers (except 1) which every consecutive term is relatively prime and each natural number appears ?,\textbf{not} \textbf{exactly once},['sequences-and-series']
28,Convergence of $\sum\limits_{n=0}^{\infty} (1-|a_n|)$,Convergence of,\sum\limits_{n=0}^{\infty} (1-|a_n|),"So I must prove that if $(a_n)$ is a sequence of points in $\mathbb{C}$ with $0< |a_n| < 1 \; \forall n \in \mathbb{N}$ and verifying that $|b| \leq \prod\limits_{n=1}^{\infty} |a_n|$ with $0<|b| < 1$ , then the series $$\sum\limits_{n=0}^{\infty} \left(1-|a_n|\right)$$ converges. My closest attempt: Naming the partial sums as $S_n = \sum\limits_{k=1}^n \left(1-|a_n|\right)$ using the general Bernouilli inequality for $-\frac{|a_k|}{n}$ I get that $$\prod\limits_{k=1}^n \left(1-\frac{|a_n|}{n}\right) \geq 1 - \sum\limits_{k=1}^n \frac{|a_n|}{n} $$ Multiplying by $n$ in each side give us $$n \prod\limits_{k=1}^n \left(1-\frac{|a_n|}{n}\right) \geq n - \sum\limits_{k=1}^n |a_n| = \sum\limits_{k=1}^n (1-|a_n|)=S_n$$ Therefore we get that $S_n \leq n \prod\limits_{k=1}^n \left(1-\frac{|a_n|}{n}\right)$ Taking $\log$ both sides give us $$\log{S_n} \leq \log{(n)} + \sum\limits_{k=1}^n \log{\left(1-\frac{|a_n|}{n}\right)}$$ Now using that $\log{(1-x)} \leq -x$ we get $$\log{S_n} \leq \log(n) - \sum\limits_{k=1}^n \frac{|a_n|}{n}$$ And now I can't continue, the problem is I need to use $|b| \leq \prod\limits_{n=1}^{\infty} |a_n|$ somewhere but I couldn't manipulate the series to use that. Any hint on how can I show convergence?","So I must prove that if is a sequence of points in with and verifying that with , then the series converges. My closest attempt: Naming the partial sums as using the general Bernouilli inequality for I get that Multiplying by in each side give us Therefore we get that Taking both sides give us Now using that we get And now I can't continue, the problem is I need to use somewhere but I couldn't manipulate the series to use that. Any hint on how can I show convergence?",(a_n) \mathbb{C} 0< |a_n| < 1 \; \forall n \in \mathbb{N} |b| \leq \prod\limits_{n=1}^{\infty} |a_n| 0<|b| < 1 \sum\limits_{n=0}^{\infty} \left(1-|a_n|\right) S_n = \sum\limits_{k=1}^n \left(1-|a_n|\right) -\frac{|a_k|}{n} \prod\limits_{k=1}^n \left(1-\frac{|a_n|}{n}\right) \geq 1 - \sum\limits_{k=1}^n \frac{|a_n|}{n}  n n \prod\limits_{k=1}^n \left(1-\frac{|a_n|}{n}\right) \geq n - \sum\limits_{k=1}^n |a_n| = \sum\limits_{k=1}^n (1-|a_n|)=S_n S_n \leq n \prod\limits_{k=1}^n \left(1-\frac{|a_n|}{n}\right) \log \log{S_n} \leq \log{(n)} + \sum\limits_{k=1}^n \log{\left(1-\frac{|a_n|}{n}\right)} \log{(1-x)} \leq -x \log{S_n} \leq \log(n) - \sum\limits_{k=1}^n \frac{|a_n|}{n} |b| \leq \prod\limits_{n=1}^{\infty} |a_n|,"['real-analysis', 'sequences-and-series', 'complex-analysis', 'convergence-divergence', 'infinite-product']"
29,Asking about $\sum_{n=2}^{\infty}\frac{(-1)^n}{n}\left[\frac{4372}{(2n-1)^7(n-1)}+\frac{n^2+n+4372}{(2n+1)^7(n+1)}\right]$,Asking about,\sum_{n=2}^{\infty}\frac{(-1)^n}{n}\left[\frac{4372}{(2n-1)^7(n-1)}+\frac{n^2+n+4372}{(2n+1)^7(n+1)}\right],$$\sum_{n=2}^{\infty}\frac{(-1)^n}{n}\left[\frac{4372}{(2n-1)^7(n-1)}+\frac{n^2+n+4372}{(2n+1)^7(n+1)}\right]=\frac{61}{184320}\pi^7\tag1$$ Step 1: $$\sum_{n=2}^{\infty}\frac{(-1)^n}{n}\left[\frac{4372}{(2n-1)^7(n-1)}+\frac{4372}{(2n+1)^7(n+1)}\right]+\sum_{n=2}^{\infty}\frac{(-1)^n}{n}\left[\frac{n^2+n}{(2n+1)^7(n+1)}\right]\tag2$$ $$\sum_{n=2}^{\infty}\frac{(-1)^n}{n}\left[\frac{4372}{(2n-1)^7(n-1)}+\frac{4372}{(2n+1)^7(n+1)}\right]+\sum_{n=2}^{\infty}(-1)^n\left[\frac{1}{(2n+1)^7}\right]\tag3$$ Recall $$\sum_{n=0}^{\infty}(-1)^n\frac{1}{(2n+1)^7}=\frac{61}{184320}\pi^7$$ It looks like that this sum $$\sum_{n=2}^{\infty}\frac{(-1)^n}{n}\left[\frac{4372}{(2n-1)^7(n-1)}+\frac{4372}{(2n+1)^7(n+1)}\right]$$ is a rational number I am not able to show that sum $(1)=\frac{61}{184320}\pi^7$ Any help.Thank you!,Step 1: Recall It looks like that this sum is a rational number I am not able to show that sum Any help.Thank you!,\sum_{n=2}^{\infty}\frac{(-1)^n}{n}\left[\frac{4372}{(2n-1)^7(n-1)}+\frac{n^2+n+4372}{(2n+1)^7(n+1)}\right]=\frac{61}{184320}\pi^7\tag1 \sum_{n=2}^{\infty}\frac{(-1)^n}{n}\left[\frac{4372}{(2n-1)^7(n-1)}+\frac{4372}{(2n+1)^7(n+1)}\right]+\sum_{n=2}^{\infty}\frac{(-1)^n}{n}\left[\frac{n^2+n}{(2n+1)^7(n+1)}\right]\tag2 \sum_{n=2}^{\infty}\frac{(-1)^n}{n}\left[\frac{4372}{(2n-1)^7(n-1)}+\frac{4372}{(2n+1)^7(n+1)}\right]+\sum_{n=2}^{\infty}(-1)^n\left[\frac{1}{(2n+1)^7}\right]\tag3 \sum_{n=0}^{\infty}(-1)^n\frac{1}{(2n+1)^7}=\frac{61}{184320}\pi^7 \sum_{n=2}^{\infty}\frac{(-1)^n}{n}\left[\frac{4372}{(2n-1)^7(n-1)}+\frac{4372}{(2n+1)^7(n+1)}\right] (1)=\frac{61}{184320}\pi^7,['sequences-and-series']
30,All sequences are sets?,All sequences are sets?,,"I have learned that: A sequence is a function from a subset of natural numbers to some set A A function is a relation with certain properties A relation is a subset of a Cartesian product It seems, therefore, that I could represent any sequence as a set like $\left\{\left(n_1,a_1\right),\left(n_2,a_2\right),\dots\right\}$ , where the $n_i$ form the subset of natural numbers and $a_i$ are what we would normally refer to as the elements of the sequence. Is that correct? If so, it would help me think carefully about things like Cartesian products of sequences, functions from sequences to a set, etc., because I could think about things in terms of sets. The Wikipedia article on sequences compares and contrasts them with sets, and I couldn't find a source that viewed a sequence as a kind of set, so I'm wondering whether my interpretation is wrong or just uncommon (or neither). I have some exposure to real analysis and am learning game theory at the doctoral level.","I have learned that: A sequence is a function from a subset of natural numbers to some set A A function is a relation with certain properties A relation is a subset of a Cartesian product It seems, therefore, that I could represent any sequence as a set like , where the form the subset of natural numbers and are what we would normally refer to as the elements of the sequence. Is that correct? If so, it would help me think carefully about things like Cartesian products of sequences, functions from sequences to a set, etc., because I could think about things in terms of sets. The Wikipedia article on sequences compares and contrasts them with sets, and I couldn't find a source that viewed a sequence as a kind of set, so I'm wondering whether my interpretation is wrong or just uncommon (or neither). I have some exposure to real analysis and am learning game theory at the doctoral level.","\left\{\left(n_1,a_1\right),\left(n_2,a_2\right),\dots\right\} n_i a_i","['sequences-and-series', 'functions', 'elementary-set-theory', 'relations']"
31,Prove $a_n = \lfloor ni \rfloor$ for some irrational $i$ has no pattern,Prove  for some irrational  has no pattern,a_n = \lfloor ni \rfloor i,"I have a sequence $a_n = \lfloor ni \rfloor$ for an irrational $i$ and I want to prove that there is no 'pattern' to these terms. In particular, I have $1 < i <2$ and I want to prove that $\forall a,b \in \mathbb{N}, \exists k \in \mathbb{N}$ such that $a +bk \neq a_n$ for any $n$ . This makes sense to me intuitively because $a_n - a_{n-1}$ will be 1 or 2 'randomly', so the sequence must eventually 'skip over' one of the terms of $a+bk$ . My approach has been to assume that it holds, then show that $i$ must be rational for a contradiction. However, the floor is messing up the simple divisibility techniques I would use.","I have a sequence for an irrational and I want to prove that there is no 'pattern' to these terms. In particular, I have and I want to prove that such that for any . This makes sense to me intuitively because will be 1 or 2 'randomly', so the sequence must eventually 'skip over' one of the terms of . My approach has been to assume that it holds, then show that must be rational for a contradiction. However, the floor is messing up the simple divisibility techniques I would use.","a_n = \lfloor ni \rfloor i 1 < i <2 \forall a,b \in \mathbb{N}, \exists k \in \mathbb{N} a +bk \neq a_n n a_n - a_{n-1} a+bk i","['sequences-and-series', 'irrational-numbers']"
32,Test the convergence of series $\sum \frac{a^n}{a^n+x^n}$ when $x\neq0$,Test the convergence of series  when,\sum \frac{a^n}{a^n+x^n} x\neq0,"Let $ t_n=\frac{a^n}{a^n+x^n}$ and using root test $$ \displaystyle \lim_{n \to \infty} {t_n}^{\frac{1}{n}}=  \lim_{n \to \infty} \left(\frac{a^n}{a^n+x^n}\right)^{\frac{1}{n}}= \lim_{n \to \infty} \frac{1}{\big(1+(\frac{x}{a})^n\big)^{\frac{1}{n}}}$$ Now I am stuck, I don't know how to evaluate this limit","Let and using root test Now I am stuck, I don't know how to evaluate this limit", t_n=\frac{a^n}{a^n+x^n}  \displaystyle \lim_{n \to \infty} {t_n}^{\frac{1}{n}}=  \lim_{n \to \infty} \left(\frac{a^n}{a^n+x^n}\right)^{\frac{1}{n}}= \lim_{n \to \infty} \frac{1}{\big(1+(\frac{x}{a})^n\big)^{\frac{1}{n}}},"['real-analysis', 'calculus', 'sequences-and-series']"
33,Attempt at sequence proof $\frac{n+3}{n^2 -3}$ converges to $0$,Attempt at sequence proof  converges to,\frac{n+3}{n^2 -3} 0,"Prove convergence of the following sequence: $$\frac{n+3}{n^2 -3} \rightarrow 0$$ Proof discussion: Notice that since whenever $n>3$ ,  we have $n^2 -3 >0$ , we also know that $n+3 >0$ , so $\frac{n+3}{n^2 -3}>0$ . This means we can drop the absolute value signs in: $$  \left|\frac{n+3}{n^2 -3}-0\right|=\frac{n+3}{n^2 -3} $$ We now notice that for $n>3$ also $n^2 -9>0$ and $n^2 -3 > n^2 -9$ so $\frac{1}{n^2 -3}< \frac{1}{n^2 -9}$ we can thus write: $$\frac{n+3}{n^2 -3}<\frac{n+3}{n^2 -9}=\frac{(n+3)}{(n+3)(n-3)}=\frac{1}{n-3} $$ To be able to complete this proof we want that $\frac{1}{n-3}<\epsilon$ , we write $n-3>\frac{1}{\epsilon}$ or $n> \frac{1}{\epsilon} +3$ . If we pick $n_0 =\lceil\frac{1}{\epsilon} +3\rceil$ , it will also be automatically larger than $3$ . We can now write our proof: Proof: For all $\epsilon>0$ , we let $n_0=\lceil{\frac{1}{\epsilon}+3 }\rceil$ then for all $n>n_0$ , we know that: $$|a_n-0|=\left|\frac{n+3}{n^2-3} \right|<\frac{n+3}{n^2-9}=\frac{1}{n-3}< \frac{1}{\frac{1}{\epsilon}+3-3}=\epsilon$$ And hence our sequence converges to $0$ $\square$ . Is my proof okay?","Prove convergence of the following sequence: Proof discussion: Notice that since whenever ,  we have , we also know that , so . This means we can drop the absolute value signs in: We now notice that for also and so we can thus write: To be able to complete this proof we want that , we write or . If we pick , it will also be automatically larger than . We can now write our proof: Proof: For all , we let then for all , we know that: And hence our sequence converges to . Is my proof okay?",\frac{n+3}{n^2 -3} \rightarrow 0 n>3 n^2 -3 >0 n+3 >0 \frac{n+3}{n^2 -3}>0   \left|\frac{n+3}{n^2 -3}-0\right|=\frac{n+3}{n^2 -3}  n>3 n^2 -9>0 n^2 -3 > n^2 -9 \frac{1}{n^2 -3}< \frac{1}{n^2 -9} \frac{n+3}{n^2 -3}<\frac{n+3}{n^2 -9}=\frac{(n+3)}{(n+3)(n-3)}=\frac{1}{n-3}  \frac{1}{n-3}<\epsilon n-3>\frac{1}{\epsilon} n> \frac{1}{\epsilon} +3 n_0 =\lceil\frac{1}{\epsilon} +3\rceil 3 \epsilon>0 n_0=\lceil{\frac{1}{\epsilon}+3 }\rceil n>n_0 |a_n-0|=\left|\frac{n+3}{n^2-3} \right|<\frac{n+3}{n^2-9}=\frac{1}{n-3}< \frac{1}{\frac{1}{\epsilon}+3-3}=\epsilon 0 \square,"['real-analysis', 'sequences-and-series']"
34,Convergence of the series $\sum a_n$ when $\sqrt[n]{a_n}\leq 1-\frac{1}{n^\alpha}$ for $0<\alpha<1$.,Convergence of the series  when  for .,\sum a_n \sqrt[n]{a_n}\leq 1-\frac{1}{n^\alpha} 0<\alpha<1,"Examine the convergence of the series $\sum a_n$ , where: $$\sqrt[n]{a_n}\leq 1-\frac{1}{n^\alpha}$$ for all $n$ ( $0<\alpha<1$ ). Attempt. Since $$\limsup \sqrt[n]{a_n}\leq \limsup\left(1-\frac{1}{n^\alpha}\right)=1$$ we can not use the root test. Comparison test also doesn't work, since $\sum(1-n^{-\alpha})$ diverges to $+\infty$ . Thanks in advance.","Examine the convergence of the series , where: for all ( ). Attempt. Since we can not use the root test. Comparison test also doesn't work, since diverges to . Thanks in advance.",\sum a_n \sqrt[n]{a_n}\leq 1-\frac{1}{n^\alpha} n 0<\alpha<1 \limsup \sqrt[n]{a_n}\leq \limsup\left(1-\frac{1}{n^\alpha}\right)=1 \sum(1-n^{-\alpha}) +\infty,"['calculus', 'real-analysis', 'sequences-and-series']"
35,Extension of Borel-Cantelli in Probability Theory,Extension of Borel-Cantelli in Probability Theory,,"I am working on a problem regarding an extension of the Borel-Cantelli lemma that goes as follows: Let $E_1, E_2, ...$ be an arbitrary sequence of sets. It is known that $\lim_{n \to \infty}P(E_n) = 0$ and $\sum_n P(E_n \cap E_{n+1}^c) < \infty$ . Show that $P(E_n \text{ infinitely often})=0$ I have tried a few different attempts at the answer, with the most current one given below: \begin{align*}       &P(\limsup_n E_n)&&\\       &= P(\cap_{n=1}^\infty \cup_{k=n}^\infty E_n)&&\\       &= \lim_{n \nearrow \infty} P(\cup_{k=n}^\infty E_n)&&\text{intersection is monotone decreasing}\\       &= \lim_{n \nearrow \infty} P\bigg(\cup_{k=n}^\infty \big[[E_n \cap E_{n+1}^c] \cup [E_n \cap E_{n+1}]\big]\bigg)&&\\       &= \lim_{n \nearrow \infty} P\bigg(\big(\cup_{k=n}^\infty [E_n \cap E_{n+1}^c]\big) \cup \big(\cup_{k=n}^\infty [E_n \cap E_{n+1}]\big)\bigg)&&\\       &= \lim_{n \nearrow \infty} P\bigg(\big(\cup_{k=n}^\infty [E_n \cap E_{n+1}^c]\big) \cup \big(\cup_{k=n}^\infty E_n \cap \cup_{k=n}^\infty E_{n+1}]\big)\bigg)&&\\       &= \lim_{n \nearrow \infty} P\bigg(\big(\cup_{k=n}^\infty [E_n \cap E_{n+1}^c]\big) \cup [\cup_{k=n}^\infty E_{n+1}]\bigg)&&\\       &= \lim_{n \nearrow \infty} \bigg[P\big(\cup_{k=n}^\infty [E_n \cap E_{n+1}^c]\big)+ P\big(\cup_{k=n}^\infty E_{n+1}\big)\bigg]&&\text{disjoint additivity}\\       &= \lim_{n \nearrow \infty} P\big(\cup_{k=n}^\infty [E_n \cap E_{n+1}^c]\big)+ \lim_{n \nearrow \infty} P\big(\cup_{k=n}^\infty E_{n+1}\big)&&\\       &\leq \lim_{n \nearrow \infty} \sum_{k=n}^\infty P\big(E_n \cap E_{n+1}^c\big)+ \lim_{n \nearrow \infty} P\big(\cup_{k=n}^\infty E_{n+1}\big)&&\text{subadditivity}\\     \end{align*} The main problem with this answer, as well as the other ones I have drafted, is that I can't seem to get rid of the union over $E_n$ . Because of this I can't make any statements about the limiting probability of the union going to $0$ (e.g. if $P(E_n) = 1/n$ the conditions of the problem are fulfilled but the probability of the union does not converge). Am I missing something in the way I am breaking up the sets? I have been banging my head against this for days with no success - any resources you all could suggest/ direction that you could give would be highly appreciated.","I am working on a problem regarding an extension of the Borel-Cantelli lemma that goes as follows: Let be an arbitrary sequence of sets. It is known that and . Show that I have tried a few different attempts at the answer, with the most current one given below: The main problem with this answer, as well as the other ones I have drafted, is that I can't seem to get rid of the union over . Because of this I can't make any statements about the limiting probability of the union going to (e.g. if the conditions of the problem are fulfilled but the probability of the union does not converge). Am I missing something in the way I am breaking up the sets? I have been banging my head against this for days with no success - any resources you all could suggest/ direction that you could give would be highly appreciated.","E_1, E_2, ... \lim_{n \to \infty}P(E_n) = 0 \sum_n P(E_n \cap E_{n+1}^c) < \infty P(E_n \text{ infinitely often})=0 \begin{align*}
      &P(\limsup_n E_n)&&\\
      &= P(\cap_{n=1}^\infty \cup_{k=n}^\infty E_n)&&\\
      &= \lim_{n \nearrow \infty} P(\cup_{k=n}^\infty E_n)&&\text{intersection is monotone decreasing}\\
      &= \lim_{n \nearrow \infty} P\bigg(\cup_{k=n}^\infty \big[[E_n \cap E_{n+1}^c] \cup [E_n \cap E_{n+1}]\big]\bigg)&&\\
      &= \lim_{n \nearrow \infty} P\bigg(\big(\cup_{k=n}^\infty [E_n \cap E_{n+1}^c]\big) \cup \big(\cup_{k=n}^\infty [E_n \cap E_{n+1}]\big)\bigg)&&\\
      &= \lim_{n \nearrow \infty} P\bigg(\big(\cup_{k=n}^\infty [E_n \cap E_{n+1}^c]\big) \cup \big(\cup_{k=n}^\infty E_n \cap \cup_{k=n}^\infty E_{n+1}]\big)\bigg)&&\\
      &= \lim_{n \nearrow \infty} P\bigg(\big(\cup_{k=n}^\infty [E_n \cap E_{n+1}^c]\big) \cup [\cup_{k=n}^\infty E_{n+1}]\bigg)&&\\
      &= \lim_{n \nearrow \infty} \bigg[P\big(\cup_{k=n}^\infty [E_n \cap E_{n+1}^c]\big)+ P\big(\cup_{k=n}^\infty E_{n+1}\big)\bigg]&&\text{disjoint additivity}\\
      &= \lim_{n \nearrow \infty} P\big(\cup_{k=n}^\infty [E_n \cap E_{n+1}^c]\big)+ \lim_{n \nearrow \infty} P\big(\cup_{k=n}^\infty E_{n+1}\big)&&\\
      &\leq \lim_{n \nearrow \infty} \sum_{k=n}^\infty P\big(E_n \cap E_{n+1}^c\big)+ \lim_{n \nearrow \infty} P\big(\cup_{k=n}^\infty E_{n+1}\big)&&\text{subadditivity}\\
    \end{align*} E_n 0 P(E_n) = 1/n","['real-analysis', 'sequences-and-series', 'probability-theory', 'measure-theory', 'borel-cantelli-lemmas']"
36,"If $\sum\limits_na_n$ converges, $f$ is a bijection and $|f(n)-n|<X$ for every $n$, for some fixed $X$, then $\sum\limits_na_{f(n)}$ converges","If  converges,  is a bijection and  for every , for some fixed , then  converges",\sum\limits_na_n f |f(n)-n|<X n X \sum\limits_na_{f(n)},Let $f(n)$ be a bijection from $\Bbb N$ to $\Bbb N$ such that $$|f(n)-n|\lt X$$ for some fixed natural $X$ and $\forall  n \in \Bbb N$. If $$\sum_{n=1}^\infty a_n$$ is convergent then prove that $$\sum_{n=1}^\infty a_{f(n)}$$ is also convergent. I don't know how to proceed with this problem. I am not able to see any direct way to use the cauchy criterion or any other method to prove that the given series is convergent using the fact that $$\sum_{n=1}^\infty a_{n}$$ is convergent and the condition on $f(n)$. Any hints will be helpful.,Let $f(n)$ be a bijection from $\Bbb N$ to $\Bbb N$ such that $$|f(n)-n|\lt X$$ for some fixed natural $X$ and $\forall  n \in \Bbb N$. If $$\sum_{n=1}^\infty a_n$$ is convergent then prove that $$\sum_{n=1}^\infty a_{f(n)}$$ is also convergent. I don't know how to proceed with this problem. I am not able to see any direct way to use the cauchy criterion or any other method to prove that the given series is convergent using the fact that $$\sum_{n=1}^\infty a_{n}$$ is convergent and the condition on $f(n)$. Any hints will be helpful.,,"['sequences-and-series', 'convergence-divergence']"
37,Does this matrix sequence always converge?,Does this matrix sequence always converge?,,"Suppose $a_0, a_1, ... , a_{n-1}$ are real numbers from $(0; 1)$, such that $\sum_{k=0}^{n-1} a_k=1$. Suppose $A = (c_{ij})$ is a $n \times n$ matrix with entries $c_{ij} = a_{(i-j)\%n}$, where $\%$ is modulo operation. Is it always true that $\lim_{m \to \infty} A^m = \frac{1}{n} \begin{pmatrix} 1 & 1 & \cdots & 1 \\1 & 1 & \cdots & 1 \\ \vdots & \vdots & \ddots & \vdots \\ 1 & 1 & \cdots & 1 \end{pmatrix}$? This statement is true for $n = 2$:  Suppose $A = \begin{pmatrix} a_0 & {1 - a_0} \\ {1 - a_0} & a_0 \end{pmatrix} = \begin{pmatrix} 1 & -1 \\ 1 & 1\end{pmatrix}^{-1}\begin{pmatrix} 1 & 0 \\ 0 & {1-2a_0} \end{pmatrix}\begin{pmatrix} 1 & -1 \\ 1 & 1 \end{pmatrix}$. Because $a_0$ is in $(0; 1)$, $1-2a_0$ is in $(-1;1)$. Thus $$\lim_{m \to \infty} A^m = \begin{pmatrix} 1 & -1 \\ 1 & 1\end{pmatrix}^{-1}\begin{pmatrix} 1 & 0 \\ 0 & 0\end{pmatrix}\begin{pmatrix} 1 & -1 \\ 1 & 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix}$$ However, I do not know how to prove this statement for arbitrary $n$. Any help will be appreciated.","Suppose $a_0, a_1, ... , a_{n-1}$ are real numbers from $(0; 1)$, such that $\sum_{k=0}^{n-1} a_k=1$. Suppose $A = (c_{ij})$ is a $n \times n$ matrix with entries $c_{ij} = a_{(i-j)\%n}$, where $\%$ is modulo operation. Is it always true that $\lim_{m \to \infty} A^m = \frac{1}{n} \begin{pmatrix} 1 & 1 & \cdots & 1 \\1 & 1 & \cdots & 1 \\ \vdots & \vdots & \ddots & \vdots \\ 1 & 1 & \cdots & 1 \end{pmatrix}$? This statement is true for $n = 2$:  Suppose $A = \begin{pmatrix} a_0 & {1 - a_0} \\ {1 - a_0} & a_0 \end{pmatrix} = \begin{pmatrix} 1 & -1 \\ 1 & 1\end{pmatrix}^{-1}\begin{pmatrix} 1 & 0 \\ 0 & {1-2a_0} \end{pmatrix}\begin{pmatrix} 1 & -1 \\ 1 & 1 \end{pmatrix}$. Because $a_0$ is in $(0; 1)$, $1-2a_0$ is in $(-1;1)$. Thus $$\lim_{m \to \infty} A^m = \begin{pmatrix} 1 & -1 \\ 1 & 1\end{pmatrix}^{-1}\begin{pmatrix} 1 & 0 \\ 0 & 0\end{pmatrix}\begin{pmatrix} 1 & -1 \\ 1 & 1 \end{pmatrix} = \frac{1}{2}\begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix}$$ However, I do not know how to prove this statement for arbitrary $n$. Any help will be appreciated.",,"['linear-algebra', 'sequences-and-series', 'matrices', 'limits', 'matrix-calculus']"
38,Generating function for the number of unlabeled trees on $n$ vertices,Generating function for the number of unlabeled trees on  vertices,n,"According to OEIS sequence A000055 , if $(T_n)$ denotes the sequence of number of  trees with $n$ unlabeled vertices, then it has the generating function $$G(x)=1+A(x)-A^2(x)/2+A(x^2)/2=\sum_{n=0}^{\infty}T_n x^n,$$ where $A(x)=x + x^2 + 2x^3 + 4x^4 + 9x^5 + 20x^6+\cdots$ is the generating function for OEIS sequence A000081 . I tried to derive this generating function by myself, but do not have any clue. Can any body give my a detailed explanation on this formula? Thank you in advance.","According to OEIS sequence A000055 , if $(T_n)$ denotes the sequence of number of  trees with $n$ unlabeled vertices, then it has the generating function $$G(x)=1+A(x)-A^2(x)/2+A(x^2)/2=\sum_{n=0}^{\infty}T_n x^n,$$ where $A(x)=x + x^2 + 2x^3 + 4x^4 + 9x^5 + 20x^6+\cdots$ is the generating function for OEIS sequence A000081 . I tried to derive this generating function by myself, but do not have any clue. Can any body give my a detailed explanation on this formula? Thank you in advance.",,"['sequences-and-series', 'combinatorics', 'graph-theory', 'generating-functions', 'trees']"
39,Show that $\int_0^n\sin x^2dx$ converges,Show that  converges,\int_0^n\sin x^2dx,"The question Okay. So I'm trying to solve the problem below for a previous exam in real analysis. Thus, only such methods may be used. The integral $\int_0^\infty\sin x^2dx$ is called a Fresnel integral and it arises in wave optics. Show that this integral converges, by proving that the sequence $a_n:=\int_0^n\sin x^2dx$ converges in $\mathbb{R}$. The question also comes with the below hint. Hint: Use the fact that   $$ 	\sin x^2=-\frac{1}{2x}\frac{d}{dx}\cos x^2. $$ It makes me think of using integration by parts, and that has been the hint in similar questions. However, when I do that things don't get easier. Consequently, I'm kind of stuck. Here are my computations $$ 	\int_0^n\sin x^2dx=-\int_0^n\frac{1}{2x}\frac{d}{dx}\cos x^2dx=[-\frac{1}{2x}\cos x^2]_0^n-\int_0^n\frac{1}{2x^2}\cos x^2dx. $$ Related questions There is a thread about evaluating the Fresnel integral called "" Evaluating $\int_0^\infty \sin x^2\, dx$ with real methods? "" and another one called "" Trig Fresnel Integral "", but none of the answers to these questions involve showing convergence as instructed in this question, and both involve the Gamma function, which wasn't included in my course on real analysis.","The question Okay. So I'm trying to solve the problem below for a previous exam in real analysis. Thus, only such methods may be used. The integral $\int_0^\infty\sin x^2dx$ is called a Fresnel integral and it arises in wave optics. Show that this integral converges, by proving that the sequence $a_n:=\int_0^n\sin x^2dx$ converges in $\mathbb{R}$. The question also comes with the below hint. Hint: Use the fact that   $$ 	\sin x^2=-\frac{1}{2x}\frac{d}{dx}\cos x^2. $$ It makes me think of using integration by parts, and that has been the hint in similar questions. However, when I do that things don't get easier. Consequently, I'm kind of stuck. Here are my computations $$ 	\int_0^n\sin x^2dx=-\int_0^n\frac{1}{2x}\frac{d}{dx}\cos x^2dx=[-\frac{1}{2x}\cos x^2]_0^n-\int_0^n\frac{1}{2x^2}\cos x^2dx. $$ Related questions There is a thread about evaluating the Fresnel integral called "" Evaluating $\int_0^\infty \sin x^2\, dx$ with real methods? "" and another one called "" Trig Fresnel Integral "", but none of the answers to these questions involve showing convergence as instructed in this question, and both involve the Gamma function, which wasn't included in my course on real analysis.",,"['real-analysis', 'sequences-and-series', 'fresnel-integrals']"
40,Sequence of arithmetic means of a square summable sequence is square summable,Sequence of arithmetic means of a square summable sequence is square summable,,"Is it true that if $x \in \ell^2$ then $\left(\frac{1}{n} \sum_{i=1}^n x_i\right)_{n} \in \ell^2$ ? I conjecture that this is false and the sequence $x_n = \frac{1}{\sqrt{n}\ln(n)}$ is a counterexample, but I cannot prove it.","Is it true that if $x \in \ell^2$ then $\left(\frac{1}{n} \sum_{i=1}^n x_i\right)_{n} \in \ell^2$ ? I conjecture that this is false and the sequence $x_n = \frac{1}{\sqrt{n}\ln(n)}$ is a counterexample, but I cannot prove it.",,['sequences-and-series']
41,last 2 digits of a sequence,last 2 digits of a sequence,,"$x+\frac{1}{x} = 3$, what are the last 2 digits of  $x^{2^{2013}}+\frac{1}{x^{2^{2013}}}$? Getting the next value, we have to square then subtract by 2, I am clueless in getting to the next step","$x+\frac{1}{x} = 3$, what are the last 2 digits of  $x^{2^{2013}}+\frac{1}{x^{2^{2013}}}$? Getting the next value, we have to square then subtract by 2, I am clueless in getting to the next step",,['sequences-and-series']
42,Simplifying a Geometric Series with Two Power Terms,Simplifying a Geometric Series with Two Power Terms,,"I have derived a geometric series below that I want to simplify but keep making a mess. Can anyone help?   $$s = aq^{n-1}r^{0} + aq^{n-2}r^{1} + \dotsb + aq^{1}r^{n-2} + aq^{0}r^{n-1}$$ I get the following, but I know it's wrong $$s = \frac{aq^{n-1} - (ar^{n})/q}{1 - (r/q)}$$","I have derived a geometric series below that I want to simplify but keep making a mess. Can anyone help?   $$s = aq^{n-1}r^{0} + aq^{n-2}r^{1} + \dotsb + aq^{1}r^{n-2} + aq^{0}r^{n-1}$$ I get the following, but I know it's wrong $$s = \frac{aq^{n-1} - (ar^{n})/q}{1 - (r/q)}$$",,"['sequences-and-series', 'geometric-series']"
43,Limit with terms of convergent series problem,Limit with terms of convergent series problem,,"Prove that if a positive series $\sum_{\nu =1}^\infty a_\nu$ is convergent and the sequence $(\nu a_\nu)_{\nu =1}^\infty$ is decreasing, then $\lim_{\nu\to\infty}(\nu\log\nu)a_\nu=0$. I've been trying to prove this for days, but so far I've only managed to prove that if the limit exists, it is equal to 0. Could someone give me a hint?","Prove that if a positive series $\sum_{\nu =1}^\infty a_\nu$ is convergent and the sequence $(\nu a_\nu)_{\nu =1}^\infty$ is decreasing, then $\lim_{\nu\to\infty}(\nu\log\nu)a_\nu=0$. I've been trying to prove this for days, but so far I've only managed to prove that if the limit exists, it is equal to 0. Could someone give me a hint?",,"['real-analysis', 'sequences-and-series']"
44,Sum of infinite series $ {1+ \frac{2}{6} + \frac{2\cdot5}{6\cdot12} + \frac{2\cdot5\cdot8}{6\cdot12\cdot18} + \cdots}$.,Sum of infinite series ., {1+ \frac{2}{6} + \frac{2\cdot5}{6\cdot12} + \frac{2\cdot5\cdot8}{6\cdot12\cdot18} + \cdots},"Prove that $1+ \frac{2}{6} + \frac{2\cdot5}{6\cdot12} + \frac{2\cdot5\cdot8}{6\cdot12\cdot18} +\cdots=4^{\frac13}$ I tried it in the backward method... I rewrote $4^{\frac13}$ in this way...  $(1+3)^{\frac13}$ and expanded it in the binomial expansion method, but it doesn't help in any way.","Prove that $1+ \frac{2}{6} + \frac{2\cdot5}{6\cdot12} + \frac{2\cdot5\cdot8}{6\cdot12\cdot18} +\cdots=4^{\frac13}$ I tried it in the backward method... I rewrote $4^{\frac13}$ in this way...  $(1+3)^{\frac13}$ and expanded it in the binomial expansion method, but it doesn't help in any way.",,['sequences-and-series']
45,Convergence of a series to an integral,Convergence of a series to an integral,,"Suppose we have a real function $f$ bounded continuous on $[0,1]$. We know that $$ \frac 1 n \sum_{i=1}^n f(x_i) \to \int_0^1 f(x) \,dx$$ for $x_i \in [(i-1)/n, i/n]$, as $n\to \infty$. Now suppose we have a sequence $f_n$ of bounded continuous functions on $[0,1]$ converging pointwise to $f$. Is it true that $$ \frac 1 n \sum_{i=1}^n f_n(x_i) \to \int_0^1 f(x) \,dx$$","Suppose we have a real function $f$ bounded continuous on $[0,1]$. We know that $$ \frac 1 n \sum_{i=1}^n f(x_i) \to \int_0^1 f(x) \,dx$$ for $x_i \in [(i-1)/n, i/n]$, as $n\to \infty$. Now suppose we have a sequence $f_n$ of bounded continuous functions on $[0,1]$ converging pointwise to $f$. Is it true that $$ \frac 1 n \sum_{i=1}^n f_n(x_i) \to \int_0^1 f(x) \,dx$$",,"['real-analysis', 'sequences-and-series', 'functional-analysis', 'analysis', 'convergence-divergence']"
46,Find all real values of $a$ such that $\sum_{n=0}^{\infty} \sin(\pi\sqrt{a^2+n^2})$ diverges,Find all real values of  such that  diverges,a \sum_{n=0}^{\infty} \sin(\pi\sqrt{a^2+n^2}),"To find all $a$ that makes the series diverge, it is sufficient to make the limit of $\sin(\pi\sqrt{a^2+n^2})$ not exist or exists but not  equal to $0$ as $n\to\infty.$ I suspect only $a=0$ would converge the series, and the limit of $\sin(\pi\sqrt{a^2+n^2})$ would not even exist if $a\neq 0.$ .","To find all $a$ that makes the series diverge, it is sufficient to make the limit of $\sin(\pi\sqrt{a^2+n^2})$ not exist or exists but not  equal to $0$ as $n\to\infty.$ I suspect only $a=0$ would converge the series, and the limit of $\sin(\pi\sqrt{a^2+n^2})$ would not even exist if $a\neq 0.$ .",,"['real-analysis', 'sequences-and-series']"
47,Iterations of the radical of an integer,Iterations of the radical of an integer,,"We denote for an integer $n>1$ its square-free kernel as $$\operatorname{rad}(n)=\prod_{\substack{p\mid n\\p\text{ prime}}}p,\tag{0}$$ with the definition $\operatorname{rad}(1)=1$. You can see this definition and the properties of this arithmetic function from the Wikipedia Radical of an integer . Then I wondered about a variant of two problems showed in last paragraphs of section B 41 of Guy's book [1]. Definition. For each fixed integer $n\geq 1$, I consider the arithmetic function $$f(n)=f^1(n):=\operatorname{rad}(n)+1,\tag{1}$$ and we create the iterated $$f^{k+1}=f(f^{k}(n))\tag{2}$$ until $f^{T}(n)$ reaches a prime number, here thus $T=T(n)$ is a function depending on $n$ (that is the number of steps in our iteration that we need to wait until the sequence of iterated $f^{k}(n)$ reaches a prime number  for the first time). We can call stopping time to the arithmetic function $T(n)$ (defined thus for integers $n\geq 1$ and taking positive values). Example 1. Let $n=1$, then in a step the sequence of iterations reaches a prime number since $f(1)=f^1(1)=\operatorname{rad}(1)+1=1+1=2$ is a prime number. The same argument works with the composite number $n=8$, because $f(8)=f^1(8)=\operatorname{rad}(8)+1=2+1=3$ a prime number. Thus in our table $T(1)=1$ iteration, and also in this example we've seen that the corresponding  sequence defined for the integer $8$ has stopping time $T(8)=1$. Example 2. We work about the calculation of $T(33)$. We iterate while the result is a composite integer. Here $\operatorname{rad}(33)=33$, thus $f(33)=34$ and since $34=2\cdot 17$ is also square-free then $f^2(33)=f(f(33))=34+1=35$. Again our last iterated, that is $35=5\cdot 7$ has no repeated prime factors, thus we write $f^3(33)=f(35)=36$. Finally $f^4(33)=\operatorname{rad}(36)+1=6+1=7$ that results a prime number. Thus we conclude that $T(33)=4$. Computational fact. I did few experiments/calculations and seems that the arithmetic function $T(n)$ is erratic, thus it makes sense to study averages of consecutive values of this stopping time. Question. I would like to know if it is possible to deduce a tighter upper bound for $$\frac{1}{N}\sum_{1\leq n\leq N}T(n)\tag{3}$$   as $N$ grows (if you are able to provide an elaborated statement about the asymptotic behaviour of $(3)$ as $N\to\infty$ feel free to do it). Many thanks. Final remarks. My motivation was to propose a similar variant of the mentioned problems in Guy's book, now for other interesting arithmetic function $\operatorname{rad}(n)$. I've no idea about a strategy to attack the problem to get idea about the size of the average means of the $T(n)$. References: [1]  Richard K. Guy, Unsolved Problems in Number Theory , Volume I, Second Edition, Springer (1994).","We denote for an integer $n>1$ its square-free kernel as $$\operatorname{rad}(n)=\prod_{\substack{p\mid n\\p\text{ prime}}}p,\tag{0}$$ with the definition $\operatorname{rad}(1)=1$. You can see this definition and the properties of this arithmetic function from the Wikipedia Radical of an integer . Then I wondered about a variant of two problems showed in last paragraphs of section B 41 of Guy's book [1]. Definition. For each fixed integer $n\geq 1$, I consider the arithmetic function $$f(n)=f^1(n):=\operatorname{rad}(n)+1,\tag{1}$$ and we create the iterated $$f^{k+1}=f(f^{k}(n))\tag{2}$$ until $f^{T}(n)$ reaches a prime number, here thus $T=T(n)$ is a function depending on $n$ (that is the number of steps in our iteration that we need to wait until the sequence of iterated $f^{k}(n)$ reaches a prime number  for the first time). We can call stopping time to the arithmetic function $T(n)$ (defined thus for integers $n\geq 1$ and taking positive values). Example 1. Let $n=1$, then in a step the sequence of iterations reaches a prime number since $f(1)=f^1(1)=\operatorname{rad}(1)+1=1+1=2$ is a prime number. The same argument works with the composite number $n=8$, because $f(8)=f^1(8)=\operatorname{rad}(8)+1=2+1=3$ a prime number. Thus in our table $T(1)=1$ iteration, and also in this example we've seen that the corresponding  sequence defined for the integer $8$ has stopping time $T(8)=1$. Example 2. We work about the calculation of $T(33)$. We iterate while the result is a composite integer. Here $\operatorname{rad}(33)=33$, thus $f(33)=34$ and since $34=2\cdot 17$ is also square-free then $f^2(33)=f(f(33))=34+1=35$. Again our last iterated, that is $35=5\cdot 7$ has no repeated prime factors, thus we write $f^3(33)=f(35)=36$. Finally $f^4(33)=\operatorname{rad}(36)+1=6+1=7$ that results a prime number. Thus we conclude that $T(33)=4$. Computational fact. I did few experiments/calculations and seems that the arithmetic function $T(n)$ is erratic, thus it makes sense to study averages of consecutive values of this stopping time. Question. I would like to know if it is possible to deduce a tighter upper bound for $$\frac{1}{N}\sum_{1\leq n\leq N}T(n)\tag{3}$$   as $N$ grows (if you are able to provide an elaborated statement about the asymptotic behaviour of $(3)$ as $N\to\infty$ feel free to do it). Many thanks. Final remarks. My motivation was to propose a similar variant of the mentioned problems in Guy's book, now for other interesting arithmetic function $\operatorname{rad}(n)$. I've no idea about a strategy to attack the problem to get idea about the size of the average means of the $T(n)$. References: [1]  Richard K. Guy, Unsolved Problems in Number Theory , Volume I, Second Edition, Springer (1994).",,"['sequences-and-series', 'prime-numbers']"
48,Summation of $\sum_{r=1}^{n} \frac{\cos (2rx)}{\sin((2r+1)x \sin((2r-1)x}$,Summation of,\sum_{r=1}^{n} \frac{\cos (2rx)}{\sin((2r+1)x \sin((2r-1)x},Summation of $$S=\sum_{r=1}^{n} \frac{\cos (2rx)}{\sin((2r+1)x) \sin((2r-1)x)}$$ My Try: $$S=\sum_{r=1}^{n} \frac{\cos (2rx) \sin((2r+1)x-(2r-1)x)}{\sin 2x \:\sin((2r+1)x \sin((2r-1)x}$$ $$S=\sum_{r=1}^{n} \frac{\cos (2rx) \left(\sin((2r+1)x \cos (2r-1)x-\cos(2r-1)x)\sin(2r+1)x\right)}{\sin 2x \:\sin((2r+1)x \sin((2r-1)x)}$$ $$S=\sum_{r=1}^n \frac{\cos(2rx)}{\sin 2x}\left(\cot(2r-1)x-\cot(2r+1)x\right)$$ Any clue here?,Summation of My Try: Any clue here?,S=\sum_{r=1}^{n} \frac{\cos (2rx)}{\sin((2r+1)x) \sin((2r-1)x)} S=\sum_{r=1}^{n} \frac{\cos (2rx) \sin((2r+1)x-(2r-1)x)}{\sin 2x \:\sin((2r+1)x \sin((2r-1)x} S=\sum_{r=1}^{n} \frac{\cos (2rx) \left(\sin((2r+1)x \cos (2r-1)x-\cos(2r-1)x)\sin(2r+1)x\right)}{\sin 2x \:\sin((2r+1)x \sin((2r-1)x)} S=\sum_{r=1}^n \frac{\cos(2rx)}{\sin 2x}\left(\cot(2r-1)x-\cot(2r+1)x\right),"['sequences-and-series', 'trigonometry', 'summation', 'telescopic-series']"
49,Events in Tail $\sigma$-algebra,Events in Tail -algebra,\sigma,"Let $X_1,X_2,...$ be real valued random variables. Put $\mathfrak S_n=\sigma (X_n)$ and $S_n=X_1+X_2+...+X_n$ . Let $\mathfrak T_n=\sigma (X_{n+1},X_{n+2},...)$ and define the tail $\sigma$ -algebra $\mathfrak T=\cap _n \mathfrak T_n$ . The book I am reading now says : $\{\limsup S_n>b\}\notin \mathfrak T$ But I don't get why this holds. Intuitively, this event seems to be unaffected by first finite happenings... Could you give me an example or explanation? Thank you in advance. Edit: For example, let $X_n =^{dist} U_{(-1,1)}$ for all $n$ , assuming that they are not independent and let $b=0$ . Is is still true that $\{\limsup S_n>b\}\notin \mathfrak T$ ?","Let be real valued random variables. Put and . Let and define the tail -algebra . The book I am reading now says : But I don't get why this holds. Intuitively, this event seems to be unaffected by first finite happenings... Could you give me an example or explanation? Thank you in advance. Edit: For example, let for all , assuming that they are not independent and let . Is is still true that ?","X_1,X_2,... \mathfrak S_n=\sigma (X_n) S_n=X_1+X_2+...+X_n \mathfrak T_n=\sigma (X_{n+1},X_{n+2},...) \sigma \mathfrak T=\cap _n \mathfrak T_n \{\limsup S_n>b\}\notin \mathfrak T X_n =^{dist} U_{(-1,1)} n b=0 \{\limsup S_n>b\}\notin \mathfrak T","['real-analysis', 'sequences-and-series', 'probability-theory', 'measure-theory', 'stochastic-processes']"
50,Precision of Rational Approximation to $\pi$ versus series convergence,Precision of Rational Approximation to  versus series convergence,\pi,"For $n\geq 1$ , let: $$ a_n = \text{min} \lbrace{|\sin(k)|: 1\leq k\leq n} \rbrace $$ So that $a_1=\sin(1)$ , $a_2=\sin(1)$ , $a_3=\sin(3)$ , $a_4=\sin(3)$ , $a_5=\sin(3)$ and so on. And let: $$ S_n = \sum_{k=1}^n a_k $$ The questions: 1-Does $a_n$ converge?  (yes, proven in a comment by  Xander Henderson) 2-What is the limit of $a_n$ as $n$ goes to infinity? (proven to be zero by Matt F. in his answer) 3-Does $S_n$ converge? (Still open) I believe this can be related to the precision of rational approximations of $\pi$ because for some integer $a$ there exists $b\in]0,\pi[$ such that: $$ n= a\pi+b $$ Then: $$ |\sin(n)|=|\sin(a\pi+b)| = |\sin(b)| $$ And: $$ \pi = \frac{n}{a}-\frac{b}{a} $$ So $n/a$ is a rational approximation of $\pi$ with error smaller than $\pi/a$ in absolute value. But since $b$ is in the interval ]0,\pi[ (cannot be zero because $\pi$ is irrational), then the sequence is basically the value of the smallest $b$ found for $k\leq n$ . My guess is that the sequence converges to zero, even if it never reaches zero (just like a geometric progression). I would also believe the series is convergent, but these would depend on how fast the accuracy of the rational approximations to $\pi$ grows with respect to their denominator.","For , let: So that , , , , and so on. And let: The questions: 1-Does converge?  (yes, proven in a comment by  Xander Henderson) 2-What is the limit of as goes to infinity? (proven to be zero by Matt F. in his answer) 3-Does converge? (Still open) I believe this can be related to the precision of rational approximations of because for some integer there exists such that: Then: And: So is a rational approximation of with error smaller than in absolute value. But since is in the interval ]0,\pi[ (cannot be zero because is irrational), then the sequence is basically the value of the smallest found for . My guess is that the sequence converges to zero, even if it never reaches zero (just like a geometric progression). I would also believe the series is convergent, but these would depend on how fast the accuracy of the rational approximations to grows with respect to their denominator.","n\geq 1 
a_n = \text{min} \lbrace{|\sin(k)|: 1\leq k\leq n} \rbrace
 a_1=\sin(1) a_2=\sin(1) a_3=\sin(3) a_4=\sin(3) a_5=\sin(3) 
S_n = \sum_{k=1}^n a_k
 a_n a_n n S_n \pi a b\in]0,\pi[ 
n= a\pi+b
 
|\sin(n)|=|\sin(a\pi+b)| = |\sin(b)|
 
\pi = \frac{n}{a}-\frac{b}{a}
 n/a \pi \pi/a b \pi b k\leq n \pi","['sequences-and-series', 'irrational-numbers', 'rational-numbers']"
51,Evaluate infinite sum involving n!,Evaluate infinite sum involving n!,,"Evaluate $\sum_{n=1}^\infty \frac{1}{nn!}$ I really don't know where to begin with this but I'm pretty sure $e$ is involved somehow. If it can help, $nn!=(n+1)!-n!$","Evaluate $\sum_{n=1}^\infty \frac{1}{nn!}$ I really don't know where to begin with this but I'm pretty sure $e$ is involved somehow. If it can help, $nn!=(n+1)!-n!$",,['sequences-and-series']
52,How to evaluate the sum of infinite series numerically? [closed],How to evaluate the sum of infinite series numerically? [closed],,"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 6 years ago . Improve this question As mentioned in document, Mathematica can evaluate Riemann Zeta function to arbitrary numerical precision. I see related posts which takes advantage of the property of Zeta function. But for a converged general series without closed form, how do we evaluate it numerically? Do we have to sum many terms one by one. When should we stop? How do we know the result reaches given precision? And the sum of all remaining terms won't affect the result? If the sum of the series converges very slowly, the computation would be very expensive. ==== UPDATE Since this post is on hold, I know that there is no general way to evaluate the sum of infinite series. Many thanks to your replies. They give me a good start point for further study.","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 6 years ago . Improve this question As mentioned in document, Mathematica can evaluate Riemann Zeta function to arbitrary numerical precision. I see related posts which takes advantage of the property of Zeta function. But for a converged general series without closed form, how do we evaluate it numerically? Do we have to sum many terms one by one. When should we stop? How do we know the result reaches given precision? And the sum of all remaining terms won't affect the result? If the sum of the series converges very slowly, the computation would be very expensive. ==== UPDATE Since this post is on hold, I know that there is no general way to evaluate the sum of infinite series. Many thanks to your replies. They give me a good start point for further study.",,"['sequences-and-series', 'summation', 'numerical-methods']"
53,Convergence of a Cesaro sequence,Convergence of a Cesaro sequence,,"Let $\{a_n\}_{n=1}^{\infty}$ be a sequence such that $a_i\in[0,1]$ for every $i\in \mathbb{N}$, and suppose that $$\lim_{n \to \infty}\frac{1}{n} \sum_{i=1}^n a_i = p.$$ Does $$\frac{1}{n} \sum_{i=1}^n a_i^2$$ necessarily converge when $n \to \infty$? Clearly, that fact that $$\left|\frac{1}{n} \sum_{i=1}^n a_i\right|\geqslant\left|\frac{1}{n} \sum_{i=1}^n a_i^2\right|$$ is not enough, but together with the fact that the sequence $a_n^2$ is the square of $a_n$, is it enough?","Let $\{a_n\}_{n=1}^{\infty}$ be a sequence such that $a_i\in[0,1]$ for every $i\in \mathbb{N}$, and suppose that $$\lim_{n \to \infty}\frac{1}{n} \sum_{i=1}^n a_i = p.$$ Does $$\frac{1}{n} \sum_{i=1}^n a_i^2$$ necessarily converge when $n \to \infty$? Clearly, that fact that $$\left|\frac{1}{n} \sum_{i=1}^n a_i\right|\geqslant\left|\frac{1}{n} \sum_{i=1}^n a_i^2\right|$$ is not enough, but together with the fact that the sequence $a_n^2$ is the square of $a_n$, is it enough?",,"['calculus', 'sequences-and-series', 'convergence-divergence', 'cesaro-summable']"
54,Find limit of $\{a_n\}$,Find limit of,\{a_n\},"The sequence $\{a_n\}$ is determined by $$a_1 = 1, a_{n+1} = \frac{3n-1}{3n} a_n + \frac{1}{n^2}, \quad \forall n\ge 1.$$ Find the limit of $\{a_n\}$ (if it exists). I guess the limit is $0$ by using MATLAB, but the sequence converges really slowly.","The sequence is determined by Find the limit of (if it exists). I guess the limit is by using MATLAB, but the sequence converges really slowly.","\{a_n\} a_1 = 1, a_{n+1} = \frac{3n-1}{3n} a_n + \frac{1}{n^2}, \quad \forall n\ge 1. \{a_n\} 0","['real-analysis', 'sequences-and-series', 'limits']"
55,"General formula for Evaluating $\sum_{n=0}^\infty n^ar^n$ where $ |r|<1 , a\ge0$",General formula for Evaluating  where,"\sum_{n=0}^\infty n^ar^n  |r|<1 , a\ge0","I'm trying to derive a general formula for $$\sum_{n=0}^\infty n^ar^n$$ where $a\ge0$ and $|r|<1$ I know the first couple a: $$I(0)=\sum_{n=0}^\infty r^n=\frac{1}{(1-r)}$$ $$I(1)=\sum_{n=0}^\infty nr^n=\frac{r}{(1-r)^2}$$ $$I(2)=\sum_{n=0}^\infty n^2r^n=\frac{-r(r+1)}{(r-1)^3}$$ $$I(a)=\sum_{n=0}^\infty n^ar^n=???$$ assuming my math was correct. I got these by differentiating the general summation formula for geometric series. After doing it a couple more times, I can't seem to discern a pattern.","I'm trying to derive a general formula for $$\sum_{n=0}^\infty n^ar^n$$ where $a\ge0$ and $|r|<1$ I know the first couple a: $$I(0)=\sum_{n=0}^\infty r^n=\frac{1}{(1-r)}$$ $$I(1)=\sum_{n=0}^\infty nr^n=\frac{r}{(1-r)^2}$$ $$I(2)=\sum_{n=0}^\infty n^2r^n=\frac{-r(r+1)}{(r-1)^3}$$ $$I(a)=\sum_{n=0}^\infty n^ar^n=???$$ assuming my math was correct. I got these by differentiating the general summation formula for geometric series. After doing it a couple more times, I can't seem to discern a pattern.",,"['calculus', 'sequences-and-series', 'derivatives', 'summation']"
56,Infinite series of $\frac{1}{n^p+1}$,Infinite series of,\frac{1}{n^p+1},"I was wondering if the infinite series $$\sum_{n=0}^\infty \frac{1}{n^{3/2}+1}\approx 1.95202$$ can be expressed in closed form (unlikely) or in terms of the fractional values of the zeta function (more likely). More generally, I would like to know if anyone can find a way to do so for  $$\sum_{n=0}^\infty \frac{1}{n^{p}+1}$$ where $p\ne \mathbb Z$. Wolfram yields nothing but the numerical approximation above.","I was wondering if the infinite series $$\sum_{n=0}^\infty \frac{1}{n^{3/2}+1}\approx 1.95202$$ can be expressed in closed form (unlikely) or in terms of the fractional values of the zeta function (more likely). More generally, I would like to know if anyone can find a way to do so for  $$\sum_{n=0}^\infty \frac{1}{n^{p}+1}$$ where $p\ne \mathbb Z$. Wolfram yields nothing but the numerical approximation above.",,"['sequences-and-series', 'summation', 'riemann-zeta']"
57,Show that the inequality is valid for infinite terms of a sequence,Show that the inequality is valid for infinite terms of a sequence,,"This question comes from a Brazilian book of real analysis, which is ""Introduo a Anlise"" (Introduction to Analysis) of Antonio Caminha. The problem is: Let $(a_n)_{n \in \mathbb{N}}$ be a sequence of positive real numbers. Show that the inequality $$ 1 + a_n > 2^{1/n}a_{n-1} $$ is true for infinity $n \in \mathbb{N}$.","This question comes from a Brazilian book of real analysis, which is ""Introduo a Anlise"" (Introduction to Analysis) of Antonio Caminha. The problem is: Let $(a_n)_{n \in \mathbb{N}}$ be a sequence of positive real numbers. Show that the inequality $$ 1 + a_n > 2^{1/n}a_{n-1} $$ is true for infinity $n \in \mathbb{N}$.",,"['real-analysis', 'sequences-and-series', 'inequality', 'real-numbers']"
58,How to prove that $\sum _{p}\sum_{k = 2}^\infty \frac{1}{kp^k}$ is convergent?,How to prove that  is convergent?,\sum _{p}\sum_{k = 2}^\infty \frac{1}{kp^k},How to prove that $\sum _{p}\sum_{k=2}^\infty \frac{1}{kp^k}$ is convergent? where $p$ is prime. What I have done is $$\sum_{k = 2}^\infty \frac{1}{kp^k}=-\log\left(1-\frac 1p\right)-\frac 1p $$ Then for $\sum _{p}(-\log(1-\frac 1p)-\frac 1p) $ I was trying to use integral test after putting $n\in \Bbb N$ in place of $p$. But I was not getting my desired result. Please help.,How to prove that $\sum _{p}\sum_{k=2}^\infty \frac{1}{kp^k}$ is convergent? where $p$ is prime. What I have done is $$\sum_{k = 2}^\infty \frac{1}{kp^k}=-\log\left(1-\frac 1p\right)-\frac 1p $$ Then for $\sum _{p}(-\log(1-\frac 1p)-\frac 1p) $ I was trying to use integral test after putting $n\in \Bbb N$ in place of $p$. But I was not getting my desired result. Please help.,,"['real-analysis', 'sequences-and-series', 'number-theory', 'analysis', 'analytic-number-theory']"
59,What does the p-harmonic series converge to when p = 1 + ?,What does the p-harmonic series converge to when p = 1 + ?,,"In infinitesimal calculus, $\epsilon$ is an infinitesimal number, that is, it is defined to be a number smaller than any real number but greater than $0$. The p-harmonic series is: $\displaystyle \sum_{n=1}^{\infty} \frac{1}{n^p}$ It is well known that this series diverges when $p \leq 1$ and converges when $p > 1$. A lot of teachers like to do examples of this problem with $p$ arbitrarily close to one, but still greater, like $p = 1 + 0.001$. What I want to know is, what happens when $p$ is infinitesimally close to $1$? In other words what does the series converge to when $p = 1 + \epsilon$?: $\displaystyle \sum_{n=1}^{\infty} \frac{1}{n^{1 + \epsilon}}$ Is this any different from just taking the limit as $p$ approaches 1?: $\displaystyle \lim_{p \to 1^+} \sum_{n=1}^{\infty} \frac{1}{n^{p}}$ $1 + \epsilon$ is a number that is greater than $1$, whereas, the limit is getting arbitrarily close to $1$, and presumably that means it gets closer to $1$ than $1 + \epsilon$. However, I don't know what number the series could possible converge to when $p = 1 + \epsilon$.","In infinitesimal calculus, $\epsilon$ is an infinitesimal number, that is, it is defined to be a number smaller than any real number but greater than $0$. The p-harmonic series is: $\displaystyle \sum_{n=1}^{\infty} \frac{1}{n^p}$ It is well known that this series diverges when $p \leq 1$ and converges when $p > 1$. A lot of teachers like to do examples of this problem with $p$ arbitrarily close to one, but still greater, like $p = 1 + 0.001$. What I want to know is, what happens when $p$ is infinitesimally close to $1$? In other words what does the series converge to when $p = 1 + \epsilon$?: $\displaystyle \sum_{n=1}^{\infty} \frac{1}{n^{1 + \epsilon}}$ Is this any different from just taking the limit as $p$ approaches 1?: $\displaystyle \lim_{p \to 1^+} \sum_{n=1}^{\infty} \frac{1}{n^{p}}$ $1 + \epsilon$ is a number that is greater than $1$, whereas, the limit is getting arbitrarily close to $1$, and presumably that means it gets closer to $1$ than $1 + \epsilon$. However, I don't know what number the series could possible converge to when $p = 1 + \epsilon$.",,"['sequences-and-series', 'power-series', 'infinitesimals']"
60,Find the range of $x$ for the convergence of the series $\sum_{n=1}^{\infty} \frac{1}{\left(-3\right)^{n+2}} \frac{\left(4x-12\right)^{n}}{n^{2}+1}$,Find the range of  for the convergence of the series,x \sum_{n=1}^{\infty} \frac{1}{\left(-3\right)^{n+2}} \frac{\left(4x-12\right)^{n}}{n^{2}+1},"Question: Find the range of $x$ for the convergence of the series$$\sum_{n=1}^{\infty} \frac{1}{\left(-3\right)^{n+2}} \frac{\left(4x-12\right)^{n}}{n^{2}+1}$$ MY Approach: By $n$th term divergence test, $$\lim_{n\rightarrow\infty} \frac{1}{\left(-3\right)^{n+2}} \frac{\left(4x-12\right)^{n}}{n^{2}+1}=0 \Longleftrightarrow |4x-12|<1\Longleftrightarrow\frac{11}{4}<x<\frac{13}{4},$$ not in the options. Edit","Question: Find the range of $x$ for the convergence of the series$$\sum_{n=1}^{\infty} \frac{1}{\left(-3\right)^{n+2}} \frac{\left(4x-12\right)^{n}}{n^{2}+1}$$ MY Approach: By $n$th term divergence test, $$\lim_{n\rightarrow\infty} \frac{1}{\left(-3\right)^{n+2}} \frac{\left(4x-12\right)^{n}}{n^{2}+1}=0 \Longleftrightarrow |4x-12|<1\Longleftrightarrow\frac{11}{4}<x<\frac{13}{4},$$ not in the options. Edit",,"['real-analysis', 'sequences-and-series', 'limits', 'convergence-divergence']"
61,Series $\sum_{n=1}^{\infty} \left[K_0\left(\sqrt{[n\beta-it]^2+s^2 }\right)+K_0\left(\sqrt{[n\beta+it]^2+s^2}\right)\right]$,Series,\sum_{n=1}^{\infty} \left[K_0\left(\sqrt{[n\beta-it]^2+s^2 }\right)+K_0\left(\sqrt{[n\beta+it]^2+s^2}\right)\right],"Let $\beta > 0$ and $t, s \in \mathbb{R}$. Furthermore, suppose that $-t^2 + s^2 > 0$. Define the following function: $$ F( \beta, t, s )\ : = \ \sum_{n=1}^{\infty} \left[K_0\left(\sqrt{[n\beta-it]^2+s^2 }\right)+K_0\left(\sqrt{[n\beta+it]^2+s^2}\right)\right] $$ where $K_0$ is the modified Bessel function of the second kind (McDonald function) of order $0$. I know that $K_0(z) \sim - \log(z)$ for $z=0$ (this is where the function blows up). Also, I know that $K_0(z) \sim \frac{e^{-z}}{\sqrt{z}}$ for $z\to\infty$ where the function dies away to $0$. I am interested in the following questions: Is there a way to evaluate this series? (I am guessing probably not. I have found nothing helpful in Gradshteyn+Ryzhik nor DLMF) How does this function look like in the limit $t \to 0$? (Asymptotically) How does this function look like in the limit $t \to \infty$? I am more interested in the latter 2 questions. Because $F$ is a series I am not sure how to deal with this.","Let $\beta > 0$ and $t, s \in \mathbb{R}$. Furthermore, suppose that $-t^2 + s^2 > 0$. Define the following function: $$ F( \beta, t, s )\ : = \ \sum_{n=1}^{\infty} \left[K_0\left(\sqrt{[n\beta-it]^2+s^2 }\right)+K_0\left(\sqrt{[n\beta+it]^2+s^2}\right)\right] $$ where $K_0$ is the modified Bessel function of the second kind (McDonald function) of order $0$. I know that $K_0(z) \sim - \log(z)$ for $z=0$ (this is where the function blows up). Also, I know that $K_0(z) \sim \frac{e^{-z}}{\sqrt{z}}$ for $z\to\infty$ where the function dies away to $0$. I am interested in the following questions: Is there a way to evaluate this series? (I am guessing probably not. I have found nothing helpful in Gradshteyn+Ryzhik nor DLMF) How does this function look like in the limit $t \to 0$? (Asymptotically) How does this function look like in the limit $t \to \infty$? I am more interested in the latter 2 questions. Because $F$ is a series I am not sure how to deal with this.",,"['sequences-and-series', 'functions', 'special-functions', 'bessel-functions', 'special-relativity']"
62,Show uniform convergence of the series of functions $\sum_{n=1}^\infty \frac{x^n \sin(nx)}{n}$,Show uniform convergence of the series of functions,\sum_{n=1}^\infty \frac{x^n \sin(nx)}{n},"Show uniform convergence of the series of functions $\sum_{n=1}^\infty \frac{x^n \sin(nx)}{n}$ on the interval $[-1,1]$ My attempt : I showed the series converges uniformly on the interval $[-1/2,1/2]$ using Weierstrass M-test. I also showed the series converges uniformly on the interval $[1/2,1]$ by using Dirichlet's criterium, where I used that $\left|\sum_{k=1}^n \sin(kx)\right| \leq \frac{1}{\sin(x/2)}$ However, I'm stuck at showing it converges uniformly on the interval $[-1,-1/2]$. I tried to apply Dirichlet's criterium but can't conclude anything because of the behaviour of the term $x^n/n$ (which does not decrease monotonically). Any ideas?","Show uniform convergence of the series of functions $\sum_{n=1}^\infty \frac{x^n \sin(nx)}{n}$ on the interval $[-1,1]$ My attempt : I showed the series converges uniformly on the interval $[-1/2,1/2]$ using Weierstrass M-test. I also showed the series converges uniformly on the interval $[1/2,1]$ by using Dirichlet's criterium, where I used that $\left|\sum_{k=1}^n \sin(kx)\right| \leq \frac{1}{\sin(x/2)}$ However, I'm stuck at showing it converges uniformly on the interval $[-1,-1/2]$. I tried to apply Dirichlet's criterium but can't conclude anything because of the behaviour of the term $x^n/n$ (which does not decrease monotonically). Any ideas?",,"['real-analysis', 'sequences-and-series']"
63,Evaluate lim$_{n\rightarrow\infty}$ $\frac{1-2+3-4+5-...............+\left(-2n\right)}{\sqrt{n^{2}+1}+\sqrt{n^{2}-1}}$ [duplicate],Evaluate lim  [duplicate],_{n\rightarrow\infty} \frac{1-2+3-4+5-...............+\left(-2n\right)}{\sqrt{n^{2}+1}+\sqrt{n^{2}-1}},"This question already has answers here : Compute: $\lim_{n \rightarrow \infty}\sqrt{n}(A_{n+1}  A_n)$ where $A_n = \frac{1}{n}(a_1 + a_2 + \cdots + a_n)$ (2 answers) Closed 5 years ago . Evaluate $$\lim_{n\rightarrow\infty}\frac{1-2+3-4+5-\cdots+\left(-2n\right)}{\sqrt{n^{2}+1}+\sqrt{n^{2}-1}}.$$ My Approach Let $A_{n}=1+3+5+\cdots\left(2n-1\right)$ and $B_{n}=2+4+6+\cdots\left(2n\right)$, then $A_n=\frac{n}{2}\left(1+2n-1\right)=n^{2}$ and $B_{n}=\frac{n}{2}\left(2+2n\right)=n+n^{2}$. Therefore, $$\lim_{n\rightarrow\infty}\frac{A_{n}-B_{n}}{\sqrt{n^{2}+1}+\sqrt{n^{2}-1}}=\lim_{n\rightarrow\infty}\frac{-n}{\sqrt{n^{2}+1}+\sqrt{n^{2}-1}}=-\frac{1}{2}.$$ But the book mentions that the answer is $0$.","This question already has answers here : Compute: $\lim_{n \rightarrow \infty}\sqrt{n}(A_{n+1}  A_n)$ where $A_n = \frac{1}{n}(a_1 + a_2 + \cdots + a_n)$ (2 answers) Closed 5 years ago . Evaluate $$\lim_{n\rightarrow\infty}\frac{1-2+3-4+5-\cdots+\left(-2n\right)}{\sqrt{n^{2}+1}+\sqrt{n^{2}-1}}.$$ My Approach Let $A_{n}=1+3+5+\cdots\left(2n-1\right)$ and $B_{n}=2+4+6+\cdots\left(2n\right)$, then $A_n=\frac{n}{2}\left(1+2n-1\right)=n^{2}$ and $B_{n}=\frac{n}{2}\left(2+2n\right)=n+n^{2}$. Therefore, $$\lim_{n\rightarrow\infty}\frac{A_{n}-B_{n}}{\sqrt{n^{2}+1}+\sqrt{n^{2}-1}}=\lim_{n\rightarrow\infty}\frac{-n}{\sqrt{n^{2}+1}+\sqrt{n^{2}-1}}=-\frac{1}{2}.$$ But the book mentions that the answer is $0$.",,"['real-analysis', 'sequences-and-series', 'limits', 'convergence-divergence']"
64,Calculate the length of the curve.,Calculate the length of the curve.,,"$L_1, \ L_2,...,L_{12}$ are twelve lines going through origo with $30^{\text{o}}$ apart as shown in the figure. The length of $OP_1$ is equal to $1$. One can, as shown in the figure construct an infinite spiral by drawing normals from the next line to the previous. If this spiral is to go around origo for an infinite number of times, what is the total length of this spiral curve? I think I solved this problem, but my book has no answer page, so I need someone to check my work. This is what I did: I noticed that \begin{array}{lcl} P_1P_2 & = & OP_1\sin{30} \\ P_2P_3 & = & OP_2\sin{30} =OP_1\cos{30}\sin{30} \\ P_3P_4 & = & OP_2\cos{30}\sin{30}=OP_1\cos^2{30}\sin{30} \\  & \vdots & \\ P_{n+1}P_{n+2} & = & \cos^{n}{30}\sin{30}. \end{array} So, the total length of the curve is given by the geometric sum $$\sum_{k=1}^{\infty}\cos^k{30}\sin{30}=\lim_{n\rightarrow\infty}\frac{1}{2}\sum_{k=1}^{n}\left(\frac{\sqrt{3}}{2}\right)^k=\lim_{n\rightarrow\infty}\frac{1}{2}\frac{\left(\frac{\sqrt{3}}{2}\right)^{n+1}-\left(\frac{\sqrt{3}}{2}\right)}{1-\frac{\sqrt{3}}{2}}= \frac{\sqrt{3}}{4-2\sqrt{3}}\approx3.232.$$ Questions: Is the above correct? Why do I get a different answer when I instead use $P_{n}P_{n+1}  =  \cos^{n-1}{30}\sin{30}?$ I then get $$\frac{1}{2}\sum_{k=1}^{\infty}\left(\frac{\sqrt{3}}{2}\right)^k\left(\frac{4}{\sqrt{3}}\right)=\frac{2}{2-\sqrt{3}}\approx7.465.$$ Note: I don't want an alternative fance show-off-solution, I just want to know how I can improve my method.","$L_1, \ L_2,...,L_{12}$ are twelve lines going through origo with $30^{\text{o}}$ apart as shown in the figure. The length of $OP_1$ is equal to $1$. One can, as shown in the figure construct an infinite spiral by drawing normals from the next line to the previous. If this spiral is to go around origo for an infinite number of times, what is the total length of this spiral curve? I think I solved this problem, but my book has no answer page, so I need someone to check my work. This is what I did: I noticed that \begin{array}{lcl} P_1P_2 & = & OP_1\sin{30} \\ P_2P_3 & = & OP_2\sin{30} =OP_1\cos{30}\sin{30} \\ P_3P_4 & = & OP_2\cos{30}\sin{30}=OP_1\cos^2{30}\sin{30} \\  & \vdots & \\ P_{n+1}P_{n+2} & = & \cos^{n}{30}\sin{30}. \end{array} So, the total length of the curve is given by the geometric sum $$\sum_{k=1}^{\infty}\cos^k{30}\sin{30}=\lim_{n\rightarrow\infty}\frac{1}{2}\sum_{k=1}^{n}\left(\frac{\sqrt{3}}{2}\right)^k=\lim_{n\rightarrow\infty}\frac{1}{2}\frac{\left(\frac{\sqrt{3}}{2}\right)^{n+1}-\left(\frac{\sqrt{3}}{2}\right)}{1-\frac{\sqrt{3}}{2}}= \frac{\sqrt{3}}{4-2\sqrt{3}}\approx3.232.$$ Questions: Is the above correct? Why do I get a different answer when I instead use $P_{n}P_{n+1}  =  \cos^{n-1}{30}\sin{30}?$ I then get $$\frac{1}{2}\sum_{k=1}^{\infty}\left(\frac{\sqrt{3}}{2}\right)^k\left(\frac{4}{\sqrt{3}}\right)=\frac{2}{2-\sqrt{3}}\approx7.465.$$ Note: I don't want an alternative fance show-off-solution, I just want to know how I can improve my method.",,"['calculus', 'sequences-and-series']"
65,Analyze the convergence of the series: $\sum_{n=1}^{\infty} \frac{n^n}{(n+1)!}$,Analyze the convergence of the series:,\sum_{n=1}^{\infty} \frac{n^n}{(n+1)!},"In analyzing the convergence of the following series: $$\sum_{n=1}^{\infty} \frac{n^n}{(n+1)!}$$ Using the quotient criteria, I get the following: $$ \frac{a_{n+1}}{a_n} = \frac{\frac{(n+1)^{n+1}}{(n+2)!}}{\frac{n^n}{(n+1)!}} = \frac{(n+1)^{n+1}(n+1)!}{(n+2)!n^n} = \frac{(n+1)^{n+1}(n+1)!}{(n+2)(n+1)!n^n} = \frac{(n+1)^{n+1}}{(n+2)n^n} $$ Now I am trying to find the limit of $\frac{a_{n+1}}{a_n}$: $$ \lim_{n \to \infty}\frac{a_{n+1}}{a_n} = \lim_{n \to \infty}\frac{(n+1)^{n+1}}{(n+2)n^n} = ? $$ But I am having trouble solving this. What steps do I need to follow to simplify and solve this limit?","In analyzing the convergence of the following series: $$\sum_{n=1}^{\infty} \frac{n^n}{(n+1)!}$$ Using the quotient criteria, I get the following: $$ \frac{a_{n+1}}{a_n} = \frac{\frac{(n+1)^{n+1}}{(n+2)!}}{\frac{n^n}{(n+1)!}} = \frac{(n+1)^{n+1}(n+1)!}{(n+2)!n^n} = \frac{(n+1)^{n+1}(n+1)!}{(n+2)(n+1)!n^n} = \frac{(n+1)^{n+1}}{(n+2)n^n} $$ Now I am trying to find the limit of $\frac{a_{n+1}}{a_n}$: $$ \lim_{n \to \infty}\frac{a_{n+1}}{a_n} = \lim_{n \to \infty}\frac{(n+1)^{n+1}}{(n+2)n^n} = ? $$ But I am having trouble solving this. What steps do I need to follow to simplify and solve this limit?",,"['sequences-and-series', 'limits']"
66,"Show that $u_n$ converges if $\min(u_n,u_{n+1})$ converges.",Show that  converges if  converges.,"u_n \min(u_n,u_{n+1})","Let $\lambda \in (0,1)$ and $(u_n)_n$ a sequence of real numbers such that :  $\forall n \in \mathbb N : \; u_{n+2}\ge \lambda u_{n+1} + (1-\lambda)u_n$. And $\forall n \in \Bbb N \; v_n=\min(u_{n+1},u_n)$ . The problem first asks to show that $v_n$ does have a limit, I have done this by showing that it's an increasing sequence. This immediately gives us that if $v_n \to +\infty$ then $u_n \to +\infty$ . The next question is to show that if $v_n \to l \in \Bbb R$ then $u_n$ converges. I fail to see why this must be true, I tried to use the definition of limits but to no avail.","Let $\lambda \in (0,1)$ and $(u_n)_n$ a sequence of real numbers such that :  $\forall n \in \mathbb N : \; u_{n+2}\ge \lambda u_{n+1} + (1-\lambda)u_n$. And $\forall n \in \Bbb N \; v_n=\min(u_{n+1},u_n)$ . The problem first asks to show that $v_n$ does have a limit, I have done this by showing that it's an increasing sequence. This immediately gives us that if $v_n \to +\infty$ then $u_n \to +\infty$ . The next question is to show that if $v_n \to l \in \Bbb R$ then $u_n$ converges. I fail to see why this must be true, I tried to use the definition of limits but to no avail.",,"['real-analysis', 'sequences-and-series', 'convergence-divergence', 'real-numbers']"
67,Prove that $\lim_{n\to \infty}S_n = \infty$,Prove that,\lim_{n\to \infty}S_n = \infty,"Let $(x_n),(y_n)$ be two sequences of positive real numbers, with $x_n \to \infty$ and $$S_n=\frac{x_n}{x_n+y_1}+\frac{x_n}{2x_n+y_2}+\dots+\frac{x_n}{nx_n+y_n}$$   Prove that $\lim_{n\to \infty}S_n = \infty$ I tried to write the given sum as $S_n=x_n \left(\frac{1}{x_n+y_1}+\frac{1}{2\left(x_n+\frac{y_2}{2}\right)}+\dots+\frac{1}{n\left(x_n+\frac{y_n}{n}\right)} \right)$ and managed to prove the claim when $\left(\frac{y_n}{n}\right)$ is bounded. For the case when it is unbounded, I tried to use the sequence $a_n=\max \{\frac{y_1}{1}, \dots , \frac{y_n}{n} \}$, for which $a_n \to \infty$, in order to get $S_n \geq \frac{x_n}{x_n+a_n}\left(1+\frac{1}{2}+\dots+\frac{1}{n} \right)$, but I couldn't finish. Also, I tried writing the sum as $S_n=\frac{1}{1+\frac{y_1}{x_n}}+\frac{1}{2+\frac{y_2}{x_n}}+\dots+\frac{1}{n+\frac{y_n}{x_n}}$, but nothing came out of it...","Let $(x_n),(y_n)$ be two sequences of positive real numbers, with $x_n \to \infty$ and $$S_n=\frac{x_n}{x_n+y_1}+\frac{x_n}{2x_n+y_2}+\dots+\frac{x_n}{nx_n+y_n}$$   Prove that $\lim_{n\to \infty}S_n = \infty$ I tried to write the given sum as $S_n=x_n \left(\frac{1}{x_n+y_1}+\frac{1}{2\left(x_n+\frac{y_2}{2}\right)}+\dots+\frac{1}{n\left(x_n+\frac{y_n}{n}\right)} \right)$ and managed to prove the claim when $\left(\frac{y_n}{n}\right)$ is bounded. For the case when it is unbounded, I tried to use the sequence $a_n=\max \{\frac{y_1}{1}, \dots , \frac{y_n}{n} \}$, for which $a_n \to \infty$, in order to get $S_n \geq \frac{x_n}{x_n+a_n}\left(1+\frac{1}{2}+\dots+\frac{1}{n} \right)$, but I couldn't finish. Also, I tried writing the sum as $S_n=\frac{1}{1+\frac{y_1}{x_n}}+\frac{1}{2+\frac{y_2}{x_n}}+\dots+\frac{1}{n+\frac{y_n}{x_n}}$, but nothing came out of it...",,"['calculus', 'real-analysis', 'sequences-and-series', 'limits', 'convergence-divergence']"
68,Find $\lim_{x\to \infty}{\sin(x^2)}x^{-1/2} $,Find,\lim_{x\to \infty}{\sin(x^2)}x^{-1/2} ,Find $$\lim_{x\to \infty}\frac{\sin(x^2)}{ \sqrt{x}} $$ (1) $$-1 \le \sin(x^2) \le 1 $$ $$\frac{-1}{\sqrt{x}} \le \frac{\sin(x^2)}{\sqrt{x}} \le \frac{1}{\sqrt{x}}$$ (2) I prove that $\lim \frac{1}{\sqrt{x}} = 0$ using the delta definition (3) $$0 \le \lim_{x\to \infty}\frac{\sin(x^2)}{\sqrt{x}} \le 0$$ $$\lim_{x\to \infty}\frac{\sin(x^2)}{\sqrt{x}} =0$$ Have I solved this correctly?,Find $$\lim_{x\to \infty}\frac{\sin(x^2)}{ \sqrt{x}} $$ (1) $$-1 \le \sin(x^2) \le 1 $$ $$\frac{-1}{\sqrt{x}} \le \frac{\sin(x^2)}{\sqrt{x}} \le \frac{1}{\sqrt{x}}$$ (2) I prove that $\lim \frac{1}{\sqrt{x}} = 0$ using the delta definition (3) $$0 \le \lim_{x\to \infty}\frac{\sin(x^2)}{\sqrt{x}} \le 0$$ $$\lim_{x\to \infty}\frac{\sin(x^2)}{\sqrt{x}} =0$$ Have I solved this correctly?,,"['calculus', 'sequences-and-series']"
69,Arrow up notation,Arrow up notation,,"I have a simple question about a notation that I found in a scientific paper. The authors use the following notation: $ [...] \hspace{0.5cm} d_n \uparrow \infty \hspace{0.2cm} \text{as} \hspace{0.2cm} n \rightarrow\infty. \hspace{0.5cm} [...] $ What could the authors possibly mean with the arrow that goes up? What happens to $d_n$ as n goes to infinity? When I was searching for an explanation, all I found was Knuth's arrow up. But the authors don't seem to use the arrow in that way. I don't think that this is a typo, as the authors are quite renowned in their field of study, and the paper was published in the Journal of Econometrics. Note : I think more context would only distract from the question at hand. If you disagree, I can provide more details.","I have a simple question about a notation that I found in a scientific paper. The authors use the following notation: $ [...] \hspace{0.5cm} d_n \uparrow \infty \hspace{0.2cm} \text{as} \hspace{0.2cm} n \rightarrow\infty. \hspace{0.5cm} [...] $ What could the authors possibly mean with the arrow that goes up? What happens to $d_n$ as n goes to infinity? When I was searching for an explanation, all I found was Knuth's arrow up. But the authors don't seem to use the arrow in that way. I don't think that this is a typo, as the authors are quite renowned in their field of study, and the paper was published in the Journal of Econometrics. Note : I think more context would only distract from the question at hand. If you disagree, I can provide more details.",,"['sequences-and-series', 'notation']"
70,Determine for what values of $x$ the given series converges,Determine for what values of  the given series converges,x,"The given series is $\sum_{n=1}^ (1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}+\frac{1}{7}+...+\frac{1}{n} )x^{n} $. I tried it by using Cauchy Root Test as follows- Let  $y=\lim_{n\to\infty}(1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}+\frac{1}{7}+...+\frac{1}{n} )^{1/n}$, then by taking logarithm both sides,we get $\log(y)=\lim_{n\to\infty}\frac{1}{n}\log(1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}+\frac{1}{7}+...+\frac{1}{n} )$ Since, $\log(0)=-\infty$. So, $\log(1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}+\frac{1}{7}+...+\frac{1}{n} )=-\infty$. Applying,L'Hpital's rule,we get $\log(y)=\lim_{n\to\infty}-\frac{(\frac{1}{n^2}+\frac{1}{(n-1)^2}+\frac{1}{(n-2)^2}+...+...+... )}{(1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}+\frac{1}{7}+...+\frac{1}{n} )}$.( Please Check this step!! ) Since,$\sum_{k=1}^\infty\frac{1}{k^2}=\lim_{n\to\infty}\sum_{k=1}^n\frac{1}{k^2}=\frac{\pi^2}{6}$ & $\sum_{k=1}^\infty\frac{1}{k}=\lim_{n\to\infty}\sum_{k=1}^n\frac{1}{k}=\infty$.So,$\log(y)=0\implies y=1$. Now let $a_n=(1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}+\frac{1}{7}+...+\frac{1}{n} )x^{n} $. Then,$$(a_n)^{1/n}=\lim_{n\to\infty}(1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}+\frac{1}{7}+...+\frac{1}{n} )^{1/n}x$$ $\implies \lim_{n\to\infty}\vert (a_n)^{1/n}\vert=1.x$.By , Cauchy root test the given series converges if $\lim_{n\to\infty}(a_n)^{1/n}<1$.Hence, the given series converges if $\vert x\vert<1$. I  NEED TO KNOW WHETHER MY SOLUTION IS CORRECT OR NOT?","The given series is $\sum_{n=1}^ (1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}+\frac{1}{7}+...+\frac{1}{n} )x^{n} $. I tried it by using Cauchy Root Test as follows- Let  $y=\lim_{n\to\infty}(1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}+\frac{1}{7}+...+\frac{1}{n} )^{1/n}$, then by taking logarithm both sides,we get $\log(y)=\lim_{n\to\infty}\frac{1}{n}\log(1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}+\frac{1}{7}+...+\frac{1}{n} )$ Since, $\log(0)=-\infty$. So, $\log(1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}+\frac{1}{7}+...+\frac{1}{n} )=-\infty$. Applying,L'Hpital's rule,we get $\log(y)=\lim_{n\to\infty}-\frac{(\frac{1}{n^2}+\frac{1}{(n-1)^2}+\frac{1}{(n-2)^2}+...+...+... )}{(1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}+\frac{1}{7}+...+\frac{1}{n} )}$.( Please Check this step!! ) Since,$\sum_{k=1}^\infty\frac{1}{k^2}=\lim_{n\to\infty}\sum_{k=1}^n\frac{1}{k^2}=\frac{\pi^2}{6}$ & $\sum_{k=1}^\infty\frac{1}{k}=\lim_{n\to\infty}\sum_{k=1}^n\frac{1}{k}=\infty$.So,$\log(y)=0\implies y=1$. Now let $a_n=(1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}+\frac{1}{7}+...+\frac{1}{n} )x^{n} $. Then,$$(a_n)^{1/n}=\lim_{n\to\infty}(1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}+\frac{1}{6}+\frac{1}{7}+...+\frac{1}{n} )^{1/n}x$$ $\implies \lim_{n\to\infty}\vert (a_n)^{1/n}\vert=1.x$.By , Cauchy root test the given series converges if $\lim_{n\to\infty}(a_n)^{1/n}<1$.Hence, the given series converges if $\vert x\vert<1$. I  NEED TO KNOW WHETHER MY SOLUTION IS CORRECT OR NOT?",,"['real-analysis', 'sequences-and-series', 'proof-verification', 'power-series', 'proof-explanation']"
71,When do $\sum_{n=1}^{\infty} \dfrac1{n^{1+a\sin(bn)}} $ and $\sum_{n=1}^{\infty} \dfrac1{n\ln^{1+a\sin(bn)}(n)} $ converge or diverge?,When do  and  converge or diverge?,\sum_{n=1}^{\infty} \dfrac1{n^{1+a\sin(bn)}}  \sum_{n=1}^{\infty} \dfrac1{n\ln^{1+a\sin(bn)}(n)} ,It is well known that $\sum_{n=1}^{\infty} \dfrac1{n^{1+c}} $ and $\sum_{n=1}^{\infty} \dfrac1{n\ln^{1+c}(n)} $ converge for $c > 0$ and diverge for $c \le 0$. This got me to wondering  what would happen if $c$ varied. The obvious choice is $c = a\sin(bn)$ where $b$ is not a multiple of $\pi$. So that's my question: When conditions on $a$ and $b$ make $\sum_{n=1}^{\infty} \dfrac1{n^{1+a\sin(bn)}} $ and $\sum_{n=1}^{\infty} \dfrac1{n\ln^{1+a\sin(bn)}(n)} $ converge or diverge? I don't have a clue.,It is well known that $\sum_{n=1}^{\infty} \dfrac1{n^{1+c}} $ and $\sum_{n=1}^{\infty} \dfrac1{n\ln^{1+c}(n)} $ converge for $c > 0$ and diverge for $c \le 0$. This got me to wondering  what would happen if $c$ varied. The obvious choice is $c = a\sin(bn)$ where $b$ is not a multiple of $\pi$. So that's my question: When conditions on $a$ and $b$ make $\sum_{n=1}^{\infty} \dfrac1{n^{1+a\sin(bn)}} $ and $\sum_{n=1}^{\infty} \dfrac1{n\ln^{1+a\sin(bn)}(n)} $ converge or diverge? I don't have a clue.,,"['sequences-and-series', 'divergent-series']"
72,Two dissimilar continued fractions that are equivalent $F(q)=G(q)$,Two dissimilar continued fractions that are equivalent,F(q)=G(q),"Given the following two continued fractions,with $|q|\lt1$ $F(q)= \cfrac{1}{1+\cfrac{q}{1+\cfrac{q^2}{1+\cfrac{q^5}{1+\cfrac{q^8}{1+\cfrac{q^{12}}{1+\cfrac{q^{16}}{1+\cfrac{q^{24}}{1+\dots}}}}}}}}\tag1$ where the exponents are given by the Generating function $f(z)=\frac{-2z^4-4z^3-3z^2-2z-1}{2z^2-1}$ and $G(q)= 1-\cfrac{q}{1+\cfrac{q}{1-\cfrac{q}{1+\cfrac{q}{1-\cfrac{q^4}{1+\cfrac{q^{4}}{1-\cfrac{q^{4}}{1+\cfrac{q^{4}}{1-\dots}}}}}}}}\tag2$ in which case the exponents are given by the generating function $g(z)=\frac{-2z^7-2z^6-2z^5-2z^4-z^3-z^2-z-1}{2z^4-1}$ and satisfy the recurrence relation $a(n+4)=2a(n)$ for $n\geq4$ How do we prove that $F(q)=G(q)$? Note:by comparing coefficients of each continued fraction,we observe that they are equal. Curiously though,by plotting each generating function on the complex plane yields beautiful images( f(z) and g(z) ) of bugs","Given the following two continued fractions,with $|q|\lt1$ $F(q)= \cfrac{1}{1+\cfrac{q}{1+\cfrac{q^2}{1+\cfrac{q^5}{1+\cfrac{q^8}{1+\cfrac{q^{12}}{1+\cfrac{q^{16}}{1+\cfrac{q^{24}}{1+\dots}}}}}}}}\tag1$ where the exponents are given by the Generating function $f(z)=\frac{-2z^4-4z^3-3z^2-2z-1}{2z^2-1}$ and $G(q)= 1-\cfrac{q}{1+\cfrac{q}{1-\cfrac{q}{1+\cfrac{q}{1-\cfrac{q^4}{1+\cfrac{q^{4}}{1-\cfrac{q^{4}}{1+\cfrac{q^{4}}{1-\dots}}}}}}}}\tag2$ in which case the exponents are given by the generating function $g(z)=\frac{-2z^7-2z^6-2z^5-2z^4-z^3-z^2-z-1}{2z^4-1}$ and satisfy the recurrence relation $a(n+4)=2a(n)$ for $n\geq4$ How do we prove that $F(q)=G(q)$? Note:by comparing coefficients of each continued fraction,we observe that they are equal. Curiously though,by plotting each generating function on the complex plane yields beautiful images( f(z) and g(z) ) of bugs",,"['sequences-and-series', 'continued-fractions', 'conjectures']"
73,Closed form for $\sum_{0\le x\lt\infty}n^{2^{-x}}-1$,Closed form for,\sum_{0\le x\lt\infty}n^{2^{-x}}-1,Is there a closed form for the expression below? $$f(n)=\sum_{0\le x\lt\infty}n^{2^{-x}}-1=(n-1)+(\sqrt{n}-1)+(\sqrt{\sqrt{n}}-1)+\cdots$$ Approximations are good as well. This appeared to me while analyzing an algorithm.,Is there a closed form for the expression below? $$f(n)=\sum_{0\le x\lt\infty}n^{2^{-x}}-1=(n-1)+(\sqrt{n}-1)+(\sqrt{\sqrt{n}}-1)+\cdots$$ Approximations are good as well. This appeared to me while analyzing an algorithm.,,"['sequences-and-series', 'discrete-mathematics']"
74,"Analyze the existence of the infimum, minimum, supreme and maximum of the following sequence","Analyze the existence of the infimum, minimum, supreme and maximum of the following sequence",,"Analyze the existence of the infimum, minimum, supreme and maximum of the following set: $A=\{{a_n}:n \in\mathbb{N}\}$ where $a_n=P(n).b_n$ and $P(x)=1/3x^3-x^2-3x+10$ and $(b_n)_{n\in\mathbb{N}}$ is a sequence of positive terms that verifies: $b_1=b_2=b_3$ $b_n<b_{n+1}$ If we observe the behavior of $P(n)$ we can obviously appreciate that it grows infinitely, then diverges, and even if it grows monotonously, we know that it won't have supreme and maximum. But, what happens with $(b_n)_{n\in\mathbb{N}}$ (apart from its monotonically increasing)? Should we consider the cases where is bounded then is convergent so it will have a supreme, and the cases where is not? And then, what we can say about $a_n$ ?","Analyze the existence of the infimum, minimum, supreme and maximum of the following set: where and and is a sequence of positive terms that verifies: If we observe the behavior of we can obviously appreciate that it grows infinitely, then diverges, and even if it grows monotonously, we know that it won't have supreme and maximum. But, what happens with (apart from its monotonically increasing)? Should we consider the cases where is bounded then is convergent so it will have a supreme, and the cases where is not? And then, what we can say about ?",A=\{{a_n}:n \in\mathbb{N}\} a_n=P(n).b_n P(x)=1/3x^3-x^2-3x+10 (b_n)_{n\in\mathbb{N}} b_1=b_2=b_3 b_n<b_{n+1} P(n) (b_n)_{n\in\mathbb{N}} a_n,"['calculus', 'sequences-and-series', 'algebra-precalculus', 'exact-sequence']"
75,Sequential continuity implies $\varepsilon-\delta$ continuity,Sequential continuity implies  continuity,\varepsilon-\delta,"Let $A\subset \mathbb{R}^n$ be a set, $f:A\to\mathbb{R}^m$ be a function, $a\in A$. Suppose that $f$ is sequentially continuous at $a$. Prove that $f$ is continuous at $a$ in the sense of $\varepsilon-\delta$ definition. My proof: Let $\{x_k\}\subset A$ be a sequence such that $x_k$ converges to $a$. Then, since $f$ is sequentially continuous on $A$, $\forall \varepsilon >0$, $\exists k_0\in\mathbb{N}$ such that $\|f(x_k)-f(a)\|<\varepsilon$ whenever $k\ge k_0$. Also, $\forall\delta >0$, $\exists k_1\in\mathbb{N}$ such that $\|x_k-a\|<\delta$ whenever $k\ge k_1$. Let $k':=\max\{k_0, k_1\}$, let $k\ge k'$ (we can fix $k$), then $\|x_k-a\|<\delta\implies \|f(x_k)-f(a)\|<\varepsilon$. Hence, $f$ is continuous at $a$ in the $\varepsilon-\delta$ sense. The marker deducted about 67% of the marks and commented that my argument is done for one sequence convergent to $a$ instead of covering all sequences convergent to $a$. However, I don't understand this argument because $x_k$ was taken to be an arbitrary sequence converging to $a$. So what is my mistake then?","Let $A\subset \mathbb{R}^n$ be a set, $f:A\to\mathbb{R}^m$ be a function, $a\in A$. Suppose that $f$ is sequentially continuous at $a$. Prove that $f$ is continuous at $a$ in the sense of $\varepsilon-\delta$ definition. My proof: Let $\{x_k\}\subset A$ be a sequence such that $x_k$ converges to $a$. Then, since $f$ is sequentially continuous on $A$, $\forall \varepsilon >0$, $\exists k_0\in\mathbb{N}$ such that $\|f(x_k)-f(a)\|<\varepsilon$ whenever $k\ge k_0$. Also, $\forall\delta >0$, $\exists k_1\in\mathbb{N}$ such that $\|x_k-a\|<\delta$ whenever $k\ge k_1$. Let $k':=\max\{k_0, k_1\}$, let $k\ge k'$ (we can fix $k$), then $\|x_k-a\|<\delta\implies \|f(x_k)-f(a)\|<\varepsilon$. Hence, $f$ is continuous at $a$ in the $\varepsilon-\delta$ sense. The marker deducted about 67% of the marks and commented that my argument is done for one sequence convergent to $a$ instead of covering all sequences convergent to $a$. However, I don't understand this argument because $x_k$ was taken to be an arbitrary sequence converging to $a$. So what is my mistake then?",,"['real-analysis', 'sequences-and-series', 'proof-verification', 'continuity', 'epsilon-delta']"
76,Numerical evaluation of an infinite sum,Numerical evaluation of an infinite sum,,"I am trying to evaluate numerically : \begin{equation} G = \frac{-1}{4\pi}\sum_{l=0}^{\infty}\frac{2l+1}{\frac{l(l+1)}{R^2}+\frac{1}{L_d^2}}P_l(\cos(\gamma)) \end{equation} Where $P_l$ is the $l_{th}$ Legendre Polynomial, $R = 6371000, Ld = 1000000$ and $\cos(\gamma)\in [-1,1) $. I know that the series converges for any $\cos(\gamma) \neq 1$. I did a very simple code on fortran90 that calculates the sum, but i really dont know how much terms to sum, is there any tolerance or relative errors i can include in my code?","I am trying to evaluate numerically : \begin{equation} G = \frac{-1}{4\pi}\sum_{l=0}^{\infty}\frac{2l+1}{\frac{l(l+1)}{R^2}+\frac{1}{L_d^2}}P_l(\cos(\gamma)) \end{equation} Where $P_l$ is the $l_{th}$ Legendre Polynomial, $R = 6371000, Ld = 1000000$ and $\cos(\gamma)\in [-1,1) $. I know that the series converges for any $\cos(\gamma) \neq 1$. I did a very simple code on fortran90 that calculates the sum, but i really dont know how much terms to sum, is there any tolerance or relative errors i can include in my code?",,"['sequences-and-series', 'numerical-methods', 'summation-method']"
77,Proving the general limit $\lim_{n\to\infty} \frac{an+c}{bn+d} = \frac{a}{b}$,Proving the general limit,\lim_{n\to\infty} \frac{an+c}{bn+d} = \frac{a}{b},"I'm trying to prove the general $$ \lim_{n\to\infty} \frac{an+c}{bn+d} = \frac{a}{b} $$ using the definition of the limit of a sequence, for any $\varepsilon > 0 \,\, \exists N \in \mathbb{N}$ s.t. for every $n \geq N$ $|a_n - a| < \varepsilon$. My (not so valiant) efforts: \begin{align*}  \left| \frac{an+c}{bn+d} - \frac{a}{b} \right| &< \varepsilon \\ \left| \frac{abn + bc - abn - ad}{b^2n+bd} \right| &< \varepsilon \\ \left| \frac{bc-ad}{bn+d} \right| &< \varepsilon \left| b \right| \\ \left| bn+d \right| &> \left| \frac{bc - ad}{\varepsilon b} \right| \\ \left| bn+d \right| &> \left| \frac{c}{\varepsilon} - \frac{ad}{\varepsilon b} \right| \end{align*} I'm used to being able to manipulate constants or remove absolute values when solving these kinds of problems, but with general constants I'm not sure what to do next.","I'm trying to prove the general $$ \lim_{n\to\infty} \frac{an+c}{bn+d} = \frac{a}{b} $$ using the definition of the limit of a sequence, for any $\varepsilon > 0 \,\, \exists N \in \mathbb{N}$ s.t. for every $n \geq N$ $|a_n - a| < \varepsilon$. My (not so valiant) efforts: \begin{align*}  \left| \frac{an+c}{bn+d} - \frac{a}{b} \right| &< \varepsilon \\ \left| \frac{abn + bc - abn - ad}{b^2n+bd} \right| &< \varepsilon \\ \left| \frac{bc-ad}{bn+d} \right| &< \varepsilon \left| b \right| \\ \left| bn+d \right| &> \left| \frac{bc - ad}{\varepsilon b} \right| \\ \left| bn+d \right| &> \left| \frac{c}{\varepsilon} - \frac{ad}{\varepsilon b} \right| \end{align*} I'm used to being able to manipulate constants or remove absolute values when solving these kinds of problems, but with general constants I'm not sure what to do next.",,"['real-analysis', 'sequences-and-series', 'limits']"
78,$\sum_1^\infty{\frac{1}{n(n+1)(n+2)}}$? [duplicate],? [duplicate],\sum_1^\infty{\frac{1}{n(n+1)(n+2)}},This question already has answers here : Find the sum of the series $\sum \frac{1}{n(n+1)(n+2)}$ (10 answers) Closed 7 years ago . How to find the sum of the series $\sum_1^\infty{\frac{1}{n(n+1)(n+2)}}$? I expanded it via partial fractions but it does not look like a telescoping series which I was expecting. Am I missing something obvious or easy manipulation here?,This question already has answers here : Find the sum of the series $\sum \frac{1}{n(n+1)(n+2)}$ (10 answers) Closed 7 years ago . How to find the sum of the series $\sum_1^\infty{\frac{1}{n(n+1)(n+2)}}$? I expanded it via partial fractions but it does not look like a telescoping series which I was expecting. Am I missing something obvious or easy manipulation here?,,['sequences-and-series']
79,"If the average of a sequence converges, does the average of the square roots converge?","If the average of a sequence converges, does the average of the square roots converge?",,"I'm looking for a nice proof or counterexample for the following claim: If $d_i \in [0,1]$ are such that $\lim_{n \to \infty} (d_1+...+d_n)/n$ is well-defined, then $\lim_{n \to \infty} (\sqrt{d_1}+...+\sqrt{d_n})/n$ is well-defined.","I'm looking for a nice proof or counterexample for the following claim: If $d_i \in [0,1]$ are such that $\lim_{n \to \infty} (d_1+...+d_n)/n$ is well-defined, then $\lim_{n \to \infty} (\sqrt{d_1}+...+\sqrt{d_n})/n$ is well-defined.",,"['sequences-and-series', 'limits', 'average']"
80,showing $ 1-\frac{3}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}-\frac{3}{6}+\frac{1}{7}+\frac{1}{8}+\cdots=0 $,showing, 1-\frac{3}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}-\frac{3}{6}+\frac{1}{7}+\frac{1}{8}+\cdots=0 ,"How to show that the following infinite series $$ 1-\frac{3}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}-\frac{3}{6}+\frac{1}{7}+\frac{1}{8}+\cdots=0? $$ The above series is of the form $\sum_{n \ge 1} \frac{f(n)}{n}$, where $f$ is a periodic arithmetical function of period $4$, with the values $f(1)=f(3)=f(4)=1$ and $f(2)=-3$. Since $\sum_{1 \le i \le 4} f(i)=0$, it is assured that this series is convergent.","How to show that the following infinite series $$ 1-\frac{3}{2}+\frac{1}{3}+\frac{1}{4}+\frac{1}{5}-\frac{3}{6}+\frac{1}{7}+\frac{1}{8}+\cdots=0? $$ The above series is of the form $\sum_{n \ge 1} \frac{f(n)}{n}$, where $f$ is a periodic arithmetical function of period $4$, with the values $f(1)=f(3)=f(4)=1$ and $f(2)=-3$. Since $\sum_{1 \le i \le 4} f(i)=0$, it is assured that this series is convergent.",,"['sequences-and-series', 'number-theory', 'elementary-number-theory', 'analytic-number-theory']"
81,Proving the p-series test using the mean value theorem,Proving the p-series test using the mean value theorem,,"So I am tasked with proving the p series test, i.e prove that for $r \in \mathbb{R}$, if $r>1$, then the series: $$\sum_{n=1}^{\infty}\frac{1}{n^r}$$ converges. I was given a hint on the problem, that reads: Hint: To prove convergence, use the Mean Value Theorem on $f(x) = \frac{1}{x^{r1}}$ Doing that I saw that there exists $c\in [n,n+1]$ such that $$\frac{1}{n^{r-1}} - \frac{1}{(n+1)^{r-1}} = \frac{r-1}{c^r}$$ I do not know where to go from here. I attempted a comparison and wasted much time with $\frac{1}{n^2+n}$ but then realized that only works for $r\geq2$. A hint would be appreciated.","So I am tasked with proving the p series test, i.e prove that for $r \in \mathbb{R}$, if $r>1$, then the series: $$\sum_{n=1}^{\infty}\frac{1}{n^r}$$ converges. I was given a hint on the problem, that reads: Hint: To prove convergence, use the Mean Value Theorem on $f(x) = \frac{1}{x^{r1}}$ Doing that I saw that there exists $c\in [n,n+1]$ such that $$\frac{1}{n^{r-1}} - \frac{1}{(n+1)^{r-1}} = \frac{r-1}{c^r}$$ I do not know where to go from here. I attempted a comparison and wasted much time with $\frac{1}{n^2+n}$ but then realized that only works for $r\geq2$. A hint would be appreciated.",,"['real-analysis', 'sequences-and-series', 'functions', 'derivatives']"
82,Reverse lookup: decimal to irrational,Reverse lookup: decimal to irrational,,"Is there an online resource that lists irrationals close to given a decimal? For example, if $x=0.3740049$, a candidate solution would be $x_c = \left ( \frac{1+\sqrt{5}}{2} \right ) ^2 /7$. This would be something akin to the OEIS (Online Encyclopedia of Integer Sequences), which is a reverse lookup for integer sequences and various properties about them. While there are an infinite number of irrationals over any fixed range, a list of ""simple"" (operation depth, low coefficients, etc...) would be very useful.","Is there an online resource that lists irrationals close to given a decimal? For example, if $x=0.3740049$, a candidate solution would be $x_c = \left ( \frac{1+\sqrt{5}}{2} \right ) ^2 /7$. This would be something akin to the OEIS (Online Encyclopedia of Integer Sequences), which is a reverse lookup for integer sequences and various properties about them. While there are an infinite number of irrationals over any fixed range, a list of ""simple"" (operation depth, low coefficients, etc...) would be very useful.",,"['sequences-and-series', 'approximation', 'irrational-numbers', 'integers']"
83,How do I prove that the sum: $1/\ln(n)^p$ diverges for $p>1$,How do I prove that the sum:  diverges for,1/\ln(n)^p p>1,So I need to prove that the infinite sum $\frac{1}{(\ln(n)^p)}$ diverges for all values of $p$ . I managed to prove it for $p\leq 1$ via comparison test with $1/n$ . but for this I can't seem to find a way to prove it diverges for $p>1$ .,So I need to prove that the infinite sum diverges for all values of . I managed to prove it for via comparison test with . but for this I can't seem to find a way to prove it diverges for .,\frac{1}{(\ln(n)^p)} p p\leq 1 1/n p>1,"['calculus', 'sequences-and-series', 'summation']"
84,"Proof, without logs/exp that (1+x/n)^n converges","Proof, without logs/exp that (1+x/n)^n converges",,"was wondering if any of you would be able to help with this question: Prove that $$\left(1 +\frac{x}{n}\right)^{n}$$ converges as n approaches infinity for $x\in\mathbb{R}$ and $n=1,2,3...$ Now, since this question was given before we learnt the proper definition of exponential functions and logarithms, I assume it requires a proof without these functions. I was able to prove the convergence for $x\geq0$ using the binomial expansion and the fact that $$\binom{n+1}{k}\frac{x^{k}}{(n+1)^{k}}>\binom{n}{k}\frac{x^{k}}{n^{k}}$$ for $x\geq0$ (i.e I proved the sequence to be increasing and was bounded above, and hence convergent). However, that inequality is the other way round for $x<0$ and the inequalities I used to prove the sequence to be bounded above also relied on the fact that $x\geq0$. How would I go about proving that the sequence is increasing and bounded above (without logs/exponentials) for $x<0$? Would I have to come up with some new inequalities? Thanks","was wondering if any of you would be able to help with this question: Prove that $$\left(1 +\frac{x}{n}\right)^{n}$$ converges as n approaches infinity for $x\in\mathbb{R}$ and $n=1,2,3...$ Now, since this question was given before we learnt the proper definition of exponential functions and logarithms, I assume it requires a proof without these functions. I was able to prove the convergence for $x\geq0$ using the binomial expansion and the fact that $$\binom{n+1}{k}\frac{x^{k}}{(n+1)^{k}}>\binom{n}{k}\frac{x^{k}}{n^{k}}$$ for $x\geq0$ (i.e I proved the sequence to be increasing and was bounded above, and hence convergent). However, that inequality is the other way round for $x<0$ and the inequalities I used to prove the sequence to be bounded above also relied on the fact that $x\geq0$. How would I go about proving that the sequence is increasing and bounded above (without logs/exponentials) for $x<0$? Would I have to come up with some new inequalities? Thanks",,"['sequences-and-series', 'limits', 'convergence-divergence']"
85,Show that for any $w \in \mathbb{C}$ there exists a sequence $z_n$ s.t. $f(z_n) \rightarrow w$,Show that for any  there exists a sequence  s.t.,w \in \mathbb{C} z_n f(z_n) \rightarrow w,I want to prove the following: Let $f: \mathbb{C} \rightarrow \mathbb{C}$ be holomorphic and non-constant. Then for $w \in \mathbb{C}$ there exists a sequence $(z_n)_{n \in \mathbb{N}} \subset \mathbb{C}$ with $lim_{n\rightarrow w}f(z_n) = w$. Which theorem can I use here? I know that by Liouville $f$ must be unbounded but does that help me? Can someone give me a hint?,I want to prove the following: Let $f: \mathbb{C} \rightarrow \mathbb{C}$ be holomorphic and non-constant. Then for $w \in \mathbb{C}$ there exists a sequence $(z_n)_{n \in \mathbb{N}} \subset \mathbb{C}$ with $lim_{n\rightarrow w}f(z_n) = w$. Which theorem can I use here? I know that by Liouville $f$ must be unbounded but does that help me? Can someone give me a hint?,,"['sequences-and-series', 'complex-analysis', 'holomorphic-functions']"
86,On the limit of $\sin^2 (\pi\sqrt{n^2+n})$,On the limit of,\sin^2 (\pi\sqrt{n^2+n}),What is the limit of the sequence $\sin^2 (\pi\sqrt{n^2+n})$ as $n$ tends to infinity? My Attemp: I replace the square root with $n+\frac 12$ (its equivalent) and the rest is routine: $\lim \sin^2 (\pi\sqrt{n^2+n}) = \lim \sin^2 (\pi n + \frac{\pi}2) = 1$ Is this correct?,What is the limit of the sequence $\sin^2 (\pi\sqrt{n^2+n})$ as $n$ tends to infinity? My Attemp: I replace the square root with $n+\frac 12$ (its equivalent) and the rest is routine: $\lim \sin^2 (\pi\sqrt{n^2+n}) = \lim \sin^2 (\pi n + \frac{\pi}2) = 1$ Is this correct?,,"['calculus', 'sequences-and-series', 'limits', 'convergence-divergence']"
87,Series with Binomial Coefficients,Series with Binomial Coefficients,,"I need to get a closed form for this series $$\sum_{x=0}^{\infty} x {z \choose x} \lambda ^ x \mu^{z-x}$$ I know that that $\sum_{x=0}^{\infty} {z \choose x} \lambda ^ x \mu^{z-x} = (\lambda + \mu)^z$ (formally) and I feel that I am supposed to proceed from here by differentiation, but I do not know how.","I need to get a closed form for this series $$\sum_{x=0}^{\infty} x {z \choose x} \lambda ^ x \mu^{z-x}$$ I know that that $\sum_{x=0}^{\infty} {z \choose x} \lambda ^ x \mu^{z-x} = (\lambda + \mu)^z$ (formally) and I feel that I am supposed to proceed from here by differentiation, but I do not know how.",,"['sequences-and-series', 'summation', 'power-series', 'binomial-coefficients']"
88,Show that $\sum_{k=0}^{n}(-1)^{n+k}{n\choose k}(ak+b)_n=n!a^n$,Show that,\sum_{k=0}^{n}(-1)^{n+k}{n\choose k}(ak+b)_n=n!a^n,How would we go about showing that? $$\sum_{k=0}^{n}(-1)^{n+k}{n\choose k}(ak+b)_n=n!a^n\tag1$$ $(x)_n=x(x+1)(x+2)\cdots(x+n-1)$ $(x)_0=1$ Recall from Binomial theorem $$(x+a)^n=\sum_{k=0}^{n}{n\choose k}x^ka^{n-k}\tag2$$ Setting $a=-1$ $$(x-1)^n=\sum_{k=0}^{n}(-1)^{n-k}{n\choose k}x^k\tag3$$ Maybe differentiates $(3)$ by m times? $$n(x-1)^{n-1}=\sum_{k=0}^{n}(-1)^{n-k}{n\choose k}kx^{k-1}\tag4$$ $$n(n-1)(x-1)^{n-2}=\sum_{k=0}^{n}(-1)^{n-k}{n\choose k}k(k-1)x^{k-2}\tag5$$ an so on...but I can't see how to get to $(1)$,How would we go about showing that? $$\sum_{k=0}^{n}(-1)^{n+k}{n\choose k}(ak+b)_n=n!a^n\tag1$$ $(x)_n=x(x+1)(x+2)\cdots(x+n-1)$ $(x)_0=1$ Recall from Binomial theorem $$(x+a)^n=\sum_{k=0}^{n}{n\choose k}x^ka^{n-k}\tag2$$ Setting $a=-1$ $$(x-1)^n=\sum_{k=0}^{n}(-1)^{n-k}{n\choose k}x^k\tag3$$ Maybe differentiates $(3)$ by m times? $$n(x-1)^{n-1}=\sum_{k=0}^{n}(-1)^{n-k}{n\choose k}kx^{k-1}\tag4$$ $$n(n-1)(x-1)^{n-2}=\sum_{k=0}^{n}(-1)^{n-k}{n\choose k}k(k-1)x^{k-2}\tag5$$ an so on...but I can't see how to get to $(1)$,,"['sequences-and-series', 'binomial-theorem']"
89,Proving that a series diverges,Proving that a series diverges,,Let $(a_n)$ positive sequence where $$\dfrac{n-1}{n} \leq \dfrac{a_{n+1}}{a_n} \leq \dfrac {n}{n+1}$$ Show that $\sum_{n=1}^{\infty} a_n$ diverges. I already found out that  $\sum_{n=1}^{\infty} (-1)^na_n$ is convergent and that $\lim a_n =0$. I'm not sure how to approach this one.,Let $(a_n)$ positive sequence where $$\dfrac{n-1}{n} \leq \dfrac{a_{n+1}}{a_n} \leq \dfrac {n}{n+1}$$ Show that $\sum_{n=1}^{\infty} a_n$ diverges. I already found out that  $\sum_{n=1}^{\infty} (-1)^na_n$ is convergent and that $\lim a_n =0$. I'm not sure how to approach this one.,,"['calculus', 'sequences-and-series']"
90,Convergence of $\sum_{n\geq 0}\frac{(n!)^d}{(d\cdot n)!}$ [duplicate],Convergence of  [duplicate],\sum_{n\geq 0}\frac{(n!)^d}{(d\cdot n)!},"This question already has answers here : How to prove the convergence of $\sum_{n\geq 0}\frac{n!^d}{(dn)!}$ for $d\geq 2$? (3 answers) Closed 7 years ago . In an exam I have been asked to discuss the convergence of a series regarding a parameter $d$. Here's the following : $\sum_{n=0}^\infty \frac{(n!)^d}{(d\cdot n)!}$ The answer is that this series converges for $d \geq 2$. I totally understand that if $d \leq 1$, the series will not converge but I am blocked while trying to use the d'Alembert or Cauchy's rules. Can somebody give me a tip ?","This question already has answers here : How to prove the convergence of $\sum_{n\geq 0}\frac{n!^d}{(dn)!}$ for $d\geq 2$? (3 answers) Closed 7 years ago . In an exam I have been asked to discuss the convergence of a series regarding a parameter $d$. Here's the following : $\sum_{n=0}^\infty \frac{(n!)^d}{(d\cdot n)!}$ The answer is that this series converges for $d \geq 2$. I totally understand that if $d \leq 1$, the series will not converge but I am blocked while trying to use the d'Alembert or Cauchy's rules. Can somebody give me a tip ?",,"['sequences-and-series', 'convergence-divergence', 'factorial']"
91,Why does this process generate the factorial of the exponent? [duplicate],Why does this process generate the factorial of the exponent? [duplicate],,"This question already has an answer here : Property of $\{0^n, 1^n, \ldots\}$ [duplicate] (1 answer) Closed 7 years ago . Consider the process of taking a series of numbers and constructing a new series consisting of the difference between consecutive terms, and repeating this until a constant is reached: $$2,8,18,32,50\\6,10,14,18\\4,4,4$$ When this process is applied to sequences of the form $f(n) = n^a$, the constant reached seems to always be $a!$: $$1,2,3\\1,1$$ $$1,4,9,16\\3,5,7\\2,2\\$$ $$1,8,27,64,125\\7,19,37,61\\12,18,24\\6,6$$ $$1,16,81,256,625,1296\\15,65,175,369,671\\50,110,194,302\\60,84,108\\24,24$$ Can it be proven?","This question already has an answer here : Property of $\{0^n, 1^n, \ldots\}$ [duplicate] (1 answer) Closed 7 years ago . Consider the process of taking a series of numbers and constructing a new series consisting of the difference between consecutive terms, and repeating this until a constant is reached: $$2,8,18,32,50\\6,10,14,18\\4,4,4$$ When this process is applied to sequences of the form $f(n) = n^a$, the constant reached seems to always be $a!$: $$1,2,3\\1,1$$ $$1,4,9,16\\3,5,7\\2,2\\$$ $$1,8,27,64,125\\7,19,37,61\\12,18,24\\6,6$$ $$1,16,81,256,625,1296\\15,65,175,369,671\\50,110,194,302\\60,84,108\\24,24$$ Can it be proven?",,"['sequences-and-series', 'factorial']"
92,Question on a Proof of Rearrangements for Absolutely Converging Double Series,Question on a Proof of Rearrangements for Absolutely Converging Double Series,,"In Appendix B of Jameson's The Prime Number Theorem , the author gives a proof of the assertion that given real numbers $\left\{a_{j,k}\right\}_{j,k\ge 1},$ if $$\sum_{j=1}^\infty \sum_{k=1}^\infty \left|a_{j,k}\right|$$ then for any bijection $\sigma : \mathbb{N} \to \mathbb{N}^2$ we have that the sums  $$\sum_{j=1}^\infty \sum_{k=1}^\infty a_{j,k} = \sum_{k=1}^\infty \sum_{j=1}^\infty a_{j,k}  = \sum_{n=1}^\infty a_{\sigma(n)}$$ all converge and are equal to one another. The proof begins (and this is the part I do not understand) by saying that it suffices to show that the result holds for the case where $a_{j,k} \ge 0$ for all $j,k\ge 1$ because if this is true then the assertion follows for general real valued sequences by writing $$a_{j,k} =  a_{j,k}^+ - a_{j,k}^-$$ where for any real $x$ we denote $$x^+ = \begin{cases}  x & \text{if} & x\ge 0 \\ 0 & \text{otherwise} \end{cases} $$ and $$x^- = \begin{cases}  -x & \text{if} & x < 0 \\ 0 & \text{otherwise.} \end{cases} $$ How does this substitution actually imply that the result holds for general real-valued sequences once we know that it holds for nonnegative sequences? Any explanation on how this argument works would be greatly appreciated.","In Appendix B of Jameson's The Prime Number Theorem , the author gives a proof of the assertion that given real numbers $\left\{a_{j,k}\right\}_{j,k\ge 1},$ if $$\sum_{j=1}^\infty \sum_{k=1}^\infty \left|a_{j,k}\right|$$ then for any bijection $\sigma : \mathbb{N} \to \mathbb{N}^2$ we have that the sums  $$\sum_{j=1}^\infty \sum_{k=1}^\infty a_{j,k} = \sum_{k=1}^\infty \sum_{j=1}^\infty a_{j,k}  = \sum_{n=1}^\infty a_{\sigma(n)}$$ all converge and are equal to one another. The proof begins (and this is the part I do not understand) by saying that it suffices to show that the result holds for the case where $a_{j,k} \ge 0$ for all $j,k\ge 1$ because if this is true then the assertion follows for general real valued sequences by writing $$a_{j,k} =  a_{j,k}^+ - a_{j,k}^-$$ where for any real $x$ we denote $$x^+ = \begin{cases}  x & \text{if} & x\ge 0 \\ 0 & \text{otherwise} \end{cases} $$ and $$x^- = \begin{cases}  -x & \text{if} & x < 0 \\ 0 & \text{otherwise.} \end{cases} $$ How does this substitution actually imply that the result holds for general real-valued sequences once we know that it holds for nonnegative sequences? Any explanation on how this argument works would be greatly appreciated.",,"['sequences-and-series', 'analysis', 'summation', 'absolute-convergence']"
93,$\sum_{n=1}^\infty \frac{1}{\sqrt{n^2+1}}$ Divergent? Did I do this right?,Divergent? Did I do this right?,\sum_{n=1}^\infty \frac{1}{\sqrt{n^2+1}},"$$\sum_{n=1}^\infty \frac{1}{\sqrt{n^2+1}}$$ $$a_n = \frac{1}{\sqrt{n^2+1}} <\frac{1}{\sqrt{n^2}} \le \frac{1}{n},  \forall n\ge1$$ Then by The Comparison Test with $b_n$, where $b_n$ is a divergent p-series  = $\frac{1}{n}$ and $a_n \le b_n$, Then $\sum_{n=1}^\infty \frac{1}{\sqrt{n^2+1}}$ is Divergent.","$$\sum_{n=1}^\infty \frac{1}{\sqrt{n^2+1}}$$ $$a_n = \frac{1}{\sqrt{n^2+1}} <\frac{1}{\sqrt{n^2}} \le \frac{1}{n},  \forall n\ge1$$ Then by The Comparison Test with $b_n$, where $b_n$ is a divergent p-series  = $\frac{1}{n}$ and $a_n \le b_n$, Then $\sum_{n=1}^\infty \frac{1}{\sqrt{n^2+1}}$ is Divergent.",,"['calculus', 'sequences-and-series']"
94,Sum of an infinite series of fractions,Sum of an infinite series of fractions,,"I am taking a fun walk into Number Theory land, and I am conducting an investigation about an infinite sum of fractions. These fractions have to do with the amount of composites within an even number. All the fractions have to do with the reciprocal of a prime. This is my sum: $\frac{1}{3} + \frac{1}{5} - (\frac{1}{3}*\frac{1}{5}) + \frac{1}{7}-(\frac{1}{3} * \frac{1}{7} + \frac{1}{5}*\frac{1}{7}) + \frac{1}{11} - (\frac{1}{3}*\frac{1}{11} + \frac{1}{5} * \frac{1}{11} + \frac{1}{7} * \frac{1}{11}) + ...  $ I don't quite know how to simplify the sequence, or even whether it is convergent or divergent. Each term $ a_n $ in the series involves the next largest prime. $ a_n = \frac{1}{p_n} - (\frac{1}{p_{n-1}}*\frac{1}{p_n} + \frac{1}{p_{n-2}}*\frac{1}{p_n} + \ \   ...)$ Therefore, $\frac{1}{7}-(\frac{1}{3} * \frac{1}{7} + \frac{1}{5}*\frac{1}{7})$ is a single term, where 7 would be $p$ and 5 would be $p_{n-1}$ and 3 would be $p_{n-2}$. EDIT: I have been having trouble understanding some of the answers (I understand the math, just not the answer). The basis for the problem was the following: if 1/3 of all positive integers are divisible by 3, and 1/5 of all positive integers are divisible by 5, and there is an overlap here of 1/15, ($\frac{1}{3} * \frac{1}{5}$), then $\frac{1}{3} + \frac{1}{5} - \frac{1}{15}$ represents all numbers that are divisible by either 3 or 5. I expanded this to include all prime  numbers in my series, and was hoping that someone would show that the series would converge to 1, allowing me to continue on my way with a new piece of knowledge. The proofs below show that this sum goes to negative infinity--that is, the amount of composite numbers expressed as some number between 0 and 1 goes to negative infinity. How is this possible? (please provide an explanation in your answer or update it) Maybe I have made some sort of logical or conceptual mistake that needs to be addressed, or maybe there is actually a good way of interpreting this answer. Thanks!","I am taking a fun walk into Number Theory land, and I am conducting an investigation about an infinite sum of fractions. These fractions have to do with the amount of composites within an even number. All the fractions have to do with the reciprocal of a prime. This is my sum: $\frac{1}{3} + \frac{1}{5} - (\frac{1}{3}*\frac{1}{5}) + \frac{1}{7}-(\frac{1}{3} * \frac{1}{7} + \frac{1}{5}*\frac{1}{7}) + \frac{1}{11} - (\frac{1}{3}*\frac{1}{11} + \frac{1}{5} * \frac{1}{11} + \frac{1}{7} * \frac{1}{11}) + ...  $ I don't quite know how to simplify the sequence, or even whether it is convergent or divergent. Each term $ a_n $ in the series involves the next largest prime. $ a_n = \frac{1}{p_n} - (\frac{1}{p_{n-1}}*\frac{1}{p_n} + \frac{1}{p_{n-2}}*\frac{1}{p_n} + \ \   ...)$ Therefore, $\frac{1}{7}-(\frac{1}{3} * \frac{1}{7} + \frac{1}{5}*\frac{1}{7})$ is a single term, where 7 would be $p$ and 5 would be $p_{n-1}$ and 3 would be $p_{n-2}$. EDIT: I have been having trouble understanding some of the answers (I understand the math, just not the answer). The basis for the problem was the following: if 1/3 of all positive integers are divisible by 3, and 1/5 of all positive integers are divisible by 5, and there is an overlap here of 1/15, ($\frac{1}{3} * \frac{1}{5}$), then $\frac{1}{3} + \frac{1}{5} - \frac{1}{15}$ represents all numbers that are divisible by either 3 or 5. I expanded this to include all prime  numbers in my series, and was hoping that someone would show that the series would converge to 1, allowing me to continue on my way with a new piece of knowledge. The proofs below show that this sum goes to negative infinity--that is, the amount of composite numbers expressed as some number between 0 and 1 goes to negative infinity. How is this possible? (please provide an explanation in your answer or update it) Maybe I have made some sort of logical or conceptual mistake that needs to be addressed, or maybe there is actually a good way of interpreting this answer. Thanks!",,"['sequences-and-series', 'number-theory']"
95,"If $\sum_{n=1}^\infty a_n$ converges to $A$, then ${1 \over 2}(a_1 + a_2) + {1 \over 2}(a_2 + a_3) + \cdots$ converges","If  converges to , then  converges",\sum_{n=1}^\infty a_n A {1 \over 2}(a_1 + a_2) + {1 \over 2}(a_2 + a_3) + \cdots,"I need to prove If $a_1 + a_2 + a_3 + \cdots$ converges to $A$, then ${1\over2}(a_1 +a_2) + {1\over2}(a_2 + a_3) + {1\over2}(a_3+a_4) + \cdots$ converges. Find what the latter series converges to. PROOF : Given that $\displaystyle \sum_{n=1}^\infty a_n$ converges to $A$, then the sequence of partial sums of the series, $\{s_n\}$, converges to $A$, where $\displaystyle s_n = \sum_{k=1}^na_k$. That is, $$\lim_{n\to\infty}s_n = A.$$ Now, for the $2^{nd}$ series, observe that we may describe its sequence of partial sums as $\{t_n\}$, where $\displaystyle t_n =  {1\over2}\sum_{k=1}^n\left(a_k + a_{k+1}\right)$. Then $$\begin{align}\lim_{n\to\infty}t_n &= \lim_{n\to\infty}\left({1\over2}\sum_{k=1}^n(a_k + a_{k+1})\right) \\ &= {1\over2}\lim_{n\to\infty}\left(\sum_{k=1}^na_k + \sum_{k=1}^na_{k+1}\right) \tag{$*$}\\ &= {1\over2}\lim_{n\to\infty}\sum_{k=1}^na_k + {1\over2}\lim_{n\to\infty}\sum_{k=1}^na_{k+1}\\&= {1\over2}\lim_{n\to\infty}s_n + {1\over2}\lim_{n\to\infty}s_{n+1} \tag{$\bf{\star}$}\\ &= {1\over2}A + {1\over2}A \\&= A.\end{align}$$ Thus, the sequence of partial sums, $\{t_n\}$, converges and hence the series ${1\over2}(a_1 +a_2) + {1\over2}(a_2 + a_3) + {1\over2}(a_3+a_4) + \cdots$ converges to $A$. $\square$ QUESTION: I may split the sequence of partial sums at $(*)$ up because it is a finite sum, correct? If it were an infinite series, then I don't think it would be valid since we don't necessarily know that it converges to begin with (which is what we're trying to show). Also, is it correct to write $\lim_{n\to\infty}s_{n+1}$ at $(\star)$? Or is it supposed to be $\lim_{n\to\infty}s_n$?","I need to prove If $a_1 + a_2 + a_3 + \cdots$ converges to $A$, then ${1\over2}(a_1 +a_2) + {1\over2}(a_2 + a_3) + {1\over2}(a_3+a_4) + \cdots$ converges. Find what the latter series converges to. PROOF : Given that $\displaystyle \sum_{n=1}^\infty a_n$ converges to $A$, then the sequence of partial sums of the series, $\{s_n\}$, converges to $A$, where $\displaystyle s_n = \sum_{k=1}^na_k$. That is, $$\lim_{n\to\infty}s_n = A.$$ Now, for the $2^{nd}$ series, observe that we may describe its sequence of partial sums as $\{t_n\}$, where $\displaystyle t_n =  {1\over2}\sum_{k=1}^n\left(a_k + a_{k+1}\right)$. Then $$\begin{align}\lim_{n\to\infty}t_n &= \lim_{n\to\infty}\left({1\over2}\sum_{k=1}^n(a_k + a_{k+1})\right) \\ &= {1\over2}\lim_{n\to\infty}\left(\sum_{k=1}^na_k + \sum_{k=1}^na_{k+1}\right) \tag{$*$}\\ &= {1\over2}\lim_{n\to\infty}\sum_{k=1}^na_k + {1\over2}\lim_{n\to\infty}\sum_{k=1}^na_{k+1}\\&= {1\over2}\lim_{n\to\infty}s_n + {1\over2}\lim_{n\to\infty}s_{n+1} \tag{$\bf{\star}$}\\ &= {1\over2}A + {1\over2}A \\&= A.\end{align}$$ Thus, the sequence of partial sums, $\{t_n\}$, converges and hence the series ${1\over2}(a_1 +a_2) + {1\over2}(a_2 + a_3) + {1\over2}(a_3+a_4) + \cdots$ converges to $A$. $\square$ QUESTION: I may split the sequence of partial sums at $(*)$ up because it is a finite sum, correct? If it were an infinite series, then I don't think it would be valid since we don't necessarily know that it converges to begin with (which is what we're trying to show). Also, is it correct to write $\lim_{n\to\infty}s_{n+1}$ at $(\star)$? Or is it supposed to be $\lim_{n\to\infty}s_n$?",,"['calculus', 'real-analysis', 'sequences-and-series', 'proof-verification', 'convergence-divergence']"
96,"If $a_{n+2} = \frac{1}{3}\left(a_{n+1}+\frac{1}{a_{n}}\right)$, then $\lim_{n\to\infty}a_{n} = ?$","If , then",a_{n+2} = \frac{1}{3}\left(a_{n+1}+\frac{1}{a_{n}}\right) \lim_{n\to\infty}a_{n} = ?,"If $\displaystyle a_{n+2} = \frac{1}{3}\left(a_{n+1}+\frac{1}{a_{n}}\right),a_{n}>0$, then $\lim_{n\rightarrow \infty}a_{n} = ?$ My try: It seems that when $n \rightarrow \infty$ then we can write $a_{n}=a_{n+1}=a_{n+2} = l$ (finite number), but I did not understand how I can prove that the sequence is strictly increasing. Help required. Thanks.","If $\displaystyle a_{n+2} = \frac{1}{3}\left(a_{n+1}+\frac{1}{a_{n}}\right),a_{n}>0$, then $\lim_{n\rightarrow \infty}a_{n} = ?$ My try: It seems that when $n \rightarrow \infty$ then we can write $a_{n}=a_{n+1}=a_{n+2} = l$ (finite number), but I did not understand how I can prove that the sequence is strictly increasing. Help required. Thanks.",,"['sequences-and-series', 'limits']"
97,How to prove this Harmonic numbers identity?,How to prove this Harmonic numbers identity?,,"While answering a question involving Harmonic numbers $H_n$, I wanted to simplify the terms  $$f_n = \sum_{i=0}^{n-1}{H_i}^2 - \frac{1}{n}\sum_{0\le i,j\le n-1}H_i H_j. $$ To do so, I used SageMath to compute $f_n$ for $1\le n \le 100$ and then found the numerators of the resulting sequence to be OEIS sequence A187487 ; i.e., the $n$th numerator is the numerator of $n-H_n$. Indeed, all cases computed are consistent with the following being an identity for $n\ge 1$: $$\sum_{i=0}^{n-1}{H_i}^2 - \frac{1}{n}\sum_{i=0}^{n-1}\sum_{j=0}^{n-1}H_i H_j = n - H_n $$ which is the same as  $$\sum_{i=0}^{n-1}{H_i}^2 - \frac{1}{n}\left(\sum_{i=0}^{n-1}H_i\right)^2 = n - H_n. $$ Does anyone have an idea of how to prove this? Or a reference?","While answering a question involving Harmonic numbers $H_n$, I wanted to simplify the terms  $$f_n = \sum_{i=0}^{n-1}{H_i}^2 - \frac{1}{n}\sum_{0\le i,j\le n-1}H_i H_j. $$ To do so, I used SageMath to compute $f_n$ for $1\le n \le 100$ and then found the numerators of the resulting sequence to be OEIS sequence A187487 ; i.e., the $n$th numerator is the numerator of $n-H_n$. Indeed, all cases computed are consistent with the following being an identity for $n\ge 1$: $$\sum_{i=0}^{n-1}{H_i}^2 - \frac{1}{n}\sum_{i=0}^{n-1}\sum_{j=0}^{n-1}H_i H_j = n - H_n $$ which is the same as  $$\sum_{i=0}^{n-1}{H_i}^2 - \frac{1}{n}\left(\sum_{i=0}^{n-1}H_i\right)^2 = n - H_n. $$ Does anyone have an idea of how to prove this? Or a reference?",,"['sequences-and-series', 'harmonic-numbers']"
98,Divergence at the endpoints of the interval of convergence for $\sum_{k=0}^{\infty}\frac{k!}{k^k}x^k$,Divergence at the endpoints of the interval of convergence for,\sum_{k=0}^{\infty}\frac{k!}{k^k}x^k,"It is easy enough to see from the ratio test that the radius of the series is $e$, but I struggled to show divergence of the series at $\pm e$. I am wondering in particular if there is a way using the series definition of $e$. Also I did not expect this sequence to diverge to infinity so any intuition for why $e^kk!$ beats $k^k$ so handily is welcome. My way: $$ L=\lim_{k\rightarrow \infty}\frac{k!}{k^k}e^k\Rightarrow \log(L)=\lim_{k\rightarrow \infty}k+\log(k!)-k\log(k) $$ And then using stirling's, $k!=O(e^{-k}k^{k}\sqrt{k})$, $$ \log(L)=\lim_{k\rightarrow \infty}k+\log(e^{-k}k^{k}\sqrt{k})-k\log(k)\\ =\lim_{k\rightarrow \infty}k-k+k\log(k)+\frac{1}{2}\log(k)-k\log(k)=\lim_{k\rightarrow \infty}\frac{1}{2}\log(k)=\infty $$","It is easy enough to see from the ratio test that the radius of the series is $e$, but I struggled to show divergence of the series at $\pm e$. I am wondering in particular if there is a way using the series definition of $e$. Also I did not expect this sequence to diverge to infinity so any intuition for why $e^kk!$ beats $k^k$ so handily is welcome. My way: $$ L=\lim_{k\rightarrow \infty}\frac{k!}{k^k}e^k\Rightarrow \log(L)=\lim_{k\rightarrow \infty}k+\log(k!)-k\log(k) $$ And then using stirling's, $k!=O(e^{-k}k^{k}\sqrt{k})$, $$ \log(L)=\lim_{k\rightarrow \infty}k+\log(e^{-k}k^{k}\sqrt{k})-k\log(k)\\ =\lim_{k\rightarrow \infty}k-k+k\log(k)+\frac{1}{2}\log(k)-k\log(k)=\lim_{k\rightarrow \infty}\frac{1}{2}\log(k)=\infty $$",,"['calculus', 'real-analysis', 'sequences-and-series', 'power-series']"
99,Proving a sequence is in $\ell^{p'}$ - Brezis' Exercise 2.7,Proving a sequence is in  - Brezis' Exercise 2.7,\ell^{p'},"I am self-studying Brezis' functional analysis, and here is an exercise in it: Exercise 2.7 Let $a=(a_n)$ be a given sequence sequence of real numbers and let $1\leq p\leq\infty$. Assume that    $$\sum |a_n x_n|<\infty$$   for every $x=(x_n)\in \ell^p$. Prove that $a\in\ell^{p'}$, where $\frac{1}{p}+\frac{1}{p'}=1$. My attempt (basically following the book's hint): Write $E=\ell^{p}$. Define $$T_nx:=\sum_{i=1}^n a_ix_i$$    for all $n\in \mathbb{N}$. Note that $T_n\in E^\star$. Since $\sum |a_n x_n|<\infty$, $T_nx$ tends to a limit $Tx\in\mathbb{R}$ as $n\rightarrow\infty$. By uniform boundedness principle, we have   $$|T_nx|\leq C\lVert x\rVert_{\mathscr{l}^p}$$   for some $C>0$. I stopped here. It seems that I need to take specific $x$ to derive desired conclusion, but I only have a little experience with sequence spaces. Could anyone offer a further hint for me?","I am self-studying Brezis' functional analysis, and here is an exercise in it: Exercise 2.7 Let $a=(a_n)$ be a given sequence sequence of real numbers and let $1\leq p\leq\infty$. Assume that    $$\sum |a_n x_n|<\infty$$   for every $x=(x_n)\in \ell^p$. Prove that $a\in\ell^{p'}$, where $\frac{1}{p}+\frac{1}{p'}=1$. My attempt (basically following the book's hint): Write $E=\ell^{p}$. Define $$T_nx:=\sum_{i=1}^n a_ix_i$$    for all $n\in \mathbb{N}$. Note that $T_n\in E^\star$. Since $\sum |a_n x_n|<\infty$, $T_nx$ tends to a limit $Tx\in\mathbb{R}$ as $n\rightarrow\infty$. By uniform boundedness principle, we have   $$|T_nx|\leq C\lVert x\rVert_{\mathscr{l}^p}$$   for some $C>0$. I stopped here. It seems that I need to take specific $x$ to derive desired conclusion, but I only have a little experience with sequence spaces. Could anyone offer a further hint for me?",,"['sequences-and-series', 'functional-analysis', 'analysis']"
