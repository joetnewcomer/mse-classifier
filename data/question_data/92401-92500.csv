,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,To prove this complex polynomial has all zeros on unit circle,To prove this complex polynomial has all zeros on unit circle,,"I'm trying to prove a self-inversive polynomial $P(z) = \sum\limits_{n=0}^{N-1}a_nz^n$ has all its roots on the unit circle. The coefficients are such that $ a_n = e^{j(n-\frac{N-1}{2})\pi u_0} - \beta e^{j(n-\frac{N-1}{2})\pi u_1}$ and $0 \leq n \leq N - 1$ These coefficients satisfy $a_n = a^*_{N-1-n}$ i.e. $P(z)$ is self-inversive. The necessary and sufficient condition for a self-inversive polynomial to have all roots on the unit circle is that $P'(z)$ has all its roots in $|z| \leq 1$. I considered Eneström–Kakeya theorem to show $P'(z)$ has all its roots inside unit circle, but the theorem extended for complex polynomial doesn't seem to be valid for the above polynomial. I'm unable to make headway in trying to prove $P(z)$ has all roots on unit circle although numerical experiments show the roots are on unit circle and infact roots of $P'(z)$ are inside the unit disk. Please provide me with any suggestions on how to approach the proof.  Thanks","I'm trying to prove a self-inversive polynomial $P(z) = \sum\limits_{n=0}^{N-1}a_nz^n$ has all its roots on the unit circle. The coefficients are such that $ a_n = e^{j(n-\frac{N-1}{2})\pi u_0} - \beta e^{j(n-\frac{N-1}{2})\pi u_1}$ and $0 \leq n \leq N - 1$ These coefficients satisfy $a_n = a^*_{N-1-n}$ i.e. $P(z)$ is self-inversive. The necessary and sufficient condition for a self-inversive polynomial to have all roots on the unit circle is that $P'(z)$ has all its roots in $|z| \leq 1$. I considered Eneström–Kakeya theorem to show $P'(z)$ has all its roots inside unit circle, but the theorem extended for complex polynomial doesn't seem to be valid for the above polynomial. I'm unable to make headway in trying to prove $P(z)$ has all roots on unit circle although numerical experiments show the roots are on unit circle and infact roots of $P'(z)$ are inside the unit disk. Please provide me with any suggestions on how to approach the proof.  Thanks",,"['complex-analysis', 'polynomials', 'roots']"
1,"Book on Complex Analysis, geometrical approach...","Book on Complex Analysis, geometrical approach...",,"I have already taken a course on Complex Variable. The course focused mainly on the analytical approach of the subject (power series, etc). Now, I want to study a more geometric view of the subject, specially regarding the work of the functions on the Riemann Sphere, and all the formalities behind that approach. I've been searching for a book in this line, but haven't found many good recomendations. Any recomendations on what books or what material may be helpful? I'm trying to get into complex dynamics through Milnor's book, and I wanted to get more familiarity on working with the Riemann Sphere...","I have already taken a course on Complex Variable. The course focused mainly on the analytical approach of the subject (power series, etc). Now, I want to study a more geometric view of the subject, specially regarding the work of the functions on the Riemann Sphere, and all the formalities behind that approach. I've been searching for a book in this line, but haven't found many good recomendations. Any recomendations on what books or what material may be helpful? I'm trying to get into complex dynamics through Milnor's book, and I wanted to get more familiarity on working with the Riemann Sphere...",,['complex-analysis']
2,Meromorphic function tending to infinity cannot have poles at all integer points,Meromorphic function tending to infinity cannot have poles at all integer points,,"Let $f$ be a meromorphic function on $\mathbb{C}$ for which $|f(z)|\to\infty$ as $|z|\to\infty$. Show that $f$ cannot have poles at all integer points. I know that we can construct a homeomorphism from the extended complex plane $\mathbb{C} \cup \infty$ to the sphere $S^2$ by stereographic projection, and further that the sphere is compact. So, if a meromorphic function has infinitely many disjoint poles (i.e at the integers), perhaps we can construct a cover without a finite subcover. I am however getting confused as to the details, in particular where $\infty$ comes in. Many thanks for you help.","Let $f$ be a meromorphic function on $\mathbb{C}$ for which $|f(z)|\to\infty$ as $|z|\to\infty$. Show that $f$ cannot have poles at all integer points. I know that we can construct a homeomorphism from the extended complex plane $\mathbb{C} \cup \infty$ to the sphere $S^2$ by stereographic projection, and further that the sphere is compact. So, if a meromorphic function has infinitely many disjoint poles (i.e at the integers), perhaps we can construct a cover without a finite subcover. I am however getting confused as to the details, in particular where $\infty$ comes in. Many thanks for you help.",,[]
3,"How can I find all analytic functions $ f = u + iv $ with $ u(x,y) = x^{2} - y^{2} $",How can I find all analytic functions  with," f = u + iv   u(x,y) = x^{2} - y^{2} ","This homework problem is giving me some trouble. My current thought process is this: In order for $ f = u + iv $ to be analytic, it must differentiable. Therefore, it must satisfy the Cauchy-Riemann equation, $ f_{y} = if_{x} $ , and $ f_{x} \text{ and } f_{y} $ must be continuous. The Cauchy-Riemann equation is equivalent to: $$ u_{x} = v_{y},\\ u_{y} = -v_{x} $$ Because the function must be analytic, they must be differentiable on open neighborhoods of $ z = x + iy $ as well as at z. Because of this fact, I tried doing this: $$ u_{x} = v_{y} \implies v_{y} = 2x \implies v = 2xy + h(x)\\    u_{y} = -v_{x} \implies v_{x} = 2y  \implies v = 2xy + g(y) $$ These two lines imply that $ h(x) = g(y) = constant $, so $ v = 2xy + c $. Thus, functions of the form $ f = x^{2} - y^{2} + i(2xy + c) $ should be analytic. I have two problems. The first problem is that I'm not confident my derivation of v is sound mathematics. Secondly, even if the equation I derived is analytic, how can be certain only equations of this form are analytic? Thanks for the help. I appreciate it.","This homework problem is giving me some trouble. My current thought process is this: In order for $ f = u + iv $ to be analytic, it must differentiable. Therefore, it must satisfy the Cauchy-Riemann equation, $ f_{y} = if_{x} $ , and $ f_{x} \text{ and } f_{y} $ must be continuous. The Cauchy-Riemann equation is equivalent to: $$ u_{x} = v_{y},\\ u_{y} = -v_{x} $$ Because the function must be analytic, they must be differentiable on open neighborhoods of $ z = x + iy $ as well as at z. Because of this fact, I tried doing this: $$ u_{x} = v_{y} \implies v_{y} = 2x \implies v = 2xy + h(x)\\    u_{y} = -v_{x} \implies v_{x} = 2y  \implies v = 2xy + g(y) $$ These two lines imply that $ h(x) = g(y) = constant $, so $ v = 2xy + c $. Thus, functions of the form $ f = x^{2} - y^{2} + i(2xy + c) $ should be analytic. I have two problems. The first problem is that I'm not confident my derivation of v is sound mathematics. Secondly, even if the equation I derived is analytic, how can be certain only equations of this form are analytic? Thanks for the help. I appreciate it.",,['complex-analysis']
4,Proving $f$ is a constant function,Proving  is a constant function,f,Let $f$ be a $2\pi$ periodic entire function satisfying $|f(z)|\leq 1+|{\rm Im}\; z|$. I am trying to show $f$ is constant. Initially I thought it is very easy that I can apply  Louiville's Theorem. But I realized proving $f$ is bounded is not straight forward. This has to do something with that period of the function. I do not see what I can do with that.,Let $f$ be a $2\pi$ periodic entire function satisfying $|f(z)|\leq 1+|{\rm Im}\; z|$. I am trying to show $f$ is constant. Initially I thought it is very easy that I can apply  Louiville's Theorem. But I realized proving $f$ is bounded is not straight forward. This has to do something with that period of the function. I do not see what I can do with that.,,['complex-analysis']
5,Show that an entire function bounded by $|z|^{10/3}$ is cubic,Show that an entire function bounded by  is cubic,|z|^{10/3},"Question: Let $f$ be an entire function such that $|f(z)|\leq1+2|z|^{10/3}$ for all z. Prove that $f$ is a cubic polynomial Thoughts so far: Using a corollary of Liouville's theorem, we know that we want to show that $|f(z)|\leq a+b|z|^3$ and $|f(z)|\geq a+b|z|^3$ for some constants a and b. We know that within the unit circle $|f(z)|\leq 1+2|z|^{10/3} < 1+2|z|^3$ which gives us an upper bound, while outside of the unit circle we know that $-|f(z)|\geq -1-2|z|^{10/3} \implies |f(x)| \geq |-1-2|z|^{10/3}| = |2|z|^{10/3}--1|$ (by triangle inequality) $\geq 2|z|^{10/3}-1 > 2|z|^3-1$, which provides an lower bound of three, which by the corollary of Liouville's theorem implies that f(z) must be cubic. However, this proof makes me quesy because I feel that the upper and lower limits were chosen arbitrarily and could be any such function with a power less than $\frac{10}{3}%$, which makes me feel rather frustrated. Furthermore, this also leads me to believe that this is not a constructive line of thought for this problem. Thank you in advance for any help that you may provide.","Question: Let $f$ be an entire function such that $|f(z)|\leq1+2|z|^{10/3}$ for all z. Prove that $f$ is a cubic polynomial Thoughts so far: Using a corollary of Liouville's theorem, we know that we want to show that $|f(z)|\leq a+b|z|^3$ and $|f(z)|\geq a+b|z|^3$ for some constants a and b. We know that within the unit circle $|f(z)|\leq 1+2|z|^{10/3} < 1+2|z|^3$ which gives us an upper bound, while outside of the unit circle we know that $-|f(z)|\geq -1-2|z|^{10/3} \implies |f(x)| \geq |-1-2|z|^{10/3}| = |2|z|^{10/3}--1|$ (by triangle inequality) $\geq 2|z|^{10/3}-1 > 2|z|^3-1$, which provides an lower bound of three, which by the corollary of Liouville's theorem implies that f(z) must be cubic. However, this proof makes me quesy because I feel that the upper and lower limits were chosen arbitrarily and could be any such function with a power less than $\frac{10}{3}%$, which makes me feel rather frustrated. Furthermore, this also leads me to believe that this is not a constructive line of thought for this problem. Thank you in advance for any help that you may provide.",,['complex-analysis']
6,Conformal parametrization of an ellipse,Conformal parametrization of an ellipse,,"I am looking to a formula for the conformal map from the unit disc in the interior of an ellipse centered in $0$ and with semiaxes $a,b>0$. I know that depends on elliptic function, but I didn't find any references. Thanks in advance for any formula or reference.","I am looking to a formula for the conformal map from the unit disc in the interior of an ellipse centered in $0$ and with semiaxes $a,b>0$. I know that depends on elliptic function, but I didn't find any references. Thanks in advance for any formula or reference.",,"['complex-analysis', 'reference-request']"
7,"$f, g$ entire functions with $f^2 + g^2 \equiv 1 \implies \exists h $ entire with $f(z) = \cos(h(z))$ and $g(z) = \sin(h(z))$",entire functions with  entire with  and,"f, g f^2 + g^2 \equiv 1 \implies \exists h  f(z) = \cos(h(z)) g(z) = \sin(h(z))","I am studying for a qualifier exam in complex analysis and right now I'm solving questions from old exams. I am trying to prove the following: Prove that if $f$ and $g$ are entire functions such that $f(z)^2 + g(z)^2 = 1$ for all $z \in \mathbb{C}$, then there exists an entire function $h$ such that $f(z) = \cos(h(z))$ and $g(z) = \sin(h(z))$. My Attempt The approach that occurred to me is the following. Since $f(z)^2 + g(z)^2 = 1$ then we have $(f(z) + ig(z))(f(z) - ig(z)) =  1$. Then each factor is nonvanishing everywhere in $\mathbb{C}$ and thus by the ""holomorphic logarithm theorem"" we know that since $\mathbb{C}$ is simply connected, there exists a holomorphic function $H:\mathbb{C} \to \mathbb{C}$ such that $$e^{H(z)} = f(z) + ig(z)$$ and then we can write $\exp(H(z)) = \exp\left(i\dfrac{H(z)}{i} \right) = \exp(ih(z))$, where  $h(z) := \dfrac{H(z)}{i}$. Thus so far we have an entire function $h(z)$ that satisfies $$e^{ih(z)} = f(z) + ig(z)$$ On the other hand, we also know that $e^{iz} = \cos{z} + i \sin{z}$ for any $z \in \mathbb{C}$, thus we see that $$e^{ih(z)} = \cos{(h(z))} + i \sin{(h(z))} = f(z) + ig(z)$$ Thus at this point I would like to conclude somehow that we must have $f(z) = \cos(h(z))$ and $g(z) = \sin(h(z))$, but I can't see how and if this is possible. My questions Is the approach I have outlined a correct way to proceed, and if so how can I finish my argument? If my argument does not work, how can this be proved? Thanks for any help.","I am studying for a qualifier exam in complex analysis and right now I'm solving questions from old exams. I am trying to prove the following: Prove that if $f$ and $g$ are entire functions such that $f(z)^2 + g(z)^2 = 1$ for all $z \in \mathbb{C}$, then there exists an entire function $h$ such that $f(z) = \cos(h(z))$ and $g(z) = \sin(h(z))$. My Attempt The approach that occurred to me is the following. Since $f(z)^2 + g(z)^2 = 1$ then we have $(f(z) + ig(z))(f(z) - ig(z)) =  1$. Then each factor is nonvanishing everywhere in $\mathbb{C}$ and thus by the ""holomorphic logarithm theorem"" we know that since $\mathbb{C}$ is simply connected, there exists a holomorphic function $H:\mathbb{C} \to \mathbb{C}$ such that $$e^{H(z)} = f(z) + ig(z)$$ and then we can write $\exp(H(z)) = \exp\left(i\dfrac{H(z)}{i} \right) = \exp(ih(z))$, where  $h(z) := \dfrac{H(z)}{i}$. Thus so far we have an entire function $h(z)$ that satisfies $$e^{ih(z)} = f(z) + ig(z)$$ On the other hand, we also know that $e^{iz} = \cos{z} + i \sin{z}$ for any $z \in \mathbb{C}$, thus we see that $$e^{ih(z)} = \cos{(h(z))} + i \sin{(h(z))} = f(z) + ig(z)$$ Thus at this point I would like to conclude somehow that we must have $f(z) = \cos(h(z))$ and $g(z) = \sin(h(z))$, but I can't see how and if this is possible. My questions Is the approach I have outlined a correct way to proceed, and if so how can I finish my argument? If my argument does not work, how can this be proved? Thanks for any help.",,['complex-analysis']
8,Precise definition of conformal structure based on a Riemannian metric on a Riemann surface,Precise definition of conformal structure based on a Riemannian metric on a Riemann surface,,"As I read the literature, I keep having some doubt about what a "" conformal structure on a Riemann surface "" exactly means. ( You can assume all the Riemann surface in this literature have universal cover $ \mathbb{D} $ ) .In some literature, it says a conformal structure is the same as a complex structure, which is okay with me. But sometime, after talking to people I get the impression that a putting conformal structure and putting a complex structure on a 2 dimensional smooth manifold $X$ are equivalent, but still not exactly the same. I get the idea : two 'conformally equivalent' Riemannnnian metrics determine the same angle, so a conformal structure should uniquely determine the angle between curves, which is done by a complex structure / Riemann surface structure. But then what exactly is / are the definition of a  "" conformal structure "" ?? And, what is conformal metric then ? Is it an equivalence class of conformally equivalent metrics so that any metric in that class is called conformal metric ? Also, according to the definition in your answers, what is / are the meaning of "" conformal structure based on a conformal metric ? "" If you want a reference to the literature I am taking this from, then please look at page 335 of Lipman Ber's paper  "" Quasiconformal Maps and Teichmüller's Theorems "", the last paragraph, where he says : "" we define a new conformal structure based on the conformal metric $ g = | dz + \mu(z) \; d\bar{z}  |  $. It is clear to me, however, that $g$ is conformal to the locally Euclidean metric $ | dz| $ by the quasiconformal homeomorphism $w$ with the ( local ) Beltrami coefficient $ \mu $","As I read the literature, I keep having some doubt about what a "" conformal structure on a Riemann surface "" exactly means. ( You can assume all the Riemann surface in this literature have universal cover $ \mathbb{D} $ ) .In some literature, it says a conformal structure is the same as a complex structure, which is okay with me. But sometime, after talking to people I get the impression that a putting conformal structure and putting a complex structure on a 2 dimensional smooth manifold $X$ are equivalent, but still not exactly the same. I get the idea : two 'conformally equivalent' Riemannnnian metrics determine the same angle, so a conformal structure should uniquely determine the angle between curves, which is done by a complex structure / Riemann surface structure. But then what exactly is / are the definition of a  "" conformal structure "" ?? And, what is conformal metric then ? Is it an equivalence class of conformally equivalent metrics so that any metric in that class is called conformal metric ? Also, according to the definition in your answers, what is / are the meaning of "" conformal structure based on a conformal metric ? "" If you want a reference to the literature I am taking this from, then please look at page 335 of Lipman Ber's paper  "" Quasiconformal Maps and Teichmüller's Theorems "", the last paragraph, where he says : "" we define a new conformal structure based on the conformal metric $ g = | dz + \mu(z) \; d\bar{z}  |  $. It is clear to me, however, that $g$ is conformal to the locally Euclidean metric $ | dz| $ by the quasiconformal homeomorphism $w$ with the ( local ) Beltrami coefficient $ \mu $",,"['complex-analysis', 'riemannian-geometry', 'riemann-surfaces', 'conformal-geometry', 'quasiconformal-maps']"
9,Variations on the Stirling's formula for $\Gamma(z)$,Variations on the Stirling's formula for,\Gamma(z),"I am currently reading some material that makes heavy usage of Hypergeometric functions, and there is one particular point about applying Stirling's approximation to various terms consisting of Gamma-Functions that is not very clear to me. We have the classical Stirling's approximation formula for the Gamma-Function in the form: $$   \Gamma(z)=\sqrt{2\pi}e^{-z}z^{z-1/2}\left(1+O\left(\frac{1}{|z|}\right)\right) $$ for $|\arg(z)|<\pi$ as $|z|\to\infty$. In absolute value: $$   |\Gamma(z)|=\sqrt{2\pi}e^{-\Re(z)}|z|^{\Re(z)-1/2}e^{-\Im(z)\arg(z)}\left(1+O\left(\frac{1}{|z|}\right)\right) $$ Now, there is also the shifted Stirling's approximation for the Gamma-Function due to C. Rowe, if I am not mistaken, that says: $$   \Gamma(z+a)=\sqrt{2\pi}e^{-z}z^{z+a-1/2}\left(1+O\left(\frac{1}{|z|}\right)\right) $$ uniformly for $|\arg(z)|\leq\pi-\varepsilon$, $a$ in a compact subset of $\mathbb{C}$ and some suitable fixed $\varepsilon>0$, as $|z|\to\infty$. In absolute value: $$   |\Gamma(z+a)|=\sqrt{2\pi}e^{-\Re(z)}|z|^{\Re(z+a)-1/2}e^{-\Im(z+a)\arg(z)}\left(1+O\left(\frac{1}{|z|}\right)\right) $$ My first question refers to terms of the type $$   \Gamma(az+b)\Gamma(cz+d) $$ for some complex numbers $a,b,c$ and $d$. (Q1) Using the classical Stirling's approximation formula (i.e. not the shifted one), how can one obtain a meaningful aggregated asymptotics for the above expression? I am asking this because there are several places that apply the non-shifted version of Stirling's formula to shifted Gamma factors without mentioning any details, which leaves the impression that this is a fairly standard or even trivial argument. Unfortunately, at this point I am unable to see its triviality. What bothers me here is the term $$   (az+b)^{az+b-1/2}(cz+d)^{cz+d-1/2} $$ as well as $\arg(az+b)$ and $\arg(cz+d)$, since the shifts by $c$ and $d$ break any easy manipulations. I am naturally assuming that I am missing something very obvious here (as usual). I have intentionally not specified anything about the parameters $a,b,c$ and $d$ because my question rather aims at the principle of applying the non-shifted Stirling's approximation to Gamma terms like the above one. (Q2) Are there any other versions or forms of the Stirling's approximation for $\Gamma(z)$ that could be particularly useful for computing such kinds of asymptotics? I will be extremely thankful if someone could give some insight in (principle of) the application of Stirling's approximatioin formula(s) to terms composed of Gamma factors!","I am currently reading some material that makes heavy usage of Hypergeometric functions, and there is one particular point about applying Stirling's approximation to various terms consisting of Gamma-Functions that is not very clear to me. We have the classical Stirling's approximation formula for the Gamma-Function in the form: $$   \Gamma(z)=\sqrt{2\pi}e^{-z}z^{z-1/2}\left(1+O\left(\frac{1}{|z|}\right)\right) $$ for $|\arg(z)|<\pi$ as $|z|\to\infty$. In absolute value: $$   |\Gamma(z)|=\sqrt{2\pi}e^{-\Re(z)}|z|^{\Re(z)-1/2}e^{-\Im(z)\arg(z)}\left(1+O\left(\frac{1}{|z|}\right)\right) $$ Now, there is also the shifted Stirling's approximation for the Gamma-Function due to C. Rowe, if I am not mistaken, that says: $$   \Gamma(z+a)=\sqrt{2\pi}e^{-z}z^{z+a-1/2}\left(1+O\left(\frac{1}{|z|}\right)\right) $$ uniformly for $|\arg(z)|\leq\pi-\varepsilon$, $a$ in a compact subset of $\mathbb{C}$ and some suitable fixed $\varepsilon>0$, as $|z|\to\infty$. In absolute value: $$   |\Gamma(z+a)|=\sqrt{2\pi}e^{-\Re(z)}|z|^{\Re(z+a)-1/2}e^{-\Im(z+a)\arg(z)}\left(1+O\left(\frac{1}{|z|}\right)\right) $$ My first question refers to terms of the type $$   \Gamma(az+b)\Gamma(cz+d) $$ for some complex numbers $a,b,c$ and $d$. (Q1) Using the classical Stirling's approximation formula (i.e. not the shifted one), how can one obtain a meaningful aggregated asymptotics for the above expression? I am asking this because there are several places that apply the non-shifted version of Stirling's formula to shifted Gamma factors without mentioning any details, which leaves the impression that this is a fairly standard or even trivial argument. Unfortunately, at this point I am unable to see its triviality. What bothers me here is the term $$   (az+b)^{az+b-1/2}(cz+d)^{cz+d-1/2} $$ as well as $\arg(az+b)$ and $\arg(cz+d)$, since the shifts by $c$ and $d$ break any easy manipulations. I am naturally assuming that I am missing something very obvious here (as usual). I have intentionally not specified anything about the parameters $a,b,c$ and $d$ because my question rather aims at the principle of applying the non-shifted Stirling's approximation to Gamma terms like the above one. (Q2) Are there any other versions or forms of the Stirling's approximation for $\Gamma(z)$ that could be particularly useful for computing such kinds of asymptotics? I will be extremely thankful if someone could give some insight in (principle of) the application of Stirling's approximatioin formula(s) to terms composed of Gamma factors!",,"['complex-analysis', 'special-functions', 'asymptotics', 'gamma-function']"
10,Is The Inverse Laplace Transform of $e^{st}\operatorname{Log}\left(\frac{s+1}{s}\right)$ doable using inversion formula?,Is The Inverse Laplace Transform of  doable using inversion formula?,e^{st}\operatorname{Log}\left(\frac{s+1}{s}\right),"I'm trying to solve inverse laplace transform using inversion formula and given by this integral: $$\frac{1}{2\pi i}\int_{\gamma-i\infty}^{\gamma+i \infty} e^{st}\operatorname{Log}\left(\frac{s+1}{s}\right)\,\Bbb ds.$$ Here is my contour, since the branch points of $\operatorname{Log} \left(\frac{s+1}{s}\right)$ are $0$ and $-1$ First, i want to show integral on $L_u\cup L_d$ is $0$ by bounding the integral with ML and then take the limit when $R$ goes to $\infty$ . By letting $L_u,\, L_d: s= \xi\pm iR,0\leq \xi\leq \gamma$ , where $\gamma$ is the real number that the vertical line of the given contour passed by. Since the $L$ is $\lvert e^{t(\xi\pm iR)} \rvert$ , then i have ML inequality as below: $$\lvert F(s)e^{st} \rvert \leq M_R \lvert e^{t(\xi\pm iR)} \rvert = M_R e^{\xi t} \leq M_R e^{at}$$ Next, i need to find $M_R$ and take the limit. $$\begin{align} \left|F(s)\right| &= \left|\operatorname{Log}\left(\frac{s+1}{s}\right)\right|\\ &= \left|\operatorname{Log}\left(\frac{\xi\pm iR+1}{\xi\pm iR}\right)\right| = M_R \end{align}$$ And by taking the limit of the last expression when $R$ goes to infinity yields $0$ . Meaning the integrals along those lines are $0$ . So, from here, am i doing this right? I'm not sure my work is correct. Maybe there are some mistakes there. Help me please! Edit: Working with my $L_u$ with $ML$ inequality, i have $L=\gamma$ . Assuming $-\pi<\operatorname{arg}{s}\leq \pi$ and parametrizing $s=-\xi+iR$ , $\xi\in [-\gamma,0]$ : $\begin{align} \left|\int_{L_u}\right|  &\leq \left|e^{st} \log\left(1 + \frac 1s\right)\right|\\ &\leq \left|e^{-\xi t}\right| \left|e^{iRt}\right|\left|\ln\left|1+ \frac{1}{-\xi+iR}\right| + i\pi\right|\\ &\leq 1\cdot 1 \cdot \ln\left(1+\frac 1R\right) + \pi\\ &\approx \frac 1R + \pi \end{align}$ Combining the $ML$ i have $$\frac{\gamma}{R} +\gamma\pi$$ Which does NOT approach to $0$ . Why? Please spot my mistake. I can't think about how to make it goes to $0$ since yesterday. Hope you kind to help me. New Edit : Now my main question is not about ML. I managed to set the big and small arc goes to $0$ . My main question now is ""is it possible to evaluate this by using inversion formula (without differentiate both sides) and use log form instead?"" What i mean by differentiate both sides is: $$\begin{align} \mathcal{L}^{-1} &= \operatorname{Log}\left(\frac{s+1}{s}\right)\\ (\mathcal{L}^{-1})' &= \frac{1}{1+s} - \frac{1}{s} \end{align}$$ I don't want this kind of solution. What i really want is evaluating $\operatorname{Log}\left(\frac{s+1}{s}\right)$ by inversion formula. That's it. because I keep getting integrals on the contour lines above and below the branch cut cancel each other and make everything 0, which of course I don't want it. Attempt:","I'm trying to solve inverse laplace transform using inversion formula and given by this integral: Here is my contour, since the branch points of are and First, i want to show integral on is by bounding the integral with ML and then take the limit when goes to . By letting , where is the real number that the vertical line of the given contour passed by. Since the is , then i have ML inequality as below: Next, i need to find and take the limit. And by taking the limit of the last expression when goes to infinity yields . Meaning the integrals along those lines are . So, from here, am i doing this right? I'm not sure my work is correct. Maybe there are some mistakes there. Help me please! Edit: Working with my with inequality, i have . Assuming and parametrizing , : Combining the i have Which does NOT approach to . Why? Please spot my mistake. I can't think about how to make it goes to since yesterday. Hope you kind to help me. New Edit : Now my main question is not about ML. I managed to set the big and small arc goes to . My main question now is ""is it possible to evaluate this by using inversion formula (without differentiate both sides) and use log form instead?"" What i mean by differentiate both sides is: I don't want this kind of solution. What i really want is evaluating by inversion formula. That's it. because I keep getting integrals on the contour lines above and below the branch cut cancel each other and make everything 0, which of course I don't want it. Attempt:","\frac{1}{2\pi i}\int_{\gamma-i\infty}^{\gamma+i \infty} e^{st}\operatorname{Log}\left(\frac{s+1}{s}\right)\,\Bbb ds. \operatorname{Log} \left(\frac{s+1}{s}\right) 0 -1 L_u\cup L_d 0 R \infty L_u,\, L_d: s= \xi\pm iR,0\leq \xi\leq \gamma \gamma L \lvert e^{t(\xi\pm iR)} \rvert \lvert F(s)e^{st} \rvert \leq M_R \lvert e^{t(\xi\pm iR)} \rvert = M_R e^{\xi t} \leq M_R e^{at} M_R \begin{align}
\left|F(s)\right| &= \left|\operatorname{Log}\left(\frac{s+1}{s}\right)\right|\\
&= \left|\operatorname{Log}\left(\frac{\xi\pm iR+1}{\xi\pm iR}\right)\right| = M_R
\end{align} R 0 0 L_u ML L=\gamma -\pi<\operatorname{arg}{s}\leq \pi s=-\xi+iR \xi\in [-\gamma,0] \begin{align}
\left|\int_{L_u}\right| 
&\leq \left|e^{st} \log\left(1 + \frac 1s\right)\right|\\
&\leq \left|e^{-\xi t}\right| \left|e^{iRt}\right|\left|\ln\left|1+ \frac{1}{-\xi+iR}\right| + i\pi\right|\\
&\leq 1\cdot 1 \cdot \ln\left(1+\frac 1R\right) + \pi\\
&\approx \frac 1R + \pi
\end{align} ML \frac{\gamma}{R} +\gamma\pi 0 0 0 \begin{align}
\mathcal{L}^{-1} &= \operatorname{Log}\left(\frac{s+1}{s}\right)\\
(\mathcal{L}^{-1})' &= \frac{1}{1+s} - \frac{1}{s}
\end{align} \operatorname{Log}\left(\frac{s+1}{s}\right)","['complex-analysis', 'inequality', 'laplace-transform', 'complex-integration', 'inverse-laplace']"
11,A generalization of maximum modulus principle,A generalization of maximum modulus principle,,"Let $ \emptyset \neq U \subset \mathbb{C} $ be a bounded open connected set and let $ f_1, \dots, f_n $ be analytic in $ \overline{U} $ . Prove that $$ \max_{z \in \overline{U}} \sum_{j=1}^n |f_j(z) | = \max_{z \in \partial U} \sum_{j=1}^n |f_j(z) |. $$ Clearly we have "" $\geq$ "" but I don't know how to reduce to the $ n = 1 $ case to use the usual maximum modulus principle. Help is appreciated.","Let be a bounded open connected set and let be analytic in . Prove that Clearly we have "" "" but I don't know how to reduce to the case to use the usual maximum modulus principle. Help is appreciated."," \emptyset \neq U \subset \mathbb{C}   f_1, \dots, f_n   \overline{U}   \max_{z \in \overline{U}} \sum_{j=1}^n |f_j(z) | = \max_{z \in \partial U} \sum_{j=1}^n |f_j(z) |.  \geq  n = 1 ",['complex-analysis']
12,Why is $\cos \sqrt z$ entire but $\sin \sqrt{z}$ isn't?,Why is  entire but  isn't?,\cos \sqrt z \sin \sqrt{z},"I've been trying to formulate a way of comparing these two functions, in order to find out why the function $\sin \sqrt z$ is not entire, but I couldn't find a good way of doing that. What I tried so far: I wrote the series of both functions: \begin{align}\cos(\sqrt{z})&=\sum_{n=0}^\infty \frac{(-1)^nz^n}{(2n)!}\\ \sin(\sqrt{z})&=\sum_{n=0}^\infty \frac{(-1)^nz^n\cdot\sqrt{z}}{(2n+1)!}\end{align} The $e$ version: \begin{align}\cos(\sqrt{z})&=\frac{e^{i\sqrt{z}}+e^{-i\sqrt{z}}}{2}\\ \sin(\sqrt{z})&=\frac{e^{i\sqrt{z}}-e^{-i\sqrt{z}}}{2i} ,\end{align} but they didn't help me on solving the problem. How could I progress from here? I could not find a way of writing Cauchy-Riemann equations for $\cos$ or $\sin$ .","I've been trying to formulate a way of comparing these two functions, in order to find out why the function is not entire, but I couldn't find a good way of doing that. What I tried so far: I wrote the series of both functions: The version: but they didn't help me on solving the problem. How could I progress from here? I could not find a way of writing Cauchy-Riemann equations for or .","\sin \sqrt z \begin{align}\cos(\sqrt{z})&=\sum_{n=0}^\infty \frac{(-1)^nz^n}{(2n)!}\\
\sin(\sqrt{z})&=\sum_{n=0}^\infty \frac{(-1)^nz^n\cdot\sqrt{z}}{(2n+1)!}\end{align} e \begin{align}\cos(\sqrt{z})&=\frac{e^{i\sqrt{z}}+e^{-i\sqrt{z}}}{2}\\
\sin(\sqrt{z})&=\frac{e^{i\sqrt{z}}-e^{-i\sqrt{z}}}{2i} ,\end{align} \cos \sin","['complex-analysis', 'power-series', 'entire-functions']"
13,Difference between Cauchy theorem and Cauchy goursat theorem,Difference between Cauchy theorem and Cauchy goursat theorem,,"In some books it is given that Cauchy theorem is equivalent to Cauchy Goursat theorem.And in some other it is given to be different. In my class , our teacher has given it differently. Cauchy theorem states that if $~f(z)~$ is an analytic function over a domain $D$ and $~f'(z)~$ is continuous in $D$ ,then $~\int f(z)dz~$ over a simple closed contour $C$ , which lies entirely in $D$ , is zero. Whereas  Cauchy Goursat theorem states that if $~f(z)~$ is analytic at all points on and inside of a simple closed contour $C$ , then $~∫f(z)dz~$ over $C$ is zero. So my doubt is whether in Cauchy Goursat theorem  is continuity of $~f'(z)~$ over $~z~$ , not a required condition. Which of them is a stronger theorem. How? please elaborate.","In some books it is given that Cauchy theorem is equivalent to Cauchy Goursat theorem.And in some other it is given to be different. In my class , our teacher has given it differently. Cauchy theorem states that if is an analytic function over a domain and is continuous in ,then over a simple closed contour , which lies entirely in , is zero. Whereas  Cauchy Goursat theorem states that if is analytic at all points on and inside of a simple closed contour , then over is zero. So my doubt is whether in Cauchy Goursat theorem  is continuity of over , not a required condition. Which of them is a stronger theorem. How? please elaborate.",~f(z)~ D ~f'(z)~ D ~\int f(z)dz~ C D ~f(z)~ C ~∫f(z)dz~ C ~f'(z)~ ~z~,['complex-analysis']
14,"Definition of a ""region""","Definition of a ""region""",,"Definition given - Region: Open set with none, some, or all of its boundary points. This seems quite unimportant... and it seems that almost all sets are regions (I can only think of regions, I can't think of any example that isn't.). It feels like it I'm given a set that is, neither open or closed, it could always be decomposed by taking away the boundary, meaning it is an open set with some of its boundary points. This is why I think the following set is a region: $$S = \{z=x+iy \in \mathbb{C}:x\geq 0, y>0\}.$$ If it is a region, what would be an example for a non-region?","Definition given - Region: Open set with none, some, or all of its boundary points. This seems quite unimportant... and it seems that almost all sets are regions (I can only think of regions, I can't think of any example that isn't.). It feels like it I'm given a set that is, neither open or closed, it could always be decomposed by taking away the boundary, meaning it is an open set with some of its boundary points. This is why I think the following set is a region: $$S = \{z=x+iy \in \mathbb{C}:x\geq 0, y>0\}.$$ If it is a region, what would be an example for a non-region?",,"['complex-analysis', 'terminology']"
15,Are solutions $z$ of $Im(z^z)=0$ dense in $\mathbb{C}$?,Are solutions  of  dense in ?,z Im(z^z)=0 \mathbb{C},"Inspired by this question ... More specifically, say $z$ is a solution of $Im(z^z)=0$ if there exist real numbers $\theta$, $r>0$, and integer $n$ such that $z=r e^{i\theta}$ and $$ r (\ln r \sin \theta + \theta \cos \theta) = n \pi $$ The left hand side is $Im(z \ln z)$ for some branch of $\ln z$ (not necessarily the principal one). Is the set of such $z$ dense in $\mathbb{C}$?","Inspired by this question ... More specifically, say $z$ is a solution of $Im(z^z)=0$ if there exist real numbers $\theta$, $r>0$, and integer $n$ such that $z=r e^{i\theta}$ and $$ r (\ln r \sin \theta + \theta \cos \theta) = n \pi $$ The left hand side is $Im(z \ln z)$ for some branch of $\ln z$ (not necessarily the principal one). Is the set of such $z$ dense in $\mathbb{C}$?",,"['complex-analysis', 'exponentiation']"
16,Convergence of power series around another point,Convergence of power series around another point,,Suppose $f(z)=\sum_{n=0}^\infty a_nz^n$ is a power series that converges on $B_R(0)$ for some $R>0$. Let $w \in B_R(0)$ and $r=|w|<R$. I'm trying to show that there exists a power series $f(z)=\sum_{n=0}^\infty b_n (z-w)^n$ that converges on $B_{R-r}(w)$. I tried to expand $f(z+w)$ to determine coefficients $b_n$ but I'm having a lot of trouble.,Suppose $f(z)=\sum_{n=0}^\infty a_nz^n$ is a power series that converges on $B_R(0)$ for some $R>0$. Let $w \in B_R(0)$ and $r=|w|<R$. I'm trying to show that there exists a power series $f(z)=\sum_{n=0}^\infty b_n (z-w)^n$ that converges on $B_{R-r}(w)$. I tried to expand $f(z+w)$ to determine coefficients $b_n$ but I'm having a lot of trouble.,,['complex-analysis']
17,Is there a direct method for evaluating this integral: $\int_{0}^{2\pi}\ln^2(2\sin(\frac{x}{2}))dx$?,Is there a direct method for evaluating this integral: ?,\int_{0}^{2\pi}\ln^2(2\sin(\frac{x}{2}))dx,"I stumbled upon this integral while attempting to evaluate $\sum_{n=1}^{\infty}\frac{\cos(n\theta)}{n}$. I started with the series $-\ln(1-z)=\sum_{n=1}^{\infty}\frac{z^n}{n}$, replaced z with $e^{i\theta}$ and extracted the real part to get $-\ln(2\sin(\frac{\theta}{2}))= \sum_{n=1}^{\infty}\frac{\cos(n\theta)}{n}$. Using Parseval's identity it follows that $\frac{1}{\pi}\int_{0}^{2\pi}\ln^2(2\sin(\frac{\theta}{2}))d\theta=\sum_{n=1}^{\infty}\frac{1}{n^2}=\frac{\pi^2}{6}$. This gives me the result: $\int_{0}^{2\pi}\ln^2(2\sin(\frac{\theta}{2}))d\theta=\frac{\pi^3}{6}$. Now this is the most roundabout way I have ever evaluated an integral, and I have attempted to find a more direct way to do it without any success. Does anyone know of other methods for evaluating this?","I stumbled upon this integral while attempting to evaluate $\sum_{n=1}^{\infty}\frac{\cos(n\theta)}{n}$. I started with the series $-\ln(1-z)=\sum_{n=1}^{\infty}\frac{z^n}{n}$, replaced z with $e^{i\theta}$ and extracted the real part to get $-\ln(2\sin(\frac{\theta}{2}))= \sum_{n=1}^{\infty}\frac{\cos(n\theta)}{n}$. Using Parseval's identity it follows that $\frac{1}{\pi}\int_{0}^{2\pi}\ln^2(2\sin(\frac{\theta}{2}))d\theta=\sum_{n=1}^{\infty}\frac{1}{n^2}=\frac{\pi^2}{6}$. This gives me the result: $\int_{0}^{2\pi}\ln^2(2\sin(\frac{\theta}{2}))d\theta=\frac{\pi^3}{6}$. Now this is the most roundabout way I have ever evaluated an integral, and I have attempted to find a more direct way to do it without any success. Does anyone know of other methods for evaluating this?",,"['complex-analysis', 'definite-integrals', 'improper-integrals', 'fourier-series']"
18,"Definition of exponential function, single-valued or multi-valued?","Definition of exponential function, single-valued or multi-valued?",,"If we define $$e^z=1+z+\frac{z^2}{2!}+\cdots$$ then it is single-valued. However, if we write $$e^z=e^{z\ln e}$$ then it is multi-valued. Besides, $a^z$ is multi-valued in general. It is kind of strange if only when the base is $e$ that it is single-valued. My thought: Is it true that there are two exponential functions, let's call them $\exp(z)$ and $e^z$? Where $\exp(z)$ is defined by $$\exp(z)=1+z+\frac{z^2}{2!}+\cdots$$ and is single-valued, while $e^z$ is defined by $$e^z = \text{exp}(z\ln e)$$ and is multi-valued? Here $\ln z$ is defined by $\exp(\ln z)=z$ and is multi-valued.","If we define $$e^z=1+z+\frac{z^2}{2!}+\cdots$$ then it is single-valued. However, if we write $$e^z=e^{z\ln e}$$ then it is multi-valued. Besides, $a^z$ is multi-valued in general. It is kind of strange if only when the base is $e$ that it is single-valued. My thought: Is it true that there are two exponential functions, let's call them $\exp(z)$ and $e^z$? Where $\exp(z)$ is defined by $$\exp(z)=1+z+\frac{z^2}{2!}+\cdots$$ and is single-valued, while $e^z$ is defined by $$e^z = \text{exp}(z\ln e)$$ and is multi-valued? Here $\ln z$ is defined by $\exp(\ln z)=z$ and is multi-valued.",,"['complex-analysis', 'complex-numbers', 'exponential-function']"
19,A question regarding power series expansion of an entire function [duplicate],A question regarding power series expansion of an entire function [duplicate],,"This question already has answers here : Entire function with vanishing derivatives? (3 answers) Closed 9 years ago . Let $f$ be an entire function and let for each $a\in \mathbb R$, there exists at least one coefficient $c_n$ in $f(z)=\sum\limits_{n=0}^{\infty}c_n(z-a)^n$, which is zero. Then $f^{(n)}(0)=0$ for infinitely many $n\geq 0$ $f^{(n)}(0)=0$ for every $n\geq 0$ $f^{(2n+1)}(0)=0$ for every $n\geq 0$ There exists $k\geq 0$ such that $f^{(n)}(0)=0$ for all $n\geq k$ We know that $c_n=\frac{f^{(n)}(a)}{n!}$ for all $n\in \{0,1,2\ldots\}$. Thus for $a=0$, $c_n=\frac{f^{(n)}(0)}{n!}$. By hypothersis, atleast one $c_n=0$. After that I could not do anything. Please help!","This question already has answers here : Entire function with vanishing derivatives? (3 answers) Closed 9 years ago . Let $f$ be an entire function and let for each $a\in \mathbb R$, there exists at least one coefficient $c_n$ in $f(z)=\sum\limits_{n=0}^{\infty}c_n(z-a)^n$, which is zero. Then $f^{(n)}(0)=0$ for infinitely many $n\geq 0$ $f^{(n)}(0)=0$ for every $n\geq 0$ $f^{(2n+1)}(0)=0$ for every $n\geq 0$ There exists $k\geq 0$ such that $f^{(n)}(0)=0$ for all $n\geq k$ We know that $c_n=\frac{f^{(n)}(a)}{n!}$ for all $n\in \{0,1,2\ldots\}$. Thus for $a=0$, $c_n=\frac{f^{(n)}(0)}{n!}$. By hypothersis, atleast one $c_n=0$. After that I could not do anything. Please help!",,"['complex-analysis', 'power-series']"
20,Contour Integral $ \int_{0}^1 \frac{\ln{x}}{\sqrt{1-x^2}} \mathrm dx$,Contour Integral, \int_{0}^1 \frac{\ln{x}}{\sqrt{1-x^2}} \mathrm dx,"I need help evaluating this with contour integration $$ \int_{0}^{1}{\ln\left(\,x\,\right)\over \,\sqrt{\vphantom{\large A}\,1 - x^{2}\,}}\,{\rm d}x $$ I am not sure as to how to work with the branch cuts of both $\ln\left(\,x\,\right)$ and $\sqrt{1 - x^{2}}$ Second part is to evaluate $$ \int_{0}^1 \frac{\sqrt{\,\vphantom{\large a}\ln\left(\,x\,\right)}} {\sqrt{\vphantom{\large A}\,1 - x^{2}\,}} \mathrm dx$$","I need help evaluating this with contour integration $$ \int_{0}^{1}{\ln\left(\,x\,\right)\over \,\sqrt{\vphantom{\large A}\,1 - x^{2}\,}}\,{\rm d}x $$ I am not sure as to how to work with the branch cuts of both $\ln\left(\,x\,\right)$ and $\sqrt{1 - x^{2}}$ Second part is to evaluate $$ \int_{0}^1 \frac{\sqrt{\,\vphantom{\large a}\ln\left(\,x\,\right)}} {\sqrt{\vphantom{\large A}\,1 - x^{2}\,}} \mathrm dx$$",,"['complex-analysis', 'definite-integrals', 'logarithms', 'contour-integration', 'branch-cuts']"
21,Argument Principle -Meaning of Derivative of Complex Logarithm,Argument Principle -Meaning of Derivative of Complex Logarithm,,"Intuitively in the argument principle , why does the integral of the logarithmic derivative of a meromorphic function over a closed curve give the number of zeros minus the number of poles?  My guess is that by writing $$\int _{ \gamma} \frac{d}{dz} \ln[f(z)]dz = \int _{ \gamma} \frac{d}{dz} \ln ( r(z)e^{i\theta (z)} ) dz =\int _{ \gamma} \frac{d}{dz} \ln(r(z)) dz + i \int _{ \gamma} \frac{d}{dz} \theta (z) dz$$ we see $\int _{ \gamma} \frac{d}{dz} \ln(r(z)) dz = 0$ because $f$ has no zero's or poles on $\gamma$ so the total change of $r(z)$ is zero. Hence making sense of $ i \int _{ \gamma} \frac{d}{dz} \theta (z) dz$ is all that's left, but I can't see why the sum of the changes in the argument around a contour containing zero's and poles should give the number of zero's minus the number of poles. At best, using the trick you use in proving Cauchy's integral formula I can see that: so $ i \int _{ \gamma} \frac{d}{dz} \theta (z) dz$ can be interpreted as summing up these changes, but I don't see why the arrows have to be in the direction they are by looking at $ i \int _{ \gamma} \frac{d}{dz} \theta (z) dz$. Is there a nice rock-solid way to make sense of $ i \int _{ \gamma} \frac{d}{dz} \theta (z) dz$ ?","Intuitively in the argument principle , why does the integral of the logarithmic derivative of a meromorphic function over a closed curve give the number of zeros minus the number of poles?  My guess is that by writing $$\int _{ \gamma} \frac{d}{dz} \ln[f(z)]dz = \int _{ \gamma} \frac{d}{dz} \ln ( r(z)e^{i\theta (z)} ) dz =\int _{ \gamma} \frac{d}{dz} \ln(r(z)) dz + i \int _{ \gamma} \frac{d}{dz} \theta (z) dz$$ we see $\int _{ \gamma} \frac{d}{dz} \ln(r(z)) dz = 0$ because $f$ has no zero's or poles on $\gamma$ so the total change of $r(z)$ is zero. Hence making sense of $ i \int _{ \gamma} \frac{d}{dz} \theta (z) dz$ is all that's left, but I can't see why the sum of the changes in the argument around a contour containing zero's and poles should give the number of zero's minus the number of poles. At best, using the trick you use in proving Cauchy's integral formula I can see that: so $ i \int _{ \gamma} \frac{d}{dz} \theta (z) dz$ can be interpreted as summing up these changes, but I don't see why the arrows have to be in the direction they are by looking at $ i \int _{ \gamma} \frac{d}{dz} \theta (z) dz$. Is there a nice rock-solid way to make sense of $ i \int _{ \gamma} \frac{d}{dz} \theta (z) dz$ ?",,['complex-analysis']
22,All roots of polynomial inside the open unit disc,All roots of polynomial inside the open unit disc,,I know from here that for a polynomial $p(z)=a_0+a_1z+...+a_nz^n$ with $0<a_0\leq a_1\leq...\leq a_n$ all roots are in the closed unit disk. What condition do we need to get that all roots are in the open unit disc? I was thinking that maybe some $a_i\neq a_{i+1}$. But I don't know how to prove that?,I know from here that for a polynomial $p(z)=a_0+a_1z+...+a_nz^n$ with $0<a_0\leq a_1\leq...\leq a_n$ all roots are in the closed unit disk. What condition do we need to get that all roots are in the open unit disc? I was thinking that maybe some $a_i\neq a_{i+1}$. But I don't know how to prove that?,,"['complex-analysis', 'roots']"
23,Level sets of holomorphic functions,Level sets of holomorphic functions,,"It is a somewhat well known fact that any closed set (say in the plane) can be realized as the level set of a smooth ($C^\infty$) function, so level sets of smooth functions are as general as they can possibly be. Question (very basic and probably well known, sorry) : what about level sets of holomorphic functions ? By the isolated zero principle, any non constant holomorphic function (in one variable) must be a submersion at all but a discrete set of points, so you get level sets which are fairly reasonnable. What is the most general scenario for such sets ? I would like to know this in those 3 levels of generality, if possible : 1) level sets of holomorphic maps from $\mathbb{C}^n$ to $\mathbb{C}^k$ 2) level sets of holomorphic maps from complex manifolds to complex manifolds (finite dimensional ; all local information should be the same as case 1). Feel free to add all relevant hypotheses I wouldn't know about (Kähler, Stein, I don't know...) 3) level sets of holomorphic maps from (possibily infinite dimensional) complex Banach manifold to complex Banach manifold.","It is a somewhat well known fact that any closed set (say in the plane) can be realized as the level set of a smooth ($C^\infty$) function, so level sets of smooth functions are as general as they can possibly be. Question (very basic and probably well known, sorry) : what about level sets of holomorphic functions ? By the isolated zero principle, any non constant holomorphic function (in one variable) must be a submersion at all but a discrete set of points, so you get level sets which are fairly reasonnable. What is the most general scenario for such sets ? I would like to know this in those 3 levels of generality, if possible : 1) level sets of holomorphic maps from $\mathbb{C}^n$ to $\mathbb{C}^k$ 2) level sets of holomorphic maps from complex manifolds to complex manifolds (finite dimensional ; all local information should be the same as case 1). Feel free to add all relevant hypotheses I wouldn't know about (Kähler, Stein, I don't know...) 3) level sets of holomorphic maps from (possibily infinite dimensional) complex Banach manifold to complex Banach manifold.",,"['complex-analysis', 'complex-geometry', 'several-complex-variables']"
24,holomorphic function with bounded real part on punctured neighborhood $\dot{D}_{\epsilon}(z_0)$,holomorphic function with bounded real part on punctured neighborhood,\dot{D}_{\epsilon}(z_0),"I've seen here that a holomorphic function with bounded imaginary part on a punctured neighborhood of $0$ has a removable singularity at $0$. I just wanted to know if this result could be also extended to get this: Let $\epsilon >0$, $z_0 \in \mathbb{C}$ and $f$ be holomorphic on a punctured neighborhood $\dot{D_{\epsilon}}(z_0)$. Futhermore it holds for all $z \in \dot{D_{\epsilon}}(z_0)$ that $Re(f(z))< K \in \mathbb{R}$ This implies that $z_0$ is a removable singularity of $f$ $(|f(z)|$ is bounded ?$)$. If the answer is yes I'm searching for a proof Thanks for help !","I've seen here that a holomorphic function with bounded imaginary part on a punctured neighborhood of $0$ has a removable singularity at $0$. I just wanted to know if this result could be also extended to get this: Let $\epsilon >0$, $z_0 \in \mathbb{C}$ and $f$ be holomorphic on a punctured neighborhood $\dot{D_{\epsilon}}(z_0)$. Futhermore it holds for all $z \in \dot{D_{\epsilon}}(z_0)$ that $Re(f(z))< K \in \mathbb{R}$ This implies that $z_0$ is a removable singularity of $f$ $(|f(z)|$ is bounded ?$)$. If the answer is yes I'm searching for a proof Thanks for help !",,['complex-analysis']
25,Find all entire functions that satisfy $f(2z) = (1-2z)f(z)$,Find all entire functions that satisfy,f(2z) = (1-2z)f(z),"This is for homework, and I could use a little help.  The question asks Find all entire functions that satisfy $f(2z) = (1-2z)f(z)$. Here is what I have done so far.  Since $f$ is entire, I wrote $$ f(z) = \sum_{n=0}^{\infty} a_n z^n = a_0 + a_1z + a_2z^2 + a_3z^3 + a_4z^4 + \dotsb $$ for some $z \in \mathbb{C}$.  Then $$ f(2z) = a_0 + 2a_1z + 4a_2z^2 + 8a_3z^3 + 16a_4z^4 + \dotsb $$ and $$ (1-2z)f(z) = a_0 + (a_1-2a_0)z + (a_2-2a_1)z^2+(a_3-2a_2)z^3 + (a_4-2a_3)z^4 + \dotsb. $$ Comparing coefficients, I find that \begin{align*} a_0 &= a_0 \\ a_1 &= -2a_0 \\ a_2 &= \frac{2^2}{3}a_0 \\ a_3 &= -\frac{2^3}{7 \cdot 3}a_0 \\ a_4 &= \frac{2^4}{15 \cdot 7 \cdot 3}a_0 \\ a_5 &= \frac{2^5}{31 \cdot 15 \cdot 7 \cdot 3} a_0 \\ &\vdots \end{align*} Now $f$ looks like $$ f(z) = a_0 \left( 1 - 2z + \frac{2^2}{3}z^2 - \frac{2^3}{7 \cdot 3}z^3 + \frac{2^4}{15 \cdot 7 \cdot 3}z^4 - \frac{2^5}{31 \cdot 15 \cdot 7 \cdot 3}z^5 + \dotsb \right). $$ Does the series in parenthesis represent any elementary function?  Besides the denominators, it looks like the Taylor expansion of $e^{-2z}$.","This is for homework, and I could use a little help.  The question asks Find all entire functions that satisfy $f(2z) = (1-2z)f(z)$. Here is what I have done so far.  Since $f$ is entire, I wrote $$ f(z) = \sum_{n=0}^{\infty} a_n z^n = a_0 + a_1z + a_2z^2 + a_3z^3 + a_4z^4 + \dotsb $$ for some $z \in \mathbb{C}$.  Then $$ f(2z) = a_0 + 2a_1z + 4a_2z^2 + 8a_3z^3 + 16a_4z^4 + \dotsb $$ and $$ (1-2z)f(z) = a_0 + (a_1-2a_0)z + (a_2-2a_1)z^2+(a_3-2a_2)z^3 + (a_4-2a_3)z^4 + \dotsb. $$ Comparing coefficients, I find that \begin{align*} a_0 &= a_0 \\ a_1 &= -2a_0 \\ a_2 &= \frac{2^2}{3}a_0 \\ a_3 &= -\frac{2^3}{7 \cdot 3}a_0 \\ a_4 &= \frac{2^4}{15 \cdot 7 \cdot 3}a_0 \\ a_5 &= \frac{2^5}{31 \cdot 15 \cdot 7 \cdot 3} a_0 \\ &\vdots \end{align*} Now $f$ looks like $$ f(z) = a_0 \left( 1 - 2z + \frac{2^2}{3}z^2 - \frac{2^3}{7 \cdot 3}z^3 + \frac{2^4}{15 \cdot 7 \cdot 3}z^4 - \frac{2^5}{31 \cdot 15 \cdot 7 \cdot 3}z^5 + \dotsb \right). $$ Does the series in parenthesis represent any elementary function?  Besides the denominators, it looks like the Taylor expansion of $e^{-2z}$.",,['complex-analysis']
26,Determine all the values of $1^{\sqrt{2}}$,Determine all the values of,1^{\sqrt{2}},"I can't seem to understand how to solve this. I mean, if we weren't dealing with complex numbers, then I suppose it is clearly 1, but I don't know how to approach this. Apparently the answer is $\cos(2\sqrt{2} k \pi) + i\sin (2 \sqrt{2} k \pi)$, but I don't know how to go through with this. Do I begin with setting it to $e^{\sqrt{2}ln(1)}$? Even then, $ln(1) = 0$, and $e^\sqrt{2}$ is just that... I'm not sure how to go about this. In short, how do I go from $1^{\sqrt{2}}$ to $\cos(2\sqrt{2} k \pi) + i\sin (2 \sqrt{2} k \pi)$?","I can't seem to understand how to solve this. I mean, if we weren't dealing with complex numbers, then I suppose it is clearly 1, but I don't know how to approach this. Apparently the answer is $\cos(2\sqrt{2} k \pi) + i\sin (2 \sqrt{2} k \pi)$, but I don't know how to go through with this. Do I begin with setting it to $e^{\sqrt{2}ln(1)}$? Even then, $ln(1) = 0$, and $e^\sqrt{2}$ is just that... I'm not sure how to go about this. In short, how do I go from $1^{\sqrt{2}}$ to $\cos(2\sqrt{2} k \pi) + i\sin (2 \sqrt{2} k \pi)$?",,['complex-analysis']
27,Evaluating $\int_{-\infty}^{\infty} \frac{\log^{2}(1+ix^{2})}{1+ix^{2}} dx $ using contour integration,Evaluating  using contour integration,\int_{-\infty}^{\infty} \frac{\log^{2}(1+ix^{2})}{1+ix^{2}} dx ,"It was recommended to me that I evaluate $$ \int_{-\infty}^{\infty} \frac{\log^{2}(1+ix^{2})}{1+ix^{2}} \ dx $$ by integrating $ \displaystyle f(z) = \frac{\log^{2}(1+z^{2})}{1+z^{2}}$around a semicircle that has its diameter along the line $ z= e^{i \pi /4}t, t \in \mathbb{R}$. Using the principal branch of the logarithm, there are branch cuts on the imaginary axis from $i$ to $i \infty$ and from $-i$ to $-i  \infty$. Deforming the contour around branch cut in the upper half-plane I get $$ e^{ \frac{i \pi }{4}} \int_{-\infty}^{\infty} \frac{\log^{2}(1+it^{2})}{1+it^{2}} \ dt   + i \int^{1}_{\infty} \frac{\left(\log (t^{2}-1) + \pi i\right)^{2}}{1-t^{2}} \ dt +  i \int_{1}^{\infty} \frac{\left(\log (t^{2}-1) - \pi i \right)^{2}}{1-t^{2}}  \ dt = 0 $$ which implies $$ \int_{-\infty}^{\infty} \frac{\log^{2}(1+it^{2})}{1+it^{2}} \ dt = -4 \pi e^{- i \pi /4}  \int_{1}^{\infty} \frac{\log(t^{2}-1)}{1-t^{2}} \ dt.$$ But $ \displaystyle \int_{1}^{\infty} \frac{\log(t^{2}-1)}{1-t^{2}} \ dt$  does not converge. What's going on here? EDIT : The issue is the indentation around the branch point at $z=i$. It's contribution doesn't vanish (nor is it finite) in the limit. If you integrate $ \displaystyle f(z) = \frac{\log^{2}(1+iz^{2})}{1+iz^{2}} $ around a semicircular contour that includes the real axis, you run into a similar issue with the branch point at $z=e^{i \pi/4}$. I have not been able to come up with another approach that would make the evaluation less difficult.","It was recommended to me that I evaluate $$ \int_{-\infty}^{\infty} \frac{\log^{2}(1+ix^{2})}{1+ix^{2}} \ dx $$ by integrating $ \displaystyle f(z) = \frac{\log^{2}(1+z^{2})}{1+z^{2}}$around a semicircle that has its diameter along the line $ z= e^{i \pi /4}t, t \in \mathbb{R}$. Using the principal branch of the logarithm, there are branch cuts on the imaginary axis from $i$ to $i \infty$ and from $-i$ to $-i  \infty$. Deforming the contour around branch cut in the upper half-plane I get $$ e^{ \frac{i \pi }{4}} \int_{-\infty}^{\infty} \frac{\log^{2}(1+it^{2})}{1+it^{2}} \ dt   + i \int^{1}_{\infty} \frac{\left(\log (t^{2}-1) + \pi i\right)^{2}}{1-t^{2}} \ dt +  i \int_{1}^{\infty} \frac{\left(\log (t^{2}-1) - \pi i \right)^{2}}{1-t^{2}}  \ dt = 0 $$ which implies $$ \int_{-\infty}^{\infty} \frac{\log^{2}(1+it^{2})}{1+it^{2}} \ dt = -4 \pi e^{- i \pi /4}  \int_{1}^{\infty} \frac{\log(t^{2}-1)}{1-t^{2}} \ dt.$$ But $ \displaystyle \int_{1}^{\infty} \frac{\log(t^{2}-1)}{1-t^{2}} \ dt$  does not converge. What's going on here? EDIT : The issue is the indentation around the branch point at $z=i$. It's contribution doesn't vanish (nor is it finite) in the limit. If you integrate $ \displaystyle f(z) = \frac{\log^{2}(1+iz^{2})}{1+iz^{2}} $ around a semicircular contour that includes the real axis, you run into a similar issue with the branch point at $z=e^{i \pi/4}$. I have not been able to come up with another approach that would make the evaluation less difficult.",,"['complex-analysis', 'contour-integration']"
28,Laplace transform of the Bessel function of the first kind,Laplace transform of the Bessel function of the first kind,,"I want to show that $$ \int_{0}^{\infty} J_{n}(bx) e^{-ax} \, dx = \frac{(\sqrt{a^{2}+b^{2}}-a)^{n}}{b^{n}\sqrt{a^{2}+b^{2}}}\ , \quad \ (n \in \mathbb{Z}_{\ge 0} \, , \text{Re}(a) >0 , \,  b >0 ),$$ where $J_{n}(x)$ is the Bessel function of the first kind of order $n$. But the result I get using an integral representation of $J_{n}(bx)$ is off by a factor of $ \displaystyle \frac{1}{b}$, and I don't understand why. $$ \begin{align} \int_{0}^{\infty} J_{n}(bx) e^{-ax} \, dx &=  \frac{1}{2 \pi} \int_{0}^{\infty} \int_{-\pi}^{\pi}  e^{i(n \theta -bx \sin \theta)} e^{-ax} \, d \theta \, dx \\ &=  \frac{1}{2 \pi} \int_{-\pi}^{\pi} \int_{0}^{\infty} e^{i n \theta} e^{-(a+ib \sin \theta)x} \, dx \, d \theta \\ &=  \frac{1}{2 \pi} \int_{-\pi}^{\pi} \frac{e^{i n \theta}}{a + ib \sin \theta} \, d \theta  \\  &= \frac{1}{2 \pi} \int_{|z|=1} \frac{z^{n}}{a+\frac{b}{2} \left(z-\frac{1}{z} \right)} \frac{dz} {iz} \\ &= \frac{1}{i\pi} \int_{|z|=1} \frac{z^{n}}{bz^{2}+2az-b} \, dz  \end{align}$$ The integrand has simple poles at $\displaystyle z= -\frac{a}{b} \pm \frac{\sqrt{a^{2}+b^{2}}}{b}$. But only the pole at $\displaystyle z= -\frac{a}{b} + \frac{\sqrt{a^{2}+b^{2}}}{b}$ is inside the unit circle. Therefore, $$ \begin{align} \int_{0}^{\infty} J_{n}(bx) e^{-ax} \, dx &= \frac{1}{i \pi} \, 2 \pi i \ \text{Res} \left[ \frac{z^{n}}{bz^{2}+2az-b}, -\frac{a}{b} + \frac{\sqrt{a^{2}+b^{2}}}{b} \right] \\ &= {\color{red}{b}} \  \frac{(\sqrt{a^{2}+b^{2}}-a)^{n}}{b^{n}\sqrt{a^{2}+b^{2}}} . \end{align}$$","I want to show that $$ \int_{0}^{\infty} J_{n}(bx) e^{-ax} \, dx = \frac{(\sqrt{a^{2}+b^{2}}-a)^{n}}{b^{n}\sqrt{a^{2}+b^{2}}}\ , \quad \ (n \in \mathbb{Z}_{\ge 0} \, , \text{Re}(a) >0 , \,  b >0 ),$$ where $J_{n}(x)$ is the Bessel function of the first kind of order $n$. But the result I get using an integral representation of $J_{n}(bx)$ is off by a factor of $ \displaystyle \frac{1}{b}$, and I don't understand why. $$ \begin{align} \int_{0}^{\infty} J_{n}(bx) e^{-ax} \, dx &=  \frac{1}{2 \pi} \int_{0}^{\infty} \int_{-\pi}^{\pi}  e^{i(n \theta -bx \sin \theta)} e^{-ax} \, d \theta \, dx \\ &=  \frac{1}{2 \pi} \int_{-\pi}^{\pi} \int_{0}^{\infty} e^{i n \theta} e^{-(a+ib \sin \theta)x} \, dx \, d \theta \\ &=  \frac{1}{2 \pi} \int_{-\pi}^{\pi} \frac{e^{i n \theta}}{a + ib \sin \theta} \, d \theta  \\  &= \frac{1}{2 \pi} \int_{|z|=1} \frac{z^{n}}{a+\frac{b}{2} \left(z-\frac{1}{z} \right)} \frac{dz} {iz} \\ &= \frac{1}{i\pi} \int_{|z|=1} \frac{z^{n}}{bz^{2}+2az-b} \, dz  \end{align}$$ The integrand has simple poles at $\displaystyle z= -\frac{a}{b} \pm \frac{\sqrt{a^{2}+b^{2}}}{b}$. But only the pole at $\displaystyle z= -\frac{a}{b} + \frac{\sqrt{a^{2}+b^{2}}}{b}$ is inside the unit circle. Therefore, $$ \begin{align} \int_{0}^{\infty} J_{n}(bx) e^{-ax} \, dx &= \frac{1}{i \pi} \, 2 \pi i \ \text{Res} \left[ \frac{z^{n}}{bz^{2}+2az-b}, -\frac{a}{b} + \frac{\sqrt{a^{2}+b^{2}}}{b} \right] \\ &= {\color{red}{b}} \  \frac{(\sqrt{a^{2}+b^{2}}-a)^{n}}{b^{n}\sqrt{a^{2}+b^{2}}} . \end{align}$$",,"['complex-analysis', 'improper-integrals', 'laplace-transform', 'contour-integration']"
29,The minimum value of $|z+1|+|z-1|+|z-i|$ for $z \in \mathbb C?$,The minimum value of  for,|z+1|+|z-1|+|z-i| z \in \mathbb C?,"I was thinking about the following problem: How can i find the minimum value of $|z+1|+|z-1|+|z-i|$ for $z \in \mathbb C?$ There are four options which are $(a)2,(b)2\sqrt 2,(c)1+ \sqrt 3,(d)\sqrt 5.$ It is a multiple choice question and so i am looking for a shorter method so that utilizing minimum effort and time i can get the correct option. Can someone point me in the right direction? Thanks in advance for your time.","I was thinking about the following problem: How can i find the minimum value of $|z+1|+|z-1|+|z-i|$ for $z \in \mathbb C?$ There are four options which are $(a)2,(b)2\sqrt 2,(c)1+ \sqrt 3,(d)\sqrt 5.$ It is a multiple choice question and so i am looking for a shorter method so that utilizing minimum effort and time i can get the correct option. Can someone point me in the right direction? Thanks in advance for your time.",,['complex-analysis']
30,Relation between circle mean value property and disk mean value property,Relation between circle mean value property and disk mean value property,,"Let $u$ be a continuous function on an open set $U$ of the complex plane. We say that $u$ satisfies the circle mean value property at a point $z_0\in U$ if $$ u(z_0)=\frac{1}{2\pi}\int_0^{2\pi}u(z_0+re^{i\theta})d\theta$$ for all $r$ sufficiently small such that the disc centered at $z_0$ with radius $r$> is contained in $U$. We say that $u$ satisfies the disc mean value property at a point $z_0$ if $$u(z_0)=\frac{1}{\pi r^2}\iint_{D(z_0,r)}u dxdy$$ I think the two properties are related. In particular i'd like to show that the first implies the second. Is this an application of Green's Thm maybe?","Let $u$ be a continuous function on an open set $U$ of the complex plane. We say that $u$ satisfies the circle mean value property at a point $z_0\in U$ if $$ u(z_0)=\frac{1}{2\pi}\int_0^{2\pi}u(z_0+re^{i\theta})d\theta$$ for all $r$ sufficiently small such that the disc centered at $z_0$ with radius $r$> is contained in $U$. We say that $u$ satisfies the disc mean value property at a point $z_0$ if $$u(z_0)=\frac{1}{\pi r^2}\iint_{D(z_0,r)}u dxdy$$ I think the two properties are related. In particular i'd like to show that the first implies the second. Is this an application of Green's Thm maybe?",,"['complex-analysis', 'analysis', 'harmonic-analysis']"
31,$\int_0^{2\pi} \log|1-ae^{i\theta}|d\theta=0$ when $|a| = 1$,when,\int_0^{2\pi} \log|1-ae^{i\theta}|d\theta=0 |a| = 1,"I'm taking a course on complex analysis, and I've been working on this problem forever, but can't seem to figure out. The question asks you to show the following: $\int_0^{2\pi} \log|1-ae^{i\theta}| \; \mathrm d\theta=0$ when $|a|<1$. I was able to do this by showing that $\int_0^{2\pi} \log(1-ae^{i\theta})\; \mathrm d\theta=0$ by substituting $z=e^{i\theta}$ and then calculating the residue of $\frac{\log(1-az)}{zi}$ at the origin to be zero. However, the question further asks you to show the same equation holds when $|a|=1$. Can someone help me with this? Thank you in advance. My attempt at solution -> Define $F(a) = \int_0^{2\pi} \log(1-ae^{i\theta})\; \mathrm d\theta$ Then, it can be shown that $F(a)$ is holomorphic in $|a|<1$. Given that $F(a)=0$ on the entire $|a|<1$, we can say that limit of $F(a)$ is $0$ when $|a|$ approaches 1. Therefore, since $F(a)$ is holomorphic in $|a|<1$ and converges uniformly to $0$ as $|a|$ approaches $1$, we can extend $F(a)$ to the boundary $|a|=1$ ((Is this true? Or in general, when can you ""continuously extend"" a holomorphic function defined on an open set to the boundary of the open set?)) Thus, we have a function $F(a)$ that takes on the value $0$ for $|a|<=1$. Since $\int_0^{2\pi} \log|1-ae^{i\theta}|\; \mathrm d\theta $ is the real part of $\int_0^{2\pi} \log(1-ae^{i\theta})\; \mathrm d\theta $, it follows that $\int_0^{2\pi} \log|1-ae^{i\theta}|\; \mathrm d\theta=0 $ for $|a| = 1$ as well. Could you let me know if the steps are correct? I'm very iffy about the ""continuous extension"" that I did.","I'm taking a course on complex analysis, and I've been working on this problem forever, but can't seem to figure out. The question asks you to show the following: $\int_0^{2\pi} \log|1-ae^{i\theta}| \; \mathrm d\theta=0$ when $|a|<1$. I was able to do this by showing that $\int_0^{2\pi} \log(1-ae^{i\theta})\; \mathrm d\theta=0$ by substituting $z=e^{i\theta}$ and then calculating the residue of $\frac{\log(1-az)}{zi}$ at the origin to be zero. However, the question further asks you to show the same equation holds when $|a|=1$. Can someone help me with this? Thank you in advance. My attempt at solution -> Define $F(a) = \int_0^{2\pi} \log(1-ae^{i\theta})\; \mathrm d\theta$ Then, it can be shown that $F(a)$ is holomorphic in $|a|<1$. Given that $F(a)=0$ on the entire $|a|<1$, we can say that limit of $F(a)$ is $0$ when $|a|$ approaches 1. Therefore, since $F(a)$ is holomorphic in $|a|<1$ and converges uniformly to $0$ as $|a|$ approaches $1$, we can extend $F(a)$ to the boundary $|a|=1$ ((Is this true? Or in general, when can you ""continuously extend"" a holomorphic function defined on an open set to the boundary of the open set?)) Thus, we have a function $F(a)$ that takes on the value $0$ for $|a|<=1$. Since $\int_0^{2\pi} \log|1-ae^{i\theta}|\; \mathrm d\theta $ is the real part of $\int_0^{2\pi} \log(1-ae^{i\theta})\; \mathrm d\theta $, it follows that $\int_0^{2\pi} \log|1-ae^{i\theta}|\; \mathrm d\theta=0 $ for $|a| = 1$ as well. Could you let me know if the steps are correct? I'm very iffy about the ""continuous extension"" that I did.",,"['complex-analysis', 'contour-integration', 'residue-calculus']"
32,"Holomorphic extension to a perfect, nowhere dense set.","Holomorphic extension to a perfect, nowhere dense set.",,"Suppose $f$ is holomorphic and uniformly bounded by $M$ on $\mathbb{C}\setminus E$, where $E$ is perfect and nowhere dense? Can $f$ be extended to a holomorphic function on $\mathbb{C}$? Riemann's theorem on removable singularities let's you remove one singularity $\{a\}$ at a time, provided $f$ is holomorphic and bounded on $\mathbb{C}\setminus\{a\}$. I suspect that the proof may be tailored in this case, since $E$ is nowhere dense, but would like your help on this. Furthermore, as is usual in cases of ""I want to do something uncountably many times, but only have a method for doing it once"", it seems natural to invoke Zorn's Lemma, so I tried: Let $\mathfrak{F}$ be the collection of all pairs $\{(F,\Omega)\}$ satisfying: $\Omega$ is an open subset of $\mathbb{C}$. $\mathbb{C}\setminus E\subseteq \Omega$ $F: \Omega\to \mathbb{C}$ is uniformly bounded by $M$ and is holomorphic. $F\mid_{C\setminus E}=f$ Since $f\in \mathfrak{F}$, it's nonempty. So we may define a partial order on $\mathfrak{F}$ by declaring that $(F,\Omega)\le (G,\Omega')$ if: $\Omega\subseteq \Omega'$ $G\mid_{\Omega}=F$ Now if $\{(F_{\alpha},\Omega_{\alpha})\}$ is a chain in $(\mathfrak{F},\le)$, we set $O=\bigcup_{\alpha\in A}F_{\alpha}$ and $F(x)=f_{\alpha}(x)$ for all $x\in \Omega_{\alpha}$. It is clear that $O$ is open, does not meet $E$, and that $F$ is well-defined, uniformly bounded by $M$, and $F\mid_{C\setminus E}=f$. It remains to show that $F$ is holomorphic. So here's my try: pick $a\in O$. Find $\epsilon>0$ so that $B(a,\epsilon)\subseteq O$ and $\overline{(B(a,\frac{\epsilon}{2}))}\subseteq O$. Then the closed ball is compact and, being covered by $\{\Omega_{\alpha}\}$, admits a finite subcover. Since they lie in a chain, there exists some $\alpha^*$ for which $a\in \Omega_{\alpha^*}$. But $F=F_{\alpha^*}$ on $\Omega_{\alpha^*}$, and so taking difference quotients shows that $F$ is holomorphic at $a$. So $F\in \mathfrak{F}$, and hence $(F,O)$ is clearly an upper bound (if this all worked) on the chain. By Zorn's Lemma, there exists some maximal element $(\mathcal{F},\mathcal{O})$. I claim that $\mathcal{O}=\mathbb{C}$. It is clear that there must be some $a\in E$ for which $a\not\in E$. But now we run through the proof of Riemann's Removable Singularity Theorem and find an extension of $F$ to...what!? $E$ has no isolated points, so I'm out of luck. I can't extend $F$ in a way to contradict its maximality. Does anyone have an idea of how to fix this, or do this in general? The question I'm actually interested in knowing is if one embeds the Cantor Set into $\mathbb{C}$ and finds a holomorphic function $F$ that is uniformly bounded on the complement of the Cantor set, can one extend it to all of $\mathbb{C}$. Thanks!","Suppose $f$ is holomorphic and uniformly bounded by $M$ on $\mathbb{C}\setminus E$, where $E$ is perfect and nowhere dense? Can $f$ be extended to a holomorphic function on $\mathbb{C}$? Riemann's theorem on removable singularities let's you remove one singularity $\{a\}$ at a time, provided $f$ is holomorphic and bounded on $\mathbb{C}\setminus\{a\}$. I suspect that the proof may be tailored in this case, since $E$ is nowhere dense, but would like your help on this. Furthermore, as is usual in cases of ""I want to do something uncountably many times, but only have a method for doing it once"", it seems natural to invoke Zorn's Lemma, so I tried: Let $\mathfrak{F}$ be the collection of all pairs $\{(F,\Omega)\}$ satisfying: $\Omega$ is an open subset of $\mathbb{C}$. $\mathbb{C}\setminus E\subseteq \Omega$ $F: \Omega\to \mathbb{C}$ is uniformly bounded by $M$ and is holomorphic. $F\mid_{C\setminus E}=f$ Since $f\in \mathfrak{F}$, it's nonempty. So we may define a partial order on $\mathfrak{F}$ by declaring that $(F,\Omega)\le (G,\Omega')$ if: $\Omega\subseteq \Omega'$ $G\mid_{\Omega}=F$ Now if $\{(F_{\alpha},\Omega_{\alpha})\}$ is a chain in $(\mathfrak{F},\le)$, we set $O=\bigcup_{\alpha\in A}F_{\alpha}$ and $F(x)=f_{\alpha}(x)$ for all $x\in \Omega_{\alpha}$. It is clear that $O$ is open, does not meet $E$, and that $F$ is well-defined, uniformly bounded by $M$, and $F\mid_{C\setminus E}=f$. It remains to show that $F$ is holomorphic. So here's my try: pick $a\in O$. Find $\epsilon>0$ so that $B(a,\epsilon)\subseteq O$ and $\overline{(B(a,\frac{\epsilon}{2}))}\subseteq O$. Then the closed ball is compact and, being covered by $\{\Omega_{\alpha}\}$, admits a finite subcover. Since they lie in a chain, there exists some $\alpha^*$ for which $a\in \Omega_{\alpha^*}$. But $F=F_{\alpha^*}$ on $\Omega_{\alpha^*}$, and so taking difference quotients shows that $F$ is holomorphic at $a$. So $F\in \mathfrak{F}$, and hence $(F,O)$ is clearly an upper bound (if this all worked) on the chain. By Zorn's Lemma, there exists some maximal element $(\mathcal{F},\mathcal{O})$. I claim that $\mathcal{O}=\mathbb{C}$. It is clear that there must be some $a\in E$ for which $a\not\in E$. But now we run through the proof of Riemann's Removable Singularity Theorem and find an extension of $F$ to...what!? $E$ has no isolated points, so I'm out of luck. I can't extend $F$ in a way to contradict its maximality. Does anyone have an idea of how to fix this, or do this in general? The question I'm actually interested in knowing is if one embeds the Cantor Set into $\mathbb{C}$ and finds a holomorphic function $F$ that is uniformly bounded on the complement of the Cantor set, can one extend it to all of $\mathbb{C}$. Thanks!",,['complex-analysis']
33,Topology of Branch Cuts and Elliptic Integrals,Topology of Branch Cuts and Elliptic Integrals,,"In reading these notes (elliptic curves starting from elliptic integrals) I came across a couple claims about the topology of some complex surfaces. On page 4, they discuss the integral $$\phi(x) = \int_0 ^x \frac{dt}{\sqrt{1 - t^2}}$$ In order to define it on all of $\mathbb C$, you have to use a branch cut; they glue two copies of $\mathbb C$ together along $[-1,1]$, in the same crossing-over manner as you do when dealing with $\sqrt z$ (at least, I think).  They then claim that this surface $C$ is homeomorphic to a cylinder.  However, I'm having trouble seeing a way to explicitly bend $C$ into a cylinder.  I think I might be missing some intuition on what a complex cylinder looks like. I think I understand why $C$ would be homotopically equivalent (not sure if that's the best term) to a cylinder, because there's one set of loops from going around the branch cut, and if you avoid integrating across the branch cut the other ones are all null-homotopic.  But why glue two copies of $\mathbb C$ together at all if you're going to avoid integration across the branch cut? I also don't quite get they say that $C$ can also be defined as $\{ (x,y) \in \mathbb C ^2 : x^2 + y^2 = 1 \}$; is it just that we can integrate $dx/y$ on $C$, because that differential on $C$ looks like the differential in $\phi$? They make similar claims a page later about  $$ \psi (x)  = \int_0^x \frac{dt}{\sqrt{t(t-1)(t-\lambda)}}$$ but I think my issues are basically the same.","In reading these notes (elliptic curves starting from elliptic integrals) I came across a couple claims about the topology of some complex surfaces. On page 4, they discuss the integral $$\phi(x) = \int_0 ^x \frac{dt}{\sqrt{1 - t^2}}$$ In order to define it on all of $\mathbb C$, you have to use a branch cut; they glue two copies of $\mathbb C$ together along $[-1,1]$, in the same crossing-over manner as you do when dealing with $\sqrt z$ (at least, I think).  They then claim that this surface $C$ is homeomorphic to a cylinder.  However, I'm having trouble seeing a way to explicitly bend $C$ into a cylinder.  I think I might be missing some intuition on what a complex cylinder looks like. I think I understand why $C$ would be homotopically equivalent (not sure if that's the best term) to a cylinder, because there's one set of loops from going around the branch cut, and if you avoid integrating across the branch cut the other ones are all null-homotopic.  But why glue two copies of $\mathbb C$ together at all if you're going to avoid integration across the branch cut? I also don't quite get they say that $C$ can also be defined as $\{ (x,y) \in \mathbb C ^2 : x^2 + y^2 = 1 \}$; is it just that we can integrate $dx/y$ on $C$, because that differential on $C$ looks like the differential in $\phi$? They make similar claims a page later about  $$ \psi (x)  = \int_0^x \frac{dt}{\sqrt{t(t-1)(t-\lambda)}}$$ but I think my issues are basically the same.",,"['complex-analysis', 'special-functions', 'elliptic-integrals']"
34,Complex and real forms of the Poisson integral formula,Complex and real forms of the Poisson integral formula,,"In my complex analysis book there is the expression $$\frac{1 - |z|^2}{|1 - \bar z e^{it}|^2}$$ and it says that when $z = re^{it}$, we can write the above expression as $$P_r(t) = \frac{1 - r^2}{1 - 2r\cos t + r^2} = \text{Re}\left( \frac{1 + z}{1 - z} \right)$$ I do not see where the $\cos t$ comes from though. Isn't $\bar z = re^{-it}$, so the top is $1 - r^2$ and the bottom is $|1 - r|^2 = 1 - 2r + r^2$. I have not really figured out where the $\text{Re}(1 + z)/(1 - z)$ comes from either.","In my complex analysis book there is the expression $$\frac{1 - |z|^2}{|1 - \bar z e^{it}|^2}$$ and it says that when $z = re^{it}$, we can write the above expression as $$P_r(t) = \frac{1 - r^2}{1 - 2r\cos t + r^2} = \text{Re}\left( \frac{1 + z}{1 - z} \right)$$ I do not see where the $\cos t$ comes from though. Isn't $\bar z = re^{-it}$, so the top is $1 - r^2$ and the bottom is $|1 - r|^2 = 1 - 2r + r^2$. I have not really figured out where the $\text{Re}(1 + z)/(1 - z)$ comes from either.",,"['complex-analysis', 'partial-differential-equations', 'harmonic-functions']"
35,"Upper bound on complex integral of real-valued function, estimation lemma too loose","Upper bound on complex integral of real-valued function, estimation lemma too loose",,"I've encountered the following problem in a set of course notes on complex analysis, but I can't seem to solve it: Prove that if f is a continuous real-valued function with $|f(z)| \leq 1$, then $\left|\int_{|z| = 1} f(z)\,dz\right| \leq 4$. This is my work so far: \begin{align*} \left|\int_{|z| = 1} f(z) \,dz \right| &= \left|\int_0^{2\pi}f\left(e^{i\theta}\right)ie^{i\theta}\,d\theta\right| \\ &= \left|\int_0^{2\pi}f\left(e^{i\theta}\right)\cos\theta\,d\theta + i\int_0^{2\pi}f\left(e^{i\theta}\right)\sin\theta\,d\theta\right| \end{align*} I initially tried to use the triangle inequality at this point and then bound the real integrals, but this gives me an upper bound of $4\pi$. Using the estimation lemma on the initial integral gives me an upper bound of $2\pi$. I can't manage to get it any tighter. The emphasis on real-valued makes it seem that this is a key point. Any ideas?","I've encountered the following problem in a set of course notes on complex analysis, but I can't seem to solve it: Prove that if f is a continuous real-valued function with $|f(z)| \leq 1$, then $\left|\int_{|z| = 1} f(z)\,dz\right| \leq 4$. This is my work so far: \begin{align*} \left|\int_{|z| = 1} f(z) \,dz \right| &= \left|\int_0^{2\pi}f\left(e^{i\theta}\right)ie^{i\theta}\,d\theta\right| \\ &= \left|\int_0^{2\pi}f\left(e^{i\theta}\right)\cos\theta\,d\theta + i\int_0^{2\pi}f\left(e^{i\theta}\right)\sin\theta\,d\theta\right| \end{align*} I initially tried to use the triangle inequality at this point and then bound the real integrals, but this gives me an upper bound of $4\pi$. Using the estimation lemma on the initial integral gives me an upper bound of $2\pi$. I can't manage to get it any tighter. The emphasis on real-valued makes it seem that this is a key point. Any ideas?",,['complex-analysis']
36,Formula for calculating residue at a simple pole.,Formula for calculating residue at a simple pole.,,"Suppose $f=P/Q$ is a rational function and suppose $f$ has a simple pole at $a$. Then a formula for calculating the residue of $f$ at $a$ is  $$ \text{Res}(f(z),a)=\lim_{z\to a}(z-a)f(z)=\lim_{z\to a}\frac{P(z)}{\frac{Q(z)-Q(a)}{z-a}}=\frac{P(a)}{Q'(a)}. $$ In the second equality, how does the $Q(z)-Q(a)$ appear? I only see that it would equal $\lim_{z\to a}\frac{P(z)}{\frac{Q(z)}{z-a}}$.","Suppose $f=P/Q$ is a rational function and suppose $f$ has a simple pole at $a$. Then a formula for calculating the residue of $f$ at $a$ is  $$ \text{Res}(f(z),a)=\lim_{z\to a}(z-a)f(z)=\lim_{z\to a}\frac{P(z)}{\frac{Q(z)-Q(a)}{z-a}}=\frac{P(a)}{Q'(a)}. $$ In the second equality, how does the $Q(z)-Q(a)$ appear? I only see that it would equal $\lim_{z\to a}\frac{P(z)}{\frac{Q(z)}{z-a}}$.",,['complex-analysis']
37,Complex Analysis: Continuity of Function,Complex Analysis: Continuity of Function,,"Problem Define g to be the function $g(z)=re^{\frac{i\theta}{2}}$ if $z=re^{i\theta}$ with $r>0$ and $-\pi<\theta\le\pi$ , and $g(z)=0$ when $z=0$ . Is $g$ continuous from $\mathbb{C}\longrightarrow\mathbb{C}$ ? Progress Claim: $g$ is not continuous from $\mathbb{C}\longrightarrow\mathbb{C}$ . [It seems that all the function seems to be doing is halving $arg(z)$ for each $z\in\mathbb{C}$ .] If we consider points on the negative real line, i.e. $z=-a$ for $a\in\mathbb{R}$ , then let $\epsilon=\frac{a}{2}$ . If $g$ is continuous, then $\exists \delta>0$ such that $g(B_{\delta}(z))\subset B_{\epsilon}((g)z)$ . Clearly $g(-a-(i\delta/2))\in g(B_{\delta}(-a))$ does not lie in $B_{a/2}(g(-a))$ for any $\delta>0$ as $-a$ is mapped to $ai$ and $-a-(i\delta/2)$ is mapped to a point in the lower half-plane. We can conclude then that $g$ is not continuous from $\mathbb{C}\longrightarrow\mathbb{C}$ . Thoughts Is this proof valid (if I play around to make it a little more formal), i.e. is the reasoning behind the claim correct? Any verification/objection would be appreciated. Thanks, TJO.","Problem Define g to be the function if with and , and when . Is continuous from ? Progress Claim: is not continuous from . [It seems that all the function seems to be doing is halving for each .] If we consider points on the negative real line, i.e. for , then let . If is continuous, then such that . Clearly does not lie in for any as is mapped to and is mapped to a point in the lower half-plane. We can conclude then that is not continuous from . Thoughts Is this proof valid (if I play around to make it a little more formal), i.e. is the reasoning behind the claim correct? Any verification/objection would be appreciated. Thanks, TJO.",g(z)=re^{\frac{i\theta}{2}} z=re^{i\theta} r>0 -\pi<\theta\le\pi g(z)=0 z=0 g \mathbb{C}\longrightarrow\mathbb{C} g \mathbb{C}\longrightarrow\mathbb{C} arg(z) z\in\mathbb{C} z=-a a\in\mathbb{R} \epsilon=\frac{a}{2} g \exists \delta>0 g(B_{\delta}(z))\subset B_{\epsilon}((g)z) g(-a-(i\delta/2))\in g(B_{\delta}(-a)) B_{a/2}(g(-a)) \delta>0 -a ai -a-(i\delta/2) g \mathbb{C}\longrightarrow\mathbb{C},"['complex-analysis', 'functions']"
38,"For holomorphic functions, does the mean-value property for $0<r<R$ imply it for $r=R$?","For holomorphic functions, does the mean-value property for  imply it for ?",0<r<R r=R,"The mean-value property for holomorphic functions states that if $f$ is holomorphic in an open disc centered at $z_{0}$ of radius $R$, then $$f(z_{0}) = \frac{1}{2\pi}\int_{0}^{2\pi}f(z_{0} + re^{i\theta})\, d\theta$$ for any $0 < r < R$. When can I say this is true for $r = R$?","The mean-value property for holomorphic functions states that if $f$ is holomorphic in an open disc centered at $z_{0}$ of radius $R$, then $$f(z_{0}) = \frac{1}{2\pi}\int_{0}^{2\pi}f(z_{0} + re^{i\theta})\, d\theta$$ for any $0 < r < R$. When can I say this is true for $r = R$?",,['complex-analysis']
39,HAKMEM 123: Fourier Clocks,HAKMEM 123: Fourier Clocks,,"I recently wrote a program to do what was described in HAKMEM 123 . Copy-pasting verbatim... Consider the image of the circle $|z| = 1$ under the function $$f(z) = \sum_n \frac{z^{2^{n}}}{2^{n}}$$ This is physically analogous to a series of clock hands placed end to end. The first hand rotates around the center (0,0) at some rate. the next hand is half as long and rotates around the end of the first hand at twice this rate. The third hand rotates around the end of the second at four times this rate; etc. It would seem that the end of the ""last"" hand (really there are infinitely many) would sweep through space very fast, tracing out an (infinitely) long curve in the time the first hand rotates once. The hands shrink, however, because of the $2^n$ in the denominator. Thus it is unclear whether the curve's arc length is really infinite. Was this problem ever solved? Is the curve's arc length infinite or finite? My gut feeling says that it's infinite, but I don't really know how to go about proving it. (By the way, tagging help would be appreciated.)","I recently wrote a program to do what was described in HAKMEM 123 . Copy-pasting verbatim... Consider the image of the circle under the function This is physically analogous to a series of clock hands placed end to end. The first hand rotates around the center (0,0) at some rate. the next hand is half as long and rotates around the end of the first hand at twice this rate. The third hand rotates around the end of the second at four times this rate; etc. It would seem that the end of the ""last"" hand (really there are infinitely many) would sweep through space very fast, tracing out an (infinitely) long curve in the time the first hand rotates once. The hands shrink, however, because of the in the denominator. Thus it is unclear whether the curve's arc length is really infinite. Was this problem ever solved? Is the curve's arc length infinite or finite? My gut feeling says that it's infinite, but I don't really know how to go about proving it. (By the way, tagging help would be appreciated.)",|z| = 1 f(z) = \sum_n \frac{z^{2^{n}}}{2^{n}} 2^n,['complex-analysis']
40,Proving for polynomial: $P (1)=0\implies|P'(1)|\leq \frac{\deg(P)}{2}\max_{|z|=1}|P(z)|$.,Proving for polynomial: .,P (1)=0\implies|P'(1)|\leq \frac{\deg(P)}{2}\max_{|z|=1}|P(z)|,"I wonder if it is true that any polynomial $P(z):\mathbb C\to\mathbb C$ with $P (1)=0$ satisfies $$|P'(1)|\leq \frac{\deg(P)}{2}\max_{|z|=1}|P(z)|, $$ where the maximum is taken over the unit circle. At least numerically it seems to be the case and the extremizer seems to be $P(z)=z^n-1$ . If $\deg(P)=1$ , then $P(z)=z-1$ . Hence, $P'(1)=1$ and $\max_{|z|=1}|P(z)|=2$ .","I wonder if it is true that any polynomial with satisfies where the maximum is taken over the unit circle. At least numerically it seems to be the case and the extremizer seems to be . If , then . Hence, and .","P(z):\mathbb C\to\mathbb C P (1)=0 |P'(1)|\leq \frac{\deg(P)}{2}\max_{|z|=1}|P(z)|,  P(z)=z^n-1 \deg(P)=1 P(z)=z-1 P'(1)=1 \max_{|z|=1}|P(z)|=2",['complex-analysis']
41,Let $f$ be an entire function s.t. $F(z) = \lim_{n\to\infty} f^{(n)}(z)$ exists for all $z$ with local uniform convergence. What can we say about $F$?,Let  be an entire function s.t.  exists for all  with local uniform convergence. What can we say about ?,f F(z) = \lim_{n\to\infty} f^{(n)}(z) z F,"I have stumbled into this problem, without a given answer. Let $f$ be an entire function such that $F(z) = \lim\limits_{n\to\infty} f^{(n)}(z)$ exists $\forall z \in \mathbb{C}$ with local uniform convergence. What can you say about the function $F$ ? What can you say about the function $f$ ? I have sort of convinced myself that $F(z) =Ce^z$ and thus $f(z)=F(z)$ but i am very doubtful about this and even if it is correct I have no idea how to prove it, and there is probably more information you have to provide about the given functions. Such that $F$ is analytic implies that $f$ is analytic.","I have stumbled into this problem, without a given answer. Let be an entire function such that exists with local uniform convergence. What can you say about the function ? What can you say about the function ? I have sort of convinced myself that and thus but i am very doubtful about this and even if it is correct I have no idea how to prove it, and there is probably more information you have to provide about the given functions. Such that is analytic implies that is analytic.",f F(z) = \lim\limits_{n\to\infty} f^{(n)}(z) \forall z \in \mathbb{C} F f F(z) =Ce^z f(z)=F(z) F f,"['complex-analysis', 'uniform-convergence']"
42,"Construction of the complex exponential, extending real identities to complex, and proving $e^{ix} = \cos x+i\sin x$ from those identities","Construction of the complex exponential, extending real identities to complex, and proving  from those identities",e^{ix} = \cos x+i\sin x,"Let's say that we have already defined $f(x)=e^x$ on $\mathbb R$ as the solution to the equation $f'(x) = f(x)$ with $f(0)=1$ , and let's say that we've proved the following three properties: $f(x) = \sum\limits_{n=0}^\infty \frac{x^n}{n!}$ $f(x+y)=f(x)f(y)$ $f(x) = \lim\limits_{n\to\infty} (1+\frac xn)^n$ Now we want to extend this function to the entire complex plane analytically, and so (using the identity theorem) the continuation is $f(z) = \sum\limits_{n=0}^\infty \frac{z^n}{n!}$ . First question: I know that on $\mathbb C$ , properties $2$ , $3$ , and $f'(z)=f(z)$ still hold. Is this a surprise, or coincidental? That is, in general is it true that if we have some formulas $F_1, \ldots, F_n$ (like the identities above, or things like continued fractions, etc) involving $g: \mathbb R\to \mathbb R$ , will those formulas $F_1,\ldots, F_n$ hold on $\mathbb C$ as well if we analytically extend $g$ to the complex plane? Now let's say that we have all these properties, and we want to use property $2$ to prove $e^{ix}=\cos x+i\sin x$ . Well, following the lead of this 3b1b video at @18:50: https://www.youtube.com/watch?v=mvmuCPvRoWQ , (maybe start watching at around minute @18:30), Grant says that it ""would be reasonable"" to think that pure vertical shifts would result in pure rotations (i.e. exponentiating a pure imaginary would result in a number on the unit circle). Yes, this is reasonable, but how do we prove it? It seems that property $2$ alone (along with the fact that $f(x+i0)=e^x$ for all $x\in \mathbb R$ ) is not enough to nail down exactly the complex exponential. So: What's the easiest step we need to take fully justify that pure vertical slides correspond to pure rotations? Note that I'm asking for a step starting from the ""group-theoretic"" framework Grant laid out in the video above; that is, I'm NOT asking for just any proof of $e^{ix}=\cos x+i\sin x$ using heavy calculus (like Taylor series, or differential equations). P.S. Are there results like the Bohr-Mollerup theorem for $e^z$ ? Like is it true that any ( continuous /differentiable?) function defined by $f(x+y)=f(x)f(y)$ (+ other conditions?) MUST be $e^z$ ?","Let's say that we have already defined on as the solution to the equation with , and let's say that we've proved the following three properties: Now we want to extend this function to the entire complex plane analytically, and so (using the identity theorem) the continuation is . First question: I know that on , properties , , and still hold. Is this a surprise, or coincidental? That is, in general is it true that if we have some formulas (like the identities above, or things like continued fractions, etc) involving , will those formulas hold on as well if we analytically extend to the complex plane? Now let's say that we have all these properties, and we want to use property to prove . Well, following the lead of this 3b1b video at @18:50: https://www.youtube.com/watch?v=mvmuCPvRoWQ , (maybe start watching at around minute @18:30), Grant says that it ""would be reasonable"" to think that pure vertical shifts would result in pure rotations (i.e. exponentiating a pure imaginary would result in a number on the unit circle). Yes, this is reasonable, but how do we prove it? It seems that property alone (along with the fact that for all ) is not enough to nail down exactly the complex exponential. So: What's the easiest step we need to take fully justify that pure vertical slides correspond to pure rotations? Note that I'm asking for a step starting from the ""group-theoretic"" framework Grant laid out in the video above; that is, I'm NOT asking for just any proof of using heavy calculus (like Taylor series, or differential equations). P.S. Are there results like the Bohr-Mollerup theorem for ? Like is it true that any ( continuous /differentiable?) function defined by (+ other conditions?) MUST be ?","f(x)=e^x \mathbb R f'(x) = f(x) f(0)=1 f(x) = \sum\limits_{n=0}^\infty \frac{x^n}{n!} f(x+y)=f(x)f(y) f(x) = \lim\limits_{n\to\infty} (1+\frac xn)^n f(z) = \sum\limits_{n=0}^\infty \frac{z^n}{n!} \mathbb C 2 3 f'(z)=f(z) F_1, \ldots, F_n g: \mathbb R\to \mathbb R F_1,\ldots, F_n \mathbb C g 2 e^{ix}=\cos x+i\sin x 2 f(x+i0)=e^x x\in \mathbb R e^{ix}=\cos x+i\sin x e^z f(x+y)=f(x)f(y) e^z","['complex-analysis', 'exponential-function']"
43,Reference request for a book that covers analytic continuation in great detail starting from basics,Reference request for a book that covers analytic continuation in great detail starting from basics,,"I have earlier self studied Tom M. Apostol's Introduction to Analytic Number Theory after doing a course in complex analysis, but my instructor at university didn't even mention analytic continuation. Although I self studied from Complex Variables with Applications from Ponnusamy and Silvermann and then studied Chapter 12 and 13 of Apostol's Introduction to Analytic Number Theory but I don't feel sometimes comfortable in analytic continuation. Can you please suggest some good reference book for Analytic Continuation which has explained analytic continuation in detail and also contains exercises based on analytic continuation which I can try?","I have earlier self studied Tom M. Apostol's Introduction to Analytic Number Theory after doing a course in complex analysis, but my instructor at university didn't even mention analytic continuation. Although I self studied from Complex Variables with Applications from Ponnusamy and Silvermann and then studied Chapter 12 and 13 of Apostol's Introduction to Analytic Number Theory but I don't feel sometimes comfortable in analytic continuation. Can you please suggest some good reference book for Analytic Continuation which has explained analytic continuation in detail and also contains exercises based on analytic continuation which I can try?",,"['complex-analysis', 'reference-request']"
44,Grothendieck Residue,Grothendieck Residue,,"In the article: Residues Of Codimension one Singular Holomorphic Distribution,  the author : Takeshi Izawa, states that: Theorem: Let $X$ an $n$ -dimensional compact complex manifold and $\mathcal{G}$ a rank-one locally-free subsheaf of $\Omega_{X}$ . We assume that the singular supports of $\Omega_{X}/ \mathcal{G}$ are all isolated. Then we have: $$ \int_{X}c_{n}(\Omega_{X} \otimes \mathcal{G}^{\vee}) = \displaystyle \sum_{j = 1}^{k}\text{Res}_{p_{j}}  \left[ \begin{array}{cccc} df_{1}^{(j)} \wedge & \cdots & \wedge \,\, df_{n}^{(j)}\\ f_{1}^{(j)} \wedge & \cdots & \wedge f_{n}^{(j)} \end{array} \right] $$ where above there is the Grothendieck residue. In this article, the author provides no example of how to calculate this residue. The Distribution $\mathscr{F}$ of codimension one on $\mathbb{P}^{3}$ induced by: $$\omega = (z_{0}^{2} + z_{1}^{2} + z_{2}^{2})dz_{3} - (z_{3}z_{0} +  z_{2}z_{1})dz_{0} + (z_{2}z_{0} - z_{3}z_{1})dz_{1} - z_{3}z_{2}dz_{2}$$ It has as singular scheme : $\lbrace 2[i : -1 : 0 : 0], 2[i : 1 : 0 : 0], [0 : 0 : 0 : 1] \rbrace$ . Frankly, I don't know how to calculate the Grothendieck residue for singular points for the above distribution.  References on this subject and examples will be greatly appreciated. Thanks a lot.","In the article: Residues Of Codimension one Singular Holomorphic Distribution,  the author : Takeshi Izawa, states that: Theorem: Let an -dimensional compact complex manifold and a rank-one locally-free subsheaf of . We assume that the singular supports of are all isolated. Then we have: where above there is the Grothendieck residue. In this article, the author provides no example of how to calculate this residue. The Distribution of codimension one on induced by: It has as singular scheme : . Frankly, I don't know how to calculate the Grothendieck residue for singular points for the above distribution.  References on this subject and examples will be greatly appreciated. Thanks a lot.","X n \mathcal{G} \Omega_{X} \Omega_{X}/ \mathcal{G}  \int_{X}c_{n}(\Omega_{X} \otimes \mathcal{G}^{\vee}) = \displaystyle \sum_{j = 1}^{k}\text{Res}_{p_{j}}  \left[
\begin{array}{cccc}
df_{1}^{(j)} \wedge & \cdots & \wedge \,\, df_{n}^{(j)}\\
f_{1}^{(j)} \wedge & \cdots & \wedge f_{n}^{(j)}
\end{array}
\right]  \mathscr{F} \mathbb{P}^{3} \omega = (z_{0}^{2} + z_{1}^{2} + z_{2}^{2})dz_{3} - (z_{3}z_{0} +  z_{2}z_{1})dz_{0} + (z_{2}z_{0} - z_{3}z_{1})dz_{1} - z_{3}z_{2}dz_{2} \lbrace 2[i : -1 : 0 : 0], 2[i : 1 : 0 : 0], [0 : 0 : 0 : 1] \rbrace","['complex-analysis', 'algebraic-geometry', 'residue-calculus']"
45,Show that $e^z$ is continuous on $\mathbb{C}$,Show that  is continuous on,e^z \mathbb{C},"I know that $e^z$ is continuous on $\mathbb{R}$ , but how would I show this rigorously on $\mathbb{C}$ using the $\epsilon - \delta$ definition of continuity? I know how to begin: If $|z - z_0| < \delta$ then we want $|f(z) - f(z_0)| < \epsilon$ . To work backwards, I know we want to basically play around with $|f(z) - f(z_0)| = |e^z - e^{z_0}|$ and then pick $\delta$ to have some relationship with $\epsilon$ so that we get the inequality. However, I am having a hard time figuring out how to proceed with expanding $|e^z - e^{z_0}|$ in a way that gets me to a point where I can get $|z - z_0|$ to appear somewhere.","I know that is continuous on , but how would I show this rigorously on using the definition of continuity? I know how to begin: If then we want . To work backwards, I know we want to basically play around with and then pick to have some relationship with so that we get the inequality. However, I am having a hard time figuring out how to proceed with expanding in a way that gets me to a point where I can get to appear somewhere.",e^z \mathbb{R} \mathbb{C} \epsilon - \delta |z - z_0| < \delta |f(z) - f(z_0)| < \epsilon |f(z) - f(z_0)| = |e^z - e^{z_0}| \delta \epsilon |e^z - e^{z_0}| |z - z_0|,"['complex-analysis', 'complex-numbers', 'continuity', 'epsilon-delta']"
46,The Weierstrass map between a torus and an elliptic curve is biholomorphic,The Weierstrass map between a torus and an elliptic curve is biholomorphic,,Let $\Lambda$ be a lattice in $\mathbb C$. We can build by this lattice the Weierstrass $\wp$-function in the following manner: $$ \wp(z) = \frac{1}{z^2}+\sum\limits_{l\notin\Lambda\setminus\{0\}}\left(  \frac{1}{(z-l)^2} - \frac{1}{l^2}\right) $$ It can be shown that this function satisfies the following differential equation: $$ \wp'(z)^2 = 4\wp(z)^3 - 60G_4\wp(z) - 140 G_6 $$ This function gives us a map frop $\mathbb C/\Lambda$ to the elliptic curve $y^2 = 4x^3 - 60G_4 x - 140G_6$ in such a way: $$ z \mapsto [\wp(z):\wp'(z):1] $$ My question is: why this map is biholomorphic?,Let $\Lambda$ be a lattice in $\mathbb C$. We can build by this lattice the Weierstrass $\wp$-function in the following manner: $$ \wp(z) = \frac{1}{z^2}+\sum\limits_{l\notin\Lambda\setminus\{0\}}\left(  \frac{1}{(z-l)^2} - \frac{1}{l^2}\right) $$ It can be shown that this function satisfies the following differential equation: $$ \wp'(z)^2 = 4\wp(z)^3 - 60G_4\wp(z) - 140 G_6 $$ This function gives us a map frop $\mathbb C/\Lambda$ to the elliptic curve $y^2 = 4x^3 - 60G_4 x - 140G_6$ in such a way: $$ z \mapsto [\wp(z):\wp'(z):1] $$ My question is: why this map is biholomorphic?,,"['complex-analysis', 'elliptic-curves']"
47,Does there necessarily exist such a holomorphic function?,Does there necessarily exist such a holomorphic function?,,"This is an old qual problem I'm working on: Let $f:[0,1]\rightarrow \mathbb{R}$ be a $C^{\infty}$ function. Does there necessarily exist a holomorphic function $g: \mathbb{C}\setminus\{0\}\rightarrow \mathbb{C}$ such that $f(x)-g(x)$ vanishes to infinite order at $0$ as $x$ tends to $0$ in $[0,1]$? To be honest, maybe I couldn't make much progress on this. I tried to write Laurent series for $0$, and using the given condition, tried to conclude that if such a $g$ exists, it must be analytically extended to $0$ too. Then, I tried to find such an $f$ that cannot be extended analytically to the whole plane, but failed. But, my reasoning here might be very false, I'm not sure. I would appreciate any kind of help. Thanks!","This is an old qual problem I'm working on: Let $f:[0,1]\rightarrow \mathbb{R}$ be a $C^{\infty}$ function. Does there necessarily exist a holomorphic function $g: \mathbb{C}\setminus\{0\}\rightarrow \mathbb{C}$ such that $f(x)-g(x)$ vanishes to infinite order at $0$ as $x$ tends to $0$ in $[0,1]$? To be honest, maybe I couldn't make much progress on this. I tried to write Laurent series for $0$, and using the given condition, tried to conclude that if such a $g$ exists, it must be analytically extended to $0$ too. Then, I tried to find such an $f$ that cannot be extended analytically to the whole plane, but failed. But, my reasoning here might be very false, I'm not sure. I would appreciate any kind of help. Thanks!",,"['complex-analysis', 'analyticity', 'analytic-continuation']"
48,The Duplication Formula for the Gamma Function by logarithmic derivatives.,The Duplication Formula for the Gamma Function by logarithmic derivatives.,,"I was reading Ahlfors' ""Complex Analysis"" (second edition) and in Chapter 5, section 2.4, where he studies the Gamma Function, he proves Legendre's Duplication Formula: $$\sqrt{\pi}\Gamma(2z)=2^{2z-1}\Gamma(z)\Gamma\left(z+\frac{1}{2}\right).$$His deduction begins with the fact that$$\frac{d}{dz}\left(\frac{\Gamma'(z)}{\Gamma(z)}\right)=\sum_{n=0}^{\infty}\frac{1}{(z+n)^2}$$(where I don't have any problem deducing) and considers the sum $$ \frac{d}{dz}\left(\frac{\Gamma'\left(z\right)}{\Gamma\left(z\right)}\right)+\frac{d}{dz}\left(\frac{\Gamma'\left(z+\frac{1}{2}\right)}{\Gamma\left(z+\frac{1}{2}\right)}\right)	=	\sum_{n=0}^{\infty}\frac{1}{\left(z+n\right)^{2}}+\sum_{n=0}^{\infty}\frac{1}{\left(z+n+\frac{1}{2}\right)^{2}} 	=	4\left[\sum_{n=0}^{\infty}\frac{1}{\left(2z+2n\right)^{2}}+\sum_{n=0}^{\infty}\frac{1}{\left(2z+2n+1\right)^{2}}\right] 	=	4\sum_{m=0}^{\infty}\frac{1}{\left(2z+m\right)^{2}}.  $$I fully understand these simple calculations, however, Ahlfors then states that the last series is equal to $$ 2\frac{d}{dz}\left(\frac{\Gamma'(2z)}{\Gamma{2z}}\right).  $$ According to the first equation, shouldn't the coefficient be 4? My other question is after the differential equation is integrated two times and then exponentiated. According to Ahlfors, after integrating twice and exponentiating, the expression turns to $$ \Gamma(z)\Gamma\left(z+\frac{1}{2}\right)=e^{az+b}\Gamma(2z) $$ where $a$ and $b$ are constants, my question is: shouldn't to equation be $$\Gamma(z)\Gamma\left(z+\frac{1}{2}\right)=e^{az+b}\left(\Gamma(2z)\right)^2$$becuase of the coefficient 2 preceding the left hand side of the differential equation? (Or elevated to the fourth power as my first question would suggest?) I know that the duplication formula is correctly stated in Ahlfors' book and I know I'm either missing something or (perhaps less probably) Ahlfors is missing something.","I was reading Ahlfors' ""Complex Analysis"" (second edition) and in Chapter 5, section 2.4, where he studies the Gamma Function, he proves Legendre's Duplication Formula: $$\sqrt{\pi}\Gamma(2z)=2^{2z-1}\Gamma(z)\Gamma\left(z+\frac{1}{2}\right).$$His deduction begins with the fact that$$\frac{d}{dz}\left(\frac{\Gamma'(z)}{\Gamma(z)}\right)=\sum_{n=0}^{\infty}\frac{1}{(z+n)^2}$$(where I don't have any problem deducing) and considers the sum $$ \frac{d}{dz}\left(\frac{\Gamma'\left(z\right)}{\Gamma\left(z\right)}\right)+\frac{d}{dz}\left(\frac{\Gamma'\left(z+\frac{1}{2}\right)}{\Gamma\left(z+\frac{1}{2}\right)}\right)	=	\sum_{n=0}^{\infty}\frac{1}{\left(z+n\right)^{2}}+\sum_{n=0}^{\infty}\frac{1}{\left(z+n+\frac{1}{2}\right)^{2}} 	=	4\left[\sum_{n=0}^{\infty}\frac{1}{\left(2z+2n\right)^{2}}+\sum_{n=0}^{\infty}\frac{1}{\left(2z+2n+1\right)^{2}}\right] 	=	4\sum_{m=0}^{\infty}\frac{1}{\left(2z+m\right)^{2}}.  $$I fully understand these simple calculations, however, Ahlfors then states that the last series is equal to $$ 2\frac{d}{dz}\left(\frac{\Gamma'(2z)}{\Gamma{2z}}\right).  $$ According to the first equation, shouldn't the coefficient be 4? My other question is after the differential equation is integrated two times and then exponentiated. According to Ahlfors, after integrating twice and exponentiating, the expression turns to $$ \Gamma(z)\Gamma\left(z+\frac{1}{2}\right)=e^{az+b}\Gamma(2z) $$ where $a$ and $b$ are constants, my question is: shouldn't to equation be $$\Gamma(z)\Gamma\left(z+\frac{1}{2}\right)=e^{az+b}\left(\Gamma(2z)\right)^2$$becuase of the coefficient 2 preceding the left hand side of the differential equation? (Or elevated to the fourth power as my first question would suggest?) I know that the duplication formula is correctly stated in Ahlfors' book and I know I'm either missing something or (perhaps less probably) Ahlfors is missing something.",,"['complex-analysis', 'gamma-function']"
49,If $f'(z_0)\neq 0$ then $f$ has an holomorphic inverse.,If  then  has an holomorphic inverse.,f'(z_0)\neq 0 f,"Problem: Let $U\subset\mathbb{C}$ be an open set, $f:U\to\mathbb{C}$ an holomorphic function of class $C^1$ and $z_0\in U$. Prove that if $f'(z_0)\neq 0$ then there exists a neighborhood $V$ of $z_0$ such that the restriction of $f$ to $V$ has an holomorphic inverse. I would like to know if the solution below is correct/acceptable. This exercise was taken of a section that studies the Inverse Function Theorem for mappings from $U\subset\mathbb{R}^m$ to $\mathbb{R}^m$. Solution: Since  \begin{matrix} f & : & U& \longrightarrow & \mathbb{C}\\   &  & (x,y) & \longmapsto & (u(x,y),v(x,y)) \end{matrix} is holomorphic, we conclude that $u,v:U\longrightarrow\mathbb{C}$ are differentiable and $$\frac{\partial u}{\partial x}=\frac{\partial v}{\partial y},\quad\frac{\partial u}{\partial y}=-\frac{\partial v}{\partial x}.$$ It follows that $$\det J_f(z_0)=\left(\frac{\partial u}{\partial x}(z_0)\right)^2+\left(\frac{\partial u}{\partial y}(z_0)\right)^2\neq0$$ because $$\left(\frac{\partial u}{\partial x}(z_0),-\frac{\partial u}{\partial y}(z_0)\right)=f'(z_0)\neq 0.$$ So, by Inverse Function Theorem, there exists a neighborhood $V$ of $z_0$ and an open set $W\ni f(z_0)$ such that $f|_V:V\to W$ is a diffeomorphism and thus has a differentiable inverse \begin{matrix} (f|_V)^{-1} & : & W& \longrightarrow & V\\   &  & (x,y) & \longmapsto & (\tilde{u}(x,y),\tilde{v}(x,y)) \end{matrix} Furthermore, for all $v\in \mathbb{R}^2$, $$\left((f|_V)^{-1}\right)'(f(z_0))\cdot v=(f'(z_0))^{-1}\cdot v= \begin{vmatrix} \frac{\partial u}{\partial x} (z_0)& \frac{\partial u}{\partial y}(z_0)\\  -\frac{\partial u}{\partial y}(z_0)& \frac{\partial u}{\partial x}(z_0) \end{vmatrix}^{-1}v= \frac{1}{\det J_f(z_0)}\begin{vmatrix} \frac{\partial u}{\partial x}(z_0) & -\frac{\partial u}{\partial y}(z_0)\\  \frac{\partial u}{\partial y}(z_0)& \frac{\partial u}{\partial x}(z_0) \end{vmatrix}v$$ and thus $$\frac{\partial \tilde{u}}{\partial x}(f(z_0))=\frac{\partial \tilde{v}}{\partial y}(f(z_0)),\quad  \frac{\partial \tilde{u}}{\partial y}(f(z_0))=-\frac{\partial \tilde{v}}{\partial x}(f(z_0)).$$ For any point $p=f(z)\in W$, we have $\det J_f(z)\neq 0$ (because $f|_V$ is a diffeomorphism) so that we can apply a similar argument to conclude that  $$\frac{\partial \tilde{u}}{\partial x}(f(z))=\frac{\partial \tilde{v}}{\partial y}(f(z)),\quad  \frac{\partial \tilde{u}}{\partial y}(f(z))=-\frac{\partial \tilde{v}}{\partial x}(f(z)).$$ Hence, $(f|_V)^{-1}$ is holomorphic. $\blacksquare$ Thanks.","Problem: Let $U\subset\mathbb{C}$ be an open set, $f:U\to\mathbb{C}$ an holomorphic function of class $C^1$ and $z_0\in U$. Prove that if $f'(z_0)\neq 0$ then there exists a neighborhood $V$ of $z_0$ such that the restriction of $f$ to $V$ has an holomorphic inverse. I would like to know if the solution below is correct/acceptable. This exercise was taken of a section that studies the Inverse Function Theorem for mappings from $U\subset\mathbb{R}^m$ to $\mathbb{R}^m$. Solution: Since  \begin{matrix} f & : & U& \longrightarrow & \mathbb{C}\\   &  & (x,y) & \longmapsto & (u(x,y),v(x,y)) \end{matrix} is holomorphic, we conclude that $u,v:U\longrightarrow\mathbb{C}$ are differentiable and $$\frac{\partial u}{\partial x}=\frac{\partial v}{\partial y},\quad\frac{\partial u}{\partial y}=-\frac{\partial v}{\partial x}.$$ It follows that $$\det J_f(z_0)=\left(\frac{\partial u}{\partial x}(z_0)\right)^2+\left(\frac{\partial u}{\partial y}(z_0)\right)^2\neq0$$ because $$\left(\frac{\partial u}{\partial x}(z_0),-\frac{\partial u}{\partial y}(z_0)\right)=f'(z_0)\neq 0.$$ So, by Inverse Function Theorem, there exists a neighborhood $V$ of $z_0$ and an open set $W\ni f(z_0)$ such that $f|_V:V\to W$ is a diffeomorphism and thus has a differentiable inverse \begin{matrix} (f|_V)^{-1} & : & W& \longrightarrow & V\\   &  & (x,y) & \longmapsto & (\tilde{u}(x,y),\tilde{v}(x,y)) \end{matrix} Furthermore, for all $v\in \mathbb{R}^2$, $$\left((f|_V)^{-1}\right)'(f(z_0))\cdot v=(f'(z_0))^{-1}\cdot v= \begin{vmatrix} \frac{\partial u}{\partial x} (z_0)& \frac{\partial u}{\partial y}(z_0)\\  -\frac{\partial u}{\partial y}(z_0)& \frac{\partial u}{\partial x}(z_0) \end{vmatrix}^{-1}v= \frac{1}{\det J_f(z_0)}\begin{vmatrix} \frac{\partial u}{\partial x}(z_0) & -\frac{\partial u}{\partial y}(z_0)\\  \frac{\partial u}{\partial y}(z_0)& \frac{\partial u}{\partial x}(z_0) \end{vmatrix}v$$ and thus $$\frac{\partial \tilde{u}}{\partial x}(f(z_0))=\frac{\partial \tilde{v}}{\partial y}(f(z_0)),\quad  \frac{\partial \tilde{u}}{\partial y}(f(z_0))=-\frac{\partial \tilde{v}}{\partial x}(f(z_0)).$$ For any point $p=f(z)\in W$, we have $\det J_f(z)\neq 0$ (because $f|_V$ is a diffeomorphism) so that we can apply a similar argument to conclude that  $$\frac{\partial \tilde{u}}{\partial x}(f(z))=\frac{\partial \tilde{v}}{\partial y}(f(z)),\quad  \frac{\partial \tilde{u}}{\partial y}(f(z))=-\frac{\partial \tilde{v}}{\partial x}(f(z)).$$ Hence, $(f|_V)^{-1}$ is holomorphic. $\blacksquare$ Thanks.",,"['complex-analysis', 'multivariable-calculus', 'proof-verification']"
50,universal covering of punctured plane and Poincaré metric,universal covering of punctured plane and Poincaré metric,,"I want to prove the following result: Let $\Omega$ be the domain $\mathbb{C}\backslash \{a_1,a_2,a_3,a_4\}$. Its universal covering is the unit disk, and the standard Poincaré metric is pulled back to a metric $ds=\rho(z)|dz| $ on $\Omega$. For $\rho(z)$ we have the asymptotic expansions $$\rho(z)\sim \frac{C_j}{|z-a_j|\log|z-a_j|} \text{as}\  z\rightarrow a_j$$ and $$\rho(z)\sim \frac{C_0}{|z|\log|z|} \text{as}\  z\rightarrow \infty$$  where $C_j$ are constants different from zero. Is it possible to give an elementary proof, accessible to someone who has little knowledge on Riemann surfaces?","I want to prove the following result: Let $\Omega$ be the domain $\mathbb{C}\backslash \{a_1,a_2,a_3,a_4\}$. Its universal covering is the unit disk, and the standard Poincaré metric is pulled back to a metric $ds=\rho(z)|dz| $ on $\Omega$. For $\rho(z)$ we have the asymptotic expansions $$\rho(z)\sim \frac{C_j}{|z-a_j|\log|z-a_j|} \text{as}\  z\rightarrow a_j$$ and $$\rho(z)\sim \frac{C_0}{|z|\log|z|} \text{as}\  z\rightarrow \infty$$  where $C_j$ are constants different from zero. Is it possible to give an elementary proof, accessible to someone who has little knowledge on Riemann surfaces?",,['complex-analysis']
51,Any general methods to calculate integral of $P(x)/Q(x)$ from $0$ to $\infty$?,Any general methods to calculate integral of  from  to ?,P(x)/Q(x) 0 \infty,"In complex analysis, we have general formula for $P(x)/Q(x)$ [$P$ and $Q$ are polynomials] from minus infinity to infinity, if $ \deg Q - \deg P > 2$. Is it possible to have a general formula for improper integral of P(x)/Q(x) from 0 to infinity? Like, $$\int_0^{\infty} \frac{1}{1+x^3} \mathrm{d} x =\frac{2\pi}{3\sqrt{3}} $$ $$\int_0^{\infty} \frac{1}{1+x+x^2+x^3} \mathrm{d} x =\frac{\pi}{4}$$ $$\int_0^{\infty} \frac{1}{(x+1)(x+2)(x+3)} \mathrm{d} x=\frac{\ln(4/3)}{2}$$","In complex analysis, we have general formula for $P(x)/Q(x)$ [$P$ and $Q$ are polynomials] from minus infinity to infinity, if $ \deg Q - \deg P > 2$. Is it possible to have a general formula for improper integral of P(x)/Q(x) from 0 to infinity? Like, $$\int_0^{\infty} \frac{1}{1+x^3} \mathrm{d} x =\frac{2\pi}{3\sqrt{3}} $$ $$\int_0^{\infty} \frac{1}{1+x+x^2+x^3} \mathrm{d} x =\frac{\pi}{4}$$ $$\int_0^{\infty} \frac{1}{(x+1)(x+2)(x+3)} \mathrm{d} x=\frac{\ln(4/3)}{2}$$",,"['complex-analysis', 'improper-integrals', 'complex-integration']"
52,Constructing Riemann surfaces,Constructing Riemann surfaces,,"At the risk of asking a question that has been already answered, I have been trying to figure out how to construct the Riemann surface of slightly more complicated examples, but after reading examples in Alfors; Churchill and Brown; Gamelin; Silverman and several existing examples here, I feel like I have a good intuition of examples such as $w=\sqrt[n]{z}$ or the logarithm, but I am unable to take that understanding and go much further. For example, I would like to try to find a Riemann surface with an intersecting branch cut. It seems like a nice way to do this is to take a function like $$f(z) = \sqrt[4]{(z-1)(z+1)(z-i)(z+i)}.$$ From my perspective, $f(z)$ is a four-valued function everywhere except the points $z=1,-1,i,-i,\infty$ where it is only a single valued function. As such, I would need four sheets and from there my ability to go further promptly falls flat on its face. I have a very strong inclination to construct my branch cut as a ""+"" shape connecting the four points $i,-i,1,-1$ respectively, but this seems like a poor choice for a few reasons: I am defining a branch cut between -1 and 1, then another cut running between -i and i. The intersection seems bad to me, but I cannot justify whether or not it truly matters. If I do this, it seems like we can traverse from any of the four sheets by passing through the origin. In that sense, if I define my branch cuts in this manner, I think I am introducing a new point where $f$ is four-valued at the origin. I think in that case, I have to then run a third branch cut connecting the origin to the point at infinity. If I make this choice, I have no clue how to actually begin the gluing process for my sheets. It seems like a smarter way might be to define four rays originating at the four points $i,-i,1,-1$ and sending them each off to infinity. But to remark on item 3 again, even if I do that I am not quite sure how to align these cuts (also I am not sure if we can choose our branch cut so that this makes sense). In the case of this four ray choice I just described,  I think I have two options: Construct glue my sheets such that starting on sheet #1, going around any of the points $1,-1,i,-i$ in a closed positively oriented curve will always take me to sheet 2, then sheet 3, then sheet 4. While going in the opposite orientation takes me to sheet 4, then 3, then 2 then 1. That is, from sheet #1, I can only travel to sheet 2 or 4, but I cannot skip to sheet 3 without traversing through 2 or 4 (but then what happens when I try to make a closed curve through the point at infinity?). Alternatively, it seems like it might be possible to glue the sheets in such a way that I can traverse from sheet 1 to any of the 3 remaining sheets without visiting a different sheet to get there. This motivates why I chose the four root as my example of interest: In the case of a cubic root, we can always traverse from one sheet to another without visiting any intermediary sheets. Finally, using the Riemann-Hurwitz formula, $$2-2g^{\prime} = n(2-2g)-\sum_{P}(e_{p}-1)$$ is causing me issues because it is not obvious to me how to determine the value of $g$. I think in the case of a complex plane, this value of $g$ must always be zero since we just have an complex plane which has no ""holes"".","At the risk of asking a question that has been already answered, I have been trying to figure out how to construct the Riemann surface of slightly more complicated examples, but after reading examples in Alfors; Churchill and Brown; Gamelin; Silverman and several existing examples here, I feel like I have a good intuition of examples such as $w=\sqrt[n]{z}$ or the logarithm, but I am unable to take that understanding and go much further. For example, I would like to try to find a Riemann surface with an intersecting branch cut. It seems like a nice way to do this is to take a function like $$f(z) = \sqrt[4]{(z-1)(z+1)(z-i)(z+i)}.$$ From my perspective, $f(z)$ is a four-valued function everywhere except the points $z=1,-1,i,-i,\infty$ where it is only a single valued function. As such, I would need four sheets and from there my ability to go further promptly falls flat on its face. I have a very strong inclination to construct my branch cut as a ""+"" shape connecting the four points $i,-i,1,-1$ respectively, but this seems like a poor choice for a few reasons: I am defining a branch cut between -1 and 1, then another cut running between -i and i. The intersection seems bad to me, but I cannot justify whether or not it truly matters. If I do this, it seems like we can traverse from any of the four sheets by passing through the origin. In that sense, if I define my branch cuts in this manner, I think I am introducing a new point where $f$ is four-valued at the origin. I think in that case, I have to then run a third branch cut connecting the origin to the point at infinity. If I make this choice, I have no clue how to actually begin the gluing process for my sheets. It seems like a smarter way might be to define four rays originating at the four points $i,-i,1,-1$ and sending them each off to infinity. But to remark on item 3 again, even if I do that I am not quite sure how to align these cuts (also I am not sure if we can choose our branch cut so that this makes sense). In the case of this four ray choice I just described,  I think I have two options: Construct glue my sheets such that starting on sheet #1, going around any of the points $1,-1,i,-i$ in a closed positively oriented curve will always take me to sheet 2, then sheet 3, then sheet 4. While going in the opposite orientation takes me to sheet 4, then 3, then 2 then 1. That is, from sheet #1, I can only travel to sheet 2 or 4, but I cannot skip to sheet 3 without traversing through 2 or 4 (but then what happens when I try to make a closed curve through the point at infinity?). Alternatively, it seems like it might be possible to glue the sheets in such a way that I can traverse from sheet 1 to any of the 3 remaining sheets without visiting a different sheet to get there. This motivates why I chose the four root as my example of interest: In the case of a cubic root, we can always traverse from one sheet to another without visiting any intermediary sheets. Finally, using the Riemann-Hurwitz formula, $$2-2g^{\prime} = n(2-2g)-\sum_{P}(e_{p}-1)$$ is causing me issues because it is not obvious to me how to determine the value of $g$. I think in the case of a complex plane, this value of $g$ must always be zero since we just have an complex plane which has no ""holes"".",,"['complex-analysis', 'manifolds', 'riemann-surfaces']"
53,Applications of conformal mapping,Applications of conformal mapping,,"The idea is through conformal transformations satisfying the conditions requested of the problem  make this an easier problem to deal,but i don't know which be this transformation. I would appreciate any hint how to solve this. thank you very much","The idea is through conformal transformations satisfying the conditions requested of the problem  make this an easier problem to deal,but i don't know which be this transformation. I would appreciate any hint how to solve this. thank you very much",,['complex-analysis']
54,Continuous extension of analytic functions,Continuous extension of analytic functions,,"Is it possible to prove the following statement or is there a counter-example: Let $H=\{y>0\}$ be the upper half plane in the complex plane. If $f$ is an analytic function on $H$ and its real part is continuously extendable on the closure of $H$, which is $\overline H$, then $f$ is continuously extendable on $\overline H$.","Is it possible to prove the following statement or is there a counter-example: Let $H=\{y>0\}$ be the upper half plane in the complex plane. If $f$ is an analytic function on $H$ and its real part is continuously extendable on the closure of $H$, which is $\overline H$, then $f$ is continuously extendable on $\overline H$.",,"['complex-analysis', 'continuity']"
55,Inverse Laplace transform of $\frac{\log(s)}{1 + s}$,Inverse Laplace transform of,\frac{\log(s)}{1 + s},"Is it possible to find the inverse laplace transform $$\mathcal{L}^{-1}\frac{\log(s)}{1 + s}$$ using the Bromwich integral formula $$\mathcal{L}^{-1} \{F(s)\}(t) = f(t) = \frac{1}{2\pi i}\lim_{T\to\infty}\int_{\gamma-iT}^{\gamma+iT}e^{st}F(s)\,ds$$  I'm having trouble coming up with a suitable contour to use.  If the denominator were $1 - s$, then the pole would be in the right hand plane and the residue theorem would reduce the integral to the sum of the residues plus the integral around the branch cut.  But with this one, the pole is in the left hand plane where the branch cut should be.  Instead of setting $\gamma = 1$ as it must be in the case where the denominator is $1 - s$, can I set $\gamma = 0$, run the contour down the real axis and detour around the origin? I'm not sure if this is allowed, or will work.  Thanks for any advice.","Is it possible to find the inverse laplace transform $$\mathcal{L}^{-1}\frac{\log(s)}{1 + s}$$ using the Bromwich integral formula $$\mathcal{L}^{-1} \{F(s)\}(t) = f(t) = \frac{1}{2\pi i}\lim_{T\to\infty}\int_{\gamma-iT}^{\gamma+iT}e^{st}F(s)\,ds$$  I'm having trouble coming up with a suitable contour to use.  If the denominator were $1 - s$, then the pole would be in the right hand plane and the residue theorem would reduce the integral to the sum of the residues plus the integral around the branch cut.  But with this one, the pole is in the left hand plane where the branch cut should be.  Instead of setting $\gamma = 1$ as it must be in the case where the denominator is $1 - s$, can I set $\gamma = 0$, run the contour down the real axis and detour around the origin? I'm not sure if this is allowed, or will work.  Thanks for any advice.",,"['complex-analysis', 'laplace-transform', 'contour-integration']"
56,Power series and singularity,Power series and singularity,,"Consider the power series $\sum a_n z^n$.Given that $a_n$ converges to $0$, prove that    $f(z)$ cannot have pole on the unit circle, where $f(z)$ is the function represented by the power series in the question. EDIT I have thought an answer for it. Since $a_n$ converges to $0$, we can write $\lvert a_n \rvert <1$ for all $n >N_0$. From here, we can say radius of convergence of the power series is bigger than or equal to $1$. If the radius of convergence is bigger than $1$, the series converges on the unit circle. If it is equal to $1$, then points on the unit circle cannot be an isolated singularity. But I am not sure of my answer.","Consider the power series $\sum a_n z^n$.Given that $a_n$ converges to $0$, prove that    $f(z)$ cannot have pole on the unit circle, where $f(z)$ is the function represented by the power series in the question. EDIT I have thought an answer for it. Since $a_n$ converges to $0$, we can write $\lvert a_n \rvert <1$ for all $n >N_0$. From here, we can say radius of convergence of the power series is bigger than or equal to $1$. If the radius of convergence is bigger than $1$, the series converges on the unit circle. If it is equal to $1$, then points on the unit circle cannot be an isolated singularity. But I am not sure of my answer.",,[]
57,The power series $\sum\limits_{n=1}^{\infty} \frac {z^{n} }{ n^{2}} \ $,The power series,\sum\limits_{n=1}^{\infty} \frac {z^{n} }{ n^{2}} \ ,This is an exercise from Remmert. The power series $\sum\limits_{n=1}^{\infty} \frac {z^{n} }{ n^{2}} \ $ has radius of convergence $1 \ $. Show that the function it represents is injective in $\{ z \in \mathbb{C} | \ \ \lVert z \rVert < \frac{2}{3}  \} \ $. The text gives the hint: $z^n -w^n = (z-w)\ ( z^{n-1}+z^{n-2}w + \ldots + w^{n-1} ) \ $.,This is an exercise from Remmert. The power series $\sum\limits_{n=1}^{\infty} \frac {z^{n} }{ n^{2}} \ $ has radius of convergence $1 \ $. Show that the function it represents is injective in $\{ z \in \mathbb{C} | \ \ \lVert z \rVert < \frac{2}{3}  \} \ $. The text gives the hint: $z^n -w^n = (z-w)\ ( z^{n-1}+z^{n-2}w + \ldots + w^{n-1} ) \ $.,,"['complex-analysis', 'power-series']"
58,Finding a Möbius transformation,Finding a Möbius transformation,,"Let $f$ be a holomorphic mapping from {$z:\Re(z)>0$} into itself. Let $1$ be a fixed point of $f$. In addition suppose that $\left|\frac{f(2)-1}{f(2)+1}\right|=\frac13$. I want to show that $f(z)=\frac{az+b}{bz+a}$ where $a=1+e^{i\theta}$ and $b=1-e^{i\theta}$ for some $\theta$. I tried looking at this problem in different ways, I just don't know what to do. Of course if $f(z)=\frac{az+b}{cz+d}$ then I have the obvious $a+b=c+d$. And when I look at  $\left|\frac{f(2)-1}{f(2)+1}\right|=\frac13,$ this actually looks like  $\left|\frac{f(2)-f(1)}{f(2)+f(1)}\right|=\frac13,$ but I don't know what to do with this last expression or if it is useful at all to write things this way and compute this expression. In general I know that a Möbius transformation has at most 2 fixed points and can be written as a composition of inversions, rotations, dilations and translations. Thanks.","Let $f$ be a holomorphic mapping from {$z:\Re(z)>0$} into itself. Let $1$ be a fixed point of $f$. In addition suppose that $\left|\frac{f(2)-1}{f(2)+1}\right|=\frac13$. I want to show that $f(z)=\frac{az+b}{bz+a}$ where $a=1+e^{i\theta}$ and $b=1-e^{i\theta}$ for some $\theta$. I tried looking at this problem in different ways, I just don't know what to do. Of course if $f(z)=\frac{az+b}{cz+d}$ then I have the obvious $a+b=c+d$. And when I look at  $\left|\frac{f(2)-1}{f(2)+1}\right|=\frac13,$ this actually looks like  $\left|\frac{f(2)-f(1)}{f(2)+f(1)}\right|=\frac13,$ but I don't know what to do with this last expression or if it is useful at all to write things this way and compute this expression. In general I know that a Möbius transformation has at most 2 fixed points and can be written as a composition of inversions, rotations, dilations and translations. Thanks.",,"['complex-analysis', 'conformal-geometry']"
59,Möbius Transforms that preserve the unit disk,Möbius Transforms that preserve the unit disk,,"Prove that every automorphism of the unit disc can be written in the following form: $A(z) = e^{i\theta}\frac{z+a}{1+\bar{a}z}$ , where $\theta$ is a real number and $a$ is a point in the unit disk which is defined to be $\mathbb{D} = \{z \in \mathbb{C} : |z|<1\}$ . The general element of a möbius transform that preserves the extended real line is any one of the four möbius transforms of the following kind (I'll only state one) $m(z)= \frac{az+b}{cz+d}, a,b,c,d \in \mathbb{R}$ and $ad-bc = 1$ . Now let $p$ be a möbius transform that maps the extended real line to the unit circle. It can be shown that the choice of $p$ does not matter, so i'll just take $p(z) = \frac{z-i}{z+i}$ . Any möbius transform that preserves the unit circle is of the form $p \circ m \circ p$ , where $m$ is any one of the möbius transforms that preserves the extended real line, $\mathbb{\bar{R}}$ . Of course to check if a point in the unit circle still remains in the unit circle, I'll have to check and if it does not I can apply combine the above with $K(z) = \frac{-1}{z}$ . The problem With many choices of $m$ in fact for all 4 I would have to check and write down $p^{-1} (z)$ and do compositions of functions and other things. The algebra is messy, but what's even worse is it tells me nothing of whether the coefficient of $z$ is a complex number that is within the disk (as what is asked to be proved). Is there a simpler way?","Prove that every automorphism of the unit disc can be written in the following form: , where is a real number and is a point in the unit disk which is defined to be . The general element of a möbius transform that preserves the extended real line is any one of the four möbius transforms of the following kind (I'll only state one) and . Now let be a möbius transform that maps the extended real line to the unit circle. It can be shown that the choice of does not matter, so i'll just take . Any möbius transform that preserves the unit circle is of the form , where is any one of the möbius transforms that preserves the extended real line, . Of course to check if a point in the unit circle still remains in the unit circle, I'll have to check and if it does not I can apply combine the above with . The problem With many choices of in fact for all 4 I would have to check and write down and do compositions of functions and other things. The algebra is messy, but what's even worse is it tells me nothing of whether the coefficient of is a complex number that is within the disk (as what is asked to be proved). Is there a simpler way?","A(z) = e^{i\theta}\frac{z+a}{1+\bar{a}z} \theta a \mathbb{D} = \{z \in \mathbb{C} : |z|<1\} m(z)= \frac{az+b}{cz+d}, a,b,c,d \in \mathbb{R} ad-bc = 1 p p p(z) = \frac{z-i}{z+i} p \circ m \circ p m \mathbb{\bar{R}} K(z) = \frac{-1}{z} m p^{-1} (z) z",['complex-analysis']
60,$\int_{-\infty}^\infty \frac{e^{pz}}{e^z-1}dz$ Cauchy principal value,Cauchy principal value,\int_{-\infty}^\infty \frac{e^{pz}}{e^z-1}dz,"$$\int_{-\infty}^\infty \frac{e^{pz}}{e^z-1}dz$$ I started by defining the following contour: rectangular contour It is easy to show that the integrals along the 2 vertical sides of the rectangle go to $0$ as $R\Rightarrow\infty$ by applying the triangle inequality for integrals. Note that we must have $0<p<1$ for this to work. For the integral along the top side of the rectangle we define $z=x+\pi i$ so the integral becomes: $$\int_{R}^{-R} \frac{e^{p(x+\pi i)}}{e^{x+\pi i}-1}dx$$ Using some basic algebra and taking the limit as $R\Rightarrow\infty$ this simplifies to: $${e^{p \pi i}}\int_{-\infty}^{\infty} \frac{e^{px}}{e^{x}+1}dx$$ This integral has a known solution and plugging this solution in yields: $${e^{p \pi i}} {\frac{\pi}{\sin{p \pi}}}$$ Now we need to tackle the integral over the semi-circle and to do so we define: $z=\epsilon e^{i \theta}$ so $dz=i \epsilon e^{i \theta} d\theta$ and $-\pi \leq \theta \leq 0$ The integral becomes: $$\int_{- \pi}^{0} \frac{e^{p \epsilon e^{i \theta}}}{e^{\epsilon e^{i \theta}}-1} i \epsilon e^{i \theta}d\theta$$ Taking the limit as $\epsilon \Rightarrow 0$ using l'Hopital's rule we get: $$\int_{- \pi}^{0} \frac{e^{p \epsilon e^{i \theta}}}{e^{\epsilon e^{i \theta}}-1} i \epsilon e^{i \theta}d\theta = i \pi$$ Putting everything together and using the fact that the closed contour integral is zero since there are no singularities inside the contour yields. I let WolframAlpha do the simplification: $$\int_{-\infty}^\infty \frac{e^{pz}}{e^z-1}dz = -\pi \cot{(p \pi)} -2 \pi i$$ In my opinion this seems weird because the integrand is real for all inputs of z except $0$ . I expected the cauchy principal value, which this integral actually is because it blows up at $0$ , to be real valued as well. Unfortunately my calculations show that this integral is complex valued. Could someone please tell me if I did something wrong or not. I found an article which also has this integral covered but I believe there is a mistake in their calculation of the integral along the semi-circle (they forgot a minus sign), which if corrected results in the same answer I got. link: article covering the integral . Any help is greatly appreciated! PS: I am 17 years old so this is my first post on this forum, if there are any (informal) rules which I am not aware of please let me know as well!","I started by defining the following contour: rectangular contour It is easy to show that the integrals along the 2 vertical sides of the rectangle go to as by applying the triangle inequality for integrals. Note that we must have for this to work. For the integral along the top side of the rectangle we define so the integral becomes: Using some basic algebra and taking the limit as this simplifies to: This integral has a known solution and plugging this solution in yields: Now we need to tackle the integral over the semi-circle and to do so we define: so and The integral becomes: Taking the limit as using l'Hopital's rule we get: Putting everything together and using the fact that the closed contour integral is zero since there are no singularities inside the contour yields. I let WolframAlpha do the simplification: In my opinion this seems weird because the integrand is real for all inputs of z except . I expected the cauchy principal value, which this integral actually is because it blows up at , to be real valued as well. Unfortunately my calculations show that this integral is complex valued. Could someone please tell me if I did something wrong or not. I found an article which also has this integral covered but I believe there is a mistake in their calculation of the integral along the semi-circle (they forgot a minus sign), which if corrected results in the same answer I got. link: article covering the integral . Any help is greatly appreciated! PS: I am 17 years old so this is my first post on this forum, if there are any (informal) rules which I am not aware of please let me know as well!",\int_{-\infty}^\infty \frac{e^{pz}}{e^z-1}dz 0 R\Rightarrow\infty 0<p<1 z=x+\pi i \int_{R}^{-R} \frac{e^{p(x+\pi i)}}{e^{x+\pi i}-1}dx R\Rightarrow\infty {e^{p \pi i}}\int_{-\infty}^{\infty} \frac{e^{px}}{e^{x}+1}dx {e^{p \pi i}} {\frac{\pi}{\sin{p \pi}}} z=\epsilon e^{i \theta} dz=i \epsilon e^{i \theta} d\theta -\pi \leq \theta \leq 0 \int_{- \pi}^{0} \frac{e^{p \epsilon e^{i \theta}}}{e^{\epsilon e^{i \theta}}-1} i \epsilon e^{i \theta}d\theta \epsilon \Rightarrow 0 \int_{- \pi}^{0} \frac{e^{p \epsilon e^{i \theta}}}{e^{\epsilon e^{i \theta}}-1} i \epsilon e^{i \theta}d\theta = i \pi \int_{-\infty}^\infty \frac{e^{pz}}{e^z-1}dz = -\pi \cot{(p \pi)} -2 \pi i 0 0,"['complex-analysis', 'definite-integrals', 'improper-integrals', 'contour-integration', 'cauchy-principal-value']"
61,Fourier transform of $e^{-i\lambda\sqrt{1+x^2}}$ - asymptotics for $\lambda$?,Fourier transform of  - asymptotics for ?,e^{-i\lambda\sqrt{1+x^2}} \lambda,"As the title says: I want to compute the Fourier transform (in the distributional sense) of $f(x)=e^{-i\sqrt{1+x^2}}$ , $x\in \mathbb{R}^n$ - say $n=1$ for the moment. I have no idea how to get it done: I have tried with the usual machinery (""ODE approach"" like for the Gaussian, explicit computations, estimates for oscillatory integrals, complex analysis) but I am not able to come up with a useful suggestion. Any hints or partial results? Is there any result in order to connect this transform with the one of $e^{-i|x|}$ , at least in asymptotic terms? In fact, I am interested in an estimate for the parameter $\lambda >0$ in the Fourier transform of $f_{\lambda}(x)=e^{-i\lambda\sqrt{1+x^2}}$ . Given the analogy with $$ \mathcal{F}[e^{-i\lambda|\cdot|}](y)=\frac{\lambda}{y^2+\lambda^2},$$ I expect a similar decay for $\lambda$ in $\mathcal{F}[f_{\lambda}]$ . Is there any way to prove that?","As the title says: I want to compute the Fourier transform (in the distributional sense) of , - say for the moment. I have no idea how to get it done: I have tried with the usual machinery (""ODE approach"" like for the Gaussian, explicit computations, estimates for oscillatory integrals, complex analysis) but I am not able to come up with a useful suggestion. Any hints or partial results? Is there any result in order to connect this transform with the one of , at least in asymptotic terms? In fact, I am interested in an estimate for the parameter in the Fourier transform of . Given the analogy with I expect a similar decay for in . Is there any way to prove that?","f(x)=e^{-i\sqrt{1+x^2}} x\in \mathbb{R}^n n=1 e^{-i|x|} \lambda >0 f_{\lambda}(x)=e^{-i\lambda\sqrt{1+x^2}}  \mathcal{F}[e^{-i\lambda|\cdot|}](y)=\frac{\lambda}{y^2+\lambda^2}, \lambda \mathcal{F}[f_{\lambda}]","['complex-analysis', 'fourier-analysis', 'fourier-transform', 'distribution-theory', 'oscillatory-integral']"
62,An estimate involving polynomial of degree 2,An estimate involving polynomial of degree 2,,"Let $P(z)=(z-a)(z-b)$ where $a,b$ are any complex numbers such that $|a|\geq 1, |b|\geq 1.$ Then may I know, if $$\max_{|z|=1}|P'(z)|\leq \left(\frac{1}{2}+\frac{1}{1+|ab|}\right)\max_{|z|=1}|P(z)|$$ is true?","Let $P(z)=(z-a)(z-b)$ where $a,b$ are any complex numbers such that $|a|\geq 1, |b|\geq 1.$ Then may I know, if $$\max_{|z|=1}|P'(z)|\leq \left(\frac{1}{2}+\frac{1}{1+|ab|}\right)\max_{|z|=1}|P(z)|$$ is true?",,['complex-analysis']
63,"Identities with inverse hyperbolic and trigonometric functions, such as $\tanh^{-1} (\cos a)+\tanh^{-1} (\cos b)=\tanh^{-1} (\cos c)$","Identities with inverse hyperbolic and trigonometric functions, such as",\tanh^{-1} (\cos a)+\tanh^{-1} (\cos b)=\tanh^{-1} (\cos c),"This was a very surprising discovery for me that identities like this exist: $$\tan \frac{c}{2}=\tan \frac{a}{2}\tan \frac{b}{2} \qquad \rightarrow$$ $$\tanh^{-1} (\cos c)=\tanh^{-1} (\cos a)+\tanh^{-1} (\cos b)$$ This is a fairly well known one, and can be proven by making substitutions: $$u=\tan \frac{a}{2}, \qquad v=\tan \frac{b}{2}$$ Another, interesting one exists (proven in the same way): $$\tan \frac{c}{2}=\frac{\tan \frac{a}{2}-\tan \frac{b}{2}}{\tan \frac{a}{2}+\tan \frac{b}{2}} \qquad \rightarrow$$ $$\tanh^{-1} (\sin c)=\tanh^{-1} (\cos b)-\tanh^{-1} (\cos a)$$ What other identities like this exist? What is the interpretation of such identities in terms of: Complex numbers Geometry Or is it just a coincidense with no particular significance?","This was a very surprising discovery for me that identities like this exist: $$\tan \frac{c}{2}=\tan \frac{a}{2}\tan \frac{b}{2} \qquad \rightarrow$$ $$\tanh^{-1} (\cos c)=\tanh^{-1} (\cos a)+\tanh^{-1} (\cos b)$$ This is a fairly well known one, and can be proven by making substitutions: $$u=\tan \frac{a}{2}, \qquad v=\tan \frac{b}{2}$$ Another, interesting one exists (proven in the same way): $$\tan \frac{c}{2}=\frac{\tan \frac{a}{2}-\tan \frac{b}{2}}{\tan \frac{a}{2}+\tan \frac{b}{2}} \qquad \rightarrow$$ $$\tanh^{-1} (\sin c)=\tanh^{-1} (\cos b)-\tanh^{-1} (\cos a)$$ What other identities like this exist? What is the interpretation of such identities in terms of: Complex numbers Geometry Or is it just a coincidense with no particular significance?",,"['complex-analysis', 'trigonometry', 'hyperbolic-functions']"
64,Behaviour of $\zeta(s)$ near $s=1$,Behaviour of  near,\zeta(s) s=1,"I would appreciate if somebody could run this over and see if it works out? any suggestions or pointers would be appreciated. I denote the standard eta function $\eta$ by $\zeta^{*}$. I have not used big O notation and just used general well behaved functions. I do not wish to express the full error term, but instead ,just the principal part. Behaviour of $\zeta(s)$ near $1$ From Abel's Theorem we can see that when $s=1$, $ \zeta^{*}(1) = \log(2)$. Now looking at $(1-2^{1-s})$ we can write it in terms of an exponential like so, \begin{equation} 1-2^{1-s} = 1 - e^{(1-s)\log(2)} \end{equation} The power series expansion of $e^{z}$ is, \begin{equation} e^{z}= \sum_{n=0}^{\infty} \frac{z^{n}}{n!}\\ \Rightarrow  1-2^{1-s} = - e^{\log(2)(s-1)}=  - \sum_{n=0}^{\infty} \frac{((1-s)\log(2))^{n}}{n!} \end{equation} We can ignore the term when $n=0$ due to it being zero and sum from $n=1$ instead, \begin{equation} 1-2^{1-s} = 0 - \sum_{n=1}^{\infty} \frac{(1-s)^{n}\log(2)^{n}}{n!} \end{equation} Expanding this sum and multiplying in the negative sign we have, \begin{equation} 1-2^{1-s}= (s-1) \Bigg( \log(2) - \frac{\log(2)^{2}}{2!}(s-1) + \cdot \cdot \cdot \Bigg ) \end{equation} Factorizing  the $\log(2)$ term out, \begin{equation*} (s-1)\log(2)\Bigg [ 1 - \bigg( \frac{\log(2)}{2!}(s-1) + \frac{\log(2)}{3!}(s-1)^{2} - \cdot \cdot \cdot  \bigg ) \Bigg ] \end{equation*} By the geometric series formula,  for $|s| < 1$,  \begin{equation} \frac{1}{\bigg[1 -  \bigg(  \frac{\log(2)}{2!}(s-1) + \cdot \cdot \cdot \bigg ) \bigg ] }= 1 + \Bigg( \frac{\log(2)}{2!}(s-1) + \cdot \cdot \cdot \Bigg ) +  \Bigg( \frac{\log(2)}{2!}(s-1) + \cdot \cdot \cdot \Bigg )^{2} +  \cdot \cdot \cdot  \end{equation} The terms of this geometric series decrease rapidly, so we are only  interested in keeping the first terms while letting a well-behaved and analytic function $g$ represent the remaining terms as a function in $s$. \begin{equation} \frac{1}{\bigg[1 -  \bigg(  \frac{\log(2)}{2!}(s-1) + \cdot \cdot \cdot \bigg ) \bigg ] } = 1 + \frac{\log(2)(s-1)}{2} + (s-1)^{2}\cdot g(s). \end{equation} We can now return to  $\frac{1}{1-2^{1-s}}$, and express  it in terms of what we have learned. \begin{equation} \frac{1}{1-2^{1-s}} = \frac{1}{\log(2)(s-1)} \Bigg(  1 + \frac{\log(2)(s-1)}{2} + (s-1)^{2}\cdot g(s) \Bigg )  = \frac{1}{\log(2)} \cdot \Bigg [ \frac{1}{s-1} + \frac{\log(2)}{2} + (s-1)g(s)\Bigg ] \end{equation} We can now study $\zeta(s)$ when $s$ is near to $1$.  \begin{equation} \zeta(s) = \frac{\zeta^{*}(s)}{1-2^{1-s}} =  \frac{\zeta^{*}(s)}{\log(2)} \cdot \Bigg [ \frac{1}{s-1} + \frac{\log(2)}{2} + (s-1)g(s)\Bigg ] = \frac{\zeta^{*}(s)}{\log(2)} \cdot \frac{1}{s-1} + \frac{\zeta^{*}(s)}{2 \log(2)} \log(2) + \frac{\zeta^{*}(s)(s-1)g(s)}{\log(2)} \end{equation} As we know already, $\zeta^{*}(1) = \log(2)$ is analytic, so $\zeta^{*}(s)$ can be expanded as a series around $1$, \begin{equation} \zeta^{*}(s) = \log(2) + (s-1)a_1 + (s-1)^{2}a_2 +  \cdot \cdot \cdot = \log(2) + (s-1) h(s) \end{equation} for a well behaved and analytic $h$. Near $s=1$ and by just looking at the principal terms, \begin{equation} \zeta(s) = \frac{\zeta^{*}(s)}{1-2^{1-s}} = \frac{ \log(2) +(s-1)h(s) }{\log(2)(s-1)} = \frac{1}{s-1} + \frac{h(s)}{\log(2)} \end{equation}","I would appreciate if somebody could run this over and see if it works out? any suggestions or pointers would be appreciated. I denote the standard eta function $\eta$ by $\zeta^{*}$. I have not used big O notation and just used general well behaved functions. I do not wish to express the full error term, but instead ,just the principal part. Behaviour of $\zeta(s)$ near $1$ From Abel's Theorem we can see that when $s=1$, $ \zeta^{*}(1) = \log(2)$. Now looking at $(1-2^{1-s})$ we can write it in terms of an exponential like so, \begin{equation} 1-2^{1-s} = 1 - e^{(1-s)\log(2)} \end{equation} The power series expansion of $e^{z}$ is, \begin{equation} e^{z}= \sum_{n=0}^{\infty} \frac{z^{n}}{n!}\\ \Rightarrow  1-2^{1-s} = - e^{\log(2)(s-1)}=  - \sum_{n=0}^{\infty} \frac{((1-s)\log(2))^{n}}{n!} \end{equation} We can ignore the term when $n=0$ due to it being zero and sum from $n=1$ instead, \begin{equation} 1-2^{1-s} = 0 - \sum_{n=1}^{\infty} \frac{(1-s)^{n}\log(2)^{n}}{n!} \end{equation} Expanding this sum and multiplying in the negative sign we have, \begin{equation} 1-2^{1-s}= (s-1) \Bigg( \log(2) - \frac{\log(2)^{2}}{2!}(s-1) + \cdot \cdot \cdot \Bigg ) \end{equation} Factorizing  the $\log(2)$ term out, \begin{equation*} (s-1)\log(2)\Bigg [ 1 - \bigg( \frac{\log(2)}{2!}(s-1) + \frac{\log(2)}{3!}(s-1)^{2} - \cdot \cdot \cdot  \bigg ) \Bigg ] \end{equation*} By the geometric series formula,  for $|s| < 1$,  \begin{equation} \frac{1}{\bigg[1 -  \bigg(  \frac{\log(2)}{2!}(s-1) + \cdot \cdot \cdot \bigg ) \bigg ] }= 1 + \Bigg( \frac{\log(2)}{2!}(s-1) + \cdot \cdot \cdot \Bigg ) +  \Bigg( \frac{\log(2)}{2!}(s-1) + \cdot \cdot \cdot \Bigg )^{2} +  \cdot \cdot \cdot  \end{equation} The terms of this geometric series decrease rapidly, so we are only  interested in keeping the first terms while letting a well-behaved and analytic function $g$ represent the remaining terms as a function in $s$. \begin{equation} \frac{1}{\bigg[1 -  \bigg(  \frac{\log(2)}{2!}(s-1) + \cdot \cdot \cdot \bigg ) \bigg ] } = 1 + \frac{\log(2)(s-1)}{2} + (s-1)^{2}\cdot g(s). \end{equation} We can now return to  $\frac{1}{1-2^{1-s}}$, and express  it in terms of what we have learned. \begin{equation} \frac{1}{1-2^{1-s}} = \frac{1}{\log(2)(s-1)} \Bigg(  1 + \frac{\log(2)(s-1)}{2} + (s-1)^{2}\cdot g(s) \Bigg )  = \frac{1}{\log(2)} \cdot \Bigg [ \frac{1}{s-1} + \frac{\log(2)}{2} + (s-1)g(s)\Bigg ] \end{equation} We can now study $\zeta(s)$ when $s$ is near to $1$.  \begin{equation} \zeta(s) = \frac{\zeta^{*}(s)}{1-2^{1-s}} =  \frac{\zeta^{*}(s)}{\log(2)} \cdot \Bigg [ \frac{1}{s-1} + \frac{\log(2)}{2} + (s-1)g(s)\Bigg ] = \frac{\zeta^{*}(s)}{\log(2)} \cdot \frac{1}{s-1} + \frac{\zeta^{*}(s)}{2 \log(2)} \log(2) + \frac{\zeta^{*}(s)(s-1)g(s)}{\log(2)} \end{equation} As we know already, $\zeta^{*}(1) = \log(2)$ is analytic, so $\zeta^{*}(s)$ can be expanded as a series around $1$, \begin{equation} \zeta^{*}(s) = \log(2) + (s-1)a_1 + (s-1)^{2}a_2 +  \cdot \cdot \cdot = \log(2) + (s-1) h(s) \end{equation} for a well behaved and analytic $h$. Near $s=1$ and by just looking at the principal terms, \begin{equation} \zeta(s) = \frac{\zeta^{*}(s)}{1-2^{1-s}} = \frac{ \log(2) +(s-1)h(s) }{\log(2)(s-1)} = \frac{1}{s-1} + \frac{h(s)}{\log(2)} \end{equation}",,"['complex-analysis', 'analytic-number-theory', 'riemann-zeta']"
65,A problem about $e^{2\pi i \alpha_1}+e^{2\pi i \alpha_2}+\cdots+e^{2\pi i \alpha_N}=0$,A problem about,e^{2\pi i \alpha_1}+e^{2\pi i \alpha_2}+\cdots+e^{2\pi i \alpha_N}=0,"Let $\alpha_i\in [0,1),\; i\in \{1,\cdots,N\}$ for some positive integer $N$, such that $$e^{2\pi i \alpha_1}+e^{2\pi i \alpha_2}+\cdots+e^{2\pi i \alpha_N}=0$$ and if for any non-empty proper subset $E\subset \{1,\cdots,N\}$ satisfy $\sum_{k\in E}e^{2\pi i\alpha_{k}}\neq 0$, then $N$ be a prime number, and $\{\alpha_i: i\in \{1,\cdots,N\}\}=\rho+\{\frac{i}{N}:i\in\{0,\cdots,N-1\}\}$  for some $\rho \in [0,1)$.","Let $\alpha_i\in [0,1),\; i\in \{1,\cdots,N\}$ for some positive integer $N$, such that $$e^{2\pi i \alpha_1}+e^{2\pi i \alpha_2}+\cdots+e^{2\pi i \alpha_N}=0$$ and if for any non-empty proper subset $E\subset \{1,\cdots,N\}$ satisfy $\sum_{k\in E}e^{2\pi i\alpha_{k}}\neq 0$, then $N$ be a prime number, and $\{\alpha_i: i\in \{1,\cdots,N\}\}=\rho+\{\frac{i}{N}:i\in\{0,\cdots,N-1\}\}$  for some $\rho \in [0,1)$.",,"['complex-analysis', 'elementary-number-theory', 'prime-numbers', 'algebraic-number-theory']"
66,Describe the Riemann surface for $w=z^2-1$.,Describe the Riemann surface for .,w=z^2-1,"Question: Describe the Riemann surface for $w=z^2-1$. My thoughts so far: the Riemann surface needs two cuts emanating from the origin across the real line since it maps every input to one point above the real line and one point below. This means we would need two ""sheets"" to make the mapping one-to-one.","Question: Describe the Riemann surface for $w=z^2-1$. My thoughts so far: the Riemann surface needs two cuts emanating from the origin across the real line since it maps every input to one point above the real line and one point below. This means we would need two ""sheets"" to make the mapping one-to-one.",,"['complex-analysis', 'riemann-surfaces']"
67,enitre function that preserve the rationals?,enitre function that preserve the rationals?,,Here's a question i would be curious to know the answer The question is: what is the set of all entire functions $f: \mathbb{C} \to \mathbb{C}$ such that $f(\mathbb{Q})\subseteq \mathbb{Q}$.,Here's a question i would be curious to know the answer The question is: what is the set of all entire functions $f: \mathbb{C} \to \mathbb{C}$ such that $f(\mathbb{Q})\subseteq \mathbb{Q}$.,,['complex-analysis']
68,About B. Ya Levin's proof that $|f(x)| \leq M$ implies $|f(x+iy)| \leq Me^{\sigma y}$,About B. Ya Levin's proof that  implies,|f(x)| \leq M |f(x+iy)| \leq Me^{\sigma y},"This question is about Theorems 1 through 3 on pages 37-38 of B. Ya Levin's Lectures on Entire Functions , available on Google Books . If you can't access the Google Books link there is also a screenshot of the relevant portion of the book available here: https://i.sstatic.net/8f9kV.jpg I'm trying to understand the proofs of these three theorems for the case where the hypotheses of Theorem 3 are satisfied. In Theorem 3, $f$ is a function analytic in $\operatorname{Im} z \geq 0$ which is bounded on the real axis by a constant, $M$.  Further, there is a positive number $\sigma$ such that, for any $\epsilon > 0$, the bound $$ |f(z)| < e^{(\sigma + \epsilon)|z|} $$ holds for $|z|$ large enough with $\operatorname{Im} z > 0$.  The theorem states that, for such an $f$, $$ |f(x+iy)| \leq M e^{\sigma y} $$ for all $x+iy \in \mathbb C$ with $y \geq 0$. To prove Theorem 3, the author recommends applying Theorem 2 with $\alpha = \pi/2$ and $\rho = 1$ to the rotated function $f(iz)$.  (Actually the author suggests using $f(-iz)$ instead, but I believe this is a typo.  This function is not analytic for $\operatorname{Re} z > 0$, which is a requirement of Theorem 2.) Now in Theorem 2, the author defines $$ D = \left\{z : |\arg z| < \alpha = \frac{\pi}{2\rho}\right\} = \{z:\operatorname{Re}z > 0\} $$ and $$ \varphi_\epsilon(z) = f(iz)e^{-(\sigma + \epsilon)z}. $$ The function $\varphi_\epsilon$ is bounded by $M$ on the boundary of $D$, since $$ |\varphi_\epsilon(ix)| = \left|f(-x) e^{i(\sigma + \epsilon)x}\right| \leq M. $$ Further, it tends to zero along the positive real axis.  Indeed, for $|z|$ large enough we have $|f(z)| < e^{(\sigma + \epsilon/2)|z|}$, so for $x > 0$ large enough we see that $$ |\varphi_\epsilon(x)| < e^{(\sigma+\epsilon/2)x}e^{-(\sigma+\epsilon)x} = e^{-x\epsilon/2}. $$ Thus there is a constant $C_\epsilon$ such that $$ |\varphi_\epsilon(x)| \leq C_\epsilon $$ for all $x \geq 0$.  I believe this is what the author means by the first sentence of the proof, The function $\varphi_\epsilon(z)$ is bounded on a positive ray and on the boundary of $D$. I can understand the next line, According to the previous theorem [Theorem 1], it is bounded by a constant in each angle $D_+ = \{z:0<\arg z<\pi/2\}$ and $D_- = \{z:-\pi/2<\arg z<0\}$. Here the author seems to have applied Theorem 1 with $\rho = 1$ and $\lambda = 2$ to $\varphi_\epsilon(z)$ in each of the angles $D_+$ and $D_-$.  It seems that the $M$ in Theorem 1 was taken to be $\max\{M,C_\epsilon\}$.  This is then the constant bound being referred to. I do not understand the next line, Applying the previous theorem once more, we obtain $|\varphi_\epsilon(z)| \leq M$ for $z \in D$. How was the previous theorem applied this time?  How does he conclude that $|\varphi_\epsilon(z)| \leq M$ when we apparently only have $$ |\varphi_\epsilon(z)| \leq \max\{M,C_\epsilon\}? $$","This question is about Theorems 1 through 3 on pages 37-38 of B. Ya Levin's Lectures on Entire Functions , available on Google Books . If you can't access the Google Books link there is also a screenshot of the relevant portion of the book available here: https://i.sstatic.net/8f9kV.jpg I'm trying to understand the proofs of these three theorems for the case where the hypotheses of Theorem 3 are satisfied. In Theorem 3, $f$ is a function analytic in $\operatorname{Im} z \geq 0$ which is bounded on the real axis by a constant, $M$.  Further, there is a positive number $\sigma$ such that, for any $\epsilon > 0$, the bound $$ |f(z)| < e^{(\sigma + \epsilon)|z|} $$ holds for $|z|$ large enough with $\operatorname{Im} z > 0$.  The theorem states that, for such an $f$, $$ |f(x+iy)| \leq M e^{\sigma y} $$ for all $x+iy \in \mathbb C$ with $y \geq 0$. To prove Theorem 3, the author recommends applying Theorem 2 with $\alpha = \pi/2$ and $\rho = 1$ to the rotated function $f(iz)$.  (Actually the author suggests using $f(-iz)$ instead, but I believe this is a typo.  This function is not analytic for $\operatorname{Re} z > 0$, which is a requirement of Theorem 2.) Now in Theorem 2, the author defines $$ D = \left\{z : |\arg z| < \alpha = \frac{\pi}{2\rho}\right\} = \{z:\operatorname{Re}z > 0\} $$ and $$ \varphi_\epsilon(z) = f(iz)e^{-(\sigma + \epsilon)z}. $$ The function $\varphi_\epsilon$ is bounded by $M$ on the boundary of $D$, since $$ |\varphi_\epsilon(ix)| = \left|f(-x) e^{i(\sigma + \epsilon)x}\right| \leq M. $$ Further, it tends to zero along the positive real axis.  Indeed, for $|z|$ large enough we have $|f(z)| < e^{(\sigma + \epsilon/2)|z|}$, so for $x > 0$ large enough we see that $$ |\varphi_\epsilon(x)| < e^{(\sigma+\epsilon/2)x}e^{-(\sigma+\epsilon)x} = e^{-x\epsilon/2}. $$ Thus there is a constant $C_\epsilon$ such that $$ |\varphi_\epsilon(x)| \leq C_\epsilon $$ for all $x \geq 0$.  I believe this is what the author means by the first sentence of the proof, The function $\varphi_\epsilon(z)$ is bounded on a positive ray and on the boundary of $D$. I can understand the next line, According to the previous theorem [Theorem 1], it is bounded by a constant in each angle $D_+ = \{z:0<\arg z<\pi/2\}$ and $D_- = \{z:-\pi/2<\arg z<0\}$. Here the author seems to have applied Theorem 1 with $\rho = 1$ and $\lambda = 2$ to $\varphi_\epsilon(z)$ in each of the angles $D_+$ and $D_-$.  It seems that the $M$ in Theorem 1 was taken to be $\max\{M,C_\epsilon\}$.  This is then the constant bound being referred to. I do not understand the next line, Applying the previous theorem once more, we obtain $|\varphi_\epsilon(z)| \leq M$ for $z \in D$. How was the previous theorem applied this time?  How does he conclude that $|\varphi_\epsilon(z)| \leq M$ when we apparently only have $$ |\varphi_\epsilon(z)| \leq \max\{M,C_\epsilon\}? $$",,"['complex-analysis', 'inequality']"
69,Complex differentiable but not analytic on circle of convergence,Complex differentiable but not analytic on circle of convergence,,"I'm trying to get a better handle on behavior of complex power series on the boundary of their maximal disk of convergence. I'm reading Bak-Newman's Complex Analysis , Chapter 18.1. A regular point $z_0$ on the circle bounding the maximal disk of convergence is defined as one where the function in question can be continued analytically to some open neighborhood of $z_0$. My understanding of analytic at a point in this book is that it is always used to indicate differentiability on some neighborhood of the point , so that being analytic at a point is equivalent to being analytic in some open disk around a point. (By differentiable at a point $z_0$ I mean that $\lim_{z \to z_0}\frac{f(z)-f(z_0)}{z - z_0}$ exists, or that equivalently the function $\mathbb{R}^2 \to \mathbb{R}^2$ is differentiable and the Cauchy-Riemann equations hold.) This section of the book also defines a singularity on the circle of convergence to be a point which is not a regular point. I'm trying to figure out how this definition of singularity relates to the notion of isolated singularity with which I'm already (more or less) comfortable. My question is this: Is it possible to be differentiable at a point on the circle of convergence, but not analytic at that point? More or less, I'm trying to figure out if there is a function which is defined in some open neighborhood of the closed unit disk, analytic in the open unit disk, complex differentiable at $z = 1$, but not differentiable at each of a sequence of real $x_n > 1$ which converge to $1$. Can this happen?","I'm trying to get a better handle on behavior of complex power series on the boundary of their maximal disk of convergence. I'm reading Bak-Newman's Complex Analysis , Chapter 18.1. A regular point $z_0$ on the circle bounding the maximal disk of convergence is defined as one where the function in question can be continued analytically to some open neighborhood of $z_0$. My understanding of analytic at a point in this book is that it is always used to indicate differentiability on some neighborhood of the point , so that being analytic at a point is equivalent to being analytic in some open disk around a point. (By differentiable at a point $z_0$ I mean that $\lim_{z \to z_0}\frac{f(z)-f(z_0)}{z - z_0}$ exists, or that equivalently the function $\mathbb{R}^2 \to \mathbb{R}^2$ is differentiable and the Cauchy-Riemann equations hold.) This section of the book also defines a singularity on the circle of convergence to be a point which is not a regular point. I'm trying to figure out how this definition of singularity relates to the notion of isolated singularity with which I'm already (more or less) comfortable. My question is this: Is it possible to be differentiable at a point on the circle of convergence, but not analytic at that point? More or less, I'm trying to figure out if there is a function which is defined in some open neighborhood of the closed unit disk, analytic in the open unit disk, complex differentiable at $z = 1$, but not differentiable at each of a sequence of real $x_n > 1$ which converge to $1$. Can this happen?",,"['complex-analysis', 'power-series', 'analyticity']"
70,Dirichlet L-series and Gamma function question,Dirichlet L-series and Gamma function question,,"Could someone help me, please, with this exercise? Consider a sequence of complex numbers $\{a_n\}$ such that $a_n=a_m $ iff $ n\cong m $   mod $q$ for some positive integer $q$. Define the Dirichlet L-series associated to the sequence by $$L(s)=\sum_{n=1}^{\infty} \frac{a_n}{n^s} \ \ \  \text{  for   Re}(s)>1. $$ Also define $$M(x)=\sum_{m=0}^{q-1}a_{q-m} e^{mx}\ \ \ \text{  with   }\ \  a_0=a_q.$$ Questions How can we show that  $$ L(s)=\frac{1}{\Gamma(s)}\int_{0}^{\infty}\frac{M(x)x^{s-1}}{e^{qx}-1}dx,  \ \ \text{for   Re}(s)>1 ? $$ Note: $\Gamma(s)$ is the Gamma function. How does that imply $L(s)$ is continuable into the complex plane, with the only possible singularity a pole at $s=1$. Any help is really appreciated.","Could someone help me, please, with this exercise? Consider a sequence of complex numbers $\{a_n\}$ such that $a_n=a_m $ iff $ n\cong m $   mod $q$ for some positive integer $q$. Define the Dirichlet L-series associated to the sequence by $$L(s)=\sum_{n=1}^{\infty} \frac{a_n}{n^s} \ \ \  \text{  for   Re}(s)>1. $$ Also define $$M(x)=\sum_{m=0}^{q-1}a_{q-m} e^{mx}\ \ \ \text{  with   }\ \  a_0=a_q.$$ Questions How can we show that  $$ L(s)=\frac{1}{\Gamma(s)}\int_{0}^{\infty}\frac{M(x)x^{s-1}}{e^{qx}-1}dx,  \ \ \text{for   Re}(s)>1 ? $$ Note: $\Gamma(s)$ is the Gamma function. How does that imply $L(s)$ is continuable into the complex plane, with the only possible singularity a pole at $s=1$. Any help is really appreciated.",,"['complex-analysis', 'number-theory', 'special-functions']"
71,Physical interpretation of the generating function for the Bessel functions.,Physical interpretation of the generating function for the Bessel functions.,,"It is well known that the generating function for the Bessel function is $$f(z) = \exp \left (\frac12 \left (z - \frac1z \right ) w \right ).$$ So, we have $$f(z) = \sum_{\nu = -\infty}^{\infty} J_\nu(w) z^\nu.$$ Okay excellent! It is quite easy for those that pay attention well to the details to derive our friend the Bessel function from this (series and integral representations). Now my question is actually: What is the (physical) interpretation of this $f(z)$? I know that for Hermite polynomials, the similar generating function is something that has to do with the random walk. This makes lots of sense thanks to our friend the Ornstein-Uhlenbeck operator! What is it here? I have plotted $f$ for $w = 1$ under the image of a circle. That gives me some kickass animation if I let the radius grow. But what the heck is it? The Bessel functions are intimately connected to the wave equation, so an interpretation in that direction would be nice.","It is well known that the generating function for the Bessel function is $$f(z) = \exp \left (\frac12 \left (z - \frac1z \right ) w \right ).$$ So, we have $$f(z) = \sum_{\nu = -\infty}^{\infty} J_\nu(w) z^\nu.$$ Okay excellent! It is quite easy for those that pay attention well to the details to derive our friend the Bessel function from this (series and integral representations). Now my question is actually: What is the (physical) interpretation of this $f(z)$? I know that for Hermite polynomials, the similar generating function is something that has to do with the random walk. This makes lots of sense thanks to our friend the Ornstein-Uhlenbeck operator! What is it here? I have plotted $f$ for $w = 1$ under the image of a circle. That gives me some kickass animation if I let the radius grow. But what the heck is it? The Bessel functions are intimately connected to the wave equation, so an interpretation in that direction would be nice.",,"['complex-analysis', 'special-functions', 'intuition', 'generating-functions', 'physics']"
72,Sequence of analytic functions on $U \subset \mathbb{C} $ tending locally uniformly to $ f $ implies $ f $ analytic on $U$,Sequence of analytic functions on  tending locally uniformly to  implies  analytic on,U \subset \mathbb{C}   f   f  U,"I want to prove that if $ f_n $ are analytic functions on a domain $ U \subset \mathbb{C} $ and $ f_n $ tends locally uniformly to $ f $ on $U$, then $f$ is analytic on $U$. My thoughts: I'd like to show that $ f $ is necessarily continuous on $ U $, and that for any simple closed curve $ \gamma $, $ \int_\gamma f(z) dz = 0 $. Then by Morera's theorem, $f$ is analytic. Now $f_n $ tends locally uniformly to $ f$ on $U$ means that for any $ x \in U $, $ \exists r > 0 $ such that $ f_n $ tends uniformly on $ B(x;r) $ to $f$. I know that continuity is preserved under uniform convergence, and so for any $ x \in U $, $ f$ is continuous on some ball around $x$, and so is continuous at $x$. Thus $ f $ is continuous on $ U $. Let $ \gamma $ be a simple, closed curve in $ U $. Then for any $ x $ on $ \gamma $, $\exists $ $ r > 0 $ such that $ f_n $ converges uniformly to $f$ on $ B(x;r_x) $. Let $ N_x $ be the associated 'magic uniform convergence number' (for lack of a better term) for the sequence on this ball. Now, the collection of these balls for all $ x $ on $\gamma$ forms a cover of $\gamma$, and by compactness there is a finite subcover, say $ \{ B(x_i;r_i), 1 \leq i \leq n \} $. Let  $ N = \max_i N_{x_i} $. Then $ N $ gives us uniform convergence of the sequence $ f_n $ to $ f$ on $\gamma$. Thus we can say $ \int_\gamma f(z) dz = \lim_{n\to \infty} \int_\gamma f_n(z) dz = 0 $, and so we're done. Is this proof valid? Thanks!","I want to prove that if $ f_n $ are analytic functions on a domain $ U \subset \mathbb{C} $ and $ f_n $ tends locally uniformly to $ f $ on $U$, then $f$ is analytic on $U$. My thoughts: I'd like to show that $ f $ is necessarily continuous on $ U $, and that for any simple closed curve $ \gamma $, $ \int_\gamma f(z) dz = 0 $. Then by Morera's theorem, $f$ is analytic. Now $f_n $ tends locally uniformly to $ f$ on $U$ means that for any $ x \in U $, $ \exists r > 0 $ such that $ f_n $ tends uniformly on $ B(x;r) $ to $f$. I know that continuity is preserved under uniform convergence, and so for any $ x \in U $, $ f$ is continuous on some ball around $x$, and so is continuous at $x$. Thus $ f $ is continuous on $ U $. Let $ \gamma $ be a simple, closed curve in $ U $. Then for any $ x $ on $ \gamma $, $\exists $ $ r > 0 $ such that $ f_n $ converges uniformly to $f$ on $ B(x;r_x) $. Let $ N_x $ be the associated 'magic uniform convergence number' (for lack of a better term) for the sequence on this ball. Now, the collection of these balls for all $ x $ on $\gamma$ forms a cover of $\gamma$, and by compactness there is a finite subcover, say $ \{ B(x_i;r_i), 1 \leq i \leq n \} $. Let  $ N = \max_i N_{x_i} $. Then $ N $ gives us uniform convergence of the sequence $ f_n $ to $ f$ on $\gamma$. Thus we can say $ \int_\gamma f(z) dz = \lim_{n\to \infty} \int_\gamma f_n(z) dz = 0 $, and so we're done. Is this proof valid? Thanks!",,['complex-analysis']
73,Find all analytic functions $f: \mathbb{C} \longrightarrow \mathbb{C}$ such that f(3z)-f(2z)=5f(z),Find all analytic functions  such that f(3z)-f(2z)=5f(z),f: \mathbb{C} \longrightarrow \mathbb{C},as the title states: Find all analytic functions $f: \mathbb{C} \longrightarrow \mathbb{C}$ such that $f(3z)-f(2z)=5f(z)$ where $z \in \mathbb{C}$ and $f(1)=3$ Starting with the taylor series of expansion of $f(z)$ we have $$f(z) = \sum_{n=0}^{\infty}a_n z^n$$ then substituting the above we have $$f(3z)-f(2z)=5f(z) \implies \sum_{n=0}^{\infty}a_n3^nz^n - \sum_{n=0}^{\infty}a_n2^nz^n = 5\sum_{n=0}^{\infty}a_nz^n$$ then via the uniqueness of power series coeffecients we have $$a_n3^n - a_n2^n = 5a_n$$ which has a single solution at $n=2$ then $a_n = 0~\forall n \in \mathbb{N}\setminus \{2\}$ otherwise. then we have $$f(z)=\sum_{n=0}^{\infty}a_nz^n = a_2z^2$$ from here i'm tempted to use the formula for $a_2$ ie $$a_n = \frac{1}{2 \pi i}\int_{S_{r}^{+}(0)}\frac{f(w)}{w}dw $$ but since it's been given to me that $f(1)=3$ i'm tempted to just state that $a_2 = 3$ . as i can't really think of any other way of determining f. Thoughts? is this correct?,as the title states: Find all analytic functions such that where and Starting with the taylor series of expansion of we have then substituting the above we have then via the uniqueness of power series coeffecients we have which has a single solution at then otherwise. then we have from here i'm tempted to use the formula for ie but since it's been given to me that i'm tempted to just state that . as i can't really think of any other way of determining f. Thoughts? is this correct?,f: \mathbb{C} \longrightarrow \mathbb{C} f(3z)-f(2z)=5f(z) z \in \mathbb{C} f(1)=3 f(z) f(z) = \sum_{n=0}^{\infty}a_n z^n f(3z)-f(2z)=5f(z) \implies \sum_{n=0}^{\infty}a_n3^nz^n - \sum_{n=0}^{\infty}a_n2^nz^n = 5\sum_{n=0}^{\infty}a_nz^n a_n3^n - a_n2^n = 5a_n n=2 a_n = 0~\forall n \in \mathbb{N}\setminus \{2\} f(z)=\sum_{n=0}^{\infty}a_nz^n = a_2z^2 a_2 a_n = \frac{1}{2 \pi i}\int_{S_{r}^{+}(0)}\frac{f(w)}{w}dw  f(1)=3 a_2 = 3,"['complex-analysis', 'complex-numbers', 'analytic-functions']"
74,Prove that $\sum_{n=0}^{\infty}{{a_n}{z^n}}$ converges absolutely and uniformly in $D$.,Prove that  converges absolutely and uniformly in .,\sum_{n=0}^{\infty}{{a_n}{z^n}} D,"PROBLEM Suppose that the complex series $\displaystyle \sum_{n=0}^{\infty}{a_n}$ converges.  Let $r < 1$ and set $D = \{z \in \mathbb{C} : |z| < r\}$. Prove that $\displaystyle \sum_{n=0}^{\infty}{{a_n}{z^n}}$ converges absolutely and uniformly in $D$. MY FUTILE ATTEMPTS I know that I must somehow use the result(s) in this question: If the complex series $\displaystyle \sum_{n=0}^{\infty}{a_n}$ converges, show that there exists a positive number $A$ such that $|a_n| \leq A$ for all $n$. . Also, the easiest way that I can think of to solve this problem is to use the following theorem: THEOREM ( Weierstrass M-Test or Dominated Convergence Theorem ) Given the series of functions $\ \displaystyle \sum_{n=1}^{\infty}{{f_n}(z)}, z \in E$.  Suppose that $\{M_n\}$ is a sequence of positive real numbers such that     (i) $|{f_n}(z)| \leq M_n, \forall n \in \mathbb{N}, \forall z \in E$.  (ii) $\displaystyle \sum_{n=1}^{\infty}{M_n}$ converges.  Then $\displaystyle \sum_{n=1}^{\infty}{{f_n}(z)}$ converges absolutely and uniformly on $E$. Of course I know that I need to set ${f_n}(z) = {a_n}{z^n}$.  Then ${f_n}(z)$ is a power series.  What I don't know is the sequence $\{M_n\}$. QUESTIONS (1) Is the Weierstrass M-Test indeed the best way to tackle this problem?  If so, what should be my $M_n$? (2) If the answer to the first question in (1) is NO , how can I be able to solve this problem?","PROBLEM Suppose that the complex series $\displaystyle \sum_{n=0}^{\infty}{a_n}$ converges.  Let $r < 1$ and set $D = \{z \in \mathbb{C} : |z| < r\}$. Prove that $\displaystyle \sum_{n=0}^{\infty}{{a_n}{z^n}}$ converges absolutely and uniformly in $D$. MY FUTILE ATTEMPTS I know that I must somehow use the result(s) in this question: If the complex series $\displaystyle \sum_{n=0}^{\infty}{a_n}$ converges, show that there exists a positive number $A$ such that $|a_n| \leq A$ for all $n$. . Also, the easiest way that I can think of to solve this problem is to use the following theorem: THEOREM ( Weierstrass M-Test or Dominated Convergence Theorem ) Given the series of functions $\ \displaystyle \sum_{n=1}^{\infty}{{f_n}(z)}, z \in E$.  Suppose that $\{M_n\}$ is a sequence of positive real numbers such that     (i) $|{f_n}(z)| \leq M_n, \forall n \in \mathbb{N}, \forall z \in E$.  (ii) $\displaystyle \sum_{n=1}^{\infty}{M_n}$ converges.  Then $\displaystyle \sum_{n=1}^{\infty}{{f_n}(z)}$ converges absolutely and uniformly on $E$. Of course I know that I need to set ${f_n}(z) = {a_n}{z^n}$.  Then ${f_n}(z)$ is a power series.  What I don't know is the sequence $\{M_n\}$. QUESTIONS (1) Is the Weierstrass M-Test indeed the best way to tackle this problem?  If so, what should be my $M_n$? (2) If the answer to the first question in (1) is NO , how can I be able to solve this problem?",,"['complex-analysis', 'power-series', 'uniform-convergence', 'absolute-convergence']"
75,(Rudin's) Definition of a harmonic function,(Rudin's) Definition of a harmonic function,,"In Chapter 11 of Rudin's RCA, a harmonic function is defined to be a complex continuous function $u$ on a plane open set such that the Laplacian of $u$, i.e. the sum of its pure second-order partial derivatives $$u_{xx}+u_{yy}$$ is $0$. I was wondering if this was missing a condition, namely that $u_{xy}=u_{yx}$, because I was unable to show the following without this assumption. For every harmonic function $u$ whose domain includes the image of a holomorphic function $f$ in a plane open set $\Omega$, the composite $u\circ f$ is harmonic in $\Omega$. I attempted to show this by just brute calculation, and what remained was  $u_{xy}-u_{yx}$ with some partials of $f$ multiplied on the outside. Of course, Rudin later shows that harmonic functions have continuous partial derivatives of all orders because the real-valued ones are locally real parts of holomorphic functions, but I think his proof relies on a certain composite of functions being harmonic...","In Chapter 11 of Rudin's RCA, a harmonic function is defined to be a complex continuous function $u$ on a plane open set such that the Laplacian of $u$, i.e. the sum of its pure second-order partial derivatives $$u_{xx}+u_{yy}$$ is $0$. I was wondering if this was missing a condition, namely that $u_{xy}=u_{yx}$, because I was unable to show the following without this assumption. For every harmonic function $u$ whose domain includes the image of a holomorphic function $f$ in a plane open set $\Omega$, the composite $u\circ f$ is harmonic in $\Omega$. I attempted to show this by just brute calculation, and what remained was  $u_{xy}-u_{yx}$ with some partials of $f$ multiplied on the outside. Of course, Rudin later shows that harmonic functions have continuous partial derivatives of all orders because the real-valued ones are locally real parts of holomorphic functions, but I think his proof relies on a certain composite of functions being harmonic...",,"['complex-analysis', 'harmonic-functions']"
76,(Non-)Canonicity of using zeta function to assign values to divergent series [duplicate],(Non-)Canonicity of using zeta function to assign values to divergent series [duplicate],,"This question already has an answer here : Can different choices of regulator assign different values to the same divergent series? (1 answer) Closed 6 years ago . This article http://blogs.scientificamerican.com/roots-of-unity/does-123-really-equal-112/ got me thinking about the ""identity"" $$1 + 2 + 3 + \cdots = -1/12,$$ and I wanted to convince myself there was nothing particularly unique about this identity or the Riemann zeta construction. More precisely, this identity only really makes sense if you think of an integer $n$ as being the specialization at $z=-1$ of the function $n^{-z}$. So here's a question: For any complex number $c$, does there exist a domain $\Omega \subset \mathbb{C}$, and analytic functions $F(n, s)_{n\in\mathbb{N}}$ and $f(s)$ on $\Omega$, such that the following hold i. $F(n,0) = n$ ii. $\sum_{n=1}^\infty F(n,s) = f(s)$ on $\Omega$ in some reasonable sense (maybe converges uniformly on compact subsets of $\Omega$?) iii. $f$ can be extended holomorphically to some domain containing both $\Omega$ and $0$ such that $f(0) = c$. So shifting the Euler series and Riemann zeta would be such a construction for $c=-1/12$. As the question stands, I feel that the answer is almost certainly yes, although to be fair the functions $n^{-s}$ have a lot more structure than ""holomorphic functions on some domain"". So a follow-up question would be: are there ""natural"" additional constraints for which the answer to this question is No ? I apologize that this is kind of open-ended, but the goal is to convince myself that there is nothing particularly canonical about $-1/12$ (or to hear an explanation of why it is canonical).","This question already has an answer here : Can different choices of regulator assign different values to the same divergent series? (1 answer) Closed 6 years ago . This article http://blogs.scientificamerican.com/roots-of-unity/does-123-really-equal-112/ got me thinking about the ""identity"" $$1 + 2 + 3 + \cdots = -1/12,$$ and I wanted to convince myself there was nothing particularly unique about this identity or the Riemann zeta construction. More precisely, this identity only really makes sense if you think of an integer $n$ as being the specialization at $z=-1$ of the function $n^{-z}$. So here's a question: For any complex number $c$, does there exist a domain $\Omega \subset \mathbb{C}$, and analytic functions $F(n, s)_{n\in\mathbb{N}}$ and $f(s)$ on $\Omega$, such that the following hold i. $F(n,0) = n$ ii. $\sum_{n=1}^\infty F(n,s) = f(s)$ on $\Omega$ in some reasonable sense (maybe converges uniformly on compact subsets of $\Omega$?) iii. $f$ can be extended holomorphically to some domain containing both $\Omega$ and $0$ such that $f(0) = c$. So shifting the Euler series and Riemann zeta would be such a construction for $c=-1/12$. As the question stands, I feel that the answer is almost certainly yes, although to be fair the functions $n^{-s}$ have a lot more structure than ""holomorphic functions on some domain"". So a follow-up question would be: are there ""natural"" additional constraints for which the answer to this question is No ? I apologize that this is kind of open-ended, but the goal is to convince myself that there is nothing particularly canonical about $-1/12$ (or to hear an explanation of why it is canonical).",,"['complex-analysis', 'analytic-number-theory', 'riemann-zeta']"
77,Branch points and branching number on Riemann surface,Branch points and branching number on Riemann surface,,"I am attempting to analyze the Riemann surface of the algebraic function $w=(\sqrt{z} - 1)^{1/4}$. To do this, I started out by writing as a polynomial, $P(w,z) = w^8 +2w^4 + 1 -z = 0$. Next, I want to identify the branch points. I understand these points to be the points where the inverse function theorem fails, so I $\dfrac{\partial P}{\partial w}=0,$ identify the values of $w$ satisfying this, and use them to determine some corresponding $z$'s. This gives the ordered pairs $(w,z) = (0,0), (1,3), (i,3), (-1,3), (-i,3)$. (Here I am just listing the pairs). Next I would like to compute a branching number for each of these points. I understand that this amounts to determining the minimal number $l \in \mathbb N$ so that $\dfrac{\partial^l P}{\partial w^l}(w,z) \neq 0.$ The branching number is defined as $l-1$. Using this, it is easy to compute the branching numbers. The branching number for the first is $3$, and all the others have branching number $1$. From here I want to compute the genus of the Riemann surface of this polynomial. To do this, I should expect the sum over all the branching numbers to be an even number, by considering Riemann-Hurwitz. However, their sum is currently $7$. This made me think I had missed a point, and was thinking about the point at infinity. However, I do not understand (or maybe it's obvious and I've just forgotten) how to determine the branching number of the point at infinity. I am a bit unsure about even my work so far though, because it is a result in Schlag that the degree of a polynomial is equal to the number of sheets of the Riemann surface. This means that this surface has $8$ sheets. By Riemann-Hurwitz, we would expect something of the form $g_{RS} = 1+8(g-1)+\dfrac{\sum B(p)}{2}$, where $g$ is the genus of the Riemann sphere, which is $0$. In other words, $g_{RS} = -7 + \dfrac{\sum B(p)}{2}$, implying that the branching number of infinity must be very large, since genus must be at least $0$. So my question is, did anything go wrong in this analysis? If so, where? Furthermore, how do I compute this branching number at infinity?","I am attempting to analyze the Riemann surface of the algebraic function $w=(\sqrt{z} - 1)^{1/4}$. To do this, I started out by writing as a polynomial, $P(w,z) = w^8 +2w^4 + 1 -z = 0$. Next, I want to identify the branch points. I understand these points to be the points where the inverse function theorem fails, so I $\dfrac{\partial P}{\partial w}=0,$ identify the values of $w$ satisfying this, and use them to determine some corresponding $z$'s. This gives the ordered pairs $(w,z) = (0,0), (1,3), (i,3), (-1,3), (-i,3)$. (Here I am just listing the pairs). Next I would like to compute a branching number for each of these points. I understand that this amounts to determining the minimal number $l \in \mathbb N$ so that $\dfrac{\partial^l P}{\partial w^l}(w,z) \neq 0.$ The branching number is defined as $l-1$. Using this, it is easy to compute the branching numbers. The branching number for the first is $3$, and all the others have branching number $1$. From here I want to compute the genus of the Riemann surface of this polynomial. To do this, I should expect the sum over all the branching numbers to be an even number, by considering Riemann-Hurwitz. However, their sum is currently $7$. This made me think I had missed a point, and was thinking about the point at infinity. However, I do not understand (or maybe it's obvious and I've just forgotten) how to determine the branching number of the point at infinity. I am a bit unsure about even my work so far though, because it is a result in Schlag that the degree of a polynomial is equal to the number of sheets of the Riemann surface. This means that this surface has $8$ sheets. By Riemann-Hurwitz, we would expect something of the form $g_{RS} = 1+8(g-1)+\dfrac{\sum B(p)}{2}$, where $g$ is the genus of the Riemann sphere, which is $0$. In other words, $g_{RS} = -7 + \dfrac{\sum B(p)}{2}$, implying that the branching number of infinity must be very large, since genus must be at least $0$. So my question is, did anything go wrong in this analysis? If so, where? Furthermore, how do I compute this branching number at infinity?",,"['complex-analysis', 'riemann-surfaces']"
78,Absolute Value of Complex Integral,Absolute Value of Complex Integral,,"Let $[a,b]$ be a closed real interval. Let $f:[a,b] \to \mathbb{C}$ be a continuous complex-valued function. Then $$\bigg|\int_{a}^{b} f(t)dt \ \bigg| \leq \int_{a}^{b} \bigg|f(t)\bigg| dt,$$ where the first integral is a complex integral, and the second integral is a definite real integral. There's a neat ""rotational"" proof of this in D'Angelo's An Introduction to Complex Analysis and Geometry . Question: Can this fact also be proven using the Cauchy-Schwarz Inequality? If so, some help would be nice. Thank you...","Let $[a,b]$ be a closed real interval. Let $f:[a,b] \to \mathbb{C}$ be a continuous complex-valued function. Then $$\bigg|\int_{a}^{b} f(t)dt \ \bigg| \leq \int_{a}^{b} \bigg|f(t)\bigg| dt,$$ where the first integral is a complex integral, and the second integral is a definite real integral. There's a neat ""rotational"" proof of this in D'Angelo's An Introduction to Complex Analysis and Geometry . Question: Can this fact also be proven using the Cauchy-Schwarz Inequality? If so, some help would be nice. Thank you...",,['complex-analysis']
79,Find the derivative of a polylogarithm function,Find the derivative of a polylogarithm function,,"I was trying to find to which function the next series converges. $$ \sum_{n=1}^{\infty} \ln(n)z^n $$ If we take the polylogarithm function $Li_s(z)$ defined as $$ Li_s(s)=\sum_{n=1}^{\infty} \frac{z^n}{n^s} $$ Then it is easily seen that $$ \sum_{n=1}^{\infty} \ln(n)z^n = - \left( \frac{\partial}{\partial s}Li_s(z)\right)_{s=0} $$ Now, my question is how to calculate $ \frac{\partial}{\partial s}Li_s(z)$, using an integral representation for $Li$, such as   $$ Li_s(z)=\frac{1}{\Gamma(s)}\int_{0}^{\infty} \frac{zt^{s-1}}{e^t-z} dt $$ Is there any nice solution to this? All my attempts are unclear about it, especially because of the derivative of $\Gamma(s)$.","I was trying to find to which function the next series converges. $$ \sum_{n=1}^{\infty} \ln(n)z^n $$ If we take the polylogarithm function $Li_s(z)$ defined as $$ Li_s(s)=\sum_{n=1}^{\infty} \frac{z^n}{n^s} $$ Then it is easily seen that $$ \sum_{n=1}^{\infty} \ln(n)z^n = - \left( \frac{\partial}{\partial s}Li_s(z)\right)_{s=0} $$ Now, my question is how to calculate $ \frac{\partial}{\partial s}Li_s(z)$, using an integral representation for $Li$, such as   $$ Li_s(z)=\frac{1}{\Gamma(s)}\int_{0}^{\infty} \frac{zt^{s-1}}{e^t-z} dt $$ Is there any nice solution to this? All my attempts are unclear about it, especially because of the derivative of $\Gamma(s)$.",,"['complex-analysis', 'partial-derivative', 'polylogarithm']"
80,Showing a complex analytic function is unbounded,Showing a complex analytic function is unbounded,,"This was one of the problems on a previous year's Complex Analysis final exam. Assume $f\in \mathcal O (\mathbb H )$, non-constant, and $f(\frac {i}{\sqrt n})=0, \forall n\in \mathbb N$. Prove that $f$ takes unbounded values. What I tried so far: I tried to argue that the point $z=0$ had to be an essential singularity since the function cannot be continued to be holomorphic there (taking the value $0$), for then it would be forced to be identically the $0$ function (which it is assumed not to be). Then i squared the input domain to argue that the essential singularity must take on unbounded values in the upper-half plane somewhere near $z=0$. But, I think my reasoning is wrong because this may not be an isolated singularity at all and may be a point in the branch cut of a holomorphic function or something. I'm wondering if someone can write me up a nice proof and/or explanation about how to tackle this problem, thanks.","This was one of the problems on a previous year's Complex Analysis final exam. Assume $f\in \mathcal O (\mathbb H )$, non-constant, and $f(\frac {i}{\sqrt n})=0, \forall n\in \mathbb N$. Prove that $f$ takes unbounded values. What I tried so far: I tried to argue that the point $z=0$ had to be an essential singularity since the function cannot be continued to be holomorphic there (taking the value $0$), for then it would be forced to be identically the $0$ function (which it is assumed not to be). Then i squared the input domain to argue that the essential singularity must take on unbounded values in the upper-half plane somewhere near $z=0$. But, I think my reasoning is wrong because this may not be an isolated singularity at all and may be a point in the branch cut of a holomorphic function or something. I'm wondering if someone can write me up a nice proof and/or explanation about how to tackle this problem, thanks.",,"['complex-analysis', 'singularity-theory']"
81,Is this contour continuously deformable into a circle?,Is this contour continuously deformable into a circle?,,"As an exam question, we had to solve the integral of $\frac{1}{z}$ over the following contour: (The contour is a sequence of straights arcs joining -1, -$\frac{i}{2}$, $\frac{1}{2}$, i, $-\frac{1}{2}$, -i, 1, $\frac{i}{2}$ and -1). I assumed for the time being that the contour was continuously deformable into a circle with radius 1 around the origin (by the Deformation Invariance Theorem) as the whole contour was around the origin as well. However, is it allowed to make this statement or is the only way to calculate it summing the integrals of the separate straight arcs?","As an exam question, we had to solve the integral of $\frac{1}{z}$ over the following contour: (The contour is a sequence of straights arcs joining -1, -$\frac{i}{2}$, $\frac{1}{2}$, i, $-\frac{1}{2}$, -i, 1, $\frac{i}{2}$ and -1). I assumed for the time being that the contour was continuously deformable into a circle with radius 1 around the origin (by the Deformation Invariance Theorem) as the whole contour was around the origin as well. However, is it allowed to make this statement or is the only way to calculate it summing the integrals of the separate straight arcs?",,"['complex-analysis', 'homotopy-theory', 'contour-integration']"
82,Proving that two functions involving integrals with Legendre polynomials are equal,Proving that two functions involving integrals with Legendre polynomials are equal,,"I have two functions that I expect to be equal (where $P_{2l}$ are the even Legendre Polynomials): $$F_{2l}(x)=x\, \tanh(\pi x/2)\left|\int_0^1 u^{i x-1}P_{2l}(u)\,du\right|^2$$ $$G_{2l}(x)=\frac{1}{2\pi}\, \int_{-\infty}^\infty dt\int^1_{-1}du\frac{P_{2l}(u)e^{-i x t}}{\cosh(t)-u}$$ I checked the Taylor expansion up to fifth order for $2l=0,2,4,6,8,10$. Do you have any ideas or tips what a good approach could look like to prove the equality analytically? Beside trying standard transformations, I have been thinking about constructing a linear differential equation in x whose solution is given by one of them and showing that the other one also solves it. In particular, the second term is just a simple Fourier transform of the given integrals. The functions seem to be analytical (!?) and in fact for $F$, I did the integral for $\Im(x)<0$ and continued analytically (for the Taylor expansion). Do you have any other tips or ideas to approach this problem?","I have two functions that I expect to be equal (where $P_{2l}$ are the even Legendre Polynomials): $$F_{2l}(x)=x\, \tanh(\pi x/2)\left|\int_0^1 u^{i x-1}P_{2l}(u)\,du\right|^2$$ $$G_{2l}(x)=\frac{1}{2\pi}\, \int_{-\infty}^\infty dt\int^1_{-1}du\frac{P_{2l}(u)e^{-i x t}}{\cosh(t)-u}$$ I checked the Taylor expansion up to fifth order for $2l=0,2,4,6,8,10$. Do you have any ideas or tips what a good approach could look like to prove the equality analytically? Beside trying standard transformations, I have been thinking about constructing a linear differential equation in x whose solution is given by one of them and showing that the other one also solves it. In particular, the second term is just a simple Fourier transform of the given integrals. The functions seem to be analytical (!?) and in fact for $F$, I did the integral for $\Im(x)<0$ and continued analytically (for the Taylor expansion). Do you have any other tips or ideas to approach this problem?",,"['complex-analysis', 'definite-integrals', 'fourier-analysis', 'special-functions', 'orthogonal-polynomials']"
83,Specifying a holomorphic function by a sequence of values,Specifying a holomorphic function by a sequence of values,,"Given a sequence $(z_n, w_n)$ of pairs of complex numbers such that $|z_n| \to \infty$ as $n \to \infty$, there exists a holomorphic function $f$ such that $f(z_n) = w_n$ for all $n$. Proof: By the Weierstrass factorization theorem, there exists a holomorphic function $f_1$ with only simple zeros precisely at each $z_n$. By the Mittag-Leffler theorem, there exists a meromorphic function $f_2$ with only simple poles precisely at each $z_n$ and with residues $w_n /f_1'(z_n)$. If $f = f_1 \cdot f_2$, then $f$ has removable singularities at each $z_n$ with values $w_n$ since \begin{align*} \lim_{z \to z_n} f(z)  &= \lim_{z \to z_n} {f_1(z) - f_1(z_n) \over z-z_n} \cdot \lim_{z \to z_n}(z-z_n) f_2(z) \\[2ex]  &= f_1'(z_n) \cdot \operatorname*{Res}_{z = z_n} f_2(z). \end{align*} One use of this theorem is to give a very motivated definition of the gamma function, if you just want a holomorphic interpolation of the factorial function. So does this theorem have a name? It is considered obvious or trivial? Is it well-known? Which complex analysis textbooks talk about it? Can it be used to prove other interesting things?","Given a sequence $(z_n, w_n)$ of pairs of complex numbers such that $|z_n| \to \infty$ as $n \to \infty$, there exists a holomorphic function $f$ such that $f(z_n) = w_n$ for all $n$. Proof: By the Weierstrass factorization theorem, there exists a holomorphic function $f_1$ with only simple zeros precisely at each $z_n$. By the Mittag-Leffler theorem, there exists a meromorphic function $f_2$ with only simple poles precisely at each $z_n$ and with residues $w_n /f_1'(z_n)$. If $f = f_1 \cdot f_2$, then $f$ has removable singularities at each $z_n$ with values $w_n$ since \begin{align*} \lim_{z \to z_n} f(z)  &= \lim_{z \to z_n} {f_1(z) - f_1(z_n) \over z-z_n} \cdot \lim_{z \to z_n}(z-z_n) f_2(z) \\[2ex]  &= f_1'(z_n) \cdot \operatorname*{Res}_{z = z_n} f_2(z). \end{align*} One use of this theorem is to give a very motivated definition of the gamma function, if you just want a holomorphic interpolation of the factorial function. So does this theorem have a name? It is considered obvious or trivial? Is it well-known? Which complex analysis textbooks talk about it? Can it be used to prove other interesting things?",,"['complex-analysis', 'analyticity']"
84,"$f$ is entire and maps a rectangle to a rectangle, then $f$ is linear","is entire and maps a rectangle to a rectangle, then  is linear",f f,"The problem is in the subject line, I have it for homework. $f$ is a complex valued function. For completeness: Prove that if $f$ is an entire function and for some rectangle $R$, the image $f(R)$ is also a rectangle, then $f$ is linear. The composition of linear maps is linear, so we can choose the two rectangles to have two edges coinciding with the real and imaginary axes, and their common vertex at the origin. So as a portion of the real line gets mapped to itself, we can take $f$ to be the analytic continuation of a real function. Then I'm stuck. This question is confusing me. It's well known from the Riemann mapping theorem that there exists many holomorphic functions taking any rectangle to any other given rectangle. But if $f$ is linear, then the two rectangles must be similar. So the added restraint of $f$ being entire seems to be causing this hassle. Thoughts?","The problem is in the subject line, I have it for homework. $f$ is a complex valued function. For completeness: Prove that if $f$ is an entire function and for some rectangle $R$, the image $f(R)$ is also a rectangle, then $f$ is linear. The composition of linear maps is linear, so we can choose the two rectangles to have two edges coinciding with the real and imaginary axes, and their common vertex at the origin. So as a portion of the real line gets mapped to itself, we can take $f$ to be the analytic continuation of a real function. Then I'm stuck. This question is confusing me. It's well known from the Riemann mapping theorem that there exists many holomorphic functions taking any rectangle to any other given rectangle. But if $f$ is linear, then the two rectangles must be similar. So the added restraint of $f$ being entire seems to be causing this hassle. Thoughts?",,['complex-analysis']
85,Find laurent expansion of $\frac{z-1}{(z-2)(z-3)}$ in annulus {$z:2<|z|<3$}.,Find laurent expansion of  in annulus {}.,\frac{z-1}{(z-2)(z-3)} z:2<|z|<3,"Find the Laurent expansion of $\frac{z-1}{(z-2)(z-3)}$ in annulus { $z:2<|z|<3$ }. So far I have the following; I'm not 100% sure if it is right. $\frac{z-1}{(z-2)(z-3)}$ = $\frac{2}{(z-3)}$ - $\frac{1}{(z-2)}$ For $\frac{1}{(z-2)}$ = $\frac{1}{z}$ $\frac{1}{1-(\frac{2}{z})}$ = $\frac{1}{z}$$\sum_{k=1}^n\frac{2^k}{z^k}$ = $\sum_{k=1}^n\frac{2^k}{z^{k+1}}$ for $|z|<1$ . I am having trouble with the other fraction.  I have seen similar questions asked, but I cannot seem to get the information I need.  Any input would be much appreciated!","Find the Laurent expansion of in annulus { }. So far I have the following; I'm not 100% sure if it is right. = - For = = = for . I am having trouble with the other fraction.  I have seen similar questions asked, but I cannot seem to get the information I need.  Any input would be much appreciated!",\frac{z-1}{(z-2)(z-3)} z:2<|z|<3 \frac{z-1}{(z-2)(z-3)} \frac{2}{(z-3)} \frac{1}{(z-2)} \frac{1}{(z-2)} \frac{1}{z} \frac{1}{1-(\frac{2}{z})} \frac{1}{z}\sum_{k=1}^n\frac{2^k}{z^k} \sum_{k=1}^n\frac{2^k}{z^{k+1}} |z|<1,['complex-analysis']
86,Show that $8^{1/\pi}$ has infinitely many values.,Show that  has infinitely many values.,8^{1/\pi},"Show that $8^{1/\pi}$ has infinitely many values. If it were possible to plot all its values, what would the picture look like. How do I go about solving this.","Show that $8^{1/\pi}$ has infinitely many values. If it were possible to plot all its values, what would the picture look like. How do I go about solving this.",,['complex-analysis']
87,Calculate $\#(Per_n(f))$ when $f(z)=z^2$,Calculate  when,\#(Per_n(f)) f(z)=z^2,"DEFINITIONS: A complex number $z_0$ is called a fixed point of $f$ if $f(z_0)=z_0$. It is called a periodic point of period $n>1$ of $f$ if $f^i(z_0)\neq z_0$ for $1\leq i \leq n-1$ but $f^n(z_0)=z_0$. A complex number $z_0$ is called a preperiodic point if $z_0,f(z_0),\ldots ,f^{k-1}(z_0)$ are not periodic points but $f^k(z_0)$ is a periodic point for some $k\geq 1$. Let $$Fix(f^n)=\{z\in \Bbb C\mid f^n(z)=z\}$$ be the set of all fixed points of $f^n$. Let $Per_n(f)$ be the set of all periodic points of period $n$. Then it is clear $Per_n(f)\subseteq Fix(f^n)$. QUESTION: Consider $f(z)=z^2$. (a) Describe $Fix(f^n)$ and all preperiodic points. (b) Calculate $\#(Per_n(f))$. ATTEMPT: I answered part (a) by finding all solutions of $z^{2^n}=z$. I found that $$Fix(f^n)=\{0\}\cup\{e^{2\pi ik/(2^n-1)}\mid k\in\Bbb Z , 1\leq k \leq 2^n-1\}.$$ i.e. zero union all $2^n-1^{th}$ roots of unity. Then, with a little more thought, I found that $$\{\text{preperiodic points of } f\}=\{e^{2\pi ir}\mid r\in \Bbb Q, r\neq {k\over{2^n-1}} \text{for any } k,n\in \Bbb N\}.$$ i.e. The periodic points of $f$ are all the rational roots of unity that are not fixed points themselves. I found part (b) to be much harder, and this is the question I pose to the forum. I calculated these sets by hand for $1\leq n\leq 8$, working with modular arithmetic, and thought I was on to something but hit a wall. Then I made the sort of obvious realization that $$\#(Per_n(f))=2^n-\sum _{k\mid n, 1\leq k\leq n} \#(Per_k(f)).$$ I think that this is correct, but I'm unhapy with the recursive definition (although it does simplify to be just $2^n-2$ when $2^n-1$ is prime). Is it possible to find the order of this set explicitly for all $n$?","DEFINITIONS: A complex number $z_0$ is called a fixed point of $f$ if $f(z_0)=z_0$. It is called a periodic point of period $n>1$ of $f$ if $f^i(z_0)\neq z_0$ for $1\leq i \leq n-1$ but $f^n(z_0)=z_0$. A complex number $z_0$ is called a preperiodic point if $z_0,f(z_0),\ldots ,f^{k-1}(z_0)$ are not periodic points but $f^k(z_0)$ is a periodic point for some $k\geq 1$. Let $$Fix(f^n)=\{z\in \Bbb C\mid f^n(z)=z\}$$ be the set of all fixed points of $f^n$. Let $Per_n(f)$ be the set of all periodic points of period $n$. Then it is clear $Per_n(f)\subseteq Fix(f^n)$. QUESTION: Consider $f(z)=z^2$. (a) Describe $Fix(f^n)$ and all preperiodic points. (b) Calculate $\#(Per_n(f))$. ATTEMPT: I answered part (a) by finding all solutions of $z^{2^n}=z$. I found that $$Fix(f^n)=\{0\}\cup\{e^{2\pi ik/(2^n-1)}\mid k\in\Bbb Z , 1\leq k \leq 2^n-1\}.$$ i.e. zero union all $2^n-1^{th}$ roots of unity. Then, with a little more thought, I found that $$\{\text{preperiodic points of } f\}=\{e^{2\pi ir}\mid r\in \Bbb Q, r\neq {k\over{2^n-1}} \text{for any } k,n\in \Bbb N\}.$$ i.e. The periodic points of $f$ are all the rational roots of unity that are not fixed points themselves. I found part (b) to be much harder, and this is the question I pose to the forum. I calculated these sets by hand for $1\leq n\leq 8$, working with modular arithmetic, and thought I was on to something but hit a wall. Then I made the sort of obvious realization that $$\#(Per_n(f))=2^n-\sum _{k\mid n, 1\leq k\leq n} \#(Per_k(f)).$$ I think that this is correct, but I'm unhapy with the recursive definition (although it does simplify to be just $2^n-2$ when $2^n-1$ is prime). Is it possible to find the order of this set explicitly for all $n$?",,"['number-theory', 'complex-analysis']"
88,Existence of an antiderivative in $U \cup V$ if it exists in both $U$ and $V$,Existence of an antiderivative in  if it exists in both  and,U \cup V U V,"I'm doing this exercise where I know that a function $f$ that is holomorphic in $U \cup V$, has a holomorphic antiderivative in $U$ and also another holomorphic antiderivative in $V$, where $U, V \subseteq \mathbb{C}$ are open sets such that $U \cap V \neq \emptyset$ and $U \cap V$ is connected. Then the question is to prove that $f$ has a holomorphic antiderivative in the union $U \cup V$, and provide a counterexample to show that the hypothesis on the intersection $U \cap V$ are required for the result to be true. My attempt I thought that since there are holomorphic functions $F: U \rightarrow \mathbb{C}$ and $G: V \rightarrow \mathbb{C}$ such that $F' = f$ in $U$ and $G' = f$ in $V$, then in the intersection both derivatives coincide so in $U \cap V$ we have $F' = G'$ and so $F = G + C$ in $U \cap V$, where $C$ is a constant. But now my problem is that I don't see how to extend this to the whole union $U \cup V$, and I don't see where I'll use the connectedness assumption. So if you could help me with my argument I would be most grateful. By the way, if you could also give me a hint to construct a counterexample that would be great. Thanks.","I'm doing this exercise where I know that a function $f$ that is holomorphic in $U \cup V$, has a holomorphic antiderivative in $U$ and also another holomorphic antiderivative in $V$, where $U, V \subseteq \mathbb{C}$ are open sets such that $U \cap V \neq \emptyset$ and $U \cap V$ is connected. Then the question is to prove that $f$ has a holomorphic antiderivative in the union $U \cup V$, and provide a counterexample to show that the hypothesis on the intersection $U \cap V$ are required for the result to be true. My attempt I thought that since there are holomorphic functions $F: U \rightarrow \mathbb{C}$ and $G: V \rightarrow \mathbb{C}$ such that $F' = f$ in $U$ and $G' = f$ in $V$, then in the intersection both derivatives coincide so in $U \cap V$ we have $F' = G'$ and so $F = G + C$ in $U \cap V$, where $C$ is a constant. But now my problem is that I don't see how to extend this to the whole union $U \cup V$, and I don't see where I'll use the connectedness assumption. So if you could help me with my argument I would be most grateful. By the way, if you could also give me a hint to construct a counterexample that would be great. Thanks.",,['complex-analysis']
89,Non-standard complex structures on $\Bbb H\times \Bbb H$ so that multiplication is holomorphic,Non-standard complex structures on  so that multiplication is holomorphic,\Bbb H\times \Bbb H,"Let $$\mu:\Bbb H\times \Bbb H\to \Bbb H, \qquad (x,y)\mapsto x\cdot_{\Bbb H} y$$ denote the product of two quaternions. With the standard identification $$\Bbb H\cong\Bbb C^2\cong \Bbb R^4, \qquad x_0+ix_1+jx_3+kx_4\equiv (x_0+ix_1, x_3+ix_4)\equiv(x_0,x_1,x_3,x_4)$$ one sees: $$\mu: \Bbb C^4 \to \Bbb C^2,\qquad (z_1,z_2,w_1,w_2)\mapsto (z_1\cdot w_1-z_2\overline{w_2}, z_1w_2+z_2\overline{w_1})$$ and $\mu$ is not holomorphic. My question is whether or one can choose a different complex structure on the domain so that this map does become holomorphic. More precisely: Does there exist a real orthogonal transformation $A\in O(8)$ so that $$(\mu\circ A): \Bbb C^2\times \Bbb C^2\cong\Bbb R^4\times\Bbb R^4\to \Bbb R^4 \cong \Bbb C^2,\qquad x\mapsto \mu(Ax)$$ is holomorphic?",Let denote the product of two quaternions. With the standard identification one sees: and is not holomorphic. My question is whether or one can choose a different complex structure on the domain so that this map does become holomorphic. More precisely: Does there exist a real orthogonal transformation so that is holomorphic?,"\mu:\Bbb H\times \Bbb H\to \Bbb H, \qquad (x,y)\mapsto x\cdot_{\Bbb H} y \Bbb H\cong\Bbb C^2\cong \Bbb R^4, \qquad x_0+ix_1+jx_3+kx_4\equiv (x_0+ix_1, x_3+ix_4)\equiv(x_0,x_1,x_3,x_4) \mu: \Bbb C^4 \to \Bbb C^2,\qquad (z_1,z_2,w_1,w_2)\mapsto (z_1\cdot w_1-z_2\overline{w_2}, z_1w_2+z_2\overline{w_1}) \mu A\in O(8) (\mu\circ A): \Bbb C^2\times \Bbb C^2\cong\Bbb R^4\times\Bbb R^4\to \Bbb R^4 \cong \Bbb C^2,\qquad x\mapsto \mu(Ax)","['complex-analysis', 'complex-geometry', 'quaternions', 'kahler-manifolds']"
90,"If $f$ is complex analytic on $S=\{x+iy : |x|<1, |y|<1\}$, continuous on $\bar{S}$ and bounded by $1,2,3,4$ on each side, then is $|f(0)|>2$ possible?","If  is complex analytic on , continuous on  and bounded by  on each side, then is  possible?","f S=\{x+iy : |x|<1, |y|<1\} \bar{S} 1,2,3,4 |f(0)|>2","I'm a second-year undergraduate taking an introductory course in complex analysis. I am stuck on this problem from one of the previous year's exam: True or False: For a function $f$ analytic on $S = \{ x + iy : x \in \mathbb{R}, y \in \mathbb{R}, |x| < 1, |y| < 1 \}$ and continuous on $\bar{S} = \{ x + iy : x \in \mathbb{R}, y \in \mathbb{R}, |x| \leq 1, |y| \leq 1 \}$ , and satisfying that $|f|$ is bounded on the four sides $\gamma_1, \gamma_2, \gamma_3, \gamma_4$ of the square $\bar{S}$ respectively by $1, 2, 3, 4$ , it is possible to have $|f(0)| > 2$ . I'm not able to disprove the existence of such a function or construct an example of such a function, but my guess is that it should be false. We have learnt about the Maximum Modulus Theorem, which says that A non-constant holomorphic function on an open connected domain never attains its maximum modulus at any point in the domain. Maybe by shifting the function $f$ by some constant or linear function I can show that it violates this Theorem, and so $f$ cannot exist, but I am not able to come up with a proof. Another result that we were taught that seems relevant is the Schwarz Lemma, which says that: Let $\mathbb{D} = \{ z : |z| < 1 \}$ be the open unit disk and let $f \colon \mathbb{D} \to \mathbb{C}$ be a holomorphic map such that $f(0) = 0$ and $|f(z)| \leq 1$ on $\mathbb{D}$ . Then $|f(z)| \leq |z|$ $\forall\ z \in \mathbb{D}$ and $|f'(0)| \leq 1$ . Moreover, if $|f(z)| = |z|$ for some non-zero $z$ or $|f'(0)| = 1$ , then $f(z) = az$ for some $a \in \mathbb{C}$ with $|a| = 1$ . Maybe by considering the restriction of $f$ to the unit disk and rescaling I could apply Schwarz Lemma, but I'm not sure how to go about this either. Of course, I could be wrong and there is indeed such a function $f$ , but in that case, I don't know how to go about constructing it. How can I solve this problem? Any useful hints are also fine, a complete solution is not necessary.","I'm a second-year undergraduate taking an introductory course in complex analysis. I am stuck on this problem from one of the previous year's exam: True or False: For a function analytic on and continuous on , and satisfying that is bounded on the four sides of the square respectively by , it is possible to have . I'm not able to disprove the existence of such a function or construct an example of such a function, but my guess is that it should be false. We have learnt about the Maximum Modulus Theorem, which says that A non-constant holomorphic function on an open connected domain never attains its maximum modulus at any point in the domain. Maybe by shifting the function by some constant or linear function I can show that it violates this Theorem, and so cannot exist, but I am not able to come up with a proof. Another result that we were taught that seems relevant is the Schwarz Lemma, which says that: Let be the open unit disk and let be a holomorphic map such that and on . Then and . Moreover, if for some non-zero or , then for some with . Maybe by considering the restriction of to the unit disk and rescaling I could apply Schwarz Lemma, but I'm not sure how to go about this either. Of course, I could be wrong and there is indeed such a function , but in that case, I don't know how to go about constructing it. How can I solve this problem? Any useful hints are also fine, a complete solution is not necessary.","f S = \{ x + iy : x \in \mathbb{R}, y \in \mathbb{R}, |x| < 1, |y| < 1 \} \bar{S} = \{ x + iy : x \in \mathbb{R}, y \in \mathbb{R}, |x| \leq 1, |y| \leq 1 \} |f| \gamma_1, \gamma_2, \gamma_3, \gamma_4 \bar{S} 1, 2, 3, 4 |f(0)| > 2 f f \mathbb{D} = \{ z : |z| < 1 \} f \colon \mathbb{D} \to \mathbb{C} f(0) = 0 |f(z)| \leq 1 \mathbb{D} |f(z)| \leq |z| \forall\ z \in \mathbb{D} |f'(0)| \leq 1 |f(z)| = |z| z |f'(0)| = 1 f(z) = az a \in \mathbb{C} |a| = 1 f f",['complex-analysis']
91,Prove the zeros of a polynomial all lie in an annulus.,Prove the zeros of a polynomial all lie in an annulus.,,"I am working on a problem. It has two parts: (a) Let $c_{0}>c_{1}>\cdots c_{n}>0$ . Show that the polynomial $P(z):=c_{0}+c_{1}z+\cdots+c_{n}z^{n}$ has no zeros inside the closed unit disc. (b) Show that the zeros of polynomial $P_{n}(z):=1+\frac{z}{2}+\frac{z^{2}}{3}+\cdots+\frac{z^{n}}{n+1}$ all lie in an annulus $\{1<|z|<1+\delta_{n}\}$ where $\delta_{n}\rightarrow 0$ as $n\rightarrow\infty$ . I've proved part (a), but I am stuck in part (b). I think the proof of part (b) may be similar to part (a), so I state part (a) above and give my proof below, then I will give my attempt for part (b). Part (a): Suppose there exists $z_{0}\in\mathbb{C}$ such that $P(z_{0})=0$ and $|z_{0}|<1$ . Since $P(z_{0})=0$ , we also have $$(1-z_{0})P(z_{0})=0, $$ where $LHS=c_{0}+(c_{1}-c_{0})z_{0}+(c_{2}-c_{1})z_{0}^{2}+\cdots+ (c_{n}-c_{n-1})z_{0}^{n}-c_{n}z_{0}^{n+1}.$ Thus, we have $$c_{0}=(c_{0}-c_{1})z_{0}+(c_{1}-c_{2})z_{0}^{2}+\cdots (c_{n-1}-c_{n})z_{0}^{n}+c_{n}z_{0}^{n+1}.$$ Now, taking norm to both side, and recalling that $c_{0}>c_{1}>\cdots>c_{n}>0$ and $|z_{0}|<1$ , we have \begin{align*} c_{0}&<c_{0}-c_{1}+c_{1}-c_{2}+\cdots+c_{n-1}-c_{n}+c_{n}\\ &=c_{0} \end{align*} which is a contradiction. Thus, there is no zero of $P(z)$ that is inside the closed unit disc. Part (b): For part (b), I mimic what I've done in part (a). Let $z\in\mathbb{C}$ be a zero of $P_{n}(z)$ , then $P_{n}(z)=0$ implies that $$(1-z)P_{n}(z)=0.$$ Thus, we have $$\Big(1-\dfrac{z^{n+1}}{n+1}\Big)-\dfrac{z}{2}-\dfrac{z^{2}}{6}-\cdots-\dfrac{z^{n}}{n(n+1)}=0.$$ Set $Q_{n}(z):=-\dfrac{z}{2}-\dfrac{z^{2}}{6}-\cdots-\dfrac{z^{n}}{n(n+1)}.$ Then if $|z|<1$ , we have \begin{align*} 1&\leq|Q_{n}(z)|+\Big|\dfrac{z^{n+1}}{n+1}\Big|\\ &\leq\dfrac{|z|}{2}+\dfrac{|z|^{2}}{6}+\cdots+\dfrac{|z|^{n}}{n(n+1)}+\dfrac{|z|^{n+1}}{n+1}\\ &<\dfrac{1}{2}+\dfrac{1}{6}+\cdots+\dfrac{1}{n(n+1)}+\dfrac{1}{n+1}\\ &=1-\dfrac{1}{2}+\dfrac{1}{2}-\dfrac{1}{3}+\cdots+\dfrac{1}{n}-\dfrac{1}{n+1}+\dfrac{1}{n+1}\\ &=1, \end{align*} which is a contradiction. Thus, zeros of $P_{n}(z)$ must lie in $|z|\geq 1$ . Then, I try to get rid of $|z|=1$ by using the same techniques, but I found something else interesting. If $|z|=1$ , then by definition $$|Q_{n}(z)|\leq 1-\dfrac{1}{2}+\dfrac{1}{2}-\dfrac{1}{3}+\cdots+\dfrac{1}{n}-\dfrac{1}{n+1}=\dfrac{n}{n+1}.$$ On the other hand, since we assume $z$ is a zero, we have $$|Q_{n}(z)|=\Big|1-\dfrac{z^{n+1}}{n+1}\Big|\geq \Big|1-\dfrac{1}{n+1}\Big|=\dfrac{n}{n+1}.$$ Thus, if $|z|=1$ , we have $$\dfrac{n}{n+1}\leq |Q_{n}(z)|\leq\dfrac{n}{n+1},$$ and thus $$|Q_{n}(z)|=\dfrac{n}{n+1}.$$ This did not give me any contradiction, but an idea of $\delta_{n}$ . By the problem itself, we can see that if $\delta_{n}\rightarrow 0$ , then the annulus will become to a unit circle $|z|=1$ , which is exactly our case. Also, by my argument above, I want my $\delta_{n}$ to be related to $|Q_{n}(z)|$ , so I tried to set $$1+\delta_{n}=\dfrac{n}{n+1},$$ which gives us $$\delta_{n}=-\dfrac{1}{n+1},$$ which tends to be $0$ as $n\rightarrow\infty$ . But then I don't know how to proceed, what should I do now? Thank you!","I am working on a problem. It has two parts: (a) Let . Show that the polynomial has no zeros inside the closed unit disc. (b) Show that the zeros of polynomial all lie in an annulus where as . I've proved part (a), but I am stuck in part (b). I think the proof of part (b) may be similar to part (a), so I state part (a) above and give my proof below, then I will give my attempt for part (b). Part (a): Suppose there exists such that and . Since , we also have where Thus, we have Now, taking norm to both side, and recalling that and , we have which is a contradiction. Thus, there is no zero of that is inside the closed unit disc. Part (b): For part (b), I mimic what I've done in part (a). Let be a zero of , then implies that Thus, we have Set Then if , we have which is a contradiction. Thus, zeros of must lie in . Then, I try to get rid of by using the same techniques, but I found something else interesting. If , then by definition On the other hand, since we assume is a zero, we have Thus, if , we have and thus This did not give me any contradiction, but an idea of . By the problem itself, we can see that if , then the annulus will become to a unit circle , which is exactly our case. Also, by my argument above, I want my to be related to , so I tried to set which gives us which tends to be as . But then I don't know how to proceed, what should I do now? Thank you!","c_{0}>c_{1}>\cdots c_{n}>0 P(z):=c_{0}+c_{1}z+\cdots+c_{n}z^{n} P_{n}(z):=1+\frac{z}{2}+\frac{z^{2}}{3}+\cdots+\frac{z^{n}}{n+1} \{1<|z|<1+\delta_{n}\} \delta_{n}\rightarrow 0 n\rightarrow\infty z_{0}\in\mathbb{C} P(z_{0})=0 |z_{0}|<1 P(z_{0})=0 (1-z_{0})P(z_{0})=0,  LHS=c_{0}+(c_{1}-c_{0})z_{0}+(c_{2}-c_{1})z_{0}^{2}+\cdots+ (c_{n}-c_{n-1})z_{0}^{n}-c_{n}z_{0}^{n+1}. c_{0}=(c_{0}-c_{1})z_{0}+(c_{1}-c_{2})z_{0}^{2}+\cdots (c_{n-1}-c_{n})z_{0}^{n}+c_{n}z_{0}^{n+1}. c_{0}>c_{1}>\cdots>c_{n}>0 |z_{0}|<1 \begin{align*}
c_{0}&<c_{0}-c_{1}+c_{1}-c_{2}+\cdots+c_{n-1}-c_{n}+c_{n}\\
&=c_{0}
\end{align*} P(z) z\in\mathbb{C} P_{n}(z) P_{n}(z)=0 (1-z)P_{n}(z)=0. \Big(1-\dfrac{z^{n+1}}{n+1}\Big)-\dfrac{z}{2}-\dfrac{z^{2}}{6}-\cdots-\dfrac{z^{n}}{n(n+1)}=0. Q_{n}(z):=-\dfrac{z}{2}-\dfrac{z^{2}}{6}-\cdots-\dfrac{z^{n}}{n(n+1)}. |z|<1 \begin{align*}
1&\leq|Q_{n}(z)|+\Big|\dfrac{z^{n+1}}{n+1}\Big|\\
&\leq\dfrac{|z|}{2}+\dfrac{|z|^{2}}{6}+\cdots+\dfrac{|z|^{n}}{n(n+1)}+\dfrac{|z|^{n+1}}{n+1}\\
&<\dfrac{1}{2}+\dfrac{1}{6}+\cdots+\dfrac{1}{n(n+1)}+\dfrac{1}{n+1}\\
&=1-\dfrac{1}{2}+\dfrac{1}{2}-\dfrac{1}{3}+\cdots+\dfrac{1}{n}-\dfrac{1}{n+1}+\dfrac{1}{n+1}\\
&=1,
\end{align*} P_{n}(z) |z|\geq 1 |z|=1 |z|=1 |Q_{n}(z)|\leq 1-\dfrac{1}{2}+\dfrac{1}{2}-\dfrac{1}{3}+\cdots+\dfrac{1}{n}-\dfrac{1}{n+1}=\dfrac{n}{n+1}. z |Q_{n}(z)|=\Big|1-\dfrac{z^{n+1}}{n+1}\Big|\geq \Big|1-\dfrac{1}{n+1}\Big|=\dfrac{n}{n+1}. |z|=1 \dfrac{n}{n+1}\leq |Q_{n}(z)|\leq\dfrac{n}{n+1}, |Q_{n}(z)|=\dfrac{n}{n+1}. \delta_{n} \delta_{n}\rightarrow 0 |z|=1 \delta_{n} |Q_{n}(z)| 1+\delta_{n}=\dfrac{n}{n+1}, \delta_{n}=-\dfrac{1}{n+1}, 0 n\rightarrow\infty","['complex-analysis', 'proof-verification']"
92,Defining the square root of $z$ squared and determining the location of branch cuts,Defining the square root of  squared and determining the location of branch cuts,z,"I am asked the following: For $\epsilon > 0$, we define     $$ \sqrt{z^2} = \lim_{\epsilon \to 0} \sqrt{z^2 + \epsilon^2}\,, $$     where the principle value square root is used on the right-hand side.     Determine the location of the branch cuts and show that $\sqrt{z^2} = \text{sign}(\text{Re } z) z$ I have tried the following. Let $\epsilon > 0$ be given and l et $z-i\epsilon = r_1 e^{i\theta_1}$ and $z+i\epsilon = r_2 e^{i\theta_2}$. I know we can write  $$f_\epsilon(z) := \sqrt{z^2 + \epsilon^2} = \sqrt{(z-i\epsilon)(z+i\epsilon)} = \sqrt{r_1r_2} e^{i(\theta_1 + \theta_2)/2}\,.$$ I see that the branch points are $i\epsilon$ and $-i\epsilon$. Now, following the reasoning done in this StackExchange question and this handout, we can argue that $[-i\epsilon, i\epsilon]$ would be a sufficient branch cut to make $f_\epsilon(z)$ single-valued. The book defines the principle value square root by a branch cut along the negative real axis, corresponding to $\sqrt 1 = 1$. This means $\sqrt z = \sqrt r e^{\theta i / 2}$ where $\theta \in (-\pi, \pi]$, the principle value of the argument, i.e. $\text{Arg } z$. In the given defition, the principle value square root is used, therefore; $\theta_1, \theta_2 \in (-\pi, \pi]$. Does this mean that, for example, reasoning about encircling $z = i\epsilon$ (and not $z = -i\epsilon$), as done in mentioned StackExchange question; $$\sqrt{r_1}e^{i(\theta_1+2\pi)/2} = \sqrt{r_1}e^{i\theta_1/2}e^{\pi i} = -\sqrt{r_1}e^{i\theta_1/2}\,,$$ is not permitted by the bounds of $\theta_1$? I'm not quite sure whether this means I am force to make the branch cuts $[i\epsilon, \infty)$ and $[-i\epsilon, -\infty)$. As for the follow-up question; $\sqrt{z^2} = \text{sign}(\text{Re } z) z$, I have tried writing it as follows: $$ \begin{align*} \sqrt{z^2} &= e^{\log(z^2)/2} \\ &= e^{\frac{1}{2}\left( \ln |z|^2 + i \text{Arg} (z^2) \right)} \\ &= |z|e^{i \text{Arg} (z^2)}\,. \end{align*} $$ This means I have to show $e^{i \text{Arg} (z^2)} = \text{sign}(\text{Re } z)e^{i \text{Arg} z}$, which I've been unable to do thus far.","I am asked the following: For $\epsilon > 0$, we define     $$ \sqrt{z^2} = \lim_{\epsilon \to 0} \sqrt{z^2 + \epsilon^2}\,, $$     where the principle value square root is used on the right-hand side.     Determine the location of the branch cuts and show that $\sqrt{z^2} = \text{sign}(\text{Re } z) z$ I have tried the following. Let $\epsilon > 0$ be given and l et $z-i\epsilon = r_1 e^{i\theta_1}$ and $z+i\epsilon = r_2 e^{i\theta_2}$. I know we can write  $$f_\epsilon(z) := \sqrt{z^2 + \epsilon^2} = \sqrt{(z-i\epsilon)(z+i\epsilon)} = \sqrt{r_1r_2} e^{i(\theta_1 + \theta_2)/2}\,.$$ I see that the branch points are $i\epsilon$ and $-i\epsilon$. Now, following the reasoning done in this StackExchange question and this handout, we can argue that $[-i\epsilon, i\epsilon]$ would be a sufficient branch cut to make $f_\epsilon(z)$ single-valued. The book defines the principle value square root by a branch cut along the negative real axis, corresponding to $\sqrt 1 = 1$. This means $\sqrt z = \sqrt r e^{\theta i / 2}$ where $\theta \in (-\pi, \pi]$, the principle value of the argument, i.e. $\text{Arg } z$. In the given defition, the principle value square root is used, therefore; $\theta_1, \theta_2 \in (-\pi, \pi]$. Does this mean that, for example, reasoning about encircling $z = i\epsilon$ (and not $z = -i\epsilon$), as done in mentioned StackExchange question; $$\sqrt{r_1}e^{i(\theta_1+2\pi)/2} = \sqrt{r_1}e^{i\theta_1/2}e^{\pi i} = -\sqrt{r_1}e^{i\theta_1/2}\,,$$ is not permitted by the bounds of $\theta_1$? I'm not quite sure whether this means I am force to make the branch cuts $[i\epsilon, \infty)$ and $[-i\epsilon, -\infty)$. As for the follow-up question; $\sqrt{z^2} = \text{sign}(\text{Re } z) z$, I have tried writing it as follows: $$ \begin{align*} \sqrt{z^2} &= e^{\log(z^2)/2} \\ &= e^{\frac{1}{2}\left( \ln |z|^2 + i \text{Arg} (z^2) \right)} \\ &= |z|e^{i \text{Arg} (z^2)}\,. \end{align*} $$ This means I have to show $e^{i \text{Arg} (z^2)} = \text{sign}(\text{Re } z)e^{i \text{Arg} z}$, which I've been unable to do thus far.",,"['complex-analysis', 'radicals', 'branch-cuts', 'branch-points']"
93,$f$ is an entire function such that $f(0)=0$,is an entire function such that,f f(0)=0,"Let $f$ be a non-constant entire function satisfying the following conditions: $f(0)=0$ and for each $N \gt 0$ the set $\{z \mid \left| f(z)\right| < N\}$ is connected. Prove that $f(z)=cz^n$ for some constant $c$ and positive integer $n$. $f(0)=0$ implies there is $r>0$ such that $f(z)\neq 0$ for any $z\in \{z: 0<|z|\leq r\}$ All I can see it $0$ is the only root of $f(z)$. Suppose not, for small $M$,  the set $\{z: |f(z)|<M\}$ contains disjoint open sets which contradicts connectedness of the set. So, there is only one root. So, $0$ is the only root of $f(z)$. Can we now say that we are forced to have $f(z)=cz^n$ for some $n$? I could not see more than this.. please give some hints.","Let $f$ be a non-constant entire function satisfying the following conditions: $f(0)=0$ and for each $N \gt 0$ the set $\{z \mid \left| f(z)\right| < N\}$ is connected. Prove that $f(z)=cz^n$ for some constant $c$ and positive integer $n$. $f(0)=0$ implies there is $r>0$ such that $f(z)\neq 0$ for any $z\in \{z: 0<|z|\leq r\}$ All I can see it $0$ is the only root of $f(z)$. Suppose not, for small $M$,  the set $\{z: |f(z)|<M\}$ contains disjoint open sets which contradicts connectedness of the set. So, there is only one root. So, $0$ is the only root of $f(z)$. Can we now say that we are forced to have $f(z)=cz^n$ for some $n$? I could not see more than this.. please give some hints.",,['complex-analysis']
94,Series for $\text{Arg}( \zeta (z))$ [closed],Series for  [closed],\text{Arg}( \zeta (z)),"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 years ago . Improve this question Though I don't know if the formula I've found is useful, I decided to publish it anyway. $$ \text{Arg}( \zeta (z)) = -\sum_ {k = 1}^{\infty}\sum _ {q = 1}^{\infty}\frac {1} {k P_q^{k x}}\text {Sin}( k y \text{ Log}(P_q ) ) \text{ , } |z|>1 $$ where $z=x+i y$ and $p_q$ is th $q^{th}$ prime number. Here is an example with a plot of $\text{Arg}( \zeta (1+i y))$ in blue, and a plot of the sum in red: My question is whether the formula is known, whether someone finds it helpful. EDIT: this post was put 'on hold'. I don't know why. I'm a graphist and foreigner to the mathematics' community, thus it's very hard for me to check the results I got, and this is the reason of this post. EDIT 2: If someone's interested, this other post shows at the end how the series was calculated simple tools to extract Re, Im, Abs... of any complex function","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 years ago . Improve this question Though I don't know if the formula I've found is useful, I decided to publish it anyway. $$ \text{Arg}( \zeta (z)) = -\sum_ {k = 1}^{\infty}\sum _ {q = 1}^{\infty}\frac {1} {k P_q^{k x}}\text {Sin}( k y \text{ Log}(P_q ) ) \text{ , } |z|>1 $$ where $z=x+i y$ and $p_q$ is th $q^{th}$ prime number. Here is an example with a plot of $\text{Arg}( \zeta (1+i y))$ in blue, and a plot of the sum in red: My question is whether the formula is known, whether someone finds it helpful. EDIT: this post was put 'on hold'. I don't know why. I'm a graphist and foreigner to the mathematics' community, thus it's very hard for me to check the results I got, and this is the reason of this post. EDIT 2: If someone's interested, this other post shows at the end how the series was calculated simple tools to extract Re, Im, Abs... of any complex function",,"['complex-analysis', 'riemann-zeta']"
95,Describing co-ordinate systems in 3D for which Laplace's equation is separable,Describing co-ordinate systems in 3D for which Laplace's equation is separable,,"Laplace's Equation in 3 dimensions is given by $$\nabla^2f=\frac{ \partial^2f}{\partial x^2}+\frac{ \partial^2f}{\partial z^2}+\frac{ \partial^2f}{\partial y^2}=0$$ and  is a very important PDE in many areas of science. One of the usual ways to solve it is by seperation of variables . We let $f(x,y,z)=X(x)Y(y)Z(z)$ and then the PDE reduces to 3 independent ODE's of the form $X''(x)+k^2 x=0$ with $k$ a constant. This method works for a surprising number of coordinate systems. I can use cylindrical coordinates, spherical coordinates, bi-spherical coordinates and more. In fact in 2 dimensions, I can take $\mathbb{R}^2$ to be $\mathbb{C}$, and then any analytic function $f(z)$ maps the Cartesian coordinates of $\mathbb{R}^2$ onto a set of coordinates that is separable in Laplace's equation. This follows from analytic functions also being harmonic functions. For example $f(z)=z^2$ maps the cartesian coordinates to the parabolic coordinates . So how about in 3 dimensions? Is there a way to describe all coordinate systems such that the Laplacian separates in this way?I have no idea how to start. I think that Confocal Ellipsoidal Coordinates will work but I'm not sure how to verify it. I'm not familIar with differential geometry, so any help appreciated. Image source","Laplace's Equation in 3 dimensions is given by $$\nabla^2f=\frac{ \partial^2f}{\partial x^2}+\frac{ \partial^2f}{\partial z^2}+\frac{ \partial^2f}{\partial y^2}=0$$ and  is a very important PDE in many areas of science. One of the usual ways to solve it is by seperation of variables . We let $f(x,y,z)=X(x)Y(y)Z(z)$ and then the PDE reduces to 3 independent ODE's of the form $X''(x)+k^2 x=0$ with $k$ a constant. This method works for a surprising number of coordinate systems. I can use cylindrical coordinates, spherical coordinates, bi-spherical coordinates and more. In fact in 2 dimensions, I can take $\mathbb{R}^2$ to be $\mathbb{C}$, and then any analytic function $f(z)$ maps the Cartesian coordinates of $\mathbb{R}^2$ onto a set of coordinates that is separable in Laplace's equation. This follows from analytic functions also being harmonic functions. For example $f(z)=z^2$ maps the cartesian coordinates to the parabolic coordinates . So how about in 3 dimensions? Is there a way to describe all coordinate systems such that the Laplacian separates in this way?I have no idea how to start. I think that Confocal Ellipsoidal Coordinates will work but I'm not sure how to verify it. I'm not familIar with differential geometry, so any help appreciated. Image source",,"['complex-analysis', 'differential-geometry', 'partial-differential-equations', 'coordinate-systems', 'harmonic-functions']"
96,Proof of the product formula for sine function,Proof of the product formula for sine function,,"I am looking for a simple way to prove $$\frac{\sin \pi z}{\pi z}=\prod_{n=1}^\infty \left(1-\frac{z^2}{n^2}\right)$$ using mainly on the fact that the entire function has simple zeros at $n=\pm 1, \pm 2,\cdots$.","I am looking for a simple way to prove $$\frac{\sin \pi z}{\pi z}=\prod_{n=1}^\infty \left(1-\frac{z^2}{n^2}\right)$$ using mainly on the fact that the entire function has simple zeros at $n=\pm 1, \pm 2,\cdots$.",,"['complex-analysis', 'infinite-product']"
97,N-nacci Identities: The Final Question (Generalizing Time!),N-nacci Identities: The Final Question (Generalizing Time!),,"Okay so here is my personal work on the problem set. I only have question 5 remaining which involves generalization of any recursive sequence. $n$'s correspond to the $n$  in n-nacci. I hope to write a paper in which I discuss my results and to devise a theorem describing a method which to find any ath term of a recursion sequence. (Beginning with a n-nacci sequence) Links to previous postings: Fibonacci Numbers - Complex Analysis Fibonacci( Binet's Formula Derivation)-Revised with work shown Here's my attempt on the problem set on page 106 thus far: (Number 5 being the only question that I have left) http://www.math.binghamton.edu/sabalka/teaching/09Spring375/Chapter10.pdf (2) To derive a generating function for $f_a$, note that the n-nacci series is defined by the sequence of numbers $f_a = f_{a-1}+f_{a-2}+f_{a-3} \cdots + f_{a-n}, \ldots )$. If we break this up into $n+1$ separate generating functions and sum them to obtain the generating function $F(z)$ it will look something like: for a $F(z) = f_0+f_1z+f_2z^2+...+f_az^a$ $$(0,1,0,0,0...) \rightarrow\,z)$$ $$+(0,f_0,f_1,f_2, \cdots )\to\,zF(z)$$  $$+ (0,0,f_0,f_1,f_2, \cdots )\to z^2F(z)$$ $$+ (0,0,0,f_0,f_1,f_2, \cdots )\to z^3F(z)$$  $ \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \small \bullet $ $ \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \small \bullet $ $ \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \small \bullet $  $$+ (0_1,0_2,0_3, \cdots ,0_n,f_0,f_1,f_2, \cdots )\to z^nF(z)$$ This all equals $$(0,1, \cdots f_{a-1}+f_{a-2}+f_{a-3} + \cdots +f_{a-n})\to z+zF(z)+z^2F(z)+z^3F(z) + \cdots + z^nF(z)$$ Therefore $F(z)=z+zF(z)+z^2F(z)+z^3F(z) + \cdots + z^nF(z)$, solving for $F(z)$ we obtain $$F(z) = \frac {z}{1-z-z^2-z^3- \cdots - z^n} \bullet$$ Am I on the right track? ~ I felt that it would make more sense to do (2) before (1) here's (1) *First note that by the quadratic formula, the two roots of the denominator are $\varphi,\bar \varphi$ where $\varphi= \frac {1+\sqrt5}{2}$. $$\lim_{n\to\infty}\left|\frac{f_{n+1}z^{n+1}}{f_nz^n}\right|=|z|\lim_{n\to\infty}\frac{f_{n+1}}{f_n}=\varphi|z|\;,$$ so the radius of convergence is $\dfrac1\varphi=\dfrac{-1+\sqrt5}2$ Don't have any clue how to generalize this to a n-nacci sequence. ~ (3) $Res(f,c) = \frac{1}{a-1!}\lim_{z\to c}\frac{d^a-1}{dz^a-1} ((z-c)^aF(z)$ for a pole of order $a$. $$1=Res_{z=0}z^{-1}$$ then  $z^{a+1}$ would be the extracting term: $$f_a=Res_{z=0}\frac{1}{z^{a+1}} \sum_{n>1}{f_az^a}$$ Could I instead generalize this to? $$\operatorname {Res}_{z=0}\left(\frac{z}{z^{a+1}(1-z-z^2-z^3- \cdots -z^n)}\right)$$ $$\begin{align*} &=\frac1{a!}\lim_{z\to 0}\frac{d^a}{dz^a}\left(z^{a+1}\frac{z}{z^{a+1}(1-z-z^2-z^3- \cdots - z^n)}\right)\\ &=\frac1{a!}\lim_{z\to 0}\frac{d^a}{dz^a}\big(F(z)\big)\\ &=\frac1{a!}\lim_{z\to 0}\frac{d^a}{dz^a}\sum_{k\ge 0}f_kz^k\\ &=\frac1{a!}\lim_{z\to 0}\sum_{k\ge 0}f_k\frac{d^a}{dz^a}z^k\\ &=\frac1{a!}\lim_{z\to 0}\sum_{k\ge a}f_k \Big( \prod_{i=0}^{a-1} (k-i) \Big)z^{k-a}\\ &=\frac1{a!}\lim_{z\to 0}\left(f_aa!+\sum_{k>a}f_k \Big( \prod_{i=0}^{a-1} (k-i) \Big) z^{k-a}\right)\\ &=f_n+\frac1{a!}\lim_{z\to 0}z\sum_{k\ge a+1}f_k \Big( \prod_{i=0}^{a-1} (k-i) \Big) z^{k-(a+1)}\ &=f_n\; \bullet \end{align*}$$","Okay so here is my personal work on the problem set. I only have question 5 remaining which involves generalization of any recursive sequence. $n$'s correspond to the $n$  in n-nacci. I hope to write a paper in which I discuss my results and to devise a theorem describing a method which to find any ath term of a recursion sequence. (Beginning with a n-nacci sequence) Links to previous postings: Fibonacci Numbers - Complex Analysis Fibonacci( Binet's Formula Derivation)-Revised with work shown Here's my attempt on the problem set on page 106 thus far: (Number 5 being the only question that I have left) http://www.math.binghamton.edu/sabalka/teaching/09Spring375/Chapter10.pdf (2) To derive a generating function for $f_a$, note that the n-nacci series is defined by the sequence of numbers $f_a = f_{a-1}+f_{a-2}+f_{a-3} \cdots + f_{a-n}, \ldots )$. If we break this up into $n+1$ separate generating functions and sum them to obtain the generating function $F(z)$ it will look something like: for a $F(z) = f_0+f_1z+f_2z^2+...+f_az^a$ $$(0,1,0,0,0...) \rightarrow\,z)$$ $$+(0,f_0,f_1,f_2, \cdots )\to\,zF(z)$$  $$+ (0,0,f_0,f_1,f_2, \cdots )\to z^2F(z)$$ $$+ (0,0,0,f_0,f_1,f_2, \cdots )\to z^3F(z)$$  $ \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \small \bullet $ $ \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \small \bullet $ $ \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \small \bullet $  $$+ (0_1,0_2,0_3, \cdots ,0_n,f_0,f_1,f_2, \cdots )\to z^nF(z)$$ This all equals $$(0,1, \cdots f_{a-1}+f_{a-2}+f_{a-3} + \cdots +f_{a-n})\to z+zF(z)+z^2F(z)+z^3F(z) + \cdots + z^nF(z)$$ Therefore $F(z)=z+zF(z)+z^2F(z)+z^3F(z) + \cdots + z^nF(z)$, solving for $F(z)$ we obtain $$F(z) = \frac {z}{1-z-z^2-z^3- \cdots - z^n} \bullet$$ Am I on the right track? ~ I felt that it would make more sense to do (2) before (1) here's (1) *First note that by the quadratic formula, the two roots of the denominator are $\varphi,\bar \varphi$ where $\varphi= \frac {1+\sqrt5}{2}$. $$\lim_{n\to\infty}\left|\frac{f_{n+1}z^{n+1}}{f_nz^n}\right|=|z|\lim_{n\to\infty}\frac{f_{n+1}}{f_n}=\varphi|z|\;,$$ so the radius of convergence is $\dfrac1\varphi=\dfrac{-1+\sqrt5}2$ Don't have any clue how to generalize this to a n-nacci sequence. ~ (3) $Res(f,c) = \frac{1}{a-1!}\lim_{z\to c}\frac{d^a-1}{dz^a-1} ((z-c)^aF(z)$ for a pole of order $a$. $$1=Res_{z=0}z^{-1}$$ then  $z^{a+1}$ would be the extracting term: $$f_a=Res_{z=0}\frac{1}{z^{a+1}} \sum_{n>1}{f_az^a}$$ Could I instead generalize this to? $$\operatorname {Res}_{z=0}\left(\frac{z}{z^{a+1}(1-z-z^2-z^3- \cdots -z^n)}\right)$$ $$\begin{align*} &=\frac1{a!}\lim_{z\to 0}\frac{d^a}{dz^a}\left(z^{a+1}\frac{z}{z^{a+1}(1-z-z^2-z^3- \cdots - z^n)}\right)\\ &=\frac1{a!}\lim_{z\to 0}\frac{d^a}{dz^a}\big(F(z)\big)\\ &=\frac1{a!}\lim_{z\to 0}\frac{d^a}{dz^a}\sum_{k\ge 0}f_kz^k\\ &=\frac1{a!}\lim_{z\to 0}\sum_{k\ge 0}f_k\frac{d^a}{dz^a}z^k\\ &=\frac1{a!}\lim_{z\to 0}\sum_{k\ge a}f_k \Big( \prod_{i=0}^{a-1} (k-i) \Big)z^{k-a}\\ &=\frac1{a!}\lim_{z\to 0}\left(f_aa!+\sum_{k>a}f_k \Big( \prod_{i=0}^{a-1} (k-i) \Big) z^{k-a}\right)\\ &=f_n+\frac1{a!}\lim_{z\to 0}z\sum_{k\ge a+1}f_k \Big( \prod_{i=0}^{a-1} (k-i) \Big) z^{k-(a+1)}\ &=f_n\; \bullet \end{align*}$$",,"['complex-analysis', 'fibonacci-numbers']"
98,Primality using $\Gamma(x)$,Primality using,\Gamma(x),"Wilson's theorem states $n \in \mathbb N$ is prime iff $(n-1)! \equiv -1\pmod n$. The $\Gamma$-function extends the usual factorial to complex numbers. What are the complex numbers such that $\Gamma(z)+1 = nz$ , $n \in \mathbb Z$? Eisenstein or Gaussian primes don't necessarily satisfy the requirement, take for  example $2+\omega$ and $5+12i$ respectively. What I've tried: Let $z=a+ib$. From the definition of the $\Gamma$-function, we have $\Gamma(z)=(z-1)\Gamma(z-1)$. $\Gamma(a+ib)=(a-1+ib)\Gamma(a-1+ib)$ $=(a-1+ib)(a-2+ib)\Gamma(a-2+ib)$ $=(a-1+ib)(a-2+ib)\cdots(a-k+ib)\Gamma(a-k+ib)$ $=\Gamma(ib)\prod_{k=0}^{a-1}{(k+ib)}$ Now, turning to the imaginary-$\Gamma$, a brick wall I ran into... $$\Gamma(ib)= \int_0^{\infty}\frac{t^{-1+ib}}{e^t}\mathrm{d}t$$ ... and cannot evaluate. Questions How do we evaluate $\Gamma(a+ib)$? How should we go about solving for $z$ once 1. is done? Computational 'evidence' Wolfram|Alpha thinks these $z$ exist, infact they seem plentiful. I'm not sure if approximation is muddling the results, but I doubt it. I'm using solve Gamma(a+ib) + 1= n(a+ib) and plugging in values of $a,b,n$.","Wilson's theorem states $n \in \mathbb N$ is prime iff $(n-1)! \equiv -1\pmod n$. The $\Gamma$-function extends the usual factorial to complex numbers. What are the complex numbers such that $\Gamma(z)+1 = nz$ , $n \in \mathbb Z$? Eisenstein or Gaussian primes don't necessarily satisfy the requirement, take for  example $2+\omega$ and $5+12i$ respectively. What I've tried: Let $z=a+ib$. From the definition of the $\Gamma$-function, we have $\Gamma(z)=(z-1)\Gamma(z-1)$. $\Gamma(a+ib)=(a-1+ib)\Gamma(a-1+ib)$ $=(a-1+ib)(a-2+ib)\Gamma(a-2+ib)$ $=(a-1+ib)(a-2+ib)\cdots(a-k+ib)\Gamma(a-k+ib)$ $=\Gamma(ib)\prod_{k=0}^{a-1}{(k+ib)}$ Now, turning to the imaginary-$\Gamma$, a brick wall I ran into... $$\Gamma(ib)= \int_0^{\infty}\frac{t^{-1+ib}}{e^t}\mathrm{d}t$$ ... and cannot evaluate. Questions How do we evaluate $\Gamma(a+ib)$? How should we go about solving for $z$ once 1. is done? Computational 'evidence' Wolfram|Alpha thinks these $z$ exist, infact they seem plentiful. I'm not sure if approximation is muddling the results, but I doubt it. I'm using solve Gamma(a+ib) + 1= n(a+ib) and plugging in values of $a,b,n$.",,"['complex-analysis', 'complex-numbers', 'gamma-function']"
99,Maximum distance between images of two points under an analytic function,Maximum distance between images of two points under an analytic function,,"Let $z$ and $w$ be two points in the complex unit disk, and let $f$ be a holomorphic function from the unit disk to itself (i.e. $|f| < 1$). Intuitively, it seems that the maximum value of $|f(z) - f(w)|$ over all such $f$ should occur when $f$ is fractional linear. I have tried to prove this using an argument similar to that for the Schwarz lemma, without much success. First, is this fact true? And, second, how would I prove it?","Let $z$ and $w$ be two points in the complex unit disk, and let $f$ be a holomorphic function from the unit disk to itself (i.e. $|f| < 1$). Intuitively, it seems that the maximum value of $|f(z) - f(w)|$ over all such $f$ should occur when $f$ is fractional linear. I have tried to prove this using an argument similar to that for the Schwarz lemma, without much success. First, is this fact true? And, second, how would I prove it?",,['complex-analysis']
