,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Differences between the geometry and topology books of A. T. Fomenko,Differences between the geometry and topology books of A. T. Fomenko,,"Anatoly T. Fomenko has authored and coauthored a number of books on differential geometry and topology. He may be more known for other things , but I have been told his books are quite good for learning geometry and topology. As an undergraduate student planning on learning differential geometry, this piqued my interest. They all seem to be translations of works originally written in Russian. Can anyone compare and contrast them? Here I list them with his coauthors. Dubrovin, B. A., Novikov, S. P. (1984, 1985, 1990). Modern Geometry — Methods and Applications: Parts 1, 2, 3. Graduate Texts in Mathematics. Springer. Differential Geometry and Topology . (1987). Consultants Bureau. Mishchenko, A. S. (1988). A Course of Differential Geometry and Topology . Mir Publishers. Novikov, S. P. (1990). Basic Elements of Differential Geometry and Topology. Mathematics and Its Application . Kluwer Academic Publishers. Visual Geometry and Topology. (1994). Springer. Mishchenko, A. S. (2009). A Short Course in Differential Geometry and Topology . Cambridge Scientific Publishers. Bonus: His wife also seems to have coauthored a book on topology: Borisovich, Yuri G., Bliznyakov, Nikolai M., Fomenko, Tatyana N., Izrailevich, Yakov. A. (1995). Introduction to Differential and Algebraic Topology. Kluwer Texts in the Mathematical Sciences. Kluwer Academic Publishers. From what I can make of them, book (6) seems to be a trimmed version of (3), and (1) seems to be more geared towards physics despite being a GTM book, but I'm not sure.","Anatoly T. Fomenko has authored and coauthored a number of books on differential geometry and topology. He may be more known for other things , but I have been told his books are quite good for learning geometry and topology. As an undergraduate student planning on learning differential geometry, this piqued my interest. They all seem to be translations of works originally written in Russian. Can anyone compare and contrast them? Here I list them with his coauthors. Dubrovin, B. A., Novikov, S. P. (1984, 1985, 1990). Modern Geometry — Methods and Applications: Parts 1, 2, 3. Graduate Texts in Mathematics. Springer. Differential Geometry and Topology . (1987). Consultants Bureau. Mishchenko, A. S. (1988). A Course of Differential Geometry and Topology . Mir Publishers. Novikov, S. P. (1990). Basic Elements of Differential Geometry and Topology. Mathematics and Its Application . Kluwer Academic Publishers. Visual Geometry and Topology. (1994). Springer. Mishchenko, A. S. (2009). A Short Course in Differential Geometry and Topology . Cambridge Scientific Publishers. Bonus: His wife also seems to have coauthored a book on topology: Borisovich, Yuri G., Bliznyakov, Nikolai M., Fomenko, Tatyana N., Izrailevich, Yakov. A. (1995). Introduction to Differential and Algebraic Topology. Kluwer Texts in the Mathematical Sciences. Kluwer Academic Publishers. From what I can make of them, book (6) seems to be a trimmed version of (3), and (1) seems to be more geared towards physics despite being a GTM book, but I'm not sure.",,"['differential-geometry', 'differential-topology', 'book-recommendation']"
1,Classify all $3$-manifolds such that this map is injective,Classify all -manifolds such that this map is injective,3,"Is it possible to classify all the compact, connected and orientable $3$ -manifolds $M$ with nonempty boundary such that the map $H_2(M, \partial M) \to H_1(\partial M)$ , appearing in the long exact sequence of the pair $(M, \partial M)$ , is injective? Obviously, a sufficient condition is that $H_2(M) = 0$ , but can we describe the manifolds in the general case?","Is it possible to classify all the compact, connected and orientable -manifolds with nonempty boundary such that the map , appearing in the long exact sequence of the pair , is injective? Obviously, a sufficient condition is that , but can we describe the manifolds in the general case?","3 M H_2(M, \partial M) \to H_1(\partial M) (M, \partial M) H_2(M) = 0","['differential-geometry', 'algebraic-topology', 'smooth-manifolds']"
2,Coordinate free derivation of Euler-Lagrange equations,Coordinate free derivation of Euler-Lagrange equations,,"I am studying Symplectic Geometry and I was wondering how one can compute Euler-Lagrange equation in a coordinate free manner.  For instance, I know for the following Lagrangian $L(x,v)=\frac{1}{2}g_{x}(v,v)-V(x)$ the corresponding equation is $\nabla_{\dot\gamma}\dot\gamma=-\nabla V$ , but it is a bit complicated to derive it in a coordinate system.","I am studying Symplectic Geometry and I was wondering how one can compute Euler-Lagrange equation in a coordinate free manner.  For instance, I know for the following Lagrangian the corresponding equation is , but it is a bit complicated to derive it in a coordinate system.","L(x,v)=\frac{1}{2}g_{x}(v,v)-V(x) \nabla_{\dot\gamma}\dot\gamma=-\nabla V","['differential-geometry', 'symplectic-geometry', 'euler-lagrange-equation']"
3,smooth structure on a smooth manifold [closed],smooth structure on a smooth manifold [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question Why there is a unique smooth structure (choice of a smooth atlas) up to diffeomorphism on the real line? Can someone please send a proof, thanks.","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question Why there is a unique smooth structure (choice of a smooth atlas) up to diffeomorphism on the real line? Can someone please send a proof, thanks.",,"['differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds']"
4,Maximal integral curve is injective or periodic,Maximal integral curve is injective or periodic,,"Suppose $\gamma$ is a maximal integral curve of $X\in\mathfrak{X}(M)$ , where $M$ is smooth manifold. I am trying to prove that $\gamma$ is injective or periodic. Here is my attempt: Suppose $\gamma$ is not injective. Then there are distinct $t,t'\in\mathbb{R}$ such that $\gamma(t)=\gamma(t')$ and $t<t'$ .  Let $T=t'-t$ . Then $\gamma$ and $\delta$ , defined by $\delta(s)=\gamma(s+T)$ , are both integral curves starting at $\gamma(t)=\gamma(t')$ . By the uniqueness of maximal integral curves, we must have that $\gamma$ is defined on $(t-\varepsilon,t'+T+\varepsilon)$ for some $\varepsilon>0$ and that $\gamma(s)=\gamma(s+T)$ whenever $s$ and $s+T$ are in the domain of $\gamma$ . Hence $\gamma$ is periodic with period $T$ . Is this correct?","Suppose is a maximal integral curve of , where is smooth manifold. I am trying to prove that is injective or periodic. Here is my attempt: Suppose is not injective. Then there are distinct such that and .  Let . Then and , defined by , are both integral curves starting at . By the uniqueness of maximal integral curves, we must have that is defined on for some and that whenever and are in the domain of . Hence is periodic with period . Is this correct?","\gamma X\in\mathfrak{X}(M) M \gamma \gamma t,t'\in\mathbb{R} \gamma(t)=\gamma(t') t<t' T=t'-t \gamma \delta \delta(s)=\gamma(s+T) \gamma(t)=\gamma(t') \gamma (t-\varepsilon,t'+T+\varepsilon) \varepsilon>0 \gamma(s)=\gamma(s+T) s s+T \gamma \gamma T","['differential-geometry', 'smooth-manifolds']"
5,Meaning of higher-order derivations in differential geometry?,Meaning of higher-order derivations in differential geometry?,,"In differential geometry, a derivation is defined to be an operator $D:C^{\infty}(M)\rightarrow C^{\infty}(M)$ that is linear and satisfies the first-order product rule: $$ D(fg) = D(f)g + fD(g). $$ When I say ""second-order derivations,"" I mean operators of the form $DD'$ where $D, D'$ are derivations. In this case, $DD'$ is linear and satisfies $$ DD'(fg) = DD'(f)g + D(f)D'(g) + D'(f)D(g) + DD'(g). $$ Questions. Are there any references that discuss these types of operators? Does anyone have an intuitive/geometric interpretation of these operators? First-order derivations can be interpreted as vector fields (or tangent vectors if we're talking about pointwise derivations). Is there an extension of this type of reasoning? Edit. It looks like my definition has in general $DD'\ne D'D$ . For example, in local coordinates let $D = \partial_{1}$ and $D' = x^{1}\partial_{2}$ . Then $$ DD' = \partial_{1}(x^{1}\partial_{2}) = \partial_{2} + x^{1}\partial_{1}\partial_{2} \ne D'D. $$ I'm not sure what definition is appropriate, actually. The above is only my attempt. Actually, the non-commutativity I just noted above is nothing new. We already know Lie brackets $[X, Y]$ can be nonzero. However, the more I play around, the more surprising nuances I seem to discover.","In differential geometry, a derivation is defined to be an operator that is linear and satisfies the first-order product rule: When I say ""second-order derivations,"" I mean operators of the form where are derivations. In this case, is linear and satisfies Questions. Are there any references that discuss these types of operators? Does anyone have an intuitive/geometric interpretation of these operators? First-order derivations can be interpreted as vector fields (or tangent vectors if we're talking about pointwise derivations). Is there an extension of this type of reasoning? Edit. It looks like my definition has in general . For example, in local coordinates let and . Then I'm not sure what definition is appropriate, actually. The above is only my attempt. Actually, the non-commutativity I just noted above is nothing new. We already know Lie brackets can be nonzero. However, the more I play around, the more surprising nuances I seem to discover.","D:C^{\infty}(M)\rightarrow C^{\infty}(M)  D(fg) = D(f)g + fD(g).  DD' D, D' DD'  DD'(fg) = DD'(f)g + D(f)D'(g) + D'(f)D(g) + DD'(g).  DD'\ne D'D D = \partial_{1} D' = x^{1}\partial_{2}  DD' = \partial_{1}(x^{1}\partial_{2}) = \partial_{2} + x^{1}\partial_{1}\partial_{2} \ne D'D.  [X, Y]","['differential-geometry', 'reference-request', 'intuition']"
6,Is there a coordinate-free proof of this Lie derivative identity?,Is there a coordinate-free proof of this Lie derivative identity?,,"Wikipedia mentions ( here and here ) that the Lie derivative has the following appealing commutator: $$[\mathcal{L}_X,\iota_Y]=\iota_{[X,Y]}$$ The only way I know to demonstrate this identity relies on coordinate-based manipulations, which are summarized (with a mistake) in this problem .  I would like a coordinate-free (purely algebraic, one might say) proof of the same result. Here's one possible route to a proof, but I can't seem to stick the landing.  Let $\phi_t$ be the diffeomorphisms infinitesimally generated by $X$ and recall that $\mathcal{L}_X\omega=\left.\partial_t(\phi_t^*\omega)\right|_{t=0}$ .  Similarly, $[X,Y]=\mathcal{L}_XY=\left.\partial_t(\phi_{-t}^*Y)\right|_{t=0}$ . Now $\iota_{(\cdot_1)}(\cdot_2)$ is bilinear and smooth, so it commutes with the (Gateaux) time derivative when the equation is interpreted sufficiently weakly.  So it suffices to show that $$\left.\partial_t\left([\phi_t^*,\iota_Y]-\iota_{\phi_{-t}^*Y}\right)\right|_{t=0}=0$$ But, applying LHS to a test form, I don't see how to deduce the result. This answer suggests that it should be obvious from the Leibniz rule, but I don't see why the contraction operator $C$ in that answer should commute with $\mathcal{L}_X$ (as it does, moving from the first to second line). How can I prove the commutator claim in a coordinate-independent manner?","Wikipedia mentions ( here and here ) that the Lie derivative has the following appealing commutator: The only way I know to demonstrate this identity relies on coordinate-based manipulations, which are summarized (with a mistake) in this problem .  I would like a coordinate-free (purely algebraic, one might say) proof of the same result. Here's one possible route to a proof, but I can't seem to stick the landing.  Let be the diffeomorphisms infinitesimally generated by and recall that .  Similarly, . Now is bilinear and smooth, so it commutes with the (Gateaux) time derivative when the equation is interpreted sufficiently weakly.  So it suffices to show that But, applying LHS to a test form, I don't see how to deduce the result. This answer suggests that it should be obvious from the Leibniz rule, but I don't see why the contraction operator in that answer should commute with (as it does, moving from the first to second line). How can I prove the commutator claim in a coordinate-independent manner?","[\mathcal{L}_X,\iota_Y]=\iota_{[X,Y]} \phi_t X \mathcal{L}_X\omega=\left.\partial_t(\phi_t^*\omega)\right|_{t=0} [X,Y]=\mathcal{L}_XY=\left.\partial_t(\phi_{-t}^*Y)\right|_{t=0} \iota_{(\cdot_1)}(\cdot_2) \left.\partial_t\left([\phi_t^*,\iota_Y]-\iota_{\phi_{-t}^*Y}\right)\right|_{t=0}=0 C \mathcal{L}_X","['differential-geometry', 'tensors', 'lie-derivative']"
7,Embedding of $U(n)$ in $SO(2n)$,Embedding of  in,U(n) SO(2n),"I want to study the embedding of $U(n)$ in $SO(2n)$ . I write $Z=X+iY\in U(n)$ and use the realification map \begin{align*} \varphi:C^n\rightarrow R^{2n}:X+iY\mapsto\begin{bmatrix} X &-Y\\ Y & X \end{bmatrix}. \end{align*} I note that \begin{align*} \begin{bmatrix} X & -Y\\ Y & X \end{bmatrix}^T\begin{bmatrix} X & -Y\\ Y & X \end{bmatrix}=\begin{bmatrix} X^TX+Y^TY & -X^TY+Y^TX\\ -Y^TX+X^TY & Y^TY+X^TX \end{bmatrix}=\begin{bmatrix} I & 0\\ 0 & I \end{bmatrix} \end{align*} since $Z^*Z=(X^T-iY^T)(X+iY)=X^TX+iX^TY-iY^TX+Y^TY=I$ . My question is: how to determine the orthogonal projection operator $\pi$ of any $A\in R^{2n\times 2n}$ on the tangent space of $\varphi U(n)$ at $\varphi Z$ ? Attempt: I note that any element of the tangent space of $\varphi U(n)$ at $\varphi Z$ must be on the form \begin{bmatrix} A & -B\\ B & A \end{bmatrix} and must satisfy $A^TX+X^TA+B^TY+Y^TB=0$ and $-A^TY+X^TB+B^TX+Y^TA=0$ . The last relations are from the time derivatives of the matrix equations above. I am stuck here. How to orthogonally project an arbitrary matrix on \begin{align} \left\{\begin{bmatrix} A & -B\\ B & A \end{bmatrix}\in R^{2n\times 2n}\,|\, A^TX+X^TA+B^TY+Y^TB=0,-A^TY+X^TB+B^TX+Y^TA=0\right\}? \end{align}",I want to study the embedding of in . I write and use the realification map I note that since . My question is: how to determine the orthogonal projection operator of any on the tangent space of at ? Attempt: I note that any element of the tangent space of at must be on the form and must satisfy and . The last relations are from the time derivatives of the matrix equations above. I am stuck here. How to orthogonally project an arbitrary matrix on,"U(n) SO(2n) Z=X+iY\in U(n) \begin{align*}
\varphi:C^n\rightarrow R^{2n}:X+iY\mapsto\begin{bmatrix}
X &-Y\\
Y & X
\end{bmatrix}.
\end{align*} \begin{align*}
\begin{bmatrix}
X & -Y\\
Y & X
\end{bmatrix}^T\begin{bmatrix}
X & -Y\\
Y & X
\end{bmatrix}=\begin{bmatrix}
X^TX+Y^TY & -X^TY+Y^TX\\
-Y^TX+X^TY & Y^TY+X^TX
\end{bmatrix}=\begin{bmatrix}
I & 0\\
0 & I
\end{bmatrix}
\end{align*} Z^*Z=(X^T-iY^T)(X+iY)=X^TX+iX^TY-iY^TX+Y^TY=I \pi A\in R^{2n\times 2n} \varphi U(n) \varphi Z \varphi U(n) \varphi Z \begin{bmatrix}
A & -B\\
B & A
\end{bmatrix} A^TX+X^TA+B^TY+Y^TB=0 -A^TY+X^TB+B^TX+Y^TA=0 \begin{align}
\left\{\begin{bmatrix}
A & -B\\
B & A
\end{bmatrix}\in R^{2n\times 2n}\,|\, A^TX+X^TA+B^TY+Y^TB=0,-A^TY+X^TB+B^TX+Y^TA=0\right\}?
\end{align}","['differential-geometry', 'lie-groups']"
8,Immersion of $(RP)^2$ in $R^3$,Immersion of  in,(RP)^2 R^3,"I am working on the following problem.. Let g: $S^2$ --> $R^3$ be a map given by the formula g(x,y,z)=(yz,xz,xy), which induces in a natural way a mapping $G$ from $RP^2$ into $R^3$ . I need to find six points of the real projective plane $p_i$ i=1,...,6 such that G is an immersion for all the other points in $RP^2$ . However my calculations show that we do not need to deduct those points for $G$ to be an immersion. I am propably missing something here, so any help would be much appreciated!","I am working on the following problem.. Let g: --> be a map given by the formula g(x,y,z)=(yz,xz,xy), which induces in a natural way a mapping from into . I need to find six points of the real projective plane i=1,...,6 such that G is an immersion for all the other points in . However my calculations show that we do not need to deduct those points for to be an immersion. I am propably missing something here, so any help would be much appreciated!",S^2 R^3 G RP^2 R^3 p_i RP^2 G,"['differential-geometry', 'smooth-manifolds']"
9,Geodesic distance on Orthogonal group,Geodesic distance on Orthogonal group,,"Let ${U,V}$ be two points on the orthogonal group $O(n)=\{X\in\mathbb{R}^{n\times n}: X^TX=I\}$ equipped with the usual Riemannian metric. Let $d(U,V)$ be the geodesic distance between $U,V$ on $O(n)$ . Do we have any analytic expression of $d(U,V)$ ? Let $\|\|_F$ be the Frobenius norm on $\mathbb{R}^{n\times n}$ . Then we of course have $\|U-V\|_F\leq d(U,V)$ . There must also exist a constant $C>0$ , such that $d(U,V)\leq C\|U-V\|_F$ . What is the best constant $C$ we can have?","Let be two points on the orthogonal group equipped with the usual Riemannian metric. Let be the geodesic distance between on . Do we have any analytic expression of ? Let be the Frobenius norm on . Then we of course have . There must also exist a constant , such that . What is the best constant we can have?","{U,V} O(n)=\{X\in\mathbb{R}^{n\times n}: X^TX=I\} d(U,V) U,V O(n) d(U,V) \|\|_F \mathbb{R}^{n\times n} \|U-V\|_F\leq d(U,V) C>0 d(U,V)\leq C\|U-V\|_F C","['differential-geometry', 'riemannian-geometry']"
10,Partition of unity on a manifold with a non-vanishing global vector field,Partition of unity on a manifold with a non-vanishing global vector field,,"Suppose $M$ is manifold with a global non-vanishing vector field $X$ . Let $\{U\}_{\alpha\in I}$ be a locally finite covering of $M$ such that for each $\alpha$ and $p\in U_{\alpha}$ the maximal integral curve of $X$ containing $p$ is contained in $U_{\alpha.}$ Is it possible to find a partition of unity $\{\phi_{\alpha}\}_{\alpha\in I}$ subordinate to the covering such that $X(\phi_{\alpha})=0,$ for all $\alpha\in I$ ?",Suppose is manifold with a global non-vanishing vector field . Let be a locally finite covering of such that for each and the maximal integral curve of containing is contained in Is it possible to find a partition of unity subordinate to the covering such that for all ?,"M X \{U\}_{\alpha\in I} M \alpha p\in U_{\alpha} X p U_{\alpha.} \{\phi_{\alpha}\}_{\alpha\in I} X(\phi_{\alpha})=0, \alpha\in I","['differential-geometry', 'manifolds']"
11,Hessian squared and Laplacian on a Riemannian manifold,Hessian squared and Laplacian on a Riemannian manifold,,"I have been trying to understand more about the norm squared of the Hessian on a Riemannian manifold, that is $$ |\nabla^2f|^2 $$ This quantity shows up in the Bochner formula, for instance. On $\mathbb{R}^n$ , the induced fiber metric on the 2-tensor bundle is just a dot product of matrices (viewed as $\mathbb{R}^{n\times n}$ in this case), so viewing the contribution from the diagonal terms, we get $$ \sum_{i=1}^n\frac{\partial^2 f}{\partial x_i^2} $$ These can be used to estimate the square of the Laplacian via the Cauchy-Schwartz inequality. I'm wondering how to show that we have an analogous property in the more general case, that is, showing that the norm of the Hessian squared is equal to a sum of terms that resemble the Laplacian in coordinates squared plus some other non-negative terms. So far, I have tried the following: take a symmetric two-tensor $T$ on a manifold $(M^n,g)$ ; it induces a self-adjoint operator $A$ satisfying $T(v,w)=\langle A(v),w\rangle$ . Fix a point $p\in M$ and choose a local frame about $p$ , call it $E_j$ , which diagonalizes $A$ . Using the canonical association between endomorphisms and $(1,1)$ tensors, we can write $$ A=\lambda_i \epsilon^i\otimes E_i $$ where there is a sum in $i$ and $\epsilon^i$ is the coframe dual to $E_i$ . Then $$ \langle A,A\rangle =\sum_{i,j}\lambda_i\lambda_j\langle\epsilon^i,\epsilon^j\rangle\langle E_i,E_j\rangle $$ Here, I want to claim that the last quantity is a sum of squares of eigenvalues plus a non-negative error term, but I think I am missing some relevant identity from linear algebra. The sum of squares of eigenvalues would then specialize in our Hessian case to be related to the Laplacian terms (I think). I'm interested in advice either for how to make this approach work, or for a different approach to thinking about this that is simpler.","I have been trying to understand more about the norm squared of the Hessian on a Riemannian manifold, that is This quantity shows up in the Bochner formula, for instance. On , the induced fiber metric on the 2-tensor bundle is just a dot product of matrices (viewed as in this case), so viewing the contribution from the diagonal terms, we get These can be used to estimate the square of the Laplacian via the Cauchy-Schwartz inequality. I'm wondering how to show that we have an analogous property in the more general case, that is, showing that the norm of the Hessian squared is equal to a sum of terms that resemble the Laplacian in coordinates squared plus some other non-negative terms. So far, I have tried the following: take a symmetric two-tensor on a manifold ; it induces a self-adjoint operator satisfying . Fix a point and choose a local frame about , call it , which diagonalizes . Using the canonical association between endomorphisms and tensors, we can write where there is a sum in and is the coframe dual to . Then Here, I want to claim that the last quantity is a sum of squares of eigenvalues plus a non-negative error term, but I think I am missing some relevant identity from linear algebra. The sum of squares of eigenvalues would then specialize in our Hessian case to be related to the Laplacian terms (I think). I'm interested in advice either for how to make this approach work, or for a different approach to thinking about this that is simpler.","
|\nabla^2f|^2
 \mathbb{R}^n \mathbb{R}^{n\times n} 
\sum_{i=1}^n\frac{\partial^2 f}{\partial x_i^2}
 T (M^n,g) A T(v,w)=\langle A(v),w\rangle p\in M p E_j A (1,1) 
A=\lambda_i \epsilon^i\otimes E_i
 i \epsilon^i E_i 
\langle A,A\rangle =\sum_{i,j}\lambda_i\lambda_j\langle\epsilon^i,\epsilon^j\rangle\langle E_i,E_j\rangle
","['differential-geometry', 'riemannian-geometry', 'tensors', 'multilinear-algebra', 'hessian-matrix']"
12,On the convergence of metric spaces,On the convergence of metric spaces,,"Suppose $(X_n,d_n) \rightarrow (X_{\infty}, d_{\infty})$ in the Gromov-Hausdorff sense. Is there a compact (or locally compact) space $Z$ such that (almost all) the $X_i$ embed isometrically into $Z$ and and $d_H(X_n, X_\infty) \rightarrow 0$ where $d_H$ is the Hausdorff distance in $Z$ . If not, is this true when $X_n$ is a smooth manifold, and $d_n$ is a distance inducing the topology (if not, then $d_n$ a Riemannian distance)?","Suppose in the Gromov-Hausdorff sense. Is there a compact (or locally compact) space such that (almost all) the embed isometrically into and and where is the Hausdorff distance in . If not, is this true when is a smooth manifold, and is a distance inducing the topology (if not, then a Riemannian distance)?","(X_n,d_n) \rightarrow (X_{\infty}, d_{\infty}) Z X_i Z d_H(X_n, X_\infty) \rightarrow 0 d_H Z X_n d_n d_n","['real-analysis', 'differential-geometry', 'metric-spaces', 'riemannian-geometry']"
13,Degree of a map from sphere to general linear group is mutliple of (n-1)!,Degree of a map from sphere to general linear group is mutliple of (n-1)!,,"I am trying to understand Atiyah's paper "" Algebraic Topology and Elliptic Operators "" (link is pay-walled). In the paper he defines the degree of a map from $S^{2n-1}\rightarrow GL(n,\mathbb{C})$ by mapping to the first column and then normalizing to obtain a map $S^{2n-1}\rightarrow S^{2n-1}$ which has the usual notion of degree. He claims that the degree of such a map will be a multiple of $(n-1)!$ . Can anyone explain why this should be true? I am also interested in a reference with this notion of degree.","I am trying to understand Atiyah's paper "" Algebraic Topology and Elliptic Operators "" (link is pay-walled). In the paper he defines the degree of a map from by mapping to the first column and then normalizing to obtain a map which has the usual notion of degree. He claims that the degree of such a map will be a multiple of . Can anyone explain why this should be true? I am also interested in a reference with this notion of degree.","S^{2n-1}\rightarrow GL(n,\mathbb{C}) S^{2n-1}\rightarrow S^{2n-1} (n-1)!","['differential-geometry', 'algebraic-topology', 'differential-topology', 'general-linear-group']"
14,"Verify Nijenhuis tensor is a (1,2) tensor","Verify Nijenhuis tensor is a (1,2) tensor",,"I've been working the following problem: If $T_i^j$ is a type (1,1) tensor field show that $$ H_{ij}^k = T_i^r  \dfrac{\partial T_j^k}{\partial x^r} - T_j^r \dfrac{\partial  T_i^k}{\partial x^r} +  T_r^k \left( \dfrac{\partial T_i^r}{ \partial   x^j} - \dfrac{\partial T_j^r}{\partial x^i} \right) $$ is a type (1,2)    tensor. $-$ From Tensors, Differential Forms, and Variational Principles by Lovelock and Rund (p.99). and after introducing the transformation $x^i = x^i(\bar{x}^\alpha)$ and expanding, I'm able to show $$ \begin{align*} H_{ij}^k &= \dfrac{\partial \bar{x}^\alpha}{\partial x^i} \dfrac{\partial \bar{x}^\beta}{\partial x^j} \dfrac{\partial x^k}{\partial \bar{x}^\gamma} \overline{H}_{\alpha \beta}^\gamma \\ &+ \dfrac{\partial \bar{x}^\mu}{\partial x^i} \dfrac{\partial \bar{x}^\nu}{\partial x^j} \dfrac{\partial x^k}{\partial \bar{x}^\lambda} \dfrac{\partial \bar{x}^\rho}{\partial x^r} \dfrac{\partial^2 x^r}{\partial \bar{x}^\sigma \partial \bar{x}^\nu} \overline{T}_\rho^\lambda \overline{T}_\mu^\sigma - \dfrac{\partial \bar{x}^\mu}{\partial x^j} \dfrac{\partial \bar{x}^\nu}{\partial x^i} \dfrac{\partial x^k}{\partial \bar{x}^\lambda} \dfrac{\partial \bar{x}^\rho}{\partial x^r} \dfrac{\partial^2 x^r}{\partial \bar{x}^\sigma \partial \bar{x}^\nu} \overline{T}_\rho^\lambda \overline{T}_\mu^\sigma \end{align*} $$ by noting that $$\begin{align*} T_a^b &= \dfrac{\partial \bar{x}^\mu}{\partial x^a} \dfrac{\partial x^b}{\partial \bar{x}^\nu}\overline{T}_\mu^\nu \\ \dfrac{\partial T_a^b}{\partial x^c} &=  \dfrac{\partial \bar{x}^\lambda}{\partial x^c} \dfrac{\partial \bar{x}^\mu}{\partial x^a} \dfrac{\partial x^b}{\partial \bar{x}^\nu} \dfrac{\partial \overline{T}_\mu^\nu}{\partial \bar{x}^\lambda} + \dfrac{\partial \bar{x}^\lambda}{\partial x^c} \dfrac{\partial \bar{x}^\mu}{\partial x^a} \dfrac{\partial^2 x^b}{\partial \bar{x}^\nu \partial \bar{x}^\lambda} \overline{T}_\mu^\nu, \end{align*}$$ but I haven't been able to get the last two terms to cancel. Any help would be appreciated. As Ted mentioned in the comments, my derivative of $T$ was missing a term: $$\dfrac{\partial T_a^b}{\partial x^c} = \dfrac{\partial \bar{x}^\lambda}{\partial x^c} \dfrac{\partial \bar{x}^\mu}{\partial x^a} \dfrac{\partial x^b}{\partial \bar{x}^\nu} \dfrac{\partial \overline{T}_\mu^\nu}{\partial \bar{x}^\lambda} + \dfrac{\partial \bar{x}^\lambda}{\partial x^c} \dfrac{\partial \bar{x}^\mu}{\partial x^a} \dfrac{\partial^2 x^b}{\partial \bar{x}^\nu \partial \bar{x}^\lambda} \overline{T}_\mu^\nu  +  \dfrac{\partial x^b}{\partial \bar{x}^\nu} \dfrac{\partial \bar{x}^\mu}{\partial x^a \partial x^c} \overline{T}_\mu^\nu. $$ After correcting this term and using identity (3.19) from Lovelock and Rund, I am able to show that $$ H_{ij}^k = \dfrac{\partial \bar{x}^\alpha}{\partial x^i} \dfrac{\partial \bar{x}^\beta}{\partial x^j} \dfrac{\partial x^k}{\partial \bar{x}^\gamma} \overline{H}_{\alpha \beta}^\gamma $$ as desired.","I've been working the following problem: If is a type (1,1) tensor field show that is a type (1,2)    tensor. From Tensors, Differential Forms, and Variational Principles by Lovelock and Rund (p.99). and after introducing the transformation and expanding, I'm able to show by noting that but I haven't been able to get the last two terms to cancel. Any help would be appreciated. As Ted mentioned in the comments, my derivative of was missing a term: After correcting this term and using identity (3.19) from Lovelock and Rund, I am able to show that as desired.","T_i^j  H_{ij}^k = T_i^r
 \dfrac{\partial T_j^k}{\partial x^r} - T_j^r \dfrac{\partial
 T_i^k}{\partial x^r} +  T_r^k \left( \dfrac{\partial T_i^r}{ \partial
  x^j} - \dfrac{\partial T_j^r}{\partial x^i} \right)  - x^i = x^i(\bar{x}^\alpha)  \begin{align*} H_{ij}^k &= \dfrac{\partial \bar{x}^\alpha}{\partial x^i} \dfrac{\partial \bar{x}^\beta}{\partial x^j} \dfrac{\partial x^k}{\partial \bar{x}^\gamma} \overline{H}_{\alpha \beta}^\gamma \\ &+ \dfrac{\partial \bar{x}^\mu}{\partial x^i} \dfrac{\partial \bar{x}^\nu}{\partial x^j} \dfrac{\partial x^k}{\partial \bar{x}^\lambda} \dfrac{\partial \bar{x}^\rho}{\partial x^r} \dfrac{\partial^2 x^r}{\partial \bar{x}^\sigma \partial \bar{x}^\nu} \overline{T}_\rho^\lambda \overline{T}_\mu^\sigma - \dfrac{\partial \bar{x}^\mu}{\partial x^j} \dfrac{\partial \bar{x}^\nu}{\partial x^i} \dfrac{\partial x^k}{\partial \bar{x}^\lambda} \dfrac{\partial \bar{x}^\rho}{\partial x^r} \dfrac{\partial^2 x^r}{\partial \bar{x}^\sigma \partial \bar{x}^\nu} \overline{T}_\rho^\lambda \overline{T}_\mu^\sigma \end{align*}  \begin{align*} T_a^b &= \dfrac{\partial \bar{x}^\mu}{\partial x^a} \dfrac{\partial x^b}{\partial \bar{x}^\nu}\overline{T}_\mu^\nu \\ \dfrac{\partial T_a^b}{\partial x^c} &= 
\dfrac{\partial \bar{x}^\lambda}{\partial x^c} \dfrac{\partial \bar{x}^\mu}{\partial x^a} \dfrac{\partial x^b}{\partial \bar{x}^\nu} \dfrac{\partial \overline{T}_\mu^\nu}{\partial \bar{x}^\lambda} + \dfrac{\partial \bar{x}^\lambda}{\partial x^c} \dfrac{\partial \bar{x}^\mu}{\partial x^a} \dfrac{\partial^2 x^b}{\partial \bar{x}^\nu \partial \bar{x}^\lambda} \overline{T}_\mu^\nu, \end{align*} T \dfrac{\partial T_a^b}{\partial x^c} = \dfrac{\partial \bar{x}^\lambda}{\partial x^c} \dfrac{\partial \bar{x}^\mu}{\partial x^a} \dfrac{\partial x^b}{\partial \bar{x}^\nu} \dfrac{\partial \overline{T}_\mu^\nu}{\partial \bar{x}^\lambda} + \dfrac{\partial \bar{x}^\lambda}{\partial x^c} \dfrac{\partial \bar{x}^\mu}{\partial x^a} \dfrac{\partial^2 x^b}{\partial \bar{x}^\nu \partial \bar{x}^\lambda} \overline{T}_\mu^\nu  + 
\dfrac{\partial x^b}{\partial \bar{x}^\nu} \dfrac{\partial \bar{x}^\mu}{\partial x^a \partial x^c} \overline{T}_\mu^\nu.   H_{ij}^k = \dfrac{\partial \bar{x}^\alpha}{\partial x^i} \dfrac{\partial \bar{x}^\beta}{\partial x^j} \dfrac{\partial x^k}{\partial \bar{x}^\gamma} \overline{H}_{\alpha \beta}^\gamma ","['differential-geometry', 'tensors']"
15,Is any smooth fibre bundle a smooth Hurewicz fibration?,Is any smooth fibre bundle a smooth Hurewicz fibration?,,"From https://pdfs.semanticscholar.org/e737/a4f8b93242910c050c2faf761236dcf60f64.pdf ( Theorem 2.1 ) it follows: (*) If $\pi:P\rightarrow M$ is a topological  fibre bundle over a paracompat hausdorff topological space $M$ then it is a Hurewicz fibration and hence a Serre fibration. (In the category of topological spaces) I found the analogous notion of homotopy lifting property and Serre/Hurewiz fibration in the category of smooth manifolds here When is a fibration a fiber bundle? . My question is the following : Does (*) holds in the category of smooth manifolds also? I got an affirmative answer at least for Serre fibration in https://mathoverflow.net/questions/116231/given-a-serre-fibration-between-manifolds-how-ugly-can-it-be (where in the question it is mentioned ""Clearly smooth fibre bundles are Serre fibrations"" by @David Roberts.) But (no proof or any reference where such proof is discussed) is mentioned in the question. So can anyone please give a proof of (*) or suggest any reference where such proof is discussed (at least for Serre fibration)? Also it would be very helpful if someone can suggest some references or literature resources where the notion of Serre/Hurewicz  fibration in the category of smooth manifolds is discussed. Thanks in Advance.","From https://pdfs.semanticscholar.org/e737/a4f8b93242910c050c2faf761236dcf60f64.pdf ( Theorem 2.1 ) it follows: (*) If is a topological  fibre bundle over a paracompat hausdorff topological space then it is a Hurewicz fibration and hence a Serre fibration. (In the category of topological spaces) I found the analogous notion of homotopy lifting property and Serre/Hurewiz fibration in the category of smooth manifolds here When is a fibration a fiber bundle? . My question is the following : Does (*) holds in the category of smooth manifolds also? I got an affirmative answer at least for Serre fibration in https://mathoverflow.net/questions/116231/given-a-serre-fibration-between-manifolds-how-ugly-can-it-be (where in the question it is mentioned ""Clearly smooth fibre bundles are Serre fibrations"" by @David Roberts.) But (no proof or any reference where such proof is discussed) is mentioned in the question. So can anyone please give a proof of (*) or suggest any reference where such proof is discussed (at least for Serre fibration)? Also it would be very helpful if someone can suggest some references or literature resources where the notion of Serre/Hurewicz  fibration in the category of smooth manifolds is discussed. Thanks in Advance.",\pi:P\rightarrow M M,"['differential-geometry', 'algebraic-topology', 'smooth-manifolds', 'fiber-bundles', 'fibration']"
16,Relation between Lie Bracket and exponetial map,Relation between Lie Bracket and exponetial map,,"Let $X,Y$ be in the lie algebra of a lie group, I want to show that the following identity is true. $$[X,Y]= \frac{d}{ds}\Big|_{s=0}\frac{d}{dt}\Big|_{t=0}\exp(sX)\exp(tY)\exp(-sX)\exp(-tY).$$ I'm getting stuck and I feel some of the steps I used may not be allowed. Here is my attempt $$\frac{d}{ds}\Big|_{s=0}\frac{d}{dt}\Big|_{t=0}\exp(sX)\exp(tY)\exp(-sX)\exp(-tY)$$ using $a \exp(V) a^{-1}=exp(\text{Ad}(a)V)$ $$=\frac{d}{ds}\Big|_{s=0}\frac{d}{dt}\Big|_{t=0}\exp(sX)\exp(-s \text{Ad}(\exp(tY))X)$$ $$=\frac{d}{ds}\Big|_{s=0}\exp(sX)\frac{d}{dt}\Big|_{t=0}\exp(-s \text{Ad}(\exp(tY))X)$$ $$=\frac{d}{ds}\Big|_{s=0}\exp(sX)\left(\frac{d}{dt}\Big|_{t=0}\left(-s \text{Ad}(\exp(tY))X\right)\right)\exp(-s \text{Ad}(\exp(tY))X)$$ using $ \text{ad}(X)=\frac{d}{dt}\Big|_{t=0} \text{Ad}(\exp(tX)) $ $$=\frac{d}{ds}\Big|_{s=0}\exp(sX)\left(\left(-s \text{ad}(Y)X\right)\right)\exp(-s \text{Ad}(\exp(tY))X)$$ I'm not sure where to go from I tried working out the product rule but that did not seem to help. I also tried to work backwards from the definition of $[X,Y]$ to try and guide me $$[X,Y]=\text(ad)(X)Y=\frac{d}{dt}\Big|_{t=0}\text{Ad}(\exp(tX))Y$$ but this also did not help","Let be in the lie algebra of a lie group, I want to show that the following identity is true. I'm getting stuck and I feel some of the steps I used may not be allowed. Here is my attempt using using I'm not sure where to go from I tried working out the product rule but that did not seem to help. I also tried to work backwards from the definition of to try and guide me but this also did not help","X,Y [X,Y]= \frac{d}{ds}\Big|_{s=0}\frac{d}{dt}\Big|_{t=0}\exp(sX)\exp(tY)\exp(-sX)\exp(-tY). \frac{d}{ds}\Big|_{s=0}\frac{d}{dt}\Big|_{t=0}\exp(sX)\exp(tY)\exp(-sX)\exp(-tY) a \exp(V) a^{-1}=exp(\text{Ad}(a)V) =\frac{d}{ds}\Big|_{s=0}\frac{d}{dt}\Big|_{t=0}\exp(sX)\exp(-s \text{Ad}(\exp(tY))X) =\frac{d}{ds}\Big|_{s=0}\exp(sX)\frac{d}{dt}\Big|_{t=0}\exp(-s \text{Ad}(\exp(tY))X) =\frac{d}{ds}\Big|_{s=0}\exp(sX)\left(\frac{d}{dt}\Big|_{t=0}\left(-s \text{Ad}(\exp(tY))X\right)\right)\exp(-s \text{Ad}(\exp(tY))X)  \text{ad}(X)=\frac{d}{dt}\Big|_{t=0} \text{Ad}(\exp(tX))  =\frac{d}{ds}\Big|_{s=0}\exp(sX)\left(\left(-s \text{ad}(Y)X\right)\right)\exp(-s \text{Ad}(\exp(tY))X) [X,Y] [X,Y]=\text(ad)(X)Y=\frac{d}{dt}\Big|_{t=0}\text{Ad}(\exp(tX))Y","['differential-geometry', 'lie-groups']"
17,"If $f$ is a $0$-form and $dx$ a $1$-form, then does $f\ dx=f\wedge dx$?","If  is a -form and  a -form, then does ?",f 0 dx 1 f\ dx=f\wedge dx,"If $f$ is a $0$ -form and $dx$ a $1$ -form, then does $f\ dx=f\wedge dx$ ? Background: I am trying to prove that $d(f\ dx)=df\wedge dx$ using only the four properties of $d$ : (1) $d(w+v)=dw+dv$ (2) $d(w\wedge v)=dw\wedge v+(-1)^{\deg w}w\wedge dv$ (3) $f$ is a $0$ -form $\implies df$ is the differential of $f$ (4) $f$ is a $0$ -form $\implies d^2f=0$ My proof: $d(f\ dx)=d(f\wedge dx)=df\wedge dx+f\wedge d^2x=df\wedge dx$ . The second and third equal signs come from property 2 and 4 respectively. But the first one must come from $f\ dx=f\wedge dx$ . My question is why this is true. Although it seems very trivial, I believe a rigorous explanation is as follows: Let $A$ be the alternating map from the tensor product of $0$ -forms and $1$ -forms to its subspace of alternating tensors. Then by definition $f\wedge dx=A(f\otimes dx)$ . But there is a multiplication defined between $0$ -forms and $1$ -forms, so that tensoring means multiplying, and $f\otimes dx= f\ dx$ . And $A$ , as the alternating map over $1$ -forms, is actually the identity. Hence $f\wedge dx=A(f\otimes dx)=f\ dx$ Is this a correct explanation?","If is a -form and a -form, then does ? Background: I am trying to prove that using only the four properties of : (1) (2) (3) is a -form is the differential of (4) is a -form My proof: . The second and third equal signs come from property 2 and 4 respectively. But the first one must come from . My question is why this is true. Although it seems very trivial, I believe a rigorous explanation is as follows: Let be the alternating map from the tensor product of -forms and -forms to its subspace of alternating tensors. Then by definition . But there is a multiplication defined between -forms and -forms, so that tensoring means multiplying, and . And , as the alternating map over -forms, is actually the identity. Hence Is this a correct explanation?",f 0 dx 1 f\ dx=f\wedge dx d(f\ dx)=df\wedge dx d d(w+v)=dw+dv d(w\wedge v)=dw\wedge v+(-1)^{\deg w}w\wedge dv f 0 \implies df f f 0 \implies d^2f=0 d(f\ dx)=d(f\wedge dx)=df\wedge dx+f\wedge d^2x=df\wedge dx f\ dx=f\wedge dx A 0 1 f\wedge dx=A(f\otimes dx) 0 1 f\otimes dx= f\ dx A 1 f\wedge dx=A(f\otimes dx)=f\ dx,"['differential-geometry', 'differential-forms', 'exterior-algebra', 'exterior-derivative']"
18,types of morphisms in Differential/Algebriac geometry,types of morphisms in Differential/Algebriac geometry,,"In differential geometry, given two manifolds, only special types of morphisms between them are, submersions/immersions/and some one or two other types of maps. In Algebriac geometry, given two schemes, there are more than 10 types of maps between schemes that are of interest. Separated Quasi compact Locally of finite presentation Proper Affine Finite Flat Smooth Unramified Etale Embedding Closed embedding fpqc morphism and many more whose names itself far from my reach. It is difficult to even remember some names, let alone how they are defined. Question : Why is it the case that maps between schemes are super different from that of manifolds? Or, are there analogues of above maps in differential geometry setup as well?","In differential geometry, given two manifolds, only special types of morphisms between them are, submersions/immersions/and some one or two other types of maps. In Algebriac geometry, given two schemes, there are more than 10 types of maps between schemes that are of interest. Separated Quasi compact Locally of finite presentation Proper Affine Finite Flat Smooth Unramified Etale Embedding Closed embedding fpqc morphism and many more whose names itself far from my reach. It is difficult to even remember some names, let alone how they are defined. Question : Why is it the case that maps between schemes are super different from that of manifolds? Or, are there analogues of above maps in differential geometry setup as well?",,"['differential-geometry', 'algebraic-geometry']"
19,Find range of parameters for which a given curve is a geodesic,Find range of parameters for which a given curve is a geodesic,,"I am working on the following problem; Given  parameterised surface $X(u,v)=(u \cdot \cos v,u \cdot  \sin v,v)$ determine for which values $\alpha$ the curve $\gamma_{\alpha}=(t \cdot \cos (\alpha t),t \cdot \sin(\alpha t),\alpha t)$ is a geodesic. According to a theorem a curve $\gamma = X \circ \beta $ is a geodesic if and only if $\beta(t)=(u(t),v(t))$ satisfy $\frac{d}{dt}(E\dot{u}+F\dot{v})=\frac{1}{2}(E_{u}(\dot{u})^{2}+2F_{u}\dot{u}\dot{v} +G_{u}(\dot{v})^{2})$ $\frac{d}{dt}(F\dot{u}+G\dot{v})=\frac{1}{2}(E_{v}(\dot{u})^{2}+2F_{v}\dot{u}\dot{v} +G_{v} (\dot{v})^{2})$ . Given the data in this problem we have, $X_{u}=(\cos v,\sin v,0)$ $X_{v}=(-u \cdot \sin v, u \cdot \cos v, 1 )$ Hence $<X_{u},X_{u}>=E=1$ $<X_{u},X_{v}>=F=0$ $<X_{v},X_{v}>=G=u(t)^2+1$ Therefore we get the system $0=\alpha^2\cdot t$ $\alpha\cdot 2t=0$ Which means that $\alpha$ must be zero. This however dosn't seem quite right. Can anyone see where I go wrong and what the right answer should be?","I am working on the following problem; Given  parameterised surface determine for which values the curve is a geodesic. According to a theorem a curve is a geodesic if and only if satisfy . Given the data in this problem we have, Hence Therefore we get the system Which means that must be zero. This however dosn't seem quite right. Can anyone see where I go wrong and what the right answer should be?","X(u,v)=(u \cdot \cos v,u \cdot 
\sin v,v) \alpha \gamma_{\alpha}=(t \cdot \cos (\alpha t),t \cdot \sin(\alpha t),\alpha t) \gamma = X \circ \beta  \beta(t)=(u(t),v(t)) \frac{d}{dt}(E\dot{u}+F\dot{v})=\frac{1}{2}(E_{u}(\dot{u})^{2}+2F_{u}\dot{u}\dot{v} +G_{u}(\dot{v})^{2}) \frac{d}{dt}(F\dot{u}+G\dot{v})=\frac{1}{2}(E_{v}(\dot{u})^{2}+2F_{v}\dot{u}\dot{v} +G_{v}
(\dot{v})^{2}) X_{u}=(\cos v,\sin v,0) X_{v}=(-u \cdot \sin v, u \cdot \cos v, 1 ) <X_{u},X_{u}>=E=1 <X_{u},X_{v}>=F=0 <X_{v},X_{v}>=G=u(t)^2+1 0=\alpha^2\cdot t \alpha\cdot 2t=0 \alpha","['differential-geometry', 'geodesic']"
20,Immersion is equivalent to local embedding: Different proof when image is submanifold,Immersion is equivalent to local embedding: Different proof when image is submanifold,,"Update : Based on this , I think: Surjective immersions are local diffeomorphisms because surjective immersions have $\dim {\text{domain}} = \dim{\text{range/image}}$ . Similarly, immersions whose images are (regular/embedded) submanifolds of range are local diffeomorphisms onto their images because $\dim {\text{domain}} = \dim{\text{image}}$ , i.e. $n=k$ , as below. Please verify that this in fact answers these three questions: Immersions whose images are actually submanifolds? Or surjective immersions? (I think surjective immersions are local diffeomorphisms) https://math.stackexchange.com/questions/3301259/are-immersions-equivalent-to-local-diffeomorphisms-onto-their-images-if-their-im Immersion is equivalent to local embedding: Different proof when image is submanifold Question A . For these proofs (one on stackexchange, one on wordpress ) that immersions are local embeddings: I understand that images of immersions are immersed submanifolds , not necessarily (regular/embedded) submanifolds and not necessarily manifolds. Do I understand correctly that, nevertheless, immersions are local embeddings and that these proofs indeed prove such with the images of the immersions being assumed only immersed submanifolds? Question B . Is this proof for immersion, whose image is a submanifold, is a local embedding correct? (I won't prove that local embeddings are immersions.) In particular, I'm not sure about (5). I think (5) is true if $F(N)$ has the same dimension as $N$ . I think I at least proved local diffeomorphisms onto images with images submanifolds are local embeddings Let $N$ and $M$ be smooth manifolds with respective dimensions $n$ and $m$ . Let $p \in N$ . Let $F: N \to M$ be an immersion at $p$ . Let its image $F(N)$ be a (regular/embedded) $k$ -submanifold of $M$ . Let us show $F$ is a local embedding at $p$ , defined as that there exists a neighborhood $V_p$ of $p$ in $N$ such that $F|_{V_p}: V_p \to M$ is an embedding. Because $F(N)$ is a submanifold of $M$ , $F(N)$ is a manifold, so it would make sense to say, if we were to say that 3.1. The inclusion $\iota: F(N) \to M$ is a map of manifolds 3.2. $\tilde F: N \to F(N)$ , $F$ with restricted range that satisfies $F = \iota \circ \tilde F$ , is a map of manifolds. Assert (3.1) and (3.2). Additionally, the maps in (3) are smooth because $F(N)$ is a submanifold: 4.1. $\iota$ is smooth by this 4.2. $\tilde F$ is smooth by this . $\tilde F$ is a local diffeomorphism, i.e. $F$ is a ""local diffeomorphism onto its image"" by this , where there is no ambiguity in the definition of ""local diffeomorphism onto its image"" because its image is a submanifold. Edit: Not quite sure about this step actually. I think true if $n=k$ . Let $G=\tilde F$ By (5), there exists a neighborhood $U_p$ of $p$ in $N$ such that $G(U_p)$ is open in $F(N)$ , and $\tilde{G|_{U_p}}: U_p \to G(U_p)$ is a diffeomorphism, where $\tilde{G|_{U_p}}$ is $G|_{U_p}: U_p \to F(N)$ with restricted range. Choose $V_p = U_p$ . This works because, under this definition for embedding , equivalent to the more natural one : 7.1 $G|_{U_p}$ is an immersion if and only if $\tilde{G|_{U_p}}$ is an immersion, by this . 7.2 $G|_{U_p}$ is a topological embedding because $\tilde{G|_{U_p}}$ is a homeomorphism because $\tilde{G|_{U_p}}$ is a diffeomorphism. 7.3 $F|_{U_p} = \iota \circ G|_{U_p}$ 7.4 $F|_{U_p}$ is an immersion if both $G|_{U_p}$ and $\iota$ are immersions. 7.5 $\iota$ is an immersion by this . 7.6 $\tilde{G|_{U_p}}$ is an immersion since $\tilde{G|_{U_p}}$ is a diffeomorphism. 7.7 $G|_{U_p}$ is an immersion by (7.1) and (7.6). 7.8 Therefore, $F|_{U_p}$ is an immersion by (7.4) and (7.7). 7.9 $F|_{U_p}$ is a topological embedding if and only if $G|_{U_p}$ is a topoloigcal embedding. 7.10 Therefore, $F|_{U_p}$ is a topological embedding by (7.9) and (7.2). 7.11 Therefore, $F|_{U_p}$ is a smooth embedding by (7.10) and (7.8).","Update : Based on this , I think: Surjective immersions are local diffeomorphisms because surjective immersions have . Similarly, immersions whose images are (regular/embedded) submanifolds of range are local diffeomorphisms onto their images because , i.e. , as below. Please verify that this in fact answers these three questions: Immersions whose images are actually submanifolds? Or surjective immersions? (I think surjective immersions are local diffeomorphisms) https://math.stackexchange.com/questions/3301259/are-immersions-equivalent-to-local-diffeomorphisms-onto-their-images-if-their-im Immersion is equivalent to local embedding: Different proof when image is submanifold Question A . For these proofs (one on stackexchange, one on wordpress ) that immersions are local embeddings: I understand that images of immersions are immersed submanifolds , not necessarily (regular/embedded) submanifolds and not necessarily manifolds. Do I understand correctly that, nevertheless, immersions are local embeddings and that these proofs indeed prove such with the images of the immersions being assumed only immersed submanifolds? Question B . Is this proof for immersion, whose image is a submanifold, is a local embedding correct? (I won't prove that local embeddings are immersions.) In particular, I'm not sure about (5). I think (5) is true if has the same dimension as . I think I at least proved local diffeomorphisms onto images with images submanifolds are local embeddings Let and be smooth manifolds with respective dimensions and . Let . Let be an immersion at . Let its image be a (regular/embedded) -submanifold of . Let us show is a local embedding at , defined as that there exists a neighborhood of in such that is an embedding. Because is a submanifold of , is a manifold, so it would make sense to say, if we were to say that 3.1. The inclusion is a map of manifolds 3.2. , with restricted range that satisfies , is a map of manifolds. Assert (3.1) and (3.2). Additionally, the maps in (3) are smooth because is a submanifold: 4.1. is smooth by this 4.2. is smooth by this . is a local diffeomorphism, i.e. is a ""local diffeomorphism onto its image"" by this , where there is no ambiguity in the definition of ""local diffeomorphism onto its image"" because its image is a submanifold. Edit: Not quite sure about this step actually. I think true if . Let By (5), there exists a neighborhood of in such that is open in , and is a diffeomorphism, where is with restricted range. Choose . This works because, under this definition for embedding , equivalent to the more natural one : 7.1 is an immersion if and only if is an immersion, by this . 7.2 is a topological embedding because is a homeomorphism because is a diffeomorphism. 7.3 7.4 is an immersion if both and are immersions. 7.5 is an immersion by this . 7.6 is an immersion since is a diffeomorphism. 7.7 is an immersion by (7.1) and (7.6). 7.8 Therefore, is an immersion by (7.4) and (7.7). 7.9 is a topological embedding if and only if is a topoloigcal embedding. 7.10 Therefore, is a topological embedding by (7.9) and (7.2). 7.11 Therefore, is a smooth embedding by (7.10) and (7.8).",\dim {\text{domain}} = \dim{\text{range/image}} \dim {\text{domain}} = \dim{\text{image}} n=k F(N) N N M n m p \in N F: N \to M p F(N) k M F p V_p p N F|_{V_p}: V_p \to M F(N) M F(N) \iota: F(N) \to M \tilde F: N \to F(N) F F = \iota \circ \tilde F F(N) \iota \tilde F \tilde F F n=k G=\tilde F U_p p N G(U_p) F(N) \tilde{G|_{U_p}}: U_p \to G(U_p) \tilde{G|_{U_p}} G|_{U_p}: U_p \to F(N) V_p = U_p G|_{U_p} \tilde{G|_{U_p}} G|_{U_p} \tilde{G|_{U_p}} \tilde{G|_{U_p}} F|_{U_p} = \iota \circ G|_{U_p} F|_{U_p} G|_{U_p} \iota \iota \tilde{G|_{U_p}} \tilde{G|_{U_p}} G|_{U_p} F|_{U_p} F|_{U_p} G|_{U_p} F|_{U_p} F|_{U_p},"['general-topology', 'differential-geometry']"
21,Why is the mean curvature usually denoted by $H$?,Why is the mean curvature usually denoted by ?,H,"Soft question. For surfaces in $\Bbb R^3$ (for example), there are two relevant curvatures: the Gaussian curvature $K$ , and the mean curvature $H$ . Thinking here, I realized that while calling the Gaussian curvature $K$ makes sense (since in German curvature is Krümmung ), I have no idea why is the mean curvature denoted by $H$ . Is there any historical reason, or some word in German (or any other language) I'm missing?","Soft question. For surfaces in (for example), there are two relevant curvatures: the Gaussian curvature , and the mean curvature . Thinking here, I realized that while calling the Gaussian curvature makes sense (since in German curvature is Krümmung ), I have no idea why is the mean curvature denoted by . Is there any historical reason, or some word in German (or any other language) I'm missing?",\Bbb R^3 K H K H,"['differential-geometry', 'notation', 'riemannian-geometry', 'math-history']"
22,A simple compactness argument?,A simple compactness argument?,,"I am still trying to figure out how to construct positive line bundles on the blow up of a Kähler manifold and thus a Kähler form. In Voisin's book (Hodge Theory and Complex Algebraic Geometry), it is written: I fail to see the logic of the argument. Assuming $X$ is compact, then $\lambda$ is bounded, so everywhere where $\tau^* \omega_X$ is positive, $C \tau^* \omega_X + \lambda$ is positive for some fixed constant $C>0$ . This is the case everywhere but on the tangent space of the fibers of $\tau$ . But there $\lambda$ is positive and $\tau^* \omega $ vanishes. Did I understand it right, that the argument is this simple? The additional complexity should then come from the assumption of $X$ not neccesarily being compact. But I could still apply the same argument as above replacing $X$ with $K$ , a compact nbhd of $Y$ where $\lambda$ is zero. The fact that I did not use compactness of $Y$ at all, indicates that I did miss some subtlety. But I cannot figure out which one. Update: I can make the argument work if $\lambda$ is semi-positive on a neighbourhood of $\tau^{-1}(Y)$ . Does it work without this assumption? I don't think so.","I am still trying to figure out how to construct positive line bundles on the blow up of a Kähler manifold and thus a Kähler form. In Voisin's book (Hodge Theory and Complex Algebraic Geometry), it is written: I fail to see the logic of the argument. Assuming is compact, then is bounded, so everywhere where is positive, is positive for some fixed constant . This is the case everywhere but on the tangent space of the fibers of . But there is positive and vanishes. Did I understand it right, that the argument is this simple? The additional complexity should then come from the assumption of not neccesarily being compact. But I could still apply the same argument as above replacing with , a compact nbhd of where is zero. The fact that I did not use compactness of at all, indicates that I did miss some subtlety. But I cannot figure out which one. Update: I can make the argument work if is semi-positive on a neighbourhood of . Does it work without this assumption? I don't think so.",X \lambda \tau^* \omega_X C \tau^* \omega_X + \lambda C>0 \tau \lambda \tau^* \omega  X X K Y \lambda Y \lambda \tau^{-1}(Y),"['proof-verification', 'differential-geometry', 'compactness', 'complex-geometry']"
23,Riemannian Curvature and Levi-Civita Connection on Symmetric Positive Definite Matrix Manifold,Riemannian Curvature and Levi-Civita Connection on Symmetric Positive Definite Matrix Manifold,,"Let $\mathcal{S}$ be the Symmetric Matrices and $\mathcal{P}$ be the positive definite matrices. $\mathcal{S}$ naturally carries the structure of a vector space. Inner product on $\mathcal{S}$ is given by $\langle A , B \rangle =  trace(A B)$ . $\mathcal{P}$ is an open set in $\mathcal{S}$ . the map $$ log : \mathcal{P} \rightarrow \mathcal{S} $$ is a diffeomorphism between two manifolds. We can identify the tangent space at x $ T_{\text{x}}\mathcal{P} $ with $\text{x} \times \mathcal{S} $ . Induced metric on the Tangent space is given by $$ \langle A , B \rangle_{x}  = \langle dlog(A) |_{x} , dlog(B) |_{x} \rangle  $$ ,where $$ dlog : T_x\mathcal{P} \rightarrow T_{log(x)}\mathcal{S} $$ $$          A \mapsto A X^{-1}   $$ Writing out explicitly the inner product on $\mathcal{P}$ is given by $$\langle A , B \rangle_{X} = \text{trace}( A X^{-1} B X ^{-1})$$ Length $L(\gamma)$ and Energy $ E(\gamma)$ of a curve $ \gamma : [0,1] \rightarrow \mathcal{P} $ is given by $$    L(\gamma) = \int_a^b \| \dfrac{d\gamma}{dt} \|_{\gamma(t)} dt$$ $$E(\gamma) = \frac{1}{2} \int_a^b \| \dfrac{d\gamma}{dt}\|_{\gamma(t)}^2 dt $$ Geodesics are energy minimizing curves on a manifold. They allow us to introduce distance between two points on a manifold. To calculate them we can simply employ euler lagrange equations $$ \frac{d}{dt} \frac{d}{d\dot{\gamma}} f(t,\gamma(t), \dot{\gamma}(t)) = \frac{d}{d\gamma} f(t,\gamma(t), \dot{\gamma}(t))  $$ writing out explicitly we have $$ \frac{d}{dt} \frac{d}{d\dot{\gamma}}    \text{trace}( \dot{\gamma} \gamma^{-1} \dot{\gamma} \gamma ^{-1}) = \frac{d}{d\gamma}    \text{trace}( \dot{\gamma} \gamma^{-1} \dot{\gamma} \gamma ^{-1}) $$ Lefthand side of the equation reduces to $$ \frac{d}{dt} \gamma^{-1} \dot{\gamma} \gamma ^{-1}  $$ whereas the righthand side of the equation reduces to $$ - \gamma^{-1} \dot{\gamma} \gamma^{-1} \dot{\gamma} \gamma^{-1}  $$ Solving the differential equation we get two different expressions for the geodesics. $$ \gamma(t) = P exp(t P^{-1} S) $$ here P lies on the manifold and S lies on the tangent space. Intuitively $\gamma$ is the curve, which starts at P with direction S. $$ \gamma_{AB}(t) = A( A^{-1} B)^t $$ here gamma is the geodesic between the points on the manifold A and B. Now that the geodesics are defined, distance on the spd manifold may be defined via the length of the geodesic curve connecting two points. After some calculations we arrive at $$ d(X,Y) = \| log( X^{-1} Y ) \| $$ So those are my calculations so far. I am quite new to the differential geometry. My first question is do the arguments generally make sense? I am not really convinced that $ dlog = dX X^{-1} $ or that the inner product on $\mathcal{S}$ is $ trace(AB)$ . My ultimate goal is to read christoffel symbols from the geodesics eq. and calculate the riem. curvature. But i am not sure how to proceed or if the calculations so far makes sense. Edit: I tried to find another expression for dlog (and hoped it would be equivalent to $ AX^{-1}$ ) by taking the directional derivative of log-series . But generally the direction in which i take the derivative and the base point wont commute. That is why i dont think my expression for dlog is true. It is somehow funny that a wrong expression still produces a valid metric.","Let be the Symmetric Matrices and be the positive definite matrices. naturally carries the structure of a vector space. Inner product on is given by . is an open set in . the map is a diffeomorphism between two manifolds. We can identify the tangent space at x with . Induced metric on the Tangent space is given by ,where Writing out explicitly the inner product on is given by Length and Energy of a curve is given by Geodesics are energy minimizing curves on a manifold. They allow us to introduce distance between two points on a manifold. To calculate them we can simply employ euler lagrange equations writing out explicitly we have Lefthand side of the equation reduces to whereas the righthand side of the equation reduces to Solving the differential equation we get two different expressions for the geodesics. here P lies on the manifold and S lies on the tangent space. Intuitively is the curve, which starts at P with direction S. here gamma is the geodesic between the points on the manifold A and B. Now that the geodesics are defined, distance on the spd manifold may be defined via the length of the geodesic curve connecting two points. After some calculations we arrive at So those are my calculations so far. I am quite new to the differential geometry. My first question is do the arguments generally make sense? I am not really convinced that or that the inner product on is . My ultimate goal is to read christoffel symbols from the geodesics eq. and calculate the riem. curvature. But i am not sure how to proceed or if the calculations so far makes sense. Edit: I tried to find another expression for dlog (and hoped it would be equivalent to ) by taking the directional derivative of log-series . But generally the direction in which i take the derivative and the base point wont commute. That is why i dont think my expression for dlog is true. It is somehow funny that a wrong expression still produces a valid metric.","\mathcal{S} \mathcal{P} \mathcal{S} \mathcal{S} \langle A , B \rangle =  trace(A B) \mathcal{P} \mathcal{S}  log : \mathcal{P} \rightarrow \mathcal{S}   T_{\text{x}}\mathcal{P}  \text{x} \times \mathcal{S}   \langle A , B \rangle_{x}  = \langle dlog(A) |_{x} , dlog(B) |_{x} \rangle   
dlog : T_x\mathcal{P} \rightarrow T_{log(x)}\mathcal{S}  
         A \mapsto A X^{-1}
   \mathcal{P} \langle A , B \rangle_{X} = \text{trace}( A X^{-1} B X ^{-1}) L(\gamma)  E(\gamma)  \gamma : [0,1] \rightarrow \mathcal{P}  
   L(\gamma) = \int_a^b \| \dfrac{d\gamma}{dt} \|_{\gamma(t)} dt E(\gamma) = \frac{1}{2} \int_a^b \| \dfrac{d\gamma}{dt}\|_{\gamma(t)}^2 dt   \frac{d}{dt} \frac{d}{d\dot{\gamma}} f(t,\gamma(t), \dot{\gamma}(t)) = \frac{d}{d\gamma} f(t,\gamma(t), \dot{\gamma}(t))    \frac{d}{dt} \frac{d}{d\dot{\gamma}}
   \text{trace}( \dot{\gamma} \gamma^{-1} \dot{\gamma} \gamma ^{-1}) = \frac{d}{d\gamma}
   \text{trace}( \dot{\gamma} \gamma^{-1} \dot{\gamma} \gamma ^{-1})   \frac{d}{dt} \gamma^{-1} \dot{\gamma} \gamma ^{-1}    - \gamma^{-1} \dot{\gamma} \gamma^{-1} \dot{\gamma} \gamma^{-1}    \gamma(t) = P exp(t P^{-1} S)  \gamma  \gamma_{AB}(t) = A( A^{-1} B)^t   d(X,Y) = \| log( X^{-1} Y ) \|   dlog = dX X^{-1}  \mathcal{S}  trace(AB)  AX^{-1}","['differential-geometry', 'manifolds', 'matrix-calculus', 'positive-definite', 'symmetric-matrices']"
24,Extending differential form from a submanifold to a closed form,Extending differential form from a submanifold to a closed form,,"I am in $R^4$ in coordinates $x,y,z,t$ . Can I extend an arbitrary 3-form defined only at points of the line $x=y=z=0$ to a closed 3-form in a neighbourhood of the line. In fact my question is only local, I do not need to have the whole line. My intuition says ""yes"", but I have no idea how to prove it, or where to look for similar extension theorems. Added: Thanks to Ted Shifrin for his observation. That solves my problem. If I am, for instance, in Minkowski space, then the question can be transformed to divergenceless vector field. Then we extend all components $X^\mu(t)$ as constant with respect to  x,y,z, except of, say the first one, which we make linear in $x$ , like $X^1=x\, dX^4(t)/dt.$ Thanks","I am in in coordinates . Can I extend an arbitrary 3-form defined only at points of the line to a closed 3-form in a neighbourhood of the line. In fact my question is only local, I do not need to have the whole line. My intuition says ""yes"", but I have no idea how to prove it, or where to look for similar extension theorems. Added: Thanks to Ted Shifrin for his observation. That solves my problem. If I am, for instance, in Minkowski space, then the question can be transformed to divergenceless vector field. Then we extend all components as constant with respect to  x,y,z, except of, say the first one, which we make linear in , like Thanks","R^4 x,y,z,t x=y=z=0 X^\mu(t) x X^1=x\, dX^4(t)/dt.","['differential-geometry', 'differential-forms', 'submanifold']"
25,"Grassmannian is homogeneous, isotropic, and symmetric","Grassmannian is homogeneous, isotropic, and symmetric",,"I'm trying to prove the Grassmann manifold $\mathrm G_k(\mathbb R^n)$ of $k$ -dimensional linear subspaces of $\mathbb R^n$ is isotropic and symmetric. By ""isotropic"" I specifically that for every point $P \in \mathrm G_k(\mathbb R^n)$ , and for every pair of unit tangent vectors $u, v \in T_P \mathrm G_k(\mathbb R^n)$ , there is an isometry $\phi : \mathrm G_k(\mathbb R^n) \to \mathrm G_k(\mathbb R^n)$ fixing $P$ and with $d\phi_P u = v$ . By ""symmetric"" I mean for every $P \in \mathrm G_k(\mathbb R^n)$ , there is an isometry $\phi$ fixing $P$ and so that $d\phi_P = -\mathrm{Id} : T_P \mathrm G_k(\mathbb R^n) \to T_P \mathrm G_k(\mathbb R^n)$ . There appear to be a few different definitions for each, and I want to be clear with which one I'm using. My setting: $\mathrm G_k(\mathbb R^n)$ has a unique smooth structure with respect to which the natural action of $\mathrm{GL}(n,\mathbb R)$ on $\mathrm G_k(\mathbb R^n)$ is smooth. To define the Riemannian metric, we consider the Stiefel manifold $\mathrm V_k(\mathbb R^n)$ of $k$ -tuples of orthonormal vectors in $\mathbb R^n$ . This may be considered a submanifold of the space $\mathrm M(n \times k, \mathbb R)$ of $n \times k$ real matrices, with the Euclidean metric from identifying $\mathrm M(n \times k, \mathbb R) \approx \mathbb R^{nk}$ . The map $\pi : \mathrm V_k(\mathbb R^n) \to \mathrm G_k(\mathbb R^n)$ sending a $k$ -tuple of orthonormal vectors to its span is a surjective smooth submersion. One can show $\mathrm O(k)$ acts on the right of $\mathrm V_k(\mathbb R^n)$ isometrically, vertically (meaning for $A \in O(k)$ , $B \in \mathrm V_k(\mathbb R^n)$ , we have $\pi(BA) = \pi(B)$ ), and transitively on fibers (meaning if $B$ and $B'$ are two orthonormal $k$ -tuples with the same span, there's some $A \in \mathrm O(k)$ with $BA = B'$ ). It follows that there is a unique Riemannian metric on $\mathrm G_k(\mathbb R^n)$ with respect to which $\pi : \mathrm V_k(\mathbb R^n) \to \mathrm G_k(\mathbb R^n)$ is a Riemannian submersion, meaning for each $B \in \mathrm V_k(\mathbb R^n)$ , $d\pi_B : \ker\left(d\pi_B\right)^\perp \to T_{\pi(B)} \mathrm G_k(\mathbb R^n)$ is a linear isometry. Call this metric $g$ on $\mathrm G_k(\mathbb R^n)$ . My strategy: I know $\mathrm O(n)$ acts on the left transitively and isometrically on $\mathrm V_k(\mathbb R^n)$ , and hence acts transitively and isometrically on $\mathrm G_k(\mathbb R^n)$ , so $\mathrm G_k(\mathbb R^n)$ is homogeneous. So I only need to prove $\mathrm G_k(\mathbb R^n)$ is isotropic and symmetric at a single point; say the subspace $P = \mathbb R^k \subset \mathbb R^n$ , spanned by the first $k$ coordinates. The isotropy group in $\mathrm O(n)$ of this point is $G_P := \mathrm O(k) \oplus \mathrm O(n-k)$ . It seems intuitively obvious that with an appropriate choice of matrix $A \in \mathrm O(k) \oplus \mathrm O(n-k)$ , the differential of the action map $\theta_A : \mathrm G_k(\mathbb R^n) \to \mathrm G_k(\mathbb R^n)$ may either reflect the tangent space at $P$ or act transitively on unit tangent vectors, but I'm having trouble with the specifics. Plus the coordinates of the Grassmannian seem kind of weird and intimidating. Is there a coordinate-free way to make this argument rigorous?","I'm trying to prove the Grassmann manifold of -dimensional linear subspaces of is isotropic and symmetric. By ""isotropic"" I specifically that for every point , and for every pair of unit tangent vectors , there is an isometry fixing and with . By ""symmetric"" I mean for every , there is an isometry fixing and so that . There appear to be a few different definitions for each, and I want to be clear with which one I'm using. My setting: has a unique smooth structure with respect to which the natural action of on is smooth. To define the Riemannian metric, we consider the Stiefel manifold of -tuples of orthonormal vectors in . This may be considered a submanifold of the space of real matrices, with the Euclidean metric from identifying . The map sending a -tuple of orthonormal vectors to its span is a surjective smooth submersion. One can show acts on the right of isometrically, vertically (meaning for , , we have ), and transitively on fibers (meaning if and are two orthonormal -tuples with the same span, there's some with ). It follows that there is a unique Riemannian metric on with respect to which is a Riemannian submersion, meaning for each , is a linear isometry. Call this metric on . My strategy: I know acts on the left transitively and isometrically on , and hence acts transitively and isometrically on , so is homogeneous. So I only need to prove is isotropic and symmetric at a single point; say the subspace , spanned by the first coordinates. The isotropy group in of this point is . It seems intuitively obvious that with an appropriate choice of matrix , the differential of the action map may either reflect the tangent space at or act transitively on unit tangent vectors, but I'm having trouble with the specifics. Plus the coordinates of the Grassmannian seem kind of weird and intimidating. Is there a coordinate-free way to make this argument rigorous?","\mathrm G_k(\mathbb R^n) k \mathbb R^n P \in \mathrm G_k(\mathbb R^n) u, v \in T_P \mathrm G_k(\mathbb R^n) \phi : \mathrm G_k(\mathbb R^n) \to \mathrm G_k(\mathbb R^n) P d\phi_P u = v P \in \mathrm G_k(\mathbb R^n) \phi P d\phi_P = -\mathrm{Id} : T_P \mathrm G_k(\mathbb R^n) \to T_P \mathrm G_k(\mathbb R^n) \mathrm G_k(\mathbb R^n) \mathrm{GL}(n,\mathbb R) \mathrm G_k(\mathbb R^n) \mathrm V_k(\mathbb R^n) k \mathbb R^n \mathrm M(n \times k, \mathbb R) n \times k \mathrm M(n \times k, \mathbb R) \approx \mathbb R^{nk} \pi : \mathrm V_k(\mathbb R^n) \to \mathrm G_k(\mathbb R^n) k \mathrm O(k) \mathrm V_k(\mathbb R^n) A \in O(k) B \in \mathrm V_k(\mathbb R^n) \pi(BA) = \pi(B) B B' k A \in \mathrm O(k) BA = B' \mathrm G_k(\mathbb R^n) \pi : \mathrm V_k(\mathbb R^n) \to \mathrm G_k(\mathbb R^n) B \in \mathrm V_k(\mathbb R^n) d\pi_B : \ker\left(d\pi_B\right)^\perp \to T_{\pi(B)} \mathrm G_k(\mathbb R^n) g \mathrm G_k(\mathbb R^n) \mathrm O(n) \mathrm V_k(\mathbb R^n) \mathrm G_k(\mathbb R^n) \mathrm G_k(\mathbb R^n) \mathrm G_k(\mathbb R^n) P = \mathbb R^k \subset \mathbb R^n k \mathrm O(n) G_P := \mathrm O(k) \oplus \mathrm O(n-k) A \in \mathrm O(k) \oplus \mathrm O(n-k) \theta_A : \mathrm G_k(\mathbb R^n) \to \mathrm G_k(\mathbb R^n) P","['differential-geometry', 'riemannian-geometry', 'grassmannian']"
26,"About the term $-\nabla_{[u,v]}w$ in the definition of Riemann curvature tensor",About the term  in the definition of Riemann curvature tensor,"-\nabla_{[u,v]}w","As we know, in the definition of Riemann curvature tensor, we require $$ R(u,v)w=\nabla_u\nabla_v w-\nabla_v\nabla_u w-\nabla_{[u,v]}w $$ Could somebody tell me why we need $-\nabla_{[u,v]}w$ appearing in this definition. Is there any geometric meaning in it? Because the geometric meaning of $\nabla_u\nabla_v w-\nabla_v\nabla_u w$ is pretty clear, but for $-\nabla_{[u,v]}w$ I feel not so direct. In my opinion, because $[u,v]=\cal L_u v$, then $-\nabla_{[u,v]}w=-\nabla_{\cal L_u v}w$. So it looks like that this term is kind of correction of $\nabla_u\nabla_v w-\nabla_v\nabla_u w$, I mean, to neutralize the effects of the vector fields. This is a very naive hunch. Could you give me a more clear answer?","As we know, in the definition of Riemann curvature tensor, we require $$ R(u,v)w=\nabla_u\nabla_v w-\nabla_v\nabla_u w-\nabla_{[u,v]}w $$ Could somebody tell me why we need $-\nabla_{[u,v]}w$ appearing in this definition. Is there any geometric meaning in it? Because the geometric meaning of $\nabla_u\nabla_v w-\nabla_v\nabla_u w$ is pretty clear, but for $-\nabla_{[u,v]}w$ I feel not so direct. In my opinion, because $[u,v]=\cal L_u v$, then $-\nabla_{[u,v]}w=-\nabla_{\cal L_u v}w$. So it looks like that this term is kind of correction of $\nabla_u\nabla_v w-\nabla_v\nabla_u w$, I mean, to neutralize the effects of the vector fields. This is a very naive hunch. Could you give me a more clear answer?",,"['geometry', 'differential-geometry', 'differential-topology', 'general-relativity']"
27,Fundamental vector field and moment map for action on mathematical pendulum.,Fundamental vector field and moment map for action on mathematical pendulum.,,"I am trying to compute the moment map , for an action. As I understand it if I have a configuration space which is given by a manifold $M$ and an action $\rho_g \colon M \to M$ , it induces an action on the phase space $(\rho_{g^{-1}})^* : T^*M \to T^*M$ , $(\rho_{g^{-1}})^* : (q,p) \mapsto (gq, (\rho_{g^{-1}})^*(p))$ . Then we can compute the fundamental vector field . Let $X\in \mathfrak{g}=T_eG$ be the an element of the Lie algebra, we then have $X^\#_{(q,p)}=\frac{d}{dt}_{\vert_{t=0}} \rho_{exp(tX)^{-1}}^*(q,p)$ . I was trying do do an example to understand how it works. The mathematical pendulum with coordinate $(\phi,\theta)$ , and the action (with $G=S^1$ ) $\rho_g : S^2 \to S^2$ , $\rho_{\theta}:(\phi_0,\theta_0) \mapsto (\phi_0,\theta_0+\theta)$ . But in practice, I am confused as to how exactly calculat $(\rho_{-\theta})^*$ and $X^\#_{(q,p)}$ .","I am trying to compute the moment map , for an action. As I understand it if I have a configuration space which is given by a manifold and an action , it induces an action on the phase space , . Then we can compute the fundamental vector field . Let be the an element of the Lie algebra, we then have . I was trying do do an example to understand how it works. The mathematical pendulum with coordinate , and the action (with ) , . But in practice, I am confused as to how exactly calculat and .","M \rho_g \colon M \to M (\rho_{g^{-1}})^* : T^*M \to T^*M (\rho_{g^{-1}})^* : (q,p) \mapsto (gq, (\rho_{g^{-1}})^*(p)) X\in \mathfrak{g}=T_eG X^\#_{(q,p)}=\frac{d}{dt}_{\vert_{t=0}} \rho_{exp(tX)^{-1}}^*(q,p) (\phi,\theta) G=S^1 \rho_g : S^2 \to S^2 \rho_{\theta}:(\phi_0,\theta_0) \mapsto (\phi_0,\theta_0+\theta) (\rho_{-\theta})^* X^\#_{(q,p)}","['differential-geometry', 'lie-groups', 'group-actions', 'vector-fields', 'moment-map']"
28,Existence of Solutions to Elliptic Equations on Compact Manifolds -- Global Obstructions?,Existence of Solutions to Elliptic Equations on Compact Manifolds -- Global Obstructions?,,"Let $(M,g)$ be a smooth, closed Riemannian manifold and let $X$ and $c$ respectively be a smooth vector field and a smooth function on $M$ . Do there exist general criteria for determining for which smooth functions $f$ there exists a smooth solution to the elliptic PDE $$\Delta u +X(u) +cu =f?$$ I'm familiar with the local theory which guarantees for us the existence of local solutions in any coordinate patch but there seem to be global obstructions once we move to the manifold setting. For example, in the instance that $X$ and $c$ are both identically $0$ , there is a clear global obstruction to the problem, namely whether or not the integral of $f$ over $M$ vanishes (one can show, using the heat flow [or sheaf cohomology in the instance that $M$ is a Kähler] that, in this instance, this is in fact the only obstruction). I believe that in the case that either $c \geq 0$ or $c \leq 0$ the local theory combined with sheaf cohomology tells us that the answer is essentially the same as for the Laplacian, but if we don't have control over $c$ , then what happens? Any and all insights are welcomed!","Let be a smooth, closed Riemannian manifold and let and respectively be a smooth vector field and a smooth function on . Do there exist general criteria for determining for which smooth functions there exists a smooth solution to the elliptic PDE I'm familiar with the local theory which guarantees for us the existence of local solutions in any coordinate patch but there seem to be global obstructions once we move to the manifold setting. For example, in the instance that and are both identically , there is a clear global obstruction to the problem, namely whether or not the integral of over vanishes (one can show, using the heat flow [or sheaf cohomology in the instance that is a Kähler] that, in this instance, this is in fact the only obstruction). I believe that in the case that either or the local theory combined with sheaf cohomology tells us that the answer is essentially the same as for the Laplacian, but if we don't have control over , then what happens? Any and all insights are welcomed!","(M,g) X c M f \Delta u +X(u) +cu =f? X c 0 f M M c \geq 0 c \leq 0 c","['differential-geometry', 'elliptic-equations', 'linear-pde']"
29,Is a $C^1$ immersion that is injective on a closed set $K$ injective on a neighborhood of $K$?,Is a  immersion that is injective on a closed set  injective on a neighborhood of ?,C^1 K K,"I'm doing problem 7 of section 2.1 on ""Differential topology"" written by Hirsch which goes as \begin{array}{l}{\text { 7. A } C^{1} \text { immersion } f : M \rightarrow N \text { which is injective on a closed subset } K \subset M \text { is injective }} \\ {\text { on a neighborhood of } K . \text { In fact } f \text { has a neighborhood } \mathscr{N} \subset C_{S}^{1}(M, N) \text { and } K \text { has a }} \\ {\text { neighborhood } U \subset M \text { such that every } g \in \mathscr{N} \text { is injective on } U . \text { If } K \text { is compact } \mathcal{N}} \\ {\text { can be taken in } C_{W}^{1}(M, N) .}\end{array} I have no problem about the compact case, but I think the conclusion does not hold when $K$ is not compact for the following counterexample that I cook up. Consider the figure ""8"" $\beta :(-\pi, \pi) \rightarrow \mathbb{R}^{2}, \text { with } \beta(t)=(\sin  t, \sin 2t)$ and $n(t)$ be its normal $n(t)=(-2\cos2t,\cos t)$ . We define $f:(-\pi, \pi)\times(-1,1)\to\mathbb{R}^{2}$ $f(t,s)=\beta(t)+sn(t)$ . Then $f$ is $C^1$ immersion which is injective on a closed subset $K=(-\pi,\pi)\times\{0\}$ but $f$ cannot be injective on a neighborhood of $K$ since $f$ is not injective on $K\cup B_\delta(0)$ for any $\delta>0$ . Does this disprove the problem on the book?","I'm doing problem 7 of section 2.1 on ""Differential topology"" written by Hirsch which goes as I have no problem about the compact case, but I think the conclusion does not hold when is not compact for the following counterexample that I cook up. Consider the figure ""8"" and be its normal . We define . Then is immersion which is injective on a closed subset but cannot be injective on a neighborhood of since is not injective on for any . Does this disprove the problem on the book?","\begin{array}{l}{\text { 7. A } C^{1} \text { immersion } f : M \rightarrow N \text { which is injective on a closed subset } K \subset M \text { is injective }} \\ {\text { on a neighborhood of } K . \text { In fact } f \text { has a neighborhood } \mathscr{N} \subset C_{S}^{1}(M, N) \text { and } K \text { has a }} \\ {\text { neighborhood } U \subset M \text { such that every } g \in \mathscr{N} \text { is injective on } U . \text { If } K \text { is compact } \mathcal{N}} \\ {\text { can be taken in } C_{W}^{1}(M, N) .}\end{array} K \beta :(-\pi, \pi) \rightarrow \mathbb{R}^{2}, \text { with } \beta(t)=(\sin  t, \sin 2t) n(t) n(t)=(-2\cos2t,\cos t) f:(-\pi, \pi)\times(-1,1)\to\mathbb{R}^{2} f(t,s)=\beta(t)+sn(t) f C^1 K=(-\pi,\pi)\times\{0\} f K f K\cup B_\delta(0) \delta>0","['differential-geometry', 'differential-topology']"
30,"If $f_n:\Omega\to\Omega$ are homeomorphisms of a planar domain $\Omega$ such that $f_n\to f$, $f_n^{-1}\to g$ in $L^1$, is $f=g^{-1}$?","If  are homeomorphisms of a planar domain  such that ,  in , is ?",f_n:\Omega\to\Omega \Omega f_n\to f f_n^{-1}\to g L^1 f=g^{-1},"In Marchioro and Pulvirenti's book Mathematical Theory of Incompressible Nonviscous Fluids , the proof of global well-posedness of the 2D Euler equation in a bounded domain $\Omega\subset\mathbb R^2$ works by approximating the flow $\Phi^n_t(x)$ of the fluid given initial vorticity $\omega_0\in L^\infty(\Omega)$ , and showing that $\Phi^n\to\Phi$ for some $\Phi$ , with convergence in $L^\infty([0,T];L^1(\Omega))$ , and similar arguments show convergence $(\Phi^n)^{-1}\to\tilde\Phi$ for some $\tilde\Phi$ . Implicitly, the authors assume that $\Phi_t^{-1}=\tilde \Phi_t$ for all $t$ , but I don't see why this must hold. If it is of any use, I have found that the $\Phi^n$ and their inverses must all be incompressible flows, which are differentiable in time, and $C^{0,s}$ in space for some $s>0$ .","In Marchioro and Pulvirenti's book Mathematical Theory of Incompressible Nonviscous Fluids , the proof of global well-posedness of the 2D Euler equation in a bounded domain works by approximating the flow of the fluid given initial vorticity , and showing that for some , with convergence in , and similar arguments show convergence for some . Implicitly, the authors assume that for all , but I don't see why this must hold. If it is of any use, I have found that the and their inverses must all be incompressible flows, which are differentiable in time, and in space for some .","\Omega\subset\mathbb R^2 \Phi^n_t(x) \omega_0\in L^\infty(\Omega) \Phi^n\to\Phi \Phi L^\infty([0,T];L^1(\Omega)) (\Phi^n)^{-1}\to\tilde\Phi \tilde\Phi \Phi_t^{-1}=\tilde \Phi_t t \Phi^n C^{0,s} s>0","['real-analysis', 'differential-geometry', 'fluid-dynamics']"
31,Topological invariance of compactly supported de Rham cohomology,Topological invariance of compactly supported de Rham cohomology,,"It is well-known that if we are given two smooth manifolds (without) boundary, whose underlying topological spaces are homotopic, then the de Rham cohomologies $H^k_{dR}$ of $M$ and $N$ are isomorphic for all $k\geq 0$ [See Theorem 17.11 in Lee's smooth manifolds book]. I was wondering if a similar result holds for the compactly supported de Rham cohomologies $H^k_c(M)$ and $H^k_c(N)$ . I know that such a result doesn't hold if we only demand a standard homotopy relation. However Lee mentions shortly in his book that proper smooth maps induce maps between the compactly supported groups. In Exercise 6-8 of Lee's book  we are asked to show that every proper continuous map is homotopic to a proper smooth map, but I'm not sure if the homotopy is in fact proper, which according to this thread Invariance of de Rham cohomology with compact support and the cited book by Michor seems to be what we need in order to establish the result. Strangely enough I couldn't find any reference which explicitly states that the compactly supported de Rham cohomology groups are isomorphic for homeomorphic manifolds. To explicitly state my question: If the underlying topological spaces of two smooth manifolds (without boundary) $M$ and $N$ are homeomorphic, are their compactly supported de Rham cohomologies isomorphic? Kind regards","It is well-known that if we are given two smooth manifolds (without) boundary, whose underlying topological spaces are homotopic, then the de Rham cohomologies of and are isomorphic for all [See Theorem 17.11 in Lee's smooth manifolds book]. I was wondering if a similar result holds for the compactly supported de Rham cohomologies and . I know that such a result doesn't hold if we only demand a standard homotopy relation. However Lee mentions shortly in his book that proper smooth maps induce maps between the compactly supported groups. In Exercise 6-8 of Lee's book  we are asked to show that every proper continuous map is homotopic to a proper smooth map, but I'm not sure if the homotopy is in fact proper, which according to this thread Invariance of de Rham cohomology with compact support and the cited book by Michor seems to be what we need in order to establish the result. Strangely enough I couldn't find any reference which explicitly states that the compactly supported de Rham cohomology groups are isomorphic for homeomorphic manifolds. To explicitly state my question: If the underlying topological spaces of two smooth manifolds (without boundary) and are homeomorphic, are their compactly supported de Rham cohomologies isomorphic? Kind regards",H^k_{dR} M N k\geq 0 H^k_c(M) H^k_c(N) M N,"['differential-geometry', 'differential-topology', 'smooth-manifolds', 'differential-forms', 'de-rham-cohomology']"
32,Fibre bundles over interval are trivial - but in a smooth way?,Fibre bundles over interval are trivial - but in a smooth way?,,"I'm trying to understand the homotopy invariance theorem for smooth fibre bundles. A main step is to show that the interval $[0,1]$ only admits trivial fibre bundles. I found this proof (see Lemma 3) in the topological setting. In the very last step the author ""glues"" the previously constructed maps $ \varphi_i $ together to receive a global trivialisation, which is evidently well defined and a homeomorphism. But in the smooth world, I cannot find reason for smoothness here. I know proofs of the theorem for vector bundles by choosing a connection and parallel sections, but I need the statement for general fibre bundles. Anywhere I can find this proof?","I'm trying to understand the homotopy invariance theorem for smooth fibre bundles. A main step is to show that the interval only admits trivial fibre bundles. I found this proof (see Lemma 3) in the topological setting. In the very last step the author ""glues"" the previously constructed maps together to receive a global trivialisation, which is evidently well defined and a homeomorphism. But in the smooth world, I cannot find reason for smoothness here. I know proofs of the theorem for vector bundles by choosing a connection and parallel sections, but I need the statement for general fibre bundles. Anywhere I can find this proof?","[0,1]  \varphi_i ","['differential-geometry', 'fiber-bundles']"
33,"Euclidean sphere $\mathbb{S}^n$ immersed in Lorentzian sphere $\mathbb{S}^{(1,n+1)}$",Euclidean sphere  immersed in Lorentzian sphere,"\mathbb{S}^n \mathbb{S}^{(1,n+1)}","Let $\mathbb{S}^n=\{x\in\mathbb{R}^{n+1}\mid \langle x,x\rangle_\text{euc}=1\}$ and $\mathbb{S}^{(1,n+1)}:=\{x\in \mathbb{R}^{(1,n+2)}\mid \langle x,x\rangle=1\}$ , where $(\mathbb{R}^{(1,n+2)},\langle\cdot,\cdot\rangle)$ is the Lorentzian space with $\langle\cdot,\cdot\rangle=-dx_1^2+dx_2^2+...+dx_{n+3}^2$ . Define: \begin{align*} f: \mathbb{S}^n &\to \mathbb{S}^{(1,n+1)}\\ x &\mapsto (\psi(x),\psi(x),i(x)) \end{align*} where $\psi:\mathbb{S}^n\to\mathbb{R}$ is a smooth function and $i:\mathbb{S}^n\to \mathbb{R}^{n+1}$ is the natural embedding. Show that $f$ is an isometric immersion and compute its second fundamental form. I could easily show that $f$ is an isometric immersion by using the fact that $i$ is an immersion and by verifying that $f^*(-dx_1^2+dx_2^2+...+dx_{n+3}^2)=i^*(dx_1^2+...+dx_{n+1}^2)=g_{\mathbb{S}^n}$ . I had the following idea for computing the fundamental form, which I'm not sure is correct: If $\nabla, \nabla^\text{euc}$ are the Levi-Civita connections for $\mathbb{S}^n$ and $\mathbb{R}^{n+1}$ respectively, we can easily verify that $\nabla_XY(p)=\nabla^\text{euc}_xY(p)-\langle X,Y\rangle_\text{euc}p$ . Similarly, if $\widetilde{\nabla}$ , $\nabla^\text{lor}$ are the LC connections for $\mathbb{S}^{(1,n+1)}$ and $\mathbb{R}^{(1,n+2)}$ respectively, we find $\widetilde{\nabla}_XY(p)=\nabla^\text{lor}_XY(p)+\langle X,Y\rangle p$ . The second fundamental form $\alpha$ of $f$ would therefore be given by: \begin{align*} \alpha(X,Y)(p)&=\widetilde{\nabla}_XY(p)-\nabla_XY(p)\\ &=\nabla^\text{euc}_XY(p)-\nabla^\text{lor}_XY(p)+(\langle X,Y\rangle+\langle X,Y\rangle_\text{euc})p\\ &=(\langle X,Y\rangle+\langle X,Y\rangle_\text{euc})p \end{align*} Where in the last equality I tried to argue that, since Christoffel symbols vanish in Euclidean and Lorentzian spaces, then $\nabla^\text{euc}$ and $\nabla^\text{lor}$ look essentially the same. I know I've used some cheating and language abuse, but I hope this is essentialy correct, or at least restorable.","Let and , where is the Lorentzian space with . Define: where is a smooth function and is the natural embedding. Show that is an isometric immersion and compute its second fundamental form. I could easily show that is an isometric immersion by using the fact that is an immersion and by verifying that . I had the following idea for computing the fundamental form, which I'm not sure is correct: If are the Levi-Civita connections for and respectively, we can easily verify that . Similarly, if , are the LC connections for and respectively, we find . The second fundamental form of would therefore be given by: Where in the last equality I tried to argue that, since Christoffel symbols vanish in Euclidean and Lorentzian spaces, then and look essentially the same. I know I've used some cheating and language abuse, but I hope this is essentialy correct, or at least restorable.","\mathbb{S}^n=\{x\in\mathbb{R}^{n+1}\mid \langle x,x\rangle_\text{euc}=1\} \mathbb{S}^{(1,n+1)}:=\{x\in \mathbb{R}^{(1,n+2)}\mid \langle x,x\rangle=1\} (\mathbb{R}^{(1,n+2)},\langle\cdot,\cdot\rangle) \langle\cdot,\cdot\rangle=-dx_1^2+dx_2^2+...+dx_{n+3}^2 \begin{align*}
f: \mathbb{S}^n &\to \mathbb{S}^{(1,n+1)}\\
x &\mapsto (\psi(x),\psi(x),i(x))
\end{align*} \psi:\mathbb{S}^n\to\mathbb{R} i:\mathbb{S}^n\to \mathbb{R}^{n+1} f f i f^*(-dx_1^2+dx_2^2+...+dx_{n+3}^2)=i^*(dx_1^2+...+dx_{n+1}^2)=g_{\mathbb{S}^n} \nabla, \nabla^\text{euc} \mathbb{S}^n \mathbb{R}^{n+1} \nabla_XY(p)=\nabla^\text{euc}_xY(p)-\langle X,Y\rangle_\text{euc}p \widetilde{\nabla} \nabla^\text{lor} \mathbb{S}^{(1,n+1)} \mathbb{R}^{(1,n+2)} \widetilde{\nabla}_XY(p)=\nabla^\text{lor}_XY(p)+\langle X,Y\rangle p \alpha f \begin{align*}
\alpha(X,Y)(p)&=\widetilde{\nabla}_XY(p)-\nabla_XY(p)\\
&=\nabla^\text{euc}_XY(p)-\nabla^\text{lor}_XY(p)+(\langle X,Y\rangle+\langle X,Y\rangle_\text{euc})p\\
&=(\langle X,Y\rangle+\langle X,Y\rangle_\text{euc})p
\end{align*} \nabla^\text{euc} \nabla^\text{lor}","['proof-verification', 'differential-geometry', 'riemannian-geometry']"
34,The set of differentiable functions $f:M \to \mathbb{R}$ whose domains include a given point $m\in M$ doesn't form an algebra?!,The set of differentiable functions  whose domains include a given point  doesn't form an algebra?!,f:M \to \mathbb{R} m\in M,"I am reading the book ""Differentiable Manifolds"" by Brickell and Clark. on page 54, it  is written that:If we denote the set of differentiable functions $f:M \to \mathbb{R}$ on a manifold $M$ whose domains include a given point $m\in M$ by $\mathcal{F}(m)$ , then $\mathcal{F}(m)$ does not form a vector space over the set of real number $\mathbb{R}$ . And that is because $\mathcal{F}(m)$ does not contain a function $-f$ such that $f + (-f) = 0$ for all $f\in \mathcal{F}(m)$ ! I'm confused a little bit. Because if a function $f$ is defined at a point $m\in M$ , then $-f$ is also defined at $m$ . Am i making a mistake? Thanks for any help.","I am reading the book ""Differentiable Manifolds"" by Brickell and Clark. on page 54, it  is written that:If we denote the set of differentiable functions on a manifold whose domains include a given point by , then does not form a vector space over the set of real number . And that is because does not contain a function such that for all ! I'm confused a little bit. Because if a function is defined at a point , then is also defined at . Am i making a mistake? Thanks for any help.",f:M \to \mathbb{R} M m\in M \mathcal{F}(m) \mathcal{F}(m) \mathbb{R} \mathcal{F}(m) -f f + (-f) = 0 f\in \mathcal{F}(m) f m\in M -f m,"['differential-geometry', 'smooth-manifolds']"
35,Pulling back $\mathfrak g $-valued 1-forms,Pulling back -valued 1-forms,\mathfrak g ,"Let $\omega$ be a vector-valued 1-form where the vector space is the Lie algebra $\mathfrak g$ and let $\mathcal P$ be a trivial principal bundle over a manifold $M$ . Thus $$ \omega\in\Omega^1(\mathcal P,\mathfrak g)=\Gamma((\mathcal P \times \mathfrak g)\otimes T^*\mathcal P).\tag1  $$ I am reading that pulling back $\omega$ via the trivializing section $\sigma:M\to\mathcal P$ gives me a pull-back section $\sigma^*\omega\in\Omega^1(M,\mathfrak g)=\Gamma((M\times\mathfrak g)\otimes T^*M)$ . Namely, $\sigma^*\omega$ is a smooth section of the bundle $(M\times\mathfrak g)\otimes T^*M$ . Since a pull-back section is a section in the pull-back bundle, namely $$ \sigma^*\omega\in\Gamma(\sigma^*((\mathcal P\times\mathfrak g)\otimes T^*\mathcal P)),\tag2 $$ if what I am reading is correct, it follows that $$ \sigma^*((\mathcal P\times\mathfrak g)\otimes T^*\mathcal P)\cong(M\times\mathfrak g)\otimes T^*M. $$ Moreover, given a fiber bundle $\pi:E\to M$ and a function $f:M'\to M$ , then the pull-back bundle $f^*E$ and the bundle $E$ share same fibers over points $x'\in M'$ and $x=f(x')\in M$ , since it is a special case of a product bundle. Then it follows that $(\mathcal P\times\mathfrak g)\otimes T^*\mathcal P$ must share same fibers with $(M\times\mathfrak g)\otimes T^*M$ $\textbf {Problem}$ : same fibers means $\mathfrak g\otimes T^*P\cong\mathfrak g\otimes T^*M$ , which is of course not true. So what's wrong?","Let be a vector-valued 1-form where the vector space is the Lie algebra and let be a trivial principal bundle over a manifold . Thus I am reading that pulling back via the trivializing section gives me a pull-back section . Namely, is a smooth section of the bundle . Since a pull-back section is a section in the pull-back bundle, namely if what I am reading is correct, it follows that Moreover, given a fiber bundle and a function , then the pull-back bundle and the bundle share same fibers over points and , since it is a special case of a product bundle. Then it follows that must share same fibers with : same fibers means , which is of course not true. So what's wrong?","\omega \mathfrak g \mathcal P M 
\omega\in\Omega^1(\mathcal P,\mathfrak g)=\Gamma((\mathcal P \times \mathfrak g)\otimes T^*\mathcal P).\tag1 
 \omega \sigma:M\to\mathcal P \sigma^*\omega\in\Omega^1(M,\mathfrak g)=\Gamma((M\times\mathfrak g)\otimes T^*M) \sigma^*\omega (M\times\mathfrak g)\otimes T^*M 
\sigma^*\omega\in\Gamma(\sigma^*((\mathcal P\times\mathfrak g)\otimes T^*\mathcal P)),\tag2
 
\sigma^*((\mathcal P\times\mathfrak g)\otimes T^*\mathcal P)\cong(M\times\mathfrak g)\otimes T^*M.
 \pi:E\to M f:M'\to M f^*E E x'\in M' x=f(x')\in M (\mathcal P\times\mathfrak g)\otimes T^*\mathcal P (M\times\mathfrak g)\otimes T^*M \textbf {Problem} \mathfrak g\otimes T^*P\cong\mathfrak g\otimes T^*M","['differential-geometry', 'differential-forms', 'fiber-bundles']"
36,Theorem of Pappus,Theorem of Pappus,,"Given a surface of revolution $S$ which can be parametrized by the map $$ \mathbf x(u,v) = (f(v)\cos u,f(v)\sin u,g(v)), $$ over the open set $U =\{(u,v) \in \mathbb R^2 \mid 0 < u < 2\pi, a < v < b\}$ , I computed the area of $S$ to be \begin{align*} \int_a^b\int_0^{2\pi} |\mathbf x_u \times \mathbf x_v| \, du \, dv = 2\pi\int_a^b |f(v)| \sqrt{(f'(v))^2+(g'(v))^2} \, dv. \end{align*} If $l$ is the length of the generating curve $C$ , how does one then get the area of $S$ to also be written $$ 2\pi \int_0^l \rho (s) \, ds, $$ where $\rho=\rho(s)$ is the distance to the rotation axis of the point $C$ corresponding to $s$ ? I think that the arc length $s=\int_a^b |\alpha'(t)| \, dt$ , where $\alpha$ is the space curve, but I'm not sure in particular how one changes the interval $[a,b]$ to $[0,l]$ when changing the variable $v$ to $s$ .","Given a surface of revolution which can be parametrized by the map over the open set , I computed the area of to be If is the length of the generating curve , how does one then get the area of to also be written where is the distance to the rotation axis of the point corresponding to ? I think that the arc length , where is the space curve, but I'm not sure in particular how one changes the interval to when changing the variable to .","S 
\mathbf x(u,v) = (f(v)\cos u,f(v)\sin u,g(v)),
 U =\{(u,v) \in \mathbb R^2 \mid 0 < u < 2\pi, a < v < b\} S \begin{align*}
\int_a^b\int_0^{2\pi} |\mathbf x_u \times \mathbf x_v| \, du \, dv = 2\pi\int_a^b |f(v)| \sqrt{(f'(v))^2+(g'(v))^2} \, dv.
\end{align*} l C S 
2\pi \int_0^l \rho (s) \, ds,
 \rho=\rho(s) C s s=\int_a^b |\alpha'(t)| \, dt \alpha [a,b] [0,l] v s","['differential-geometry', 'surfaces', 'surface-integrals']"
37,Which 3-manifolds can be cubulated?,Which 3-manifolds can be cubulated?,,"I am trying to get a picture of what is currently known about cubulability of 3-manifolds, though cannot seem to find a good overview.  I am personally most interested in compact 3-manifolds with boundary embedded in $\mathbb{R}^3$ , but would be happy to hear any answers to this question.  If I had to name one concrete question, it would be: Question: Can you cubulate every compact 3-manifold $M \subset \mathbb{R}^3$ ?  If not, which ones can you cubulate?  What are some specific examples of non-cubulable $M$ ? I am aware of some scattered results, e.g., all hyperbolic 3-manifolds are cubulable (discussed in Sections 4.5, 4.6 of this paper ) there is some discussion about cubulability of Kähler groups/Kähler manifolds here there is a characterization in terms of the boundary here Apart from the result about hyperbolic 3-manifolds, I find it quite hard to connect largely algebraic results like these back to a more concrete geometric/topological picture.","I am trying to get a picture of what is currently known about cubulability of 3-manifolds, though cannot seem to find a good overview.  I am personally most interested in compact 3-manifolds with boundary embedded in , but would be happy to hear any answers to this question.  If I had to name one concrete question, it would be: Question: Can you cubulate every compact 3-manifold ?  If not, which ones can you cubulate?  What are some specific examples of non-cubulable ? I am aware of some scattered results, e.g., all hyperbolic 3-manifolds are cubulable (discussed in Sections 4.5, 4.6 of this paper ) there is some discussion about cubulability of Kähler groups/Kähler manifolds here there is a characterization in terms of the boundary here Apart from the result about hyperbolic 3-manifolds, I find it quite hard to connect largely algebraic results like these back to a more concrete geometric/topological picture.",\mathbb{R}^3 M \subset \mathbb{R}^3 M,"['differential-geometry', 'algebraic-topology', 'differential-topology', 'geometric-topology', 'geometric-group-theory']"
38,Is the metric tensor relative to a reference coordinate system?,Is the metric tensor relative to a reference coordinate system?,,"I am fairly new to this topic, and I don't know anything about tensors, but I have to know what a metric tensor is and this is how I have been thinking about it: 1)A metric tensor is a mathematical entity that expresses distances between points in generalized coordinates; This part I got quite well I think, but now here's my question: I am a being that lives in a flat 3D space, that is, everything I see and experience is according to cartesian coordinates and even if I represent something with other coordinate system (say, with spherical coordinates) that new system arises from my experience on a 3D flat space. Another way of saying this is that the ""instinctive"" metric tensor I live by is: $$g_1=\begin{bmatrix}     1 & 0 & 0 \\     0 & 1 & 0 \\     0 & 0 & 1 \end{bmatrix}$$ But if I then, somehow, want to be in a spherical space, that is, a space where the coordinates are $(r,\theta ,\phi )$ , then I say (well the books do) that my new metric space is: $$g_2=\begin{bmatrix}     1 & 0 & 0 \\     0 & r^2 & 0 \\     0 & 0 & r^2sin^2(\theta) \end{bmatrix}$$ But that results seems to me that is biased,that is, $g_2$ exists as it is because I want that a given distance between 2 points in 3D space to have the same value in the spherical space between those 2 same points when they are parametrized from one space to the other. But what if it all went backwards? Suppose now that I live in a 3D spherical space, I could represent all of space with a 3 orthogonal axis space (like the figure below) and simply replace x,y and z by $(r,\theta ,\phi)$ and I would and my ""natural"" metric tensor would still be $g_1$ but when I went to the 3D flat space, then $g_2$ would not be the same. My question/argument is that all metric tensors are relative to our own experience of day to day life, and all other metric spaces exist as they do to agree with our experience, to be in conformity with our reference ( $g_1$ ), thus we cannot talk of metric tensors as absolute entities, we have to mention the reference as well.","I am fairly new to this topic, and I don't know anything about tensors, but I have to know what a metric tensor is and this is how I have been thinking about it: 1)A metric tensor is a mathematical entity that expresses distances between points in generalized coordinates; This part I got quite well I think, but now here's my question: I am a being that lives in a flat 3D space, that is, everything I see and experience is according to cartesian coordinates and even if I represent something with other coordinate system (say, with spherical coordinates) that new system arises from my experience on a 3D flat space. Another way of saying this is that the ""instinctive"" metric tensor I live by is: But if I then, somehow, want to be in a spherical space, that is, a space where the coordinates are , then I say (well the books do) that my new metric space is: But that results seems to me that is biased,that is, exists as it is because I want that a given distance between 2 points in 3D space to have the same value in the spherical space between those 2 same points when they are parametrized from one space to the other. But what if it all went backwards? Suppose now that I live in a 3D spherical space, I could represent all of space with a 3 orthogonal axis space (like the figure below) and simply replace x,y and z by and I would and my ""natural"" metric tensor would still be but when I went to the 3D flat space, then would not be the same. My question/argument is that all metric tensors are relative to our own experience of day to day life, and all other metric spaces exist as they do to agree with our experience, to be in conformity with our reference ( ), thus we cannot talk of metric tensors as absolute entities, we have to mention the reference as well.","g_1=\begin{bmatrix}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    0 & 0 & 1
\end{bmatrix} (r,\theta ,\phi ) g_2=\begin{bmatrix}
    1 & 0 & 0 \\
    0 & r^2 & 0 \\
    0 & 0 & r^2sin^2(\theta)
\end{bmatrix} g_2 (r,\theta ,\phi) g_1 g_2 g_1","['differential-geometry', 'metric-spaces', 'tensors']"
39,Smooth structures on noncompact 6-manifolds,Smooth structures on noncompact 6-manifolds,,"Does a noncompact, simply connected 6-manifold have a unique smooth structure? Maybe with more assumptions like having torsion-free homology and being spin? Note that in the compact case C.T.C. Wall showed that this is true. Can counterexamples be constructed with exotic $\mathbb{R}^4$ s, e.g. $X\times S^2$ with $X$ an exotic $\mathbb{R}^4$ ? Any related references would be appreciated.","Does a noncompact, simply connected 6-manifold have a unique smooth structure? Maybe with more assumptions like having torsion-free homology and being spin? Note that in the compact case C.T.C. Wall showed that this is true. Can counterexamples be constructed with exotic s, e.g. with an exotic ? Any related references would be appreciated.",\mathbb{R}^4 X\times S^2 X \mathbb{R}^4,"['differential-geometry', 'algebraic-topology', 'differential-topology']"
40,Orthogonality of principal curvature directions,Orthogonality of principal curvature directions,,"I was trying to find a counterexample to the theorem that states that principal curvature directions are orthogonal. Obviously such an example doesn't exist but I'm having hard time understanding what's wrong with the following example. I construct the surface as follows. I take a planar curve, namely a parabola $a (r^2)$ and revolve it through the $Z$ axis while adjusting the parameter $a$ that controls the curvature of the parabola. The parametrization is given by: $$ \left [X = rcos(\theta), \quad \quad Y = rsin(\theta),  \quad \quad Z = ar^2 \right],$$ $$a(\theta)=0.5(1 + sin(4\theta)),$$ where the parametric domain is $$ \theta \in [0,\pi],  \quad \quad r \in [-0.5,0.5].$$ The ""problematic"" point is the origin $(0,0,0)$ . See a Matlab rendering of the surface in $3D$ : For $\theta \in \{3\pi/8,7\pi/8\}$ the $\sin(4\theta)$ in the expression for $a(\theta)$ is at minimum ( $-1$ ) and we get $a=0$ . The restriction of $\theta$ to these two values corresponds to two orthogonal  straight lines on the surface (green in the figure). Hence $\kappa_2 = 0$ . For $\theta \in \{\pi/8,5\pi/8\}$ the $\sin(4\theta)$ in the expression for $a(\theta)$ is at maximum ( $1$ ) and we get $a=1$ . The restriction of $\theta$ to these two values corresponds to two orthogonal parabolas on the surface (red in the figure) with $\kappa_1=2$ . Here is a top view of the $XY$ plane: The ""contradiction"" seems to be that the curves with minimal and maximal curvatures at the origin are attained at $45$ degrees rather than $90$ .","I was trying to find a counterexample to the theorem that states that principal curvature directions are orthogonal. Obviously such an example doesn't exist but I'm having hard time understanding what's wrong with the following example. I construct the surface as follows. I take a planar curve, namely a parabola and revolve it through the axis while adjusting the parameter that controls the curvature of the parabola. The parametrization is given by: where the parametric domain is The ""problematic"" point is the origin . See a Matlab rendering of the surface in : For the in the expression for is at minimum ( ) and we get . The restriction of to these two values corresponds to two orthogonal  straight lines on the surface (green in the figure). Hence . For the in the expression for is at maximum ( ) and we get . The restriction of to these two values corresponds to two orthogonal parabolas on the surface (red in the figure) with . Here is a top view of the plane: The ""contradiction"" seems to be that the curves with minimal and maximal curvatures at the origin are attained at degrees rather than .","a (r^2) Z a  \left [X = rcos(\theta), \quad \quad Y = rsin(\theta),  \quad \quad Z = ar^2 \right], a(\theta)=0.5(1 + sin(4\theta)),  \theta \in [0,\pi],  \quad \quad r \in [-0.5,0.5]. (0,0,0) 3D \theta \in \{3\pi/8,7\pi/8\} \sin(4\theta) a(\theta) -1 a=0 \theta \kappa_2 = 0 \theta \in \{\pi/8,5\pi/8\} \sin(4\theta) a(\theta) 1 a=1 \theta \kappa_1=2 XY 45 90",['differential-geometry']
41,Integrating on a Manifold,Integrating on a Manifold,,"I'm new to working with differential forms and integrating over manifolds. I think that I have the following problem solved, but I'm not all that confident in my work. Let $D=\{(x,y,z)\in\mathbb{R}^{3}~:~y=x^{2}+z^{2},y\leq 4\}$ , and let the region be oriented by the $2$ -form $\sigma=dz\wedge dx$ . Evaluate $\int_{D}\omega$ , where $\omega=z~dx\wedge dy$ . Here's my work: We parametrize the region with the map $\psi:(0,2]\times(-\pi,\pi)\to\mathbb{R}^{3}$ given by $$\psi(r,\theta)=(r\cos\theta,r^2,r\sin\theta)$$ (I think that the open intervals are okay, because we only need to cover the manifold modulo sets of measure zero). We now check orientations by computing the pullbacks $\psi^{*}\sigma$ and $\psi^{*}\omega$ . We have \begin{align} \psi^{*}\sigma&=\psi^{*}(dz\wedge dx)\\ &=d(r\sin\theta)\wedge d(r\cos\theta)\\ &=(\sin\theta~dr+r\cos\theta~d\theta)\wedge(\cos\theta~dr-r\sin\theta~d\theta)\\ &=-r\sin^{2}\theta~dr\wedge d\theta+r\cos^{2}\theta~d\theta\wedge dr\\ &=-r\sin^{2}\theta~dr\wedge d\theta-r\cos^{2}\theta~dr\wedge d\theta\\ &=-r~dr\wedge d\theta \end{align} and we have \begin{align} \psi^{*}\omega&=\psi^{*}(z~dx\wedge dy)\\ &=r\sin\theta~\left[d(r\cos\theta)\wedge d(r^{2})\right]\\ &=r\sin\theta~\left[(\cos\theta~dr-r\sin\theta~d\theta)\wedge(2r~dr)\right]\\ &=r\sin\theta~(-2r^{2}\sin\theta~d\theta\wedge dr)\\ &=(2r^{3}\sin^{2}\theta)~dr\wedge d\theta. \end{align} Since $\psi^{*}\sigma$ is everywhere negative and $\psi^{*}\omega$ is everywhere positive, we have $\int_{D}\omega=-\int_{(0,2]\times(-\pi,\pi)}\psi^{*}\omega$ . Hence, \begin{align} \int_{D}\omega&=-\int_{-\pi}^{\pi}\int_{0}^{2}(2r^{3}\sin^{2}\theta)dr~d\theta\\ &=-8\int_{-\pi}^{\pi}\sin^{2}\theta~d\theta\\ &=-4\int_{-\pi}^{\pi}(1-\cos(2\theta))~d\theta\\ &=-4(\theta-\frac{1}{2}\sin(2\theta))\bigg|_{-\pi}^{\pi}\\ &=-4\pi-(-4)(-\pi)\\ &=-8\pi. \end{align} Does my work look correct? I've tried this several times and I've gotten a couple of different answers, but I think this one is correct (I went through the steps methodically and tried not to make any stupid mistakes). Any help is appreciated.","I'm new to working with differential forms and integrating over manifolds. I think that I have the following problem solved, but I'm not all that confident in my work. Let , and let the region be oriented by the -form . Evaluate , where . Here's my work: We parametrize the region with the map given by (I think that the open intervals are okay, because we only need to cover the manifold modulo sets of measure zero). We now check orientations by computing the pullbacks and . We have and we have Since is everywhere negative and is everywhere positive, we have . Hence, Does my work look correct? I've tried this several times and I've gotten a couple of different answers, but I think this one is correct (I went through the steps methodically and tried not to make any stupid mistakes). Any help is appreciated.","D=\{(x,y,z)\in\mathbb{R}^{3}~:~y=x^{2}+z^{2},y\leq 4\} 2 \sigma=dz\wedge dx \int_{D}\omega \omega=z~dx\wedge dy \psi:(0,2]\times(-\pi,\pi)\to\mathbb{R}^{3} \psi(r,\theta)=(r\cos\theta,r^2,r\sin\theta) \psi^{*}\sigma \psi^{*}\omega \begin{align}
\psi^{*}\sigma&=\psi^{*}(dz\wedge dx)\\
&=d(r\sin\theta)\wedge d(r\cos\theta)\\
&=(\sin\theta~dr+r\cos\theta~d\theta)\wedge(\cos\theta~dr-r\sin\theta~d\theta)\\
&=-r\sin^{2}\theta~dr\wedge d\theta+r\cos^{2}\theta~d\theta\wedge dr\\
&=-r\sin^{2}\theta~dr\wedge d\theta-r\cos^{2}\theta~dr\wedge d\theta\\
&=-r~dr\wedge d\theta
\end{align} \begin{align}
\psi^{*}\omega&=\psi^{*}(z~dx\wedge dy)\\
&=r\sin\theta~\left[d(r\cos\theta)\wedge d(r^{2})\right]\\
&=r\sin\theta~\left[(\cos\theta~dr-r\sin\theta~d\theta)\wedge(2r~dr)\right]\\
&=r\sin\theta~(-2r^{2}\sin\theta~d\theta\wedge dr)\\
&=(2r^{3}\sin^{2}\theta)~dr\wedge d\theta.
\end{align} \psi^{*}\sigma \psi^{*}\omega \int_{D}\omega=-\int_{(0,2]\times(-\pi,\pi)}\psi^{*}\omega \begin{align}
\int_{D}\omega&=-\int_{-\pi}^{\pi}\int_{0}^{2}(2r^{3}\sin^{2}\theta)dr~d\theta\\
&=-8\int_{-\pi}^{\pi}\sin^{2}\theta~d\theta\\
&=-4\int_{-\pi}^{\pi}(1-\cos(2\theta))~d\theta\\
&=-4(\theta-\frac{1}{2}\sin(2\theta))\bigg|_{-\pi}^{\pi}\\
&=-4\pi-(-4)(-\pi)\\
&=-8\pi.
\end{align}","['integration', 'proof-verification', 'differential-geometry', 'smooth-manifolds', 'differential-forms']"
42,Musical Isomorphisms,Musical Isomorphisms,,"I'm studying from Fecko's Differential Geometry and Lie Groups for Physicists , and in the part introducing metric tensors, Fecko introduces the musical isomorphisms between the tangent and cotangent space as the following maps for some metric tensor $g$ . $$\flat{g}:v \mapsto g(v, \cdot)$$ and similarly, $$\sharp{g}:\alpha \mapsto g^{-1}(\alpha, \cdot)$$ Fecko then gives an exercise to show these equal, in component form, the following: $$g_{ab}v^b$$ and $$g^{ab}\alpha_b$$ respectively. How do I calculate $g(v, \cdot)$ or $g^{-1}(\alpha, \cdot)$ ? I'm not sure where to begin... I'm new to tensors and get lost easily with the notation.","I'm studying from Fecko's Differential Geometry and Lie Groups for Physicists , and in the part introducing metric tensors, Fecko introduces the musical isomorphisms between the tangent and cotangent space as the following maps for some metric tensor . and similarly, Fecko then gives an exercise to show these equal, in component form, the following: and respectively. How do I calculate or ? I'm not sure where to begin... I'm new to tensors and get lost easily with the notation.","g \flat{g}:v \mapsto g(v, \cdot) \sharp{g}:\alpha \mapsto g^{-1}(\alpha, \cdot) g_{ab}v^b g^{ab}\alpha_b g(v, \cdot) g^{-1}(\alpha, \cdot)","['linear-algebra', 'differential-geometry', 'tensors', 'multilinear-algebra']"
43,Jet prolongation of a distribution on a manifold,Jet prolongation of a distribution on a manifold,,"I'm trying to work with the first jet prolongation of a $k$ -distribution on a manifold $M$ of dimension $n$ . My intuition is to consider the Grassmann bundle $X=Gr_k(TM)\to M$ and look at the first jet space $X^{(1)}$ . But I'm stuck at how to write down a point in the jet space. From the definition, a typical point has to be of the form $j^1_\mathcal{D}(p)$ , for some germ of local section $\mathcal{D}$ of $X$ at the point $p\in M$ . Thus $\mathcal{D}$ is a locally defined $k$ -distribution around $p$ . But how do I write $j^1_\mathcal{D}(p)$ in local coordinates? Another approach could be using the $k$ -frame bundle and the take jet prolongation. But again, I cannot think about the local coordinates. Any help is appreciated.","I'm trying to work with the first jet prolongation of a -distribution on a manifold of dimension . My intuition is to consider the Grassmann bundle and look at the first jet space . But I'm stuck at how to write down a point in the jet space. From the definition, a typical point has to be of the form , for some germ of local section of at the point . Thus is a locally defined -distribution around . But how do I write in local coordinates? Another approach could be using the -frame bundle and the take jet prolongation. But again, I cannot think about the local coordinates. Any help is appreciated.",k M n X=Gr_k(TM)\to M X^{(1)} j^1_\mathcal{D}(p) \mathcal{D} X p\in M \mathcal{D} k p j^1_\mathcal{D}(p) k,"['differential-geometry', 'grassmannian', 'jet-bundles']"
44,"$\text{SL}(2,\mathbb{R})$ acts on the hyperbolic space by isometries",acts on the hyperbolic space by isometries,"\text{SL}(2,\mathbb{R})","Let $H:=\{(x_0,x_1,x_2)\in\mathbb{R}^3\mid -x_0^2+x_1^2+x_2^2=-1\}$ be the hyperbolic space with metric $g_{hip}$ induced by the Lorenz inner product $g_{Lor}=-dx_0^2+dx_1^2+dx_2^2$ . Find a bijection between $H$ and $X:=\{M\in\mathbb{R}^{2\times 2}\mid M^t=M,\,\det(M)=1\}$ and show that $\text{SL}(2,\mathbb{R})$ acts on $H$ by isometries. I've found the following correspondence: $(x_0,x_1,x_2)\in H\mapsto\left(\begin{array}{ll}(x_0+x_1) & x_2\\x_2 & (x_0-x_1)\end{array}\right)\in X$ and conversely $\left(\begin{array}{ll}a & b\\b & c\end{array}\right)\in X\mapsto\left(\frac{a+c}{2},\frac{a-c}{2},b\right)\in H$ , which are mutually inverse. I've also defined an action on $X$ given by: \begin{align*} \rho:\text{SL}(2,\mathbb{R})&\to \text{Bij}(X)\\ M&\mapsto (A\mapsto M^tAM) \end{align*} I've checked that $\rho$ is indeed a group action, but I don't know how to prove that this will be translated into an isometry of $H$ . Any suggestions?","Let be the hyperbolic space with metric induced by the Lorenz inner product . Find a bijection between and and show that acts on by isometries. I've found the following correspondence: and conversely , which are mutually inverse. I've also defined an action on given by: I've checked that is indeed a group action, but I don't know how to prove that this will be translated into an isometry of . Any suggestions?","H:=\{(x_0,x_1,x_2)\in\mathbb{R}^3\mid -x_0^2+x_1^2+x_2^2=-1\} g_{hip} g_{Lor}=-dx_0^2+dx_1^2+dx_2^2 H X:=\{M\in\mathbb{R}^{2\times 2}\mid M^t=M,\,\det(M)=1\} \text{SL}(2,\mathbb{R}) H (x_0,x_1,x_2)\in H\mapsto\left(\begin{array}{ll}(x_0+x_1) & x_2\\x_2 & (x_0-x_1)\end{array}\right)\in X \left(\begin{array}{ll}a & b\\b & c\end{array}\right)\in X\mapsto\left(\frac{a+c}{2},\frac{a-c}{2},b\right)\in H X \begin{align*}
\rho:\text{SL}(2,\mathbb{R})&\to \text{Bij}(X)\\
M&\mapsto (A\mapsto M^tAM)
\end{align*} \rho H","['differential-geometry', 'riemannian-geometry', 'group-actions', 'hyperbolic-geometry']"
45,Conformal Killing Equation,Conformal Killing Equation,,"I saw this come up in a lecture on conformal field theory, and was a bit skeptical of the claim. So, given some conformal Killing field, $$ \mathcal{L}_{\xi}~g = \lambda g $$ it was said the following is true $$ \mathcal{L}_{\nabla^2\xi}g=g\nabla^2\lambda $$ Where $\nabla^2=\nabla^a\nabla_a$ (a contraction of covariant derivatives). I have tried writing things out but can't get anywhere.  I end up with a bunch of Riemann tensor terms that don't cancel. So, first off is this even true, and if so how can I show it?","I saw this come up in a lecture on conformal field theory, and was a bit skeptical of the claim. So, given some conformal Killing field, $$ \mathcal{L}_{\xi}~g = \lambda g $$ it was said the following is true $$ \mathcal{L}_{\nabla^2\xi}g=g\nabla^2\lambda $$ Where $\nabla^2=\nabla^a\nabla_a$ (a contraction of covariant derivatives). I have tried writing things out but can't get anywhere.  I end up with a bunch of Riemann tensor terms that don't cancel. So, first off is this even true, and if so how can I show it?",,"['differential-geometry', 'riemannian-geometry', 'laplacian']"
46,Is there a category theoretic characterisation of the exponential map from differential geometry?,Is there a category theoretic characterisation of the exponential map from differential geometry?,,"While I have only a shallow understanding, I like category theory. I find definitions and proofs in terms of category theoretic concepts to be very clean and deep, often cutting to the core of a concept and what its ""about"", and why we care about it, especially definitions in terms of universal properties. I wanted to know if there is a definition of the exponential map from differential geometry in category theoretic terms. The definition I know of is for a manifold $M$, and a point $p \in M$, $\exp: (v \in T_pM) \mapsto \gamma_v(1)$ Where $\gamma$ is the locally unique geodesic though $p$ of velocity $v$ such that $\gamma_v(0) = p$. I may have slightly messed up the definiton. I would be especially interested in definitions in geometrical/topological terms with as few constructions/parametrisations as possible.","While I have only a shallow understanding, I like category theory. I find definitions and proofs in terms of category theoretic concepts to be very clean and deep, often cutting to the core of a concept and what its ""about"", and why we care about it, especially definitions in terms of universal properties. I wanted to know if there is a definition of the exponential map from differential geometry in category theoretic terms. The definition I know of is for a manifold $M$, and a point $p \in M$, $\exp: (v \in T_pM) \mapsto \gamma_v(1)$ Where $\gamma$ is the locally unique geodesic though $p$ of velocity $v$ such that $\gamma_v(0) = p$. I may have slightly messed up the definiton. I would be especially interested in definitions in geometrical/topological terms with as few constructions/parametrisations as possible.",,"['differential-geometry', 'category-theory', 'universal-property']"
47,Gradient descent for functionals?,Gradient descent for functionals?,,"If $f:\mathbb{R}^2\longrightarrow\mathbb{R}$ is smooth, then given an initial point $x_0\in\mathbb{R}^2$, we can use gradient descent to find a sequence of points $\{x_i\}_{i=1}^{\infty}$ that converges to a critical point of $f$ (if one exists). I was wondering if there is any equivalent method for functionals? That is, is there any way of generating a sequence of functions $\{g_i\}_{i=1}^{\infty}$ (preferably polynomials?) that converges to the function $g$ that minimises a functional $E[\phi]$? For example, we could take $E[\phi]$ to be the Dirichlet energy of $\phi$: $$ E[\phi] = \int_\Omega{\|\nabla\phi(x)\|^2\,\text{d}V}\,. $$ I have briefly looked at Sobolev gradients but I don't quite understand it. This is slightly different to my specific problem, as the functional I am interested is the vector Dirichlet energy: $$ E[\mathbf{v}] = \int_\Omega\left((\nabla \cdot \mathbf{v})^2 + \|\nabla \times \mathbf{v}\|^2\right)\,\text{d}V\,. $$ with conditions $$ \begin{array}{c}\langle \mathbf{v}, \hat{\mathbf{n}}\rangle=0 \mathrm{\ on\ } \partial \Omega,\\ \int_{\Omega} \|\mathbf{v}\|^2\,dV = 1.\end{array} $$ Edit: The case that I am interested specifically is when $\Omega$ is a torus with a slightly perturbed boundary or an infinite tube twisted helically around the $z$-axis.","If $f:\mathbb{R}^2\longrightarrow\mathbb{R}$ is smooth, then given an initial point $x_0\in\mathbb{R}^2$, we can use gradient descent to find a sequence of points $\{x_i\}_{i=1}^{\infty}$ that converges to a critical point of $f$ (if one exists). I was wondering if there is any equivalent method for functionals? That is, is there any way of generating a sequence of functions $\{g_i\}_{i=1}^{\infty}$ (preferably polynomials?) that converges to the function $g$ that minimises a functional $E[\phi]$? For example, we could take $E[\phi]$ to be the Dirichlet energy of $\phi$: $$ E[\phi] = \int_\Omega{\|\nabla\phi(x)\|^2\,\text{d}V}\,. $$ I have briefly looked at Sobolev gradients but I don't quite understand it. This is slightly different to my specific problem, as the functional I am interested is the vector Dirichlet energy: $$ E[\mathbf{v}] = \int_\Omega\left((\nabla \cdot \mathbf{v})^2 + \|\nabla \times \mathbf{v}\|^2\right)\,\text{d}V\,. $$ with conditions $$ \begin{array}{c}\langle \mathbf{v}, \hat{\mathbf{n}}\rangle=0 \mathrm{\ on\ } \partial \Omega,\\ \int_{\Omega} \|\mathbf{v}\|^2\,dV = 1.\end{array} $$ Edit: The case that I am interested specifically is when $\Omega$ is a torus with a slightly perturbed boundary or an infinite tube twisted helically around the $z$-axis.",,"['differential-geometry', 'partial-differential-equations', 'optimization', 'calculus-of-variations', 'gradient-descent']"
48,Equivalence between two definitions of tangent vectors,Equivalence between two definitions of tangent vectors,,"Let $M$ be an $n-$dimensional smooth manifold. Usually, a tangent vector at $p \in M$ is defined as function $V$ from $C^{\infty}(M) $ to $\mathbb R$ satisfying the following properties(linear derivation): $V(f+g)=V(f) + V(g)$. $V(\alpha f)= \alpha V(F)$. $V(fg) = V(f)g(p) + V(g)f(p)$. However, in Hirsch's differential topology, a tangent vector to $M$ is an equivalence class $[x,i,a]$ of triples $(x,i,a)\in M\times \Lambda \times \mathbb R^n$ where $\lambda$ is the index set for charts $(U_i,\phi_i)$, under the equivalence relation: $$[x,i,a]=[y,j,b]$$ if and only if $x=y$ and  $$D(\phi_j \phi_i^{-1})(\phi_i(x))a=b.$$ How to prove these two definitions are equivalent, if they indeed are?","Let $M$ be an $n-$dimensional smooth manifold. Usually, a tangent vector at $p \in M$ is defined as function $V$ from $C^{\infty}(M) $ to $\mathbb R$ satisfying the following properties(linear derivation): $V(f+g)=V(f) + V(g)$. $V(\alpha f)= \alpha V(F)$. $V(fg) = V(f)g(p) + V(g)f(p)$. However, in Hirsch's differential topology, a tangent vector to $M$ is an equivalence class $[x,i,a]$ of triples $(x,i,a)\in M\times \Lambda \times \mathbb R^n$ where $\lambda$ is the index set for charts $(U_i,\phi_i)$, under the equivalence relation: $$[x,i,a]=[y,j,b]$$ if and only if $x=y$ and  $$D(\phi_j \phi_i^{-1})(\phi_i(x))a=b.$$ How to prove these two definitions are equivalent, if they indeed are?",,"['differential-geometry', 'smooth-manifolds']"
49,Direct image of vector bundle under projection map,Direct image of vector bundle under projection map,,"Let $\pi: Y \to X$ be a smooth projection map between manifolds, and assume the fibres of the map have constant dimension: dim $\left(\pi^{-1}(x)\right)=d ~~ \forall x \in X$ . Given a smooth map between manifolds, one can define the pushforward or direct image $\pi_*V$ of a vector bundle $V$ . Formally one thinks of the vector bundle as a sheaf and then defines the direct image as for a sheaf . My question is how to actually compute the result for common, simple vector bundles. Examples are the trivial vector bundle $\mathcal{O}_Y$ , the tangent $T_Y$ or cotangent bundle $T_Y^*$ , or the canonical $K_Y$ or anti-canonical bundle $K_Y^*$ . I would be interested to know how to work these out using the formal definition of the direct image, or how to cleverly avoid this explicit computation. Even better would be to understand also the answers in the case of the higher direct images $R^p\pi_*V$ .","Let be a smooth projection map between manifolds, and assume the fibres of the map have constant dimension: dim . Given a smooth map between manifolds, one can define the pushforward or direct image of a vector bundle . Formally one thinks of the vector bundle as a sheaf and then defines the direct image as for a sheaf . My question is how to actually compute the result for common, simple vector bundles. Examples are the trivial vector bundle , the tangent or cotangent bundle , or the canonical or anti-canonical bundle . I would be interested to know how to work these out using the formal definition of the direct image, or how to cleverly avoid this explicit computation. Even better would be to understand also the answers in the case of the higher direct images .",\pi: Y \to X \left(\pi^{-1}(x)\right)=d ~~ \forall x \in X \pi_*V V \mathcal{O}_Y T_Y T_Y^* K_Y K_Y^* R^p\pi_*V,"['differential-geometry', 'algebraic-geometry', 'sheaf-theory', 'vector-bundles']"
50,A compact complex manifold admits an ample line bundle if and only if it is projective,A compact complex manifold admits an ample line bundle if and only if it is projective,,"Given a holomorphic line bundle $L$ on a complex manifold $X$, a point $x\in X$ is called a base point of $L$ if $s(x)=0$ for all $s\in H^0(X,L)$ (the space of global holomorphic sections of $L$). The base locus $\operatorname{Bs}(L)$ is the set of all base points of $L$. Given a basis $s_0,\dots,s_N$ of $H^0(X,L)$, one can define a map \begin{equation} \phi_L:X\backslash\operatorname{Bs}(L)\rightarrow \mathbb{CP}^n \end{equation} sending a point $x$ to $[s_0(x):\dots:s_N(x)]$. This is well-defined, since not all $s_i(x)$ are zero (we exclude $\operatorname{Bs}(L)$ in the domain) and since changing trivialisation scales all components $s_i(x)$ by the same amount. I am told that the line bundle $L$ is called very ample if for any such basis, the associated map $\phi_L$ is an embedding. $L$ is called ample if there exists a positive integer $m_0$ such that $L^m$ is very ample for all $m\geq m_0$. In Huybrechts' book Complex Geometry, he says that by definition, a compact complex manifold is projective (i.e. embeds as a complex submanifold of $\mathbb{CP}^n$) if and only if it admits an ample line bundle. But I do not understand how this follows? Do we not only get an embedding of $X\backslash \operatorname{Bs}(L)$ into $\mathbb{CP}^n$, rather than the whole of $X$? I would agree with this statement if $L$ was also assumed to be globally generated , i.e. satisfies $\operatorname{Bs}(L)=\emptyset$, but this is not assumed. Any help would be much appreciated!","Given a holomorphic line bundle $L$ on a complex manifold $X$, a point $x\in X$ is called a base point of $L$ if $s(x)=0$ for all $s\in H^0(X,L)$ (the space of global holomorphic sections of $L$). The base locus $\operatorname{Bs}(L)$ is the set of all base points of $L$. Given a basis $s_0,\dots,s_N$ of $H^0(X,L)$, one can define a map \begin{equation} \phi_L:X\backslash\operatorname{Bs}(L)\rightarrow \mathbb{CP}^n \end{equation} sending a point $x$ to $[s_0(x):\dots:s_N(x)]$. This is well-defined, since not all $s_i(x)$ are zero (we exclude $\operatorname{Bs}(L)$ in the domain) and since changing trivialisation scales all components $s_i(x)$ by the same amount. I am told that the line bundle $L$ is called very ample if for any such basis, the associated map $\phi_L$ is an embedding. $L$ is called ample if there exists a positive integer $m_0$ such that $L^m$ is very ample for all $m\geq m_0$. In Huybrechts' book Complex Geometry, he says that by definition, a compact complex manifold is projective (i.e. embeds as a complex submanifold of $\mathbb{CP}^n$) if and only if it admits an ample line bundle. But I do not understand how this follows? Do we not only get an embedding of $X\backslash \operatorname{Bs}(L)$ into $\mathbb{CP}^n$, rather than the whole of $X$? I would agree with this statement if $L$ was also assumed to be globally generated , i.e. satisfies $\operatorname{Bs}(L)=\emptyset$, but this is not assumed. Any help would be much appreciated!",,"['differential-geometry', 'algebraic-geometry', 'complex-geometry', 'vector-bundles']"
51,principal curvature in high dimensions,principal curvature in high dimensions,,"The principal curvature of a 2D (m=2) manifold in a 3D (n=3) ambient Euclidean space, is given by the eigenvalues of the second fundamental form (or the Hessian matrix) $\Pi \in \Re^{m \times m}$ at each point of the surface. The principal directions are the corresponding eigenvectors. I'm looking for the generalization of this for higher dimensions of both the manifold and its ambient space (i.e., both $m$ and $n$). According to wikipedia the eigenvectors of the second fundamental form of a hypersurface can give us the principal directions, and therefore the generalization is straight-forward. However, this seems to hold only if $n = m+1$, because otherwise the hypersurface has a normal hyperplane rather than a normal vector , and the second fundamental form will be a 3D array $\Pi \in \Re^{m \times m \times (n-m)}$, rather than a matrix. In this case, what is the generalization of principal (directions of) curvatures, and how do we calculate them?","The principal curvature of a 2D (m=2) manifold in a 3D (n=3) ambient Euclidean space, is given by the eigenvalues of the second fundamental form (or the Hessian matrix) $\Pi \in \Re^{m \times m}$ at each point of the surface. The principal directions are the corresponding eigenvectors. I'm looking for the generalization of this for higher dimensions of both the manifold and its ambient space (i.e., both $m$ and $n$). According to wikipedia the eigenvectors of the second fundamental form of a hypersurface can give us the principal directions, and therefore the generalization is straight-forward. However, this seems to hold only if $n = m+1$, because otherwise the hypersurface has a normal hyperplane rather than a normal vector , and the second fundamental form will be a 3D array $\Pi \in \Re^{m \times m \times (n-m)}$, rather than a matrix. In this case, what is the generalization of principal (directions of) curvatures, and how do we calculate them?",,"['differential-geometry', 'riemannian-geometry', 'curvature', 'tensor-decomposition']"
52,"What is $H_{3}Spin(3)$, and how is this related with the twist of framing on a 3-manifold?","What is , and how is this related with the twist of framing on a 3-manifold?",H_{3}Spin(3),"From the question , Mr Ryan Thorngren said in the answer that the the framing anomaly of the gravitational Chern-Simons action $$I(g)=\frac{1}{4\pi}\int_{M}\mathrm{Tr}(\omega\wedge d\omega+\frac{2}{3}\omega\wedge\omega\wedge\omega)$$ i.e. it changes under a twist of framing on $M$ by $I(g)\rightarrow I(g)+2\pi s$ with $s\in\mathbb{Z}$ , is related with the group $H_{3}Spin(3)=\mathbb{Z}$ . What is this group $H_{3}Spin(3)$ ? Why is it isomorphic to $\mathbb{Z}$ ? How exactly is it related with the change of Pontryagin class under a change of framing on $M$ ? They also talked about $\Omega_{3}^{fr}=\mathbb{Z}_{24}$ . What exactly is this $\Omega_{3}^{fr}$ ? (I also posted my question hoping to receive answers from physicists)","From the question , Mr Ryan Thorngren said in the answer that the the framing anomaly of the gravitational Chern-Simons action i.e. it changes under a twist of framing on by with , is related with the group . What is this group ? Why is it isomorphic to ? How exactly is it related with the change of Pontryagin class under a change of framing on ? They also talked about . What exactly is this ? (I also posted my question hoping to receive answers from physicists)",I(g)=\frac{1}{4\pi}\int_{M}\mathrm{Tr}(\omega\wedge d\omega+\frac{2}{3}\omega\wedge\omega\wedge\omega) M I(g)\rightarrow I(g)+2\pi s s\in\mathbb{Z} H_{3}Spin(3)=\mathbb{Z} H_{3}Spin(3) \mathbb{Z} M \Omega_{3}^{fr}=\mathbb{Z}_{24} \Omega_{3}^{fr},"['differential-geometry', 'mathematical-physics', 'quantum-field-theory', 'topological-quantum-field-theory']"
53,Existence of Commuting Vector Fields in a Nonintegrable Distribution,Existence of Commuting Vector Fields in a Nonintegrable Distribution,,"Let $M$ be a (smooth) manifold. Given tangent vectors $X_q,Y_q \in T_qM$ ($q \in M$), there exist (locally about $q$) vector fields $X,Y \in \Gamma(TM)$ extending $X_q$, $Y_q$ (i.e., $X(q) = X_q$ and $Y(q) = Y_q$), and such that $[X,Y] = 0$. My question is whether this result will extend to the following situation. Suppose that $\mathcal{D}$ is a nonintegrable subbundle of $M$, and $\mathcal{E}$ is a complement to $\mathcal{D}$ (so that $TM = \mathcal{D} \oplus \mathcal{E}$). Let $\pi : TM \to \mathcal{D}$ be the corresponding projection. Given $X_q,Y_q \in \mathcal{D}_q$, do there exist (local) $X,Y \in \Gamma(\mathcal{D})$ extending $X_q$ and $Y_q$ and such that $\pi([X,Y]) = 0$? I can think of two situations when this will be true: $M$ is a Lie group $G$, and $\mathcal{D}$, $\mathcal{E}$ are left invariant. (Take $X$ to be the left -invariant vector field corresponding to $TL^{-1}_q\cdot X_q$, and $Y$ to be the right -invariant vector field corresponding to $TL^{-1}_q\cdot Y_q$, where $L_q$ is left translation; then $X,Y \in \Gamma(\mathcal{D})$ extend $X_q,Y_q$, and $[X,Y] = 0$ since left- and right-invariant vector fields commute; hence $\pi([X,Y]) = 0$.) $\mathcal{E}$ is integrable. (Let $X,Y \in \Gamma(TM)$ be commuting extensions of $X_q$ and $Y_q$; then $\pi(X),\pi(Y) \in \Gamma(\mathcal{D})$ extend $X_q,Y_q$, and $\pi([\pi(X),\pi(Y)]) = 0$, since the $\pi([\mathcal{D},\mathcal{E}])$ and $\pi([\mathcal{E},\mathcal{E}])$ terms vanish.) This seems like a fairly straightforward question, but I haven't had any luck in the general case (either in finding a counterexample, or proving it).","Let $M$ be a (smooth) manifold. Given tangent vectors $X_q,Y_q \in T_qM$ ($q \in M$), there exist (locally about $q$) vector fields $X,Y \in \Gamma(TM)$ extending $X_q$, $Y_q$ (i.e., $X(q) = X_q$ and $Y(q) = Y_q$), and such that $[X,Y] = 0$. My question is whether this result will extend to the following situation. Suppose that $\mathcal{D}$ is a nonintegrable subbundle of $M$, and $\mathcal{E}$ is a complement to $\mathcal{D}$ (so that $TM = \mathcal{D} \oplus \mathcal{E}$). Let $\pi : TM \to \mathcal{D}$ be the corresponding projection. Given $X_q,Y_q \in \mathcal{D}_q$, do there exist (local) $X,Y \in \Gamma(\mathcal{D})$ extending $X_q$ and $Y_q$ and such that $\pi([X,Y]) = 0$? I can think of two situations when this will be true: $M$ is a Lie group $G$, and $\mathcal{D}$, $\mathcal{E}$ are left invariant. (Take $X$ to be the left -invariant vector field corresponding to $TL^{-1}_q\cdot X_q$, and $Y$ to be the right -invariant vector field corresponding to $TL^{-1}_q\cdot Y_q$, where $L_q$ is left translation; then $X,Y \in \Gamma(\mathcal{D})$ extend $X_q,Y_q$, and $[X,Y] = 0$ since left- and right-invariant vector fields commute; hence $\pi([X,Y]) = 0$.) $\mathcal{E}$ is integrable. (Let $X,Y \in \Gamma(TM)$ be commuting extensions of $X_q$ and $Y_q$; then $\pi(X),\pi(Y) \in \Gamma(\mathcal{D})$ extend $X_q,Y_q$, and $\pi([\pi(X),\pi(Y)]) = 0$, since the $\pi([\mathcal{D},\mathcal{E}])$ and $\pi([\mathcal{E},\mathcal{E}])$ terms vanish.) This seems like a fairly straightforward question, but I haven't had any luck in the general case (either in finding a counterexample, or proving it).",,['differential-geometry']
54,A question about holomorphic structure in Atiyah Bott's paper.,A question about holomorphic structure in Atiyah Bott's paper.,,"I am reading Atiyah & Bott's The Yang-Mills equations over Riemann surfaces . I meet a question about the holomorphic structure. Let $E\to M$ be a complex vector bundle over a compact Riemann surface. There is a Hermitian metric on $E$. Then  \begin{equation} 	\mathscr A\cong\mathscr B \end{equation} for  \begin{equation} 	\begin{split} 		\mathscr A=&\{\text{all smooth hermitian connections}\}\\ 		\mathscr B=&\{\text{all holomorphic structures on }E\} 	\end{split} \end{equation} The identification is described as: given a connection in $\mathscr A$ \begin{equation} 	d_A\colon\Omega^0(M;E)\to\Omega^1(M;E) \end{equation} then complexify it  \begin{equation} 	d_A\colon\Omega^0_{\mathbb C}(M;E)\to\Omega^1_{\mathbb C}(M;E) \end{equation} and we have  \begin{equation} 	\Omega^1_{\mathbb C}(M;E)=\Omega^{1,0}(M;E)\oplus\Omega^{0,1}(M;E) \end{equation} Then  \begin{equation} 	d_A=d_A'\oplus d_A'' \end{equation} for  \begin{equation} 	\begin{split} 		d_A'\colon & \Omega^0_{\mathbb C}(M;E)\to\Omega^{1,0}(M;E)\\ 		d_A''\colon & \Omega^0_{\mathbb C}(M;E)\to\Omega^{0,1}(M;E) 	\end{split} \end{equation} and the operator $d_A''$ determines a holomorphic structure of $E$. Questions: The decomposition $\Omega^1_{\mathbb C}(M;E)=\Omega^{1,0}(M;E)\oplus\Omega^{0,1}(M;E)$ is due to a Hodge star operator. Is there a canonical Hodge star operator here? I know there is another decomposition using the canonical almost complex structure $J$, and I do not understand why not use this. How to recover $d_A$ from $d_A''$? I guess here we need the Hermitian metric. Thanks in advance.","I am reading Atiyah & Bott's The Yang-Mills equations over Riemann surfaces . I meet a question about the holomorphic structure. Let $E\to M$ be a complex vector bundle over a compact Riemann surface. There is a Hermitian metric on $E$. Then  \begin{equation} 	\mathscr A\cong\mathscr B \end{equation} for  \begin{equation} 	\begin{split} 		\mathscr A=&\{\text{all smooth hermitian connections}\}\\ 		\mathscr B=&\{\text{all holomorphic structures on }E\} 	\end{split} \end{equation} The identification is described as: given a connection in $\mathscr A$ \begin{equation} 	d_A\colon\Omega^0(M;E)\to\Omega^1(M;E) \end{equation} then complexify it  \begin{equation} 	d_A\colon\Omega^0_{\mathbb C}(M;E)\to\Omega^1_{\mathbb C}(M;E) \end{equation} and we have  \begin{equation} 	\Omega^1_{\mathbb C}(M;E)=\Omega^{1,0}(M;E)\oplus\Omega^{0,1}(M;E) \end{equation} Then  \begin{equation} 	d_A=d_A'\oplus d_A'' \end{equation} for  \begin{equation} 	\begin{split} 		d_A'\colon & \Omega^0_{\mathbb C}(M;E)\to\Omega^{1,0}(M;E)\\ 		d_A''\colon & \Omega^0_{\mathbb C}(M;E)\to\Omega^{0,1}(M;E) 	\end{split} \end{equation} and the operator $d_A''$ determines a holomorphic structure of $E$. Questions: The decomposition $\Omega^1_{\mathbb C}(M;E)=\Omega^{1,0}(M;E)\oplus\Omega^{0,1}(M;E)$ is due to a Hodge star operator. Is there a canonical Hodge star operator here? I know there is another decomposition using the canonical almost complex structure $J$, and I do not understand why not use this. How to recover $d_A$ from $d_A''$? I guess here we need the Hermitian metric. Thanks in advance.",,"['differential-geometry', 'connections']"
55,Learning Differentiable Manifolds prior to Classical Differential Geometry,Learning Differentiable Manifolds prior to Classical Differential Geometry,,"Is it possible to study Differentiable Manifolds from Lee's ""Introduction to smooth manifolds"" before studying classical differential geometry from DoCarmo's text or Kristopher Tapp's ""Differential Geometry of Curves and Surfaces"". Right now I'm hearing two sides, with one saying that Differentiable Manifolds doesn't really tie in with Classical Differential Geometry and the other opposing side states that its necessary to understand Classical Differential Geometry to supposedly help with intuition. In this case I'm wondering what side is right in terms of what course of action to take. Study Differentiable Manifolds first then go back to studying classical differential geometry or start in the other direction? I currently understand Topology, Abstract Algebra, Real Analysis, Linear Algebra.","Is it possible to study Differentiable Manifolds from Lee's ""Introduction to smooth manifolds"" before studying classical differential geometry from DoCarmo's text or Kristopher Tapp's ""Differential Geometry of Curves and Surfaces"". Right now I'm hearing two sides, with one saying that Differentiable Manifolds doesn't really tie in with Classical Differential Geometry and the other opposing side states that its necessary to understand Classical Differential Geometry to supposedly help with intuition. In this case I'm wondering what side is right in terms of what course of action to take. Study Differentiable Manifolds first then go back to studying classical differential geometry or start in the other direction? I currently understand Topology, Abstract Algebra, Real Analysis, Linear Algebra.",,"['differential-geometry', 'smooth-manifolds']"
56,When is the index of minimal submanifold finite?,When is the index of minimal submanifold finite?,,"Let $(M^n,g)$ be a Riemannian manifold and $f:\Sigma^k\to M^n$ a minimal submanifold. The Morse index of $\Sigma$ is the number of negative eigenvalues of the stability operator $L:\Gamma(N\Sigma)\to \Gamma(N\Sigma)$ acting on (smooth) sections of the normal bundle $N\Sigma$ of $\Sigma$ in $M$. The Morse index of $\Sigma$ need not be finite in general, however, under certain conditions it is. For example: the classical Morse index theorem says that if $\gamma:[0,1]\to (M^n,g)$ is a geodesic, then the Morse index of $\gamma$ is finite and equal to the number of points on $\gamma$ which are conjugate to $\gamma(0)$ (counted with multiplicity). Another example: a complete oriented minimal surface in $(\mathbb{R}^n,\delta)$ with finite total curvature has finite morse index . Question: Suppose $\Sigma^{n-1}\subset (M^n,g)$ is a closed (compact without boundary) minimal hypersurface. Is the Morse index of $\Sigma$ finite? If this is not true in general, which extra assumptions are sufficient to ensure the Morse index is finite?","Let $(M^n,g)$ be a Riemannian manifold and $f:\Sigma^k\to M^n$ a minimal submanifold. The Morse index of $\Sigma$ is the number of negative eigenvalues of the stability operator $L:\Gamma(N\Sigma)\to \Gamma(N\Sigma)$ acting on (smooth) sections of the normal bundle $N\Sigma$ of $\Sigma$ in $M$. The Morse index of $\Sigma$ need not be finite in general, however, under certain conditions it is. For example: the classical Morse index theorem says that if $\gamma:[0,1]\to (M^n,g)$ is a geodesic, then the Morse index of $\gamma$ is finite and equal to the number of points on $\gamma$ which are conjugate to $\gamma(0)$ (counted with multiplicity). Another example: a complete oriented minimal surface in $(\mathbb{R}^n,\delta)$ with finite total curvature has finite morse index . Question: Suppose $\Sigma^{n-1}\subset (M^n,g)$ is a closed (compact without boundary) minimal hypersurface. Is the Morse index of $\Sigma$ finite? If this is not true in general, which extra assumptions are sufficient to ensure the Morse index is finite?",,"['differential-geometry', 'partial-differential-equations', 'calculus-of-variations', 'minimal-surfaces']"
57,Dependence of spinor bundle on choice of metric,Dependence of spinor bundle on choice of metric,,"For an oriented Riemannian manifold $(M^n,g)$ with spin structure, one can define the spinor bundle $\pi_g:\mathbf{S}_g\to M$. The space of metrics is convex. So if $g_t=(1-t)g_0+tg_1$ is a family of metrics, I think all spinor bundles $\pi_{g_t}:\mathbf{S}_{g_t}\to M$ are isomorphic as smooth vector bundles over $M$. So what exactly is the dependence of the spinor bundle on the choice of metric?","For an oriented Riemannian manifold $(M^n,g)$ with spin structure, one can define the spinor bundle $\pi_g:\mathbf{S}_g\to M$. The space of metrics is convex. So if $g_t=(1-t)g_0+tg_1$ is a family of metrics, I think all spinor bundles $\pi_{g_t}:\mathbf{S}_{g_t}\to M$ are isomorphic as smooth vector bundles over $M$. So what exactly is the dependence of the spinor bundle on the choice of metric?",,"['differential-geometry', 'spin-geometry']"
58,Degrees of freedom of a metric up to coordinate changes (precise formulation),Degrees of freedom of a metric up to coordinate changes (precise formulation),,"Let $M$ be a smooth $n$-dimensional manifold. I have heard that a Riemannian metric on $M$, depends locally on $ n(n+1) / 2 - n = n(n-1) /2$ ""independent"" functions up to coordinate changes . I can roughly see the intuition for that: The symmetric matrix $g_{ij} $ depends on $n(n+1) / 2$ functions, but you can ""change the coordinates"" which loses $n$ degrees of freedom. Is there a precise formulation of this statement? Given an arbitrary metric, can you  really specify $n$ out of the $ n(n+1)/2$ $g_{ij}$ functions as you wish? How can we see it's impossible specify more than $n$? I heard that Cartan proved something like this, using the language of jets.  (Something about the dimension of the space of $k$-jets of metrics modulu diffeomorphisms). Maybe there are other references; any pointer in the right direction is welcomed. This question was supposedly answered here , but I find the answer there to be too vague. I am looking for a precise statement.","Let $M$ be a smooth $n$-dimensional manifold. I have heard that a Riemannian metric on $M$, depends locally on $ n(n+1) / 2 - n = n(n-1) /2$ ""independent"" functions up to coordinate changes . I can roughly see the intuition for that: The symmetric matrix $g_{ij} $ depends on $n(n+1) / 2$ functions, but you can ""change the coordinates"" which loses $n$ degrees of freedom. Is there a precise formulation of this statement? Given an arbitrary metric, can you  really specify $n$ out of the $ n(n+1)/2$ $g_{ij}$ functions as you wish? How can we see it's impossible specify more than $n$? I heard that Cartan proved something like this, using the language of jets.  (Something about the dimension of the space of $k$-jets of metrics modulu diffeomorphisms). Maybe there are other references; any pointer in the right direction is welcomed. This question was supposedly answered here , but I find the answer there to be too vague. I am looking for a precise statement.",,"['differential-geometry', 'reference-request', 'differential-topology', 'riemannian-geometry', 'jet-bundles']"
59,Constant sectional curvature and unit normal vector to a totally geodesic hypersurface,Constant sectional curvature and unit normal vector to a totally geodesic hypersurface,,"I was reading about totally geodesic hypersurfaces when I found the next proposition: Proposition: The sectional curvature $K$ of $M$ is constant at $p$ if and only if every unit vector in $T_{p}M$ is normal to a totally geodesic hypersurface at $p$ . The proof is following by Codazzi equation. I'm stuck proving this. If $K$ is constant, we get from Codazzi equation that $R_{xy}x=K(\langle x,x\rangle y-\langle x,y\rangle x).$ Then,for nonnull $x\perp y$ such equation becomes $R_{xy}x=\langle x,x\rangle K(x,y) y.$ But I don't get how this works to prove that each unit vector on $T_{p}M$ is normal to a totally geodesic hypersurface. I know that a semi-Riemann submanifold is totally geodesic if the shape tensor vanishes: $\mathrm{II}=0$ but I can't see how this works with the above to get the desire result. For the other direction I'm not sure how to proceed to get that $K$ is constant. Any kind of help is thanked in advanced.","I was reading about totally geodesic hypersurfaces when I found the next proposition: Proposition: The sectional curvature of is constant at if and only if every unit vector in is normal to a totally geodesic hypersurface at . The proof is following by Codazzi equation. I'm stuck proving this. If is constant, we get from Codazzi equation that Then,for nonnull such equation becomes But I don't get how this works to prove that each unit vector on is normal to a totally geodesic hypersurface. I know that a semi-Riemann submanifold is totally geodesic if the shape tensor vanishes: but I can't see how this works with the above to get the desire result. For the other direction I'm not sure how to proceed to get that is constant. Any kind of help is thanked in advanced.","K M p T_{p}M p K R_{xy}x=K(\langle x,x\rangle y-\langle x,y\rangle x). x\perp y R_{xy}x=\langle x,x\rangle K(x,y) y. T_{p}M \mathrm{II}=0 K","['differential-geometry', 'riemannian-geometry', 'semi-riemannian-geometry']"
60,Vector Laplacian on Manifolds,Vector Laplacian on Manifolds,,"I'm trying to understand some basics of calculus on a surface (i.e. a 2-manifold in $\mathbb{R}^3$ ), without having much knowledge in differential geometry (so from an engineer's perspective). I am not able to get much about how the vector Laplacian on surfaces is defined. There was a similar question here , but the answer there seems to be above my pay grade. Let's say we have a (sufficiently smooth) surface $S \subset \mathbb{R}^3$ , and (sufficiently smooth) functions $u: S \rightarrow \mathbb{R}$ , $\vec{v}: S \rightarrow \mathbb{R}^3$ . Then, from a lay-man's perspective, for the projection operator(which removes the normal component) $P = \mathbf{I} - \mathbf{n}\mathbf{n}^T$ , the surface derivatives can be defined as \begin{align} \nabla_S u &= P\nabla u = \text{(say) } \left( \begin{array}{c} D_1u \\ D_2 u \\ D_3 u \\ \end{array}\right) \\ \nabla_S \cdot \vec{v} &= P\nabla \cdot \vec{v} = D_1v_1 + D_2v_2 + D_3v_3\\ \Delta_S u &= \nabla_S \cdot \nabla_S u = D_1D_1u + D_2D_2u + D_3 D_3u \end{align} There seem to be multiple definitions for the Laplacian of a vector field Wiki Page . Two specific ones are what I am trying to understand. The Bochner Laplaican, and the Hodge Laplacian (since those are the ones used in the context I need). There is also a third one here (starting after equation 1.1, till equation 1.3) that has me a bit confused. Can any of them be understood in a way similar to the surface gradient/surface divergence/Laplace beltrami of a scalar field written above? Is any of them simply a component wise Laplace-Beltrami operator? \begin{equation} \left( \begin{array}{c}  \Delta_S v_1 \\ \Delta_S v_2 \\ \Delta_S v_3 \\ \end{array}\right)? \end{equation} Another way to look at this is to ask if we can define a Vector Laplacian on a 2-manifold in 3-space without going in to the differential geometry formalism. i.e. using cartesian coordinates only.","I'm trying to understand some basics of calculus on a surface (i.e. a 2-manifold in ), without having much knowledge in differential geometry (so from an engineer's perspective). I am not able to get much about how the vector Laplacian on surfaces is defined. There was a similar question here , but the answer there seems to be above my pay grade. Let's say we have a (sufficiently smooth) surface , and (sufficiently smooth) functions , . Then, from a lay-man's perspective, for the projection operator(which removes the normal component) , the surface derivatives can be defined as There seem to be multiple definitions for the Laplacian of a vector field Wiki Page . Two specific ones are what I am trying to understand. The Bochner Laplaican, and the Hodge Laplacian (since those are the ones used in the context I need). There is also a third one here (starting after equation 1.1, till equation 1.3) that has me a bit confused. Can any of them be understood in a way similar to the surface gradient/surface divergence/Laplace beltrami of a scalar field written above? Is any of them simply a component wise Laplace-Beltrami operator? Another way to look at this is to ask if we can define a Vector Laplacian on a 2-manifold in 3-space without going in to the differential geometry formalism. i.e. using cartesian coordinates only.","\mathbb{R}^3 S \subset \mathbb{R}^3 u: S \rightarrow \mathbb{R} \vec{v}: S \rightarrow \mathbb{R}^3 P = \mathbf{I} - \mathbf{n}\mathbf{n}^T \begin{align}
\nabla_S u &= P\nabla u = \text{(say) } \left( \begin{array}{c} D_1u \\ D_2 u \\ D_3 u \\ \end{array}\right) \\
\nabla_S \cdot \vec{v} &= P\nabla \cdot \vec{v} = D_1v_1 + D_2v_2 + D_3v_3\\
\Delta_S u &= \nabla_S \cdot \nabla_S u = D_1D_1u + D_2D_2u + D_3 D_3u
\end{align} \begin{equation}
\left( \begin{array}{c} 
\Delta_S v_1 \\ \Delta_S v_2 \\ \Delta_S v_3 \\ \end{array}\right)?
\end{equation}","['calculus', 'differential-geometry', 'manifolds', 'differential-topology', 'surfaces']"
61,Is there a formula for how the Hodge star interacts with the wedge product?,Is there a formula for how the Hodge star interacts with the wedge product?,,"Let $V$ be a real vector space of dimension $n$ with an inner product $g$. Let $e_1,\ldots,e_n\in V$ be an orthonormal basis with respect to $g$. On the $k$th exterior power $\bigwedge^k V$ the induced inner product is characterized by the property that the wedges $e_{i_1}\wedge\cdots\wedge e_{i_k}$ give an orthonormal basis for the induced inner product, where $i_1 < i_2 < \cdots < i_k$. In particular, the top wedge power $\bigwedge^n V\cong\mathbb{R}$ is generated by the norm 1 vector $\omega := e_1\wedge\cdots\wedge e_n$. Let $\beta\in\bigwedge^k V$ be a $k$-form. The Hodge dual (or Hodge star) of $\beta$ is by definition the $(n-k)$-form $*\beta$ satisfying: $$\alpha\wedge(*\beta) = g(\alpha,\beta)\cdot\omega$$ for all $k$-forms $\alpha\in \bigwedge^k V$. I'd like to know if there is a ""formula"" for $*(\alpha\wedge\beta)$ in terms of $\alpha,\beta,*\alpha,*\beta$ where $\alpha,\beta$ are forms of degrees $k,\ell$ respectively, with $k+\ell < n$.","Let $V$ be a real vector space of dimension $n$ with an inner product $g$. Let $e_1,\ldots,e_n\in V$ be an orthonormal basis with respect to $g$. On the $k$th exterior power $\bigwedge^k V$ the induced inner product is characterized by the property that the wedges $e_{i_1}\wedge\cdots\wedge e_{i_k}$ give an orthonormal basis for the induced inner product, where $i_1 < i_2 < \cdots < i_k$. In particular, the top wedge power $\bigwedge^n V\cong\mathbb{R}$ is generated by the norm 1 vector $\omega := e_1\wedge\cdots\wedge e_n$. Let $\beta\in\bigwedge^k V$ be a $k$-form. The Hodge dual (or Hodge star) of $\beta$ is by definition the $(n-k)$-form $*\beta$ satisfying: $$\alpha\wedge(*\beta) = g(\alpha,\beta)\cdot\omega$$ for all $k$-forms $\alpha\in \bigwedge^k V$. I'd like to know if there is a ""formula"" for $*(\alpha\wedge\beta)$ in terms of $\alpha,\beta,*\alpha,*\beta$ where $\alpha,\beta$ are forms of degrees $k,\ell$ respectively, with $k+\ell < n$.",,"['linear-algebra', 'differential-geometry']"
62,Consider homotopy of closed curves. Show equality of winding numbers.,Consider homotopy of closed curves. Show equality of winding numbers.,,"a) Let  $H: [0,K] \times [0,1] \rightarrow \mathbb{R}^2 $ be a homotopy of closed curves, so $H$ is continuous and for every $\sigma \in [0,1]$  it holds that  $ c_{\sigma}:[0,K] \rightarrow \mathbb{R}^2$, $c_{\sigma}(t) := c(t,\sigma) $ is a $C^0$-closed curve. Consider $ p \in \mathbb{R}^2$ with $p \notin H([0,K] \times [0,1]) $. Show: $$ W_{c_0}(p) = W_{c_1}(p) $$ (winding number around $p$) b) Consider now a $C^0$-closed curve  $s : [0,K] \rightarrow \mathbb{R}^2$. Let $p,q \in \mathbb{R}^2$ be in the same connected component of $\mathbb{R}^2$\ $s([0,K])$ Show: $$ W_s(p) = W_s(q) $$ Attempt: So for a) :First I tried to use the definition of the winding number around a point. $W_{c_o}(p)$:= $\frac{1}{2\pi}$ $( \Theta(K) - \Theta(0))$, where $\Theta$ is the angle function of $\frac{ c_o - p}{||c_o -p||}$, but I failed. So I've started to consider $H$. We know that $H$ is continuous and $[0,K] \times [0,1] $ is compact. So $H$ is uniformly continuous, which means that for $\varepsilon = 1$ there is a $\delta > 0$ such that $| H_{s1}(t) - H_{s2}(t) | < 1$ $\forall t \in [0,K]$ and $|s_1 - s_2 | < \delta $, where $s_1, s_2 \in [0,1]$. This implies (""hopefully"") that $| \frac{H_{s1}(t)}{H_{s2}(t)} - 1 | < \frac{1}{|H_{s2}(t)|}$. Like you see I'm really lost in this exercise. I really need help here. b) For this part I have only an little idea. So I think that we somehow can use a) for this. We could try to get the claim of a) to solve b) , but to be honest I don't know how the "" transform"" b) to a).","a) Let  $H: [0,K] \times [0,1] \rightarrow \mathbb{R}^2 $ be a homotopy of closed curves, so $H$ is continuous and for every $\sigma \in [0,1]$  it holds that  $ c_{\sigma}:[0,K] \rightarrow \mathbb{R}^2$, $c_{\sigma}(t) := c(t,\sigma) $ is a $C^0$-closed curve. Consider $ p \in \mathbb{R}^2$ with $p \notin H([0,K] \times [0,1]) $. Show: $$ W_{c_0}(p) = W_{c_1}(p) $$ (winding number around $p$) b) Consider now a $C^0$-closed curve  $s : [0,K] \rightarrow \mathbb{R}^2$. Let $p,q \in \mathbb{R}^2$ be in the same connected component of $\mathbb{R}^2$\ $s([0,K])$ Show: $$ W_s(p) = W_s(q) $$ Attempt: So for a) :First I tried to use the definition of the winding number around a point. $W_{c_o}(p)$:= $\frac{1}{2\pi}$ $( \Theta(K) - \Theta(0))$, where $\Theta$ is the angle function of $\frac{ c_o - p}{||c_o -p||}$, but I failed. So I've started to consider $H$. We know that $H$ is continuous and $[0,K] \times [0,1] $ is compact. So $H$ is uniformly continuous, which means that for $\varepsilon = 1$ there is a $\delta > 0$ such that $| H_{s1}(t) - H_{s2}(t) | < 1$ $\forall t \in [0,K]$ and $|s_1 - s_2 | < \delta $, where $s_1, s_2 \in [0,1]$. This implies (""hopefully"") that $| \frac{H_{s1}(t)}{H_{s2}(t)} - 1 | < \frac{1}{|H_{s2}(t)|}$. Like you see I'm really lost in this exercise. I really need help here. b) For this part I have only an little idea. So I think that we somehow can use a) for this. We could try to get the claim of a) to solve b) , but to be honest I don't know how the "" transform"" b) to a).",,"['differential-geometry', 'homotopy-theory', 'curves', 'winding-number']"
63,de Rham isomorphism,de Rham isomorphism,,"Let $X$ be an open manifold, with one end $N$, Q How to show that $H^1_{c,dR}(X)\to H^1_{dR}(X)$ is an injective,? here $H^1_{dR}$ denotes the de Rham cohomology and $H^1_{c,dR}$ denotes the compactly supported de Rham cohomology. Suppose that $H^1(N;\mathbb R)=0$. Q How to show that $H^1_{c,dR}(X)\cong H^1_{dR}(X)$?","Let $X$ be an open manifold, with one end $N$, Q How to show that $H^1_{c,dR}(X)\to H^1_{dR}(X)$ is an injective,? here $H^1_{dR}$ denotes the de Rham cohomology and $H^1_{c,dR}$ denotes the compactly supported de Rham cohomology. Suppose that $H^1(N;\mathbb R)=0$. Q How to show that $H^1_{c,dR}(X)\cong H^1_{dR}(X)$?",,"['differential-geometry', 'de-rham-cohomology']"
64,Space of principal connections is affine modelled on $\Lambda^1(M;\mathfrak{g})$?,Space of principal connections is affine modelled on ?,\Lambda^1(M;\mathfrak{g}),"I'm working within the jet-formulation espoused by Saunders in ""The Geometry of Jet Bundles"" and am struggling to prove the stated result. I would like to stay in this context and understand the result in the following terms. The context is this. Given a principal $G$-bundle $\pi:P\rightarrow M$ over a manifold $M$ for some Lie group $G$, the first jet prolongation of $\pi$ is the manifold $J^1P$, whose points are equivalence classes $j^1_ps$ of local sections $s$ defined in some neighbourhood $U$ of $p$. Two local sections $s$, $t$ at $p$ are equivalent if both conditions $$s(p)=t(p),\qquad \frac{\partial s^a}{\partial x^i}=\frac{\partial t^a}{\partial x^i}$$ hold for some fibred cordinates $(x^i,u^a)$ at $s(p)$. The first jet manifold fibres over $P$, with the projection $\pi_{1,0}:J^1P\rightarrow P$, $j^1_ps\mapsto s(p)$. The right $G$-action on $P$ extends to one on $J^1P$, given explicitly by $(j^1ps)\cdot g=j^1_p(s\cdot g)$, and defined thus the map $\pi_{1,0}$ is $G$-equivariant. There is a contact map $\lambda:J^1P\rightarrow Hom(\pi^*TM,TP)$ as well as a complementary map $\theta:J^1P\rightarrow Hom(TP,VP)$. These are bundle maps over $P$. They are embeddings and enjoy certain equivariance properties with respect to the $G$-actions on all spaces. Explicitly they are defined by $$\lambda(j^1_ps)=T_ps,\qquad \theta(j^1_ps)=1-T_ps\circ T_{s(p)}\pi.$$ In this context a connection on $\pi$ is a section of $\pi_{1,0}$, given by a map $\omega:P\rightarrow J^1P$. A connection $\omega$ is said to be principal if it is equivariant with respect to the right $G$-action. The standard result is that the ""difference"" of two connections descends to give a well-defined 1-form on $M$ with values in the Lie algebra $\mathfrak{g}$. This statement should be understood in terms of (one of) the embeddings $\lambda$, $\theta$. However I cannot prove it. My attempt below yields an $ad_g$-dependence on my choice of lifting vector fields of which I cannot rid myself. I proceed as follows. I assume given two principal connections $\omega_1,\omega_2:P\rightarrow J^1P$. At an arbitrary point $p_0\in M$ I choose a local section $s$ defined in some neighbourhood $U$ of $p_0$ and define a $\mathfrak{g}$-valued 1-form $A^s_U$ on $U$ by setting $$A^s_U(X)(p)=T_{s(p)}\hat s\circ(\theta\circ\omega_2(s(p))-\theta\circ\omega_1(s(p)))\circ T_ps(X_p)$$ where $X\in\mathcal{X}(U)$ is a vector field on $U$ and $p\in U$. Here $\hat s:P|_U\rightarrow G$ is the local trivialisation of $P$ determined by $s$. That is, for $e\in P|_U$, it is defined by $e=s(\pi(p))\cdot \hat s(e)$. The tangent map $T_ps$ lifts $X$ to $TP$. Then each $\theta(\omega_i(s(p))\in Hom(T_{s(p)}P,V_{s(p)}P)$ sends it to the vertical subspace. Finally $\hat s(s(p))=1_G$, so the tangent map $T_{s(p)}\hat s$ takes values in $T_1G\cong\mathfrak{g}$. I need to show that the choice of local section $s$ is of no consequence, so that $A_U^s=A_U$. This will then allow for the various $A_U$'s to be patched together as $U$ ranges over an open cover of $M$. My difficulty is that if I choose a different section $t:U\rightarrow P|_U$ (defined without loss of generality on the same neighbourhood of $p_0$) then over $U$ it is related to $s$ by $t(p)=s(p)\cdot f(p)$, for some map $f:U\rightarrow G$, and I get $$A^t_U=ad_{f(p)^{-1}}\circ A^s_U$$ where $ad_{f(p)^{-1}}:\mathfrak{g}\rightarrow \mathfrak{g}$ is the adjoint action of $G$ on its Lie algebra. I can't rid myself of this conjugation. Where am I going wrong?","I'm working within the jet-formulation espoused by Saunders in ""The Geometry of Jet Bundles"" and am struggling to prove the stated result. I would like to stay in this context and understand the result in the following terms. The context is this. Given a principal $G$-bundle $\pi:P\rightarrow M$ over a manifold $M$ for some Lie group $G$, the first jet prolongation of $\pi$ is the manifold $J^1P$, whose points are equivalence classes $j^1_ps$ of local sections $s$ defined in some neighbourhood $U$ of $p$. Two local sections $s$, $t$ at $p$ are equivalent if both conditions $$s(p)=t(p),\qquad \frac{\partial s^a}{\partial x^i}=\frac{\partial t^a}{\partial x^i}$$ hold for some fibred cordinates $(x^i,u^a)$ at $s(p)$. The first jet manifold fibres over $P$, with the projection $\pi_{1,0}:J^1P\rightarrow P$, $j^1_ps\mapsto s(p)$. The right $G$-action on $P$ extends to one on $J^1P$, given explicitly by $(j^1ps)\cdot g=j^1_p(s\cdot g)$, and defined thus the map $\pi_{1,0}$ is $G$-equivariant. There is a contact map $\lambda:J^1P\rightarrow Hom(\pi^*TM,TP)$ as well as a complementary map $\theta:J^1P\rightarrow Hom(TP,VP)$. These are bundle maps over $P$. They are embeddings and enjoy certain equivariance properties with respect to the $G$-actions on all spaces. Explicitly they are defined by $$\lambda(j^1_ps)=T_ps,\qquad \theta(j^1_ps)=1-T_ps\circ T_{s(p)}\pi.$$ In this context a connection on $\pi$ is a section of $\pi_{1,0}$, given by a map $\omega:P\rightarrow J^1P$. A connection $\omega$ is said to be principal if it is equivariant with respect to the right $G$-action. The standard result is that the ""difference"" of two connections descends to give a well-defined 1-form on $M$ with values in the Lie algebra $\mathfrak{g}$. This statement should be understood in terms of (one of) the embeddings $\lambda$, $\theta$. However I cannot prove it. My attempt below yields an $ad_g$-dependence on my choice of lifting vector fields of which I cannot rid myself. I proceed as follows. I assume given two principal connections $\omega_1,\omega_2:P\rightarrow J^1P$. At an arbitrary point $p_0\in M$ I choose a local section $s$ defined in some neighbourhood $U$ of $p_0$ and define a $\mathfrak{g}$-valued 1-form $A^s_U$ on $U$ by setting $$A^s_U(X)(p)=T_{s(p)}\hat s\circ(\theta\circ\omega_2(s(p))-\theta\circ\omega_1(s(p)))\circ T_ps(X_p)$$ where $X\in\mathcal{X}(U)$ is a vector field on $U$ and $p\in U$. Here $\hat s:P|_U\rightarrow G$ is the local trivialisation of $P$ determined by $s$. That is, for $e\in P|_U$, it is defined by $e=s(\pi(p))\cdot \hat s(e)$. The tangent map $T_ps$ lifts $X$ to $TP$. Then each $\theta(\omega_i(s(p))\in Hom(T_{s(p)}P,V_{s(p)}P)$ sends it to the vertical subspace. Finally $\hat s(s(p))=1_G$, so the tangent map $T_{s(p)}\hat s$ takes values in $T_1G\cong\mathfrak{g}$. I need to show that the choice of local section $s$ is of no consequence, so that $A_U^s=A_U$. This will then allow for the various $A_U$'s to be patched together as $U$ ranges over an open cover of $M$. My difficulty is that if I choose a different section $t:U\rightarrow P|_U$ (defined without loss of generality on the same neighbourhood of $p_0$) then over $U$ it is related to $s$ by $t(p)=s(p)\cdot f(p)$, for some map $f:U\rightarrow G$, and I get $$A^t_U=ad_{f(p)^{-1}}\circ A^s_U$$ where $ad_{f(p)^{-1}}:\mathfrak{g}\rightarrow \mathfrak{g}$ is the adjoint action of $G$ on its Lie algebra. I can't rid myself of this conjugation. Where am I going wrong?",,"['differential-geometry', 'manifolds', 'connections', 'principal-bundles', 'jet-bundles']"
65,Showing that a regular curve is a pregeodesic,Showing that a regular curve is a pregeodesic,,"I'm trying to prove the next: To show that a regular curve $\alpha$ with $\alpha^{'}$ and $\alpha^{''}$ collinear is a pregeodesic, write $\alpha^{''}(s)=f(s)\alpha^{'}(s)$ and prove that a) $\beta=\alpha\circ h$ is a geodesic if and only if $h''+ (f\circ h) (h')^2 = 0$. b) If  $\langle \alpha',\alpha'\rangle $ is never zero, then any constant speed reparametrization of $\alpha$ is a geodesic. Suposse $\beta$ has unit speed, so $\langle \beta''(s), \beta'(s)\rangle = 0$ for all $s.$ From here $h'(s) ( h''(s) + f( h(s)) (h'(s))^2) \langle \alpha'(s),\alpha'(s)\rangle = 0,$ because $\beta^{''}$ is as a) and $\beta^{'}=(\alpha^{'}\circ h)h^{'}.$ c)$\langle \alpha',\alpha'\rangle$ is always zero or never zero. To see this,  $\langle \alpha'(s),\alpha'(s)\rangle' = 2f(s)\langle \alpha'(s),\alpha'(s)\rangle$, then $\langle \alpha'(s),\alpha'(s)\rangle = Ce^{2\int f(s)\,{\rm d}s}$ for some integration constant $C.$ d) If $\langle \alpha',\alpha'\rangle$ is always zero, then $\alpha$ is pre-geodesic. I've proved a), b) and c). Such points follow by some computations with $\beta^{'}$ and $\beta^{''},$ the hypotesis that $\alpha$ is regular and the first at the proposition: $\alpha^{''}(s)=f(s)\alpha^{'}(s).$ My first doubt is: How is possible write  $\alpha^{''}(s)=f(s)\alpha^{'}(s)?$ I don't get how to prove this. It is part of the hypotesis? Also I'm stuck prove d). Second: Why the proof of the behind ensures $\alpha$ is pregeodesic? I think the next result ensures that, if the previous holds, then $\alpha$ is pregeodesic: Let $\gamma:I\rightarrow M$ be a nonconstant geodesic. A reparametrization $\gamma\circ h:J\rightarrow M$ is a geodesic if and only if $h$ has the form $h(t)=at+b.$ If a curve has a reparametrization as a geodesic we call it pregeodesic. Any kind of help is thanked in advanced.","I'm trying to prove the next: To show that a regular curve $\alpha$ with $\alpha^{'}$ and $\alpha^{''}$ collinear is a pregeodesic, write $\alpha^{''}(s)=f(s)\alpha^{'}(s)$ and prove that a) $\beta=\alpha\circ h$ is a geodesic if and only if $h''+ (f\circ h) (h')^2 = 0$. b) If  $\langle \alpha',\alpha'\rangle $ is never zero, then any constant speed reparametrization of $\alpha$ is a geodesic. Suposse $\beta$ has unit speed, so $\langle \beta''(s), \beta'(s)\rangle = 0$ for all $s.$ From here $h'(s) ( h''(s) + f( h(s)) (h'(s))^2) \langle \alpha'(s),\alpha'(s)\rangle = 0,$ because $\beta^{''}$ is as a) and $\beta^{'}=(\alpha^{'}\circ h)h^{'}.$ c)$\langle \alpha',\alpha'\rangle$ is always zero or never zero. To see this,  $\langle \alpha'(s),\alpha'(s)\rangle' = 2f(s)\langle \alpha'(s),\alpha'(s)\rangle$, then $\langle \alpha'(s),\alpha'(s)\rangle = Ce^{2\int f(s)\,{\rm d}s}$ for some integration constant $C.$ d) If $\langle \alpha',\alpha'\rangle$ is always zero, then $\alpha$ is pre-geodesic. I've proved a), b) and c). Such points follow by some computations with $\beta^{'}$ and $\beta^{''},$ the hypotesis that $\alpha$ is regular and the first at the proposition: $\alpha^{''}(s)=f(s)\alpha^{'}(s).$ My first doubt is: How is possible write  $\alpha^{''}(s)=f(s)\alpha^{'}(s)?$ I don't get how to prove this. It is part of the hypotesis? Also I'm stuck prove d). Second: Why the proof of the behind ensures $\alpha$ is pregeodesic? I think the next result ensures that, if the previous holds, then $\alpha$ is pregeodesic: Let $\gamma:I\rightarrow M$ be a nonconstant geodesic. A reparametrization $\gamma\circ h:J\rightarrow M$ is a geodesic if and only if $h$ has the form $h(t)=at+b.$ If a curve has a reparametrization as a geodesic we call it pregeodesic. Any kind of help is thanked in advanced.",,"['differential-geometry', 'semi-riemannian-geometry']"
66,"Exercises for Spivak's Vol 2 ""A comprehensive Introduction to differential geometry""","Exercises for Spivak's Vol 2 ""A comprehensive Introduction to differential geometry""",,"Looking through Spivak's Vol 2. of ""A Comprehensive Introduction to Differential geometry"", I don't think there are any exercises. Is there a good source of supplementary exercises for Spivak's Differential Geometry?","Looking through Spivak's Vol 2. of ""A Comprehensive Introduction to Differential geometry"", I don't think there are any exercises. Is there a good source of supplementary exercises for Spivak's Differential Geometry?",,"['differential-geometry', 'reference-request', 'book-recommendation']"
67,Local Convexity and Curvature (Do Carmo),Local Convexity and Curvature (Do Carmo),,"I find myself unable to start the following problem in Differential Geometry of Curves and Surfaces by Do Carmo, Section 3.3 Problem 24.a Edit: (Definition) (Local Convexity and Curvature). A surface $S \subset R^3$ is locally convex at a point p ∈ S if there exists a neighborhood V ⊂ S of p such that V is contained in one of the closed half-spaces determined by Tp(S) in R3. If, in addition, V has only one common point with Tp(S), then S is called strictly locally convex at p. ""Prove that S is strictly locally convex at $p$ if the principal curvatures of   $S$ at $p$ are nonzero with the same sign (that is, the Gaussian curvature   $K(p)$ satisfies $K(p) > 0$)."" I fail to see why this is strictly locally convex, in fact, I fail to see why this must be locally convex. What if we had a surface that was generated by revolving about the y axis a curve with infinitely many bumps as x approaches to 0 (with decreasing amplitude to bound its derivative)?, but also somehow makesure that this surface is elliptic at (x,y) = (0,0)? My guts tell me that this would not be a regular surface, but I am unable to prove it. I would appreciate any hints!","I find myself unable to start the following problem in Differential Geometry of Curves and Surfaces by Do Carmo, Section 3.3 Problem 24.a Edit: (Definition) (Local Convexity and Curvature). A surface $S \subset R^3$ is locally convex at a point p ∈ S if there exists a neighborhood V ⊂ S of p such that V is contained in one of the closed half-spaces determined by Tp(S) in R3. If, in addition, V has only one common point with Tp(S), then S is called strictly locally convex at p. ""Prove that S is strictly locally convex at $p$ if the principal curvatures of   $S$ at $p$ are nonzero with the same sign (that is, the Gaussian curvature   $K(p)$ satisfies $K(p) > 0$)."" I fail to see why this is strictly locally convex, in fact, I fail to see why this must be locally convex. What if we had a surface that was generated by revolving about the y axis a curve with infinitely many bumps as x approaches to 0 (with decreasing amplitude to bound its derivative)?, but also somehow makesure that this surface is elliptic at (x,y) = (0,0)? My guts tell me that this would not be a regular surface, but I am unable to prove it. I would appreciate any hints!",,['differential-geometry']
68,What is the Topology of the Iwasawa Manifold?,What is the Topology of the Iwasawa Manifold?,,"Let $$ H= \left\{ \begin{pmatrix} 1 & z_1 & z_3 \\ 0 &   1 & z_2 \\ 0 &   0 &   1 \end{pmatrix} : z_1,z_2,z_3 \in \mathbb{C} \right\} $$ be the complex Heisenberg group and denote by $G$ the subgroup of $H$ where the entries $z_1,z_2,z_3 \in \mathbb{Z}[i]$ are in the Gaussian integers. Then $G$ acts on $H$ from the left and the quotient $W=H/G$ is a compact manifold with 6 real dimensions (3 complex dimensions, but $W$ is not Kähler). $W$ is called Iwasawa manifold . Note that $$ \begin{pmatrix} 1 &   a & c \\ 0 &   1 & b \\ 0 &   0 &   1 \end{pmatrix} \begin{pmatrix} 1 & z_1 & z_3 \\ 0 &   1 & z_2 \\ 0 &   0 &   1 \end{pmatrix} = \begin{pmatrix} 1 & z_1+a & z_3+a z_2+c \\ 0 &   1 & z_2+b \\ 0 &   0 &   1 \end{pmatrix}, $$ i.e. every element in $W$ has exactly one representative with elements $z_1,z_2,z_3 \in [0,1)\times [0,1)i$. It is mentioned e.g. in Daniel Huybrecht: Complex Geometry that $W$ is a non-trivial $2$-torus bundle over a $4$-torus (the non-triviality is checked by computing homology groups). Question 1:   Consider the map   $$\Phi: ([0,1]/_{\{0,1\}} \times [0,1]/_{\{0,1\}} i)^3 \rightarrow W, (z_1,z_2,z_3) \mapsto  \begin{pmatrix} 1 & z_1 & z_3 \\ 0 &   1 & z_2 \\ 0 &   0 &   1 \end{pmatrix}.$$   This is a well-defined (i.e. $\Phi(0,0,0)=\Phi(1,0,0)=\Phi(0,1,0)=\dots$), bijective (statement about representatives for elements in $W$ above), continuous map.   Thus it is a homeomorphism.   However it can't be, because it has different homology groups.   What is the problem with my ""homeomorphism""? And Question 2:   What is a good way to define functions on $W$?   I was hoping to use above bijection, but there is something wrong with it, so it seems like a bad idea.","Let $$ H= \left\{ \begin{pmatrix} 1 & z_1 & z_3 \\ 0 &   1 & z_2 \\ 0 &   0 &   1 \end{pmatrix} : z_1,z_2,z_3 \in \mathbb{C} \right\} $$ be the complex Heisenberg group and denote by $G$ the subgroup of $H$ where the entries $z_1,z_2,z_3 \in \mathbb{Z}[i]$ are in the Gaussian integers. Then $G$ acts on $H$ from the left and the quotient $W=H/G$ is a compact manifold with 6 real dimensions (3 complex dimensions, but $W$ is not Kähler). $W$ is called Iwasawa manifold . Note that $$ \begin{pmatrix} 1 &   a & c \\ 0 &   1 & b \\ 0 &   0 &   1 \end{pmatrix} \begin{pmatrix} 1 & z_1 & z_3 \\ 0 &   1 & z_2 \\ 0 &   0 &   1 \end{pmatrix} = \begin{pmatrix} 1 & z_1+a & z_3+a z_2+c \\ 0 &   1 & z_2+b \\ 0 &   0 &   1 \end{pmatrix}, $$ i.e. every element in $W$ has exactly one representative with elements $z_1,z_2,z_3 \in [0,1)\times [0,1)i$. It is mentioned e.g. in Daniel Huybrecht: Complex Geometry that $W$ is a non-trivial $2$-torus bundle over a $4$-torus (the non-triviality is checked by computing homology groups). Question 1:   Consider the map   $$\Phi: ([0,1]/_{\{0,1\}} \times [0,1]/_{\{0,1\}} i)^3 \rightarrow W, (z_1,z_2,z_3) \mapsto  \begin{pmatrix} 1 & z_1 & z_3 \\ 0 &   1 & z_2 \\ 0 &   0 &   1 \end{pmatrix}.$$   This is a well-defined (i.e. $\Phi(0,0,0)=\Phi(1,0,0)=\Phi(0,1,0)=\dots$), bijective (statement about representatives for elements in $W$ above), continuous map.   Thus it is a homeomorphism.   However it can't be, because it has different homology groups.   What is the problem with my ""homeomorphism""? And Question 2:   What is a good way to define functions on $W$?   I was hoping to use above bijection, but there is something wrong with it, so it seems like a bad idea.",,"['differential-geometry', 'complex-geometry']"
69,Is this a valid way to think of decomposable $k$-forms?,Is this a valid way to think of decomposable -forms?,k,"Let $V$ be a finite dimensional vector space and $\eta \in \Lambda^k(V^\ast)$ be decomposable and non-zero. Then there exists covectors $\omega^1,\dots,\omega^k$ such that $$\eta(v_1, \dots, v_k) = \omega_1 \wedge \dots \wedge \omega_k (v_1, \dots, v_k) = \det \left(\omega^i(v_j)\right).$$ Fix a basis for $V$, I will now treat covectors like vectors. Define the matrices  \begin{align} \Omega &=  (\omega_i^j) \\ V &= (v_j^i). \end{align} Then $$\eta(v_1, \dots, v_k) = \det(\Omega V)$$ Define $S=\text{span}(\omega^1, \dots, \omega^k)$ and let $E$ be a $k\times n$ matrix whose rows form an orthonormal basis for $S$. Then $\Omega = \Omega E^T E$ so \begin{align} \eta(v_1, \dots, v_k) &= \det(\Omega E^T E V)\\ &= \det(\Omega E^T) \det(E V) \\ &= \det(E\Omega^T) \det(E V) \\ &= \text{Vol}_S(\omega^1,\dots,\omega^k) \text{Vol}_S(v_1, \dots, v_k) \end{align} Where $\text{Vol}_S(u_1, \dots, u_k)$ gives the $S$-projected volume of the parallelotope spanned by $u_1, \dots, u_k$. Assuming I didn't make any mistakes, is there an analogous viewpoint for non-decomposable $k$-covectors? Edit: Here is another question that probably has an obvious answer. Is every $k$-covector decomposable in the right basis?","Let $V$ be a finite dimensional vector space and $\eta \in \Lambda^k(V^\ast)$ be decomposable and non-zero. Then there exists covectors $\omega^1,\dots,\omega^k$ such that $$\eta(v_1, \dots, v_k) = \omega_1 \wedge \dots \wedge \omega_k (v_1, \dots, v_k) = \det \left(\omega^i(v_j)\right).$$ Fix a basis for $V$, I will now treat covectors like vectors. Define the matrices  \begin{align} \Omega &=  (\omega_i^j) \\ V &= (v_j^i). \end{align} Then $$\eta(v_1, \dots, v_k) = \det(\Omega V)$$ Define $S=\text{span}(\omega^1, \dots, \omega^k)$ and let $E$ be a $k\times n$ matrix whose rows form an orthonormal basis for $S$. Then $\Omega = \Omega E^T E$ so \begin{align} \eta(v_1, \dots, v_k) &= \det(\Omega E^T E V)\\ &= \det(\Omega E^T) \det(E V) \\ &= \det(E\Omega^T) \det(E V) \\ &= \text{Vol}_S(\omega^1,\dots,\omega^k) \text{Vol}_S(v_1, \dots, v_k) \end{align} Where $\text{Vol}_S(u_1, \dots, u_k)$ gives the $S$-projected volume of the parallelotope spanned by $u_1, \dots, u_k$. Assuming I didn't make any mistakes, is there an analogous viewpoint for non-decomposable $k$-covectors? Edit: Here is another question that probably has an obvious answer. Is every $k$-covector decomposable in the right basis?",,"['linear-algebra', 'differential-geometry', 'tensors', 'differential-forms', 'exterior-algebra']"
70,"Why $\mathbb{C}[f_1(t),f_2(t)]=\mathbb{C}[t]$ iff $(f'_1(t),f'_2(t))\neq0$ and $t\mapsto (f_1(t),f_2(t))$ is injective?",Why  iff  and  is injective?,"\mathbb{C}[f_1(t),f_2(t)]=\mathbb{C}[t] (f'_1(t),f'_2(t))\neq0 t\mapsto (f_1(t),f_2(t))","Let $k$ be a field of characteristic zero. Let $f_1(t),f_2(t) \in k[t]$ and $f: k \to k^2$ defined by $f(t):=(f_1(t),f_2(t))$. First case $k=\mathbb{C}$: According to A. van den Essen (page 2), the following claim holds: $\mathbb{C}[f_1(t),f_2(t)]=\mathbb{C}[t]$ if and only if $f'(t)\neq (0,0)$ for all $t \in \mathbb{C}$ and $f$ is injective. (1) Can one please sketch a proof for this claim? Second case $k=\mathbb{R}$: It is not true that if $f'(t)\neq (0,0)$ for all $t \in \mathbb{R}$ and $f$ is injective, then $\mathbb{R}[f_1(t),f_2(t)]=\mathbb{R}[t]$, as the following example shows: $f_1(t)=t^2$, $f_2(t)=t+t^3$. (2) Is there an additional differential geometry condition, call it $C$, such that: $\mathbb{R}[f_1(t),f_2(t)]=\mathbb{R}[t]$ if and only if $f'(t)\neq (0,0)$ for all $t \in \mathbb{R}$, $f$ is injective, and $C$. Remarks : Concerning question (2): (i) I am interested in a 'not too strong' additional condition, namely, not something like $f_1'(t)=1$. (ii) Perhaps the additional condition $C$ will involve the second derivative $f''(t)$? Concerning both questions: (iii) Please see the comments in this question , especially, how page 8, claim b is relevant to my question? (iv) Considering the fields of fractions $k(f_1(t),f_2(t))=k(t)$ instead of $k[f_1(t),f_2(t)]=k[t]$ seem also interesting. Edit: This paper is somewhat relevant. Any comments and hints are welcome!","Let $k$ be a field of characteristic zero. Let $f_1(t),f_2(t) \in k[t]$ and $f: k \to k^2$ defined by $f(t):=(f_1(t),f_2(t))$. First case $k=\mathbb{C}$: According to A. van den Essen (page 2), the following claim holds: $\mathbb{C}[f_1(t),f_2(t)]=\mathbb{C}[t]$ if and only if $f'(t)\neq (0,0)$ for all $t \in \mathbb{C}$ and $f$ is injective. (1) Can one please sketch a proof for this claim? Second case $k=\mathbb{R}$: It is not true that if $f'(t)\neq (0,0)$ for all $t \in \mathbb{R}$ and $f$ is injective, then $\mathbb{R}[f_1(t),f_2(t)]=\mathbb{R}[t]$, as the following example shows: $f_1(t)=t^2$, $f_2(t)=t+t^3$. (2) Is there an additional differential geometry condition, call it $C$, such that: $\mathbb{R}[f_1(t),f_2(t)]=\mathbb{R}[t]$ if and only if $f'(t)\neq (0,0)$ for all $t \in \mathbb{R}$, $f$ is injective, and $C$. Remarks : Concerning question (2): (i) I am interested in a 'not too strong' additional condition, namely, not something like $f_1'(t)=1$. (ii) Perhaps the additional condition $C$ will involve the second derivative $f''(t)$? Concerning both questions: (iii) Please see the comments in this question , especially, how page 8, claim b is relevant to my question? (iv) Considering the fields of fractions $k(f_1(t),f_2(t))=k(t)$ instead of $k[f_1(t),f_2(t)]=k[t]$ seem also interesting. Edit: This paper is somewhat relevant. Any comments and hints are welcome!",,"['differential-geometry', 'algebraic-geometry', 'polynomials', 'commutative-algebra']"
71,Mean curvature is the divergence of the normal,Mean curvature is the divergence of the normal,,"As a definition, I was told that for a surface in 3D, $ 2H = -\nabla \cdot \nu$ where $H$ is the mean curvature and $\nu$ is the normal unit vector. In some results that I am studying, the factor 2 always disappears... Is this normal ? can we ignore the factor 2 and consider the definition ""up to a constant"" ?","As a definition, I was told that for a surface in 3D, $ 2H = -\nabla \cdot \nu$ where $H$ is the mean curvature and $\nu$ is the normal unit vector. In some results that I am studying, the factor 2 always disappears... Is this normal ? can we ignore the factor 2 and consider the definition ""up to a constant"" ?",,"['differential-geometry', 'definition']"
72,Twice contracted Bianchi identity from diffeomorphism invariance,Twice contracted Bianchi identity from diffeomorphism invariance,,"I've been reading Straumann's book ""General Relativity & Relativistic Astrophysics"". In it, he claims that the twice contracted Bianchi identity: $$\nabla_{\mu}G^{\mu\nu}=0$$ (where $G^{\mu\nu}=R^{\mu\nu}-\frac{1}{2}g^{\mu\nu}R$) is a consequence of the diffeomorphism (diff) invariance of the Einstein-Hilbert (EH) action. Now, I can show (I think) that the EH action is diff invariant, by considering a infinitesimal diff, generated by a vector field $X$: $$\delta_{X}S_{EH}=\phi^{\ast}S_{EH}-S_{EH}=\int_{M}\mathcal{L}_{X}\left(d^{4}x\sqrt{-g}R\right)=\int_{M}\left[\mathcal{L}_{X}\left(d^{4}x\sqrt{-g}\right)R +d^{4}x\sqrt{-g}\mathcal{L}_{X}\left(R\right)\right]\\ \qquad\qquad\qquad\quad\;\;=\int_{M}d^{4}x\sqrt{-g}\left[\nabla_{\mu}X^{\mu}R+X^{\mu}\nabla_{\mu}R\right]=\int_{M}d^{4}x\sqrt{-g}\,\nabla_{\mu}\left(X^{\mu}R\right)\\ =\int_{\partial M}d^{3}x\sqrt{h}\,n_{\mu}X^{\mu}R=0\;\;\qquad\qquad\qquad\quad$$ where $h_{ij}$ is the induced metric on the boundary $\partial M$ of the manifold $M$, with $n^{\mu}$ the normal vector to the boundary. The last equality follows upon the assumption that $X^{\mu}$ has compact support in $M$. However, I'm unsure how one uses this fact to derive the (twice-contracted) Bianchi identity? Straumann simply writes: $$\delta S=\int_{M}d^{4}x\sqrt{-g}\left(\frac{1}{\sqrt{-g}}\frac{\delta S_{EH}}{\delta g^{\mu\nu}}\right)\delta g^{\mu\nu}=\int_{M}d^{4}x\sqrt{-g}\,G_{\mu\nu}\delta g^{\mu\nu}=-\int_{M}d^{4}x\sqrt{-g}\,G^{\mu\nu}\delta g_{\mu\nu}$$ and notes that for an infinitesimal diff (generated by some vector field $X$), $\delta g_{\mu\nu}=2\nabla_{(\mu}X_{\nu)}$, such that $$\delta_{X} S=-2\int_{M}d^{4}x\sqrt{-g}\,G^{\mu\nu}\nabla_{\mu}X_{\nu}=2\int_{M}d^{4}x\sqrt{-g}\,X_{\nu}\nabla_{\mu}G^{\mu\nu}=0$$ and so, since $X^{\nu}$ is arbitrary, it must be that $\nabla_{\mu}G^{\mu\nu}=0$. What confuses me about this, is that one neglects the effect of the Lie derivative on $d^{4}x$ in this case (in the proof that the EH action is diff invariant, it was taken into account). Is the point that an infinitesimal diff is carried out in the same coordinate chart, and so $d^{4}x$ doesn't change in this case?","I've been reading Straumann's book ""General Relativity & Relativistic Astrophysics"". In it, he claims that the twice contracted Bianchi identity: $$\nabla_{\mu}G^{\mu\nu}=0$$ (where $G^{\mu\nu}=R^{\mu\nu}-\frac{1}{2}g^{\mu\nu}R$) is a consequence of the diffeomorphism (diff) invariance of the Einstein-Hilbert (EH) action. Now, I can show (I think) that the EH action is diff invariant, by considering a infinitesimal diff, generated by a vector field $X$: $$\delta_{X}S_{EH}=\phi^{\ast}S_{EH}-S_{EH}=\int_{M}\mathcal{L}_{X}\left(d^{4}x\sqrt{-g}R\right)=\int_{M}\left[\mathcal{L}_{X}\left(d^{4}x\sqrt{-g}\right)R +d^{4}x\sqrt{-g}\mathcal{L}_{X}\left(R\right)\right]\\ \qquad\qquad\qquad\quad\;\;=\int_{M}d^{4}x\sqrt{-g}\left[\nabla_{\mu}X^{\mu}R+X^{\mu}\nabla_{\mu}R\right]=\int_{M}d^{4}x\sqrt{-g}\,\nabla_{\mu}\left(X^{\mu}R\right)\\ =\int_{\partial M}d^{3}x\sqrt{h}\,n_{\mu}X^{\mu}R=0\;\;\qquad\qquad\qquad\quad$$ where $h_{ij}$ is the induced metric on the boundary $\partial M$ of the manifold $M$, with $n^{\mu}$ the normal vector to the boundary. The last equality follows upon the assumption that $X^{\mu}$ has compact support in $M$. However, I'm unsure how one uses this fact to derive the (twice-contracted) Bianchi identity? Straumann simply writes: $$\delta S=\int_{M}d^{4}x\sqrt{-g}\left(\frac{1}{\sqrt{-g}}\frac{\delta S_{EH}}{\delta g^{\mu\nu}}\right)\delta g^{\mu\nu}=\int_{M}d^{4}x\sqrt{-g}\,G_{\mu\nu}\delta g^{\mu\nu}=-\int_{M}d^{4}x\sqrt{-g}\,G^{\mu\nu}\delta g_{\mu\nu}$$ and notes that for an infinitesimal diff (generated by some vector field $X$), $\delta g_{\mu\nu}=2\nabla_{(\mu}X_{\nu)}$, such that $$\delta_{X} S=-2\int_{M}d^{4}x\sqrt{-g}\,G^{\mu\nu}\nabla_{\mu}X_{\nu}=2\int_{M}d^{4}x\sqrt{-g}\,X_{\nu}\nabla_{\mu}G^{\mu\nu}=0$$ and so, since $X^{\nu}$ is arbitrary, it must be that $\nabla_{\mu}G^{\mu\nu}=0$. What confuses me about this, is that one neglects the effect of the Lie derivative on $d^{4}x$ in this case (in the proof that the EH action is diff invariant, it was taken into account). Is the point that an infinitesimal diff is carried out in the same coordinate chart, and so $d^{4}x$ doesn't change in this case?",,"['differential-geometry', 'general-relativity', 'lie-derivative', 'diffeomorphism']"
73,"Writing an integrand as divergence, looking for geometric interpretations","Writing an integrand as divergence, looking for geometric interpretations",,"Let $ u : \Omega\to \mathbb R$, where $\Omega$ is an open set in $\mathbb R^2$. Let $a\ge 0$. Consider the following integral: $$ \int_\Omega \frac{\det D^2 u}{(1+ |D u|^2)^a} \mathrm d x \mathrm d y.$$ In an answer to another question, it is shown that the above integral depends only on the value of $Du, D^2u$ on the boundary $\partial \Omega$. This is done using some simple argument in calculus of variations. This result is suggesting the following Question : Can the above integrand be (explicitly) written as divergence of something? When $a=0$ it is easy: $$\int_\Omega \det D^2 u \mathrm dx \mathrm dy = \int_\Omega (u_{xx}u_{yy} - u_{xy}^2 )\mathrm dx\mathrm dy = \int_\Omega \mathrm{div}\big( u_xu_{yy} , -u_x u_{yx}\big) \mathrm dx\mathrm dy.$$ When $a = 3/2$, the above integration can be written as  $$ \int_\Omega K \mathrm dA,$$ where $K$, $\mathrm dA$ are respectively the Gaussian curvature and the area element of the graph $(x, y, u(x, y))$. Thus, again, the integrand can be written as $K\mathrm dA= \mathrm d\omega_{12}$, where $\omega_{12}$ is basically the Christoffel symbols given by $$ \nabla e_1 = \omega_{12} e_2,$$ where $\{e_1, e_2\}$ is an orthonormal frame on the surface (the graph). So $\{e_1, e_2\}$ and thus $\omega_{12}$ can be represented as partial derivatives of $u$ so it is sort of explicit. (Remark: in general for a surface, if the first fundamental form is diagonal $(F=0$), then  $$K \mathrm dA= \mathrm{div}\bigg( \frac{\sqrt g}{E} \Gamma_{xx}^y \ , - \frac{\sqrt g}{G} \Gamma_{xy}^y\bigg) \mathrm dx\mathrm dy,$$ which is divergence of something. But for a graph $(x, y, u(x, y))$, the first fundamental form is in general not diagonal and it is extremely messy to write down explicitly, though doable). Thus the answer to the question is yes at least when $a = 0, 3/2$. What about the general situation? Also, if the answer is yes, are there any geometric interpretations? (I guess it would be no, since the curvature should be the only geometric invariance).","Let $ u : \Omega\to \mathbb R$, where $\Omega$ is an open set in $\mathbb R^2$. Let $a\ge 0$. Consider the following integral: $$ \int_\Omega \frac{\det D^2 u}{(1+ |D u|^2)^a} \mathrm d x \mathrm d y.$$ In an answer to another question, it is shown that the above integral depends only on the value of $Du, D^2u$ on the boundary $\partial \Omega$. This is done using some simple argument in calculus of variations. This result is suggesting the following Question : Can the above integrand be (explicitly) written as divergence of something? When $a=0$ it is easy: $$\int_\Omega \det D^2 u \mathrm dx \mathrm dy = \int_\Omega (u_{xx}u_{yy} - u_{xy}^2 )\mathrm dx\mathrm dy = \int_\Omega \mathrm{div}\big( u_xu_{yy} , -u_x u_{yx}\big) \mathrm dx\mathrm dy.$$ When $a = 3/2$, the above integration can be written as  $$ \int_\Omega K \mathrm dA,$$ where $K$, $\mathrm dA$ are respectively the Gaussian curvature and the area element of the graph $(x, y, u(x, y))$. Thus, again, the integrand can be written as $K\mathrm dA= \mathrm d\omega_{12}$, where $\omega_{12}$ is basically the Christoffel symbols given by $$ \nabla e_1 = \omega_{12} e_2,$$ where $\{e_1, e_2\}$ is an orthonormal frame on the surface (the graph). So $\{e_1, e_2\}$ and thus $\omega_{12}$ can be represented as partial derivatives of $u$ so it is sort of explicit. (Remark: in general for a surface, if the first fundamental form is diagonal $(F=0$), then  $$K \mathrm dA= \mathrm{div}\bigg( \frac{\sqrt g}{E} \Gamma_{xx}^y \ , - \frac{\sqrt g}{G} \Gamma_{xy}^y\bigg) \mathrm dx\mathrm dy,$$ which is divergence of something. But for a graph $(x, y, u(x, y))$, the first fundamental form is in general not diagonal and it is extremely messy to write down explicitly, though doable). Thus the answer to the question is yes at least when $a = 0, 3/2$. What about the general situation? Also, if the answer is yes, are there any geometric interpretations? (I guess it would be no, since the curvature should be the only geometric invariance).",,"['differential-geometry', 'partial-differential-equations']"
74,Spinor bundle of a spin Manifold is a Clifford bundle,Spinor bundle of a spin Manifold is a Clifford bundle,,"I'm following Gompf and Stipsicz book about $4$-Manifold and Kirby Calculus. Here (page 34) they claim that the spinor bundle $S\to X$ over a spin compact manifold $X$ of dimension $n$ (even) is a Clifford bundle. I'm trying to prove that. I'm interested in showing that the Clifford action is skew-adjoint with respect to the hermitian inner product. As far as I understood the bundle of spinors is build in the following way. Let $\rho\colon \text{Spin}(n)\to M_{2^n}(\Bbb C)$ be the representation of the Clifford algebra as a matrix algebra (the authors claim it's an isomorphism), with a little abuse of notation we will use $\rho$ to denote the representation of $\text{Spin}(n)\subset \Bbb C L_n$, given by the restriction of the above isomorphism. Therefore the spinor bundle $S$ is $$ S = P_{\text{Spin}(n)} \times_{\rho} \Bbb C^{2^n} \to X$$ We have an action of $\Bbb C l (TX)$ on the second summand which respect the identifications, hence we have an action of the Clifford algebra on $S$. I need to prove that such an action is skew symmetric when restricted to unitary elements $v \in T_x(X)\subset \Bbb C l (TX)$. Skew-symmetry involves the fact that when restrict to a fiber of $S$ with the canonical hermitian product defined (please correct me if I'm wrong) as $$ \langle (\alpha,s_1),(\beta,s_2)\rangle := \langle \rho(\alpha)s_1,\rho(\beta)s_2\rangle$$ where the latter is the canonical hermitian product on $\Bbb C^{2^n}$, we have $$\langle v\cdot s_1,s_2\rangle =  -\langle  s_1,v\cdot s_2\rangle $$ for $s_1,s_2$ in some fiber of $S$. Problem is that I don't understand what kind of property I can impose on the matrix $\rho(v)$ (which should be skew hermitian), and this prevents me for proving the result. can someone help me with that?","I'm following Gompf and Stipsicz book about $4$-Manifold and Kirby Calculus. Here (page 34) they claim that the spinor bundle $S\to X$ over a spin compact manifold $X$ of dimension $n$ (even) is a Clifford bundle. I'm trying to prove that. I'm interested in showing that the Clifford action is skew-adjoint with respect to the hermitian inner product. As far as I understood the bundle of spinors is build in the following way. Let $\rho\colon \text{Spin}(n)\to M_{2^n}(\Bbb C)$ be the representation of the Clifford algebra as a matrix algebra (the authors claim it's an isomorphism), with a little abuse of notation we will use $\rho$ to denote the representation of $\text{Spin}(n)\subset \Bbb C L_n$, given by the restriction of the above isomorphism. Therefore the spinor bundle $S$ is $$ S = P_{\text{Spin}(n)} \times_{\rho} \Bbb C^{2^n} \to X$$ We have an action of $\Bbb C l (TX)$ on the second summand which respect the identifications, hence we have an action of the Clifford algebra on $S$. I need to prove that such an action is skew symmetric when restricted to unitary elements $v \in T_x(X)\subset \Bbb C l (TX)$. Skew-symmetry involves the fact that when restrict to a fiber of $S$ with the canonical hermitian product defined (please correct me if I'm wrong) as $$ \langle (\alpha,s_1),(\beta,s_2)\rangle := \langle \rho(\alpha)s_1,\rho(\beta)s_2\rangle$$ where the latter is the canonical hermitian product on $\Bbb C^{2^n}$, we have $$\langle v\cdot s_1,s_2\rangle =  -\langle  s_1,v\cdot s_2\rangle $$ for $s_1,s_2$ in some fiber of $S$. Problem is that I don't understand what kind of property I can impose on the matrix $\rho(v)$ (which should be skew hermitian), and this prevents me for proving the result. can someone help me with that?",,"['differential-geometry', 'spin-geometry']"
75,Construct a smooth curve with length $10$ and enclosing an area $6$,Construct a smooth curve with length  and enclosing an area,10 6,"The problem is the title and when I tried to construct such a curve I found my always obtain an ellipse, but failed to calculate the length of it. Are there any better constructions? I forget to add a condition.","The problem is the title and when I tried to construct such a curve I found my always obtain an ellipse, but failed to calculate the length of it. Are there any better constructions? I forget to add a condition.",,"['calculus', 'differential-geometry']"
76,Can Ricci flow develop singularity if metric is bounded?,Can Ricci flow develop singularity if metric is bounded?,,"Suppose I have a Ricci flow $(M, g(t))$ on $[0, T)$ can it develop a singularity if the metrics $g(t)$ are uniformly bounded? i.e $C^{-1}g(0)\leq g(t) \leq Cg(0)$ for all $t\in [0,T)$. In the Kahler case, I think if you can control the metric, you can control the curvature and then by Shi's theorem you can extend the flow past time $T$, but is there similar statement in the Riemannian case? If not, is there a counterexample?","Suppose I have a Ricci flow $(M, g(t))$ on $[0, T)$ can it develop a singularity if the metrics $g(t)$ are uniformly bounded? i.e $C^{-1}g(0)\leq g(t) \leq Cg(0)$ for all $t\in [0,T)$. In the Kahler case, I think if you can control the metric, you can control the curvature and then by Shi's theorem you can extend the flow past time $T$, but is there similar statement in the Riemannian case? If not, is there a counterexample?",,"['differential-geometry', 'riemannian-geometry', 'ricci-flow']"
77,Normal bundle of the diagonal,Normal bundle of the diagonal,,"The normal bundle of a smooth submanifold $X \subset Y \subset R^N$ is defined as $N(X,Y)=\{(x,v) : x \in X, v \in T_xY, v \perp T_xX\}$. I want to show that $TX \cong N(\Delta,X\times X)$, where $\Delta$ is the diagonal submanifold of $X \times X$. Intuitively to me, the points of $N(\Delta,X \times X)$, should be of the form $(x,v-v)$ but I have no idea how to show that.  I showed that the normal bundle is locally trivial, but I don't see if this can help in any way. Can someone help please?","The normal bundle of a smooth submanifold $X \subset Y \subset R^N$ is defined as $N(X,Y)=\{(x,v) : x \in X, v \in T_xY, v \perp T_xX\}$. I want to show that $TX \cong N(\Delta,X\times X)$, where $\Delta$ is the diagonal submanifold of $X \times X$. Intuitively to me, the points of $N(\Delta,X \times X)$, should be of the form $(x,v-v)$ but I have no idea how to show that.  I showed that the normal bundle is locally trivial, but I don't see if this can help in any way. Can someone help please?",,"['differential-geometry', 'differential-topology', 'vector-bundles']"
78,D. Joyce's decomposition of complex tensors,D. Joyce's decomposition of complex tensors,,"This question/reference request is related to the books Compact manifolds with special holonomy , Riemannian holonomy groups and calibrated geometry and the paper Manifolds with many complex structures all by D. Joyce. In all of this there is the fallowing notation. Let $(M,J)$ be a complex manifold of real dimension $2m$. Fix some (real) coordinate chart $(U,x_1,...,x_{2m})$. Suppose we have a tensor $t=t^{a...}_{b...}$ i.e. $t=\sum_{a,...,b,...}\partial_{x_1} \otimes ...\otimes dx_b\otimes ...$ . Now he defines (tensors?) $$t^{\alpha ...}_{...}=\frac{1}{2}(t^{a ...}_{...}-i J^a_ct^{c ...}_{...}), \:\:t^{\overline{\alpha} ...}_{...}=\frac{1}{2}(t^{a ...}_{...}+i J^a_ct^{c ...}_{...})$$ $$t^{ ...}_{\beta ...}=\frac{1}{2}(t^{ ...}_{b...}-i J^c_bt^{ ...}_{c...}), \:\:t^{ ...}_{\overline{\beta} ...}=\frac{1}{2}(t^{ ...}_{b...}+i J^c_bt^{ ...}_{c...}).$$ The first question is whether one knows a reference for precise elaboration on that notation since in mentioned place I only found hardly this formulas. The second and most important question is how this correspond to the usual notation in which $Greek$ and $\overline{Greek}$ letters correspond to holomorphic and anti-holomorphic decomposition. Let me elaborate on that second question. For a fixed tensor t of type $(p,q)$ we have its decomposition into $2^{p+q}$ tensors being sections of $${T^{1,0}}^{P'}M \otimes {T^{1,0}}^{P''} M \otimes {{T^{1,0}}^*}^{Q'}M \otimes {{T^{1,0}}^*}^{Q''}M$$ where $P' \cup P'' = [p]$, $Q' \cup Q'' = [q]$ and $P',P'',Q',Q''$ actually indicate order in which $i$ and $-i$ eigenspaces are tensored. It seems to me (I would as well appreciate an easy reason for that) that for a fixed combination of bars and no-bars, $t^{\alpha \overline{\beta}...}_{\gamma \delta...}$ are coordinates for the tensor being a member of decomposition of $t$ corresponding to this ""type"" but still in coordinates $(U,x_1,...,x_{2m})$. Suppose now in addition that we have started with a holomorphic coordinates i.e. $x_j+ix_{m+j}$ are holomorphic coordinates. How are then this  $t^{\alpha ...}_{...}$ related to the components of $t$ in holomorphic coordinate i.e. with respect to $\partial_{z_j}, \partial_{\overline{z_j}}, dz_j, d\overline{z_j}$. For example for Hermitina metric $g$ is $g_{\alpha \overline{\beta}}$ in usual sense, i.e. $g=g_{\alpha \overline{\beta}}(dz_\alpha \otimes d\overline{z_\beta} + d\overline{z_\beta} \otimes dz_\alpha)$, the same as in the one defined in the beginning? Note that in formulas from the begging, Greek letters can be choose to be bigger than $m$ so it's probably not that this components are the same on the other hand latter in the book in case of holomorphic coordinates Joyce is using them as they were the same.","This question/reference request is related to the books Compact manifolds with special holonomy , Riemannian holonomy groups and calibrated geometry and the paper Manifolds with many complex structures all by D. Joyce. In all of this there is the fallowing notation. Let $(M,J)$ be a complex manifold of real dimension $2m$. Fix some (real) coordinate chart $(U,x_1,...,x_{2m})$. Suppose we have a tensor $t=t^{a...}_{b...}$ i.e. $t=\sum_{a,...,b,...}\partial_{x_1} \otimes ...\otimes dx_b\otimes ...$ . Now he defines (tensors?) $$t^{\alpha ...}_{...}=\frac{1}{2}(t^{a ...}_{...}-i J^a_ct^{c ...}_{...}), \:\:t^{\overline{\alpha} ...}_{...}=\frac{1}{2}(t^{a ...}_{...}+i J^a_ct^{c ...}_{...})$$ $$t^{ ...}_{\beta ...}=\frac{1}{2}(t^{ ...}_{b...}-i J^c_bt^{ ...}_{c...}), \:\:t^{ ...}_{\overline{\beta} ...}=\frac{1}{2}(t^{ ...}_{b...}+i J^c_bt^{ ...}_{c...}).$$ The first question is whether one knows a reference for precise elaboration on that notation since in mentioned place I only found hardly this formulas. The second and most important question is how this correspond to the usual notation in which $Greek$ and $\overline{Greek}$ letters correspond to holomorphic and anti-holomorphic decomposition. Let me elaborate on that second question. For a fixed tensor t of type $(p,q)$ we have its decomposition into $2^{p+q}$ tensors being sections of $${T^{1,0}}^{P'}M \otimes {T^{1,0}}^{P''} M \otimes {{T^{1,0}}^*}^{Q'}M \otimes {{T^{1,0}}^*}^{Q''}M$$ where $P' \cup P'' = [p]$, $Q' \cup Q'' = [q]$ and $P',P'',Q',Q''$ actually indicate order in which $i$ and $-i$ eigenspaces are tensored. It seems to me (I would as well appreciate an easy reason for that) that for a fixed combination of bars and no-bars, $t^{\alpha \overline{\beta}...}_{\gamma \delta...}$ are coordinates for the tensor being a member of decomposition of $t$ corresponding to this ""type"" but still in coordinates $(U,x_1,...,x_{2m})$. Suppose now in addition that we have started with a holomorphic coordinates i.e. $x_j+ix_{m+j}$ are holomorphic coordinates. How are then this  $t^{\alpha ...}_{...}$ related to the components of $t$ in holomorphic coordinate i.e. with respect to $\partial_{z_j}, \partial_{\overline{z_j}}, dz_j, d\overline{z_j}$. For example for Hermitina metric $g$ is $g_{\alpha \overline{\beta}}$ in usual sense, i.e. $g=g_{\alpha \overline{\beta}}(dz_\alpha \otimes d\overline{z_\beta} + d\overline{z_\beta} \otimes dz_\alpha)$, the same as in the one defined in the beginning? Note that in formulas from the begging, Greek letters can be choose to be bigger than $m$ so it's probably not that this components are the same on the other hand latter in the book in case of holomorphic coordinates Joyce is using them as they were the same.",,"['differential-geometry', 'reference-request', 'complex-geometry']"
79,Complexified cotangent bundle,Complexified cotangent bundle,,"I have never worked with differential geometry over $\mathbb{C}$, and I feel a little bit confused. If $(M,J)$ is an almost complex manifold of dimension $2n$, we can extend $J_{p}$ to $T_{p}(M)\otimes_{\mathbb{R}}\mathbb{C}$ (which is a $2n$ dimensional $\mathbb{C}$-vector space), by $$J_{p}(v\otimes z)=J_{p}(v)\otimes z.$$ Then, $J_{p}$ is a $\mathbb{C}$-linear map and $J_{p}^{2}=-\text{Id}$, so $J_{p}$ has two eigenvalues: $i$ and $-i$ If $T_{1,0}$ is the $i$-eigenspace and $T_{0,1}$ is the $-i$-eigenspace (which are complex subspaces), it can be proved that $TM\otimes_{\mathbb R}\mathbb{C} \cong T_{1,0}\oplus T_{0,1}$. Similarly, $T^{*}M\otimes_{\mathbb R} \mathbb{C} \cong T^{1,0}\oplus T^{0,1}$. Then, $\bigwedge^{k}(T^{*}M\otimes_{\mathbb{R}} \mathbb{C})$ equals $\oplus_{m+l=k}(\bigwedge^{m}(T^{1,0})\otimes \bigwedge^{l}(T^{0,1}))$. My question is: I believe that the last tensor product should be taken over $\mathbb{C}$, since $T^{1,0}$ and $T^{0,1}$ are vector spaces over $\mathbb{C}$. Am I right? Moreover, how do elements of $\bigwedge^{m}(T^{1,0})\otimes \bigwedge^{l}(T^{0,1})$ look like? I am following these notes (page 78): https://people.math.ethz.ch/~acannas/Papers/lsg.pdf Thanks in advance!","I have never worked with differential geometry over $\mathbb{C}$, and I feel a little bit confused. If $(M,J)$ is an almost complex manifold of dimension $2n$, we can extend $J_{p}$ to $T_{p}(M)\otimes_{\mathbb{R}}\mathbb{C}$ (which is a $2n$ dimensional $\mathbb{C}$-vector space), by $$J_{p}(v\otimes z)=J_{p}(v)\otimes z.$$ Then, $J_{p}$ is a $\mathbb{C}$-linear map and $J_{p}^{2}=-\text{Id}$, so $J_{p}$ has two eigenvalues: $i$ and $-i$ If $T_{1,0}$ is the $i$-eigenspace and $T_{0,1}$ is the $-i$-eigenspace (which are complex subspaces), it can be proved that $TM\otimes_{\mathbb R}\mathbb{C} \cong T_{1,0}\oplus T_{0,1}$. Similarly, $T^{*}M\otimes_{\mathbb R} \mathbb{C} \cong T^{1,0}\oplus T^{0,1}$. Then, $\bigwedge^{k}(T^{*}M\otimes_{\mathbb{R}} \mathbb{C})$ equals $\oplus_{m+l=k}(\bigwedge^{m}(T^{1,0})\otimes \bigwedge^{l}(T^{0,1}))$. My question is: I believe that the last tensor product should be taken over $\mathbb{C}$, since $T^{1,0}$ and $T^{0,1}$ are vector spaces over $\mathbb{C}$. Am I right? Moreover, how do elements of $\bigwedge^{m}(T^{1,0})\otimes \bigwedge^{l}(T^{0,1})$ look like? I am following these notes (page 78): https://people.math.ethz.ch/~acannas/Papers/lsg.pdf Thanks in advance!",,"['differential-geometry', 'differential-forms', 'complex-geometry', 'exterior-algebra']"
80,Dimension of the Marsden-Weinstein reduction of a coadjoint orbit in the dual of the Lie algebra of the gauge group (Atiyah-Bott context),Dimension of the Marsden-Weinstein reduction of a coadjoint orbit in the dual of the Lie algebra of the gauge group (Atiyah-Bott context),,"Let $P\to \Sigma$ be a $\mathrm{SU}(2)$-principal bundle over a smooth orientable closed genus $g$ real surface $\Sigma$. Let $\mathcal{A}$ be the space of connexions over $P$ and let $\mathcal{G}$ be the gauge group. Let $\Omega^k:=\Omega^k(\Sigma;\mathrm{Ad}P)$ be the space of $\mathrm{Ad}P$-valued differential $k$-forms on $\Sigma$ (here $\mathrm{Ad}P=P\times_\mathrm{Ad}\mathfrak{su}(2)$ is the adjoint bundle). On $\mathcal{A}$ lives not only a pretty canonical symplectic form but also Atiyah-Bott's moment map $$ F : \mathcal{A}\to \mathrm{Lie}(\mathcal{G})^* \; ; \quad A\mapsto F_A $$ whose hamiltonian action is the $\mathcal{G}$ action on $\mathcal{A}$ acting by pull-backs. Here $F_A\in \Omega^2<\mathrm{Lie}(\mathcal{G})^*$ is $A$'s curvature form. The Marsden-Weinstein reduction $$ \mathcal{M}^{\mathrm{fl}} := \mathcal{A}^{\mathrm{fl}}/\mathcal{G} = F^{-1}(0) \; /\!/ \; \mathcal{G} $$ is the so-called moduli space of flat connections over $\Sigma$. It is a symplectic orbifold whose irreducible part is smooth. If $\Sigma$ has genus $g\geq 2$, this irreducible part has dimension $6g-6$. Consider now $\mathcal{O}\ne\{0\}$ be some coadjoint orbit inside $\mathrm{Lie}(\mathcal{G})^*$. Again, we can consider a Marsden-Weinstein reduction : $$ \mathcal{M}^{\mathcal{O}} := F^{-1}(\mathcal{O}) \; /\!/ \; \mathcal{G} $$ Question : What is the dimension of (the irreducible part of) $\mathcal{M}^{\mathcal{O}}$ ? Is it finite ? Remark 1 : If my calculations are right, for $A$ irreducible I think we have the isomorphism $$ T_{[A]}\mathcal{M}^\mathcal{O}\cong\frac{\{\tau\in \Omega^1 | \mathrm{d}_A \tau\in \mathrm{im}(\mathrm{d}_A^2:\Omega^0\to\Omega^2)\}}{\mathrm{im}(\mathrm{d}_A:\Omega^0\to\Omega^1)} $$ (if $A$ is flat we recover the usual $T_{[A]}\mathcal{M}^{\mathrm{fl}}$). So the dimension I'm looking for should correspond to the dimension of that space. I just don't know how to compute it. Remark 2 : According to the answer I got to this related question , the "" Remark 1 "" can be reformulated as : $$ T_{[A]}\mathcal{M}^\mathcal{O}\cong \frac{\ker(\pi_A\circ\mathrm{d}_A|_{\Omega^1})}{\mathrm{im}(\mathrm{d}_A|_{\Omega^0})} $$ where $\pi_A$ is this quotient projection : $$ \pi_A : \Omega^2 \to \frac{\Omega^2}{\mathrm{im}(\mathrm{d}_A^2 : \Omega^0\to\Omega^2)} $$ Remark 3 : By giving $\Sigma$ a Riemannian metric and considering $\delta_A:\Omega^k\to\Omega^{k-1}$ the $L^2$-adjoint operator of $\mathrm{d}_A$ (i.e. the covariant coderivative) and the Laplacian $\Delta_A:=\mathrm{d}_A\delta_A+\delta_A \mathrm{d}_A:\Omega^k\to\Omega^k$, I also get that : $$ \ker(\Delta_A|_{\Omega^1}) < T_{[A]}\mathcal{M}^\mathcal{O} $$ But I'm not sure how ""bigger"" is $T_{[A]}\mathcal{M}^\mathcal{O}$ compared to the space $\ker(\Delta_A|_{\Omega^1})$ of harmonic $\mathrm{Ad}P$-valued differential 1-forms. Remark 4 : the projection $\pi_A$ can be reformulated as $$ \pi_A : \Omega^2 \to \ker(\delta_A^2:\Omega^2\to \Omega^0) $$ 2018-02-16 update : meanwhile I found that $T_{[A]}\mathcal{M}^{\mathcal{O}}_\Sigma \cong \ker(\Delta_{A}|_{\Omega^1})$. Now, my question becomes : for $A$ irreducible, does the dimension of $\ker(\Delta_{A}|_{\Omega^1})$ change if one takes a non-flat connection $A$ instead of a flat one ?","Let $P\to \Sigma$ be a $\mathrm{SU}(2)$-principal bundle over a smooth orientable closed genus $g$ real surface $\Sigma$. Let $\mathcal{A}$ be the space of connexions over $P$ and let $\mathcal{G}$ be the gauge group. Let $\Omega^k:=\Omega^k(\Sigma;\mathrm{Ad}P)$ be the space of $\mathrm{Ad}P$-valued differential $k$-forms on $\Sigma$ (here $\mathrm{Ad}P=P\times_\mathrm{Ad}\mathfrak{su}(2)$ is the adjoint bundle). On $\mathcal{A}$ lives not only a pretty canonical symplectic form but also Atiyah-Bott's moment map $$ F : \mathcal{A}\to \mathrm{Lie}(\mathcal{G})^* \; ; \quad A\mapsto F_A $$ whose hamiltonian action is the $\mathcal{G}$ action on $\mathcal{A}$ acting by pull-backs. Here $F_A\in \Omega^2<\mathrm{Lie}(\mathcal{G})^*$ is $A$'s curvature form. The Marsden-Weinstein reduction $$ \mathcal{M}^{\mathrm{fl}} := \mathcal{A}^{\mathrm{fl}}/\mathcal{G} = F^{-1}(0) \; /\!/ \; \mathcal{G} $$ is the so-called moduli space of flat connections over $\Sigma$. It is a symplectic orbifold whose irreducible part is smooth. If $\Sigma$ has genus $g\geq 2$, this irreducible part has dimension $6g-6$. Consider now $\mathcal{O}\ne\{0\}$ be some coadjoint orbit inside $\mathrm{Lie}(\mathcal{G})^*$. Again, we can consider a Marsden-Weinstein reduction : $$ \mathcal{M}^{\mathcal{O}} := F^{-1}(\mathcal{O}) \; /\!/ \; \mathcal{G} $$ Question : What is the dimension of (the irreducible part of) $\mathcal{M}^{\mathcal{O}}$ ? Is it finite ? Remark 1 : If my calculations are right, for $A$ irreducible I think we have the isomorphism $$ T_{[A]}\mathcal{M}^\mathcal{O}\cong\frac{\{\tau\in \Omega^1 | \mathrm{d}_A \tau\in \mathrm{im}(\mathrm{d}_A^2:\Omega^0\to\Omega^2)\}}{\mathrm{im}(\mathrm{d}_A:\Omega^0\to\Omega^1)} $$ (if $A$ is flat we recover the usual $T_{[A]}\mathcal{M}^{\mathrm{fl}}$). So the dimension I'm looking for should correspond to the dimension of that space. I just don't know how to compute it. Remark 2 : According to the answer I got to this related question , the "" Remark 1 "" can be reformulated as : $$ T_{[A]}\mathcal{M}^\mathcal{O}\cong \frac{\ker(\pi_A\circ\mathrm{d}_A|_{\Omega^1})}{\mathrm{im}(\mathrm{d}_A|_{\Omega^0})} $$ where $\pi_A$ is this quotient projection : $$ \pi_A : \Omega^2 \to \frac{\Omega^2}{\mathrm{im}(\mathrm{d}_A^2 : \Omega^0\to\Omega^2)} $$ Remark 3 : By giving $\Sigma$ a Riemannian metric and considering $\delta_A:\Omega^k\to\Omega^{k-1}$ the $L^2$-adjoint operator of $\mathrm{d}_A$ (i.e. the covariant coderivative) and the Laplacian $\Delta_A:=\mathrm{d}_A\delta_A+\delta_A \mathrm{d}_A:\Omega^k\to\Omega^k$, I also get that : $$ \ker(\Delta_A|_{\Omega^1}) < T_{[A]}\mathcal{M}^\mathcal{O} $$ But I'm not sure how ""bigger"" is $T_{[A]}\mathcal{M}^\mathcal{O}$ compared to the space $\ker(\Delta_A|_{\Omega^1})$ of harmonic $\mathrm{Ad}P$-valued differential 1-forms. Remark 4 : the projection $\pi_A$ can be reformulated as $$ \pi_A : \Omega^2 \to \ker(\delta_A^2:\Omega^2\to \Omega^0) $$ 2018-02-16 update : meanwhile I found that $T_{[A]}\mathcal{M}^{\mathcal{O}}_\Sigma \cong \ker(\Delta_{A}|_{\Omega^1})$. Now, my question becomes : for $A$ irreducible, does the dimension of $\ker(\Delta_{A}|_{\Omega^1})$ change if one takes a non-flat connection $A$ instead of a flat one ?",,"['differential-geometry', 'symplectic-geometry', 'gauge-theory']"
81,Spin Bundle and Connection on $R^3$?,Spin Bundle and Connection on ?,R^3,"What is the spin connection on the spin bundle $S$ over $R^3$? Let metric be $dx_1^2+dx_2^2+dx_3^2$ with orientation $dx_1 \wedge dx_2 \wedge dx_3$. From my understanding, the spin bundle over $R^3$ is a trivial rank 4 bundle equipped with anticommuting involutions I, J e.g. $I=\begin{pmatrix} 0 & 1 &0 &0 \\ -1 &0 &0 &0 \\ 0 & 0 &0 &1 \\0 &0 &-1&0\end{pmatrix}, J=\begin{pmatrix} 0 & 0 & 0 & -1 \\ 0 & 0 & -1 & 0 \\ 0 & 1 & 0 & 0 \\ 1 & 0 & 0 & 0 \end{pmatrix}$. We need a representation $\Gamma$ of the Clifford algebra of $TR^3$ onto the space $R^4$ that commutes with I,J. Let $\frac{\partial}{\partial x_1}, \frac{\partial}{\partial x_2}, \frac{\partial}{\partial x_3}$ be frame of $TR^3$. I suppose $\Gamma$ could be given by  $\Gamma(\frac{\partial}{\partial x_1})=\begin{pmatrix} 0 & 1 & 0 & 0 \\ -1 & 0 & 0 & 0 \\ 0 & 0 & 0 & -1 \\ 0 & 0 & 1 & 0 \end{pmatrix}$,  $\Gamma(\frac{\partial}{\partial x_2})=\begin{pmatrix} 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 \\ -1 & 0 & 0 & 0 \\ 0 & -1 & 0 & 0\end{pmatrix}$, $\Gamma(\frac{\partial}{\partial x_3})=\begin{pmatrix} 0 & 0 & 0 & -1 \\ 0 & 0 & 1 & 0 \\ 0 & -1 & 0 & 0 \\ 1 & 0 & 0 & 0 \end{pmatrix}$. Then what remains is to define a connection on $S$ that is both compatiable with the Levi-Civita connection on $R^3$ and with the inner product on $R^4$, i.e. if $s,s'$ are sections of $S$ then $\nabla_X(\Gamma(Y)s)= \Gamma(Y) \nabla_X s + \Gamma(\nabla_X Y) s$ for all vector fields $X,Y$ on $R^3$ and $X<s,s'>=<\nabla_X s,s'>+<s,\nabla_X s'>$ For our spin connection, I believe there are 4x4x3=48 Christoffel symbols to calculate. Are we to use compatability conditions to generate 48 equations and solve for the Christoffel symbols? How does one get the spin connection? I am looking for explicit form of this connection and calculation, not abstract definition of this connection like ""unique lift of Levi-Civita connection"" etc.","What is the spin connection on the spin bundle $S$ over $R^3$? Let metric be $dx_1^2+dx_2^2+dx_3^2$ with orientation $dx_1 \wedge dx_2 \wedge dx_3$. From my understanding, the spin bundle over $R^3$ is a trivial rank 4 bundle equipped with anticommuting involutions I, J e.g. $I=\begin{pmatrix} 0 & 1 &0 &0 \\ -1 &0 &0 &0 \\ 0 & 0 &0 &1 \\0 &0 &-1&0\end{pmatrix}, J=\begin{pmatrix} 0 & 0 & 0 & -1 \\ 0 & 0 & -1 & 0 \\ 0 & 1 & 0 & 0 \\ 1 & 0 & 0 & 0 \end{pmatrix}$. We need a representation $\Gamma$ of the Clifford algebra of $TR^3$ onto the space $R^4$ that commutes with I,J. Let $\frac{\partial}{\partial x_1}, \frac{\partial}{\partial x_2}, \frac{\partial}{\partial x_3}$ be frame of $TR^3$. I suppose $\Gamma$ could be given by  $\Gamma(\frac{\partial}{\partial x_1})=\begin{pmatrix} 0 & 1 & 0 & 0 \\ -1 & 0 & 0 & 0 \\ 0 & 0 & 0 & -1 \\ 0 & 0 & 1 & 0 \end{pmatrix}$,  $\Gamma(\frac{\partial}{\partial x_2})=\begin{pmatrix} 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 \\ -1 & 0 & 0 & 0 \\ 0 & -1 & 0 & 0\end{pmatrix}$, $\Gamma(\frac{\partial}{\partial x_3})=\begin{pmatrix} 0 & 0 & 0 & -1 \\ 0 & 0 & 1 & 0 \\ 0 & -1 & 0 & 0 \\ 1 & 0 & 0 & 0 \end{pmatrix}$. Then what remains is to define a connection on $S$ that is both compatiable with the Levi-Civita connection on $R^3$ and with the inner product on $R^4$, i.e. if $s,s'$ are sections of $S$ then $\nabla_X(\Gamma(Y)s)= \Gamma(Y) \nabla_X s + \Gamma(\nabla_X Y) s$ for all vector fields $X,Y$ on $R^3$ and $X<s,s'>=<\nabla_X s,s'>+<s,\nabla_X s'>$ For our spin connection, I believe there are 4x4x3=48 Christoffel symbols to calculate. Are we to use compatability conditions to generate 48 equations and solve for the Christoffel symbols? How does one get the spin connection? I am looking for explicit form of this connection and calculation, not abstract definition of this connection like ""unique lift of Levi-Civita connection"" etc.",,"['differential-geometry', 'riemannian-geometry', 'spin-geometry']"
82,Conformal map from R3 to R2 x S1,Conformal map from R3 to R2 x S1,,"There exists a global conformal map between $\mathbb{R}^3$ and $S_3$: $$ g = dr^2+r^2\left(d\theta^2 + \sin^2\theta\ d\phi^2\right) $$ $$ r = R \tan \frac{\alpha}{2} $$ $$ g = \frac{R^2}{4\cos^4\frac{\alpha}{2}}\left[d\alpha^2+\sin^2\alpha\left(d\theta^2 + \sin^2\theta\ d\phi^2\right)\right] $$ There also exists a global conformal map between $\mathbb{R}^3$ and the cylinder $\mathbb{R}\times S_2$: $$ r = R\ e^{x/R} $$ $$ g=e^{2x/R}\left[dx^2+R^2\left(d\theta^2 + \sin^2\theta\ d\phi^2\right)\right] $$ There does not appear to be a global conformal map between $\mathbb{R}^3$ and the cylinder $\mathbb{R^2}\times S_1$. At least, my attempts to find one starting from $\mathbb{R^3}$ in cylindrical coordinates: $$ g = dz^2+ d\rho^2 +\rho^2 d\phi^2 $$ and remapping $(z, \rho)$ have failed. So my questions are: 1) Is it true that there is no such map? 2) If so, how do you show that? I think that local invariants like the Cotton tensor have nothing to say, because both $\mathbb{R}^3$ and $\mathbb{R^2}\times S_1$ are flat, and instead there is some kind of global obstruction.","There exists a global conformal map between $\mathbb{R}^3$ and $S_3$: $$ g = dr^2+r^2\left(d\theta^2 + \sin^2\theta\ d\phi^2\right) $$ $$ r = R \tan \frac{\alpha}{2} $$ $$ g = \frac{R^2}{4\cos^4\frac{\alpha}{2}}\left[d\alpha^2+\sin^2\alpha\left(d\theta^2 + \sin^2\theta\ d\phi^2\right)\right] $$ There also exists a global conformal map between $\mathbb{R}^3$ and the cylinder $\mathbb{R}\times S_2$: $$ r = R\ e^{x/R} $$ $$ g=e^{2x/R}\left[dx^2+R^2\left(d\theta^2 + \sin^2\theta\ d\phi^2\right)\right] $$ There does not appear to be a global conformal map between $\mathbb{R}^3$ and the cylinder $\mathbb{R^2}\times S_1$. At least, my attempts to find one starting from $\mathbb{R^3}$ in cylindrical coordinates: $$ g = dz^2+ d\rho^2 +\rho^2 d\phi^2 $$ and remapping $(z, \rho)$ have failed. So my questions are: 1) Is it true that there is no such map? 2) If so, how do you show that? I think that local invariants like the Cotton tensor have nothing to say, because both $\mathbb{R}^3$ and $\mathbb{R^2}\times S_1$ are flat, and instead there is some kind of global obstruction.",,"['differential-geometry', 'conformal-geometry']"
83,Invariant differential operators on equivariant vector bundles over Lie groups,Invariant differential operators on equivariant vector bundles over Lie groups,,"This is a quick and dirty formulation of my question, with the hope that experts will quickly figure out what I am looking for and provide a reference. Let $G$ be a Lie group, and let $\pi:E\to G$ be a finite dimensional real or complex $G$-equivariant vector bundle, i.e., $\pi(gs)=g\pi(s)$ for all $s\in E$. Then $E$ is trivial since the simply transitive action of $G$ defines $G$-invariant sections $e_j\in C^\infty(E)$ that comprise a global frame. The same happens with the tangent bundle $TG$ and the endomorphism bundle $\mathrm{Hom}(E)$. The vector space of (left) $G$-inavriant vector fields in $C^\infty(TG)$ is a Lie algebra isomorphic to the Lie algebra $\mathrm{Lie}(G)$, whereas the vector space of $G$-invariant endomorphism fields in $C^\infty(\mathrm{Hom})$ is an associative algebra isomorphic to $\mathrm{gl}(\dim E/G)$. Let $\nabla$ be the flat connection on $E$ corresponding to $G$-translation. Question: Let $\operatorname{D}:C^\infty(E)\to C^\infty(E)$ be a $G$-invariant partial differential operator. I believe that it can be written as $$ \operatorname{D}=\sum_{k=0}^m D_k(\nabla^k), $$  where $D_k\in\mathrm{Lie}(G)^{\otimes k}\otimes\mathrm{gl}(\dim E/G)$. I think I know how to prove this, but does anyone know of a reference where this is stated? Thank you.","This is a quick and dirty formulation of my question, with the hope that experts will quickly figure out what I am looking for and provide a reference. Let $G$ be a Lie group, and let $\pi:E\to G$ be a finite dimensional real or complex $G$-equivariant vector bundle, i.e., $\pi(gs)=g\pi(s)$ for all $s\in E$. Then $E$ is trivial since the simply transitive action of $G$ defines $G$-invariant sections $e_j\in C^\infty(E)$ that comprise a global frame. The same happens with the tangent bundle $TG$ and the endomorphism bundle $\mathrm{Hom}(E)$. The vector space of (left) $G$-inavriant vector fields in $C^\infty(TG)$ is a Lie algebra isomorphic to the Lie algebra $\mathrm{Lie}(G)$, whereas the vector space of $G$-invariant endomorphism fields in $C^\infty(\mathrm{Hom})$ is an associative algebra isomorphic to $\mathrm{gl}(\dim E/G)$. Let $\nabla$ be the flat connection on $E$ corresponding to $G$-translation. Question: Let $\operatorname{D}:C^\infty(E)\to C^\infty(E)$ be a $G$-invariant partial differential operator. I believe that it can be written as $$ \operatorname{D}=\sum_{k=0}^m D_k(\nabla^k), $$  where $D_k\in\mathrm{Lie}(G)^{\otimes k}\otimes\mathrm{gl}(\dim E/G)$. I think I know how to prove this, but does anyone know of a reference where this is stated? Thank you.",,"['differential-geometry', 'reference-request', 'lie-groups', 'vector-bundles']"
84,Recovering Curvature Endomorphism out of Holonomy,Recovering Curvature Endomorphism out of Holonomy,,"In $\S 3$ of this document the following is stated: Let $M$ be a $2$-dimensional Riemannian manifold and $R$ denote the curvature tensor. Let $p$ be a point in $M$ and $X_0, Y_0\in T_p M$ be linearly independent. Extend $X_0$ and $Y_0$ locally around $p$ to get commuting vector fields $X$ and $Y$. Thus $R(X, Y)= [\nabla_X, \nabla_Y]$, where $\nabla$ is the Levi-Civita connection. For each $t>0$ small enough, let $\gamma_t$ be the loop formed by flowing for $\sqrt{t}$ time along $X$, then for $\sqrt{t}$ time along $Y$, then flowing for $\sqrt{t}$ time opposite to the flow of $X$, and lastly for $\sqrt{t}$ time opposite to the flow of $Y$. This actually gives a loop because $X$ and $Y$ are commuting. Then $R(X_0, Y_0) = \lim_{t\to 0}\frac{P_{\gamma_t}-I}{t}$ where $P_{\gamma_t}:T_pM\to T_pM$ is the parallel transport along $\gamma_t$. It is remarked in the document that this can be proved in a similar manner as one proves the Lie bracket of two vector fields is the Lie derivative of one with respect to the other. Since $X$ and $Y$ are commuting, we may assume that they are coordinate vector fields. But when trying to write down the coordinate expression for $[\nabla_X, \nabla_Y]$, I end up with a horrible mess featuring the Cristoffel coefficients and their derivatives. I am not able to see how to connect this to the parallel transport.","In $\S 3$ of this document the following is stated: Let $M$ be a $2$-dimensional Riemannian manifold and $R$ denote the curvature tensor. Let $p$ be a point in $M$ and $X_0, Y_0\in T_p M$ be linearly independent. Extend $X_0$ and $Y_0$ locally around $p$ to get commuting vector fields $X$ and $Y$. Thus $R(X, Y)= [\nabla_X, \nabla_Y]$, where $\nabla$ is the Levi-Civita connection. For each $t>0$ small enough, let $\gamma_t$ be the loop formed by flowing for $\sqrt{t}$ time along $X$, then for $\sqrt{t}$ time along $Y$, then flowing for $\sqrt{t}$ time opposite to the flow of $X$, and lastly for $\sqrt{t}$ time opposite to the flow of $Y$. This actually gives a loop because $X$ and $Y$ are commuting. Then $R(X_0, Y_0) = \lim_{t\to 0}\frac{P_{\gamma_t}-I}{t}$ where $P_{\gamma_t}:T_pM\to T_pM$ is the parallel transport along $\gamma_t$. It is remarked in the document that this can be proved in a similar manner as one proves the Lie bracket of two vector fields is the Lie derivative of one with respect to the other. Since $X$ and $Y$ are commuting, we may assume that they are coordinate vector fields. But when trying to write down the coordinate expression for $[\nabla_X, \nabla_Y]$, I end up with a horrible mess featuring the Cristoffel coefficients and their derivatives. I am not able to see how to connect this to the parallel transport.",,"['differential-geometry', 'riemannian-geometry', 'curvature', 'holonomy']"
85,Local Form of Covariant Derivative Induced from a Connection one-form,Local Form of Covariant Derivative Induced from a Connection one-form,,"Let $P\rightarrow M$ be a Principal G-Bundle with $E=P\times_\rho V$ the associated vector bundle with $\rho$ a representation of $G$ on $GL(V)$. Also let $\omega$ be a connection one-form on $P$ i.e. $\omega\in\Omega(P; Lie(G))$. We have for some local trivialisation $\phi:P\rightarrow U\times G$, $ (\phi^{-1})^*\omega=g^{-1}a_Ug+ g^{-1}dg $ with $a_U$ a lie algebra valued one form on $U$, and open set of $M$. Let $\nabla$ be the covariant derivative induced by the connection $\omega$. If we have a local trivivialisation $\psi:E\rightarrow U\times V$. with a section $s\in\Omega^{0}(M; E)$. I am wondering how we derive the formula $\psi(\nabla s)=(x, ds_U+\rho_*(a_u)s)$ in the local trivialisation. Please just comment if something is unclear. I have seen this formula in multiple sources and can't find a derivation. Appreciate any help that is given.","Let $P\rightarrow M$ be a Principal G-Bundle with $E=P\times_\rho V$ the associated vector bundle with $\rho$ a representation of $G$ on $GL(V)$. Also let $\omega$ be a connection one-form on $P$ i.e. $\omega\in\Omega(P; Lie(G))$. We have for some local trivialisation $\phi:P\rightarrow U\times G$, $ (\phi^{-1})^*\omega=g^{-1}a_Ug+ g^{-1}dg $ with $a_U$ a lie algebra valued one form on $U$, and open set of $M$. Let $\nabla$ be the covariant derivative induced by the connection $\omega$. If we have a local trivivialisation $\psi:E\rightarrow U\times V$. with a section $s\in\Omega^{0}(M; E)$. I am wondering how we derive the formula $\psi(\nabla s)=(x, ds_U+\rho_*(a_u)s)$ in the local trivialisation. Please just comment if something is unclear. I have seen this formula in multiple sources and can't find a derivation. Appreciate any help that is given.",,"['differential-geometry', 'vector-bundles', 'fiber-bundles', 'connections', 'principal-bundles']"
86,Second order Terms from the Laplacian and Lie Bracket,Second order Terms from the Laplacian and Lie Bracket,,"The Laplacian measures the second order average difference of u in a neighbourhood around a point, i.e. $$ \frac{1}{v(B_r)} \int_{B_r(x)} [f(y) - f(x)] = C \Delta u(x) r^2 + o(r^2) $$ Where the constant $C$ depends on the dimension. On the other hand, in a Lie group, the second order terms of the conjugate $ghg^{-1}h^{-1}$ forms the Lie bracket structure on the induced Lie algebra, which is a sort of 'difference measurement'. Is there a connection between these two 'second order' operators in mathematics?","The Laplacian measures the second order average difference of u in a neighbourhood around a point, i.e. $$ \frac{1}{v(B_r)} \int_{B_r(x)} [f(y) - f(x)] = C \Delta u(x) r^2 + o(r^2) $$ Where the constant $C$ depends on the dimension. On the other hand, in a Lie group, the second order terms of the conjugate $ghg^{-1}h^{-1}$ forms the Lie bracket structure on the induced Lie algebra, which is a sort of 'difference measurement'. Is there a connection between these two 'second order' operators in mathematics?",,"['differential-geometry', 'partial-differential-equations', 'lie-groups', 'lie-algebras']"
87,Prove that $\pi:S^3\rightarrow \mathbb{P}^1(\mathbb{C})\cong S^2$ is a submersion,Prove that  is a submersion,\pi:S^3\rightarrow \mathbb{P}^1(\mathbb{C})\cong S^2,"I have to solve this one: Let us consider the sphere $S^3\subset \mathbb{R}^4\cong\mathbb{C}^2$, and the map $\pi:S^3\rightarrow \mathbb{P}^1(\mathbb{C})\cong S^2$ defined as the projection's restriction $(z_1,z_2)\mapsto [z_1:z_2]$. Prove that $\pi$ is a submersion. Solution: I identify $\mathbb{P}^1(\mathbb{C})$ and $S^2$ through a diffeomorphism \begin{array}{crcl} f:& \mathbb{P}^1(\mathbb{C}) & \longrightarrow & S^2 \\ & [z_1,z_2] & \longmapsto & \frac{1}{|z_1|^2+|z_2|^2}\big(|z_2|^2-|z_1|^2,2z_1\overline{z_2} \big) \end{array} This way we have \begin{array}{crcl} f\circ\pi:& S^3 & \longrightarrow & S^2 \\ & (z_1,z_2) & \longmapsto & \big(|z_2|^2-|z_1|^2,2z_1\overline{z_2} \big) \end{array} because $|z_1|^2+|z_2|^2=1$. Now we compute the Jacobian matrix of $f\circ\pi$ \begin{equation} J_{f\circ\pi}=\left( \begin{array}{cc} 2\overline{z_2} & 2z_1\frac{2|z_2|z_2-|z_2|^2}{z_2^2} \\ 2|z_1| & -2|z_2| \end{array} \right) \end{equation} that has full rank, so $f\circ\pi$ is a submersion. Now the thing is: how can I conclude that $\pi$ is a submersion? Any other idea to solve it? Thanks a lot","I have to solve this one: Let us consider the sphere $S^3\subset \mathbb{R}^4\cong\mathbb{C}^2$, and the map $\pi:S^3\rightarrow \mathbb{P}^1(\mathbb{C})\cong S^2$ defined as the projection's restriction $(z_1,z_2)\mapsto [z_1:z_2]$. Prove that $\pi$ is a submersion. Solution: I identify $\mathbb{P}^1(\mathbb{C})$ and $S^2$ through a diffeomorphism \begin{array}{crcl} f:& \mathbb{P}^1(\mathbb{C}) & \longrightarrow & S^2 \\ & [z_1,z_2] & \longmapsto & \frac{1}{|z_1|^2+|z_2|^2}\big(|z_2|^2-|z_1|^2,2z_1\overline{z_2} \big) \end{array} This way we have \begin{array}{crcl} f\circ\pi:& S^3 & \longrightarrow & S^2 \\ & (z_1,z_2) & \longmapsto & \big(|z_2|^2-|z_1|^2,2z_1\overline{z_2} \big) \end{array} because $|z_1|^2+|z_2|^2=1$. Now we compute the Jacobian matrix of $f\circ\pi$ \begin{equation} J_{f\circ\pi}=\left( \begin{array}{cc} 2\overline{z_2} & 2z_1\frac{2|z_2|z_2-|z_2|^2}{z_2^2} \\ 2|z_1| & -2|z_2| \end{array} \right) \end{equation} that has full rank, so $f\circ\pi$ is a submersion. Now the thing is: how can I conclude that $\pi$ is a submersion? Any other idea to solve it? Thanks a lot",,"['differential-geometry', 'projective-space', 'spheres', 'hopf-fibration']"
88,Is any regular algebraic curve in the plane union of closed curves?,Is any regular algebraic curve in the plane union of closed curves?,,"This is related to the attempt I am doing trying to prove that any polynomial lemniscate is the union of regular closed curves. Recall by the way that a polynomial lemniscate is a curve of the form $\{z\in\mathbb C: |p(z)|=K\}$, where p is a polynomial of one complex variable with complex coefficients and $K>0$. I proved that any polynomial lemniscate is the union of regular curves defined on open intervals. However, I have no idea of how to prove that these regular curves are indeed closed. The following picture represents a lemniscate of 8 foci (the polynomial is of degree 8). Although there is a self-intersecting component, it can be parametrized regularly. I conjecture that something like the following could be true: If a bounded algebraic curve on the plane is the union of regular curves, these curves are indeed closed. Thank you so much in advance.","This is related to the attempt I am doing trying to prove that any polynomial lemniscate is the union of regular closed curves. Recall by the way that a polynomial lemniscate is a curve of the form $\{z\in\mathbb C: |p(z)|=K\}$, where p is a polynomial of one complex variable with complex coefficients and $K>0$. I proved that any polynomial lemniscate is the union of regular curves defined on open intervals. However, I have no idea of how to prove that these regular curves are indeed closed. The following picture represents a lemniscate of 8 foci (the polynomial is of degree 8). Although there is a self-intersecting component, it can be parametrized regularly. I conjecture that something like the following could be true: If a bounded algebraic curve on the plane is the union of regular curves, these curves are indeed closed. Thank you so much in advance.",,"['differential-geometry', 'algebraic-geometry', 'algebraic-curves']"
89,Sections of a Vector Bundle and Equivariant Maps on the Frame Bundle,Sections of a Vector Bundle and Equivariant Maps on the Frame Bundle,,"Throughout we work in the smooth setting. Let $\pi:E\to M$ be a rank $k$ real vector bundle and $F(E)\to M$ denote the corresponding frame bundle. I am trying to understand the following statement, which is taken from this wikipedia article, under the heading ""Relation to Principal and Ehresmann Connections."" The sections of $E$ are in one to one correspondence with the equivariant maps $F(E)\to \mathbf R^k$. (This can be seen by considering the pullback of $E$ over $F(E)\to M$, which is a trivial bundle isomorphic to $F(E)\times \mathbf R^k$). I don't see how the correspondence comes about, and especially how the triviality of the pullback bundle gives it. What I can see is that if we have a section $\sigma$ of $E$, then we can define a map $F(E)\to \mathbf R^k$ which sends $(p, T)\in FE_p$ to $T^{-1}(\sigma(p))$. But I am unable to get a map in the reverse direction. Can somebody please help, especially elucidating as to how the triviality of the pullback comes to our rescue.","Throughout we work in the smooth setting. Let $\pi:E\to M$ be a rank $k$ real vector bundle and $F(E)\to M$ denote the corresponding frame bundle. I am trying to understand the following statement, which is taken from this wikipedia article, under the heading ""Relation to Principal and Ehresmann Connections."" The sections of $E$ are in one to one correspondence with the equivariant maps $F(E)\to \mathbf R^k$. (This can be seen by considering the pullback of $E$ over $F(E)\to M$, which is a trivial bundle isomorphic to $F(E)\times \mathbf R^k$). I don't see how the correspondence comes about, and especially how the triviality of the pullback bundle gives it. What I can see is that if we have a section $\sigma$ of $E$, then we can define a map $F(E)\to \mathbf R^k$ which sends $(p, T)\in FE_p$ to $T^{-1}(\sigma(p))$. But I am unable to get a map in the reverse direction. Can somebody please help, especially elucidating as to how the triviality of the pullback comes to our rescue.",,"['differential-geometry', 'vector-bundles', 'connections', 'principal-bundles']"
90,Positive sectional curvature & finite isometry group,Positive sectional curvature & finite isometry group,,Is there a known example of a compact Riemannian manifold with positive sectional curvature that doesn't have continuous symmetry (i.e. there are no nontrivial Killing fields)? I'm more interested in the case when the manifold is even-dimensional (related to the Hopf conjecture on Euler characteristic) but I'd be interested in the general case as well.,Is there a known example of a compact Riemannian manifold with positive sectional curvature that doesn't have continuous symmetry (i.e. there are no nontrivial Killing fields)? I'm more interested in the case when the manifold is even-dimensional (related to the Hopf conjecture on Euler characteristic) but I'd be interested in the general case as well.,,"['differential-geometry', 'riemannian-geometry']"
91,Grassmanian of k-plane in R^n,Grassmanian of k-plane in R^n,,"I am reading the script http://www3.math.tu-berlin.de/geometrie/Lehre/WS16/DGII/script.pdf and I want to prove exercise 9 where you need to show that $G_1(\Bbb R^3) \subset sym(3)$ is a submanifold diffeomorphic to $ \Bbb RP^2 $. The Grassmanian of k-plane in $ R^n $ is defined as follows $ G_k(\Bbb R^n):= \{ p\in \Bbb R^{n \times n}|p^*=p , p^2=p, tr(p)=k \}$ and there is a theorem that says $ G_k(\Bbb R^n)$ is a submanifold of $\Bbb R^{n \times n}$ of dimension $k(n-k)$. I don't really see how I can show it's a submanifold of $sym(3)$ and how it's diffeomorphic to $\Bbb RP^2$ .","I am reading the script http://www3.math.tu-berlin.de/geometrie/Lehre/WS16/DGII/script.pdf and I want to prove exercise 9 where you need to show that $G_1(\Bbb R^3) \subset sym(3)$ is a submanifold diffeomorphic to $ \Bbb RP^2 $. The Grassmanian of k-plane in $ R^n $ is defined as follows $ G_k(\Bbb R^n):= \{ p\in \Bbb R^{n \times n}|p^*=p , p^2=p, tr(p)=k \}$ and there is a theorem that says $ G_k(\Bbb R^n)$ is a submanifold of $\Bbb R^{n \times n}$ of dimension $k(n-k)$. I don't really see how I can show it's a submanifold of $sym(3)$ and how it's diffeomorphic to $\Bbb RP^2$ .",,"['differential-geometry', 'differential-topology']"
92,Integration on manifold using the flow of a vector field,Integration on manifold using the flow of a vector field,,"In a Physics paper the author states without proof something that seemed quite strange to me. The paper is on General Relativity, so he assumes a Lorentzian manifold $(M,g)$ is given. His hypothesis are: Suppose $f$ is a continuous scalar function on $M$ whose support $W$ extends to past and future infinity but which is bounded in spacelike directions, and take $L$, parametrized as $\gamma(s)$ by the proper time $s$ along it, to be a timelike worldline representing an observer. We shall now take $\Sigma(s)$ to be an arbitrary spacelike hypersurface through $\gamma(s)$ which depends continuously on $s$. Then if $w^\alpha$ is a vector field such that displacement of every point by $w^\alpha ds$ maps $\Sigma(s)$ into $\Sigma(s+ds)$ for each $s$, we have   $$\langle f,\phi\rangle=\int ds \int_{\Sigma(s)} f\phi \sqrt{-g}w^\alpha n_\alpha d\Sigma,$$   for all compactly supported $\phi\in C^\infty_0(M)$ being $n^\alpha$ the normal to $\Sigma(s)$. I believe that it all boils down to this: given a one-parameter family of spacelike hypersurfaces $\Sigma(s)$, and a vector field $W$ such that its flow satisfies $\Phi^X_\delta(\Sigma(s))=\Sigma(s+\delta)$, we have $$\int_M f(x) d^nx=\int ds \int_{\Sigma(s)} f \sqrt{-g} W^\alpha n_\alpha d\Sigma.$$ I might be wrong though, and it might only work with $\phi$ and with the hypothesis on the support of $f$. The thing is: how this is proven? Actually, if $\phi : (-\epsilon,\epsilon)\times M\to M$ is the flow of $W$ so that $\phi_t : M\to M$ is the diffeomorphism moving points a parameter value $t$ on the integral curves, we can consider the set $$A = \{\phi(s,p) \in M :s\in (-\epsilon,\epsilon),p\in \Sigma(s)\}$$ Then if $\varphi : U\subset \mathbb{R}^{n-1}\to \Sigma(s)$ is a parametrization of the hypersurface, we shall have a parametrization $\psi : (-\epsilon,\epsilon)\times U\to A$ given by $$\psi(s,q)=\phi(s,\varphi(q)).$$ Let $(y^\alpha)$ a coordinate system on $(-\epsilon,\epsilon)\times U\subset \mathbb{R}^n$ and $(x^\mu)$ a coordinate system on $M$ Now pick $f\in C^\infty_0(M)$, the $n$-form $f\epsilon$ has compact support, where $\epsilon$ is the Lorentzian volume form. But if $h : M\to \mathbb{R}$ is $h = \sqrt{|g|}$ what we want is to integrate $\omega = fh dx^0\wedge\cdots \wedge dx^{n-1}$. But by a theorem on Spivak DG Vol. 1 (7.7) we have $$\psi^\ast \omega=(fh\circ\psi) \det\left(\dfrac{\partial(x^\mu \circ \psi)}{\partial y^\alpha}\right) dy^0\wedge \cdots dy^{n-1}$$ The issue now is to compute that determinant. I concluded (not much rigorously really) that $$\dfrac{\partial(x^\mu \circ \psi)}{\partial y^0}=W^\mu\circ \psi$$ While for the other I computed not rigorously also that $$\dfrac{\partial(x^\mu \circ \psi)}{\partial y^i}=\dfrac{\partial(x^\mu\circ \phi)}{\partial x^\nu}\dfrac{\partial (x^\nu\circ \varphi)}{\partial y^i}$$ The first seems to be the Jacobian of the flow of $W$, the second seems to be the components of $\varphi_\ast e_i$ so the basis of the tangent spaces of $\Sigma$ induced by the basis of $\mathbb{R}^{n-1}$. If I'm not mistaken this is the same as $$\dfrac{\partial(x^\mu \circ \psi)}{\partial y^i}=\phi_{\ast}(\varphi_\ast e_i)=(\phi\circ\varphi)_\ast e_i$$ So the first column of the matrix are the components of $W$ and the $i$-th column are the components of the $i$-th basis vector of $\mathbb{R}^n$ pushed to $M$ throguh $(\phi\circ\varphi)$ - the parametrization followed by the flow. Now I think that the normal covector $n$ is $$n = \star (\phi\circ\varphi)_\ast e_1\wedge \cdots \wedge (\phi\circ\varphi)_\ast e_{n-1}$$ The matrix above has $W$ in one column and these vectors on the others. Computing the determinant with the Levi-Civita symbol $\varepsilon_{\mu_1\dots\mu_n}$ gives $$\det(J)=\varepsilon_{\mu_1\dots \mu_n} W^{\mu_1} (\phi\circ\varphi)_\ast e_1^{\mu_2}\cdots e_{n-1}^{\mu_n}$$ But then combining with the factor $h\circ \psi$ we factored will turn the Levi Civita symbol to $\epsilon_{\mu_1\cdots\mu_n}$ which in turn gives the Hodge dual $$\psi^\ast \epsilon = (f \epsilon_{\mu_1\cdots \mu_n}\circ \psi W^{\mu_1})\circ \psi(\phi\circ\varphi)_\ast e_1^{\mu_2}\cdots(\phi\circ\varphi)_\ast e_{n-1}^{\mu_n} dy^0\wedge \cdots \wedge dy^{n-1}= (fW^\mu n_\mu)\circ \psi dy^0\wedge\cdots \wedge dy^{n-1} $$ I just don't know if this is right. Is my approach correct?","In a Physics paper the author states without proof something that seemed quite strange to me. The paper is on General Relativity, so he assumes a Lorentzian manifold $(M,g)$ is given. His hypothesis are: Suppose $f$ is a continuous scalar function on $M$ whose support $W$ extends to past and future infinity but which is bounded in spacelike directions, and take $L$, parametrized as $\gamma(s)$ by the proper time $s$ along it, to be a timelike worldline representing an observer. We shall now take $\Sigma(s)$ to be an arbitrary spacelike hypersurface through $\gamma(s)$ which depends continuously on $s$. Then if $w^\alpha$ is a vector field such that displacement of every point by $w^\alpha ds$ maps $\Sigma(s)$ into $\Sigma(s+ds)$ for each $s$, we have   $$\langle f,\phi\rangle=\int ds \int_{\Sigma(s)} f\phi \sqrt{-g}w^\alpha n_\alpha d\Sigma,$$   for all compactly supported $\phi\in C^\infty_0(M)$ being $n^\alpha$ the normal to $\Sigma(s)$. I believe that it all boils down to this: given a one-parameter family of spacelike hypersurfaces $\Sigma(s)$, and a vector field $W$ such that its flow satisfies $\Phi^X_\delta(\Sigma(s))=\Sigma(s+\delta)$, we have $$\int_M f(x) d^nx=\int ds \int_{\Sigma(s)} f \sqrt{-g} W^\alpha n_\alpha d\Sigma.$$ I might be wrong though, and it might only work with $\phi$ and with the hypothesis on the support of $f$. The thing is: how this is proven? Actually, if $\phi : (-\epsilon,\epsilon)\times M\to M$ is the flow of $W$ so that $\phi_t : M\to M$ is the diffeomorphism moving points a parameter value $t$ on the integral curves, we can consider the set $$A = \{\phi(s,p) \in M :s\in (-\epsilon,\epsilon),p\in \Sigma(s)\}$$ Then if $\varphi : U\subset \mathbb{R}^{n-1}\to \Sigma(s)$ is a parametrization of the hypersurface, we shall have a parametrization $\psi : (-\epsilon,\epsilon)\times U\to A$ given by $$\psi(s,q)=\phi(s,\varphi(q)).$$ Let $(y^\alpha)$ a coordinate system on $(-\epsilon,\epsilon)\times U\subset \mathbb{R}^n$ and $(x^\mu)$ a coordinate system on $M$ Now pick $f\in C^\infty_0(M)$, the $n$-form $f\epsilon$ has compact support, where $\epsilon$ is the Lorentzian volume form. But if $h : M\to \mathbb{R}$ is $h = \sqrt{|g|}$ what we want is to integrate $\omega = fh dx^0\wedge\cdots \wedge dx^{n-1}$. But by a theorem on Spivak DG Vol. 1 (7.7) we have $$\psi^\ast \omega=(fh\circ\psi) \det\left(\dfrac{\partial(x^\mu \circ \psi)}{\partial y^\alpha}\right) dy^0\wedge \cdots dy^{n-1}$$ The issue now is to compute that determinant. I concluded (not much rigorously really) that $$\dfrac{\partial(x^\mu \circ \psi)}{\partial y^0}=W^\mu\circ \psi$$ While for the other I computed not rigorously also that $$\dfrac{\partial(x^\mu \circ \psi)}{\partial y^i}=\dfrac{\partial(x^\mu\circ \phi)}{\partial x^\nu}\dfrac{\partial (x^\nu\circ \varphi)}{\partial y^i}$$ The first seems to be the Jacobian of the flow of $W$, the second seems to be the components of $\varphi_\ast e_i$ so the basis of the tangent spaces of $\Sigma$ induced by the basis of $\mathbb{R}^{n-1}$. If I'm not mistaken this is the same as $$\dfrac{\partial(x^\mu \circ \psi)}{\partial y^i}=\phi_{\ast}(\varphi_\ast e_i)=(\phi\circ\varphi)_\ast e_i$$ So the first column of the matrix are the components of $W$ and the $i$-th column are the components of the $i$-th basis vector of $\mathbb{R}^n$ pushed to $M$ throguh $(\phi\circ\varphi)$ - the parametrization followed by the flow. Now I think that the normal covector $n$ is $$n = \star (\phi\circ\varphi)_\ast e_1\wedge \cdots \wedge (\phi\circ\varphi)_\ast e_{n-1}$$ The matrix above has $W$ in one column and these vectors on the others. Computing the determinant with the Levi-Civita symbol $\varepsilon_{\mu_1\dots\mu_n}$ gives $$\det(J)=\varepsilon_{\mu_1\dots \mu_n} W^{\mu_1} (\phi\circ\varphi)_\ast e_1^{\mu_2}\cdots e_{n-1}^{\mu_n}$$ But then combining with the factor $h\circ \psi$ we factored will turn the Levi Civita symbol to $\epsilon_{\mu_1\cdots\mu_n}$ which in turn gives the Hodge dual $$\psi^\ast \epsilon = (f \epsilon_{\mu_1\cdots \mu_n}\circ \psi W^{\mu_1})\circ \psi(\phi\circ\varphi)_\ast e_1^{\mu_2}\cdots(\phi\circ\varphi)_\ast e_{n-1}^{\mu_n} dy^0\wedge \cdots \wedge dy^{n-1}= (fW^\mu n_\mu)\circ \psi dy^0\wedge\cdots \wedge dy^{n-1} $$ I just don't know if this is right. Is my approach correct?",,"['integration', 'differential-geometry', 'riemannian-geometry', 'general-relativity', 'semi-riemannian-geometry']"
93,Are area minimizing Seifert surfaces minimal genus,Are area minimizing Seifert surfaces minimal genus,,"Let $K \subset S^3$ be a knot and let $S \subset S^3$ be an orientable surface with $\partial S = K$.  If $S$ is area minimizing among all such surfaces, then is $S$ genus minimizing?","Let $K \subset S^3$ be a knot and let $S \subset S^3$ be an orientable surface with $\partial S = K$.  If $S$ is area minimizing among all such surfaces, then is $S$ genus minimizing?",,"['differential-geometry', 'differential-topology']"
94,Is every vector bundle a tangent bundle [closed],Is every vector bundle a tangent bundle [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question We know every tangent bundles is orientable and have even dimension. I think these properties are not sufficient to a vector bunble be (isomorphic) to a tangent one. I want to find some geometric/topological property, which is only satisfied by tangent bundle to formulate something like: Let $E$ a $2n$-dimensional orientable manifold that can be realised as the total space of some vector bundle over a manifold $M$. If (some condition), then $E$ can also be realised as a tangent bundle. I'm trying to get some feeling about vector bundle based on the tangent one. Edit: the comments show me it's not a precise question. Ok, let's change a little bit: Fixed a manifold $M$, I want to characterize $TM$ in the follow sense: in what conditions a VB $E$ over $M$ is (isomorphic to) the tangent one and I can formulate: Let $M$ be a manifold and $E$ be orientable $2n-$dimensional VB of $M$. If (some conditions over $E$), then $E$ is VB-isomorphic to $TM$, $E \simeq TM$. I want, at least, a thinner necessary condition to $E \simeq TM$.","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question We know every tangent bundles is orientable and have even dimension. I think these properties are not sufficient to a vector bunble be (isomorphic) to a tangent one. I want to find some geometric/topological property, which is only satisfied by tangent bundle to formulate something like: Let $E$ a $2n$-dimensional orientable manifold that can be realised as the total space of some vector bundle over a manifold $M$. If (some condition), then $E$ can also be realised as a tangent bundle. I'm trying to get some feeling about vector bundle based on the tangent one. Edit: the comments show me it's not a precise question. Ok, let's change a little bit: Fixed a manifold $M$, I want to characterize $TM$ in the follow sense: in what conditions a VB $E$ over $M$ is (isomorphic to) the tangent one and I can formulate: Let $M$ be a manifold and $E$ be orientable $2n-$dimensional VB of $M$. If (some conditions over $E$), then $E$ is VB-isomorphic to $TM$, $E \simeq TM$. I want, at least, a thinner necessary condition to $E \simeq TM$.",,"['differential-geometry', 'differential-topology', 'vector-bundles', 'tangent-bundle']"
95,Geometric interpretation of Christoffel symbol symmetry in polar and cylindrical coordinates,Geometric interpretation of Christoffel symbol symmetry in polar and cylindrical coordinates,,"As outlined in this blog post , we can give a geometric interpretation to the Christoffel symbols (of the second kind) as follows: If you take the vector $\partial_i$ and infinitesimally translate this in the direction of $\partial_j$, it will change by $\Gamma_{ij}^k\partial_k$. For example, consider polar coordinates in the plane $(r,\phi)$: If we take the vector $\partial_r$ and translate this outwards in the $r$-direction, the vector is unchanged since it still has the same direction and magnitude. Thus $\Gamma_{rr}^r=\Gamma_{rr}^\phi=0$. If we translate the vector $\partial_r$ in the $\theta$-direction, the change in direction is given by $\frac{1}{r}\partial_{\theta}$, so $\Gamma_{r\theta}^r=0$ and $\Gamma_{r\theta}^\theta=\frac{1}{r}$. If we calculate these symbols, we find that they are symmetric in the lower two indices. The same goes for the Christoffel symbols for cylindrical and polar coordinates. Why is this? It doesn't seem 'obvious' to me that the change in $\partial_r$ from translation in the $\partial_\theta$ direction should be the same as the change of $\partial_\theta$ in the $\partial_r$ direction. I know that this is a feature of the Levi-Civita connection, and you can see this from its definition in terms of the metric. However, is there a geometric way of looking at this?","As outlined in this blog post , we can give a geometric interpretation to the Christoffel symbols (of the second kind) as follows: If you take the vector $\partial_i$ and infinitesimally translate this in the direction of $\partial_j$, it will change by $\Gamma_{ij}^k\partial_k$. For example, consider polar coordinates in the plane $(r,\phi)$: If we take the vector $\partial_r$ and translate this outwards in the $r$-direction, the vector is unchanged since it still has the same direction and magnitude. Thus $\Gamma_{rr}^r=\Gamma_{rr}^\phi=0$. If we translate the vector $\partial_r$ in the $\theta$-direction, the change in direction is given by $\frac{1}{r}\partial_{\theta}$, so $\Gamma_{r\theta}^r=0$ and $\Gamma_{r\theta}^\theta=\frac{1}{r}$. If we calculate these symbols, we find that they are symmetric in the lower two indices. The same goes for the Christoffel symbols for cylindrical and polar coordinates. Why is this? It doesn't seem 'obvious' to me that the change in $\partial_r$ from translation in the $\partial_\theta$ direction should be the same as the change of $\partial_\theta$ in the $\partial_r$ direction. I know that this is a feature of the Levi-Civita connection, and you can see this from its definition in terms of the metric. However, is there a geometric way of looking at this?",,"['differential-geometry', 'riemannian-geometry', 'curvature']"
96,Does the proof of Yamabe problem gives a method for finding metric of constant scalar curvature?,Does the proof of Yamabe problem gives a method for finding metric of constant scalar curvature?,,"Yamabe problem states that: Given a smooth, compact manifold $M$ of dimension $n \geq 3$ with a Riemannian metric $g$, does there exist a metric $h$ conformal to $g$ for which the scalar curvature of $h$ is constant? The answer is now known to be yes and I want to know Question: Does the proof of Yamabe problem give a method for finding metric of constant scalar curvature? If the answer is positive, then what is its method? Thanks.","Yamabe problem states that: Given a smooth, compact manifold $M$ of dimension $n \geq 3$ with a Riemannian metric $g$, does there exist a metric $h$ conformal to $g$ for which the scalar curvature of $h$ is constant? The answer is now known to be yes and I want to know Question: Does the proof of Yamabe problem give a method for finding metric of constant scalar curvature? If the answer is positive, then what is its method? Thanks.",,"['differential-geometry', 'riemannian-geometry']"
97,Using bump function in coordinate chart to construct a vector field $V$ along a curve $\gamma$ with particular properties.,Using bump function in coordinate chart to construct a vector field  along a curve  with particular properties.,V \gamma,"I get a little confused by the details of the following theorem from John Lee's book Riemannian Manifold page 100. It basically about construction of vector field along a piecewise smooth curve using smooth bump function. Let $\gamma : [a,b] \rightarrow M$ be piecewise smooth curve (i.e there are subdivision $a_0=a<a_1<...<a_{n-1}<a_n=b$ s.t $\gamma_{[a_i,a_{i+1}]}$ is smooth). Now we want a vector field $V : [a,b] \rightarrow M$ along $\gamma$ such that at a point in the ""corner"", say at $\gamma(a_i)$ for $0<i<n$, $V$ having a particular value, say $V(a_i)=V_i$, but at any other corner $a_j (j\neq i)$, $V(a_j)=0$. This particular construction arise from the following proof. $\textbf{Theorem 6.6.}$ Every minimizing curve is a geodesic when it is given a unit speed parametrization   The idea is to use First Variation Formula    \begin{equation} \frac{d}{ds}\Bigg|_{s=0} L(\Gamma_s) = -\int_a^b \langle V,D_t\dot{\gamma} \rangle dt - \sum_{i=1}^{k-1} \langle V(a_i), \Delta_i\dot{\gamma} \rangle \end{equation}   to show that the initial piecewise curve $\gamma$ satisfying the hypothesis (minimizing and unit speed) is a broken geodesic, that is $D_t \dot{\gamma} \equiv 0$ on each subdivision where its smooth, and to show that it has no corners, that is $\Delta_i \dot{\gamma} = 0$ for all $i$. My trouble is to follow the second step. It is says that to show $\Delta_i \dot{\gamma} = 0$, we can use a smooth bump function in a coordinate chart to construct a vector field $V$ along $\gamma$ such that $V(a_i)=\Delta_i \dot{\gamma}$ and $V(a_j)=0$ for all $j\neq i$. After a lot of thinking i already did such construction but not sure it is right. I worried because the similar proof for the above theorem in another text like do Carmo (Riemannian Geometry, Ch.9 prop 2.5 p.196) does not show either how to construct such vector field. Here is my ideas : Choose a small neighbourhood $U$ of $\gamma (a_i)$ such that it does not contain any other points $\gamma(a_j)$ except for $j=i$. Build a local vector field $V$ such that $V$ is constant with the constant coefficient equal to $\Delta_i \dot{\gamma}$. Choose a bump function $\varphi$ supported in $U$ such that $\varphi(\gamma(a_i)) = 1$. Restrict $\varphi$ to $U$ and multiplied it by $V$. Therefore we have a vector field $\varphi V$ defined in $U$. By Gluing lemma for smooth map we can extend $\varphi V$ to the whole $M$ such that $\varphi V$ vanish outside $U$ (details for extending $\varphi V$ is in here : Using Gluing Lemma for Smooth Functions ). Finally defined vector field along $\gamma$ by restrict the global vector field above to the image of $\gamma$ in $M$. I've been thinking some easier way (i'm not sure its correct or not). First we choose a appropriate small neighbourhood of $a_i$ in the domain of $\gamma : I \rightarrow M$, say $U \subset I$ such that $U$ does not contain $a_j$ for $j \neq i$. Choose a bump function $\varphi$ supported in $U$. Parallel translate the vector $\Delta_i \dot{\gamma}$ at $\gamma(a_i)$ along all portion of $\gamma(I)$, called this vector field $V$. Multiplied the resulting vector field by $\varphi$. The result is the vector field along $\gamma$, $\varphi V$, with the property that we needed, which is vanish for all $\gamma(a_j)$ for $j\neq i$ Any one can suggest another way (or correct way) to construct such vector field ? Thank you.","I get a little confused by the details of the following theorem from John Lee's book Riemannian Manifold page 100. It basically about construction of vector field along a piecewise smooth curve using smooth bump function. Let $\gamma : [a,b] \rightarrow M$ be piecewise smooth curve (i.e there are subdivision $a_0=a<a_1<...<a_{n-1}<a_n=b$ s.t $\gamma_{[a_i,a_{i+1}]}$ is smooth). Now we want a vector field $V : [a,b] \rightarrow M$ along $\gamma$ such that at a point in the ""corner"", say at $\gamma(a_i)$ for $0<i<n$, $V$ having a particular value, say $V(a_i)=V_i$, but at any other corner $a_j (j\neq i)$, $V(a_j)=0$. This particular construction arise from the following proof. $\textbf{Theorem 6.6.}$ Every minimizing curve is a geodesic when it is given a unit speed parametrization   The idea is to use First Variation Formula    \begin{equation} \frac{d}{ds}\Bigg|_{s=0} L(\Gamma_s) = -\int_a^b \langle V,D_t\dot{\gamma} \rangle dt - \sum_{i=1}^{k-1} \langle V(a_i), \Delta_i\dot{\gamma} \rangle \end{equation}   to show that the initial piecewise curve $\gamma$ satisfying the hypothesis (minimizing and unit speed) is a broken geodesic, that is $D_t \dot{\gamma} \equiv 0$ on each subdivision where its smooth, and to show that it has no corners, that is $\Delta_i \dot{\gamma} = 0$ for all $i$. My trouble is to follow the second step. It is says that to show $\Delta_i \dot{\gamma} = 0$, we can use a smooth bump function in a coordinate chart to construct a vector field $V$ along $\gamma$ such that $V(a_i)=\Delta_i \dot{\gamma}$ and $V(a_j)=0$ for all $j\neq i$. After a lot of thinking i already did such construction but not sure it is right. I worried because the similar proof for the above theorem in another text like do Carmo (Riemannian Geometry, Ch.9 prop 2.5 p.196) does not show either how to construct such vector field. Here is my ideas : Choose a small neighbourhood $U$ of $\gamma (a_i)$ such that it does not contain any other points $\gamma(a_j)$ except for $j=i$. Build a local vector field $V$ such that $V$ is constant with the constant coefficient equal to $\Delta_i \dot{\gamma}$. Choose a bump function $\varphi$ supported in $U$ such that $\varphi(\gamma(a_i)) = 1$. Restrict $\varphi$ to $U$ and multiplied it by $V$. Therefore we have a vector field $\varphi V$ defined in $U$. By Gluing lemma for smooth map we can extend $\varphi V$ to the whole $M$ such that $\varphi V$ vanish outside $U$ (details for extending $\varphi V$ is in here : Using Gluing Lemma for Smooth Functions ). Finally defined vector field along $\gamma$ by restrict the global vector field above to the image of $\gamma$ in $M$. I've been thinking some easier way (i'm not sure its correct or not). First we choose a appropriate small neighbourhood of $a_i$ in the domain of $\gamma : I \rightarrow M$, say $U \subset I$ such that $U$ does not contain $a_j$ for $j \neq i$. Choose a bump function $\varphi$ supported in $U$. Parallel translate the vector $\Delta_i \dot{\gamma}$ at $\gamma(a_i)$ along all portion of $\gamma(I)$, called this vector field $V$. Multiplied the resulting vector field by $\varphi$. The result is the vector field along $\gamma$, $\varphi V$, with the property that we needed, which is vanish for all $\gamma(a_j)$ for $j\neq i$ Any one can suggest another way (or correct way) to construct such vector field ? Thank you.",,"['differential-geometry', 'riemannian-geometry', 'smooth-manifolds', 'vector-fields']"
98,Does any Riemannian manifold admit Ricci flow and Ricci soliton? [closed],Does any Riemannian manifold admit Ricci flow and Ricci soliton? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I started studying Ricci flow and Ricci soliton (personally) and I have read some basic content of Ricci flow. I want to know the following: Does any Riemannian manifold admit Ricci flow and Ricci soliton? Is there difference between  the Ricci flow and the Ricci soliton? Thanks.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I started studying Ricci flow and Ricci soliton (personally) and I have read some basic content of Ricci flow. I want to know the following: Does any Riemannian manifold admit Ricci flow and Ricci soliton? Is there difference between  the Ricci flow and the Ricci soliton? Thanks.",,"['differential-geometry', 'riemannian-geometry', 'ricci-flow']"
99,Distance in modified cylindrical coordinates,Distance in modified cylindrical coordinates,,"Cylindrical coordinates infinitesimal distance is given by: $d^2s = d^2z + d^2r + r^2 d^2θ$ And formula for squared distance between two points $(θ_1, r_1, z_1)$ and $(θ_2, r_2, z_2)$ is: $distance^2 = (z_2 - z_1)^2 + r_1^2 + r_2^2 - 2 r_1 r_2 \cos(θ_2 - θ_1)$ I need to find distance between two points $(θ_1, r_1, z_1)$ and $(θ_2, r_2, z_2)$ when infinitesimal distance is: $d^2s = d^2z + f^2(z) d^2r + f^2(z) r^2 d^2θ$ Essentially, $f(z)$ used for scaling to capture intuition that at certain values of $z$, distance depends only on $z$ ($f(z) = 0$ at this points, but it is positive otherwise).","Cylindrical coordinates infinitesimal distance is given by: $d^2s = d^2z + d^2r + r^2 d^2θ$ And formula for squared distance between two points $(θ_1, r_1, z_1)$ and $(θ_2, r_2, z_2)$ is: $distance^2 = (z_2 - z_1)^2 + r_1^2 + r_2^2 - 2 r_1 r_2 \cos(θ_2 - θ_1)$ I need to find distance between two points $(θ_1, r_1, z_1)$ and $(θ_2, r_2, z_2)$ when infinitesimal distance is: $d^2s = d^2z + f^2(z) d^2r + f^2(z) r^2 d^2θ$ Essentially, $f(z)$ used for scaling to capture intuition that at certain values of $z$, distance depends only on $z$ ($f(z) = 0$ at this points, but it is positive otherwise).",,"['calculus', 'differential-geometry', 'coordinate-systems']"
