,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Tautological 1-form: Lectures on Symplectic Geometry,Tautological 1-form: Lectures on Symplectic Geometry,,"I am referring to page 10 of da Silva's Lectures on Symplectic Geometry. In particular, the exercise asks to show that $\alpha$ is tautological one-form if and only if for every one-form $\mu:X\to T*X$, we have $\mu^*\alpha=\mu$. Here $X$ is the base manifold, and $\alpha_p$ is a covector on the cotangent space of the cotangent bundle , i.e. $\alpha_p\in T_p^*(T^*X)$. I want to find a way to do this in coordinate-free and coordinate-dependent ways. What I am struggling to see is the meaning of $\mu^*$. Usually, e.g. in case of vector fields, the tangent map $T_pF$ induced by a smooth map $F$ has then effect on vector field $v$ such that \begin{equation} T_pF(v)(f)=v(f\circ F) \end{equation}  which can be written as pull-back map \begin{equation} T_pF(v)=v\circ F^* \end{equation} In other words, $f\circ F=F^*\circ f$. However in this case I cannot see what $\mu^*$ should be. I do know that one can see one-forms as just a map and hence we could imagine making a pull-back out of it. But it's a pullback of what to what? For coordinate-dependent one, I am essentially stuck at the step which sources like Wikipedia does: \begin{equation} \beta ^{*}\theta =\beta ^{*}(\sum _{i}p_{i}\,dq^{i})=\sum _{i}\beta ^{*}p_{i}\,dq^{i}=\sum _{i}\beta _{i}\,dq^{i}=\beta . \end{equation} I do not see at all why $\beta^*p_i=\beta_i$. I suspect this is again a problem of identifying which one-form belongs to which space, but I am not clear about this. Would be great to see if this problem can be solved in both ways.","I am referring to page 10 of da Silva's Lectures on Symplectic Geometry. In particular, the exercise asks to show that $\alpha$ is tautological one-form if and only if for every one-form $\mu:X\to T*X$, we have $\mu^*\alpha=\mu$. Here $X$ is the base manifold, and $\alpha_p$ is a covector on the cotangent space of the cotangent bundle , i.e. $\alpha_p\in T_p^*(T^*X)$. I want to find a way to do this in coordinate-free and coordinate-dependent ways. What I am struggling to see is the meaning of $\mu^*$. Usually, e.g. in case of vector fields, the tangent map $T_pF$ induced by a smooth map $F$ has then effect on vector field $v$ such that \begin{equation} T_pF(v)(f)=v(f\circ F) \end{equation}  which can be written as pull-back map \begin{equation} T_pF(v)=v\circ F^* \end{equation} In other words, $f\circ F=F^*\circ f$. However in this case I cannot see what $\mu^*$ should be. I do know that one can see one-forms as just a map and hence we could imagine making a pull-back out of it. But it's a pullback of what to what? For coordinate-dependent one, I am essentially stuck at the step which sources like Wikipedia does: \begin{equation} \beta ^{*}\theta =\beta ^{*}(\sum _{i}p_{i}\,dq^{i})=\sum _{i}\beta ^{*}p_{i}\,dq^{i}=\sum _{i}\beta _{i}\,dq^{i}=\beta . \end{equation} I do not see at all why $\beta^*p_i=\beta_i$. I suspect this is again a problem of identifying which one-form belongs to which space, but I am not clear about this. Would be great to see if this problem can be solved in both ways.",,"['differential-geometry', 'symplectic-geometry']"
1,"How to compute the pullback of $(2xy+x^{2}+1)dx+(x^{2}-y)dy$ along $f(u,v,w)=(u-v,v^{2}-w)$?",How to compute the pullback of  along ?,"(2xy+x^{2}+1)dx+(x^{2}-y)dy f(u,v,w)=(u-v,v^{2}-w)","I'm trying to do my first pull-back of a differential form. I know that $\omega=(2xy+x^{2}+1)dx+(x^{2}-y)dy$ is a differential form on $\mathbb{R}^{2}$. I have $f : \mathbb{R}^{3} \to \mathbb{R}^{2}$ which is $$f(u,v,w)=(u-v,v^{2}-w)$$ and I have to calculate the pullback. I was told that by definition $$(f^{*}\omega)(X) = \omega(f_{*}(X)),$$ and so I calculated  $$f_{*}=\begin{pmatrix} 1 & -1 & 0\\ 0 & 2v & 1 \end{pmatrix}$$ But then I don't really know how to proceed. Should I take a general vector and calculate the form, should I substitute $x,y$ with $u,v,w$? Do you have a general recipe to proceed?","I'm trying to do my first pull-back of a differential form. I know that $\omega=(2xy+x^{2}+1)dx+(x^{2}-y)dy$ is a differential form on $\mathbb{R}^{2}$. I have $f : \mathbb{R}^{3} \to \mathbb{R}^{2}$ which is $$f(u,v,w)=(u-v,v^{2}-w)$$ and I have to calculate the pullback. I was told that by definition $$(f^{*}\omega)(X) = \omega(f_{*}(X)),$$ and so I calculated  $$f_{*}=\begin{pmatrix} 1 & -1 & 0\\ 0 & 2v & 1 \end{pmatrix}$$ But then I don't really know how to proceed. Should I take a general vector and calculate the form, should I substitute $x,y$ with $u,v,w$? Do you have a general recipe to proceed?",,"['differential-geometry', 'differential-forms']"
2,How big are regular (hyperbolic) polygons?,How big are regular (hyperbolic) polygons?,,"Given a hyperbolic surface of constant curvature $K=-1/a^2$ embedded in $\mathbb{R}^3$, is there a known formula for the length of the edges of a  regular polygon? I know that the Gauss–Bonnet theorem tells us that the area of an $n$-gon is given by: $$A=(n-2)\pi-\sum_{i=1}^n \alpha_i = n(\pi-\alpha) - 2\pi$$ But i'm not sure how one would go about calculating the edge length without explicitly specifying the surface. Is an explicit formula even possible?","Given a hyperbolic surface of constant curvature $K=-1/a^2$ embedded in $\mathbb{R}^3$, is there a known formula for the length of the edges of a  regular polygon? I know that the Gauss–Bonnet theorem tells us that the area of an $n$-gon is given by: $$A=(n-2)\pi-\sum_{i=1}^n \alpha_i = n(\pi-\alpha) - 2\pi$$ But i'm not sure how one would go about calculating the edge length without explicitly specifying the surface. Is an explicit formula even possible?",,"['differential-geometry', 'surfaces', 'hyperbolic-geometry', 'geodesic']"
3,"Diffeomorphism between the Grassmannian manifolds $\mathbf{Gr}(n,k)$ and $\mathbf{Gr}(n,n-k)$.",Diffeomorphism between the Grassmannian manifolds  and .,"\mathbf{Gr}(n,k) \mathbf{Gr}(n,n-k)","This seems to be a common exercise question, however I am having trouble with it. The hint is to use a map that associates the k-plane to its orthogonal complement. But I have not been able to show this as a diffeomorphism. I was thinking of using the orthonormal basis and extending it to get a basis of $\mathbb{R}^n$, then using the remaining $n-k$ vectors to generate the orthogonal complement. Am I on the right path??How else should I approach this otherwise??","This seems to be a common exercise question, however I am having trouble with it. The hint is to use a map that associates the k-plane to its orthogonal complement. But I have not been able to show this as a diffeomorphism. I was thinking of using the orthonormal basis and extending it to get a basis of $\mathbb{R}^n$, then using the remaining $n-k$ vectors to generate the orthogonal complement. Am I on the right path??How else should I approach this otherwise??",,"['differential-geometry', 'manifolds']"
4,Unit circle can't be covered by one chart,Unit circle can't be covered by one chart,,"I am hoping that someone can give me a proof showing why the unit circle cannot be covered by one coordinate chart, or a reference where I can find a proof.","I am hoping that someone can give me a proof showing why the unit circle cannot be covered by one coordinate chart, or a reference where I can find a proof.",,"['reference-request', 'differential-geometry', 'manifolds', 'circles']"
5,Proof: Force always perpendicular and motion in a plane implies that the trajectory is a circle,Proof: Force always perpendicular and motion in a plane implies that the trajectory is a circle,,"I am looking for a proof for a physics problem. Consider a particle which is subject to a force $\vec{F}(t)$ with $|\vec{F}(t)| = \text{const}$ which is always perpendicular to the velocity $\vec{v}(t)$. Further assume that the motion takes places in a plane. To put it in a mathematical problem: Let $x\colon \mathbb{R} \to \mathbb{R}^2$ (2 because of the ""plane"" condition) be smooth. Suppose $<x''(t),x'(t)>= 0$ for all $t$ and $|x''(t)| = \text{const}$. Then $x(\mathbb{R})$ is a circle. $<\cdot,\cdot>$ denotes the standard scalar product on $\mathbb{R}^2$ and $'$ the derivative. How to prove this? Does the theorem remains correct if one drops the assumption $|x''(t)| = \text{const}$? Note this is not a homework problem, I just want to know how to prove this physical result mathematically. In physics books the statement above is claimed sometimes, but in every instance I have seen they proved just the logically converse statement.","I am looking for a proof for a physics problem. Consider a particle which is subject to a force $\vec{F}(t)$ with $|\vec{F}(t)| = \text{const}$ which is always perpendicular to the velocity $\vec{v}(t)$. Further assume that the motion takes places in a plane. To put it in a mathematical problem: Let $x\colon \mathbb{R} \to \mathbb{R}^2$ (2 because of the ""plane"" condition) be smooth. Suppose $<x''(t),x'(t)>= 0$ for all $t$ and $|x''(t)| = \text{const}$. Then $x(\mathbb{R})$ is a circle. $<\cdot,\cdot>$ denotes the standard scalar product on $\mathbb{R}^2$ and $'$ the derivative. How to prove this? Does the theorem remains correct if one drops the assumption $|x''(t)| = \text{const}$? Note this is not a homework problem, I just want to know how to prove this physical result mathematically. In physics books the statement above is claimed sometimes, but in every instance I have seen they proved just the logically converse statement.",,"['differential-geometry', 'physics', 'vector-analysis']"
6,Showing Jacobi identity for Poisson Bracket,Showing Jacobi identity for Poisson Bracket,,"We were given the following problem: show that $[A,[B,C]] + [B,[C,A]] + [C,[A,B]] = 0$ where $[A,[B,C]]$ et cetera are Poisson brackets. As I understand it this is a poisson bracket (where $\mathcal{H}$ is the Hamiltonian): $$\sum_i \left(\frac{\partial f}{\partial q_i} \frac{\partial \mathcal H}{\partial p_i} - \frac{\partial f}{\partial p_i} \frac{\partial \mathcal H}{\partial q_i} \right)$$ Well and good, that means, for example, that $[B,C]$ would be: $$ \sum_i \left(\frac{\partial B}{\partial q_i} \frac{\partial C}{\partial p_i} - \frac{\partial B}{\partial p_i} \frac{\partial C}{\partial q_i} \right) $$ and $[A,[B,C]]$ would be $$\sum_{i,j} \frac{\partial A}{\partial q_j}\frac{\partial}{\partial p_j}\left(\frac{\partial B}{\partial q_i} \frac{\partial C}{\partial p_i} - \frac{\partial B}{\partial p_i} \frac{\partial C}{\partial q_i} \right)-\frac{\partial A}{\partial p_j}\frac{\partial}{\partial q_j}\left(\frac{\partial B}{\partial q_i} \frac{\partial C}{\partial p_i} - \frac{\partial B}{\partial p_i} \frac{\partial C}{\partial q_i} \right)$$ Multiplying this all out and taking the derivatives  $$\sum_{i,j} \frac{\partial A}{\partial q_j}\left(\frac{\partial^2C}{\partial p_j p_i}\frac{\partial B}{\partial q_i} + \frac{\partial^2B}{\partial p_j q_i}\frac{\partial C}{\partial p_i}  - \frac{\partial^2 B}{\partial p_i p_j} \frac{\partial C}{\partial q_i} + \frac{\partial B}{\partial p_i} \frac{\partial^2 C}{\partial q_i} \right)-\frac{\partial A}{\partial p_j}\left(\frac{\partial B}{\partial q_i} \frac{\partial^2 C}{\partial p_i q_j} + \frac{\partial^2 B}{\partial q_i q_j} \frac{\partial C}{\partial p_i} - \frac{\partial^2 B}{\partial p_i q_j} \frac{\partial C}{\partial q_i} + \frac{\partial B}{\partial p_i } \frac{\partial^2 C}{\partial q_i q_j}\right)$$ its hard to keep track of this. So I figure that there has to be an easier way to do this, at least notation-wise. I have seen some other notations but there's never any explanation and I might be able to follow them if I understood what I was seeing. So for non-mathematicians who are seeing this in a physics class, if there are any suggestions as to a better notational system that would be most appreciated. I'm not really even sure what tags to put on this...","We were given the following problem: show that $[A,[B,C]] + [B,[C,A]] + [C,[A,B]] = 0$ where $[A,[B,C]]$ et cetera are Poisson brackets. As I understand it this is a poisson bracket (where $\mathcal{H}$ is the Hamiltonian): $$\sum_i \left(\frac{\partial f}{\partial q_i} \frac{\partial \mathcal H}{\partial p_i} - \frac{\partial f}{\partial p_i} \frac{\partial \mathcal H}{\partial q_i} \right)$$ Well and good, that means, for example, that $[B,C]$ would be: $$ \sum_i \left(\frac{\partial B}{\partial q_i} \frac{\partial C}{\partial p_i} - \frac{\partial B}{\partial p_i} \frac{\partial C}{\partial q_i} \right) $$ and $[A,[B,C]]$ would be $$\sum_{i,j} \frac{\partial A}{\partial q_j}\frac{\partial}{\partial p_j}\left(\frac{\partial B}{\partial q_i} \frac{\partial C}{\partial p_i} - \frac{\partial B}{\partial p_i} \frac{\partial C}{\partial q_i} \right)-\frac{\partial A}{\partial p_j}\frac{\partial}{\partial q_j}\left(\frac{\partial B}{\partial q_i} \frac{\partial C}{\partial p_i} - \frac{\partial B}{\partial p_i} \frac{\partial C}{\partial q_i} \right)$$ Multiplying this all out and taking the derivatives  $$\sum_{i,j} \frac{\partial A}{\partial q_j}\left(\frac{\partial^2C}{\partial p_j p_i}\frac{\partial B}{\partial q_i} + \frac{\partial^2B}{\partial p_j q_i}\frac{\partial C}{\partial p_i}  - \frac{\partial^2 B}{\partial p_i p_j} \frac{\partial C}{\partial q_i} + \frac{\partial B}{\partial p_i} \frac{\partial^2 C}{\partial q_i} \right)-\frac{\partial A}{\partial p_j}\left(\frac{\partial B}{\partial q_i} \frac{\partial^2 C}{\partial p_i q_j} + \frac{\partial^2 B}{\partial q_i q_j} \frac{\partial C}{\partial p_i} - \frac{\partial^2 B}{\partial p_i q_j} \frac{\partial C}{\partial q_i} + \frac{\partial B}{\partial p_i } \frac{\partial^2 C}{\partial q_i q_j}\right)$$ its hard to keep track of this. So I figure that there has to be an easier way to do this, at least notation-wise. I have seen some other notations but there's never any explanation and I might be able to follow them if I understood what I was seeing. So for non-mathematicians who are seeing this in a physics class, if there are any suggestions as to a better notational system that would be most appreciated. I'm not really even sure what tags to put on this...",,"['differential-geometry', 'mathematical-physics', 'symplectic-geometry']"
7,"For covariant tensors, why is it $\bigwedge^k(V)$, not $\bigwedge^k(V^*)$?","For covariant tensors, why is it , not ?",\bigwedge^k(V) \bigwedge^k(V^*),"In learning the very basics of differential geometry, I have seen the exterior product defined a couple of ways: First, I have seen it as the image of the covariant tensors (which I believe are essentially the $k$-fold tensor product of $V^*$ with itself) transformed by the mapping ""Alt"". Second, I have seen it defined somewhat more abstractly as the $k$-fold tensor product of $V$ with itself, modulo certain relations which make it anti-symmetric. (However, at this early stage it seems we have no need for contravariant tensors.) In either case, we write it $\bigwedge^k(V)$. Since we are focusing on covariant tensors, why do we not write $\bigwedge^k(V^*)$? Is there something I am missing which makes these two equivalent?","In learning the very basics of differential geometry, I have seen the exterior product defined a couple of ways: First, I have seen it as the image of the covariant tensors (which I believe are essentially the $k$-fold tensor product of $V^*$ with itself) transformed by the mapping ""Alt"". Second, I have seen it defined somewhat more abstractly as the $k$-fold tensor product of $V$ with itself, modulo certain relations which make it anti-symmetric. (However, at this early stage it seems we have no need for contravariant tensors.) In either case, we write it $\bigwedge^k(V)$. Since we are focusing on covariant tensors, why do we not write $\bigwedge^k(V^*)$? Is there something I am missing which makes these two equivalent?",,"['differential-geometry', 'tensor-products', 'tensors', 'multilinear-algebra']"
8,Concerning the tangent space of an exotic $\mathbb R^4$,Concerning the tangent space of an exotic,\mathbb R^4,"My geometric intuition is very poor, so my naive approach to this question is ""if $M$ is an exotic $\mathbb R^4$, then $TM$ must be something like $\mathbb R^8$, which is not exotic"". Of course, my statement ""like $\mathbb R^8$ "" is probably rubbish. So, my concrete question is: is the tangent space of an exotic $\mathbb R^4$ a ""nice"" manifold? I personally don't consider exotic manifolds ""nice"" (again, because of my poor geometric intuition, though certainly they are very respectable objects of study). I am open-minded about what manifolds a topologist would regard as ""nice"".","My geometric intuition is very poor, so my naive approach to this question is ""if $M$ is an exotic $\mathbb R^4$, then $TM$ must be something like $\mathbb R^8$, which is not exotic"". Of course, my statement ""like $\mathbb R^8$ "" is probably rubbish. So, my concrete question is: is the tangent space of an exotic $\mathbb R^4$ a ""nice"" manifold? I personally don't consider exotic manifolds ""nice"" (again, because of my poor geometric intuition, though certainly they are very respectable objects of study). I am open-minded about what manifolds a topologist would regard as ""nice"".",,"['differential-geometry', 'manifolds']"
9,How to show something is a contraction?,How to show something is a contraction?,,"If we let $X$ be a complete metric space, and let $S:X\to X$ be a map, such that $S^m$ is a contraction. We now want to show, that $S$ has a unique fixed point This is what I've thought so far: Due to Banachs fixed point theorem is it enough to show, that $S$ is a contraction. Due to $S^m$ being a contraction, we know this about $S^m$(the definition of being a contraction): $$\exists\beta, 0\le\beta\lt1:d(S^mx,S^my)\le\beta d(x,y),\forall x,y\in X$$ I'm not really sure how to show that S is a contraction.. Any ideas ad to how to approach this?","If we let $X$ be a complete metric space, and let $S:X\to X$ be a map, such that $S^m$ is a contraction. We now want to show, that $S$ has a unique fixed point This is what I've thought so far: Due to Banachs fixed point theorem is it enough to show, that $S$ is a contraction. Due to $S^m$ being a contraction, we know this about $S^m$(the definition of being a contraction): $$\exists\beta, 0\le\beta\lt1:d(S^mx,S^my)\le\beta d(x,y),\forall x,y\in X$$ I'm not really sure how to show that S is a contraction.. Any ideas ad to how to approach this?",,"['differential-geometry', 'fixed-point-theorems']"
10,parallel vectors along a curve,parallel vectors along a curve,,"What does it mean for a vector field X(t) to be parallel along a curve, gamma(t)? and how can we show that if X(t) is parallel along gamma(t), then |X(t)| is constant? Thanks","What does it mean for a vector field X(t) to be parallel along a curve, gamma(t)? and how can we show that if X(t) is parallel along gamma(t), then |X(t)| is constant? Thanks",,['differential-geometry']
11,Implicit function theorem,Implicit function theorem,,"Suppose I have the curve $\gamma: \mathbb{R} \rightarrow \mathbb{R}^2$ given by $\gamma: t \mapsto (\gamma_1(t),\gamma_2(t)) =(t^2,t)$. If I want to apply the implicit function theorem to this to see if  $\gamma_1$ can be expressed in $\gamma_2$ at $t=0$ then I need to show that $d \gamma_2 / d \gamma_1$ is non-zero. However, $d \gamma_2 / d \gamma_1 \rightarrow \infty $ for  $t \rightarrow 0$. So in these cases you cannot apply the implicit function theorem? Or can I just compactify the plane by ""adding the point at infinity"" and then apply the implicit function theorem.","Suppose I have the curve $\gamma: \mathbb{R} \rightarrow \mathbb{R}^2$ given by $\gamma: t \mapsto (\gamma_1(t),\gamma_2(t)) =(t^2,t)$. If I want to apply the implicit function theorem to this to see if  $\gamma_1$ can be expressed in $\gamma_2$ at $t=0$ then I need to show that $d \gamma_2 / d \gamma_1$ is non-zero. However, $d \gamma_2 / d \gamma_1 \rightarrow \infty $ for  $t \rightarrow 0$. So in these cases you cannot apply the implicit function theorem? Or can I just compactify the plane by ""adding the point at infinity"" and then apply the implicit function theorem.",,['differential-geometry']
12,Continuity equation on manifolds,Continuity equation on manifolds,,"Mass conservation is usually written as $$\frac{\partial \rho}{\partial t} + \operatorname{div}(\rho \boldsymbol v) = 0$$ $\rho$ is the density and $\boldsymbol v$ is the fluid velocity. My attempt to rewrite it in notions used in differential geometry: $$\frac{\partial \rho}{\partial t} + \star\, \text{d} \star (\rho v^\flat) = 0$$ But I have a doubt that it may have another form, probably like in classical mechanics Liouville equation. Maybe there is a book or something about fluid dynamics on manifolds? (I've asked this last question on Physics.SE, but if somebody knows it here let me know).","Mass conservation is usually written as $$\frac{\partial \rho}{\partial t} + \operatorname{div}(\rho \boldsymbol v) = 0$$ $\rho$ is the density and $\boldsymbol v$ is the fluid velocity. My attempt to rewrite it in notions used in differential geometry: $$\frac{\partial \rho}{\partial t} + \star\, \text{d} \star (\rho v^\flat) = 0$$ But I have a doubt that it may have another form, probably like in classical mechanics Liouville equation. Maybe there is a book or something about fluid dynamics on manifolds? (I've asked this last question on Physics.SE, but if somebody knows it here let me know).",,"['differential-geometry', 'fluid-dynamics', 'mathematical-physics']"
13,Relation between uniform convergence of curves in a manifold and homotopy,Relation between uniform convergence of curves in a manifold and homotopy,,"I was working through some things in riemannian geometry and I had this doubt: Let $M$ be a closed riemannian manifold, $H$ an embedded submanifold and $V$ be its $\varepsilon$-tubular neighborhood. Consider a sequence of continuous curves $\sigma_{l}:[0,1] \rightarrow M\setminus V$. Suppose that the sequence converges uniformly to a continuous curve  $\sigma:[0,1]\rightarrow M\setminus V$.  Can I assume that $\sigma$ is homotopic to some $\sigma_l$ for $l$ large enough?","I was working through some things in riemannian geometry and I had this doubt: Let $M$ be a closed riemannian manifold, $H$ an embedded submanifold and $V$ be its $\varepsilon$-tubular neighborhood. Consider a sequence of continuous curves $\sigma_{l}:[0,1] \rightarrow M\setminus V$. Suppose that the sequence converges uniformly to a continuous curve  $\sigma:[0,1]\rightarrow M\setminus V$.  Can I assume that $\sigma$ is homotopic to some $\sigma_l$ for $l$ large enough?",,"['differential-geometry', 'riemannian-geometry', 'homotopy-theory']"
14,Differential form is closed if the integral over a curve is rational number.,Differential form is closed if the integral over a curve is rational number.,,"The following problem comes from do Carmo's book Differential Forms and Applications , Chapter 2, Exercise 4: Let $\omega$ be a differentiable 1-from defined on an open subset $U\subset \mathbb{R}^n$. Assume that for each closed differential curve $C$ in $C$, $\int_C \omega$ is a rational number. Prove that $\omega$ is closed. Can anyone give some hints? My idea was that we could try to show the integral vanishes if the curve lies in $N_\epsilon (p)$ (i.e. a small neighborhood around $p$) for any $p$ in $U$ and use the Poincare Lemma, but failed.","The following problem comes from do Carmo's book Differential Forms and Applications , Chapter 2, Exercise 4: Let $\omega$ be a differentiable 1-from defined on an open subset $U\subset \mathbb{R}^n$. Assume that for each closed differential curve $C$ in $C$, $\int_C \omega$ is a rational number. Prove that $\omega$ is closed. Can anyone give some hints? My idea was that we could try to show the integral vanishes if the curve lies in $N_\epsilon (p)$ (i.e. a small neighborhood around $p$) for any $p$ in $U$ and use the Poincare Lemma, but failed.",,['differential-geometry']
15,Curves have no intrinsic geometry,Curves have no intrinsic geometry,,"Please someone could explain me why the curves have no intrinsic geometry? With surfaces I can see that there are two kind of geometries, i.e. the euclidean one (related to euclidean isometries) and the intrinsic (related to isometries on surfaces), but I am not able to make a comparison/analogy with curves. Thanks.","Please someone could explain me why the curves have no intrinsic geometry? With surfaces I can see that there are two kind of geometries, i.e. the euclidean one (related to euclidean isometries) and the intrinsic (related to isometries on surfaces), but I am not able to make a comparison/analogy with curves. Thanks.",,[]
16,Surface area of a flexible tube,Surface area of a flexible tube,,"Consider the hollow tube formed by sweeping a circle of radius $r(t)$ along a curve $\gamma(t)$ in $\mathbb{R}^3$; in other words, the set of points $$S=\{\gamma(t) + r(t) \hat{n}\quad \vert\quad \|\hat n\| = 1, \hat{n}\cdot \gamma'(t) = 0, t \in [a,b]\}.$$ What is the surface area of this tube? There are some easy special cases: when $\gamma$ is a straight line, $S$ is a surface of revolution. When $r$ is constant and $\gamma$ is a circle, $S$ is a torus -- and, surprisingly, the surface area of this torus is the same as if we ""straightened"" the centerline of the tube, turning the torus into a cylinder! Does a similar result hold generally?","Consider the hollow tube formed by sweeping a circle of radius $r(t)$ along a curve $\gamma(t)$ in $\mathbb{R}^3$; in other words, the set of points $$S=\{\gamma(t) + r(t) \hat{n}\quad \vert\quad \|\hat n\| = 1, \hat{n}\cdot \gamma'(t) = 0, t \in [a,b]\}.$$ What is the surface area of this tube? There are some easy special cases: when $\gamma$ is a straight line, $S$ is a surface of revolution. When $r$ is constant and $\gamma$ is a circle, $S$ is a torus -- and, surprisingly, the surface area of this torus is the same as if we ""straightened"" the centerline of the tube, turning the torus into a cylinder! Does a similar result hold generally?",,"['differential-geometry', 'surfaces']"
17,"What is the ""typical"" map between surfaces?","What is the ""typical"" map between surfaces?",,"I've seen the concept of map between surfaces $S\to \overline{S}$ and at first, I was extremely confused because I spent a lot of time thinking on how to actually send points from $S$ to $\overline{S}$ ""directly"". I'll try to explain what I mean with the following example: Look at the map $f$ in this example: It is constructed by first inverting $x$ , making a change of coordinates and then computing $x^{*}$ so, this was not ""direct"", it took some ""detours"" in order to be made. Are all the maps we commonly use in differential geometry like this? Are there ways to make ""direct"" maps?","I've seen the concept of map between surfaces and at first, I was extremely confused because I spent a lot of time thinking on how to actually send points from to ""directly"". I'll try to explain what I mean with the following example: Look at the map in this example: It is constructed by first inverting , making a change of coordinates and then computing so, this was not ""direct"", it took some ""detours"" in order to be made. Are all the maps we commonly use in differential geometry like this? Are there ways to make ""direct"" maps?",S\to \overline{S} S \overline{S} f x x^{*},['differential-geometry']
18,"Reading Rovelli's ""General Relativity"" - how to calculate a ""diad""?","Reading Rovelli's ""General Relativity"" - how to calculate a ""diad""?",,"So I'm reading Carlo Rovelli's ""General Relativity"" and there is this notion of ""diad field"" or ""frame field"" that I do not really get. According to Rovelli, given a differentiable manifold $\Sigma$ and a point $p$ on it, one can consider the tangent plane $T_p\Sigma$ and Cartesian coordinates $X^i$ on that plane. Than one can define ""local Cartesian coordinates"" $X^i_p$ by orthogonally projecting the $X^i$ onto the manifold. Let also $x^j$ be general coordinates on $\Sigma$ (here I guess Rovelli means that the $x^j$ are coordinates in an open set of the same dimension of the manifold that are mapped to $\Sigma$ via some diffeomorphism $\varphi$ ). Then the frame field, or ""diad field"" is defined as follows: \begin{equation} e^i_j :=\frac{\partial X^i_p(x^j_p)}{\partial x^j} \end{equation} where $X^i_p$ maps the general coordinates to the local Cartesian coordinates and $x^j_p$ are the coordinates for the point $p$ . I have some problems understanding this definition, and also calculating the actual diad field in some easy cases- i.e. for the paraboloid $z=x^2+y^2$ at a specific point $p$ . Can somebody please explain this concept to me?","So I'm reading Carlo Rovelli's ""General Relativity"" and there is this notion of ""diad field"" or ""frame field"" that I do not really get. According to Rovelli, given a differentiable manifold and a point on it, one can consider the tangent plane and Cartesian coordinates on that plane. Than one can define ""local Cartesian coordinates"" by orthogonally projecting the onto the manifold. Let also be general coordinates on (here I guess Rovelli means that the are coordinates in an open set of the same dimension of the manifold that are mapped to via some diffeomorphism ). Then the frame field, or ""diad field"" is defined as follows: where maps the general coordinates to the local Cartesian coordinates and are the coordinates for the point . I have some problems understanding this definition, and also calculating the actual diad field in some easy cases- i.e. for the paraboloid at a specific point . Can somebody please explain this concept to me?","\Sigma p T_p\Sigma X^i X^i_p X^i x^j \Sigma x^j \Sigma \varphi \begin{equation}
e^i_j :=\frac{\partial X^i_p(x^j_p)}{\partial x^j}
\end{equation} X^i_p x^j_p p z=x^2+y^2 p","['differential-geometry', 'general-relativity', 'tangent-spaces']"
19,Different definitions of the tangent space at a point of a smooth manifold: Biduals?,Different definitions of the tangent space at a point of a smooth manifold: Biduals?,,"There are two different definitions of the tangent space $T_pM$ at a point $p$ of a smooth manifold $M$ . Define $T_pM$ as the set of all equivalence classes of curves (smooth functions) $u : (\mathbb R, 0) \to (M,p)$ , where $u \sim v$ if $u, v$ have the same derivative at $0$ . Define $T_pM$ as the set of all derivations $d : C^\infty(M) \to \mathbb R$ at $p$ . Here $C^\infty(M)$ denotes the set of all smooth functions $M \to \mathbb R$ and a derivation at $p$ has the property $d(f\cdot g) = df \cdot g(p) + f(p)\cdot dg$ . Concerning 1. it is worth to mention that having the same derivative at some point $q$ of a smooth manifold $N$ is an equivalence relation on the set of smooth maps $f : N  \to M$ which can be defined without previously introducing the concepts of tangent spaces and  differentials $d_qf : T_qN  \to T_{f(q)}M$ . It works via charts around $q$ and $f(q)$ . It is well-known that both definitions are equivalent. Definition 1. is certainly more intuitive, but its disadvantage is that there is no ""intrinsic"" definition of a vector space structure on $T_pM$ . Only scalar multiplication has an obvious interpretation on the level of curves, addition has to be defined via using charts and observing that each curve with range in an open subset of $\mathbb R^n$ is equivalent to a ""locally linear curve"" determined by a vector $x \in \mathbb R^n$ . Definition 2. is less intuitive, but its advantage is that the vector space structure on $T_pM$ is provided for free. My question: It seems to me that the tangent space in the sense of 2. is something like the bidual of the tangent space in the sense of 1.  My intuition says that $(T_pM)^*$ is something like equivalence classes of smooth maps $M \to \mathbb R$ (i.e. maps in $C^\infty(M)$ , the equivalence relation again being ""same derivative at $p$ ""), thus $(T_pM)^{**}$ would be something like suitable equivalence classes of maps in $(C^\infty(M))^*$ which could be related to derivations. I have no idea how this could be made precice. Perhaps somebody can do this?","There are two different definitions of the tangent space at a point of a smooth manifold . Define as the set of all equivalence classes of curves (smooth functions) , where if have the same derivative at . Define as the set of all derivations at . Here denotes the set of all smooth functions and a derivation at has the property . Concerning 1. it is worth to mention that having the same derivative at some point of a smooth manifold is an equivalence relation on the set of smooth maps which can be defined without previously introducing the concepts of tangent spaces and  differentials . It works via charts around and . It is well-known that both definitions are equivalent. Definition 1. is certainly more intuitive, but its disadvantage is that there is no ""intrinsic"" definition of a vector space structure on . Only scalar multiplication has an obvious interpretation on the level of curves, addition has to be defined via using charts and observing that each curve with range in an open subset of is equivalent to a ""locally linear curve"" determined by a vector . Definition 2. is less intuitive, but its advantage is that the vector space structure on is provided for free. My question: It seems to me that the tangent space in the sense of 2. is something like the bidual of the tangent space in the sense of 1.  My intuition says that is something like equivalence classes of smooth maps (i.e. maps in , the equivalence relation again being ""same derivative at ""), thus would be something like suitable equivalence classes of maps in which could be related to derivations. I have no idea how this could be made precice. Perhaps somebody can do this?","T_pM p M T_pM u : (\mathbb R, 0) \to (M,p) u \sim v u, v 0 T_pM d : C^\infty(M) \to \mathbb R p C^\infty(M) M \to \mathbb R p d(f\cdot g) = df \cdot g(p) + f(p)\cdot dg q N f : N  \to M d_qf : T_qN  \to T_{f(q)}M q f(q) T_pM \mathbb R^n x \in \mathbb R^n T_pM (T_pM)^* M \to \mathbb R C^\infty(M) p (T_pM)^{**} (C^\infty(M))^*","['differential-geometry', 'tangent-spaces']"
20,Vector field invariant under certain diffeomorphisms,Vector field invariant under certain diffeomorphisms,,This probably should only require elementary differential geometry but somehow I can't seem to prove it. How can I show the vector field $\displaystyle \sum_{i=1}^n x_i \frac{\partial}{\partial x_i}$ on $\mathbb{R}^n$ is invariant under the action of $\mathrm{SO}(n)$ ?,This probably should only require elementary differential geometry but somehow I can't seem to prove it. How can I show the vector field on is invariant under the action of ?,\displaystyle \sum_{i=1}^n x_i \frac{\partial}{\partial x_i} \mathbb{R}^n \mathrm{SO}(n),"['differential-geometry', 'lie-groups', 'vector-fields']"
21,What is the Euler characteristic of a square? (Confusion with Gauss-Bonnet theorem),What is the Euler characteristic of a square? (Confusion with Gauss-Bonnet theorem),,"Highschooler here, trying to learn about the Euler characteristic, Gaussian curvature and the Gauss-Bonnet theorem linking them together. As per the Gauss-Bonnet theorem: total curvature $= 2 \pi \times$ euler characteristic. Here's my confusion. A square (for example a flat sheet of paper) has a Gaussian curvature of zero. But following the formula $\chi = V - E + F$ , I calculate that a square's Euler characteristic is $1$ . This is because vertices $V = 4$ , edges $E = 4$ and faces $F = 1$ . Therefore $\chi = 4 - 4 + 1\Rightarrow \chi = 1$ . So I get the equation $0 = 2\pi  1$ , i.e. $0 = 2\pi$ . Where is my mistake?","Highschooler here, trying to learn about the Euler characteristic, Gaussian curvature and the Gauss-Bonnet theorem linking them together. As per the Gauss-Bonnet theorem: total curvature euler characteristic. Here's my confusion. A square (for example a flat sheet of paper) has a Gaussian curvature of zero. But following the formula , I calculate that a square's Euler characteristic is . This is because vertices , edges and faces . Therefore . So I get the equation , i.e. . Where is my mistake?",= 2 \pi \times \chi = V - E + F 1 V = 4 E = 4 F = 1 \chi = 4 - 4 + 1\Rightarrow \chi = 1 0 = 2\pi  1 0 = 2\pi,"['differential-geometry', 'curvature']"
22,Interpretation of Wikipedia formula relating curvature form and curvature tensor,Interpretation of Wikipedia formula relating curvature form and curvature tensor,,"According to Wikipedia (see here ), the curvature $2$ -form $$ \Omega_{j}^{i} = d\omega_{j}^{i}+\omega_{k}^{i}\wedge\omega_{j}^{k}\, , $$ is related to the Riemann curvature endomorphism by $$ R(X,Y)Z = \nabla_{X}\nabla_{Y}Z + \nabla_{Y}\nabla_{X}Z + \nabla_{[X,Y]}Z = \Omega(X\wedge Y)Z\,. $$ I am confused because $\Omega(X\wedge Y)$ is a function (is not it?), and so it seems that one could conclude that $R(X,Y)Z$ is parallel to $Z$ , which is clearly false. So how should I interpret this equation?","According to Wikipedia (see here ), the curvature -form is related to the Riemann curvature endomorphism by I am confused because is a function (is not it?), and so it seems that one could conclude that is parallel to , which is clearly false. So how should I interpret this equation?","2 
\Omega_{j}^{i} = d\omega_{j}^{i}+\omega_{k}^{i}\wedge\omega_{j}^{k}\, ,
 
R(X,Y)Z = \nabla_{X}\nabla_{Y}Z + \nabla_{Y}\nabla_{X}Z + \nabla_{[X,Y]}Z = \Omega(X\wedge Y)Z\,.
 \Omega(X\wedge Y) R(X,Y)Z Z","['differential-geometry', 'notation']"
23,Differential of a one-form eating a vector?,Differential of a one-form eating a vector?,,"Let $(M,g)$ be a Riemannian manifold with Levi-Civita connection $\nabla$ , and consider a one-form $\alpha\in\Omega^1(M;\mathbb{R})$ and a vector field $X\in\Gamma(TM)$ . Since $\alpha(X)\in C^\infty(M;\mathbb{R})$ we can consider it's differential $d(\alpha(X))$ . Is there a coordinate invariant way to computer this quantity? Maybe something like $d(\alpha(X))(Y) = d\alpha(X,Y) + \alpha(\nabla_{Y}X)$ ? How does this generalize if we consider the differential of the smooth function $\beta(X,Y)$ where $\beta$ is now a 2-form and $X,Y$ are both vector fields?","Let be a Riemannian manifold with Levi-Civita connection , and consider a one-form and a vector field . Since we can consider it's differential . Is there a coordinate invariant way to computer this quantity? Maybe something like ? How does this generalize if we consider the differential of the smooth function where is now a 2-form and are both vector fields?","(M,g) \nabla \alpha\in\Omega^1(M;\mathbb{R}) X\in\Gamma(TM) \alpha(X)\in C^\infty(M;\mathbb{R}) d(\alpha(X)) d(\alpha(X))(Y) = d\alpha(X,Y) + \alpha(\nabla_{Y}X) \beta(X,Y) \beta X,Y","['differential-geometry', 'manifolds', 'differential-forms']"
24,Example of two homotopically equivalent manifolds such that one admits a symplectic structure and the other does not,Example of two homotopically equivalent manifolds such that one admits a symplectic structure and the other does not,,"A smooth manifold $M$ admits a symplectic structure if there is an alternating non degenerate $2$ -form $\omega \in \Lambda^2(M)$ that is also closed i.e. $d\omega = 0.$ Usually we can express obstructions to the existence of certain tensors in terms of vanishing of some cohomology classes. On the other hand, due to the ""integrability"" condition $d\omega = 0$ one should expect that a set of necessary and sufficient condition for $M$ to admit a symplectic structure cannot be expressed just in homological terms. In order to support this guess I  am thus looking for  a concrete example: Find $M_1, M_2 $ (possibly) compact smooth manifolds (of the same dimension) such that $M_1$ is symplectic $M_2$ does not admit a symplectic structure $M_1$ is homotopically equivalent to $M_2$","A smooth manifold admits a symplectic structure if there is an alternating non degenerate -form that is also closed i.e. Usually we can express obstructions to the existence of certain tensors in terms of vanishing of some cohomology classes. On the other hand, due to the ""integrability"" condition one should expect that a set of necessary and sufficient condition for to admit a symplectic structure cannot be expressed just in homological terms. In order to support this guess I  am thus looking for  a concrete example: Find (possibly) compact smooth manifolds (of the same dimension) such that is symplectic does not admit a symplectic structure is homotopically equivalent to","M 2 \omega \in \Lambda^2(M) d\omega = 0. d\omega = 0 M M_1, M_2  M_1 M_2 M_1 M_2","['differential-geometry', 'algebraic-topology', 'differential-topology', 'smooth-manifolds', 'symplectic-geometry']"
25,Surface with prescribed first fundamental form,Surface with prescribed first fundamental form,,"Consider a Riemannian manifold $(S,g)$ of dimension 2.  What can we say about the possibility of an isometric immersion of this surface into $\mathbb{R}^3$? Of course this is not unique, even up to rigid motions (like in the case of zero Gaussian curvature). How can we find at least one of the possible isometries? Do we have a condition for uniqueness? If you want to make it simpler, think about a $U \subset \mathbb{R}^2$ with assigned $g_{ij}\neq \delta_{ij}$ (with respect to the standard Cartesian coordinates).","Consider a Riemannian manifold $(S,g)$ of dimension 2.  What can we say about the possibility of an isometric immersion of this surface into $\mathbb{R}^3$? Of course this is not unique, even up to rigid motions (like in the case of zero Gaussian curvature). How can we find at least one of the possible isometries? Do we have a condition for uniqueness? If you want to make it simpler, think about a $U \subset \mathbb{R}^2$ with assigned $g_{ij}\neq \delta_{ij}$ (with respect to the standard Cartesian coordinates).",,"['differential-geometry', 'riemannian-geometry', 'surfaces', 'curvature', 'isometry']"
26,What if replacing the anticommutativity by commutativity in the definition of Lie algebra?,What if replacing the anticommutativity by commutativity in the definition of Lie algebra?,,"As the definition of Lie algebra in Wikipedia. A Lie algebra is a vector space together with a bilinear map, called Lie bracket, satisfying the alternativity and the Jacobi identity. The alternativity can be replaced by anticommutativity since they are equivalent under the Jacobi identity bilinearity. I know the motivation of this definition. But what's going to happen if we replace the alternativity or anticommutativity by commutativity in the definition? Are there some mathematical notions related to this? I just wonder. Maybe it makes no sense at all. Does anyone know about this? TIA...","As the definition of Lie algebra in Wikipedia. A Lie algebra is a vector space together with a bilinear map, called Lie bracket, satisfying the alternativity and the Jacobi identity. The alternativity can be replaced by anticommutativity since they are equivalent under the Jacobi identity bilinearity. I know the motivation of this definition. But what's going to happen if we replace the alternativity or anticommutativity by commutativity in the definition? Are there some mathematical notions related to this? I just wonder. Maybe it makes no sense at all. Does anyone know about this? TIA...",,"['differential-geometry', 'lie-groups', 'lie-algebras']"
27,Connection compatible with a volume form,Connection compatible with a volume form,,"Let $M$ be a smooth, orientable $n$-manifold and $\eta$ a volume form on $M$. Does there exist a connection $A$ on $TM$ such that  $$\tag{$*$}D\eta=0,$$ where $D$ is the appropriate covariant derivative associated to $A$ on $\Omega^n(M)$? Can one assume $A$ to be symmetric? I have a feeling that if one writes $(*)$ plus the torsion equation and then applies the Frobenius theorem, some local result can be obtained. But that doesn't give global conditions (on $M$ nor $\eta$). A reasonable assumption would be $M$ parallelizable.","Let $M$ be a smooth, orientable $n$-manifold and $\eta$ a volume form on $M$. Does there exist a connection $A$ on $TM$ such that  $$\tag{$*$}D\eta=0,$$ where $D$ is the appropriate covariant derivative associated to $A$ on $\Omega^n(M)$? Can one assume $A$ to be symmetric? I have a feeling that if one writes $(*)$ plus the torsion equation and then applies the Frobenius theorem, some local result can be obtained. But that doesn't give global conditions (on $M$ nor $\eta$). A reasonable assumption would be $M$ parallelizable.",,"['differential-geometry', 'riemannian-geometry']"
28,Is every variation field a Lie derivative of the metric?,Is every variation field a Lie derivative of the metric?,,"$\newcommand{\Vol}{\text{Vol}}$ Let $(M,g)$ be a smooth Riemannian manifold, and let $V \in \Gamma(T^*M \otimes T^*M)$ be symmetric. Is it true that $V=L_Xg$ for some vector field $X \in \Gamma(TM)$? I think the answer is negative, but I have no idea how to show this. (This is a question about whether every section is ""exact"" in a suitable sense). Edit: The global question: The answer is in general no. To understand the question better, let's separate into cases: $M$ is compact. Let $X \in \Gamma(TM)$, and denote by $\phi_t$ its flow. Define $g_t=\phi_t^*g$. Since $$\Vol(M,\phi_t^*g)=\Vol(M,g)=\text{const},$$ we get by differentiating that $$0=\left.\frac{d}{dt}\Vol(M,\phi_t^*g) \right |_{t=0}= \frac{1}{2}\int_M \langle g,\left.\frac{\partial g}{\partial t}\right |_{t=0}\rangle \Vol_g=\frac{1}{2}\int_M \langle g ,L_x g \rangle \Vol_g.$$ So, a necessary condition for $V \in \{ L_xg \, | \, X \in \Gamma(TM) \}$ is $ \int_M \langle g ,V \rangle \Vol_g=0$. Is this condition sufficient? What happens when $M$ is non-compact? Are there any necessary conditions? The local question: In dimension $1$ every variation field is realized in this way. In higher dimensions I guess that is not so; my heuristic is that there are different numbers of degrees of freedom: If $\dim M=d$, then pointwise $\dim(T^*M \otimes T^*M)=d^2$ while $\dim(TM)=d$.","$\newcommand{\Vol}{\text{Vol}}$ Let $(M,g)$ be a smooth Riemannian manifold, and let $V \in \Gamma(T^*M \otimes T^*M)$ be symmetric. Is it true that $V=L_Xg$ for some vector field $X \in \Gamma(TM)$? I think the answer is negative, but I have no idea how to show this. (This is a question about whether every section is ""exact"" in a suitable sense). Edit: The global question: The answer is in general no. To understand the question better, let's separate into cases: $M$ is compact. Let $X \in \Gamma(TM)$, and denote by $\phi_t$ its flow. Define $g_t=\phi_t^*g$. Since $$\Vol(M,\phi_t^*g)=\Vol(M,g)=\text{const},$$ we get by differentiating that $$0=\left.\frac{d}{dt}\Vol(M,\phi_t^*g) \right |_{t=0}= \frac{1}{2}\int_M \langle g,\left.\frac{\partial g}{\partial t}\right |_{t=0}\rangle \Vol_g=\frac{1}{2}\int_M \langle g ,L_x g \rangle \Vol_g.$$ So, a necessary condition for $V \in \{ L_xg \, | \, X \in \Gamma(TM) \}$ is $ \int_M \langle g ,V \rangle \Vol_g=0$. Is this condition sufficient? What happens when $M$ is non-compact? Are there any necessary conditions? The local question: In dimension $1$ every variation field is realized in this way. In higher dimensions I guess that is not so; my heuristic is that there are different numbers of degrees of freedom: If $\dim M=d$, then pointwise $\dim(T^*M \otimes T^*M)=d^2$ while $\dim(TM)=d$.",,"['differential-geometry', 'differential-topology', 'riemannian-geometry', 'calculus-of-variations', 'vector-bundles']"
29,Find a smooth function $f \in C^\infty$ such that $A=f^{-1}(0)$ and $B=f^{-1}(1)$,Find a smooth function  such that  and,f \in C^\infty A=f^{-1}(0) B=f^{-1}(1),"The problem is: Let $A$ and $B$ disjoint closed subsets of a smooth manifold $M$. Show that there exist a function $f \in C^\infty(M)$ such that $A=f^{-1}(0)$ and $B=f^{-1}(1)$. I thought this problem could be solved by using the Smooth Urysohn's Lemma, but can't see how to guarantee that $0 < f(x) < 1$ for all $x\in M\backslash (A\cup B)$. Tips?","The problem is: Let $A$ and $B$ disjoint closed subsets of a smooth manifold $M$. Show that there exist a function $f \in C^\infty(M)$ such that $A=f^{-1}(0)$ and $B=f^{-1}(1)$. I thought this problem could be solved by using the Smooth Urysohn's Lemma, but can't see how to guarantee that $0 < f(x) < 1$ for all $x\in M\backslash (A\cup B)$. Tips?",,"['differential-geometry', 'differential-topology', 'smooth-manifolds']"
30,Looking for an elementary explanation for the existence of spinors,Looking for an elementary explanation for the existence of spinors,,"(Dear mods, I have edited the question. The previous version was probably too confused.) I can convince myself that spinors exist in 2D using complex numbers. The elementary example is a (complex number) $f (\theta) = \exp(i \theta /2)$. When the argument is increased by $2\pi$, it flips sign ($\exp(i (\theta + 2\pi) /2) $ = $-\exp(i \theta /2)$), and requires another rotation of $2\pi$ to bring it back to the original value, and it is therefore a spinor. I want to understand why we can deduce, hopefully in a similarly easy way,  that spinors can exist even in a three (odd-dimensional) space. Thanks","(Dear mods, I have edited the question. The previous version was probably too confused.) I can convince myself that spinors exist in 2D using complex numbers. The elementary example is a (complex number) $f (\theta) = \exp(i \theta /2)$. When the argument is increased by $2\pi$, it flips sign ($\exp(i (\theta + 2\pi) /2) $ = $-\exp(i \theta /2)$), and requires another rotation of $2\pi$ to bring it back to the original value, and it is therefore a spinor. I want to understand why we can deduce, hopefully in a similarly easy way,  that spinors can exist even in a three (odd-dimensional) space. Thanks",,"['differential-geometry', 'lie-groups', 'spin-geometry']"
31,Lie groups where $x \mapsto x^2$ is a diffeomorphism?,Lie groups where  is a diffeomorphism?,x \mapsto x^2,"In every Lie group $G$ the function $x \mapsto x^2$ is a local diffeomorphism in a neighbourhood of the identiy. (This is because its differential is: $v \mapsto 2v$ when considered as a map from $T_eG$ to itself). In some Lie groups it is a global diffeomorphism, for instance in $\mathbb{R}^n$. I would like to find more examples for Lie groups where the square is a global diffeomorphism. Are there any non-abelian groups where this holds?","In every Lie group $G$ the function $x \mapsto x^2$ is a local diffeomorphism in a neighbourhood of the identiy. (This is because its differential is: $v \mapsto 2v$ when considered as a map from $T_eG$ to itself). In some Lie groups it is a global diffeomorphism, for instance in $\mathbb{R}^n$. I would like to find more examples for Lie groups where the square is a global diffeomorphism. Are there any non-abelian groups where this holds?",,"['differential-geometry', 'differential-topology', 'lie-groups', 'smooth-manifolds']"
32,"Möbius band as line bundle over $S^1$, starting from the cocycles","Möbius band as line bundle over , starting from the cocycles",S^1,"The professor asked us to construct a non-trivial line bundle over $S^1$ by giving an open cover of $S^1$ and the cocycles. My idea was to take as open cover $U_1:=S^1\setminus\{0\}$ and $U_2:=S^1\setminus\{\frac{1}{2}\}$. Then, as cocycles, $$ g_{12}:U_1\cap U_2\to\mathbb{R}\\ g_{12}(x)(y):=1-y $$ for every $x\in U_1\cap U_2$, $y\in\mathbb{R}$. I want to verify that I've actually obtained the Möbius band using the ""canonical"" construction starting from the coccycles. Define $E:=\dfrac{(U_1\cup U_2)\times\mathbb{R}}{\sim}$ where $\sim$ is the equivalence relation defined as $$ (p_1,y_1)\sim (p_2,y_2)\iff p_1=p_2,\,\,g_{12}(p_1)(y_2)=y_1 $$ We can rewrite the equivalence relation as $(p,y)\sim(p,1-y)$. But this is not the Möbius band, since I should have gotten $(0,y)\sim(1,1-y)$. What am I doing wrong? For me, the Möbius band is $([0,1]\times\mathbb{R})/\sim$ where $\sim$ is the equivalence relation which identifies the points $(0,y)$ and $(1,1-y)$.","The professor asked us to construct a non-trivial line bundle over $S^1$ by giving an open cover of $S^1$ and the cocycles. My idea was to take as open cover $U_1:=S^1\setminus\{0\}$ and $U_2:=S^1\setminus\{\frac{1}{2}\}$. Then, as cocycles, $$ g_{12}:U_1\cap U_2\to\mathbb{R}\\ g_{12}(x)(y):=1-y $$ for every $x\in U_1\cap U_2$, $y\in\mathbb{R}$. I want to verify that I've actually obtained the Möbius band using the ""canonical"" construction starting from the coccycles. Define $E:=\dfrac{(U_1\cup U_2)\times\mathbb{R}}{\sim}$ where $\sim$ is the equivalence relation defined as $$ (p_1,y_1)\sim (p_2,y_2)\iff p_1=p_2,\,\,g_{12}(p_1)(y_2)=y_1 $$ We can rewrite the equivalence relation as $(p,y)\sim(p,1-y)$. But this is not the Möbius band, since I should have gotten $(0,y)\sim(1,1-y)$. What am I doing wrong? For me, the Möbius band is $([0,1]\times\mathbb{R})/\sim$ where $\sim$ is the equivalence relation which identifies the points $(0,y)$ and $(1,1-y)$.",,"['differential-geometry', 'algebraic-topology', 'vector-bundles', 'fiber-bundles', 'mobius-band']"
33,ricci tensor of 2-sphere $S^2$,ricci tensor of 2-sphere,S^2,Hi could someone show me explicitly how to compute the ricci tensor $g_{ij}$?,Hi could someone show me explicitly how to compute the ricci tensor $g_{ij}$?,,"['differential-geometry', 'riemannian-geometry', 'semi-riemannian-geometry']"
34,When are the eigenvalues of the second fundamental form equal to the principal curvatures?,When are the eigenvalues of the second fundamental form equal to the principal curvatures?,,"I am confused about the following concerning the second fundamental form. Consider a surface $S$ $\subset R^3$ If we consider a chart at a point $p \in S$, $f$: $R^2$$\to S$  and suppose $\partial f/\partial x$ and $\partial f/\partial y$ are orthonormal, Does it then follow that the eigenvalues of the second fundamental form are the principal curvatures and the eigenvectors are the principal directions? Moreover If  $\partial f/\partial x$ and $\partial f/\partial y$ are not orthonormal this may not be true? Thanks in advance","I am confused about the following concerning the second fundamental form. Consider a surface $S$ $\subset R^3$ If we consider a chart at a point $p \in S$, $f$: $R^2$$\to S$  and suppose $\partial f/\partial x$ and $\partial f/\partial y$ are orthonormal, Does it then follow that the eigenvalues of the second fundamental form are the principal curvatures and the eigenvectors are the principal directions? Moreover If  $\partial f/\partial x$ and $\partial f/\partial y$ are not orthonormal this may not be true? Thanks in advance",,['differential-geometry']
35,Expression for codifferential in terms of interior product,Expression for codifferential in terms of interior product,,"Let $(M^n,g)$ be a Riemannian manifold with local orthonormal frame $\{e_1,\ldots,e_n\}$ with dual basis $\{e^1,\ldots,e^n\}$ and with Levi-Civita connection $\nabla$. It can be checked on basis  that $d \colon \Omega^k M \to \Omega^{k+1} M$ can be represented in the form $$    d = \sum_{i=1}^n e^i \wedge \nabla_{e_i}. $$ I have to show that the coddiferential $\delta \colon \Omega^{k+1} M \to \Omega^k M$ can be represented in the form $$    \delta = -\sum_{i=1}^n e_i \, \lrcorner \, \nabla_{e_i}. $$ We have the following formulas: $$    \langle X \, \lrcorner \, \omega, \tau \rangle = \langle \omega, X^\flat \wedge \tau \rangle, \quad X \in TM, \; \omega \in \Lambda^k M, \; \tau \in \Lambda^{k-1} M, $$ and $$ e^i \wedge \nabla_{e_i} \tau = \nabla_{e_i} ( e^i \wedge \tau) - (\nabla_{e_i} e^i) \wedge \tau. $$ Using these formulas we find that $$    \langle e^i \wedge \nabla_{e_i} \tau, \omega \rangle = \langle \nabla_{e_i} (e^i \wedge \tau), \omega \rangle - \langle (\nabla_{e_i} e^i) \wedge  \tau, \omega \rangle \\    = - \langle \tau, e_i \, \lrcorner \, \nabla_{e_i} \omega \rangle - \langle \tau, (\nabla_{e_i} e^i)^\sharp \, \lrcorner \, \omega \rangle. $$ Hence, the last scalar product must always vanish, but I'm not sure that it is always true. Am I missing something?","Let $(M^n,g)$ be a Riemannian manifold with local orthonormal frame $\{e_1,\ldots,e_n\}$ with dual basis $\{e^1,\ldots,e^n\}$ and with Levi-Civita connection $\nabla$. It can be checked on basis  that $d \colon \Omega^k M \to \Omega^{k+1} M$ can be represented in the form $$    d = \sum_{i=1}^n e^i \wedge \nabla_{e_i}. $$ I have to show that the coddiferential $\delta \colon \Omega^{k+1} M \to \Omega^k M$ can be represented in the form $$    \delta = -\sum_{i=1}^n e_i \, \lrcorner \, \nabla_{e_i}. $$ We have the following formulas: $$    \langle X \, \lrcorner \, \omega, \tau \rangle = \langle \omega, X^\flat \wedge \tau \rangle, \quad X \in TM, \; \omega \in \Lambda^k M, \; \tau \in \Lambda^{k-1} M, $$ and $$ e^i \wedge \nabla_{e_i} \tau = \nabla_{e_i} ( e^i \wedge \tau) - (\nabla_{e_i} e^i) \wedge \tau. $$ Using these formulas we find that $$    \langle e^i \wedge \nabla_{e_i} \tau, \omega \rangle = \langle \nabla_{e_i} (e^i \wedge \tau), \omega \rangle - \langle (\nabla_{e_i} e^i) \wedge  \tau, \omega \rangle \\    = - \langle \tau, e_i \, \lrcorner \, \nabla_{e_i} \omega \rangle - \langle \tau, (\nabla_{e_i} e^i)^\sharp \, \lrcorner \, \omega \rangle. $$ Hence, the last scalar product must always vanish, but I'm not sure that it is always true. Am I missing something?",,"['differential-geometry', 'riemannian-geometry']"
36,Computing the exterior derivative of a wedge product,Computing the exterior derivative of a wedge product,,How can we prove the following relation for differentiating the wedge product of a p-form $\alpha_p$ and a q-form $\beta_q$ ? $$d(\alpha_p\wedge\beta _q)=d\alpha_p\wedge\beta_q+(-1)^{p}\alpha_p\wedge d\beta_q$$,How can we prove the following relation for differentiating the wedge product of a p-form and a q-form ?,\alpha_p \beta_q d(\alpha_p\wedge\beta _q)=d\alpha_p\wedge\beta_q+(-1)^{p}\alpha_p\wedge d\beta_q,['differential-geometry']
37,Riemannian metric induced by metric,Riemannian metric induced by metric,,"This seems a very basic and useful construction, and yet I cannot find any reference for it. So my questions are,  1) Is the following definition correct? 2) Is there a simpler construction? 3) Do you know any references where this definition is used/found? Definition: Let $\mathcal{M}$ be a differentiable manifold on which we have a metric $d:\mathcal{M}\times \mathcal{M}\rightarrow \mathbb{R} $ whose square is twice differentiable on the diagonal $\{(p,q)\in \mathcal{M}\times \mathcal{M}\;|\; p=q\}$. We define a Riemannian metric $g$ as follows. Let $p\in\mathcal{M}$ and $X,Y\in T_p\mathcal{M}$. Let $\epsilon>0$ and pick two curves $\gamma_1,\gamma_2: (-\epsilon,\epsilon)\rightarrow \mathcal{M}$ with  $$ \gamma_1(0)=\gamma_2(0)=p, $$ $$ \gamma_1'(0)=X,\quad \gamma_2'(0)=Y. $$ Then, $$g_p(X,Y)=-\frac{1}{2}\frac{\partial^2}{\partial t_1\partial t_2}d^2(\gamma_1(t_1),\gamma_2(t_2)) \Bigg|_{t_1=t_2=0}$$ This works for $X\neq Y$. For $X=Y$ take  $$g_p(X,X)=\frac{\partial^2}{\partial t_1^2}d^2(\gamma_1(t_1),p) \Bigg|_{t_1=0}$$ Remark These formulae work in Euclidean space, i.e. $$\| \gamma_1(t_1)-\gamma_2(t_2)\|^2=t_1^2\|X\|^2+t_2^2\|Y\|^2-2t_1t_2X\cdot Y+...,$$ so taking the 2nd derivatives as specified above will produce the correct scalar products. This leads me to believe that they are correct. However, my first guess was to take the pushforward of $d$, which I couldn't get to work out. What is the interpretation of the above construction in terms of pushforwards?","This seems a very basic and useful construction, and yet I cannot find any reference for it. So my questions are,  1) Is the following definition correct? 2) Is there a simpler construction? 3) Do you know any references where this definition is used/found? Definition: Let $\mathcal{M}$ be a differentiable manifold on which we have a metric $d:\mathcal{M}\times \mathcal{M}\rightarrow \mathbb{R} $ whose square is twice differentiable on the diagonal $\{(p,q)\in \mathcal{M}\times \mathcal{M}\;|\; p=q\}$. We define a Riemannian metric $g$ as follows. Let $p\in\mathcal{M}$ and $X,Y\in T_p\mathcal{M}$. Let $\epsilon>0$ and pick two curves $\gamma_1,\gamma_2: (-\epsilon,\epsilon)\rightarrow \mathcal{M}$ with  $$ \gamma_1(0)=\gamma_2(0)=p, $$ $$ \gamma_1'(0)=X,\quad \gamma_2'(0)=Y. $$ Then, $$g_p(X,Y)=-\frac{1}{2}\frac{\partial^2}{\partial t_1\partial t_2}d^2(\gamma_1(t_1),\gamma_2(t_2)) \Bigg|_{t_1=t_2=0}$$ This works for $X\neq Y$. For $X=Y$ take  $$g_p(X,X)=\frac{\partial^2}{\partial t_1^2}d^2(\gamma_1(t_1),p) \Bigg|_{t_1=0}$$ Remark These formulae work in Euclidean space, i.e. $$\| \gamma_1(t_1)-\gamma_2(t_2)\|^2=t_1^2\|X\|^2+t_2^2\|Y\|^2-2t_1t_2X\cdot Y+...,$$ so taking the 2nd derivatives as specified above will produce the correct scalar products. This leads me to believe that they are correct. However, my first guess was to take the pushforward of $d$, which I couldn't get to work out. What is the interpretation of the above construction in terms of pushforwards?",,"['differential-geometry', 'metric-spaces', 'riemannian-geometry']"
38,"Every 1- or 2-dimensional compact, connected Lie group is abelian","Every 1- or 2-dimensional compact, connected Lie group is abelian",,"I know that in the 1-dimensional case the conclusion follows immediately from the fact that there exists a maximal torus (which then has to be the group itself). In the 2-dimensional case, we also know that there exists a maximal torus, and so the point is to show that it must have dimension 2 (or equivalently, that the dimension cannot be 1). I've been trying to prove this for quite a while, but unfortunately I'm stuck and really don't know what to do. I understand that this is probably an easy question, but my background is in physics and I'm a beginner in these more abstract topics of mathematics; as such, any help would be greatly appreciated.","I know that in the 1-dimensional case the conclusion follows immediately from the fact that there exists a maximal torus (which then has to be the group itself). In the 2-dimensional case, we also know that there exists a maximal torus, and so the point is to show that it must have dimension 2 (or equivalently, that the dimension cannot be 1). I've been trying to prove this for quite a while, but unfortunately I'm stuck and really don't know what to do. I understand that this is probably an easy question, but my background is in physics and I'm a beginner in these more abstract topics of mathematics; as such, any help would be greatly appreciated.",,['differential-geometry']
39,the shortest path between two points and the unit sphere and the arc of the great circle,the shortest path between two points and the unit sphere and the arc of the great circle,,"Prove that the shortest path between two points on the unit sphere is an arc of a great circle connecting them Great Circle: the equator or any circle obtained from the equator by rotating further: latitude lines are not the great circle except the equator I need help with starting this question, because I am not quite sure how to prove this.","Prove that the shortest path between two points on the unit sphere is an arc of a great circle connecting them Great Circle: the equator or any circle obtained from the equator by rotating further: latitude lines are not the great circle except the equator I need help with starting this question, because I am not quite sure how to prove this.",,"['differential-geometry', 'spheres', 'geodesic']"
40,Submanifolds - same dimension,Submanifolds - same dimension,,Let $M$ be a smooth manifold and $N$ a closed embedded submanifold. Assume that they have the same dimension. In this case are they equal? EDIT: M is connected.,Let $M$ be a smooth manifold and $N$ a closed embedded submanifold. Assume that they have the same dimension. In this case are they equal? EDIT: M is connected.,,"['differential-geometry', 'smooth-manifolds']"
41,Complex structure on $\mathbb{C}\mathbb{P}^2\# \dots \# \mathbb{C}\mathbb{P}^2$,Complex structure on,\mathbb{C}\mathbb{P}^2\# \dots \# \mathbb{C}\mathbb{P}^2,"I know the chern classes-related theorem that states that $\mathbb{C}\mathbb{P}^2\# \dots \# \mathbb{C}\mathbb{P}^2$ ($k$ times) has no almost complex structure (hence no complex structure) if and only if $k$ is even. I also know that $\mathbb{C}\mathbb{P}^2\# \mathbb{C}\mathbb{P}^2 \# \mathbb{C}\mathbb{P}^2$ has no complex structure, hence the almost complex ones you define on it are not integrable. Where can I find a proof of this proposition? How do I see that the connected sum of three (or five, or seven, or every odd number) copies of $\mathbb{C}\mathbb{P}^2$ doesn't admit a complex structure?","I know the chern classes-related theorem that states that $\mathbb{C}\mathbb{P}^2\# \dots \# \mathbb{C}\mathbb{P}^2$ ($k$ times) has no almost complex structure (hence no complex structure) if and only if $k$ is even. I also know that $\mathbb{C}\mathbb{P}^2\# \mathbb{C}\mathbb{P}^2 \# \mathbb{C}\mathbb{P}^2$ has no complex structure, hence the almost complex ones you define on it are not integrable. Where can I find a proof of this proposition? How do I see that the connected sum of three (or five, or seven, or every odd number) copies of $\mathbb{C}\mathbb{P}^2$ doesn't admit a complex structure?",,"['differential-geometry', 'complex-geometry']"
42,Why is a vector space equal to its tangent space for any point?,Why is a vector space equal to its tangent space for any point?,,"I'm self-studying Guillemin and Pollack, but I'm stuck on Problem 3 of section 2. It says that if $V$ is a vector subspace of $\mathbb{R}^N$, then $T_x(V)=V$ if $x\in V$. If $x\in V$, then since $V$ is a manifold, there is a local parametrization $\phi: U\to V$ where $U$ is open in $\mathbb{R}^k$. Without loss of generality, we can require $\phi(0)=x$. Then $T_x(V)$ is defined to be the image of $d\phi_0$ on $\mathbb{R}^k$. An arbitrary element of $T_x(V)$ looks like $$ d\phi_0(v)=\lim_{t\to 0}\frac{\phi(0+tv)-\phi(0)}{t}=\lim_{t\to 0}\frac{\phi(tv)-x}{t} $$ but this doesn't seem very useful to show $T_x(V)=V$. What is the right approach?","I'm self-studying Guillemin and Pollack, but I'm stuck on Problem 3 of section 2. It says that if $V$ is a vector subspace of $\mathbb{R}^N$, then $T_x(V)=V$ if $x\in V$. If $x\in V$, then since $V$ is a manifold, there is a local parametrization $\phi: U\to V$ where $U$ is open in $\mathbb{R}^k$. Without loss of generality, we can require $\phi(0)=x$. Then $T_x(V)$ is defined to be the image of $d\phi_0$ on $\mathbb{R}^k$. An arbitrary element of $T_x(V)$ looks like $$ d\phi_0(v)=\lim_{t\to 0}\frac{\phi(0+tv)-\phi(0)}{t}=\lim_{t\to 0}\frac{\phi(tv)-x}{t} $$ but this doesn't seem very useful to show $T_x(V)=V$. What is the right approach?",,"['differential-geometry', 'differential-topology']"
43,The first fundamental form can NOT be identity,The first fundamental form can NOT be identity,,"Let $f:V \to S^{2} \subset \mathbb{R}^{3}$ be a surface whose image is an open subset of the usual unit sphere $S^2$. Prove that there is NOT a change of variables $\phi: U \to V$ such that in the new variables the components of the first fundamental form are $g_{ij}=\delta_{ij}$ where $g_{ij}= \langle f_{v^{1}} ,f_{v^{2}} \rangle$ and $\delta _{ij}$ is the Kronecker delta. Note: There is a result states that the Gauss curvature of $f$ at $v$ is zero if and only if there exists local coordinates in which the matrix rep of the first fundamental form of $f$ at $v$ is the identity matrix under the coordinates (for instance one may take the Fermi local coordinates). Based on this result, is it true that if there is a global change of variables which makes $g_{ij}=\delta_{ij}$ hold then this change of varibles can also be considered as locally at each point on the surface,  thus by above result the Gauss curvature of each point on the surface is zero?","Let $f:V \to S^{2} \subset \mathbb{R}^{3}$ be a surface whose image is an open subset of the usual unit sphere $S^2$. Prove that there is NOT a change of variables $\phi: U \to V$ such that in the new variables the components of the first fundamental form are $g_{ij}=\delta_{ij}$ where $g_{ij}= \langle f_{v^{1}} ,f_{v^{2}} \rangle$ and $\delta _{ij}$ is the Kronecker delta. Note: There is a result states that the Gauss curvature of $f$ at $v$ is zero if and only if there exists local coordinates in which the matrix rep of the first fundamental form of $f$ at $v$ is the identity matrix under the coordinates (for instance one may take the Fermi local coordinates). Based on this result, is it true that if there is a global change of variables which makes $g_{ij}=\delta_{ij}$ hold then this change of varibles can also be considered as locally at each point on the surface,  thus by above result the Gauss curvature of each point on the surface is zero?",,"['differential-geometry', 'differential-topology']"
44,Knot with genus $1$ and trivial Alexander polynomial?,Knot with genus  and trivial Alexander polynomial?,1,I would like to know whether there exists a knot $K$ with genus $g(K)=1$ and trivial Alexander polynomial $\Delta(K) \doteq 1$. A linked question could be: does there exist a Whitehead double with genus $1$? Thanks to all!,I would like to know whether there exists a knot $K$ with genus $g(K)=1$ and trivial Alexander polynomial $\Delta(K) \doteq 1$. A linked question could be: does there exist a Whitehead double with genus $1$? Thanks to all!,,"['algebraic-topology', 'differential-geometry', 'differential-topology', 'knot-theory']"
45,Intuition about geodesic incompleteness,Intuition about geodesic incompleteness,,"To state the context, I am familiar with the Hopf-Rinow theorem. My request is three fold, I would like to know of general classes of geodesically incomplete spaces. I basically want to see lots of examples for this. I want to know of techniques of proving and testing for geodesic incompleteness or completeness. I want to know of methods of proving and testing for existence of maximal extension of curves. {Confusingly in quite a bit of literature I have seen the adjective ""inextensible"" being used when actually they seem to want to mean ""maximally extended"". Is there some subtle point here that I am missing?}","To state the context, I am familiar with the Hopf-Rinow theorem. My request is three fold, I would like to know of general classes of geodesically incomplete spaces. I basically want to see lots of examples for this. I want to know of techniques of proving and testing for geodesic incompleteness or completeness. I want to know of methods of proving and testing for existence of maximal extension of curves. {Confusingly in quite a bit of literature I have seen the adjective ""inextensible"" being used when actually they seem to want to mean ""maximally extended"". Is there some subtle point here that I am missing?}",,['differential-geometry']
46,Reading off connection 1-forms from Cartan's structural equation $de=-\omega\wedge e$,Reading off connection 1-forms from Cartan's structural equation,de=-\omega\wedge e,"Suppose we have a Lorentzian metric of the form \begin{align} g&=-f(r)^2\,dt^2+ h(r)^2(dr^2+r^2\,d\theta^2+r^2\sin^2\theta\,d\phi^2) \end{align} Where $f,h$ are say strictly positive functions. We use the Levi-Civita connection. I introduced the 1-forms \begin{align} e^0=f(r)\,dt,\quad e^1=h(r)\,dr,\quad e^2=rh(r)\,d\theta,\quad e^3=rh(r)\sin\theta\,d\phi \end{align} which diagonalize the metric, and now I'm trying to use these to calculate the connection 1-forms $\omega^a_{\,b}$ using Cartan's structural equation $de=-\omega\wedge e$ (since Levi-Civita connection is torsion free). Question 1. The issue I'm facing is that once I calculate $de$ , I'm not sure how to identify $\omega$ from those equations: initially I tried the most naive thing by just looking at the appropriate coefficient and calling that the appropriate component of $\omega$ , but I think this naive approach is wrong, probably because the wedge-product of non-zero forms can still be zero (so ""cancelling"" terms won't work). To be more explicit, I calculated \begin{align} \begin{cases} de^0= f'(r)\,dr\wedge dt\\ de^1= 0\\ de^2=(h(r)+rh'(r))\,dr\wedge d\theta\\ de^3= (h(r)+rh'(r))\sin\theta\,dr\wedge d\phi+ rh(r)\cos\theta\,d\theta\wedge d\phi \end{cases} \end{align} When I first did the calculation, I naively concluded that \begin{align} de^0=f'(r)\,dr\wedge dt=-\left[-\frac{f'(r)}{f(r)}\,dr\right]\wedge e^0, \end{align} and thus that $\omega^0_0=-\frac{f'(r)}{f(r)}\,dr, \omega^0_1=\omega^0_2=\omega^0_3=0$ . Next, from $de^1=0$ I naively concluded that $\omega^1_{\,b}=0$ for all $b=0,1,2,3$ . I did a similar thing with the other equations. But now I realize this is wrong, because for example, we can also write \begin{align} de^0=f'(r)\,dr\wedge dt= -\left[\frac{f'(r)}{h(r)}\,dt\right]\wedge e^1, \end{align} so if I were to use my above logic, I would have $\omega^0_0=0, \omega^0_1=\frac{f'(r)}{h(r)}\,dt, \omega^0_2=\omega^0_3=0$ . So clearly my mistake stems from the fact that the wedge of non-zero forms can be zero. But now I'm not sure what the correct approach is. I have read this answer by @Ted Shifrin, and it seems like the correct answer is the second approach, but I'm not sure why. Also, I can't really understand that answer because it's not clear to me why certain certain $\omega^a_b$ are equal to certain functions and why others are multiples of some $e^i$ , and why some others are zero. Question 2. The equation $de=-\omega\wedge e$ consists of four equations relating $2$ -forms. However, $\omega$ being a $4\times 4$ matrix (in this case) of $1$ -forms, consists a-priori of 16 unknowns. I believe in this case due to the Lorentzian signature and the diagonalizability of the metric, there is some relationship between $\omega^a_b$ and $\omega^b_a$ , so that it can be written as \begin{align} [\omega^a_b]&= \begin{pmatrix} 0&\alpha_1&\alpha_2&\alpha_3\\ \alpha_1&0&\beta_1&\beta_2\\ \alpha_2&-\beta_1&0&\beta_3\\ \alpha_3& -\beta_2&-\beta_3&0 \end{pmatrix} \end{align} for some 1-forms $\alpha_1,\beta_i$ . So, now there are only 6-unknowns, but this is still too many  unknowns for the number of equations. So my question is whether we can always use this structural equation to determine $\omega$ completely? I believe the answer is yes because for the case of Christoffel symbols $\Gamma^i_{jk}$ we have explicit formulas for it in terms of the metric, and now since $\omega$ are related to $\Gamma$ in some fashion, the same ought to hold true; but now I'm not sure how to reconcile this with the above counting argument (6 unknowns vs 4 equations).","Suppose we have a Lorentzian metric of the form Where are say strictly positive functions. We use the Levi-Civita connection. I introduced the 1-forms which diagonalize the metric, and now I'm trying to use these to calculate the connection 1-forms using Cartan's structural equation (since Levi-Civita connection is torsion free). Question 1. The issue I'm facing is that once I calculate , I'm not sure how to identify from those equations: initially I tried the most naive thing by just looking at the appropriate coefficient and calling that the appropriate component of , but I think this naive approach is wrong, probably because the wedge-product of non-zero forms can still be zero (so ""cancelling"" terms won't work). To be more explicit, I calculated When I first did the calculation, I naively concluded that and thus that . Next, from I naively concluded that for all . I did a similar thing with the other equations. But now I realize this is wrong, because for example, we can also write so if I were to use my above logic, I would have . So clearly my mistake stems from the fact that the wedge of non-zero forms can be zero. But now I'm not sure what the correct approach is. I have read this answer by @Ted Shifrin, and it seems like the correct answer is the second approach, but I'm not sure why. Also, I can't really understand that answer because it's not clear to me why certain certain are equal to certain functions and why others are multiples of some , and why some others are zero. Question 2. The equation consists of four equations relating -forms. However, being a matrix (in this case) of -forms, consists a-priori of 16 unknowns. I believe in this case due to the Lorentzian signature and the diagonalizability of the metric, there is some relationship between and , so that it can be written as for some 1-forms . So, now there are only 6-unknowns, but this is still too many  unknowns for the number of equations. So my question is whether we can always use this structural equation to determine completely? I believe the answer is yes because for the case of Christoffel symbols we have explicit formulas for it in terms of the metric, and now since are related to in some fashion, the same ought to hold true; but now I'm not sure how to reconcile this with the above counting argument (6 unknowns vs 4 equations).","\begin{align}
g&=-f(r)^2\,dt^2+ h(r)^2(dr^2+r^2\,d\theta^2+r^2\sin^2\theta\,d\phi^2)
\end{align} f,h \begin{align}
e^0=f(r)\,dt,\quad e^1=h(r)\,dr,\quad e^2=rh(r)\,d\theta,\quad e^3=rh(r)\sin\theta\,d\phi
\end{align} \omega^a_{\,b} de=-\omega\wedge e de \omega \omega \begin{align}
\begin{cases}
de^0= f'(r)\,dr\wedge dt\\
de^1= 0\\
de^2=(h(r)+rh'(r))\,dr\wedge d\theta\\
de^3= (h(r)+rh'(r))\sin\theta\,dr\wedge d\phi+ rh(r)\cos\theta\,d\theta\wedge d\phi
\end{cases}
\end{align} \begin{align}
de^0=f'(r)\,dr\wedge dt=-\left[-\frac{f'(r)}{f(r)}\,dr\right]\wedge e^0,
\end{align} \omega^0_0=-\frac{f'(r)}{f(r)}\,dr, \omega^0_1=\omega^0_2=\omega^0_3=0 de^1=0 \omega^1_{\,b}=0 b=0,1,2,3 \begin{align}
de^0=f'(r)\,dr\wedge dt=
-\left[\frac{f'(r)}{h(r)}\,dt\right]\wedge e^1,
\end{align} \omega^0_0=0, \omega^0_1=\frac{f'(r)}{h(r)}\,dt, \omega^0_2=\omega^0_3=0 \omega^a_b e^i de=-\omega\wedge e 2 \omega 4\times 4 1 \omega^a_b \omega^b_a \begin{align}
[\omega^a_b]&=
\begin{pmatrix}
0&\alpha_1&\alpha_2&\alpha_3\\
\alpha_1&0&\beta_1&\beta_2\\
\alpha_2&-\beta_1&0&\beta_3\\
\alpha_3& -\beta_2&-\beta_3&0
\end{pmatrix}
\end{align} \alpha_1,\beta_i \omega \Gamma^i_{jk} \omega \Gamma","['differential-geometry', 'differential-forms', 'connections', 'semi-riemannian-geometry']"
47,Shortest path in conformal maps of a surface,Shortest path in conformal maps of a surface,,"My intuition tells me that the shortest distance between two points on the surface corresponds to a line segment joining the two points on the map of said surface, because, the path on the surface is same as the shortest path in the map. However, this turns out to be wrong. Take for instance, the Beltrami-Poincare half-plane model of $\mathbb{H}^2$ , the shortest path between two points seems to be an arc of a semi circle centered at somewhere on the horizon. Picture: Why is the shortest distance not a straight line in the map here? Probably I am missing something quite basic, but I just can't seem to figure it out.","My intuition tells me that the shortest distance between two points on the surface corresponds to a line segment joining the two points on the map of said surface, because, the path on the surface is same as the shortest path in the map. However, this turns out to be wrong. Take for instance, the Beltrami-Poincare half-plane model of , the shortest path between two points seems to be an arc of a semi circle centered at somewhere on the horizon. Picture: Why is the shortest distance not a straight line in the map here? Probably I am missing something quite basic, but I just can't seem to figure it out.",\mathbb{H}^2,['differential-geometry']
48,"What are the smooth, compact hypersurfaces of the euclidean space whose interior is contractible?","What are the smooth, compact hypersurfaces of the euclidean space whose interior is contractible?",,"Let $S$ be a smooth, compact hypersurface (without boundary) of the euclidean space $\mathbb R^N$ . In addition assume that the interior region of $S$ ( i.e., the bounded connected component of $\mathbb R^N\backslash S$ ) is contractible. Does it imply that $S$ is diffeomorphic to the sphere? Of course, this is true for $N=2$ . I do not know whether it still holds in higher dimensions $N\geq 3$ .","Let be a smooth, compact hypersurface (without boundary) of the euclidean space . In addition assume that the interior region of ( i.e., the bounded connected component of ) is contractible. Does it imply that is diffeomorphic to the sphere? Of course, this is true for . I do not know whether it still holds in higher dimensions .",S \mathbb R^N S \mathbb R^N\backslash S S N=2 N\geq 3,"['differential-geometry', 'algebraic-topology', 'differential-topology']"
49,Proving that the Hopf map $S^3 \to S^2$ is a submersion,Proving that the Hopf map  is a submersion,S^3 \to S^2,"I need to show that the Hopf map $H : S^3 \to S^2$ is a submersion. There are many ways to define it, but for now I've gone with the restriction of the function $F : \mathbb{R}^4 \to \mathbb{R}^3$ mapping $$(x,y,u,v)\mapsto (2(xu+yv), 2(xv-yu), x^2+y^2-u^2-v^2).$$ It wasn't too bad to show that $F$ is a submersion, but is there a way to go from here to show that $H$ is a submersion? I can write down $H$ as the composition $$S^3 \overset{\iota}{\hookrightarrow} \mathbb{R}^4 \overset{F}{\to} \mathbb{R}^3 \overset{\pi}{\to} S^2,$$ and define $\pi(p) = p/\lVert p\rVert$ , but I don't really know where to go after computing the Jacobian of $\pi$ , and I don't know if this will even work for my purposes (I don't see how to argue that the composition of the corresponding differentials here isn't rank $1$ — I know $d\iota$ has trivial kernel but things seem to break down once I get to $d\pi$ ). I'm really just trying to avoid having to compute the Jacobian of $H$ with respect to the stereographic projections and show that that beast of a thing is full rank. Am I on the right track, or is there a better way?","I need to show that the Hopf map is a submersion. There are many ways to define it, but for now I've gone with the restriction of the function mapping It wasn't too bad to show that is a submersion, but is there a way to go from here to show that is a submersion? I can write down as the composition and define , but I don't really know where to go after computing the Jacobian of , and I don't know if this will even work for my purposes (I don't see how to argue that the composition of the corresponding differentials here isn't rank — I know has trivial kernel but things seem to break down once I get to ). I'm really just trying to avoid having to compute the Jacobian of with respect to the stereographic projections and show that that beast of a thing is full rank. Am I on the right track, or is there a better way?","H : S^3 \to S^2 F : \mathbb{R}^4 \to \mathbb{R}^3 (x,y,u,v)\mapsto (2(xu+yv), 2(xv-yu), x^2+y^2-u^2-v^2). F H H S^3 \overset{\iota}{\hookrightarrow} \mathbb{R}^4 \overset{F}{\to} \mathbb{R}^3 \overset{\pi}{\to} S^2, \pi(p) = p/\lVert p\rVert \pi 1 d\iota d\pi H","['differential-geometry', 'hopf-fibration']"
50,Geodesics under Levi-Civita connection,Geodesics under Levi-Civita connection,,"I read somewhere that minimum energy paths are geodesics under the Levi-Civita connection, on a Riemannian energy landscape. The Levi-Civita connection is the ""unique connection on the tangent bundle of a manifold that preserves the Riemannian metric and is torsion-free"". What exactly is the intuition of geodesics under the Levi-Civita connection? Why would torsion-free connections give geodesics with least energy?","I read somewhere that minimum energy paths are geodesics under the Levi-Civita connection, on a Riemannian energy landscape. The Levi-Civita connection is the ""unique connection on the tangent bundle of a manifold that preserves the Riemannian metric and is torsion-free"". What exactly is the intuition of geodesics under the Levi-Civita connection? Why would torsion-free connections give geodesics with least energy?",,"['differential-geometry', 'riemannian-geometry', 'geodesic', 'connections']"
51,The orbit space $\dfrac{\mathbb{R}^n}{\mathbb{R}^+}$ has an open subset homeomorphic to $S^{n-1}$,The orbit space  has an open subset homeomorphic to,\dfrac{\mathbb{R}^n}{\mathbb{R}^+} S^{n-1},"Let $X$ be the orbit space $\dfrac{\mathbb{R}^n}{\mathbb{R}^+}$ , where the action of $\mathbb{R}^+$ is given by the following lemma. I want to show that $X$ has an open subset homeomorphic to $S^{n-1}$ , and a point that belongs to every nonempty closed subset. Could anyone help me show this? It's problem $2$ of the chapter $21$ of Introduction of smooth manifolds john lee. here is the lemma : For any continuous action of a topological group $G$ on a topological space $M$ ; the quotient map $\pi : M \to \dfrac{M}{G}$ is an open map. Recall: Suppose we are given an action of a group $G$ on a topological space $M$ ; which we write either as $\theta: G \times G \to M$ or as $(g,p) \to g.p $ . (For definiteness, let us assume that $G$ acts on the left; similar considerations apply to right actions.) Recall that the orbit of a point $p \in M$ is the set of images of $p$ under all elements of the group: \begin{align} G.p=\{g.p : g \in G\} \end{align} Define a relation on $M$ by setting $p \sim q$ if there exists $g \in G$ such that $g.p=q$ . This is an equivalence relation, whose equivalence classes are exactly the orbits of $G$ in $M$ . The set of orbits is denoted by $\dfrac{M}{G}$ ; with the quotient topology it is called the orbit space of the action","Let be the orbit space , where the action of is given by the following lemma. I want to show that has an open subset homeomorphic to , and a point that belongs to every nonempty closed subset. Could anyone help me show this? It's problem of the chapter of Introduction of smooth manifolds john lee. here is the lemma : For any continuous action of a topological group on a topological space ; the quotient map is an open map. Recall: Suppose we are given an action of a group on a topological space ; which we write either as or as . (For definiteness, let us assume that acts on the left; similar considerations apply to right actions.) Recall that the orbit of a point is the set of images of under all elements of the group: Define a relation on by setting if there exists such that . This is an equivalence relation, whose equivalence classes are exactly the orbits of in . The set of orbits is denoted by ; with the quotient topology it is called the orbit space of the action","X \dfrac{\mathbb{R}^n}{\mathbb{R}^+} \mathbb{R}^+ X S^{n-1} 2 21 G M \pi : M \to \dfrac{M}{G} G M \theta: G \times G \to M (g,p) \to g.p  G p \in M p \begin{align}
G.p=\{g.p : g \in G\}
\end{align} M p \sim q g \in G g.p=q G M \dfrac{M}{G}","['differential-geometry', 'manifolds', 'topological-groups']"
52,Does an injective map stay injective under small smooth perturbations?,Does an injective map stay injective under small smooth perturbations?,,"Let $M,N$ be smooth two-dimensional connected, oriented, compact Riemannian manifolds with boundaries, and let $f:M \to N$ be smooth and injective . Let $f_t:M \to N$ be a smooth variation of $f$ . Is $f_t$ injective for sufficiently small $t$ ? If that matters, I am fine with assuming that $\det(df)>0$ and $f(\partial M) \subseteq \partial N$ . (although I am not sure if it's needed.) Here is a naive attempt: Suppose that this is not so; then we have $t_n \to 0$ , $x_n \neq y_n  \in M$ such that $f_{t_n}(x_n)=f_{t_n}(y_n)$ . Since $M$ is compact we have $x_n \to x,y_n \to y$ (modulue subsequences). Thus $f(x)=f(y)$ . Since $f$ is injective, this forces $x=y$ . So, $x_n \neq y_n, x_n,y_n \to x$ and $f_{t_n}(x_n)=f_{t_n}(y_n)$ . Now, if $x \in N^o$ , then $f(x) \in M^o$ (since $df_x$ is non-singular), so by the inverse function theorem, applied to $f_t|_{M^o}:M^o \to N^o$ at $x$ , $f_t$ is injective in a neighbourhood of $x$ . This might be contradictory with $x_n,y_n \to x$ , if we can quantify the size of the neighbourhood where the IFT gives us injectivity, independently of $t$ for small $t$ . (see e.g. here ). A similar argument should work when $x \in \partial M$ . Can this approach work? Are there other approaches? Or is there a counter-example?","Let be smooth two-dimensional connected, oriented, compact Riemannian manifolds with boundaries, and let be smooth and injective . Let be a smooth variation of . Is injective for sufficiently small ? If that matters, I am fine with assuming that and . (although I am not sure if it's needed.) Here is a naive attempt: Suppose that this is not so; then we have , such that . Since is compact we have (modulue subsequences). Thus . Since is injective, this forces . So, and . Now, if , then (since is non-singular), so by the inverse function theorem, applied to at , is injective in a neighbourhood of . This might be contradictory with , if we can quantify the size of the neighbourhood where the IFT gives us injectivity, independently of for small . (see e.g. here ). A similar argument should work when . Can this approach work? Are there other approaches? Or is there a counter-example?","M,N f:M \to N f_t:M \to N f f_t t \det(df)>0 f(\partial M) \subseteq \partial N t_n \to 0 x_n \neq y_n 
\in M f_{t_n}(x_n)=f_{t_n}(y_n) M x_n \to x,y_n \to y f(x)=f(y) f x=y x_n \neq y_n, x_n,y_n \to x f_{t_n}(x_n)=f_{t_n}(y_n) x \in N^o f(x) \in M^o df_x f_t|_{M^o}:M^o \to N^o x f_t x x_n,y_n \to x t t x \in \partial M","['differential-geometry', 'differential-topology', 'riemannian-geometry', 'smooth-manifolds']"
53,How to convince myself (imagine) that $\Bbb S^1$-action on $\Bbb S^3$ fixes a circle of sphere?,How to convince myself (imagine) that -action on  fixes a circle of sphere?,\Bbb S^1 \Bbb S^3,"How to convince myself (imagine) that $\Bbb S^1$ -action on $\Bbb S^3$ fixes a circle of sphere? Due to this comment of Jason DeVito , it is easy to see that action of $\Bbb S^1$ on $\Bbb S^3\subset \Bbb C^2$ defined by $z*(w_1,w_2)=(zw_1,w_2)$ fixes the entire circle $\{(0,w):|w|=1\}\subset\Bbb S^3\subset \Bbb C^2$ . But I can't imagine it, because the common picture of action in my mind is that an circle action is a kind of rotation, so it has a rotation axis and spinning around this axis can fix at most 2 point. Is it possible that the axis of rotation is not a line? Now, how can I think about this action geometrically? $z*(w_1,w_2)=(zw_1,\bar zw_2)$ . Edit: My understanding of last action is that: one side of $\Bbb S^3$ is spinning clockwise and other side is spinning counterclockwise (in different plane from first action) and these actions effect on the middle of sphere and it become scarious and kink in middle, Like cylinder if we spin the boundaries of it in different directions it become kink in middle like screw.","How to convince myself (imagine) that -action on fixes a circle of sphere? Due to this comment of Jason DeVito , it is easy to see that action of on defined by fixes the entire circle . But I can't imagine it, because the common picture of action in my mind is that an circle action is a kind of rotation, so it has a rotation axis and spinning around this axis can fix at most 2 point. Is it possible that the axis of rotation is not a line? Now, how can I think about this action geometrically? . Edit: My understanding of last action is that: one side of is spinning clockwise and other side is spinning counterclockwise (in different plane from first action) and these actions effect on the middle of sphere and it become scarious and kink in middle, Like cylinder if we spin the boundaries of it in different directions it become kink in middle like screw.","\Bbb S^1 \Bbb S^3 \Bbb S^1 \Bbb S^3\subset \Bbb C^2 z*(w_1,w_2)=(zw_1,w_2) \{(0,w):|w|=1\}\subset\Bbb S^3\subset \Bbb C^2 z*(w_1,w_2)=(zw_1,\bar zw_2) \Bbb S^3","['differential-geometry', 'differential-topology', 'riemannian-geometry', 'group-actions']"
54,Calculate gradient in polar coordinates using exterior derivative,Calculate gradient in polar coordinates using exterior derivative,,"I'm teaching myself some basics of differential form, and stumbled over the calculation of gradient in polar coordinates. The book I'm reading is Fortney's A Visual Introduction to Differential Forms and Calculus on Manifolds , which talks little about gradient in non-Cartesian coordinates, so I turned to wikipedia. According to the wikipedia of exterior derivative : $$\nabla f = (df)^\sharp = \frac{\partial f}{\partial x^i}\, (dx^i)^\sharp$$ This formula involves $\sharp$ . According to the wikipedia of musical isomorphism : $$\omega^\sharp := g^{ij} \omega_i \mathbf{e}_j = \omega^j \mathbf{e}_j$$ This formula involves inverse metric tensor $g^{ij}$ (inverse matrix to metric tensor $g_{ij}$ ). According to wikipedia of metric tensor , the metric tensor in polar coordinates is: $$g_{ij} = \begin{bmatrix}     1 & 0 \\     0 & r^2   \end{bmatrix}$$ Combining all these, the gradient of $f(r,\theta)$ in polar coordinates seems to be $$ \nabla f(r, \theta) = \frac{\partial f}{\partial r}\mathbf{e}_r + \frac{1}{r^\color{red}{2}}\frac{\partial f}{\partial \theta}\mathbf{e}_\theta$$ which is different from the gradient in polar coordinates we usually refer to, if not wrong. What am I missing here? How can I calculate the usual gradient in polar coordinates using exterior derivative as the tool? Clarification Post shown by Si Kucing in the comment helps, but I think my question is a bit different. Specifically speaking, I'm also interested in the standard way to obtain the usual gradient, but it's not explained in detail in that post. It's not immediately clear to me why ""the norm of $\frac{∂}{∂θ}$ is $r$ "". Look forward to answer(s) elaborating on this part.","I'm teaching myself some basics of differential form, and stumbled over the calculation of gradient in polar coordinates. The book I'm reading is Fortney's A Visual Introduction to Differential Forms and Calculus on Manifolds , which talks little about gradient in non-Cartesian coordinates, so I turned to wikipedia. According to the wikipedia of exterior derivative : This formula involves . According to the wikipedia of musical isomorphism : This formula involves inverse metric tensor (inverse matrix to metric tensor ). According to wikipedia of metric tensor , the metric tensor in polar coordinates is: Combining all these, the gradient of in polar coordinates seems to be which is different from the gradient in polar coordinates we usually refer to, if not wrong. What am I missing here? How can I calculate the usual gradient in polar coordinates using exterior derivative as the tool? Clarification Post shown by Si Kucing in the comment helps, but I think my question is a bit different. Specifically speaking, I'm also interested in the standard way to obtain the usual gradient, but it's not explained in detail in that post. It's not immediately clear to me why ""the norm of is "". Look forward to answer(s) elaborating on this part.","\nabla f = (df)^\sharp = \frac{\partial f}{\partial x^i}\, (dx^i)^\sharp \sharp \omega^\sharp := g^{ij} \omega_i \mathbf{e}_j = \omega^j \mathbf{e}_j g^{ij} g_{ij} g_{ij} = \begin{bmatrix}
    1 & 0 \\
    0 & r^2
  \end{bmatrix} f(r,\theta) 
\nabla f(r, \theta) = \frac{\partial f}{\partial r}\mathbf{e}_r + \frac{1}{r^\color{red}{2}}\frac{\partial f}{\partial \theta}\mathbf{e}_\theta \frac{∂}{∂θ} r","['differential-geometry', 'vector-analysis', 'differential-forms', 'exterior-algebra', 'exterior-derivative']"
55,Unique group structure on compact connected manifold,Unique group structure on compact connected manifold,,"Does every compact connected manifold carry at most one continuous group structure? In other words, let G and G’ be compact connected Lie groups. If G and G’ are homeomorphic does that imply they are isomorphic as Lie groups? Does uniqueness follow from classification of compact connected Lie groups? Even if so, is there a more direct way of showing uniqueness? I know that uniqueness fails for non connected case ( for example, finite groups) and it fails for non compact case ( for example there are many distinct groups structures on Euclidean space for any $ n \geq 2$ ).","Does every compact connected manifold carry at most one continuous group structure? In other words, let G and G’ be compact connected Lie groups. If G and G’ are homeomorphic does that imply they are isomorphic as Lie groups? Does uniqueness follow from classification of compact connected Lie groups? Even if so, is there a more direct way of showing uniqueness? I know that uniqueness fails for non connected case ( for example, finite groups) and it fails for non compact case ( for example there are many distinct groups structures on Euclidean space for any ).", n \geq 2,"['differential-geometry', 'lie-groups', 'smooth-manifolds']"
56,Properties of Orientation Covering: Lee's Construction,Properties of Orientation Covering: Lee's Construction,,"Let $M$ be a smooth, connected manifold of dimension $n>1$ , and $\mathscr O_p$ an orientation of $T_pM$ . define $\widehat M=\{(p,\mathscr O_p)\}_{p\in M}$ . Then, $\widehat M$ can be made into an oriented manifold. To do this, define the projection $\hat \pi:(p,\mathscr O_p)\mapsto p,$ let $\mathscr O$ be an orientation on $U\in  \tau_M$ and declare the basis elements in $\widehat M$ to be $\widehat U_{\mathscr O}=\{(p,\mathscr O_p):p\in U\}.$ This assignment induces a topology on $\widehat M$ . No problems so far. We have $1).\ \widehat M$ is basically two copies of $M$ , because there are two orentations for $T_pM$ , which are in turn equivalence classes of bases for $T_pM:(X_i)\sim (Y_i)\Leftrightarrow $ the change of basis matrix beteween them has positive determinant. $2).\ $ The orientation $\mathscr O$ on $U$ is induced by a chart $(\phi,U)$ on $M$ . $3).\hat \pi$ is a generalized covering map ( $\widehat M$ need not be connected). So far so good. Now, paraphrasing Lee, $4).\ $ Using $\hat \pi$ we can define a pointwise orientation on $T_{(p,\mathscr O_p)}\widehat M$ : we have that $(\pi_*)_p:T_{(p,\mathscr O_p)}\widehat M\to T_pM$ . We can define a pointwise orientation as the ""unique orientation such that $(\pi_*)_p$ os orientation-preserving."" The orientation on $T_pM$ is either $\mathscr O_p$ or $-\mathscr O_p$ . Is Lee saying that we pick one, compute the det of $\hat \pi_*$ and if it comes out positive, then we assign that as the orientation of $T_{(p,\mathscr O_p)}\widehat M$ , and if not then we take the opposite orientation? I am confused. $5).\ $ The orientation defined in $3).$ agrees with the pullback induced by $\hat \pi$ from $(U,\mathscr O)$ so the pointwise orientation is continuous. I computed the pullback but have not been able to show that the orientation it induces agrees with the previous one. Here is the paragraph from Lee's book that I am having trouble with: I have seen this construction using top forms (Jeffrey Lee), and homology (Hatcher) both of which I understand (I think!), but I want to understand clearly what is going on in Lee's construction, because it is very basic which  means that I am missing some fundamental ideas, which I want to get straight.","Let be a smooth, connected manifold of dimension , and an orientation of . define . Then, can be made into an oriented manifold. To do this, define the projection let be an orientation on and declare the basis elements in to be This assignment induces a topology on . No problems so far. We have is basically two copies of , because there are two orentations for , which are in turn equivalence classes of bases for the change of basis matrix beteween them has positive determinant. The orientation on is induced by a chart on . is a generalized covering map ( need not be connected). So far so good. Now, paraphrasing Lee, Using we can define a pointwise orientation on : we have that . We can define a pointwise orientation as the ""unique orientation such that os orientation-preserving."" The orientation on is either or . Is Lee saying that we pick one, compute the det of and if it comes out positive, then we assign that as the orientation of , and if not then we take the opposite orientation? I am confused. The orientation defined in agrees with the pullback induced by from so the pointwise orientation is continuous. I computed the pullback but have not been able to show that the orientation it induces agrees with the previous one. Here is the paragraph from Lee's book that I am having trouble with: I have seen this construction using top forms (Jeffrey Lee), and homology (Hatcher) both of which I understand (I think!), but I want to understand clearly what is going on in Lee's construction, because it is very basic which  means that I am missing some fundamental ideas, which I want to get straight.","M n>1 \mathscr O_p T_pM \widehat M=\{(p,\mathscr O_p)\}_{p\in M} \widehat M \hat \pi:(p,\mathscr O_p)\mapsto p, \mathscr O U\in  \tau_M \widehat M \widehat U_{\mathscr O}=\{(p,\mathscr O_p):p\in U\}. \widehat M 1).\ \widehat M M T_pM T_pM:(X_i)\sim (Y_i)\Leftrightarrow  2).\  \mathscr O U (\phi,U) M 3).\hat \pi \widehat M 4).\  \hat \pi T_{(p,\mathscr O_p)}\widehat M (\pi_*)_p:T_{(p,\mathscr O_p)}\widehat M\to T_pM (\pi_*)_p T_pM \mathscr O_p -\mathscr O_p \hat \pi_* T_{(p,\mathscr O_p)}\widehat M 5).\  3). \hat \pi (U,\mathscr O)","['differential-geometry', 'algebraic-topology', 'smooth-manifolds', 'covering-spaces', 'orientation']"
57,"If $\omega$ is a volume form, then $X\mapsto i_X\omega$ generates all $(n-1)$-forms","If  is a volume form, then  generates all -forms",\omega X\mapsto i_X\omega (n-1),"I've read the following claim in a textbook (I don't think the context is relevant): Let $M$ be a compact smooth manifold. If $\omega\in\Omega^n(M)$ is a volume form, then every $(n-1)$ -form $\eta\in\Omega^{n-1}(M)$ is given by $\eta=i_X\omega$ for some vector field $X\in\Gamma(TM)$ . In order to convince myself, I tested the statement for $n=3$ , only locally (i.e., in coordinate neighbourhoods), but couldn't do it generally. The author, rather vaguely, says that $X\mapsto i_X\omega$ is an ""isomorphism"", but I don't know what this is supposed to mean here. Any ideas?","I've read the following claim in a textbook (I don't think the context is relevant): Let be a compact smooth manifold. If is a volume form, then every -form is given by for some vector field . In order to convince myself, I tested the statement for , only locally (i.e., in coordinate neighbourhoods), but couldn't do it generally. The author, rather vaguely, says that is an ""isomorphism"", but I don't know what this is supposed to mean here. Any ideas?",M \omega\in\Omega^n(M) (n-1) \eta\in\Omega^{n-1}(M) \eta=i_X\omega X\in\Gamma(TM) n=3 X\mapsto i_X\omega,"['differential-geometry', 'differential-topology', 'smooth-manifolds', 'exterior-algebra']"
58,Is there a metric on $\mathbb{R}^2$ such that the unit circle is a geodesic?,Is there a metric on  such that the unit circle is a geodesic?,\mathbb{R}^2,"It is well known that all 1D spaces are flat, and furthermore that all paths in 1D spaces with unit tangent vectors are geodesics.  In particular the space $S^1$ is flat, and the closed loop traversing the space once is a geodesic. I've been attempting to embed $S^1$ as the unit circle in $\mathbb{R}^2$ so that the unit tangent vector field $\vec V = [1]$ on $S^1$ , which is parallel transported about $S^1$ , remains parallel transported about the unit circle in $\mathbb{R}^2$ , and furthermore that the path $l(t) = [t]$ which is a geodesic in $S^1$ has its $\mathbb{R}^2$ embedding $l(t) = [\cos (t), \sin (t)]$ also a geodesic. However, I haven't been able to make the terms work out.  I've been attempting to transform the metric tensor and the vector field from $S^1$ to the higher-dimensional space $\mathbb{R}^2$ using the partial derivatives of the coordinate transformations, and from the derived $\mathbb{R}^2$ metric tensor finding the Christoffel symbols, then checking that $V$ and $l$ are parallel transported and a geodesic respectively using the parallel transport condition $<\vec U, \nabla \vec V > = 0$ and the geodesic condition $<\vec U, \nabla \vec U> = 0$ . So, is there a metric on $\mathbb{R}^2$ so that the path $l(t) = [\cos(t), \sin(t)]$ is a geodesic, and if so, what is it?  (I'm ready for the answer, since I've burned through all the options that seem evidently available to me).","It is well known that all 1D spaces are flat, and furthermore that all paths in 1D spaces with unit tangent vectors are geodesics.  In particular the space is flat, and the closed loop traversing the space once is a geodesic. I've been attempting to embed as the unit circle in so that the unit tangent vector field on , which is parallel transported about , remains parallel transported about the unit circle in , and furthermore that the path which is a geodesic in has its embedding also a geodesic. However, I haven't been able to make the terms work out.  I've been attempting to transform the metric tensor and the vector field from to the higher-dimensional space using the partial derivatives of the coordinate transformations, and from the derived metric tensor finding the Christoffel symbols, then checking that and are parallel transported and a geodesic respectively using the parallel transport condition and the geodesic condition . So, is there a metric on so that the path is a geodesic, and if so, what is it?  (I'm ready for the answer, since I've burned through all the options that seem evidently available to me).","S^1 S^1 \mathbb{R}^2 \vec V = [1] S^1 S^1 \mathbb{R}^2 l(t) = [t] S^1 \mathbb{R}^2 l(t) = [\cos (t), \sin (t)] S^1 \mathbb{R}^2 \mathbb{R}^2 V l <\vec U, \nabla \vec V > = 0 <\vec U, \nabla \vec U> = 0 \mathbb{R}^2 l(t) = [\cos(t), \sin(t)]","['differential-geometry', 'tensors', 'geodesic']"
59,Characteristic classes of spheres,Characteristic classes of spheres,,"Since an exotic sphere is a differentiable manifold $M$ that is homeomorphic but not diffeomorphic to the standard Euclidean $n$-sphere, we may not be able to distinguish spheres from exotic sphere through characteristic classes. However, it is still worthwhile to know the basic characteristic class data of spheres: Stiefel–Whitney class $w_i$: Spheres are orientable and non-spin, thus $$ w_1(S^d)=0, $$ $$ w_2(S^d)=0, $$ More generally, what do we have for other $i$: $$ w_i(S^d)=? $$ Chern class $c_i$: Even-dimensional spheres have an even-real dimensional tangent bundle $TS^d$, thus we may define the Chern class  $$c_i(TS^d)=c_i(S^d)=?$$ One may also consider the frame bundle of spheres  $$c_i(FS^d)=?$$ Euler class: $$ \chi(S^d)=2, \text{ if $d$ even};  $$ $$ \chi(S^d)=0, \text{ if $d$ odd.}   $$ Wu class $u_i$: is related to the Stiefel–Whitney class $w_i$ through Stenrod square, so $$ u_1(S^d)=u_2(S^d)=u_3(S^d)=0 $$ More generally, what do we have for other $i$: $$ u_i(S^d)=? $$ Pontryagin class $p_i$: $$ p_i(S^d)=? $$ We can consider all the $d=0 \pmod 4$ dimensions of spheres. We know that $p_1(TS^4)=0$ and $p_1(FS^4)=?$ (The frame bundle of spheres). Are there other powerful/ useful Characteristic classes of spheres?","Since an exotic sphere is a differentiable manifold $M$ that is homeomorphic but not diffeomorphic to the standard Euclidean $n$-sphere, we may not be able to distinguish spheres from exotic sphere through characteristic classes. However, it is still worthwhile to know the basic characteristic class data of spheres: Stiefel–Whitney class $w_i$: Spheres are orientable and non-spin, thus $$ w_1(S^d)=0, $$ $$ w_2(S^d)=0, $$ More generally, what do we have for other $i$: $$ w_i(S^d)=? $$ Chern class $c_i$: Even-dimensional spheres have an even-real dimensional tangent bundle $TS^d$, thus we may define the Chern class  $$c_i(TS^d)=c_i(S^d)=?$$ One may also consider the frame bundle of spheres  $$c_i(FS^d)=?$$ Euler class: $$ \chi(S^d)=2, \text{ if $d$ even};  $$ $$ \chi(S^d)=0, \text{ if $d$ odd.}   $$ Wu class $u_i$: is related to the Stiefel–Whitney class $w_i$ through Stenrod square, so $$ u_1(S^d)=u_2(S^d)=u_3(S^d)=0 $$ More generally, what do we have for other $i$: $$ u_i(S^d)=? $$ Pontryagin class $p_i$: $$ p_i(S^d)=? $$ We can consider all the $d=0 \pmod 4$ dimensions of spheres. We know that $p_1(TS^4)=0$ and $p_1(FS^4)=?$ (The frame bundle of spheres). Are there other powerful/ useful Characteristic classes of spheres?",,"['differential-geometry', 'algebraic-topology', 'differential-topology', 'homology-cohomology', 'characteristic-classes']"
60,Let $N \subset M$ be a submanifold. A minimizing geodesic which joins a point $q \in M-N$ minimum distance from $N$ is orthogonal to $N$ at $q$.,Let  be a submanifold. A minimizing geodesic which joins a point  minimum distance from  is orthogonal to  at .,N \subset M q \in M-N N N q,"Let $M$ be a complete Riemannian manifold and let $N \subset M$ be a closed submanifold of $M$. Let $p_0 \in M$ where $p_{0} \notin N$ and let $d(p_{0},N)$ be the distance from $p_{0}$ to $N$. Show that there exists a point $q_{0} \in N$ such that $d(p_0,q_0)=d(p_{0},N)$. Moreover that a minimizing geodesic which joins $p_{0}$ to $q_{0}$ is orthogonal to $N$ at $q_{0}$. I've done the first part but am at a total loss for the second part (highlighted). This comes from chapter 9 of do Carmo on variations of energy so I assume you have to use a variation somehow.","Let $M$ be a complete Riemannian manifold and let $N \subset M$ be a closed submanifold of $M$. Let $p_0 \in M$ where $p_{0} \notin N$ and let $d(p_{0},N)$ be the distance from $p_{0}$ to $N$. Show that there exists a point $q_{0} \in N$ such that $d(p_0,q_0)=d(p_{0},N)$. Moreover that a minimizing geodesic which joins $p_{0}$ to $q_{0}$ is orthogonal to $N$ at $q_{0}$. I've done the first part but am at a total loss for the second part (highlighted). This comes from chapter 9 of do Carmo on variations of energy so I assume you have to use a variation somehow.",,"['differential-geometry', 'riemannian-geometry']"
61,Proving that the cone is not a smooth manifold,Proving that the cone is not a smooth manifold,,"Show that the cone given by $C = \{(x, y, z) \in \mathbb{R}^3 \mid z = \sqrt{x^2 + y^2}\}$ is not a smooth manifold In the definition I'm using of a smooth manifold, each point $x \in M \subseteq \mathbb{R}^k$ (where $M$ inherits the subspace topology from $\mathbb{R}^k$ with the usual topology) has a neighborhood $U$ of $x$ in $M$ such that $U$ is diffeomorphic to some open set of $\mathbb{R}^n$ for some $n > 0$. (This is the definition I'm using from Guillemin and Pollack's Differential Topology book) Now to prove that $C$ is not a smooth manifold I'd have to show that there exists a point $x \in C$ such that any neighborhood $U$ of $x$ in $C$ is not diffeomorphic to any open set of $\mathbb{R}^2$. Now I recall reading that $C$ is a topological $2$-manifold, hence each point of $C$ would have a neighborhood in $C$ homeomorphic to an open subset of $\mathbb{R}^2$. So the smoothness of the homeomorphism must fail at some point in $C$. It seems that smoothness will fail at $x = 0 \in C$. I want to find out how to rigorously prove this. I'm guessing the proof outline will go something like this; Proof Outline: Let $U$ be a neighbourhood of $0$ in $C$ and suppose that there existed a diffeomorphism $f : U \to \widehat{U}$ where $\widehat{U}$ is an open subset of $\mathbb{R}^2$. We show that this results in a  contradiction, hence it will follow that no neighborhood of $0$ in $C$ is diffeomorphic to an open subset of $\mathbb{R}^2$ and hence $C$ consequently will not be a smooth manifold. However since I've picked an arbitrary diffeomorphism $f$, I don't know of any way to go about finding a contradiction. How can I go about proving this? Also in my proof outline I wrote above, the proof really only shows that $C$ is not a smooth $2$-manifold, wouldn't I need to show that $C$ is not a smooth manifold for any $n > 0$? In that case I'm guessing that $C$ wouldn't even be a topological manifold for any $n \neq 2$.","Show that the cone given by $C = \{(x, y, z) \in \mathbb{R}^3 \mid z = \sqrt{x^2 + y^2}\}$ is not a smooth manifold In the definition I'm using of a smooth manifold, each point $x \in M \subseteq \mathbb{R}^k$ (where $M$ inherits the subspace topology from $\mathbb{R}^k$ with the usual topology) has a neighborhood $U$ of $x$ in $M$ such that $U$ is diffeomorphic to some open set of $\mathbb{R}^n$ for some $n > 0$. (This is the definition I'm using from Guillemin and Pollack's Differential Topology book) Now to prove that $C$ is not a smooth manifold I'd have to show that there exists a point $x \in C$ such that any neighborhood $U$ of $x$ in $C$ is not diffeomorphic to any open set of $\mathbb{R}^2$. Now I recall reading that $C$ is a topological $2$-manifold, hence each point of $C$ would have a neighborhood in $C$ homeomorphic to an open subset of $\mathbb{R}^2$. So the smoothness of the homeomorphism must fail at some point in $C$. It seems that smoothness will fail at $x = 0 \in C$. I want to find out how to rigorously prove this. I'm guessing the proof outline will go something like this; Proof Outline: Let $U$ be a neighbourhood of $0$ in $C$ and suppose that there existed a diffeomorphism $f : U \to \widehat{U}$ where $\widehat{U}$ is an open subset of $\mathbb{R}^2$. We show that this results in a  contradiction, hence it will follow that no neighborhood of $0$ in $C$ is diffeomorphic to an open subset of $\mathbb{R}^2$ and hence $C$ consequently will not be a smooth manifold. However since I've picked an arbitrary diffeomorphism $f$, I don't know of any way to go about finding a contradiction. How can I go about proving this? Also in my proof outline I wrote above, the proof really only shows that $C$ is not a smooth $2$-manifold, wouldn't I need to show that $C$ is not a smooth manifold for any $n > 0$? In that case I'm guessing that $C$ wouldn't even be a topological manifold for any $n \neq 2$.",,"['differential-geometry', 'differential-topology']"
62,Lie derivative of the Christoffel symbol,Lie derivative of the Christoffel symbol,,"The Lie derivative of the Christoffel symbol is $$  \mathcal{L}_\xi \Gamma^k_{ij} = \nabla_i \nabla_j \xi^k - R^k_{ijl} \xi^l \,. $$ How can one prove that? And why does it make sense, because Christoffel symbols are functions? I know that the last question could be irrelevant, since the correct form of the LHS of the equation should be $(\mathcal{L}_\xi \Gamma)^k_{ij}$. But, I still cannot figure it out.","The Lie derivative of the Christoffel symbol is $$  \mathcal{L}_\xi \Gamma^k_{ij} = \nabla_i \nabla_j \xi^k - R^k_{ijl} \xi^l \,. $$ How can one prove that? And why does it make sense, because Christoffel symbols are functions? I know that the last question could be irrelevant, since the correct form of the LHS of the equation should be $(\mathcal{L}_\xi \Gamma)^k_{ij}$. But, I still cannot figure it out.",,[]
63,Why does the tangent vector measure the rate of change of the angle which neighboring tangent make with the tangent?,Why does the tangent vector measure the rate of change of the angle which neighboring tangent make with the tangent?,,I'm reading the classical Manfredo's differential geometry book and I couldn't prove formally the following statement written on page 16: Why does the tangent vector measure the rate of change of the angle which neighboring tangent make with the tangent at $s$?,I'm reading the classical Manfredo's differential geometry book and I couldn't prove formally the following statement written on page 16: Why does the tangent vector measure the rate of change of the angle which neighboring tangent make with the tangent at $s$?,,"['calculus', 'differential-geometry']"
64,Example of Hessian of a function with respect to Riemannian metric?,Example of Hessian of a function with respect to Riemannian metric?,,"Can someone explain : how to take the Hessian of a function with respect to a riemannian metric? In other words, in Euclidean space, the hessian of a function $f: \mathbb{R}^n \to \mathbb{R}$ is simply $\text{Hess}f(x) = \nabla^2 f(x)$ , what is the difference when I move to $(\mathbb{R}^n, g)$ ? For instance : suppose I have a manifold $(\mathbb{R}^n, g)$ , $x \in \mathbb{R}^n$ , where $g$ is given by $g_{ij} = \dfrac{1}{x_i}\delta_{ij}$ . Then what is the Hessian of $f(x) = \sum\limits_{i = 1}^n x_i\log(x_i)$ with respect to this metric? Even better, if someone can tell me how to compute the gradient of $f$ under this metric! Any reference on examples to compute the gradient and hessian of functions on Riemannian manifolds will be greatly appreciated! Disclaimer: know almost nothing about riemannian geometry","Can someone explain : how to take the Hessian of a function with respect to a riemannian metric? In other words, in Euclidean space, the hessian of a function is simply , what is the difference when I move to ? For instance : suppose I have a manifold , , where is given by . Then what is the Hessian of with respect to this metric? Even better, if someone can tell me how to compute the gradient of under this metric! Any reference on examples to compute the gradient and hessian of functions on Riemannian manifolds will be greatly appreciated! Disclaimer: know almost nothing about riemannian geometry","f: \mathbb{R}^n \to \mathbb{R} \text{Hess}f(x) = \nabla^2 f(x) (\mathbb{R}^n, g) (\mathbb{R}^n, g) x \in \mathbb{R}^n g g_{ij} = \dfrac{1}{x_i}\delta_{ij} f(x) = \sum\limits_{i = 1}^n x_i\log(x_i) f","['differential-geometry', 'manifolds', 'riemannian-geometry']"
65,Vector bundles and de Rham cohomology,Vector bundles and de Rham cohomology,,"So $M$ is a compact manifold and I am asked to either prove the following statement or give a counterexample: if $\pi: E \rightarrow M$ is a vector bundle, then $H^2(E) \simeq H^2(M)$. I know the definition of a vector bundle, and know how the de Rham cohomology is defined, but that's all I have. After some research, I found that it might have to do with 'homotopy equivalence' but I don't understand it. Can someone explain this without going too deep in technical stuff? Thanks in advance!","So $M$ is a compact manifold and I am asked to either prove the following statement or give a counterexample: if $\pi: E \rightarrow M$ is a vector bundle, then $H^2(E) \simeq H^2(M)$. I know the definition of a vector bundle, and know how the de Rham cohomology is defined, but that's all I have. After some research, I found that it might have to do with 'homotopy equivalence' but I don't understand it. Can someone explain this without going too deep in technical stuff? Thanks in advance!",,"['differential-geometry', 'algebraic-topology']"
66,Does the associated bundle functor have left or right adjoints?,Does the associated bundle functor have left or right adjoints?,,"Let $\mathsf{Prin}_G$ be the category of (right) $G$-principal bundles, with a morphism from the bundle $p: P \to M$ to the bundle $p': P' \to M'$ being a pair of arrows $\chi: P \to P'$ and $\bar{\chi}: M \to M'$ such that $\chi$ is $G$-equivariant and the obvious diagram commutes. We only need to specify the morphism $\chi: P \to P'$ since the corresponding morphism down on the base is uniquely determined by $\chi$. Let $\mathsf{Space}_G$ be the category of (left) $G$-spaces, with a morphism from $S$ to $S'$ being a $G$-equivariant arrow $f: S \to S'$. Let $\mathsf{Bund}$ be the category of fibre bundles, with morphisms from $E \to M$, $E' \to M'$ being a pair of arrows such that we get a commutative square. Then associated bundle assignment $$\mathsf{Prin}_G \times \mathsf{Space}_G \to \mathsf{Bund}$$ sending a pair of morphisms $\chi: P \to P'$ and $f: S \to S'$ to the morphism $$\chi \times_G f: P \times_G S \to P' \times_G S'$$ given by $$(\chi \times_G f) [u, s] = [\chi(u), f(s)]$$ is a bifunctor. Now suppose we fix a principal $G$-bundle $P \to M$. Then this gives us an associated bundle functor $$P[-] := P \times_G (-): \mathsf{Space}_G \to \mathsf{Bund}(M),$$ where $\mathsf{Bund}(M)$ is the category of fibre bundles over $M$, with morphisms covering the identity on $M$. Does this functor have any left or right adjoints? Do we need to restrict the target category to get an adjunction? What if instead we fix the other argument (the $G$-space) and let the principal bundle vary? To provide a bit of motivation, I have read that for any fixed principal bundle the associated bundle functor from representations to vector bundles is exact, which leads me to guess that it might have both a left and a right adjoint.","Let $\mathsf{Prin}_G$ be the category of (right) $G$-principal bundles, with a morphism from the bundle $p: P \to M$ to the bundle $p': P' \to M'$ being a pair of arrows $\chi: P \to P'$ and $\bar{\chi}: M \to M'$ such that $\chi$ is $G$-equivariant and the obvious diagram commutes. We only need to specify the morphism $\chi: P \to P'$ since the corresponding morphism down on the base is uniquely determined by $\chi$. Let $\mathsf{Space}_G$ be the category of (left) $G$-spaces, with a morphism from $S$ to $S'$ being a $G$-equivariant arrow $f: S \to S'$. Let $\mathsf{Bund}$ be the category of fibre bundles, with morphisms from $E \to M$, $E' \to M'$ being a pair of arrows such that we get a commutative square. Then associated bundle assignment $$\mathsf{Prin}_G \times \mathsf{Space}_G \to \mathsf{Bund}$$ sending a pair of morphisms $\chi: P \to P'$ and $f: S \to S'$ to the morphism $$\chi \times_G f: P \times_G S \to P' \times_G S'$$ given by $$(\chi \times_G f) [u, s] = [\chi(u), f(s)]$$ is a bifunctor. Now suppose we fix a principal $G$-bundle $P \to M$. Then this gives us an associated bundle functor $$P[-] := P \times_G (-): \mathsf{Space}_G \to \mathsf{Bund}(M),$$ where $\mathsf{Bund}(M)$ is the category of fibre bundles over $M$, with morphisms covering the identity on $M$. Does this functor have any left or right adjoints? Do we need to restrict the target category to get an adjunction? What if instead we fix the other argument (the $G$-space) and let the principal bundle vary? To provide a bit of motivation, I have read that for any fixed principal bundle the associated bundle functor from representations to vector bundles is exact, which leads me to guess that it might have both a left and a right adjoint.",,"['differential-geometry', 'category-theory', 'fiber-bundles', 'principal-bundles']"
67,The projective space as a homogeneous space,The projective space as a homogeneous space,,I want to understand why the projective space $\mathbb RP^n$ is diffeomorophic to $SO(n+1)/O(n)$? and why we can write the latter as $O(n+1)/O(n)\times O(1)$?,I want to understand why the projective space $\mathbb RP^n$ is diffeomorophic to $SO(n+1)/O(n)$? and why we can write the latter as $O(n+1)/O(n)\times O(1)$?,,"['differential-geometry', 'group-actions', 'homogeneous-spaces']"
68,What is the differential of the quotient map?,What is the differential of the quotient map?,,"We can view the projective space $P(\mathbb R^n)$ as the quotient of $S^n/\sim$  where $x \sim y$ if and only if $x = -y$. The quotient map $q: S^n \to P(\mathbb R^n)$ is the map $x \mapsto [x]$ where $[x] = \{x,-x\}$. I want to calculate the Jacobian matrix differential of $q$ but I don't see what it is. To me it seems that it is both the identity $I$ and $-I$ at the same time. What is the differential of $q$ and how to caluclate it? Here is what I have so far: Since I didn't know how to do the general case I tried to do the explicit caluclation for $n=2$. Let $\varphi : \mathbb R^2 \to S^2, (x,y) \mapsto ({2x \over x^2 + y^2 + 1}, {2y \over x^2 + y^2 +1}, {x^2 +y^2 -1\over x^2 +y^2 +1})$ and $\psi^{-1}:P(\mathbb R^2) \to \mathbb R^2, [(x,y,z)] \mapsto ({y\over x}, {z\over x})$ and $F: S^2 \to P(\mathbb R^2), x \mapsto [x]$. Then $$ \psi^{-1}\circ F \circ \varphi (x,y) = ({y\over x}, {x^2 +y^2 -1 \over 2x}) $$ and the Jacobian I calculated as $$ J_{\psi^{-1}\circ F \circ \varphi} =\left ( \begin{matrix} -{y \over x^2} & {1\over x} \\ {2x^2 - 2y^2 + 2 \over 4 x^2 } & {y\over x} \end{matrix}\right )$$ Is this correct? And if so, how can I generalise to arbitrary $n$?","We can view the projective space $P(\mathbb R^n)$ as the quotient of $S^n/\sim$  where $x \sim y$ if and only if $x = -y$. The quotient map $q: S^n \to P(\mathbb R^n)$ is the map $x \mapsto [x]$ where $[x] = \{x,-x\}$. I want to calculate the Jacobian matrix differential of $q$ but I don't see what it is. To me it seems that it is both the identity $I$ and $-I$ at the same time. What is the differential of $q$ and how to caluclate it? Here is what I have so far: Since I didn't know how to do the general case I tried to do the explicit caluclation for $n=2$. Let $\varphi : \mathbb R^2 \to S^2, (x,y) \mapsto ({2x \over x^2 + y^2 + 1}, {2y \over x^2 + y^2 +1}, {x^2 +y^2 -1\over x^2 +y^2 +1})$ and $\psi^{-1}:P(\mathbb R^2) \to \mathbb R^2, [(x,y,z)] \mapsto ({y\over x}, {z\over x})$ and $F: S^2 \to P(\mathbb R^2), x \mapsto [x]$. Then $$ \psi^{-1}\circ F \circ \varphi (x,y) = ({y\over x}, {x^2 +y^2 -1 \over 2x}) $$ and the Jacobian I calculated as $$ J_{\psi^{-1}\circ F \circ \varphi} =\left ( \begin{matrix} -{y \over x^2} & {1\over x} \\ {2x^2 - 2y^2 + 2 \over 4 x^2 } & {y\over x} \end{matrix}\right )$$ Is this correct? And if so, how can I generalise to arbitrary $n$?",,"['differential-geometry', 'proof-verification']"
69,How to understand the notion of a differential of a function,How to understand the notion of a differential of a function,,"In elementary calculus (and often in courses beyond) we are taught that a differential of a function, $df$ quantifies an infinitesimal change in that function. However, the notion of an infinitesimal is not well-defined and is nonsensical (I mean, one cannot define it in terms of a limit, and it seems nonsensical to have a number that is smaller than any other real number - this simply doesn't exist in standard analysis). Clearly the definition $$df=\lim_{\Delta x\rightarrow 0}\Delta f =f'(x)dx$$ makes no sense, since, in the case where $f(x)=x$ we have that $$ dx=\lim_{\Delta x\rightarrow 0}\Delta x =0.$$ All of this leaves me confused on how to interpret expressions such as $$df=f'(x)dx$$ Should it be seen simply as a definition, quantifying the first-order (linear) change in a function about a point $x$? i.e. a new function that is dependent both on $x$ and a finite change in $x$, $\Delta x$, $$df(x,\Delta x):=f'(x)\Delta x$$ then one can interpret $dx$ as $$dx:=dx(x,\Delta x)= \Delta x$$ such that $$\Delta f=f'(x)dx+\varepsilon =df +\varepsilon$$ (in which $\varepsilon$ quantifies the error between this linear change in $f$ and the actual change in $f$, with $\lim_{\Delta x\rightarrow 0}\varepsilon =0$). I feel that there must be some sort of rigorous treatment of the notion of differentials since these kind of manipulations are used all the time, at least in physics?! I've had some exposure to differential geometry in which one has differential forms, in particular $1-$forms which suggestively notationally ""look like"" differentials, for example $$\omega =df$$ but as I understand it these are defined as linear maps , members of a dual space to some vector space, $V$, which act on elements of $V$, mapping them to real numbers. Furthermore, the basis $1-$forms are suggestively written as what in elementary calculus one would interpret as an infinitesimal change in x , $dx$. But again, this is simply symbolic notation, since the basis $1-$forms simply span the dual space and are themselves linear maps which act on elements of $V$. I've heard people say that differential forms make the notion of a differential of a function mathematically rigorous, however, in my mind I can't seem to reconcile how this is the case, since at best they specify the direction in which the differential change in a function occurs, via $$df(v)=v(f)$$ (since $v(f)$ is the directional derivative of a function $f$ along the vector $v$). If someone could enlighten me on this subject I'd really appreciate it.","In elementary calculus (and often in courses beyond) we are taught that a differential of a function, $df$ quantifies an infinitesimal change in that function. However, the notion of an infinitesimal is not well-defined and is nonsensical (I mean, one cannot define it in terms of a limit, and it seems nonsensical to have a number that is smaller than any other real number - this simply doesn't exist in standard analysis). Clearly the definition $$df=\lim_{\Delta x\rightarrow 0}\Delta f =f'(x)dx$$ makes no sense, since, in the case where $f(x)=x$ we have that $$ dx=\lim_{\Delta x\rightarrow 0}\Delta x =0.$$ All of this leaves me confused on how to interpret expressions such as $$df=f'(x)dx$$ Should it be seen simply as a definition, quantifying the first-order (linear) change in a function about a point $x$? i.e. a new function that is dependent both on $x$ and a finite change in $x$, $\Delta x$, $$df(x,\Delta x):=f'(x)\Delta x$$ then one can interpret $dx$ as $$dx:=dx(x,\Delta x)= \Delta x$$ such that $$\Delta f=f'(x)dx+\varepsilon =df +\varepsilon$$ (in which $\varepsilon$ quantifies the error between this linear change in $f$ and the actual change in $f$, with $\lim_{\Delta x\rightarrow 0}\varepsilon =0$). I feel that there must be some sort of rigorous treatment of the notion of differentials since these kind of manipulations are used all the time, at least in physics?! I've had some exposure to differential geometry in which one has differential forms, in particular $1-$forms which suggestively notationally ""look like"" differentials, for example $$\omega =df$$ but as I understand it these are defined as linear maps , members of a dual space to some vector space, $V$, which act on elements of $V$, mapping them to real numbers. Furthermore, the basis $1-$forms are suggestively written as what in elementary calculus one would interpret as an infinitesimal change in x , $dx$. But again, this is simply symbolic notation, since the basis $1-$forms simply span the dual space and are themselves linear maps which act on elements of $V$. I've heard people say that differential forms make the notion of a differential of a function mathematically rigorous, however, in my mind I can't seem to reconcile how this is the case, since at best they specify the direction in which the differential change in a function occurs, via $$df(v)=v(f)$$ (since $v(f)$ is the directional derivative of a function $f$ along the vector $v$). If someone could enlighten me on this subject I'd really appreciate it.",,"['calculus', 'differential-geometry', 'intuition', 'differential-forms']"
70,Obtaining the Rodrigues formula,Obtaining the Rodrigues formula,,"On $So(3)$ the algebra of a $3 \times 3$ skew symmetric matrices define Lie bracket $[A,B]=AB-BA$ Consider the exponential map $$EXP: So(3) \to So(3)$$. We have the $So(3)$ matrix $$A=\begin{bmatrix} 0 & -c & b \\c &  0 & -a\\ -b & a & 0\end{bmatrix}$$ Upon letting $\theta=\sqrt{a^2 + b^2 +c^2}$ , show that we obtain the identity (which is the Rodrigues formula) $$EXP (A)=I_3 + \frac{sin \theta}{\theta} A+ \frac{I-cos \theta}{\theta^2} A^2$$ I am not sure how we get the expressions $$A^{2n}=(-1)^{n+1} \theta^{2(n+1)}\begin{bmatrix} -(b^2+c^2) & ab & ac \\ab &  -(a^2+c^2) & bc\\ ac & bc & -(a^2+b^2)\end{bmatrix}$$ and $$A^{2n+1}=(-1)^n \theta^{2n}\begin{bmatrix} 0 & -c & b \\c &  0 & -a\\ -b & a & 0\end{bmatrix}$$ I understand that you look at the powers of $A$, $A^2$, $A^3$ and so on. I also understand that you get $A^{2n}$ for even powers of n and $A^{2n+1}$ for odd powers of n. I work out $$A^2= \begin{bmatrix} -b^2-c^2 & ab & ac \\ab &  -a^2-c^2 & bc\\ ac & bc & -a^2-b^2\end{bmatrix}$$ $$A^3= \begin{bmatrix} 0 & a^2c-c(-b^2-c^2) & -a^2b+b(-b^2-c^2)  \\-b^2 c+c(-a^2-c^2) &  0 & ab^2-a(-a^2-c^2)\\ bc^2-b(-a^2-b^2) & -ac^2+a(-a^2-b^2) &  0\end{bmatrix}$$ From $A^2$ how do you get the expression for $A^{2n}$? From $A^3$ how do you get the expression for $A^{2n+1}$? For example how is $\theta$ incorporated?","On $So(3)$ the algebra of a $3 \times 3$ skew symmetric matrices define Lie bracket $[A,B]=AB-BA$ Consider the exponential map $$EXP: So(3) \to So(3)$$. We have the $So(3)$ matrix $$A=\begin{bmatrix} 0 & -c & b \\c &  0 & -a\\ -b & a & 0\end{bmatrix}$$ Upon letting $\theta=\sqrt{a^2 + b^2 +c^2}$ , show that we obtain the identity (which is the Rodrigues formula) $$EXP (A)=I_3 + \frac{sin \theta}{\theta} A+ \frac{I-cos \theta}{\theta^2} A^2$$ I am not sure how we get the expressions $$A^{2n}=(-1)^{n+1} \theta^{2(n+1)}\begin{bmatrix} -(b^2+c^2) & ab & ac \\ab &  -(a^2+c^2) & bc\\ ac & bc & -(a^2+b^2)\end{bmatrix}$$ and $$A^{2n+1}=(-1)^n \theta^{2n}\begin{bmatrix} 0 & -c & b \\c &  0 & -a\\ -b & a & 0\end{bmatrix}$$ I understand that you look at the powers of $A$, $A^2$, $A^3$ and so on. I also understand that you get $A^{2n}$ for even powers of n and $A^{2n+1}$ for odd powers of n. I work out $$A^2= \begin{bmatrix} -b^2-c^2 & ab & ac \\ab &  -a^2-c^2 & bc\\ ac & bc & -a^2-b^2\end{bmatrix}$$ $$A^3= \begin{bmatrix} 0 & a^2c-c(-b^2-c^2) & -a^2b+b(-b^2-c^2)  \\-b^2 c+c(-a^2-c^2) &  0 & ab^2-a(-a^2-c^2)\\ bc^2-b(-a^2-b^2) & -ac^2+a(-a^2-b^2) &  0\end{bmatrix}$$ From $A^2$ how do you get the expression for $A^{2n}$? From $A^3$ how do you get the expression for $A^{2n+1}$? For example how is $\theta$ incorporated?",,['differential-geometry']
71,Lie groups pre-requisites and reference,Lie groups pre-requisites and reference,,"What are the minimum pre-requisites in analysis (differential geometry) required to study Lie-groups? And for that material, what are some good references? I have done basic courses in Metric spaces, Topology, Complex analysis etc. and Linear Algebra and Functional analysis. I also have some knowledge of Curves and surfaces  ( $\mathbb{R^3}$ ). I have to do a reading in Lie groups and, perhaps, later continue with its representation theory. Though it is (probably?) an algebraic study, I would still like to know the role played by Lie groups and algebras in Geometry too. Ideally I would prefer to have a brief but sufficiently rigorous introduction in Differential geometry so that I may continue with the study of Lie groups without hindrance. For that if there is a reference recommendation then I would be really thankful.If there exist some lecture notes serving this purpose,then that would be great too.) Thanks in advance!","What are the minimum pre-requisites in analysis (differential geometry) required to study Lie-groups? And for that material, what are some good references? I have done basic courses in Metric spaces, Topology, Complex analysis etc. and Linear Algebra and Functional analysis. I also have some knowledge of Curves and surfaces  ( $\mathbb{R^3}$ ). I have to do a reading in Lie groups and, perhaps, later continue with its representation theory. Though it is (probably?) an algebraic study, I would still like to know the role played by Lie groups and algebras in Geometry too. Ideally I would prefer to have a brief but sufficiently rigorous introduction in Differential geometry so that I may continue with the study of Lie groups without hindrance. For that if there is a reference recommendation then I would be really thankful.If there exist some lecture notes serving this purpose,then that would be great too.) Thanks in advance!",,"['differential-geometry', 'reference-request', 'lie-groups']"
72,Why is this the equation of the tangent plane?,Why is this the equation of the tangent plane?,,"I want to find the equation of the tangent plane of the surface patch $\sigma (r, \theta)=(r\cosh \theta , r\sinh \theta , r^2)$ at the point $(1,0,1)$. I have done the following: The point $(1,0,1)$ corresponds to $\sigma (1,0)$. We have that $$\sigma_r=(\cosh \theta , \sinh \theta , 2r) \rightarrow \sigma_r(1,0)=(1,0,2) \\ \sigma_{\theta}=(r \sinh \theta , r \cosh \theta , 0) \rightarrow \sigma_{\theta}(1,0)=(0,1,0)$$ $$\sigma_r (1,0) \times \sigma_{\theta} (1,0)=(-2,0,1)$$ The equation of the tangent plane is given by the formula $$(-2, 0, 1) \cdot (x-1, y-0, z-1)=0 \\ \Rightarrow -2x+z+1=0$$ $$$$ In the solution of the book, the answer is $-2x - 2y + z =0$. Where is the mistake at my calculations?","I want to find the equation of the tangent plane of the surface patch $\sigma (r, \theta)=(r\cosh \theta , r\sinh \theta , r^2)$ at the point $(1,0,1)$. I have done the following: The point $(1,0,1)$ corresponds to $\sigma (1,0)$. We have that $$\sigma_r=(\cosh \theta , \sinh \theta , 2r) \rightarrow \sigma_r(1,0)=(1,0,2) \\ \sigma_{\theta}=(r \sinh \theta , r \cosh \theta , 0) \rightarrow \sigma_{\theta}(1,0)=(0,1,0)$$ $$\sigma_r (1,0) \times \sigma_{\theta} (1,0)=(-2,0,1)$$ The equation of the tangent plane is given by the formula $$(-2, 0, 1) \cdot (x-1, y-0, z-1)=0 \\ \Rightarrow -2x+z+1=0$$ $$$$ In the solution of the book, the answer is $-2x - 2y + z =0$. Where is the mistake at my calculations?",,"['differential-geometry', 'surfaces', 'plane-curves']"
73,Gradient vector field and level sets,Gradient vector field and level sets,,"So assume we have a complete Riemannian manifold $M$, and $f\in C^\infty(M)$. Suppose that $|\nabla f|=1$. Then if we let $p\in f^{-1}(0)$ does that imply that $f(\exp_p(t\nabla f))=t$. I asked an earlier question regarding the Cheeger-Gromell splitting theorem and the Busemann function, and it more or less reduces to this question.","So assume we have a complete Riemannian manifold $M$, and $f\in C^\infty(M)$. Suppose that $|\nabla f|=1$. Then if we let $p\in f^{-1}(0)$ does that imply that $f(\exp_p(t\nabla f))=t$. I asked an earlier question regarding the Cheeger-Gromell splitting theorem and the Busemann function, and it more or less reduces to this question.",,"['differential-geometry', 'riemannian-geometry', 'smooth-manifolds']"
74,What is the intuition behind differential forms? [duplicate],What is the intuition behind differential forms? [duplicate],,"This question already has answers here : What's the geometrical intuition behind differential forms? (2 answers) Closed 2 years ago . I am comfortable with the way physicists use differentials as elements of area/volume. I know the (algebraic) formal definition of differential forms, but it makes no intuitive sense, especially since it is not immediately compatible (to me) with the physicist POV. How do the two fit in?","This question already has answers here : What's the geometrical intuition behind differential forms? (2 answers) Closed 2 years ago . I am comfortable with the way physicists use differentials as elements of area/volume. I know the (algebraic) formal definition of differential forms, but it makes no intuitive sense, especially since it is not immediately compatible (to me) with the physicist POV. How do the two fit in?",,['differential-geometry']
75,Convexity over a manifold,Convexity over a manifold,,"First post on math.stackexchange! I have a question which probably requires a bit of Differential Geometry knowledge which I'm lacking. By definition a convex function over a vector space $V$ is such that $f(\lambda x+(1-\lambda)y) \leq \lambda f(x) + (1-\lambda)f(y)$ for $\lambda \in [0,1]$ and $x, y \in V$. Two ways to check convexity are: Compute the Hessian and verify that it is positive semidefinite everywhere Check that $\frac{d^2 f(x+ty)}{dt^2}\mid_{t=0} \geq 0$ for all $x, y \in V$ Even though these two are equivalent, sometimes I feel it is a bit easier to use the second condition. Now, if we define convexity over a manifold similarly to $(1)$, i.e. the Hessian is positive semi-definite everywhere, then what a natural equivalent of $(2)$ would be? I guess some additional term will pop-up because of the curvature of the manifold? Or if we differentiate similarly along a geodesic would be fine? Just a reference would be enough, thanks.","First post on math.stackexchange! I have a question which probably requires a bit of Differential Geometry knowledge which I'm lacking. By definition a convex function over a vector space $V$ is such that $f(\lambda x+(1-\lambda)y) \leq \lambda f(x) + (1-\lambda)f(y)$ for $\lambda \in [0,1]$ and $x, y \in V$. Two ways to check convexity are: Compute the Hessian and verify that it is positive semidefinite everywhere Check that $\frac{d^2 f(x+ty)}{dt^2}\mid_{t=0} \geq 0$ for all $x, y \in V$ Even though these two are equivalent, sometimes I feel it is a bit easier to use the second condition. Now, if we define convexity over a manifold similarly to $(1)$, i.e. the Hessian is positive semi-definite everywhere, then what a natural equivalent of $(2)$ would be? I guess some additional term will pop-up because of the curvature of the manifold? Or if we differentiate similarly along a geodesic would be fine? Just a reference would be enough, thanks.",,"['differential-geometry', 'manifolds', 'convex-analysis']"
76,Does bounded scalar curvature imply bounded Ricci curvature?,Does bounded scalar curvature imply bounded Ricci curvature?,,"Does bounded scalar curvature imply bounded Ricci curvature? It is trivial to show the converse, but I do not know whether the above is true. Inspired by a vaguely similar question , I am thinking that the product of a manifold with lower-unbounded and one with upper-unbounded Ricci curvature (provided the metrics be chosen carefully) might have bounded scalar curvature, but I am not sure.","Does bounded scalar curvature imply bounded Ricci curvature? It is trivial to show the converse, but I do not know whether the above is true. Inspired by a vaguely similar question , I am thinking that the product of a manifold with lower-unbounded and one with upper-unbounded Ricci curvature (provided the metrics be chosen carefully) might have bounded scalar curvature, but I am not sure.",,"['differential-geometry', 'riemannian-geometry', 'tensors', 'smooth-manifolds', 'curvature']"
77,Geodesic vector field is well-defined,Geodesic vector field is well-defined,,"Let $(M,g)$ be a Riemannian manifold. I just learnt that for a curve $x:I\to M$ to be a geodesic, the geodesic equation  $$\ddot{x}^k+\dot{x}^i\dot{x}^j\Gamma^k_{ij}=0$$ is equivalent to the condition that the curve $(x,\dot{x})$ in $TM$ is an integral curve of the vector field $$G=v^k\frac{\partial}{\partial x^k}-v^iv^j\Gamma^k_{ij}\frac{\partial}{\partial v^k}.$$ This is straightforward to verify, but I am unable to show that $G$ is a well-defined global vector field. Question: How do you show that if $(\tilde{x},\tilde{v})$ are other coordinates for the tangent bundle $TM$, then   $$\tilde{v}^k\frac{\partial}{\partial \tilde{x}^k}-\tilde{v}^i\tilde{v}^j\Gamma^k_{ij}\frac{\partial}{\partial \tilde{v}^k}=v^k\frac{\partial}{\partial x^k}-v^iv^j\Gamma^k_{ij}\frac{\partial}{\partial v^k}?\tag{1}$$   i.e., in the language of physicists, I want to show that ""$G$ transforms like a vector"". (I want to prove this without assuming existence and uniqueness of geodesics.) Attempt: Denote by $\tilde{G}$ and $G$ the left and right hand-side of $(1)$, respectively. Using the transformation $$\tilde{\Gamma}^k_{ij}=\frac{\partial x^p}{\partial\tilde{x}^i}\frac{\partial x^q}{\partial\tilde{x}^j}\Gamma^m_{pq}\frac{\partial\tilde{x}^k}{\partial x^m}+\frac{\partial\tilde{x}^k}{\partial x^m}\frac{\partial^2x^m}{\partial\tilde{x}^i\partial\tilde{x}^j}$$ I get $$\tilde{G}=G-v^rv^s\frac{\partial\tilde x^i}{\partial x^r}\frac{\partial\tilde x^j}{\partial x^s}\frac{\partial^2x^m}{\partial\tilde{x}^i\partial\tilde{x}^j}\frac{\partial}{\partial v^m}$$ But then, why does   $$v^rv^s\frac{\partial\tilde x^i}{\partial x^r}\frac{\partial\tilde x^j}{\partial x^s}\frac{\partial^2x^m}{\partial\tilde{x}^i\partial\tilde{x}^j}=0?$$","Let $(M,g)$ be a Riemannian manifold. I just learnt that for a curve $x:I\to M$ to be a geodesic, the geodesic equation  $$\ddot{x}^k+\dot{x}^i\dot{x}^j\Gamma^k_{ij}=0$$ is equivalent to the condition that the curve $(x,\dot{x})$ in $TM$ is an integral curve of the vector field $$G=v^k\frac{\partial}{\partial x^k}-v^iv^j\Gamma^k_{ij}\frac{\partial}{\partial v^k}.$$ This is straightforward to verify, but I am unable to show that $G$ is a well-defined global vector field. Question: How do you show that if $(\tilde{x},\tilde{v})$ are other coordinates for the tangent bundle $TM$, then   $$\tilde{v}^k\frac{\partial}{\partial \tilde{x}^k}-\tilde{v}^i\tilde{v}^j\Gamma^k_{ij}\frac{\partial}{\partial \tilde{v}^k}=v^k\frac{\partial}{\partial x^k}-v^iv^j\Gamma^k_{ij}\frac{\partial}{\partial v^k}?\tag{1}$$   i.e., in the language of physicists, I want to show that ""$G$ transforms like a vector"". (I want to prove this without assuming existence and uniqueness of geodesics.) Attempt: Denote by $\tilde{G}$ and $G$ the left and right hand-side of $(1)$, respectively. Using the transformation $$\tilde{\Gamma}^k_{ij}=\frac{\partial x^p}{\partial\tilde{x}^i}\frac{\partial x^q}{\partial\tilde{x}^j}\Gamma^m_{pq}\frac{\partial\tilde{x}^k}{\partial x^m}+\frac{\partial\tilde{x}^k}{\partial x^m}\frac{\partial^2x^m}{\partial\tilde{x}^i\partial\tilde{x}^j}$$ I get $$\tilde{G}=G-v^rv^s\frac{\partial\tilde x^i}{\partial x^r}\frac{\partial\tilde x^j}{\partial x^s}\frac{\partial^2x^m}{\partial\tilde{x}^i\partial\tilde{x}^j}\frac{\partial}{\partial v^m}$$ But then, why does   $$v^rv^s\frac{\partial\tilde x^i}{\partial x^r}\frac{\partial\tilde x^j}{\partial x^s}\frac{\partial^2x^m}{\partial\tilde{x}^i\partial\tilde{x}^j}=0?$$",,"['differential-geometry', 'riemannian-geometry', 'smooth-manifolds', 'geodesic']"
78,"What is meant by ""The Lie derivative commutes with contraction""?","What is meant by ""The Lie derivative commutes with contraction""?",,"This was stated recently in a GR course I am taking, and I found it also stated on Wikipedia (second paragraph ). I simply don't know what is meant by this. For a vector $X$ and 1-form $\eta$, I would define the contraction as $$ \eta(X) $$ Whilst the Lie derivative of this quantity is $$ \mathcal{L}_Y(\eta(X)) = (\mathcal{L}_Y\eta)(X) + \eta(\mathcal{L}_Y X) $$ By the Leibniz rule. So I can't see what ""commutes"" could mean in this context.","This was stated recently in a GR course I am taking, and I found it also stated on Wikipedia (second paragraph ). I simply don't know what is meant by this. For a vector $X$ and 1-form $\eta$, I would define the contraction as $$ \eta(X) $$ Whilst the Lie derivative of this quantity is $$ \mathcal{L}_Y(\eta(X)) = (\mathcal{L}_Y\eta)(X) + \eta(\mathcal{L}_Y X) $$ By the Leibniz rule. So I can't see what ""commutes"" could mean in this context.",,"['differential-geometry', 'lie-derivative']"
79,Which Lie groups are also symmetric spaces?,Which Lie groups are also symmetric spaces?,,"I've scanned some of the literature on this, but couldn't find an answer to the following simple questions (probably because I'm not an expert): Q1: Let G be a Lie group with a left-invariant metric. What are some simple criteria for G to be symmetric, namely, for G to admit, for any point and geodesic through that point, an isometry reversing that geodesic? Q2: In three dimensions, in terms of the structure constants, one can easily work out essentially all simply-connected groups very concretely. Is there a criterion for going through the list of 3D Lie groups, looking at the structure constants, and deciding which ones are symmetric spaces? Thank you for your time!","I've scanned some of the literature on this, but couldn't find an answer to the following simple questions (probably because I'm not an expert): Q1: Let G be a Lie group with a left-invariant metric. What are some simple criteria for G to be symmetric, namely, for G to admit, for any point and geodesic through that point, an isometry reversing that geodesic? Q2: In three dimensions, in terms of the structure constants, one can easily work out essentially all simply-connected groups very concretely. Is there a criterion for going through the list of 3D Lie groups, looking at the structure constants, and deciding which ones are symmetric spaces? Thank you for your time!",,"['differential-geometry', 'lie-groups']"
80,Gradient vector derived from the metric tensor,Gradient vector derived from the metric tensor,,"According to Frankel's book ""The Geometry of Physics"", the components of a contravariant gradient vector can be obtained from the inverse of the metric tensor as follows (in section 2.1d, Page 73): $$ (\nabla f)^i = \sum_j g^{ij} \frac{\partial f}{\partial x^j}, $$ while the metric sensor is: $$ g_{ij} = \bigg\langle \frac{\partial}{\partial x^i}, \frac{\partial}{\partial x^j} \bigg\rangle. $$ Take the spherical coordinate as example, \begin{align} x &= r\sin\theta\cos\phi \\ y &= r\sin\theta\sin\phi \\ z &= r\cos\theta \end{align} and let $J$ be the Jacobi matrix $$ J = \begin{pmatrix} \sin\theta\cos\phi & -r\sin\phi\sin\theta & r\cos\phi\cos\theta \\ \sin\theta\sin\phi & r\cos\phi\sin\theta & r\sin\phi\cos\theta \\ \cos\theta & 0 & -r\sin\theta \end{pmatrix}, $$ the metric tensor can be obtained as $$ \left( g_{ij} \right) = J^TJ = \begin{pmatrix} 1 & 0 & 0 \\ 0 & r^2\sin^2\theta & 0 \\ 0 & 0 & r^2 \end{pmatrix}. $$ Finally, the contravariant gradient vector can be obtained as follows according to the first equation: $$ \nabla f = \begin{pmatrix}\displaystyle{ \frac{\partial f}{\partial r} \\ \frac{1}{r^2\sin^2\theta} \frac{\partial f}{\partial \phi} \\ \frac{1}{r^2} \frac{\partial f}{\partial \theta}} \end{pmatrix}. $$ However, the correct answer is $$ \nabla f = \begin{pmatrix}\displaystyle{ \frac{\partial f}{\partial r} \\ \frac{1}{r\sin\theta} \frac{\partial f}{\partial \phi} \\ \frac{1}{r} \frac{\partial f}{\partial \theta}} \end{pmatrix}. $$ I don't know why I cannot get the correct answer using metric tensor. Could you please help me figure it out? Thank you!","According to Frankel's book ""The Geometry of Physics"", the components of a contravariant gradient vector can be obtained from the inverse of the metric tensor as follows (in section 2.1d, Page 73): $$ (\nabla f)^i = \sum_j g^{ij} \frac{\partial f}{\partial x^j}, $$ while the metric sensor is: $$ g_{ij} = \bigg\langle \frac{\partial}{\partial x^i}, \frac{\partial}{\partial x^j} \bigg\rangle. $$ Take the spherical coordinate as example, \begin{align} x &= r\sin\theta\cos\phi \\ y &= r\sin\theta\sin\phi \\ z &= r\cos\theta \end{align} and let $J$ be the Jacobi matrix $$ J = \begin{pmatrix} \sin\theta\cos\phi & -r\sin\phi\sin\theta & r\cos\phi\cos\theta \\ \sin\theta\sin\phi & r\cos\phi\sin\theta & r\sin\phi\cos\theta \\ \cos\theta & 0 & -r\sin\theta \end{pmatrix}, $$ the metric tensor can be obtained as $$ \left( g_{ij} \right) = J^TJ = \begin{pmatrix} 1 & 0 & 0 \\ 0 & r^2\sin^2\theta & 0 \\ 0 & 0 & r^2 \end{pmatrix}. $$ Finally, the contravariant gradient vector can be obtained as follows according to the first equation: $$ \nabla f = \begin{pmatrix}\displaystyle{ \frac{\partial f}{\partial r} \\ \frac{1}{r^2\sin^2\theta} \frac{\partial f}{\partial \phi} \\ \frac{1}{r^2} \frac{\partial f}{\partial \theta}} \end{pmatrix}. $$ However, the correct answer is $$ \nabla f = \begin{pmatrix}\displaystyle{ \frac{\partial f}{\partial r} \\ \frac{1}{r\sin\theta} \frac{\partial f}{\partial \phi} \\ \frac{1}{r} \frac{\partial f}{\partial \theta}} \end{pmatrix}. $$ I don't know why I cannot get the correct answer using metric tensor. Could you please help me figure it out? Thank you!",,['differential-geometry']
81,Is there any situation in which a geodesic maximize the path length between two points?,Is there any situation in which a geodesic maximize the path length between two points?,,"Some people (even in here) claim that geodesics are, in general, stationary curves. Locally speaking, geodesics always minimize arc length (see Manfredo, for example). But I can't visualize a surface having geodesics that maximize the arc length in Riemannian manifolds. Is it possible? Consider the sphere for instance (Figure 1 ). The geodesic represented as full line minimizes the path locally. What about the geodesic pictured as dashed line? Certainly, it's not maximize the arc length since there is a lot of other curves that have longer paths. Is this dashed geodesic also a locally minimum path? Or is it neither maximum nor minimum?","Some people (even in here) claim that geodesics are, in general, stationary curves. Locally speaking, geodesics always minimize arc length (see Manfredo, for example). But I can't visualize a surface having geodesics that maximize the arc length in Riemannian manifolds. Is it possible? Consider the sphere for instance (Figure 1 ). The geodesic represented as full line minimizes the path locally. What about the geodesic pictured as dashed line? Certainly, it's not maximize the arc length since there is a lot of other curves that have longer paths. Is this dashed geodesic also a locally minimum path? Or is it neither maximum nor minimum?",,['differential-geometry']
82,Curve from curvature,Curve from curvature,,It is possible to obtain the parameters of a curve in 2d simply by having only its curvature k(s)? I need to obtain its parametric equations in order to reconstruct the curve but i don't have any idea how or even if its possible? I try to search on internet but i couldn't find anything related to the problem.I even look into different differential geometry books but i couldn't found anything related to the problem,It is possible to obtain the parameters of a curve in 2d simply by having only its curvature k(s)? I need to obtain its parametric equations in order to reconstruct the curve but i don't have any idea how or even if its possible? I try to search on internet but i couldn't find anything related to the problem.I even look into different differential geometry books but i couldn't found anything related to the problem,,['differential-geometry']
83,Compute a parallel transport,Compute a parallel transport,,"Let $\mathbb{S}^{2} \subset \mathbb{R}^{3}$ be the $2$-sphere ($\mathbb{S}^{2} = \left\{ (x,y,z) \in \mathbb{R}^3, \; x^2+y^2+z^2 = 1 \right\}$). Let $p \in \mathbb{S}^{2}$ and $\xi \in T_{p}S^{2} = \left\{ p \right\}^{\perp} \simeq \mathbb{R}^2$. When I wanted to compute explicitly the parallel transport of $\xi$ along a geodesic $\gamma$ (such that $\gamma(0)=p$), I used the following ""trick"" : if $T_{\gamma,0,t}(\xi)$ denotes the parallel transport of $\xi$ from the point $p$ to $\gamma(t)$, along $\gamma$, then : $$\forall t, \; T_{\gamma,0,t}(\xi) \in T_{\gamma(t)}\mathbb{S}^{2}$$ and an orthogonal basis of $T_{\gamma(t)}\mathbb{S}^{2}$ is given by : $(e_{1}(t),e_{2}(t))=(\gamma'(t), \gamma(t) \wedge \gamma'(t))$. As a consequence, $T_{\gamma,0,t}(\xi)$ writes : $$ \forall t, \; T_{\gamma,0,t}(\xi) = \alpha(t) e_{1}(t) + \beta(t) e_{2}(t) $$ And, since the parallel transport is an isometry, $$ \left\langle T_{\gamma,0,t}(\xi),\gamma'(t) \right\rangle = \left\langle \xi,\gamma'(0) \right\rangle = \alpha^{2}(t) \Vert e_{1}(t) \Vert^{2} \tag{1}$$ and $$ \Vert T_{\gamma,0,t}(\xi) \Vert^{2} = \Vert \xi \Vert^{2} = \alpha^{2}(t) + \beta^{2}(t) \tag{2}$$ $(1)$ and $(2)$ allow to determine $\alpha$ and $\beta$.  But I think the method does not generalize to higher dimension.. Here is my idea : If I want to compute the parallel transport in $\mathbb{S}^{3} \subset \mathbb{R}^{4}$ using the same method, I could determine an orthogonal basis of $T_{\gamma(t)} \mathbb{S}^{3}$, say $(e_{1}(t),e_{2}(t),e_{3}(t))$ and write : $$ T_{\gamma,0,t}(\xi) = \alpha_{1}(t) e_{1}(t) + \alpha_{2}e_{2}(t) + \alpha_{3}(t) e_{3}(t) $$ but I don't know how I would determine $\alpha_{1},\alpha_{2}$ and $\alpha_{3}$ since the relations $\left\langle T_{\gamma,0,t}(\xi),\gamma'(t)\right\rangle = \left\langle \xi,\gamma'(0) \right\rangle$ and $\Vert T_{\gamma,0,t}(\xi) \Vert^{2} = \Vert \xi \Vert^{2}$ do not give enough information (mainly because two equations are not enough to determine the three $\alpha_{1},\alpha_{2}$ and $\alpha_{3}$)... Is there a way out with this method or shall I compute the parallel transport by solving (when possible) the differential equation ?","Let $\mathbb{S}^{2} \subset \mathbb{R}^{3}$ be the $2$-sphere ($\mathbb{S}^{2} = \left\{ (x,y,z) \in \mathbb{R}^3, \; x^2+y^2+z^2 = 1 \right\}$). Let $p \in \mathbb{S}^{2}$ and $\xi \in T_{p}S^{2} = \left\{ p \right\}^{\perp} \simeq \mathbb{R}^2$. When I wanted to compute explicitly the parallel transport of $\xi$ along a geodesic $\gamma$ (such that $\gamma(0)=p$), I used the following ""trick"" : if $T_{\gamma,0,t}(\xi)$ denotes the parallel transport of $\xi$ from the point $p$ to $\gamma(t)$, along $\gamma$, then : $$\forall t, \; T_{\gamma,0,t}(\xi) \in T_{\gamma(t)}\mathbb{S}^{2}$$ and an orthogonal basis of $T_{\gamma(t)}\mathbb{S}^{2}$ is given by : $(e_{1}(t),e_{2}(t))=(\gamma'(t), \gamma(t) \wedge \gamma'(t))$. As a consequence, $T_{\gamma,0,t}(\xi)$ writes : $$ \forall t, \; T_{\gamma,0,t}(\xi) = \alpha(t) e_{1}(t) + \beta(t) e_{2}(t) $$ And, since the parallel transport is an isometry, $$ \left\langle T_{\gamma,0,t}(\xi),\gamma'(t) \right\rangle = \left\langle \xi,\gamma'(0) \right\rangle = \alpha^{2}(t) \Vert e_{1}(t) \Vert^{2} \tag{1}$$ and $$ \Vert T_{\gamma,0,t}(\xi) \Vert^{2} = \Vert \xi \Vert^{2} = \alpha^{2}(t) + \beta^{2}(t) \tag{2}$$ $(1)$ and $(2)$ allow to determine $\alpha$ and $\beta$.  But I think the method does not generalize to higher dimension.. Here is my idea : If I want to compute the parallel transport in $\mathbb{S}^{3} \subset \mathbb{R}^{4}$ using the same method, I could determine an orthogonal basis of $T_{\gamma(t)} \mathbb{S}^{3}$, say $(e_{1}(t),e_{2}(t),e_{3}(t))$ and write : $$ T_{\gamma,0,t}(\xi) = \alpha_{1}(t) e_{1}(t) + \alpha_{2}e_{2}(t) + \alpha_{3}(t) e_{3}(t) $$ but I don't know how I would determine $\alpha_{1},\alpha_{2}$ and $\alpha_{3}$ since the relations $\left\langle T_{\gamma,0,t}(\xi),\gamma'(t)\right\rangle = \left\langle \xi,\gamma'(0) \right\rangle$ and $\Vert T_{\gamma,0,t}(\xi) \Vert^{2} = \Vert \xi \Vert^{2}$ do not give enough information (mainly because two equations are not enough to determine the three $\alpha_{1},\alpha_{2}$ and $\alpha_{3}$)... Is there a way out with this method or shall I compute the parallel transport by solving (when possible) the differential equation ?",,"['differential-geometry', 'manifolds', 'riemannian-geometry']"
84,What is the difference between intrinsic and extrinsic manifold?,What is the difference between intrinsic and extrinsic manifold?,,I'm asking this question because a course change on differential geometry at my university has updated the wording from extrinsic manifold to intrinsic manifold. This got me wonder as to what the difference between the two terms might be. Can someone illuminate with an example of what would be considered an intrinsic and what would be considered extrinsic manifold. Just for clarification purposes. Thanks,I'm asking this question because a course change on differential geometry at my university has updated the wording from extrinsic manifold to intrinsic manifold. This got me wonder as to what the difference between the two terms might be. Can someone illuminate with an example of what would be considered an intrinsic and what would be considered extrinsic manifold. Just for clarification purposes. Thanks,,"['differential-geometry', 'manifolds']"
85,Example of Something That's Not A Manifold,Example of Something That's Not A Manifold,,"Two examples of non-manifolds that I know are the cross and the cone. Also the sphere with a hair isn't a topological manifold. But what's an example of a topological space $X$ such that $X$ is not a manifold and $X\setminus\{p_1,\ldots p_n\}$ is not a manifold for all $n\in\mathbb{N}$ and $p_i\in X$?","Two examples of non-manifolds that I know are the cross and the cone. Also the sphere with a hair isn't a topological manifold. But what's an example of a topological space $X$ such that $X$ is not a manifold and $X\setminus\{p_1,\ldots p_n\}$ is not a manifold for all $n\in\mathbb{N}$ and $p_i\in X$?",,"['differential-geometry', 'manifolds', 'examples-counterexamples']"
86,Covariant Derivative of a vector field - Parallel Vector Field,Covariant Derivative of a vector field - Parallel Vector Field,,"I'm having trouble to understand the concept of Covariant Derivative of a vector field. The definition from doCarmo's book states that the Covariant Derivative $(\frac{Dw}{dt})(t), t \in I$ is defined as the orthogonal projection of $\frac{dw}{dt}$ in the tangent plane. Does that mean that if $w_0 \in T_pS$ is a vector in the tangent plane at point $p$, then its covariant derivative $Dw/dt$ is always zero? Since $dw_0/dt$ will be parallel to the normal $N$ at point $p$. Is that correct? If so, then for a vector field to be parallel, then every vector must be in the tangent plane. Is that also correct? Could you explain without using tensors and Riemannian Manifolds? Thank you","I'm having trouble to understand the concept of Covariant Derivative of a vector field. The definition from doCarmo's book states that the Covariant Derivative $(\frac{Dw}{dt})(t), t \in I$ is defined as the orthogonal projection of $\frac{dw}{dt}$ in the tangent plane. Does that mean that if $w_0 \in T_pS$ is a vector in the tangent plane at point $p$, then its covariant derivative $Dw/dt$ is always zero? Since $dw_0/dt$ will be parallel to the normal $N$ at point $p$. Is that correct? If so, then for a vector field to be parallel, then every vector must be in the tangent plane. Is that also correct? Could you explain without using tensors and Riemannian Manifolds? Thank you",,['differential-geometry']
87,Ricci Soliton geometric meaning,Ricci Soliton geometric meaning,,"I wonder what is the geometrical, intuitive meaning of a Ricci soliton on a manifold.  The definition that I use is as follows. $V$ is a vector field on the manifold, $g$ is a Riemannian metric. $\lambda$ a real constant. $$\mathcal L_Vg+2Ric+2\lambda g=0$$","I wonder what is the geometrical, intuitive meaning of a Ricci soliton on a manifold.  The definition that I use is as follows. $V$ is a vector field on the manifold, $g$ is a Riemannian metric. $\lambda$ a real constant. $$\mathcal L_Vg+2Ric+2\lambda g=0$$",,"['differential-geometry', 'riemannian-geometry']"
88,"Geodesics: a (for me) ""mysterious"" property related to affine parameters.","Geodesics: a (for me) ""mysterious"" property related to affine parameters.",,"Consider a Riemannian manifold $(M,g)$ with the Levi-Civita connection $\nabla$. If $D_t$ is the covariant derivative along curves descending from $\nabla$, a geodesic is a curve $\gamma: I\subseteq\mathbb R\longrightarrow M$ such that $D_t\gamma'=0$ where $\gamma'$ is the velocity vector field along $\gamma$. In coordinates (respect the coordinare frame $\frac{\partial}{\partial x^1},\ldots\frac{\partial}{\partial x^n}$) a geodesic is a curve that satisfies the following equation(s): $$\ddot \gamma^k(t)+ \dot\gamma^j(t)\dot\gamma^i(t)\Gamma^k_{ij}(\gamma(t))=0$$ It is evident that there aren't constraints for the parameter $t$, but on the book ""Carroll - Spacetime and relativity"" I read the following mysteriuous phrases: Notation: Here by the parametrization with the ""proper time"" $\tau$,  he means the parametrization with the arclength parameter. The equation $3.44$ is the same that I've just written above and  moreover the others cited equations deal with the variational approach to geodesics. So I don't understand  why, according to Carroll, if a curve satisfies the above equation(s), then its parametrization should be affine. The author doesn't explain this point.","Consider a Riemannian manifold $(M,g)$ with the Levi-Civita connection $\nabla$. If $D_t$ is the covariant derivative along curves descending from $\nabla$, a geodesic is a curve $\gamma: I\subseteq\mathbb R\longrightarrow M$ such that $D_t\gamma'=0$ where $\gamma'$ is the velocity vector field along $\gamma$. In coordinates (respect the coordinare frame $\frac{\partial}{\partial x^1},\ldots\frac{\partial}{\partial x^n}$) a geodesic is a curve that satisfies the following equation(s): $$\ddot \gamma^k(t)+ \dot\gamma^j(t)\dot\gamma^i(t)\Gamma^k_{ij}(\gamma(t))=0$$ It is evident that there aren't constraints for the parameter $t$, but on the book ""Carroll - Spacetime and relativity"" I read the following mysteriuous phrases: Notation: Here by the parametrization with the ""proper time"" $\tau$,  he means the parametrization with the arclength parameter. The equation $3.44$ is the same that I've just written above and  moreover the others cited equations deal with the variational approach to geodesics. So I don't understand  why, according to Carroll, if a curve satisfies the above equation(s), then its parametrization should be affine. The author doesn't explain this point.",,"['differential-geometry', 'geodesic']"
89,why positive scalar curvature manifolds,why positive scalar curvature manifolds,,"I am studying scalar curvature and I have seen that many mathematicians studied obstruction against positive scalar curvature (for example Stolz, Schick, Roe, J. Rosenberg, Hanke and  many others). Unfortunately, I couldn't find out why it is important that a manifolds has a positive scalar curvature metric. Does anyone knows why?","I am studying scalar curvature and I have seen that many mathematicians studied obstruction against positive scalar curvature (for example Stolz, Schick, Roe, J. Rosenberg, Hanke and  many others). Unfortunately, I couldn't find out why it is important that a manifolds has a positive scalar curvature metric. Does anyone knows why?",,"['differential-geometry', 'riemannian-geometry']"
90,Identification of each tangent space $T_pV$ with $V$ itself?,Identification of each tangent space  with  itself?,T_pV V,"I found this statement from my text very confusing: What does it mean by identification of each tangent space $T_pV$ with $V$ itself? - what does ""identification"" really mean here? If it means isomorphic, then it conflicts with my understanding that each tangent space $T_pV$ is locally isomorphic to $V$. What is $Xf$? I don't understand the expression. I don't know what is the function $f$. Thank you very much for your help.","I found this statement from my text very confusing: What does it mean by identification of each tangent space $T_pV$ with $V$ itself? - what does ""identification"" really mean here? If it means isomorphic, then it conflicts with my understanding that each tangent space $T_pV$ is locally isomorphic to $V$. What is $Xf$? I don't understand the expression. I don't know what is the function $f$. Thank you very much for your help.",,"['differential-geometry', 'differential-topology']"
91,Curvature (Gaussian) of a hypersphere,Curvature (Gaussian) of a hypersphere,,"I am looking for a general formula for the Gaussian curvature of an $n$-sphere (the set of points in $R^{n+1}$ equidistant from the origin) of radius $r$. From what I have read, there would be $n$ principal curvatures to consider, but since this space is so simple, I was hoping there would be a great deal of simplification. For a circle, the Gaussian curvature is $1/r$ and for a sphere it is $1/r^2$, but it seems too simple for it to be $1/r^n$ for $S^n$. However if it is indeed so, I would gladly welcome any sources, or just pointers in the right direction.","I am looking for a general formula for the Gaussian curvature of an $n$-sphere (the set of points in $R^{n+1}$ equidistant from the origin) of radius $r$. From what I have read, there would be $n$ principal curvatures to consider, but since this space is so simple, I was hoping there would be a great deal of simplification. For a circle, the Gaussian curvature is $1/r$ and for a sphere it is $1/r^2$, but it seems too simple for it to be $1/r^n$ for $S^n$. However if it is indeed so, I would gladly welcome any sources, or just pointers in the right direction.",,"['differential-geometry', 'curvature']"
92,Trivial Tangent and Cotangent Bundles,Trivial Tangent and Cotangent Bundles,,"If we have a smooth manifold $M$, why is the tangent bundle $TM$ trivial (as a vector bundle) iff the cotangent bundle $T^*M$ is trivial as well?","If we have a smooth manifold $M$, why is the tangent bundle $TM$ trivial (as a vector bundle) iff the cotangent bundle $T^*M$ is trivial as well?",,"['differential-geometry', 'manifolds', 'vector-bundles']"
93,"do Carmo: near isolated zeros, killing field tangent to geodesic spheres","do Carmo: near isolated zeros, killing field tangent to geodesic spheres",,"Exercise 3.5b of do Carmo's Riemannian Geometry asks the reader to prove that given a Killing field $X$ on a manifold $M$, an isolated zero $p$ of $X$, and a normal neighborhood $U$ of $p$ in which $X$ has no other zeros, $X$ is tangent (in $U$) to the geodesic spheres centered at $p$. I have a ""proof"", but it doesn't use the fact that $X_p=0$, so I must be missing something. Here's the ""proof"": Let $\phi_t$ be the flow of $X$ on $U$, and let $q=\exp_p{v}\in U$. Since $\phi_t$ is an isometry, $\phi_t(q) = \exp_{\phi_t(p)} d(\phi_t)_p v$. So, denoting the radial distance function at $p$ by $r_p$, we get $$r_{\phi_t(p)}(\phi_t(q)) = \|d(\phi_t)_pv\| = \|v\|,$$ which means $\frac{d}{dt}\!\left[r_{\phi_t(p)}(\phi_t(q)) \right]=0$. But by the chain rule, $$\frac{d}{dt}\!\left[r_{\phi_t(p)}(\phi_t(q)) \right] =  \begin{pmatrix} \text{stuff} &d(r_p)_q X_q \end{pmatrix},$$ where $\text{stuff}$ is an unimportant block matrix. Thus, $d(r_p)_q X_q=0$. Hence, $\left\langle \frac{\partial}{\partial r_p}, X\right\rangle\equiv 0$. Thus, $X$ is tangent to the geodesic spheres in $U$. What did I miss?","Exercise 3.5b of do Carmo's Riemannian Geometry asks the reader to prove that given a Killing field $X$ on a manifold $M$, an isolated zero $p$ of $X$, and a normal neighborhood $U$ of $p$ in which $X$ has no other zeros, $X$ is tangent (in $U$) to the geodesic spheres centered at $p$. I have a ""proof"", but it doesn't use the fact that $X_p=0$, so I must be missing something. Here's the ""proof"": Let $\phi_t$ be the flow of $X$ on $U$, and let $q=\exp_p{v}\in U$. Since $\phi_t$ is an isometry, $\phi_t(q) = \exp_{\phi_t(p)} d(\phi_t)_p v$. So, denoting the radial distance function at $p$ by $r_p$, we get $$r_{\phi_t(p)}(\phi_t(q)) = \|d(\phi_t)_pv\| = \|v\|,$$ which means $\frac{d}{dt}\!\left[r_{\phi_t(p)}(\phi_t(q)) \right]=0$. But by the chain rule, $$\frac{d}{dt}\!\left[r_{\phi_t(p)}(\phi_t(q)) \right] =  \begin{pmatrix} \text{stuff} &d(r_p)_q X_q \end{pmatrix},$$ where $\text{stuff}$ is an unimportant block matrix. Thus, $d(r_p)_q X_q=0$. Hence, $\left\langle \frac{\partial}{\partial r_p}, X\right\rangle\equiv 0$. Thus, $X$ is tangent to the geodesic spheres in $U$. What did I miss?",,['differential-geometry']
94,Every point in S is umbilical $\rightarrow $ S is a plane or sphere.,Every point in S is umbilical  S is a plane or sphere.,\rightarrow ,"Umbilic points on a connected smooth surface problem Here we have a proof that if every point in a surface $S\subset\mathbb{R}^3$ is umbilical then it is contained in a sphere or a plane. But this proof only works for open sets of S. In Manfredo's Differential Geometry of Curves and Surfaces is a proof that if this is true in a neighborhood of $p$, for all $p\in S$, then the surface is contained in a plane or sphere. It is the second part of the proof. But at certain point he says ""Since S is connected, given any other point $r$ in S there is a continuous curve in S, $\alpha: I\rightarrow S$ such that $\alpha (0)=p$, $\alpha (1)=r$. how can this be true in general? Connectedness does not imply path connected in general, right?","Umbilic points on a connected smooth surface problem Here we have a proof that if every point in a surface $S\subset\mathbb{R}^3$ is umbilical then it is contained in a sphere or a plane. But this proof only works for open sets of S. In Manfredo's Differential Geometry of Curves and Surfaces is a proof that if this is true in a neighborhood of $p$, for all $p\in S$, then the surface is contained in a plane or sphere. It is the second part of the proof. But at certain point he says ""Since S is connected, given any other point $r$ in S there is a continuous curve in S, $\alpha: I\rightarrow S$ such that $\alpha (0)=p$, $\alpha (1)=r$. how can this be true in general? Connectedness does not imply path connected in general, right?",,['differential-geometry']
95,Thoughts about sectional curvature,Thoughts about sectional curvature,,"I'm currently trying to understand the sectional curvature of riemannian manifolds and I don't know if I'm thinking correctly. So, say we have a riemannian manifold $(M,g)$ with constant sectional curvature $k$. As far as i know the curvature at any given point is completely determined by the metric $g$. After doing some calculations it seems true to me, that if we equip $M$ with a new metric  $$ \tilde{g} = \lambda \cdot g, $$ where $\lambda$ is just some strictly positive scalar, the curvature of the manifold $(M,\tilde{g})$ is scaled in the same way, i.e. $(M,\tilde{g})$ has constant sectional curvature $\lambda \cdot k$. Now, I know that the sectional curvature of the sphere with radius $1$ is equal to $1$ and the curvature of the sphere with radius $2$ is equal to $\frac{1}{4}$. I'm wondering if, from a riemannian geometry viewpoint, it's somehow the same to look at the radius $2$ sphere, embedded in euclidean space OR the radius $1$ sphere, equipped with the ""compressed"" metric $\frac{1}{4}g$, where $g$ is the usual scalar product of $\mathbb{R}^n$. This is probably a rather soft question, but maybe someone has something to add or can correct my reasoning :)","I'm currently trying to understand the sectional curvature of riemannian manifolds and I don't know if I'm thinking correctly. So, say we have a riemannian manifold $(M,g)$ with constant sectional curvature $k$. As far as i know the curvature at any given point is completely determined by the metric $g$. After doing some calculations it seems true to me, that if we equip $M$ with a new metric  $$ \tilde{g} = \lambda \cdot g, $$ where $\lambda$ is just some strictly positive scalar, the curvature of the manifold $(M,\tilde{g})$ is scaled in the same way, i.e. $(M,\tilde{g})$ has constant sectional curvature $\lambda \cdot k$. Now, I know that the sectional curvature of the sphere with radius $1$ is equal to $1$ and the curvature of the sphere with radius $2$ is equal to $\frac{1}{4}$. I'm wondering if, from a riemannian geometry viewpoint, it's somehow the same to look at the radius $2$ sphere, embedded in euclidean space OR the radius $1$ sphere, equipped with the ""compressed"" metric $\frac{1}{4}g$, where $g$ is the usual scalar product of $\mathbb{R}^n$. This is probably a rather soft question, but maybe someone has something to add or can correct my reasoning :)",,"['differential-geometry', 'riemannian-geometry']"
96,Pullback connection and curve,Pullback connection and curve,,"My teacher defined the pullback bundle and gave me an example: Let $\gamma:(-1,1) \to \mathbb{R}^2$ be a smooth curve. Then for $w \in \Gamma(\gamma^*T_p{\mathbb{R}^2})$, the pullback connection is   $$\nabla_{\frac{\partial}{\partial x}}w = \text{directional derivative along curve}$$ Can someone explain this? So this is the directional derivative of $w$ along $\frac{\partial}{\partial x}$? What would such a $w$ look like?","My teacher defined the pullback bundle and gave me an example: Let $\gamma:(-1,1) \to \mathbb{R}^2$ be a smooth curve. Then for $w \in \Gamma(\gamma^*T_p{\mathbb{R}^2})$, the pullback connection is   $$\nabla_{\frac{\partial}{\partial x}}w = \text{directional derivative along curve}$$ Can someone explain this? So this is the directional derivative of $w$ along $\frac{\partial}{\partial x}$? What would such a $w$ look like?",,['differential-geometry']
97,Equivalence of two definitions of differentiablitity on Regular Surfaces,Equivalence of two definitions of differentiablitity on Regular Surfaces,,"When dealing with differentiable surfaces one defines a function $f:S\rightarrow \mathbb{R}$ as being differentiable if its expression in local coordinates is differentiable. But one could also define it to be differentiable if there exists differentiable function $F: V\subset \mathbb{R}^3 \rightarrow \mathbb{R}$ from an open set $V$ of $\mathbb{R}^3$ such that $S\subset V$ and $F|_{S} = f$, i.e. a differentiable extension of $f$. Are these two definitions of differentiability equivalent? More precisely, when given a differentiable function on a surface can you always extend it to a differentiable function of an open set of $\mathbb{R}^3$ containing the surface?","When dealing with differentiable surfaces one defines a function $f:S\rightarrow \mathbb{R}$ as being differentiable if its expression in local coordinates is differentiable. But one could also define it to be differentiable if there exists differentiable function $F: V\subset \mathbb{R}^3 \rightarrow \mathbb{R}$ from an open set $V$ of $\mathbb{R}^3$ such that $S\subset V$ and $F|_{S} = f$, i.e. a differentiable extension of $f$. Are these two definitions of differentiability equivalent? More precisely, when given a differentiable function on a surface can you always extend it to a differentiable function of an open set of $\mathbb{R}^3$ containing the surface?",,"['differential-geometry', 'surfaces']"
98,What is an example of a vector field that is not left-invariant?,What is an example of a vector field that is not left-invariant?,,"Let $G$ be a Lie group, $L_g$ the left-translation on this group with differential $d L_g$. A vector field $X$ on $G$ is called left-invariant if $$ X \circ L_g = d L_g \circ X \quad \forall g \in G$$ i.e. $$ X_{gh} = (d L_g)_h (X_h) \quad \forall g,h \in G. $$ Now, this definition seems so natural to me that I cannot come up with a non-trivial counterexample for a vector field that is $\textit{not}$ left-invariant. In my mind, pushing forward on the tangent space is basically always the same as the group action... Could you provide me with such a counterexample that helps understand the notion of left-invariance?","Let $G$ be a Lie group, $L_g$ the left-translation on this group with differential $d L_g$. A vector field $X$ on $G$ is called left-invariant if $$ X \circ L_g = d L_g \circ X \quad \forall g \in G$$ i.e. $$ X_{gh} = (d L_g)_h (X_h) \quad \forall g,h \in G. $$ Now, this definition seems so natural to me that I cannot come up with a non-trivial counterexample for a vector field that is $\textit{not}$ left-invariant. In my mind, pushing forward on the tangent space is basically always the same as the group action... Could you provide me with such a counterexample that helps understand the notion of left-invariance?",,"['differential-geometry', 'lie-groups', 'lie-algebras', 'vector-fields']"
99,What exactly is a manifold?,What exactly is a manifold?,,"Wikipedia's ""Simple English"" entry describes a 2D map of the Earth as a manifold of the planet Earth. Does this mean that in mathematics a manifold is essentially a representation of something that otherwise would difficult to ""model in another way"" in order to use it for some other purpose? I have no idea what I'm talking about, but I am curious.","Wikipedia's ""Simple English"" entry describes a 2D map of the Earth as a manifold of the planet Earth. Does this mean that in mathematics a manifold is essentially a representation of something that otherwise would difficult to ""model in another way"" in order to use it for some other purpose? I have no idea what I'm talking about, but I am curious.",,"['differential-geometry', 'terminology', 'intuition', 'definition', 'manifolds']"
