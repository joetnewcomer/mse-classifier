,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Cotangent bundle of a $n$-dimensional differentiable manifold is a $2n$-dimensional manifold,Cotangent bundle of a -dimensional differentiable manifold is a -dimensional manifold,n 2n,How to prove that cotangent bundle of a $n$ -dimensional differentiable manifold is a $2n$ -dimensional manifold? Detailed explanation is welcome. Thanks in advance.,How to prove that cotangent bundle of a -dimensional differentiable manifold is a -dimensional manifold? Detailed explanation is welcome. Thanks in advance.,n 2n,"['differential-geometry', 'manifolds', 'vector-bundles']"
1,Hessian matrix on Riemannian manifolds,Hessian matrix on Riemannian manifolds,,"$(M, g)$ is a Riemannian manifold, and $u$ is a smooth function on $M$, one says that under a normal coordinate system, $\operatorname{Hess}(u)_{ij} = (u_{lk} - u_h \Gamma^h _{lk})B^{li}B^{kj}$, where  $(B^{ij})$ is the square  root of matrix of $(g^{ij})$, and $(g^{ij})$ is the inverse matrix of $(g_{ij})$. How to get this conclusion?","$(M, g)$ is a Riemannian manifold, and $u$ is a smooth function on $M$, one says that under a normal coordinate system, $\operatorname{Hess}(u)_{ij} = (u_{lk} - u_h \Gamma^h _{lk})B^{li}B^{kj}$, where  $(B^{ij})$ is the square  root of matrix of $(g^{ij})$, and $(g^{ij})$ is the inverse matrix of $(g_{ij})$. How to get this conclusion?",,"['differential-geometry', 'riemannian-geometry']"
2,Continuous function approximation on manifolds,Continuous function approximation on manifolds,,"I am asked to show that every cont. function from a manifold M to $\mathbb{R}$ can be approximated by smooth functions. Try: let f be a map from M to the reals(R). Let ${s_{i}, U_{i}}$ be our atlas. Then $f(p)$ can be rewritten as $fs_{i}^{-1}$ at $s_{i}(p)$. Now, since $f$ is cont. and $s_{i}$ is a chart, their composition is cont. Now, we have $f$ represented by all these cont. maps according to the appropriate charts. But notice that $fs_{i}^{-1}$ is a map from the reals to the reals, and hence we invoke the Wierstrass approximation theorem and say there exists a polynomial $P(x)_{i}$, such that the supremum of the distance between $P(x)_{i}$ and $fs_{i}^{-1}$ is less than arbitrary $\epsilon_{i}.$ Hence, a candidate for the desired function is $\{P(x)_{i} : x = s_{i}(p)\}$. I hope this makes, its the collection of all these approximating polynomials, in accordance with the charts. Now the issue is showing that this map is smooth. I am assuming the coordinate transformations are supposed to come in here, but i am at a loss. Thanks in advance.","I am asked to show that every cont. function from a manifold M to $\mathbb{R}$ can be approximated by smooth functions. Try: let f be a map from M to the reals(R). Let ${s_{i}, U_{i}}$ be our atlas. Then $f(p)$ can be rewritten as $fs_{i}^{-1}$ at $s_{i}(p)$. Now, since $f$ is cont. and $s_{i}$ is a chart, their composition is cont. Now, we have $f$ represented by all these cont. maps according to the appropriate charts. But notice that $fs_{i}^{-1}$ is a map from the reals to the reals, and hence we invoke the Wierstrass approximation theorem and say there exists a polynomial $P(x)_{i}$, such that the supremum of the distance between $P(x)_{i}$ and $fs_{i}^{-1}$ is less than arbitrary $\epsilon_{i}.$ Hence, a candidate for the desired function is $\{P(x)_{i} : x = s_{i}(p)\}$. I hope this makes, its the collection of all these approximating polynomials, in accordance with the charts. Now the issue is showing that this map is smooth. I am assuming the coordinate transformations are supposed to come in here, but i am at a loss. Thanks in advance.",,"['differential-geometry', 'manifolds', 'differential-topology']"
3,Change of coordinates with Jacobian,Change of coordinates with Jacobian,,"We know that the change of variable in $\mathbb{R^n}$ with a $T: V \to U$ is a diffeomorphism of open sets in $\mathbb{R^n}$ and $f$ is an integrable function on $U$. Then $$\int_U f dx_1 \cdots dx_k = \int_V (f \circ T) |\det(dT)|dy_1 \cdots dy_k.$$ How can i prove this in Manifolds : $ dT_1 \wedge … \wedge dT_n = J(T) dy_1 \wedge … \wedge dy_n$ where $J(T)$ is the Jacobian determinant of T. Ok this is my new answer but please check it! σ $T^∗dx_1···dT_n = dT_1 \wedge … \wedge dT_n = (\sum_i^n\frac{∂T_1}{∂y_{i_1}} dy_{i_1})\wedge ···\wedge (\sum_i^n\frac{∂T_n}{∂y_{i_n}} dy_{i_n})  = $ $\sum_{1=i_1,…,1_n}^n\prod_{j=1}^n (\frac{∂T_j}{∂y_{i_1}}) dy_{i_1}\wedge ···\wedge dy_{i_n} = $ $\sum_{σ \in S_n} \prod_{j=1}^n (\frac{∂T_j}{∂y_{σ(j)}}) dy_{σ(1)}\wedge ···\wedge dy_{σ(n)} = $ $\sum_{σ \in S_n} \epsilon(σ) \prod_{j=1}^n (\frac{∂T_j}{∂y_{σ(j)}}) dy_{1}\wedge ···\wedge dy_{n} =$ $ det (\frac{∂T_j}{∂y_{j}})_{i,j} dy_{1}\wedge ···\wedge dy_{n} =$ $ J(T) dy_{1}\wedge ···\wedge dy_{n}$ Is it correct? Thanks for your comments please check it!!","We know that the change of variable in $\mathbb{R^n}$ with a $T: V \to U$ is a diffeomorphism of open sets in $\mathbb{R^n}$ and $f$ is an integrable function on $U$. Then $$\int_U f dx_1 \cdots dx_k = \int_V (f \circ T) |\det(dT)|dy_1 \cdots dy_k.$$ How can i prove this in Manifolds : $ dT_1 \wedge … \wedge dT_n = J(T) dy_1 \wedge … \wedge dy_n$ where $J(T)$ is the Jacobian determinant of T. Ok this is my new answer but please check it! σ $T^∗dx_1···dT_n = dT_1 \wedge … \wedge dT_n = (\sum_i^n\frac{∂T_1}{∂y_{i_1}} dy_{i_1})\wedge ···\wedge (\sum_i^n\frac{∂T_n}{∂y_{i_n}} dy_{i_n})  = $ $\sum_{1=i_1,…,1_n}^n\prod_{j=1}^n (\frac{∂T_j}{∂y_{i_1}}) dy_{i_1}\wedge ···\wedge dy_{i_n} = $ $\sum_{σ \in S_n} \prod_{j=1}^n (\frac{∂T_j}{∂y_{σ(j)}}) dy_{σ(1)}\wedge ···\wedge dy_{σ(n)} = $ $\sum_{σ \in S_n} \epsilon(σ) \prod_{j=1}^n (\frac{∂T_j}{∂y_{σ(j)}}) dy_{1}\wedge ···\wedge dy_{n} =$ $ det (\frac{∂T_j}{∂y_{j}})_{i,j} dy_{1}\wedge ···\wedge dy_{n} =$ $ J(T) dy_{1}\wedge ···\wedge dy_{n}$ Is it correct? Thanks for your comments please check it!!",,['differential-geometry']
4,Kähler form on a complex projective space,Kähler form on a complex projective space,,"This is what I found in: H.B. Lawson, Lectures on Minimal Submanifolds, Vol.1, Publish or Perish, pp.34-36. On a complex projective space Kähler form looks like this  \begin{align} \omega_{0}=\frac{\sqrt{-1}}{2}\sum_{i,j}g_{ij}dz^{i}\wedge d\overline{z}^{j}. \end{align} On the other hand  \begin{align} \omega_{0} = 4\partial\overline{\partial}\log |z|^{2}. \end{align} $z=(z^{0},..,z^{n})$. When I calculate the second equation I can not get the same expression as in the first equation. The problem is $\sqrt{-1}$, I can not get it. What would be the problem here? Thank you.","This is what I found in: H.B. Lawson, Lectures on Minimal Submanifolds, Vol.1, Publish or Perish, pp.34-36. On a complex projective space Kähler form looks like this  \begin{align} \omega_{0}=\frac{\sqrt{-1}}{2}\sum_{i,j}g_{ij}dz^{i}\wedge d\overline{z}^{j}. \end{align} On the other hand  \begin{align} \omega_{0} = 4\partial\overline{\partial}\log |z|^{2}. \end{align} $z=(z^{0},..,z^{n})$. When I calculate the second equation I can not get the same expression as in the first equation. The problem is $\sqrt{-1}$, I can not get it. What would be the problem here? Thank you.",,"['differential-geometry', 'kahler-manifolds']"
5,Curvature Using Circles,Curvature Using Circles,,"Given the equation $(x - h)^2 + (y - k)^2 = r^2$ representing the family of all circles of radius r at the point $(h,k)$ if we try to form the differential equation representing this family we find an equation of the form $$\kappa = \frac{1}{r} = \frac{y''}{\sqrt{(1 + y'^2)^3}}$$ which is surprisingly the equation for the curvature of a plane curve (ignoring absolute values which arise in the derivation). But this expression was derived interpreting $y$ as part of a circle, how in the world can one justify plugging in other functions & saying this represents the curvature of that curve at the point? I know you're trying to say that, locally, the curve moves as though it were moving along the arc of a circle of radius $r$, but there seems to be a jump in my mind as to how you get that interpretation out of what I've written.","Given the equation $(x - h)^2 + (y - k)^2 = r^2$ representing the family of all circles of radius r at the point $(h,k)$ if we try to form the differential equation representing this family we find an equation of the form $$\kappa = \frac{1}{r} = \frac{y''}{\sqrt{(1 + y'^2)^3}}$$ which is surprisingly the equation for the curvature of a plane curve (ignoring absolute values which arise in the derivation). But this expression was derived interpreting $y$ as part of a circle, how in the world can one justify plugging in other functions & saying this represents the curvature of that curve at the point? I know you're trying to say that, locally, the curve moves as though it were moving along the arc of a circle of radius $r$, but there seems to be a jump in my mind as to how you get that interpretation out of what I've written.",,['differential-geometry']
6,Relation between de Rham cohomology and integration,Relation between de Rham cohomology and integration,,"This question is a follow-up to When does a null integral implies that a form is exact? . As mentionned in the selected answer, given certain conditions it is possible to find an isomorphism between the top de Rham cohomology and the integral $\int_M \omega$ of the members of each equivalence class $\omega$. Moving on to de Rham cohomology below the top one. Taking the example of the torus as in http://topospaces.subwiki.org/wiki/Torus , is it possible to link the rank $\binom{n}{k}$ to the values of specific integrals in a similar fashion ?","This question is a follow-up to When does a null integral implies that a form is exact? . As mentionned in the selected answer, given certain conditions it is possible to find an isomorphism between the top de Rham cohomology and the integral $\int_M \omega$ of the members of each equivalence class $\omega$. Moving on to de Rham cohomology below the top one. Taking the example of the torus as in http://topospaces.subwiki.org/wiki/Torus , is it possible to link the rank $\binom{n}{k}$ to the values of specific integrals in a similar fashion ?",,"['differential-geometry', 'integration', 'differential-forms']"
7,Approximate parallel transport using Jacobi fields,Approximate parallel transport using Jacobi fields,,"Let $M$ be a riemannian manifold (let $\left\langle \cdot,\cdot \right\rangle_{p}$ be the scalar product on $T_{p}M$). Let $p \in M$ and $\xi \in T_{p}M$. We consider the geodesic $\gamma \, : \, t \, \mapsto \, \exp_{\gamma(0)}(t\xi)$ where $\gamma(0)=p$. Let $\eta \in T_{p}M$. We can introduce a ""small perturbation"" of the geodesic $\gamma$ : $\gamma_{\varepsilon}(t) = \exp_{\gamma(0)}(t(\xi+\varepsilon \eta))$. Let $f \, : \, (t,\varepsilon) \, \mapsto \, \exp_{\gamma(0)}(t(\xi + \varepsilon \eta))$. We definie $J(t) = \frac{\partial f}{\partial \varepsilon}(t,0)$. Then, $\forall t, \, J(t) \in T_{\gamma(t)}M$. $J$ is a Jacobi vector field. Let $P_{\gamma,0,t} \, : \, T_{p}M \, \rightarrow \, T_{\gamma(t)}M$ be the parallel transport along $\gamma$. I have read that we have the following approximation : for a ""small"" $\delta t$, $$ \frac{J(\delta t)}{\delta t} - P_{\gamma, 0, \delta t}(\eta) = o(\delta t) $$ The Jacobi vector field $J$ gives a first order approximation of the parallel transport of $\eta$ along the geodesic $\gamma$. I would like to prove this approximation but I don't really know how to start... Considering that $J(t) = \frac{\partial f}{\partial \varepsilon}(t,0)$, we can easily show that $$ J(t) = \mathrm{D}_{t \xi} \left( \exp_{\gamma(0)} \right) \cdot (t \eta) $$ So that, $J(\delta t) = \mathrm{D}_{\delta t \xi} \left( \exp_{\gamma(0)} \right) \cdot (\delta t \eta) = \delta t \,  \mathrm{D}_{\delta t \xi} \left( \exp_{\gamma(0)} \right) \cdot \eta$. Then, $$ \frac{J(\delta t)}{\delta t} = \mathrm{D}_{\delta t \xi} \left( \exp_{\gamma(0)} \right) \cdot \eta$$ We want to prove that $\mathrm{D}_{\delta t \xi} \left( \exp_{\gamma(0)} \right) \cdot \eta - P_{\gamma,0,\delta t}(\eta)$ goes to $0$ as $\delta t \, \rightarrow \, 0$. One idea I had was to consider $$ \Vert \mathrm{D}_{\delta t \xi} \left( \exp_{\gamma(0)} \right) \cdot \eta - P_{\gamma,0,\delta t}(\eta) \Vert_{\gamma(\delta t)}$$ since the parallel transport is a linear isometry, $\Vert P_{\gamma,0,\delta t}(\eta) , P_{\gamma,0,\delta t}(\eta) \Vert_{\gamma(\delta t)} = \Vert \eta \Vert_{p}$. But it doesn't seem to be very helpful. Can anyone give me a hint ? Thank you for your help.","Let $M$ be a riemannian manifold (let $\left\langle \cdot,\cdot \right\rangle_{p}$ be the scalar product on $T_{p}M$). Let $p \in M$ and $\xi \in T_{p}M$. We consider the geodesic $\gamma \, : \, t \, \mapsto \, \exp_{\gamma(0)}(t\xi)$ where $\gamma(0)=p$. Let $\eta \in T_{p}M$. We can introduce a ""small perturbation"" of the geodesic $\gamma$ : $\gamma_{\varepsilon}(t) = \exp_{\gamma(0)}(t(\xi+\varepsilon \eta))$. Let $f \, : \, (t,\varepsilon) \, \mapsto \, \exp_{\gamma(0)}(t(\xi + \varepsilon \eta))$. We definie $J(t) = \frac{\partial f}{\partial \varepsilon}(t,0)$. Then, $\forall t, \, J(t) \in T_{\gamma(t)}M$. $J$ is a Jacobi vector field. Let $P_{\gamma,0,t} \, : \, T_{p}M \, \rightarrow \, T_{\gamma(t)}M$ be the parallel transport along $\gamma$. I have read that we have the following approximation : for a ""small"" $\delta t$, $$ \frac{J(\delta t)}{\delta t} - P_{\gamma, 0, \delta t}(\eta) = o(\delta t) $$ The Jacobi vector field $J$ gives a first order approximation of the parallel transport of $\eta$ along the geodesic $\gamma$. I would like to prove this approximation but I don't really know how to start... Considering that $J(t) = \frac{\partial f}{\partial \varepsilon}(t,0)$, we can easily show that $$ J(t) = \mathrm{D}_{t \xi} \left( \exp_{\gamma(0)} \right) \cdot (t \eta) $$ So that, $J(\delta t) = \mathrm{D}_{\delta t \xi} \left( \exp_{\gamma(0)} \right) \cdot (\delta t \eta) = \delta t \,  \mathrm{D}_{\delta t \xi} \left( \exp_{\gamma(0)} \right) \cdot \eta$. Then, $$ \frac{J(\delta t)}{\delta t} = \mathrm{D}_{\delta t \xi} \left( \exp_{\gamma(0)} \right) \cdot \eta$$ We want to prove that $\mathrm{D}_{\delta t \xi} \left( \exp_{\gamma(0)} \right) \cdot \eta - P_{\gamma,0,\delta t}(\eta)$ goes to $0$ as $\delta t \, \rightarrow \, 0$. One idea I had was to consider $$ \Vert \mathrm{D}_{\delta t \xi} \left( \exp_{\gamma(0)} \right) \cdot \eta - P_{\gamma,0,\delta t}(\eta) \Vert_{\gamma(\delta t)}$$ since the parallel transport is a linear isometry, $\Vert P_{\gamma,0,\delta t}(\eta) , P_{\gamma,0,\delta t}(\eta) \Vert_{\gamma(\delta t)} = \Vert \eta \Vert_{p}$. But it doesn't seem to be very helpful. Can anyone give me a hint ? Thank you for your help.",,"['differential-geometry', 'riemannian-geometry']"
8,Quantitative Transversality,Quantitative Transversality,,"I came across the following problem while reading some literature in Dynamical Systems. Say I have an ambient Riemannian manifold $(M,g)$ and a pair of transverse embedded disks $D_1, D_2$ of complementary dimension. With some conditions, the common result in this situation is that the set $D_1 \cap D_2$ is finite. For my purposes, though, what I'd like is to have a lower bound on the distance between any two points of $D_1, D_2$. Obviously I need a notion of distance, hence the Riemannian metric $g$ on the ambient space $M$. However, it's also clear that I need some way of controlling the 'robustness' of the transversality of $D_1, D_2$, and also some way of controlling how wild the embeddings of $D_1, D_2$ are. Question 1: Given a uniform bound on the minimal angle $\theta_z$ between $T_z D_1$ and $T_z D_2$ in the metric $g$, where $z \in D_1 \cap D_2$, and some control over the second fundamental forms of $D_1, D_2$, is there a way to bound from below the minimal distance between two distinct points of $D_1 \cap D_2$? Clarification: The situation in my head is where $D_1$ is practically flat and $D_2$ can be very curved. What I want is a lower bound on either of the $D_1$ or $D_2$ distances between elements of $D_1 \cap D_2$. Question 2: Is there a name for this kind of problem? I feel like the methods used in the solution to this problem will be simple, but the overall estimate will likely be somewhat more tedious than an exercise. I would be very happy to be pointed to a geometry reference that carries out an example of this kind of computation. EDIT: One needs control over the extrinsic geometry of the embedding, and not just the intrinsic curvatures of the disks $D_i$ (see user72694's answer below).","I came across the following problem while reading some literature in Dynamical Systems. Say I have an ambient Riemannian manifold $(M,g)$ and a pair of transverse embedded disks $D_1, D_2$ of complementary dimension. With some conditions, the common result in this situation is that the set $D_1 \cap D_2$ is finite. For my purposes, though, what I'd like is to have a lower bound on the distance between any two points of $D_1, D_2$. Obviously I need a notion of distance, hence the Riemannian metric $g$ on the ambient space $M$. However, it's also clear that I need some way of controlling the 'robustness' of the transversality of $D_1, D_2$, and also some way of controlling how wild the embeddings of $D_1, D_2$ are. Question 1: Given a uniform bound on the minimal angle $\theta_z$ between $T_z D_1$ and $T_z D_2$ in the metric $g$, where $z \in D_1 \cap D_2$, and some control over the second fundamental forms of $D_1, D_2$, is there a way to bound from below the minimal distance between two distinct points of $D_1 \cap D_2$? Clarification: The situation in my head is where $D_1$ is practically flat and $D_2$ can be very curved. What I want is a lower bound on either of the $D_1$ or $D_2$ distances between elements of $D_1 \cap D_2$. Question 2: Is there a name for this kind of problem? I feel like the methods used in the solution to this problem will be simple, but the overall estimate will likely be somewhat more tedious than an exercise. I would be very happy to be pointed to a geometry reference that carries out an example of this kind of computation. EDIT: One needs control over the extrinsic geometry of the embedding, and not just the intrinsic curvatures of the disks $D_i$ (see user72694's answer below).",,"['reference-request', 'differential-geometry', 'differential-topology']"
9,How does $\operatorname{Ric} \ge 0$ guarentee the Busemann function is regular in the splitting theorem?,How does  guarentee the Busemann function is regular in the splitting theorem?,\operatorname{Ric} \ge 0,"Cheeger-Gromoll's famous splitting theorem says If $(M,g)$ contains a line and $\operatorname{Ric} \ge 0$. Then $(M,g)$ is isometric to a product. I want to know how does $\operatorname{Ric} \ge 0$ guarentee that the Busemann function is regular, since it's regular then by Morse theory $M$ is homeomorphic to a product.","Cheeger-Gromoll's famous splitting theorem says If $(M,g)$ contains a line and $\operatorname{Ric} \ge 0$. Then $(M,g)$ is isometric to a product. I want to know how does $\operatorname{Ric} \ge 0$ guarentee that the Busemann function is regular, since it's regular then by Morse theory $M$ is homeomorphic to a product.",,"['differential-geometry', 'riemannian-geometry', 'morse-theory']"
10,Examples of 2-dimensional foliations of a 4-sphere.,Examples of 2-dimensional foliations of a 4-sphere.,,"This is a follow up to The 4-sphere does not admit dimension 2 foliations , where I asked about the existence of nonsingular foliations of a 4-sphere. Since that question determined there are no such foliations, I am now looking for examples of any 2-dimensional foliations of the 4-sphere. The simplier the better; for instance the 3-sphere has a foliation coming from the Hopf map which one can explicitly describe with coordinates. I have been struggling to find something similar for the 4-sphere case and haven't had any luck. Does anyone know of any?","This is a follow up to The 4-sphere does not admit dimension 2 foliations , where I asked about the existence of nonsingular foliations of a 4-sphere. Since that question determined there are no such foliations, I am now looking for examples of any 2-dimensional foliations of the 4-sphere. The simplier the better; for instance the 3-sphere has a foliation coming from the Hopf map which one can explicitly describe with coordinates. I have been struggling to find something similar for the 4-sphere case and haven't had any luck. Does anyone know of any?",,"['differential-geometry', 'examples-counterexamples', 'foliations']"
11,"Uniqueness of the vector in $\mathbb{R}^n$ specified by the curl, divergence and the normal component","Uniqueness of the vector in  specified by the curl, divergence and the normal component",\mathbb{R}^n,"If I know the curl, and divergence of a n-component vector in a region, and its normal component around its boundary, is the vector uniquely specified? If yes, how do I prove it? Also, is there a straightforward way to solve these equations, and get the vector? $\partial_i V_i=s \,\,\,\,\, \partial_iV_j-\partial_jV_i=c_{ij}$","If I know the curl, and divergence of a n-component vector in a region, and its normal component around its boundary, is the vector uniquely specified? If yes, how do I prove it? Also, is there a straightforward way to solve these equations, and get the vector? $\partial_i V_i=s \,\,\,\,\, \partial_iV_j-\partial_jV_i=c_{ij}$",,['differential-geometry']
12,What is an overlap?,What is an overlap?,,"I want to ask what an overlap is. My teacher said that for example $1$: Everything is an overlap hence it is not locally finite. For example $2$, it doesnt overlap. Please teach me these two examples. Thanks.","I want to ask what an overlap is. My teacher said that for example $1$: Everything is an overlap hence it is not locally finite. For example $2$, it doesnt overlap. Please teach me these two examples. Thanks.",,"['real-analysis', 'linear-algebra', 'general-topology', 'differential-geometry', 'manifolds']"
13,Gradient in Riemannian manifold,Gradient in Riemannian manifold,,"I have a calculation involving a gradient and a parametrization, but I haven't been able to find out the relation between them. Let me explain. Let $f:X↦R$ be a smooth function and $\mathrm{grad}f\in \mathcal T X$ its gradient. $X$ is a Riemannian manifold, and therefore $\mathrm{grad}f$ has a norm. While my calculation requires this norm, the only expression that I have is through a parametrizion $\alpha:R^n \mapsto X$. This parametrization, yields the vector $\mathrm{grad}f \circ \alpha \in \mathcal T R^n$, whose norm I can compute. However, I haven't been able to find how these two norms are related. I hope someone can point me in the right direction. Thank you and have a nice day.","I have a calculation involving a gradient and a parametrization, but I haven't been able to find out the relation between them. Let me explain. Let $f:X↦R$ be a smooth function and $\mathrm{grad}f\in \mathcal T X$ its gradient. $X$ is a Riemannian manifold, and therefore $\mathrm{grad}f$ has a norm. While my calculation requires this norm, the only expression that I have is through a parametrizion $\alpha:R^n \mapsto X$. This parametrization, yields the vector $\mathrm{grad}f \circ \alpha \in \mathcal T R^n$, whose norm I can compute. However, I haven't been able to find how these two norms are related. I hope someone can point me in the right direction. Thank you and have a nice day.",,"['differential-geometry', 'riemannian-geometry']"
14,Classification of flat complex line bundles,Classification of flat complex line bundles,,"I'm having a contradiction with two different classifications of flat complex line bundles over a manifold $X$.  Suppose for simplicity that $H^2(X;\mathbb Z) = 0 = H^1(X;\mathbb C)$.  Then the only complex line bundle is the trivial one and (thinking in terms of connection 1-forms) isomorphism classes of line bundles with connection become just one-forms on $X$ modulo gauge transformations $\Omega^1(X;\mathbb C) \ni \theta \mapsto \theta^g:=\theta + g^{-1} dg$ where $g: X \to \mathbb C^\times$.  If $f: X \to \mathbb C$ is arbitrary and $g = e^f$ then $\theta^g = \theta + df$ is cohomologous to $\theta$.  Since $H^1(X;\mathbb C) = 0$ any 1-forms are cohomologous so there is just one equivalence class of flat connections. On the other hand, the Riemann-Hilbert correspondence says that there is a 1-to-1 correspondence between iso classes of flat line bundles with flat connection and representations of $\pi_1(X)$ on $\mathbb C$.  But in the situation above $\pi_1(X)$ can be something like $\mathbb Z/n\mathbb Z$, which has more than one rep on $\mathbb C$. What am I missing?  Is the equivalence of flat bundles under Riemann-Hilbert stronger than gauge equivalence?","I'm having a contradiction with two different classifications of flat complex line bundles over a manifold $X$.  Suppose for simplicity that $H^2(X;\mathbb Z) = 0 = H^1(X;\mathbb C)$.  Then the only complex line bundle is the trivial one and (thinking in terms of connection 1-forms) isomorphism classes of line bundles with connection become just one-forms on $X$ modulo gauge transformations $\Omega^1(X;\mathbb C) \ni \theta \mapsto \theta^g:=\theta + g^{-1} dg$ where $g: X \to \mathbb C^\times$.  If $f: X \to \mathbb C$ is arbitrary and $g = e^f$ then $\theta^g = \theta + df$ is cohomologous to $\theta$.  Since $H^1(X;\mathbb C) = 0$ any 1-forms are cohomologous so there is just one equivalence class of flat connections. On the other hand, the Riemann-Hilbert correspondence says that there is a 1-to-1 correspondence between iso classes of flat line bundles with flat connection and representations of $\pi_1(X)$ on $\mathbb C$.  But in the situation above $\pi_1(X)$ can be something like $\mathbb Z/n\mathbb Z$, which has more than one rep on $\mathbb C$. What am I missing?  Is the equivalence of flat bundles under Riemann-Hilbert stronger than gauge equivalence?",,"['differential-geometry', 'algebraic-topology', 'vector-bundles']"
15,Lagrangian subspaces,Lagrangian subspaces,,"Let $\Lambda_{n}$ be the set of all Lagrangian subspaces of $C^{n}$, and $P\in \Lambda_{n}$. Put $U_{P} = \{Q\in \Lambda_{n} : Q\cap (iP)=0\}$. There is an assertion that the set $U_{P}$ is homeomorphic to the real vector space of all symmetric endomorphisms of $P$. And then in the proof of it there is a fact that the subspaces $Q$ that intersect $iP$ only at $0$ are the graphs of the linear maps $\phi : P\to iP$. This is what I don't understand, any explanation or reference where I can find it would be helpful.","Let $\Lambda_{n}$ be the set of all Lagrangian subspaces of $C^{n}$, and $P\in \Lambda_{n}$. Put $U_{P} = \{Q\in \Lambda_{n} : Q\cap (iP)=0\}$. There is an assertion that the set $U_{P}$ is homeomorphic to the real vector space of all symmetric endomorphisms of $P$. And then in the proof of it there is a fact that the subspaces $Q$ that intersect $iP$ only at $0$ are the graphs of the linear maps $\phi : P\to iP$. This is what I don't understand, any explanation or reference where I can find it would be helpful.",,"['differential-geometry', 'symplectic-geometry']"
16,Question regarding Nash-Kuiper embedding theorem,Question regarding Nash-Kuiper embedding theorem,,"In Wikipedia description of Nash-Kuiper theorem, it says: Let $(M,g)$ be a Riemannian manifold and $f: M^{m} \rightarrow \mathbb{R}^n$ a short $C^{\infty}$-embedding into Euclidean space   $\mathbb{R}^n$, where $n \ge m+1$. Then for arbitrary $\epsilon > 0$   there is embedding $f_\epsilon: M^m \rightarrow \mathbb{R}^n$ which is i) in class $C^1$ ii) isometric iii) $\epsilon$-close to $f$. I am not sure what $M^m$ is implying. Is it saying that $M$ is m-dimensional? Or is it using m-tuple copies of each point of $M$?","In Wikipedia description of Nash-Kuiper theorem, it says: Let $(M,g)$ be a Riemannian manifold and $f: M^{m} \rightarrow \mathbb{R}^n$ a short $C^{\infty}$-embedding into Euclidean space   $\mathbb{R}^n$, where $n \ge m+1$. Then for arbitrary $\epsilon > 0$   there is embedding $f_\epsilon: M^m \rightarrow \mathbb{R}^n$ which is i) in class $C^1$ ii) isometric iii) $\epsilon$-close to $f$. I am not sure what $M^m$ is implying. Is it saying that $M$ is m-dimensional? Or is it using m-tuple copies of each point of $M$?",,"['differential-geometry', 'riemannian-geometry']"
17,Formal finite sum for integration on k-chains,Formal finite sum for integration on k-chains,,"This question is related to the integration of differential forms on chains, as exposed in the document at: http://www.math.upenn.edu/~ryblair/Math%20600/papers/Lec17.pdf . The author gives the following definitions: Let U be an open subset of $\mathbb{R}^n$. A singular k-cube in U is a continuous map $c:[0,1]^k\rightarrow U$ A (singular) k-chain in U is a formal finite sum of singular k-cubes in U with integer coefficients, such as $2c^1+ 3c^2−4c^3$. Such a decomposition is used later for the integration of a differential form $\omega$, in: $\int_c \omega = \sum a_i\int_{c_i} \omega$ What is, in simple terms, the definition (or at least an intuition) of a formal finite sum of functions in this context ? Is a Free Abelian Group involved, with which group operation ?","This question is related to the integration of differential forms on chains, as exposed in the document at: http://www.math.upenn.edu/~ryblair/Math%20600/papers/Lec17.pdf . The author gives the following definitions: Let U be an open subset of $\mathbb{R}^n$. A singular k-cube in U is a continuous map $c:[0,1]^k\rightarrow U$ A (singular) k-chain in U is a formal finite sum of singular k-cubes in U with integer coefficients, such as $2c^1+ 3c^2−4c^3$. Such a decomposition is used later for the integration of a differential form $\omega$, in: $\int_c \omega = \sum a_i\int_{c_i} \omega$ What is, in simple terms, the definition (or at least an intuition) of a formal finite sum of functions in this context ? Is a Free Abelian Group involved, with which group operation ?",,"['differential-geometry', 'integration', 'differential-forms']"
18,Flat torsionfree connection in Kähler manifold,Flat torsionfree connection in Kähler manifold,,"If $\nabla$ is a flat torsionfree connection and $J$ is a complex structure, we define \begin{align} d^{\nabla}J(X,Y)=(\nabla_{X}J)Y-(\nabla_{Y}J)X. \end{align} Why flatness of $\nabla$ means $d^{\nabla}=0$, and $\nabla$ is torsionfree means $(d^{\nabla })^{2}(\mathrm{id})=0$?","If $\nabla$ is a flat torsionfree connection and $J$ is a complex structure, we define \begin{align} d^{\nabla}J(X,Y)=(\nabla_{X}J)Y-(\nabla_{Y}J)X. \end{align} Why flatness of $\nabla$ means $d^{\nabla}=0$, and $\nabla$ is torsionfree means $(d^{\nabla })^{2}(\mathrm{id})=0$?",,"['differential-geometry', 'complex-geometry', 'kahler-manifolds', 'connections']"
19,Understand the Hyperbolic space,Understand the Hyperbolic space,,"I've been trying to find the expression for the metric of the hyperbolic n-space, $\mathbb H^n$. For $n=2$ I've found (e.g. here ) that $$ds^2=\frac{dx^2+dy^2}{y^2}.$$ But for $n>2$ I can't seem to find the expression for the metric... Can anyone help me with this? Also, on a related question, If I have a scalar field that obeys to the Laplace equation in $\mathbb H^2$, I get that the solution is the same as if I've written the Lapace equation in $\mathbb R^2$...that came as a surprise for me...Why does that happen? (I'm trying to have some understanding of the Hyperbolic space.)","I've been trying to find the expression for the metric of the hyperbolic n-space, $\mathbb H^n$. For $n=2$ I've found (e.g. here ) that $$ds^2=\frac{dx^2+dy^2}{y^2}.$$ But for $n>2$ I can't seem to find the expression for the metric... Can anyone help me with this? Also, on a related question, If I have a scalar field that obeys to the Laplace equation in $\mathbb H^2$, I get that the solution is the same as if I've written the Lapace equation in $\mathbb R^2$...that came as a surprise for me...Why does that happen? (I'm trying to have some understanding of the Hyperbolic space.)",,"['differential-geometry', 'hyperbolic-geometry']"
20,Special Kähler manifolds,Special Kähler manifolds,,"These are facts from article by V. Cortes, ""Realization of special Kähler manifolds as parabolic spheres"". So, I tried to understand them by using the simplest example where $m = 2$ but unsuccessfully. Let us have complex vector space $V=T^{*}C^{m}$ with standard complex symplectic form $\Omega =\sum_{i=1}^{m}dz^{i}\wedge dw^{i}$ , and $\tau : V\to V$ is standard real structure of $V$ with set of fixed points $V^{\tau }=T^{*}R^{m}$ . Then $\gamma := \sqrt{-1}  \Omega (.,\tau .)$ defines a Hermitian form. A holomorphic immersion $\phi : M\to V$ of a complex manifold $M$ into $V$ is called non-degenerate if $\phi ^{*}\gamma$ is non-degenerate. If $\phi$ is non-degenerate then $\phi^{*}\gamma$ defines a Kähler metric $g$ on $M$ . If, additionally, $\phi$ is a Lagrangian immersion then it induces a torsion-free flat connection $\nabla$ on $M$ . How do we get metric $g$ and connection $\nabla$ on $M$ ? What does it mean that $\phi^{*}\gamma$ is non-degenerate?","These are facts from article by V. Cortes, ""Realization of special Kähler manifolds as parabolic spheres"". So, I tried to understand them by using the simplest example where but unsuccessfully. Let us have complex vector space with standard complex symplectic form , and is standard real structure of with set of fixed points . Then defines a Hermitian form. A holomorphic immersion of a complex manifold into is called non-degenerate if is non-degenerate. If is non-degenerate then defines a Kähler metric on . If, additionally, is a Lagrangian immersion then it induces a torsion-free flat connection on . How do we get metric and connection on ? What does it mean that is non-degenerate?","m = 2 V=T^{*}C^{m} \Omega =\sum_{i=1}^{m}dz^{i}\wedge dw^{i} \tau : V\to V V V^{\tau }=T^{*}R^{m} \gamma := \sqrt{-1}  \Omega (.,\tau .) \phi : M\to V M V \phi ^{*}\gamma \phi \phi^{*}\gamma g M \phi \nabla M g \nabla M \phi^{*}\gamma","['differential-geometry', 'symplectic-geometry', 'connections', 'kahler-manifolds']"
21,Differentials and second order derivative,Differentials and second order derivative,,"I have a question from my tutorials and I don't know how to start... Let $U$ be open in $\mathbb{R}^{n}$ and let $f:U\rightarrow \mathbb{R}$ a $C^{2}$ function. Let $p$ be a point in $U$ where $df_{p}$ of $f$ at $p$ does not vanish. Show that there exists a system of local coordinates $x^{i}$ defined in a neighbourhood of $p$ in which \begin{eqnarray*} \frac{\partial^{2}f}{\partial x^{i}\partial x^{j}}=0 \end{eqnarray*} for all $1\leq i,j\leq n$. Thanks!","I have a question from my tutorials and I don't know how to start... Let $U$ be open in $\mathbb{R}^{n}$ and let $f:U\rightarrow \mathbb{R}$ a $C^{2}$ function. Let $p$ be a point in $U$ where $df_{p}$ of $f$ at $p$ does not vanish. Show that there exists a system of local coordinates $x^{i}$ defined in a neighbourhood of $p$ in which \begin{eqnarray*} \frac{\partial^{2}f}{\partial x^{i}\partial x^{j}}=0 \end{eqnarray*} for all $1\leq i,j\leq n$. Thanks!",,['differential-geometry']
22,Inversion of Hopf's Umlaufsatz,Inversion of Hopf's Umlaufsatz,,"Hopf's Umlaufsatz (better known as?) says: Let $\gamma$ be a simple closed differentiable positively oriented   curve in the plane. Then for its curvature $\kappa$ it holds: $$\int_{\gamma}\kappa\ \text{d}s = 2\pi$$ I wonder if (and cannot see why not) the inversion holds, too: Let $\kappa$ be a continuous function $\kappa: [0,1] \rightarrow \mathbb{R}$ with $\kappa(0) = \kappa(1)$ and $\int_0^{1}\kappa\ \text{d}s = 2\pi$. Then there is a simple closed differentiable   positively oriented curve $\gamma$ (of length 1) with curvature $\kappa$. (If this holds, $\gamma$ would be unique upto congruency via Euclidean motions.)","Hopf's Umlaufsatz (better known as?) says: Let $\gamma$ be a simple closed differentiable positively oriented   curve in the plane. Then for its curvature $\kappa$ it holds: $$\int_{\gamma}\kappa\ \text{d}s = 2\pi$$ I wonder if (and cannot see why not) the inversion holds, too: Let $\kappa$ be a continuous function $\kappa: [0,1] \rightarrow \mathbb{R}$ with $\kappa(0) = \kappa(1)$ and $\int_0^{1}\kappa\ \text{d}s = 2\pi$. Then there is a simple closed differentiable   positively oriented curve $\gamma$ (of length 1) with curvature $\kappa$. (If this holds, $\gamma$ would be unique upto congruency via Euclidean motions.)",,['differential-geometry']
23,what are Ricci curvatures?,what are Ricci curvatures?,,"What are Ricci curvatures (in the plural)? I know the definition of the Ricci tensor ($Ric_{jk} = R_{ijki}$ where $R$ is the Riemann curvature tensor), but I've doing a problem which asks for definitions of the Ricci tensor and then the sectional and Ricci curvatures. It's not in the books by do Carmo, Lee, or Guillemin & Pollack. More exactly, the problem says: 'Define what is meant by the Ricci tensor on a Riemannian manifold M, proving that it is a rank-2 symmetric tensor. Define the sectional curvatures and the Ricci curvatures . When dim$(M)=3$, show that if the Ricci curvatures are constant at some point, then so too are the sectional curvatures. Show that there is a Riemannian metric on $S^2\times S^2$ for which the Ricci curvatures are constant but the sectional curvatures are not.' Many thanks for any help with this!","What are Ricci curvatures (in the plural)? I know the definition of the Ricci tensor ($Ric_{jk} = R_{ijki}$ where $R$ is the Riemann curvature tensor), but I've doing a problem which asks for definitions of the Ricci tensor and then the sectional and Ricci curvatures. It's not in the books by do Carmo, Lee, or Guillemin & Pollack. More exactly, the problem says: 'Define what is meant by the Ricci tensor on a Riemannian manifold M, proving that it is a rank-2 symmetric tensor. Define the sectional curvatures and the Ricci curvatures . When dim$(M)=3$, show that if the Ricci curvatures are constant at some point, then so too are the sectional curvatures. Show that there is a Riemannian metric on $S^2\times S^2$ for which the Ricci curvatures are constant but the sectional curvatures are not.' Many thanks for any help with this!",,"['differential-geometry', 'curvature']"
24,Nonexistence of a global coordinate system,Nonexistence of a global coordinate system,,"I asked this question in https://mathoverflow.net/ , but was advised to ask it here. So here it is. I just started a self-study of differential geometry and topology. And in several text I came accross the question, asking to show that the global coordinates cannot be defined on a circle $S_{1}$. It seems like quite easy question, but I cannot work the proof. I have a hunch that it has something to do with a Jacobian being zero at some points. Suppose $S_{1}= [(x,y)\in R^{2} | x^{2}+y^{2}=1] $ and there exist a global coordinate system $u=f(x,y)$, $x=g(x,y)$. The Jacobian then is as follows:  $$  J=\begin{vmatrix} \frac{\partial f}{\partial x}  & \frac{\partial f}{\partial y}  \\\  \frac{\partial g}{\partial x}  & \frac{\partial g}{\partial y}  \end{vmatrix}$$ Since $y=\pm \sqrt{1-x^{2}}$ $$\frac{\partial f}{\partial y}=0$$ $$\frac{\partial g}{\partial y}=0$$ So I have that Jacobian is equal to zero. But this also feels not quite right. I'm I missing something? Comment: the global coordinates means that the mapping is smooth bijective and has a non-zero Jacobian everywhere.","I asked this question in https://mathoverflow.net/ , but was advised to ask it here. So here it is. I just started a self-study of differential geometry and topology. And in several text I came accross the question, asking to show that the global coordinates cannot be defined on a circle $S_{1}$. It seems like quite easy question, but I cannot work the proof. I have a hunch that it has something to do with a Jacobian being zero at some points. Suppose $S_{1}= [(x,y)\in R^{2} | x^{2}+y^{2}=1] $ and there exist a global coordinate system $u=f(x,y)$, $x=g(x,y)$. The Jacobian then is as follows:  $$  J=\begin{vmatrix} \frac{\partial f}{\partial x}  & \frac{\partial f}{\partial y}  \\\  \frac{\partial g}{\partial x}  & \frac{\partial g}{\partial y}  \end{vmatrix}$$ Since $y=\pm \sqrt{1-x^{2}}$ $$\frac{\partial f}{\partial y}=0$$ $$\frac{\partial g}{\partial y}=0$$ So I have that Jacobian is equal to zero. But this also feels not quite right. I'm I missing something? Comment: the global coordinates means that the mapping is smooth bijective and has a non-zero Jacobian everywhere.",,['differential-geometry']
25,Verification of Frenet Serret,Verification of Frenet Serret,,"I'm trying to show that (1) $T'\times T'' = k^2(kB +\tau T)$ $T' = \kappa N$, from Frenet Serret $T'' = \kappa'N + N'\kappa$, but the algebra didn't follow when I tried to substitute this on the Left hand side, of (1) above","I'm trying to show that (1) $T'\times T'' = k^2(kB +\tau T)$ $T' = \kappa N$, from Frenet Serret $T'' = \kappa'N + N'\kappa$, but the algebra didn't follow when I tried to substitute this on the Left hand side, of (1) above",,['differential-geometry']
26,Parametric curve on cylinder surface,Parametric curve on cylinder surface,,"Let $r(t)=(x(t),y(t),z(t)),t\geq0$ be a parametric curve with $r(0)$ lies on cylinder surface $x^2+2y^2=C$. Let the tangent vector of $r$ is $r'(t)=\left( 2y(t)(z(t)-1), -x(t)(z(t)-1),  x(t)y(t)\right)$. Would you help me to show that : (a) The curve always lies on ylinder surface $x^2+2y^2=C$. (b) The curve $r(t)$ is periodic (we can find $T_0\neq0$ such that $r(T_0)=r(0)$).If we make the C smaller then the parametric curve $r(t)$ more closer to the origin (We can make a Neighboorhood that contain this parametric curve) My effort: (a) Let $V(x,y,z)=x^2+2y^2$. If  $V(x,y,z)=C$ then $\frac{d}{dt} V(x,y,z)=0$. Since $\frac{d}{dt} V(x,y,z)=(2x,4y,0)\cdot (x'(t),y'(t),z'(t))=2x(2y(z-1))+4y(-x(z-1))=0$, then $r(0)$ would be parpendicular with normal of cylinder surface. Hence the tangent vector must be on the tangent plane of cylinder. So $r(t)$ must lie on cylinder surface. (b) From $z'=xy$, I analyze the sign of $z'$ (in 1st quadrant z'>0 so the z component of $r(t)$ increasing and etc.) and conclude that if $r(t)$ never goes unbounded when move to another octan ( But I can't guarante $r(t)$ accros another octan.). I also consider the case when $(x=0, y>0), (x=0, y<0,z>1), (x>0, y=0,z>1$and so on)  and draw the vector $r'(t)$. Thank you so much of your help.","Let $r(t)=(x(t),y(t),z(t)),t\geq0$ be a parametric curve with $r(0)$ lies on cylinder surface $x^2+2y^2=C$. Let the tangent vector of $r$ is $r'(t)=\left( 2y(t)(z(t)-1), -x(t)(z(t)-1),  x(t)y(t)\right)$. Would you help me to show that : (a) The curve always lies on ylinder surface $x^2+2y^2=C$. (b) The curve $r(t)$ is periodic (we can find $T_0\neq0$ such that $r(T_0)=r(0)$).If we make the C smaller then the parametric curve $r(t)$ more closer to the origin (We can make a Neighboorhood that contain this parametric curve) My effort: (a) Let $V(x,y,z)=x^2+2y^2$. If  $V(x,y,z)=C$ then $\frac{d}{dt} V(x,y,z)=0$. Since $\frac{d}{dt} V(x,y,z)=(2x,4y,0)\cdot (x'(t),y'(t),z'(t))=2x(2y(z-1))+4y(-x(z-1))=0$, then $r(0)$ would be parpendicular with normal of cylinder surface. Hence the tangent vector must be on the tangent plane of cylinder. So $r(t)$ must lie on cylinder surface. (b) From $z'=xy$, I analyze the sign of $z'$ (in 1st quadrant z'>0 so the z component of $r(t)$ increasing and etc.) and conclude that if $r(t)$ never goes unbounded when move to another octan ( But I can't guarante $r(t)$ accros another octan.). I also consider the case when $(x=0, y>0), (x=0, y<0,z>1), (x>0, y=0,z>1$and so on)  and draw the vector $r'(t)$. Thank you so much of your help.",,['differential-geometry']
27,Find circle given a point on a sphere and a tangent vector,Find circle given a point on a sphere and a tangent vector,,"I need to formulate an equation for a circle that exists on a given sphere, given a point on the sphere and a directional tangent vector. I am trying to write a graphical program that has some characters moving around a sphere. I need the equation so I can update each character's position. The characters have an orientations and a starting point. I just need to move them over time around a sphere.","I need to formulate an equation for a circle that exists on a given sphere, given a point on the sphere and a directional tangent vector. I am trying to write a graphical program that has some characters moving around a sphere. I need the equation so I can update each character's position. The characters have an orientations and a starting point. I just need to move them over time around a sphere.",,"['algebraic-geometry', 'differential-geometry']"
28,Existence of orthonormal frame,Existence of orthonormal frame,,"Let $M$ be a surface with Riemannian metric $g$. Recall that an orthonormal framing of $M$ is an ordered pair of vector fields $(E_1,E_2)$ such that $g(E_i,E_j)=\delta_{ij}$. Prove that an orthonormal framing exists iff $M$ is orientable and $M$ admits a nowhere vanishing vector field $X$. Remark: It's obvious in $\mathbb{R}^3$, but how to formally justify it?  The definition for orientabily: $M$ is orientable if there exists an atlas $(u_{\alpha},M_{\alpha})_{\alpha}$ such that $\mathrm{det}(\mathrm{d}(u_{\beta}\circ u_{\alpha}^{-1}))>0$, for each $(\alpha,\beta)$ such that $M_{\alpha} \cap M_{\beta} \neq \Phi$","Let $M$ be a surface with Riemannian metric $g$. Recall that an orthonormal framing of $M$ is an ordered pair of vector fields $(E_1,E_2)$ such that $g(E_i,E_j)=\delta_{ij}$. Prove that an orthonormal framing exists iff $M$ is orientable and $M$ admits a nowhere vanishing vector field $X$. Remark: It's obvious in $\mathbb{R}^3$, but how to formally justify it?  The definition for orientabily: $M$ is orientable if there exists an atlas $(u_{\alpha},M_{\alpha})_{\alpha}$ such that $\mathrm{det}(\mathrm{d}(u_{\beta}\circ u_{\alpha}^{-1}))>0$, for each $(\alpha,\beta)$ such that $M_{\alpha} \cap M_{\beta} \neq \Phi$",,"['differential-geometry', 'differential-forms']"
29,geodesics and unit speed curves,geodesics and unit speed curves,,"Say we have 2 surfaces $M$ and $\hat M$ that intersect perpendicularly --> $\left<n,\hat n\right> = 0$ along the curve of the intersection intersection, where $n$ is the unit normal to $M$ and $\hat n$ is the unit normal to $\hat M$. Assume the intersection of $M$ and $\hat M$ is the image of a unit speed curve $\gamma$ that is a geodesic in both $M$ and $\hat M$. How can we show that $\gamma$ is a straight line? Thanks","Say we have 2 surfaces $M$ and $\hat M$ that intersect perpendicularly --> $\left<n,\hat n\right> = 0$ along the curve of the intersection intersection, where $n$ is the unit normal to $M$ and $\hat n$ is the unit normal to $\hat M$. Assume the intersection of $M$ and $\hat M$ is the image of a unit speed curve $\gamma$ that is a geodesic in both $M$ and $\hat M$. How can we show that $\gamma$ is a straight line? Thanks",,['differential-geometry']
30,Index notation and differentiation,Index notation and differentiation,,"Let $x_i$ such that $i=1,2,\ldots,n$, and $\vec{x}=(x_1,\ldots,x_n)$ Define $$A:= M_{ij}(\vec{x})\dot{x}^i\dot{x}^j$$ where Einstein summation applies. Also, $M$ is symmetric and invertible -- a metric. What then is ${\partial \over \partial \vec{x}}A$ and ${\partial \over \partial \dot{\vec{x}}}A$? I can't remember how this sort of index notation work, could someone please help? Also, if anyone has any good references on the subject, and would not mind sharing, that would be greatly appreciated.","Let $x_i$ such that $i=1,2,\ldots,n$, and $\vec{x}=(x_1,\ldots,x_n)$ Define $$A:= M_{ij}(\vec{x})\dot{x}^i\dot{x}^j$$ where Einstein summation applies. Also, $M$ is symmetric and invertible -- a metric. What then is ${\partial \over \partial \vec{x}}A$ and ${\partial \over \partial \dot{\vec{x}}}A$? I can't remember how this sort of index notation work, could someone please help? Also, if anyone has any good references on the subject, and would not mind sharing, that would be greatly appreciated.",,"['differential-geometry', 'metric-spaces']"
31,Extension of Yau's theorem to general bundles,Extension of Yau's theorem to general bundles,,Calabi-Yau manifolds have the nice property that $c_1(TM) = 0$ implies there is a Ricci flat metric: $\text{Ric}(\omega)$. Is it possible to construct a similar theorem vor a Vector Bundle over a Calabi-Yau manifold? i.e. $c_1(V) = 0$ implies that there exists some flat connection on the bundle? Or something related?,Calabi-Yau manifolds have the nice property that $c_1(TM) = 0$ implies there is a Ricci flat metric: $\text{Ric}(\omega)$. Is it possible to construct a similar theorem vor a Vector Bundle over a Calabi-Yau manifold? i.e. $c_1(V) = 0$ implies that there exists some flat connection on the bundle? Or something related?,,"['algebraic-topology', 'differential-geometry']"
32,$M_m$ is naturally isomorphic to $(F_m/F_m^2)^{*}$,is naturally isomorphic to,M_m (F_m/F_m^2)^{*},"Let us denote $M_m$ be the set of tangent vectors to a manifold $M$ at point $m$ and is called tangent space  to $M$ at point $m$ we denote $\bar{F_m}$ be the set of all germs at point $m$ and $F_m$ be the set of germs vanishes at $m$ In warner book there is a lemma: $M_m$ is naturally isomorphic to $(F_m/F_m^2)^{*}$: In proof he says if $v\in M_m$, then $v$ is a linear function  on $F_m$ vanishing on $F_m^2$ because of the derivation property ,but I do not get why is that so?Could any one explain me a explicitly why? derivation property says $v(f.g)=f(m)v(g)+g(m)v(f)$, but I do not connect this with the above line of my confusion. Thank you.","Let us denote $M_m$ be the set of tangent vectors to a manifold $M$ at point $m$ and is called tangent space  to $M$ at point $m$ we denote $\bar{F_m}$ be the set of all germs at point $m$ and $F_m$ be the set of germs vanishes at $m$ In warner book there is a lemma: $M_m$ is naturally isomorphic to $(F_m/F_m^2)^{*}$: In proof he says if $v\in M_m$, then $v$ is a linear function  on $F_m$ vanishing on $F_m^2$ because of the derivation property ,but I do not get why is that so?Could any one explain me a explicitly why? derivation property says $v(f.g)=f(m)v(g)+g(m)v(f)$, but I do not connect this with the above line of my confusion. Thank you.",,['differential-geometry']
33,Proving a curve is a geodesic.,Proving a curve is a geodesic.,,"I am really stuck on the following question. Let $ \ \gamma : I \longrightarrow M \ $ be a non-constant (i.e  $ \ \gamma'\ $  is not identically zero) geodesic. Show that a reparametrization $\ \gamma \circ h : J \longrightarrow M \ $ is a geodesic if and only if $ \ h: J \longrightarrow I \ $ is of the form $h(t) = at+b \ $ with $ \ a, b \in \mathbb{R}$. Does anyone have any idea how to prove this?","I am really stuck on the following question. Let $ \ \gamma : I \longrightarrow M \ $ be a non-constant (i.e  $ \ \gamma'\ $  is not identically zero) geodesic. Show that a reparametrization $\ \gamma \circ h : J \longrightarrow M \ $ is a geodesic if and only if $ \ h: J \longrightarrow I \ $ is of the form $h(t) = at+b \ $ with $ \ a, b \in \mathbb{R}$. Does anyone have any idea how to prove this?",,"['differential-geometry', 'riemannian-geometry']"
34,How to calculate scalar curvature in a local chart,How to calculate scalar curvature in a local chart,,I want to find a complete manifold with infinite diameter which has uniformly positive scalar curvature. And I want to show that $M^n = S^2(r) \times \mathbb{R}^{n-2}$ with $n \geq 3$ is an example which satisfying the properties above. How do I calculate the scalar curvature of $M$ in a local chart? How do I begin the calculations? Could everyone give me some hints or reference? Thank you very much!,I want to find a complete manifold with infinite diameter which has uniformly positive scalar curvature. And I want to show that $M^n = S^2(r) \times \mathbb{R}^{n-2}$ with $n \geq 3$ is an example which satisfying the properties above. How do I calculate the scalar curvature of $M$ in a local chart? How do I begin the calculations? Could everyone give me some hints or reference? Thank you very much!,,"['differential-geometry', 'riemannian-geometry']"
35,Covariant Derivatives and the Cross Product,Covariant Derivatives and the Cross Product,,"I've recently read a paper that used a covariant derivative product rule for cross products. It was something like $\nabla_v (A \times B) = (\nabla_v A) \times B + A \times (\nabla_v B)$.  Here, $A, B$ are vector fields on a regular surface $S$, and $\nabla$ is the Levi-Civita connection. From my limited knowledge of covariant derivatives, this seems implausible.  For instance, I believed that the output of the covariant derivative always lies in the tangent plane, which seems to contradict the above rule.  For example, assume $A$ and $B$ are tangent vectors, then $\nabla_v A, B$ are tangent vectors, so $\nabla_v A \times B \notin T_p(S)$. I'd like to read up on this, but none of my standard books on differential geometry cover the cross product. I understand that the cross product is a (1, 2) tensor, so it should follow the product rule associated with tensors, but I'm not sure if that results in the product rule above.  Could any differential geometers please give me a reference? Thanks!","I've recently read a paper that used a covariant derivative product rule for cross products. It was something like $\nabla_v (A \times B) = (\nabla_v A) \times B + A \times (\nabla_v B)$.  Here, $A, B$ are vector fields on a regular surface $S$, and $\nabla$ is the Levi-Civita connection. From my limited knowledge of covariant derivatives, this seems implausible.  For instance, I believed that the output of the covariant derivative always lies in the tangent plane, which seems to contradict the above rule.  For example, assume $A$ and $B$ are tangent vectors, then $\nabla_v A, B$ are tangent vectors, so $\nabla_v A \times B \notin T_p(S)$. I'd like to read up on this, but none of my standard books on differential geometry cover the cross product. I understand that the cross product is a (1, 2) tensor, so it should follow the product rule associated with tensors, but I'm not sure if that results in the product rule above.  Could any differential geometers please give me a reference? Thanks!",,"['differential-geometry', 'physics']"
36,Reversing a roulette on a straight line - solving for a parameterization?,Reversing a roulette on a straight line - solving for a parameterization?,,"(See below for update.) I would like to reverse the following equations.  Here, the path is traced out by the polar origin of the wheel.  You can put the trace point anywhere on or off of the wheel by translating the wheel relative to the polar origin.  To generate a cycloid, $r(t)$ would be a circle which passes through the origin. Equations of any roulette generated by a wheel given by $r(t)$ rolling on a straight line: $$x(t) = \int \sqrt{r(t)^2 + r'(t)^2} dt - \frac{r(t) r'(t)}{\sqrt{r(t)^2 + r'(t)^2}}$$ $$y(t) = \frac{r(t)^2}{\sqrt{r(t)^2 + r'(t)^2}}$$ Given such a roulette in $x(t)$ and $y(t)$, how can I determine the original wheel?  This is all motivated by a specific example, but I would like to understand the general case. I worked out the above equations by geometric inspection, more or less.  At time $t$, the wheel is touching the road at a point on the road ($y = 0$) and the distance is the arc length around the wheel from the initial angle to $t$ ($x = \int \sqrt{r(t)^2 + r'(t)^2} dt$).  Add to that the offset from the tangent point on the wheel to the origin of the wheel.  The origin is a distance $r(t)$ from the tangent point at an angle given by the fact that the wheel is also tangent to the road at all times, so doing a bit of trigonometric substitution gives the rest. Nothing similar is coming to me to work out the reverse equations. I also tried to work it out by treating the wheel as the limit of a class of polygons with an increasing number of sides where the vertices lie on the wheel.  I got as far as: $\Delta x = (L - x)(1 + \cos(a)) + y \sin(a)$ $\Delta y = -y(1 + \cos(a)) + (L - x) \sin(a)$ Where $L$ is the current arc length traveled so far, $x$ and $y$ are the current trace position and $a$ is the next angle that the polygon approximation of the wheel will pivot on.  I'm unable to come up with the angle given simply $t$ and a change in t, since I need three sample points from the wheel to determine the next angle, unless I assume that $\Delta t$ will be constant so the previous $t$ was $t - \Delta t$.  I am afraid that might cause problems when I try to reverse it, given who knows what parameterization.  It won't be linear with respect to $t$. So, where should I go from here? EDIT: New idea.  $\dfrac{dy}{dx}(t) = \dfrac{r'(t)}{r(t)}$. Therefore: $y(t) = \dfrac{r(t)^2}{\sqrt{r(t)^2 + r'(t)^2}} = \dfrac{r(t)}{\sqrt{1 + \frac{r'(t)^2}{r(t)^2}}} = \dfrac{r(t)}{\sqrt{1 + \left(\frac{dy}{dx}(t)\right)^2}}$ $r(t) = y(t) \sqrt{1 + \left(\frac{dy}{dx}(t)\right)^2}$ So given $y(\theta)$ and $x(\theta)$, $r(t) = y(\theta) \sqrt{1 + \left(\frac{dy}{dx}\right)^2}$ Is there any way to find $t$ in terms of $\theta$, the relation between the rate at which the wheel turns and the parameterization of the given $x$ and $y$? Also, $x(t) + \frac{dy}{dx} y(t) = \int \sqrt{r(t)^2 + r'(t)^2}$ and $\sqrt{r(t)^2 + r'(t)^2}$ = $y(t) \left(1 + \left(\frac{dy}{dx}\right)^2\right)$.","(See below for update.) I would like to reverse the following equations.  Here, the path is traced out by the polar origin of the wheel.  You can put the trace point anywhere on or off of the wheel by translating the wheel relative to the polar origin.  To generate a cycloid, $r(t)$ would be a circle which passes through the origin. Equations of any roulette generated by a wheel given by $r(t)$ rolling on a straight line: $$x(t) = \int \sqrt{r(t)^2 + r'(t)^2} dt - \frac{r(t) r'(t)}{\sqrt{r(t)^2 + r'(t)^2}}$$ $$y(t) = \frac{r(t)^2}{\sqrt{r(t)^2 + r'(t)^2}}$$ Given such a roulette in $x(t)$ and $y(t)$, how can I determine the original wheel?  This is all motivated by a specific example, but I would like to understand the general case. I worked out the above equations by geometric inspection, more or less.  At time $t$, the wheel is touching the road at a point on the road ($y = 0$) and the distance is the arc length around the wheel from the initial angle to $t$ ($x = \int \sqrt{r(t)^2 + r'(t)^2} dt$).  Add to that the offset from the tangent point on the wheel to the origin of the wheel.  The origin is a distance $r(t)$ from the tangent point at an angle given by the fact that the wheel is also tangent to the road at all times, so doing a bit of trigonometric substitution gives the rest. Nothing similar is coming to me to work out the reverse equations. I also tried to work it out by treating the wheel as the limit of a class of polygons with an increasing number of sides where the vertices lie on the wheel.  I got as far as: $\Delta x = (L - x)(1 + \cos(a)) + y \sin(a)$ $\Delta y = -y(1 + \cos(a)) + (L - x) \sin(a)$ Where $L$ is the current arc length traveled so far, $x$ and $y$ are the current trace position and $a$ is the next angle that the polygon approximation of the wheel will pivot on.  I'm unable to come up with the angle given simply $t$ and a change in t, since I need three sample points from the wheel to determine the next angle, unless I assume that $\Delta t$ will be constant so the previous $t$ was $t - \Delta t$.  I am afraid that might cause problems when I try to reverse it, given who knows what parameterization.  It won't be linear with respect to $t$. So, where should I go from here? EDIT: New idea.  $\dfrac{dy}{dx}(t) = \dfrac{r'(t)}{r(t)}$. Therefore: $y(t) = \dfrac{r(t)^2}{\sqrt{r(t)^2 + r'(t)^2}} = \dfrac{r(t)}{\sqrt{1 + \frac{r'(t)^2}{r(t)^2}}} = \dfrac{r(t)}{\sqrt{1 + \left(\frac{dy}{dx}(t)\right)^2}}$ $r(t) = y(t) \sqrt{1 + \left(\frac{dy}{dx}(t)\right)^2}$ So given $y(\theta)$ and $x(\theta)$, $r(t) = y(\theta) \sqrt{1 + \left(\frac{dy}{dx}\right)^2}$ Is there any way to find $t$ in terms of $\theta$, the relation between the rate at which the wheel turns and the parameterization of the given $x$ and $y$? Also, $x(t) + \frac{dy}{dx} y(t) = \int \sqrt{r(t)^2 + r'(t)^2}$ and $\sqrt{r(t)^2 + r'(t)^2}$ = $y(t) \left(1 + \left(\frac{dy}{dx}\right)^2\right)$.",,"['differential-geometry', 'plane-curves']"
37,antipodal map of complex projective space,antipodal map of complex projective space,,Let $CP(n)$ be the complex projective space with Fubini-Study metric with diameter $=\frac{\pi}{2}$. Fix a point say $p\in CP(n)$; my question is what is the set of points of maximum distance to the point $p$? (The hint given in the class is $CP(n-1)$.) I can't figure out why. Could anyone help me please? Or give any reference with a detailed study of this kind of properties?,Let $CP(n)$ be the complex projective space with Fubini-Study metric with diameter $=\frac{\pi}{2}$. Fix a point say $p\in CP(n)$; my question is what is the set of points of maximum distance to the point $p$? (The hint given in the class is $CP(n-1)$.) I can't figure out why. Could anyone help me please? Or give any reference with a detailed study of this kind of properties?,,"['differential-geometry', 'riemannian-geometry']"
38,Length of loxodrome,Length of loxodrome,,"On a sphere with radius $R$, find the length of a loxodrome which starts at the equator and makes an angle $\gamma$ with all the meridians. (No equations for such a loxodrome are given, and should be derived.)","On a sphere with radius $R$, find the length of a loxodrome which starts at the equator and makes an angle $\gamma$ with all the meridians. (No equations for such a loxodrome are given, and should be derived.)",,['differential-geometry']
39,Riemannian metric induced by immersion,Riemannian metric induced by immersion,,"Let $F:S^{2}\rightarrow\mathbb{R}^{4}$ be the immersion defined as $(x^{2}-y^{2},xy,xz,yz)$ and consider the metric on $S^{2}$ induced by $F$. Find $g_{ij}(0,0)$ for the upper hemisphere parameterization $\phi(x,y)=(x,y,\sqrt{1-x^{2}-y^{2}})$ For the metric on $S^{2}$ induced by $F$, we can explicity determine $g_{ij}$ (this is just finding $(DF)^{T}(DF)$): $$ g_{ij}=\left(\begin{array}{cccc} 4x^{2}+4y^{2} & 0 & 2xz & 0\\ 0 & y^{2}+z^{2} & yz & xz\\ 2xz & yz & x^{2}+z^{2} & xy\\ -2yz & xz & xy & z^{2}+y^{2}\end{array}\right)$$ I am wondering for the parameterization $\phi$, would I just substitute $z$ by $\sqrt{1-x^{2}-y^{2}}$ and calculuate $g_{ij}(0,0)$?","Let $F:S^{2}\rightarrow\mathbb{R}^{4}$ be the immersion defined as $(x^{2}-y^{2},xy,xz,yz)$ and consider the metric on $S^{2}$ induced by $F$. Find $g_{ij}(0,0)$ for the upper hemisphere parameterization $\phi(x,y)=(x,y,\sqrt{1-x^{2}-y^{2}})$ For the metric on $S^{2}$ induced by $F$, we can explicity determine $g_{ij}$ (this is just finding $(DF)^{T}(DF)$): $$ g_{ij}=\left(\begin{array}{cccc} 4x^{2}+4y^{2} & 0 & 2xz & 0\\ 0 & y^{2}+z^{2} & yz & xz\\ 2xz & yz & x^{2}+z^{2} & xy\\ -2yz & xz & xy & z^{2}+y^{2}\end{array}\right)$$ I am wondering for the parameterization $\phi$, would I just substitute $z$ by $\sqrt{1-x^{2}-y^{2}}$ and calculuate $g_{ij}(0,0)$?",,"['differential-geometry', 'riemannian-geometry']"
40,Partial derivative notation: is that a projection function?,Partial derivative notation: is that a projection function?,,"Consider the following definition: Let $(U,\phi)$ be a chart and $f$ a $C^\infty$ function on a manifold $M$ of dimension $n$. As a function into $\mathbb{R}^n$, $\phi$ has $n$ components $x^1,\dots x^n$. This means if $r^1,\dots r^n$ are the standard coordinates on $\mathbb{R}^n$, then $x^i = r^i \circ \phi$. For $p \in U$, we define the partial derivative $\partial f / \partial x^i$ at $p$ to be $$  \frac{\partial}{\partial x^i}\bigg|_p f \quad \buildrel {\mathrm{def}}\over{=}   \frac{\partial f}{\partial x^i}(p) = \frac{\partial(f \circ \phi^{-1})}{\partial r^i} (\phi(p)) . $$ What does $r^i$ stand for? Is it the projection function $\mathrm{pr}_i$ ?","Consider the following definition: Let $(U,\phi)$ be a chart and $f$ a $C^\infty$ function on a manifold $M$ of dimension $n$. As a function into $\mathbb{R}^n$, $\phi$ has $n$ components $x^1,\dots x^n$. This means if $r^1,\dots r^n$ are the standard coordinates on $\mathbb{R}^n$, then $x^i = r^i \circ \phi$. For $p \in U$, we define the partial derivative $\partial f / \partial x^i$ at $p$ to be $$  \frac{\partial}{\partial x^i}\bigg|_p f \quad \buildrel {\mathrm{def}}\over{=}   \frac{\partial f}{\partial x^i}(p) = \frac{\partial(f \circ \phi^{-1})}{\partial r^i} (\phi(p)) . $$ What does $r^i$ stand for? Is it the projection function $\mathrm{pr}_i$ ?",,['differential-geometry']
41,Relation between a Lie group and Lie algebra representation for $W \otimes V$,Relation between a Lie group and Lie algebra representation for,W \otimes V,"We can define a representation of a Lie group and get the induced representation of the Lie algebra. Let $G$ act on $V$ and $W$, $\mathfrak{g}$ be the Lie algebra associated to $G$ and $X \in \mathfrak{g}$. Then the action on $V$ is defined as $\displaystyle X(v)=\left.\frac{d}{dt}\right|_{t=0}\gamma_t(v)$ where $\gamma_t$ is a path in $G$ with $\gamma'_0 = X$. Then: $$ \begin{align*} X(v \otimes w) & = \left.\frac{d}{dt}\right|_{t=0}\gamma_t(v)\otimes \gamma_t(w) \\ & \stackrel{?}{=}\left(\left.\frac{d}{dt}\right|_{t=0}\gamma_t(v)\right)\otimes w + v\otimes \left(\left.\frac{d}{dt}\right|_{t=0}\gamma_t(v)\right) \\ & = X(v)\otimes w + v \otimes x(w)\end{align*}$$ My question is: why does it split?","We can define a representation of a Lie group and get the induced representation of the Lie algebra. Let $G$ act on $V$ and $W$, $\mathfrak{g}$ be the Lie algebra associated to $G$ and $X \in \mathfrak{g}$. Then the action on $V$ is defined as $\displaystyle X(v)=\left.\frac{d}{dt}\right|_{t=0}\gamma_t(v)$ where $\gamma_t$ is a path in $G$ with $\gamma'_0 = X$. Then: $$ \begin{align*} X(v \otimes w) & = \left.\frac{d}{dt}\right|_{t=0}\gamma_t(v)\otimes \gamma_t(w) \\ & \stackrel{?}{=}\left(\left.\frac{d}{dt}\right|_{t=0}\gamma_t(v)\right)\otimes w + v\otimes \left(\left.\frac{d}{dt}\right|_{t=0}\gamma_t(v)\right) \\ & = X(v)\otimes w + v \otimes x(w)\end{align*}$$ My question is: why does it split?",,"['differential-geometry', 'representation-theory', 'lie-groups', 'lie-algebras']"
42,Bounding projective spaces,Bounding projective spaces,,"For which $n$ does there exist a (topological, smooth, PL, complex) manifold $M^n$ such that $\partial M = \mathbb{R}\mathbb{P}^m$. Obvously, $m = n -1 $ (at least an in the real case). There are a couple of questions: Does there always exist a bounding projective space. And if not, what are the demands on your $M^n$ to have a bounding projective space (that is, apart from the obvious ones) ? When does non-orientability of the bounding projective space implies non-orientability of the $M^n$ (Obviously, when $\partial M^{2n+1}=\mathbb{R} \mathbb{P}^{2n}$, then the boundary is non-orientable) ? When does a complex projective space $\mathbb{C}\mathbb{P}^n$ bounds ? And is there any ""aftereffect"" (i.e. are there some specific properties that such a (probably smooth) $2n-1$-manifold has because of the complex structure of the bounding $\mathbb{C}\mathbb{P}^n$) visible in the manifold that it bounds because of the complex structure of $\mathbb{C}\mathbb{P}^n$ ? Does the fake complex projective plane bounds anything ? I know this is a multitude of questions spanning probably a multitude of disciplines.","For which $n$ does there exist a (topological, smooth, PL, complex) manifold $M^n$ such that $\partial M = \mathbb{R}\mathbb{P}^m$. Obvously, $m = n -1 $ (at least an in the real case). There are a couple of questions: Does there always exist a bounding projective space. And if not, what are the demands on your $M^n$ to have a bounding projective space (that is, apart from the obvious ones) ? When does non-orientability of the bounding projective space implies non-orientability of the $M^n$ (Obviously, when $\partial M^{2n+1}=\mathbb{R} \mathbb{P}^{2n}$, then the boundary is non-orientable) ? When does a complex projective space $\mathbb{C}\mathbb{P}^n$ bounds ? And is there any ""aftereffect"" (i.e. are there some specific properties that such a (probably smooth) $2n-1$-manifold has because of the complex structure of the bounding $\mathbb{C}\mathbb{P}^n$) visible in the manifold that it bounds because of the complex structure of $\mathbb{C}\mathbb{P}^n$ ? Does the fake complex projective plane bounds anything ? I know this is a multitude of questions spanning probably a multitude of disciplines.",,"['algebraic-topology', 'differential-geometry', 'projective-space', 'big-picture', 'cobordism']"
43,Why does my tangent vector not lie in the tangent space?,Why does my tangent vector not lie in the tangent space?,,"Me again , still learning my lesson of ""don't drink and derive"": I have got two parametrizations of the surface $H :=\{ (x,y,z) \in \mathbb{R}^3 \, | \, z^2 = 1+x^2+y^2, \, z > 0\}$, $$F:\mathbb{R}^2 \rightarrow H, \  (x,y) \mapsto (x,y,\sqrt{1+x^2+y^2})$$ $$G:D^2 \rightarrow H, \ (x,y) \mapsto (\frac{x}{\sqrt{1-x^2-y^2}}, \frac{y}{\sqrt{1-x^2-y^2}}, \frac{1}{\sqrt{1-x^2-y^2}})$$ where $D^2$ denotes the open unit disk in $\mathbb{R}^2$. I take the first to give me a base of the tangent space at a point $F(x,y)$: $$\frac{\partial F}{\partial x}(x,y)=(1,0,\frac{x}{\sqrt{1+x^2+y^2}}), \ \ \frac{\partial F}{\partial y}(x,y)=(0,1,\frac{y}{\sqrt{1+x^2+y^2}})$$ Now I triple checked the fact that $G$ really goes to $H$ and that $$\frac{\partial G}{\partial x}(x,y) = (\frac{1-y^2}{\sqrt{1-x^2-y^2}^3}, \frac{xy}{\sqrt{1-x^2-y^2}^3}, \frac{x}{\sqrt{1-x^2-y^2}^3})$$ I even got the latter confirmed from a book. But then $\frac{\partial G}{\partial x}(x,y)$ should lie in the tangent space, hence be expressible as linear combination of the above basis vectors. Due to the $1$s and $0$s in our basis vectors the coefficients are easy to read off, we must have $$ \frac{\partial G}{\partial x}(x,y) = \frac{1-y^2}{\sqrt{1-x^2-y^2}^3}\frac{\partial F}{\partial x}(x,y) + \frac{xy}{\sqrt{1-x^2-y^2}^3}\frac{\partial F}{\partial y}(x,y)$$ But then the third coordinate doesn't match: $$\frac{x}{\sqrt{1-x^2-y^2}^3} \neq \frac{1-y^2}{\sqrt{1-x^2-y^2}^3} \cdot \frac{x}{\sqrt{1+x^2+y^2}} + \frac{xy}{\sqrt{1-x^2-y^2}^3} \cdot \frac{y}{\sqrt{1+x^2+y^2}}$$ The difference is exactly the factor of $\frac{1}{\sqrt{1+x^2+y^2}}$ which I can't get rid of. Where is my mistake (apart from drinking too much yesterday)? Thank you!","Me again , still learning my lesson of ""don't drink and derive"": I have got two parametrizations of the surface $H :=\{ (x,y,z) \in \mathbb{R}^3 \, | \, z^2 = 1+x^2+y^2, \, z > 0\}$, $$F:\mathbb{R}^2 \rightarrow H, \  (x,y) \mapsto (x,y,\sqrt{1+x^2+y^2})$$ $$G:D^2 \rightarrow H, \ (x,y) \mapsto (\frac{x}{\sqrt{1-x^2-y^2}}, \frac{y}{\sqrt{1-x^2-y^2}}, \frac{1}{\sqrt{1-x^2-y^2}})$$ where $D^2$ denotes the open unit disk in $\mathbb{R}^2$. I take the first to give me a base of the tangent space at a point $F(x,y)$: $$\frac{\partial F}{\partial x}(x,y)=(1,0,\frac{x}{\sqrt{1+x^2+y^2}}), \ \ \frac{\partial F}{\partial y}(x,y)=(0,1,\frac{y}{\sqrt{1+x^2+y^2}})$$ Now I triple checked the fact that $G$ really goes to $H$ and that $$\frac{\partial G}{\partial x}(x,y) = (\frac{1-y^2}{\sqrt{1-x^2-y^2}^3}, \frac{xy}{\sqrt{1-x^2-y^2}^3}, \frac{x}{\sqrt{1-x^2-y^2}^3})$$ I even got the latter confirmed from a book. But then $\frac{\partial G}{\partial x}(x,y)$ should lie in the tangent space, hence be expressible as linear combination of the above basis vectors. Due to the $1$s and $0$s in our basis vectors the coefficients are easy to read off, we must have $$ \frac{\partial G}{\partial x}(x,y) = \frac{1-y^2}{\sqrt{1-x^2-y^2}^3}\frac{\partial F}{\partial x}(x,y) + \frac{xy}{\sqrt{1-x^2-y^2}^3}\frac{\partial F}{\partial y}(x,y)$$ But then the third coordinate doesn't match: $$\frac{x}{\sqrt{1-x^2-y^2}^3} \neq \frac{1-y^2}{\sqrt{1-x^2-y^2}^3} \cdot \frac{x}{\sqrt{1+x^2+y^2}} + \frac{xy}{\sqrt{1-x^2-y^2}^3} \cdot \frac{y}{\sqrt{1+x^2+y^2}}$$ The difference is exactly the factor of $\frac{1}{\sqrt{1+x^2+y^2}}$ which I can't get rid of. Where is my mistake (apart from drinking too much yesterday)? Thank you!",,['differential-geometry']
44,Metric connection,Metric connection,,"How to prove that any vector bundle with a fiber metric g admits a metric connection? It seems I should use partition of unity, but I have no idea how to proceed. Also it seems there are two definitions of connection on a vector bundle E, one is that  $\nabla: \Gamma(TM) \times \Gamma(E) \to \Gamma$(E), and the other one is that $\nabla: \Gamma(E) \to \Gamma(E) \otimes\Gamma(T^\ast M)$, and they should be equivalent. But I don't see how to use this to show the following equations are equivalent: If there is a fiber metric g on vector bundle E, then $d(g(u,v))=g(\nabla u,v)+g(u,\nabla v)$ for all $u,v\in\Gamma(E)$ is equivalent to $X(g(u,v))=g(\nabla_X u,v)+g(u,\nabla_X v)$ for all $X\in TM$, is it because that $d(g(u,v))(X)=X(g(u,v))$?  I am just not sure about how vector fields act on metrics.","How to prove that any vector bundle with a fiber metric g admits a metric connection? It seems I should use partition of unity, but I have no idea how to proceed. Also it seems there are two definitions of connection on a vector bundle E, one is that  $\nabla: \Gamma(TM) \times \Gamma(E) \to \Gamma$(E), and the other one is that $\nabla: \Gamma(E) \to \Gamma(E) \otimes\Gamma(T^\ast M)$, and they should be equivalent. But I don't see how to use this to show the following equations are equivalent: If there is a fiber metric g on vector bundle E, then $d(g(u,v))=g(\nabla u,v)+g(u,\nabla v)$ for all $u,v\in\Gamma(E)$ is equivalent to $X(g(u,v))=g(\nabla_X u,v)+g(u,\nabla_X v)$ for all $X\in TM$, is it because that $d(g(u,v))(X)=X(g(u,v))$?  I am just not sure about how vector fields act on metrics.",,[]
45,Tolman-Bondi-Lemaitre space times,Tolman-Bondi-Lemaitre space times,,"One can see this reference for TBL space-times. I would like to know how the explicit expression for the function called $G$ in equations $3.108,3.108,3.110$ in the above reference is obtained. Also it would be nice to see some further references about TBL space-times.","One can see this reference for TBL space-times. I would like to know how the explicit expression for the function called $G$ in equations $3.108,3.108,3.110$ in the above reference is obtained. Also it would be nice to see some further references about TBL space-times.",,['differential-geometry']
46,Local equation for the manifold from its principal curvatures,Local equation for the manifold from its principal curvatures,,"If $k_1,k_2,...,k_n$ are principal curvatures of a hypersurface in $\mathbb{R}^{n+1}$ then one can apparently locally parametrize the manifold as $(x_1,x_2,...,x_n,y)$ such that, $y = \frac{1}{2}(k_1 x_1^2 +...+k_n x_n^2) + O(\vert x \vert ^3) $ I would like to know how this is proven. I guess the coordinates are obtained by ""integrating"" the eigen-vectors of the shape operator whose eigen-values are the principal curvatures anyway. I suppose one has to be able to find out curves passing through a point which have as velocity at that point the principal directions. But I have no experience of doing such a calculation on arbitrary manifolds and hence I can't see how to do this. Further I would like to understand how for dimension 2 the principal curvatures (as defined above) become the minimum and the maximum of geodesic curvatures and also minimum and maximum of curvatures of curves obtained by intersecting the manifold with planes orthogonal to the tangent space. (in elementary surface theory the principal curvatures get defined as the maximum and the minimum of the above quantities)","If $k_1,k_2,...,k_n$ are principal curvatures of a hypersurface in $\mathbb{R}^{n+1}$ then one can apparently locally parametrize the manifold as $(x_1,x_2,...,x_n,y)$ such that, $y = \frac{1}{2}(k_1 x_1^2 +...+k_n x_n^2) + O(\vert x \vert ^3) $ I would like to know how this is proven. I guess the coordinates are obtained by ""integrating"" the eigen-vectors of the shape operator whose eigen-values are the principal curvatures anyway. I suppose one has to be able to find out curves passing through a point which have as velocity at that point the principal directions. But I have no experience of doing such a calculation on arbitrary manifolds and hence I can't see how to do this. Further I would like to understand how for dimension 2 the principal curvatures (as defined above) become the minimum and the maximum of geodesic curvatures and also minimum and maximum of curvatures of curves obtained by intersecting the manifold with planes orthogonal to the tangent space. (in elementary surface theory the principal curvatures get defined as the maximum and the minimum of the above quantities)",,['differential-geometry']
47,"Ricci tensor of an arbitary Riemannian bundle $(E,g')$",Ricci tensor of an arbitary Riemannian bundle,"(E,g')","Consider a Riemannian manifold $(M,g)$ . One can then equip $TM$ with the Levi-Civita connection and talk about the curvature tensor $R \in \Gamma(\Lambda^2 T^*M \otimes \text{End}(TM))$ . The Ricci tensor will be the $(0,2)$ -tensor obtained by contracting $R$ with $g$ . What about if we have some arbitary bundle with a another Riemannian metric $(E,g')$ over $M$ equipped with a connection $\nabla$ . This gives us a way to talk about curvature $R_\nabla$ and hence we could in theory obtain something similar to the Ricci tensor, by contracting $R_\nabla$ with $g'$ right? Is this still called the Ricci tensor even when we don't consider the tangent bundle or what is this?","Consider a Riemannian manifold . One can then equip with the Levi-Civita connection and talk about the curvature tensor . The Ricci tensor will be the -tensor obtained by contracting with . What about if we have some arbitary bundle with a another Riemannian metric over equipped with a connection . This gives us a way to talk about curvature and hence we could in theory obtain something similar to the Ricci tensor, by contracting with right? Is this still called the Ricci tensor even when we don't consider the tangent bundle or what is this?","(M,g) TM R \in \Gamma(\Lambda^2 T^*M \otimes \text{End}(TM)) (0,2) R g (E,g') M \nabla R_\nabla R_\nabla g'","['differential-geometry', 'riemannian-geometry']"
48,Generic intersection of hyperplanes,Generic intersection of hyperplanes,,"Let $V$ be a finite dimensional real vector space and $V_1,\cdots,V_n$ be subspaces of $V$ . My main question is Prove that $$f:\bigoplus_{i=1}^n V_i\to V^n/\Delta$$ is surjective, where the map is induced by inclusions $V_i\to V$ and $\Delta$ is the diagonal $\Delta= \{ (v,\cdots,v),v\in V \} \in V^n$ , if and only if $V$ have a direct sum decomposition $V=L\oplus L_1\oplus\cdots\oplus L_n$ (the summands are allowed to be $0$ ) so that $$V_i=L\oplus L_1\oplus\cdots L_{i-1}\oplus L_{i+1}\oplus\cdots L_n$$ Some Backgrounds: When $f$ is surjective, we also say $\{V_i\}$ intersect generically, since this condition is equivalent to "" given arbitrary vectors $a_i\in V$ , we can find $v_i\in V_i$ and $v\in V$ , so that $$v_i+a_i=v$$ This means if we move the planes $\{V_i\}$ a little $a_i$ , they still intersect at some point $v$ . More backgrounds(Not needed to solving this linear algebra problem): manifold version In many interesting cases in differential geometry, we need to compactify configuration spaces, and they are done by blowing up submanifolds successively. It turns out that if these submanifolds intersect generically, then the order you perform to blow up these submanifolds doesn't effect the result of compactification ( Dylan Thurston's thesis ). This question is local linearized version.","Let be a finite dimensional real vector space and be subspaces of . My main question is Prove that is surjective, where the map is induced by inclusions and is the diagonal , if and only if have a direct sum decomposition (the summands are allowed to be ) so that Some Backgrounds: When is surjective, we also say intersect generically, since this condition is equivalent to "" given arbitrary vectors , we can find and , so that This means if we move the planes a little , they still intersect at some point . More backgrounds(Not needed to solving this linear algebra problem): manifold version In many interesting cases in differential geometry, we need to compactify configuration spaces, and they are done by blowing up submanifolds successively. It turns out that if these submanifolds intersect generically, then the order you perform to blow up these submanifolds doesn't effect the result of compactification ( Dylan Thurston's thesis ). This question is local linearized version.","V V_1,\cdots,V_n V f:\bigoplus_{i=1}^n V_i\to V^n/\Delta V_i\to V \Delta \Delta= \{ (v,\cdots,v),v\in V \} \in V^n V V=L\oplus L_1\oplus\cdots\oplus L_n 0 V_i=L\oplus L_1\oplus\cdots L_{i-1}\oplus L_{i+1}\oplus\cdots L_n f \{V_i\} a_i\in V v_i\in V_i v\in V v_i+a_i=v \{V_i\} a_i v","['linear-algebra', 'abstract-algebra', 'differential-geometry']"
49,Existence of smooth functions decaying fast near the boundary,Existence of smooth functions decaying fast near the boundary,,"This question concerns the following claim: Let $M$ be a manifold and $U\subset M$ be open. For every smooth function $f:U\to\mathbb{R}$ , there exists a smooth function $g:M\to[0,1]$ such that $g$ is strictly positive on $U$ , vanishes outisde $U$ , and the function $$ fg(x)=\begin{cases} f(x)g(x)&~x\in U, \\ 0&~x\notin U, \end{cases} $$ is smooth on $M$ . This cannot be solved directly using bump functions, since we are not assuming that $\operatorname{supp}g\subset U$ . I have been thinking about this for a while. An idea is to take a compact exhaustion of $U$ , take a sequence of bump functions $h_i$ on those compact sets, choose bounds on the derivatives of $h_i$ and $h_if$ , and finally consider a power series of the form similar to $\sum_i2^{-i}\frac{1}{1+C_i+D_i}$ , where $C_i,D_i$ are the bounds. This idea comes from the bottom of page 28 on the book $C^\infty$ -Differentiable Spaces by Juan A. Navarro González. However, I don't know how to prove this rigorously. The proof given in the book is unclear because it does not specify computing the derivative in which coordinate charts, and it does not provide full details. Any help would be greatly appreciated. If you have a different proof, please feel free to include it!","This question concerns the following claim: Let be a manifold and be open. For every smooth function , there exists a smooth function such that is strictly positive on , vanishes outisde , and the function is smooth on . This cannot be solved directly using bump functions, since we are not assuming that . I have been thinking about this for a while. An idea is to take a compact exhaustion of , take a sequence of bump functions on those compact sets, choose bounds on the derivatives of and , and finally consider a power series of the form similar to , where are the bounds. This idea comes from the bottom of page 28 on the book -Differentiable Spaces by Juan A. Navarro González. However, I don't know how to prove this rigorously. The proof given in the book is unclear because it does not specify computing the derivative in which coordinate charts, and it does not provide full details. Any help would be greatly appreciated. If you have a different proof, please feel free to include it!","M U\subset M f:U\to\mathbb{R} g:M\to[0,1] g U U 
fg(x)=\begin{cases}
f(x)g(x)&~x\in U,
\\
0&~x\notin U,
\end{cases}
 M \operatorname{supp}g\subset U U h_i h_i h_if \sum_i2^{-i}\frac{1}{1+C_i+D_i} C_i,D_i C^\infty","['differential-geometry', 'smooth-manifolds']"
50,"Let G be a topological group that is T2,N2 and locally Euclidean and suppose G admits an open lie subgroup H. Prove that G is Lie","Let G be a topological group that is T2,N2 and locally Euclidean and suppose G admits an open lie subgroup H. Prove that G is Lie",,"I found this exercise in Tao’s book “Note on Hilbert fifth problem” . Note that if $G$ is connected then $H=G$ since $H$ is also closed and $H\neq\emptyset$ since the neutral element lies in $H$ . But if $G$ is not connected I’m a little bit stuck. Tao suggest to take a coordinate chart $(U,\phi:U \to V)$ from the atlas on $H$ and translate it around to create an atlas on $G$ which makes $G$ a Lie group so i was trying to take the atlas $\{(gU,\psi_{g})\}_{g\in G}$ where $\psi_{g}:gU\to V , gu \mapsto \phi(u)$ for all $u$ in $U$ . Unfortunately i don’t know how to prove the compatibility of the charts. Sorry for the bad English I’m from Italy :)",I found this exercise in Tao’s book “Note on Hilbert fifth problem” . Note that if is connected then since is also closed and since the neutral element lies in . But if is not connected I’m a little bit stuck. Tao suggest to take a coordinate chart from the atlas on and translate it around to create an atlas on which makes a Lie group so i was trying to take the atlas where for all in . Unfortunately i don’t know how to prove the compatibility of the charts. Sorry for the bad English I’m from Italy :),"G H=G H H\neq\emptyset H G (U,\phi:U \to V) H G G \{(gU,\psi_{g})\}_{g\in G} \psi_{g}:gU\to V , gu \mapsto \phi(u) u U",['differential-geometry']
51,On the induced map in cohomology,On the induced map in cohomology,,"This comes from page 48/49 in Bott and Tu's book on Differential forms in Algebraic Topology . Let $M$ and $N$ be two manifolds and consider two projections $\pi_M : M \rightarrow N$ and $\pi_N : M \times N \rightarrow N$ . With these maps we can bring forms from both $M$ and $N$ to $M \times N$ : $$\pi_M^* : \Omega^i(M) \rightarrow \Omega^i(M \times N),$$ and $$\pi_N^* : \Omega^j(N) \rightarrow \Omega^j(M \times N).$$ With these then we can edge them to get a new $i+j$ form on $M \times N$ , $$\Omega^i(M) \times \Omega^j(N) \rightarrow \Omega^{i+j}(M \times N),$$ given by $(\omega,\eta) \mapsto \pi_M^*\omega \wedge \pi_N^*\eta.$ This map is clearly bilinear since everything is linear. By the universal mapping property for bilinear maps we have an unique induced map in the their tensor product such that $$\Omega^i(M) \times \Omega^j(N) \rightarrow \Omega^i(M) \otimes \Omega^j(N) \rightarrow \Omega^{i+j}(M\times N),$$ corresponds to $$(\omega,\eta) \mapsto \omega \otimes \eta \mapsto \pi_M^*\omega \wedge \pi_N^*\eta.$$ Now the authors claim this gives rise to a map in cohomology $$\psi : H^*(M) \otimes H^*(N) \rightarrow H^*(M \times N).$$ This is the part that I am not understanding: I believe we need to check that the map given by the universal property is a cochain map?","This comes from page 48/49 in Bott and Tu's book on Differential forms in Algebraic Topology . Let and be two manifolds and consider two projections and . With these maps we can bring forms from both and to : and With these then we can edge them to get a new form on , given by This map is clearly bilinear since everything is linear. By the universal mapping property for bilinear maps we have an unique induced map in the their tensor product such that corresponds to Now the authors claim this gives rise to a map in cohomology This is the part that I am not understanding: I believe we need to check that the map given by the universal property is a cochain map?","M N \pi_M : M \rightarrow N \pi_N : M \times N \rightarrow N M N M \times N \pi_M^* : \Omega^i(M) \rightarrow \Omega^i(M \times N), \pi_N^* : \Omega^j(N) \rightarrow \Omega^j(M \times N). i+j M \times N \Omega^i(M) \times \Omega^j(N) \rightarrow \Omega^{i+j}(M \times N), (\omega,\eta) \mapsto \pi_M^*\omega \wedge \pi_N^*\eta. \Omega^i(M) \times \Omega^j(N) \rightarrow \Omega^i(M) \otimes \Omega^j(N) \rightarrow \Omega^{i+j}(M\times N), (\omega,\eta) \mapsto \omega \otimes \eta \mapsto \pi_M^*\omega \wedge \pi_N^*\eta. \psi : H^*(M) \otimes H^*(N) \rightarrow H^*(M \times N).","['differential-geometry', 'differential-topology', 'homology-cohomology', 'differential-forms']"
52,Explicit formula for the principal connection 1-form induced by a Cartan connection,Explicit formula for the principal connection 1-form induced by a Cartan connection,,"Let $P \subseteq G$ be a closed Lie subgroup. Suppose that a principal $P$ -bundle $\mathcal{P} \to M$ is equipped with a Cartan connection $\omega: T\mathcal{P} \to \mathfrak{g}$ . Then the extended principal $G$ -bundle $\mathcal{P} \times_P G \to M$ admits a principal connection $\overline{\omega}$ . However, I cannot find a nice explicit formula given in Sharpe's or Cap & Slovak's book for this principal connection $1$ -form. Note that the tangent bundle of the extended principal $G$ -bundle is $$T(\mathcal{P} \times_P G) \cong T\mathcal{P} \times_{TP} TG,$$ where $TP$ is the tangent group of $P$ . For those unaware of this term, note that the tangent bundle of a Lie group is again a Lie group when we apply the tangent functor to the multiplication and inversion operations (since the tangent functor preserves limits). Thus, for some tangent vector $[\gamma, \tau] \in T\mathcal{P} \times_{TP} TG$ , I would naively guess that the formula should be something like $$\overline{\omega} [\gamma, \tau] = \omega(\gamma) + \omega_G(\tau) $$ where $\omega_G$ is the Maurer-Cartan form for $G$ . However, while I have a formula for how the Maurer-Cartan form behaves with respect to the action of the tangent group $TP$ , I don't see how to get a similar formula for the Cartan connection with respect to the action of $TP$ .","Let be a closed Lie subgroup. Suppose that a principal -bundle is equipped with a Cartan connection . Then the extended principal -bundle admits a principal connection . However, I cannot find a nice explicit formula given in Sharpe's or Cap & Slovak's book for this principal connection -form. Note that the tangent bundle of the extended principal -bundle is where is the tangent group of . For those unaware of this term, note that the tangent bundle of a Lie group is again a Lie group when we apply the tangent functor to the multiplication and inversion operations (since the tangent functor preserves limits). Thus, for some tangent vector , I would naively guess that the formula should be something like where is the Maurer-Cartan form for . However, while I have a formula for how the Maurer-Cartan form behaves with respect to the action of the tangent group , I don't see how to get a similar formula for the Cartan connection with respect to the action of .","P \subseteq G P \mathcal{P} \to M \omega: T\mathcal{P} \to \mathfrak{g} G \mathcal{P} \times_P G \to M \overline{\omega} 1 G T(\mathcal{P} \times_P G) \cong T\mathcal{P} \times_{TP} TG, TP P [\gamma, \tau] \in T\mathcal{P} \times_{TP} TG \overline{\omega} [\gamma, \tau] = \omega(\gamma) + \omega_G(\tau)  \omega_G G TP TP","['differential-geometry', 'connections', 'principal-bundles', 'cartan-geometry']"
53,Problem with understanding Morse's Lemma / Function.,Problem with understanding Morse's Lemma / Function.,,"https://math.stackexchange.com/a/398282/1257548 In this answer it is said that $f:S→\mathbb{R}, (x,y,z)↦y$ is Morse function but I don't see why. As far as I understand, because function is defined on manifold $S = \{(x,y,z):z^4+(x^2+y^2-1)(2x^2+3y^2-1)=0\}$ then using implicit function theorem we have that $$\frac{dy}{dz} = -\frac{4z^3}{12y^3+10x^2y-8y}$$ and $$\frac{dy}{dx} = -\frac{8x^3+10xy^2-6x}{12y^3+10x^2y-8y}$$ so $$\frac{d^2y}{dz^2}(x,y,0)=0, \frac{d^2y}{dx^2}(0,y,0)=a,\frac{d^2y}{dxdz}(x,y,0)=0.$$ So Hessian of $f$ is degenerated in $(0,−1,0),(0,−\frac{1}{\sqrt{3}},0),(0,\frac{1}{\sqrt{3}},0),(0,1,0)$ thus it can't be Morse function. Even differentiating $f$ like $\frac{df}{dy}=1$ and $\frac{d^2f}{dy^2}=0$ shows that it's also degenerated. I don't know if I don't understand something or if the answer is wrong. I know that taking the height function as Morse function works on torus and I see that taking $f(x,y,z)=y$ on S should work the same but I don't know why it doesn't work (or if I'm just doing something wrong). And if the function is wrong is it possible to correct it to proper Morse function?","https://math.stackexchange.com/a/398282/1257548 In this answer it is said that is Morse function but I don't see why. As far as I understand, because function is defined on manifold then using implicit function theorem we have that and so So Hessian of is degenerated in thus it can't be Morse function. Even differentiating like and shows that it's also degenerated. I don't know if I don't understand something or if the answer is wrong. I know that taking the height function as Morse function works on torus and I see that taking on S should work the same but I don't know why it doesn't work (or if I'm just doing something wrong). And if the function is wrong is it possible to correct it to proper Morse function?","f:S→\mathbb{R}, (x,y,z)↦y S = \{(x,y,z):z^4+(x^2+y^2-1)(2x^2+3y^2-1)=0\} \frac{dy}{dz} = -\frac{4z^3}{12y^3+10x^2y-8y} \frac{dy}{dx} = -\frac{8x^3+10xy^2-6x}{12y^3+10x^2y-8y} \frac{d^2y}{dz^2}(x,y,0)=0, \frac{d^2y}{dx^2}(0,y,0)=a,\frac{d^2y}{dxdz}(x,y,0)=0. f (0,−1,0),(0,−\frac{1}{\sqrt{3}},0),(0,\frac{1}{\sqrt{3}},0),(0,1,0) f \frac{df}{dy}=1 \frac{d^2f}{dy^2}=0 f(x,y,z)=y","['differential-geometry', 'algebraic-geometry', 'surfaces', 'morse-theory']"
54,"Understanding the Geometry Spawned from Quotient Spaces $GL^+(4,R)/SO(3,1)$, $GL^+(4,R)/Spin(3,1)$, and $GL^+(4,R)/Spin^c(3,1)$","Understanding the Geometry Spawned from Quotient Spaces , , and","GL^+(4,R)/SO(3,1) GL^+(4,R)/Spin(3,1) GL^+(4,R)/Spin^c(3,1)","I'm working on a theoretical framework where I explore different quotient spaces formed with GL $^+$ (4,R) and various groups. Specifically, I'm interested in the types of geometry that arise from the following quotient spaces: GL $^+$ (4,R)/SO(3,1) GL $^+$ (4,R)/Spin(3,1) GL $^+$ (4,R)/Spin $^c$ (3,1) For GL $^+$ (4,R)/SO(3,1), the situation is relatively clear as it leads to the usual symmetric, non-degenerate metric tensors commonly used in theories of gravity. However, I encounter difficulties when trying trying to understand the GL $^+$ (4,R)/Spin(3,1) and GL $^+$ (4,R)/Spin $^c$ (3,1) cases. In these scenarios, what geometry is described by these? To provide some context, I am using the Majorana representation of the Dirac matrices to construct a representation of 4x4 matrices. Furthermore in this representation Spin $^c$ (3,1) can be represented by exp (f+b), where f is a bivector and b a pseudo-scalar which is in GL $+$ (4,R). My question is: For instances GL+(4,R)/SO(3,1)xR spawns Weyl conformal geometry. But what do GL $^+$ (4,R)/Spin(3,1) and GL $^+$ (4,R)/Spin $^c$ (3,1) spawn? Any insights, references, or suggestions on how to approach these constructions would be greatly appreciated.","I'm working on a theoretical framework where I explore different quotient spaces formed with GL (4,R) and various groups. Specifically, I'm interested in the types of geometry that arise from the following quotient spaces: GL (4,R)/SO(3,1) GL (4,R)/Spin(3,1) GL (4,R)/Spin (3,1) For GL (4,R)/SO(3,1), the situation is relatively clear as it leads to the usual symmetric, non-degenerate metric tensors commonly used in theories of gravity. However, I encounter difficulties when trying trying to understand the GL (4,R)/Spin(3,1) and GL (4,R)/Spin (3,1) cases. In these scenarios, what geometry is described by these? To provide some context, I am using the Majorana representation of the Dirac matrices to construct a representation of 4x4 matrices. Furthermore in this representation Spin (3,1) can be represented by exp (f+b), where f is a bivector and b a pseudo-scalar which is in GL (4,R). My question is: For instances GL+(4,R)/SO(3,1)xR spawns Weyl conformal geometry. But what do GL (4,R)/Spin(3,1) and GL (4,R)/Spin (3,1) spawn? Any insights, references, or suggestions on how to approach these constructions would be greatly appreciated.",^+ ^+ ^+ ^+ ^c ^+ ^+ ^+ ^c ^c + ^+ ^+ ^c,"['differential-geometry', 'lie-groups', 'general-relativity', 'quantum-field-theory', 'gauge-theory']"
55,Upper bound on second fundamental form,Upper bound on second fundamental form,,"Consider a manifold $\mathcal{M}$ embedded in $\mathbb{R}^d$ and let $V$ and $W$ be two vector fields on $\mathcal{M}$ . As usual, we define the second fundamental form to be $ \mathrm{I\!I}(V, W) = (\tilde{\nabla}_V (W))^\perp $ , where $\tilde{\nabla}$ is the ambient covariant derivative and $X^\perp$ represents the normal projection of $X$ . I am interested in bounding $\| \mathrm{I\!I}(V, W) \|$ in terms of the bounds on the norms of $V$ and $W$ . For example, when the manifold is the sphere with the usual inherited metric, assuming that for all $x$ it holds that $\| V(x) \| \leq \alpha $ and $\| W(X) \| \leq \beta $ , I believe we have $\| \mathrm{I\!I}(V, W) \| \leq \alpha \beta $ . In general, I would expect such a bound to also depend on the curvature of the manifold. Later edit : when $\mathcal{M}$ is a hypersurface in $\mathbb{R}^d$ , letting $N$ be a smooth normal vector field, I know that $ \| \mathrm{I\!I}(V, W) \| =  \lvert \langle N, \mathrm{I\!I}(V, W) \rangle \rvert = \lvert h(V, W) \rvert $ , where $h$ is the scalar second fundamental form. In this case, the principal curvatures $\mathcal{k}_i$ are defined as the eigenalues of the shape operator $s : T_x \mathcal{M} \rightarrow T_x \mathcal{M}$ , $s = W_N$ , where $W_N$ is the Weingarten map in direction $N$ . We can write $h(V, W)$ in the basis of $T_x \mathcal{M}$ given by the eigenvectors $b_i$ of $s$ (with corresponding eigenvalue $\mathcal{k}_i$ ) to obtain $$ h(V, W) = \langle W, sV \rangle = \langle W, s \sum_i \langle V, b_i \rangle b_i \rangle = \sum_i \mathcal{k}_i \langle V, b_i \rangle \langle W, b_i \rangle $$ From here, it's easy to obtain a bound on $\lvert h(V, W) \rvert$ in terms of the maximum principal curvature. The question would be how to extend this for the case when $\mathcal{M}$ is an arbitrary smooth manifold. I know, for example, that the second fundamental form is related to the Riemann curvature tensor through the Gauss Equation (in Lee's Riemannian manifolds, Theorem 8.5), but it's not clear how to proceed from there. I am willing to assume I have bounds on (any sort of) curvature that comes up. Any pointers on how I could proceed for obtaining such a bound in the general case are appreciated!","Consider a manifold embedded in and let and be two vector fields on . As usual, we define the second fundamental form to be , where is the ambient covariant derivative and represents the normal projection of . I am interested in bounding in terms of the bounds on the norms of and . For example, when the manifold is the sphere with the usual inherited metric, assuming that for all it holds that and , I believe we have . In general, I would expect such a bound to also depend on the curvature of the manifold. Later edit : when is a hypersurface in , letting be a smooth normal vector field, I know that , where is the scalar second fundamental form. In this case, the principal curvatures are defined as the eigenalues of the shape operator , , where is the Weingarten map in direction . We can write in the basis of given by the eigenvectors of (with corresponding eigenvalue ) to obtain From here, it's easy to obtain a bound on in terms of the maximum principal curvature. The question would be how to extend this for the case when is an arbitrary smooth manifold. I know, for example, that the second fundamental form is related to the Riemann curvature tensor through the Gauss Equation (in Lee's Riemannian manifolds, Theorem 8.5), but it's not clear how to proceed from there. I am willing to assume I have bounds on (any sort of) curvature that comes up. Any pointers on how I could proceed for obtaining such a bound in the general case are appreciated!","\mathcal{M} \mathbb{R}^d V W \mathcal{M}  \mathrm{I\!I}(V, W) = (\tilde{\nabla}_V (W))^\perp  \tilde{\nabla} X^\perp X \| \mathrm{I\!I}(V, W) \| V W x \| V(x) \| \leq \alpha  \| W(X) \| \leq \beta  \| \mathrm{I\!I}(V, W) \| \leq \alpha \beta  \mathcal{M} \mathbb{R}^d N  \| \mathrm{I\!I}(V, W) \| =  \lvert \langle N, \mathrm{I\!I}(V, W) \rangle \rvert = \lvert h(V, W) \rvert  h \mathcal{k}_i s : T_x \mathcal{M} \rightarrow T_x \mathcal{M} s = W_N W_N N h(V, W) T_x \mathcal{M} b_i s \mathcal{k}_i  h(V, W) = \langle W, sV \rangle = \langle W, s \sum_i \langle V, b_i \rangle b_i \rangle = \sum_i \mathcal{k}_i \langle V, b_i \rangle \langle W, b_i \rangle  \lvert h(V, W) \rvert \mathcal{M}","['differential-geometry', 'manifolds', 'smooth-manifolds', 'curvature', 'submanifold']"
56,Lie bracket as a directional derivative,Lie bracket as a directional derivative,,"I'm trying to understand the Lie bracket operation $[X, Y]$ as the rate of change of $Y$ as seen by an observer moving along the flow of $X$ . Example 1 Suppose $X=\{1, x\}^T$ and $Y=\{1, 0\}^T$ , then $[X, Y]=\{0, -1\}$ and the flow of $X$ is $\{t+x_0,\frac{1}{2}t^2+ t\ x_0+ y_0\}$ . But I'm failing to see how along any of the flows below, the rate of change of vector $\{1, 0\}$ is $\{0,-1\}$ . Example 2 Suppose $X=\{x, x\}^T$ and $Y=\{1, 0\}^T$ , then $[X, Y]=\{-1, -1\}$ and the flow of $X$ is $\{e^t\ x_0,e^t\ x_0-x_0+y_0\}$ . Again from plot below I'm not able to see how the directional derivative makes sense. Edit Adding except from the source.","I'm trying to understand the Lie bracket operation as the rate of change of as seen by an observer moving along the flow of . Example 1 Suppose and , then and the flow of is . But I'm failing to see how along any of the flows below, the rate of change of vector is . Example 2 Suppose and , then and the flow of is . Again from plot below I'm not able to see how the directional derivative makes sense. Edit Adding except from the source.","[X, Y] Y X X=\{1, x\}^T Y=\{1, 0\}^T [X, Y]=\{0, -1\} X \{t+x_0,\frac{1}{2}t^2+ t\ x_0+ y_0\} \{1, 0\} \{0,-1\} X=\{x, x\}^T Y=\{1, 0\}^T [X, Y]=\{-1, -1\} X \{e^t\ x_0,e^t\ x_0-x_0+y_0\}","['differential-geometry', 'lie-derivative']"
57,$\Phi$ is smooth iff $\Psi$ is smooth,is smooth iff  is smooth,\Phi \Psi,"So I was trying to solve this problem in the Differential Geometry notes of Rui Loja Fernandes: Let $\pi: M \to Q$ be a surjective submersion, $\Phi:M \to N$ and $\Psi: Q \to N$ any maps into a smooth manifold $N$ such that the following diagram commutes: I want to show that $\Phi$ is smooth iff $\Psi$ is smooth. So one direction is easy: if $\Psi$ is smooth, then $\Phi$ is smooth as the composition of smooth functions. On the other hand, suppose $\Phi$ is smooth, and let $q \in Q$ . We want to show that $\Psi$ is smooth at $q$ . As $\pi$ is surjective, there is an $m \in M$ such that $q=\pi(m)$ . By the local form for submersions, locally $\pi$ can be written as $\pi(x^1,\dots,x^d)=(x^1,\dots,x^e)$ , where $d=\dim M, e = \dim Q$ . So locally we have $\Phi(x^1,\dots,x^d)=\Psi(x^1,\dots,x^e)$ . Is this enough to prove smoothness of $\Psi$ ?","So I was trying to solve this problem in the Differential Geometry notes of Rui Loja Fernandes: Let be a surjective submersion, and any maps into a smooth manifold such that the following diagram commutes: I want to show that is smooth iff is smooth. So one direction is easy: if is smooth, then is smooth as the composition of smooth functions. On the other hand, suppose is smooth, and let . We want to show that is smooth at . As is surjective, there is an such that . By the local form for submersions, locally can be written as , where . So locally we have . Is this enough to prove smoothness of ?","\pi: M \to Q \Phi:M \to N \Psi: Q \to N N \Phi \Psi \Psi \Phi \Phi q \in Q \Psi q \pi m \in M q=\pi(m) \pi \pi(x^1,\dots,x^d)=(x^1,\dots,x^e) d=\dim M, e = \dim Q \Phi(x^1,\dots,x^d)=\Psi(x^1,\dots,x^e) \Psi","['differential-geometry', 'solution-verification', 'manifolds']"
58,"How to characterize the tangent space $T_f C^\infty(K, \mathbb{R}^n)$ and paths in $C^\infty(K, \mathbb{R}^n)$",How to characterize the tangent space  and paths in,"T_f C^\infty(K, \mathbb{R}^n) C^\infty(K, \mathbb{R}^n)","Let $K \subset \mathbb{R}$ be compact. For any function $f \in C^\infty(K, \mathbb{R}^n)$ how would one characterize the tangent space $T_f C^\infty(K, \mathbb{R}^n)$ ? I am following a set of notes that says for any $f$ , $T_f C^\infty(K, \mathbb{R}^n)$ can be identified with the space of smooth sections of some pullback bundle. If this is true, how would one arrive to this conclusion? Why do sections of the pullback bundle appear? Secondly how would one define smooth paths in such a space?","Let be compact. For any function how would one characterize the tangent space ? I am following a set of notes that says for any , can be identified with the space of smooth sections of some pullback bundle. If this is true, how would one arrive to this conclusion? Why do sections of the pullback bundle appear? Secondly how would one define smooth paths in such a space?","K \subset \mathbb{R} f \in C^\infty(K, \mathbb{R}^n) T_f C^\infty(K, \mathbb{R}^n) f T_f C^\infty(K, \mathbb{R}^n)","['differential-geometry', 'manifolds', 'smooth-manifolds', 'tangent-spaces']"
59,Curved space described by inverse matrix of another curved space,Curved space described by inverse matrix of another curved space,,"I was introduced to geometry of curved space in General Relativity but now I am more interested in learning more about it in general.The tensors which  describe a curved 3D space can be represented in the form of a matrix A.The eleements of the main diagonal of $A$ give the distance conversion of each dimension and $A[i,j] , j \ne i$ give the skew angle between corresponding dimensions.Suppose we get the inverse of A $A^{-1}$ .Which is the relationship between the curved space described by $A$ and $A^{-1}$ ?",I was introduced to geometry of curved space in General Relativity but now I am more interested in learning more about it in general.The tensors which  describe a curved 3D space can be represented in the form of a matrix A.The eleements of the main diagonal of give the distance conversion of each dimension and give the skew angle between corresponding dimensions.Suppose we get the inverse of A .Which is the relationship between the curved space described by and ?,"A A[i,j] , j \ne i A^{-1} A A^{-1}",['differential-geometry']
60,Covariant derivative of a rotationally symmetric metric,Covariant derivative of a rotationally symmetric metric,,"I'm trying to follow a calculation of the curvature tensor of a rotationally symmetric metric, and there's this step I can't justify to myself. The discussion can be found on Petersen's ""Riemannian Geometry"", section 4.2.3. The setting is as follows. We have a metric $$g =dr^2 +\rho(r)^2ds^2_{n-1} $$ and we set $$ g_r = \rho^2 ds^2_{n-1} $$ We've proved that $$ Hess(r)=\frac{\partial_r \rho}{\rho} g_r $$ The author then calculates as follows: $$  \begin{align}   \nabla_{\partial_r}Hess(r)      &= \nabla_{\partial_r}(\frac{\partial_r \rho}{\rho} g_r) \\     &= \nabla_{\partial_r} (\frac{\partial_r \rho}{\rho}) g_r + \frac{\partial_r \rho}{\rho} \nabla_{\partial_r} (g_r)\\  \# &= \frac{(\partial_r^2 \rho)\rho - (\partial_r \rho)^2}{\rho^2}g_r \\     &= \frac{(\partial_r^2 \rho)}{\rho}g_r -Hess^2(r) \end{align} $$ I've marked the step I'm confused about with a #. I think it implies $\nabla_{\partial_r} g_r =0$ , but when calculating, I have: $$ \nabla_{\partial_r} (g_r) = \nabla_{\partial_r}(\rho^2 ds^2_{n-1} ) = 2\rho \partial_r (\rho)ds^2_{n-1} $$ What did I get wrong?","I'm trying to follow a calculation of the curvature tensor of a rotationally symmetric metric, and there's this step I can't justify to myself. The discussion can be found on Petersen's ""Riemannian Geometry"", section 4.2.3. The setting is as follows. We have a metric and we set We've proved that The author then calculates as follows: I've marked the step I'm confused about with a #. I think it implies , but when calculating, I have: What did I get wrong?","g =dr^2 +\rho(r)^2ds^2_{n-1}   g_r = \rho^2 ds^2_{n-1}   Hess(r)=\frac{\partial_r \rho}{\rho} g_r   
\begin{align} 
 \nabla_{\partial_r}Hess(r) 
    &= \nabla_{\partial_r}(\frac{\partial_r \rho}{\rho} g_r) \\
    &= \nabla_{\partial_r} (\frac{\partial_r \rho}{\rho}) g_r + \frac{\partial_r \rho}{\rho} \nabla_{\partial_r} (g_r)\\
 \# &= \frac{(\partial_r^2 \rho)\rho - (\partial_r \rho)^2}{\rho^2}g_r \\
    &= \frac{(\partial_r^2 \rho)}{\rho}g_r -Hess^2(r)
\end{align}
 \nabla_{\partial_r} g_r =0 
\nabla_{\partial_r} (g_r) = \nabla_{\partial_r}(\rho^2 ds^2_{n-1} ) = 2\rho \partial_r (\rho)ds^2_{n-1}
","['differential-geometry', 'riemannian-geometry']"
61,"If $(V, \langle,\rangle)$ is a $4$ dim vector space, then show that the set of all compatible complex structures consists of two copies of $S^2$.","If  is a  dim vector space, then show that the set of all compatible complex structures consists of two copies of .","(V, \langle,\rangle) 4 S^2","If $(V, \langle,\rangle)$ is a four-dimensional Euclidean vector space, then show that the set of all compatible complex structures consists of two copies of $S^2$ . I'm quite new to complex differential geometry and this feels a bit weird to me as if we let $A$ denote the set of all complex structures of $V$ , then $A = \{I : V \to V \mid I^2 = -\operatorname{id}, \langle I(v), I(w)\rangle = \langle v, w\rangle \}$ and for some reason this should consist of two copies of $S^2$ ? I know that we also have $I \in O((V, \langle,\rangle))$ , but this ain't helping that much either. By compatible we mean that $\langle I(v), I(w)\rangle = \langle v, w\rangle$ .","If is a four-dimensional Euclidean vector space, then show that the set of all compatible complex structures consists of two copies of . I'm quite new to complex differential geometry and this feels a bit weird to me as if we let denote the set of all complex structures of , then and for some reason this should consist of two copies of ? I know that we also have , but this ain't helping that much either. By compatible we mean that .","(V, \langle,\rangle) S^2 A V A = \{I : V \to V \mid I^2 = -\operatorname{id}, \langle I(v), I(w)\rangle = \langle v, w\rangle \} S^2 I \in O((V, \langle,\rangle)) \langle I(v), I(w)\rangle = \langle v, w\rangle","['differential-geometry', 'complex-geometry']"
62,Orientation preserving isometries of the sphere,Orientation preserving isometries of the sphere,,"I know that the isometries of $\mathbb{S}^n\subseteq\mathbb{E}^{n+1}$ are $O(n+1)$ . Intuitively, I think that $SO(n+1)$ should be the orientation-preserving ones. But I'd like to prove this rigourosly. I know that a map is orientation preserving iff its differential at any point is orientation preserving. Clearly if $A\in O(n+1)$ is an isometry, then $d_pA(v)=Av$ but $d_pA$ is NOT an endomorphism (it has different domain and codomain) so I cannot simply say that it's orientation  preserving iff $\det(A)>0$ . Right? How do I solve this?","I know that the isometries of are . Intuitively, I think that should be the orientation-preserving ones. But I'd like to prove this rigourosly. I know that a map is orientation preserving iff its differential at any point is orientation preserving. Clearly if is an isometry, then but is NOT an endomorphism (it has different domain and codomain) so I cannot simply say that it's orientation  preserving iff . Right? How do I solve this?",\mathbb{S}^n\subseteq\mathbb{E}^{n+1} O(n+1) SO(n+1) A\in O(n+1) d_pA(v)=Av d_pA \det(A)>0,"['linear-algebra', 'differential-geometry', 'riemannian-geometry', 'orientation']"
63,"Understanding the ""abuse of notation"" in the differential of tangent vectors","Understanding the ""abuse of notation"" in the differential of tangent vectors",,"I am reading John Lee's Smooth Manifolds book, current looking at the bottom of Page 63 in which we are working out what the differential looks like in the special case that it's along the transition map between two charts. Let $M$ be a smooth manifold and and $(U,\psi)$ and $(V,\phi)$ be two smooth coordinate charts with coordinate functions $(x^i)$ and $(\tilde x^i)$ respectively. It goes on to mention that we are engaging in a typical abuse of notation by writing the transition map as follows: $$\phi\circ\psi^{-1}(x):=(\tilde x^1(x),...,\tilde x^n(x)).$$ It then mentions that here we are thinking of the $\tilde x^i$ in $\tilde x^i(x)$ as a coordinate function, but $x$ as representing a point. I want to make sure I have understood what exactly about this is abuse of notation (my background is physics so I am no stranger to abuse of notation). I want to say that we are doing two things that are ""questionable notation"" here, the first is that (as the author mentions) before, the letter $x$ would have represented the coordinate functions on $U$ but now represent a point. And also that $\tilde x^j$ is no longer a function $$\tilde x^j:V\rightarrow \Bbb R^N$$ but instead the different function $$\tilde x^j:\psi(U)\rightarrow \phi(V).$$ Which leads on to me now looking at the final equation we end up with (which is much more recognisable to a physicist), $$\frac{\partial \tilde x^{j}}{\partial x^{i}}(\psi(p)) \frac{\partial}{\partial \tilde x^{j}}|_{\psi(p)},$$ in which $\tilde x^k$ is now simultaneously two objects in the same expression. in the first ""half"" of the expression, $\frac{\partial \tilde x^j}{\partial x^i}(\psi(p))$ , it is the transition map, and in the second ""half"", $\frac{\partial}{\partial \tilde x^j}\biggr|_{\psi(p)}$ , it is the (strictly completely different) coordinate function on $V$ . My question is, is my reasoning above correct? Thanks in advance :)","I am reading John Lee's Smooth Manifolds book, current looking at the bottom of Page 63 in which we are working out what the differential looks like in the special case that it's along the transition map between two charts. Let be a smooth manifold and and and be two smooth coordinate charts with coordinate functions and respectively. It goes on to mention that we are engaging in a typical abuse of notation by writing the transition map as follows: It then mentions that here we are thinking of the in as a coordinate function, but as representing a point. I want to make sure I have understood what exactly about this is abuse of notation (my background is physics so I am no stranger to abuse of notation). I want to say that we are doing two things that are ""questionable notation"" here, the first is that (as the author mentions) before, the letter would have represented the coordinate functions on but now represent a point. And also that is no longer a function but instead the different function Which leads on to me now looking at the final equation we end up with (which is much more recognisable to a physicist), in which is now simultaneously two objects in the same expression. in the first ""half"" of the expression, , it is the transition map, and in the second ""half"", , it is the (strictly completely different) coordinate function on . My question is, is my reasoning above correct? Thanks in advance :)","M (U,\psi) (V,\phi) (x^i) (\tilde x^i) \phi\circ\psi^{-1}(x):=(\tilde x^1(x),...,\tilde x^n(x)). \tilde x^i \tilde x^i(x) x x U \tilde x^j \tilde x^j:V\rightarrow \Bbb R^N \tilde x^j:\psi(U)\rightarrow \phi(V). \frac{\partial \tilde x^{j}}{\partial x^{i}}(\psi(p)) \frac{\partial}{\partial \tilde x^{j}}|_{\psi(p)}, \tilde x^k \frac{\partial \tilde x^j}{\partial x^i}(\psi(p)) \frac{\partial}{\partial \tilde x^j}\biggr|_{\psi(p)} V","['differential-geometry', 'smooth-manifolds', 'coordinate-systems', 'tangent-spaces', 'pushforward']"
64,Different definitions for a connection,Different definitions for a connection,,"I'm learning Riemannian geometry and in particular about connections and I have now seen multiple different definitions for this and trying to understand how they are all the same. The first one and the one I'm relatively comfortable with is that if $\pi : E \to M$ is a smooth vector bundle over a smooth manifold $M$ , then a connection is a map $$\nabla : \mathfrak{X}(M) \times \Gamma(E) \to \Gamma(E), (X,Y) \mapsto \nabla_XY$$ satisfying certain the product rule and linearity over $\mathbb{R}$ in $Y$ as well as linearity over $C^\infty(M)$ in $X$ . The second one I have is that a connection on a smooth vector bundle $\xi$ is an $\mathbb{R}$ -linear map $$\nabla: \Omega^0(\xi) \to \Omega^1(M) \otimes_{\Omega^0(M)} \Omega^0(\xi)$$ which satisfies the Leibnitz rule $\nabla(f\cdot s)=df \otimes s + f \cdot \nabla s.$ The last one is from Wikipedia which states that for a smooth vector bundle $E \to M$ a connection is an $\mathbb{R}$ -linear map $$\nabla:\Gamma(E) \to \Gamma(T^*M \otimes E)$$ that satisfies the same kinda properties as the two above. Now I think that most of my confusion here is due to not understanding the tensor product properly. If anyone can provide some idea on why the two latter ones should coincide with the first one that would be much appreciated. Also for the record I'm quite well acquainted with differential forms so there is no need to explain what $\Omega^k(M)$ 's are here.","I'm learning Riemannian geometry and in particular about connections and I have now seen multiple different definitions for this and trying to understand how they are all the same. The first one and the one I'm relatively comfortable with is that if is a smooth vector bundle over a smooth manifold , then a connection is a map satisfying certain the product rule and linearity over in as well as linearity over in . The second one I have is that a connection on a smooth vector bundle is an -linear map which satisfies the Leibnitz rule The last one is from Wikipedia which states that for a smooth vector bundle a connection is an -linear map that satisfies the same kinda properties as the two above. Now I think that most of my confusion here is due to not understanding the tensor product properly. If anyone can provide some idea on why the two latter ones should coincide with the first one that would be much appreciated. Also for the record I'm quite well acquainted with differential forms so there is no need to explain what 's are here.","\pi : E \to M M \nabla : \mathfrak{X}(M) \times \Gamma(E) \to \Gamma(E), (X,Y) \mapsto \nabla_XY \mathbb{R} Y C^\infty(M) X \xi \mathbb{R} \nabla: \Omega^0(\xi) \to \Omega^1(M) \otimes_{\Omega^0(M)} \Omega^0(\xi) \nabla(f\cdot s)=df \otimes s + f \cdot \nabla s. E \to M \mathbb{R} \nabla:\Gamma(E) \to \Gamma(T^*M \otimes E) \Omega^k(M)","['differential-geometry', 'riemannian-geometry']"
65,Help understanding the derivation of weingarten formula.,Help understanding the derivation of weingarten formula.,,"Let $f: M^n \to \tilde{M}^m$ be an isometric immersion of Riemannian manifolds (that is $\langle X,Y \rangle_M =\langle f_*(x) X, f_*(x)Y \rangle_{\tilde{M}}$ with $\langle , \rangle_M$ and $\langle , \rangle_{\tilde{M}}$ be the Riemannian structures of $M$ and $\tilde{M}$ respectively and with $\tilde{\nabla}$ the Levi-Civita connection for $\tilde{M}^m$ For $X,Y \in \mathcal{X} (M)$ we have the decomposition $$\tilde{\nabla}_X f_* Y =(\tilde{\nabla}_X f_* Y )^T +(\tilde{\nabla}_X f_*Y )^{\perp}$$ with respect to the decomposition $$f^* T \tilde{M} =f_*TM \oplus N_fM,$$ where $N_fM$ is the normal bundle of $f$ . Let $a:\mathcal{X} (M) \times \mathcal{X} (M) \to \Gamma (N_fM)$ defined by $$a^f (X,Y) =(\tilde{\nabla }_X f_* Y)^{\perp}$$ be the second fundamental form of $f$ . Let $A_{\xi}$ της $f$ στο $x \in M^n$ the shape operator at $\xi \in N_fM(x)$ defined as $$\langle A_{\xi} X,Y \rangle =\langle a(X,Y),\xi \rangle$$ for all $X,Y \in T_xM$ . We will derive the weingarten formula. For vector fields $X,Y \in \mathcal{X}(M)$ and $\xi \in \Gamma (N_fM)$ we have $$\langle \tilde{\nabla}_X \xi ,f_* Y\rangle =-\langle \xi ,\tilde{\nabla}_X f_*Y \rangle $$ $$ =-\langle \xi , a(X,Y) \rangle$$ $$ = -\langle A_{\xi} X,Y \rangle$$ Therefore the tangential component of $\tilde{\nabla_X} \xi$ is $-f_* A_{\xi} X$ . I don't understand the proof, specifically why is it true that $ -\langle \xi ,\tilde{\nabla}_X f_*Y \rangle=-\langle \xi , a(X,Y) \rangle$ , since $a$ is defined to be equal to $(\tilde{\nabla }_X f_* Y)^{\perp}$ , not $\tilde{\nabla }_X f_* Y$ , there must be some property of inner products that I am missing and why does $\langle \tilde{\nabla}_X \xi ,f_* Y\rangle = -\langle A_{\xi} X, Y \rangle$ imply that the tangential component of $\tilde{\nabla_X} \xi$ is $-f_* A_{\xi} X$ , I think this should imply that $\tilde{\nabla}_X \xi = -f_* A_{\xi } X$ by the properties of inner products, but here the author of the proof concludes that $$\tilde{\nabla}_X \xi = -f_* A_{\xi } X +\text{normal component}$$ why is that? Can you explain?","Let be an isometric immersion of Riemannian manifolds (that is with and be the Riemannian structures of and respectively and with the Levi-Civita connection for For we have the decomposition with respect to the decomposition where is the normal bundle of . Let defined by be the second fundamental form of . Let της στο the shape operator at defined as for all . We will derive the weingarten formula. For vector fields and we have Therefore the tangential component of is . I don't understand the proof, specifically why is it true that , since is defined to be equal to , not , there must be some property of inner products that I am missing and why does imply that the tangential component of is , I think this should imply that by the properties of inner products, but here the author of the proof concludes that why is that? Can you explain?","f: M^n \to \tilde{M}^m \langle X,Y \rangle_M =\langle f_*(x) X, f_*(x)Y \rangle_{\tilde{M}} \langle , \rangle_M \langle , \rangle_{\tilde{M}} M \tilde{M} \tilde{\nabla} \tilde{M}^m X,Y \in \mathcal{X} (M) \tilde{\nabla}_X f_* Y =(\tilde{\nabla}_X f_* Y )^T +(\tilde{\nabla}_X f_*Y )^{\perp} f^* T \tilde{M} =f_*TM \oplus N_fM, N_fM f a:\mathcal{X} (M) \times \mathcal{X} (M) \to \Gamma (N_fM) a^f (X,Y) =(\tilde{\nabla }_X f_* Y)^{\perp} f A_{\xi} f x \in M^n \xi \in N_fM(x) \langle A_{\xi} X,Y \rangle =\langle a(X,Y),\xi \rangle X,Y \in T_xM X,Y \in \mathcal{X}(M) \xi \in \Gamma (N_fM) \langle \tilde{\nabla}_X \xi ,f_* Y\rangle =-\langle \xi ,\tilde{\nabla}_X f_*Y \rangle   =-\langle \xi , a(X,Y) \rangle  = -\langle A_{\xi} X,Y \rangle \tilde{\nabla_X} \xi -f_* A_{\xi} X  -\langle \xi ,\tilde{\nabla}_X f_*Y \rangle=-\langle \xi , a(X,Y) \rangle a (\tilde{\nabla }_X f_* Y)^{\perp} \tilde{\nabla }_X f_* Y \langle \tilde{\nabla}_X \xi ,f_* Y\rangle = -\langle A_{\xi} X, Y \rangle \tilde{\nabla_X} \xi -f_* A_{\xi} X \tilde{\nabla}_X \xi = -f_* A_{\xi } X \tilde{\nabla}_X \xi = -f_* A_{\xi } X +\text{normal component}","['differential-geometry', 'proof-explanation', 'riemannian-geometry', 'inner-products']"
66,The image of a Riemannian submanifold under a diffeomorphism,The image of a Riemannian submanifold under a diffeomorphism,,"Let $\Sigma$ be a compact submanifold of a Riemannian manifold $(M,g)$ , let $h$ be the induced metric on $\Sigma$ , and let $\Phi:M\to M$ be a diffeomorphism. $h_\Phi$ will denote the induced metric on the image $\Phi(\Sigma)$ , pulled back to $\Sigma$ via $\Phi$ . What is the $h_\Phi$ really? I know $\Phi(\Sigma)$ is an embedded submanifold of $M$ with the property that $\Phi$ maps $\Sigma$ diffeomorphically onto $\Phi(\Sigma)$ , which begs a question:do the Riemannian metrics on $\Phi(\Sigma)$ induced respectively by the inclusion $\iota|_{\Phi(\Sigma)}:\Phi(\Sigma)\hookrightarrow M$ and the restriction $\Phi|_\Sigma$ coincide? I supposed that $h_\Phi$ is the Riemannian metric induced by $\iota|_{\Phi(\Sigma)}$ and tried to show that $$\Phi|_\Sigma^*h_\Phi=h$$ but didn't find a way. The following is as far as I can go now: $$\Phi|_\Sigma^*h_\Phi=\Phi|_\Sigma^*(\iota_{\Phi(\Sigma)}^*g)=(\iota_{\Phi(\Sigma)}\circ\Phi|_\Sigma)^*g=???=\iota_\Sigma^*g=h$$ $\iota_\Sigma$ is the inclusion $\Sigma\hookrightarrow M$ . Thanks for help. Edit. I think the author was trying to say $$h_\Phi=(\Phi|_\Sigma^{-1})^*h.$$ That way, we would have $$h=\Phi|_\Sigma^*h_\Phi.$$ This is pretty much the scenario described in the quote.","Let be a compact submanifold of a Riemannian manifold , let be the induced metric on , and let be a diffeomorphism. will denote the induced metric on the image , pulled back to via . What is the really? I know is an embedded submanifold of with the property that maps diffeomorphically onto , which begs a question:do the Riemannian metrics on induced respectively by the inclusion and the restriction coincide? I supposed that is the Riemannian metric induced by and tried to show that but didn't find a way. The following is as far as I can go now: is the inclusion . Thanks for help. Edit. I think the author was trying to say That way, we would have This is pretty much the scenario described in the quote.","\Sigma (M,g) h \Sigma \Phi:M\to M h_\Phi \Phi(\Sigma) \Sigma \Phi h_\Phi \Phi(\Sigma) M \Phi \Sigma \Phi(\Sigma) \Phi(\Sigma) \iota|_{\Phi(\Sigma)}:\Phi(\Sigma)\hookrightarrow M \Phi|_\Sigma h_\Phi \iota|_{\Phi(\Sigma)} \Phi|_\Sigma^*h_\Phi=h \Phi|_\Sigma^*h_\Phi=\Phi|_\Sigma^*(\iota_{\Phi(\Sigma)}^*g)=(\iota_{\Phi(\Sigma)}\circ\Phi|_\Sigma)^*g=???=\iota_\Sigma^*g=h \iota_\Sigma \Sigma\hookrightarrow M h_\Phi=(\Phi|_\Sigma^{-1})^*h. h=\Phi|_\Sigma^*h_\Phi.","['differential-geometry', 'riemannian-geometry', 'submanifold']"
67,In the proof of the Gauss-Bonnet Formula ( John Lee's Riemannian Manifold ),In the proof of the Gauss-Bonnet Formula ( John Lee's Riemannian Manifold ),,"I'm reading the John Lee's Introduction to Riemannian Manifold, p.273, proof of Theorem 9.3. and stuck at understanding some statement : Theorem 9.3 ( The Gauss-Bonnet Formula ). Let $(M, g)$ be an oriented Riemannian 2-manifold. Suppose $\gamma$ is a positively oriented curved polygon in $M$ , and $\Omega$ is its interior. Then $$ \int_{\Omega}KdA + \int_{\gamma}\kappa_Nds +\Sigma_{i=1}^{k} \epsilon_i = 2\pi,$$ where $K$ is the Gaussian curvature of $g$ , $dA$ is ita Riemannian volume form, $\epsilon_1 , \dots , \epsilon_k$ are the exterior angles of $\gamma$ ( c.f. his book p.271 ), and the second integral is taken with respect to arc length ( Problem 2-32 ). In the proof of the theroem, he argues as follows : Proof. Let $(a_0 , \dots ,a_k)$ be an admissible partition of $[a,b]$ , and let $(x,y)$ be oriented smooth coordinates on an open set $U$ containing $\bar{\Omega}$ ( by the definition of $\Omega$ , refer to definition of curved polygon ; his book p.271 ). Let $\theta : [a,b] \to \mathbb{R}$ be a tangent angle function for $\gamma$ ( c.f. his book p.272 ). Using the rotation index theorem ( his book Lemma 9.2. ) and the fundamental theorem of calculus, we can write $$ 2\pi = \theta(b) - \theta(a) = \Sigma_{i=1}^{k}\epsilon_i + \Sigma_{i=1}^{k}\int_{a_{i-1}}^{a_i}\theta'(t)dt$$ Q. And why this is true? Why the term $\Sigma_{i=1}^{k}\epsilon_i$ appears ? An issue that makes me confusing is, $$ \Sigma_{i=1}^{k}\int_{a_{i-1}}^{a_i}\theta'(t)dt = \Sigma_{i=1}^{k} ( \theta(a_i) - \theta(a_{i-1})) = \theta(b) - \theta (a) ?$$ What is a point that I made misunderstood? What is the definition of $\int_{a_{i-1}}^{a_i}\theta'(t)dt$ for each $i$ ? In page p.272, the author defined a tangent angle function for $\gamma$ as a piecewise continuous function $\theta : [a,b] \to \mathbb{R}$ that satisfies $$ T(t) = \cos\theta(t) E_1 |_{\gamma(t)} + \sin\theta(t) E_2|_{\gamma(t)}$$ ( where $T(t)$ is the unit tangent vector field of $\gamma$ , c.f. p.271 ) at each $t$ where $\gamma'$ is continuous, and that is continuous from the right and satisfies (9.1) and (9.2) at vertices. Here the (9.1) and (9.2) in his book are as follows : $$ \theta(a_i) = \lim_{t \nearrow a_i}\theta(t) + \epsilon_i,$$ $$ \theta(b) = \lim_{t \nearrow b}\theta(t) + \epsilon_k $$ Can we try to use these ? Can anyone helps?","I'm reading the John Lee's Introduction to Riemannian Manifold, p.273, proof of Theorem 9.3. and stuck at understanding some statement : Theorem 9.3 ( The Gauss-Bonnet Formula ). Let be an oriented Riemannian 2-manifold. Suppose is a positively oriented curved polygon in , and is its interior. Then where is the Gaussian curvature of , is ita Riemannian volume form, are the exterior angles of ( c.f. his book p.271 ), and the second integral is taken with respect to arc length ( Problem 2-32 ). In the proof of the theroem, he argues as follows : Proof. Let be an admissible partition of , and let be oriented smooth coordinates on an open set containing ( by the definition of , refer to definition of curved polygon ; his book p.271 ). Let be a tangent angle function for ( c.f. his book p.272 ). Using the rotation index theorem ( his book Lemma 9.2. ) and the fundamental theorem of calculus, we can write Q. And why this is true? Why the term appears ? An issue that makes me confusing is, What is a point that I made misunderstood? What is the definition of for each ? In page p.272, the author defined a tangent angle function for as a piecewise continuous function that satisfies ( where is the unit tangent vector field of , c.f. p.271 ) at each where is continuous, and that is continuous from the right and satisfies (9.1) and (9.2) at vertices. Here the (9.1) and (9.2) in his book are as follows : Can we try to use these ? Can anyone helps?","(M, g) \gamma M \Omega  \int_{\Omega}KdA + \int_{\gamma}\kappa_Nds +\Sigma_{i=1}^{k} \epsilon_i = 2\pi, K g dA \epsilon_1 , \dots , \epsilon_k \gamma (a_0 , \dots ,a_k) [a,b] (x,y) U \bar{\Omega} \Omega \theta : [a,b] \to \mathbb{R} \gamma  2\pi = \theta(b) - \theta(a) = \Sigma_{i=1}^{k}\epsilon_i + \Sigma_{i=1}^{k}\int_{a_{i-1}}^{a_i}\theta'(t)dt \Sigma_{i=1}^{k}\epsilon_i  \Sigma_{i=1}^{k}\int_{a_{i-1}}^{a_i}\theta'(t)dt = \Sigma_{i=1}^{k} ( \theta(a_i) - \theta(a_{i-1})) = \theta(b) - \theta (a) ? \int_{a_{i-1}}^{a_i}\theta'(t)dt i \gamma \theta : [a,b] \to \mathbb{R}  T(t) = \cos\theta(t) E_1 |_{\gamma(t)} + \sin\theta(t) E_2|_{\gamma(t)} T(t) \gamma t \gamma'  \theta(a_i) = \lim_{t \nearrow a_i}\theta(t) + \epsilon_i,  \theta(b) = \lim_{t \nearrow b}\theta(t) + \epsilon_k ","['differential-geometry', 'riemannian-geometry']"
68,Proving that Fubini metric is well-defined,Proving that Fubini metric is well-defined,,"Let $$\pi:S^{2n+1}\to S^{2n+1}/S^1=\mathbb{P}^n\mathbb{C}$$ be the Hopf fibration. I already know that $d_z\pi$ is a vector space isomorphism for every $z\in S^{2n+1}$ (when restricted to the orthogonal space to the orbit). We'd like to define a riemannian structure on $\mathbb{P}^n\mathbb{C}$ by push-forwarding the riemannian structure of $S^{2n+1}$ on each tangent space through $d_z \pi$ . Basically we want to define the Fubini metric as: $$\mathsf{fub}_{[z]}(u,v):=\mathsf{sph}_z((d_z\pi)^{-1}(u),(d_z\pi)^{-1}(v)),$$ where $\mathsf{sph}$ is the standard spheric metric. The only problem with this definition is that it may depend on the choice of the representative $z$ of the equivalence class $[z]$ . So let $e^{i\theta}z$ be a new representative: $$\mathsf{sph}_{e^{i\theta}z}((d_{e^{i\theta}z}\pi)^{-1}(u),(d_{e^{i\theta}z}\pi)^{-1}(v))=\langle (d_{e^{i\theta}z}\pi)^{-1}(u), d_{e^{i\theta}z}\pi)^{-1}(v) \rangle$$ where $\langle -,- \rangle$ is the standard euclidean inner product on $\mathbb{C}^{n}\cong \mathbb{R}^{2n}$ (the fixed isomorphism is $(x_1+iy_1,...,x_n+iy_n)\to (x_1,...,x_n,y_1,...,y_n)$ ). My problems would be over if I had an euclidean isometry $I:\mathbb{C}^n\to \mathbb{C}^n$ such that: $$(d_{e^{i\theta}z}\pi)^{-1}=I\circ (d_z\pi)^{-1}$$ so basically I'd like to prove that: $$(d_{e^{i\theta}z}\pi)^{-1}\circ (d_z\pi)$$ is an euclidean isometry. Is there an elegant way of doing this without dwelving too much into coordinates? Or in alternative, is there a better approach?","Let be the Hopf fibration. I already know that is a vector space isomorphism for every (when restricted to the orthogonal space to the orbit). We'd like to define a riemannian structure on by push-forwarding the riemannian structure of on each tangent space through . Basically we want to define the Fubini metric as: where is the standard spheric metric. The only problem with this definition is that it may depend on the choice of the representative of the equivalence class . So let be a new representative: where is the standard euclidean inner product on (the fixed isomorphism is ). My problems would be over if I had an euclidean isometry such that: so basically I'd like to prove that: is an euclidean isometry. Is there an elegant way of doing this without dwelving too much into coordinates? Or in alternative, is there a better approach?","\pi:S^{2n+1}\to S^{2n+1}/S^1=\mathbb{P}^n\mathbb{C} d_z\pi z\in S^{2n+1} \mathbb{P}^n\mathbb{C} S^{2n+1} d_z \pi \mathsf{fub}_{[z]}(u,v):=\mathsf{sph}_z((d_z\pi)^{-1}(u),(d_z\pi)^{-1}(v)), \mathsf{sph} z [z] e^{i\theta}z \mathsf{sph}_{e^{i\theta}z}((d_{e^{i\theta}z}\pi)^{-1}(u),(d_{e^{i\theta}z}\pi)^{-1}(v))=\langle (d_{e^{i\theta}z}\pi)^{-1}(u), d_{e^{i\theta}z}\pi)^{-1}(v) \rangle \langle -,- \rangle \mathbb{C}^{n}\cong \mathbb{R}^{2n} (x_1+iy_1,...,x_n+iy_n)\to (x_1,...,x_n,y_1,...,y_n) I:\mathbb{C}^n\to \mathbb{C}^n (d_{e^{i\theta}z}\pi)^{-1}=I\circ (d_z\pi)^{-1} (d_{e^{i\theta}z}\pi)^{-1}\circ (d_z\pi)","['differential-geometry', 'riemannian-geometry', 'complex-geometry', 'projective-space', 'kahler-manifolds']"
69,Counterexample to isomorphisms between tensor product of finite-dimensional vector spaces,Counterexample to isomorphisms between tensor product of finite-dimensional vector spaces,,"One of my homework problems required me to prove that If $V$ and $W$ are finite-dimensional vector spaces, then prove that \begin{equation*} V^{\ast} \otimes W^{\ast} \cong \mathcal{L}(V, W; \mathbb{R}) \cong \mathcal{L}(V \otimes W; \mathbb{R}) \end{equation*} and \begin{equation*} V^{\ast} \otimes W \cong \mathcal{L}(V; W), \end{equation*} where $\mathcal{L}(V_1, \ldots, V_n; W)$ means all multilinear maps $f \colon V_{1} \times \ldots \times V_{n} \rightarrow W$ . I was able to prove the above and it required a dimension argument, i. e. used the fact that the vector spaces are finite-dimensional. But then I was trying to come up with an infinite-dimensional example such that the above isomorphisms would fail but I can't seem to find one. I would assume that an example where the dimension of the dual space is larger should do the trick. Is there an obvious straight forward counterexample to the above isomorphisms that I am simply missing?","One of my homework problems required me to prove that If and are finite-dimensional vector spaces, then prove that and where means all multilinear maps . I was able to prove the above and it required a dimension argument, i. e. used the fact that the vector spaces are finite-dimensional. But then I was trying to come up with an infinite-dimensional example such that the above isomorphisms would fail but I can't seem to find one. I would assume that an example where the dimension of the dual space is larger should do the trick. Is there an obvious straight forward counterexample to the above isomorphisms that I am simply missing?","V W \begin{equation*}
V^{\ast} \otimes W^{\ast} \cong \mathcal{L}(V, W; \mathbb{R}) \cong \mathcal{L}(V \otimes W; \mathbb{R})
\end{equation*} \begin{equation*}
V^{\ast} \otimes W \cong \mathcal{L}(V; W),
\end{equation*} \mathcal{L}(V_1, \ldots, V_n; W) f \colon V_{1} \times \ldots \times V_{n} \rightarrow W","['linear-algebra', 'differential-geometry', 'vector-spaces']"
70,A question about Folland's definition of parametrization,A question about Folland's definition of parametrization,,"Here is Folland's definition of parametrization in his book Real analysis: modern techniques and their applications Chapter 11.2 Hausdorff measure. We now consider lower-dimensional sets in $\mathbb{R}^n$ . If $1 \le k \le n$ , a k-dimensional $C^1$ submanifold of $\mathbb{R}^n$ is a set $M\subset\mathbb{R}^n$ with the following property: For each $x \in M$ there exist a neighborhood $U$ of $x$ in $\mathbb{R}^n$ , an open set $V\subset\mathbb{R}^k$ , and an injective map $f:V\to U$ of class $C^1$ such that $f(V) = M\cap U$ and the differential $D_xf$ - i.e., the linear map from $\mathbb{R}^k$ to $\mathbb{R}^n$ whose matrix is $\left[\left(\frac{\partial f_i}{\partial x_j}\right)(x)\right]$ - is injective for each $x\in V$ . Such an $f$ is called a parametrization of $M \cap U$ . Compare this definition with the definition of smooth manifold, which requires the coordinate map is a local homeomorphism. I want to show in Folland's definition, the local inverse $f^{-1}:M\cap U\to V$ is continuous with respect to the subspace topology of $M\subset\mathbb{R}^n$ . But in Do Carmo's book Differential geometry of curves and surfaces , in the definition of regular surface, local homeomorphism is required. Thanks in advance if you can give me any hint (or counterexample)! Thanks to @Kenny Wong's answer (figure 8 space) below. We can conclude that, ""figure 8 space"" is a $1$ -dimensional $C^1$ manifold in Folland's definition, but in the mean time, it is not a topological manifold if it is equipped with subspace topology.","Here is Folland's definition of parametrization in his book Real analysis: modern techniques and their applications Chapter 11.2 Hausdorff measure. We now consider lower-dimensional sets in . If , a k-dimensional submanifold of is a set with the following property: For each there exist a neighborhood of in , an open set , and an injective map of class such that and the differential - i.e., the linear map from to whose matrix is - is injective for each . Such an is called a parametrization of . Compare this definition with the definition of smooth manifold, which requires the coordinate map is a local homeomorphism. I want to show in Folland's definition, the local inverse is continuous with respect to the subspace topology of . But in Do Carmo's book Differential geometry of curves and surfaces , in the definition of regular surface, local homeomorphism is required. Thanks in advance if you can give me any hint (or counterexample)! Thanks to @Kenny Wong's answer (figure 8 space) below. We can conclude that, ""figure 8 space"" is a -dimensional manifold in Folland's definition, but in the mean time, it is not a topological manifold if it is equipped with subspace topology.",\mathbb{R}^n 1 \le k \le n C^1 \mathbb{R}^n M\subset\mathbb{R}^n x \in M U x \mathbb{R}^n V\subset\mathbb{R}^k f:V\to U C^1 f(V) = M\cap U D_xf \mathbb{R}^k \mathbb{R}^n \left[\left(\frac{\partial f_i}{\partial x_j}\right)(x)\right] x\in V f M \cap U f^{-1}:M\cap U\to V M\subset\mathbb{R}^n 1 C^1,"['differential-geometry', 'manifolds']"
71,Isometric invariance of riemannian distance function,Isometric invariance of riemannian distance function,,"I need proof verification on the following theorem (Lee intro to Riemannian Manifolds Prop 2.51): Let $\varphi : (M,g) \longrightarrow (\tilde{M},\tilde{g})$ be an isometry between connected riemannian manifolds, then for all $x,y \in M$ we have $$d_g(x,y)=d_{\tilde{g}}(\varphi(x),\varphi(y)),$$ $d_g$ and $d_{\tilde{g}}$ being the Riemann distance function on $M$ and $\tilde{M}$ respectively. I start by proving that if $\varphi$ is a local isometry, then $$d_g(x,y)\geq d_{\tilde{g}}(\varphi(x),\varphi(y)) \quad \forall x,y\in M.$$ If then $\varphi$ is an isometry, then both $\varphi$ and its inverse are local isometry and I can conclude that equality holds. Let $x,y \in M$ and $\gamma : [a,b] \longrightarrow M$ be an admissible curve (piecewise regular) joining $x$ and $y$ in $M$ , and here I'm assuming $\gamma$ is injective, and let $\Gamma = \gamma([a,b])$ . Observe that $\Gamma$ is compact by continuity of $\gamma$ . Since $\varphi$ is a local isometry, for each $p\in \Gamma$ we find a neighborhood $U_p$ in $M$ such that $\varphi\big|_{U_p}$ is an isometry. Since $\{U_p\}_{p\in \Gamma}$ is an open cover of $\Gamma$ we find a finite subcover $\{U_0,\ldots,U_n\}$ . Define $\Gamma_i = U_i \cap \Gamma$ . What I have in mind here is that, after suitable reordering of the indexes and refinement, that $\Gamma_i$ is a partition of $\Gamma$ , meaning $[t_i,t_{i+1}]=\gamma^{-1}(\overline{\Gamma_i})$ and $a=t_0<\ldots<t_{n+1}=b$ is a partition of $[a,b]$ . I can now write \begin{align} L_g(\gamma)&=\sum_{i=0}^{n} L_g(\gamma|_{[t_i,t_{i+1}]})=\sum_{i=0}^{n} L_{\tilde{g}}((\varphi \circ \gamma)|_{[t_i,t_{i+1}]}) \tag{1}\\ &\geq \sum_{i=0}^{n} d_{\tilde{g}}(\varphi(x_i),\varphi(x_{i+1})) \geq d_{\tilde{g}}(\varphi(x),\varphi(y)) \tag{2} \end{align} where $x_i=\gamma(t_i), \quad i=1,\ldots,n$ . The first equality follows by definition of local isometry and the second inequality from the triangle inequality. Since $\gamma$ is arbitrary I conclude that $d_g(x,y)\geq d_{\tilde{g}}(\varphi(x),\varphi(y)).$ In the exercise Lee asks for a counterexample showing that local isometries don't preserve distances, I thought of $$\varphi : [0,2\pi] \longrightarrow \mathbb{S}^1, \quad \varphi(t)=(\cos t,\sin t),$$ which is clearly a local isometry but not injective.","I need proof verification on the following theorem (Lee intro to Riemannian Manifolds Prop 2.51): Let be an isometry between connected riemannian manifolds, then for all we have and being the Riemann distance function on and respectively. I start by proving that if is a local isometry, then If then is an isometry, then both and its inverse are local isometry and I can conclude that equality holds. Let and be an admissible curve (piecewise regular) joining and in , and here I'm assuming is injective, and let . Observe that is compact by continuity of . Since is a local isometry, for each we find a neighborhood in such that is an isometry. Since is an open cover of we find a finite subcover . Define . What I have in mind here is that, after suitable reordering of the indexes and refinement, that is a partition of , meaning and is a partition of . I can now write where . The first equality follows by definition of local isometry and the second inequality from the triangle inequality. Since is arbitrary I conclude that In the exercise Lee asks for a counterexample showing that local isometries don't preserve distances, I thought of which is clearly a local isometry but not injective.","\varphi : (M,g) \longrightarrow (\tilde{M},\tilde{g}) x,y \in M d_g(x,y)=d_{\tilde{g}}(\varphi(x),\varphi(y)), d_g d_{\tilde{g}} M \tilde{M} \varphi d_g(x,y)\geq d_{\tilde{g}}(\varphi(x),\varphi(y)) \quad \forall x,y\in M. \varphi \varphi x,y \in M \gamma : [a,b] \longrightarrow M x y M \gamma \Gamma = \gamma([a,b]) \Gamma \gamma \varphi p\in \Gamma U_p M \varphi\big|_{U_p} \{U_p\}_{p\in \Gamma} \Gamma \{U_0,\ldots,U_n\} \Gamma_i = U_i \cap \Gamma \Gamma_i \Gamma [t_i,t_{i+1}]=\gamma^{-1}(\overline{\Gamma_i}) a=t_0<\ldots<t_{n+1}=b [a,b] \begin{align}
L_g(\gamma)&=\sum_{i=0}^{n} L_g(\gamma|_{[t_i,t_{i+1}]})=\sum_{i=0}^{n} L_{\tilde{g}}((\varphi \circ \gamma)|_{[t_i,t_{i+1}]}) \tag{1}\\
&\geq \sum_{i=0}^{n} d_{\tilde{g}}(\varphi(x_i),\varphi(x_{i+1})) \geq d_{\tilde{g}}(\varphi(x),\varphi(y)) \tag{2}
\end{align} x_i=\gamma(t_i), \quad i=1,\ldots,n \gamma d_g(x,y)\geq d_{\tilde{g}}(\varphi(x),\varphi(y)). \varphi : [0,2\pi] \longrightarrow \mathbb{S}^1, \quad \varphi(t)=(\cos t,\sin t),","['differential-geometry', 'riemannian-geometry', 'isometry']"
72,How can I compute the differential of this function between surfaces $C$ and $G$?,How can I compute the differential of this function between surfaces  and ?,C G,"Let me consider the surface $S:=\{(x,y,z): x^2+y^2=1\}$ and $G:=\{(0,y,z): y,z\in \Bbb{R}\}$ and define $f:C\rightarrow G$ by $f(x,y,z)=(0,y,z)$ . Let us take the following two patches for $C$ and $G$ : $$\sigma_1(u,v)=(\cos(u),\sin(u), v)$$ and respectively $$\sigma_2(w,z)=(0,w,z)$$ Now I want to compute the differential at an arbitrary point $p\in C$ and express it in the base of the tangent plane. My idea was the following: Let me pick an arbitrary point $p\in C$ , then since $\sigma_1$ is a patch we know that $p=\sigma_1(u_0,v_0)$ for some $u_0,v_0$ . Then let us define $$\begin{align}\gamma(t)&=\sigma_1(u_0+t,v_0)\\\beta(t)&=\sigma_1(u_0,v_0+t)\end{align}$$ we see that $\gamma\perp \beta$ . At this point also remark that $\gamma'(0)=\sigma_{1,u}(u_0,v_0)$ and $\beta'(0)=\sigma_{1,v}(u_0,v_0)$ Then let us compute $$\begin{align}Df_p(\gamma'(0))&=(f\circ\gamma)'(0)\\&=\frac{d}{dt}~\left(f(\gamma(t))\right)\big|_{t=0}\\&=(0,\cos(u_0),0) \end{align}$$ and similarly $$\begin{align}Df_p(\beta'(0))&=(f\circ\beta)'(0)\\&=\frac{d}{dt}~\left(f(\beta(t))\right)\big|_{t=0}\\&=(0,0,1) \end{align}$$ so we have found two tangent vectors which are linealy independent. Now since the differential is linear we know that for a general curve $\alpha:[-1,1]\rightarrow C$ with $\alpha(0)=p$ and $\alpha'(0)=a\sigma_{1,u}(u_0,v_0)+b\sigma_{1,v} (u_0,v_0)$ we have $$\begin{align}Df_p(\alpha'(0))&=Df_p(a\cdot\sigma_{1,u}(u_0,v_0)+b\cdot\sigma_{1,v} (u_0,v_0))\\&=a\cdot Df_p(\sigma_{1,u}(u_0,v_0))+b\cdot Df_p(\sigma_{1,v}(u_0,v_0))\\&=a\cdot Df_p(\gamma'(0))+b\cdot Df_p(\beta'(0))\\&=a\cdot (0,\cos(u_0),0)^T+b\cdot (0,0,1)^T\\&=a\cdot \cos(u_0) \sigma_{2,w}+b\cdot \sigma_{2,v}\end{align}$$ Does this work or am I wrong?","Let me consider the surface and and define by . Let us take the following two patches for and : and respectively Now I want to compute the differential at an arbitrary point and express it in the base of the tangent plane. My idea was the following: Let me pick an arbitrary point , then since is a patch we know that for some . Then let us define we see that . At this point also remark that and Then let us compute and similarly so we have found two tangent vectors which are linealy independent. Now since the differential is linear we know that for a general curve with and we have Does this work or am I wrong?","S:=\{(x,y,z): x^2+y^2=1\} G:=\{(0,y,z): y,z\in \Bbb{R}\} f:C\rightarrow G f(x,y,z)=(0,y,z) C G \sigma_1(u,v)=(\cos(u),\sin(u), v) \sigma_2(w,z)=(0,w,z) p\in C p\in C \sigma_1 p=\sigma_1(u_0,v_0) u_0,v_0 \begin{align}\gamma(t)&=\sigma_1(u_0+t,v_0)\\\beta(t)&=\sigma_1(u_0,v_0+t)\end{align} \gamma\perp \beta \gamma'(0)=\sigma_{1,u}(u_0,v_0) \beta'(0)=\sigma_{1,v}(u_0,v_0) \begin{align}Df_p(\gamma'(0))&=(f\circ\gamma)'(0)\\&=\frac{d}{dt}~\left(f(\gamma(t))\right)\big|_{t=0}\\&=(0,\cos(u_0),0) \end{align} \begin{align}Df_p(\beta'(0))&=(f\circ\beta)'(0)\\&=\frac{d}{dt}~\left(f(\beta(t))\right)\big|_{t=0}\\&=(0,0,1) \end{align} \alpha:[-1,1]\rightarrow C \alpha(0)=p \alpha'(0)=a\sigma_{1,u}(u_0,v_0)+b\sigma_{1,v} (u_0,v_0) \begin{align}Df_p(\alpha'(0))&=Df_p(a\cdot\sigma_{1,u}(u_0,v_0)+b\cdot\sigma_{1,v} (u_0,v_0))\\&=a\cdot Df_p(\sigma_{1,u}(u_0,v_0))+b\cdot Df_p(\sigma_{1,v}(u_0,v_0))\\&=a\cdot Df_p(\gamma'(0))+b\cdot Df_p(\beta'(0))\\&=a\cdot (0,\cos(u_0),0)^T+b\cdot (0,0,1)^T\\&=a\cdot \cos(u_0) \sigma_{2,w}+b\cdot \sigma_{2,v}\end{align}","['real-analysis', 'differential-geometry', 'differential', 'tangent-spaces']"
73,Placement of critical points of Morse function on the sphere,Placement of critical points of Morse function on the sphere,,"On a similar note to my previous question , I am still thinking about functions on the sphere. Assume I have a $C^2$ function on the sphere $ f : S^{d-1} \mapsto \mathbb{R} $ which is Morse (i.e. all critical points are non-degenerate and thus all critical points are isolated) and assume that this function has at least one saddle point. Now, if we say $ d = 3 $ , if I am not mistaken, then we will actually have at least two saddles, since by the Poincare-Hopf theorem, the sum of the indices of any vector field must sum up to its Euler characteristic, which in this case is 2. Now, my question is, are there any restrictions regarding where these critical points are exactly on the sphere (when $ d = 3 $ , but also in general) ? Can they be arbitrarily close to each other? If there are some restrictions, what exactly is causing them? Again, apologies if my question is really basic, as I am absolutely unknowledgeable about differential topology. Any references or comments are appreciated!","On a similar note to my previous question , I am still thinking about functions on the sphere. Assume I have a function on the sphere which is Morse (i.e. all critical points are non-degenerate and thus all critical points are isolated) and assume that this function has at least one saddle point. Now, if we say , if I am not mistaken, then we will actually have at least two saddles, since by the Poincare-Hopf theorem, the sum of the indices of any vector field must sum up to its Euler characteristic, which in this case is 2. Now, my question is, are there any restrictions regarding where these critical points are exactly on the sphere (when , but also in general) ? Can they be arbitrarily close to each other? If there are some restrictions, what exactly is causing them? Again, apologies if my question is really basic, as I am absolutely unknowledgeable about differential topology. Any references or comments are appreciated!",C^2  f : S^{d-1} \mapsto \mathbb{R}   d = 3   d = 3 ,"['differential-geometry', 'differential-topology', 'smooth-manifolds', 'morse-theory']"
74,Can every Riemannian manifold be written as a statistical manifold?,Can every Riemannian manifold be written as a statistical manifold?,,"Given a sufficiently nice PDF $f:M\times \Theta \to \mathbb{R}$ where $M\subset \mathbb{R}^D$ and $\Theta\subset \mathbb{R}^p$ if the Fisher Information matrix $$I_{ij}(\vec{\theta})=\mathbb{E}\left[\left(\partial_{\theta_i} \log f(\vec{X}, \vec{\theta})\right) \cdot \left(\partial_{\theta_j} \log f(\vec{X}, \vec{\theta})\right)\bigg|\theta\right]$$ is positive definite (PD) then it forms a metric tensor in the variable $\theta$ and we can say that $(\Theta, I)$ is a manifold, called a statistical manifold. Thus, for nice enough PDFs, we can always find an associated a statistical manifold. Question: Given a Riemannian manifold $(\Theta,g)$ with metric tensor $g$ , can we find a PDF $f:M\times \Theta\to\mathbb{R}$ (for some $M$ ) such that $I(\vec{\theta})=g(\vec{\theta})$ ? If so, is such a PDF unique? In other words: is every metric tensor the Fisher information metric for some RV $X$ ? Another way to ask is whether every metric tensor $g$ on $\Theta$ can be written as $$g(\theta) = - \mathbb{E}\left[\nabla_\theta^2 \log f(\vec{X}, \vec{\theta})\bigg| \theta\right],$$ for some sufficiently nice $f$ ? Some thoughts: I would wager that the class of manifolds is larger than the class of statistical manifolds (those whose metric tensors are the FIM of some RV). But this is just a rough guess and I am not sure what tools to use to approach this question. If anybody has suggestions or hints I would gladly expend more effort on this and add some attempts.","Given a sufficiently nice PDF where and if the Fisher Information matrix is positive definite (PD) then it forms a metric tensor in the variable and we can say that is a manifold, called a statistical manifold. Thus, for nice enough PDFs, we can always find an associated a statistical manifold. Question: Given a Riemannian manifold with metric tensor , can we find a PDF (for some ) such that ? If so, is such a PDF unique? In other words: is every metric tensor the Fisher information metric for some RV ? Another way to ask is whether every metric tensor on can be written as for some sufficiently nice ? Some thoughts: I would wager that the class of manifolds is larger than the class of statistical manifolds (those whose metric tensors are the FIM of some RV). But this is just a rough guess and I am not sure what tools to use to approach this question. If anybody has suggestions or hints I would gladly expend more effort on this and add some attempts.","f:M\times \Theta \to \mathbb{R} M\subset \mathbb{R}^D \Theta\subset \mathbb{R}^p I_{ij}(\vec{\theta})=\mathbb{E}\left[\left(\partial_{\theta_i} \log f(\vec{X}, \vec{\theta})\right) \cdot \left(\partial_{\theta_j} \log f(\vec{X}, \vec{\theta})\right)\bigg|\theta\right] \theta (\Theta, I) (\Theta,g) g f:M\times \Theta\to\mathbb{R} M I(\vec{\theta})=g(\vec{\theta}) X g \Theta g(\theta) = - \mathbb{E}\left[\nabla_\theta^2 \log f(\vec{X}, \vec{\theta})\bigg| \theta\right], f","['differential-geometry', 'information-geometry']"
75,Can a vector field on a non-intersecting smooth curve assign multiple vectors to a point?,Can a vector field on a non-intersecting smooth curve assign multiple vectors to a point?,,"I'm reading Semi-Riemannian Geometry by Newman - currently about vector fields on curves. Let $\gamma(t)$ be an injective smooth curve from $(a,b)\subset \mathbb{R}$ to a smooth manifold $M$ . I know that for any $t_0\in(a,b)$ , $\frac{d\gamma}{dt}(t_0)$ is an operator (or a tangent vector in $T_{\gamma(t_0)}(M)$ ), where $$\frac{d\gamma}{dt}(t_0)(f)\equiv\frac{d(f\circ\gamma)}{dt}(t_0)$$ The book states that a vector field on $\gamma$ is defined as a map $J_{\gamma}$ that assigns each $t\in(a,b)$ to a vector $J_{\gamma}(t)$ in $T_{\gamma(t)}(M)$ . The set of smooth vector fields on $\gamma$ is denoted by $\mathfrak{X}_M(\gamma)$ . Then there is a theorem stating that $d\lambda/dt$ is a vector field in $\mathfrak{X}_M(\gamma)$ . I'm confused at this stage: corresponding to a particular curve $\gamma$ and at a particular point $p=\gamma(t_0)\in M$ , by definition we identify a single vector, right? Which is $d\gamma/dt$ evaluated at $t=t_0$ . So then we should have only one vector field on $\gamma$ ? Because if there were several, then we could identify at least two fields in $\mathfrak{X}_M(\gamma)$ that pick out different values at some $p$ lying in $\gamma$ 's image, which contradicts the previous paragraph. My understanding is: even if there are obviously several vectors in $T_{\gamma(t_0)}(M)$ , there's only one that is tangential to $\gamma$ . Would appreciate any help since I seem to be missing something. Maybe I'm wrong in my assumption that the vectors in the vector field need to be tangential to the curve?","I'm reading Semi-Riemannian Geometry by Newman - currently about vector fields on curves. Let be an injective smooth curve from to a smooth manifold . I know that for any , is an operator (or a tangent vector in ), where The book states that a vector field on is defined as a map that assigns each to a vector in . The set of smooth vector fields on is denoted by . Then there is a theorem stating that is a vector field in . I'm confused at this stage: corresponding to a particular curve and at a particular point , by definition we identify a single vector, right? Which is evaluated at . So then we should have only one vector field on ? Because if there were several, then we could identify at least two fields in that pick out different values at some lying in 's image, which contradicts the previous paragraph. My understanding is: even if there are obviously several vectors in , there's only one that is tangential to . Would appreciate any help since I seem to be missing something. Maybe I'm wrong in my assumption that the vectors in the vector field need to be tangential to the curve?","\gamma(t) (a,b)\subset \mathbb{R} M t_0\in(a,b) \frac{d\gamma}{dt}(t_0) T_{\gamma(t_0)}(M) \frac{d\gamma}{dt}(t_0)(f)\equiv\frac{d(f\circ\gamma)}{dt}(t_0) \gamma J_{\gamma} t\in(a,b) J_{\gamma}(t) T_{\gamma(t)}(M) \gamma \mathfrak{X}_M(\gamma) d\lambda/dt \mathfrak{X}_M(\gamma) \gamma p=\gamma(t_0)\in M d\gamma/dt t=t_0 \gamma \mathfrak{X}_M(\gamma) p \gamma T_{\gamma(t_0)}(M) \gamma",['differential-geometry']
76,"In a Lie group, is it true that $i_*v^L=-v^R$?","In a Lie group, is it true that ?",i_*v^L=-v^R,"If $G$ is a Lie group and $v\in T_eG$ , then I want to show that $$i_*v^L=-v^R$$ where $i$ is the inversion map $G\to G: g\mapsto g^{-1}$ and $v^L$ and $v^R$ are the left and right invariant vector fields, respectively, extending $v$ . I already have: $$(i_*)_g(v^L)_g=(i_*)_g((L_g)_*)_ev=((R_{g^{-1}})_*)_e(i_*)_e v=-(v^R)_{g^{-1}}$$ where I have used that $i(L_g(h))=R_{g^{-1}}(i(h))$ . Is it then true that $(v^R)_{g^{-1}}=(v^R)_g$ ? Any help would be welcome!","If is a Lie group and , then I want to show that where is the inversion map and and are the left and right invariant vector fields, respectively, extending . I already have: where I have used that . Is it then true that ? Any help would be welcome!",G v\in T_eG i_*v^L=-v^R i G\to G: g\mapsto g^{-1} v^L v^R v (i_*)_g(v^L)_g=(i_*)_g((L_g)_*)_ev=((R_{g^{-1}})_*)_e(i_*)_e v=-(v^R)_{g^{-1}} i(L_g(h))=R_{g^{-1}}(i(h)) (v^R)_{g^{-1}}=(v^R)_g,"['differential-geometry', 'lie-groups', 'lie-algebras']"
77,Geodesic curvature on hyperbolic manifold with boundary,Geodesic curvature on hyperbolic manifold with boundary,,Let $\Sigma$ be a compact oriented surface of genus $1$ having a single boundary component (i.e. $T^2$ minus an open disk) and let $g$ be a Riemannian metric on $\Sigma$ with constant Gaussian curvature $K=-1$ . Is it necessarily the case that $\int_{\partial \Sigma} k_gds \leq 0$ ? The Gauss-Bonnet theorem gives a lower bound $\int_{\partial \Sigma} k_gds  = \text{Vol}(\Sigma)-2\pi \geq -2\pi $ but I am wondering about an upper bound.,Let be a compact oriented surface of genus having a single boundary component (i.e. minus an open disk) and let be a Riemannian metric on with constant Gaussian curvature . Is it necessarily the case that ? The Gauss-Bonnet theorem gives a lower bound but I am wondering about an upper bound.,\Sigma 1 T^2 g \Sigma K=-1 \int_{\partial \Sigma} k_gds \leq 0 \int_{\partial \Sigma} k_gds  = \text{Vol}(\Sigma)-2\pi \geq -2\pi ,"['differential-geometry', 'riemannian-geometry', 'hyperbolic-geometry']"
78,Correspondence between $H^1_{dR}$ and harmonic 1-forms,Correspondence between  and harmonic 1-forms,H^1_{dR},"Let $S$ be a compact oriented Riemannian surface. And let $\mathcal{H}^1(S)$ be the space of the harmonic $1$ -forms of $S$ . I’m trying to prove that there is a linear isomorphism: $$H^1_{dR}(S)\to  \mathcal{H}^1(S).$$ By Hodge decomposition theorem, given a $1$ -form $\omega$ : $$[\omega]=[\omega’+d\eta+\delta \varphi]= [\omega’+\delta \varphi]$$ where $\omega’$ is harmomic. The proof will be basically complete if we manage to prove that $\delta \varphi=0$ . By Hodge decomposition theorem it suffices to prove that $d \delta \varphi=0$ but I don’t know how to prove this.","Let be a compact oriented Riemannian surface. And let be the space of the harmonic -forms of . I’m trying to prove that there is a linear isomorphism: By Hodge decomposition theorem, given a -form : where is harmomic. The proof will be basically complete if we manage to prove that . By Hodge decomposition theorem it suffices to prove that but I don’t know how to prove this.",S \mathcal{H}^1(S) 1 S H^1_{dR}(S)\to  \mathcal{H}^1(S). 1 \omega [\omega]=[\omega’+d\eta+\delta \varphi]= [\omega’+\delta \varphi] \omega’ \delta \varphi=0 d \delta \varphi=0,"['differential-geometry', 'riemannian-geometry', 'homology-cohomology', 'de-rham-cohomology', 'hodge-theory']"
79,Regarding a converse to Hopf's Umlaufsatz,Regarding a converse to Hopf's Umlaufsatz,,"I read in a differential geometry textbook that the total signed curvature of a closed plane curve is an integer multiple of $2\pi$ . In that same textbook, I also read about Hopf's Umlaufsatz, which states that the total signed curvature of a simple closed plane curve is either $2\pi$ or $-2\pi$ . Now, I am interested in a converse of the previous statement. If a closed plane curve has total signed curvature either $2\pi$ or $-2\pi$ , must that curve be a simple closed plane curve?","I read in a differential geometry textbook that the total signed curvature of a closed plane curve is an integer multiple of . In that same textbook, I also read about Hopf's Umlaufsatz, which states that the total signed curvature of a simple closed plane curve is either or . Now, I am interested in a converse of the previous statement. If a closed plane curve has total signed curvature either or , must that curve be a simple closed plane curve?",2\pi 2\pi -2\pi 2\pi -2\pi,['differential-geometry']
80,Expression of a metric tensor with constant curvature on surface,Expression of a metric tensor with constant curvature on surface,,"Consider the plane $\mathbb{R}^2$ together with a metric $\mathsf{g}$ . Choosing suitable local coordinates $(x_1,x_2)$ , $\mathsf{g}$ takes the form : $$ \mathsf{g}=r(x_1,x_2)\left((dx_1)^2+\epsilon (dx_2)^2\right),\quad r>0\quad\textrm{and}\quad\epsilon = \pm1. $$ Question : Assume that $\mathsf{g}$ has constant curvature $K$ , is there a closed form expression for $r(x,y)$ ? In particular in [1] (p. 331)  it is claimed $\mathsf{g}$ is isometrically equivalent to $$ \mathsf{g} =\frac{1}{\left(1+\frac{K}{4}\left((y_1)^2+\epsilon(y_2)^2\right)\right)^2}\left((dy_1)^2+\epsilon (dy_2)^2\right) $$ Is this true ? and if so can somebody provides a reference or a proof of that result ? My work : When trying to solve the question myself, I'm stuck with the following non-linear PDE (Liouville equation) $$ \frac{\partial ^2r}{\partial (x_1)^2}r + \epsilon\frac{\partial ^2r}{\partial (x_2)^2}r +\left(\frac{\partial r}{\partial x_1}\right)^2  - \epsilon\left(\frac{\partial r}{\partial x_2}\right)^2 = - K $$ [1] George R. Wilkens. “Centro-Affine Geometry in the Plane and Feedback Invariants of Two-State Scalar Control Systems”. Proceedings of Symposia in Pure Mathematics. Ed. by G. Ferreyra et al. Vol. 64. Amer- ican Mathematical Society, 1998. doi: 10.1090/pspum/064/1654544.","Consider the plane together with a metric . Choosing suitable local coordinates , takes the form : Question : Assume that has constant curvature , is there a closed form expression for ? In particular in [1] (p. 331)  it is claimed is isometrically equivalent to Is this true ? and if so can somebody provides a reference or a proof of that result ? My work : When trying to solve the question myself, I'm stuck with the following non-linear PDE (Liouville equation) [1] George R. Wilkens. “Centro-Affine Geometry in the Plane and Feedback Invariants of Two-State Scalar Control Systems”. Proceedings of Symposia in Pure Mathematics. Ed. by G. Ferreyra et al. Vol. 64. Amer- ican Mathematical Society, 1998. doi: 10.1090/pspum/064/1654544.","\mathbb{R}^2 \mathsf{g} (x_1,x_2) \mathsf{g} 
\mathsf{g}=r(x_1,x_2)\left((dx_1)^2+\epsilon (dx_2)^2\right),\quad r>0\quad\textrm{and}\quad\epsilon = \pm1.
 \mathsf{g} K r(x,y) \mathsf{g} 
\mathsf{g} =\frac{1}{\left(1+\frac{K}{4}\left((y_1)^2+\epsilon(y_2)^2\right)\right)^2}\left((dy_1)^2+\epsilon (dy_2)^2\right)
 
\frac{\partial ^2r}{\partial (x_1)^2}r + \epsilon\frac{\partial ^2r}{\partial (x_2)^2}r
+\left(\frac{\partial r}{\partial x_1}\right)^2  - \epsilon\left(\frac{\partial r}{\partial x_2}\right)^2
= - K
","['differential-geometry', 'partial-differential-equations', 'curvature']"
81,Why are the tangent spaces $T_pM$ and $T_qM$ disjoint for $p \neq q$?,Why are the tangent spaces  and  disjoint for ?,T_pM T_qM p \neq q,"Let $p, q \in M$ , where $M$ is some smooth manifold. Then, according to Tu's book Introduction to Manifolds the tangent spaces $T_pM$ and $T_qM$ are disjoint. Of course we define the tangent bundle $TM$ as a disjoint union, but Tu claims that even if we had not done this the tangent spaces $T_pM$ and $T_qM$ in $TM$ would still be disjoint. Why is this? Is it because if we view $T_pM$ as the set of all derivations mapping $C_p^\infty(M)$ (the algebra of germs of $C^\infty$ functions at $p$ ) into $\mathbb{R}$ then $T_pM$ and $T_qM$ have different domains, and so the functions are by definition different? I am hoping that there is a more geometrical reason for this.","Let , where is some smooth manifold. Then, according to Tu's book Introduction to Manifolds the tangent spaces and are disjoint. Of course we define the tangent bundle as a disjoint union, but Tu claims that even if we had not done this the tangent spaces and in would still be disjoint. Why is this? Is it because if we view as the set of all derivations mapping (the algebra of germs of functions at ) into then and have different domains, and so the functions are by definition different? I am hoping that there is a more geometrical reason for this.","p, q \in M M T_pM T_qM TM T_pM T_qM TM T_pM C_p^\infty(M) C^\infty p \mathbb{R} T_pM T_qM","['differential-geometry', 'smooth-manifolds', 'tangent-spaces', 'tangent-bundle']"
82,Show that the arc length is a limit of lengths of inscribed polygons.,Show that the arc length is a limit of lengths of inscribed polygons.,,"In Do Carmo's book (page 11), asked to find given $\epsilon>0$ , there exists $\delta>0$ such that if $|P|<\delta$ then $\left|\int_a^b |\alpha'(t)|~dt-l(\alpha,P)\right|<\epsilon$ . Here $P$ is a partition with $|P|=\max(t_i,t_{i-1}),i=1, \dots, n$ , $\alpha:I \to \mathbb{R}^3$ for an interval $I$ , $l(\alpha, P)= \sum_{i=1}^n|\alpha(t_i)-\alpha(t_{i-1})|$ . Any ideas to prove this?","In Do Carmo's book (page 11), asked to find given , there exists such that if then . Here is a partition with , for an interval , . Any ideas to prove this?","\epsilon>0 \delta>0 |P|<\delta \left|\int_a^b |\alpha'(t)|~dt-l(\alpha,P)\right|<\epsilon P |P|=\max(t_i,t_{i-1}),i=1, \dots, n \alpha:I \to \mathbb{R}^3 I l(\alpha, P)= \sum_{i=1}^n|\alpha(t_i)-\alpha(t_{i-1})|","['real-analysis', 'differential-geometry']"
83,Proof of Global Rank theorem on Lee's Smooth manifolds,Proof of Global Rank theorem on Lee's Smooth manifolds,,"There's a theorem named 'Global Rank theorem' in Lee's smooth manifold textbook which states that: Let $M$ and $N$ be smooth manifolds, and suppose $F:M\to N$ is a smooth map of constant rank. (1) If $F$ is surjective then it's a smooth submersion. (2) If $F$ is injective then it's a smooth immersion. (3) If $F$ is bijective then it's a diffeomorphism. The proof of (1) uses the Baire category theorem which is not quite intuitive to me. I wonder if this argument works: Since $F$ has a constant rank, say $r$ , if $p\in M$ then we can find a smooth chart $(U,\varphi)$ at $p$ and $(V,\psi)$ at $F(p)$ s.t. with respect to these coordinates, $F$ has a representation $\hat{F}(x_1,...,x_r,...,x_m)\to (x_1,...,x_r,0,...,0)$ where $m$ is the dimension of $M$ (and denote the dimension of $N$ by $n$ ). Since $\varphi,\psi$ are bijective, $\hat{F}$ should be surjective by assumption. Hence, $r = n$ . Hence, taking the differentials to $\varphi,\psi,\hat{F}$ , we conclude $dF_p$ is surjective. A similar argument shows (2). Does it work? Proof given in Lee's textbook.","There's a theorem named 'Global Rank theorem' in Lee's smooth manifold textbook which states that: Let and be smooth manifolds, and suppose is a smooth map of constant rank. (1) If is surjective then it's a smooth submersion. (2) If is injective then it's a smooth immersion. (3) If is bijective then it's a diffeomorphism. The proof of (1) uses the Baire category theorem which is not quite intuitive to me. I wonder if this argument works: Since has a constant rank, say , if then we can find a smooth chart at and at s.t. with respect to these coordinates, has a representation where is the dimension of (and denote the dimension of by ). Since are bijective, should be surjective by assumption. Hence, . Hence, taking the differentials to , we conclude is surjective. A similar argument shows (2). Does it work? Proof given in Lee's textbook.","M N F:M\to N F F F F r p\in M (U,\varphi) p (V,\psi) F(p) F \hat{F}(x_1,...,x_r,...,x_m)\to (x_1,...,x_r,0,...,0) m M N n \varphi,\psi \hat{F} r = n \varphi,\psi,\hat{F} dF_p","['differential-geometry', 'solution-verification', 'smooth-manifolds']"
84,Example for which the Donaldson-Futaki invariant is $0$,Example for which the Donaldson-Futaki invariant is,0,"Background: Let $X$ be a Fano variety, and consider a test configuration for $(X,-K_X)$ , tha is a pair $(\mathcal{X}, \mathcal{L})$ where: $\mathcal{X}$ is a normal variety, endowed with a $\mathbb{C}^*$ -action; there is a flat $\mathbb{C}^*$ -equivariant morphism $f:X\to \mathbb{P}^1$ , with $\mathbb{C}^*$ acts on $\mathbb{P}^1$ as $[tx:y]$ ; $\mathcal{L}$ is an $f$ -ample line bundle on $\mathcal{X}$ , and there is a $\mathbb{C}^*$ -equivariant isomorphism $$(\mathcal{X}\setminus \mathcal{X}_0, \mathcal{L}|_{\mathcal{X}\setminus \mathcal{X}_0})\simeq (X\times (\mathbb{P}^1\setminus 0), \text{pr}_1^\star(-K_X)),$$ where $0=[0:1]$ and $\text{pr}_1 : X\times \mathbb{P}^1\to X$ . With this setting, one defines the Donaldson-Futaki invariant as $$DF(\mathcal{X},\mathcal{L})=\frac{1}{(-K_X)^n}(\mathcal{L}^n\cdot K_{\mathcal{X}|\mathbb{P}^1}+\frac{n}{n+1}\mathcal{L}^{n+1}),$$ with $n=\dim X$ , and one says that the Fano variety is semistable if for every test configuration one has $DF(\mathcal{X};\mathcal{L})\geq 0$ ; polystable if it is semistable, and $DF(\mathcal{X},\mathcal{L})=0 \iff (\mathcal{X},\mathcal{L})$ is of product type, i.e. it holds $\mathcal{X}\setminus \mathcal{X}_\infty\simeq X\times (\mathbb{P}^1\setminus \infty)$ , with $\infty=[1:0]$ . Question: From this definition it seems easy to see that, if a test configuration is of product type, then its Donaldson-Futaki invariant is $0$ . However, I am having troubles proving it, or at least even convincing myself it should be true. Seeing the expression, $DF=0$ should correspond to having $\mathcal{L}=-K_{\mathcal{X}\mid \mathbb{P}^1}$ , but still I don't see why we have the $\frac{n}{n+1}$ factor. Moreover, so far most of the proofs of stability of Fano varieties I've seen use different approachs, instead of computing the DF-invariant. Any help would be much appreciated!","Background: Let be a Fano variety, and consider a test configuration for , tha is a pair where: is a normal variety, endowed with a -action; there is a flat -equivariant morphism , with acts on as ; is an -ample line bundle on , and there is a -equivariant isomorphism where and . With this setting, one defines the Donaldson-Futaki invariant as with , and one says that the Fano variety is semistable if for every test configuration one has ; polystable if it is semistable, and is of product type, i.e. it holds , with . Question: From this definition it seems easy to see that, if a test configuration is of product type, then its Donaldson-Futaki invariant is . However, I am having troubles proving it, or at least even convincing myself it should be true. Seeing the expression, should correspond to having , but still I don't see why we have the factor. Moreover, so far most of the proofs of stability of Fano varieties I've seen use different approachs, instead of computing the DF-invariant. Any help would be much appreciated!","X (X,-K_X) (\mathcal{X}, \mathcal{L}) \mathcal{X} \mathbb{C}^* \mathbb{C}^* f:X\to \mathbb{P}^1 \mathbb{C}^* \mathbb{P}^1 [tx:y] \mathcal{L} f \mathcal{X} \mathbb{C}^* (\mathcal{X}\setminus \mathcal{X}_0, \mathcal{L}|_{\mathcal{X}\setminus \mathcal{X}_0})\simeq (X\times (\mathbb{P}^1\setminus 0), \text{pr}_1^\star(-K_X)), 0=[0:1] \text{pr}_1 : X\times \mathbb{P}^1\to X DF(\mathcal{X},\mathcal{L})=\frac{1}{(-K_X)^n}(\mathcal{L}^n\cdot K_{\mathcal{X}|\mathbb{P}^1}+\frac{n}{n+1}\mathcal{L}^{n+1}), n=\dim X DF(\mathcal{X};\mathcal{L})\geq 0 DF(\mathcal{X},\mathcal{L})=0 \iff (\mathcal{X},\mathcal{L}) \mathcal{X}\setminus \mathcal{X}_\infty\simeq X\times (\mathbb{P}^1\setminus \infty) \infty=[1:0] 0 DF=0 \mathcal{L}=-K_{\mathcal{X}\mid \mathbb{P}^1} \frac{n}{n+1}","['differential-geometry', 'algebraic-geometry', 'complex-geometry', 'birational-geometry']"
85,Showing that $\mathbb{RP}^n$ is a manifold,Showing that  is a manifold,\mathbb{RP}^n,"I would like to show that the real projective space $\mathbb{RP}^n$ is a manifold. This seems like a standard problem, and the explanation can be found in Lee's book on smooth manifolds as well as numerous proofs being available on this site. For the most part I understand the proof, but I am missing some intuition. The idea, as I understand it, is to construct coordinate domains $U_i$ whose union cover our set, where $U_i = \pi(\tilde{U}_i)$ , $\pi: \mathbb{R}^{n+1}\backslash\{0\} \rightarrow \mathbb{RP}^n$ is the quotient map, and each $\tilde{U_i} \subset \mathbb{R}^{n+1}$ is defined to be the set of all points such that $x_i \neq 0$ . The union of all such $U_i$ clearly cover $\mathbb{RP}^n$ , so all that is left is to construct the coordinate maps $\varphi_i$ such that $\varphi_i(U_i) \subset \mathbb{R}^n$ and $\varphi_i$ is a homeomorphism. Lee defines this map as $$\varphi_i[x^1,\ldots, x^{n+1}] = \Big(\frac{x^1}{x^i}, \ldots, \frac{x^{i-1}}{x^i}, \frac{x^{i+1}}{x^i}, \ldots, \frac{x^{n+1}}{x^i}\Big)$$ and so the corresponding inverse is given by $$\varphi_i^{-1}(u_1,u_2,.....,u_n)=[u_1,u_2,.....,u_{i-1},1,u_{i+1},.....,u_n].$$ What is the motivation behind $\varphi_i$ (and its inverse), and why is the coordinate $x^i$ omitted in its image? From what I have gathered it has to do with some kind of slope of a hyperplane, but I do not see this or why we are scaling by $x^i$ . Also, why is the inverse necessarily continuous? My guess is that it has to do with some property of quotient maps, but I am not sure. As a side question, is the argument of $\varphi_i$ a single equivalence class and each $x^i$ is a component of $[x]$ ? If so, how come there are $n+1$ entries and not $n$ ?","I would like to show that the real projective space is a manifold. This seems like a standard problem, and the explanation can be found in Lee's book on smooth manifolds as well as numerous proofs being available on this site. For the most part I understand the proof, but I am missing some intuition. The idea, as I understand it, is to construct coordinate domains whose union cover our set, where , is the quotient map, and each is defined to be the set of all points such that . The union of all such clearly cover , so all that is left is to construct the coordinate maps such that and is a homeomorphism. Lee defines this map as and so the corresponding inverse is given by What is the motivation behind (and its inverse), and why is the coordinate omitted in its image? From what I have gathered it has to do with some kind of slope of a hyperplane, but I do not see this or why we are scaling by . Also, why is the inverse necessarily continuous? My guess is that it has to do with some property of quotient maps, but I am not sure. As a side question, is the argument of a single equivalence class and each is a component of ? If so, how come there are entries and not ?","\mathbb{RP}^n U_i U_i = \pi(\tilde{U}_i) \pi: \mathbb{R}^{n+1}\backslash\{0\} \rightarrow \mathbb{RP}^n \tilde{U_i} \subset \mathbb{R}^{n+1} x_i \neq 0 U_i \mathbb{RP}^n \varphi_i \varphi_i(U_i) \subset \mathbb{R}^n \varphi_i \varphi_i[x^1,\ldots, x^{n+1}] = \Big(\frac{x^1}{x^i}, \ldots, \frac{x^{i-1}}{x^i}, \frac{x^{i+1}}{x^i}, \ldots, \frac{x^{n+1}}{x^i}\Big) \varphi_i^{-1}(u_1,u_2,.....,u_n)=[u_1,u_2,.....,u_{i-1},1,u_{i+1},.....,u_n]. \varphi_i x^i x^i \varphi_i x^i [x] n+1 n","['general-topology', 'differential-geometry', 'manifolds', 'smooth-manifolds']"
86,Is the cohomology of the dual operator of exterior differential operator isomorphic to homology?,Is the cohomology of the dual operator of exterior differential operator isomorphic to homology?,,"The dual operator of exterior derivative $d$ is given by $\delta = -*  d  *$ , where $*$ is the Hodge operator. On the other hand, there is also a dual operator given by $\int _{\partial C} \omega = \int_C d\omega. $ These two operator $\delta, \partial$ make two homologies. Are these homogologies ismorphic? Is there any reference or book explaining about this topic? Edit: Using the Hodge operator as a chain map, we  get the following $$H^k_{DR}( \Omega^\bullet	,d) = H_k(\Omega^{n-\bullet}, \delta)  \cdots(1).$$ $$\begin{array} A0  & \stackrel{d}{\longrightarrow}  & \mathbb{R}   & \stackrel{d}{\longrightarrow} & \Omega^0   & \stackrel{d}{\longrightarrow} &\Omega^1  & \stackrel{d}{\longrightarrow}   &\Omega^2  &\stackrel{d}{\longrightarrow}\\ \downarrow{*} & & \downarrow{*}&&\downarrow{*} && \downarrow{*}&&   \downarrow{*}&&\\ 0  & \stackrel{\delta}{\longrightarrow}  & \mathbb{R}   & \stackrel{\delta}{\longrightarrow} & \Omega^{n-0}   & \stackrel{\delta}{\longrightarrow} &\Omega^{n-1}  & \stackrel{\delta}{\longrightarrow}   &\Omega^{n-2}  &\stackrel{\delta}{\longrightarrow}\\ \end{array} $$ Furthermore, now $M$ is closed manifold,  so by the Poincare duality, it follows that $$H^k_{DR}( \Omega^\bullet	,d) = H_{n-k}(M, \mathbb{R}) \cdots(2)$$ . Combining (1) and (2),  the homology of the operator $\delta = -*d*$ is isomorphic to the singular homology; $ H_k(\Omega^{n-\bullet}, \delta) =  H_{n-k}(M, \mathbb{R}) $ . I am not sure about  the universal coefficients theorem ... I neet to learn about  the universal coefficients theorem.","The dual operator of exterior derivative is given by , where is the Hodge operator. On the other hand, there is also a dual operator given by These two operator make two homologies. Are these homogologies ismorphic? Is there any reference or book explaining about this topic? Edit: Using the Hodge operator as a chain map, we  get the following Furthermore, now is closed manifold,  so by the Poincare duality, it follows that . Combining (1) and (2),  the homology of the operator is isomorphic to the singular homology; . I am not sure about  the universal coefficients theorem ... I neet to learn about  the universal coefficients theorem.","d \delta = -*  d  * * \int _{\partial C} \omega = \int_C d\omega.  \delta, \partial H^k_{DR}( \Omega^\bullet	,d) = H_k(\Omega^{n-\bullet}, \delta)  \cdots(1). \begin{array}
A0
 & \stackrel{d}{\longrightarrow} 
& \mathbb{R} 
 & \stackrel{d}{\longrightarrow}
& \Omega^0
  & \stackrel{d}{\longrightarrow}
&\Omega^1
 & \stackrel{d}{\longrightarrow}
  &\Omega^2 
&\stackrel{d}{\longrightarrow}\\
\downarrow{*} & & \downarrow{*}&&\downarrow{*} && \downarrow{*}&&   \downarrow{*}&&\\
0
 & \stackrel{\delta}{\longrightarrow} 
& \mathbb{R} 
 & \stackrel{\delta}{\longrightarrow}
& \Omega^{n-0}
  & \stackrel{\delta}{\longrightarrow}
&\Omega^{n-1}
 & \stackrel{\delta}{\longrightarrow}
  &\Omega^{n-2} 
&\stackrel{\delta}{\longrightarrow}\\
\end{array}
 M H^k_{DR}( \Omega^\bullet	,d) = H_{n-k}(M, \mathbb{R}) \cdots(2) \delta = -*d*  H_k(\Omega^{n-\bullet}, \delta) =  H_{n-k}(M, \mathbb{R}) ","['functional-analysis', 'differential-geometry']"
87,How does the pushforward of the inverse metric relate to the inverse of the pullback metric for an embedding?,How does the pushforward of the inverse metric relate to the inverse of the pullback metric for an embedding?,,"I am learning some geometry and stumbled upon these two ways to obtain a different metric. For a smooth manifold embedding $\phi:N\to M$ suppose a non-degenerate, covariant metric $g_{ij}$ on the tangent space $TM$ which induces a pullback metric $g'_{i'j'}$ on the tangent space $TN$ by $\quad g'_{i'j'}=\dfrac{\partial \phi^{i}}{\partial x^{i'}}\,g_{ij}\,\dfrac{\partial \phi^{j}}{\partial x^{j'}}=[\mathrm J_\phi]^{i}_{i'}\,g_{ij}\,[\mathrm J_\phi]^{j}_{j'}\quad$ (components) $\quad [g']=[\mathrm J_\phi]^T\,[g]\,[\mathrm J_\phi]\quad$ (matrix) $\quad g'=\phi^*\,g\quad$ (geometric) where $\mathrm J_\phi$ is the Jacobian of $\phi$ . On $T^*M$ we have that $g_{ij}$ also induces a contravariant inverse metric $h^{kl}$ via $\quad g_{ij}\,h^{jl}=\delta_i^l\quad$ (components) $\quad [g][h]=[h][g]=\mathrm I\quad$ (matrix) $\quad [h] = [g]^{-1}\quad$ (matrix inverse) Further, on the codomain $\phi(N)$ of $\phi$ , this inverse metric $h$ can be pushed forward along $\phi^{-1}$ by $\quad h'^{k'l'}=\dfrac{\partial (\phi^{-1})^{k'}}{\partial x^{k}}\,h^{kl}\,\dfrac{\partial (\phi^{-1})^{l'}}{\partial x^{l}}=[\mathrm J_{\phi^{-1}}]^{k'}_{k}\,h^{kl}\,[\mathrm J_{\phi^{-1}}]^{l'}_{l}\quad$ (components) $\quad [h']=[\mathrm J_{\phi^{-1}}]\,[h]\,[\mathrm J_{\phi^{-1}}]^T\quad$ (matrix) $\quad h'={\phi^{-1}}_*\,h\quad$ (geometric) where the Jacobian $\mathrm J_{\phi^{-1}}$ can be obtained as the Moore-Penrose pseudoinverse ${\mathrm J_{\phi^{-1}}=(\mathrm J_{\phi}^T\,\mathrm J_{\phi}^{\vphantom{T}})^{-1}\,\mathrm J_{\phi}^T}$ . ( Update: here lies the mistake! As pointed out in the comments, this definition of the Moore-Penrose pseudoinverse does an orthogonal projection w.r.t. the standard metric and not w.r.t. the metric $g$ .) Now, it seems that for embeddings, this pushforward inverse metric $h'$ and the matrix inverse of the pullback metric $g'$ generally do not agree (given I have made no mistakes in my trials where they do agree for diffeomorphisms): $\quad g'_{i'j'}\,h'^{j'l'}\neq\delta_{i'}^{l'}\quad$ (components) $\quad [h'] \neq [g']^{-1}\quad$ (matrix) $\quad {\phi^{-1}}_*(g^{-1})\neq(\phi^*\,g)^{-1}\quad$ (geometric) Q: Which metric, the pushforward of the inverse metric or the inverse of the pullback metric is ""used"" on $T^*N$ ? (...and what is it used for in physics?) On one hand, the pushforward of the inverse metric ${\phi^{-1}}_*\,h$ preserves inner products on covectors from the reachable subspace ${\{\omega\in T_{\phi(p)}^* M\,|\,\phi^{-1\,*}(\phi^*\,(\omega))=\omega\}}$ . When $\mathrm P_\phi$ is a projection onto that subspace $\quad [\mathrm P_\phi]^i_k=[\mathrm J_{\phi^{\vphantom{-1}}}]^i_{i'}\; [\mathrm J_{\phi^{{-1}}}]^{i'}_k\quad$ (components) $\quad [\mathrm P_\phi]=[\mathrm J_{\phi^{\vphantom{-1}}}]\; [\mathrm J_{\phi^{{-1}}}]\quad$ (matrix) $\quad \mathrm P_\phi(\omega)=\phi^{-1\,*}(\phi^*\,(\omega))\quad$ (geometric) then we obtain $\quad \hphantom{={}}{\langle\, \mathrm P_\phi(\omega)\,,\,\mathrm P_\phi(\mu)\,\rangle}_h$ $\quad =(\omega_i\;[\mathrm P_\phi]^i_k)\;h^{kl}\;([\mathrm P_{\phi}]^{j}_l\;\mu_j)$ $\quad =(\omega_i\;[\mathrm J_{\phi^{\vphantom{-1}}}]^i_{i'}\; [\mathrm J_{\phi^{{-1}}}]^{i'}_k)\;h^{kl}\;([\mathrm J_{\phi^{{-1}}}]^{j'}_l\;[\mathrm J_{\phi^{\vphantom{-1}}}]^j_{j'}\;\mu_j)$ $\quad =(\omega_i\;[\mathrm J_{\phi^{\vphantom{-1}}}]^i_{i'})\; ([\mathrm J_{\phi^{{-1}}}]^{i'}_k\;h^{kl}\;[\mathrm J_{\phi^{{-1}}}]^{j'}_l)\;([\mathrm J_{\phi^{\vphantom{-1}}}]^j_{j'}\;\mu_j)$ $\quad =(\phi^*\,\omega)_{i'}\;({\phi^{-1}}_*\,h)^{i'j'}\;(\phi^*\,\mu)_{j'}$ $\quad ={\langle\,\phi^*(\omega)\,,\,\phi^*(\mu)\,\rangle}_{{\phi^{-1}}_*\,h}\quad$ (desirable property 1) On the other hand, the inverse of the pullback metric $(\phi^*g)^{-1}$ or ${g'}^{i',j'}$ can be used for raising and lowering indices in invariant expressions $\quad\langle u,v\rangle_{g'} =u^{i'}\,g'_{i'j'}\,v^{j'}=u_{k'}\,g'^{k',i'}\,g'_{i'j'}\,v^{j'}=u_{k'}\,v^{j'}\quad$ (desirable property 2) I think that both properties, preservation of covector inner products and preservation of invariants when raising and lowering indices are desirable. So currently my questions are Is there any advice how to deal with these two different inverse metrics on $T^*N$ ? E.g., do we just have both of them and use one for inner products and the other one for raising and lowering? Which one is used to define the hodge operator on $T^*N$ then? Where else is preservation of the covector inner product necessary? Edit: I have previously displayed the pushforward along $\phi^{-1}$ wrong, it is updated to be ${\phi^{-1}}_*\,h$","I am learning some geometry and stumbled upon these two ways to obtain a different metric. For a smooth manifold embedding suppose a non-degenerate, covariant metric on the tangent space which induces a pullback metric on the tangent space by (components) (matrix) (geometric) where is the Jacobian of . On we have that also induces a contravariant inverse metric via (components) (matrix) (matrix inverse) Further, on the codomain of , this inverse metric can be pushed forward along by (components) (matrix) (geometric) where the Jacobian can be obtained as the Moore-Penrose pseudoinverse . ( Update: here lies the mistake! As pointed out in the comments, this definition of the Moore-Penrose pseudoinverse does an orthogonal projection w.r.t. the standard metric and not w.r.t. the metric .) Now, it seems that for embeddings, this pushforward inverse metric and the matrix inverse of the pullback metric generally do not agree (given I have made no mistakes in my trials where they do agree for diffeomorphisms): (components) (matrix) (geometric) Q: Which metric, the pushforward of the inverse metric or the inverse of the pullback metric is ""used"" on ? (...and what is it used for in physics?) On one hand, the pushforward of the inverse metric preserves inner products on covectors from the reachable subspace . When is a projection onto that subspace (components) (matrix) (geometric) then we obtain (desirable property 1) On the other hand, the inverse of the pullback metric or can be used for raising and lowering indices in invariant expressions (desirable property 2) I think that both properties, preservation of covector inner products and preservation of invariants when raising and lowering indices are desirable. So currently my questions are Is there any advice how to deal with these two different inverse metrics on ? E.g., do we just have both of them and use one for inner products and the other one for raising and lowering? Which one is used to define the hodge operator on then? Where else is preservation of the covector inner product necessary? Edit: I have previously displayed the pushforward along wrong, it is updated to be","\phi:N\to M g_{ij} TM g'_{i'j'} TN \quad g'_{i'j'}=\dfrac{\partial \phi^{i}}{\partial x^{i'}}\,g_{ij}\,\dfrac{\partial \phi^{j}}{\partial x^{j'}}=[\mathrm J_\phi]^{i}_{i'}\,g_{ij}\,[\mathrm J_\phi]^{j}_{j'}\quad \quad [g']=[\mathrm J_\phi]^T\,[g]\,[\mathrm J_\phi]\quad \quad g'=\phi^*\,g\quad \mathrm J_\phi \phi T^*M g_{ij} h^{kl} \quad g_{ij}\,h^{jl}=\delta_i^l\quad \quad [g][h]=[h][g]=\mathrm I\quad \quad [h] = [g]^{-1}\quad \phi(N) \phi h \phi^{-1} \quad h'^{k'l'}=\dfrac{\partial (\phi^{-1})^{k'}}{\partial x^{k}}\,h^{kl}\,\dfrac{\partial (\phi^{-1})^{l'}}{\partial x^{l}}=[\mathrm J_{\phi^{-1}}]^{k'}_{k}\,h^{kl}\,[\mathrm J_{\phi^{-1}}]^{l'}_{l}\quad \quad [h']=[\mathrm J_{\phi^{-1}}]\,[h]\,[\mathrm J_{\phi^{-1}}]^T\quad \quad h'={\phi^{-1}}_*\,h\quad \mathrm J_{\phi^{-1}} {\mathrm J_{\phi^{-1}}=(\mathrm J_{\phi}^T\,\mathrm J_{\phi}^{\vphantom{T}})^{-1}\,\mathrm J_{\phi}^T} g h' g' \quad g'_{i'j'}\,h'^{j'l'}\neq\delta_{i'}^{l'}\quad \quad [h'] \neq [g']^{-1}\quad \quad {\phi^{-1}}_*(g^{-1})\neq(\phi^*\,g)^{-1}\quad T^*N {\phi^{-1}}_*\,h {\{\omega\in T_{\phi(p)}^* M\,|\,\phi^{-1\,*}(\phi^*\,(\omega))=\omega\}} \mathrm P_\phi \quad [\mathrm P_\phi]^i_k=[\mathrm J_{\phi^{\vphantom{-1}}}]^i_{i'}\; [\mathrm J_{\phi^{{-1}}}]^{i'}_k\quad \quad [\mathrm P_\phi]=[\mathrm J_{\phi^{\vphantom{-1}}}]\; [\mathrm J_{\phi^{{-1}}}]\quad \quad \mathrm P_\phi(\omega)=\phi^{-1\,*}(\phi^*\,(\omega))\quad \quad \hphantom{={}}{\langle\, \mathrm P_\phi(\omega)\,,\,\mathrm P_\phi(\mu)\,\rangle}_h \quad =(\omega_i\;[\mathrm P_\phi]^i_k)\;h^{kl}\;([\mathrm P_{\phi}]^{j}_l\;\mu_j) \quad =(\omega_i\;[\mathrm J_{\phi^{\vphantom{-1}}}]^i_{i'}\; [\mathrm J_{\phi^{{-1}}}]^{i'}_k)\;h^{kl}\;([\mathrm J_{\phi^{{-1}}}]^{j'}_l\;[\mathrm J_{\phi^{\vphantom{-1}}}]^j_{j'}\;\mu_j) \quad =(\omega_i\;[\mathrm J_{\phi^{\vphantom{-1}}}]^i_{i'})\; ([\mathrm J_{\phi^{{-1}}}]^{i'}_k\;h^{kl}\;[\mathrm J_{\phi^{{-1}}}]^{j'}_l)\;([\mathrm J_{\phi^{\vphantom{-1}}}]^j_{j'}\;\mu_j) \quad =(\phi^*\,\omega)_{i'}\;({\phi^{-1}}_*\,h)^{i'j'}\;(\phi^*\,\mu)_{j'} \quad ={\langle\,\phi^*(\omega)\,,\,\phi^*(\mu)\,\rangle}_{{\phi^{-1}}_*\,h}\quad (\phi^*g)^{-1} {g'}^{i',j'} \quad\langle u,v\rangle_{g'} =u^{i'}\,g'_{i'j'}\,v^{j'}=u_{k'}\,g'^{k',i'}\,g'_{i'j'}\,v^{j'}=u_{k'}\,v^{j'}\quad T^*N T^*N \phi^{-1} {\phi^{-1}}_*\,h","['differential-geometry', 'physics', 'inner-products', 'pullback', 'pushforward']"
88,Show that the projection map of $S^n_+$ is orientation preserving $\iff$ $n$ is even,Show that the projection map of  is orientation preserving   is even,S^n_+ \iff n,"This is problem $22.10(b)$ from Introduction to Manifolds (Tu). This question has been posed here and here , but no proof has been given. The text provided the answer to $22.10(a)$ , which is $(-1)^n dx^1 \wedge \ldots \wedge dx^n$ . We must first show that $\pi$ is a diffeomorphism. I get stuck here. I want to show that $\sigma : U \rightarrow \mathbb{R}^n \times \{0\}$ , defined by $$\sigma(x^1, \ldots, x^{n+1}) = (x^1, \ldots, x^n, 0), $$ is a diffeomorphism. But the Jacobian is clearly not invertible. If I could show that $\sigma$ was a diffeomorphism, then I would finish the proof as follows. Since $\mathbb{R}^n\times \{0\} \simeq \mathbb{R}^n$ , we now only consider the latter. A nowhere-vanishing form on $\pi(U) \subset \mathbb{R}^n$ is $dx^1 \wedge \ldots \wedge dx^n$ , and its pullback by $\pi$ is the same expression. Therefore, $\pi$ is orientation preserving $\iff$ $n$ is even. $\square$","This is problem from Introduction to Manifolds (Tu). This question has been posed here and here , but no proof has been given. The text provided the answer to , which is . We must first show that is a diffeomorphism. I get stuck here. I want to show that , defined by is a diffeomorphism. But the Jacobian is clearly not invertible. If I could show that was a diffeomorphism, then I would finish the proof as follows. Since , we now only consider the latter. A nowhere-vanishing form on is , and its pullback by is the same expression. Therefore, is orientation preserving is even.","22.10(b) 22.10(a) (-1)^n dx^1 \wedge \ldots \wedge dx^n \pi \sigma : U \rightarrow \mathbb{R}^n \times \{0\} \sigma(x^1, \ldots, x^{n+1}) = (x^1, \ldots, x^n, 0),  \sigma \mathbb{R}^n\times \{0\} \simeq \mathbb{R}^n \pi(U) \subset \mathbb{R}^n dx^1 \wedge \ldots \wedge dx^n \pi \pi \iff n \square","['differential-geometry', 'smooth-manifolds']"
89,Lines with irrational slope in a torus,Lines with irrational slope in a torus,,"I'm trying understand one point about Example 15.9 in the Introduction to Manfolds by Tu (p. 167). I'll reproduce the example here. See this post , which addressed a separate question I had. Example 15.9 ( Lines with irrational slope in a torus ). Let $G$ be the torus $\mathbb{R}^2/\mathbb{Z}^2$ and $L$ a line through the origin in $\mathbb{R}^2$ . The torus can also be represented by the unit square with the opposite edges identified. The image $H$ of $L$ under the projection $\pi:\mathbb{R}^2\longrightarrow\mathbb{R}^2/\mathbb{Z}^2$ is a closed curve if and only if the line $L$ goes through another lattice point, say $(m,n)\in\mathbb{Z}^2$ . This is the case if and only if the slope of $L$ is $n/m$ , a rational number or $\infty$ ; then $H$ is the image of finitely many line segments on the unit square. It is a closed curve diffeomorphic to a circle and is a regular submanifold of $\mathbb{R}^2/\mathbb{Z}^2$ (Figure 15.1). If the slope of L is irrational, then its image H on the torus will never close up. In this case the restriction to L of the projection map, $f := \pi\big|_L : L \rightarrow \mathbb{R}^2/\mathbb{Z}^2$ , is a one-to-one immersion . We give H the topology and manifold structure induced from f. I don't understand why $f$ is an immersion. How would I prove this? Why is the subspace topology of H in $\mathbb{R}^2/\mathbb{Z}^2$ a strict subset of the  topology on $H$ induced from $ f : L \xrightarrow{\sim} H$ ? For the induced topology, I understand that a basic open set of H is the image under $f$ of an open set in $L$ . I also understand that basic open sets in the subspace topology will be the intersection of H with the image of an open ball in $\mathbb{R^2}$ .","I'm trying understand one point about Example 15.9 in the Introduction to Manfolds by Tu (p. 167). I'll reproduce the example here. See this post , which addressed a separate question I had. Example 15.9 ( Lines with irrational slope in a torus ). Let be the torus and a line through the origin in . The torus can also be represented by the unit square with the opposite edges identified. The image of under the projection is a closed curve if and only if the line goes through another lattice point, say . This is the case if and only if the slope of is , a rational number or ; then is the image of finitely many line segments on the unit square. It is a closed curve diffeomorphic to a circle and is a regular submanifold of (Figure 15.1). If the slope of L is irrational, then its image H on the torus will never close up. In this case the restriction to L of the projection map, , is a one-to-one immersion . We give H the topology and manifold structure induced from f. I don't understand why is an immersion. How would I prove this? Why is the subspace topology of H in a strict subset of the  topology on induced from ? For the induced topology, I understand that a basic open set of H is the image under of an open set in . I also understand that basic open sets in the subspace topology will be the intersection of H with the image of an open ball in .","G \mathbb{R}^2/\mathbb{Z}^2 L \mathbb{R}^2 H L \pi:\mathbb{R}^2\longrightarrow\mathbb{R}^2/\mathbb{Z}^2 L (m,n)\in\mathbb{Z}^2 L n/m \infty H \mathbb{R}^2/\mathbb{Z}^2 f := \pi\big|_L : L \rightarrow \mathbb{R}^2/\mathbb{Z}^2 f \mathbb{R}^2/\mathbb{Z}^2 H  f : L \xrightarrow{\sim} H f L \mathbb{R^2}","['differential-geometry', 'smooth-manifolds']"
90,How does this step rewriting the Lie derivative of a vector field work?,How does this step rewriting the Lie derivative of a vector field work?,,"I am reading some differential geometry notes and I stuck with understandig what seems to be a simple part of a proof but for me comes out of nowhere. Let $M$ be a smooth manifold and let $X,Y$ be two smooth vector fields on the manifold. Then one can define the Lie derivative of $Y$ in direction of $X$ as $$ L_X Y = \frac{d}{dt} ((\Psi_{-t})_* Y) \bigg \vert_0.$$ Here, $\Psi_{-t}$ denotes the local flow of the vector field $X$ , that is in some neighborhood of some point one has $$ \frac{d}{dt} \Psi_t(q) = X_{\Psi_t(q)}.$$ $(\Psi_{-t})_*$ denotes the push-forward of $\Psi_{-t}$ and we have $$(\Psi_{-t})_* Y)_{\Psi_{-t}p} = {d\Psi_{-t}}_p Y_p$$ and thus $$(\Psi_{-t})_* Y)_{p} = {d\Psi_{-t}}_{\Psi_{t}(p)} Y_{\Psi_{t}(p)}.$$ Now in the proof that the definition above for the Lie derivative is the same as using $[X,Y]$ where this denotes the Lie bracket, the first step is as follows: For a function $f \in C^{\infty}(M)$ , we have $$ {L_X Y}_p \cdot f = \frac{d}{dt}(Y_{\Psi_{t}(p)} \cdot (f \circ \Psi_{-t}) ) \bigg \vert_{t = 0}.$$ This is already the step that I do not understand: From above we have $$ {L_X Y}_p \cdot f = \frac{d}{dt}{d\Psi_{-t}}_{\Psi_{t}(p)} Y_{\Psi_{t}(p)}\bigg \vert_{t = 0} \cdot f.$$ How can we now get the function $f$ ""inside"" of the time derivative, and where does the change of the composition order come frome? If the element in brackets was some $t \to M$ then maybe it would make more sense to me, since the elements of the tangent space $T_pM$ can be represented by such curves (or rather there derivatives at point $p$ ), but here we have a curve in $T_pM$ . Could anyone please explain this step a bit to me?","I am reading some differential geometry notes and I stuck with understandig what seems to be a simple part of a proof but for me comes out of nowhere. Let be a smooth manifold and let be two smooth vector fields on the manifold. Then one can define the Lie derivative of in direction of as Here, denotes the local flow of the vector field , that is in some neighborhood of some point one has denotes the push-forward of and we have and thus Now in the proof that the definition above for the Lie derivative is the same as using where this denotes the Lie bracket, the first step is as follows: For a function , we have This is already the step that I do not understand: From above we have How can we now get the function ""inside"" of the time derivative, and where does the change of the composition order come frome? If the element in brackets was some then maybe it would make more sense to me, since the elements of the tangent space can be represented by such curves (or rather there derivatives at point ), but here we have a curve in . Could anyone please explain this step a bit to me?","M X,Y Y X  L_X Y = \frac{d}{dt} ((\Psi_{-t})_* Y) \bigg \vert_0. \Psi_{-t} X  \frac{d}{dt} \Psi_t(q) = X_{\Psi_t(q)}. (\Psi_{-t})_* \Psi_{-t} (\Psi_{-t})_* Y)_{\Psi_{-t}p} = {d\Psi_{-t}}_p Y_p (\Psi_{-t})_* Y)_{p} = {d\Psi_{-t}}_{\Psi_{t}(p)} Y_{\Psi_{t}(p)}. [X,Y] f \in C^{\infty}(M)  {L_X Y}_p \cdot f = \frac{d}{dt}(Y_{\Psi_{t}(p)} \cdot (f \circ \Psi_{-t}) ) \bigg \vert_{t = 0}.  {L_X Y}_p \cdot f = \frac{d}{dt}{d\Psi_{-t}}_{\Psi_{t}(p)} Y_{\Psi_{t}(p)}\bigg \vert_{t = 0} \cdot f. f t \to M T_pM p T_pM","['differential-geometry', 'vector-fields', 'lie-derivative']"
91,Bounding diameter of the arc of a closed curve,Bounding diameter of the arc of a closed curve,,"I was reading chapter 4 of Colding and Minicozzi's A Course in Minimal surfaces and I came across a statement in the proof of Lemma 4.14: Suppose $\Gamma\subset\mathbb{R}^3$ is a simple closed curve of finite arc length. Then for any sufficiently small $\epsilon>0$ there exists $d>0$ such that if $p,q\in\Gamma$ with $0<|p-q|<d$ , then $\Gamma\setminus\{p,q\}$ has exactly one component with diameter $<\epsilon$ . I think I know how to prove something like this assuming that $\Gamma$ is $C^2$ (or whatever condition that leads to the existence tubular neighbourhoods), but I'm not sure how to prove this when the curve is simply finite arc-length. Edit: Changed ''for any $\epsilon>0$ '' to ''for any sufficiently small $\epsilon>0$ ''.","I was reading chapter 4 of Colding and Minicozzi's A Course in Minimal surfaces and I came across a statement in the proof of Lemma 4.14: Suppose is a simple closed curve of finite arc length. Then for any sufficiently small there exists such that if with , then has exactly one component with diameter . I think I know how to prove something like this assuming that is (or whatever condition that leads to the existence tubular neighbourhoods), but I'm not sure how to prove this when the curve is simply finite arc-length. Edit: Changed ''for any '' to ''for any sufficiently small ''.","\Gamma\subset\mathbb{R}^3 \epsilon>0 d>0 p,q\in\Gamma 0<|p-q|<d \Gamma\setminus\{p,q\} <\epsilon \Gamma C^2 \epsilon>0 \epsilon>0","['real-analysis', 'differential-geometry', 'curves', 'minimal-surfaces']"
92,Levi Civita Connections vs. Ehresmann connection,Levi Civita Connections vs. Ehresmann connection,,"Forgive me if I mess some of these concepts up or say something incorrect, I am still figuring out all the details of an Ehresmann connection in an associated vector bundle. So, how do we relate these two practically? Like for a two sphere I can very easily write down the levi civita connection in the standard way for the usual round metric, but if I wanted to get something equivalent by starting with a connection in the frame bundle I don't really know where to begin. Specifically, it seems we would  have a natural choice of a horizontal distribution on the frame bundle if we have imposed a metric on it (i.e. the horizontal vector fields are those such that $g(\mathfrak{gl},H)=0$ , for a metric $g$ ), but I'm not sure what other conditions I would need to get the equivalent of the levi civita connection in the tangent bundle. Or would we want to look at an orthonormal frame bundle? I don't see why we would necessitate that other than that maybe the structure group is smaller as it would be $O(n)$ instead of $GL(n)$ , but at that point why not consider the bundle of orthonormal frames with the same orientation and use $SO(n)$ ? I think I am missing something","Forgive me if I mess some of these concepts up or say something incorrect, I am still figuring out all the details of an Ehresmann connection in an associated vector bundle. So, how do we relate these two practically? Like for a two sphere I can very easily write down the levi civita connection in the standard way for the usual round metric, but if I wanted to get something equivalent by starting with a connection in the frame bundle I don't really know where to begin. Specifically, it seems we would  have a natural choice of a horizontal distribution on the frame bundle if we have imposed a metric on it (i.e. the horizontal vector fields are those such that , for a metric ), but I'm not sure what other conditions I would need to get the equivalent of the levi civita connection in the tangent bundle. Or would we want to look at an orthonormal frame bundle? I don't see why we would necessitate that other than that maybe the structure group is smaller as it would be instead of , but at that point why not consider the bundle of orthonormal frames with the same orientation and use ? I think I am missing something","g(\mathfrak{gl},H)=0 g O(n) GL(n) SO(n)","['differential-geometry', 'connections', 'principal-bundles']"
93,Why in Green's theorem can we not simply integrate $y \mathrm{d} x$ instead of $y \mathrm{d} x - x \mathrm{d} y$?,Why in Green's theorem can we not simply integrate  instead of ?,y \mathrm{d} x y \mathrm{d} x - x \mathrm{d} y,"According to the multidimensional Stoke's theorem, in order to evaluate the integral of a form $\omega$ , I just have to find a one-form $\alpha$ so that $d\alpha=\omega$ and then use $\int_{\partial \Omega} \alpha=\int_{\Omega} \omega$ say $\omega$ is just the area form, $dx \wedge dy$ . Then, according to Stokes' theorem I just have integrate $-x dy$ around the contour. However, according the Green's theorem I should choose rather the one form $y dx-x dy$ . I can see the second one is the right choice but I can't see why the first one is the wrong one. Can anyone tell me the error in my reasoning please?","According to the multidimensional Stoke's theorem, in order to evaluate the integral of a form , I just have to find a one-form so that and then use say is just the area form, . Then, according to Stokes' theorem I just have integrate around the contour. However, according the Green's theorem I should choose rather the one form . I can see the second one is the right choice but I can't see why the first one is the wrong one. Can anyone tell me the error in my reasoning please?",\omega \alpha d\alpha=\omega \int_{\partial \Omega} \alpha=\int_{\Omega} \omega \omega dx \wedge dy -x dy y dx-x dy,"['differential-geometry', 'vector-analysis', 'differential-forms', 'greens-theorem']"
94,Geometrical meaning of the commutator of vectors on a manifold,Geometrical meaning of the commutator of vectors on a manifold,,"On a manifold, vectors do not describe finite displacements, unlike in euclidean geometry, but they do describe infinitesimal displacements, so we can take two vectors, $v^a$ and $w^a$ to span an infinitesimal parallelogram. I would like to understand how $ v^a w^b−w^a v^b$ is what describes the ""infinitesimal parallelogram"" spanned by $v$ and $w$ . For example, a vector is (parallel) transported from a point $P$ to a point $P'$ , along two different paths: the first $ P \rightarrow P_{1} \rightarrow P'$ consists of two infinitesimal shifts, the second $ P \rightarrow P_{2} \rightarrow P'$ consists of the same shifts but in reverse order. How are the movements represented ?","On a manifold, vectors do not describe finite displacements, unlike in euclidean geometry, but they do describe infinitesimal displacements, so we can take two vectors, and to span an infinitesimal parallelogram. I would like to understand how is what describes the ""infinitesimal parallelogram"" spanned by and . For example, a vector is (parallel) transported from a point to a point , along two different paths: the first consists of two infinitesimal shifts, the second consists of the same shifts but in reverse order. How are the movements represented ?",v^a w^a  v^a w^b−w^a v^b v w P P'  P \rightarrow P_{1} \rightarrow P'  P \rightarrow P_{2} \rightarrow P',"['general-relativity', 'differential-geometry', 'vectors']"
95,"Osculating Plane of $(t,t^2,t^3)$ and a result",Osculating Plane of  and a result,"(t,t^2,t^3)","Find the osculating plane of curve parametric form $(t,t^2,t^3)$ . Also prove that intersection of three osculating planes on any three points of curve lies on plane containing those three points . My attempt :: I solved first part of question and found equation of osculating on a point on curve whose parameter is t $$3t^2X-3tY+Z-t^3=0$$ Now second part of question is where I am stuck . My thoughts are let three points on curve be whose parameter are a,b and c. Then write equation for their osculating plane ,Find intersection point and  find equation of plane containing three points . And finally satisfie the intersection point in plane . This process seems quite lengthy . Is there a smart way to do it ?","Find the osculating plane of curve parametric form . Also prove that intersection of three osculating planes on any three points of curve lies on plane containing those three points . My attempt :: I solved first part of question and found equation of osculating on a point on curve whose parameter is t Now second part of question is where I am stuck . My thoughts are let three points on curve be whose parameter are a,b and c. Then write equation for their osculating plane ,Find intersection point and  find equation of plane containing three points . And finally satisfie the intersection point in plane . This process seems quite lengthy . Is there a smart way to do it ?","(t,t^2,t^3) 3t^2X-3tY+Z-t^3=0","['differential-geometry', '3d', 'plane-geometry']"
96,Curves with the same speed and distance to origin,Curves with the same speed and distance to origin,,"Let $\alpha,\beta:[0,1]\to\mathbb{R}^2$ be two smooth curves satisfying $|\alpha(t)| = |\beta(t)|$ and $|\dot{\alpha}(t)| = |\dot{\beta}(t)|$ for all $t\in[0,1]$ .  That is, $\alpha$ and $\beta$ have the same speed and are at the same distance to the origin. Does there exist a rotation matrix $Q$ (with possibly negative determinant) such that $\alpha(t) = Q\beta(t)$ ? It seems that the answer is yes.  The speed $|\dot{\alpha}|$ should be enough to tell how quickly the curve is going around the circle.  This seems to be enough to recover the angular data of the curve, but I do not know of a good way to make this precise.","Let be two smooth curves satisfying and for all .  That is, and have the same speed and are at the same distance to the origin. Does there exist a rotation matrix (with possibly negative determinant) such that ? It seems that the answer is yes.  The speed should be enough to tell how quickly the curve is going around the circle.  This seems to be enough to recover the angular data of the curve, but I do not know of a good way to make this precise.","\alpha,\beta:[0,1]\to\mathbb{R}^2 |\alpha(t)| = |\beta(t)| |\dot{\alpha}(t)| = |\dot{\beta}(t)| t\in[0,1] \alpha \beta Q \alpha(t) = Q\beta(t) |\dot{\alpha}|","['differential-geometry', 'plane-curves']"
97,How can the Chern-Simons form trivialize a non-trivial characteristic class?,How can the Chern-Simons form trivialize a non-trivial characteristic class?,,"I have a very basic confusion about Chern-Simons forms: On Wikipedia and other sources, it is stated that the Chern-Simons 3-form $$Tr(A\wedge dA+\frac23 A\wedge [A\wedge A])$$ trivializes $Tr(F^2)$ , where $$F=dA+[A\wedge A]$$ is the curvature 2-form of the connection 1-form $A$ of a Lie-group principle bundle. Now, $Tr(F^2)$ is proportional to the second Chern character, $$\frac12 c_1^2-c_2$$ which is a characteristic class, i.e., a cohomology class in $H^4(BU(n), \mathbb{Q})$ . More specifically, we can imagine $Tr(F^2)$ as a specific representing cocycle of this class, which is pulled back via the classifying map of the principle bundle from the base manifold to $BU(n)$ (chosen some $U(n)$ representation of the Lie group $A$ takes values in). A locally computable trivialization of $Tr(F^2)$ should arise from a trivialization of the corresponding cocycle on $BU(n)$ , also by pullback via the classifying map. However, since $\frac12 c_1^2-c_2$ is a non-trivial characteristic class, $Tr(F^2)$ shouldn't have any locally computable trivialization. So where is my misconception here? Is it that even though $c_1$ and $c_2$ are non-trivial as $\mathbb{Z}$ -valued characteristic classes, the Chern character is trivial as a rational characteristic class? Or is it that if we consider those characteristic classes applied to principle bundles instead of vector bundles as usual, they become trivial? Or has it something to do with the choice of $U(n)$ representation of the concerned Lie group? Or am I misinterpreting the statement that the Chern-Simons form trivializes the Chern character?","I have a very basic confusion about Chern-Simons forms: On Wikipedia and other sources, it is stated that the Chern-Simons 3-form trivializes , where is the curvature 2-form of the connection 1-form of a Lie-group principle bundle. Now, is proportional to the second Chern character, which is a characteristic class, i.e., a cohomology class in . More specifically, we can imagine as a specific representing cocycle of this class, which is pulled back via the classifying map of the principle bundle from the base manifold to (chosen some representation of the Lie group takes values in). A locally computable trivialization of should arise from a trivialization of the corresponding cocycle on , also by pullback via the classifying map. However, since is a non-trivial characteristic class, shouldn't have any locally computable trivialization. So where is my misconception here? Is it that even though and are non-trivial as -valued characteristic classes, the Chern character is trivial as a rational characteristic class? Or is it that if we consider those characteristic classes applied to principle bundles instead of vector bundles as usual, they become trivial? Or has it something to do with the choice of representation of the concerned Lie group? Or am I misinterpreting the statement that the Chern-Simons form trivializes the Chern character?","Tr(A\wedge dA+\frac23 A\wedge [A\wedge A]) Tr(F^2) F=dA+[A\wedge A] A Tr(F^2) \frac12 c_1^2-c_2 H^4(BU(n), \mathbb{Q}) Tr(F^2) BU(n) U(n) A Tr(F^2) BU(n) \frac12 c_1^2-c_2 Tr(F^2) c_1 c_2 \mathbb{Z} U(n)","['differential-geometry', 'homology-cohomology', 'characteristic-classes', 'de-rham-cohomology', 'classifying-spaces']"
98,Coefficients of inverse conformal metric,Coefficients of inverse conformal metric,,"I'm trying to understand some proof written in local coordinates. The situation is as follows: We have a $2$ -dim Riemannian manifold $(M,g)$ and a conformal diffeomorphism $f:M\rightarrow M$ such that $\tilde{g}:=f^*g=e^{2\lambda}g$ . The claim in the proof is that $$ e^{2\lambda}g^{ij}= \sum_{k,l=1}^2g^{kl}\frac{\partial f_i}{\partial x_k}\frac{\partial f_j}{\partial x_l} $$ but I don't see this. By calculation I got $$ e^{2\lambda}g_{ij}=\tilde{g}_{ij}:=\tilde{g}(\partial_i,\partial_j)=\sum_{kl=1}^2 g_{kl}\frac{\partial f_k}{\partial x_i}\frac{\partial f_l}{\partial x_j} $$ and don't now how to continue. I'd be thankfull for some help!",I'm trying to understand some proof written in local coordinates. The situation is as follows: We have a -dim Riemannian manifold and a conformal diffeomorphism such that . The claim in the proof is that but I don't see this. By calculation I got and don't now how to continue. I'd be thankfull for some help!,"2 (M,g) f:M\rightarrow M \tilde{g}:=f^*g=e^{2\lambda}g 
e^{2\lambda}g^{ij}= \sum_{k,l=1}^2g^{kl}\frac{\partial f_i}{\partial x_k}\frac{\partial f_j}{\partial x_l}
 
e^{2\lambda}g_{ij}=\tilde{g}_{ij}:=\tilde{g}(\partial_i,\partial_j)=\sum_{kl=1}^2 g_{kl}\frac{\partial f_k}{\partial x_i}\frac{\partial f_l}{\partial x_j}
","['differential-geometry', 'riemannian-geometry', 'conformal-geometry']"
99,Determining whether a given mapping between tangent bundle $TU$ and $\phi(U)\times\mathbb{R}$ is also a diffeomorphism,Determining whether a given mapping between tangent bundle  and  is also a diffeomorphism,TU \phi(U)\times\mathbb{R},"Let $M$ be an $n$ -dimensional smooth manifold, $(U,\phi) = (U,x^1\dots,x^n)$ a coordinate chart and $c^1,\dots,c^n$ coefficients. Then at the point $p\in M$ , any $v \in T_pU = T_pM$ can be written as $v = \sum_{i=1}^nc^i \frac{\partial}{\partial x^i}\bigg|_p$ . Given Loring's ( An Introduction to Manifolds , pp.130-131) homeomorphism $\psi:TU\to \phi(U)\times \mathbb{R}^n$ , $\psi(v) = (x^1(p),\dots,x^n(p),c^1(v),\dots,c^n(v))$ and its inverse $\psi^{-1}(v) = (\phi(p),c^1,\dots,c^n) = \sum c^i \frac{\partial}{\partial x^i}\bigg|_p$ , I'd like to know whether this mapping is also a diffeomorphism? Bijectivity and smoothness of $\psi$ are evident (smootness is due to the smoothness of $\phi$ and the projection mappings $c^1,\dots,c^n$ ). And while it is easy to argue about the partial derivatives of $\psi^{-1}$ w.r.t. $c^1,\dots,c^n$ , I've hit a brick while trying to argue about the partial derivative w.r.t. $\phi(p)$ . Namely how can you argue that the evaluation mapping $p \mapsto \frac{\partial}{\partial x^i}\bigg|_p$ is smooth in this context, where the partial derivatives represent the basis vectors of $TU$ at the point $p$ ?","Let be an -dimensional smooth manifold, a coordinate chart and coefficients. Then at the point , any can be written as . Given Loring's ( An Introduction to Manifolds , pp.130-131) homeomorphism , and its inverse , I'd like to know whether this mapping is also a diffeomorphism? Bijectivity and smoothness of are evident (smootness is due to the smoothness of and the projection mappings ). And while it is easy to argue about the partial derivatives of w.r.t. , I've hit a brick while trying to argue about the partial derivative w.r.t. . Namely how can you argue that the evaluation mapping is smooth in this context, where the partial derivatives represent the basis vectors of at the point ?","M n (U,\phi) = (U,x^1\dots,x^n) c^1,\dots,c^n p\in M v \in T_pU = T_pM v = \sum_{i=1}^nc^i \frac{\partial}{\partial x^i}\bigg|_p \psi:TU\to \phi(U)\times \mathbb{R}^n \psi(v) = (x^1(p),\dots,x^n(p),c^1(v),\dots,c^n(v)) \psi^{-1}(v) = (\phi(p),c^1,\dots,c^n) = \sum c^i \frac{\partial}{\partial x^i}\bigg|_p \psi \phi c^1,\dots,c^n \psi^{-1} c^1,\dots,c^n \phi(p) p \mapsto \frac{\partial}{\partial x^i}\bigg|_p TU p","['real-analysis', 'differential-geometry', 'vector-analysis', 'smooth-manifolds']"
