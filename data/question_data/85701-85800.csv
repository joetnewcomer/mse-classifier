,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Show that if operator $T$ is such that $||I-T||<1$ , then $T$ is bijective.","Show that if operator  is such that  , then  is bijective.",T ||I-T||<1 T,"I came across this statement in a proof and I can't figure out why its true, could someone point out why (or give a hint). Thanks. Suppose that $T:X\to X$ is a bounded linear operator that maps a Banach space $X$ to itself such that $$||I-T||<1,\quad\quad(*)$$ where $I$ denotes the identity on $X$, and the $||\cdot||$ the induced operator norm. Then $T$ is bijective. In case anyone comes across this later on here's a follow up on Karene's answer. It follows from $(*)$ that $$S_n:=\sum_{i=0}^n(I-T)^i$$ is bounded for all $n$ and that the sequence $(S_n)$ is Cauchy. Since $X$ is complete, the space of linear bounded operators on $X$ is complete as well. Thus $S_n$ tends to some linear bounded operator $S$ as $n$ tends to infinity. Then, it's easy to verify that $$(I-T)S=S-I\Rightarrow TS=I$$ and similarly to show that $ST=I$.","I came across this statement in a proof and I can't figure out why its true, could someone point out why (or give a hint). Thanks. Suppose that $T:X\to X$ is a bounded linear operator that maps a Banach space $X$ to itself such that $$||I-T||<1,\quad\quad(*)$$ where $I$ denotes the identity on $X$, and the $||\cdot||$ the induced operator norm. Then $T$ is bijective. In case anyone comes across this later on here's a follow up on Karene's answer. It follows from $(*)$ that $$S_n:=\sum_{i=0}^n(I-T)^i$$ is bounded for all $n$ and that the sequence $(S_n)$ is Cauchy. Since $X$ is complete, the space of linear bounded operators on $X$ is complete as well. Thus $S_n$ tends to some linear bounded operator $S$ as $n$ tends to infinity. Then, it's easy to verify that $$(I-T)S=S-I\Rightarrow TS=I$$ and similarly to show that $ST=I$.",,['functional-analysis']
1,"Dense subspace of $L^{2}[0,1]$",Dense subspace of,"L^{2}[0,1]","I know that $C[0,1]$ is dense in $L^{2}[0,1]$ but is $\{f\in C^{2}[0,1]:f(0)=f(1)=0\}$ dense in $L^{2}[0,1]$?","I know that $C[0,1]$ is dense in $L^{2}[0,1]$ but is $\{f\in C^{2}[0,1]:f(0)=f(1)=0\}$ dense in $L^{2}[0,1]$?",,"['real-analysis', 'functional-analysis', 'hilbert-spaces', 'lebesgue-integral']"
2,Does the dualizing process on vector spaces necessarily terminate?,Does the dualizing process on vector spaces necessarily terminate?,,"It's well-known (assuming the axiom of choice) that the inclusion $\ell^1 \subset (\ell^1)^{**}$ is proper as a simple corollary of the Hahn-Banach theorem. But is this the end of the dualizing process; e.g., does $(\ell^1)^{**} = (\ell^1)^{****}$, or do we continue to get more unwieldy vector spaces over time? If this process does not terminate, is there a non-trivial (i.e. not 'reflexive') condition on vector spaces $V$ such that, for some large enough $n$, $V^{2n*}=V^{(2n+2)*}$? On a similar topic, if we deny the axiom of choice, we know that $(\ell^1)^{**}=\ell^1$ ( source ). In this case, do we also have $V^{**}=V$ for all $V$?","It's well-known (assuming the axiom of choice) that the inclusion $\ell^1 \subset (\ell^1)^{**}$ is proper as a simple corollary of the Hahn-Banach theorem. But is this the end of the dualizing process; e.g., does $(\ell^1)^{**} = (\ell^1)^{****}$, or do we continue to get more unwieldy vector spaces over time? If this process does not terminate, is there a non-trivial (i.e. not 'reflexive') condition on vector spaces $V$ such that, for some large enough $n$, $V^{2n*}=V^{(2n+2)*}$? On a similar topic, if we deny the axiom of choice, we know that $(\ell^1)^{**}=\ell^1$ ( source ). In this case, do we also have $V^{**}=V$ for all $V$?",,['functional-analysis']
3,Poincare Inequality implies Equivalent Norms,Poincare Inequality implies Equivalent Norms,,"I am currently working through the subject of Sobolev Spaces using the book 'Partial Differential Equations' by Lawrence Evans. After the result proving the Poincare Inequality it says the following in the book(page 266.) ""In view of the Poincare Inequality, on $W_{0}^{1,p}(U)$ the norm $||DU||_{L^{p}}$ is equivalent to $||u||_{W^{1,p}(U)}$, if $U$ is bounded."" Do you know the argument behind this statement?","I am currently working through the subject of Sobolev Spaces using the book 'Partial Differential Equations' by Lawrence Evans. After the result proving the Poincare Inequality it says the following in the book(page 266.) ""In view of the Poincare Inequality, on $W_{0}^{1,p}(U)$ the norm $||DU||_{L^{p}}$ is equivalent to $||u||_{W^{1,p}(U)}$, if $U$ is bounded."" Do you know the argument behind this statement?",,"['functional-analysis', 'inequality', 'partial-differential-equations', 'sobolev-spaces', 'normed-spaces']"
4,How common is it for a densely-defined linear functional to be closed?,How common is it for a densely-defined linear functional to be closed?,,"I've always held the vague belief that any densely-defined operator encountered ""in nature"", if it isn't bounded, is probably at least closable. But, today I noticed the following thing: Consider the Banach space $C_0(\mathbb{R})$ of continuous, complex-valued function vanishing at $\pm \infty$ in the uniform norm. We have a densely-defined linear functional  $\int : C_c(\mathbb{R}) \to \mathbb{C}$ given by Riemann integrating compactly supported functions. This functional is not closable. Indeed, choose $f \in C_c(\mathbb{R})$ with $\int f = 1$ and put $f_n(t) = (1/n) \cdot f(t/n)$. Then $f_n \to 0$ uniformly, but $\int f_n = 1$ for all $n$. Thus $(0,1)$ belongs to the closure of $\operatorname{Graph}(\int) \subset C_0(\mathbb{R}) \times \mathbb{C}$, and $\overline{\int}$ is not single-valued. This surprised me because integration against an infinite measure is one of the most fundamental examples of an unbounded linear functional. So, if integration is not closed, how ubiquitous could closed linear functionals possibly be? Question: Can you come up with any good ""natural"" examples of densely-defined linear functionals on Banach spaces which are closable? Do you have a sense for how important, or common, such examples are? Or are non-closable functionals the rule rather than the exception? Thanks.","I've always held the vague belief that any densely-defined operator encountered ""in nature"", if it isn't bounded, is probably at least closable. But, today I noticed the following thing: Consider the Banach space $C_0(\mathbb{R})$ of continuous, complex-valued function vanishing at $\pm \infty$ in the uniform norm. We have a densely-defined linear functional  $\int : C_c(\mathbb{R}) \to \mathbb{C}$ given by Riemann integrating compactly supported functions. This functional is not closable. Indeed, choose $f \in C_c(\mathbb{R})$ with $\int f = 1$ and put $f_n(t) = (1/n) \cdot f(t/n)$. Then $f_n \to 0$ uniformly, but $\int f_n = 1$ for all $n$. Thus $(0,1)$ belongs to the closure of $\operatorname{Graph}(\int) \subset C_0(\mathbb{R}) \times \mathbb{C}$, and $\overline{\int}$ is not single-valued. This surprised me because integration against an infinite measure is one of the most fundamental examples of an unbounded linear functional. So, if integration is not closed, how ubiquitous could closed linear functionals possibly be? Question: Can you come up with any good ""natural"" examples of densely-defined linear functionals on Banach spaces which are closable? Do you have a sense for how important, or common, such examples are? Or are non-closable functionals the rule rather than the exception? Thanks.",,"['functional-analysis', 'operator-theory', 'examples-counterexamples']"
5,Norm of a $2\times 2$ matrix as a Hilbert space operator,Norm of a  matrix as a Hilbert space operator,2\times 2,"Work in the Hilbert space $\mathbb C^2$. Let $$A =          \begin{bmatrix}         a & b \\         c & d  \\         \end{bmatrix} $$ be a matrix with entries in $\mathbb C$, and let $A$ act in the standard way on $\mathbb C^2$. This gives a linear operator on $\mathbb C^2$. Define $\alpha=[|a|^2+|b|^2+|c|^2+|d|^2]^{1/2}$ and $\delta = \sqrt{\det A^* A}$. I would like to show that $$\|A\|=\frac{\alpha^2+\sqrt{\alpha^4-4\delta^2}}{2},$$ where $\|A\|$ is the norm as a Hilbert space operator. (Note the resemblance to the quadratic formula.) This problem comes from page 30 of Conway's A Course in Functional Analysis , 2nd edition. It is problem 1.11 in chapter 2.","Work in the Hilbert space $\mathbb C^2$. Let $$A =          \begin{bmatrix}         a & b \\         c & d  \\         \end{bmatrix} $$ be a matrix with entries in $\mathbb C$, and let $A$ act in the standard way on $\mathbb C^2$. This gives a linear operator on $\mathbb C^2$. Define $\alpha=[|a|^2+|b|^2+|c|^2+|d|^2]^{1/2}$ and $\delta = \sqrt{\det A^* A}$. I would like to show that $$\|A\|=\frac{\alpha^2+\sqrt{\alpha^4-4\delta^2}}{2},$$ where $\|A\|$ is the norm as a Hilbert space operator. (Note the resemblance to the quadratic formula.) This problem comes from page 30 of Conway's A Course in Functional Analysis , 2nd edition. It is problem 1.11 in chapter 2.",,"['functional-analysis', 'hilbert-spaces']"
6,Is every operator unitary equivalent to a banded operator?,Is every operator unitary equivalent to a banded operator?,,"Let $H$ be an infinite dimensional separable Hilbert space and $B(H)$ the algebra of bounded operators. Definition : Let $(e_{n})_{n \in \mathbb{N}}$ be an orthonormal basis. $T \in B(H)$ is banded if $\exists r \in \mathbb{N}$ such that $ (Te_{n}, e_{m})\ne 0 \Rightarrow \vert n-m \vert \leq r$. Is every operator unitary equivalent to a banded operator ? Remark : A banded operator is a thick generalization of a diagonal operator. It's also a finite sum of finite product of weight shift operators.","Let $H$ be an infinite dimensional separable Hilbert space and $B(H)$ the algebra of bounded operators. Definition : Let $(e_{n})_{n \in \mathbb{N}}$ be an orthonormal basis. $T \in B(H)$ is banded if $\exists r \in \mathbb{N}$ such that $ (Te_{n}, e_{m})\ne 0 \Rightarrow \vert n-m \vert \leq r$. Is every operator unitary equivalent to a banded operator ? Remark : A banded operator is a thick generalization of a diagonal operator. It's also a finite sum of finite product of weight shift operators.",,"['functional-analysis', 'reference-request', 'operator-theory']"
7,Prove that $A$ is bounded operator on $\ell^p$ and find $\| A\|$,Prove that  is bounded operator on  and find,A \ell^p \| A\|,"For which one $p \ge 1$ is with $$A(x_n)_{n=1}^{\infty}=\left(\frac{1}{m}\sum_{n=1}^{m}\frac{x_n}{\sqrt{n}}\right)_{m=1}^{\infty}$$ defined bounded linear operator $A:\ell^p \to \ell^p$? Find norm $\| A\|.$ First, I have to show that if $x = (x_n)_{n=1}^{\infty} \in \ell^p$ then $\displaystyle y=(y_m)_{m=1}^{\infty} \stackrel{\text{def}}{=}\left(\frac{1}{m}\sum_{n=1}^{m}\frac{x_n}{\sqrt{n}}\right)_{m=1}^{\infty} \in \ell^p$, that is $\displaystyle\sqrt[p]{\sum_{m=1}^{\infty}|y_m|^p} < +\infty.$ All right, $$\begin{align*} |y_m|=\left|\frac{1}{m}\sum_{n=1}^{m}\frac{x_n}{\sqrt{n}}\right|&\leq\frac{1}{m} \sum_{n=1}^{m} \frac{|x_n|}{\sqrt{n}}\\ &\stackrel{\star}{\leq}\frac{1}{m} \sqrt[p]{\sum_{n=1}^{m}|x_n|^p} \sqrt[q]{\sum_{n=1}^{m} n^{-q/2}} \\ &\leq \frac{\| x \|_p}{m}\sqrt[q]{\sum_{n=1}^{m} n^{-q/2}}.\end{align*}$$ So $$\begin{align*} \sum_{m=1}^{\infty} |y_m|^p &\leq \sum_{m=1}^{\infty} \left|\frac{\| x \|_p}{m}\sqrt[q]{\sum_{n=1}^{m} n^{-q/2}}\right|^p\\&=\sum_{m=1}^{\infty} \frac{1}{m^p} \| x\|^p_p \left(\sum_{n=1}^{m} n^{-q/2}\right)^{p/q}\\ &\leq \|x\|^p_p \sum_{m=1}^{\infty} \frac{1}{m^p}   \left(\sum_{n=1}^{\infty} n^{-q/2}\right)^{p/q} \end{align*}$$ If I see well, last sum is convergent for $q/2 >1 \iff q>2$ and $p>1$ (but with condition $1/p + 1/q =1$). I think my estimate is too sharp. And we find that $$\| A \| \leq \sqrt[p]{\sum_{m=1}^{\infty} \frac{1}{m^p}   \left(\sum_{n=1}^{\infty} n^{-q/2}\right)^{p/q}}$$ But for part (if my approximation is good enough) with $\geq$ I don't have idea (to be honest, I used Hölder inequality, so we want $x_n = c  \frac{1}{\sqrt{n}}$, that will give us something divergent I think so). $\star$ - one doubt also: I used here Hölder inequality, but that works only for $p,q >1$, but in my question we have $p \geq 1$, so basically I have to work case $p=1$ as separate?","For which one $p \ge 1$ is with $$A(x_n)_{n=1}^{\infty}=\left(\frac{1}{m}\sum_{n=1}^{m}\frac{x_n}{\sqrt{n}}\right)_{m=1}^{\infty}$$ defined bounded linear operator $A:\ell^p \to \ell^p$? Find norm $\| A\|.$ First, I have to show that if $x = (x_n)_{n=1}^{\infty} \in \ell^p$ then $\displaystyle y=(y_m)_{m=1}^{\infty} \stackrel{\text{def}}{=}\left(\frac{1}{m}\sum_{n=1}^{m}\frac{x_n}{\sqrt{n}}\right)_{m=1}^{\infty} \in \ell^p$, that is $\displaystyle\sqrt[p]{\sum_{m=1}^{\infty}|y_m|^p} < +\infty.$ All right, $$\begin{align*} |y_m|=\left|\frac{1}{m}\sum_{n=1}^{m}\frac{x_n}{\sqrt{n}}\right|&\leq\frac{1}{m} \sum_{n=1}^{m} \frac{|x_n|}{\sqrt{n}}\\ &\stackrel{\star}{\leq}\frac{1}{m} \sqrt[p]{\sum_{n=1}^{m}|x_n|^p} \sqrt[q]{\sum_{n=1}^{m} n^{-q/2}} \\ &\leq \frac{\| x \|_p}{m}\sqrt[q]{\sum_{n=1}^{m} n^{-q/2}}.\end{align*}$$ So $$\begin{align*} \sum_{m=1}^{\infty} |y_m|^p &\leq \sum_{m=1}^{\infty} \left|\frac{\| x \|_p}{m}\sqrt[q]{\sum_{n=1}^{m} n^{-q/2}}\right|^p\\&=\sum_{m=1}^{\infty} \frac{1}{m^p} \| x\|^p_p \left(\sum_{n=1}^{m} n^{-q/2}\right)^{p/q}\\ &\leq \|x\|^p_p \sum_{m=1}^{\infty} \frac{1}{m^p}   \left(\sum_{n=1}^{\infty} n^{-q/2}\right)^{p/q} \end{align*}$$ If I see well, last sum is convergent for $q/2 >1 \iff q>2$ and $p>1$ (but with condition $1/p + 1/q =1$). I think my estimate is too sharp. And we find that $$\| A \| \leq \sqrt[p]{\sum_{m=1}^{\infty} \frac{1}{m^p}   \left(\sum_{n=1}^{\infty} n^{-q/2}\right)^{p/q}}$$ But for part (if my approximation is good enough) with $\geq$ I don't have idea (to be honest, I used Hölder inequality, so we want $x_n = c  \frac{1}{\sqrt{n}}$, that will give us something divergent I think so). $\star$ - one doubt also: I used here Hölder inequality, but that works only for $p,q >1$, but in my question we have $p \geq 1$, so basically I have to work case $p=1$ as separate?",,"['functional-analysis', 'operator-theory']"
8,Image of closed unit ball under a compact operator,Image of closed unit ball under a compact operator,,"Let $X,Y$ be Banach spaces and $A\in\mathcal L(X,Y)$ . The task is to prove the following: $A$ is compact if and only if the image of the closed unit ball in $X$ is compact in $Y$ . I have proven this when $X$ is a reflexive space. Proof. Let $X$ be a reflexive space, $\bar B$ the closed unit ball in $X$, and $A$ a compact operator. Let further $y_n=Ax_n$ be a sequence in $A(\bar B)$. In reflexive spaces $\bar B$ is weakly compact, so there exists a subsequence $x_{n_j} \to x$ weakly. Because $A$ is compact, $Ax_{n_j}\to Ax$ strongly. On the other side, $A(\bar B)$ is relatively compact, so there exists $z_k=Ax_{n_{j_k}}$ that converges strongly to $y\in Y$. But $z_k\to Ax$ strongly. So by unicity of the limit $y=Ax$ and the image is compact. It's easily proved that if the image is compact, the operator is also compact. But I don't know what to do in case of nonreflexive spaces. Is there any counterexample or proof in such case?","Let $X,Y$ be Banach spaces and $A\in\mathcal L(X,Y)$ . The task is to prove the following: $A$ is compact if and only if the image of the closed unit ball in $X$ is compact in $Y$ . I have proven this when $X$ is a reflexive space. Proof. Let $X$ be a reflexive space, $\bar B$ the closed unit ball in $X$, and $A$ a compact operator. Let further $y_n=Ax_n$ be a sequence in $A(\bar B)$. In reflexive spaces $\bar B$ is weakly compact, so there exists a subsequence $x_{n_j} \to x$ weakly. Because $A$ is compact, $Ax_{n_j}\to Ax$ strongly. On the other side, $A(\bar B)$ is relatively compact, so there exists $z_k=Ax_{n_{j_k}}$ that converges strongly to $y\in Y$. But $z_k\to Ax$ strongly. So by unicity of the limit $y=Ax$ and the image is compact. It's easily proved that if the image is compact, the operator is also compact. But I don't know what to do in case of nonreflexive spaces. Is there any counterexample or proof in such case?",,"['functional-analysis', 'proof-writing']"
9,How to understand C(X)'' = bounded Borel measurable functions?,How to understand C(X)'' = bounded Borel measurable functions?,,"Let $X$ be a compact metric space and $C(X)=\{ f:X\rightarrow \mathbb{R} \ | \ \ f \ continuous\}$ with the uniform norm. It is a separable Banach space. 1) I'm aware of the fact that $C(X)^*$, the space of continuous linear functionals $C(X)\rightarrow \mathbb{R}$ coincide with $M(X)$, the space of signed regular borel measures on $X$. This intuitively makes sense because $\mu\in M(X)$ can be naturally be seen as an evaluation map $f\mapsto \mathbb{R}$ by means of integration. 2) I'm also aware that $(C(X)^*)^*$, the dual of the dual, coincide with the set of bounded Borel measurable functions $F:X\rightarrow\mathbb{R}$ (source: P. Lax, Functional Analysis ). UPDATE Landscape provided a counterexample in the comments. My source was: P. Lax ""Functional Analysis"" 2002, Page 82, Theorem 14(ii). I guess this might be a mistake, perhaps fixed in some errata somewhere. New question: C.f. Landscape's example, let $g_A$ be the extension (given by Hahn-Banach) of $f_A$ to $C([0,1])^{**}$. Looking at $g_A$ as a function $X\rightarrow\mathbb{R}$, $g_A$ must satisfy by construction the equation $\int_{[0,1]}g_A \ d \ \delta_x= 1$ if $x\in A$ and $0$ otherwise. This seems to imply that $g_A$ is the characteristic function of $A$. Hence not Borel if $A$ is not Borel. Thus, $g_A$ as a function $(X\rightarrow\mathbb{R})$ is uniquely determined by the construction starting from $f_A$. But is it $g_A$ as an element of $C([0,1])^{**}$ uniquely determined? If so, it looks to me we would have a reasonably well defined notion of integration for non-measurable sets. Thanks! Screen shot of Lax's theorem 14 on page 82:","Let $X$ be a compact metric space and $C(X)=\{ f:X\rightarrow \mathbb{R} \ | \ \ f \ continuous\}$ with the uniform norm. It is a separable Banach space. 1) I'm aware of the fact that $C(X)^*$, the space of continuous linear functionals $C(X)\rightarrow \mathbb{R}$ coincide with $M(X)$, the space of signed regular borel measures on $X$. This intuitively makes sense because $\mu\in M(X)$ can be naturally be seen as an evaluation map $f\mapsto \mathbb{R}$ by means of integration. 2) I'm also aware that $(C(X)^*)^*$, the dual of the dual, coincide with the set of bounded Borel measurable functions $F:X\rightarrow\mathbb{R}$ (source: P. Lax, Functional Analysis ). UPDATE Landscape provided a counterexample in the comments. My source was: P. Lax ""Functional Analysis"" 2002, Page 82, Theorem 14(ii). I guess this might be a mistake, perhaps fixed in some errata somewhere. New question: C.f. Landscape's example, let $g_A$ be the extension (given by Hahn-Banach) of $f_A$ to $C([0,1])^{**}$. Looking at $g_A$ as a function $X\rightarrow\mathbb{R}$, $g_A$ must satisfy by construction the equation $\int_{[0,1]}g_A \ d \ \delta_x= 1$ if $x\in A$ and $0$ otherwise. This seems to imply that $g_A$ is the characteristic function of $A$. Hence not Borel if $A$ is not Borel. Thus, $g_A$ as a function $(X\rightarrow\mathbb{R})$ is uniquely determined by the construction starting from $f_A$. But is it $g_A$ as an element of $C([0,1])^{**}$ uniquely determined? If so, it looks to me we would have a reasonably well defined notion of integration for non-measurable sets. Thanks! Screen shot of Lax's theorem 14 on page 82:",,"['functional-analysis', 'measure-theory']"
10,partially reconstruct information of function convoluted with boxcar kernel,partially reconstruct information of function convoluted with boxcar kernel,,"the function (f) I want to reconstruct partially could look like this: The following properties are known: It consists only of alternating plateau (high/low). So the first derivation is zero respectively undefined at the edges. The function was convoluted with a kernel fulfilling the following conditions: It is a boxcar function Its center is at x=0 Its integral is 1. I want to reconstruct only the positions of the edges of the original function (f) from the convolution result (c). So just these positions are of interest to me: If the convolution kernel width (k) is less than the minimum plateau width (b, 40 in the example above) of f, c looks as follows: (The width of the box car convolution kernel here is k=31.) In that case it is easy to reconstruct the edge positions: I look for (possibly broad) extrema, and in between to neighbours [e1_x, e1_y] and [e2_x, e2_y] (one of them is a minimum and one a maximum of course), I search the x0 fulfilling: c(x0) = (e1_y + e2_y) / 2. The reconstructed edge positions look like that: But if k > b my approach fails: (k=57) Is there a possibility to calculate the original edge positions in f, if g (and so k) and c are known, also for the k>b cases?","the function (f) I want to reconstruct partially could look like this: The following properties are known: It consists only of alternating plateau (high/low). So the first derivation is zero respectively undefined at the edges. The function was convoluted with a kernel fulfilling the following conditions: It is a boxcar function Its center is at x=0 Its integral is 1. I want to reconstruct only the positions of the edges of the original function (f) from the convolution result (c). So just these positions are of interest to me: If the convolution kernel width (k) is less than the minimum plateau width (b, 40 in the example above) of f, c looks as follows: (The width of the box car convolution kernel here is k=31.) In that case it is easy to reconstruct the edge positions: I look for (possibly broad) extrema, and in between to neighbours [e1_x, e1_y] and [e2_x, e2_y] (one of them is a minimum and one a maximum of course), I search the x0 fulfilling: c(x0) = (e1_y + e2_y) / 2. The reconstructed edge positions look like that: But if k > b my approach fails: (k=57) Is there a possibility to calculate the original edge positions in f, if g (and so k) and c are known, also for the k>b cases?",,"['functional-analysis', 'signal-processing', 'convolution']"
11,Quotients of C*-algebras,Quotients of C*-algebras,,"It is known that every unital separable C*-algebra is a quotient of the full group C*-algebra $C^*(F_I)$, where $F_I$ is the free group generated by some index set $I$. Can we drop the separability assumption here? Any references would be appreciated.","It is known that every unital separable C*-algebra is a quotient of the full group C*-algebra $C^*(F_I)$, where $F_I$ is the free group generated by some index set $I$. Can we drop the separability assumption here? Any references would be appreciated.",,"['functional-analysis', 'reference-request', 'operator-algebras', 'c-star-algebras']"
12,Invertibility of compact operators,Invertibility of compact operators,,"I'm a little confused about compact operators and whether or not they are invertible. Just hoping someone here can clear up my confusion: Let $T$ be a compact operator on a Banach space $X$. Since $T$ is compact, we know that $0$ is in the spectrum of $T$. This implies that either $T$ is not invertible, or if it is then the inverse operator isn't bounded. Now, if $T$ did have an inverse $T^{-1}$, then $T$ would be a bijective bounded operator. Hence, by the Banach Open mapping theorem, the map $T^{-1}$ would be bounded. This seems to imply that no compact operator is invertible. But it seems that if $\{x_{n}\}$ is a basis for $X$, then define our operator $T$ so that $Tx_{n}=\lambda_{n}x_{n}$, where, say $\lambda_{n}=2^{-n}$. This operator $T$ is approximated by finite-rank operators, and hence is compact. Also $T^{-1}$ exists, but it obviously isn't bounded. What is going on here? I feel like I'm going in circles.","I'm a little confused about compact operators and whether or not they are invertible. Just hoping someone here can clear up my confusion: Let $T$ be a compact operator on a Banach space $X$. Since $T$ is compact, we know that $0$ is in the spectrum of $T$. This implies that either $T$ is not invertible, or if it is then the inverse operator isn't bounded. Now, if $T$ did have an inverse $T^{-1}$, then $T$ would be a bijective bounded operator. Hence, by the Banach Open mapping theorem, the map $T^{-1}$ would be bounded. This seems to imply that no compact operator is invertible. But it seems that if $\{x_{n}\}$ is a basis for $X$, then define our operator $T$ so that $Tx_{n}=\lambda_{n}x_{n}$, where, say $\lambda_{n}=2^{-n}$. This operator $T$ is approximated by finite-rank operators, and hence is compact. Also $T^{-1}$ exists, but it obviously isn't bounded. What is going on here? I feel like I'm going in circles.",,"['functional-analysis', 'operator-theory', 'compact-operators']"
13,natural embedding of normed linear space is an isometry,natural embedding of normed linear space is an isometry,,"To review for an exam, I'm trying to write up a short proof of the following: Let $J: X \rightarrow X^{**}$ be the natural embedding of the normed   linear space $X$ into its bidual $X^{**}$, given by $J(x) = f(x)$. This embedding is a linear and isometric. The Hahn-Banach theorem gives us $\phi \in X^*$ (a linear functional on $X$) which $\| \phi \| =1$ and $f(x) =  \|x\|$. This implies $||x|| \leq \|J(x)\|$. I have difficulty in following the proofs demonstrating that the embedding is bounded, that $\|J(x)\| \leq \|x\|.$ How can this be proven in a short manner without being ""handwaving in manner""?","To review for an exam, I'm trying to write up a short proof of the following: Let $J: X \rightarrow X^{**}$ be the natural embedding of the normed   linear space $X$ into its bidual $X^{**}$, given by $J(x) = f(x)$. This embedding is a linear and isometric. The Hahn-Banach theorem gives us $\phi \in X^*$ (a linear functional on $X$) which $\| \phi \| =1$ and $f(x) =  \|x\|$. This implies $||x|| \leq \|J(x)\|$. I have difficulty in following the proofs demonstrating that the embedding is bounded, that $\|J(x)\| \leq \|x\|.$ How can this be proven in a short manner without being ""handwaving in manner""?",,['functional-analysis']
14,$\ell x = 0$ for all $\ell \in X'$ for banach spaces,for all  for banach spaces,\ell x = 0 \ell \in X',"I guess this is probably asked before but I can not find it. Let $X$ be a Banach space, and let $\ell x = 0$ for all $\ell \in X'$. Then $x = 0$ If all projections $\pi_\alpha x = 0$ and hence get  ""all coordinates"" equal zero. But that probably not hold and I read you need Hahn-banach to prove it.","I guess this is probably asked before but I can not find it. Let $X$ be a Banach space, and let $\ell x = 0$ for all $\ell \in X'$. Then $x = 0$ If all projections $\pi_\alpha x = 0$ and hence get  ""all coordinates"" equal zero. But that probably not hold and I read you need Hahn-banach to prove it.",,"['functional-analysis', 'banach-spaces']"
15,the dimension of continuous functions on a compact set is finite [duplicate],the dimension of continuous functions on a compact set is finite [duplicate],,"This question already has an answer here : Closed 11 years ago . Possible Duplicate: vector space of continuous functions on compact Hausdorff space This is a problem  am trying to solve.  Suppose the dimension of $C(X)$ is finite where $X$ is compact and Hausdorff.  Why is $X$ finite? I was able to show that if $X$ is finite, then the dimension of $C(X)$ is finite.  I am having trouble proving the converse.","This question already has an answer here : Closed 11 years ago . Possible Duplicate: vector space of continuous functions on compact Hausdorff space This is a problem  am trying to solve.  Suppose the dimension of $C(X)$ is finite where $X$ is compact and Hausdorff.  Why is $X$ finite? I was able to show that if $X$ is finite, then the dimension of $C(X)$ is finite.  I am having trouble proving the converse.",,"['analysis', 'functional-analysis']"
16,"Show that if the Riesz map is surjective on $H$, then $H$ is a Hilbert space","Show that if the Riesz map is surjective on , then  is a Hilbert space",H H,"Let $H$ be a vector space equipped with an inner product $(\cdot, \cdot)$ and $f:H\to H',\ f(x)=(\cdot,x)$ surjective. Now, why $H$  is a Hilbert space? The other direction is clear by Riesz' representation theorem but what about this?","Let $H$ be a vector space equipped with an inner product $(\cdot, \cdot)$ and $f:H\to H',\ f(x)=(\cdot,x)$ surjective. Now, why $H$  is a Hilbert space? The other direction is clear by Riesz' representation theorem but what about this?",,"['functional-analysis', 'banach-spaces', 'hilbert-spaces', 'inner-products']"
17,"Is the derivate on a closed subspace of $C^1[0,1]$ is a continuous linear map?",Is the derivate on a closed subspace of  is a continuous linear map?,"C^1[0,1]","I'm trying to show that $D:(X, \|\cdot\|_\infty) \rightarrow C[0,1]$  is a continuous map. $D$ is the differential operator and  $X$ is a closed (proper) subset of $C^1[0,1]$. The fact that $X$ is closed in $C^1[0,1]$ must be important in the proof because otherwise this result is obviously false. However, I don't know how to use this fact. I need this result to apply Arzela-Ascoli theorem to show that unit ball of X is compact and then conclude that $X$ is finite dimensional. Does anyone know how to tackle this problem ?","I'm trying to show that $D:(X, \|\cdot\|_\infty) \rightarrow C[0,1]$  is a continuous map. $D$ is the differential operator and  $X$ is a closed (proper) subset of $C^1[0,1]$. The fact that $X$ is closed in $C^1[0,1]$ must be important in the proof because otherwise this result is obviously false. However, I don't know how to use this fact. I need this result to apply Arzela-Ascoli theorem to show that unit ball of X is compact and then conclude that $X$ is finite dimensional. Does anyone know how to tackle this problem ?",,['functional-analysis']
18,Rademacher functions form an orthonormal system but not an orthonormal basis,Rademacher functions form an orthonormal system but not an orthonormal basis,,"I would like to know how to show that the functions  $$r_n(t)=\operatorname{sgn}\big(\sin(2^n \pi t)\big)$$ (where $\operatorname{sgn}$ is the sign function) form an orthonormal system but not an orthonormal basis from $L_2([0,1])$. Progress : I pick two different variables $i,k$ and show that $\langle r_i (t),r_k (t)\rangle =0$, so I can take the integral $\int_0^1  r_i (t) r_k (t)\,dt$, but I do not know how to show that this is 0.","I would like to know how to show that the functions  $$r_n(t)=\operatorname{sgn}\big(\sin(2^n \pi t)\big)$$ (where $\operatorname{sgn}$ is the sign function) form an orthonormal system but not an orthonormal basis from $L_2([0,1])$. Progress : I pick two different variables $i,k$ and show that $\langle r_i (t),r_k (t)\rangle =0$, so I can take the integral $\int_0^1  r_i (t) r_k (t)\,dt$, but I do not know how to show that this is 0.",,"['functional-analysis', 'hilbert-spaces', 'lp-spaces', 'orthonormal']"
19,Unit Ball of $\mathcal{l}_2$,Unit Ball of,\mathcal{l}_2,"Let $B(\mathcal{l}_2) :=\{x \in \mathcal{l}_2 : \|x \| \leq 1 \}$ and $S(\mathcal{l}_2) :=\{x \in \mathcal{l}_2 : \|x \| = 1 \}$ be the unit ball and the unit sphere of $\mathcal{l}_2$, respectively. I'm trying to show that $B(\mathcal{l}_2)$ contains an infinite set $A$ such that, for every $x,y \in A$ with $x \neq y$, we have $\|x -y \| > \sqrt{2}$. My intuition tells me that such a set $A$ should lie inside $S(\mathcal{l}_2)$. Next, I've tried to use a point $z$ such that $d(z,S(\mathcal{l}_2)) = \sqrt{2}$ to define $A$. I know that for such a $z$ there exists $w \in S(\mathcal{l}_2)$ such that $\|z - w \| = \sqrt{2}$, and for every $v \in S(\mathcal{l}_2),v \ne w$, we must have $\|z - v \| > \sqrt{2}$. So, right now I'm confused about how to go ahead with the definition of $A$ in a way that the distance between any two distinct points in $A$ is greater that $\sqrt{2}$. I get the feeling that I should be able to use what I've described in the previous paragraph, but I don't see how. Could somebody point me in the right way?","Let $B(\mathcal{l}_2) :=\{x \in \mathcal{l}_2 : \|x \| \leq 1 \}$ and $S(\mathcal{l}_2) :=\{x \in \mathcal{l}_2 : \|x \| = 1 \}$ be the unit ball and the unit sphere of $\mathcal{l}_2$, respectively. I'm trying to show that $B(\mathcal{l}_2)$ contains an infinite set $A$ such that, for every $x,y \in A$ with $x \neq y$, we have $\|x -y \| > \sqrt{2}$. My intuition tells me that such a set $A$ should lie inside $S(\mathcal{l}_2)$. Next, I've tried to use a point $z$ such that $d(z,S(\mathcal{l}_2)) = \sqrt{2}$ to define $A$. I know that for such a $z$ there exists $w \in S(\mathcal{l}_2)$ such that $\|z - w \| = \sqrt{2}$, and for every $v \in S(\mathcal{l}_2),v \ne w$, we must have $\|z - v \| > \sqrt{2}$. So, right now I'm confused about how to go ahead with the definition of $A$ in a way that the distance between any two distinct points in $A$ is greater that $\sqrt{2}$. I get the feeling that I should be able to use what I've described in the previous paragraph, but I don't see how. Could somebody point me in the right way?",,"['functional-analysis', 'hilbert-spaces']"
20,Abelian von Neumann Algebras on non-separable Hilbert spaces,Abelian von Neumann Algebras on non-separable Hilbert spaces,,"Is there a classification of Abelian von Neumann algebras on non-separable Hilbert spaces? For a classification of Abelian von Neumann algebras on separable Hilbert spaces, see this link .","Is there a classification of Abelian von Neumann algebras on non-separable Hilbert spaces? For a classification of Abelian von Neumann algebras on separable Hilbert spaces, see this link .",,"['functional-analysis', 'operator-theory', 'operator-algebras']"
21,Cylindrical sigma algebra and continuous functions.,Cylindrical sigma algebra and continuous functions.,,"Consider the space $\mathbb R^{[0,1]}$ of all functions from $[0,1]$ to $\mathbb R$  and the cylindrical sigma algebra $\mathcal B$ on it. I know how to prove that $C[0,1]\not \in \mathcal B$. My question is the following: does there exist a subset of $C[0,1]$ that is in $\mathcal B$? Thank you.","Consider the space $\mathbb R^{[0,1]}$ of all functions from $[0,1]$ to $\mathbb R$  and the cylindrical sigma algebra $\mathcal B$ on it. I know how to prove that $C[0,1]\not \in \mathcal B$. My question is the following: does there exist a subset of $C[0,1]$ that is in $\mathcal B$? Thank you.",,"['functional-analysis', 'probability-theory', 'stochastic-processes', 'metric-spaces']"
22,Orthogonality checking in Kreyszig exercise,Orthogonality checking in Kreyszig exercise,,"Let $H$ be inner product space with inner product $\langle\cdot,\cdot\rangle$ and norm $\lVert \cdot\rVert$. Let $x,y \in H$. Would you help me to prove that $\langle x,y\rangle=0$ if and only if $\lVert x+\alpha y\rVert \geq\lVert x\rVert$ for all scalar $\alpha$? I have proved that $\langle x,y\rangle=0$ implies $\lVert x+\alpha y\rVert\geq \lVert x\rVert$, but don't know how to prove the converse. I just try to show that $\lVert x+\alpha y\rVert\geq \lVert x\rVert$ implies $\lVert x+\alpha y\rVert=\lVert x-\alpha y\rVert$ (but still not success) since this equality equivalent with  $\langle x,y\rangle=0$. Is there any solution of this problem using this information: ∥x+αy∥=∥x−αy∥ if and only if =0 ? Thanks.","Let $H$ be inner product space with inner product $\langle\cdot,\cdot\rangle$ and norm $\lVert \cdot\rVert$. Let $x,y \in H$. Would you help me to prove that $\langle x,y\rangle=0$ if and only if $\lVert x+\alpha y\rVert \geq\lVert x\rVert$ for all scalar $\alpha$? I have proved that $\langle x,y\rangle=0$ implies $\lVert x+\alpha y\rVert\geq \lVert x\rVert$, but don't know how to prove the converse. I just try to show that $\lVert x+\alpha y\rVert\geq \lVert x\rVert$ implies $\lVert x+\alpha y\rVert=\lVert x-\alpha y\rVert$ (but still not success) since this equality equivalent with  $\langle x,y\rangle=0$. Is there any solution of this problem using this information: ∥x+αy∥=∥x−αy∥ if and only if =0 ? Thanks.",,"['functional-analysis', 'hilbert-spaces', 'inner-products']"
23,How to prove that the space of convergent sequences is complete?,How to prove that the space of convergent sequences is complete?,,"Let $X=\mathrm{Conv}(\mathbf R)$, the collection of all convergent sequences in $\mathbf{R}$. Is the normed space $(X,\|\cdot\|_\infty)$ complete?","Let $X=\mathrm{Conv}(\mathbf R)$, the collection of all convergent sequences in $\mathbf{R}$. Is the normed space $(X,\|\cdot\|_\infty)$ complete?",,"['functional-analysis', 'banach-spaces']"
24,"If $a\ge 0$ and $b\ge 0$, then $\sigma(ab)\subset\mathbb{R}^+$.","If  and , then .",a\ge 0 b\ge 0 \sigma(ab)\subset\mathbb{R}^+,"This is an exercise in Murphy's book : Let $A$ be a unital $C^*$-algebra and $a,b$ are positive elements in $A$. Then $\sigma(ab)\subset\mathbb{R}^+$. The problem would be trivial if the algebra is abelian. On the other hand I do not have a clue for the non-abelian case. I guess one needs to use the fact $\sigma(ab)\cup\{0\}=\sigma(ba)\cup\{0\}$ and then maybe use some algebraic manipulation. Anyway, I wonder whether someone has a hint on this. I guess I am missing a trick. Better though, maybe someone has some general insight on the many techniques concerning positive elements and approximate identities. For me they all seem very tricky and mysterious. For instance, how can they think of those strange functions when proving the existence of approximate identities and quasicentral approximate identities. Thanks!","This is an exercise in Murphy's book : Let $A$ be a unital $C^*$-algebra and $a,b$ are positive elements in $A$. Then $\sigma(ab)\subset\mathbb{R}^+$. The problem would be trivial if the algebra is abelian. On the other hand I do not have a clue for the non-abelian case. I guess one needs to use the fact $\sigma(ab)\cup\{0\}=\sigma(ba)\cup\{0\}$ and then maybe use some algebraic manipulation. Anyway, I wonder whether someone has a hint on this. I guess I am missing a trick. Better though, maybe someone has some general insight on the many techniques concerning positive elements and approximate identities. For me they all seem very tricky and mysterious. For instance, how can they think of those strange functions when proving the existence of approximate identities and quasicentral approximate identities. Thanks!",,"['functional-analysis', 'operator-theory', 'banach-algebras']"
25,Idea behind factoring an operator?,Idea behind factoring an operator?,,Suppose if we have an operator $\partial_t^2-\partial_x^2 $ what does it mean to factorise this operator to write it as $(\partial_t-\partial_x) (\partial_t+\partial x)$ When does it actually make sense and why ?,Suppose if we have an operator $\partial_t^2-\partial_x^2 $ what does it mean to factorise this operator to write it as $(\partial_t-\partial_x) (\partial_t+\partial x)$ When does it actually make sense and why ?,,"['functional-analysis', 'partial-differential-equations']"
26,How to determine the $\delta$ in the open mapping theorem?,How to determine the  in the open mapping theorem?,\delta,"Let $X$ and $Y$ be Banach spaces and $T\in\mathcal{L}(X,Y)$ be a bounded linear operator from $X$ to $Y$. If $T$ is surjective, then the open mapping theorem says that there is a positive $\delta$ such that $TB_1\supset\delta B_2$, where $B_1$ and $B_2$ are open unit balls in $X$ and $Y$ respectively. My question is how is the $\delta$ related to the norm of $T$, which gives a (sharp) bound for the norm of the inverse of $T$ if $T$ is also injective. Thanks! And another related question: If $\mu$ is at a positive distance to $\sigma(T)$, the spectrum of $T$, how is $\|(\mu-T)^{-1}\|$ related to the distance from $\mu$ to $\sigma(T)$? Obviously we have an lower bound, but what I need is an upper bound. Thanks!","Let $X$ and $Y$ be Banach spaces and $T\in\mathcal{L}(X,Y)$ be a bounded linear operator from $X$ to $Y$. If $T$ is surjective, then the open mapping theorem says that there is a positive $\delta$ such that $TB_1\supset\delta B_2$, where $B_1$ and $B_2$ are open unit balls in $X$ and $Y$ respectively. My question is how is the $\delta$ related to the norm of $T$, which gives a (sharp) bound for the norm of the inverse of $T$ if $T$ is also injective. Thanks! And another related question: If $\mu$ is at a positive distance to $\sigma(T)$, the spectrum of $T$, how is $\|(\mu-T)^{-1}\|$ related to the distance from $\mu$ to $\sigma(T)$? Obviously we have an lower bound, but what I need is an upper bound. Thanks!",,"['functional-analysis', 'banach-spaces']"
27,Is the set of all probability measures weak*-closed?,Is the set of all probability measures weak*-closed?,,"Let $(\Omega,\Sigma)$ be a measurable space. Denote by $ba(\Sigma)$ the set of all bounded and finitely additive measures on $(\Omega,\Sigma)$ (see http://en.wikipedia.org/wiki/Ba_space for a definition). Is the set of all probability measures $\mathcal{M}_1(\Sigma)\subseteq ba(\Sigma)$ weak*-closed? The weak*-topology on $ba(\Sigma)$ is the weakest topology such that the maps $l_Z:ba(\Sigma)\rightarrow \mathbb{R}$, mapping $\mu\mapsto \int_\Omega Z d\mu$, are continuous for all bounded and measurable maps $Z:\Omega\rightarrow \mathbb{R}$.","Let $(\Omega,\Sigma)$ be a measurable space. Denote by $ba(\Sigma)$ the set of all bounded and finitely additive measures on $(\Omega,\Sigma)$ (see http://en.wikipedia.org/wiki/Ba_space for a definition). Is the set of all probability measures $\mathcal{M}_1(\Sigma)\subseteq ba(\Sigma)$ weak*-closed? The weak*-topology on $ba(\Sigma)$ is the weakest topology such that the maps $l_Z:ba(\Sigma)\rightarrow \mathbb{R}$, mapping $\mu\mapsto \int_\Omega Z d\mu$, are continuous for all bounded and measurable maps $Z:\Omega\rightarrow \mathbb{R}$.",,"['functional-analysis', 'probability-theory']"
28,If $L$ is normed and for every hyperplane $M \cap \operatorname{ball} L^*$ weak*-closed implies $M$ weak*-closed then $L$ is a Banach space,If  is normed and for every hyperplane  weak*-closed implies  weak*-closed then  is a Banach space,L M \cap \operatorname{ball} L^* M L,"If $L$ is a normed space with the property that if $M$ is a hyperplane in $L^*$ and $M \cap \operatorname{ball} L^*$ is weak-star closed $\implies$ $M$ itself is weak star closed, then how do I show $L$ is a Banach space? I think I should should identify $L$ with $L^{**}$, but I'm not sure how to prove this.","If $L$ is a normed space with the property that if $M$ is a hyperplane in $L^*$ and $M \cap \operatorname{ball} L^*$ is weak-star closed $\implies$ $M$ itself is weak star closed, then how do I show $L$ is a Banach space? I think I should should identify $L$ with $L^{**}$, but I'm not sure how to prove this.",,"['functional-analysis', 'banach-spaces', 'locally-convex-spaces']"
29,Existence of faithful state in $C^\ast$-algebras,Existence of faithful state in -algebras,C^\ast,Why does there always exist a faithful state in a separable $C^\ast$-algebra?,Why does there always exist a faithful state in a separable $C^\ast$-algebra?,,"['functional-analysis', 'operator-theory', 'c-star-algebras']"
30,Measure in the Riesz representation theorem on open subsets,Measure in the Riesz representation theorem on open subsets,,"Let $X$ be locally compact Hausdorff space and $\Lambda$ be a positive linear functional on $C_c(X)$. It is known [W.Rudin, Real and complex analysis, th.2.14] that the measure $\mu$ in the Riesz representation theorem is given on an open set $V$  by formulae: $$\mu(V)=\sup \{\Lambda(f): f\in C_c, 0\leq f \leq 1, \operatorname{supp}{f} \subset V \}.$$ Is it true that $$\mu(V)=\sup\{\Lambda(f): f\in C_c, 0\leq f \leq 1, \operatorname{supp}{f} \subset \operatorname{cl}{ V} \}$$ for open $V$ ? Thanks.","Let $X$ be locally compact Hausdorff space and $\Lambda$ be a positive linear functional on $C_c(X)$. It is known [W.Rudin, Real and complex analysis, th.2.14] that the measure $\mu$ in the Riesz representation theorem is given on an open set $V$  by formulae: $$\mu(V)=\sup \{\Lambda(f): f\in C_c, 0\leq f \leq 1, \operatorname{supp}{f} \subset V \}.$$ Is it true that $$\mu(V)=\sup\{\Lambda(f): f\in C_c, 0\leq f \leq 1, \operatorname{supp}{f} \subset \operatorname{cl}{ V} \}$$ for open $V$ ? Thanks.",,"['functional-analysis', 'analysis', 'measure-theory', 'riesz-representation-theorem']"
31,Is this functional weakly continuous?,Is this functional weakly continuous?,,"Take a $C^1$ function $G \colon \mathbb{R}\to \mathbb{R}$ and define a functional $$\mathcal{G}(u)=\int_0^1G(u(t))\, dt, \quad u \in H^1(0, 1).$$ We then have $\mathcal{G}\in C^1\big(H^1(0, 1)\to \mathbb{R}\big)$. Now, I would like to apply Weierstrass's theorem to this functional, and so I need to show that it is weakly lower semicontinuous. Question 1 Is it true? Some course notes I'm reading act as if $\mathcal{G}$ were weakly continuous , because they claim the differential $$\mathcal{G}' \colon H^1(0, 1) \to \big[ H^1(0, 1) \big] ' $$ is weak-strong continuous. (This trivially implies the claim). To show that, they first compute $$\langle \mathcal{G}'(u), v \rangle = \int_0^1 G'(u)v\, dt,$$ which is clear to me, and then factor the mapping $$u \in H^1 \mapsto \mathcal{G}'(u) \in \big[ H^1 \big]'$$ as $$u \in H^1 \mapsto u \in L^\infty \mapsto G'\circ u \in L^\infty \mapsto \mathcal{G}'(u) \in \big[ H^1 \big]';$$ then, since the first embedding is compact (so they say) and the other arrows are continuous, the whole mapping is weak-strong continuous. Question 2 This reasoning seems wrong to me, because the embedding   $H^1(0, 1) \hookrightarrow L^\infty(0, 1)$ is not compact. Am I wrong?","Take a $C^1$ function $G \colon \mathbb{R}\to \mathbb{R}$ and define a functional $$\mathcal{G}(u)=\int_0^1G(u(t))\, dt, \quad u \in H^1(0, 1).$$ We then have $\mathcal{G}\in C^1\big(H^1(0, 1)\to \mathbb{R}\big)$. Now, I would like to apply Weierstrass's theorem to this functional, and so I need to show that it is weakly lower semicontinuous. Question 1 Is it true? Some course notes I'm reading act as if $\mathcal{G}$ were weakly continuous , because they claim the differential $$\mathcal{G}' \colon H^1(0, 1) \to \big[ H^1(0, 1) \big] ' $$ is weak-strong continuous. (This trivially implies the claim). To show that, they first compute $$\langle \mathcal{G}'(u), v \rangle = \int_0^1 G'(u)v\, dt,$$ which is clear to me, and then factor the mapping $$u \in H^1 \mapsto \mathcal{G}'(u) \in \big[ H^1 \big]'$$ as $$u \in H^1 \mapsto u \in L^\infty \mapsto G'\circ u \in L^\infty \mapsto \mathcal{G}'(u) \in \big[ H^1 \big]';$$ then, since the first embedding is compact (so they say) and the other arrows are continuous, the whole mapping is weak-strong continuous. Question 2 This reasoning seems wrong to me, because the embedding   $H^1(0, 1) \hookrightarrow L^\infty(0, 1)$ is not compact. Am I wrong?",,"['functional-analysis', 'hilbert-spaces']"
32,Why $L^{r}(X)\cap L^{t}(X)\subset L^{s}(X)$ for $1<r<s<t$?,Why  for ?,L^{r}(X)\cap L^{t}(X)\subset L^{s}(X) 1<r<s<t,"I am working on this homework problem, and I am totally stuck: Let $(X,\mu)$ be a measure space, and let $1 \leq r < s < t < \infty$.  Prove that there exist constants $\alpha,\beta>0$ so that $$ \|f\|_s \;\leq\; \|f\|_r^\alpha\,\|f\|_t^\beta $$ for any measurable function $f\colon X\to\mathbb{R}$.  Use this to show that $$ L^r(X) \cap L^t(X) \,\subset\, L^s(X). $$ I know this is supposed not to be difficult. But I cannot solve it.","I am working on this homework problem, and I am totally stuck: Let $(X,\mu)$ be a measure space, and let $1 \leq r < s < t < \infty$.  Prove that there exist constants $\alpha,\beta>0$ so that $$ \|f\|_s \;\leq\; \|f\|_r^\alpha\,\|f\|_t^\beta $$ for any measurable function $f\colon X\to\mathbb{R}$.  Use this to show that $$ L^r(X) \cap L^t(X) \,\subset\, L^s(X). $$ I know this is supposed not to be difficult. But I cannot solve it.",,"['real-analysis', 'functional-analysis', 'banach-spaces']"
33,Weak convergence implies convergence in probability?,Weak convergence implies convergence in probability?,,"I'm striving to understand a proof from a paper. Denote the symbol $\rightsquigarrow$ as a weak convergence, and $l^{\infty}(\Omega)$ as the space of bounded functions on a metric space $(\Omega, d)$ . Let $M_n$ be a sequence of random objects of $l^{\infty}(\Omega)$ , which converges weakly to $M$ , i.e. $M_n \rightsquigarrow M$ . Is it true that $\lVert M_n - M \rVert _{l^{\infty} (\Omega)}$ converges to zero in probability? I know that convergence in probability implies convergence in distribution, but the converse is not always true. If you need a reference, please read the last paragraph of https://arxiv.org/pdf/1608.03012.pdf . (Alexander Petersen and Hans-Georg Müller, Fréchet Regression for Random Objects with Euclidean Predictors) Thank you very much. Caution : $\Omega$ is not a probability space in this question, instead it is a metric space. P.S. I just highlighted the part. Thank you. Theorem 1.3.6 in van der Vaart(1996) is about the continuous mapping theorem.","I'm striving to understand a proof from a paper. Denote the symbol as a weak convergence, and as the space of bounded functions on a metric space . Let be a sequence of random objects of , which converges weakly to , i.e. . Is it true that converges to zero in probability? I know that convergence in probability implies convergence in distribution, but the converse is not always true. If you need a reference, please read the last paragraph of https://arxiv.org/pdf/1608.03012.pdf . (Alexander Petersen and Hans-Georg Müller, Fréchet Regression for Random Objects with Euclidean Predictors) Thank you very much. Caution : is not a probability space in this question, instead it is a metric space. P.S. I just highlighted the part. Thank you. Theorem 1.3.6 in van der Vaart(1996) is about the continuous mapping theorem.","\rightsquigarrow l^{\infty}(\Omega) (\Omega, d) M_n l^{\infty}(\Omega) M M_n \rightsquigarrow M \lVert M_n - M \rVert _{l^{\infty} (\Omega)} \Omega","['functional-analysis', 'probability-theory', 'weak-convergence']"
34,Proof of $ran(E(\lambda)) = ker(\lambda-A)^\alpha$,Proof of,ran(E(\lambda)) = ker(\lambda-A)^\alpha,"Let $A: H \to H$ be a compact operator on the complex Hilbert space $H$ . Let $\lambda \neq 0$ be an Eigenvalue of $A$ . Since A is compact, it's Eigenvalues can only accumulate at $0$ , so we can find a smooth curve $\Gamma \subset \mathbb{C}$ enclosing no other Eigenvalue than $\lambda$ . Then the Risz-Projector $E(\lambda)$ (see also https://en.wikipedia.org/wiki/Riesz_projector ) is defined as $$ E(\lambda):= \frac{1}{2\pi i}\int_\Gamma (z-A)^{-1} dz $$ Question: How to prove $ran(E(\lambda)) = ker(\lambda-A)^\alpha$ , where $\alpha$ is the ascent multiplicity of $\lambda - A$ , i. e. the smallest integer such that $ker(\lambda - A)^\alpha = ker(\lambda - A)^{\alpha + 1}$ . $ker(\lambda-A)^\alpha$ is sometimes called the generalized Eigenspace. Background : This property of Riesz-Projectors is key to the Babuska-Osborn-Theory for approximating non-symmetric Eigenvalue problems. Babuska and Osborn state this property in their paper 'Eigenvalue Problems, 1991' but give no proof (they seem to refer to Dunford and Schwartz but I can't find a proof there either). I found a proof for the special case when $A$ is self-adjoint (in this case $\alpha = 1$ ) in this book https://link.springer.com/book/10.1007/978-1-4612-0741-2 . In the proof of "" $\supset$ "" (self-adj. case) they show that for $f \in ker(\lambda - A)$ we have $E(\lambda)f = f$ . I could generalize this to the non self-adjoint case by looking at Jordan-chains and using that $(\lambda - A)$ and $E(\lambda)$ commute. However, I don't see how to generalize "" $\subset$ "". Here is how the proof in the self-adjoint case works: They show $$ (\lambda - A) E(\lambda) = \frac{1}{2\pi i}\int_\Gamma (\lambda - A)(z-A)^{-1} dz = \frac{1}{2\pi i}\int_\Gamma (\lambda - z)(z-A)^{-1} dz = 0\\ $$ For the last equality the argument is as follows: We have $||(\lambda - A)^{-1}|| \leq d(\lambda, \sigma(A))^{-1}$ (which is true for self-adjoint operators). Therefore $ |(\lambda - z)| ||(z-A)^{-1}||$ is uniformly bounded on $interior(\Gamma) \backslash \{ \lambda \} $ . The equality then follows from Riemann's theorem on removable singularities and Cauchy's theorem. Any references or ideas are greatly appreciated. Thanks!","Let be a compact operator on the complex Hilbert space . Let be an Eigenvalue of . Since A is compact, it's Eigenvalues can only accumulate at , so we can find a smooth curve enclosing no other Eigenvalue than . Then the Risz-Projector (see also https://en.wikipedia.org/wiki/Riesz_projector ) is defined as Question: How to prove , where is the ascent multiplicity of , i. e. the smallest integer such that . is sometimes called the generalized Eigenspace. Background : This property of Riesz-Projectors is key to the Babuska-Osborn-Theory for approximating non-symmetric Eigenvalue problems. Babuska and Osborn state this property in their paper 'Eigenvalue Problems, 1991' but give no proof (they seem to refer to Dunford and Schwartz but I can't find a proof there either). I found a proof for the special case when is self-adjoint (in this case ) in this book https://link.springer.com/book/10.1007/978-1-4612-0741-2 . In the proof of "" "" (self-adj. case) they show that for we have . I could generalize this to the non self-adjoint case by looking at Jordan-chains and using that and commute. However, I don't see how to generalize "" "". Here is how the proof in the self-adjoint case works: They show For the last equality the argument is as follows: We have (which is true for self-adjoint operators). Therefore is uniformly bounded on . The equality then follows from Riemann's theorem on removable singularities and Cauchy's theorem. Any references or ideas are greatly appreciated. Thanks!","A: H \to H H \lambda \neq 0 A 0 \Gamma \subset \mathbb{C} \lambda E(\lambda) 
E(\lambda):= \frac{1}{2\pi i}\int_\Gamma (z-A)^{-1} dz
 ran(E(\lambda)) = ker(\lambda-A)^\alpha \alpha \lambda - A ker(\lambda - A)^\alpha = ker(\lambda - A)^{\alpha + 1} ker(\lambda-A)^\alpha A \alpha = 1 \supset f \in ker(\lambda - A) E(\lambda)f = f (\lambda - A) E(\lambda) \subset 
(\lambda - A) E(\lambda) = \frac{1}{2\pi i}\int_\Gamma (\lambda - A)(z-A)^{-1} dz = \frac{1}{2\pi i}\int_\Gamma (\lambda - z)(z-A)^{-1} dz = 0\\
 ||(\lambda - A)^{-1}|| \leq d(\lambda, \sigma(A))^{-1}  |(\lambda - z)| ||(z-A)^{-1}|| interior(\Gamma) \backslash \{ \lambda \} ","['functional-analysis', 'spectral-theory', 'compact-operators']"
35,How to calculate the eigenvalues of an operator?,How to calculate the eigenvalues of an operator?,,"I am trying to determine the eigenvalues of the following operator. $T:L^2[0,1] \rightarrow L^2[0,1]$ , $Tf(x)=\int_0^1(2xy-x-y+1)f(y)dy$ The Eigenvalues are $\rho_p(T):=\{\lambda: \lambda-T \text{ is not injective}\}$ My approach: Let $\lambda \in \mathbb{R}$ , $(\lambda-T)f(x)=\lambda f(x)- Tf(x)=\lambda f(x)-\int_0^1(2xy-x-y+1)f(y)dy$ My idea would be not to set $\lambda f(x)- Tf(x)=\lambda f(x)-\int_0^1(2xy-x-y+1)f(y)dy=a$ for $a \neq 0$ and trying to solve it for $\lambda$ . But there comes my next problem, that I don't know how to handle the Integral. Do I just set $F'=f$ , and do formal calculation?","I am trying to determine the eigenvalues of the following operator. , The Eigenvalues are My approach: Let , My idea would be not to set for and trying to solve it for . But there comes my next problem, that I don't know how to handle the Integral. Do I just set , and do formal calculation?","T:L^2[0,1] \rightarrow L^2[0,1] Tf(x)=\int_0^1(2xy-x-y+1)f(y)dy \rho_p(T):=\{\lambda: \lambda-T \text{ is not injective}\} \lambda \in \mathbb{R} (\lambda-T)f(x)=\lambda f(x)- Tf(x)=\lambda f(x)-\int_0^1(2xy-x-y+1)f(y)dy \lambda f(x)- Tf(x)=\lambda f(x)-\int_0^1(2xy-x-y+1)f(y)dy=a a \neq 0 \lambda F'=f",['functional-analysis']
36,Reference request to the theory and examples of the spectrum of the Laplace-Beltrami operator on different compact manifolds,Reference request to the theory and examples of the spectrum of the Laplace-Beltrami operator on different compact manifolds,,"In virtually all books, lecture notes, and articles I've encountered, it is taken as a fact that the Laplace-Beltrami operator $\Delta$ has a discrete spectrum on compact Riemannian manifolds. Some texts attempt to reference supporting material, but the cited resources are often so extensive that a beginner would need to read hundreds of pages to verify whether the reference indeed supports the claim. Consequently, I am seeking helpful guides that can walk me through the necessary theory of eigenfunctions and eigenvalues of the Laplace operator: i) with simple examples in a Euclidean setting (no need to go beyond $\mathbb{R}^2$ ), and ii) on Riemannian manifolds (involving the Laplace-Beltrami operator). Essentially, I am looking for a text which covers discussions such as 1.) What is spectrum for Laplacian in $\mathbb{R}^n$? and 2.) Spectrum of the Laplace operator with Neumann condition on intervals by introducing/referring to necessary theory and shows some examples of computing the said spectrum with some example boundary-initial value problems. Additionally, I would like to comment that the post: What is spectrum for Laplacian in $\mathbb{R}^n$? offers useful insights into what I am interested in: understanding when and why the spectrum of $\Delta$ is what it is, and how we interpret $\Delta$ as an operator. However, I would prefer to refer to established sources, and the comments in the post do not delve into the depth I desire. Edit: Rosenberg's book, The Laplacian on Riemannian manifold , seems to have some components which I am seeking: The book has a strong start with the basic examples, but then jumps, understandably, to heavier machinery with Hodge theory. I have no need for Hodge theory as of now. I am satisfied with a example rich text which takes the time to look at the eigenvalue-function problem with different domains and different boundary conditions.","In virtually all books, lecture notes, and articles I've encountered, it is taken as a fact that the Laplace-Beltrami operator has a discrete spectrum on compact Riemannian manifolds. Some texts attempt to reference supporting material, but the cited resources are often so extensive that a beginner would need to read hundreds of pages to verify whether the reference indeed supports the claim. Consequently, I am seeking helpful guides that can walk me through the necessary theory of eigenfunctions and eigenvalues of the Laplace operator: i) with simple examples in a Euclidean setting (no need to go beyond ), and ii) on Riemannian manifolds (involving the Laplace-Beltrami operator). Essentially, I am looking for a text which covers discussions such as 1.) What is spectrum for Laplacian in $\mathbb{R}^n$? and 2.) Spectrum of the Laplace operator with Neumann condition on intervals by introducing/referring to necessary theory and shows some examples of computing the said spectrum with some example boundary-initial value problems. Additionally, I would like to comment that the post: What is spectrum for Laplacian in $\mathbb{R}^n$? offers useful insights into what I am interested in: understanding when and why the spectrum of is what it is, and how we interpret as an operator. However, I would prefer to refer to established sources, and the comments in the post do not delve into the depth I desire. Edit: Rosenberg's book, The Laplacian on Riemannian manifold , seems to have some components which I am seeking: The book has a strong start with the basic examples, but then jumps, understandably, to heavier machinery with Hodge theory. I have no need for Hodge theory as of now. I am satisfied with a example rich text which takes the time to look at the eigenvalue-function problem with different domains and different boundary conditions.",\Delta \mathbb{R}^2 \Delta \Delta,"['functional-analysis', 'partial-differential-equations', 'reference-request', 'spectral-theory', 'laplacian']"
37,Is there any relationship between Gleason's theorem and Riesz representation theorem?,Is there any relationship between Gleason's theorem and Riesz representation theorem?,,"Gleason's Theorem Section 2.3.3 states that if a mapping $p$ satisfies several conditions, $p$ can be written as $p(E)=\text{tr}(\rho E)$ which is the inner product with a given density matrix. The third condition if $E_1E_2=0$ , then $p(E_1+E_2)=p(E_1)+p(E_2)$ looks like linearity condition. So I think it is very similiar to Riesz representation theorem in functional analysis. Is there any further relationship between the two theorems?","Gleason's Theorem Section 2.3.3 states that if a mapping satisfies several conditions, can be written as which is the inner product with a given density matrix. The third condition if , then looks like linearity condition. So I think it is very similiar to Riesz representation theorem in functional analysis. Is there any further relationship between the two theorems?",p p p(E)=\text{tr}(\rho E) E_1E_2=0 p(E_1+E_2)=p(E_1)+p(E_2),"['functional-analysis', 'intuition', 'quantum-mechanics', 'riesz-representation-theorem', 'quantum-information']"
38,"Subset of non-decreasing functions in $L^1[0,1]$ is compact?",Subset of non-decreasing functions in  is compact?,"L^1[0,1]","I'm interested in the subset of functions \begin{equation} A := \{f:[0,1]\rightarrow [0,1] | \text{$f$ is non-decreasing}\} \subset L^1[0,1]. \end{equation} Do we know if $A$ is compact? Since $L^1[0,1]$ is a Banach space, I tried to use the result in one of answers in Examples of compact sets that are infinite dimensional and not bounded , namely: $A$ is compact iff, (1) $A$ is closed and bounded. (2) For each $\varepsilon > 0$ there exists a finite dimensional subset $F \subset L^1[0,1]$ such that $d(f, F) < \varepsilon$ for all $f \in A$ . I think (2) should hold since any non-decreasing functions are Riemann integrable and so I can approximate any $f \in A$ by points in a space of rectangular functions (essentially Riemann sum approximation of the Riemann integral) to any $\varepsilon$ accuracy. For (1) I think it is clear that $A$ is bounded (in a unit ball). But do we know if $A$ is closed? In other words, if we have a sequence $\{f_i\} \in A$ such that $f_i\rightarrow_{L^1} f$ , do we know if $f \in A$ ? I think I can see this if $L^1$ convergence on $A$ implies point-wise convergence, but I'm also not sure if this is true.","I'm interested in the subset of functions Do we know if is compact? Since is a Banach space, I tried to use the result in one of answers in Examples of compact sets that are infinite dimensional and not bounded , namely: is compact iff, (1) is closed and bounded. (2) For each there exists a finite dimensional subset such that for all . I think (2) should hold since any non-decreasing functions are Riemann integrable and so I can approximate any by points in a space of rectangular functions (essentially Riemann sum approximation of the Riemann integral) to any accuracy. For (1) I think it is clear that is bounded (in a unit ball). But do we know if is closed? In other words, if we have a sequence such that , do we know if ? I think I can see this if convergence on implies point-wise convergence, but I'm also not sure if this is true.","\begin{equation}
A := \{f:[0,1]\rightarrow [0,1] | \text{f is non-decreasing}\} \subset L^1[0,1].
\end{equation} A L^1[0,1] A A \varepsilon > 0 F \subset L^1[0,1] d(f, F) < \varepsilon f \in A f \in A \varepsilon A A \{f_i\} \in A f_i\rightarrow_{L^1} f f \in A L^1 A","['real-analysis', 'functional-analysis', 'analysis']"
39,Norm of bounded operators of direct sum,Norm of bounded operators of direct sum,,Yesterday I posted this one regarding direct sum on Hilbert spaces $H_1$ and $H_2$ - have a look! Direct sum of two Hilbert spaces is a inner product. I am studying bounded operators and I just want to know if we can say something about the norm of my direct sum. I.e. let $T_1\in B(H_1)$ and $T_2\in B(H_2)$ then $T_1\oplus T_2$ is bounded by using the definition of bounded operator but how about its norm? I cannot se how this should be possible. Any suggestion? I belive we should use operator norm but I still cannot see how that would work. Thanks in advance.,Yesterday I posted this one regarding direct sum on Hilbert spaces and - have a look! Direct sum of two Hilbert spaces is a inner product. I am studying bounded operators and I just want to know if we can say something about the norm of my direct sum. I.e. let and then is bounded by using the definition of bounded operator but how about its norm? I cannot se how this should be possible. Any suggestion? I belive we should use operator norm but I still cannot see how that would work. Thanks in advance.,H_1 H_2 T_1\in B(H_1) T_2\in B(H_2) T_1\oplus T_2,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'operator-algebras', 'direct-sum']"
40,How does pointwise Hölder continuous on compact subsets not imply locally Hölder continuous?,How does pointwise Hölder continuous on compact subsets not imply locally Hölder continuous?,,"When Gilbarg and Trudinger introduced the Hölder spaces, they mentioned on page 52 that Furthermore note that local Hölder continuity is a stronger property than pointwise Hölder continuity in compact subsets. without further elaboration. Can someone kindly explain why?","When Gilbarg and Trudinger introduced the Hölder spaces, they mentioned on page 52 that Furthermore note that local Hölder continuity is a stronger property than pointwise Hölder continuity in compact subsets. without further elaboration. Can someone kindly explain why?",,"['functional-analysis', 'partial-differential-equations', 'function-spaces']"
41,The Laplace transform $\mathcal L$ is a self-adjoint operator on $L^2(\mathbb R_+)$,The Laplace transform  is a self-adjoint operator on,\mathcal L L^2(\mathbb R_+),"Let $\mathbb R_+ = [0, \infty)$ and consider the kernel $K(x,y) = e^{-xy}$ on $\mathbb R_+ \times \mathbb R_+$ . The associated integral operator on $L^2(\mathbb R_+)$ is called the Laplace transform $\mathcal L$ , i.e. $$(\mathcal L f)(x) = \int_0^\infty K(x,y) f(y)\, dy$$ Show that the Laplace transform $\mathcal L$ is a self-adjoint operator on $L^2(\mathbb R_+)$ . This question is similar to another question that I'd asked a few days ago, but the same approach doesn't work since the kernel is not square-integrable - so Fubini's theorem may not be applicable. My work: We want to show $\langle \mathcal Lf, g\rangle = \langle f, \mathcal Lg\rangle$ for all $f,g\in L^2(\mathbb R_+)$ . We have $$\begin{align*} \langle \mathcal Lf,g\rangle &= \int_0^\infty \mathcal Lf(x) \overline{g(x)} \, dx\\ &= \int_0^\infty \int_0^\infty e^{-xy} f(y) \overline{g(x)}\, dy\, dx \end{align*}$$ and $$\begin{align*} \langle f, \mathcal L g\rangle &= \int_0^\infty f(x) \overline{\mathcal Lg(x)}\, dx\\ &= \int_0^\infty \int_0^\infty e^{-xy} f(x) \overline{g(y)} \, dy\, dx\\&=   \int_0^\infty \int_0^\infty e^{-xy} f(y) \overline{g(x)} \, dx\, dy   \end{align*}$$ So, we must show $$\int_0^\infty \int_0^\infty e^{-xy} f(y) \overline{g(x)}\, dy\, dx =  \int_0^\infty \int_0^\infty e^{-xy} f(y) \overline{g(x)} \, dx\, dy $$ This can be done easily if Fubini's theorem is applicable. For Fubini's theorem, we require $$\int_0^\infty \int_0^\infty |e^{-xy}| |f(y)| |g(x)| \, dx\, dy < \infty$$ By applying Cauchy-Schwarz inequality twice (as in the linked post's answer), I was able to get $$\int_0^\infty \int_0^\infty |e^{-xy}| |f(y)| |g(x)| \, dx\, dy \le \|f\|_2 \|g\|_2 \left(\int_0^\infty \int_0^\infty e^{-2xy}\, dx\, dy \right)^{1/2}$$ Unfortunately, $$\int_0^\infty \int_0^\infty e^{-2xy}\, dx\, dy$$ diverges, so this bound is useless. Two possibilities arise: (i) either Fubini's theorem is applicable, and we must find a stronger bound to show $\int_0^\infty \int_0^\infty |e^{-xy}| |f(y)| |g(x)| \, dx\, dy < \infty$ , or (ii) we must show that the two integrals are equal using some technique other than Fubini's theorem. To me, (ii) seems less likely. I'd appreciate any help in completing the proof. Thank you! Note: $\mathcal L$ is a bounded bijective operator on $L^2(\mathbb R_+)$ , in fact, $\| \mathcal L\| = \sqrt\pi$ . The explicit calculations can be found in Rajendra Bhatia's Notes on Functional Analysis , Pg. $26-27$ , and also in Setterqvist E., Unitary Equivalence: A New Approach to the Laplace transform and the Hardy operator. Master’s Thesis, Department of Mathematics Lule ̊a University of Technology, 2005:329 CIV here . Further, see Post 1 , Post 2 and Post 3 .","Let and consider the kernel on . The associated integral operator on is called the Laplace transform , i.e. Show that the Laplace transform is a self-adjoint operator on . This question is similar to another question that I'd asked a few days ago, but the same approach doesn't work since the kernel is not square-integrable - so Fubini's theorem may not be applicable. My work: We want to show for all . We have and So, we must show This can be done easily if Fubini's theorem is applicable. For Fubini's theorem, we require By applying Cauchy-Schwarz inequality twice (as in the linked post's answer), I was able to get Unfortunately, diverges, so this bound is useless. Two possibilities arise: (i) either Fubini's theorem is applicable, and we must find a stronger bound to show , or (ii) we must show that the two integrals are equal using some technique other than Fubini's theorem. To me, (ii) seems less likely. I'd appreciate any help in completing the proof. Thank you! Note: is a bounded bijective operator on , in fact, . The explicit calculations can be found in Rajendra Bhatia's Notes on Functional Analysis , Pg. , and also in Setterqvist E., Unitary Equivalence: A New Approach to the Laplace transform and the Hardy operator. Master’s Thesis, Department of Mathematics Lule ̊a University of Technology, 2005:329 CIV here . Further, see Post 1 , Post 2 and Post 3 .","\mathbb R_+ = [0, \infty) K(x,y) = e^{-xy} \mathbb R_+ \times \mathbb R_+ L^2(\mathbb R_+) \mathcal L (\mathcal L f)(x) = \int_0^\infty K(x,y) f(y)\, dy \mathcal L L^2(\mathbb R_+) \langle \mathcal Lf, g\rangle = \langle f, \mathcal Lg\rangle f,g\in L^2(\mathbb R_+) \begin{align*}
\langle \mathcal Lf,g\rangle &= \int_0^\infty \mathcal Lf(x) \overline{g(x)} \, dx\\
&= \int_0^\infty \int_0^\infty e^{-xy} f(y) \overline{g(x)}\, dy\, dx
\end{align*} \begin{align*}
\langle f, \mathcal L g\rangle &= \int_0^\infty f(x) \overline{\mathcal Lg(x)}\, dx\\ &= \int_0^\infty \int_0^\infty e^{-xy} f(x) \overline{g(y)} \, dy\, dx\\&=  
\int_0^\infty \int_0^\infty e^{-xy} f(y) \overline{g(x)} \, dx\, dy  
\end{align*} \int_0^\infty \int_0^\infty e^{-xy} f(y) \overline{g(x)}\, dy\, dx =  \int_0^\infty \int_0^\infty e^{-xy} f(y) \overline{g(x)} \, dx\, dy  \int_0^\infty \int_0^\infty |e^{-xy}| |f(y)| |g(x)| \, dx\, dy < \infty \int_0^\infty \int_0^\infty |e^{-xy}| |f(y)| |g(x)| \, dx\, dy \le \|f\|_2 \|g\|_2 \left(\int_0^\infty \int_0^\infty e^{-2xy}\, dx\, dy \right)^{1/2} \int_0^\infty \int_0^\infty e^{-2xy}\, dx\, dy \int_0^\infty \int_0^\infty |e^{-xy}| |f(y)| |g(x)| \, dx\, dy < \infty \mathcal L L^2(\mathbb R_+) \| \mathcal L\| = \sqrt\pi 26-27","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'improper-integrals', 'fubini-tonelli-theorems']"
42,Distance between two states in a C$^*$-algebra,Distance between two states in a C-algebra,^*,"$\def\h{\mathcal H}$ $\def\bh{\mathcal B(\h)}$ $\def\cA{\mathcal A}$ Let $\h$ be a Hilbert space, and $\xi,\eta\in\h$ with $\|\xi\|=\|\eta\|=1$ . Then $$ \phi(A)=\langle A\xi,\xi\rangle,\qquad \psi(A)=\langle A\eta,\eta\rangle $$ are (pure) states on $\bh$ . We are looking for a proof that $$\tag{$*$} \|\phi-\psi\|=2\sqrt{1-|\langle\xi,\eta\rangle|^2}. $$ While $(*)$ is well-known, I couldn't find a proof in the literature available to me. So I'm posting a proof below.","Let be a Hilbert space, and with . Then are (pure) states on . We are looking for a proof that While is well-known, I couldn't find a proof in the literature available to me. So I'm posting a proof below.","\def\h{\mathcal H} \def\bh{\mathcal B(\h)} \def\cA{\mathcal A} \h \xi,\eta\in\h \|\xi\|=\|\eta\|=1 
\phi(A)=\langle A\xi,\xi\rangle,\qquad \psi(A)=\langle A\eta,\eta\rangle
 \bh \tag{*}
\|\phi-\psi\|=2\sqrt{1-|\langle\xi,\eta\rangle|^2}.
 (*)","['functional-analysis', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras']"
43,Is broken Sobolev space a Sobolev space?,Is broken Sobolev space a Sobolev space?,,"The definition of a broken Sobolev space is as follows. Given infinite-dimensional (but mesh-dependent) spaces on an open bounded domain $\Omega \in R^3$ with Lipschitz boundary. The mesh, denoted by $\Omega_h$ , is a disjoint partitioning of $\Omega$ into open elements $K$ such that the union of their closures is the closure of $\Omega$ . The collection of element boundaries $\partial K$ for all $K \in \Omega_h$ , is denoted by $\partial \Omega_h$ . We assume that each element boundary $\partial K$ is Lipschitz. The shape of the elements is otherwise arbitrary for now. The broken Sobolev space is defined as $$\hat{H}^{1}\left(\Omega_{h}\right)=\left\{u \in L^{2}(\Omega):\left.u\right|_{K} \in H^{1}(K), K \in \Omega_{h}\right\},$$ where $H^1$ is the standard Sobolev space. According to my understanding, if $\Omega_h$ can be partitioned into a finite number of subdomains, $K$ 's, and because the union of the intersections of $K$ 's is a set of measure zero, then $\forall u \in \hat{H}^1, \int_{\Omega_h} \sum_{|\alpha|\leq 1} (D^\alpha u)^2 dx = \sum_{K=1}^n \int_K  \sum_{|\alpha|\leq 1} (D^\alpha u)^2 dx$ . This seems mean that $\hat{H}^{1}$ is also a Sobolev space. If the partion of $\Omega_h$ consists of an infinite number of $K$ 's, then the equality of the integration above would not hold. In this case, $\hat{H}^{1}$ is not a Sobolev space. Am I right about the above two statements? Thanks a lot.","The definition of a broken Sobolev space is as follows. Given infinite-dimensional (but mesh-dependent) spaces on an open bounded domain with Lipschitz boundary. The mesh, denoted by , is a disjoint partitioning of into open elements such that the union of their closures is the closure of . The collection of element boundaries for all , is denoted by . We assume that each element boundary is Lipschitz. The shape of the elements is otherwise arbitrary for now. The broken Sobolev space is defined as where is the standard Sobolev space. According to my understanding, if can be partitioned into a finite number of subdomains, 's, and because the union of the intersections of 's is a set of measure zero, then . This seems mean that is also a Sobolev space. If the partion of consists of an infinite number of 's, then the equality of the integration above would not hold. In this case, is not a Sobolev space. Am I right about the above two statements? Thanks a lot.","\Omega \in R^3 \Omega_h \Omega K \Omega \partial K K \in \Omega_h \partial \Omega_h \partial K \hat{H}^{1}\left(\Omega_{h}\right)=\left\{u \in L^{2}(\Omega):\left.u\right|_{K} \in H^{1}(K), K \in \Omega_{h}\right\}, H^1 \Omega_h K K \forall u \in \hat{H}^1, \int_{\Omega_h} \sum_{|\alpha|\leq 1} (D^\alpha u)^2 dx = \sum_{K=1}^n \int_K  \sum_{|\alpha|\leq 1} (D^\alpha u)^2 dx \hat{H}^{1} \Omega_h K \hat{H}^{1}","['functional-analysis', 'finite-element-method']"
44,"If $\dim (V/ W) = 1$, what can we say about $\dim(\overline{V}/\overline{W})$","If , what can we say about",\dim (V/ W) = 1 \dim(\overline{V}/\overline{W}),"Let $X$ be a Banach space and $W\subset V \subset X$ are two subspaces of $X$ . Suppose now we know $\dim(V/ W) = 1$ , then what can we say about the dimension $\dim(\overline{V}/\overline{W})$ ? Here $\overline{V}$ and $\overline{W}$ are the closures of $V$ and $W$ in $X$ , respectively. Is it true that $\dim(\overline{V}/\overline{W})\leq1$ ? Any hint will be appreciated. Thanks!","Let be a Banach space and are two subspaces of . Suppose now we know , then what can we say about the dimension ? Here and are the closures of and in , respectively. Is it true that ? Any hint will be appreciated. Thanks!",X W\subset V \subset X X \dim(V/ W) = 1 \dim(\overline{V}/\overline{W}) \overline{V} \overline{W} V W X \dim(\overline{V}/\overline{W})\leq1,"['functional-analysis', 'banach-spaces', 'normed-spaces', 'quotient-spaces']"
45,"Show that in a Hilbert space, $||x+\alpha y|| \ge ||x|| \,\forall\,\alpha\in\mathbb{C}\implies (x,y)=0$","Show that in a Hilbert space,","||x+\alpha y|| \ge ||x|| \,\forall\,\alpha\in\mathbb{C}\implies (x,y)=0","We have a Hilbert space, equipped with the norm $||\cdot||=\sqrt{(\cdot,\cdot)}$ , and we're given the following inequality holds for all $\alpha\in\mathbb{C}: ||x+\alpha y||\ge ||x||$ How would you go about showing this inequality leads to $(x,y)=0$ Squaring both sides I get to $(x,x)+\overline{\alpha}(x,y)+\alpha\overline{(x,y)}+|\alpha|^2(y,y)\ge (x,x)\implies \overline{\alpha}(x,y)+\alpha\overline{(x,y)}+|\alpha|^2(y,y)\ge 0$ I can write this in terms of real or imaginary parts depending on choice of $\alpha$ but I'm perplexed how to make this something meaningful. Any help appreciated.","We have a Hilbert space, equipped with the norm , and we're given the following inequality holds for all How would you go about showing this inequality leads to Squaring both sides I get to I can write this in terms of real or imaginary parts depending on choice of but I'm perplexed how to make this something meaningful. Any help appreciated.","||\cdot||=\sqrt{(\cdot,\cdot)} \alpha\in\mathbb{C}: ||x+\alpha y||\ge ||x|| (x,y)=0 (x,x)+\overline{\alpha}(x,y)+\alpha\overline{(x,y)}+|\alpha|^2(y,y)\ge (x,x)\implies \overline{\alpha}(x,y)+\alpha\overline{(x,y)}+|\alpha|^2(y,y)\ge 0 \alpha","['complex-analysis', 'functional-analysis', 'hilbert-spaces', 'normed-spaces', 'inner-products']"
46,Bounded linear map which is not continuous,Bounded linear map which is not continuous,,"Definition: A subset $B$ of the TVS $E$ is said to be bounded if to every neighborhood of zero $U$ in $E$ there is a number $\lambda >0$ such that $B \subset \lambda U.$ Definition: Let $E,F$ be two TVS, and $u$ a linear map of $E$ into $F$ . Let us say that $u$ is bounded if, for every bounded subset $B$ of $E$ , $u(B)$ is a bounded subset of $F$ . We have the following result: Theorem: Let $E$ be a metrizable space TVS. If a linear map of $E$ into a TVS $F$ is bounded, it is continuous. My question: Is there a counterexample of a bounded linear map which is not continuous? If this example exists, the space $E$ cannot be metrizable.","Definition: A subset of the TVS is said to be bounded if to every neighborhood of zero in there is a number such that Definition: Let be two TVS, and a linear map of into . Let us say that is bounded if, for every bounded subset of , is a bounded subset of . We have the following result: Theorem: Let be a metrizable space TVS. If a linear map of into a TVS is bounded, it is continuous. My question: Is there a counterexample of a bounded linear map which is not continuous? If this example exists, the space cannot be metrizable.","B E U E \lambda >0 B \subset \lambda U. E,F u E F u B E u(B) F E E F E","['functional-analysis', 'continuity', 'topological-vector-spaces']"
47,Image of Borel functional calculus of a bounded normal operator,Image of Borel functional calculus of a bounded normal operator,,"Let $ H $ be a (not necessarily separable) Hilbert space and $ N $ be a bounded normal operator on $ H $ . For a bounded Borel function $ \phi\colon \sigma(N) \to \mathbb{C} $ on the spectrum of $ N $ , we consider Borel functional calculus $$ \phi(N) = \int_{\sigma(N)} \phi \,dE, $$ where $ E $ is the spectral measure of $ N $ . I want to find the image of Borel functional calculus $$ X = \{\phi(N) \mid \text{$ \phi\colon \sigma(N) \to \mathbb{C} $ is a bounded Borel function}\}. $$ To my understanding, $ X \subseteq W^*(N) $ , where $ W^*(N) $ is the von Neumann algebra generated by $ N $ (Proposition IX.8.1 of Conway’s A Course in Functional Analysis (2nd edition)), and $ X = W^*(N) $ if $ H $ is separable (Lemma IX.8.7 of Conway). I tried to generalize the proof of Conway’s Lemma IX.8.7 to non-separable case, but it seems that separability (or, more specifically, existence of a separating vector for $ W^*(N) $ ) is essential for Conway’s proof. So, my question is: Does $ X = W^*(N) $ hold if we don’t assume that $ H $ is separable? If not, how can we describe $ X $ ?","Let be a (not necessarily separable) Hilbert space and be a bounded normal operator on . For a bounded Borel function on the spectrum of , we consider Borel functional calculus where is the spectral measure of . I want to find the image of Borel functional calculus To my understanding, , where is the von Neumann algebra generated by (Proposition IX.8.1 of Conway’s A Course in Functional Analysis (2nd edition)), and if is separable (Lemma IX.8.7 of Conway). I tried to generalize the proof of Conway’s Lemma IX.8.7 to non-separable case, but it seems that separability (or, more specifically, existence of a separating vector for ) is essential for Conway’s proof. So, my question is: Does hold if we don’t assume that is separable? If not, how can we describe ?"," H   N   H   \phi\colon \sigma(N) \to \mathbb{C}   N  
\phi(N) = \int_{\sigma(N)} \phi \,dE,
  E   N  
X = \{\phi(N) \mid \text{ \phi\colon \sigma(N) \to \mathbb{C}  is a bounded Borel function}\}.
  X \subseteq W^*(N)   W^*(N)   N   X = W^*(N)   H   W^*(N)   X = W^*(N)   H   X ","['functional-analysis', 'operator-algebras', 'functional-calculus']"
48,"What's the difference between the Wiener measure on $C^0[0,1]$ and the distribution function of a Brownian motion?",What's the difference between the Wiener measure on  and the distribution function of a Brownian motion?,"C^0[0,1]","Let $(\Omega,\mathcal A, P)$ be a probability space and $B_t$ a standard Brownian motion on that space ( $t \in [0,1]$ ). I am trying to understand what is called the ""Wiener measure"". I never had a course on that, but I always thought that what is called the Wiener measure is simply the dynamical Gaussian measure associated with the Brownian motion, that is $\mu_t(A)= P(B_t \in A)=\int_A \frac{1}{\sqrt{2\pi t}} e^{-x^2/2\sqrt{t}} \, dx$ $\forall A \in \mathcal B(\mathbb R)$ , so for each $t>0$ , $\mu_t$ is a Gaussian measure (the cumulative distribution function/pushforward measure of the Brownian motion). But I just discovered that it is not exactly the case. The Wiener measure is a measure on $(C^0[0,1], ||.||_\infty)$ . So a measure on an infinite dimensional space. How do we even build such measure ? Intuitively, $\mu_t$ is ""the projection on one dimension"" of the Wiener measure. So the Wiener measure is able to measure much more than just sets in $\mathcal B(\mathbb R)$ . It can measure sets in $\mathcal B(C^0[0,1])$ . I have many questions on the Wiener measure, call it $W$ : How is $W(A)$ defined for $A \in \mathcal B(C^0[0,1]) $ ? Does it have a density ? With regard to what measure ? Is it enough the give all ""one dimensional projection"" of a measure on an infinite dimensional space to define this measure ? So in that case, is knowing all $\mu_t$ enough to build $W$ ? How to do that ? Is knowing $W$ enough to build all $\mu_t$ ? If so, how to do that ? Same question but for a general measure on an infinite dimensional space, not necessarily $W$ . What's the connection between $W$ and $B$ besides through the one dimensional projections ? Is $W$ the pushforward measure of a Brownian motion on $\mathbb R ^\infty$ ? Is the latter well defined ?","Let be a probability space and a standard Brownian motion on that space ( ). I am trying to understand what is called the ""Wiener measure"". I never had a course on that, but I always thought that what is called the Wiener measure is simply the dynamical Gaussian measure associated with the Brownian motion, that is , so for each , is a Gaussian measure (the cumulative distribution function/pushforward measure of the Brownian motion). But I just discovered that it is not exactly the case. The Wiener measure is a measure on . So a measure on an infinite dimensional space. How do we even build such measure ? Intuitively, is ""the projection on one dimension"" of the Wiener measure. So the Wiener measure is able to measure much more than just sets in . It can measure sets in . I have many questions on the Wiener measure, call it : How is defined for ? Does it have a density ? With regard to what measure ? Is it enough the give all ""one dimensional projection"" of a measure on an infinite dimensional space to define this measure ? So in that case, is knowing all enough to build ? How to do that ? Is knowing enough to build all ? If so, how to do that ? Same question but for a general measure on an infinite dimensional space, not necessarily . What's the connection between and besides through the one dimensional projections ? Is the pushforward measure of a Brownian motion on ? Is the latter well defined ?","(\Omega,\mathcal A, P) B_t t \in [0,1] \mu_t(A)= P(B_t \in A)=\int_A \frac{1}{\sqrt{2\pi t}} e^{-x^2/2\sqrt{t}} \, dx \forall A \in \mathcal B(\mathbb R) t>0 \mu_t (C^0[0,1], ||.||_\infty) \mu_t \mathcal B(\mathbb R) \mathcal B(C^0[0,1]) W W(A) A \in \mathcal B(C^0[0,1])  \mu_t W W \mu_t W W B W \mathbb R ^\infty","['functional-analysis', 'probability-theory', 'measure-theory', 'brownian-motion']"
49,Continuity of $\int_{0}^{1} \frac{f(t)^2}{\sqrt{t}}dt$ wrt Lp norm,Continuity of  wrt Lp norm,\int_{0}^{1} \frac{f(t)^2}{\sqrt{t}}dt,"Let $F:C^{0}[0,1]\rightarrow \mathbb{R}$ , $F(f)=\displaystyle\int_{0}^{1} \frac{f(t)^2}{\sqrt{t}}dt$ How to prove that $F$ is continuous wrt the metric induced by $L^{p}$ norm for $2<p\leq \infty$ UPDATE: The statement doesn't hold true for $2<p\leq 4$ . Thanks MaoWao and Sangchul Lee!","Let , How to prove that is continuous wrt the metric induced by norm for UPDATE: The statement doesn't hold true for . Thanks MaoWao and Sangchul Lee!","F:C^{0}[0,1]\rightarrow \mathbb{R} F(f)=\displaystyle\int_{0}^{1} \frac{f(t)^2}{\sqrt{t}}dt F L^{p} 2<p\leq \infty 2<p\leq 4",['functional-analysis']
50,Minimize $q\mapsto\int\frac{(pf)^2}q\:{\rm d}\lambda$ subject to $\int q\:{\rm }\lambda=1$ using the method of Lagrange multipliers,Minimize  subject to  using the method of Lagrange multipliers,q\mapsto\int\frac{(pf)^2}q\:{\rm d}\lambda \int q\:{\rm }\lambda=1,"Let $(E,\mathcal E,\lambda)$ be a measure space $p:E\to[0,\infty)$ be $\mathcal E$ -measurable with $$\int p\:{\rm d}\lambda=1$$ $\mu:=p\lambda$ $f\in\mathcal L^1(\mu)$ I want to minimize $$\Phi(q):=\int_{\left\{\:q\:>\:0\:\right\}}\frac{(pf)^2}q\:{\rm d}\lambda$$ over all $\mathcal E$ -measurable $q:E\to[0,\infty)$ subject to $$\int q\:{\rm d}\lambda=1.\tag1$$ I already know that the solution is proportional to $p|f|$ , but I want to verify this rigorously. I want to use he method of Lagrange multipliers . We should be able to rephrase the problem in the following way: We want to minimize a functional on a Banach space subject to the condition that the norm of the candidate is $1$ . We would clearly take the Banach space $\mathcal L^1(\mu)$ (note that $(1)$ is noting else than the norm of $q$ in this space). How do we need to proceed in detail? It's clear to me that it's sufficient to find a stationary point of the Lagrange function. It's then easy to show that the resulting candidate solution is a minimum (using the Cauchy-Schwarz inequality). Please take note of my related question: How can we compute the Fréchet derivative of $q\mapsto\int\frac{(pf)^2}q\:{\rm d}\lambda$? .","Let be a measure space be -measurable with I want to minimize over all -measurable subject to I already know that the solution is proportional to , but I want to verify this rigorously. I want to use he method of Lagrange multipliers . We should be able to rephrase the problem in the following way: We want to minimize a functional on a Banach space subject to the condition that the norm of the candidate is . We would clearly take the Banach space (note that is noting else than the norm of in this space). How do we need to proceed in detail? It's clear to me that it's sufficient to find a stationary point of the Lagrange function. It's then easy to show that the resulting candidate solution is a minimum (using the Cauchy-Schwarz inequality). Please take note of my related question: How can we compute the Fréchet derivative of $q\mapsto\int\frac{(pf)^2}q\:{\rm d}\lambda$? .","(E,\mathcal E,\lambda) p:E\to[0,\infty) \mathcal E \int p\:{\rm d}\lambda=1 \mu:=p\lambda f\in\mathcal L^1(\mu) \Phi(q):=\int_{\left\{\:q\:>\:0\:\right\}}\frac{(pf)^2}q\:{\rm d}\lambda \mathcal E q:E\to[0,\infty) \int q\:{\rm d}\lambda=1.\tag1 p|f| 1 \mathcal L^1(\mu) (1) q","['functional-analysis', 'measure-theory', 'optimization', 'lp-spaces', 'lagrange-multiplier']"
51,Riesz-Markov-Kakutani representation theorem: qualitative or abstract proofs.,Riesz-Markov-Kakutani representation theorem: qualitative or abstract proofs.,,"I am referring to the famous result which states: Let X be a locally compact Hausdorff space. For any positive linear functional $\psi$ on $C_c(X)$ , there is a unique regular Borel measure μ on X such that $$\psi(f)=\int_{X}fd\mu(x)\ \\ \forall f\in C_c(x)$$ The proofs I read of this result involve very tricky and seemingly articificial calculations: they are very quatitative and make a lot of use of $\epsilon-\delta$ arguments. I absolutely do not mean they are less truthful whatsoever, nonetheless I find it strange there is not a 'qualitative' proof of this result, as we have for a lot of important duality theorems. Do anyone know some enlightening proof?","I am referring to the famous result which states: Let X be a locally compact Hausdorff space. For any positive linear functional on , there is a unique regular Borel measure μ on X such that The proofs I read of this result involve very tricky and seemingly articificial calculations: they are very quatitative and make a lot of use of arguments. I absolutely do not mean they are less truthful whatsoever, nonetheless I find it strange there is not a 'qualitative' proof of this result, as we have for a lot of important duality theorems. Do anyone know some enlightening proof?",\psi C_c(X) \psi(f)=\int_{X}fd\mu(x)\ \\ \forall f\in C_c(x) \epsilon-\delta,"['functional-analysis', 'measure-theory', 'soft-question', 'alternative-proof', 'duality-theorems']"
52,"Intuition: $]0,\infty[: \{x \mapsto \arctan{(nx)}: n \in \mathbb N\}$",Intuition:,"]0,\infty[: \{x \mapsto \arctan{(nx)}: n \in \mathbb N\}","Let $X=]0,\infty[: \{x \mapsto \arctan{(nx)}: n \in \mathbb N \}$ so $f_{n}: ]0,\infty[ \to \mathbb R, x \mapsto \arctan{(nx)}$ for all $n \in \mathbb N$ There is a statement, saying (w.r.t. $d_{\infty}$ ): $1.$ $(f_{n})_{n}$ is equicontinuous $2.$ $(f_{n})_{n}$ is not uniformly equicontinuous $3.$ each function $f_{n}$ is uniformly continuous. The difference between $1.$ and $2.$ is clear but I do not understand why $(f_{n})_{n}$ is equicontinuous because with every increasing $n$ my slope close to $0$ increases, so my chosen $\delta$ will need to get smaller and smaller. And surely if $1.$ and $3.$ are true our sequence $(f_{n})_{n}$ necessarily has to be uniformly equicontinuous. Why is this not the case, any explanations are greatly appreciated.","Let so for all There is a statement, saying (w.r.t. ): is equicontinuous is not uniformly equicontinuous each function is uniformly continuous. The difference between and is clear but I do not understand why is equicontinuous because with every increasing my slope close to increases, so my chosen will need to get smaller and smaller. And surely if and are true our sequence necessarily has to be uniformly equicontinuous. Why is this not the case, any explanations are greatly appreciated.","X=]0,\infty[: \{x \mapsto \arctan{(nx)}: n \in \mathbb N \} f_{n}: ]0,\infty[ \to \mathbb R, x \mapsto \arctan{(nx)} n \in \mathbb N d_{\infty} 1. (f_{n})_{n} 2. (f_{n})_{n} 3. f_{n} 1. 2. (f_{n})_{n} n 0 \delta 1. 3. (f_{n})_{n}","['functional-analysis', 'convergence-divergence', 'continuity']"
53,A sufficient and necessary condition for a special linear operator to be compact,A sufficient and necessary condition for a special linear operator to be compact,,"Suppose $X$ is Banach and $T\in B(X)$ (i.e. $T$ is a linear and continuous map and $T:X \to X$ ). Also, suppose $\exists c > 0$ , s.t. $\|Tx\| \ge c\|x\|, \forall x\in X$ . Prove $T$ is a compact operator if and only if $X$ is finite dimensional. "" $X$ is finite dimensional $\implies$ $T$ is compact"" is easy to show. To prove the other side, at first, I made a mistake, thinking $X$ is reflexive. Then this work can be easily done by the fact that any sequence of a reflexive linear space has a weakly convergent subsequence and $T$ is completely continuous (since $T$ is compact). But this is not the situation. So how to prove "" $T$ is compact $\implies X$ is finite dimensional""?","Suppose is Banach and (i.e. is a linear and continuous map and ). Also, suppose , s.t. . Prove is a compact operator if and only if is finite dimensional. "" is finite dimensional is compact"" is easy to show. To prove the other side, at first, I made a mistake, thinking is reflexive. Then this work can be easily done by the fact that any sequence of a reflexive linear space has a weakly convergent subsequence and is completely continuous (since is compact). But this is not the situation. So how to prove "" is compact is finite dimensional""?","X T\in B(X) T T:X \to X \exists c > 0 \|Tx\| \ge c\|x\|, \forall x\in X T X X \implies T X T T T \implies X","['functional-analysis', 'weak-convergence', 'compact-operators']"
54,"For a Schwartz function $f$, if $\int_{\mathbb{R}} f(x) x^n dx = 0$ for all nonnegative integers $n$, is $f$ identically 0?","For a Schwartz function , if  for all nonnegative integers , is  identically 0?",f \int_{\mathbb{R}} f(x) x^n dx = 0 n f,"This is an old exam question I'm practicing with. The associated hint is to use the Fourier transform. I'm pretty lost, but here are my thoughts so far. First, in this old stack exchange question a user referenced Classical Fourier Analysis by Loukas Grafakos, which in Prop 2.3.25 defines $S_\infty (\mathbb{R}^n)$ to be a subspace of $S(\mathbb{R}^n)$ such that for $f \in S(\mathbb{R}^n)$ $$\int_{\mathbb{R}^n} x^\alpha f(x) = 0$$ which leads me to think there are non-trivial $f$ in this space. Moreover, as user Jonas Teuwen wrote in the question linked above, the Fourier transform maps the Schwartz function to itself, so the question is equivalently asking whether the Fourier tranform evaluated at $0$ of $\hat{x^\alpha} f(x) = 0$ implies that $f$ is identically $0$ . Since $x^\alpha \mapsto i^\alpha d/dx^\alpha$ , we want $f$ so that $$\frac{d}{dx^{\alpha}} \hat{f(x)} = 0$$ when evaluated at $x = 0$ . But I'm at a loss as to how to construct such a function. Any help or hints would be very much appreciated!","This is an old exam question I'm practicing with. The associated hint is to use the Fourier transform. I'm pretty lost, but here are my thoughts so far. First, in this old stack exchange question a user referenced Classical Fourier Analysis by Loukas Grafakos, which in Prop 2.3.25 defines to be a subspace of such that for which leads me to think there are non-trivial in this space. Moreover, as user Jonas Teuwen wrote in the question linked above, the Fourier transform maps the Schwartz function to itself, so the question is equivalently asking whether the Fourier tranform evaluated at of implies that is identically . Since , we want so that when evaluated at . But I'm at a loss as to how to construct such a function. Any help or hints would be very much appreciated!",S_\infty (\mathbb{R}^n) S(\mathbb{R}^n) f \in S(\mathbb{R}^n) \int_{\mathbb{R}^n} x^\alpha f(x) = 0 f 0 \hat{x^\alpha} f(x) = 0 f 0 x^\alpha \mapsto i^\alpha d/dx^\alpha f \frac{d}{dx^{\alpha}} \hat{f(x)} = 0 x = 0,"['functional-analysis', 'fourier-analysis', 'fourier-transform', 'schwartz-space']"
55,Bounded and Self-adjoint Linear Operator and Its Inverse,Bounded and Self-adjoint Linear Operator and Its Inverse,,"Let $H$ be a Hilbert space and suppose that $A:H \rightarrow H$ is a bounded, self-adjoint linear operator such that there is a constant $c>0$ with $c\|x\| \leq \|Ax\|$ for all $x\in H$ . Prove that $A^{-1}:H \rightarrow H$ exist and it is bounded. Hint: For ontoness of $A$ it is enough to show that range of $A$ is closed. Why ? Please help me, if you have any good answer in this question.","Let be a Hilbert space and suppose that is a bounded, self-adjoint linear operator such that there is a constant with for all . Prove that exist and it is bounded. Hint: For ontoness of it is enough to show that range of is closed. Why ? Please help me, if you have any good answer in this question.",H A:H \rightarrow H c>0 c\|x\| \leq \|Ax\| x\in H A^{-1}:H \rightarrow H A A,"['functional-analysis', 'self-adjoint-operators']"
56,Prove that $T$ is bounded and find its norm,Prove that  is bounded and find its norm,T,"Consider $T\colon C[0,1] \to C[0,1]$ by $$T(f) = \int_{0}^1 \sin(t) \;f(t) \;dt$$ Show that $T$ is a bounded linear operator. Find the norm of $T$ . This is my solution Is it true? Thanks a lot..",Consider by Show that is a bounded linear operator. Find the norm of . This is my solution Is it true? Thanks a lot..,"T\colon C[0,1] \to C[0,1] T(f) = \int_{0}^1 \sin(t) \;f(t) \;dt T T","['functional-analysis', 'operator-theory', 'normed-spaces']"
57,"Integration Representation of Bounded Bilinear Functional on $L_2([0,1])$",Integration Representation of Bounded Bilinear Functional on,"L_2([0,1])","Suppose $B(f,g)$ is a bilinear functional on $L_2([0,1])$ , satisfying $|B(f,g)|\leq M \|f\|_2\|g\|_2$ for some $M>0$ . My question is whether there always exists a function $\xi_B(x,y)$ (Maybe essentially bounded?) such that $$B(f,g) = \int_{[0,1]^{\otimes2}}\xi_B(x,y)f(x)g(y)dxdy.$$ One possible idea to prove it is to use Riesz Representation theorem first and have $B(f,g) = <\tau_B f,g>$ , where $\tau_B$ is a bounded linear operator from $L_2([0,1])$ to $L_2([0,1])$ and then there might be some results for an integration representation of $\tau_B$ . But I am not sure where can I find results about it. P.S.: In my research, $B(f,g)$ is also symmetric, i.e. $B(f,g)=B(g,f)$ , or, as a result, $\tau_B$ is self-adjoint. It will also be good if you can help me proving integration representation with this extra condition. I don't think it will be very useful though.","Suppose is a bilinear functional on , satisfying for some . My question is whether there always exists a function (Maybe essentially bounded?) such that One possible idea to prove it is to use Riesz Representation theorem first and have , where is a bounded linear operator from to and then there might be some results for an integration representation of . But I am not sure where can I find results about it. P.S.: In my research, is also symmetric, i.e. , or, as a result, is self-adjoint. It will also be good if you can help me proving integration representation with this extra condition. I don't think it will be very useful though.","B(f,g) L_2([0,1]) |B(f,g)|\leq M \|f\|_2\|g\|_2 M>0 \xi_B(x,y) B(f,g) = \int_{[0,1]^{\otimes2}}\xi_B(x,y)f(x)g(y)dxdy. B(f,g) = <\tau_B f,g> \tau_B L_2([0,1]) L_2([0,1]) \tau_B B(f,g) B(f,g)=B(g,f) \tau_B","['real-analysis', 'functional-analysis', 'operator-theory']"
58,Convolution of a compactly supported function and an $L^1$ function.,Convolution of a compactly supported function and an  function.,L^1,"I have these related questions here that I could really use some help on. I believe there is a related question here although I don't think it is exactly the same... 1) Let $f\in L^1(\mathbb R)$ and $\varphi$ a smooth compactly   supported function. Prove that $f\ast \varphi$ is a smooth function   whose derivative is $f\ast \varphi'$ . Any help would be much appreciated. I have been trying to work on this for the past couple days but all my ideas didn't lead me very far. Namely, I was trying to use the definition of a convolution. I am not sure though how the smooth and compactly supported $L^1$ function fits into this...","I have these related questions here that I could really use some help on. I believe there is a related question here although I don't think it is exactly the same... 1) Let and a smooth compactly   supported function. Prove that is a smooth function   whose derivative is . Any help would be much appreciated. I have been trying to work on this for the past couple days but all my ideas didn't lead me very far. Namely, I was trying to use the definition of a convolution. I am not sure though how the smooth and compactly supported function fits into this...",f\in L^1(\mathbb R) \varphi f\ast \varphi f\ast \varphi' L^1,"['real-analysis', 'functional-analysis', 'hilbert-spaces', 'convolution']"
59,"Proving that $d(x,\ker f) = \frac{|f(x)|}{\|f\|}$ if $f \in X^*$",Proving that  if,"d(x,\ker f) = \frac{|f(x)|}{\|f\|} f \in X^*","Exercise : Let $(X,\|\cdot\|)$ be a normed space and $V\subseteq X$ . The distance of one point $x \in X$ to $V$ is defined by : $$d(x,V)=\inf\{\|x-v\|: v \in V\}$$ Show that if $f \in X^*=B(X,\mathbb R)$ which is the space of the bounded linear functionals, thefe for all $x \in X$ it is : $$d(x,\ker f)=\frac{|f(x)|}{\|f\|}$$ Attempt - thoughts : So, first of all, since $f$ is a bounded linear functional, then there exists some $M>0$ such that : $$\|f(x)\| \leq M\|x\|$$ Also, the operator norm is given by : $$\|f\| = \sup\bigg\{\frac{\|f(x)\|}{\|x\|} : x \in X, x \neq 0\bigg\}$$ Now, the kernel of the function $f$ is defined as : $$\ker f = \{x \in X : f(x) = 0\}$$ Essentialy, we need to calculate : $$d(x,\ker f) = \inf\{\|x-v\|:v \in \ker f\}$$ Now, of course, the kernel of $f$ is a subspace of $X$ and also, we know that : $$\text{co}\dim\{\ker f\} = 1$$ I can't see how to combine these facts yielded by the hypothesis of the exercise, though, to continue to an attempted solution. Any hints, tips or thorough elaborations will be greatly appreciated !","Exercise : Let be a normed space and . The distance of one point to is defined by : Show that if which is the space of the bounded linear functionals, thefe for all it is : Attempt - thoughts : So, first of all, since is a bounded linear functional, then there exists some such that : Also, the operator norm is given by : Now, the kernel of the function is defined as : Essentialy, we need to calculate : Now, of course, the kernel of is a subspace of and also, we know that : I can't see how to combine these facts yielded by the hypothesis of the exercise, though, to continue to an attempted solution. Any hints, tips or thorough elaborations will be greatly appreciated !","(X,\|\cdot\|) V\subseteq X x \in X V d(x,V)=\inf\{\|x-v\|: v \in V\} f \in X^*=B(X,\mathbb R) x \in X d(x,\ker f)=\frac{|f(x)|}{\|f\|} f M>0 \|f(x)\| \leq M\|x\| \|f\| = \sup\bigg\{\frac{\|f(x)\|}{\|x\|} : x \in X, x \neq 0\bigg\} f \ker f = \{x \in X : f(x) = 0\} d(x,\ker f) = \inf\{\|x-v\|:v \in \ker f\} f X \text{co}\dim\{\ker f\} = 1","['real-analysis', 'functional-analysis', 'operator-theory']"
60,"Prove that the right shift operator $S(x_1,x_2, \dots) = (0,x_1,x_2,\dots)$ is bounded.",Prove that the right shift operator  is bounded.,"S(x_1,x_2, \dots) = (0,x_1,x_2,\dots)","Exercise : Let $S: l^1 \to l^1$ be the right-shift operator : $$S(x_1,x_2,\dots) = (0,x_1,x_2,\dots)$$ Prove that $S$ is bounded and find its norm. Attempt : The space $l^1$ is : $$l^1 = \{(x=(x_n) : \sum_{i=1}^\infty x_n < + \infty\}$$ To show that the operator $S$ is bounded, I must show that : $$\exists \; M>0 : \|Sx\|\leq M\|x\|$$ But I can't really see how to proceed on this particular proof without having any knowledge of the norm that should be used. Shall the norm of $l^1$ space be used ? If so, what does  ""find the norm of the operator S"" ? I would really appreciate any tips/solutions or clarifications regarding this particular exercise. Note : I have NOT been introduced to isometries in my Functional Analysis class yet, so I am looking for an elementary bounded operator approach.","Exercise : Let be the right-shift operator : Prove that is bounded and find its norm. Attempt : The space is : To show that the operator is bounded, I must show that : But I can't really see how to proceed on this particular proof without having any knowledge of the norm that should be used. Shall the norm of space be used ? If so, what does  ""find the norm of the operator S"" ? I would really appreciate any tips/solutions or clarifications regarding this particular exercise. Note : I have NOT been introduced to isometries in my Functional Analysis class yet, so I am looking for an elementary bounded operator approach.","S: l^1 \to l^1 S(x_1,x_2,\dots) = (0,x_1,x_2,\dots) S l^1 l^1 = \{(x=(x_n) : \sum_{i=1}^\infty x_n < + \infty\} S \exists \; M>0 : \|Sx\|\leq M\|x\| l^1","['real-analysis', 'functional-analysis', 'operator-theory']"
61,What are the connections between square integrable functions in the context of Fourier series and least squares regression?,What are the connections between square integrable functions in the context of Fourier series and least squares regression?,,"$L^2([0,1])$ integrability is a condition to express a periodic function as a Fourier series: $$\left\vert \int_{0}^L f(x)- \int_{0}^L \sum_{k=-n}^n \hat f(k)\;\mathrm e^{\frac{2\pi}{L} kx} \right \vert^2\mathrm dx\to0$$ as $n\to \infty.$ The idea is that the infinity FS converges to the function as mean square convergence. I don't know if any parallels in conceptual framework can be established between this idea of convergence and the estimation of a least square regression (OLS) hyperplane minimizing squared differences between predicted and actual values. And if so, in what sense these concepts are connected. Could the FS be interpreted as an OLS approximation to an overdeteemined problem?","$L^2([0,1])$ integrability is a condition to express a periodic function as a Fourier series: $$\left\vert \int_{0}^L f(x)- \int_{0}^L \sum_{k=-n}^n \hat f(k)\;\mathrm e^{\frac{2\pi}{L} kx} \right \vert^2\mathrm dx\to0$$ as $n\to \infty.$ The idea is that the infinity FS converges to the function as mean square convergence. I don't know if any parallels in conceptual framework can be established between this idea of convergence and the estimation of a least square regression (OLS) hyperplane minimizing squared differences between predicted and actual values. And if so, in what sense these concepts are connected. Could the FS be interpreted as an OLS approximation to an overdeteemined problem?",,"['functional-analysis', 'convergence-divergence', 'fourier-analysis', 'least-squares']"
62,Is the spectrum of an unbounded self-adjoint operator always an unbounded set?,Is the spectrum of an unbounded self-adjoint operator always an unbounded set?,,For a bounded self-adjoint operator $A$ on a Hilbert space $H$ we know that the spectrum is a compact subset of $\mathbb R$ with spectral radius given by the operator norm of $A$. Now assume that $A$ is a densely defined unbounded self-adjoint operator. Can we conclude that the spectrum of $A$ is an unbounded set of the reals?,For a bounded self-adjoint operator $A$ on a Hilbert space $H$ we know that the spectrum is a compact subset of $\mathbb R$ with spectral radius given by the operator norm of $A$. Now assume that $A$ is a densely defined unbounded self-adjoint operator. Can we conclude that the spectrum of $A$ is an unbounded set of the reals?,,"['functional-analysis', 'operator-theory', 'spectral-theory']"
63,$L^{p}_{loc}$ as a normed space,as a normed space,L^{p}_{loc},What norms can we define on $L^p_{\mathrm{loc}}$ ? or What is the most commonly used norm on $L^p_{\mathrm{loc}}$. It is tempting to define  $$\|f\|_{L^p_{\mathrm{loc}}}:=\sup_{K\;\text{is compact}}{\|f\|_{L^{p}(K)}}$$ But this can be infinite for $f\in L^p_{\mathrm{loc}}$.,What norms can we define on $L^p_{\mathrm{loc}}$ ? or What is the most commonly used norm on $L^p_{\mathrm{loc}}$. It is tempting to define  $$\|f\|_{L^p_{\mathrm{loc}}}:=\sup_{K\;\text{is compact}}{\|f\|_{L^{p}(K)}}$$ But this can be infinite for $f\in L^p_{\mathrm{loc}}$.,,"['real-analysis', 'functional-analysis', 'analysis', 'lebesgue-integral']"
64,"For which n differential operator $C^{(n)}[0, 1] \rightarrow C[0,1]$ is compact",For which n differential operator  is compact,"C^{(n)}[0, 1] \rightarrow C[0,1]","I'm trying to learn functional analysis mostly on my own, and I'm stuck with the following task on operator compactness. Consider the operator $Tx(t)=\frac{dx}{dt}$, given $T$ maps $C^{(n)}[0,1]$ to $C[0,1]$. The norm in $C^{(n)}[0,1]$ is given by (standard) $||f||=sup|f^{(n)}| + \dots + sup|f^{'}| + sup|f|$. The task is to find out for which $n$ the operator is compact and bounded. I have successfully managed to prove that under the given norm, $T$ is always bounded. Now, I'm trying to analyse its compactness. It may be possible to make use of Arzela-Ascoli theorem (Let $X$ be a compact metric space and $\{f_{n}\}$ a uniformly bounded equicontinuous sequence of real-valued functions on $X$. Then $\{f_{n}\}$ has a subsequence that converges uniformly on $X$ to a continuous function $f$ on $X$), but I'm unable to move forward with this.","I'm trying to learn functional analysis mostly on my own, and I'm stuck with the following task on operator compactness. Consider the operator $Tx(t)=\frac{dx}{dt}$, given $T$ maps $C^{(n)}[0,1]$ to $C[0,1]$. The norm in $C^{(n)}[0,1]$ is given by (standard) $||f||=sup|f^{(n)}| + \dots + sup|f^{'}| + sup|f|$. The task is to find out for which $n$ the operator is compact and bounded. I have successfully managed to prove that under the given norm, $T$ is always bounded. Now, I'm trying to analyse its compactness. It may be possible to make use of Arzela-Ascoli theorem (Let $X$ be a compact metric space and $\{f_{n}\}$ a uniformly bounded equicontinuous sequence of real-valued functions on $X$. Then $\{f_{n}\}$ has a subsequence that converges uniformly on $X$ to a continuous function $f$ on $X$), but I'm unable to move forward with this.",,"['functional-analysis', 'analysis', 'operator-theory', 'compactness', 'compact-operators']"
65,"Showing that $(\frac{\mathrm d}{\mathrm dx}+1)^{-1}$ is bounded on $L^2(0,\infty)$",Showing that  is bounded on,"(\frac{\mathrm d}{\mathrm dx}+1)^{-1} L^2(0,\infty)","I wish to show that if we consider the symmetric operator $L= i\frac{\mathrm d}{\mathrm dx}$ on $L^2((0,\infty))$, then the resolvent $R(-i) = (L+i)^{-1}$ is everywhere defined on $L^2(0,\infty)$. This reduces to showing that for any $v\in L^2(0,\infty)$, we can solve for $u\in L^2(0,\infty)$ such that  $$ \frac{\mathrm d u}{\mathrm dx}(x)+u(x)=v(x). $$ It is easy to see that we can use Duhamel's formula to get the formula $$ u(x)=\int_0^x\! e^{y-x}v(y)\,\mathrm dy. $$ so I wish to show that $T:v\mapsto u$ is bounded on $L^2$. I would like to apply Hilbert-Schmidt type bounds here, but unfortunately, the kernel $K(x,y)=1_{0\le y\le x}e^{y-x}$ does not lie in $L^2((0,\infty)^2)$. How would one prove that $T$ is bounded?","I wish to show that if we consider the symmetric operator $L= i\frac{\mathrm d}{\mathrm dx}$ on $L^2((0,\infty))$, then the resolvent $R(-i) = (L+i)^{-1}$ is everywhere defined on $L^2(0,\infty)$. This reduces to showing that for any $v\in L^2(0,\infty)$, we can solve for $u\in L^2(0,\infty)$ such that  $$ \frac{\mathrm d u}{\mathrm dx}(x)+u(x)=v(x). $$ It is easy to see that we can use Duhamel's formula to get the formula $$ u(x)=\int_0^x\! e^{y-x}v(y)\,\mathrm dy. $$ so I wish to show that $T:v\mapsto u$ is bounded on $L^2$. I would like to apply Hilbert-Schmidt type bounds here, but unfortunately, the kernel $K(x,y)=1_{0\le y\le x}e^{y-x}$ does not lie in $L^2((0,\infty)^2)$. How would one prove that $T$ is bounded?",,"['functional-analysis', 'partial-differential-equations', 'operator-theory']"
66,Use Baire's Category Theorem to show continuity point of a function,Use Baire's Category Theorem to show continuity point of a function,,"Here is the problem. I want to contruct a collection of sets so that I can use Baire's Category Theorem but no thoughts came into mind. Let $f:\left(0,1\right)\times\left(0,1\right)\rightarrow\mathbb{R}$ be       a real value function. Assume that for every fixed $x$ (respectively       for every fixed $y$) the function $f\left(x,y\right)$ is continuous       in $y$ (respectively in $x$). Prove that there exists a point $\left(x_{0},y_{0}\right)$       where $f$ is continuous. (Hint: use Baire's category theorem) Any help is appreciated!","Here is the problem. I want to contruct a collection of sets so that I can use Baire's Category Theorem but no thoughts came into mind. Let $f:\left(0,1\right)\times\left(0,1\right)\rightarrow\mathbb{R}$ be       a real value function. Assume that for every fixed $x$ (respectively       for every fixed $y$) the function $f\left(x,y\right)$ is continuous       in $y$ (respectively in $x$). Prove that there exists a point $\left(x_{0},y_{0}\right)$       where $f$ is continuous. (Hint: use Baire's category theorem) Any help is appreciated!",,"['functional-analysis', 'analysis']"
67,"Show that $(C([a,b]),\|{\cdot}\|_2)$ is not a complete normed vector space",Show that  is not a complete normed vector space,"(C([a,b]),\|{\cdot}\|_2)","Problem: Show that $(C([a,b]),\|{\cdot}\|_2)$ is not a complete normed vector space. I have tried to proceed along the lines given in the accepted answer, and subsequent comment, to this question: Example of a non complete normed vector space. Although, I am running into difficulties and wondering if the example really generalises so well when we have a general $[a,b]$ . Is the Cauchy sequence I have chosen below a valid one, or have I overlooked a much simpler example to use in this case? Attempt: In order to show that $(C([a,b]),\|{\cdot}\|_2)$ is not a complete normed vector space we need to show that there is some Cauchy sequence that does not converge to it's limit in $C([a,b])$ . In particular, it will suffice to show that our chosen Cauchy sequence converges under $\|\cdot\|_2$ to a discontinuous function. Consider the following sequence of functions, $(f_n)_{n=1}^\infty\subset C([a,b])$ , given by, $$f_n(x)=\begin{cases} 0,\,\text{when}\,\,x\in[a,\frac{b-a}2-\frac{2^{-n}}{b-a}] \\[2ex]  1,\,\text{when}\,\,x\in[\frac{b-a}2+\frac{2^{-n}}{b-a},b] \\[2ex]  \frac{(2x-b+a)(b-a)-2^{-n+1}}{2^{-n+2}},\,\text{when}\,\,x\in[\frac{b-a}2-\frac{2^{-n}}{b-a},\frac{b-a}2+\frac{2^{-n}}{b-a}] \end{cases} $$ The definition of $f_n(x)$ when $x\in[\frac{b-a}2-\frac{2^{-n}}{b-a},\frac{b-a}2+\frac{2^{-n}}{b-a}]$ is the linear interpolant over that particular subinterval of $[a,b]$ . I claim that this is a Cauchy sequence. We consider: $$\|f_n-f_m\|_2^2=\int_a^b|f_n(x)-f_m(x)|^2dx$$ $$=\int_a^{\frac{b-a}2-\frac{2^{-n}}{b-a}}|f_n(x)-f_m(x)|^2dx+\int_{\frac{b-a}2-\frac{2^{-n}}{b-a}}^{\frac{b-a}2+\frac{2^{-n}}{b-a}}|f_n(x)-f_m(x)|^2dx+\int_{\frac{b-a}2+\frac{2^{-n}}{b-a}}^b|f_n(x)-f_m(x)|^2dx$$ $$=0+\int_{\frac{b-a}2-\frac{2^{-n}}{b-a}}^{\frac{b-a}2+\frac{2^{-n}}{b-a}}|f_n(x)-f_m(x)|^2dx+0$$ The $0$ 's for the first and last integrals because we have $f_n(x)-f_m(x)=0-0$ and $f_n(x)-f_m(x)=1-1$ on each respectively. As to the middle integral, here is what I've gotten so far: $$\int_{\frac{b-a}2-\frac{2^{-n}}{b-a}}^{\frac{b-a}2+\frac{2^{-n}}{b-a}}|f_n(x)-f_m(x)|^2dx=\int_{\frac{b-a}2-\frac{2^{-n}}{b-a}}^{\frac{b-a}2+\frac{2^{-n}}{b-a}}|(2x-b-a)(b-a)(2^{n-2}-2^{m-2})|^2dx$$ Based in the example I am following, supposing that $m\ge n$ , I think that I should be able to argue that the whole thing is bound above by $\frac{2^{-n}}{b-a}$ which would mean that $\|f_n-f_m\|_2^2\le\frac{2^{-n}}{b-a}\to0$ as $n\to\infty$ . I don't quite see how I'm meant to bound it above by $\frac{2^{-n}}{b-a}$ , as I keep tripping up over applying that $m\ge n$ , leading me to question whether the approach I have employed here is a fruitful one after all.","Problem: Show that is not a complete normed vector space. I have tried to proceed along the lines given in the accepted answer, and subsequent comment, to this question: Example of a non complete normed vector space. Although, I am running into difficulties and wondering if the example really generalises so well when we have a general . Is the Cauchy sequence I have chosen below a valid one, or have I overlooked a much simpler example to use in this case? Attempt: In order to show that is not a complete normed vector space we need to show that there is some Cauchy sequence that does not converge to it's limit in . In particular, it will suffice to show that our chosen Cauchy sequence converges under to a discontinuous function. Consider the following sequence of functions, , given by, The definition of when is the linear interpolant over that particular subinterval of . I claim that this is a Cauchy sequence. We consider: The 's for the first and last integrals because we have and on each respectively. As to the middle integral, here is what I've gotten so far: Based in the example I am following, supposing that , I think that I should be able to argue that the whole thing is bound above by which would mean that as . I don't quite see how I'm meant to bound it above by , as I keep tripping up over applying that , leading me to question whether the approach I have employed here is a fruitful one after all.","(C([a,b]),\|{\cdot}\|_2) [a,b] (C([a,b]),\|{\cdot}\|_2) C([a,b]) \|\cdot\|_2 (f_n)_{n=1}^\infty\subset C([a,b]) f_n(x)=\begin{cases}
0,\,\text{when}\,\,x\in[a,\frac{b-a}2-\frac{2^{-n}}{b-a}] \\[2ex] 
1,\,\text{when}\,\,x\in[\frac{b-a}2+\frac{2^{-n}}{b-a},b] \\[2ex] 
\frac{(2x-b+a)(b-a)-2^{-n+1}}{2^{-n+2}},\,\text{when}\,\,x\in[\frac{b-a}2-\frac{2^{-n}}{b-a},\frac{b-a}2+\frac{2^{-n}}{b-a}]
\end{cases}
 f_n(x) x\in[\frac{b-a}2-\frac{2^{-n}}{b-a},\frac{b-a}2+\frac{2^{-n}}{b-a}] [a,b] \|f_n-f_m\|_2^2=\int_a^b|f_n(x)-f_m(x)|^2dx =\int_a^{\frac{b-a}2-\frac{2^{-n}}{b-a}}|f_n(x)-f_m(x)|^2dx+\int_{\frac{b-a}2-\frac{2^{-n}}{b-a}}^{\frac{b-a}2+\frac{2^{-n}}{b-a}}|f_n(x)-f_m(x)|^2dx+\int_{\frac{b-a}2+\frac{2^{-n}}{b-a}}^b|f_n(x)-f_m(x)|^2dx =0+\int_{\frac{b-a}2-\frac{2^{-n}}{b-a}}^{\frac{b-a}2+\frac{2^{-n}}{b-a}}|f_n(x)-f_m(x)|^2dx+0 0 f_n(x)-f_m(x)=0-0 f_n(x)-f_m(x)=1-1 \int_{\frac{b-a}2-\frac{2^{-n}}{b-a}}^{\frac{b-a}2+\frac{2^{-n}}{b-a}}|f_n(x)-f_m(x)|^2dx=\int_{\frac{b-a}2-\frac{2^{-n}}{b-a}}^{\frac{b-a}2+\frac{2^{-n}}{b-a}}|(2x-b-a)(b-a)(2^{n-2}-2^{m-2})|^2dx m\ge n \frac{2^{-n}}{b-a} \|f_n-f_m\|_2^2\le\frac{2^{-n}}{b-a}\to0 n\to\infty \frac{2^{-n}}{b-a} m\ge n","['real-analysis', 'functional-analysis', 'banach-spaces', 'normed-spaces']"
68,Weak derivative of the Weierstrass function?,Weak derivative of the Weierstrass function?,,"The Weierstrass function is a function that is continuous everywhere but nowhere differentiable. I'm wondering if it has 1-th weak derivative. According to a book I'm reading, $u(x_1,x_2) = f(x_1) + f(x_2)$ defined in $\Omega = (0,1) \times (0,1)$, where $f$ is the Weierstrass function, actually has 2-th weak derivative. We have $$0 = \int_\Omega(f(x_1)+f(x_2))\frac{\partial^2 \phi}{\partial x_1 \partial x_2}dx _1dx_2$$ for all $\phi \in C_c^\infty (\Omega)$. Hence weak derivative $D_{x_1}D_{x_2}u = 0.$ So does weak derivate $D_{x_1}u$ exist?","The Weierstrass function is a function that is continuous everywhere but nowhere differentiable. I'm wondering if it has 1-th weak derivative. According to a book I'm reading, $u(x_1,x_2) = f(x_1) + f(x_2)$ defined in $\Omega = (0,1) \times (0,1)$, where $f$ is the Weierstrass function, actually has 2-th weak derivative. We have $$0 = \int_\Omega(f(x_1)+f(x_2))\frac{\partial^2 \phi}{\partial x_1 \partial x_2}dx _1dx_2$$ for all $\phi \in C_c^\infty (\Omega)$. Hence weak derivative $D_{x_1}D_{x_2}u = 0.$ So does weak derivate $D_{x_1}u$ exist?",,"['functional-analysis', 'partial-differential-equations']"
69,$T(M^\perp)\subseteq M^\perp \Longleftrightarrow T^*(M)\subseteq M?$,,T(M^\perp)\subseteq M^\perp \Longleftrightarrow T^*(M)\subseteq M?,Let $E$ be an infinite-dimensional complex Hilbert space and $\mathcal{L}(E)$ be the algebra of all bounded linear operators from $E$ to $E$. Let $M$ be a subspace of $E$ and $T\in \mathcal{L}(E)$. It is true that   $$T(M^\perp)\subseteq M^\perp \Longleftrightarrow T^*(M)\subseteq M?$$,Let $E$ be an infinite-dimensional complex Hilbert space and $\mathcal{L}(E)$ be the algebra of all bounded linear operators from $E$ to $E$. Let $M$ be a subspace of $E$ and $T\in \mathcal{L}(E)$. It is true that   $$T(M^\perp)\subseteq M^\perp \Longleftrightarrow T^*(M)\subseteq M?$$,,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
70,Elementary properties of absolute value operator,Elementary properties of absolute value operator,,"Let $T$ be a bounded linear operator on a Hilbert space. Define $|T| = (T^*T)^{1/2}$. I know $|T|$ is well-defined because $T^*T$ is a positive operator, so the positive square root exists. This is probably a trivial question, but why is $|T|$ bounded and linear? I don't see how to manipulate it because it is defined as a square root.","Let $T$ be a bounded linear operator on a Hilbert space. Define $|T| = (T^*T)^{1/2}$. I know $|T|$ is well-defined because $T^*T$ is a positive operator, so the positive square root exists. This is probably a trivial question, but why is $|T|$ bounded and linear? I don't see how to manipulate it because it is defined as a square root.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
71,Spectrum of bounded self-adjoint operator,Spectrum of bounded self-adjoint operator,,"Suppose $A$ is a bounded self-adjoint operator on the Hilbert space $\mathcal{H}$. How do I prove that $\sigma(A) \subseteq \overline{\{\langle Ax,x\rangle: x\in \mathcal{H},\; \lVert x\rVert = 1\}}$?","Suppose $A$ is a bounded self-adjoint operator on the Hilbert space $\mathcal{H}$. How do I prove that $\sigma(A) \subseteq \overline{\{\langle Ax,x\rangle: x\in \mathcal{H},\; \lVert x\rVert = 1\}}$?",,"['functional-analysis', 'spectral-theory']"
72,Showing that $p(x):=\inf\left\{a>0|\frac{1}{a}x\in K\right\}$ is a norm under certain circumstances,Showing that  is a norm under certain circumstances,p(x):=\inf\left\{a>0|\frac{1}{a}x\in K\right\},"Let $(X,\|\cdot\|_X)$ be a normed space and $K\subset X$ an open, convex set with $0\in K$ . Let $p:X\rightarrow\mathbb{R}$ be the Minkowski-functional of $K$ defined by: $$p(x):=\inf\left\{a>0 | \frac{1}{a}x\in K\right\}$$ i) Show that: If $K$ is symmetric $(-K=K)$ and bounded, then $p(x)$ is a norm in $X$ , which is equivalent to $\|\cdot\|_X$ Do I have to show, that $p(x)$ is well defined? I thought about the following: If $x=0$ : $$p(0)=\inf\{a>0|0\in K\}$$ $$=\inf\{a>0\}$$ $$=0$$ The positivity for $x\neq0$ is obvious. Then I found a theorem about the minkowski-functional: Let $K$ be convex, open with $0\in K$ and $p(x)$ defined like above, then: i) $p$ is sublinear, ii) There is a $M>0 \forall x\in X: 0\le p(x)\le M\|x\|_X$ iii) $K=\{x\in X|p(x)<1\}$ With the sublinearity of $p$ , the homogenity and the triangle inequality are clear. My problem here is: Where do I need the information, that $K$ is bounded? Now I have to show that $p(x)$ is equivalent to $\|\cdot\|_X$ . Which means: There are $c,C>0$ , so that $$c\|x\|_X\le p(x)\le C\|x\|_X$$ The theorem gives us a $C$ with $p(x)\le C\|x\|_X$ but I have no idea how to find the $c$ for the lower bound. Could someone help me with these problems?","Let be a normed space and an open, convex set with . Let be the Minkowski-functional of defined by: i) Show that: If is symmetric and bounded, then is a norm in , which is equivalent to Do I have to show, that is well defined? I thought about the following: If : The positivity for is obvious. Then I found a theorem about the minkowski-functional: Let be convex, open with and defined like above, then: i) is sublinear, ii) There is a iii) With the sublinearity of , the homogenity and the triangle inequality are clear. My problem here is: Where do I need the information, that is bounded? Now I have to show that is equivalent to . Which means: There are , so that The theorem gives us a with but I have no idea how to find the for the lower bound. Could someone help me with these problems?","(X,\|\cdot\|_X) K\subset X 0\in K p:X\rightarrow\mathbb{R} K p(x):=\inf\left\{a>0 | \frac{1}{a}x\in K\right\} K (-K=K) p(x) X \|\cdot\|_X p(x) x=0 p(0)=\inf\{a>0|0\in K\} =\inf\{a>0\} =0 x\neq0 K 0\in K p(x) p M>0 \forall x\in X: 0\le p(x)\le M\|x\|_X K=\{x\in X|p(x)<1\} p K p(x) \|\cdot\|_X c,C>0 c\|x\|_X\le p(x)\le C\|x\|_X C p(x)\le C\|x\|_X c","['functional-analysis', 'normed-spaces']"
73,Frechet differential in $L^\infty$ spaces,Frechet differential in  spaces,L^\infty,"define $L :L^\infty([0,1]) \to L^\infty([0,1])$, $f \to \cos f$. Show that this operator is not Frechet differentiable at $f = 0$. My idea was just to use the taylor expansion: $$\cos (f+h) = \cos f + h \sin f + \mathcal{o}(\|h\|)  $$ to conclude that the derivative is given by $L'(f)(h)=h \sin f$. Is this correct? Thanks for any hints.","define $L :L^\infty([0,1]) \to L^\infty([0,1])$, $f \to \cos f$. Show that this operator is not Frechet differentiable at $f = 0$. My idea was just to use the taylor expansion: $$\cos (f+h) = \cos f + h \sin f + \mathcal{o}(\|h\|)  $$ to conclude that the derivative is given by $L'(f)(h)=h \sin f$. Is this correct? Thanks for any hints.",,"['functional-analysis', 'lp-spaces', 'frechet-derivative']"
74,Replacing expectation by Lp norm,Replacing expectation by Lp norm,,"It is known that for a Lipschitz function $f: \mathbb{R}^n \rightarrow \mathbb{R}$ that if $X \sim \mathcal{N}(0,I_n)$ then $$ \| f(X) - \mathbb{E}f(X)\|_{\psi_2} \leq C \|f\|_{Lip} $$ where $\| \|_{\psi_2}$ refers to the subgaussian norm (i.e. the smallest constant $C$ such that $\mathbb{E} \exp(X^2/C^2) \leq 2$).  Is it possible to replace the $\mathbb{E}f(X)$ by $(\mathbb{E} f(X)^3)^{1/3}$ and still get a concentration inequality of the same form. I have no problem replacing the expectation by the median as it is well known that the expectation and median are close for subgaussian random variables.  I would like to prove the same phenomenon for Lp norms.","It is known that for a Lipschitz function $f: \mathbb{R}^n \rightarrow \mathbb{R}$ that if $X \sim \mathcal{N}(0,I_n)$ then $$ \| f(X) - \mathbb{E}f(X)\|_{\psi_2} \leq C \|f\|_{Lip} $$ where $\| \|_{\psi_2}$ refers to the subgaussian norm (i.e. the smallest constant $C$ such that $\mathbb{E} \exp(X^2/C^2) \leq 2$).  Is it possible to replace the $\mathbb{E}f(X)$ by $(\mathbb{E} f(X)^3)^{1/3}$ and still get a concentration inequality of the same form. I have no problem replacing the expectation by the median as it is well known that the expectation and median are close for subgaussian random variables.  I would like to prove the same phenomenon for Lp norms.",,"['functional-analysis', 'probability-theory', 'normed-spaces', 'expected-value', 'lipschitz-functions']"
75,Normability of $\mathscr{S}(\mathbb{R}^n)$,Normability of,\mathscr{S}(\mathbb{R}^n),"Let $\mathscr{S}(\mathbb{R}^n)$ be the space of Schwartz functions. In this post https://mathoverflow.net/questions/218023/the-schwartz-space-is-not-normable we are provided with an example of a Schwartz function which converges in some of the semi-norms, but not all. The function is $$f(x) = \frac{e^{-\left| x \right|^2} \sin (Nx_1)}{N^k}.$$ The semi-norms on $\mathscr{S}(\mathbb{R}^n)$ are given by $$\rho_{\alpha \beta} = \sup_{x \in \mathbb{R}^n} \left| x^{\alpha} \partial^{\beta}(f)(x) \right|,$$ where $\alpha$ and $\beta$ are multi-indices. I've attempted to go through this counter example explicitly, but do not understand how to compute the $\rho_{\alpha\beta}$ quantities explicitly. Could someone assist me in the explicit computations of $\rho_{\alpha \beta}(f)$?","Let $\mathscr{S}(\mathbb{R}^n)$ be the space of Schwartz functions. In this post https://mathoverflow.net/questions/218023/the-schwartz-space-is-not-normable we are provided with an example of a Schwartz function which converges in some of the semi-norms, but not all. The function is $$f(x) = \frac{e^{-\left| x \right|^2} \sin (Nx_1)}{N^k}.$$ The semi-norms on $\mathscr{S}(\mathbb{R}^n)$ are given by $$\rho_{\alpha \beta} = \sup_{x \in \mathbb{R}^n} \left| x^{\alpha} \partial^{\beta}(f)(x) \right|,$$ where $\alpha$ and $\beta$ are multi-indices. I've attempted to go through this counter example explicitly, but do not understand how to compute the $\rho_{\alpha\beta}$ quantities explicitly. Could someone assist me in the explicit computations of $\rho_{\alpha \beta}(f)$?",,['functional-analysis']
76,"Prob. 10, Sec. 3.5, in Kreyszig's Functional Analysis: How to show that this set is at most countable?","Prob. 10, Sec. 3.5, in Kreyszig's Functional Analysis: How to show that this set is at most countable?",,"This is Prob. 10, Sec. 3.5, in the book Introductory Functional Analysis With Applications by Erwine Kreyszig: Let $X$ be an inner product space, let $M$ be an uncountable orthonormal subset of $X$, let $x \in X$ such that $x$ is not the zero vector $\mathbf{0}_X$ in $X$, and let $S(x)$ be the subset of $M$ defined as follows:    $$ S(x) \colon= \left\{ \ v \in M \ \colon \ \langle x, v \rangle \neq 0 \ \right\}. $$   Then how to show that this set $S(x)$ is at most countable? And, this is Prob. 8, Sec. 3.4, in the same book: Let $\left( e_k \right)_{k \in \mathbb{N} }$ be an orthonormal sequence in an inner product space $X$, let $x \in X$, let $m \in \mathbb{N}$, let $A_m(x)$ be the subset of $\mathbb{N}$ defined as follows:    $$ A_m(x) \colon= \left\{ \ k \in \mathbb{N} \ \colon \ \left\lvert \left\langle x, e_k \right\rangle \right\rvert > \frac{1}{m} \ \right\}, $$   and let $n_m$ be the cardinality of $A_m(x)$. Then    $$ n_m \leq m^2 \lVert x \rVert^2. $$ The proof of this result involves the Bessel's inequality and goes as follows: As $\left( e_k \right)_{k \in \mathbb{N}}$ is an orthonormal sequence in the inner product space $X$, so by Theorem 3.4-6 (Bessel Inequality) in Kreyszig, for any $x \in X$, the series $\sum \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2$ converges in $\mathbb{R}$, and   $$ \sum_{k=1}^\infty \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2 \leq \lVert x \rVert^2. $$ Let $x\in X$, let $m$ be a given natural number, and let $A_m(x)$ be ths subset of $\mathbb{N}$ given by   $$ A_m(x) \colon= \left\{ \  k \in \mathbb{N}  \ \colon \ \left\lvert \left\langle x, e_k \right\rangle \right\rvert > \frac{1}{m} \ \right\}. $$ Let $n_m$ denote the cardinality of the set  $A_m(x)$ (which is the same as  the number of elements in the set $A_m(x)$ if $A_m(x)$ is finite ),  where   $$n_m \in \{ \ 0 \ \} \cup \mathbb{N} \cup \{ \ \aleph_0  \ \},$$   where $\aleph_0$ (pronounced ``aleph null'') denotes the cardinality of the set $\mathbb{N}$ of natural numbers,    because the set $A_m(x)$ can be empty, non-empty but finite, or countably infinite. Furthermore, as $A_m(x) \subset \mathbb{N}$ and as $\mathbb{N}$ is countable, so $A_m(x)$ cannot be uncountable. If $x = \mathbf{0}_X$, the zero vector in $X$, then   $$ \left\langle x, e_k \right\rangle = 0 $$   for all $k \in \mathbb{N}$, and so the set $A_m(x)$ is empty, and therefore   $$ n_m = 0 = m^2 \cdot 0 =  m^2 \lVert x \rVert^2. $$ So let's suppose that $x$ is not the zero vector in $X$, and suppose also that $n_m \geq m^2 \lVert x \rVert^2$. Then as   $$ \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2 \geq 0 $$   for all $k \in \mathbb{N}$ and as   $$ \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2 > \frac{1}{m^2} $$   for all $k \in A_m(x)$, so we note that   \begin{align*}  \sum_{k=1}^\infty  \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2 &= \sum_{k \in \mathbb{N} }  \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2 \\  &= \sum_{k \in A_m(x) }  \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2 + \sum_{k \in \mathbb{N} - A_m(x)  }  \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2 \\  &\geq \sum_{k \in A_m(x) }  \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2 \\\  &> \frac{n_m}{m^2} \\  &\geq \frac{m^2 \lVert x \rVert^2 }{m^2} \\  &=  \lVert x \rVert^2, \end{align*}   which contradicts the Bessel's inequality. Hence we must have   $$ n_m < m^2 \lVert x \rVert^2, $$   as required. In the above calculation, we have used the equality   $$  \sum_{k=1}^\infty  \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2 = \sum_{k \in \mathbb{N} }  \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2. $$   This is because of Theorem 3.55 in the book \emph{Principles of Mathematical Analysis} by Walter Rudin, 3rd edition, which says that if a series of complex numbers converges absolutely, then, by altering the order of the terms of that series in any way whatsoever, we obtain a series that also converges absolutely and has the same sum as the sum of the original series. Is this proof correct? If so, then can we use the latter result to establish the former? If not, then where have I erred in this proof? And, how to give an independent proof of the former result?","This is Prob. 10, Sec. 3.5, in the book Introductory Functional Analysis With Applications by Erwine Kreyszig: Let $X$ be an inner product space, let $M$ be an uncountable orthonormal subset of $X$, let $x \in X$ such that $x$ is not the zero vector $\mathbf{0}_X$ in $X$, and let $S(x)$ be the subset of $M$ defined as follows:    $$ S(x) \colon= \left\{ \ v \in M \ \colon \ \langle x, v \rangle \neq 0 \ \right\}. $$   Then how to show that this set $S(x)$ is at most countable? And, this is Prob. 8, Sec. 3.4, in the same book: Let $\left( e_k \right)_{k \in \mathbb{N} }$ be an orthonormal sequence in an inner product space $X$, let $x \in X$, let $m \in \mathbb{N}$, let $A_m(x)$ be the subset of $\mathbb{N}$ defined as follows:    $$ A_m(x) \colon= \left\{ \ k \in \mathbb{N} \ \colon \ \left\lvert \left\langle x, e_k \right\rangle \right\rvert > \frac{1}{m} \ \right\}, $$   and let $n_m$ be the cardinality of $A_m(x)$. Then    $$ n_m \leq m^2 \lVert x \rVert^2. $$ The proof of this result involves the Bessel's inequality and goes as follows: As $\left( e_k \right)_{k \in \mathbb{N}}$ is an orthonormal sequence in the inner product space $X$, so by Theorem 3.4-6 (Bessel Inequality) in Kreyszig, for any $x \in X$, the series $\sum \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2$ converges in $\mathbb{R}$, and   $$ \sum_{k=1}^\infty \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2 \leq \lVert x \rVert^2. $$ Let $x\in X$, let $m$ be a given natural number, and let $A_m(x)$ be ths subset of $\mathbb{N}$ given by   $$ A_m(x) \colon= \left\{ \  k \in \mathbb{N}  \ \colon \ \left\lvert \left\langle x, e_k \right\rangle \right\rvert > \frac{1}{m} \ \right\}. $$ Let $n_m$ denote the cardinality of the set  $A_m(x)$ (which is the same as  the number of elements in the set $A_m(x)$ if $A_m(x)$ is finite ),  where   $$n_m \in \{ \ 0 \ \} \cup \mathbb{N} \cup \{ \ \aleph_0  \ \},$$   where $\aleph_0$ (pronounced ``aleph null'') denotes the cardinality of the set $\mathbb{N}$ of natural numbers,    because the set $A_m(x)$ can be empty, non-empty but finite, or countably infinite. Furthermore, as $A_m(x) \subset \mathbb{N}$ and as $\mathbb{N}$ is countable, so $A_m(x)$ cannot be uncountable. If $x = \mathbf{0}_X$, the zero vector in $X$, then   $$ \left\langle x, e_k \right\rangle = 0 $$   for all $k \in \mathbb{N}$, and so the set $A_m(x)$ is empty, and therefore   $$ n_m = 0 = m^2 \cdot 0 =  m^2 \lVert x \rVert^2. $$ So let's suppose that $x$ is not the zero vector in $X$, and suppose also that $n_m \geq m^2 \lVert x \rVert^2$. Then as   $$ \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2 \geq 0 $$   for all $k \in \mathbb{N}$ and as   $$ \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2 > \frac{1}{m^2} $$   for all $k \in A_m(x)$, so we note that   \begin{align*}  \sum_{k=1}^\infty  \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2 &= \sum_{k \in \mathbb{N} }  \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2 \\  &= \sum_{k \in A_m(x) }  \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2 + \sum_{k \in \mathbb{N} - A_m(x)  }  \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2 \\  &\geq \sum_{k \in A_m(x) }  \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2 \\\  &> \frac{n_m}{m^2} \\  &\geq \frac{m^2 \lVert x \rVert^2 }{m^2} \\  &=  \lVert x \rVert^2, \end{align*}   which contradicts the Bessel's inequality. Hence we must have   $$ n_m < m^2 \lVert x \rVert^2, $$   as required. In the above calculation, we have used the equality   $$  \sum_{k=1}^\infty  \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2 = \sum_{k \in \mathbb{N} }  \left\lvert \left\langle x, e_k \right\rangle \right\rvert^2. $$   This is because of Theorem 3.55 in the book \emph{Principles of Mathematical Analysis} by Walter Rudin, 3rd edition, which says that if a series of complex numbers converges absolutely, then, by altering the order of the terms of that series in any way whatsoever, we obtain a series that also converges absolutely and has the same sum as the sum of the original series. Is this proof correct? If so, then can we use the latter result to establish the former? If not, then where have I erred in this proof? And, how to give an independent proof of the former result?",,"['real-analysis', 'functional-analysis', 'analysis', 'inner-products', 'orthonormal']"
77,"$C^{n}[0, 1]$ is not a C*-algebra",is not a C*-algebra,"C^{n}[0, 1]","Let $C^{n}[0, 1]$ be the space of all $n$-times continously differentiable functions endowed with the norm $$\|f\| = \sum_{k=0}^n \frac{\sup_{t \in [0, 1]}{|f^{(k)}(t)|}}{k!}$$ Let $*$ be the involution map that acts as follows: $f^{*}(t) = \overline{f(t)}$. I would like to show that $A = (C^{n}[0, 1], \| \cdot \|, *)$ is not a C*-algebra. So the first step is to show that there exists a sequence of self-adjoint (w.r.t. to the involution) functions of a unit norm, e.g. $\|f_n\| = 1$ so that $ f^2_n \rightarrow 0$ (if so, then the C*-identity would fail). Apparently, this example is a sort of a classical one for the first course on functional analysis, but i bumped into troubles while trying to invent something suitable. What are the possible approaches/examples? Update Looks as if $f_{n} = \frac{x^{n}}{n}$ works, since $f^{2}_{n} = \frac{x^{2n}}{n^{2}}$ converges to $0$ as $n \rightarrow + \infty$, but $||f_{n}|| = \frac{1}{n} + 1 \rightarrow 1$","Let $C^{n}[0, 1]$ be the space of all $n$-times continously differentiable functions endowed with the norm $$\|f\| = \sum_{k=0}^n \frac{\sup_{t \in [0, 1]}{|f^{(k)}(t)|}}{k!}$$ Let $*$ be the involution map that acts as follows: $f^{*}(t) = \overline{f(t)}$. I would like to show that $A = (C^{n}[0, 1], \| \cdot \|, *)$ is not a C*-algebra. So the first step is to show that there exists a sequence of self-adjoint (w.r.t. to the involution) functions of a unit norm, e.g. $\|f_n\| = 1$ so that $ f^2_n \rightarrow 0$ (if so, then the C*-identity would fail). Apparently, this example is a sort of a classical one for the first course on functional analysis, but i bumped into troubles while trying to invent something suitable. What are the possible approaches/examples? Update Looks as if $f_{n} = \frac{x^{n}}{n}$ works, since $f^{2}_{n} = \frac{x^{2n}}{n^{2}}$ converges to $0$ as $n \rightarrow + \infty$, but $||f_{n}|| = \frac{1}{n} + 1 \rightarrow 1$",,"['functional-analysis', 'normed-spaces', 'c-star-algebras', 'banach-algebras']"
78,Bound on projection to finite dimensional subspace of Banach Space,Bound on projection to finite dimensional subspace of Banach Space,,"Let $M$ be a finite dimensional subspace of a Banach space $X$ with basis $\{x_1,\dots,x_n\}$ (through scaling we can assume each basis element has unit norm). We can construct a projection $P:X\to M$ as follows. For $i\in \{1,\dots ,n\}$ consider the linear coefficient functional $f_i':M\to \mathbb{F}$ defined on the basis elements by $f_i'(x_k)=\delta^i_k$. Now from Lemma 2.4-1 [1] we know that there exists a $c>0$ such that for any $i\in\{1,\dots,\}$ and $x=\sum_{k=1}^n\alpha_k x_k\in M$ we have that $$|f_i'(x)|=|\alpha_k|\leq \sum_{k=1}^n|\alpha_k|\leq c\|x\|_M\quad(1).$$ Hahn-Banach allows us to extend each $f'_i$ to $f_i:X\to \mathbb F$, where $f_i$ has all the regular properties of an extended functional. We can now define $Px=\sum_{k=1}^nf_k(x)x_k$ for each $x\in X$. It is easy to see that $P$ is linear, idempotent, and from $(1)$ that $\|P\|\leq cn$. I would like to know whether there is any way to improve this bound? I think critically I would like to know more about the behaviour of the constant $c$. Kreyzsig uses proof by contradiction to prove the existence of the $c$, and I have not been able to find another direct proof so I can figure out a way to bound $c$. My intuition says that $c$ should be bounded, perhaps even equal $1$, as I've now spent some time being unable to come up with a counter-example. However, I have been unable to to come up with any bound either. I've played around with trying to use Riesz's Lemma, but without success. Any ideas and/or references would be greatly appreciated. References: [1] Erwin Kreyzsig. Introductory Functional Analysis with Applications. Wiley, 1st edition, 1989.","Let $M$ be a finite dimensional subspace of a Banach space $X$ with basis $\{x_1,\dots,x_n\}$ (through scaling we can assume each basis element has unit norm). We can construct a projection $P:X\to M$ as follows. For $i\in \{1,\dots ,n\}$ consider the linear coefficient functional $f_i':M\to \mathbb{F}$ defined on the basis elements by $f_i'(x_k)=\delta^i_k$. Now from Lemma 2.4-1 [1] we know that there exists a $c>0$ such that for any $i\in\{1,\dots,\}$ and $x=\sum_{k=1}^n\alpha_k x_k\in M$ we have that $$|f_i'(x)|=|\alpha_k|\leq \sum_{k=1}^n|\alpha_k|\leq c\|x\|_M\quad(1).$$ Hahn-Banach allows us to extend each $f'_i$ to $f_i:X\to \mathbb F$, where $f_i$ has all the regular properties of an extended functional. We can now define $Px=\sum_{k=1}^nf_k(x)x_k$ for each $x\in X$. It is easy to see that $P$ is linear, idempotent, and from $(1)$ that $\|P\|\leq cn$. I would like to know whether there is any way to improve this bound? I think critically I would like to know more about the behaviour of the constant $c$. Kreyzsig uses proof by contradiction to prove the existence of the $c$, and I have not been able to find another direct proof so I can figure out a way to bound $c$. My intuition says that $c$ should be bounded, perhaps even equal $1$, as I've now spent some time being unable to come up with a counter-example. However, I have been unable to to come up with any bound either. I've played around with trying to use Riesz's Lemma, but without success. Any ideas and/or references would be greatly appreciated. References: [1] Erwin Kreyzsig. Introductory Functional Analysis with Applications. Wiley, 1st edition, 1989.",,"['functional-analysis', 'inequality', 'banach-spaces']"
79,Show that $l^2$ is the only $l^p$ space which norm is induced by the inner product,Show that  is the only  space which norm is induced by the inner product,l^2 l^p,"I want to use the theorem of Jordan and von Neumann which states that norm is induced by inner product if and only if the parallelogram law is true Let $\Vert x \Vert_p$ be the norm in $l^p, 1\le p < \infty$. In parallelogram law we have, $\Vert x+y \Vert_p^2 + \Vert x-y \Vert_p^2 = 2\Vert x \Vert_p^2 + 2\Vert y \Vert_p^2$ which is equivalent $(\sum|x_i+y_i|^p)^{(2/p)} + (\sum|x_i-y_i|^p)^{(2/p)} = 2(\sum|x_i|^p)^{(2/p)} +2(\sum|y_i|^p)^{(2/p)}$. But now how can we get that $p=2$ is the only correct one? Is it possible to construct a sequence for which parallelogram fails for each $p$ different than 2?","I want to use the theorem of Jordan and von Neumann which states that norm is induced by inner product if and only if the parallelogram law is true Let $\Vert x \Vert_p$ be the norm in $l^p, 1\le p < \infty$. In parallelogram law we have, $\Vert x+y \Vert_p^2 + \Vert x-y \Vert_p^2 = 2\Vert x \Vert_p^2 + 2\Vert y \Vert_p^2$ which is equivalent $(\sum|x_i+y_i|^p)^{(2/p)} + (\sum|x_i-y_i|^p)^{(2/p)} = 2(\sum|x_i|^p)^{(2/p)} +2(\sum|y_i|^p)^{(2/p)}$. But now how can we get that $p=2$ is the only correct one? Is it possible to construct a sequence for which parallelogram fails for each $p$ different than 2?",,['functional-analysis']
80,On Mazur-Ulam theorem,On Mazur-Ulam theorem,,"From classical theorem of Mazur-Ulam it follows that if $(X,\|\cdot\|)$ Banach space and $T\colon X\to X$ is surjective isometry (i.e. $\|T(x)-T(y)\|=\|x-y\|$ for all $x,y\in X$) with $T(0)=0$ then $T$ is linear. My question is what if we instead of $\|T(x)-T(y)\|=\|x-y\|$ for all $x,y\in X$ require $\|T(x)+T(y)\|=\|x+y\|$ for all $x,y\in X$. In other words is it true: if $(X,\|\cdot\|)$ Banach space and map $T\colon X\to X$ continuously bijective map such that $\|T(x)+T(y)\|=\|x+y\|$ for all $x,y\in X$ and $T(0)=0$ then $T$ is linear? Thank's in advance.","From classical theorem of Mazur-Ulam it follows that if $(X,\|\cdot\|)$ Banach space and $T\colon X\to X$ is surjective isometry (i.e. $\|T(x)-T(y)\|=\|x-y\|$ for all $x,y\in X$) with $T(0)=0$ then $T$ is linear. My question is what if we instead of $\|T(x)-T(y)\|=\|x-y\|$ for all $x,y\in X$ require $\|T(x)+T(y)\|=\|x+y\|$ for all $x,y\in X$. In other words is it true: if $(X,\|\cdot\|)$ Banach space and map $T\colon X\to X$ continuously bijective map such that $\|T(x)+T(y)\|=\|x+y\|$ for all $x,y\in X$ and $T(0)=0$ then $T$ is linear? Thank's in advance.",,['functional-analysis']
81,"Space of linear operators complete, but target space not.","Space of linear operators complete, but target space not.",,"Let $X$, $Y$ be normed spaces and denote by $L(X,Y)$ the space of bounded linear operators from $X$ to $Y$. We know that $L(X,Y)$ is complete if $Y$ is. Could you provide me with an example where $L(X,Y)$ is complete, but $Y$ is not?","Let $X$, $Y$ be normed spaces and denote by $L(X,Y)$ the space of bounded linear operators from $X$ to $Y$. We know that $L(X,Y)$ is complete if $Y$ is. Could you provide me with an example where $L(X,Y)$ is complete, but $Y$ is not?",,['functional-analysis']
82,"""A straightforward application of Zorn's Lemma""?","""A straightforward application of Zorn's Lemma""?",,"I was reading a textbook on functional analysis and I came across the following: 4.2. Proposition. If $\mathscr{E}$ is an orthonormal set in $\mathscr{H}$ , then there is a basis for $\mathscr{H}$ that contains $\mathscr{E}$ . The proof of this proposition is a straightforward application of Zorn's Lemma and is left to the reader. It is assumed $\mathscr{H}$ is a Hilbert space. This caught me completely off guard. I've never heard of Zorn's Lemma (though I probably should've...), and when I looked it up it was some bizarre criteria for partially ordered sets to have a maximal element. Furthermore, it's equivalent to AC ? You can't just drop a lemma like that and expect everyone to be ok with it. Am I missing something? Is there another ""Zorn's Lemma"" that they're referring too? If not, what's the ""straightforward application"" they're talking about, because I don't see it at all. By the way, the textbook is Conway's ""A Course in Functional Analysis"", 2nd Ed.","I was reading a textbook on functional analysis and I came across the following: 4.2. Proposition. If is an orthonormal set in , then there is a basis for that contains . The proof of this proposition is a straightforward application of Zorn's Lemma and is left to the reader. It is assumed is a Hilbert space. This caught me completely off guard. I've never heard of Zorn's Lemma (though I probably should've...), and when I looked it up it was some bizarre criteria for partially ordered sets to have a maximal element. Furthermore, it's equivalent to AC ? You can't just drop a lemma like that and expect everyone to be ok with it. Am I missing something? Is there another ""Zorn's Lemma"" that they're referring too? If not, what's the ""straightforward application"" they're talking about, because I don't see it at all. By the way, the textbook is Conway's ""A Course in Functional Analysis"", 2nd Ed.",\mathscr{E} \mathscr{H} \mathscr{H} \mathscr{E} \mathscr{H},"['functional-analysis', 'proof-explanation', 'axiom-of-choice']"
83,An example of a Banach space isomorphic but not isometric to a dual Banach space,An example of a Banach space isomorphic but not isometric to a dual Banach space,,"I am wondering the following question: Let $X$ be a separable Banach space which is linearly isomorphic to a dual Banach space $Y^*$. Is there a Banach space $Z$ such that $X$ is lineraly isometric to the dual of $Z$: $X=Z^*$. I think that the answer is no, but I do not have a counterexample. Since $L_1$ is not isometric to any dual Banach space, maybe one can find a dual Banach space which is isomorphic to $L_1$... To finish, do that change anythink if I suppose $X$ to be almost linearly isometric to $Y^*$ ? By almost linearly isometric I mean that for every $\varepsilon >0$ there exist $T$: $X \to Y$ a linear isomorphism satisfying $\|T\|  \|T^{-1}\| \leq 1+\varepsilon$.","I am wondering the following question: Let $X$ be a separable Banach space which is linearly isomorphic to a dual Banach space $Y^*$. Is there a Banach space $Z$ such that $X$ is lineraly isometric to the dual of $Z$: $X=Z^*$. I think that the answer is no, but I do not have a counterexample. Since $L_1$ is not isometric to any dual Banach space, maybe one can find a dual Banach space which is isomorphic to $L_1$... To finish, do that change anythink if I suppose $X$ to be almost linearly isometric to $Y^*$ ? By almost linearly isometric I mean that for every $\varepsilon >0$ there exist $T$: $X \to Y$ a linear isomorphism satisfying $\|T\|  \|T^{-1}\| \leq 1+\varepsilon$.",,"['functional-analysis', 'banach-spaces', 'duality-theorems', 'isometry', 'vector-space-isomorphism']"
84,"Approximation on partitions in $L^2([0,1]\times \Omega)$",Approximation on partitions in,"L^2([0,1]\times \Omega)","I’m working on Nualart’s book “The Malliavin calculus and related topics” and in the proof of lemma 1.1.3 he mentions that the operators $P_n$ have their operator norm bounded by 1. I fail to see why, can you help me? Using Jensen’s inequality I get a norm more akin to $2^n$, so I guess Jensen is too weak to prove that? Quoting the proof: Let $u$ be a process in $L^2_a([0,1]\times\Omega)$ ($L^2_a$ are the adapted processes w.r.t Brownian motion) and consider the sequence of processes defined by $\tilde u^n(t)=\sum_{i=1}^{2^n-1}2^n\left(\int_{(i-1)2^{-n}}^{i2^{-n}}u(s)ds\right)1_{]i2^{-n},(i+1)2^{-n}]}(t)$. We claim that the sequence converges to $u$ in $L^2([0,1]\times\Omega)$. In fact define $P_n(u)=\tilde u^n$. Then $P_n$ is a linear operator in $L^2([0,1]\times\Omega)$ with norm bounded by one.","I’m working on Nualart’s book “The Malliavin calculus and related topics” and in the proof of lemma 1.1.3 he mentions that the operators $P_n$ have their operator norm bounded by 1. I fail to see why, can you help me? Using Jensen’s inequality I get a norm more akin to $2^n$, so I guess Jensen is too weak to prove that? Quoting the proof: Let $u$ be a process in $L^2_a([0,1]\times\Omega)$ ($L^2_a$ are the adapted processes w.r.t Brownian motion) and consider the sequence of processes defined by $\tilde u^n(t)=\sum_{i=1}^{2^n-1}2^n\left(\int_{(i-1)2^{-n}}^{i2^{-n}}u(s)ds\right)1_{]i2^{-n},(i+1)2^{-n}]}(t)$. We claim that the sequence converges to $u$ in $L^2([0,1]\times\Omega)$. In fact define $P_n(u)=\tilde u^n$. Then $P_n$ is a linear operator in $L^2([0,1]\times\Omega)$ with norm bounded by one.",,"['functional-analysis', 'probability-theory', 'measure-theory', 'stochastic-processes', 'malliavin-calculus']"
85,Uniform boundedness principle on dense subspace,Uniform boundedness principle on dense subspace,,"In my thesis I encountered the following problem: Let $X,Y$ Banach spaces and $Z\subset X$ a norm-dense subspace. Suppose we have operators $\left\{T_n:n\in\mathbb{N}\right\}$ such that for all $x\in Z$ it holds that $\left\{\left\lVert T_nx\right\rVert:n\in\mathbb{N}\right\}$ is bounded. Can I somehow use the Uniform Boundedness principle to conclude that $\left\{\lVert T_n\rVert:n\in\mathbb{N}\right\}$ is bounded? Thanks in advance!","In my thesis I encountered the following problem: Let $X,Y$ Banach spaces and $Z\subset X$ a norm-dense subspace. Suppose we have operators $\left\{T_n:n\in\mathbb{N}\right\}$ such that for all $x\in Z$ it holds that $\left\{\left\lVert T_nx\right\rVert:n\in\mathbb{N}\right\}$ is bounded. Can I somehow use the Uniform Boundedness principle to conclude that $\left\{\lVert T_n\rVert:n\in\mathbb{N}\right\}$ is bounded? Thanks in advance!",,"['functional-analysis', 'operator-theory', 'banach-spaces']"
86,"Is $C[0,1]$ a Banach space for the $L^1$ norm?",Is  a Banach space for the  norm?,"C[0,1] L^1","Is $C[0,1]$ a Banach space with respect to the norm $\|f\| = \int\limits_0^1|f(t)| \, dt$? People keep telling me it is, but lets consider: $f_n(x) = x^n$. This function defines a Cauchy sequence, yet the limit clearly isn't a continuous function!","Is $C[0,1]$ a Banach space with respect to the norm $\|f\| = \int\limits_0^1|f(t)| \, dt$? People keep telling me it is, but lets consider: $f_n(x) = x^n$. This function defines a Cauchy sequence, yet the limit clearly isn't a continuous function!",,"['functional-analysis', 'banach-spaces']"
87,Bounded differentiation operator,Bounded differentiation operator,,"Is there an example of a normed space $X$, $\dim X=\infty$ such that the differentiation operator $T=\frac{d}{dx}$ is bounded, meaning that $T \in B(X)$ ?","Is there an example of a normed space $X$, $\dim X=\infty$ such that the differentiation operator $T=\frac{d}{dx}$ is bounded, meaning that $T \in B(X)$ ?",,"['functional-analysis', 'operator-theory']"
88,"Intuition for Integrating ""Against a Test Function"" in Distribution Theory","Intuition for Integrating ""Against a Test Function"" in Distribution Theory",,"I know that we can consider (locally integrable) functions and measures to be distributions via the relationships $$ \langle T_{f},\varphi\rangle=\int_{\mathbb{R}} f(x)\varphi(x) \, d\mu(x) $$ and $$ \langle T_{\mu},\varphi\rangle=\int_{\mathbb{R}} \varphi(x) \, d\mu(x) $$ and the fact that $$ \langle T_{f},\varphi \rangle = \langle T_{g} , \varphi\rangle \implies f=g \, a.e. $$ but I'm not completely sure how by integrating against a test function that we can recover the pointwise values of $f$ or $\mu$ (at least a.e.). My understanding is that the value of the distribution $T_{f}$ depend on the test function that it is being evaluated at and the values of the distribution determine the pointwise values of $f$ almost everywhere since evaluating the function at a point would involve a integrating against the limit of a sequence of test functions whose limit is not a test function (i.e. the Dirac distribution). My intuition tells me that the test function just serves as some sort of ""smooth approximation to an indicator function"" and then you can dilate the test function in the same manner you might change the support of an indicator function. Am I on the right track or am I missing something?","I know that we can consider (locally integrable) functions and measures to be distributions via the relationships $$ \langle T_{f},\varphi\rangle=\int_{\mathbb{R}} f(x)\varphi(x) \, d\mu(x) $$ and $$ \langle T_{\mu},\varphi\rangle=\int_{\mathbb{R}} \varphi(x) \, d\mu(x) $$ and the fact that $$ \langle T_{f},\varphi \rangle = \langle T_{g} , \varphi\rangle \implies f=g \, a.e. $$ but I'm not completely sure how by integrating against a test function that we can recover the pointwise values of $f$ or $\mu$ (at least a.e.). My understanding is that the value of the distribution $T_{f}$ depend on the test function that it is being evaluated at and the values of the distribution determine the pointwise values of $f$ almost everywhere since evaluating the function at a point would involve a integrating against the limit of a sequence of test functions whose limit is not a test function (i.e. the Dirac distribution). My intuition tells me that the test function just serves as some sort of ""smooth approximation to an indicator function"" and then you can dilate the test function in the same manner you might change the support of an indicator function. Am I on the right track or am I missing something?",,"['functional-analysis', 'distribution-theory']"
89,Proof that $C(K)$ is a Grothendieck space for $K$ an extremely disconnected compact space.,Proof that  is a Grothendieck space for  an extremely disconnected compact space.,C(K) K,"I am looking for a proof, other than the original article by Grothendieck which is in French, that the space $C(K)$ is Grothendieck when $K$ is extremely disconnected.","I am looking for a proof, other than the original article by Grothendieck which is in French, that the space $C(K)$ is Grothendieck when $K$ is extremely disconnected.",,"['functional-analysis', 'banach-spaces', 'compactness']"
90,"Show that the subspace $Y = \{ x \in \mathcal{C}[a,b] \mid x(a) = x(b) \} \subset \mathcal{C}[a,b]$ is complete",Show that the subspace  is complete,"Y = \{ x \in \mathcal{C}[a,b] \mid x(a) = x(b) \} \subset \mathcal{C}[a,b]","Now I understand that the function space $\mathcal{C}[a,b]$ of continuous functions from the closed interval $[a,b]$ to $\mathbb{R}$ is complete, with the metric: $ d(x, y) = \underset{t \ \in \ [a,b]}{\max} \vert x(t) - y(t) \vert $ I also understand the theorem which states that a subspace $M$ of a complete metric space $X$ is itself complete if and only if the set $M$ is closed in $X$. Finally I understand that $M$ is closed if and only if the situation $x_n \in M, x_n \longrightarrow x$ implies that $x \in M$. What is don't know what to do is how to put this all together to show that the given subspace $Y$ is closed in  $\mathcal{C}[a,b]$.","Now I understand that the function space $\mathcal{C}[a,b]$ of continuous functions from the closed interval $[a,b]$ to $\mathbb{R}$ is complete, with the metric: $ d(x, y) = \underset{t \ \in \ [a,b]}{\max} \vert x(t) - y(t) \vert $ I also understand the theorem which states that a subspace $M$ of a complete metric space $X$ is itself complete if and only if the set $M$ is closed in $X$. Finally I understand that $M$ is closed if and only if the situation $x_n \in M, x_n \longrightarrow x$ implies that $x \in M$. What is don't know what to do is how to put this all together to show that the given subspace $Y$ is closed in  $\mathcal{C}[a,b]$.",,"['functional-analysis', 'metric-spaces', 'complete-spaces']"
91,"$(\mathbb{R}^n,\|\cdot\|_{p})$ is isometrically isomorphic to $(\mathbb{R}^n,\|\cdot\|_{q})$ iff $p=q,$",is isometrically isomorphic to  iff,"(\mathbb{R}^n,\|\cdot\|_{p}) (\mathbb{R}^n,\|\cdot\|_{q}) p=q,","I want to prove, that $(\mathbb{R}^n,\|\cdot\|_{p})$ is isometrically isomorphic to $(\mathbb{R}^n,\|\cdot\|_{q})$ iff $p=q,$ I have tried looking the unitary balls, and I have been proved that $(\mathbb{R}^n,\|\cdot\|_{1})$ is not isometrically isometric to any other $p$-norm.","I want to prove, that $(\mathbb{R}^n,\|\cdot\|_{p})$ is isometrically isomorphic to $(\mathbb{R}^n,\|\cdot\|_{q})$ iff $p=q,$ I have tried looking the unitary balls, and I have been proved that $(\mathbb{R}^n,\|\cdot\|_{1})$ is not isometrically isometric to any other $p$-norm.",,"['real-analysis', 'analysis', 'functional-analysis']"
92,"Is $GL(E)$ dense in $L(E)$, when $\dim E=\infty$?","Is  dense in , when ?",GL(E) L(E) \dim E=\infty,"Let $E$ be a normed vector space (Banach space, if you like). Is $GL(E)$, the set of invertible and continuous endomorphism of $E$, dense in $L(E)$, the set of continuous endomorphism of $E$? I specify that I know the answer if $dim(E)<\infty$, with classical arguments about the spectrum of matrices, and, I know that $GL(E)$ is open in $L(E)$, even if $dim(E)=\infty$ (if $E$ is a Banach space), using the formula $(I-u)^{-1}=\sum_{n\in\mathbb{N}}u^n$ for $u$ small enough. So the remaining question I would like to ask is about the density of $GL(E)$ in $L(E)$, and in the case it is not, about its closure.","Let $E$ be a normed vector space (Banach space, if you like). Is $GL(E)$, the set of invertible and continuous endomorphism of $E$, dense in $L(E)$, the set of continuous endomorphism of $E$? I specify that I know the answer if $dim(E)<\infty$, with classical arguments about the spectrum of matrices, and, I know that $GL(E)$ is open in $L(E)$, even if $dim(E)=\infty$ (if $E$ is a Banach space), using the formula $(I-u)^{-1}=\sum_{n\in\mathbb{N}}u^n$ for $u$ small enough. So the remaining question I would like to ask is about the density of $GL(E)$ in $L(E)$, and in the case it is not, about its closure.",,"['functional-analysis', 'operator-theory', 'banach-algebras']"
93,Locally compact Hausdorff topological vector spaces are finite-dimensional,Locally compact Hausdorff topological vector spaces are finite-dimensional,,"It's an important fact that locally compact Hausdorff topological vector spaces are finite-dimensional, a proof can be found here . I'm somewhat stuck with the proof. If ${U}$ is a neighbourhood of the origin. then for every ${x \in V}$ we see that ${2^{-n} x \in U}$ for sufficiently large ${n}$. By compactness of ${K}$ (and continuity of the scalar multiplication map at zero), we conclude that ${2^{-n} K \subset U}$ for some sufficiently large ${n}$. Here $K$ is a compact neighborhood of the origin, From the above argument, I know that for every $x\in K$, we have $x\in 2^n U$ sufficiently large $n$, then by the compactness of $K$, we can find a finite collection of sets $\{2^{n_1}U,\cdots,2^{n_k}U\}$ such that  $$K\subset 2^{n_1}U\cup\cdots\cup 2^{n_k}U.$$ But how can we say there exists a $n$ such that $K\subset 2^nU$?","It's an important fact that locally compact Hausdorff topological vector spaces are finite-dimensional, a proof can be found here . I'm somewhat stuck with the proof. If ${U}$ is a neighbourhood of the origin. then for every ${x \in V}$ we see that ${2^{-n} x \in U}$ for sufficiently large ${n}$. By compactness of ${K}$ (and continuity of the scalar multiplication map at zero), we conclude that ${2^{-n} K \subset U}$ for some sufficiently large ${n}$. Here $K$ is a compact neighborhood of the origin, From the above argument, I know that for every $x\in K$, we have $x\in 2^n U$ sufficiently large $n$, then by the compactness of $K$, we can find a finite collection of sets $\{2^{n_1}U,\cdots,2^{n_k}U\}$ such that  $$K\subset 2^{n_1}U\cup\cdots\cup 2^{n_k}U.$$ But how can we say there exists a $n$ such that $K\subset 2^nU$?",,"['real-analysis', 'functional-analysis', 'topological-vector-spaces']"
94,"Unit sphere in $L^p([0,1])$ is not compact.",Unit sphere in  is not compact.,"L^p([0,1])","I am studying $L^p$ spaces and I would like a proof why the unit sphere in $L^p([0,1])$ is not compact. I know that unit sphere is not compact in infinite dimensional spaces, but I think there is an elementary proof, tailored to this example. I would appreciate your help.","I am studying $L^p$ spaces and I would like a proof why the unit sphere in $L^p([0,1])$ is not compact. I know that unit sphere is not compact in infinite dimensional spaces, but I think there is an elementary proof, tailored to this example. I would appreciate your help.",,"['functional-analysis', 'lp-spaces']"
95,$\mathcal M(K)$ is an $\mathcal{l}_1-$sum of $L_1(\mu)$ spaces,is an sum of  spaces,\mathcal M(K) \mathcal{l}_1- L_1(\mu),"Let $K$ be a compact Hausdorff space. I want to show $\mathcal M(K)$ is an $\mathcal{l}_1$ -sum of $L_1(\mu)$ spaces, where $\mathcal M(K)$ is the dual of $C(K)$ . I have got the sketch of the proof but there are some small details that I don't know how to verify. First, by Zorn's Lemma, we can choose a maximal collection of mutually singular probability measures, say $(\mu_i)_{i\in I}$ and claim that $$\mathcal M(K) \cong \big(\oplus_{i\in I} L_1{(\mu_i)}\big)_{l_1}$$ For any $\nu \in \mathcal M(K)$ and $i \in I$ , by Lebesgue's decomposition theorem , there exists finite signed measures $\lambda_i$ and $\rho_i$ such that $\nu=\lambda_i + \rho_i$ , $\rho_i<<\mu_i $ and $\lambda_i \perp \mu_i$ . Let $f_i := \frac{d\rho_i}{d\mu_i}$ be the Radon–Nikodym derivative. Now my first question is: How to show that $(f_i)_{i\in I} \in \big(\oplus_{i\in I} L_1{(\mu_i)}\big)_{l_1}$ ? By the Radon–Nikodym theorem, each $f_i \in L_1(\mu_i)$ . But we need to show that the sum $\sum_{i\in I} \|f_i\|_1$ is finite. Do we actually have $\|v\|=\sum_{i\in I} \|f_i\|_1$ ? After showing this, we define the map $\phi:\mathcal M(K) \to \big(\oplus_{i\in I} L_1{(\mu_i)}\big)_{l_1}$ by $\nu \mapsto (f_i)_{i\in I}$ , which is an isometry. My second question is: How to verify that this map is surjective? Thank you in advance! (Sorry for the typos. I have corrected many of them.)","Let be a compact Hausdorff space. I want to show is an -sum of spaces, where is the dual of . I have got the sketch of the proof but there are some small details that I don't know how to verify. First, by Zorn's Lemma, we can choose a maximal collection of mutually singular probability measures, say and claim that For any and , by Lebesgue's decomposition theorem , there exists finite signed measures and such that , and . Let be the Radon–Nikodym derivative. Now my first question is: How to show that ? By the Radon–Nikodym theorem, each . But we need to show that the sum is finite. Do we actually have ? After showing this, we define the map by , which is an isometry. My second question is: How to verify that this map is surjective? Thank you in advance! (Sorry for the typos. I have corrected many of them.)",K \mathcal M(K) \mathcal{l}_1 L_1(\mu) \mathcal M(K) C(K) (\mu_i)_{i\in I} \mathcal M(K) \cong \big(\oplus_{i\in I} L_1{(\mu_i)}\big)_{l_1} \nu \in \mathcal M(K) i \in I \lambda_i \rho_i \nu=\lambda_i + \rho_i \rho_i<<\mu_i  \lambda_i \perp \mu_i f_i := \frac{d\rho_i}{d\mu_i} (f_i)_{i\in I} \in \big(\oplus_{i\in I} L_1{(\mu_i)}\big)_{l_1} f_i \in L_1(\mu_i) \sum_{i\in I} \|f_i\|_1 \|v\|=\sum_{i\in I} \|f_i\|_1 \phi:\mathcal M(K) \to \big(\oplus_{i\in I} L_1{(\mu_i)}\big)_{l_1} \nu \mapsto (f_i)_{i\in I},"['functional-analysis', 'measure-theory', 'banach-spaces']"
96,Lax-Milgram theorem on Evans. If the mapping is injective why do we need to prove uniqueness again?,Lax-Milgram theorem on Evans. If the mapping is injective why do we need to prove uniqueness again?,,"This is the theorem and its proof (From Evans L., Partial Differential Equations, p. $297-299$) Theorem 1 (Lax-Milgram Theorem). Assume that$$ B: H × H → \mathbb{R} \tag{i} $$   is a bilinear mapping, for which there exists constant $α, β > 0$ such that$$ |B[u, v]| \le α \| u \| \| v \| $$   and $$\beta\|u\|^2\leq B[u,u]\ \,(u\in H).\tag{ii}$$ Finally, let $f:H\to\mathbb{R}$ be a bounded linear functional on $H$. Then there exists a unique element $u\in H$ such that $$B[u,v]=\langle f,v\rangle\tag{1}$$ for all $v\in H$. Proof. For each fixed element $u\in H$, the mapping $v\mapsto B[u,v]$ is a bounded linear functional on $H$; whence the Riesz Representation Theorem (D.3) asserts the existence of a unique element $w\in H$ satisfying $$B[u,v]=(w,v)\ \, (v\in H).\tag{2}$$ Let us write $Au=w$ whenever $(2)$ holds; so that $$B[u,v]=(Au,v)\ \, (u,v\in H).\tag{3}$$ We first claim $A:H\to H$ is a bounded linear operator. Indeed if $\lambda_1,\lambda_2\in\mathbb{R}$ and $u_1,u_2\in H$, we see for each $v\in H$ that $$\begin{align}(A(\lambda_1u_1+\lambda_2u_2),v)&=B[\lambda_1u_1+\lambda_2u_2,v]\ \text{ by }(3)\\ &=\lambda_1B[u_1,v]+\lambda_2 B[u_2,v] \\ &=\lambda_1(Au_1,v)+\lambda_2(Au_2,v)\ \text{ by }(3)\text{ again} \\&=(\lambda_1 Au_1+\lambda_2 Au_2,v). \end{align}$$ This equality obtains for each $v\in H$, and so $A$ is linear. Furthermore $$\|Au\|^2=(Au,Au)=B[u,Au]\leq\alpha\|u\|\,\|Au\|.$$ Consequently $\|Au\|\leq\alpha\|u\|$ for all $u\in H$, and so $A$ is bounded. Next we assert $$\left\{\begin{array}{l}A\text{ is one-to-one, and}\\ R(A),\text{ the range of }A,\text{ is closed in }H. \end{array}\right.\tag{4}$$ To prove this, let us compare $$\beta\|u\|^2\leq B[u,u]=(Au,u)\leq\|Au\|\,\|u\|.$$ Hence $\beta\|u\|\leq\|Au\|$. This inequality easily implies $(4)$. We demonstrate now $$R(A)=H.\tag{5}$$ For if not, then since $R(A)$ is closed, there would exist a nonzero element $w\in H$ with $w\in R(A)^{\bot}$. But this fact in turn implies the contradiction $\beta\|w\|^2\leq B[w,w]=(Aw,w)=0$. Next, we observe once more from the Riesz Representation Theorem that $$\langle f,v\rangle =(w,v)\quad\text{for all }v\in H$$ for some element $w\in H$. We then utilize $(4)$ and $(5)$ to find $u\in H$ satisfying $Au=w$. Then $$B[u,v]=(Au,v)=(w,v)=\langle f,v\rangle\quad(v\in H),$$ and this is $(1)$. Finally, we show there is at most one element $u\in H$ verifying $(1)$. For if both $B[u,v]=\langle f,v\rangle$ and $B[\tilde{u},v]=\langle f,v\rangle$, then $B[u-\tilde{u},v]=0\ (v\in H)$. We set $v=u-\tilde{u}$ to find $\beta\|u-\tilde{u}\|^2\leq B[u-\tilde{u},u-\tilde{u}]=0.$ $\tag*{$\square$}$ If we already know that $\langle f,v \rangle = (w,v)$ = $B[u,v] = (Au, v)$ and we know that $A$ is one-to-one, isn't that already a proof that there can be only one $u$ for which  $$ B(u,v) = (w,v) \tag{2}$$ holds? Why do we need point 6 in the proof of the above theorem? Isn't that already explained?","This is the theorem and its proof (From Evans L., Partial Differential Equations, p. $297-299$) Theorem 1 (Lax-Milgram Theorem). Assume that$$ B: H × H → \mathbb{R} \tag{i} $$   is a bilinear mapping, for which there exists constant $α, β > 0$ such that$$ |B[u, v]| \le α \| u \| \| v \| $$   and $$\beta\|u\|^2\leq B[u,u]\ \,(u\in H).\tag{ii}$$ Finally, let $f:H\to\mathbb{R}$ be a bounded linear functional on $H$. Then there exists a unique element $u\in H$ such that $$B[u,v]=\langle f,v\rangle\tag{1}$$ for all $v\in H$. Proof. For each fixed element $u\in H$, the mapping $v\mapsto B[u,v]$ is a bounded linear functional on $H$; whence the Riesz Representation Theorem (D.3) asserts the existence of a unique element $w\in H$ satisfying $$B[u,v]=(w,v)\ \, (v\in H).\tag{2}$$ Let us write $Au=w$ whenever $(2)$ holds; so that $$B[u,v]=(Au,v)\ \, (u,v\in H).\tag{3}$$ We first claim $A:H\to H$ is a bounded linear operator. Indeed if $\lambda_1,\lambda_2\in\mathbb{R}$ and $u_1,u_2\in H$, we see for each $v\in H$ that $$\begin{align}(A(\lambda_1u_1+\lambda_2u_2),v)&=B[\lambda_1u_1+\lambda_2u_2,v]\ \text{ by }(3)\\ &=\lambda_1B[u_1,v]+\lambda_2 B[u_2,v] \\ &=\lambda_1(Au_1,v)+\lambda_2(Au_2,v)\ \text{ by }(3)\text{ again} \\&=(\lambda_1 Au_1+\lambda_2 Au_2,v). \end{align}$$ This equality obtains for each $v\in H$, and so $A$ is linear. Furthermore $$\|Au\|^2=(Au,Au)=B[u,Au]\leq\alpha\|u\|\,\|Au\|.$$ Consequently $\|Au\|\leq\alpha\|u\|$ for all $u\in H$, and so $A$ is bounded. Next we assert $$\left\{\begin{array}{l}A\text{ is one-to-one, and}\\ R(A),\text{ the range of }A,\text{ is closed in }H. \end{array}\right.\tag{4}$$ To prove this, let us compare $$\beta\|u\|^2\leq B[u,u]=(Au,u)\leq\|Au\|\,\|u\|.$$ Hence $\beta\|u\|\leq\|Au\|$. This inequality easily implies $(4)$. We demonstrate now $$R(A)=H.\tag{5}$$ For if not, then since $R(A)$ is closed, there would exist a nonzero element $w\in H$ with $w\in R(A)^{\bot}$. But this fact in turn implies the contradiction $\beta\|w\|^2\leq B[w,w]=(Aw,w)=0$. Next, we observe once more from the Riesz Representation Theorem that $$\langle f,v\rangle =(w,v)\quad\text{for all }v\in H$$ for some element $w\in H$. We then utilize $(4)$ and $(5)$ to find $u\in H$ satisfying $Au=w$. Then $$B[u,v]=(Au,v)=(w,v)=\langle f,v\rangle\quad(v\in H),$$ and this is $(1)$. Finally, we show there is at most one element $u\in H$ verifying $(1)$. For if both $B[u,v]=\langle f,v\rangle$ and $B[\tilde{u},v]=\langle f,v\rangle$, then $B[u-\tilde{u},v]=0\ (v\in H)$. We set $v=u-\tilde{u}$ to find $\beta\|u-\tilde{u}\|^2\leq B[u-\tilde{u},u-\tilde{u}]=0.$ $\tag*{$\square$}$ If we already know that $\langle f,v \rangle = (w,v)$ = $B[u,v] = (Au, v)$ and we know that $A$ is one-to-one, isn't that already a proof that there can be only one $u$ for which  $$ B(u,v) = (w,v) \tag{2}$$ holds? Why do we need point 6 in the proof of the above theorem? Isn't that already explained?",,"['functional-analysis', 'partial-differential-equations']"
97,Operator norm of positive operator.,Operator norm of positive operator.,,"I'm studying Reed and Simon's ""Methods of Modern Mathematical Physics"" Vol. 1 ( http://www.math.bme.hu/~balint/oktatas/fun/notes/Reed_Simon_Vol1.pdf ). In the proof of the square root lemma (p.196) they use the equation $\|I-A\|=\sup\limits_{|\varphi|=1}|((I-A)\varphi,\varphi)|,$ where $A$ is a bounded positive operator on a Hilbert space $\mathcal{H}$ and $I$ is the identity operator in $\mathcal{H}$.  I understand that for any bounded operator $T$, the Cauchy-Schwarz imequality implies that $\|T\|\geq\sup\limits_{|\varphi|=1}|(T\varphi,\varphi)|$. But I am not able to prove the other inequality. Under what hypothesis is it true?","I'm studying Reed and Simon's ""Methods of Modern Mathematical Physics"" Vol. 1 ( http://www.math.bme.hu/~balint/oktatas/fun/notes/Reed_Simon_Vol1.pdf ). In the proof of the square root lemma (p.196) they use the equation $\|I-A\|=\sup\limits_{|\varphi|=1}|((I-A)\varphi,\varphi)|,$ where $A$ is a bounded positive operator on a Hilbert space $\mathcal{H}$ and $I$ is the identity operator in $\mathcal{H}$.  I understand that for any bounded operator $T$, the Cauchy-Schwarz imequality implies that $\|T\|\geq\sup\limits_{|\varphi|=1}|(T\varphi,\varphi)|$. But I am not able to prove the other inequality. Under what hypothesis is it true?",,"['functional-analysis', 'operator-theory']"
98,"Extension theorem for Sobolev spaces $W^{1,\infty}(\Omega)$: is there an elementary proof?",Extension theorem for Sobolev spaces : is there an elementary proof?,"W^{1,\infty}(\Omega)","Basically, I have the same question as in Extension of $W^{1,\infty}(\Omega)$ : Given a bounded, open set $\Omega\subset\mathbb{R}^n$ with $\mathcal{C}^1$-boundary and another open bounded set $V\supset\supset\Omega$. I want to find an extension operator $E:W^{1,\infty}(\Omega)\rightarrow W^{1,\infty}(\mathbb{R}^n)$ which is linear, bounded and satisfies: $Eu=u$ $dx$-a.e on $\Omega$ as well as $\mathrm{supp}(Eu)\subset V$ for each $u\in W^{1,\infty}(\Omega)$. I do not know the result about the coincidence of $W^{1,\infty}(\Omega)$ with Lipschitz continuous functions as stated in the link above. Moreover, all approximation results I know for Sobolev functions are for $p<\infty$. I was wondering whether it is possible to construct a Cauchy sequence in $W^{1,\infty}(\mathbb{R}^n)$ by mollifying the zero-extension of $u\in W^{1,\infty}(\Omega)$. Maybe the limit has the desired properties. Unfortunately, I was not able to show the Cauchy-property. Does someone know an elementary proof of the desired result?","Basically, I have the same question as in Extension of $W^{1,\infty}(\Omega)$ : Given a bounded, open set $\Omega\subset\mathbb{R}^n$ with $\mathcal{C}^1$-boundary and another open bounded set $V\supset\supset\Omega$. I want to find an extension operator $E:W^{1,\infty}(\Omega)\rightarrow W^{1,\infty}(\mathbb{R}^n)$ which is linear, bounded and satisfies: $Eu=u$ $dx$-a.e on $\Omega$ as well as $\mathrm{supp}(Eu)\subset V$ for each $u\in W^{1,\infty}(\Omega)$. I do not know the result about the coincidence of $W^{1,\infty}(\Omega)$ with Lipschitz continuous functions as stated in the link above. Moreover, all approximation results I know for Sobolev functions are for $p<\infty$. I was wondering whether it is possible to construct a Cauchy sequence in $W^{1,\infty}(\mathbb{R}^n)$ by mollifying the zero-extension of $u\in W^{1,\infty}(\Omega)$. Maybe the limit has the desired properties. Unfortunately, I was not able to show the Cauchy-property. Does someone know an elementary proof of the desired result?",,"['functional-analysis', 'sobolev-spaces']"
99,Schur complement condition for positive definiteness of operators,Schur complement condition for positive definiteness of operators,,"To verify if a symmetric block matrix is positive definite, one can check the definiteness of its diagonal blocks and the Schur complement of the respective blocks. Is this also true in the infinite dimensional setting? Precisely, being $A$, $B$ and $C$ be linear bounded operators defined on a Hilbert space $\mathcal{H}$, it is true that if $C$ is invertible and $C^{-1}$ is also a bounded linear operator, then the operator block matrix $$ \begin{bmatrix} A & B^{*} \\ B & C \end{bmatrix} $$ on $\mathcal{H} \oplus \mathcal{H}$ is positive if and only if $C$ is positive and $A - B^{*} C^{-1} B$ is positive?","To verify if a symmetric block matrix is positive definite, one can check the definiteness of its diagonal blocks and the Schur complement of the respective blocks. Is this also true in the infinite dimensional setting? Precisely, being $A$, $B$ and $C$ be linear bounded operators defined on a Hilbert space $\mathcal{H}$, it is true that if $C$ is invertible and $C^{-1}$ is also a bounded linear operator, then the operator block matrix $$ \begin{bmatrix} A & B^{*} \\ B & C \end{bmatrix} $$ on $\mathcal{H} \oplus \mathcal{H}$ is positive if and only if $C$ is positive and $A - B^{*} C^{-1} B$ is positive?",,"['functional-analysis', 'schur-complement']"
