,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Improper integral complex analysis $\int_{-\infty}^\infty \frac{e^{ax} \, dx}{\cosh(x)}$",Improper integral complex analysis,"\int_{-\infty}^\infty \frac{e^{ax} \, dx}{\cosh(x)}","I tried the following problem but I don't think I got the right answer. I checked it by substituting $a=\frac{1}{2}$ into the integral and putting that through Wolfram Alpha but it didn't match the answer I found when I substituted $a=\frac{1}{2}$ into my final answer. So I would be so grateful if someone could tell me where I went wrong. I'm not sure if there's an easier contour than a rectangle but if there is please don't suggest any because I was required to solve this problem using a rectangular contour. Thank you in advance! :) Problem: Evaluate $$\int_{-\infty}^\infty \frac{e^{ax} \, dx}{\cosh(x)}$$ where $-1<\operatorname{Re}(a)<1$ using a rectangular contour integral and residue calculus. My attempt: $$\cosh(z)=\cos(iz)=0$$ $$z=\frac{i\pi}{2}-k\pi i,k\in Z$$ Let $L>0$ be a real number, and $C_1, C_2, C_3, C_4$ be the line segments that go from $-L$ to $L$, from $L$ to $L+\pi i$, from $L + \pi i$ to $-L+\pi i$ and from $-L+\pi i$ to $-L$, respectively.  Let $C = C_1 + C_2 + C_3 + C_4$, a  rectangular contour surrounding the singularity $z=\frac{i\pi}{2}$. $$\oint_C\frac{e^{az} \, dz}{\cosh(z)}=\int_{-L}^L \frac{e^{ax}dx}{\cosh(x)} + \int_0^\pi \frac{e^{a(L+iy)}i \, dy}{\cosh(L+iy)}+\int_L^{-L} \frac{e^{a(x+\pi i)} \, dx}{\cosh(x+\pi i)}+\int_\pi^0 \frac{e^{a(-L+iy)}i \, dy}{\cosh(-L+iy)}$$ Now, $$\oint_C\frac{e^{az} \, dz}{\cosh(z)}=2\pi i \operatorname{Res} \left(\frac{e^{az}}{\cosh(z)};\frac{i\pi}{2}\right) =2\pi i \lim_{z \rightarrow \frac{i\pi}{2}}\frac{e^{az}(z-\frac{i\pi}{2})}{\cosh(z)}=-ie^{\frac{ai\pi}{2}}$$ and $$\int_{-L}^L \frac{e^{ax} \,dx}{\cosh(x)}+\int_L^{-L} \frac{e^{a(x+\pi i)} \, dx}{\cosh(x+\pi i)} = (1+e^{a\pi i})\int_{-L}^L \frac{e^{ax} \, dx}{\cosh(x)}$$ using the fact that $\cosh(x+\pi i)=-\cosh(x)$. $$\Rightarrow -ie^{\frac{ai\pi}{2}} = (1+e^{a\pi i})\int_{-L}^L \frac{e^{ax} \, dx}{\cosh(x)} + \int_0^\pi \frac{e^{a(L+iy)}i \, dy}{\cosh(L+iy)}+\int_\pi^0 \frac{e^{a(-L+iy)}i \, dy}{\cosh(-L+iy)}$$ Then after showing that $\int_0^\pi \frac{e^{a(L+iy)}i \, dy}{\cosh(L+iy)}$, $\int_\pi^0 \frac{e^{a(-L+iy)}i\,dy}{\cosh(-L+iy)} \rightarrow 0$ as $L\rightarrow \infty$ we find that $$-ie^{\frac{ai\pi}{2}} = (1+e^{a\pi i})\int_{-\infty}^\infty \frac{e^{ax} \, dx}{\cosh(x)}$$ $$\Rightarrow \int_{-\infty}^\infty \frac{e^{ax} \, dx}{\cosh(x)} = \frac{-i e^{\frac{ai\pi}{2}}}{(1+e^{a\pi i})}$$","I tried the following problem but I don't think I got the right answer. I checked it by substituting $a=\frac{1}{2}$ into the integral and putting that through Wolfram Alpha but it didn't match the answer I found when I substituted $a=\frac{1}{2}$ into my final answer. So I would be so grateful if someone could tell me where I went wrong. I'm not sure if there's an easier contour than a rectangle but if there is please don't suggest any because I was required to solve this problem using a rectangular contour. Thank you in advance! :) Problem: Evaluate $$\int_{-\infty}^\infty \frac{e^{ax} \, dx}{\cosh(x)}$$ where $-1<\operatorname{Re}(a)<1$ using a rectangular contour integral and residue calculus. My attempt: $$\cosh(z)=\cos(iz)=0$$ $$z=\frac{i\pi}{2}-k\pi i,k\in Z$$ Let $L>0$ be a real number, and $C_1, C_2, C_3, C_4$ be the line segments that go from $-L$ to $L$, from $L$ to $L+\pi i$, from $L + \pi i$ to $-L+\pi i$ and from $-L+\pi i$ to $-L$, respectively.  Let $C = C_1 + C_2 + C_3 + C_4$, a  rectangular contour surrounding the singularity $z=\frac{i\pi}{2}$. $$\oint_C\frac{e^{az} \, dz}{\cosh(z)}=\int_{-L}^L \frac{e^{ax}dx}{\cosh(x)} + \int_0^\pi \frac{e^{a(L+iy)}i \, dy}{\cosh(L+iy)}+\int_L^{-L} \frac{e^{a(x+\pi i)} \, dx}{\cosh(x+\pi i)}+\int_\pi^0 \frac{e^{a(-L+iy)}i \, dy}{\cosh(-L+iy)}$$ Now, $$\oint_C\frac{e^{az} \, dz}{\cosh(z)}=2\pi i \operatorname{Res} \left(\frac{e^{az}}{\cosh(z)};\frac{i\pi}{2}\right) =2\pi i \lim_{z \rightarrow \frac{i\pi}{2}}\frac{e^{az}(z-\frac{i\pi}{2})}{\cosh(z)}=-ie^{\frac{ai\pi}{2}}$$ and $$\int_{-L}^L \frac{e^{ax} \,dx}{\cosh(x)}+\int_L^{-L} \frac{e^{a(x+\pi i)} \, dx}{\cosh(x+\pi i)} = (1+e^{a\pi i})\int_{-L}^L \frac{e^{ax} \, dx}{\cosh(x)}$$ using the fact that $\cosh(x+\pi i)=-\cosh(x)$. $$\Rightarrow -ie^{\frac{ai\pi}{2}} = (1+e^{a\pi i})\int_{-L}^L \frac{e^{ax} \, dx}{\cosh(x)} + \int_0^\pi \frac{e^{a(L+iy)}i \, dy}{\cosh(L+iy)}+\int_\pi^0 \frac{e^{a(-L+iy)}i \, dy}{\cosh(-L+iy)}$$ Then after showing that $\int_0^\pi \frac{e^{a(L+iy)}i \, dy}{\cosh(L+iy)}$, $\int_\pi^0 \frac{e^{a(-L+iy)}i\,dy}{\cosh(-L+iy)} \rightarrow 0$ as $L\rightarrow \infty$ we find that $$-ie^{\frac{ai\pi}{2}} = (1+e^{a\pi i})\int_{-\infty}^\infty \frac{e^{ax} \, dx}{\cosh(x)}$$ $$\Rightarrow \int_{-\infty}^\infty \frac{e^{ax} \, dx}{\cosh(x)} = \frac{-i e^{\frac{ai\pi}{2}}}{(1+e^{a\pi i})}$$",,['complex-analysis']
1,Relationship between Möbius transformations and flows/vector fields,Relationship between Möbius transformations and flows/vector fields,,"I've noticed that the pictures illustrating the effect of Möbius transformations on the Riemann sphere (after stereographic projection to the plane) resemble the phase portrait of a vector field. For instance: This is the representation of a hyperbolic transformation (from Wikipedia ), and seems very similar to the phase portrait of a field generated by a positive and a negative charge located at the fixed points of the transformation (that is, of an irrotational and incompressible field). One could ever think of linking the fact that poles have integer order to the discretization of charges, using Gauss's divergence theorem. I guess the analogy arises from conformal mappings satisfying Laplace's equation, but I wonder how far can one push it. This is where I'm doubting: in the example cited above, hyperbolic transformations are the stereographic projection of discrete rotations of the sphere. In general, Möbius transformations are discrete mappings from the Riemann sphere to itself, whereas a vector field suggests a continuous flow. Could we rigorously obtain a one-parameter subgroup of continuous transformations from those infinitesimal, discrete transformations, and could we define a (unique) vector field corresponding to this continuous subgroup (for example, writing each transformation as a differential equation)? How? Please excuse me if my approach is hand-waving, I don't know much about this subject.","I've noticed that the pictures illustrating the effect of Möbius transformations on the Riemann sphere (after stereographic projection to the plane) resemble the phase portrait of a vector field. For instance: This is the representation of a hyperbolic transformation (from Wikipedia ), and seems very similar to the phase portrait of a field generated by a positive and a negative charge located at the fixed points of the transformation (that is, of an irrotational and incompressible field). One could ever think of linking the fact that poles have integer order to the discretization of charges, using Gauss's divergence theorem. I guess the analogy arises from conformal mappings satisfying Laplace's equation, but I wonder how far can one push it. This is where I'm doubting: in the example cited above, hyperbolic transformations are the stereographic projection of discrete rotations of the sphere. In general, Möbius transformations are discrete mappings from the Riemann sphere to itself, whereas a vector field suggests a continuous flow. Could we rigorously obtain a one-parameter subgroup of continuous transformations from those infinitesimal, discrete transformations, and could we define a (unique) vector field corresponding to this continuous subgroup (for example, writing each transformation as a differential equation)? How? Please excuse me if my approach is hand-waving, I don't know much about this subject.",,"['complex-analysis', 'geometry', 'lie-groups', 'dynamical-systems', 'vector-analysis']"
2,Is there a deep reason why replacing $\cos(x)$ with $e^{ix}$ and taking the real part often makes a contour integral work out?,Is there a deep reason why replacing  with  and taking the real part often makes a contour integral work out?,\cos(x) e^{ix},"I'm grading a complex analysis course right now and it turns out to involve a lot of contour integration.  For instance, students are asked to find the integral $$\int_0^\infty \frac{\cos (ax)}{(x^2 + b^2)^2} \, dx$$ where $a, b > 0$ are real parameters.  This can be done as follows: \begin{align} \int_0^\infty \frac{\cos (ax)}{(x^2 + b^2)^2} \, dx & = \frac{1}{2} \int_{-\infty}^\infty \frac{\cos (ax)}{(x^2 + b^2)^2} \, dx \\ \\ &= \frac{1}{2} \operatorname{Re} \left[\int_{-\infty}^\infty \frac{e^{iax}}{(x^2 + b^2)^2} \, dx\right] \\ \\ &= \frac{1}{2} \operatorname{Re} \left[\lim_{R \to \infty} \int_{-R}^R \frac{e^{iax}}{(x^2 + b^2)^2} \, dx\right]. \end{align} Now $$\int_{-R}^R \frac{e^{iax} \, dx}{(x^2 + b^2)^2} = \oint_{L_R+C_R} \frac{e^{iaz}\, dz}{(z^2 + b^2)^2} - \oint_{C_R} \frac{e^{iaz} \, dz}{(z^2 + b^2)^2}$$ where $L_R$ is the line segment going from $-R$ to $R$ and $C_R$ is the circular arc with center 0 going from $R$ to $-R$. By the residue theorem, $$\oint_{L_R+C_R} \frac{e^{iaz}\, dz}{(z^2 + b^2)^2} = 2 \pi i \operatorname{res}_{z=bi} \left[\frac{e^{iaz}}{(z^2 + b^2)^2}\right] = \frac{\pi e^{-ab} (1 + ab)}{2 b^3}$$ for $R > b$.  Further, by Jordan's lemma \begin{align} \left|\left|\oint_{C_R} \frac{e^{iaz} \, dz}{(z^2 + b^2)^2}\right|\right| &\leq \frac{\pi}{a} \max_{z \in C_r} \left|\left|\frac{1}{(z^2 + b^2)^2}\right|\right| = \frac{\pi}{a(R^2 + b^2)^2} \to 0 \end{align} as $R \to 0$, from which we see that $$\int_0^\infty \frac{\cos (ax)}{(x^2 + b^2)^2} \, dx = \frac{\pi e^{-ab} (1 + ab)}{4 b^3}.$$ Suppose, however, that instead of writing $\cos(a x)$ as $\operatorname{Re}[e^{i x}]$ and pulling the $\operatorname{Re}$ outside the integral we'd tried to do things the same way directly.  The problem in this case is that the integral $$\oint_{C_R} \frac{\cos(az)}{(z^2 + b^2)^2}$$ doesn't vanish as $R \to \infty$.  By adding an extra term to our equation, though, we managed to make things work out quite nicely. If I try to distill the general technique here, it's something like this: We had a function $f(z)$ for which  $$\lim_{R \to \infty} \oint_{C_R} f(z) \, dz$$ didn't vanish, so we found a function $g(z)$ which vanished along $L_R$ and for which $$\lim_{R \to \infty} \oint_{C_R} f(z) + g(z) \, dz$$ vanished.  However, it seems incredibly fortuitous that we had such a readily available choice for $g$.  Is this just a consequence of picking a homework problem that can actually be done with pencil in paper in a reasonable amount of time?  Or is something deeper going on? Specific questions: Given a function $f$, is there any nice way of rephrasing the condition that $$\oint_{C_R} f(z)\, dz \to 0 \text{ as } R \to \infty$$ as a more straightforward property of $f$?  (At first I wondered if $C_R$ was ""a closed curve around $\infty$ in the limit"" but this doesn't seem to be right.) Given a meromorphic function $f$ such that $$\oint_{C_R} f(z)\, dz \not \to 0 \text{ as } R \to \infty,$$ can we always find a meromorphic function $g$ such that $g|_\mathbb{R} = 0$ and $$\lim_{R \to \infty} \oint_{C_R} f(z) + g(z) =0?$$ If not, are there any nice constraints on $f$ that make it possible?  If so, how many such $g$ are there, and can we construct one of them easily? Same questions as above with $L_R$ and $C_R$ replaced by more general curves.","I'm grading a complex analysis course right now and it turns out to involve a lot of contour integration.  For instance, students are asked to find the integral $$\int_0^\infty \frac{\cos (ax)}{(x^2 + b^2)^2} \, dx$$ where $a, b > 0$ are real parameters.  This can be done as follows: \begin{align} \int_0^\infty \frac{\cos (ax)}{(x^2 + b^2)^2} \, dx & = \frac{1}{2} \int_{-\infty}^\infty \frac{\cos (ax)}{(x^2 + b^2)^2} \, dx \\ \\ &= \frac{1}{2} \operatorname{Re} \left[\int_{-\infty}^\infty \frac{e^{iax}}{(x^2 + b^2)^2} \, dx\right] \\ \\ &= \frac{1}{2} \operatorname{Re} \left[\lim_{R \to \infty} \int_{-R}^R \frac{e^{iax}}{(x^2 + b^2)^2} \, dx\right]. \end{align} Now $$\int_{-R}^R \frac{e^{iax} \, dx}{(x^2 + b^2)^2} = \oint_{L_R+C_R} \frac{e^{iaz}\, dz}{(z^2 + b^2)^2} - \oint_{C_R} \frac{e^{iaz} \, dz}{(z^2 + b^2)^2}$$ where $L_R$ is the line segment going from $-R$ to $R$ and $C_R$ is the circular arc with center 0 going from $R$ to $-R$. By the residue theorem, $$\oint_{L_R+C_R} \frac{e^{iaz}\, dz}{(z^2 + b^2)^2} = 2 \pi i \operatorname{res}_{z=bi} \left[\frac{e^{iaz}}{(z^2 + b^2)^2}\right] = \frac{\pi e^{-ab} (1 + ab)}{2 b^3}$$ for $R > b$.  Further, by Jordan's lemma \begin{align} \left|\left|\oint_{C_R} \frac{e^{iaz} \, dz}{(z^2 + b^2)^2}\right|\right| &\leq \frac{\pi}{a} \max_{z \in C_r} \left|\left|\frac{1}{(z^2 + b^2)^2}\right|\right| = \frac{\pi}{a(R^2 + b^2)^2} \to 0 \end{align} as $R \to 0$, from which we see that $$\int_0^\infty \frac{\cos (ax)}{(x^2 + b^2)^2} \, dx = \frac{\pi e^{-ab} (1 + ab)}{4 b^3}.$$ Suppose, however, that instead of writing $\cos(a x)$ as $\operatorname{Re}[e^{i x}]$ and pulling the $\operatorname{Re}$ outside the integral we'd tried to do things the same way directly.  The problem in this case is that the integral $$\oint_{C_R} \frac{\cos(az)}{(z^2 + b^2)^2}$$ doesn't vanish as $R \to \infty$.  By adding an extra term to our equation, though, we managed to make things work out quite nicely. If I try to distill the general technique here, it's something like this: We had a function $f(z)$ for which  $$\lim_{R \to \infty} \oint_{C_R} f(z) \, dz$$ didn't vanish, so we found a function $g(z)$ which vanished along $L_R$ and for which $$\lim_{R \to \infty} \oint_{C_R} f(z) + g(z) \, dz$$ vanished.  However, it seems incredibly fortuitous that we had such a readily available choice for $g$.  Is this just a consequence of picking a homework problem that can actually be done with pencil in paper in a reasonable amount of time?  Or is something deeper going on? Specific questions: Given a function $f$, is there any nice way of rephrasing the condition that $$\oint_{C_R} f(z)\, dz \to 0 \text{ as } R \to \infty$$ as a more straightforward property of $f$?  (At first I wondered if $C_R$ was ""a closed curve around $\infty$ in the limit"" but this doesn't seem to be right.) Given a meromorphic function $f$ such that $$\oint_{C_R} f(z)\, dz \not \to 0 \text{ as } R \to \infty,$$ can we always find a meromorphic function $g$ such that $g|_\mathbb{R} = 0$ and $$\lim_{R \to \infty} \oint_{C_R} f(z) + g(z) =0?$$ If not, are there any nice constraints on $f$ that make it possible?  If so, how many such $g$ are there, and can we construct one of them easily? Same questions as above with $L_R$ and $C_R$ replaced by more general curves.",,"['complex-analysis', 'contour-integration']"
3,Conformal map from disk with smaller disk removed to upper half plane,Conformal map from disk with smaller disk removed to upper half plane,,"I'm working on a problem that was a previous complex qualifying exam at my university. I believe I have a solution, but I'm not entirely confident in it. The problem is as follows: Find a one-to-one conformal map of the region $\Omega=\{z\in\mathbb{C}\,|\,|z|<2\text{ and }|z-1|>1\}$ onto the upper half plane. Here's my attempt: The region $\Omega$ can be mapped to the vertical strip $\{z\in\mathbb{C}\,|\, -1/2<\text{Re }(z)<-1/4\}$ by the map $z\mapsto\frac{1}{z-2}$. Then $z\mapsto\left(\frac{4\pi}{z-2}+2\pi\right)i$  maps $\Omega$ to the horizontal strip $\{z\in\mathbb{C}\,|\,0<\text{Im }(z)<\pi\}$. Lastly $$ z\mapsto \exp\left(\frac{4\pi}{z-2}i+2\pi i\right) $$ or $$ z\mapsto\exp\left(\frac{4\pi}{z-2}i\right) $$ should map to the upper half plane. Is this correct? Is there any easier way to see this? Any input would be greatly appreciated, thanks in advance.","I'm working on a problem that was a previous complex qualifying exam at my university. I believe I have a solution, but I'm not entirely confident in it. The problem is as follows: Find a one-to-one conformal map of the region $\Omega=\{z\in\mathbb{C}\,|\,|z|<2\text{ and }|z-1|>1\}$ onto the upper half plane. Here's my attempt: The region $\Omega$ can be mapped to the vertical strip $\{z\in\mathbb{C}\,|\, -1/2<\text{Re }(z)<-1/4\}$ by the map $z\mapsto\frac{1}{z-2}$. Then $z\mapsto\left(\frac{4\pi}{z-2}+2\pi\right)i$  maps $\Omega$ to the horizontal strip $\{z\in\mathbb{C}\,|\,0<\text{Im }(z)<\pi\}$. Lastly $$ z\mapsto \exp\left(\frac{4\pi}{z-2}i+2\pi i\right) $$ or $$ z\mapsto\exp\left(\frac{4\pi}{z-2}i\right) $$ should map to the upper half plane. Is this correct? Is there any easier way to see this? Any input would be greatly appreciated, thanks in advance.",,"['complex-analysis', 'conformal-geometry']"
4,"What word means ""the property of being holomorphic""?","What word means ""the property of being holomorphic""?",,"As in the title, I am looking for a single word meaning ""the property of being holomorphic"". The obvious candidates are ""holomorphy"" and ""holomorphicity"" but both look wrong to my eye.  ""Holomorphism"" would seem to mean ""a holomorphic function"" rather than referring to the property itself. As an analogy, the phrase ""because $f$ is continuous"" can be rephrased as ""by the continuity of $f$"".  I would like a word that I can use to rephrase ""because $f$ is holomorphic"" as ""by the ________ of $f$"". In SAT notation: continuous : continuity :: holomorphic : ? (This almost belongs on English.SE but I am specifically interested in idiomatic usage in mathematical writing rather than textbook grammar, if they conflict.) Edit : Regarding the suggestions to use ""analyticity"" or ""complex differentiability"", we have been using ""holomorphic"" consistently through the rest of the paper and I think it would be confusing to switch.  Moreover, my understanding is that ""analytic"" refers specifically to being representable as a power series - in our paper we are working on a complex manifold, so this notion isn't immediately applicable.","As in the title, I am looking for a single word meaning ""the property of being holomorphic"". The obvious candidates are ""holomorphy"" and ""holomorphicity"" but both look wrong to my eye.  ""Holomorphism"" would seem to mean ""a holomorphic function"" rather than referring to the property itself. As an analogy, the phrase ""because $f$ is continuous"" can be rephrased as ""by the continuity of $f$"".  I would like a word that I can use to rephrase ""because $f$ is holomorphic"" as ""by the ________ of $f$"". In SAT notation: continuous : continuity :: holomorphic : ? (This almost belongs on English.SE but I am specifically interested in idiomatic usage in mathematical writing rather than textbook grammar, if they conflict.) Edit : Regarding the suggestions to use ""analyticity"" or ""complex differentiability"", we have been using ""holomorphic"" consistently through the rest of the paper and I think it would be confusing to switch.  Moreover, my understanding is that ""analytic"" refers specifically to being representable as a power series - in our paper we are working on a complex manifold, so this notion isn't immediately applicable.",,"['complex-analysis', 'terminology', 'article-writing']"
5,Understanding branch cuts by manually choosing the branch cuts of a function,Understanding branch cuts by manually choosing the branch cuts of a function,,"Below I will explain what I have done in order to illustrate my confusion with branch cuts of a typical function. If I say something wrong at any point please do not hesitate to correct me! In order to understand branch cuts and to go about implementing tailored versions of multivalued complex functions in python (or any other language), I have experimented with some implementations, and the writing in this post can be thought of me ""thinking aloud."" I will explain all the code so it won't be necessary to know python specifically, its basically pseudo code anyway. So lets start, I have the complex function: \begin{align} w = \sqrt{z^2-1}. \end{align} With $z=x+iy$. This function will be used in a computer program, and I want to ensure that for all values $z$ can take on along a specified path, $w$ will remain continuous. Furthermore let's say for this particular problem that I want to ensure that my branch cuts are +1 to $+\infty$ and -1 to $-\infty$, and that $w$ is continuous in the upper half plane. I don't trust the way standard functions in python handle branch cuts, so I start by looking at real and imaginary $w$ over the argand plane. Here is the python version: def python_func(z):     return np.sqrt(z**2-1) #pretty self explanatory: returns sqrt(z^2-1) for a given z I then take this function and plot the real and imaginary parts over the argand plane: So it appears python introduces a discontinuity along the imaginary axis! This is not what I want so I decide to define my own version of the function above. The code consists mainly of two functions, a ""myatan"" which manually assigns the inverse tangent in the range $(0,2\pi)$ as a point moves along the quadrants anti-clockwise, and ""my_func"" which implements my required version of $w$. In constructing this function I reason as follows: For the required branch cuts above, if $|z|<1$ then arg$(w)$ should be continuous around the origin. But if $|z|>1$ then we need to factorize $ \sqrt{z^2-1}=\sqrt{z-1}\sqrt{z+1}$ and look at each factor in turn: $\sqrt{z-1}$: make arg$(\sqrt{z-1})$ jump across the line +1 to $+\infty$ $\sqrt{z+1}$: make arg$(\sqrt{z+1})$ jump across the line -1 to $-\infty$ The python definition of the functions are: import numpy as np #a module needed for some of the math functions used. import math         #a module needed for some of the math functions used.  #(x,y) are the coordinates of a point on a 2D plane # the math.atan function does what you expects, it returns the inverse tangent as in a triangle   def myatan(y,x):       if y == 0:            if x > 0:                 return 0            if x < 0:                 return np.pi            if x == 0:                 return 0       if y > 0:            if x > 0:                 return math.atan(y/x)            if x < 0:                 return np.pi + math.atan(y/x)            if x == 0:                 return np.pi/2       if y < 0:            if x > 0:                 return 2*np.pi + math.atan(y/x)            if x < 0:                 return np.pi + math.atan(y/x)            if x == 0:                 return 1.5*np.pi   def my_func(z):     """"""Calculate sqrt(z^2-1) for a complex number z. Manually choose branch cuts.     """"""     #For reference all functions return what their name suggests: abs() returns the magnitude of a complex number,      #np.imag() the imaginary part, np.real() the real part of a number etc.     temp = z**2-1     if abs(z) < 1: #if condition is true execute the next few lines indented          theta = myatan(np.imag(temp),np.real(temp))         return np.sqrt(abs(temp))*np.exp(1j*theta/2)                 elif abs(z) > 1: #else if condition is true execute the next few lines indented          q1, q2 = z-1, z+1     r1, theta1 = abs(q1), myatan(np.imag(q1),np.real(q1))      #should be a jump on the positive real axis     r2, theta2 = abs(q2), math.atan2(np.imag(q2),np.real(q2)) #should jump on the negative real axis         return np.sqrt(r1*r2)*np.exp(1j/2*(theta1+theta2)) With this new definition of our function we get the following plot: and now there are clear branch cuts as we want them. However the plots from the two methods look very different and so I started thinking, am I really getting the value I am supposed to from my customised function? To look at the values returned by the function I decided to plot the real and imaginary values of $w$ as I walk along a circle of different radii: For circle radius 0.9, we see that my_func does not have any jumps as we want: For circle radius 1.1, we see that my_func has jumps at $\theta = \pi$ and $\theta = 2\pi$ as expected: The only problem I have is this: I am happy with the branch cuts of my function: it seems that I have gotten that part right because my_func is continuous in the range I want it to be. But how do I know that it takes on the right value in that range? I am using this function in a physics based simulation, so it should clearly matter whether the real/imaginary part of $w$ takes on the negative or positive possibility as can be seen from the latest graphs above. How do I know I am calculating the correct ""version"" of my function given the branch cuts I have chosen?","Below I will explain what I have done in order to illustrate my confusion with branch cuts of a typical function. If I say something wrong at any point please do not hesitate to correct me! In order to understand branch cuts and to go about implementing tailored versions of multivalued complex functions in python (or any other language), I have experimented with some implementations, and the writing in this post can be thought of me ""thinking aloud."" I will explain all the code so it won't be necessary to know python specifically, its basically pseudo code anyway. So lets start, I have the complex function: \begin{align} w = \sqrt{z^2-1}. \end{align} With $z=x+iy$. This function will be used in a computer program, and I want to ensure that for all values $z$ can take on along a specified path, $w$ will remain continuous. Furthermore let's say for this particular problem that I want to ensure that my branch cuts are +1 to $+\infty$ and -1 to $-\infty$, and that $w$ is continuous in the upper half plane. I don't trust the way standard functions in python handle branch cuts, so I start by looking at real and imaginary $w$ over the argand plane. Here is the python version: def python_func(z):     return np.sqrt(z**2-1) #pretty self explanatory: returns sqrt(z^2-1) for a given z I then take this function and plot the real and imaginary parts over the argand plane: So it appears python introduces a discontinuity along the imaginary axis! This is not what I want so I decide to define my own version of the function above. The code consists mainly of two functions, a ""myatan"" which manually assigns the inverse tangent in the range $(0,2\pi)$ as a point moves along the quadrants anti-clockwise, and ""my_func"" which implements my required version of $w$. In constructing this function I reason as follows: For the required branch cuts above, if $|z|<1$ then arg$(w)$ should be continuous around the origin. But if $|z|>1$ then we need to factorize $ \sqrt{z^2-1}=\sqrt{z-1}\sqrt{z+1}$ and look at each factor in turn: $\sqrt{z-1}$: make arg$(\sqrt{z-1})$ jump across the line +1 to $+\infty$ $\sqrt{z+1}$: make arg$(\sqrt{z+1})$ jump across the line -1 to $-\infty$ The python definition of the functions are: import numpy as np #a module needed for some of the math functions used. import math         #a module needed for some of the math functions used.  #(x,y) are the coordinates of a point on a 2D plane # the math.atan function does what you expects, it returns the inverse tangent as in a triangle   def myatan(y,x):       if y == 0:            if x > 0:                 return 0            if x < 0:                 return np.pi            if x == 0:                 return 0       if y > 0:            if x > 0:                 return math.atan(y/x)            if x < 0:                 return np.pi + math.atan(y/x)            if x == 0:                 return np.pi/2       if y < 0:            if x > 0:                 return 2*np.pi + math.atan(y/x)            if x < 0:                 return np.pi + math.atan(y/x)            if x == 0:                 return 1.5*np.pi   def my_func(z):     """"""Calculate sqrt(z^2-1) for a complex number z. Manually choose branch cuts.     """"""     #For reference all functions return what their name suggests: abs() returns the magnitude of a complex number,      #np.imag() the imaginary part, np.real() the real part of a number etc.     temp = z**2-1     if abs(z) < 1: #if condition is true execute the next few lines indented          theta = myatan(np.imag(temp),np.real(temp))         return np.sqrt(abs(temp))*np.exp(1j*theta/2)                 elif abs(z) > 1: #else if condition is true execute the next few lines indented          q1, q2 = z-1, z+1     r1, theta1 = abs(q1), myatan(np.imag(q1),np.real(q1))      #should be a jump on the positive real axis     r2, theta2 = abs(q2), math.atan2(np.imag(q2),np.real(q2)) #should jump on the negative real axis         return np.sqrt(r1*r2)*np.exp(1j/2*(theta1+theta2)) With this new definition of our function we get the following plot: and now there are clear branch cuts as we want them. However the plots from the two methods look very different and so I started thinking, am I really getting the value I am supposed to from my customised function? To look at the values returned by the function I decided to plot the real and imaginary values of $w$ as I walk along a circle of different radii: For circle radius 0.9, we see that my_func does not have any jumps as we want: For circle radius 1.1, we see that my_func has jumps at $\theta = \pi$ and $\theta = 2\pi$ as expected: The only problem I have is this: I am happy with the branch cuts of my function: it seems that I have gotten that part right because my_func is continuous in the range I want it to be. But how do I know that it takes on the right value in that range? I am using this function in a physics based simulation, so it should clearly matter whether the real/imaginary part of $w$ takes on the negative or positive possibility as can be seen from the latest graphs above. How do I know I am calculating the correct ""version"" of my function given the branch cuts I have chosen?",,"['complex-analysis', 'branch-cuts']"
6,"Dirichlet problem in the disk: behavior of conjugate function, and the effect of discontinuities","Dirichlet problem in the disk: behavior of conjugate function, and the effect of discontinuities",,"Dirichlet's problem in the unit disk is to construct the harmonic function from the given continuous function on the boundary circle. It is solved by the convolution with the Poisson kernel, and we know that the constructed function has uniform limit which is the given continuous function as $r\to 1$, and we can complexify the solution by taking the Schwarz integral formula. Now (in this very particular case) does the imaginary part has a uniform limit ? If it does, why don't we prove the uniqueness of the solution by a simple application of the Cauchy integral formula ? Here is the proof that I reckon to be reasonable(which is what I expose here to be criticised) We construct the Schwarz integral, or $\frac{1}{2\pi}\int _{0}^{2\pi}\frac{\exp(it)+z}{\exp{(it)}-z}u(\exp{(it)})\mathrm{d}t$. This function is an analytic function in the interior unit disk, and is continuous in the closed unit disk(its closure). Let this analytic function denoted by $f$, and another analytic function that has the same uniform limit function on the circle be $v$. Then $u-v$ is an complex analytic function in the interior of the unit disk, continuous on the closure, with boundary value identically zero. An application of Cauchy's integral formula gives rise to the conclusion that $u-v$ in identically zero on the entire disk. Another question being if the boundary function has finite jump discontinuities, what is the behaviour of the convolution with the Poisson kernel near the discontinuous points ?","Dirichlet's problem in the unit disk is to construct the harmonic function from the given continuous function on the boundary circle. It is solved by the convolution with the Poisson kernel, and we know that the constructed function has uniform limit which is the given continuous function as $r\to 1$, and we can complexify the solution by taking the Schwarz integral formula. Now (in this very particular case) does the imaginary part has a uniform limit ? If it does, why don't we prove the uniqueness of the solution by a simple application of the Cauchy integral formula ? Here is the proof that I reckon to be reasonable(which is what I expose here to be criticised) We construct the Schwarz integral, or $\frac{1}{2\pi}\int _{0}^{2\pi}\frac{\exp(it)+z}{\exp{(it)}-z}u(\exp{(it)})\mathrm{d}t$. This function is an analytic function in the interior unit disk, and is continuous in the closed unit disk(its closure). Let this analytic function denoted by $f$, and another analytic function that has the same uniform limit function on the circle be $v$. Then $u-v$ is an complex analytic function in the interior of the unit disk, continuous on the closure, with boundary value identically zero. An application of Cauchy's integral formula gives rise to the conclusion that $u-v$ in identically zero on the entire disk. Another question being if the boundary function has finite jump discontinuities, what is the behaviour of the convolution with the Poisson kernel near the discontinuous points ?",,"['complex-analysis', 'partial-differential-equations', 'fourier-analysis', 'harmonic-functions']"
7,Integral formulation for the solution of $xy'' + y' = y$,Integral formulation for the solution of,xy'' + y' = y,"Let's say that $y$ satisfies the following ODE: $$xy'' + y' = y$$ I want to formulate $y$ as a contour integral. I know that the final result I should get is: $$y(x)=\frac{1}{2i\pi} \int_{C}{\frac{1}{t}e^{\sqrt{x}(t+1/t)}dt}$$ where $C$ is an appropriate contour. However, I don't know where to start in order to derive this result. PS: There are some similarities between this integral formulation and that of the Modified Bessel Function of the First Kind , $I_n(x)$, as we can observe by looking at expression (1) in Mathworld.","Let's say that $y$ satisfies the following ODE: $$xy'' + y' = y$$ I want to formulate $y$ as a contour integral. I know that the final result I should get is: $$y(x)=\frac{1}{2i\pi} \int_{C}{\frac{1}{t}e^{\sqrt{x}(t+1/t)}dt}$$ where $C$ is an appropriate contour. However, I don't know where to start in order to derive this result. PS: There are some similarities between this integral formulation and that of the Modified Bessel Function of the First Kind , $I_n(x)$, as we can observe by looking at expression (1) in Mathworld.",,"['complex-analysis', 'analysis', 'ordinary-differential-equations']"
8,Extended Proof of the Theorem that a bounded analytic function is constant.,Extended Proof of the Theorem that a bounded analytic function is constant.,,"I am having trouble feeling convinced by my proof and more importantly - feeling confident in my working out. The question reads (a)  Let $f$ be an entire function such that there exist real constants $M$ and $N$ such that $|f(z)|<M|z|+N$ for all $z$ . Prove that for any three pairwise different complex numbers $a,b,c$ , $\frac{f(a)}{(a-b)(a-c)}+\frac{f(b)}{(b-a)(b-c)}+\frac{f(c)}{(c-a)(c-b)}=0$ . (b) Deduce that there are constants $A,B\in\mathbb{C}$ such that $f(z)=Az+B$ for all $z$ . So to begin, I realise that the LHS of the equality that I am required to prove is simply the sum of residues (without $2\pi i$ ) of the integral $\oint_{\Gamma}\frac{f(z)}{(z-a)(z-b)(z-c)}dz$ . That is, $$\oint_{\Gamma}\frac{f(z)}{(z-a)(z-b)(z-c)}dz=2\pi i\left(\frac{f(a)}{(a-b)(a-c)}+\frac{f(b)}{(b-a)(b-c)}+\frac{f(c)}{(c-a)(c-b)}\right),$$ for $\Gamma$ being the circle contour of radius $R$ . Furthermore, for the equality to hold, singularities at $z=a,b,c$ must be inside $\Gamma$ . So the next chain of thought would be show that $$\oint_{\Gamma}\frac{f(z)}{(z-a)(z-b)(z-c)}dz=0.$$ This will obviously yield the result I want. I relate to limits and the M-L Lemma to do this. So, $$\left|\frac{f(z)}{(z-a)(z-b)(z-c)}dz\right|\leq\frac{MR+N}{(R-|a|)(R-|b|)(R-|c|)},$$ by the equality given in the question, reserve triangle inequality and since complex numbers $a,b,c$ lie inside the contour thus $|a|,|b|,|c|<R$ . Thus by the M-L lemma we have that $$lim_{R\to\infty}\left|\oint_{\Gamma}\frac{f(z)}{(z-a)(z-b)(z-c)}dz\right|\leq \lim_{R\to\infty}\frac{(MR+N)2\pi R}{(R-|a|)(R-|b|)(R- |c|)}$$ Clearly the RHS of the inequality converges to $0$ . Thus $$lim_{R\to\infty}\oint_{\Gamma}\frac{f(z)}{(z-a)(z-b)(z-c)}dz=0.$$ But we know that $$lim_{R\to\infty}\oint_{\Gamma}\frac{f(z)}{(z-a)(z-b)(z-c)}dz=lim_{R\to\infty}2\pi i\left(\frac{f(a)}{(a-b)(a-c)}+\frac{f(b)}{(b-a)(b-c)}+\frac{f(c)}{(c-a)(c-b)}\right).$$ So $$2\pi i\left(\frac{f(a)}{(a-b)(a-c)}+\frac{f(b)}{(b-a)(b-c)}+\frac{f(c)}{(c-a)(c-b)}\right)=0$$ $$\implies\left(\frac{f(a)}{(a-b)(a-c)}+\frac{f(b)}{(b-a)(b-c)}+\frac{f(c)}{(c-a)(c-b)}\right)=0.$$ With part (b), I begin by using the result I proved. Simplifying the expression I have that $$f(a)(b-c)+f(b)(c-a)+f(c)(a-b)=0.$$ It's clear that if I let $f(z)=Az+B$ and substitute it into the equation above then I am done. Is this valid though? Thank you to all for your time in advanced.","I am having trouble feeling convinced by my proof and more importantly - feeling confident in my working out. The question reads (a)  Let be an entire function such that there exist real constants and such that for all . Prove that for any three pairwise different complex numbers , . (b) Deduce that there are constants such that for all . So to begin, I realise that the LHS of the equality that I am required to prove is simply the sum of residues (without ) of the integral . That is, for being the circle contour of radius . Furthermore, for the equality to hold, singularities at must be inside . So the next chain of thought would be show that This will obviously yield the result I want. I relate to limits and the M-L Lemma to do this. So, by the equality given in the question, reserve triangle inequality and since complex numbers lie inside the contour thus . Thus by the M-L lemma we have that Clearly the RHS of the inequality converges to . Thus But we know that So With part (b), I begin by using the result I proved. Simplifying the expression I have that It's clear that if I let and substitute it into the equation above then I am done. Is this valid though? Thank you to all for your time in advanced.","f M N |f(z)|<M|z|+N z a,b,c \frac{f(a)}{(a-b)(a-c)}+\frac{f(b)}{(b-a)(b-c)}+\frac{f(c)}{(c-a)(c-b)}=0 A,B\in\mathbb{C} f(z)=Az+B z 2\pi i \oint_{\Gamma}\frac{f(z)}{(z-a)(z-b)(z-c)}dz \oint_{\Gamma}\frac{f(z)}{(z-a)(z-b)(z-c)}dz=2\pi i\left(\frac{f(a)}{(a-b)(a-c)}+\frac{f(b)}{(b-a)(b-c)}+\frac{f(c)}{(c-a)(c-b)}\right), \Gamma R z=a,b,c \Gamma \oint_{\Gamma}\frac{f(z)}{(z-a)(z-b)(z-c)}dz=0. \left|\frac{f(z)}{(z-a)(z-b)(z-c)}dz\right|\leq\frac{MR+N}{(R-|a|)(R-|b|)(R-|c|)}, a,b,c |a|,|b|,|c|<R lim_{R\to\infty}\left|\oint_{\Gamma}\frac{f(z)}{(z-a)(z-b)(z-c)}dz\right|\leq \lim_{R\to\infty}\frac{(MR+N)2\pi R}{(R-|a|)(R-|b|)(R- |c|)} 0 lim_{R\to\infty}\oint_{\Gamma}\frac{f(z)}{(z-a)(z-b)(z-c)}dz=0. lim_{R\to\infty}\oint_{\Gamma}\frac{f(z)}{(z-a)(z-b)(z-c)}dz=lim_{R\to\infty}2\pi i\left(\frac{f(a)}{(a-b)(a-c)}+\frac{f(b)}{(b-a)(b-c)}+\frac{f(c)}{(c-a)(c-b)}\right). 2\pi i\left(\frac{f(a)}{(a-b)(a-c)}+\frac{f(b)}{(b-a)(b-c)}+\frac{f(c)}{(c-a)(c-b)}\right)=0 \implies\left(\frac{f(a)}{(a-b)(a-c)}+\frac{f(b)}{(b-a)(b-c)}+\frac{f(c)}{(c-a)(c-b)}\right)=0. f(a)(b-c)+f(b)(c-a)+f(c)(a-b)=0. f(z)=Az+B","['complex-analysis', 'contour-integration', 'analyticity']"
9,How to better understand where the circles and lines go under fractional linear transformations?,How to better understand where the circles and lines go under fractional linear transformations?,,"Today I encountered the transformation $f(z) = \frac{z}{z-1}$. It has the following property: As the point $z$ makes a counter-clockwise revolution around the unit circle beginning at $1$, the point $f(z)$ parametrizes the line with real part $1/2$, travelling upward. This is not a difficult thing to verify with a bit of fiddling around. I used this fact to show that a certain operator had a gap in its spectrum. But, if I hadn't already expected this was going to happen for another reason, I would never have noticed the above property of this transformation. Another example: the Cayley transform $f(z) = \frac{z -i}{z+i}$. As $z$ travels the real line from left to right, $f(z)$ undergoes a counterclockwise revolution of the circle, beginning and ending at $1$. Again, this is easy to check. I'm aware of the phenomenon because the transform is relatively famous, but, if I had encountered this transformation ""in the wild"", I would never have expected the above property.  Which leads to my question: Is there some more systematic way to see where lines and circles go under fractional linear transformations $f(z) = \frac{az+b}{cz+d}$? I can verify expected facts by doing things like computing the norm, or real and imaginary parts of the right hand side, but I cannot help but feel like there is some gap in my knowledge that prevents me from really understanding what is going on.","Today I encountered the transformation $f(z) = \frac{z}{z-1}$. It has the following property: As the point $z$ makes a counter-clockwise revolution around the unit circle beginning at $1$, the point $f(z)$ parametrizes the line with real part $1/2$, travelling upward. This is not a difficult thing to verify with a bit of fiddling around. I used this fact to show that a certain operator had a gap in its spectrum. But, if I hadn't already expected this was going to happen for another reason, I would never have noticed the above property of this transformation. Another example: the Cayley transform $f(z) = \frac{z -i}{z+i}$. As $z$ travels the real line from left to right, $f(z)$ undergoes a counterclockwise revolution of the circle, beginning and ending at $1$. Again, this is easy to check. I'm aware of the phenomenon because the transform is relatively famous, but, if I had encountered this transformation ""in the wild"", I would never have expected the above property.  Which leads to my question: Is there some more systematic way to see where lines and circles go under fractional linear transformations $f(z) = \frac{az+b}{cz+d}$? I can verify expected facts by doing things like computing the norm, or real and imaginary parts of the right hand side, but I cannot help but feel like there is some gap in my knowledge that prevents me from really understanding what is going on.",,"['complex-analysis', 'special-functions', 'rational-functions']"
10,"Proving $g(\omega)=\frac{1}{2\pi i}\int_{\gamma}\frac{zf'(z)}{f(z)-\omega}\, dz$ where $g$ is the inverse of $f$",Proving  where  is the inverse of,"g(\omega)=\frac{1}{2\pi i}\int_{\gamma}\frac{zf'(z)}{f(z)-\omega}\, dz g f","I have the following exercise: Let $G$ be an open subset of $\mathbb{C}$ and let $f$ be a one to one   function in $H(G)$ such that $f'(z)\neq0$ for all $z\in G$. For each $\omega\in f(G)$ let $g(\omega)$ denote the unique complex   number $z\in G$ for which $f(z)=\omega$. Suppose that the closed disk $\overline{D(z_{o},r)}\subseteq G$ and   that $\gamma:[0,2\pi]\to G$ is the curve given by   $\gamma(t)=z_{0}+re^{it}$. Prove, with the help of the residue theorem, that, for every   $\omega\in f(D(z_{0},r))$ $$g(\omega)=\frac{1}{2\pi  i}\int_{\gamma}\frac{zf'(z)}{f(z)-\omega}\, dz$$ Your solution should also explain why this integral is well defined. I will divide my question into two parts: I have a solution for the case that $g(\omega)\neq0$, but there is an argument made in it that I can't totally justify: Consider the function  $$ \frac{zf'(z)}{f(z)-\omega} $$ it have the singular point when  $$ f(z)=\omega $$ since $f$ is $1-1$ and $\omega$ is in the image of $f$, there exist a   unique point $z_{1}$ s.t  $$ f(z_{1})=\omega $$ Since $f'(z)\neq0$ we have it that  $$ h(z):=f(z)-\omega $$ have a zero of order $1$. assume $z_{1}$ maps to $\omega$ $z_{1}f'(z_{1})\neq0$ and $f(z_{1})-\omega=0$, $(f-\omega)'=f'\neq0$   hence  $$ Res\frac{zf'(z)}{f(z)-\omega} $$ at $z=z_{1}$ is  $$ \frac{z_{1}f'(z_{1})}{(f(z)-\omega)'_{z_{1}}}=z_{1}  $$ and by the residue theorem  $$ \frac{1}{2\pi  i}\int_{\gamma}\frac{zf'(z)}{f(z)-\omega}=\frac{1}{2\pi i}2\pi  iz_{1}=z_{1}=g(\omega) $$ The part that I can't justify is why $h$ have a zero of order $1$ ? I think its because $f$ is $1-1$, but I'm not sure how to use it 2) I don't think it holds for when $g(\omega)=0$, since then $$z_{1}f'(z_{1})=0\cdot f'(0)=0$$ and so I can't use the theorem I used. Can someone please help me with this case ? Added later: I am referring to the following theorem, that can be found at page $253$ of the book Complex Variables and Applications by Brown and Churchill: Let two functions $p,q$ be holomorphic at a point $z_{0}$. If   $p(z_{0})\neq0,q(z_{0})=0$ and $q'(z_{0})\neq0$ then   $$Res_{z=z_{0}}\frac{p(z)}{q(z)}=\frac{p(z_{0})}{q'(z_{0})}$$","I have the following exercise: Let $G$ be an open subset of $\mathbb{C}$ and let $f$ be a one to one   function in $H(G)$ such that $f'(z)\neq0$ for all $z\in G$. For each $\omega\in f(G)$ let $g(\omega)$ denote the unique complex   number $z\in G$ for which $f(z)=\omega$. Suppose that the closed disk $\overline{D(z_{o},r)}\subseteq G$ and   that $\gamma:[0,2\pi]\to G$ is the curve given by   $\gamma(t)=z_{0}+re^{it}$. Prove, with the help of the residue theorem, that, for every   $\omega\in f(D(z_{0},r))$ $$g(\omega)=\frac{1}{2\pi  i}\int_{\gamma}\frac{zf'(z)}{f(z)-\omega}\, dz$$ Your solution should also explain why this integral is well defined. I will divide my question into two parts: I have a solution for the case that $g(\omega)\neq0$, but there is an argument made in it that I can't totally justify: Consider the function  $$ \frac{zf'(z)}{f(z)-\omega} $$ it have the singular point when  $$ f(z)=\omega $$ since $f$ is $1-1$ and $\omega$ is in the image of $f$, there exist a   unique point $z_{1}$ s.t  $$ f(z_{1})=\omega $$ Since $f'(z)\neq0$ we have it that  $$ h(z):=f(z)-\omega $$ have a zero of order $1$. assume $z_{1}$ maps to $\omega$ $z_{1}f'(z_{1})\neq0$ and $f(z_{1})-\omega=0$, $(f-\omega)'=f'\neq0$   hence  $$ Res\frac{zf'(z)}{f(z)-\omega} $$ at $z=z_{1}$ is  $$ \frac{z_{1}f'(z_{1})}{(f(z)-\omega)'_{z_{1}}}=z_{1}  $$ and by the residue theorem  $$ \frac{1}{2\pi  i}\int_{\gamma}\frac{zf'(z)}{f(z)-\omega}=\frac{1}{2\pi i}2\pi  iz_{1}=z_{1}=g(\omega) $$ The part that I can't justify is why $h$ have a zero of order $1$ ? I think its because $f$ is $1-1$, but I'm not sure how to use it 2) I don't think it holds for when $g(\omega)=0$, since then $$z_{1}f'(z_{1})=0\cdot f'(0)=0$$ and so I can't use the theorem I used. Can someone please help me with this case ? Added later: I am referring to the following theorem, that can be found at page $253$ of the book Complex Variables and Applications by Brown and Churchill: Let two functions $p,q$ be holomorphic at a point $z_{0}$. If   $p(z_{0})\neq0,q(z_{0})=0$ and $q'(z_{0})\neq0$ then   $$Res_{z=z_{0}}\frac{p(z)}{q(z)}=\frac{p(z_{0})}{q'(z_{0})}$$",,"['complex-analysis', 'residue-calculus']"
11,Integral formula for $\frac{1}{\Gamma(z)}$,Integral formula for,\frac{1}{\Gamma(z)},"Let $c>0$. How to prove that for any complex number $z$, $$\frac{1}{\Gamma(z)}=\frac{1}{2\pi}\int_{-\infty}^\infty (c+it)^{-z}e^{c+it}\,dt?$$ where $\Gamma(z)$ is the Gamma function.","Let $c>0$. How to prove that for any complex number $z$, $$\frac{1}{\Gamma(z)}=\frac{1}{2\pi}\int_{-\infty}^\infty (c+it)^{-z}e^{c+it}\,dt?$$ where $\Gamma(z)$ is the Gamma function.",,"['complex-analysis', 'special-functions', 'gamma-function']"
12,Integrating: $\int_0^\infty \frac{\sin (ax)}{e^x + 1}dx$,Integrating:,\int_0^\infty \frac{\sin (ax)}{e^x + 1}dx,"I am trying to evaluate the following integral using the method of contour which I am not being able to. Can anyone point out what mistake I am making? $$\int_0^\infty \frac{\sin ax}{e^x + 1}dx$$ I am considering the following contour. And function $\displaystyle f(z):= \frac{e^{iaz}}{e^z + 1}$ The pole of order $1$ occours at odd multiple of $i\pi$ . By considering above contour there is no singularity. The integral can be broken down into six parts. $$\int_0^R \frac{e^{iax}}{e^x + 1} dx + i \int_0^{2\pi} \frac{e^{ia(R + iy)}}{e^{R + iy} + 1} dy + \int_{R}^{0}\frac{e^{ia(x+2\pi i)}}{e^{x + 2 \pi i } + 1} dx +  \\ i \int_{2 \pi }^{\pi + \epsilon} \frac{e^{ai( iy)}}{e^{ iy } + 1}dy + \int_\gamma \frac{e^{iaz}}{e^z + 1} dz + i \int_{ \pi -\epsilon}^{0} \frac{e^{ia( iy)}}{e^{ iy } + 1}dy$$ First and third gives $\displaystyle (1 - e^{-2 a\pi})\int_0^R\frac{e^{iax}}{e^x + 1} dx$ . Second goes to $0$ as $R \to \infty$ For fifth integral, $$\int_\gamma \frac{e^{iaz}}{e^z + 1} dz = \int_{-\pi/2}^{\pi/2} \frac{e^{ia\pi + a\epsilon e^{i\theta}}}{e^{i\pi + \epsilon e^{i\theta}+1}}i \epsilon i e^{i\theta }d\theta \to 0 \text{ as } \epsilon \to 0$$ The real part of fourth and sixth integral does not converge. But since my original integral is imaginary, it suffices to take imaginary part. As $\epsilon \to 0$ , I get $$i\int_{2\pi }^0 \Re \left [\frac{e^{-ay}}{e^{iy} + 1} \right] dy = i \int_{2\pi}^0 \frac{e^{-ay}}{2}dy = i \frac{e^{-2\pi a} - 1}{2a}$$ Finally using residue theorem, I am geting which is incorrect. $$(1 - e^{-2 a\pi})\int_0^\infty \Im \left [\frac{e^{iax}}{e^x + 1} \right ] dx +\frac{e^{-2\pi a} - 1}{2a} = 0$$ Can anyone point out my mistake or give worked out solution?? Thanks in advance!! ADDED:: I evaluated fifth integral incorrectly $$\int_\gamma \frac{e^{iaz}}{e^z + 1} dz = \int_{-\pi/2}^{\pi/2} \frac{e^{ia(i\pi + \epsilon e^{i\theta})}}{e^{i\pi + \epsilon e^{i\theta}}+1}i \epsilon  e^{i\theta }d\theta = ie^{-a\pi}\int_{\pi/2}^{-\pi/2}\frac{e^{ia\epsilon e^{i\theta}}}{-e^{\epsilon e^{i\theta}} + 1} \epsilon e^{i\theta}d\theta = i \pi e^{-a\pi}$$ So the total sum should be $$(1 - e^{-2 a\pi})\int_0^\infty \Im \left [\frac{e^{iax}}{e^x + 1} \right ] dx +\frac{e^{-2\pi a} - 1}{2a} +\pi e^{-a\pi}= 0 $$ After slight manipulation we find that $$\int_0^\infty \frac{\sin ax}{e^x + 1}dx = -\frac{\pi}{2\sinh (\pi a)} +\frac{1}{2a}$$","I am trying to evaluate the following integral using the method of contour which I am not being able to. Can anyone point out what mistake I am making? I am considering the following contour. And function The pole of order occours at odd multiple of . By considering above contour there is no singularity. The integral can be broken down into six parts. First and third gives . Second goes to as For fifth integral, The real part of fourth and sixth integral does not converge. But since my original integral is imaginary, it suffices to take imaginary part. As , I get Finally using residue theorem, I am geting which is incorrect. Can anyone point out my mistake or give worked out solution?? Thanks in advance!! ADDED:: I evaluated fifth integral incorrectly So the total sum should be After slight manipulation we find that",\int_0^\infty \frac{\sin ax}{e^x + 1}dx \displaystyle f(z):= \frac{e^{iaz}}{e^z + 1} 1 i\pi \int_0^R \frac{e^{iax}}{e^x + 1} dx + i \int_0^{2\pi} \frac{e^{ia(R + iy)}}{e^{R + iy} + 1} dy + \int_{R}^{0}\frac{e^{ia(x+2\pi i)}}{e^{x + 2 \pi i } + 1} dx +  \\ i \int_{2 \pi }^{\pi + \epsilon} \frac{e^{ai( iy)}}{e^{ iy } + 1}dy + \int_\gamma \frac{e^{iaz}}{e^z + 1} dz + i \int_{ \pi -\epsilon}^{0} \frac{e^{ia( iy)}}{e^{ iy } + 1}dy \displaystyle (1 - e^{-2 a\pi})\int_0^R\frac{e^{iax}}{e^x + 1} dx 0 R \to \infty \int_\gamma \frac{e^{iaz}}{e^z + 1} dz = \int_{-\pi/2}^{\pi/2} \frac{e^{ia\pi + a\epsilon e^{i\theta}}}{e^{i\pi + \epsilon e^{i\theta}+1}}i \epsilon i e^{i\theta }d\theta \to 0 \text{ as } \epsilon \to 0 \epsilon \to 0 i\int_{2\pi }^0 \Re \left [\frac{e^{-ay}}{e^{iy} + 1} \right] dy = i \int_{2\pi}^0 \frac{e^{-ay}}{2}dy = i \frac{e^{-2\pi a} - 1}{2a} (1 - e^{-2 a\pi})\int_0^\infty \Im \left [\frac{e^{iax}}{e^x + 1} \right ] dx +\frac{e^{-2\pi a} - 1}{2a} = 0 \int_\gamma \frac{e^{iaz}}{e^z + 1} dz = \int_{-\pi/2}^{\pi/2} \frac{e^{ia(i\pi + \epsilon e^{i\theta})}}{e^{i\pi + \epsilon e^{i\theta}}+1}i \epsilon  e^{i\theta }d\theta = ie^{-a\pi}\int_{\pi/2}^{-\pi/2}\frac{e^{ia\epsilon e^{i\theta}}}{-e^{\epsilon e^{i\theta}} + 1} \epsilon e^{i\theta}d\theta = i \pi e^{-a\pi} (1 - e^{-2 a\pi})\int_0^\infty \Im \left [\frac{e^{iax}}{e^x + 1} \right ] dx +\frac{e^{-2\pi a} - 1}{2a} +\pi e^{-a\pi}= 0  \int_0^\infty \frac{\sin ax}{e^x + 1}dx = -\frac{\pi}{2\sinh (\pi a)} +\frac{1}{2a},"['complex-analysis', 'contour-integration']"
13,Integrate: $\int_0^\infty \frac{\sin^2(x)}{x^2}dx$ [duplicate],Integrate:  [duplicate],\int_0^\infty \frac{\sin^2(x)}{x^2}dx,"This question already has answers here : Proof of $\int_0^\infty \left(\frac{\sin x}{x}\right)^2 \mathrm dx=\frac{\pi}{2}.$ (15 answers) Closed 6 years ago . I am trying to integrate $\displaystyle \int_0^\infty \frac{\sin^2(x)}{x^2} dx$  by method of contour. I am considering the following contour but I am not being able to. Also I am not sure if it's right approach. $$\int_\Gamma f(z) dz + 2 \int_0^\infty f(z) dz + \int_\gamma f(z)dz = 0$$ The first integral tends to zero as $R \to \infty $, but letting $\epsilon \to 0$, for the last integral I am getting. $$\int_{\pi }^0 \frac{\sin^2({\epsilon e^{i\theta}})}{\epsilon^2 e^{i2\theta }} i \epsilon e^{i\theta}d\theta = 0$$ ADDED :: Taking the above contour, we do not have any pole inside the contour. $$\int_{-\infty}^\infty \frac{1 - e^{i2z}}{2z^2}dz + \int_\Gamma \frac{1 - e^{i2z}}{2z^2} dz + \int_\gamma \frac{1 - e^{i2z}}{2z^2} dz = 0 \hspace{1 cm }(1)$$ $\displaystyle \int_\Gamma \frac{1 - e^{i2z}}{2z^2} dz \to 0$ due to Jordan Lemma. To evaluate $\displaystyle \int_\gamma \frac{1 - e^{i2z}}{2z^2} dz $ let the radius of the small semi circle be $\epsilon \to 0 $. $$\lim_{\epsilon \to 0}\int_\pi^0 \frac{1 - e^{i2\epsilon e^{i\theta}}}{2\epsilon ^2 e^{i2\theta}} i \epsilon e^{i\theta}d\theta =\lim_{\epsilon \to 0} \int_\pi^0 \frac{1 - 1 - 2i\epsilon e^{i\theta} + O(\epsilon^2)}{2\epsilon e^{i\theta}} i  = \lim_{\epsilon \to 0} \int_\pi^0 1+  O(\epsilon) d\theta = -\pi \hspace{1 cm }(2)$$ From $(2)$, $(1)$ reduces to  $$\int_{-\infty}^\infty \frac{1 - e^{i2z}}{2z^2}dz - \pi = 0 \implies \Re \int_{-\infty}^\infty \frac{1 - e^{i2z}}{2z^2}dz = \int_{-\infty}^{\infty}\frac{\sin(x)^2}{x^2}dx = \pi$$ Including singularity at $z = 0$, we will have that small inner circle on lower plane. $$\int_{-\infty}^\infty \frac{1 - e^{i2z}}{2z^2}dz + \int_\Gamma \frac{1 - e^{i2z}}{2z^2} dz + \int_\gamma \frac{1 - e^{i2z}}{2z^2} dz = 2 \pi i \text{Residue}[f(z), z = 0] = 2\pi \hspace{1 cm }(3)$$ As for $\displaystyle \int_\gamma \frac{1 - e^{i2z}}{2z^2} dz = \lim_{\epsilon \to 0}\int_{-\pi}^0 \frac{1 - e^{i2\epsilon e^{i\theta}}}{2\epsilon ^2 e^{i2\theta}} i \epsilon e^{i\theta}d\theta = \pi \hspace{1 cm }(4)$ From $(3)$ and $(4)$ we get the same result.","This question already has answers here : Proof of $\int_0^\infty \left(\frac{\sin x}{x}\right)^2 \mathrm dx=\frac{\pi}{2}.$ (15 answers) Closed 6 years ago . I am trying to integrate $\displaystyle \int_0^\infty \frac{\sin^2(x)}{x^2} dx$  by method of contour. I am considering the following contour but I am not being able to. Also I am not sure if it's right approach. $$\int_\Gamma f(z) dz + 2 \int_0^\infty f(z) dz + \int_\gamma f(z)dz = 0$$ The first integral tends to zero as $R \to \infty $, but letting $\epsilon \to 0$, for the last integral I am getting. $$\int_{\pi }^0 \frac{\sin^2({\epsilon e^{i\theta}})}{\epsilon^2 e^{i2\theta }} i \epsilon e^{i\theta}d\theta = 0$$ ADDED :: Taking the above contour, we do not have any pole inside the contour. $$\int_{-\infty}^\infty \frac{1 - e^{i2z}}{2z^2}dz + \int_\Gamma \frac{1 - e^{i2z}}{2z^2} dz + \int_\gamma \frac{1 - e^{i2z}}{2z^2} dz = 0 \hspace{1 cm }(1)$$ $\displaystyle \int_\Gamma \frac{1 - e^{i2z}}{2z^2} dz \to 0$ due to Jordan Lemma. To evaluate $\displaystyle \int_\gamma \frac{1 - e^{i2z}}{2z^2} dz $ let the radius of the small semi circle be $\epsilon \to 0 $. $$\lim_{\epsilon \to 0}\int_\pi^0 \frac{1 - e^{i2\epsilon e^{i\theta}}}{2\epsilon ^2 e^{i2\theta}} i \epsilon e^{i\theta}d\theta =\lim_{\epsilon \to 0} \int_\pi^0 \frac{1 - 1 - 2i\epsilon e^{i\theta} + O(\epsilon^2)}{2\epsilon e^{i\theta}} i  = \lim_{\epsilon \to 0} \int_\pi^0 1+  O(\epsilon) d\theta = -\pi \hspace{1 cm }(2)$$ From $(2)$, $(1)$ reduces to  $$\int_{-\infty}^\infty \frac{1 - e^{i2z}}{2z^2}dz - \pi = 0 \implies \Re \int_{-\infty}^\infty \frac{1 - e^{i2z}}{2z^2}dz = \int_{-\infty}^{\infty}\frac{\sin(x)^2}{x^2}dx = \pi$$ Including singularity at $z = 0$, we will have that small inner circle on lower plane. $$\int_{-\infty}^\infty \frac{1 - e^{i2z}}{2z^2}dz + \int_\Gamma \frac{1 - e^{i2z}}{2z^2} dz + \int_\gamma \frac{1 - e^{i2z}}{2z^2} dz = 2 \pi i \text{Residue}[f(z), z = 0] = 2\pi \hspace{1 cm }(3)$$ As for $\displaystyle \int_\gamma \frac{1 - e^{i2z}}{2z^2} dz = \lim_{\epsilon \to 0}\int_{-\pi}^0 \frac{1 - e^{i2\epsilon e^{i\theta}}}{2\epsilon ^2 e^{i2\theta}} i \epsilon e^{i\theta}d\theta = \pi \hspace{1 cm }(4)$ From $(3)$ and $(4)$ we get the same result.",,['complex-analysis']
14,Is this a correct way to calculate $\int_{-\infty}^\infty\frac{x\sin(\pi x)}{x^2+2x+5}dx?$,Is this a correct way to calculate,\int_{-\infty}^\infty\frac{x\sin(\pi x)}{x^2+2x+5}dx?,"I have this integral to calculate: $$I=\int_{-\infty}^\infty\frac{x\sin(\pi x)}{x^2+2x+5}dx.$$ I think I have done it, but I would like to make sure my solution is correct. I take the function $$f(z)=\frac{ze^{i\pi z}}{z^2+2z+5}$$ for $z\in\Bbb C.$ Now $$f(z)=\frac{z\cos(\pi z)}{z^2+2z+5}+i\frac{z\sin(\pi z)}{z^2+2z+5}$$ so $$\int_{-\infty}^\infty f(x)dx=\int_{-\infty}^\infty\frac{x\cos(\pi x)}{x^2+2x+5}dx+i\int_{-\infty}^\infty\frac{x\sin(\pi x)}{x^2+2x+5}dx.$$ Therefore, to calculate $I$, I need to calculate the left-hand side and take the imaginary part of it. I consider contours $C_R$ composed of the upper half-circles $H_R$ of radius $R$ and the real interval $I_R=[-R,R]$. $f$ has two simple poles, $-1+2i$ and $-1-2i$, of which only $-1+2i$ lies in the upper half-plane. I have $$\mathrm{res}_{(-1+2i)}f=\frac{(-1+2i)e^{i\pi(-1+2i)}}{2(-1+2i)+2}=-\frac14(2+i)e^{-2\pi}.$$ Therefore, $$\int_{H_R} f(z)dz+\int_{I_R} f(z)dz=\int_{C_R} f(z)dz=2i\pi\cdot(-\frac14)(2-i)e^{-2\pi}=\frac\pi 2(1-2i)e^{-2\pi}.$$ $\int_{H_R} f(z)dz$ tends to zero as $R$ tends to infinity by Jordan's lemma. I have $$\begin{eqnarray}|\int_{H_R}f(z)dz|&\leq&\max_{\theta\in[0,\pi]}|\frac{Re^{i\theta}}{(Re^{i\theta})^2+2Re^{i\theta}+5}|\\&=&\max_{\theta\in[0,\pi]}\frac R{|(Re^{i\theta})^2+2Re^{i\theta}+5|}\\&\leq&\frac R{R^2-2R-5},\end{eqnarray}$$ by this . The last expression tends to zero as $R$ tends to infinity. $\int_{I_R} f(z)dz$ tends to $\int_{-\infty}^\infty f(x)dx$ as $R$ tends to infinity. Therefore, $$\int_{-\infty}^\infty f(z)dz=\frac\pi 2(1-2i)e^{-2\pi}=\frac\pi 2e^{-2\pi}-i\pi e^{-2\pi},$$ whence $$I=-\pi e^{-2\pi}.$$","I have this integral to calculate: $$I=\int_{-\infty}^\infty\frac{x\sin(\pi x)}{x^2+2x+5}dx.$$ I think I have done it, but I would like to make sure my solution is correct. I take the function $$f(z)=\frac{ze^{i\pi z}}{z^2+2z+5}$$ for $z\in\Bbb C.$ Now $$f(z)=\frac{z\cos(\pi z)}{z^2+2z+5}+i\frac{z\sin(\pi z)}{z^2+2z+5}$$ so $$\int_{-\infty}^\infty f(x)dx=\int_{-\infty}^\infty\frac{x\cos(\pi x)}{x^2+2x+5}dx+i\int_{-\infty}^\infty\frac{x\sin(\pi x)}{x^2+2x+5}dx.$$ Therefore, to calculate $I$, I need to calculate the left-hand side and take the imaginary part of it. I consider contours $C_R$ composed of the upper half-circles $H_R$ of radius $R$ and the real interval $I_R=[-R,R]$. $f$ has two simple poles, $-1+2i$ and $-1-2i$, of which only $-1+2i$ lies in the upper half-plane. I have $$\mathrm{res}_{(-1+2i)}f=\frac{(-1+2i)e^{i\pi(-1+2i)}}{2(-1+2i)+2}=-\frac14(2+i)e^{-2\pi}.$$ Therefore, $$\int_{H_R} f(z)dz+\int_{I_R} f(z)dz=\int_{C_R} f(z)dz=2i\pi\cdot(-\frac14)(2-i)e^{-2\pi}=\frac\pi 2(1-2i)e^{-2\pi}.$$ $\int_{H_R} f(z)dz$ tends to zero as $R$ tends to infinity by Jordan's lemma. I have $$\begin{eqnarray}|\int_{H_R}f(z)dz|&\leq&\max_{\theta\in[0,\pi]}|\frac{Re^{i\theta}}{(Re^{i\theta})^2+2Re^{i\theta}+5}|\\&=&\max_{\theta\in[0,\pi]}\frac R{|(Re^{i\theta})^2+2Re^{i\theta}+5|}\\&\leq&\frac R{R^2-2R-5},\end{eqnarray}$$ by this . The last expression tends to zero as $R$ tends to infinity. $\int_{I_R} f(z)dz$ tends to $\int_{-\infty}^\infty f(x)dx$ as $R$ tends to infinity. Therefore, $$\int_{-\infty}^\infty f(z)dz=\frac\pi 2(1-2i)e^{-2\pi}=\frac\pi 2e^{-2\pi}-i\pi e^{-2\pi},$$ whence $$I=-\pi e^{-2\pi}.$$",,"['complex-analysis', 'improper-integrals', 'contour-integration']"
15,Finding a conformal map of lunar domain to upper half disk,Finding a conformal map of lunar domain to upper half disk,,"Does there exist a conformal map from the region $\Omega = \{z :|z|<1\} \cap \{z: |z- \frac{1+i}{\sqrt2}|<1\}$ onto the region $\{z: |z|<1,  \operatorname{Im}z>0\}$? I think I need  to find  at least three intersection point of the two circles and mapped them  to real axis using the formula of fractional linear transformation. I even have difficulty finding the intersection points. I would really appreciate if someone do this rigorously. This is not a homework problem. This is from the collection of previous qual exams.","Does there exist a conformal map from the region $\Omega = \{z :|z|<1\} \cap \{z: |z- \frac{1+i}{\sqrt2}|<1\}$ onto the region $\{z: |z|<1,  \operatorname{Im}z>0\}$? I think I need  to find  at least three intersection point of the two circles and mapped them  to real axis using the formula of fractional linear transformation. I even have difficulty finding the intersection points. I would really appreciate if someone do this rigorously. This is not a homework problem. This is from the collection of previous qual exams.",,['complex-analysis']
16,Fractional calculus in complex analysis,Fractional calculus in complex analysis,,"According to Fractional calculus , we know that $$(J^\alpha f) ( x ) = { 1 \over \Gamma ( \alpha ) } \int_0^x (x-t)^{\alpha-1} f(t) \; dt$$ It's in real analysis, but what about in complex analysis? As we know, if $\alpha$ is not a integer, then $(x-t)^{\alpha-1}$ may returns more than one values. So my question is can we find a method to let fractional calculus working on complex field?","According to Fractional calculus , we know that $$(J^\alpha f) ( x ) = { 1 \over \Gamma ( \alpha ) } \int_0^x (x-t)^{\alpha-1} f(t) \; dt$$ It's in real analysis, but what about in complex analysis? As we know, if $\alpha$ is not a integer, then $(x-t)^{\alpha-1}$ may returns more than one values. So my question is can we find a method to let fractional calculus working on complex field?",,"['complex-analysis', 'fractional-calculus']"
17,Trouble with a problem involving Rouché's Theorem,Trouble with a problem involving Rouché's Theorem,,"The problem is from Marden, the first section: The polynomial $g(z) = z^n + b_1 z^{n-1} + ... + b_n$ has at least $m+1$ zeros in an arbitrary neighborhood of a point $z = c$ if $|g^{(k)}(c)| \leq \epsilon$ for $k = 0,1,...,m$ and for $\epsilon$ sufficiently small and positive. There is a hint provided: use Rouché's Theorem. I can prove the result in the special case of $c = 0$, because then I can bound each of the relevant $b_j$ by $\epsilon$. Unfortunately I don't see a way to extend this to the general case. I would appreciate some help on working toward a solution. I've been stumped since lunch on this one.","The problem is from Marden, the first section: The polynomial $g(z) = z^n + b_1 z^{n-1} + ... + b_n$ has at least $m+1$ zeros in an arbitrary neighborhood of a point $z = c$ if $|g^{(k)}(c)| \leq \epsilon$ for $k = 0,1,...,m$ and for $\epsilon$ sufficiently small and positive. There is a hint provided: use Rouché's Theorem. I can prove the result in the special case of $c = 0$, because then I can bound each of the relevant $b_j$ by $\epsilon$. Unfortunately I don't see a way to extend this to the general case. I would appreciate some help on working toward a solution. I've been stumped since lunch on this one.",,"['complex-analysis', 'polynomials', 'roots']"
18,Zero set of holomorphic function locally isomorphic to zero set of finitely many polynomial?,Zero set of holomorphic function locally isomorphic to zero set of finitely many polynomial?,,"Let $f\colon \Omega \to \mathbb{C}$ be a holomorphic function on an open subset $\Omega$ of $\mathbb{C}^n$ . Denote by $Z(f)$ its zero set. It is clear that there exists $f$ such that $Z(f)$ is not the zero set of finitely many polynomials. My question is: Does the above remain true if one allows to locally change the embedding of $Z(f)$ by a biholomorphic map. More precisely, does there exist an $f$ such that there is a point $p\in Z(f)$ with no open neighbourhood $U\subseteq \Omega$ that admits a biholomorphic map $\phi\colon U \to V$ such that $Z(f\circ \phi^{-1})=Z(P_1,...,P_k)$ for some polynomials $P_i$ on $V$ . It is clear that if $Z(f)$ is a complex submanifold, then for every point such a $\phi$ always exists. So, the zero set needs to be singular and $n>1$ . Essentially, my question is: Is every analytic hypersurface $X\subseteq \mathbb{\Omega}$ locally equivalent to an algebraic variety (up to biholomorphic changes of the embedding). If not are there explicit examples? What happens in the case of $Z(f_1,...,f_l)$ for multiple analytic functions.","Let be a holomorphic function on an open subset of . Denote by its zero set. It is clear that there exists such that is not the zero set of finitely many polynomials. My question is: Does the above remain true if one allows to locally change the embedding of by a biholomorphic map. More precisely, does there exist an such that there is a point with no open neighbourhood that admits a biholomorphic map such that for some polynomials on . It is clear that if is a complex submanifold, then for every point such a always exists. So, the zero set needs to be singular and . Essentially, my question is: Is every analytic hypersurface locally equivalent to an algebraic variety (up to biholomorphic changes of the embedding). If not are there explicit examples? What happens in the case of for multiple analytic functions.","f\colon \Omega \to \mathbb{C} \Omega \mathbb{C}^n Z(f) f Z(f) Z(f) f p\in Z(f) U\subseteq \Omega \phi\colon U \to V Z(f\circ \phi^{-1})=Z(P_1,...,P_k) P_i V Z(f) \phi n>1 X\subseteq \mathbb{\Omega} Z(f_1,...,f_l)","['complex-analysis', 'algebraic-geometry', 'complex-geometry']"
19,Asymptotic behavior of a Fourier/Laplace transform,Asymptotic behavior of a Fourier/Laplace transform,,"I see many results concerning the asymptotics of Fourier transforms. These link in particular the regularity/continuation properties of the function to the polynomial/exponential decay of its Fourier transform. However, these results often hold only in the real variable. I am interested in the Fourier transform ""along the imaginary axis"" instead. Let us be more precise. I am interested by the digamma function $\psi = \frac{\Gamma'}{\Gamma}$ , and in the function $$h(\nu) = \exp\left(-\alpha \psi \left( \frac14 \pm \frac{i\nu}{2} \right)\right),$$ where $\alpha$ is a fixed parameter, say $\alpha > 1$ . I am interested in the asymptotic behavior of the Fourier transform of $h$ at $+\infty$ . More precisely, $$\widehat{h}(x) = \int_{\mathbb{R}} h(\nu) e^{ix\nu} d\nu.$$ How to get asymptoptics when $x \to +\infty$ in this situation? I have no feeling about what determines it: size? variations? only asymptotics of $h$ ? I had many trials, not convincing. Typically, just changing variables, I can get an expression of the shape $$e^{-\frac{x}{2}} \int_{i\mathbb{R}} e^{-\alpha \psi(u)} e^{2xu} du$$ which looks more like a Laplace (?) transform than a Fourier transform. I was motivated by the fact that I am expecting for other reasons an exponential decay as above, so that I am hoping for a polynomial behavior in $x$ for the remaining integral. However, is the growth/decay estimate of this last integral easier to understand than the original one? So my question could be synthzised into Do we have $\int_{i\mathbb{R}} e^{-\alpha \psi(u)} e^{xu} du \ll x^A$ for a certain $A$ ?","I see many results concerning the asymptotics of Fourier transforms. These link in particular the regularity/continuation properties of the function to the polynomial/exponential decay of its Fourier transform. However, these results often hold only in the real variable. I am interested in the Fourier transform ""along the imaginary axis"" instead. Let us be more precise. I am interested by the digamma function , and in the function where is a fixed parameter, say . I am interested in the asymptotic behavior of the Fourier transform of at . More precisely, How to get asymptoptics when in this situation? I have no feeling about what determines it: size? variations? only asymptotics of ? I had many trials, not convincing. Typically, just changing variables, I can get an expression of the shape which looks more like a Laplace (?) transform than a Fourier transform. I was motivated by the fact that I am expecting for other reasons an exponential decay as above, so that I am hoping for a polynomial behavior in for the remaining integral. However, is the growth/decay estimate of this last integral easier to understand than the original one? So my question could be synthzised into Do we have for a certain ?","\psi = \frac{\Gamma'}{\Gamma} h(\nu) = \exp\left(-\alpha \psi \left( \frac14 \pm \frac{i\nu}{2} \right)\right), \alpha \alpha > 1 h +\infty \widehat{h}(x) = \int_{\mathbb{R}} h(\nu) e^{ix\nu} d\nu. x \to +\infty h e^{-\frac{x}{2}} \int_{i\mathbb{R}} e^{-\alpha \psi(u)} e^{2xu} du x \int_{i\mathbb{R}} e^{-\alpha \psi(u)} e^{xu} du \ll x^A A","['complex-analysis', 'definite-integrals', 'laplace-transform', 'fourier-transform', 'gamma-function']"
20,Which mathematical subjects simplify another mathematical subject by removing exceptions?,Which mathematical subjects simplify another mathematical subject by removing exceptions?,,"I have often heard it said that complex analysis is in some ways simpler than real analysis (because every differentiable function can be differentiated as many times as we want, and always has a power series expansion). Similarly, many theorems in projective geometry are simpler than their equivalents in euclidean geometry because one doesn't have to deal with the exceptional case of non-intersecting lines. Are there any other well-known pairs of mathematical topics that bear a similar relationship, where theorems are greatly simplified by the removal of an exceptional case?","I have often heard it said that complex analysis is in some ways simpler than real analysis (because every differentiable function can be differentiated as many times as we want, and always has a power series expansion). Similarly, many theorems in projective geometry are simpler than their equivalents in euclidean geometry because one doesn't have to deal with the exceptional case of non-intersecting lines. Are there any other well-known pairs of mathematical topics that bear a similar relationship, where theorems are greatly simplified by the removal of an exceptional case?",,"['complex-analysis', 'projective-geometry']"
21,How do the roots behave asymoptotically?,How do the roots behave asymoptotically?,,"Let $g, h \in \mathbb C[x]$ and $$ f(x, a) = (x-x_0)^m g(x) + h(x) (a-a_0),$$ where $m \ge 2$ , $a \in \mathbb R$ and $a_0$ is a fixed real number. Suppose $g(x_0) \neq 0$ and $h(x_0) \neq 0$ . By this setup, we should be able to have $n$ continuous functions $\alpha_1, \dots, \alpha_n: \mathbb R \to \mathbb C$ such that for each $t \in \mathbb R$ , $\alpha_1(t), \dots, \alpha_n(t)$ constituents the zeros of $f(x, t)$ . If $a \to a_0$ , then we should have $m$ functions converges to $x_0$ . I am wondering how these functions behave. More specifically, it seems to me: we can set $$ (x-x_0)^m g(x) + h(x)(a-a_0) = 0.$$ As $a \to a_0$ , $g(x) \to g(x_0)$ and $h(x) \to h(x_0)$ . If I am allowed to hand wave a little bit, then in a neighborhood of $a_0$ $$ \alpha_j(a) \approx x_0 + \left( \frac{-h(x_0)}{g(x_0)} (a-a_0) \right)^{1/m} \omega_j^m, \text{ for } j=1, \dots, m,$$ where we assume $\alpha_1, \dots, \alpha_m$ are functions converging to $x_0$ and $\omega_j^m$ are solutions to $x^m =1 $ . Is there a way to a rigorous statement on the asymptotic behavior of $\alpha_j$ 's?","Let and where , and is a fixed real number. Suppose and . By this setup, we should be able to have continuous functions such that for each , constituents the zeros of . If , then we should have functions converges to . I am wondering how these functions behave. More specifically, it seems to me: we can set As , and . If I am allowed to hand wave a little bit, then in a neighborhood of where we assume are functions converging to and are solutions to . Is there a way to a rigorous statement on the asymptotic behavior of 's?","g, h \in \mathbb C[x]  f(x, a) = (x-x_0)^m g(x) + h(x) (a-a_0), m \ge 2 a \in \mathbb R a_0 g(x_0) \neq 0 h(x_0) \neq 0 n \alpha_1, \dots, \alpha_n: \mathbb R \to \mathbb C t \in \mathbb R \alpha_1(t), \dots, \alpha_n(t) f(x, t) a \to a_0 m x_0  (x-x_0)^m g(x) + h(x)(a-a_0) = 0. a \to a_0 g(x) \to g(x_0) h(x) \to h(x_0) a_0  \alpha_j(a) \approx x_0 + \left( \frac{-h(x_0)}{g(x_0)} (a-a_0) \right)^{1/m} \omega_j^m, \text{ for } j=1, \dots, m, \alpha_1, \dots, \alpha_m x_0 \omega_j^m x^m =1  \alpha_j","['complex-analysis', 'polynomials', 'roots']"
22,Positivity of Currents,Positivity of Currents,,"I already asked about this a couple of weeks ago but had introduced some rather annoying notation. I decided to reformulate the question in a more compact format. (edit: old post taken down as it is basically a duplicate now) Suppose $\psi$ is the complex differential $(1,1)$ -form $$\psi = i \sum_{j,k=1}^n h_{j,k} ~dz_j \wedge d\bar{z}_k$$ and that the matrix $H$ with entries $h_{j,k}$ is hermitian (i.e. $\psi$ is a real form). In a lecture of mine, it was given as an exercise that $\psi$ is positive (i.e. $\psi(v,Jv) > 0$ for all $v \ne 0$ , where $J$ is the canonical almost complex structure) if and only if $H$ is positive-definite. This differential form induces a current by integration, $$T_{\psi} ~\colon ~ \Omega^{n-1,n-1}_c(\mathbb{C^n}) \rightarrow \mathbb{C}, ~ \phi \mapsto \int_{\mathbb{C^n}} \psi \wedge \phi.$$ In Harris and Griffiths' textbook ""Principles of Algebraic Geometry"" (on page 386 with $p=1$ ), a real $(1,1)$ -current is defined to be positive if for every $(n-1,0)$ -form $\eta$ we have that $T(\eta \wedge \bar{\eta})$ is a non-negative real number. Take such a test form $$\eta = \sum_{j=1}^n \phi_j ~dz_J,$$ where $dz_J$ denotes $dz_1 \wedge \dots \wedge \hat{dz_j} \wedge \dots \wedge dz_n$ . Then we have $$\eta \wedge \bar{\eta} = \sum_{j,k} \phi_j \overline{\phi_k} ~dz_J \wedge d\bar{z}_K$$ and \begin{align*} T_{\psi}(\eta \wedge \bar{\eta}) &= i \sum_{j,k} \int h_{j,k} \phi_j \overline{\phi_k} ~dz_j \wedge d\bar{z}_k \wedge dz_J \wedge d\bar{z}_K \\ &= i \sum_{j,k} \int h_{j,k} \phi_j \overline{\phi_k} ~\sigma(j,k) ~dz_1 \wedge d\bar{z}_1 \wedge \dots \wedge dz_n \wedge d\bar{z}_n, \end{align*} where $\sigma(j,k)$ denotes the sign coming from $$dz_j \wedge d\bar{z}_k \wedge dz_J \wedge d\bar{z}_K = \sigma(j,k) ~dz_1 \wedge d\bar{z_1} \wedge \dots \wedge dz_n \wedge d\bar{z}_n.$$ Thus, the current $T_{\psi}$ is positive not if $H$ is positive definite but if the matrix with entries $\sigma(j,k) h_{j,k}$ is positive definite. Is it true that positivity of currents and positivity of differential forms do not give rise to the same notion? Can this be fixed?","I already asked about this a couple of weeks ago but had introduced some rather annoying notation. I decided to reformulate the question in a more compact format. (edit: old post taken down as it is basically a duplicate now) Suppose is the complex differential -form and that the matrix with entries is hermitian (i.e. is a real form). In a lecture of mine, it was given as an exercise that is positive (i.e. for all , where is the canonical almost complex structure) if and only if is positive-definite. This differential form induces a current by integration, In Harris and Griffiths' textbook ""Principles of Algebraic Geometry"" (on page 386 with ), a real -current is defined to be positive if for every -form we have that is a non-negative real number. Take such a test form where denotes . Then we have and where denotes the sign coming from Thus, the current is positive not if is positive definite but if the matrix with entries is positive definite. Is it true that positivity of currents and positivity of differential forms do not give rise to the same notion? Can this be fixed?","\psi (1,1) \psi = i \sum_{j,k=1}^n h_{j,k} ~dz_j \wedge d\bar{z}_k H h_{j,k} \psi \psi \psi(v,Jv) > 0 v \ne 0 J H T_{\psi} ~\colon ~ \Omega^{n-1,n-1}_c(\mathbb{C^n}) \rightarrow \mathbb{C}, ~ \phi \mapsto \int_{\mathbb{C^n}} \psi \wedge \phi. p=1 (1,1) (n-1,0) \eta T(\eta \wedge \bar{\eta}) \eta = \sum_{j=1}^n \phi_j ~dz_J, dz_J dz_1 \wedge \dots \wedge \hat{dz_j} \wedge \dots \wedge dz_n \eta \wedge \bar{\eta} = \sum_{j,k} \phi_j \overline{\phi_k} ~dz_J \wedge d\bar{z}_K \begin{align*}
T_{\psi}(\eta \wedge \bar{\eta}) &= i \sum_{j,k} \int h_{j,k} \phi_j \overline{\phi_k} ~dz_j \wedge d\bar{z}_k \wedge dz_J \wedge d\bar{z}_K \\
&= i \sum_{j,k} \int h_{j,k} \phi_j \overline{\phi_k} ~\sigma(j,k) ~dz_1 \wedge d\bar{z}_1 \wedge \dots \wedge dz_n \wedge d\bar{z}_n,
\end{align*} \sigma(j,k) dz_j \wedge d\bar{z}_k \wedge dz_J \wedge d\bar{z}_K = \sigma(j,k) ~dz_1 \wedge d\bar{z_1} \wedge \dots \wedge dz_n \wedge d\bar{z}_n. T_{\psi} H \sigma(j,k) h_{j,k}","['complex-analysis', 'algebraic-geometry', 'differential-topology', 'complex-geometry']"
23,"Evaluating $\oint_{|z|=2} \frac{\log{(z-\alpha)}}{z}-\frac{\log z}z \, \mathrm dz$",Evaluating,"\oint_{|z|=2} \frac{\log{(z-\alpha)}}{z}-\frac{\log z}z \, \mathrm dz","Let $\alpha \in (-1,0)$ and define $$f(z)= \frac{\log{(z-\alpha)}}{z}-\frac{\log z}z$$ where the logarithms take their principal values, i.e. the arguments of $z$ and $z-\alpha$ are between $-\pi$ and $\pi$. Evaluate $$\oint_{|z|=2}f(z) \, \mathrm dz$$ I get $0$ but I am not sure if I have calculated the Laurent series correctly. I said  $$f(z) = \frac {1}{z}\log\left(1-\frac {\alpha} z\right)=-\frac{\alpha}{z^2} - \frac{\alpha^2}{z^3} + \cdots$$ which would imply the integral is $0$. Laurent series is valid as $f$ is analytic on an annulus $1 \le |z| \le 3$ taking the branch cut from $\alpha$ to $0$, and the series is convergent as $|\alpha/z| < 1$. I am just a bit concerned about the use of the identity $\log z - \log \omega = \log(z/\omega)$ as this is only true modulo $2 \pi i$, but I am pretty sure (from a rough sketch) that there is no added constant there. Other solutions would also be appreciated.","Let $\alpha \in (-1,0)$ and define $$f(z)= \frac{\log{(z-\alpha)}}{z}-\frac{\log z}z$$ where the logarithms take their principal values, i.e. the arguments of $z$ and $z-\alpha$ are between $-\pi$ and $\pi$. Evaluate $$\oint_{|z|=2}f(z) \, \mathrm dz$$ I get $0$ but I am not sure if I have calculated the Laurent series correctly. I said  $$f(z) = \frac {1}{z}\log\left(1-\frac {\alpha} z\right)=-\frac{\alpha}{z^2} - \frac{\alpha^2}{z^3} + \cdots$$ which would imply the integral is $0$. Laurent series is valid as $f$ is analytic on an annulus $1 \le |z| \le 3$ taking the branch cut from $\alpha$ to $0$, and the series is convergent as $|\alpha/z| < 1$. I am just a bit concerned about the use of the identity $\log z - \log \omega = \log(z/\omega)$ as this is only true modulo $2 \pi i$, but I am pretty sure (from a rough sketch) that there is no added constant there. Other solutions would also be appreciated.",,"['complex-analysis', 'definite-integrals', 'contour-integration', 'residue-calculus', 'laurent-series']"
24,"For complex numbers $a,b,c$, explain why $a^{b\cdot c}=(a^b)^c$ is not necessarily true.","For complex numbers , explain why  is not necessarily true.","a,b,c a^{b\cdot c}=(a^b)^c","For complex numbers $a,b,c$, explain why $a^{b\cdot c}=(a^b)^c$ is not   necessarily true. I know that complex powers are really sets of complex numbers.  But coming from real analysis the above seems confusing.  Can anyone give a simple explanation of what is going on.","For complex numbers $a,b,c$, explain why $a^{b\cdot c}=(a^b)^c$ is not   necessarily true. I know that complex powers are really sets of complex numbers.  But coming from real analysis the above seems confusing.  Can anyone give a simple explanation of what is going on.",,['complex-analysis']
25,Zeros of $f(z) = z^5+3z^4+9z^3+10$ in the unit disk,Zeros of  in the unit disk,f(z) = z^5+3z^4+9z^3+10,"Show that $f(z) = z^5+3z^4+9z^3+10$ has $2$ zeros in the unit disk I'm  trying to use Rouche's theorem. So I tried to find a function $g$ that has 2 zeros in the unit disk and: $$|f(z)- g(z)| < |f(z)|+|g(z)| \quad \forall z \in \mathbb{D}  \quad \text{(1)}$$ However, I couldn't find  such function. I tried $g(z) = 3z^4+9z^3+10$. This function has $2$ zeros  in the unit disk according to Wolfram Alpha . I wasn't able to prove $(1)$ and that $g$ has  $2$ zeros  in the unit disk  with an analytical method. I did the same for the function $g(z) = z^5+9z^3+10$ that has two zeros in unit disk by Wolfram Alpha . It didn't work either. Could somebody help out to prove that $f$ has $2$ zeros in the unit disk?","Show that $f(z) = z^5+3z^4+9z^3+10$ has $2$ zeros in the unit disk I'm  trying to use Rouche's theorem. So I tried to find a function $g$ that has 2 zeros in the unit disk and: $$|f(z)- g(z)| < |f(z)|+|g(z)| \quad \forall z \in \mathbb{D}  \quad \text{(1)}$$ However, I couldn't find  such function. I tried $g(z) = 3z^4+9z^3+10$. This function has $2$ zeros  in the unit disk according to Wolfram Alpha . I wasn't able to prove $(1)$ and that $g$ has  $2$ zeros  in the unit disk  with an analytical method. I did the same for the function $g(z) = z^5+9z^3+10$ that has two zeros in unit disk by Wolfram Alpha . It didn't work either. Could somebody help out to prove that $f$ has $2$ zeros in the unit disk?",,"['complex-analysis', 'polynomials', 'complex-numbers', 'rouches-theorem']"
26,For which polynomials $p\in\mathbb{C}[w]$ are the branches of the inverse $p^{-1}$ expressible using algebraic operations?,For which polynomials  are the branches of the inverse  expressible using algebraic operations?,p\in\mathbb{C}[w] p^{-1},"The collection of all degree-$n$ polynomials in the variable $w$ (call this set $\mathbb{C}[w]_n$) can be identifies with $\mathbb{C}^{n+1}$ by the bijection $F:\mathbb{C}^{n+1}\to\mathbb{C}[w]_n$ defined by $$F:(a_0,a_1,\ldots,a_n)\mapsto w=p(z)=a_0+a_1z+\cdots+a_nz^n.$$  Let $\mathcal{A}_n\subset\mathbb{C}^{n+1}$ denote the set of polynomials (using the above identification) defined by saying that $p(z)\in\mathcal{A}_n$ if and only if each branch of the inverse $z=p^{-1}(w)$ is expressible as an explicit formula using finitely many algebraic operations (ie addition/subtraction, multiplication/division, and roots).  That is, something like $$z=p^{-1}(w)=\sqrt{w+\sqrt{2/w}}.$$  Note that for any polynomial $p(z)\in\mathbb{C}^{n+1}$, either each branch of $p^{-1}$ is so expressible, or none is (since every branch can be reached as an analytic continuation of any other). My Question: What is the structure of $\mathcal{A}_n$ in $\mathbb{C}^{n+1}$?  Is it an algebraic variety?  What is its dimension?  What can we say about its topology?","The collection of all degree-$n$ polynomials in the variable $w$ (call this set $\mathbb{C}[w]_n$) can be identifies with $\mathbb{C}^{n+1}$ by the bijection $F:\mathbb{C}^{n+1}\to\mathbb{C}[w]_n$ defined by $$F:(a_0,a_1,\ldots,a_n)\mapsto w=p(z)=a_0+a_1z+\cdots+a_nz^n.$$  Let $\mathcal{A}_n\subset\mathbb{C}^{n+1}$ denote the set of polynomials (using the above identification) defined by saying that $p(z)\in\mathcal{A}_n$ if and only if each branch of the inverse $z=p^{-1}(w)$ is expressible as an explicit formula using finitely many algebraic operations (ie addition/subtraction, multiplication/division, and roots).  That is, something like $$z=p^{-1}(w)=\sqrt{w+\sqrt{2/w}}.$$  Note that for any polynomial $p(z)\in\mathbb{C}^{n+1}$, either each branch of $p^{-1}$ is so expressible, or none is (since every branch can be reached as an analytic continuation of any other). My Question: What is the structure of $\mathcal{A}_n$ in $\mathbb{C}^{n+1}$?  Is it an algebraic variety?  What is its dimension?  What can we say about its topology?",,"['complex-analysis', 'algebraic-geometry', 'polynomials', 'galois-theory']"
27,Evaluate the improper integral with residues.,Evaluate the improper integral with residues.,,"$$\int_0^{\infty} \frac{x^2+1}{x^4+1}dx$$ What i've found are the singularities at: $e^{\pi/4+\pi/2n}$ for $n=0,1,2,3$. But i'm unsure how to calculate the integral since I don't want to include the singularity at $x_2=\frac{-1+i}{\sqrt{2}}$ since then I would be calculating the integral from negative to positive infinity. My idea was to construct a contour $\gamma : x=ti$ where $R<t\leq0$ and $\lim_{R\rightarrow \infty}$. My reckoning was that since: $$\int_{\gamma}\frac{x^2+1}{x^4+1}dx=i\int_R^0\frac{1-t^2}{t^4+1}dt$$ doesn't have any singularities along the positive real numberline, it is therefore bounded and thus: $$i\int_R^0\frac{1-t^2}{t^4+1}dt\leq \Big| i\int_R^0\frac{1-t^2}{t^4+1}dt\Big|\leq\int_R^0\frac{|1-t^2|}{|t^4+1|}dt\leq\frac{|R^2|+1}{|R^4|-1}\rightarrow0 \text{ when } R\rightarrow \infty.$$ The answer would then be:  $$\lim_{R\rightarrow \infty}\int_0^{R}\frac{x^2+1}{x^4+1}dx=2\pi iRes(f;e^{\pi/4})-\int_0^{\pi/2}f(x)dx-i\int_R^0f(x)dx=\frac{\pi}{2\sqrt{2}}.$$ But sadly I am mistaken, what is wrong?","$$\int_0^{\infty} \frac{x^2+1}{x^4+1}dx$$ What i've found are the singularities at: $e^{\pi/4+\pi/2n}$ for $n=0,1,2,3$. But i'm unsure how to calculate the integral since I don't want to include the singularity at $x_2=\frac{-1+i}{\sqrt{2}}$ since then I would be calculating the integral from negative to positive infinity. My idea was to construct a contour $\gamma : x=ti$ where $R<t\leq0$ and $\lim_{R\rightarrow \infty}$. My reckoning was that since: $$\int_{\gamma}\frac{x^2+1}{x^4+1}dx=i\int_R^0\frac{1-t^2}{t^4+1}dt$$ doesn't have any singularities along the positive real numberline, it is therefore bounded and thus: $$i\int_R^0\frac{1-t^2}{t^4+1}dt\leq \Big| i\int_R^0\frac{1-t^2}{t^4+1}dt\Big|\leq\int_R^0\frac{|1-t^2|}{|t^4+1|}dt\leq\frac{|R^2|+1}{|R^4|-1}\rightarrow0 \text{ when } R\rightarrow \infty.$$ The answer would then be:  $$\lim_{R\rightarrow \infty}\int_0^{R}\frac{x^2+1}{x^4+1}dx=2\pi iRes(f;e^{\pi/4})-\int_0^{\pi/2}f(x)dx-i\int_R^0f(x)dx=\frac{\pi}{2\sqrt{2}}.$$ But sadly I am mistaken, what is wrong?",,"['complex-analysis', 'complex-numbers', 'improper-integrals', 'residue-calculus']"
28,Show the Cauchy-Riemann equations hold but f is not differentiable,Show the Cauchy-Riemann equations hold but f is not differentiable,,"Let $$f(z)={x^{4/3} y^{5/3}+i\,x^{5/3}y^{4/3}\over x^2+y^2}\text{ if }z\neq0 \text{, and }f(0)=0$$    Show that the Cauchy-Riemann equations hold at $z=0$ but $f$ is not differentiable at $z=0$ Here's what I've done so far: $\quad$As noted above, there are two cases: $z=0$ and $z\neq0$. The Cauchy-Riemann equations hold at $\quad z\neq0$ because $f(x)$ is analytic everywhere except at the origin. $\quad$Now we consider $z=0$. In this case,  $$f_x(0,0) = \lim_{x\to 0} \frac{0 + 0}{x^2+0}=0$$  $\quad$and $$f_y(0,0) = \lim_{y\to 0} \frac{0 + 0}{0+y^2}=0$$ $\quad$So, we see that $\frac{\delta u}{\delta x}=0=\frac{\delta v}{\delta y}$ and $\frac{\delta u}{\delta y}=0= -\frac{\delta v}{\delta x}$. Therefore, the Cauchy-Riemann equations $\quad$hold at $z=0$. From here, I'm a little confused about how to show that $f$ is not differentiable at $z=0$. I instinctively believe that $f$ is not continuous at $z=0$, which would imply that $f$ is not differentiable at $z=0$. However, I'm not sure how I can prove this. Any help would be greatly appreciated. Thank you!! EDIT: I now see that $f$ is continuous at $z=0$, but I'm not sure how to prove that it is not differentiable.  I know I should use $\lim_{z\to 0} \frac{f(z) - f(0)}{z-0}$ to determine differentiability, and that I should get two different answers when I approach the limit from two different paths (for example: $x=0$, $y=0$, or $x=y$), but I'm not sure how to evaluate $\lim_{z\to 0} \frac{f(z) - f(0)}{z-0}$ for $x=0$, $y=0$ or $x=y$. As before, any help would be much appreciated. Thanks!","Let $$f(z)={x^{4/3} y^{5/3}+i\,x^{5/3}y^{4/3}\over x^2+y^2}\text{ if }z\neq0 \text{, and }f(0)=0$$    Show that the Cauchy-Riemann equations hold at $z=0$ but $f$ is not differentiable at $z=0$ Here's what I've done so far: $\quad$As noted above, there are two cases: $z=0$ and $z\neq0$. The Cauchy-Riemann equations hold at $\quad z\neq0$ because $f(x)$ is analytic everywhere except at the origin. $\quad$Now we consider $z=0$. In this case,  $$f_x(0,0) = \lim_{x\to 0} \frac{0 + 0}{x^2+0}=0$$  $\quad$and $$f_y(0,0) = \lim_{y\to 0} \frac{0 + 0}{0+y^2}=0$$ $\quad$So, we see that $\frac{\delta u}{\delta x}=0=\frac{\delta v}{\delta y}$ and $\frac{\delta u}{\delta y}=0= -\frac{\delta v}{\delta x}$. Therefore, the Cauchy-Riemann equations $\quad$hold at $z=0$. From here, I'm a little confused about how to show that $f$ is not differentiable at $z=0$. I instinctively believe that $f$ is not continuous at $z=0$, which would imply that $f$ is not differentiable at $z=0$. However, I'm not sure how I can prove this. Any help would be greatly appreciated. Thank you!! EDIT: I now see that $f$ is continuous at $z=0$, but I'm not sure how to prove that it is not differentiable.  I know I should use $\lim_{z\to 0} \frac{f(z) - f(0)}{z-0}$ to determine differentiability, and that I should get two different answers when I approach the limit from two different paths (for example: $x=0$, $y=0$, or $x=y$), but I'm not sure how to evaluate $\lim_{z\to 0} \frac{f(z) - f(0)}{z-0}$ for $x=0$, $y=0$ or $x=y$. As before, any help would be much appreciated. Thanks!",,"['complex-analysis', 'limits', 'derivatives']"
29,How do I show Theta function is not identically zero,How do I show Theta function is not identically zero,,"How do I show that for a fixed $\omega$ in the upper half plane, the theta function $\theta(z) = \sum_{n=-\infty}^{\infty} e^{\pi i(n^2\omega + 2nz)}$ is not identically zero? Is there an obvious choice of z that would work or would I have to resort to some fourier coefficient argument? Thanks","How do I show that for a fixed $\omega$ in the upper half plane, the theta function $\theta(z) = \sum_{n=-\infty}^{\infty} e^{\pi i(n^2\omega + 2nz)}$ is not identically zero? Is there an obvious choice of z that would work or would I have to resort to some fourier coefficient argument? Thanks",,"['complex-analysis', 'complex-numbers', 'theta-functions']"
30,Is there a holomorphic function $f$ on the unit disc such that $|f(z)|\rightarrow\infty$ as $|z|\rightarrow 1$?,Is there a holomorphic function  on the unit disc such that  as ?,f |f(z)|\rightarrow\infty |z|\rightarrow 1,"When I learnt that there exists a holomorphic function on the unit disc $D$ that cannot be continuously extended to a domain that is strictly larger $D$, I was taught the example $$z\mapsto\sum_{n=1}^\infty z^{n!}.$$ The reason why this function cannot be continuously extended is for at any root of unity $\xi$, there is a sequence in $D$ that converges to $\xi$ whose function values go to infinity and the roots of unity are dense on $\partial D$. This lead me to thinking that there should not be a holomorphic function $f$ on the unit disc such that $|f(z)|\rightarrow\infty$ as $|z|\rightarrow 1$, for otherwise such an $f$ would clearly be a holomorphic function on $D$ that cannot be continuously extended, and why bother with the above series? So I tried to prove that there is not a holomorphic function $f$ on the unit disc such that $|f(z)|\rightarrow\infty$ as $|z|\rightarrow 1$, but could not get anywhere. Can anyone prove this assertion? Or is it false? Many thanks!","When I learnt that there exists a holomorphic function on the unit disc $D$ that cannot be continuously extended to a domain that is strictly larger $D$, I was taught the example $$z\mapsto\sum_{n=1}^\infty z^{n!}.$$ The reason why this function cannot be continuously extended is for at any root of unity $\xi$, there is a sequence in $D$ that converges to $\xi$ whose function values go to infinity and the roots of unity are dense on $\partial D$. This lead me to thinking that there should not be a holomorphic function $f$ on the unit disc such that $|f(z)|\rightarrow\infty$ as $|z|\rightarrow 1$, for otherwise such an $f$ would clearly be a holomorphic function on $D$ that cannot be continuously extended, and why bother with the above series? So I tried to prove that there is not a holomorphic function $f$ on the unit disc such that $|f(z)|\rightarrow\infty$ as $|z|\rightarrow 1$, but could not get anywhere. Can anyone prove this assertion? Or is it false? Many thanks!",,"['complex-analysis', 'analytic-continuation']"
31,"If all the roots of a polynomial P(z) have negative real parts, prove that all the roots of P'(z) also have negative real parts","If all the roots of a polynomial P(z) have negative real parts, prove that all the roots of P'(z) also have negative real parts",,"If all the roots of a polynomial $P(z)$ have negative real parts, prove that all the roots of the derivative $P'(z)$ also have negative real parts. Could anyone provide a proof for this please?","If all the roots of a polynomial $P(z)$ have negative real parts, prove that all the roots of the derivative $P'(z)$ also have negative real parts. Could anyone provide a proof for this please?",,"['complex-analysis', 'polynomials', 'analyticity']"
32,Area growth of harmonic functions,Area growth of harmonic functions,,Can one construct a harmonic function $f$ defined in unit disk with condition $f(0)\geq1$ such that area of $\{z\in\mathbb{D}: f(z)>0\}$ is small enough?,Can one construct a harmonic function $f$ defined in unit disk with condition $f(0)\geq1$ such that area of $\{z\in\mathbb{D}: f(z)>0\}$ is small enough?,,"['complex-analysis', 'harmonic-functions']"
33,Divergence set at radius of convergence,Divergence set at radius of convergence,,"I came up with this question on my own while I was musing around reviewing notes. After unsuccessful Google search (thwarted by a deluge amount of webpages on basic calculus), I decided to ask here. We know that radius of convergence characterize the behaviour of a power series at point inside and outside the radius, but not on it. Calculus book never take much of a careful look at that details. Thus the question is thus: Does there exist a power series $s(z)=\sum\limits_{k=0}^{\infty}a_{k}z^{k}$ such that the set $$D=\{z\in\mathbb{C}:|z|=1, \;s(z) \text{ diverges } \}$$ is $\underline{not}$ a countable union of arcs (close, open or otherwise). Hope someone can solve it. Thank you.","I came up with this question on my own while I was musing around reviewing notes. After unsuccessful Google search (thwarted by a deluge amount of webpages on basic calculus), I decided to ask here. We know that radius of convergence characterize the behaviour of a power series at point inside and outside the radius, but not on it. Calculus book never take much of a careful look at that details. Thus the question is thus: Does there exist a power series $s(z)=\sum\limits_{k=0}^{\infty}a_{k}z^{k}$ such that the set $$D=\{z\in\mathbb{C}:|z|=1, \;s(z) \text{ diverges } \}$$ is $\underline{not}$ a countable union of arcs (close, open or otherwise). Hope someone can solve it. Thank you.",,"['complex-analysis', 'convergence-divergence', 'power-series', 'examples-counterexamples']"
34,sequence of complex polynomials $p_n$ s.t. $p_n(0) = 1$ for every $n \in \mathbb{N}$ and $p_n(z) \to 0$ for each $\mathbb{C}-\{0\}$?,sequence of complex polynomials  s.t.  for every  and  for each ?,p_n p_n(0) = 1 n \in \mathbb{N} p_n(z) \to 0 \mathbb{C}-\{0\},Is there a sequence of complex polynomials $p_n$ s.t. $p_n(0) = 1$ for every $n \in \mathbb{N}$ and $p_n(z) \to 0$ for each $z \in \mathbb{C} \setminus \{0\}$? Any help with this would be great!,Is there a sequence of complex polynomials $p_n$ s.t. $p_n(0) = 1$ for every $n \in \mathbb{N}$ and $p_n(z) \to 0$ for each $z \in \mathbb{C} \setminus \{0\}$? Any help with this would be great!,,"['complex-analysis', 'analysis']"
35,Conformal map of doubly connected domain into annulus.,Conformal map of doubly connected domain into annulus.,,"I have a homework question that I'm stuck on. It asks Let $\Omega$ be a bounded domain whose boundary consists of two disjoint continua $C_1$ and $C_2$. Let $u(z)$ be the harmonic function on $\Omega$ such that $u(z)=0$ on $C_1$ and u(z)=1 on $C_2$, and let $v(z)$ be a locally defined harmonic conjugate of $u(z)$. Prove that there exists a constant $\lambda>0$ such that $F(z)=e^{\lambda(u(z)+iv(z))}$ is single-valued, and that $F(z)$ maps $\Omega$ conformally to the annulus $\{z \in \Bbb C:1<|z|<e^\lambda\}$. I have a hint for the problem to first assume without loss in generality that $C_1$ is the unit circle, and $C_2$ is some simple closed analytic curve in $\{z\in \Bbb C:|z|>1\}$. I do understand this part, since we can use the Riemann mapping theorem on the complement of the bounded component of $\Omega^c$. Next, the hint says that $v(z)$ is strictly increasing on $C_1$, and that we should choose $\lambda$ such that the increase of $\lambda v(z)$ around $C_1$ is $2\pi$. I don't see why this is true. Even if I assume this part, I don't see how that shows $F(z)$ is single-valued. Perhaps it would be better to assume $C_1$ and $C_2$ are both circles and use the ides presented in this problem . However, I'm not sure if I'm allowed to do that. To show that $F(z)$ maps $\Omega$ conformally into an annulus, I believe Ahlfors does this in theorem 10 on page 255 of his complex analysis book. However, I don't understand his proof, and I think it might be too complicated for my situation since I only have two components. He talks about conjugate harmonic differentials, and I don't know what that is. Any help would be extremely appreciated!","I have a homework question that I'm stuck on. It asks Let $\Omega$ be a bounded domain whose boundary consists of two disjoint continua $C_1$ and $C_2$. Let $u(z)$ be the harmonic function on $\Omega$ such that $u(z)=0$ on $C_1$ and u(z)=1 on $C_2$, and let $v(z)$ be a locally defined harmonic conjugate of $u(z)$. Prove that there exists a constant $\lambda>0$ such that $F(z)=e^{\lambda(u(z)+iv(z))}$ is single-valued, and that $F(z)$ maps $\Omega$ conformally to the annulus $\{z \in \Bbb C:1<|z|<e^\lambda\}$. I have a hint for the problem to first assume without loss in generality that $C_1$ is the unit circle, and $C_2$ is some simple closed analytic curve in $\{z\in \Bbb C:|z|>1\}$. I do understand this part, since we can use the Riemann mapping theorem on the complement of the bounded component of $\Omega^c$. Next, the hint says that $v(z)$ is strictly increasing on $C_1$, and that we should choose $\lambda$ such that the increase of $\lambda v(z)$ around $C_1$ is $2\pi$. I don't see why this is true. Even if I assume this part, I don't see how that shows $F(z)$ is single-valued. Perhaps it would be better to assume $C_1$ and $C_2$ are both circles and use the ides presented in this problem . However, I'm not sure if I'm allowed to do that. To show that $F(z)$ maps $\Omega$ conformally into an annulus, I believe Ahlfors does this in theorem 10 on page 255 of his complex analysis book. However, I don't understand his proof, and I think it might be too complicated for my situation since I only have two components. He talks about conjugate harmonic differentials, and I don't know what that is. Any help would be extremely appreciated!",,['complex-analysis']
36,Computing Riemann surfaces of a given algebraic function,Computing Riemann surfaces of a given algebraic function,,"I've never seen written in a book a way or an algorithm for computing Riemann surfaces of a given algebraic function. I would like to know how to construct such Riemann surface using intuitive cutting and pasting techniques as people used to do long time ago. In general, the general statement is that given $Y$ a Riemann surface and some polynomial $P(T) \in \mathscr{M}(Y)[T]$ of degree $n$, one can find another Riemann surface $X$ such that $\pi: X \longrightarrow Y$ is an holomorphic $n$-branched covering and a meromorphic function $F \in \mathscr{M}(X)$ such that $\pi^{*}(P(F)) =0$. So, in summary, given a Riemann surface and a multivalued function one can always find another Riemann surface such that the multivalued function is a meromorphic function. However the proof of the statement above, in general, is done by constructing $X$ with the sheaf of holomorphic functions (as an étale space) and extending germs (to get the ""monodromy"" information). Therefore, the proof does not show a general way of computing such surfaces. Furthermore, I would be glad if someone could show a good example of such construction. Thanks in advance.","I've never seen written in a book a way or an algorithm for computing Riemann surfaces of a given algebraic function. I would like to know how to construct such Riemann surface using intuitive cutting and pasting techniques as people used to do long time ago. In general, the general statement is that given $Y$ a Riemann surface and some polynomial $P(T) \in \mathscr{M}(Y)[T]$ of degree $n$, one can find another Riemann surface $X$ such that $\pi: X \longrightarrow Y$ is an holomorphic $n$-branched covering and a meromorphic function $F \in \mathscr{M}(X)$ such that $\pi^{*}(P(F)) =0$. So, in summary, given a Riemann surface and a multivalued function one can always find another Riemann surface such that the multivalued function is a meromorphic function. However the proof of the statement above, in general, is done by constructing $X$ with the sheaf of holomorphic functions (as an étale space) and extending germs (to get the ""monodromy"" information). Therefore, the proof does not show a general way of computing such surfaces. Furthermore, I would be glad if someone could show a good example of such construction. Thanks in advance.",,"['complex-analysis', 'algebraic-geometry', 'algebraic-curves', 'riemann-surfaces']"
37,Order and type of an entire function $f$ such that the numbers $f^{(n)}(0)$ are integers.,Order and type of an entire function  such that the numbers  are integers.,f f^{(n)}(0),Let $f$ be an entire function with order $p=1$ and such that the numbers $f^{(n)}(0)$ are integers. Then show that the type $\sigma$ is at least $1$. I appreciate any suggestions.,Let $f$ be an entire function with order $p=1$ and such that the numbers $f^{(n)}(0)$ are integers. Then show that the type $\sigma$ is at least $1$. I appreciate any suggestions.,,"['complex-analysis', 'asymptotics']"
38,Complex exponent properties?,Complex exponent properties?,,"Here is a line in a proof in a complex analysis text: $\sqrt{1-z^2}=\sqrt{1-z}\sqrt{1+z}$ I know you can't do this in general, but when can you do it? Here is what I tried: $\sqrt{1-z^2}=e^{1/2\log(1-z^2)}=e^{1/2\log((1-z)(1+z))}$ which, at this point, I would like to say is: $e^{1/2(\log(1-z)+\log(1+z))}$? But I don't believe this can necessarily be done either. And so my question of when it's okay seems like it will depend on what branch/argument I give log. If I choose the branch of log to be $(-\infty,0]$ then $\sqrt{1-z^2}$ only has issues on $[1,\infty)$ and $(-\infty,-1]$.  So if I was on a domain that avoided these intervals, say the open unit disc...would I be able to do what I want with spitting the square root? My reasoning is this: If $arg(z) \in (0,\pi)$, then $arg(-z) \in (-\pi,0)$, and thus $arg(1+z) \in (0,\pi)$ and $arg(1-z) \in (-\pi,0)$.  Thus the sum of the two arguments individually is in $(-\pi,\pi)$. Since $arg(1-z^2) \in (-\pi,\pi)$, this value must equal the sum the two individually. (Since it is well known the identity works mod $2\pi$).","Here is a line in a proof in a complex analysis text: $\sqrt{1-z^2}=\sqrt{1-z}\sqrt{1+z}$ I know you can't do this in general, but when can you do it? Here is what I tried: $\sqrt{1-z^2}=e^{1/2\log(1-z^2)}=e^{1/2\log((1-z)(1+z))}$ which, at this point, I would like to say is: $e^{1/2(\log(1-z)+\log(1+z))}$? But I don't believe this can necessarily be done either. And so my question of when it's okay seems like it will depend on what branch/argument I give log. If I choose the branch of log to be $(-\infty,0]$ then $\sqrt{1-z^2}$ only has issues on $[1,\infty)$ and $(-\infty,-1]$.  So if I was on a domain that avoided these intervals, say the open unit disc...would I be able to do what I want with spitting the square root? My reasoning is this: If $arg(z) \in (0,\pi)$, then $arg(-z) \in (-\pi,0)$, and thus $arg(1+z) \in (0,\pi)$ and $arg(1-z) \in (-\pi,0)$.  Thus the sum of the two arguments individually is in $(-\pi,\pi)$. Since $arg(1-z^2) \in (-\pi,\pi)$, this value must equal the sum the two individually. (Since it is well known the identity works mod $2\pi$).",,"['complex-analysis', 'logarithms', 'branch-cuts']"
39,$\Gamma(1/2-n+it)$ converges uniformly,converges uniformly,\Gamma(1/2-n+it),"Prove that $\Gamma(1/2-n+it)\rightarrow 0$ uniformly as $n\rightarrow\infty$ for $t\in\mathbb{R}$, where $n$ is a positive integer. I'm not sure which definition of $\Gamma$ would be easiest to work with, perhaps this one: $$\Gamma(1/2-n+it)=\dfrac{1}{1/2-n+it}\prod_{m=1}^\infty \dfrac{\left(1+\frac1m\right)^{1/2-n+it}}{1+\frac{1/2-n+it}{m}}$$ How can we go from here?","Prove that $\Gamma(1/2-n+it)\rightarrow 0$ uniformly as $n\rightarrow\infty$ for $t\in\mathbb{R}$, where $n$ is a positive integer. I'm not sure which definition of $\Gamma$ would be easiest to work with, perhaps this one: $$\Gamma(1/2-n+it)=\dfrac{1}{1/2-n+it}\prod_{m=1}^\infty \dfrac{\left(1+\frac1m\right)^{1/2-n+it}}{1+\frac{1/2-n+it}{m}}$$ How can we go from here?",,"['complex-analysis', 'convergence-divergence', 'gamma-function']"
40,Visualization of complex functions,Visualization of complex functions,,"How can I find the image of a rectangle $$a<\Re(z)<b \\c<\Im(z)<d$$ under the function $z^3$ , I tried breaking up $z$ into $x+iy$ and cubing it. I got the real and imaginary parts but how can I plot the function under given domain.","How can I find the image of a rectangle $$a<\Re(z)<b \\c<\Im(z)<d$$ under the function $z^3$ , I tried breaking up $z$ into $x+iy$ and cubing it. I got the real and imaginary parts but how can I plot the function under given domain.",,"['complex-analysis', 'complex-numbers']"
41,"Weierstrass factorization of sine, and related questions","Weierstrass factorization of sine, and related questions",,"So the idea is that you can represent a function as a product of its zeroes, and there are some fundamental factors that often crop up. I am interested in, give this is the WF of sine : Is it really this simple? Just take a function where it is zero, and product these? For $sin(\pi)$ with $z^2$ = $1$ the first factor in the product is 0. And for any integer multiple of $\pi$, $n$, the $n$th term in the product will be zero, and the correct result is achieved. But how does knowledge of the zeroes of the function determine the unique sinusoidal curve between those zeroes? Is it due in this case to $\pi$ giving the sinusoidal shape and in general, what is the determination of the shape of the curve between the zeroes that allows the WF to reproduce it? Other questions is there a neat formula that relates WF to Fourier Series, or Taylor Expansion? (other methods of approximating functions). And the bonus question is : can we form the Riemann Zeta function by the WF of a product of its zeroes?","So the idea is that you can represent a function as a product of its zeroes, and there are some fundamental factors that often crop up. I am interested in, give this is the WF of sine : Is it really this simple? Just take a function where it is zero, and product these? For $sin(\pi)$ with $z^2$ = $1$ the first factor in the product is 0. And for any integer multiple of $\pi$, $n$, the $n$th term in the product will be zero, and the correct result is achieved. But how does knowledge of the zeroes of the function determine the unique sinusoidal curve between those zeroes? Is it due in this case to $\pi$ giving the sinusoidal shape and in general, what is the determination of the shape of the curve between the zeroes that allows the WF to reproduce it? Other questions is there a neat formula that relates WF to Fourier Series, or Taylor Expansion? (other methods of approximating functions). And the bonus question is : can we form the Riemann Zeta function by the WF of a product of its zeroes?",,"['complex-analysis', 'functions', 'approximation-theory']"
42,Prove $|Im(z)|\le |\cos (z)|$ for $z\in \mathbb{C}$.,Prove  for .,|Im(z)|\le |\cos (z)| z\in \mathbb{C},"Let $z\in \mathbb{C}$ i.e. $z=x+iy$. Show that $|Im(z)|\le |\cos (z)|$. My hand wavy hint was to consider $\cos (z)=\cos (x+iy)=\cos (x)\cosh (y)+i\sin (x)\sinh(y)$ then do ""stuff"". Then I have $|\cos (z)|=|Re(z)+iIm(z)|$ and the result will be obvious. Thanks in advance. I am missing something trivial I know.","Let $z\in \mathbb{C}$ i.e. $z=x+iy$. Show that $|Im(z)|\le |\cos (z)|$. My hand wavy hint was to consider $\cos (z)=\cos (x+iy)=\cos (x)\cosh (y)+i\sin (x)\sinh(y)$ then do ""stuff"". Then I have $|\cos (z)|=|Re(z)+iIm(z)|$ and the result will be obvious. Thanks in advance. I am missing something trivial I know.",,"['complex-analysis', 'inequality']"
43,"Closed form of, or series for $\int_{\epsilon-i\infty}^{\epsilon+i\infty}\frac{e^{az+b^2z^2}}{\sin\pi z}\,dz$","Closed form of, or series for","\int_{\epsilon-i\infty}^{\epsilon+i\infty}\frac{e^{az+b^2z^2}}{\sin\pi z}\,dz","I've been trying to find a closed form expression/series expansion for the following integral without success: $$F(a,b)=\int_{\epsilon-i\infty}^{\epsilon+i\infty} e^{az+b^2z^2}\Gamma(z)\Gamma(1-z)\,dz=\pi\int_{\epsilon-i\infty}^{\epsilon+i\infty}\frac{e^{az+b^2z^2}}{\sin\pi z}\,dz$$ for some $\epsilon\in(0,1)$ . Any input is greatly appreciated!",I've been trying to find a closed form expression/series expansion for the following integral without success: for some . Any input is greatly appreciated!,"F(a,b)=\int_{\epsilon-i\infty}^{\epsilon+i\infty} e^{az+b^2z^2}\Gamma(z)\Gamma(1-z)\,dz=\pi\int_{\epsilon-i\infty}^{\epsilon+i\infty}\frac{e^{az+b^2z^2}}{\sin\pi z}\,dz \epsilon\in(0,1)","['complex-analysis', 'definite-integrals', 'improper-integrals', 'gamma-function']"
44,The converse to Schwarz Pick lemma?,The converse to Schwarz Pick lemma?,,"The Schwarz-Pick lemma states that if $D$ denotes the unit disk in the complex plane, and $f: D\rightarrow D$ is a holomorphic function, then it is a contraction with respect to the Poincare metric (which we shall denote as $\rho$) on the disk. A natural question to ask (for me at least) is are all functions $f: D\rightarrow D$ which are contractions with respect to $\rho$ holomorphic? This cannot be true exactly as stated since, if we denote the conjugation map by $\tau: z\mapsto \bar{z}$, we have, for an arbitrary holomorphic function $f$: \begin{align} \rho(f\circ\tau(z_1), f\circ\tau(z_2)) & \leq \rho(\tau(z_1),\tau(z_2))\\                                        &= \rho(z_1,z_2) \end{align} Since $\tau$ is an isometry for $\rho$; but $f\circ\tau$ is anti-analytic. So, my question is: Is every function which is a contraction with respect to $\rho$ either analytic or anti-analytic? This seems too good to be true, so could anyone provide a simple counter-example? Edit: contraction is the wrong word. It should be replaced with non-expansive or 1 Lispchitz as in 5P.M.'s answer.","The Schwarz-Pick lemma states that if $D$ denotes the unit disk in the complex plane, and $f: D\rightarrow D$ is a holomorphic function, then it is a contraction with respect to the Poincare metric (which we shall denote as $\rho$) on the disk. A natural question to ask (for me at least) is are all functions $f: D\rightarrow D$ which are contractions with respect to $\rho$ holomorphic? This cannot be true exactly as stated since, if we denote the conjugation map by $\tau: z\mapsto \bar{z}$, we have, for an arbitrary holomorphic function $f$: \begin{align} \rho(f\circ\tau(z_1), f\circ\tau(z_2)) & \leq \rho(\tau(z_1),\tau(z_2))\\                                        &= \rho(z_1,z_2) \end{align} Since $\tau$ is an isometry for $\rho$; but $f\circ\tau$ is anti-analytic. So, my question is: Is every function which is a contraction with respect to $\rho$ either analytic or anti-analytic? This seems too good to be true, so could anyone provide a simple counter-example? Edit: contraction is the wrong word. It should be replaced with non-expansive or 1 Lispchitz as in 5P.M.'s answer.",,['complex-analysis']
45,Order of growth of the entire function $\sin(\sqrt{z})/\sqrt{z}$,Order of growth of the entire function,\sin(\sqrt{z})/\sqrt{z},"Show that $$f(z)=\frac{\sin\sqrt z}{\sqrt z}$$ is an entire function of finite order $\rho$ and determine $\rho$ . I observed that the two determinations of the square root differ only for the signum. Since $\sin(-z)=-\sin z$ , we have that $f(z)$ is well defined, and entire because it's the ratio of two entire functions with denominator never vanishing. For the order i use the Taylor expansion $$\sin z=\sum_{n=0}^{\infty}(-1)^n\frac{z^{2n+1}}{(2n+1)!}$$ which for $z=\sqrt z$ gives $$\sin\sqrt z=\sum_{n=0}^{\infty}(-1)^n\frac{z^{n}\sqrt z}{(2n+1)!}$$ Thus $$\frac{\sin\sqrt z}{\sqrt z}=\sum_{n=0}^{\infty}(-1)^n\frac{z^{n}}{(2n+1)!}$$ Then we have $$(2n+1)!\geq2^n n!$$ hence $$\bigg|\frac{\sin\sqrt z}{\sqrt z}\bigg|\leq\large\sum_{n=0}^{\infty}\left(\frac{|z|}{2}\right)^{n}\cdot\frac{1}{n!}=e^{|z|/2}$$ This (if correct) shows that $\rho\leq\frac{1}{2}$ . How can be shown the identity?","Show that is an entire function of finite order and determine . I observed that the two determinations of the square root differ only for the signum. Since , we have that is well defined, and entire because it's the ratio of two entire functions with denominator never vanishing. For the order i use the Taylor expansion which for gives Thus Then we have hence This (if correct) shows that . How can be shown the identity?",f(z)=\frac{\sin\sqrt z}{\sqrt z} \rho \rho \sin(-z)=-\sin z f(z) \sin z=\sum_{n=0}^{\infty}(-1)^n\frac{z^{2n+1}}{(2n+1)!} z=\sqrt z \sin\sqrt z=\sum_{n=0}^{\infty}(-1)^n\frac{z^{n}\sqrt z}{(2n+1)!} \frac{\sin\sqrt z}{\sqrt z}=\sum_{n=0}^{\infty}(-1)^n\frac{z^{n}}{(2n+1)!} (2n+1)!\geq2^n n! \bigg|\frac{\sin\sqrt z}{\sqrt z}\bigg|\leq\large\sum_{n=0}^{\infty}\left(\frac{|z|}{2}\right)^{n}\cdot\frac{1}{n!}=e^{|z|/2} \rho\leq\frac{1}{2},"['complex-analysis', 'asymptotics', 'entire-functions']"
46,How $f^{2}=g^{6}-1$ implies $f$ and $g$ are constant?,How  implies  and  are constant?,f^{2}=g^{6}-1 f g,"From Harvard qualification exam, 1990. Let $f,g$ be two entire holomorphic functions satisfy the property $$f(z)^{2}=g(z)^{6}-1,\forall z\in \mathbb{C}$$ Prove that $f,g$ are constant functions. Would this be the same if $f,g$ are allowed to be meromorphic functions? The problem comes with a hint that I should think about the algebraic curve $$y^{2}=x^{6}-1$$but I do not see how they are related. I know this curve is hyperellipitic (from Riemann-Hurwitz or simply the wiki article). But how this help?(this curve should be of genus 2). Taking a short look at the entire function article also seems to be no help. Is the author implying $f,g$ is not best to be treated by classical Riemann Surface applications (as opposed to algebraic geometry ones)?","From Harvard qualification exam, 1990. Let $f,g$ be two entire holomorphic functions satisfy the property $$f(z)^{2}=g(z)^{6}-1,\forall z\in \mathbb{C}$$ Prove that $f,g$ are constant functions. Would this be the same if $f,g$ are allowed to be meromorphic functions? The problem comes with a hint that I should think about the algebraic curve $$y^{2}=x^{6}-1$$but I do not see how they are related. I know this curve is hyperellipitic (from Riemann-Hurwitz or simply the wiki article). But how this help?(this curve should be of genus 2). Taking a short look at the entire function article also seems to be no help. Is the author implying $f,g$ is not best to be treated by classical Riemann Surface applications (as opposed to algebraic geometry ones)?",,"['complex-analysis', 'riemann-surfaces']"
47,Zeros in the complex plane and convergence,Zeros in the complex plane and convergence,,"I'm doing some number theory which requires some work in $\mathbb{C}$, but unfortunately my complex analysis is a little rusty. A text I am reading states the following: ...and given that $\sum_{\rho}|\rho|^{-2}$ converges, it follows that the product $\prod \limits_\rho (1-\frac{z}{\rho})e^{z/\rho}$ converges to an entire function with zeros at $z=\rho$ and nowhere else. Could anyone explain, preferably without going into too much detail (just refreshing my memory!) why this is? Here, $\rho$ ranges over the set of zeros of an integral function $f: \mathbb{C} \to \mathbb{C}$ of order 1, which is not identically zero. It's obvious that the product is zero at each $\rho$; what do we need to know it converges to an entire function with zeros nowhere else? For convergence, do we simply need to bound the modulus above by some finite value at each $z$? And since it's an infinite product, how do we confirm that it's zero nowhere else; a lower bound of the same manner? Finally, what tells us it is entire? Again, given that it's an infinite product I don't know how trivial that claim is; not very hard I'm sure but perhaps requiring some small justification. As I said, I have probably learned all this at some point in my life so no need for extraordinary detail, just a brief explanation would be very helpful. It all seems vaguely reminiscent of a course I took on Riemann surfaces a few years back. Thanks!","I'm doing some number theory which requires some work in $\mathbb{C}$, but unfortunately my complex analysis is a little rusty. A text I am reading states the following: ...and given that $\sum_{\rho}|\rho|^{-2}$ converges, it follows that the product $\prod \limits_\rho (1-\frac{z}{\rho})e^{z/\rho}$ converges to an entire function with zeros at $z=\rho$ and nowhere else. Could anyone explain, preferably without going into too much detail (just refreshing my memory!) why this is? Here, $\rho$ ranges over the set of zeros of an integral function $f: \mathbb{C} \to \mathbb{C}$ of order 1, which is not identically zero. It's obvious that the product is zero at each $\rho$; what do we need to know it converges to an entire function with zeros nowhere else? For convergence, do we simply need to bound the modulus above by some finite value at each $z$? And since it's an infinite product, how do we confirm that it's zero nowhere else; a lower bound of the same manner? Finally, what tells us it is entire? Again, given that it's an infinite product I don't know how trivial that claim is; not very hard I'm sure but perhaps requiring some small justification. As I said, I have probably learned all this at some point in my life so no need for extraordinary detail, just a brief explanation would be very helpful. It all seems vaguely reminiscent of a course I took on Riemann surfaces a few years back. Thanks!",,"['complex-analysis', 'convergence-divergence', 'products']"
48,Maximization of complex quadratic function with quadratic and cubic equality constraints,Maximization of complex quadratic function with quadratic and cubic equality constraints,,"I am trying to solve $$\max_{g_0,...,g_{M-1}} \left|\sum_{m=0}^{M-1} g_m\right|^2\ \text{s.t.}\ \sum_{m=0}^{M-1} |g_m|^2=M,\ \sum_{m=0}^{M-1} g_m |g_m|^2=0.$$ where $g_m$ can be complex. The problem does not seem easy to solve for me. Intuitively, I would conjecture that an optimal $g_m$ should be purely real up to a constant phasor ( $g_me^{\jmath \phi}$ achieves the same cost function as $g_m$ and also meets the constraints if $g_m$ does). If this phasor is set to one, the problem is converted to an all real problem $$\max_{g_0,...,g_{M-1}} \left(\sum_{m=0}^{M-1} g_m\right)^2\ \text{s.t.}\ \sum_{m=0}^{M-1} g_m^2=M,\ \sum_{m=0}^{M-1} g_m^3=0.$$ I can find the globally optimal solution of this problem using the Lagrangian, setting its derivative to zero, and finding the global optimum among the different critical points. The optimal solution is then ""simply"" to set all $g_m$ to the same value except for one with an opposite sign to meet the second constraint. For instance, using first element as the opposite one \begin{align*} 	g_m&=\frac{\sqrt{M}}{\sqrt{M-1+(M-1)^{2/3}}}\begin{cases} 	- \left(M-1\right)^{1/3}\ &\text{if}\ m=0\\ 	1\ &\text{otherwise} 	\end{cases}. \end{align*} Of course all of that relies on the conjecture, which I find hard to prove... Any idea? Thank you for your help!","I am trying to solve where can be complex. The problem does not seem easy to solve for me. Intuitively, I would conjecture that an optimal should be purely real up to a constant phasor ( achieves the same cost function as and also meets the constraints if does). If this phasor is set to one, the problem is converted to an all real problem I can find the globally optimal solution of this problem using the Lagrangian, setting its derivative to zero, and finding the global optimum among the different critical points. The optimal solution is then ""simply"" to set all to the same value except for one with an opposite sign to meet the second constraint. For instance, using first element as the opposite one Of course all of that relies on the conjecture, which I find hard to prove... Any idea? Thank you for your help!","\max_{g_0,...,g_{M-1}} \left|\sum_{m=0}^{M-1} g_m\right|^2\ \text{s.t.}\ \sum_{m=0}^{M-1} |g_m|^2=M,\ \sum_{m=0}^{M-1} g_m |g_m|^2=0. g_m g_m g_me^{\jmath \phi} g_m g_m \max_{g_0,...,g_{M-1}} \left(\sum_{m=0}^{M-1} g_m\right)^2\ \text{s.t.}\ \sum_{m=0}^{M-1} g_m^2=M,\ \sum_{m=0}^{M-1} g_m^3=0. g_m \begin{align*}
	g_m&=\frac{\sqrt{M}}{\sqrt{M-1+(M-1)^{2/3}}}\begin{cases}
	- \left(M-1\right)^{1/3}\ &\text{if}\ m=0\\
	1\ &\text{otherwise}
	\end{cases}.
\end{align*}","['complex-analysis', 'optimization', 'non-convex-optimization']"
49,Finding the bounds for $|e^z - 1|$ on unit circle.,Finding the bounds for  on unit circle.,|e^z - 1|,"The sharp upper bound is relatively easy to find: $$|e^z - 1| = \left|\sum_{n = 1}^\infty \frac{z^n}{n!} \right| \leq \sum_{n = 1}^\infty \frac{|z|^n}{n!} = e^{|z|} - 1 = e - 1$$ and it is attained at $z = 1$ . I am wondering if there is a simple way to obtain a positive lower bound. I am suspecting a sharp lower bound is $(1 - 1/e)$ but I cannot prove it. I was told that $(3 - e)$ is a positive lower bound, but I could not prove it neither. Remark: One can do some horrible single variable calculus by writing $z = e^{it}$ , where $t \in [0, 2\pi]$ but I would like to know if there is another (possibly much simpler) way to find a nontrivial lower bound. Edit: It seems that I got many answer like the following but they are deleted by the author very soon. I think it is a good idea to show a wrong attempt so I put it here: Putting $z = e^{it}$ , then \begin{align*}|e^z - 1|^2 & = |e^{2 \cos t} - 2e^{\cos t} \cos (\sin t)) + 1| \\ & \geq |e^{\cos t} - 1|^2 \\ & \geq (1 - 1/e)^2 \end{align*} The last estimation is WRONG when $t = \pi/2$ . (End of edit)","The sharp upper bound is relatively easy to find: and it is attained at . I am wondering if there is a simple way to obtain a positive lower bound. I am suspecting a sharp lower bound is but I cannot prove it. I was told that is a positive lower bound, but I could not prove it neither. Remark: One can do some horrible single variable calculus by writing , where but I would like to know if there is another (possibly much simpler) way to find a nontrivial lower bound. Edit: It seems that I got many answer like the following but they are deleted by the author very soon. I think it is a good idea to show a wrong attempt so I put it here: Putting , then The last estimation is WRONG when . (End of edit)","|e^z - 1| = \left|\sum_{n = 1}^\infty \frac{z^n}{n!} \right| \leq \sum_{n = 1}^\infty \frac{|z|^n}{n!} = e^{|z|} - 1 = e - 1 z = 1 (1 - 1/e) (3 - e) z = e^{it} t \in [0, 2\pi] z = e^{it} \begin{align*}|e^z - 1|^2 & = |e^{2 \cos t} - 2e^{\cos t} \cos (\sin t)) + 1| \\
& \geq |e^{\cos t} - 1|^2 \\
& \geq (1 - 1/e)^2
\end{align*} t = \pi/2",['complex-analysis']
50,Asymptotic expansion of the Volterra integral equation with series ansatz,Asymptotic expansion of the Volterra integral equation with series ansatz,,"Problem I have a problem which can be boiled down to the Volterra integral equation $$ \begin{aligned} w(\eta) &\sim \eta \int _0^\infty K(s)F(\eta s)ds \end{aligned} $$ for $\alpha \in (\frac 12 , 1)$ , with kernel and non-linearity defined as $$ K(s) := \frac{1}{\Gamma(\alpha)}(1-s)^{\alpha-1} \theta(1-s) \qquad F(\eta s) := (\eta s + \eta_0)^{-1-\alpha} (c_0 + c_1w(\eta s) + c_2 w(\eta s)^2) $$ where $\theta(s)$ is Heaviside step function is $\eta_0>0$ is a positive constant. It is assumed that for our choice of coefficients $c_0, c_1, c_2$ the function $w(\eta)\rightarrow \infty$ as $\eta \rightarrow \infty$ . The equation cannot be solved explicitly, the goal is to obtain the asymptotic expansion of $w(\eta)$ as $\eta \rightarrow \infty$ . My attempt Recall the definition of the Mellin transform $$ \mathrm M [f(s); z] = \int _0^\infty s^{z-1} f(s) ds. $$ Once formulated as above, we can use Parseval formula for the Mellin transform and rewrite the problem as $$ w(\eta) \sim \frac{\eta}{2 \pi i} \int_{c-i \infty}^{c+i \infty} \mathrm{M}[K(s) ; 1-z] \mathrm{M}[F(\eta s) ; z] d z $$ whereas $\Re (c)$ is in the analiticity strip of both Mellin transforms. Ansatz We now make an ansatz $$ w(\eta) = \sum_{k=1}^{-\infty} d_k \eta^{\alpha k} = d_1 \eta^\alpha + d_0 + d_{-1} \eta ^ {-\alpha} + \dots = d_1 \eta^\alpha + d_0 + O(\eta^{-\alpha}) $$ The idea is to calculate Mellin transforms in the above integral and match the coefficients to calculate $d_1$ and $d_0$ . Mellin transform of the kernel $$ M[K(s); 1-z] = \frac{\Gamma(1-z)}{\Gamma(1+\alpha-z)} = - \sum _{n=0} ^\infty \frac{(-1)^n}{\Gamma(\alpha-n) n!} \left(\frac{1}{z-(n+1)}\right). $$ It has poles at $z = 1, 2, 3, \dots$ and hence analytical for $\Re (z) < 1$ . Mellin transform of the non-linearity If we plug in $w(\eta)$ from ansatz above into the non-linearity $F(\eta s)$ , we obtain $$ \begin{aligned} F(\eta s) &= (\eta s + \eta _0)^{-1-\alpha}\left\{c_2 d_1^2  (\eta s)^{2\alpha} + (2 c_2 d_0d_1 + c_1 d_1)(\eta s)^{\alpha}\right\} + O((\eta s)^{-1-\alpha} ) \\ &\sim c_2 d_1^2  (\eta s)^{-1-\alpha} + (2 c_2 d_0d_1 + c_1 d_1)(\eta s)^{-1} + O((\eta s)^{-1-\alpha} ) \end{aligned} $$ Mellin transforms of the first two terms are $$ \begin{aligned} M\left[c_2 d_{1}^{2} (\eta s)^{-1+\alpha}; z\right] &= (c_2 d_{1}^{2}) \frac{\eta ^{-z}}{z-(1-\alpha)}\\ M\left[(2 c_2 d_0d_1 + c_1 d_1) (\eta s)^{-1}; z\right] &= (2 c_2 d_0d_1 + c_1 d_1) \frac{\eta ^{-z}}{z-1}. \end{aligned} $$ In order for the Mellin transforms to exist, we require $z < 1-\alpha$ . Hence $\mathrm{M}[F(\eta s) ; z]$ is analytic for $\Re(z) < 1-\alpha$ . So we see that each term in the expansion of $F(\eta s)$ leads to the pole of $\mathrm{M}[F(\eta s) ; z]$ at $z = 1-\alpha, 1, 1+\alpha, \dots$ . Shifting the contour to the right Recall that using Parseval formula we have rewritten our problem as $$ w(\eta) \sim \frac{\eta}{2 \pi i} \int_{c-i \infty}^{c+i \infty} \mathrm{M}[K(s) ; 1-z] \mathrm{M}[F(\eta s) ; z] d z. $$ Now that we obtained analiticity strips of the Mellin transforms above, we see it is required that $\Re (c) < 1 - \alpha$ . The idea now is to shift the integration contour to the right and use Cauchy integral formula $$ f^{(n)}(a)=\frac{n !}{2 \pi i} \oint_{\gamma} \frac{f(z)}{(z-a)^{n+1}} d z $$ to calculate the integrals around the poles. Assume at this point that we can shift the contour to the right. We plug in the Mellin transforms calculated above and shift the contour to the right so that $u \in (1, 1+\alpha)$ to obtain first two terms in the integral expansion: $$ \begin{aligned} d_1 \eta ^\alpha + d_0 + \dots &\sim \frac{\eta}{2 \pi i} \int_{\gamma_1} \left( \frac{\Gamma(1-z)}{\Gamma(1+\alpha-z)}\right) \left(c_{2} d_{1}^{2}\right)  \frac{\eta^{-z}}{z-(1-\alpha)} \\ &+ \frac{\eta}{2 \pi i} \int_{\gamma_0} \left( \frac{\Gamma(1-z)}{\Gamma(1+\alpha-z)}\right) \left(2 c_{2} d_{0} d_{1}+c_{1} d_{1}\right) \frac{\eta^{-z}}{z-1} \\ &+ \frac{\eta}{2 \pi i} \int_{u - i\infty} ^{u + i \infty} \mathbf{M}[K(s) ; 1-z] \mathbf{M}[F(\eta s) ; z] d z \end{aligned} $$ such that $\gamma_1$ encloses $z=1-\alpha$ and $\gamma_0$ encloses $z=1$ . First coefficient $d_1$ The contour integral around $z = 1-\alpha$ can be calculated with Cauchy integral formula $$ \frac{\eta}{2 \pi i} \int_{\gamma_1} \left(c_{2} d_{1}^{2}\right) \left( \frac{\Gamma(1-z)}{\Gamma(1+\alpha-z)}\right) \frac{\eta^{-z}}{z-(1-\alpha)} = c_2 d_1^2 \frac{\Gamma(\alpha)}{\Gamma(2\alpha)} \eta ^\alpha $$ Matching the first coefficient leads to $$ d_1 \eta ^\alpha = c_2 d_1^2 \frac{\Gamma(\alpha)}{\Gamma(2\alpha)} \eta ^\alpha \qquad \text{and thus} \qquad d_1 = \frac{\Gamma(2\alpha)}{c_2 \Gamma(\alpha)} $$ Second coefficient $d_0$ The problem that arises now is that both kernel and non-linearity have pole at $z=1$ . Hence the integrand has the pole of order 2 and Cauchy integral formula will involve derivative of $\eta ^{-z}$ , which will yield the term $\log (\eta)$ : $$ \begin{array}{l} \frac{\eta}{2 \pi i} \int_{\gamma_0} \frac{\Gamma(1-z)}{\Gamma(1+\alpha-z)} M[F(\eta s) ; z] d z \\ = \eta \cdot \text{Res}(\Gamma(1-z), 1) \cdot \text{Res}(M[F(\eta s); z], 1) \cdot \left. [f'(z)] \right| _{z = 1, f(z) = \frac{\eta^{-z}}{\Gamma(1+\alpha-z)}} \\ = (2c_2 d_{0} d_{1}+c_1 d_{1}) \frac{-\log (\eta) \Gamma(\alpha) + \Gamma'(\alpha)}{\Gamma(\alpha)^2}. \end{array} $$ Matching the coefficient $d_0$ leads to $$ d_0 = (2c_2 d_{0} d_{1}+c_1 d_{1}) \frac{\Gamma'(\alpha)}{\Gamma(\alpha)^2}. $$ Since we know the $d_1$ , the above equation can be solved for $d_0$ . However , we are left with the residual term $- \frac{(2c_2 d_{0} d_{1}+c_1 d_{1}) \Gamma(\alpha)}{\Gamma(\alpha)^2} \log (\eta)$ of order $ \log (\eta)$ of order $ \log (\eta)$ , which cannot be matched with anything on the left-hand side, since our ansatz did not have a logarithmic term. Hence this ansatz does not work directly and probably should be modified. Remark Extending the ansatz to involve the logarithmic term $$ w(\eta) = d_1 \eta^\alpha + d_\text{log} \log (\eta) + d_0 + d_{-1} \eta ^ {-\alpha} + \dots $$ will lead to the pole of order 3 in the integrand, and Cauchy integral formula will involve second derivative and lead to the term of order $\log ^2 (\eta)$ on the right-hand side (including $\log ^2 (\eta)$ will lead to $\log ^3 (\eta)$ on the right-hand side and so on). In conclusion, I wanted to ask whether there is a way to improve this ansatz so that all coefficients can be matched. On the other hand, maybe some alternative approach to the problem can be considered. Any help appreciated, thank you.","Problem I have a problem which can be boiled down to the Volterra integral equation for , with kernel and non-linearity defined as where is Heaviside step function is is a positive constant. It is assumed that for our choice of coefficients the function as . The equation cannot be solved explicitly, the goal is to obtain the asymptotic expansion of as . My attempt Recall the definition of the Mellin transform Once formulated as above, we can use Parseval formula for the Mellin transform and rewrite the problem as whereas is in the analiticity strip of both Mellin transforms. Ansatz We now make an ansatz The idea is to calculate Mellin transforms in the above integral and match the coefficients to calculate and . Mellin transform of the kernel It has poles at and hence analytical for . Mellin transform of the non-linearity If we plug in from ansatz above into the non-linearity , we obtain Mellin transforms of the first two terms are In order for the Mellin transforms to exist, we require . Hence is analytic for . So we see that each term in the expansion of leads to the pole of at . Shifting the contour to the right Recall that using Parseval formula we have rewritten our problem as Now that we obtained analiticity strips of the Mellin transforms above, we see it is required that . The idea now is to shift the integration contour to the right and use Cauchy integral formula to calculate the integrals around the poles. Assume at this point that we can shift the contour to the right. We plug in the Mellin transforms calculated above and shift the contour to the right so that to obtain first two terms in the integral expansion: such that encloses and encloses . First coefficient The contour integral around can be calculated with Cauchy integral formula Matching the first coefficient leads to Second coefficient The problem that arises now is that both kernel and non-linearity have pole at . Hence the integrand has the pole of order 2 and Cauchy integral formula will involve derivative of , which will yield the term : Matching the coefficient leads to Since we know the , the above equation can be solved for . However , we are left with the residual term of order of order , which cannot be matched with anything on the left-hand side, since our ansatz did not have a logarithmic term. Hence this ansatz does not work directly and probably should be modified. Remark Extending the ansatz to involve the logarithmic term will lead to the pole of order 3 in the integrand, and Cauchy integral formula will involve second derivative and lead to the term of order on the right-hand side (including will lead to on the right-hand side and so on). In conclusion, I wanted to ask whether there is a way to improve this ansatz so that all coefficients can be matched. On the other hand, maybe some alternative approach to the problem can be considered. Any help appreciated, thank you.","
\begin{aligned}
w(\eta) &\sim \eta \int _0^\infty K(s)F(\eta s)ds
\end{aligned}
 \alpha \in (\frac 12 , 1) 
K(s) := \frac{1}{\Gamma(\alpha)}(1-s)^{\alpha-1} \theta(1-s) \qquad F(\eta s) := (\eta s + \eta_0)^{-1-\alpha} (c_0 + c_1w(\eta s) + c_2 w(\eta s)^2)
 \theta(s) \eta_0>0 c_0, c_1, c_2 w(\eta)\rightarrow \infty \eta \rightarrow \infty w(\eta) \eta \rightarrow \infty 
\mathrm M [f(s); z] = \int _0^\infty s^{z-1} f(s) ds.
 
w(\eta) \sim \frac{\eta}{2 \pi i} \int_{c-i \infty}^{c+i \infty} \mathrm{M}[K(s) ; 1-z] \mathrm{M}[F(\eta s) ; z] d z
 \Re (c) 
w(\eta) = \sum_{k=1}^{-\infty} d_k \eta^{\alpha k} = d_1 \eta^\alpha + d_0 + d_{-1} \eta ^ {-\alpha} + \dots = d_1 \eta^\alpha + d_0 + O(\eta^{-\alpha})
 d_1 d_0 
M[K(s); 1-z] = \frac{\Gamma(1-z)}{\Gamma(1+\alpha-z)} = - \sum _{n=0} ^\infty \frac{(-1)^n}{\Gamma(\alpha-n) n!} \left(\frac{1}{z-(n+1)}\right).
 z = 1, 2, 3, \dots \Re (z) < 1 w(\eta) F(\eta s) 
\begin{aligned}
F(\eta s) &= (\eta s + \eta _0)^{-1-\alpha}\left\{c_2 d_1^2  (\eta s)^{2\alpha} + (2 c_2 d_0d_1 + c_1 d_1)(\eta s)^{\alpha}\right\} + O((\eta s)^{-1-\alpha} ) \\
&\sim c_2 d_1^2  (\eta s)^{-1-\alpha} + (2 c_2 d_0d_1 + c_1 d_1)(\eta s)^{-1} + O((\eta s)^{-1-\alpha} )
\end{aligned}
 
\begin{aligned}
M\left[c_2 d_{1}^{2} (\eta s)^{-1+\alpha}; z\right] &= (c_2 d_{1}^{2}) \frac{\eta ^{-z}}{z-(1-\alpha)}\\
M\left[(2 c_2 d_0d_1 + c_1 d_1) (\eta s)^{-1}; z\right] &= (2 c_2 d_0d_1 + c_1 d_1) \frac{\eta ^{-z}}{z-1}.
\end{aligned}
 z < 1-\alpha \mathrm{M}[F(\eta s) ; z] \Re(z) < 1-\alpha F(\eta s) \mathrm{M}[F(\eta s) ; z] z = 1-\alpha, 1, 1+\alpha, \dots 
w(\eta) \sim \frac{\eta}{2 \pi i} \int_{c-i \infty}^{c+i \infty} \mathrm{M}[K(s) ; 1-z] \mathrm{M}[F(\eta s) ; z] d z.
 \Re (c) < 1 - \alpha 
f^{(n)}(a)=\frac{n !}{2 \pi i} \oint_{\gamma} \frac{f(z)}{(z-a)^{n+1}} d z
 u \in (1, 1+\alpha) 
\begin{aligned}
d_1 \eta ^\alpha + d_0 + \dots &\sim \frac{\eta}{2 \pi i} \int_{\gamma_1} \left( \frac{\Gamma(1-z)}{\Gamma(1+\alpha-z)}\right) \left(c_{2} d_{1}^{2}\right)  \frac{\eta^{-z}}{z-(1-\alpha)} \\
&+ \frac{\eta}{2 \pi i} \int_{\gamma_0} \left( \frac{\Gamma(1-z)}{\Gamma(1+\alpha-z)}\right) \left(2 c_{2} d_{0} d_{1}+c_{1} d_{1}\right) \frac{\eta^{-z}}{z-1} \\
&+ \frac{\eta}{2 \pi i} \int_{u - i\infty} ^{u + i \infty} \mathbf{M}[K(s) ; 1-z] \mathbf{M}[F(\eta s) ; z] d z
\end{aligned}
 \gamma_1 z=1-\alpha \gamma_0 z=1 d_1 z = 1-\alpha 
\frac{\eta}{2 \pi i} \int_{\gamma_1} \left(c_{2} d_{1}^{2}\right) \left( \frac{\Gamma(1-z)}{\Gamma(1+\alpha-z)}\right) \frac{\eta^{-z}}{z-(1-\alpha)} = c_2 d_1^2 \frac{\Gamma(\alpha)}{\Gamma(2\alpha)} \eta ^\alpha
 
d_1 \eta ^\alpha = c_2 d_1^2 \frac{\Gamma(\alpha)}{\Gamma(2\alpha)} \eta ^\alpha
\qquad \text{and thus} \qquad
d_1 = \frac{\Gamma(2\alpha)}{c_2 \Gamma(\alpha)}
 d_0 z=1 \eta ^{-z} \log (\eta) 
\begin{array}{l}
\frac{\eta}{2 \pi i} \int_{\gamma_0} \frac{\Gamma(1-z)}{\Gamma(1+\alpha-z)} M[F(\eta s) ; z] d z \\
= \eta \cdot \text{Res}(\Gamma(1-z), 1) \cdot \text{Res}(M[F(\eta s); z], 1) \cdot \left. [f'(z)] \right| _{z = 1, f(z) = \frac{\eta^{-z}}{\Gamma(1+\alpha-z)}} \\
= (2c_2 d_{0} d_{1}+c_1 d_{1}) \frac{-\log (\eta) \Gamma(\alpha) + \Gamma'(\alpha)}{\Gamma(\alpha)^2}.
\end{array}
 d_0 
d_0 = (2c_2 d_{0} d_{1}+c_1 d_{1}) \frac{\Gamma'(\alpha)}{\Gamma(\alpha)^2}.
 d_1 d_0 - \frac{(2c_2 d_{0} d_{1}+c_1 d_{1}) \Gamma(\alpha)}{\Gamma(\alpha)^2} \log (\eta)  \log (\eta)  \log (\eta) 
w(\eta) = d_1 \eta^\alpha + d_\text{log} \log (\eta) + d_0 + d_{-1} \eta ^ {-\alpha} + \dots
 \log ^2 (\eta) \log ^2 (\eta) \log ^3 (\eta)","['complex-analysis', 'asymptotics', 'integral-equations', 'cauchy-integral-formula', 'mellin-transform']"
51,How is the determinant related to the unit circle?,How is the determinant related to the unit circle?,,"Here is a STEP 3 question from 2018, of which the Latex code can be downloaded here . I know perfectly how to answer this question, so please do not answer it . The  distinct points $A$ , $Q$ and $C$ lie on a straight line in the Argand diagram, and  represent the distinct complex numbers $a$ , $q$ and $c$ , respectively.  Show that $\dfrac {q-a}{c-a}$ is real and hence that $(c-a)(q^*-a^*) = (c^*-a^*)(q-a)\,$ . Given that $aa^* = cc^* = 1$ , show further that $$ q+ ac q^* = a+c  $$ The distinct points $A$ , $B$ , $C$ and $D$ lie, in anticlockwise order, on the circle of unit radius  with centre at the origin   (so that, for example, $aa^* =1$ ). The lines $AC$ and $BD$ meet at $Q$ . Show that $$ (ac-bd)q^* = (a+c)-(b+d) \,, $$ where $b$ and $d$ are complex numbers represented by the  points $B$ and $D$ respectively, and show further that $$ (ac-bd)  (q+q^*) =  (a-b)(1+cd) +(c-d)(1+ab)  \,. $$ The lines $AB$ and $CD$ meet at $P$ , which  represents the complex number $p$ . Given that~ $p$ is real, show that $p(1+ab)=a+b\,$ . Given further that $ac-bd \ne 0\,$ , show that $$ p(q+q^*) =  2  \,. $$ This question involves a large amount of algebra, and one can easily get lost in it. However, there are some interesting patterns emerging in the problem: Why $ac-bd$ appears? This is the $2\times 2$ determinant! What's really going on here? In complex analysis/methods books, I have not seen any determinants related to circles or straight lines. (For circles, we have cross ratios, which is something completely different.) Are there any generalizations to $3\times 3$ or higher determinants? The last result, which states that $p\Re (q)=1$ , is also quite interesting. How to interpret this result? To summarize, this question seems to be tackling a very deep theory in geometry in an elementary way. I try to find more about this in complex methods textbooks, but I have not found any. Can anyone explain intuitively what's going on about the determinants , or tell me where to read more about the geometry of the unit circle? Just tell me where this question leads us to if we go any further.","Here is a STEP 3 question from 2018, of which the Latex code can be downloaded here . I know perfectly how to answer this question, so please do not answer it . The  distinct points , and lie on a straight line in the Argand diagram, and  represent the distinct complex numbers , and , respectively.  Show that is real and hence that . Given that , show further that The distinct points , , and lie, in anticlockwise order, on the circle of unit radius  with centre at the origin   (so that, for example, ). The lines and meet at . Show that where and are complex numbers represented by the  points and respectively, and show further that The lines and meet at , which  represents the complex number . Given that~ is real, show that . Given further that , show that This question involves a large amount of algebra, and one can easily get lost in it. However, there are some interesting patterns emerging in the problem: Why appears? This is the determinant! What's really going on here? In complex analysis/methods books, I have not seen any determinants related to circles or straight lines. (For circles, we have cross ratios, which is something completely different.) Are there any generalizations to or higher determinants? The last result, which states that , is also quite interesting. How to interpret this result? To summarize, this question seems to be tackling a very deep theory in geometry in an elementary way. I try to find more about this in complex methods textbooks, but I have not found any. Can anyone explain intuitively what's going on about the determinants , or tell me where to read more about the geometry of the unit circle? Just tell me where this question leads us to if we go any further.","A Q C a q c \dfrac {q-a}{c-a} (c-a)(q^*-a^*) = (c^*-a^*)(q-a)\, aa^* = cc^* = 1  q+ ac q^* = a+c
  A B C D aa^* =1 AC BD Q  (ac-bd)q^* = (a+c)-(b+d) \,,  b d B D  (ac-bd)  (q+q^*) =  (a-b)(1+cd) +(c-d)(1+ab)
 \,.  AB CD P p p p(1+ab)=a+b\, ac-bd \ne 0\,  p(q+q^*) =  2  \,.  ac-bd 2\times 2 3\times 3 p\Re (q)=1","['complex-analysis', 'geometry', 'complex-numbers']"
52,$L_f(z) = \frac 1 {2 \pi i}\int_{ \mathbb{T} } \frac{ \zeta+z}{ \zeta ( \zeta -z)} f( \zeta ) d\zeta$,,L_f(z) = \frac 1 {2 \pi i}\int_{ \mathbb{T} } \frac{ \zeta+z}{ \zeta ( \zeta -z)} f( \zeta ) d\zeta,"I'm trying to prove that for any harmonic function $u$ , we have : let $ \Omega \subset \mathbb{R}^2$ and $ \overline B(0,R) \subset \Omega $ $$ u \colon \Omega \to \mathbb R  $$ $$\forall z \in B(0,R) : u(z) = \Re \ \ \frac 1 {2 \pi i}\int_{  |\zeta| = R } \frac{ \zeta+z}{ \zeta ( \zeta -z)} u( \zeta ) d\zeta $$ I've tried a few things: I've shown that $$ \int_{|\zeta| = R } \frac{ \zeta+z}{ \zeta ( \zeta -z)} u( \zeta ) d\zeta  =   2 \int_{|\zeta| = R } \frac{ u( \zeta ) }{ ( \zeta -z)}  d\zeta  - \int_{|\zeta| = R } \frac{ u( \zeta ) }{ \zeta}  d\zeta $$ Which ( I'm not sure about this point... but in complex analysis I think it would have made sense ) is proportional to $$ 2 \operatorname{Res}_z(u) - \operatorname{Res}_0(u) $$ But I don't think I'm going anywhere ... So I started again and I studied the function : $$L_f(z) = \frac 1 {2 \pi i}\int_{ \mathbb{T} } \frac{ \zeta+z}{ \zeta ( \zeta -z)} f( \zeta ) d\zeta$$ I would still need to prove that this is holomorphic, but the derivative is given by : $$L'_f(z) = \frac 1 { \pi i}\int_{ \mathbb{T} } \frac{  f( \zeta ) }{ ( \zeta -z)^2    }d\zeta$$ I was very surprised because the RHS is exactly the expression of $ 2 f'(z) $ according to Cauchy Integral Formula. So I was believing that $L_f \equiv f$ . But in order to prove the equality, I would still need to prove that : $$- \int_{ \mathbb{T} } \frac{ f( \zeta ) }{ \zeta}  d\zeta  = \frac 1 { \pi i}\int_{ \mathbb{T} } \frac{  f( \zeta ) }{  \zeta -z    }d\zeta $$ So could you please tell me if my reasoning is true/ going somewhere, if I'm allowed to talk about residues for harmonic functions...  Or if you have another solution for the main problem, I would also be very grateful to read it :)","I'm trying to prove that for any harmonic function , we have : let and I've tried a few things: I've shown that Which ( I'm not sure about this point... but in complex analysis I think it would have made sense ) is proportional to But I don't think I'm going anywhere ... So I started again and I studied the function : I would still need to prove that this is holomorphic, but the derivative is given by : I was very surprised because the RHS is exactly the expression of according to Cauchy Integral Formula. So I was believing that . But in order to prove the equality, I would still need to prove that : So could you please tell me if my reasoning is true/ going somewhere, if I'm allowed to talk about residues for harmonic functions...  Or if you have another solution for the main problem, I would also be very grateful to read it :)","u  \Omega \subset \mathbb{R}^2  \overline B(0,R) \subset \Omega   u \colon \Omega \to \mathbb R   \forall z \in B(0,R) : u(z) = \Re \ \ \frac 1 {2 \pi i}\int_{
 |\zeta| = R } \frac{ \zeta+z}{ \zeta ( \zeta -z)} u( \zeta ) d\zeta   \int_{|\zeta| = R } \frac{ \zeta+z}{ \zeta ( \zeta -z)} u( \zeta ) d\zeta 
=  
2 \int_{|\zeta| = R } \frac{ u( \zeta ) }{ ( \zeta -z)}  d\zeta 
-
\int_{|\zeta| = R } \frac{ u( \zeta ) }{ \zeta}  d\zeta   2 \operatorname{Res}_z(u) - \operatorname{Res}_0(u)  L_f(z) = \frac 1 {2 \pi i}\int_{ \mathbb{T} } \frac{ \zeta+z}{ \zeta ( \zeta -z)} f( \zeta ) d\zeta L'_f(z) = \frac 1 { \pi i}\int_{ \mathbb{T} } \frac{  f( \zeta ) }{ ( \zeta -z)^2    }d\zeta  2 f'(z)  L_f \equiv f - \int_{ \mathbb{T} } \frac{ f( \zeta ) }{ \zeta}  d\zeta 
=
\frac 1 { \pi i}\int_{ \mathbb{T} } \frac{  f( \zeta ) }{  \zeta -z    }d\zeta ","['complex-analysis', 'harmonic-functions', 'cauchy-integral-formula']"
53,Complete elliptic integral $K(k) $ for $k>1$,Complete elliptic integral  for,K(k)  k>1,"I have always tried to work with elliptic integrals with modulus $k\in(0,1)$ to avoid the issues related to complex variables. In what follows I have tried to link the integral of modulus greater than $1$ with those of modulus less than $1$ . Let $k>1$ and consider $$K(k) =\int_{0}^{1}\frac{dx}{\sqrt {(1-x^2)(1-k^2x^2)}} $$ Splitting the range of integration into $[0,1/k]$ and $[1/k,1]$ we get $$K(k) =\frac{1}{k}K\left(\frac{1}{k}\right)-i\int_{1/k}^{1}\frac{dx}{\sqrt{(1-x^2)(k^2x^2-1)}}\tag{1}$$ and let $x=1/\sqrt{1-k'^2y^2}$ then we have $$dx=\frac{k'^2y\,dy}{(1-k'^2y^2)^{3/2}}$$ and $$1-x^2=-\frac{k'^2y^2}{1-k'^2y^2}$$ and $$k^2x^2-1=-\frac {k'^2(1-y^2)}{1-k'^2y^2}$$ and hence we arrive at the relation $$K(k) =\frac{1}{k}\left\{K\left(\frac{1}{k}\right)-ikK\left(k' \right) \right\} $$ Here $k'=i\sqrt{k^2-1}$ is purely imaginary and with some manipulation one can show that $$K(k') =\frac{1}{k}K\left(\frac {\sqrt{k^2-1}}{k}\right)$$ and thus we arrive at $$K(k) =\frac{1}{k}\left\{K\left(\frac {1}{k}\right)-iK\left(\frac{\sqrt{k^2-1}}{k}\right)\right\}$$ where $k>1$ . Replacing $k$ with $1/k$ we get the typical representation of the above formula as $$K(1/k)=k(K(k)-iK(k'))\tag{2}$$ where $0<k<1$ . My question is about the choice of $i$ in equation $(1)$ . We could equally well have used $-i$ instead of $i$ . How does one choose the correct sign of $i$ ? The DLMF reference (equation 19.7.2) gives the rule that the sign of $i$ is opposite to that of imaginary part of $k^2$ . But that does not help here as $k^2$ is real. The derivation above was more to confirm that my calculations are correct and one does not need to get bogged down into them.",I have always tried to work with elliptic integrals with modulus to avoid the issues related to complex variables. In what follows I have tried to link the integral of modulus greater than with those of modulus less than . Let and consider Splitting the range of integration into and we get and let then we have and and and hence we arrive at the relation Here is purely imaginary and with some manipulation one can show that and thus we arrive at where . Replacing with we get the typical representation of the above formula as where . My question is about the choice of in equation . We could equally well have used instead of . How does one choose the correct sign of ? The DLMF reference (equation 19.7.2) gives the rule that the sign of is opposite to that of imaginary part of . But that does not help here as is real. The derivation above was more to confirm that my calculations are correct and one does not need to get bogged down into them.,"k\in(0,1) 1 1 k>1 K(k) =\int_{0}^{1}\frac{dx}{\sqrt {(1-x^2)(1-k^2x^2)}}  [0,1/k] [1/k,1] K(k) =\frac{1}{k}K\left(\frac{1}{k}\right)-i\int_{1/k}^{1}\frac{dx}{\sqrt{(1-x^2)(k^2x^2-1)}}\tag{1} x=1/\sqrt{1-k'^2y^2} dx=\frac{k'^2y\,dy}{(1-k'^2y^2)^{3/2}} 1-x^2=-\frac{k'^2y^2}{1-k'^2y^2} k^2x^2-1=-\frac {k'^2(1-y^2)}{1-k'^2y^2} K(k) =\frac{1}{k}\left\{K\left(\frac{1}{k}\right)-ikK\left(k' \right) \right\}  k'=i\sqrt{k^2-1} K(k') =\frac{1}{k}K\left(\frac {\sqrt{k^2-1}}{k}\right) K(k) =\frac{1}{k}\left\{K\left(\frac {1}{k}\right)-iK\left(\frac{\sqrt{k^2-1}}{k}\right)\right\} k>1 k 1/k K(1/k)=k(K(k)-iK(k'))\tag{2} 0<k<1 i (1) -i i i i k^2 k^2","['complex-analysis', 'elliptic-integrals']"
54,About the proof that $\int_0^\infty\frac{dx}{x^2+6x+8} =\frac12\log2$ via residue formula,About the proof that  via residue formula,\int_0^\infty\frac{dx}{x^2+6x+8} =\frac12\log2,"In the text ""Functions of one Complex Variable"" by Robert E.Greene and Steven G.Krantz is my understanding of the proof to $\text{Proposition (1.1)}$ correct ? $\text{Proposition (1.1)}$ $$\int_{0}^{ \infty} \frac{dx}{x^{2} + 6x + 8} = \frac{1}{2} \log(2) \, \, $$ $\text{Proof}$ For the sake and using Complex-Analytic techniques the author considers the following integral. $$\oint_{\eta_{R}} \frac{\log(z)}{z^{2} + 6z + 8}dz$$ As an exercise, it was left to us by the author that $\log(r)$ is a well defined holomorphic function. To address a trivial proof, one can define $\log(z)$ on $U \equiv \mathbb{C}  \setminus  \{x : x \geq 0  \}$ by $\{ \log(re^{i \theta}) = (\log(r)) + i \theta$  when $0 < \theta < 2 \pi, r > 0 \}$. Before proceeding any further, take note that $$u(r, \theta)=\log(r) \ \ \ \text{ and } \ \ \ v(r, \theta) =\theta.$$ Now it's easy to note that $$  \big(  \partial_{r}u \big) =\frac{1}{r}= \frac{1}{r} \cdot 1 = \frac{1}{r} \cdot \left(  \partial_{\theta} v\right)\ \ \ \ \ \text{and } \ \ \ \  \big(  \partial_{r}u \big) = 0 = \frac{-1}{r}\cdot 0 = \frac{-1}{r} \cdot \big( \partial_{\theta} u \big) $$ So indeed, $log(z)$ is analytic. But before proceeding further he defines $\eta_{R}$ such that, $$\, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \eta_{R}^{1}(t)  =  t + i/\sqrt{2R},  \, \, \, \,   1/\sqrt{2R} \leq t \leq R,$$ $$\eta_{R}^{2}(t)= Re^{it}, \, \, \, \,  \theta_{0} \leq t \leq 2 \pi - \theta_{0},$$ where $\theta_{0} = \theta_{0}(R) = \sin^{-1}(1/(R \sqrt{2R}))$ $$\, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \eta_{R}^{3}(t)  =  R -t -i/\sqrt{2R},  \, \, \, \, 0 \leq t \leq R-1/\sqrt{2R},$$ $$\eta_{R}^{4}(t)  =  e^{it}/\sqrt{R}, \, \, \, \, \,  \, \, \, \, \, \, \, \, \, \, \, \, \, \pi/4 \leq t \leq 7 \pi /4.$$ $\text{Remark}$ For those who don't have the book on hand a picture of the Contour employed can be found in $\text{Figure (1.1)}$ $\text{Figure (1.1)}$ $\, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, $ The author now says that: $(*)$ $$ \bigg| \lim_{R \rightarrow \infty}\oint_{\eta_{R}^{4}} \frac{\log(z)}{z^{2} + 6z + 8}dz\bigg| \rightarrow 0$$ , and that $(**)$ $$ \bigg| \lim_{R \rightarrow \infty}\oint_{\eta_{R}^{2}} \frac{\log(z)}{z^{2} + 6z + 8}dz\bigg| \rightarrow 0.$$ A particular device that the author cites to justify convergence over $\eta_{R}^{2}$ and $\eta_{R}^{4}$ consider on faith $$\bigg(\log \bigg( \frac{x + i \sqrt{2R}}{(x-i/\sqrt{2R}} \bigg) \bigg)\rightarrow -2 \pi i.$$ We will come back to this after dealing with the integrals over $\eta_{R}^{2}$ and $\eta_{R}^{4}$. One should note that $$ \sum_{\psi}^{4} \bigg(\oint_{\eta_{R}^{\psi}} \frac{\log(z)}{z^{2} + 6z + 8}dz \bigg).$$ Now over $\eta_{R}^{2}$ we have, \begin{align*} \bigg| \oint_{\eta_{R}^{2}}\frac{\log(z)}{z^{2} + 6z + 8}dz\bigg|& = \bigg| \int_{-R}^{+Ri} \frac{\log(Re^{it})}{(Re^{it})^{2} + 6(Re^{it}) + 8} iRe^{i \theta} d \theta\bigg|\\&=  \int_{-R}^{+Ri} \bigg|\frac{\log(Re^{it})}{(Re^{it})^{2} + 6(Re^{it}) + 8} \bigg| \big| iRe^{i \theta} d \theta \big|\\&= \int_{-R}^{+Ri} \frac{\bigg|\log(Re^{it}) \bigg|}{\bigg|(Re^{it})^{2} + 6(Re^{it}) + 8 \bigg|}  \bigg|iRe^{i \theta} \bigg| \bigg|d \theta  \bigg| \\& = \int_{\theta_{0}}^{2 \pi - \theta_{0}} \frac{\bigg|\log(Re^{it}) \bigg|}{\bigg|(Re^{it})^{2} + 6(Re^{it}) + 8 \bigg|}  \bigg|iRe^{i \theta} \bigg| \bigg|d \theta  \bigg| \end{align*} Now we can establish a precise estimate over $\eta_{R}^{2}$, $$\bigg| \oint_{\eta_{R}^{2}} \frac{\log(z)}{z^{2} + 6z + 8}dz\bigg| \leq  \frac{\ln(R) + \pi }{R^{2} - 13} \pi r \, \, \text{as} \, \, \, R \rightarrow \infty $$ There by proving $(*)$. A similar process can be done for $\eta_{R}^{4}$, hence: \begin{align*} \bigg| \oint_{\eta_{R}^{4}} \frac{\log(e^{it}/\sqrt{R})}{(e^{it}/ \sqrt{R})^{2} + (e^{it} / \sqrt{R})(6) +8}  dz\bigg|& =  \oint_{\eta_{R}^{4}} \bigg| \frac{\log(e^{it}/\sqrt{R})}{(e^{it}/ \sqrt{R})^{2} + (e^{it} / \sqrt{R})(6) +8}  iRe^{i \theta} d \theta\bigg|\\&= \oint_{\eta_{R}^{4}}  \frac{\bigg|\log(e^{it}/\sqrt{R}) \bigg|}{\bigg|(e^{it}/ \sqrt{R})^{2} + (e^{it} / \sqrt{R})(6) +8 \bigg|}  iRe^{i \theta} d \theta \\&= \oint_{\eta_{R}^{4}}  \frac{\bigg| \log(e^{it})- \frac{1}{2}\log(R^{}) \bigg|}{ \bigg|\frac{e^{2it}}{\sqrt{2R}} + (e^{it} / \sqrt{R})(6) +8 \bigg|} \bigg|  iRe^{i \theta} d \theta \bigg|\\& =\oint_{\frac{\pi}{4}}^{\frac{7 \pi}{4}}  \frac{\bigg| it\log(e^{})- \frac{1}{2}\log(R^{}) \bigg|}{ \bigg|\frac{e^{2it}}{\sqrt{2R}} + (e^{it} / \sqrt{R})(6) +8 \bigg|} \bigg|  iRe^{i \theta}\bigg| d \theta \bigg|.  \end{align*} Now finally a precise estimate for $\eta_{R}^{4}$ $$\bigg| \oint_{\eta_{R}^{4}} \frac{\log(e^{it}/\sqrt{R})}{(e^{it}/ \sqrt{R})^{2} + (e^{it} / \sqrt{R})(6) +8}  dz\bigg|  \leq  \text{length}(\eta_{R}^{4})  \cdot \sup_{\eta_{R}^{4}}(g) \leq \pi R \frac{O(\log(R))}{\sqrt{R}} \, \text{as} \, R \rightarrow \infty  $$ Thus proving $(**)$ After achieving our preliminary results now we have that, $(***)$ \begin{align*}  \bigg( \oint_{\eta_{R}^{1}} g(z) dz + \oint_{\eta_{R}^{3}} g(z) dz \bigg)& = \lim_{R \rightarrow \infty }  \bigg( \oint_{\mu_{R}^{1} } \frac{\log(x+  \sqrt{2R})}{(\log(x+  \sqrt{2R}))^{2} + 6(\log(x+  \sqrt{2R})) + 8} - \oint_{\mu_{R}^{3} } \frac{\log(x - i/ \sqrt{2R})}{(\log(x -i /\sqrt{2R}))^{2} + 6(\log(x - i  /\sqrt{2R})) + 8}   \bigg) \\&= -2 \pi i \lim_{R \rightarrow \infty}\int_{0}^{R} \frac{dt}{t^{2} + 6t + 8} \\&  \end{align*} Using the Residue Theorem it's easy to observe that: $(****)$ $$ \oint_{\eta_{R}} g(z) dz  = 2 \pi i (\operatorname{Res_{g}}(-2) \cdot + Res_{g}(-4) \cdot 1) = - \pi i \log(2)$$ Finally putting $(****)$, $(***)$, $(**)$ and $(*)$ together yields that the, $$\lim_{R \rightarrow \infty}\int_{0}^{R} \frac{dt}{t^{2} + 6t + 8} = \frac{1}{2}\log(2).$$","In the text ""Functions of one Complex Variable"" by Robert E.Greene and Steven G.Krantz is my understanding of the proof to $\text{Proposition (1.1)}$ correct ? $\text{Proposition (1.1)}$ $$\int_{0}^{ \infty} \frac{dx}{x^{2} + 6x + 8} = \frac{1}{2} \log(2) \, \, $$ $\text{Proof}$ For the sake and using Complex-Analytic techniques the author considers the following integral. $$\oint_{\eta_{R}} \frac{\log(z)}{z^{2} + 6z + 8}dz$$ As an exercise, it was left to us by the author that $\log(r)$ is a well defined holomorphic function. To address a trivial proof, one can define $\log(z)$ on $U \equiv \mathbb{C}  \setminus  \{x : x \geq 0  \}$ by $\{ \log(re^{i \theta}) = (\log(r)) + i \theta$  when $0 < \theta < 2 \pi, r > 0 \}$. Before proceeding any further, take note that $$u(r, \theta)=\log(r) \ \ \ \text{ and } \ \ \ v(r, \theta) =\theta.$$ Now it's easy to note that $$  \big(  \partial_{r}u \big) =\frac{1}{r}= \frac{1}{r} \cdot 1 = \frac{1}{r} \cdot \left(  \partial_{\theta} v\right)\ \ \ \ \ \text{and } \ \ \ \  \big(  \partial_{r}u \big) = 0 = \frac{-1}{r}\cdot 0 = \frac{-1}{r} \cdot \big( \partial_{\theta} u \big) $$ So indeed, $log(z)$ is analytic. But before proceeding further he defines $\eta_{R}$ such that, $$\, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \eta_{R}^{1}(t)  =  t + i/\sqrt{2R},  \, \, \, \,   1/\sqrt{2R} \leq t \leq R,$$ $$\eta_{R}^{2}(t)= Re^{it}, \, \, \, \,  \theta_{0} \leq t \leq 2 \pi - \theta_{0},$$ where $\theta_{0} = \theta_{0}(R) = \sin^{-1}(1/(R \sqrt{2R}))$ $$\, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \eta_{R}^{3}(t)  =  R -t -i/\sqrt{2R},  \, \, \, \, 0 \leq t \leq R-1/\sqrt{2R},$$ $$\eta_{R}^{4}(t)  =  e^{it}/\sqrt{R}, \, \, \, \, \,  \, \, \, \, \, \, \, \, \, \, \, \, \, \pi/4 \leq t \leq 7 \pi /4.$$ $\text{Remark}$ For those who don't have the book on hand a picture of the Contour employed can be found in $\text{Figure (1.1)}$ $\text{Figure (1.1)}$ $\, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, $ The author now says that: $(*)$ $$ \bigg| \lim_{R \rightarrow \infty}\oint_{\eta_{R}^{4}} \frac{\log(z)}{z^{2} + 6z + 8}dz\bigg| \rightarrow 0$$ , and that $(**)$ $$ \bigg| \lim_{R \rightarrow \infty}\oint_{\eta_{R}^{2}} \frac{\log(z)}{z^{2} + 6z + 8}dz\bigg| \rightarrow 0.$$ A particular device that the author cites to justify convergence over $\eta_{R}^{2}$ and $\eta_{R}^{4}$ consider on faith $$\bigg(\log \bigg( \frac{x + i \sqrt{2R}}{(x-i/\sqrt{2R}} \bigg) \bigg)\rightarrow -2 \pi i.$$ We will come back to this after dealing with the integrals over $\eta_{R}^{2}$ and $\eta_{R}^{4}$. One should note that $$ \sum_{\psi}^{4} \bigg(\oint_{\eta_{R}^{\psi}} \frac{\log(z)}{z^{2} + 6z + 8}dz \bigg).$$ Now over $\eta_{R}^{2}$ we have, \begin{align*} \bigg| \oint_{\eta_{R}^{2}}\frac{\log(z)}{z^{2} + 6z + 8}dz\bigg|& = \bigg| \int_{-R}^{+Ri} \frac{\log(Re^{it})}{(Re^{it})^{2} + 6(Re^{it}) + 8} iRe^{i \theta} d \theta\bigg|\\&=  \int_{-R}^{+Ri} \bigg|\frac{\log(Re^{it})}{(Re^{it})^{2} + 6(Re^{it}) + 8} \bigg| \big| iRe^{i \theta} d \theta \big|\\&= \int_{-R}^{+Ri} \frac{\bigg|\log(Re^{it}) \bigg|}{\bigg|(Re^{it})^{2} + 6(Re^{it}) + 8 \bigg|}  \bigg|iRe^{i \theta} \bigg| \bigg|d \theta  \bigg| \\& = \int_{\theta_{0}}^{2 \pi - \theta_{0}} \frac{\bigg|\log(Re^{it}) \bigg|}{\bigg|(Re^{it})^{2} + 6(Re^{it}) + 8 \bigg|}  \bigg|iRe^{i \theta} \bigg| \bigg|d \theta  \bigg| \end{align*} Now we can establish a precise estimate over $\eta_{R}^{2}$, $$\bigg| \oint_{\eta_{R}^{2}} \frac{\log(z)}{z^{2} + 6z + 8}dz\bigg| \leq  \frac{\ln(R) + \pi }{R^{2} - 13} \pi r \, \, \text{as} \, \, \, R \rightarrow \infty $$ There by proving $(*)$. A similar process can be done for $\eta_{R}^{4}$, hence: \begin{align*} \bigg| \oint_{\eta_{R}^{4}} \frac{\log(e^{it}/\sqrt{R})}{(e^{it}/ \sqrt{R})^{2} + (e^{it} / \sqrt{R})(6) +8}  dz\bigg|& =  \oint_{\eta_{R}^{4}} \bigg| \frac{\log(e^{it}/\sqrt{R})}{(e^{it}/ \sqrt{R})^{2} + (e^{it} / \sqrt{R})(6) +8}  iRe^{i \theta} d \theta\bigg|\\&= \oint_{\eta_{R}^{4}}  \frac{\bigg|\log(e^{it}/\sqrt{R}) \bigg|}{\bigg|(e^{it}/ \sqrt{R})^{2} + (e^{it} / \sqrt{R})(6) +8 \bigg|}  iRe^{i \theta} d \theta \\&= \oint_{\eta_{R}^{4}}  \frac{\bigg| \log(e^{it})- \frac{1}{2}\log(R^{}) \bigg|}{ \bigg|\frac{e^{2it}}{\sqrt{2R}} + (e^{it} / \sqrt{R})(6) +8 \bigg|} \bigg|  iRe^{i \theta} d \theta \bigg|\\& =\oint_{\frac{\pi}{4}}^{\frac{7 \pi}{4}}  \frac{\bigg| it\log(e^{})- \frac{1}{2}\log(R^{}) \bigg|}{ \bigg|\frac{e^{2it}}{\sqrt{2R}} + (e^{it} / \sqrt{R})(6) +8 \bigg|} \bigg|  iRe^{i \theta}\bigg| d \theta \bigg|.  \end{align*} Now finally a precise estimate for $\eta_{R}^{4}$ $$\bigg| \oint_{\eta_{R}^{4}} \frac{\log(e^{it}/\sqrt{R})}{(e^{it}/ \sqrt{R})^{2} + (e^{it} / \sqrt{R})(6) +8}  dz\bigg|  \leq  \text{length}(\eta_{R}^{4})  \cdot \sup_{\eta_{R}^{4}}(g) \leq \pi R \frac{O(\log(R))}{\sqrt{R}} \, \text{as} \, R \rightarrow \infty  $$ Thus proving $(**)$ After achieving our preliminary results now we have that, $(***)$ \begin{align*}  \bigg( \oint_{\eta_{R}^{1}} g(z) dz + \oint_{\eta_{R}^{3}} g(z) dz \bigg)& = \lim_{R \rightarrow \infty }  \bigg( \oint_{\mu_{R}^{1} } \frac{\log(x+  \sqrt{2R})}{(\log(x+  \sqrt{2R}))^{2} + 6(\log(x+  \sqrt{2R})) + 8} - \oint_{\mu_{R}^{3} } \frac{\log(x - i/ \sqrt{2R})}{(\log(x -i /\sqrt{2R}))^{2} + 6(\log(x - i  /\sqrt{2R})) + 8}   \bigg) \\&= -2 \pi i \lim_{R \rightarrow \infty}\int_{0}^{R} \frac{dt}{t^{2} + 6t + 8} \\&  \end{align*} Using the Residue Theorem it's easy to observe that: $(****)$ $$ \oint_{\eta_{R}} g(z) dz  = 2 \pi i (\operatorname{Res_{g}}(-2) \cdot + Res_{g}(-4) \cdot 1) = - \pi i \log(2)$$ Finally putting $(****)$, $(***)$, $(**)$ and $(*)$ together yields that the, $$\lim_{R \rightarrow \infty}\int_{0}^{R} \frac{dt}{t^{2} + 6t + 8} = \frac{1}{2}\log(2).$$",,"['complex-analysis', 'proof-explanation', 'contour-integration']"
55,In which sense are the Cauchy-Riemann equations elliptic,In which sense are the Cauchy-Riemann equations elliptic,,"I often read that the rigidity and smoothness properties of holomorphic functions can be explained by the fact that the Cauchy-Riemann equations are elliptic. In which sense is that true? Obviously they are not elliptic in the sense of the Wikipedia definition or that of Lecture notes of Ambrosio, both of which are restricted to second order PDE. There is also a definition of hypoellipticity out there that is simply based on smoothness of solutions. That one would hardly be useful to make sense of how ellipticity explains smoothness properties of holomorphic functions. It remains the definition of elliptic equations as those with definite principal symbol. However, I don't believe the CR equations can be reasonably be classified as elliptic under this definition. Of course we can say that the symbol of the Cauchy-Riemann operator $\partial_x+i\partial_y$ is $x+iy$ for $x,y\in \mathbb{R}$. If that's it, I already have my answer, because the last expression is definite. However, I feel like this would be cheating. Since the differentials $\partial_x f$ and $\partial_y f$ occuring in the Cauchy-Riemann equations are elements of $\mathbb{C}$ the variables in the symbol should probably be too, and in that case $x+iy$ can be zero even for nonzero $x$ and $y$.  Is there any insight to gain in using the other form of the symbol and deriving properties of holomorphic functions from there?","I often read that the rigidity and smoothness properties of holomorphic functions can be explained by the fact that the Cauchy-Riemann equations are elliptic. In which sense is that true? Obviously they are not elliptic in the sense of the Wikipedia definition or that of Lecture notes of Ambrosio, both of which are restricted to second order PDE. There is also a definition of hypoellipticity out there that is simply based on smoothness of solutions. That one would hardly be useful to make sense of how ellipticity explains smoothness properties of holomorphic functions. It remains the definition of elliptic equations as those with definite principal symbol. However, I don't believe the CR equations can be reasonably be classified as elliptic under this definition. Of course we can say that the symbol of the Cauchy-Riemann operator $\partial_x+i\partial_y$ is $x+iy$ for $x,y\in \mathbb{R}$. If that's it, I already have my answer, because the last expression is definite. However, I feel like this would be cheating. Since the differentials $\partial_x f$ and $\partial_y f$ occuring in the Cauchy-Riemann equations are elements of $\mathbb{C}$ the variables in the symbol should probably be too, and in that case $x+iy$ can be zero even for nonzero $x$ and $y$.  Is there any insight to gain in using the other form of the symbol and deriving properties of holomorphic functions from there?",,"['complex-analysis', 'elliptic-equations']"
56,Is it true that $\lvert\sin z\rvert\le 1$ implies that $z\in\mathbb R$?,Is it true that  implies that ?,\lvert\sin z\rvert\le 1 z\in\mathbb R,"My book says Prove that if $z\in\mathbb C$ and $\lvert\sin z\rvert\le 1$ , then $z\in\mathbb R$ . But I think this can't be true as $$\lvert\sin z\rvert^2=\sin^2x+\sinh^2y$$ and so if $\lvert\sin z\rvert\le 1$ , then, $$\sinh^2y\le1-\sin^2x=\cos^2x.$$ Clearly we can find some $y\neq 0$ , such that $\sinh^2y\le\cos^2x$ for some $x$ . Thus I want to know if something went wrong in my explanations?","My book says Prove that if and , then . But I think this can't be true as and so if , then, Clearly we can find some , such that for some . Thus I want to know if something went wrong in my explanations?",z\in\mathbb C \lvert\sin z\rvert\le 1 z\in\mathbb R \lvert\sin z\rvert^2=\sin^2x+\sinh^2y \lvert\sin z\rvert\le 1 \sinh^2y\le1-\sin^2x=\cos^2x. y\neq 0 \sinh^2y\le\cos^2x x,['complex-analysis']
57,"Prove that if all of the roots of a polynomial $P(z)$ are real, then for any $b$ the roots of the polynomial $R(z)=P(z+ib)+P(z-ib)$ are also real.","Prove that if all of the roots of a polynomial  are real, then for any  the roots of the polynomial  are also real.",P(z) b R(z)=P(z+ib)+P(z-ib),"Prove that if all of the roots of a polynomial $P(z)$ are real, then for any $b$ the roots of the polynomial $R(z)=P(z+ib)+P(z-ib)$ are also real. I'm just trying take the polynomial $$P(z)=a_0+a_1z+\dotsb+a_nz^n$$ and look at $$P(z+bi)=a_0+a_1(z+bi)+\dotsb+a_n(z+bi)^n$$ and $$P(z-bi)=a_0+a_1(z-bi)+\dotsb+a_n(z-bi)^n$$ and then considering $$P(z+ib)+P(z-ib)=2a_0+2a_1z+2a_2(z^2-b^2)+\dotsb$$ we can see that every term hasn't the imaginary part, i.e all of $i$ are missing and we get new polynomial $G$ which have coefficients as in a polynomial $P(z)$ multiplying on $b$ . But how to explain that all of the roots of $R(z)$ are real?","Prove that if all of the roots of a polynomial are real, then for any the roots of the polynomial are also real. I'm just trying take the polynomial and look at and and then considering we can see that every term hasn't the imaginary part, i.e all of are missing and we get new polynomial which have coefficients as in a polynomial multiplying on . But how to explain that all of the roots of are real?",P(z) b R(z)=P(z+ib)+P(z-ib) P(z)=a_0+a_1z+\dotsb+a_nz^n P(z+bi)=a_0+a_1(z+bi)+\dotsb+a_n(z+bi)^n P(z-bi)=a_0+a_1(z-bi)+\dotsb+a_n(z-bi)^n P(z+ib)+P(z-ib)=2a_0+2a_1z+2a_2(z^2-b^2)+\dotsb i G P(z) b R(z),"['complex-analysis', 'polynomials', 'roots']"
58,Cauchy's Integral Formula and Delta Functions,Cauchy's Integral Formula and Delta Functions,,"As we know from complex analysis, Cauchy's integral formula states: $f(z_o)=\frac{1}{2\pi i}\int_\gamma{\frac{f(z)}{z-z_o}dz}$ for a closed contour $\gamma$. However there is also the result from other areas of maths that states: $f(x_o)=\int_R{f(x)\delta(x-x_o)dx}$ for some region $R$ Given the similarity in the results, is there any significance in comparing $\delta(x-x_o)$ to $\frac{1}{2 \pi i (x-x_o)}$ since basically integrating a function over them always gives the function's value at $x_o$ (Apologies in advance if this question may seem silly but I haven't found any satisfactory answers in my search so I thought I'd ask)","As we know from complex analysis, Cauchy's integral formula states: $f(z_o)=\frac{1}{2\pi i}\int_\gamma{\frac{f(z)}{z-z_o}dz}$ for a closed contour $\gamma$. However there is also the result from other areas of maths that states: $f(x_o)=\int_R{f(x)\delta(x-x_o)dx}$ for some region $R$ Given the similarity in the results, is there any significance in comparing $\delta(x-x_o)$ to $\frac{1}{2 \pi i (x-x_o)}$ since basically integrating a function over them always gives the function's value at $x_o$ (Apologies in advance if this question may seem silly but I haven't found any satisfactory answers in my search so I thought I'd ask)",,"['complex-analysis', 'contour-integration', 'dirac-delta', 'cauchy-integral-formula']"
59,"Solve $\vert i+2i^2+3i^3+...+ni^n\vert$=$18\sqrt 2$ for $n$, where $i^2=-1$","Solve = for , where",\vert i+2i^2+3i^3+...+ni^n\vert 18\sqrt 2 n i^2=-1,"Suppose $n\in \mathbb N$ such that $\vert  i+2i^2+3i^3+...+ni^n\vert$=$18\sqrt 2$.Where $i$ is a square root of   $-1$.Then what is the value of $n$? Solution: Let $S_n=i+2i^2+3i^3+...+ni^n\tag{1}$ Then  $iS_n=i^2+2i^3+3i^4+...ni^{n+1}\tag{2}$ Subtracting $(2)$ from $(1)$, we get $$S_n(1-i)=(i+i^2+i^3+...+i^n)-ni^{n+1}$$ hence $$S_n=\frac{i(1-i^n)}{(1-i)^2}-\frac{ni^{n+1}}{1-i}=\frac{i(1-i^n)}{-2i}-\frac{ni^{n+1}}{1-i}$$ This is where I get stuck.","Suppose $n\in \mathbb N$ such that $\vert  i+2i^2+3i^3+...+ni^n\vert$=$18\sqrt 2$.Where $i$ is a square root of   $-1$.Then what is the value of $n$? Solution: Let $S_n=i+2i^2+3i^3+...+ni^n\tag{1}$ Then  $iS_n=i^2+2i^3+3i^4+...ni^{n+1}\tag{2}$ Subtracting $(2)$ from $(1)$, we get $$S_n(1-i)=(i+i^2+i^3+...+i^n)-ni^{n+1}$$ hence $$S_n=\frac{i(1-i^n)}{(1-i)^2}-\frac{ni^{n+1}}{1-i}=\frac{i(1-i^n)}{-2i}-\frac{ni^{n+1}}{1-i}$$ This is where I get stuck.",,"['complex-analysis', 'complex-numbers', 'summation']"
60,$\log|z|$ has no harmonic conjugate in $\Bbb C\setminus\{0\}$ – different proof,has no harmonic conjugate in  – different proof,\log|z| \Bbb C\setminus\{0\},"There are a number of proofs in the Internet but I am specifically interested in the claim made by John B. Conway on page 43 of his Functions of One Complex Variable I (2nd edition). Suppose $G$ is a region in the plane and $u:G\to\Bbb R$ is harmonic, if there exists a harmonic function $v:G\to\Bbb R$ such that $f=u+iv$ is analytic in $G$ then $v$ is a harmonic conjugate $\ldots u(z) = \log |z|$ of a harmonic function on the region $G = \mathbb{C} - \{ 0 \}$ has no harmonic conjugate, indeed, if it did then it would be possible to define an analytic branch of the logarithm on $G$, and this cannot be done. The definition of an analytic function and analytic branch as given in text: Def 1 A function $f: G \rightarrow \mathbb{C}$ is analytic if it is continuously differentiable on $G$, where $G$ is an open subset of $\mathbb{C}$. Def 2 If $G$ is an open conncted set such that in $\mathbb{C}$ and $f: G \rightarrow \mathbb{C}$ is a continuous function such that $z = \exp f(z)$ for all $z \in G$ then $f$ is an analytic branch of logarithm . I could only prove the latter part of the statement that it is not possible to define an analytic branch of the logarithm on $G$, which I provide below in (1), hopefully it is right. The part which I do not understand is how it is possible to define an analytic branch of the logarithm on $G$ . What am I missing? Thanks! My proof for (1): If $f$ is a branch of logarithm we require that for all $z \in G$,    $$ e^{f(z)} =e^{a+ib} =  e^{a(z)} e^{ib(z)} = z = |z|e^{i \theta}, $$   where $a(z), b(z) \in \mathbb{R}$ and $\theta = \arg z$. Now $e^{a(z)} = |z| $ and $e^{ib(z)} = e^{i \theta}$. So we must have $a(z) = \log |z|$, and $b(z)= \theta + 2 \pi k(z) \in (  - \pi, \pi ] $  for some $k(z) \in \mathbb{N}$. So we obtain that    $$ f(z) = \log |z| +i [ \theta + 2 \pi k(z) ] $$    where $k: G \rightarrow \mathbb{Z}$. But since $f$ is continuous (we assume $f$ is a branch) and that $G$ is connected, $k(G)$ is a connected set. Hence, $k$ is constant function.    We now show that there exists a sequence, $z_n \rightarrow z$ such that $f(z_n) \not \rightarrow f(z)$ so $f$ is not continuous. Consider $z = e^{i \pi} $, and the sequence of points, $z_n = e^{ i  (-1)^n  (\pi - \frac{1}{n})}$. Then    \begin{align*} |f(z) - f(z_n)| & = | \log 1 - \log z_n + i ( \theta - \theta_n)| \\  &=  | \log \bigg| \cos ( \pi - \frac{1}{n}) \bigg| + i \bigg( \pi - (-1)^n ( \pi - \frac{1}{n} )\bigg) | \\  &\ge | \pi - (-1)^n (\pi - \frac{1}{n} ) | \\ \end{align*}   which does not converge.","There are a number of proofs in the Internet but I am specifically interested in the claim made by John B. Conway on page 43 of his Functions of One Complex Variable I (2nd edition). Suppose $G$ is a region in the plane and $u:G\to\Bbb R$ is harmonic, if there exists a harmonic function $v:G\to\Bbb R$ such that $f=u+iv$ is analytic in $G$ then $v$ is a harmonic conjugate $\ldots u(z) = \log |z|$ of a harmonic function on the region $G = \mathbb{C} - \{ 0 \}$ has no harmonic conjugate, indeed, if it did then it would be possible to define an analytic branch of the logarithm on $G$, and this cannot be done. The definition of an analytic function and analytic branch as given in text: Def 1 A function $f: G \rightarrow \mathbb{C}$ is analytic if it is continuously differentiable on $G$, where $G$ is an open subset of $\mathbb{C}$. Def 2 If $G$ is an open conncted set such that in $\mathbb{C}$ and $f: G \rightarrow \mathbb{C}$ is a continuous function such that $z = \exp f(z)$ for all $z \in G$ then $f$ is an analytic branch of logarithm . I could only prove the latter part of the statement that it is not possible to define an analytic branch of the logarithm on $G$, which I provide below in (1), hopefully it is right. The part which I do not understand is how it is possible to define an analytic branch of the logarithm on $G$ . What am I missing? Thanks! My proof for (1): If $f$ is a branch of logarithm we require that for all $z \in G$,    $$ e^{f(z)} =e^{a+ib} =  e^{a(z)} e^{ib(z)} = z = |z|e^{i \theta}, $$   where $a(z), b(z) \in \mathbb{R}$ and $\theta = \arg z$. Now $e^{a(z)} = |z| $ and $e^{ib(z)} = e^{i \theta}$. So we must have $a(z) = \log |z|$, and $b(z)= \theta + 2 \pi k(z) \in (  - \pi, \pi ] $  for some $k(z) \in \mathbb{N}$. So we obtain that    $$ f(z) = \log |z| +i [ \theta + 2 \pi k(z) ] $$    where $k: G \rightarrow \mathbb{Z}$. But since $f$ is continuous (we assume $f$ is a branch) and that $G$ is connected, $k(G)$ is a connected set. Hence, $k$ is constant function.    We now show that there exists a sequence, $z_n \rightarrow z$ such that $f(z_n) \not \rightarrow f(z)$ so $f$ is not continuous. Consider $z = e^{i \pi} $, and the sequence of points, $z_n = e^{ i  (-1)^n  (\pi - \frac{1}{n})}$. Then    \begin{align*} |f(z) - f(z_n)| & = | \log 1 - \log z_n + i ( \theta - \theta_n)| \\  &=  | \log \bigg| \cos ( \pi - \frac{1}{n}) \bigg| + i \bigg( \pi - (-1)^n ( \pi - \frac{1}{n} )\bigg) | \\  &\ge | \pi - (-1)^n (\pi - \frac{1}{n} ) | \\ \end{align*}   which does not converge.",,"['complex-analysis', 'proof-verification', 'proof-explanation', 'harmonic-functions', 'analytic-functions']"
61,Do standard gradient descent methods work on complex variables,Do standard gradient descent methods work on complex variables,,"I am currently whishing to optimize a function numerically $f(z)$ where $z \in \mathbb{C} $ ($f(z) \in \mathbb{R}$) . I am doing this via numerical packages (specifically scipy in python) and I have noticed that all the optimization methods in this package are tailored to only functions of domain in $\mathbb{R}$. I Played around for a bit with the complex optimization problem and at first sight it just seems like numerically optimizing a function of two variables since $z = (x,y) \equiv z = x + iy$ . I am aware that the definition of an analytic function is more rigorous than that of a real differentiable function in the sense that it should be differential from all directions $\Delta z = (\Delta x, \Delta y)$ so things become a bit more complicated. Given the situation above how can one approach the task of numerical optimization on a function of complex domain? Are there any standard routines for this ?","I am currently whishing to optimize a function numerically $f(z)$ where $z \in \mathbb{C} $ ($f(z) \in \mathbb{R}$) . I am doing this via numerical packages (specifically scipy in python) and I have noticed that all the optimization methods in this package are tailored to only functions of domain in $\mathbb{R}$. I Played around for a bit with the complex optimization problem and at first sight it just seems like numerically optimizing a function of two variables since $z = (x,y) \equiv z = x + iy$ . I am aware that the definition of an analytic function is more rigorous than that of a real differentiable function in the sense that it should be differential from all directions $\Delta z = (\Delta x, \Delta y)$ so things become a bit more complicated. Given the situation above how can one approach the task of numerical optimization on a function of complex domain? Are there any standard routines for this ?",,"['complex-analysis', 'optimization', 'numerical-optimization']"
62,Minimizing the area of a square enclosing a given set of points,Minimizing the area of a square enclosing a given set of points,,"I am learning about the science of algorithms and I'm studying some problems with their optimum algorithm. The problem I describe below is one of them. I need a lower and an upper bound of its runtime complexity. What is its optimum algorithm? I don't need any implementation. Problem: Given a set of coordinates in a $2$-dimensional plane, how do we find   the area of a minimum square which includes all the points? The points   can exist on the border also. And the square's orientation doesn't have   to be parallel to the Cartesian axes. For example, Consider the points $(-1,1)$, $(1,3)$, $(0,2)$, $(-2,2)$. The minimum square height to cover these points is $2\sqrt{2}$. Hence the area is $8$. I hope that the explanation is clear. Thank you in advance!","I am learning about the science of algorithms and I'm studying some problems with their optimum algorithm. The problem I describe below is one of them. I need a lower and an upper bound of its runtime complexity. What is its optimum algorithm? I don't need any implementation. Problem: Given a set of coordinates in a $2$-dimensional plane, how do we find   the area of a minimum square which includes all the points? The points   can exist on the border also. And the square's orientation doesn't have   to be parallel to the Cartesian axes. For example, Consider the points $(-1,1)$, $(1,3)$, $(0,2)$, $(-2,2)$. The minimum square height to cover these points is $2\sqrt{2}$. Hence the area is $8$. I hope that the explanation is clear. Thank you in advance!",,"['complex-analysis', 'geometry', 'optimization', 'algorithms', 'computational-complexity']"
63,Inner Functions in Annuli: Not Likely!,Inner Functions in Annuli: Not Likely!,,"The other day someone reminded me of something I'd thought about some years ago. As back then it took me a little while to see why there was any problem; this time I got much farther on a solution than I did back then. This is supposed to be a question. Question: Is the stuff below (especially the result at the very end) actually true? Question: Reference? Background If $\Omega\subset\Bbb C$ is open the notation $H^\infty(\Omega)$ denotes the bounded holomorphic functions in $\Omega$. If $\Bbb D$ is the unit disk it's very well known that $f\in H^\infty(\Bbb D)$ has radial limits, in fact ""non-tangential"" limits, at almost every boundary point. A function $f\in H^\infty(\Bbb D)$ is an inner function if the boundary values have modulus $1$ almost everywhere. If $f\in H^\infty(\Bbb D)$ and the zeroes of $f$ are $(a_j)$ then $$\sum(1-|a_j|)<\infty.$$Conversely, this condition implies that $(a_j)$ is the zero set of some inner function (a Blaschke product). The Problem Now fix $R\in(0,1)$ and let $A$ be the annulus $R<|z|<1$. Define ""inner function"" in the obvious way. What are the zero sets of the inner functions in $A$? Obvious Conjecture (OC) The obvious conjecture is that $(a_j)$ is the zero set of an inner function in $A$ if and only if $$\sum d(a_j,\partial A)<\infty.$$Seems like an obvious conjecture to me anyway. The zero set of any (non-trivial) $f\in H^\infty(A)$ satisfies this  condition; this follows in any of various ways from the result in the disk. Conversely, given $(a_j)$ with $\sum d(a_j,\partial A)<\infty$, separate the $a_j$ into two classes, those closer to $|z|=1$ and those closer to $|z|=R$. Let $B_1$ be the Blachke product formed from the $a_j$ in the first class, and let $B_2$ be the Blaschke product with zeroes at $R/a_j$ for $a_j$ in the second class. Let $$f(z)=B_1(z)B_2(R/z).$$For minute I thought that was an inner function. Of course it's not. But it is a bounded holomorphic function, so we've established this: Theorem The sequence $(a_j)$ is the zero set of some $f\in H^\infty(A)$ if and only if $\sum d(a_j,\partial A)<\infty$. To get an inner function with the right zero set I thought I'd try constructing some things analogous to Blaschke products. So given $a\in A$ I want to construct or say something about an inner function with just one zero, at $a$; then I could hope that a product of such things converged. Getting an inner function with zero set $\{a\}$ is very simple. Just say $$f(z)=(z-a)e^{u(z)+iv(z)},$$where $u$ is the solution to the Dirichlet problem with boundary data $-\log|z-a|$ and $v$ is a harmonic conjugate of $u$. For a few hours some years ago and a few hours the other day I thought that did it. Oops , harmonic functions need not have harmonic conjugates. Too much time in the disk... So this raises the question of which harmonic functions in $A$ have harmonic conjugates. And then come to think of it, $e^{u+iv}$ can be single-valued even if $v$ is not; the actual question of interest is which harmonic functions in $A$ are equal to $\log|f|$ for some non-vanishing holomorphic function $f$. I was surprised that both these questions have simple answers. In general let $u^\#$ be the radialization or radial part of $u$: $$u^\#(z)=\frac1{2\pi}\int_0^{2\pi}u(e^{it}z)\,dt.$$ Calculus $$r\frac d{dr}u^\#(r)=\frac1{2\pi i}\int_{|z|=r}2\frac{\partial u}{\partial z}\,dz.$$(Express $\partial u/\partial z$ in polar coordinates...) Now note that if $u$ is harmonic in $A$ then there exist $a,b\in\Bbb R$ with $$u^\#(r)=a+b\log(r).$$We will say $b(u)=b$ below. Theorem Suppose $u$ is harmonic in $A$. (i) The function $u$ has a harmonic conjugate if and only if $b(u)=0$. (ii) There exists a nonvanishing holomorphic $f$ with $u=\log|f|$ if and only if $b(u)\in\Bbb Z$. Proof (i) One direction is just Cauchy's Theorem. For the other direction, suppose $b(u)=0$. Note that $\partial u/\partial z$ is holomorphic. The calculus above shows that $\int_\gamma\partial u/\partial z=0$ for any closed curve $\gamma$. Hence $\partial u/\partial z$ has an antiderivative: There exists a holomorphic $f$ with $2\partial u/\partial z=f'=\partial f/\partial z$. This says that $2u-\overline f$ is holomorphic. Hence $2u-(\overline f+f)$ is holomorphic and real-valued, hence constant. (ii) Suppose that $u=\log|f|$. Then $2\partial u/\partial z=f'/f$. Since $\frac1{2\pi i}\int_{|z|=r}f'/f\in\Bbb Z$ the calculus above shows that $u^\#=c+n\log(r)$, $n\in\Bbb Z$. Conversely, suppose $b(u)=n\in\Bbb Z$. Let $v(z)=u(z)-n\log|z|$. Part (i) shows that $v$ has a harmonic conjugate $w$, and hence $v=\log\left|e^{v+iw}\right|$. So $u=\log\left|z^ne^{v+iw}\right|$. QED. We can now determine which finite subsets of $A$ are the zero sets of inner functions. Given $a_1,\dots,a_n\in A$, let $$p(z)=\prod_{j=1}^n(z-a_j),$$and let $u$ be the solution to the Dirichlet problem with boundary data $-\log|p|$. There exists an inner function with zero set the same as $p$ if and only if there exists $f$ with $u=\log|f|$. This happens if and only if $b(u)\in\Bbb Z$. One can calulate $u^\#(1)$ and $u^\#(R)$ explicitly, and it turns out that Theorem Suppose $a_1,\dots,a_n\in A$. There exists an inner function with precisely these zeroes if and only if $$\frac1{\log(R)}\sum_{j=1}^n\log|a_j|\in\Bbb Z.\quad(*)$$That seems interesting enough to justify reading this far, not that anybody will. Corollary Inner functions are not as fundamental in $A$ as they are in $\Bbb D$. Corollary $n=1$ is impossible: There is no inner function in $A$ with exactly one zero. But $n=2$ is possible. Very curious. That's as far as I got way back then. What about inner functions with infinitely many zeroes? Condition ($*$) makes no sense. Say $R<R'<1$. An analysis like the above, with that $B_1(z)B_2(R/z)$ thing in place of $p$, proves this: Theorem . Suppose $a_1,\dots\in A$. There exists an inner function with zero set $(a_j)$ if and only if $\sum d(a_j,\partial A)<\infty$ and $$\frac1{\log(R)}\left(\sum_{|a_j|>R'}\log|a_j|-\sum_{|a_j|\le R'}\log\left|\frac{R}{a_j}\right|\right)\in\Bbb Z.$$I'll spare you the details. Heh.","The other day someone reminded me of something I'd thought about some years ago. As back then it took me a little while to see why there was any problem; this time I got much farther on a solution than I did back then. This is supposed to be a question. Question: Is the stuff below (especially the result at the very end) actually true? Question: Reference? Background If $\Omega\subset\Bbb C$ is open the notation $H^\infty(\Omega)$ denotes the bounded holomorphic functions in $\Omega$. If $\Bbb D$ is the unit disk it's very well known that $f\in H^\infty(\Bbb D)$ has radial limits, in fact ""non-tangential"" limits, at almost every boundary point. A function $f\in H^\infty(\Bbb D)$ is an inner function if the boundary values have modulus $1$ almost everywhere. If $f\in H^\infty(\Bbb D)$ and the zeroes of $f$ are $(a_j)$ then $$\sum(1-|a_j|)<\infty.$$Conversely, this condition implies that $(a_j)$ is the zero set of some inner function (a Blaschke product). The Problem Now fix $R\in(0,1)$ and let $A$ be the annulus $R<|z|<1$. Define ""inner function"" in the obvious way. What are the zero sets of the inner functions in $A$? Obvious Conjecture (OC) The obvious conjecture is that $(a_j)$ is the zero set of an inner function in $A$ if and only if $$\sum d(a_j,\partial A)<\infty.$$Seems like an obvious conjecture to me anyway. The zero set of any (non-trivial) $f\in H^\infty(A)$ satisfies this  condition; this follows in any of various ways from the result in the disk. Conversely, given $(a_j)$ with $\sum d(a_j,\partial A)<\infty$, separate the $a_j$ into two classes, those closer to $|z|=1$ and those closer to $|z|=R$. Let $B_1$ be the Blachke product formed from the $a_j$ in the first class, and let $B_2$ be the Blaschke product with zeroes at $R/a_j$ for $a_j$ in the second class. Let $$f(z)=B_1(z)B_2(R/z).$$For minute I thought that was an inner function. Of course it's not. But it is a bounded holomorphic function, so we've established this: Theorem The sequence $(a_j)$ is the zero set of some $f\in H^\infty(A)$ if and only if $\sum d(a_j,\partial A)<\infty$. To get an inner function with the right zero set I thought I'd try constructing some things analogous to Blaschke products. So given $a\in A$ I want to construct or say something about an inner function with just one zero, at $a$; then I could hope that a product of such things converged. Getting an inner function with zero set $\{a\}$ is very simple. Just say $$f(z)=(z-a)e^{u(z)+iv(z)},$$where $u$ is the solution to the Dirichlet problem with boundary data $-\log|z-a|$ and $v$ is a harmonic conjugate of $u$. For a few hours some years ago and a few hours the other day I thought that did it. Oops , harmonic functions need not have harmonic conjugates. Too much time in the disk... So this raises the question of which harmonic functions in $A$ have harmonic conjugates. And then come to think of it, $e^{u+iv}$ can be single-valued even if $v$ is not; the actual question of interest is which harmonic functions in $A$ are equal to $\log|f|$ for some non-vanishing holomorphic function $f$. I was surprised that both these questions have simple answers. In general let $u^\#$ be the radialization or radial part of $u$: $$u^\#(z)=\frac1{2\pi}\int_0^{2\pi}u(e^{it}z)\,dt.$$ Calculus $$r\frac d{dr}u^\#(r)=\frac1{2\pi i}\int_{|z|=r}2\frac{\partial u}{\partial z}\,dz.$$(Express $\partial u/\partial z$ in polar coordinates...) Now note that if $u$ is harmonic in $A$ then there exist $a,b\in\Bbb R$ with $$u^\#(r)=a+b\log(r).$$We will say $b(u)=b$ below. Theorem Suppose $u$ is harmonic in $A$. (i) The function $u$ has a harmonic conjugate if and only if $b(u)=0$. (ii) There exists a nonvanishing holomorphic $f$ with $u=\log|f|$ if and only if $b(u)\in\Bbb Z$. Proof (i) One direction is just Cauchy's Theorem. For the other direction, suppose $b(u)=0$. Note that $\partial u/\partial z$ is holomorphic. The calculus above shows that $\int_\gamma\partial u/\partial z=0$ for any closed curve $\gamma$. Hence $\partial u/\partial z$ has an antiderivative: There exists a holomorphic $f$ with $2\partial u/\partial z=f'=\partial f/\partial z$. This says that $2u-\overline f$ is holomorphic. Hence $2u-(\overline f+f)$ is holomorphic and real-valued, hence constant. (ii) Suppose that $u=\log|f|$. Then $2\partial u/\partial z=f'/f$. Since $\frac1{2\pi i}\int_{|z|=r}f'/f\in\Bbb Z$ the calculus above shows that $u^\#=c+n\log(r)$, $n\in\Bbb Z$. Conversely, suppose $b(u)=n\in\Bbb Z$. Let $v(z)=u(z)-n\log|z|$. Part (i) shows that $v$ has a harmonic conjugate $w$, and hence $v=\log\left|e^{v+iw}\right|$. So $u=\log\left|z^ne^{v+iw}\right|$. QED. We can now determine which finite subsets of $A$ are the zero sets of inner functions. Given $a_1,\dots,a_n\in A$, let $$p(z)=\prod_{j=1}^n(z-a_j),$$and let $u$ be the solution to the Dirichlet problem with boundary data $-\log|p|$. There exists an inner function with zero set the same as $p$ if and only if there exists $f$ with $u=\log|f|$. This happens if and only if $b(u)\in\Bbb Z$. One can calulate $u^\#(1)$ and $u^\#(R)$ explicitly, and it turns out that Theorem Suppose $a_1,\dots,a_n\in A$. There exists an inner function with precisely these zeroes if and only if $$\frac1{\log(R)}\sum_{j=1}^n\log|a_j|\in\Bbb Z.\quad(*)$$That seems interesting enough to justify reading this far, not that anybody will. Corollary Inner functions are not as fundamental in $A$ as they are in $\Bbb D$. Corollary $n=1$ is impossible: There is no inner function in $A$ with exactly one zero. But $n=2$ is possible. Very curious. That's as far as I got way back then. What about inner functions with infinitely many zeroes? Condition ($*$) makes no sense. Say $R<R'<1$. An analysis like the above, with that $B_1(z)B_2(R/z)$ thing in place of $p$, proves this: Theorem . Suppose $a_1,\dots\in A$. There exists an inner function with zero set $(a_j)$ if and only if $\sum d(a_j,\partial A)<\infty$ and $$\frac1{\log(R)}\left(\sum_{|a_j|>R'}\log|a_j|-\sum_{|a_j|\le R'}\log\left|\frac{R}{a_j}\right|\right)\in\Bbb Z.$$I'll spare you the details. Heh.",,"['complex-analysis', 'reference-request', 'proof-verification', 'hardy-spaces']"
64,Connection between algebraic geometry and complex analysis?,Connection between algebraic geometry and complex analysis?,,"I've studied some complex analysis and basics in algebraic geometry (let's say over $\mathbb C $). We had been mentioned GAGA but nothing in detail. Anyway, from my beginner's point of view, I already see many parallels between both areas of study like compact riemann surfaces vs. projective curves regular functions being holomorphic ramified coverings globally holomorphic/regular maps on projective varieties/compact riemann surfaces being constant Also, the field of elliptic functions on a torus is finitely generated, reminiscent of function fields of varieties (in fact the torus algebro-geometrically is an elliptic curve). However, I don't see the precise correspondence. After all, the notion of morphism should be weaker than that of a holomorphic map. Or can one get a 1:1-correspondence? How would algebraic geometry help in studying all holomorphic functions and not just those taat happen to be regular. Maybe you could give me some intuition on the topic or GAGA in basic terms. Thank you","I've studied some complex analysis and basics in algebraic geometry (let's say over $\mathbb C $). We had been mentioned GAGA but nothing in detail. Anyway, from my beginner's point of view, I already see many parallels between both areas of study like compact riemann surfaces vs. projective curves regular functions being holomorphic ramified coverings globally holomorphic/regular maps on projective varieties/compact riemann surfaces being constant Also, the field of elliptic functions on a torus is finitely generated, reminiscent of function fields of varieties (in fact the torus algebro-geometrically is an elliptic curve). However, I don't see the precise correspondence. After all, the notion of morphism should be weaker than that of a holomorphic map. Or can one get a 1:1-correspondence? How would algebraic geometry help in studying all holomorphic functions and not just those taat happen to be regular. Maybe you could give me some intuition on the topic or GAGA in basic terms. Thank you",,"['complex-analysis', 'algebraic-geometry']"
65,Cauchy-Riemann Equations Written as Complex Conjugate,Cauchy-Riemann Equations Written as Complex Conjugate,,"Apparently, it can be shown that the Cauchy-Riemann equations can be written simply as, $df/dz^*=0$. I do not understand how it does not immediately follow from this that $df/dz=0$. When we proved the relations originally, we used $$\frac{df}{dz} = \frac{\delta u+i\delta v}{\delta x+i\delta y}$$ Taking both the limits $\delta x\to0$ and $\delta y \to 0$, and requiring they be equal for the derivative to be defined. Doing the same thing for $df/dz^*$, we get exactly the same thing for $\delta x\to 0$. Since this has to be zero, haven't we also shown that $df/dz=0$ if $df/dz^*$ is defined? Or am I missing something obvious? Thanks!","Apparently, it can be shown that the Cauchy-Riemann equations can be written simply as, $df/dz^*=0$. I do not understand how it does not immediately follow from this that $df/dz=0$. When we proved the relations originally, we used $$\frac{df}{dz} = \frac{\delta u+i\delta v}{\delta x+i\delta y}$$ Taking both the limits $\delta x\to0$ and $\delta y \to 0$, and requiring they be equal for the derivative to be defined. Doing the same thing for $df/dz^*$, we get exactly the same thing for $\delta x\to 0$. Since this has to be zero, haven't we also shown that $df/dz=0$ if $df/dz^*$ is defined? Or am I missing something obvious? Thanks!",,['complex-analysis']
66,Argument at branch cut,Argument at branch cut,,"I try to use residue to calculate this integral $$\int_1^2 \frac{\sqrt {(x-1)(2-x)}} {x}\ dx$$ I let $$f(z)=\frac{\sqrt {(z-1)(2-z)}} {z}$$ and evaluate the integral $$\int_{(\Gamma)} f(z)dz$$ along the contour $\Gamma$ consisting of: $(1)$ circle$(1;\epsilon)$; $(2)$ circle$(2;\epsilon)$; $(3) $circle$(0;R)$; $(4)$ segments $[1+\epsilon,2-\epsilon]$ - upper and lower sides of branch cut $[1,2]$, and $(5)$ segments $[2+\epsilon,R]$ My problem is how to define the argument of $z-1$ and $2-z$ at upper and lower sides of branch cut In a similar example: http://en.wikipedia.org/wiki/Methods_of_contour_integration#Example_.28VI.29_.E2.80.93_logarithms_and_the_residue_at_infinity why $\arg(z)$ ranged from $-\pi$ to $\pi$ while $\arg(3-z)$ ranged from $0$ to $2\pi$","I try to use residue to calculate this integral $$\int_1^2 \frac{\sqrt {(x-1)(2-x)}} {x}\ dx$$ I let $$f(z)=\frac{\sqrt {(z-1)(2-z)}} {z}$$ and evaluate the integral $$\int_{(\Gamma)} f(z)dz$$ along the contour $\Gamma$ consisting of: $(1)$ circle$(1;\epsilon)$; $(2)$ circle$(2;\epsilon)$; $(3) $circle$(0;R)$; $(4)$ segments $[1+\epsilon,2-\epsilon]$ - upper and lower sides of branch cut $[1,2]$, and $(5)$ segments $[2+\epsilon,R]$ My problem is how to define the argument of $z-1$ and $2-z$ at upper and lower sides of branch cut In a similar example: http://en.wikipedia.org/wiki/Methods_of_contour_integration#Example_.28VI.29_.E2.80.93_logarithms_and_the_residue_at_infinity why $\arg(z)$ ranged from $-\pi$ to $\pi$ while $\arg(3-z)$ ranged from $0$ to $2\pi$",,"['complex-analysis', 'contour-integration', 'branch-cuts']"
67,"Methods for ""recognizing"" a polynomial of several variables.","Methods for ""recognizing"" a polynomial of several variables.",,"If $f(z)$ is an entire function of a single complex variable, then the following are indirect methods for recognizing that $f$ is a polynomial. 1) Show that $f^{(n)}\equiv0$ for some $n\geq0$. 2) Show that $\displaystyle\lim_{z\to\infty}f(z)$ exists. I suppose that the first one could be adopted to several variables, but I do not think the second one can be.  Does anyone know other similar methods? EDIT: I would also be interested in an answer to the same question with ""rational function"" subbed in for ""polynomial"".","If $f(z)$ is an entire function of a single complex variable, then the following are indirect methods for recognizing that $f$ is a polynomial. 1) Show that $f^{(n)}\equiv0$ for some $n\geq0$. 2) Show that $\displaystyle\lim_{z\to\infty}f(z)$ exists. I suppose that the first one could be adopted to several variables, but I do not think the second one can be.  Does anyone know other similar methods? EDIT: I would also be interested in an answer to the same question with ""rational function"" subbed in for ""polynomial"".",,"['complex-analysis', 'several-complex-variables']"
68,Conformal equivalence of resistance,Conformal equivalence of resistance,,"Link to the question in the physics portal. I'm currently working on a system that uses a logarithmic and a Schwarz-Christoffel transformation to calculate the resistance of a specific area. With resistance I mean the resistance that would apply to that area if it were between two equipotential irregular plates (which are defined by their vertices). In my case it is the magnetic reluctance but it is analogous to electrical resistance . Right click on the image and choose the appropriate option to view a larger image or click here I have multiple areas of the canonical domain that have to be translated to a resistance value in the physical domain(with the intermediate step of a logarithm). Is the resistance (defined analogous to electrical resitance) that can be calculated in the homogeneous field of the canonical domain directly related to the resitance in the phyisical domain? The geometry of a resistor in the canonical domain is a simple rectangle formed from four prevertices. In the physical domain it is far more complicated (see figure). The measure of resistance can be formulated with the help of an ""equivalent length"". Could it be that this $\Lambda$ is not affected by the conformal tranformations? \begin{align} &R=\rho\dfrac{1}{\Lambda}\\ &\text{cylinder gives: } &\Lambda_\text{cyl}=\frac{2\pi \ell}{\log\frac{r_2}{r_1}}\\ &\text{cuboid gives: } &\Lambda_\text{cub}=\dfrac{A}{\ell} \end{align} I have done some calculations by discretising the physical domain and comparing it to the resistance generated in the canonical domain. The results were comparable, maybe because of accident, maybe because of a strong mathematical implication, I can't say. Question in short: Can the prevertices that define a rectangle in the canonical domain define the resistance value of the mapped rectangle in the phyisical domain. (With the intermidate step of a logarithm) I use the SC-Toolbox for Matlab created by Tobin A. Driscoll. EDIT: Addition Lets say that we have a rectangle which has been rotated and translated (Möbius transformations if you want) so that its sides are perpendiculary oriented to the real and imaginary axis, one of its vertices is (0,0) and that it is in the 1st quadrant. We have to calculate its resistance. Lets say the opposite vertex of (0,0) is $z=x+iy=|z|e^{i\varphi}$, the imaginary part of $z$ represents the length of the path, while the real part represents the projected area(the area is only visible in 3D, we are looking at it in 2D). We write $R'$ because of the 2D representation. The resistance of this rectangle will therefore be: \begin{align} R'=\rho \frac{\mathfrak{Im}(z)}{\mathfrak{Re}(z)} \end{align} Which can be written as: \begin{align} R'&=\rho \frac{|z|\sin\varphi}{|z|\cos\varphi}=\rho \frac{\sin\varphi}{\cos\varphi}\\ R'&=\rho\tan\varphi \end{align} The thing that the resistance is only dependent on the angle $\varphi$ and the definition of conformal transformations as angle preserving , provoked me to ask this question. I found a lot about space being conformally invariant, but in this case it is a function that is discussed. I'm not sure how to proceed. I can prove that the transformations(maps) are conformal, but I don't know what to do about a function in the canonical space.","Link to the question in the physics portal. I'm currently working on a system that uses a logarithmic and a Schwarz-Christoffel transformation to calculate the resistance of a specific area. With resistance I mean the resistance that would apply to that area if it were between two equipotential irregular plates (which are defined by their vertices). In my case it is the magnetic reluctance but it is analogous to electrical resistance . Right click on the image and choose the appropriate option to view a larger image or click here I have multiple areas of the canonical domain that have to be translated to a resistance value in the physical domain(with the intermediate step of a logarithm). Is the resistance (defined analogous to electrical resitance) that can be calculated in the homogeneous field of the canonical domain directly related to the resitance in the phyisical domain? The geometry of a resistor in the canonical domain is a simple rectangle formed from four prevertices. In the physical domain it is far more complicated (see figure). The measure of resistance can be formulated with the help of an ""equivalent length"". Could it be that this $\Lambda$ is not affected by the conformal tranformations? \begin{align} &R=\rho\dfrac{1}{\Lambda}\\ &\text{cylinder gives: } &\Lambda_\text{cyl}=\frac{2\pi \ell}{\log\frac{r_2}{r_1}}\\ &\text{cuboid gives: } &\Lambda_\text{cub}=\dfrac{A}{\ell} \end{align} I have done some calculations by discretising the physical domain and comparing it to the resistance generated in the canonical domain. The results were comparable, maybe because of accident, maybe because of a strong mathematical implication, I can't say. Question in short: Can the prevertices that define a rectangle in the canonical domain define the resistance value of the mapped rectangle in the phyisical domain. (With the intermidate step of a logarithm) I use the SC-Toolbox for Matlab created by Tobin A. Driscoll. EDIT: Addition Lets say that we have a rectangle which has been rotated and translated (Möbius transformations if you want) so that its sides are perpendiculary oriented to the real and imaginary axis, one of its vertices is (0,0) and that it is in the 1st quadrant. We have to calculate its resistance. Lets say the opposite vertex of (0,0) is $z=x+iy=|z|e^{i\varphi}$, the imaginary part of $z$ represents the length of the path, while the real part represents the projected area(the area is only visible in 3D, we are looking at it in 2D). We write $R'$ because of the 2D representation. The resistance of this rectangle will therefore be: \begin{align} R'=\rho \frac{\mathfrak{Im}(z)}{\mathfrak{Re}(z)} \end{align} Which can be written as: \begin{align} R'&=\rho \frac{|z|\sin\varphi}{|z|\cos\varphi}=\rho \frac{\sin\varphi}{\cos\varphi}\\ R'&=\rho\tan\varphi \end{align} The thing that the resistance is only dependent on the angle $\varphi$ and the definition of conformal transformations as angle preserving , provoked me to ask this question. I found a lot about space being conformally invariant, but in this case it is a function that is discussed. I'm not sure how to proceed. I can prove that the transformations(maps) are conformal, but I don't know what to do about a function in the canonical space.",,"['complex-analysis', 'conformal-geometry']"
69,"""Natural"" interpolation between partial sums of a power series","""Natural"" interpolation between partial sums of a power series",,"Suppose $f(z)=\sum_{n=0}^\infty a_n z^n$ has a radius of convergence of $R$. Let the $N$-th partial sum be $f_N (z)=\sum_{n=0}^N a_n z^n$. What smooth (analytic) function interpolates between $f_N(z)$. In other words what ""natural"" analytic function $F(\alpha,z)$ has the property that $F(N,z)=f_N(z)$ for $N=0,1,\cdots$. Related Question for $f=e^z$","Suppose $f(z)=\sum_{n=0}^\infty a_n z^n$ has a radius of convergence of $R$. Let the $N$-th partial sum be $f_N (z)=\sum_{n=0}^N a_n z^n$. What smooth (analytic) function interpolates between $f_N(z)$. In other words what ""natural"" analytic function $F(\alpha,z)$ has the property that $F(N,z)=f_N(z)$ for $N=0,1,\cdots$. Related Question for $f=e^z$",,"['complex-analysis', 'power-series']"
70,complex proof not sure,complex proof not sure,,"There's this problem in my homework, I did it, but somehow it just doesn't seem right. I wonder where the problem is... Please help me :) Show that $\int_\gamma z^n dz=0$ for any closed smooth $\gamma$ and any integer $n\neq -1$. [If $n$ is negative, assume that $\gamma$ does not pass through the origin, since otherwise the integral is not defined.] $\rightarrow$  Sol. Let $z=\gamma(t)$, $dz=\gamma'(t)dt$, $a\leq t\leq b$, $\gamma(a)=\gamma(b)$. Then: \begin{align*} &\int_\gamma z^n dz\\ =&\int_a^b\gamma(t)^n\gamma'(t)dt\\ =&\int_{\gamma(a)}^{\gamma(b)} z^n dz\\ =&\frac{z^{n+1}}{n+1}\bigg|_{\gamma(a)}^{\gamma(b)}\\ =&0\\ \end{align*} What could the problem be? Thank you!","There's this problem in my homework, I did it, but somehow it just doesn't seem right. I wonder where the problem is... Please help me :) Show that $\int_\gamma z^n dz=0$ for any closed smooth $\gamma$ and any integer $n\neq -1$. [If $n$ is negative, assume that $\gamma$ does not pass through the origin, since otherwise the integral is not defined.] $\rightarrow$  Sol. Let $z=\gamma(t)$, $dz=\gamma'(t)dt$, $a\leq t\leq b$, $\gamma(a)=\gamma(b)$. Then: \begin{align*} &\int_\gamma z^n dz\\ =&\int_a^b\gamma(t)^n\gamma'(t)dt\\ =&\int_{\gamma(a)}^{\gamma(b)} z^n dz\\ =&\frac{z^{n+1}}{n+1}\bigg|_{\gamma(a)}^{\gamma(b)}\\ =&0\\ \end{align*} What could the problem be? Thank you!",,['complex-analysis']
71,Showing a function is holomorphic,Showing a function is holomorphic,,"$f$ is continuous on $\gamma$ which is smooth & bounded. Let F be a function such that  $$F=\int_\gamma \frac{f(\beta)}{\beta-z} d\beta$$ for all $z$ not in $\gamma$ Show F is holomorphic at $z$ not on the curve and that $$F^'(z)=\int_\gamma \frac{f(\beta)}{(\beta-z)^2} d\beta$$ I used the basic definition: $$F^'(z)=\lim_{h\to0}\frac{F(z+h)-F(z)}{h}$$ $$=\lim_{h\to0}\frac{\int_\gamma \frac{f(\beta)}{\beta-(z+h)} d\beta-\int_\gamma \frac{f(\beta)}{\beta-z} d\beta}{h}$$ $$=\lim_{h\to0}\int_\gamma \frac{(f(\beta)(\beta-z)-f(\beta)(\beta-z-h)}{h(\beta-z-h)(\beta-z)} d\beta$$ $$=\lim_{h\to0}\int_\gamma \frac{f(\beta)}{(\beta-z-h)(\beta-z)} d\beta$$ $$=\int_\gamma \frac{f(\beta)}{(\beta-z)^2} d\beta$$ Just wondering is what I done correct (since it seems a bit trivial)? If so is it necessary that the curve is smooth & bounded, and that $f$ is continuous on it?","$f$ is continuous on $\gamma$ which is smooth & bounded. Let F be a function such that  $$F=\int_\gamma \frac{f(\beta)}{\beta-z} d\beta$$ for all $z$ not in $\gamma$ Show F is holomorphic at $z$ not on the curve and that $$F^'(z)=\int_\gamma \frac{f(\beta)}{(\beta-z)^2} d\beta$$ I used the basic definition: $$F^'(z)=\lim_{h\to0}\frac{F(z+h)-F(z)}{h}$$ $$=\lim_{h\to0}\frac{\int_\gamma \frac{f(\beta)}{\beta-(z+h)} d\beta-\int_\gamma \frac{f(\beta)}{\beta-z} d\beta}{h}$$ $$=\lim_{h\to0}\int_\gamma \frac{(f(\beta)(\beta-z)-f(\beta)(\beta-z-h)}{h(\beta-z-h)(\beta-z)} d\beta$$ $$=\lim_{h\to0}\int_\gamma \frac{f(\beta)}{(\beta-z-h)(\beta-z)} d\beta$$ $$=\int_\gamma \frac{f(\beta)}{(\beta-z)^2} d\beta$$ Just wondering is what I done correct (since it seems a bit trivial)? If so is it necessary that the curve is smooth & bounded, and that $f$ is continuous on it?",,['complex-analysis']
72,Question regarding Goursat's Theorem,Question regarding Goursat's Theorem,,"I read through and pretty much understand most of Goursat's Theorem in $\textit{Complex Analysis}$ by Gamelin. The theorem states that if $f(z)$ is a complex-valued function on a domain $D$ such that $f'(z_0)$ exists at each point $z_0 \in D$, then $f(z)$ is analytic on $D$. Here the requirement that $f'(z)$ be continuous is redundant. This section only had one problem on p. 124: Find an application for Goursat's Theorem in which it is not patently clear  by other means that the function in question is analytic. Seems kind of vague to me, and I've been struggling with this for quite a bit. I would appreciate some input on how we should proceed.","I read through and pretty much understand most of Goursat's Theorem in $\textit{Complex Analysis}$ by Gamelin. The theorem states that if $f(z)$ is a complex-valued function on a domain $D$ such that $f'(z_0)$ exists at each point $z_0 \in D$, then $f(z)$ is analytic on $D$. Here the requirement that $f'(z)$ be continuous is redundant. This section only had one problem on p. 124: Find an application for Goursat's Theorem in which it is not patently clear  by other means that the function in question is analytic. Seems kind of vague to me, and I've been struggling with this for quite a bit. I would appreciate some input on how we should proceed.",,['complex-analysis']
73,General form of Rouche's Theorem,General form of Rouche's Theorem,,"Let $\Omega$ be the interior of a compact set $K$ in the plane. Suppose $f$ and $g$ are continuous on $K$ and holomorphic in $\Omega$, and $|f(z)-g(z)|<|f(z)|$ for all $z\in K-\Omega$. Then $f$ and $g$ have the same number of zeros in $\Omega$. PS: This problem is from Rudin's book in Ch.10. So, I just know some basic theorems about holomorphic functions.(I don't know anything about harmonic functions or conformal mapping, which I will learn in later chapters) Something I tried: Since I don't know how to solve this problem with arbitrary compact set $K$, I just assume that $K$ is a closed disc $\bar{D}(0;R)$ to simplify the problem. So $\Omega=D(0;R)$ (Actually, even if I could solve the problem in this simple case, I don't know how to solve the problem in the general case. I just make the problem simpler and see where this specific case will lead me to) Clearly, $f$ has no zeros on $\partial\bar{D}$. Let $N$ denote the number of zeros of $f$ in $D(0;R)$ and $\gamma$ be the circle with center at $0$ and radius $R$. If I could prove that $$N=\frac{1}{2\pi i}\int_\gamma\frac{f'(z)}{f(z)}dz$$ (which is different from the classical Argument Principle I learnt), I could solve the simpler case. Since $f$ is holomorphic in $D(0;R)$ and not identically zero in $D(0;R)$, the number of zeros of $f$ in $D(0;R)$ is finite. Let $r=sup\lbrace|a|:f(a)=0, a\in D(0;R)\rbrace$. Therefore, all the zeros of $f$ lie in the open disc $D(0;r)$. Pick $\rho$ such that$\rho$ such that $R>\rho>r$. Define $\gamma_\rho(\theta)=\rho e^{i\theta}$ on $[0,2\pi]$ Now, the classical Argument Principle can be used. Therefore, $$N(\rho)=\frac{1}{2\pi i}\int_{\gamma_\rho}\frac{f'(z)}{f(z)}dz$$ or $$N(\rho)=\frac{1}{2\pi}\int_0^{2\pi}\frac{f'(\rho e^{i\theta})}{f(\rho e^{i\theta})}\rho e^{i\theta}d\theta$$ Now, let $\rho\to R$. Therefore, $\lim_{\rho\to R}N(\rho)=N$. However, I cannot prove that $f'$ is continuous on $\bar{D}(0;R)$, though $f'$ is really continuous in $D(0;R)$. Thus, I failed to solve the problem. PS: This question has been posted in https://mathoverflow.net/questions/75716/general-form-of-rouches-theorem , too Any hints will be appreciated.","Let $\Omega$ be the interior of a compact set $K$ in the plane. Suppose $f$ and $g$ are continuous on $K$ and holomorphic in $\Omega$, and $|f(z)-g(z)|<|f(z)|$ for all $z\in K-\Omega$. Then $f$ and $g$ have the same number of zeros in $\Omega$. PS: This problem is from Rudin's book in Ch.10. So, I just know some basic theorems about holomorphic functions.(I don't know anything about harmonic functions or conformal mapping, which I will learn in later chapters) Something I tried: Since I don't know how to solve this problem with arbitrary compact set $K$, I just assume that $K$ is a closed disc $\bar{D}(0;R)$ to simplify the problem. So $\Omega=D(0;R)$ (Actually, even if I could solve the problem in this simple case, I don't know how to solve the problem in the general case. I just make the problem simpler and see where this specific case will lead me to) Clearly, $f$ has no zeros on $\partial\bar{D}$. Let $N$ denote the number of zeros of $f$ in $D(0;R)$ and $\gamma$ be the circle with center at $0$ and radius $R$. If I could prove that $$N=\frac{1}{2\pi i}\int_\gamma\frac{f'(z)}{f(z)}dz$$ (which is different from the classical Argument Principle I learnt), I could solve the simpler case. Since $f$ is holomorphic in $D(0;R)$ and not identically zero in $D(0;R)$, the number of zeros of $f$ in $D(0;R)$ is finite. Let $r=sup\lbrace|a|:f(a)=0, a\in D(0;R)\rbrace$. Therefore, all the zeros of $f$ lie in the open disc $D(0;r)$. Pick $\rho$ such that$\rho$ such that $R>\rho>r$. Define $\gamma_\rho(\theta)=\rho e^{i\theta}$ on $[0,2\pi]$ Now, the classical Argument Principle can be used. Therefore, $$N(\rho)=\frac{1}{2\pi i}\int_{\gamma_\rho}\frac{f'(z)}{f(z)}dz$$ or $$N(\rho)=\frac{1}{2\pi}\int_0^{2\pi}\frac{f'(\rho e^{i\theta})}{f(\rho e^{i\theta})}\rho e^{i\theta}d\theta$$ Now, let $\rho\to R$. Therefore, $\lim_{\rho\to R}N(\rho)=N$. However, I cannot prove that $f'$ is continuous on $\bar{D}(0;R)$, though $f'$ is really continuous in $D(0;R)$. Thus, I failed to solve the problem. PS: This question has been posted in https://mathoverflow.net/questions/75716/general-form-of-rouches-theorem , too Any hints will be appreciated.",,['complex-analysis']
74,"Riemann's $\zeta$ function and the uniform distribution on $[-1,0]$",Riemann's  function and the uniform distribution on,"\zeta [-1,0]","It seems that the $n$th cumulant of the uniform distribution on the interval $[-1,0]$ is $B_n/n$, where $B_n$ is the $n$th Bernoulli number. And also $-\zeta(1-n) = B_n/n$, where $\zeta$ is Riemann's $\zeta$ function. Is there some reason why one should expect these to be the same, as opposed to proofs that convince you that they are?","It seems that the $n$th cumulant of the uniform distribution on the interval $[-1,0]$ is $B_n/n$, where $B_n$ is the $n$th Bernoulli number. And also $-\zeta(1-n) = B_n/n$, where $\zeta$ is Riemann's $\zeta$ function. Is there some reason why one should expect these to be the same, as opposed to proofs that convince you that they are?",,"['complex-analysis', 'probability-theory', 'analytic-number-theory', 'riemann-zeta', 'bernoulli-numbers']"
75,Poisson kernel for upper half plane,Poisson kernel for upper half plane,,"Can anyone tell me how to calculate the Poisson kernel for the upper half plane? I am able to calculate it for the unit disc and I know the unit disc and the upper half plane are conformally equivalent, do I need this?","Can anyone tell me how to calculate the Poisson kernel for the upper half plane? I am able to calculate it for the unit disc and I know the unit disc and the upper half plane are conformally equivalent, do I need this?",,['complex-analysis']
76,Construct an explicit biholomorphism between two domains,Construct an explicit biholomorphism between two domains,,"This problem is from my homework: Construct an explicit biholomorphism between $D_1=\mathbb{C}-\{-x\pm\sqrt{-1}\pi\mid x\ge1\}$ and $D_2=\{x+\sqrt{-1}y\mid -\infty<x<\infty, -\pi<y<\pi\}$ . It is obvious that we can find a biholomorphism between $D_2$ and the upper plane, but the defination of $D_1$ is so strange and complex that I have no idea how to deal with it. Any help would be appreciated.","This problem is from my homework: Construct an explicit biholomorphism between and . It is obvious that we can find a biholomorphism between and the upper plane, but the defination of is so strange and complex that I have no idea how to deal with it. Any help would be appreciated.","D_1=\mathbb{C}-\{-x\pm\sqrt{-1}\pi\mid x\ge1\} D_2=\{x+\sqrt{-1}y\mid -\infty<x<\infty, -\pi<y<\pi\} D_2 D_1","['complex-analysis', 'complex-numbers', 'conformal-geometry']"
77,Embedding $\mathbb{CP}^n$ into $\mathbb{R}^{4n-1}$ [closed],Embedding  into  [closed],\mathbb{CP}^n \mathbb{R}^{4n-1},"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . The community reviewed whether to reopen this question 2 months ago and left it closed: Original close reason(s) were not resolved Improve this question I'm looking for a generalization of the map of $\mathbb{C}P^1$ into $\mathbb{R}^3$ as a sphere. Are there any such (preferably canonical) embeddings of $\mathbb{C}P^n$ into $\mathbb{R}^{4n-1}$ ? (And is $4n-1$ the correct dimension to be asking this question in?)","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . The community reviewed whether to reopen this question 2 months ago and left it closed: Original close reason(s) were not resolved Improve this question I'm looking for a generalization of the map of into as a sphere. Are there any such (preferably canonical) embeddings of into ? (And is the correct dimension to be asking this question in?)",\mathbb{C}P^1 \mathbb{R}^3 \mathbb{C}P^n \mathbb{R}^{4n-1} 4n-1,"['complex-analysis', 'projective-space']"
78,"Real-Analysis Methods to Evaluate $\int_0^\infty \frac{x^a}{1+x^2}\,dx$, $|a|<1$.","Real-Analysis Methods to Evaluate , .","\int_0^\infty \frac{x^a}{1+x^2}\,dx |a|<1","In THIS ANSWER , I used straightforward contour integration to evaluate the integral $$\bbox[5px,border:2px solid #C0A000]{\int_0^\infty \frac{x^a}{1+x^2}\,dx=\frac{\pi}{2}\sec\left(\frac{\pi a}{2}\right)}$$for $|a|<1$. An alternative approach is to enforce the substitution $x\to e^x$ to obtain $$\begin{align} \int_0^\infty \frac{x^a}{1+x^2}\,dx&=\int_{-\infty}^\infty \frac{e^{(a+1)x}}{1+e^{2x}}\,dx\\\\ &=\int_{-\infty}^0\frac{e^{(a+1)x}}{1+e^{2x}}\,dx+\int_{0}^\infty\frac{e^{(a-1)x}}{1+e^{-2x}}\,dx\\\\ &=\sum_{n=0}^\infty (-1)^n\left(\int_{-\infty}^0 e^{(2n+1+a)x}\,dx+\int_{0}^\infty e^{-(2n+1-a)x}\,dx\right)\\\\ &=\sum_{n=0}^\infty (-1)^n \left(\frac{1}{2n+1+a}+\frac{1}{2n+1-a}\right)\\\\ &=2\sum_{n=0}^\infty (-1)^n\left(\frac{2n+1}{(2n+1)^2-a^2}\right) \tag 1\\\\ &=\frac{\pi}{2}\sec\left(\frac{\pi a}{2}\right)\tag 2 \end{align}$$ Other possible ways forward include writing the integral of interest as $$\begin{align} \int_0^\infty \frac{x^a}{1+x^2}\,dx&=\int_{0}^1 \frac{x^{a}+x^{-a}}{1+x^2}\,dx \end{align}$$ and proceeding similarly, using $\frac{1}{1+x^2}=\sum_{n=0}^\infty (-1)^nx^{2n}$. Without appealing to complex analysis, what are other approaches one can use to evaluate this very standard integral? EDIT: Note that we can show that $(1)$ is the partial fraction representation of $(2)$ using Fourier series analysis.  I've included this development for completeness in the appendix of the solution I posted on THIS PAGE .","In THIS ANSWER , I used straightforward contour integration to evaluate the integral $$\bbox[5px,border:2px solid #C0A000]{\int_0^\infty \frac{x^a}{1+x^2}\,dx=\frac{\pi}{2}\sec\left(\frac{\pi a}{2}\right)}$$for $|a|<1$. An alternative approach is to enforce the substitution $x\to e^x$ to obtain $$\begin{align} \int_0^\infty \frac{x^a}{1+x^2}\,dx&=\int_{-\infty}^\infty \frac{e^{(a+1)x}}{1+e^{2x}}\,dx\\\\ &=\int_{-\infty}^0\frac{e^{(a+1)x}}{1+e^{2x}}\,dx+\int_{0}^\infty\frac{e^{(a-1)x}}{1+e^{-2x}}\,dx\\\\ &=\sum_{n=0}^\infty (-1)^n\left(\int_{-\infty}^0 e^{(2n+1+a)x}\,dx+\int_{0}^\infty e^{-(2n+1-a)x}\,dx\right)\\\\ &=\sum_{n=0}^\infty (-1)^n \left(\frac{1}{2n+1+a}+\frac{1}{2n+1-a}\right)\\\\ &=2\sum_{n=0}^\infty (-1)^n\left(\frac{2n+1}{(2n+1)^2-a^2}\right) \tag 1\\\\ &=\frac{\pi}{2}\sec\left(\frac{\pi a}{2}\right)\tag 2 \end{align}$$ Other possible ways forward include writing the integral of interest as $$\begin{align} \int_0^\infty \frac{x^a}{1+x^2}\,dx&=\int_{0}^1 \frac{x^{a}+x^{-a}}{1+x^2}\,dx \end{align}$$ and proceeding similarly, using $\frac{1}{1+x^2}=\sum_{n=0}^\infty (-1)^nx^{2n}$. Without appealing to complex analysis, what are other approaches one can use to evaluate this very standard integral? EDIT: Note that we can show that $(1)$ is the partial fraction representation of $(2)$ using Fourier series analysis.  I've included this development for completeness in the appendix of the solution I posted on THIS PAGE .",,"['real-analysis', 'definite-integrals']"
79,Why is the measure determined by the Stieltjes inversion formula?,Why is the measure determined by the Stieltjes inversion formula?,,"$f$ is a Herglotz-Nevanlinna function if it is analytic in the open upper half plane and the imaginary part $\Im f (z) \geq 0$ for $\Im z >0$ . $f$ has the following integral representation $$f(z) = a + bz + \int_\mathbb{R} \frac{1}{t-z} - \frac{t}{1+t^2} d \mu(t)$$ where $a \in \mathbb{R}, \ b \geq 0$ and $\mu$ is a Borel measure on $\mathbb{R}$ such that $$\int_\mathbb{R} \frac{d \mu(t)}{1+t^2} < \infty$$ The Stieltjes inversion formula gives, that for any interval $(t_1, t_2) \subset \mathbb{R}$ $$\mu((t_1, t_2)) + \frac{\mu(\{t_1\}) + \mu(\{t_2\})}{2} = \lim_{y \to 0^+} \frac{1}{\pi} \int_{t_1}^{t_2} \Im f(t+iy) d t \tag{1}$$ My question is, why is the measure $\mu$ determined by $f$ ? Can the left hand side of $(1)$ be interpreted as a measure of an interval? The Wikipedia article has $\mu((t_1, t_2])$ on the left hand side. If this is the case, then I understand why the measure would be determined, but what happened to the point masses $\mu(\{t_1\})$ and $\mu(\{t_2\})$ ?","is a Herglotz-Nevanlinna function if it is analytic in the open upper half plane and the imaginary part for . has the following integral representation where and is a Borel measure on such that The Stieltjes inversion formula gives, that for any interval My question is, why is the measure determined by ? Can the left hand side of be interpreted as a measure of an interval? The Wikipedia article has on the left hand side. If this is the case, then I understand why the measure would be determined, but what happened to the point masses and ?","f \Im f (z) \geq 0 \Im z >0 f f(z) = a + bz + \int_\mathbb{R} \frac{1}{t-z} - \frac{t}{1+t^2} d \mu(t) a \in \mathbb{R}, \ b \geq 0 \mu \mathbb{R} \int_\mathbb{R} \frac{d \mu(t)}{1+t^2} < \infty (t_1, t_2) \subset \mathbb{R} \mu((t_1, t_2)) + \frac{\mu(\{t_1\}) + \mu(\{t_2\})}{2} = \lim_{y \to 0^+} \frac{1}{\pi} \int_{t_1}^{t_2} \Im f(t+iy) d t \tag{1} \mu f (1) \mu((t_1, t_2]) \mu(\{t_1\}) \mu(\{t_2\})","['complex-analysis', 'measure-theory', 'stieltjes-integral']"
80,Using the Residue theorem to solve contour integral $\oint_{|z|=R}\frac{z^2}{1-e^{2\pi i z^3}}dz$ with $n<R^3<n+1$ for positive integer $n$.,Using the Residue theorem to solve contour integral  with  for positive integer .,\oint_{|z|=R}\frac{z^2}{1-e^{2\pi i z^3}}dz n<R^3<n+1 n,"I'm a second-year undergraduate in a non-major complex analysis course. We just started looking at using residues to compute the values of contour integrals, and I've run into a homework problem that's giving me some trouble. I spent a lot of time on this one and I think I got it, but my answer is off by a negative compared to the one in a student-created answer bank that on rare occasion does have incorrect answers, but is usually right. I'm looking for help confirming my thought process and making sure that I didn't make any mistakes here. The integral is $\oint_{|z|=R}\frac{z^2}{1-e^{2\pi i z^3}}dz$ with $n<R^3<n+1$ for positive integer $n$ . I started by identifying all singularities as those $z$ where $1-e^{2\pi i z^3}=0$ , and discovered that this is true exactly when $z^3=k$ for some integer $k$ . I then let $z=re^{i\theta}$ , which gives $z^3=k\Rightarrow r^3e^{3i\theta}=ke^{i(0)}\Rightarrow r=k^{1/3},\theta=\frac{2\pi l}{3}$ , where $l$ is an integer. Since $z$ is like a ""3rd root of $k$ "" (like a 3rd root of unity), there are 3 of them with unique positions in the complex plane, these are those $z$ with $l=0,1,2$ , or $\theta=0,\frac{2\pi}{3},\frac{4\pi}{3}$ , and all with $r=k^{1/3}$ . Then, for a particular integer $k$ , we have 3 distinct roots that solve $1-e^{1\pi i z^3}=0$ . However, the integers $k$ that we are concerned with are restricted by those that fall within the interior of the contour $|z|=R$ . These are those $k$ where $|k|\leq n$ , or $k=0,\pm 1,\pm 2,\dots , \pm n$ . This is because of the fact that if a number $z$ is to fall within the interior of $|z|=R$ , then its modulus $|z|$ should surely be less than $R$ , or $|z|<R$ , which implies that $|z|^3<R^3$ , and since we have $n<R^3<n+1$ , this implies that $|z|^3\leq n<R^3<n+1$ (All of this was difficult for me to visualize at first. I can't really think of a better way to explain this fact, and to be honest, I only feel like I've half convinced myself of it). Given that we have our general singularity $z=re^{i\theta}$ from above, and the constraint that $|z|^3\leq n$ for a point to be in the contour, we can now put a restriction on the values of $k$ that allow $z=re^{i\theta}=k^{1/3}e^{i\theta}$ to fall within the interior of the contour. We have $|z|=|k^{1/3}|\Rightarrow |z|^3=|k|\leq n$ , so we select $k=0,\pm 1,\pm 2,\dots , \pm n$ as previously stated. Now that we have a finite number of singularities that fall within the interior of the contour, we can count them and see that there are $2n$ values of $k$ (not counting $k=0$ ) and 3 values of $l$ , which makes for $6n$ distinct singularities. When $k=0$ , we only count 1 singularity, since the length of $z$ just becomes 0 and changing to different angles makes no difference in its distinct position on the complex plane. We let all of the $6n$ distinct non-zero singularities be defined as $z_{k,l}=k^{1/3}e^{i\frac{2\pi}{3}l}$ for ranges of $k$ and $l$ previously defined. We now compute the integral using the Residue theorem. Let $f(z)=\frac{z^2}{1-e^{2\pi i z^3}}$ . This is $\oint_{|z|=R}\frac{z^2}{1-e^{2\pi i z^3}}dz =\oint_{|z|=R}f(z)dz=2\pi i \left[ \sum_{k=1}^{n}\sum_{l=0}^{2}(Res(f(z),z_{k,l})) +\sum_{k=1}^{n}\sum_{l=0}^{2}(Res(f(z),z_{-k,l})) +Res(f(z),0)\right]$ . Now to compute the residue for each non-zero singularity $z_{k,l}$ . I claim that each $z_{k,l}$ is a finite pole of order 1, or a simple pole. This can be shown by taking \begin{eqnarray} \lim_{z\to z_{k,l}}(z-z_{k,l})f(z)\\ =\lim_{z\to z_{k,l}}(z-z_{k,l})\frac{z^2}{1-e^{2\pi i z^3}}\\ =\lim_{z\to z_{k,l}}\frac{z^3-z_{k,l}z^2}{1-e^{2\pi i z^3}}\\ =\lim_{z\to z_{k,l}}\frac{3z^2-2z_{k,l}z}{-e^{2\pi i z^3}(6\pi i z^2)}\\ =-\frac{1}{6\pi i}\lim_{z\to z_{k,l}}\frac{3-2z_{k,l}z^{-1}}{e^{2\pi i z^3}}\\ =-\frac{1}{6\pi i}\frac{3-2z_{k,l}z_{k,l}^{-1}}{e^{2\pi i z_{k,l}^3}}\\ =-\frac{1}{6\pi i}\frac{1}{e^{2\pi i z_{k,l}^3}} \end{eqnarray} Since this value is certainly not zero, each non-zero $z_{k,l}$ is indeed a simple pole, and it just happens that the limit we just computed is the same limit that computes exactly the residue at the point $z_{k,l}$ , since it is a simple pole. Since $z_{k,l}^3=k$ as we have previously defined we then have $-\frac{1}{6\pi i}\frac{1}{e^{2\pi i k}}$ , where $e^{2\pi i k}=1$ since the coefficient $k$ is an integer. This leaves us with a residue of $-\frac{1}{6\pi i}$ for all non-zero $z_{k,l}$ . Now we look at the residue at $z=0$ . We similarly use a limit to simultaneously show that $f(z)$ has a simple pole at $z=0$ and compute the residue at that pole. \begin{eqnarray} \lim_{z\to 0}zf(z)\\ =\lim_{z\to 0}z\frac{z^2}{1-e^{2\pi i z^3}}\\ =\lim_{z\to 0}\frac{z^3}{1-e^{2\pi i z^3}}\\ =\lim_{z\to 0}\frac{3z^2}{-e^{2\pi i z^3}(6\pi i z^2)}\\ =-\frac{1}{2\pi i}\lim_{z\to 0}\frac{1}{e^{2\pi i z^3}}\\ =-\frac{1}{2\pi i} \end{eqnarray} This gives the residue $Res(f(z),0)=-\frac{1}{2\pi i}$ . With the residues $Res(f(z),z_{k,l})=-\frac{1}{6\pi i}$ for all valid $k,l$ from before, this gives $$ \oint_{|z|=R}\frac{z^2}{1-e^{2\pi i z^3}}dz =\oint_{|z|=R}f(z)dz =2\pi i \left[ \sum_{k=1}^{n}\sum_{l=0}^{2}(Res(f(z),z_{k,l})) +\sum_{k=1}^{n}\sum_{l=0}^{2}(Res(f(z),z_{-k,l})) +Res(f(z),0)\right] = 2\pi i \left[ \sum_{k=1}^{n}\sum_{l=0}^{2}(-\frac{1}{6\pi i}) +\sum_{k=1}^{n}\sum_{l=0}^{2}(-\frac{1}{6\pi i}) -\frac{1}{2\pi i}\right] = 2\pi i \left[ 3n(-\frac{1}{6\pi i}) +3n(-\frac{1}{6\pi i}) -\frac{1}{2\pi i}\right] = 2\pi i \left[ 6n(-\frac{1}{6\pi i}) -\frac{1}{2\pi i}\right] = 6n(-\frac{1}{3}) -1 = -2n-1 $$ So my end answer is $-2n-1$ , but the answer bank says $2n+1$ , without much additional explanation. Is there any place I messed up? Thanks.","I'm a second-year undergraduate in a non-major complex analysis course. We just started looking at using residues to compute the values of contour integrals, and I've run into a homework problem that's giving me some trouble. I spent a lot of time on this one and I think I got it, but my answer is off by a negative compared to the one in a student-created answer bank that on rare occasion does have incorrect answers, but is usually right. I'm looking for help confirming my thought process and making sure that I didn't make any mistakes here. The integral is with for positive integer . I started by identifying all singularities as those where , and discovered that this is true exactly when for some integer . I then let , which gives , where is an integer. Since is like a ""3rd root of "" (like a 3rd root of unity), there are 3 of them with unique positions in the complex plane, these are those with , or , and all with . Then, for a particular integer , we have 3 distinct roots that solve . However, the integers that we are concerned with are restricted by those that fall within the interior of the contour . These are those where , or . This is because of the fact that if a number is to fall within the interior of , then its modulus should surely be less than , or , which implies that , and since we have , this implies that (All of this was difficult for me to visualize at first. I can't really think of a better way to explain this fact, and to be honest, I only feel like I've half convinced myself of it). Given that we have our general singularity from above, and the constraint that for a point to be in the contour, we can now put a restriction on the values of that allow to fall within the interior of the contour. We have , so we select as previously stated. Now that we have a finite number of singularities that fall within the interior of the contour, we can count them and see that there are values of (not counting ) and 3 values of , which makes for distinct singularities. When , we only count 1 singularity, since the length of just becomes 0 and changing to different angles makes no difference in its distinct position on the complex plane. We let all of the distinct non-zero singularities be defined as for ranges of and previously defined. We now compute the integral using the Residue theorem. Let . This is . Now to compute the residue for each non-zero singularity . I claim that each is a finite pole of order 1, or a simple pole. This can be shown by taking Since this value is certainly not zero, each non-zero is indeed a simple pole, and it just happens that the limit we just computed is the same limit that computes exactly the residue at the point , since it is a simple pole. Since as we have previously defined we then have , where since the coefficient is an integer. This leaves us with a residue of for all non-zero . Now we look at the residue at . We similarly use a limit to simultaneously show that has a simple pole at and compute the residue at that pole. This gives the residue . With the residues for all valid from before, this gives So my end answer is , but the answer bank says , without much additional explanation. Is there any place I messed up? Thanks.","\oint_{|z|=R}\frac{z^2}{1-e^{2\pi i z^3}}dz n<R^3<n+1 n z 1-e^{2\pi i z^3}=0 z^3=k k z=re^{i\theta} z^3=k\Rightarrow r^3e^{3i\theta}=ke^{i(0)}\Rightarrow r=k^{1/3},\theta=\frac{2\pi l}{3} l z k z l=0,1,2 \theta=0,\frac{2\pi}{3},\frac{4\pi}{3} r=k^{1/3} k 1-e^{1\pi i z^3}=0 k |z|=R k |k|\leq n k=0,\pm 1,\pm 2,\dots , \pm n z |z|=R |z| R |z|<R |z|^3<R^3 n<R^3<n+1 |z|^3\leq n<R^3<n+1 z=re^{i\theta} |z|^3\leq n k z=re^{i\theta}=k^{1/3}e^{i\theta} |z|=|k^{1/3}|\Rightarrow |z|^3=|k|\leq n k=0,\pm 1,\pm 2,\dots , \pm n 2n k k=0 l 6n k=0 z 6n z_{k,l}=k^{1/3}e^{i\frac{2\pi}{3}l} k l f(z)=\frac{z^2}{1-e^{2\pi i z^3}} \oint_{|z|=R}\frac{z^2}{1-e^{2\pi i z^3}}dz
=\oint_{|z|=R}f(z)dz=2\pi i \left[
\sum_{k=1}^{n}\sum_{l=0}^{2}(Res(f(z),z_{k,l}))
+\sum_{k=1}^{n}\sum_{l=0}^{2}(Res(f(z),z_{-k,l}))
+Res(f(z),0)\right] z_{k,l} z_{k,l} \begin{eqnarray}
\lim_{z\to z_{k,l}}(z-z_{k,l})f(z)\\
=\lim_{z\to z_{k,l}}(z-z_{k,l})\frac{z^2}{1-e^{2\pi i z^3}}\\
=\lim_{z\to z_{k,l}}\frac{z^3-z_{k,l}z^2}{1-e^{2\pi i z^3}}\\
=\lim_{z\to z_{k,l}}\frac{3z^2-2z_{k,l}z}{-e^{2\pi i z^3}(6\pi i z^2)}\\
=-\frac{1}{6\pi i}\lim_{z\to z_{k,l}}\frac{3-2z_{k,l}z^{-1}}{e^{2\pi i z^3}}\\
=-\frac{1}{6\pi i}\frac{3-2z_{k,l}z_{k,l}^{-1}}{e^{2\pi i z_{k,l}^3}}\\
=-\frac{1}{6\pi i}\frac{1}{e^{2\pi i z_{k,l}^3}}
\end{eqnarray} z_{k,l} z_{k,l} z_{k,l}^3=k -\frac{1}{6\pi i}\frac{1}{e^{2\pi i k}} e^{2\pi i k}=1 k -\frac{1}{6\pi i} z_{k,l} z=0 f(z) z=0 \begin{eqnarray}
\lim_{z\to 0}zf(z)\\
=\lim_{z\to 0}z\frac{z^2}{1-e^{2\pi i z^3}}\\
=\lim_{z\to 0}\frac{z^3}{1-e^{2\pi i z^3}}\\
=\lim_{z\to 0}\frac{3z^2}{-e^{2\pi i z^3}(6\pi i z^2)}\\
=-\frac{1}{2\pi i}\lim_{z\to 0}\frac{1}{e^{2\pi i z^3}}\\
=-\frac{1}{2\pi i}
\end{eqnarray} Res(f(z),0)=-\frac{1}{2\pi i} Res(f(z),z_{k,l})=-\frac{1}{6\pi i} k,l 
\oint_{|z|=R}\frac{z^2}{1-e^{2\pi i z^3}}dz
=\oint_{|z|=R}f(z)dz
=2\pi i \left[
\sum_{k=1}^{n}\sum_{l=0}^{2}(Res(f(z),z_{k,l}))
+\sum_{k=1}^{n}\sum_{l=0}^{2}(Res(f(z),z_{-k,l}))
+Res(f(z),0)\right]
=
2\pi i \left[
\sum_{k=1}^{n}\sum_{l=0}^{2}(-\frac{1}{6\pi i})
+\sum_{k=1}^{n}\sum_{l=0}^{2}(-\frac{1}{6\pi i})
-\frac{1}{2\pi i}\right]
=
2\pi i \left[
3n(-\frac{1}{6\pi i})
+3n(-\frac{1}{6\pi i})
-\frac{1}{2\pi i}\right]
=
2\pi i \left[
6n(-\frac{1}{6\pi i})
-\frac{1}{2\pi i}\right]
=
6n(-\frac{1}{3})
-1
=
-2n-1
 -2n-1 2n+1","['complex-analysis', 'solution-verification', 'contour-integration', 'residue-calculus']"
81,A bounded set in $\mathbb{C}$ is simply connected iff the complement is connected.,A bounded set in  is simply connected iff the complement is connected.,\mathbb{C},"In complex analysis, there is a classical result concerning simple connectivity. A set $E \subset \mathbb{C}$ is open, bounded and connected. Then $E$ is simply connected iff $E^c$ is connected. I know a proof by means of complex analysis. Its sketch is as follows: "" $\Leftarrow$ "": By the general Cauchy Theorem, for a closed curve $\gamma$ in $E$ and a function $f \in H(E)$ , \begin{equation} \int_\gamma f \operatorname{d\!} z=0. \end{equation} Hence $E$ is holomorphically simply connected. Due to the Riemann Mapping Theorem, $E$ is homeomorphic to $\mathbb{D}$ , providing that $E$ is simply connected. "" $\Rightarrow$ "": If $E^c$ is not connected, we can construct a closed curve $\gamma$ in $E$ such that $\operatorname{Ind}_\gamma(a)\ne 0$ for some $a \in E^c$ , which contradicts the fact that $E$ is simply connected. My question is whether there is a topological proof of it. Thank you very much!","In complex analysis, there is a classical result concerning simple connectivity. A set is open, bounded and connected. Then is simply connected iff is connected. I know a proof by means of complex analysis. Its sketch is as follows: "" "": By the general Cauchy Theorem, for a closed curve in and a function , Hence is holomorphically simply connected. Due to the Riemann Mapping Theorem, is homeomorphic to , providing that is simply connected. "" "": If is not connected, we can construct a closed curve in such that for some , which contradicts the fact that is simply connected. My question is whether there is a topological proof of it. Thank you very much!","E \subset \mathbb{C} E E^c \Leftarrow \gamma E f \in H(E) \begin{equation}
\int_\gamma f \operatorname{d\!} z=0.
\end{equation} E E \mathbb{D} E \Rightarrow E^c \gamma E \operatorname{Ind}_\gamma(a)\ne 0 a \in E^c E","['complex-analysis', 'algebraic-topology']"
82,Is there any geometric explanation of Koebe's $1/4$ theorem?,Is there any geometric explanation of Koebe's  theorem?,1/4,"Koebe's $1/4$ theorem claims that if $f:\mathbb{D}\to \mathbb{C}$ is an injective holomorphic function defined on a unit disk such that $f(0) =0$ and $f'(0)= 1$ , then the image $f(\mathbb{D})$ of $\mathbb{D}$ contains an open disk of radius $1/4$ centered at the origin. There are some known proofs of the theorem, but all of them seems to be nonintuitive.  For example, one proof uses Bieberbach's coefficient theorem. Is there any possible geometric explanation or even proof of Koebe's theorem? Thanks in advance.","Koebe's theorem claims that if is an injective holomorphic function defined on a unit disk such that and , then the image of contains an open disk of radius centered at the origin. There are some known proofs of the theorem, but all of them seems to be nonintuitive.  For example, one proof uses Bieberbach's coefficient theorem. Is there any possible geometric explanation or even proof of Koebe's theorem? Thanks in advance.",1/4 f:\mathbb{D}\to \mathbb{C} f(0) =0 f'(0)= 1 f(\mathbb{D}) \mathbb{D} 1/4,['complex-analysis']
83,Evaluation of $\int_0^1\frac{\ln(x)\ln(x+1)\ln(x^2+x+1)}{(1-x)(1+x^2)}dx$,Evaluation of,\int_0^1\frac{\ln(x)\ln(x+1)\ln(x^2+x+1)}{(1-x)(1+x^2)}dx,"I originally saw this logarithmic integral pop up on the Integrals and Series forum but due to the inactivity there no conversation has developed. I originally tried generalizing the integral to $$I(\alpha,\;\beta)=\int_0^1\frac{\ln(x)\ln(\alpha x+1)\ln(\beta(x^2+x)+1)}{(1-x)(1+x^2)}dx$$ and differentiating under the integral sign with respect to $\alpha$ and $\beta$ but it didn't seem to go anywhere. However, I did get the related integrals $$\int_0^1\frac{(x^2+x)\ln(x)}{(1-x)(1+x^2)(x^2+x+1)}dx=-\frac{17\pi^2}{432}$$ and $$\int_0^1\frac{(x^2+x)\ln(x)}{(1-x^2)(1+x^2)(x^2+x+1)}dx=\frac{-1296G-115\pi^2+192\psi\left(\frac{1}{3}\right)-96\psi\left(\frac{2}{3}\right)}{2592}.$$ My questions are: What is the closed form of this integral, if there is any? And are there any methods or techniques that would be effective at attacking integrals with multiple logarithms in the numerator of the integrand? Edit: G is Catalan's constant and psi is the digamma function.","I originally saw this logarithmic integral pop up on the Integrals and Series forum but due to the inactivity there no conversation has developed. I originally tried generalizing the integral to and differentiating under the integral sign with respect to and but it didn't seem to go anywhere. However, I did get the related integrals and My questions are: What is the closed form of this integral, if there is any? And are there any methods or techniques that would be effective at attacking integrals with multiple logarithms in the numerator of the integrand? Edit: G is Catalan's constant and psi is the digamma function.","I(\alpha,\;\beta)=\int_0^1\frac{\ln(x)\ln(\alpha x+1)\ln(\beta(x^2+x)+1)}{(1-x)(1+x^2)}dx \alpha \beta \int_0^1\frac{(x^2+x)\ln(x)}{(1-x)(1+x^2)(x^2+x+1)}dx=-\frac{17\pi^2}{432} \int_0^1\frac{(x^2+x)\ln(x)}{(1-x^2)(1+x^2)(x^2+x+1)}dx=\frac{-1296G-115\pi^2+192\psi\left(\frac{1}{3}\right)-96\psi\left(\frac{2}{3}\right)}{2592}.","['complex-analysis', 'definite-integrals', 'special-functions']"
84,Are Differential Structure of a Complex Number and its Field Structure Independent?,Are Differential Structure of a Complex Number and its Field Structure Independent?,,"It is well known that $\mathbb{R}^2$ has a very famous field structure defiend by $(a,b)(c,d)=(ac-bd,ad+bc)$. And it also has a holomorphic structure, which makes $z\mapsto z$ differentiable but not $z\mapsto \bar{z}$. One of my friends asked me about the difference between $\mathbb{R}^2$ and $\mathbb{C}$, and I stated these two structures, but when I did it, I realized that I am not aware of the relation, or independence, of these two structures. So is one of these structures implies the other? So, to elaborate my question more, it would be like this: Suppose we have a holomorphic structure (of course with topology) on $\mathbb{R}^2$ which makes $(x,y)\mapsto(x,y)$ holomorphic but not $(x,y)\mapsto (x,-y)$. Now we want to find a field structure $\cdot:\mathbb{R}^2 \times \mathbb{R}^2 \to \mathbb{R}^2$ which is compatible with the holomorphic structure; $z \mapsto a\cdot z$ is complex-differentiable, and its derivative is a constant $a$. (edit) And of course the operation should be continuous with respect to the usual topology. Is it always isomophic to $\mathbb{C}$? Here I stated the holomorphic structure first, but I am also curious about the other way: defining the field structure first and finding the 'compatible' holomorphic structure. And I am also curious if there is any way to see that one of these structures are actually implying the other 'directly,' which is the fact that I am not really sure of. Thanks in advance! (edit) I stated that the operation should be continuous with respect to the usual topology. (edit) I changed ""differentiability"" condition into ""holomorphicity.""","It is well known that $\mathbb{R}^2$ has a very famous field structure defiend by $(a,b)(c,d)=(ac-bd,ad+bc)$. And it also has a holomorphic structure, which makes $z\mapsto z$ differentiable but not $z\mapsto \bar{z}$. One of my friends asked me about the difference between $\mathbb{R}^2$ and $\mathbb{C}$, and I stated these two structures, but when I did it, I realized that I am not aware of the relation, or independence, of these two structures. So is one of these structures implies the other? So, to elaborate my question more, it would be like this: Suppose we have a holomorphic structure (of course with topology) on $\mathbb{R}^2$ which makes $(x,y)\mapsto(x,y)$ holomorphic but not $(x,y)\mapsto (x,-y)$. Now we want to find a field structure $\cdot:\mathbb{R}^2 \times \mathbb{R}^2 \to \mathbb{R}^2$ which is compatible with the holomorphic structure; $z \mapsto a\cdot z$ is complex-differentiable, and its derivative is a constant $a$. (edit) And of course the operation should be continuous with respect to the usual topology. Is it always isomophic to $\mathbb{C}$? Here I stated the holomorphic structure first, but I am also curious about the other way: defining the field structure first and finding the 'compatible' holomorphic structure. And I am also curious if there is any way to see that one of these structures are actually implying the other 'directly,' which is the fact that I am not really sure of. Thanks in advance! (edit) I stated that the operation should be continuous with respect to the usual topology. (edit) I changed ""differentiability"" condition into ""holomorphicity.""",,"['complex-analysis', 'differential-topology']"
85,On the complex function $f(s)=\sum\limits_{n=1}^\infty\sigma(n)^{-s}$,On the complex function,f(s)=\sum\limits_{n=1}^\infty\sigma(n)^{-s},"Let $s=x+iy$ the complex variable (if you want a difffernt notation you are welcome), then I know that $\sum_{n=1}^\infty n^{-s}$ converges for $\Re s>1$. On the other hand let $\sigma(n)=\sum_{d\mid n}d$ the sum of divisors function . An important fact is that $\sigma(p)=p+1$ if and only i $p$ is a prime number . We define for some abscissa of convergence $$\sum_{n=1}^\infty\frac{1}{(\sigma(n))^s}.$$ Since applying the triangle inequality one has $$\left|\sum_{n=1}^\infty\frac{1}{(\sigma(n))^s}\right|\leq\sum_{n=1}^\infty\frac{1}{|\sigma(n)^s|}=\sum_{n=1}^\infty\frac{1}{\sigma(n)^{\Re s}},$$ and one knows that $\sigma(n)\geq n+1>n$ for each $n>1$ (notice that $\sigma(1)=1$) then $(\sigma(n))^{-\Re s}<n^{-\Re s}$ with convergence of the infinite series thus for $\Re s>1$ by the comparison test . And since $\sum_{p \text{ prime}}1/p$ diverges (thus by comparison also $\sum_{p \text{ prime}}1/(p+1)$) I believe that the abscissa of convergence is $1$ (please if there is some mistake or inaccurancie in my claims say me, I want learn and write mathematics rigurously). Thus the information that I can deduce for this function is that has a pole at $s=1$ and converges in the half-plane $\Re s>1$. But I don't know what different claims can be deduced easily. Question. I would like to learn more about complex analysis, what's about this function $$f(s)=\sum_{n=1}^\infty\frac{1}{(\sigma(n))^s}$$   concerning if  is it meromorphic , (I hope that my words and claims are rights), it is possible /feasible an analytic continuation to different regions of the complex plane, or can you deduce other easy things about non-vanishing for $\Re s>1$...? Has zeros ? Thus I am asking about what's things are easily deduced for a complex function of this kind. I understand that is a question involving a lot of possible computations, but I would like to know how works with this kind of functions from the complex path. You can deduce the more relevant facts and other provide us as hints. Thanks in advance.","Let $s=x+iy$ the complex variable (if you want a difffernt notation you are welcome), then I know that $\sum_{n=1}^\infty n^{-s}$ converges for $\Re s>1$. On the other hand let $\sigma(n)=\sum_{d\mid n}d$ the sum of divisors function . An important fact is that $\sigma(p)=p+1$ if and only i $p$ is a prime number . We define for some abscissa of convergence $$\sum_{n=1}^\infty\frac{1}{(\sigma(n))^s}.$$ Since applying the triangle inequality one has $$\left|\sum_{n=1}^\infty\frac{1}{(\sigma(n))^s}\right|\leq\sum_{n=1}^\infty\frac{1}{|\sigma(n)^s|}=\sum_{n=1}^\infty\frac{1}{\sigma(n)^{\Re s}},$$ and one knows that $\sigma(n)\geq n+1>n$ for each $n>1$ (notice that $\sigma(1)=1$) then $(\sigma(n))^{-\Re s}<n^{-\Re s}$ with convergence of the infinite series thus for $\Re s>1$ by the comparison test . And since $\sum_{p \text{ prime}}1/p$ diverges (thus by comparison also $\sum_{p \text{ prime}}1/(p+1)$) I believe that the abscissa of convergence is $1$ (please if there is some mistake or inaccurancie in my claims say me, I want learn and write mathematics rigurously). Thus the information that I can deduce for this function is that has a pole at $s=1$ and converges in the half-plane $\Re s>1$. But I don't know what different claims can be deduced easily. Question. I would like to learn more about complex analysis, what's about this function $$f(s)=\sum_{n=1}^\infty\frac{1}{(\sigma(n))^s}$$   concerning if  is it meromorphic , (I hope that my words and claims are rights), it is possible /feasible an analytic continuation to different regions of the complex plane, or can you deduce other easy things about non-vanishing for $\Re s>1$...? Has zeros ? Thus I am asking about what's things are easily deduced for a complex function of this kind. I understand that is a question involving a lot of possible computations, but I would like to know how works with this kind of functions from the complex path. You can deduce the more relevant facts and other provide us as hints. Thanks in advance.",,"['complex-analysis', 'convergence-divergence']"
86,Geometry of the zeros of a power series.,Geometry of the zeros of a power series.,,"This is probably a basic question that is easily googlable, but it seems that I dont have the right keywords. So my question is, having some power series $$ f(z)=\sum_{k=0}^{\infty}C_{k}z^{k}, z\in\mathbb{C}, C_{k}\in \mathbb{R}\;\wedge\;C_{0}=1 $$ Is there some theorem relating the coeficients $C_{k}$ of the power series to the geometry of the zeros? More specifically: Is there some theorem implying  that the only zeros of $f(z)$ are real zeros if the coefficients $C_{k}$ have some specific properties? References are welcome. Thanks in advance.","This is probably a basic question that is easily googlable, but it seems that I dont have the right keywords. So my question is, having some power series $$ f(z)=\sum_{k=0}^{\infty}C_{k}z^{k}, z\in\mathbb{C}, C_{k}\in \mathbb{R}\;\wedge\;C_{0}=1 $$ Is there some theorem relating the coeficients $C_{k}$ of the power series to the geometry of the zeros? More specifically: Is there some theorem implying  that the only zeros of $f(z)$ are real zeros if the coefficients $C_{k}$ have some specific properties? References are welcome. Thanks in advance.",,"['complex-analysis', 'analysis', 'reference-request', 'power-series', 'roots']"
87,Analytic function with a non-essential singularity at $\infty$ reduces to a polynomial.,Analytic function with a non-essential singularity at  reduces to a polynomial.,\infty,"Show that a function $f(z)$, which is analytic in the whole plane and has a non-essential singularity at $\infty$ reduces to a polynomial. This question has been asked previously and I have gone through a solution. Following is a line of reasoning I came up with independently, but I need to know if it is sound enough. $f(z)$ has no poles in the complex plane. Then $g(z) = f(\frac{1}{z})$ has a non-essential singularity at $z=0$ and none other. Suppose the algebraic order of this singularity of $g(z)$ is $h$. Following cases are possible. $h=0$. Then $g(0)\ne 0$ and $g(z)$ is analytic at $0$. Then $[f(z)]_{z\rightarrow \infty}$ is finite. Since $f(z)$ is analytic, from Liouville's Theorem it follows that $f(z)$ is a constant. $h\lt 0$. Then $g(z)$ has a zero of order $h$ and the same conclusion is possible as in 1. $h>0$. In this case $g(z)$ has a pole of order $h$ at $0$. By Taylor's Theorem $$z^hg(z)=B_h+B_{h-1}z+\cdots + B_1z^{h-1} + \phi(z)z^h$$where $\phi(z)$ is analytic at $0$. For $z\ne0$, it may be now written as $$g(z)=\frac{B_h}{z^h}+\cdots+\frac{B_1}{z}+\phi(z).$$Since the only singular part of $g(z)$ is in the RHS of above apart from $\phi(z)$, it must be true that $\phi(z)$ has no singularities in the extended plane. Thus $\phi(z)$ is a constant. By $f(z) = g(\frac{1}{z})$, $f(z)$ is a polynomial. Thanks.","Show that a function $f(z)$, which is analytic in the whole plane and has a non-essential singularity at $\infty$ reduces to a polynomial. This question has been asked previously and I have gone through a solution. Following is a line of reasoning I came up with independently, but I need to know if it is sound enough. $f(z)$ has no poles in the complex plane. Then $g(z) = f(\frac{1}{z})$ has a non-essential singularity at $z=0$ and none other. Suppose the algebraic order of this singularity of $g(z)$ is $h$. Following cases are possible. $h=0$. Then $g(0)\ne 0$ and $g(z)$ is analytic at $0$. Then $[f(z)]_{z\rightarrow \infty}$ is finite. Since $f(z)$ is analytic, from Liouville's Theorem it follows that $f(z)$ is a constant. $h\lt 0$. Then $g(z)$ has a zero of order $h$ and the same conclusion is possible as in 1. $h>0$. In this case $g(z)$ has a pole of order $h$ at $0$. By Taylor's Theorem $$z^hg(z)=B_h+B_{h-1}z+\cdots + B_1z^{h-1} + \phi(z)z^h$$where $\phi(z)$ is analytic at $0$. For $z\ne0$, it may be now written as $$g(z)=\frac{B_h}{z^h}+\cdots+\frac{B_1}{z}+\phi(z).$$Since the only singular part of $g(z)$ is in the RHS of above apart from $\phi(z)$, it must be true that $\phi(z)$ has no singularities in the extended plane. Thus $\phi(z)$ is a constant. By $f(z) = g(\frac{1}{z})$, $f(z)$ is a polynomial. Thanks.",,"['complex-analysis', 'proof-verification']"
88,How to choose the right branch to find the roots.,How to choose the right branch to find the roots.,,"I want to find the roots of  $$f(z)=\left[a+zg(z)\right]^2+g(z)^2=0$$ Where $a$ is real number and: $$ g(z)=\frac{1}{2\sqrt{z^2+1}}\ln\left(\frac{z+\sqrt{z^2+1}}{z-\sqrt{z^2+1}}\right) $$ It is known that $f(z)=0$ has double complex roots when $a\in(-\pi/2,\pi/2)$, no roots when $a>\pi/2$ and four complex roots when $a<-\pi/2$. It also says that the complex roots are purely imaginary and comes in conjugate pairs. (The conclusion can be visualized by the accepted answer here .) For example: when $a=-\pi$,  $z=\pm 8.02398 i, \quad\pm14.5019 i$. when $a=-\pi/6$,  $z=\pm 1.62943 i $ when $a=\pi/6$,  $z=\pm 0.556395 i $ Note if you have an analytical answer in mind for the above conclusion you can stop here and kindly post it in an answer. I want a more analytical method to get that conclusion , so I did this: $$ a=-\frac{z\pm\mathrm{i}}{2\sqrt{z^2+1}}\ln\left(\frac{z+\sqrt{z^2+1}}{z-\sqrt{z^2+1}}\right). $$ Let $z=\sinh q$, then $\sqrt{z^2+1}=\cosh q$.  $$ \ln\left(\frac{z+\sqrt{z^2+1}}{z-\sqrt{z^2+1}}\right)=2q + 2n\pi+\pi i \quad n\in \mathcal{N} $$ So we get: $$ a=-\frac{\sinh q \pm i}{\cosh q}(q+n\pi i+ \frac{\pi}{2}i) $$ Let $p=q+n\pi i+ \frac{\pi}{2}i$, then $z=\sinh q = (-1)^{n+1}i\cosh p$, and $\cosh q = (-1)^{n+1} i \sinh p$ Substitute to the expression of $a$: $$ a=-\frac{\cosh p\pm 1}{\sinh p}p = -p\coth\frac{p}{2} \qquad\text{or} \qquad -p\tanh\frac{p}{2} $$ Recall that $a$ is real, so $p$ must be purely real or purely imaginary(Is this claim true?), but $z=\pm i \cosh p$ is always purely imaginary.  So I've proved that the roots must be purely imaginary. If $p=ip_0$ is purely imaginary, $z=\pm i \cos p_0$. The form of the equation for $a$ reads: $$ a = p_0 \cot \frac{p_0}{2} \quad\text{  or  }\quad p_0 \tan \frac{p_0}{2}$$ First we reckon $p$ to be real, and plot out the RHS of w.r.t $p$: When $p=-\pi$, we read out from the graph, $p=2.77168$ and $3.36624$. $z=\pm \cosh p$ give us the four desired root. But the problem is, when $a\in(-2,-\pi/2)$, there seems only one pair of roots from the graph. When $p=-\pi/6$, we read out from the graph, that $p=1.07018$, $z=\pm i\cosh p=\pm 1.62943 i$, which again give us the desired pair of roots. However, what if $a>0$, for example $a=\pi/6$, can't read out from this graph. Next we reckon $p=ip_0$: There are many crossings, read the ones most close to the $y$ axis(I don't have a particular reason). when $p=\pi/6$, $p_0 = 0.980755$ and $z=\pm i\cos p_0 = \pm 0.556395 i$. We get the desired results, but why should I choose the one nearest to the $y$ axis, there are many roots after all.  Besides, it seems that from this graph that $a>\pi/2$ we still have solutions, which is not right. I also want to mention that, the intersection of blue and orange lines  has the height of $\pi/2$. when $p=-\pi/6$ or $-\pi$, we can never get the right results, for $|\cos p_0| <=1$. Question is that what's the hidden flaws in this derivation? How can I fix them so that I can get the desired conclusion and results?","I want to find the roots of  $$f(z)=\left[a+zg(z)\right]^2+g(z)^2=0$$ Where $a$ is real number and: $$ g(z)=\frac{1}{2\sqrt{z^2+1}}\ln\left(\frac{z+\sqrt{z^2+1}}{z-\sqrt{z^2+1}}\right) $$ It is known that $f(z)=0$ has double complex roots when $a\in(-\pi/2,\pi/2)$, no roots when $a>\pi/2$ and four complex roots when $a<-\pi/2$. It also says that the complex roots are purely imaginary and comes in conjugate pairs. (The conclusion can be visualized by the accepted answer here .) For example: when $a=-\pi$,  $z=\pm 8.02398 i, \quad\pm14.5019 i$. when $a=-\pi/6$,  $z=\pm 1.62943 i $ when $a=\pi/6$,  $z=\pm 0.556395 i $ Note if you have an analytical answer in mind for the above conclusion you can stop here and kindly post it in an answer. I want a more analytical method to get that conclusion , so I did this: $$ a=-\frac{z\pm\mathrm{i}}{2\sqrt{z^2+1}}\ln\left(\frac{z+\sqrt{z^2+1}}{z-\sqrt{z^2+1}}\right). $$ Let $z=\sinh q$, then $\sqrt{z^2+1}=\cosh q$.  $$ \ln\left(\frac{z+\sqrt{z^2+1}}{z-\sqrt{z^2+1}}\right)=2q + 2n\pi+\pi i \quad n\in \mathcal{N} $$ So we get: $$ a=-\frac{\sinh q \pm i}{\cosh q}(q+n\pi i+ \frac{\pi}{2}i) $$ Let $p=q+n\pi i+ \frac{\pi}{2}i$, then $z=\sinh q = (-1)^{n+1}i\cosh p$, and $\cosh q = (-1)^{n+1} i \sinh p$ Substitute to the expression of $a$: $$ a=-\frac{\cosh p\pm 1}{\sinh p}p = -p\coth\frac{p}{2} \qquad\text{or} \qquad -p\tanh\frac{p}{2} $$ Recall that $a$ is real, so $p$ must be purely real or purely imaginary(Is this claim true?), but $z=\pm i \cosh p$ is always purely imaginary.  So I've proved that the roots must be purely imaginary. If $p=ip_0$ is purely imaginary, $z=\pm i \cos p_0$. The form of the equation for $a$ reads: $$ a = p_0 \cot \frac{p_0}{2} \quad\text{  or  }\quad p_0 \tan \frac{p_0}{2}$$ First we reckon $p$ to be real, and plot out the RHS of w.r.t $p$: When $p=-\pi$, we read out from the graph, $p=2.77168$ and $3.36624$. $z=\pm \cosh p$ give us the four desired root. But the problem is, when $a\in(-2,-\pi/2)$, there seems only one pair of roots from the graph. When $p=-\pi/6$, we read out from the graph, that $p=1.07018$, $z=\pm i\cosh p=\pm 1.62943 i$, which again give us the desired pair of roots. However, what if $a>0$, for example $a=\pi/6$, can't read out from this graph. Next we reckon $p=ip_0$: There are many crossings, read the ones most close to the $y$ axis(I don't have a particular reason). when $p=\pi/6$, $p_0 = 0.980755$ and $z=\pm i\cos p_0 = \pm 0.556395 i$. We get the desired results, but why should I choose the one nearest to the $y$ axis, there are many roots after all.  Besides, it seems that from this graph that $a>\pi/2$ we still have solutions, which is not right. I also want to mention that, the intersection of blue and orange lines  has the height of $\pi/2$. when $p=-\pi/6$ or $-\pi$, we can never get the right results, for $|\cos p_0| <=1$. Question is that what's the hidden flaws in this derivation? How can I fix them so that I can get the desired conclusion and results?",,"['complex-analysis', 'roots', 'branch-cuts', 'multivalued-functions']"
89,How to compute intersection numbers in practice?,How to compute intersection numbers in practice?,,"When speaking about plane curves, one of the most fundamental and important results is Bézout's Theorem , which states that over an algebraically closed field $k$, two plane projective curves of respective degrees $d$ and $d'$ with no common component meet in exactly $dd'$ points, counted with multiplicity. One can also compute it in several other ways, see for example this question . However, computing intersection numbers in a more general setting usually gives me a lot of trouble. Say we are working over the field of complex numbers $\mathbb{C}$ and consider a complex manifold $X$ of dimension $n$ and a complex submanifold $Y \subset X$ of dimension $m$. Then, by Poincaré duality, we get the (well-defined) fundamental class of $Y$ defined as $[Y] \colon H^{2m}(X,\mathbb{R}) \to \mathbb{R}$, by sending an $m$-form $\omega$ representing a cohomology class to $\int_Y \omega$. If $Z \subset X$ is another complex submanifold, say of dimension $n-m$, then one has $[Y]\cdot [Z] \in \mathbb{R}$, by wedging the respective representative forms and integrating over $X$. One can then show that if the intersection $Y \cap Z$ is finite, then $[Y]\cdot [Z]$ equals the cardinality of this intersection, counted with multiplicity. One standard example of computing these intersection numbers is considering the blow-up $\pi \colon \hat{X} \to X$ of $X = \mathbb{P}^2$ at a point and the computation of the self-intersection of the exceptional divisor. Then one can go one step further and define the following. $X$ is as above, $Y \subset X$ is now an irreducible analytic set of dimension $m$ and $L$ a line bundle on $X$. Then one can define $L^m.Y := \int_Y \omega^m$, where $\omega$ is a $(1,1)$-form which represents the first Chern class $c_1(L)$ of $L$. (One can also define $L^m.Y$ on singular complex spaces, say reduced. But let's say that this does not play a role in this question.) On manifolds, this is just the the fundamental class $[Y]$ evaluated at $c_1(L)^m$. This intersection number is widely used in algebraic geometry and complex analysis, for instance in nef- and ampleness criteria like Nakai-Moishezon, or in the definition of numerical equivalence and hence also in the definitions of the nef and ample cone. But how can one compute this intersection number in practice? It does not seem very appropriate to use the definitions. A lot of texts that I've been reading use somehow intuitive and not very rigor arguments, not explaining why the intersection number takes the desired value. More generally, if one has a specific variety and a line bundle on it, how can one decide via intersection numbers (i.e., what standard methods come into play) if this line bundle is ample or nef? Can somebody please give a more or less complete overview of standard methods which can be used to compute intersection numbers? It does not have to be detailed, a good reference or a good example would also satisfy me.","When speaking about plane curves, one of the most fundamental and important results is Bézout's Theorem , which states that over an algebraically closed field $k$, two plane projective curves of respective degrees $d$ and $d'$ with no common component meet in exactly $dd'$ points, counted with multiplicity. One can also compute it in several other ways, see for example this question . However, computing intersection numbers in a more general setting usually gives me a lot of trouble. Say we are working over the field of complex numbers $\mathbb{C}$ and consider a complex manifold $X$ of dimension $n$ and a complex submanifold $Y \subset X$ of dimension $m$. Then, by Poincaré duality, we get the (well-defined) fundamental class of $Y$ defined as $[Y] \colon H^{2m}(X,\mathbb{R}) \to \mathbb{R}$, by sending an $m$-form $\omega$ representing a cohomology class to $\int_Y \omega$. If $Z \subset X$ is another complex submanifold, say of dimension $n-m$, then one has $[Y]\cdot [Z] \in \mathbb{R}$, by wedging the respective representative forms and integrating over $X$. One can then show that if the intersection $Y \cap Z$ is finite, then $[Y]\cdot [Z]$ equals the cardinality of this intersection, counted with multiplicity. One standard example of computing these intersection numbers is considering the blow-up $\pi \colon \hat{X} \to X$ of $X = \mathbb{P}^2$ at a point and the computation of the self-intersection of the exceptional divisor. Then one can go one step further and define the following. $X$ is as above, $Y \subset X$ is now an irreducible analytic set of dimension $m$ and $L$ a line bundle on $X$. Then one can define $L^m.Y := \int_Y \omega^m$, where $\omega$ is a $(1,1)$-form which represents the first Chern class $c_1(L)$ of $L$. (One can also define $L^m.Y$ on singular complex spaces, say reduced. But let's say that this does not play a role in this question.) On manifolds, this is just the the fundamental class $[Y]$ evaluated at $c_1(L)^m$. This intersection number is widely used in algebraic geometry and complex analysis, for instance in nef- and ampleness criteria like Nakai-Moishezon, or in the definition of numerical equivalence and hence also in the definitions of the nef and ample cone. But how can one compute this intersection number in practice? It does not seem very appropriate to use the definitions. A lot of texts that I've been reading use somehow intuitive and not very rigor arguments, not explaining why the intersection number takes the desired value. More generally, if one has a specific variety and a line bundle on it, how can one decide via intersection numbers (i.e., what standard methods come into play) if this line bundle is ample or nef? Can somebody please give a more or less complete overview of standard methods which can be used to compute intersection numbers? It does not have to be detailed, a good reference or a good example would also satisfy me.",,"['complex-analysis', 'algebraic-geometry', 'intersection-theory']"
90,Analytic function defined in the punctured unit disk real in the unit circle then $f(z)=\overline{f(1/\overline{z})}$,Analytic function defined in the punctured unit disk real in the unit circle then,f(z)=\overline{f(1/\overline{z})},"This is a follow up to a question I asked a few days ago. I initially thought I understood the solution to the problem, but there's something I can't quite grasp: Let $f$ be analytic in the set $\{ x \in \mathbb{C} : 0<|z|<1\}$. If $f$ is real in the unit circle $\{z\in \mathbb{C}: |z|=1\}$, and has a continuous extension to the unit circle, then show that: $$f(z)=\overline{f\left ( \frac{1}{\overline{z}} \right )} \ \forall z\in \mathbb{C}$$ My approach was as follows : Let $\phi: \mathbb{C}\setminus\{-i\} \to \mathbb{C}\setminus \{1\}$ be given by $$\phi(z)=\frac{z-i}{z+i}$$ It is easy to prove that $\phi$ maps the upper half plane into the unit disk, this is $\phi (\mathbb{C}^+)= D$ and that it maps the real axis into the unit circle, i.e.  $|\phi(x)|=1$ for real $x$. Note that $\phi^{-1}:\mathbb{C}\setminus \{1\} \to \mathbb{C}\setminus\{-i\}$ is given by: $$\phi^{-1}(z)=i\frac{z+1}{1-z}$$ Also note that \begin{equation}\overline{\phi^{-1}(z)}=\phi^{-1}\left ( \frac{1}{\overline{z}}\right )\tag1\end{equation} Now, by the preceding remarks, the composition $g=f\circ \phi : \overline{\mathbb{C}^+}\setminus\{i\} \to \mathbb{C}$ is continuous in its domain and analytic in $\mathbb{C}^+ \setminus\{i\}$. Further, since $g(\mathbb{R})\subset \mathbb{R}$, we can apply the Schwarz reflection principle to extend $g$ to $\mathbb{C}\setminus\{i,-i\}$, that is the function $h:\mathbb{C}\setminus\{i,-i\} \to \mathbb{C}$ given by: $$h(z)=\begin{cases}g(z)=(f\circ \phi)(z) & \textrm{if}  \ z \in \overline{\mathbb{C}^+}\setminus\{i\} \\\overline{g(\overline{z})}=\overline{(f\circ \phi)(\overline {z})} & \textrm{if} \ z \in \overline{\mathbb{C}^-}\setminus\{-i\} \end{cases}\tag2$$ is analytic in $\mathbb{C}\setminus\{i,-i\}$ and verifies $h(z)=\overline{h(\overline{z})}$ for all $z \in \mathbb{C}\setminus \{i,-i\}$. Now, if we take $z\neq i,-i$, from $(1)$ and the fact that $h(z)=\overline{h(\overline{z})}$ we get that: \begin{equation}f(z)=(f\circ \phi)(\phi^{-1}(z))=h(\phi^{-1}(z))=\overline{h(\overline{\phi^{-1}(z)})}=\overline{h\left ( \phi^{-1}\left ( \frac{1}{\overline{z}}\right ) \right )}=\overline{f\left ( \frac{1}{\overline{z}} \right )}\tag3\end{equation} Which would complete the proof (the cases $z=i,-i$ are easily handled separately since the function is real in the unit circle). My question is: In $(3)$, why does $h\circ \phi^{-1}=f$ (this is used in the second and final equalities). If $\phi^{-1}(z) \in \overline{\mathbb{C}^+}\setminus\{i\}$, then in is clear from $(2)$ that $h(\phi^{-1}(z))=(f\circ \phi)(\phi^{-1}(z))=f(z)$, since this is the definition of $h$ in that region, but what if $\phi^{-1}(z) \in \overline{\mathbb{C}^-}\setminus\{-i\}$? Using $(2)$ and some other identities we already know I can get: $$h(\phi^{-1}(z))=\overline{(f\circ \phi)(\overline {\phi^{-1}z})}=\overline{(f\circ \phi)\left ( \phi^{-1}\left ( \frac{1}{\overline{z}} \right )\right )}=\overline{f\left ( \frac{1}{\overline{z}}\right )}$$ Alternatively: $$h(\phi^{-1}(z))=\overline{h(\overline{\phi^{-1}(z)})}=\overline{h\left ( \phi^{-1}\left (\frac{1}{\overline z} \right ) \right )}$$ Both paths seemingly lead nowhere, and the argument becomes almost circular. Any help? Thanks in advance!","This is a follow up to a question I asked a few days ago. I initially thought I understood the solution to the problem, but there's something I can't quite grasp: Let $f$ be analytic in the set $\{ x \in \mathbb{C} : 0<|z|<1\}$. If $f$ is real in the unit circle $\{z\in \mathbb{C}: |z|=1\}$, and has a continuous extension to the unit circle, then show that: $$f(z)=\overline{f\left ( \frac{1}{\overline{z}} \right )} \ \forall z\in \mathbb{C}$$ My approach was as follows : Let $\phi: \mathbb{C}\setminus\{-i\} \to \mathbb{C}\setminus \{1\}$ be given by $$\phi(z)=\frac{z-i}{z+i}$$ It is easy to prove that $\phi$ maps the upper half plane into the unit disk, this is $\phi (\mathbb{C}^+)= D$ and that it maps the real axis into the unit circle, i.e.  $|\phi(x)|=1$ for real $x$. Note that $\phi^{-1}:\mathbb{C}\setminus \{1\} \to \mathbb{C}\setminus\{-i\}$ is given by: $$\phi^{-1}(z)=i\frac{z+1}{1-z}$$ Also note that \begin{equation}\overline{\phi^{-1}(z)}=\phi^{-1}\left ( \frac{1}{\overline{z}}\right )\tag1\end{equation} Now, by the preceding remarks, the composition $g=f\circ \phi : \overline{\mathbb{C}^+}\setminus\{i\} \to \mathbb{C}$ is continuous in its domain and analytic in $\mathbb{C}^+ \setminus\{i\}$. Further, since $g(\mathbb{R})\subset \mathbb{R}$, we can apply the Schwarz reflection principle to extend $g$ to $\mathbb{C}\setminus\{i,-i\}$, that is the function $h:\mathbb{C}\setminus\{i,-i\} \to \mathbb{C}$ given by: $$h(z)=\begin{cases}g(z)=(f\circ \phi)(z) & \textrm{if}  \ z \in \overline{\mathbb{C}^+}\setminus\{i\} \\\overline{g(\overline{z})}=\overline{(f\circ \phi)(\overline {z})} & \textrm{if} \ z \in \overline{\mathbb{C}^-}\setminus\{-i\} \end{cases}\tag2$$ is analytic in $\mathbb{C}\setminus\{i,-i\}$ and verifies $h(z)=\overline{h(\overline{z})}$ for all $z \in \mathbb{C}\setminus \{i,-i\}$. Now, if we take $z\neq i,-i$, from $(1)$ and the fact that $h(z)=\overline{h(\overline{z})}$ we get that: \begin{equation}f(z)=(f\circ \phi)(\phi^{-1}(z))=h(\phi^{-1}(z))=\overline{h(\overline{\phi^{-1}(z)})}=\overline{h\left ( \phi^{-1}\left ( \frac{1}{\overline{z}}\right ) \right )}=\overline{f\left ( \frac{1}{\overline{z}} \right )}\tag3\end{equation} Which would complete the proof (the cases $z=i,-i$ are easily handled separately since the function is real in the unit circle). My question is: In $(3)$, why does $h\circ \phi^{-1}=f$ (this is used in the second and final equalities). If $\phi^{-1}(z) \in \overline{\mathbb{C}^+}\setminus\{i\}$, then in is clear from $(2)$ that $h(\phi^{-1}(z))=(f\circ \phi)(\phi^{-1}(z))=f(z)$, since this is the definition of $h$ in that region, but what if $\phi^{-1}(z) \in \overline{\mathbb{C}^-}\setminus\{-i\}$? Using $(2)$ and some other identities we already know I can get: $$h(\phi^{-1}(z))=\overline{(f\circ \phi)(\overline {\phi^{-1}z})}=\overline{(f\circ \phi)\left ( \phi^{-1}\left ( \frac{1}{\overline{z}} \right )\right )}=\overline{f\left ( \frac{1}{\overline{z}}\right )}$$ Alternatively: $$h(\phi^{-1}(z))=\overline{h(\overline{\phi^{-1}(z)})}=\overline{h\left ( \phi^{-1}\left (\frac{1}{\overline z} \right ) \right )}$$ Both paths seemingly lead nowhere, and the argument becomes almost circular. Any help? Thanks in advance!",,['complex-analysis']
91,Local normal form of a (several complex variable) holomorphic map at a point?,Local normal form of a (several complex variable) holomorphic map at a point?,,"Suppose $F\colon\Omega\subseteq\mathbb C^m\to\mathbb C^n$ is a holomorphic map. WLOG, $0\in\Omega$ and $F(0)=0$. I want to determine the local normal form of $F$, i.e. classifying $F$ up to local biholomorphic coordinate changes: $$ \require{AMScd} \begin{CD} \Omega_0@>F>>\mathbb C_0^n\\ @V\sim VV@V\sim VV\\ \Omega_0'@>F'>>\mathbb C_0^n \end{CD} $$ When $m=n=1$, the result is well-known: $F$ is either a constant function, or locally $z\mapsto z^n$. On the other hand, when $F'(0)$ is injective or surjective, then implicit function theorem tells us that $F$ is locally equivalent to $F'(0)$, which is classified up to congruence. When $m,n>1$, maybe there's no complete classification, but I want some partial results. Thoughts: Maybe we can view the problem formally. Instead of holomorphic maps, we can consider formal power series, especially when $n=1$. Weierstrass preparation theorem might work. Background: I learnt that injective holomorphic maps $\mathbb C^n\to\mathbb C^n$ are biholomorphic. The proof in the course is approximately this . However, such a proof doesn't give any information on the classification of maps. I'm just looking for a result which is strong enough to prove that proposition. Any idea? Thanks!","Suppose $F\colon\Omega\subseteq\mathbb C^m\to\mathbb C^n$ is a holomorphic map. WLOG, $0\in\Omega$ and $F(0)=0$. I want to determine the local normal form of $F$, i.e. classifying $F$ up to local biholomorphic coordinate changes: $$ \require{AMScd} \begin{CD} \Omega_0@>F>>\mathbb C_0^n\\ @V\sim VV@V\sim VV\\ \Omega_0'@>F'>>\mathbb C_0^n \end{CD} $$ When $m=n=1$, the result is well-known: $F$ is either a constant function, or locally $z\mapsto z^n$. On the other hand, when $F'(0)$ is injective or surjective, then implicit function theorem tells us that $F$ is locally equivalent to $F'(0)$, which is classified up to congruence. When $m,n>1$, maybe there's no complete classification, but I want some partial results. Thoughts: Maybe we can view the problem formally. Instead of holomorphic maps, we can consider formal power series, especially when $n=1$. Weierstrass preparation theorem might work. Background: I learnt that injective holomorphic maps $\mathbb C^n\to\mathbb C^n$ are biholomorphic. The proof in the course is approximately this . However, such a proof doesn't give any information on the classification of maps. I'm just looking for a result which is strong enough to prove that proposition. Any idea? Thanks!",,"['complex-analysis', 'several-complex-variables']"
92,Lower bound for $ F(z) = \sum_{n=1}^\infty d(n)z^n $ near radius of convergence.,Lower bound for  near radius of convergence., F(z) = \sum_{n=1}^\infty d(n)z^n ,"In Stein and Sharkarchi Problem 2.7.2 one is asked to find a lower bound $$ |F(z)| \geq c\frac{1}{1-r}\log\left(\frac{1}{1-r}\right) $$ for the function $$ F(z) = \sum_{n=1}^\infty d(n)z^n $$ near the radius of convergence $ R $. Here $ d(n) $ is the number of divisors of $ n $. I have already established $ R = 1 $ and the identity $$ \sum_{n=1}^\infty d(n)z^n = \sum_{n=1}^\infty \frac{z^n}{1-z^n}. $$ Furthermore, when $ z $ is a real number $ r $ then clearly $$ F(r) = \sum_{n=1}^\infty \frac{r^n}{1-r^n} \geq \int_1^\infty \frac{r^n}{1-r^n} dn = -\frac{1}{\log(r)}\log\left(\frac{1}{1-r}\right) $$ by substituting $ u = 1-r^n $ and integrating. Since $ r \to 1 $ I have $ \log(r) = (r-1) + O((r-1)^2) \approx (r-1) $ and thus $$ F(r) \geq c\frac{1}{1-r}\log\left(\frac{1}{1-r}\right), $$ for some constant $ c $ coming from the approximation of $ \log(r) \approx (r-1) $. In the problem I have to establish the same lower bound when $ z = re^{i\theta} $ for some $ \theta = 2\pi p/q $ with $ p $ and $ q $ integers. Can I somehow use a similar approach for this? or do I need to do something completely different? Edit #1 : added difinition of $ d(n) $. Edit #2 : Okay, I think I have an answer now. Maybe someone can verify or deny it. Let $ N_q := \{n\in \mathbb{N}\mid q\ \text{does not divide}\ n \} $ and consider the follwing splitting of the sum $$ |F(z)| = \left|\sum_{n=1}^\infty \frac{z^n}{1-z^n}\right| = \left|\underbrace{\sum_{n=1}^\infty\frac{z^{qn}}{1-z^{qn}}}_{=: A} + \underbrace{\sum_{n\in N_q}\frac{z^n}{1-z^n}}_{=: B}\right|. $$ Now part $ A $ is strictly real so with $ z = r $ we have as before $$ A \geq c_A\frac{1}{1-r^q}\log\left(\frac{1}{1-r^q}\right) \geq c_A\frac{1}{1-r}\log\left(\frac{1}{1-r}\right) $$ since $ r < 1 $. For part $ B $ we have th following observation. Since $ e^{ik\theta} = e^{ik\theta}e^{iq\theta} = e^{i(k+q)\theta} $ clearly we only have $ q-1 $ directions to worry about and let $ k' $ be defined such that $ e^{ik'\theta} $ is the closest to 1 when following the unitcicle perimiter. Let $ c_B = \min\{1,\inf\{|1-re^{ik'\theta}|\mid 0< r <1 \}\} $ then we have $$ |B| \leq \sum_{n\in N_q}\frac{|z|^n}{|1-z^n|} \leq \sum_{n\in N_q}\frac{|z|^n}{c_B} \leq \frac{c_B^{-1}}{1-|z|} = \frac{c_B^{-1}}{1-r} $$. Now, since $ A \geq 0 $ we have $ |A+B|\geq A-|B| $ and thus $$ F(z) \geq A - |B| \geq c_A\frac{1}{1-r}\log\left(\frac{1}{1-r}\right) - |B| \geq c_A\frac{1}{1-r}\log\left(\frac{1}{1-r}\right) - \frac{c_B^{-1}}{1-r}, $$ but this we can rewrite at bit $$ c_A\frac{1}{1-r}\log\left(\frac{1}{1-r}\right) - \frac{c_B^{-1}}{1-r} = c_A\frac{1}{1-r}\left(\log\left(\frac{1}{1-r}\right) - c_B^{-1}\right) $$ and since $ \log\left(\frac{1}{1-r}\right) \gg c_B^{-1} $ as $ r \to 1 $ we simply have $$ F(z) \geq c_{p/q}\frac{1}{1-r}\log\left(\frac{1}{1-r}\right) $$ for some constant $ c_{p/q} $. Edit #3 : I realize that there was something wrong. I should probably assume $ p $ and $ q $ relatively prime.","In Stein and Sharkarchi Problem 2.7.2 one is asked to find a lower bound $$ |F(z)| \geq c\frac{1}{1-r}\log\left(\frac{1}{1-r}\right) $$ for the function $$ F(z) = \sum_{n=1}^\infty d(n)z^n $$ near the radius of convergence $ R $. Here $ d(n) $ is the number of divisors of $ n $. I have already established $ R = 1 $ and the identity $$ \sum_{n=1}^\infty d(n)z^n = \sum_{n=1}^\infty \frac{z^n}{1-z^n}. $$ Furthermore, when $ z $ is a real number $ r $ then clearly $$ F(r) = \sum_{n=1}^\infty \frac{r^n}{1-r^n} \geq \int_1^\infty \frac{r^n}{1-r^n} dn = -\frac{1}{\log(r)}\log\left(\frac{1}{1-r}\right) $$ by substituting $ u = 1-r^n $ and integrating. Since $ r \to 1 $ I have $ \log(r) = (r-1) + O((r-1)^2) \approx (r-1) $ and thus $$ F(r) \geq c\frac{1}{1-r}\log\left(\frac{1}{1-r}\right), $$ for some constant $ c $ coming from the approximation of $ \log(r) \approx (r-1) $. In the problem I have to establish the same lower bound when $ z = re^{i\theta} $ for some $ \theta = 2\pi p/q $ with $ p $ and $ q $ integers. Can I somehow use a similar approach for this? or do I need to do something completely different? Edit #1 : added difinition of $ d(n) $. Edit #2 : Okay, I think I have an answer now. Maybe someone can verify or deny it. Let $ N_q := \{n\in \mathbb{N}\mid q\ \text{does not divide}\ n \} $ and consider the follwing splitting of the sum $$ |F(z)| = \left|\sum_{n=1}^\infty \frac{z^n}{1-z^n}\right| = \left|\underbrace{\sum_{n=1}^\infty\frac{z^{qn}}{1-z^{qn}}}_{=: A} + \underbrace{\sum_{n\in N_q}\frac{z^n}{1-z^n}}_{=: B}\right|. $$ Now part $ A $ is strictly real so with $ z = r $ we have as before $$ A \geq c_A\frac{1}{1-r^q}\log\left(\frac{1}{1-r^q}\right) \geq c_A\frac{1}{1-r}\log\left(\frac{1}{1-r}\right) $$ since $ r < 1 $. For part $ B $ we have th following observation. Since $ e^{ik\theta} = e^{ik\theta}e^{iq\theta} = e^{i(k+q)\theta} $ clearly we only have $ q-1 $ directions to worry about and let $ k' $ be defined such that $ e^{ik'\theta} $ is the closest to 1 when following the unitcicle perimiter. Let $ c_B = \min\{1,\inf\{|1-re^{ik'\theta}|\mid 0< r <1 \}\} $ then we have $$ |B| \leq \sum_{n\in N_q}\frac{|z|^n}{|1-z^n|} \leq \sum_{n\in N_q}\frac{|z|^n}{c_B} \leq \frac{c_B^{-1}}{1-|z|} = \frac{c_B^{-1}}{1-r} $$. Now, since $ A \geq 0 $ we have $ |A+B|\geq A-|B| $ and thus $$ F(z) \geq A - |B| \geq c_A\frac{1}{1-r}\log\left(\frac{1}{1-r}\right) - |B| \geq c_A\frac{1}{1-r}\log\left(\frac{1}{1-r}\right) - \frac{c_B^{-1}}{1-r}, $$ but this we can rewrite at bit $$ c_A\frac{1}{1-r}\log\left(\frac{1}{1-r}\right) - \frac{c_B^{-1}}{1-r} = c_A\frac{1}{1-r}\left(\log\left(\frac{1}{1-r}\right) - c_B^{-1}\right) $$ and since $ \log\left(\frac{1}{1-r}\right) \gg c_B^{-1} $ as $ r \to 1 $ we simply have $$ F(z) \geq c_{p/q}\frac{1}{1-r}\log\left(\frac{1}{1-r}\right) $$ for some constant $ c_{p/q} $. Edit #3 : I realize that there was something wrong. I should probably assume $ p $ and $ q $ relatively prime.",,['complex-analysis']
93,Compactly supported Dolbeault Cohomology: is this True?,Compactly supported Dolbeault Cohomology: is this True?,,"nLab states that for $D$ the unit disk in $\mathbb C$, the cohomology of the complex $$ (\Omega_c^{1,\ast}(D),\overline{\partial})$$ is the continuous dual of the space of holomorphic functions $\mathcal O(D)$. Is it true that any continuous linear form on $\mathcal O(D)$ can be represented by a form $f dz\wedge d\overline{z}$ with $f$ having compact support? This result looks really weird to me. What would be the function representing the Delta distribution?","nLab states that for $D$ the unit disk in $\mathbb C$, the cohomology of the complex $$ (\Omega_c^{1,\ast}(D),\overline{\partial})$$ is the continuous dual of the space of holomorphic functions $\mathcal O(D)$. Is it true that any continuous linear form on $\mathcal O(D)$ can be represented by a form $f dz\wedge d\overline{z}$ with $f$ having compact support? This result looks really weird to me. What would be the function representing the Delta distribution?",,"['complex-analysis', 'homology-cohomology']"
94,Cauchy representation and branch point order,Cauchy representation and branch point order,,"This question is about the nature of branch points which arise in certain Cauchy-integral representations of functions of a single complex argument, $z$ . The main application is for dispersion relations but we can ignore that connection since this is a straightforwardly mathematical question. (I posted to math.stackexchange but no attention, even with 50 point bounty.) Suppose we have the following representation: \begin{align} f(z) &= \frac{1}{\pi}\int_0^\infty dx \frac{\Im f(x)}{x-z}, \end{align} where we assume the integral exists for $z=0$ . This function has branch-point singularities at $z=0,\infty$ due to the fact that the (constant) endpoints of integration coincide with the pole of the integrand at those points. The question that I have regarding the order of the branch point is equivalent to understanding the behavior of $f(z)$ as a circuit is traced around the branch point $z=0$ . Suppose I define the ""first sheet"" as the values $f^{(I)}$ of $f(z)$ where $z=x_0+i\epsilon$ ( $\epsilon$ infinitesimal, as usual). I consider a circuit in the $z$ -plane as $z=x_0e^{i\theta}$ ( $0<\theta<2\pi$ ). The function is analytic at all points on this trajectory. Once, however, we consider $2\pi < \theta$ we must distort the contour to avoid the singularity in the integrand at $x=x_0$ . This effects the analytic continuation of $f(z)$ onto what we'll call the ""second sheet"". The value $f^{(II)}$ of $f(x_0)$ on the second sheet is \begin{align} f^{(II)}(x_0) &= \frac{1}{\pi}\int_0^\infty dx \frac{\Im f^{(I)}(x)}{x-(x_0-i\epsilon)},\\ &= \frac{1}{\pi}\int_0^\infty dx \frac{\Im  f^{(I)}(x)}{x-x_0}-i\,\Im f^{(I)}(x_0). \end{align} This demonstrates that $f(x_0+i\epsilon)-f(x_0-i\epsilon) = 2i\,\Im f(x_0)$ and shows that the integration contour is the branch cut. We can continue the above procedure, I believe, an arbitrary number of times. So the order of the branch point at $z=0$ appears to be of the logarithmic variety (of infinite order). My question: Is the branch point that arises from an endpoint singularity always logarithmic? (I suspect there should be way to obtain a square-root type of (or ""first order"") branch point from this Cauchy representation. But I don't see how to construct it given the above arguments.)","This question is about the nature of branch points which arise in certain Cauchy-integral representations of functions of a single complex argument, . The main application is for dispersion relations but we can ignore that connection since this is a straightforwardly mathematical question. (I posted to math.stackexchange but no attention, even with 50 point bounty.) Suppose we have the following representation: where we assume the integral exists for . This function has branch-point singularities at due to the fact that the (constant) endpoints of integration coincide with the pole of the integrand at those points. The question that I have regarding the order of the branch point is equivalent to understanding the behavior of as a circuit is traced around the branch point . Suppose I define the ""first sheet"" as the values of where ( infinitesimal, as usual). I consider a circuit in the -plane as ( ). The function is analytic at all points on this trajectory. Once, however, we consider we must distort the contour to avoid the singularity in the integrand at . This effects the analytic continuation of onto what we'll call the ""second sheet"". The value of on the second sheet is This demonstrates that and shows that the integration contour is the branch cut. We can continue the above procedure, I believe, an arbitrary number of times. So the order of the branch point at appears to be of the logarithmic variety (of infinite order). My question: Is the branch point that arises from an endpoint singularity always logarithmic? (I suspect there should be way to obtain a square-root type of (or ""first order"") branch point from this Cauchy representation. But I don't see how to construct it given the above arguments.)","z \begin{align}
f(z) &= \frac{1}{\pi}\int_0^\infty dx \frac{\Im f(x)}{x-z},
\end{align} z=0 z=0,\infty f(z) z=0 f^{(I)} f(z) z=x_0+i\epsilon \epsilon z z=x_0e^{i\theta} 0<\theta<2\pi 2\pi < \theta x=x_0 f(z) f^{(II)} f(x_0) \begin{align}
f^{(II)}(x_0) &= \frac{1}{\pi}\int_0^\infty dx \frac{\Im f^{(I)}(x)}{x-(x_0-i\epsilon)},\\
&= \frac{1}{\pi}\int_0^\infty dx \frac{\Im  f^{(I)}(x)}{x-x_0}-i\,\Im f^{(I)}(x_0).
\end{align} f(x_0+i\epsilon)-f(x_0-i\epsilon) = 2i\,\Im f(x_0) z=0","['complex-analysis', 'mathematical-physics', 'quantum-field-theory']"
95,Fejer-Riesz Lemma,Fejer-Riesz Lemma,,"I'm trying to apply the Fejer-Riesz Lemma constructively. The lemma says that for a Laurent polynomial $a(z) = \sum_{-n}^na_jz^j$ with $a_j = \bar a_{-j}$ and $a(e^{i\theta})\geq0$ on the complex unit circle, there exists a polynomial $b(z) = \sum_{0}^nb_jz^j$ such that $a(e^{i\theta})=|b(e^{i\theta})|^2$ for all $\theta$. The proof is rather simple (in hindsight). My particular scenario is a simpler version, where $a_j=a_{-j}\in\mathbb R$, which gives an even stronger result: $a(z) = b(z)b(1/z)$ for all complex $z$. But I'm not managing to use this constructively - I'm not sure in general there is a constructive approach, because we can't explicitly reduce all polynomials. In any case, my particular case is, $$a(z) = (4-128\theta) + (112\theta-1)(z+z^{-1}) + 64\theta(z^2+z^{-2}) + 16\theta(z^3+z^{-3})$$ I'm simply not managing to find $\{b_j\}$. This of course reduces to a system of nonlinear equations, if we simply compare coefficients, but that wasn't particularly fruitful either. Thanks. EDIT The parameter $\theta$ is a constant on a smallish neighbourhood of zero. It shouldn't be important for the general result, although if it helps, you can assume $\theta\in[-\frac 1{10},\frac 1 {10}]$.","I'm trying to apply the Fejer-Riesz Lemma constructively. The lemma says that for a Laurent polynomial $a(z) = \sum_{-n}^na_jz^j$ with $a_j = \bar a_{-j}$ and $a(e^{i\theta})\geq0$ on the complex unit circle, there exists a polynomial $b(z) = \sum_{0}^nb_jz^j$ such that $a(e^{i\theta})=|b(e^{i\theta})|^2$ for all $\theta$. The proof is rather simple (in hindsight). My particular scenario is a simpler version, where $a_j=a_{-j}\in\mathbb R$, which gives an even stronger result: $a(z) = b(z)b(1/z)$ for all complex $z$. But I'm not managing to use this constructively - I'm not sure in general there is a constructive approach, because we can't explicitly reduce all polynomials. In any case, my particular case is, $$a(z) = (4-128\theta) + (112\theta-1)(z+z^{-1}) + 64\theta(z^2+z^{-2}) + 16\theta(z^3+z^{-3})$$ I'm simply not managing to find $\{b_j\}$. This of course reduces to a system of nonlinear equations, if we simply compare coefficients, but that wasn't particularly fruitful either. Thanks. EDIT The parameter $\theta$ is a constant on a smallish neighbourhood of zero. It shouldn't be important for the general result, although if it helps, you can assume $\theta\in[-\frac 1{10},\frac 1 {10}]$.",,"['complex-analysis', 'polynomials']"
96,One-dimensional projective group in linear transformation,One-dimensional projective group in linear transformation,,"A convenient way to express a linear transformation is by use of homogeneous coordinates. If we write $z=z_1/z_2$ and $w=w_1/w_2$ we find that $w=Sz$ if $$w_1=az_1+bz_2\text{ and }  w_2=cz_1+dz_2$$ All linear transformations form a group. The ratios $z_1:z_2\neq 0:0$ are the points of the complex projective line, and the two equations above identify the group of linear transformations with the one-dimensional projective group over the complex numbers, usually denoted by $P(1,\mathbb{C})$ . What is meant by the complex projective line here? What about the one-dimensional projective group over the complex numbers? Isn't this transformation just taking the set of extended plane (i.e. all complex numbers, union with infinity) onto itself?","A convenient way to express a linear transformation is by use of homogeneous coordinates. If we write and we find that if All linear transformations form a group. The ratios are the points of the complex projective line, and the two equations above identify the group of linear transformations with the one-dimensional projective group over the complex numbers, usually denoted by . What is meant by the complex projective line here? What about the one-dimensional projective group over the complex numbers? Isn't this transformation just taking the set of extended plane (i.e. all complex numbers, union with infinity) onto itself?","z=z_1/z_2 w=w_1/w_2 w=Sz w_1=az_1+bz_2\text{ and }  w_2=cz_1+dz_2 z_1:z_2\neq 0:0 P(1,\mathbb{C})",['complex-analysis']
97,Inverse Laplace Transform as Bromwich Integral,Inverse Laplace Transform as Bromwich Integral,,"I am seeking a references that provide a rigorous treatment of the inverse Laplace transform (Bromwich integrals), and how to compute them (beyond using tabled solutions - they don't cover my needs, so I'm trying to learn to do it via complex analysis)? Textbooks or papers would be great. I would prefer something with lots of examples worked out if possible, my experience with complex integration is a bit shallow. To clarify, I'd like to understand how to handle integrals like this: $$ \mathscr{L}^{-1}_s\lbrace F(s)\rbrace=\frac{1}{2\pi i}\int_{\gamma-i\infty}^{\gamma+i\infty} e^{st}F(s) ds $$ for a real number $$\gamma > Re(s)$$ for each singularity s of F. Should I just be looking at the calculus of residues, or is there something special about integrals of this sort? It appears a bit different than what I've seen in my complex analysis text - there I would always see integrals of this sort: $$ \int_L f(s)ds $$ But L would always be a closed rectifiable curve, while the inverse Laplace transform appears to be over a vertical line in the complex plane, which I'm not sure how to interpret. Perhaps it's just a notational misunderstanding, and I'm meant to construct a suitable contour expanding on that vertical line? Any direction would be greatly appreciated!","I am seeking a references that provide a rigorous treatment of the inverse Laplace transform (Bromwich integrals), and how to compute them (beyond using tabled solutions - they don't cover my needs, so I'm trying to learn to do it via complex analysis)? Textbooks or papers would be great. I would prefer something with lots of examples worked out if possible, my experience with complex integration is a bit shallow. To clarify, I'd like to understand how to handle integrals like this: $$ \mathscr{L}^{-1}_s\lbrace F(s)\rbrace=\frac{1}{2\pi i}\int_{\gamma-i\infty}^{\gamma+i\infty} e^{st}F(s) ds $$ for a real number $$\gamma > Re(s)$$ for each singularity s of F. Should I just be looking at the calculus of residues, or is there something special about integrals of this sort? It appears a bit different than what I've seen in my complex analysis text - there I would always see integrals of this sort: $$ \int_L f(s)ds $$ But L would always be a closed rectifiable curve, while the inverse Laplace transform appears to be over a vertical line in the complex plane, which I'm not sure how to interpret. Perhaps it's just a notational misunderstanding, and I'm meant to construct a suitable contour expanding on that vertical line? Any direction would be greatly appreciated!",,"['complex-analysis', 'laplace-transform']"
98,number of zeros of complex waves,number of zeros of complex waves,,"Does anybody know about any type of methods how to calucalte/estimate the number of the zeros of complex waves (periodic functions as superposition of many harmonic waves) within a given period [0,x] under the condition that the wave function is even? - It is indeed about the number of zeros and not determining the zeros themselves. Does anybody knows about problems rising in other disciplines like physiscs where the number of such zeros are studied and essential? Alternatively, if there might be a proof that such method can not generally exist (for instance because of a type of uncertainty principle), it would be also very helpful. Many thanks","Does anybody know about any type of methods how to calucalte/estimate the number of the zeros of complex waves (periodic functions as superposition of many harmonic waves) within a given period [0,x] under the condition that the wave function is even? - It is indeed about the number of zeros and not determining the zeros themselves. Does anybody knows about problems rising in other disciplines like physiscs where the number of such zeros are studied and essential? Alternatively, if there might be a proof that such method can not generally exist (for instance because of a type of uncertainty principle), it would be also very helpful. Many thanks",,"['complex-analysis', 'reference-request', 'fourier-analysis', 'periodic-functions']"
99,Finding a sequence of polynomials that converges uniformly to a holomorphic function on an open set,Finding a sequence of polynomials that converges uniformly to a holomorphic function on an open set,,"The following is exercise 13.2 in Rudin's Real & Complex Analysis, which I'm self-studying. Let $\Omega = \{z: |z| < 1 \text{ and } |2z - 1| > 1\}$, and suppose $f \in H(\Omega)$. Must there exist a sequence of polynomials which converges to $f$ uniformly in $\Omega$? I have a solution, but I feel it's simple and the shape of $\Omega$ is suspicious so there might be a trick somewhere. Assume such a sequence exists. Let $0 < \epsilon < 1$, $f(z) = 1/z$ and $P$ be a polynomial that satisfies: $$|f(z) - P(z)| < \epsilon \ \ \forall z \in \Omega$$ Therefore $$|P(z)| < |f(z)| + \epsilon \ \ \forall z \in \Omega$$ But near the boundary of the unit disc, $|f(z)| < 2$, so $|P(z)| < 3$ near the boundary. By the continuity of $P$, we have $P(z) \le 3$ on the boundary. By the maximum modulus principle, $P(z) < 3$ on the unit disc. But $|f(z)|$ gets arbitrarily large near $0$. Therefore $P$ cannot approximate $f$ on $\Omega$. What gives me confidence in my argument is that it doesn't work on compact subsets of $\Omega$ (for which the existence of the polynomial sequence is guaranteed by Runge's theorem). Is my counter-example correct?","The following is exercise 13.2 in Rudin's Real & Complex Analysis, which I'm self-studying. Let $\Omega = \{z: |z| < 1 \text{ and } |2z - 1| > 1\}$, and suppose $f \in H(\Omega)$. Must there exist a sequence of polynomials which converges to $f$ uniformly in $\Omega$? I have a solution, but I feel it's simple and the shape of $\Omega$ is suspicious so there might be a trick somewhere. Assume such a sequence exists. Let $0 < \epsilon < 1$, $f(z) = 1/z$ and $P$ be a polynomial that satisfies: $$|f(z) - P(z)| < \epsilon \ \ \forall z \in \Omega$$ Therefore $$|P(z)| < |f(z)| + \epsilon \ \ \forall z \in \Omega$$ But near the boundary of the unit disc, $|f(z)| < 2$, so $|P(z)| < 3$ near the boundary. By the continuity of $P$, we have $P(z) \le 3$ on the boundary. By the maximum modulus principle, $P(z) < 3$ on the unit disc. But $|f(z)|$ gets arbitrarily large near $0$. Therefore $P$ cannot approximate $f$ on $\Omega$. What gives me confidence in my argument is that it doesn't work on compact subsets of $\Omega$ (for which the existence of the polynomial sequence is guaranteed by Runge's theorem). Is my counter-example correct?",,"['complex-analysis', 'uniform-convergence']"
