,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"where do sensitivity, specificity, recall and precision terms come from?","where do sensitivity, specificity, recall and precision terms come from?",,"Binomial classification accuracy metrics is filled with lot of definitions as sensitivity, specificity, recall, precision . Sometimes I have felt confused with the terms and I would appreciate if instead of memorizing the terms, I understand why they are called in such way. Do someone know where such terms come from? Can someone reccommend a book chapter with the history of this terms or how they rose up to the literature?","Binomial classification accuracy metrics is filled with lot of definitions as sensitivity, specificity, recall, precision . Sometimes I have felt confused with the terms and I would appreciate if instead of memorizing the terms, I understand why they are called in such way. Do someone know where such terms come from? Can someone reccommend a book chapter with the history of this terms or how they rose up to the literature?",,"['statistics', 'terminology', 'statistical-inference', 'math-history']"
1,Q: Help to understand simple probability problem from Kahneman 'Thinking fast and slow',Q: Help to understand simple probability problem from Kahneman 'Thinking fast and slow',,"I'm new to statistics and I'm trying to solve this easy problem. Unfortunately I can't find a solution that would confirm that scenario with 4 same coloured marbles is six times more likely than the other one. Here's the problem from Kahneman's book: Imagine a large urn filled with marbles. Half the marbles are   red, half are white. Next, imagine a very patient person (or a robot)   who blindly draws 4 marbles from the urn, records the number of red   balls in the sample, throws the balls back into the urn, and then does   it all again, many times. If you summarize the results, you will find   that the outcome “2 red, 2 white” occurs (almost exactly) 6 times as   often as the outcome “4 red” or “4 white.” My solution (I assumed that there are 10k marbles in total): probability of drawing 4 marbles with same colour: 5000/10000 * 4999/9999 * 4998/9998 * 4997/9997 = 6,25% there are two combinations (rrrr, wwww), so: 6,25% * 2 = 12,49% probability of drawing 2 marbles of each colour: 5000/10000 * 4999/9999 * 5000/9998 * 4999/9997 = 6,25% here we have six combinations (wwrr, rrww, wrrw, rwwr, rwrw, wrwr): 6,25% * 6 = 37,51%","I'm new to statistics and I'm trying to solve this easy problem. Unfortunately I can't find a solution that would confirm that scenario with 4 same coloured marbles is six times more likely than the other one. Here's the problem from Kahneman's book: Imagine a large urn filled with marbles. Half the marbles are   red, half are white. Next, imagine a very patient person (or a robot)   who blindly draws 4 marbles from the urn, records the number of red   balls in the sample, throws the balls back into the urn, and then does   it all again, many times. If you summarize the results, you will find   that the outcome “2 red, 2 white” occurs (almost exactly) 6 times as   often as the outcome “4 red” or “4 white.” My solution (I assumed that there are 10k marbles in total): probability of drawing 4 marbles with same colour: 5000/10000 * 4999/9999 * 4998/9998 * 4997/9997 = 6,25% there are two combinations (rrrr, wwww), so: 6,25% * 2 = 12,49% probability of drawing 2 marbles of each colour: 5000/10000 * 4999/9999 * 5000/9998 * 4999/9997 = 6,25% here we have six combinations (wwrr, rrww, wrrw, rwwr, rwrw, wrwr): 6,25% * 6 = 37,51%",,"['probability', 'statistics']"
2,What is saturated model used in glm in R?,What is saturated model used in glm in R?,,"So, I've read on stack exchange ( glm summary explained ) that residual deviance computed in the glm output is just the likelihood ratio chi-square stat comparing the saturated model to the reduced model. 1) But what saturated model is used? 2) How is the log likelihood evaluated at mle estimates computed for the given saturated model? For simplicity, let's assume the glm is from the normal family and is just standard linear regression. 1)As I understand it a saturated model has as many parameters as data points-so there should be several (infinite) possible saturated models. For example, suppose you have two explanatory variables with four data points.  One possible saturated model could be $y=b_1x_1+b_2x_2+b_3x_1x_2+b_4$ or another possible saturated model could be $y=b_1x_1+b_2x_2+b_3x_2^2+b_4$ . 2)Regardless of the saturated model wouldn't the mle estimates for these coefficients just be found by solving the system directly using these four data points (as R naturally computes them)? Indeed, these would lead you to an infinite likelihood as residuals would be 0.","So, I've read on stack exchange ( glm summary explained ) that residual deviance computed in the glm output is just the likelihood ratio chi-square stat comparing the saturated model to the reduced model. 1) But what saturated model is used? 2) How is the log likelihood evaluated at mle estimates computed for the given saturated model? For simplicity, let's assume the glm is from the normal family and is just standard linear regression. 1)As I understand it a saturated model has as many parameters as data points-so there should be several (infinite) possible saturated models. For example, suppose you have two explanatory variables with four data points.  One possible saturated model could be or another possible saturated model could be . 2)Regardless of the saturated model wouldn't the mle estimates for these coefficients just be found by solving the system directly using these four data points (as R naturally computes them)? Indeed, these would lead you to an infinite likelihood as residuals would be 0.",y=b_1x_1+b_2x_2+b_3x_1x_2+b_4 y=b_1x_1+b_2x_2+b_3x_2^2+b_4,"['statistics', 'linear-regression']"
3,In which reliable textbook I can find the derivation of the multi cells (more than 2X2) version of pearson's chi square test?,In which reliable textbook I can find the derivation of the multi cells (more than 2X2) version of pearson's chi square test?,,"I can't find the statement, proof and defintion in Dasgupta asymtotic statistics textbook (Springer press), however I found it mentioned somewhere in Dasgupta's textbook as a section title, where can I find its statement and derivation? If not, can you try to state in an elementary level and derive here? Many Thanks for enligten me!","I can't find the statement, proof and defintion in Dasgupta asymtotic statistics textbook (Springer press), however I found it mentioned somewhere in Dasgupta's textbook as a section title, where can I find its statement and derivation? If not, can you try to state in an elementary level and derive here? Many Thanks for enligten me!",,"['statistics', 'reference-request']"
4,Tangents of the Means of the Roots of $n$th Order Polynomials,Tangents of the Means of the Roots of th Order Polynomials,n,"In Stewart's Calculus w. Early Transcendentals 8th Ed. Chapter $3$ Problems Plus Question 26 we establish that the tangent of the mean of any two roots of a third order polynomial passes through the third root. Does this hold for an nth order polynomial? If so how does one go about deriving the product given as $$\prod_{k=0}^n (x-a_k)$$ where $a_k$ is the $k$ th root of the $n$ th order polynomial. The means of the roots can be taken as $$\mu_{a_0,a_{n-1}}=\frac{a_0+a_1+a_2+\ldots+a_n-1}{a_n}=\frac{\sum_{k=0}^{n-1} a_k}{a_n}$$ any help would be appreciated.",In Stewart's Calculus w. Early Transcendentals 8th Ed. Chapter Problems Plus Question 26 we establish that the tangent of the mean of any two roots of a third order polynomial passes through the third root. Does this hold for an nth order polynomial? If so how does one go about deriving the product given as where is the th root of the th order polynomial. The means of the roots can be taken as any help would be appreciated.,"3 \prod_{k=0}^n (x-a_k) a_k k n \mu_{a_0,a_{n-1}}=\frac{a_0+a_1+a_2+\ldots+a_n-1}{a_n}=\frac{\sum_{k=0}^{n-1} a_k}{a_n}","['calculus', 'geometry', 'statistics']"
5,population distribution & sampling distribution [closed],population distribution & sampling distribution [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question What is the difference between the population distribution of a random variable X and the sampling distribution of a random variable that is a sample statistic? This is a question I got from my econometrics teacher, but I'm very uncertain about the terms that she uses. It would help me greatly if some simple and straightforward explanation can be given. Thank you in advance.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question What is the difference between the population distribution of a random variable X and the sampling distribution of a random variable that is a sample statistic? This is a question I got from my econometrics teacher, but I'm very uncertain about the terms that she uses. It would help me greatly if some simple and straightforward explanation can be given. Thank you in advance.",,"['statistics', 'probability-distributions', 'sampling']"
6,How to show that a particular distribution is the Lebesgue measure,How to show that a particular distribution is the Lebesgue measure,,"Let $X_1 , X_2,..$ be independent r.v's, defined on some probability space $(\Omega, \mathcal{F},P)$ , s.t. $$P(X_n = 0) = P(X_n = 1) =1/2 \text{ } \forall n$$ Let $U = \sum_{n=1}^{\infty}X_n 2^{-n}$ . (i) Show that the distribution of $U$ is the Lebesgue measure.    (ii) Construct an independent sequence $U_1,U_2,..$ on $((0,1),\mathcal{B},\lambda)$ s.t. the distribution of each $U_i$ is $\lambda$ where $\lambda$ is Lebesgue. My attempt: Let $E_n = \{ X_i = T_i | i=1,..,n \text{  } \& X_{n+1}<T_{n+1}\}$ . To find the distribution of $U$ , I need $P(X_1 X_2... < T_1 T_2...)$ where $X_i , T_i \in \{0,1\}$ . Then $$\{X_1 X_2... < T_1 T_2...\} = \coprod_{n=1}^{n=\infty}\{E_n \cap \{T_{n+1}=1\}\}$$ where $\coprod$ is the disjoint union. $$P\{E_n \cap \{T_{n+1}=1\}\} = 1_{\{T_{n+1}=1\}}.(\frac{1}{2})^{n+1}$$ and thus: $$P\{X_1 X_2... < T_1 T_2...\} = \sum_{n=1}^{\infty}1_{\{T_{n+1}=1\}}.(\frac{1}{2})^{n+1}$$ Am I thinking in the right direction? and if yes, I'm not sure which set on $\mathbb{R}$ I should be looking at to take it's Lebesgue measure to be equal to the distribution obtained above? Thanks and appreciate a hint.","Let be independent r.v's, defined on some probability space , s.t. Let . (i) Show that the distribution of is the Lebesgue measure.    (ii) Construct an independent sequence on s.t. the distribution of each is where is Lebesgue. My attempt: Let . To find the distribution of , I need where . Then where is the disjoint union. and thus: Am I thinking in the right direction? and if yes, I'm not sure which set on I should be looking at to take it's Lebesgue measure to be equal to the distribution obtained above? Thanks and appreciate a hint.","X_1 , X_2,.. (\Omega, \mathcal{F},P) P(X_n = 0) = P(X_n = 1) =1/2 \text{ } \forall n U = \sum_{n=1}^{\infty}X_n 2^{-n} U U_1,U_2,.. ((0,1),\mathcal{B},\lambda) U_i \lambda \lambda E_n = \{ X_i = T_i | i=1,..,n \text{  } \& X_{n+1}<T_{n+1}\} U P(X_1 X_2... < T_1 T_2...) X_i , T_i \in \{0,1\} \{X_1 X_2... < T_1 T_2...\} = \coprod_{n=1}^{n=\infty}\{E_n \cap \{T_{n+1}=1\}\} \coprod P\{E_n \cap \{T_{n+1}=1\}\} = 1_{\{T_{n+1}=1\}}.(\frac{1}{2})^{n+1} P\{X_1 X_2... < T_1 T_2...\} = \sum_{n=1}^{\infty}1_{\{T_{n+1}=1\}}.(\frac{1}{2})^{n+1} \mathbb{R}","['real-analysis', 'probability-theory']"
7,Prove a.s. convergence of $(X_n)_n$ satisfying $E(X_{n+1} \mid F_n) \leq X_n+Y_n$ for $\sum_n Y_n<\infty$,Prove a.s. convergence of  satisfying  for,(X_n)_n E(X_{n+1} \mid F_n) \leq X_n+Y_n \sum_n Y_n<\infty,"I am have a problem with proving a convergence of a sequence of random variables in the given context: Let $F_n$ be a filtration. Assume that $X_n$ and $Y_n$ are non-negative and integrable $F_n$ -adapted random variables for $n\geq 0$ . Furthermore, I assume that: $\mathbb{E}[X_{n+1} \mid F_n]\leq X_n+Y_n$ and that $\sum_{n}Y_n < \infty$ . Under the above conditions, I should show that $X_n$ converges almost surely for $n\rightarrow \infty$ . My approach has been to define a variable $Z_n=X_n-\sum_{i=0}^{n-1} Y_i$ , and to set this into the expression for the conditional mean of $X_{n+1}$ , but this did not gave any result. Anybody has an idea to this?","I am have a problem with proving a convergence of a sequence of random variables in the given context: Let be a filtration. Assume that and are non-negative and integrable -adapted random variables for . Furthermore, I assume that: and that . Under the above conditions, I should show that converges almost surely for . My approach has been to define a variable , and to set this into the expression for the conditional mean of , but this did not gave any result. Anybody has an idea to this?",F_n X_n Y_n F_n n\geq 0 \mathbb{E}[X_{n+1} \mid F_n]\leq X_n+Y_n \sum_{n}Y_n < \infty X_n n\rightarrow \infty Z_n=X_n-\sum_{i=0}^{n-1} Y_i X_{n+1},"['probability-theory', 'convergence-divergence', 'martingales']"
8,Expectation of Maximum of Translated Gaussian,Expectation of Maximum of Translated Gaussian,,"Given $X\propto N(\mu,\psi^2)$ and $K$ constant, find $E(\max\{K-X,0\})$ . My attempt: $$ \begin{align} E(\max\{K-X,0\})\\ &=\int_{-\infty}^{\infty}\max\{K-x,0\}f_X(x)dx\\ &=\int_{K}^{\infty}(K-x)f_X(x)dx\\ &=\int_{K}^{\infty}[(K-\mu)-(X-\mu)]f_X(x)dx\\ &=\int_{K}^{\infty}(K-\mu)f_X(x)dx-\int_{K}^{\infty}(x-\mu)f_X(x)dx\\ &=(K-\mu)(1-\Phi(K))-\int_{K}^{\infty}(x-\mu)f_X(x)dx\\ &=(K-\mu)(1-\Phi(K))-\int_{K}^{\infty}(x-\mu)\frac{1}{(2\pi \psi^2)^{1/2}}e^{-\frac{(x-\mu)^2}{2\psi^2}}dx\\ &=(K-\mu)(1-\Phi(K))-\int_{\frac{(K-\mu)^2}{2\psi^2}}^{\infty}\psi^2\frac{1}{(2\pi \psi^2)^{1/2}}e^{-z}dz\\ &=(K-\mu)(1-\Phi(K))+\frac{\psi}{\sqrt{2\pi}}e^{-z}|_{\frac{(K-\mu)^2}{2\psi^2}}^{\infty}\\ &=(K-\mu)(1-\Phi(K))-\frac{\psi}{\sqrt{2\pi}}e^{-\frac{(K-\mu)^2}{2\psi^2}} \end{align} $$ where I have used the change of variables $z=\frac{(x-\mu)^2}{2\psi^2}$ . However, when I check my answer numerically, I see that the integral is not correct. Here is working Python code to check: import numpy as np from scipy.stats import norm  # simulation parameters for checking answers numerically trials = 100000 K = 0.25 mu = np.pi/2 psi = 3.0  simulated = np.mean([np.max([K-x, 0])                      for x in np.random.normal(mu, psi, trials)]) numerical = (K-mu)*(1-norm.cdf(K, mu, psi)) - np.exp(-((K-mu)**2)/(2*psi**2))*psi/np.sqrt(2*np.pi)  print(simulated) print(numerical) This gives: simulated = 0.6448298784565597 numerical = -1.9713797586737627 What is the issue with my integration?","Given and constant, find . My attempt: where I have used the change of variables . However, when I check my answer numerically, I see that the integral is not correct. Here is working Python code to check: import numpy as np from scipy.stats import norm  # simulation parameters for checking answers numerically trials = 100000 K = 0.25 mu = np.pi/2 psi = 3.0  simulated = np.mean([np.max([K-x, 0])                      for x in np.random.normal(mu, psi, trials)]) numerical = (K-mu)*(1-norm.cdf(K, mu, psi)) - np.exp(-((K-mu)**2)/(2*psi**2))*psi/np.sqrt(2*np.pi)  print(simulated) print(numerical) This gives: simulated = 0.6448298784565597 numerical = -1.9713797586737627 What is the issue with my integration?","X\propto N(\mu,\psi^2) K E(\max\{K-X,0\}) 
\begin{align}
E(\max\{K-X,0\})\\
&=\int_{-\infty}^{\infty}\max\{K-x,0\}f_X(x)dx\\
&=\int_{K}^{\infty}(K-x)f_X(x)dx\\
&=\int_{K}^{\infty}[(K-\mu)-(X-\mu)]f_X(x)dx\\
&=\int_{K}^{\infty}(K-\mu)f_X(x)dx-\int_{K}^{\infty}(x-\mu)f_X(x)dx\\
&=(K-\mu)(1-\Phi(K))-\int_{K}^{\infty}(x-\mu)f_X(x)dx\\
&=(K-\mu)(1-\Phi(K))-\int_{K}^{\infty}(x-\mu)\frac{1}{(2\pi \psi^2)^{1/2}}e^{-\frac{(x-\mu)^2}{2\psi^2}}dx\\
&=(K-\mu)(1-\Phi(K))-\int_{\frac{(K-\mu)^2}{2\psi^2}}^{\infty}\psi^2\frac{1}{(2\pi \psi^2)^{1/2}}e^{-z}dz\\
&=(K-\mu)(1-\Phi(K))+\frac{\psi}{\sqrt{2\pi}}e^{-z}|_{\frac{(K-\mu)^2}{2\psi^2}}^{\infty}\\
&=(K-\mu)(1-\Phi(K))-\frac{\psi}{\sqrt{2\pi}}e^{-\frac{(K-\mu)^2}{2\psi^2}}
\end{align}
 z=\frac{(x-\mu)^2}{2\psi^2}","['statistics', 'numerical-methods', 'normal-distribution', 'expected-value']"
9,Almost sure convergence of positive random variables,Almost sure convergence of positive random variables,,"I have a sequence of random variables $X_1, X_2, \ldots : \Omega \rightarrow \mathbb{R}$ and $(\Omega, \mathcal{F}, \mathbb{P})$ is a probability space. The variables are known to be non-negative, i.e., $X_n \ge 0$ for all $n$ . If we assume that $$\liminf_{n \to \infty} \: \mathbb{E}[X_n] = 0,$$ then, can we show that $$\liminf_{n \to \infty} \: X_n = 0$$ almost surely? My tentative proof is as follows. The expected value of $X_n$ is $$\mathbb{E}[X_n] = \int_{\Omega} X_n(\omega) \mathrm{d}\mathbb{P}(\omega).$$ If we apply Fatou's Lemma we conclude that $$\int_{\Omega} \liminf_{n \to \infty} X_n(\omega) \mathrm{d}\mathbb{P}(\omega) \le \liminf_{n \to \infty} \int_{\Omega} X_n(\omega) \mathrm{d}\mathbb{P}(\omega) = 0,$$ where the right-hand side is 0 by assumption. Since each $X_n \ge 0$ , then $\liminf_{n \to \infty} X_n(\omega) \ge 0$ for all $\omega$ . Therefore, the left-hand side is also $\ge 0$ and, thus, it is $=0$ . Therefore we can conclude that $$\liminf_{n \to \infty} X_n = 0$$ almost surely.","I have a sequence of random variables and is a probability space. The variables are known to be non-negative, i.e., for all . If we assume that then, can we show that almost surely? My tentative proof is as follows. The expected value of is If we apply Fatou's Lemma we conclude that where the right-hand side is 0 by assumption. Since each , then for all . Therefore, the left-hand side is also and, thus, it is . Therefore we can conclude that almost surely.","X_1, X_2, \ldots : \Omega \rightarrow \mathbb{R} (\Omega, \mathcal{F}, \mathbb{P}) X_n \ge 0 n \liminf_{n \to \infty} \: \mathbb{E}[X_n] = 0, \liminf_{n \to \infty} \: X_n = 0 X_n \mathbb{E}[X_n] = \int_{\Omega} X_n(\omega) \mathrm{d}\mathbb{P}(\omega). \int_{\Omega} \liminf_{n \to \infty} X_n(\omega) \mathrm{d}\mathbb{P}(\omega) \le \liminf_{n \to \infty} \int_{\Omega} X_n(\omega) \mathrm{d}\mathbb{P}(\omega) = 0, X_n \ge 0 \liminf_{n \to \infty} X_n(\omega) \ge 0 \omega \ge 0 =0 \liminf_{n \to \infty} X_n = 0","['probability-theory', 'statistics', 'random-variables']"
10,Using a standard pair of dice. What is the probability of roling a $12$ four tosses in a row?,Using a standard pair of dice. What is the probability of roling a  four tosses in a row?,12,This is throwing me off a bit I believe mainly because the way the question is worded? Would this simply be $4$ out of $36$ ?,This is throwing me off a bit I believe mainly because the way the question is worded? Would this simply be out of ?,4 36,"['probability', 'statistics']"
11,Probability of rolling fewer than m distinct numbers on n sided die after k rolls,Probability of rolling fewer than m distinct numbers on n sided die after k rolls,,"Question Suppose I have an n-sided die which I roll k times. For any given m $\le$ n, what is the probability that I roll $\le$ m distinct numbers. Follow-up What is the smallest m such that I can be 99% sure there are $\le$ m distinct numbers after k rolls?","Question Suppose I have an n-sided die which I roll k times. For any given m n, what is the probability that I roll m distinct numbers. Follow-up What is the smallest m such that I can be 99% sure there are m distinct numbers after k rolls?",\le \le \le,"['probability', 'statistics', 'dice']"
12,How to find the mean squared error in an exponential distribution?,How to find the mean squared error in an exponential distribution?,,"Say we are given an exponential distribution. This questions first asks you to find the MLE of $\theta$ an exponential distribution which I found to be equal to $\bar{X}$ . Then it asks you to compute the Mean Squared Error? I have no idea how to do it. I've been given the formula where it is equal to $\operatorname{Var}(T) + \operatorname{Bias}(T)^2$ but I am unsure of what it means. In the solution of the question it says that the bias is equal to $0$ , but where does that come from? How can I know when a bias is equal to $0$ , and when it isn't? Again, why is the bias $0$ in this case?","Say we are given an exponential distribution. This questions first asks you to find the MLE of an exponential distribution which I found to be equal to . Then it asks you to compute the Mean Squared Error? I have no idea how to do it. I've been given the formula where it is equal to but I am unsure of what it means. In the solution of the question it says that the bias is equal to , but where does that come from? How can I know when a bias is equal to , and when it isn't? Again, why is the bias in this case?",\theta \bar{X} \operatorname{Var}(T) + \operatorname{Bias}(T)^2 0 0 0,['statistics']
13,Confidence that a statement is false,Confidence that a statement is false,,"As a software developer, I have made a program that uploads files one by one to a blob storage in the cloud. After the upload is supposedly complete, a different method will try to verify that the upload was successful, and based on the outcome of this verification I get log statements saying whether the upload went ok or not. Recently, I saw about 2400 log statements saying that the upload had failed. Out of these 2400 error messages, I took 20 random ones and manually checked, but found that the files had been uploaded. So out of 2400 error messages, I found that 20 out of a sample of 20 that those error messages were wrong. Rerunning the verification process is unfortunately not easily done since it will disturb the data, i.e. data being uploaded agin. Therefore I wanted to see if I could use math to conclude whether all error messages can be ignored, but my knowledge on statistic is too rusty. So the question is basically, with what confidence level can I state that all error messages can be ignored?","As a software developer, I have made a program that uploads files one by one to a blob storage in the cloud. After the upload is supposedly complete, a different method will try to verify that the upload was successful, and based on the outcome of this verification I get log statements saying whether the upload went ok or not. Recently, I saw about 2400 log statements saying that the upload had failed. Out of these 2400 error messages, I took 20 random ones and manually checked, but found that the files had been uploaded. So out of 2400 error messages, I found that 20 out of a sample of 20 that those error messages were wrong. Rerunning the verification process is unfortunately not easily done since it will disturb the data, i.e. data being uploaded agin. Therefore I wanted to see if I could use math to conclude whether all error messages can be ignored, but my knowledge on statistic is too rusty. So the question is basically, with what confidence level can I state that all error messages can be ignored?",,"['statistics', 'confidence-interval']"
14,Neyman - Pearson - Test with Poisson distribution,Neyman - Pearson - Test with Poisson distribution,,"Let $X$ be a Poi( $\nu$ ) distributed rv with unknown $\nu \in (0,\infty)$ and we set $ \theta:=\nu $ . We want to test the hypotheses $ H_0:\nu_0=1 $ against $ H_1:\nu_1=\nu_0=2 $ a) We look at the (randomized) Neyman - Pearson - Test which has the form $T(k) = \begin{cases} 1 & R(k) > c \\ \gamma & R(k)=c \\ 0 & R(k)<c \end{cases}$ , with $c \in \mathbb{R} $ and $\gamma \in [0,1]$ $ R(k) := \frac{P_{\nu_1}(X=k)}{P_{\nu_0}(X=k)} $ is the Maximum Liklihood quotient. Compute $c^*$ and $ \gamma^* $ such that $T$ is a test with niveau $\alpha = 0.05$ i.e. $E_{\nu_0}[T]=\alpha$ . b) You see that $X=3$ . How do you decide in terms of the test wich you construct in a)? Values of a Poi( $\nu$ ) distributed rv for task a') $ P(X\leq 0) = 0.368$ $P(X\leq 1) = 0.736$ $P(X\leq 2) = 0.92$ $P(X\leq 3) = 0.981$ $P(X\leq 4) = 0.996$ $P(X\leq 5) = 0.999$ I have computed $ R(k) = \frac{e^{-2n} \prod_{i=1}^n \frac{2^{k_i}}{k_i !} }{e^{-n}\prod_{i=1}^n \frac{1}{k_i !}} = e^2 2^{\sum_{i=1}^n k_i} $ . But how can i now compute $c^*$ ? If i have $c^*$ then i can compute $\gamma^*$ with the fact that $ E_{\nu_0}[T] = P(R(k)>c^*) + \gamma^* P(R(k)=c^*) = 0.05 = \alpha  $","Let be a Poi( ) distributed rv with unknown and we set . We want to test the hypotheses against a) We look at the (randomized) Neyman - Pearson - Test which has the form , with and is the Maximum Liklihood quotient. Compute and such that is a test with niveau i.e. . b) You see that . How do you decide in terms of the test wich you construct in a)? Values of a Poi( ) distributed rv for task a') I have computed . But how can i now compute ? If i have then i can compute with the fact that","X \nu \nu \in (0,\infty)  \theta:=\nu   H_0:\nu_0=1   H_1:\nu_1=\nu_0=2  T(k) = \begin{cases}
1 & R(k) > c \\
\gamma & R(k)=c \\
0 & R(k)<c
\end{cases} c \in \mathbb{R}  \gamma \in [0,1]  R(k) := \frac{P_{\nu_1}(X=k)}{P_{\nu_0}(X=k)}  c^*  \gamma^*  T \alpha = 0.05 E_{\nu_0}[T]=\alpha X=3 \nu  P(X\leq 0) = 0.368 P(X\leq 1) = 0.736 P(X\leq 2) = 0.92 P(X\leq 3) = 0.981 P(X\leq 4) = 0.996 P(X\leq 5) = 0.999  R(k) = \frac{e^{-2n} \prod_{i=1}^n \frac{2^{k_i}}{k_i !} }{e^{-n}\prod_{i=1}^n \frac{1}{k_i !}} = e^2 2^{\sum_{i=1}^n k_i}  c^* c^* \gamma^*  E_{\nu_0}[T] = P(R(k)>c^*) + \gamma^* P(R(k)=c^*) = 0.05 = \alpha  ","['probability', 'probability-theory', 'statistics', 'hypothesis-testing']"
15,finding the mean and variance descriptive statistics,finding the mean and variance descriptive statistics,,"Suppose the following data are obtained by recording $X$ , the number of customers that arrive at an automatic banking machine during $15$ successive one-minute time intervals. Q) Record the mean and variance. mean is $u_{X} = \sum_{x=1}^{15} x f_{X}(x) = 1.67$ using the data from below: $f_{X}(0) = 4/15, f_{X}(1) = 3/15, f_{X}(2) = 4/15, f_{X}(3) = 2/15, f_{X}(4) = 2/15$ variance is $\sigma^2_{X} = \sum_{x=1}^{15} x f_{X}(x) - 1.67^2 = 1.88$ the mean is the same as the solution, but the variance they got was $1.952$ . What am I doing wrong?","Suppose the following data are obtained by recording , the number of customers that arrive at an automatic banking machine during successive one-minute time intervals. Q) Record the mean and variance. mean is using the data from below: variance is the mean is the same as the solution, but the variance they got was . What am I doing wrong?","X 15 u_{X} = \sum_{x=1}^{15} x f_{X}(x) = 1.67 f_{X}(0) = 4/15, f_{X}(1) = 3/15, f_{X}(2) = 4/15, f_{X}(3) = 2/15, f_{X}(4) = 2/15 \sigma^2_{X} = \sum_{x=1}^{15} x f_{X}(x) - 1.67^2 = 1.88 1.952","['probability', 'statistics', 'descriptive-statistics']"
16,"Showing that $\sum\limits_{i=1}^n X_i^2$ is a sufficient statistic for $\theta$ from an $N(0,\theta)$ population",Showing that  is a sufficient statistic for  from an  population,"\sum\limits_{i=1}^n X_i^2 \theta N(0,\theta)","I am trying to show that, for a random sample $X_1,...,X_n$ drawn from an $N(0,\theta)$ population, $\sum\limits_{i=1}^nX_i^2$ is a sufficient statistic for theta. I figured I would use the Factorization theorem so I looked at the joint pdf: $$f(x_1,x_2...,x_n|\theta)=\left(\frac{1}{2\pi\theta}\right)^{n/2}e^{-\frac{1}{2\theta} \sum\limits_{i=1}^nx_i^2}$$ The factorization theorem says a statistic $T(X)$ is sufficient if the joint pdf of the sample factors as $$f(x|\theta)=g(T(x)|\theta)h(x) $$ I think, then, that I'm done because I can just let $h(x)=1$ or even $h(x)=\left(\frac{1}{2\pi}\right)^{n/2}$ . Is my use of the factorization theorem correct in this case? Thanks!","I am trying to show that, for a random sample drawn from an population, is a sufficient statistic for theta. I figured I would use the Factorization theorem so I looked at the joint pdf: The factorization theorem says a statistic is sufficient if the joint pdf of the sample factors as I think, then, that I'm done because I can just let or even . Is my use of the factorization theorem correct in this case? Thanks!","X_1,...,X_n N(0,\theta) \sum\limits_{i=1}^nX_i^2 f(x_1,x_2...,x_n|\theta)=\left(\frac{1}{2\pi\theta}\right)^{n/2}e^{-\frac{1}{2\theta}
\sum\limits_{i=1}^nx_i^2} T(X) f(x|\theta)=g(T(x)|\theta)h(x)  h(x)=1 h(x)=\left(\frac{1}{2\pi}\right)^{n/2}","['probability', 'statistics']"
17,proof of conditional expectation given n i.i.d. random variables,proof of conditional expectation given n i.i.d. random variables,,"This is another question from my self-study of Hayashi's Econometrics. How do we show in mathematical proof that given: $X = \begin{bmatrix}x_{1}' \\x_{2}' \\\vdots \\x_{n}'\end{bmatrix}$ where $x_{i} = \begin{bmatrix}x_{i1} \\x_{i2} \\\vdots \\x_{ik} \end{bmatrix} $ and $y = \begin{bmatrix}y_{1}' \\y_{2}' \\\vdots \\y_{n}'\end{bmatrix}$ If $(y, X)$ is a random sample, where $(y_{i},x_{i})$ and $(y_{j},x_{j})$ are i.i.d. for $i\neq j$ , and $\epsilon_{i}$ is a function of $(y_{i},x_{i})$ , then the assumption: $E[\epsilon_{i}|X]$ = $E[\epsilon_{i}|x_{i}]$ and $E[\epsilon_{i}^2|X]$ = $E[\epsilon_{i}^2|x_{i}]$ ? I mean it looks intuitively correct, but I checked the probability text and couldn't find a matching theorem corresponding to this. The original text from the book Econometrics Hayashi is quoted: Thank you very much. Update of the proof from my cousin: $E[\epsilon_{i}|X]$ = $E[\epsilon_{i}|x_{i}]$ $E[\epsilon_{i}|x_{1},x_{2}, \ldots,x_{n}]  = \int_{-\infty}^{\infty} \epsilon_{i} \cdot f_{\epsilon_{i}|X}(\epsilon_{i}|x_{1},x_{2}, \ldots,x_{n})d\epsilon_{i}$ $= \int_{-\infty}^{\infty} \epsilon_{i} \cdot \dfrac{f(\epsilon_{i},x_{1},x_{2}, \ldots,x_{n})}{f(x_{1},x_{2}, \ldots,x_{n})} d\epsilon_{i}$ $= \int_{-\infty}^{\infty} \epsilon_{i} \cdot \dfrac{f(\epsilon_{i},x_{1},x_{2}, \ldots,x_{n})}{f(x_{1})f(x_{2}) \cdots f(x_{n})} d\epsilon_{i}$ $= \int_{-\infty}^{\infty} \epsilon_{i} \cdot \dfrac{f(\epsilon_{i},x_{i})f(x_{1})f(x_{2}) \cdots f(x_{n})}{f(x_{i})f(x_{1})f(x_{2}) \cdots f(x_{i-1})f(x_{i+1})f(x_{n})} d\epsilon_{i}$ $= \int_{-\infty}^{\infty} \epsilon_{i} \cdot \dfrac{f(\epsilon_{i},x_{i})}{f(x_{i})} d\epsilon_{i}$ $= \int_{-\infty}^{\infty} \epsilon_{i} \cdot f(\epsilon_{i}|x_{i}) d\epsilon_{i}$ $= E[\epsilon_{i}|x_{i}]$ QED I really appreciate the help from StackExchange Mathematics. This question is more related to econometrics in Cross Validation section. I post the same question there but got downvoted for no reason and was held on hold. Maybe my questions are naiive to some of you, but I really appreciate it your tolerance and kindness in helping me understand some of these theorems/proofs.","This is another question from my self-study of Hayashi's Econometrics. How do we show in mathematical proof that given: where and If is a random sample, where and are i.i.d. for , and is a function of , then the assumption: = and = ? I mean it looks intuitively correct, but I checked the probability text and couldn't find a matching theorem corresponding to this. The original text from the book Econometrics Hayashi is quoted: Thank you very much. Update of the proof from my cousin: = QED I really appreciate the help from StackExchange Mathematics. This question is more related to econometrics in Cross Validation section. I post the same question there but got downvoted for no reason and was held on hold. Maybe my questions are naiive to some of you, but I really appreciate it your tolerance and kindness in helping me understand some of these theorems/proofs.","X = \begin{bmatrix}x_{1}' \\x_{2}' \\\vdots \\x_{n}'\end{bmatrix} x_{i} = \begin{bmatrix}x_{i1} \\x_{i2} \\\vdots \\x_{ik} \end{bmatrix}  y = \begin{bmatrix}y_{1}' \\y_{2}' \\\vdots \\y_{n}'\end{bmatrix} (y, X) (y_{i},x_{i}) (y_{j},x_{j}) i\neq j \epsilon_{i} (y_{i},x_{i}) E[\epsilon_{i}|X] E[\epsilon_{i}|x_{i}] E[\epsilon_{i}^2|X] E[\epsilon_{i}^2|x_{i}] E[\epsilon_{i}|X] E[\epsilon_{i}|x_{i}] E[\epsilon_{i}|x_{1},x_{2}, \ldots,x_{n}]
 = \int_{-\infty}^{\infty} \epsilon_{i} \cdot f_{\epsilon_{i}|X}(\epsilon_{i}|x_{1},x_{2}, \ldots,x_{n})d\epsilon_{i} = \int_{-\infty}^{\infty} \epsilon_{i} \cdot \dfrac{f(\epsilon_{i},x_{1},x_{2}, \ldots,x_{n})}{f(x_{1},x_{2}, \ldots,x_{n})} d\epsilon_{i} = \int_{-\infty}^{\infty} \epsilon_{i} \cdot \dfrac{f(\epsilon_{i},x_{1},x_{2}, \ldots,x_{n})}{f(x_{1})f(x_{2}) \cdots f(x_{n})} d\epsilon_{i} = \int_{-\infty}^{\infty} \epsilon_{i} \cdot \dfrac{f(\epsilon_{i},x_{i})f(x_{1})f(x_{2}) \cdots f(x_{n})}{f(x_{i})f(x_{1})f(x_{2}) \cdots f(x_{i-1})f(x_{i+1})f(x_{n})} d\epsilon_{i} = \int_{-\infty}^{\infty} \epsilon_{i} \cdot \dfrac{f(\epsilon_{i},x_{i})}{f(x_{i})} d\epsilon_{i} = \int_{-\infty}^{\infty} \epsilon_{i} \cdot f(\epsilon_{i}|x_{i}) d\epsilon_{i} = E[\epsilon_{i}|x_{i}]","['linear-algebra', 'probability', 'statistics', 'conditional-expectation', 'economics']"
18,"A class of sets ""picking out"" a set","A class of sets ""picking out"" a set",,"The idea of sets being shattered comes up a lot in statistical learning theory with applications to VC dimension. Before learning about this, I am trying to understand the following definition. Let $F=\left \{ x_{1}, x_{2},...,x_{n} \right \}$ be a finite set.  Let $G$ be a subset of $F$ .  We say that a class of sets $\mathcal{A}$ $\textbf{picks out}$ $G$ if $$A \cap F = G$$ for some set $A \in \mathcal{A}$ . The author then gives the following example: Consider the class of sets $\mathcal{A} =\left \{ (a,b): a \leq b \right \}$ .  Suppose that $F=\left \{ 1,2,7,8,9 \right \}$ and $G = \left \{ 2,7 \right \}.$ Then $\mathcal{A}$ picks out $G$ since $A \cap F = G$ , if we take $A= \left \{ 1.5,7.5 \right \}$ for example. Clearly, looking at this example, $$A \cap F = \emptyset \neq G.$$ So, what am I missing? Thanks in advance!","The idea of sets being shattered comes up a lot in statistical learning theory with applications to VC dimension. Before learning about this, I am trying to understand the following definition. Let be a finite set.  Let be a subset of .  We say that a class of sets if for some set . The author then gives the following example: Consider the class of sets .  Suppose that and Then picks out since , if we take for example. Clearly, looking at this example, So, what am I missing? Thanks in advance!","F=\left \{ x_{1}, x_{2},...,x_{n} \right \} G F \mathcal{A} \textbf{picks out} G A \cap F = G A \in \mathcal{A} \mathcal{A} =\left \{ (a,b): a \leq b \right \} F=\left \{ 1,2,7,8,9 \right \} G = \left \{ 2,7 \right \}. \mathcal{A} G A \cap F = G A= \left \{ 1.5,7.5 \right \} A \cap F = \emptyset \neq G.",['statistics']
19,Conditional Probabilities - Are the Events Independent - Confused About part of this problem,Conditional Probabilities - Are the Events Independent - Confused About part of this problem,,"No answers to refer to, so would be really greatful if someone can take a look at this problem and explain me a bit where am I going wrong or if I've done something right to begin with, haha. A fair coin is tossed tree times. Specific the probability space for the experiment and consider the following events: A: The result of the third toss is heads B: the coin shows heads exactly two times Compute the conditional probabilities P(A given B) and P(B given A). Are A and B independent? So our sample space is: ${HHH}, {TTT}, {HHT}, {HTT}, {THH}, {TTH}, {HTH}, {THT}$ Hence, $P(A): 0.5$ $P(B): 0.375$ We can see that event A appears exactly 2 times when event B happens, hence, A is independent of B as the conditional probability of A given B is still equal to the probability of event A= 0.5 However, I'm a bit confused for the second part in finding the conditional probability of B given A. B is appearing also twice while A is taking place, but that is different than the probability of event B alone, so is it true that B is dependent on A? 0.66 versus the P(B) = 0.375. If so, how do we compute the conditional probability? Any help would be much much aprpeciated!","No answers to refer to, so would be really greatful if someone can take a look at this problem and explain me a bit where am I going wrong or if I've done something right to begin with, haha. A fair coin is tossed tree times. Specific the probability space for the experiment and consider the following events: A: The result of the third toss is heads B: the coin shows heads exactly two times Compute the conditional probabilities P(A given B) and P(B given A). Are A and B independent? So our sample space is: Hence, We can see that event A appears exactly 2 times when event B happens, hence, A is independent of B as the conditional probability of A given B is still equal to the probability of event A= 0.5 However, I'm a bit confused for the second part in finding the conditional probability of B given A. B is appearing also twice while A is taking place, but that is different than the probability of event B alone, so is it true that B is dependent on A? 0.66 versus the P(B) = 0.375. If so, how do we compute the conditional probability? Any help would be much much aprpeciated!","{HHH}, {TTT}, {HHT}, {HTT}, {THH}, {TTH}, {HTH}, {THT} P(A): 0.5 P(B): 0.375","['probability', 'statistics', 'conditional-probability']"
20,Assumptions on test statistics to guarantee uniform asymptotic level,Assumptions on test statistics to guarantee uniform asymptotic level,,"I'm trying to formalize the fundamental ideas behind test statistics in the context of hypothesis testing. In particular, I want to define different concepts of test statistics leading to different desireable qualities of tests. I'm having trouble formalizing the idea of a ""uniform test statistic"" yielding a test of uniformly asymptotic level (defined below) and was hoping for some input. Setup Let $(\mathcal{X}, \mathbb{E})$ be a measure space and let $\mathcal{P}$ be a set of probabilty measures on the space. Let furthmore $\mathcal{P}_0 \subseteq \mathcal{P}$ . We imagine getting a sample of size $n$ sampled independently, i.e. some $x \in \mathcal{X}^n$ and want to determine whether any of the measures in $\mathcal{P}_0$ are acceptable distributions for the observation. For each $n \in \mathbb{N}$ , we define a test of size $n$ as a partition of $\mathcal{X}^n$ into an acceptance region $\mathcal{A}_n$ and a critical region $\mathcal{A}_n^c$ . This partition is also expressed through the critical function $\psi_n: \mathcal{X}^n \to \{0,1\}$ given by $$ \psi_n(x) = \begin{cases} 0 & \text{if $x \in \mathcal{A}_n$}\\ 1 & \text{if $x \in \mathcal{A}_n^c$} \end{cases} $$ A sequence of tests is either $(\mathcal{A}_n)_{n \in \mathbb{N}}$ or equivalently $(\psi_n)_{n \in \mathbb{N}}$ . For a given level $\alpha \in (0,1)$ a sequence of tests is said to have pointwise asymptotic level if $$ \sup_{\nu \in \mathcal{P}_0} \limsup_{n \to \infty} P_\nu(\psi_n =1) \leq \alpha $$ and uniformly asymptotic level if $$ \limsup_{n \to \infty} \sup_{\nu \in \mathcal{P}_0}  P_\nu(\psi_n =1) \leq \alpha $$ where $P_\nu$ denotes the probability assuming that $X$ has distribution $\nu$ . Pointwise asymptotic test statistic Let $(T_n)_{n \in \mathbb{N}}$ be a sequence of functions $T_n: \mathcal{X}^n \to \mathbb{R}$ . If $T_n(X^n)$ converges in distribution to the same distribution for all $\nu \in \mathcal{P_0}$ , we say that $(T_n)_{n \in \mathbb{N}}$ is a pointwise asymptotic test statistic wrt. $\mathcal{P}_0$ . Letting $V$ be a random variable with the same distribution as the limit of $T_n(X)$ for any $\nu \in \mathcal{P}_0$ , if $\mathcal{B}$ is a closed set such that $P(V \in \mathcal{B}) \leq \alpha$ , we say that the sequence of tests $$ \psi_n(x) = \begin{cases} 1 & \text{if $T_n(x) \in \mathcal{B}$}\\ 0 & \text{otherwise} \end{cases} $$ is based on the pointwise asymptotic test statistic $(T_n)_{n \in \mathbb{N}}$ . Note that it is quite easy to show that this test has pointwise asymptotic level by an application of the Portmanteau theorem (for the second to last inequality) since $$ \limsup_{n \to \infty} P_\nu(\psi_n = 1) = \limsup_{n \to \infty} P_\nu(T_n(X^n) \in \mathcal{B}) \leq P(V \in \mathcal{B}) \leq \alpha $$ and then taking supremums. Uniform asymptotic test statistic What extra assumptions are required to prove uniform asymptotic level of a test constructed as above? We would need to ensure that the $$ \sup_{\nu \in \mathcal{P}_0} P_\nu(\psi_n=1) = \sup_{\nu \in \mathcal{P}_0} P_\nu(T_n(X^n) \in \mathcal{B}) $$ are convergent to $P(V \in \mathcal{B})$ . What is a sufficient condition for this to occur? Hope someone can help! EDIT: I'm thinking that some conditions are required on $\mathcal{P}_0$ , since in the case of $\mathcal{P}$ being all distributions on $\mathbb{R}$ with finite variance and $\mathcal{P}_0$ being all distributions with mean zero, one can show that the usual $t$ -test has pointwise asymptotic level but not uniform asymptotic level.","I'm trying to formalize the fundamental ideas behind test statistics in the context of hypothesis testing. In particular, I want to define different concepts of test statistics leading to different desireable qualities of tests. I'm having trouble formalizing the idea of a ""uniform test statistic"" yielding a test of uniformly asymptotic level (defined below) and was hoping for some input. Setup Let be a measure space and let be a set of probabilty measures on the space. Let furthmore . We imagine getting a sample of size sampled independently, i.e. some and want to determine whether any of the measures in are acceptable distributions for the observation. For each , we define a test of size as a partition of into an acceptance region and a critical region . This partition is also expressed through the critical function given by A sequence of tests is either or equivalently . For a given level a sequence of tests is said to have pointwise asymptotic level if and uniformly asymptotic level if where denotes the probability assuming that has distribution . Pointwise asymptotic test statistic Let be a sequence of functions . If converges in distribution to the same distribution for all , we say that is a pointwise asymptotic test statistic wrt. . Letting be a random variable with the same distribution as the limit of for any , if is a closed set such that , we say that the sequence of tests is based on the pointwise asymptotic test statistic . Note that it is quite easy to show that this test has pointwise asymptotic level by an application of the Portmanteau theorem (for the second to last inequality) since and then taking supremums. Uniform asymptotic test statistic What extra assumptions are required to prove uniform asymptotic level of a test constructed as above? We would need to ensure that the are convergent to . What is a sufficient condition for this to occur? Hope someone can help! EDIT: I'm thinking that some conditions are required on , since in the case of being all distributions on with finite variance and being all distributions with mean zero, one can show that the usual -test has pointwise asymptotic level but not uniform asymptotic level.","(\mathcal{X}, \mathbb{E}) \mathcal{P} \mathcal{P}_0 \subseteq \mathcal{P} n x \in \mathcal{X}^n \mathcal{P}_0 n \in \mathbb{N} n \mathcal{X}^n \mathcal{A}_n \mathcal{A}_n^c \psi_n: \mathcal{X}^n \to \{0,1\} 
\psi_n(x) = \begin{cases}
0 & \text{if x \in \mathcal{A}_n}\\
1 & \text{if x \in \mathcal{A}_n^c}
\end{cases}
 (\mathcal{A}_n)_{n \in \mathbb{N}} (\psi_n)_{n \in \mathbb{N}} \alpha \in (0,1) 
\sup_{\nu \in \mathcal{P}_0} \limsup_{n \to \infty} P_\nu(\psi_n =1) \leq \alpha
 
\limsup_{n \to \infty} \sup_{\nu \in \mathcal{P}_0}  P_\nu(\psi_n =1) \leq \alpha
 P_\nu X \nu (T_n)_{n \in \mathbb{N}} T_n: \mathcal{X}^n \to \mathbb{R} T_n(X^n) \nu \in \mathcal{P_0} (T_n)_{n \in \mathbb{N}} \mathcal{P}_0 V T_n(X) \nu \in \mathcal{P}_0 \mathcal{B} P(V \in \mathcal{B}) \leq \alpha 
\psi_n(x) = \begin{cases}
1 & \text{if T_n(x) \in \mathcal{B}}\\
0 & \text{otherwise}
\end{cases}
 (T_n)_{n \in \mathbb{N}} 
\limsup_{n \to \infty} P_\nu(\psi_n = 1) = \limsup_{n \to \infty} P_\nu(T_n(X^n) \in \mathcal{B}) \leq P(V \in \mathcal{B}) \leq \alpha
 
\sup_{\nu \in \mathcal{P}_0} P_\nu(\psi_n=1) = \sup_{\nu \in \mathcal{P}_0} P_\nu(T_n(X^n) \in \mathcal{B})
 P(V \in \mathcal{B}) \mathcal{P}_0 \mathcal{P} \mathbb{R} \mathcal{P}_0 t","['statistics', 'hypothesis-testing']"
21,Sum of Beta Random Variables,Sum of Beta Random Variables,,"Supose I have $I$ independently (but not necessarily identically) distributed beta random variables, $X_i = \text{beta}(\alpha_i,\beta_i)$ , for $i=1,\dots,I$ . Is there a known distribution for the sum of these r.v.s, $Y=\sum_i X_i$ ? Furthermore, is there a known distribution for the mixture of these r.v.s, as in $Y=\sum_i \omega_i X_i$ , where $\sum_i \omega_i = 1$ ?","Supose I have independently (but not necessarily identically) distributed beta random variables, , for . Is there a known distribution for the sum of these r.v.s, ? Furthermore, is there a known distribution for the mixture of these r.v.s, as in , where ?","I X_i = \text{beta}(\alpha_i,\beta_i) i=1,\dots,I Y=\sum_i X_i Y=\sum_i \omega_i X_i \sum_i \omega_i = 1","['statistics', 'probability-distributions', 'random-variables']"
22,Estimating a parameter from a sequence of signals with non i.i.d. noise,Estimating a parameter from a sequence of signals with non i.i.d. noise,,"I have the following statistics/probability question: Let $A$ and $B$ be two finite sets of real numbers. Let $n \geq 1$ . Let $T_1,...,T_n$ be random variables with values in $A$ (not necessarily independent). Let $Q$ be a random variable with values in $B$ .  Let $\epsilon_1, \epsilon_2,...,\epsilon_n$ be a sequence of independent random variables which are identically normally distributed, with mean 0 and variance $\sigma>0$ . Assume that for all $1 \leq i \leq n$ , $\epsilon_i$ is independent of $T_i$ and of $Q$ (note that $\epsilon_i$ may be correlated with $T_{i-1}$ for instance). Let \begin{equation*} X_i=T_i+Q+\epsilon_i \end{equation*} I would like to construct a random variable $Q_n$ that is $(X_1,X_2,...,X_n)$ -measurable, and such that for some constant $C$ and $d>0$ that depend only on $A$ , $B$ and $\sigma$ , we have \begin{equation*} \left\|Q_n-Q\right\|_{L^2} \leq C n^{-d}. \end{equation*} In words, knowing $X_1,X_2,...,X_n$ , I would like to approximate $Q$ in an efficient way. Many thanks!","I have the following statistics/probability question: Let and be two finite sets of real numbers. Let . Let be random variables with values in (not necessarily independent). Let be a random variable with values in .  Let be a sequence of independent random variables which are identically normally distributed, with mean 0 and variance . Assume that for all , is independent of and of (note that may be correlated with for instance). Let I would like to construct a random variable that is -measurable, and such that for some constant and that depend only on , and , we have In words, knowing , I would like to approximate in an efficient way. Many thanks!","A B n \geq 1 T_1,...,T_n A Q B \epsilon_1, \epsilon_2,...,\epsilon_n \sigma>0 1 \leq i \leq n \epsilon_i T_i Q \epsilon_i T_{i-1} \begin{equation*}
X_i=T_i+Q+\epsilon_i
\end{equation*} Q_n (X_1,X_2,...,X_n) C d>0 A B \sigma \begin{equation*}
\left\|Q_n-Q\right\|_{L^2} \leq C n^{-d}.
\end{equation*} X_1,X_2,...,X_n Q","['probability-theory', 'statistics', 'normal-distribution', 'parameter-estimation']"
23,What is the probability of SPECIAL PIRATE KNIVES GAME ??,What is the probability of SPECIAL PIRATE KNIVES GAME ??,,"https://www.google.com/search?q=pirate+knife+game&rlz=1C1CHZL_enTH705TH708&source=lnms&tbm=isch&sa=X&ved=0ahUKEwirheygt5TgAhUYSX0KHbQ5AacQ_AUIDigB&biw=1536&bih=762 The link above is what I refer to as "" Pirate Knives game "". Traditionally, it is the game which your objective is to find a one and the only spot hit the pirates. So there are 15 spots and 15 knives. Each turn player 1 and 2 will stab a knife in one spot and the person who stab to the right spot wins! But I am a lazy person so I create a new game and bet with my friends. **The betting is fixed 10 if he cannot win within 10 knives. EDITED: The game is 20 dollar bet 10 is fixed and 10 is marginally decreased per round. IF he wins the first round he will get 20 but if he fails at first round the bet decrease to 19 dollars Winning bet is 10 + (10-k+1) The faster he wins the higher he gets.** So basically, I change this game to be one player game. Which I found after watching my friends smile and sad, before and after the game. I realized that it is an unfair game for him. X denotes the random variable that stands for the round that he wins.  This game is no-replacement event then it is sample space of each round decrease by one. The probability of each round  Pr(X= $x_{i}$ ) = 1/15 , 1/14 , 1/13 , ... , 1/7 , 1/6. Even though he got many chances to stab that thing he still has the chance only of 1/6 at most. That made me realize that the game is designed not to win easily it is a famous game the play with the fear and thrill of children. It must be more than 10 for an expected round that the knife will hit that spot. So here is the favor I would like to ask that what is the probability of my friends will win.","https://www.google.com/search?q=pirate+knife+game&rlz=1C1CHZL_enTH705TH708&source=lnms&tbm=isch&sa=X&ved=0ahUKEwirheygt5TgAhUYSX0KHbQ5AacQ_AUIDigB&biw=1536&bih=762 The link above is what I refer to as "" Pirate Knives game "". Traditionally, it is the game which your objective is to find a one and the only spot hit the pirates. So there are 15 spots and 15 knives. Each turn player 1 and 2 will stab a knife in one spot and the person who stab to the right spot wins! But I am a lazy person so I create a new game and bet with my friends. **The betting is fixed 10 if he cannot win within 10 knives. EDITED: The game is 20 dollar bet 10 is fixed and 10 is marginally decreased per round. IF he wins the first round he will get 20 but if he fails at first round the bet decrease to 19 dollars Winning bet is 10 + (10-k+1) The faster he wins the higher he gets.** So basically, I change this game to be one player game. Which I found after watching my friends smile and sad, before and after the game. I realized that it is an unfair game for him. X denotes the random variable that stands for the round that he wins.  This game is no-replacement event then it is sample space of each round decrease by one. The probability of each round  Pr(X= ) = 1/15 , 1/14 , 1/13 , ... , 1/7 , 1/6. Even though he got many chances to stab that thing he still has the chance only of 1/6 at most. That made me realize that the game is designed not to win easily it is a famous game the play with the fear and thrill of children. It must be more than 10 for an expected round that the knife will hit that spot. So here is the favor I would like to ask that what is the probability of my friends will win.",x_{i},"['probability', 'statistics']"
24,Find the UMVUE of $b^{\mu}$,Find the UMVUE of,b^{\mu},"Let $X_1,X_2,..X_n$ be a random sample from Cauchy $(\mu,1)$ population. Find the UMVUE of $b^{\mu}$ where $b$ is any positive real number. Now actually calculating sample mean won't work here because its distribution is also Cauchy $(\mu,1)$ ,so expectation won't exist.And all I know is that the sample median asymptotically goes to $\mu$ ,so it won't work here either.Is there any trick other than the normal procedures like Lehmann Scheffe to do this?","Let be a random sample from Cauchy population. Find the UMVUE of where is any positive real number. Now actually calculating sample mean won't work here because its distribution is also Cauchy ,so expectation won't exist.And all I know is that the sample median asymptotically goes to ,so it won't work here either.Is there any trick other than the normal procedures like Lehmann Scheffe to do this?","X_1,X_2,..X_n (\mu,1) b^{\mu} b (\mu,1) \mu","['statistics', 'probability-distributions']"
25,Higher moments of linear regression residuals?,Higher moments of linear regression residuals?,,"Background In the following linear regression with i.i.d $\epsilon_i$ $(i = 1, \cdots, n)$ with mean 0 finite variance $\sigma^2$ , \begin{align*} Y_i = X_i^\intercal\beta + \epsilon_i \end{align*} we know the least-squares estimator for $\beta$ is \begin{align*} \hat{\beta}=(X^\intercal X)^{-1}X^\intercal Y \end{align*} where $X = (X_1, \cdots, X_n)^\intercal \in \mathbb{R}^{n\times p}$ , $Y = (Y_1,\cdots, Y_n)^\intercal \in \mathbb{R}^n$ . Now, we can easily derive the variance of $\hat{\epsilon} = Y - X\hat{\beta}$ with \begin{align*} \text{Var}(\hat{\epsilon}) &= \text{Var}((I-H)Y) \\ &\overset{\heartsuit}{=} (I-H)\text{Var}(Y)(I-H)^\intercal \\ &= \sigma^2(I-H)(I-H)^\intercal \\ &\overset{\spadesuit}{=} \sigma^2(I-H) \end{align*} where $H = X(X^\intercal X)^{-1}X^\intercal$ is a projection matrix of rank $p$ , thus justifying equality $(\spadesuit)$ . Hence, this allows us to find an unbiased estimator for $\sigma^2$ , since \begin{align*} \text{Trace}(\text{Var}(\hat{\epsilon})) = \sigma^2\text{Trace}(I-H) = \sigma^2(n-p) \implies \widehat{\sigma^2}=(n-p)^{-1}\|Y - \hat{Y}\|_2^2 \end{align*} An attempt for higher moments How would we generalize this computation in coming up with unbiased estimators for the third centralized moments \begin{align*} \mu_3 \overset{\text{def}}{=} \mathbb{E}\epsilon^3_i  \end{align*} or beyond? Here's my attempt. Define \begin{align*} \mathcal{S}(\hat{\epsilon}) = \mathbb{E}(\hat{\epsilon}_i - \mathbb{E}\hat{\epsilon}_i)^{\otimes 3} \end{align*} I don't understand tensor products quite well, but I'm guessing \begin{align*} \mathcal{S}(\hat{\epsilon}) = (I-H) \underset{(I-H)}{\mathcal{S}(Y)}(I-H)^\intercal = \mu_3(I-H) \underset{(I-H)}{I_{n\times n \times n}}(I-H)^\intercal \end{align*} in the same way as equality $(\heartsuit)$ under ""Background"".  I included the additional underset $(I-H)$ to elicit the idea that we are now ""matrix"" multiplying along the additional dimension induced from the 3-dimensional tensor. But, I don't quite understand what it means to multiply in this direction. Am I on the right track? Are there other matrix tricks I could use? Edit: I found that that tensor product is simply a 3-mode product, resulting in \begin{align*} [\mathcal{S}(\hat{\epsilon})]_{ijk} = \mu_3 \sum_{v=1}^{n}M_{iv}M_{jv}M_{kv} \end{align*} where $M = I - H$ is still a projection matrix. How to proceed from here?","Background In the following linear regression with i.i.d with mean 0 finite variance , we know the least-squares estimator for is where , . Now, we can easily derive the variance of with where is a projection matrix of rank , thus justifying equality . Hence, this allows us to find an unbiased estimator for , since An attempt for higher moments How would we generalize this computation in coming up with unbiased estimators for the third centralized moments or beyond? Here's my attempt. Define I don't understand tensor products quite well, but I'm guessing in the same way as equality under ""Background"".  I included the additional underset to elicit the idea that we are now ""matrix"" multiplying along the additional dimension induced from the 3-dimensional tensor. But, I don't quite understand what it means to multiply in this direction. Am I on the right track? Are there other matrix tricks I could use? Edit: I found that that tensor product is simply a 3-mode product, resulting in where is still a projection matrix. How to proceed from here?","\epsilon_i (i = 1, \cdots, n) \sigma^2 \begin{align*}
Y_i = X_i^\intercal\beta + \epsilon_i
\end{align*} \beta \begin{align*}
\hat{\beta}=(X^\intercal X)^{-1}X^\intercal Y
\end{align*} X = (X_1, \cdots, X_n)^\intercal \in \mathbb{R}^{n\times p} Y = (Y_1,\cdots, Y_n)^\intercal \in \mathbb{R}^n \hat{\epsilon} = Y - X\hat{\beta} \begin{align*}
\text{Var}(\hat{\epsilon}) &= \text{Var}((I-H)Y) \\
&\overset{\heartsuit}{=} (I-H)\text{Var}(Y)(I-H)^\intercal \\
&= \sigma^2(I-H)(I-H)^\intercal \\
&\overset{\spadesuit}{=} \sigma^2(I-H)
\end{align*} H = X(X^\intercal X)^{-1}X^\intercal p (\spadesuit) \sigma^2 \begin{align*}
\text{Trace}(\text{Var}(\hat{\epsilon})) = \sigma^2\text{Trace}(I-H) = \sigma^2(n-p) \implies \widehat{\sigma^2}=(n-p)^{-1}\|Y - \hat{Y}\|_2^2
\end{align*} \begin{align*}
\mu_3 \overset{\text{def}}{=} \mathbb{E}\epsilon^3_i 
\end{align*} \begin{align*}
\mathcal{S}(\hat{\epsilon}) = \mathbb{E}(\hat{\epsilon}_i - \mathbb{E}\hat{\epsilon}_i)^{\otimes 3}
\end{align*} \begin{align*}
\mathcal{S}(\hat{\epsilon}) = (I-H) \underset{(I-H)}{\mathcal{S}(Y)}(I-H)^\intercal = \mu_3(I-H) \underset{(I-H)}{I_{n\times n \times n}}(I-H)^\intercal
\end{align*} (\heartsuit) (I-H) \begin{align*}
[\mathcal{S}(\hat{\epsilon})]_{ijk} = \mu_3 \sum_{v=1}^{n}M_{iv}M_{jv}M_{kv}
\end{align*} M = I - H","['linear-algebra', 'statistics', 'tensor-products', 'projection-matrices']"
26,Stuck at hypothesis testing assignment,Stuck at hypothesis testing assignment,,So I have this assignment in statistics that states the following: We need to either accept or throw away a big package of processors. Because of quality control we take take a sample of 200 processors and find 24 that are not working. The maker of the processors claims that in the entire package there are at most 10 processors that are not working. Do we have enough evidence to throw away his statement with a confidence level of 4%. I assume this is a Hypothesis Testing question with the formula being equaled to: z = $\frac{p - po}{\sqrt{\frac{po(1-po)}{n}}}$ I can see that n = 200 however I don't know what is p or what is po Is p = $\frac{24}{200}$ and po = $\frac{10}{200}$ or is it the other way around?,So I have this assignment in statistics that states the following: We need to either accept or throw away a big package of processors. Because of quality control we take take a sample of 200 processors and find 24 that are not working. The maker of the processors claims that in the entire package there are at most 10 processors that are not working. Do we have enough evidence to throw away his statement with a confidence level of 4%. I assume this is a Hypothesis Testing question with the formula being equaled to: z = I can see that n = 200 however I don't know what is p or what is po Is p = and po = or is it the other way around?,\frac{p - po}{\sqrt{\frac{po(1-po)}{n}}} \frac{24}{200} \frac{10}{200},['statistics']
27,"UMVUE of $\theta$ when $X_1,\ldots,X_n$ are i.i.d with pdf $f(x)=\frac{(\ln\theta)\theta^x }{\theta -1}$",UMVUE of  when  are i.i.d with pdf,"\theta X_1,\ldots,X_n f(x)=\frac{(\ln\theta)\theta^x }{\theta -1}","I'm having some trouble finding the UMVU estimator of $\theta$ for the following distribution $$f(x)=\frac{(\ln\theta)\theta^x }{\theta -1} \text{ for } x \in (0,1)$$ Specifically, I know $T_n=\sum x_i$ is a sufficient complete statistics, but I cannot find an unbiased estimator that is function of $T_n$ nor the MVE estimator. (I actually have trouble even in finding any unbiased estimator of $\theta$ , so that I cannot use Rao Blackwell theorem). Thank you for your help.","I'm having some trouble finding the UMVU estimator of for the following distribution Specifically, I know is a sufficient complete statistics, but I cannot find an unbiased estimator that is function of nor the MVE estimator. (I actually have trouble even in finding any unbiased estimator of , so that I cannot use Rao Blackwell theorem). Thank you for your help.","\theta f(x)=\frac{(\ln\theta)\theta^x }{\theta -1} \text{ for } x \in (0,1) T_n=\sum x_i T_n \theta","['statistics', 'statistical-inference', 'parameter-estimation']"
28,Probability of two different groups of students passing an exam,Probability of two different groups of students passing an exam,,"A group of $60$ students pass their exam with a probability of $0.3$ . Another group of $70$ students pass their exam with a probability of $0.5$ . What is the expected number of students who will pass their exams? What is the probability of one student passing her/his exam? So far the only way to approach the problem I can think of is $0.3 \cdot 60 + 0.5 \cdot 70 = 53$ will pass their exams. Therefore, $\frac{53}{(60+70)} = 0.4$ is the probability of one student passing her/his exam.  However, the groups have different number of people. I am not sure if this makes one of the group a more reliable prediction of the outcome.","A group of students pass their exam with a probability of . Another group of students pass their exam with a probability of . What is the expected number of students who will pass their exams? What is the probability of one student passing her/his exam? So far the only way to approach the problem I can think of is will pass their exams. Therefore, is the probability of one student passing her/his exam.  However, the groups have different number of people. I am not sure if this makes one of the group a more reliable prediction of the outcome.",60 0.3 70 0.5 0.3 \cdot 60 + 0.5 \cdot 70 = 53 \frac{53}{(60+70)} = 0.4,"['probability', 'statistics']"
29,Is it possible to assign equal probabilities to individuals and groups of individuals?,Is it possible to assign equal probabilities to individuals and groups of individuals?,,"A popular music festival with a fixed number of available tickets uses a system (algorithm?) that randomly picks from a group of registered individuals who is able to purchase a ticket. The group of registered individuals is considerably larger than the number of available tickets. Nothing confusing so far. However, the festival organization provides the possibility for registered individuals to become part of a group (up to 20 individuals). The idea is that the system either picks everybody or nobody from a group. The festival organization claims that the probability of being picked by the system is equal for individuals and for groups. I wonder whether this is possible or not?","A popular music festival with a fixed number of available tickets uses a system (algorithm?) that randomly picks from a group of registered individuals who is able to purchase a ticket. The group of registered individuals is considerably larger than the number of available tickets. Nothing confusing so far. However, the festival organization provides the possibility for registered individuals to become part of a group (up to 20 individuals). The idea is that the system either picks everybody or nobody from a group. The festival organization claims that the probability of being picked by the system is equal for individuals and for groups. I wonder whether this is possible or not?",,"['probability', 'statistics', 'algorithms']"
30,Linear Regression's Expectation of Prediction Error on a given point in the test set,Linear Regression's Expectation of Prediction Error on a given point in the test set,,"I'm self-learning the book ""The Elements of Statistical Learning"", and I've got a little problem on deriving equation 2.27 in this book. I would appreciate if anyone could help me with this. In order to make this question consistent, I'll list all the information needed for the deriving. Suppose we have two random variables $Y$ and $X$ with the following relation: $Y = X^T\beta + \epsilon$ where $\epsilon \sim N(0, \sigma^2)$ . and we fit data in a training set $\mathcal{T}$ with linear regression by least squares: $\hat{Y} = X^T \hat{\beta}$ , where $\hat{\beta}$ is the parameter and $\hat{Y}$ is our prediction, $X$ is the input. we define the Expected Prediction Error (EPE) of a record ( $x_0, y_0$ ) in test data as $EPE(x_0) = E_{y_0|x_0}E_{\mathcal{T}}(y_0 - \hat{y_0})^2$ where $\hat{y_0}$ is our prediction w.r.t. $x_0$ . According to the book , $EPE(x_0) = Var(y_0|x_0) + Var_{\mathcal{T}}(\hat{y_0}) + Bias^2(\hat{y_0})$ where $Bias^2(\hat{y_0}) = (E_{\mathcal{T}}\hat{y_0} - y_0)^2$ . Here is my derivation: $EPE(x_0) = E_{y_0|x_0}E_{\mathcal{T}}(y_0 - \hat{y_0})^2$ $=E_{y_0|x_0}E_{\mathcal{T}}(y_0^2 - 2y_0\hat{y_0} + \hat{y_0}^2)$ $=E_{y_0|x_0}(y_0^2) -2E_{y_0|x_0}y_0E_{\mathcal{T}}\hat{y_0} + E_{\mathcal{T}}\hat{y_0}^2$ By the lemma $Var(X) = E(X^2) - (E(X))^2$ we have $EPE(x_0) = Var(y_0|x_0) + (E_{y_0|x_0}(y_0))^2 -2E_{y_0|x_0}y_0E_{\mathcal{T}}\hat{y_0} + Var_{\mathcal{T}}(\hat{y_0)} + (E_{\mathcal{T}}(\hat{y_0}))^2$ $= Var(y_0|x_0) + Var_{\mathcal{T}}(\hat{y_0}) + (E_{\mathcal{T}}(\hat{y_0}) - E_{y_0|x_0}(y_0))^2$ which is really close to the conclusion given in the book, as long as we can prove $E_{y_0|x_0}(y_0) = y_0$ the proof is completed. But I've no clue how to prove $E_{y_0|x_0}(y_0) = y_0$ since I've no idea about $p(y_0 | x_0)$ . I'm wondering if anyone could help me on that. My guess is that, since $y_0 = x_0^T\beta + \epsilon$ , $E_{y_0|x_0}(y_0) = E_{y_0|x_0}(x_0^T\beta) + E_{y_0|x_0}(\epsilon) = E_{y_0|x_0}(x_0^T\beta) + \epsilon$ , and $x_0^T\beta$ is deterministic given $x_0$ , so $E_{y_0|x_0}(y_0) = x_0^T\beta + \epsilon = y_0$ , but I'm not sure if this is right. Thank you very much for your reading! Possible relative questions: What is Expected Prediction Error (EPE) a function of? Expected squared prediction error conditioned on training set","I'm self-learning the book ""The Elements of Statistical Learning"", and I've got a little problem on deriving equation 2.27 in this book. I would appreciate if anyone could help me with this. In order to make this question consistent, I'll list all the information needed for the deriving. Suppose we have two random variables and with the following relation: where . and we fit data in a training set with linear regression by least squares: , where is the parameter and is our prediction, is the input. we define the Expected Prediction Error (EPE) of a record ( ) in test data as where is our prediction w.r.t. . According to the book , where . Here is my derivation: By the lemma we have which is really close to the conclusion given in the book, as long as we can prove the proof is completed. But I've no clue how to prove since I've no idea about . I'm wondering if anyone could help me on that. My guess is that, since , , and is deterministic given , so , but I'm not sure if this is right. Thank you very much for your reading! Possible relative questions: What is Expected Prediction Error (EPE) a function of? Expected squared prediction error conditioned on training set","Y X Y = X^T\beta + \epsilon \epsilon \sim N(0, \sigma^2) \mathcal{T} \hat{Y} = X^T \hat{\beta} \hat{\beta} \hat{Y} X x_0, y_0 EPE(x_0) = E_{y_0|x_0}E_{\mathcal{T}}(y_0 - \hat{y_0})^2 \hat{y_0} x_0 EPE(x_0) = Var(y_0|x_0) + Var_{\mathcal{T}}(\hat{y_0}) + Bias^2(\hat{y_0}) Bias^2(\hat{y_0}) = (E_{\mathcal{T}}\hat{y_0} - y_0)^2 EPE(x_0) = E_{y_0|x_0}E_{\mathcal{T}}(y_0 - \hat{y_0})^2 =E_{y_0|x_0}E_{\mathcal{T}}(y_0^2 - 2y_0\hat{y_0} + \hat{y_0}^2) =E_{y_0|x_0}(y_0^2) -2E_{y_0|x_0}y_0E_{\mathcal{T}}\hat{y_0} + E_{\mathcal{T}}\hat{y_0}^2 Var(X) = E(X^2) - (E(X))^2 EPE(x_0) = Var(y_0|x_0) + (E_{y_0|x_0}(y_0))^2 -2E_{y_0|x_0}y_0E_{\mathcal{T}}\hat{y_0} + Var_{\mathcal{T}}(\hat{y_0)} + (E_{\mathcal{T}}(\hat{y_0}))^2 = Var(y_0|x_0) + Var_{\mathcal{T}}(\hat{y_0}) + (E_{\mathcal{T}}(\hat{y_0}) - E_{y_0|x_0}(y_0))^2 E_{y_0|x_0}(y_0) = y_0 E_{y_0|x_0}(y_0) = y_0 p(y_0 | x_0) y_0 = x_0^T\beta + \epsilon E_{y_0|x_0}(y_0) = E_{y_0|x_0}(x_0^T\beta) + E_{y_0|x_0}(\epsilon) = E_{y_0|x_0}(x_0^T\beta) + \epsilon x_0^T\beta x_0 E_{y_0|x_0}(y_0) = x_0^T\beta + \epsilon = y_0","['statistics', 'linear-regression']"
31,How to fit data to a piecewise function?,How to fit data to a piecewise function?,,"My question today regards a set of data that I wish to fit a piecewise-defined continuous function. This data set covers a domain of x-values from $0$ to $\mu$ on the x-axis. What I need is to determine a value $x_0 \in {\rm I\!R}+$ and two functions of given forms $f_1: [0, x_0] \mapsto {\rm I\!R}$ and $f_2: [x_0, \mu] \mapsto {\rm I\!R}$ such that $f_1$ and $f_2$ are both continuous and $f_1(x_0) = f_2(x_0)$ and $f_1 \cup f_2$ is the piecewise function of this type which best fits the data. Can I please have some information/instruction on the background theory regarding how to do this? Would linear least squares and elementary multivariable calculus be enough given that $f_1$ and $f_2$ must both be smooth on $(0, x_0)$ and $(x_0, \mu)$ respectively? In this case, I need to find $f_1 = ax^\frac{3}{2}$ for some $a \in {\rm I\!R}$ and $f_2 = bx + c$ for some $b, c \in {\rm I\!R}$ such that $b \in [-d,d]$ for some given $d \in {\rm I\!R}$ ; so the goal is essentially to find a piecewise function consisting of a power law curve and a line that is nearly horizontal which best fits the data I am looking at. I would very much appreciate help on this problem if you would be so kind.","My question today regards a set of data that I wish to fit a piecewise-defined continuous function. This data set covers a domain of x-values from to on the x-axis. What I need is to determine a value and two functions of given forms and such that and are both continuous and and is the piecewise function of this type which best fits the data. Can I please have some information/instruction on the background theory regarding how to do this? Would linear least squares and elementary multivariable calculus be enough given that and must both be smooth on and respectively? In this case, I need to find for some and for some such that for some given ; so the goal is essentially to find a piecewise function consisting of a power law curve and a line that is nearly horizontal which best fits the data I am looking at. I would very much appreciate help on this problem if you would be so kind.","0 \mu x_0 \in {\rm I\!R}+ f_1: [0, x_0] \mapsto {\rm I\!R} f_2: [x_0, \mu] \mapsto {\rm I\!R} f_1 f_2 f_1(x_0) = f_2(x_0) f_1 \cup f_2 f_1 f_2 (0, x_0) (x_0, \mu) f_1 = ax^\frac{3}{2} a \in {\rm I\!R} f_2 = bx + c b, c \in {\rm I\!R} b \in [-d,d] d \in {\rm I\!R}","['calculus', 'linear-algebra']"
32,"For a set of functions, can we create a function with a maximal average correlation?","For a set of functions, can we create a function with a maximal average correlation?",,"Let $F = \{F_1, F_2, \dots, F_n\}$ be a set of functions of the form $F_i: S \to \mathbb R$ . Additionally, let $X$ be a random variable with state space $S$ . The average correlation of $f: S \to \mathbb R$ (not necessarily in $F$ ) is defined as $$\overline{\rho_{f(X), F(X)}} = \frac 1n \sum_{i=1}^n\rho_{f(X), F_i(X)}$$ if $f(X)$ is defined. My question is is there is function $f: S \to \mathbb R$ with maximal average correlation (by which I mean $f(X)$ is defined and there does not exist a $f': S \to \mathbb R$ such that $f'(X)$ is defined and $\overline{\rho_{f'(X), F(X)}} > \overline{\rho_{f(X), F(X)}}$ )? Since $\overline{\rho_{f(X), F(x)}}$ is bounded above by $1$ , a supremum exists. I do not know if a $f$ exists achieving this supermum, though (hence my question). Also, $f$ is not unique, since if $f$ has maximal average correlation so does $g$ if $g(x) = a + bf(x)$ for $a \in \mathbb R_+$ , $b \in \mathbb R_{\neq 0}$ , and $x$ ranging over $S$ . That said $f$ is likely unique up to this transformation on the support of $X$ . Note also that simply taking the average of $F$ likely will not work, since the pearson coefficient ignores constant factors, whereas the average does not.","Let be a set of functions of the form . Additionally, let be a random variable with state space . The average correlation of (not necessarily in ) is defined as if is defined. My question is is there is function with maximal average correlation (by which I mean is defined and there does not exist a such that is defined and )? Since is bounded above by , a supremum exists. I do not know if a exists achieving this supermum, though (hence my question). Also, is not unique, since if has maximal average correlation so does if for , , and ranging over . That said is likely unique up to this transformation on the support of . Note also that simply taking the average of likely will not work, since the pearson coefficient ignores constant factors, whereas the average does not.","F = \{F_1, F_2, \dots, F_n\} F_i: S \to \mathbb R X S f: S \to \mathbb R F \overline{\rho_{f(X), F(X)}} = \frac 1n \sum_{i=1}^n\rho_{f(X), F_i(X)} f(X) f: S \to \mathbb R f(X) f': S \to \mathbb R f'(X) \overline{\rho_{f'(X), F(X)}} > \overline{\rho_{f(X), F(X)}} \overline{\rho_{f(X), F(x)}} 1 f f f g g(x) = a + bf(x) a \in \mathbb R_+ b \in \mathbb R_{\neq 0} x S f X F","['probability', 'statistics', 'optimization', 'random-variables', 'correlation']"
33,Simple Statistics/Probability Problem,Simple Statistics/Probability Problem,,"I have used a python script to identify target sequences in a DNA sequence file. There are two classes of sequence: coding and non-coding. I have identified $728$ sequences of interest. $597$ of these fall into the coding regions and $131$ of these fall into the non-coding regions. This is the equivalent of $18\%\,$ non-coding, but the total non-coding region in the sequence file is $13\% $ . Is there a statistical tool to demonstrate the python script identified target sequences in a non-random fashion way? If the script identified sequences that were randomly distributed then $13\% $ of them would have been found in the non-coding region, from a total of $728$ sequences. This seems like it should be reliable. I hope my question is clear.","I have used a python script to identify target sequences in a DNA sequence file. There are two classes of sequence: coding and non-coding. I have identified sequences of interest. of these fall into the coding regions and of these fall into the non-coding regions. This is the equivalent of non-coding, but the total non-coding region in the sequence file is . Is there a statistical tool to demonstrate the python script identified target sequences in a non-random fashion way? If the script identified sequences that were randomly distributed then of them would have been found in the non-coding region, from a total of sequences. This seems like it should be reliable. I hope my question is clear.","728 597 131 18\%\, 13\%  13\%  728","['probability', 'statistics', 'biology']"
34,How to find which percentile is a value in a skewed normal distribution,How to find which percentile is a value in a skewed normal distribution,,"I have a skewed normal distribution for which I know the average, standard deviation, skewness & kurtosis (which is different from zero). Given a number $X,$ how can estimate which percentile corresponds to that value? (I'm ok with getting an approximate value of this percentile.) I used z-score tables in the past (before having skewed distributions), but they seem to apply only to non-skewed distributions. Thanks for your help.","I have a skewed normal distribution for which I know the average, standard deviation, skewness & kurtosis (which is different from zero). Given a number how can estimate which percentile corresponds to that value? (I'm ok with getting an approximate value of this percentile.) I used z-score tables in the past (before having skewed distributions), but they seem to apply only to non-skewed distributions. Thanks for your help.","X,",['statistics']
35,"""Fragmentation"" of a distribution (from paper)","""Fragmentation"" of a distribution (from paper)",,"I've been reading a paper by Robert Morris (""Sets, Scales and Rhythmic Cycles; A Classification of Talas in Indian Music"") and came across a formula that I've found a bit tricky. He is referring to the ""fragmentation"" of a distribution and includes the formula below without derivation or reference. I'm pretty new to statistics, so this may be a standard formula that I'm just unaware of. However, I haven't been able to find it in the same format online. One feature for use in ordering talas is fragmentation. We have   already grouped talas into partition classes. All talas in a   particular partition class have the same fragmentation. We use the   partition P as the input to a function that yields the fragmentation   of the partition. Fragmentation varies between 0 and 1 and is a   measure of the uniformity of a distribution—the higher the   fragmentation, the more even the distribution. We calculate the   fragmentation of a partition of the number N into z parts using the   following formula...: $FRAG(P)=1 - \frac{\sum_{k=1}^{z}{PAIRS(p_{k})}}{PAIRS(N)}$ where $PAIRS(s)=\frac{{s^2}-s}{2} \:, \: P=\{{p_{1},p_{2}, p_{3}},...p_{z}\},\\ N = sum(P), and \: z = card(p) . $ I found the formula to be much more readable in this format: $Let \: P = \{p_{1}, p_{2}, p_{3},..., p_{z}\}, \: z = card(P),\: and \: N = sum(P).\\ FRAG(P)=1- \frac{\sum_{k=1}^{z} \frac{p_{k}^{2}-p_{k}}{2}}{\frac{N^{2}-N}{2}}=1-2\frac{\sum_{k=1}^{z}\frac{p_{k}^2-p_{k}}{2}}{N^2-N}$ The author uses the formula with the example $P=\{2, 2, 4\} \rightarrow N = 2 + 2 + 4 = 8$ and $z = 3.$ This returns $FRAG(P)=1-2(\frac{8}{56})=0.714285714...$ Does this formula (or a similar one) have a name? Are there any places where I can find some further information? More generally, what does this mean? Thanks for the help!","I've been reading a paper by Robert Morris (""Sets, Scales and Rhythmic Cycles; A Classification of Talas in Indian Music"") and came across a formula that I've found a bit tricky. He is referring to the ""fragmentation"" of a distribution and includes the formula below without derivation or reference. I'm pretty new to statistics, so this may be a standard formula that I'm just unaware of. However, I haven't been able to find it in the same format online. One feature for use in ordering talas is fragmentation. We have   already grouped talas into partition classes. All talas in a   particular partition class have the same fragmentation. We use the   partition P as the input to a function that yields the fragmentation   of the partition. Fragmentation varies between 0 and 1 and is a   measure of the uniformity of a distribution—the higher the   fragmentation, the more even the distribution. We calculate the   fragmentation of a partition of the number N into z parts using the   following formula...: where I found the formula to be much more readable in this format: The author uses the formula with the example and This returns Does this formula (or a similar one) have a name? Are there any places where I can find some further information? More generally, what does this mean? Thanks for the help!","FRAG(P)=1 - \frac{\sum_{k=1}^{z}{PAIRS(p_{k})}}{PAIRS(N)} PAIRS(s)=\frac{{s^2}-s}{2} \:, \: P=\{{p_{1},p_{2}, p_{3}},...p_{z}\},\\ N = sum(P), and \: z = card(p) .  Let \: P = \{p_{1}, p_{2}, p_{3},..., p_{z}\}, \: z = card(P),\: and \: N = sum(P).\\
FRAG(P)=1- \frac{\sum_{k=1}^{z} \frac{p_{k}^{2}-p_{k}}{2}}{\frac{N^{2}-N}{2}}=1-2\frac{\sum_{k=1}^{z}\frac{p_{k}^2-p_{k}}{2}}{N^2-N} P=\{2, 2, 4\} \rightarrow N = 2 + 2 + 4 = 8 z = 3. FRAG(P)=1-2(\frac{8}{56})=0.714285714...","['statistics', 'uniform-distribution', 'music-theory']"
36,Integrating Taylor's Approximation,Integrating Taylor's Approximation,,I am reviewing Casella's All of Statistics. A particular integral comes up when reviewing non-parametric statistics in particular Histograms. Assume that some $x\in B_j$ and any other $u \in B_j$ where $B_j$ is some particular bin in the histogram. I don't think the frequencies are going to  be too important here... $$\int_{B_j}f(u)du \approx \int_{B_j}f(x) + (u-x)f^{\prime}(u)$$ $$= f(x)h + hf^{\prime}(x) ( h (j-\frac{1}{2})-x)$$ Now I can see that the first term is just base times height.... this is a histogram after all... But that second term is bothering me. I can't think of a simple geometrical interpretation for what it means. I figure it is some sort of compensation for the value that exists between the histogram and the true $f$ . Is this accurate? And if so where does a derivation of this exist? Or did I just forget my elementary calculus?,I am reviewing Casella's All of Statistics. A particular integral comes up when reviewing non-parametric statistics in particular Histograms. Assume that some and any other where is some particular bin in the histogram. I don't think the frequencies are going to  be too important here... Now I can see that the first term is just base times height.... this is a histogram after all... But that second term is bothering me. I can't think of a simple geometrical interpretation for what it means. I figure it is some sort of compensation for the value that exists between the histogram and the true . Is this accurate? And if so where does a derivation of this exist? Or did I just forget my elementary calculus?,x\in B_j u \in B_j B_j \int_{B_j}f(u)du \approx \int_{B_j}f(x) + (u-x)f^{\prime}(u) = f(x)h + hf^{\prime}(x) ( h (j-\frac{1}{2})-x) f,"['calculus', 'statistics']"
37,What is the probability of having 10 or more crashes in the first 1000 rides?,What is the probability of having 10 or more crashes in the first 1000 rides?,,"You have recently invested in an electric skateboard. You always wear a helmet and padding to protect yourself (of course), but are worried that at some point you'll take a tumble and get scratched up. After assessing your skating ability, you estimate your probability of a crash on any single ride to be $0.005$ . I got this question while studying geometric and binomial distribution. My current idea is $1 - (P(x=0) + P(x=1) + P(x=2) + \ldots + P(x=9))$ where $x$ is the number of crashes, and get each probability by binomial distribution's formula. I came up with this equation as I thought having $10$ or more crashes means same as not having $9$ or less crashes. Is my approach correct? Also, if it's correct, is there any way to simplify the calculation?","You have recently invested in an electric skateboard. You always wear a helmet and padding to protect yourself (of course), but are worried that at some point you'll take a tumble and get scratched up. After assessing your skating ability, you estimate your probability of a crash on any single ride to be . I got this question while studying geometric and binomial distribution. My current idea is where is the number of crashes, and get each probability by binomial distribution's formula. I came up with this equation as I thought having or more crashes means same as not having or less crashes. Is my approach correct? Also, if it's correct, is there any way to simplify the calculation?",0.005 1 - (P(x=0) + P(x=1) + P(x=2) + \ldots + P(x=9)) x 10 9,"['probability', 'statistics', 'binomial-distribution']"
38,Generalized Circumcenter: minimizing the range of distances from a point to the vertices of a polygon,Generalized Circumcenter: minimizing the range of distances from a point to the vertices of a polygon,,"It is well known that the circumcenter of a polygon exists if and only if the polygon is cyclic. I would like to extend the definition of a circumcenter for noncyclic polygons. Let us define $c(A)$ as the range of the lengths of the distances from $A$ to the vertices of the polygon; that is, the longest minus shortest distance from $A$ to the vertices of the polygon.   The range is chosen as a simple measure of spread. If there exists an $A_0$ such that $0 \leq c(A_0) < c(A)$ for all $A$ not equal to $A_0$ , and $A_0$ is not equivalently at infinity, then this $A_0$ is defined to be the generalized circumcenter of the polygon. Note that this generalization follows from the fact that the distances from the circumcenter to the vertices of a cyclic polygon are equal to each other. Does the generalized circumcenter exist for all n-gons?","It is well known that the circumcenter of a polygon exists if and only if the polygon is cyclic. I would like to extend the definition of a circumcenter for noncyclic polygons. Let us define as the range of the lengths of the distances from to the vertices of the polygon; that is, the longest minus shortest distance from to the vertices of the polygon.   The range is chosen as a simple measure of spread. If there exists an such that for all not equal to , and is not equivalently at infinity, then this is defined to be the generalized circumcenter of the polygon. Note that this generalization follows from the fact that the distances from the circumcenter to the vertices of a cyclic polygon are equal to each other. Does the generalized circumcenter exist for all n-gons?",c(A) A A A_0 0 \leq c(A_0) < c(A) A A_0 A_0 A_0,"['geometry', 'statistics', 'euclidean-geometry']"
39,How can I prove the asymptotic equipartition property (AEP) for an identically distributed markov chain?,How can I prove the asymptotic equipartition property (AEP) for an identically distributed markov chain?,,"$ $ Hi, everyone. I am recently reading the lecture note of EE376a : Information Theory course from Stanford University. This note introduces that we can prove the Asymptotic Equipartition Property (or the Shannon-McMillan-Breiman Theorem) for the case that the given stochastic process $\left\{ X_n \right\}$ is a time-invariant discrete-time Markov chain with a finite state space $\mathcal{X}$ such that every $X_n$ is identically distributed over $\mathcal{X}$ with the distributuion $p$ . The following is the statement. : $$-\frac{1}{n} \log p(X_1, \cdots, X_n) \rightarrow H(X_2|X_1)$$ in probability as $n \rightarrow \infty$ . The note introduces the proof of this statement by using Weak Law of Large Numbers for weak dependency. : Let $\{ Y_n \}$ be a sequence of identically distributed random variables such that $$\lim_{n \rightarrow \infty} \frac{1}{n^2} \sum_{i=1}^{n} \sum_{j=1}^{n} Cov[Y_i, Y_j] = 0.$$ Then, $\frac{1}{n} \sum_{i=1}^{n} Y_i \rightarrow \mathbb{E}[Y_1]$ in probability as $n \rightarrow \infty$ . Thus, we let $Y_k := \log p(X_k |X_{k-1})$ for $k \geq 2$ and $Y_1 := \log p(X_1)$ . Therefore, it suffices to verify that $$\lim_{n \rightarrow \infty} \frac{1}{n^2} \sum_{i=1}^{n} \sum_{j=1}^{n} Cov[Y_i, Y_j] = 0 \ \cdots (\star)$$ and the statement comes from the WLLN for weak dependency. Now, here is my question. How can I prove the part $(\star)$ ? Please, share some good ideas for this problem.","Hi, everyone. I am recently reading the lecture note of EE376a : Information Theory course from Stanford University. This note introduces that we can prove the Asymptotic Equipartition Property (or the Shannon-McMillan-Breiman Theorem) for the case that the given stochastic process is a time-invariant discrete-time Markov chain with a finite state space such that every is identically distributed over with the distributuion . The following is the statement. : in probability as . The note introduces the proof of this statement by using Weak Law of Large Numbers for weak dependency. : Let be a sequence of identically distributed random variables such that Then, in probability as . Thus, we let for and . Therefore, it suffices to verify that and the statement comes from the WLLN for weak dependency. Now, here is my question. How can I prove the part ? Please, share some good ideas for this problem.","  \left\{ X_n \right\} \mathcal{X} X_n \mathcal{X} p -\frac{1}{n} \log p(X_1, \cdots, X_n) \rightarrow H(X_2|X_1) n \rightarrow \infty \{ Y_n \} \lim_{n \rightarrow \infty} \frac{1}{n^2} \sum_{i=1}^{n} \sum_{j=1}^{n} Cov[Y_i, Y_j] = 0. \frac{1}{n} \sum_{i=1}^{n} Y_i \rightarrow \mathbb{E}[Y_1] n \rightarrow \infty Y_k := \log p(X_k |X_{k-1}) k \geq 2 Y_1 := \log p(X_1) \lim_{n \rightarrow \infty} \frac{1}{n^2} \sum_{i=1}^{n} \sum_{j=1}^{n} Cov[Y_i, Y_j] = 0 \ \cdots (\star) (\star)","['probability', 'statistics', 'information-theory']"
40,Modeling a yes/no event,Modeling a yes/no event,,"I was wondering what kind of distribution applies to a variable that can have one of two outcomes (say yes or no) but the probability of any of these outcomes is completely random and cannot he determined ? Example: I am stopping 10,000 people on the street and asking them: are you happy today. Thank you !","I was wondering what kind of distribution applies to a variable that can have one of two outcomes (say yes or no) but the probability of any of these outcomes is completely random and cannot he determined ? Example: I am stopping 10,000 people on the street and asking them: are you happy today. Thank you !",,['statistics']
41,Odds in a “reverse” raffle,Odds in a “reverse” raffle,,"If in a raffle style drawing, but where you draw until one card or number is left, are the odds any different than when the first card drawn is the winner/loser?","If in a raffle style drawing, but where you draw until one card or number is left, are the odds any different than when the first card drawn is the winner/loser?",,"['probability', 'combinatorics', 'statistics']"
42,What are the differences between these two methods of Semi-logarithmic plotting?,What are the differences between these two methods of Semi-logarithmic plotting?,,"I have my measurement data in (x, y). I am trying to plot a semi-logarithmic plot of y versus log (x). It looks like that there are two ways to plot such a graph. Transform the values of x to log (x) for all values of x. Then, I could plot (log x, y) similar to that of plotting (x, y). Arrange y in log scale (example, for a base of 10, arrange x axis by a decade), and plot the data set exactly like I would plot (x, y) in this logarithmic scale. In other words, I do not need to compute logarithmic values of x. Instead, I could simply rearrange x axis in logarithmic scale and then plot (x, y). Here are my two questions: Are both the options discussed above the same thing in terms of data representation? If both methods of plotting are the same, I would assume the slope of data set would be the same using both the methods. I would like to show that my variable in y is linear with log of the variable in x axis. In order to do so, I plotted the (x, y) data set using the second method of plotting discussed above and did a linear fit. I got a R2 value close to 0.95. Please provide comments or your suggestions about the validity of this method.","I have my measurement data in (x, y). I am trying to plot a semi-logarithmic plot of y versus log (x). It looks like that there are two ways to plot such a graph. Transform the values of x to log (x) for all values of x. Then, I could plot (log x, y) similar to that of plotting (x, y). Arrange y in log scale (example, for a base of 10, arrange x axis by a decade), and plot the data set exactly like I would plot (x, y) in this logarithmic scale. In other words, I do not need to compute logarithmic values of x. Instead, I could simply rearrange x axis in logarithmic scale and then plot (x, y). Here are my two questions: Are both the options discussed above the same thing in terms of data representation? If both methods of plotting are the same, I would assume the slope of data set would be the same using both the methods. I would like to show that my variable in y is linear with log of the variable in x axis. In order to do so, I plotted the (x, y) data set using the second method of plotting discussed above and did a linear fit. I got a R2 value close to 0.95. Please provide comments or your suggestions about the validity of this method.",,"['statistics', 'logarithms', 'graphing-functions']"
43,Minimal sufficient statistic criterion,Minimal sufficient statistic criterion,,"(Note: This is not about Bayesian inference, but about classical inference) Let $\{P_\theta\}_{\theta\in \Theta}$ be a family of probability measures on $\mathbb{R}^n$ with density functions $f_\theta$ . Let $T:\mathbb{R}^n \rightarrow \mathscr{T}$ be a statistic. Define $$D(x):=\{y\in \mathbb{R}^n: \text{ There exists a positive function } h \text{ such that } f_{\theta}(x)=f_{\theta}(y)h(x,y) \text{ for all } \theta \}$$ . (Note that $D(x)$ forms a partition of $\mathbb{R}^n$ ) Assume that $T(x)=T(y)$ if and only if $x\in D(y)$ . Many textbooks and even wikipedia asserts that, with the above assumption, one can show that $T$ is minimal sufficient. However, I do not get this Here is a proof that textbooks I have seen have: Let $\alpha:range(T)\rightarrow \mathbb{R}^n$ be a representative function for $T$ . (That is, $T(\alpha(t))=t$ ) If we pick $x\in\mathbb{R}^n$ , from our assumption, $f_\theta(x)=f_\theta(\alpha(T(x)))h(x,\alpha(T(x))$ holds for all $\theta$ for some positive function $h>0$ . If we take $g_\theta:=f_\theta\circ \alpha$ , then by Fisher-Neymann theorem, $T$ is sufficient. However , since $\alpha$ need not be measurable, $g_\theta$ need not be measurable. So we cannot apply Fisher-Neymann theorem. (As you can see here , $\alpha$ need mot be measurable) Is $g_\theta$ measurable in anyways? Or is there a correct proof for this? Thank you in advance.","(Note: This is not about Bayesian inference, but about classical inference) Let be a family of probability measures on with density functions . Let be a statistic. Define . (Note that forms a partition of ) Assume that if and only if . Many textbooks and even wikipedia asserts that, with the above assumption, one can show that is minimal sufficient. However, I do not get this Here is a proof that textbooks I have seen have: Let be a representative function for . (That is, ) If we pick , from our assumption, holds for all for some positive function . If we take , then by Fisher-Neymann theorem, is sufficient. However , since need not be measurable, need not be measurable. So we cannot apply Fisher-Neymann theorem. (As you can see here , need mot be measurable) Is measurable in anyways? Or is there a correct proof for this? Thank you in advance.","\{P_\theta\}_{\theta\in \Theta} \mathbb{R}^n f_\theta T:\mathbb{R}^n \rightarrow \mathscr{T} D(x):=\{y\in \mathbb{R}^n: \text{ There exists a positive function } h \text{ such that } f_{\theta}(x)=f_{\theta}(y)h(x,y) \text{ for all } \theta \} D(x) \mathbb{R}^n T(x)=T(y) x\in D(y) T \alpha:range(T)\rightarrow \mathbb{R}^n T T(\alpha(t))=t x\in\mathbb{R}^n f_\theta(x)=f_\theta(\alpha(T(x)))h(x,\alpha(T(x)) \theta h>0 g_\theta:=f_\theta\circ \alpha T \alpha g_\theta \alpha g_\theta","['statistics', 'statistical-inference']"
44,Establish bound for a probability using moment generating function,Establish bound for a probability using moment generating function,,"I have the following question Let $X_{1}$ , $X_{2}$ , ..., $X_{n}$ be independent and identically   distributed random variables with moment generating function $M_{X}(t)$ , for -h < t < h, h > 0, $S_{n}$ = $\sum_{i=1}^{n}X_i$ , and $\bar{X}$ = $S_{n}/n$ . Ultimately I need to establish the following: Use the fact that $M_{X}(0)=1$ and $dM_{X}(t)/dt$ $\vert_{t=0} = > \mathbb{E}(X)$ to show that if $\mathbb{E}(X)<0$ then there is a $0>c<1$ with $P(S_{n}>a) \leq c^{n}$ . Establish a similar bound for $P(S_{n} \leq a)$ . I have previously shown that $P(S_{n}>a) \leq e^{-at}[M_{X}(t)]^{n}$ for $0<t<h$ , $a\geq0$ and $P(S_{n}\leq a) \leq e^{-at}[M_{X}(t)]^{n}$ for $ -h<t<0 $ As follows: $P(S_{n} > a) = \int_a^{\infty} dF(s) \leq \int_a^{\infty} e^{-at} e^{st} dF(s) \leq \int_{-\infty}^{\infty} e^{-at} e^{st} dF(s) = e^{-at} \mathbb{E} (e^{t \sum_{i=1}^{n}X_i}) = e^{-at}[M_{X}(t)]^{n} $ And similarly: $P(S_{n} \leq a) = \int_{-\infty}^{a} dF(s) \leq \int_{-\infty}^{a} e^{-at} e^{st} dF(s) \leq \int_{-\infty}^{\infty} e^{-at} e^{st} dF(s) = e^{-at} \mathbb{E} (e^{t \sum_{i=1}^{n}X_i}) = e^{-at}[M_{X}(t)]^{n} $ Now, I have really no clue on how to establish a bound at $c_{n}$ using the fact that $M_{X}(t) = 0 $ and $dM_{X}(t)/dt$ $\vert_{t=0} = \mathbb{E}(X)$ to show that if $\mathbb{E}(X)<0$ then there is a $0>c<1$ with $P(S_{n}>a) \leq c^{n}$ . I have no attempt to show but any ideas would be very welcome. Thanks in advance","I have the following question Let , , ..., be independent and identically   distributed random variables with moment generating function , for -h < t < h, h > 0, = , and = . Ultimately I need to establish the following: Use the fact that and to show that if then there is a with . Establish a similar bound for . I have previously shown that for , and for As follows: And similarly: Now, I have really no clue on how to establish a bound at using the fact that and to show that if then there is a with . I have no attempt to show but any ideas would be very welcome. Thanks in advance","X_{1} X_{2} X_{n} M_{X}(t) S_{n} \sum_{i=1}^{n}X_i \bar{X} S_{n}/n M_{X}(0)=1 dM_{X}(t)/dt \vert_{t=0} =
> \mathbb{E}(X) \mathbb{E}(X)<0 0>c<1 P(S_{n}>a) \leq c^{n} P(S_{n} \leq a) P(S_{n}>a) \leq e^{-at}[M_{X}(t)]^{n} 0<t<h a\geq0 P(S_{n}\leq a) \leq e^{-at}[M_{X}(t)]^{n}  -h<t<0  P(S_{n} > a) = \int_a^{\infty} dF(s) \leq \int_a^{\infty} e^{-at} e^{st} dF(s) \leq \int_{-\infty}^{\infty} e^{-at} e^{st} dF(s) = e^{-at} \mathbb{E} (e^{t \sum_{i=1}^{n}X_i}) = e^{-at}[M_{X}(t)]^{n}  P(S_{n} \leq a) = \int_{-\infty}^{a} dF(s) \leq \int_{-\infty}^{a} e^{-at} e^{st} dF(s) \leq \int_{-\infty}^{\infty} e^{-at} e^{st} dF(s) = e^{-at} \mathbb{E} (e^{t \sum_{i=1}^{n}X_i}) = e^{-at}[M_{X}(t)]^{n}  c_{n} M_{X}(t) = 0  dM_{X}(t)/dt \vert_{t=0} = \mathbb{E}(X) \mathbb{E}(X)<0 0>c<1 P(S_{n}>a) \leq c^{n}","['statistics', 'random-variables', 'moment-generating-functions']"
45,If T is a Consistent estimator of $\theta$ then $T^3$ is consistent estimator of $\theta^3$,If T is a Consistent estimator of  then  is consistent estimator of,\theta T^3 \theta^3,If T is a Consistent estimator of $\theta$ then $T^3$ is a consistent estimator of $\theta^3$ . Can anyone tell me in a single line what's the logic behind this? I am familiar with invariance property of MLE where $T$ is MLE of $\theta$ and $T^2$ will be MLE of $\theta ^2$ and we know that all MLE's are consistent. If there is some other logic please do tell me I might ve skipped that portion. I want to study that.,If T is a Consistent estimator of then is a consistent estimator of . Can anyone tell me in a single line what's the logic behind this? I am familiar with invariance property of MLE where is MLE of and will be MLE of and we know that all MLE's are consistent. If there is some other logic please do tell me I might ve skipped that portion. I want to study that.,\theta T^3 \theta^3 T \theta T^2 \theta ^2,"['statistics', 'statistical-inference']"
46,Analogue to the beta-binomial distribution for sampling without replacement?,Analogue to the beta-binomial distribution for sampling without replacement?,,"The beta-binomial distribution characterizes the number of successes in $n$ trials, but where the probability of success at each trial is unknown or random. However, suppose that you had finite populations and required that samples occurred without replacement (hypergeometric distribution). Is there an analogue to the beta-binomial distribution which characterizes sampling without replacement from a population of $n$ items, where $b$ are labelled black and $w$ are labelled white ( $n = b + w$ ), but where you do not precisely know what the values of $b$ and $w$ are?","The beta-binomial distribution characterizes the number of successes in trials, but where the probability of success at each trial is unknown or random. However, suppose that you had finite populations and required that samples occurred without replacement (hypergeometric distribution). Is there an analogue to the beta-binomial distribution which characterizes sampling without replacement from a population of items, where are labelled black and are labelled white ( ), but where you do not precisely know what the values of and are?",n n b w n = b + w b w,"['probability', 'probability-theory', 'statistics', 'binomial-distribution', 'beta-function']"
47,Confidence interval for mean of a normal population,Confidence interval for mean of a normal population,,"Consider a normal population with unknown mean $\mu$ and variance $\sigma^2=9$ . To test $H_{0}:\mu=0$ ,against $H_{1}:\mu \ne 0$ . A random sample of size 100 is taken. Based on this sample, the test of the form $|\bar{X_n}| > K$ rejects the null hypothesis at 5% level of significance. Then, which of the following is a possible 95% confidence interval for $\mu$ ? (A) (-0.488, 0.688) (B) (-1.96, 1.96) (C) (0.422, 1.598) (D) (0.588, 1.96) Now, if we construct the test statistic $\tau=\frac{\bar{X_n}-\mu}{0.3} \sim N(0,1)$ Therefore our test ,actually based on the observed value of $\tau=\tau_{0}$ is given by $|\tau_{0}|> \tau_{\frac{\alpha}{2}}$ where $\alpha=0.05$ Now,we get $K=\frac{3}{10}\tau_{0.025}=0.588$ Thus the 95% confidence interval for $\mu$ is coming to be $(\bar{X_n}-0.588 ,\bar{X_n}+0.588)$ So, looking at the options it seems that both (A) , (C) are correct but only (C) is given to be correct. Please help!","Consider a normal population with unknown mean and variance . To test ,against . A random sample of size 100 is taken. Based on this sample, the test of the form rejects the null hypothesis at 5% level of significance. Then, which of the following is a possible 95% confidence interval for ? (A) (-0.488, 0.688) (B) (-1.96, 1.96) (C) (0.422, 1.598) (D) (0.588, 1.96) Now, if we construct the test statistic Therefore our test ,actually based on the observed value of is given by where Now,we get Thus the 95% confidence interval for is coming to be So, looking at the options it seems that both (A) , (C) are correct but only (C) is given to be correct. Please help!","\mu \sigma^2=9 H_{0}:\mu=0 H_{1}:\mu \ne 0 |\bar{X_n}| > K \mu \tau=\frac{\bar{X_n}-\mu}{0.3} \sim N(0,1) \tau=\tau_{0} |\tau_{0}|> \tau_{\frac{\alpha}{2}} \alpha=0.05 K=\frac{3}{10}\tau_{0.025}=0.588 \mu (\bar{X_n}-0.588 ,\bar{X_n}+0.588)","['probability', 'statistics']"
48,Physical interpretation of mean squared divided by variance of a distribution,Physical interpretation of mean squared divided by variance of a distribution,,"In chromatography, the signal is shaped like a Gaussian peak, and it is plotted against time vs. instrument's signal. https://en.wikipedia.org/wiki/Chromatography#/media/File:Rt_5_12.png Background: One of the ways to measure chromatographic efficiency is to calculate ""number of theoretical plates"" which is just (time of peak maximum)^2/ (variance of the peak in time units). It is a dimensionless number which essentially shows how narrow the peak is. I have searched the work of Martin & Synge (Nobel Prize) for they came up with the theoretical plate concept, however, nowhere they used this equation. However, every modern textbook, says the number of theoretical plates is defined as (peak maximum)^2/ (variance of the peak). One can use widths of the peak instead of variance, assuming the peak is Gaussian. No logic is provided as to why this measure was invented. https://www.shimadzu.com/an/hplc/support/lib/lctalk/theoretical_plate.html Is there any mathematical analog as to why one would divide the (mean)^2 by its variance or more rigorously, is there any physical interpretation of first-moment squared divided by the variance of the distribution. Thank you.","In chromatography, the signal is shaped like a Gaussian peak, and it is plotted against time vs. instrument's signal. https://en.wikipedia.org/wiki/Chromatography#/media/File:Rt_5_12.png Background: One of the ways to measure chromatographic efficiency is to calculate ""number of theoretical plates"" which is just (time of peak maximum)^2/ (variance of the peak in time units). It is a dimensionless number which essentially shows how narrow the peak is. I have searched the work of Martin & Synge (Nobel Prize) for they came up with the theoretical plate concept, however, nowhere they used this equation. However, every modern textbook, says the number of theoretical plates is defined as (peak maximum)^2/ (variance of the peak). One can use widths of the peak instead of variance, assuming the peak is Gaussian. No logic is provided as to why this measure was invented. https://www.shimadzu.com/an/hplc/support/lib/lctalk/theoretical_plate.html Is there any mathematical analog as to why one would divide the (mean)^2 by its variance or more rigorously, is there any physical interpretation of first-moment squared divided by the variance of the distribution. Thank you.",,"['statistics', 'normal-distribution', 'mathematical-physics', 'mathematical-modeling']"
49,Variance in linear combinations,Variance in linear combinations,,"I am having a problem understanding why the below is calculating the variance when the exercise is asking about the standard deviation. The standard deviation of the time you take for each statistics homework problem is 1.5 minutes, and it is 2 minutes for each chemistry problem. What is the standard deviation of the time you expect to spend on statistics and physics homework for the week if you have 5 statistics and 4 chemistry homework problems assigned? Variability of a linear combination of two independent random variables: V(aX + bY) = $a^2$ ×V(X) + $b^2$ ×V(Y) The standard deviation of the linear combination is the square root of the variance. So we will use the above formula to calculate the exercise: V(5S + 4C) = $5^2$ × V(S) + $4^2$ × V(C) = 25 × $1.5^2$ + 16 × $2^2$ = 56.25 + 64 = 120.25 In my mind we are clearly finding the variance here, not the standard deviation, as that would be the sqrt of the 120.25, still the answer is 120.25, why? Edit: Also, the formula says that $a^2$ and $b^2$ but still they do power of two on both 5 and 4 and V(S) and V(C).","I am having a problem understanding why the below is calculating the variance when the exercise is asking about the standard deviation. The standard deviation of the time you take for each statistics homework problem is 1.5 minutes, and it is 2 minutes for each chemistry problem. What is the standard deviation of the time you expect to spend on statistics and physics homework for the week if you have 5 statistics and 4 chemistry homework problems assigned? Variability of a linear combination of two independent random variables: V(aX + bY) = ×V(X) + ×V(Y) The standard deviation of the linear combination is the square root of the variance. So we will use the above formula to calculate the exercise: V(5S + 4C) = × V(S) + × V(C) = 25 × + 16 × = 56.25 + 64 = 120.25 In my mind we are clearly finding the variance here, not the standard deviation, as that would be the sqrt of the 120.25, still the answer is 120.25, why? Edit: Also, the formula says that and but still they do power of two on both 5 and 4 and V(S) and V(C).",a^2 b^2 5^2 4^2 1.5^2 2^2 a^2 b^2,['statistics']
50,Sufficient statistic for a function of the parameter,Sufficient statistic for a function of the parameter,,"We know that if $T$ is a sufficient statistic for $\theta$ then $f(T)$ is a sufficient statistic for $f(\theta)$ if $f(.)$ is a one -one function. But,what if $f$ is not one one? For example, in case of Bernoulli $(p)$ ,how to find the sufficient statistic for $p(1-p)$ ?","We know that if is a sufficient statistic for then is a sufficient statistic for if is a one -one function. But,what if is not one one? For example, in case of Bernoulli ,how to find the sufficient statistic for ?",T \theta f(T) f(\theta) f(.) f (p) p(1-p),['statistics']
51,Does spatial depth identifies probability distribution?,Does spatial depth identifies probability distribution?,,"For a probability distribution, $P$ defined on $(\mathbb{R}^n,\mathcal{B}(\mathbb{R}^n))$ , we define spatial depth function $D_P:\mathbb{R}^n\rightarrow \mathbb{R}$ as $D_P(x)=1-\left\|E\left[\frac{X-x}{\|X-x\|_2}\right]\right\|_2$ . If we have two probability distributions $P$ and $Q$ on $(\mathbb{R}^n,\mathcal{B}(\mathbb{R}^n))$ and if we know $D_P(x)=D_Q(x)$ for all $x\in \mathbb{R}^n$ then does that imply $P=Q$ ? It is true if $P$ and $Q$ are spherically symmetric about $0$ . But I have no idea for general case. (Spherically symmeric distribution : If $X\sim P$ then $X$ is spherically symmitrically distributed about $0$ if $X\stackrel{d}{=}EX$ for any $n\times n$ orthogonal matrix $E$ .)","For a probability distribution, defined on , we define spatial depth function as . If we have two probability distributions and on and if we know for all then does that imply ? It is true if and are spherically symmetric about . But I have no idea for general case. (Spherically symmeric distribution : If then is spherically symmitrically distributed about if for any orthogonal matrix .)","P (\mathbb{R}^n,\mathcal{B}(\mathbb{R}^n)) D_P:\mathbb{R}^n\rightarrow \mathbb{R} D_P(x)=1-\left\|E\left[\frac{X-x}{\|X-x\|_2}\right]\right\|_2 P Q (\mathbb{R}^n,\mathcal{B}(\mathbb{R}^n)) D_P(x)=D_Q(x) x\in \mathbb{R}^n P=Q P Q 0 X\sim P X 0 X\stackrel{d}{=}EX n\times n E","['probability', 'statistics']"
52,Central limit theorem when variables are dependent,Central limit theorem when variables are dependent,,"I'm wondering if the central limit theorem can be applied when covariance between variables (say time series data) fades quickly enough. For example if there is a sequence of random variables $Z_i$ , where $Z_i$ and $Z_j$ are correlated when $|i-j|=1$ , can the central limit theorem still be applied to $\sqrt{n}\frac{1}{n}\sum_{i=1}^nZ_i$ ?","I'm wondering if the central limit theorem can be applied when covariance between variables (say time series data) fades quickly enough. For example if there is a sequence of random variables , where and are correlated when , can the central limit theorem still be applied to ?",Z_i Z_i Z_j |i-j|=1 \sqrt{n}\frac{1}{n}\sum_{i=1}^nZ_i,"['probability', 'statistics']"
53,Mean Absolute Error (MAE) equal or more than 1.,Mean Absolute Error (MAE) equal or more than 1.,,"Can be the estimated Mean Absolute Error (MAE) equal or more than 1 ? If it is possible (which it happened to me), when it happens and what is the reason? Thanks,","Can be the estimated Mean Absolute Error (MAE) equal or more than 1 ? If it is possible (which it happened to me), when it happens and what is the reason? Thanks,",,"['statistics', 'discrete-mathematics', 'error-function']"
54,"Hubs in high-dimensional point clouds (distribution of ""being within nearest neighbours of how_many other points"")","Hubs in high-dimensional point clouds (distribution of ""being within nearest neighbours of how_many other points"")",,"The hubness problem is a phenomenon mentioned in this paper , for instance. It claims that for random data point clouds in high-dimensional spaces, there will be ""many"" hubs -- that is, points that are within k nearest neighbors of many other points. We define, for each point $x$ , the number $N_k(x)$ to be the number of other points $y$ such that $x$ belongs to $k$ nearest members of $y$ . Radonovic claims that $N_k(x)$ has approximately normal distribution for random point clouds in low dimensional manifolds, but a highly skewed distribution with long right-tail in high dimensions. Radonovic illustrates this with uniformly distributed points in $[0,1]^N$ . I tried to reproduce some of that in Python and came to a surprising observation. While the $N_k(x)$ distribution is indeed skewed in high dimensions when generating uniform point cloud in the cube and using the Euclidean distance function, I didn't observe this when generating uniform point clouds in the sphere . Experiment with a cube (uniformly generated 2000 points in $[0,1]^{500}$ ) The same experiment with a sphere (uniformly generated 2000 points in $S^{500}$ ) My intuition is that there should be no difference between hub-histograms in an $n$ -cube or an $n$ -sphere, because this hubeness seems to be a local phenomenon. Unless I have some stupid mistake in the code , my intuition seems to be wrong. Generating more points, I think I could see some skewness in the sphere as well, but only very slightly, if at all. So here are my questions: How is the cube different from a sphere? Could the difference be only explained by boundaries, corners or corners of corners? Any insight into this hubeness-phenomena?","The hubness problem is a phenomenon mentioned in this paper , for instance. It claims that for random data point clouds in high-dimensional spaces, there will be ""many"" hubs -- that is, points that are within k nearest neighbors of many other points. We define, for each point , the number to be the number of other points such that belongs to nearest members of . Radonovic claims that has approximately normal distribution for random point clouds in low dimensional manifolds, but a highly skewed distribution with long right-tail in high dimensions. Radonovic illustrates this with uniformly distributed points in . I tried to reproduce some of that in Python and came to a surprising observation. While the distribution is indeed skewed in high dimensions when generating uniform point cloud in the cube and using the Euclidean distance function, I didn't observe this when generating uniform point clouds in the sphere . Experiment with a cube (uniformly generated 2000 points in ) The same experiment with a sphere (uniformly generated 2000 points in ) My intuition is that there should be no difference between hub-histograms in an -cube or an -sphere, because this hubeness seems to be a local phenomenon. Unless I have some stupid mistake in the code , my intuition seems to be wrong. Generating more points, I think I could see some skewness in the sphere as well, but only very slightly, if at all. So here are my questions: How is the cube different from a sphere? Could the difference be only explained by boundaries, corners or corners of corners? Any insight into this hubeness-phenomena?","x N_k(x) y x k y N_k(x) [0,1]^N N_k(x) [0,1]^{500} S^{500} n n","['statistics', 'euclidean-geometry', 'experimental-mathematics']"
55,"Conditional Expectation of One Member of a Multinomial Distribution, Conditioned on a Second Member","Conditional Expectation of One Member of a Multinomial Distribution, Conditioned on a Second Member",,"I have a homework problem, which asks: Let X = $(X_1, X_2, X_3, X_4, X_5) \sim \text{Mult}_5(n, p)$ with p = $(p_1, p_2, p_3, p_4, p_5)$ . (a) Find $E(X_1 | X_2) \text{ and } Var(X_1 | X_2)$ . (b) Find $E(X_1 | X_2 + X_3)$ . So here is my approach to part (a): To find $E(X_1|X_2 = x_2)$ , I think of $X_2$ being set at a fixed value and remove it from the distribution. So first I have to normalize p, so say that: $$ p_1^{'} = \frac{p_1}{1-p_2}, p_3^{'} = \frac{p_3}{1-p_2}, p_4^{'} = \frac{p_4}{1-p_2}, p_5^{'} = \frac{p_5}{1-p_2} $$ then let $p^{'} = (p_1^{'}, p_3^{'}, p_4^{'}, p_5^{'})$ So with $X_2$ fixed, I have a new distribution: $\text{Mult}_4(n-X_2, p^{'})$ . And to find the probability of $(X_1|X_2)$ , I can treat it like any other marginal of a multinomial distribution, and say that: $(X_1|X_2 = x_2) \sim \text{Bin}(n-X_2, p_1^{'})$ I know that the expected value for a binomial distribution is $n \cdot p$ and the variance is $n \cdot p(1-p)$ , so I can say that: $$ E(X_1|X_2) = p_1^{'}(n-X_2)$$ $$ Var(X_1|X_2) = p_1^{'}(n-X_2)(1-p_1^{'}) $$ So I have two questions. Is this approach OK? If so, can I simply take the same steps for (b) but adding $X_2$ and $X_3$ together?","I have a homework problem, which asks: Let X = with p = . (a) Find . (b) Find . So here is my approach to part (a): To find , I think of being set at a fixed value and remove it from the distribution. So first I have to normalize p, so say that: then let So with fixed, I have a new distribution: . And to find the probability of , I can treat it like any other marginal of a multinomial distribution, and say that: I know that the expected value for a binomial distribution is and the variance is , so I can say that: So I have two questions. Is this approach OK? If so, can I simply take the same steps for (b) but adding and together?","(X_1, X_2, X_3, X_4, X_5) \sim \text{Mult}_5(n, p) (p_1, p_2, p_3, p_4, p_5) E(X_1 | X_2) \text{ and } Var(X_1 | X_2) E(X_1 | X_2 + X_3) E(X_1|X_2 = x_2) X_2  p_1^{'} = \frac{p_1}{1-p_2}, p_3^{'} = \frac{p_3}{1-p_2}, p_4^{'} = \frac{p_4}{1-p_2}, p_5^{'} = \frac{p_5}{1-p_2}  p^{'} = (p_1^{'}, p_3^{'}, p_4^{'}, p_5^{'}) X_2 \text{Mult}_4(n-X_2, p^{'}) (X_1|X_2) (X_1|X_2 = x_2) \sim \text{Bin}(n-X_2, p_1^{'}) n \cdot p n \cdot p(1-p)  E(X_1|X_2) = p_1^{'}(n-X_2)  Var(X_1|X_2) = p_1^{'}(n-X_2)(1-p_1^{'})  X_2 X_3","['probability', 'statistics', 'conditional-expectation', 'expected-value']"
56,Calculation of probability with arithmetic mean of random variables for a total of 3 times,Calculation of probability with arithmetic mean of random variables for a total of 3 times,,"Thanks to @Ben W for his answer to my previous question , now I can calculate and have 3 equal probabilities: $P(X_1) = P(X_2) = P(X_3) \approx 0.000148646896$ with $X_1 = X_2 = X_3 = 1620$ Following up, once that the 4 people got 405 as the arithmetic mean of the number on their cards, then they repeat the drawing 2 more time (3 in total). So, I would like to calculate the probability that the arithmetic mean of the number on their cards is 405 for a total of 3 times. How to make that? Some explanation is welcome.","Thanks to @Ben W for his answer to my previous question , now I can calculate and have 3 equal probabilities: with Following up, once that the 4 people got 405 as the arithmetic mean of the number on their cards, then they repeat the drawing 2 more time (3 in total). So, I would like to calculate the probability that the arithmetic mean of the number on their cards is 405 for a total of 3 times. How to make that? Some explanation is welcome.",P(X_1) = P(X_2) = P(X_3) \approx 0.000148646896 X_1 = X_2 = X_3 = 1620,"['probability', 'statistics']"
57,Sum-to-zero constraints in a two-way ANOVA model,Sum-to-zero constraints in a two-way ANOVA model,,"I'm reviewing my lecture notes on sum-to-zero constraints and I am having a tough time understanding the concept. Say the constraints are $\sum_{i=1}^{a} \alpha_i = 0$ , $\sum_{j=1}^{b} \beta_j = 0$ , $\sum_{i=1}^{a} (\alpha \beta)_{ij} = 0$ for $j = 1,...,b$ and $\sum_{j=1}^{b} (\alpha \beta)_{ij} = 0$ for $i = 1,...,a$ . Here are the following questions I have: 1) Why does this represent $a + b + 1$ independent constraints and not $a + b + 2$ independent constraints? 2) How do I determine that there are $a-1$ linearly independent $\alpha_i$ 's, $b-1$ linearly independent $\beta_j$ 's and $(a-1)(b-1)$ linearly independent $(\alpha \beta ) _{ij}$ 's? Thanks in advance.","I'm reviewing my lecture notes on sum-to-zero constraints and I am having a tough time understanding the concept. Say the constraints are , , for and for . Here are the following questions I have: 1) Why does this represent independent constraints and not independent constraints? 2) How do I determine that there are linearly independent 's, linearly independent 's and linearly independent 's? Thanks in advance.","\sum_{i=1}^{a} \alpha_i = 0 \sum_{j=1}^{b} \beta_j = 0 \sum_{i=1}^{a} (\alpha \beta)_{ij} = 0 j = 1,...,b \sum_{j=1}^{b} (\alpha \beta)_{ij} = 0 i = 1,...,a a + b + 1 a + b + 2 a-1 \alpha_i b-1 \beta_j (a-1)(b-1) (\alpha \beta ) _{ij}","['linear-algebra', 'statistics']"
58,Information theory - Intuition of channel capacity,Information theory - Intuition of channel capacity,,"Question As stated in Elements of Information theory , given $p(y|x)$ , the Information channel capacity formula is $C = \max_{p(x)} I(X; Y)$ where $X, Y$ are input and output symbols, $p(x)$ is the p.m.f of the distribution of $X$ Can anyone tell me the intuition of this formula ? My understanding $C = \max_{p(x)} I(X; Y) = \max_{p(x)} [H(X) - H(X|Y)]$ $H(X)$ can be understood as the expected amount of unknown information (measured in bits) of $X$ . $H(X|Y)$ is the expected the expected amount of remaining unknown information (measured in bits) of $X$ given $Y$ is known. Thus, $I(X; Y)$ is the expected amount of known information (measured in bits) about $X$ given by $Y$ . Thus, $C =\max_{p(x)} I(X; Y)$ gives the maximum number of bits in $X$ , which can be exactly given by $Y$ . There are two problems with my understanding: According to my understanding, for any input symbol $X$ , there are only $I(X; Y)$ bits can be transmitted without error (i.e. no matter whether $H(X)$ exceeds the channel capacity $C$ or not) In Elements of Information theory , $C$ is usually written as $C = \max_{p(x)}[H(Y) - H(Y|X)]$ , instead of $\max_{p(X)}[H(X) - H(X|Y)]$ (i.e. my formula). I think $H(Y) - H(Y|X)$ says something about the right intuition of the formula $C = \max_{p(x)} I(X; Y)$ .","Question As stated in Elements of Information theory , given , the Information channel capacity formula is where are input and output symbols, is the p.m.f of the distribution of Can anyone tell me the intuition of this formula ? My understanding can be understood as the expected amount of unknown information (measured in bits) of . is the expected the expected amount of remaining unknown information (measured in bits) of given is known. Thus, is the expected amount of known information (measured in bits) about given by . Thus, gives the maximum number of bits in , which can be exactly given by . There are two problems with my understanding: According to my understanding, for any input symbol , there are only bits can be transmitted without error (i.e. no matter whether exceeds the channel capacity or not) In Elements of Information theory , is usually written as , instead of (i.e. my formula). I think says something about the right intuition of the formula .","p(y|x) C = \max_{p(x)} I(X; Y) X, Y p(x) X C = \max_{p(x)} I(X; Y) = \max_{p(x)} [H(X) - H(X|Y)] H(X) X H(X|Y) X Y I(X; Y) X Y C =\max_{p(x)} I(X; Y) X Y X I(X; Y) H(X) C C C = \max_{p(x)}[H(Y) - H(Y|X)] \max_{p(X)}[H(X) - H(X|Y)] H(Y) - H(Y|X) C = \max_{p(x)} I(X; Y)","['probability', 'statistics', 'information-theory', 'entropy']"
59,Distribution of the sum of n independent variables of the exponential family.,Distribution of the sum of n independent variables of the exponential family.,,"Suppose you have $n$ random and independent variables $Y_{1},...,Y_{n}$ whose distribution belongs to the uniparametric exponential family. How do I find the distribution of $\sum_{i=1}^{n} Yi$ ?",Suppose you have random and independent variables whose distribution belongs to the uniparametric exponential family. How do I find the distribution of ?,"n Y_{1},...,Y_{n} \sum_{i=1}^{n} Yi","['statistics', 'probability-distributions', 'statistical-inference']"
60,Smooth function from $\mathbb R^n$ to a polytope,Smooth function from  to a polytope,\mathbb R^n,"Given an open bounded convex polytope $C$ in $\mathbb{R}^n$ , is there a way to construct a smooth function from $\mathbb{R}^m$ to $\mathbb{R}^n$ whose image is $C$ ? For instance, if $C$ is the unit cube, we can use the logistic function in each coordinate; thus we can get any parallelepiped. If $C$ is a simplex, you can use the stick-breaking process. What other polytopes work? I am actually interested in one particular polytope that comes from a problem in statistics. My polytope is entirely contained in the unit cube and its defining matrix is all 0's and 1's. I mention this just in case it proves relevant, even though I don't see why it would. I suspect if there is a solution for my case, then it would work more generally. Would appreciate any leads!","Given an open bounded convex polytope in , is there a way to construct a smooth function from to whose image is ? For instance, if is the unit cube, we can use the logistic function in each coordinate; thus we can get any parallelepiped. If is a simplex, you can use the stick-breaking process. What other polytopes work? I am actually interested in one particular polytope that comes from a problem in statistics. My polytope is entirely contained in the unit cube and its defining matrix is all 0's and 1's. I mention this just in case it proves relevant, even though I don't see why it would. I suspect if there is a solution for my case, then it would work more generally. Would appreciate any leads!",C \mathbb{R}^n \mathbb{R}^m \mathbb{R}^n C C C,"['real-analysis', 'statistics', 'convex-analysis', 'polytopes']"
61,"What are the connections (if any) between ""kernel"" in ""kernel density estimation,"" ""kernel of a matrix,"" and ""kernel method""?","What are the connections (if any) between ""kernel"" in ""kernel density estimation,"" ""kernel of a matrix,"" and ""kernel method""?",,"I'm getting my understanding of kernel density estimation from pages 6-7 of this PDF . If there are conceptual relationships between the ""kernels"" in each of these topics, I'd like to understand them.","I'm getting my understanding of kernel density estimation from pages 6-7 of this PDF . If there are conceptual relationships between the ""kernels"" in each of these topics, I'd like to understand them.",,"['linear-algebra', 'statistics', 'machine-learning', 'estimation']"
62,SVM: Are all the support vectors necessarily used to construct the weights,SVM: Are all the support vectors necessarily used to construct the weights,,"I know what exactly the SVM is and very clear about the principles and algorithms. But I'm curious about are all support vectors necessarily used in constructing weights $w$ . Let $w^Tx_i + b$ denote SVM model. Based on KKT dual complementarity condition, $\alpha_i[y_i(w^Tx_i+b)-1]=0, i=1,\cdots,N,$ where $w$ and $b$ are weights and bias, $\alpha_i$ is Lagrange multiplier. we know that if $\alpha_i \not=0$ , then $y_i(w^Tx_i+b)-1=0$ . And such a $x_i$ is called support vector. Sequentially, the estimation of weights $w = \sum_{i=1}^m\alpha_{(i)}y_{(i)}x_{(i)}$ where $x_{(i)}s$ are the support vectors. What I'm confused about is: Is it possible that some $\alpha_0=0$ and $y_0(w^Tx_0+b)-1=0$ hold simultaneously so that such a $x_i$ is a support vector itself, but is not used in constructing weights $w$ , since $\alpha_0=0$ . Thanks for any ideas. :)","I know what exactly the SVM is and very clear about the principles and algorithms. But I'm curious about are all support vectors necessarily used in constructing weights . Let denote SVM model. Based on KKT dual complementarity condition, where and are weights and bias, is Lagrange multiplier. we know that if , then . And such a is called support vector. Sequentially, the estimation of weights where are the support vectors. What I'm confused about is: Is it possible that some and hold simultaneously so that such a is a support vector itself, but is not used in constructing weights , since . Thanks for any ideas. :)","w w^Tx_i + b \alpha_i[y_i(w^Tx_i+b)-1]=0, i=1,\cdots,N, w b \alpha_i \alpha_i \not=0 y_i(w^Tx_i+b)-1=0 x_i w = \sum_{i=1}^m\alpha_{(i)}y_{(i)}x_{(i)} x_{(i)}s \alpha_0=0 y_0(w^Tx_0+b)-1=0 x_i w \alpha_0=0","['statistics', 'machine-learning']"
63,Showing that the difference of Chi squared random variables follows a chi squared distribution,Showing that the difference of Chi squared random variables follows a chi squared distribution,,"how can I show that given $ \textbf{y} =(y_1,y_2)^T \sim  N (\textbf {0} ,\Sigma ) $ $$(\textbf{y}^t\Sigma^{-1}\textbf{y} - \frac{y_1^2}{\sigma_{11}}) \sim \chi^2_1$$ where $ \Sigma =(\sigma_{i,j})$ I have tried considering moment generating functions. Is it true that $\textbf{y}^t\Sigma^{-1}\textbf{y}$ is chi squared with 2 degrees of freedom and that $ \frac{y_1^2}{\sigma_{11}}$ is chi squared with 1 df? Thanks for your help",how can I show that given where I have tried considering moment generating functions. Is it true that is chi squared with 2 degrees of freedom and that is chi squared with 1 df? Thanks for your help," \textbf{y} =(y_1,y_2)^T \sim  N (\textbf {0} ,\Sigma )  (\textbf{y}^t\Sigma^{-1}\textbf{y} - \frac{y_1^2}{\sigma_{11}}) \sim \chi^2_1  \Sigma =(\sigma_{i,j}) \textbf{y}^t\Sigma^{-1}\textbf{y}  \frac{y_1^2}{\sigma_{11}}","['statistics', 'chi-squared']"
64,Elastic Net as LASSO,Elastic Net as LASSO,,"Good evening everybody, I need help with an excercise on Regularised Regression. What I need to do is turn an Elastic-net problem: \begin{equation} argmin_\omega \Vert y-\Phi(x)^T \omega \Vert_2^2 + \lambda(\alpha\Vert\omega\Vert_2^2 + (1-\alpha)\Vert w\Vert_1) \end{equation} Into a LASSO: \begin{equation}  argmin_\omega \Vert \bar y-\bar\Phi(x)^T \omega \Vert_2^2 + \bar\lambda\Vert w\Vert_1 \end{equation} for suitable new $\bar\lambda$ , $\bar y$ and $\bar \Phi(x)$ . What I have thought is that, if $y-\Phi(x)^T\omega$ and $\omega$ are orthogonal (this is the case if $\omega$ is the solution of the Least Squares problem without regularization), we have that: \begin{equation} \Vert y-\Phi(x)^T \omega \Vert_2^2 + \lambda\alpha\Vert\omega\Vert_2^2 = \Vert y-(\Phi(x)^T-\lambda^2\alpha^2 I)\omega\Vert_2^2 \end{equation} And so, I have solved the problem. But this is not the case. Any idea? Thank you in advance","Good evening everybody, I need help with an excercise on Regularised Regression. What I need to do is turn an Elastic-net problem: Into a LASSO: for suitable new , and . What I have thought is that, if and are orthogonal (this is the case if is the solution of the Least Squares problem without regularization), we have that: And so, I have solved the problem. But this is not the case. Any idea? Thank you in advance","\begin{equation}
argmin_\omega \Vert y-\Phi(x)^T \omega \Vert_2^2 + \lambda(\alpha\Vert\omega\Vert_2^2 + (1-\alpha)\Vert w\Vert_1)
\end{equation} \begin{equation}
 argmin_\omega \Vert \bar y-\bar\Phi(x)^T \omega \Vert_2^2 + \bar\lambda\Vert w\Vert_1
\end{equation} \bar\lambda \bar y \bar \Phi(x) y-\Phi(x)^T\omega \omega \omega \begin{equation}
\Vert y-\Phi(x)^T \omega \Vert_2^2 + \lambda\alpha\Vert\omega\Vert_2^2 = \Vert y-(\Phi(x)^T-\lambda^2\alpha^2 I)\omega\Vert_2^2
\end{equation}","['statistics', 'regression', 'machine-learning']"
65,Variance of the sum of elements of a Wishart distributed matrix,Variance of the sum of elements of a Wishart distributed matrix,,"Looking for the variance of $S=\sigma _{1,3}-\sigma _{1,4}-\sigma _{2,3}+\sigma _{2,4}$ , where $\sigma_{i,j}$ are Wishart-distributed elements of the random matrix $$\Sigma =\left( \begin{array}{cccc}  \sigma _1^2 & \sigma _{1,2} & \sigma _{1,3} & \sigma _{1,4} \\  \sigma _{1,2} & \sigma _2^2 & \sigma _{2,3} & \sigma _{2,4} \\  \sigma _{1,3} & \sigma _{2,3} & \sigma _3^2 & \sigma _{3,4} \\  \sigma _{1,4} & \sigma _{2,4} & \sigma _{3,4} & \sigma _4^2 \\ \end{array} \right)$$ the $m$ -sample estimation of the covariance matrix of 4 multivariate Gaussian distributed random variables with $n$ observations each. Answer: $$\left(\left(\sigma _{1,3}-\sigma _{1,4}-\sigma _{2,3}+\sigma _{2,4}\right)^2+\left(-2 \sigma _{1,2}+\sigma _1^2+\sigma _2^2\right) \left(-2 \sigma _{3,4}+\sigma _3^2+\sigma _4^2\right)\right)$$","Looking for the variance of , where are Wishart-distributed elements of the random matrix the -sample estimation of the covariance matrix of 4 multivariate Gaussian distributed random variables with observations each. Answer:","S=\sigma _{1,3}-\sigma _{1,4}-\sigma _{2,3}+\sigma _{2,4} \sigma_{i,j} \Sigma =\left(
\begin{array}{cccc}
 \sigma _1^2 & \sigma _{1,2} & \sigma _{1,3} & \sigma _{1,4} \\
 \sigma _{1,2} & \sigma _2^2 & \sigma _{2,3} & \sigma _{2,4} \\
 \sigma _{1,3} & \sigma _{2,3} & \sigma _3^2 & \sigma _{3,4} \\
 \sigma _{1,4} & \sigma _{2,4} & \sigma _{3,4} & \sigma _4^2 \\
\end{array}
\right) m n \left(\left(\sigma _{1,3}-\sigma _{1,4}-\sigma _{2,3}+\sigma _{2,4}\right)^2+\left(-2 \sigma _{1,2}+\sigma _1^2+\sigma _2^2\right) \left(-2 \sigma _{3,4}+\sigma _3^2+\sigma _4^2\right)\right)","['statistics', 'probability-distributions']"
66,Use simulations in R to numerically estimate medians and modes for discrete uniform variables.,Use simulations in R to numerically estimate medians and modes for discrete uniform variables.,,"The question I have been given is: Let X be Discrete Uniform on 1, 2, . . . , n. Please note that your answers to the questions below can depend on whether n is even or odd. (a) Use simulations in R (the statistical programming language) to numerically estimate all medians and all modes of X for n = 1, 2, . . . , 10. And here is the R code I have written: set.seed(1987)  rDiscUnif <- function(n,k) sample(1:k, n, replace=T) #sample randomly from disc. unif.  findModes <- function(x) {   ux <- unique(x) #extracts unique elements of a vector   matchx <- match(x, ux) #stores index of ux match for ea. x   tab <- tabulate(matchx) #counts how many times each index appears  (effectively counting the times each unique value appeared)   ux[tab == max(tab)] #returns the mode (or modes) }   for(i in 1:10) { #for each required value of k (n in problem statement)   x <- rDiscUnif(1000, i) #make sample   print(table(x)) #make a table so you can spot the mode manually as well   plot(table(x)) #plot the table so you can see it looks uniformish   print(paste(""for n = "", i, "" median is "", median(x)))   z <- findModes(x)   print(paste(""for n = "", i, "" mode(s) is/are "",  z)) } So my question is: does this satisfy the question? In particular I'm not sure if I should write a function that will find the median based on a formula (which I found in another part of the question; med=(n+1)/2 when n is odd and $x_{n/2} \leq med \leq x_{(n/2)+1}$ when n is even), or if I should use the regular median function for the ""numerical estimate"".","The question I have been given is: Let X be Discrete Uniform on 1, 2, . . . , n. Please note that your answers to the questions below can depend on whether n is even or odd. (a) Use simulations in R (the statistical programming language) to numerically estimate all medians and all modes of X for n = 1, 2, . . . , 10. And here is the R code I have written: set.seed(1987)  rDiscUnif <- function(n,k) sample(1:k, n, replace=T) #sample randomly from disc. unif.  findModes <- function(x) {   ux <- unique(x) #extracts unique elements of a vector   matchx <- match(x, ux) #stores index of ux match for ea. x   tab <- tabulate(matchx) #counts how many times each index appears  (effectively counting the times each unique value appeared)   ux[tab == max(tab)] #returns the mode (or modes) }   for(i in 1:10) { #for each required value of k (n in problem statement)   x <- rDiscUnif(1000, i) #make sample   print(table(x)) #make a table so you can spot the mode manually as well   plot(table(x)) #plot the table so you can see it looks uniformish   print(paste(""for n = "", i, "" median is "", median(x)))   z <- findModes(x)   print(paste(""for n = "", i, "" mode(s) is/are "",  z)) } So my question is: does this satisfy the question? In particular I'm not sure if I should write a function that will find the median based on a formula (which I found in another part of the question; med=(n+1)/2 when n is odd and when n is even), or if I should use the regular median function for the ""numerical estimate"".",x_{n/2} \leq med \leq x_{(n/2)+1},"['probability', 'statistics', 'probability-distributions', 'median']"
67,Bias adjustment for the Box-Cox back-transformation,Bias adjustment for the Box-Cox back-transformation,,"I'm learning time series analysis and I don't understand why the back-transform of Box-Cox transformation outputs the median instead of the mean of the forecast distribution. The family of Box-Cox transformations is defined as follows: $$\tag{1} w_t  =     \begin{cases}       \log(y_t) & \text{if $\lambda=0$};  \\       (y_t^\lambda-1)/\lambda & \text{otherwise}.     \end{cases}$$ Hence the normal back-transform would be: $$\begin{equation} \tag{2}   y_{t} =     \begin{cases}       \exp(w_{t}) & \text{if $\lambda=0$};\\       (\lambda w_t+1)^{1/\lambda} & \text{otherwise}.     \end{cases} \end{equation}$$ In the book that I'm reading ""Forecasting: Principles and Practice"". It says that: One issue with using mathematical transformations such as Box-Cox transformations is that the back-transformed point forecast will not be the mean of the forecast distribution. In fact, it will usually be the median of the forecast distribution (assuming that the distribution on the transformed space is symmetric). For many purposes, this is acceptable, but occasionally the mean forecast is required. For example, you may wish to add up sales forecasts from various regions to form a forecast for the whole country. But medians do not add up, whereas means do. For a Box-Cox transformation, the back-transformed mean is given by: $$\begin{equation} \tag{3} y_t =   \begin{cases}      \exp(w_t)\left[1 + \frac{\sigma_h^2}{2}\right] & \text{if $\lambda=0$;}\\      (\lambda w_t+1)^{1/\lambda}\left[1 + \frac{\sigma_h^2(1-\lambda)}{2(\lambda w_t+1)^{2}}\right] & \text{otherwise;}   \end{cases} \end{equation}$$ where $\sigma_h^2$ is the $h$ -step forecast variance. The larger the forecast variance, the bigger the difference between the mean and the median. Could you please help me explain why the point forecast in equation (2) is the median and the bias-adjusted forecast in equation (3) is the mean of the forecast distribution and what is the formula for $\sigma_h^2$ in equation (3)? Many thanks in advance for your help!","I'm learning time series analysis and I don't understand why the back-transform of Box-Cox transformation outputs the median instead of the mean of the forecast distribution. The family of Box-Cox transformations is defined as follows: Hence the normal back-transform would be: In the book that I'm reading ""Forecasting: Principles and Practice"". It says that: One issue with using mathematical transformations such as Box-Cox transformations is that the back-transformed point forecast will not be the mean of the forecast distribution. In fact, it will usually be the median of the forecast distribution (assuming that the distribution on the transformed space is symmetric). For many purposes, this is acceptable, but occasionally the mean forecast is required. For example, you may wish to add up sales forecasts from various regions to form a forecast for the whole country. But medians do not add up, whereas means do. For a Box-Cox transformation, the back-transformed mean is given by: where is the -step forecast variance. The larger the forecast variance, the bigger the difference between the mean and the median. Could you please help me explain why the point forecast in equation (2) is the median and the bias-adjusted forecast in equation (3) is the mean of the forecast distribution and what is the formula for in equation (3)? Many thanks in advance for your help!","\tag{1} w_t  =
    \begin{cases}
      \log(y_t) & \text{if \lambda=0};  \\
      (y_t^\lambda-1)/\lambda & \text{otherwise}.
    \end{cases} \begin{equation}
\tag{2}
  y_{t} =
    \begin{cases}
      \exp(w_{t}) & \text{if \lambda=0};\\
      (\lambda w_t+1)^{1/\lambda} & \text{otherwise}.
    \end{cases}
\end{equation} \begin{equation}
\tag{3}
y_t =
  \begin{cases}
     \exp(w_t)\left[1 + \frac{\sigma_h^2}{2}\right] & \text{if \lambda=0;}\\
     (\lambda w_t+1)^{1/\lambda}\left[1 + \frac{\sigma_h^2(1-\lambda)}{2(\lambda w_t+1)^{2}}\right] & \text{otherwise;}
  \end{cases}
\end{equation} \sigma_h^2 h \sigma_h^2","['statistics', 'time-series']"
68,upper bound of an inequality,upper bound of an inequality,,"Let $X_t = \theta_1\epsilon_{t-1} + ... + \theta_q\epsilon_{t-q} + \epsilon_t$ where $\epsilon_t$ is a white noise with zero mean variance $\sigma^2$ . $X_t$ is said to be invertible if $\epsilon_t = \sum_{j=0}^\infty \pi_j X_{t-j}$ where $\sum_{j=0}^\infty | \pi_{j}| < \infty$ I want to show \begin{equation} \sigma^2 + E\left(\sum_{j > m} \pi_j X_{m+1-j}\right)^2 \leq \sigma^2 + \left(\sum_{j>m}|\pi_j|\right)^2\gamma(0) \end{equation} where $\gamma(0) = E(X_{t}^2)$ for all $t$ . Also, \begin{equation} \left(\sum_{j>m}|\pi_j|\right)^2\gamma(0) \leq Kc^m \end{equation} where $K > 0$ and $c \in (0, 1)$ Any hints will be appreciated.","Let where is a white noise with zero mean variance . is said to be invertible if where I want to show where for all . Also, where and Any hints will be appreciated.","X_t = \theta_1\epsilon_{t-1} + ... + \theta_q\epsilon_{t-q} + \epsilon_t \epsilon_t \sigma^2 X_t \epsilon_t = \sum_{j=0}^\infty \pi_j X_{t-j} \sum_{j=0}^\infty | \pi_{j}| < \infty \begin{equation}
\sigma^2 + E\left(\sum_{j > m} \pi_j X_{m+1-j}\right)^2 \leq \sigma^2 + \left(\sum_{j>m}|\pi_j|\right)^2\gamma(0)
\end{equation} \gamma(0) = E(X_{t}^2) t \begin{equation}
\left(\sum_{j>m}|\pi_j|\right)^2\gamma(0) \leq Kc^m
\end{equation} K > 0 c \in (0, 1)","['statistics', 'inequality', 'time-series']"
69,Derivation of the bivariate normal distribution,Derivation of the bivariate normal distribution,,"I am reading through a derivation of the bivariate normal distribution, (from the US Defence Department!) and came across an expression that I can't understand. The derivation starts off with the observation that the total area, $A$ , under the curve of the distribution is $1$ , since it is a probability distribution.  Also, the distribution can be expressed as a differential equation: $$dy=-k \ xy \ dx \tag{1}$$ $$y= Ce^{-k{x^2\over2}} \tag{2}$$ $$A= C\int_{-\infty}^{\infty}e^{-k{x^2\over2}}  \tag{3}$$ Using integration by parts, the text proceeds to evaluate $$A= C|e^{-k{x^2\over2}}|_{-\infty}^{\infty}+C\int_{-\infty}^{\infty}x^2e^{-k{x^2\over2}}  \tag{4}$$ (I skipped some steps for brevity. Please tell me if that creates confusion.) Then the text says the following line: Since the first expression takes an indeterminate form, new   numerators and denominators are obtained by independent derivatives, and the   limiting value of the expression then becomes zero. Since, by definition,   the n-th moment of a frequency distribution is defined as $$\text {n-th moment} = \int_{b}^{a}x^n f(x)dx$$ and since from fundamental principles the standard deviation is the square   root of the second moment about the mean, then it follows, considering $(3)$ ,   that the second expression in $(4)$ becomes $$A=Ak\sigma_X^2 \tag{5}$$ I think I understand how we got rid of the first expression $C|e^{-k{x^2\over2}}|_{-\infty}^{\infty}$ in $(4)$ , but what I don't understand is, how does this last step, $(5)$ , follow from the previous steps? Also, where did the $C$ go?","I am reading through a derivation of the bivariate normal distribution, (from the US Defence Department!) and came across an expression that I can't understand. The derivation starts off with the observation that the total area, , under the curve of the distribution is , since it is a probability distribution.  Also, the distribution can be expressed as a differential equation: Using integration by parts, the text proceeds to evaluate (I skipped some steps for brevity. Please tell me if that creates confusion.) Then the text says the following line: Since the first expression takes an indeterminate form, new   numerators and denominators are obtained by independent derivatives, and the   limiting value of the expression then becomes zero. Since, by definition,   the n-th moment of a frequency distribution is defined as and since from fundamental principles the standard deviation is the square   root of the second moment about the mean, then it follows, considering ,   that the second expression in becomes I think I understand how we got rid of the first expression in , but what I don't understand is, how does this last step, , follow from the previous steps? Also, where did the go?",A 1 dy=-k \ xy \ dx \tag{1} y= Ce^{-k{x^2\over2}} \tag{2} A= C\int_{-\infty}^{\infty}e^{-k{x^2\over2}}  \tag{3} A= C|e^{-k{x^2\over2}}|_{-\infty}^{\infty}+C\int_{-\infty}^{\infty}x^2e^{-k{x^2\over2}}  \tag{4} \text {n-th moment} = \int_{b}^{a}x^n f(x)dx (3) (4) A=Ak\sigma_X^2 \tag{5} C|e^{-k{x^2\over2}}|_{-\infty}^{\infty} (4) (5) C,"['probability', 'probability-theory', 'statistics', 'probability-distributions']"
70,To find which of the following statistics is (are) sufficient but NOT complete,To find which of the following statistics is (are) sufficient but NOT complete,,"Let $X_1,X_2,X_3,....X_n$ be a random sample from a distribution with the probability density function $$f(x|\theta) = \begin{cases} \dfrac{x}{\theta^2}e^{\frac{-x}{\theta}},  & \text{if $x>0$; $\theta>0$} \\ 0, & \text{otherwise} \end{cases}$$ Which of the following statistics is(are) sufficient but NOT complete? $A=\bar X$ $B=\bar X^2+3$ $C=( X_1,\sum_{i=2}^{n}X_i) $ $D=(X_1,\bar X)$ My input The joint probability density function of the sample is $f(x_1,x_3,x_2...x_n|\theta) =\dfrac{\prod_{i=1}^{n}x_i}{\theta^{2n}}\bigg(e^{\dfrac{-\sum_{i=1}^{n}x_i}{\theta}}\bigg)$ Let $T(x)=\sum_{i=1}^{n}x_i$ .We see that the pdf can be expressed as a function that depends on the sample only through $T(x)$ . Thus $T(x)$ is a sufficient statistic for $\theta$ $A$ =  is sufficient statistic because $\bar X$ is a function of $\sum_{i=1}^{n}x_i$ by dividing the whole sum by $n$ gives $\bar X$ ( I am not sure if this reasoning of mine is valid I just can't explain it to someone in brief. I need a perfect reasoning for that so someone tell me that.) $B$ = is a sufficient statistic because any one to one function of sufficient statistic T is also sufficient statistic. For example, if $x>0$ $x^2$ will be a one to one function. $C$ = Sum of these two statistics give $\sum_{i=1}^{n}x_i$ $D$ = I am not sure how to calculate sufficient statistic in this one because I am not able to derive $\sum_{i=1}^{n}x_i$ with any linear combination. So my intuition says it's not sufficient statistics. Completeness is the next step but I am stuck in calculating sufficient statistic. I am learning these concepts  so please give me any tips ,advice before calculating these things.","Let be a random sample from a distribution with the probability density function Which of the following statistics is(are) sufficient but NOT complete? My input The joint probability density function of the sample is Let .We see that the pdf can be expressed as a function that depends on the sample only through . Thus is a sufficient statistic for =  is sufficient statistic because is a function of by dividing the whole sum by gives ( I am not sure if this reasoning of mine is valid I just can't explain it to someone in brief. I need a perfect reasoning for that so someone tell me that.) = is a sufficient statistic because any one to one function of sufficient statistic T is also sufficient statistic. For example, if will be a one to one function. = Sum of these two statistics give = I am not sure how to calculate sufficient statistic in this one because I am not able to derive with any linear combination. So my intuition says it's not sufficient statistics. Completeness is the next step but I am stuck in calculating sufficient statistic. I am learning these concepts  so please give me any tips ,advice before calculating these things.","X_1,X_2,X_3,....X_n f(x|\theta) =
\begin{cases}
\dfrac{x}{\theta^2}e^{\frac{-x}{\theta}},  & \text{if x>0; \theta>0} \\
0, & \text{otherwise}
\end{cases} A=\bar X B=\bar X^2+3 C=( X_1,\sum_{i=2}^{n}X_i)  D=(X_1,\bar X) f(x_1,x_3,x_2...x_n|\theta) =\dfrac{\prod_{i=1}^{n}x_i}{\theta^{2n}}\bigg(e^{\dfrac{-\sum_{i=1}^{n}x_i}{\theta}}\bigg) T(x)=\sum_{i=1}^{n}x_i T(x) T(x) \theta A \bar X \sum_{i=1}^{n}x_i n \bar X B x>0 x^2 C \sum_{i=1}^{n}x_i D \sum_{i=1}^{n}x_i","['statistics', 'statistical-inference']"
71,what am I doing wrong computing this moment generating function?,what am I doing wrong computing this moment generating function?,,"For independent random variables $Y_1,...,Y_n$ with distribution $N(0,1)$ I've been told to prove that $$\overline{Y}, Y_1-\overline{Y}, Y_2-\overline{Y}, ..., Y_n - \overline{Y}$$ are independent by showing that the moment generating function (call it $\varphi(t,s_1,s_2,...,s_n)$ ) of $$(\overline{Y}, Y_1-\overline{Y}, Y_2-\overline{Y}, ..., Y_n - \overline{Y})$$ factors into $$MGF_{\overline{Y}}(t)\cdot MGF_{Y_1-\overline{Y}}(s_1)\cdot MGF_{ Y_2-\overline{Y}}(s_2) ...MGF_{ Y_n - \overline{Y}}(s_n).$$ Call the latter function $\psi(t,s_1,s_2,...,s_n)$ .  I've done these computations a number of times, and every time I get $$\psi(t,s_1,s_2,...,s_n) = \exp \big[ \frac{1}{2n}(t^2+(n-1)\sum_{i=1}^ns_i^2)\big]$$ $$\varphi(t,s_1,s_2,...,s_n)= \exp \big[ \frac{1}{2n}(t^2+n\sum_{i=1}^ns_i^2- (\sum_{i=1}^ns_i)^2)\big].$$ Which is close but not equal. What am I doing wrong? Here are my computations: $$\varphi(t,s_1,s_2,...,s_n) = E[\exp (t\overline{Y}+\sum_{i=1}^ns_i(Y_i-\overline{Y}))]=E[\exp (\sum_{i=1}^n(\frac{t}{n}+s_i-\frac{1}{n}\sum_{j=1}^ns_j)Y_i)]=$$ $$\Pi_{i=1}^nE[\exp ((\frac{t}{n}+s_i-\frac{1}{n}\sum_{j=1}^ns_j)Y_i)]= \Pi_{i=1}^nMGF_{Y_i}(\frac{t}{n}+s_i-\frac{1}{n}\sum_{j=1}^ns_j)=$$ $$\Pi_{i=1}^n \exp\big(\frac{1}{2}(\frac{t}{n}+s_i-\frac{1}{n}\sum_{j=1}^ns_j)^2\big)=$$ $$ \exp\bigg[\frac{1}{2}\sum_{i=1}^n\big(\frac{t^2}{n^2}+s_i^2+\frac{1}{n^2}(\sum_{j=1}^ns_j)^2+2\frac{ts_i}{n}-2\frac{t}{n^2}\sum_{j=1}^ns_j-2\frac{s_i}{n}\sum_{j=1}^ns_j\big)\bigg]= $$ $$\exp\bigg[\frac{1}{2}\big(\frac{t^2}{n}+\sum_{i=1}^ns_i^2+\frac{1}{n}(\sum_{j=1}^ns_j)^2+2\frac{t}{n}\sum_{i=1}^ns_i-2\frac{t}{n}\sum_{j=1}^ns_j-2\frac{1}{n}(\sum_{j=1}^ns_j)^2\big)\bigg]=$$ $$\exp\bigg[\frac{1}{2}\big(\frac{t^2}{n}+\sum_{i=1}^ns_i^2-\frac{1}{n}(\sum_{j=1}^ns_j)^2\big)\bigg].$$ $$\psi(t,s_1,s_2,...,s_n)= MGF_{\overline{Y}}(t)\cdot MGF_{Y_1-\overline{Y}}(s_1)\cdot MGF_{ Y_2-\overline{Y}}(s_2) ...MGF_{ Y_n - \overline{Y}}(s_n)=$$ $$ \exp[\frac{1}{2n}t^2]\Pi_{i=1}^n \exp[\frac{1}{2}\frac{n-1}{n}s_i^2]= \exp\bigg[\frac{1}{2}[\frac{1}{n}t^2+\frac{n-1}{n}\sum_{i=1}^ns_i^2]\bigg] $$ where I used the fact that $Y_i - \overline{Y}$ is normally distributed with mean 0 and variance $\frac{n-1}{n}$ and that a variable $X\sim N(0,\sigma^2)$ has $$MGF_X(s) =\exp[\frac{1}{2}\sigma^2s^2].$$","For independent random variables with distribution I've been told to prove that are independent by showing that the moment generating function (call it ) of factors into Call the latter function .  I've done these computations a number of times, and every time I get Which is close but not equal. What am I doing wrong? Here are my computations: where I used the fact that is normally distributed with mean 0 and variance and that a variable has","Y_1,...,Y_n N(0,1) \overline{Y}, Y_1-\overline{Y}, Y_2-\overline{Y}, ..., Y_n - \overline{Y} \varphi(t,s_1,s_2,...,s_n) (\overline{Y}, Y_1-\overline{Y}, Y_2-\overline{Y}, ..., Y_n - \overline{Y}) MGF_{\overline{Y}}(t)\cdot MGF_{Y_1-\overline{Y}}(s_1)\cdot MGF_{ Y_2-\overline{Y}}(s_2) ...MGF_{ Y_n - \overline{Y}}(s_n). \psi(t,s_1,s_2,...,s_n) \psi(t,s_1,s_2,...,s_n) = \exp \big[ \frac{1}{2n}(t^2+(n-1)\sum_{i=1}^ns_i^2)\big] \varphi(t,s_1,s_2,...,s_n)= \exp \big[ \frac{1}{2n}(t^2+n\sum_{i=1}^ns_i^2- (\sum_{i=1}^ns_i)^2)\big]. \varphi(t,s_1,s_2,...,s_n) = E[\exp (t\overline{Y}+\sum_{i=1}^ns_i(Y_i-\overline{Y}))]=E[\exp (\sum_{i=1}^n(\frac{t}{n}+s_i-\frac{1}{n}\sum_{j=1}^ns_j)Y_i)]= \Pi_{i=1}^nE[\exp ((\frac{t}{n}+s_i-\frac{1}{n}\sum_{j=1}^ns_j)Y_i)]= \Pi_{i=1}^nMGF_{Y_i}(\frac{t}{n}+s_i-\frac{1}{n}\sum_{j=1}^ns_j)= \Pi_{i=1}^n \exp\big(\frac{1}{2}(\frac{t}{n}+s_i-\frac{1}{n}\sum_{j=1}^ns_j)^2\big)=  \exp\bigg[\frac{1}{2}\sum_{i=1}^n\big(\frac{t^2}{n^2}+s_i^2+\frac{1}{n^2}(\sum_{j=1}^ns_j)^2+2\frac{ts_i}{n}-2\frac{t}{n^2}\sum_{j=1}^ns_j-2\frac{s_i}{n}\sum_{j=1}^ns_j\big)\bigg]=  \exp\bigg[\frac{1}{2}\big(\frac{t^2}{n}+\sum_{i=1}^ns_i^2+\frac{1}{n}(\sum_{j=1}^ns_j)^2+2\frac{t}{n}\sum_{i=1}^ns_i-2\frac{t}{n}\sum_{j=1}^ns_j-2\frac{1}{n}(\sum_{j=1}^ns_j)^2\big)\bigg]= \exp\bigg[\frac{1}{2}\big(\frac{t^2}{n}+\sum_{i=1}^ns_i^2-\frac{1}{n}(\sum_{j=1}^ns_j)^2\big)\bigg]. \psi(t,s_1,s_2,...,s_n)= MGF_{\overline{Y}}(t)\cdot MGF_{Y_1-\overline{Y}}(s_1)\cdot MGF_{ Y_2-\overline{Y}}(s_2) ...MGF_{ Y_n - \overline{Y}}(s_n)=  \exp[\frac{1}{2n}t^2]\Pi_{i=1}^n \exp[\frac{1}{2}\frac{n-1}{n}s_i^2]= \exp\bigg[\frac{1}{2}[\frac{1}{n}t^2+\frac{n-1}{n}\sum_{i=1}^ns_i^2]\bigg]  Y_i - \overline{Y} \frac{n-1}{n} X\sim N(0,\sigma^2) MGF_X(s) =\exp[\frac{1}{2}\sigma^2s^2].","['probability', 'probability-theory', 'statistics']"
72,Statistics $E[V]$ Problems,Statistics  Problems,E[V],"I have 2 statistics problems I am stuck on. Can anyone help me? Use the definition in Expression 3.13 to prove that $V(aX+b)=a^2\sigma_x^2$ . [Hint: With $h(x)=aX+b$ , $E[h(X)=a\mu+b$ where $\mu=E(X)$ .] Expression 3.1 is: $V(ax+b)=\sigma_{aX+b}^2=a^2\cdot\sigma_X^2$ And: $\sigma_{aX+b}=|a|\cdot\sigma_X.$ Write a general rule for $E(X-c)$ where c is a constant. What happens when you let $c=\mu$ , the expected value of $X$ . I can prove number #1 using the shortcut identity, but I don't think that's what it wants, I'm not sure where to start for #2.","I have 2 statistics problems I am stuck on. Can anyone help me? Use the definition in Expression 3.13 to prove that . [Hint: With , where .] Expression 3.1 is: And: Write a general rule for where c is a constant. What happens when you let , the expected value of . I can prove number #1 using the shortcut identity, but I don't think that's what it wants, I'm not sure where to start for #2.",V(aX+b)=a^2\sigma_x^2 h(x)=aX+b E[h(X)=a\mu+b \mu=E(X) V(ax+b)=\sigma_{aX+b}^2=a^2\cdot\sigma_X^2 \sigma_{aX+b}=|a|\cdot\sigma_X. E(X-c) c=\mu X,['statistics']
73,Function to calculate t-stat of similarity in survey answers,Function to calculate t-stat of similarity in survey answers,,"I have a survey of a large number of questions.  Each question is multiple choice, and has three possible answers. Users get served random questions to answer.   So they do not all answer the same set of questions. If ""user 1"" and ""user 2"" have both answered 'm' (say 90) questions in common, and of these 'm' questions, 'n' have been the same answer (say 70). If my null hypothesis is ""user 1 and user 2 have uncorrelated answers"", how would I create a t-state from the above to reject / not reject. Thank you!","I have a survey of a large number of questions.  Each question is multiple choice, and has three possible answers. Users get served random questions to answer.   So they do not all answer the same set of questions. If ""user 1"" and ""user 2"" have both answered 'm' (say 90) questions in common, and of these 'm' questions, 'n' have been the same answer (say 70). If my null hypothesis is ""user 1 and user 2 have uncorrelated answers"", how would I create a t-state from the above to reject / not reject. Thank you!",,"['probability', 'statistics', 'probability-distributions', 'bernoulli-numbers']"
74,Simplifying Likelihood Ratio,Simplifying Likelihood Ratio,,"(Answered here: https://stats.stackexchange.com/questions/372040/rejection-region-for-likelihood-ratio-test ) I have a data set $((Y_1,x_1),(Y_2,x_2),...,(Y_n,x_n))$ where $Y_i$ is distributed as $N(\theta x_i,1)$ . I want to perform a likelihood ratio test for $\theta$ to investigate the hypothesis $H_0: \theta=\theta_0$ or $H_1: \theta\neq\theta_0$ : $$\lambda(X)=\frac{exp(\frac{-\sum_i(Y_i-x_i\theta_0)^2}{2})}{exp(\frac{-\sum_i(Y_i-x_i\hat\theta)^2}{2})}$$ Where $\hat\theta$ is the maximum likelihood estimator, which I have determined to be $\frac{\sum_i x_iY_i}{\sum_ix_i^2}$ . I want to simplify this ratio as much as possible, but I don't know how to go about this, because $x_i\theta$ varies with $i$ , and as such, cannot be taken out of the sum. Normally, I would solve this by adding $0$ (i.e. adding and subtracting a term), but this approach did not help me this time around. Is there a trick that I am missing? Thanks in advance.","(Answered here: https://stats.stackexchange.com/questions/372040/rejection-region-for-likelihood-ratio-test ) I have a data set where is distributed as . I want to perform a likelihood ratio test for to investigate the hypothesis or : Where is the maximum likelihood estimator, which I have determined to be . I want to simplify this ratio as much as possible, but I don't know how to go about this, because varies with , and as such, cannot be taken out of the sum. Normally, I would solve this by adding (i.e. adding and subtracting a term), but this approach did not help me this time around. Is there a trick that I am missing? Thanks in advance.","((Y_1,x_1),(Y_2,x_2),...,(Y_n,x_n)) Y_i N(\theta x_i,1) \theta H_0: \theta=\theta_0 H_1: \theta\neq\theta_0 \lambda(X)=\frac{exp(\frac{-\sum_i(Y_i-x_i\theta_0)^2}{2})}{exp(\frac{-\sum_i(Y_i-x_i\hat\theta)^2}{2})} \hat\theta \frac{\sum_i x_iY_i}{\sum_ix_i^2} x_i\theta i 0","['statistics', 'summation', 'statistical-inference']"
75,Convert a vector of distances to a normalized vector of similarities,Convert a vector of distances to a normalized vector of similarities,,"I'm struggling to find a way to solve this problem. I have derived a $m \times n$ matrix containing in each row the Mahalanobis distance from a certain centroid. So at the end I have $m$ rows each expressing the distance of that variable from $n$ features. Now I want to obtain another matrix such that each row of the new matrix is the measure of similarity ( $\in [0,1]$ ) between the $i$ -th variable and the $j$ -th feature. Also, I want the rows of this matrix to be normalized to 1, since I want to plot each of this variable as a convex combination of a the vertices of a regular polytope. For a very naive example (the numbers are completely off my head): $d_i = [13 \,\, 60 \,\, 4]$ $\rightarrow$ $s_i = [0.15 \,\, 0.05 \,\, 0.8]$ In such a way that I can express $x_i$ and $y_i$ as $\sum_{j=1}^ns_{ij}\,p_{x,y}$ (where $p$ is the $x$ or $y$ coordinate of a vertex). Initially I tried $s_i = \dfrac{\dfrac{1}{d_i}}{\sum_{i=1}^n\dfrac{1}{d_i}} \, \forall i$ , but then I discovered that using the reciprocal I'm loosing some propriety of the distribution. With some research I also found the RBF kernel, but after normalization I just obtain a list of values which are basically identical. Do you have any clue on how I can achieve this? Thanks","I'm struggling to find a way to solve this problem. I have derived a matrix containing in each row the Mahalanobis distance from a certain centroid. So at the end I have rows each expressing the distance of that variable from features. Now I want to obtain another matrix such that each row of the new matrix is the measure of similarity ( ) between the -th variable and the -th feature. Also, I want the rows of this matrix to be normalized to 1, since I want to plot each of this variable as a convex combination of a the vertices of a regular polytope. For a very naive example (the numbers are completely off my head): In such a way that I can express and as (where is the or coordinate of a vertex). Initially I tried , but then I discovered that using the reciprocal I'm loosing some propriety of the distribution. With some research I also found the RBF kernel, but after normalization I just obtain a list of values which are basically identical. Do you have any clue on how I can achieve this? Thanks","m \times n m n \in [0,1] i j d_i = [13 \,\, 60 \,\, 4] \rightarrow s_i = [0.15 \,\, 0.05 \,\, 0.8] x_i y_i \sum_{j=1}^ns_{ij}\,p_{x,y} p x y s_i = \dfrac{\dfrac{1}{d_i}}{\sum_{i=1}^n\dfrac{1}{d_i}} \, \forall i","['statistics', 'machine-learning', 'convex-geometry', 'clustering', 'mahalanobis-distance']"
76,Minimum of a sum proof.,Minimum of a sum proof.,,"The problem I am working on is: Let $ Y = \{{y_1,y_2,y_3,...y_n\}}$ and $c=median(Y)$ . Prove that: $$ \text{min}\left[\sum_{i=1}^n \lvert y_{i}-c\rvert\right]=c $$ My question is: Is the $\text{min}\left[\right]$ function here, asking for the which $y_i$ the distance between $y_i$ and $c$ , $\lvert y_{i}-c\rvert$ is the smallest? Or is it asking, for the literal minimum of the arugments its given, like $\text{min}\left[99,1,4,7,121\right]=1$ ? What I have tried so far: 1. First I tried an example to get a feel for things: Let $ Y = \{{1,2,3,4,5\}}$ and $c=3$ . Then we have: $$\begin{align} \sum_{i=1}^5 \lvert y_{i}-3\rvert & = \lvert 1-3\rvert = 2 \\  & = \lvert 1-3\rvert = 2 \\   & = \lvert 2-3\rvert = 1 \\  & = \lvert 3-3\rvert = 0 \\  & = \lvert 4-3\rvert = 1 \\  & = \lvert 5-3\rvert = 2 \\   & = 2+1+0+1+2=6 \end{align}$$ So, $$ \text{min}\left[\sum_{i=1}^5 \lvert y_{i}-3\rvert\right]=\text{min}\left[6\right]=6 $$ Since this would now be acounterexample to the statement I am supposed to prove, I must be having a misunderstanding? 2. If the $\text{min}\left[\right]$ function works the other way, I tried the following proof: Proof: Since the distance between a point and itself is $0$ , $\left[c-c\right]=0$ and the fact that there can only be one median $c$ for a given set of $y$ , clearly $\left[c-c\right] \lt \left[y_i-c\right]$ for all $y_i.$ Is this correct if thats the case?","The problem I am working on is: Let and . Prove that: My question is: Is the function here, asking for the which the distance between and , is the smallest? Or is it asking, for the literal minimum of the arugments its given, like ? What I have tried so far: 1. First I tried an example to get a feel for things: Let and . Then we have: So, Since this would now be acounterexample to the statement I am supposed to prove, I must be having a misunderstanding? 2. If the function works the other way, I tried the following proof: Proof: Since the distance between a point and itself is , and the fact that there can only be one median for a given set of , clearly for all Is this correct if thats the case?"," Y = \{{y_1,y_2,y_3,...y_n\}} c=median(Y) 
\text{min}\left[\sum_{i=1}^n \lvert y_{i}-c\rvert\right]=c  \text{min}\left[\right] y_i y_i c \lvert y_{i}-c\rvert \text{min}\left[99,1,4,7,121\right]=1  Y = \{{1,2,3,4,5\}} c=3 \begin{align}
\sum_{i=1}^5 \lvert y_{i}-3\rvert & = \lvert 1-3\rvert = 2 \\
 & = \lvert 1-3\rvert = 2 \\ 
 & = \lvert 2-3\rvert = 1 \\
 & = \lvert 3-3\rvert = 0 \\
 & = \lvert 4-3\rvert = 1 \\
 & = \lvert 5-3\rvert = 2 \\ 
 & = 2+1+0+1+2=6
\end{align}  \text{min}\left[\sum_{i=1}^5 \lvert y_{i}-3\rvert\right]=\text{min}\left[6\right]=6
 \text{min}\left[\right] 0 \left[c-c\right]=0 c y \left[c-c\right] \lt \left[y_i-c\right] y_i.","['statistics', 'proof-verification', 'maxima-minima', 'median']"
77,Is it possible that probability of occuring intersection of two events will be greater than probability of occuring each of them?,Is it possible that probability of occuring intersection of two events will be greater than probability of occuring each of them?,,"If $A$ and $B$ are correlated events, Is it possible that we have : $$P\left(A \cap B \right) \geq P\left( A\right)$$ and $$P\left(A \cap B \right) \geq P\left( B\right)$$ Is it possible?","If and are correlated events, Is it possible that we have : and Is it possible?",A B P\left(A \cap B \right) \geq P\left( A\right) P\left(A \cap B \right) \geq P\left( B\right),"['probability', 'probability-theory', 'statistics', 'statistical-inference']"
78,Finding the PMF of a Binomial Distribution with $Y=\sqrt{x}$.,Finding the PMF of a Binomial Distribution with .,Y=\sqrt{x},"Let $X$ be a random variable with pmf $$ f(x) = \begin{cases} \binom nxp^x (1-p)^{n-x}, & \text{if } x=0,1,2,...,n \\ 0, & \text{elsewhere} \end{cases} $$ Find the pmf of $Y=\sqrt{X}$ . My attempt: $$F(Y) = P(Y\le y) = P(\sqrt{X}\le y) = P(X\le y^2) =\binom n{y^2}p^{y^2} (1-p)^{n-y^2}  $$ Am I on the right path?",Let be a random variable with pmf Find the pmf of . My attempt: Am I on the right path?,"X  f(x) = \begin{cases} \binom nxp^x (1-p)^{n-x}, & \text{if } x=0,1,2,...,n \\ 0, & \text{elsewhere} \end{cases}  Y=\sqrt{X} F(Y) = P(Y\le y) = P(\sqrt{X}\le y) = P(X\le y^2) =\binom n{y^2}p^{y^2} (1-p)^{n-y^2}  ","['probability', 'statistics', 'probability-distributions']"
79,"why are ""least square estimators"" in fact ""estimators""?","why are ""least square estimators"" in fact ""estimators""?",,"I'm trying to reconcile the notion of a ""least square estimator"" with the definition of an estimator I have in my head. An estimator for me assumes a set $\Omega$ and a family of probability measures $$\{\mu_\theta: \theta \in \Theta\}$$ on $\Omega$, and a function on the index set $g:\Theta \rightarrow \mathbb{R}$. An unbiased estimator for $g$ is then a function $\tilde{g}: \Omega \rightarrow \mathbb{R}$ such that $$\int_\Omega \tilde{g} \, d\mu_\theta = g(\theta)$$ for all $\theta\in\Theta$. A ""least squares estimator"" on the other hand assumes we have some uncorrelated random variables $X_1,\ldots,X_n: \mathscr{X} \rightarrow \mathbb{R}$ on a space $\mathscr{X}$ (I think with a fixed probability measure?) with common variance and expectations $\theta_1,\ldots,\theta_n$ assumed to lie in some linear subspace $V\subset \mathbb{R}^n$ (as something varies? what specifically i don't know.  Maybe varies with a family of probability measures on $\mathscr{X}$?).  Then given an ""observation"" $x=(x_1,\ldots,x_n)\in \mathbb{R}^n$ we ""estimate""  $(\theta_1,\ldots,\theta_n)$ by just projecting $x$ to the subspace $V$ obtaining say $x'$. Then given any linear $L: \mathbb{R}^n\rightarrow \mathbb{R}$, $L(x')$ is supposed to be an estimator for $L(X_1,...,X_n)$. (I hope that's a fair treatment. I've tried to simplify it by not including the matrix $A$ which parametrizes subspace $V$) Now my question is how should I define $\Omega$ and $\Theta$ and $\mu_\theta$ and $g$ and $\tilde{g}$ to show that the latter is an instance of the former?  I'd be inclined to just make $\Omega = \mathbb{R}^n$ and $\mu_\theta$ some kind of product measure if the $X_1,\ldots,X_n$ were independent, but they are only assumed uncorrelated.","I'm trying to reconcile the notion of a ""least square estimator"" with the definition of an estimator I have in my head. An estimator for me assumes a set $\Omega$ and a family of probability measures $$\{\mu_\theta: \theta \in \Theta\}$$ on $\Omega$, and a function on the index set $g:\Theta \rightarrow \mathbb{R}$. An unbiased estimator for $g$ is then a function $\tilde{g}: \Omega \rightarrow \mathbb{R}$ such that $$\int_\Omega \tilde{g} \, d\mu_\theta = g(\theta)$$ for all $\theta\in\Theta$. A ""least squares estimator"" on the other hand assumes we have some uncorrelated random variables $X_1,\ldots,X_n: \mathscr{X} \rightarrow \mathbb{R}$ on a space $\mathscr{X}$ (I think with a fixed probability measure?) with common variance and expectations $\theta_1,\ldots,\theta_n$ assumed to lie in some linear subspace $V\subset \mathbb{R}^n$ (as something varies? what specifically i don't know.  Maybe varies with a family of probability measures on $\mathscr{X}$?).  Then given an ""observation"" $x=(x_1,\ldots,x_n)\in \mathbb{R}^n$ we ""estimate""  $(\theta_1,\ldots,\theta_n)$ by just projecting $x$ to the subspace $V$ obtaining say $x'$. Then given any linear $L: \mathbb{R}^n\rightarrow \mathbb{R}$, $L(x')$ is supposed to be an estimator for $L(X_1,...,X_n)$. (I hope that's a fair treatment. I've tried to simplify it by not including the matrix $A$ which parametrizes subspace $V$) Now my question is how should I define $\Omega$ and $\Theta$ and $\mu_\theta$ and $g$ and $\tilde{g}$ to show that the latter is an instance of the former?  I'd be inclined to just make $\Omega = \mathbb{R}^n$ and $\mu_\theta$ some kind of product measure if the $X_1,\ldots,X_n$ were independent, but they are only assumed uncorrelated.",,"['probability', 'probability-theory', 'statistics']"
80,Get quartiles and a half of the data,Get quartiles and a half of the data,,"The following table shows a frequency distribution of the scores obtained in a test. Punctuation           (3, 4] (4, 5] (5, 6] (6, 7] (7, 8] (8, 9] (9, 10] Number of participants  2      4      10     20     40     35      9 (a) The highest score reached by the bottom 20% of the participants and the score lowest obtained by the top 25% of the participants (b) The quartiles of the distribution For section a) to be continuous variables that can have any value within a range what I do is calculate the average for that 20%, that is to say who is in position 24. I calculate the relative frequency (that for this I need to know the absolute frequency) and multiplied it by the midpoint of the interval. I am applying according to the definition and the formula, but I am stuck. It is a note that is between (6,7] and the average I get 0.1, so the note would be 6.1. For b) of the quartiles I get that 1 is in (6,7], 2 is in (7,8] and 3 is in (8,9), but I do not know how to get the exact note I've done it that way, but I do not know if it's okay since it's the first time I've done something similar, can someone verify it? a) I have the table Class | partici | Ni 3-4   |     2   | 2 4-5   |     4   | 6 5-6   |    10   | 16 6-7   |    20   | 36 7-8   |    40   | 76 8-9   |    35   | 111 9-10  |     9   | 120 For The highest score reached by the bottom 20% of the participants means the 20th percentile so P20 = 6+ ((0,20*120)-16)*1 /20 = 6,4 score The lowest score obtained by the top 25% of the participants means the 75th percentile, so it is calculated in the same way P75 = 8 + ((0,75*120)-76)*1 /35 = 8,4 score b) For the quartiles, it is the same as calculating the percentiles for 25% 50% and 75%. Q2 is equal to the median Q1 = 6 + ((0,25*120)-16)*1 /20 = 6,7 score  Q2 = 7 + ((0,5*120)-36)*1 /40 = 7,6 score  Q3 = 8 + ((0,75*120)-76)*1 /35 = 8,4 score =P75 (From the section a-))","The following table shows a frequency distribution of the scores obtained in a test. Punctuation           (3, 4] (4, 5] (5, 6] (6, 7] (7, 8] (8, 9] (9, 10] Number of participants  2      4      10     20     40     35      9 (a) The highest score reached by the bottom 20% of the participants and the score lowest obtained by the top 25% of the participants (b) The quartiles of the distribution For section a) to be continuous variables that can have any value within a range what I do is calculate the average for that 20%, that is to say who is in position 24. I calculate the relative frequency (that for this I need to know the absolute frequency) and multiplied it by the midpoint of the interval. I am applying according to the definition and the formula, but I am stuck. It is a note that is between (6,7] and the average I get 0.1, so the note would be 6.1. For b) of the quartiles I get that 1 is in (6,7], 2 is in (7,8] and 3 is in (8,9), but I do not know how to get the exact note I've done it that way, but I do not know if it's okay since it's the first time I've done something similar, can someone verify it? a) I have the table Class | partici | Ni 3-4   |     2   | 2 4-5   |     4   | 6 5-6   |    10   | 16 6-7   |    20   | 36 7-8   |    40   | 76 8-9   |    35   | 111 9-10  |     9   | 120 For The highest score reached by the bottom 20% of the participants means the 20th percentile so P20 = 6+ ((0,20*120)-16)*1 /20 = 6,4 score The lowest score obtained by the top 25% of the participants means the 75th percentile, so it is calculated in the same way P75 = 8 + ((0,75*120)-76)*1 /35 = 8,4 score b) For the quartiles, it is the same as calculating the percentiles for 25% 50% and 75%. Q2 is equal to the median Q1 = 6 + ((0,25*120)-16)*1 /20 = 6,7 score  Q2 = 7 + ((0,5*120)-36)*1 /40 = 7,6 score  Q3 = 8 + ((0,75*120)-76)*1 /35 = 8,4 score =P75 (From the section a-))",,['statistics']
81,From Ng video: Using feature normalization with polynomial regression,From Ng video: Using feature normalization with polynomial regression,,"In this video on machine learning by Andrew Ng, called ""Features and Polynomial Regression"", at time 4:34, he mentions the possibility of feature normalization in polynomial regression. By which he means, I believe, applying an affine transformation to the feature vector $(1, x, x^2, \dotsc, x^{n-1})$ so that the variances of the $x^i$ are closer to one another. Does anyone know of a reference on this practice? I'd like to investigate it and its effects. (That is, the specific application of feature normalization to polynomial regression. Not just feature normalization in general.)","In this video on machine learning by Andrew Ng, called ""Features and Polynomial Regression"", at time 4:34, he mentions the possibility of feature normalization in polynomial regression. By which he means, I believe, applying an affine transformation to the feature vector $(1, x, x^2, \dotsc, x^{n-1})$ so that the variances of the $x^i$ are closer to one another. Does anyone know of a reference on this practice? I'd like to investigate it and its effects. (That is, the specific application of feature normalization to polynomial regression. Not just feature normalization in general.)",,"['statistics', 'reference-request', 'optimization', 'regression', 'machine-learning']"
82,Dealing with different definitions of the Ornstein–Uhlenbeck process,Dealing with different definitions of the Ornstein–Uhlenbeck process,,"I've run up against a wall in reconciling two different definitions of the Ornstein–Uhlenbeck process, and would appreciate some help. On the one hand, as discussed here , we can define an Ornstein–Uhlenbeck process as a Gaussian process with a kernel function of the form $k(x, y) \propto \exp(-\left\lVert x - y\right\rVert / \theta)$, which is clearly stationary. On the other hand, we have the definition of the Ornstein–Uhlenbeck process as the solution to the stochastic differential equation $du(t) = \theta(\mu - u(t))+\sigma \, dW(t)$, which is given by $$u(t)= u(0) \exp⁡(-\theta t)+\mu(1-\exp⁡(-\theta t) )+\sigma \exp⁡(-\theta t) \int_0^t \exp⁡(\theta\tau) \, dW(\tau).$$ Using the Itô isometry, as shown here and here on SE , this process can be shown to have the covariance $$k(x, y) = \frac{\sigma^2}{2\theta} \exp(-\theta (x+y)) (1 - \exp(2 \theta (x - y))).$$ Not only is this not equal to the previous definition, this is not even stationary. What gives? Are these two distinct definitions of what ""Ornstein–Uhlenbeck process"" means, or can these two processes be shown to be equal, possibly modulo certain assumptions? As a bonus question, just because I've never seen anyone prove it - how do you prove that the solution to the above SDE is a Gaussian process (assuming it is)?","I've run up against a wall in reconciling two different definitions of the Ornstein–Uhlenbeck process, and would appreciate some help. On the one hand, as discussed here , we can define an Ornstein–Uhlenbeck process as a Gaussian process with a kernel function of the form $k(x, y) \propto \exp(-\left\lVert x - y\right\rVert / \theta)$, which is clearly stationary. On the other hand, we have the definition of the Ornstein–Uhlenbeck process as the solution to the stochastic differential equation $du(t) = \theta(\mu - u(t))+\sigma \, dW(t)$, which is given by $$u(t)= u(0) \exp⁡(-\theta t)+\mu(1-\exp⁡(-\theta t) )+\sigma \exp⁡(-\theta t) \int_0^t \exp⁡(\theta\tau) \, dW(\tau).$$ Using the Itô isometry, as shown here and here on SE , this process can be shown to have the covariance $$k(x, y) = \frac{\sigma^2}{2\theta} \exp(-\theta (x+y)) (1 - \exp(2 \theta (x - y))).$$ Not only is this not equal to the previous definition, this is not even stationary. What gives? Are these two distinct definitions of what ""Ornstein–Uhlenbeck process"" means, or can these two processes be shown to be equal, possibly modulo certain assumptions? As a bonus question, just because I've never seen anyone prove it - how do you prove that the solution to the above SDE is a Gaussian process (assuming it is)?",,"['probability', 'statistics', 'stochastic-processes', 'stochastic-calculus']"
83,What is the meaning of subsampling level in machine learning/statistics?,What is the meaning of subsampling level in machine learning/statistics?,,"I am reading a paper but nowhere it is defined but the term is being used a lot. The paper is - Less is More : Nystrom Computational Regularization -Rudi,Camariano,                 Rosasco  Link : https://papers.nips.cc/paper/5936-less-is-more-nystrom-computational-regularization.pdf","I am reading a paper but nowhere it is defined but the term is being used a lot. The paper is - Less is More : Nystrom Computational Regularization -Rudi,Camariano,                 Rosasco  Link : https://papers.nips.cc/paper/5936-less-is-more-nystrom-computational-regularization.pdf",,"['statistics', 'machine-learning', 'sampling', 'learning', 'descriptive-statistics']"
84,Estimate parameters of Wishart matrix.,Estimate parameters of Wishart matrix.,,"Given a sequence of real Wishart matrices $W_1 , \cdots , W_k \sim \mathcal{W}_m(n,\Sigma)$ where $\Sigma$ is a singular matrix. Are there good estimates for the degrees of freedom? The MLE for $\Sigma$ is $\frac{1}{k\cdot n-1}\sum_{i=1}^k W_i$ since this is the MLE if we had access to the samples which gave rise to the observed Wishart matrices. The only estimate I have been able to come up for the degrees of freedom is to take a random vector $Y$ and consider $\frac{Y^T W Y}{Y^T (\frac{1}{k}\sum_{i=1}^k W_i) Y}$. This should be approximately $\chi^2_n /n$ according to theorem 3.2.8 in Muirhead's Aspects of multivariate statistical theory, estimating $n$ now comes down to estimating the shape parameter of the $\chi^2_n /n$.","Given a sequence of real Wishart matrices $W_1 , \cdots , W_k \sim \mathcal{W}_m(n,\Sigma)$ where $\Sigma$ is a singular matrix. Are there good estimates for the degrees of freedom? The MLE for $\Sigma$ is $\frac{1}{k\cdot n-1}\sum_{i=1}^k W_i$ since this is the MLE if we had access to the samples which gave rise to the observed Wishart matrices. The only estimate I have been able to come up for the degrees of freedom is to take a random vector $Y$ and consider $\frac{Y^T W Y}{Y^T (\frac{1}{k}\sum_{i=1}^k W_i) Y}$. This should be approximately $\chi^2_n /n$ according to theorem 3.2.8 in Muirhead's Aspects of multivariate statistical theory, estimating $n$ now comes down to estimating the shape parameter of the $\chi^2_n /n$.",,"['statistics', 'statistical-inference', 'estimation', 'parameter-estimation']"
85,"As n approaches infinity, the likelihood function at true parameter values is maximum among any other feasible choice of the parameters","As n approaches infinity, the likelihood function at true parameter values is maximum among any other feasible choice of the parameters",,"Assume that a density $f(x;\theta)$ is distinct for different values of parameter $\theta$ and has common support for all $\theta$. To show that for $\theta \neq \theta_0$ (=true value that generates samples), $$\lim_{n \to \infty} P\left(L(\theta_0;x_1,...,x_n)>L(\theta;x_1,...,x_n)\right)=1$$ where $L$ is a likelihood function of the density $f$, my textbook proved it by showing that  $$\frac{1}{n}\sum_{i=1}^{n} \log\left(\frac{f(x;\theta)}{f(x;\theta_0)}\right)<0 $$ which by the WLLN, as $n \longrightarrow \infty$, the left hand side is equal to $$E\left[\log\left(\frac{f(x;\theta)}{f(x;\theta_0)}\right) \right] < \log E\left[\frac{f(x;\theta)}{f(x;\theta_0)}\right]=\log(1)=0$$ by Jensen's inequality. But I would like to know whether the following solution can also be used. From AM-GM inequality,  $$\left(\prod_{i=1}^{n} f(x_i;\theta)\right)^{1/n} = L(\theta;x_1,...,x_n)^{1/n} \leq \frac{\sum_{i=1}^{n} f(x_i;\theta)}{n}$$ As $n \longrightarrow \infty$, by the WLLN $$L(\theta;x_1,...,x_n)^{1/n} \leq E[f(X;\theta)]= \int f(x;\theta)f(x;\theta_0)dx = \left<f(x;\theta),f(x;\theta_0)\right>$$ From Cauchy-Schwarz inequality, the inner product between two vectors is maximized when they are in the same direction. So the strict maximum of $L(\theta;x_1,...,x_n)$ is attained when $f(x;\theta)=f(x;\theta_0)$ by the assumption of the distinct density for different $\theta$, which implies $\theta = \theta_0$. Hence, as $n \longrightarrow \infty$, $P(L(\theta;x_1,...,x_n) < L(\theta_0;x_1,...,x_n))=1$.","Assume that a density $f(x;\theta)$ is distinct for different values of parameter $\theta$ and has common support for all $\theta$. To show that for $\theta \neq \theta_0$ (=true value that generates samples), $$\lim_{n \to \infty} P\left(L(\theta_0;x_1,...,x_n)>L(\theta;x_1,...,x_n)\right)=1$$ where $L$ is a likelihood function of the density $f$, my textbook proved it by showing that  $$\frac{1}{n}\sum_{i=1}^{n} \log\left(\frac{f(x;\theta)}{f(x;\theta_0)}\right)<0 $$ which by the WLLN, as $n \longrightarrow \infty$, the left hand side is equal to $$E\left[\log\left(\frac{f(x;\theta)}{f(x;\theta_0)}\right) \right] < \log E\left[\frac{f(x;\theta)}{f(x;\theta_0)}\right]=\log(1)=0$$ by Jensen's inequality. But I would like to know whether the following solution can also be used. From AM-GM inequality,  $$\left(\prod_{i=1}^{n} f(x_i;\theta)\right)^{1/n} = L(\theta;x_1,...,x_n)^{1/n} \leq \frac{\sum_{i=1}^{n} f(x_i;\theta)}{n}$$ As $n \longrightarrow \infty$, by the WLLN $$L(\theta;x_1,...,x_n)^{1/n} \leq E[f(X;\theta)]= \int f(x;\theta)f(x;\theta_0)dx = \left<f(x;\theta),f(x;\theta_0)\right>$$ From Cauchy-Schwarz inequality, the inner product between two vectors is maximized when they are in the same direction. So the strict maximum of $L(\theta;x_1,...,x_n)$ is attained when $f(x;\theta)=f(x;\theta_0)$ by the assumption of the distinct density for different $\theta$, which implies $\theta = \theta_0$. Hence, as $n \longrightarrow \infty$, $P(L(\theta;x_1,...,x_n) < L(\theta_0;x_1,...,x_n))=1$.",,"['statistics', 'maximum-likelihood']"
86,Sampling error of correlation coefficient (Phi coefficient) for binary variables,Sampling error of correlation coefficient (Phi coefficient) for binary variables,,"Suppose I have two correlated binary variables (A and B) with known probabilities ($p_a$ and $p_b$) and correlation ( Phi ) coefficient in population - $\rho$ . Is there any analytic function for sampling error of correlation coefficient if I have finite sample from the population? I've tried to use Fisher z-transformation, with sampling variance estimation of $1/N$ but it gives inappropriate (lower than actual) estimation of variance. As my simulations show, sampling error of Phi coefficient is a function of population correlation coefficient, frequencies of both binary variables and of course sample size. Thanks in advance!","Suppose I have two correlated binary variables (A and B) with known probabilities ($p_a$ and $p_b$) and correlation ( Phi ) coefficient in population - $\rho$ . Is there any analytic function for sampling error of correlation coefficient if I have finite sample from the population? I've tried to use Fisher z-transformation, with sampling variance estimation of $1/N$ but it gives inappropriate (lower than actual) estimation of variance. As my simulations show, sampling error of Phi coefficient is a function of population correlation coefficient, frequencies of both binary variables and of course sample size. Thanks in advance!",,"['statistics', 'statistical-inference', 'correlation']"
87,Find the expected value of the additional pickups?,Find the expected value of the additional pickups?,,I find a probability problem in a computer game. The problem is as following. The player has a passive ability that has $28$% chance every $27$ second to grant random buff. There are 6 types of buff and they have equal chance to occur. The desired buff lasts $120$ second and it doubles($\times2$) the pickups of the player during the period. The desired buff effect can be piled and the player earns $\times2^n$ pickups for n numbers of the desired buff. What is the expected value of the additional pickups? Someone has given the following solution: Chance of random buff$ = 28$% Time between trying buff$ = 27$s Number of buff types$ = 6$ Desired buff$ = $“Double Pickups” Duration of the desired buff$ = 120$s Average time it takes to proc “Double Pickups”$ = (27$s$ \times 1/0.28) \times 6 = 578$s$ = 9.64 $min How often is the “Double Pickups” active $ = 120$s$ / 578$s$ = 20.76$% of the time How much pickups does one gain over all $ = 1 + (1 \times 0.2) = 1.2 = 120$%$ = 20$% more pickups overall I don't think this is the right solution. May someone tell me if it is correct or not? What is the correct answer? Please explain.,I find a probability problem in a computer game. The problem is as following. The player has a passive ability that has $28$% chance every $27$ second to grant random buff. There are 6 types of buff and they have equal chance to occur. The desired buff lasts $120$ second and it doubles($\times2$) the pickups of the player during the period. The desired buff effect can be piled and the player earns $\times2^n$ pickups for n numbers of the desired buff. What is the expected value of the additional pickups? Someone has given the following solution: Chance of random buff$ = 28$% Time between trying buff$ = 27$s Number of buff types$ = 6$ Desired buff$ = $“Double Pickups” Duration of the desired buff$ = 120$s Average time it takes to proc “Double Pickups”$ = (27$s$ \times 1/0.28) \times 6 = 578$s$ = 9.64 $min How often is the “Double Pickups” active $ = 120$s$ / 578$s$ = 20.76$% of the time How much pickups does one gain over all $ = 1 + (1 \times 0.2) = 1.2 = 120$%$ = 20$% more pickups overall I don't think this is the right solution. May someone tell me if it is correct or not? What is the correct answer? Please explain.,,"['probability', 'statistics', 'proof-verification', 'probability-distributions', 'expected-value']"
88,Find the cumulants of the power level of a given gaussian process,Find the cumulants of the power level of a given gaussian process,,"I have given a zero-mean, circular symmetric, complex gaussian stochastic process $x[n] = a[n] + jb[n]$, where $a[n]$, $b[n]$, are jointly independent and $\sim N (0, \sigma^2)$. And I want to find the cumulants of the function: $z[n] = \sum_{l=1}^{L} |x[l]|^2$ Whereby all samples of $x[n]$ are i.i.d. $\sim \mathcal{N}(0, \sigma ^2)$. It is clear I can write: $|x[l]|^2 = a[l]^2 + b[l]^2$ However, I am stuck at the further steps of the derivation.","I have given a zero-mean, circular symmetric, complex gaussian stochastic process $x[n] = a[n] + jb[n]$, where $a[n]$, $b[n]$, are jointly independent and $\sim N (0, \sigma^2)$. And I want to find the cumulants of the function: $z[n] = \sum_{l=1}^{L} |x[l]|^2$ Whereby all samples of $x[n]$ are i.i.d. $\sim \mathcal{N}(0, \sigma ^2)$. It is clear I can write: $|x[l]|^2 = a[l]^2 + b[l]^2$ However, I am stuck at the further steps of the derivation.",,"['probability', 'probability-theory', 'statistics']"
89,Undistorting night sky star motion (given that stars don't move) [closed],Undistorting night sky star motion (given that stars don't move) [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 5 years ago . Improve this question My ultimate goal: out of 500 night-sky photos, I'd like to distort 499 of them to the exact star position of the first one.  (Imagine a fancy motorized star-tracking rig, but done with math instead of motors) But I don't know my camera's distortion, so is there a way to brute-force solve this? What I've got to work with: 500 2-second nighttime photos over a several hour range. Perfectly stationary camera (normal field of view) Extracted star locations as x,y pixel coordinates Star correlation, for the ~15 brightest stars I know: frameTimeLocation(time, bright_star_number) = (x,y) Exact time each of the 500 photos were taken The knowledge that stars don't move relative to each other The knowledge that stars are rotating around a fixed point (which may be outside the camera's FOV) The assumption that the distortion of the camera is smooth Assuming everything above, I could either Solve the camera distortion equation Solve some general distortion field matrix thing The problem is that I'm not sure how to start with either.  I'm very much a programmer and not as much a mathematician, and eventually I need to end up with pixelValuesAcrossAllPhotosMappedToTime0(targetx, targety) = 500 pixels of data.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 5 years ago . Improve this question My ultimate goal: out of 500 night-sky photos, I'd like to distort 499 of them to the exact star position of the first one.  (Imagine a fancy motorized star-tracking rig, but done with math instead of motors) But I don't know my camera's distortion, so is there a way to brute-force solve this? What I've got to work with: 500 2-second nighttime photos over a several hour range. Perfectly stationary camera (normal field of view) Extracted star locations as x,y pixel coordinates Star correlation, for the ~15 brightest stars I know: frameTimeLocation(time, bright_star_number) = (x,y) Exact time each of the 500 photos were taken The knowledge that stars don't move relative to each other The knowledge that stars are rotating around a fixed point (which may be outside the camera's FOV) The assumption that the distortion of the camera is smooth Assuming everything above, I could either Solve the camera distortion equation Solve some general distortion field matrix thing The problem is that I'm not sure how to start with either.  I'm very much a programmer and not as much a mathematician, and eventually I need to end up with pixelValuesAcrossAllPhotosMappedToTime0(targetx, targety) = 500 pixels of data.",,"['statistics', 'optimization', 'nonlinear-optimization', 'least-squares']"
90,Given the correlation between shares of all $\frac{n(n-1)}{2}$ pairs among $n$ different companies. How to acheive maximum diversification?,Given the correlation between shares of all  pairs among  different companies. How to acheive maximum diversification?,\frac{n(n-1)}{2} n,"I have the historical data about the stock prices of the companies and can easily calculate the historical correlation between any two of them. Given this information, how should I go about finding the position sizes that will provide me the maximum diversification? Example: Consider three companies, out of which two of them are real estate companies and the third one is an automobile company. The correlation between the two real estate companies is higher[as found from the data]. My intuition tells me that I should give less than (1/3) weight to each of the real estate companies, in order to achieve higher diversification.","I have the historical data about the stock prices of the companies and can easily calculate the historical correlation between any two of them. Given this information, how should I go about finding the position sizes that will provide me the maximum diversification? Example: Consider three companies, out of which two of them are real estate companies and the third one is an automobile company. The correlation between the two real estate companies is higher[as found from the data]. My intuition tells me that I should give less than (1/3) weight to each of the real estate companies, in order to achieve higher diversification.",,"['probability', 'statistics', 'correlation']"
91,Minimal sufficient statistic for $\theta$ where $f(x;\theta)$ = $2(1+\theta-x) I_{\theta \le x \le\theta+1}$,Minimal sufficient statistic for  where  =,\theta f(x;\theta) 2(1+\theta-x) I_{\theta \le x \le\theta+1},"I am not able to find the minimal sufficient statistic for the following density function: $$f(x_i;\theta) = 2(1+\theta-x_i)I_{\theta \le x_i \le \theta+1}$$ The function does not belong to the exponential family distribution and so I apply the the Lehmann Scheffé Theorem, from which I get that a minimal sufficient statistic should be: $$T(\mathbf x) = (\min(x_i), \max(x_i), \prod(1+\theta+x_i))$$ But since a statistic cannot depend on the parameter, it is wrong for sure.","I am not able to find the minimal sufficient statistic for the following density function: $$f(x_i;\theta) = 2(1+\theta-x_i)I_{\theta \le x_i \le \theta+1}$$ The function does not belong to the exponential family distribution and so I apply the the Lehmann Scheffé Theorem, from which I get that a minimal sufficient statistic should be: $$T(\mathbf x) = (\min(x_i), \max(x_i), \prod(1+\theta+x_i))$$ But since a statistic cannot depend on the parameter, it is wrong for sure.",,"['statistics', 'sufficient-statistics']"
92,Minimal sufficient statistic for $\theta$ where $f(x;\theta)=\frac{\beta^3}{2}e^{-\beta(x-\theta)}(x-\theta)^2\mathbf1_{x\ge\theta}$,Minimal sufficient statistic for  where,\theta f(x;\theta)=\frac{\beta^3}{2}e^{-\beta(x-\theta)}(x-\theta)^2\mathbf1_{x\ge\theta},"I have this density function for which I am not able to find a minimal sufficient statistic, as required. It does not belong to the exponential families distribution as the support depend also on the parameter, and with the Lehmann Scheffé approach I am not able to separate the random variable $X$ from the parameter $\theta$. $$f(x;\theta)=\frac{\beta^3}{2}e^{-\beta(x-\theta)}(x-\theta)^2 \mathbf1_{x\ge\theta}, \quad \beta\text{ known}$$","I have this density function for which I am not able to find a minimal sufficient statistic, as required. It does not belong to the exponential families distribution as the support depend also on the parameter, and with the Lehmann Scheffé approach I am not able to separate the random variable $X$ from the parameter $\theta$. $$f(x;\theta)=\frac{\beta^3}{2}e^{-\beta(x-\theta)}(x-\theta)^2 \mathbf1_{x\ge\theta}, \quad \beta\text{ known}$$",,"['statistics', 'sufficient-statistics']"
93,"Show $T=X_1(X_3+X_4)+X_2$ is not sufficient for $p$ where $X_1,...,X_4$ are iid Bernoulli(p)",Show  is not sufficient for  where  are iid Bernoulli(p),"T=X_1(X_3+X_4)+X_2 p X_1,...,X_4","I am attempting to show that $T=X_1(X_3+X_4)+X_2$ is not sufficient for $p$ where $X_1,...,X_4$ are iid Bernoulli(p), and the question specifies that I am to use the conditional distribution method. Here is my work: It can be shown first that $T=0$ iff $[X_1=0$ $\cup$ ($X_3=0$ $\cap$ $X_4=0$)] $\cap$ $X_2=0$. So the probability of obtaining $\bigcap_{i=1}^4X_i=0 $ given that $T=0$ can be expressed as: $$ \frac{Pr[\bigcap_{i=1}^4X_i=0]}{Pr[T=0]}=\frac{(1-p)^4}{(1-p)^2+(1-p)^3-(1-p)^4}  $$ Hence, $T$ is not sufficient for $p$ because the above expression depends on $p$. My questions are, first, did I successfully prove the statement that $T$ is not sufficient for $p$? And second, could I have completed this proof without using particular values of $X$ and $T$?","I am attempting to show that $T=X_1(X_3+X_4)+X_2$ is not sufficient for $p$ where $X_1,...,X_4$ are iid Bernoulli(p), and the question specifies that I am to use the conditional distribution method. Here is my work: It can be shown first that $T=0$ iff $[X_1=0$ $\cup$ ($X_3=0$ $\cap$ $X_4=0$)] $\cap$ $X_2=0$. So the probability of obtaining $\bigcap_{i=1}^4X_i=0 $ given that $T=0$ can be expressed as: $$ \frac{Pr[\bigcap_{i=1}^4X_i=0]}{Pr[T=0]}=\frac{(1-p)^4}{(1-p)^2+(1-p)^3-(1-p)^4}  $$ Hence, $T$ is not sufficient for $p$ because the above expression depends on $p$. My questions are, first, did I successfully prove the statement that $T$ is not sufficient for $p$? And second, could I have completed this proof without using particular values of $X$ and $T$?",,['probability-theory']
94,Getting the best fitting distribution using the p value,Getting the best fitting distribution using the p value,,"I have a set of data points, and I want to get the best theoretical distribution that fits the data. For that I'm using Kolmogorov-Smirnov test for goodness of fit. This test reveals the p value of the two sided test. Can I chose the distribution as the best fitting distribution, which gives the highest p value for the K-S test?","I have a set of data points, and I want to get the best theoretical distribution that fits the data. For that I'm using Kolmogorov-Smirnov test for goodness of fit. This test reveals the p value of the two sided test. Can I chose the distribution as the best fitting distribution, which gives the highest p value for the K-S test?",,"['statistics', 'probability-distributions']"
95,Solving for a stationary point of a multivariate Gaussian parameter (CCA),Solving for a stationary point of a multivariate Gaussian parameter (CCA),,"I am reading a paper, probabilistic CCA , and am stuck on a particular derivation. Given the following multivariate Gaussian: $$ x \sim N(u, W W^{\top} + P) $$ where $x \in \mathbb{R}^p$. Let $S = W W^{\top} + P$ where $S \in \mathbb{R}^{p \times p}$, $W \in \mathbb{R}^{p \times n}$ and $P \in \mathbb{R}^{p \times p}$. Given the negative log-likelihood, $L$: $$ L = \frac{1}{2} \sum_{i=1}^{n}(x_i - u)^{\top} S^{-1} (x_i - u) + \frac{n}{2} \ln |S| + \text{const} $$ Taking the derivative, I have a stationary point $\frac{dL}{dW} = 0$, and I would like to solve for $W$ (Equation 3 in the paper): $$ (S^{-1} - S^{-1} Z Z^{\top} S^{-1}) W = 0 $$ where $Z = (x - u)$. How can I solve for $W$? I can reduce it to this form: $$ \begin{align} (S^{-1} - S^{-1} Z Z^{\top} S^{-1}) W &= 0 \\ S^{-1} W - S^{-1} Z Z^{\top} S^{-1} W &= 0 \\ S^{-1} W &= S^{-1} Z Z^{\top} S^{-1} W \\ W &= Z Z^{\top} S^{-1} W \end{align} $$ This looks like an eigenvector problem, $A v = \lambda v$, but $S^{-1}$ contains $W$: $$ W = Z Z^{\top} (WW^{\top} + P) W $$ I'm not sure how to simplify this further.","I am reading a paper, probabilistic CCA , and am stuck on a particular derivation. Given the following multivariate Gaussian: $$ x \sim N(u, W W^{\top} + P) $$ where $x \in \mathbb{R}^p$. Let $S = W W^{\top} + P$ where $S \in \mathbb{R}^{p \times p}$, $W \in \mathbb{R}^{p \times n}$ and $P \in \mathbb{R}^{p \times p}$. Given the negative log-likelihood, $L$: $$ L = \frac{1}{2} \sum_{i=1}^{n}(x_i - u)^{\top} S^{-1} (x_i - u) + \frac{n}{2} \ln |S| + \text{const} $$ Taking the derivative, I have a stationary point $\frac{dL}{dW} = 0$, and I would like to solve for $W$ (Equation 3 in the paper): $$ (S^{-1} - S^{-1} Z Z^{\top} S^{-1}) W = 0 $$ where $Z = (x - u)$. How can I solve for $W$? I can reduce it to this form: $$ \begin{align} (S^{-1} - S^{-1} Z Z^{\top} S^{-1}) W &= 0 \\ S^{-1} W - S^{-1} Z Z^{\top} S^{-1} W &= 0 \\ S^{-1} W &= S^{-1} Z Z^{\top} S^{-1} W \\ W &= Z Z^{\top} S^{-1} W \end{align} $$ This looks like an eigenvector problem, $A v = \lambda v$, but $S^{-1}$ contains $W$: $$ W = Z Z^{\top} (WW^{\top} + P) W $$ I'm not sure how to simplify this further.",,"['statistics', 'derivatives', 'partial-derivative', 'matrix-calculus']"
96,Inverse Laplace and Fourier Transform in Statistics,Inverse Laplace and Fourier Transform in Statistics,,"I am currently exploring the use of inverse laplace transform and inverse fourier transform in statistics. From what I have read, for a random variable $ X $ with $ f(x) $ and $ F(x) $ as its PDF and CDF, we can use inverse fourier transform to recover its PDF, which is $$ f(x) = \frac{1}{2\pi} \int_{-\infty}^{\infty} e^{-itx} \phi(t) dt $$ If I want to calculate the CDF of $ X $ at point a, I can integrate above formula $$ F(a) = \frac{1}{2\pi} \int_{-\infty}^{a} \int_{-\infty}^{\infty} e^{-itx} \phi(t) dt dx $$ with $ \phi(t) = E[e^{itX}] $ is a characteristic function of $ X $. From what I have read from Wikipedia, we can use inverse laplace transform to calculate a CDF of a random variable directly by using this formula $$ F(a) = \mathcal{L}^{-1} \bigg{\{} \frac{1}{s} E \Big{[}e^{-sX} \Big{]} \bigg{\}} $$ $$ F(a) = \frac{1}{2 \pi i} \int_{\gamma - i \infty}^{\gamma + i \infty} \frac{e^{sa}}{s} E \Big{[}e^{-sX} \Big{]} ds $$ I know inverse fourier transform is equal to inverse laplace transform if we take $ s = \gamma + it $. I am trying to prove the formula for $ F(a) $ is equal if we use inverse fourier transform and inverse laplace transform, but somehow, it is obvious that they are different, one with one integral and the other with two integrals. Or is there something wrong in the formula that I have stated so both of the are not the same? If it is already correct, kindly need your help to prove it. Thank you.","I am currently exploring the use of inverse laplace transform and inverse fourier transform in statistics. From what I have read, for a random variable $ X $ with $ f(x) $ and $ F(x) $ as its PDF and CDF, we can use inverse fourier transform to recover its PDF, which is $$ f(x) = \frac{1}{2\pi} \int_{-\infty}^{\infty} e^{-itx} \phi(t) dt $$ If I want to calculate the CDF of $ X $ at point a, I can integrate above formula $$ F(a) = \frac{1}{2\pi} \int_{-\infty}^{a} \int_{-\infty}^{\infty} e^{-itx} \phi(t) dt dx $$ with $ \phi(t) = E[e^{itX}] $ is a characteristic function of $ X $. From what I have read from Wikipedia, we can use inverse laplace transform to calculate a CDF of a random variable directly by using this formula $$ F(a) = \mathcal{L}^{-1} \bigg{\{} \frac{1}{s} E \Big{[}e^{-sX} \Big{]} \bigg{\}} $$ $$ F(a) = \frac{1}{2 \pi i} \int_{\gamma - i \infty}^{\gamma + i \infty} \frac{e^{sa}}{s} E \Big{[}e^{-sX} \Big{]} ds $$ I know inverse fourier transform is equal to inverse laplace transform if we take $ s = \gamma + it $. I am trying to prove the formula for $ F(a) $ is equal if we use inverse fourier transform and inverse laplace transform, but somehow, it is obvious that they are different, one with one integral and the other with two integrals. Or is there something wrong in the formula that I have stated so both of the are not the same? If it is already correct, kindly need your help to prove it. Thank you.",,"['statistics', 'laplace-transform', 'fourier-transform']"
97,Posterior distribution of a random distribution sampled from Dirichlet process,Posterior distribution of a random distribution sampled from Dirichlet process,,"I was reading a bit into nonparametric Bayesian statistics and came across the expression of the posterior of a random distribution $G$ sampled from the Dirichlet process given data sampled from $G$, namely: Let $G\sim DP(\alpha, H)$ be a random probability measure on a standard Borel space $\mathcal{X}$. Let $X_1,\dots,X_n\stackrel{\text{iid}}{\sim} G$. Then $$G\mid X_1,\dots,X_n\sim DP\left(\alpha+n,\; \frac{\alpha H + \sum_{i=1}^n \delta_{X_i}}{\alpha+n}\right).$$ However, no proof was given in the lecture notes and in other notes I could only find short, hand-waving proofs. I wanted to do this rigourously but don't know if the proof is correct. My proof follows from the fact that $G\sim DP(\alpha, H)$ if and only if for every partition $A_1,\dots, A_k$ of $\mathcal{X}$ we have that the vector $(G(A_1),\dots, G(A_k))\sim \operatorname{Dir}(\alpha H(A_1),\dots, \alpha H(A_k)).$ My proof: Let $A_1,\dots,A_k$ be a partition of $\mathcal{X}$ and let $N_j$ be $\sum_{i=1}^n\mathbb{1}_{\{X_i\in A_j\}}$ for $j\in\{1,\dots,k\}$. For our notation, denote $V_A:= (G(A_1),\dots,G(A_k)),\; X := (X_1,\dots,X_n),\; N_A:=(N_1,\dots,N_k)$ and let $n_A:=(n_1,\dots,n_k)$ be our observation of $N_A.$ Then we have by Bayes' rule and the definition of $G$ that: $$ f_{V_A\mid X}\left(p_1,\dots,p_k \right) \stackrel{(*)}{=}f_{V_A\mid N_A}\left(p_1,\dots,p_k \right) \propto f_{N_A\mid V_A}\left(n_1,\dots,n_k\right) f_{V_A}(p_1,\dots,p_k)\\\propto \prod_{i=1}^k p_j^{n_j} e^{\sum_{j=1}^k(\alpha H(A_j)-1)\log(p_j)} = e^{\sum_{i=1}^k n_j \log(p_j)} e^{\sum_{j=1}^k(\alpha H(A_j)-1)\log(p_j)}= e^{\sum_{j=1}^k(n_j+\alpha H(A_j)-1)\log(p_j)}. $$ Hence $V_A\mid X\sim \operatorname{Dir}(\alpha H(A_1)+\sum_{j=1}^n \delta_{X_j}(A_1),\dots,\alpha H(A_k)+\sum_{j=1}^n \delta_{X_j}(A_k))$ and by normalizing the measure and using the if and only if statement above: $$G\mid X\sim DP\left(a+n,\frac{\alpha H + \sum_{i=1}^n \delta_{X_i}}{\alpha+n}\right).\tag{$\square$}$$ The part of the proof I'm not quite sure about is the equation with $(*)$ above it. I got some information from page 41 of this source: https://www4.stat.ncsu.edu/~sghosal/papers/BayesAsymp.pdf The crux here is that we can consider a finer partition $B_1,\dots, B_m$ of $\mathcal{X}$ than $A$. Following the notation above, we see that $$V_B\mid N_B\sim \operatorname{Dir}(\alpha H(B_1)+\sum_{j=1}^n \delta_{X_j}(B_1),\dots,\alpha H(B_m)+\sum_{j=1}^n \delta_{X_j}(B_m))$$ If we now denote $s_{i,j}:=\mathbb{1}_{\{B_i\subseteq A_j\}}$ then we must have that $\sum_{i=1}^m s_{i,j}G(B_{i})=G(A_j)$ and hence by the aggregation property of the Dirichlet distribution and as the partition is disjoint: \begin{align} V_A\mid N_B & \sim \operatorname{Dir}\left(\sum_{j=1}^ms_{j,1}\left(\alpha H(B_j) + \sum_{k=1}^n \delta_{X_k}(B_j)\right), \dots, \sum_{j=1}^ms_{j,m} \left(\alpha H(B_j) + \sum_{k=1}^n \delta_{X_k}(B_j)\right)\right) \\ & \sim \operatorname{Dir}(\alpha H(A_1) + \sum_{j=1}^n \delta_{X_j}(A_1),\dots,\alpha H(A_k)+\sum_{j=1}^n \delta_{X_j}(A_k))\sim V_A\mid N_A. \end{align} Now consider a nested sequence of partitions $(A_j)_{j\in\mathbb{N}}$ converging to a partition over the dense subset of the regular Borel space $\mathcal{X}$. Then we know by Lévy's upward theorem (as $V_A$ is bounded, hence in $L^1$) that $V_j:= V_A\mid N_{A_j}$ is a martingale converging almost surely to a version of $V_A\mid \mathcal{F}$ where $\mathcal{F} = \sigma(\cup_{j} \sigma(N_{A_j})).$ Now we have $\mathcal{F}=\sigma(X)$. This holds as $\sigma(X)=\sigma(X^{-1}(\mathcal{B}(\prod_{i=1}^n\mathcal{X})))$ (where $\mathcal{B}(\prod_{i=1}^n\mathcal{X})$ are Borel sets of $\prod_{i=1}^n \mathcal{X}$ and $\prod$ denotes Cartesian product) and $\sigma(N_{A_j})= \sigma(X^{-1}(\prod_{i=1}^n A_j))$ (where $A_j$ denotes the collection). As every Borel set in $\mathcal{B}(\prod_{i=1}^n \mathcal{X})$ can be approximated arbitrarily close by (possible unions) of sets in $\prod_{i=1}^n A_j$ by taking $j$ large enough, the sigma algebra's are equal in the limit. Hence as $V_A\mid N_A\sim V_A\mid N_{A_j}$ for all $j$, and $V_j\stackrel{d}{\rightarrow}V_A\mid X$ (by almost sure convergence), we must have $V_A\mid N_A\sim V_A\mid X$ and hence the corresponding densities are the same. As I said I'm not quite sure about the last part, certainly the part with the sigma-algebra's. I hope you could give some feedback.. The other sources I checked were: http://stat.columbia.edu/~porbanz/papers/porbanz_BNP_draft.pdf http://www.math.leidenuniv.nl/~avdvaart/BNP/BNP.pdf https://www.stats.ox.ac.uk/~teh/research/npbayes/Teh2010a.pdf","I was reading a bit into nonparametric Bayesian statistics and came across the expression of the posterior of a random distribution $G$ sampled from the Dirichlet process given data sampled from $G$, namely: Let $G\sim DP(\alpha, H)$ be a random probability measure on a standard Borel space $\mathcal{X}$. Let $X_1,\dots,X_n\stackrel{\text{iid}}{\sim} G$. Then $$G\mid X_1,\dots,X_n\sim DP\left(\alpha+n,\; \frac{\alpha H + \sum_{i=1}^n \delta_{X_i}}{\alpha+n}\right).$$ However, no proof was given in the lecture notes and in other notes I could only find short, hand-waving proofs. I wanted to do this rigourously but don't know if the proof is correct. My proof follows from the fact that $G\sim DP(\alpha, H)$ if and only if for every partition $A_1,\dots, A_k$ of $\mathcal{X}$ we have that the vector $(G(A_1),\dots, G(A_k))\sim \operatorname{Dir}(\alpha H(A_1),\dots, \alpha H(A_k)).$ My proof: Let $A_1,\dots,A_k$ be a partition of $\mathcal{X}$ and let $N_j$ be $\sum_{i=1}^n\mathbb{1}_{\{X_i\in A_j\}}$ for $j\in\{1,\dots,k\}$. For our notation, denote $V_A:= (G(A_1),\dots,G(A_k)),\; X := (X_1,\dots,X_n),\; N_A:=(N_1,\dots,N_k)$ and let $n_A:=(n_1,\dots,n_k)$ be our observation of $N_A.$ Then we have by Bayes' rule and the definition of $G$ that: $$ f_{V_A\mid X}\left(p_1,\dots,p_k \right) \stackrel{(*)}{=}f_{V_A\mid N_A}\left(p_1,\dots,p_k \right) \propto f_{N_A\mid V_A}\left(n_1,\dots,n_k\right) f_{V_A}(p_1,\dots,p_k)\\\propto \prod_{i=1}^k p_j^{n_j} e^{\sum_{j=1}^k(\alpha H(A_j)-1)\log(p_j)} = e^{\sum_{i=1}^k n_j \log(p_j)} e^{\sum_{j=1}^k(\alpha H(A_j)-1)\log(p_j)}= e^{\sum_{j=1}^k(n_j+\alpha H(A_j)-1)\log(p_j)}. $$ Hence $V_A\mid X\sim \operatorname{Dir}(\alpha H(A_1)+\sum_{j=1}^n \delta_{X_j}(A_1),\dots,\alpha H(A_k)+\sum_{j=1}^n \delta_{X_j}(A_k))$ and by normalizing the measure and using the if and only if statement above: $$G\mid X\sim DP\left(a+n,\frac{\alpha H + \sum_{i=1}^n \delta_{X_i}}{\alpha+n}\right).\tag{$\square$}$$ The part of the proof I'm not quite sure about is the equation with $(*)$ above it. I got some information from page 41 of this source: https://www4.stat.ncsu.edu/~sghosal/papers/BayesAsymp.pdf The crux here is that we can consider a finer partition $B_1,\dots, B_m$ of $\mathcal{X}$ than $A$. Following the notation above, we see that $$V_B\mid N_B\sim \operatorname{Dir}(\alpha H(B_1)+\sum_{j=1}^n \delta_{X_j}(B_1),\dots,\alpha H(B_m)+\sum_{j=1}^n \delta_{X_j}(B_m))$$ If we now denote $s_{i,j}:=\mathbb{1}_{\{B_i\subseteq A_j\}}$ then we must have that $\sum_{i=1}^m s_{i,j}G(B_{i})=G(A_j)$ and hence by the aggregation property of the Dirichlet distribution and as the partition is disjoint: \begin{align} V_A\mid N_B & \sim \operatorname{Dir}\left(\sum_{j=1}^ms_{j,1}\left(\alpha H(B_j) + \sum_{k=1}^n \delta_{X_k}(B_j)\right), \dots, \sum_{j=1}^ms_{j,m} \left(\alpha H(B_j) + \sum_{k=1}^n \delta_{X_k}(B_j)\right)\right) \\ & \sim \operatorname{Dir}(\alpha H(A_1) + \sum_{j=1}^n \delta_{X_j}(A_1),\dots,\alpha H(A_k)+\sum_{j=1}^n \delta_{X_j}(A_k))\sim V_A\mid N_A. \end{align} Now consider a nested sequence of partitions $(A_j)_{j\in\mathbb{N}}$ converging to a partition over the dense subset of the regular Borel space $\mathcal{X}$. Then we know by Lévy's upward theorem (as $V_A$ is bounded, hence in $L^1$) that $V_j:= V_A\mid N_{A_j}$ is a martingale converging almost surely to a version of $V_A\mid \mathcal{F}$ where $\mathcal{F} = \sigma(\cup_{j} \sigma(N_{A_j})).$ Now we have $\mathcal{F}=\sigma(X)$. This holds as $\sigma(X)=\sigma(X^{-1}(\mathcal{B}(\prod_{i=1}^n\mathcal{X})))$ (where $\mathcal{B}(\prod_{i=1}^n\mathcal{X})$ are Borel sets of $\prod_{i=1}^n \mathcal{X}$ and $\prod$ denotes Cartesian product) and $\sigma(N_{A_j})= \sigma(X^{-1}(\prod_{i=1}^n A_j))$ (where $A_j$ denotes the collection). As every Borel set in $\mathcal{B}(\prod_{i=1}^n \mathcal{X})$ can be approximated arbitrarily close by (possible unions) of sets in $\prod_{i=1}^n A_j$ by taking $j$ large enough, the sigma algebra's are equal in the limit. Hence as $V_A\mid N_A\sim V_A\mid N_{A_j}$ for all $j$, and $V_j\stackrel{d}{\rightarrow}V_A\mid X$ (by almost sure convergence), we must have $V_A\mid N_A\sim V_A\mid X$ and hence the corresponding densities are the same. As I said I'm not quite sure about the last part, certainly the part with the sigma-algebra's. I hope you could give some feedback.. The other sources I checked were: http://stat.columbia.edu/~porbanz/papers/porbanz_BNP_draft.pdf http://www.math.leidenuniv.nl/~avdvaart/BNP/BNP.pdf https://www.stats.ox.ac.uk/~teh/research/npbayes/Teh2010a.pdf",,"['probability-theory', 'statistics', 'measure-theory', 'statistical-inference', 'bayesian']"
98,Equivalent defintions of minimal sufficient statistics,Equivalent defintions of minimal sufficient statistics,,"Wikipedia claims that the statistic $S(X)$ is minimal sufficient if and only if $f_{\theta}(x)/f_{\theta}(y) $ is independent of $\theta$ $\iff$ $S(x) = S(y)$. It is also claimed that this is a direct consequence of Fisher's factorization theorem. However, I do not see how this is a direct consequence. As a definition of sufficient statistic, I know that the following two are equivalent: $S(x) = S(y)$ $\implies$  $f_{\theta}(x)/f_{\theta}(y) $ is independent of $\theta$ The conditional distribution of $X$ given $S(X)$ does not depend on $\theta$. As a definition of minimal sufficient, I use that a sufficient statistic $S(X)$ is a minimal sufficient statistic if and only if for all sufficient statistics $S'$, $S'(x) = S'(y)$ implies $S(x)=S(y)$. I can prove that if $f_{\theta}(x)/f_{\theta}(y) $ is independent of $\theta$ $\iff$ $S(x) = S(y)$, then $S(X)$ is minimal sufficient The direction $S(x) = S(y)$ $\implies$  $f_{\theta}(x)/f_{\theta}(y) $ is independent of $\theta$  is implies the fact $S$ is sufficient. Now if $S'$ is sufficient, then  $S'(x) = S'(y)$ implies $f_{\theta}(x)/f_{\theta}(y) $ is independent of $\theta$, which implies $S(x) = S(y)$. So  $S(X)$ is minimal sufficient. But I am struggeling with showing that if $S(X)$ is minimal sufficient, then  $f_{\theta}(x)/f_{\theta}(y) $ is independent of $\theta$ $\iff$ $S(x) = S(y)$. I don't see how the factorization theorem helps here.","Wikipedia claims that the statistic $S(X)$ is minimal sufficient if and only if $f_{\theta}(x)/f_{\theta}(y) $ is independent of $\theta$ $\iff$ $S(x) = S(y)$. It is also claimed that this is a direct consequence of Fisher's factorization theorem. However, I do not see how this is a direct consequence. As a definition of sufficient statistic, I know that the following two are equivalent: $S(x) = S(y)$ $\implies$  $f_{\theta}(x)/f_{\theta}(y) $ is independent of $\theta$ The conditional distribution of $X$ given $S(X)$ does not depend on $\theta$. As a definition of minimal sufficient, I use that a sufficient statistic $S(X)$ is a minimal sufficient statistic if and only if for all sufficient statistics $S'$, $S'(x) = S'(y)$ implies $S(x)=S(y)$. I can prove that if $f_{\theta}(x)/f_{\theta}(y) $ is independent of $\theta$ $\iff$ $S(x) = S(y)$, then $S(X)$ is minimal sufficient The direction $S(x) = S(y)$ $\implies$  $f_{\theta}(x)/f_{\theta}(y) $ is independent of $\theta$  is implies the fact $S$ is sufficient. Now if $S'$ is sufficient, then  $S'(x) = S'(y)$ implies $f_{\theta}(x)/f_{\theta}(y) $ is independent of $\theta$, which implies $S(x) = S(y)$. So  $S(X)$ is minimal sufficient. But I am struggeling with showing that if $S(X)$ is minimal sufficient, then  $f_{\theta}(x)/f_{\theta}(y) $ is independent of $\theta$ $\iff$ $S(x) = S(y)$. I don't see how the factorization theorem helps here.",,"['statistics', 'statistical-inference', 'sufficient-statistics']"
99,noise-free Gaussian Process likelyhood,noise-free Gaussian Process likelyhood,,"I am learning Gaussian Process reading GPML . I am a bit confused with understanding the Bayesian analysis. Let consider the standard linear regression model with ""Gaussian noise"", i.e, $$ f(\textbf{x}) = \textbf{x}^T\textbf{w}, \qquad y = f(\textbf{x}) + \epsilon, \qquad \epsilon \sim \mathcal{N}(0,\sigma_n^2) $$ where $\textbf{w}, \textbf{x} \in \mathbb{R}^n$. Note that $$ \epsilon = y - f(\textbf{x}) = y - \textbf{x}^T\textbf{w} \sim \mathcal{N}(0,\sigma_n^2) $$ and the p.d.f. of $\epsilon$ is  $$ p_\epsilon(z) = \frac{1}{\sqrt{2\pi}\sigma_n}\exp\left(-\frac{z^2}{2\sigma_n^2}\right).  $$ Therefore, given $\textbf{x}$ and $\textbf{w}$, the p.d.f. of $y$ would be $$ p_{y\mid \textbf{x}, \textbf{w}}(z) = \frac{1}{\sqrt{2\pi}\sigma_n}\exp\left(-\frac{(z-\textbf{x}^T\textbf{w})^2}{2\sigma_n^2}\right).  $$ It then follows from the Bayes' rule that $$ p_{\textbf{w}\mid y, \textbf{x}}(w) = \frac{p_{y\mid \textbf{x},\textbf{w}}(z)\cdot p_{\textbf{w}}(w)}{p_{y\mid \textbf{x}}(z)}. $$ Question: In the noise-free setup, how one can derive the posterior distribution $p_{\textbf{w}\mid y, \textbf{x}}(w)$? It seems that in the noise-free setup, $y$ is completely determined by $\textbf{x}$ and $\textbf{w}$. Thus  $$p_{y\mid \textbf{x},\textbf{w}}(z) = \delta_{\{z=\textbf{x}^T\textbf{w}\}}(z), $$ a point distribution. Then this gives $$ p_{\textbf{w}\mid y, \textbf{x}}(w) = \frac{\delta_{\{z=\textbf{x}^T\textbf{w}\}}(z)}{P_{\textbf{w}}(\textbf{x}^T\textbf{w}=z \mid \textbf{x})}p_{\textbf{w}}(w) ? $$ (actually, not 100% sure about this). At this point, I don't see how the Bayeian approach is somehow useful in the noise-free senario. Or Is Bayeian approach based on the assumption of the presence of the noise? Any comments/answers/suggestions would be very appreciated. Thank you in advance.","I am learning Gaussian Process reading GPML . I am a bit confused with understanding the Bayesian analysis. Let consider the standard linear regression model with ""Gaussian noise"", i.e, $$ f(\textbf{x}) = \textbf{x}^T\textbf{w}, \qquad y = f(\textbf{x}) + \epsilon, \qquad \epsilon \sim \mathcal{N}(0,\sigma_n^2) $$ where $\textbf{w}, \textbf{x} \in \mathbb{R}^n$. Note that $$ \epsilon = y - f(\textbf{x}) = y - \textbf{x}^T\textbf{w} \sim \mathcal{N}(0,\sigma_n^2) $$ and the p.d.f. of $\epsilon$ is  $$ p_\epsilon(z) = \frac{1}{\sqrt{2\pi}\sigma_n}\exp\left(-\frac{z^2}{2\sigma_n^2}\right).  $$ Therefore, given $\textbf{x}$ and $\textbf{w}$, the p.d.f. of $y$ would be $$ p_{y\mid \textbf{x}, \textbf{w}}(z) = \frac{1}{\sqrt{2\pi}\sigma_n}\exp\left(-\frac{(z-\textbf{x}^T\textbf{w})^2}{2\sigma_n^2}\right).  $$ It then follows from the Bayes' rule that $$ p_{\textbf{w}\mid y, \textbf{x}}(w) = \frac{p_{y\mid \textbf{x},\textbf{w}}(z)\cdot p_{\textbf{w}}(w)}{p_{y\mid \textbf{x}}(z)}. $$ Question: In the noise-free setup, how one can derive the posterior distribution $p_{\textbf{w}\mid y, \textbf{x}}(w)$? It seems that in the noise-free setup, $y$ is completely determined by $\textbf{x}$ and $\textbf{w}$. Thus  $$p_{y\mid \textbf{x},\textbf{w}}(z) = \delta_{\{z=\textbf{x}^T\textbf{w}\}}(z), $$ a point distribution. Then this gives $$ p_{\textbf{w}\mid y, \textbf{x}}(w) = \frac{\delta_{\{z=\textbf{x}^T\textbf{w}\}}(z)}{P_{\textbf{w}}(\textbf{x}^T\textbf{w}=z \mid \textbf{x})}p_{\textbf{w}}(w) ? $$ (actually, not 100% sure about this). At this point, I don't see how the Bayeian approach is somehow useful in the noise-free senario. Or Is Bayeian approach based on the assumption of the presence of the noise? Any comments/answers/suggestions would be very appreciated. Thank you in advance.",,"['statistics', 'statistical-inference', 'machine-learning', 'bayesian']"
